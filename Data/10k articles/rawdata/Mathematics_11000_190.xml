<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>22 (number)</title>
    <ns>0</ns>
    <id>362193</id>
    <revision>
      <id>870043396</id>
      <parentid>870043291</parentid>
      <timestamp>2018-11-22T00:44:15Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>/* In mathematics */ fix access date</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7178">{{about|the number||22 (disambiguation)}}
{{example farm|date=March 2010}}
{{Infobox number
| number =  22
| divisor = 1, 2, 11, 22
}}
'''22''' ('''twenty-two''') is the [[natural number]] following [[21 (number)|21]] and preceding [[23 (number)|23]].

== In mathematics ==
*22 is a [[deficient number]]
*22 is an even [[composite number]] and a [[semiprime]]; its proper [[divisor]]s are [[1 (number)|1]], [[2 (number)|2]], and [[11 (number)|11]].
*22 is a [[pentagonal number]]&lt;ref&gt;{{Cite OEIS|A000326|Pentagonal numbers|access-date=2016-05-31}}&lt;/ref&gt; and a [[centered heptagonal number]].&lt;ref&gt;{{Cite OEIS|A069099|Centered heptagonal numbers|access-date=2016-05-31}}&lt;/ref&gt;
*When cutting a [[circle]] with just six [[line segment]]s, the maximum number of pieces that can be so created is 22,&lt;ref&gt;Wells, D. ''[[The Penguin Dictionary of Curious and Interesting Numbers]]'' London: Penguin Group. (1986): 31&lt;/ref&gt; thus 22 is a central polygonal number (see [[lazy caterer's sequence]]).&lt;ref&gt;{{Cite OEIS|A000124|Central polygonal numbers (the Lazy Caterer's sequence)|access-date=2016-05-31}}&lt;/ref&gt;
*22 is the sum of the [[Euler's totient function|totient function]] for the first eight integers.&lt;ref&gt;{{Cite OEIS|A002088|Sum of totient function|access-date=2016-05-31}}&lt;/ref&gt;
*22 is a [[Perrin number]], preceded in the sequence by [[10 (number)|10]], [[12 (number)|12]], and [[17 (number)|17]].&lt;ref&gt;{{Cite OEIS|A001608|Perrin sequence|access-date=2016-05-31}}&lt;/ref&gt;
*22 divided by [[7 (number)|7]] approximates the [[irrational number]] [[Pi|{{pi}}]], the ratio of the [[circumference]] of a circle to its [[diameter]].
*22 is an [[Erdős–Woods number]], since it is possible to find sequences of 22 consecutive integers such that each inner member shares a factor with either the first or the last member.&lt;ref&gt;{{Cite OEIS|A059756|Erdős-Woods numbers|access-date=2016-05-31}}&lt;/ref&gt;
*22 is a [[Smith number]] in base 10.&lt;ref&gt;{{Cite OEIS|A006753|Smith numbers|access-date=2016-05-31}}&lt;/ref&gt;
*"2-2" is the only [[fixed point (mathematics)|fixed point]] of [[John Horton Conway|John Conway's]] [[look-and-say sequence|look-and-say function]].&lt;ref name="Martin2006"&gt;
{{cite journal
 |title=Look-and-Say Biochemistry: Exponential RNA and Multistranded DNA
 |first=Oscar
 |last=Martin
 |journal=American Mathematical Monthly
 |year=2006
 |volume=113
 |issue=4
 |pages=289&amp;ndash;307	
 |publisher=Mathematical association of America
 |issn=0002-9890
 |url=http://www.uam.es/personal_pdi/ciencias/omartin/Biochem.PDF
 |archiveurl=https://web.archive.org/web/20061224154744/http://www.uam.es/personal_pdi/ciencias/omartin/Biochem.PDF
 |archivedate=2006-12-24
 |accessdate=2018-11-21
 |doi=10.2307/27641915
}}&lt;/ref&gt;{{importance inline}}

==In physics and chemistry==
*22 is the [[atomic number]] of [[titanium]].

==In aircraft==
*22 is the designation of the USAF stealth fighter, the [[F-22 Raptor]].

==In art, entertainment, and media==

===In music===
*[[Twenty Two (Millencolin song)|"Twenty Two"]] is a 1997 song by the punk band Millencolin
*In [[Jay-Z]]'s song "22 Two's", he rhymes the words: too, to, and two, 22 times in the first verse.
*"22 Acacia Avenue" is a song by Iron Maiden on the album ''[[The Number of the Beast (album)|The Number of the Beast]]''
*''[[Catch 22 (Hypocrisy album)|Catch 22]]'' is an album by death metal band Hypocrisy
*"[[22 (Lily Allen song)|22]]" is a song by Lily Allen on the album ''It's Not Me, It's You''.
*''[[22 Dreams]]'' is a song and album by Paul Weller. The album contains 22 songs on it.
*The Norwegian electronica project [[Ugress]] uses 22 as a recurring theme. All four albums features a track with 22 in the title.
*"[[22 (Taylor Swift song)|22]]" is a song by Taylor Swift on her fourth album ''Red''
*"The Number 22" is a song by [[Ashbury Heights]] on the album ''The Looking Glass Society''.
*''[[22, A Million]]'' is an album by Bon Iver. The first track of the album is called "22 (OVER SOON)".
*[[Cubic 22]] was a Belgian techno duo.
*"22" is a song by the English alternative rock band Deaf Havana on their album [[Old Souls (album)|Old Souls]]

===In other fields===
*''[[Catch-22]]'' (1961), [[Joseph Heller]]'s novel, and its 1970 film adaptation gave rise to the expression of logic "[[Catch-22 (logic)|catch-22]]".
*''[[Revista 22]]'' is a magazine published in [[Romania]].
*There are 22 stars in the [[Paramount Pictures]] logo.
*"[[Twenty Two (The Twilight Zone)|Twenty Two]]" (February 10, 1961) is Season 2&amp;ndash;episode 17 (February 10, 1961) of the 1959-64 TV series ''[[The Twilight Zone (1959 TV series)|The Twilight Zone]]'', in which a hospitalized dancer has nightmares about a sinister nurse inviting her to Room 22, the hospital morgue.
*Traditional [[Tarot]] decks have 22 cards with allegorical subjects. These serve as [[trump (card games)|trump]] cards in the [[French tarot|game]]. The [[The Fool (Tarot card)|Fool]] is usually a kind of [[Wild card (card games)|wild-card]] among the trumps and unnumbered, so the highest trump is numbered 21. [[Divinatory tarot|Occult Tarot decks]] usually have 22 similar cards which are called [[Major Arcana]] by [[fortune-telling|fortune-tellers]]. Occultists have related this number to the 22 letters of the Hebrew alphabet and the 22 paths in the Kabbalistic [[Tree of life (Kabbalah)|Tree of Life]].

==In computing and technology==
*22 is the standard [[List of TCP and UDP port numbers|port number]] for the [[Secure Shell]] protocol
*A [[quotation mark]] (in a [[URL]] it appears as a "%22")

==In religion==
*There are 22 letters in the [[Hebrew alphabet]].
*In the [[Kabbalah]], there are 22 paths between the ''[[Sephirot]]''.

==In sports==
*In soccer there are 22 players that start a game and the maximum number of players playing at any time. 
*In [[Australian rules football]], each team is allowed a squad of 22 players (18 on the field and 4 interchanges).
*The length of a [[cricket pitch]] is 22 yards.
*In [[rugby union]], the "22" is a line in each half of the field which is 22 meters from the respective try line. It has significance in a number of laws particularly relating to kicking the ball away.

==In weights and measures==
*The number of [[yard]]s in a [[chain (unit)|chain]].

==In other uses==
'''Twenty-two''' may also refer to:
* 22 is the number of the [[French department]] [[Côtes-d'Armor]]
* "22" is a common name for the .22 calibre [[.22 Long Rifle]] cartridge.
*In [[French (language)|French]] jargon, "22" is used as a phrase to warn of the coming of the police (typically ''"22, v'là les flics !"'' (In English: "5-0! Cops!")
* In photography, f/22 is the largest [[F-number|f-stop]] (and thus smallest [[aperture]]) available on most lenses made for [[single-lens reflex camera]]s

==See also==
*[[Catch 22 (disambiguation)]]
*[[List of highways numbered 22]]
*[[Synchronicity]]{{relevance-inline|date=November 2018}}

==References==
&lt;references/&gt;

==External links==
{{Commons category|22 (number)}}
* {{cite web|url=http://www.virtuescience.com/22.html|website=Virtuescience|title= The Number 22 at The Database of Number Correlations}}

{{Integers|zero}}

{{DEFAULTSORT:22 (Number)}}
[[Category:Integers]]</text>
      <sha1>pzjl7pa1ut7vnrmyz4n8x09faszjnel</sha1>
    </revision>
  </page>
  <page>
    <title>Academic Games</title>
    <ns>0</ns>
    <id>894157</id>
    <revision>
      <id>866885739</id>
      <parentid>866885730</parentid>
      <timestamp>2018-11-02T05:12:16Z</timestamp>
      <contributor>
        <username>Jim1138</username>
        <id>7695475</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/35.21.119.53|35.21.119.53]] ([[User talk:35.21.119.53|talk]]): [[WP:NOR|original research]] ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19518">{{Infobox company
| name        = Academic Games
| logo        = Academic Games League of America logo.png
| caption     = Academic Games Logo
| type        = [[Non-Profit Organization]]
| predecessor = [[National Academic Games Project]]
| foundation  = 1991
| homepage    = http://agloa.org
}}

'''Academic Games''' is a competition in the U.S. in which players win by out-thinking each other in [[mathematics]], [[language arts]], and [[social studies]].  Formal tournaments are organized by local leagues, and on a national level by the '''Academic Games Leagues of America''' ('''AGLOA'''). Member leagues in eight states hold a national tournament every year, in which players in four divisions compete in eight different games covering math, English, and history. Some turn-based games require a kit consisting of a board and playing cubes, while other games have a central reader announcing questions or clues and each player answering individually.

==History==
[[File:Equations an Academic Game (circa 1969).jpg|thumb|"Equations" by Layman E. Allen (circa 1969)]]
Before the existence of AGLOA, tournaments were held by the [[National Academic Games Project]] founded by the creator of many of the games. The earliest tournaments, in the late 1960s, were held on or near the campus of [[Nova High School]] in Davie, Florida. Nova was the [[user acceptance testing|beta test]] site for the game "Propaganda" and others. Many AGLOA leaders were involved with NAGP. The new league was created partially because of personal conflict with Robert W. Allen. Allen later sued the AGLOA for copyright, trademark, and tradename infringement.&lt;ref&gt;{{cite web|url=http://laws.lp.findlaw.com/9th/9456593.html |title=Archived copy |accessdate=2004-08-12 |deadurl=yes |archiveurl=https://web.archive.org/web/20040822005857/http://laws.lp.findlaw.com/9th/9456593.html |archivedate=2004-08-22 |df= }}&lt;/ref&gt;

Academic Games Leagues of America was founded in 1991 to encourage the use of Academic Games as an educational tool and as a scholar competition.  Many of the games used in tournaments, however, were created as early as in the 1960s and 1970s. Most of the games played at tournaments are available from Wff 'N Proof Learning Games. Brother Neal Golden of New Orleans is the current board president of AGLOA; Rod Beard of West Bloomfiend, MI is the current vice-president. Other board members represent Academic Games leagues in Florida, Georgia, Louisiana, Michigan, Pennsylvania, and West Virginia.

==Divisions==
Academic Games players compete with other players in their own age group.  These are the four age divisions in the league.
#Elementary - Grades 6 or below
#Middle - Grades 7-8
#Junior - Grades 9-10
#Senior - Grades 11-12

However, there is no restriction against playing one of your players in a higher division. Several teams have won national championships in the senior division, even though half their players belonged, agewise, in the junior division.

Games become more challenging as a player progresses through the divisions. There are often two variations of the games: basic and adventurous. Basic games have no variations or special demands players can make on game solutions. Adventurous games have a series of variation possibilities that may apply and increase in difficulty as players age.

==Games Played==
Eight games are played in official AGLOA tournaments.  Some local leagues also play other games such as [[On-Words]] (a simplified version of LinguiSHTIK).

===Math Games===
Two math games, '''Equations''' and '''On-Sets''' are played at AGLOA tournaments.

====Equations====
'''[[Equations (game)|Equations]]''' is a [[mathematics]] game created in 1965 for 2-3 players. The game uses a playing mat with Forbidden, Permitted, and Required sections and 24 cubes, each labeled with numbers and mathematical operations. At the beginning of each "shake", one player uses up to six cubes to set a "goal." All players must use the remaining cubes to devise a solution that equals the goal or win by challenging an impossible board + goal situation.

Gameplay can become more complicated through the use of "variations" called on the game. Applicable variations differ by the player's age division. The game progresses with each player moving one cube on their turn, or alternatively challenging that they can create a solution with the cubes in play, that a solution was possible on the last turn and the player before had missed it, or challenging that it is impossible to create a solution with the cubes available.  When a player calls a challenge, it is called against the player who most recently completed their move.

In a three player game, the indifferent player may choose who he sides with in the case of a challenge.  A player who correctly challenges another player wins the game. The loser of a game gains two points, The winner six, and the sider (if he sided with the winner) gains four or two (if he sided with the loser).  Equations games become more intricate with the use of [[factorial]]s, [[vulgar fraction]]s, and even [[logarithms]], in the Senior division.

====On-Sets====
[[On-Sets]] is a board and cube game that teaches basic [[logic]] and [[set theory]]. This game also uses a deck of 16 cards that is used to make the "Universe".  Each card contains a different combination of colored dots. The cubes contain numbers, colors and logic operators.

Players learn logic concepts such as [[union (set theory)|union]] and [[intersect (set theory)|intersection]], and learn to use restrictions such as [[subset]]. Variations can be also be used in On-Sets games. A player wins by using the cubes in resources to create a logical statement which equals the goal set using the numeral cubes. Challenges and multiplayer games work in a similar way to Equations game.

====WFF 'N Proof====
{{main|WFF 'N PROOF}}
WFF 'N Proof is a board and cube game that was created by Professor Layman Allen in 1961 to teach the basics of symbolic logic.&lt;ref&gt;{{cite web|url=http://mlagonline.com/Wff.html?AOLHelp%3D3d947422.3a9.70c.1%26ServerName%3Dwww.wff-n-proof.com |title=Archived copy |accessdate=2011-03-19 |deadurl=yes |archiveurl=https://web.archive.org/web/20110822070307/http://mlagonline.com/Wff.html?AOLHelp=3d947422.3a9.70c.1&amp;ServerName=www.wff-n-proof.com |archivedate=2011-08-22 |df= }}&lt;/ref&gt;
It is played with 28 cubes that contain various letters, such as p, q, C, or N. The game board contains a forbidden section, a permitted section, and a required section. To win the game, you have to write a proof, using the cubes to create "WFFs" ([[Well-formed formula|Well-Formed Formulas]]). This game is now part of the AGLOA National Tournament, beginning in 2013.

===Language Games===

====LinguiSHTIK====
[[LinguiSHTIK]] is a technical game that teaches [[language arts]] and [[linguistics]]. The game has a playing mat and 23 cubes which are imprinted with the 26 letters of the alphabet.

A player has to create a word using the letters available, and the word must be used in a sentence that matches the Demands called.  A demand specifies something about the sentence or word, such as number of clauses, part of speech, number of letters, etc. Challenges in LinguiSHTIK work similarly as in the other cube games with the exception of a forceout, which is called when moving any cube would result in a Challenge Win.  Some concepts taught in LinguiSHTIK include [[sentence patterns]], [[clause]]s, [[grammar]], and [[verbs]].

The game has elements similar to the popular word game [[Scrabble]] but adds a different element of play through grammatical demands and the shared letter pool.

====Propaganda====
{{see also|propaganda|logical fallacy}}
In '''Propaganda''', clues are read to all players by a central reader. Each player must decide, from a list, which [[persuasion]] technique that clue used, if any. There are several different sections of Propaganda techniques; the reader also specifies which section the persuasion technique is listed in.

Different leagues have different scoring methods, but the official AGLOA scoring involves a "bold" and "cautious" wager method. If you wager "bold", then you receive four points for a correct answer or lose two points for an incorrect answer.  If you wager "cautious," then you receive two points for a correct answer; however, you lose nothing for an incorrect answer.  A round consists of nine questions, so the highest score possible per round is 36 points, while the lowest is -18 points.

Most Propaganda clues involve statements that are likely to be heard in [[advertising]] or [[politics]].  There are six different Propaganda sections, but only four specific sections are used in each season. Sections A, B, D, and E are being used for the 2016-2017 season, and B, C, D, and F will be used for the 2017-2018 season.  For 2018-2019, the sections will be A, C, D, and E. For 2019-2020, the sections will be A, B, C, and F. For 2020-2021, the sections will be B, C, D, and E. Here are all the Propaganda techniques, listed by section.

=====Propaganda Techniques=====
{{see|propaganda techniques}}
More complete definitions of the individual techniques can be found on agloa.org.&lt;ref&gt;http://www.academicgames.org/propDefinitions.html&lt;/ref&gt;
{| border="1" class="wikitable"
|-
| #||''Section A''||''Section B''||''Section C''||''Section D''||''Section E''||''Section F''
|-
| ||'Techniques of [[self-deception|Self-Deception]]'||'Techniques of Language'||'Techniques of Irrelevance'||'Techniques of Exploitation'||'Techniques of Form'||'Techniques of Maneuver'
|-
|0
|No Technique
|No Technique
|No Technique
|No Technique
|No Technique
|No Technique
|-
| 1||[[Prejudice]]||[[pathos|Emotional]] Terms||Appearance||[[Appeal To Pity]]||[[cum hoc ergo propter hoc|Concurrency]]||[[Distraction|Diversion]]
|-
| 2||Academic Detachment||[[Metaphor]]/[[Simile]]||Manner||Appeal to [[Flattery]]||[[Post hoc ergo propter hoc|Post Hoc]]||Disproving a Minor Point
|-
| 3||[[False dilemma|Drawing the Line]]||Emphasis||Degrees and Titles||[[Appeal to Ridicule]]||[[Instance selection|Selected Instances]]||[[Ad Hominem]]
|-
| 4||Not Drawing the Line||[[Quotation out of Context]]||Numbers||Appeal to [[reputation|Prestige]]||[[Hasty Generalization]]||[[Appeal to Ignorance]]
|-
| 5||[[Conservatism]], [[Political radicalism|Radicalism]], [[Compromise|Moderatism]]||Abstract Terms||Status||[[Appeal to prejudice|Appeal to Prejudice]]||[[Faulty Analogy]]||[[Leading Question]]
|-
| 6||[[Rationalization (psychology)|Rationalization]]||[[Vagueness]]||[[Repetition variation|Repetition]]||Bargain Appeal||[[Fallacy of composition|Composition]]||[[Complex Question]]
|-
| 7||[[Wishful thinking|Wishful Thinking]]||[[Ambiguity]]||[[Slogan]]s||[[Folksy]] Appeal||[[Fallacy of division|Division]]||Inconsequent Argument
|-
| 8||[[Tabloid journalism|Tabloid]] Thinking||Shift of Meaning||Technical [[Jargon]]||[[Join the Bandwagon]] Appeal||[[Non sequitur (logic)|Non-Sequitur]]||[[Attacking a Straw Man]]
|-
| 9||[[Causal Oversimplification]]||---||Sophistical Formula||Appeal to Practical [[Appeal to consequences|Consequences]]||---||Victory By Definition
|-
| 10||Inconceivability||---||---||[[Slippery slope|Passing from the Acceptable to the Dubious]] ||---||[[Begging the Question]]
|}

===Social Studies Games===

====Presidents====
A reader announces three clues about a particular [[President of the United States|U.S. President]].  Each player must individually write down which President the clue describes. Players who answer correctly on the earliest clue get more points than players that answer after more clues are given.  The first clue is worth 6 points, the second is worth 4 points, and the third is worth 2 points. The 6 point clue is the hardest clue, while the 4 point and 2 point clues get progressively easier.

In the Elementary and Middle divisions, only a portion of presidents are used per season. For those divisions, ranges switch between presidents 1-24 and 25-45 every other year. In Junior and Senior divisions, however, all the presidents are used every season. During a tournament, players are assisted by a gazetteer which has each president's name, birth date, birthplace, and other basic information.

====World Events====
This event was part of the national tournament through 2016, after which its two rounds, Current Events and Theme, were each made an independent game.

This game was originally known as “World Card.”

==== Current Events ====
This event concerns events from the past year, both foreign and domestic. It consists of a Wager Round, in which the players choose how many points they wish to wager, and a Lightning Round, in which the point values for each question are determined before the round.

In the Wager Round, players may wager two, four, or six points after being given a broad category (such as “international politics” or “arts and entertainment”). The player need not have any points to wager; thus, negative scores are possible. After the wager is made, the question is asked and the players answer. A correct answer earns as many points as were wagered, while an incorrect answer loses half that many.

In the Lightning Round, the questions are assigned point values (two, four, or six, with six questions of each value) by a panel of judges before the game starts. The questions are asked rapidly, and a correct answer earns its value; however, unlike the Wager Round, there is no penalty for answering incorrectly.

==== Theme ====
This event is very similar to its sister game, Current Events, which was once also a round of World Events. It is played and scored in the same fashion, with a Wager Round followed by a Lightning Round. The only notable difference is that this game concerns historical facts related to a theme chosen at the national tournament two years prior. Examples of past themes include the 1970s, the history of [[NASA]], the [[Mesoamerica]]n civilizations ([[Aztec]]s, [[Inca Empire|Incas]], [[Maya civilization|Mayas]]), World War I, and the [[American Civil War]].

The theme of the 2017-2018 season is [[Greek mythology|Greek]] and [[Roman mythology|Roman]] Mythology, which was chosen by vote at the 2015-2016 tournament.

===Terminology===
A spectator at an Academic Games tournament will hear a lot of jargon being thrown around that he or she may not be familiar with. Here are some of the most common AG-related words and their meanings.

*'''Challenge Win''' or '''Now''' -- A player calls Challenge Win when he can create a solution using the cubes in play, and optionally one more cube from resources. It can also be called C-A-flub or A-flub in classic version.
*'''Challenge Impossible''' or '''Never''' -- Challenge Impossible is called when a player believes it is impossible to create a solution, because of a previous player's move. The player it was called against must try to create a solution, and show that there was a correct solution possible. In classic version, it is called a P-flub.
*'''Demand''' -- A [[LinguiSHTIK]] demand can be called by stating the name of the demand and placing a green or black cube in the "Demands" section of the playing mat. The word and sentence in a player's solution must meet all demands called in that shake.
*'''Force Out''' -- In the case that a game is not finished within the time limit, or that no possible moves can be made that would not create a "Now" or "Never" situation, the game goes into a force out. During a force out, players are given two minutes to create a solution. Players with a correct solution earn a 4, and the ones with an incorrect solution receive a 2, or the minimum possible for that round.
*'''Goal''' -- Equations, On-Sets, and WFF 'N Proof require the first player to use cubes from resources to set a goal. This is what players try to achieve a solution to throughout the shake.
*'''Resources''' -- Resources are the cubes that are rolled at the beginning of each shake.
*'''Shake''' -- One match of a cube game is called a shake.  A shake can last anywhere from a few minutes to an hour depending on the cubes rolled and the players involved.
*'''Solution''' -- A player uses the cubes in resources to create a solution that equals the goal. A solution must be written on paper.  After a solution is presented, other players check that solution.
*'''Stall''' -- As a courtesy, players say the word "stall" before flipping the one-minute timer during their opponents turn.  Most actions in the games have a time limit, ranging from 15 seconds to three minutes. Surpassing the time limit usually carries a small penalty of one point.
*'''Universe''' -- At the beginning of an [[On-Sets]] shake, one player randomly lays out between six and fourteen unique cards containing colored dots. This collection of cards is called the universe.
*'''Variation''' -- In [[Equations (game)|Equations]] and [[On-Sets]], players can call a total of three variations that affect that shake, or six in the Senior division.  Variations are intended to make the game more interesting and more challenging for experienced players. Some examples of variations are "wilds" where one cube can represent another cube, "upside down", where an upside down number is interpreted as the number's additive inverse, etc.

==National tournaments&lt;ref&gt;[http://www.agloa.net/content/national-tournament-information Nationals Information] {{webarchive |url=https://web.archive.org/web/20091213133446/http://www.agloa.net/content/national-tournament-information |date=December 13, 2009 }}&lt;/ref&gt;==
*2019: [[Orlando, Florida|Orlando]], [[Florida]]
*2018: [[Knoxville, Tennessee|Knoxville]], [[Tennessee]]
*2017: [[Wheeling, West Virginia|Wheeling]], [[West Virginia]]
*2016: [[Atlanta, Georgia|Atlanta]], [[Georgia (U.S. state)|Georgia]]
*2015: [[Orlando, Florida|Orlando]], [[Florida]]
*2014: [[Knoxville, Tennessee|Knoxville]], [[Tennessee]]
*2013: [[Charlotte, North Carolina|Charlotte]], [[North Carolina]]
*2012: [[Wheeling, West Virginia|Wheeling]], [[West Virginia]]
*2011: [[Kissimmee, Florida|Kissimmee]], [[Florida]]
*2010: [[Cincinnati, Ohio|Cincinnati]], [[Ohio]]
*2009: [[Knoxville, Tennessee|Knoxville]], [[Tennessee]]
*2008: [[Kissimmee, Florida|Kissimmee]], [[Florida]]
*2007: [[Wheeling, West Virginia|Wheeling]], [[West Virginia]]
*2006: [[Charlotte, North Carolina|Charlotte]], [[North Carolina]]
*2005: [[Baton Rouge, Louisiana|Baton Rouge]], [[Louisiana]]
*2004: [[Orlando, Florida|Orlando]], [[Florida]]
*2003: [[Wheeling, West Virginia|Wheeling]], [[West Virginia]]
*2002: [[Charlotte, North Carolina|Charlotte]], [[North Carolina]]
*2001: [[Baton Rouge, Louisiana|Baton Rouge]], [[Louisiana]]
*2000: [[Orlando, Florida|Orlando]], [[Florida]]
*1999: [[Wheeling, West Virginia|Wheeling]], [[West Virginia]]

==See also==
* [[Academic Challenge (Ohio)]]
* [[Commissioner's Academic Challenge]] (Florida)
* [[Academic Pentathlon]]
* [[Quizbowl]]
* [[Reach for the Top]]
* [[MathCounts]]
* [[United States Academic Decathlon|Academic Decathlon]]

==References==
{{Reflist}}

==External links==
*[http://agloa.org Academic Games Leagues of America Official Website]
*[http://www.wffnproof.com WFF 'N PROOF Learning Games]
*[http://flambeauxstudios.com/AbloG/ AbloG | ALL THINGS ACADEMIC GAMES]
*[http://www.p2sis.com/educationgames/equation/maths-equation-game.html Maths Equation Game]

{{Main world championships}}

[[Category:Competitions]]
[[Category:Educational games]]
[[Category:Mathematics competitions]]
[[Category:Quiz games]]</text>
      <sha1>nvow76s20hokqxvkcfzlrpjhpwtfpsl</sha1>
    </revision>
  </page>
  <page>
    <title>Alpha Profiling</title>
    <ns>0</ns>
    <id>53283857</id>
    <revision>
      <id>841537082</id>
      <parentid>770369493</parentid>
      <timestamp>2018-05-16T12:57:16Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8427">{{Orphan|date=February 2017}}

'''Alpha profiling'''&lt;ref name="MarketsMedia"&gt;{{cite web|url=http://daniels.du.edu/alpha-profiling-in-focus/|title=Alpha Profiling in Focus|year=2013|publisher=Markets Media }}&lt;/ref&gt;&lt;ref name="TheTrade"&gt;{{cite web|url=http://www.thetradenews.com/magazine/The_TRADE_Magazine/2014/Jul_-_Sept/Learning_by_doing.aspx|title=Learning by Doing|year=2014|publisher=The Trade }}&lt;/ref&gt;  is an application of [[machine learning]] to optimize the execution of large orders in financial markets by means of [[algorithmic trading]]. The purpose is to select an execution schedule that minimizes the expected [[implementation shortfall]], or more generally, ensures compliance with a [[best execution]] mandate.
Alpha profiling models learn statistically-significant patterns in the execution of orders from a particular trading strategy or portfolio manager and leverages these patterns to associate an optimal execution schedule to new orders. In this sense, it is an application of [[statistical arbitrage]] to best execution. For example, a [[portfolio manager]] specialized in [[value investing]] may have a [[Behavioral economics|behavioral]]  bias to place orders to buy while an asset is still declining in value. In this case a slow or back-loaded execution schedule would provide better execution results than an urgent one. But this same portfolio manager will occasionally place an order after the asset price has already begun to rise in which case it should best be handled with urgency; this example illustrates the fact that Alpha Profiling must combine public information such as market data with private information including as the identity of the portfolio manager and the size and origin of the order, to identify the optimal execution schedule.

== Market Impact==
Large block orders can generally not be executed immediately because there is no available counterparty with the same size. Instead, they must be sliced into smaller pieces which are sent to the market over time. Each slice has some impact on the price, so on average the realized price for a buy order will be higher than at the time of the decision, or less for a sell order. The [[implementation shortfall]] is difference between the price at the time of the decision and the average expected price to be paid for executing the block, and is usually expressed in basis points as follows.
:&lt;math&gt;IS[bps] = 10000*\frac{P_{fill}-P_{decision}}{P_{decision}}.&lt;/math&gt;

== Alpha Profile==
The alpha profile of an order is the expected impact-free price conditioned on the order and the state of the market, form the decision time to the required completion time. In other words, it is the price that one expects for the security would have over the execution horizon if the order were not executed. To estimate the cost of an execution strategy, market impact must be added to the impact-free price.&lt;ref name="IFRPatent"&gt;{{cite journal|first=H.|last=Waelbroeck|title=Methods and Systems Related to Securities Trading|journal=US Patent|year=2012|volume=8301548|url=http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&amp;Sect2=HITOFF&amp;p=1&amp;u=%2Fnetahtml%2FPTO%2Fsearch-bool.html&amp;r=1&amp;f=G&amp;l=50&amp;co1=AND&amp;d=PTXT&amp;s1=8301548&amp;OS=8301548&amp;RS=8301548 }}&lt;/ref&gt; It is well worth stressing that attempts to estimate the cost of alternative schedules without impact adjustments are counter-productive: high urgency strategies would capture more liquidity near the decision time and therefore would always be preferred if one did not account for their impact. In fact, front-loaded execution schedules have a higher average impact cost.&lt;ref&gt;{{cite journal |first=A. |last=Criscuolo |first2=H.|last2=Waelbroeck|title= Optimal Execution and Alpha Capture|journal=Journal of Trading |year=2012 |volume=7 |issue=2 |pages=48–56|doi=10.1016/S1386-4181(97)00012-8}}&lt;/ref&gt;

== Estimating an alpha profile ==
One way to compute an alpha profile is to use a [[Statistical classification|classification]] technique such as [[Naive Bayes]]: find in the historical record a collection of orders with similar features, compute the impact-free price for each case, and take the simple average return from trade start over the next few days. This method is [[robust statistics|robust]] and transparent: each order is attached to a class of orders that share specific features that can be shown to the user as part of an explanation for the proposed optimal decision. However, an alpha profiling model based on classifying trades by similarity has limited [[generalization (learning)|generalization]] power. New orders do not always behave in the same way as other orders with similar features behaved in the past. A more accurate estimation of alpha profiles can be accomplished using [[Machine Learning]] (ML) methods to learn the probabilities of future price scenarios given the order and the state of the market. Alpha profiles are then computed as the statistical average of the security price under various scenarios, weighted by scenario probabilities.

==Risk-adjusted Cost==
Optimal execution is the problem of identifying the execution schedule that minimizes a risk-adjusted cost function, where the cost term is the expected effect of trading costs on the portfolio value and the risk term is a measure of the effect of trade execution on risk. It is difficult to attribute the effect of trade execution on portfolio returns, and even more difficult to attribute its effect on risk, so in practice an alternate specification is often used: cost is defined as the implementation shortfall and risk is taken to be the variance of the same quantity. While this specification is commonly used, it is important to be aware of two shortcomings. First, the implementation shortfall as just defined is only a measure of the cost to the portfolio if all orders are entirely filled as originally entered; if portfolio managers edit the size of orders or some orders are left incomplete, opportunity costs must be considered. Second, execution risk as just defined is not directly related to portfolio risk and therefore has little practical value.

== Optimal Execution Schedule==
A method for deriving optimal execution schedules that minimize a risk-adjusted cost function was proposed by Bertsimas and Lo.&lt;ref&gt;{{cite journal |first=D.|last=Bertsimas|first2=A.W.|last2=Lo|title=Optimal Control of Execution Costs|journal=Journal of Financial Markets |year=1998 |volume=1 |issue=1 |pages=1–50|doi=10.3905/jot/2012.7.2.048 }}&lt;/ref&gt; Almgren and Chriss provided closed-form solutions of the basic risk-adjusted cost optimization problem with a linear impact model and trivial alpha profile.&lt;ref&gt;{{cite journal|first=R.|last=Almgren|first2=N.|last2=Chriss|title="Optimal Execution of Portfolio Transactions"|url=http://www.math.nyu.edu/faculty/chriss/optliq_f.pdf|journal=Risk|year=1999}}&lt;/ref&gt; More recent solutions have been proposed based on a propagator model for market impact,&lt;ref&gt;{{cite journal |first=G.|last=Curato|first2=J.|last2=Gatheral|first3=F.|last3=Lillo|title=Optimal Execution with Nonlinear Transient Market Impact|journal=Quantitative Finance|year=2017|volume=17|issue=1|pages=41–54|doi=10.1080/14697688.2016.1181274|arxiv=1412.4839}}&lt;/ref&gt; but here again the alpha profile is assumed to be trivial. In practice, impact is non-linear and the optimal schedule is sensitive to the alpha profile. A [[diffusion]] model &lt;ref&gt;{{cite journal|first=J.|last=Donier|first2=J.|last2=Bonart|first3=I.|last3=Mastromatteo|first4=J.-P.|last4=Bouchaud|title=A Fully Consistent, Minimal Model for Nonlinear Market Impact|journal=Quantitative Finance|volume=15|issue=7|year=2015|pages=1109–1121]}}&lt;/ref&gt; yields a functional form of market impact including an estimate of the speed exponent at 0.25 (trading faster causes more impact). It is not difficult to derive optimal execution solutions numerically with non-trivial alpha profiles using such a functional form for market impact &lt;ref&gt;{{cite journal |first=A. |last=Criscuolo |first2=H.|last2=Waelbroeck|title= Optimal Execution and Alpha Capture|journal=Journal of Trading |year=2012 |volume=7 |issue=2 |pages=48–56|doi=10.1016/S1386-4181(97)00012-8}}&lt;/ref&gt;

==References==
{{Reflist|30em}}

==External links==
*[http://www.thetradenews.com/The_TRADE_Magazine/2014/Jul_-_Sept/Learning_by_doing.aspx Learning By Doing]

== Alpha Profiling ==

[[Category:Mathematical finance]]
[[Category:Investment]]</text>
      <sha1>ibu38spbwmirf6ilb5ceg01bg8nrjcz</sha1>
    </revision>
  </page>
  <page>
    <title>Anthony Hill (artist)</title>
    <ns>0</ns>
    <id>11585295</id>
    <revision>
      <id>785598401</id>
      <parentid>775610989</parentid>
      <timestamp>2017-06-14T11:54:50Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4508">{{other people|Anthony Hill}}
'''Anthony Hill''' (born 1930) is an [[England|English]] [[artist]], [[Painting|painter]] and [[relief]]-maker, originally a member of the post-[[World War II]] British art movement termed the Constructionist Group whose work was essentially in the international constructivist tradition.

His fellow members in this group were [[Victor Pasmore]], [[Adrian Heath (painter)|Adrian Heath]], [[John Ernest]], [[Kenneth Martin]], [[Mary Martin (artist)|Mary Martin]], [[Gillian Wise (artist)]] and [[Stephen Gilbert]]. He was born on 23 April 1930 in London, and studied at the St Martin's and the Central Schools of Art 1948–51. He began painting in the style of [[Dada]] and [[Surrealism]] in 1948 but quickly moved on to geometric abstract idioms. He made his first relief in 1954 and abandoned painting for relief-making in 1956. One feature of these reliefs has been the use of non-traditional materials such as industrial aluminium and Perspex. His first one-man show of reliefs was held at the [[Institute of Contemporary Arts]] in 1958. He has participated in exhibitions of abstract and constructivist art in the UK, Paris, Germany, Holland, Poland, Switzerland and the USA. In 1978 he exhibited in the Arts Council's exhibition, Constructive Context, alongside a number if artists such as [[Jeffrey Steele (artist)|Jeffrey Steele]] and Peter Lowe who had begun working in a systematised constructive mode in the mid to late 1960s and came together in the Systems Group in December 1969. Hill, however, along with the Martins, declined membership of this group. In 1983 the [[Hayward Gallery]] held a major retrospective exhibition of Anthony Hill's constructivist work.

Anthony Hill has had a lifelong fascination with mathematics, and there are many mathematicians among his circle of acquaintances. Together with his colleague [[John Ernest]] he made contributions to graph theory ([[crossing number (graph theory)|crossing number]]) and in 1979, in recognition of a number of his mathematical papers, he was elected a member of the London Mathematical Society and made a visiting research associate in the Department of Mathematics at University College, London. But although almost all his reliefs have an underlying mathematical structure or logic, he was always insistent that in his art, in his own words, "the mathematical thematic or mathematical process can only be a component: one is calculating or organising something which is clearly not mathematical."  From the late 1980s onward, working in parallel with his systems-based work but in a very different mode, Anthony Hill exhibited dadaist pictures and collages under the pseudonym [[Achill Redo]]. The [[Tate Gallery]], London has collections under both of the names Anthony Hill and Achill Redo.

An excellent summary of the life and constructivist work of Anthony Hill, together with that of the other British constructivists, is given in [[Alastair Grieve]]'s authoritative book of 2005.

==References==
* Fowler, Alan. Essay in online Philosophy of Mathematics Education Journal No. 24, December 2009, 'A Rational Aesthetic'.
* Fowler, Alan, Essay, 'The Systems Group and its Constructivist Context', in exhibition catalogue 'A Rational Aesthetic', Southampton City Art Gallery, 2009.
* Grieve, Alastair, Essay in exhibition catalogue 'Anthony Hill', Arts Council, London, 1983
* Grieve, Alastair ''Constructed Abstract Art in England After the Second World War: A Neglected Avant Garde'', Yale University Press. 2005. {{ISBN|978-0-300-10703-6}}.
* Harary, Frank and Hill, Anthony. On the number of crossings in a complete graph. ''Proceedings of the Edinburgh Math. Society'' (2), 13:333-338, 1962/1963.
* Hill, Anthony, editor ''Data: Directions in Art, Theory and Aesthetics'', Faber and Faber. 1968. {{ISBN|978-0-571-08762-4}}
* Hill, Anthony, editor ''Duchamp: Passim'', Craftsman House. 1994. {{ISBN|978-976-8097-78-1}}

==External links==
The Tate Gallery, London holds 11 of Hill's works. See their online listing for Anthony Hill:  
* http://www.tate.org.uk/servlet/ArtistWorks?cgroupid=999999961&amp;artistid=1284&amp;page=1
and for [[Achill Redo]]:
* http://www.tate.org.uk/servlet/WorksList?searchid=25977&amp;page=1

{{Authority control}}

{{DEFAULTSORT:Hill, Anthony}}
{{Mathematical art}}
[[Category:20th-century English painters]]
[[Category:English male painters]]
[[Category:21st-century English painters]]
[[Category:1930 births]]
[[Category:Living people]]
[[Category:Mathematical artists]]</text>
      <sha1>hbyukmyuzydypnlzrgozoio6hww8vha</sha1>
    </revision>
  </page>
  <page>
    <title>Antiderivative</title>
    <ns>0</ns>
    <id>2823</id>
    <revision>
      <id>861859617</id>
      <parentid>861704123</parentid>
      <timestamp>2018-09-30T15:29:27Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>/* External links */ regardless, their main site shouldn't be linked also</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18147">{{for|lists of antiderivatives of primitive functions|lists of integrals}}
{{Calculus |Integral}}
[[File:Slope Field.png|thumb|The [[slope field]] of &lt;math&gt;F(x) = \frac{x^3}{3}-\frac{x^2}{2}-x+c&lt;/math&gt;, showing three of the infinitely many solutions that can be produced by varying the [[Constant of integration|arbitrary constant]] {{math|''c''}}.]]

In [[calculus]], an '''antiderivative''', '''primitive function''', '''primitive integral''' or '''indefinite integral'''{{#tag:ref|Antiderivatives are also called '''general integrals''', and sometimes '''integrals'''. The latter term is generic, and refers not only to indefinite integrals (antiderivatives), but also to [[definite integral]]s. When the word ''integral'' is used without additional specification, the reader is supposed to deduce from the context whether it refers to a definite or indefinite integral. Some authors define the indefinite integral of a function as the set of its infinitely many possible antiderivatives. Others define it as an arbitrarily selected element of that set. Wikipedia adopts the latter approach.{{citation needed|date=June 2016}}|group=Note}} of a [[function (mathematics)|function]] {{math|''f''}} is a differentiable function {{math|''F''}} whose [[derivative]] is equal to the original function {{math|''f''}}. This can be stated symbolically as &lt;math&gt;F' = f&lt;/math&gt;.&lt;ref&gt;{{cite book | last=Stewart | first=James | authorlink=James Stewart (mathematician) | title=Calculus: Early Transcendentals |publisher=[[Brooks/Cole]] | edition=6th | year=2008 | isbn=0-495-01166-5}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last1=Larson | first1=Ron | authorlink=Ron Larson (mathematician)| last2=Edwards | first2=Bruce H. | title=Calculus | publisher=[[Brooks/Cole]] | edition=9th | year=2009 | isbn=0-547-16702-4}}&lt;/ref&gt; The process of solving for antiderivatives is called '''antidifferentiation''' (or '''indefinite integration''') and its opposite operation is called differentiation, which is the process of finding a derivative.

Antiderivatives are related to [[integral|definite integral]]s through the [[fundamental theorem of calculus]]: the definite integral of a function over an [[interval (mathematics)|interval]] is equal to the difference between the values of an antiderivative evaluated at the endpoints of the interval.

The discrete equivalent of the notion of antiderivative is [[antidifference]].

==Example==
The function &lt;math&gt;F(x) = \frac{x^3}{3}&lt;/math&gt; is an antiderivative of &lt;math&gt;f(x) = x^2&lt;/math&gt;, as the derivative of &lt;math&gt;\frac{x^3}{3}&lt;/math&gt; is &lt;math&gt;x^2&lt;/math&gt;. As the derivative of a [[Constant function|constant]] is [[0 (number)|zero]], &lt;math&gt;x^2&lt;/math&gt; will have an [[Infinite set|infinite]] number of antiderivatives, such as &lt;math&gt;\frac{x^3}{3}&lt;/math&gt;, &lt;math&gt;\frac{x^3}{3}+1&lt;/math&gt;, &lt;math&gt;\frac{x^3}{3}-2&lt;/math&gt;, etc. Thus, all the antiderivatives of &lt;math&gt;x^2&lt;/math&gt; can be obtained by changing the value of {{math|''c''}} in &lt;math&gt;F(x) = \frac{x^3}{3}+c&lt;/math&gt;, where {{math|''c''}} is an arbitrary constant known as the [[constant of integration]]. Essentially, the [[graph of a function|graphs]] of antiderivatives of a given function are [[vertical translation]]s of each other; each graph's vertical location depending upon the [[Value (mathematics)|value]] {{math|''c''}}.

In physics, the integration of acceleration yields velocity plus a constant. The constant is the initial velocity term that would be lost upon taking the derivative of velocity because the derivative of a constant term is zero. This same pattern applies to further integrations and derivatives of motion (position, velocity, acceleration, and so on).

==Uses and properties==
Antiderivatives can be used to [[integral#Calculating integrals|compute definite integrals]], using the [[fundamental theorem of calculus]]: if {{math|''F''}} is an antiderivative of the [[Riemann integral|integrable]] function {{math|''f''}} over the interval &lt;math&gt;[a,b]&lt;/math&gt;, then:

:&lt;math&gt;\int_a^b f(x)\,dx = F(b) - F(a).&lt;/math&gt;

Because of this, each of the infinitely many antiderivatives of a given function {{math|''f''}} is sometimes called the "general integral" or "indefinite integral" of ''f'' and is written using the integral symbol with no bounds:
:&lt;math&gt;\int f(x)\, dx.&lt;/math&gt;

If {{math|''F''}} is an antiderivative of {{math|''f''}}, and the function {{math|''f''}} is defined on some interval, then every other antiderivative {{math|''G''}} of {{math|''f''}} differs from {{math|''F''}} by a constant: there exists a number {{math|''c''}} such that &lt;math&gt;G(x) = F(x)+c&lt;/math&gt; for all {{math|''x''}}. {{math|''c''}} is called the [[constant of integration]]. If the domain of {{math|''F''}} is a [[disjoint union]] of two or more (open) intervals, then a different constant of integration may be chosen for each of the intervals. For instance

:&lt;math&gt;F(x)=\begin{cases}-\frac{1}{x}+c_1\quad x&lt;0\\-\frac{1}{x}+c_2\quad x&gt;0\end{cases}&lt;/math&gt;

is the most general antiderivative of &lt;math&gt;f(x)=1/x^2&lt;/math&gt; on its natural domain &lt;math&gt;(-\infty,0)\cup(0,\infty).&lt;/math&gt;

Every [[continuous function]] {{math|''f''}} has an antiderivative, and one antiderivative {{math|''F''}} is given by the definite integral of {{math|''f''}} with variable upper boundary:
:&lt;math&gt;F(x)=\int_0^x f(t)\,dt.&lt;/math&gt;
Varying the lower boundary produces other antiderivatives (but not necessarily all possible antiderivatives). This is another formulation of the [[fundamental theorem of calculus]].

There are many functions whose antiderivatives, even though they exist, cannot be expressed in terms of [[elementary function]]s (like [[polynomial]]s, [[exponential function]]s, [[logarithm]]s, [[trigonometric functions]], [[inverse trigonometric functions]] and their combinations). Examples of these are
:&lt;math&gt;\int e^{-x^2}\,dx,\qquad \int \sin x^2\,dx, \qquad\int \frac{\sin x}{x}\,dx,\qquad \int\frac{1}{\ln x}\,dx,\qquad \int x^{x}\,dx.&lt;/math&gt;
''From left to right, the first four are the [[error function]], the [[Fresnel function]], the [[trigonometric integral]], and the [[logarithmic integral function]].''

See also [[Differential Galois theory]] for a more detailed discussion.

==Techniques of integration==
Finding antiderivatives of elementary functions is often considerably harder than finding their derivatives. For some elementary functions, it is impossible to find an antiderivative in terms of other elementary functions. See the articles on [[Elementary function (differential algebra)|elementary functions]] and [[nonelementary integral]] for further information.

There are various methods available:

* the [[linearity of integration]] allows us to break complicated integrals into simpler ones
* [[integration by substitution]], often combined with [[trigonometric identity|trigonometric identities]] or the [[natural logarithm]]
** the [[inverse chain rule method]], a special case of integration by substitution
* [[integration by parts]] to integrate products of functions
* [[Inverse function integration]], a formula that expresses the antiderivative of the inverse &lt;math&gt;f^{-1}&lt;/math&gt; of an invertible and continuous function &lt;math&gt;f&lt;/math&gt; in terms of the antiderivative of &lt;math&gt;f&lt;/math&gt; and of &lt;math&gt;f^{-1}&lt;/math&gt;.
* the method of [[partial fractions in integration]] allows us to integrate all [[rational function]]s (fractions of two polynomials)
* the [[Risch algorithm]]
* when integrating multiple times, certain additional techniques can be used, see for instance [[double integral]]s and [[Polar coordinate system|polar coordinates]], the [[Jacobian matrix and determinant|Jacobian]] and the [[Stokes' theorem]]
* if a function has no elementary antiderivative (for instance, &lt;math&gt;\exp (-x^2)&lt;/math&gt;), its definite integral can be approximated using [[numerical integration]]
* it is often convenient to algebraically manipulate the integrand such that other integration techniques, such as integration by substitution, may be used.
* to calculate the ({{math|''n''}} times) repeated antiderivative of a function {{math|''f''}}, [[Cauchy]]'s formula is useful (cf. [[Cauchy formula for repeated integration]]):
::&lt;math&gt;\int_{x_0}^x \int_{x_0}^{x_1} \dots \int_{x_0}^{x_{n-1}} f(x_n) \,dx_n \dots \, dx_2\, dx_1= \int_{x_0}^x f(t) \frac{(x-t)^{n-1}}{(n-1)!}\,dt.&lt;/math&gt;

[[Computer algebra system]]s can be used to automate some or all of the work involved in the symbolic techniques above, which is particularly useful when the algebraic manipulations involved are very complex or lengthy. Integrals which have already been derived can be looked up in a [[table of integrals]].

==Of non-continuous functions==
Non-continuous functions can have antiderivatives. While there are still open questions in this area, it is known that:
* Some highly [[pathological (mathematics)|pathological functions]] with large sets of discontinuities may nevertheless have antiderivatives.
* In some cases, the antiderivatives of such pathological functions may be found by [[Riemann integral|Riemann integration]], while in other cases these functions are not Riemann integrable.

Assuming that the domains of the functions are open intervals:
* A necessary, but not sufficient, condition for a function {{math|''f''}} to have an antiderivative is that {{math|''f''}} have the [[intermediate value theorem|intermediate value property]]. That is, if &lt;math&gt;[a,b]&lt;/math&gt; is a subinterval of the domain of {{math|''f''}} and {{math|''c''}} is any real number between {{math|''f''(''a'')}} and {{math|''f''(''b'')}}, then &lt;math&gt;f(c) = c&lt;/math&gt; for some {{math|''c''}} between {{math|''a''}} and {{math|''b''}}. This is a consequence of [[Darboux's theorem (analysis)|Darboux's theorem]].
* The set of discontinuities of {{math|''f''}} must be a [[meagre set]]. This set must also be an [[F-sigma]] set (since the set of discontinuities of any function must be of this type). Moreover, for any meagre F-sigma set, one can construct some function {{math|''f''}} having an antiderivative, which has the given set as its set of discontinuities.
* If {{math|''f''}} has an antiderivative, is [[bounded function|bounded]] on closed finite subintervals of the domain and has a set of discontinuities of [[Lebesgue measure]] 0, then an antiderivative may be found by integration in the sense of Lebesgue. In fact, using more powerful integrals like the [[Henstock–Kurzweil integral]], every function for which an antiderivative exists is integrable, and its general integral coincides with its antiderivative.
* If {{math|''f''}} has an antiderivative {{math|''F''}} on a closed interval &lt;math&gt;[a,b]&lt;/math&gt;, then for any choice of partition &lt;math&gt;a=x_0&lt;x_1&lt;x_2&lt;\dots&lt;x_n=b&lt;/math&gt;, if one chooses sample points &lt;math&gt;x_i^*\in[x_{i-1},x_i]&lt;/math&gt; as specified by the [[mean value theorem]], then the corresponding Riemann sum [[telescoping series|telescopes]] to the value &lt;math&gt;F(b)-F(a)&lt;/math&gt;.

:: &lt;math&gt;
\begin{align}
\sum_{i=1}^n f(x_i^*)(x_i-x_{i-1}) &amp; = \sum_{i=1}^n [F(x_i)-F(x_{i-1})] \\
&amp; = F(x_n)-F(x_0) = F(b)-F(a)
\end{align}
&lt;/math&gt;

:However if {{math|''f''}} is unbounded, or if {{math|''f''}} is bounded but the set of discontinuities of {{math|''f''}} has positive Lebesgue measure, a different choice of sample points &lt;math&gt;x_i^*&lt;/math&gt; may give a significantly different value for the Riemann sum, no matter how fine the partition. See Example 4 below.

===Some examples===
{{ordered list
|1= The function
:&lt;math&gt;f(x)=2x\sin\left(\frac{1}{x}\right)-\cos\left(\frac{1}{x}\right)&lt;/math&gt;

with &lt;math&gt;f\left(0\right)=0&lt;/math&gt; is not continuous at &lt;math&gt;x=0&lt;/math&gt; but has the antiderivative

:&lt;math&gt;F\left(x\right)=x^2\sin\left(\frac{1}{x}\right)&lt;/math&gt;

with &lt;math&gt;F\left(0\right)=0&lt;/math&gt;. Since {{math|''f''}} is bounded on closed finite intervals and is only discontinuous at 0, the antiderivative {{math|''F''}} may be obtained by integration: &lt;math&gt;F(x)=\int_0^x f(t)\,dt&lt;/math&gt;.
|2= The function

:&lt;math&gt;f(x)=2x\sin\left(\frac{1}{x^2}\right)-\frac{2}{x}\cos\left(\frac{1}{x^2}\right)&lt;/math&gt;

with &lt;math&gt;f\left(0\right)=0&lt;/math&gt; is not continuous at &lt;math&gt;x=0&lt;/math&gt; but has the antiderivative

:&lt;math&gt;F(x)=x^2\sin\left(\frac{1}{x^2}\right)&lt;/math&gt;

with &lt;math&gt;F\left(0\right)=0&lt;/math&gt;. Unlike Example 1, {{math|''f''(''x'')}} is unbounded in any interval containing 0, so the Riemann integral is undefined.

|3= If {{math|''f''(''x'')}} is the function in Example 1 and {{math|''F''}} is its antiderivative, and &lt;math&gt;\{x_n\}_{n\ge1}&lt;/math&gt; is a [[dense set|dense]] [[countable]] [[subset]] of the open interval &lt;math&gt;\left(-1,1\right)&lt;/math&gt;, then the function

:&lt;math&gt;g(x)=\sum_{n=1}^\infty \frac{f(x-x_n)}{2^n}&lt;/math&gt;

has an antiderivative

:&lt;math&gt;G(x)=\sum_{n=1}^\infty \frac{F(x-x_n)}{2^n}.&lt;/math&gt;

The set of discontinuities of {{math|''g''}} is precisely the set &lt;math&gt;\{x_n\}_{n\ge1}&lt;/math&gt;. Since {{math|''g''}} is bounded on closed finite intervals and the set of discontinuities has measure 0, the antiderivative {{math|''G''}} may be found by integration.

|4= Let &lt;math&gt;\{x_n\}_{n\ge1}&lt;/math&gt; be a [[dense set|dense]] [[countable]] subset of the open interval &lt;math&gt;\left(-1,1\right)&lt;/math&gt;. Consider the everywhere continuous strictly increasing function

:&lt;math&gt;F(x)=\sum_{n=1}^\infty\frac{1}{2^n}(x-x_n)^{1/3}.&lt;/math&gt;

It can be shown that

:&lt;math&gt;F'(x)=\sum_{n=1}^\infty\frac{1}{3\cdot2^n}(x-x_n)^{-2/3}&lt;/math&gt;
[[Image:Antideriv1.png|125px|right|thumb|Figure 1.]]
[[Image:Antideriv2.png|thumb|right|125px|Figure 2.]]

for all values {{math|''x''}} where the series converges, and that the graph of {{math|''F''(''x'')}} has vertical tangent lines at all other values of {{math|''x''}}. In particular the graph has vertical tangent lines at all points in the set &lt;math&gt;\{x_n\}_{n\ge1}&lt;/math&gt;.

Moreover &lt;math&gt;F\left(x\right)\ge0&lt;/math&gt; for all {{math|''x''}} where the derivative is defined. It follows that the inverse function &lt;math&gt;G=F^{-1}&lt;/math&gt; is differentiable everywhere and that

:&lt;math&gt;g\left(x\right)=G'\left(x\right)=0&lt;/math&gt;

for all {{math|''x''}} in the set &lt;math&gt;\{F(x_n)\}_{n\ge1}&lt;/math&gt; which is dense in the interval &lt;math&gt;\left[F\left(-1\right),F\left(1\right)\right]&lt;/math&gt;. Thus {{math|''g''}} has an antiderivative {{math|''G''}}. On the other hand, it can not be true that

:&lt;math&gt;\int_{F(-1)}^{F(1)}g(x)\,dx=GF(1)-GF(-1)=2,&lt;/math&gt;

since for any partition of &lt;math&gt;\left[F\left(-1\right),F\left(1\right)\right]&lt;/math&gt;, one can choose sample points for the Riemann sum from the set &lt;math&gt;\{F(x_n)\}_{n\ge1}&lt;/math&gt;, giving a value of 0 for the sum. It follows that {{math|''g''}} has a set of discontinuities of positive Lebesgue measure. Figure 1 on the right shows an approximation to the graph of {{math|''g''(''x'')}} where &lt;math&gt;\{x_n=\cos(n)\}_{n\ge1}&lt;/math&gt; and the series is truncated to 8 terms. Figure 2 shows the graph of an approximation to the antiderivative {{math|''G''(''x'')}}, also truncated to 8 terms. On the other hand if the Riemann integral is replaced by the [[Lebesgue integral]], then [[Fatou's lemma]] or the [[dominated convergence theorem]] shows that {{math|''g''}} does satisfy the fundamental theorem of calculus in that context.

|5= In Examples 3 and 4, the sets of discontinuities of the functions {{math|''g''}} are dense only in a finite open interval &lt;math&gt;\left(a,b\right)&lt;/math&gt;. However, these examples can be easily modified so as to have sets of discontinuities which are dense on the entire real line &lt;math&gt;(-\infty,\infty)&lt;/math&gt;. Let
:&lt;math&gt;\lambda(x) = \frac{a+b}{2} + \frac{b-a}{\pi}\tan^{-1} x.&lt;/math&gt;
Then &lt;math&gt;g\left(\lambda(x)\right)\lambda'(x)&lt;/math&gt; has a dense set of discontinuities on &lt;math&gt;(-\infty,\infty)&lt;/math&gt; and has antiderivative &lt;math&gt;G\cdot\lambda.&lt;/math&gt;

|6= Using a similar method as in Example 5, one can modify {{math|''g''}} in Example 4 so as to vanish at all [[rational numbers]]. If one uses a naive version of the [[Riemann integral]] defined as the limit of left-hand or right-hand Riemann sums over regular partitions, one will obtain that the integral of such a function {{math|''g''}} over an interval &lt;math&gt;\left[a,b\right]&lt;/math&gt; is 0 whenever {{math|''a''}} and {{math|''b''}} are both rational, instead of &lt;math&gt;G\left(b\right)-G\left(a\right)&lt;/math&gt;. Thus the fundamental theorem of calculus will fail spectacularly.

}}

==See also==
* [[Antiderivative (complex analysis)]]
* [[Lists of integrals]]
* [[Symbolic integration]]
* [[Area]]

==Notes==
{{reflist|group=Note}}

==References==
&lt;div class="references"&gt;
&lt;references /&gt;
&lt;/div&gt;

==Bibliography==
* ''Introduction to Classical Real Analysis'', by Karl R. Stromberg; Wadsworth, 1981 (see [https://groups.google.com/group/sci.math/browse_frm/thread/8d900a2d79429d43/0ba4ff0d46efe076?lnk=st&amp;q=&amp;rnum=19&amp;hl=en#0ba4ff0d46efe076 also])
* [https://groups.google.com/group/sci.math/msg/814be41b1ea8c024 ''Historical Essay On Continuity Of Derivatives''] by Dave L. Renfro;

==External links==
* [http://integrals.wolfram.com Wolfram Integrator] — Free online symbolic integration with [[Mathematica]]
* [http://um.mendelu.cz/maw-html/index.php?lang=en&amp;form=integral Mathematical Assistant on Web] — symbolic computations online. Allows users to integrate in small steps (with hints for next step (integration by parts, substitution, partial fractions, application of formulas and others), powered by [[Maxima (software)|Maxima]]
* [http://wims.unice.fr/wims/wims.cgi?module=tool/analysis/function.en Function Calculator] from WIMS
* [http://hyperphysics.phy-astr.gsu.edu/hbase/integ.html Integral] at [[HyperPhysics]]
* [https://www.khanacademy.org/video/antiderivatives-and-indefinite-integrals Antiderivatives and indefinite integrals] at the [[Khan Academy]]
* [http://www.symbolab.com/solver/integral-calculator Integral calculator] at [[Symbolab]]
* [http://www-math.mit.edu/~djk/calculus_beginners/chapter16/section01.html The Antiderivative] at [[MIT]]
* [http://www.sparknotes.com/math/calcab/introductiontointegrals/section1.rhtml Introduction to Integrals] at [[SparkNotes]]
* [https://www.math.hmc.edu/calculus/tutorials/antiderivatives/ Antiderivatives] at Harvy Mudd College

[[Category:Integral calculus]]
[[Category:Linear operators in calculus]]</text>
      <sha1>5p4eod2nqywqmr3va4jeb1dz4rp1yht</sha1>
    </revision>
  </page>
  <page>
    <title>Apeirotope</title>
    <ns>0</ns>
    <id>12768648</id>
    <revision>
      <id>765898757</id>
      <parentid>765889599</parentid>
      <timestamp>2017-02-17T01:29:14Z</timestamp>
      <contributor>
        <username>Tomruen</username>
        <id>63601</id>
      </contributor>
      <comment>wlink is useful Undid revision 765889599 by [[Special:Contributions/Primefac|Primefac]] ([[User talk:Primefac|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2564">An '''apeirotope''' or '''infinite polytope''' is a [[polytope]] which has infinitely many [[Facet (geometry)|facets]]. There are two main geometric classes of apeirotope:&lt;ref&gt;Grünbaum, B.; "Regular Polyhedra—Old and New", ''Aeqationes mathematicae'', Vol. 16 (1977), pp 1–20.&lt;/ref&gt;
*[[honeycomb (geometry)|honeycombs]] in ''n'' dimensions, which completely fill an [[n-dimensional space|''n''-dimensional space]].
*[[skew apeirotope]]s, comprising an ''n''-dimensional manifold in a higher space 

==Honeycombs==
{{Main|Honeycomb (geometry)}}
In general, a honeycomb in ''n'' dimensions is an infinite example of a polytope in ''n''&amp;nbsp;+&amp;nbsp;1 dimensions. 

Tilings of the plane and close-packed space-fillings of polyhedra are examples of honeycombs in two and three dimensions respectively.

A line divided into infinitely many finite segments is an example of an [[apeirogon]]. 

==Skew apeirotopes==

=== Skew apeirogons ===

{{Main|Skew apeirogon}}

A skew apeirogon in two dimensions forms a zig-zag line in the plane. If the zig-zag is even and symmetrical, then the apeirogon is regular.

Skew apeirogons can be constructed in any number of dimensions. In three dimensions, a regular [[Skew_apeirogon#Helical_apeirogons_in_3-dimensions|skew apeirogon]] traces out a helical spiral and may be either left- or right-handed.

=== Infinite skew polyhedra ===
{{Main|Regular skew apeirohedron}}
There are three regular skew apeirohedra, which look rather like polyhedral sponges:
* 6 squares around each vertex, Coxeter symbol {4,6|4}
* 4 hexagons around each vertex, Coxeter symbol {6,4|4}
* 6 hexagons around each vertex, Coxeter symbol {6,6|3}

There are thirty regular apeirohedra in Euclidean space.&lt;ref&gt;{{Harvtxt |McMullen |Schulte |2002 |loc=Section 7E}}&lt;/ref&gt; These include those listed above, as well as (in the plane) polytopes of type: {∞,3}, {∞,4}, {∞,6} and in 3-dimensional space, blends of these with either an apeirogon or a line segment, and the "pure" 3-dimensional apeirohedra (12 in number)

== References ==
{{reflist}}
{{refbegin}}
*{{citation
 | last1 = McMullen | first1 = Peter | author1-link = Peter McMullen
 | last2 = Schulte | first2 = Egon | author2-link = Egon Schulte
 | doi = 10.1017/CBO9780511546686
 | isbn = 0-521-81496-0
 | mr = 1965665
 | publisher = Cambridge University Press | location = Cambridge
 | series = Encyclopedia of Mathematics and its Applications
 | title = Abstract Regular Polytopes
 | volume = 92
 | year = 2002}}
{{refend}}

[[Category:Polytopes| ]]
[[Category:Multi-dimensional geometry]]</text>
      <sha1>do4cc424o14dq7u9zdvwj0bpftqmxbj</sha1>
    </revision>
  </page>
  <page>
    <title>Barrel shifter</title>
    <ns>0</ns>
    <id>314425</id>
    <revision>
      <id>870500986</id>
      <parentid>869783780</parentid>
      <timestamp>2018-11-25T06:37:30Z</timestamp>
      <contributor>
        <username>Trevorgunn</username>
        <id>35214970</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4276">[[File:crossbar barrel shifter.svg|thumb|250px|Schematic of a 4-bit crossbar barrel shifter. ''x''&amp;nbsp;denotes input bits and ''y'' denotes output bits.]]

A ''' barrel shifter''' is a [[digital circuit]] that can [[Bit shift|shift]] a [[Word (data type)|data word]] by a specified number of [[bit]]s without the use of any [[sequential logic]], only pure [[combinational logic]]. One way to implement it is as a sequence of [[multiplexer]]s where the output of one multiplexer is connected to the input of the next multiplexer in a way that depends on the shift distance. A barrel shifter is often used to shift and rotate n-bits in modern microprocessors, typically within a single [[clock cycle]].

For example, take a four-bit barrel shifter, with inputs A, B, C and D. The shifter can cycle the order of the bits ''ABCD'' as ''DABC'', ''CDAB'', or ''BCDA''; in this case, no bits are lost. That is, it can shift all of the outputs up to three positions to the right (and thus make any cyclic combination of A, B, C and D). The barrel shifter has a variety of applications, including being a useful component in [[microprocessor]]s (alongside the [[Arithmetic logic unit|ALU]]).

== Implementation ==

A barrel shifter is often implemented as a cascade of parallel 2×1 multiplexers.  For an 8-bit barrel shifter, two intermediate signals are used which shifts by four and two bits, or passes the same data, based on the value of S[2] and S[1].  This signal is then shifted by another multiplexer, which is controlled by S[0]:

  int1  = IN       , if S[2] == 0
        = IN   &lt;&lt; 4, if S[2] == 1
  int2  = int1     , if S[1] == 0
        = int1 &lt;&lt; 2, if S[1] == 1
  OUT   = int2     , if S[0] == 0
        = int2 &lt;&lt; 1, if S[0] == 1

Larger barrel shifters have additional stages.

== Cost ==

The number of multiplexers required for an ''n''-bit word is &lt;math&gt;n\log_2 n&lt;/math&gt;.&lt;ref&gt;{{cite book
| title=Decision Procedures
| first=Daniel
| last=Kroening
| first2=Ofer
| last2=Strichman
| publisher=[[Springer Science+Business Media|Springer]]
| year=2008
| page=159
| isbn=978-3-540-74104-6}}&lt;/ref&gt;  Five common [[word size]]s and the number of multiplexers needed are listed below:
* 128-bit &amp;mdash; &lt;math&gt;128 \times \log_2 128 = 128 \times 7 = 896&lt;/math&gt;
* 64-bit &amp;mdash; &lt;math&gt;64 \times \log_2 64 = 64 \times 6 = 384&lt;/math&gt;
* 32-bit &amp;mdash; &lt;math&gt;32 \times \log_2 32 = 32 \times 5 = 160&lt;/math&gt;
* 16-bit &amp;mdash; &lt;math&gt;16 \times \log_2 16 = 16 \times 4 = 64&lt;/math&gt;
* 8-bit &amp;mdash; &lt;math&gt;8 \times \log_2 8 = 8 \times 3 = 24&lt;/math&gt;

Cost of critical path in [[FO4]] (estimated, without wire delay):
* 32-bit: from 18 FO4 to 14 FO4&lt;ref&gt;{{cite web
| url=http://www.realworldtech.com/fo4-metric/4/
| title=Revisiting the FO4 Metric
| first=David T.
| last=Wang
| date=2002-08-15
| accessdate=2016-05-19}}&lt;/ref&gt;

== Uses ==

A common usage of a barrel shifter is in the hardware implementation of [[floating-point]] arithmetic. For a floating-point add or subtract operation, the [[significand]]s of the two numbers must be aligned, which requires shifting the smaller number to the right, increasing its [[exponent]], until it matches the exponent of the larger number. This is done by subtracting the exponents and using the barrel shifter to shift the smaller number to the right by the difference, in one cycle. If a simple shifter were used, shifting by ''n'' bit positions would require ''n'' clock cycles.

==See also==
*[[Circular shift]]

==References==

{{reflist}}

==External links==

* [https://tams.informatik.uni-hamburg.de/applets/hades/webdemos/10-gates/60-barrel/shifter8.html Barrel-shifter (8 bit)], [[University of Hamburg]]
* [http://www.xilinx.com/support/documentation/application_notes/xapp195.pdf Implementing Barrel Shifters Using Multipliers] (Paul Gigliotti, 2004-08-17)

==Further reading==
* {{cite book
| title=Decision Procedures
| first=Daniel
| last=Kroening
| first2=Ofer
| last2=Strichman
| publisher=[[Springer Science+Business Media|Springer]]
| year=2008
| isbn=978-3-540-74104-6}}

{{FOLDOC}}

{{CPU technologies}}

[[Category:Digital circuits]]
[[Category:Binary arithmetic]]
[[Category:Computer arithmetic]]
[[Category:Unary operations]]&lt;!-- bits.shiftLeftByOneBit() --&gt;
[[Category:Binary operations]]&lt;!-- bits.shiftLeftBy(n bits) --&gt;</text>
      <sha1>cbsybq1r1evqha3sr3hryy743z678jk</sha1>
    </revision>
  </page>
  <page>
    <title>Cactus graph</title>
    <ns>0</ns>
    <id>9944209</id>
    <revision>
      <id>867707612</id>
      <parentid>841677886</parentid>
      <timestamp>2018-11-07T14:05:04Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: isbn, title. Add: isbn, citeseerx, issue. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11194">[[Image:Cactus graph.svg|thumb|225px|A cactus graph]]
In [[graph theory]], a '''cactus''' (sometimes called a '''cactus tree''') is a [[connected graph]] in which any two simple [[cycle (graph theory)|cycle]]s have at most one vertex in common. Equivalently, it is a connected graph in which every edge belongs to at most one simple cycle, or (for nontrivial cactus) in which every block (maximal subgraph without a [[cut-vertex]]) is an edge or a cycle.

==Properties==
Cacti are [[outerplanar graph]]s. Every [[pseudoforest|pseudotree]] is a cactus.  A nontrivial graph is a cactus if and only if every [[Glossary of graph theory|block]] is either a [[cycle (graph theory)|simple cycle]] or a single edge.

The family of graphs in which each [[component (graph theory)|component]] is a cactus is [[downwardly closed]] under [[graph minor]] operations. This graph family may be characterized by a single [[forbidden minor]], the four-vertex [[diamond graph]] formed by removing an edge from the [[complete graph]] ''K''&lt;sub&gt;4&lt;/sub&gt;.&lt;ref&gt;{{citation |last1=El-Mallah |first1=Ehab |last2=Colbourn |first2=Charles J. |author2-link=Charles Colbourn |title=The complexity of some edge deletion problems |journal=IEEE Transactions on Circuits and Systems |volume=35 |issue=3 |year=1988 |pages=354–362 |doi=10.1109/31.1748}}&lt;/ref&gt;

==Triangular cactus==
[[File:Friendship graphs.svg|thumb|upright=1.6|[[Friendship graph]]s are triangular cacti]]
A triangular cactus is a special type of cactus graph such that each cycle has length three. For instance, the [[friendship graph]]s, graphs formed from a collection of triangles joined together at a single shared vertex, are triangular cacti. As well as being cactus graphs the triangular cacti are also [[block graph]]s.

The largest triangular cactus in any graph may be found in [[polynomial time]] using an algorithm for the [[matroid parity problem]]. Since triangular cactus graphs are [[planar graph]]s, the largest triangular cactus can be used as an approximation to the largest planar subgraph, an important subproblem in [[planarization]]. As an [[approximation algorithm]], this method has [[approximation ratio]] 4/9, the best known for the maximum planar subgraph problem.&lt;ref&gt;{{citation
 | last1 = Călinescu | first1 = Gruia
 | last2 = Fernandes | first2 = Cristina G
 | last3 = Finkler | first3 = Ulrich
 | last4 = Karloff | first4 = Howard
 | doi = 10.1006/jagm.1997.0920
 | journal = Journal of Algorithms
 | pages = 269– 302
 | series = 2
 | title = A Better Approximation Algorithm for Finding Planar Subgraphs
 | volume = 27
 | issue = 2
 | year = 2002| citeseerx = 10.1.1.47.4731
 }}&lt;/ref&gt;

The algorithm for finding the largest triangular cactus is associated with a theorem of Lovász and Plummer that characterizes the number of triangles in this largest cactus.&lt;ref&gt;{{Citation|last1=Lovász|first1=L.|author1-link=László_Lovász|last2= Plummer |first2=M.D.|authorlink2=Michael_D._Plummer|date=2009|title=Matching Theory|location=|publisher=AMS Chelsea Publishing Series|isbn= 9780821847596}}&lt;/ref&gt;
Lovász and Plummer consider pairs of partitions of the vertices and edges of the given graph into subsets, with the property that every triangle of the graph either has two vertices in a single class of the vertex partition or all three edges in a single class of the edge partition; they call a pair of partitions with this property ''valid''.
Then the number of triangles in the largest triangular cactus equals the maximum, over pairs of valid partitions &lt;math&gt;\mathcal{P}=\{V_1, V_2, \dots, V_k\}&lt;/math&gt; and &lt;math&gt;\mathcal{Q} = \{E_1, E_2, \dots, E_m\}&lt;/math&gt;, of
:&lt;math&gt;\sum_{i=1}^{m}\frac{(u_i - 1)}{2} + n - k,&lt;/math&gt;,
where &lt;math&gt;n&lt;/math&gt; is the number of vertices in the given graph and &lt;math&gt;u_i&lt;/math&gt; is the number of vertex classes met by edge class &lt;math&gt;E_i&lt;/math&gt;.

===Rosa's Conjecture===

An important conjecture related to the triangular cactus is the '''Rosa's Conjecture''', named after '''Alexander Rosa''', which says that all triangular cacti are [[Graceful_labeling | graceful]] or nearly-graceful&lt;ref name="Rosa1988"&gt;{{citation
 | last = Rosa | first = A.
 | journal = Scientia
 | pages = 87–95
 | title = Cyclic Steiner Triple Systems and Labelings of Triangular Cacti
 | volume = 1
 | year = 1988}}.&lt;/ref&gt;. More precisely 

''All triangular cacti with t ≡ 0, 1 mod 4 blocks are graceful, and those with t ≡ 2, 3 mod 4 are near graceful.''

==Algorithms and applications==
Some [[facility location problem]]s which are [[NP-hard]] for general graphs, as well as some other graph problems,  may be solved in [[polynomial time]] for cacti.&lt;ref&gt;{{citation |first1=Boaz |last1=Ben-Moshe |first2=Binay |last2=Bhattacharya |first3=Qiaosheng |last3=Shi |year=2005 |contribution=Efficient algorithms for the weighted 2-center problem in a cactus graph  |publisher=Springer-Verlag |series=[[Lecture Notes in Computer Science]] |volume=3827 |pages=693–703 |title=Algorithms and Computation, 16th Int. Symp., ISAAC 2005| doi=10.1007/11602613_70|isbn=978-3-540-30935-2 }}&lt;/ref&gt;&lt;ref&gt;{{citation |first1=Blaz |last1=Zmazek |first2=Janez |last2=Zerovnik |year=2005 |pages=536–541 |doi=10.1109/IV.2005.48 |contribution=Estimating the traffic on weighted cactus networks in linear time |title=Ninth International Conference on Information Visualisation (IV'05) |isbn=978-0-7695-2397-2}}&lt;/ref&gt;

Since cacti are special cases of [[outerplanar graph]]s, a number of [[combinatorial optimization]] problems on graphs  may be solved for them in [[polynomial time]].&lt;ref&gt;{{Citation |author=Korneyenko, N. M. |title=Combinatorial algorithms on a class of graphs |journal=Discrete Applied Mathematics|volume=54 |issue=2–3 |pages=215–217 |year=1994 |doi=10.1016/0166-218X(94)90022-1 |postscript=.}} Translated from ''Notices of the BSSR Academy of Sciences, Ser. Phys.-Math. Sci.'', (1984) no. 3, pp. 109-111 {{ru icon}}&lt;/ref&gt;

Cacti represent [[electrical circuit]]s that have useful properties. An early application of cacti was associated with the representation of op-amps.&lt;ref&gt;{{citation |first1=Tetsuo |last1=Nishi |first2=Leon O. |last2=Chua |author2-link=Leon O. Chua |title=Topological proof of the Nielsen-Willson theorem |journal=IEEE Transactions on Circuits and Systems |volume=33 |issue=4 |pages=398–405 |year=1986 |doi=10.1109/TCS.1986.1085935}}&lt;/ref&gt;&lt;ref&gt;{{citation |first1=Tetsuo |last1=Nishi |first2=Leon O. |last2=Chua |author2-link=Leon O. Chua |title=Uniqueness of solution for nonlinear resistive circuits containing CCCS's or VCVS's whose controlling coefficients are finite |journal=IEEE Transactions on Circuits and Systems |volume=33 |issue=4 |pages=381–397 |year=1986 |doi=10.1109/TCS.1986.1085934}}&lt;/ref&gt;&lt;ref&gt;{{citation |first=Tetsuo |last=Nishi |contribution=On the number of solutions of a class of nonlinear resistive circuit |title=Proceedings of the IEEE International Symposium on Circuits and Systems, Singapore |pages=766–769 |year=1991}}&lt;/ref&gt;

Cacti have also recently been used in [[comparative genomics]] as a way of representing the relationship between different genomes or parts of genomes.&lt;ref&gt;{{citation |first1=Benedict |last1=Paten |first2=Mark |last2=Diekhans |first3=Dent |last3=Earl |first4=John |last4=St. John |first5=Jian |last5=Ma |first6=Bernard |last6=Suh |first7=David |last7=Haussler |title=Research in Computational Molecular Biology |volume=6044 |pages=410–425 |year=2010 |doi=10.1007/978-3-642-12683-3_27 |chapter=Cactus Graphs for Genome Comparisons |series=Lecture Notes in Computer Science |isbn=978-3-642-12682-6}}&lt;/ref&gt;

If a cactus is connected, and each of its vertices belongs to at most two blocks, then it is called a '''Christmas cactus'''. Every [[polyhedral graph]] has a Christmas cactus subgraph that includes all of its vertices, a fact that plays an essential role in a proof by {{harvtxt|Leighton|Moitra|2010}} that every polyhedral graph has a [[greedy embedding]] in the [[Euclidean plane]], an assignment of coordinates to the vertices for which [[Geographic routing|greedy forwarding]] succeeds in routing messages between all pairs of vertices.&lt;ref&gt;{{citation
 | last1 = Leighton | first1 = Tom |authorlink1= F. Thomson Leighton
 | last2 = Moitra | first2 = Ankur
 | issue = 3
 | journal = [[Discrete &amp; Computational Geometry]]
 | pages = 686–705
 | title = Some Results on Greedy Embeddings in Metric Spaces
 | volume = 44
 | doi = 10.1007/s00454-009-9227-6
 | url = http://people.csail.mit.edu/moitra/docs/dcg-greedy.pdf
 | year = 2010}}.&lt;/ref&gt;

In [[topological graph theory]], the graphs whose [[graph embedding|cellular embeddings]] are all [[planar graph|planar]] are exactly the subfamily of the cactus graphs with the additional property that each vertex belongs to at most one cycle. These graphs have two forbidden minors, the diamond graph and the five-vertex [[friendship graph]].&lt;ref&gt;{{citation
 | last1 = Nordhaus | first1 = E. A.
 | last2 = Ringeisen | first2 = R. D.
 | last3 = Stewart | first3 = B. M.
 | last4 = White | first4 = A. T.
 | doi = 10.1016/0095-8956(72)90040-8
 | journal = Journal of Combinatorial Theory
 | mr = 0299523
 | pages = 260–267
 | series = Series B
 | title = A Kuratowski-type theorem for the maximum genus of a graph
 | volume = 12
 | issue = 3
 | year = 1972}}&lt;/ref&gt;

==History==

Cacti were first studied under the name of '''Husimi trees''', bestowed on them by [[Frank Harary]] and [[George Eugene Uhlenbeck]] in honor of previous work on these graphs by [[Kôdi Husimi]].&lt;ref&gt;{{citation |last1=Harary |first1=Frank |last2=Uhlenbeck |authorlink1 = Frank Harary |first2=George E. |authorlink2=George Eugene Uhlenbeck |title=On the number of Husimi trees, I |journal=[[Proceedings of the National Academy of Sciences]] |volume=39 |year=1953 |pages=315–322 |mr=0053893 |doi=10.1073/pnas.39.4.315 |issue=4|pmid=16589268 |pmc=1063779}}&lt;/ref&gt;&lt;ref&gt;{{citation |last=Husimi |first=Kodi |title=Note on Mayers' theory of cluster integrals |journal=Journal of Chemical Physics |volume=18 |year=1950 |pages=682–684 |mr=0038903 |doi=10.1063/1.1747725 |issue=5}}&lt;/ref&gt; The same Harary–Uhlenbeck paper reserves the name "cactus" for graphs of this type in which every cycle is a triangle, but now allowing cycles of all lengths is standard.

Meanwhile, the name '''Husimi tree''' commonly came to refer to graphs in which every [[Glossary of graph theory|block]] is a [[complete graph]] (equivalently, the intersection graphs of the blocks in some other graph).  This usage had little to do with the work of Husimi, and the more pertinent term [[block graph]] is now used for this family; however, because of this ambiguity this phrase has become less frequently used to refer to cactus graphs.&lt;ref&gt;See, e.g., {{MR|0659742}}, a 1983 review by Robert E. Jamison of a paper using the other definition, which attributes the ambiguity to an error in a book by [[Mehdi Behzad]] and [[Gary Chartrand]].&lt;/ref&gt;

==References==
{{reflist|colwidth=30em}}

==External links==
*[http://www.angelfire.com/electronic2/cas/ Application of Cactus Graphs in Analysis and Design of Electronic Circuits]

[[Category:Graph families]]
[[Category:Planar graphs]]
[[Category:Integrated circuits]]</text>
      <sha1>e7q8es0c9vgyif8uw9i4tgfoeqnxblp</sha1>
    </revision>
  </page>
  <page>
    <title>Chaos machine</title>
    <ns>0</ns>
    <id>51838760</id>
    <revision>
      <id>765113525</id>
      <parentid>764354284</parentid>
      <timestamp>2017-02-12T18:39:10Z</timestamp>
      <contributor>
        <username>Magioladitis</username>
        <id>1862829</id>
      </contributor>
      <minor/>
      <comment>/* top */fixing stuff, removed underlinked tag using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2324">In [[mathematics]], a '''chaos machine''' is a class of algorithms constructed on the base of [[chaos theory]] (mainly deterministic chaos) to produce [[random oracle|pseudo-random oracle]]. It represents the idea of creating a universal scheme with modular design and customizable parameters, which can be applied wherever [[randomness]] and [[butterfly effect|sensitiveness]] is needed.&lt;ref&gt;{{cite speech |title=Cryptography using Chaos|first=J M|last=Blackledge|event=Executive Speeches|location=Warsaw University of Technology|date=March 10, 2010|url=http://konwersatorium.pw.edu.pl/wyklady/2010_VLZ7_02_wyklad.pdf}}&lt;/ref&gt;

Theoretical model was published&lt;ref&gt;{{cite report |url=https://eprint.iacr.org/2016/468 |title=Chaos Machine: Different Approach to the Application and Significance of Numbers |publisher=Cryptology ePrint Archive, Report 2016/468 |author=Maciej A. Czyzewski|language=English |year=2016}}&lt;/ref&gt; in early 2015 by Maciej A. Czyzewski. It was designed specifically to combine the benefits of [[hash function]] and [[pseudo-random function]]. However, it can be used to implement many cryptographic primitives,&lt;ref&gt;{{cite web|last=Barker|first=Elaine|title=Recommendation for Key Management|url=http://csrc.nist.gov/publications/nistpubs/800-57/sp800-57_part1_rev3_general.pdf|work=[[NIST]] Special Publication 800-57|publisher=[[NIST]]|accessdate=19 August 2013|author2=Barker, William |author3=Burr, William |author4=Polk, William |author5= Smid, Miles |date=July 2012}}&lt;/ref&gt; including [[cryptographic hash]]es, [[message authentication codes]] and [[randomness extractor]]s.&lt;ref&gt;{{cite journal |url=http://opac.inria.fr/record=b1101628 |title=Complex systems : chaos and beyond a constructive approach with applications in life sciences |publisher=Springer| isbn=3-540-67202-8 |series = Physics and astronomy online library|language= Japanese|author=Kaneko, Kunihiko and Tsuda, Ichiro |year=2001}}&lt;/ref&gt;

== See also ==
* [[Merkle–Damgård construction]]
* [[Sponge function]]

== External links ==
* [https://github.com/maciejczyzewski/libchaos#chaos-machines-theorypdf Libchaos - implemented chaos machines]
* [https://eprint.iacr.org/2016/468.pdf Official paper published at IACR]

== References ==

{{reflist}}

[[Category:Theory of cryptography]]
[[Category:Chaos theory]]


{{crypto-stub}}</text>
      <sha1>13ito79feby9gumn9iurarccjcyxq5r</sha1>
    </revision>
  </page>
  <page>
    <title>Cheryl Praeger</title>
    <ns>0</ns>
    <id>9031833</id>
    <revision>
      <id>870911988</id>
      <parentid>859189226</parentid>
      <timestamp>2018-11-27T19:21:31Z</timestamp>
      <contributor>
        <username>GünniX</username>
        <id>237572</id>
      </contributor>
      <minor/>
      <comment>External link with a line break</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17626">{{EngvarB|date=September 2014}}
{{Use dmy dates|date=September 2014}}
{{Infobox scientist
| name = 
| image = Cheryl Praeger, in Perth.jpg
| image_size = 
| alt = 
| caption = Praeger by the Swan River in [[Perth, Australia]]
| birth_date = {{Birth date and age|df=yes|1948|09|07}}
| birth_place = [[Toowoomba, Queensland]], [[Australia]]
| residence = 
| nationality = 
| fields = {{Flatlist|
* [[Group theory]]
* [[algebraic graph theory]]
* [[combinatorial design]]s
}}
| workplaces = [[University of Western Australia]]
| alma_mater = {{Plainlist|
* [[University of Queensland]]
* [[University of Oxford]]
* [[University of Western Australia]]
}}
| doctoral_advisor = [[Peter M. Neumann]]
| doctoral_students = 
| notable_students = 
| website = {{URL|www.maths.uwa.edu.au/~praeger}}
}}
'''Cheryl Elisabeth Praeger''', [[Order of Australia|AM]], [[Fellow of the Australian Academy of Science|FAA]], (born 7 September 1948, [[Toowoomba, Queensland|Toowoomba]], [[Queensland]]) is an [[Australia|Australian]] mathematician. Praeger received BSc (1969) and [[Master's degree|MSc]] degrees from the [[University of Queensland]] (1974), and doctorate from the [[University of Oxford]] in 1973 under direction of [[Peter M. Neumann]]. She has published widely and has advised 27 PhD students (as of March 2018). She is currently Emeritus Professor of Mathematics at the [[University of Western Australia]]. She is best known for her works in [[group theory]], [[algebraic graph theory]] and [[combinatorial design]]s.

==Education==
Praeger completed her high school education at [[Brisbane Girls Grammar School]]. After graduating high school, Praeger went to the government vocational guidance section to inquire about how she could further study mathematics. The vocational guidance officer she spoke with tried to discourage her from studying mathematics further,&lt;ref name=interview&gt;{{cite web
|url=http://science.org.au/scientists/interviews/p/cp.html
|title=Interviews with Australian Scientists: Professor Cheryl Praeger Mathematician
|publisher=[[Australian Academy of Science]]
|accessdate=16 April 2013
|deadurl=yes
|archiveurl=https://web.archive.org/web/20130408224736/http://www.science.org.au/scientists/interviews/p/cp.html
|archivedate=8 April 2013
|df=dmy-all
}}&lt;/ref&gt; suggesting she become a teacher or a nurse because two other girls who came to him wanting to study math weren't able to pass their courses.&lt;ref name=interview/&gt; He reluctantly showed her an engineering course description, but she felt it didn't have enough mathematics. So she left without getting much information that day, but did continue on to receive her bachelor's and master's degrees from the [[University of Queensland]].

Having met several women on the mathematics staff during her undergraduate studies, the prospect of becoming a mathematician didn't seem strange to her. During her first and second years she did honours studies in mathematics and physics, choosing to continue in mathematics after her second year.&lt;ref name=interview/&gt; After completing her education at University of Queensland she was offered a research scholarship at [[Australian National University|ANU]] but chose instead to take the Commonwealth Scholarship to the [[University of Oxford]] and attended [[St Anne's College, Oxford|St Anne's College]]. At that point she knew she wanted to study algebra.

After earning her doctorate in 1973, she obtained a research fellowship at ANU. She had her first opportunity at teaching regular classes at the [[University of Virginia]] during the semester she worked there. Afterwards, she returned to ANU, where she met her future husband, John Henstridge, who was studying statistics. She was later offered a short-term position at the [[University of Western Australia]], which turned into a long term position, where she currently works today.&lt;ref name=interview/&gt; In 1989 she received the degree of Doctor of Science from the University of Western Australia for her work on permutation groups and algebraic graph theory.

==Career==

Her career has been largely the Department of Mathematics and Statistics at the University of Western Australia.  She was appointed full Professor in 1983 and was Head of the Department of Mathematics 1992–1994, inaugural Dean of Postgraduate Research Studies 1996–1998, Chair Promotions and Tenure Committee 2000–2004, Deputy Dean of the Faculty of Engineering Computing and Mathematics 2003–2006, ARC Professorial Fellow 2007.&lt;ref&gt;{{cite web
|url=http://www.uwa.edu.au/profile?dn=cn%25253DCheryl%252520Praeger%252520AM%252520FAA%25252Cou%25253DSchool%252520of%252520Mathematics%252520and%252520Statistics%25252Cou%25253DFaculty%252520of%252520Engineering%25255C%25252C%252520Computing%252520and%252520Mathematics%25252Cou%25253DFaculties%25252Co%25253DThe%252520University%252520of%252520Western%252520Australia
|title=UWA Staff Profile:W/Prof Cheryl Praeger AM FAA
|publisher=[[University of Western Australia]]
|accessdate=16 April 2013
}}&lt;/ref&gt; and ARC Federation Fellow in 2009.&lt;ref&gt;{{cite web
|url=http://www.arc.gov.au/ncgp/fedfellows/FF07_Selection_Rpt.htm
|title=Federation Fellowships Selection Report for Funding commencing in 2007
|publisher=[[Australian Research Council]]
|accessdate=25 January 2013
|deadurl=yes
|archiveurl=https://web.archive.org/web/20130413114253/http://arc.gov.au/ncgp/fedfellows/FF07_Selection_Rpt.htm
|archivedate=13 April 2013
|df=dmy-all
}}&lt;/ref&gt;

During her career, Praeger has been invited to speak at many conferences, including ones in [[South Korea]], [[Singapore]], [[Hong Kong]], [[Morocco]], [[Slovakia]], [[Slovenia]], [[France]], [[Germany]], [[Soviet Union|USSR]], [[Belgium]], [[Iran]], [[Italy]], [[Philippines|the Philippines]], and [[Japan]].&lt;ref name=interview/&gt;&lt;ref name=agnesscott/&gt;

==Awards, honours and memberships==
Praeger is a Fellow of the [[Australian Academy of Science]], former president of the
[[Australian Mathematical Society]] (1992–1994 and first female President of the Society), and was appointed as a member of the [[Order of Australia]] in 1999 for her service to mathematics in Australia, especially through research and professional associations.&lt;ref&gt;{{cite web
|url=http://www.itsanhonour.gov.au/honours/honour_roll/search.cfm?aus_award_id=881121&amp;search_type=simple&amp;showInd=true
|title=It's an Honour – Honours – Search Australian Honours
|publisher=[[Department of the Prime Minister and Cabinet (Australia)|Department of the Prime Minister and Cabinet]]
|accessdate=25 January 2013
}}&lt;/ref&gt;
Other awards include:
* In 1993 she was awarded an honorary Doctor of Science by the [[Prince of Songkla University]], Thailand.
* In 2003 she received the [[Centenary Medal]] of the Australian Government.&lt;ref name=agnesscott/&gt;
* In 2005 she was awarded Doctor Honoris Causis by the [[Université Libre de Bruxelles]], Belgium.
* In 2009 she was named Western Australian Scientist of the Year.&lt;ref&gt;{{cite web
|url=http://www.mediastatements.wa.gov.au/Pages/StatementDetails.aspx?StatId=1980&amp;listName=StatementsBarnett
|title=Leading mathematician crowned 2009 WA Scientist of the Year
|date=2 December 2009
|publisher=[[Department of Commerce (Western Australia)|Department of Commerce]]
|accessdate=25 January 2013
|deadurl=yes
|archiveurl=https://archive.is/20130219173328/http://www.mediastatements.wa.gov.au/Pages/StatementDetails.aspx?StatId=1980&amp;listName=StatementsBarnett
|archivedate=19 February 2013
|df=dmy-all
}}&lt;/ref&gt;
* In 2011 she was awarded the Moyal Medal by [[Macquarie University]], Australia (the first female recipient of the Medal since its establishment in 2000).
* She was awarded the 2011 Euler Medal of the [[Institute of Combinatorics and its Applications]] (presented in 2017).
* In 2012 she became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 26 May 2013.&lt;/ref&gt;
* In 2013 she was awarded the [[Thomas Ranken Lyle Medal]] by the Australian Academy of Science (the first female recipient of the Medal since its establishment in 1935).
* In 2014 she was awarded the [[George Szekeres Medal]] by the [[Australian Mathematical Society]] (the first female recipient of the Medal since its establishment in 2002).
* In 2014 she was elected an Honorary Member of the [[London Mathematical Society]].&lt;ref&gt;[https://www.lms.ac.uk/sites/lms.ac.uk/files/Membership/HONORARY%20MEMBERS%20%28updated%202015%29.pdf List of honorary members of the London Mathematical Society], retrieved 14 October 2015.&lt;/ref&gt;
* In 2015 she was awarded an honorary doctorate in Mathematics Education by [[Yazd University]], Iran.
* In 2015 she was awarded the [[Mehdi Behzad]] Prize of the Iranian Mathematical Society, for management in mathematics.
* In 2015 she was awarded Honorary Doctor of Science by the [[University of Saint Andrews]], Scotland.
* In 2015 she was inducted into both the Western Australian Women's Hall of Fame and the Western Australian Science Hall of Fame.&lt;ref&gt;[http://www.jtsi.wa.gov.au/what-we-do/science-and-innovation/science-award-programs/wa-science-hall-of-fame], retrieved 10 June 2018.&lt;/ref&gt;
* In 2017 she was awarded Honorary Doctor of Mathematics by the [[University of Queensland]], Australia.
* in 2018 she was awarded Honorary Doctor by the [[University of Primorska]], Slovenia.&lt;ref&gt;[https://www.upr.si/en/press-center/news-index/dr-cheryl-praeger-and-artist-metka-krasovec-receive-honorary-doctorates-from-up] Dr. Cheryl E. Praeger and artist Metka Krašovec receive honorary doctorates from UP&lt;/ref&gt;

Since 2014, the Women in Mathematics Special Interest Group of the Australian Mathematical Society bestows the [[Cheryl E. Praeger Travel Awards]] to female mathematicians.&lt;ref&gt;http://www.austms.org.au/Praeger+Awardees&lt;/ref&gt;   Since 2017 the Australian Mathematics Trust has awarded the Cheryl Praeger Medal to the best performing female contestants in the [[Australian Mathematics Competition]]. &lt;ref&gt;https://www.amt.edu.au/cheryl-praeger-award-announcement/&lt;/ref&gt;

Praeger has also held memberships with the [[Combinatorial Mathematics Society of Australasia]], [[Institute of Combinatorics and its Applications]], Australian Mathematics Trust, [[American Mathematical Society]], and the [[London Mathematical Society]]. Her past affiliations have not been limited to academia. 

==Other Activities==
She has also been a member of the Curriculum Development Center of the Commonwealth Schools Commission, the Prime Minister's Science Advisory Council, WISET Advisory Committee to the Federal Minister for Science on participation of women in Science, Engineering, and Technology, UWA Academy of Young Mathematicians Lectures, the Western Australian School Mathematics Enrichment Course Tutor, and Data Analysis Australia Pty Ltd. She has also served on the [[Australian Federation of University Women]] (Western Australian Branch) and the Nedlands Primary School Council.&lt;ref name=agnesscott /&gt;  Since 1992 she has been a board member of the Australian Mathematics Trust.  Since 2001 she has chaired the Australian Mathematical Olympiad Committee.

Between 2007 and 2014 she was a member of the Executive Committee of the [[International Mathematical Union]] and between 2013 and 2016 a Vice President of the [[International Commission on Mathematical Instruction]].

Between 2014 and 2018 she was Foreign Secretary of the [[Australian Academy of Science]].  Professor Praeger was elected as a Member-at-Large of the Executive Board of the Association of Academies and Societies of Sciences in Asia (AASSA) for 2016–18 and accepted an invitation to Chair the AASSA Committee of Women in Science and Engineering (WISE).  She is a Member of the Executive Committee of the Inter Academy Partnership - Science, 2017-19.

==Personal life==
In August 1975 she married John Henstridge in [[Brisbane]]. They have two children, James (1979) and Tim (1982).&lt;ref name=interview /&gt;

In addition to holding a doctorate in mathematics, she also holds an [[Associate in Music, Australia|AMusA]] in piano performance and is a member of the University of Western Australia Collegium Musicum. She has been a member of the [[Uniting Church in Australia]], Nedlands Parish since 1977, functioned as an elder from 1981–1987, and as an organist since 1985. She lists keyboard music among her stronger interests along with sailing, hiking, and cycling.&lt;ref name=agnesscott /&gt;

Praeger also promotes the involvement of women in mathematics by encouraging girls in primary and secondary schools with lectures, workshops, conferences and through Family Maths Program Australia (FAMPA), which she was key in implementing in local primary schools.&lt;ref name=agnesscott&gt;{{cite web
|url=http://www.agnesscott.edu/lriddle/women/praeger.htm
|title=Cheryl E. Praeger
|publisher=[[Agnes Scott College]]
|accessdate=21 April 2013
}}&lt;/ref&gt;

==Research==

Praeger's key research is in [[Group Theory]] and [[Combinatorics]], including [[Analysis of algorithms]] and complexity, [[Discrete Mathematics]] and [[Geometry]]. She was first published in 1970 while still an undergraduate. As of September 2018, she has 395 publications total.

She has co-authored several papers on [[symmetric graph]]s and [[distance-transitive graph]]s with [[Tony Gardiner]]. She has also co-authored several papers with [[Peter Cameron (mathematician)|Peter Cameron]], including the proof of Sims' Conjecture in 1983.&lt;ref&gt;[https://www.theoremoftheday.org/GroupTheory/Sims/TotDSims.pdf The Sims Conjecture], THEOREM OF THE DAY, 1999, retrieved May 2018.&lt;/ref&gt;

With Jan Saxl and Martin Liebeck, she has co-authored papers on many topics including: [[permutation group]]s, [[primitive permutation group]]s, [[simple group]]s, and [[almost simple group]]s.&lt;ref name=researchlist&gt;{{cite web|title=Cheryl E Praeger's Publications|url=http://school.maths.uwa.edu.au/~praeger/research.html|publisher=University of Western Australia|accessdate=24 April 2013}}&lt;/ref&gt; Together they co-authored "On the [[O'Nan–Scott theorem|O'Nan Scott Theorem]] for primitive permutation groups". It pertains to the [[classification of finite simple groups]], namely the classification of finite primitive permutation groups.&lt;ref&gt;{{cite journal|last=Liebeck|first=Martin W.|author2=Cheryl E. Praeger and Jan Saxl|title=On the O'Nan Scott Theorem for primitive permutation groups|journal=J. Austral. Math. Soc.|year=1988|url=http://journals.cambridge.org/download.php?file=%2FJAZ%2FJAZ1_44_03%2FS144678870003216Xa.pdf&amp;code=390c373663b91e6414e1b68b258da7cd|accessdate=24 April 2013}}&lt;/ref&gt; The paper contains a complete self-contained proof of the theorem. Praeger later went on to generalise the O'Nan–Scott Theorem to quasiprimitive groups.

==Selected publications==
* with Martin Liebeck, Jan Saxl: [https://books.google.com/books?id=dfWTnEioFrkC ''The maximal factorizations of the finite simple groups and their automorphism groups''], American Mathematical Society 1990
* with Leonard Soicher: [http://www.cambridge.org/gb/academic/subjects/mathematics/algebra/low-rank-representations-and-graphs-sporadic-groups?format=PB#d0JuDEdQLFJUrtmL.97, ''Low rank representations and graphs for sporadic groups''], Cambridge University Press 1997
* with Jason Fulman, Peter Neumann: ''A generating function approach to the enumeration of matrices in classical groups over finite fields'', American Mathematical Society 2005
* with Martin Liebeck, Jan Saxl: [https://books.google.com/books?id=WWjNCoVyWqAC ''Regular subgroups of primitive permutation groups''], American Mathematical Society 2010
* with Csaba Schneider: [http://www.cambridge.org/gb/academic/subjects/mathematics/algebra/permutation-groups-and-cartesian-decompositions?format=PB#feUwRoSODCuilmMr.97,''Permutation Groups and Cartesian Decompositions''], Cambridge University Press 2018

==References==
{{reflist}}

==External links==
* [http://www.maths.uwa.edu.au/~praeger Personal web page]
* [http://school.maths.uwa.edu.au/~praeger/research.html Publication list]
* {{MathGenealogy |id=35943}}
*[http://www.agnesscott.edu/lriddle/women/praeger.htm "Cheryl Praeger", Biographies of Women Mathematicians], [[Agnes Scott College]]
* {{MacTutor Biography|id=Praeger}}
* [https://web.archive.org/web/20060902102916/http://science.org.au/scientists/notescp.htm Summary of Cheryl Praeger's career]
* [https://web.archive.org/web/20070104173306/http://science.org.au/scientists/cp.htm Interview with Cheryl Praeger] – by [[Bernhard Neumann]] in 1999.
* [http://www.theoremoftheday.org/Resources/Mathematicians.html#P Theorems by Cheryl Praeger at Theorem of the Day].
* [https://scholar.google.com/citations?user=vWpNYgIAAAAJ&amp;hl=en&amp;oi=ao Cheryl Praeger's Profile on Google Scholars]
* {{YouTube|19tDlkUu2ls|"PRIMA2009 Plenary Lecture 11: Cheryl Praeger,"}} [[University of New South Wales]]

{{Authority control}}

{{DEFAULTSORT:Praeger, Cheryl}}
[[Category:1948 births]]
[[Category:Living people]]
[[Category:20th-century Australian mathematicians]]
[[Category:21st-century Australian mathematicians]]
[[Category:Australian women mathematicians]]
[[Category:Group theorists]]
[[Category:Combinatorialists]]
[[Category:Members of the Order of Australia]]
[[Category:Fellows of the Australian Academy of Science]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:People from Toowoomba]]
[[Category:University of Queensland alumni]]
[[Category:Alumni of the University of Oxford]]
[[Category:University of Western Australia faculty]]
[[Category:Recipients of grants/fellowships from the Australian Research Council (ARC)]]</text>
      <sha1>ssw4ufa5q03sgg6bfgh10hu0sbjalqo</sha1>
    </revision>
  </page>
  <page>
    <title>Clarence Raymond Adams</title>
    <ns>0</ns>
    <id>36810753</id>
    <revision>
      <id>837725690</id>
      <parentid>809582838</parentid>
      <timestamp>2018-04-22T17:07:22Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (1 source from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4219">{{BLP sources|date=August 2012}}
{{Infobox scientist
| name              = Clarence Raymond Adams
| image             = Bays Fueter Chuard Adams Zurich1932.tif
| image_size        = 
| caption           = Adams (right) at the [[International Congress of Mathematicians|ICM]] 1932
| birth_date        = April 10, 1898
| birth_place       = [[Cranston, Rhode Island]]
| death_date        = {{d-da|October 15, 1965|April 10, 1898}}
| nationality       = American
| fields            = [[Mathematics]]
| workplaces        = [[Brown University]]
| alma_mater        = Brown University&lt;br&gt;[[Harvard University]]
| doctoral_advisor  = [[George David Birkhoff|G. D. Birkhoff]]
| doctoral_students = [[Anthony Morse]]&lt;br&gt;[[James A. Clarkson]]
| known_for         = 
| awards            = 
}}
'''Clarence Raymond Adams''' (April 10, 1898 – October 15, 1965) was an American mathematician who worked on [[Finite difference|partial difference equations]].

He entered [[Brown University]] in the fall of 1915 and graduated in 1918. Adams received his PhD in 1922 from [[Harvard University]] under the direction of [[George David Birkhoff|G. D. Birkhoff]]. On August 17, 1922, he married Rachel Blodgett, who earned a PhD from Radcliffe College in 1921. As a Sheldon Traveling Fellow of Harvard University, he studied at the [[Sapienza University of Rome]] under [[Tullio Levi-Civita]] and at the [[University of Göttingen]] under [[Richard Courant]]. In 1923 Adams returned to Brown University as an instructor, then became a full professor in 1936 and eventually chair of the mathematics department from 1942 to 1960. In 1965 he retired and died on October 15 of that same year.&lt;ref&gt;"[https://www.brown.edu/Administration/News_Bureau/Databases/Encyclopedia/search.php?serial=A0040 Adams, Clarence Raymond]" from Martha Mitchell's ''[[Encyclopedia Brunoniana]]''&lt;/ref&gt;&lt;ref&gt;{{cite book | url=https://books.google.de/books?id=IRbOAwAAQBAJ | isbn=978-0-8218-4376-5 | first1 = Judy | last1 = Green | author1-link = Judy Green (mathematician) | first2 = Jeanne | last2 = LaDuke | author2-link = Jeanne LaDuke| title=Pioneering Women in American Mathematics &amp;mdash; The Pre-1940 PhD's | location= | publisher=[[American Mathematical Society]],  The [[London Mathematical Society]] | series=History of Mathematics | volume=34 | edition=1st | date=2008 }} Rachel (Blodgett) Adams biography on p.6-7 of the [https://www.ams.org/bookpages/hmath-34-PioneeringWomen.pdf Supplementary Material] at [https://www.ams.org/publications/authors/books/postpub/hmath-34 AMS]&lt;/ref&gt;

==Publications==
* {{cite journal|title=The general theory of a class of linear partial ''q''-difference equations|journal=Trans. Amer. Math. Soc.|year=1924|volume=26|issue=3|pages=283–312|doi=10.1090/s0002-9947-1924-1501279-2}}
* {{cite journal|title=On the linear ordinary ''q''-difference equations|journal=Ann. Math.|year=1929|volume=30|pages=195–205}}
* {{cite journal|title=On the linear partial ''q''-difference equations of general type|journal=Trans. Amer. Math. Soc.|year=1929|volume=31|pages=360–371|doi=10.1090/s0002-9947-1929-1501487-5}}
* {{cite journal|title=Linear ''q''-difference equations|journal=Bull. Amer. Math. Soc.|year=1931|volume=37|issue=6|pages=361–400|mr=1562160|doi=10.1090/s0002-9904-1931-05162-4}}
* {{cite journal|title=Transformations of double sequences with application to Cesàro summability of double series|journal=Bull. Amer. Math. Soc.|year=1931|volume=37|issue=10|pages=741–748|mr=1562249|doi=10.1090/s0002-9904-1931-05258-7}}

==References==
{{Reflist}}

==External links==
*{{MathGenealogy |id=4931}}
* [https://zbmath.org/authors/?q=ai:adams.clarence-raymond Author profile] in the database [[Zentralblatt MATH|zbMATH]]
* {{commons category inline|Clarence Raymond Adams (mathematician)}}

{{Authority control}}

{{DEFAULTSORT:Adams, Clarence Raymond}}
[[Category:1898 births]]
[[Category:1965 deaths]]
[[Category:Place of death missing]]
[[Category:20th-century American mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Brown University alumni]]
[[Category:Harvard University alumni]]
[[Category:Brown University faculty]]
[[Category:Mathematicians from Rhode Island]]


{{US-mathematician-stub}}</text>
      <sha1>f1i15efcl49ax0ludfasxpruxx09wex</sha1>
    </revision>
  </page>
  <page>
    <title>Complete partial order</title>
    <ns>0</ns>
    <id>572352</id>
    <revision>
      <id>827605758</id>
      <parentid>788141783</parentid>
      <timestamp>2018-02-25T18:25:41Z</timestamp>
      <contributor>
        <ip>93.167.52.61</ip>
      </contributor>
      <comment>/* Definitions */ Don't claim the reader already knows this</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8439">In [[mathematics]], the phrase '''complete partial order''' is variously used to refer to at least three similar, but distinct, classes of [[partially ordered set]]s, characterized by particular [[completeness (order theory)|completeness properties]]. Complete partial orders play a central role in [[theoretical computer science]], in [[denotational semantics]] and [[domain theory]].

== Definitions ==

A '''complete partial order''' abbreviated '''cpo''' can, depending on context, refer to any of the following concepts. 

* A partially ordered set is a '''directed-complete partial order''' ('''dcpo''') if each of its [[directed set|directed subsets]] has a [[supremum]]. A subset of a partial order is directed if it is non-empty and every pair of elements has an upper bound in the subset. In the literature, dcpos sometimes also appear under the label '''up-complete poset'''.

* A partially ordered set is a '''pointed directed-complete partial order''' if it is a dcpo with a least element. They are sometimes abbreviated '''cppo'''s.

* A partially ordered set is a '''ω-complete partial order''' ('''ω-cpo''')  if it is a poset in which every ω-chain (''x''&lt;sub&gt;1&lt;/sub&gt;≤''x''&lt;sub&gt;2&lt;/sub&gt;≤''x''&lt;sub&gt;3&lt;/sub&gt;≤''x''&lt;sub&gt;4&lt;/sub&gt;≤...) has a supremum that belongs to the underlying set of the poset. Every dcpo is an ω-cpo, since every ω-chain is a directed set, but the converse is not true. However, every ω-cpo with a [[domain theory#Bases of domains|basis]] is also a dcpo (with the same basis).&lt;ref&gt;{{Cite book|title=Handbook of Logic in Computer Science, volume 3|vauthors=Abramsky S, Gabbay DM, Maibaum TS|collaboration=|publisher=Clarendon Press|year=1994|isbn=9780198537625|location=Oxford|at=Prop 2.2.14, pp. 20|quote=|via=}}&lt;/ref&gt; An ω-cpo (dcpo) with a basis is also called a '''continuous''' ω-cpo (continuous dcpo).

Note that ''complete partial order'' is never used to mean a poset in which ''all'' subsets have suprema; the terminology [[complete lattice]] is used for this concept.

Requiring the existence of directed suprema can be motivated by viewing directed sets as generalized approximation sequences and suprema as ''limits'' of the respective (approximative) computations. This intuition, in the context of denotational semantics, was the motivation behind the development of [[domain theory]].

The [[duality (order theory)|dual]] notion of a directed complete poset is called a '''filtered complete partial order'''. However, this concept occurs far less frequently in practice, since one usually can work on the dual order explicitly.

== Examples ==

* Every finite poset is directed complete.
* All [[complete lattice]]s are also directed complete.
* For any poset, the set of all [[non-empty]] [[filter (mathematics)|filters]], ordered by subset inclusion, is a dcpo. Together with the empty filter it is also pointed. If the order has binary [[join and meet|meets]], then this construction (including the empty filter) actually yields a [[complete lattice]].
* The set of all [[partial function]]s on some given set ''S'' can be ordered by defining ''f''&amp;nbsp;≤&amp;nbsp;''g'' for functions ''f'' and ''g'' if and only if ''g'' extends ''f'', i.e. if the domain of ''f'' is a subset of the domain of ''g'' and the values of ''f'' and ''g'' agree on all inputs for which both functions are defined. (Equivalently, ''f''&amp;nbsp;≤&amp;nbsp;''g'' if and only if ''f''&amp;nbsp;⊆&amp;nbsp;''g'' where ''f'' and ''g'' are identified with their respective [[graph of a function|graphs]].) This order is a pointed dcpo, where the least element is the nowhere-defined function (with empty domain). In fact, ≤ is also [[bounded complete]]. This example also demonstrates why it is not always natural to have a greatest element.
* The [[specialization order]] of any [[sober space]] is a dcpo.
* Let us use the term “[[deductive system]]” as a set of sentences closed under consequence (for defining notion of consequence, let us use e.g. Tarski's algebraic approach&lt;ref name=Tar-BizIg&gt;Tarski, Alfred: Bizonyítás és igazság / Válogatott tanulmányok. Gondolat, Budapest, 1990. (Title means: Proof and truth / Selected papers.)&lt;/ref&gt;&lt;ref name=BurSan-UnivAlg&gt;[http://www.math.uwaterloo.ca/~snburris/index.html Stanley N. Burris] and H.P. Sankappanavar: [http://www.math.uwaterloo.ca/~snburris/htdocs/ualg.html A Course in Universal Algebra]&lt;/ref&gt;). There are interesting theorems which concern a set of deductive systems being a directed-complete partial ordering.&lt;ref name=seqdcpo&gt;See online in p. 24 exercises 5–6 of §5 in [[#_note-BurSan-UnivAlg|BurSan:UnivAlg]]. Or, on paper, see [[#_note-Tar-BizIg|Tar:BizIg]].&lt;/ref&gt; Also, a set of deductive systems can be chosen to have a least element in a natural way (so that it can be also a pointed dcpo), because the set of all consequences of the empty set (i.e. “the set of the logically provable / logically valid sentences”) is (1) a deductive system (2) contained by all deductive systems.

== Properties ==

An ordered set ''P'' is a pointed dcpo if and only if every [[chain (order theory)|chain]] has a supremum in ''P'', i.e., ''P'' is [[chain-complete partial order|chain-complete]]&lt;ref&gt;{{citation
 | last = Markowsky | first = George
 | issue = 1
 | journal = Algebra Universalis
 | mr = 0398913
 | pages = 53–68
 | title = Chain-complete posets and directed sets with applications
 | volume = 6
 | year = 1976
 | doi=10.1007/bf02485815}}.&lt;/ref&gt;. Alternatively, an ordered set ''P'' is a pointed dcpo if and only if every [[order-preserving]] self-map of ''P'' has a least [[fixpoint]]. Every set ''S'' can be turned into a pointed dcpo by adding a least element ⊥ and introducing a flat order with ⊥&amp;nbsp;≤&amp;nbsp;''s'' and s&amp;nbsp;≤&amp;nbsp;''s'' for every ''s''&amp;nbsp;∈&amp;nbsp;''S'' and no other order relations.

== Continuous functions and fixpoints ==

A function ''f'' between two dcpos ''P'' and ''Q'' is called '''[[Scott continuity|(Scott) continuous]]''' if it maps directed sets to directed sets while preserving their suprema:
* &lt;math&gt;f(D) \subseteq Q&lt;/math&gt; is directed for every directed &lt;math&gt;D \subseteq P&lt;/math&gt;.
* &lt;math&gt;f(\sup D) = \sup f(D)&lt;/math&gt; for every directed &lt;math&gt;D \subseteq P&lt;/math&gt;.
Note that every continuous function between dcpos is a [[Monotone function#Monotonicity in order theory|monotone function]]. 
This notion of continuity is equivalent to the topological continuity induced by the [[Scott topology]].

The set of all continuous functions between two dcpos ''P'' and ''Q'' is denoted &lt;nowiki&gt;[&lt;/nowiki&gt;''P''&amp;nbsp;→&amp;nbsp;''Q''&lt;nowiki&gt;]&lt;/nowiki&gt;. Equipped with the pointwise order, this is again a dcpo, and a cpo whenever ''Q'' is a cpo.
Thus the complete partial orders with Scott-continuous maps form a [[cartesian closed category]].&lt;ref name="barendregt1984"&gt;[[Henk Barendregt|Barendregt, Henk]], [http://www.elsevier.com/wps/find/bookdescription.cws_home/501727/description#description ''The lambda calculus, its syntax and semantics''], [[North-Holland]] (1984)&lt;/ref&gt;

Every order-preserving self-map ''f'' of a cpo (''P'', ⊥) has a least fixpoint.&lt;ref&gt;See [[Knaster–Tarski theorem]]; The foundations of program verification, 2nd edition, Jacques Loeckx and Kurt Sieber, John Wiley &amp; Sons, {{ISBN|0-471-91282-4}}, Chapter 4; the Knaster-Tarski theorem, formulated over cpo's, is given to prove as exercise 4.3-5 on page 90.&lt;/ref&gt; If ''f'' is continuous then this fixpoint is equal to the supremum of the [[Iterated function|iterates]] (⊥, ''f''(⊥), ''f''(''f''(⊥)), … ''f''&lt;sup&gt;''n''&lt;/sup&gt;(⊥), …) of ⊥ (see also the [[Kleene fixpoint theorem]]).

== See also ==

Directed completeness relates in various ways to other [[completeness (order theory)|completeness]] notions such as [[chain complete]]ness. Directed completeness alone is quite a basic property that occurs often in other order-theoretic investigations, using for instance [[algebraic poset]]s and the [[Scott topology]].

== Notes ==

&lt;references/&gt;

== References ==
* {{cite book
 |author1=Davey, B.A. |author2=Priestley, H. A.
 | year = 2002
 | title = '''Introduction to Lattices and Order'''
 | edition = Second
 | publisher = Cambridge University Press
 | isbn = 0-521-78451-4
}}

{{DEFAULTSORT:Complete Partial Order}}
[[Category:Order theory]]

[[ru:Частично упорядоченное множество#Полное частично упорядоченное множество]]</text>
      <sha1>inxiq38ern9zakgbqe5qy6v51ywghvp</sha1>
    </revision>
  </page>
  <page>
    <title>Compressed sensing</title>
    <ns>0</ns>
    <id>11403316</id>
    <revision>
      <id>868664188</id>
      <parentid>859982741</parentid>
      <timestamp>2018-11-13T17:25:32Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; remove 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="45680">{{pp-semi|small=yes}}
'''Compressed sensing''' (also known as '''compressive sensing''', '''compressive sampling''', or '''sparse sampling''') is a [[signal processing]] technique for efficiently acquiring and reconstructing a [[Signal (electronics)|signal]], by finding solutions to [[Underdetermined system|underdetermined linear systems]]. This is based on the principle that, through optimization, the sparsity of a signal can be exploited to recover it from far fewer samples than required by the [[Nyquist–Shannon sampling theorem|Shannon-Nyquist sampling theorem]]. There are two conditions under which recovery is possible.&lt;ref&gt;[http://nuit-blanche.blogspot.com/2009/09/cs.html CS: Compressed Genotyping, DNA Sudoku - Harnessing high throughput sequencing for multiplexed specimen analysis]&lt;/ref&gt; The first one is [[sparsity]] which requires the signal to be sparse in some domain. The second one is [[Coherence (signal processing)|incoherence]] which is applied through the isometric property which is sufficient for sparse signals.&lt;ref&gt;{{cite journal | last1 = Donoho | first1 = David L | year = 2006 | title =  For most large underdetermined systems of linear equations the minimal 1-norm solution is also the sparsest solution| url = | journal = Communications on pure and applied mathematics | volume = 59 | issue = | pages = 797–829 | doi = 10.1002/cpa.20132 }}&lt;/ref&gt;&lt;ref&gt;[http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zCdz10BfTRz0z0 M. Davenport, "The Fundamentals of Compressive Sensing", SigView, April 12, 2013.]&lt;/ref&gt;

== Overview ==
A common goal of the engineering field of [[signal processing]] is to reconstruct a signal from a series of sampling measurements. In general, this task is impossible because there is no way to reconstruct a signal during the times that the signal is not measured. Nevertheless, with prior knowledge or assumptions about the signal, it turns out to be possible to perfectly reconstruct a signal from a series of measurements (acquiring this series of measurements is called [[Sampling (signal processing)|sampling]]). Over time, engineers have improved their understanding of which assumptions are practical and how they can be generalized.

An early breakthrough in signal processing was the [[Nyquist–Shannon sampling theorem]]. It states that if a [[Real number|real]] signal's highest frequency is less than half of the sampling rate (or less than the sampling rate, if the signal is [[Complex number|complex]]), then the signal can be reconstructed perfectly by means of [[Whittaker–Shannon interpolation formula|sinc interpolation]]. The main idea is that with prior knowledge about constraints on the signal's frequencies, fewer samples are needed to reconstruct the signal.

Around 2004, [[Emmanuel Candès]], [[Justin Romberg]], [[Terence Tao]], and [[David Donoho]] proved that given knowledge about a signal's [[sparsity]], the signal may be reconstructed with even fewer samples than the sampling theorem requires.&lt;ref&gt;{{Cite journal|doi=10.1002/cpa.20124|url=http://www-stat.stanford.edu/~candes/papers/StableRecovery.pdf|title=Stable signal recovery from incomplete and inaccurate measurements|year=2006|last1=Candès|first1=Emmanuel J.|last2=Romberg|first2=Justin K.|last3=Tao|first3=Terence|journal=Communications on Pure and Applied Mathematics|volume=59|issue=8|pages=1207–1223|arxiv=math/0503066}}&lt;/ref&gt;&lt;ref name=Donoho&gt;{{Cite journal|doi=10.1109/TIT.2006.871582|title=Compressed sensing|year=2006|last1=Donoho|first1=D.L.|journal=IEEE Transactions on Information Theory|volume=52|issue=4|pages=1289–1306}}&lt;/ref&gt; This idea is the basis of compressed sensing.

==History==
Compressed sensing relies on [[Lp space|L1]] techniques, which several other scientific fields have used historically.&lt;ref&gt;[http://2.bp.blogspot.com/_0ZCyAOBrUtA/TTwqLEeLvdI/AAAAAAAAEXI/7S0_SnWoC0E/s1600/l1-minimization.JPG List of L1 regularization ideas] from Vivek Goyal, Alyson Fletcher, Sundeep Rangan, [http://www.math.uiuc.edu/%7Elaugesen/imaha10/goyal_talk.pdf The Optimistic Bayesian: Replica Method Analysis of Compressed Sensing]&lt;/ref&gt; In statistics, the [[least squares]] method was complemented by the [[Lp norm|&lt;math&gt;L^1&lt;/math&gt;-norm]], which was introduced by [[Pierre-Simon Laplace|Laplace]]. Following the introduction of [[linear programming]] and [[George Dantzig|Dantzig]]'s [[simplex algorithm]], the &lt;math&gt;L^1&lt;/math&gt;-norm was used in [[computational statistics]]. In statistical theory, the &lt;math&gt;L^1&lt;/math&gt;-norm was used by [[George W. Brown (academic)|George W. Brown]] and later writers on [[median-unbiased estimator]]s. It was used by Peter J. Huber and others working on [[robust statistics]]. The &lt;math&gt;L^1&lt;/math&gt;-norm was also used in signal processing, for example, in the 1970s, when seismologists constructed images of reflective layers within the earth based on data that did not seem to satisfy the [[Nyquist–Shannon sampling theorem|Nyquist–Shannon criterion]].&lt;ref&gt;{{Cite journal |doi = 10.1511/2009.79.276 |title = The Best Bits |year = 2009 |last1 = Hayes |first1 = Brian |journal = American Scientist |volume = 97 |issue = 4 |pages = 276 }}&lt;/ref&gt;  It was used in [[matching pursuit]] in 1993, the [[Lasso regression|LASSO estimator]] by [[Robert Tibshirani]] in 1996&lt;ref&gt;{{Cite journal |url = http://www-stat.stanford.edu/~tibs/lasso.html |first = Robert |last = Tibshirani |title = Regression shrinkage and selection via the lasso |journal = [[Journal of the Royal Statistical Society, Series B]] |volume = 58 |issue = 1 |pages = 267–288 }}&lt;/ref&gt; and [[basis pursuit]] in 1998.&lt;ref&gt;"Atomic decomposition by basis pursuit", by Scott Shaobing Chen, David L. Donoho, Michael, A. Saunders. SIAM Journal on Scientific Computing&lt;/ref&gt;  There were theoretical results describing when these algorithms recovered sparse solutions, but the required type and number of measurements were sub-optimal and subsequently greatly improved by compressed sensing.{{citation needed|date=May 2013}}

At first glance, compressed sensing might seem to violate [[Nyquist–Shannon sampling theorem|the sampling theorem]], because compressed sensing depends on the [[Sparse matrix|sparsity]] of the signal in question and not its highest frequency. This is a misconception, because the sampling theorem guarantees perfect reconstruction given sufficient, not necessary, conditions. A sampling method fundamentally different from classical fixed-rate sampling cannot "violate" the sampling theorem. Sparse signals with high frequency components can be highly under-sampled using compressed sensing compared to classical fixed-rate sampling.&lt;ref&gt;{{Cite journal |url = http://www-stat.stanford.edu/~candes/papers/ExactRecovery.pdf |title = Robust Uncertainty Principles: Exact Signal Reconstruction from Highly Incomplete Fourier Information |year = 2006 |last1 = Candès |first1 = Emmanuel J. |last2 = Romberg |first2 = Justin K. |last3 = Tao |first3 = Terence |journal = IEEE Trans. Inf. Theory |volume = 52 |issue = 8 |pages = 489–509 |doi=10.1109/tit.2005.862083|arxiv = math/0409186 }}&lt;/ref&gt;

==Method==

===Underdetermined linear system===
An [[underdetermined system]] of linear equations has more unknowns than equations and generally has an infinite number of solutions. The figure below shows such an equation system &lt;math&gt; \mathbf{y}=D\mathbf{x} &lt;/math&gt; where we want to find a solution for &lt;math&gt; \mathbf{x} &lt;/math&gt;.

[[File:Underdetermined equation system.svg|mini|200px|alt=Underdetermined linear equation system|Underdetermined linear equation system]]

In order to choose a solution to such a system, one must impose extra constraints or conditions (such as smoothness) as appropriate. In compressed sensing, one adds the constraint of sparsity, allowing only solutions which have a small number of nonzero coefficients. Not all underdetermined systems of linear equations have a sparse solution. However, if there is a unique sparse solution to the underdetermined system, then the compressed sensing framework allows the recovery of that solution.

===Solution / reconstruction method===
Compressed sensing takes advantage of the redundancy in many interesting signals—they are not pure noise. In particular, many signals are [[sparse matrix|sparse]], that is, they contain many coefficients close to or equal to zero, when represented in some domain.&lt;ref&gt;Candès, E.J., &amp; Wakin, M.B., ''An Introduction To Compressive Sampling'', IEEE Signal Processing Magazine, V.21, March 2008 [http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=4472240&amp;isnumber=4472102]&lt;/ref&gt; This is the same insight used in many forms of [[lossy compression]].

Compressed sensing typically starts with taking a weighted linear combination of samples also called compressive measurements in a [[Basis (linear algebra)|basis]] different from the basis in which the signal is known to be sparse. The results found by  [[Emmanuel Candès]], [[Justin Romberg]],  [[Terence Tao]] and  [[David Donoho]], showed that the number of these compressive measurements can be small and still contain nearly all the useful information. Therefore, the task of converting the image back into the intended domain involves solving an underdetermined [[matrix equation]] since the number of compressive measurements taken is smaller than the number of pixels in the full image. However, adding the constraint that the initial signal is sparse enables one to solve this underdetermined [[system of linear equations]].

The least-squares solution to such problems is to minimize the [[L2 norm|&lt;math&gt;L^2&lt;/math&gt; norm]]—that is, minimize the amount of energy in the system. This is usually simple mathematically (involving only a [[matrix multiplication]] by the [[pseudo-inverse]] of the basis sampled in). However, this leads to poor results for many practical applications, for which the unknown coefficients have nonzero energy.

To enforce the sparsity constraint when solving for the underdetermined system of linear equations, one can minimize the number of nonzero components of the solution. The function counting the number of non-zero components of a vector was called the [[L0 norm|&lt;math&gt;L^0&lt;/math&gt; "norm"]] by David Donoho{{refn|group=note|The quotation marks served two warnings.  First, the number-of-nonzeros &lt;math&gt;L^0&lt;/math&gt;-"norm" is not a proper [[F-space|F-norm]], because it is not continuous in its scalar argument: ''nnzs''(α''x'') is constant as α approaches zero. Unfortunately, authors now neglect the quotation marks and [[abuse of terminology|abused terminology]]—clashing with the established use of the &lt;math&gt;L^0&lt;/math&gt; norm for the space of measurable functions (equipped with an appropriate metric) or for the [[F-space|space]] of sequences with [[F-space|F–norm]] &lt;math&gt;(x_n) \mapsto \sum_n{2^{-n} x_n/(1+x_n)}&lt;/math&gt;.&lt;ref&gt;Stefan Rolewicz. ''Metric Linear Spaces''.&lt;/ref&gt;}}.

[[Emmanuel Candès|Candès]] et al. proved that for many problems it is probable that the [[L1 norm|&lt;math&gt;L^1&lt;/math&gt; norm]] is equivalent to the [[L0 norm|&lt;math&gt;L^0&lt;/math&gt; norm]], in a technical sense: This equivalence result allows one to solve the &lt;math&gt;L^1&lt;/math&gt; problem, which is easier than the &lt;math&gt;L^0&lt;/math&gt; problem. Finding the candidate with the smallest &lt;math&gt;L^1&lt;/math&gt; norm can be expressed relatively easily as a [[linear program]], for which efficient solution methods already exist.&lt;ref&gt;[http://www.acm.caltech.edu/l1magic/ L1-MAGIC is a collection of MATLAB routines]&lt;/ref&gt;  When measurements may contain a finite amount of noise, [[basis pursuit denoising]] is preferred over linear programming, since it preserves sparsity in the face of noise and can be solved faster than an exact linear program.

=== Total Variation based CS reconstruction ===
{{see also|Total variation denoising}}
{{split section|Total variation reconstruction|date=May 2017}}&lt;!-- reason=Longest section in current article. --&gt;

==== Motivation and Applications ====

===== Role of TV regularization =====
[[Total variation]] can be seen as a [[non-negative]] [[real number|real]]-valued [[functional (mathematics)|functional]] defined on the space of [[real number|real-valued]] [[function (mathematics)|function]]s (for the case of functions of one variable) or on the space of [[integrable function]]s (for the case of functions of several variables). For signals, especially, [[total variation]] refers to the integral of the absolute [[gradient]] of the signal. In signal and image reconstruction, it is applied as [[total variation regularization]] where the underlying principle is that signals with excessive details have high total variation and that removing these details, while retaining important information such as edges, would reduce the total variation of the signal and make the signal subject closer to the original signal in the problem.

For the purpose of signal and image reconstruction, &lt;math&gt;l1&lt;/math&gt; minimization models are used. Other approaches also include the least-squares as has been discussed before in this article. These methods are extremely slow and return a not-so-perfect reconstruction of the signal. The current CS Regularization models attempt to address this problem by incorporating sparsity priors of the original image, one of which is the total variation (TV). Conventional TV approaches are designed to give piece-wise constant solutions. Some of these include (as discussed ahead) - constrained l1-minimization which uses an iterative scheme. This method, though fast, subsequently leads to over-smoothing of edges resulting in blurred image edges.&lt;ref name = "EPTV" /&gt; TV methods with iterative re-weighting have been implemented to reduce the influence of large gradient value magnitudes in the images. This has been used in [[Tomography|computed tomography]] (CT) reconstruction as a method known as edge-preserving total variation. However, as gradient magnitudes are used for estimation of relative penalty weights between the data fidelity and regularization terms, this method is not robust to noise and artifacts and accurate enough for CS image/signal reconstruction and, therefore, fails to preserve smaller structures.

Recent progress on this problem involves using an iteratively directional TV refinement for CS reconstruction.&lt;ref name = "Orientation and directional refinement" /&gt; This method would have 2 stages: the first stage would estimate and refine the initial orientation field - which is defined as a noisy point-wise initial estimate, through edge-detection, of the given image. In the second stage, the CS reconstruction model is presented by utilizing directional TV regularizer. More details about these TV-based approaches - iteratively reweighted l1 minimization, edge-preserving TV and iterative model using directional orientation field and TV- are provided below.

==== Existing approaches ====

=====Iteratively reweighted &lt;math&gt;l_{1}&lt;/math&gt; minimization &lt;ref name="Original source for IRLS"&gt;{{cite journal | last1 = Candes | first1 = E. J. | last2 = Wakin | first2 = M. B. | last3 = Boyd | first3 = S. P. | year = 2008 | title = Enhancing sparsity by reweighted l1 minimization | url = | journal = J. Fourier Anal. Applicat | volume = 14 | issue = 5-6| pages = 877–905 | doi=10.1007/s00041-008-9045-x| arxiv = 0711.1612 }}&lt;/ref&gt; =====
[[File:IRLS.png|thumb|iteratively reweighted l1 minimization method for CS]]
In the CS reconstruction models using constrained &lt;math&gt;l_{1}&lt;/math&gt; minimization, larger coefficients are penalized heavily in the &lt;math&gt;l_{1}&lt;/math&gt; norm. It was proposed to have a weighted formulation of &lt;math&gt;l_{1}&lt;/math&gt; minimization designed to more democratically penalize nonzero coefficients. An iterative algorithm is used for constructing the appropriate weights.&lt;ref name="Iteration"&gt;Lange, K.: Optimization, Springer Texts in Statistics. Springer, New York (2004)&lt;/ref&gt; Each iteration requires solving one &lt;math&gt;l_{1}&lt;/math&gt; minimization problem by finding the local minimum of a concave penalty function that more closely resembles the &lt;math&gt;l_{0}&lt;/math&gt; norm. An additional parameter, usually to avoid any sharp transitions in the penalty function curve, is introduced into the iterative equation to ensure stability and so that a zero estimate in one iteration does not necessarily lead to a zero estimate in the next iteration. The method essentially involves using the current solution for computing the weights to be used in the next iteration.

====== Advantages and disadvantages ======
Early iterations may find inaccurate sample estimates, however this method will down-sample these at a later stage to give more weight to the smaller non-zero signal estimates. One of the disadvantages is the need for defining a valid starting point as a global minimum might not be obtained every time due to the concavity of the function. Another disadvantage is that this method tends to uniformly penalize the image gradient irrespective of the underlying image structures. This causes over-smoothing of edges, especially those of low contrast regions, subsequently leading to loss of low contrast information. The advantages of this method include: reduction of the sampling rate for sparse signals; reconstruction of the image while being robust to the removal of noise and other artifacts; and use of very few iterations. This can also help in recovering images with sparse gradients.

In the figure shown below, '''P1''' refers to the first-step of the iterative reconstruction process, of the projection matrix '''P''' of the fan-beam geometry, which is constrained by the data fidelity term. This may contain noise and artifacts as no regularization is performed. The minimization of '''P1''' is solved through the conjugate gradient least squares method. '''P2''' refers to the second step of the iterative reconstruction process wherein it utilizes the edge-preserving total variation regularization term to remove noise and artifacts, and thus improve the quality of the reconstructed image/signal. The minimization of '''P2''' is done through a simple gradient descent method. Convergence is determined by testing, after each iteration, for image positivity, by checking if &lt;math&gt;f^{k-1} = 0&lt;/math&gt; for the case when &lt;math&gt;f^{k-1} &lt; 0&lt;/math&gt; (Note that &lt;math&gt;f&lt;/math&gt; refers to the different x-ray linear attenuation coefficients at different voxels of the patient image).

=====Edge-preserving total variation (TV) based compressed sensing&lt;ref name ="EPTV"&gt;{{cite journal | last1 = Tian | first1 = Z. | last2 = Jia | first2 = X. | last3 = Yuan | first3 = K. | last4 = Pan | first4 = T. | last5 = Jiang | first5 = S. B. | year = 2011 | title = Low-dose CT reconstruction via edge preserving total variation regularization | url = | journal = Phys Med Biol | volume = 56 | issue = 18| pages = 5949–5967 | doi=10.1088/0031-9155/56/18/011| pmc = 4026331 | arxiv = 1009.2288 | bibcode = 2011PMB....56.5949T }}&lt;/ref&gt;=====
[[File:Edge preserving TV.png|thumb|Flow diagram figure for edge preserving total variation method for compressed sensing]]
This is an iterative CT reconstruction algorithm with edge-preserving TV regularization to reconstruct CT images from highly undersampled data obtained at low dose CT through low current levels (milliampere).  In order to reduce  the imaging dose, one of the approaches used is to reduce the number of x-ray projections acquired by the scanner detectors. However, this insufficient projection data which is used to reconstruct the CT image can cause streaking artifacts. Furthermore, using these insufficient projections in standard TV algorithms end up making the problem under-determined and thus leading to infinitely many possible solutions. In this method, an additional penalty weighted function is assigned to the original TV norm. This allows for easier detection of sharp discontinuities in intensity in the images and thereby adapt the weight to store the recovered edge information during the process of signal/image reconstruction. The parameter &lt;math&gt;\sigma&lt;/math&gt; controls the amount of smoothing applied to the pixels at the edges to differentiate them from the non-edge pixels. The value of &lt;math&gt;\sigma&lt;/math&gt; is changed adaptively based on the values of the histogram of the gradient magnitude so that a certain percentage of pixels have gradient values larger than &lt;math&gt;\sigma&lt;/math&gt;. The edge-preserving total variation term, thus, becomes sparser and this speeds up the implementation. A two-step iteration process known as forward-backward splitting algorithm is used.&lt;ref name = "Forward-Backward"&gt;{{cite journal | last1 = Combettes | first1 = P | last2 = Wajs | first2 = V | year = 2005 | title = Signal recovery by proximal forward-backward splitting | url = | journal = Multiscale Model Simul | volume = 4 | issue = | pages = 1168–200 | doi=10.1137/050626090}}&lt;/ref&gt; The optimization problem is split into two sub-problems which are then solved with the conjugate gradient least squares method&lt;ref name="CGLS"&gt;{{cite journal | last1 = Hestenes | first1 = M | last2 = Stiefel | first2 = E | year = 1952 | title = Methods of conjugate gradients for solving linear systems | url = | journal = J Res Natl Bur Stand | volume = 49 | issue = | pages = 409–36 | doi=10.6028/jres.049.044}}&lt;/ref&gt; and the simple gradient descent method respectively. The method is stopped when the desired convergence has been achieved or if the maximum number of iterations is reached.

===== Advantages and disadvantages =====
Some of the disadvantages of this method are the absence of smaller structures in the reconstructed image and degradation of image resolution. This edge preserving TV algorithm, however, requires fewer iterations than the conventional TV algorithm.&lt;ref name ="EPTV" /&gt; Analyzing the horizontal and vertical intensity profiles of the reconstructed images, it can be seen that there are sharp jumps at edge points and negligible, minor fluctuation at non-edge points. Thus, this method leads to low relative error and higher correlation as compared to the TV method. It also effectively suppresses and removes any form of image noise and image artifacts such as streaking.

=====Iterative model using a directional orientation field and directional total variation&lt;ref name="Orientation and directional refinement"&gt;http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=6588871&lt;/ref&gt;=====
To prevent over-smoothing of edges and texture details and to obtain a reconstructed CS image which is accurate and robust to noise and artifacts, this method is used. First, an initial estimate of the noisy point-wise orientation field of the image &lt;math&gt;I&lt;/math&gt;, &lt;math&gt;\hat{d}&lt;/math&gt;, is obtained. This noisy orientation field is defined so that it can be refined at a later stage to reduce the noise influences in orientation field estimation.A coarse orientation field estimation is then introduced based on structure tensor which is formulated as:&lt;ref name="Structure tensor"&gt;{{cite journal | last1 = Brox | first1 = T. | last2 = Weickert | first2 = J. | last3 = Burgeth | first3 = B. | last4 = Mrázek | first4 = P. | year = 2006 | title = Nonlinear structure tensors | url = | journal = Image Vis. Comput | volume = 24 | issue = 1| pages = 41–55 | doi=10.1016/j.imavis.2005.09.010}}&lt;/ref&gt; &lt;math&gt; J_\rho(\nabla I_{\sigma}) = G_\rho * (\nabla I_{\sigma} \otimes \nabla I_{\sigma}) = \begin{pmatrix}J_{11} &amp; J_{12}\\J_{12} &amp; J_{22}\end{pmatrix}&lt;/math&gt;. Here, &lt;math&gt; J_\rho &lt;/math&gt; refers to the structure tensor related with the image pixel point (i,j) having standard deviation &lt;math&gt;\rho&lt;/math&gt;. &lt;math&gt;G&lt;/math&gt; refers to the Gaussian kernel &lt;math&gt;(0, \rho ^2)&lt;/math&gt; with standard deviation &lt;math&gt;\rho&lt;/math&gt;. &lt;math&gt;\sigma&lt;/math&gt; refers to the manually defined parameter for the image &lt;math&gt;I&lt;/math&gt; below which the edge detection is insensitive to noise. &lt;math&gt;\nabla I_{\sigma}&lt;/math&gt; refers to the gradient of the image &lt;math&gt;I&lt;/math&gt; and &lt;math&gt;(\nabla I_{\sigma} \otimes \nabla I_{\sigma})&lt;/math&gt; refers to the tensor product obtained by using this gradient.

The structure tensor obtained is convolved with a Gaussian kernel &lt;math&gt;G&lt;/math&gt; to improve the accuracy of the orientation estimate with &lt;math&gt;\sigma&lt;/math&gt; being set to high values to account for the unknown noise levels. For every pixel (i,j) in the image, the structure tensor J is a symmetric and positive semi-definite matrix. Convolving all the pixels in the image with &lt;math&gt;G&lt;/math&gt;, gives orthonormal eigen vectors  ω and υ of the &lt;math&gt;J&lt;/math&gt; matrix. ω points in the direction of the dominant orientation having the largest contrast and υ points in the direction of the structure orientation having the smallest contrast.  The orientation field coarse initial estimation &lt;math&gt;\hat{d}&lt;/math&gt; is defined as &lt;math&gt;\hat{d}&lt;/math&gt; = υ.  This estimate is accurate at strong edges. However, at weak edges or on regions with noise, its reliability decreases.

To overcome this drawback, a refined orientation model is defined in which the data term reduces the effect of noise and improves accuracy while the second penalty term with the L2-norm is a fidelity term which ensures accuracy of initial coarse estimation.

This orientation field is introduced into the directional total variation optimization model for CS reconstruction through the equation: &lt;math&gt;min_\Chi\lVert \nabla \Chi \bullet d \rVert _{1} + \frac{\lambda}{2}\ \lVert Y - \Phi\Chi \rVert ^2_{2}&lt;/math&gt;. &lt;math&gt;\Chi&lt;/math&gt; is the objective signal which needs to be recovered. Y is the corresponding measurement vector, d is the iterative refined orientation field and &lt;math&gt;\Phi&lt;/math&gt; is the CS measurement matrix. This method undergoes a few iterations ultimately leading to convergence.&lt;math&gt;\hat{d}&lt;/math&gt; is the orientation field approximate estimation of the reconstructed image &lt;math&gt;X^{k-1}&lt;/math&gt; from the previous iteration (in order to check for convergence and the subsequent optical performance, the previous iteration is used). For the two vector fields represented by  &lt;math&gt;\Chi&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt;, &lt;math&gt;\Chi \bullet d&lt;/math&gt; refers to the multiplication of respective horizontal and vertical vector elements of &lt;math&gt;\Chi&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt; followed by their subsequent addition. These equations are reduced to a series of convex minimization problems which are then solved with a combination of variable splitting and augmented Lagrangian (FFT-based fast solver with a closed form solution) methods.&lt;ref name = "Orientation and directional refinement" /&gt; It (Augmented Lagrangian) is considered equivalent to the split Bregman iteration which ensures convergence of this method.  The orientation field, d is defined as being equal to &lt;math&gt;(d_{h}, d_{v})&lt;/math&gt;, where &lt;math&gt;d_{h},  d_{v}&lt;/math&gt; define the horizontal and vertical estimates of &lt;math&gt;d&lt;/math&gt;.

[[File:Augmented Lagrangian.png|thumb|right|Augmented Lagrangian method for orientation field and iterative directional field refinement models]]

The Augmented Lagrangian method for the orientation field,  &lt;math&gt;min_\Chi\lVert \nabla \Chi \bullet d \rVert _{1} + \frac{\lambda}{2}\ \lVert Y - \Phi\Chi \rVert ^2_{2}&lt;/math&gt;,  involves initializing &lt;math&gt;d_{h}, d_{v}, H, V&lt;/math&gt; and then finding the approximate minimizer of &lt;math&gt;L_{1}&lt;/math&gt; with respect to these variables.  The Lagrangian multipliers are then updated and the iterative process is stopped when convergence is achieved. For the iterative directional total variation refinement model, the augmented lagrangian method involves initializing &lt;math&gt;\Chi, P, Q, \lambda_{P}, \lambda_{Q}&lt;/math&gt;.&lt;ref name="TV"&gt;{{cite journal | last1 = Goldluecke | first1 = B. | last2 = Strekalovskiy | first2 = E. | last3 = Cremers | first3 = D. | last4 = Siims | first4 = P.-T. A. I. | year = 2012 | title = The natural vectorial total variation which arises from geometric measure theory | url = | journal = SIAM J. Imag Sci | volume = 5 | issue = 2| pages = 537–563 | doi=10.1137/110823766}}&lt;/ref&gt;

Here, &lt;math&gt;H, V, P, Q&lt;/math&gt; are newly introduced variables where &lt;math&gt;H&lt;/math&gt; = &lt;math&gt;\nabla d_{h}&lt;/math&gt;, &lt;math&gt;V&lt;/math&gt; = &lt;math&gt;\nabla d_{v}&lt;/math&gt;, &lt;math&gt;P&lt;/math&gt; = &lt;math&gt;\nabla \Chi&lt;/math&gt;, and &lt;math&gt;Q&lt;/math&gt; = &lt;math&gt;P \bullet d&lt;/math&gt;. &lt;math&gt;\lambda_{H}, \lambda_{V}, \lambda_{P}, \lambda_{Q}&lt;/math&gt; are the Lagrangian multipliers for &lt;math&gt;H, V, P, Q&lt;/math&gt;. For each iteration, the approximate minimizer of &lt;math&gt;L_{2}&lt;/math&gt; with respect to variables (&lt;math&gt;\Chi, P, Q&lt;/math&gt;) is calculated. And as in the field refinement model, the lagrangian multipliers are updated and the iterative process is stopped when convergence is achieved.

For the orientation field refinement model, the Lagrangian multipliers are updated in the iterative process as follows:

&lt;math&gt;(\lambda_{H})^k = (\lambda_{H})^{k-1} +  \gamma_{H}(H^k - \nabla (d_{h})^k)&lt;/math&gt;

&lt;math&gt;(\lambda_{V})^k = (\lambda_{V})^{k-1} +  \gamma_{V}(V^k - \nabla (d_{v})^k)&lt;/math&gt;

For the iterative directional total variation refinement model, the Lagrangian multipliers are updated as follows:

&lt;math&gt;(\lambda_{P})^k = (\lambda_{P})^{k-1} +  \gamma_{P}(P^k - \nabla (\Chi)^k)&lt;/math&gt;

&lt;math&gt;(\lambda_{Q})^k = (\lambda_{Q})^{k-1} +  \gamma_{Q}(Q^k - P^{k} \bullet d)&lt;/math&gt;

Here, &lt;math&gt;\gamma_{H}, \gamma_{V}, \gamma_{P}, \gamma_{Q}&lt;/math&gt; are positive constants.

=====Advantages and disadvantages=====

Based on Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) metrics and known ground-truth images for testing performance, it is concluded that iterative directional total variation has a better reconstructed performance than the non-iterative methods in preserving edge and texture areas. The orientation field refinement model plays a major role in this improvement in performance as it increases the number of directionless pixels in the flat area while enhancing the orientation field consistency in the regions with edges.

==Applications==
The field of compressive sensing is related to several topics in signal processing and computational mathematics, such as [[underdetermined system|underdetermined linear-system]]s, [[group testing]], heavy hitters, [[sparse coding]], [[multiplexing]], sparse sampling, and finite rate of innovation. Its broad scope and generality has enabled several innovative CS-enhanced approaches in signal processing and compression, solution of inverse problems, design of radiating systems, radar and through-the-wall imaging, and antenna characterization.&lt;ref&gt;{{Cite journal|author1=Andrea Massa |author2=Paolo Rocca |author3=Giacomo Oliveri |title = Compressive Sensing in Electromagnetics - A Review|journal = IEEE Antennas and Propagation Magazine|volume = 57|number = 1|year = 2015|pp = 224–238|doi = 10.1109/MAP.2015.2397092|url = http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7046378|bibcode=2015IAPM...57..224M}}&lt;/ref&gt;  Imaging techniques having a strong affinity with compressive sensing include [[coded aperture]] and [[computational photography]]. Implementations of compressive sensing in hardware at different [[technology readiness level]]s is available.&lt;ref&gt;Compressive Sensing Hardware, http://sites.google.com/site/igorcarron2/compressedsensinghardware&lt;/ref&gt;

Conventional CS reconstruction uses sparse signals (usually sampled at a rate less than the Nyquist sampling rate) for reconstruction through constrained &lt;math&gt;l_{1}&lt;/math&gt; minimization. One of the earliest applications of such an approach was in reflection seismology which used sparse reflected signals from band-limited data for tracking changes between sub-surface layers.&lt;ref name="Seismic sparse signals"&gt;Taylor, H.L., Banks, S.C., McCoy, J.F. "Deconvolution with the 1 norm. ''Geophysics'' 44(1), 39–52 (1979)&lt;/ref&gt;  When the LASSO model came into prominence in the 1990s as a statistical method for selection of sparse models,&lt;ref name="LASSO"&gt;Tibshirani, R. "Regression shrinkage and selection via the lasso. ''J. R. Stat. Soc. B'' 58(1), 267–288 (1996)&lt;/ref&gt; this method was further used in computational harmonic analysis for sparse signal representation from over-complete dictionaries. Some of the other applications include incoherent sampling of radar pulses. The work by ''Boyd et al.''&lt;ref name = "Original source for IRLS" /&gt; has applied the LASSO model- for selection of sparse models- towards analog to digital converters (the current ones use a sampling rate higher than the Nyquist rate along with the quantized Shannon representation). This would involve a parallel architecture in which the polarity of the analog signal changes at a high rate followed by digitizing the integral at the end of each time-interval to obtain the converted digital signal.

===Photography===
Compressed sensing is used in a mobile phone camera sensor. The approach allows a reduction in image acquisition energy per image by as much as a factor of 15 at the cost of complex decompression algorithms; the computation may require an off-device implementation.&lt;ref&gt;{{cite journal|title=New Camera Chip Captures Only What It Needs|author=David Schneider|journal=IEEE Spectrum|date=March 2013|url=http://spectrum.ieee.org/semiconductors/optoelectronics/camera-chip-makes-alreadycompressed-images|accessdate=2013-03-20}}&lt;/ref&gt;

Compressed sensing is used in single-pixel cameras from [[Rice University]].&lt;ref name=cscamera&gt;{{cite web |url=http://dsp.rice.edu/cscamera |archive-url=https://web.archive.org/web/20100605170550/http://dsp.rice.edu/cscamera |dead-url=yes |archive-date=2010-06-05 |title=Compressive Imaging: A New Single-Pixel Camera &amp;#124; Rice DSP |publisher=Dsp.rice.edu |date= |accessdate=2013-06-04 }}&lt;/ref&gt; [[Bell Labs]] employed the technique in a lensless single-pixel camera that takes stills using repeated snapshots of randomly chosen apertures from a grid. Image quality improves with the number of snapshots, and generally requires a small fraction of the data of conventional imaging, while eliminating lens/focus-related aberrations.&lt;ref&gt;{{cite web|author=The Physics arXiv Blog June 3, 2013 |url=http://www.technologyreview.com/view/515651/bell-labs-invents-lensless-camera/ |title=Bell Labs Invents Lensless Camera &amp;#124; MIT Technology Review |publisher=Technologyreview.com |date=2013-05-25 |accessdate=2013-06-04}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author1=Gang Huang|author2=Hong Jiang|author3=Kim Matthews|author4=Paul Wilford|title=Lensless Imaging by Compressive Sensing|year=2013|volume=2393|journal=IEEE International Conference on Image Processing, ICIP, Paper #|arxiv=1305.7181|bibcode=2013arXiv1305.7181H}}&lt;/ref&gt;

===Holography===
Compressed sensing can be used to improve image reconstruction in [[holography]] by increasing the number of [[voxel]]s one can infer from a single hologram.&lt;ref&gt;{{cite journal | last1 = Brady | first1 = David | last2 = Choi | first2 = Kerkil | last3 = Marks | first3 = Daniel | last4 = Horisaki | first4 = Ryoichi | last5 = Lim | first5 = Sehoon | year = 2009 | title = Compressive holography | url = | journal = Optics Express | volume = 17 | issue = | pages = 13040–13049 | doi=10.1364/oe.17.013040| bibcode = 2009OExpr..1713040B }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Rivenson | first1 = Y. | last2 = Stern | first2 = A. | last3 = Javidi | first3 = B. | year = 2010 | title = Compressive fresnel holography | url = | journal = Display Technology, Journal of | volume = 6 | issue = 10| pages = 506–509 | doi=10.1109/jdt.2010.2042276| bibcode = 2010JDisT...6..506R }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Denis | first1 = Loic | last2 = Lorenz | first2 = Dirk | last3 = Thibaut | first3 = Eric | last4 = Fournier | first4 = Corinne | last5 = Trede | first5 = Dennis | year = 2009 | title = Inline hologram reconstruction with sparsity constraints | url = | journal = Opt. Lett. | volume = 34 | issue = 22| pages = 3475–3477 | doi=10.1364/ol.34.003475| bibcode = 2009OptL...34.3475D }}&lt;/ref&gt; It is also used for image retrieval from undersampled measurements in optical &lt;ref&gt;{{cite journal | last1 = Marim | first1 = M. | last2 = Angelini | first2 = E. | last3 = Olivo-Marin | first3 = J. C. | last4 = Atlan | first4 = M. | year = 2011 | title = Off-axis compressed holographic microscopy in low-light conditions | arxiv = 1101.1735| journal = Optics Letters | volume = 36 | issue = 1| pages = 79–81 | doi=10.1364/ol.36.000079| bibcode = 2011OptL...36...79M }}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Marim | first1 = M. M. | last2 = Atlan | first2 = M. | last3 = Angelini | first3 = E. | last4 = Olivo-Marin | first4 = J. C. | year = 2010 | title = Compressed sensing with off-axis frequency-shifting holography | arxiv = 1004.5305| journal = Optics Letters | volume = 35 | issue = 6| pages = 871–873 | doi=10.1364/ol.35.000871| bibcode = 2010OptL...35..871M }}&lt;/ref&gt; and millimeter-wave &lt;ref&gt;{{cite journal | last1 = Fernandez Cull | first1 = Christy | last2 = Wikner | first2 = David A. | last3 = Mait | first3 = Joseph N. | last4 = Mattheiss | first4 = Michael | last5 = Brady | first5 = David J. | year = 2010 | title = Millimeter-wave compressive holography | url = | journal = Appl. Opt. | volume = 49 | issue = 19| pages = E67–E82 | doi=10.1364/ao.49.000e67| bibcode = 2010ApOpt..49E..67C }}&lt;/ref&gt; holography.

===Facial recognition===
Compressed sensing is being used in facial recognition applications.&lt;ref&gt;[https://www.wired.com/science/discoveries/news/2008/03/new_face_recognition Engineers Test Highly Accurate Face Recognition]&lt;/ref&gt;

===Magnetic resonance imaging===
Compressed sensing has been used &lt;ref name="dx.doi.org"&gt;Sparse MRI: The application of compressed sensing for rapid MR imaging; See Lustig, Michael and Donoho, David and Pauly, John M, Magnetic resonance in medicine, 58(6), 1182-1195 (2007)  {{DOI|10.1002/mrm.21391}}&lt;/ref&gt;&lt;ref name="Compressed Sensing MRI 2008"&gt;{{cite journal | last1 = Lustig | first1 = M. | last2 = Donoho | first2 = D.L. | last3 = Santos | first3 = J.M. | last4 = Pauly | first4 = J.M. | year = 2008 | title = Compressed Sensing MRI; | url = | journal = Signal Processing Magazine, IEEE | volume = 25 | issue = 2| pages = 72–82 | doi = 10.1109/MSP.2007.914728 | bibcode = 2008ISPM...25...72L }}&lt;/ref&gt;  to shorten [[magnetic resonance imaging]] scanning sessions on conventional hardware.&lt;ref&gt;{{cite web|author=Jordan EllenbergEmail Author |url=https://www.wired.com/magazine/2010/02/ff_algorithm/all/1 |title=Fill in the Blanks: Using Math to Turn Lo-Res Datasets Into Hi-Res Samples &amp;#124; Wired Magazine |publisher=Wired.com |date=2010-03-04 |accessdate=2013-06-04}}&lt;/ref&gt;&lt;ref&gt;[http://nuit-blanche.blogspot.com/2010/03/why-compressed-sensing-is-not-csi.html Why Compressed Sensing is NOT a CSI "Enhance" technology ... yet !]&lt;/ref&gt;&lt;ref&gt;[http://nuit-blanche.blogspot.com/2010/03/surely-you-must-be-joking-mr.html Surely You Must Be Joking Mr. Screenwriter]&lt;/ref&gt; Reconstruction methods include
* ISTA
* FISTA
* SISTA
* ePRESS &lt;ref&gt;{{cite journal|last1=Zhang|first1=Y.|last2=Peterson|first2=B.|title=Energy Preserved Sampling for Compressed Sensing MRI|journal=Computational and Mathematical Methods in Medicine|date=2014|volume=2014|doi=10.1155/2014/546814|url=http://www.hindawi.com/journals/cmmm/2014/546814|pages=1–12}}&lt;/ref&gt;
* EWISTA &lt;ref name=Zhang_2015&gt;{{cite journal|last1=Zhang|first1=Y.|title=Exponential Wavelet Iterative Shrinkage Thresholding Algorithm for Compressed Sensing Magnetic Resonance Imaging|journal=Information Sciences|date=2015|volume=322|pages=115–132|url=http://www.sciencedirect.com/science/article/pii/S0020025515004491|doi=10.1016/j.ins.2015.06.017}}&lt;/ref&gt;
* EWISTARS &lt;ref&gt;{{cite journal|last1=Zhang|first1=Y.|last2=Wang|first2=S.|title=Exponential Wavelet Iterative Shrinkage Thresholding Algorithm with Random Shift for Compressed Sensing Magnetic Resonance Imaging|journal=IEEJ Transactions on Electrical and Electronic Engineering|date=2015|volume=10|issue=1|pages=116–117|url=http://onlinelibrary.wiley.com/doi/10.1002/tee.22059/abstract|doi=10.1002/tee.22059}}&lt;/ref&gt; etc.

Compressed sensing addresses the issue of high scan time by enabling faster acquisition by measuring fewer Fourier coefficients. This produces a high-quality image with relatively lower scan time. Another application (also discussed ahead) is for CT reconstruction with fewer X-ray projections. Compressed sensing, in this case, removes the high spatial gradient parts - mainly, image noise and artifacts. This holds tremendous potential as one can obtain high-resolution CT images at low radiation doses (through lower current-mA settings).&lt;ref name="MRI"&gt;{{cite journal | last1 = Figueiredo | first1 = M. | last2 = Bioucas-Dias | first2 = J.M. | last3 = Nowak | first3 = R.D. | year = 2007 | title = Majorization–minimization algorithms for wavelet-based image restoration | url = | journal = IEEE Trans. Image Process | volume = 16 | issue = 12| pages = 2980–2991 | doi=10.1109/tip.2007.909318| bibcode = 2007ITIP...16.2980F }}&lt;/ref&gt;

===Network tomography===
Compressed sensing has showed outstanding results in the application of [[network tomography]] to [[network management]]. [[Network delay]] estimation and [[network congestion]] detection can both be modeled as underdetermined [[System of linear equations|systems of linear equations]] where the coefficient matrix is the network routing matrix. Moreover, in the [[Internet]], network routing matrices usually satisfy the criterion for using compressed sensing.&lt;ref&gt;[Network tomography via compressed sensing|http://www.ee.washington.edu/research/funlab/Publications/2010/CS-Tomo.pdf]&lt;/ref&gt;

===Shortwave-infrared cameras===
Commercial shortwave-infrared cameras based upon compressed sensing are available.&lt;ref&gt;{{cite web|title=InView web site|url=http://www.inviewcorp.com/products |website=inviewcorp.com}}&lt;/ref&gt; These cameras have light sensitivity from 0.9&amp;nbsp;[[µm]] to 1.7&amp;nbsp;µm, which are wavelengths invisible to the human eye.

===Aperture synthesis in radio astronomy===
In the field of [[radio astronomy]], compressed sensing has been proposed for deconvolving an interferometric image.&lt;ref&gt;[http://mnras.oxfordjournals.org/content/395/3/1733|Compressed sensing imaging techniques for radio interferometry]&lt;/ref&gt; In fact, the [[CLEAN (algorithm)|Högbom CLEAN algorithm]] that has been in use for the deconvolution of radio images since 1974, is similar to compressed sensing's matching pursuit algorithm.

===Transmission electron microscopy===
Compressed sensing combined with a moving aperture has been used to increase the acquisition rate of images in a [[transmission electron microscopy|transmission electron microscope]].&lt;ref&gt;{{cite journal|last1=Stevens|first1=Andrew|last2=Kovarik|first2=Libor|last3=Abellan|first3=Patricia|last4=Yuan|first4=Xin|last5=Carin|first5=Lawrence|last6=Browning|first6=Nigel D.|title=Applying compressive sensing to TEM video: a substantial frame rate increase on any camera|journal=Advanced Structural and Chemical Imaging|date=13 August 2015|volume=1|issue=1|doi=10.1186/s40679-015-0009-3}}&lt;/ref&gt; In [[Scanning transmission electron microscopy|scanning mode]], compressive sensing combined with random scanning of the electron beam has enabled both faster acquisition and less electron dose, which allows for imaging of electron beam sensitive materials.&lt;ref&gt;{{cite journal|last1=Kovarik|first1=L.|last2=Stevens|first2=A.|last3=Liyu|first3=A.|last4=Browning|first4=N. D.|title=Implementing an accurate and rapid sparse sampling approach for low-dose atomic resolution STEM imaging|journal=Applied Physics Letters|date=17 October 2016|volume=109|issue=16|pages=164102|doi=10.1063/1.4965720|bibcode=2016ApPhL.109p4102K}}&lt;/ref&gt;

==See also==
*[[Noiselet]]
*[[Sparse approximation]]
*[[Sparse coding]]
*[[Low-density parity-check code]]
*[[Compressed sensing in speech signals]]

==Notes==
{{reflist|group=note}}

==References==
{{reflist|30em}}

==Further reading==
* "The Fundamentals of Compressive Sensing" [http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zCdz10BfTRz0z0 Part 1], [http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zCgzXgcEKz0z0 Part 2] and [http://www.brainshark.com/brainshark/brainshark.net/portal/title.aspx?pid=zAvz9F41cz0z0 Part 3]: video tutorial by Mark Davenport, Georgia Tech. at [http://www.brainshark.com/sps SigView, the IEEE Signal Processing Society Tutorial Library].
* [https://www.wired.com/magazine/2010/02/ff_algorithm/all/1 Using Math to Turn Lo-Res Datasets Into Hi-Res Samples] Wired Magazine article
* [http://arquivo.pt/wayback/20160516193158/http://dsp.rice.edu/cs/ Compressive Sensing Resources] at [[Rice University]].
* [http://igorcarron.googlepages.com/cs Compressed Sensing: The Big Picture]
* [http://igorcarron.googlepages.com/compressedsensinghardware A list of different hardware implementation of Compressive Sensing]
* [http://compressedsensing.googlepages.com/home Compressed Sensing 2.0 ]
* [http://www.ams.org/happening-series/hap7-pixel.pdf Compressed Sensing Makes Every Pixel Count] – article in the AMS ''What's Happening in the Mathematical Sciences'' series
* [http://nuit-blanche.blogspot.com/search/label/CS Nuit Blanche] A blog on Compressive Sensing featuring the most recent information on the subject (preprints, presentations, Q/As)
* [http://igorcarron.googlepages.com/csvideos Online Talks focused on Compressive Sensing]
* [https://web.archive.org/web/20150504060355/http://ugcs.caltech.edu/~srbecker/wiki/Main_Page Wiki on sparse reconstruction]
* [https://stemblab.github.io/intuitive-cs/ Intuitive Compressive Sensing]

{{DEFAULTSORT:Compressed Sensing}}
[[Category:Information theory]]
[[Category:Signal estimation]]
[[Category:Linear algebra]]
[[Category:Mathematical optimization]]</text>
      <sha1>l74elb0cnwhfuvzmhhva4aqj1kx3ofz</sha1>
    </revision>
  </page>
  <page>
    <title>Computability theory</title>
    <ns>0</ns>
    <id>155414</id>
    <revision>
      <id>856992279</id>
      <parentid>831923390</parentid>
      <timestamp>2018-08-28T21:10:18Z</timestamp>
      <contributor>
        <username>InedibleHulk</username>
        <id>877242</id>
      </contributor>
      <minor/>
      <comment>/* Name of the subject */ What else would we be talking about here?</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="43492">{{For|the concept of computability|Computability}}

'''Computability theory''', also known as '''recursion theory''', is a branch of [[mathematical logic]], of [[computer science]], and of the [[theory of computation]] that originated in the 1930s with the study of [[computable function]]s and [[Turing degree]]s. The field has since expanded to include the study of generalized computability and definability. In these areas, recursion theory overlaps with [[proof theory]] and [[effective descriptive set theory]].

Basic questions addressed by recursion theory include:
* What does it mean for a function on the [[natural number]]s to be computable?
* How can noncomputable functions be classified into a hierarchy based on their level of noncomputability?

Although there is considerable overlap in terms of knowledge and methods, mathematical recursion theorists study the theory of relative computability, reducibility notions, and degree structures; those in the computer science field focus on the theory of [[Computational complexity theory|subrecursive hierarchies]], [[formal methods]], and [[formal language]]s.

==Computable and uncomputable sets==
Recursion theory originated in the 1930s, with work of [[Kurt Gödel]], [[Alonzo Church]], [[Rózsa Péter]], [[Alan Turing]], [[Stephen Kleene]], and [[Emil Post]].&lt;ref&gt;Many of these foundational papers are collected in ''The Undecidable'' (1965) edited by [[Martin Davis]].&lt;/ref&gt;&lt;ref&gt;{{cite web|last1=Soare|first1=Robert Irving|title=Computability Theory and Applications: The Art of Classical Computability|url=http://www.people.cs.uchicago.edu/~soare/Turing/frontice.pdf|website=Department of Mathematics|publisher=University of Chicago|accessdate=23 August 2017|date=22 December 2011}}&lt;/ref&gt;.

The fundamental results the researchers obtained established [[Computable function|Turing computability]] as the correct formalization of the informal idea of effective calculation. These results led [[Stephen Kleene]] (1952) to coin the two names "Church's thesis" (Kleene 1952:300) and "Turing's Thesis" (Kleene 1952:376). Nowadays these are often considered as a single hypothesis, the '''[[Church–Turing thesis]]''', which states that any function that is computable by an [[algorithm]] is a [[computable function]]. Although initially skeptical, by 1946 Gödel argued in favor of this thesis: 

:"Tarski has stressed in his lecture (and I think justly) the great importance of the concept of general recursiveness (or Turing's computability). It seems to me that this importance is largely due to the fact that with this concept one has for the first time succeeded in giving an absolute notion to an interesting epistemological notion, i.e., one not depending on the formalism chosen.*"(Gödel 1946 in Davis 1965:84).&lt;ref&gt;The full paper can also be found at pages 150ff (with commentary by Charles Parsons at 144ff) in Feferman et al. editors 1990 ''Kurt Gödel Volume II Publications 1938-1974'', Oxford University Press, New York, {{ISBN|978-0-19-514721-6}}. Both reprintings have the following footnote * added to the Davis volume by Gödel in 1965: "To be more precise: a function of integers is computable in any formal system containing arithmetic if and only if it is computable in arithmetic, where a function ''f'' is called computable in ''S'' if there is in ''S'' a computable term representing ''f'' (p. 150).&lt;/ref&gt;

With a definition of effective calculation came the first proofs that there are problems in mathematics that cannot be effectively [[Recursive set|decided]]. Church (1936a, 1936b) and Turing (1936), inspired by techniques used by Gödel (1931) to prove his incompleteness theorems, independently demonstrated that the [[Entscheidungsproblem]] is not effectively decidable. This result showed that there is no algorithmic procedure that can correctly decide whether arbitrary mathematical propositions are true or false.

Many problems in [[mathematics]] have been shown to be undecidable after these initial examples were established.  In 1947, Markov and Post published independent papers showing that the word problem for semigroups cannot be effectively decided. Extending this result, [[Pyotr Novikov]] and [[William Boone (mathematician)|William Boone]] showed independently in the 1950s that the [[word problem for groups]] is not effectively solvable: there is no effective procedure that, given a word in a finitely presented [[group (mathematics)|group]], will decide whether the element represented by the word is the [[identity element]] of the group. In 1970, [[Yuri Matiyasevich]] proved (using results of [[Julia Robinson]]) [[Matiyasevich's theorem]], which implies that [[Hilbert's tenth problem]] has no effective solution; this problem asked whether there is an effective procedure to decide whether a [[Diophantine equation]] over the integers has a solution in the integers. The [[list of undecidable problems]] gives additional examples of problems with no computable solution.

The study of which mathematical constructions can be effectively performed is sometimes called '''recursive mathematics'''; the ''Handbook of Recursive Mathematics'' (Ershov ''et al.'' 1998) covers many of the known results in this field.

==Turing computability==
The main form of computability studied in recursion theory was introduced by Turing (1936).  A set of natural numbers is said to be a ''[[computable set]]'' (also called a ''decidable'',  ''recursive'', or ''Turing computable'' set) if there is a [[Turing machine]] that, given a number ''n'', halts with output 1 if ''n'' is in the set and halts with output 0 if ''n'' is not in the set.   A function ''f'' from the natural numbers to themselves is a ''recursive'' or ''(Turing) [[computable function]]'' if there is a Turing machine that, on input ''n'', halts and returns output ''f''(''n''). The use of Turing machines here is not necessary; there are many other [[Model of computation|models of computation]] that have the same computing power as Turing machines; for example the [[mu-recursive function|μ-recursive functions]] obtained from primitive recursion and the μ operator.

The terminology for recursive functions and sets is not completely standardized. 
The definition in terms of μ-recursive functions as well as a different definition of ''rekursiv'' functions by Gödel led to the traditional name ''recursive'' for sets and functions computable by a Turing machine. The word ''decidable'' stems from the German word ''Entscheidungsproblem'' which was used in the original papers of Turing and others. In contemporary use, the term "computable function" has various definitions: according to Cutland (1980), it is a partial recursive function (which can be undefined for some inputs), while according to Soare (1987) it is a total recursive (equivalently, general recursive) function. This article follows the second of these conventions.  Soare (1996) gives additional comments about the terminology.

Not every set of natural numbers is computable. The [[halting problem]], which is the set of (descriptions of) Turing machines that halt on input 0, is a well-known example of a noncomputable set.  The existence of many noncomputable sets follows from the facts that there are only [[countable set|countably many]] Turing machines, and thus only countably many computable sets, but there are [[uncountable set|uncountably many]] sets of natural numbers.

Although the halting problem is not computable, it is possible to simulate program execution and produce an infinite list of the programs that do halt. Thus the halting problem is an example of a ''[[recursively enumerable set]]'', which is a set that can be enumerated by a Turing machine (other terms for recursively enumerable include ''computably enumerable'' and ''semidecidable''). Equivalently, a set is recursively enumerable if and only if it is the range of some computable function.  The recursively enumerable sets, although not decidable in general, have been studied in detail in recursion theory.

==Areas of research==
Beginning with the theory of recursive sets and functions described above, the field of recursion theory has grown to include the study of many closely related topics. These are not independent areas of research: each of these areas draws ideas and results from the others, and most recursion theorists are familiar with the majority of them.

===Relative computability and the Turing degrees===
{{Main|Turing reduction|Turing degree}}

Recursion theory in mathematical logic has traditionally focused on ''relative computability'', a generalization of Turing computability defined using [[oracle Turing machine]]s, introduced by Turing&amp;nbsp;(1939).  An oracle Turing machine is a hypothetical device which, in addition to performing the actions of a regular Turing machine, is able to ask questions of an ''oracle'', which is a particular set of natural numbers.  The oracle machine may only ask questions of the form "Is ''n'' in the oracle set?". Each question will be immediately answered correctly, even if the oracle set is not computable. Thus an oracle machine with a noncomputable oracle will be able to compute sets that a Turing machine without an oracle cannot.

Informally, a set of natural numbers ''A'' is ''[[Turing reduction|Turing reducible]]'' to a set ''B'' if there is an oracle machine that correctly tells whether numbers are in ''A'' when run with ''B'' as the oracle set (in this case, the set ''A'' is also said to be (''relatively'') ''computable from'' ''B'' and ''recursive in'' ''B'').  If a set ''A'' is Turing reducible to a set ''B'' and ''B'' is Turing reducible to ''A'' then the sets are said to have the same ''[[Turing degree]]'' (also called ''degree of unsolvability'').  The Turing degree of a set gives a precise measure of how uncomputable the set is.

The natural examples of sets that are not computable, including many different sets that encode variants of the [[halting problem]], have two properties in common:
#They are [[recursively enumerable]], and
#Each can be translated into any other via a [[many-one reduction]]. That is, given such sets ''A'' and ''B'', there is a total computable function ''f'' such that ''A'' = {''x'' : ''f''(''x'') ∈ ''B''}. These sets are said to be ''many-one equivalent'' (or ''m-equivalent'').

Many-one reductions are "stronger" than Turing reductions: if a set ''A'' is many-one reducible to a set ''B'', then ''A'' is Turing reducible to ''B'', but the converse does not always hold. Although the natural examples of noncomputable sets are all many-one equivalent, it is possible to construct recursively enumerable sets ''A'' and ''B'' such that ''A'' is Turing reducible to ''B'' but not many-one reducible to ''B''. It can be shown that every recursively enumerable set is many-one reducible to the halting problem, and thus the halting problem is the most complicated recursively enumerable set with respect to many-one reducibility and with respect to Turing reducibility. Post (1944) asked whether ''every'' recursively enumerable set is either computable or [[Turing degree#Turing equivalence|Turing equivalent]] to the halting problem, that is, whether there is no recursively enumerable set with a Turing degree intermediate between those two.

As intermediate results, Post defined natural types of recursively enumerable sets like the [[simple set|simple]], [[hypersimple set|hypersimple]] and hyperhypersimple sets. Post showed that these sets are strictly between the computable sets and the halting problem with respect to many-one reducibility. Post also showed that some of them are strictly intermediate under other reducibility notions stronger than Turing reducibility.  But Post left open the main problem of the existence of recursively enumerable sets of intermediate Turing degree; this problem became known as ''[[Post's problem]]''. After ten years, Kleene and Post showed in 1954 that there are intermediate Turing degrees between those of the computable sets and the halting problem, but they failed to show that any of these degrees contains a recursively enumerable set. Very soon after this, Friedberg and Muchnik independently solved Post's problem by establishing the existence of recursively enumerable sets of intermediate degree. This groundbreaking result opened a wide study of the Turing degrees of the recursively enumerable sets which turned out to possess a very complicated and non-trivial structure.

There are uncountably many sets that are not recursively enumerable, and the investigation of the Turing degrees of all sets is as central in recursion theory as the investigation of the recursively enumerable Turing degrees. Many degrees with special properties were constructed: ''hyperimmune-free degrees'' where every function computable relative to that degree is majorized by a (unrelativized) computable function; ''high degrees'' relative to which one can compute a function ''f'' which dominates every computable function ''g'' in the sense that there is a constant ''c'' depending on ''g'' such that ''g(x) &amp;lt; f(x)'' for all ''x &amp;gt; c''; ''random degrees'' containing [[Algorithmically random sequence|algorithmically random sets]]; ''1-generic'' degrees of 1-generic sets; and the degrees below the halting problem of [[Limiting recursive|limit-recursive]] sets.

The study of arbitrary (not necessarily recursively enumerable) Turing degrees involves the study of the Turing jump.  Given a set ''A'', the ''[[Turing jump]]'' of ''A'' is a set of natural numbers encoding a solution to the halting problem for oracle Turing machines running with oracle ''A''.  The Turing jump of any set is always of higher Turing degree than the original set, and a theorem of Friedburg shows that any set that computes the Halting problem can be obtained as the Turing jump of another set. [[Post's theorem]] establishes a close relationship between the Turing jump operation and the [[arithmetical hierarchy]], which is a classification of certain subsets of the natural numbers based on their definability in arithmetic.

Much recent research on Turing degrees has focused on the overall structure of the set of Turing degrees and the set of Turing degrees containing recursively enumerable sets.  A deep theorem of Shore and Slaman (1999) states that the function mapping a degree ''x'' to the degree of its Turing jump is definable in the partial order of the Turing degrees.  A recent survey by Ambos-Spies and Fejer (2006) gives an overview of this research and its historical progression.

===Other reducibilities===
{{Main|Reduction (recursion theory)}}

An ongoing area of research in recursion theory studies reducibility relations other than Turing reducibility. Post (1944) introduced several ''strong reducibilities'', so named because they imply truth-table reducibility. A Turing machine implementing a strong reducibility will compute a total function regardless of which oracle it is presented with.  ''Weak reducibilities'' are those where a reduction process may not terminate for all oracles; Turing reducibility is one example.

The strong reducibilities include:
;[[Many-one reduction|One-one reducibility]]: ''A'' is ''one-one reducible'' (or ''1-reducible'') to ''B'' if there is a total computable [[injective function]] ''f'' such that each ''n'' is in ''A'' if and only if ''f''(''n'') is in ''B''.
;[[Many-one reduction|Many-one reducibility]]: This is essentially one-one reducibility without the constraint that ''f'' be injective.  ''A'' is ''many-one reducible'' (or ''m-reducible'') to ''B'' if there is a total computable function ''f'' such that each ''n'' is in ''A'' if and only if ''f''(''n'') is in ''B''.
;[[Truth table reduction|Truth-table reducibility]]: ''A'' is truth-table reducible to ''B'' if ''A'' is Turing reducible to ''B'' via an oracle Turing machine that computes a total function regardless of the oracle it is given.  Because of compactness of [[Cantor space]], this is equivalent to saying that the reduction presents a single list of questions (depending only on the input) to the oracle simultaneously, and then having seen their answers is able to produce an output without asking additional questions regardless of the oracle's answer to the initial queries. Many variants of truth-table reducibility have also been studied.
Further reducibilities (positive, disjunctive, conjunctive, linear and their weak and bounded versions) are discussed in the article [[Reduction (recursion theory)]].

The major research on strong reducibilities has been to compare their theories, both for the class of all recursively enumerable sets as well as for the class of all subsets of the natural numbers. Furthermore, the relations between the reducibilities has been studied. For example, it is known that every Turing degree is either a truth-table degree or is the union of infinitely many truth-table degrees.

Reducibilities weaker than Turing reducibility (that is, reducibilities that are implied by Turing reducibility) have also been studied.  The most well known are [[arithmetical reducibility]] and [[hyperarithmetical reducibility]]. These reducibilities are closely connected to definability over the standard model of arithmetic.

===Rice's theorem and the arithmetical hierarchy===
Rice showed that for every nontrivial class ''C'' (which contains some but not all r.e. sets) the index set ''E'' = {''e'': the ''e''th r.e. set ''W&lt;sub&gt;e&lt;/sub&gt;'' is in ''C''} has the property that either the [[halting problem]] or its complement is many-one reducible to ''E'', that is, can be mapped using a [[many-one reduction]] to ''E'' (see [[Rice's theorem]] for more detail). But, many of these index sets are even more complicated than the halting problem. These type of sets can be classified using the [[arithmetical hierarchy]]. For example, the index set FIN of class of all finite sets is on the level Σ&lt;sub&gt;2&lt;/sub&gt;, the index set REC of the class of all recursive sets is on the level Σ&lt;sub&gt;3&lt;/sub&gt;, the index set COFIN of all cofinite sets is also on the level Σ&lt;sub&gt;3&lt;/sub&gt; and the index set COMP of the class of all Turing-complete sets Σ&lt;sub&gt;4&lt;/sub&gt;. These hierarchy levels are defined inductively, Σ&lt;sub&gt;''n''+1&lt;/sub&gt; contains just all sets which are recursively enumerable relative to Σ&lt;sub&gt;''n''&lt;/sub&gt;; Σ&lt;sub&gt;1&lt;/sub&gt; contains the recursively enumerable sets. The index sets given here are even complete for their levels, that is, all the sets in these levels can be many-one reduced to the given index sets.

===Reverse mathematics===
{{Main|Reverse mathematics}}

The program of ''[[reverse mathematics]]'' asks which set-existence axioms are necessary to prove particular theorems of mathematics in subsystems of [[second-order arithmetic]].  This study was initiated by [[Harvey Friedman]] and was studied in detail by [[Steve Simpson (mathematician)|Stephen Simpson]] and others; Simpson (1999) gives a detailed discussion of the program. The set-existence axioms in question correspond informally to axioms saying that the powerset of the natural numbers is closed under various reducibility notions. The weakest such axiom studied in reverse mathematics is ''recursive comprehension'', which states that the powerset of the naturals is closed under Turing reducibility.

===Numberings===
A numbering is an enumeration of functions; it has two parameters, ''e'' and ''x'' and outputs the value of the ''e''-th function in the numbering on the input ''x''. Numberings can be partial-recursive although some of its members are total recursive, that is, computable functions. [[Admissible numbering]]s are those into which all others can be translated. A [[Friedberg numbering]] (named after its discoverer) is a one-one numbering of all partial-recursive functions; it is necessarily not an admissible numbering. Later research dealt also with numberings of other classes like classes of recursively enumerable sets. Goncharov discovered for example a class of recursively enumerable sets for which the numberings fall into exactly two classes with respect to recursive isomorphisms.

===The priority method===
:''For further explanation, see the section ''[[Turing degree#Post's problem and the priority method|Post's problem and the priority method]]'' in the article ''[[Turing degree]].

Post's problem was solved with a method called the ''priority method''; a proof using this method is called a ''priority argument''.  This method is primarily used to construct recursively enumerable sets with particular properties. To use this method, the desired properties of the set to be constructed are broken up into an infinite list of goals, known as ''requirements'', so that satisfying all the requirements will cause the set constructed to have the desired properties.   Each requirement is assigned to a natural number representing the priority of the requirement; so 0 is assigned to the most important priority, 1 to the second most important, and so on.  The set is then constructed in stages, each stage attempting to satisfy one of more of the requirements by either adding numbers to the set or banning numbers from the set so that the final set will satisfy the requirement. It may happen that satisfying one requirement will cause another to become unsatisfied; the priority order is used to decide what to do in such an event.

Priority arguments have been employed to solve many problems in recursion theory, and have been classified into a hierarchy based on their complexity (Soare 1987). Because complex priority arguments can be technical and difficult to follow, it has 
traditionally been considered desirable to prove results without priority arguments, or to see if results proved with priority arguments can also be proved without them. 
For example, Kummer published a paper on a proof for the existence of Friedberg numberings without using the priority method.

===The lattice of recursively enumerable sets===
When Post defined the notion of a simple set as an r.e. set with an infinite complement not containing any infinite r.e. set, he started to study the structure of the recursively enumerable sets under inclusion. This lattice became a well-studied structure. Recursive sets can be defined in this structure by the basic result that a set is recursive if and only if the set and its complement are both recursively enumerable. Infinite r.e. sets have always infinite recursive subsets; but on the other hand, simple sets exist but do not have a coinfinite recursive superset. Post (1944) introduced already hypersimple and hyperhypersimple sets; later maximal sets were constructed which are r.e. sets such that every r.e. superset is either a finite variant of the given maximal set or is co-finite. Post's original motivation in the study of this lattice was to find a structural notion such that every set which satisfies this property is neither in the Turing degree of the recursive sets nor in the Turing degree of the halting problem. Post did not find such a property and the solution to his problem applied priority methods instead; Harrington and Soare (1991) found eventually such a property.

===Automorphism problems===
Another important question is the existence of automorphisms in recursion-theoretic structures. One of these structures is that one of recursively enumerable sets under inclusion modulo finite difference; in this structure, ''A'' is below ''B'' if and only if the set difference ''B''&amp;nbsp;&amp;minus;&amp;nbsp;''A'' is finite. [[Maximal set]]s (as defined in the previous paragraph) have the property that they cannot be automorphic to non-maximal sets, that is, if there is an automorphism of the recursive enumerable sets under the structure just mentioned, then every maximal set is mapped to another maximal set. Soare (1974) showed that also the converse holds, that is, every two maximal sets are automorphic. So the maximal sets form an orbit, that is, every automorphism preserves maximality and any two maximal sets are transformed into each other by some automorphism. Harrington gave a further example of an automorphic property: that of the creative sets, the sets which are many-one equivalent to the halting problem.

Besides the lattice of recursively enumerable sets, automorphisms are also studied for the structure of the Turing degrees of all sets as well as for the structure of the Turing degrees of r.e. sets. In both cases, Cooper claims to have constructed nontrivial automorphisms which map some degrees to other degrees; this construction has, however, not been verified and some colleagues believe that the construction contains errors and that the question of whether there is a nontrivial automorphism of the Turing degrees is still one of the main unsolved questions in this area (Slaman and Woodin 1986, Ambos-Spies and Fejer 2006).

===Kolmogorov complexity===
{{Main|Kolmogorov complexity}}

The field of [[Kolmogorov complexity]] and [[algorithmic randomness]] was developed during the 1960s and 1970s by Chaitin, Kolmogorov, Levin, Martin-Löf and Solomonoff (the names are given here in alphabetical order; much of the research was independent, and the unity of the concept of randomness was not understood at the time). The main idea is to consider a [[universal Turing machine]] ''U'' and to measure the complexity of a number (or string) ''x'' as the length of the shortest input ''p'' such that ''U''(''p'') outputs ''x''. This approach revolutionized earlier ways to determine when an infinite sequence (equivalently, characteristic function of a subset of the natural numbers) is random or not by invoking a notion of randomness for finite objects. Kolmogorov complexity became not only a subject of independent study but is also applied to other subjects as a tool for obtaining proofs.
There are still many open problems in this area. For that reason, a recent research conference in this area was held in January 2007&lt;ref&gt;[http://www-2.dc.uba.ar/logic2007/ Conference on Logic, Computability and Randomness], January 10–13, 2007.&lt;/ref&gt; and a list of open problems&lt;ref&gt;[http://www.cs.auckland.ac.nz/~nies/ The homepage] of Andre Nies has a list of open problems in Kolmogorov complexity&lt;/ref&gt; is maintained by Joseph Miller and Andre Nies.

===Frequency computation===
This branch of recursion theory analyzed the following question: For fixed ''m'' and ''n'' with 0&amp;nbsp;&amp;lt;&amp;nbsp;''m''&amp;nbsp;&amp;lt;&amp;nbsp;''n'', for which functions ''A'' is it possible to compute for any different ''n'' inputs ''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''x''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''x&lt;sub&gt;n&lt;/sub&gt;'' a tuple of ''n'' numbers ''y&lt;sub&gt;1&lt;/sub&gt;,y&lt;sub&gt;2&lt;/sub&gt;,...,y&lt;sub&gt;n&lt;/sub&gt;'' such that at least ''m'' of the equations ''A''(''x&lt;sub&gt;k&lt;/sub&gt;'') = ''y&lt;sub&gt;k&lt;/sub&gt;'' are true. Such sets are known as (''m'',&amp;nbsp;''n'')-recursive sets. The first major result in this branch of Recursion Theory is Trakhtenbrot's result that a set is computable if it is (''m'',&amp;nbsp;''n'')-recursive for some ''m'',&amp;nbsp;''n'' with 2''m''&amp;nbsp;&amp;gt;&amp;nbsp;''n''. On the other hand, Jockusch's [[semirecursive]] sets (which were already known informally before Jockusch introduced them 1968) are examples of a set which is (''m'',&amp;nbsp;''n'')-recursive if and only if 2''m''&amp;nbsp;&amp;lt;&amp;nbsp;''n''&amp;nbsp;+&amp;nbsp;1. There are uncountably many of these sets and also some recursively enumerable but noncomputable sets of this type. Later, Degtev established a hierarchy of recursively enumerable sets that are (1,&amp;nbsp;''n''&amp;nbsp;+&amp;nbsp;1)-recursive but not (1,&amp;nbsp;''n'')-recursive. After a long phase of research by Russian scientists, this subject became repopularized in the west by Beigel's thesis on bounded queries, which linked frequency computation to the above-mentioned bounded reducibilities and other related notions. One of the major results was Kummer's Cardinality Theory which states that a set ''A'' is computable if and only if there is an ''n'' such that some algorithm enumerates for each tuple of ''n'' different numbers up to ''n'' many possible choices of the cardinality of this set of ''n'' numbers intersected with ''A''; these choices must contain the true cardinality but leave out at least one false one.

===Inductive inference===
This is the recursion-theoretic branch of learning theory. It is based on Gold's model of learning in the limit from 1967 and has developed since then more and more models of learning. The general scenario is the following: Given a class ''S'' of computable functions, is there a learner (that is, recursive functional) which outputs for any input of the form (''f''(0),''f''(1),...,''f''(''n'')) a hypothesis. A learner ''M'' learns a function ''f'' if almost all hypotheses are the same index ''e'' of ''f'' with respect to a previously agreed on acceptable numbering of all computable functions; ''M'' learns ''S'' if ''M'' learns every ''f'' in ''S''. Basic results are that all recursively enumerable classes of functions are learnable while the class REC of all computable functions is not learnable. Many related models have been considered and also the learning of classes of recursively enumerable sets from positive data is a topic studied from Gold's pioneering paper in 1967 onwards.

===Generalizations of Turing computability===
Recursion theory includes the study of generalized notions of this field such as [[arithmetic reducibility]], [[hyperarithmetical reducibility]] and [[alpha recursion theory|α-recursion theory]], as described by Sacks (1990).  These generalized notions include reducibilities that cannot be executed by Turing machines but are nevertheless natural generalizations of Turing reducibility. These studies include approaches to investigate the [[analytical hierarchy]] which differs from the [[arithmetical hierarchy]] by permitting quantification over sets of natural numbers in addition to quantification over individual numbers. These areas are linked to the theories of well-orderings and trees; for example the set of all indices of recursive (nonbinary) trees without infinite branches is complete for level &lt;math&gt;\Pi^1_1&lt;/math&gt; of the analytical hierarchy. Both Turing reducibility and hyperarithmetical reducibility are important in the field of [[effective descriptive set theory]].  The even more general notion of [[Degree of constructibility|degrees of constructibility]] is studied in [[set theory]].

===Continuous computability theory===
Computability theory for digital computation is well developed. Computability theory is less well developed for [[analog computation]] that occurs in [[analog computer]]s, [[analog signal processing]], [[analog electronics]], [[neural networks]] and continuous-time [[control theory]], modelled by [[differential equation]]s and continuous [[dynamical system]]s (Orponen 1997; Moore 1996).

==Relationships between definability, proof and computability==
There are close relationships between the Turing degree of a set of natural numbers and the difficulty (in terms of the [[arithmetical hierarchy]]) of defining that set using a [[first-order logic|first-order formula]]. One such relationship is made precise by [[Post's theorem]]. A weaker relationship was demonstrated by [[Kurt Gödel]] in the proofs of his [[Gödel's completeness theorem|completeness theorem]] and [[Gödel's incompleteness theorem|incompleteness theorems]]. Gödel's proofs show that the set of logical consequences of an effective first-order theory is a [[recursively enumerable set]], and that if the theory is strong enough this set will be uncomputable.  Similarly, [[Tarski's indefinability theorem]] can be interpreted both in terms of definability and in terms of computability.

Recursion theory is also linked to [[second order arithmetic]], a formal theory of natural numbers and sets of natural numbers.  The fact that certain sets are computable or relatively computable often implies that these sets can be defined in weak subsystems of second order arithmetic.  The program of [[reverse mathematics]] uses these subsystems to measure the noncomputability inherent in well known mathematical theorems. Simpson&amp;nbsp;(1999) discusses many aspects of second-order arithmetic and reverse mathematics.

The field of [[proof theory]] includes the study of second-order arithmetic and [[Peano arithmetic]], as well as formal theories of the natural numbers weaker than Peano arithmetic.  One method of classifying the strength of these weak systems is by characterizing which computable functions the system can prove to be [[total function|total]] (see Fairtlough and Wainer (1998)).  For example, in [[primitive recursive arithmetic]] any computable function that is provably total is actually [[primitive recursive function|primitive recursive]], while [[Peano arithmetic]] proves that functions like the [[Ackermann function]], which are not primitive recursive, are total. Not every total computable function is provably total in Peano arithmetic, however; an example of such a function is provided by [[Goodstein's theorem]].

==Name==
The field of mathematical logic dealing with computability and its generalizations has been called "recursion theory" since its early days. [[Robert I. Soare]], a prominent researcher in the field, has proposed (Soare 1996) that the field should be called "computability theory" instead. He argues that Turing's terminology using the word "computable" is more natural and more widely understood than the terminology using the word "recursive" introduced by Kleene. Many contemporary researchers have begun to use this alternate terminology.&lt;ref&gt;[[Mathscinet]] searches for the titles like "computably enumerable" and "c.e." show that many papers have been published with this terminology as well as with the other one.&lt;/ref&gt; These researchers also use terminology such as ''partial computable function'' and ''computably enumerable ''(''c.e.'')'' set'' instead of ''partial recursive function'' and ''recursively enumerable ''(''r.e.'')'' set''. Not all researchers have been convinced, however, as explained by Fortnow&lt;ref&gt;Lance Fortnow, "[https://blog.computationalcomplexity.org/2004/02/is-it-recursive-computable-or.html Is it Recursive, Computable or Decidable?],"  2004-2-15, accessed 2018-3-22.&lt;/ref&gt; and Simpson.&lt;ref&gt;[[Steve Simpson (mathematician)|Stephen G. Simpson]], "[http://www.cs.nyu.edu/pipermail/fom/1998-August/001993.html What is computability theory?]," FOM email list, 1998-8-24, accessed 2006-1-9.&lt;/ref&gt;
Some commentators argue that both the names ''recursion theory'' and ''computability theory'' fail to convey the fact that most of the objects studied in recursion theory are not computable.&lt;ref&gt;Harvey Friedman, "[http://www.cs.nyu.edu/pipermail/fom/1998-August/002017.html Renaming recursion theory]," FOM email list, 1998-8-28, accessed 2006-1-9.&lt;/ref&gt;

Rogers (1967) has suggested that a key property of recursion theory is that its results and structures should be invariant under computable [[bijection]]s on the natural numbers (this suggestion draws on the ideas of the [[Erlangen program]] in geometry). The idea is that a computable bijection merely renames numbers in a set, rather than indicating any structure in the set, much as a rotation of the Euclidean plane does not change any geometric aspect of lines drawn on it. Since any two infinite computable sets are linked by a computable bijection, this proposal identifies all the infinite computable sets (the finite computable sets are viewed as trivial). According to Rogers, the sets of interest in recursion theory are the noncomputable sets, partitioned into equivalence classes by computable bijections of the natural numbers.

== Professional organizations ==
The main professional organization for recursion theory is the ''[[Association for Symbolic Logic]]'', which holds several research conferences each year. The interdisciplinary research Association  ''[[Computability in Europe]]'' (''CiE'') also organizes a series of annual conferences.

== See also ==
{{Portal|Logic}}
* [[Recursion (computer science)]]
* [[Computability logic]]
* [[Transcomputational problem]]

== Notes ==
{{Reflist}}

== References ==
; Undergraduate level texts
:* [[S. Barry Cooper|S. B. Cooper]], 2004. ''Computability Theory'', Chapman &amp; Hall/CRC. {{ISBN|1-58488-237-9}}
:* N. Cutland, 1980. ''Computability, An introduction to recursive function theory'', Cambridge University Press. {{ISBN|0-521-29465-7}}
:* [[Yuri Matiyasevich|Y. Matiyasevich]], 1993. ''Hilbert's Tenth Problem'', MIT Press. {{ISBN|0-262-13295-8}}

; Advanced texts
:* S. Jain, D. Osherson, J. Royer and A. Sharma, 1999. ''Systems that learn, an introduction to learning theory, second edition'', Bradford Book. {{ISBN|0-262-10077-0}}
:* [[Stephen Kleene|S. Kleene]], 1952. ''Introduction to Metamathematics'', North-Holland (11th printing; 6th printing added comments). {{ISBN|0-7204-2103-9}}
:* M. Lerman, 1983. ''Degrees of unsolvability'', Perspectives in Mathematical Logic, Springer-Verlag. {{ISBN|3-540-12155-2}}.
:* Andre Nies, 2009. ''Computability and Randomness'', Oxford University Press, 447 pages. {{ISBN|978-0-19-923076-1}}.
:* [[Piergiorgio Odifreddi|P. Odifreddi]], 1989. ''Classical Recursion Theory'', North-Holland. {{ISBN|0-444-87295-7}}
:* P. Odifreddi, 1999. ''Classical Recursion Theory, Volume II'', Elsevier. {{ISBN|0-444-50205-X}}
:* [[Hartley Rogers, Jr.|H. Rogers, Jr.]], 1967. ''The Theory of Recursive Functions and Effective Computability'', second edition 1987, MIT Press. {{ISBN|0-262-68052-1}} (paperback), {{ISBN|0-07-053522-1}}
:* G Sacks, 1990.  ''Higher Recursion Theory'', Springer-Verlag. {{ISBN|3-540-19305-7}}
:* [[Steve Simpson (mathematician)|S. G. Simpson]], 1999. ''Subsystems of Second Order Arithmetic'', Springer-Verlag. {{ISBN|3-540-64882-8}}
:* R. I. Soare, 1987. ''Recursively Enumerable Sets and Degrees'', Perspectives in Mathematical Logic, Springer-Verlag. {{ISBN|0-387-15299-7}}.

; Survey papers and collections
:* K. Ambos-Spies and P. Fejer, 2006. "[http://www.cs.umb.edu/~fejer/articles/History_of_Degrees.pdf Degrees of Unsolvability]." Unpublished preprint.
:* H. Enderton, 1977.  "Elements of Recursion Theory." ''Handbook of Mathematical Logic'', edited by  [[Jon Barwise|J. Barwise]], North-Holland (1977),  pp.&amp;nbsp;527–566. {{ISBN|0-7204-2285-X}}
:* Y. L. Ershov, S. S. Goncharov, A. Nerode, and J. B. Remmel, 1998. ''Handbook of Recursive Mathematics'', North-Holland (1998). {{ISBN|0-7204-2285-X}}
:* M. Fairtlough and S. Wainer, 1998. "Hierarchies of Provably Recursive Functions". In ''Handbook of Proof Theory'', edited by S. Buss, Elsevier (1998).
:* R. I. Soare, 1996. ''Computability and recursion,'' ''Bulletin of Symbolic Logic'' v. 2 pp.&amp;nbsp;284–321.

; Research papers and collections
:* Burgin, M. and Klinger, A. "Experience, Generations, and Limits in Machine Learning." ''Theoretical Computer Science'' v. 317, No. 1/3, 2004, pp.&amp;nbsp;71–91
:* A. Church, 1936a. "An unsolvable problem of elementary number theory." ''American Journal of Mathematics'' v. 58, pp.&amp;nbsp;345–363.  Reprinted in "The Undecidable", M. Davis ed., 1965.
:* A. Church, 1936b. "A note on the Entscheidungsproblem." ''Journal of Symbolic Logic'' v. 1, n. 1, and v. 3, n. 3. Reprinted in "The Undecidable", M. Davis ed., 1965.
:* M. Davis, ed., 1965.  ''The Undecidable—Basic Papers on Undecidable Propositions, Unsolvable Problems and Computable Functions'', Raven, New York. Reprint, Dover, 2004. {{ISBN|0-486-43228-9}}
:* R. M. Friedberg, 1958. "Three theorems on recursive enumeration: I. Decomposition, II. Maximal Set, III. Enumeration without repetition." ''The Journal of Symbolic Logic'', v. 23, pp.&amp;nbsp;309–316.
:* {{Citation
  | last=Gold | first=E. Mark
  | title=Language Identification in the Limit
  | volume=10
  | pages=447–474
  | url=http://web.mit.edu/~6.863/www/spring2009/readings/gold67limit.pdf
  | publisher=[[Information and Control]] | year=1967}} [https://web.archive.org/web/20090125120159/http://www.isrl.uiuc.edu/~amag/langev/paper/gold67limit.html]
:* L. Harrington and R. I. Soare, 1991. "Post's Program and incomplete recursively enumerable sets", ''Proceedings of the National Academy of Sciences of the USA'', volume 88, pages 10242—10246.
:* C. Jockusch jr, "Semirecursive sets and positive reducibility", ''[[Trans. Amer. Math. Soc.]]'' '''137''' (1968) 420-436
:* S. C. Kleene and E. L. Post, 1954. "The upper semi-lattice of degrees of recursive unsolvability." ''Annals of Mathematics'' v. 2 n. 59, 379–407.
:*{{cite journal | title = Recursion theory on the reals and continuous-time computation | citeseerx = 10.1.1.6.5519 | authorlink = Cris Moore | first = C. | last = Moore | journal = Theoretical Computer Science | year = 1996 | doi = 10.1016/0304-3975(95)00248-0 }}
:* J. Myhill, 1956. "The lattice of recursively enumerable sets." ''The Journal of Symbolic Logic'', v. 21, pp.&amp;nbsp;215–220.
:* {{cite journal | title = A survey of continuous-time computation theory | citeseerx = 10.1.1.53.1991 | first = P. | last = Orponen | journal = Advances in algorithms, languages, and complexity | year = 1997 }}
:* E. Post, 1944, "Recursively enumerable sets of positive integers and their decision problems", ''Bulletin of the American Mathematical Society'', volume 50, pages 284–316.
:* E. Post, 1947. "Recursive unsolvability of a problem of Thue." ''Journal of Symbolic Logic '' v. 12, pp.&amp;nbsp;1–11. Reprinted in "The Undecidable", M. Davis ed., 1965.
:* {{Citation | last1=Shore | first1=Richard A. | last2=Slaman | first2=Theodore A. | author2-link=Theodore Slaman |title=Defining the Turing jump |url=http://www.math.cornell.edu/~shore/papers/pdf/jumpmrl.pdf | mr=1739227 | year=1999 | journal=[[Mathematical Research Letters]] | issn=1073-2780 | volume=6 | pages=711–722 | doi=10.4310/mrl.1999.v6.n6.a10}}
:* T. Slaman and W. H. Woodin, 1986. "[http://citeseer.ist.psu.edu/cache/papers/cs/11492/http:zSzzSzwww.math.berkeley.eduzSz~slamanzSzpaperszSzslaman-woodin.pdf/slaman86definability.pdf Definability in the Turing degrees]." ''Illinois J. Math.'' v. 30 n. 2, pp.&amp;nbsp;320–334.
:* R. I. Soare, 1974. "Automorphisms of the lattice of recursively enumerable sets, Part I: Maximal sets." ''Annals of Mathematics'', v. 100, pp.&amp;nbsp;80–120.
:* A. Turing, 1937. "On computable numbers, with an application to the Entscheidungsproblem." ''Proceedings of the London Mathematics Society'', ser. 2 v. 42, pp.&amp;nbsp;230–265.  Corrections ''ibid.'' v. 43 (1937) pp.&amp;nbsp;544–546.  Reprinted in "The Undecidable", M. Davis ed., 1965. [http://web.comlab.ox.ac.uk/oucl/research/areas/ieg/e-library/sources/tp2-ie.pdf PDF from comlab.ox.ac.uk]
:* A. Turing, 1939. "Systems of logic based on ordinals." ''Proceedings of the London Mathematics Society'', ser. 2 v. 45, pp.&amp;nbsp;161–228. Reprinted in "The Undecidable", M. Davis ed., 1965.

== External links ==
* [http://www.aslonline.org/ Association for Symbolic Logic homepage]
* [http://www.maths.leeds.ac.uk/cie/ Computability in Europe homepage]
* [http://www.comp.nus.edu.sg/~fstephan/recursiontheory.html Webpage on Recursion Theory Course at Graduate Level with approximately 100 pages of lecture notes]
* [http://www.comp.nus.edu.sg/~fstephan/learning.ps German language lecture notes on inductive inference]

{{Computer science}}
{{Mathematical logic}}

[[Category:Computability theory| ]]
[[Category:Mathematical logic| C]]</text>
      <sha1>beg6rk95lqgrylsp12uok0juss7czrw</sha1>
    </revision>
  </page>
  <page>
    <title>Crispin Wright</title>
    <ns>0</ns>
    <id>302883</id>
    <revision>
      <id>867527885</id>
      <parentid>862341677</parentid>
      <timestamp>2018-11-06T08:27:15Z</timestamp>
      <contributor>
        <username>TopologischerIdealismus</username>
        <id>31090224</id>
      </contributor>
      <comment>/* Philosophical work */ removed misleading link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9464">{{Use dmy dates|date=July 2015}}
{{Use British English|date=July 2015}}
{{more footnotes|date=July 2013|BLP=yes}}
{{Infobox philosopher
|region          = [[Western philosophy]]
|era             = [[20th-century philosophy]]
|image           =
|name             = Crispin Wright
|birth_date       = 21 December 1942
|birth_place      = [[Surrey]], England
|alma_mater       = [[Trinity College, Cambridge]]
|institutions     = [[All Souls College, Oxford]]
|school_tradition = [[Analytic philosophy|Analytic]]&lt;br/&gt;[[Neo-logicism]] ([[Scottish School (philosophy of mathematics)|Scottish School]])&lt;ref&gt;[http://www.st-andrews.ac.uk/~mr30/papers/EbertRossbergPurpose.pdf st-andrews.ac.uk] {{webarchive|url=https://web.archive.org/web/20061224165534/http://www.st-andrews.ac.uk/~mr30/papers/EbertRossbergPurpose.pdf |date=2006-12-24 }}&lt;/ref&gt;
|main_interests   = [[Philosophy of mind]]&lt;br/&gt;[[Philosophy of language]]&lt;br/&gt;[[Philosophy of mathematics]]&lt;br/&gt;[[Gottlob Frege|Frege]]{{·}} [[Ludwig Wittgenstein|Wittgenstein]]&lt;br/&gt;[[Epistemology]]
|notable_ideas    = [[Rule-following]] considerations&lt;ref&gt;C. Wright (1989), "Wittgenstein's Rule-following Considerations and the Central Project of Theoretical Linguistics", in ''Reflections on Chomsky'', ed. A. George, Oxford and New York: Basil Blackwell; reprinted in C. Wright (2001), ''Rails to Infinity'', Cambridge, Mass., Harvard.&lt;/ref&gt;&lt;br/&gt;[[Neo-logicism]]&lt;br/&gt;Truth pluralism&lt;ref&gt;[https://plato.stanford.edu/entries/truth-pluralist/ Pluralist Theories of Truth (Stanford Encyclopedia of Philosophy)]&lt;/ref&gt;&lt;br/&gt;Epistemic entitlement&lt;ref&gt;[http://www.iep.utm.edu/ep-en/ Epistemic Entitlement – Internet Encyclopedia of Philosophy]&lt;/ref&gt;&lt;br/&gt;[[Superassertibility]]&lt;br/&gt;[[Semantic anti-realism (epistemology)|Anti-realist semantics]] for [[empirical language]]&lt;ref&gt;[http://www.iep.utm.edu/d/dummett.htm  Dummett, Michael – Internet Encyclopedia of Philosophy]&lt;/ref&gt;
|influences       = [[Ludwig Wittgenstein]], [[Gottlob Frege]], [[Michael Dummett]], [[Noam Chomsky]]
|influenced       = [[Paul Boghossian]], [[Carrie Ichikawa Jenkins]], [[Michael Lynch (philosopher)|Michael Lynch]], [[Duncan Pritchard]], [[Jose Zalabardo]]
}}
'''Crispin James Garth Wright''' ({{IPAc-en|r|aɪ|t}}; born 21 December 1942) is a [[United Kingdom|British]] philosopher, who has written on [[Neo-logicism|neo-Fregean]] (neo-logicist) [[philosophy of mathematics]], [[Wittgenstein]]'s later [[philosophy]], and on issues related to [[truth]], [[Philosophical realism|realism]], [[Cognitivism (ethics)|cognitivism]], [[skepticism]], [[knowledge]], and [[Objectivity (philosophy)|objectivity]].  He is Professor of Philosophy at [[New York University]] and Professor of Philosophical Research at the [[University of Stirling]], and taught previously at the [[University of St Andrews]], [[University of Aberdeen]], [[Princeton University]] and [[University of Michigan]].&lt;ref&gt;http://philosophy.fas.nyu.edu/object/crispinwright&lt;/ref&gt; 

==Life and career==
{{BLP unsourced section|date=July 2018}}
He was born in Surrey and was educated at [[Birkenhead School]] (1950–61) and at [[Trinity College, Cambridge]], graduating in Moral Sciences in 1964 and taking a PhD in 1968. He took an Oxford BPhil in 1969 and was elected Prize Fellow and then Research Fellow at [[All Souls College, Oxford]], where he worked until 1978. He then moved to the [[University of St. Andrews]], where he was appointed Professor of Logic and Metaphysics and then the first Bishop Wardlaw University
Professorship in 1997. As of fall 2008, he is professor at [[New York University]] (NYU).  He has also taught at the [[University of Michigan]], [[Oxford University]], [[Columbia University]], and [[Princeton University]]. Crispin Wright is founder and director of Arché at the University of St. Andrews, which he left in September 2009 to take up leadership of the new Northern Institute of Philosophy (NIP) at the [[University of Aberdeen]].

==Philosophical work&lt;!--'Superassertibility' redirects here--&gt;==
{{BLP unsourced section|date=July 2018}}
In the philosophy of mathematics, he is best known for his book ''Frege's Conception of Numbers as Objects'' (1983), where he argues that Frege's [[logicism|logicist]] project could be revived by removing the [[axiom schema of unrestricted comprehension]] (sometimes referred to as [[Basic Law V]]) from the [[formal system]].  [[Arithmetic]] is then derivable in [[second-order logic]] from [[Hume's principle]].  He gives informal [[argument]]s that (i) [[David Hume|Hume]]'s [[principle]] plus second-order logic is [[consistency|consistent]], and (ii) from it one can produce the [[Peano axioms|Dedekind–Peano axioms]].  Both results were [[proof (mathematics)|proven]] informally by Gottlob Frege ([[Frege's Theorem]]), and would later be more rigorously proven by [[George Boolos]] and Richard Heck. Wright is one of the major proponents of [[neo-logicism]], alongside his frequent collaborator [[Bob Hale (philosopher)|Bob Hale]]. He has also written ''Wittgenstein and the Foundations of Mathematics'' (1980).

In general metaphysics, his most important work is ''Truth and Objectivity'' (Harvard University Press, 1992). He argues in this book that there need be no single, discourse-invariant thing in which [[truth]] consists, making an analogy with [[identity (social science)|identity]]. There need only be some [[principle]]s regarding how the truth [[Predicate (grammar)|predicate]] can be applied to a [[Sentence (linguistics)|sentence]], some 'platitudes' about true sentences. Wright also argues that in some contexts, probably including [[morality|moral]] contexts, '''superassertibility'''&lt;!--boldface per WP:R#PLA--&gt; will effectively function as a truth predicate. He [[stipulative definition|defines]] a predicate as superassertible if and only if it is "assertible" in some state of information and then remains so no matter how that state of information is enlarged upon or improved. Assertiveness is [[Theory of justification|warrant]] by whatever standards inform the [[discourse]] in question.

Many of his most important papers in philosophy of language, epistemology, philosophical logic, meta-ethics, and the interpretation of Wittgenstein have been collected in two volumes published by [[Harvard University Press]].

== Awards ==
* Fellow of the [[American Academy of Arts and Sciences]], 2012&lt;ref&gt;https://www.amacad.org/news/alphalist2012.pdf&lt;/ref&gt;
* [[Leverhulme Trust]] Personal Research Professor, 1998–2003
* FRSE: [[Fellow of the Royal Society of Edinburgh]], 1996
* FBA: [[Fellow of the British Academy]], 1992&lt;ref&gt;http://www.britac.ac.uk/users/professor-crispin-wright&lt;/ref&gt;
* [[British Academy]] Research Reader, 1990-2
* [[Fulbright scholar]]  at [[Princeton University]], 1985-6
* Prize Fellow, [[All Souls College]], [[Oxford]], 1969–71

==Books==
*''Wittgenstein on the Foundations of Mathematics'' (Harvard University Press, 1980)
*''Frege's Conception of Numbers as Objects'' (Humanities Press 1983) 
*''Truth and Objectivity'' (Harvard University Press, 1992)
*''Realism, Meaning, and Truth,'' 2nd edition (Blackwell 1993)
*''The Reason's Proper Study'' (co-authored with [[Bob Hale (philosopher)|Bob Hale]]) (Oxford University Press, 2001)
*''Rails to Infinity'' (Harvard University Press, 2001)
*''Saving the Differences'' (Harvard University Press, 2003).

==References==
{{Reflist}}

==External links==
* {{cite web |url=http://as.nyu.edu/object/crispinwright.html |title=NYU Arts &amp; Science: Crispin Wright |deadurl=yes |archiveurl=https://web.archive.org/web/20160128133346/http://as.nyu.edu/object/crispinwright.html |archivedate=28 January 2016 |df=dmy-all }}
* {{cite web|url=http://www.abdn.ac.uk/nip/members/member?id=wright|title=Northern Institute of Philosophy: Crispin Wright|publisher=University of Aberdeen|deadurl=yes|archiveurl=https://web.archive.org/web/20131202233058/http://www.abdn.ac.uk/nip/members/member?id=wright|archivedate=2 December 2013|df=dmy-all}}
* {{cite web |url=http://thephilosopherseye.com/2012/12/04/philosophers-on-film-crispin-wright/ |title=Philosophers on Film: Crispin Wright|publisher=The Philosopher's Eye|date=4 December 2012}}
* {{cite web |url=http://ndpr.nd.edu/news/41036-mind-meaning-and-knowledge-themes-from-the-philosophy-of-crispin-wright/ |title=Mind, Meaning, and Knowledge: Themes from the Philosophy of Crispin Wright |first=Annalisa |last=Coliva |date=8 July 2013 |publisher=University of Notre Dame}}
* {{cite web |url=http://philpapers.org/s/Crispin%20Wright|title=Works by Crispin Wright|publisher=PhilPapers}}
* {{cite web|url=http://www.st-andrews.ac.uk/arche/old/pages/papers/Wright%20Liars%20and%20Heaps.pdf|first=Crispin |last=Wright|title=VAGUENESS: A FIFTH COLUMN APPROACH}}

{{Authority control}}

{{DEFAULTSORT:Wright, Crispin}}
[[Category:Fulbright Scholars]]
[[Category:1942 births]]
[[Category:Living people]]
[[Category:20th-century philosophers]]
[[Category:Analytic philosophers]]
[[Category:British philosophers]]
[[Category:Philosophers of mathematics]]
[[Category:Epistemologists]]
[[Category:21st-century philosophers]]
[[Category:Fellows of the British Academy]]
[[Category:Philosophers of language]]
[[Category:Academics of the University of St Andrews]]
[[Category:Fellows of the Royal Society of Edinburgh]]
[[Category:People educated at Birkenhead School]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:University of Michigan faculty]]</text>
      <sha1>nxnkp70xr7trlgqvggat6ni51e2p9ra</sha1>
    </revision>
  </page>
  <page>
    <title>Dimension (graph theory)</title>
    <ns>0</ns>
    <id>39179243</id>
    <revision>
      <id>855184409</id>
      <parentid>855182946</parentid>
      <timestamp>2018-08-16T14:18:46Z</timestamp>
      <contributor>
        <ip>178.157.248.174</ip>
      </contributor>
      <comment>Added a reference to a proof of dimensionality of complete graphs from an unpublished paper by Ryan Kavangh, who according to his website is a PhD from Carnegie Mellon University.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9059">[[File:Petersen graph, unit distance.svg|thumb|170px|The dimension of the [[Petersen graph]] is 2.]]
In [[mathematics]], and particularly in [[graph theory]], the '''dimension of a graph''' is the least integer {{mvar|n}} such that there exists a "classical representation" of the graph in the [[Euclidean space]] of dimension {{mvar|n}} with all the edges having unit length.

In a classical representation, the vertices must be distinct points, but the edges may cross one another.&lt;ref&gt;Some mathematicians regard this strictly as an "[[Immersion (mathematics)|immersion]]", but many graph theorists, including Erdős, Harary and Tutte, use the term "[[embedding]]".&lt;/ref&gt;

The dimension of a graph {{mvar|G}} is written: &lt;math&gt;\dim G&lt;/math&gt;.

For example, the [[Petersen graph]] can be drawn with unit edges in &lt;math&gt;E^2&lt;/math&gt;, but not in &lt;math&gt;E^1&lt;/math&gt;: its dimension is therefore 2 (see the figure to the right).

This concept was introduced in 1965 by [[Paul Erdős]], [[Frank Harary]] and [[William Tutte]].&lt;ref&gt;{{Cite journal | last1=Erdős | first1=P. | last2=Harary | first2=F. | last3=Tutte | first3=W. T.| title=On the dimension of a graph | url=http://www.renyi.hu/~p_erdos/1965-09.pdf | journal=Mathematika | volume=12 | year=1965 | pages=118–122 | doi=10.1112/s0025579300005222}}&lt;/ref&gt; It generalises the concept of [[unit distance graph]] to more than 2 dimensions.

== Examples ==
[[File:Tetrahedron.svg|thumb|170px|With 4 equally spaced points, we need 3 dimensions.]]

=== Complete graph ===
In the worst case, every pair of vertices is connected, giving a [[complete graph]].

To [[Immersion (mathematics)|immerse]] the complete graph &lt;math&gt;K_n&lt;/math&gt; with all the edges having unit length, we need the Euclidean space of dimension &lt;math&gt;n-1&lt;/math&gt;.&lt;ref&gt;{{Cite web|url=https://rak.ac/files/papers/graph.pdf|title=Explorations on the dimensionality of graphs|last=Kavangh|first=Ryan|date=|website=|archive-url=|archive-date=|dead-url=|access-date=August 16, 2018}}&lt;/ref&gt; For example, it takes two dimensions to immerse &lt;math&gt;K_3&lt;/math&gt; (an equilateral triangle), and three to immerse &lt;math&gt;K_4&lt;/math&gt; (a regular tetrahedron) as shown to the right.
:&lt;math&gt;\dim K_n = n-1&lt;/math&gt;

In other words, the dimension of the complete graph is the same as that of the [[simplex]] having the same number of vertices.

[[File:CompleteBipartite3D.svg|thumb|170px|The complete bipartite graph &lt;math&gt;K_{4,2}&lt;/math&gt; drawn in Euclidean 3-space.]]

=== Complete bipartite graphs ===
[[File:Intercpunetstar.png|thumb|170px|left|A [[Star (graph theory)|star graph]] drawn in the plane with edges of unit length.]]
All [[Star (graph theory)|star graphs]] &lt;math&gt;K_{m,1}&lt;/math&gt;, for &lt;math&gt;m \ge 3&lt;/math&gt;, have dimension 2, as shown in the figure to the left. Star graphs with {{mvar|m}} equal to 1 or 2 need only dimension 1.

The dimension of a [[complete bipartite graph]] &lt;math&gt;K_{m,2}&lt;/math&gt;, for &lt;math&gt;m \ge 3&lt;/math&gt;, can be drawn as in the figure to the right, by placing {{mvar|m}} vertices on a circle whose radius is less than a unit, and the other two vertices one each side of the plane of the circle, at a suitable distance from it. &lt;math&gt;K_{2,2}&lt;/math&gt; has dimension 2, as it can be drawn as a unit rhombus in the plane.
{|
|{{math_theorem 
|The dimension of a general complete bipartite graph &lt;math&gt;K_{m,n}&lt;/math&gt;, for &lt;math&gt;m \ge 3&lt;/math&gt; and &lt;math&gt;n \ge 3&lt;/math&gt;, is 4.
}}
{{hidden begin|style=border:solid 1px #aaa|toggle=left|title=Proof}}
To show that 4-space is sufficient, as with the previous case, we use circles.

Denoting the coordinates of the 4-space by &lt;math&gt;w, x, y, z&lt;/math&gt;, we arrange one set of vertices arbitrarily on the circle given by &lt;math&gt;w^2+x^2=a, y=0, z=0&lt;/math&gt; where &lt;math&gt;0 &lt; a &lt; 1&lt;/math&gt;, and the other set arbitrarily on the circle &lt;math&gt;y^2+z^2=1-a, w=0, x=0&lt;/math&gt;. Then we see that the distance between any vertex in one set and any vertex in the other set is &lt;math&gt;{\sqrt{w^2+x^2+y^2+z^2}} = {\sqrt{a+1-a}} = 1&lt;/math&gt;.

We can also show that the subgraph &lt;math&gt;K_{3,3}&lt;/math&gt; does not admit such a representation in a space of dimension less than 3:

If such a representation exists, then the three points &lt;math&gt;A_1&lt;/math&gt;, &lt;math&gt;A_2&lt;/math&gt; and &lt;math&gt;A_3&lt;/math&gt; lie on a unit sphere with center &lt;math&gt;B_1&lt;/math&gt;. Likewise, they lie on unit spheres with centers &lt;math&gt;B_2&lt;/math&gt; and &lt;math&gt;B_3&lt;/math&gt;. The first two spheres must intersect in a circle, in a point, or not at all; to accommodate the three distinct points &lt;math&gt;A_1&lt;/math&gt;, &lt;math&gt;A_2&lt;/math&gt; and &lt;math&gt;A_3&lt;/math&gt;, we must assume a circle. Either this circle lies entirely on the third unit sphere, implying that the third sphere coincides with one of the other two, so &lt;math&gt;B_1&lt;/math&gt;, &lt;math&gt;B_2&lt;/math&gt; and &lt;math&gt;B_3&lt;/math&gt; are not all distinct; or it does not, so its intersection with the third sphere is no more than two points, insufficient to accommodate &lt;math&gt;A_1&lt;/math&gt;, &lt;math&gt;A_2&lt;/math&gt; and &lt;math&gt;A_3&lt;/math&gt;.
{{hidden end}}
|}
To summarise: 
: &lt;math&gt;\dim K_{m,n} = 1, 2, 3 \text{ or } 4&lt;/math&gt;, depending on the values of {{mvar|m}} and {{mvar|n}}.

== Dimension and chromatic number ==
{{math_theorem 
|The dimension of any graph {{mvar|G}} is always less than or equal to twice its [[chromatic number]]:
:&lt;math&gt;\dim G \le 2\,\chi(G)&lt;/math&gt;
}}
{{hidden begin|style=border:solid 1px #aaa|toggle=left|title=Proof}}
This proof also uses circles.

We write {{mvar|n}} for the chromatic number of {{mvar|G}}, and assign the integers &lt;math&gt;(1..n)&lt;/math&gt; to the {{mvar|n}} colours. In &lt;math&gt;2n&lt;/math&gt;-dimensional Euclidean space, with its dimensions denoted &lt;math&gt;x_1, x_2, .. x_{2n}&lt;/math&gt;, we arrange all the vertices of colour {{mvar|n}} arbitrarily on the circle given by &lt;math&gt;x_{2n-2}^2+x_{2n-1}^2=1/2,\quad x_i|(i\neq 2{n-2}, i\neq 2{n-1}) = 0&lt;/math&gt;.

Then the distance from a vertex of colour {{mvar|p}} to a vertex of colour {{mvar|q}} is given by &lt;math&gt;{\sqrt{x_{2p-2}^2+x_{2p-1}^2+x_{2q-2}^2+x_{2q-1}^2}} = {\sqrt{1/2+1/2}} = 1&lt;/math&gt;.
{{hidden end}}

== Euclidean dimension ==
[[File:AlmostWheel3D.svg|thumb|170px|The wheel graph with one spoke removed is of dimension 2.]]
[[File:AlmostWheel3DFolded.svg|thumb|170px|The same wheel is of Euclidean dimension 3.]]

The definition of the dimension of a graph given above says, of the minimal-{{mvar|n}} representation:
* if two vertices of {{mvar|G}} are connected by an edge, they must be at unit distance apart;
* however, two vertices at unit distance apart are not necessarily connected by an edge.

This definition is rejected by some authors. A different definition was proposed in 1991 by [[Alexander Soifer]], for what he termed the '''Euclidean dimension''' of a graph.&lt;ref&gt;{{Cite book | last1=Soifer | first1=Alexander | title=The Mathematical Coloring Book | publisher=Springer | isbn=978-0-387-74640-1 | year=2009}}&lt;/ref&gt; Previously, in 1980, [[Paul Erdős]] and [[Miklós Simonovits]] had already proposed it with the name '''faithful dimension'''.&lt;ref name="esi"&gt;{{Cite journal | last1=Erdős | first1=P. | last2=Simonovits | first2=M. | title=On the chromatic number of geometric graphs | journal=Ars Comb. | issue=9 | year=1980 | pages=229–246}}&lt;/ref&gt; By this definition, the minimal-{{mvar|n}} representation is one such that two vertices of the graph are connected ''if and only if'' their representations are at distance 1.

The figures opposite show the difference between these definitions, in the case of a [[wheel graph]] having a central vertex and six peripheral vertices, with one spoke removed. Its representation in the plane allows two vertices at distance 1, but they are not connected.

We write this dimension as &lt;math&gt;\operatorname{Edim}G&lt;/math&gt;. It is never less than the dimension defined as above:
: &lt;math&gt;\dim G \le \operatorname{Edim}G&lt;/math&gt;

== Euclidean dimension and maximal degree ==
Paul Erdős and Miklós Simonovits proved the following result in 1980:&lt;ref name="esi"/&gt;

{{Math_theorem|The Euclidean dimension of a graph {{mvar|G}} is no more than twice its maximal [[Degree (graph theory)|degree]] plus one:
: &lt;math&gt;\operatorname{Edim}G \le 2\,\Delta(G)+1&lt;/math&gt;}}
&lt;!-- See the [http://fr.wikipedia.org/wiki/Discussion:Dimension_(th%C3%A9orie_des_graphes) French discussion page for discussion of a better limit (2 Delta) mentioned by Soifer but not found in the source cited. --&gt;

==Computational complexity==
It is [[NP-hard]], and more specifically complete for the [[existential theory of the reals]], to test whether the dimension or the Euclidean dimension of a given graph is at most a given value.
The problem remains hard even for testing whether the dimension or Euclidean dimension is two.&lt;ref&gt;{{citation
 | last = Schaefer | first = Marcus
 | editor-last = Pach | editor-first = János | editor-link = János Pach
 | contribution = Realizability of graphs and linkages
 | doi = 10.1007/978-1-4614-0110-0_24
 | pages = 461–482
 | publisher = Springer
 | title = Thirty Essays on Geometric Graph Theory
 | year = 2013}}.&lt;/ref&gt;

== References ==
{{reflist}}

[[Category:Geometric graph theory]]
[[Category:Graph invariants]]</text>
      <sha1>9m24m2hco9qzdkkpitquua6hznosd03</sha1>
    </revision>
  </page>
  <page>
    <title>E. M. V. Krishnamurthy</title>
    <ns>0</ns>
    <id>22945970</id>
    <revision>
      <id>837434133</id>
      <parentid>827301532</parentid>
      <timestamp>2018-04-20T20:00:43Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (8 sources from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2493">{{BLP sources|date=September 2011}}
{{Infobox scientist
| name = E. M. V. Krishnamurthy
| birth_name = Edayyathu Mangalam Venkatarama Krishnamurthy
| birth_date = 18 June 1934
| birth_place = [[Ariyalur]], [[Tamil Nadu]], [[India]]
| death_date = {{death date and age|2012|10|26|1934|6|18|df=y}}
| death_place = [[Canberra]], [[Australia]]
| occupation = computer scientist
| nationality = [[Indian people|Indian]]
| field = [[Computer Science]]
| known_for = [[Fast Division Algorithm]]&lt;br /&gt; [[Theoretical computer science]]
}}
{{Use dmy dates|date=July 2011}}

'''Edayyathu Mangalam Venkatarama Krishnamurthy''' (18 June 1934 - 26 October 2012) was an Indian-born computer scientist. He was a professor at the Department of Computer science, [[Indian Institute of Science]], Bangalore.  He was an Emeritus Fellow, Computer Sciences Laboratory, Research School of Information Sciences and Engineering, [[Australian National University]], [[Canberra]].

He received the prestigious [[Shanti Swarup Bhatnagar Prize for Science and Technology]] (1978).&lt;ref&gt;{{cite web|url=http://www.csir.res.in/External/Utilities/Frames/career/main_page.asp?a=topframe.htm&amp;b=leftcon.htm&amp;c=../../../Heads/career/awards.htm|title=MATHEMATICAL  SCIENCES|publisher=[[Council of Scientific and Industrial Research]]|accessdate=22 September 2011|deadurl=yes|archiveurl=https://web.archive.org/web/20120210163924/http://www.csir.res.in/External/Utilities/Frames/career/main_page.asp?a=topframe.htm&amp;b=leftcon.htm&amp;c=..%2F..%2F..%2FHeads%2Fcareer%2Fawards.htm|archivedate=10 February 2012|df=dmy-all}}&lt;/ref&gt; He held several positions working for many institutions in India, Australia, USA, Europe and other nations.

==References==
{{Reflist}}
* [https://web.archive.org/web/20100429144324/http://www.jucs.org/jucs_articles_by_author/Krishnamurthy_E_V_/BusinessCard E.V. Krishnamurthy]
*{{cite journal|author=R. K. Shyamasundar|year=2012|title=E. V. Krishnamurthy (1934–2012)|journal=[[Current Science]]|volume=103|number=12|page=1473|URL=http://www.currentscience.ac.in/Volumes/103/12/1473.pdf|format=PDF}}

{{SSBPST recipients in Mathematical Science}}
{{Shanti Swarup Bhatnagar Laureates of Tamil Nadu}}
{{Authority control}}

{{DEFAULTSORT:Krishnamurthy, E. M. V.}}
[[Category:1934 births]]
[[Category:2012 deaths]]
[[Category:People from Ariyalur district]]
[[Category:Graph theorists]]
[[Category:Indian Institute of Science faculty]]
[[Category:Scientists from Tamil Nadu]]
[[Category:Indian combinatorialists]]</text>
      <sha1>1t4heqx4l8ar4cp1hkf2kt3itus0v0k</sha1>
    </revision>
  </page>
  <page>
    <title>Ehrenpreis conjecture</title>
    <ns>0</ns>
    <id>36201091</id>
    <revision>
      <id>831217491</id>
      <parentid>831216979</parentid>
      <timestamp>2018-03-19T12:39:57Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>add more links to the text</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1648">[[File:Jeremy Kahn and Vladimir Markovic.jpg|thumb|250px|[[Jeremy Kahn]] and [[Vladimir Markovic]], who first proved the conjecture, at [[Aarhus University]] in 2012.]]
In [[mathematics]], the '''Ehrenpreis conjecture''' of [[Leon Ehrenpreis]] states that for any ''K'' greater than 1, any two closed [[Riemann surface]]s of [[Genus (mathematics)|genus]] at least 2 have finite-degree [[Covering space|covers]] which are ''K''-[[Quasiconformal mapping|quasiconformal]]: that is, the covers are arbitrarily close in the [[Teichmüller metric]].

A proof was announced by [[Jeremy Kahn]] and [[Vladimir Markovic]] in January 2011, using their proof of the [[Surface subgroup conjecture ]] and a newly developed "good [[pair of pants (mathematics)|pants]] homology" theory.  In June 2012, Kahn and Markovic were given the [[Clay Research Award]]s for their work on these two problems by the [[Clay Mathematics Institute]] at a ceremony at [[Oxford University]].&lt;ref&gt;{{ cite web | url=http://www.claymath.org/research_conference/2012/ | title=2012 Clay Research Conference | date=18 June 2012 | accessdate=2012-06-20 | deadurl=yes | archiveurl=https://web.archive.org/web/20120604035509/http://claymath.org/research_conference/2012/ | archivedate=4 June 2012 | df= }}&lt;/ref&gt;

==References==
{{reflist}}
* {{ cite web | title=The good pants homology and a proof of the Ehrenpreis conjecture | first1=Jeremy | last1=Kahn | first2=Vladimir | last2=Markovic | date=29 April 2011 | arxiv=0910.5501 }}&lt;!--| accessdate=2012-06-20 --&gt;

[[Category:3-manifolds]]
[[Category:Conjectures that have been proved]]
[[Category:Theorems in topology]]


{{topology-stub}}</text>
      <sha1>okx92p8pji67jxsh091sn1yaelqlqjw</sha1>
    </revision>
  </page>
  <page>
    <title>Exsphere (polyhedra)</title>
    <ns>0</ns>
    <id>34873594</id>
    <revision>
      <id>827244154</id>
      <parentid>827243839</parentid>
      <timestamp>2018-02-23T16:22:39Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>/* Parameters */ fix one</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4047">In [[geometry]], the '''exsphere''' of a face of a regular polyhedron is the sphere outside the polyhedron which touches the face and the planes defined by extending the adjacent faces outwards. It is tangent to the face externally and tangent to the adjacent faces internally.

It is the 3-dimensional equivalent of the [[excircle]].

The sphere is more generally well-defined for any face which is a regular
polygon and delimited by faces with the same dihedral angles
at the shared edges. Faces of semi-regular polyhedra often 
have different types of faces, which define exspheres of different size with each type of face.

== Parameters ==
The exsphere touches the face of the regular polyedron at the center
of the incircle of that face. If the exsphere radius is denoted {{math|r&lt;sub&gt;ex&lt;/sub&gt;}}, the radius of this incircle {{math|r&lt;sub&gt;in&lt;/sub&gt;}}
and the dihedral angle between the face and the extension of the 
adjacent face {{math|&amp;delta;}}, the center of the exsphere
is located from the viewpoint at the middle of one edge of the
face by bisecting the dihedral angle. Therefore

:&lt;math&gt;\tan\frac{\delta}{2} = \frac{r_{\mathrm{ex}}}{r_{\mathrm{in}}}.&lt;/math&gt;

{{math|&amp;delta;}} is the 180-degree complement of the 
internal face-to-face angle.

=== Tetrahedron ===
Applied to the geometry of the [[Tetrahedron]] of edge length {{math|a}},
we have an [[Incircle|incircle radius]] {{math|''r''&lt;sub&gt;in&lt;/sub&gt; {{=}} ''a''/(2{{radic|3}})}} (derived by dividing twice the face area {{math|(''a''&lt;sup&gt;2&lt;/sup&gt;{{radic|3}})/4}} through the
perimeter {{math|3''a''}}), a dihedral angle {{math|''&amp;delta;'' {{=}} ''&amp;pi;'' - arccos(1/3)}}, and in consequence {{math|''r''&lt;sub&gt;ex&lt;/sub&gt; {{=}} ''a''/{{radic|6}}}}.

=== Cube ===
The radius of the exspheres of the 6 faces of the [[Cube]]
is the same as the radius of the inscribed
sphere, since {{math|&amp;delta;}} and its complement are the same, 90 degrees.

=== Icosahedron ===
The dihedral angle applicable to the [[Icosahedron]] is derived by
considering the coordinates of two triangles with a common edge,
for [[Icosahedron#Cartesian coordinates|example]] one face with vertices
at

:&lt;math&gt;(0,-1,g), (g,0,1), (0,1,g),&lt;/math&gt;

the other at

:&lt;math&gt;(1,-g,0), (g,0,1), (0,-1,g),&lt;/math&gt;

where {{math|g}} is the [[golden ratio]]. Subtracting vertex coordinates
defines edge vectors,

:&lt;math&gt;(g,1,1-g), (-g,1,g-1)&lt;/math&gt;

of the first face and

:&lt;math&gt;(g-1,g,1), (-g,-1,g-1)&lt;/math&gt;

of the other. [[Cross product]]s of the edges of the first face and second
face yield (not normalized) face [[Normal (geometry)|normal vectors]]

:&lt;math&gt;(2g-2,0,2g) \sim (g-1,0,g)&lt;/math&gt;
of the first and
:&lt;math&gt;(g^2-g+1,-g-(g-1)^2,1-g+g^2) = (2,-2,2)\sim (1,-1,1)&lt;/math&gt;
of the second face, using {{math|g&lt;sup&gt;2&lt;/sup&gt;{{=}}1+g}}.
The [[dot product]] between these two face normals yields the cosine
of the dihedral angle,

:&lt;math&gt;\cos\delta = \frac{(g-1)\cdot 1+g\cdot 1}{\sqrt{(g-1)^2+g^2} \sqrt{3}} =\frac{2g-1}{3} =\frac{\surd 5}{3}\approx 0.74535599.&lt;/math&gt; {{OEIS2C|A208899}}
:&lt;math&gt;\therefore \delta \approx 0.72973 \,\mathrm{rad} \approx 41.81^\circ&lt;/math&gt;
:&lt;math&gt;\therefore \tan\frac{\delta}{2} = \frac{\sin\delta}{1+\cos\delta}
=\frac{2}{3+\surd 5} \approx 0.3819660&lt;/math&gt; {{OEIS2C|A132338}}

For an icosahedron of edge length {{math|a}}, the incircle radius of the triangular faces is {{math|''r''&lt;sub&gt;in&lt;/sub&gt; {{=}} ''a''/(2{{radic|3}})}}, and finally the radius of the 20 exspheres
:&lt;math&gt;r_{\mathrm{ex}} = \frac{a}{(3+\sqrt{5})\sqrt 3} \approx 0.1102641 a.&lt;/math&gt;

== See also ==
* [[Inscribed sphere|Insphere]]

== External links ==
*{{cite journal
|first1=Leon
|last1=Gerber
|title=Associated and skew-orthologic simplexes
|year=1977
|journal=Trans. Am. Math. Soc.
|volume=231
|number=1
|pages=47–63
|jstor=1997867
|mr=0445393 
|doi=10.1090/S0002-9947-1977-0445393-6 
}}
*{{cite journal
|first1=Mowaffaq
|last1=Hajja
|title=The Gergonne and Nagel centers of an n-dimensional simplex
|journal=J. Geom.
|doi=10.1007/s00022-005-0011-3
|volume=83
|number=1-2
|pages=46–56
|year=2005
}}

[[Category:Geometry]]</text>
      <sha1>pt5wykk3k0y5rmqfp54936rhra3uziy</sha1>
    </revision>
  </page>
  <page>
    <title>Filter (mathematics)</title>
    <ns>0</ns>
    <id>19719</id>
    <revision>
      <id>849634942</id>
      <parentid>841769291</parentid>
      <timestamp>2018-07-10T09:46:36Z</timestamp>
      <contributor>
        <username>NikelsenH</username>
        <id>18120325</id>
      </contributor>
      <comment>+ add. links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20990">{{more footnotes|date=June 2017}}
[[File:Filter vs ultrafilter.svg|thumb|The powerset lattice of the set {1,2,3,4}, with the [[upper set]] ↑{1,4} colored yellow. It is a ''principal filter'', but not an ''ultrafilter'', as it can be extended to the larger nontrivial filter ↑{1}, by including also the light green elements. Since ↑{1} cannot be extended any further, it is an ultrafilter.]] 
In [[mathematics]], a '''filter''' is a special [[subset]] of a [[partially ordered set]]. For example, the [[power set]] of some set, partially ordered by set inclusion, is a filter. Filters appear in [[order theory|order]] and [[lattice theory]], but can also be found in [[topology]] from where they originate. The [[duality (order theory)|dual]] notion of a filter is an [[ideal (order theory)|ideal]].

Filters were introduced by [[Henri Cartan]] in 1937&lt;ref&gt;H. Cartan, [http://gallica.bnf.fr/ark:/12148/bpt6k3157c/f594.image "Théorie des filtres"], ''CR Acad. Paris'', '''205''', (1937) 595–598.&lt;/ref&gt;&lt;ref&gt;H. Cartan,  [http://gallica.bnf.fr/ark:/12148/bpt6k3157c/f776.image "Filtres et ultrafiltres"], ''CR Acad. Paris'', '''205''', (1937) 777–779.&lt;/ref&gt; and subsequently used by [[Nicolas Bourbaki|Bourbaki]] in their book ''[[Topologie Générale]]'' as an alternative to the similar notion of a [[net (topology)|net]] developed in 1922 by [[E. H. Moore]] and [[H. L. Smith]].

== Motivation ==
Intuitively, a filter in a partially ordered set (''poset''), X, is a subset of X that includes as members those elements that are large enough to satisfy some criterion. For example, if ''x'' is an element of the poset, then the set of elements that are above ''x'' is a filter, called the '''principal filter''' at ''x''. (Notice that if ''x'' and ''y'' are incomparable elements of the poset, then neither of the principal filters at ''x'' and ''y'' is contained in the other one, and conversely.)

Similarly, a filter on a set contains those subsets that are sufficiently large to contain ''something''. For example, if the set is the [[real line]] and ''x'' is one of its points, then the family of sets that include ''x'' in their interior is a filter, called the '''filter of neighbourhoods''' of ''x''. (Notice that the ''thing'' in this case is slightly larger than ''x'', but it still doesn't contain any other specific point of the line.)

The above interpretations do not really, without elaboration, explain the condition 2. of the general definition of filter (see below). For, why should two "large enough" things contain a ''common'' "large enough" thing? (Note, however, that they do explain conditions 1 and 3: Clearly the empty set is not "large enough", and clearly the collection of "large enough" things should be "upward closed".)

Alternatively, a filter can be viewed as a "locating scheme": Suppose we try to locate something (a point or a subset) in the space X. Call a filter the ''collection of subsets of X that might contain "what we are looking for".'' Then this "filter" should possess the following natural structure: 1. Empty set cannot contain anything so it will not belong to our filter. 2. If two subsets, E and F, both might contain "what we are looking for", then so might their intersection. Thus our filter should be closed with respect to finite intersection. 3. If a set E might contain "what we are looking for", so might any superset of it. Thus our filter is upward closed.

An '''ultrafilter''' can be viewed as a "perfect locating scheme" where ''each'' subset E of the space X can be used in deciding whether "what we are looking for" might lie in E.

From this interpretation, '''compactness''' (see the mathematical characterization below) can be viewed as the property that ''no location scheme can end up with nothing'', or, to put it another way, ''we will always find something''.

The mathematical notion of '''filter''' provides a precise language to treat these situations in a rigorous and general way, which is useful in analysis, [[general topology]] and logic.

== {{Anchor|PROPER}}General definition ==
A subset ''F'' of a partially ordered set (''P'',≤) is a '''filter''' if the following conditions hold:

# ''F'' is nonempty.
# For every ''x'', ''y'' in ''F'', there is some element ''z'' in ''F'' such that ''z''&amp;nbsp;≤&amp;nbsp;''x'' and ''z''&amp;nbsp;≤&amp;nbsp;''y''. (''F'' is a '''filter base''' (see below), or downward [[directed set|directed]])
# For every ''x'' in ''F'' and ''y'' in ''P'', ''x''&amp;nbsp;≤&amp;nbsp;''y'' implies that ''y'' is in ''F''. (''F'' is an ''[[upper set]]'', or upward closed)

A filter is '''proper''' if it is not equal to the whole set ''P''. This condition is sometimes added to the definition of a filter.

While the above definition is the most general way to define a filter for arbitrary [[Partially ordered set|posets]], it was originally defined for [[lattice (order)|lattice]]s only. In this case, the above definition can be characterized by the following equivalent statement:
A subset ''F'' of a lattice (''P'',≤) is a filter, [[if and only if]] it is an upper set that is closed under finite intersection ([[infimum|infima]] or [[Meet (mathematics)|meet]]), i.e., for all ''x'', ''y'' in ''F'', we find that ''x'' ∧ ''y'' is also in ''F''.

The smallest filter that contains a given element ''p'' is a '''principal filter''' and ''p'' is a '''principal element''' in this situation. The principal filter for ''p'' is just given by the set &lt;math&gt;\{x \in P\ |\ p \leq x\}&lt;/math&gt; and is denoted by prefixing ''p'' with an upward arrow: {{nobreak|&lt;math&gt;\uparrow p&lt;/math&gt;.}}

The [[Duality (mathematics)|dual notion]] of a filter, i.e. the concept obtained by reversing all ≤ and exchanging ∧ with ∨, is '''ideal'''. Because of this duality, the discussion of filters usually boils down to the discussion of ideals. Hence, most additional information on this topic (including the definition of '''maximal filters''' and '''prime filters''') is to be found in the article on [[ideal (order theory)|ideals]]. There is a separate article on [[ultrafilter]]s.

== Filter on a set ==
A special case of a filter is a filter defined on a set. Given a set ''S'', a partial ordering ⊆ can be defined on the [[powerset]] '''P'''(''S'') by subset inclusion, turning ('''P'''(''S''),⊆) into a lattice. Define a '''filter''' ''F'' on ''S'' as a nonempty subset of '''P'''(''S'') with the following properties:

# ''S'' is in ''F'', and if ''A'' and ''B'' are in ''F'', then so is their intersection. (''F is closed under finite intersection'')
# If ''A'' is in ''F'' and ''A'' is a subset of ''B'', then ''B'' is in ''F'', for all subsets ''B'' of ''S''. (''F is upward closed'')

If the empty set is not in ''F'', we say ''F'' is a proper filter. &lt;ref&gt;{{cite book|last1=Goldblatt|first1=R|title=Lectures on the Hyperreals: an Introduction to Nonstandard Analysis|page=32|url=https://archive.org/stream/springer_10.1007-978-1-4612-0615-6/10.1007-978-1-4612-0615-6#page/n31/mode/2up/search/proper+filter}}&lt;/ref&gt;

The first two properties imply that a '''filter on a set''' has the [[finite intersection property]]. With this definition, a filter on a set is indeed a filter. The only nonproper filter on ''S'' is '''P'''(''S'').

A '''filter base''' (or '''filter basis''') is a subset ''B'' of '''P'''(''S'') with the following properties:
# ''B'' is non-empty and the intersection of any two members of ''B'' contains a member of ''B'' (''B is downward directed'').
# The empty set is not a member of ''B'' (''B is a proper filter base'').

Given a filter base ''B'', the filter generated or spanned by ''B'' is defined as the minimum filter containing ''B''. It is the family of all the subsets of ''S'' which contain a member of ''B''. Every filter is also a filter base, so the process of passing from filter base to filter may be viewed as a sort of completion.

If ''B'' and ''C'' are two filter bases on ''S'', one says ''C'' is '''finer''' than ''B'' (or that ''C'' is a '''refinement''' of ''B'') if for each ''B''&lt;sub&gt;0&lt;/sub&gt; ∈ ''B'', there is a ''C''&lt;sub&gt;0&lt;/sub&gt; ∈ ''C'' such that ''C''&lt;sub&gt;0&lt;/sub&gt; ⊆ ''B''&lt;sub&gt;0&lt;/sub&gt;. If also ''B'' is finer than ''C'', one says that they are '''equivalent filter bases'''.
* If ''B'' and ''C'' are filter bases, then ''C'' is finer than ''B'' if and only if the filter spanned by ''C'' contains the filter spanned by ''B''. Therefore, ''B'' and ''C'' are equivalent filter bases if and only if they generate the same filter.
* For filter bases ''A'', ''B'', and ''C'', if ''A'' is finer than ''B'' and ''B'' is finer than ''C'' then ''A'' is finer than ''C''.  Thus the refinement relation is a [[preorder]] on the set of filter bases, and the passage from filter base to filter is an instance of passing from a preordering to the associated partial ordering.

For any subset ''T'' of '''P'''(''S'') there is a smallest (possibly nonproper) filter ''F'' containing ''T'', called the filter generated or spanned by ''T''. It is constructed by taking all finite intersections of ''T'', which then form a filter base for ''F''. This filter is proper if and only if any finite intersection of elements of ''T'' is non-empty, and in that case we say that ''T'' is a '''filter subbase'''.

=== Examples ===
* Let ''S'' be a nonempty set and ''C'' be a nonempty subset of ''S''.  Then &lt;math&gt;\{ C \}&lt;/math&gt; is a filter base.  The filter it generates (i.e., the collection of all subsets containing ''C'') is called the '''principal filter''' generated by ''C''.
* A filter is said to be a '''free filter''' if the intersection of all of its members is empty.  A principal filter is not free.  Since the intersection of any finite number of members of a filter is also a member, no filter on a finite set is free, and indeed is the principal filter generated by the common intersection of all of its members.  A nonprincipal filter on an infinite set is not necessarily free.
* The [[Fréchet filter]] on an infinite set ''S'' is the set of all subsets of ''S'' that have finite complement.  A filter on ''S'' is free if and only if it contains the Fréchet filter.
* Every [[uniform structure]] on a set ''X'' is a filter on ''X''&amp;times;''X''.
* A filter in a [[poset]] can be created using the [[Rasiowa-Sikorski lemma]], often used in [[forcing (mathematics)|forcing]].
* The set &lt;math&gt;\{ \{ N, N+1, N+2, \dots \} : N \in \{1,2,3,\dots\} \}&lt;/math&gt; is called a ''filter base of tails'' of the sequence of natural numbers &lt;math&gt;(1,2,3,\dots)&lt;/math&gt;. A filter base of tails can be made of any [[net (mathematics)|net]] &lt;math&gt;(x_\alpha)_{\alpha \in A}&lt;/math&gt; using the construction &lt;math&gt;\{ \{ x_\alpha : \alpha \in A, \alpha_0 \leq \alpha \} : \alpha_0 \in A \}&lt;/math&gt; where the filter that this filter base generates is called the net's ''eventuality filter.'' Therefore, all nets generate a filter base (and therefore a filter). Since all sequences are nets, this holds for sequences as well.

=== Filters in model theory ===
For any filter ''F'' on a set ''S'', the set function defined by
:&lt;math&gt;
m(A)=
\begin{cases}
1 &amp; \text{if }A\in F \\
0 &amp; \text{if }S\setminus A\in F \\
\text{undefined} &amp; \text{otherwise}
\end{cases}
&lt;/math&gt;
is finitely additive — a "[[measure (mathematics)|measure]]" if that term is construed rather loosely.  Therefore the statement

:&lt;math&gt;\left\{\,x\in S: \varphi(x)\,\right\}\in F&lt;/math&gt;

can be considered somewhat analogous to the statement that φ holds "almost everywhere".  That interpretation of membership in a filter is used (for motivation, although it is not needed for actual ''proofs'') in the theory of [[ultraproduct]]s in [[model theory]], a branch of [[mathematical logic]].

=== Filters in topology ===
In [[topology]] and analysis, filters are used to define convergence in a manner similar to the role of [[sequence]]s in a [[metric space]].

In topology and related areas of mathematics, a filter is a generalization of a [[net (mathematics)|net]]. Both nets and filters provide very general contexts to unify the various notions of [[Limit (mathematics)|limit]] to arbitrary [[topological space]]s.

A [[sequence]] is usually indexed by the [[natural numbers]], which are a [[totally ordered set]]. Thus, limits in [[first-countable space]]s can be described by sequences. However, if the space is not first-countable, nets or filters must be used. Nets generalize the notion of a sequence by requiring the index set simply be a [[directed set]]. Filters can be thought of as sets built from multiple nets. Therefore, both the limit of a filter and the limit of a net are conceptually the same as the limit of a sequence.&lt;!--An advantage to using filters is that many results can be shown without using the [[axiom of choice]].

This sentence is very misleading. Whenever invoking the ultrafilter lemma, you are essentially using the axiom of choice (if my understanding is correct.) Besides, regardless of the use of filter, you can't avoid ac to prove, say, Tychonoff's theorem. TakuyaMurata --&gt;

====Neighbourhood bases====

Let ''X'' be a topological space and ''x'' a point of ''X''.

* Take ''N''&lt;sub&gt;''x''&lt;/sub&gt; to be the '''[[Neighbourhood system|neighbourhood filter]]''' at point ''x'' for ''X''. This means that ''N''&lt;sub&gt;''x''&lt;/sub&gt; is the set of all topological [[neighbourhood (mathematics)|neighbourhood]]s of  the point ''x''. It can be verified that ''N''&lt;sub&gt;''x''&lt;/sub&gt; is a filter. A '''neighbourhood system''' is another name for a '''neighbourhood filter'''.
* To say that ''N'' is a '''neighbourhood base''' at ''x'' for ''X'' means that each subset ''V''&lt;sub&gt;0&lt;/sub&gt; of X is a neighbourhood of ''x'' if and only if there exists ''N''&lt;sub&gt;0&lt;/sub&gt; ∈ ''N'' such that ''N''&lt;sub&gt;0&lt;/sub&gt; ⊆ ''V''&lt;sub&gt;0&lt;/sub&gt;. Every neighbourhood base at ''x'' is a filter base that generates the neighbourhood filter at ''x''.

====Convergent filter bases====

Let ''X'' be a topological space and ''x'' a point of ''X''.

* To say that a filter base ''B'' '''converges''' to ''x'', denoted ''B'' → ''x'', means that for every neighbourhood ''U'' of ''x'', there is a ''B''&lt;sub&gt;0&lt;/sub&gt; ∈ ''B'' such that ''B''&lt;sub&gt;0&lt;/sub&gt; ⊆ ''U''. In this case, ''x'' is called a [[Limit (mathematics)|limit]] of ''B'' and ''B'' is called a '''convergent filter base'''.
* Every neighbourhood base ''N'' of ''x'' converges to ''x''.
** If ''N'' is a neighbourhood base at ''x'' and ''C'' is a filter base on ''X'', then ''C'' → ''x'' [[if and only if]] ''C'' is finer than ''N''.
** If ''Y'' ⊆ ''X'', a point ''p ∈ X'' is called a '''limit point''' of ''Y'' in ''X'' if and only if each neighborhood ''U'' of ''p'' in ''X'' intersects ''Y''. This happens if and only if there is a filter base of subsets of ''Y'' that converges to ''p'' in ''X''.
* For ''Y'' ⊆ ''X'', the following are equivalent:
** (i) There exists a filter base ''F'' whose elements are all contained in ''Y'' such that ''F'' → ''x''.
** (ii) There exists a filter ''F'' such that ''Y'' is an element of ''F'' and ''F'' → ''x''.
** (iii) The point ''x'' lies in the closure of ''Y''.

Indeed:

(i) implies (ii): if ''F'' is a filter base satisfying the properties of (i), then the filter associated to ''F'' satisfies the properties of (ii).

(ii) implies (iii): if ''U'' is any open neighborhood of ''x'' then by the definition of convergence ''U'' contains an element of ''F''; since also ''Y'' is an element of ''F'', 
''U'' and ''Y'' have nonempty intersection.

(iii) implies (i): Define &lt;math&gt; F = \{ U \cap Y \ | \ U \in N_x \}&lt;/math&gt;.  Then ''F'' is a filter base satisfying the properties of (i).

====Clustering====

Let ''X'' be a topological space and ''x'' a point of ''X''.

* A filter base ''B'' on ''X'' is said to '''cluster''' at ''x'' (or have ''x'' as a [[cluster point]]) if and only if each element of ''B'' has nonempty intersection with each neighbourhood of ''x''.
** If a filter base ''B'' clusters at ''x'' and is finer than a filter base ''C'', then ''C'' clusters at ''x'' too.
** Every limit of a filter base is also a cluster point of the base.
** A filter base ''B'' that has ''x'' as a cluster point may not converge to ''x''. But there is a finer filter base that does. For example the filter base of finite intersections of sets of the subbase &lt;math&gt;B\cup N_x&lt;/math&gt;.
** For a filter base ''B'', the set ∩{cl(''B''&lt;sub&gt;0&lt;/sub&gt;) : ''B''&lt;sub&gt;0&lt;/sub&gt;∈''B''} is the set of all cluster points of ''B'' (note: cl(''B''&lt;sub&gt;0&lt;/sub&gt;) is the [[closure (topology)|closure]] of ''B''&lt;sub&gt;0&lt;/sub&gt;). Assume that ''X'' is a [[complete lattice]].
*** The [[limit inferior]] of ''B'' is the [[infimum]] of the set of all cluster points of ''B''.
*** The [[limit superior]] of ''B'' is the [[supremum]] of the set of all cluster points of ''B''.
*** ''B'' is a convergent filter base [[if and only if]] its limit inferior and limit superior agree; in this case, the value on which they agree is the limit of the filter base.

====Properties of a topological space====

Let ''X'' be a topological space.

* ''X'' is a [[Hausdorff space]] [[if and only if]] every filter base on ''X'' has at most one limit.
* ''X'' is [[Compact space|compact]] if and only if every filter base on ''X'' clusters or has a cluster point.
* ''X'' is compact if and only if every filter base on ''X'' is a subset of a convergent filter base.
* ''X'' is compact if and only if every [[ultrafilter]] on ''X'' converges.

====Functions on topological spaces====

Let &lt;math&gt;X&lt;/math&gt;, &lt;math&gt;Y&lt;/math&gt; be topological spaces. Let &lt;math&gt;A&lt;/math&gt; be a filter base on &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;f\colon X \to Y&lt;/math&gt; be a function.  The [[Image (mathematics)|image]] of &lt;math&gt;A&lt;/math&gt; under &lt;math&gt;f&lt;/math&gt; is defined as the set &lt;math&gt;\{ f[a] : a \in A \}&lt;/math&gt;. The image is denoted &lt;math&gt;f[A]&lt;/math&gt; and forms a filter base on &lt;math&gt;Y&lt;/math&gt;. 
* &lt;math&gt;f&lt;/math&gt; is [[Continuous function (topology)|continuous]] at &lt;math&gt;x&lt;/math&gt; if and only if &lt;math&gt;A \to x&lt;/math&gt; implies &lt;math&gt;f[A] \to f(x)&lt;/math&gt;.

==== Cauchy filters ====

Let &lt;math&gt;(X,d)&lt;/math&gt; be a [[metric space]].
* To say that a filter base ''B'' on ''X'' is '''Cauchy''' means that for each [[real number]] ε&gt;0, there is a ''B''&lt;sub&gt;0&lt;/sub&gt; ∈ ''B'' such that the metric [[diameter]] of ''B''&lt;sub&gt;0&lt;/sub&gt; is less than ε.
* Take (''x&lt;sub&gt;n&lt;/sub&gt;'') to be a [[sequence]] in metric space ''X''. (''x&lt;sub&gt;n&lt;/sub&gt;'') is a [[Cauchy sequence]] if and only if the filter base &lt;nowiki&gt;{{&lt;/nowiki&gt;''x''&lt;sub&gt;''N''&lt;/sub&gt;, ''x''&lt;sub&gt;''N''  +1&lt;/sub&gt;, ...} : ''N'' ∈ {1,2,3,...} } is Cauchy.

More generally, given a [[uniform space]] ''X'', a filter ''F'' on ''X'' is called '''Cauchy filter''' if for every  [[entourage (topology)|entourage]] ''U'' there is an ''A'' ∈ ''F'' with (''x'', ''y'') ∈ ''U'' for all ''x'', ''y'' ∈ ''A''. In a metric space this agrees with the previous definition. ''X'' is said to be complete if every Cauchy filter converges. Conversely, on a uniform space every convergent filter is a Cauchy filter. Moreover, every cluster point of a Cauchy filter is a limit point.

A compact uniform space is complete: on a compact space each filter has a cluster point, and if the filter is Cauchy, such a cluster point is a limit point. Further, a uniformity is compact if and only if it is complete and [[totally bounded]].

Most generally, a [[Cauchy space]] is a set equipped with a class of filters declared to be Cauchy. These are required to have the following properties:
# for each ''x'' in ''X'', the [[ultrafilter]] at ''x'', ''U''(''x''), is Cauchy.
# if ''F'' is a Cauchy filter, and ''F'' is a subset of a filter ''G'', then ''G'' is Cauchy.
# if ''F'' and ''G'' are Cauchy filters and each member of ''F'' intersects each member of ''G'', then ''F'' ∩ ''G'' is Cauchy.
The Cauchy filters on a uniform space have these properties, so every uniform space (hence every metric space) defines a Cauchy space.

== See also ==
* [[Ultrafilter]]
* [[Filtration (mathematics)]]
* [[Filtration (probability theory)]]
* [[Filtration (abstract algebra)]]
* [[Net (mathematics)]]
* [[Generic filter]]
* [[Ideal (set theory)]]

== Notes ==
{{reflist}}

== References ==
*[[Nicolas Bourbaki]], &lt;cite&gt;General Topology&lt;/cite&gt; (&lt;cite&gt;Topologie Générale&lt;/cite&gt;), {{ISBN|0-387-19374-X}} (Ch. 1-4): Provides a good reference for filters in general topology (Chapter I) and for Cauchy filters in uniform spaces (Chapter II)
* Stephen Willard, ''General Topology'', (1970) Addison-Wesley Publishing Company, Reading Massachusetts. ''(Provides an introductory review of filters in topology.)''
*David MacIver, ''[http://www.efnet-math.org/~david/mathematics/filters.pdf Filters in Analysis and Topology]'' (2004) ''(Provides an introductory review of filters in topology and in metric spaces.)''
* Burris, Stanley N., and H.P. Sankappanavar, H. P., 1981. ''[http://www.thoralf.uwaterloo.ca/htdocs/ualg.html A Course in Universal Algebra.]''  Springer-Verlag. {{ISBN|3-540-90578-2}}.

[[Category:Order theory]]
[[Category:General topology]]</text>
      <sha1>qn1lllh26cmf3v3dvpcgdyh9iiakc44</sha1>
    </revision>
  </page>
  <page>
    <title>Fueter–Pólya theorem</title>
    <ns>0</ns>
    <id>48831575</id>
    <revision>
      <id>849358533</id>
      <parentid>849358457</parentid>
      <timestamp>2018-07-08T12:48:58Z</timestamp>
      <contributor>
        <ip>91.130.15.58</ip>
      </contributor>
      <comment>/* Higher dimensions */ fix index</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3382">{{refimprove|date=December 2015}}

The '''Fueter–Pólya theorem''', first proved by [[Rudolf Fueter]] and [[George Pólya]], states that the only [[quadratic function|quadratic]] [[pairing function]]s are the Cantor [[polynomial]]s.

== Introduction ==
In 1873, [[Georg Cantor]] showed that the so-called Cantor polynomial&lt;ref&gt;G. Cantor: ''Ein Beitrag zur Mannigfaltigkeitslehre'', J. Reine Angew. Math., Band 84 (1878), Pages 242–258&lt;/ref&gt;

: &lt;math&gt;P(x,y) := \frac{1}{2} ((x+y)^2+3x+y)&lt;/math&gt;

is a [[bijective]] mapping from &lt;math&gt;\N^2&lt;/math&gt; to &lt;math&gt;\N&lt;/math&gt;.
The polynomial given by swapping the variables is also a pairing function.

Fueter was investigating whether there are other quadratic polynomials with this property, and concluded that this is not the case assuming &lt;math&gt;P(0,0)=0&lt;/math&gt;. He then wrote to Pólya, who showed the theorem does not require this condition.&lt;ref&gt;Rudolf Fueter, Georg Pólya: [http://www.ngzh.ch/archiv/1923_68/68_3-4/68_14.pdf ''Rationale Abzählung der Gitterpunkte''], Vierteljschr. Naturforsch. Ges. Zürich 58 (1923), Pages 280–386&lt;/ref&gt;

=== Statement ===
If &lt;math&gt;P&lt;/math&gt; is a real quadratic polynomial in two variables whose restriction to &lt;math&gt;\N^2&lt;/math&gt; is a bijection from &lt;math&gt;\N^2&lt;/math&gt; to &lt;math&gt;\N&lt;/math&gt; then it is

: &lt;math&gt;P(x,y) := \frac{1}{2} ((x+y)^2+3x+y)&lt;/math&gt;

or

:&lt;math&gt;P(x,y) := \frac{1}{2} ((y+x)^2+3y+x).&lt;/math&gt;

=== Proof ===
The original proof is surprisingly difficult, using the [[Lindemann–Weierstrass theorem]] to prove the transcendence of
&lt;math&gt;e^a&lt;/math&gt; for a nonzero algebraic number &lt;math&gt;a&lt;/math&gt;.&lt;ref&gt;Craig Smoryński: ''Logical Number Theory I'', Springer-Verlag 1991, {{ISBN|3-540-52236-0}}, Chapters I.4 and I.5: ''The Fueter–Pólya Theorem I/II''&lt;/ref&gt;
In 2002, M. A. Vsemirnov published an elementary proof of this result.&lt;ref&gt;M. A. Vsemirnov, Two elementary proofs of the Fueter–Pólya theorem on pairing polynomials.
St. Petersburg Math. J. 13 (2002), no. 5, pp. 705–715. Correction: ibid. 14 (2003), no. 5, p. 887.&lt;/ref&gt;

==Fueter–Pólya conjecture ==
The theorem states that the Cantor polynomial is the only quadratic paring polynomial of &lt;math&gt;\N^2&lt;/math&gt; and &lt;math&gt;\N&lt;/math&gt;. The Cantor polynomial can be generalized to higher degree as bijection of ℕ&lt;sup&gt;''k''&lt;/sup&gt; with ℕ for ''k'' &gt; 2. The conjecture is that these are the only such pairing polynomials.

=== Higher dimensions ===

The generalization of the Cantor polynomial in higher dimensions is as follows:&lt;ref&gt;P. Chowla: ''On some Polynomials which represent every natural number exactly once'', Norske Vid. Selsk. Forh. Trondheim (1961), volume 34, pages 8–9&lt;/ref&gt;
:&lt;math&gt;P_n(x_1,\ldots,x_n) = \sum_{k=1}^n \binom{k-1+\sum_{j=1}^k x_j}{k} = x_1 + \binom{x_1+x_2+1}{2} + \cdots +\binom{x_1+\cdots +x_n+n-1}{n}&lt;/math&gt;

The sum of these [[binomial coefficients]] yields a polynomial of degree &lt;math&gt;n&lt;/math&gt; in &lt;math&gt;n&lt;/math&gt; variables. It is an open question whether every degree &lt;math&gt;n&lt;/math&gt; polynomial which is a bijection &lt;math&gt;\N^n\rightarrow \N&lt;/math&gt; arises as a permutation of the variables of the polynomial &lt;math&gt;P_n&lt;/math&gt;.&lt;ref&gt;Craig Smoryński: ''Logical Number Theory I'', Springer-Verlag 1991, {{ISBN|3-540-52236-0}}, Chapter I.4, Conjecture 4.3&lt;/ref&gt;

== References ==

&lt;references /&gt;

{{DEFAULTSORT:Fueter-Polya theorem}}
[[Category:Mathematical theorems]]
[[Category:Number theory]]</text>
      <sha1>1d9ua5q9o6w1p4ks4qenq5i01ah0zew</sha1>
    </revision>
  </page>
  <page>
    <title>George Jerrard</title>
    <ns>0</ns>
    <id>8354790</id>
    <revision>
      <id>836012702</id>
      <parentid>728151449</parentid>
      <timestamp>2018-04-12T04:19:09Z</timestamp>
      <contributor>
        <username>Kinewma</username>
        <id>8089377</id>
      </contributor>
      <comment>birthdate from MacTutor Biography</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1162">'''George Birch Jerrard''' (25 November 1804 &amp;ndash; 23 November 1863) was a British [[mathematician]].

He studied at [[Trinity College, Dublin]] from 1821 to 1827.  His main work was on the [[theory of equations]], where he was reluctant to accept the validity of the work of [[Niels Henrik Abel]] on the insolubility of the [[quintic equation]] by [[Nth root|radical]]s.  He found a way of using [[Tschirnhaus transformation]]s to eliminate three of the terms in an equation, which generalised work of [[Erland Samuel Bring|Erland Bring]] (1736–1798), and is now called [[Bring–Jerrard normal form]].

==Works==
* ''An essay on the resolution of equations'', part 1, London 1858, ([https://books.google.com/books?id=by8DAAAAQAAJ online]).

==References==
*{{cite DNBSupp|wstitle=Jerrard, George Birch}}

==External links==
* {{MacTutor Biography|id=Jerrard}}

{{Authority control}}

{{DEFAULTSORT:Jerrard, George Birch}}
[[Category:English mathematicians]]
[[Category:1804 births]]
[[Category:1863 deaths]]
[[Category:Algebraists]]
[[Category:19th-century British mathematicians]]
[[Category:Alumni of Trinity College, Dublin]]


{{UK-mathematician-stub}}</text>
      <sha1>1k7ungvqwsif9fmsi7r7wtn4pm8c4n9</sha1>
    </revision>
  </page>
  <page>
    <title>Growing context-sensitive grammar</title>
    <ns>0</ns>
    <id>35739443</id>
    <revision>
      <id>822669868</id>
      <parentid>722698503</parentid>
      <timestamp>2018-01-27T20:26:20Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>adding a link using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4054">In [[formal language theory]], a '''growing context-sensitive grammar''' is a [[context-sensitive grammar]] in which the productions increase the length of the sentences being generated.&lt;ref name=STAC /&gt;&lt;ref name="Buntrock.Otto.1998"&gt;{{cite journal | author=Gerhard Buntrock and Friedrich Otto | title=Growing Context-Sensitive Languages and Church-Rosser Languages | journal=Information and Computation | volume=141 | pages=1&amp;mdash;36 | url=http://www.sciencedirect.com/science/article/pii/S089054019792681X/pdf?md5=80d9589df38d54d3ea5989cfdfacaf8b&amp;pid=1-s2.0-S089054019792681X-main.pdf | year=1998 | doi=10.1006/inco.1997.2681}}&lt;/ref&gt; These grammars are thus [[noncontracting grammar|noncontracting]] and context-sensitive. A '''growing context-sensitive language''' is a [[context-sensitive language]] generated by these grammars.
 
In these grammars the "start symbol" S does not appear on the right hand side of any production rule and the length of the right hand side of each production exceeds the length of the left side, unless the left side is S.&lt;ref name=STAC&gt;{{cite book | author=G. Buntrock and F. Otto | contribution=Growing Context-Sensitive Languages  and Church-Rosser Languages | editor=Ernst W. Mayr and Claude Puech | title=Proc. 12th STACS | publisher=Springer | series=LNCS | volume=900 | pages=313&amp;mdash;324 | isbn=3540590420 | year=1995 }} Here: p.316-317&lt;/ref&gt;

These grammars were introduced by Dahlhaus and Warmuth.&lt;ref name=Kuich &gt;{{cite book | author=Gundula Niemann and Jens R. Woinowski | contribution=The Growing Context-Sensitive Languages Are  the Acyclic Context-Sensitive Languages | editor=Werner Kuich and Grzegorz Rozenberg and Arto Salomaa | title=Proc. 5th Int. Conf on  Developments in Language Theory (DLT) | publisher=Springer | series=Lecture Notes in Computer Science | volume=2295 | pages=197&amp;mdash;205 | isbn=3540434534 | year=2002 }}. Here: p.197-198&lt;/ref&gt; They were later shown to be equivalent to the [[acyclic context-sensitive grammar]]s.&lt;ref name=Kuich /&gt; Membership in any growing context-sensitive language is [[polynomial time]] computable;&lt;ref&gt;{{cite book | author=E. Dahlhaus und M.K. Warmuth | contribution=Membership for growing context-sensitive grammars  is polynomial | editor=Paul Franchi-Zannettacci | title=Proc. 11th Colloquium on  Trees in Algebra and Programming (CAAP) | publisher=Springer | series=LNCS | volume=214 | pages=85&amp;mdash;99 | year=1986 |url=https://users.soe.ucsc.edu/~manfred/pubs/J8.pdf}} Here: p.85-86&lt;/ref&gt;&lt;ref&gt;{{cite journal | author=E. Dahlhaus und M.K. Warmuth | title=Membership for growing context-sensitive grammars  is polynomial | journal=Journal of Computer and System Sciences | volume=33 | pages=456&amp;mdash;472 | url=http://www.sciencedirect.com/science/article/pii/0022000086900620/pdf?md5=b050cd8c37d8e2f3ce0183c85c53e2a8&amp;pid=1-s2.0-0022000086900620-main.pdf | year=1986 | doi=10.1016/0022-0000(86)90062-0}}&lt;/ref&gt; however, the [[Complexity_of_constraint_satisfaction#Uniform_and_non-uniform_restrictions|''uniform'']] problem of deciding whether a given string belongs to the language generated by a given growing&lt;ref&gt;G. Buntrock and K. Lorys. [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.55.2654 On growing context-sensitive languages.] In Proc. 19th ICALP, Lecture
Notes in Computer Science (W. Kuich,ed, pages 77–88. Springer-Verlag, 1992.&lt;/ref&gt; or acyclic&lt;ref&gt;{{cite book | author=Erik Aarts | contribution=Uniform recognition for context-sensitive grammars  is NP-complete | editor= | title=Proc. 14th Int. Conf. on  Computational Linguistics (COLING, Nantes, Aug. 23-28) | publisher= | pages=1157&amp;mdash;1161 | contributionurl=http://aclweb.org/anthology-new/C/C92/C92-4183.pdf | year=1992 }}&lt;/ref&gt; context-sensitive grammar is [[NP-complete]].

==See also==
* [[Noncontracting grammar]]

==References==
{{Reflist}}

==External links==
* G. Buntrock: [http://www.tcs.uni-luebeck.de/en/mitarbeiter/buntrock/gcsl.html Growing context-sensitive languages]

{{Formal languages and grammars|state=collapsed}}

[[Category:Formal languages]]</text>
      <sha1>dtkgz21bu4s7h352qo6ta1b4olxxgbf</sha1>
    </revision>
  </page>
  <page>
    <title>György Elekes</title>
    <ns>0</ns>
    <id>26640478</id>
    <revision>
      <id>838027875</id>
      <parentid>822486717</parentid>
      <timestamp>2018-04-24T13:58:30Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (1 source from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5817">{{Infobox scientist|name = György Elekes
|birth_date = {{Birth date|1949|5|19|df=y}}
|birth_place = [[Budapest]], [[Hungary]]
|death_date = {{death date and age|2008|9|29|1949|5|19|df=y}}
|death_place = [[Fót]], [[Hungary]]
|residence = [[Fót|Fót, Hungary]]
|fields = [[Mathematics]] and [[Computer science]]
|workplaces = [[Eötvös Loránd University]]
|alma_mater = [[Eötvös Loránd University]]
|known_for = [[Combinatorial geometry]]&lt;br/&gt;[[Combinatorial set theory]]&lt;br /&gt;[[Number theory]]
}}
'''György Elekes''' ({{date|1949-05-19}} – {{date|2008-09-29}})&lt;ref name="obit"&gt;{{cite web|url=http://www.cs.elte.hu/math/news/obituary.html|title=Obituary|publisher=Eötvös Loránd University|accessdate=21 March 2010}}&lt;/ref&gt; was a [[Hungary|Hungarian]] [[mathematician]] and [[computer scientist]] who specialized in [[Combinatorial geometry]] and [[Combinatorial set theory]]. He may be best known for his work in the field that would eventually be called [[Additive number theory|Additive Combinatorics]]. Particularly notable was his "ingenious"&lt;ref&gt;{{cite book|last1=Tao|first1=Terence|authorlink1=Terence Tao|last2=Vu|first2=Van H.|authorlink2=Van H. Vu|title=Additive Combinatorics|publisher=Cambridge University Press|year=2010|edition=Paperback|page=315|chapter=8.3|isbn=978-0-521-13656-3}}&lt;/ref&gt; application of the [[Szemerédi–Trotter theorem]] to improve the best known lower bound for the [[sum-product problem]].&lt;ref&gt;{{cite journal|last=Elekes|first=György |year=1997|title=On the number of sums and products|journal=Acta Arith.|volume=81|pages=365–367}}&lt;/ref&gt; He also proved that any [[Time complexity#Polynomial time|polynomial-time algorithm]] approximating the [[volume]] of [[Convex body|convex bodies]] must have a [[Numerical stability|multiplicative error]], and the error grows [[Exponential growth|exponentially]] on the dimension.&lt;ref name="volume"/&gt; With [[Micha Sharir]] he set up a framework which eventually led [[Larry Guth|Guth]] and [[Nets Hawk Katz|Katz]] to the solution of the [[Erdős distinct distances problem]].&lt;ref name="The Erdős distance problem"&gt;[http://www.cs.umd.edu/~gasarch/erdos_dist/erdos_dist.html The Erdős distance problem] {{webarchive|url=https://web.archive.org/web/20110611055716/http://www.cs.umd.edu/~gasarch/erdos_dist/erdos_dist.html |date=2011-06-11 }}&lt;/ref&gt; (See below.)

==Life==
After graduating from the mathematics program at [[Fazekas Mihály Gimnázium (Budapest)|Fazekas Mihály Gimnázium]] (i.e., "[[Fazekas Mihály]] high school" in [[Budapest]], which is known for its excellence, especially in mathematics), Elekes studied mathematics at the [[Eötvös Loránd University]]. Upon completing his degree, he joined the faculty in the Department of [[Mathematical analysis|Analysis]] at the university. In 1984, he joined the newly forming Department of [[Computer Science]], which was being headed by [[László Lovász]]. Elekes was promoted to [[Professor#Tenured and tenure-track positions|full professor]] in 2005. He received the ''[[Doktor nauk|Doctor of Mathematical Sciences]]'' title from the [[Hungarian Academy of Sciences]] in 2001.&lt;ref name="obit"/&gt;

==Work==
Elekes started his mathematical work in [[combinatorial set theory]], answering some questions posed by [[Paul Erdős|Erdős]] and [[András Hajnal|Hajnal]]. One of his results states that if the set of infinite subsets of the set of natural numbers is split into countably many parts, then in one of them, there is a solution of the equation ''A''∪''B''=''C''.&lt;ref name="obit"/&gt;&lt;ref&gt;{{cite journal|last1=Elekes|first1=György|last2=Erdős|first2=Paul|authorlink2=Paul Erdős|last3=Hajnal|first3=András|authorlink3=András Hajnal|year=1978|title=On some partition properties of families of sets|journal=Studia Scientiarum Mathematicarum Hungarica|pages=151–155}}&lt;/ref&gt; His interest later switched to another favorite topic of Erdős, [[discrete geometry]] and [[Computational geometry|geometric algorithm theory]]. In 1986 he proved that if a deterministic polynomial algorithm computes a number ''V''(''K'') for every convex body ''K'' in any Euclidean space given by a separation oracle such that ''V''(''K'') always at least vol(''K''), the volume of ''K'', then for every large enough dimension ''n'', there is a convex body in the ''n''-dimensional Euclidean space such that ''V''(''K'')&gt;2&lt;sup&gt;0.99''n''&lt;/sup&gt;vol(''K''). That is, any polynomial-time estimate the volume of ''K'' must be inaccurate by at least an exponential factor.&lt;ref name="obit"/&gt;&lt;ref name="volume"&gt;{{cite journal|last=Elekes|first=György|year=1986|title=A geometric inequality and the complexity of computing volume|journal=[[Discrete and Computational Geometry]]|volume=1|pages=289–292|doi=10.1007/bf02187701}}&lt;/ref&gt;

Not long before his death he developed new tools in [[Algebraic geometry]] and used them to obtain results in [[Discrete geometry]], proving [[George B. Purdy#Purdy's Conjecture|Purdy's Conjecture]]. [[Micha Sharir]] organized, extended and published Elekes's posthumous notes on these methods.&lt;ref&gt;''On lattices, distinct distances, and the Elekes-Sharir framework'',
Javier Cilleruelo, Micha Sharir, Adam Sheffer, https://arxiv.org/abs/1306.0242&lt;/ref&gt; Then [[Nets Katz]] and [[Larry Guth]] used them to solve (apart from a factor of (log n) &lt;sup&gt;1/2 &lt;/sup&gt;) the [[Erdős distinct distances problem]], posed in 1946.&lt;ref name="The Erdős distance problem"/&gt;

==References==
{{Reflist}}

==External links==
*[http://www.cs.elte.hu/~elekes/ Elekes' home page]

{{Authority control}}

{{DEFAULTSORT:Elekes, Gyorgy}}
[[Category:Number theorists]]
[[Category:Combinatorialists]]
[[Category:Researchers in geometric algorithms]]
[[Category:Hungarian mathematicians]]
[[Category:Hungarian computer scientists]]
[[Category:1949 births]]
[[Category:2008 deaths]]</text>
      <sha1>9yq77jxoava4i605i38o61sntqopq5x</sha1>
    </revision>
  </page>
  <page>
    <title>Imaging cycler microscopy</title>
    <ns>0</ns>
    <id>42191418</id>
    <revision>
      <id>870959534</id>
      <parentid>855923477</parentid>
      <timestamp>2018-11-28T01:42:10Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: pages, author2, author3, author4, author5, author6, author7, template type. Add: isbn, series, citeseerx, chapter, pages, issue, volume, doi-broken-date, pmc, pmid. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]]; [[Category:Bioinformatics]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27140">An '''imaging cycler microscope (ICM)''' is a fully automated (epi)[[fluorescence microscope]] which overcomes the spectral resolution limit resulting in parameter- and dimension-unlimited fluorescence imaging.  The principle and robotic device was described by Walter Schubert in 1997 &lt;ref name=ref1&gt;Schubert W (1997) Automated device and method for measuring and identifying molecules or fragments thereof. European patent EP 0810428 B1 [see also Schubert W. US patent 6,150,173 (2000); Japanese patent 3739528 (1998)].&lt;/ref&gt; and ever since has been further developed with his co-workers within the human [[toponome]] project.&lt;ref name=ref2&gt;{{cite journal|last=Cottingham|first=Katie|title=Human Toponome Project {{!}} Human Proteinpedia is open for (free) business|journal=Journal of Proteome Research|date=May 2008|volume=7|issue=5|pages=1806|doi=10.1021/pr083701k}}&lt;/ref&gt;&lt;ref name=ref3&gt;{{cite journal|last=Schubert|first=Walter|author2=Bonnekoh, Bernd |author3=Pommer, Ansgar J |author4=Philipsen, Lars |author5=Böckelmann, Raik |author6=Malykh, Yanina |author7=Gollnick, Harald |author8=Friedenberger, Manuela |author9=Bode, Marcus |author10= Dress, Andreas W M |title=Analyzing proteome topology and function by automated multidimensional fluorescence microscopy|journal=Nature Biotechnology|date=1 October 2006|volume=24|issue=10|pages=1270–1278|doi=10.1038/nbt1250 |pmid=17013374}}&lt;/ref&gt;&lt;ref name=ref4&gt;{{cite journal|last=Friedenberger|first=Manuela|author2=Bode, Marcus |author3=Krusche, Andreas |author4= Schubert, Walter |title=Fluorescence detection of protein clusters in individual cells and tissue sections by using toponome imaging system: sample preparation and measuring procedures|journal=Nature Protocols|date=September 2007|volume=2|issue=9|pages=2285–2294|doi=10.1038/nprot.2007.320|pmid=17853885}}&lt;/ref&gt;&lt;ref name=ref5&gt;{{cite web|last=Schubert|first=W|title=Direct, spatial imaging of randomly large supermolecules by using parameter unlimited TIS imaging cycler microscopy.|url=http://www.toposnomos.com/doku/MC2013.pdf|publisher=International Microscopy Conference 2013|accessdate=2013-09-23}}&lt;/ref&gt; The ICM runs robotically controlled repetitive incubation-imaging-bleaching cycles  with dye-conjugated probe libraries recognizing target structures in situ (biomolecules in fixed cells or tissue sections). This results in the transmission of a randomly large number of distinct biological informations by re-using the same fluorescence channel after bleaching for the transmission of another biological information using the same dye which is conjugated to another specific probe, a.s.o. Thereby noise-reduced quasi-multi channel fluorescence images with reproducible physical, geometrical, and biophyscial stabilities are generated. The resulting power of combinatorial molecular discrimination (PCMD) per data point is given by 65,536&lt;sup&gt;''k''&lt;/sup&gt;, where 65,536  is the number of grey value levels (output of a 16-bit CCD camera) and ''k'' is the number of co-mapped biomolecules and/or subdomains per biomolecule(s). High PCMD has been shown for ''k''&amp;nbsp;=&amp;nbsp;100,&lt;ref name=ref3 /&gt;&lt;ref name=ref5 /&gt; and in principle can be expanded for much higher numbers of&amp;nbsp;''k''.  In contrast to traditional multi-channel-few parameter fluorescence microscopy  (Fig 1a) high PCMDs in an ICM lead to high functional and spatial resolution (Fig 1b). Systematic ICM analysis of biological systems reveals the supramolecular segregation law that describes the principle of order of large, hierarchically organized biomolecular networks in situ (toponome).&lt;ref name=ref6&gt;{{cite journal|last=Schubert|first=W|title=Systematic, spatial imaging of large multimolecular assemblies and the emerging principles of supramolecular order in biological systems.|journal=Journal of Molecular Recognition|year=2014|volume=27|issue=1|pages=3–18|doi=10.1002/jmr.2326|pmid=24375580|pmc=4283051}}&lt;/ref&gt; The ICM is the core technology for the systematic mapping of the complete protein network code in tissues (human toponome project).&lt;ref name=ref2 /&gt; The original ICM method &lt;ref name=ref1 /&gt; includes any modification of the bleaching step. Corresponding modifications have been reported for [[antibody]] retrieval &lt;ref name=ref7&gt;{{cite journal|last=Micheva|first=Kristina D.|author2=Smith, Stephen J|title=Array Tomography: A New Tool for Imaging the Molecular Architecture and Ultrastructure of Neural Circuits|journal=Neuron|date=July 2007|volume=55|issue=1|pages=25–36|doi=10.1016/j.neuron.2007.06.014|pmid=17610815|pmc=2080672}}&lt;/ref&gt; and chemical [[Quenching (fluorescence)|dye-quenching]] &lt;ref name=ref8&gt;{{cite journal|last1=Gerdes|first1=M. J.|last2=Sevinsky|first2=C. J.|last3=Sood|first3=A.|last4=Adak|first4=S.|last5=Bello|first5=M. O.|last6=Bordwell|first6=A.|last7=Can|first7=A.|last8=Corwin|first8=A.|last9=Dinn|first9=S.|last10=Filkins |first10=R. J.|last11=Hollman|first11=D.|last12=Kamath|first12=V.|last13=Kaanumalle|first13=S.|last14=Kenny|first14=K.|last15=Larsen|first15=M.|last16=Lazare|first16=M.|last17=Li|first17=Q.|last18=Lowes|first18=C.|last19=McCulloch|first19=C. C.|last20=McDonough|first20=E.|last21=Montalto|first21=M. C.|last22=Pang|first22=Z.|last23=Rittscher|first23=J.|last24=Santamaria-Pang|first24=A.|last25=Sarachan|first25=B. D.|last26=Seel|first26=M. L.|last27=Seppo|first27=A.|last28=Shaikh|first28=K.|last29=Sui|first29=Y.|last30=Zhang|first30=J.|last31=Ginty|first31=F.|title=Highly multiplexed single-cell analysis of formalin-fixed, paraffin-embedded cancer tissue|journal=Proceedings of the National Academy of Sciences|date=1 July 2013|volume=110|issue=29|pages=11982–11987|doi=10.1073/pnas.1300136110|pmid=23818604|bibcode=2013PNAS..11011982G|pmc=3718135}}&lt;/ref&gt; debated recently.&lt;ref name=ref9&gt;{{cite journal|last=Schubert|first=W.|author2=Dress, A. |author3=Ruonala, M. |author4=Krusche, A. |author5=Hillert, R. |author6=Gieseler, A. |author7= Walden, P. |title=Imaging cycler microscopy|journal=Proceedings of the National Academy of Sciences|date=7 January 2014|volume=111|issue=2|pages=E215|doi=10.1073/pnas.1319017111|pmid=24398531|bibcode=2014PNAS..111E.215S|pmc=3896151}}&lt;/ref&gt;&lt;ref name=ref10&gt;{{cite journal|last=Gerdes|first=M. J.|title=Reply to Schubert et al.: Regarding critique of highly multiplexed technologies|journal=Proceedings of the National Academy of Sciences|date=7 January 2014|volume=111|issue=2|pages=E216|doi=10.1073/pnas.1319622111|pmid=24571024|bibcode=2014PNAS..111E.216G|pmc=3896205}}&lt;/ref&gt; The Toponome Imaging Systems (TIS) and Multi-Epitope-Ligand cartographs (MELC) represent different stages of the ICM technological development. '''Imaging Cycler Microscopy''' received the American ISAC best paper award in 2008 for the three symbol code of organized proteomes.&lt;ref name=ref11&gt;{{cite journal|last=Schubert|first=Walter|title=A three-symbol code for organized proteomes based on cyclical imaging of protein locations|journal=Cytometry Part A|date=June 2007|volume=71A|issue=6|pages=352–360|doi=10.1002/cyto.a.20281|pmid=17326231}}&lt;/ref&gt;

[[File:Comparison of dimension-unlimited epifluorescence imaging cycler microscopy (ICM) and standard three-parameter fluorescence microscopy..jpg|thumbnail|right|Comparison of dimension-unlimited fluorescence imaging cycler microscopy (ICM) and standard three-parameter fluorescence microscopy.]]

==Citations==
{{Reflist}}

==References==
* [http://www.toposnomos.com/moviemaster.php?vid=leberzelle_video_black "3D all-organelle real time visualization of a single cell."]
* [http://www.toposnomos.com/moviemaster.php?vid=insideLeberCell_black "Visualizing the protein-DNA network code inside the cell nucleus."]

== Further reading==
*{{cite journal|last=Abott|first=A|title=Research highlights|journal=Nature|date=12 October 2006|volume=443|issue=7112|pages=608–609|doi=10.1038/443608a|bibcode=2006Natur.443..608.}}
*{{cite journal|last=Ademmer|author2=Ebert  |author3=Müller-Ostermeyer  |author4=Friess  |author5=Büchler  |author6=Schubert  |author7= Malfertheiner |title=Effector T lymphocyte subsets in human pancreatic cancer: detection of CD8+ CD18+ cells and CD8+ CD103+ cells by multi-epitope imaging|journal=Clinical and Experimental Immunology|date=April 1998|volume=112|issue=1|pages=21–26|doi=10.1046/j.1365-2249.1998.00546.x}}
*{{cite journal|last=Barysenka|first=Andrei|author2=Dress, Andreas W.M. |author3=Schubert, Walter |title=An information theoretic thresholding method for detecting protein colocalizations in stacks of fluorescence images|journal=Journal of Biotechnology|date=1 September 2010|volume=149|issue=3|pages=127–131|doi=10.1016/j.jbiotec.2010.01.009|pmid=20100525}}
*{{cite journal|last=Bedner|first=Elzbieta|author2=Du, Litong |author3=Traganos, Frank |author4= Darzynkiewicz, Zbigniew |title=Caffeine dissociates complexes between DNA and intercalating dyes: Application for bleaching fluorochrome-stained cells for their subsequent restaining and analysis by laser scanning cytometry|journal=Cytometry|date=1 January 2001|volume=43|issue=1|pages=38–45|doi=10.1002/1097-0320(20010101)43:1&lt;38::AID-CYTO1017&gt;3.0.CO;2-S|pmid=11122483}}
*{{cite journal|last=Berndt|first=Uta|author2=Philipsen, Lars |author3=Bartsch, Sebastian |author4=Hu, Yuqin |author5=Röcken, Christoph |author6=Bertram, Wiedenmann |author7=Hämmerle, Marcus |author8=Rösch, Thomas |author9= Sturm, Andreas  |title=Comparative Multi-Epitope-Ligand-Cartography reveals essential immunological alterations in Barrett's metaplasia and esophageal adenocarcinoma|journal=Molecular Cancer|year=2010|volume=9|issue=1|pages=177|doi=10.1186/1476-4598-9-177|pmid=20604962|pmc=2909181}}
*{{cite journal|last=Bhattacharya|first=Sayantan|author2=Mathew, George |author3=Ruban, Ernie |author4=Epstein, David B. A. |author5=Krusche, Andreas |author6=Hillert, Reyk |author7=Schubert, Walter |author8= Khan, Michael |title=Toponome Imaging System: Protein Network Mapping in Normal and Cancerous Colon from the Same Patient Reveals More than Five-Thousand Cancer Specific Protein Clusters and Their Subcellular Annotation by Using a Three Symbol Code|journal=Journal of Proteome Research|date=3 December 2010|volume=9|issue=12|pages=6112–6125|doi=10.1021/pr100157p |pmid=20822185}}
*{{cite journal|last1=Bode|first1=Marcus|author2=Irmler, Martin|author3=Friedenberger, Manuela|author4=May, Caroline|author5=Jung, Klaus|author6=Stephan, Christian|author7=Meyer, Helmut E.|author8=Lach, Christiane|author9=Hillert, Reyk|author10=Krusche, Andreas|author11=Beckers, Johannes|author12=Marcus, Katrin|author13=Schubert, Walter|title=Interlocking transcriptomics, proteomics and toponomics technologies for brain tissue analysis in murine hippocampus|journal=Proteomics|date=March 2008|volume=8|issue=6|pages=1170–1178|doi=10.1002/pmic.200700742|pmid=18283665}}
*{{cite journal|last1=Bonnekoh|first1=B.|author2=Böckelmann, R.|author3=Pommer, A.J.|author4=Malykh, Y.|author5=Philipsen, L.|author6=Gollnick, H.|title=The CD11a Binding Site of Efalizumab in Psoriatic Skin Tissue as Analyzed by Multi-Epitope Ligand Cartography Robot Technology|journal=Skin Pharmacology and Physiology|year=2007|volume=20|issue=2|pages=96–111|doi=10.1159/000097982|pmid=17167274}}
*{{cite journal|last=Bonnekoh|first=Bernd|author2=Malykh, Yanina |author3=Böckelmann, Raik |author4=Bartsch, Sebastian |author5=Pommer, Ansgar J. |author6= Gollnick, Harald. |title=Profiling lymphocyte subpopulations in peripheral blood under efalizumab treatment of psoriasis by multi epitope ligand cartography (MELC) robot microscopy|journal=Eur J Dermatol.|year=2006|volume=16|issue=6|pages=623–635|doi=10.1684/ejd.2006.0005|url=http://www.jle.com/en/revues/medecine/ejd/e-docs/00/04/28/34/article.phtml|doi-broken-date=2018-11-28}}
*{{cite journal|last=Bonnekoh|first=B.|author2=Pommer, A.J.|author3=Böckelmann, R.|author4=Hofmeister, H.|author5=Philipsen, L.|author6=Gollnick, H.|title=Topo-Proteomic in situ Analysis of Psoriatic Plaque under Efalizumab Treatment|journal=Skin Pharmacology and Physiology|year=2007|volume=20|issue=5|pages=237–252|doi=10.1159/000104422|pmid=17587888}}
*{{cite journal|last=Bonnekoh|first=Bernd|author2=Pommer, Ansgar J. |author3=Böckelmann, Raik |author4=Philipsen, Lars |author5=Hofmeister, Henning |author6= Gollnick, Harald |title=In-situ-topoproteome analysis of cutaneous lymphomas: Perspectives of assistance for dermatohistologic diagnostics by Multi Epitope Ligand Cartography (MELC)|journal=Journal der Deutschen Dermatologischen Gesellschaft|volume=6|issue=12|pages=1038–51|date=June 2008|doi=10.1111/j.1610-0387.2007.06754.x|pmid=18540979}}
*{{cite journal|last=Coste|first=O.|author2=Brenneis, C. |author3=Linke, B. |author4=Pierre, S. |author5=Maeurer, C. |author6=Becker, W. |author7=Schmidt, H. |author8=Gao, W. |author9=Geisslinger, G. |author10= Scholich, K. |title=Sphingosine 1-Phosphate Modulates Spinal Nociceptive Processing|journal=Journal of Biological Chemistry|date=10 September 2008|volume=283|issue=47|pages=32442–32451|doi=10.1074/jbc.M806410200 |pmid=18805787}}
*{{cite journal|last=Dress|first=Andreas W. M. |author2=Lokot, T. |author3=Pustyl’nikov, L. D. |author4=Schubert, W.|title=Poisson Numbers and Poisson Distributions in Subset Surprisology|journal=Annals of Combinatorics|date=January 2005|volume=8|issue=4|pages=473–485|doi=10.1007/s00026-004-0234-2}}
*{{cite journal|last=Dress|first=Andreas|author2=Lokot, Tatjana |author3=Schubert, Walter |author4= Serocka, Peter |title=Two Theorems about Similarity Maps|journal=Annals of Combinatorics|date=3 October 2008|volume=12|issue=3|pages=279–290|doi=10.1007/s00026-008-0351-4}}
*{{cite journal|last=Ebert|first=Matthias P.A.|author2=Ademmer, Karin |author3=Muller-Ostermeyer, Frauke |author4=Friess, Helmut |author5=Buchler, Markus W. |author6=Schubert, Walter |author7= Malfertheiner, Peter |title=CD8+CD103+ T cells analogous to intestinal intraepithelial lymphocytes infiltrate the pancreas in chronic pancreatitis|journal=The American Journal of Gastroenterology|date=November 1998|volume=93|issue=11|pages=2141–2147|doi=10.1111/j.1572-0241.1998.00610.x|pmid=9820387}}
*{{cite journal|last=Ecker|first=Rupert C.|author2=Rogojanu, Radu |author3=Streit, Marc |author4=Oesterreicher, Katja |author5= Steiner, Georg E. |title=An improved method for discrimination of cell populations in tissue sections using microscopy-based multicolor tissue cytometry|journal=Cytometry Part A|date=March 2006|volume=69A|issue=3|pages=119–123|doi=10.1002/cyto.a.20219|pmid=16479616}}
*{{cite journal|last=Eckhardt|first=J.|author2=Ostalecki, C. |author3=Kuczera, K. |author4=Schuler, G. |author5=Pommer, A. J. |author6= Lechmann, M. |title=Murine Whole-Organ Immune Cell Populations Revealed by Multi-epitope-Ligand Cartography|journal=Journal of Histochemistry &amp; Cytochemistry|date=16 November 2012|volume=61|issue=2|pages=125–133|doi=10.1369/0022155412470140|pmid=23160665|pmc=3636694}}
*{{cite journal|last=Eyerich|first=Kilian|author2=Böckelmann, Raik|author3=Pommer, Ansgar J.|author4=Foerster, Stefanie|author5=Hofmeister, Henning|author6=Huss-Marp, Johannes|author7=Cavani, Andrea; |author8=Behrendt, Heidrun|author9=Ring, Johannes|author10=Gollnick, Harald|author11=Bonnekoh, Bernd|author12=Traidl-Hoffmann, Claudia|title=Comparative in situ topoproteome analysis reveals differences in patch test-induced eczema: cytotoxicity-dominated nickel versus pleiotrope pollen reaction|journal=Experimental Dermatology|date=15 September 2009|volume=19|issue=6|pages=511–517|doi=10.1111/j.1600-0625.2009.00980.x|pmid=19758337}}
*{{cite book|last=Gieseler|first=A|title="Cell Membrane Toponomics" in Dubitzky, Wolkenhauer, Cho, Yokota. Encyclopedia of Systems Biology|year=2013|publisher=Springer New  York|isbn=978-1-4419-9862-0|pages=364–366|doi=10.1007/978-1-4419-9863-7_1568|chapter=Cell Membrane Toponomics}}
*{{cite book|last=Gieseler|first=A|title="Synaptic proteins" in Dubitzky, Wolkenhauer, Cho, Yokota. Encyclopedia of Systems Biology|year=2013|publisher=Springer New York|isbn=978-1-4419-9862-0|pages=2034–2036|doi=10.1007/978-1-4419-9863-7_632|chapter=Synaptic Proteins}}
*{{cite book|last=Gieseler|first=A|title="Synaptic toponome" in Dubitzky, Wolkenhauer, Cho, Yokota. Encyclopedia of Systems Biology|year=2013|publisher=Springer New York|isbn=978-1-4419-9862-0|pages=2036–2038|doi=10.1007/978-1-4419-9863-7_633|chapter=Synaptic Toponome}}
*{{cite journal|last=Haars|first=Regina|author2=Schneider, Abidat |author3=Bode, Marcus |author4= Schubert, W. |title=Secretion and differential localization of the proteolytic cleavage products Abeta40 and Abeta42 of the Alzheimer amyloid precursor protein in human fetal myogenic cells|journal=European Journal of Cell Biology|year=2000|volume=79|issue=6|pages=400–406|pmid=10928455 |doi=10.1078/0171-9335-00064}}
*{{cite journal|last=Herold|first=Julia|author2=Schubert, Walter |author3=Nattkemper, Tim W. |title=Automated detection and quantification of fluorescently labeled synapses in murine brain tissue sections for high throughput applications|journal=Journal of Biotechnology|date=15 September 2010|volume=149|issue=4|pages=299–309|doi=10.1016/j.jbiotec.2010.03.004|pmid=20230863}}
*{{cite book|last=Hillert|first=R|title="Combinatorial molecular phenotypes (CMPs)" in Dubitzky, Wolkenhauer, Cho, Yokota. Encyclopedia of Systems Biology|year=2013|publisher=Springer New York|isbn=978-1-4419-9862-0|pages=440–441|doi=10.1007/978-1-4419-9863-7_634|chapter=Combinatorial Molecular Phenotypes (CMPs)}}
*{{cite book|last=Hillert|first=R|title="Toponome analysis" in Dubitzky, Wolkenhauer, Cho, Yokota. Encyclopedia of Systems Biology|year=2013|publisher=Springer New York|isbn=978-1-4419-9862-0|pages=2188–2191|doi=10.1007/978-1-4419-9863-7_635|chapter=Toponome Analysis}}
*{{cite journal|last=Kovacheva|first=V. N.|author2=Khan, A. M. |author3=Khan, M. |author4=Epstein, D. B. A. |author5= Rajpoot, N. M. |title=DiSWOP: a novel measure for cell-level protein network analysis in localized proteomics image data|journal=Bioinformatics|date=21 November 2013|volume=30|issue=3|pages=420–427|doi=10.1093/bioinformatics/btt676 |pmid=24273247}}
*{{cite book|last=Krusche|first=A|title="TIS robot" in Dubitzky, Wolkenhauer, Cho, Yokota. Encyclopedia of Systems Biology|year=2013|publisher=Springer New York|isbn=978-1-4419-9862-0|pages=2172–2174|doi=10.1007/978-1-4419-9863-7_636|chapter=TIS Robot}}
*{{cite journal|last=Laffers|first=Wiebke|author2=Mittag, Anja |author3=Lenz, Dominik |author4=Tárnok, Attila |author5= Gerstner, Andreas O. H. |title=Iterative restaining as a pivotal tool for n-color immunophenotyping by slide-based cytometry|journal=Cytometry Part A|date=March 2006|volume=69A|issue=3|pages=127–130|doi=10.1002/cyto.a.20216|pmid=16479595}}
*{{cite journal|last=Mittag|first=Anja|author2=Lenz, Dominik |author3=Gerstner, Andreas O. H. |author4= Tárnok, Attila |title=Hyperchromatic cytometry principles for cytomics using slide based cytometry|journal=Cytometry Part A|date=July 2006|volume=69A|issue=7|pages=691–703|doi=10.1002/cyto.a.20285|pmid=16680709}}
*{{cite journal|last=Murphy|first=Robert F|title=Putting proteins on the map|journal=Nature Biotechnology|date=October 2006|volume=24|issue=10|pages=1223–1224|doi=10.1038/nbt1006-1223|pmid=17033657}}
*{{cite journal|last=Nattkemper|first=T.W.|author2=Ritter, H.J. |author3=Schubert, W. |title=A neural classifier enabling high-throughput topological analysis of lymphocytes in tissue sections|journal=IEEE Transactions on Information Technology in Biomedicine|date=June 2001|volume=5|issue=2|pages=138–149|doi=10.1109/4233.924804}}
*{{cite journal|last=Nattkemper|first=Tim W.|author2=Twellmann, Thorsten |author3=Ritter, Helge |author4= Schubert, Walter |title=Human vs. machine: evaluation of fluorescence micrographs|journal=Computers in Biology and Medicine|date=January 2003|volume=33|issue=1|pages=31–43|doi=10.1016/s0010-4825(02)00060-4|pmid=12485628|citeseerx=10.1.1.324.4664}}
*{{cite journal|last=Oeltze|first=S.|author2=Freiler, W. |author3=Hillert, Reyk |author4=Doleisch, Helmut |author5=Preim, Bernhard |author6= Schubert, Walter |title=Interactive, Graph-based Visual Analysis of High-dimensional, Multi-parameter Fluorescence Microscopy Data in Toponomics|journal=IEEE Transactions on Visualization and Computer Graphics|date=December 2011|volume=17|issue=12|pages=1882–1891|doi=10.1109/TVCG.2011.217|pmid=22034305}}
*{{cite journal|last=Ostalecki|first=Christian|author2=Konrad, Andreas |author3=Thurau, Elisabeth |author4=Schuler, Gerold |author5=Croner, Roland S. |author6=Pommer, Ansgar J. |author7= Stürzl, Mich ael |title=Combined multi-gene analysis at the RNA and protein levels in single FFPE tissue sections|journal=Experimental and Molecular Pathology|date=August 2013|volume=95|issue=1|pages=1–6|doi=10.1016/j.yexmp.2013.03.008|pmid=23583336}}
*{{cite journal|last=Philipsen|first=L.|author2=Engels, T. |author3=Schilling, K. |author4=Gurbiel, S. |author5=Fischer, K.-D. |author6=Tedford, K. |author7=Schraven, B. |author8=Gunzer, M. |author9= Reichardt, P.  |title=Multimolecular Analysis of Stable Immunological Synapses Reveals Sustained Recruitment and Sequential Assembly of Signaling Clusters|journal=Molecular &amp; Cellular Proteomics|date=10 June 2013|volume=12|issue=9|pages=2551–2567|doi=10.1074/mcp.M112.025205 |pmid=23754785 |pmc=3769330}}
*{{cite journal|last=Ruetze|first=Martin|author2=Gallinat, Stefan |author3=Wenck, Horst |author4=Deppert, Wolfgang |author5= Knott, Anja |title=In situ localization of epidermal stem cells using a novel multi epitope ligand cartography approach|journal=Integrative Biology|year=2010|volume=2|issue=5–6|pages=241–9|doi=10.1039/b926147h|pmid=20535415}}
*{{cite journal|last=Sage|first=Linda|title=The molecular face of prostate cancer|journal=Journal of Proteome Research|date=5 June 2009|volume=8|issue=6|pages=2616|doi=10.1021/pr9003129|pmid=19385645}}
*{{cite journal|last=Schmid|first=Eva M.|author2=McMahon, Harvey T.|title=Integrating molecular and network biology to decode endocytosis|journal=Nature|date=23 August 2007|volume=448|issue=7156|pages=883–888|doi=10.1038/nature06031|pmid=17713526|bibcode=2007Natur.448..883S}}
*{{cite journal|last=Schubert|first=Walter|title=Polymyositis, Topological Proteomics Technology and Paradigm for Cell Invasion Dynamics|journal=Journal of Theoretical Medicine|year=2002|volume=4|issue=1|pages=75–84|doi=10.1080/10273660290015224}}
*{{cite book|last=Schubert|first=W.|title=Topological Proteomics, Toponomics, MELK-Technology|journal=Adv Biochem Eng Biotechnol|year=2003|volume=83|pages=189–209|doi=10.1007/3-540-36459-5_8|pmid=12934931|series=Advances in Biochemical Engineering/Biotechnology|isbn=978-3-540-00546-9}}
*{{cite journal|last=Schubert|first=Walter|title=Cytomics in characterizing Toponomes: Towards the biological code of the cell|journal=Cytometry Part A|date=April 2006|volume=69A|issue=4|pages=209–211|doi=10.1002/cyto.a.20203|pmid=16498673}}
*{{cite journal|last=Schubert|first=Walter|title=Exploring molecular networks directly in the cell|journal=Cytometry Part A|date=March 2006|volume=69A|issue=3|pages=109–112|doi=10.1002/cyto.a.20234|pmid=16496422}}
*{{cite journal|last=Schubert|first=Walter|title=Breaking the biological code|journal=Cytometry Part A|date=October 2007|volume=71A|issue=10|pages=771–772|doi=10.1002/cyto.a.20466|pmid=17879221}}
*{{cite journal|last=Schubert|first=Walter|title=On the origin of cell functions encoded in the toponome|journal=Journal of Biotechnology|date=15 September 2010|volume=149|issue=4|pages=252–259|doi=10.1016/j.jbiotec.2010.03.009|pmid=20362632}}
*{{cite book|last=Schubert|first=W|title="Toponomanalyse" in Lottspeich, Engels. Bioanalytik|year=2012|publisher=Spektrum Heidelberg|isbn=978-3-8274-2942-1|pages=1139–1151|edition=3rd}}
*{{cite journal|last=Schubert|first=Walter|author2=Bode, Marcus |author3=Hillert, Reyk |author4=Krusche, Andreas |author5= Friedenberger, Manuela |title=Toponomics and neurotoponomics: a new way to medical systems biology|journal=Expert Review of Proteomics|date=April 2008|volume=5|issue=2|pages=361–369|doi=10.1586/14789450.5.2.361|pmid=18466063}}
*{{cite journal|last=Schubert|first=Walter|author2=Friedenberger, Manuela |author3=Bode, Marcus |author4=Krusche, Andreas |author5= Hillert, Reyk |title=Functional architecture of the cell nucleus: Towards comprehensive toponome reference maps of apoptosis|journal=Biochimica et Biophysica Acta (BBA) - Molecular Cell Research|date=November 2008|volume=1783|issue=11|pages=2080–2088|doi=10.1016/j.bbamcr.2008.07.019|pmid=18718492}}
*{{cite journal|last=Schubert|first=W.|author2=Friedenberger, M. |author3=Haars, R. |author4=Bode, M. |author5=Philipsen, L. |author6=Nattkemper, T. |author7= Ritter, H. |title=Automatic Recognition of Muscle-Invasive T-Lymphocytes Expressing Dipeptidyl-Peptidase IV (CD26) and Analysis of the Associated Cell Surface Phenotypes|journal=Journal of Theoretical Medicine|year=2002|volume=4|issue=1|pages=67–74|doi=10.1080/10273660290015189}}
*{{cite journal|last=Schubert|first=Walter|author2=Gieseler, Anne |author3=Krusche, Andreas |author4= Hillert, Reyk |title=Toponome Mapping in Prostate Cancer: Detection of 2000 Cell Surface Protein Clusters in a Single Tissue Section and Cell Type Specific Annotation by Using a Three Symbol Code|journal=Journal of Proteome Research|date=5 June 2009|volume=8|issue=6|pages=2696–2707|doi=10.1021/pr800944f |pmid=19275201}}
*{{cite journal|last=Schubert|first=Walter|author2=Gieseler, Anne |author3=Krusche, Andreas |author4=Serocka, Peter |author5= Hillert, Reyk |title=Next-generation biomarkers based on 100-parameter functional super-resolution microscopy TIS|journal=New Biotechnology|date=June 2012|volume=29|issue=5|pages=599–610|doi=10.1016/j.nbt.2011.12.004|pmid=22209707}}
*{{cite book|last=Schubert|first=W|title="Toponomics" in Dubitzky, Wolkenhauer, Cho, Yokota. Encyclopedia of Systems Biology|year=2013|publisher=Springer New York|isbn=978-1-4419-9862-0|pages=2191–2212|doi=10.1007/978-1-4419-9863-7_631|chapter=Toponomics}}
*{{cite journal|last=Schubert|first=Walter|title=Systematic, spatial imaging of large multimolecular assemblies and the emerging principles of supramolecular order in biological systems|journal=Journal of Molecular Recognition|date=January 2014|volume=27|issue=1|pages=3–18|doi=10.1002/jmr.2326|pmid=24375580|pmc=4283051}}
*{{cite book|last=Schubert|first=W.|author2=de Wit, N.C.J.|author3=Walden, P.|title="Systems Biology of Cancer" in Pelengaris, Khan. Molecular biology of cancer: a bridge from bench to bedside|year=2013|publisher=Wiley-Blackwell New York|isbn=978-1-118-02287-0|pages=554–584|edition=2nd}}

&lt;!--- STOP! Be warned that by using this process instead of Articles for Creation, this article is subject to scrutiny. As an article in "mainspace", it will be DELETED if there are problems, not just declined. If you wish to use AfC, please return to the Wizard and continue from there. ---&gt;

[[Category:Systems biology]]
[[Category:Bioinformatics]]
[[Category:Omics]]
[[Category:Topology]]</text>
      <sha1>mwi9aaqd2bclmhm8o8j7x43hfkhq9l5</sha1>
    </revision>
  </page>
  <page>
    <title>Infinite monkey theorem in popular culture</title>
    <ns>0</ns>
    <id>12653871</id>
    <revision>
      <id>866719524</id>
      <parentid>860107387</parentid>
      <timestamp>2018-11-01T03:02:42Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30187">{{refimprove|date=February 2012}}
[[Image:monkey-typing.jpg|thumb|250px|Given enough time, a hypothetical [[chimpanzee]] typing at random would, as part of its output, [[almost surely]] produce one of Shakespeare's plays (or any other text).]]

The '''[[infinite monkey theorem]]''' and its associated imagery is considered a [[popular culture|popular]] and [[proverb]]ial illustration of the mathematics of probability, widely known to the general public because of its transmission through '''popular culture''' rather than because of its transmission via the classroom.&lt;ref&gt;Examples of the theorem being referred to as proverbial include: [https://www.jstor.org/stable/1449463 Why Creativity Is Not like the Proverbial Typing Monkey] Jonathan W. Schooler, Sonya Dougal, ''Psychological Inquiry'', Vol. 10, No. 4 (1999); and ''The Case of the Midwife Toad'' ([[Arthur Koestler]], New York, 1972, page 30): ''"Neo-Darwinism does indeed carry the nineteenth-century brand of materialism to its extreme limits—to the proverbial monkey at the typewriter, hitting by pure chance on the proper keys to produce a Shakespeare sonnet."'' The latter is sourced from [http://www.angelfire.com/in/hypnosonic/Parable_of_the_Monkeys.html Parable of the Monkeys], a collection of historical references to the theorem in various formats.&lt;/ref&gt;

However, this popularity as either presented to or taken in the public's mind often oversimplifies or confuses important aspects of the different scales of the concepts involved: '''infinity''', '''probability''', and '''time'''—all of these are in measures beyond average human experience and practical comprehension or comparison.

==Popularity==
The history of the imagery of "typing monkeys" dates back at least as far as [[Émile Borel]]'s use of the metaphor in his essay in 1913, and this imagery has recurred many times since in a variety of media.

*The Hoffmann and Hofmann paper (2001) referenced a collection compiled by Jim Reeds, titled "The Parable of the Monkeys – a.k.a. The Topos of the Monkeys and the Typewriters".&lt;ref&gt;[http://www.angelfire.com/in/hypnosonic/Parable_of_the_Monkeys.html "The Parable of the Monkeys"], as of 2007, is hosted at the website of the experimental music/dance/performance art group [http://www.angelfire.com/in/hypnosonic/ "Infinite Monkeys"].&lt;/ref&gt;
*The enduring, widespread and popular nature of the knowledge of the theorem was noted in a 2001 paper, "Monkeys, Typewriters and Networks – the Internet in the Light of the Theory of Accidental Excellence". In their introduction to that paper, Hoffmann and Hofmann stated: "The Internet is home to a vast assortment of quotations and experimental designs concerning monkeys and typewriters. They all expand on the theory […] that if an infinite number of monkeys were left to bang on an infinite number of typewriters, sooner or later they would accidentally reproduce the complete works of William Shakespeare (or even just one of his sonnets)."&lt;ref&gt;[http://skylla.wz-berlin.de/pdf/2002/ii02-101.pdf Monkeys, Typewriters and Networks] {{webarchive|url=https://web.archive.org/web/20080513012236/http://skylla.wz-berlin.de/pdf/2002/ii02-101.pdf |date=2008-05-13 }}, Ute Hoffmann &amp; Jeanette Hofmann, Wissenschaftszentrum Berlin für Sozialforschung gGmbH (WZB), 2001.&lt;/ref&gt;
*In 2002, a ''[[Washington Post]]'' article said: "Plenty of people have had fun with the famous notion that an infinite number of monkeys with an infinite number of typewriters and an infinite amount of time could eventually write the works of Shakespeare".&lt;ref&gt;[https://www.washingtonpost.com/ac2/wp-dyn/A28521-2002Oct27?language=printer "Hello? This is Bob"], Ken Ringle, ''Washington Post'', 28 October 2002, page C01.&lt;/ref&gt;
*In 2003, an [[Arts Council England|Arts Council]] funded experiment involving real monkeys and a computer keyboard received widespread press coverage.&lt;ref&gt;[http://www.vivaria.net/experiments/notes/documentation/press/ "Notes Towards the Complete Works of Shakespeare"] {{Webarchive|url=https://web.archive.org/web/20070716153346/http://www.vivaria.net/experiments/notes/documentation/press/ |date=2007-07-16 }} – some press clippings.&lt;/ref&gt;
*In 2007, the theorem was listed by ''[[Wired (magazine)|Wired]]'' magazine in a list of eight classic [[thought experiment]]s.&lt;ref&gt;Greta Lorge, [https://www.wired.com/science/discoveries/magazine/15-06/st_best "The Best Thought Experiments: Schrödinger's Cat, Borel's Monkeys"], ''Wired'' Issue 15.06, May 2007.&lt;/ref&gt;
*Another study of the history was published in the introduction to a study published in 2007 by Terry Butler, "Monkeying Around with Text".&lt;ref&gt;Terry Butler, 
[http://www.chass.utoronto.ca/epc/chwp/CHC2005/Butler/Butler.htm "Monkeying Around with Text"], University of Alberta, ''Computing in the Humanities Working Papers'', 2007.&lt;/ref&gt;

Today, popular interest in the typing monkeys is sustained by numerous appearances in literature, television and radio, music, and the Internet, as well as graphic novels and stand-up comedy routines. Several collections of cultural references to the theorem have been published.

The following thematic timelines are based on these existing collections. The timelines are not comprehensive – instead, they document notable examples of references to the theorem appearing in various media.&lt;ref&gt;The examples included invariably refer directly to a variation on the theme of a large number of typing monkeys producing a work of literature, usually, but not always, a work by Shakespeare. Infinite libraries, and random text generation (instead of monkeys) are also included. Trivial or incomplete references are excluded.&lt;/ref&gt; The initial timeline starts with some of the early history following Borel, and the later timelines record examples of the history, from the stories by Maloney and Borges in the 1940s, up to the present day.

==Early history==
*1913 – [[Émile Borel|Émile Borel’s]] essay – “Mécanique Statistique et Irréversibilité”
*1928 – [[Arthur Stanley Eddington|Arthur Eddington’s]] book – ''The Nature of the Physical World''
*1931 – [[James Jean|James Jean’s]] book – ''The Mysterious Universe''
*1939 – [[Jorge Luis Borges]]' essay – “[[Infinite monkey theorem#Origins and "The Total Library"|The Total Library]]”

==Literature==
*1940 – In "Inflexible Logic" by Russell Maloney, a short story that appeared in ''[[The New Yorker]]'', the protagonist felt that his wealth put him under an obligation to support the [[science]]s, and so he tested the theory. His monkeys immediately set to work typing, without error, classics of fiction and nonfiction. The rich man was amused to see unexpurgated versions of [[Samuel Pepys]]' diaries, of which he owned only a copy of a [[expurgation|bowdlerise]]d edition.&lt;ref&gt;[http://math.cofc.edu/kasman/MATHFICT/mfview.php?callnumber=mf99 Inflexible Logic] {{webarchive|url=https://web.archive.org/web/20070805082643/http://math.cofc.edu/kasman/MATHFICT/mfview.php?callnumber=mf99 |date=2007-08-05 }}, synopsis at the Mathematical Fiction database.&lt;/ref&gt;&lt;ref&gt;The story was reprinted in the classic four-volume ''The World of Mathematics'' by [[James R. Newman]], published in 1956.&lt;/ref&gt;
*1969 - "Uncollected Works", a short story by [[Lin Carter]], describes a machine that rapidly simulates the infinite monkeys with the result that it generates the sum total of human writing from first principles, and onward into the future.
*1970 – A humorous [[short story]] by [[R. A. Lafferty]], "Been a Long, Long Time" (''[[Fantastic (magazine)|Fantastic]]'', December), tells the story of an angel who is punished by having to supervise (for trillions of years) randomly typing monkeys who are attempting to produce a perfect copy of the collected works of Shakespeare.&lt;ref&gt;[http://math.cofc.edu/kasman/MATHFICT/mfview.php?callnumber=mf464 Been a long, long time] {{webarchive|url=https://web.archive.org/web/20070808185150/http://math.cofc.edu/kasman/MATHFICT/mfview.php?callnumber=mf464 |date=2007-08-08 }}, synopsis by Fred Galvin, at the Mathematical Fiction database.&lt;/ref&gt;
*1979 – Chapter XXIII of [[The Neverending Story]] by [[Michael Ende]] describes a city full of people that have lost their memories, overseen by a monkey. The monkey entertains these people by letting them play a game of dice with letters on them. The monkey explains that since these people have lost their capability to write stories themselves, the game will make it possible for them to produce sentences, stories, or poems by pure chance. Eventually this game would produce any story ever told, including the Neverending Story itself.
*1987 – In the one-act [[theatre|play]] ''[[Words, Words, Words]]'' by [[David Ives]], three monkeys named [[John Milton|Milton]], [[Jonathan Swift|Swift]], and [[Franz Kafka|Kafka]] have been confined to a cage by a Dr Rosenbaum, who has the hypothesis: "Three monkeys hitting keys at random on typewriters for an infinite amount of time will almost surely produce ''[[Hamlet]]''." The play's humour mainly involves literary references, including moments when the random typing produces passages from great works of literature. The play premiered in January 1987, and is still being performed almost 30 years later.&lt;ref&gt;[http://theater2.nytimes.com/mem/theater/treview.html?res=9B0DE5D71630F936A25752C0A961948260  The Stage: One-acts at Punchline], Mel Gussow, ''[[The New York Times]]'', 15 January 1987.&lt;/ref&gt;&lt;ref&gt;[http://www.eugeneweekly.com/2006/04/06/theater.html It's All in the Laughing, All in the Timing will have you in stitches], review by Melissa Bearns for Eugene Weekly, 4 June 2006.&lt;/ref&gt;
*1996 – In Jim Cowan's short story "The Spade of Reason" (published in ''Century'' 4, 1996), the main character seeks to find meaning in the universe through text randomly generated through various means; the original program he uses to do so is something he dubs the "Motorola Monkey".*
*2001 - In [[Fooled by Randomness]], [[Nassim Nicholas Taleb]] used it as an example of the role of randomness.

==Motion pictures==
*1959 – In the film ''[[On the Beach (1959 film)|On the Beach]]'', when wireless Morse code signals are detected by radio operators on the submarine, the commander mentions "the old story about an infinite number of monkeys and an infinite number of typewriters", and that "one of them has to end up writing ''[[King Lear]]''".

==Radio and television==
*1978 – In his radio play, ''[[The Hitchhiker's Guide to the Galaxy]]'', [[Douglas Adams]] invoked the theorem to illustrate the power of the ‘Infinite Improbability Drive’ that powered a spaceship. From Episode 2: "[[Ford Prefect (character)|Ford]], there’s an infinite number of monkeys outside who want to talk to us about this script for [[Hamlet]] they’ve worked out".
*1983 – In the ''[[Doctor Who]]'' episode "[[Mawdryn Undead]]", the Doctor mentions the theorem in passing (quoting it as "a treeful of monkeys"), stating to [[Tegan Jovanka|Tegan]] that "you and I both know, at the end of a millennium they'd still be tapping out gibberish." Tegan's response: "And you'd be tapping it out right alongside them."
*1993 – In ''[[The Simpsons]]'' episode "[[Last Exit to Springfield]]", [[Montgomery Burns]] has his own room with 1000 monkeys at typewriters, one of which he chastises for mistyping a word in the opening sentence of ''[[A Tale of Two Cities]]'': &lt;blockquote&gt; "'It was the best of times, it was the ''blurst'' of times?' You stupid monkey!"&lt;ref&gt;{{cite web|url=http://www.simpsoncrazy.com/information/scripts/9f15.shtml |title=Last Exit To Springfield |publisher=Simpson Crazy |archiveurl=https://web.archive.org/web/20080819201126/http://www.simpsoncrazy.com/information/scripts/9f15.shtml |archivedate=19 August 2008 |deadurl=yes |df= }}&lt;/ref&gt;&lt;ref&gt;[http://www.pressconnects.com/apps/pbcs.dll/article?AID=/20070727/LIFESTYLE/707270303/1004/LIFESTYLE Woo-hoo! A look at the 10 best 'Simpsons' episodes ever]{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}, Press &amp; Sun-Bulletin, 27 July 2007. "The genius of this joke is a child can laugh at it, but those who understand the allusion to Charles Dickens and the infinite monkey theorem can laugh on another level."{{Dead link|date=January 2009}}&lt;/ref&gt;
*1998 – An advertisement for Molson Canadian beer depicts an array of typing chimpanzees filling a seemingly endless cathedral-like structure while a voice-over sardonically asks "Could an infinite number of monkeys on an infinite number of typewriters eventually define what it is to be Canadian?" &lt;ref&gt;"Molson Monkeys", ''Advertising Age'', June 1998&lt;/ref&gt;
*1998 – In the "Battle of the Sexists" episode of ''[[That '70s Show]]'', [[Eric Forman]] yells after his girlfriend [[Donna Pinciotti]] scored during a game of basketball:&lt;blockquote&gt;"Pinciotti actually scores! Hell freezes over! A monkey types Hamlet!"&lt;/blockquote&gt;
*1998 – In the animated series ''[[Fat Dog Mendoza]]'', one of the series main villains, Doctor Rectangle, keeps a basement full of monkeys typing away on typewriters.  The [[running gag]] is that Doctor Rectangle mistakenly believes that he can directly and practically use the infinite monkey theorem, using real monkeys and typewriters, to create a great work of literature or come up with a plan that will make him famous and/or powerful.  It is also believed that, unbeknown to Doctor Rectangle, the monkeys are in fact very intelligent and just type things at random to amuse themselves and receive a steady income of bananas.
*1999 – The infinite monkey theorem is the subject of a brief sketch in the ''[[Histeria!]]'' episode "Super Writers".
*1999 – "A Troo Storee", an episode of ''[[I Am Weasel]]'', features a large room filled with several types of monkeys with typewriters who are working on a novel. When Weasel tries to pay them in bananas, they consider it an insult and quit their job, all except for Baboon.&lt;ref&gt;[http://www.tv.com/i-am-weasel/a-troo-storee/episode/170385/summary.html?tag=ep_list;ep_title;22 "A Troo Storee"], TV.com episode guide: "Weasel tries to test the "monkeys typing Shakespeare" theorem".&lt;/ref&gt;
*2000 – In the ''[[Family Guy]]'' episode "[[The King Is Dead (Family Guy)|The King is Dead]]", [[Lois Griffin|Lois]] questions [[Peter Griffin|Peter]]'s creativity, to which he replies:&lt;blockquote&gt;"Oh, art-schmart. Put enough monkeys in a room with a typewriter they'll produce Shakespeare."&lt;/blockquote&gt; The scene then cuts to several monkeys in a room, arguing over which flower is most appropriate in the famous line from ''[[Romeo and Juliet]]''.&lt;ref&gt;[http://www.familyguy.com/search/index.php?cat=flash&amp;id=127 Family Guy official website] – script of the "Monkeys Writing Shakespeare" scene. {{webarchive |url=https://web.archive.org/web/20060623145132/http://www.familyguy.com/search/index.php?cat=flash&amp;id=127 |date=June 23, 2006 }}&lt;/ref&gt;
*2001 – In the sixth episode of the first season of ''[[The Ricky Gervais Show]]'', comedian [[Ricky Gervais]] tries to explain this theorem to [[Karl Pilkington]], who refuses to believe it possible. In attempting to explain the mathematics behind the theorem, Gervais eventually gives up and storms out of the room when, after a long explication by Gervais and [[Stephen Merchant]], Karl says, "If they haven't even read Shakespeare, how do they know what they're doin?"&lt;ref&gt;[http://www.xfm.co.uk/Article.asp?id=25769 XFM archives] "Season 1 Vol. 6", "Do you know what he said to me? I explained it to him, I said 'You've got an infinite number of monkeys, an infinite number of typewriters, they will type the complete works of Shakespeare.' He said, 'Have they read Shakespeare?'"&lt;/ref&gt;
*2004 – In "The Science Fair Affair" episode of ''[[The Adventures of Jimmy Neutron: Boy Genius]]'', Sheen's science fair project is having an iguana sprawled on a typewriter under the assumption that it will "write the next great American novel".
*2005 – At the end of the ''[[Robot Chicken]]'' episode "Badunkadunk", the [[Stoopid Monkey]] production logo's background is made up of upside-down text pertaining to the Infinite Monkey Theorem.&lt;ref&gt;[http://www.robotchicken.info/gallery/view_photo.php?set_albumName=Stoop%21d_Monkey&amp;id=Stoop_d_Monkey_Badunkadunk The Robot Chicken Wiki] – Screenshot of ''Robot Chicken'' Stoopid Monkey production logo that refers to the Infinite Monkey Theorem&lt;/ref&gt;
*2005 – In the ''[[Veronica Mars]]'' episode "[[Cheatty Cheatty Bang Bang]]", Veronica, commenting on the sudden realization she did know David 'Curly' Moran says: &lt;blockquote&gt;"Somewhere, those million chimps, with their million typewriters, must've written [[King Lear]]."&lt;/blockquote&gt;
*2006 – In June 2006, ''[[The Colbert Report]]'' featured a humorous segment on how many monkeys it would take for various works. This was in response to comments made in the news on monkeys typing out the [[Bible]] or the [[Qur'an]]. According to Colbert, one million monkeys typing for eternity would produce Shakespeare, ten thousand (drinking) monkeys typing for ten thousand years would produce [[Ernest Hemingway|Hemingway]], and ten monkeys typing for three days would produce a work of [[Dan Brown]].
*2007 – In an episode of the daytime soap opera ''[[The Young and the Restless]]'' (broadcast January and February 2007 in Canada and the USA), when [[Colleen Carlton]] copies scrambled letters obtained from the Grugeon [[Reliquary]] onto a dry board, Professor [[Adrian Korbel]] jokingly asks if she's testing the Infinite Monkey Theorem. When asked what this is, he replies:&lt;blockquote&gt; "Thomas Henry Huxley said if you gave keyboards to an infinite amount of monkeys, and gave said monkeys an infinite amount of time… Well it is safe to say…you are not the magic monkey." &lt;ref&gt;[http://tvmegasite.net/day/yr/transcripts/older/2007/yr-trans-02-01-07.shtml Episode transcript] {{webarchive|url=https://web.archive.org/web/20071112051339/http://tvmegasite.net/day/yr/transcripts/older/2007/yr-trans-02-01-07.shtml |date=2007-11-12 }}, at tvmegasite.net&lt;/ref&gt;&lt;/blockquote&gt;
*2009 – ''[[The Infinite Monkey Cage]]'' is a "Witty, irreverent look at the world through scientists eyes. With Brian Cox and Robin Ince" on Radio 4 on the BBC.&lt;ref&gt;http://www.bbc.co.uk/programmes/b00p29l8&lt;/ref&gt;
*2010 – BBC Horizon, To Infinity And Beyond
*2011 – on an episode of the topical comedy programme ''[[Mock the Week]]'', Comedian [[Micky Flanagan]] references it in a segment of "Scenes We'd Like to See."
*2013 - presented in the philosophical thriller ''[[After the Dark]]'' referenced prior to the second experiment
*2016 - In an episode of ''[[Downton Abbey]]'', Lady Mary remarks, “A monkey could type out the Bible if you leave it long enough.”

==Video games==
*2000 – When talking to Inspector Canard in ''[[Escape from Monkey Island]]'', he says that "if [he] had a monkey for every time some penny-ante crook tried to pin their criminal malfeasance on Pegnose Pete...[he would] have enough monkeys to work out a reasonable sequel to Hamlet by now."
*2004 – During a cutscene in ''[[Killzone]]'', Colonel Hakha says to Rico during an argument, "Even a monkey will write Shakespeare if given enough time".

==Comics and graphic novels==
*1981 – ''Fone'', a science fiction comic by [[Milo Manara]].
*1989 – In the comic strip ''[[Dilbert]]'', [[Dogbert]] tells [[Dilbert (character)|Dilbert]] that his poem would take "three monkeys, ten minutes".&lt;ref&gt;http://dilbert.com/strips/comic/1989-05-15/&lt;/ref&gt;
*1990 – The ''[[Animal Man#Revival|Animal Man]]'' comic by [[Grant Morrison]] (a revival of the [[Animal Man]] DC character) contained an issue (''Monkey Puzzles'') including a monkey who typed not only the works of Shakespeare, but comic books as well. The [[Trade paperback (comics)|TPB]] this issue is collected in (''Deus ex Machina'' – 2003) featured an "infinite" number of Grant Morrisons typing on the cover.&lt;ref&gt;[http://www.io.com/~woodward/chroma/crtanimal.html Grant Morrison's Animal Man #8-26], Jonathan Woodward, "Issue #25, July '90: "Monkey Puzzles" […] The text in the typewriter is Morrison's script for this issue. The monkey, of course, is the famous one who, given an infinite amount of time, will eventually write out the complete Shakespeare, completely at random."&lt;/ref&gt;&lt;ref&gt;[https://www.amazon.com/dp/images/156389968X Animal Man, Book 3 – Deus Ex Machina (Paperback)], Amazon.com scan of the book cover.&lt;/ref&gt;
*2008 – The cartoonist [[Ruben Bolling]] satirized the thought experiment in his ''[[Tom the Dancing Bug]]'' cartoon, with a monkey asking "How can I credibly delay Hamlet's revenge until Act V" in the final frame.&lt;ref&gt;[http://www.gocomics.com/tomthedancingbug/2008/07/12/ "Tom the Dancing Bug July 2008]&lt;/ref&gt;
*2008 – In a comic book written by [[Scott McCloud]] about [[Google Chrome]], monkeys on laptops are used as an analogy to random data.&lt;ref&gt;{{cite web|url= https://www.google.com/googlebooks/chrome/#size=big&amp;page=10 |title= Google Chrome |accessdate= 2008-09-04}}&lt;/ref&gt;
*2009 – In the graphic novel &lt;!--REDLINK--&gt;''[[Umineko: When They Cry]]'', Bernkastel was involved in a situation which had her make a miracle out of a nearly impossible situation. This was compared to the monkey theorem, trying at random to obtain a miracle that had an incredibly low chance.

==Software and internet culture==
*1979 – [[Apple Computer]] released [[Bruce Tognazzini]]'s [https://www.youtube.com/watch?v=IfMDWhc_ohU "The Infinite No. Of Monkeys"], a humorous demonstration of Apple BASIC, on their DOS 3.2 disk for the Apple II computer.
*1995 – "The famous Brett Watson" published his Internet paper, [https://web.archive.org/web/20150414231327/http://www.nutters.org/docs/monkeys "The Mathematics of Monkeys and Shakespeare"] which was, in 2000, to be included as a reference in RFC 2795 (see below)
*1996 – Robert Wilensky once jocularly remarked, "We've all heard that a million monkeys banging on a million typewriters will eventually reproduce the entire works of Shakespeare. Now, thanks to the Internet, we know this is not true." This version of the internet analogy "began appearing as a very frequent email and web-page epigraph starting in 1997".[http://www.angelfire.com/in/hypnosonic/Parable_of_the_Monkeys.html]
** A variant appeared in USENET at about the same time: "The Experiment has begun! A million monkeys and a million keyboards.  We call it USENET."{{Citation needed|date=March 2010}}
*2000 – The [[Internet Engineering Task Force|IETF]] Internet standards committee's [[April Fools' Day RFC]] proposed an "Infinite Monkey Protocol Suite (IMPS)", a method of directing a farm of infinitely many monkeys over the Internet.&lt;ref&gt;{{cite web | title=RFC 2795: The Infinite Monkey Protocol Suite (IMPS) | author=S. Christey | url=http://tools.ietf.org/html/2795 | date= 1 April 2000 | accessdate=2006-06-13}}&lt;/ref&gt;
*2005 – ''[[Goats (webcomic)|Goats]]'', a [[webcomic]] illustrated by [[Jonathan Rosenberg (webcomic artist)|Jonathan Rosenberg]], started in August 2005 an ongoing story line named ''[https://web.archive.org/web/20070101152515/http://www.goats.com/archive/050718.html infinite typewriters]'' where several characters accidentally teleport to an alternate dimension. There they find that this dimension is populated by monkeys with typewriters, presumably typing the scripts of many other dimensions.
*2006 – The Infinite Monkey Project was launched by predictive text company T9. The Europe-wide project sees users, unknown to each other, text a word of their choosing to the Website. The text message is free and as it continues the words are combined to form lyrics. The lyrics are then made into a song by the Hip Hop artist Sparo which will be released as an album. If any of the tracks becomes a hit the people who texted in the words for the lyrics will receive royalties from the project.&lt;ref&gt;{{cite web|url=http://www.computermusic.co.uk/page/computermusic?entry=monkeys|title=The articulate monkeys|publisher=Computer Music|accessdate=2006-11-09}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.pocket-lint.co.uk/news/news.phtml/5299/6323/Infinite-Infinite-Project-t9-texting.phtml|title=Infinite Monkey Project wants your texts|publisher=Pocket-lint|accessdate=2006-11-09}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.caughtinthecrossfire.com/music/news/2445|title=The Infinite Monkey Project|publisher=Crossfire|accessdate=2006-11-09}}&lt;/ref&gt;
*2007 – A website named One Million Monkeys Typing was introduced, a [[collaborative writing]] site where anyone can sign up and add writing "snippets" that others can add on to, eventually creating stories with many outcomes.
*2008 – An issue of [[Mad (magazine)|MAD]] shows a depiction of the Infinite Monkey Theorem which states that when good monkeys go bad, one of the infinite monkeys would surely plagiarize ''[[A Tale of Two Cities]]''.
*2008 – Monkeys are depicted typing random bits of text in Google's online comic book advertising their [[Google Chrome]] Web Browser.&lt;ref&gt;{{cite web|url=https://www.google.com/googlebooks/chrome/big_10.html|title=10th Page of Google Chrome comic book.}}&lt;/ref&gt;
*2009 – ''[http://www.infinitecomic.com Infinite Monkey Comics]'' was launched, which features a random comic generator that creates three-panel comics by placing a random tweet from Twitter over a random image from Flickr based on keywords of the user's choosing. The result is a nearly inexhaustible collection of potential comics generated by the random musings and typing of internet users.
*2009 – ''[http://www.mwt-studios.com Monkeys With Typewriters]'' draws its namesake from the theorem.
*2010 – ''[https://web.archive.org/web/20100821121850/http://behind.lyrois.com/2010/06/free-e-book-beating-million-monkeys.html Lyrois Beating a Million Monkeys]'' a somewhat sarcastic look at contemporary art uses the monkeys as a metaphor.
*2011 – ''[http://www.shakespearean-monkeys.com www.shakespearean-monkeys.com]'' a social literature website, where the users are the monkeys.
*2015 - ''[http://goofyxgridathome.net/ GoofyxGrid@Home]'' is a [[BOINC]] project that checks for the Infinite Monkey Theorem by using the distributed computing software [[BOINC]]

==Stand-up comedy==
*1960 onwards – [[Comedian]] [[Bob Newhart]] had a [[stand-up comedy|stand-up]] routine in which a lab technician monitoring an "infinitely many monkeys" experiment discovered that one of the monkeys has typed something of interest. A typical punchline would be: "Hey, Harry! This one looks a little famous: 'To be or not to be – that is the gggzornonplatt.'"&lt;ref&gt;[https://www.washingtonpost.com/ac2/wp-dyn/A28521-2002Oct27?language=printer "Hello? This is Bob"], Ken Ringle, ''Washington Post'', 28 October 2002, page C01.&lt;/ref&gt;&lt;ref&gt;[http://aroundcny.com/technofile/texts/compupoet85.html Flashback: Computer poetry from 1985], Al Fasoldt, ''The Syracuse Newspapers'', 1985.&lt;/ref&gt;&lt;ref&gt;The date of 1960 is given in [http://www.chass.utoronto.ca/epc/chwp/CHC2005/Butler/Butler.htm Monkeying Around with Text], Terry Butler, University of Alberta, ''Computing in the Humanities Working Papers'', January 2007.&lt;/ref&gt;

==Music==
*1979 – The debut album by Leeds [[punk rock]] band [[the Mekons]] is called [[The Quality of Mercy Is Not Strnen]] (1979). Originally released on [[Virgin Records]] in the United Kingdom, its cover features a photo, not of a monkey, but of a typing [[chimpanzee]]. The title refers to [[The Quality of Mercy (Shakespeare quote)|a Shakespeare quote]] from [[The Merchant of Venice]]: ''"The quality of mercy is not strain'd"''.&lt;ref&gt;[http://www.mekons.de/mercy.htm Mekons fansite] – picture and commentary on the album and cover: "This unusual title was drawn from the axiom that, if you give a monkey a typewriter and an infinite amount of time, it would eventually produce the complete works of Shakespeare, a wry comment on the group's own musical ability. The rest of the Shakespeare quote appears on the Mekons Story". The last sentence refers to the later collection ''The Mekons Story'', which included the song 'It Falleth Like Gentle Rain from Heaven'.&lt;/ref&gt;
*1982 - The song "Conspiracy" by [[The Higsons]] contains the line: "Who wrote The [[Bible]]? Monkeys typed The Bible".
*1989 - The band Timbuk3's critically acclaimed album "Edge of Allegiance" included the song "Don't Give Up on Me," which contains the lyrics: "They say that a monkey, in the right frame of mind, given enough paper, and given enough time, is bound to type Shakespeare eventually, oh baby, don't give up on me."
*1989 –  The band [[Negativland]] sampled [[Estus Pirkle]] on their album [[Helter Stupid]] (1989) saying, "If you get enough monkeys, enough typewriters, and enough bread, one of them will eventually come up with the [[Authorized King James Version|King James Version]] of the [[Bible]]!!!" while to chants of "We don't have enough data. We just don't have enough data" said by a Japanese secretary.
*2002 – Hip Hop Artist [[El-P]] references the theorem in rhyme with "see me as a banshee, as the illest motherfucker since Oedipus / monkey number one million with a typewriter, flipping tempest text" on "Truancy" from the album "[[Fantastic Damage]]"
*2007 – [[Robot Goes Here]], an electronic rock band on [http://www.infidelrecords.com Infidel Records], recorded ''The Infinite Monkey Theorem'' (2007) featuring a chorus with the lyrics, "Got a pet monkey down in the basement, chained to a typewriter pounding away, churning out copies of the works of [[Shakespeare]]; halfway through [[Hamlet]] he wrote me this song."

==See also==
* [[Extreme value theory#Models for exceedances|Model for a rare event comparison]]

==References and notes==
&lt;!--This article uses the Cite.php citation mechanism. If you would like more information on how to add references to this article, please see http://meta.wikimedia.org/wiki/Cite/Cite.php --&gt;
{{Reflist|2}}

==External links==
* [http://www.angelfire.com/in/hypnosonic/Parable_of_the_Monkeys.html The Parable of the Monkeys], a bibliography with quotations

[[Category:Mathematics-related topics in popular culture]]</text>
      <sha1>eac84q64epywzjmfhg9que00stxl060</sha1>
    </revision>
  </page>
  <page>
    <title>International Congress on Mathematical Physics</title>
    <ns>0</ns>
    <id>23897905</id>
    <revision>
      <id>810394632</id>
      <parentid>675635758</parentid>
      <timestamp>2017-11-15T00:10:58Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.1)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1257">{{Use dmy dates|date=July 2013}}
{{unreferenced|date=September 2009}}
The '''International Congress on Mathematical Physics''' (ICMP) is the largest research congress in [[mathematical physics]]. It is held every three years, on behalf of the [[International Association of Mathematical Physics]] (IAMP).

== Prizes ==
The [[Henri Poincaré Prize]] and the IAMP early career award are both delivered at the ICMP.

== List of IAMP Congresses (ICMP) ==
1972: [[Moscow]]&lt;br /&gt;
1974: [[Warsaw]]&lt;br /&gt;
1975: [[Kyoto]]&lt;br /&gt;
1977: [[Rome]]&lt;br /&gt;
1979: [[Lausanne]]&lt;br /&gt;
1981: [[Berlin]]&lt;br /&gt;
1983: [[Boulder]]&lt;br /&gt;
1986: [[Marseille]]&lt;br /&gt;
1988: [[Swansea]]&lt;br /&gt;
1991: [[Leipzig]]&lt;br /&gt;
1994: [[Paris]]&lt;br /&gt;
1997: [[Brisbane]] ([https://web.archive.org/web/20091224131034/http://www.maths.uq.edu.au/~icmp97/ website])&lt;br /&gt;
2000: [[London]]&lt;br /&gt;
2003: [[Lisbon]] ([http://icmp2003.net website])&lt;br /&gt;
2006: [[Rio de Janeiro]] ([http://www.impa.br/opencms/pt/eventos/store_old/evento_0005.html website])&lt;br /&gt;
2009: [[Prague]] ([http://icmp.ujf.cas.cz/ website])&lt;br /&gt;
2012: [[Aalborg]] ([http://www.icmp12.com website])&lt;br /&gt;
2015: [[Santiago]] ([http://www.icmp2015.cl website])&lt;br /&gt;

[[Category:Mathematics conferences]]
[[Category:Physics conferences]]</text>
      <sha1>k822onif8a6esoio5ehgx5mqoqemr5m</sha1>
    </revision>
  </page>
  <page>
    <title>Isoline retrieval</title>
    <ns>0</ns>
    <id>27586152</id>
    <revision>
      <id>855916084</id>
      <parentid>846643762</parentid>
      <timestamp>2018-08-21T17:53:43Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9337">'''Isoline retrieval''' is a [[remote sensing]] [[Inverse problem|inverse method]] that retrieves one or more [[Contour line|isoline]]s of a trace atmospheric constituent or variable. When used to validate another contour, it is the most accurate method possible for the task.  When used to retrieve a whole field, it is a general, nonlinear inverse method and a robust estimator.

==For validating advected contours==
===Rationale===

Suppose we have, as in [[contour advection]], inferred knowledge of a
single contour or isoline of an atmospheric constituent, ''q''
and we wish to validate this against satellite remote-sensing data.
Since satellite instruments cannot measure the constituent directly,
we need to perform some sort of inversion.
In order to validate the contour, it is not necessary to know,
at any given point, the exact value of the constituent.  We only need to
know whether it falls inside or outside, that is, is it greater
than or less than the value of the contour, ''q&lt;sub&gt;0&lt;/sub&gt;''.

This is a classification problem.  Let:

: &lt;math&gt;
j = \begin{cases} 1; &amp; q &lt; q_0 \\
		2; &amp; q \geq q_0\end{cases}
&lt;/math&gt;

be the discretized variable.
This will be related to the satellite ''measurement vector'', &lt;math&gt;\vec y&lt;/math&gt;,
by some conditional probability, &lt;math&gt;P(\vec y|j)&lt;/math&gt;,
which we approximate by collecting samples, called ''training data'', of both the
measurement vector and the state variable, ''q''.
By generating classification results over the region of interest
and using any contouring algorithm to separate the
two classes, the isoline will have been "retrieved."

The accuracy of a retrieval will be given by integrating
the conditional probability over the area of interest, ''A'':

:&lt;math&gt;
a = \frac {1}{A} \int_A P \left[c(\vec{r}) | \vec{y}(\vec{r}) \right]
                \, d\vec{r}
&lt;/math&gt;

where ''c'' is the retrieved class at position, &lt;math&gt;\vec r&lt;/math&gt;.
We can maximize this quantity by maximizing the value of the integrand
at each point:

:&lt;math&gt;
\max(a) = \frac{1}{A} \int_A \left \lbrace \max_j P \left [j |
        \vec{y}(\vec{r}) \right ] \right \rbrace \, d\vec{r}
&lt;/math&gt;

Since this is the definition of maximum likelihood,
a [[statistical classification|classification algorithm]] based on [[maximum likelihood]]
is the most accurate method possible of validating an advected contour.
A good method for performing maximum likelihood classification
from a set of training data is [[variable kernel density estimation]].

===Training data===

There are two methods of generating the training data.
The most obvious is empirically, by simply matching measurements of
the variable, ''q'', with [[collocation (remote sensing)|collocated]]
measurements from the satellite instrument.  In this case,
no knowledge of the actual physics that produce the measurement
is required and the retrieval algorithm is purely statistical.
The second is with a forward model:

:&lt;math&gt;
\vec y = \vec f(\vec x) \,
&lt;/math&gt;

where &lt;math&gt;\vec x&lt;/math&gt; is the ''state vector'' and
''q = x&lt;sub&gt;k&lt;/sub&gt;'' is a single component.
An advantage of this method is that state vectors need not
reflect actual atmospheric configurations, they need only
take on a state that could reasonably occur in the real atmosphere.
There are also none of the errors inherent in
most [[collocation (remote sensing)|collocation]] procedures,
e.g. because of offset errors in the locations of the paired samples
and differences in the footprint sizes of the two instruments.
Since retrievals will be biased towards more common states,
however, the statistics ought to reflect those in the real world.

===Error characterization===

The conditional probabilities, &lt;math&gt;P(\vec y|j)&lt;/math&gt;, provide
excellent error characterization, therefore the classification
algorithm ought to return them.
We define the ''confidence rating'' by rescaling the conditional
probability:

: &lt;math&gt;
C = \frac{n_c P(c|\vec y) - 1}{n_c - 1}
&lt;/math&gt;

where ''n&lt;sub&gt;c&lt;/sub&gt;'' is the number of classes (in this case, two).
If ''C'' is zero, then the classification is little better than
chance, while if it is one, then it should be perfect.
To transform the confidence rating to a statistical ''tolerance'',
the following line integral can be applied to an isoline retrieval
for which the true isoline is known:

:&lt;math&gt;
\delta(C) = \frac{1}{l} \int_0^l h(C - C^\prime(\vec{r})) \, ds
&lt;/math&gt;

where ''s'' is the path, ''l'' is the length of the isoline
and &lt;math&gt;C^\prime&lt;/math&gt; is the retrieved confidence as a function
of position.
While it appears that the integral must be evaluated separately
for each value of the confidence rating, ''C'', in fact it may be
done for all values of ''C'' by sorting the confidence ratings of the
results, &lt;math&gt;C^\prime&lt;/math&gt;.
The function relates the threshold value of the confidence rating
for which the tolerance is applicable.
That is, it defines a region that contains a fraction of the true
isoline equal to the tolerance.

===Example: water vapour from AMSU===

[[Image:tolerance from confidence.png|thumb|right|upright=1.5|alt=Tolerance vs. confidence|Statistical tolerance versus confidence rating for water-vapour isoline retrieval.]]

The [[Advanced Microwave Sounding Unit]] (AMSU) series of satellite instruments
are designed to detect temperature and water vapour.  They have a high
horizontal resolution (as little as 15&amp;nbsp;km) and because they are
mounted on more than one satellite, full global coverage can be
obtained in less than one day.
Training data was generated using the second method from
[[European Centre for Medium-Range Weather Forecasts]] (ECMWF) ERA-40
data fed to a fast [[radiative transfer]] model called
[[RTTOV (radiative transfer code)|RTTOV]].
The function, &lt;math&gt;\delta(C)&lt;/math&gt; has been generated from
simulated retrievals and is shown in the figure to the right.
This is then used to set the 90 percent tolerance in the figure
below by shading all the confidence ratings less than 0.8.
Thus we expect the true isoline to fall within the shading
90 percent of the time.

[[Image:ret colour.gif|thumb|center|upright=3|alt=Sample isoline retrieval|Water vapour isoline retrieved from AMSU measurements and compared with ECMWF reanalysis.]]

==For continuum retrievals==

[[Image:conditional probability proxy.png|thumb|left|upright=1.5|alt=The conditional probability as proxy for the continuum variable|Specific humidity versus conditional probabilities from water-vapour isoline retrieval.]]

Isoline retrieval is also useful for retrieving a continuum variable
and constitutes a general, [[nonlinear]] [[inverse transform sampling method|inverse method]].
It has the advantage over both a [[neural network]], as well as iterative
methods such as [[optimal estimation]] that invert the forward model
directly, in that there is no possibility of getting stuck in a
[[local minimum]].

There are a number of methods of reconstituting the continuum variable
from the discretized one.  Once a sufficient number of contours
have been retrieved, it is straightforward to [[interpolate]] between
them.  Conditional probabilities make a good [[Proxy (statistics)|proxy]] for
the continuum value.

Consider the transformation from a continuum to a discrete variable:

:&lt;math&gt;
P(1 | \vec{y}) = \int_{-\infty}^{q_0} P(q | \vec{y}) \, dq
&lt;/math&gt;

:&lt;math&gt;
P(2 | \vec{y}) =  \int^{\infty}_{q_0} P(q | \vec{y}) \, dq
&lt;/math&gt;

Suppose that &lt;math&gt;P(q | \vec y)&lt;/math&gt; is given by a Gaussian:

:&lt;math&gt;
P(q | \vec y) = \frac{1}{\sqrt{2 \pi} \sigma_q}
	\exp \left \lbrace - \frac{\left [q - \bar q (\vec y)\right ]^2}{2 \sigma_q} \right \rbrace
&lt;/math&gt;

where &lt;math&gt;\bar q&lt;/math&gt; is the expectation value and &lt;math&gt;\sigma_q&lt;/math&gt;
is the standard deviation, then the conditional probability is related to the
continuum variable, ''q'', by the error function:

:&lt;math&gt;
R=P(2 | \vec{y})-P(1 | \vec{y}) = \mathrm{erf} \left [ \frac{q_0 - \bar q (\vec y)}{\sqrt 2 \sigma_q} \right ]
&lt;/math&gt;

The figure shows conditional probability versus specific humidity for the example
retrieval discussed above.

===As a robust estimator===

The location of ''q''&lt;sub&gt;0&lt;/sub&gt; is found by setting the conditional probabilities
of the two classes to be equal:

: &lt;math&gt;
\int_{-\infty}^{q_0} P(q | \vec{y}) \, dq = 
\int^\infty_{q_0} P(q | \vec{y}) \, dq
&lt;/math&gt;

In other words, equal amounts of the "zeroeth order moment" lie on either side
of ''q''&lt;sub&gt;0&lt;/sub&gt;. This type of formulation is characteristic of a [[robust estimator]].

==References==

* {{Cite journal
 | author = Peter Mills
 | title = Isoline retrieval: An optimal method for validation of advected contours
 | journal = Computers &amp; Geosciences
 | volume = 35
 | number = 11
 | pages = 2020–2031
 | year = 2009
 | doi = 10.1016/j.cageo.2008.12.015
 | url = http://peteysoft.users.sourceforge.net/Mills2009.pdf
| arxiv = 1202.5659
 | bibcode = 2009CG.....35.2020M
 }}

* {{Cite journal
 | author = Peter Mills
 | title = Efficient statistical classification of satellite measurements
 | journal = International Journal of Remote Sensing
 | doi = 10.1080/01431161.2010.507795
 | year = 2010
 | url = http://peteysoft.users.sourceforge.net/TRES_A_507795.pdf
| arxiv = 1202.2194
 }}

==External links==
* [http://isoret.sourceforge.net Software for isoline retrieval]

[[Category:Remote sensing]]
[[Category:Inverse problems]]</text>
      <sha1>cy5cy2dta65anrr2tlc1rwq4tn56dtp</sha1>
    </revision>
  </page>
  <page>
    <title>John Henry Michell</title>
    <ns>0</ns>
    <id>2376138</id>
    <revision>
      <id>837834484</id>
      <parentid>793559712</parentid>
      <timestamp>2018-04-23T09:44:24Z</timestamp>
      <contributor>
        <username>Mitch Ames</username>
        <id>6326132</id>
      </contributor>
      <comment>Remove supercategory of existing category per [[WP:SUBCAT]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8647">{{Other people|John Michell}}
&lt;!-- Deleted image removed: [[Image:jhmichell.jpg|right|thumb|200px]] --&gt;
'''John Henry Michell''', [[Fellow of the Royal Society|FRS]]&lt;ref name="frs"&gt;{{Cite journal | last1 = Michell | first1 = A. G. M. | authorlink = Anthony Michell| title = John Henry Michell. 1863-1940 | doi = 10.1098/rsbm.1941.0008 | journal = [[Obituary Notices of Fellows of the Royal Society]] | volume = 3 | issue = 9 | pages = 363–382| year = 1941 | pmid =  | pmc = }}&lt;/ref&gt; (26 October 1863 – 3 February 1940) was an [[Australia]]n [[mathematician]], Professor of Mathematics at the [[University of Melbourne]].&lt;ref name=adb/&gt;

==Early life==
Michell was the son of John Michell (pronounced Mitchell),&lt;ref name=adb/&gt; a miner, and his wife Grace, ''née'' Rowse and was born at [[Maldon, Victoria]]. His parents had migrated from [[Devon]]shire in 1854.&lt;ref name=adb/&gt; Educated at first at Maldon, he went to [[Wesley College, Melbourne]], in 1877, where he won the Draper and Walter Powell scholarships. In 1881 he began the arts course at the University of Melbourne, and qualified for the [[Bachelor of Arts|B.A.]] degree at the end of 1883. He had an outstanding course, heading the list with first-class honours each year, and winning the final honour scholarship in mathematics and physics.

Michell then went to the [[University of Cambridge]], obtained a major scholarship at [[Trinity College, Cambridge|Trinity College]], and was bracketed [[Wrangler (University of Cambridge)|senior wrangler]] with three others in the first part of the mathematical [[tripos]] in 1887. In the second part of the tripos in 1888, Michell was placed in division one of the first class.&lt;ref name=adb&gt;{{Australian Dictionary of Biography
|last=Cherry
|first=T. M.
|authorlink=
|year=1986
|id=A100481b
|title= Michell, John Henry (1863 - 1940)
|volume=10
|pages=494-495
|accessdate=2009-10-08 }}&lt;/ref&gt;&lt;ref name=dab&gt;{{Dictionary of Australian Biography|First=John Henry|Last=Michell|shortlink=0-dict-biogMa-Mo.html#michell1 |accessdate=2009-10-08 }}&lt;/ref&gt;&lt;ref&gt;{{acad|id=MCL884JH|name=Michell, John Henry}}&lt;/ref&gt;

==University of Melbourne==
Michell was elected a fellow of Trinity in 1890, but returned to [[Melbourne]] later the same year, and was appointed lecturer in mathematics at Melbourne University. He held this position for over 30 years. His academic work occupied so much of his time that it was difficult to do original research. The first of his papers, "On the theory of free streamlines", which appeared in ''Transactions of the Royal Society'' in 1890, had drawn attention to his ability as a mathematician, and during the following 12 years about 15 papers were contributed to English mathematical journals. It was recognized that these were important contributions to the knowledge of hydrodynamics and elasticity, and in June 1902 he was elected a [[Fellow of the Royal Society]] (FRS), London.&lt;ref&gt;{{Cite newspaper The Times |articlename=Court Circular |day_of_week=Friday |date=6 June 1902 |page_number=10 |issue=36787| }}&lt;/ref&gt; The number of his students at the University steadily increased, but there was no corresponding staff increase for a long while. Michell continued his research work but none of it was published. In 1923 he became professor of mathematics and, obtaining some increase of staff, established practice-classes and tutorials, thus considerably improving the efficiency of his department.&lt;ref name=dab/&gt; Michell resigned the chair at the end of 1928 and was given the title of honorary research professor. He died after a short illness on 3 February 1940 at [[Camberwell, Victoria|Camberwell]]. Michell did not marry. Michell published ''The Elements of Mathematical Analysis'' (1937), a substantial work in two volumes written in collaboration with [[Maurice Belz]].&lt;ref name=adb/&gt;

==Legacy==
Michell was regarded as a shy man and was one of the earliest graduates of an Australian university to be elected to the Royal Society. He was a good teacher, good-natured and patient with students, but his heart was really in his research work. His assistance was freely given to his engineering friends in clearing up their problems, and he did a good deal of physical experimentation including the devising and construction of several new forms of gyroscopes. He was continually at work, and it is not known why he did not choose to publish any papers after 1902. The value of his paper on "The wave resistance of a ship", published in 1898, was not realized until some 30 years later, when both English and German designers began to recognize its importance. Michell's brother, [[Anthony Michell]] (born 1870) made significant contributions to mechanical science, including the famous Michell thrust bearing.&lt;ref name=dab/&gt;

During a relatively short research career, Michell published 23 scientific papers that are some of the most important contributions ever made by an Australian mathematician.
A mini-symposium has held at the 3rd Biennial Engineering Mathematics and Applications Conference (EMAC '98) celebrating the centenary of the publication of Michell's famous 1898 paper on ship [[hydrodynamics]], ''The wave resistance of a ship'', Phil. Mag. (5) 45 (1898) 106-123.&lt;ref name=dab/&gt;

Since 1999, The JH Michell Medal has been awarded by [[ANZIAM]] in his honour.&lt;ref&gt;[http://www.anziam.org.au/The+JH+Michell+Medal The JH Michell Medal], www.anziam.org.au&lt;/ref&gt;

==Publications of J.H. Michell==
# The small deformation of curves and surfaces with applications to the vibrations of a helix and a circular ring, Messeng. Math. 19, (1890) 68-82.
# On the exhaustion of Neumann's mode of solution for the motion of solids of revolution in liquids, and similar problems, Messeng. Math. 19 (1890) 83-86.
# Vibrations of a string stretched on a surface, Messeng. Math. 19 (1890) 87-88.
# On the stability of a bent and twisted wire, Messeng. Math. 19 (1890) 181-184.
# On the theory of free stream lines, Phil. Trans. A. 181 (1890) 389-431.
# On a property of algebraic curves, Australasian Assoc. Adv. Sci. Report (1892) 257.
# On the bulging of flat plates, Australasian Assoc. Adv. Sci. Report (1892) 258.
# The highest waves in water, Phil. Mag. (5) 36 (1893) 430-437.
# A map of the complex Z-function: a condenser problem, Messeng. Math. 23 (1894) 72-78.
# The wave resistance of a ship, Phil. Mag. (5) 45 (1898) 106-123.
# On the direct determination of stress in an elastic solid, with application to the theory of plates, Proc. Lond. Math. Soc. 31 (1899) 100-124.
# The stress in a rotating lamina, Proc. Lond. Math. Soc. 31 (1899) 124-130.
# The uniform torsion and flexure of incomplete tores, with application to helical springs,Proc. Lond. Math. Soc. 31 (1899) 130-146.
# The transmission of stress across a plane of discontinuity in an isotropic elastic solid, and the potential solutions for a plane boundary,Proc. Lond. Math. Soc. 31 (1899) 183-192.
# Some elementary distributions of stress in three dimensions, Proc. Lond. Math. Soc. 32 (1900) 23-35.
# Elementary distributions of plane stress, Proc. Lond. Math. Soc. 32 (1900) 35-61.
# The stress in an aeolotropic elastic solid with an infinite plane boundary,Proc. Lond. Math. Soc. 32 (1900) 247-258.
# The stress in the web of a plate girder, Quart. J. Pure Appl. Math. 31 (1900) 377-382.
# The theory of uniformly loaded beams, Quart. J. Pure Appl. Math. 32 (1900) 28-42.
# The determination of the stress in an isotropic elastic sphere by means of intrinsic equations, Messeng. Math. n.s. 350 (1900) 16-25.
# The uniplanar stability of a rigid body, Messeng. Math. n.s. 351 (1900) 35-40.
# The inversion of plane stress, Proc. Lond. Math. Soc. 34 (1902) 134-142.
# The flexure of a circular plate, Proc. Lond. Math. Soc. 34 (1902) 223-228.
# (with M.H. Belz) The elements of mathematical analysis (2 vols) Macmillan 1937.

==Further reading==
* E.O. Tuck, "The wave resistance formula of J.H. Michell (1898) and its significance to recent research in ship hydrodynamics", J. Austral. Math. Soc. Series B 30 (989) 365-377;
* A. Goriely, "Twisted elastic rings and the rediscoveries of Michell's instability", J. Elasticity 84, 281 - 299. (2006)

==References==
{{Reflist}}

{{Use dmy dates|date=September 2010}}

{{Authority control}}

{{DEFAULTSORT:Michell, John Henry}}
[[Category:1863 births]]
[[Category:1940 deaths]]
[[Category:Mathematicians from Melbourne]]
[[Category:Senior Wranglers]]
[[Category:Fellows of the Royal Society]]
[[Category:People educated at Wesley College (Victoria)]]
[[Category:University of Melbourne alumni]]
[[Category:University of Melbourne faculty]]
[[Category:People from Maldon, Victoria]]</text>
      <sha1>9lkihoe9tb7liobboh3t2rok231po7c</sha1>
    </revision>
  </page>
  <page>
    <title>Joseph Pérès</title>
    <ns>0</ns>
    <id>52066850</id>
    <revision>
      <id>860212074</id>
      <parentid>857268848</parentid>
      <timestamp>2018-09-19T03:09:08Z</timestamp>
      <contributor>
        <username>Smasongarrison</username>
        <id>16185737</id>
      </contributor>
      <comment>copy edit with [[Wikipedia:AutoWikiBrowser/General_fixes|General fixes]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4012">{{other people||Pérès}}
{{Infobox scientist
| name        = Joseph Pérès
| image       = Joseph Pérès 1890-1962.JPG
| image_size  =
| caption     =
| birth_name  =
| birth_date  = 31 October 1890
| birth_place = [[Clermont-Ferrand]]
| death_date  = 12 February 1962
| death_place =
| death_cause =
| fields      = Mathematics
| workplaces  = 
| patrons     = 
| education   = 
| alma_mater  = 
| thesis_title =        &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url  =         &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year =         &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor =    &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = 
| influences  = 
| influenced  = 
| awards      = 
| nationality = [[France]]
}}
'''Joseph Pérès''' (31 October 1890 – 12 February 1962) was a French mathematician.

Pérès was born in [[Clermont-Ferrand]] on 31 October 1890.&lt;ref name=":0"&gt;{{Cite web|url=http://www-history.mcs.st-andrews.ac.uk/Biographies/Peres.html|title=Pérès biography|website=www-history.mcs.st-andrews.ac.uk|access-date=2016-10-22}}&lt;/ref&gt; Former student of the [[Ecole Normale Superieure]], he worked in Rome with [[Vito Volterra]] and defended his doctoral thesis in 1915.&lt;ref name=":0" /&gt; In 1920 he became a lecturer at the Faculty of Sciences of Strasbourg and in 1921 held the mechanics chair of the faculty of sciences of Marseille.&lt;ref&gt;{{Cite journal|last=Costabel|first=Pierre|title=Joseph Pérès (1890-1962)|url=http://www.persee.fr/doc/rhs_0048-7996_1962_num_15_2_4424|journal=Revue d'histoire des sciences et de leurs applications|volume=15|issue=2}}&lt;/ref&gt;

In 1932, he was appointed lecturer at the Faculty of Paris. He was elected member of the Academy of Sciences in 1942. He held the chair of mechanics in 1950 and Dean of the Faculty of Science in 1954, succeeding [[Albert Châtelet]]. During his deanship, he undertakes the creation of the Orsay campus. He was also one of the founders of the [[Institut des Hautes Études Scientifiques]] and its first président until his death.

==Selected publications==
===Articles===
*{{Citation
|author-first= Joseph
|author-last= Pérès
|author-link =
|title = Le parallélisme de Mr. Levi-Civita et la courbure riemannienne
|trans-title= 
|journal = Rendiconti della Reale Accademia dei Lincei, (Serie 5) 
|volume =28
|issue=
|pages =425–428
|year =1919
|language =Italian
|url = https://babel.hathitrust.org/cgi/pt?id=njp.32101077264677;view=1up;seq=431
|doi =
|jfm = 
}}
*[http://www.numdam.org/article/BSMF_1919__47__16_1.pdf "Sur les transformations qui conservent la composition."] Bull. Soc. Math. France 47 (1919): 16–37.
*[https://eudml.org/doc/103412 "Choc en tenant compte du frottement."] Nouvelles annales de mathématiques: journal des candidats aux écoles polytechnique et normale 2 (1923): 98–107.
*[https://eudml.org/doc/235638 "Contribution à l'étude des jets fluides."] Journal de Mathématiques Pures et Appliquées 11 (1932): 57–66.

===Books===
* {{cite book | author = Joseph Pérès |title=Mécanique des Fluides| postscript =; published with the collaboration of Lucien Malavard | publisher = Gauthier-Villars | url=https://books.google.com/books?id=YsUoAQAAMAAJ}}&lt;ref&gt;{{cite journal|author=Shook, C. A.|title=Review of ''Mécanique des Fluides'' par Joseph Pérès|journal=Bull. Amer. Math. Soc.|volume=45|year=1939|pages=512–513|doi=10.1090/S0002-9904-1939-07031-6}}&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
*{{MathGenealogy |id=120086}}
* [http://data.bnf.fr/ark:/12148/cb109210440 A French short biography of Joseph Pérès] in ''BnF''

{{Authority control}}

{{DEFAULTSORT:Pérès, Joseph}}
[[Category:1890 births]]
[[Category:1962 deaths]]
[[Category:People from Clermont-Ferrand]]
[[Category:Mathematicians]]
[[Category:Members of the United States National Academy of Sciences]]


{{France-bio-stub}}
{{Mathematician-stub}}</text>
      <sha1>6zhgm3dkhnklh5yvnqen3z8gmbflndk</sha1>
    </revision>
  </page>
  <page>
    <title>Lie bracket of vector fields</title>
    <ns>0</ns>
    <id>10282799</id>
    <revision>
      <id>859293850</id>
      <parentid>816686061</parentid>
      <timestamp>2018-09-13T02:52:34Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>/* Flows and limits */ italic 't'</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9463">{{Use dmy dates|date=October 2011}}
In the mathematical field of [[differential topology]], the '''Lie bracket of vector fields''', also known as the '''Jacobi&amp;ndash;Lie bracket''' or the '''commutator of vector fields''', is an operator that assigns to any two [[vector field]]s ''X'' and ''Y'' on a [[smooth manifold]] ''M'' a third vector field denoted {{nowrap|[''X'', ''Y'']}}.

Conceptually, the Lie bracket {{nowrap|[''X'', ''Y'']}} is the derivative of ''Y'' along the [[vector flow|flow]] generated by ''X''.  A generalization of the Lie bracket is the [[Lie derivative]], which allows differentiation of any [[tensor field]] along the flow generated by ''X''.  The Lie bracket {{nowrap|[''X'', ''Y'']}} equals the Lie derivative of the vector ''Y'' (which is a tensor field) along ''X'', and is sometimes denoted &lt;math&gt;\mathcal{L}_X Y&lt;/math&gt; (read "the Lie derivative of ''Y'' along ''X''").

The Lie bracket is an '''R'''-[[bilinear operator|bilinear]] operation and turns the set of all [[Smoothness|smooth]] vector fields on the manifold ''M'' into an (infinite-dimensional) [[Lie algebra]].

The Lie bracket plays an important role in [[differential geometry]] and [[differential topology]], for instance in the [[Frobenius theorem (differential topology)|Frobenius theorem]], and is also fundamental in the geometric theory for [[nonlinear control theory|nonlinear control systems]] ({{harvnb|Isaiah|2009|pp=20&amp;ndash;21}}, [[nonholonomic system]]s; {{harvnb|Khalil|2002|pp=523&amp;ndash;530}}, [[feedback linearization]]).

==Definitions==
There are three conceptually different but equivalent approaches to defining the Lie bracket:

===Vector fields as derivations===
Each vector field ''X'' on a smooth manifold ''M''
may be regarded as a [[differential operator]] acting on smooth
functions on ''M''. Indeed, each
smooth vector field ''X'' becomes a [[Derivation (abstract algebra)|derivation]] on the smooth 
functions ''C''&lt;sup&gt;∞&lt;/sup&gt;(''M'')  when we define ''X''(''f'') to be the element of ''C''&lt;sup&gt;∞&lt;/sup&gt;(''M'') whose value at a point ''p'' is the [[directional derivative]] of ''f'' at ''p'' in the direction ''X''(''p''). Furthermore, it is known that any derivation on ''C''&lt;sup&gt;∞&lt;/sup&gt;(''M'') arises in this fashion from a uniquely determined smooth vector field ''X''.

In general, the [[commutator]] &lt;math&gt;\delta_1\circ \delta_2 - \delta_2\circ\delta_1&lt;/math&gt; of any two derivations &lt;math&gt;\delta_1&lt;/math&gt; and &lt;math&gt;\delta_2&lt;/math&gt; is again a derivation. This can be used to define the Lie bracket of vector fields as follows.

The Lie bracket, {{nowrap|[''X'', ''Y'']}}, of two smooth vector fields 
''X'' and ''Y'' is the smooth vector field {{nowrap|[''X'', ''Y'']}} such that 
:&lt;math&gt;[X,Y](f) = X(Y(f))-Y(X(f)) \;\;\text{  for all } f\in C^\infty(M).&lt;/math&gt;

===Flows and limits===
Let &lt;math&gt;\Phi^X_t&lt;/math&gt; be the [[Flow (mathematics)|flow]] associated with the vector field ''X'', and let d denote the [[Pushforward (differential)|tangent map derivative operator]]. Then the Lie bracket of ''X'' and ''Y'' at the point {{nowrap|''x'' &amp;isin; ''M''}} can be defined as
:&lt;math&gt;[X, Y]_x := \lim_{t \to 0}\frac{(\mathrm{d}\Phi^X_{-t}) Y_{\Phi^X_t(x)} - Y_x}t = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\mathrm{d}\Phi^X_{-t}) Y_{\Phi^X_t(x)} ,&lt;/math&gt;

or in terms of the [[Lie derivative]]
:&lt;math&gt;[X, Y] = \mathcal{L}_X Y ,&lt;/math&gt;

which is also equivalent to
:&lt;math&gt;[X, Y]_x := \left.\frac12\frac{\mathrm{d}^2}{\mathrm{d}t^2}\right|_{t=0} (\Phi^Y_{-t} \circ \Phi^X_{-t} \circ \Phi^Y_{t} \circ \Phi^X_{t})(x) = \left.\frac{\mathrm{d}}{\mathrm{d} t}\right|_{t=0} (\Phi^Y_{-\sqrt{t}} \circ \Phi^X_{-\sqrt{t}} \circ \Phi^Y_{\sqrt{t}} \circ \Phi^X_{\sqrt{t}})(x) .&lt;/math&gt;

===In coordinates===
Though neither definition of the Lie bracket depends on a choice of coordinates, in practice one often wants to compute the bracket with respect to a coordinate system.

If we have picked a coordinate chart on ''M'' with local coordinate functions &lt;math&gt;\{ x^i \}&lt;/math&gt;, and we write &lt;math&gt;\partial_i = \frac{\partial}{\partial x^i}&lt;/math&gt; for the associated local basis for the tangent bundle, then the vector fields can be written as 
:&lt;math&gt;X=\sum_{i=1}^n X^i \partial_i&lt;/math&gt;
and 
:&lt;math&gt;Y=\sum_{i=1}^n Y^i \partial_i&lt;/math&gt; 
with smooth functions &lt;math&gt;X^i:M\to\mathbb{R}&lt;/math&gt; and &lt;math&gt;Y^i:M\to\mathbb{R}&lt;/math&gt;.  Then the Lie bracket is given by

:&lt;math&gt;[X,Y] := \sum_{i=1}^n\left(X(Y^i) - Y(X^i)\right) \partial_i = \sum_{i=1}^n \sum_{j=1}^n \left(X^j \partial_j Y^i - Y^j \partial_j X^i \right) \partial_i .&lt;/math&gt;

If ''M'' is (an open subset of) '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, then the vector fields ''X'' and ''Y'' can be written as smooth maps of the form &lt;math&gt;X:M\to\mathbb{R}^n&lt;/math&gt; and &lt;math&gt;Y:M\to\mathbb{R}^n&lt;/math&gt;, and the Lie bracket &lt;math&gt;[X,Y]:M\to\mathbb{R}^n&lt;/math&gt; is given by
:&lt;math&gt;[X,Y] := J_Y  X - J_X Y&lt;/math&gt;
where &lt;math&gt;J_Y&lt;/math&gt; and &lt;math&gt;J_X&lt;/math&gt; are the [[Jacobian matrix|Jacobian matrices]] of &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;X&lt;/math&gt;, respectively. These ''n''-by-''n'' matrices are multiplied by the ''n''-vectors ''X'' and ''Y''.

==Properties==

The Lie bracket of vector fields equips the real vector space &lt;math&gt;V=\Gamma(TM)&lt;/math&gt; of all vector fields on ''M'' (i.e., smooth sections of the tangent bundle &lt;math&gt;TM&lt;/math&gt; of &lt;math&gt;M&lt;/math&gt;) with the structure of a [[Lie algebra]], i.e., [·,·] is a map &lt;math&gt;V\times V\to V&lt;/math&gt; with the following properties
*'''R'''-[[Bilinear map|bilinearity]]
*Anti-symmetry, &lt;math&gt;[X, Y] = -[Y, X]&lt;/math&gt;
*Satisfying the [[Jacobi identity]], &lt;math&gt;[X, [Y, Z]] + [Z, [X, Y]] + [Y, [Z, X]] = 0 .&lt;/math&gt;

An immediate consequence of the second property is that &lt;math&gt;[X, X] = 0&lt;/math&gt; for any &lt;math&gt;X&lt;/math&gt;.

Furthermore, there is a "[[product rule]]" for Lie brackets. Given a smooth real-valued function ''f'' defined on ''M'' and a vector field ''Y'' on ''M'', we have a new vector field ''fY'', defined by multiplying the vector ''Y&lt;sub&gt;x&lt;/sub&gt;'' with the number ''f''(''x''), at each point {{nowrap|''x'' &amp;isin; ''M''}}. The Lie bracket of ''X'' and ''fY'' is then given by
*&lt;math&gt; [X, fY] = X(f) Y + f [X,Y] ,&lt;/math&gt;
where on the right-hand side we multiply the function ''X''(''f'') with the vector field ''Y'', and the function ''f'' with the vector field {{nowrap|[''X'', ''Y'']}}.
This turns the vector fields with the Lie bracket into a [[Lie algebroid]].

We also have the following fact:

'''Theorem:'''

&lt;math&gt;[X,Y]=0\,&lt;/math&gt; iff the flows of ''X'' and ''Y'' commute locally, i.e. [[iff]] for every {{nowrap|''x'' &amp;isin; ''M''}} and all sufficiently small real numbers ''s'', ''t'' we have &lt;math&gt;(\Phi^Y_t \Phi^X_s) (x) =(\Phi^X_{s}\, \Phi^Y_t)(x)&lt;/math&gt;.

== Examples ==
For a [[Lie group]] ''G'', the corresponding [[Lie algebra]] is the tangent space at the identity, which can be identified with the left invariant vector fields on ''G''. The Lie bracket of the Lie algebra is then the Lie bracket of the left invariant vector fields, which is also left invariant.

For a matrix Lie group, smooth vector fields can be locally represented in the corresponding Lie algebra.  Since the Lie algebra associated with a Lie group is isomorphic to the group's tangent space at the identity, elements of the Lie algebra of a matrix Lie group are also matrices.  Hence the Jacobi–Lie bracket corresponds to the usual commutator for a matrix group:

:&lt;math&gt;[X,Y] = XY - YX ,&lt;/math&gt;

where juxtaposition indicates matrix multiplication.

== Applications ==

The Jacobi&amp;ndash;Lie bracket is essential to proving [[small-time local controllability]] (STLC) for driftless [[affine control systems]].

==Generalizations==
As mentioned above, the [[Lie derivative]] can be seen as a generalization of the Lie bracket. Another generalization of the Lie bracket (to [[vector-valued differential form]]s) is the [[Frölicher–Nijenhuis bracket]].

==References==
* {{springer|title=Lie bracket|id=p/l058550}}
* {{citation|last=Isaiah|first=Pantelis|title=Controlled parking [Ask the experts]|journal=IEEE Control Systems Magazine|year=2009|volume=29|issue=3|pages=17&amp;ndash;21, 132|doi=10.1109/MCS.2009.932394}}
* {{citation
 | last = Khalil
 | first = H.K.
 | authorlink = Hassan K. Khalil
 | year = 2002
 | edition = 3rd
 | url = http://www.egr.msu.edu/~khalil/NonlinearSystems/
 | isbn = 0-13-067389-7
 | title = Nonlinear Systems
 | publisher=[[Prentice Hall]]
 | location = Upper Saddle River, NJ}}
* {{Citation|author=Kolář, I., Michor, P., and Slovák, J.|title=Natural operations in differential geometry|url=http://www.emis.de/monographs/KSM/index.html|publisher=Springer-Verlag|year=1993}} Extensive discussion of Lie brackets, and the general theory of Lie derivatives.
* {{Citation|author=Lang, S.|title=Differential and Riemannian manifolds|publisher=Springer-Verlag|year=1995|isbn=978-0-387-94338-1}} For generalizations to infinite dimensions.
* {{Citation|author=Lewis, Andrew D.|url=http://penelope.mast.queensu.ca/math890-03/ps/math890.pdf|title=Notes on (Nonlinear) Control Theory}}{{dead link|date=December 2017 |bot=InternetArchiveBot |fix-attempted=yes }}
*{{Citation | last =Warner | first = Frank | title = Foundations of differentiable manifolds and Lie groups | origyear = 1971 | edition = | year = 1983 | publisher=Springer-Verlag | location = New York-Berlin | isbn = 0-387-90894-3 }}

[[Category:Bilinear operators]]
[[Category:Binary operations]]
[[Category:Differential topology]]
[[Category:Riemannian geometry]]</text>
      <sha1>qk56r1yr9dim9epi2qlbb23r1sptwla</sha1>
    </revision>
  </page>
  <page>
    <title>Liouville's equation</title>
    <ns>0</ns>
    <id>12677528</id>
    <revision>
      <id>837966113</id>
      <parentid>796680355</parentid>
      <timestamp>2018-04-24T02:52:39Z</timestamp>
      <contributor>
        <ip>2001:250:4001:1005:B8F0:C8FA:1ECE:D8F6</ip>
      </contributor>
      <comment>/* General solution of the equation */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7145">: ''For Liouville's equation in dynamical systems, see [[Liouville's theorem (Hamiltonian)]].''
: ''For Liouville's equation in quantum mechanics, see [[Density operator#Von Neumann equation|Von Neumann equation]].''
: ''For Liouville's equation in Euclidean space, see [[Liouville–Bratu–Gelfand equation]].''
In [[differential geometry]], '''Liouville's equation''', named after [[Joseph Liouville]], is the nonlinear [[partial differential equation]] satisfied by the conformal factor {{mvar|f}} of a metric {{math|''f''{{i sup|2}}(d''x''{{sup|2}}&amp;nbsp;+&amp;nbsp;d''y''{{sup|2}})}} on a [[surface (differential geometry)|surface]] of constant [[Gaussian curvature]] {{mvar|K}}:

:&lt;math&gt;\Delta_0\log f = -K f^2,&lt;/math&gt;

where {{math|∆{{sub|0}}}} is the flat [[Laplace operator]]

:&lt;math&gt;\Delta_0 = \frac{\partial^2}{\partial x^2} +\frac{\partial^2}{\partial y^2} 
= 4 \frac{\partial}{\partial z} \frac{\partial}{\partial \bar z}.&lt;/math&gt;

Liouville's equation appears in the study of [[isothermal coordinates]] in differential geometry: the [[Dependent and independent variables#Calculus|independent variable]]s {{mvar|x,y}} are the coordinates, while {{mvar|f}} can be described as the conformal factor with respect to the flat metric. Occasionally it is the square {{math|''f''{{i sup|2}}}} that is referred to as the conformal factor, instead of {{mvar|f}} itself.

Liouville's equation was also taken as an example by [[David Hilbert]] in the formulation of his [[Hilbert's nineteenth problem|nineteenth problem]].&lt;ref name="Hilbertp288"&gt;See {{harv|Hilbert|1900|p=288}}: Hilbert does not cite explicitly Joseph Liouville.&lt;/ref&gt;

==Other common forms of Liouville's equation==
By using the [[change of variables]] {{math|log&amp;nbsp;''f''&amp;nbsp;↦&amp;nbsp;''u''}}, another commonly found form of Liouville's equation is obtained:

:&lt;math&gt;\Delta_0 u = - K e^{2u}.&lt;/math&gt;

Other two forms of the equation, commonly found in the literature,&lt;ref&gt;See {{harv|Dubrovin|Novikov|Fomenko|1992|p=118}} and {{harv|Henrici|p=294}}.&lt;/ref&gt; are obtained by using the slight variant {{math|2&amp;nbsp;log&amp;nbsp;''f''&amp;nbsp;↦&amp;nbsp;''u''}} of the previous change of variables and [[Wirtinger derivatives|Wirtinger calculus]]:&lt;ref&gt;See {{harv|Henrici|pp=287–294}}.&lt;/ref&gt;

:&lt;math&gt;\Delta_0 u = - 2K e^{u}\quad\Longleftrightarrow\quad \frac{\partial^2 u}{{\partial z}{\partial \bar z}} = - \frac{K}{2} e^{u}.&lt;/math&gt;

Note that it is exactly in the first one of the preceding two forms that Liouville's equation was cited by David Hilbert in the formulation of his [[Hilbert's nineteenth problem|nineteenth problem]].&lt;ref name="Hilbertp288" /&gt;&lt;ref&gt;Hilbert assumes {{math|''K'' &lt;nowiki&gt;=&lt;/nowiki&gt; -1/2}}, therefore the equation appears as the following [[Semilinear partial differential equation|semilinear]] [[elliptic equation]]:
:&lt;math&gt;\frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} = e^f&lt;/math&gt;
&lt;/ref&gt;

===A formulation using the Laplace–Beltrami operator===

In a more invariant fashion, the equation can be written in terms of the ''intrinsic'' [[Laplace-Beltrami operator]]

: &lt;math&gt;\Delta_{\mathrm{LB}} = \frac{1}{f^2} \Delta_0&lt;/math&gt;

as follows:

:&lt;math&gt;\Delta_{\mathrm{LB}}\log\; f = -K.&lt;/math&gt;

==Properties==
===Relation to Gauss–Codazzi equations===
Liouville's equation is a consequence of the [[Gauss–Codazzi equations]] when the metric is written in [[isothermal coordinates]].

===General solution of the equation===
In a [[Connection (mathematics)|simply connected]] [[Domain (mathematical analysis)|domain]] {{math|&amp;Omega;}}, the general solution of Liouville's equation can be found by using Wirtinger calculus.&lt;ref name="Henricip294" &gt;See {{harv|Henrici|p=294}}.&lt;/ref&gt; Its form is given by
:&lt;math&gt;
u(z,\bar z) = \ln \left(
4 \frac{ \left|{\mathrm{d} f(z)}/{\mathrm{d} z}\right|^2  }{ ( 1+K \left|f(z)\right|^2)^2 }
\right)
&lt;/math&gt;

where {{math|''f''&amp;nbsp;(''z'')}} is any [[meromorphic function]] such that
*{{math|{{sfrac|d''f''|d''z''}}(''z'')&amp;nbsp;≠&amp;nbsp;0}} for every {{math|''z''&amp;nbsp;∈&amp;nbsp;&amp;Omega;}}.&lt;ref name="Henricip294" /&gt;
*{{math|''f''&amp;nbsp;(''z'')}} has at most [[Pole (complex analysis)|simple poles]] in {{math|&amp;Omega;}}.&lt;ref name="Henricip294" /&gt;

==Application==
Liouville's equation can be used to prove the following classification results for surfaces:

{{EquationRef|1|Theorem}}.&lt;ref&gt;See {{harv|Dubrovin|Novikov|Fomenko|1992|pp=118–120}}.&lt;/ref&gt; A surface in the Euclidean 3-space with metric {{math|d''l''{{i sup|2}}&amp;nbsp;{{=}}&amp;nbsp;''g''(''z'',{{overset|_|''z''}})d''z''d{{overset|_|''z''}}}}, and with constant scalar curvature {{mvar|K}} is locally isometric to:
# the [[sphere]] if {{math|''K''&amp;nbsp;&gt;&amp;nbsp;0}};
# the [[Euclidean plane]] if {{math|''K''&amp;nbsp;{{=}}&amp;nbsp;0}};
# the [[Lobachevski plane|Lobachevskian plane]] if {{math|''K''&amp;nbsp;&lt;&amp;nbsp;0}}.

==See also==
*[[Liouville field theory]], a two-dimensional conformal field theory whose classical equation of motion is a generalization of Liouville's equation

==Notes==
{{reflist|29em}}

==References==
*{{Citation
 | last = Dubrovin
 | first =B. A.
 | author-link =
 | last2 = Novikov
 | first2 =S. P.
 | author2-link =Sergei Novikov (mathematician)
 | last3 =Fomenko
 | first3 =A. T.
 | author3-link =Anatoly Fomenko
 | title =Modern Geometry–Methods and Applications. Part I. The Geometry of Surfaces, Transformation Groups, and Fields
 | place = Berlin–Heidelberg–New York
 | publisher =[[Springer Verlag]]
 | series =[[Graduate Studies in Mathematics]]
 | volume =93
 | origyear =1984
 | year =1992
 | edition =2nd
 | pages= xv+468 
 | isbn =3-540-97663-9
 | mr =0736837
 | zbl = 0751.53001
}}
*{{Citation
  | last = Henrici
  | first = Peter
  | author-link = Peter Henrici (mathematician)
  | title = Applied and Computational Complex Analysis Volume 3
  | place = New York - Chichester - Brisbane - Toronto - Singapore
  | publisher = [[John Wiley &amp; Sons]]
  | origyear = 1986
  | year = 1993
  | series = Wiley Classics Library
  | volume =
  | edition = Reprint
  | pages = X+637
  | url = https://books.google.com/books?id=vKZPsjaXuF4C&amp;printsec=frontcover#v=onepage&amp;q
  | doi =
  | id = 
  | mr = 0822470
  | zbl = 1107.30300
  | isbn = 0-471-58986-1}}.
*{{Citation
 | last = Hilbert
 | first = David
 | author-link = David Hilbert
 | title = Mathematische Probleme
 | journal = [[Nachrichten von der Königlichen Gesellschaft der Wissenschaften zu Göttingen, Mathematisch-Physikalische Klasse]]
 | issue = 3
 | pages = 253–297
 | year = 1900
 | language = German
 | url = http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN252457811_1900&amp;DMDID=DMDLOG_0037
 | jfm =31.0068.03
}}, translated in English by [[Mary Frances Winston Newson]] as {{Citation
 | last = Hilbert
 | first = David
 | author-link = David Hilbert
 | title = Mathematical Problems
 | journal = [[Bulletin of the American Mathematical Society]]
 | volume = 8
 | issue = 10
 | pages = 437–479
 | year = 1902
 | url = http://www.ams.org/journals/bull/1902-08-10/S0002-9904-1902-00923-3/
 | doi = 10.1090/S0002-9904-1902-00923-3
 | jfm = 33.0976.07
 | mr = 1557926
}}.

[[Category:Differential geometry]]
[[Category:Differential equations]]</text>
      <sha1>erccohehpg2yqugizwg74jy83gydeo2</sha1>
    </revision>
  </page>
  <page>
    <title>Liouville–Arnold theorem</title>
    <ns>0</ns>
    <id>40071018</id>
    <revision>
      <id>855021523</id>
      <parentid>854293907</parentid>
      <timestamp>2018-08-15T11:29:13Z</timestamp>
      <contributor>
        <ip>193.84.204.98</ip>
      </contributor>
      <comment>refce added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2416">In [[dynamical systems]] theory, the '''Liouville–Arnold theorem''' states that if, in a [[Hamiltonian system|Hamiltonian dynamical system]] with ''n'' [[Degrees of freedom (mechanics)|degrees of freedom]], there are also known ''n'' first [[Integral of motion|integrals of motion]] that are independent and in [[Involution (mathematics)|involution]], then there exists a [[canonical transformation]] to [[action-angle coordinates]] in which the transformed Hamiltonian is dependent only upon the action coordinates and the angle coordinates evolve linearly in time. Thus the equations of motion for the system can be solved in [[Quadrature (mathematics)|quadratures]] if the canonical transform is explicitly known. The theorem is named after [[Joseph Liouville]] and [[Vladimir Arnold]].&lt;ref&gt;J. Liouville, « Note sur l'intégration des équations différentielles de la Dynamique, présentée au Bureau des Longitudes le 29 juin 1853 », ''[[Journal de mathématiques pures et appliquées|JMPA]]'', 1855, {{p.|137-138}}, [http://sites.mathdoc.fr/JMPA/PDF/JMPA_1855_1_20_A11_0.pdf pdf]&lt;/ref&gt;&lt;ref name="Benatti2009"&gt;{{cite book|author=Fabio Benatti|title=Dynamics, Information and Complexity in Quantum Systems|url=https://books.google.com/books?id=zTFiCm4Yq1cC&amp;pg=PA16|year=2009|publisher=[[Springer Science &amp; Business Media]]|isbn=978-1-4020-9306-7|page=16}}&lt;/ref&gt;&lt;ref name="Rodriguez"&gt;{{cite book|editors=P. Tempesta, P. Winternitz, J. Harnad, W. Miller, Jr., G. Pogosyan, and M. Rodriguez|title=Superintegrability in Classical and Quantum Systems|url=https://books.google.com/books?id=1Yke_LPQTd8C&amp;pg=PA48|year=2004|publisher=[[American Mathematical Society]]|isbn=978-0-8218-7032-7|page=48}}&lt;/ref&gt;&lt;ref name="JonesKhibnik2012"&gt;{{cite book|editor1=Christopher K. R. T. Jones|editor2=Alexander I. Khibnik|title=Multiple-Time-Scale Dynamical Systems|url=https://books.google.com/books?id=LYLkBwAAQBAJ&amp;pg=PA1|year=2012|publisher=[[Springer Science &amp; Business Media]]|isbn=978-1-4613-0117-2|page=1}}&lt;/ref&gt;&lt;ref name=Arnold1989&gt;{{cite book|last=Arnold|first=V. I.|title=Mathematical Methods of Classical Mechanics|year=1989|publisher=Springer|isbn=9780387968902}}&lt;/ref&gt;{{rp|pages=270–272}}

==References==
{{reflist}}

{{DEFAULTSORT:Liouville-Arnold theorem}}
[[Category:Hamiltonian mechanics]]
[[Category:Integrable systems]]
[[Category:Theorems in dynamical systems]]


{{physics-stub}}
{{Mech-engineering-stub}}</text>
      <sha1>230lc8fupnpp0ak7jz2i9kdxy2tqlwa</sha1>
    </revision>
  </page>
  <page>
    <title>List of linear algebra topics</title>
    <ns>0</ns>
    <id>353855</id>
    <revision>
      <id>867470320</id>
      <parentid>846789920</parentid>
      <timestamp>2018-11-05T22:39:54Z</timestamp>
      <contributor>
        <username>The Man in Question</username>
        <id>835170</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4218">This is a list of '''[[linear algebra]] topics'''. See also:

*[[List of matrices]]
*[[Glossary of tensor theory]].

==[[Linear equation]]s==

*[[System of linear equations]]
*[[Determinant]]
**[[Minor (linear algebra)|Minor]]
**[[Cauchy–Binet formula]]
*[[Cramer's rule]]
*[[Gaussian elimination]]
*[[Gauss–Jordan elimination]]
*[[Strassen algorithm]]

==[[Matrix (mathematics)|Matrices]]==

*[[2 × 2 real matrices]]
*[[Matrix (mathematics)|Matrix theory]]
*[[Matrix addition]]
*[[Matrix multiplication]]
*[[Basis transformation matrix]]
*[[Characteristic polynomial]]
*[[Trace (matrix)|Trace]]
*[[Eigenvalue, eigenvector and eigenspace]]
**[[Cayley–Hamilton theorem]]
**[[Spread of a matrix]]
**[[Jordan normal form]]
**[[Weyr canonical form]]
*[[Rank (matrix theory)|Rank]]
*[[Matrix inversion]], [[invertible matrix]]
**[[Pseudoinverse]]
*[[Adjugate]]
*[[Transpose]]
**[[Dot product]]
**[[Symmetric matrix]]
**[[Orthogonal matrix]]
**[[Skew-symmetric matrix]]
**[[Conjugate transpose]]
***[[Unitary matrix]]
***[[Hermitian matrix]], [[Antihermitian matrix]]
*[[Positive-definite matrix|Positive-definite]], [[positive-semidefinite matrix]]
*[[Pfaffian]]
*[[Projection (linear algebra)|Projection]]
*[[Spectral theorem]]
*[[Perron–Frobenius theorem]]
*[[List of matrices]]
**[[Diagonal matrix]], [[main diagonal]]
***[[Diagonalizable matrix]]
**[[Triangular matrix]]
**[[Tridiagonal matrix]]
**[[Block matrix]]
**[[Sparse matrix]]
**[[Hessenberg matrix]]
**[[Hessian matrix]]
**[[Vandermonde matrix]]
**[[Stochastic matrix]]
**[[Toeplitz matrix]]
***[[Circulant matrix]]
**[[Hankel matrix]]
**[[(0,1)-matrix]]

==[[Matrix decomposition]]s==

*[[Cholesky decomposition]]
*[[LU decomposition]]
*[[QR decomposition]]
*[[Polar decomposition]]
*[[Spectral theorem]]
*[[Singular value decomposition]]
**[[Higher-order singular value decomposition]]
*[[Schur decomposition]]
**[[Schur complement]]
**[[Haynsworth inertia additivity formula]]

==Relations==
*[[Matrix equivalence]]
*[[Matrix congruence]]
*[[Matrix similarity]]
*[[Matrix consimilarity]]
*[[Row equivalence]]

==Computations==
*[[Elementary row operations]]
*[[Householder transformation]]
*[[Least squares]], [[linear least squares (mathematics)|linear least squares]]
*[[Gram–Schmidt process]]
*[[Woodbury matrix identity]]

==[[Vector space]]s==

*[[Linear combination]]
*[[Linear span]]
*[[Linear independence]]
*[[Scalar multiplication]]
*[[Basis (linear algebra)|Basis]]
**[[Change of basis]]
**[[Hamel basis]]
*[[Cyclic decomposition theorem]]
*[[Dimension theorem for vector spaces]]
**[[Hamel dimension]]
*[[Examples of vector spaces]]
*[[Linear map]]
**[[Shear mapping]] or [[Galilean transformation]]
**[[Squeeze mapping]] or [[Lorentz transformation]]
*[[Linear subspace]]
**[[Row and column spaces]]
**[[Column space]]
**[[Row space]]
**[[Cyclic subspace]]
**[[Null space]], nullity
**[[Rank–nullity theorem]]
**[[Nullity theorem]]
*[[Dual space]]
**[[Linear function]]
**[[Linear functional]]
*[[Category of vector spaces]]

==Structures==
*[[Topological vector space]]
*[[Normed vector space]]
*[[Inner product space]]
**[[Euclidean space]]
**[[Orthogonality]]
**[[Orthogonal complement]]
**[[Orthogonal projection]]
**[[Orthogonal group]]
*[[Pseudo-Euclidean space]]
**[[Null vector]]
**[[Indefinite orthogonal group]]
* [[Orientation (geometry)]]
**[[Improper rotation]]
* [[Symplectic structure]]

==[[Multilinear algebra]]==

*[[Tensor]]
**[[Classical treatment of tensors]]
**[[Component-free treatment of tensors]]
*[[Outer product]]
*[[Tensor algebra]]
**[[Exterior algebra]]
**[[Symmetric algebra]]
**[[Clifford algebra]]
**[[Geometric algebra]]

==[[Affine space]] and related topics==

*[[Affine transformation]]
*[[Affine group]]
*[[Affine geometry]]
*[[Affine coordinate system]]
*[[Flat (geometry)]]
*[[Cartesian coordinate system]]
*[[Euclidean group]]
*[[Poincaré group]]
*[[Galilean group]]

==[[Projective space]]==
*[[Projective transformation]]
*[[Projective geometry]]
*[[Projective linear group]]
*[[Quadric]] and [[conic section]]

[[Category:Mathematics-related lists|Linear algebra]]
[[Category:Linear algebra|*]]
[[Category:Wikipedia outlines|Linear algebra]]
[[Category:Lists of topics|Linear algebra]]</text>
      <sha1>mcqucodjjbfzjnramp84qvamly6o9b9</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Hermann Weyl</title>
    <ns>0</ns>
    <id>7218498</id>
    <revision>
      <id>848708094</id>
      <parentid>840231611</parentid>
      <timestamp>2018-07-03T19:14:35Z</timestamp>
      <contributor>
        <username>DeprecatedFixerBot</username>
        <id>33330201</id>
      </contributor>
      <minor/>
      <comment>Removed deprecated parameter(s) from [[Template:Div col]] using [[User:DeprecatedFixerBot| DeprecatedFixerBot]]. Questions? See [[Template:Div col#Usage of "cols" parameter]] or [[User talk:TheSandDoctor|msg TSD!]] (please mention that this is task #2!))</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1866">This is a list of topics named after [[Hermann Weyl]], the influential German mathematician from the 20th century.
{{Div col|colwidth=25em}}
* [[De Donder–Weyl theory]]
* [[Majorana–Weyl spinor]]
* [[Peter–Weyl theorem]]
* [[Schur–Weyl duality]]
* [[Weyl algebra]]
* [[Weyl basis]] of the [[gamma matrices]]
* [[Weyl chamber]]
* [[Weyl character formula]]
* [[Weyl curvature]]: see Weyl tensor
* [[Weyl curvature hypothesis]]
* [[Weyl dimension formula]], a specialization of the character formula
* [[Weyl distance function]]
* [[Weyl equation]], a [[relativistic wave equation]]
* [[Weyl fermion]]
* [[Weyl gauge]]
* [[Conformal gravity|Weyl gravity]]
* [[Weyl group]]
** [[Length of a Weyl group element]]
* [[Weyl integral]]
* [[Weyl law]]
* [[Weyl metrics]]
* [[Weyl module]]
* [[Weyl notation]]
* [[Weyl quantization]]
* [[Weyl scalar]]
* [[Weyl semimetal]]
* [[Weyl sequence]]
* [[Weyl spinor]]
* [[Weyl sum]], a type of [[exponential sum]]
* [[Weyl symmetry]]: see Weyl transformation
* [[Weyl tensor]]
* [[Weyl transform]]
* [[Weyl transformation]]
* [[Weyl vector]] of a [[compact Lie group]]
* [[Weyl–Brauer matrices]]
* [[Weyl−Lewis−Papapetrou coordinates]]
* [[Weyl–Schouten theorem]]
* [[Weyl–von Neumann theorem]]
* [[Weyl's criterion]]
* [[Weyl's inequality]]
* [[Weyl's theorem (disambiguation)|Weyl's lemma]]: several results, for example;
** [[Weyl's lemma (Laplace equation)|Weyl's lemma]] on the "very weak" form of the [[Laplace equation]]
** [[Weyl sum|Weyl's lemma]] on [[hypoellipticity]]
** [[Weyl's paradox]] (properly the Grelling–Nelson paradox)
* [[Weyl's postulate]]
* [[Weyl's theorem on complete reducibility]]
* [[Weyl's tile argument]]
* [[Weyl's tube formula]]
* [[Weyl's unitary trick]]
* [[Weyl (crater)]]
{{div col end}}

{{DEFAULTSORT:Weyl, Hermann}}
[[Category:Lists of things named after mathematicians]]</text>
      <sha1>t9dmddrdvi2dbkmnkf9sv3ihnly0b7e</sha1>
    </revision>
  </page>
  <page>
    <title>Monatshefte für Mathematik</title>
    <ns>0</ns>
    <id>30852653</id>
    <revision>
      <id>799027181</id>
      <parentid>780495206</parentid>
      <timestamp>2017-09-05T05:57:51Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2293">{{Infobox journal
 | title        = Monatshefte für Mathematik
 | cover        = File:Monatshefte für Mathematik 1890 Titel.png
 | abbreviation = Monatsh. Math.
 | discipline   = [[Mathematics]]
 | editor       = Adrian Constantin
 | publisher    = [[Springer Science+Business Media|Springer]]
 | frequency    = Monthly
 | history      = 1890–present
 | impact       = 0.764
 | impact-year  = 2009
 | url          = https://www.springer.com/mathematics/journal/605
 | ISSN         = 0026-9255
 | eISSN        = 1436-5081
 | CODEN        = MNMTA2
 | LCCN         = 51026443
 | OCLC         = 01589453
 | formernames = Monatshefte für Mathematik und Physik
 | link1        = http://www.springerlink.com/content/1436-5081/ 
 | link1-name   = Online access
}}

''''' Monatshefte für Mathematik''''' is a [[peer review|peer-reviewed]] [[mathematics journal]] established in 1890.  Among its well-known papers is "[[Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I]]" by [[Kurt Gödel]], published in 1931.

The journal was founded by [[Gustav von Escherich]] and [[Emil Weyr]] in 1890 as ''Monatshefte für Mathematik und Physik'' and published until 1941. In 1947 it was reestablished by [[Johann Radon]] under its current title. It is currently published by [[Springer Science+Business Media|Springer]] in cooperation with the [[Austrian Mathematical Society]]. The journal is indexed by ''[[Mathematical Reviews]]'' and [[Zentralblatt MATH]].
Its 2009 [[Mathematical Citation Quotient|MCQ]] was 0.58, and its 2009 [[impact factor]] was 0.764.

==External links==
*{{Official website|1=https://www.springer.com/mathematics/journal/605}}
*[http://www.literature.at/viewer.alo?viewmode=overview&amp;objid=12405&amp;page= ''Monatshefte für Mathematik und Physik''] vol. 1&amp;ndash;29 (1890&amp;ndash;1918) at [[Austrian Literature Online|ALO]]
*[http://gdz.sub.uni-goettingen.de/dms/load/toc/?PID=PPN362162050 ''Monatshefte für Mathematik''] vol. 52&amp;ndash;126 (1948&amp;ndash;1998) at [[GDZ]]

{{DEFAULTSORT:Monatshefte fur Mathematik}}
[[Category:Mathematics journals]]
[[Category:Publications established in 1890]]
[[Category:English-language journals]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:Monthly journals]]


{{math-journal-stub}}</text>
      <sha1>j5hx0mu9merxyilrc0goybnr9b7dm23</sha1>
    </revision>
  </page>
  <page>
    <title>Moscow Mathematical Journal</title>
    <ns>0</ns>
    <id>4190631</id>
    <revision>
      <id>795224895</id>
      <parentid>795224782</parentid>
      <timestamp>2017-08-12T20:52:21Z</timestamp>
      <contributor>
        <username>Flyer22 Reborn</username>
        <id>4293477</id>
      </contributor>
      <comment>Comment: You need to source your content.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="967">{{Italic title}}
The '''''Moscow Mathematical Journal''''' is a [[mathematics journal]] published quarterly by the [[Independent University of Moscow]] and the [[HSE Faculty of Mathematics]] and distributed by the [[American Mathematical Society]]. The journal published its first issue in 2001. Its [[editor-in-chief|editors-in-chief]] are [[Yulij Ilyashenko]] ([[Independent University of Moscow]] and [[Cornell University]]), [[Michael Tsfasman]] ([[Independent University of Moscow]] and [[Aix-Marseille University]]), and [[Sabir Gusein-Zade]]  ([[Moscow State University]] and the Independent University of Moscow).
==External links==
* {{Official website|http://www.ams.org/distribution/mmj/}}

[[Category:Publications established in 2001]]
[[Category:Mathematics journals]]
[[Category:National Research University – Higher School of Economics academic journals]]
[[Category:Quarterly journals]]
[[Category:English-language journals]]


{{math-journal-stub}}</text>
      <sha1>8q4a2uyjvhjurri5ese0juo3bncxh8q</sha1>
    </revision>
  </page>
  <page>
    <title>Multiplication (music)</title>
    <ns>0</ns>
    <id>2540892</id>
    <revision>
      <id>865882316</id>
      <parentid>791889692</parentid>
      <timestamp>2018-10-26T20:02:11Z</timestamp>
      <contributor>
        <username>Squandermania</username>
        <id>7083768</id>
      </contributor>
      <minor/>
      <comment>/* Affine transformation */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22982">{{about|multiplication in music|multiplication in mathematics|Multiplication}}
[[File:Bartok - Third Quartet tetrachord multiplication.png|thumb|right|Example from [[Béla Bartók]]'s [[String Quartet No. 3 (Bartók)|Third Quartet]] ({{harvnb|Antokoletz|1993|loc=260}}, cited in {{harvnb|Schuijer|2008|loc=77–78}}): multiplication of a chromatic [[tetrachord]] ({{audio|Bartok - Third Quartet tetrachord multiplication top.mid|Play}}) to a [[quartal chord|fifths]] chord ({{audio|Bartok - Third Quartet tetrachord multiplication bottom.mid|Play}}). C{{music|#}}=0: 0·''7''='''0''', 1·''7''='''7''', 2·''7''='''2''', 3·''7''='''9''' (mod 12).]]
[[File:Bartok - Music for Strings, Percussion and Celesta interval expansion.png|thumb|350px|right|Bartók - ''[[Music for Strings, Percussion and Celesta]]'' interval expansion example, mov. I, mm. 1–5 and mov. IV, mm. 204–9 {{harv|Schuijer|2008|loc=79}} {{audio|Bartok - Music for Strings, Percussion and Celesta interval expansion.mid|Play}}.]]

The mathematical operations of '''multiplication''' have several applications to [[music]]. Other than its application to the frequency ratios of [[Interval (music)|intervals]] (e.g., [[Just intonation]], and the [[twelfth root of two]] in [[equal temperament]]), it has been used in other ways for [[twelve-tone technique]], and [[set theory (music)|musical set theory]]. Additionally [[ring modulation]] is an electrical audio process involving multiplication that has been used for musical effect.

A multiplicative operation is a [[Map (mathematics)|mapping]] in which the [[Mathematical argument|argument]] is multiplied {{harv|Rahn|1980|loc=53}}. Multiplication originated intuitively in '''interval expansion''', including [[tone row]] order number [[Rotation (mathematics)|rotation]], for example in the music of [[Béla Bartók]] and [[Alban Berg]] {{harv|Schuijer|2008|loc=77–78}}. Pitch number rotation, ''Fünferreihe'' or "five-series" and ''Siebenerreihe'' or "seven-series", was first described by [[Ernst Krenek]] in ''Über neue Musik'' ({{harvnb|Krenek|1937}}; {{harvnb|Schuijer|2008|loc=77–78}}). Princeton-based theorists, including [[James K. Randall|James K.]] {{harvtxt|Randall|1962}}, Godfrey {{harvtxt|Winham|1970}}, and Hubert S. {{harvtxt|Howe|1967}} "were the first to discuss and adopt them, not only with regards {{sic}} to twelve-tone series" {{harv|Schuijer|2008|loc=81}}.

== Pitch-class multiplication modulo 12 ==

When dealing with [[pitch class|pitch-class]] sets, multiplication [[modular arithmetic|modulo]] 12 is a common operation. Dealing with all [[twelve tone technique|twelve tones]], or a [[tone row]], there are only a few numbers which one may multiply a row by and still end up with a set of twelve distinct tones. Taking the prime or unaltered form as P&lt;sub&gt;0&lt;/sub&gt;, multiplication is indicated by &lt;math&gt;M_x&lt;/math&gt;, &lt;math&gt;x&lt;/math&gt; being the multiplicator:
*&lt;math&gt;M_x(y) \equiv xy \pmod{12}&lt;/math&gt;

The following table lists all possible multiplications of a chromatic twelve-tone row:

{| class="wikitable" style="text-align:center" align="center"
 |-
 ! M
 ! colspan="12" | M &amp;times; (0,1,2,3,4,5,6,7,8,9,10,11) mod 12
 |-
 ! width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 | width="20" | 0
 |- style="background:#ffdddd"
 ! 1
 | 0 || 1 || 2 || 3 || 4 || 5 || 6 || 7 || 8 || 9 || 10 || 11
 |-
 ! 2
 | 0 || 2 || 4 || 6 || 8 || 10 || 0 || 2 || 4 || 6 || 8 || 10
 |-
 ! 3
 | 0 || 3 || 6 || 9 || 0 || 3 || 6 || 9 || 0 || 3 || 6 || 9
 |-
 ! 4
 | 0 || 4 || 8 || 0 || 4 || 8 || 0 || 4 || 8 || 0 || 4 || 8
 |- style="background:#ffdddd"
 ! 5
 | 0 || 5 || 10 || 3 || 8 || 1 || 6 || 11 || 4 || 9 || 2 || 7
 |-
 ! 6
 | 0 || 6 || 0 || 6 || 0 || 6 || 0 || 6 || 0 || 6 || 0 || 6
 |- style="background:#ffdddd"
 ! 7
 | 0 || 7 || 2 || 9 || 4 || 11 || 6 || 1 || 8 || 3 || 10 || 5
 |-
 ! 8
 | 0 || 8 || 4 || 0 || 8 || 4 || 0 || 8 || 4 || 0 || 8 || 4
 |-
 ! 9
 | 0 || 9 || 6 || 3 || 0 || 9 || 6 || 3 || 0 || 9 || 6 || 3
 |-
 ! 10
 | 0 || 10 || 8 || 6 || 4 || 2 || 0 || 10 || 8 || 6 || 4 || 2
 |- style="background:#ffdddd"
 ! 11
 | 0 || 11 || 10 || 9 || 8 || 7 || 6 || 5 || 4 || 3 || 2 || 1
 |}

Note that only M&lt;sub&gt;1&lt;/sub&gt;, M&lt;sub&gt;5&lt;/sub&gt;, M&lt;sub&gt;7&lt;/sub&gt;, and M&lt;sub&gt;11&lt;/sub&gt; give a [[Bijection|one-to-one]] mapping (a complete set of 12 unique tones). This is because each of these numbers is [[relatively prime]] to 12. Also interesting is that the [[chromatic]] scale is mapped to the [[circle of fourths]] with M&lt;sub&gt;5&lt;/sub&gt;, or fifths with M&lt;sub&gt;7&lt;/sub&gt;, and more generally under M&lt;sub&gt;7&lt;/sub&gt; all even numbers stay the same while odd numbers are transposed by a [[tritone]]. This kind of multiplication is frequently combined with a [[Transposition (music)|transposition]] operation. It was first described in print by [[Herbert Eimert]], under the terms "Quartverwandlung" (fourth transformation) and "Quintverwandlung" (fifth transformation) {{harv|Eimert|1950|loc=29–33}}, and has been used by the composers [[Milton Babbitt]] ({{harvnb|Morris|1997|loc=238 &amp; 242–43}}; {{harvnb|Winham|1970|loc=65–66}}), [[Robert Morris (composer)|Robert]] {{harvtxt|Morris|1997|loc=238–39 &amp; 243}}, and [[Charles Wuorinen]] {{harv|Hibbard|1969|loc=157–58}}. This operation also accounts for certain harmonic transformations in jazz {{harv|Morris|1982|loc=153–54}}.

Thus multiplication by the two meaningful operations (5 &amp; 7) may be designated with '''''M'''''&lt;sub&gt;5&lt;/sub&gt;(''a'') and '''''M'''''&lt;sub&gt;7&lt;/sub&gt;(''a'') or '''''M''''' and '''''IM''''' {{harv|Schuijer|2008|loc=77–78}}.

*M&lt;sub&gt;1&lt;/sub&gt; = Identity
*M&lt;sub&gt;5&lt;/sub&gt; = Cycle of fourths transform
*M&lt;sub&gt;7&lt;/sub&gt; = Cycle of fifths transform
*M&lt;sub&gt;11&lt;/sub&gt; = Inversion
*M&lt;sub&gt;11&lt;/sub&gt;M&lt;sub&gt;5&lt;/sub&gt; = M&lt;sub&gt;7&lt;/sub&gt;
*M&lt;sub&gt;7&lt;/sub&gt;M&lt;sub&gt;5&lt;/sub&gt; = M&lt;sub&gt;11&lt;/sub&gt;
*M&lt;sub&gt;5&lt;/sub&gt;M&lt;sub&gt;5&lt;/sub&gt; = M&lt;sub&gt;1&lt;/sub&gt;
*M&lt;sub&gt;7&lt;/sub&gt;M&lt;sub&gt;11&lt;/sub&gt;M&lt;sub&gt;5&lt;/sub&gt; = M&lt;sub&gt;1&lt;/sub&gt;
*...

== Pitch multiplication ==

[[Pierre Boulez|Pierre]] {{harvtxt|Boulez|1971|loc={{Page needed|date=October 2010}}}}&lt;!--On pp. 79–80 Boulez speaks of "isomorphic families", "a double network of privileged series", "dividing" a series and "the whole is multiplied by each of its parts in turn", thereby creating "multiple isomorphic relationships", objects "multiplied by themselves", etc., but where is this expression "pitch multiplication"?--&gt; described an operation he called '''pitch multiplication''', which is somewhat akin {{Clarify|date=March 2013}} to the [[Cartesian product]] of pitch-class sets. Given two sets, the result of pitch multiplication will be the set of sums ([[modular arithmetic|modulo]] 12) of all possible pairings of elements between the original two sets. Its definition:

:&lt;math&gt;X \times Y = \{ (x+y)\bmod 12 | x\in X, y\in Y\}&lt;/math&gt;

For example, if multiplying a C-major chord &lt;math&gt;\{ 0,4,7 \}&lt;/math&gt; with a dyad containing '''C''','''D''' &lt;math&gt;\{ 0,2 \}&lt;/math&gt;, the result is:

:&lt;math&gt;\{ 0,4,7 \} \times \{ 0,2 \} = \{ 0,2,4,6,7,9 \}&lt;/math&gt;

In this example, a set of three pitches multiplied with a set of two pitches gives a new set of 3 &amp;times; 2 pitches. Given the limited space of modulo 12 arithmetic, when using this procedure very often duplicate tones are produced, which are generally omitted. This technique was used most famously in Boulez's 1955 ''[[Le marteau sans maître]]'', as well as in his [[Piano sonatas (Boulez)|Third Piano Sonata]], ''[[Pli selon pli]]'', ''Eclat'' (and ''Eclat multiples''), ''Figures-Doubles-Prisms'', ''Domaines'', and ''Cummings ist der Dichter'', as well as the withdrawn choral work, ''Oubli signal lapidé'' (1952) ({{harvnb|Koblyakov|1990}}; {{harvnb|Heinemann|1993}}; {{harvnb|Heinemann|1998}}).

[[Howard Hanson]] called this operation of [[commutative]] mathematical [[convolution]] "superposition"  {{harv|Hanson|1960|loc=44, 167}} or "@-projection" and used the "/" notation interchangeably.  Thus "p@m" or "p/m" means "perfect fifth at major third", e.g.: { C E G B }. He specifically noted that two triad forms could be so multiplied, or a triad multiplied by itself, to produce a resultant scale.  The latter "squaring" of a triad produces a particular scale highly saturated in instances of the source triad {{harv|Hanson|1960|loc=167}}. Thus "pmn", Hanson's name for common the major triad, when squared, is "PMN", e.g.: { C D E G G{{music|sharp}} B }.

[[Nicholas Slonimsky]] used this operation, non-generalized, to form 1300 scales by multiplying the [[Symmetry|symmetric]] [[tritone]]s, [[augmented chord]]s, [[diminished seventh chord]]s, and [[wholetone scale]]s by the sum of 3 factors which he called interpolation, infrapolation, and ultrapolation {{harv|Slonimsky|1947|loc=v}}.  The combination of interpolation, infrapolation, and ultrapolation, forming obliquely infra-interpolation, infra-ultrapolation, and infra-inter-ultrapolation, [[Addition|additively]] sums to what is effectively a second sonority.  This second sonority, multiplied by the first, gives his formula for generating scales and their [[harmonization]]s.

[[Joseph Schillinger]] used the idea, undeveloped, to categorize common 19th- and early 20th-century harmonic styles as product of horizontal harmonic root-motion and vertical harmonic structure {{harv|Schillinger|1941|loc=147}}. Some of the composers' styles which he cites appear in the following multiplication table.

{| class="wikitable" style="text-align:center" align="center"
|-
! colspan="1" | 
! colspan="4" | Chord Type
|-
! Root Scale !! [[Major chord]] !! [[Augmented chord]]!! [[Minor chord]] !! [[Diminished seventh chord]] 
|-
! [[Diminished seventh chord]] 
| [[Octatonic scale]]&lt;br /&gt;[[Richard Wagner]] || [[Chromatic scale]] || [[Octatonic scale]] || 
|-
! [[Augmented chord]] 
| [[Augmented scale]]&lt;br /&gt;[[Franz Liszt]] || [[Claude Debussy]]&lt;br /&gt;[[Maurice Ravel]] || [[Augmented scale]]&lt;br /&gt;[[Nikolai Rimsky-Korsakov]] || 
|-
! [[Wholetone scale]] 
| [[Chromatic scale]]&lt;br /&gt;[[Claude Debussy]]&lt;br /&gt;[[Maurice Ravel]] || [[Wholetone scale]]&lt;br /&gt;[[Claude Debussy]]&lt;br /&gt;[[Maurice Ravel]] || [[Chromatic scale]]&lt;br /&gt;[[Claude Debussy]]&lt;br /&gt;[[Maurice Ravel]] || 
|-
! [[Chromatic scale]] 
| [[Chromatic scale]]&lt;br /&gt;[[Richard Wagner]] || [[Chromatic scale]] || [[Chromatic scale]] || [[Chromatic scale]] 
|-
! [[Quartal chord]] 
| [[Major scale]] ||  || [[Aeolian scale|Natural]] [[Minor scale]] ||  
|-
! [[Major chord]] 
| [[Hexatonic scale|6-note analog of]] [[Harmonic major scale]] || [[Augmented scale]] || || [[Octatonic scale]]  
|-
! [[Minor chord]] 
| || [[Augmented scale]] || [[Hexatonic scale|6-note analog of]] [[Harmonic major scale]] || [[Octatonic scale]]  
|-
! [[Diatonic scale]] 
| [[Undecatonic scale]] || [[Chromatic scale]] || [[Undecatonic scale]] || [[Chromatic scale]]  
|}

The [[Approximation theory|approximation]] of the 12 pitches of Western music by [[Modular arithmetic|modulus-12 math]], forming the [[Necklace (combinatorics)|Circle of Halfsteps]], means that musical intervals can also be thought of as [[angle]]s in a [[polar coordinate system]], stacking of identical intervals as functions of [[Simple harmonic motion|harmonic motion]], and [[transposition (music)|transposition]] as [[Axis–angle representation|rotation around an axis]].  Thus, in the multiplication example above from Hanson, "p@m" or "p/m" ("perfect 5th at major 3rd", e.g.: { C E G B }) also means "perfect fifth, superimposed upon perfect fifth rotated 1/3 of the circumference of the Circle of Halfsteps".  A conversion table of intervals to angular measure (taken as negative numbers for clockwise rotation) follows:

{| class="wikitable" style="text-align:center" align="center"
|-
! colspan="1" rowspan="2"| Interval
! colspan="3" | Circle of Halfsteps
! colspan="3" | Circle of Fifths
|-
! Halfsteps !! Radians (times π) !! Degrees !! Fifths !! Radians (times π) !! Degrees
|-
! [[Unison]]
| 0 || 0 || 0 || 0 || 0 || 0
|-
! [[Minor second]]  
| 1 || 1/6 || 30 || 7 || 7/6 || 210
|-
! [[Major second]] 
| 2 || 1/3 || 60 || 2 || 1/3 || 60 
|-
! [[Minor third]] 
| 3 || 1/2 || 90 || 9 || 3/2 || 270 
|-
! [[Major third]]
| 4 || 2/3 || 120 || 4 || 2/3 || 120
|-
! [[Perfect fourth]] 
| 5 || 5/6 || 150 || 11 || 11/6 || 330
|-
! [[Diminished fifth]] or [[Augmented fourth]] 
| 6 || 1 || 180 || 6 || 1 || 180 
|-
! [[Perfect fifth]]
| 7 || 7/6 || 210 || 1 || 1/6 || 30
|-
! [[Minor sixth]]
| 8 || 4/3 || 240 || 8 || 4/3 || 240
|-
! [[Major sixth]]
| 9 || 3/2 || 270 || 3 || 1/2 || 90
|-
! [[Minor seventh]]
| 10 || 5/3 || 300 || 10 || 5/3 || 300
|-
! [[Major seventh]]
| 11 || 11/6 || 330 || 5 || 5/6 || 150
|-
! [[Octave]]  
| 12 || 2 || 360 || 12 || 2 || 360
|}

This angular interpretation of intervals is helpful to visualize a very practical example of multiplication in music: [[Euler–Fokker genus|Euler-Fokker genera]] used in describing the [[Just intonation]] [[Musical tuning|tuning]] of keyboard instruments {{harv|Fokker|1987}}. Each genus represents an harmonic function such as "3 perfect fifths stacked" or other sonority such as { C G D F{{music|sharp}} }, which, when multiplied by the correct angle(s) of copy, approximately [[Tessellation|fills]] the [[12TET]] [[Circumference|circumferential]] space of the [[Circle of fifths]].  It would be possible, though not musically pretty, to tune an [[Augmented chord|augmented triad]] of two perfect non-beating [[major third]]s, then (multiplying) tune two tempered [[Perfect fifth|fifths]] above and 1 below each note of the augmented chord; this is Euler-Fokker genus [555].  A different result is obtained by starting with the "3 perfect fifths stacked", and from these non-beating notes tuning a tempered [[major third]] above and below; this is Euler-Fokker genus [333].

==Time multiplication==
[[Joseph Schillinger]] described an operation of "[[Polynomial multiplication|polynomial time multiplication]]" (''polynomial'' refers to any rhythm consisting of more than one duration) corresponding roughly to that of [[#Pitch multiplication|Pitch multiplication]] above ({{harvnb|Schillinger|1941|loc=70–?}} {{Page needed|date=September 2014}}&lt;!--"70ff" is not adequate, since it might mean 70–72, 70–9361, or any terminal number larger than 71.--&gt;).  A theme, reduced to a consistent series of integers representing the quarter, 8th-, or 16th-note duration of each of the notes of the theme, could be [[Polynomial multiplication|multiplied]] by itself or the series of another theme to produce a coherent and related variation.  Especially, a theme's series could be squared or cubed or taken to higher powers to produce a saturation of related material.

==Affine transformation==
{{See also|Affine transformation}}[[File:Multiplication as mirror operation.png|thumb|350px|right|[[Chromatic scale]] into circle of fourths and/or fifths through multiplication as mirror operation ({{harvnb|Eimert|1950}}, {{Page needed|date=September 2014}}, as reproduced with minor alterations in {{harvnb|Schuijer|2008|loc=80}}) {{audio|Multiplication as mirror operation.mid|Play}} or {{audio|Chromatic scale ascending on C.mid|chromatic scale}}, {{audio|Circle of fifths desc within octave.mid|circle of fourths}}, or {{audio|Circle of fifths ascending within octave.mid|circle of fifths}}.]]

[[Herbert Eimert]] described what he called the "eight modes" of the twelve-tone series, all mirror forms of one another. The [[Melodic inversion|inverse]] is obtained through a horizontal mirror, the [[retrograde (music)|retrograde]] through a vertical mirror, the [[retrograde inversion|retrograde-inverse]] through both a horizontal and a vertical mirror, and the "cycle-of-fourths-transform" or ''Quartverwandlung'' and "cycle-of-fifths-transform" or ''Quintverwandlung'' obtained through a slanting mirror {{harv|Eimert|1950|loc=28–29}}. With the retrogrades of these transforms and the prime, there are eight [[permutation (music)|permutations]].

{{quote|Furthermore, one can sort of move the mirror at an angle, that is the 'angle' of a fourth or fifth, so that the chromatic row is reflected in both cycles.&amp;nbsp;.&amp;nbsp;.&amp;nbsp;. In this way, one obtains the cycle-of-fourths transform and the cycle-of-fifths transform of the row. ({{harvnb|Eimert|1950|loc=29}}, translated in {{harvnb|Schuijer|2008|loc=81}})}}

[[Joseph Schillinger]] embraced not only contrapuntal [[Melodic inversion|inverse]], [[retrograde (music)|retrograde]], and [[retrograde inversion|retrograde-inverse]]—operations of [[matrix multiplication]] in [[Euclidean space|Euclidean vector space]]—but also their rhythmic counterparts as well.  Thus he could describe a variation of theme using the same pitches in same order, but employing its original time values in [[Retrograde motion|retrograde]] order.  He saw the scope of this [[Map (mathematics)|multiplicatory universe]] beyond simple [[Reflection (mathematics)|reflection]], to include [[Translation (geometry)|transposition]] and [[Rotation (mathematics)|rotation]] (possibly with [[Projection (linear algebra)|projection]] back to source), as well as [[Dilation (affine geometry)|dilation]] which had formerly been limited in use to the time dimension (via [[Augmentation (music)#Augmentation in composition|augmentation]] and [[Diminution#Diminution in composition|diminution]]) ({{harvnb|Schillinger|1941|loc=187ff}}{{Page needed|date=February 2014}}&lt;!--Use of "ff" is discouraged because it is vague; please supply exact terminal page number instead.--&gt;). Thus he could describe another variation of theme, or even of a basic scale, by multiplying the halfstep counts between each successive pair of notes by some factor, possibly [[Normalized vector|normalizing]] to the octave via [[Modulo operation|Modulo]]-12 operation ({{harvnb|Schillinger|1941|loc=115ff{{Page needed|date=February 2014}}&lt;!--Use of "ff" is discouraged because it is vague; please supply exact terminal page number instead.--&gt;, 208ff{{Page needed|date=February 2014}}&lt;!--Use of "ff" is discouraged because it is vague; please supply exact terminal page number instead.--&gt;}}).

==Z-relation==
Some [[Interval vector|Z-related]] chords are connected by ''M'' or ''IM'' (multiplication by 5 or multiplication by 7), due to identical entries for 1 and 5 on the [[interval vector|APIC vector]] {{harv|Schuijer|2008|loc=98n18}}.

== References ==
* {{wikicite|ref={{harvid|Antokoletz|1993}}|reference=Antokoletz, Elliott. 1993. "Middle Period String Quartets". In ''The Bartok Companion'', edited by Malcolm Gillies, 257–77. London: Faber and Faber. {{ISBN|0-571-15330-5}} (cased); {{ISBN|0-571-15331-3}} (pbk).}}
* {{wikicite|ref={{harvid|Boulez|1971}}|reference=Boulez, Pierre. 1971. ''Boulez on Music Today''. Translated by Susan Bradshaw and Richard Rodney Bennett. Cambridge, Mass.: Harvard University Press. {{ISBN|0-674-08006-8}}.}}
* {{wikicite|ref={{harvid|Eimert|1950}}|reference=Eimert, Herbert. 1950. ''Lehrbuch der Zwölftontechnik''. Wiesbaden: Breitkopf &amp; Härtel.}}
* {{wikicite|ref={{harvid|Fokker|1987}}|reference=Fokker, Adriaan Daniël. 1987. ''Selected Musical Compositions''. Utrech: The Diapason Press. {{ISBN|90-70907-11-9}}.}}
* {{wikicite|ref={{harvid|Hanson|1960}}|reference=Hanson, Howard. 1960. ''Harmonic Materials of Modern Music''. New York: Appleton-Century-Crofts.}}
* {{wikicite|ref={{harvid|Heinemann|1993}}|reference=Heinemann, Stephen. 1993. "Pitch-Class Set Multiplication in Boulez's Le Marteau sans maître. D.M.A. diss., University of Washington.}}
* {{wikicite|ref={{harvid|Heinemann|1998}}|reference=Heinemann, Stephen. 1998. "Pitch-Class Set Multiplication in Theory and Practice." ''Music Theory Spectrum'' 20, no. 1 (Spring): 72-96.}}
* {{wikicite|ref={{harvid|Hibbard|1969}}|reference=Hibbard, William. 1969. "Charles Wuorinen: ''The Politics of Harmony''". ''Perspectives of New Music'' 7, no. 2 (Spring-Summer): 155–66.}}
* {{wikicite|ref={{harvid|Howe|1985}}|reference=Howe, Hubert S. 1965. “Some Combinational Properties of Pitch Structures.” ''Perspectives of New Music'' 4, no. 1 (Fall-Winter): 45–61.}}
* {{wikicite|ref={{harvid|Koblyakov|1990}}|reference=Koblyakov, Lev . 1990. ''Pierre Boulez: A World of Harmony''. Chur: Harwood Academic Publishers. {{ISBN|3-7186-0422-1}}.}}
* {{wikicite|ref={{harvid|Krenek|1937}}|reference=[[Ernst Krenek|Krenek, Ernst]]. 1937. ''Über neue Musik: Sechs Vorlesungen zur Einführung in die theoretischen Grundlagen''. Vienna: Ringbuchhandlung.}}
* {{wikicite|ref={{harvid|Morris|1982}}|reference=Morris, Robert D. 1982. Review: "[[John Rahn]], ''Basic Atonal Theory''. New York: Longman, 1980". ''Music Theory Spectrum'' 4:138–54.}}
* {{wikicite|ref={{harvid|Morris|1997}}|reference=Morris, Robert D. 1997. "Some Remarks on ''Odds and Ends''". ''Perspectives of New Music'' 35, no. 2 (Summer): 237–56.}}
* {{wikicite|ref={{harvid|Rahn|1980}}|reference=Rahn, John. 1980. ''Basic Atonal Theory''. Longman Music Series. New York and London: Longman. Reprinted, New York: Schirmer Books; London: Collier Macmillan, 1987.}}
* {{wikicite|ref={{harvid|Randall|1962}}|reference=[[James K. Randall|Randall, James K.]] 1962. "Pitch-Time Correlation". Unpublished. Cited in Schuijer 2008, 82.}}
* {{wikicite|ref={{harvid|Schillinger|1941}}|reference=Schillinger, Joseph. 1941. ''The Schillinger System of Musical Composition''. New York: Carl Fischer. {{ISBN|0306775220}}.}}
* {{wikicite|ref={{harvid|Schuijer|2008}}|reference=Schuijer, Michiel. 2008. ''Analyzing Atonal Music: Pitch-Class Set Theory and Its Contexts''. Eastman Studies in Music 60. Rochester, NY: University of Rochester Press. {{ISBN|978-1-58046-270-9}}.}}
* {{wikicite|ref={{harvid|Slonimsky|1947}}|reference=Slonimsky, Nicholas.  1947. ''Thesaurus of Scales and Melodic Patterns''. New York: Charles Scribner Sons. {{ISBN|002-6118505}}.}}
* {{wikicite|ref={{harvid|Winham|1970}}|reference=Winham, Godfrey. 1970. “Composition with Arrays”. ''Perspectives of New Music'' 9, no. 1 (Fall-Winter): 43–67.}}

== Further reading ==
* {{wikicite|ref={{harvid|Morris|1977}}|reference=Morris, Robert D. 1977. "On the Generation of Multiple-Order-Function Twelve-Tone Rows". ''Journal of Music Theory'' 21, no. 2 (Autumn): 238–62.}}
* {{wikicite|ref={{harvid|Morris|1982–83}}|reference=Morris, Robert D. 1982–83. "[[Combinatoriality]] without the [[tone row#total chromatic|Aggregate]]". ''Perspectives of New Music'' 21, nos. 1 &amp; 2 (Autumn-Winter/Spring-Summer): 432–86.}}
* {{wikicite|ref={{harvid|Morris|1990}}|reference=Morris, Robert D. 1990. "Pitch-Class Complementation and Its Generalizations". ''Journal of Music Theory'' 34, no. 2 (Autumn): 175–245.}}
* {{wikicite|ref={{harvid|Starr|1978}}|reference=Starr, Daniel V. 1978. "Sets, Invariance, and Partitions." ''Journal of Music Theory'' 22, no. 1:1–42.}}

{{Set theory (music)}}
{{Twelve-tone technique}}

[[Category:Musical techniques]]
[[Category:Mathematics of music]]</text>
      <sha1>auy35w0ojgt8ldboovvjaltdpk0rp3j</sha1>
    </revision>
  </page>
  <page>
    <title>Neyman–Pearson lemma</title>
    <ns>0</ns>
    <id>685158</id>
    <revision>
      <id>864995010</id>
      <parentid>864629726</parentid>
      <timestamp>2018-10-21T00:07:12Z</timestamp>
      <contributor>
        <ip>165.124.144.206</ip>
      </contributor>
      <comment>Edited formatting and changed Neyman-Santos back to Neyman-Pearson.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8976">{{More footnotes|date=May 2018}}

In [[statistics]], the '''Neyman–Pearson [[lemma (mathematics)|lemma]]''' was introduced by [[Jerzy Neyman]] and [[Egon Pearson]] in a paper in 1933.&lt;ref&gt;{{Cite journal|last=Neyman|first=J.|last2=Pearson|first2=E. S.|date=1933-02-16|title=IX. On the problem of the most efficient tests of statistical hypotheses|url=http://rsta.royalsocietypublishing.org/content/231/694-706/289|journal=Phil. Trans. R. Soc. Lond. A|language=en|volume=231|issue=694-706|pages=289–337|doi=10.1098/rsta.1933.0009|issn=0264-3952}}&lt;/ref&gt;

Suppose one is performing a [[statistical hypothesis testing|hypothesis test]] between two [[Statistical hypothesis testing#Definition of terms|simple hypotheses]] ''H''&lt;sub&gt;0&lt;/sub&gt;:&amp;nbsp;''θ''&amp;nbsp;=&amp;nbsp;''θ''&lt;sub&gt;0&lt;/sub&gt; and ''H''&lt;sub&gt;1&lt;/sub&gt;:&amp;nbsp;''θ''&amp;nbsp;=&amp;nbsp;''θ''&lt;sub&gt;1&lt;/sub&gt; using the [[likelihood-ratio test]] with threshold &lt;math&gt;\eta&lt;/math&gt;,  which rejects ''H''&lt;sub&gt;0&lt;/sub&gt; in favour of ''H''&lt;sub&gt;1&lt;/sub&gt; at a significance level of 
:&lt;math&gt;\alpha = P(\Lambda(X)\leq \eta\mid H_0),&lt;/math&gt;
where
:&lt;math&gt;\Lambda(x) := \frac{ \mathcal{L}(\theta_0 \mid x)}{ \mathcal{L}(\theta_1 \mid x)}&lt;/math&gt;
and &lt;math&gt;\mathcal{L}(\theta \mid x)&lt;/math&gt; is the likelihood function.
Then, the lemma states that &lt;math&gt;\Lambda(x)&lt;/math&gt; is the '''most [[Statistical power|powerful]] test''' at [[Statistical hypothesis testing#Definition of terms|significance level ''α'']].

If the test is most powerful for all &lt;math&gt;\theta_1 \in \Theta_1&lt;/math&gt;, it is said to be [[uniformly most powerful]] (UMP) for alternatives in the set &lt;math&gt;\Theta_1 &lt;/math&gt;.

In practice, the [[Likelihood function|likelihood ratio]] is often used directly to construct tests — see [[likelihood-ratio test]]. However it can also be used to suggest particular test-statistics that might be of interest or to suggest simplified tests — for this, one considers algebraic manipulation of the ratio to see if there are key statistics in it related to the size of the ratio (i.e. whether a large statistic corresponds to a small ratio or to a large one).

== Proof ==
Define the rejection region of the null hypothesis for the Neyman–Pearson (NP) test as

:&lt;math&gt;R_{NP}=\left\{ x : \frac{\mathcal{L}(\theta_0 \mid x)}{\mathcal{L}(\theta_1 \mid x)} \leqslant \eta \right\}&lt;/math&gt;

where &lt;math&gt;\eta&lt;/math&gt; is chosen so that &lt;math&gt;P(R_{NP},\theta_0)=\alpha.&lt;/math&gt;

Any other test will have a different rejection region that we denote by &lt;math&gt;R_A&lt;/math&gt;. The probability of the data falling in region &lt;math&gt;R,&lt;/math&gt; given parameter &lt;math&gt;\theta&lt;/math&gt; is

:&lt;math&gt;P(R,\theta)=\int_R \mathcal{L}(\theta \mid x)\, dx. &lt;/math&gt;

For the test with critical region &lt;math&gt;R_A&lt;/math&gt; to have level &lt;math&gt;\alpha&lt;/math&gt;, it must be true that &lt;math&gt;\alpha \geqslant  P(R_A, \theta_0) &lt;/math&gt;, hence

:&lt;math&gt;\alpha= P(R_{NP}, \theta_0) \geqslant  P(R_A, \theta_0).&lt;/math&gt;

It will be useful to break these down into integrals over distinct regions:

:&lt;math&gt;\begin{align}
P(R_{NP},\theta) &amp;= P(R_{NP} \cap R_A, \theta) + P(R_{NP} \cap R_A^c, \theta) \\
P(R_A,\theta) &amp;= P(R_{NP} \cap R_A, \theta) + P(R_{NP}^c \cap R_A, \theta)
\end{align}&lt;/math&gt;

Setting &lt;math&gt;\theta=\theta_0&lt;/math&gt;, these two expressions and the above inequality yield that

:&lt;math&gt;P(R_{NP} \cap R_A^c, \theta_0) \geqslant   P(R_{NP}^c \cap R_A, \theta_0).&lt;/math&gt;

The powers of the two tests are &lt;math&gt;P(R_{NP},\theta_1)&lt;/math&gt; and &lt;math&gt;P(R_A,\theta_1)&lt;/math&gt;, and we would like to prove that:

:&lt;math&gt;P(R_{NP},\theta_1) \geqslant P(R_A,\theta_1) &lt;/math&gt;

However, as shown above this is equivalent to:

&lt;math&gt;P(R_{NP} \cap R_A^c, \theta_1) \geqslant P(R_{NP}^c \cap R_A, \theta_1) &lt;/math&gt;

in what follows we show that the above [[Inequality (mathematics)|inequality]] holds:

:''&lt;math&gt;\begin{align}
P(R_{NP} \cap R_A^c, \theta_1) &amp;= \int_{R_{NP}\cap R_A^c} \mathcal{L}(\theta_1 \mid x)\,dx \\ [4pt]
&amp;\geqslant \frac{1}{\eta} \int_{R_{NP}\cap R_A^c} \mathcal{L}(\theta_0 \mid x)\,dx &amp;&amp; \text{by definition of } R_{NP} \text{ this is true for its subset}\\ [4pt]
&amp;= \frac{1}{\eta}P(R_{NP} \cap R_A^c, \theta_0) &amp;&amp; \text{by definition of } P(R, \theta) \\ [4pt]
&amp;\geqslant \frac{1}{\eta}P(R_{NP}^c \cap R_A, \theta_0) \\ [4pt]
&amp;= \frac{1}{\eta}\int_{R_{NP}^c \cap R_A} \mathcal{L}(\theta_0 \mid x)\,dx \\ [4pt]
&amp;&gt; \int_{R_{NP}^c\cap R_A} \mathcal{L}(\theta_1 \mid x)\, dx &amp;&amp; \text{by definition of } R_{NP} \text{ this is true for its complement and complement subsets}\\ [4pt]
&amp; = P(R_{NP}^c \cap R_A, \theta_1)
\end{align}&lt;/math&gt;''

== Example ==

Let &lt;math&gt;X_1,\dots,X_n&lt;/math&gt; be a random sample from the &lt;math&gt;\mathcal{N}(\mu,\sigma^2)&lt;/math&gt; distribution where the mean &lt;math&gt;\mu&lt;/math&gt; is known, and suppose that we wish to test for &lt;math&gt;H_0:\sigma^2=\sigma_0^2&lt;/math&gt; against &lt;math&gt;H_1:\sigma^2=\sigma_1^2&lt;/math&gt;. The likelihood for this set of [[normally distributed]] data is

:&lt;math&gt;\mathcal{L}\left(\sigma^2\mid\mathbf{x}\right)\propto \left(\sigma^2\right)^{-n/2} \exp\left\{-\frac{\sum_{i=1}^n (x_i-\mu)^2}{2\sigma^2}\right\}.&lt;/math&gt;

We can compute the [[Likelihood function|likelihood ratio]] to find the key statistic in this test and its effect on the test's outcome:

:&lt;math&gt;\Lambda(\mathbf{x}) = \frac{\mathcal{L}\left({\sigma_0}^2\mid\mathbf{x}\right)}{\mathcal{L}\left({\sigma_1}^2\mid\mathbf{x}\right)} =
\left(\frac{\sigma_0^2}{\sigma_1^2}\right)^{-n/2} \exp\left\{-\frac{1}{2}(\sigma_0^{-2} -\sigma_1^{-2})\sum_{i=1}^n (x_i-\mu)^2\right\}.&lt;/math&gt;

This ratio only depends on the data through &lt;math&gt;\sum_{i=1}^n (x_i-\mu)^2&lt;/math&gt;. Therefore, by the Neyman–Pearson lemma, the most [[Statistical power|powerful]] test of this type of [[Statistical hypothesis testing|hypothesis]] for this data will depend only on &lt;math&gt;\sum_{i=1}^n (x_i-\mu)^2&lt;/math&gt;. Also, by inspection, we can see that if &lt;math&gt;\sigma_1^2&gt;\sigma_0^2&lt;/math&gt;, then &lt;math&gt;\Lambda(\mathbf{x})&lt;/math&gt; is a [[decreasing function]] of &lt;math&gt;\sum_{i=1}^n (x_i-\mu)^2&lt;/math&gt;. So we should reject &lt;math&gt;H_0&lt;/math&gt; if &lt;math&gt;\sum_{i=1}^n (x_i-\mu)^2&lt;/math&gt; is sufficiently large. The rejection threshold depends on the [[Type I and type II errors|size]]  of the test. In this example, the test statistic can be shown to be a scaled Chi-square distributed random variable and an exact critical value can be obtained.

== Application in economics ==
A variant of the Neyman–Pearson lemma has found an application in the seemingly unrelated domain of the economics of land value. One of the fundamental problems in [[consumer theory]] is calculating the [[demand function]] of the consumer given the prices. In particular, given a heterogeneous land-estate, a price measure over the land, and a subjective utility measure over the land, the consumer's problem is to calculate the best land parcel that he can buy – i.e. the land parcel with the largest utility, whose price is at most his budget. It turns out that this problem is very similar to the problem of finding the most powerful statistical test, and so the Neyman–Pearson lemma can be used.&lt;ref&gt;{{Cite journal | doi = 10.1016/0022-0531(84)90091-7| title = A characterization of the demand for land| journal = Journal of Economic Theory| volume = 33| issue = 2| pages = 289| year = 1984| last1 = Berliant | first1 = M. }}&lt;/ref&gt;

== Uses in electronics engineering ==
The Neyman–Pearson lemma is quite useful in [[electronics engineering]], namely in the design and use of [[radar]] systems, [[data transmission|digital communication system]]s, and in [[signal processing]] systems. 
In radar systems, the Neyman–Pearson lemma is used in first setting the rate of [[False positives and false negatives#False negative error|missed detection]]s to a desired (low) level, and then minimizing the rate of [[False positives and false negatives#False positive error|false alarm]]s, or vice versa.
Neither false alarms nor missed detections can be set at arbitrarily low rates, including zero. All of the above goes also for many systems in signal processing.

== Uses in particle physics ==
The Neyman–Pearson lemma is applied to the construction of analysis-specific likelihood-ratios, used to e.g. test for signatures of [[new physics]] against the nominal [[Standard Model]] prediction in proton-proton collision datasets collected at the [[Large Hadron Collider|LHC]].

== See also ==
* [[Statistical power]]
* [[F-distribution|the Fisher F-test]]

== References ==
{{reflist}}

* E. L. Lehmann, Joseph P. Romano, ''Testing statistical hypotheses'', Springer, 2008, p.&amp;nbsp;60

== External links ==
* Cosma Shalizi, a professor of statistics at Carnegie–Mellon University, gives an intuitive derivation of the Neyman–Pearson Lemma [http://bactra.org/weblog/630.html using ideas from economics]
* [http://cnx.org/content/m11548/latest/ cnx.org: Neyman–Pearson criterion]

{{DEFAULTSORT:Neyman-Pearson Lemma}}
[[Category:Statistical theorems]]
[[Category:Statistical tests]]
[[Category:Articles containing proofs]]
[[Category:Lemmas]]</text>
      <sha1>5xp5rtz7nips2gmbdsghvr532z0v3lf</sha1>
    </revision>
  </page>
  <page>
    <title>Non-constructive algorithm existence proofs</title>
    <ns>0</ns>
    <id>44465987</id>
    <revision>
      <id>841541046</id>
      <parentid>808405829</parentid>
      <timestamp>2018-05-16T13:30:28Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8939">The vast majority of positive results about [[computational problem]]s are [[constructive proof]]s, i.e., a computational problem is proved to be solvable by showing an [[algorithm]] that solves it; a computational problem is shown to be in [[P (complexity)]] by showing an algorithm that solves it in time that is polynomial in the size of the input; etc.

However, there are several [[non-constructive]] results, where an algorithm is proved to exist without showing the algorithm itself. Several techniques are used to provide such existence proofs.

== Using an unknown finite set ==

===In combinatorial game theory===
A simple example of a non-constructive algorithm was published in 1982 by [[Elwyn R. Berlekamp]], [[John H. Conway]], and [[Richard K. Guy]], in their book ''[[Winning Ways for your Mathematical Plays]]''. It concerns the game of [[Sylver Coinage]], in which players take turns specifying a positive integer that cannot be expressed as a sum of previously specified values, with a player losing when they are forced to specify the number&amp;nbsp;1. There exists an algorithm (given in the book as a flow chart) for determining whether a given first move is winning or losing: if it is a [[prime number]] greater than three, or one of a finite set of [[smooth number|3-smooth numbers]], then it is a winning first move, and otherwise it is losing. However, the finite set is not known.

===In graph theory===
Non-constructive algorithm proofs  for problems in [[graph theory]] were studied beginning in 1988 by [[Michael Fellows]] and [[Michael Langston]].&lt;ref name=FellowsLangston1988&gt;{{Cite journal | doi = 10.1145/44483.44491| title = Nonconstructive tools for proving polynomial-time decidability| journal = Journal of the ACM| volume = 35| issue = 3| pages = 727| year = 1988| last1 = Fellows | first1 = M. R. | last2 = Langston | first2 = M. A. }}&lt;/ref&gt;

A common question in graph theory is whether a certain input graph has a certain property. For example:

:::Input: a graph ''G''.
:::Question: Can ''G'' be embedded in a 3-dimensional space, such that no two disjoint cycles of ''G'' are topologically linked (as in links of a chain)?

There is a highly exponential algorithm that decides whether two cycles embedded in a 3d-space are linked, and one could test all pairs of cycles in the graph, but it is not obvious how to account for all possible embeddings in a 3d-space. Thus, it is a-priori not clear at all if the linkedness problem is decidable.

However, there is a non-constructive proof that shows that linkedness is decidable in polynomial time. The proof relies on the following facts:

* The set of graphs for which the answer is "yes" is closed under taking [[minor (graph theory)|minors]]. I.e., if a graph G can be embedded linklessly in 3-d space, then every minor of G can also be embedded linklessly.
* For every two graphs G and H, it is possible to find in polynomial time whether H is a minor of G.
* By [[Robertson–Seymour theorem]], any set of finite graphs contains only a finite number of minor-minimal elements. In particular, the set of "yes" instances has a finite number of minor-minimal elements.

Given an input graph G, the following "algorithm" solves the above problem:
:: For every minor-minimal element H:
:::: If H is a minor of G then return "yes".
:: return "no".

The non-constructive part here is the Robertson–Seymour theorem. Although it guarantees that there is a finite number of minor-minimal elements it does not tell us what these elements are. Therefore, we cannot really execute the "algorithm" mentioned above. But, we do know that an algorithm exists and that its runtime is polynomial.

There are many more similar problems whose decidability can be proved in a similar way. In some cases, the knowledge that a problem can be proved in a polynomial time has led researchers to search and find an actual polynomial-time algorithm that solves the problem in an entirely different way. This shows that non-constructive proofs can have constructive outcomes.&lt;ref name=FellowsLangston1988 /&gt;

The main idea is that a problem can be solved using an algorithm that uses, as a parameter, an unknown set. Although the set is unknown, we know that it must be finite, and thus a polynomial-time algorithm exists.

There are many other combinatorial problems that can be solved with a similar technique.&lt;ref&gt;{{Cite journal | doi = 10.1080/00207168908803783| title = Polynomial-time self-reducibility: Theoretical motivations and practical results∗| journal = International Journal of Computer Mathematics| volume = 31| pages = 1| year = 2007| last1 = Brown | first1 = D. J. | last2 = Fellows | first2 = M. R. | last3 = Langston | first3 = M. A. }}&lt;/ref&gt;

== Counting the algorithms ==

Sometimes the number of potential algorithms for a given problem is finite. We can count the number of possible algorithms and prove that only a bounded number of them are "bad", so at least one algorithm must be "good".

As an example, consider the following problem.&lt;ref name=GrebinskyKucherov2000&gt;{{Cite journal | doi = 10.1007/s004530010033| title = Optimal Reconstruction of Graphs under the Additive Model| journal = Algorithmica| volume = 28| pages = 104| year = 2000| last1 = Grebinski | first1 = V.| last2 = Kucherov | first2 = G.}}&lt;/ref&gt;

I select a vector ''v'' composed of ''n'' elements which are integers between 0 and a certain constant ''d''.

You have to guess ''v'' by asking ''sum queries'', which are queries of the form: "what is the sum of the elements with indices ''i'' and ''j''?". A sum query can relate to any number of indices from 1 to ''n''.

How many queries do you need? Obviously, ''n'' queries are always sufficient, because you can use ''n'' queries asking for the "sum" of a single element. But when ''d'' is sufficiently small, it is possible to do better. The general idea is as follows.

Every query can be represented as a 1-by-''n'' vector whose elements are all in the set {0,1}. The response to the query is just the dot product of the query vector by ''v''.   Every set of ''k'' queries can be represented by an ''k''-by-''n'' matrix over {0,1}; the set of responses is the product of the matrix by ''v''.

A matrix ''M'' is "good" if it enables us to uniquely identify ''v''. This means that, for every vector ''v'', the product ''M v'' is different.  A matrix ''M'' is "bad" if there are two different vectors, ''v'' and ''u'', such that ''M v'' = ''M u''.

Using some algebra, it is possible to bound the number of "bad" matrices. The bound is a function of ''d'' and ''k''. Thus, for a sufficiently small ''d'', there must be a "good" matrix with a small ''k'', which corresponds to an efficient algorithm for solving the identification problem.

This proof is non-constructive in two ways: it is not known how to find a good matrix; and even if a good matrix is supplied, it is not known how to efficiently re-construct the vector from the query replies.

There are many more similar problems which can be proved to be solvable in a similar way.&lt;ref name=GrebinskyKucherov2000/&gt;

== Additional examples ==
* Some computational problems can be shown to be decidable by using the [[Law of Excluded Middle#Use in computer science proofs|Law of Excluded Middle]]. Such proofs are usually not very useful in practice, since the problems involved are quite artificial.
* An example from [[Quantum complexity theory]] (related to [[Quantum query complexity]]) is given in.&lt;ref&gt;{{Cite journal | doi = 10.4086/cjtcs.2013.004| year = 2013| last1 = Kimmel | first1 = S.| title = Quantum Adversary (Upper) Bound| journal = Chicago Journal of Theoretical Computer Science| volume = 19| pages = 1–14| arxiv = 1101.0797}}&lt;/ref&gt;

== References ==
{{reflist}}

== Credits ==
The references in this page were collected from the following [[Stack Exchange]] threads: 
* {{Cite web|first1=|title=Are there problems without efficient algorithms, where existence theorems have proved such algorithms must exist?|url=http://cstheory.stackexchange.com/questions/4777/are-there-problems-without-efficient-algorithms-where-existence-theorems-have-p|website=CS Theory Stack Exchange|accessdate=21 November 2014}}
* {{Cite web|title=Are there non-constructive algorithm existence proofs?|url=http://cstheory.stackexchange.com/questions/12162/are-there-non-constructive-algorithm-existence-proofs|website=CS Theory Stack Exchange|accessdate=21 November 2014}}
* {{Cite web|title=Is there an algorithm that provably exists although we don't know what it is?|url=http://cs.stackexchange.com/questions/32325/is-there-an-algorithm-that-provably-exists-although-we-dont-know-what-it-is|website=Computer Science Stack Exchange|accessdate=21 November 2014}}

== See also ==
* [[Existence theorem#'Pure' existence results]]
* [[Constructive proof#Non-constructive proofs]]

[[Category:Computational complexity theory]]
[[Category:Constructivism (mathematics)]]</text>
      <sha1>801s3bileaf29xncgfm8pxw1bfgp1rw</sha1>
    </revision>
  </page>
  <page>
    <title>Phase response</title>
    <ns>0</ns>
    <id>1543837</id>
    <revision>
      <id>825251197</id>
      <parentid>825250959</parentid>
      <timestamp>2018-02-12T09:23:56Z</timestamp>
      <contributor>
        <ip>14.139.87.181</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="990">{{Unreferenced|date=October 2009}}

In [[signal processing]], '''phase response''' is the relationship between the [[phase (waves)|phase]] of a [[Sine wave|sinusoid]]al input and the output [[signal (information theory)|signal]] passing through any device that accepts input and produces an output signal, such as an [[amplifier]] or a [[filter (signal processing)|filter]].

Amplifiers, filters, and other devices are often categorized by their amplitude and/or phase response. The amplitude response is the ratio of output amplitude to input, usually a function of the frequency. Similarly, phase response is the phase of the output with the input as reference. The input is defined as zero phase. A phase response is not limited to lying between 0° and 360°, as phase can accumulate to any amount of time.

==See also==
* [[Group delay and phase delay]]

{{DEFAULTSORT:Phase Response}}
[[Category:Trigonometry]]
[[Category:Wave mechanics]]
[[Category:Signal processing]]

{{Tech-stub}}</text>
      <sha1>2w772uo83kotv0qwzrg0ovtqy0sk1sk</sha1>
    </revision>
  </page>
  <page>
    <title>Polyhedral graph</title>
    <ns>0</ns>
    <id>24656270</id>
    <revision>
      <id>814446173</id>
      <parentid>814406571</parentid>
      <timestamp>2017-12-08T21:49:16Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 814406571 by [[Special:Contributions/2620:DF:8000:540A:0:2:FD64:97E4]] true but misplaced</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5029">[[File:Dodecahedron schlegel diagram.png|thumb|The polyhedral graph formed as the [[Schlegel diagram]] of a [[regular dodecahedron]].]]
[[File:Truncated icosidodecahedral graph.png|thumb|Schlegel diagram of [[truncated icosidodecahedral graph]]]]
In [[geometric graph theory]], a branch of [[mathematics]], a '''polyhedral graph''' is the [[undirected graph]] formed from the vertices and edges of a [[convex polyhedron]]. Alternatively, in purely graph-theoretic terms, the polyhedral graphs are the [[k-vertex-connected graph|3-vertex-connected]] [[planar graph]]s.

==Characterization==
The [[Schlegel diagram]] of a convex polyhedron represents its vertices and edges as points and line segments in the [[Euclidean plane]], forming a subdivision of an outer [[convex polygon]] into smaller convex polygons. It has no crossings, so every polyhedral graph is also a [[planar graph]]. Additionally, by [[Balinski's theorem]], it is a [[k-vertex-connected graph|3-vertex-connected graph]].

According to [[Steinitz's theorem]], these two graph-theoretic properties are enough to completely [[Characterization (mathematics)|characterize]] the polyhedral graphs: they are exactly the 3-vertex-connected planar graphs. That is, whenever a graph is both planar and 3-vertex-connected, there exists a polyhedron whose vertices and edges form an [[graph isomorphism|isomorphic]] graph.&lt;ref&gt;''Lectures on Polytopes'', by [[Günter M. Ziegler]] (1995) {{isbn|0-387-94365-X}} , Chapter 4 "Steinitz' Theorem for 3-Polytopes", p.103.&lt;/ref&gt;&lt;ref name=grun&gt;{{citation|first=Branko|last=Grünbaum|authorlink=Branko Grünbaum|title=Convex Polytopes|edition=2nd|year=2003|isbn=978-0-387-40409-7|publisher=Springer-Verlag|series=[[Graduate Texts in Mathematics]]|volume=221}}.&lt;/ref&gt; Given such a graph, a representation of it as a subdivision of a convex polygon into smaller convex polygons may be found using the [[Tutte embedding]].&lt;ref&gt;{{Citation
 | last = Tutte | first = W. T. | authorlink = W. T. Tutte
 | title = How to draw a graph
 | journal = Proceedings of the London Mathematical Society
 | volume = 13
 | year = 1963
 | pages = 743–767
 | mr = 0158387
 | doi = 10.1112/plms/s3-13.1.743}}.&lt;/ref&gt;

==Hamiltonicity and shortness==
[[Tait's conjecture|Tait conjectured]] that every [[cubic graph|cubic]] polyhedral graph (that is, a polyhedral graph in which each vertex is incident to exactly three edges) has a [[Hamiltonian cycle]], but this conjecture was disproved by a counterexample of [[W. T. Tutte]], the polyhedral but non-Hamiltonian [[Tutte graph]].  If one relaxes the requirement that the graph be cubic, there are much smaller non-Hamiltonian polyhedral graphs; the one with the fewest vertices and edges is the 11-vertex and 18-edge [[Herschel graph]],&lt;ref&gt;{{mathworld|title=Herschel Graph|urlname=HerschelGraph}}.&lt;/ref&gt; and there also exists an 11-vertex non-Hamiltonian polyhedral graph in which all faces are triangles, the [[Goldner–Harary graph]].&lt;ref&gt;{{mathworld|title=Goldner-Harary Graph|urlname=Goldner-HararyGraph}}.&lt;/ref&gt;

More strongly, there exists a constant α&amp;nbsp;&amp;lt;&amp;nbsp;1 (the [[shortness exponent]]) and an infinite family of polyhedral graphs such that the length of the longest [[path (graph theory)|simple path]] of an ''n''-vertex graph in the family is O(''n''&lt;sup&gt;α&lt;/sup&gt;).&lt;ref&gt;{{mathworld|title=Shortness Exponent|urlname=ShortnessExponent}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Longest simple paths in polyhedral graphs|first1=Branko|last1=Grünbaum|author1-link=Branko Grünbaum|first2=T. S.|last2=Motzkin|journal=Journal of the London Mathematical Society|year=1962|volume=s1-37|issue=1|pages=152–160|doi=10.1112/jlms/s1-37.1.152}}.&lt;/ref&gt;

==Combinatorial enumeration==
Duijvestijn provides a count of the polyhedral graphs with up to 26 edges;&lt;ref&gt;{{citation|title=The number of polyhedral (3-connected planar) graphs|first=A. J. W.|last=Duijvestijn|journal=Mathematics of Computation|volume=65|year=1996|pages=1289–1293|doi=10.1090/S0025-5718-96-00749-1}}.&lt;/ref&gt; The number of these graphs with 6, 7, 8, ... edges is
:1, 0, 1, 2, 2, 4, 12, 22, 58, 158, 448, 1342, 4199, 13384, 43708, 144810, ... {{OEIS|A002840}}.
One may also [[graph enumeration|enumerate]] the polyhedral graphs by their numbers of vertices: for graphs with 4, 5, 6, ... vertices, the number of polyhedral graphs is
:1, 2, 7, 34, 257, 2606, 32300, 440564, 6384634, 96262938, 1496225352, ... {{OEIS|A000944}}.

==Special cases==
A polyhedral graph is the graph of a [[simple polyhedron]] if it is [[cubic graph|cubic]] (every vertex has three edges), and it is the graph of a [[simplicial polyhedron]] if it is a [[maximal planar graph]]. The [[Halin graph]]s, graphs formed from a planar embedded [[tree (graph theory)|tree]] by adding an outer cycle connecting all of the leaves of the tree, form another important subclass of the polyhedral graphs.

==References==
{{reflist}}

==External links==
*{{mathworld|title=Polyhedral Graph|urlname=PolyhedralGraph}}

[[Category:Geometric graphs]]
[[Category:Planar graphs]]</text>
      <sha1>tp9420d0k6vp62rrhzkoillvt087ppm</sha1>
    </revision>
  </page>
  <page>
    <title>Regression validation</title>
    <ns>0</ns>
    <id>15935860</id>
    <revision>
      <id>853699979</id>
      <parentid>853699831</parentid>
      <timestamp>2018-08-06T12:49:09Z</timestamp>
      <contributor>
        <ip>134.34.5.9</ip>
      </contributor>
      <comment>fixed formatting error</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7851">{{Regression bar}}
In [[statistics]], '''regression validation''' is the process of deciding whether the numerical results quantifying hypothesized relationships between variables, obtained from [[regression analysis]], are acceptable as descriptions of the data. The validation process can involve analyzing the [[goodness of fit]] of the regression, analyzing whether the [[Residual (statistics)|regression residual]]s are random, and checking whether the model's predictive performance deteriorates substantially when applied to data that were not used in model estimation.

==Goodness of fit ==
{{Main|Goodness of fit}}

One measure of goodness of fit is the ''R''&lt;sup&gt;2&lt;/sup&gt; ([[coefficient of determination]]), which in ordinary least squares with an intercept ranges between 0 and 1. While a low ''R''&lt;sup&gt;2&lt;/sup&gt; implies that the model does not fit the data well, an ''R''&lt;sup&gt;2&lt;/sup&gt; close to 1 does not guarantee that the model fits the data well: as [[Anscombe's quartet]] shows, a high ''R''&lt;sup&gt;2&lt;/sup&gt; can occur in the presence of misspecification of the functional form of a relationship or in the presence of outliers that distort the true relationship.

One problem with the ''R''&lt;sup&gt;2&lt;/sup&gt; as a measure of model validity is that it can always be increased by adding more variables into the model, except in the unlikely event that the additional variables are exactly uncorrelated with the dependent variable in the data sample being used. This problem can be avoided by doing an [[F-test]] of the statistical significance of the increase in the ''R''&lt;sup&gt;2&lt;/sup&gt;, or by instead using the [[adjusted R-squared|adjusted ''R''2]].

==Analysis of residuals==
The [[errors and residuals in statistics|residuals]] from a fitted model are the differences between the responses observed at each combination of values of the [[explanatory variable]]s and the corresponding prediction of the response computed using the regression function. Mathematically, the definition of the residual for the ''i''&lt;sup&gt;th&lt;/sup&gt; observation in the [[data set]] is written
:&lt;math&gt;
e_i = y_i - f(x_i;\hat{\beta}),
&lt;/math&gt;
with ''y&lt;sub&gt;i&lt;/sub&gt;'' denoting the ''i''&lt;sup&gt;th&lt;/sup&gt; response in the data set and ''x&lt;sub&gt;i&lt;/sub&gt;'' the vector of explanatory variables, each set at the corresponding values found in the ''i''&lt;sup&gt;th&lt;/sup&gt; observation in the data set.

If the model fit to the data were correct, the residuals would approximate the random errors that make the relationship between the explanatory variables and the response variable a statistical relationship. Therefore, if the residuals appear to behave randomly, it suggests that the model fits the data well. On the other hand, if non-random structure is evident in the residuals, it is a clear sign that the model fits the data poorly. The next section details the types of plots to use to test different aspects of a model and gives the correct interpretations of different results that could be observed for each type of plot.

===Graphical analysis of residuals===
{{See also|Statistical graphics}}
A basic, though not quantitatively precise, way to check for problems that render a model inadequate is to conduct a visual examination of the residuals (the mispredictions of the data used in quantifying the model) to look for obvious deviations from randomness. If a visual examination suggests, for example, the possible presence of [[heteroskedasticity]] (a relationship between the variance of the model errors and the size of an independent variable's observations), then statistical tests can be performed to confirm or reject this hunch; if it is confirmed, different modeling procedures are called for.

Different types of plots of the residuals from a fitted model provide information on the adequacy of different aspects of the model.
#sufficiency of the functional part of the model: [[scatter plot]]s of residuals versus predictors
#non-constant variation across the data: [[scatter plot]]s of residuals versus predictors; for data collected over time, also plots of residuals against time
#drift in the errors (data collected over time): [[run chart]]s of the response and errors versus time
#independence of errors: [[lag plot]]
#normality of errors: [[histogram]] and [[normal probability plot]]
Graphical methods have an advantage over numerical methods for model validation because they readily illustrate a broad range of complex aspects of the relationship between the model and the data.

===Quantitative analysis of residuals===
{{Main|Regression diagnostic}}
Numerical methods also play an important role in model validation. For example, the [[goodness of fit|lack-of-fit test]] for assessing the correctness of the functional part of the model can aid in interpreting a borderline residual plot. One common situation when numerical validation methods take precedence over graphical methods is when the number of [[statistical parameter|parameters]] being estimated is relatively close to the size of the data set. In this situation residual plots are often difficult to interpret due to constraints on the residuals imposed by the estimation of the unknown parameters. One area in which this typically happens is in optimization applications using [[designed experiment]]s. [[Logistic regression]] with binary data is another area in which graphical residual analysis can be difficult.

[[Serial correlation]] of the residuals can indicate model misspecification, and can be checked for with the [[Durbin–Watson statistic]]. The problem of [[heteroskedasticity]] can be checked for in any of [[Heteroskedasticity#Detection|several ways]].
&lt;!--here, should talk about
significant terms missing/misspecified in the functional part of the model
necessity of all terms in the functional part of the model
--&gt;

==Out-of-sample evaluation==
{{main|Cross-validation (statistics){{!}}Cross-validation}}
Cross-validation is the process of assessing how the results of a statistical analysis will generalize to an independent data set. If the model has been estimated over some, but not all, of the available data, then the model using the estimated parameters can be used to predict the held-back data. If, for example, the out-of-sample [[mean squared error]], also known as the [[mean squared prediction error]], is substantially higher than the in-sample mean square error, this is a sign of deficiency in the model. 

A development in medical statistics is the use of out-of-sample cross validation techniques in meta-analysis. It forms the basis of the ''validation statistic, Vn'', which is used to test the statistical validity of meta-analysis summary estimates. Essentially it measures a type of normalized prediction error and its distribution is a linear combination of ''χ''&lt;sup&gt;2&lt;/sup&gt; variables of degree 1. &lt;ref&gt;{{cite journal | author = Willis BH, Riley RD | year = 2017 | title = Measuring the statistical validity of summary meta-analysis and meta-regression results for use in clinical practice | url = https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5575530/pdf/SIM-36-3283.pdf| journal = Statistics in Medicine | volume = 36 | issue = 21 | pages = 3283-3301 | doi = 10.1002/sim.7372| pmid = 28620945 }}&lt;/ref&gt;

==See also==
* [[Specification (regression)]]

==References==
{{Unreferenced|date=March 2010}}
{{reflist}}
* {{cite book |last=Kmenta |first=Jan |authorlink=Jan Kmenta |title=Elements of Econometrics |location=New York |publisher=Macmillan |year=1986 |edition=Second |isbn=0-02-365070-2 |pages=593–600 }}

==External links==
*[http://www.itl.nist.gov/div898/handbook/pmd/section4/pmd44.htm How can I tell if a model fits my data? (NIST)]
*[http://www.itl.nist.gov/div898/handbook/ NIST/SEMATECH e-Handbook of Statistical Methods (Accessed September 2011)],

{{NIST-PD}}

[[Category:Validity (statistics)]]
[[Category:Regression diagnostics| ]]</text>
      <sha1>6qm1ne5l2ld1betd74ksa5npi63wfxc</sha1>
    </revision>
  </page>
  <page>
    <title>Richard M. Karp</title>
    <ns>0</ns>
    <id>298763</id>
    <revision>
      <id>859540493</id>
      <parentid>859534332</parentid>
      <timestamp>2018-09-14T17:49:21Z</timestamp>
      <contributor>
        <username>Mike Schwartz</username>
        <id>99797</id>
      </contributor>
      <comment>/* Turing Award */ This section, which is about Richard M. Karp's citation for the year (1985) when Karp was awarded the [[Turing Award]], previously did not specify (as prominently) what year the award was given to Karp. Adding in the parenthetical note, ''(1985)'', may help readers to know what year that [[Turing Award]] citation was written, and hence to know the context, and better understand how (and how much) Karp had **contributed** to the history of the field of the [[Computer science]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9193">&lt;!-- Image with unknown copyright status removed: [[File:karp.jpg|frame|right|Richard Karp]] --&gt;
{{Infobox scientist
| name                    = Richard Manning Karp
| image                   = Karp mg 7725-b.cr2.jpg
| image_size             = 
| caption                 = Richard Karp at the EPFL on 13th of July 2009
| birth_date              = {{Birth date and age|1935|1|3|mf=yes}}
| birth_place             = [[Boston, Massachusetts|Boston]], [[Massachusetts]]
| death_date              = 
| death_place             = 
| residence               = 
| citizenship             =
| nationality             = American
| ethnicity               =
| field                   = [[Computer Science]]
| work_institution        = [[University of California, Berkeley]]&lt;br&gt;[[IBM]]
| alma_mater              = [[Harvard University]]
| doctoral_advisor        = Anthony Oettinger&lt;ref name="mg"&gt;{{MathGenealogy|id=25275}}.&lt;/ref&gt;
| doctoral_students       = {{plainlist|1=
*[[Faith Ellen]]
*[[Sally Floyd]]
*[[Dan Gusfield]]
*[[Narendra Karmarkar]]
*[[Valerie King]]
*[[Michael Luby]]
*[[Rajeev Motwani]]
*[[Noam Nisan]]
*[[Raymond Reiter]]
*[[Thomas Jerome Schaefer|Thomas J. Schaefer]]
*[[Ron Shamir]]
*[[Barbara Simons]]
*[[Eric Xing]]
*[[Norman Zadeh]]&lt;ref name="mg"/&gt;
}}
| known_for               = [[Edmonds–Karp algorithm]]&lt;br /&gt;[[Karp's 21 NP-complete problems]]&lt;br /&gt;[[Hopcroft–Karp algorithm]]&lt;br /&gt;[[Karp–Lipton theorem]]&lt;br /&gt;[[Rabin–Karp string search algorithm]]
| thesis_title = Some Applications of Logical Syntax to Digital Computer Programming
| thesis_year = 1959
| author_abbreviation_bot = 
| author_abbreviation_zoo = 
| prizes                  = [[Turing Award]] &lt;small&gt;(1985)&lt;/small&gt;&lt;br&gt;[[John von Neumann Theory Prize]] &lt;small&gt;(1990)&lt;/small&gt;&lt;br&gt;[[National Medal of Science]] &lt;small&gt;(1996)&lt;/small&gt;&lt;br&gt;[[Harvey Prize]]&lt;br&gt;[[Franklin Institute#The Benjamin Franklin Awards|Benjamin Franklin Medal]]&lt;br&gt;[[Kyoto Prize]]&lt;br&gt;[[International Parallel and Distributed Processing Symposium#IEEE Computer Society Charles Babbage Award|IEEE Computer Society Charles Babbage Award]]
| religion                = 
| footnotes               = 
}}

'''Richard Manning Karp''' (born January 3, 1935) is an American [[computer scientist]] and [[computational theorist]] at the [[University of California, Berkeley]]. He is most notable for his research in the [[theory of algorithms]], for which he received a [[Turing Award]] in 1985, [[The Franklin Institute Awards|The Benjamin Franklin Medal in Computer and Cognitive Science in 2004]], and the [[Kyoto Prize]] in 2008.&lt;ref&gt;[https://web.archive.org/web/20100314142146/http://www.inamori-f.or.jp/laureates/k24_a_richard/prs_e.html Richard Manning Karp - THE 2008 KYOTO PRIZE - Advanced Technology&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

== Biography ==
Born to Abraham and Rose Karp in [[Boston, Massachusetts]], Karp has three younger siblings: Robert, [[David A. Karp|David]], and Carolyn.  He attended [[Harvard University]], where he received his bachelor's degree in 1955, his master's degree in 1956, and his [[Doctor of Philosophy|Ph.D.]] in [[applied mathematics]] in 1959.

He started working at [[IBM]]'s [[Thomas J. Watson Research Center]]. In 1968, he became Professor of Computer Science, Mathematics, and Operations Research at the [[University of California, Berkeley]]. Apart from a 4-year period as a professor at the [[University of Washington]], he has remained at Berkeley. From 1988 to 1995 and 1999 to the present he has also been a Research Scientist at the [[International Computer Science Institute]] in Berkeley, where he currently leads the Algorithms Group.

Richard Karp was awarded the [[National Medal of Science]], and was the recipient of the [[Harvey Prize]] of the [[Technion]]  and the 2004 [[Franklin Institute#The Benjamin Franklin Awards|Benjamin Franklin Medal]] in Computer and Cognitive Science for his insights into [[Computational complexity theory|computational complexity]]. In 1994 he was inducted as a [[Fellow]] of the [[Association for Computing Machinery]]. He is the recipient of several honorary degrees.

In 2012, Karp became the founding director of the [[Simons Institute for the Theory of Computing]] at the [[University of California, Berkeley]].&lt;ref&gt;{{cite web|url=https://www.nytimes.com/2012/05/01/science/simons-foundation-chooses-uc-berkeley-for-computing-center.html?_r=0|title=California Chosen as Home for Computing Institute|date=30 April 2012|publisher=The New York Times|accessdate=23 October 2016}}&lt;/ref&gt;

== Work ==
Karp has made many important discoveries in computer science, [[Combinatorial optimization|combinatorial algorithms]], and [[operations research]] . His major current research interests include [[bioinformatics]].
 
In 1971 he co-developed with [[Jack Edmonds]] the [[Edmonds–Karp algorithm]] for solving the max-flow problem on networks, and in 1972 he published a landmark paper in complexity theory, "Reducibility Among Combinatorial Problems", in which he proved [[Karp's 21 NP-complete problems|21 Problems to be NP-complete]].&lt;ref&gt;{{cite book | author = Richard M. Karp | chapter = Reducibility Among Combinatorial Problems | chapter-url = http://www.cs.berkeley.edu/~luca/cs172/karp.pdf | title = Complexity of Computer Computations | editor = R. E. Miller and J. W. Thatcher (editors) | publisher = New York: Plenum | pages = 85&amp;ndash;103 | year = 1972}}&lt;/ref&gt;

In 1973 he and [[John Hopcroft]] published the [[Hopcroft–Karp algorithm]], still the fastest known method for finding maximum cardinality [[Matching (graph theory)|matchings]] in [[bipartite graph]]s.

In 1980, along with [[Richard J. Lipton]], Karp proved the [[Karp-Lipton theorem]] (which proves that, if [[Boolean satisfiability problem|SAT]] can be solved by [[Boolean circuit]]s with a polynomial number of [[logic gate]]s, then the [[polynomial hierarchy]] collapses to its second level).

In 1987 he co-developed with [[Michael O. Rabin]] the [[Rabin-Karp string search algorithm]].

=== Turing Award ===
His citation&lt;ref&gt;{{cite web |url=http://awards.acm.org/citation.cfm?id=3256708&amp;srt=all&amp;aw=140&amp;ao=AMTURING&amp;yr=1985 |title=ACM Award Citation/Richard M. Karp |author=Association for Computing Machinery |publisher= |accessdate=2010-01-17 |archive-url=https://wayback.archive-it.org/all/20120703015825/http://amturing.acm.org/award_winners/karp_3256708.cfm |archive-date=2012-07-03 |dead-url=yes |df= }}&lt;/ref&gt; for the ''(1985)'' Turing Award was as follows: 

:''For his continuing contributions to the theory of algorithms including the development of efficient algorithms for network flow and other combinatorial optimization problems, the identification of polynomial-time computability with the intuitive notion of [[algorithmic efficiency]], and, most notably, contributions to the theory of [[NP-complete]]ness. Karp introduced the now standard methodology for proving problems to be NP-complete which has led to the identification of many theoretical and practical problems as being computationally difficult.''

== References ==
&lt;references/&gt;

== External links ==
{{Commons category|Richard Karp}}
* [https://web.archive.org/web/20100420002246/http://www.acm.org/crossroads/dayinlife/bios/richard_karp.html ACM Crossroads magazine interview/bio of Richard Karp]
* [http://www.eecs.berkeley.edu/Faculty/Homepages/karp.html Karp's Home Page at Berkeley]
* [https://www.informs.org/content/view/full/272029 Biography of Richard Karp] from the Institute for Operations Research and the Management Sciences

{{s-start}}
{{succession box |
 before=[[John McCarthy (computer scientist)|John McCarthy]] |
 title=Benjamin Franklin Medal in Computer and Cognitive Science |
 after=[[Aravind Joshi]] |
 years=2004}}
{{s-end}}

{{EATCS Award laureates}}
{{Turing award}}
{{Winners of the National Medal of Science|math-stat-comp}}
{{John von Neumann Lecturers}}
{{John von Neumann Theory Prize recipients}}
{{Authority control}}

{{DEFAULTSORT:Karp, Richard}}
[[Category:American computer scientists]]
[[Category:American operations researchers]]
[[Category:1935 births]]
[[Category:Living people]]
[[Category:Theoretical computer scientists]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]
[[Category:Kyoto laureates in Advanced Technology]]
[[Category:Members of the United States National Academy of Engineering]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:John von Neumann Theory Prize winners]]
[[Category:National Medal of Science laureates]]
[[Category:Turing Award laureates]]
[[Category:University of California, Berkeley College of Engineering faculty]]
[[Category:Members of the French Academy of Sciences]]
[[Category:Harvard University alumni]]
[[Category:People from Boston]]
[[Category:20th-century American engineers]]
[[Category:21st-century American engineers]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:20th-century American scientists]]
[[Category:21st-century American scientists]]
[[Category:Harvard School of Engineering and Applied Sciences alumni]]</text>
      <sha1>ghkmhvhd8ye3n4ar1cptqi6945yk8ho</sha1>
    </revision>
  </page>
  <page>
    <title>Ruan Yuan</title>
    <ns>0</ns>
    <id>6419203</id>
    <revision>
      <id>870651080</id>
      <parentid>870650988</parentid>
      <timestamp>2018-11-26T05:03:17Z</timestamp>
      <contributor>
        <username>YuanTaizu</username>
        <id>34942500</id>
      </contributor>
      <minor/>
      <comment>added chinese name in infobox</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4923">{{Infobox person
|name            = Ruan Yuan&lt;br&gt;阮元
|image           = [[File:Ruan Yuan Portrait.jpg|200px]]
|succession      = [[Governer-General]] of [[Guangdong]]
|predecessor     = [[Jiang Youxian]]
|successor       = [[Li Hongbin]]
|birth_date      = February 21, 1764
|birth_place     = [[Yizheng]], [[Qing Dynasty]]
|death_date      = November 27, 1849 (aged 85)
|death_place     = [[Yangzhou]], [[Qing Dynasty]]
}}
{{Infobox Chinese
|c=阮元
|p=Ruǎn Yuán
|w=Juan&lt;sup&gt;3&lt;/sup&gt; Yüan&lt;sup&gt;2&lt;/sup&gt;
|mi={{IPAc-cmn|r|uan|3|-|yuan|2}}
|j=Jyun&lt;sup&gt;5&lt;/sup&gt; Jyun&lt;sup&gt;4&lt;/sup&gt;
|wuu=Niun-nyy
|y=Yúhn Yùhn
|tl=Ńg Guân
}}
{{Chinese name|[[Ruan (surname)|Ruan]]}}
'''Ruan Yuan''' ({{zh|c=阮元}}; 1764–1849) was a Chinese [[scholar official]] of the [[Qing Dynasty]] who was the most prominent Chinese scholar during the first half of the 19th century.{{sfnp|Shaughnessy|p=12}}  He won the ''jinshi'' degree in the [[imperial examination]]s in 1789 and was subsequently appointed to the [[Hanlin Academy]]. He was known for his work ''Biographies of Astronomers and Mathematicians'' and for his editing the ''[[Shisan Jing Zhushu]]'' (Commentaries and Notes on the Thirteen Classics) for the Qing emperor.

Ruan Yuan was a successful official as well as a scholar. He was the [[Viceroy of Liangguang]], the most important imperial official in Canton ([[Guangzhou]]), during the critical years 1817–1826, just before the [[First Opium War]] with Britain. It was a crucial time when Chinese trade with the outside world was allowed only through the [[Canton System]], with all foreigners confined to Canton, the capital of [[Guangdong]] Province. During his tenure in Canton, Ruan is estimated to have earned more than 195,000 [[tael]]s of silver.{{sfn|Wei|2006|p=301}}

He was widely recognized as an official, scholar, and patron of learning both by his contemporaries and by modern scholars. He was also praised as an honest official and an exemplary man of the ‘Confucian persuasion’. His name is mentioned in almost all works on Qing history or Chinese classics because of the wide range of his research and publications. A number of these publications are still reprinted. Ruan Yuan was a follower of the [[Han Learning]] tradition and as such, with the encouragement of [[Liu Fenglu]], he edited and organized publication of the compendium of the imperial achievements in ''kaozheng'' scholarship, the ''Huang Qing Jingjie'' ([[:zh:皇清经解]]) published in 1829.

Kong Luhua (relative of the [[Duke Yansheng]]) was the second wife of Ruan Yuan.&lt;ref name="Wei2006"&gt;{{cite book|author=Betty Peh-T'I Wei|title=Ruan Yuan, 1764-1849: The Life and Work of a Major Scholar-Official in Nineteenth-Century China before the Opium War|url=https://books.google.com/books?id=8lxUMoR5TXcC&amp;pg=PA246#v=onepage&amp;q=kong%20luhua&amp;f=false|date=1 August 2006|publisher=[[Hong Kong University Press]]|isbn=978-962-209-785-8|pages=246–}}&lt;/ref&gt;

==References==
{{reflist}}

;Bibliography
* {{Cite book
| first = Betty Peh-T'i
| last = Wei
| author-link = Betty Wei
| title = Ruan Yuan, 1764–1849: The Life And Work of a Major Scholar-Official in Nineteenth-Century China Before the Opium War
| year= 2006
| publisher= Hong Kong University Press
| isbn = 962-209-785-5
| ref = harv}}

* {{cite book
  | title = Confucian Cultures of Authority
  | chapter = Establishing authority through scholarship: Ruan Yuan and the Xuehaitang Academy
  | first = Steven B. | last = Miles | pages = 151–169
  | editor1-first = Peter D. | editor1-last = Hershock
  | editor2-first = Roger T. | editor2-last = Ames|editor-link2=Roger T. Ames
  | publisher = [[SUNY Press]] | year = 2006 | isbn = 978-0-7914-8156-1
  }}
* {{cite book
  | title = The Sea of Learning: Mobility and Identity in Nineteenth-Century Guangzhou
  | first = Steven B. | last = Miles
  | publisher = [[Harvard University Press]] | year = 2006 | isbn = 978-0-674-02134-1
  }}

==External links==
* [http://www-history.mcs.st-andrews.ac.uk/Printonly/Ruan_Yuan.html Ruan Yuan biography from St. Andrews University]

&lt;!-- Succession box --&gt;
{{s-start}}
{{s-gov}}
{{s-bef|before=[[Jiang Youxian]] (蔣攸銛)}}
{{s-ttl|title=[[Viceroy of Liangguang|Governor-general of Liangguang]]|years=22 October 1817{{spaced ndash}}22 June 1826}}
{{s-aft|after=[[Li Hongbin]] (李鴻賓)}}
{{s-end}}

{{Authority control}}

{{DEFAULTSORT:Ruan, Yuan}}
[[Category:Qing dynasty politicians from Jiangsu]]
[[Category:Chinese Confucianists]]
[[Category:Historians of astronomy]]
[[Category:Historians of mathematics]]
[[Category:1764 births]]
[[Category:1849 deaths]]
[[Category:Writers from Yangzhou]]
[[Category:Qing dynasty historians]]
[[Category:Politicians from Yangzhou]]
[[Category:Historians from Jiangsu]]
[[Category:19th-century Chinese historians]]
[[Category:Viceroys of Huguang]]
[[Category:Viceroys of Yun-Gui]]
[[Category:Viceroys of Liangguang]]


{{China-politician-stub}}</text>
      <sha1>970950m50fg1wqo5fzzew4y898ktfku</sha1>
    </revision>
  </page>
  <page>
    <title>Samuel L. Greitzer</title>
    <ns>0</ns>
    <id>715594</id>
    <revision>
      <id>868766015</id>
      <parentid>867802076</parentid>
      <timestamp>2018-11-14T08:52:11Z</timestamp>
      <contributor>
        <ip>173.68.139.31</ip>
      </contributor>
      <comment>[[National Science Foundation]], [[Category:Imperial Russian emigrants to the United States]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3695">[[File:Greitzer-Sam.jpg|thumb]]
'''Samuel L. Greitzer''' (August 10, 1905 – February 22, 1988) was an American [[mathematician]], the founding chairman of the [[United States of America Mathematical Olympiad]], and the publisher of the precollege mathematics journal ''Arbelos''.&lt;ref name=obit/&gt; Together with [[H.S.M. Coxeter]] in 1967, Greitzer coauthored the well-received textbook ''Geometry Revisited'', which has remained in print for more than 40 years.&lt;ref&gt;{{cite web |url=http://www.maa.org/node/109133 |title=MAA Review: Geometry Revisited |first=P.N. |last=Ruane |year=2008}}&lt;/ref&gt;

==Biography==
Born in [[Russia]], Greitzer moved to the United States in 1906, graduated from [[Stuyvesant High School]], received his bachelor's degree in 1927 from [[City College of New York]], and later earned a Ph.D. from [[Yeshiva University]]. He held academic positions at [[Yeshiva University]], [[Brooklyn Polytechnic Institute]], [[Columbia University]], and [[Rutgers University]].&lt;ref name=obit/&gt; In the 1970s, he directed a [[National Science Foundation]] summer program at Rutgers for high-ability high-school math students.

Samuel Greitzer and his wife Ethel had one son.&lt;ref&gt;{{cite web |url=http://www.ancestry.com/1940-census/usa/New-York/Samuel-Greitzer_6q34z |title=Samuel Greitzer in the 1940 Census |accessdate=May 23, 2016}}&lt;/ref&gt; Samuel died on February 22, 1988 in [[Metuchen, New Jersey]].&lt;ref name=obit&gt;{{cite journal |title=Obituary: Samuel L Greitzer |url=http://www.amt.edu.au/obitgreitzer.html |first1=G. |last1=Berzsenyi |first2=W. |last2=Mientka |journal=Mathematics Competitions |volume=1 |issue=1 |page=29 |year=1988 |deadurl=yes |archiveurl=https://web.archive.org/web/20140204082356/http://www.amt.edu.au/obitgreitzer.html |archivedate=2014-02-04 |df= }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.myheritage.com/research/collection-10002/us-social-security-death-index-ssdi?itemId=20314214&amp;action=showRecord |title=Social Security Death Index |accessdate=May 21, 2016}}&lt;/ref&gt;

==Selected publications==
* {{cite book |title=Geometry Revisited |first1=H.S.M. |last1=Coxeter |first2=S.L. |last2=Greitzer |publisher=Mathematical Association of America |year=1967 |isbn=978-0-88385-619-2 |url=http://www.maa.org/node/109133}}
* {{cite journal |last=Greitzer |first=S. |title=The First U.S.A. Mathematical Olympiad |journal=American Mathematical Monthly |volume=80 |number=3 |pages=276–281 |year=1973 |doi=10.2307/2318449 |jstor=2318449}}
* {{cite book |title=International Mathematical Olympiads 1959–1977 |first=Samuel |last=Greitzer |publisher=Mathematical Association of America |year=1979 |isbn=978-0-88385-627-7 |url=http://www.maa.org/press/ebooks/international-mathematical-olympiads-1959-1977}}

==References==
{{Reflist}}

==External links==
*{{cite journal |url=http://www.maa.org/publications/periodicals/convergence/dear-professor-greitzer-sam-greitzer |title=Dear Professor Greitzer |first1=Joe |last1=Richards |first2=Don |last2=Crossfield |journal=Convergence |publisher=Mathematical Association of America |year=2008}}

{{Authority control}}

{{DEFAULTSORT:Greitzer, Samuel L.}}
[[Category:1905 births]]
[[Category:1988 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:Geometers]]
[[Category:Imperial Russian emigrants to the United States]]
[[Category:City College of New York alumni]]
[[Category:Yeshiva University alumni]]
[[Category:Stuyvesant High School alumni]]
[[Category:People from Metuchen, New Jersey]]
[[Category:Yeshiva University faculty]]
[[Category:Columbia University faculty]]
[[Category:Rutgers University faculty]]
[[Category:Polytechnic Institute of New York University faculty]]


{{US-mathematician-stub}}</text>
      <sha1>o5mw69l0axdn6vdemssvzz8qhcpgaoj</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical geography</title>
    <ns>0</ns>
    <id>10851027</id>
    <revision>
      <id>855561520</id>
      <parentid>855561517</parentid>
      <timestamp>2018-08-19T06:49:41Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/61.74.166.55|61.74.166.55]] to version by Az1568. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3450121) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11116">{{Expert-subject|Geography|date=August 2009}}

'''Statistical geography''' is the study and practice of collecting, analysing and presenting data that has a geographic or areal dimension, such as census or demographics data. It uses techniques from [[spatial analysis]], but also encompasses geographical activities such as the defining and naming of geographical regions for statistical purposes. For example, for the purposes of statistical geography, the [[Australian Bureau of Statistics]] uses the Australian Standard Geographical Classification, a hierarchical regionalisation that divides [[Australia]] up into [[states and territories of Australia|states and territories]], then statistical divisions, statistical subdivisions, statistical local areas, and finally census collection districts.

==Background==
[[File:Devils Punchbowl Waterfall, New Zealand.jpg|thumb|200px|right|Devil's Punchbowl Waterfall, [[New Zealand]] may be studied using geostatistics]]

[[Geography|Geographers]] study how and why elements differ from place to place, as well as how spatial patterns change through time. Geographers begin with the question 'Where?', exploring how features are distributed on a physical or cultural landscape, observing spatial patterns and the variation of phenomena. Contemporary geographical analysis has shifted to 'Why?', determining why a specific spatial pattern exists, what spatial or ecological processes may have affected a pattern, and why such processes operate. Only by approaching the 'why?' questions can social scientists begin to appreciate the mechanisms of change, which are infinite in their complexity.

===Role of statistics in geography===

Statistical techniques and procedures are applied in all fields of academic research; wherever data are collected and summarized or wherever any numerical information is analyzed or research is conducted, statistics are needed for sound analysis and interpretation of results. 

Geographers use statistics in numerous ways:{{Citation needed|date=January 2009}}

* To describe and summarize spatial data.
* To make generalizations concerning complex spatial patterns.
* To estimate the probability of outcomes for an event at a given location.
* To use samples of geographic data to infer characteristics for a larger set of geographic data (population).
* To determine if the magnitude or frequency of some phenomenon differs from one location to another.
* To learn whether an actual spatial pattern matches some expected pattern.

==Spatial data and descriptive statistics==
There are several potential difficulties associated with the analysis of spatial data, among these are boundary delineation, modifiable areal units, and the level of spatial aggregation or scale. In each of these cases, the absolute descriptive statistics of an area - the mean, median, mode, standard deviation, and variation - are changed through the manipulation of these spatial problems.

===Boundary delineation===
The location of a study area boundary and the positioning of internal boundaries affect various descriptive statistics. With respect to measures such as the mean or standard deviation, the study area size alone may have large implications; consider a study of per capita income within a city, if confined to the inner city, income levels are likely to be lower because of a less affluent population, if expanded to include the suburbs or surrounding communities, income levels will become greater with the influence of homeowner populations. Because of this problem, absolute descriptive statistics such as the mean, standard deviation, and variance should be evaluated comparatively only in relation to a particular study area. In the determination of internal boundaries this is also true, as these statistics may only have valid interpretations for the area and subarea configuration over which they are calculated.

===Modifiable areal units===
''See also'': [[Modifiable areal unit problem]]

In many cases the subdivision of spatial data has already been determined, this is evident in demographic datasets, as the available information will be grouped into their respective counties or municipalities. For this type of data, analysts must use the same county or municipal boundaries delineated in the collected data for their subsequent analysis. When alternate boundaries are possible, an analyst must take into account that any new subdivision model may create different results.
;;

===Spatial aggregation/scale problem===
Socio-economic data may be available at a variety of scales, for example: municipalities, regional districts, census tracts, enumeration districts, or at the provincial/state level. When this data is aggregated at different scales, the resulting descriptive statistics may exhibit variations, either in a systematic, predictable way, or in a more uncertain fashion. If we are observing economic data, we may notice a distinct reduction in manufacturing productivity for a country (the USA) over a certain period; since this is a general model, individual states may experience these effects differently. The result of this aggregation is that the standard deviation of the data in question is increased due to the variability among states.'''

==Descriptive spatial statistics==
:''See main article'' [[Spatial descriptive statistics]]

For summarizing point pattern analysis, a set of descriptive spatial statistics has been developed that are areal equivalents to nonspatial measures. Since geographers are particularly concerned with the analysis of locational data, these descriptive spatial statistics (geostatistics) are often applied to summarize point patterns and to describe the degree of spatial variability of some phenomena.

===Spatial measures of central tendency===
An example here is the idea of a [[center of population]], of which a particular example is the [[mean center of U.S. population]]. Several different ways of defining a center are available:
*Mean center: The mean is an important measure of central tendency, which when extended to a set of points, located on a [[Cartesian coordinate system]], the average location, [[centroid]] or mean center, can be determined.
*The weighted mean center is analogous to frequencies in the calculation of grouped statistics, such as the weighted mean. A point may represent a retail outlet, while its frequency will represent the volume of sales within the particular store. 
*Median center or Euclidean center and in the [[median center of United States population]]. This is related to the [[Manhattan distance]].

===Spatial measures of dispersion===
*Standard distance
Just as the [[standard deviation]] indicates how closely the values in a data set are clustered around the mean, so standard distance in a spatial distribution indicates how closely the points are clustered around the mean centre.

*Relative distance

==Topology==
{{Main|Topology}} [[File:Konigsberg bridges.png|thumb|right|The Seven Bridges of Königsberg, one of the most famous problems in topology]]

The motivating insight behind topology is that some geometric problems depend not on the exact shape of the objects involved, but rather on the "way they are connected together". One of the first papers in topology was the demonstration, by [[Leonhard Euler]], that it was impossible to find a route through the town of Königsberg (now [[Kaliningrad]]) that would cross each of its seven bridges exactly once. This result did not depend on the lengths of the bridges, nor on their distance from one another, but only on connectivity properties: which bridges are connected to which islands or riverbanks. This problem, the ''[[Seven Bridges of Königsberg]]'', is now a famous problem in introductory mathematics, and led to the branch of mathematics known as [[graph theory]].

===Topology rules===

Topology rules are particularly important within [[GIS]], and are used for a variety of correction and analytical procedures. The primary shapes in GIS are the [[Point (geometry)|point]], [[Line (geometry)|line]], and [[polygon]], each of which implies different spatial characteristics; for instance, the only shape which has a distinguishable inside and outside is the polygon. Principles of connectivity associated with topology lead to applications in [[hydrology]], [[urban planning]], and [[logistics]], as well as other fields; as such, topological analyses offer unique modelling capabilities, defining the vector nature of topological features and correcting spatial data errors from digitizing.

==National Examples==
===United Kingdom===
Due to the devolved nature of the United Kingdom, responsibility for managing statistical geographies often falls to the National Statistical Institute with jurisdiction for that devolved administration. For England and Wales this is the [[Office for National Statistics]], for Scotland [[National Records of Scotland]] and for Northern Ireland the [[NISRA|Northern Ireland Statistics and Research Agency]].

====England and Wales====
The lowest form of statistical geography in England and Wales is the [[Output_area#Geography_of_the_UK_Census|Output Area]]. These are small geographies of approximately 300 people and 100 households for which Census data is published. By containing roughly the same number of people and households it is possible to compare statistics for any two Output Areas in the country, and know that this is being done in a consistent way (unlike comparing statistics for Administrative geographies).

The Output Areas form the smallest part of a hierarchy that consists of [[ONS_Coding_System|Output Areas, Lower Layer Super Output Areas and Middle Layer Super Output Areas]].

England and Wales also have a statistical geography designed specifically for the publication of workplace statistics. This is because Output Areas are built around residential populations and make analysing workplace statistics difficult. Workplace Zones have been released as part of the 2011 Census.

====Scotland====
Like England and Wales, the lowest level of statistical geography in Scotland is the Output Area. Scottish OAs are smaller than those for England and Wales because smaller thresholds are applied, but the methodology for their creation is broadly similar to that used by ONS.

The higher levels are again similar to England and Wales but operate as Data Zones and Intermediate Zones rather than Lower and Middle Layer Super Output Areas.

There are no Workplace Zones for Scotland.

==See also==

* [[Geostatistics]]
* [[Spatial analysis]]

{{No footnotes|date=November 2011}}
==References==
* {{cite book | year = 1977 | author = Duncan, Otis Dudley, Raymond Paul Cuzzort and Beverly Duncan | title = Statistical Geography: Problems in Analyzing Areal Data | publisher = Greenwood Press | isbn= 0-8371-9676-0}}
* {{cite book | year = 1973 | author = Dickinson, G.C.| title = Statistical mapping and the presentation of statistics| publisher = Edward Arnold | isbn= 0-7131-5641-4}}




[[Category:Human geography]]
[[Category:Applied statistics]]
[[Category:Spatial data analysis]]</text>
      <sha1>5xbglf9sgzkv8itluw6suppmnxgmftk</sha1>
    </revision>
  </page>
  <page>
    <title>Table of Integrals, Series, and Products</title>
    <ns>0</ns>
    <id>49421630</id>
    <redirect title="Gradshteyn and Ryzhik" />
    <revision>
      <id>705177854</id>
      <parentid>704867227</parentid>
      <timestamp>2016-02-15T23:38:24Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="164">#redirect [[Gradshteyn and Ryzhik]] {{R from alternative title}}

[[Category:Handbooks and manuals]]
[[Category:Mathematics books]]
[[Category:Mathematical tables]]</text>
      <sha1>rgvizw6vg9ygvw9vu449ejnmiwrxnp7</sha1>
    </revision>
  </page>
  <page>
    <title>Thamsanqa Kambule</title>
    <ns>0</ns>
    <id>57961238</id>
    <revision>
      <id>852473143</id>
      <parentid>852473106</parentid>
      <timestamp>2018-07-29T06:27:42Z</timestamp>
      <contributor>
        <username>Cmr08</username>
        <id>6383155</id>
      </contributor>
      <comment>/* References */ add defaultsort</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6834">{{Infobox person
| name               = Thamsanqa Kambule
| alma_mater         = [[University of South Africa]] &lt;br&gt;
[[Adams College]]
| birth_date         = {{birth date|1921|01|15}}
| death_date         = {{death date and age |2009|8|7 |1921|01|15}}
| employer           = [[University of the Witwatersrand]]
| awards             = [[Order of the Baobab]] 2002
}}

'''Thamsanqa Kambule''' (15 January 1921 – 7 August 2009) was a South African Mathematician and Educator. He was the first [[Black people|black]] professor at the [[University of the Witwatersrand]], and was the first black person to be awarded honorary membership to the [[Actuarial Society of South Africa]]. He was awarded the [[Order of the Baobab]] in 2002 for his services to mathematics education.

== Early life and education ==
Kambule was born in [[Aliwal North]].&lt;ref name=":0"&gt;{{Cite news|url=https://www.independent.co.uk/news/obituaries/professor-thamsanqa-kambule-inspirational-teacher-who-fought-for-high-quality-black-education-in-1818793.html|title=Professor Thamsanqa Kambule: Inspirational teacher who fought for|work=The Independent|access-date=2018-07-21|language=en-GB}}&lt;/ref&gt; His mother died when he was 18 months old, and his aunt was responsible for raising him.&lt;ref name=":1"&gt;{{Cite web|url=https://www.pressreader.com/south-africa/sunday-times/20090816/281917359096481|title=TW Kambule: Legendary maths teacher|last=|first=|date=|website=www.pressreader.com|archive-url=|archive-date=|dead-url=|access-date=2018-07-21}}&lt;/ref&gt; He did not attend school until he was 11 years old, when he joined Anglican St Peter's School in [[Johannesburg]].&lt;ref name=":0" /&gt; He completed a Teachers Diploma at [[Adams College]] in 1946 and a Bachelor's degree at the [[University of South Africa]] in 1954.&lt;ref name=":2"&gt;{{Cite web|url=https://www.wits.ac.za/maths/about-us/dr-thamsanqa-kambule-honoured/|title=Dr Thamsanqa Kambule honoured - Wits University|last=Johannesburg|first=The University of the Witwatersrand,|website=www.wits.ac.za|language=en|access-date=2018-07-21}}&lt;/ref&gt;

== Career ==
Kambule taught in Zambia, Malawai as well as several schools in South Africa before being appointed Principal of Orlando High School in Soweto in 1958.&lt;ref name=":0" /&gt; He campaigned to ensure the children had the best education possible, despite the restrictions of the [[Bantu Education Act, 1953]].&lt;ref name=":0" /&gt; Orlando High School had a library named after [[Robert Birley]], a visiting professor at the [[University of the Witwatersrand]].&lt;ref name=":0" /&gt; He led the Rand Bursary Fund, a support program that provided scholarships for pupils in need.&lt;ref name=":0" /&gt; The fund allowed more than 1,000 students to complete high school.&lt;ref name=":3"&gt;{{Cite news|url=https://www.news24.com/Archives/City-Press/Remembering-a-man-of-multiplied-wisdom-20150429|title=Remembering a man of multiplied wisdom|work=News24|access-date=2018-07-21|language=en}}&lt;/ref&gt; His former pupils included [[Desmond Tutu]] and [[Jackie Selebi]].&lt;ref name=":4"&gt;{{Cite web|url=http://www.deeplearningindaba.com/kambule-award.html|title=Kambule Award|website=DEEP LEARNING INDABA|language=en|access-date=2018-07-21}}&lt;/ref&gt; In 1976 during the [[Soweto uprising]], the schoolchildren revolted against being forced to learn in the [[Afrikaans]] language.&lt;ref&gt;{{Cite news|url=https://afrolegends.com/2013/06/16/remembrance-16-june-1976-soweto-massacre/ |title= Remembrance: 16 June 1976 Soweto Massacre|date=2013-06-17|work=African Heritage|access-date=2018-07-21 |language=en-US}}&lt;/ref&gt; An undetermined number of children were shot dead by police, and education in townships fell apart.&lt;ref&gt;{{Cite news|url=https://www.sahistory.org.za/topic/june-16-soweto-youth-uprising|title=The June 16 Soweto Youth Uprising|last=Leander|date=2013-05-21|work=South African History Online|access-date=2018-07-21|language=en}}&lt;/ref&gt; Kambule resigned in 1977 to protest against the [[Department of Bantu Education]], and became the head of Pace College.&lt;ref name=":0" /&gt; 

In 1978 he joined the [[University of the Witwatersrand]], where he became the first black professor.&lt;ref name=":2" /&gt;&lt;ref&gt;{{Cite web|url=http://www.statssa.gov.za/?page_id=7674|title=Dedication {{!}} Statistics South Africa|last=Africa|first=Statistics South|website=www.statssa.gov.za|language=en-US|access-date=2018-07-21}}&lt;/ref&gt; He published a series of maths textbooks for non-specialist teachers.&lt;ref name=":1" /&gt; He retired in 1976 and promptly became the Principal of ''O R T Step College of Technology''.&lt;ref name=":1" /&gt; He was awarded an honorary doctorate in 1997 and a doctorate of education in 2006.&lt;ref name=":4" /&gt; In 2002 he was awarded the [[Order of the Baobab]] from [[Thabo Mbeki]].&lt;ref name=":4" /&gt;&lt;ref&gt;{{Cite web|url=https://www.pa.org.za/hansard/2009/august/18/proceedings-of-the-national-assembly-tuesday-18--2/motion-of-condolence-the-late-dr-t-w-kambule|title=People's Assembly|website=www.pa.org.za|access-date=2018-07-21}}&lt;/ref&gt; He became known as ''the Rock'' for his transparent principles.&lt;ref&gt;{{Cite book |url= https://www.worldcat.org/oclc/1005016527|title=After Mandela: The Battle for the Soul of South Africa |last=Alec|first=Russell,|isbn=9781407089737|location=London|oclc=1005016527}}&lt;/ref&gt; 

Kambule died on 7 August 2009.&lt;ref&gt;{{Cite news|url=http://www.polity.org.za/article/sa-mbeki-oration-by-the-former-president-of-south-africa-in-honour-of-the-late-prof-wilkinson-kambule-orlando-east-20082009-2009-08-20|title=SA: Mbeki: Oration by the former President of South Africa in honour of the late Prof Wilkinson Kambule, Orlando East (20/08/2009)|work=Polity.org.za|access-date=2018-07-21}}&lt;/ref&gt; He was a much loved teacher, and his former students [[Siphiwe Nyanda]], [[Felicia Mabuza-Suttle]] and Mokotedi Mpshe attended his memorial service.&lt;ref name=":3" /&gt;&lt;ref&gt;{{Cite news|url= https://www.dailysun.co.za/Speakup/Letters/who-will-tell-south-africas-stories-20161213|title=WHO WILL TELL SOUTH AFRICA'S STORIES?|work=DailySun|access-date=2018-07-21|language=en}}&lt;/ref&gt;&lt;ref name=":5"&gt;{{Cite news |url=https://www.iol.co.za/news/south-africa/kambule-remembered-455865|title=Kambule remembered {{!}} IOL News|access-date=2018-07-21|language=en}}&lt;/ref&gt; His student Trevor Mdaka was his doctor at the Unitas Hospital in Centurion.&lt;ref name=":5" /&gt; 

=== Legacy ===
In 2017 the [[University of the Witwatersrand]] named their Mathematical Sciences Building after him.&lt;ref name=":2" /&gt; Deep Learning Indaba have an annual Thamsanqa Kambule Doctoral Dissertation Award.&lt;ref name=":4" /&gt;

== References ==
{{Reflist}}

{{DEFAULTSORT:Kambule, Thamsanqa}}
[[Category:African mathematicians]]
[[Category:People from Aliwal North]]
[[Category:1921 births]]
[[Category:2009 deaths]]
[[Category:University of South Africa alumni]]
[[Category:University of the Witwatersrand academics]]</text>
      <sha1>sdu4s3yd4612zvkjvweb4y97kat1q6x</sha1>
    </revision>
  </page>
  <page>
    <title>Typability</title>
    <ns>0</ns>
    <id>24091766</id>
    <redirect title="Type inference" />
    <revision>
      <id>590045599</id>
      <parentid>309770491</parentid>
      <timestamp>2014-01-10T08:03:25Z</timestamp>
      <contributor>
        <username>Magioladitis</username>
        <id>1862829</id>
      </contributor>
      <minor/>
      <comment>clean up using [[Project:AWB|AWB]] (9842)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="54">#REDIRECT [[Type inference]]

[[Category:Type theory]]</text>
      <sha1>ac8oi7mq2axgrq20oj6gwo2fysaj57b</sha1>
    </revision>
  </page>
</mediawiki>
