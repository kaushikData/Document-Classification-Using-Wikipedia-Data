<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>A Course of Pure Mathematics</title>
    <ns>0</ns>
    <id>641270</id>
    <revision>
      <id>862118482</id>
      <parentid>743225336</parentid>
      <timestamp>2018-10-02T08:54:12Z</timestamp>
      <contributor>
        <username>KarlFrei</username>
        <id>235716</id>
      </contributor>
      <comment>removed link to malicious website which was inserted as a fake reference</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4363">{{Refimprove|date=June 2016}}
{{Infobox book
| name             = A Course of Pure Mathematics
| image            = A.Course.of.Pure.Mathematics,Hardy.G.H.(Godfrey Harold).jpg
| image_size       = 175px
| caption          = Cover of Third edition, 1921
| author           =  [[G. H. Hardy]]
| country          = England
| language         = English
| subject          = [[Mathematical Analysis]]
| publisher        = [[Cambridge University Press]]
| pub_date         = 1908
| isbn             = 0521720559
| wikisource       =
}}
'''''A Course of Pure Mathematics''''' is a classic textbook in introductory [[mathematical analysis]], written by [[G. H. Hardy]]. It is recommended for people studying calculus. First published in 1908, it went through ten editions (up to 1952) and several reprints. It is now out of copyright in UK and is downloadable from various internet web sites. It remains one of the most popular books on pure mathematics.

==Contents==
The book contains a large number of descriptive and study materials together with a number of difficult problems with regards to number theory analysis. The book is organized into the following chapters, with each chapter further divided.

I. REAL VARIABLES

II. FUNCTIONS OF REAL VARIABLES

III COMPLEX NUMBERS

IV LIMITS OF FUNCTIONS OF A POSITIVE INTEGRAL VARIABLE

V LIMITS OF FUNCTIONS OF A CONTINUOUS VARIABLE. CONTINUOUS AND DISCONTINUOUS FUNCTIONS

VI DERIVATIVES AND INTEGRALS

VII ADDITIONAL THEOREMS IN THE DIFFERENTIAL AND INTEGRAL CALCULUS

VIII THE CONVERGENCE OF INFINITE SERIES AND INFINITE INTEGRALS

IX THE LOGARITHMIC, EXPONENTIAL AND CIRCULAR FUNCTIONS OF A REAL VARIABLE

X THE GENERAL THEORY OF THE LOGARITHMIC, EXPONENTIAL AND CIRCULAR FUNCTIONS

Appendices

INDEX

==Review==
The book was intended to help reform mathematics teaching in the UK, and more specifically in the [[University of Cambridge]] and in schools preparing to study higher mathematics.  It was aimed directly at "scholarship level" students – the top 10% to 20% by ability.  Hardy himself did not originally find a passion for mathematics, only seeing it as a way to beat other students, which he did decisively, and gain scholarships.&lt;ref&gt;{{cite web|url=http://www-history.mcs.st-andrews.ac.uk/Biographies/Hardy.html |title=Hardy biography |website=History.mcs.st-andrews.ac.uk |date=1947-12-01 |accessdate=2016-06-15}}&lt;/ref&gt; However, his book excels in effectively explaining analytical number theory and calculus following the rigor of mathematics.

Whilst his book changed the way the subject was taught at university, the content reflects the era in which the book was written. The whole book explores number theory and the author constructs real numbers theoretically. It adequately deals with single-variable calculus, sequences, number series, properties of cos, sin, log, etc. but does not refer to mathematical groups, multi-variable functions or vector calculus. Each section includes some demanding problems. Hardy combines the enthusiasm of the missionary with the rigor of the purist in his exposition of the fundamental ideas of the differential and integral calculus, of the properties of infinite series and of other topics involving the notion of limit. Hardy's presentation of mathematical analysis is as valid today as when first written: students will find that his economical and energetic style of presentation is one that modern authors rarely come close to. Despite its limitations, it is considered a classic in its field. It is probably of most use to 1st year university students of pure mathematics.

==References==
{{Reflist}}

==External links==

===Online copies===
* [https://archive.org/details/coursepuremath00hardrich Third edition (1921) at Internet Archive]
* [http://www.gutenberg.org/ebooks/38769 Third edition (1921) at Project Gutenberg]
* [http://www.hti.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=ACM1516.0001.001 First edition (1908) at University of Michigan Historical Math Collection]

===Other===
* [http://www.cambridge.org/us/academic/subjects/mathematics/real-and-complex-analysis/course-pure-mathematics-10th-edition-1 ''A Course of Pure Mathematics'' at Cambridge University Press] (10 e. 1952, reissued 2008)

{{DEFAULTSORT:Course of Pure Mathematics}}
[[Category:1908 books]]
[[Category:Mathematics textbooks]]
[[Category:Mathematical analysis]]</text>
      <sha1>o5w5wt3z8l7f6qimjkhs6gbqf13w7dd</sha1>
    </revision>
  </page>
  <page>
    <title>Alpha recursion theory</title>
    <ns>0</ns>
    <id>12008116</id>
    <revision>
      <id>812103432</id>
      <parentid>804686025</parentid>
      <timestamp>2017-11-26T01:22:50Z</timestamp>
      <contributor>
        <ip>132.178.150.197</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2939">In [[recursion theory]], '''α recursion theory''' is a generalisation of [[recursion theory]] to subsets of  [[admissible ordinal]]s &lt;math&gt;\alpha&lt;/math&gt;.  An admissible set is closed under &lt;math&gt;\Sigma_1(L_\alpha)&lt;/math&gt; functions.  If &lt;math&gt;L_{\alpha}&lt;/math&gt; is a  model of [[Kripke–Platek set theory]] then &lt;math&gt;\alpha&lt;/math&gt; is an admissible ordinal.  In what follows &lt;math&gt;\alpha&lt;/math&gt; is considered to be fixed.

The objects of study in &lt;math&gt;\alpha&lt;/math&gt; recursion are subsets of &lt;math&gt;\alpha&lt;/math&gt;.  A is said to be '''&lt;math&gt;\alpha&lt;/math&gt; recursively enumerable''' if it is &lt;math&gt; \Sigma_1&lt;/math&gt; definable over &lt;math&gt;L_\alpha&lt;/math&gt;.  A is recursive if both A and &lt;math&gt;\alpha \setminus A&lt;/math&gt; (its complement in &lt;math&gt;\alpha&lt;/math&gt;) are &lt;math&gt;\alpha&lt;/math&gt; recursively enumerable.

Members of &lt;math&gt;L_\alpha&lt;/math&gt; are called &lt;math&gt;\alpha&lt;/math&gt; finite and play a similar role to the finite numbers in classical recursion theory.

We say R is a reduction procedure if it is &lt;math&gt;\alpha&lt;/math&gt; recursively enumerable and every member of R is of the form &lt;math&gt; \langle H,J,K \rangle &lt;/math&gt; where ''H'', ''J'', ''K'' are all α-finite.

''A'' is said to be α-recursive in ''B'' if there exist &lt;math&gt;R_0,R_1&lt;/math&gt; reduction procedures such that:

: &lt;math&gt;K \subseteq A \leftrightarrow \exists H: \exists J:[\langle H,J,K \rangle \in R_0 \wedge H \subseteq B \wedge J \subseteq \alpha / B ],&lt;/math&gt;

: &lt;math&gt;K \subseteq \alpha / A \leftrightarrow \exists H: \exists J:[\langle H,J,K \rangle \in R_1 \wedge H \subseteq B \wedge J \subseteq \alpha / B ].&lt;/math&gt;

If ''A'' is recursive in ''B'' this is written &lt;math&gt;\scriptstyle A \le_\alpha B&lt;/math&gt;.  By this definition ''A'' is recursive in &lt;math&gt;\scriptstyle\varnothing&lt;/math&gt; (the [[empty set]]) if and only if ''A'' is recursive.  However A being recursive in B is not equivalent to A being &lt;math&gt;\Sigma_1(L_\alpha[B])&lt;/math&gt;.

We say ''A'' is regular if &lt;math&gt;\forall \beta \in \alpha: A \cap \beta \in L_\alpha&lt;/math&gt; or in other words if every initial portion of ''A'' is α-finite.

==Results in &lt;math&gt;\alpha&lt;/math&gt; recursion==

Shore's splitting theorem:  Let A be &lt;math&gt;\alpha&lt;/math&gt; recursively enumerable and regular.  There exist &lt;math&gt;\alpha&lt;/math&gt; recursively enumerable &lt;math&gt;B_0,B_1&lt;/math&gt; such that &lt;math&gt;A=B_0 \cup B_1 \wedge B_0 \cap B_1 = \varnothing \wedge A \not\le_\alpha B_i (i&lt;2).&lt;/math&gt;

Shore's density theorem:  Let ''A'', ''C'' be α-regular recursively enumerable sets such that &lt;math&gt;\scriptstyle A &lt;_\alpha C&lt;/math&gt; then there exists a regular α-recursively enumerable set ''B'' such that &lt;math&gt;\scriptstyle A &lt;_\alpha B &lt;_\alpha C&lt;/math&gt;.

==References==

* Gerald Sacks, ''Higher recursion theory'', Springer Verlag, 1990 https://projecteuclid.org/euclid.pl/1235422631
* Robert Soare, ''Recursively Enumerable Sets and Degrees'', Springer Verlag, 1987 https://projecteuclid.org/euclid.bams/1183541465

[[Category:Computability theory]]</text>
      <sha1>0wqumvx3j7sp0hry82uujnlvv0ojcsq</sha1>
    </revision>
  </page>
  <page>
    <title>Aristarchus's inequality</title>
    <ns>0</ns>
    <id>31152478</id>
    <revision>
      <id>816411229</id>
      <parentid>816411205</parentid>
      <timestamp>2017-12-21T04:38:21Z</timestamp>
      <contributor>
        <username>Cherkash</username>
        <id>10363</id>
      </contributor>
      <minor/>
      <comment>Cherkash moved page [[Aristarchus' inequality]] to [[Aristarchus's inequality]] over redirect: singular possessive</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1024">'''Aristarchus's inequality''' (after the Greek astronomer and mathematician [[Aristarchus of Samos]]; c. 310 – c. 230 BCE) is a law of [[trigonometry]] which states that if ''&amp;alpha;'' and ''&amp;beta;'' are [[acute angle]]s (i.e.&amp;nbsp;between 0 and a right angle) and ''&amp;beta;''&amp;nbsp;&lt;&amp;nbsp;''&amp;alpha;'' then

: &lt;math&gt; \frac{\sin\alpha}{\sin\beta} &lt; \frac{\alpha}{\beta} &lt; \frac{\tan\alpha}{\tan\beta}. &lt;/math&gt;

[[Ptolemy]] used the first of these inequalities while constructing [[Ptolemy's table of chords|his table of chords]].&lt;ref name=toomer&gt;{{Citation|title=Ptolemy's Almagest|last1=Toomer|first1=G. J.|authorlink=Gerald J. Toomer|publisher=Princeton University Press|page= 54|year= 1998|ISBN =0-691-00260-6}}&lt;/ref&gt;

== Notes and references ==
{{Reflist}}

== External links ==
* [http://www.math.uconn.edu/~leibowitz/math2720s11/Greek_Trig.pdf Hellenistic Astronomers and the Origins of Trigonometry, by Professor Gerald M. Leibowitz]

[[Category:Trigonometry]]
[[Category:Inequalities]]


{{elementary-geometry-stub}}</text>
      <sha1>652s2sixflekvlqetyv6cg35828o7bj</sha1>
    </revision>
  </page>
  <page>
    <title>BB84</title>
    <ns>0</ns>
    <id>6178477</id>
    <revision>
      <id>865503440</id>
      <parentid>846495086</parentid>
      <timestamp>2018-10-24T09:53:00Z</timestamp>
      <contributor>
        <username>Qcomp</username>
        <id>138574</id>
      </contributor>
      <comment>added the need for authenticated classical channel to first paragraph (due to confusion in the QKD article), addeed and since Nielsen/Chuang are not clear about this requirement</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6040">'''BB84'''&lt;ref&gt;C. H. Bennett and G. Brassard. "Quantum cryptography: Public key distribution and coin tossing". In ''Proceedings of IEEE International Conference on Computers, Systems and Signal Processing'', volume 175, page 8. New York, 1984. http://researcher.watson.ibm.com/researcher/files/us-bennetc/BB84highest.pdf&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Bennett|first=Charles H.|last2=Brassard|first2=Gilles|date=2014-12-04|title=Quantum cryptography: Public key distribution and coin tossing|url=http://www.sciencedirect.com/science/article/pii/S0304397514004241|journal=Theoretical Computer Science|series=Theoretical Aspects of Quantum Cryptography – celebrating 30 years of BB84|volume=560, Part 1|pages=7–11|doi=10.1016/j.tcs.2014.05.025}}&lt;/ref&gt; is a [[quantum key distribution]] scheme developed by [[Charles H. Bennett (computer scientist)|Charles Bennett]] and [[Gilles Brassard]] in 1984. It is the first [[quantum cryptography]] [[quantum cryptography protocol|protocol]].&lt;ref&gt;{{cite journal |doi=10.1103/PhysRevA.72.032301 |arxiv=quant-ph/0505035 |title=Security of two quantum cryptography protocols using the same four qubit states |year=2005 |last1=Branciard |first1=Cyril |last2=Gisin |first2=Nicolas |last3=Kraus |first3=Barbara |last4=Scarani |first4=Valerio |journal=Physical Review A |volume=72 |issue=3|bibcode=2005PhRvA..72c2301B }}&lt;/ref&gt; The protocol is [[provable security|provably secure]], relying on the quantum property that information gain is only possible at the expense of disturbing the signal if the two states one is trying to distinguish are not orthogonal (see [[no-cloning theorem]]) and an [[authenticated]] public classical channel.&lt;ref&gt;{{cite journal |title=The security of practical quantum key distribution |first1=Valerio |last1=Scarani |first2=Helle |last2=Bechmann-Pasquinucci |first3=Nicolas J.|last3=Cerf |first4=Miloslav |last4=Dušek |first5=Norbert |last5=Lütkenhaus |first6=Momtchil |last6=Peev |journal=Rev. Mod. Phys. |volume=81 |pages=1301 |date=2009 |doi=10.1103/RevModPhys.81.1301 |arxiv=0802.4155}}&lt;/ref&gt; It is usually explained as a method of securely communicating a [[private key]] from one party to another for use in [[one-time pad]] encryption.&lt;ref&gt;''Quantum Computing and Quantum Information'', Michael Nielsen and Isaac Chuang, Cambridge University Press 2000&lt;/ref&gt;

== Description ==
In the BB84 scheme, [[Alice and Bob|Alice]] wishes to send a private key to [[Alice and Bob|Bob]]. She begins with two strings of [[bit]]s, &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt;, each &lt;math&gt;n&lt;/math&gt; bits long. She then encodes these two strings as a string of &lt;math&gt;n&lt;/math&gt; [[qubit]]s:

:&lt;math&gt;|\psi\rangle = \bigotimes_{i=1}^{n}|\psi_{a_ib_i}\rangle,&lt;/math&gt;

where &lt;math&gt;a_i&lt;/math&gt; and &lt;math&gt;b_i&lt;/math&gt; are the &lt;math&gt;i&lt;/math&gt;-th bits of &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt; respectively. Together, &lt;math&gt;a_ib_i&lt;/math&gt; give us an index into the following four qubit states:

:&lt;math&gt;|\psi_{00}\rangle = |0\rangle,&lt;/math&gt;
:&lt;math&gt;|\psi_{10}\rangle = |1\rangle,&lt;/math&gt;
:&lt;math&gt;|\psi_{01}\rangle = |+\rangle = \frac{1}{\sqrt{2}}|0\rangle + \frac{1}{\sqrt{2}}|1\rangle,&lt;/math&gt;
:&lt;math&gt;|\psi_{11}\rangle = |-\rangle = \frac{1}{\sqrt{2}}|0\rangle - \frac{1}{\sqrt{2}}|1\rangle.&lt;/math&gt;

Note that the bit &lt;math&gt;b_i&lt;/math&gt; is what decides which basis &lt;math&gt;a_i&lt;/math&gt; is encoded in (either in the computational basis or the Hadamard basis). The qubits are now in states that are not mutually orthogonal, and thus it is impossible to distinguish all of them with certainty without knowing &lt;math&gt;b&lt;/math&gt;.

Alice sends &lt;math&gt;|\psi\rangle&lt;/math&gt; over a public and authenticated [[quantum channel]] &lt;math&gt;\mathcal{E}&lt;/math&gt; to Bob. Bob receives a state &lt;math&gt;\mathcal{E}(\rho) = \mathcal{E}(|\psi\rangle\langle\psi|)&lt;/math&gt;, where &lt;math&gt;\mathcal{E}&lt;/math&gt; represents both the effects of noise in the channel and eavesdropping by a third party we'll call Eve. After Bob receives the string of qubits, all three parties, namely Alice, Bob and Eve, have their own states. However, since only Alice knows &lt;math&gt;b&lt;/math&gt;, it makes it virtually impossible for either Bob or Eve to distinguish the states of the qubits. Also, after Bob has received the qubits, we know that Eve cannot be in possession of a copy of the qubits sent to Bob, by the [[no-cloning theorem]], unless she has made measurements. Her measurements, however, risk disturbing a particular qubit with probability ½ if she guesses the wrong basis.

Bob proceeds to generate a string of random bits &lt;math&gt;b'&lt;/math&gt; of the same length as &lt;math&gt;b&lt;/math&gt; and then measures the string he has received from Alice, &lt;math&gt;a'&lt;/math&gt;. At this point, Bob announces publicly that he has received Alice's transmission. Alice then knows she can now safely announce &lt;math&gt;b&lt;/math&gt;. Bob communicates over a public channel with Alice to determine which &lt;math&gt;b_i&lt;/math&gt; and &lt;math&gt;b'_i&lt;/math&gt; are not equal. Both Alice and Bob now discard the qubits in &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;a'&lt;/math&gt; where &lt;math&gt;b&lt;/math&gt; and &lt;math&gt;b'&lt;/math&gt; do not match.

From the remaining &lt;math&gt;k&lt;/math&gt; bits where both Alice and Bob measured in the same basis, Alice randomly chooses &lt;math&gt;k/2&lt;/math&gt; bits and discloses her choices over the public channel. Both Alice and Bob announce these bits publicly and run a check to see whether more than a certain number of them agree. If this check passes, Alice and Bob proceed to use [[Quantum_key_distribution#Information_reconciliation_and_privacy_amplification|information reconciliation and privacy amplification]] techniques to create some number of shared secret keys. Otherwise, they cancel and start over.

== See also ==
* [[SARG04]]
* [[Quantum key distribution#E91 protocol: Artur Ekert .281991.29|E91]] – [[Quantum Cryptography|quantum cryptographic]] communication protocol

== References ==
&lt;references/&gt;

{{quantum_computing}}

[[Category:Cryptographic algorithms]]
[[Category:Quantum information science]]
[[Category:Quantum cryptography]]
[[Category:Quantum cryptography protocols]]

[[de:Quantenkryptografie#BB84-Protokoll]]</text>
      <sha1>g30zfb3ctk2nakrkzv80z63f3vzbadb</sha1>
    </revision>
  </page>
  <page>
    <title>Ben Green (mathematician)</title>
    <ns>0</ns>
    <id>1927952</id>
    <revision>
      <id>867331898</id>
      <parentid>862291275</parentid>
      <timestamp>2018-11-05T02:15:35Z</timestamp>
      <contributor>
        <username>Eric Rowland</username>
        <id>7918938</id>
      </contributor>
      <minor/>
      <comment>/* Mathematics */ add missing space</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13344">{{about|the mathematician|the British World War II internee|Ben Greene|those of a similar name|Benjamin Green (disambiguation)}}
{{EngvarB|date=June 2017}}
{{Use dmy dates|date=June 2017}}
{{Infobox scientist
| name = Ben Green
|birth_name              = Ben Joseph Green
|image             = Ben Green.jpg
|image_size       = 
|caption           = 
|birth_date        = {{birth date and age|df=yes|1977|2|27}}
|birth_place       = [[Bristol]], England
|death_date        = 
|death_place       = 
|residence         = [[Oxford]], England
|citizenship       = 
|nationality       = British
|ethnicity         = 
|fields            = [[Mathematics]]
|workplaces        = [[University of Bristol]]&lt;br&gt;[[University of Cambridge]]&lt;br&gt;[[University of Oxford]]&lt;br&gt;[[Princeton University]]&lt;br&gt;[[University of British Columbia]]&lt;br&gt;[[Massachusetts Institute of Technology]] 
|alma_mater        = [[Trinity College, Cambridge]]&lt;br&gt;([[Bachelor of Arts|BA]], [[Part III of the Mathematical Tripos|MMath]], [[Doctor of Philosophy|PhD]])
|doctoral_advisor  = [[Timothy Gowers]]
|thesis_title = Topics in Arithmetic Combinatorics
|thesis_year = 2003
|doctoral_students = [[Vicky Neale]]
|known_for         = 
|influences        = 
|influenced        = 
|awards            = {{no wrap|[[Clay Research Award]] {{small|(2004)}}&lt;br&gt;[[Salem Prize]] {{small|(2005)}}&lt;br&gt;[[Whitehead Prize]] {{small|(2005)}}&lt;br&gt;[[SASTRA Ramanujan Prize]] {{small|(2007)}}&lt;br&gt; [[European Mathematical Society|EMS Prize]] {{small|(2008)}}&lt;br&gt; [[Fellow of the Royal Society]] {{small|(2010)}}&lt;br&gt;[[Sylvester Medal]] &lt;small&gt;(2014)&lt;/small&gt;}}
|religion          = 
|signature         = 
|footnotes         = 
}}
'''Ben Joseph Green''' [[Fellow of the Royal Society|FRS]] (born 27 February 1977) is a British mathematician, specialising in [[combinatorics]] and [[number theory]]. He is the [[Waynflete Professor of Pure Mathematics]] at the [[University of Oxford]].

== Early life and education ==
Ben Green was born on 27 February 1977 in [[Bristol]], England. He studied at local schools in Bristol, Bishop Road Primary School and [[Fairfield Grammar School]], competing in the [[International Mathematical Olympiad]] in 1994 and 1995.&lt;ref&gt;{{IMO results |id=1137}}&lt;/ref&gt; He entered [[Trinity College, Cambridge]] in 1995 and completed his [[Bachelor of Arts|BA]] in mathematics in 1998, winning the [[Senior Wrangler (University of Cambridge)|Senior Wrangler]] title. He stayed on for [[Part III of the Mathematical Tripos|Part III]] and earned his [[doctorate]] under the supervision of English mathematician [[Timothy Gowers]], with a thesis entitled ''Topics in arithmetic combinatorics'' (2003). During his PhD he spent a year as a [[visiting student]] at [[Princeton University]]. He was a research Fellow at Trinity College, Cambridge between 2001 and 2005, before becoming a Professor of Mathematics at the [[University of Bristol]] from January 2005 to September 2006 and then the first [[Herchel Smith Professor of Pure Mathematics]] at the [[University of Cambridge]] from September 2006 to August 2013. He became the [[Waynflete Professorship|Waynflete Professor]] of Pure Mathematics at the [[University of Oxford]] on 1 August 2013. He was also a Research Fellow of the [[Clay Mathematics Institute]] and held various positions at institutes such as [[Princeton University]], [[University of British Columbia]], and [[Massachusetts Institute of Technology]].

== Mathematics ==

The majority of Green's research is in the fields of [[analytic number theory]] and [[Additive Combinatorics|additive combinatorics]], but he also has results in [[harmonic analysis]] and in [[group theory]]. His most well known theorem, proved jointly with his frequent collaborator [[Terence Tao]], states that there exist arbitrarily long arithmetic progressions in the [[prime number]]s: this is now known as the [[Green–Tao theorem]].&lt;ref&gt;{{Cite journal|last=Green|first=Ben|last2=Tao|first2=Terence|date=2008|title=The Primes Contain Arbitrarily Long Arithmetic Progressions|jstor=40345354|journal=Annals of Mathematics|volume=167|issue=2|pages=481–547}}&lt;/ref&gt;

Amongst Green's early results in additive combinatorics are an improvement of a result of [[Jean Bourgain]] of the size of [[arithmetic progression]]s in [[sumset]]s,&lt;ref&gt;{{Cite journal|last=Green|first=B.|date=2002-08-01|title=Arithmetic progressions in sumsets|url=https://link.springer.com/article/10.1007/s00039-002-8258-4|journal=Geometric &amp; Functional Analysis GAFA|language=en|volume=12|issue=3|pages=584–597|doi=10.1007/s00039-002-8258-4|issn=1016-443X}}&lt;/ref&gt; as well as a proof of the [[Cameron–Erdős conjecture]] on sum-free sets of [[natural number]]s.&lt;ref&gt;{{Cite journal|last=GREEN|first=BEN|date=2004-10-19|title=THE CAMERON–ERDOS CONJECTURE|url=http://doi.wiley.com/10.1112/S0024609304003650|journal=Bulletin of the London Mathematical Society|language=en|volume=36|issue=6|pages=769–778|doi=10.1112/s0024609304003650|issn=0024-6093|arxiv=math/0304058}}&lt;/ref&gt; He also proved an arithmetic regularity lemma&lt;ref&gt;{{Cite journal|last=Green|first=B.|date=2005-04-01|title=A Szemerédi-type regularity lemma in abelian groups, with applications|url=https://link.springer.com/article/10.1007/s00039-005-0509-8|journal=Geometric &amp; Functional Analysis GAFA|language=en|volume=15|issue=2|pages=340–376|doi=10.1007/s00039-005-0509-8|issn=1016-443X|arxiv=math/0310476}}&lt;/ref&gt; for functions defined on the first &lt;math&gt;N&lt;/math&gt; natural numbers, somewhat analogous to the [[Szemerédi regularity lemma]] for graphs.

From 2004-2010, in joint work with [[Terence Tao]] and [[Tamar Ziegler]], he developed so-called [[higher order Fourier analysis]]. This theory relates [[Gowers norm]]s with objects known as [[nilsequences]]. The theory derives its name from these nilsequences, which play an analogous role to the role that [[Character group|characters]] play in classical [[Fourier analysis]]. Green and Tao used higher order Fourier analysis to present a new method for counting the number of solutions to simultaneous equations in certain sets of integers, including in the primes.&lt;ref&gt;{{Cite journal|last=Green|first=Benjamin|last2=Tao|first2=Terence|date=2010|title=Linear equations in primes|jstor=20752252|journal=Annals of Mathematics|volume=171|issue=3|pages=1753–1850}}&lt;/ref&gt; This generalises the classical approach using [[Hardy–Littlewood circle method|Hardy--Littlewood circle method]]. Many aspects of this theory, including the quantitative aspects of the inverse theorem for the Gowers norms,&lt;ref&gt;{{Cite journal|last=Green|first=Ben|last2=Tao|first2=Terence|last3=Ziegler|first3=Tamar|date=2012|title=An inverse theorem for the Gowers U s+1 [N]-norm|jstor=23350588|journal=Annals of Mathematics|volume=176|issue=2|pages=1231–1372}}&lt;/ref&gt; are still the subject of ongoing research.

Green has also collaborated with [[Emmanuel Breuillard]] on topics in group theory. In particular, jointly with [[Terence Tao]], they proved a structure theorem&lt;ref&gt;{{Cite journal|last=Breuillard|first=Emmanuel|last2=Green|first2=Ben|last3=Tao|first3=Terence|date=2012-11-01|title=The structure of approximate groups|url=https://link.springer.com/article/10.1007/s10240-012-0043-9|journal=Publications mathématiques de l'IHÉS|language=en|volume=116|issue=1|pages=115–221|doi=10.1007/s10240-012-0043-9|issn=0073-8301|arxiv=1110.5008}}&lt;/ref&gt; for [[approximate group]]s, generalising the [[Freiman's theorem|Freiman-Ruzsa]] theorem on sets of integers with small doubling. Green also has work, joint with [[Kevin Ford (mathematician)|Kevin Ford]] and [[Sean Eberhard]], on the theory of the [[symmetric group]], in particular on what proportion of its elements fix a set of size &lt;math&gt;k&lt;/math&gt;.&lt;ref&gt;{{Cite journal|last=Eberhard|first=Sean|last2=Ford|first2=Kevin|last3=Green|first3=Ben|date=2015-12-23|title=Permutations Fixing a k-set|url=https://doi.org/10.1093/imrn/rnv371|journal=International Mathematics Research Notices|language=en|volume=2016|issue=21|pages=6713–6731|doi=10.1093/imrn/rnv371|issn=1073-7928|arxiv=1507.04465}}&lt;/ref&gt;

Green and Tao also have a paper&lt;ref&gt;{{Cite journal|last=Green|first=Ben|last2=Tao|first2=Terence|date=2013-09-01|title=On Sets Defining Few Ordinary Lines|url=https://link.springer.com/article/10.1007/s00454-013-9518-9|journal=Discrete &amp; Computational Geometry|language=en|volume=50|issue=2|pages=409–468|doi=10.1007/s00454-013-9518-9|issn=0179-5376|arxiv=1208.4714}}&lt;/ref&gt; on algebraic [[Discrete geometry|combinatorial geometry]], resolving the Dirac-Motzkin conjecture (see [[Sylvester–Gallai theorem#The number of ordinary lines|Sylvester–Gallai theorem]]). In particular they prove that, given any collection of &lt;math&gt;n&lt;/math&gt; points in the plane that are not all collinear, if &lt;math&gt;n&lt;/math&gt; is large enough then there must exist at least &lt;math&gt;n/2&lt;/math&gt; lines in the plane containing exactly two of the points.

[[Kevin Ford (mathematician)|Kevin Ford]], Ben Green, [[Sergei Konyagin]], [[James Maynard (mathematician)|James Maynard]] and [[Terence Tao]], initially in two separate research groups and then in combination, improved the lower bound for the size of the longest gap between two consecutive primes of size at most &lt;math&gt;X&lt;/math&gt;.&lt;ref&gt;{{cite arxiv|last=Ford|first=Kevin|last2=Green|first2=Ben|last3=Konyagin|first3=Sergei|last4=Maynard|first4=James|last5=Tao|first5=Terence|date=2014-12-16|title=Long gaps between primes|eprint=1412.5029|class=math.NT}}&lt;/ref&gt; The form of the previously best-known bound, essentially due to [[Robert Alexander Rankin|Rankin]], had not been improved for 76 years.

More recently Green has considered questions in arithmetic [[Ramsey theory]]. Together with [[Tom Sanders (mathematician)|Tom Sanders]] he proved that, if a finite field of prime order is finitely coloured, then there exist two elements &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; in the field such that &lt;math&gt;x&lt;/math&gt;,&lt;math&gt;y&lt;/math&gt;, &lt;math&gt;x+y&lt;/math&gt; and &lt;math&gt;xy&lt;/math&gt; all have the same colour.&lt;ref&gt;{{Cite journal|last=Green|first=Ben|last2=Sanders|first2=Tom|date=2016-03-01|title=Monochromatic sums and products|url=https://doi.org/10.19086/da.613|journal=Discrete Analysis|language=en|volume=5202016|issue=1|doi=10.19086/da.613|issn=2397-3129}}&lt;/ref&gt;

Green has also been involved with the new developments of Croot-Lev-Pach-Ellenberg-Gijswijt on applying a polynomial method to bound the size of subsets of a finite vector space without solutions to linear equations. He adapted these methods to prove, in function fields, a strong version of [[Furstenberg–Sárközy theorem|Sárközy's theorem]].&lt;ref&gt;{{Cite journal|last=Green|first=Ben|date=2016-11-23|title=Sárközy's Theorem in Function Fields|url=https://doi.org/10.1093/qmath/haw044|journal=The Quarterly Journal of Mathematics|language=en|volume=68|issue=1|pages=237–242|doi=10.1093/qmath/haw044|issn=0033-5606}}&lt;/ref&gt;

== Awards and honours ==
Green has been a Fellow of the [[Royal Society]] since 2010,&lt;ref&gt;{{cite web|url=http://royalsociety.org/people/ben-green/|title=- Royal Society}}&lt;/ref&gt; and a Fellow of the [[American Mathematical Society]] since 2012.&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society]. Retrieved 19 January 2013.&lt;/ref&gt; Green was chosen by the [[German Mathematical Society]] to deliver a [[Gauss Lectureship]] in 2013. He has received several awards:

* 2004: [[Clay Research Award]]
* 2005: [[Salem Prize]]
* 2005: [[Whitehead Prize]]&lt;ref&gt;{{cite web|url=http://www.lms.ac.uk/content/list-lms-prize-winners#Whitehead_Prize|title=List of LMS prize winners – London Mathematical Society}}&lt;/ref&gt;
* 2007: [[SASTRA Ramanujan Prize]]
* 2008: [[European Mathematical Society]] prize recipient
* 2014: [[Sylvester Medal]], awarded by the [[Royal Society]].

== References ==
{{reflist|30em}}

== External links ==
*[http://people.maths.ox.ac.uk/greenbj/ Ben Green personal homepage at Oxford]
*[https://www.maths.ox.ac.uk/contact/details/greenbj Ben Green faculty page at Oxford]
*[http://www.trin.cam.ac.uk/index.php?pageid=176&amp;conid=155 Ben Green Homepage at Trinity College, Cambridge]
*[http://www.claymath.org/research Clay Research Award 2004 announcement]
*{{MathGenealogy |id=76979 }}
*[http://front.math.ucdavis.edu/math.NT/0404188 math.NT/0404188 – Preprint on arbitrarily long arithmetic progressions on primes]

{{FRS 2010}}
{{Authority control}}

{{DEFAULTSORT:Green, Ben}}
[[Category:1977 births]]
[[Category:Living people]]
[[Category:People from Bristol]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:Academics of the University of Bristol]]
[[Category:English mathematicians]]
[[Category:Fellows of Magdalen College, Oxford]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Combinatorialists]]
[[Category:Number theorists]]
[[Category:Cambridge mathematicians]]
[[Category:Whitehead Prize winners]]
[[Category:Recipients of the SASTRA Ramanujan Prize]]
[[Category:Clay Research Award recipients]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:International Mathematical Olympiad participants]]
[[Category:Waynflete Professors of Pure Mathematics]]
[[Category:Fellows of the Royal Society]]
[[Category:Senior Wranglers]]
[[Category:Simons Investigator]]</text>
      <sha1>c23cuidssp7562mx7pta85gfn71odq3</sha1>
    </revision>
  </page>
  <page>
    <title>Bidirectional transformation</title>
    <ns>0</ns>
    <id>30780965</id>
    <revision>
      <id>868131962</id>
      <parentid>867561299</parentid>
      <timestamp>2018-11-10T05:40:45Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Reformat 2 archive links. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3883">In computer programming, '''bidirectional transformations (bx)''' are programs in which a single piece of code can be run in several ways, such that the same data are sometimes considered as input, and sometimes as output. For example, a bx run in the forward direction might transform input I into output O, while the same bx run backward would take as input versions of I and O and produce a new version of I as its output.

[[Model transformation#Unidirectional versus bidirectional|Bidirectional model transformations]] are an important special case in which a model is input to such a program.

Some bidirectional languages are [[Bijection|''bijective'']]. The bijectivity of a language is a severe restriction of its bidirectionality,&lt;ref name="nate-foster"&gt;{{Cite web |url=http://grace.gsdlab.org/images/e/e2/Nate-short.pdf |title=Archived copy |access-date=2011-02-07 |archive-url=https://web.archive.org/web/20110726133528/http://grace.gsdlab.org/images/e/e2/Nate-short.pdf |archive-date=2011-07-26 |dead-url=yes |df= }}&lt;/ref&gt; because a bijective language is merely relating two different ways to present the very same information.

More general is a lens language, in which there is a distinguished forward direction ("get") that takes a concrete input to an abstract output, discarding some information in the process: the concrete state includes all the information that is in the abstract state, and usually some more. The backward direction ("put") takes a concrete state and an abstract state and computes a new concrete state. Lenses are required to obey certain conditions to ensure sensible behaviour.

The most general case is that of symmetric bidirectional transformations. Here the two states that are related typically share some information, but each also includes some information that is not included in the other.

== Usage ==

Bidirectional transformations can be used to:

* Maintain the consistency of several sources of information&lt;ref name="grace-report"&gt;http://www.cs.cornell.edu/~jnfoster/papers/grace-report.pdf&lt;/ref&gt;
* Provide an 'abstract view' to easily manipulate data and write them back to their source

== Vocabulary ==

A bidirectional program which obeys certain round-trip laws is called a '''''lens'''''.

== Examples of implementations ==

* [[Boomerang (programming language)|Boomerang]] is a programming language which allows writing lenses to process text data formats bidirectionally
* [[Augeas (software)|Augeas]] is a configuration management library whose lens language is inspired by the Boomerang project
* ''biXid'' is a programming language for processing XML data bidirectionally&lt;ref name="bixid"&gt;{{Cite web |url=http://arbre.is.s.u-tokyo.ac.jp/~hahosoya/papers/bixid.pdf |title=Archived copy |access-date=2011-02-07 |archive-url=https://web.archive.org/web/20070702195028/http://arbre.is.s.u-tokyo.ac.jp/~hahosoya/papers/bixid.pdf |archive-date=2007-07-02 |dead-url=yes |df= }}&lt;/ref&gt;
* ''XSugar'' allows translation from XML to non-XML formats&lt;ref name="xsugar"&gt;http://www.brics.dk/xsugar/&lt;/ref&gt;

== See also ==
* [[Bidirectionalization]]
* [[Reverse computation]]
* [[Transformation language]]

== References ==

{{reflist}}

== External links ==
* {{Webarchive|url=https://web.archive.org/web/20141012223700/http://grace.gsdlab.org/index.php?title=Main_Page|date=12 October 2014|title=GRACE International Meeting on Bidirectional Transformations}}
* [http://bx-community.wikidot.com/ Bidirectional Transformations: The Bx Wiki]
* Pacheco, Hugo, and Alcino Cunha. "[https://repositorium.sdum.uminho.pt/bitstream/1822/24674/1/icmt12-1.pdf Multifocal: A strategic bidirectional transformation language for XML schemas]." International Conference on Theory and Practice of Model Transformations. Springer, Berlin, Heidelberg, 2012.

[[Category:Mathematical relations]]
[[Category:Programming languages]]


{{compu-prog-stub}}</text>
      <sha1>7nuyxqc3usyki22qg4xxesnwxyukb1w</sha1>
    </revision>
  </page>
  <page>
    <title>Birla Industrial &amp; Technological Museum</title>
    <ns>0</ns>
    <id>27378783</id>
    <revision>
      <id>864564202</id>
      <parentid>864561978</parentid>
      <timestamp>2018-10-18T01:42:02Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Unreferenced}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6002">{{Use dmy dates|date=October 2018}}
{{Use Indian English|date=October 2015}}
{{Infobox organisation
|name         = Birla Industrial &amp; Technological Museum
|image        = Birla Industrial &amp; Technological Museum, Kolkata.jpg
|image_border = 
|size         = 
|alt          = 
|caption      = 
|map          = 
|msize        = 
|malt         = 
|mcaption     = 
|formation    = 2 May 1959
|extinction   = 
|type         = Science Museum
|status       = Government
|purpose      = Educational
|headquarters = [[Kolkata]]
|location     = {{flagicon|IND}} [[India]]
|region_served = [[West Bengal]], [[Bihar]] &amp; [[Odisha]]
|membership   = Schools and l public
|language     = English, Hindi &amp; Bengali
|leader_title = Director
|leader_name  = Emdadul Islam
|main_organ   = Galleries on scientific topics
|parent_organisation = [[National Council of Science Museums]]
|affiliations = Ministry of Culture, Govt. of India
|num_staff    = 103 [As on 31 March 2015]&lt;ref&gt;''Activity report 2014–15. p-80''. National Council of Science Museums publication&lt;/ref&gt;
|num_volunteers = 6 trainees
|budget       = Rs.2229.71 lakhs &lt;ref&gt;''Activity report 2014–15. p-55'&lt;/ref&gt;
|website      = [http://www.bitm.gov.in]
|remarks      = Visitors 2,21,950 [As on 31 March 2015]&lt;ref&gt;''Activity report 2014–15. p-80'' National Council of Science Museums publication&lt;/ref&gt;
}}
'''Birla Industrial &amp; Technological Museum (BITM)''', a unit under [[National Council of Science Museums]] (NCSM), Ministry of Culture, [[Government of India]], is at Gurusaday Road, [[Kolkata]].

==History==
The first [[science museum]] in India was set up by the industrialist [[Ghanshyam Das Birla]] at [[Birla Institute of Technology and Science|BITS]], in [[Pilani]] in a hall (185 sq.mt area) of the Tower Building. The museum depicted mainly the industries and business enterprises of the Birlas. The museum was opened to the public in 1954. Ten years later the museum was shifted to the present building.

The second science museum was mooted by KS Krishnan, physicist and the then Director of [[National Physical Laboratory (United Kingdom)|National Physical Laboratory]] (NPL), he was inspired and encouraged by the then prime minister of India [[Jawaharlal Nehru]]. R Subramanian was appointed to develop science museum and planetarium project by NPL in 1956.  The science museum of 555 sq.mr floor space in Delhi was opened for public in 1956, but it was close down by the authority after few years, although it was appreciated by general visitors.

[[Bidhan Chandra Roy]], the then Chief Minister of [[West Bengal]] and physician was impressed to see [[Deutsches Museum]] of [[Munich]]. He thought to set up a science museum and a planetarium in Calcutta. Roy requested to GD Birla for a help. Birla donated his residential house to the then prime minister of India Jawaharlal Nehru. The three storied Victorian style architectural building along with five bighas land of ‘Birla Park’, where they had lived for thirty five years.&lt;ref&gt;‘Birla Industrial and Technological Museum 1959–2009’.  Book published by National Council of Science Museums – 2009&lt;/ref&gt;

{| class="toccolours" style=": right; margin-right: 1em; font-size: 85%; background:#CCFFFF; color:black; width:22em; max-width: 25%;" cellspacing="0" cellpadding="0"
! style="background-color:#cccccc;" | Former Directors
|-
| style="text-align: left;" | 
*Amalendu Bose, 1959 – 1965 &amp; 1971 – 1974
*[[Saroj Ghose]], 1965 – 1971 &amp; 1974 – 1979
*Samar Bagchi, 1979–1991
*Samaresh Goswamy, 1991–2004
*Jayanta Sthanapati, 2004–2008
*Sk. Emdadul Islam, 2008-continuing till date
|}

==Existing galleries==
[[File:Children’s Gallery - Birla Industrial &amp; Technological Museum - Kolkata 2013-04-19 7936.JPG|thumb|right|250px|The Children’s Gallery. &lt;small&gt;(April 2013.)&lt;/small&gt;]]
[[File:Birla Industrial &amp; Technological Museum - Mathematics Gallery - Kolkata 2011-03-03 1848.JPG|thumb|right|250px|The Mathematics Gallery. &lt;small&gt;(March 2011.)&lt;/small&gt; ]]

* Biotechnology
* Children's Gallery. Inaugurated on 14 November 2012
* Electricity
* Fascinating Physics
* Life Science
* Mathematics
* Metals
* Mock-up Coal Mine
* Motive Power
* Popular Science
* Television
* Transport

==Regular activities==
{{unreferenced|section|date=October 2018}}
* 3D film show, 'Lost World'
* Coal mine show
* Science shows on Magic &amp; Miracle, Surprising Chemical Reactions, Super Cool Bodies, Fun Science and Fire-y-tale
* Sky observation
* Taramandal (Portable inflatable planetarium)

==Satellite units==

* '''Bardhaman Science Centre,''' Babur Bagh. Inaugurated on 9 January 1994. Covered floor area 952.7 Sq. metres.
* '''Digha Science Centre &amp; National Science Camp,''' New [[Digha]]. Inaugurated on 31 August 1997. Covered floor area 2589 Sq. metres.
* '''Dhenkanal Science Centre,''' [[Odisha]]. Inaugurated on 5 June 1995. Covered floor area 1147 Sq. metres.
* '''District Science Centre,''' [[Purulia]]. Inaugurated on 15 December 1982. Covered floor area 1637.40 Sq. metres.
* '''Kapilas Science Park,''' [[Dhenkanal, India|Dhenkanal]]. Inaugurated on 5 June 1995. Area 4.8 Acres
* '''North Bengal Science Centre,''' [[Matigara]]. Inaugurated on 17 August 1997. Covered floor area 1875 Sq. metres.
* '''Regional Science Centre,''' [[Bhubaneswar]]. Inaugurated on 18 September 1989. Covered floor area 3819 Sq. metres.
* '''Srikrishna Science Centre,''' [[Patna]]. Inaugurated on 14 April 1978. Covered floor area 3523 Sq. metres.

==See also==
* [[Swami Vivekananda Planetarium|Swami Vivekananda Planetarium, Mangalore]]

{{Coord|22|32|4|N|88|21|49|E|display=title}}

==References==
{{Reflist}}

== External links ==
{{commons category}}
* {{Official website|http://www.bitm.gov.in/}}

{{DEFAULTSORT:Birla Industrial and Technological Museum}}
[[Category:Technology museums]]
[[Category:Science museums in India]]
[[Category:Museums established in 1959]]
[[Category:1959 establishments in India]]
[[Category:Museums in Kolkata]]
[[Category:Mathematics education]]</text>
      <sha1>mdmac57cgvlaz7axr6ko2f13uruc1ad</sha1>
    </revision>
  </page>
  <page>
    <title>Branko Grünbaum</title>
    <ns>0</ns>
    <id>1731976</id>
    <revision>
      <id>870450265</id>
      <parentid>861547996</parentid>
      <timestamp>2018-11-24T22:09:32Z</timestamp>
      <contributor>
        <username>Fiodice</username>
        <id>35220623</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6140">{{Infobox scientist
| name              = Branko Grünbaum
| image             = Branko Grünbaum.jpg
| image_size        = 220px
| caption           = Branko Grünbaum in 1975
| birth_date        = 2 October 1929
| birth_place       = [[Osijek]], [[Kingdom of Yugoslavia]], (now [[Croatia]])
| death_date        = {{death date and age|2018|9|14|1929|10|2|df=y}}
| death_place       = [[Seattle, Washington]], U.S.
| nationality       = [[Yugoslav American]]
| fields            = [[Mathematics]]
| workplaces        = [[University of Washington]]
| alma_mater        = [[Hebrew University of Jerusalem]]
| thesis_title      = On Some Properties of Minkowski Spaces
| thesis_url        = &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year       = 1957
| doctoral_advisor  = [[Aryeh Dvoretzky]]
| doctoral_students = [[Joram Lindenstrauss]]&lt;br&gt;[[Micha Perles]]
| known_for         = 
| awards            = [[Lester R. Ford|Lester R. Ford Award]] (1976)&lt;br&gt;[[Carl B. Allendoerfer Award]] (1978)&lt;br&gt;[[Leroy P. Steele Prize]] (2005)
}}
'''Branko Grünbaum''' ({{lang-he|ברנקו גרונבאום}}; 2 October 1929 – 14 September 2018)&lt;ref&gt;{{cite web|url=https://math.washington.edu/news/2018/09/18/branko-grunbaum-1929-2018|first=Rose|last=Choi|publisher=University of Washington Mathematics Department|title=Branko Grünbaum (1929—2018)|date=September 18, 2018}}&lt;/ref&gt; was a [[Yugoslavia]]n-born [[mathematician]] of [[Jews|Jewish descent]]&lt;ref name="HE"&gt;[http://www.enciklopedija.hr/Natuknica.aspx?ID=23571 Branko Grünbaum], Hrvatska enciklopedija LZMK.&lt;/ref&gt; and a professor [[emeritus]] at the [[University of Washington]] in [[Seattle]].  He received his Ph.D. in 1957 from [[Hebrew University of Jerusalem]] in [[Israel]].&lt;ref name="genealogy"&gt;{{MathGenealogy|id=26965}}&lt;/ref&gt;  
He authored over 200 papers, mostly in [[discrete geometry]], an area in which he is known for various [[classification theorem]]s. He wrote on the theory of [[abstract polyhedra]].

His paper on [[line arrangement]]s may have inspired a paper by [[N. G. de Bruijn]] on [[aperiodic tiling|quasiperiodic tilings]] (the most famous example of which is the [[Penrose tiling]] of the plane).  This paper is also cited by the authors of a monograph on hyperplane arrangements as having inspired their research.

[[File:symmetrical_5-set_Venn_diagram.svg|thumb|Grünbaum's rotationally symmetrical 5-set Venn diagram, 1975]]

Grünbaum also devised a [[multi-set]] generalisation of [[Venn diagram]]s.  He was an editor and a frequent contributor to ''[[Geombinatorics]]''.

Grünbaum's classic monograph ''Convex polytopes'', first published in 1967, became the main textbook on the subject.  His monograph ''Tilings and Patterns'', coauthored with [[Geoffrey_Colin_Shephard|G. C. Shephard]], helped to rejuvenate interest in this classic field, and has proved popular with nonmathematical audiences, as well as with mathematicians.

In 1976 Grünbaum won a [[Lester R. Ford Award]] for his expository article ''Venn diagrams and independent families of sets''.&lt;ref&gt;{{cite journal|author=Grünbaum, Branko|title=Venn diagrams and independent families of sets|journal=Mathematics Magazine|volume=48|year=1975|pages=12–23|url=http://www.maa.org/programs/maa-awards/writing-awards/venn-diagrams-and-independent-families-of-sets|doi=10.2307/2689288}}&lt;/ref&gt; In 2004, [[Gil Kalai]] and [[Victor Klee]] edited a special issue of ''[[Discrete and Computational Geometry]]'' in his honor, the "Grünbaum Festschrift". In 2005, Grünbaum was awarded the [[Leroy P. Steele Prizes|Leroy P. Steele Prize]] for Mathematical Exposition from the [[American Mathematical Society]]. He was a [[Guggenheim Fellowship|Guggenheim Fellow]], a [[Fellow of the American Association for the Advancement of Science|Fellow of the AAAS]] and in 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-01-19.&lt;/ref&gt;&lt;ref&gt;{{cite book |author=M. Pircea |title=The Best Writing on Mathematics 2010 | publisher=Princeton University Press | ISBN=9780691148410}}&lt;/ref&gt;
Grünbaum supervised 19 Ph.D.s and currently has at least 200 mathematical "descendants".&lt;ref name="genealogy" /&gt;

==Selected publications==
*{{citation
 | last = Grünbaum | first = Branko
 | edition = 2nd
 | editor1-last = Kaibel | editor1-first = Volker
 | editor2-last = Klee | editor2-first = Victor | editor2-link = Victor Klee
 | editor3-last = Ziegler | editor3-first = Günter M. | editor3-link = Günter M. Ziegler
 | isbn = 0-387-00424-6
 | publisher = [[Springer-Verlag]]
 | series = Graduate Texts in Mathematics
 | title = Convex Polytopes
 | volume = 221
 | year = 2003}}.
*{{citation
 | last1 = Grünbaum | first1 = Branko
 | last2 = Shephard | first2 = G. C.
 | isbn = 0-7167-1193-1
 | location = New York
 | publisher = W. H. Freeman
 | title = Tilings and Patterns
 | year = 1987}}&lt;ref&gt;This book is reviewed by L. Fejes Toth in BULLETIN (New Series) OF THE AMERICAN MATHEMATICAL SOCIETY
Volume 17, Number 2, October 1987, pages 369-372 read at https://projecteuclid.org/download/pdf_1/euclid.bams/1183554198&lt;/ref&gt;.

==See also==
* [[Pentagram map]]

== Notes ==
&lt;references/&gt;

== References ==
* {{Citation|last1=Orlik|first1= Peter|last2= Terao|first2=  Hiroaki|title=Arrangements of hyperplanes | location=New York | publisher=Springer |year=1992|isbn=3-540-55259-6}}

== External links ==
* [http://www.math.washington.edu/~grunbaum/ Personal web page]

{{Authority control}}

{{DEFAULTSORT:Grunbaum, Branko}}
[[Category:1929 births]]
[[Category:2018 deaths]]
[[Category:People from Osijek]]
[[Category:Yugoslav emigrants to Israel]]
[[Category:American people of Yugoslav descent]]
[[Category:20th-century American mathematicians]]
[[Category:Combinatorialists]]
[[Category:University of Washington faculty]]
[[Category:Hebrew University of Jerusalem alumni]]
[[Category:Geometers]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Guggenheim Fellows]]
[[Category:Fellows of the American Association for the Advancement of Science]]</text>
      <sha1>75xaqfax3kvagnwjew6upag4qgbbtck</sha1>
    </revision>
  </page>
  <page>
    <title>Busemann function</title>
    <ns>0</ns>
    <id>2850640</id>
    <revision>
      <id>847382591</id>
      <parentid>844139190</parentid>
      <timestamp>2018-06-24T23:31:05Z</timestamp>
      <contributor>
        <username>Michael Devore</username>
        <id>44833</id>
      </contributor>
      <minor/>
      <comment>/* Quasigeodesics in the Poincaré disk, CAT(-1) and hyperbolic spaces */ double "such that"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="80044">In [[geometric topology]], '''Busemann functions''' are used to study the large-scale geometry of geodesics in [[Hadamard space]]s and in particular [[Hadamard manifold]]s ([[simply connected]] complete [[Riemannian manifold]]s of nonpositive curvature). They are named after [[Herbert Busemann]], who introduced them; he gave an extensive treatment of the topic in his 1955 book "The geometry of geodesics".

== Definition and elementary properties ==

Let &lt;math&gt;(X,d)&lt;/math&gt; be a [[metric space]]. A [[Ray (geometry)|geodesic ray]] is a path &lt;math&gt;\gamma : [0,\infty) \to X&lt;/math&gt; which minimizes distance everywhere along its length. i.e., for all &lt;math&gt;t,t' \in [0,\infty)&lt;/math&gt;, 
:&lt;math&gt;d\big(\gamma(t), \gamma(t') \big) = \big| t - t' \big|&lt;/math&gt;. 
Equivalently, a ray is an isometry from the "canonical ray" (the set &lt;math&gt;[0,\infty)&lt;/math&gt; equipped with the Euclidean metric) into the metric space ''X''.

Given a ray ''γ'', the Busemann function &lt;math&gt;B_\gamma : X \to \mathbb R&lt;/math&gt; is defined by

:&lt;math&gt;B_\gamma(x)=\lim_{t\to\infty}\big(d\big( \gamma(t), x \big)  - t \big)&lt;/math&gt;

Thus, when ''t'' is very large, the distance &lt;math&gt;d\big( \gamma(t), x \big)&lt;/math&gt; is approximately equal to &lt;math&gt;t - B_\gamma(x)&lt;/math&gt;. Given a ray ''γ'', its Busemann function is always well-defined: indeed the right hand side ''F''&lt;sub&gt;''t''&lt;/sub&gt;(''x'') above tends pointwise to the left hand side on compacta, since &lt;math&gt;t-d( \gamma(t), x )=d(\gamma(t),\gamma(0)) - d(\gamma(t),x)&lt;/math&gt; is bounded above by &lt;math&gt; d(\gamma(0),x)&lt;/math&gt; and increasing since, if &lt;math&gt;s\le t&lt;/math&gt;,

:&lt;math&gt;t-s + d(x,\gamma(s)) - d(x,\gamma(t)) \ge t -s -d (\gamma(s),\gamma(t)) = 0.&lt;/math&gt;

It is immediate from the triangle inequality that

:&lt;math&gt;|B_\gamma(x) - B_\gamma(y)|\le d(x,y),&lt;/math&gt;

so that &lt;math&gt;B_\gamma&lt;/math&gt; is uniformly continuous. More specifically, the above estimate above shows that

*'''''Busemann functions are [[Lipschitz function]]s with constant 1'''''.&lt;ref&gt;{{harvnb|Busemann|1955|page=131}}&lt;/ref&gt;

By [[Dini's theorem]], the functions &lt;math&gt;F_t(x)=d(x,\gamma(t)) -t &lt;/math&gt; tend to &lt;math&gt;B_\gamma(x)&lt;/math&gt; uniformly on compacta as ''t'' tends to infinity.

== Example: Poincaré disk ==

Let ''D'' be the unit disk in the complex plane with the Poincaré metric

:&lt;math&gt; ds^2 = {4 \,|dz|^2 \over (1 - |z|^2)^2}.&lt;/math&gt;

Then, for |z| &lt; 1 and |ζ| = 1, the Busemann function is given by

:&lt;math&gt; B_\zeta(z) = - \log \, \left({1 - |z|^2\over |z - \zeta|^2}\right),&lt;/math&gt;

where the term in brackets on the right hand side is the [[Poisson kernel]] for the unit disk and ζ corresponds to the radial geodesic γ from the origin towards ζ,
γ(''t'') = ζ tanh(''t''/2). In fact the computation of ''d''(''x'',''y'') can be reduced to that of ''d''(''z'',0) = ''d''(|''z''|,0) = tanh&lt;sup&gt;−1&lt;/sup&gt; |''z''| = log (1+|''z''|)/(1-|''z''|), since the metric is invariant under [[Möbius transformation]]s in SU(1,1); the geodesics through 0 have the form ζ ''g''&lt;sub&gt;''t''&lt;/sub&gt;(0) where ''g''&lt;sub&gt;''t''&lt;/sub&gt; is the 1-parameter subgroup of SU(1,1)

:&lt;math&gt;g_t=\begin{pmatrix}\cosh t/2 &amp; \sinh t/2 \\ \sinh t/2 &amp; \cosh t/2\end{pmatrix}.&lt;/math&gt;

The formula above also completely determines the Busemann function by Möbius invariance. Note that

:&lt;math&gt; {1 - |z|^2\over |z - \zeta|^2} \le {1-|z|^2\over (1-|z|)^2} = 1 -\left({|z|\over 1 - |z|}\right)^2 \le 1,&lt;/math&gt;

so that the Busemann function in this case is non-negative.&lt;ref&gt;{{harvnb|Bridson|Haefliger|1999|page=273}}&lt;/ref&gt;

==Busemann functions on a Hadamard space==

In a [[Hadamard space]], where any two points are joined by a unique geodesic segment, the function ''F'' = ''F''&lt;sub&gt;''t''&lt;/sub&gt; is ''convex'', i.e. convex on geodesic segments [''x'',''y'']. Explicitly this means that if ''z''(''s'') is the point which divides [''x'',''y''] in the ratio {{math|1=''s'' : (1 − ''s'') }}, then ''F''(''z''(''s'')) ≤ ''s'' ''F''(''x'') + (1 − ''s'') ''F''(''y'').  In fact for fixed ''a'' the function ''d''(''x'',''a'') is convex and hence so are its translates; in particular, if γ is a geodesic ray in ''X'', then ''F''&lt;sub&gt;''t''&lt;/sub&gt; is convex. Since the Busemann function ''B''&lt;sub&gt;γ&lt;/sub&gt; is the pointwise limit of ''F''&lt;sub&gt;''t''&lt;/sub&gt;,

*'''''Busemann functions are convex on Hadamard spaces'''''.&lt;ref name="BGS"&gt;{{harvnb|Ballmann|Gromov|Schroeder|1985}}&lt;/ref&gt;
*'''''On a Hadamard space, the functions &lt;math&gt;F_t(y)=d(y,\gamma(t)) -t &lt;/math&gt; converge uniformly to &lt;math&gt;B_\gamma&lt;/math&gt; uniformly on any bounded subset of X.'''''&lt;ref&gt;{{harvnb|Bridson|Haefliger|1999|pages=268–269}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Lurie|2010|page=13}}&lt;/ref&gt;

In fact let {{math|1=''h''(''t'') = ''d''(''y'',γ(''t'')) − ''t'' = ''F''&lt;sub&gt;''t''&lt;/sub&gt;(''y'')}}. Since γ(''t'') is parametrised by arclength, Alexandrov's first comparison theorem for Hadamard spaces implies that the function {{math|1=''g''(''t'') = ''d''(''y'',γ(''t''))&lt;sup&gt;2&lt;/sup&gt; − ''t''&lt;sup&gt;2&lt;/sup&gt;}} is convex. Hence for 0&lt; ''s'' &lt; ''t''

:&lt;math&gt;g(s) \le (1-{s\over t})g(0) + {s\over t} g(t).&lt;/math&gt;

Thus

:&lt;math&gt;2sh(s)\le (h(s) +s)^2 - s^2 =g(s)  \le (1-{s\over t})d(x,y)^2 + {s\over t} ( 2th(t) +h(t)^2 )\le d(x,y)^2 + 2s h(t) +{s\over t} d(x,y)^2,&lt;/math&gt;

so that

:&lt;math&gt;|F_s(y) - F_t(y)|= |h(s) - h(t)| \le {1\over 2} (s^{-1} + t^{-1}) d(x,y)^2.&lt;/math&gt;

Letting ''t'' tend to ∞, it follows that

:&lt;math&gt;|F_s(y) - B_\gamma(y)| \le {d(x,y)^2\over 2s},&lt;/math&gt;

so convergence is uniform on bounded sets.

Note that the inequality above for &lt;math&gt;|F_s(y) - F_t(y)| &lt;/math&gt; (together with its proof) also holds for geodesic segments: if Γ(''t'') is a geodesic segment starting at ''x'' and parametrised by arclength then

:&lt;math&gt;|d(y,\Gamma(s)) -s -d(y,\Gamma(t)) +t| \le (s^{-1} + t^{-1}) d(x,y)^2.&lt;/math&gt;

Next suppose that ''x'', ''y''  are points in a Hadamard space, and let δ(''s'') be the geodesic through ''x'' with δ(0) = ''y'' and δ(''t'') = ''x'', where ''t'' = ''d''(''x'',''y''). This geodesic cuts the boundary of the closed ball {{overline|''B''}}(''y'',''r'') at the point δ(''r''). Thus if {{math|1=''d''(''x'',''y'') &gt; ''r''}}, there is a point ''v'' with {{math|1=''d''(''y'',''v'') = ''r''}} such that {{math|1=''d''(''x'',''v'')  = ''d''(''x'',''y'') − ''r''}}.

This condition persists for Busemann functions. The statement and proof of the property for Busemann functions relies on a fundamental theorem on closed convex subsets of a Hadamard space, which generalises [[orthogonal projection]] in a [[Hilbert space]]: if {{math|''C''}} is a closed convex set in a Hadamard space {{math|''X''}}, then every point {{math|''x''}} in {{math|''X''}} has a unique closest point {{math|1=''P''(''x'') ≡ ''P''&lt;sub&gt;''C''&lt;/sub&gt;(''x'')}} in {{math|''C''}} and {{math|1=''d''(''P''(''x''),''P''(''y'')) ≤ ''d''(''x'',''y'')}}; moreover {{math|1=''a'' = ''P''(''x'')}} is uniquely determined by the property that, for {{math|''y''}} in {{math|''C''}},

:&lt;math&gt;d(x,y)^2 \ge d(x,a) ^2 + d(a,y)^2,&lt;/math&gt;

so that the angle at {{math|''a''}} in the Euclidean [[comparison triangle]] for ''a'',''x'',''y'' is greater than or equal to {{pi}}/2.

*'''''If h is a Busemann function on a Hadamard space, then, given y in X and r &gt; 0, there is a unique point v with d(y,v) = r such that h(v) =  h(y) − r. For fixed r &gt; 0, the point v is the closest point of y to the closed convex C set of points u such that h(u) ≤ h(y) − r and therefore depends continuously on y.'''''&lt;ref&gt;{{harvnb|Bridson|Haefliger|1999|pages=271–272}}&lt;/ref&gt;

In fact let ''v'' be the closest point to ''y'' in ''C''. Then ''h''(''v'') = ''h''(''y'') − ''r'' and so ''h'' is minimised by ''v'' in {{overline|''B''}}(''y'',''R'') where ''R'' = ''d''(''y'',''v'') and ''v'' is the unique point where ''h'' is minimised. By the Lipschitz condition ''r'' = |''h''(''y'') − ''h''(''v'')| ≤ ''R''. To prove the assertion, it suffices to show that ''R'' = ''r'', i.e. ''d''(''y'',''v'') = ''r''. On the other hand, ''h'' is the uniform limit on any closed ball of functions ''h''&lt;sub&gt;''n''&lt;/sub&gt;. On {{overline|''B''}}(''y'',''r''), these are minimised by points ''v''&lt;sub&gt;''n''&lt;/sub&gt; with ''h''&lt;sub&gt;''n''&lt;/sub&gt;(''v''&lt;sub&gt;''n''&lt;/sub&gt;) = ''h''&lt;sub&gt;''n''&lt;/sub&gt;(''y'') − ''r''. Hence the infimum of ''h'' on {{overline|''B''}}(''y'',''r'') is ''h''(''y'') − ''r'' and ''h''(''v''&lt;sub&gt;''n''&lt;/sub&gt;) tends to ''h''(''y'') − ''r''. Thus ''h''(''v''&lt;sub&gt;''n''&lt;/sub&gt;) = ''h''(''y'') − ''r''&lt;sub&gt;''n''&lt;/sub&gt; with ''r''&lt;sub&gt;''n''&lt;/sub&gt; ≤ ''r'' and ''r''&lt;sub&gt;''n''&lt;/sub&gt; tending towards ''r''. Let ''u''&lt;sub&gt;''n''&lt;/sub&gt; be the closest point to ''y'' with ''h''(''u''&lt;sub&gt;''n''&lt;/sub&gt;) ≤ ''h''(''y'') − ''r''&lt;sub&gt;''n''&lt;/sub&gt;. Let ''R''&lt;sub&gt;''n''&lt;/sub&gt; = ''d''(''y'',''u''&lt;sub&gt;''n''&lt;/sub&gt;) ≤ ''r''. Then ''h''(''u''&lt;sub&gt;''n''&lt;/sub&gt;) =  ''h''(''y'') − ''r''&lt;sub&gt;''n''&lt;/sub&gt;, and, by the Lipschitz condition on ''h'', ''R''&lt;sub&gt;''n''&lt;/sub&gt; ≥ ''r''&lt;sub&gt;''n''&lt;/sub&gt;. In particular ''R''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''r''. Passing to a subsequence if necessary it can be assumed that ''r''&lt;sub&gt;''n''&lt;/sub&gt; and ''R''&lt;sub&gt;''n''&lt;/sub&gt; are both increasing (to ''r''). The inequality for convex optimisation implies that for ''n'' &gt; ''m''.

:&lt;math&gt; d(u_n,u_m)^2 \le R_n^2 - R_m^2\le 2r|R_n -R_m|,&lt;/math&gt;

so that ''u''&lt;sub&gt;''n''&lt;/sub&gt; is a Cauchy sequence. If ''u'' is its limit, then ''d''(''y'',''u'') = ''r'' and ''h''(''u'') = ''h''(''y'') − ''r''. By uniqueness it follows that ''u'' = ''v'' and hence ''d''(''y'',''v'') = ''r'', as required.

'''Uniform limits.''' The above argument proves more generally that if ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;,''x''&lt;sub&gt;0&lt;/sub&gt;) tends to infinity and the functions ''h''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') = ''d''(''x'',''x''&lt;sub&gt;''n''&lt;/sub&gt;) – ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;,''x''&lt;sub&gt;0&lt;/sub&gt;) tend uniformly on bounded sets to ''h''(''x''), then ''h'' is convex, Lipschitz with Lipschitz constant 1 and, given ''y'' in ''X'' and ''r'' &gt; 0, there is a unique point ''v'' with ''d''(''y'',''v'') = ''r'' such that ''h''(''v'') =  ''h''(''y'') − ''r''. If on the other hand the sequence (''x''&lt;sub&gt;''n''&lt;/sub&gt;) is bounded, then the terms all lie in some closed ball and uniform convergence there implies that (''x''&lt;sub&gt;''n''&lt;/sub&gt;) is a Cauchy sequence so converges to some ''x''&lt;sub&gt;∞&lt;/sub&gt; in ''X''. So ''h''&lt;sub&gt;''n''&lt;/sub&gt; tends uniformly to ''h''&lt;sub&gt;∞&lt;/sub&gt;(''x'') = ''d''(''x'',''x''&lt;sub&gt;∞&lt;/sub&gt;) – ''d''(''x''&lt;sub&gt;∞&lt;/sub&gt;,''x''&lt;sub&gt;0&lt;/sub&gt;), a function of the same form. The same argument also shows that the class of functions which satisfy the same three conditions (being convex, Lipschitz and having minima on closed balls) is closed under taking uniform limits on bounded sets.

'''Comment.''' Note that, since any closed convex subset of a Hadamard subset of a Hadamard space is also a Hadamard space, any closed ball in a Hadamard space is a Hadamard space. In particular it need not be the case that every geodesic segment is contained in a geodesic defined on the whole of '''R''' or even a semi-infinite interval [0,∞). The closed unit ball of a Hilbert space gives an explicit example which is not a proper metric space.

*'''''If h is a convex function, Lipschitz with constant 1 and h assumes its minimum on any closed ball centred on y with radius r at a unique point v on the boundary with h(v) = h(y) − r, then for each y in X there is a unique geodesic ray δ such that δ(0) = y and δ cuts each closed convex set h ≤ h(y) – r with r &gt; 0 at δ(r), so that h(δ(t)) = h(y) – t. In particular this holds for each Busemann function.'''''&lt;ref name="Bridson 1999 pages=271–272"&gt;{{harvnb|Bridson|Haefliger|1999|pages=271–272}}&lt;/ref&gt;

In fact the third condition implies that ''v'' is the closest point to ''y'' in the closed convex set ''C''&lt;sub&gt;''r''&lt;/sub&gt; of points ''u'' such that ''h''(''u'') ≤ ''h''(''y'') – ''r''. Let δ(''t'') for 0 ≤ ''t'' ≤ ''r'' be the geodesic joining ''y'' to ''v''. Then ''k''(''t'') = ''h''(δ(''t'')) - ''h''(''y'') is a convex Lipschitz function on [0,''r''] with Lipschitz constant 1 satisfying ''k''(''t'') ≤ – ''t'' and ''k''(0) = 0 and ''k''(''r'') = –''r''. So ''k'' vanishes everywhere, since if 0 &lt; ''s'' &lt; ''r'', ''k''(''s'') ≤ –''s'' and |''k''(s)| ≤ ''s''. Hence ''h''(δ(''t'')) = ''h''(''y'') – ''t''. By uniqueness it follows that δ(''t'') is the closest point to ''y'' in ''C''&lt;sub&gt;''t''&lt;/sub&gt; and that it is the unique point minimising ''h'' in {{overline|''B''}}(''y'',''t''). Uniqueness implies that these geodesics segments coincide for arbitrary ''r'' and therefore that δ extends to a geodesic ray with the stated property.

*'''''If h = h&lt;sub&gt;γ &lt;/sub&gt;, then the geodesic ray δ starting at y satisfies''''' &lt;math&gt;\sup d(\gamma(t),\delta(t)) &lt; \infty&lt;/math&gt;. '''''If δ&lt;sub&gt;1&lt;/sub&gt; is another ray starting at y with''''' &lt;math&gt;\sup d(\delta(t),\delta_1(t)) &lt; \infty&lt;/math&gt; '''''then δ&lt;sub&gt;1&lt;/sub&gt; = δ.'''''

To prove the first assertion, it is enough to check this for ''t'' sufficiently large. In that case γ(''t'') and δ(''t'' − ''h''(''y'')) are the projections of ''x'' and ''y'' onto the closed convex set {{math|1=''h'' ≤ −''t''}}. Therefore, ''d''(γ(''t''),δ(''t'' − ''h''(''y''))) ≤ ''d''(''x'',''y''). Hence  ''d''(γ(''t''),δ(''t'')) ≤ ''d''(γ(''t''),δ(''t'' − ''h''(''y''))) + ''d''(δ(''t'' − ''h''(''y'')),δ(''t'')) ≤ ''d''(''x'',''y'') + |''h''(''y'')|. The second assertion follows because ''d''(δ&lt;sub&gt;1&lt;/sub&gt;(''t''),δ(''t'')) is convex and bounded on [0,∞), so, if it vanishes at ''t'' = 0, must vanish everywhere.

*'''''Suppose that h is a continuous convex function and for each y in X there is a unique geodesic ray δ such that δ(0) = y and δ cuts each closed convex set h ≤ h(y) – r with r &gt; 0 at δ(r), so that h(δ(t)) = h(y) – t; then h is a Busemann function. In fact h − h&lt;sub&gt;δ&lt;/sub&gt; is a constant function.'''''&lt;ref name="Bridson 1999 pages=271–272"/&gt;

Let ''C''&lt;sub&gt;''r''&lt;/sub&gt; be the closed convex set of points ''z'' with ''h''(''z'') ≤ −''r''. Since ''X'' is a Hadamard space for every point ''y'' in ''X'' there is a unique closest point ''P''&lt;sub&gt;''r''&lt;/sub&gt;(''y'') to ''y'' in ''C''&lt;sub&gt;''r''&lt;/sub&gt;. It depends continuously on ''y'' and if ''y'' lies outside ''C''&lt;sub&gt;''r''&lt;/sub&gt;, then ''P''&lt;sub&gt;''r''&lt;/sub&gt;(''y'') lies on the hypersurface ''h''(''z'') = − ''r''—the boundary ∂''C''&lt;sub&gt;''r''&lt;/sub&gt; of ''C''&lt;sub&gt;''r''&lt;/sub&gt;—and ''P''&lt;sub&gt;''r''&lt;/sub&gt;(''y'') satisfies the inequality of convex optimisation. Let δ(''s'') be the geodesic ray starting at ''y''.

Fix ''x'' in ''X''. Let γ(''s'') be the geodesic ray starting at ''x''. Let ''g''(''z'') = ''h''&lt;sub&gt;γ&lt;/sub&gt;(''z''), the Busemann function for γ with base point ''x''. In particular ''g''(''x'') = 0. It suffices to show that {{math|1=''g'' = ''h'' – ''h''(''y'')1}}. Now take ''y'' with ''h''(''x'') = ''h''(''y'') and let δ(''t'') be the geodesic ray starting at ''y'' corresponding to ''h''. Then

:&lt;math&gt;d(x,y) \ge d(\gamma(t),\delta(t)),\,\,\, d(x,\delta(t))^2 \ge d(x,\gamma(t))^2+d(\gamma(t),\delta(t))^2,\,\,\,d(y,\gamma(t))^2 \ge d(y,\delta(t))^2+d(\gamma(t),\delta(t))^2.&lt;/math&gt;

On the other hand, for any four points ''a'', ''b'', ''c'', ''d'' in a Hadamard space, the following quadrilateral inequality of [[Yurii Reshetnyak|Reshetnyak]] holds:

:&lt;math&gt; |d(a,c)^2 + d(b,d)^2 - d(a,d)^2 - d(b,d)^2|\le 2 d(a,b)d(c,d).&lt;/math&gt;

Setting ''a'' = ''x'', ''b'' = ''y'', ''c'' = γ(''t''), ''d'' =  δ(''t''), it follows that

:&lt;math&gt;|d(y,\gamma(t))^2 - d(x,\delta(t))^2|\le 2d(x,y)^2,&lt;/math&gt;

so that

:&lt;math&gt;|d(y,\gamma(t)) - d(x,\gamma(t))|\le  2 {d(x,y)^2\over d(y,\gamma(t)) + d(x,\gamma(t))}\le {d(x,y)^2\over t}.&lt;/math&gt;

Hence ''h''&lt;sub&gt;γ&lt;/sub&gt;(''y'') = 0. Similarly ''h''&lt;sub&gt;δ&lt;/sub&gt;(''x'') = 0. Hence ''h''&lt;sub&gt;γ&lt;/sub&gt;(''y'') = 0 on the level surface of ''h'' containing ''x''. Now for ''t'' ≥ 0 and ''z'' in ''X'', let α&lt;sub&gt;''t''&lt;/sub&gt;(''z'') = γ&lt;sub&gt;1&lt;/sub&gt;(''t'') the geodesic ray starting at ''z''. Then {{math|1=α&lt;sub&gt;''s'' + ''t''&lt;/sub&gt; = α&lt;sub&gt;''s''&lt;/sub&gt; ∘  α&lt;sub&gt;''t''&lt;/sub&gt;}} and {{math|1=''h'' ∘ α&lt;sub&gt;''t''&lt;/sub&gt; = ''h''  − ''t''}}. Moreover, by boundedness, {{math|1=''d''(α&lt;sub&gt;''t''&lt;/sub&gt;(''u''),α&lt;sub&gt;''t''&lt;/sub&gt;(''v'')) ≤ ''d''(''u'',''v'')}}. The flow α&lt;sub&gt;''s''&lt;/sub&gt; can be used to transport this result to all the level surfaces of ''h''. In fact for general ''y''&lt;sub&gt;1&lt;/sub&gt;, if ''h''(''y''&lt;sub&gt;1&lt;/sub&gt;) &lt; ''h''(''x''), take ''s'' &gt; 0 such that ''h''(α&lt;sub&gt;''s''&lt;/sub&gt;(''x'')) = ''h''(''y''&lt;sub&gt;1&lt;/sub&gt;) and set ''x''&lt;sub&gt;1&lt;/sub&gt; = α&lt;sub&gt;''s''&lt;/sub&gt;(''x''). Then ''h''&lt;sub&gt;γ&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;(''y''&lt;sub&gt;1&lt;/sub&gt;) = 0, where γ&lt;sub&gt;1&lt;/sub&gt;(''t'') = α&lt;sub&gt;''t''&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;) = γ(''s'' + ''t''). But then ''h''&lt;sub&gt;γ&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt; = ''h''&lt;sub&gt;γ&lt;/sub&gt; – ''s'', so that ''h''&lt;sub&gt;γ&lt;/sub&gt;(''y''&lt;sub&gt;1&lt;/sub&gt;) = ''s''. Hence {{math|1=''g''(''y''&lt;sub&gt;1&lt;/sub&gt;) = ''s'' = ''h''((α&lt;sub&gt;''s''&lt;/sub&gt;(''x'')) – ''h''(''x'') = ''h''(''y''&lt;sub&gt;1&lt;/sub&gt;) – ''h''(''x'')}}, as required. Similarly if ''h''(''y''&lt;sub&gt;1&lt;/sub&gt;) &gt; ''h''(''x''), take
''s'' &gt; 0 such that ''h''(α&lt;sub&gt;''s''&lt;/sub&gt;(''y''&lt;sub&gt;1&lt;/sub&gt;)) = ''h''(''x''). Let ''y'' = α&lt;sub&gt;''s''&lt;/sub&gt;(''y''&lt;sub&gt;1&lt;/sub&gt;). Then
''h''&lt;sub&gt;γ&lt;/sub&gt;(''y'') = 0, so ''h''&lt;sub&gt;γ&lt;/sub&gt;(''y''&lt;sub&gt;1&lt;/sub&gt;) = –''s''. Hence {{math|1=''g''(''y''&lt;sub&gt;1&lt;/sub&gt;) = –''s'' =  ''h''(''y''&lt;sub&gt;1&lt;/sub&gt;) – ''h''(''x'')}}, as required.

Finally there are necessary and sufficient conditions for two geodesics to define the same Busemann function up to constant:

*'''''On a Hadamard space, the Busemann functions of two geodesic rays &lt;math&gt;\gamma_1&lt;/math&gt; and &lt;math&gt;\gamma_2&lt;/math&gt; differ by a constant if and only if &lt;math&gt;\sup_{t\ge 0} d(\gamma_1(t),\gamma_2(t)) &lt; \infty&lt;/math&gt;.'''''&lt;ref&gt;{{harvnb|Dal'bo|Peigné|Sambusetti|2012|pages=94–96}}&lt;/ref&gt;

Suppose firstly that γ and δ are two geodesic rays with Busemann functions differing by a constant. Shifting the argument of one of the geodesics by a constant, it may be assumed that ''B''&lt;sub&gt;γ&lt;/sub&gt; = ''B''&lt;sub&gt;δ&lt;/sub&gt; = ''B'', say. Let ''C'' be the closed convex set on which ''B''(''x'') ≤ −''r''. Then ''B''(γ(''t'')) = ''B''&lt;sub&gt;γ&lt;/sub&gt;(γ(''t'')) = −''t'' and similarly ''B''(δ(''t'')) = − ''t''. Then for ''s'' ≤ ''r'', the points γ(''s'') and  δ(''s'') have closest points γ(''r'') and  δ(''r'') in ''C'', so that ''d''(γ(''r''), δ(''r'')) ≤ ''d''(γ(''s''), δ(''s'')). Hence {{math|1=sup&lt;sub&gt;''t'' ≥ 0&lt;/sub&gt; ''d''(γ(''t''), δ(''t'')) &lt; ∞}}.

Now suppose that {{math|1=sup&lt;sub&gt;''t'' ≥ 0&lt;/sub&gt; ''d''(γ&lt;sub&gt;1&lt;/sub&gt;(''t''), γ&lt;sub&gt;2&lt;/sub&gt;(''t'')) &lt; ∞}}. Let δ&lt;sub&gt;''i''&lt;/sub&gt;(''t'') be the geodesic ray starting at ''y'' associated with ''h''&lt;sub&gt;γ&lt;sub&gt;''i''&lt;/sub&gt;&lt;/sub&gt;. Then {{math|1=sup&lt;sub&gt;''t'' ≥ 0&lt;/sub&gt; ''d''(γ&lt;sub&gt;''i''&lt;/sub&gt;(''t''), δ&lt;sub&gt;''i''&lt;/sub&gt;(''t'')) &lt; ∞}}. Hence {{math|1=sup&lt;sub&gt;''t'' ≥ 0&lt;/sub&gt; ''d''(δ&lt;sub&gt;1&lt;/sub&gt;(''t''), δ&lt;sub&gt;2&lt;/sub&gt;(''t'')) &lt; ∞}}. Since δ&lt;sub&gt;1&lt;/sub&gt; and δ&lt;sub&gt;2&lt;/sub&gt; both start at ''y'', it follows that δ&lt;sub&gt;1&lt;/sub&gt;(''t'') ≡ δ&lt;sub&gt;2&lt;/sub&gt;(''t''). By the previous result ''h''&lt;sub&gt;γ&lt;sub&gt;''i''&lt;/sub&gt;&lt;/sub&gt; and ''h''&lt;sub&gt;δ&lt;sub&gt;''i''&lt;/sub&gt;&lt;/sub&gt; differ by a constant; so ''h''&lt;sub&gt;γ&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt; and ''h''&lt;sub&gt;γ&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt; differ by a constant.

To summarise, the above results give the following characterisation of Busemann functions on a Hadamard space:&lt;ref name="Bridson 1999 pages=271–272"/&gt;

'''THEOREM.''' '''''On a Hadamard space, the following conditions on a function f are equivalent:'''''

*'''''h is a Busemann function.'''''
*'''''h is a convex function, Lipschitz with constant 1 and h assumes its minimum on any closed ball centred on y with radius r at a unique point v on the boundary with h(v) = h(y) − r.'''''
*'''''h is a continuous convex function and for each y in X there is a unique geodesic ray δ such that δ(0) = y and, for any r &gt;0, the ray δ cuts each closed convex set h ≤ h(y) – r at δ(r).'''''

==Bordification of a Hadamard space==
In the previous section it was shown that if ''X'' is a Hadamard space and ''x''&lt;sub&gt;0&lt;/sub&gt; is a fixed point in ''X'' then the union of the space of Busemann functions vanishing at ''x''&lt;sub&gt;0&lt;/sub&gt; and the space of functions ''h''&lt;sub&gt;''y''&lt;/sub&gt;(''x'') = ''d''(''x'',''y'') − ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''y'') is closed under taking uniform limits on bounded sets. This result can be formalised in the notion of '''bordification''' of ''X''.&lt;ref&gt;{{harvnb|Bridson|Haefliger|1999|pages=260–276}}&lt;/ref&gt; In this topology, the points ''x''&lt;sub&gt;''n''&lt;/sub&gt; tend to a geodesic ray γ starting at ''x''&lt;sub&gt;0&lt;/sub&gt; if and only if ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;) tends to ∞ and for ''t''  &gt; 0 arbitrarily large the sequence obtained by taking the point on each segment [''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;] at a distance ''t'' from ''x''&lt;sub&gt;0&lt;/sub&gt; tends to γ(''t'').

If ''X'' is a metric space, Gromov's bordification can be defined as follows. Fix a point ''x''&lt;sub&gt;0&lt;/sub&gt; in ''X'' and let ''X''&lt;sub&gt;''N''&lt;/sub&gt; = {{overline|''B''}}(''x''&lt;sub&gt;0&lt;/sub&gt;,''N''). Let ''Y'' = ''C''(''X'') be the space of Lipschitz continuous functions on ''X'', .e. those for which |''f''(''x'')  – ''f''(''y'')| ≤ ''A'' ''d''(''x'',''y'') for some constant ''A'' &gt; 0. The space ''Y'' can be topologised by the seminorms ||''f''||&lt;sub&gt;''N''&lt;/sub&gt; = sup&lt;sub&gt;''X''&lt;sub&gt;''N''&lt;/sub&gt;&lt;/sub&gt; |''f''|, the topology of uniform convergence on bounded sets. The seminorms are finite by the Lipschitz conditions. This is the topology induced by the natural map of ''C''(''X'') into the direct product of the Banach spaces ''C''&lt;sub&gt;''b''&lt;/sub&gt;(''X''&lt;sub&gt;''N''&lt;/sub&gt;) of continuous bounded functions on ''X''&lt;sub&gt;''N''&lt;/sub&gt;. It is give by the metric ''D''(''f'',''g'') = ∑ 2&lt;sup&gt;−''N''&lt;/sup&gt; ||''f'' − ''g''||&lt;sub&gt;''N''&lt;/sub&gt;(1 +||''f'' − ''g''||&lt;sub&gt;''N''&lt;/sub&gt;)&lt;sup&gt;−1&lt;/sup&gt;.

The space ''X'' is embedded into ''Y'' by sending ''x'' to the function ''f''&lt;sub&gt;''x''&lt;/sub&gt;(''y'') = ''d''(''y'',''x'') – ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''). Let {{overline|''X''}} be the closure of ''X'' in ''Y''. Then {{overline|''X''}} is metrisable, since ''Y'' is, and contains ''X'' as an open subset; moreover bordifications arising from different choices of basepoint are naturally homeomorphic.  Let ''h''(''x'') = (''d''(''x'',''x''&lt;sub&gt;0&lt;/sub&gt;) + 1)&lt;sup&gt;−1&lt;/sup&gt;. Then ''h'' lies in ''C''&lt;sub&gt;0&lt;/sub&gt;(''X''). It is non-zero on ''X'' and vanishes only at ∞. Hence it extends to a continuous function on {{overline|''X''}} with zero set  {{overline|''X''}} \ ''X''. It follows that {{overline|''X''}} \ ''X'' is closed in {{overline|''X''}}, as required. To check that {{overline|''X''}} = {{overline|''X''}}(''x''&lt;sub&gt;0&lt;/sub&gt;) is independent of the basepoint, it suffices to show that ''k''(''x'') = ''d''(''x'',''x''&lt;sub&gt;0&lt;/sub&gt;) − ''d''(''x'',''x''&lt;sub&gt;1&lt;/sub&gt;) extends to a continuous function on {{overline|''X''}}. But ''k''(''x'') = ''f''&lt;sub&gt;''x''&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;), so, for ''g'' in {{overline|''X''}}, ''k''(''g'') = ''g''(''x''&lt;sub&gt;1&lt;/sub&gt;). Hence the correspondence between the compactifications for ''x''&lt;sub&gt;0&lt;/sub&gt; and ''x''&lt;sub&gt;1&lt;/sub&gt; is given by sending ''g'' in {{overline|''X''}}(''x''&lt;sub&gt;0&lt;/sub&gt;) to ''g'' + ''g''(''x''&lt;sub&gt;1&lt;/sub&gt;)1 in {{overline|''X''}}(''x''&lt;sub&gt;1&lt;/sub&gt;).

When ''X'' is a Hadamard space, Gromov's ideal boundary ∂''X'' = {{overline|''X''}} \ ''X'' can be realised explicitly as "asymptotic limits" of geodesic rays using Busemann functions. In fact if ''x''&lt;sub&gt;''n''&lt;/sub&gt; is an unbounded sequence in ''X'' with ''h''&lt;sub&gt;''n''&lt;/sub&gt;(''x'') = ''d''(''x'',''x''&lt;sub&gt;''n''&lt;/sub&gt;) − ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;,''x''&lt;sub&gt;0&lt;/sub&gt;)  tending to ''h'' in ''Y'', then ''h'' vanishes at ''x''&lt;sub&gt;0&lt;/sub&gt;, is convex, Lipschitz with Lipschitz constant 1 and has minimum ''h''(''y'') − ''r'' on any closed ball {{overline|''B''}}(''y'',''r''). Hence ''h'' is a Busemann function ''B''&lt;sub&gt;γ&lt;/sub&gt; corresponding to a unique geodesic ray γ starting at ''x''&lt;sub&gt;0&lt;/sub&gt;.

On the other hand, ''h''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''B''&lt;sub&gt;γ&lt;/sub&gt; uniformly on bounded sets if and only if  ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;) tends to ∞ and for ''t''  &gt; 0 arbitrarily large the sequence obtained by taking the point on each segment [''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;] at a distance ''t'' from ''x''&lt;sub&gt;0&lt;/sub&gt; tends to γ(''t''). In fact for ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;) ≥ ''t'', let ''x''&lt;sub&gt;''n''&lt;/sub&gt;(''t'') be the point in [''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;] with ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;(''t'')) = ''t''. Suppose first that ''h''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''B''&lt;sub&gt;γ&lt;/sub&gt; uniformly on {{overline|''B''}}(''x''&lt;sub&gt;0&lt;/sub&gt;,''R''). Then for ''t'' ≤ ''R'',
|''h''&lt;sub&gt;''n''&lt;/sub&gt;(γ(''t'')) – ''B''&lt;sub&gt;γ&lt;/sub&gt;(γ(''t''))|=''d''(γ(''t''),''x''&lt;sub&gt;''n''&lt;/sub&gt;) – ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;,''x''&lt;sub&gt;0&lt;/sub&gt;) + ''t''. This is a convex function. It vanishes as ''t'' = 0 and hence is increasing. So it is maximised at ''t'' = ''R''. So for each ''t'', |''d''(γ(''t''),''x''&lt;sub&gt;''n''&lt;/sub&gt;) – ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;,''x''&lt;sub&gt;0&lt;/sub&gt;) – ''t''| tends towards 0. Let ''a'' = ''X''&lt;sub&gt;0&lt;/sub&gt;, ''b'' = γ(''t'') and ''c'' = ''x''&lt;sub&gt;''n''&lt;/sub&gt;. Then ''d''(''c'',''a'') – ''d''(''c'',''b'') is close to ''d''(''a'',''b'') with ''d''(''c'',''a'') large. Hence in the Euclidean comparison triangle ''CA'' - ''CB'' is close to ''AB'' with ''CA'' large. So the angle at ''A'' is small. So the point ''D'' on ''AC'' at the same distance as ''AB'' lies close to ''B''. Hence, by the first comparison theorem for geodesic triangles, ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;(''t''),γ(''t'')) is small. Conversely suppose that for fixed ''t'' and ''n'' sufficiently large ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;(''t''),γ(''t'')) tends to 0. Then from the above  ''F''&lt;sub&gt;''s''&lt;/sub&gt;(''y'') = ''d''(''y'',γ(''s'')) – ''s'' satisfies

:&lt;math&gt;|F_s(y) - B_\gamma(y)| \le {d(x_0,y)^2\over 2s},&lt;/math&gt;

so it suffices show that on any bounded set ''h''&lt;sub&gt;''n''&lt;/sub&gt;(''y'') = ''d''(''y'',''x''&lt;sub&gt;''n''&lt;/sub&gt;) – ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;''n''&lt;/sub&gt;) is uniformly close to ''F''&lt;sub&gt;''s''&lt;/sub&gt;(''y'') for ''n'' sufficiently large.&lt;ref&gt;{{harvnb|Ballmann|1995|pages=27–30}}&lt;/ref&gt;

For a fixed ball {{overline|''B''}}(''x''&lt;sub&gt;0&lt;/sub&gt;,''R''), fix ''s'' so that ''R''&lt;sup&gt;2&lt;/sup&gt;/''s'' ≤ ε.  The claim is then an immediate consequence of the inequality for geodesic segments in a Hadamard space, since

:&lt;math&gt;|d(y,x_n) -d(y,x_0) - d(y,x_n(s)) + s |\le  {d(x_0,y)^2\over s} \le \varepsilon.&lt;/math&gt;

Hence, if ''y'' in {{overline|''B''}}(''x''&lt;sub&gt;0&lt;/sub&gt;,''R'') and ''n'' is sufficiently large that ''d''(''x''&lt;sub&gt;''n''&lt;/sub&gt;(''s''),γ(''s'')) ≤ ε, then

:&lt;math&gt;|h_n(y)-B_\gamma(y)|=|d(y,x_n) -d(y,x_0) - B_\gamma(y)| \le |d(y,x_n) -d(y,x_0) - d(y,x_n(s)) + s | + d(x_n(s),\gamma(s)) + |F_s(y) - B_\gamma(y)| \le 3\varepsilon.&lt;/math&gt;

== Busemann functions on a Hadamard manifold ==

Suppose that ''x'', ''y''  are points in a Hadamard manifold and let ''γ''(''s'') be the geodesic through ''x'' with ''γ''(0) = ''y''. This geodesic cuts the boundary of the closed ball {{overline|''B''}}(''y'',''r'') at the two points γ(±''r''). Thus if ''d''(''x'',''y'') &gt; ''r'', there are points ''u'', ''v'' with ''d''(''y'',''u'') = ''d''(''y'',''v'') = ''r'' such that |''d''(''x'',''u'') − ''d''(''x'',''v'')| = 2''r''. By continuity this condition persists for Busemann functions:

*'''''If h is a Busemann function on a Hadamard manifold, then, given y in X and r &gt; 0, there are unique points u, v with d(y,u) = d(y,v) = r such that h(u) = h(y) + r and  h(v) =  h(y) − r. For fixed ''r'' &gt; 0, the points ''u'' and ''v'' depend continuously on ''y''.&lt;ref name="BGS"/&gt;

In fact taking a sequence ''t''&lt;sub&gt;''n''&lt;/sub&gt; tending to ∞ and ''h''&lt;sub&gt;''n''&lt;/sub&gt; = ''F''&lt;sub&gt;''t''&lt;sub&gt;''n''&lt;/sub&gt;&lt;/sub&gt;, there are points ''u''&lt;sub&gt;''n''&lt;/sub&gt; and ''v''&lt;sub&gt;''n''&lt;/sub&gt; which satisfy these conditions for ''h''&lt;sub&gt;''n''&lt;/sub&gt; for ''n'' sufficiently large. Passing to a subsequence if necessary, it can be assumed that ''u''&lt;sub&gt;''n''&lt;/sub&gt; and ''v''&lt;sub&gt;''n''&lt;/sub&gt; tend to ''u'' and ''v''. By continuity these points satisfy the conditions for ''h''. To prove uniqueness, note that by compactness ''h'' assumes its maximum and minimum on {{overline|''B''}}(''y'',''r''). The Lipschitz condition shows that the values of ''h'' there differ by at most 2''r''. Hence ''h'' is minimized at ''v'' and maximized at ''u''. On the other hand, ''d''(''u'',''v'') = 2''r'' and for ''u'' and ''v'' the points ''v'' and ''u'' are the unique points in {{overline|''B''}}(''y'',''r'') maximizing this distance. The Lipschitz condition on ''h'' then immediately implies ''u'' and ''v'' must be the unique points in {{overline|''B''}}(''y'',''r'') maximizing and minimizing ''h''. Now suppose that ''y''&lt;sub&gt;''n''&lt;/sub&gt; tends to ''y''. Then the corresponding points ''u''&lt;sub&gt;''n''&lt;/sub&gt; and ''v''&lt;sub&gt;''n''&lt;/sub&gt; lie in a closed ball so admit convergent subsequences. But by uniqueness of ''u'' and ''v'' any such subsequences must tend to ''u'' and ''v'', so that ''u''&lt;sub&gt;''n''&lt;/sub&gt; and ''v''&lt;sub&gt;''n''&lt;/sub&gt;
must tend to ''u'' and ''v'', establishing continuity.

The above result holds more generally in a Hadamard space.&lt;ref&gt;{{harvnb|Bridson|haefliger|1999|pages=271–272}}&lt;/ref&gt;

*'''''If h is a Busemann function on a Hadamard manifold, then h is continuously differentiable with ||dh(y)|| = 1 for all y.'''''&lt;ref name="BGS"/&gt;

From the previous properties of ''h'', for each ''y'' there is a unique geodesic γ(''t'') parametrised by arclength with γ(0) = ''y'' such that  {{math|1=''h'' ∘ γ(''t'') = ''h''(''y'') + ''t''}}. It has the property that it cuts ∂''B''(''y'',''r'') at ''t'' = ±''r'': in the previous notation γ(''r'') = ''u'' and  γ(–''r'') = ''v''. The vector field ''V''&lt;sub&gt;''h''&lt;/sub&gt; defined by the unit vector &lt;math&gt;\dot{\gamma}(0)&lt;/math&gt; at ''y'' is continuous, because ''u'' is a continuous function of ''y'' and the map  sending (''x'',''v'')  to (''x'',exp&lt;sub&gt;''x''&lt;/sub&gt; ''v'') is a diffeomorphism from ''TX'' onto ''X'' × ''X'' by the [[Cartan-Hadamard theorem]]. Let δ(''s'') be another geodesic parametrised by arclength through ''y'' with δ(0) = ''y''. Then ''dh'' ∘ δ  (0)/ ''ds'' = &lt;math&gt;(\dot{\delta}(0),\dot{\gamma}(0))&lt;/math&gt;. Indeed, let ''H''(''x'') = ''h''(''x'') − ''h''(''y''), so that ''H''(''y'') = 0. Then

:&lt;math&gt; |H(\delta(s)) - H(x)| \le d(\delta(s),x).&lt;/math&gt;

Applying this with ''x'' = ''u'' and ''v'', it follows that for ''s'' &gt; 0

:&lt;math&gt;(r- d(\delta(s),u))/s \le (h(\delta(s)) - h(y))/s \le (d(\delta(s),v) -r)/s.&lt;/math&gt;

The outer terms tend to &lt;math&gt;(\dot{\delta}(0),\dot{\gamma}(0))&lt;/math&gt; as ''s'' tends to 0, so the middle term has the same limit, as claimed. A similar argument applies for ''s'' &lt; 0.

The assertion on the outer terms follows from the first variation formula for arclength, but can be deduced directly as follows. Let 
&lt;math&gt;a=\dot{\delta}(0)&lt;/math&gt; and &lt;math&gt;b=\dot{\gamma}(0)&lt;/math&gt;, both unit vectors. Then for tangent vectors ''p'' and ''q'' at ''y'' in the unit ball&lt;ref&gt;In [[geodesic normal coordinates]], the metric ''g''(''x'') = I + ε ||''x''||. By geodesic convexity, a geodesic from ''p'' to ''q'' lies in the ball of radius ''r'' = max ||''p''||, ||''q''||. The straight line segment gives an upper estimate for ''d''(''p'',''q'') of the stated form. To obtain a similar lower estimate, observe that if ''c''(''t'') is a smooth path from ''p'' to ''q'', then ''L''(''c'') ≥  (1 − ε ''r'') ⋅ ∫ || ''c'  ''|| ''dt'' ≥  (1 − ε ''r'') ⋅ ||''p'' − ''q''||. (Note that these inequalities can be improved using the sharper estimate ''g''(''x'') = I + ε ||''x''||&lt;sup&gt;2&lt;/sup&gt;.)&lt;/ref&gt;

:&lt;math&gt;d(\exp_y p,\exp_y q) = \|p-q\| + \varepsilon \max \|p\|^2, \|q\|^2&lt;/math&gt;
 
with ε uniformly bounded. Let ''s'' = ''t''&lt;sup&gt;3&lt;/sup&gt; and ''r'' = ''t''&lt;sup&gt;2&lt;/sup&gt;. Then

:&lt;math&gt;(d(\delta(s),v) -r)/s= (d(\exp_y(t^3 a),\exp_y(-t^2 b)) - t^2)/t^3 = (\|t^3a +t^2b\| - t^2)/t^3 + \varepsilon |t|= (\|ta +b\| -1)/t + \varepsilon |t|.&lt;/math&gt;

The right hand side here tends to (''a'',''b'') as ''t'' tends to 0 since

:&lt;math&gt; {d\over dt} \|b + t a\||_{t=0 }= {1\over 2} \,{d\over dt} \|b + t a\|^2|_{t=0} = (a,b).&lt;/math&gt;

The same method works for the other terms.

Hence it follows that ''h'' is a C&lt;sup&gt;1&lt;/sup&gt; function with ''dh'' dual to the vector field ''V''&lt;sub&gt;''h''&lt;/sub&gt;, so that ||''dh''(''y'')|| = 1.  The vector field ''V''&lt;sub&gt;''h''&lt;/sub&gt; is thus the [[gradient vector field]] for ''h''. The geodesics through any point are the flow lines for the flow α&lt;sub&gt;''t''&lt;/sub&gt; for ''V''&lt;sub&gt;''h''&lt;/sub&gt;, so that α&lt;sub&gt;''t''&lt;/sub&gt; is the [[gradient flow]] for ''h''.

'''THEOREM.''' '''''On a Hadamard manifold X the following conditions on a  continuous function h are equivalent:'''''&lt;ref name="BGS"/&gt;
# '''''h is a Busemann function.'''''
# '''''h is a convex, Lipschitz function with constant 1, and for each y in X there are points u&lt;sub&gt;±&lt;/sub&gt; at a distance r from y such that h(u&lt;sub&gt;±&lt;/sub&gt;) = h(y) ± r.'''''
# '''''h is a convex C&lt;sup&gt;1&lt;/sup&gt; function with ||dh(x)|| ≡ 1.'''''

It has already been proved that (1) implies (2).

The arguments above show ''[[mutatis mutandi]]'' that (2) implies (3).

It therefore remains to show that (3) implies (1). Fix ''x'' in ''X''. Let α&lt;sub&gt;''t''&lt;/sub&gt; be the gradient flow for ''h''. It follows that {{math|1=''h'' ∘ α&lt;sub&gt;''t''&lt;/sub&gt; (''x'') = ''h''(''x'') + ''t''}} and that {{math|1=γ(''t'') = α&lt;sub&gt;''t''&lt;/sub&gt;(''x'')}} is a geodesic through ''x'' parametrised by arclength with {{math|1=γ(0) = ''x''}}. Indeed, if ''s'' &lt; ''t'', then

:&lt;math&gt;|s-t|=|h(\alpha_s(x))-h(\alpha_t(x))| \le d(\alpha_s(x),\alpha_t(x))\le \int_{s}^t \|d\alpha_\tau(x)/d\tau\|  \, d\tau =\int_s^t \|dh(\alpha_\tau(x))\| \, d\tau = |s-t|,&lt;/math&gt;

so that ''d''(γ(''s''),γ(''t'')) = |''s'' − ''t''|. Let ''g''(''y'') = ''h''&lt;sub&gt;γ&lt;/sub&gt;(''y''), the Busemann function for γ with base point ''x''. In particular ''g''(''x'') = 0. To prove (1), it suffices to show that ''g'' = ''h'' – ''h''(''x'')1.

Let ''C''(−''r'') be the closed convex set of points ''z'' with ''h''(''z'') ≤ −''r''. Since ''X'' is a Hadamard space for every point ''y'' in ''X'' there is a unique closest point ''P''&lt;sub&gt;''r''&lt;/sub&gt;(''y'') to ''y'' in ''C''(-''r''). It depends continuously on ''y'' and if ''y'' lies outside ''C''(-''r''), then ''P''&lt;sub&gt;''r''&lt;/sub&gt;(''y'') lies on the hypersurface ''h''(''z'') = − ''r''—the boundary ∂''C''(–''r'') of ''C''(–''r'')—and the geodesic from ''y'' to ''P''&lt;sub&gt;''r''&lt;/sub&gt;(''y'') is orthogonal to ∂''C''(–''r''). In this case the geodesic is just α&lt;sub&gt;''t''&lt;/sub&gt;(''y''). Indeed, the fact that α&lt;sub&gt;''t''&lt;/sub&gt; is the gradient flow of ''h'' and the conditions ||''dh''(''y'')|| ≡ 1 imply that the flow lines  α&lt;sub&gt;''t''&lt;/sub&gt;(''y'') are geodesics parametrised by arclength and cut the level curves of ''h'' orthogonally. Taking ''y'' with ''h''(''y'') = ''h''(''x'') and  ''t'' &gt; 0,

:&lt;math&gt;d(x,y) \ge d(\alpha_t(x),\alpha_t(y)),\,\,\, d(x,\alpha_t(y))^2 \ge d(x,\alpha_t(x))^2+d(\alpha_t(x),\alpha_t(y))^2,\,\,\,d(y,\alpha_t(x))^2 \ge d(y,\alpha_t(y))^2+d(\alpha_t(x),\alpha_t(y))^2.&lt;/math&gt;

On the other hand, for any four points ''a'', ''b'', ''c'', ''d'' in a Hadamard space, the following quadrilateral inequality of [[Yurii Reshetnyak|Reshetnyak]] holds:

:&lt;math&gt; |d(a,c)^2 + d(b,d)^2 - d(a,d)^2 - d(b,d)^2|\le 2 d(a,b)d(c,d).&lt;/math&gt;

Setting ''a'' = ''x'', ''b'' = ''y'', ''c'' = α&lt;sub&gt;''t''&lt;/sub&gt;(''x''), ''d'' =  α&lt;sub&gt;''t''&lt;/sub&gt;(''y''), it follows that

:&lt;math&gt;|d(y,\alpha_t(x))^2 - d(x,\alpha_t(x))^2|\le 2d(x,y)^2,&lt;/math&gt;

so that

:&lt;math&gt;|d(y,\alpha_t(x)) - d(x,\alpha_t(x))|\le  2 {d(x,y)^2\over d(y,\alpha_t(x)) + d(x,\alpha_t(x))}\le {d(x,y)^2\over t}.&lt;/math&gt;

Hence ''h''&lt;sub&gt;γ&lt;/sub&gt;(''y'') = 0 on the level surface of ''h'' containing ''x''. The flow α&lt;sub&gt;''s''&lt;/sub&gt; can be used to transport this result to all the level surfaces of ''h''. In fact for general ''y''&lt;sub&gt;1&lt;/sub&gt; take ''s'' such that ''h''(α&lt;sub&gt;''s''&lt;/sub&gt;(''x'')) = ''h''(''y''&lt;sub&gt;1&lt;/sub&gt;) and set ''x''&lt;sub&gt;1&lt;/sub&gt; = α&lt;sub&gt;''s''&lt;/sub&gt;(''x''). Then ''h''&lt;sub&gt;γ&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;(''y''&lt;sub&gt;1&lt;/sub&gt;) = 0, where γ&lt;sub&gt;1&lt;/sub&gt;(''t'') = α&lt;sub&gt;''t''&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;) = γ(''s'' + ''t''). But then ''h''&lt;sub&gt;γ&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt; = ''h''&lt;sub&gt;γ&lt;/sub&gt; – ''s'', so that ''h''&lt;sub&gt;γ&lt;/sub&gt;(''y''&lt;sub&gt;1&lt;/sub&gt;) = ''s''. Hence {{math|1=''g''(''y''&lt;sub&gt;1&lt;/sub&gt;) = ''s'' = ''h''((α&lt;sub&gt;''s''&lt;/sub&gt;(''x'')) – ''h''(''x'') = ''h''(''y''&lt;sub&gt;1&lt;/sub&gt;) – ''h''(''x'')}}, as required.

Note that this argument could be shortened using the fact that two Busemann functions ''h''&lt;sub&gt;γ&lt;/sub&gt; and ''h''&lt;sub&gt;δ&lt;/sub&gt; differ by a constant if and only if the corresponding geodesic rays satisfy sup&lt;sub&gt;''t'' ≥ 0&lt;/sub&gt; ''d''(γ(''t''),δ(''t'')) &lt; ∞. Indeed, all the geodesics defined by the flow α&lt;sub&gt;''t''&lt;/sub&gt; satisfy the latter condition, so differ by constants. Since along any of these geodesics ''h'' is linear with derivative 1, ''h'' must differ from these Busemann functions by constants.

==Compactification of a proper Hadamard space==
{{harvtxt|Eberlein|O'Neill|1973}} defined a compactification of a [[Hadamard manifold]] ''X'' which uses Busemann functions. Their construction, which can be extended more generally to proper (i.e. locally compact) [[Hadamard space]]s, gives an explicit geometric realisation of a compactification defined by Gromov—by adding an "ideal boundary"—for the more general class of [[proper metric space]]s ''X'', those for which every closed ball is compact. Note that, since any Cauchy sequence is contained in a closed ball, any proper metric space is automatically complete.&lt;ref&gt;Note that a metric space ''X''  which is complete and locally compact need not be proper, for example '''R''' with the metric ''d''(''x'',''y'') = |''x'' – ''y''|/(1 + |''x'' – ''y''|). On the other hand, by the [[Hopf-Rinow theorem]] for metric spaces, if ''X'' is complete, locally compact and geodesic—every two points ''x'' and ''y'' are joined by a geodesic parametrised by arclength—then ''X'' is proper (see {{harvnb|Bridson|Haefliger|1999|pages=35–36}}). Indeed if not, there is a point ''x'' in ''X'' and a closed ball ''K'' = {{overline|''B''}}(''x'',''r'') maximal subject to being compact; then, since by hypothesis {{overline|''B''}}(''x'',''R'') is non-compact for each ''R'' &gt; ''r'', a diagonal argument shows that there is a sequence (''x''&lt;sub&gt;''n''&lt;/sub&gt;) with ''d''(''x'',''x''&lt;sub&gt;''n''&lt;/sub&gt;) decreasing to ''r'' but with no convergent subsequence; on the other hand taking ''y''&lt;sub&gt;''n''&lt;/sub&gt; on a geodesic joining ''x'' and ''x''&lt;sub&gt;''n''&lt;/sub&gt;, with ''d''(''x'',''y''&lt;sub&gt;''n''&lt;/sub&gt;) = ''r'', compactness of  ''K'' implies (''y''&lt;sub&gt;''n''&lt;/sub&gt;), and hence (''x''&lt;sub&gt;''n''&lt;/sub&gt;), has a convergent subsequence, a contradiction.&lt;/ref&gt; The ideal boundary is a special case of the ideal boundary for a metric space. In the case of Hadamard spaces, this agrees with the space of geodesic rays emanating from any fixed point described using Busemann functions in the bordification of the space.

If ''X'' is a proper metric space, Gromov's compactification can be defined as follows. Fix a point ''x''&lt;sub&gt;0&lt;/sub&gt; in ''X'' and let ''X''&lt;sub&gt;''N''&lt;/sub&gt; = {{overline|''B''}}(''x''&lt;sub&gt;0&lt;/sub&gt;,''N''). Let ''Y'' = ''C''(''X'') be the space of Lipschitz continuous functions on ''X'', .e. those for which |''f''(''x'')  – ''f''(''y'')| ≤ ''A'' ''d''(''x'',''y'') for some constant ''A'' &gt; 0. The space ''Y'' can be topologised by the seminorms ||''f''||&lt;sub&gt;''N''&lt;/sub&gt; = sup&lt;sub&gt;''X''&lt;sub&gt;''N''&lt;/sub&gt;&lt;/sub&gt; |''f''|, the topology of uniform convergence on compacta. This is the topology induced by the natural map of ''C''(''X'') into the direct product of the Banach spaces ''C''(''X''&lt;sub&gt;''N''&lt;/sub&gt;). It is give by the metric ''D''(''f'',''g'') = ∑ 2&lt;sup&gt;−''N''&lt;/sup&gt; ||''f'' − ''g''||&lt;sub&gt;''N''&lt;/sub&gt;(1 +||''f'' − ''g''||&lt;sub&gt;''N''&lt;/sub&gt;)&lt;sup&gt;−1&lt;/sup&gt;.

The space ''X'' is embedded into ''Y'' by sending ''x'' to the function ''f''&lt;sub&gt;''x''&lt;/sub&gt;(''y'') = ''d''(''y'',''x'') – ''d''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''). Let {{overline|''X''}} be the closure of ''X'' in ''Y''. Then {{overline|''X''}} is compact (metrisable) and contains ''X'' as an open subset; moreover compactifications arising from different choices of basepoint are naturally homeomorphic. Compactness follows from the [[Arzelà–Ascoli theorem]] since the image in ''C''(''X''&lt;sub&gt;''N''&lt;/sub&gt;) is [[equicontinuous]] and uniformly bounded in norm by ''N''. Let ''x''&lt;sub&gt;''n''&lt;/sub&gt; be a sequence in ''X'' ⊂ {{overline|''X''}} tending to ''y'' in {{overline|''X''}} \ ''X''. Then all but finitely many terms must lie outside ''X''&lt;sub&gt;''N''&lt;/sub&gt; since ''X''&lt;sub&gt;''N''&lt;/sub&gt; is compact, so that any subsequence would converge to a point in ''X''&lt;sub&gt;''N''&lt;/sub&gt;; so the sequence ''x''&lt;sub&gt;''n''&lt;/sub&gt; must be unbounded in ''X''. Let ''h''(''x'') = (''d''(''x'',''x''&lt;sub&gt;0&lt;/sub&gt;) + 1)&lt;sup&gt;−1&lt;/sup&gt;. Then ''h'' lies in ''C''&lt;sub&gt;0&lt;/sub&gt;(''X''). It is non-zero on ''X'' and vanishes only at ∞. Hence it extends to a continuous function on {{overline|''X''}} with zero set  {{overline|''X''}} \ ''X''. It follows that {{overline|''X''}} \ ''X'' is closed in {{overline|''X''}}, as required. To check that the compactification  {{overline|''X''}} = {{overline|''X''}}(''x''&lt;sub&gt;0&lt;/sub&gt;) is independent of the basepoint, it suffices to show that ''k''(''x'') = ''d''(''x'',''x''&lt;sub&gt;0&lt;/sub&gt;) − ''d''(''x'',''x''&lt;sub&gt;1&lt;/sub&gt;) extends to a continuous function on {{overline|''X''}}. But ''k''(''x'') = ''f''&lt;sub&gt;''x''&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;), so, for ''g'' in {{overline|''X''}}, ''k''(''g'') = ''g''(''x''&lt;sub&gt;1&lt;/sub&gt;). Hence the correspondence between the compactifications for ''x''&lt;sub&gt;0&lt;/sub&gt; and ''x''&lt;sub&gt;1&lt;/sub&gt; is given by sending ''g'' in {{overline|''X''}}(''x''&lt;sub&gt;0&lt;/sub&gt;) to ''g'' + ''g''(''x''&lt;sub&gt;1&lt;/sub&gt;)1 in {{overline|''X''}}(''x''&lt;sub&gt;1&lt;/sub&gt;).

When ''X'' is a Hadamard manifold (or more generally a proper Hadamard space), Gromov's ideal boundary ∂''X'' = {{overline|''X''}} \ ''X'' can be realised explicitly as "asymptotic limits" of geodesics by using Busemann functions. Fixing a base point ''x''&lt;sub&gt;0&lt;/sub&gt;, there is a unique geodesic γ(''t'') parametrised by arclength such that γ(0) = ''x''&lt;sub&gt;0&lt;/sub&gt; and &lt;math&gt;\dot{\gamma}(0)&lt;/math&gt; is a given unit vector. If ''B''&lt;sub&gt;γ&lt;/sub&gt; is the corresponding Busemann function, then
''B''&lt;sub&gt;γ&lt;/sub&gt; lies in ∂''X''(''x''&lt;sub&gt;0&lt;/sub&gt;) and induces a homeomorphism of the unit (''n'' − 1)-sphere onto  ∂''X''(''x''&lt;sub&gt;0&lt;/sub&gt;), sending &lt;math&gt;\dot{\gamma}(0)&lt;/math&gt; to ''B''&lt;sub&gt;γ&lt;/sub&gt;.

== Quasigeodesics in the Poincaré disk, CAT(-1) and hyperbolic spaces==
===Morse–Mostow lemma===
In the case of spaces of negative curvature, such as the Poincaré disk, CAT(-1) and hyperbolic spaces, there is a metric structure on their Gromov boundary. This structure is preserved by the group of quasi-isometries which carry geodesics rays to quasigeodesic rays. Quasigeodesics were first studied for negatively curved surfaces—in particular the hyperbolic upper halfplane and unit disk—by [[Marston Morse|Morse]] and generalised to negatively curved [[symmetric space]]s by [[George Mostow|Mostow]], for his work on the [[Mostow rigidity theorem|rigidity of discrete groups]]. The basic result is the '''Morse–Mostow lemma''' on the stability of geodesics.&lt;ref name="Bourdon 1995"&gt;{{harvnb|Bourdon|1995}}&lt;/ref&gt;&lt;ref name="Buyalo 2007"&gt;{{harvnb|Buyalo|Schroeder|2007}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Mostow|1073}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Roe|2003}}&lt;/ref&gt;

By definition a '''[[quasigeodesic]]''' Γ defined on an interval [''a'',''b'']  with −∞  ≤ ''a'' &lt; ''b'' ≤ ∞ is a map Γ(''t'') into a metric space, not necessarily continuous, for which there are constants λ ≥ 1 and ε &gt; 0 such that for all ''s'' and ''t'':

:&lt;math&gt;\lambda^{-1} |s-t| - \varepsilon \le d(\Gamma(s),\Gamma(t)) \le \lambda |s-t| + \varepsilon.&lt;/math&gt;

The following result is essentially due to [[Marston Morse]] (1924).

'''Morse's lemma on stability of geodesics.''' In the hyperbolic disk there is a constant ''R'' depending on λ and ε such that any quasigeodesic segment Γ defined on a finite interval [''a'',''b''] is within a [[Hausdorff distance]] ''R'' of the geodesic segment [Γ(''a''),Γ(''b'')].&lt;ref&gt;{{harvnb|Buyalo|Schroeder|2007|pages=1–6}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Bridson|Haefliger|1999|pages=399–405}}&lt;/ref&gt;

===Classical proof for Poincaré disk===

The classical proof of Morse's lemma for the Poincaré unit disk or upper halfplane proceeds more directly by using orthogonal projection onto the geodesic segment.&lt;ref&gt;{{harvnb|Kapovich|2001|pages=51–52}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Morse|1924}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Ratcliffe|2006|pages=580–599}}&lt;/ref&gt;

*It can be assumed that Γ satisfies the stronger "pseudo-geodesic" condition:&lt;ref&gt;{{harvnb|Kapovich|2001|page=51}}&lt;/ref&gt;

::&lt;math&gt;\lambda^{-1}|s-t| -\varepsilon \le d(\Gamma(s),\Gamma(t)) \le \lambda |s-t|.&lt;/math&gt;

:&lt;small&gt;In fact Γ can be replaced by a continuous piecewise geodesic curve Δ with the same endpoints lying at a finite Hausdorff distance from Γ less than ''c'' = (2λ&lt;sup&gt;2&lt;/sup&gt; + 1)ε: in fact break up the interval on which Γ is defined into equal subintervals of length 2λε and take the geodesics between the images under Γ of the endpoints of the subintervals. Since Δ is piecewise geodesic, Δ is Lipschitz continuous with constant λ&lt;sub&gt;1&lt;/sub&gt;, ''d''(Δ(''s''),Δ(''t'')) ≤ λ&lt;sub&gt;1&lt;/sub&gt;|''s'' – ''t''|, where  λ&lt;sub&gt;1&lt;/sub&gt; ≤ λ + ε. The lower bound is automatic at the endpoints of intervals. By construction the other values differ from these by a uniformly bounded depending only on λ and ε; the lower bound inequality holds by increasing ε by adding on twice this uniform bound.&lt;/small&gt;

*If γ  is a piecewise smooth curve segment lying outside an ''s''-neighbourhood of a geodesic line and ''P'' is the orthogonal projection onto the geodesic line then:&lt;ref&gt;{{harvnb|Ratcliffe|2006|page=583}}, Lemma 4&lt;/ref&gt;

::&lt;math&gt;\ell(P \circ \gamma) \le {\ell(\gamma)\over \cosh s}.&lt;/math&gt;

:&lt;small&gt;In fact applying an isometry in the upper half plane it may be assumed that the geodesic line is the positive imaginary axis in which case the orthogonal projection onto it is given by ''P''(''z'') = ''i''|''z''| and |''z''| / Im z = cosh ''d''(''z'',''Pz''). Hence the hypothesis implies |γ(''t'')| ≥ cosh(''s'') Im γ(''t''), so that

::&lt;math&gt; \ell(P\circ\gamma) =  \int_a^b {|d\gamma|\over |\gamma|} \le \int_a^b {|d\gamma|\over \cosh(s)\, \Im \gamma}={\ell(\gamma)\over \cosh(s)}.&lt;/math&gt; &lt;/small&gt;

*There is a constant ''h'' &gt; 0 depending only on λ and ε such that  Γ[''a'',''b''] lies within an ''h''-neighbourhood of the geodesic segment [Γ(''a''),Γ(''b'')].&lt;ref&gt;{{harvnb|Ratcliffe|2006|pages=584–586}}, Lemmas 5–6&lt;/ref&gt;

:&lt;small&gt;Let γ(''t'') be the geodesic line containing the geodesic segment [Γ(''a''),Γ(''b'')]. Then there is a constant ''h'' &gt; 0 depending only on λ and ε such that  ''h''-neighbourhood Γ[''a'',''b''] lies within an ''h''-neighbourhood of γ('''R'''). Indeed for any ''s'' &gt; 0, the subset of [''a'',''b''] for which Γ(''t'') lies outside the closure of the ''s''-neighbourhood of γ('''R''') is open, so a countable union of open intervals (''c'',''d''). Then

::&lt;math&gt;\ell(\Gamma|_{[c,d]}) \le s_1 \equiv \lambda^2 (2s +\varepsilon) \left(1 -{\lambda^2\over \cosh(s)}\right),&lt;/math&gt;

:since the left hand side is less than or equal to λ|''c'' – ''d''| and

::&lt;math&gt;{|c-d|\over \lambda} -\varepsilon \le d(\Gamma(c),\Gamma(d)) \le 2s + d(P \circ \Gamma|_{[c,d]}) \le 2s + {\lambda |c-d|\over\cosh(s)}.&lt;/math&gt;

:Hence every point lies at a distance less than or equal to ''s'' + ''s''&lt;sub&gt;1&lt;/sub&gt;  of γ('''R'''). To deduce the assertion, note that the subset of [''a'',''b''] for which Γ(''t'') lies outside the closure of the ''s''-neighbourhood of [Γ(''a''),Γ(''b'')] ⊂ γ('''R''') is open, so a union of intervals (''c'',''d'') with Γ(''c'') and Γ(''d'') both at a distance ''s'' + ''s''&lt;sub&gt;1&lt;/sub&gt; from either Γ(''a'') or Γ(''b''). Then

::&lt;math&gt;\ell(\Gamma|_{[c,d]}) \le s_2 \equiv \lambda^2(2(s + s_1) + \varepsilon),&lt;/math&gt;

:since

::&lt;math&gt;{|c-d|\over \lambda} -\varepsilon \le d(\Gamma(c),\Gamma(d)) \le 2(s+s_1).&lt;/math&gt;

:Hence the assertion follows taking any ''h'' greater than ''s'' +''s''&lt;sub&gt;1&lt;/sub&gt; + ''s''&lt;sub&gt;2&lt;/sub&gt;.&lt;/small&gt;

*There is a constant ''h'' &gt; 0 depending only on λ and ε such that the geodesic segment [Γ(''a''),Γ(''b'')] lies within an ''h''-neighbourhood of Γ[''a'',''b''].&lt;ref&gt;{{harvnb|Kapovich|2001|page=52}}&lt;/ref&gt;

:&lt;small&gt;In fact, every point of Γ[''a'',''b''] lies within a distance ''h'' of [Γ(''a''),Γ(''b'')]. Thus orthogonal projection ''P'' carries each point of Γ[''a'',''b''] onto a point in the closed convex set [Γ(''a''),Γ(''b'')] at a distance less than ''h''. Since ''P'' is continuous and Γ[''a'',''b''] connected, the map ''P'' must be onto since the image contains the endpoints of  [Γ(''a''),Γ(''b'')]. But then every point of [Γ(''a''),Γ(''b'')] is within a distance ''h'' of a point of Γ[''a'',''b''].&lt;/small&gt;

===Gromov's proof for Poincaré disk ===
The generalisation of Morse's lemma to CAT(-1) spaces is often referred to as the Morse–Mostow lemma and can be proved by a straightforward generalisation of the classical proof. There is also a generalisation for the more general class of [[hyperbolic metric space]]s due to Gromov. Gromov's proof is given below for the Poincaré unit disk; the properties of hyperbolic metric spaces are developed in the course of the proof, so that it applies [[mutatis mutandi]] to CAT(-1) or hyperbolic metric spaces.&lt;ref name="Bourdon 1995"/&gt;&lt;ref name="Buyalo 2007"/&gt;

:&lt;small&gt;In fact since this is a large scale phenomenon, it is enough to check that any maps Δ from {0, 1, 2, ..., ''N''} for any ''N'' &gt; 0 to the disk satisfying the inequalities is within a Hausdorff distance ''R''&lt;sub&gt;1&lt;/sub&gt; of the geodesic segment [Δ(0),Δ(''N'')]. For then translating it may be assumed without loss of generality Γ is defined on [0,''r''] with ''r'' &gt; 1 and then, taking ''N'' = [''r''] (the integer part of ''r''), the result can be applied to Δ defined by Δ(''i'') = Γ(''i''). The Hausdorff distance between the images of Γ and Δ is evidently bounded by a constant ''R''&lt;sub&gt;2&lt;/sub&gt; depending only on λ and ε.

:Now the [[incircle]] of a geodesic triangle has diameter less than δ where δ = 2 log 3; indeed it is strictly maximised by that of an ideal triangle where it equals 2 log 3. In particular, since the incircle breaks the triangle breaks the triangle into three isosceles triangles with the third side opposite the vertex of the original triangle having length less than δ, it follows that every side of a geodesic triangle is contained in a δ-neighbourhood of the other two sides. A simple induction argument shows that a geodesic polygon with 2&lt;sup&gt;''k''&lt;/sup&gt; + 2 vertices for ''k'' ≥ 0 has each side within a {{math|1=(''k'' + 1)δ}} neighbourhood of the other sides (such a polygon is made by combining two geodesic polygons with {{math|1=2&lt;sup&gt;''k''−1&lt;/sup&gt; + 1}} sides along a common side). Hence if {{math|1=''M'' ≤ 2&lt;sup&gt;''k''&lt;/sup&gt; + 2}}, the same estimate holds for a polygon with ''M'' sides.

:For ''y''&lt;sub&gt;''i''&lt;/sub&gt; = Δ(''i'') let ''f''(''x'') = min ''d''(''x'',''y''&lt;sub&gt;''i''&lt;/sub&gt;), the largest radius for a closed ball centred on ''x'' which contains no ''y''&lt;sub&gt;''i''&lt;/sub&gt; in its interior. This is a continuous function non-zero on [Δ(0),Δ(''N'')] so attains its maximum ''h'' at some point ''x'' in this segment. Then [Δ(0),Δ(''N'')] lies within an ''h''&lt;sub&gt;1&lt;/sub&gt;-neighbourhood of the image of Δ for any ''h''&lt;sub&gt;1&lt;/sub&gt; &gt; ''h''. It therefore suffices to find an upper bound for ''h'' independent of ''N''.

:Choose ''y'' and ''z'' in the segment [Δ(0),Δ(''N'')] before and after ''x'' with ''d''(''x'',''y'') = 2''h'' and ''d''(''x'',''z'') = 2''h'' (or an endpoint if it within a distance of less than 2''h'' from ''x''). Then there are ''i'', ''j'' with ''d''(''y'',Δ(''i'')), ''d''(''z'',Δ(''j'')) ≤ ''h''. Hence ''d''(Δ(''i''),Δ(''j'')) ≤ 6''h'', so that |''i'' − ''j''| ≤ 6λ''h'' + λε. By the triangle inequality all points on the segments [''y'',Δ(''i'')] and [''z'',Δ(''j'')] are at a distance ≥ ''h'' from ''x''. Thus there is a finite sequence of points starting at ''y'' and ending at ''z'', lying first on the segment [''y'',Δ(''i'')], then proceeding through the points Δ(''i''), Δ(''i''+1), ..., Δ(''j''), before taking the segment [Δ(''j''),''z'']. The successive points Δ(''i''), Δ(''i''+1), ..., Δ(''j'') are separated by a distance no greater than λ + ε and successive points on the geodesic segments can also be chosen to satisfy this condition. The minimum number ''K'' of points in such a sequence satisfies ''K'' ≤ |''i'' - ''j''| + 3 + 2(λ + ε)&lt;sup&gt;–1&lt;/sup&gt;''h''. These points form a geodesic polygon, with [''y'',''z''] as one of the sides. Take ''L'' = [''h''/δ], so that the (''L'' − 1)δ-neighbourhood of [''y'',''z''] does not contain all the other sides of the polygon. Hence, from the result above, it follows that ''K'' &gt; 2&lt;sup&gt;''L'' − 1&lt;/sup&gt; + 2. Hence

:&lt;math&gt;3 + 2(\lambda+\varepsilon)^{-1}h + 6\lambda h + \varepsilon&gt; 2^{h/\delta} + 2.&lt;/math&gt;

:This inequality implies that ''h'' is uniformly bounded, independently of ''N'', as claimed.

:If all points Δ(''i'') lie within ''h''&lt;sub&gt;1&lt;/sub&gt; of the [Δ(0),Δ(''N'')], the result follows. Otherwise the points which do not fall into maximal subsets ''S'' = {''r'', ..., ''s''} with ''r'' &lt; ''s''. Thus points in [Δ(0),Δ(''N'')] have a point  Δ(''i'') with ''i''  in the complement of ''S'' within a distance of ''h''&lt;sub&gt;1&lt;/sub&gt;. But the complement of ''S'' = ''S''&lt;sub&gt;1&lt;/sub&gt;  ∐  ''S''&lt;sub&gt;2&lt;/sub&gt;, a disjoint union with ''S''&lt;sub&gt;1&lt;/sub&gt; = {0, ..., ''r'' − 1} and ''S''&lt;sub&gt;2&lt;/sub&gt; = {''s'' + 1, ..., ''N''}. [[connected space|Connectivity]] of [Δ(0),Δ(''N'')] implies there is a point ''x'' in the segment which is within a distance ''h''&lt;sub&gt;1&lt;/sub&gt; of points Δ(''i'') and Δ(''j'') with ''i'' &lt; ''r'' and ''j'' &gt; ''s''. But then ''d''(Δ(''i''),Δ(''j'')) &lt; 2 ''h''&lt;sub&gt;1&lt;/sub&gt;, so |''i'' − ''j''| ≤ 2λ''h''&lt;sub&gt;1&lt;/sub&gt; + λε. Hence the points Δ(''k'') for ''k'' in ''S'' lie within a distance from  [Δ(0),Δ(''N'')] of less than ''h''&lt;sub&gt;1&lt;/sub&gt; + λ|''i'' − ''j''| + ε ≤ ''h''&lt;sub&gt;1&lt;/sub&gt; + λ (2λ''h''&lt;sub&gt;1&lt;/sub&gt; + λε) + ε ≡ ''h''&lt;sub&gt;2&lt;/sub&gt;.&lt;/small&gt;

===Extension to quasigeodesic rays and lines===
Recall that in a Hadamard space if [''a''&lt;sub&gt;1&lt;/sub&gt;,''b''&lt;sub&gt;1&lt;/sub&gt;] and [''a''&lt;sub&gt;2&lt;/sub&gt;,''b''&lt;sub&gt;2&lt;/sub&gt;] are two geodesic segments and the intermediate points ''c''&lt;sub&gt;1&lt;/sub&gt;(''t'') and ''c''&lt;sub&gt;2&lt;/sub&gt;(''t'') divide them in the ratio ''t'':(1 – ''t''), then ''d''(''c''&lt;sub&gt;1&lt;/sub&gt;(''t''),''c''&lt;sub&gt;2&lt;/sub&gt;(''t'')) is a convex function of ''t''. In particular if Γ&lt;sub&gt;1&lt;/sub&gt;(''t'') and  Γ&lt;sub&gt;2&lt;/sub&gt;(''t'') are geodesic segments of unit speed defined on [0,''R''] starting at the same point then

:&lt;math&gt;d(\Gamma_1(t),\Gamma_2(t)) \le {t\over R} d(\Gamma_1(R),\Gamma_2(R)).&lt;/math&gt;

In particular this implies the following:

*'''''In a CAT(–1) space ''X'', there is a constant  h &gt; 0 depending only on λ and ε such that any quasi-geodesic ray is within a bounded Hausdorff distance h of a geodesic ray. A similar result holds for quasigeodesic and geodesic lines.'''''

:&lt;small&gt;In fact if Γ(''t'') is a geodesic say with constant λ and ε, let Γ&lt;sub&gt;''N''&lt;/sub&gt;(''t'') be the unit speed geodesic for the segment [Γ(0),Γ(''N'')]. The estimate above shows that for fixed ''R'' &gt; 0 and ''N'' sufficiently large, (Γ&lt;sub&gt;''N''&lt;/sub&gt;) is a Cauchy sequence in ''C''([0,''R''],''X'') with the uniform metric. Thus Γ&lt;sub&gt;''N''&lt;/sub&gt; tends to a geodesic ray γ uniformly on compacta the bound on the Hausdorff distances between Γ and the segments Γ&lt;sub&gt;''N''&lt;/sub&gt; applies also to the limiting geodesic γ. The assertion for quasigeodesic lines follows by taking Γ&lt;sub&gt;''N''&lt;/sub&gt; corresponding to the geodesic segment [Γ(–''N''),Γ(''N'')]. &lt;/small&gt;

== Efremovich–Tikhomirova theorem ==
Before discussing CAT(-1) spaces, this section will describe the '''Efremovich–Tikhomirova theorem''' for the unit disk ''D'' with the Poincaré metric. It asserts that quasi-isometries of ''D'' extend to quasi-Möbius homeomorphisms of the unit disk with the Euclidean metric. The theorem forms the prototype for the more general theory of CAT(-1) spaces. Their original theorem was proved in a slightly less general and less precise form in {{harvtxt|Efremovich|Tikhomirova|1964}} and applied to bi-Lipschitz homeomorphisms of the unit disk for the Poincaré metric;&lt;ref&gt;Bi-Lipschitz homeomorphisms are those for which they and their inverses are Lipschitz continuous&lt;/ref&gt; earlier, in the posthumous paper {{harvtxt|Mori|1957}}, the Japanese mathematician Akira Mori had proved a related result within [[Teichmüller theory]] assuring that every [[quasiconformal mapping|quasiconformal homeomorphism]] of the disk is [[Hölder continuous]] and therefore extends continuously to a homeomorphism of the unit circle (it is known that this extension is quasi-Möbius).&lt;ref&gt;See:
*{{harvnb|Ahlfors|1966}}
*{{harvnb|Lehto|1987}}
&lt;/ref&gt;

===Extension of quasi-isometries to boundary ===
If ''X'' is the Poincaré unit disk, or more generally a CAT(-1) space, the Morse lemma on stability of quasigeodesics implies that every quasi-isometry of ''X'' extends uniquely to the boundary. By definition two self-mappings ''f'', ''g'' of ''X'' are quasi-equivalent if sup&lt;sub&gt;''X''&lt;/sub&gt; ''d''(''f''(''x''),''g''(''x'')) &lt; ∞, so that corresponding points are at a uniformly bounded distance of each other. A quasi-isometry ''f''&lt;sub&gt;1&lt;/sub&gt; of ''X'' is a self-mapping of ''X'', not necessarily continuous, which has a quasi-inverse ''f''&lt;sub&gt;2&lt;/sub&gt; such that ''f''&lt;sub&gt;1&lt;/sub&gt; ∘ ''f''&lt;sub&gt;2&lt;/sub&gt; and ''f''&lt;sub&gt;2&lt;/sub&gt; ∘ ''f''&lt;sub&gt;1&lt;/sub&gt; are quasi-equivalent to he identity and such that there are constants λ ≥ 1 and ε &gt; 0 such that for all ''x'', ''y'' in ''X'' and both mappings

:&lt;math&gt; \lambda^{-1} d(x,y) - \varepsilon \le d(f_k(x),f_k(y)) \le \lambda d(x,y) +\varepsilon.&lt;/math&gt;

Note that quasi-inverses are unique up to quasi-equivalence; that equivalent definition could be given using possibly different right and left-quasi inverses, but they would necessarily be quasi-equivalent; that quasi-isometries are closed under composition which up to quasi-equivalence depends only the quasi-equivalence classes; and that, modulo quasi-equivalence, the quasi-isometries form a group.&lt;ref&gt;See:
*{{harvnb|Bourdon|1995}}
*{{harvnb|Bridson|Haefliger|1999}}
*{{harvnb|Roe|2003}}
*{{harvnb|Buyalo|Schroeder|2007}}
*{{harvnb|Bourdon|2009}}
&lt;/ref&gt;

Fixing a point ''x'' in ''X'', given a geodesic ray γ starting at ''x'', the image ''f'' ∘ γ under a quasi-isometry ''f'' is a quasi-geodesic ray. By the Morse-Mostow lemma it is within a bounded distance of a unique geodesic ray δ starting at ''x''. This defines a mapping ∂''f'' on the boundary ∂''X'' of ''X'', independent of the quasi-equivalence class of ''f'', such that ∂(''f'' ∘ ''g'') = ∂''f'' ∘ ∂''g''. Thus there is a homomorphism of the group of quasi-isometries into the group of self-mappings of  ∂''X''.

To check that ∂''f'' is continuous, note that if γ&lt;sub&gt;1&lt;/sub&gt; and γ&lt;sub&gt;2&lt;/sub&gt; are geodesic rays that are uniformly close on [0,''R''],  within a distance η, then ''f'' ∘ γ&lt;sub&gt;1&lt;/sub&gt; and ''f'' ∘ γ&lt;sub&gt;2&lt;/sub&gt; lie within a distance λη + ε  on [0,''R''], so that δ&lt;sub&gt;1&lt;/sub&gt; and δ&lt;sub&gt;2&lt;/sub&gt; lie within a distance λη + ε + 2''h''(λ,ε); hence on a smaller interval [0,''r''], δ&lt;sub&gt;1&lt;/sub&gt; and δ&lt;sub&gt;2&lt;/sub&gt; lie within a distance (''r''/''R'')⋅[λη + ε + 2''h''(λ,ε)] by convexity.&lt;ref&gt;{{harvnb|Bridson|Haefliger|1999|pages=430–431}}&lt;/ref&gt;

On CAT(-1) spaces, a finer version of continuity asserts that ∂''f'' is a quasi-Möbius mapping with respect to a natural class of metric on ∂''X'', the "visual metrics" generalising the Euclidean metric on the unit circle and its transforms under the Möbius group. These visual metrics can be defined in terms of Busemann functions.&lt;ref&gt;See:
*{{harvnb|Bourdon|1995}}
*{{harvnb|Buyalo|Schroeder|2007}}
*{{harvnb|Bourdon|2009}}
&lt;/ref&gt;

In the case of the unit disk, Teichmüller theory implies that the homomorphism carries quasiconformal homeomorphisms of the disk onto the group of quasi-Möbius homeomorphisms of the circle (using for example the Ahlfors–Beurling or [[Douady–Earle extension]]): it follows that the homomorphism from the quasi-isometry group into the quasi-Möbius group is surjective.

In the other direction, it is straightforward to prove that the homomorphism is injective.&lt;ref&gt;{{harvnb|Roe|2003|page=113}}&lt;/ref&gt; In fact suppose that ''f'' is a quasi-isometry of the unit disk such that ∂''f'' is the identity. The assumption and the Morse lemma implies that if γ('''R''') is a geodesic line, then ''f''(γ('''R''')) lies in an ''h''-neighbourhood of γ('''R'''). Now take a second geodesic line δ such that δ and γ intersect orthogonally at a given point in ''a''. Then ''f''(''a'') lies in the intersection of ''h''-neighbourhoods of δ and γ. Applying a Möbius transformation, it can be assumed that ''a'' is at the origin of the unit disk and the geodesics are the real and imaginary axes. By convexity, the ''h''-neighbourhoods of these axes intersect in a 3''h''-neighbourhood of the origin: in fact if ''z'' lies in both neighbourhoods, let ''x'' and ''y'' be the orthogonal projections of ''z''  onto the ''x''- and ''y''-axes; then {{math|1=''d''(''z'',''x'') ≤ ''h''}} so taking projections onto the ''y''-axis, {{math|1=''d''(0,''y'') ≤ ''h''}}; hence  {{math|1=''d''(''z'',0) ≤ ''d''(''z'',''y'') + ''d''(''y'',0) ≤ 2''h''}}.  Hence {{math|1=''d''(''a'',''f''(''a'')) ≤ 2''h''}}, so that ''f'' is quasi-equivalent to the identity, as claimed.

===Cross ratio and distance between non-intersecting geodesic lines===
Given two distinct points ''z'', ''w'' on the unit circle or real axis there is a unique hyperbolic geodesic [''z'',''w''] joining them. It is given by the circle (or straight line) which cuts the unit circl unit circle or real axis orthogonally at those two points. Given four distinct points ''a'', ''b'', ''c'', ''d'' in the extended complex plane their [[cross ratio]] is defined by

:&lt;math&gt;(a,b;c,d) ={(a-c)(b-d)\over (a-d)(b-c)}.&lt;/math&gt;

If ''g'' is a complex [[Möbius transformation]] then it leaves the cross ratio invariant: {{math|1=(''g''(''a''),''g''(''b'');''g''(''c''),''g''(''d'')) = (''a'',''b'':''c'',''d'')}}. Since the Möbius group acts simply transitively on triples of points, the cross ratio can alternatively be described as the complex number ''z'' in '''C'''\{0,1} such that ''g''(''a'') = 0, ''g''(''b'') = 1, ''g''(''c'') = λ, ''g''(''d'') = ∞ for a Möbius transformation ''g''.

Since ''a'', ''b'', ''c'' and ''d'' all appear in the numerator defining the cross ratio, to understand the behaviour of the cross ratio under permutations of ''a'', ''b'', ''c'' and ''d'', it suffices to consider permutations that fix ''d'', so only permute ''a'', ''b'' and ''c''. The cross ratio transforms according to the [[anharmonic group]] of order 6 generated by the Möbius transformations sending λ to 1 – λ and λ&lt;sup&gt;−1&lt;/sup&gt;. The other three transformations send λ to 1 – λ&lt;sup&gt;−1&lt;/sup&gt;, to λ(λ – 1)&lt;sup&gt;−1&lt;/sup&gt; and to (1 – λ)&lt;sup&gt;−1&lt;/sup&gt;.&lt;ref&gt;{{harvnb|Beardon|1983|pages=75–78}} Note that there is a natural homomorphism of ''S''&lt;sub&gt;4&lt;/sub&gt; onto ''S''&lt;sub&gt;3&lt;/sub&gt;, acting by conjugation on (''a'',''b'')(''c'',''d''), (''a'',''c'')(''b'',''d'') and (''a'',''d'')(''b'',''c''). Indeed these permutations together with the identty form a normal Abelian subgroup equal to its own centraliser: the action of ''S''&lt;sub&gt;4&lt;/sub&gt; by conjugation on the non-trivial elements yields the homomorphism onto ''S''&lt;sub&gt;3&lt;/sub&gt;.&lt;/ref&gt;

Now let ''a'', ''b'', ''c'', ''d'' be points on the unit circle or real axis in that order. Then the geodesics [''a'',''b''] and [''c'',''d''] do not intersect and the distance between these geodesics is well defined: there is a unique geodesic line cutting these two geodesics orthogonally and the distance is given by the length of the geodesic segment between them. It is evidently invariant under real Möbius transformations. To compare the cross ratio and the distance between geodesics, Möbius invariance allows the calculation to be reduced to a symmetric configuration. In fact for 0 &lt; ''r'' &lt; ''R'', take ''a'' = –''R'', ''b'' = −''r'', ''c'' = ''r'', ''d'' = ''R''. Then
{{math|1=λ = (''a'',''b'';''c'',''d'') = (''R'' + ''r'')&lt;sup&gt;2&lt;/sup&gt;/4''rR'' =  (''t'' + 1)&lt;sup&gt;2&lt;/sup&gt;/4''t''}} where ''t'' = ''R''/''r'' &gt; 1. On the other hand, the geodesics [''a'',''d''] and [''b'',''c''] are the semicircles in the upper half plane of radius ''r'' and ''R''. The geodesic which cuts them orthogonally is the positive imaginary axis, so the distance between them is the hyperbolic distance between ''ir'' and ''iR'', ''d''(''ir'',''iR'') = log ''R''/''r'' = log ''t''. Let ''s'' = log ''t'', then λ = cosh&lt;sup&gt;2&lt;/sup&gt;(''s''/2), so that there is a constant ''C'' &gt; 0 such that, if (''a'',''b'';''c'',''d'') &gt; 1, then

:&lt;math&gt;d([a,d];[b,c]) - C \le \log (a,b;c,d) \le d([a,d];[b,c]) + C,&lt;/math&gt;

since log[cosh(''x'')/exp''x'')] = log (1 + exp(–2''x''))/2 is bounded above and below in ''x'' ≥ 0. Note that ''a'', ''b'',''c'', ''d'' are in order around the unit circle if and only if (''a'',''b'';''c'',''d'') &gt; 1.

A more general and precise geometric interpretation of the cross ratio can be given using projections of ideal points on to a geodesic line; it does not depend on the order of the points on the circle and therefore whether or not geodesic lines intersect.&lt;ref&gt;See: 
*{{harvnb|Paulin|1996}}
*{{harvnb|Bulayo|Schroeder|2007}}&lt;/ref&gt;
*'''''If p and q are the feet of the perpendiculars from c and d to the geodesic line ab, then d(p,q) = |log |(a,b;c,d)||.'''''

Since both sides are invariant under Möbius transformations, it suffices to check this in the case that ''a'' = 0, ''b'' = ∞, ''c'' = ''x'' and ''d'' = 1. In this case the geodesic line is the positive imaginary axis, right hand side equals |log |''x''||, ''p'' = |''x''|''i'' and ''q'' = ''i''. So the left hand side equals |log|''x''||. Note that ''p'' and ''q'' are also the points where the incircles of the ideal triangles ''abc'' and ''abd'' touch ''ab''.

===Proof of theorem===
A homeomorphism ''F'' of the circle is [[quasisymmetric map|''quasisymmetric'']] if there are constants ''a'', ''b'' &gt; 0 such that

:&lt;math&gt;\displaystyle{{|F(z_1)-F(z_2)|\over |F(z_1)-F(z_3)|} \le a {|z_1-z_2|^b\over |z_1-z_3|^b}.}&lt;/math&gt;

It is ''quasi-Möbius'' is there are constants ''c'', ''d'' &gt; 0 such that

:&lt;math&gt;\displaystyle{|(F(z_1),F(z_2);F(z_3),F(z_4))| \le c |(z_1,z_2;z_3,z_4)|^d,}&lt;/math&gt;

where

:&lt;math&gt;\displaystyle{ (z_1,z_2;z_3,z_4)={(z_1-z_3)(z_2-z_4)\over(z_2-z_3)(z_1-z_4)}}&lt;/math&gt;

denotes the [[cross-ratio]].

It is immediate that quasisymmetric and quasi-Möbius homeomorphisms are closed under the operations of inversion and composition.

If ''F'' is quasisymmetric then it is also quasi-Möbius, with ''c'' = ''a''&lt;sup&gt;2&lt;/sup&gt; and ''d'' = ''b'': this follows by multiplying the first inequality for (''z''&lt;sub&gt;1&lt;/sub&gt;,''z''&lt;sub&gt;3&lt;/sub&gt;,''z''&lt;sub&gt;4&lt;/sub&gt;) and (''z''&lt;sub&gt;2&lt;/sub&gt;,''z''&lt;sub&gt;4&lt;/sub&gt;,''z''&lt;sub&gt;3&lt;/sub&gt;). Conversely any quasi-Möbius homeomorphism ''F'' is quasisymmetric. To see this, it can be first be checked that ''F'' (and hence ''F''&lt;sup&gt;−1&lt;/sup&gt;) is [[Hölder continuous]]. Let ''S'' be the set of cube roots of unity, so that if ''a'' ≠ ''b'' in ''S'', then |''a'' − ''b''| = 2 sin {{pi}}/3 = {{radic|3}}. To prove a Hölder estimate, it can be assumed that ''x'' – ''y'' is uniformly small. Then both ''x'' and ''y'' are greater than a fixed distance away from ''a'', ''b'' in ''S'' with ''a'' ≠ ''b'', so the estimate follows by applying the quasi-Möbius inequality to ''x'', ''a'', ''y'', ''b''. To verify that ''F'' is quasisymmetric, it suffices to find a uniform upper bound for |''F''(''x'') − ''F''(''y'')| / |''F''(''x'') − ''F''(''z'')| in the case of a triple with |''x'' − ''z''| = |''x'' − ''y''|, uniformly small. In this case there is a point ''w'' at a distance greater than 1 from ''x'', ''y'' and ''z''. Applying the quasi-Möbius inequality to ''x'', ''w'', ''y'' and ''z'' yields the required upper bound. To summarise:

* '''''A homeomorphism of the circle is quasi-Möbius if and only if it is quasisymmetric. In this case it and its inverse are Hölder continuous. The quasi-Möbius homeomorphisms form a group under composition.'''''&lt;ref&gt;{{harvnb|Väisälä|1984}}&lt;/ref&gt;

To prove the theorem it suffices to prove that if ''F'' = ∂''f'' then there are constants ''A'', ''B'' &gt; 0 such that for ''a'', ''b'', ''c'', ''d'' distinct points on the unit circle&lt;ref&gt;{{harvnb|Bourdon|2009}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{|(F(a),F(b);F(c),F(d))| \le A |(a,b;c,d)|^B.}&lt;/math&gt;

It has already been checked that ''F'' (and is inverse) are continuous. Composing ''f'', and hence ''F'', with complex conjugation if necessary, it can further be assumed that ''F'' preserves the orientation of the circle. In this case, if ''a'',''b'', ''c'',''d'' are in order on the circle, so too are there images under ''F''; hence both (''a'',''b'';''c'',''d'') and (''F''(''a''),''F''(''b'');''F''(''c''),''F''(''d'')) are real and greater than one. In this case

:&lt;math&gt;(F(a),F(b);F(c),F(d)) \le A (a,b;c,d)^B.&lt;/math&gt;

To prove this, it suffices to show that {{math|1=log (''F''(''a''),''F''(''b'');''F''(''c''),''F''(''d'')) ≤ ''B'' log (''a'',''b'';''c'',''d'') + ''C''}}. From the previous section it suffices show {{math|1=''d''([''F''(''a''),''F''(''b'')],[''F''(''c''),''F''(''d'')]) ≤ ''P'' ''d''([''a'',''b''],[''c'',''d'']) + ''Q''}}. This follows from the fact that the images under ''f'' of [''a'',''b''] and [''c'',''d''] lie within ''h''-neighbourhoods of [''F''(''a''),''F''(''b'')] and [''F''(''c''),''F''(''d'')]; the minimal distance can be estimated using the quasi-isometry constants for ''f'' applied to the points on [''a'',''b''] and [''c'',''d'']
realising ''d''([''a'',''b''],[''c'',''d'']).

Adjusting ''A'' and ''B'' if necessary, the inequality above applies also to ''F''&lt;sup&gt;−1&lt;/sup&gt;. Replacing ''a'', ''b'', ''c'' and ''d'' by their images under ''F'', it follows that

:&lt;math&gt;A^{-1} |(a,b;c,d)|^{-B} \le |(F(a),F(b);F(c),F(d))| \le A |(a,b;c,d)|^B&lt;/math&gt;

if ''a'', ''b'', ''c'' and ''d'' are in order on the unit circle. Hence the same inequalities are valid for the three cyclic of the quadruple ''a'', ''b'', ''c'', ''d''. If ''a'' and ''b'' are switched then the cross ratios are sent to their inverses, so lie between 0 and 1; similarly if ''c'' and ''d'' are switched. If both pairs are switched, the cross ratio remains unaltered.  Hence the inequalities are also valid in this case. Finally if ''b'' and ''c'' are interchanged, the croos ratio changes from λ to {{math|1=λ&lt;sup&gt;–1&lt;/sup&gt;
(λ – 1) = 1 – λ&lt;sup&gt;–1&lt;/sup&gt;}}, which lies between 0 and 1. Hence again the same inequalities are valid. It is easy to check that using these transformations the inequlaties are valid for all possible permutations of ''a'', ''b'', ''c'' and ''d'', so that ''F'' and its inverse are quasi-Möbius homeomorphisms.

== Busemann functions and visual metrics for CAT(-1) spaces==

Busemann functions can be used to determine special visual metrics on the class of CAT(-1) spaces. These are complete geodesic metric spaces in which the distances between points on the boundary of a geodesic triangle are less than or equal to the comparison triangle in the hyperbolic upper half plane or equivalently the unit disk with the Poincaré metric. In the case of the unit disk the chordal metric can be recovered directly using Busemann functions ''B''&lt;sub&gt;γ&lt;/sub&gt; and the special theory for the disk generalises completely to any proper CAT(-1) space ''X''. The hyperbolic upper half plane is a CAT(0) space, as lengths in a hyperbolic geodesic triangle are less than lengths in the Euclidean comparison triangle: in particular a CAT(-1) space is a CAT(0) space, so the theory of Busemann functions and the Gromov boundary applies. From the theory of the hyperbolic disk, it follows in particular that every geodesic ray in a CAT(-1) space extends to a geodesic line and given two points of the boundary there is a unique geodesic γ such that has these points as the limits γ(±∞). The theory applies equally well to any CAT(−κ) space with κ &gt; 0 since these arise by scaling the metric on a CAT(-1) space by κ&lt;sup&gt;−1/2&lt;/sup&gt;. On the hyperbolic unit disk ''D'' quasi-isometries of ''D'' induce quasi-Möbius homeomorphisms of the boundary in a functorial way. There is a more general theory of Gromov hyperbolic spaces, a similar statement holds, but with less precise control on the homeomorphisms of the boundary.&lt;ref name="Bourdon 1995"/&gt;&lt;ref name="Buyalo 2007"/&gt;

===Example: Poincaré disk===

==Further properties of Busemann functions==

{{Empty section|date=July 2017}}

==Applications in percolation theory==
More recently Busemann functions have been used by [[probability theory|probabilists]] to study asymptotic properties in models of [[first passage percolation|first-passage percolation]]&lt;ref&gt;{{harvnb|Hoffman|2005}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Damron|Hanson|2014}}&lt;/ref&gt; and directed last-passage percolation.&lt;ref&gt;{{harvnb|Georgiou|Rassoul-Agha|Sepp&amp;auml;l&amp;auml;inen|2016}}&lt;/ref&gt;

== Notes ==
{{reflist|40em}}

==References==
*{{citation|last=Ahlfors|first=Lars V.|authorlink=Lars Ahlfors|title=Lectures on quasiconformal mappings|publisher=Van Nostrand|year=1966}}
*{{citation|last1=Ballmann|first1=Werner|last2= Gromov|first2=Mikhael|last3= Schroeder|first3= Viktor|title=
Manifolds of nonpositive curvature|series=Progress in Mathematics|volume= 61|publisher=[[Birkhäuser]]|year= 1985|isbn= 0-8176-3181-X }}
*{{citation|last=Ballmann|first=Werner|title=Lectures on spaces of nonpositive curvature|series=DMV Seminar|volume= 25|publisher=Birkhäuser|year= 1995|isbn= 3-7643-5242-6}}
*{{citation|first=Alan F.|last= Beardon|title=The Geometry of Discrete Groups|year=1983|publisher=Springer-Verlag|isbn=0-387-90788-2}}
*{{citation|last=Bourdon|first= Marc|language=fr|title=Structure conforme au bord et flot géodésique d'un CAT(−1)-espace|journal=Enseign. Math.|volume= 41|year=1995|pages=63–102}}
*{{citation|last=Bourdon|first=Marc|chapter=
Quasi-conformal geometry and Mostow rigidity|title=Géométries à courbure négative ou nulle, groupes discrets et rigidités|pages= 201–212|series=Sémin. Congr.|volume=18|publisher= Soc. Math. France|year= 2009}}
*{{citation | last1=Bridson | first1=Martin R. | last2=Haefliger | first2=André | title=Metric spaces of non-positive curvature | year=1999 | publisher=Springer}}
*{{citation|last=Busemann|first=Herbert|title=The geometry of geodesics|publisher= Academic Press|year=1955}}
*{{citation|last=Buyalo|first=Sergei|last2=Schroeder|first2=Viktor|title=Elements of asymptotic geometry|series=EMS Monographs in Mathematics|publisher=[[European Mathematical Society]]|year= 2007|isbn= 978-3-03719-036-4}}
*{{citation|last=Dal'bo|first= Françoise|last2=Peigné|first2=Marc|last3= Sambusetti|first3= Andrea|title=On the horoboundary and the geometry of rays of negatively curved manifolds|journal=Pacific J. Math.|volume= 259|year=2012|pages=55–100|url=http://msp.org/pjm/2012/259-1/pjm-v259-n1-p03-s.pdf|doi=10.2140/pjm.2012.259.55|arxiv=1010.6028}}, Appendix.
*{{citation|last=Damron|first=Michael|last2=Hanson|first2= Jack|title=
Busemann functions and infinite geodesics in two-dimensional first-passage percolation|journal=Comm. Math. Phys.|volume= 325|year=2014|pages=917–963|bibcode=2014CMaPh.325..917D|doi=10.1007/s00220-013-1875-y|arxiv=1209.3036}}
*{{citation|last=Eberlein|first=P.|last2=O'Neill|first2=B.|title=Visibility manifolds|journal=Pacific J. Math.|volume= 46|year=1973|pages=45–109|doi=10.2140/pjm.1973.46.45}}
*{{citation|first=V. A.|last=Efremovich|authorlink=Efremovich|first2= E. S.|last2=Tikhomirova|title=Equimorphisms of hyperbolic spaces|journal=Izv. Akad. Nauk SSSR Ser. Mat.|volume= 28|year=1964|pages=1139–1144|url=http://www.mathnet.ru/php/getFT.phtml?jrnid=im&amp;paperid=3046&amp;what=fullt&amp;option_lang=eng|language=ru}}
*{{citation|last=Georgiou|first= Nicos|last2= Rassoul-Agha|first2= Firas|last3= Seppäläinen|first3=Timo|title=
Variational formulas and cocycle solutions for directed polymer and percolation models|journal=Comm. Math. Phys. |volume=346 |year=2016|pages= 741–779|bibcode=2016CMaPh.346..741G|doi=10.1007/s00220-016-2613-z|arxiv=1311.3016}}
*{{citation|last=Hoffman|first=Christopher|title=Coexistence for Richardson type competing spatial growth models|journal=Ann. Appl. Probab.|volume= 15 |year=2005|pages= 739–747|doi=10.1214/105051604000000729|arxiv=math/0405377}}
*{{citation|last=Kapovich|first=Michael|title=Hyperbolic manifolds and discrete groups|series=
Progress in Mathematics|volume=183|publisher=[[Birkhäuser]] |year=2001|isbn= 0-8176-3904-7 }}
*{{citation|last=Lehto|first= Olli|title=Univalent functions and Teichmüller spaces|series=Graduate Texts in Mathematics|volume= 109|publisher= Springer-Verlag|year= 1987|isbn=0-387-96310-3}}
*{{citation|last=Lurie|first=J.|url=http://www.math.harvard.eondu/~lurie/papers/hadamard.pdf|title=Notes on the theory of Hadamard spaces|year=2010|publisher=[[Harvard University]]}}
*{{citation|last=Mori|first= Akira|title=On quasi-conformality and pseudo-analyticity|journal=Trans. Amer. Math. Soc.|volume= 84 |year=1957|pages= 56–77|url=http://www.ams.org/journals/tran/1957-084-01/S0002-9947-1957-0083024-5/S0002-9947-1957-0083024-5.pdf|doi=10.1090/s0002-9947-1957-0083024-5}}
*{{citation|first=H. M.|last= Morse|authorlink=Marston Morse|title= A fundamental class of geodesics on any closed surface of genus greater than one|journal=Trans. Amer. Math. Soc.|volume=26|year=1924|pages= 25–60|url=http://www.ams.org/journals/tran/1924-026-01/S0002-9947-1924-1501263-9/S0002-9947-1924-1501263-9.pdf|doi=10.1090/s0002-9947-1924-1501263-9}}
*{{citation|last=Papadopoulos|first= Athanase|title=Metric spaces, convexity and non-positive curvature|edition=Second|series= IRMA Lectures in Mathematics and Theoretical Physics|volume= 6|publisher=[[European Mathematical Society]]|year=2014|isbn=978-3-03719-132-3}}
*{{citation|last=Paulin|first= Frédéric|title=Un groupe hyperbolique est déterminé par son bord|language=fr|journal=J. London Math. Soc. |volume=54 |year=1996|pages= 50–74|doi=10.1112/jlms/54.1.50}}
*{{citation|last=Ratcliffe|first= John G.|title=Foundations of hyperbolic manifolds|edition=
Second |series= Graduate Texts in Mathematics|volume= 149|publisher=Springer|year=2006|isbn=978-0387-33197-3}}
*{{citation|last=Roe|first=John|title=Lectures on coarse geometry|series=University Lecture Series|volume= 31|publisher=[[American Mathematical Society]]|year= 2003|isbn=0-8218-3332-4}}
*{{citation|last=Shiohama|first= Katsuhiro|chapter=Topology of complete noncompact manifolds|title=Geometry of geodesics and related topics |pages= 423–450|series=
Adv. Stud. Pure Math.|volume= 3|publisher=[[North-Holland]]|year= 1984}}
* {{SpringerEOM|id=Busemann_function&amp;oldid=13719|title=Busemann function|first=T.|last= Shioya}}
*{{citation|last=Väisälä|first= Jussi|title=Quasi-Möbius maps|journal=J. Analyse Math. |volume=44|year=1984|pages= 218–234|doi=10.1007/bf02790198}}

[[Category:Geometry]]</text>
      <sha1>nxgw0nc7gtdyayqdkpnytwmcrlp67gr</sha1>
    </revision>
  </page>
  <page>
    <title>Cyclic number</title>
    <ns>0</ns>
    <id>1672489</id>
    <revision>
      <id>871460088</id>
      <parentid>871460045</parentid>
      <timestamp>2018-12-01T06:13:30Z</timestamp>
      <contributor>
        <username>Mahveotm</username>
        <id>26817845</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/114.108.217.229|114.108.217.229]] ([[User talk:114.108.217.229|talk]]) ([[WP:HG|HG]]) (3.3.3)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15131">{{about|numbers where permutations of their digits (in some base) yield related numbers|the number theoretic concept|cyclic number (group theory)}}

A '''cyclic number''' is an [[integer]] in which [[cyclic permutation]]s of the digits are successive multiples of the number.  The most widely known is the six-digit number [[142857 (number)|142857]], whose first six integer multiples are
:142857 &amp;times; 1 = 142857
:142857 &amp;times; 2 = 285714
:142857 &amp;times; 3 = 428571
:142857 &amp;times; 4 = 571428
:142857 &amp;times; 5 = 714285
:142857 &amp;times; 6 = 857142

== Details ==
To qualify as a cyclic number, it is required that consecutive multiples be cyclic permutations.  Thus, the number 076923 would not be considered a cyclic number, because even though all cyclic permutations are multiples, they are not consecutive integer multiples:

:076923 &amp;times; 1 = 076923
:076923 &amp;times; 3 = 230769
:076923 &amp;times; 4 = 307692
:076923 &amp;times; 9 = 692307
:076923 &amp;times; 10 = 769230
:076923 &amp;times; 12 = 923076

The following trivial cases are typically excluded:
#single digits, e.g.: 5
#repeated digits, e.g.: 555
#repeated cyclic numbers, e.g.: 142857142857

If leading zeros are not permitted on numerals, then 142857 is the only cyclic number in [[decimal]], due to the necessary structure given in the next section. Allowing leading zeros, the sequence of cyclic numbers begins:

:(10&lt;sup&gt;6&lt;/sup&gt;-1) / '''7''' = 142857 (6 digits)
:(10&lt;sup&gt;16&lt;/sup&gt;-1) / '''17''' = 0588235294117647 (16 digits)
:(10&lt;sup&gt;18&lt;/sup&gt;-1) / '''19''' = 052631578947368421 (18 digits)
:(10&lt;sup&gt;22&lt;/sup&gt;-1) / '''23''' = 0434782608695652173913 (22 digits)
:(10&lt;sup&gt;28&lt;/sup&gt;-1) / '''29''' = 0344827586206896551724137931 (28 digits)
:(10&lt;sup&gt;46&lt;/sup&gt;-1) / '''47''' = 0212765957446808510638297872340425531914893617 (46 digits)
:(10&lt;sup&gt;58&lt;/sup&gt;-1) / '''59''' = 0169491525423728813559322033898305084745762711864406779661 (58 digits)
:(10&lt;sup&gt;60&lt;/sup&gt;-1) / '''61''' = 016393442622950819672131147540983606557377049180327868852459 (60 digits)
:(10&lt;sup&gt;96&lt;/sup&gt;-1) / '''97''' = 010309278350515463917525773195876288659793814432989690721649484536082474226804123711340206185567 (96 digits)

== Relation to repeating decimals ==
Cyclic numbers are related to the [[Repeating decimal|recurring digital representations]] of [[unit fractions]].  A cyclic number of length ''L'' is the digital representation of

:1/(''L'' + 1).

Conversely, if the digital period of 1 /''p'' (where ''p'' is prime) is

:''p'' &amp;minus; 1,

then the digits represent a cyclic number.

For example:

:1/7 = 0.142857 142857….

Multiples of these fractions exhibit cyclic permutation:

:1/7 = 0.142857 142857…
:2/7 = 0.285714 285714…
:3/7 = 0.428571 428571…
:4/7 = 0.571428 571428…
:5/7 = 0.714285 714285…
:6/7 = 0.857142 857142….

== Form of cyclic numbers ==

From the relation to unit fractions, it can be shown that cyclic numbers are of the form of the [[Fermat quotient]]

:&lt;math&gt;\frac{b^{p-1}-1}{p}&lt;/math&gt;

where ''b'' is the [[Radix|number base]] (10 for [[decimal]]), and ''p'' is a [[Prime number|prime]] that does not [[Divisor|divide]] ''b''. (Primes ''p'' that give cyclic numbers in base ''b'' are called [[full reptend prime]]s or long primes in base ''b'').

For example, the case ''b'' = 10, ''p'' = 7 gives the cyclic number 142857, and the case ''b'' = 12, ''p'' = 5 gives the cyclic number 2497.

Not all values of ''p'' will yield a cyclic number using this formula; for example, the case ''b'' = 10,  ''p'' = 13 gives 076923076923, and the case ''b'' = 12, ''p'' = 19 gives 076B45076B45076B45. These failed cases will always contain a repetition of digits (possibly several).

The first values of ''p'' for which this formula produces cyclic numbers in [[decimal]] (''b'' = 10) are {{OEIS|id=A001913}}

:7, 17, 19, 23, 29, 47, 59, 61, 97, 109, 113, 131, 149, 167, 179, 181, 193, 223, 229, 233, 257, 263, 269, 313, 337, 367, 379, 383, 389, 419, 433, 461, 487, 491, 499, 503, 509, 541, 571, 577, 593, 619, 647, 659, 701, 709, 727, 743, 811, 821, 823, 857, 863, 887, 937, 941, 953, 971, 977, 983, …

For ''b'' = 12 ([[duodecimal]]), these ''p''s are {{OEIS|id=A019340}}
:5, 7, 17, 31, 41, 43, 53, 67, 101, 103, 113, 127, 137, 139, 149, 151, 163, 173, 197, 223, 257, 269, 281, 283, 293, 317, 353, 367, 379, 389, 401, 449, 461, 509, 523, 547, 557, 569, 571, 593, 607, 617, 619, 631, 641, 653, 691, 701, 739, 751, 761, 773, 787, 797, 809, 821, 857, 881, 929, 953, 967, 977, 991, ...

For ''b'' = 2 ([[binary number|binary]]), these ''p''s are {{OEIS|id=A001122}}
:3, 5, 11, 13, 19, 29, 37, 53, 59, 61, 67, 83, 101, 107, 131, 139, 149, 163, 173, 179, 181, 197, 211, 227, 269, 293, 317, 347, 349, 373, 379, 389, 419, 421, 443, 461, 467, 491, 509, 523, 541, 547, 557, 563, 587, 613, 619, 653, 659, 661, 677, 701, 709, 757, 773, 787, 797, 821, 827, 829, 853, 859, 877, 883, 907, 941, 947, ...

For ''b'' = 3 ([[ternary numeral system|ternary]]), these ''p''s are {{OEIS|id=A019334}}
:2, 5, 7, 17, 19, 29, 31, 43, 53, 79, 89, 101, 113, 127, 137, 139, 149, 163, 173, 197, 199, 211, 223, 233, 257, 269, 281, 283, 293, 317, 331, 353, 379, 389, 401, 449, 461, 463, 487, 509, 521, 557, 569, 571, 593, 607, 617, 631, 641, 653, 677, 691, 701, 739, 751, 773, 797, 809, 811, 821, 823, 857, 859, 881, 907, 929, 941, 953, 977, ...

There are no such ''p''s in the [[hexadecimal]] system.

The known pattern to this sequence comes from [[algebraic number theory]], specifically, this sequence is the set of primes ''p'' such that ''b'' is a [[primitive root modulo n|primitive root modulo ''p'']]. A [[Artin's conjecture on primitive roots|conjecture of Emil Artin]] &lt;ref&gt;http://mathworld.wolfram.com/ArtinsConstant.html&lt;/ref&gt; is that this sequence contains 37.395..% of the primes (for ''b'' in {{oeis|id=A085397}}).

== Construction of cyclic numbers ==

Cyclic numbers can be constructed by the following [[Algorithm|procedure]]:

Let ''b'' be the number base (10 for decimal)&lt;br&gt;
Let ''p'' be a prime that does not divide ''b''.&lt;br&gt;
Let ''t'' = 0.&lt;br&gt;
Let ''r'' = 1.&lt;br&gt;
Let ''n'' = 0.&lt;br&gt;
loop:
:Let ''t'' = ''t'' + 1
:Let ''x'' = ''r'' &amp;middot; ''b''
:Let ''d'' = [[Floor function|int]](''x'' / ''p'')
:Let ''r'' = ''x'' [[modulo operation|mod]] ''p''
:Let ''n'' = ''n'' &amp;middot; ''b'' + ''d''
:If ''r'' &amp;ne; 1 then repeat the loop.
if ''t'' = ''p'' &amp;minus; 1 then ''n'' is a cyclic number.

This procedure works by computing the digits of 1 /''p'' in base ''b'', by [[long division]].  ''r'' is the [[remainder]] at each step, and ''d'' is the digit produced.

The step

:''n'' = ''n'' &amp;middot; ''b'' + ''d''

serves simply to collect the digits. For computers not capable of expressing very large integers, the digits may be output or collected in another way.

Note that if ''t'' ever exceeds ''p''/2, then the number must be cyclic, without the need to compute the remaining digits.

== Properties of cyclic numbers ==

*When multiplied by their generating prime, results in a sequence of {{'}}''base''&amp;minus;1' digits (9 in decimal). ''Decimal 142857 &amp;times; 7 = 999999.''
*When split in two,three four etc...regarding base 10, 100, 1000 etc.. by its digits and added the result is a sequence of 9's. ''14 + 28 + 57 = 99'', ''142 + 857 = 999'', ''1428 + 5714+ 2857 = 9999'' etc. ...  (This is a special case of [[Midy's Theorem]].)
*All cyclic numbers are divisible by  {{'}}''base''&amp;minus;1' (9 in decimal) and the sum of the remainder is the a multiple of  the divisor.  (This follows from the previous point.)

== Other numeric bases ==

Using the above technique, cyclic numbers can be found in other numeric bases. (Note that not all of these follow the second rule (all successive multiples being cyclic permutations) listed in the Special Cases section above) In each of these cases the digits across half the period add up to the base minus one. Thus for binary the sum of the bits across half the period is 1; for ternary it is 2, and so on.

In [[Binary numeral system|binary]], the sequence of cyclic numbers begins: {{OEIS|id=A001122}}
:11 (3) → 01
:101 (5) → 0011
:1011 (11) → 0001011101
:1101 (13) → 000100111011
:10011 (19) → 000011010111100101
:11101 (29) → 0000100011010011110111001011

In [[Ternary numeral system|ternary]]: {{OEIS|id=A019334}}
:2 (2) → 1
:12 (5) → 0121
:21 (7) → 010212
:122 (17) → 0011202122110201
:201 (19) → 001102100221120122

In [[Quaternary numeral system|quaternary]]:
:(none)

In [[quinary]]: {{OEIS|id=A019335}}
:2 (2) → 2
:3 (3) → 13
:12 (7) → 032412 	
:32 (17) → 0121340243231042
:43 (23) → 0102041332143424031123
:122 (37) → 003142122040113342441302322404331102
:133 (43) → 002423141223434043111442021303221010401333

In [[senary]]: {{OEIS|id=A167794}}
:15 (11) → 0313452421
:21 (13) → 024340531215
:25 (17) → 0204122453514331
:105 (41) → 0051335412440330234455042201431152253211
:135 (59) → 0033544402235104134324250301455220111533204514212313052541
:141 (61) → 003312504044154453014342320220552243051511401102541213235335
:211 (79) → 002422325434441304033512354102140052450553133230121114251522043201453415503105

In base 7: {{OEIS|id=A019337}}
:2 (2) → 3
:5 (5) → 1254
:14 (11) → 0431162355
:16 (13) → 035245631421
:23 (17) → 0261143464055232
:32 (23) → 0206251134364604155323
:56 (41) → 0112363262135202250565543034045314644161

In [[octal]]: {{OEIS|id=A019338}}
:3 (3) → 25
:5 (5) → 1463
:13 (11) → 0564272135
:35 (29) → 0215173454106475626043236713
:65 (53) → 0115220717545336140465103476625570602324416373126743
:73 (59) → 0105330745756511606404255436276724470320212661713735223415
:123 (83) → 0061262710366576352321570224030531344173277165150674112014254562075537472464336045

In [[nonary]]:
:2 (2) → 4
:(no others)

In base 11: {{OEIS|id=A019339}}
:2 (2) → 5
:3 (3) → 37
:12 (13) → 093425A17685
:16 (17) → 07132651A3978459
:21 (23) → 05296243390A581486771A
:27 (29) → 04199534608387A69115764A2723
:29 (31) → 039A32146818574A71078964292536

In [[duodecimal]]: {{OEIS|id=A019340}}
:5 (5) → 2497
:7 (7) → 186A35
:15 (17) → 08579214B36429A7
:27 (31) → 0478AA093598166B74311B28623A55
:35 (41) → 036190A653277397A9B4B85A2B15689448241207
:37 (43) → 0342295A3AA730A068456B879926181148B1B53765
:45 (53) → 02872B3A23205525A784640AA4B9349081989B6696143757B117

In base 13: {{OEIS|id=A019341}}
:2 (2) → 6
:5 (5) → 27A5 
:B (11) → 12495BA837
:16 (19) → 08B82976AC414A3562
:25 (31) → 055B42692C21347C7718A63A0AB985
:2B (37) → 0474BC3B3215368A25C85810919AB79642A7
:32 (41) → 04177C08322B13645926C8B550C49AA1B96873A6

In base 14: {{OEIS|id=A019342}}
:3 (3) → 49 
:13 (17) → 0B75A9C4D2683419
:15 (19) → 0A45C7522D398168BB
:19 (23) → 0874391B7CAD569A4C2613
:21 (29) → 06A89925B163C0D73544B82C7A1D
:3B (53) → 039AB8A075793610B146C21828DA43253D6864A7CD2C971BC5B5
:43 (59) → 03471937B8ACB5659A2BC15D09D74DA96C4A62531287843B21C80D4069

In base 15: {{OEIS|id=A019343}}
:2 (2) → 7
:D (13) → 124936DCA5B8
:14 (19) → 0BC9718A3E3257D64B
:18 (23) → 09BB1487291E533DA67C5D
:1E (29) → 07B5A528BD6ACDE73949C6318421
:27 (37) → 061339AE2C87A8194CE8DBB540C26746D5A2
:2B (41) → 0574B51C68BA922DD80AE97A39D286345CC116E4

In [[hexadecimal]]:
:(none)

In base 17: {{OEIS|id=A019344}}
:2 (2) → 8
:3 (3) → 5B 
:5 (5) → 36DA
:7 (7) → 274E9C
:B (11) → 194ADF7C63
:16 (23) → 0C9A5F8ED52G476B1823BE
:1E (31) → 09583E469EDC11AG7B8D2CA7234FF6

In base 18: {{OEIS|id=A019345}}
:5 (5) → 3AE7
:B (11) → 1B834H69ED
:1B (29) → 0B31F95A9GDAE4H6EG28C781463D
:21 (37) → 08DB37565F184FA3G0H946EACBC2G9D27E1H
:27 (43) → 079B57H2GD721C293DEBCHA86CA0F14AFG5F8E4365
:2H (53) → 0620C41682CG57EAFB3D4788EGHBFH5DGB9F51CA3726E4DA9931
:35 (59) → 058F4A6CEBAC3BG30G89DD227GE0AHC92D7B53675E61EH19844FFA13H7
	
In base 19: {{OEIS|id=A019346}}
:2 (2) → 9
:7 (7) → 2DAG58
:B (11) → 1DFA6H538C
:D (13) → 18EBD2HA475G
:14 (23) → 0FD4291C784I35EG9H6BAE
:1A (29) → 0C89FDE7G73HD1I6A9354B2BF15H
:1I (37) → 09E73B5C631A52AEGHI94BF7D6CFH8DG8421

In [[vigesimal|base 20]]: {{OEIS|id=A019347}}
:3 (3) → 6D
:D (13) → 1AF7DGI94C63
:H (17) → 13ABF5HCIG984E27
:13 (23) → 0H7GA8DI546J2C39B61EFD
:1H (37) → 0AG469EBHGF2E11C8CJ93FDA58234H5II7B7
:23 (43) → 0960IC1H43E878GEHD9F6JADJ17I2FG5BCB3526A4D
:27 (47) → 08A4522B15ACF67D3GBI5J2JB9FEHH8IE974DC6G381E0H

In base 21: {{OEIS|id=A019348}}
:2 (2) → A
:J (19) → 1248HE7F9JIGC36D5B
:12 (23) → 0J3DECG92FAK1H7684BI5A
:18 (29) → 0F475198EA2IH7K5GDFJBC6AI23D
:1A (31) → 0E4FC4179A382EIK6G58GJDBAHCI62
:2B (53) → 086F9AEDI4FHH927J8F13K47B1KCE5BA672G533BID1C5JH0GD9J
:38 (71) → 06493BB50C8I721A13HFE42K27EA785J4F7KEGBH99FK8C2DIJAJH356GI0ID6ADCF1G5D

In base 22: {{OEIS|id=A019349}}
:5 (5) → 48HD
:H (17) → 16A7GI2CKFBE53J9
:J (19) → 13A95H826KIBCG4DJF
:19 (31) → 0FDAE45EJJ3C194L68B7HG722I9KCH
:1F (37) → 0D1H57G143CAFA2872L8K4GE5KHI9B6BJDEJ
:1J (41) → 0BHFC7B5JIH3GDKK8CJ6LA469EAG234I5811D92F
:23 (47) → 0A6C3G897L18JEB5361J44ELBF9I5DCE0KD27AGIFK2HH7

In base 23: {{OEIS|id=A019350}}
:2 (2) → B
:3 (3) → 7F
:5 (5) → 4DI9
:H (17) → 182G59AILEK6HDC4
:21 (47) → 0B5K1AHE496JD4KCGEFF3L0MBH2LC58IDG39I2A6877J1M
:2D (59) → 08M51CJK65AC1LJ27I79846E9H3BFME0HLA32GHCAL13KF4FDEIG8D5JB7
:3K (89) → 05LG6ADG0BK9CL4910HJ2J8I21CF5FHD4327B8C3864EMH16GC96MB2DA1IDLM53K3E4KLA7H759IJKFBEAJEGI8

In base 24: {{OEIS|id=A019351}}
:7 (7) → 3A6KDH
:B (11) → 248HALJF6D
:D (13) → 1L795CM3GEIB
:H (17) → 19L45FCGME2JI8B7
:17 (31) → 0IDMAK327HJ8C96N5A1D3KLG64FBEH
:1D (37) → 0FDEM1735K2E6BG54CN8A91MGKI3L9HC7IJB
:1H (41) → 0E14284G98IHDB2M5KBGN9MJLFJ7EF56ACL1I3C7

In base 25:
:2 (2) → C
:(no others)

Note that in ternary (''b'' = 3), the case ''p'' = 2 yields 1 as a cyclic number. While single digits may be considered trivial cases, it may be useful for completeness of the theory to consider them only when they are generated in this way.

It can be shown that no cyclic numbers (other than trivial single digits, i.e. ''p'' = 2) exist in any numeric base which is a [[Square number|perfect square]], that is, base 4, 9, 16, 25, etc.

== See also ==
*[[Repeating decimal]]
*[[Fermat's little theorem]]
*[[Cyclic permutation of integer]]
*[[Parasitic number]]

== References ==
{{Reflist}}

==Further reading==
*Gardner, Martin. Mathematical Circus: More Puzzles, Games, Paradoxes and Other Mathematical Entertainments From Scientific American. New York: The Mathematical Association of America, 1979. pp.&amp;nbsp;111–122.
*Kalman, Dan; 'Fractions with Cycling Digit Patterns'  The College Mathematics Journal, Vol. 27, No. 2. (Mar., 1996), pp.&amp;nbsp;109–115.
* Leslie, John. ''"The Philosophy of Arithmetic: Exhibiting a Progressive View of the Theory and Practice of ...."'', Longman, Hurst, Rees, Orme, and Brown, 1820, {{ISBN|1-4020-1546-1}}
*Wells, David; ''"[[The Penguin Dictionary of Curious and Interesting Numbers]]"'',  Penguin Press.  {{ISBN|0-14-008029-5}}

==External links==
* {{MathWorld | urlname=CyclicNumber | title=Cyclic Number}}
* [https://www.youtube.com/watch?v=WUlaUalgxqI Youtube: "Cyclic Numbers - Numberphile"]

{{Classes of natural numbers}}
[[Category:Number theory]]
[[Category:Permutations]]</text>
      <sha1>gsxoltlxixo0ywm749f6p8ng749guox</sha1>
    </revision>
  </page>
  <page>
    <title>Differential Equations (journal)</title>
    <ns>0</ns>
    <id>30667752</id>
    <revision>
      <id>828310263</id>
      <parentid>797648147</parentid>
      <timestamp>2018-03-01T20:29:25Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>Fix [[:Category:Pages using deprecated image syntax]]; [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1782">{{Infobox journal
 | title        = Differential Equations
 | cover        = Differential Equations (journal).jpg
 | abbreviation = Differ. Equ.
 | discipline   = [[Differential equations]]
 | editor       = {{nowrap|1=[[Vladimir Aleksandrovich Il'in (matematician)|Vladimir A. Il'in]]}}
 | publisher    = [[Springer Science+Business Media|Springer]]
 | frequency    = Monthly
 | history      = 1965–present
 | impact       = 0.339
 | impact-year  = 2009
 | url          = https://www.springer.com/mathematics/dynamical+systems/journal/10625
 | ISSN         = 0012-2661
 | eISSN        = 1608-3083
 | CODEN        = DIEQAN
 | LCCN         = sf78000494
 | OCLC         = 01566629
 | link1        = http://www.springerlink.com/content/1608-3083/ 
 | link1-name   = Online access
}}

''''' Differential Equations''''' is a [[peer review|peer-reviewed]] [[mathematics journal]] published by [[Springer Science+Business Media|Springer]]. Founded in 1965, the journal publishes English translations of papers from the journal ''Differentsial'nye Uravneniya'' ({{ISSN|0374-0641}}), which publishes in Russian and focuses on work by scholars in states of the former USSR. 
The journal is indexed by ''[[Mathematical Reviews]]'' and [[Zentralblatt MATH]].
Its 2009 [[Mathematical Citation Quotient|MCQ]] was 0.12, and its 2009 [[impact factor]] was 0.339.

==External links==
*{{Official|1=https://www.springer.com/mathematics/dynamical+systems/journal/10625}}
* Homepage of [http://www.ac.by/publications/difur/ Differentsial'nye Uravneniya] (English)

[[Category:Mathematics journals]]
[[Category:Publications established in 1965]]
[[Category:English-language journals]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:Monthly journals]]


{{math-journal-stub}}</text>
      <sha1>pztw2reju7vyvr99k2dgs420v2nlk0u</sha1>
    </revision>
  </page>
  <page>
    <title>Direct limit</title>
    <ns>0</ns>
    <id>211566</id>
    <revision>
      <id>843822020</id>
      <parentid>837266445</parentid>
      <timestamp>2018-05-31T18:01:52Z</timestamp>
      <contributor>
        <ip>140.192.196.237</ip>
      </contributor>
      <comment>Changed "oppresses" to "suppresses", which is undoubtedly what the author actually meant.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12366">In [[mathematics]], a '''direct limit''' is a way to construct a (typically large) object from many (typically smaller) objects that are put together in a specific way. These objects may be [[Group (mathematics)|groups]], [[Ring (mathematics)|rings]], [[Vector space|vector spaces]] or in general objects from any [[Category (mathematics)|category]]. The way they are put together is specified by a system of [[Homomorphism|homomorphisms]] (group homomorphism, ring homomorphism, or in general morphisms in the category) between those smaller objects. The direct limit of the objects &lt;math&gt;A_i&lt;/math&gt;, where &lt;math&gt;i&lt;/math&gt; ranges over some [[directed set]] &lt;math&gt;I&lt;/math&gt;, is denoted by &lt;math&gt;\varinjlim A_i &lt;/math&gt;. (This is a slight [[abuse of notation]] as it suppresses the system of homomorphisms that is crucial for the structure of the limit.) 

Direct limits are a special case of the concept of [[limit (category theory)|colimit]] in [[category theory]]. Direct limits are [[Dual (category theory)|dual]] to [[Inverse limit|inverse limits]] which are a special case of [[Limit (category theory)|limits]] in category theory.

==Formal definition==
We will first give the definition for [[Algebraic structure|algebraic structures]] like [[Group (mathematics)|groups]] and [[Module (mathematics)|modules]], and then the general definition, which can be used in any [[Category (mathematics)|category]].

===Direct limits of algebraic objects===
In this section objects are understood to consist of underlying [[Set (mathematics)|sets]] with a given [[algebraic structure]], such as [[group (mathematics)|groups]], [[ring (mathematics)|rings]], [[module (mathematics)|modules]] (over a fixed ring), [[algebra over a field|algebras]] (over a fixed field), etc. With this in mind, ''[[homomorphism]]s'' are understood in the corresponding setting ([[group homomorphism]]s, etc.).

Let &lt;math&gt;\langle I,\le\rangle&lt;/math&gt; be a [[directed set]]. Let &lt;math&gt;\{A_i : i\in I\}&lt;/math&gt; be a family of objects [[index set|indexed]] by &lt;math&gt;I\,&lt;/math&gt; and  &lt;math&gt; f_{ij}\colon A_i \rightarrow A_j &lt;/math&gt; be a homomorphism for all &lt;math&gt;i \le j&lt;/math&gt; with the following properties:
# &lt;math&gt;f_{ii}\,&lt;/math&gt; is the identity of &lt;math&gt;A_i\,&lt;/math&gt;, and
# &lt;math&gt;f_{ik}= f_{jk}\circ f_{ij}&lt;/math&gt; for all &lt;math&gt;i\le j\le k&lt;/math&gt;.
Then the pair &lt;math&gt;\langle A_i,f_{ij}\rangle&lt;/math&gt; is called a direct system over &lt;math&gt;I&lt;/math&gt;.

The '''direct limit''' of the direct system &lt;math&gt;\langle A_i,f_{ij}\rangle&lt;/math&gt; is denoted by &lt;math&gt;\varinjlim A_i&lt;/math&gt; and is defined as follows. Its underlying set is the [[disjoint union]] of the &lt;math&gt;A_i\,&lt;/math&gt;'s [[Modulo (jargon)|modulo]] a certain {{nowrap|[[equivalence relation]] &lt;math&gt;\sim\,&lt;/math&gt;}}:

:&lt;math&gt;\varinjlim A_i = \bigsqcup_i A_i\bigg/\sim.&lt;/math&gt;

Here, if &lt;math&gt;x_i\in A_i&lt;/math&gt; and &lt;math&gt;x_j\in A_j&lt;/math&gt;, then &lt;math&gt;x_i\sim\, x_j&lt;/math&gt; [[iff]] there is some &lt;math&gt;k\in I&lt;/math&gt; with &lt;math&gt;i \le k&lt;/math&gt; and &lt;math&gt;j \le k&lt;/math&gt; and such that &lt;math&gt;f_{ik}(x_i) = f_{jk}(x_j)\,&lt;/math&gt;.
Heuristically, two elements in the disjoint union are equivalent if and only if they "eventually become equal" in the direct system. An equivalent formulation that highlights the duality to the [[inverse limit]] is that an element is equivalent to all its images under the maps of the direct system, i.e. &lt;math&gt;x_i\sim\, f_{ij}(x_i)&lt;/math&gt; whenever &lt;math&gt;i \le j&lt;/math&gt;.

One naturally obtains from this definition ''canonical functions'' &lt;math&gt;\phi_i \colon A_i\rightarrow \varinjlim A_i&lt;/math&gt; sending each element to its equivalence class. The algebraic operations on &lt;math&gt;\varinjlim A_i\,&lt;/math&gt; are defined such that these maps become homomorphisms.  Formally, the direct limit of the direct system &lt;math&gt;\langle A_i,f_{ij}\rangle&lt;/math&gt; consists of the object &lt;math&gt;\varinjlim A_i&lt;/math&gt; together with the canonical homomorphisms &lt;math&gt;\phi_i \colon A_i\rightarrow \varinjlim A_i&lt;/math&gt;.

=== Direct limits in an arbitrary category ===
The direct limit can be defined in an arbitrary [[category (mathematics)|category]] &lt;math&gt;\mathcal{C}&lt;/math&gt; by means of a [[universal property]]. Let &lt;math&gt;\langle X_i, f_{ij}\rangle&lt;/math&gt; be a direct system of objects and morphisms in &lt;math&gt;\mathcal{C}&lt;/math&gt; (as defined above). A ''target'' is a pair &lt;math&gt;\langle X, \phi_i\rangle&lt;/math&gt; where &lt;math&gt;X\,&lt;/math&gt; is an object in &lt;math&gt;\mathcal{C}&lt;/math&gt; and &lt;math&gt;\phi_i\colon X_i\rightarrow X&lt;/math&gt; are morphisms for each &lt;math&gt;i\in I&lt;/math&gt; such that &lt;math&gt;\phi_i =\phi_j \circ f_{ij}&lt;/math&gt; whenever  &lt;math&gt;i \le j&lt;/math&gt;. A direct limit of the direct system &lt;math&gt;\langle X_i, f_{ij}\rangle&lt;/math&gt; is a ''universally repelling target'' &lt;math&gt;\langle X, \phi_i\rangle&lt;/math&gt; in the sense that &lt;math&gt;\langle X, \phi_i\rangle&lt;/math&gt; is a target and for each target &lt;math&gt;\langle Y, \psi_i\rangle&lt;/math&gt;, there is a unique morphism &lt;math&gt; u\colon X\rightarrow Y&lt;/math&gt; such that &lt;math&gt;u\circ \phi_i=\psi_i&lt;/math&gt; for each ''i''. The following diagram
&lt;div style="text-align: center;"&gt;[[Image:Direct limit category.svg]]&lt;/div&gt;
will then [[commutative diagram|commute]] for all ''i'', ''j''. 

The direct limit is often denoted
:&lt;math&gt;X = \varinjlim X_i&lt;/math&gt;
with the direct system &lt;math&gt;\langle X_i, f_{ij}\rangle&lt;/math&gt; and the canonical morphisms &lt;math&gt;\phi_i&lt;/math&gt; being understood.

Unlike for algebraic objects, not every direct system in an arbitrary category has a direct limit. If it does, however, the direct limit is unique in a strong sense: given another direct limit ''X''′ there exists a ''unique'' [[isomorphism]] ''X''′ → ''X'' that commutes with the canonical morphisms.

==Examples==
*A collection of subsets &lt;math&gt;M_i&lt;/math&gt; of a set ''M'' can be [[Partial order|partially ordered]] by inclusion. If the collection is directed, its direct limit is the union &lt;math&gt;\bigcup M_i&lt;/math&gt;. The same is true for a directed collection of [[Subgroup|subgroups]] of a given group, or a directed collection of [[Subring|subrings]] of a given ring, etc.
*Let ''I'' be any directed set with a [[greatest element]] ''m''. The direct limit of any corresponding direct system is isomorphic to ''X''&lt;sub&gt;''m''&lt;/sub&gt; and the canonical morphism φ&lt;sub&gt;''m''&lt;/sub&gt;: ''X''&lt;sub&gt;''m''&lt;/sub&gt; → ''X'' is an isomorphism.
*Let ''K'' be a field. For a positive integer ''n'', consider the [[general linear group]] GL(''n;K'') consisting of invertible ''n'' x ''n'' - matrices with entries from ''K''. We have a group homomorphism GL(''n;K'') → GL(''n''+1;''K'') which enlarges matrices by putting a 1 in the lower right corner and zeros elsewhere in the last row and column. The direct limit of this system is the general linear group of ''K'', written as GL(''K''). An element of GL(''K'') can be thought off as an infinite invertible matrix which differs from the infinite identity matrix in only finitely many entries. The group GL(''K'') is of vital importance in [[algebraic K-theory]].
*Let ''p'' be a [[prime number]]. Consider the direct system composed of the [[Quotient group|factor groups]] '''Z'''/''p''&lt;sup&gt;''n''&lt;/sup&gt;'''Z''' and the homomorphisms '''Z'''/''p''&lt;sup&gt;''n''&lt;/sup&gt;'''Z''' → '''Z'''/''p''&lt;sup&gt;''n''+1&lt;/sup&gt;'''Z''' induced by multiplication by ''p''. The direct limit of this system consists of all the [[roots of unity]] of order some power of ''p'', and is called the [[Prüfer group]] '''Z'''(''p''&lt;sup&gt;∞&lt;/sup&gt;).
*There is a (non-obvious) injective ring homomorphism from the ring of [[Symmetric polynomial|symmetric polynomials]] in ''n'' variables to the ring of symmetric polynomials in ''n+1'' variables. Forming the direct limit of this direct system yields the ring of symmetric functions.
*Let ''F'' be a ''C''-valued [[sheaf (mathematics)|sheaf]] on a [[topological space]] ''X''. Fix a point ''x'' in ''X''. The open neighborhoods of ''x'' form a directed set ordered by inclusion (''U'' ≤ ''V'' if and only if ''U'' contains ''V''). The corresponding direct system is (''F''(''U''), ''r''&lt;sub&gt;''U'',''V''&lt;/sub&gt;) where ''r'' is the restriction map. The direct limit of this system is called the ''[[stalk (mathematics)|stalk]]'' of ''F'' at ''x'', denoted ''F''&lt;sub&gt;''x''&lt;/sub&gt;. For each neighborhood ''U'' of ''x'', the canonical morphism ''F''(''U'') → ''F''&lt;sub&gt;''x''&lt;/sub&gt; associates to a section ''s'' of ''F'' over ''U'' an element ''s''&lt;sub&gt;''x''&lt;/sub&gt; of the stalk ''F''&lt;sub&gt;''x''&lt;/sub&gt; called the ''[[germ (mathematics)|germ]]'' of ''s'' at ''x''.
*Direct limits in the [[category of topological spaces]] are given by placing the [[final topology]] on the underlying set-theoretic direct limit.

== Properties ==
Direct limits are linked to [[inverse limit]]s via

:&lt;math&gt;\mathrm{Hom} (\varinjlim X_i, Y) = \varprojlim \mathrm{Hom} (X_i, Y).&lt;/math&gt;

An important property is that taking direct limits in the category of [[module (mathematics)|modules]] is an [[exact functor]]. This means that if you start with a directed system of short exact sequences &lt;math&gt;0 \to A_i \to B_i \to C_i \to 0&lt;/math&gt; and form direct limits, you obtain a short exact sequence &lt;math&gt;0 \to \varinjlim A_i \to \varinjlim B_i \to \varinjlim C_i \to 0&lt;/math&gt;.

== Related constructions and generalizations ==
We note that a direct system in a category &lt;math&gt;\mathcal{C}&lt;/math&gt; admits an alternative description in terms of [[functor]]s. Any directed set &lt;math&gt;\langle I,\le \rangle&lt;/math&gt; can be considered as a [[small category]] &lt;math&gt;\mathcal{I}&lt;/math&gt; whose objects are the elements &lt;math&gt;I&lt;/math&gt; and there is a morphisms  &lt;math&gt;i\rightarrow j&lt;/math&gt; [[if and only if]] &lt;math&gt;i\le j&lt;/math&gt;. A direct system over &lt;math&gt;I&lt;/math&gt; is then the same as a [[covariant functor]] &lt;math&gt;\mathcal{I}\rightarrow \mathcal{C}&lt;/math&gt;. The [[Limit (category theory)|colimit]] of this functor is the same as the direct limit of the original direct system.

A notion closely related to direct limits are the [[Filtered category|filtered colimits]]. Here we start with a covariant functor &lt;math&gt;\mathcal J \to \mathcal C&lt;/math&gt; from a [[filtered category]] &lt;math&gt;\mathcal J&lt;/math&gt; to some category &lt;math&gt;\mathcal{C}&lt;/math&gt; and form the colimit of this functor. One can show that a category has all directed limits if and only if it has all filtered colimits, and a functor defined on such a category commutes with all direct limits if and only if it commutes with all filtered colimits.&lt;ref&gt;{{Cite book|url=https://books.google.de/books?id=iXh6rOd7of0C|title=Locally Presentable and Accessible Categories|last=Adamek|first=J.|last2=Rosicky|first2=J.|publisher=Cambridge University Press|year=1994|location=|pages=15|language=en}}&lt;/ref&gt;

Given an arbitrary category &lt;math&gt;\mathcal{C}&lt;/math&gt;, there may be direct systems in &lt;math&gt;\mathcal{C}&lt;/math&gt; which don't have a direct limit in &lt;math&gt;\mathcal{C}&lt;/math&gt; (consider for example the category of finite sets, or the category of finitely generated abelian groups). In this case, we can always embed &lt;math&gt;\mathcal{C}&lt;/math&gt; into a category &lt;math&gt;\text{Ind}(\mathcal{C})&lt;/math&gt; in which all direct limits exist; the objects of  &lt;math&gt;\text{Ind}(\mathcal{C})&lt;/math&gt; are called [[Ind-object|ind-objects]] of  &lt;math&gt;\mathcal{C}&lt;/math&gt;.  

The [[Dual (category theory)|categorical dual]] of the direct limit is called the [[inverse limit]]. As above, inverse limits can be viewed as limits of certain functors and are closely related to limits over cofiltered categories.

== Terminology ==
In the literature, one finds the terms "directed limit", "direct inductive limit", "directed colimit", "direct colimit" and "inductive limit" for the concept of direct limit defined above. The term "inductive limit" is ambiguous however, as some authors use it for the general concept of colimit.

== See also ==

* [[Direct limit of groups|Direct limits of groups]]

== Notes ==
{{refs}}

==References==
* {{Citation | last=Bourbaki | first=Nicolas | author-link=Nicolas Bourbaki | year=1968 | title=Elements of mathematics. Theory of sets | publisher=Hermann | location=Paris | series=Translated from French | mr=0237342 }}
* {{Citation |last=Mac Lane |first=Saunders |authorlink=Saunders Mac Lane |year=1998 |title=[[Categories for the Working Mathematician]] |edition=2nd |series=[[Graduate Texts in Mathematics]] |volume=5 |publisher=Springer-Verlag}}

{{Category theory}}

{{DEFAULTSORT:Direct Limit}}
[[Category:Limits (category theory)]]
[[Category:Abstract algebra]]</text>
      <sha1>lcnz6wuilft4vimppnz1vxypd14sq5f</sha1>
    </revision>
  </page>
  <page>
    <title>Double bind</title>
    <ns>0</ns>
    <id>937347</id>
    <revision>
      <id>871342425</id>
      <parentid>864990697</parentid>
      <timestamp>2018-11-30T12:22:05Z</timestamp>
      <contributor>
        <username>Japarthur</username>
        <id>12895600</id>
      </contributor>
      <minor/>
      <comment>Reorganizing references.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30800">{{distinguish|double-blind}}
{{Medical anthropology}}
A '''double bind''' is an emotionally distressing [[dilemma]] in [[communication]] in which an individual (or group) receives two or more conflicting messages, with one negating the other. This creates a situation in which a successful response to one message results in a failed response to the other (and vice versa), so that the person will automatically be wrong regardless of response.  The double bind occurs when the person cannot confront the inherent dilemma, and therefore can neither resolve it nor opt out of the situation.

Double bind theory was first described by [[Gregory Bateson]] and his colleagues in the 1950s.&lt;ref name="schizophrenia"&gt;Bateson, G., Jackson, D. D., Haley, J. &amp; Weakland, J., 1956, Toward a theory of schizophrenia.''Behavioral Science'', Vol. 1, 251–264.&lt;/ref&gt;

Double binds are often utilized as a form of control without open coercion—the use of confusion makes them both difficult to respond to as well as to resist.&lt;ref name="ecology"&gt;{{cite book
 | author=Bateson, Gregory
 | title=Steps to an Ecology of Mind: Collected Essays in Anthropology, Psychiatry, Evolution, and Epistemology
 | publisher=University Of Chicago Press | year=1972}}&lt;/ref&gt;: 271-278.

A double bind generally includes different levels of abstraction in the order of messages and these messages can either be stated explicitly or implicitly within the context of the situation, or they can be conveyed by tone of voice or body language. Further complications arise when frequent double binds are part of an ongoing relationship to which the person or group is committed.&lt;ref name="schizophrenia"&gt;&lt;/ref&gt;&lt;ref name="ecology"&gt;&lt;/ref&gt;

==Explanation==
The double bind is often misunderstood to be a simple contradictory situation, where the subject is trapped by two conflicting demands. While it's true that the core of the double bind is two conflicting demands, the difference lies in how they are imposed upon the subject, what the subject's understanding of the situation is, and who (or what) imposes these demands upon the subject. Unlike the usual [[no-win situation]], the subject has difficulty in defining the exact nature of the [[paradox]]ical situation in which he or she is caught. The [[contradiction]] may be unexpressed in its immediate context and therefore invisible to external observers, only becoming evident when a prior communication is considered. Typically, a demand is imposed upon the subject by someone whom he or she respects (such as a parent, teacher, or doctor) but the demand itself is inherently impossible to fulfill because some broader context forbids it. For example, this situation arises when a person in a position of [[authority]] imposes two contradictory conditions but there exists an unspoken rule that one must never question authority.

Gregory Bateson and his colleagues defined the double bind as follows&lt;ref name="schizophrenia"/&gt; (paraphrased):
{{ordered list|start=1
| The situation involves two or more people, one of whom (for the purpose of the definition), is designated as the "subject". The others are people who are considered the subject's superiors: figures of authority (such as parents), whom the subject respects.
| Repeated experience: the double bind is a recurrent theme in the experience of the subject, and as such, cannot be resolved as a single traumatic experience.
| A ‘primary [[injunction]]’ is imposed on the subject by the others generally in one of two forms:
*(a) “Do ''X'', or I will punish you”;
*(b) “Do not do ''X'', or I will punish you.”
The punishment may include the withdrawing of love, the expression of hate and anger, or abandonment resulting from the authority figure's expression of helplessness.
|4= A ‘secondary injunction’ is imposed on the subject, conflicting with the first at a higher and more abstract level. For example: “You must do ''X'', but only do it because you want to.” It is unnecessary for this injunction to be expressed verbally.
|5= If necessary, a ‘tertiary injunction’ is imposed on the subject to prevent them from escaping the dilemma. See phrase examples below for clarification.
|6= Finally, Bateson states that the complete list of the previous requirements may be unnecessary, in the event that the subject is already viewing their world in double bind patterns. Bateson goes on to give the general characteristics of such a relationship:
{{ordered list|type=lower-alpha
|1= ''When the subject is involved in an intense relationship; that is, a relationship in which he feels it is vitally important that he discriminate accurately what sort of message is being communicated so that he may respond appropriately;''
|2= ''And, the subject is caught in a situation in which the other person in the relationship is expressing two orders of message and one of these denies the other;''
|3= ''And, the subject is unable to comment on the messages being expressed to correct his discrimination of what order of message to respond to: i.e., he cannot make a [[Metacommunicative competence|metacommunicative]] statement.''
}}}}

Thus, the essence of a double bind is two conflicting demands, ''each on a different logical level'', neither of which can be ignored or escaped. This leaves the subject torn both ways, so that whichever demand they try to meet, the other demand cannot be met. "I must do it, but I can't do it" is a typical description of the double-bind experience.

For a double bind to be effective, the subject must be unable to confront or resolve the conflict between the demand placed by the primary injunction and that of the secondary injunction. In this sense, the double bind differentiates itself from a simple contradiction to a more inexpressible internal conflict, where the subject really ''wants'' to meet the demands of the primary injunction, but fails each time through an inability to address the situation's incompatibility with the demands of the secondary injunction. Thus, subjects may express feelings of extreme [[anxiety]] in such a situation, as they attempt to fulfil the demands of the primary injunction albeit with obvious contradictions in their actions.

This was a problem in United States legal circles prior to the [[Fifth Amendment to the United States Constitution]] being [[Incorporation of the Bill of Rights|applied to state action]]. A person could be subpoenaed to testify in a federal case and given Fifth Amendment immunity for testimony in that case. However, since the immunity did not apply to a state prosecution, the person could refuse to testify at the Federal level despite being given immunity, thus subjecting the person to imprisonment for contempt of court, or the person could testify, and the information he or she was forced to give in the Federal proceeding could then be used to convict the person in a state proceeding.&lt;ref&gt;[https://supreme.justia.com/cases/federal/us/378/52/case.html Murphy v. Waterfront Comm'n], 378 U.S. 52 (1964) ("One jurisdiction in our federal system may not, absent an immunity provision, compel a witness to give testimony which might incriminate him under the laws of another jurisdiction.")&lt;/ref&gt;

==History==
The term ''double bind'' was first used by the [[anthropologist]] [[Gregory Bateson]] and his colleagues (including [[Donald deAvila Jackson|Don D. Jackson]], [[Jay Haley]] and [[John Weakland|John H. Weakland]]) in the mid-1950s in their discussions on complexity of communication in relation to [[schizophrenia]]. Bateson made clear that such complexities are common in normal circumstances, especially in "play, humour, poetry, ritual and fiction" (see [[#Theory of logical types|Logical Types]] below). Their findings indicated that the tangles in communication often diagnosed as schizophrenia are not necessarily the result of an organic brain dysfunction. Instead, they found that destructive double binds were a frequent pattern of communication among families of patients, and they proposed that growing up amidst perpetual double binds could lead to learned patterns of confusion in thinking and communication.

==Complexity in communication==
Human communication is complex, and context is an essential part of it. Communication consists of the words said, tone of voice, and body language. It also includes how these relate to what has been said in the past; what is not said, but is implied; how these are modified by other nonverbal cues, such as the environment in which it is said, and so forth. For example, if someone says "I love you", one takes into account who is saying it, their [[tone of voice]] and [[body language]], and the context in which it is said. It may be a declaration of passion or a serene reaffirmation, insincere and/or manipulative, an implied demand for a response, a joke, its public or private context may affect its [[Meaning (linguistics)|meaning]], and so forth.

Conflicts in communication are common and often we ask "What do you mean?" or seek clarification in other ways. This is called ''[[meta-communication]]:'' communication about the communication.&lt;ref&gt;{{Cite news|url=https://psychcentral.com/lib/meta-communication-what-i-said-isnt-what-i-meant/|title=Meta-communication: What I Said Isn’t What I Meant {{!}} Psych Central|date=2016-05-17|newspaper=Psych Central|access-date=2017-02-21|language=en-US}}&lt;/ref&gt; Sometimes, asking for clarification is impossible. Communication difficulties in ordinary life often occur when meta-communication and feedback systems are lacking or inadequate or there isn't enough time for clarification.
 
Double binds can be extremely stressful and become destructive when one is trapped in a dilemma and punished for finding a way out.  But making the effort to find the way out of the trap can lead to emotional growth.

==Examples==
The classic example given of a negative double bind is of a mother telling her child that she loves him or her, while at the same time turning away in disgust, or inflicting [[corporal punishment]] as discipline:&lt;ref&gt;Koopmans, Mathijs. [http://www.goertzel.org/dynapsyc/1997/Koopmans.html] ''Schizophrenia and the Family: Double Bind Theory Revisited'' 1997.&lt;/ref&gt; the words are socially acceptable; the body language is in conflict with it. The child does not know how to respond to the conflict between the words and the body language and, because the child is dependent on the mother for basic needs, they are in a quandary. Small children have difficulty articulating contradictions verbally and can neither ignore them nor leave the relationship.

Another example is when one is commanded to "be spontaneous". The very command contradicts spontaneity, but it only becomes a double bind when one can neither ignore the command nor comment on the contradiction. 
Often, the contradiction in communication is not apparent to bystanders unfamiliar with previous communications.

===Phrase examples===
* Mother telling her child: "You must love me".
: The primary injunction here is the command itself: "you must"; the secondary injunction is the unspoken reality that love is spontaneous, that for the child to love the mother genuinely, it can only be of his or her own accord.
* Child-abuser to child: "You should have escaped from me earlier, now it's too late—because now, nobody will believe that you didn't want what I have done", while at the same time blocking all of the child's attempts to escape.

: Child-abusers often start the double-bind relationship by "[[Child grooming|grooming]]" the child, giving little concessions, or gifts or privileges to them, thus the primary injunction is: "You should like what you are getting from me!"

: When the child begins to go along (i.e. begins to like what she or he is receiving from the person), then the interaction goes to the next level and small [[victimization]] occurs, with the secondary injunction being: "I am punishing you! (for whatever reason the child-abuser is coming up with, e.g. "because you were bad/naughty/messy", or "because you deserve it", or "because you made me do it", etc.).

: If child shows any resistance (or tries to escape) from the abuser, then the words: "You should have escaped from me earlier (...)" serve as the third level or tertiary injunction.

: Then the loop starts to feed on itself, allowing for ever worse victimization to occur.

* Mother to son: "Leave your sister alone!", while the son knows his sister will approach and antagonize him to get him into trouble.

: The primary injunction is the command, which he will be punished for breaking. The secondary injunction is the knowledge that his sister will get into conflict with him, but his mother will not know the difference and will default to punishing him. He may be under the impression that if he argues with his mother, he may be punished. One possibility for the son to escape this double bind is to realize that his sister only antagonizes him to make him feel anxious (if indeed it is the reason behind his sister's behavior).

: If he were not bothered about punishment, his sister might not bother him. He could also leave the situation entirely, avoiding both the mother and the sister. The sister can't claim to be bothered by a non-present brother, and the mother can't punish (nor scapegoat) a non-present son. Other solutions exist too, which are based on the creative application of logic and reasoning.
: An apt reply would be: "Please tell sis the same". If mother wants to 'scapegoat' him, her response will be negative. The command has a negative undertone towards the son.

== Positive double binds ==

Bateson also described positive double binds, both in relation to [[Zen Buddhism]] with its path of spiritual growth, and the use of therapeutic double binds by psychiatrists to confront their patients with the contradictions in their life in such a way that would help them heal. One of Bateson's consultants, [[Milton H. Erickson]] (5 volumes, edited by Rossi) eloquently demonstrated the productive possibilities of double binds through his own life, showing the technique in a brighter light.

== Science ==

One of the causes of double binds is the loss of [[feedback]] systems.  Gregory Bateson and Lawrence S. Bale describe double binds that have arisen in science that have caused decades-long delays of progress in science because the scientific community had defined something as outside of its scope (or as "not science")—see Bateson in his ''Introduction'' to Steps to an Ecology of Mind (1972, 2000), pp. xv–xxvi; and Bale in his article, ''Gregory Bateson, Cybernetics and the Social/Behavioral Sciences'' (esp. pp.&amp;nbsp;1–8) on the paradigm of classical science vs. that of systems theory/cybernetics. (See also Bateson's description in his ''Forward'' of how the double bind hypothesis fell into place).

==  Work by Bateson  ==

=== Schizophrenia ===
The Double Bind Theory was first articulated in relationship to schizophrenia, but Bateson and his colleagues hypothesized that schizophrenic thinking was not necessarily an inborn mental disorder but a learned confusion in thinking.
It is helpful to remember the context in which these ideas were developed. Bateson and his colleagues were working in the Veteran's Administration Hospital (1949–1962) with World War II veterans. As soldiers they'd been able to function well in combat, but the effects of life-threatening stress had affected them.  At that time, 18 years before Post-Traumatic Stress Disorder was officially recognized, the veterans had been saddled with the catch-all diagnosis of schizophrenia.  Bateson didn't challenge the diagnosis but he did maintain that the seeming nonsense the patients said at times did make sense within context, and he gives numerous examples in section III of ''Steps to an Ecology of Mind'', "Pathology in Relationship". For example, a patient misses an appointment, and when Bateson finds him later the patient says 'the judge disapproves'; Bateson responds, "You need a defense lawyer" see following (pp.&amp;nbsp;195–6) Bateson also surmised that people habitually caught in double binds in childhood would have greater problems—that in the case of the schizophrenic, the double bind is presented continually and habitually within the family context from infancy on. By the time the child is old enough to have identified the double bind situation, it has already been internalized, and the child is unable to confront it. The solution then is to create an escape from the conflicting logical demands of the double bind, in the world of the [[delusion]]al system (see in ''Towards a Theory of Schizophrenia&amp;nbsp;– Illustrations from Clinical Data'').

One solution to a double bind is to place the problem in a larger context, a state Bateson identified as Learning III, a step up from Learning II (which requires only learned responses to reward/consequence situations). In Learning III, the double bind is contextualized and understood as an impossible no-win scenario so that ways around it can be found.

Bateson's double bind theory was never followed up by research into whether family systems imposing systematic double binds might be a cause of schizophrenia.  This complex theory has been only partly tested, and there are gaps in the current [[Psychology|psychological]] and experimental evidence required to establish [[wikt:causation|causation]] [citation?]. The current understanding of [[schizophrenia]] emphasizes the robust scientific evidence for a genetic predisposition to the disorder, with psychosocial stressors, including dysfunctional family interaction patterns, as secondary causative factors in some instances.

=== Evolution ===

After many years of research into schizophrenia, Bateson continued to explore problems of communication and learning, first with dolphins, and then with the more abstract processes of [[evolution]]. Bateson emphasised that any communicative system characterized by different logical levels might be subject to double bind problems. Especially including the communication of characteristics from one generation to another (genetics and evolution).

"...evolution always followed the pathways of viability. As Lewis Carroll has pointed out, the theory [of natural selection] explains quite satisfactorily why there are no bread-and-butter-flies today."&lt;ref&gt;{{cite journal|last=Bateson|first=Gregory|title=Cybernetic Explanation|journal=American Behavioral Scientist|date=April 1967|volume=10|issue=8|pages=29–32|doi=10.1177/0002764201000808 }}&lt;/ref&gt;

Bateson used the fictional Bread and Butter Fly (from ''[[Through the Looking-Glass|Through the Looking Glass, and What Alice Found There]]'') to illustrate the double bind in terms of natural selection. The gnat points out that the insect would be doomed if he found his food (which would dissolve his own head), and starve if he did not. Alice suggests that this must happen quite often, to which the gnat replies "it always happens".

The pressures that drive evolution therefore represent a genuine double bind. And there is truly no escape: "It always happens." No species can escape natural selection, including our own.

Bateson suggested that all evolution is driven by the double bind, whenever circumstances change: If any environment becomes toxic to any species, that species will die out unless it transforms into another species, in which case, the species becomes extinct anyway.

Most significant here is Bateson's exploration of what he later came to call 'the pattern that connects'&lt;ref&gt;{{cite book|last=Bateson|first=Gregory|title=Mind and Nature|year=1979|isbn=978-1-57273-434-0}}&lt;/ref&gt;&amp;mdash;that problems of communication which span more than one level (e.g., the relationship between the individual and the family) should also be expected to be found spanning other pairs of levels in the hierarchy (e.g. the relationship between the genotype and the phenotype):

"We are very far, then, from being able to pose specific questions for the geneticist; but I believe that the wider implications of what I have been saying modify somewhat the philosophy of genetics. Our approach to the problems of schizophrenia by way of a theory of levels or logical types has disclosed first that the problems of adaptation and learning and their pathologies must be considered in terms of a hierarchic system in which stochastic change occurs at the boundary points between the segments of the hierarchy. We have considered three such regions of stochastic change&amp;mdash;the level of genetic mutation, the level of learning, and the level of change in family organization. We have disclosed the possibility of a relationship of these levels which orthodox genetics would deny, and we have disclosed that at least in human societies the evolutionary system consists not merely in the selective survival of those persons who happen to select appropriate environments but also in the modification of family environment in a direction which might enhance the phenotypic and genotypic characteristics of the individual members."
&lt;ref&gt;{{cite journal|last=Bateson|first=Gregory|journal=Archives of General Psychiatry|year=1960|volume=2|issue=5|pages=477–491|doi=10.1001/archpsyc.1960.03590110001001|title=Minimal Requirements for a Theory of Schizophrenia*}}&lt;/ref&gt;

=={{anchor|Double bind and mimesis}}Girard's mimetic double bind&lt;!-- 'Mimetic double bind' redirects here --&gt;==
[[René Girard]], in his [[literary theory]] of [[René Girard#Mimetic desire|mimetic desire]],&lt;ref&gt;{{cite web |url=http://www.cottet.org/girard/gintro.en.htm |title=Introduction—René Girard |date=5 November 2010 |at="The hypothesis"}} [http://www.cottet.org/girard/index.htm Version française «L'hypothèse»].&lt;/ref&gt; proposes what he calls a "model-obstacle", a [[role model]] who demonstrates an object of desire and yet, in possessing that object, becomes a rival who obstructs fulfillment of the desire.&lt;ref name="girard1965deceit"&gt;{{cite book |first=René |last=Girard |authorlink=René Girard |year=1965 |title=Deceit, Desire, and the Novel: Self and Other in Literary Structure |series=Deceit, Desire, and the Novel |lccn=65028582 |url=https://books.google.com/books?id=ONlZAAAAMAAJ |page=101}}&lt;/ref&gt; According to Girard, the "internal mediation" of this [[mimesis|mimetic]] dynamic "operates along the same lines as what Gregory Bateson called the ‘double bind’."&lt;ref name="fleming2004rene"&gt;{{cite book |first=C. |last=Fleming |year=2004 |title=René Girard: Violence and Mimesis |series=Key Contemporary Thinkers |isbn=978-0-7456-2947-6 |lccn=ocm56438393 |url=https://books.google.com/books?id=gVh3QgAACAAJ |page=20}}&lt;/ref&gt; Girard found in [[Sigmund Freud|Sigmund Freud's]] psychoanalytic theory, a precursor to mimetic desire.&lt;ref name="meloni2002jep14"&gt;{{cite journal |first=Maurizio |last=Meloni |year=2002 |title=A Triangle of Thoughts: Girard, Freud, Lacan |journal=Journal of European Psychoanalysis |volume=Winter-Spring |number=14 |url=http://www.psychomedia.it/jep/number14/meloni.htm}}&lt;/ref&gt; "The individual who 'adjusts' has managed to relegate the two contradictory injunctions of the double bind—to imitate and not to imitate—to two different domains of application. This is, he divides reality in such a way as to neutralize the ''double bind''."&lt;ref name="girard2005violence"&gt;{{cite book |first=René |last=Girard |first2=Patrick |last2=Gregory |year=2005 |title=Violence and the Sacred |series=Continuum Impacts |isbn=978-0-8264-7718-7 |lccn=77004539 |url=https://books.google.com/books?id=RGVKsW5rQ1kC&amp;lpg=PA156&amp;pg=PA156 |pages=187–188, 156–157}}&lt;/ref&gt; While critical of Freud's doctrine of the [[unconscious mind]], Girard sees the ancient Greek tragedy, ''[[Oedipus Rex]]'', and key elements of Freud's [[Oedipus complex]], [[patricide|patricidal]] and [[incest]]uous desire, to serve as prototypes for his own analysis of the '''mimetic double bind'''&lt;!--boldface per WP:R#PLA--&gt;.&lt;ref name="girard2005violence"/&gt;

{{quote|Far from being restricted to a limited number of pathological cases, as American theoreticians suggest, the double bind—a contradictory double imperative, or rather a whole network of contradictory imperatives—is an extremely common phenomenon. In fact, it is so common that it might be said to form the basis of all human relationships.

Bateson is undoubtedly correct in believing that the effects of the double bind on the child are particularly devastating. All the grown-up voices around him, beginning with those of the father and mother (voices which, in our society at least, speak for the culture with the force of established authority) exclaim in a variety of accents, "Imitate us!" "Imitate me!" "I bear the secret of life, of true being!" The more attentive the child is to these seductive words, and the more earnestly he responds to the suggestions emanating from all sides, the more devastating will be the eventual conflicts. The child possesses no perspective that will allow him to see things as they are. He has no basis for reasoned judgements, no means of foreseeing the metamorphosis of his model into a rival. This model's opposition reverberates in his mind like a terrible condemnation; he can only regard it as an act of excommunication. The future orientation of his desires—that is, the choice of his future models—will be significantly affected by the dichotomies of his childhood. In fact, these models will determine the shape of his personality.

If desire is allowed its own bent, its mimetic nature will almost always lead it into a double bind. The unchanneled mimetic impulse hurls itself blindly against the obstacle of a conflicting desire. It invites its own rebuffs and these rebuffs will in turn strengthen the mimetic inclination. We have, then, a self-perpetuating process, constantly increasing in simplicity and fervor. Whenever the disciple borrows from his model what he believes to be the "true" object, he tries to possess that truth by desiring precisely what this model desires. Whenever he sees himself closest to the supreme goal, he comes into violent conflict with a rival. By a mental shortcut that is both eminently logical and self-defeating, he convinces himself that the violence itself is the most distinctive attribute of this supreme goal! Ever afterward, violence will invariably awaken desire...|[[René Girard]]|''Violence and the Sacred'': "From Mimetic Desire to the Monstrous Double", pp.156–157}}

==Neuro-linguistic programming==
The field of [[neuro-linguistic programming]] also makes use of the expression "double bind". [[John Grinder|Grinder]] and [[Richard Bandler|Bandler]] (both of whom had personal contact with Bateson and Erickson) asserted that a message could be constructed with multiple messages, whereby the recipient of the message is given the impression of choice—although both options have the same outcome at a higher level of intention. This is called a "double bind" in NLP terminology,&lt;ref name="Bandler &amp; Grinder 1981"&gt;Bandler, R., Grinder, J. (1981) Reframing: Neuro-Linguistic Programming and the Transformation of Meaning Real People Press. {{ISBN|0-911226-25-7}}&lt;/ref&gt; and has applications in both sales and therapy. In therapy, the practitioner may seek to challenge destructive double binds that limit the client in some way and may also construct double binds in which both options have therapeutic consequences. In a sales context, the speaker may give the respondent the illusion of choice between two possibilities. For example, a salesperson might ask: "Would you like to pay cash or by credit card?", with both outcomes presupposing that the person will make the purchase; whereas the third option (that of not buying) is intentionally excluded from the spoken choices.

Note that in the NLP context, the use of the phrase "double bind" does not carry the primary definition of two conflicting messages; it is about creating a false sense of choice which ultimately binds to the intended outcome. In the "cash or credit card?" example, this is not a "Bateson double bind" since there is no contradiction, although it still is an "NLP double bind". Similarly if a salesman were selling a [[Steal This Book|book about the evils of commerce]], it could perhaps be a "Bateson double bind" if the buyer happened to believe that commerce was evil, yet felt compelled or obliged to buy the book.

==See also==
{{columns-list|colwidth=22em|
* [[Ambiguity]]
* [[Buridan's bridge]]
* [[Catch-22 (logic)]]
* [[Cognitive dissonance]]
* [[Dialectic]]
* [[Doublethink]]
* [[Evaporating Cloud]]
* [[Expressed emotion]]
* [[False dilemma]]
* [[Four sides model]]
* [[Loaded question]]
* [[Master suppression techniques]]
* [[Mutually exclusive events]]
* [[No-win situation]]
* [[Procrastination]]
* [[Psychological manipulation]]
* [[R. D. Laing]]
* [[Self and Others]]
* [[Self-reference]]
* [[Zeno's Paradoxes]]
* [[Zugzwang]]
}}

==Notes==
{{reflist}}

==References==
* {{cite book |last=Watts|first=Alan|authorlink=Alan Watts|title= The Way of Zen|year= 1957|publisher= Pantheon Books|isbn= 0-375-70510-4}}
* {{cite book |last=Watts|first=Alan|authorlink=Alan Watts|title= Psychotherapy: East &amp; West|year= 1961|publisher= Pantheon Books|isbn= 0-394-71609-4}}
* Bateson, Gregory. (1972, 1999) ''Steps to an Ecology of Mind: Collected Essays in Anthropology, Psychiatry, Evolution, and Epistemology''.''Part III: Form and Pathology in Relationship''. University of Chicago Press, 1999, originally published, San Francisco: Chandler Pub. Co., 1972.
*Gibney, Paul (May 2006) The Double Bind Theory:  Still Crazy-Making After All These Years. in ''Psychotherapy in Australia''. Vol. 12. No. 3. http://www.psychotherapy.com.au/TheDoubleBindTheory.pdf
*Koopmans, Matthijs (1998) Schizophrenia and the Family II:  Paradox and Absurdity in Human Communication Reconsidered. http://www.goertzel.org/dynapsyc/1998/KoopmansPaper.htm
*Zysk, Wolfgang (2004), ″Körpersprache – Eine neue Sicht″, Doctoral Dissertation 2004, University Duisburg-Essen (Germany).

==External links==
*https://web.archive.org/web/20080211090234/http://www.mri.org/dondjackson/brp.htm
*http://www.behavenet.com/capsules/treatments/famsys/dblebnd.htm
*https://web.archive.org/web/20080215124155/http://laingsociety.org/cetera/pguillaume.htm
*[http://www.nlpuniversitypress.com/html/D48.html Reference in Encyclopedia of NLP]
*[http://mybelovedalter.wordpress.com/2009/02/24/a-poem-illustrating-the-flow-chart Double-bind loop feeding on itself, an illustration by chart (and a poem)]

{{Psychological manipulation}}

{{DEFAULTSORT:Double Bind}}
[[Category:Communication of falsehoods]]
[[Category:Cybernetics]]
[[Category:Systems psychology]]
[[Category:Dilemmas]]
[[Category:1956 introductions]]</text>
      <sha1>pa2qj28nda3i7drnhm96dz9r1bxays4</sha1>
    </revision>
  </page>
  <page>
    <title>Duality (mathematics)</title>
    <ns>0</ns>
    <id>609737</id>
    <revision>
      <id>868852229</id>
      <parentid>865013198</parentid>
      <timestamp>2018-11-14T21:29:21Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="50341">{{For|the property of optimization problems|Duality (optimization)}}

In [[mathematics]], a '''duality''', generally speaking, translates concepts, theorems or mathematical structures into other concepts, theorems or structures, in a one-to-one fashion, often (but not always) by means of an [[Involution (mathematics)|involution]] operation: if the dual of ''A'' is ''B'', then the dual of ''B'' is ''A''. Such involutions sometimes have [[fixed point (mathematics)|fixed points]], so that the dual of ''A'' is ''A'' itself. For example, [[Desargues' theorem]] is self-dual in this sense under the ''standard [[duality (projective geometry)|duality in projective geometry]]''.

In mathematical contexts, ''duality'' has numerous meanings&lt;ref&gt;{{harvnb|Atiyah|2007|page=1}}&lt;/ref&gt; although it is "a very pervasive and important concept in (modern) mathematics"&lt;ref&gt;{{harvnb|Kostrikin|2001}}{{page needed|date=July 2015}}&lt;/ref&gt; and "an important general theme that has manifestations in almost every area of mathematics".&lt;ref name="PCM187L"&gt;{{harvnb|Gowers|2008|loc=p.&amp;nbsp;187, col.&amp;nbsp;1}}&lt;/ref&gt;

Many mathematical dualities between objects of two types correspond to [[pairing]]s, [[bilinear function]]s from an object of one type and another object of the second type to some family of scalars. For instance, ''linear algebra duality'' corresponds in this way to bilinear maps from pairs of vector spaces to scalars, the ''duality between [[distribution (mathematics)|distributions]] and the associated [[test function]]s'' corresponds to the pairing in which one integrates a distribution against a test function, and ''[[Poincaré duality]]'' corresponds similarly to [[intersection number]], viewed as a pairing between submanifolds of a given manifold.&lt;ref name="PCM189R"&gt;{{harvnb|Gowers|2008|loc=p.&amp;nbsp;189, col.&amp;nbsp;2}}&lt;/ref&gt;

From a [[category theory]] viewpoint, duality can also be seen as a [[functor]], at least in the realm of vector spaces. This functor assigns to each space its dual space, and the [[pullback (category theory)|pullback]] construction assigns to each arrow {{nowrap|''f'': ''V'' → ''W''}} its dual {{nowrap|''f''&lt;sup&gt;∗&lt;/sup&gt;: ''W''&lt;sup&gt;∗&lt;/sup&gt; → ''V''&lt;sup&gt;∗&lt;/sup&gt;}}.

==Introductory examples==
In the words of [[Michael Atiyah]],
{{quote|Duality in mathematics is not a theorem, but a "principle".&lt;ref&gt;{{harvnb|Atiyah|2007|page=1}}&lt;/ref&gt;}}

The following list of examples shows the common features of many dualities, but also indicates that the precise meaning of duality may vary from case to case.

===Complement of a subset===
A simple, maybe the most simple, duality arises from considering [[subset]]s of a fixed set {{math|{{var|S}}}}. To any subset {{math|{{var|A}} &amp;sube; {{var|S}}}}, the [[complement (set theory)|complement]] {{math|{{var|A}}{{sup|{{var|c}}}}}}&lt;ref&gt;The complement is also denoted as {{math|{{var|S}} \ {{var|A}}}}.&lt;/ref&gt; consists of all those elements in {{math|{{var|S}}}} which are not contained in {{math|{{var|A}}}}. It is again a subset of {{math|{{var|S}}}}. Taking the complement has the following properties:
* Applying it twice gives back the original set, i.e., {{math|1=({{var|A}}{{sup|{{var|c}}}}){{sup|{{var|c}}}} = {{var|A}}}}. This is referred to by saying that the operation of taking the complement is an ''[[involution (mathematics)|involution]]''.
* An inclusion of sets {{math|{{var|A}} &amp;sube; {{var|B}}}} is turned into an inclusion in the ''opposite'' direction {{math|{{var|B}}{{sup|{{var|c}}}} &amp;sube; {{var|A}}{{sup|{{var|c}}}}}}.
* Given two subsets {{math|{{var|A}}}} and {{math|{{var|B}}}} of {{math|{{var|S}}}}, {{math|{{var|A}}}} is contained in {{math|{{var|B}}{{sup|{{var|c}}}}}} [[if and only if]] {{math|{{var|B}}}} is contained in {{math|{{var|A}}{{sup|{{var|c}}}}}}.

This duality appears in [[topology]] as a duality between [[open set|open]] and [[closed set|closed subset]]s of some fixed topological space {{math|{{var|X}}}}: a subset {{math|{{var|U}}}} of {{math|{{var|X}}}} is closed if and only if its complement in {{math|{{var|X}}}} is open.  Because of this, many theorems about closed sets are dual to theorems about open sets. For example, any union of open sets is open, so dually, any intersection of closed sets is closed.  The [[interior (topology)|interior]] of a set is the largest open set contained in it, and the [[closure (topology)|closure]] of the set is the smallest closed set that contains it.  Because of the duality, the complement of the interior of any set {{math|{{var|U}}}} is equal to the closure of the complement of {{math|{{var|U}}}}.

===Dual cone===
[[File:Dual cone illustration.svg|right|thumb|A set {{math|{{var|C}}}} (blue) and its dual cone {{math|{{var|C}}{{sup|*}}}} (red).]]
A duality in [[geometry]] is provided by the [[dual cone]] construction. Given a set &lt;math&gt;C&lt;/math&gt; of points in the plane &lt;math&gt;\mathbb R^2&lt;/math&gt; (or more generally points in {{nowrap|&lt;math&gt;\mathbb R^n&lt;/math&gt;),}} the dual cone is defined as the set &lt;math&gt;C^* \subseteq \mathbb R^2&lt;/math&gt; consisting of those points &lt;math&gt;(x_1, x_2)&lt;/math&gt; satisfying
{{block indent|&lt;math&gt;x_1 c_1 + x_2 c_2 \ge 0&lt;/math&gt;}}
for all points &lt;math&gt;(c_1, c_2)&lt;/math&gt; in &lt;math&gt;C&lt;/math&gt;, as illustrated in the diagram.
Unlike for the complement of sets mentioned above, it is not in general true that applying the dual cone construction twice gives back the original set &lt;math&gt;C&lt;/math&gt;. Instead, &lt;math&gt;C^{**}&lt;/math&gt; is the smallest cone&lt;ref&gt;More precisely, &lt;math&gt;C^**&lt;/math&gt; is the smallest [[closed set|closed]] [[convex set|convex]] cone containing &lt;math&gt;C&lt;/math&gt;.&lt;/ref&gt; containing &lt;math&gt;C&lt;/math&gt; which may be bigger than &lt;math&gt;C&lt;/math&gt;. Therefore this duality is weaker than the one above, in that
* Applying the operation twice gives back a possibly bigger set: for all &lt;math&gt;C&lt;/math&gt;, &lt;math&gt;C&lt;/math&gt; is contained in &lt;math&gt;C^{**}&lt;/math&gt;. (For some &lt;math&gt;C&lt;/math&gt;, namely the cones, the two are actually equal.)
The other two properties carry over without change:
* It is still true that an inclusion &lt;math&gt;C \subseteq D&lt;/math&gt; is turned into an inclusion in the opposite direction (&lt;math&gt;D^* \subseteq C^*&lt;/math&gt;).
* Given two subsets &lt;math&gt;C&lt;/math&gt; and &lt;math&gt;D&lt;/math&gt; of the plane, &lt;math&gt;C&lt;/math&gt; is contained in &lt;math&gt;D^*&lt;/math&gt; if and only if &lt;math&gt;D&lt;/math&gt; is contained in &lt;math&gt;C^*&lt;/math&gt;.

===Dual vector space===
A very important example of a duality arises in [[linear algebra]] by associating to any [[vector space]] {{math|{{var|V}}}} its [[dual vector space]] {{math|{{var|V}}{{sup|*}}}}. Its elements are the {{math|{{var|k}}}}-[[linear map]]s &lt;math&gt;\varphi: V \to k&lt;/math&gt;, where {{math|{{var|k}}}} is the [[field (mathematics)|field]] over which {{math|{{var|V}}}} is defined.
The three properties of the dual cone carry over to this type of duality by replacing subsets of &lt;math&gt;\mathbb R^2&lt;/math&gt; by vector space and inclusions of such subsets by linear maps. That is:
* Applying the operation of taking the dual vector space twice gives another vector space {{math|{{var|V}}{{sup|**}}}}. There is always a map {{math|{{var|V}} &amp;rarr; {{var|V}}{{sup|**}}}}. For some {{math|{{var|V}}}}, namely precisely the [[finite-dimensional vector space]]s, this map is an [[isomorphism]]. 
* A linear map {{math|{{var|V}} &amp;rarr; {{var|W}}}} gives rise to a map in the opposite direction ({{math|{{var|W}}{{sup|*}} &amp;rarr; {{var|V}}{{sup|*}}}}).
* Given two vector spaces {{math|{{var|V}}}} and {{math|{{var|W}}}}, the maps from {{math|{{var|V}}}} to {{math|{{var|W}}{{sup|*}}}} correspond to the maps from {{math|{{var|W}}}} to {{math|{{var|V}}{{sup|*}}}}.
A particular feature of this duality is that {{math|{{var|V}}}} and {{math|{{var|V}}{{sup|*}}}} are isomorphic for certain objects, namely finite-dimensional vector spaces. However, this is in a sense a lucky coincidence, for giving such an isomorphism requires a certain choice, for example the choice of a [[basis (linear algebra)|basis]] of {{math|{{var|V}}}}. This is also true in the case if {{math|{{var|V}}}} is a [[Hilbert space]], ''via'' the [[Riesz representation theorem]].

===Galois theory===

In all the dualities discussed before, the dual of an object is of the same kind as the object itself. For example, the dual of a vector space is again a vector space. Many duality statements are not of this kind. Instead, such dualities reveal a close relation between objects of seemingly different nature. One example of such a more general duality is from [[Galois theory]]. For a fixed [[Galois extension]] {{math|{{var|K}} / {{var|F}}}}, one may associate the [[Galois group]] {{math|Gal({{var|K}}/{{var|E}})}} to any intermediate field {{math|{{var|E}}}} (i.e., {{math|{{var|F}} &amp;sube; {{var|E}} &amp;sube; {{var|K}}}}). This group is a subgroup of the Galois group {{math|1={{var|G}} = Gal({{var|K}}/{{var|F}})}}. Conversely, to any such subgroup {{math|{{var|H}} &amp;sube; {{var|G}}}} there is the fixed field {{math|{{var|K}}{{sup|{{var|H}}}}}} consisting of elements fixed by the elements in {{math|{{var|H}}}}.

Compared to the above, this duality has the following features:
* An extension {{math|{{var|F}} &amp;sube; {{var|F}}&amp;prime;}} of intermediate fields gives rise to an inclusion of Galois groups in the opposite direction: {{math|Gal({{var|K}}/{{var|F}}&amp;prime;) &amp;sube; Gal({{var|K}}/{{var|F}})}}.
* Associating {{math|Gal({{var|K}}/{{var|E}})}} to {{math|{{var|E}}}} and {{math|{{var|K}}{{sup|{{var|H}}}}}} to {{math|{{var|H}}}} are inverse to each other. This is the content of the [[fundamental theorem of Galois theory]].

==Order-reversing dualities==
[[File:Upset.svg|thumb|[[Hasse diagram]] of the power set of {{math|{1,2,3,4}}}, partially ordered by {{math|⊂}}. The dual poset, i.e. ordering by {{math|⊃}}, is obtained by turning the diagram upside-down. The green nodes form an [[upper set]] and a lower set in the original and the dual order, respectively.]]
{{main article|Duality (order theory)}}
Given a [[poset]] {{math|1={{var|P}} = ({{var|X}}, ≤)}} (short for partially ordered set; i.e., a set that has a notion of ordering but in which two elements cannot necessarily be placed in order relative to each other), the [[duality (order theory)|dual]] poset {{math|1={{var|P}}{{sup|{{var|d}}}} = ({{var|X}}, ≥)}} comprises the same ground set but the [[converse relation]]. Familiar examples of dual partial orders include

* the subset and superset relations {{math|⊂}} and {{math|⊃}} on any collection of sets, such as the subsets of a fixed set {{math|{{var|S}}}}. This gives rise to the first example of a duality mentioned [[#Complement of a subset|above]].
* the ''divides'' and ''multiple-of'' relations on the [[integers]].
* the ''descendant-of'' and ''ancestor-of'' relations on the set of humans.

A ''duality transform'' is an [[involutive antiautomorphism]] {{math|{{var|f}}}} of a [[partially ordered set]] {{math|{{var|S}}}}, that is, an [[Order theory#Functions between orders|order-reversing]] involution {{math|{{var|f}} : {{var|S}} &amp;rarr; {{var|S}}}}.&lt;ref&gt;{{harvnb|Artstein-Avidan|Milman|2007}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Artstein-Avidan|Milman|2008}}&lt;/ref&gt; In several important cases these simple properties determine the transform uniquely up to some simple symmetries. For example, if {{math|{{var|f}}{{sub|1}}}}, {{math|{{var|f}}{{sub|2}}}} are two duality transforms then their [[Function composition|composition]] is an [[Order isomorphism|order automorphism]] of {{math|{{var|S}}}}; thus, any two duality transforms differ only by an order automorphism. For example, all order automorphisms of a [[power set]] {{math|1={{var|S}} = 2{{sup|{{var|R}}}}}} are induced by permutations of {{math|{{var|R}}}}.

A concept defined for a partial order {{math|{{var|P}}}} will correspond to a ''dual concept'' on the dual poset {{math|{{var|P}}{{sup|{{var|d}}}}}}. For instance, a [[minimal element]] of {{math|{{var|P}}}} will be a [[maximal element]] of {{math|{{var|P}}{{sup|{{var|d}}}}}}: minimality and maximality are dual concepts in order theory. Other pairs of dual concepts are [[upper and lower bounds]], [[lower set]]s and [[upper set]]s, and [[ideal (order theory)|ideals]] and [[filter (mathematics)|filters]].

In topology, [[open set]]s and [[closed set]]s are dual concepts: the complement of an open set is closed, and vice versa. In [[matroid]] theory, the family of sets complementary to the independent sets of a given matroid themselves form another matroid, called the [[dual matroid]].

==Dimension-reversing dualities==
[[File:Dual Cube-Octahedron.svg|thumb|200px|The features of the cube and its dual octahedron correspond one-for-one with dimensions reversed.]]
There are many distinct but interrelated dualities in which geometric or topological objects correspond to other objects of the same type, but with a reversal of the dimensions of the features of the objects. A classical example of this is the duality of the [[platonic solid]]s, in which the cube and the octahedron form a dual pair, the dodecahedron and the icosahedron form a dual pair, and the tetrahedron is '''self-dual'''.  The [[dual polyhedron]] of any of these polyhedra may be formed as the [[convex hull]] of the center points of each face of the primal polyhedron, so the [[vertex (geometry)|vertices]] of the dual correspond one-for-one with the faces of the primal. Similarly, each edge of the dual corresponds to an edge of the primal, and each face of the dual corresponds to a vertex of the primal. These correspondences are incidence-preserving: if two parts of the primal polyhedron touch each other, so do the corresponding two parts of the [[dual polyhedron]]. More generally, using the concept of [[pole and polar|polar reciprocation]], any [[convex polyhedron]], or more generally any [[convex polytope]], corresponds to a [[dual polyhedron]] or dual polytope, with an {{math|{{var|i}}}}-dimensional feature of an {{math|{{var|n}}}}-dimensional polytope corresponding to an {{math|({{var|n}} &amp;minus; {{var|i}} &amp;minus; 1)}}-dimensional feature of the dual polytope. The incidence-preserving nature of the duality is reflected in the fact that the [[face lattice]]s of the primal and dual polyhedra or polytopes are themselves [[duality (mathematics)#order-theoretic duality|order-theoretic duals]]. Duality of polytopes and order-theoretic duality are both [[Involution (mathematics)|involution]]s: the dual polytope of the dual polytope of any polytope is the original polytope, and reversing all order-relations twice returns to the original order. Choosing a different center of polarity leads to geometrically different dual polytopes, but all have the same combinatorial structure.

[[File:Duals graphs.svg|right|thumb|240px|A [[planar graph]] in blue, and its [[dual graph]] in red.]]
From any three-dimensional polyhedron, one can form a [[planar graph]], the graph of its vertices and edges. The dual polyhedron has a [[dual graph]], a graph with one vertex for each face of the polyhedron and with one edge for every two adjacent faces. The same concept of planar graph duality may be generalized to graphs that are drawn in the plane but that do not come from a three-dimensional polyhedron, or more generally to [[graph embedding]]s on surfaces of higher genus: one may draw a dual graph by placing one vertex within each region bounded by a cycle of edges in the embedding, and drawing an edge connecting any two regions that share a boundary edge. An important example of this type comes from [[computational geometry]]: the duality for any finite set {{math|{{var|S}}}} of points in the plane between the [[Delaunay triangulation]] of {{math|{{var|S}}}} and the [[Voronoi diagram]] of {{math|{{var|S}}}}. As with dual polyhedra and dual polytopes, the duality of graphs on surfaces is a dimension-reversing involution: each vertex in the primal embedded graph corresponds to a region of the dual embedding, each edge in the primal is crossed by an edge in the dual, and each region of the primal corresponds to a vertex of the dual. The dual graph depends on how the primal graph is embedded: different planar embeddings of a single graph may lead to different dual graphs. [[Matroid duality]] is an algebraic extension of planar graph duality, in the sense that the dual matroid of the graphic matroid of a planar graph is isomorphic to the graphic matroid of the dual graph.

A kind of geometric duality also occurs in [[Optimization (mathematics)|optimization theory]], but not one that reverses dimensions. A [[linear program]] may be specified by a system of real variables (the coordinates for a point in Euclidean space {{nowrap|&lt;math&gt;\mathbb R^n&lt;/math&gt;),}} a system of linear constraints (specifying that the point lie in a [[Half-space (geometry)|halfspace]]; the intersection of these halfspaces is a convex polytope, the feasible region of the program), and a linear function (what to optimize). Every linear program has a [[dual problem]] with the same optimal solution, but the variables in the dual problem correspond to constraints in the primal problem and vice versa.
{{Clear}}

==Duality in logic and set theory==
In logic, functions or relations {{math|{{var|A}}}} and {{math|{{var|B}}}} are considered dual if {{math|1={{var|A}}(¬{{var|x}}) = ¬{{var|B}}({{var|x}})}}, where ¬ is [[logical negation]]. The basic duality of this type is the duality of the ∃ and ∀ [[Quantifier (logic)|quantifiers]] in classical logic. These are dual because {{math|∃{{var|x}}.¬{{var|P}}({{var|x}})}} and {{math|¬∀{{var|x}}.{{var|P}}({{var|x}})}} are equivalent for all predicates {{var|P}} in classical logic: if there exists an {{var|x}} for which {{var|P}} fails to hold, then it is false that {{var|P}} holds for all {{var|x}} (but the converse does not hold constructively). From this fundamental logical duality follow several others:

* A formula is said to be ''satisfiable'' in a certain model if there are assignments to its free variables that render it true; it is ''valid'' if ''every'' assignment to its free variables makes it true. Satisfiability and validity are dual because the invalid formulas are precisely those whose negations are satisfiable, and the unsatisfiable formulas are those whose negations are valid.  This can be viewed as a special case of the previous item, with the quantifiers ranging over interpretations.
* In classical logic, the {{math|∧}} and {{math|∨}} operators are dual in this sense, because {{math|(¬{{var|x}} ∧ ¬{{var|y}})}} and {{math|¬({{var|x}} ∨ {{var|y}})}} are equivalent.  This means that for every theorem of classical logic there is an equivalent dual theorem.  [[De Morgan's laws]] are examples.  More generally, {{math|1={{big|∧}} (¬ {{var|x}}{{sub|{{var|i}}}}) = ¬{{big|∨}} {{var|x}}{{sub|{{var|i}}}}}}.  The left side is true if and only if {{math|∀{{var|i}}.¬{{var|x}}{{sub|{{var|i}}}}}}, and the right side if and only if ¬∃''i''.''x''&lt;sub&gt;''i''&lt;/sub&gt;.
* In [[modal logic]], {{math|&amp;#9633;&amp;thinsp;{{var|p}}}} means that the proposition {{math|{{var|p}}}} is "necessarily" true, and {{math|◊&amp;thinsp;{{var|p}}}} that {{math|{{var|p}}}} is "possibly" true.  Most interpretations of modal logic assign dual meanings to these two operators.  For example in [[Kripke semantics]], "{{math|{{var|p}}}} is possibly true" means "there exists some world {{math|{{var|W}}}} such that {{math|{{var|p}}}} is true in {{math|{{var|W}}}}", while "{{math|{{var|p}}}} is necessarily true" means "for all worlds {{math|{{var|W}}}}, {{math|{{var|p}}}} is true in {{math|{{var|W}}}}".  The duality of {{math|&amp;#9633;}} and {{math|◊}} then follows from the analogous duality of {{math|∀}} and {{math|∃}}. Other dual modal operators behave similarly. For example, [[temporal logic]] has operators denoting "will be true at some time in the future" and "will be true at all times in the future" which are similarly dual.

Other analogous dualities follow from these:

* Set-theoretic union and intersection are dual under the [[set complement]] operator {{math|⋅{{sup|{{var|C}}}}}}. That is, {{math|1={{var|A}}{{sup|{{var|C}}}} ∩ {{var|B}}{{sup|{{var|C}}}} = ({{var|A}} ∪ {{var|B}}){{sup|{{var|C}}}}}}, and more generally, {{math|1={{big|∩}} {{var|A}}{{sup sub|{{var|C}}|{{var|α}}}} = ({{big|∪}} {{var|A}}{{sub|{{var|α}}}}){{sup|{{var|C}}}}}}. This follows from the duality of {{math|∀}} and {{math|∃}}: an element {{math|{{var|x}}}} is a member of {{math|{{big|∩}} {{var|A}}{{sup sub|{{var|C}}|{{var|α}}}}}} if and only if {{math|∀{{var|α}}.¬{{var|x}} ∈ {{var|A}}{{sub|{{var|α}}}}}}, and is a member of {{math|({{big|∪}} {{var|A}}{{sub|{{var|α}}}}){{sup|{{var|C}}}}}} if and only if {{math|¬∃{{var|α}}. {{var|x}} ∈ {{var|A}}{{sub|{{var|α}}}}}}.

==Dual objects==
A group of dualities can be described by endowing, for any mathematical object {{math|{{var|X}}}}, the set of morphisms {{math|Hom ({{var|X}}, {{var|D}})}} into some fixed object {{math|{{var|D}}}}, with a structure similar to that of {{math|{{var|X}}}}. This is sometimes called [[internal Hom]]. In general, this yields a true duality only for specific choices of {{math|{{var|D}}}}, in which case {{math|1={{var|X}}{{sup|*}} = Hom ({{var|X}}, {{var|D}})}} is referred to as the ''dual'' of {{math|{{var|X}}}}. There is always a map from {{math|{{var|X}}}} to the ''bidual'', that is to say, the dual of the dual,
{{block indent|&lt;math&gt;X \to X^{**} := (X^*)^* = \operatorname{Hom}(\operatorname{Hom}(X, D), D).&lt;/math&gt;}}
It assigns to some {{math|{{var|x}} &amp;isin; {{var|X}}}} the map that associates to any map {{math|{{var|f}} : {{var|X}} &amp;rarr; {{var|D}}}} (i.e., an element in {{math|Hom({{var|X}}, {{var|D}})}}) the value {{math|{{var|f}}({{var|x}})}}.
Depending on the concrete duality considered and also depending on the object {{math|{{var|X}}}}, this map may or may not be an isomorphism.

===Dual vector spaces revisited===
The construction of the dual vector space
{{block indent|&lt;math&gt;V^* = \operatorname{Hom}(V, K)&lt;/math&gt;}}
mentioned in the introduction is an example of such a duality. Indeed, the set of morphisms, i.e., [[linear map]]s, forms a vector space in its own right. The map {{math|{{var|V}} → {{var|V}}{{sup|**}}}} mentioned above is always injective. It is surjective, and therefore an isomorphism, if and only if the [[Hamel dimension|dimension]] of {{math|{{var|V}}}} is finite. This fact characterizes finite-dimensional vector spaces without referring to a basis.

====Isomorphisms of {{math|''V''}} and {{math|''V''{{sup|∗}}}} and inner product spaces====
A vector space {{math|''V''}} is isomorphic to {{math|''V''{{sup|∗}}}} precisely if {{math|''V''}} is finite-dimensional. In this case, such an isomorphism is equivalent to a non-degenerate [[bilinear form]]
{{block indent|&lt;math&gt;\varphi: V \times V \to K&lt;/math&gt;}}
In this case {{math|''V''}} is called an [[inner product space]].
For example, if {{math|''K''}} is the field of [[real number|real]] or [[complex number]]s, any [[positive definite]] bilinear form gives rise to such an isomorphism. In [[Riemannian geometry]], {{math|''V''}} is taken to be the [[tangent space]] of a [[manifold]] and such positive bilinear forms are called [[Riemannian metric]]s. Their purpose is to measure angles and distances. Thus, duality is a foundational basis of this branch of geometry. Another application of inner product spaces is the [[Hodge star]] which provides a correspondence between the elements of the [[exterior algebra]]. For an {{math|''n''}}-dimensional vector space, the Hodge star operator maps [[differential form|{{math|''k''}}-forms]] to {{math|(''n'' &amp;minus; ''k'')}}-forms. This can be used to formulate [[Maxwell's equation]]s. In this guise, the duality inherent in the inner product space exchanges the role of [[magnetic field|magnetic]] and [[electric field]]s.

====Duality in projective geometry====
[[File:Complete-quads.svg|thumb|240px|The [[complete quadrangle]], a configuration of four points and six lines in the projective plane (left) and its dual configuration, the complete quadrilateral, with four lines and six points (right).]]

In some [[projective plane]]s, it is possible to find [[Transformation (geometry)|geometric transformation]]s that map each point of the projective plane to a line, and each line of the projective plane to a point, in an incidence-preserving way.&lt;ref&gt;{{harvnb|Veblen|Young|1965}}.&lt;/ref&gt; For such planes there arises a general principle of [[duality (projective geometry)|duality in projective planes]]: given any theorem in such a plane projective geometry, exchanging the terms "point" and "line" everywhere results in a new, equally valid theorem.&lt;ref&gt;{{Harvard citations|last1=Veblen|last2=Young|year=1965|loc = Ch. I, Theorem 11}}&lt;/ref&gt; A simple example is that the statement "two points determine a unique line, the line passing through these points" has the dual statement that "two lines determine a unique point, the [[Line-line intersection|intersection point]] of these two lines". For further examples, see [[Duality (projective geometry)#Dual Theorems|Dual theorems]].

A conceptual explanation of this phenomenon in some planes (notably field planes) is offered by the dual vector space. In fact, the points in the projective plane &lt;math&gt;\mathbb{RP}^2&lt;/math&gt; correspond to one-dimensional subvector spaces &lt;math&gt;V \subset \mathbb R^3&lt;/math&gt;&lt;ref&gt;More generally, one can consider the projective planes over any field, such as the complex numbers or [[finite field]]s or even [[division ring]]s.&lt;/ref&gt; while the lines in the projective plane correspond to subvector spaces &lt;math&gt;W&lt;/math&gt; of dimension 2. The duality in such projective geometries stems from assigning to a one-dimensional &lt;math&gt;V&lt;/math&gt; the subspace of &lt;math&gt;(\mathbb R^3)^*&lt;/math&gt; consisting of those linear maps &lt;math&gt;f: \mathbb R^3 \to \mathbb R&lt;/math&gt; which satisfy &lt;math&gt;f (V) = 0&lt;/math&gt;. As a consequence of the [[dimension formula]] of [[linear algebra]], this space is two-dimensional, i.e., it corresponds to a line in the projective plane associated to &lt;math&gt;(\mathbb R^3)^*&lt;/math&gt;.

The (positive definite) bilinear form
{{block indent|&lt;math&gt;\langle - , - \rangle : \mathbb R^3 \times \mathbb R^3 \to \mathbb R, \langle x , y \rangle = \sum_{i=1}^3 x_i y_i&lt;/math&gt;}}
yields an identification of this projective plane with the &lt;math&gt;\mathbb{RP}^2&lt;/math&gt;. Concretely, the duality assigns to &lt;math&gt;V \subset \mathbb R^3&lt;/math&gt; its [[orthogonal subspace|orthogonal]] &lt;math&gt;\{w \in \mathbb R^3, \langle v, w \rangle = 0 \text{ for all } v \in V\}&lt;/math&gt;. The explicit formulas in [[duality (projective geometry)|duality in projective geometry]] arise by means of this identification.

===Topological vector spaces and Hilbert spaces===
In the realm of [[topological vector space]]s, a similar construction exists, replacing the dual by the [[Dual vector space#Continuous dual space|topological dual]] vector space. A topological vector space that is canonically isomorphic to its bidual is called [[reflexive space]]. For example, the dual of an [[Lp spaces|{{math|{{var|L}}{{sup|{{var|p}}}}}}-space]] is {{math|{{var|L}}{{sup|{{var|q}}}}}} where {{math|1=1/{{var|p}} + 1/{{var|q}} = 1}} provided that {{math|1 &amp;le; {{var|p}} &lt; &amp;infin;}}, but the dual of {{math|{{var|L}}{{sup|&amp;infin;}}}} is bigger than {{math|{{var|L}}{{sup|1}}}}. Hence {{math|{{var|L}}{{sup|1}}}} is not reflexive.

[[Hilbert space]]s {{math|{{var|H}}}} are equipped with an [[inner product]] {{math|〈-, -〉}}. As in the finite-dimensional case, it allows to define a map
{{block indent|&lt;math&gt;H \to H^*, v \mapsto (w \mapsto \langle v, w \rangle).&lt;/math&gt;}}
The [[Riesz representation theorem]] asserts that this map is an isomorphism, i.e., every Hilbert space is isomorphic to its dual.

[[Distribution (mathematics)|Distributions]] are linear functionals on appropriate spaces of functions. They are an important technical means in the theory of [[partial differential equation]]s (PDE): instead of solving a PDE directly, it may be easier to first solve the PDE in the "weak sense", i.e., find a distribution that satisfies the PDE and, second, to show that the solution must in fact be a function.&lt;ref&gt;See [[elliptic regularity]].&lt;/ref&gt;

===Further dual objects===
The [[dual lattice]] of a [[Lattice (group)|lattice]] {{math|{{var|L}}}} is given by
{{block indent|&lt;math display="inline"&gt;\operatorname{Hom} (L, \mathbf{Z})&lt;/math&gt;,{{clarify|date=September 2016|reason=What is '''Z''' here?}}}}
which is used in the construction of [[toric variety|toric varieties]].&lt;ref&gt;{{Harvard citations| last1=Fulton | year=1993|nb=yes}}&lt;/ref&gt; The [[Pontryagin dual]] of [[locally compact]] [[topological group]]s ''G'' is given by
{{block indent|&lt;math display="inline"&gt;\operatorname{Hom} (G, S^1)&lt;/math&gt;,}}
continuous [[group homomorphisms]] with values in the circle (with multiplication of complex numbers as group operation).

==Dual categories==
{{main article|Dual (category theory)}}

===Opposite category and adjoint functors===
In another group of dualities, the objects of one theory are translated into objects of another theory and the maps between objects in the first theory are translated into morphisms in the second theory, but with direction reversed. Using the parlance of [[category theory]], this amounts to a [[contravariant functor]] between two [[category (mathematics)|categories]] {{math|{{var|C}}}} and {{math|{{var|D}}}}:
{{block indent|{{math|{{var|F}}: {{var|C}} → {{var|D}}}}}}
which for any two objects ''X'' and ''Y'' of ''C'' gives a map
{{block indent|{{math|Hom{{sub|{{var|C}}}}({{var|X}}, {{var|Y}}) → Hom{{sub|{{var|D}}}}({{var|F}}({{var|Y}}), {{var|F}}({{var|X}}))}}}}
That functor may or may not be an [[equivalence of categories]]. There are various situations, where such a functor is an equivalence between the [[opposite category]] {{math|{{var|C}}{{sup|op}}}} of {{math|{{var|C}}}}, and {{math|{{var|D}}}}. Using a duality of this type, every statement in the first theory can be translated into a "dual" statement in the second theory, where the direction of all arrows has to be reversed.&lt;ref&gt;{{Harvnb|Mac Lane|1998|loc=Ch. II.1}}.&lt;/ref&gt; Therefore, any duality between categories {{math|{{var|C}}}} and {{math|{{var|D}}}} is formally the same as an equivalence between {{math|{{var|C}}}} and {{math|{{var|D}}{{sup|op}}}} ({{math|{{var|C}}{{sup|op}}}} and {{math|{{var|D}}}}). However, in many circumstances the opposite categories have no inherent meaning, which makes duality an additional, separate concept.&lt;ref&gt;{{Harvard citations | last1=Lam|year=1999|loc=§19C}}&lt;/ref&gt;

A category that is equivalent to its dual is called ''self-dual''. An example of self-dual category is the category of [[Hilbert space]]s.&lt;ref name="AdamekRosicky1994"&gt;{{cite book|author1=Jiří Adámek|author2=J. Rosicky|title=Locally Presentable and Accessible Categories|url=https://books.google.com/books?id=iXh6rOd7of0C&amp;pg=PA62|year=1994|publisher=Cambridge University Press|isbn=978-0-521-42261-1|page=62}}&lt;/ref&gt;

Many [[category theory|category-theoretic]] notions come in pairs in the sense that they correspond to each other while considering the opposite category. For example, [[Cartesian product]]s {{math|{{var|Y}}{{sub|1}} × {{var|Y}}{{sub|2}}}} and [[disjoint union]]s {{math|{{var|Y}}{{sub|1}} ⊔ {{var|Y}}{{sub|2}}}} of sets are dual to each other in the sense that
{{block indent|{{math|1=Hom ({{var|X}}, {{var|Y}}{{sub|1}} &amp;times; {{var|Y}}{{sub|2}}) = Hom ({{var|X}}, {{var|Y}}{{sub|1}}) &amp;times; Hom ({{var|X}}, {{var|Y}}{{sub|2}})}}}}
and
{{block indent|{{math|1=Hom ({{var|Y}}{{sub|1}} ⊔ {{var|Y}}{{sub|2}}, {{var|X}}) = Hom ({{var|Y}}{{sub|1}}, {{var|X}}) &amp;times; Hom ({{var|Y}}{{sub|2}}, {{var|X}})}}}}
for any set {{math|{{var|X}}}}. This is a particular case of a more general duality phenomenon, under which [[limit (category theory)|limits]] in a category {{math|{{var|C}}}} correspond to [[colimit]]s in the opposite category {{math|{{var|C}}{{sup|op}}}}; further concrete examples of this are [[epimorphism]]s vs. [[monomorphism]], in particular [[factor module]]s (or groups etc.) vs. [[submodule]]s, [[direct product]]s vs. [[Direct sum of groups|direct sums]] (also called [[coproduct]]s to emphasize the duality aspect). Therefore, in some cases, proofs of certain statements can be halved, using such a duality phenomenon. Further notions displaying related by such a categorical duality are [[projective module|projective]] and [[injective module]]s in [[homological algebra]],&lt;ref&gt;{{Harvard citations | last1=Weibel |year=1994|txt}}&lt;/ref&gt; [[fibration]]s and [[cofibration]]s in topology and more generally [[model category|model categories]].&lt;ref&gt;{{Harvard citations | last1=Dwyer | last2=Spaliński | year=1995|txt}}&lt;/ref&gt;

Two [[functors]] {{math|{{var|F}}: {{var|C}} → {{var|D}}}} and {{math|{{var|G}}: {{var|D}} → {{var|C}}}} are [[adjoint functor|adjoint]] if for all objects ''c'' in ''C'' and ''d'' in ''D''
{{block indent|{{math|Hom{{sub|{{var|D}}}}(F({{var|c}}), {{var|d}}) ≅ Hom{{sub|{{var|C}}}}({{var|c}}, {{var|G}}({{var|d}}))}},}}
in a natural way.  Actually, the correspondence of limits and colimits is an example of adjoints, since there is an adjunction

{{block indent|{{math|colim: {{var|C}}{{sup|{{var|I}}}} &amp;harr; {{var|C}}: {{var|Δ}}}}}}

between the colimit functor that assigns to any diagram in {{math|{{var|C}}}} indexed by some category {{math|{{var|I}}}} its colimit and the diagonal functor that maps any object {{math|{{var|c}}}} of {{math|{{var|C}}}} to the constant diagram which has {{math|{{var|c}}}} at all places. Dually,

{{block indent|{{math|{{var|Δ}}: {{var|C}} &amp;harr; {{var|C}}{{sup|{{var|I}}}}: lim}}.}}

===Spaces and functions===

[[Gelfand duality]] is a duality between commutative [[C*-algebra]]s ''A'' and [[compact space|compact]] [[Hausdorff space]]s ''X'' is the same: it assigns to ''X'' the space of continuous functions (which vanish at infinity) from ''X'' to '''C''', the complex numbers. Conversely, the space ''X'' can be reconstructed from ''A'' as the [[spectrum]] of ''A''. Both Gelfand and Pontryagin duality can be deduced in a largely formal, category-theoretic way.&lt;ref&gt;{{Harvnb|Negrepontis|1971}}.&lt;/ref&gt;

In a similar vein there is a duality in [[algebraic geometry]] between [[commutative ring]]s and [[affine scheme]]s: to every commutative ring ''A'' there is an affine spectrum, [[spectrum of a ring|Spec ''A'']]. Conversely, given an affine scheme ''S'', one gets back a ring by taking global sections of the [[structure sheaf]] O&lt;sub&gt;''S''&lt;/sub&gt;. In addition, [[ring homomorphism]]s are in one-to-one correspondence with morphisms of affine schemes, thereby there is an equivalence
: (Commutative rings)&lt;sup&gt;op&lt;/sup&gt; ≅ (affine schemes)&lt;ref&gt;{{Harvard citations | last1=Hartshorne | year=1966 | loc=Ch. II.2, esp. Prop. II.2.3|nb=yes}}&lt;/ref&gt;
Affine schemes are the local building blocks of [[scheme (mathematics)|schemes]]. The previous result therefore tells that the local theory of schemes is the same as [[commutative algebra]], the study of commutative rings.

[[Noncommutative geometry]] draws inspiration from Gelfand duality and studies noncommutative C*-algebras as if they were functions on some imagined space. [[Tannaka–Krein duality]] is a non-commutative analogue of Pontryagin duality.&lt;ref&gt;{{Harvard citations | last1=Joyal | last2=Street|year=1991 |txt}}&lt;/ref&gt;

===Galois connections===
In a number of situations, the two categories which are dual to each other are actually arising from [[partially ordered]] sets, i.e., there is some notion of an object "being smaller" than another one. A duality that respects the orderings in question is known as a [[Galois connection]]. An example is the standard duality in [[Galois theory]] mentioned in the introduction: a bigger field extension corresponds—under the mapping that assigns to any extension ''L'' ⊃ ''K'' (inside some fixed bigger field Ω) the Galois group Gal (Ω / ''L'') —to a smaller group.&lt;ref&gt;See {{Harvard citations | last1=Lang|year=2002|loc=Theorem VI.1.1}} for finite Galois extensions.&lt;/ref&gt;

The collection of all open subsets of a topological space ''X'' forms a complete [[Heyting algebra]]. There is a duality, known as [[Stone duality]], connecting [[sober space]]s and spatial [[locale (mathematics)|locales]].

* [[Birkhoff's representation theorem]] relating [[distributive lattice]]s and [[partial order]]s

===Pontryagin duality===
[[Pontryagin duality]] gives a duality on the category of [[locally compact]] [[abelian group]]s: given any such group ''G'', the [[character group]]
:χ(''G'') = Hom (''G'', ''S''&lt;sup&gt;1&lt;/sup&gt;)
given by continuous group homomorphisms from ''G'' to the [[circle group]] ''S''&lt;sup&gt;1&lt;/sup&gt; can be endowed with the [[compact-open topology]]. Pontryagin duality states that the character group is again locally compact abelian and that
:''G'' ≅ χ(χ(''G'')).&lt;ref&gt;{{Harvard citations | last1=Loomis|year=1953 | loc=p. 151, section 37D}}&lt;/ref&gt;
Moreover, [[discrete group]]s correspond to [[compact group|compact abelian group]]s; finite groups correspond to finite groups. On the one hand, Pontryagin is a special case of Gelfand duality. On the other hand, it is the conceptual reason of [[Fourier analysis]], see below.

== Analytic dualities ==
In [[mathematical analysis|analysis]], problems are frequently solved by passing to the dual description of functions and operators.

[[Fourier transform]] switches between functions on a vector space and its dual:
:&lt;math&gt;\hat{f}(\xi) := \int_{-\infty}^{\infty} f(x)\ e^{- 2\pi i x \xi}\,dx, &lt;/math&gt;
and conversely
:&lt;math&gt;f(x) = \int_{-\infty}^{\infty} \hat{f}(\xi)\ e^{2 \pi i x \xi}\,d\xi.&lt;/math&gt;
If ''f'' is an [[Lebesgue integration|''L''&lt;sup&gt;2&lt;/sup&gt;-function]] on '''R''' or '''R'''&lt;sup&gt;''N''&lt;/sup&gt;, say, then so is &lt;math&gt;\hat{f}&lt;/math&gt; and &lt;math&gt;f(-x) = \hat{\hat{f}}(x)&lt;/math&gt;. Moreover, the transform interchanges operations of multiplication and [[convolution]] on the corresponding [[function space]]s. A conceptual explanation of the Fourier transform is obtained by the aforementioned Pontryagin duality, applied to the locally compact groups '''R''' (or '''R'''&lt;sup&gt;''N''&lt;/sup&gt; etc.): any character of '''R''' is given by ξ↦ e&lt;sup&gt;−2πi''x''ξ&lt;/sup&gt;. The dualizing character of Fourier transform has many other manifestations, for example, in alternative descriptions of [[quantum mechanics|quantum mechanical]] systems in terms of coordinate and momentum representations.

* [[Laplace transform]] is similar to Fourier transform and interchanges [[linear operator|operators]] of multiplication by polynomials with constant coefficient [[linear differential operator]]s.
* [[Legendre transformation]] is an important analytic duality which switches between [[velocity|velocities]] in [[Lagrangian mechanics]] and [[momentum|momenta]] in [[Hamiltonian mechanics]].

==Homology and cohomology==
Theorems showing that certain objects of interest are the [[dual space]]s (in the sense of linear algebra) of other objects of interest are often called ''dualities''. Many of these dualities are given by a [[bilinear function|bilinear pairing]] of two ''K''-vector spaces
:''A'' ⊗ ''B'' → ''K''.
For [[perfect pairing]]s, there is, therefore, an isomorphism of ''A'' to the [[dual vector space|dual]] of ''B''.

===Poincaré duality===
[[Poincaré duality]] of a smooth compact [[complex manifold]] ''X'' is given by a pairing of singular cohomology with '''C'''-coefficients (equivalently, [[sheaf cohomology]] of the [[constant sheaf]] '''C''')
:H&lt;sup&gt;''i''&lt;/sup&gt;(X) ⊗ H&lt;sup&gt;2''n''&amp;minus;''i''&lt;/sup&gt;(X) → '''C''',
where ''n'' is the (complex) dimension of ''X''.&lt;ref&gt;{{Harvard citations | last1=Griffiths | last2=Harris | year=1994|nb=yes|loc=p. 56}}&lt;/ref&gt; Poincaré duality can also be expressed as a relation of [[singular homology]] and [[de Rham cohomology]], by asserting that the map
:&lt;math&gt;(\gamma, \omega) \mapsto \int_\gamma \omega&lt;/math&gt;
(integrating a differential ''k''-form over an 2''n''&amp;minus;''k''-(real) -dimensional cycle) is a perfect pairing.

Poincaré duality also reverses dimensions; it corresponds to the fact that, if a topological [[manifold]] is represented as a [[cell complex]], then the dual of the complex (a higher-dimensional generalization of the planar graph dual) represents the same manifold. In Poincaré duality, this homeomorphism is reflected in an isomorphism of the ''k''th [[homology (mathematics)|homology]] group and the (''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k'')th [[cohomology]] group.

===Duality in algebraic and arithmetic geometry===
The same duality pattern holds for a smooth [[projective variety]] over a [[separably closed field]], using [[l-adic cohomology]] with '''Q'''&lt;sub&gt;ℓ&lt;/sub&gt;-coefficients instead.&lt;ref&gt;{{Harvard citations | last1=Milne |year=1980|loc=Ch. VI.11|nb=yes}}&lt;/ref&gt; This is further generalized to possibly [[singular variety|singular varieties]], using [[intersection cohomology]] instead, a duality called [[Verdier duality]].&lt;ref&gt;{{Harvard citations | last1=Iversen | year=1986|nb=yes|loc=Ch. VII.3, VII.5}}&lt;/ref&gt; [[Serre duality]] or [[coherent duality]] are similar to the statements above, but applies to cohomology of [[coherent sheaves]] instead.&lt;ref&gt;{{Harvard citations | last1=Hartshorne | year=1966 | loc=Ch. III.7|nb=yes}}&lt;/ref&gt;

With increasing level of generality, it turns out, an increasing amount of technical background is helpful or necessary to understand these theorems: the modern formulation of these dualities can be done using [[derived category|derived categories]] and certain [[image functors for sheaves|direct and inverse image functors of sheaves]] (with respect to the classical analytical topology on manifolds for Poincaré duality, l-adic sheaves and the [[étale topology]] in the second case, and with respect to coherent sheaves for coherent duality).

Yet another group of similar duality statements is encountered in [[arithmetics]]: étale cohomology of [[finite field|finite]], [[local field|local]]  and [[global field]]s (also known as [[Galois cohomology]], since étale cohomology over a field is equivalent to [[group cohomology]] of the (absolute) [[Galois group]] of the field) admit similar pairings. The absolute Galois group ''G''('''F'''&lt;sub&gt;''q''&lt;/sub&gt;) of a finite field, for example, is isomorphic to &lt;math&gt;\hat {\mathbf Z}&lt;/math&gt;, the [[profinite completion]] of '''Z''', the integers. Therefore, the perfect pairing (for any [[G-module|''G''-module]] ''M'')
:H&lt;sup&gt;''n''&lt;/sup&gt;(''G'', ''M'') × H&lt;sup&gt;1−''n''&lt;/sup&gt; (''G'', Hom (''M'', '''Q'''/'''Z''')) → '''Q'''/'''Z'''&lt;ref&gt;{{Harvard citations|last=Milne|year=2006|loc=Example I.1.10|txt}}&lt;/ref&gt;
is a direct consequence of [[Pontryagin duality]] of finite groups. For local and global fields, similar statements exist ([[Local Tate duality|local duality]] and global or [[Poitou&amp;ndash;Tate duality]]).&lt;ref&gt;{{Harvard citations|last1=Mazur|year=1973|txt}}; {{Harvard citations|last=Milne|year=2006|txt}}&lt;/ref&gt;

==See also==
{{Div col|colwidth=20em}}
* [[List of dualities]]
* [[Dual (category theory)]]
* [[Autonomous category]]
* [[Dual norm]]
* [[Dual number]]s, a certain [[associative algebra]]; the term "dual" here is synonymous with ''double'', and is unrelated to the notions given above.
* [[Duality (electrical engineering)]]
* [[Duality (optimization)]]
* [[Koszul duality]]
* [[Langlands dual]]
* [[Petrie polygon#Petrie dual|Petrie duality]]
* [[T-duality]], [[Homological mirror symmetry|Mirror symmetry]]
* [[S-duality]]
* [[Linear programming#Duality]]
* [[Dual code]]
* [[Dual lattice]]
* [[Dual basis]]
* [[Dual abelian variety]]
* [[Adjoint functor]]
* [[Dualizing module]]
* [[Matlis duality]]
* [[Dualizing sheaf]]
{{div col end}}

==Notes==
{{reflist|2}}

==References==

===Duality in general===
* Atiyah, Michael (2007), [http://www.fme.upc.edu/ca/arxius/butlleti-digital/riemann/071218_conferencia_atiyah-d_article.pdf Duality in Mathematics and Physics], lecture notes from the Institut de Matematica de la Universitat de Barcelona (IMUB).
*{{Springer|title=Duality|id=D/d034120|first=A. I.|last=Kostrikin|authorlink=Alexei Kostrikin}}.
*{{citation |contribution=III.19 Duality |title=[[The Princeton Companion to Mathematics]] |pages=187–190 |first=Timothy |last=Gowers |publisher=Princeton University Press |year=2008}}.
* {{Citation | doi=10.1090/S0273-0979-01-00913-2 | last1=Cartier | first1=Pierre | title=A mad day's work: from Grothendieck to Connes and Kontsevich. The evolution of concepts of space and symmetry | url=http://www.ams.org/bull/2001-38-04/S0273-0979-01-00913-2/ | mr=1848254 | year=2001 | journal=American Mathematical Society. Bulletin. New Series | issn=0002-9904 | volume=38 | issue=4 | pages=389–408}} (a non-technical overview about several aspects of geometry, including dualities)

===Duality in algebraic topology ===
*James C. Becker and Daniel Henry Gottlieb, [http://www.math.purdue.edu/~gottlieb/Bibliography/53.pdf A History of Duality in Algebraic Topology]

===Specific dualities===
* {{Citation | last1=Artstein-Avidan | first1=Shiri | author1-link = Shiri Artstein | last2=Milman | first2=Vitali | author2-link=Vitali Milman | year=2008 | title=The concept of duality for measure projections of convex bodies | journal=Journal of Functional Analysis | volume=254 | issue=10 | pages=2648&amp;ndash;2666 | doi=10.1016/j.jfa.2007.11.008}}. Also [http://www.math.tau.ac.il/~shiri/publications.html author's site].
* {{Citation | last1=Artstein-Avidan | first1=Shiri | last2=Milman | first2=Vitali | author2-link=Vitali Milman | year=2007 | title=A characterization of the concept of duality | journal=Electronic research announcements in mathematical sciences | volume=14 | pages=42&amp;ndash;59 | url=http://www.aimsciences.org/journals/pdfs.jsp?paperID=2887&amp;mode=full}}. Also [http://www.math.tau.ac.il/~shiri/publications.html author's site].
* {{Citation | last1=Dwyer | first1=William G. | author1-link=William Gerard Dwyer|last2=Spaliński | first2=Jan | title=Handbook of algebraic topology | url=http://hopf.math.purdue.edu/cgi-bin/generate?/Dwyer-Spalinski/theories | publisher=North-Holland | location=Amsterdam | mr=1361887 | year=1995 | chapter=Homotopy theories and model categories | pages=73–126}}
* {{Citation | last1=Fulton | first1=William | author1-link=William Fulton (mathematician) | title=Introduction to toric varieties | publisher=[[Princeton University Press]] | isbn=978-0-691-00049-7 | year=1993}}
* {{Citation | last1=Griffiths | first1=Phillip | author1-link=Phillip Griffiths | last2=Harris | first2=Joseph | author2-link=Joe Harris (mathematician) | title=Principles of algebraic geometry | publisher=[[John Wiley &amp; Sons]] | location=New York | series=Wiley Classics Library | isbn=978-0-471-05059-9 | mr=1288523 | year=1994}}
* {{Citation | last1=Hartshorne | first1=Robin | author1-link=Robin Hartshorne | title=Residues and Duality | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics '''20''' | year=1966 | pages=20–48}}
* {{Citation | last1=Hartshorne | first1=Robin | author1-link=Robin Hartshorne | title=[[Algebraic Geometry (book)|Algebraic Geometry]] | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-0-387-90244-9 | oclc=13348052 | mr=0463157 | year=1977}}
* {{Citation | last1=Iversen | first1=Birger | title=Cohomology of sheaves | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Universitext | isbn=978-3-540-16389-3 | mr=842190 | year=1986}}
* {{Citation | last1=Joyal | first1=André | author1-link=André Joyal | last2=Street | first2=Ross | author2-link=Ross Street | title=Category theory (Como, 1990) | url=http://www.maths.mq.edu.au/~street/CT90Como.pdf | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | mr=1173027 | year=1991 | volume=1488 | chapter=An introduction to Tannaka duality and quantum groups | pages=413–492}}
* {{Citation | last1=Lam | first1=Tsit-Yuen | title=Lectures on modules and rings | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics No. 189 | isbn=978-0-387-98428-5 | mr=1653294 | year=1999}}
* {{Citation | last1=Lang | first1=Serge | author1-link=Serge Lang | title=Algebra | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics | isbn=978-0-387-95385-4 | mr=1878556 | year=2002 | volume=211}}
* {{Citation | last1=Loomis | first1=Lynn H. | title=An introduction to abstract harmonic analysis | publisher=D. Van Nostrand Company, Inc. | location=Toronto-New York-London | year=1953 | pages=x+190}}
* {{Citation | last1=Mac Lane | first1=Saunders | author1-link=Saunders Mac Lane | title=[[Categories for the Working Mathematician]] | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=2nd | isbn=978-0-387-98403-2 | year=1998}}
* {{Citation | last1=Mazur | first1=Barry | author1-link=Barry Mazur | title=Notes on étale cohomology of number fields | mr=0344254 | year=1973 | journal=Annales Scientifiques de l'École Normale Supérieure |series=Série 4 | issn=0012-9593 | volume=6 | pages=521–552}}
* {{Citation | last1=Milne | first1=James S. | title=Étale cohomology | publisher=[[Princeton University Press]] | isbn=978-0-691-08238-7 | year=1980}}
* {{Citation | last1=Milne | first1=James S. | title=Arithmetic duality theorems | url=http://www.jmilne.org/math/Books/adt.html | publisher=BookSurge, LLC | location=Charleston, South Carolina | edition=2nd | isbn=978-1-4196-4274-6 | mr=2261462 | year=2006}}
* {{Citation | doi=10.1016/0021-8693(71)90105-0 | last1=Negrepontis | first1=Joan W. | title=Duality in analysis from the point of view of triples | mr=0280571 | year=1971 | journal=Journal of Algebra | issn=0021-8693 | volume=19 | issue=2 | pages=228–253}}
* {{Citation | last1=Veblen | first1=Oswald | author1-link=Oswald Veblen | last2=Young | first2=John Wesley | title=Projective geometry. Vols. 1, 2 | publisher=Blaisdell Publishing Co. Ginn and Co. New York-Toronto-London | mr=0179666 | year=1965}}
* {{Citation | last1=Weibel | first1=Charles A. | title=An introduction to homological algebra | publisher=[[Cambridge University Press]] | isbn=978-0-521-55987-4 | mr=1269324 | year=1994}}

[[Category:Duality theories|*]]

[[ja:双対]]
[[ru:Двойственность]]</text>
      <sha1>sms1we6wamjsyb3nprqahmr43g3d36a</sha1>
    </revision>
  </page>
  <page>
    <title>Euclidean distance matrix</title>
    <ns>0</ns>
    <id>8092698</id>
    <revision>
      <id>862708912</id>
      <parentid>859499831</parentid>
      <timestamp>2018-10-06T05:16:53Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2576">In [[mathematics]], a '''Euclidean distance matrix''' is an ''n×n'' [[matrix (mathematics)|matrix]] representing the spacing of a set of ''n'' [[point (geometry)|points]] in [[Euclidean space]]. If ''A'' is a Euclidean distance matrix and the points &lt;math&gt;x_1,x_2,\ldots,x_n&lt;/math&gt; are defined on ''m''-dimensional space, then the elements of ''A'' are given by

:&lt;math&gt;\begin{align}
A &amp; = (a_{ij}); \\
a_{ij} &amp; = d_{ij}^2 \;=\; \lVert x_i - x_j\rVert_2^2
\end{align}
&lt;/math&gt;

where ||.||&lt;sub&gt;2&lt;/sub&gt; denotes the [[2-norm]] on '''R'''&lt;sup&gt;m&lt;/sup&gt;.

:&lt;math&gt;A = \begin{bmatrix}
0 &amp; d_{12}^2 &amp; d_{13}^2 &amp; \dots &amp; d_{1n}^2 \\
d_{21}^2 &amp; 0 &amp; d_{23}^2 &amp; \dots &amp; d_{2n}^2 \\
d_{31}^2 &amp; d_{32}^2 &amp; 0 &amp; \dots &amp; d_{3n}^2 \\
\vdots&amp;\vdots &amp; \vdots &amp; \ddots&amp;\vdots&amp;  \\
d_{n1}^2 &amp; d_{n2}^2 &amp; d_{n3}^2 &amp; \dots &amp; 0 \\
\end{bmatrix} &lt;/math&gt;

==Properties==

Simply put, the element &lt;math&gt; a_{ij}&lt;/math&gt; describes the square of the distance between the ''i''&lt;sup&gt; th&lt;/sup&gt; and ''j''&lt;sup&gt; th&lt;/sup&gt; points in the set. By the properties of the 2-norm (or indeed, Euclidean distance in general), the matrix ''A'' has the following properties.

* All elements on the [[diagonal of a matrix|diagonal]] of ''A'' are zero (i.e. it is a [[hollow matrix]]).
* The [[trace of a matrix|trace]] of ''A'' is zero (by the above property).
* ''A'' is [[symmetric matrix|symmetric]] (i.e. &lt;math&gt; a_{ij} = a_{ji}&lt;/math&gt;).
* &lt;math&gt; \sqrt{a_{ij}} \le \sqrt{a_{ik}} + \sqrt{a_{kj}} &lt;/math&gt; (by the [[triangle inequality]])
* &lt;math&gt; a_{ij}\ge 0&lt;/math&gt;
* The number of unique (distinct) non-zero values within an ''n''-by-''n'' Euclidean distance matrix is bounded above by &lt;math&gt;n(n-1)/2&lt;/math&gt; due to the matrix being symmetric and hollow.
* In dimension ''m'', a Euclidean distance matrix has [[Rank (linear algebra)|rank]] less than or equal to ''m+2''. If the points &lt;math&gt;x_1,x_2,\ldots,x_n&lt;/math&gt; are in [[general position]], the rank is exactly {{nowrap|min(''n'', ''m'' + 2).}}

==See also==
* [[Adjacency matrix]]
* [[Coplanarity]]
* [[Distance geometry]]
* [[Distance matrix]]
* [[Euclidean random matrix]]
* Classical [[multidimensional scaling]], a visualization technique that approximates an arbitrary dissimilarity matrix by a Euclidean distance matrix

==References==
* {{cite book | author=James E. Gentle | title=Matrix Algebra: Theory, Computations, and Applications in Statistics | publisher=[[Springer-Verlag]] | date=2007 | isbn=0-387-70872-3 | page=299|url=https://books.google.com/books?id=PDjIV0iWa2cC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false}}

[[Category:Matrices]]
[[Category:Distance]]</text>
      <sha1>299vzjjv43bumr1rwy8dyuv0z8xn7pj</sha1>
    </revision>
  </page>
  <page>
    <title>Flail space model</title>
    <ns>0</ns>
    <id>47369663</id>
    <revision>
      <id>747918838</id>
      <parentid>747918816</parentid>
      <timestamp>2016-11-05T05:16:35Z</timestamp>
      <contributor>
        <username>Materialscientist</username>
        <id>7852030</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/104.173.100.38|104.173.100.38]] ([[User talk:104.173.100.38|talk]]): Unexplained removal of content ([[WP:HG|HG]]) (3.1.21)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4767">The '''flail space model (FSM)''' is a [[Physical model|model]] of how a [[passenger|car passenger]] moves in a [[vehicle]] that collides with a roadside feature such as a [[Traffic barrier|guardrail]] or a [[crash cushion]]. Its principal purpose is to assess the potential risk of harm to the hypothetical occupant as he or she impacts the interior of the passenger compartment and, ultimately, the efficacy of an experimental roadside feature undergoing full-scale vehicle crash testing.

The FSM eliminates the complexity and expense of using instrumented [[Crash test dummy|anthropometric dummies]] during the crash test experiments. Furthermore, while crash test dummies were developed to model collisions between vehicles, they are not accurate when used for the sorts of collision angles that occur when a vehicle collides with a roadside feature; by contrast, the FSM was designed for such collisions.&lt;ref name="gabauer"&gt;Gabauer, Douglas, "A methodology to evaluate the flail space model using event data recorder technology", Department of Mechanical Engineering, Rowan University, Glassboro, NJ, 2004.&lt;/ref&gt;

== History ==
The FSM is based on research performed at [[Southwest Research Institute]] in 1980&lt;ref&gt;Michie, J. D., "Development of improved criteria for evaluating safety performance of highway appurtenances", Final Report of  Internal Research Project No. 03-9254, Southwest Research Institute, San Antonio, Texas, June 1980.&lt;/ref&gt; and published in 1981 in the paper entitled "Collision Risk Assessment Based on Occupant Flail-Space Model" by Jarvis D. Michie.&lt;ref name=":0"&gt;Michie, J. D., "Collision risk assessment based on occupant flail space model," in Transportation Research Record 796, 1981, pp. 1–9.&lt;/ref&gt; The FSM (coined by Michie) was accepted by the highway community and published as a key part of the "Recommended Procedures for the Safety Evaluation of Highway Appurtenances" published in 1981 in [[National Cooperative Highway Research Program]] (NCHRP) Report 230.&lt;ref&gt;Michie, J. D.  National Cooperative Highway Research Program Report 230: Recommended Procedures for the Safety Performance Evaluation of Highway Appurtenances.  NCHRP Transportation Research Board, Washington, DC, March 1981.&lt;/ref&gt; In 1993, the NCHRP Report was updated and presented as NCHRP Report 350;&lt;ref&gt;Ross, H. E., Jr. et al.  National Cooperative Highway Research Program Report 350:  Recommended Procedures for the Safety Evaluation of Highway Features.  NCHRP Transportation Research Board, Washington, DC, 1993.&lt;/ref&gt; in this research effort performed by the [[Texas A&amp;M Transportation Institute|Texas Transportation Research Institute]], the FSM was reexamined and was unmodified in the new publication. In 2004, Douglas Gabauer further examined the efficacy of the FSM in his [[PhD thesis]].&lt;ref name="gabauer" /&gt; The [[American Association of State Highway and Transportation Officials]] (AASHTO) retained the FSM as the method of assessing the risk of harm to vehicle occupants in the 2009 "Manual for Assessing Safety Hardware" that replaced NCHRP Report 350, stating that the FSM had "served its intended purpose well".&lt;ref&gt;Manual for Assessing Safety Hardware.  American Association of State Highway and Transportation Officials, Washington, DC,  2009.&lt;/ref&gt;

== Details ==
The FSM hypothesis divides the collision into two stages.  In stage one, the unrestrained occupant is propelled forward and sideways in the compartment space due to vehicle collision [[Acceleration|accelerations]] and then impacts one or more surfaces (including the steering wheel) with velocity "V". According to the model, the vehicle (instead of the occupant) is the object that is accelerating. The occupant experiences no injury-producing force prior to contact with the compartment surfaces.&lt;ref name=":0" /&gt;

In stage two, the occupant is assumed to remain in contact with the compartment surface and experiences the same accelerations as the vehicle for the rest of the collision.  The occupant may sustain [[Blunt trauma|injury]] at the end of stage one based on the velocity of impact with the compartment surfaces and due to vehicle accelerations during stage two.  The occupant impact velocity and acceleration are computed from the vehicle collision acceleration history and the compartment geometry.  Finally, the hypothetical occupant impact velocity and acceleration are then compared to threshold values of [[Engineering tolerance|human tolerance]] to these forces.&lt;ref name=":0" /&gt;

==References==
{{reflist|colwidth=30em}}

[[Category:Articles created via the Article Wizard]]
[[Category:Scientific modeling]]
[[Category:Applied mathematics]]
[[Category:Knowledge representation]]
[[Category:Mathematical modeling]]
[[Category:Transport safety]]</text>
      <sha1>i20l5qnty5ur8n1rljkfu169uj0rmat</sha1>
    </revision>
  </page>
  <page>
    <title>Gaussian integral</title>
    <ns>0</ns>
    <id>567580</id>
    <revision>
      <id>868856536</id>
      <parentid>863254456</parentid>
      <timestamp>2018-11-14T22:03:20Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16902">{{about|the Euler–Poisson integral|Gaussian quadrature|Gaussian integration}}
[[Image:E^(-x^2).svg|thumb|right|A graph of ''f''(''x'') =&amp;nbsp;''e''&lt;sup&gt;−''x''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt; and the area between the function and the ''x''-axis, which is equal to &lt;math&gt; \scriptstyle\sqrt{\pi} &lt;/math&gt;.]]

The '''Gaussian integral''', also known as the '''Euler–Poisson integral''', is the integral of the [[Gaussian function]] ''e''&lt;sup&gt;−''x''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt; over the entire real line. It is named after the German mathematician [[Carl Friedrich Gauss]].  The integral is:

:&lt;math&gt;\int_{-\infty}^\infty e^{-x^2}\,dx = \sqrt{\pi}&lt;/math&gt;

[[Abraham de Moivre]] originally discovered this type of integral in 1733, while Gauss published the precise integral in 1809.&lt;ref name="History of normal distribution"&gt;{{cite web |url=https://www.maa.org/sites/default/files/pdf/upload_library/22/Allendoerfer/stahl96.pdf |title=The History of the Normal Distribution |work=MAA.org |first=Saul|last=Stahl|date=April 2006|accessdate=May 25, 2018}}&lt;/ref&gt; The integral has a wide range of applications.  For example, with a slight change of variables it is used to compute the [[normalizing constant]] of the [[normal distribution]].  The same integral with finite limits is closely related to both the [[error function]] and the [[cumulative distribution function]] of the [[normal distribution]]. In physics this type of integral appears frequently, for example, in [[quantum mechanics]], to find the probability density of the ground state of the harmonic oscillator. This integral is also used in the path integral formulation, to find the propagator of the harmonic oscillator, and in [[statistical mechanics]], to find its [[partition function (statistical mechanics)|partition function]].

Although no [[elementary function]] exists for the error function, as can be proven by the [[Risch algorithm]],{{Citation needed|reason=The Risch algorithm is a semi-decision procedure, is there a paper showing that it ran through to completion for Gaussian and trace of the procedure yielded a proof of this assertion?|date=August 2017}} the Gaussian integral can be solved analytically through the methods of [[multivariable calculus]]. That is, there is no elementary ''[[indefinite integral]]'' for
:&lt;math&gt;\int e^{-x^2}\,dx,&lt;/math&gt;
but the [[definite integral]]
:&lt;math&gt;\int_{-\infty}^\infty e^{-x^2}\,dx&lt;/math&gt;
can be evaluated. The definite integral of an arbitrary [[Gaussian function]] is

:&lt;math&gt;\int_{-\infty}^{\infty}  e^{-a(x+b)^2}\,dx= \sqrt{\frac{\pi}{a}}.&lt;/math&gt;

The Gaussian integral is encountered very often in physics and numerous generalizations of the integral are encountered in [[quantum field theory]].

==Computation==

===By polar coordinates===
A standard way to compute the Gaussian integral, the idea of which goes back to Poisson,&lt;ref name="york.ac.uk"&gt;{{cite web |title=The Probability Integral |url=https://www.york.ac.uk/depts/maths/histstat/normal_history.pdf }}&lt;/ref&gt; is to make use of the property that:

&lt;math&gt;\left(\int_{-\infty}^{\infty} e^{-x^2}\,dx\right)^2 = \int_{-\infty}^{\infty} e^{-x^2}\,dx \int_{-\infty}^{\infty} e^{-y^2}\,dy = \int_{-\infty}^{\infty}  \int_{-\infty}^{\infty} e^{-(x^2+y^2)}\, dx\,dy &lt;/math&gt;

* consider the function ''e''&lt;sup&gt;−(''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''y''&lt;sup&gt;2&lt;/sup&gt;)&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''e''&lt;sup&gt;−''r''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt; on the plane '''R'''&lt;sup&gt;2&lt;/sup&gt;, and compute its integral two ways:
*# on the one hand, by [[double integration]] in the [[Cartesian coordinate system]], its integral is a square:
*#: &lt;math&gt;\left(\int e^{-x^2}\,dx\right)^2;&lt;/math&gt;
*# on the other hand, by [[shell integration]] (a case of double integration in [[polar coordinates]]), its integral is computed to be {{mvar|π}}.

Comparing these two computations yields the integral, though one should take care about the improper integrals involved.

&lt;math&gt;\begin{align}
\iint_{\mathbf{R}^2} e^{-(x^2+y^2)}\,d(x,y)
&amp;= \int_0^{2\pi} \int_0^{\infty} e^{-r^2}r\,dr\,d\theta\\
&amp;= 2\pi \int_0^\infty re^{-r^2}\,dr\\
&amp;= 2\pi \int_{-\infty}^0 \tfrac{1}{2} e^s\,ds &amp;&amp; s = -r^2\\
&amp;= \pi \int_{-\infty}^0 e^s\,ds \\
&amp;= \pi (e^0 - e^{-\infty}) \\
&amp;=\pi,
\end{align}&lt;/math&gt;

where the factor of ''r'' is the [[Jacobian determinant]] which appears because of the [[list of canonical coordinate transformations|transform to polar coordinates]] (''r''&amp;nbsp;''dr''&amp;nbsp;''dθ'' is the standard measure on the plane, expressed in polar coordinates [[Wikibooks:Calculus/Polar Integration#Generalization]]), and the substitution involves taking ''s''&amp;nbsp;=&amp;nbsp;−''r''&lt;sup&gt;2&lt;/sup&gt;, so ''ds''&amp;nbsp;=&amp;nbsp;−2''r''&amp;nbsp;''dr''.

Combining these yields

: &lt;math&gt;\left ( \int_{-\infty}^\infty e^{-x^2}\,dx \right )^2=\pi,&lt;/math&gt;

so

: &lt;math&gt;\int_{-\infty}^\infty e^{-x^2}\,dx=\sqrt{\pi}&lt;/math&gt;.

====Complete proof====
To justify the improper double integrals and equating the two expressions, we begin with an approximating function:

:&lt;math&gt;I(a)=\int_{-a}^a e^{-x^2}dx.&lt;/math&gt;

If the integral
:&lt;math&gt;\int_{-\infty}^\infty e^{-x^2}\,dx&lt;/math&gt;
were [[absolutely convergent]] we would have that its [[Cauchy principal value]], that is, the limit

:&lt;math&gt;\lim_{a\to\infty} I(a) &lt;/math&gt;

would coincide with
:&lt;math&gt;\int_{-\infty}^\infty e^{-x^2}\,dx.&lt;/math&gt;
To see that this is the case, consider that

:&lt;math&gt;\int_{-\infty}^\infty |e^{-x^2}|\, dx &lt; \int_{-\infty}^{-1} -x e^{-x^2}\, dx + \int_{-1}^1 e^{-x^2}\, dx+ \int_{1}^{\infty} x e^{-x^2}\, dx&lt;\infty.&lt;/math&gt;

so we can compute
:&lt;math&gt;\int_{-\infty}^\infty e^{-x^2}\,dx&lt;/math&gt;
by just taking the limit
:&lt;math&gt;\lim_{a\to\infty} I(a)&lt;/math&gt;.

Taking the square of &lt;math&gt;I(a)&lt;/math&gt; yields

:&lt;math&gt;\begin{align}
I(a)^2 &amp; = \left ( \int_{-a}^a e^{-x^2}\, dx \right ) \left ( \int_{-a}^a e^{-y^2}\, dy \right ) \\
&amp; = \int_{-a}^a \left ( \int_{-a}^a e^{-y^2}\, dy \right )\,e^{-x^2}\, dx \\
&amp;  = \int_{-a}^a \int_{-a}^a e^{-(x^2+y^2)}\,dy\,dx.
\end{align}&lt;/math&gt;

Using [[Fubini's theorem]], the above double integral can be seen as an area integral

: &lt;math&gt;\iint_{[-a, a] \times [-a, a]} e^{-(x^2+y^2)}\,d(x,y),&lt;/math&gt;

taken over a square with vertices {(−''a'',&amp;nbsp;''a''), (''a'',&amp;nbsp;''a''), (''a'',&amp;nbsp;−''a''), (−''a'',&amp;nbsp;−''a'')} on the ''xy''-[[Cartesian plane|plane]].

Since the exponential function is greater than 0 for all real numbers, it then follows that the integral taken over the square's [[incircle]] must be less than &lt;math&gt;I(a)^2&lt;/math&gt;, and similarly the integral taken over the square's [[circumcircle]] must be greater than &lt;math&gt;I(a)^2&lt;/math&gt;. The integrals over the two disks can easily be computed by switching from cartesian coordinates to [[list of canonical coordinate transformations|polar coordinates]]:

: &lt;math&gt;
\begin{align}
x &amp; = r \cos \theta \\
y &amp; = r \sin\theta
\end{align}
&lt;/math&gt;

:&lt;math&gt;
\mathbf J(r, \theta) = 
\begin{bmatrix}
  \dfrac{\partial x}{\partial r} &amp; \dfrac{\partial x}{\partial\theta}\\[1em]
  \dfrac{\partial y}{\partial r} &amp; \dfrac{\partial y}{\partial\theta} \end{bmatrix}
= \begin{bmatrix}
  \cos\theta&amp; - r\sin \theta \\
  \sin\theta&amp;   r\cos \theta
\end{bmatrix}
&lt;/math&gt;

: &lt;math&gt;
d(x,y) = |J(r, \theta)|d(r,\theta) = r\, d(r,\theta).
&lt;/math&gt;

:&lt;math&gt;\int_0^{2\pi}\int_0^a re^{-r^2}\,dr\,d\theta &lt; I^2(a) &lt; \int_0^{2\pi}\int_0^{a\sqrt{2}} re^{-r^2}\,dr\,d\theta.&lt;/math&gt;

(See [[list of canonical coordinate transformations|to polar coordinates from Cartesian coordinates]] for help with polar transformation.)

Integrating,

:&lt;math&gt;\pi (1-e^{-a^2}) &lt;  I^2(a) &lt; \pi (1 - e^{-2a^2}). &lt;/math&gt;

By the [[squeeze theorem]], this gives the Gaussian integral

:&lt;math&gt;\int_{-\infty}^\infty e^{-x^2}\, dx = \sqrt{\pi}.&lt;/math&gt;

===By Cartesian coordinates===
A different technique, which goes back to Laplace (1812),&lt;ref name="york.ac.uk" /&gt; is the following. Let

: &lt;math&gt;\begin{align}
y &amp; = xs \\
dy &amp; = x\,ds.
\end{align}&lt;/math&gt;

Since the limits on ''s'' as ''y'' → ±∞ depend on the sign of ''x'', it simplifies the calculation to use the fact that ''e''&lt;sup&gt;−''x''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt; is an [[even function]], and, therefore, the integral over all real numbers is just twice the integral from zero to infinity. That is,

:&lt;math&gt;\int_{-\infty}^{\infty} e^{-x^2}\,dx = 2\int_{0}^{\infty} e^{-x^2}\,dx.&lt;/math&gt;

Thus, over the range of integration, ''x'' ≥ 0, and the variables ''y'' and ''s'' have the same limits. This yields:

:&lt;math&gt;\begin{align}
I^2 &amp;= 4 \int_0^\infty \int_0^\infty e^{-(x^2 + y^2)} dy\,dx \\
&amp;= 4 \int_0^\infty \left( \int_0^\infty e^{-(x^2 + y^2)} \, dy \right) \, dx \\
&amp;= 4 \int_0^\infty \left( \int_0^\infty e^{-x^2(1+s^2)} x\,ds \right) \, dx \\
&amp;= 4 \int_0^\infty \left( \int_0^\infty e^{-x^2(1 + s^2)} x \, dx \right) \, ds \\
&amp;= 4 \int_0^\infty \left[ \frac{1}{-2(1+s^2)} e^{-x^2(1+s^2)} \right]_{x=0}^{x=\infty} \, ds \\
&amp;= 4 \left (\frac{1}{2} \int_0^\infty \frac{ds}{1+s^2}  \right ) \\
&amp;= 2 \Big [ \arctan s \Big ]_0^\infty \\
&amp;= \pi.
\end{align}&lt;/math&gt;

Therefore, &lt;math&gt;I = \sqrt{\pi}&lt;/math&gt;, as expected.

==Relation to the gamma function==

The integrand is an [[even function]],

:&lt;math&gt;\int_{-\infty}^{\infty} e^{-x^2} dx = 2 \int_0^\infty e^{-x^2} dx&lt;/math&gt;

Thus, after the change of variable &lt;math&gt;x=\sqrt{t}&lt;/math&gt;, this turns into the Euler integral

:&lt;math&gt;2 \int_0^\infty e^{-x^2} dx=2\int_0^\infty \frac{1}{2}\ e^{-t} \ t^{-\frac{1}{2}} dt = \Gamma\left(\frac{1}{2}\right) = \sqrt{\pi}&lt;/math&gt;

where Γ is the [[gamma function]]. This shows why the [[factorial]] of a half-integer is a rational multiple of &lt;math&gt;\sqrt \pi&lt;/math&gt;. More generally,

:&lt;math&gt;\int_0^\infty e^{-ax^b} dx = \frac{\Gamma\left(\frac{1}{b}\right)}{ba^{\frac{1}{b}}} &lt;/math&gt;

==Generalizations==

===The integral of a Gaussian function===
{{Main|Integral of a Gaussian function}}
The integral of an arbitrary [[Gaussian function]] is

:&lt;math&gt;\int_{-\infty}^{\infty}  e^{-a(x+b)^2}\,dx= \sqrt{\frac{\pi}{a}}.&lt;/math&gt;

An alternative form is

:&lt;math&gt;\int_{-\infty}^{\infty}e^{- a x^2 + b x + c}\,dx=\sqrt{\frac{\pi}{a}}\,e^{\frac{b^2}{4a}+c},&lt;/math&gt;

This form is very useful in calculating mathematical expectations of some continuous probability distributions concerning normal distribution.

See, for example, the expectation of the log-normal distribution.

===''n''-dimensional and functional generalization===
{{main|multivariate normal distribution}}
Suppose ''A'' is a symmetric positive-definite (hence invertible) {{math|''n'' × ''n''}} [[precision matrix]], which is the matrix inverse of the [[covariance matrix]]. Then,

:&lt;math&gt;\int_{-\infty}^\infty \exp{\left(-\frac 1 2 \sum\limits_{i,j=1}^{n}A_{ij} x_i x_j \right)} \, d^nx =\int_{-\infty}^\infty \exp{\left(-\frac 1 2 x^{T} A x \right)} \, d^nx=\sqrt{\frac{(2\pi)^n}{\det A}} =\sqrt{\frac{1}{\det (A / 2\pi)}} =\sqrt{\det (2 \pi A^{-1})}&lt;/math&gt;

where the integral is understood to be over '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.  This fact is applied in the study of the [[multivariate normal distribution]].

Also,

:&lt;math&gt;\int x^{k_1}\cdots x^{k_{2N}} \, \exp{\left( -\frac{1}{2} \sum\limits_{i,j=1}^{n}A_{ij} x_i x_j \right)} \, d^nx =\sqrt{\frac{(2\pi)^n}{\det A}} \, \frac{1}{2^N N!} \, \sum_{\sigma \in S_{2N}}(A^{-1})_{k_{\sigma(1)}k_{\sigma(2)}} \cdots (A^{-1})_{k_{\sigma(2N-1)}k_{\sigma(2N)}}&lt;/math&gt;

where σ is a [[permutation]] of {1, ..., 2''N''} and the extra factor on the right-hand side is the sum over all combinatorial pairings of {1, ..., 2''N''} of ''N'' copies of ''A''&lt;sup&gt;−1&lt;/sup&gt;.

Alternatively, {{Citation needed|date=April 2015}}

:&lt;math&gt;\int f(\vec x) \exp{\left( - \frac 1 2 \sum\limits_{i,j=1}^{n}A_{ij} x_i x_j \right)} d^nx=\sqrt{(2\pi)^n\over \det A} \, \left. \exp{\left({1\over 2}\sum\limits_{i,j=1}^{n}(A^{-1})_{ij}{\partial \over \partial x_i}{\partial \over \partial x_j}\right)}f(\vec{x})\right|_{\vec{x}=0}&lt;/math&gt;

for some [[analytic function]] ''f'', provided it satisfies some appropriate bounds on its growth and some other technical criteria. (It works for some functions and fails for others. Polynomials are fine.) The exponential over a differential operator is understood as a [[power series]].

While [[functional integral]]s have no rigorous definition (or even a nonrigorous computational one in most cases), we can ''define'' a Gaussian functional integral in analogy to the finite-dimensional case. {{Citation needed|date=June 2011}} There is still the problem, though, that &lt;math&gt;(2\pi)^\infty&lt;/math&gt; is infinite and also, the [[functional determinant]] would also be infinite in general. This can be taken care of if we only consider ratios:

:&lt;math&gt;\frac{\int f(x_1)\cdots f(x_{2N}) \exp\left[{-\iint \frac{1}{2}A(x_{2N+1},x_{2N+2}) f(x_{2N+1}) f(x_{2N+2}) d^dx_{2N+1} d^dx_{2N+2}}\right] \mathcal{D}f}{\int \exp\left[{-\iint \frac{1}{2} A(x_{2N+1}, x_{2N+2}) f(x_{2N+1}) f(x_{2N+2}) d^dx_{2N+1} d^dx_{2N+2}}\right] \mathcal{D}f} =\frac{1}{2^N N!}\sum_{\sigma \in S_{2N}}A^{-1}(x_{\sigma(1)},x_{\sigma(2)})\cdots A^{-1}(x_{\sigma(2N-1)},x_{\sigma(2N)}).&lt;/math&gt;

In the [[DeWitt notation]], the equation looks identical to the finite-dimensional case.

===''n''-dimensional with linear term===
If A is again a symmetric positive-definite matrix, then (assuming all are column vectors)
:&lt;math&gt;\int e^{-\frac{1}{2}\sum\limits_{i,j=1}^{n}A_{ij} x_i x_j+\sum\limits_{i=1}^{n}B_i x_i} d^nx=\int e^{-\frac{1}{2}\vec{x}^T \mathbf{A} \vec{x}+\vec{B}^T \vec{x}} d^nx= \sqrt{ \frac{(2\pi)^n}{\det{A}} }e^{\frac{1}{2}\vec{B}^{T}\mathbf{A}^{-1}\vec{B}}.&lt;/math&gt;

===Integrals of similar form===
:&lt;math&gt;\int_0^\infty x^{2n}  e^{-\frac{x^2}{a^2}}\,dx = \sqrt{\pi}\frac{a^{2n+1} (2n-1)!!}{2^{n+1}}&lt;/math&gt;
:&lt;math&gt;\int_0^\infty x^{2n+1} e^{-\frac{x^2}{a^2}}\,dx = \frac{n!}{2} a^{2n+2}&lt;/math&gt;
:&lt;math&gt;\int_0^\infty x^{2n}e^{-ax^2}\,dx = \frac{(2n-1)!!}{a^n 2^{n+1}} \sqrt{\frac{\pi}{a}}&lt;/math&gt;
:&lt;math&gt;\int_0^\infty x^{2n+1}e^{-ax^2}\,dx = \frac{n!}{2a^{n+1}}&lt;/math&gt;
:&lt;math&gt;\int_0^\infty x^{n}e^{-ax^2}\,dx = \frac{\Gamma(\frac{n+1}{2})}{2a^{\frac{n+1}{2}}}&lt;/math&gt;
where ''n'' is a positive integer and !! denotes the [[double factorial]].

An easy way to derive these is by [[differentiation under the integral sign|parameter differentiation]].

:&lt;math&gt;\begin{align}
\int_{-\infty}^\infty x^{2n} e^{-\alpha x^2}\,dx &amp;= \left(-1\right)^n\int_{-\infty}^\infty \frac{\partial^n}{\partial \alpha^n} e^{-\alpha x^2}\,dx ~= \left(-1\right)^n\frac{\partial^n}{\partial \alpha^n} \int_{-\infty}^\infty e^{-\alpha x^2}\,dx\\
&amp;= \sqrt{\pi} \left(-1\right)^n\frac{\partial^n}{\partial \alpha^n}\alpha^{-\frac{1}{2}} ~= \sqrt{\frac{\pi}{\alpha}}\frac{(2n-1)!!}{\left(2\alpha\right)^n}
\end{align}&lt;/math&gt;

One could also integrate by parts and find a [[recurrence relation]] to solve this.

===Higher-order polynomials===

Applying a linear change of basis shows that the integral of the exponential of a homogeneous polynomial in ''n'' variables may depend only on [[SL(n)]]-invariants of the polynomial. One such invariant is the [[discriminant]],
zeros of which mark the singularities of the integral. However, the integral may also depend on other invariants.&lt;ref name="morozov2009"&gt;{{cite journal
 | last = Morozov | first = A.
 | last2 = Shakirove | first2= Sh.
 | journal = Journal of High Energy Physics
 | pages = 002
 | title = Introduction to integral discriminants
 | doi = 10.1088/1126-6708/2009/12/002
 | volume = 12
 | year = 2009 }}&lt;/ref&gt;

Exponentials of other even polynomials can numerically be solved using series. These may be interpreted as [[formal calculation]]s when there is no convergence. For example, the solution to the integral of the exponential of a quartic polynomial is{{citation needed|date=August 2015}}

: &lt;math&gt;\int_{-\infty}^{\infty} e^{a x^4+b x^3+c x^2+d x+f}\,dx =\frac12 e^f \ \sum_{\begin{smallmatrix}n,m,p=0 \\ n+p=0 \mod 2\end{smallmatrix}}^{\infty} \ \frac{b^n}{n!}    \frac{c^m}{m!} \frac{d^p}{p!} \frac{\Gamma \left (\frac{3n+2m+p+1}{4} \right)}{(-a)^{\frac{3n+2m+p+1}4}}.&lt;/math&gt;

The ''n''&amp;nbsp;+&amp;nbsp;''p'' = 0 mod 2 requirement is because the integral from −∞ to 0 contributes a factor of (−1)&lt;sup&gt;''n''+''p''&lt;/sup&gt;/2 to each term, while the integral from 0 to +∞ contributes a factor of 1/2 to each term. These integrals turn up in subjects such as [[quantum field theory]].

==See also==
* [[List of integrals of Gaussian functions]]
* [[Common integrals in quantum field theory]]
* [[Normal distribution]]
* [[List of integrals of exponential functions]]
* [[Error function]]
* [[Grassmann integral]]

==References==
{{reflist}}
*{{MathWorld|title=Gaussian Integral|urlname=GaussianIntegral}}
* {{cite book |first=David |last=Griffiths |title=Introduction to Quantum Mechanics |edition=2nd }}
* {{cite book |last=Abramowitz |first=M. |last2=Stegun |first2=I. A. |title=Handbook of Mathematical Functions |publisher=Dover Publications |location=New York }}

{{integral}}

[[Category:Integrals]]
[[Category:Articles containing proofs]]
[[Category:Gaussian function]]
[[Category:Theorems in analysis]]</text>
      <sha1>mo534dm04msyludzbyhjj7u9adh6cmo</sha1>
    </revision>
  </page>
  <page>
    <title>Generalized minimum-distance decoding</title>
    <ns>0</ns>
    <id>31707735</id>
    <revision>
      <id>810523049</id>
      <parentid>737820594</parentid>
      <timestamp>2017-11-15T19:53:22Z</timestamp>
      <contributor>
        <ip>213.16.210.142</ip>
      </contributor>
      <comment>/* Randomized algorithm */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12255">In [[coding theory]], '''generalized minimum-distance (GMD) decoding''' provides an efficient [[algorithm]] for decoding [[concatenated code]]s, which is based on using an [[error]]s-and-[[Erasure code|erasures]] decoder for the [[outer code]].

A [[Concatenated error correction code#Decoding concatenated codes|naive decoding algorithm]] for concatenated codes can not be an optimal way of decoding because it does not take into account the information that [[maximum likelihood decoding]] (MLD) gives. In other words, in the naive algorithm, inner received [[codeword]]s are treated the same regardless of the difference between their [[hamming distance]]s. Intuitively, the outer decoder should place higher confidence in symbols whose inner [[code|encodings]] are close to the received word. [[David Forney]] in 1966 devised a better algorithm called generalized minimum distance (GMD) decoding which makes use of those information better. This method is achieved by measuring confidence of each received codeword, and erasing symbols whose confidence is below a desired value. And GMD decoding algorithm was one of the first examples of [[soft-decision decoder]]s. We will present three versions of the GMD decoding algorithm. The first two will be [[randomized algorithm]]s while the last one will be a [[deterministic algorithm]].

==Setup==
* [[Hamming distance]] : Given two [[Euclidean vector|vector]]s &lt;math&gt;u, v\in\Sigma^n&lt;/math&gt; the Hamming distance between &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt;, denoted by &lt;math&gt;\Delta(u, v)&lt;/math&gt;, is defined to be the number of positions in which &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;v&lt;/math&gt; differ.
* Minimum distance: Let &lt;math&gt;C\subseteq\Sigma^n&lt;/math&gt; be a [[code]]. The minimum distance of code &lt;math&gt;C&lt;/math&gt; is defined to be &lt;math&gt;d= \min\Delta(c_1, c_2)&lt;/math&gt; where &lt;math&gt;c_1 \ne c_2 \in C &lt;/math&gt;
* Code concatenation: Given &lt;math&gt;m = (m_1, \cdots, m_K) \in [Q]^K&lt;/math&gt;, consider two codes which we call outer code and inner code 
::&lt;math&gt;C_\text{out} = [Q]^K \to [Q]^N,  \qquad C_\text{in} : [q]^k \to [q]^n,&lt;/math&gt;
:and their distances are &lt;math&gt;D&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt;. A concatenated code can be achieved by &lt;math&gt;C_\text{out} \circ C_\text{in} (m) = (C_\text{in} (C_\text{out} (m)_1), \ldots, C_\text{in} (C_\text{out} (m)_N))&lt;/math&gt; where &lt;math&gt;C_\text{out}(m) = ((C_\text{out} (m)_1, \ldots, (m)_N)).&lt;/math&gt; Finally we will take &lt;math&gt;C_\text{out}&lt;/math&gt; to be [[Reed Solomon|RS code]], which has an errors and erasure decoder, and &lt;math&gt;K = O(\log N)&lt;/math&gt;, which in turn implies that MLD on the inner code will be polynomial in &lt;math&gt;N&lt;/math&gt; time.
* Maximum likelihood decoding (MLD): MLD is a decoding method for error correcting codes, which outputs the codeword closest to the received word in Hamming distance. The MLD function denoted by &lt;math&gt;D_{MLD} : \Sigma^n \to C&lt;/math&gt; is defined as follows. For every &lt;math&gt;y\in\Sigma^n, D_{MLD}(y) = \arg \min_{c \in C}\Delta(c, y)&lt;/math&gt;.
* [[Probability density function]] : A [[probability distribution]] &lt;math&gt;\Pr&lt;/math&gt; on a sample space &lt;math&gt;S&lt;/math&gt; is a mapping from events of &lt;math&gt;S&lt;/math&gt; to [[real number]]s such that &lt;math&gt;\Pr[A] \ge 0&lt;/math&gt; for any event &lt;math&gt;A, \Pr[S] = 1&lt;/math&gt;, and &lt;math&gt;\Pr[A \cup B] = \Pr[A] + \Pr[B]&lt;/math&gt; for any two mutually exclusive events &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;
* [[Expected value]]: The expected value of a [[discrete random variable]] &lt;math&gt;X&lt;/math&gt; is 
::&lt;math&gt;\mathbb{E}[X] = \sum_x \Pr[X = x].&lt;/math&gt;

==Randomized algorithm==
Consider the received word &lt;math&gt;\mathbf{y} = (y_1,\ldots,y_N) \in [q^n]^N&lt;/math&gt; which was corrupted by a [[noisy channel]]. The following is the algorithm description for the general case. In this algorithm, we can decode y by just declaring an erasure at every bad position and running the errors and erasure decoding algorithm for &lt;math&gt;C_\text{out}&lt;/math&gt; on the resulting vector.

'''Randomized_Decoder'''
&lt;br /&gt;'''Given : '''&lt;math&gt;\mathbf{y} = (y_1,\dots,y_N) \in [q^n]^N&lt;/math&gt;.
# For every &lt;math&gt;1 \le i \le N&lt;/math&gt;, compute &lt;math&gt;y_i' = MLD_{C_\text{in}}(y_i)&lt;/math&gt;.
# Set &lt;math&gt;\omega_i = \min(\Delta(C_\text{in}(y_i'), y_i), \tfrac{d}{2})&lt;/math&gt;.
# For every &lt;math&gt;1 \le i \le N&lt;/math&gt;, repeat : With probability &lt;math&gt;2\omega_i \over d&lt;/math&gt;, set &lt;math&gt;y_i'' \leftarrow ?,&lt;/math&gt; otherwise set &lt;math&gt;y_i'' = y_i'&lt;/math&gt;.
# Run errors and erasure algorithm for &lt;math&gt;C_\text{out}&lt;/math&gt; on &lt;math&gt;\mathbf{y}'' = (y_1'', \ldots, y_N'')&lt;/math&gt;.

'''Theorem 1.''' ''Let y be a received word such that there exists a [[codeword]]'' &lt;math&gt;\mathbf{c} = (c_1,\cdots, c_N) \in C_\text{out}\circ{C_\text{in}} \subseteq  [q^n]^N&lt;/math&gt; ''such that'' &lt;math&gt;\Delta(\mathbf{c}, \mathbf{y}) &lt; \tfrac{Dd}{2}&lt;/math&gt;. ''Then the deterministic GMD algorithm outputs'' &lt;math&gt;\mathbf{c}&lt;/math&gt;.

Note that a [[Concatenated codes|naive decoding algorithm for concatenated codes]] can correct up to &lt;math&gt;\tfrac{Dd}{4}&lt;/math&gt; errors.

:'''Lemma 1.''' Let the assumption in Theorem 1 hold. And if &lt;math&gt;\mathbf{y}''&lt;/math&gt; has &lt;math&gt;e'&lt;/math&gt; errors and &lt;math&gt;s'&lt;/math&gt; erasures (when compared with &lt;math&gt;\mathbf{c}&lt;/math&gt;) after '''Step 1''', then &lt;math&gt;\mathbb{E}[2e' + s'] &lt; D.&lt;/math&gt;

''Remark.'' If &lt;math&gt;2e' + s' &lt; D&lt;/math&gt;, then the algorithm in '''Step 2''' will output &lt;math&gt;\mathbf{c}&lt;/math&gt;. The lemma above says that in expectation, this is indeed the case. Note that this is not enough to prove '''Theorem 1''', but can be crucial in developing future variations of the algorithm.

'''Proof of lemma 1.''' For every &lt;math&gt;1 \le i \le N,&lt;/math&gt; define &lt;math&gt;e_i = \Delta(y_i, c_i).&lt;/math&gt; This implies that

:&lt;math&gt;\sum_{i=1}^N e_i &lt;   \frac{Dd}{2} \qquad\qquad (1)&lt;/math&gt;

Next for every &lt;math&gt;1 \le i \le N&lt;/math&gt;, we define two [[indicator variable]]s:

: &lt;math&gt;\begin{align}
X{_i^?} = 1  &amp;\Leftrightarrow  y_i'' = ? \\
X{_i^e} = 1 &amp;\Leftrightarrow C_\text{in}(y_i'') \ne c_i \ \text{and} \ y_i'' \neq ?
\end{align}&lt;/math&gt;

We claim that we are done if we can show that for every &lt;math&gt;1 \le i \le N&lt;/math&gt;:

: &lt;math&gt;\mathbb{E} \left [2X{_i^e + X{_i^?}} \right ] \leqslant  {2e_i \over d}\qquad\qquad (2)&lt;/math&gt;

Clearly, by definition 

:&lt;math&gt;e' = \sum_i X_i^e \quad \text{and} \quad s' = \sum_i X_i^?.&lt;/math&gt; 

Further, by the [[linear]]ity of expectation, we get 

:&lt;math&gt;\mathbb{E}[2e' + s'] \leqslant \frac{2}{d}\sum_ie_i &lt; D.&lt;/math&gt;

To prove (2) we consider two cases: &lt;math&gt;i&lt;/math&gt;-th block is correctly decoded ('''Case 1'''),  &lt;math&gt;i&lt;/math&gt;-th block is incorrectly decoded ('''Case 2'''):

'''Case 1:''' &lt;math&gt;(c_i = C_\text{in}(y_i'))&lt;/math&gt;

Note that if &lt;math&gt;y_i'' = ?&lt;/math&gt; then &lt;math&gt;X_i^e = 0&lt;/math&gt;, and &lt;math&gt;\Pr[y_i'' = ?] = \tfrac{2\omega_i}{d}&lt;/math&gt; implies &lt;math&gt;\mathbb{E}[X_i^?] = \Pr[X_i^? = 1] = \tfrac{2\omega_i}{d},&lt;/math&gt; and &lt;math&gt;\mathbb{E}[X_i^e] = \Pr[X_i^e = 1] = 0&lt;/math&gt;.

Further, by definition we have

: &lt;math&gt;\omega_i = \min \left (\Delta(C_\text{in}(y_i'), y_i), \tfrac{d}{2} \right ) \leqslant \Delta(C_\text{in}(y_i'), y_i) = \Delta(c_i, y_i) = e_i&lt;/math&gt;

'''Case 2:''' &lt;math&gt;(c_i \ne C_\text{in}(y_i'))&lt;/math&gt;

In this case, &lt;math&gt;\mathbb{E}[X_i^?] = \tfrac{2\omega_i}{d}&lt;/math&gt; and &lt;math&gt;\mathbb{E}[X_i^e] = \Pr[X_i^e = 1] = 1 - \tfrac{2\omega_i}{d}.&lt;/math&gt;

Since &lt;math&gt;c_i \ne C_\text{in}(y_i'), e_i + \omega_i \geqslant d&lt;/math&gt;. This follows [http://www.cse.buffalo.edu/~atri/courses/coding-theory/lectures/lect28.pdf another case analysis] when &lt;math&gt;(\omega_i = \Delta(C_\text{in}(y_i'),  y_i) &lt; \tfrac{d}{2})&lt;/math&gt; or not.

Finally, this implies

: &lt;math&gt;\mathbb{E}[2X_i^e + X_i^?] = 2 - {2\omega_i \over d} \le {2e_i \over d}.&lt;/math&gt;

In the following sections, we will finally show that the deterministic version of the algorithm above can do unique decoding of &lt;math&gt;C_\text{out} \circ C_\text{in}&lt;/math&gt; up to half its design distance.

==Modified randomized algorithm==
Note that, in the previous version of the GMD algorithm in step "3", we do not really need to use "fresh" [[randomness]] for each &lt;math&gt;i&lt;/math&gt;. Now we come up with another randomized version of the GMD algorithm that uses the ''same'' randomness for every &lt;math&gt;i&lt;/math&gt;. This idea follows the algorithm below.

'''Modified_Randomized_Decoder'''
&lt;br /&gt;'''Given : '''&lt;math&gt;\mathbf{y} = (y_1, \ldots,y_N) \in [q^n]^N&lt;/math&gt;, pick &lt;math&gt;\theta \in [0, 1]&lt;/math&gt; at random. Then every for every &lt;math&gt;1 \le i \le N&lt;/math&gt;:
# Set &lt;math&gt;y_i' = MLD_{C_\text{in}}(y_i)&lt;/math&gt;.
# Compute &lt;math&gt;\omega_i = \min(\Delta(C_\text{in}(y_i'), y_i), {d\over2})&lt;/math&gt;.
# If &lt;math&gt;\theta&lt; \tfrac{2\omega_i}{d}&lt;/math&gt;, set &lt;math&gt;y_i'' \leftarrow ?,&lt;/math&gt; otherwise set &lt;math&gt;y_i'' = y_i'&lt;/math&gt;.
# Run errors and erasure algorithm for &lt;math&gt;C_\text{out}&lt;/math&gt; on &lt;math&gt;\mathbf{y}'' = (y_1'',\ldots, y_N'')&lt;/math&gt;.

For the proof of '''[[Lemma (mathematics)|Lemma 1]]''', we only use the randomness to show that

: &lt;math&gt;\Pr[y_i'' = ?] = {2\omega_i \over d}.&lt;/math&gt;

In this version of the GMD algorithm, we note that

: &lt;math&gt;\Pr[y_i'' = ?] = \Pr \left [\theta \in \left [0, \tfrac{2\omega_i}{d} \right ] \right ] = \tfrac{2\omega_i}{d}.&lt;/math&gt;

The second [[Equality (mathematics)|equality]] above follows from the choice of &lt;math&gt;\theta&lt;/math&gt;. The proof of '''Lemma 1''' can be also used to show &lt;math&gt;\mathbb{E}[2e' + s'] &lt; D&lt;/math&gt; for version2 of GMD. In the next section, we will see how to get a deterministic version of the GMD algorithm by choosing &lt;math&gt;\theta&lt;/math&gt; from a polynomially sized set as opposed to the current infinite set &lt;math&gt;[0, 1]&lt;/math&gt;.

==Deterministic algorithm==
Let &lt;math&gt;Q = \{0,1\} \cup \{{2\omega_1 \over d}, \ldots,{2\omega_N \over d}\}&lt;/math&gt;. Since for each &lt;math&gt;i, \omega_i = \min(\Delta(\mathbf{y_i'}, \mathbf{y_i}), {d \over 2})&lt;/math&gt;, we have

: &lt;math&gt;Q = \{0, 1\} \cup \{q_1, \ldots,q_m\}&lt;/math&gt;

where &lt;math&gt;q_1 &lt; \cdots &lt; q_m&lt;/math&gt; for some &lt;math&gt;m \le \left \lfloor \frac{d}{2} \right \rfloor&lt;/math&gt;. Note that for every &lt;math&gt;\theta \in [q_i, q_{i+1}]&lt;/math&gt;, the step 1 of the second version of randomized algorithm outputs the same &lt;math&gt;\mathbf{y}''.&lt;/math&gt;. Thus, we need to consider all possible value of &lt;math&gt;\theta \in Q&lt;/math&gt;. This gives the deterministic algorithm below.

'''Deterministic_Decoder'''
&lt;br /&gt;'''    Given : '''&lt;math&gt;\mathbf{y} = (y_1,\ldots,y_N) \in [q^n]^N&lt;/math&gt;, for every &lt;math&gt;\theta \in Q&lt;/math&gt;, repeat the following.
# Compute &lt;math&gt;y_i' = MLD_{C_\text{in}}(y_i)&lt;/math&gt; for &lt;math&gt;1 \le i \le N&lt;/math&gt;.
# Set &lt;math&gt;\omega_i = \min(\Delta(C_\text{in}(y_i'), y_i), {d\over2})&lt;/math&gt; for every &lt;math&gt;1 \le i \le N&lt;/math&gt;.
# If &lt;math&gt;\theta &lt; {2\omega_i \over d}&lt;/math&gt;, set &lt;math&gt;y_i'' \leftarrow ?,&lt;/math&gt; otherwise set &lt;math&gt;y_i'' = y_i'&lt;/math&gt;.
# Run errors-and-erasures algorithm for &lt;math&gt;C_\text{out}&lt;/math&gt; on &lt;math&gt;\mathbf{y}'' = (y_1'', \ldots, y_N'')&lt;/math&gt;. Let &lt;math&gt;c_\theta&lt;/math&gt; be the codeword in &lt;math&gt;C_\text{out} \circ C_\text{in}&lt;/math&gt; corresponding to the output of the algorithm, if any.
# Among all the &lt;math&gt;c_\theta&lt;/math&gt; output in 4, output the one closest to &lt;math&gt;\mathbf{y}&lt;/math&gt;

Every loop of 1~4 can be run in [[polynomial time]], the algorithm above can also be computed in polynomial time. Specifically, each call to an errors and erasures decoder of &lt;math&gt;&lt;dD/2&lt;/math&gt; errors takes &lt;math&gt;O(d)&lt;/math&gt; time. Finally, the runtime of the algorithm above is &lt;math&gt;O(NQn^{O(1)} + NT_\text{out})&lt;/math&gt; where &lt;math&gt;T_\text{out}&lt;/math&gt; is the running time of the outer errors and erasures decoder.

==See also==
#[[Concatenated code]]s
#[[Reed Solomon|Reed Solomon error correction]]
#[[Berlekamp–Welch algorithm|Welch Berlekamp algorithm]]

==References==
#[http://www.cse.buffalo.edu/~atri/courses/coding-theory/lectures University at Buffalo Lecture Notes on Coding Theory – Atri Rudra]
#[http://people.csail.mit.edu/madhu/FT01 MIT Lecture Notes on Essential Coding Theory – Madhu Sudan]
#[http://www.cs.washington.edu/education/courses/cse533/06au University of Washington – Venkatesan Guruswami]
#G. David Forney. Generalized Minimum Distance decoding. ''IEEE Transactions on Information Theory'', 12:125–131, 1966

{{DEFAULTSORT:Generalized minimum distance decoding}}
[[Category:Error detection and correction]]
[[Category:Coding theory]]
[[Category:Finite fields]]
[[Category:Information theory]]</text>
      <sha1>4bz2g8e70wob5j3bkry57ynampxvwmd</sha1>
    </revision>
  </page>
  <page>
    <title>Gert Sabidussi</title>
    <ns>0</ns>
    <id>31554519</id>
    <revision>
      <id>840276511</id>
      <parentid>840210476</parentid>
      <timestamp>2018-05-08T21:16:22Z</timestamp>
      <contributor>
        <ip>63.92.248.153</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2266">'''Gert Sabidussi''' (born 28 October 1929 in [[Graz]]) is an [[Austrian people|Austrian]] [[mathematician]] specializing in [[combinatorics]] and [[graph theory]].

== Biography ==
Sabidussi was born in [[Graz]], [[Austria]].  His family later moved to [[Innsbruck]] where his father was a Protestant [[deacon]]. He graduated from the [[University of Vienna]], where he attended lectured by [[Felix Ehrenhaft]], [[Nikolaus Hofreiter]], [[Johann Radon]] and [[Hans Thirring]].  In 1953, he defended his [[Ph.D.|doctorate]] on [[Logical matrix|0-1 matrices]] under the supervision of [[Edmund Hlawka]] and received a two-year fellowship at [[Princeton University]].  He was then an Instructor at [[University of Minnesota]] in [[Minneapolis]], but because of the heavy teaching load moved a year later, in 1956, to [[Tulane University]] in [[New Orleans]].  He moved to [[Montreal]] in 1963, and was instrumental in bringing to Canada a number of combinatorialists and graph theorists, including [[Anton Kotzig]], and [[Jaroslav Nešetřil]] who wrote a thesis under Sabidussi.  He first worked at [[McMaster University]] and then at [[University of Montreal]].  Over the years, he had 13 graduate students.  His 60th, 70th and 80th birthdays were celebrated with large Graph Theory birthday conferences.

== Mathematical work==
Sabidussi wrote foundational work on [[Cayley graph]]s, [[graph product]]s and [[Frucht's theorem]].

== References ==
* [http://www.oemg.ac.at/IMN/imn185.pdf Sabidussi's Biography]  (in [[German language|German]])

== External links ==
* [http://www.dms.umontreal.ca/Professeurs/sab/ Gert Sabidussi Web Page] at Université de Montréal.
*{{MathGenealogy |id=27194}}
* [http://www.cs.sfu.ca/news/conferences/AlgebraicGraphTheory/2009/ Algebraic Graph Theory 2009], a Conference in celebration of Gert Sabidussi's 80th birthday.

{{Authority control}}

{{DEFAULTSORT:Sabidussi, Gert}}
[[Category:1929 births]]
[[Category:People from Graz]]
[[Category:Living people]]
[[Category:Austrian mathematicians]]
[[Category:Canadian mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Graph theorists]]
[[Category:Université de Montréal faculty]]
[[Category:University of Vienna alumni]]</text>
      <sha1>7pvi3gzqiwtsb003bdejgyoofw4npbk</sha1>
    </revision>
  </page>
  <page>
    <title>Global cascades model</title>
    <ns>0</ns>
    <id>44402565</id>
    <revision>
      <id>865618061</id>
      <parentid>846609569</parentid>
      <timestamp>2018-10-25T02:07:26Z</timestamp>
      <contributor>
        <ip>202.20.193.254</ip>
      </contributor>
      <comment>/* See also */ Changed link to percolation theory instead of percolation process</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6880">{{Network Science}} 
'''Global cascades models''' are a class of models aiming to model large and rare cascades that are triggered by exogenous perturbations which are relatively small compared with the size of the system. The phenomenon occurs ubiquitously in various systems, like [[information cascade]]s in social systems, [[stock market crash]]es in economic systems, and [[cascading failure]] in physics infrastructure networks. The models capture some essential properties of such phenomenon.

==Model description==
To describe and understand global cascades, a network-based [[threshold model]] has been proposed by [[Duncan J. Watts]] in 2002.&lt;ref name="PNAS2002"&gt;{{Cite journal | last1 = Watts | first1 = D. J. | title = A simple model of global cascades on random networks | doi = 10.1073/pnas.082090499 | journal = Proceedings of the National Academy of Sciences | volume = 99 | issue = 9 | pages = 5766–5771| year = 2002 | pmid =  | pmc = 122850| bibcode = 2002PNAS...99.5766W}}&lt;/ref&gt; The model is motivated by considering a population of individuals who must make a decision between two alternatives, and their choices depend explicitly on other people's states or choices. The model assumes that an individual will adopt a new particular opinion (product or state) if a threshold fraction of his/her neighbors have adopted the new one, else he would keep his original state. To initiate the model, a new opinion will be randomly distributed among a small fraction of individuals in the network. If the fraction satisfies a particular condition, a large cascades can be triggered.(see Global Cascades Condition) A [[phase transition]] phenomenon has been observed: when the network of interpersonal influences is sparse, the size of the cascades exhibits a [[power law]] distribution, the most highly connected nodes are critical in triggering cascades, and if the network is relatively dense, the distribution shows a bimodal form, in which nodes with average degree show more importance by serving as triggers.

Several generalizations of the Watt's threshold model have been proposed and analyzed in the following years. For example, the original model has been combined with independent interaction models to provide a generalized model of social contagion,  which classifies the behavior of the system into three universal classes.&lt;ref&gt;{{Cite journal | last1 = Dodds | first1 = P. | last2 = Watts | first2 = D. | doi = 10.1103/PhysRevLett.92.218701 | title = Universal Behavior in a Generalized Model of Contagion | journal = Physical Review Letters | volume = 92 | issue = 21 | year = 2004 | pmid =  | pmc = |arxiv = cond-mat/0403699 |bibcode = 2004PhRvL..92u8701D }}&lt;/ref&gt; It has also been generalized on modular networks &lt;ref&gt;{{cite journal|last1=Gleeson|first1=James.P|title=Cascades on correlated and modular random networks|journal=Physical Review E | year= 2008 | doi=10.1103/PhysRevE.77.046117|volume=77|bibcode=2008PhRvE..77d6117G}}&lt;/ref&gt; degree-correlated networks &lt;ref&gt;{{cite journal|last1=Dodds|first1=Peter Sheridan|last2=Payne|first2=Joshua L.|title=Analysis of a threshold model of social contagion on degree-correlated networks|journal=Physical Review E | year= 2009 |doi=10.1103/PhysRevE.79.066115|volume=79|arxiv=0903.0597|bibcode=2009PhRvE..79f6115D}}&lt;/ref&gt; and to networks with tunable clustering.&lt;ref&gt;{{cite journal|last1=Hackett|first1=Adam|last2=Melnik|first2=Sergey|last3=Gleeson|first3=James.P| title=Cascades on a class of clustered random networks|journal=Physical Review E | year= 2011 |doi=10.1103/PhysRevE.83.056107|volume=83|arxiv=1012.3651|bibcode=2011PhRvE..83e6107H}}&lt;/ref&gt; The role of the initiators has also been studied recently, shows that different initiator would influence the size of the cascades.&lt;ref&gt;{{cite journal|last1=Singh|first1=P.|last2=Sreenivasan|first2=S.|last3=Szymanski|first3=B.K|last4=Korniss|first4=G.|title=Threshold-limited spreading in social networks with multiple initiators|journal=Scientific Reports |year=2013|doi=10.1016/j.physa.2008.01.015|volume=387|pages=2637–2652|bibcode=2008PhyA..387.2637K}}&lt;/ref&gt;

==Global cascades condition== 
To derive the precise cascade condition in the original model, a [[generating function]] method could be applied.&lt;ref name="PNAS2002" /&gt; The generating function for vulnerable nodes in the network is:

:&lt;math&gt; G_0(x)= \sum_k \rho_k p_k x^k,&lt;/math&gt;
where ''p''&lt;sub&gt;''k''&lt;/sub&gt; is the probability a node has degree ''k'', and 
:&lt;math&gt; \rho_k =
\begin{cases}
1  &amp; k=0 \\
\int_0^{1/k}f(\chi) \, d\chi &amp; k&gt;0 \\
\end{cases} 
 &lt;/math&gt;
and ''f'' is the distribution of the threshold fraction of individuals. The average vulnerable cluster size can be derived as:

:&lt;math&gt; \langle n\rangle=G_0(1)+\frac{G_0'(1)^2}{z-G_0''(1)} &lt;/math&gt;

where ''z'' is the average degree of the network. The Global cascades occur when the average vulnerable cluster size &lt;''n''&gt; diverges&lt;ref name="PNAS2002" /&gt;

: &lt;math&gt;
 G_0''(1)=\sum_k k(k-1) \rho_k p_k = z
&lt;/math&gt;

The equation could be interpreted as: When &lt;math&gt;G_0''(1)&lt;z&lt;/math&gt;, the clusters in the network is small and global cascades will not happen since the early adopters are isolated in the system, thus no enough momentum could be generated. When &lt;math&gt;G_0''(1)&gt;z&lt;/math&gt;, the typical size of the vulnerable cluster is infinite, which implies presence of global cascades.

==Relations with other contagion models==
The Model considers a change of state of individuals in different systems which belongs to a larger class of contagion problems. However it differs with other models in several aspects: Compared with 1) [[epidemic model]]: where contagion events between individual pairs are independent, the effect a single infected node having on an individual depends on the individual's other neighbors in the proposed model.  Unlike 2) [[percolation]] or [[self-organized criticality]] models, the threshold is not expressed as the absolute number of "infected" neighbors around an individual, instead, a corresponding fraction of neighbors is selected. It is also different from 3) random-field [[ising model]] and majority [[voter model]], which are frequently analyzed on regular lattices, here, however the heterogeneity of the network plays a significant role.

==See also==
*[[Threshold model]]
*[[Information cascade]]
*[[Stock market crash]]
*[[Cascading failure]]
*[[Epidemic model]]
*[[Percolation_theory]]
*[[Self-organized criticality]]
*[[Ising model]]
*[[Voter model]]
*[[Complex contagion]]
*[[Sociological theory of diffusion]]
*[[Global Cascade|Global cascade]]

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags, these references will then appear here automatically --&gt;
{{Reflist}}

&lt;!--- Categories ---&gt;
[[Category:Mathematical modeling]]
[[Category:Network theory]]
[[Category:Articles created via the Article Wizard]]</text>
      <sha1>rm84pgkvtu33y0v2roxww13trwqmycg</sha1>
    </revision>
  </page>
  <page>
    <title>Graded-symmetric algebra</title>
    <ns>0</ns>
    <id>52405621</id>
    <revision>
      <id>810709350</id>
      <parentid>810708923</parentid>
      <timestamp>2017-11-16T23:27:11Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <minor/>
      <comment>/* top */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1565">In algebra, given a commutative ring ''R'', the '''graded-symmetric algebra''' of a [[graded module|graded ''R''-module]] ''M'' is the quotient of the [[tensor algebra]] of ''M'' by the ideal ''I''; here the ideal ''I'' is generated by elements of the form:
*&lt;math&gt;xy - (-1)^{|x||y|}yx&lt;/math&gt;
*&lt;math&gt;x^2&lt;/math&gt; when |''x''| is odd
for homogeneous elements ''x'', ''y'' in ''M'' of degree |''x''|, |''y''|. By construction, a graded-symmetric algebra is [[graded-commutative ring|graded-commutative]]; i.e., &lt;math&gt;xy = (-1)^{|x||y|} yx&lt;/math&gt; and is universal for this.

In spite of the name, the notion is a common generalization of a [[symmetric algebra]] and an [[exterior algebra]]: indeed, if ''V'' is a (non-graded) ''R''-module, then the graded-symmetric algebra of ''V'' with trivial grading is the usual symmetric algebra of ''V''. Similarly, the graded-symmetric algebra of the graded module with ''V'' in degree one and zero elsewhere is the exterior algebra of ''V''.

==References==
* [[David Eisenbud]], ''Commutative Algebra. With a view toward algebraic geometry'', [[Graduate Texts in Mathematics]], vol 150, [[Springer-Verlag]], New York, 1995.  {{ISBN|0-387-94268-8}}

==External links==
*{{cite web|url=http://mathoverflow.net/questions/7080/definition-of-the-symmetric-algebra-in-arbitrary-characteristic-for-graded-vecto |title=rt.representation theory - Definition of the symmetric algebra in arbitrary characteristic for graded vector spaces |publisher=MathOverflow |date= |accessdate=2017-04-18}}


{{algebra-stub}}

[[Category:Ring theory]]</text>
      <sha1>p13lagrb3e7iyjt7fl0ei6wb8hm79ui</sha1>
    </revision>
  </page>
  <page>
    <title>Hans Eberstark</title>
    <ns>0</ns>
    <id>455398</id>
    <revision>
      <id>868567191</id>
      <parentid>863376073</parentid>
      <timestamp>2018-11-13T00:56:32Z</timestamp>
      <contributor>
        <username>Brenont</username>
        <id>4034676</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4329">'''Hans Eberstark''' (27 January 1929 in Vienna&lt;ref&gt;Ida Fleiss: Hochbegabung und Hochbegabte. Tectum Verlag, Marburg 2003, p. 70&lt;/ref&gt; – 19 December 2001&lt;ref&gt;[http://archives.tdg.ch/TG/TG/-/article-2006-12-985/in-memoriam--hans-eberstark---2001---19-decembre---2006-quand-un-vieux-sage-meurt-c-est-une Memorial notice in the ''Tribune de Genève'']{{dead link|date=August 2012}}&lt;/ref&gt;&lt;ref&gt;[https://search.ancestry.com/cgi-bin/sse.dll?indiv=1&amp;dbid=7545&amp;h=23596036&amp;tid=&amp;pid=&amp;usePUB=true&amp;_phsrc=AyH86&amp;_phstart=successSource Ancestry.com. U.S., Obituary Collection, 1930-2018 [database on-line]. Lehi, UT, USA: Ancestry.com Operations Inc, 2006&lt;/ref&gt;) was an [[Austria]]n linguist, translator, and [[mental calculator]].

Eberstark often lectured on [[language]] and [[translation]] in Europe and was known for asking someone whose first language was a small local [[dialect]] of [[German language|German]] (particularly [[Swiss German]], of which there are countless dialects) to speak with him (during the lecture); after a few minutes Eberstark would suddenly start speaking fluently in that dialect.&lt;ref name=Bernstein/&gt;

Of Viennese Jewish origin, he spent eight years in [[Shanghai]] during World War II, with many other displaced people from all over Europe.  It was there that he was exposed to many different languages. He once told science writer [[Jeremy Bernstein]] that to his "eternal disgrace" he had not learned to speak Chinese "properly" while there, but Bernstein noted that Eberstark's standards for speaking a language were "different from most people's."&lt;ref name=Bernstein&gt;Jeremy Bernstein, ''A Theory for Everything,''  Springer (1976), pages 205 and following&lt;/ref&gt;

Eberstark was living in Vienna, Austria, when he joined [[Mensa International]]. After he moved to [[Geneva, Switzerland]] in 1965 to work as an interpreter with the [[International Labour Organization]], he founded a Mensa chapter in that city.&lt;ref&gt;[https://www.mensa.ch/fr/history] Mark Dettinger, "The History of Mensa," ''Mensa Suisse: Mettez
du vent dans vos neurones,'' July 6, 2012&lt;/ref&gt;&lt;ref&gt;[http://www.mensa.ch/about Mensa Switzerland]&lt;/ref&gt; He took [[early retirement]] in 1967 and became a [[free-lance]] and also taught courses in [[translating]] and [[interpreting]] at the [[University of Geneva]].&lt;ref name=Bernstein/&gt;

Eberstark was prepared to interpret into English and German and from French, Dutch, Italian, Spanish and [[Catalan language|Catalan]]. He also knew how to speak [[Surinamese Creole]], [[Haitian Creole]] and [[Papiamento]], from the [[Netherlands Antilles]], as well as [[Yiddish]], several varieties of [[Swiss German]], [[Albanian language|Albanian]] and [[Hebrew]].&lt;ref name=Bernstein/&gt;

In the late 1960s he was married with two children. He once told a group of friends that he "knew" the date he would die.

He also is known for having once recited 11,944 successive digits of the mathematical quantity of [[pi]] from memory.&lt;ref&gt;[http://www.recordholders.org/en/list/memory.html RecordHolders.org]&lt;/ref&gt;  During an earlier attempt he had intended on reciting roughly half that many but had made a mistake.  He was angry with himself for the mistake so he memorized even more.

Eberstark once wrote that the "external rewards" of excelling in [[mental arithmetic]] were "Making friends, making money, showing off, and giving pleasure."&lt;ref&gt;Eberstark, "Introductory Comment" to Smith (1983), pages xiii–xiv, cited in Brian Butterworth, ''What Counts: How Every Brain Is Hardwired for Math'' (1999), pages 284–85&lt;/ref&gt;

==References==
{{reflist}}

==Further reading==
* [http://business.highbeam.com/436007/article-1G1-201547091/many-tongues-hans-eberstark-can-make-himself-understood] Jeremy Bernstein, "In Many Tongues: Hans Eberstark Can Make Himself Understood in Dozens of Languages, and Can Memorize Nearly Endless Strings of Words and Numbers. He Assumes That Everyone Else Can Too, With a Little Work," ''The Atlantic,'' October 1, 1993

{{authority control}}

{{DEFAULTSORT:Eberstark, Hans}}
[[Category:Mental calculators]]
[[Category:Austrian Jews]]
[[Category:Yiddish-speaking people]]
[[Category:Linguists from Austria]]
[[Category:Austrian translators]]
[[Category:Austrian expatriates in China]]
[[Category:1929 births]]
[[Category:2001 deaths]]
[[Category:20th-century translators]]</text>
      <sha1>4v54nzc27y0d4rqta3dlf0yk2e82oj1</sha1>
    </revision>
  </page>
  <page>
    <title>Hexacoordinate</title>
    <ns>0</ns>
    <id>8776613</id>
    <revision>
      <id>700744218</id>
      <parentid>700743992</parentid>
      <timestamp>2016-01-20T10:22:05Z</timestamp>
      <contributor>
        <username>Gareth Griffith-Jones</username>
        <id>13358461</id>
      </contributor>
      <comment>[[WP:REFERS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="650">'''Hexacoordinate''' in chemistry is a [[molecule]] with six [[ligand]]s or atomic attachments arranged around a single metal atom in the centre.  Most hexacoordinate species form an [[octahedral molecular geometry]], with four ligands arranged equatorially, and two axially.
 
There is research that suggests some [[planar hexacoordinate carbon|planar hexacoordinate structures of carbon]] may exist.

==External links==
*[http://www.sciencemag.org/cgi/content/abstract/290/5498/1937 Science article: Planar Hexacoordinate Carbon: A Viable Possibility]
{{MolecularGeometry}}
[[Category:Molecular geometry]]
[[Category:Stereochemistry]]
{{Chem-stub}}</text>
      <sha1>8pi9kdxdqpiupxeiuzwtox9a2tkc3hz</sha1>
    </revision>
  </page>
  <page>
    <title>Humbert polynomials</title>
    <ns>0</ns>
    <id>33013259</id>
    <revision>
      <id>746909596</id>
      <parentid>568005359</parentid>
      <timestamp>2016-10-30T08:32:38Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1057">In [[mathematics]], the '''Humbert polynomials''' π{{su|b=''n'',''m''|p=λ}}(''x'') are a generalization of [[Pincherle polynomials]] introduced by {{harvs|txt|last=Humbert|year=1921|authorlink=Pierre Humbert (mathematician)}} given by the [[generating function]]

:&lt;math&gt;\displaystyle (1-mxt+t^m)^{-\lambda}=\sum^\infty
_{n=0}\pi^\lambda_{n,m}(x)t^n&lt;/math&gt;

{{harvtxt|Boas|Buck|1958|loc=p.58}}.

==See also==

*[[Umbral calculus]]

==References==

*{{Citation | last1=Boas | first1=Ralph P. | last2=Buck | first2=R. Creighton | title=Polynomial expansions of analytic functions | url=https://books.google.com/books?id=eihMuwkh4DsC | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Ergebnisse der Mathematik und ihrer Grenzgebiete. Neue Folge.  | mr=0094466 | year=1958 | volume=19}}
*{{Citation | last1=Humbert | first1=Pierre | title=Some extensions of Pincherle's Polynomials | doi=10.1017/S0013091500035756 | year=1921 | journal=Proceedings of the Edinburgh mathematics society | volume=39 | pages=21–24}}

[[Category:Polynomials]]</text>
      <sha1>dwezn0hah56002yhg4i8go7ef70tq9c</sha1>
    </revision>
  </page>
  <page>
    <title>In silico clinical trials</title>
    <ns>0</ns>
    <id>46232572</id>
    <revision>
      <id>841420357</id>
      <parentid>778987508</parentid>
      <timestamp>2018-05-15T18:53:19Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13307">{{DISPLAYTITLE:''In silico'' clinical trials}}
An '''''in silico'' clinical trial''' is an individualised [[computer simulation]] used in the development or regulatory evaluation of a [[medicinal product]], [[medical device|device]], or intervention. While completely simulated [[clinical trial]]s are not feasible with current technology and understanding of biology, its development would be expected to have major benefits over current ''[[in vivo]]'' clinical trials, and research on it is being pursued.

== History ==
The term ''in silico'' indicates any use of computers in clinical trials, even if limited to management of clinical information in a database.&lt;ref&gt;This sense of the term was used in 2011 in a position paper from the VPH Institute commenting on the [[green paper]] written ahead of the launch of the [[European Commission]] [[Horizon 2020]] framework programme.

[http://www.vph-institute.org/upload/vphinst-position-on-fp8-greenpaper-v3_5192443874603.pdf VPH greenpaper]&lt;/ref&gt;

== Rationale ==
The traditional model for the development of medical treatments and devices begins with [[pre-clinical development]]. In laboratories, test-tube and other ''[[in vitro]]'' experiments establish the plausibility for the efficacy of the treatment.  Then ''[[in vivo]]'' [[animal models]], with different species, provide guidance on the efficacy and safety of the product for humans. With success in both ''in vitro'' and ''in vivo'' studies, scientist can propose that [[clinical trial]]s test whether the product be made available for humans. Clinical trials are often divided into four phases. Phase 3  involves testing a large number of people.&lt;ref name="Trial Watch"&gt;{{cite journal|last1=Arrowsmith|first1=John|last2=Miller|first2=Philip|title=Trial Watch: Phase II and Phase III attrition rates 2011–2012|journal=Nature Reviews Drug Discovery|date=1 August 2013|volume=12|issue=8|page=569|doi=10.1038/nrd4090|pmid=23903212}}&lt;/ref&gt; When a medication fails at this stage, the financial losses can be catastrophic.&lt;ref name="Model-Based Drug Development"&gt;{{cite journal|last1=Milligan|first1=P A|last2=Brown|first2=M J|last3=Marchant|first3=B|last4=Martin|first4=S W|last5=van der Graaf|first5=P H|last6=Benson|first6=N|last7=Nucci|first7=G|last8=Nichols|first8=D J|last9=Boyd|first9=R A|last10=Mandema|first10=J W|last11=Krishnaswami|first11=S|last12=Zwillich|first12=S|last13=Gruben|first13=D|last14=Anziano|first14=R J|last15=Stock|first15=T C|last16=Lalonde|first16=R L|title=Model-Based Drug Development: A Rational Approach to Efficiently Accelerate Drug Development|journal=Clinical Pharmacology &amp; Therapeutics|date=14 March 2013|volume=93|issue=6|pages=502–514|doi=10.1038/clpt.2013.54}}&lt;/ref&gt;
 
Predicting low-frequency side effects has been difficult, because such side effects need not become apparent until the treatment is adopted by many patients. The appearance of severe side-effects in phase three often causes development to stop, for ethical and economic reasons.&lt;ref name="Trial Watch" /&gt;&lt;ref name="Modeling and Similation as a tool. Harnisch"&gt;{{cite journal|last1=Harnisch|first1=L|last2=Shepard|first2=T|last3=Pons|first3=G|last4=Della Pasqua|first4=O|title=Modeling and Simulation as a Tool to Bridge Efficacy and Safety Data in Special Populations|journal=CPT: Pharmacometrics &amp; Systems Pharmacology|date=February 2013|volume=2|issue=2|pages=e28|doi=10.1038/psp.2013.6}}&lt;/ref&gt;&lt;ref name="canine cardiac midmyocardial model"&gt;{{cite journal|last1=Davies|first1=M. R.|last2=Mistry|first2=H. B.|last3=Hussein|first3=L.|last4=Pollard|first4=C. E.|last5=Valentin|first5=J.- P.|last6=Swinton|first6=J.|last7=Abi-Gerges|first7=N.|title=An in silico canine cardiac midmyocardial action potential duration model as a tool for early drug safety assessment|journal=AJP: Heart and Circulatory Physiology|date=23 December 2011|volume=302|issue=7|pages=H1466–H1480|doi=10.1152/ajpheart.00808.2011}}&lt;/ref&gt; Also, in recent years many candidate drugs failed in phase 3 trials because of lack of efficacy rather than for safety reasons.&lt;ref name="Trial Watch" /&gt;&lt;ref name="Model-Based Drug Development" /&gt; One reason for failure is that traditional trials aim to establish efficacy and safety for most subjects, rather than for individual subjects, and so efficacy is determined by a [[statistic]] of [[central tendency]] for the trial. Traditional trials do not adapt the treatment to the [[covariate]]s of subjects: 
* Taking account of factors such as the patient's particular physiology, the individual manifestation of the disease being treated, their lifestyle, and the presence of co-morbidities.&lt;ref name="Modeling and Similation as a tool. Harnisch" /&gt;&lt;ref name="A Vision and Strategy for VPH. Hunter et al."&gt;{{cite journal|last1=Hunter|first1=P.|last2=Chapman|first2=T.|last3=Coveney|first3=P. V.|last4=de Bono|first4=B.|last5=Diaz|first5=V.|last6=Fenner|first6=J.|last7=Frangi|first7=A. F.|last8=Harris|first8=P.|last9=Hose|first9=R.|last10=Kohl|first10=P.|last11=Lawford|first11=P.|last12=McCormack|first12=K.|last13=Mendes|first13=M.|last14=Omholt|first14=S.|last15=Quarteroni|first15=A.|last16=Shublaq|first16=N.|last17=Skar|first17=J.|last18=Stroetmann|first18=K.|last19=Tegner|first19=J.|last20=Thomas|first20=S. R.|last21=Tollis|first21=I.|last22=Tsamardinos|first22=I.|last23=van Beek|first23=J. H. G. M.|last24=Viceconti|first24=M.|title=A vision and strategy for the virtual physiological human: 2012 update|journal=Interface Focus|date=21 February 2013|volume=3|issue=2|pages=20130004–20130004|doi=10.1098/rsfs.2013.0004|pmc=3638492}}&lt;/ref&gt;
* [[Compliance (medicine)|Compliance]], or lack thereof, in taking the drug at the times and dose prescribed. In the case of a surgically implanted device, to account for the variability in surgeons’ experience and technique, as well as the particular anatomy of the patient.&lt;ref name="Pre-clinical validation of joint prostheses. Viceconti"&gt;{{cite journal|last1=Viceconti|first1=Marco|last2=Affatato|first2=Saverio|last3=Baleani|first3=Massimiliano|last4=Bordini|first4=Barbara|last5=Cristofolini|first5=Luca|last6=Taddei|first6=Fulvia|title=Pre-clinical validation of joint prostheses: a systematic approach.|journal=Journal of the mechanical behavior of biomedical materials 2|date=2009|pages=120–127}}&lt;/ref&gt; However, adjusting the evaluation of the study for noncompliance has proved difficult. Such adjustments often bias the results of the study, and so many health authorities mandate that clinical trials analyse the data according to the [[intention to treat]] principle.

== Aim ==
Accurate computer models of a treatment and its deployment, as well as patient characteristics, are necessary precursors for the development of ''in silico'' clinical trials.&lt;ref name="canine cardiac midmyocardial model" /&gt;&lt;ref name="A Vision and Strategy for VPH. Hunter et al." /&gt;&lt;ref name="Grand Challenge: Applying Regulatory Science and Big Data to Improve Medical Device Innovation. Erdman"&gt;{{cite journal|last1=Erdman|first1=A. G.|last2=Keefe|first2=D. F.|last3=Schiestl|first3=R.|title=Grand Challenge: Applying Regulatory Science and Big Data to Improve Medical Device Innovation|journal=IEEE Transactions on Biomedical Engineering|date=March 2013|volume=60|issue=3|pages=700–706|doi=10.1109/TBME.2013.2244600}}&lt;/ref&gt;&lt;ref name="In silico design of clinical trials.Clermont"&gt;{{cite journal|last1=Clermont|first1=Gilles|last2=Bartels|first2=John|last3=Kumar|first3=Rukmini|last4=Constantine|first4=Greg|last5=Vodovotz|first5=Yoram|last6=Chow|first6=Carson|title=In silico design of clinical trials: A method coming of age|journal=Critical Care Medicine|date=October 2004|volume=32|issue=10|pages=2061–2070|doi=10.1097/01.CCM.0000142394.28791.C3}}&lt;/ref&gt;  In such a scenario, ‘virtual’ patients would be given a ‘virtual’ treatment, enabling observation through a computer simulation of how the candidate biomedical product performs and whether it produces the intended effect, without inducing adverse effects.  Such ''in silico'' clinical trials could help to reduce, refine, and partially replace real clinical trials by:
* Reducing the size and the duration of clinical trials through better design,&lt;ref name="A Vision and Strategy for VPH. Hunter et al." /&gt;&lt;ref name="Grand Challenge: Applying Regulatory Science and Big Data to Improve Medical Device Innovation. Erdman" /&gt; for example, by identifying characteristics to determine which patients might be at greater risk of complications or providing earlier confirmation that the product is working as expected.&lt;ref name="canine cardiac midmyocardial model" /&gt;
* Refining clinical trials through clearer, more detailed information on potential outcomes and greater explanatory power in interpreting any adverse effects that might emerge, as well as better understanding of how the tested product interacts with the individual patient anatomy and predicting long-term or rare effects that clinical trials are unlikely to reveal.&lt;ref name="In silico design of clinical trials.Clermont" /&gt;
* Partially replacing clinical trials in those situations where it is not an absolute regulatory necessity, but only a legal requirement. There are already examples where regulators have accepted the replacement of animal models with ''in silico'' models under appropriate conditions.&lt;ref name="In silico preclinical trials: a proof of concept in closed-loop control of type 1 diabetes. Kovatchev"&gt;{{cite journal|last1=Kovatchev|first1=BP|last2=Breton|first2=M|last3=Man|first3=CD|last4=Cobelli|first4=C|title=In silico preclinical trials: a proof of concept in closed-loop control of type 1 diabetes.|journal=Journal of diabetes science and technology|date=January 2009|volume=3|issue=1|pages=44–55|pmid=19444330|doi=10.1177/193229680900300106|pmc=2681269}}&lt;/ref&gt; While real clinical trials will remain essential in most cases, there are specific situations where a reliable predictive model can conceivably replace a routine clinical assessment.
In addition, real clinical trials may indicate that a product is unsafe or ineffective, but rarely indicate why or suggest how it might be improved. As such, a product that fails during clinical trials may simply be abandoned, even if a small modification would solve the problem. This stifles innovation, decreasing the number of truly original biomedical products presented to the market every year, and at the same time increasing the cost of development.&lt;ref name="Avicenna Roadmap 2015 Viceconti"&gt;{{cite web|last1 = Viceconti|first1 = Marco|last2 = Morley-Fletcher|first2 = Edwin|last3 = Henney|first3 = Adriano|last4 = Contin|first4 = Martina|last5 = El-Arifi|first5 = Karen|last6 = McGregor|first6 = Callum|last7 = Karlstrom|first7 = Anders|last8 = Wilkinson|first8 = Emma|title = In Silico Clinical Trials: How Computer Simulation Will Transform The Biomedical Industry An international research and development roadmap for an industry-driven initiative|url = http://avicenna-isct.org/wp-content/uploads/2015/05/Avicenna_roadmap_v3.pdf|website = Avicenna-ISCT|publisher = Avicenna Project|accessdate = 1 June 2015|ref = AvicennaRoadmap}}&lt;/ref&gt;
Analysis through ''in silico'' clinical trials is expected to provide a better understanding of the mechanism that caused the product to fail in testing,&lt;ref name="Grand Challenge: Applying Regulatory Science and Big Data to Improve Medical Device Innovation. Erdman" /&gt;&lt;ref name="The Role of Modeling and Simulation in Development and Registration of Medicinal Products: Output From the EFPIA/EMA Modeling and Simulation Workshop. Manolis"&gt;{{cite journal|last1=Manolis|first1=E|last2=Rohou|first2=S|last3=Hemmings|first3=R|last4=Salmonson|first4=T|last5=Karlsson|first5=M|last6=Milligan|first6=P A|title=The Role of Modeling and Simulation in Development and Registration of Medicinal Products: Output From the EFPIA/EMA Modeling and Simulation Workshop|journal=CPT: Pharmacometrics &amp; Systems Pharmacology|date=February 2013|volume=2|issue=2|pages=e31|doi=10.1038/psp.2013.7}}&lt;/ref&gt; and may be able to provide information that could be used to refine the product to such a degree that it could successfully complete clinical trials.

''In silico'' clinical trials would also provide significant benefits over current pre-clinical practices. Unlike animal models, the virtual human models can be re-used indefinitely, providing significant cost savings.  Compared to trials in animals or a small sample of humans, ''in silico'' trials might more effectively predict the behaviour of the drug or device in large-scale trials, identifying side effects that were previously difficult or impossible to detect, helping to prevent unsuitable candidates from progressing to the costly phase 3 trials.&lt;ref name="Avicenna Roadmap 2015 Viceconti" /&gt;

== See also ==
* [[Virtual Physiological Human]]
* [[In silico medicine|''in silico'' medicine]]

==References==
{{CC-notice|cc=by4|url=http://avicenna-isct.org/wp-content/uploads/2015/05/Avicenna_roadmap_v3.pdf}}
{{reflist|30em}}

==External links==
* [http://www.taverna.org.uk/introduction/what-is-in-silico-experimentation/ Taverna site] ''What is in-silico experimentation?''

[[Category:Medical technology]]
[[Category:Computational science]]
[[Category:Anatomical simulation]]
[[Category:Clinical research]]</text>
      <sha1>6pbyuz77dub2kpej8xuljj1y9krgljl</sha1>
    </revision>
  </page>
  <page>
    <title>Industrial engineering</title>
    <ns>0</ns>
    <id>23535218</id>
    <revision>
      <id>870951986</id>
      <parentid>870950760</parentid>
      <timestamp>2018-11-28T00:34:51Z</timestamp>
      <contributor>
        <ip>122.54.199.40</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27346">{{Use mdy dates|date=August 2016}}
{{More footnotes|date=January 2017}}

'''Industrial engineering''' is an inter-disciplinary profession that is concerned with the optimization of complex [[process (engineering)|processes]], [[system]]s, or [[organizations]] by developing, improving and implementing integrated systems of people, money, knowledge, information, equipment, energy and materials&lt;ref name=":0"&gt;Salvendy, Gabriel. Handbook of Industrial Engineering. John Wiley &amp; Sons, Inc; 3rd edition p. 5&lt;/ref&gt;.     

Industrial engineers use specialized knowledge and skills in business administration, management, mathematics, physical sciences, social sciences and methods of engineering analysis and design to specify, predict, and evaluate the results obtained from systems or processes&lt;ref name=":0" /&gt;.  From these results, they are able to create new systems, processes or situations for the useful coordination of man, materials and machines and improve the quality and productivity of systems, physical or social&lt;ref&gt;{{Cite web|url=http://www.iienet2.org/details.aspx?id=716|title=What IEs Do|website=www.iienet2.org|accessdate=September 24, 2015}}&lt;/ref&gt;&lt;ref name=":1" /&gt;. Depending on the sub-specialties involved, industrial engineering may also overlap with, [[operations research]], [[systems engineering]], [[manufacturing engineering]], [[production engineering]], [[management science]], [[management engineering]], [[financial engineering]], [[ergonomics]] or [[human factors engineering]], [[safety engineering]], or others, depending on the viewpoint or motives of the user.   

Even though its underlying concepts overlap considerably with certain business-oriented disciplines, such as [[operations management]], Industrial engineering is a longstanding engineering discipline subject to (and eligible for) [[professional engineering]] licensure in most jurisdictions.   

== History ==
{{See also|List of industrial engineers}}
{{Unreferenced section|date=October 2014}}

=== Origins ===
==== Industrial Revolution ====
There is a general consensus among historians that the roots of the Industrial Engineering Profession date back to the [[Industrial Revolution]].  The technologies that helped mechanize traditional manual operations in the textile industry including the [[Flying shuttle]], the [[Spinning jenny]], and perhaps most importantly the [[Steam engine]] generated [[Economies of scale]] that made [[Mass production]] in centralized locations attractive for the first time.  The concept of the production system had its genesis in the factories created by these innovations.&lt;ref name=Maynard-Zandin&gt;Maynard &amp; Zandin. Maynard's Industrial Engineering Handbook. McGraw Hill Professional 5th Edition. June 5, 2001. p. 1.4-1.6&lt;/ref&gt;

==== Specialization of labor ====
[[File:Maquina vapor Watt ETSIIM.jpg|thumb|225px|Watt's steam engine ([[Technical University of Madrid]])]]
Adam Smith's concepts of [[Division of Labour]] and the "Invisible Hand" of capitalism introduced in his treatise "[[The Wealth of Nations]]" motivated many of the technological innovators of the Industrial revolution to establish and implement factory systems.  The efforts of James Watt and Matthew Boulton led to the first integrated machine manufacturing facility in the world, including the implementation of concepts such as cost control systems to reduce waste and increase productivity and the institution of skills training for craftsmen.&lt;ref name=Maynard-Zandin /&gt;

[[Charles Babbage]] became associated with Industrial engineering because of the concepts he introduced in his book "On the Economy of Machinery and Manufacturers" which he wrote as a result of his visits to factories in England and the United States in the early 1800s.  The book includes subjects such as the time required to perform a specific task, the effects of subdividing tasks into smaller and less detailed elements, and the advantages to be gained from repetitive tasks.&lt;ref name=Maynard-Zandin /&gt;

==== Interchangeable parts ====
[[Eli Whitney]] and [[Simeon North]] proved the feasibility of the notion of [[Interchangeable parts]] in the manufacture of muskets and pistols for the US Government.  Under this system, individual parts were mass-produced to tolerances to enable their use in any finished product.  The result was a significant reduction in the need for skill from specialized workers, which eventually led to the industrial environment to be studied later.&lt;ref name=Maynard-Zandin /&gt;

=== Pioneers ===
[[Frederick Winslow Taylor|Frederick Taylor]] (1856 – 1915) is generally credited as being the father of the Industrial Engineering discipline.  He earned a degree in mechanical engineering from Steven's University and earned several patents from his inventions.  His books, ''Shop Management'' and ''[[The Principles of Scientific Management]]'' which were published in the early 1900s, were the beginning of Industrial Engineering.&lt;ref&gt;[http://ingenieroindustrialpro.com/ All about industrial engineering]&lt;/ref&gt;  Improvements in work efficiency under his methods was based on improving work methods, developing of work standards, and reduction in time required to carry out the work.  With an abiding faith in the scientific method, Taylor's contribution to "Time Study" sought a high level of precision and predictability for manual tasks.&lt;ref name=Maynard-Zandin /&gt;

The husband-and-wife team of [[Frank Bunker Gilbreth Sr.|Frank Gilbreth]] (1868 – 1924) and [[Lillian Moller Gilbreth|Lillian Gilbreth]] (1878 – 1972) was the other cornerstone of the Industrial Engineering movement whose work is housed at Purdue University School of Industrial Engineering.  They categorized the elements of human motion into 18 basic elements called ''therbligs''.  This development permitted analysts to design jobs without knowledge of the time required to do a job. These developments were the beginning of a much broader field known as human factors or ergonomics.&lt;ref name=Maynard-Zandin /&gt;

in 1908, the first course on Industrial Engineering was offered as an elective at [[Pennsylvania State University]], which became a separate program in 1909 through the efforts of [[Hugo Diemer]].&lt;ref&gt;{{Cite web|url=http://industryengineering08.blogspot.com/2012/04/industrial-engineering-definition.html|title=Industrial Engineering - Definition, Explanation, History, and Programs|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; The first doctoral degree in industrial engineering was awarded in 1933 by [[Cornell University]].

In 1912 [[Henry Laurence Gantt]] developed the [[Gantt chart]] which outlines actions the organization along with their relationships. This chart opens later form familiar to us today by [[Henry Wallace Clark|Wallace Clark]].

Assembly lines: moving car factory of [[Henry Ford]] (1913) accounted for a significant leap forward in the field. Ford reduced the assembly time of a car more than 700 hours to 1.5 hours. In addition, he was a pioneer of the economy of the capitalist welfare ("welfare capitalism") and the flag of providing financial incentives for employees to increase productivity.

Comprehensive quality management system ([[Total quality management]] or TQM) developed in the forties was gaining momentum after World War II and was part of the recovery of Japan after the war.

The [[Institute of Industrial and Systems Engineers|American Institute of Industrial Engineering]] was formed in 1948. The early work by F. W. Taylor and the Gilbreths was documented in papers presented to the [[American Society of Mechanical Engineers]] as interest grew from merely improving machine performance to the performance of the overall manufacturing process; most notably starting with the presentation by [[Henry R. Towne]] (1844 - 1924) of his paper ''The Engineer as An Economist'' (1186).&lt;ref&gt;[https://archive.org/stream/transactionsof07amer#page/428/mode/2up Engineer as Economist]&lt;/ref&gt;

=== Modern practice ===
In 1960 to 1975, with the development of decision support systems in supply such as the [[Material requirements planning]] (MRP), you can emphasize the timing issue (inventory, production, compounding, transportation, etc.) of industrial organization. Israeli scientist Dr. [[Jacob Rubinovitz]] installed the CMMS program developed in IAI and Control-Data (Israel) in 1976 in South Africa and worldwide.

In the seventies, with the penetration of Japanese management theories such as [[Kaizen]] and [[Kanban]], Japan realized very high levels of quality and productivity.  These theories improved issues of quality, delivery time, and flexibility.   Companies in the west realized the great impact of Kaizen and started implementing their own [[Continuous improvement]] programs.

In the nineties, following the global industry globalization process, the emphasis was on supply chain management and customer-oriented business process design. [[Theory of constraints]] developed by an Israeli scientist [[Eliyahu M. Goldratt]] (1985) is also a significant milestone in the field.

=== Compared to other engineering disciplines ===
Engineering is traditionally decompositional. To understand the whole, it is first broken into its parts. One then masters the parts and puts them back together, becoming the master of the whole.
Industrial and systems engineering's (ISE) approach is the opposite; any one part cannot be understood without the context of the whole. Changes in one part affect the whole, and the role of a part is a projection into the whole. In traditional engineering, people understand the parts first, then they can understand the whole. In ISE, they understand the whole first, and then they can understand the role of each part.

Also, Industrial engineering considers the human factor and its relation to the technical aspect of the situation and the all of the other factors that influence the entire situation&lt;ref name=":1"&gt;{{Cite journal|last=Lehrer|first=Robert|date=|title=The Nature of Industrial Engineering|url=|journal=The Journal of Industrial Engineering|volume=5|pages=4|via=JSTOR}}&lt;/ref&gt;, while other engineering disciplines focuses on the design of inanimate objects 

"Industrial Engineers integrate combinations of people, information, materials, and equipment that produce innovative and efficient organizations. In addition to manufacturing, Industrial Engineers work and consult in every industry, including hospitals, communications, e-commerce, entertainment, government, finance, food, pharmaceuticals, semiconductors, sports, insurance, sales, accounting, banking, travel, and transportation."&lt;ref name=":2"&gt;{{Cite web|url=http://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1063&amp;context=imsefacpub|title=DETAILS AND DESCRIPTION OF INDUSTRIAL ENGINEERING|last=Savory|first=Paul|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;  

" Industrial Engineering is the branch of Engineering most closely related to human resources in that we apply social skills to work with all types of employees, from engineers to salespeople to top management. One of the main focuses of an Industrial Engineer is to improve the working environments of people – not to change the worker, but to change the workplace."&lt;ref name=":2" /&gt;

"All engineers, including Industrial Engineers, take mathematics through calculus and differential equations. Industrial Engineering is different in that it is based on discrete variable math, whereas all other engineering is based on continuous variable math. We emphasize the use of linear algebra and difference equations, as opposed to the use of differential equations which are so prevalent in other engineering disciplines. This emphasis becomes evident in optimization of production systems in which we are sequencing orders, scheduling batches, determining the number of materials handling units, arranging factory layouts, finding sequences of motions, etc. As, Industrial Engineers, we deal almost exclusively with systems of discrete components."&lt;ref name=":2" /&gt;
== Etymology ==
{{Unreferenced section|date=October 2014}}

===Etymology===
While originally applied to [[manufacturing]], the use of "industrial" in "industrial engineering" can be somewhat misleading, since it has grown to encompass any methodical or quantitative approach to optimizing how a process, system, or organization operates. In fact, the "Industrial" in Industrial engineering means the "industry" in its broadest sense.&lt;ref&gt;{{Cite journal|last=Darwish|first=H|last2=van Dyk|first2=L|date=2016|title=The industrial engineering identity: from historic skills to modern values, duties, and roles|url=http://www.scielo.org.za/scielo.php?script=sci_arttext&amp;pid=S2224-78902016000300006|journal=South African Journal of Industrial Engineering|volume=27|issue=3|pages=50-63|via=}}&lt;/ref&gt; People have changed the term "industrial" to broader terms such as Industrial and Manufacturing Engineering, Industrial and Systems Engineering, Industrial Engineering &amp; Operations Research, Industrial Engineering &amp; Management. 
== Sub-disciplines ==
Industrial engineering has many sub-disciplines, the most common of which are listed below. Although there are industrial engineers who focus exclusively on one of these sub-disciplines, many deal with a combination of them such as Supply Chain and Logistics, and Facilities and Energy Management.&lt;ref&gt;{{Cite web|url=https://wonderfulengineering.com/what-is-industrial-engineering/|title=What is Industrial Engineering?|last=|first=|date=|website=Wonderful Engineering|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.sebokwiki.org/wiki/Systems_Engineering_and_Industrial_Engineering|title=Industrial Engineering|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;

'''&lt;big&gt;Facilities Engineering &amp; Energy Management&lt;/big&gt;'''

'''&lt;big&gt;Financial Engineering&lt;/big&gt;'''

&lt;big&gt;'''Human Factors &amp;''' '''Safety Engineering'''&lt;/big&gt;

'''&lt;big&gt;Information Systems Engineering &amp; Management&lt;/big&gt;'''

'''&lt;big&gt;Manufacturing Engineering&lt;/big&gt;'''

'''&lt;big&gt;Operations Engineering &amp; Management&lt;/big&gt;'''{{Main article|Operations engineering|Operations management}}'''&lt;big&gt;Operations Research &amp; Optimization&lt;/big&gt;'''

'''&lt;big&gt;Policy Planning&lt;/big&gt;'''

'''&lt;big&gt;Production Engineering&lt;/big&gt;'''

&lt;big&gt;'''Quality &amp; Reliability Engineering'''&lt;/big&gt;

&lt;big&gt;'''Supply Chain Management &amp; Logistics'''&lt;/big&gt;{{Main article|Supply-chain management|Logistics}}'''&lt;big&gt;System Analysis&lt;/big&gt;'''

'''&lt;big&gt;Systems Engineering&lt;/big&gt;'''

'''&lt;big&gt;Systems Simulation&lt;/big&gt;'''

'''&lt;big&gt;Related Disciplines&lt;/big&gt;'''

'''Organization Development &amp; Change Management'''

'''Behavioral Economics'''

{{Main article|Behavioral economics}}
== Education ==
Industrial engineers study the interaction of human beings with machines, materials, information, procedures and environments in such developments and in designing a technological system&lt;ref&gt;{{Cite journal|last=Rahman|first=Chowdury|last2=Uddin|first2=Syed|last3=Iqbal|first3=Mohammad|date=|title=Importance of Human Factors in Industrial Engineering and Design|url=https://www.researchgate.net/publication/298464170_Importance_of_Human_Factors_in_Industrial_Engineering_and_Design|journal=SEU Journal of Science and Engineering|volume=8|pages=|via=Research Gate}}&lt;/ref&gt;.

Universities offer degrees at the bachelor, masters, and doctoral level.

=== Undergraduate curriculum ===
{| class="toccolours" style="float:right; margin-left:1em; font-size:90%; line-height:1.4em; width:300px;"
! colspan="2" style="text-align: center;" | '''2018 U.S. News Undergraduate Rankings'''&lt;ref&gt;{{cite web | url=http://colleges.usnews.rankingsandreviews.com/best-colleges/rankings/engineering-doctorate-industrial-manufacturing| title=Best Undergraduate Industrial / Manufacturing Engineering Program Rankings | publisher=U.S. News | accessdate=March 2, 2017}}&lt;/ref&gt;
|-
| '''University''' || '''Rank'''
|-
| colspan="2" |&lt;hr /&gt;
|-
| [[Georgia Institute of Technology]] || 1
|-
| [[University of Michigan]] || 2
|-
| [[University of California, Berkeley]] || 3
|-
| [[Purdue University]] || 4
|-
| [[Stanford University]] || 5
|-
| [[University of Wisconsin-Madison]] || 5
|-
| [[Pennsylvania State University]] || 7
|-
| [[Virginia Tech]] || 8
|-
| [[Massachusetts Institute of Technology]] || 9
|-
| [[Cornell University]]|| 10
|-
| [[Northwestern University]]|| 10

|}
In the United States, the undergraduate degree earned is the Bachelor of Science (B.S.) or Bachelor of Science and Engineering (B.S.E.) in Industrial Engineering (IE).  Variations of the title include Industrial &amp; Operations Engineering (IOE), and Industrial &amp; Systems Engineering (ISE).  The typical curriculum includes a broad math and science foundation spanning [[chemistry]], [[physics]], [[mechanics]] (i.e., statics, kinematics, and dynamics), [[materials science]], [[computer science]], electronics/circuits, [[engineering design]], and the standard range of engineering mathematics (i.e. [[calculus]], [[linear algebra]], [[differential equations]], [[statistics]]). For any engineering undergraduate program to be accredited, regardless of concentration, it must cover a largely similar span of such foundational work - which also overlaps heavily with the content tested on one or more engineering licensure exams in most jurisdictions.

The coursework specific to IE entails specialized courses in areas such as [[optimization]], [[applied probability]], [[stochastic]] modeling, [[design of experiments]], [[statistical process control]], [[Computer simulation|simulation]], [[manufacturing engineering]], [[ergonomics]]/[[safety engineering]], and [[engineering economics]]. Industrial engineering elective courses typically cover more specialized topics in areas such as [[manufacturing]], [[supply chains]] and [[logistics]], [[analytics]] and [[machine learning]], [[Operations management#Production systems|production systems]], [[human factors]] and [[industrial design]], and [[service system]]s.&lt;ref&gt;{{cite web|url=https://www.isye.gatech.edu/academics/bachelors/industrial-engineering/courses | title=ISyE Undergraduate Courses | publisher=Georgia Institute of Technology | accessdate=2 March 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://guide.berkeley.edu/courses/ind_eng/ | title=Industrial Engineering and Operations Research (IND ENG) | publisher=University of California, Berkeley | accessdate=2 March 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.engin.umich.edu/college/academics/bulletin/depts/ioe/courses | title=Courses | publisher=University of Michigan, Ann Arbor | accessdate=2 March 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.mccormick.northwestern.edu/industrial/courses/ | title=Courses | publisher=Northwestern University | accessdate=2 March 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://ise.illinois.edu/undergraduate/electives.html | title=ISE Electives | publisher=University of Illinois at Urbana-Champaign | accessdate=2 March 2017}}&lt;/ref&gt;

Certain business schools may offer programs with some overlapping relevance to IE, but the engineering programs are distinguished by a much more intensely quantitative focus, required engineering science electives, and the core math and science courses required of all engineering programs.

=== Graduate curriculum ===
{| class="toccolours" style="float:right; margin-left:1em; font-size:90%; line-height:1.4em; width:300px;"
! colspan="2" style="text-align: center;" | '''2019 U.S. News Graduate Rankings'''&lt;ref&gt;{{cite web | url=https://www.usnews.com/best-graduate-schools/top-engineering-schools/industrial-engineering-rankings?int=9d0e08&amp;int=a06908 | title=Best Industrial Engineering Programs | publisher=U.S. News | accessdate=March 2, 2017}}&lt;/ref&gt;
|-
| '''University''' || '''Rank'''
|-
| colspan="2" |&lt;hr /&gt;
|-
| [[Georgia Institute of Technology]] || 1
|-
| [[University of Michigan]] || 2
|-
| [[University of California, Berkeley]] || 3
|-
| [[Northwestern University]] || 4
|-
| [[Cornell University]]|| 5
|-
| [[Purdue University]] || 6
|-
| [[Massachusetts Institute of Technology]] || 7
|-
| [[Pennsylvania State University]] || 7
|-
| [[University of Wisconsin-Madison]] || 7
|-
| [[Virginia Tech]] || 7

|}
The usual graduate degree earned is the Master of Science (MS) or Master of Science and Engineering (MSE) in Industrial Engineering or various alternative related concentration titles.

Typical MS curricula may cover:

{{colbegin|colwidth=27em}}
* [[Analytics]] and [[machine learning]]
* [[Computer-aided manufacturing]]
* [[Engineering economics]]
* [[Financial engineering]]
* [[Human factors and ergonomics|Human factors engineering and ergonomics]] ([[safety engineering]])
* [[Lean Six Sigma]]
* [[Management science]]s
* [[Materials management]]
* [[Operations management]]
* [[Operations research]] and [[process optimization|optimization]] techniques
* [[Predetermined motion time system]] and computer use for IE 
* [[Product Development]]
* [[Production planning and control]]
* [[Productivity]] improvement
* [[Project management]]
* [[Reliability engineering]] and life testing
* [[Robotics]]
* [[Statistical process control]] or [[quality control]]
* [[Supply chain management]] and [[logistics]]
* [[System dynamics]] and policy planning
* [[Systems simulation]] and [[stochastic]] processes
* [[Time and motion study]]
* Facilities design and work-space design
* Manufacturing systems/[[manufacturing engineering]]
* Quality engineering
* System analysis and techniques
{{colend}}

=== Differences in Teaching ===
While Industrial Engineering as a formal degree has been around for years, consensus on what topics should be taught and studied differs across countries. For example, Turkey focuses on a very technical degree while Denmark, Finland and the United Kingdom have a management focus degree, thus making it less technical.  The United States focuses on case-studies and group problem solving&lt;ref&gt;{{Cite web|url=https://www.bachelorsportal.com/articles/636/what-is-industrial-engineering-and-why-should-i-study-it.html|title=What is Industrial Engineering and Why Should I Study It?|last=Oanca|first=Alexandra|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;.

== Practicing Engineers ==
Traditionally, a major aspect of industrial engineering was [[Plant layout study|planning the layouts of factories]] and designing assembly lines and other manufacturing paradigms. And now, in [[lean manufacturing]] systems, industrial engineers work to eliminate wastes of time, money, materials, energy, and other resources.

Examples of where industrial engineering might be used include flow process charting, process mapping, designing an assembly workstation, strategizing for various operational logistics, consulting as an efficiency expert, developing a new financial algorithm or loan system for a bank, streamlining operation and emergency room location or usage in a hospital, planning complex distribution schemes for materials or products (referred to as [[supply-chain management]]), and shortening lines (or [[queueing theory|queues]]) at a bank, hospital, or a theme park.

Modern industrial engineers typically use [[predetermined motion time system]], [[computer simulation]] (especially [[discrete event simulation]]), along with extensive mathematical tools for modeling, such as [[mathematical optimization]] and [[queueing theory]], and computational methods for system analysis, evaluation, and optimization. Industrial engineers also use the tools of [[data science]] and [[machine learning]] in their work owing to the strong relatedness of these disciplines with the field and the similar technical background required of industrial engineers (including a strong foundation in [[probability theory]], [[linear algebra]], and [[statistics]], as well as having [[computer programming|coding]] skills).

==See also==
=== Related topics ===
{{colbegin|colwidth=25em}}
* [[Overall equipment effectiveness]]
* [[Product design]] / [[industrial design]]
*[[Engineering economics]] 
*[[Engineering management]]
*[[Enterprise engineering]]
*[[Environment, health and safety]]
*[[Human factors engineering]]
*[[Industrial and Production Engineering]]
*[[Industrial and Systems Engineering]]
*[[Industrial Engineering &amp; Management]]
*[[List of production topics]]
*[[Maintenance engineering]]
*[[Manufacturing engineering]]  
*[[Occupational safety and health]]  
*[[Operations engineering]]
*[[Operations research]]
*[[Production engineering]]
*[[Project management]]
*[[Project Production Management]] 
*[[Quality engineering]]
*[[Reverse engineering]]
*[[Safety engineering]]
*[[Sales process engineering]]
*[[Sociotechnical systems]]
*[[Statistical process control]]
*[[Systems engineering]]
*[[Toyota production system]]
*[[Industrial Engineering Book of Knowledge]]{{colend}}

=== Associations ===
{{colbegin|colwidth=25em}}
*[http://www.iise.org// Institute of Industrial and Systems Engineers]
*[[INFORMS]]
*[[Institute of Industrial and Systems Engineers]]
*[[American Society for Engineering Education]]
*[[American Society for Quality]]
*[http://asor.org.au// The Australian Society for Operations Research]
*[http://www.ukmtm.co.uk/ The UK MTM Association]
*[[ESTIEM|European Students of Industrial Engineering and Management]]
*[http://ifors.org/web/ The International Federation of Operational Research Societies (IFORS)]
*[[Indian Institution of Industrial Engineering]]
*[http://www.iiie.ir/ Iranian Institute of Industrial Engineering]
*[[Washington Accord]]
*[http://www.orsj.or.jp/english/ The Operations Research Society of Japan]
{{colend}}

==Notes==
{{reflist}}

==Further reading==
* Badiru, A. (Ed.) (2005).  ''Handbook of industrial and systems engineering''. CRC Press. {{ISBN|0-8493-2719-9}}.
*[[Benjamin S. Blanchard|B. S. Blanchard]] and [[Fabrycky, W.]] (2005).  ''Systems Engineering and Analysis'' (4th Edition).  Prentice-Hall. {{ISBN|0-13-186977-9}}.
* Salvendy, G. (Ed.) (2001).  ''Handbook of industrial engineering: Technology and operations management''. Wiley-Interscience. {{ISBN|0-471-33057-4}}.
* Turner, W. et al. (1992). ''Introduction to industrial and systems engineering'' (Third edition). Prentice Hall.  {{ISBN|0-13-481789-3}}.
*[[Eliyahu M. Goldratt]], Jeff Cox (1984). ''The Goal''  North River Press; 2nd Rev edition (1992). {{ISBN|0-88427-061-0}}; 20th Anniversary edition (2004) {{ISBN|0-88427-178-1}}
* Miller, Doug, Towards Sustainable Labour Costing in UK Fashion Retail (February 5, 2013). {{DOI|10.2139/ssrn.2212100}}
* Malakooti, B. (2013). Operations and Production Systems with Multiple Objectives. John Wiley &amp; Sons.{{ISBN|978-1-118-58537-5}}
&lt;!--spacing--&gt;
*[http://sebokwiki.org/wiki/Guide_to_the_Systems_Engineering_Body_of_Knowledge_%28SEBoK%29/ Systems Engineering Body of Knowledge (SEBoK)]
*[http://infolab.stanford.edu/~burback/dcg/node5.html/ Traditional Engineering]
*[http://www.ise.vt.edu/academics/extended/mea/ Master of Engineering Administration (MEA)]

==External links==
*{{Commonscat-inline}}

{{IE 7 Tools}}
{{Engineering fields}}
{{Occupational safety and health}}

{{Authority control}}

{{DEFAULTSORT:Industrial Engineering}}
[[Category:Industrial engineering| ]]
[[Category:Engineering disciplines]]
[[Category:Manufacturing]]
[[Category:Operations research]]</text>
      <sha1>qvrey3p8yt736iw0zp80a4bqkxn6mrq</sha1>
    </revision>
  </page>
  <page>
    <title>Intensional type theory</title>
    <ns>0</ns>
    <id>33974084</id>
    <redirect title="Intuitionistic type theory" />
    <revision>
      <id>464393442</id>
      <timestamp>2011-12-06T14:35:12Z</timestamp>
      <contributor>
        <username>Ruud Koot</username>
        <id>170083</id>
      </contributor>
      <comment>[[WP:AES|←]]Redirected page to [[Intuitionistic type theory#Extensional versus intensional]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="122">#REDIRECT [[Intuitionistic type theory#Extensional versus intensional]] {{R with possibilities}}

[[Category:Type theory]]</text>
      <sha1>slbiahvtjksqga0b66aj5m3uca7vkfz</sha1>
    </revision>
  </page>
  <page>
    <title>Jeff Cheeger</title>
    <ns>0</ns>
    <id>7343761</id>
    <revision>
      <id>868266324</id>
      <parentid>868266106</parentid>
      <timestamp>2018-11-11T03:28:40Z</timestamp>
      <contributor>
        <ip>2604:2000:1200:5BA:B139:78DB:D9CC:43CE</ip>
      </contributor>
      <comment>/* Honors and awards */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9404">{{Infobox scientist
| name = Jeff Cheeger
| image = Cheeger Lawson.jpg
| caption = Jeff Cheeger (left) with [[H. Blaine Lawson]] (right) in 2007
| birth_date = {{birth date and age|1943|12|1|df=y}}
| birth_place = [[Brooklyn]], U.S.
| death_date =
| death_place =
| residence = [[United States]]
| nationality = [[Americans|American]]
| field = [[Mathematician]]
| work_institution = [[New York University]]&lt;br /&gt;[[Stony Brook University]]&lt;br /&gt;[[University of Michigan]]
| alma_mater = [[Harvard University|Harvard]]&lt;br /&gt;[[Princeton University|Princeton]]
| doctoral_advisor = [[Salomon Bochner]]&lt;br&gt;[[James Harris Simons]]
| doctoral_students =   [[Xian-Zhe Dai]]&lt;br /&gt;[[Xiaochun Rong]]&lt;br /&gt;[[Christina Sormani]]&lt;br /&gt;[[DaGang Yang]]&lt;br /&gt;[[Shun-Hui Zhu]] 
| known_for  = [[Riemannian geometry]]&lt;br /&gt;[[Metric Geometry]]
| prizes = [[Guggenheim Fellowship]] (1984)&lt;br /&gt;[[United States National Academy of Sciences|NAS]] member (1997)&lt;br /&gt;[[Veblen Prize]] (2001)&lt;br /&gt;[[Steele Prize for Lifetime Achievement]] (2019)
| religion =
| footnotes =
}}

'''Jeff Cheeger''' (born December 1, 1943, [[Brooklyn]], [[New York City]]), is a [[mathematician]]. Cheeger is [[professor]] at the [[Courant Institute|Courant Institute of Mathematical Sciences]] at [[New York University]] in [[New York City]].  His main interests are [[differential geometry]] and its connections with [[topology]] and [[Mathematical analysis|analysis]].

==Biography==
He graduated from [[Harvard University]] with a [[Bachelor of Arts|B.A.]] in 1964. He graduated from [[Princeton University]] with an [[Master of Science|M.S.]] in 1966 and with a [[Ph.D.]] in 1967.  He is a Silver Professor at the [[Courant Institute]] at [[NYU]] where he has worked since 1993.

He worked as a teaching assistant and research assistant at Princeton from 1966–1967, an N.S.F. Postdoctoral Fellow and Instructor from 1967–1968, an assistant professor from 1968 to 1969 at the [[University of Michigan]], and an associate professor from 1969-1971 at [[Stony Brook University|SUNY at Stony Brook]]. Cheeger was a professor at SUNY, Stony Brook from 1971 to 1985,  a leading professor from 1985 to 1990, and a distinguished professor from 1990 until 1992.

Cheeger has also had a number of visiting positions in [[Brazil]] (1971), at the [[Institute for Advanced Study]] (1972, 1977, 1978, 1995), Harvard University (1972), the [[Institut des Hautes Études Scientifiques]] (1984–1985) and the [[Mathematical Sciences Research Institute]] (1985).

He has supervised at least 13 doctoral theses and three postdocs. He has served as a member of several AMS committees and NSF panels.

Cheeger delivered Invited Addresses at the [[International Congress of Mathematicians]] in 1974 and in 1986.

He received the [[Guggenheim Fellowship]] in 1984.&lt;ref&gt;[http://www.gf.org/84fellow.html 1984 U.S. and Canadian Fellows.] {{webarchive|url=https://web.archive.org/web/20070731094137/http://www.gf.org/84fellow.html |date=2007-07-31 }} [[John Simon Guggenheim Memorial Foundation]]. Accessed August 11, 2008&lt;/ref&gt; In 1998 Cheeger was elected a foreign member of the [[Finnish Academy of Science and Letters]].&lt;ref&gt;[http://www.acadsci.fi/jasenet/ulkomaiset_jasenet.htm Foreign Members.] {{webarchive|url=https://web.archive.org/web/20141009063143/http://www.acadsci.fi/jasenet/ulkomaiset_jasenet.htm |date=2014-10-09 }} [[Finnish Academy of Science and Letters]]. Accessed August 11, 2008.&lt;/ref&gt;

Cheeger was elected a member of the [[United States National Academy of Sciences]] in 1997.&lt;ref&gt;[http://www.nasonline.org/site/Dir/1396514003?pg=vprof&amp;mbr=1002138&amp;returl=http%3A%2F%2Fwww.nasonline.org%2Fsite%2FDir%2F1396514003%3Fpg%3Dsrch%26view%3Dbasic&amp;retmk=search_again_link NAS Membership Directory.] [[United States National Academy of Sciences]]. Accessed August 11, 2008. Election citation:

&lt;blockquote&gt;Cheeger has discovered many of the deepest results in Riemannian geometry, such as estimates for the spectrum of the Laplace-Beltrami operator, and the identity of the analytic and geometric definitions of torsion, and has led to the solution of problems in topology, graph theory, number theory, and Markov processes.&lt;/ref&gt;&lt;/blockquote&gt;

He received the Fourteenth [[Oswald Veblen Prize in Geometry]] from the [[American Mathematical Society]] in 2001.&lt;ref&gt;{{cite journal|title=2001 Veblen Prize|journal=Notices of the American Mathematical Society|date=April 2001|volume=48|issue=4|page=408|url=http://ams.org/notices/200104/comm-veblen.pdf|accessdate=10 April 2018}}&lt;/ref&gt;

==Honors and awards==
*[[Steele Prize for Lifetime Achievement]], 2019
*Fellow of the [[American Mathematical Society]], 2012&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-10.&lt;/ref&gt;
*[[Oswald Veblen Prize in Geometry]], 2001
*[[United States National Academy of Sciences]], elected 1997
*Max Planck Research Award, Alexander von Humboldt Society, 1992–1994
*[[Guggenheim fellowship]], 1984–1985
*Invited Address, Annual Meeting of AMS, 1978
*[[International Congress of Mathematicians]], 1974 and 1986
*[[Sloan Fellowship]], 1971–1973
*[[National Science Foundation]] Postdoctoral Fellow, 1967-1968

&lt;ref&gt;&lt;http://as.nyu.edu/object/JeffCheeger.html&gt;&lt;/ref&gt;

==Selected publications==

* Cheeger, Jeff; Kleiner, Bruce.  On the differentiability of Lipschitz maps from metric measure spaces to Banach spaces.  Inspired by S. S. Chern,  129–152, Nankai Tracts kn Mathematics. 11, World Science Publications, Hackensack, N.J., 2006.
* Differentiability of Lipschitz functions on metric measure spaces.  Geometric and Functional Analysis. 9  (1999), no. 3, 428–517.
* Lower bounds on Ricci curvature and the almost rigidity of warped products, with T. H. Colding. Annals of Mathematics. 144. 1996. 189–237.
* On the cone structure at infinity of Ricci flat manifolds with Euclidean volume growth and quadratic curvature decay, with Gang Tian. Inventiones Mathematicae. 118. 1994. 493–571.
* Collapsing Riemannian manifolds while keeping their curvature bounded, II, with [[Mikhail Leonidovich Gromov|Mikhail Gromov]]. Journal of Differential Geometry. 31, 4. 1990. 269–298. [[Collapsing manifold]]
* Eta-invariants and their adiabatic limits, with J. M. Bismut. Journal of American Mathematical Society, 2, 1. 1989. 33–70.
*Cheeger, Jeff; Gromov, Mikhail; Taylor, Michael Finite propagation speed, kernel estimates for functions of the Laplace operator, and the geometry of complete Riemannian manifolds.  Journal of Differential Geometry.  17  (1982), no. 1, 15–53.
* On the Hodge theory of Riemannian pseudomanifolds. American Mathematical Society: Proceedings of the Symposium in Pure Mathematics. 36. 1980. 91–146. [[L² cohomology]]
*{{citation|mr=0451312
|journal=PNAS | year= 1977 | issue= 7 | pages=2651–2654
|title=Analytic Torsion and Reidemeister Torsion
|first=Jeff |last=Cheeger
|url=http://www.pnas.org/cgi/content/abstract/74/7/2651|doi=10.1073/pnas.74.7.2651|volume=74 | pmid=16592411 | pmc=431228}} [[Analytic torsion]]

* Cheeger, Jeff; Gromoll, Detlef. The splitting theorem for manifolds of nonnegative Ricci curvature.  Journal of Differential Geometry. 6 (1971/72), 119–128. [[Splitting theorem]]
* A lower bound for the smallest eigenvalue of the Laplacian.  Problems in analysis (Papers dedicated to Salomon Bochner, 1969),  pp.&amp;nbsp;195–199. Princeton University Press, Princeton, N.J., 1970. [[Cheeger constant]]
* Cheeger, Jeff; Gromoll, Detlef. The structure of complete manifolds of nonnegative curvature.  Bulletin of the American Mathematical Society. 74  1968 1147–1150.  [[Soul theorem]]
* Cheeger, Jeff. Finiteness theorems for Riemannian manifolds.  American Journal of Mathematics.  92  (1970) 61–74.
* Cheeger, Jeff; Ebin, David G.  Comparison theorems in Riemannian geometry.  Revised reprint of the 1975&lt;ref&gt;{{cite journal|author=Hermann, Robert|authorlink=Robert Hermann (mathematician)|title=Review: ''Comparison theorems in Riemannian geometry''|journal=Bull. Amer. Math. Soc.|year=1976|volume=82|issue=6|pages=834–836|url=http://www.ams.org/journals/bull/1976-82-06/S0002-9904-1976-14175-4/|doi=10.1090/s0002-9904-1976-14175-4}}&lt;/ref&gt; original. AMS Chelsea Publishing, Providence, RI, 2008.

&lt;ref&gt;[http://www.ams.org/mathscinet mathscinet]&lt;/ref&gt;

==See also==
* [[Cheeger bound]]
* [[Cheeger constant]]
* [[soul theorem]]
* [[splitting theorem]]
* [[Collapsing manifold]]

==References==
{{reflist}}

==External links==
*[http://silverdialogues.fas.nyu.edu/docs/CP/295/cheeger.pdf#search=%22jeff%20cheeger%22 CV]
* {{MathGenealogy|id=7603}}

{{Veblen Prize recipients}}

{{Authority control}}

{{DEFAULTSORT:Cheeger, Jeff}}
[[Category:Harvard University alumni]]
[[Category:Princeton University alumni]]
[[Category:1943 births]]
[[Category:Living people]]
[[Category:University of Michigan faculty]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Differential geometers]]
[[Category:ISI highly cited researchers]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Guggenheim Fellows]]
[[Category:Courant Institute of Mathematical Sciences faculty]]
[[Category:Sloan Research Fellows]]
[[Category:Mathematicians from New York (state)]]
[[Category:People from Brooklyn]]</text>
      <sha1>0q5mt69sn5jl2nah3phak1v0cha1cvt</sha1>
    </revision>
  </page>
  <page>
    <title>Korovkin approximation</title>
    <ns>0</ns>
    <id>51251595</id>
    <revision>
      <id>825299534</id>
      <parentid>733206740</parentid>
      <timestamp>2018-02-12T16:37:07Z</timestamp>
      <contributor>
        <username>Kevinalewis</username>
        <id>512560</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1091">In [[mathematics]] the '''Korovkin approximation''' is a convergence statement in which the approximation of a function is given by a certain sequence of functions. In practice a [[continuous function]] can be approximated by [[polynomials]]. With Korovkin approximations one comes a convergence for the whole approximation with examination of the convergence of the process at a finite number of functions. The Korovkin approximation is named after [[Pavel Korovkin]].&lt;ref&gt;{{cite journal|last1=Korovkin|first1=P.P.|title=On convergence of linear positive operators in the space of continuous function|journal=Proceedings of the USSR Academy of Sciences|date=1953|volume=90|pages=961–964}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Altomare |first= Francesco|last2=Campiti |first2=Michele |date= 1994|title= Korovkin-type Approximation Theory and Its Applications|url=https://books.google.co.uk/books?id=NGsXNrmWQ8YC&amp;redir_esc=y |publisher= Walter de Gruyter|pages=627 |access-date=4 August 2016}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Computational mathematics]]
[[Category:Functional analysis]]</text>
      <sha1>l9qq7rahj3uvdavtqor9gwuf91o0nv0</sha1>
    </revision>
  </page>
  <page>
    <title>Larry Stockmeyer</title>
    <ns>0</ns>
    <id>21449443</id>
    <revision>
      <id>867522692</id>
      <parentid>843454610</parentid>
      <timestamp>2018-11-06T07:36:10Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6910">{{Infobox person
| name          =  Larry Stockmeyer
| image         = &lt;!-- filename only, no "File:" or "Image:" prefix, and no enclosing [[brackets]] --&gt;
| alt           = &lt;!-- descriptive text for use by speech synthesis (text-to-speech) software --&gt;
| caption       = 
| birth_name    = &lt;!-- only use if different from name --&gt;
| birth_date    = 1948
| birth_place   = 
| death_date    = 31 July 2004
| death_place   = 
| nationality   = American
| other_names   = 
| occupation    = [[computer scientist]]
| years_active  = 
| known_for     = Pioneers in the field of [[computational complexity theory]]
| notable_works = 
}}

'''Larry Joseph Stockmeyer''' (1948 – 31 July 2004) was an American [[computer scientist]]. He was one of the pioneers in the field of [[computational complexity theory]], and he also worked in the field of [[distributed computing]].  He died of [[pancreatic cancer]].&lt;ref&gt;{{cite web|title=In Memoriam|url=http://currents.ucsc.edu/04-05/08-09/inmemoriam.html|website=currents online|publisher=UC Sanra Cruz|accessdate=6 June 2016|archiveurl=https://web.archive.org/web/20150930051821/http://currents.ucsc.edu/04-05/08-09/inmemoriam.html|archivedate=30 September 2015|date=9 August 2004}}&lt;/ref&gt;

== Career ==

* 1972: BSc in mathematics, [[Massachusetts Institute of Technology]].
* 1972: MSc in electrical engineering, Massachusetts Institute of Technology.
* 1974: PhD in computer science, Massachusetts Institute of Technology.
** Supervisor: [[Albert R. Meyer]].
* 1974–1982: [[IBM Research]], [[Thomas J. Watson Research Center]], Yorktown Heights, NY.
* 1982–November 2003: IBM Research, [[Almaden Research Center]], San Jose, CA.
* October 2002–2004: [[University of California, Santa Cruz]], Computer Science Department – Research Associate.

== Recognition ==

* 1996: Fellow of the [[Association for Computing Machinery]]: "For several fundamental contributions to computational complexity theory, which have significantly affected the course of this field."&lt;ref&gt;[http://fellows.acm.org/fellow_citation.cfm?id=1438050&amp;srt=all ACM: Fellows Award / Larry Stockmeyer] {{webarchive|url=https://web.archive.org/web/20071214193649/http://fellows.acm.org/fellow_citation.cfm?id=1438050&amp;srt=all |date=2007-12-14 }}.&lt;/ref&gt;
* 2007: The [[Edsger W. Dijkstra Prize in Distributed Computing]] for the paper {{harvtxt|Dwork|Lynch|Stockmeyer|1988}}.&lt;ref name="podc-dijkstra-2007"&gt;[[Symposium on Principles of Distributed Computing|PODC]] web site: [http://www.podc.org/podc2007/dijkstra.shtml Dijkstra Prize 2007].&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Bortnikov|2007}}.&lt;/ref&gt;

== Notable publications ==

* {{harvtxt|Meyer|Stockmeyer|1972}} — this work introduced the [[polynomial hierarchy]].&lt;ref&gt;{{harvtxt|Fortnow|2005}}.&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Rajsbaum|2004}}.&lt;/ref&gt;
* {{harvtxt|Stockmeyer|1974}} — "one of the most remarkable doctoral theses in computer science".&lt;ref&gt;[http://www.cs.jhu.edu/~stoc05/STOC-Program.pdf STOC 2005 program].&lt;/ref&gt;
* {{harvtxt|Dwork|Lynch|Stockmeyer|1988}} — this paper received the [[Dijkstra Prize]] in 2007.&lt;ref name="podc-dijkstra-2007"/&gt;

{{Expand list|date=September 2009}}

== Notes ==
{{reflist}}

== References ==
* {{citation

 | last=Bortnikov | first=Edward
 | title=Review of DISC '07
 | journal=[[ACM SIGACT News]]
 | volume=38
 | issue=4
 | year=2007
 | pages=49–53
 | issn=0163-5700
 | doi=10.1145/1345189.1386170
 | postscript=&lt;!-- none --&gt;
}}.
* {{citation

 | title=Consensus in the presence of partial synchrony
 | last1=Dwork | first1=Cynthia | authorlink1=Cynthia Dwork
 | last2=Lynch | first2=Nancy | authorlink2=Nancy Lynch
 | last3=Stockmeyer | first3=Larry
 | journal=[[Journal of the ACM]]
 | volume=35
 | issue=2
 | year=1988
 | pages=288–323
 | doi=10.1145/42282.42283
 | postscript=&lt;!-- none --&gt;
}}.
* {{citation

 | last=Fortnow | first=Lance | authorlink=Lance Fortnow
 | chapter=Beyond NP: the work and legacy of Larry Stockmeyer
 | title=Proc. 37th Annual ACM [[Symposium on Theory of Computing]] (STOC, Baltimore, MD, USA, 2005)
 | pages=120–127
 | year=2005
 | isbn=1-58113-960-8
 | doi=10.1145/1060590.1060609
 | postscript=&lt;!-- none --&gt;
 | chapter-url=http://www.cs.uchicago.edu/~fortnow/papers/beyondnp.pdf
}}.
* {{citation

 | chapter=The equivalence problem for regular expressions with squaring requires exponential space
 | last1=Meyer | first1=Albert R. | authorlink=Albert R. Meyer
 | last2=Stockmeyer | first2=Larry J.
 | title=Proc. 13th Annual [[Symposium on Switching and Automata Theory]]
 | pages=125–129
 | year=1972
 | doi=10.1109/SWAT.1972.29
 | postscript=&lt;!-- none --&gt;
}}.
* {{citation

 | last=Rajsbaum | first=Sergio
 | title=Larry Stockmeyer: 1948–2004
 | journal=ACM SIGACT News
 | volume=35
 | issue=4
 | year=2004
 | page=39
 | issn=0163-5700
 | doi=10.1145/1054916.1054930
 | postscript=&lt;!-- none --&gt;
}}.
* {{citation

 | last=Stockmeyer | first=Larry J.
 | title=The Complexity of Decision Problems in Automata Theory and Logic
 | year=1974
 | hdl=1721.1/15540
 | postscript=&lt;!-- none --&gt;
}}. PhD Thesis.
* {{cite web

 | url=http://hcr3.isiknowledge.com/author.cgi?id=1516
 | title=Larry Stockmeyer
 | work=[[ISI highly cited researcher|ISI Web of Knowledge, highly cited researchers]]
}}{{dead link|date=April 2016}}
* {{cite web

 | url=http://currents.ucsc.edu/04-05/08-09/inmemoriam.html
 | title=In Memoriam – Larry Stockmeyer
 | work=UC Santa Cruz Currents Online
 | date=9 August 2004
}}
* {{cite web
 |url          = http://www.ucsc.edu/news_events/messages/04-05/08-05.stockmeyer.asp
 |title        = Administrative Message: Passing of Larry Stockmeyer
 |work         = UC Santa Cruz
 |date         = 5 August 2004
 |access-date  = 2009-02-08
 |archive-url  = https://web.archive.org/web/20080528211529/http://www.ucsc.edu/news_events/messages/04-05/08-05.stockmeyer.asp
 |archive-date = 2008-05-28
 |dead-url     = yes
 |df           = 
}}
* {{cite web

 | url=http://genealogy.math.ndsu.nodak.edu/id.php?id=81230
 | title=Larry Joseph Stockmeyer
 | work=[[Mathematics Genealogy Project]]
}}
* {{cite web

 | url=http://www.cs.jhu.edu/~stoc05/STOC-Program.pdf
 | title=STOC 2005 conference program
}} Includes the program of 'Larry Stockmeyer Commemoration' (21 May 2005).

== External links ==
* [https://www.webcitation.org/query?url=http://www.geocities.com/stockmeyer%40sbcglobal.net/&amp;date=2009-10-25+22:24:06 Larry Stockmeyer's Home Page].
* {{DBLP|name=Larry J. Stockmeyer}}

{{Authority control}}

{{DEFAULTSORT:Stockmeyer, Larry}}

[[Category:1948 births]]
[[Category:2004 deaths]]
[[Category:American computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Researchers in distributed computing]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:University of California, Santa Cruz faculty]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:Dijkstra Prize laureates]]

{{compu-scientist-stub}}</text>
      <sha1>fj6v173mgswppwks5qq9xqpf8hy867m</sha1>
    </revision>
  </page>
  <page>
    <title>Lipman Bers</title>
    <ns>0</ns>
    <id>9335972</id>
    <revision>
      <id>859888376</id>
      <parentid>846661367</parentid>
      <timestamp>2018-09-16T23:25:30Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>added Alexander Nagel to list of doctoral students</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20917">{{Infobox scientist
| name              = Lipman Bers
| image             = &lt;!--(filename only)--&gt;
| image_size        = 
| caption           = 
| birth_date        = {{birth date|1914|05|22|mf=y}}
| birth_place       = [[Riga]], [[Governorate of Livonia]]
| death_date        = {{death date and age|1993|10|29|1914|05|22|mf=y}}
| death_place       = [[New Rochelle, New York|New Rochelle]], [[New York (state)|New York]]
| nationality       = [[United States|American]]
| fields            = [[Mathematics]]
| workplaces        = [[New York University]]&lt;br /&gt;[[Columbia University]]&lt;br /&gt;[[Brown University]]&lt;br /&gt;[[Syracuse University]]
| alma_mater        = [[Karl-Ferdinands-Universität]]
| doctoral_advisor  = [[Charles Loewner]]
| doctoral_students = [[Enrico Arbarello]]&lt;br/&gt; [[Jane Piore Gilman]]&lt;br/&gt; [[Irwin Kra]]&lt;br/&gt; [[Linda Keen]]&lt;br/&gt; [[Alexander Nagel]]&lt;br/&gt; [[Murray H. Protter]]&lt;br/&gt; [[Lesley Sibner]] &lt;br/&gt; [[Raymond O. Wells, Jr.]]
| known_for         = 
| awards            = [[Leroy P. Steele Prize]] &lt;small&gt;(1975)&lt;/small&gt;
}}
'''Lipman "Lipa" Bers''' ([[Latvian language|Latvian]]: ''Lipmans Berss''; May 22, 1914 – October 29, 1993) was an [[United States|American]] [[mathematician]] born in [[Riga]] who created the theory of [[pseudoanalytic function]]s and worked on [[Riemann surface]]s and [[Kleinian group]]s. He was also known for his work in human rights activism.&lt;ref name="mactutor"/&gt;&lt;ref name="nas"&gt;{{citation|url=http://books.nap.edu/html/biomems/lbers.html|title=Lipman Bers, May 22, 1914 — October 29, 1993|first1=Hyman|last1=Bass|author1-link=Hyman Bass|first2=Irwin|last2=Kra|author2-link=Irwin Kra|series=Biographical Memoirs of the National Academy of Sciences|publisher=National Academies Press}}.&lt;/ref&gt;

==Biography==
Bers was born in Riga, then under the rule of the Russian Csars, and spent several years as a child in [[Saint Petersburg]]; his family returned to Riga in approximately 1919, by which time it was part of independent [[Latvia]]. In Riga, his mother was the principal of a Jewish elementary school, and his father became the principal of a Jewish high school, both of which Bers attended, with an interlude in [[Berlin]] while his mother, by then separated from his father, attended the [[Berlin Psychoanalytic Institute]]. After high school, Bers studied at the [[University of Zurich]] for a year, but had to return to Riga again because of the difficulty of transferring money from Latvia in the international financial crisis of the time. He continued his studies at the [[University of Riga]], where he became active in socialist politics, including giving political speeches and working for an underground newspaper. In the aftermath of the Latvian coup in 1934 by right-wing leader [[Kārlis Ulmanis]], Bers was targeted for arrest but fled the country, first to Estonia and then to Czechoslovakia.&lt;ref name="mactutor"&gt;{{MacTutor Biography|id=Bers}}&lt;/ref&gt;&lt;ref name="mmp"&gt;{{citation|contribution=Lipman Bers|title=More Mathematical People|editor1-first=Donald J.|editor1-last=Albers|editor2-first=Gerald L.|editor2-last=Alexanderson|editor2-link=Gerald L. Alexanderson|editor3-first=Constance|editor3-last=Reid|editor3-link=Constance Reid|publisher=Harcourt Brace Jovanovich|year=1990|pages=2–21}}.&lt;/ref&gt;&lt;ref name="cur"&gt;{{citation|title=Lipman Bers, 79, Human Rights Activist, Dies|date=November 12, 1993|journal=Columbia University Record|url=http://www.columbia.edu/cu/record/archives/vol19/vol19_iss10/record1910.25|volume=19|issue=10}}.&lt;/ref&gt;

Bers received his Ph.D. in 1938 from the [[Charles University in Prague|University of Prague]].&lt;ref name="mathgen"&gt;{{MathGenealogy |id=8010}}&lt;/ref&gt; He had begun his studies in Prague with [[Rudolf Carnap]], but when Carnap moved to the US he switched to [[Charles Loewner]], who would eventually become his thesis advisor. In Prague, he lived with an aunt, and married his wife Mary (née Kagan) whom he had met in elementary school and who had followed him from Riga. Having applied for postdoctoral studies in Paris, he was given a visa to go to France soon after the [[Munich Agreement]], in which Nazi Germany annexed Czechoslovakia. He and his wife Mary had a daughter in Paris. They were unable to obtain a visa there to emigrate to the US, as the Latvian quota had filled, so they escaped to the south of France ten days before the fall of Paris, and eventually obtained an emergency US visa in Marseilles, one of a group of 10,000 visas set aside for political refugees by [[Eleanor Roosevelt]]. The Bers family rejoined Bers' mother, who had by then moved to [[New York City]] and become a psychoanalyst, married to thespian Beno Tumarin. At this time, Bers worked for a small Yiddish research agency, YIVO.&lt;ref name="mactutor"/&gt;&lt;ref name="nas"/&gt;&lt;ref name="mmp"/&gt;&lt;ref name="cur"/&gt;

Bers spent World War II teaching mathematics as a research associate at [[Brown University]], where he was joined by Loewner. After the war, Bers found an assistant professorship at [[Syracuse University]] (1945–1951), before moving to [[New York University]] (1951–1964) and then [[Columbia University]] (1964–1982), where he became the Davies Professor of Mathematics,&lt;ref name="mmp"/&gt;&lt;ref name="cur"/&gt; and where he chaired the mathematics department from 1972 to 1975.&lt;ref name="abikoff"/&gt; His move to NYU coincided with a move of his family to [[New Rochelle, New York]], where he joined a small community of émigré mathematicians.&lt;ref name="abikoff"&gt;{{citation|url=http://www.ams.org/notices/199501/bers.pdf|title=Lipman Bers|first=William|last=Abikoff|department=Remembering Lipman Bers|journal=[[Notices of the AMS]]|date=January 1995|pages=8–18|volume=42|issue=1}}.&lt;/ref&gt; He was a visiting scholar at the [[Institute for Advanced Study]] in 1949–51.&lt;ref&gt;[http://www.ias.edu/people/cos/users/4035 Community of Scholars Profile], [[Institute for Advanced Study]], retrieved 2013-03-30.&lt;/ref&gt; He was a Vice-President (1963–65) and a President (1975–77) of the [[American Mathematical Society]], chaired the Division of Mathematical Sciences of the [[United States National Research Council]] from 1969 to 1971, chaired the U.S. National Committee on Mathematics from 1977 to 1981, and chaired the Mathematics Section of the [[National Academy of Sciences]] from 1967 to 1970.&lt;ref name="cur"/&gt;&lt;ref name="amspres"/&gt;

Late in his life, Bers suffered from [[Parkinson's disease]] and [[stroke]]s. He died on October 29, 1993.&lt;ref name="cur"/&gt;

==Mathematical research==
Bers' doctoral work was on the subject of [[potential theory]]. While in Paris, he worked on [[Green's function]] and on integral representations. After first moving to the US, while working for YIVO, he researched Yiddish mathematics textbooks rather than pure mathematics.&lt;ref name="abikoff"/&gt;

At Brown, he began working on problems of [[fluid dynamics]], and in particular on the two-dimensional subsonic flows associated with cross-sections of [[airfoil]]s. At this time, he began his work with [[Abe Gelbart]] on what would eventually develop into the theory of [[pseudoanalytic function]]s. Through the 1940s and 1950s he continued to develop this theory, and to use it to study the planar [[elliptic partial differential equation]]s associated with subsonic flows. Another of his major results in this time concerned the singularities of the partial differential equations defining [[minimal surface]]s. Bers proved an extension of [[Removable singularity#Riemann's theorem|Riemann's theorem on removable singularities]], showing that any isolated singularity of a pencil of minimal surfaces can be removed; he spoke on this result at the 1950 [[International Congress of Mathematicians]] and published it in ''[[Annals of Mathematics]]''.&lt;ref name="abikoff"/&gt;

Later, beginning with his visit to the Institute for Advanced Study, Bers "began
a ten-year odyssey that took him from pseudoanalytic functions and elliptic equations to [[quasiconformal mapping]]s, [[Teichmüller theory]], and
[[Kleinian group]]s".&lt;ref name="abikoff"/&gt; With [[Lars Ahlfors]], he solved the "[[Moduli space|moduli problem]]", of finding a [[Holomorphic function|holomorphic]] parameterization of the [[Teichmüller space]], each point of which represents a [[compact space|compact]] [[Riemann surface]] of a given genus. During this period he also coined the popular phrasing of a question on eigenvalues of planar domains, "[[Hearing the shape of a drum|Can one hear the shape of a drum?]]", used as an article title by [[Mark Kac]] in 1966 and finally answered negatively in 1992 by an [[academic genealogy|academic descendant]] of Bers. In the late 1950s, by way of adding a coda to his earlier work, Bers wrote several major retrospectives of flows, pseudoanalytic functions, [[Fixed point (mathematics)|fixed point methods]], Riemann surface theory prior to his work on moduli, and the theory of [[several complex variables]]. In 1958, he presented his work on Riemann surfaces in a second talk at the International Congress of Mathematicians.&lt;ref name="abikoff"/&gt;

Bers' work on the parameterization of Teichmüller space led him in the 1960s to consider the boundary of the parameterized space, whose points corresponded to new types of [[Kleinian group]]s, eventually to be called [[Kleinian group#Degenerate Kleinian groups|singly-degenerate Kleinian groups]]. He applied [[Eichler–Shimura isomorphism|Eichler cohomology]], previously developed for applications in number theory and the theory of [[Lie group]]s, to Kleinian groups. He proved the [[Bers area inequality]], an area bound for hyperbolic surfaces that became a two-dimensional precursor to [[William Thurston]]'s work on [[Geometrization conjecture|geometrization of 3-manifolds]] and 3-manifold volume, and in this period Bers himself also studied the continuous symmetries of hyperbolic 3-space.&lt;ref name="abikoff"/&gt;

[[Quasi-Fuchsian group]]s may be mapped to a pair of Riemann surfaces by taking the quotient by the group of one of the two connected components of the complement of the group's limit set; fixing the image of one of these two maps leads to a subset of the space of Kleinian groups called a [[Bers slice]]. In 1970, Bers conjectured that the singly degenerate Kleinian surface groups can be found on the boundary of a Bers slice; this statement, known as the [[Bers density conjecture]], was finally proven by Namazi, Souto, and Ohshika in 2010 and 2011.&lt;ref&gt;{{citation|first2=Juan|last2=Souto|first=Hossein|last=Namazi|url=http://www-personal.umich.edu/~jsouto/papers.html|title=Non-realizability, ending laminations and the density conjecture|year=2010|deadurl=yes|archiveurl=https://web.archive.org/web/20090715232851/http://www-personal.umich.edu/~jsouto/papers.html|archivedate=2009-07-15|df=}}.&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Ohshika | first1=Ken'ichi| title=Realising end invariants by limits of minimally parabolic, geometrically finite groups | url=http://www.msp.warwick.ac.uk/gt/2011/15-02/p023.xhtml | year=2011 | journal = [[Geometry and Topology]] | issn=1364-0380 | volume=15 | issue =2 | pages=827–890 | doi=10.2140/gt.2011.15.827| arxiv=math/0504546 }}&lt;/ref&gt; The [[Bers compactification]] of Teichmüller space also dates to this period.

==Advising==
Over the course of his career, Bers [[Doctoral advisor|advised]] approximately 50 doctoral students,&lt;ref&gt;The Mathematics Genealogy database lists 53, but other sources count only 48.&lt;/ref&gt; among them [[Enrico Arbarello]], [[Irwin Kra]], [[Linda Keen]], [[Murray H. Protter]], and [[Lesley Sibner]].&lt;ref name="mathgen"/&gt; Approximately a third of Bers' doctoral students were women, a high proportion for mathematics.&lt;ref name="amspres"&gt;{{citation|url=http://www.ams.org/about-us/presidents/43-bers|contribution=43. Lipman Bers (1914–1993)|title=AMS Presidents: A Timeline|publisher=[[American Mathematical Society]]|accessdate=2013-03-30}}.&lt;/ref&gt;&lt;ref name="weinstein"&gt;{{citation|url=http://www.ams.org/notices/199501/bers.pdf|title=Lipman Bers as mentor|first1=Tilla|last1=Weinstein|department=Remembering Lipman Bers|journal=[[Notices of the AMS]]|date=January 1995|pages=22–23|volume=42|issue=1}}.&lt;/ref&gt; Having felt neglected by his own advisor,&lt;ref name="mmp"/&gt; Bers met regularly for meals with his students and former students,&lt;ref name="abikoff"/&gt; maintained a keen interest in their personal lives as well as their professional accomplishments,&lt;ref name="weinstein"/&gt; and kept up a friendly competition with [[Lars Ahlfors]] over who could bring to larger number of academic descendants to mathematical gatherings.&lt;ref name="nas"/&gt;

==Human rights activism==
As a small child with his mother in Saint Petersburg, Bers had cheered the Russian Revolution and the rise of the [[Soviet Union]], but by the late 1930s he had become disillusioned with communism after the assassination of [[Sergey Kirov]] and [[Stalin]]'s ensuing [[Great Purge|purges]].&lt;ref name="mmp"/&gt; His son Victor later said that "His experiences in Europe motivated his activism in the human rights movement,"&lt;ref name="cur"/&gt; and Bers himself attributed his interest in human rights to the legacy of [[Menshevik]] leader [[Julius Martov]].&lt;ref name="mmp"/&gt; He founded the Committee on Human Rights of the [[National Academy of Sciences]],&lt;ref name="cur"/&gt;&lt;ref&gt;{{citation|url=http://www.ams.org/notices/199501/bers.pdf|title=On the social activism of Lipman Bers|first1=Carol|last1=Corillon|first2=Irwin|last2=Kra|author2-link=Irwin Kra|department=Remembering Lipman Bers|journal=[[Notices of the AMS]]|date=January 1995|pages=18–22|volume=42|issue=1}}.&lt;/ref&gt; and beginning in the 1970s worked to allow the emigration of dissident soviet mathematicians including Yuri Shikhanovich, [[Leonid Plyushch]], [[Valentin Turchin]], and [[Chudnovsky brothers|David and Gregory Chudnovsky]].&lt;ref name="cur"/&gt; Within the U.S., he also opposed the American involvement in the [[Vietnam War]] and southeast Asia,&lt;ref name="nas"/&gt;&lt;ref name="abikoff"/&gt; and the maintenance of the U.S. nuclear arsenal during the [[Cold War]].&lt;ref name="nas"/&gt;

==Awards and honors==
In 1961, Bers was elected a Fellow of the [[American Academy of Arts and Sciences]],&lt;ref name=AAAS&gt;{{cite web|title=Book of Members, 1780–2010: Chapter B|url=http://www.amacad.org/publications/BookofMembers/ChapterB.pdf|publisher=American Academy of Arts and Sciences|accessdate=June 24, 2011}}&lt;/ref&gt; and in 1965 he became a Fellow of the [[American Association for the Advancement of Science]].&lt;ref name="abikoff"/&gt; He joined the [[National Academy of Sciences]] in 1964.&lt;ref name="abikoff"/&gt; He was a member of  the [[Finnish Academy of Science and Letters|Finnish Academy of Sciences]], and the [[American Philosophical Society]].  He received the [[American Mathematical Society|AMS]] [[Leroy P. Steele Prize]] for mathematical exposition in 1975 for his paper "Uniformization, moduli, and Kleinian groups". In 1986, the [[New York Academy of Sciences]] gave him their Human Rights Award.&lt;ref name="cur"/&gt; In the early 1980s, the [[Association for Women in Mathematics]] held a symposium to honor Bers' accomplishments in mentoring women mathematicians.&lt;ref name="mmp"/&gt;

== Publications ==

===Books===
*{{Citation | last1=Bers | first1=Lipman | title=Theory of pseudo-analytic functions | url=https://books.google.com/books?id=79dWAAAAMAAJ | publisher=Institute for Mathematics and Mechanics, New York University, New York | year=1953 | mr=0057347}}
*{{Citation | last1 =Bers | first1=Lipman | title=Mathematical aspects of subsonic and transonic gas dynamics | publisher=John Wiley &amp; Sons | location=New York | year=1958}}&lt;ref&gt;{{cite journal|author=Bergman, Stefan|authorlink=Stefan Bergman|title=Review: Lipman Bers, ''Mathematical aspects of subsonic and transonic gas dynamics''|journal=Bull. Amer. Math. Soc.|year=1961|volume=67|issue=4|pages=337–339|url=http://www.ams.org/journals/bull/1961-67-04/S0002-9904-1961-10602-2/|doi=10.1090/s0002-9904-1961-10602-2}}&lt;/ref&gt;
*Bers, Lipman (1976), Calculus, Holt, Rinehart and Winston, (in collaboration with Frank Karal)
*{{Citation | last1=Bers | first1=Lipman | editor1-last=Kra | editor1-first=Irwin | editor1-link = Irwin Kra | editor2-last=Maskit | editor2-first=Bernard | editor2-link = Bernard Maskit | title=Selected works of Lipman Bers. Part 1 | url=http://www.ams.org/bookstore-getitem/item=CWORKS-9-1 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | isbn=978-0-8218-0996-9 | year=1998 | mr=1643465}}
*{{Citation | last1=Bers | first1=Lipman | editor1-last=Kra | editor1-first=Irwin | editor1-link = Irwin Kra | editor2-last=Maskit | editor2-first=Bernard | editor2-link = Bernard Maskit | title=Selected works of Lipman Bers. Part 2 | url=http://www.ams.org/bookstore-getitem/item=CWORKS-9-2 | publisher=[[American Mathematical Society]] | location=Providence, R.I. | isbn=978-0-8218-0997-6 | year=1998 | mr=1643469}}

===Selected articles===
*with [[Abe Gelbart]]: {{cite journal|title=On a class of functions defined by partial differential equations|journal=Trans. Amer. Math. Soc.|year=1944|volume=56|pages=67–93|mr=0010910|doi=10.1090/s0002-9947-1944-0010910-5}}
*{{cite journal|title=On rings of analytic functions|journal=Bull. Amer. Math. Soc.|year=1948|volume=54|pages=311–315|mr=0024970|doi=10.1090/s0002-9904-1948-08992-3}}
*{{cite journal|title=Partial Differential Equations and Generalized Analytic Functions|journal=Proc Natl Acad Sci U S A|date=February 1950|volume=36|issue=2|pages=130–136|pmc=1063147|pmid=16588958|doi=10.1073/pnas.36.2.130|bibcode=1950PNAS...36..130B}}
*{{cite journal|title=Partial Differential Equations and Generalized Analytic Functions: Second Note|journal=Proc Natl Acad Sci U S A|date=January 1951|volume=37|issue=1|pages=42–47|pmc=1063297|pmid=16588987|doi=10.1073/pnas.37.1.42|bibcode=1951PNAS...37...42B}}
*{{cite journal|title=Boundary value problems for minimal surfaces with singularities at infinity|journal=Trans. Amer. Math. Soc.|year=1951|volume=70|pages=465–491|mr=0043337|doi=10.1090/s0002-9947-1951-0043337-4}}
*with [[Shmuel Agmon]]: {{cite journal|title=The expansion theorem for pseudo-analytic functions|journal=Proc. Amer. Math. Soc.|year=1952|volume=3|pages=757–764|mr=0057349|doi=10.1090/s0002-9939-1952-0057349-4}}
*{{cite journal|title=An outline of the theory  of pseudoanalytic functions|journal=Bull. Amer. Math. Soc.|year=1956|volume=62|pages=291–331|mr=0081936|doi=10.1090/s0002-9904-1956-10037-2}}
*{{cite journal|title=On a theorem of Mori and the definition of quasiconformality|journal=Trans. Amer. Math. Soc.|year=1957|volume=84|pages=78–84|mr=0083025|doi=10.1090/s0002-9947-1957-0083025-7}}
*{{cite journal|title=Simultaneous uniformization|journal=Bull. Amer. Math. Soc.|year=1960|volume=66|pages=94–97|mr=0111834|doi=10.1090/s0002-9904-1960-10413-2}}
*{{cite journal|title=Spaces of Riemann surfaces as bounded domains|journal=Bull. Amer. Math. Soc.|year=1960|volume=66|pages=98–103|mr=0111835|doi=10.1090/s0002-9904-1960-10415-6}}
*{{cite journal|title=Holomorphic differentials as functions of moduli|journal=Bull. Amer. Math. Soc.|year=1961|volume=67|pages=206–210|mr=0122989|doi=10.1090/s0002-9904-1961-10569-7}}
*with [[Leon Ehrenpreis]]: {{cite journal|title=Holomorphic convexity of Teichmüller spaces|journal=Bull. Amer. Math. Soc.|year=1964|volume=70|pages=761–764|mr=0168800|doi=10.1090/s0002-9904-1964-11230-1}}
*{{cite journal|title=On spaces of Riemann surfaces with nodes|journal=Bull. Amer. Math. Soc.|year=1974|volume=80|pages=1219–1222|mr=0361165|doi=10.1090/s0002-9904-1974-13686-4}}
*{{cite journal|title=Quasiconformal mappings with applications to differential equations, function theory and topology|journal=Bull. Amer. Math. Soc.|year=1977|volume=83|pages=1083–1100|mr=0463433|doi=10.1090/s0002-9904-1977-14390-5}}
*{{cite journal|title=Finite dimensional Teichmüller spaces and generalizations|journal=Bull. Amer. Math. Soc. (N.S.)|year=1981|volume=5|pages=131–172|mr=621883|doi=10.1090/s0273-0979-1981-14933-8}}

== References ==
{{Reflist}}

{{AMS Presidents}}

{{Authority control}}

{{DEFAULTSORT:Bers, Lipman}}
[[Category:20th-century American mathematicians]]
[[Category:Latvian mathematicians]]
[[Category:Latvian emigrants to the United States]]
[[Category:People from Riga]]
[[Category:New York University faculty]]
[[Category:Columbia University faculty]]
[[Category:Syracuse University faculty]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Fellows of the American Association for the Advancement of Science]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Complex analysts]]
[[Category:1914 births]]
[[Category:1993 deaths]]
[[Category:Presidents of the American Mathematical Society]]
[[Category:People from New Rochelle, New York]]
[[Category:Mathematical analysts]]</text>
      <sha1>gqk605qpikecqf9z5h2yic4hcnnckdp</sha1>
    </revision>
  </page>
  <page>
    <title>List of NP-complete problems</title>
    <ns>0</ns>
    <id>1707754</id>
    <revision>
      <id>870916980</id>
      <parentid>869180802</parentid>
      <timestamp>2018-11-27T19:52:48Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: isbn, template type, title. Add: series, citeseerx, year, class, date, doi, pages, issue, volume, journal, isbn, author pars. 1-2. Removed accessdate with no specified URL. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24487">{{dynamic list}}

This is a list of some of the more commonly known problems that are [[NP-complete]] when expressed as [[decision problem]]s. As there are hundreds of such problems known, this list is in no way comprehensive. Many problems of this type can be found in {{harvtxt|Garey|Johnson|1979}}.

==Graphs and hypergraphs==
[[Graph theory|Graphs]] occur frequently in everyday applications. Examples include biological or social networks, which contain hundreds, thousands and even billions of nodes in some cases (e.g. [[Facebook]] or [[LinkedIn]]). 
*[[1-planar graph|1-planarity]]{{sfnp|Grigoriev|Bodlaender|2007}}
*[[3-dimensional matching]]&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP1&lt;/ref&gt;
*[[Bipartite dimension]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT18&lt;/ref&gt;
*[[Capacitated minimum spanning tree]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND5&lt;/ref&gt;
*[[Route inspection problem]] (also called '''Chinese postman problem''') for [[mixed graph]]s (having both directed and undirected edges). The program is solvable in polynomial time if the graph has all undirected or all directed edges. Variants include the rural postman problem.&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND25, ND27&lt;/ref&gt;
*[[Clique problem]]&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT19&lt;/ref&gt;
*[[Complete coloring]], a.k.a. achromatic number&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT5&lt;/ref&gt;
*[[Domatic number]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT3&lt;/ref&gt;
*[[Dominating set problem|Dominating set]], a.k.a. domination number&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT2&lt;/ref&gt;
::NP-complete special cases include the [[edge dominating set]] problem, i.e., the dominating set problem in line graphs. NP-complete variants include the [[connected dominating set]] problem and the [[maximum leaf spanning tree]] problem.&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND2&lt;/ref&gt;
*[[Bandwidth problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT40&lt;/ref&gt;
*[[Clique cover problem]]&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT17&lt;/ref&gt;
*[[Cycle rank|Rank coloring]] a.k.a. cycle rank
*[[Degree-constrained spanning tree]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND1&lt;/ref&gt;
*[[Exact cover]] problem. Remains NP-complete for 3-sets. Solvable in polynomial time for 2-sets (this is a [[Matching (graph theory)|matching]]).&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP2&lt;/ref&gt;
*[[Feedback vertex set]]&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT7&lt;/ref&gt;
*[[Feedback arc set]]&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT8&lt;/ref&gt;
*[[Graph homomorphism]] problem&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT52&lt;/ref&gt;
*[[Graph coloring]]&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT4&lt;/ref&gt;
*[[Graph partition]] into [[Glossary of graph theory#Subgraphs|subgraphs]] of specific types (triangles, [[graph isomorphism|isomorphic]] [[Glossary of graph theory#Subgraphs|subgraphs]], [[Hamiltonian graph|Hamiltonian]] subgraphs, [[forest (graph theory)|forests]], [[perfect matching]]s) are known NP-complete. Partition into [[Glossary of graph theory#Cliques|cliques]] is the same problem as [[graph coloring|coloring]] the [[Complement (graph theory)|complement]] of the given graph. A related problem is to find a partition that is optimal terms of the number of edges between parts.&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT11, GT12, GT13, GT14, GT15, GT16, ND14&lt;/ref&gt;
*[[Hamiltonian completion]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT34&lt;/ref&gt;
*[[Hamiltonian path problem]], directed and undirected.&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT37, GT38, GT39&lt;/ref&gt;
*[[Longest path problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND29&lt;/ref&gt;
*Maximum bipartite subgraph or (especially with weighted edges) [[maximum cut]].&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT25, ND16&lt;/ref&gt;
*[[Maximum independent set]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT20&lt;/ref&gt;
*Maximum [[Induced path]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT23&lt;/ref&gt;
*[[Intersection number (graph theory)|Graph intersection number]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT59&lt;/ref&gt;
*[[Metric dimension (graph theory)|Metric dimension]] of a graph&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT61&lt;/ref&gt;
*[[Minimum k-cut]]
*[[Steiner tree problem|Steiner tree]], or [[Minimum spanning tree]] for a subset of the vertices of a graph.&lt;ref name="karp"/&gt; (The minimum spanning tree for an entire graph is solvable in polynomial time.)
*[[Modularity (networks)|Modularity maximization]]&lt;ref&gt;{{cite | title = Maximizing Modularity is hard | first1 = Ulrik | last1 = Brandes | first2 = Daniel | last2 = Delling | first3 = Marco | last3 = Gaertler | first4 = Robert | last4 = Görke | first5 = Martin | last5 = Hoefer | first6 = Zoran | last6 = Nikoloski | first7 = Dorothea | last7 = Wagner | year = 2006 | arxiv = physics/0608255| bibcode = 2006physics...8255B }}&lt;/ref&gt;
*[[Pathwidth]]&lt;ref name="acp1987"/&gt;
*[[Set cover problem|Set cover]] (also called '''minimum cover''' problem) This is equivalent, by transposing the incidence matrix, to the hitting set problem.&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP5, SP8&lt;/ref&gt;
*[[Set splitting]] problem&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP4&lt;/ref&gt;
*[[Shortest total path length spanning tree]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND3&lt;/ref&gt;
*[[Slope number]] two testing&lt;ref name=Comp2Planar&gt;{{cite book|title=Lecture Notes in Computer Science| year=1995| volume=894/1995 | pages=286–297| doi=10.1007/3-540-58950-3_384 | chapter=On the computational complexity of upward and rectilinear planarity testing| last1=Garg| first1=Ashim| last2=Tamassia| first2=Roberto| isbn=978-3-540-58950-1}}&lt;/ref&gt;
*[[Treewidth]]&lt;ref name="acp1987"&gt;{{harvtxt|Arnborg|Corneil|Proskurowski|1987}}&lt;/ref&gt;
*[[Vertex cover]]&lt;ref name="karp"&gt;{{harvtxt|Karp|1972}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT1&lt;/ref&gt;

==Mathematical programming==
*[[3-partition problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP15&lt;/ref&gt;
*[[Bin packing problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SR1&lt;/ref&gt;
*[[Knapsack problem]], [[quadratic knapsack problem]], and several variants&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: MP9&lt;/ref&gt;
*Variations on the [[Traveling salesman problem]]. The problem for graphs is NP-complete if the edge lengths are assumed integers. The problem for points on the plane is NP-complete with the discretized Euclidean metric and rectilinear metric. The problem is known to be NP-hard with the (non-discretized) Euclidean metric.&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND22, ND23&lt;/ref&gt;
*[[Bottleneck traveling salesman]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND24&lt;/ref&gt;
*[[Integer programming]]. The variant where variables are required to be 0 or 1, called zero-one linear programming, and several other variants are also NP-complete&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: MP1&lt;/ref&gt;
*[[Latin square]]s (The problem of determining if a partially filled square can be completed to form one)
*[[Numerical 3-dimensional matching]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP16&lt;/ref&gt;
*[[Partition problem]]&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP12&lt;/ref&gt;
*[[Quadratic assignment problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND43&lt;/ref&gt;
*[[Quadratic programming]] (NP-hard in some cases, P if convex)
*[[Subset sum problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP13&lt;/ref&gt;

==Formal languages and string processing==
*[[Closest string]]&lt;ref&gt;{{citation
 | last1 = Lanctot | first1 = J. Kevin
 | last2 = Li | first2 = Ming
 | last3 = Ma | first3 = Bin
 | last4 = Wang | first4 = Shaojiu
 | last5 = Zhang | first5 = Louxin
 | doi = 10.1016/S0890-5401(03)00057-9
 | issue = 1
 | journal = Information and Computation
 | mr = 1994748
 | pages = 41–55
 | title = Distinguishing string selection problems
 | volume = 185
 | year = 2003}}&lt;/ref&gt;
*[[Longest common subsequence problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SR10&lt;/ref&gt;
*The bounded variant of the [[Post correspondence problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SR11&lt;/ref&gt;
*[[Shortest common supersequence]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SR8&lt;/ref&gt;
*[[String-to-string correction problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SR20&lt;/ref&gt;

==Games and puzzles==
*[[Battleship (puzzle)|Battleship]]
*[[Bulls and Cows]], marketed as [[Mastermind (board game)|Master Mind]]: certain optimisation problems but not the game itself. 
*[[Eternity II Puzzle|Eternity II]]
*([[Generalized game|Generalized]]) [[FreeCell]]&lt;ref&gt;Malte Helmert, Complexity results for standard benchmark domains in planning, Artificial Intelligence Journal 143(2):219-262, 2003.&lt;/ref&gt;
*[[Fillomino]]&lt;ref&gt;{{cite web | last = Yato | first = Takauki | title = Complexity and Completeness of Finding Another Solution and its Application to Puzzles | year = 2003 | citeseerx = 10.1.1.103.8380 }}&lt;/ref&gt;
*[[Hashiwokakero]]&lt;ref&gt;{{cite web | title = HASHIWOKAKERO Is NP-Complete | url = http://www.cs.au.dk/~koda/hashiwokakero }}&lt;/ref&gt;
*[[Heyawake]]&lt;ref name="Holzer-Ruepp07"&gt;{{harvtxt|Holzer|Ruepp|2007}}&lt;/ref&gt;
*([[Generalized game|Generalized]]) [[Instant Insanity]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GP15&lt;/ref&gt;
*[[Kakuro|Kakuro (Cross Sums)]]
*[[Kuromasu]] (also known as Kurodoko)&lt;ref name="Kölker12b"&gt;{{cite journal | last = Kölker | first = Jonas | title = Kurodoko is NP-complete | journal = Journal of Information Processing | volume = 20 | issue = 3 | pages = 694–706 | year = 2012 | url = https://www.jstage.jst.go.jp/article/ipsjjip/20/3/20_694/_article| doi = 10.2197/ipsjjip.20.694 }}&lt;/ref&gt;
*[[Lemmings (game)|Lemmings]] (with a polynomial time limit)&lt;ref name="Cormode04"&gt;{{cite conference | author = Cormode, Graham | title = The hardness of the lemmings game, or Oh no, more NP-completeness proofs | url= http://dimacs.rutgers.edu/~graham/pubs/papers/cormodelemmings.pdf | year = 2004}}&lt;/ref&gt;
*[[Light Up (puzzle)|Light Up]]&lt;ref&gt;[https://web.archive.org/web/20080308132136/http://www.cs.umass.edu/~mcphailb/papers/2005lightup.pdf Light Up is NP-Complete]&lt;/ref&gt;
*[[Masyu]]&lt;ref name="Friedman"&gt;{{cite web | author = Friedman, Erich | title = Pearl Puzzles are NP-complete | url = http://www2.stetson.edu/~efriedma/papers/pearl/pearl.html | date = 2012-03-27}}&lt;/ref&gt;
*[[Minesweeper Consistency Problem]]&lt;ref&gt;{{harvtxt|Kaye|2000}}&lt;/ref&gt; (but see Scott, Stege, &amp; van Rooij&lt;ref&gt;Allan Scott, Ulrike Stege, Iris van Rooij, Minesweeper may not be NP-complete but is hard nonetheless, ''The Mathematical Intelligencer'' '''33''':4 (2011), pp. 5-17.&lt;/ref&gt;)
*[[Nimber]] (or Grundy number) of a directed graph.&lt;ref name="Garey GT56"&gt;{{harvtxt|Garey|Johnson|1979}}: GT56&lt;/ref&gt;
*[[Numberlink]]
*[[Nonogram]]s
*[[Nurikabe (puzzle)|Nurikabe]]
*[[Rubik's Cube]] (solved optimally)
*[[SameGame]]
*[[Slither Link]] on a variety of grids&lt;ref name=sigal87/&gt;&lt;ref name="NU07"&gt;{{cite journal | last1 = Nukui | last2 = Uejima | title = ASP-Completeness of the Slither Link Puzzle on Several Grids | journal = Ipsj Sig Notes | volume = 2007 | issue = 23 | pages = 129–136 | url = http://ci.nii.ac.jp/naid/110006249219/en/| date = March 2007 }}&lt;/ref&gt;&lt;ref name="Kölker12c"&gt;{{cite journal | last = Kölker | first = Jonas | url = https://www.jstage.jst.go.jp/article/ipsjjip/20/3/20_709/_article | title = Selected Slither Link Variants are NP-complete | journal = Journal of Information Processing | volume = 20 | issue = 3 | pages = 709–712 | year = 2012| doi = 10.2197/ipsjjip.20.709 }}&lt;/ref&gt;
*([[Generalized game|Generalized]]) [[Sudoku]]&lt;ref name=sigal87&gt;{{cite conference|url=http://www-imai.is.s.u-tokyo.ac.jp/~yato/data2/SIGAL87-2.pdf |title=Complexity and Completeness of Finding Another Solution and Its Application to Puzzles|first1=Takayuki|last1=Sato|first2=Takahiro|last2=Seta|conference= International Symposium on Algorithms  (SIGAL 1987)|year=1987}}&lt;/ref&gt;&lt;ref&gt;A SURVEY OF NP-COMPLETE PUZZLES, Section 23; Graham Kendall, Andrew Parkes, Kristian Spoerer; March 2008. [https://www.cs.wmich.edu/elise/courses/cs431/icga2008.pdf (icga2008.pdf)]&lt;/ref&gt;
*[[Super Mario Bros]], this and whole host of other [[Nintendo]] games were proved NP-hard (but not NP-complete) in 2012 by Greg Aloupis, Erik D. Demaine, Alan Guo and Giovanni Viglietta using a [[polynomial-time reduction]] from [[3SAT]].&lt;ref&gt;{{cite arXiv|eprint=1203.1895|first1=Greg|last1=Aloupis|first2=Erik D.|last2=Demaine|first3=Alan|last3=Guo|first4=Giovanni|last4=Viglietta|title=
Classic Nintendo Games are (Computationally) Hard|class=cs.CC|year=2012}}&lt;/ref&gt;
*Problems related to [[Tetris]]&lt;ref&gt;{{cite conference|url=http://erikdemaine.org/papers/Tetris_COCOON2003/paper.pdf|title=Tetris is Hard, Even to Approximate|last1=Demaine|first1=Eric D.|last2=Hohenberger |first2=Susan|last3=Liben-Nowell|first3=David|date=July 25–28, 2003|conference=Proceedings of the 9th International Computing and Combinatorics Conference (COCOON 2003)|conferenceurl= https://web.archive.org/web/20120105042734/http://www.cs.montana.edu/bhz/cocoon03.html|location=Big Sky, Montana}}&lt;/ref&gt;
*[[Verbal arithmetic]]

==Other==
*[[Art gallery problem]] and its variations.
*[[Berth allocation problem]]&lt;ref&gt;{{citation
 | last = Lim | first = Andrew
 | doi = 10.1016/S0167-6377(98)00010-8
 | issue = 2–3
 | journal = Operations Research Letters
 | mr = 1653377
 | pages = 105–110
 | title = The berth planning problem
 | volume = 22
 | year = 1998}}&lt;/ref&gt;
*[[Betweenness]]
*Assembling an optimal [[Bitcoin]] block.&lt;ref&gt;[https://freedom-to-tinker.com/blog/jbonneau/bitcoin-mining-is-np-hard/ J. Bonneau, "Bitcoin mining is NP-hard'']&lt;/ref&gt;
*[[Boolean satisfiability problem]] (SAT).&lt;ref name="karp"/&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: LO1&lt;/ref&gt; There are many variations that are also NP-complete. An important variant is where each clause has exactly three literals (3SAT), since it is used in the proof of many other NP-completeness results.&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: p. 48&lt;/ref&gt;
*[[Conjunctive Boolean query]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SR31&lt;/ref&gt;
*[[Cyclic ordering]]
*[[Circuit satisfiability problem]]
*[[Facility location|Uncapacitated Facility Location]]
*[[Flow Shop Scheduling Problem]]
*[[Generalized assignment problem]]
*[[Hasse diagram#Upward planarity|Upward planarity]] testing&lt;ref name=Comp2Planar/&gt;
*[[National Resident Matching Program#Couples|Hospitals-and-residents problem with couples]]
*Some problems related to [[Job-shop scheduling]]
*[[Monochromatic triangle]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT6&lt;/ref&gt;
*[[Minimum maximal independent set]] a.k.a. minimum independent dominating set&lt;ref&gt;[http://www.csc.kth.se/~viggo/wwwcompendium/node14.html Minimum Independent Dominating Set]&lt;/ref&gt;
::NP-complete special cases include the [[minimum maximal matching]] problem,&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT10&lt;/ref&gt; which is essentially equal to the [[edge dominating set]] problem (see above).
*[[Maximum common subgraph isomorphism problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT49&lt;/ref&gt;
*[[Minimum degree spanning tree]]
*[[Minimum k-spanning tree]]
*[[Metric k-center]]
*[[Maximum 2-satisfiability|Maximum 2-Satisfiability]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: LO5&lt;/ref&gt;
*[[Modal logic]] S5-Satisfiability
*Some problems related to [[Multiprocessor scheduling]]
*Maximum volume [[submatrix]] – Problem of selecting the best conditioned subset of a larger m x n matrix. This class of problem is associated with Rank revealing [[QR factorization]]s and D optimal experimental design.&lt;ref&gt;https://web.archive.org/web/20150203193923/http://www.meliksah.edu.tr/acivril/max-vol-original.pdf&lt;/ref&gt;
*Minimal [[addition chain]]s for sequences.&lt;ref&gt;Peter Downey, Benton Leong, and Ravi Sethi. "Computing Sequences with Addition Chains" SIAM J. Comput., 10(3), 638–646, 1981&lt;/ref&gt; The complexity of minimal addition chains for individual numbers is unknown.&lt;ref&gt;[http://cr.yp.to/papers/pippenger.pdf D. J. Bernstein, "Pippinger's exponentiation algorithm'' (draft)]&lt;/ref&gt;
*Non-linear univariate polynomials over GF[2&lt;sup&gt;n&lt;/sup&gt;], n the length of the input. Indeed, over any GF[q&lt;sup&gt;n&lt;/sup&gt;].
*[[Open-shop scheduling]]
*[[Pathwidth]],&lt;ref name="acp1987"/&gt; or, equivalently, [[Path decomposition#Interval thickness|interval thickness]], and [[Path decomposition#Vertex separation number|vertex separation number]]&lt;ref&gt;{{harvtxt|Kashiwabara|Fujisawa|1979}}; {{harvtxt|Ohtsuki|Mori|Kuh|Kashiwabara|1979}}; {{harvtxt|Lengauer|1981}}.&lt;/ref&gt;
*[[Pancake sorting]] distance problem for strings&lt;ref&gt;{{cite journal | last1 = Hurkens | first1 = C. | last2 = Iersel | first2 = L. V. | last3 = Keijsper | first3 = J. | last4 = Kelk | first4 = S. | last5 = Stougie | first5 = L. | last6 = Tromp | first6 = J. | year = 2007 | title = Prefix reversals on binary and ternary strings | url = | journal = SIAM J. Discrete Math. | volume = 21 | issue = 3| pages = 592–611 | doi=10.1137/060664252| arxiv = math/0602456 }}&lt;/ref&gt;
*[[Route inspection problem#Variants|k-Chinese postman]]
*[[Subgraph isomorphism problem]]&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: GT48&lt;/ref&gt;
*Variations of the [[Steiner tree problem]]. Specifically, with the discretized Euclidean metric, rectilinear metric. The problem is known to be NP-hard with the (non-discretized) Euclidean metric.&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: ND13&lt;/ref&gt;
*[[Set packing]]&lt;ref name="karp" /&gt;&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SP3&lt;/ref&gt;
*[[Serializability]] of database histories&lt;ref&gt;{{harvtxt|Garey|Johnson|1979}}: SR33&lt;/ref&gt;
*Scheduling to minimize weighted completion time
*[[Sparse approximation]]
*Block Sorting&lt;ref&gt;{{Cite book|last=Bein|first=W. W.|last2=Larmore|first2=L. L.|last3=Latifi|first3=S.|last4=Sudborough|first4=I. H.|date=2002-01-01|title=Block sorting is hard|url=http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=1004305&amp;url=http%253A%252F%252Fieeexplore.ieee.org%252Fxpls%252Fabs_all.jsp%253Farnumber%253D1004305|journal=International Symposium on Parallel Architectures, Algorithms and Networks, 2002. I-SPAN '02. Proceedings|pages=307–312|doi=10.1109/ISPAN.2002.1004305|isbn=978-0-7695-1579-3}}&lt;/ref&gt; (Sorting by Block Moves)
*[[Second order logic|Second order]] [[universal instantiation|instantiation]]
*[[Treewidth]]&lt;ref name="acp1987"/&gt;
*Testing whether a [[tree (graph theory)|tree]] may be represented as [[Euclidean minimum spanning tree]]
*Three-dimensional [[Ising model]]&lt;ref&gt;[[Barry A. Cipra]], "The Ising Model Is NP-Complete", SIAM News, Vol 33, No 6.&lt;/ref&gt;
*[[Vehicle routing problem]]
&lt;!--
Propositional logic problems, in particular satisfiability problems and their variants, are of particular practical interest because many practical problems can be solved by expressing them as satisfiability problems, and then using efficient [[SAT solver]]s to obtain an exact solution quickly{{Citation needed|date=November 2010}}.
--&gt;

==See also==
* [[Existential theory of the reals#Complete problems]]
* [[Karp's 21 NP-complete problems]]
* [[List of PSPACE-complete problems]]
* [[Reduction (complexity)]]

== Notes ==
{{reflist|30em}}

== References ==
'''General'''
* {{Garey-Johnson}}. This book is a classic, developing the theory, then cataloguing ''many'' NP-Complete problems.
* {{cite conference
 | last = Cook
 | first = S.A.
 | authorlink = Stephen A. Cook
 | title = The complexity of theorem proving procedures
 | booktitle = Proceedings, Third Annual ACM Symposium on the Theory of Computing, ACM, New York
 | year = 1971
 | pages = 151–158
 |  doi = 10.1145/800157.805047
}}
* {{Cite book
 | first = Richard M.
 | last = Karp
 | authorlink = Richard Karp
 | chapter = Reducibility among combinatorial problems
 | title = Complexity of Computer Computations
 | editor1-first = Raymond E.
 | editor1-last = Miller
 | editor2-first = James W.
 | editor2-last = Thatcher
 | publisher = Plenum
 | pages = 85–103
 | year = 1972
 | ref = harv
}}
* {{cite web
 | last = Dunne
 | first = P.E.
 | title = An annotated list of selected NP-complete problems
 | publisher = COMP202, Dept. of Computer Science, [[University of Liverpool]]
 | url = http://www.csc.liv.ac.uk/~ped/teachadmin/COMP202/annotated_np.html
 | accessdate = 2008-06-21
}}
* {{cite web
 | last = Crescenzi
 | first = P.
 |author2=Kann, V. |author3=Halldórsson, M. |author4=[[Marek Karpinski|Karpinski, M.]] |author5=[[Gerhard J. Woeginger|Woeginger, G]]
 | title = A compendium of NP optimization problems
 | publisher = KTH NADA, Stockholm
 | url = http://www.nada.kth.se/~viggo/problemlist/compendium.html
 | accessdate = 2008-06-21
}}
* {{cite web
 | last = Dahlke
 | first = K
 | title = NP-complete problems
 | work = Math Reference Project
 | url = http://www.mathreference.com/lan-cx-np,intro.html
 | accessdate = 2008-06-21
}}

'''Specific problems'''
* {{cite web
 | first = E
 | last = Friedman
 | title = Pearl puzzles are NP-complete
 | year = 2002
 | publisher = Stetson University, DeLand, Florida
 | url = http://www.stetson.edu/~efriedma/papers/pearl/pearl.html
 | accessdate = 2008-06-21
}}
*{{cite journal
 | last1 = Grigoriev | first1 = A
 | last2 = Bodlaender | first2 = H L | author2-link = Hans L. Bodlaender
 | doi = 10.1007/s00453-007-0010-x
 | issue = 1
 | journal = Algorithmica
 | mr = 2344391
 | pages = 1–11
 | title = Algorithms for graphs embeddable with few crossings per edge
 | volume = 49
 | year = 2007
|ref=harv| citeseerx = 10.1.1.61.3576
 }}
* {{cite book
 | first1 = S
 | title = How the World Computes
 | volume = 7318
 | pages = 283–292
 | last1 = Hartung
 | first2 = A
 | last2 = Nichterlein
 | year = 2012
 | publisher = Springer, Berlin, Heidelberg
 | doi = 10.1007/978-3-642-30870-3_29
 | series = Lecture Notes in Computer Science
 | isbn = 978-3-642-30869-7
 | citeseerx = 10.1.1.377.2077
 }}
* {{cite conference
 | last = Holzer
 | first = Markus
 |last2=Ruepp |first2=Oliver
  | title =  The Troubles of Interior Design–A Complexity Analysis of the Game Heyawake
 | booktitle = Proceedings, 4th International Conference on Fun with Algorithms, [[LNCS]] 4475
 | publisher = Springer, Berlin/Heidelberg
 | year = 2007
 | isbn = 978-3-540-72913-6
 | pages = 198–212
 | doi = 10.1007/978-3-540-72914-3_18
|ref=harv
}}
*{{cite journal
| doi        = 10.1007/BF03025367
| last        = Kaye
| first       = Richard
| year        = 2000
| title       = Minesweeper is NP-complete
| journal     = Mathematical Intelligencer
| volume      = 22
| issue       = 2
| pages       = 9–15
| ref        = harv
}} Further information available online at [http://web.mat.bham.ac.uk/R.W.Kaye/minesw/ Richard Kaye's Minesweeper pages].
*{{Cite conference
 | last1 = Kashiwabara | first1 = T.
 | last2 = Fujisawa | first2 = T.
|title=NP-completeness of the problem of finding a minimum-clique-number interval graph containing a given graph as a subgraph
|book-title=Proceedings
 | pages = 657–660
 |conference=[[International Symposium on Circuits and Systems]]
 | year = 1979
 | ref = harv
}}
*{{Cite journal
 | last1 = Ohtsuki | first1 = Tatsuo
 | last2 = Mori | first2 = Hajimu
 | last3 = Kuh | first3 = Ernest S.
 | last4 = Kashiwabara | first4 = Toshinobu
 | last5 = Fujisawa | first5 = Toshio
 | doi = 10.1109/TCS.1979.1084695
 | issue = 9
 | journal = IEEE Transactions on Circuits and Systems
 | pages = 675–684
 | title = One-dimensional logic gate assignment and interval graphs
 | volume = 26
 | year = 1979
 | ref = harv
}}
*{{Cite journal
 | last = Lengauer | first = Thomas
 | doi = 10.1007/BF00264496
 | issue = 4
 | journal = [[Acta Informatica]]
 | pages = 465–475
 | title = Black-white pebbles and graph separation
 | volume = 16
 | year = 1981
 | ref = harv
}}
*{{Cite journal
 | last1 = Arnborg | first1 = Stefan
 | last2 = Corneil | first2 = Derek G. | author2-link = Derek Corneil
 | last3 = Proskurowski | first3 = Andrzej
 | doi = 10.1137/0608024
 | issue = 2
 | journal = SIAM Journal on Algebraic and Discrete Methods
 | pages = 277–284
 | title = Complexity of finding embeddings in a ''k''-tree
 | volume = 8
 | year = 1987
 | ref = harv
}}
* {{cite conference
 | last = Cormode
 | first = Graham
 | title =  The hardness of the lemmings game, or Oh no, more NP-completeness proofs
 | booktitle = Proceedings of Third International Conference on Fun with Algorithms (FUN 2004)
 | year = 2004
 | pages = 65–76
}}

== External links ==
* [http://www.nada.kth.se/~viggo/wwwcompendium/wwwcompendium.html A compendium of NP optimization problems]
* [https://adriann.github.io/npc/npc.html Graph of NP-complete Problems]

{{Use dmy dates|date=November 2010}}

{{DEFAULTSORT:List Of Np-Complete Problems}}
[[Category:Mathematics-related lists|Np-Complete Problems]]
[[Category:NP-complete problems|*]]</text>
      <sha1>17xp9nsxxsq4a0oroolzsxhi2tci7zz</sha1>
    </revision>
  </page>
  <page>
    <title>List of algebraic constructions</title>
    <ns>0</ns>
    <id>26994422</id>
    <revision>
      <id>864935564</id>
      <parentid>692570594</parentid>
      <timestamp>2018-10-20T15:30:18Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <minor/>
      <comment>/* top */minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1368">An '''algebraic construction''' is a method by which an [[algebra]]ic entity is defined or derived from another.

Instances include:
{{Expand list|date=February 2011}}
* [[Cayley–Dickson construction]]
* [[Proj construction]]
* [[Grothendieck group]]
* [[Gelfand–Naimark–Segal construction]]
* [[Ultraproduct]]
* [[ADHM construction]]
* [[Burnside ring]]
* [[Simplicial set]]
* [[Fox derivative]]
* [[Mapping cone (homological algebra)]]
* [[Prym variety]]
* [[Todd class]]
* [[Adjunction (field theory)]]
* [[Vaughan Jones construction]]
* [[Strähle construction]]
* [[Coset construction]]
* [[Plus construction]]
* [[Algebraic K-theory]]
* [[Gelfand–Naimark–Segal construction]]
* [[Stanley–Reisner ring]] construction
* [[Quotient ring#Formal quotient ring construction|Quotient ring construction]]
* [[Ward's twistor construction]]
* [[Hilbert symbol]]
* [[Hilbert's arithmetic of ends]]
* [[Colombeau algebra|Colombeau's construction]]
* [[Vector bundle]]
* [[Integral monoid ring]] construction
* [[Integral group ring]] construction
* Category of [[Eilenberg–Moore algebra]]s
* [[Kleisli category]]
* [[Adjunction (field theory)]]
* [[Lindenbaum–Tarski algebra]] construction
* [[Freudenthal magic square]]
* [[Stone–Čech compactification]]

{{DEFAULTSORT:Algebraic constructions}}
[[Category:Mathematics-related lists]]
[[Category:Algebra]]</text>
      <sha1>kxfecrcbb49hiiehe6mtiqbg0oubp7w</sha1>
    </revision>
  </page>
  <page>
    <title>Local zeta-function</title>
    <ns>0</ns>
    <id>396014</id>
    <revision>
      <id>865211466</id>
      <parentid>843019950</parentid>
      <timestamp>2018-10-22T13:54:40Z</timestamp>
      <contributor>
        <ip>2607:FEA8:59F:FB80:DC70:BE31:A8:EAF6</ip>
      </contributor>
      <comment>/* Formulation */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8372">In [[number theory]], the '''local zeta function''' &lt;math&gt;Z(V,s)&lt;/math&gt; (sometimes called the '''congruent zeta function''') is defined as

:&lt;math&gt;Z(V, s) = \exp\left(\sum_{m = 1}^\infty \frac{N_m}{m} (q^{-s})^m\right)&lt;/math&gt;

where &lt;math&gt;N_m&lt;/math&gt; is the number of points of &lt;math&gt;V&lt;/math&gt; defined over the degree &lt;math&gt;m&lt;/math&gt; extension{{explain|date=September 2017}} &lt;math&gt;\mathbf{F}_{q^m}&lt;/math&gt; of &lt;math&gt;\mathbf{F}_q&lt;/math&gt;, and &lt;math&gt;V&lt;/math&gt; is a [[non-singular]] &lt;math&gt;n&lt;/math&gt;-dimensional [[projective algebraic variety]] over the field &lt;math&gt;\mathbf{F}_q&lt;/math&gt; with &lt;math&gt;q&lt;/math&gt; elements. By the variable transformation &lt;math&gt;u=q^{-s}&lt;/math&gt;, then it is defined by

:&lt;math&gt;
\mathit{Z} (V,u) = \exp 
\left( \sum_{m=1}^{\infty} N_m \frac{u^m}{m} \right)
&lt;/math&gt;

as the [[formal power series]] of the variable &lt;math&gt;u&lt;/math&gt;.

Equivalently, the local zeta function sometimes is defined as follows: 
:&lt;math&gt;
(1)\ \ \mathit{Z} (V,0) = 1 \,
&lt;/math&gt;
:&lt;math&gt;
(2)\ \ \frac{d}{du} \log \mathit{Z} (V,u) = \sum_{m=1}^{\infty} N_m u^{m-1}\ .&lt;/math&gt;

In other word, the local zeta function &lt;math&gt;Z(V,u)&lt;/math&gt; with coefficients in the [[finite field]] &lt;math&gt;\mathbf{F}_q&lt;/math&gt; is defined as a function whose [[logarithmic derivative]] generates the numbers &lt;math&gt;N_m&lt;/math&gt; of the solutions of equation, defining &lt;math&gt;V&lt;/math&gt;, in the ''m'' degree extension &lt;math&gt;\mathbf{F}_{q^m}&lt;/math&gt;.

&lt;!--In [[number theory]], a '''local zeta-function'''

:&lt;math&gt;Z(-t)&lt;/math&gt;

is a function whose [[logarithmic derivative]] is a [[generating function]]
for the number of solutions of a set of equations defined over a [[finite field]] ''F'', in extension fields ''F&lt;sub&gt;k&lt;/sub&gt;'' of ''F''. --&gt;

==Formulation==

Given a finite field ''F'', there is, up to [[isomorphism]], just one field ''F&lt;sub&gt;k&lt;/sub&gt;'' with

:&lt;math&gt;[ F_k : F ] = k \,&lt;/math&gt;,

for ''k'' = 1, 2, ... . Given a set of polynomial equations &amp;mdash; or an [[algebraic variety]] ''V'' &amp;mdash; defined over ''F'', we can count the number

:&lt;math&gt;N_k \,&lt;/math&gt;

of solutions in ''F&lt;sub&gt;k&lt;/sub&gt;'' and create the generating function

:&lt;math&gt;G(t) = N_1t +N_2t^2/2 + N_3t^3/3 +\cdots \,&lt;/math&gt;.

The correct definition for ''Z''(''t'') is to make log ''Z'' equal to ''G'', and so

:&lt;math&gt;Z= \exp (G(t)) \, &lt;/math&gt;

we will have ''Z''(0) = 1 since ''G''(0) = 0, and ''Z''(''t'') is ''a priori'' a [[formal power series]].

Note that the [[logarithmic derivative]]

:&lt;math&gt;Z'(t)/Z(t) \,&lt;/math&gt;

equals the generating function

:&lt;math&gt;G'(t) = N_1 +N_2t^1 + N_3t^2 +\cdots \,&lt;/math&gt;.

==Examples==

For example, assume all the ''N&lt;sub&gt;k&lt;/sub&gt;'' are 1; this happens for example if we start with an equation like ''X'' = 0, so that geometrically we are taking ''V'' a point. Then

:&lt;math&gt;G(t) = -\log(1 - t)&lt;/math&gt;

is the expansion of a logarithm (for |''t''| &lt; 1). In this case we have

:&lt;math&gt;Z(t) = \frac{1}{(1 - t)}\ .&lt;/math&gt;

To take something more interesting, let ''V'' be the [[projective line]] over ''F''. If ''F'' has ''q'' elements, then this has ''q'' + 1 points, including as we must the one [[point at infinity]]. Therefore, we shall have

:&lt;math&gt;N_k = q^k + 1&lt;/math&gt;

and

:&lt;math&gt;G(t) = -\log(1 - t) -\log(1 - qt)&lt;/math&gt;

for |''t''| small enough.

In this case we have

:&lt;math&gt;Z(t) = \frac{1}{(1 - t)(1 - qt)}\ .&lt;/math&gt;

The first study of these functions was in the 1923 dissertation of [[Emil Artin]]. He obtained results for the case of [[hyperelliptic curve]], and conjectured the further main points of the theory as applied to curves. The theory was then developed by [[F. K. Schmidt]] and [[Helmut Hasse]].&lt;ref&gt;[[Daniel Bump]], ''Algebraic Geometry'' (1998), p. 195.&lt;/ref&gt; The earliest known non-trivial cases of local zeta-functions were implicit in [[Carl Friedrich Gauss]]'s ''[[Disquisitiones Arithmeticae]]'', article 358; there certain particular examples of [[elliptic curve]]s over finite fields having [[complex multiplication]] have their points counted by means of [[cyclotomy]].&lt;ref&gt;[[Barry Mazur]], ''Eigenvalues of Frobenius'', p. 244 in ''Algebraic Geometry, Arcata 1974: Proceedings American Mathematical Society'' (1974).&lt;/ref&gt;

For the definition and some examples, see also.&lt;ref&gt;[[Robin Hartshorne]], ''Algebraic Geometry'', p. 449 Springer 1977 APPENDIX C "The Weil Conjectures"&lt;/ref&gt;

==Motivations==

The relationship between the definitions of ''G'' and ''Z'' can be explained in a number of ways. (See for example the infinite product formula for ''Z'' below.) In practice it makes ''Z'' a [[rational function]] of ''t'', something that is interesting even in the case of ''V'' an [[elliptic curve]] over  finite field.

It is the functions ''Z'' that are designed to multiply, to get '''global zeta functions'''. Those involve different finite fields (for example the whole family of fields '''Z'''/''p'''''Z''' as ''p'' runs over all [[prime number]]s). In that connection, the variable ''t'' undergoes substitution by ''p&lt;sup&gt;−s&lt;/sup&gt;'', where ''s'' is the complex variable traditionally used in [[Dirichlet series]]. (For details see [[Hasse-Weil zeta function|Hasse-Weil zeta-function]].)

With that understanding, the products of the ''Z'' in the two cases used as examples come out as &lt;math&gt;\zeta(s)&lt;/math&gt; and &lt;math&gt;\zeta(s)\zeta(s-1)&lt;/math&gt;.

==Riemann hypothesis for curves over finite fields==

For projective curves ''C'' over ''F'' that are [[non-singular]], it can be shown that

:&lt;math&gt;Z(t) = \frac{P(t)}{(1 - t)(1 - qt)}\ ,&lt;/math&gt;

with ''P''(''t'') a polynomial, of degree 2''g'' where ''g'' is the [[genus (mathematics)|genus]] of ''C''. Rewriting

:&lt;math&gt;P(t)=\prod^{2g}_{i=1}(1-\omega_i t)\ ,&lt;/math&gt;

the '''Riemann hypothesis for curves over finite fields''' states

:&lt;math&gt;|\omega_i|=q^{1/2}\ .&lt;/math&gt;

For example, for the elliptic curve case there are two roots, and it is easy to show the absolute values of the roots are ''q''&lt;sup&gt;1/2&lt;/sup&gt;. [[Hasse's theorem on elliptic curves|Hasse's theorem]] is that they have the same absolute value; and this has immediate consequences for the number of points.

[[André Weil]] proved this for the general case, around 1940 (''Comptes Rendus'' note, April 1940): he spent much time in the years after that writing up the [[algebraic geometry]] involved. This led him to the general [[Weil conjectures]], [[Alexander Grothendieck]] developed the [[scheme (mathematics)|scheme]] theory for the sake of resolving it and finally, [[Pierre Deligne]] had proved a generation later. See [[étale cohomology]] for the basic formulae of the general theory.

==General formulas for the zeta function==

It is a consequence of the [[Lefschetz trace formula]] for the [[Frobenius morphism]] that

:&lt;math&gt;Z(X,t)=\prod_{i=0}^{2\dim X}\det\big(1-t \mbox{Frob}_q |H^i_c(\overline{X},{\Bbb Q}_\ell)\big)^{(-1)^{i+1}}.&lt;/math&gt;

Here &lt;math&gt;X&lt;/math&gt; is a separated scheme of finite type over the finite field ''F'' with &lt;math&gt;q&lt;/math&gt; elements, and Frob&lt;sub&gt;q&lt;/sub&gt; is the geometric Frobenius acting on &lt;math&gt;\ell&lt;/math&gt;-adic étale cohomology with compact supports of &lt;math&gt;\overline{X}&lt;/math&gt;, the lift of &lt;math&gt;X&lt;/math&gt; to the algebraic closure of the field ''F''.  This shows that the zeta function is a rational function of &lt;math&gt;t&lt;/math&gt;.

An infinite product formula for  &lt;math&gt;Z(X, t)&lt;/math&gt; is

:&lt;math&gt;Z(X, t)=\prod\ (1-t^{\deg(x)})^{-1}.&lt;/math&gt;

Here, the product ranges over all closed points ''x'' of ''X'' and deg(''x'') is the degree of ''x''.
The local zeta function ''Z(X, t)'' is viewed as a function of the complex variable ''s'' via the change of 
variables ''q&lt;sup&gt;−s&lt;/sup&gt;''.

In the case where ''X'' is the variety ''V'' discussed above, the closed points 
are the equivalence classes ''x=[P]'' of points ''P'' on &lt;math&gt;\overline{V}&lt;/math&gt;, where two points are equivalent if they are conjugates over ''F''.  The degree of ''x'' is the degree of the field extension of ''F''
generated by the coordinates of ''P''.  The logarithmic derivative of the infinite product ''Z(X, t)'' is easily seen to be the generating function discussed above, namely

:&lt;math&gt;N_1 +N_2t^1 + N_3t^2 +\cdots \,&lt;/math&gt;.

==See also==
*[[List of zeta functions]]
*[[Weil conjectures]]
*[[Elliptic curve]]

==References==
{{reflist}}

[[Category:Algebraic varieties]]
[[Category:Finite fields]]
[[Category:Diophantine geometry]]
[[Category:Zeta and L-functions]]
[[Category:Fixed points (mathematics)]]
[[Category:Bernhard Riemann]]</text>
      <sha1>4u5rdoe8j8qo9kgaiv5738fxtxp6lq4</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical object</title>
    <ns>0</ns>
    <id>19453961</id>
    <revision>
      <id>857207663</id>
      <parentid>857127094</parentid>
      <timestamp>2018-08-30T07:41:19Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/2607:FEA8:20DF:FA44:8C7F:2AE2:D065:71A0|2607:FEA8:20DF:FA44:8C7F:2AE2:D065:71A0]] ([[User talk:2607:FEA8:20DF:FA44:8C7F:2AE2:D065:71A0|talk]]) to last revision by D.Lazard. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7143">A '''mathematical object''' is an [[abstract object]] arising in [[mathematics]]. The concept is studied in [[philosophy of mathematics]].

In mathematical practice, an ''object'' is anything that has been (or could be) formally defined, and with which one may do [[deductive reasoning]] and [[mathematical proof]]s. Commonly encountered mathematical objects include [[number]]s, [[permutation]]s, [[Partition of a set|partitions]], [[matrix (mathematics)|matrices]], [[set (mathematics)|sets]], [[function (mathematics)|functions]], and [[relation (mathematics)|relations]].  [[Geometry]] as a branch of mathematics has such objects as [[hexagon]]s, [[point (geometry)|points]], [[line (geometry)|lines]], [[triangle]]s, [[circle]]s, [[sphere]]s, [[polyhedron|polyhedra]], [[topological space]]s and [[manifold]]s.  Another branch&amp;mdash;[[algebra]]&amp;mdash;has [[group (mathematics)|groups]], [[ring (mathematics)|rings]], [[field (mathematics)|fields]], [[lattice (group)|group-theoretic lattices]], and [[lattice (order)|order-theoretic lattices]].  [[Category (mathematics)|Categories]] are simultaneously homes to mathematical objects and mathematical objects in their own right. In [[proof theory]], proofs and [[theorem]]s are also mathematical objects.

The [[Ontology|ontological status]] of mathematical objects has been the subject of much investigation and debate by philosophers of mathematics.&lt;ref&gt;[[John P. Burgess|Burgess, John]], and Rosen, Gideon, 1997. ''A Subject with No Object: Strategies for Nominalistic Reconstrual of Mathematics''. [[Oxford University Press]]. {{isbn|0198236158}}&lt;/ref&gt;

==Cantorian framework==
One view that emerged around the turn of the 20th century with the work of [[Georg Cantor|Cantor]] is that all mathematical objects can be defined as [[Set (mathematics)|sets]].  The set {0,1} is a relatively clear-cut example.  On the face of it the [[group (mathematics)|group]] '''Z'''&lt;sub&gt;2&lt;/sub&gt; of integers mod 2 is also a set with two elements.  However, it cannot simply be the set {0,1}, because this does not mention the additional structure imputed to '''Z'''&lt;sub&gt;2&lt;/sub&gt; by the [[operation (mathematics)|operation]]s of [[addition]] and [[additive inverse|negation]] mod 2: how are we to tell which of 0 or 1 is the [[additive identity]], for example?  To organize this group as a set it can first be coded as the [[Tuple|quadruple]] ({0,1},+,&amp;minus;,0), which in turn can be coded using one of several conventions as a set representing that quadruple, which in turn entails encoding the operations + and &amp;minus; and the constant 0 as sets.

Sets may include ordered denotation of the particular identities and operations that apply to them, indicating a group, abelian group, ring, field, or other mathematical object. These types of mathematical objects are commonly studied in [[abstract algebra]].

==Foundational paradoxes==
If, however, the goal of mathematical ontology is taken to be the internal consistency of mathematics, it is more important that mathematical objects be definable in some uniform way (for example, as sets) regardless of actual practice, in order to lay bare the [[essence]] of its [[paradox]]es.  This has been the viewpoint taken by [[foundations of mathematics]], which has traditionally accorded the management of paradox higher priority than the faithful reflection of the details of mathematical practice as a justification for defining mathematical objects to be sets.

Much of the tension created by this foundational identification of mathematical objects with sets can be relieved without unduly compromising the goals of foundations by allowing two kinds of objects into the mathematical universe, sets and [[relation (mathematics)|relation]]s, without requiring that either be considered merely an instance of the other.  These form the basis of [[model theory]] as the [[domain of discourse]] of [[predicate logic]].  From this viewpoint, mathematical objects are entities satisfying the [[axiom]]s of a formal theory expressed in the language of predicate logic.

==Category theory==
A variant of this approach replaces relations with [[Operation (mathematics)|operations]], the basis of [[universal algebra]].  In this variant the axioms often take the form of [[equation]]s, or implications between equations.

A more abstract variant is [[category theory]], which abstracts sets as objects and the operations thereon as [[morphism]]s between those objects.  At this level of abstraction mathematical objects reduce to mere [[vertex (geometry)|vertices]] of a [[Graph (discrete mathematics)|graph]] whose [[edge (geometry)|edge]]s as the morphisms abstract the ways in which those objects can transform and whose structure is encoded in the [[Function composition|composition law]] for morphisms. [[Category (mathematics)|Categories]] may arise as the models of some axiomatic theory and the [[homomorphism]]s between them (in which case they are usually [[concrete category|concrete]], meaning equipped with a [[Full and faithful functors|faithful]] [[forgetful functor]] to the category '''[[category of sets|Set]]''' or more generally to a suitable [[topos]]), or they may be constructed from other more primitive categories, or they may be studied as abstract objects in their own right without regard for their [[provenance]].

==See also==
* [[Abstract object]]
* [[Mathematical structure]]

==References==
{{More footnotes|date=June 2009}}
&lt;references /&gt;
* Azzouni, J., 1994. ''Metaphysical Myths, Mathematical Practice''. Cambridge University Press.
* Burgess, John, and Rosen, Gideon, 1997. ''A Subject with No Object''. Oxford Univ. Press.
* [[Philip J. Davis|Davis, Philip]] and [[Reuben Hersh]], 1999 [1981]. ''The Mathematical Experience''. Mariner Books: 156-62.
* [[Bonnie Gold|Gold, Bonnie]], and Simons, Roger A., 2011. ''[https://books.google.com/books?id=wPhwJdjI-dIC&amp;printsec=frontcover#v=onepage&amp;q=%22mathematical%20object%22&amp;f=false Proof and Other Dilemmas: Mathematics and Philosophy]''. Mathematical Association of America.
* Hersh, Reuben, 1997. ''What is Mathematics, Really?''  Oxford University Press. 
* Sfard, A., 2000, "Symbolizing mathematical reality into being,  Or how mathematical discourse and mathematical objects create each other," in Cobb, P., ''et al.'', ''Symbolizing and communicating in mathematics classrooms:  Perspectives on discourse, tools and instructional design''. Lawrence Erlbaum. 
* [[Stewart Shapiro]], 2000. ''Thinking about mathematics: The philosophy of mathematics''.  Oxford University Press.

==External links==
*[[Stanford Encyclopedia of Philosophy]]: "[http://plato.stanford.edu/entries/abstract-objects Abstract Objects]"—by Gideon Rosen.
*Wells, Charles, "[https://web.archive.org/web/20081014205857/http://www.abstractmath.org/MM//MMMathObj.htm Mathematical Objects.]"
*[https://web.archive.org/web/20100717234001/http://theory.cs.uvic.ca/amof/ AMOF: The Amazing Mathematical Object Factory]
*[https://web.archive.org/web/20100611203942/http://www.math.cuhk.edu.hk/exhibit/ Mathematical Object Exhibit]

[[Category:Philosophy of mathematics]]
[[Category:Mathematical objects| ]]</text>
      <sha1>i07nl2vnrsmcjb3f7538uovlhj1po39</sha1>
    </revision>
  </page>
  <page>
    <title>Mian–Chowla sequence</title>
    <ns>0</ns>
    <id>8410911</id>
    <revision>
      <id>864442495</id>
      <parentid>838531699</parentid>
      <timestamp>2018-10-17T07:00:58Z</timestamp>
      <contributor>
        <ip>93.174.144.106</ip>
      </contributor>
      <comment>"The" replaced by "every" for more clarity.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1739">In [[mathematics]], the '''Mian–Chowla sequence''' is an [[integer sequence]] defined
[[recursion|recursively]] in the following way. The sequence starts with

:&lt;math&gt;a_1 = 1.&lt;/math&gt; 

Then for &lt;math&gt; n&gt;1&lt;/math&gt;, &lt;math&gt;a_n&lt;/math&gt; is the smallest integer such that every pairwise sum

:&lt;math&gt;a_i + a_j&lt;/math&gt; 

is distinct, for all &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; less than or equal to &lt;math&gt;n&lt;/math&gt;.

==Properties==
Initially, with &lt;math&gt;a_1&lt;/math&gt;, there is only one pairwise sum, 1 + 1 = 2. The next term in the sequence, &lt;math&gt;a_2&lt;/math&gt;, is 2 since the pairwise sums then are 2, 3 and 4, i.e., they are distinct.  Then, &lt;math&gt;a_3&lt;/math&gt; can't be 3 because there would be the non-distinct pairwise sums 1 + 3 = 2 + 2 = 4. We find then that &lt;math&gt;a_3 = 4&lt;/math&gt;, with the pairwise sums being 2, 3, 4, 5, 6 and 8. The sequence thus begins 
:[[1 (number)|1]], [[2 (number)|2]], [[4 (number)|4]], [[8 (number)|8]], [[13 (number)|13]], [[21 (number)|21]], [[31 (number)|31]], [[45 (number)|45]], [[66 (number)|66]], [[81 (number)|81]], [[97 (number)|97]], [[123 (number)|123]], [[148 (number)|148]], [[182 (number)|182]], [[204 (number)|204]], 252, [[290 (number)|290]], 361, 401, 475, ... {{OEIS|id=A005282}}. 

==Similar sequences==
If we define &lt;math&gt;a_1 = 0&lt;/math&gt;, the resulting sequence is the same except each term is one less (that is, 0, 1, 3, 7, 12, 20, 30, 44, 65, 80, 96, ... {{OEIS2C|id=A025582}}).

==History==
The sequence was invented by Abdul Majid Mian and [[Sarvadaman Chowla]].

==References==
* S. R. Finch, ''Mathematical Constants'', Cambridge (2003): Section 2.20.2
* R. K. Guy ''Unsolved Problems in Number Theory'', New York: Springer (2003)

{{DEFAULTSORT:Mian-Chowla sequence}}
[[Category:Integer sequences]]</text>
      <sha1>n8y0b95ywzf90lkqkehjw76xi9epba3</sha1>
    </revision>
  </page>
  <page>
    <title>Model transformation</title>
    <ns>0</ns>
    <id>4716117</id>
    <revision>
      <id>794150849</id>
      <parentid>787289417</parentid>
      <timestamp>2017-08-06T05:07:24Z</timestamp>
      <contributor>
        <ip>86.183.238.228</ip>
      </contributor>
      <comment>/* References */  improve one ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7533">A '''model transformation''', in [[model-driven engineering]], is an automated way of modifying and creating models. An example use of model transformation is ensuring that a family of [[Computer model|model]]s is consistent, in a precise sense which the software engineer can define. The aim of using a model transformation is to save effort and reduce errors by automating the building and modification of models where possible.

== Overview ==
Model transformations can be thought of as programs that take models as input. There is a wide variety of kinds of model transformation and uses of them, which differ in their inputs and outputs and also in the way they are expressed.

A model transformation usually specifies which models are acceptable as input, and if appropriate what models it may produce as output, by specifying the [[Metamodeling|metamodel]] to which a model must conform.

== Classification of model transformations ==

Model transformations and languages for them have been classified in many ways.&lt;ref name="CzarneckiHelsen"/&gt;&lt;ref name="Stevens-landscape"/&gt;&lt;ref name="Jakumeit"/&gt;
Some of the more common distinctions drawn are:

=== Number and type of inputs and outputs ===

In principle a model transformation may have many inputs and outputs of various types; the only absolute limitation is that a model transformation will take at least one model as input. However, a model transformation that did not produce any model as output would more commonly be called a model analysis or model query.

=== Endogenous versus exogenous ===

Endogenous transformations are transformations between models expressed in the same language. Exogenous transformations are transformations between models expressed using different languages.&lt;ref&gt;Tom Mens, Pieter Van Gorp: A Taxonomy of Model Transformation. Electr. Notes Theor. Comput. Sci. 152: 125-142 (2006)&lt;/ref&gt; For example, in a process conforming to the [[Object Management Group|OMG]] [[Model Driven Architecture]], a [[platform-independent model]] might be transformed into a [[platform-specific model]] by an exogenous model transformation.

=== Unidirectional versus bidirectional ===

A unidirectional model transformation has only one mode of execution: that is, it always takes the same type of input and produces the same type of output.  Unidirectional model transformations are useful in compilation-like situations, where any output model is read-only. The relevant notion of consistency is then very simple: the input model is consistent with the model that the transformation would produce as output, only.

For a bidirectional model transformation, the same type of model can sometimes be input and other times be output. [[Bidirectional transformation]]s are necessary in situations where people are working on more than one model and the models must be kept consistent. Then a change to either model might necessitate a change to the other, in order to maintain consistency between the models. Because each model can incorporate information which is not reflected in the other, there may be many models which are consistent with a given model. Important special cases are:

*bijective transformations, in which there is exactly one model which is consistent with any given model; that is, the consistency relation is bijective. A pair of models is consistent if and only if it is related by the consistency bijection. Both models contain the same information, but presented differently.
*view transformations, in which a concrete model determines a single view model, but the same view model might be produced from many different concrete models. The view model is an abstraction of the concrete model. If the view may be updated, a bidirectional transformation is needed. This situation is known in the database field as [[View (database)|view-update]]. Any concrete model is consistent with its view.

It is particularly important that a bidirectional model transformation has appropriate properties to make it behave sensibly: for example, not making changes unnecessarily, or discarding deliberately made changes.&lt;ref name="Stevens-properties"/&gt;

== Languages for model transformations ==

{{Main|Model transformation language}}

A model transformation may be written in a general purpose programming language, but specialised model transformation languages are also available. Bidirectional transformations, in particular, are best written in a language that ensures the directions are appropriately related. The [[Object Management Group|OMG]]-standardised model transformation languages are collectively known as [[QVT]].

In some model transformation languages, for example the [[QVT]] languages, a model transformation is itself a model, that is, it conforms to a metamodel which is part of the model transformation language's definition. This facilitates the definition of '''Higher Order Transformation'''s (HOTs),&lt;ref name="Tisi"/&gt; i.e. transformations which have other transformations as input and/or output.

==See also==
* [[Model-driven engineering]] (MDE)
* [[Model-driven architecture]] (MDA)
* [[Domain-specific language]] (DSL)
* [[Model transformation language]]
* [[Program refinement|Refinement]]
* [[Transformation (disambiguation)]]
* [[Program transformation]]
* [[Data transformation]]
* [[Graph transformation]]

== References ==
{{Reflist|refs=
&lt;ref name="CzarneckiHelsen"&gt;
{{Cite journal 
  | doi=10.1147/sj.453.0621
  | last1=Czarnecki 
  | last2=Helsen 
  | title=Feature-based survey of model transformation approaches
  | year=2006
  | journal=IBM Systems Journal}}
&lt;/ref&gt;

&lt;ref name="Stevens-landscape"&gt;
{{Cite journal
  | doi=10.1007/978-3-540-88643-3_10
  | last=Stevens 
  | first=Perdita 
  | title=A landscape of bidirectional model transformations 
  | work=Generative and Transformational Techniques in Software Engineering II
  | pages=408-424
  | publisher=[[Springer Publishing|Springer]] 
  | year=2008}}
&lt;/ref&gt;

&lt;ref name="Stevens-properties"&gt;
{{Cite journal 
  | doi=10.1007/s10270-008-0109-9
  | last=Stevens 
  | first=Perdita 
  | title=Bidirectional model transformations in QVT: semantic issues and open questions
  | publisher=[[Springer Publishing|Springer]] 
  | year=2010
  | journal=Software and Systems Modeling}}
&lt;/ref&gt;

&lt;ref name="Tisi"&gt;
{{Cite journal 
  | doi=10.1007/978-3-642-02674-4_3
  | last=Tisi
  | first=Massimo
  | title=On the Use of Higher-Order Model Transformations
  | publisher=[[Springer Publishing|Springer]] 
  | year=2009
  | series=LNCS
  | volume=5562
  | journal=ECMDA-FA '09}}
&lt;/ref&gt;

&lt;ref name="Jakumeit"&gt;
{{Cite journal 
  | doi=10.1016/j.scico.2013.10.009
  | last1=Jakumeit 
  | last2=Buchwald 
  | last3=Wagelaar
  | last4=Dan
  | last5=Hegedüs
  | last6=Herrmannsdörfer
  | last7=Horn
  | last8=Kalnina
  | last9=Lano
  | last10=Lepper
  | last11=Rensink
  | last12=Rose
  | last13=Wätzoldt
  | last14=Mazanek
  | title=A survey and comparison of transformation tools based on the transformation tool contest
  | publisher=[[Elsevier]] 
  | year=2014
  | journal=Science of Computer Programming}}
&lt;/ref&gt;
}}

==Further reading==
* ''Model Driven Software Engineering in Practice'', Marco Brambilla, Jordi Cabot, Manuel Wimmer, foreword by [[Richard Soley]] ([[Object Management Group|OMG]] Chairman), Morgan &amp; Claypool, USA, 2012, Synthesis Lectures on Software Engineering #1. 182 pages. {{ISBN|9781608458820}} (paperback), {{ISBN|9781608458837}} (ebook) http://www.mdse-book.com

[[Category:Systems engineering]]
[[Category:Unified Modeling Language]]</text>
      <sha1>a73dsnbqf3j5kymjp976v7m9tbe2ocv</sha1>
    </revision>
  </page>
  <page>
    <title>Multiple rule-based problems</title>
    <ns>0</ns>
    <id>5442846</id>
    <revision>
      <id>634313695</id>
      <parentid>634311350</parentid>
      <timestamp>2014-11-18T02:02:32Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Unreferenced}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1049">{{Orphan|date=February 2013}}
{{unreferenced|date=November 2014}}
'''Multiple rule-based problems''' are [[problem]]s containing various conflicting rules and restrictions.  Such problems typically have an "[[Optimization (mathematics)|optimal]]" solution, found by striking a balance between the various restrictions, without directly defying any of the aforementioned restrictions.

Solutions to such problems can either require complex, non-linear [[thought|thinking]] processes, or can instead require mathematics-based solutions in which an optimal solution is found by setting the various restrictions as equations, and finding an appropriate maximum value when all equations are added.  These problems may thus require more working information as compared to causal relationship [[problem solving]] or single rule-based problem solving.  The multiple rule-based problem solving is more likely to increase [[cognition|cognitive]] load than are the other two types of problem solving.

[[Category:Mathematical analysis]]


{{mathanalysis-stub}}</text>
      <sha1>tn57vyocxbel3jdre1qem9ulnvx5jel</sha1>
    </revision>
  </page>
  <page>
    <title>Nauruan navigational system</title>
    <ns>0</ns>
    <id>52947580</id>
    <revision>
      <id>800553662</id>
      <parentid>800553193</parentid>
      <timestamp>2017-09-14T07:31:38Z</timestamp>
      <contributor>
        <username>Cote d'Azur</username>
        <id>7314633</id>
      </contributor>
      <comment>ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="804">[[File:Nauruan-navigation-system.jpg|thumb|A map of Nauru describing the Nauruan navigational system]]

The '''Nauruan navigational system''' is a way of expressing direction, similar to [[North]], [[South]], [[East]] and [[West]], but limitations in the system mean that it is unable to be used outside of [[Nauru]].

The four main directions are pago, poe, pawa and pwiju (pwijiuw). Other directions include Gankoro and Arijeijen.&lt;ref&gt;[http://worldaustronesia.ntu.edu.tw/wp-content/uploads/2013/05/201201Lai.pdf "2012 年世界南島學術研究計畫 成果報告 海潮之律：諾魯鄰海社會之生產和飲食的 即興節奏"], 2012. (Taiwanese) (Archived)&lt;/ref&gt;

==References==
{{reflist}}

{{Nauru topics}}

[[Category:Geography of Nauru]]
[[Category:Orientation (geometry)]]


{{Nauru-stub}}</text>
      <sha1>4wx2f813gfsgtak9cs2y63l44bukhfd</sha1>
    </revision>
  </page>
  <page>
    <title>Paranormal space</title>
    <ns>0</ns>
    <id>5783978</id>
    <revision>
      <id>866735984</id>
      <parentid>840567525</parentid>
      <timestamp>2018-11-01T06:23:33Z</timestamp>
      <contributor>
        <ip>128.135.98.218</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1194">{{distinguish|text=[[paranormal|paranormal]] phenomena outside the range of normal experience}}
{{Orphan|date=September 2011}}

In [[mathematics]], in the realm of [[topology]], a '''paranormal space''' {{harv|Nyikos|1984}} is a [[topological space]] in which every [[countable set|countable]] discrete collection of [[closed set]]s has a [[locally finite collection|locally finite]] open expansion.

==See also==
* [[Normal space]] &amp;ndash; a topological space in which every two [[disjoint sets|disjoint]] closed sets have disjoint [[open neighborhood]]s
* [[Paracompact space]] &amp;ndash; a topological space in which every [[open cover]] admits an open locally finite [[refinement (topology)|refinement]]

==References==
*{{citation|last=Nyikos|title= Problem Section: Problem B. 25,|journal= Top. Proc. |volume=9 |year=1984}}
*{{Citation | last1=Smith | first1=Kerry D. | last2=Szeptycki | first2=Paul J. | title=Paranormal spaces under  ◊* | doi=10.1090/S0002-9939-99-05032-7 | mr=1622981 | year=2000 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=128 | issue=3 | pages=903–908}}

[[Category:Properties of topological spaces]]


{{topology-stub}}</text>
      <sha1>6tfauxje92p9pmo96c5mgoc34b5ynym</sha1>
    </revision>
  </page>
  <page>
    <title>Pascal's rule</title>
    <ns>0</ns>
    <id>2128500</id>
    <revision>
      <id>835422994</id>
      <parentid>798928766</parentid>
      <timestamp>2018-04-08T16:50:05Z</timestamp>
      <contributor>
        <username>Jumpow</username>
        <id>17534616</id>
      </contributor>
      <comment>Wrong reference to Russian article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3700">{{distinguish|Pascal's law}}
In [[mathematics]], '''Pascal's rule''' is a [[combinatorics|combinatorial]] [[identity (mathematics)|identity]] about [[binomial coefficient]]s. It states that for any [[natural number]] ''n'' we have

:&lt;math&gt;{n-1\choose k} + {n-1\choose k-1} = {n\choose k}\quad\text{for }1 \le k \le n &lt;/math&gt;

where &lt;math&gt;{n\choose k}&lt;/math&gt; is a binomial coefficient. This is also commonly written

:&lt;math&gt;
{n \choose k} + {n \choose k-1} = {n + 1 \choose k} \quad\text{for } 1 \le k \le n + 1
&lt;/math&gt;

==Combinatorial proof==
[[Blaise Pascal|Pascal's]] rule has an intuitive combinatorial meaning. Recall that  &lt;math&gt;{a\choose b}&lt;/math&gt; counts in how many ways can we pick a [[subset]] with ''b'' elements out from a set with ''a'' elements. Therefore, the right side of the identity  &lt;math&gt;{n\choose k}&lt;/math&gt; is counting how many ways can we get a ''k''-subset out from a set with ''n'' elements.

Now, suppose you distinguish a particular element 'X' from the set with ''n'' elements. Thus, every time you choose ''k'' elements to form a subset there are two possibilities: ''X'' belongs to the chosen subset or not.

If ''X'' is in the subset, you only really need to choose ''k''&amp;nbsp;&amp;minus;&amp;nbsp;1 more objects (since it is known that ''X'' will be in the subset) out from the remaining ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 objects. This can be accomplished in &lt;math&gt;n-1\choose k-1&lt;/math&gt; ways.

When ''X'' is not in the subset, you need to choose all the ''k'' elements in the subset from the ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 objects that are not ''X''. This can be done in  &lt;math&gt;n-1\choose k&lt;/math&gt; ways.

We conclude that the numbers of ways to get a ''k''-subset from the ''n''-set, which we know is  &lt;math&gt;{n\choose k}&lt;/math&gt;, is also the number
&lt;math&gt;{n-1\choose k-1} + {n-1\choose k}.&lt;/math&gt;

See also [[Bijective proof]].

==Algebraic proof==
We need to show
:&lt;math&gt; { n \choose k } + { n \choose k-1 } = { n+1 \choose k }.&lt;/math&gt; 	 


:&lt;math&gt;\begin{align}
{ n \choose k } + { n \choose k-1} &amp; = \frac{n!}{k! (n - k)!} + \frac{n!}{(k - 1)!(n  - k + 1)!} \\
&amp; = n! \left[ \frac{n -k + 1}{k!(n -k + 1)!} + \frac{k}{k!(n -k + 1)!}\right] \\
&amp; = \frac{n!(n+1)}{k!(n -k + 1)!} = \binom{n+1}{k}
\end{align}
&lt;/math&gt;

==Generalization==
Let &lt;math&gt;n, k_1, k_2, k_3,\dots ,k_p, p \in \mathbb{N}^* &lt;/math&gt; and &lt;math&gt;n=k_1+k_2+k_3+ \cdots +k_p &lt;/math&gt;. Then

: &lt;math&gt;
\begin{align}
&amp; {} \quad {n-1\choose k_1-1,k_2,k_3, \dots, k_p}+{n-1\choose k_1,k_2-1,k_3,\dots, k_p}+\cdots+{n-1\choose k_1,k_2,k_3,\dots,k_p-1} \\
&amp; = \frac{(n-1)!}{(k_1-1)!k_2!k_3! \cdots k_p!} + \frac{(n-1)!}{k_1!(k_2-1)!k_3!\cdots k_p!} + \cdots + \frac{(n-1)!}{k_1!k_2!k_3! \cdots (k_p-1)!} \\
&amp; = \frac{k_1(n-1)!}{k_1!k_2!k_3! \cdots k_p!} + \frac{k_2(n-1)!}{k_1!k_2!k_3! \cdots k_p!} + \cdots + \frac{k_p(n-1)!}{k_1!k_2!k_3! \cdots k_p!} = \frac{(k_1+k_2+\cdots+k_p) (n-1)!}{k_1!k_2!k_3!\cdots k_p!}  \\
&amp; = \frac{n(n-1)!}{k_1!k_2!k_3! \cdots k_p!} = \frac{n!}{k_1!k_2!k_3! \cdots k_p!}
= {n\choose k_1, k_2, k_3, \dots , k_p}.
\end{align}
&lt;/math&gt;

==See also==
* [[Pascal's triangle]]

==Sources==
*{{PlanetMath attribution|id=246|title=Pascal's rule}}
*{{PlanetMath attribution|id=259|title= Pascal's rule proof}}
*Merris, Russell. [http://media.wiley.com/product_data/excerpt/6X/04712629/047126296X.pdf''Combinatorics'']. John Wiley &amp; Sons. 2003 {{ISBN|978-0-471-26296-1}}

==External links==
* {{planetmath reference|id=5936|title=Central binomial coefficient}}
* {{planetmath reference|id=273|title=Binomial coefficient}}
* {{planetmath reference|id=4248|title=Pascal's triangle}}

{{DEFAULTSORT:Pascal's Rule}}
[[Category:Combinatorics]]
[[Category:Mathematical identities]]
[[Category:Articles containing proofs]]</text>
      <sha1>96xdrhxvyfcykm4ro22jztfp5bsvg8s</sha1>
    </revision>
  </page>
  <page>
    <title>Power center (geometry)</title>
    <ns>0</ns>
    <id>326298</id>
    <revision>
      <id>846577724</id>
      <parentid>840223394</parentid>
      <timestamp>2018-06-19T16:40:12Z</timestamp>
      <contributor>
        <username>Nihiltres</username>
        <id>236191</id>
      </contributor>
      <minor/>
      <comment>Simplified hatnote syntax</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4480">{{other uses|Power center (disambiguation)}}
[[File:Radical center.svg|thumb|right|250px|The radical center (orange point) is the center of the unique circle (also orange) that intersects three given circles at right angles.]]
In [[geometry]], the '''power center''' of three [[circle]]s, also called the '''radical center''',  is the intersection point of the three [[radical axis|radical axes]] of the pairs of circles.  If the radical center lies outside of all three circles, then it is the center of the unique circle (the '''radical circle''') that intersects the three given circles orthogonally; the construction of this orthogonal circle corresponds to '''Monge's problem'''.  This is a special case of the [[three conics theorem]].

The three radical axes meet in a single point, the radical center, for the following reason.  The radical axis of a pair of circles is defined as the set of points that have equal [[power of a point|power]] ''h'' with respect to both circles.  For example, for every point '''P''' on the radical axis of circles 1 and 2, the powers to each circle are equal, ''h''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''h''&lt;sub&gt;2&lt;/sub&gt;.  Similarly, for every point on the radical axis of circles 2 and 3, the powers must be equal, ''h''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''h''&lt;sub&gt;3&lt;/sub&gt;.  Therefore, at the intersection point of these two lines, all three powers must be equal, ''h''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''h''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''h''&lt;sub&gt;3&lt;/sub&gt;.  Since this implies that ''h''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''h''&lt;sub&gt;3&lt;/sub&gt;, this point must also lie on the radical axis of circles 1 and 3.  Hence, all three radical axes pass through the same point, the radical center.

The radical center has several applications in geometry. It has an important role in a solution to [[problem of Apollonius|Apollonius' problem]] published by [[Joseph Diaz Gergonne]] in 1814. In the [[power diagram]] of a system of circles, all of the vertices of the diagram are located at radical centers of triples of circles. The [[Spieker center]] of a [[triangle]] is the radical center of its [[excircles]].&lt;ref&gt;{{citation|title=Some triangle centers associated with the circles tangent to the excircles|journal=Forum Geometricorum|url=http://forumgeom.fau.edu/FG2010volume10/FG201006.pdf|volume=10|year=2010|pages=35–40|first=Boris|last=Odenhal}}&lt;/ref&gt;  Several types of radical circles have been defined as well, such as the radical circle of the [[Lucas circle]]s.

==Notes==
{{reflist}}

==Further reading==
* {{Cite book | author = Ogilvy CS |authorlink=C. Stanley Ogilvy| year = 1990 | title = Excursions in Geometry | publisher = Dover | isbn = 0-486-26530-7 | pages = 23 | postscript = &lt;!--None--&gt;}}
* {{cite book | title = Geometry Revisited | author = [[Harold Scott MacDonald Coxeter|Coxeter HSM]], [[S. L. Greitzer|Greitzer SL]]| year = 1967 | publisher = [[Mathematical Association of America|MAA]] | location = [[Washington, D.C.|Washington]] | isbn = 978-0-88385-619-2 | pages = 35, 38}}
* {{cite book | author = Johnson RA | year = 1960 | title = Advanced Euclidean Geometry: An elementary treatise on the geometry of the triangle and the circle | edition = reprint of 1929 edition by Houghton Miflin | publisher = Dover Publications | location = New York | isbn = 978-0-486-46237-0 | pages = 32&amp;ndash;34 }}
* {{cite book | author = Wells D | year = 1991 | title = The Penguin Dictionary of Curious and Interesting Geometry | publisher = Penguin Books | location = New York | isbn = 0-14-011813-6 | pages = 35}}
* {{cite book | author = Dörrie H | year = 1965 | chapter = Monge's Problem | title = 100 Great Problems of Elementary Mathematics: Their History and Solutions | publisher = Dover | location = New York | pages = 151–154 (§31)}}
* {{cite book | author = Lachlan R | year = 1893 | title = An elementary treatise on modern pure geometry | publisher = Macmillan | location = London | pages = 185 | asin = B0008CQ720}}

== External links ==

{{commons category|Radical axes|Radical centers and axes}}

*{{mathworld|urlname=RadicalCenter|title=Radical center}}
*{{mathworld|urlname=RadicalCircle|title=Radical circle}}
*{{mathworld|urlname=MongesProblem|title=Monge's problem}}
* [http://www.cut-the-knot.org/Curriculum/Geometry/RadicalCenter.shtml Radical Center] at [[Cut-the-Knot]]
* [http://www.cut-the-knot.org/Curriculum/Geometry/RadicalAxis.shtml Radical Axis and Center] at [[Cut-the-Knot]]

[[Category:Elementary geometry]]
[[Category:Geometric centers]]</text>
      <sha1>boepv7e7xnx3vq4nug0gq0a8gob69zb</sha1>
    </revision>
  </page>
  <page>
    <title>Propositional formula</title>
    <ns>0</ns>
    <id>1557634</id>
    <revision>
      <id>862607628</id>
      <parentid>856141073</parentid>
      <timestamp>2018-10-05T13:45:27Z</timestamp>
      <contributor>
        <ip>86.175.18.7</ip>
      </contributor>
      <comment>/* Parsing formulas */ "can be easily verified" (awkward position of the adverb) improved by replacing with "can be verified easily" (adverb follows verb(s))</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="141587">In [[propositional logic]], a '''propositional formula''' is a type of syntactic [[Formula (mathematical logic)|formula]] which is [[well formed formula|well formed]] and has a [[truth value]]. If the values of all variables in a propositional formula are given, it determines a unique truth value. A propositional formula may also be called a '''propositional expression''', a '''sentence''', or a '''sentential formula'''.

A propositional formula is constructed from simple [[Proposition (logic)|proposition]]s, such as "five is greater than three" or [[propositional variable]]s such as ''P'' and ''Q'', using connectives such as NOT, AND, OR, or IMPLIES; for example:

: (''P'' AND NOT ''Q'') IMPLIES (''P'' OR ''Q'').

In [[mathematics]], a propositional formula is often more briefly referred to as a "'''proposition'''", but, more precisely, a propositional formula is not a proposition but a [[formal expression]] that ''denotes'' a [[Proposition (mathematics)|proposition]], a [[formal object]] under discussion, just like an expression such as "{{nowrap|''x'' + ''y''}}" is not a value, but denotes a value. In some contexts, maintaining the distinction may be of importance.

==Propositions==
For the purposes of the propositional calculus, '''propositions''' (utterances, sentences, assertions) are considered to be either '''simple''' or '''compound'''.&lt;ref&gt;Hamilton 1978:1&lt;/ref&gt; Compound propositions are considered to be linked by '''sentential connectives''', some of the most common of which are "AND", "OR", "IF … THEN …", "NEITHER … NOR …", "… IS EQUIVALENT TO …" . The linking semicolon ";", and connective "BUT" are considered to be expressions of "AND". A sequence of discrete sentences are considered to be linked by "AND"s, and formal analysis applies a [[Recursion|recursive]] "parenthesis rule" with respect to sequences of simple propositions (see more [[#Well-formed formulas (wffs)|below]] about well-formed formulas).
: For example: The assertion: "This cow is blue. That horse is orange but this horse here is purple." is actually a compound proposition linked by "AND"s: ( ("This cow is blue" AND "that horse is orange") AND "this horse here is purple" ) .

Simple propositions are declarative in nature, that is, they make assertions about the condition or nature of a ''particular'' object of sensation e.g. "This cow is blue", "There's a coyote!" ("That coyote IS ''there'', behind the rocks.").&lt;ref&gt;PM{{clarify|reason=What is meant by 'PM'? I couldn't find a 'References' entry which would match this abbreviation.|date=October 2013}} p. 91 eschews "the" because they require a clear-cut "object of sensation"; they stipulate the use of "this"&lt;/ref&gt; Thus the simple "primitive" [[Logical assertion|assertion]]s must be about specific objects or specific states of mind. Each must have at least a '''subject''' (an immediate object of thought or observation), a verb (in the active voice and present tense preferred), and perhaps an adjective or adverb. "Dog!" probably implies "I see a dog" but should be rejected as too ambiguous.

: Example: "That purple dog is running", "This cow is blue", "Switch M31 is closed", "This cap is off", "Tomorrow is Friday".

For the purposes of the propositional calculus a compound proposition can usually be reworded into a series of simple sentences, although the result will probably sound stilted.

=== Relationship between propositional and predicate formulas ===
The [[predicate calculus]] goes a step further than the propositional calculus to an "analysis of the ''inner structure'' of propositions"&lt;ref&gt;(italics added) Reichenbach{{clarify|reason=There is no 'Reichenbach' entry under 'References', not even a link to an article about Reichenbach.|date=October 2013}} p.80.&lt;/ref&gt; It breaks a simple sentence down into two parts (i) its '''subject''' (the object (singular or plural) of discourse) and (ii) a [[Predicate (grammar)|predicate]] (a verb or possibly verb-clause that asserts a quality or attribute of the object(s)). The predicate calculus then generalizes the "subject|predicate" form (where | symbolizes [[concatenation]] (stringing together) of symbols) into a form with the following blank-subject structure " ___|predicate", and the predicate in turn generalized to all things with that property.

: Example: "This blue pig has wings" becomes two sentences in the ''propositional calculus'': "This pig has wings" AND "This pig is blue", whose internal structure is not considered. In contrast, in the predicate calculus, the first sentence breaks into "this pig" as the subject, and "has wings" as the predicate. Thus it asserts that object "this pig" is a member of the class (set, collection) of "winged things". The second sentence asserts that object "this pig" has an attribute "blue" and thus is a member of the class of "blue things". One might choose to write the two sentences connected with AND as:
:: p|W AND p|B

The generalization of "this pig" to a (potential) member of two classes "winged things" and "blue things" means that it has a truth-relationship with both of these classes. In other words, given a '''domain of discourse''' "winged things", either we find p to be a member of this domain or not. Thus we have a relationship W (wingedness) between p (pig) and { T, F }, W(p) evaluates to { T, F } where { T, F } is the set of the [[Boolean data type|boolean values]] "true" and "false". Likewise for B (blueness) and p (pig) and { T, F }: B(p) evaluates to { T, F }. So we now can analyze the connected assertions "B(p) AND W(p)" for its overall truth-value, i.e.:
: ( B(p) AND W(p) ) evaluates to { T, F }

In particular, simple sentences that employ notions of "all", "some", "a few", "one of", etc. are treated by the predicate calculus. Along with the new function symbolism "F(x)" two new symbols are introduced: ∀ (For all), and ∃ (There exists …, At least one of … exists, etc.). The predicate calculus, but not the propositional calculus, can establish the formal validity of the following statement:
: "All blue pigs have wings but some pigs have no wings, hence some pigs are not blue".

=== Identity ===
Tarski asserts that the notion of IDENTITY (as distinguished from LOGICAL EQUIVALENCE) lies outside the propositional calculus; however, he notes that if a logic is to be of use for mathematics and the sciences it must contain a "theory" of IDENTITY.&lt;ref&gt;Tarski p.54-68. Suppes calls IDENTITY a "further rule of inference" and has a brief development around it; Robbin, Bender and Williamson, and Goodstein introduce the sign and its usage without comment or explanation. Hamilton p. 37 employs two signs ≠ and = with respect to the '''valuation''' of a formula in a formal calculus. Kleene p. 70 and Hamilton p. 52 place it in the predicate calculus, in particular with regards to the arithmetic of natural numbers.&lt;/ref&gt; Some authors refer to "predicate logic with identity" to emphasize this extension. See more about this below.

==An algebra of propositions, the propositional calculus==
An '''algebra''' (and there are many different ones), loosely defined, is a method by which a collection of '''symbols''' called '''variables''' together with some other symbols such as parentheses (, ) and some sub-set of symbols such as *, +, ~, &amp;, &amp;or;, =, ≡, &amp;and;, ￢ are manipulated within a '''system''' of rules. These symbols, and '''well-formed''' strings of them, are said to represent '''objects''', but in a specific algebraic system these objects do not have '''meanings'''. Thus work inside the algebra becomes an exercise in obeying certain '''laws''' ('''rules''') of the algebra's [[syntax]] (symbol-formation) rather than in [[semantics]] (meaning) of the symbols. The meanings are to be found outside the algebra.

For a well-formed sequence of symbols in the algebra —a '''formula'''— to have some usefulness outside the algebra the symbols are assigned meanings and eventually the variables are assigned '''values'''; then by a series of rules the formula is '''evaluated'''.

When the values are restricted to just two and applied to the notion of '''simple sentences''' (e.g. spoken utterances or written assertions) linked by '''propositional connectives''' this whole algebraic system of symbols and rules and evaluation-methods is usually called the [[propositional calculus]] or the sentential calculus.

While some of the familiar rules of arithmetic algebra continue to hold in the algebra of propositions (e.g. the commutative and associative laws for AND and OR), some do not (e.g. the distributive laws for AND, OR and NOT).

=== Usefulness of propositional formulas ===
'''Analysis''': In [[deductive reasoning]], philosophers, rhetoricians and mathematicians reduce arguments to formulas and then study them (usually with [[truth table]]s) for correctness (soundness). For example: Is the following argument sound?
: "Given that consciousness is sufficient for an [[artificial intelligence]] and only conscious entities can pass the [[Turing test]], before we can conclude that a robot is an artificial intelligence the robot must pass the Turing test."

Engineers analyze the [[logic circuits]] they have designed using synthesis techniques and then apply various reduction and minimization techniques to simplify their designs.

'''Synthesis''': Engineers in particular synthesize propositional formulas (that eventually end up as '''circuits''' of symbols) from [[truth table]]s. For example, one might write down a truth table for how [[binary addition]] should behave given the addition of variables "b" and "a" and "carry_in" "ci", and the results "carry_out" "co" and "sum" Σ:
* Example: in row 5, ( (b+a) + ci ) = ( (1+0) + 1 ) = the number "2". written as a binary number this is 10&lt;sub&gt;2&lt;/sub&gt;, where "co"=1 and Σ=0 as shown in the right-most columns.
{| class="wikitable" style="text-align:center; margin-left: auto; margin-right: auto; border: none;"
|-
! row
! b !! a !! ci !! !! (b+a)+ci !! co !! Σ
|-
! 0
| 0 || 0 || 0 || || 0 || 0 || 0
|-
! 1
| 0 || 0 || 1 || || 1 || 0 || 1
|-
! 2
| 0 || 1 || 0 || || 1 || 0 || 1
|-
! 3
| 0 || 1 || 1 || || 2 || 1 || 0
|-
! 4
| 1 || 0 || 0 || || 1 || 0 || 1
|-
! 5
| 1 || 0 || 1 || || 2 || 1 || 0
|-
! 6
| 1 || 1 || 0 || || 2 || 1 || 0
|-
! 7
| 1 || 1 || 1 || || 3 || 1 || 1
|}

=== Propositional variables ===
The simplest type of propositional formula is a '''[[propositional variable]]'''. Propositions that are simple ([[atomic formula|atomic]]), symbolic expressions are often denoted by variables named ''a'', ''b'', or ''A'', ''B'', etc. A propositional variable is intended to represent an atomic proposition (assertion), such as "It is Saturday" = ''a'' (here the symbol = means " … is assigned the variable named …") or "I only go to the movies on Monday" = ''b''.

=== Truth-value assignments, formula evaluations ===
'''Evaluation''' of a propositional formula begins with assignment of a '''truth value''' to each variable. Because each variable represents a simple sentence, the truth values are being applied to the "truth" or "falsity" of these simple sentences.

'''Truth values in rhetoric, philosophy and mathematics''': The truth values are only two: { TRUTH "T",  FALSITY "F" }. An [[empiricist]] puts all propositions into two broad classes: ''analytic''—true no matter what (e.g. [[tautology (logic)|tautology]]), and ''synthetic''—derived from experience and thereby susceptible to confirmation by third parties (the [[verification theory]] of meaning).&lt;ref&gt;Empiricits eschew the notion of ''a priori'' (built-in, born-with) knowledge. "Radical reductionists" such as [[John Locke]] and [[David Hume]] "held that every idea must either originate directly in sense experience or else be compounded of ideas thus originating"; quoted from Quine reprinted in 1996 ''The Emergence of Logical Empriricism'', Garland Publishing Inc. http://www.marxists.org/reference/subject/philosophy/works/us/quine.htm&lt;/ref&gt; Empiricits hold that, in general, to arrive at the truth-value of a [[synthetic proposition]], meanings (pattern-matching templates) must first be applied to the words, and then these meaning-templates must be matched against whatever it is that is being asserted. For example, my utterance "That cow is ''{{blue|blue}}''!" Is this statement a TRUTH? Truly I said it. And maybe I ''am'' seeing a blue cow—unless I am lying my statement is a TRUTH relative to the object of my (perhaps flawed) perception. But is the blue cow "really there"? What do you see when you look out the same window? In order to proceed with a verification, you will need a prior notion (a template) of both "cow" and "{{blue|blue}}", and an ability to match the templates against the object of sensation (if indeed there is one).{{cn|date=October 2016}}

'''Truth values in engineering''': Engineers try to avoid notions of truth and falsity that bedevil philosophers, but in the final analysis engineers must trust their measuring instruments. In their quest for [[Robust statistics|robustness]], engineers prefer to pull known objects from a small library—objects that have well-defined, predictable behaviors even in large combinations, (hence their name for the propositional calculus: "combinatorial logic"). The fewest behaviors of a single object are two (e.g. { OFF, ON }, { open, shut }, { UP, DOWN } etc.), and these are put in correspondence with { 0, 1 }. Such elements are called [[Digital data|digital]]; those with a continuous range of behaviors are called [[analog signal|analog]]. Whenever decisions must be made in an analog system, quite often an engineer will convert an analog behavior (the door is 45.32146% UP) to digital (e.g. DOWN=0 ) by use of a [[comparator]].&lt;ref&gt;[[Neural net]] modelling offers a good mathematical model for a comparator as follows: Given a signal S and a threshold "thr", subtract "thr" from S and substitute this difference d to a [[sigmoid function]]: For large "gains" k, e.g. k=100, 1/( 1 + e&lt;sup&gt;−k*d&lt;/sup&gt; ) = 1/( 1 + e&lt;sup&gt;−k*(S-thr)&lt;/sup&gt; ) = { ≃0, ≃1 }.{{clarify|What is the meaning of the curly braces here? Denoting set comprehension wouldn't make sense.|date=October 2016}} For example, if "The door is DOWN" means "The door is less than 50% of the way up", then a threshold thr=0.5 corresponding to 0.5*5.0 = +2.50 volts could be applied to a "linear" measuring-device with an output of 0 volts when fully closed and +5.0 volts when fully open.&lt;/ref&gt;

Thus an assignment of '''meaning''' of the variables and the two value-symbols { 0, 1 } comes from "outside" the formula that represents the behavior of the (usually) compound object. An example is a garage door with two "limit switches", one for UP labelled SW_U and one for DOWN labelled SW_D, and whatever else is in the door's circuitry. Inspection of the circuit (either the diagram or the actual objects themselves—door, switches, wires, circuit board, etc.) might reveal that, on the circuit board "node 22" goes to +0 volts when the contacts of switch "SW_D" are mechanically in contact ("closed") and the door is in the "down" position (95% down), and "node 29" goes to +0 volts when the door is 95% UP and the contacts of switch SW_U are in mechanical contact ("closed").&lt;ref&gt;In actuality the digital 1 and 0 are defined over non-overlapping ranges e.g. { "1" = +5/+0.2/−1.0 volts, 0 = +0.5/−0.2 volts }{{clarify|Explain the meaning of curly braces and slash here.|date=October 2016}}. When a value falls outside the defined range(s) the value becomes "u" -- unknown; e.g. +2.3 would be "u".&lt;/ref&gt; The engineer must define the meanings of these voltages and all possible combinations (all 4 of them), including the "bad" ones (e.g. both nodes 22 and 29 at 0 volts, meaning that the door is open and closed at the same time). The circuit mindlessly responds to whatever voltages it experiences without any awareness of TRUTH or FALSEHOOD, RIGHT or WRONG, SAFE or DANGEROUS.{{cn|date=October 2016}}

== Propositional connectives ==

Arbitrary propositional formulas are built from propositional variables and other propositional formulas using [[logical connective|propositional connective]]s. Examples of connectives include:
* The unary negation connective. If &lt;math&gt;\alpha&lt;/math&gt; is a formula, then &lt;math&gt;\lnot \alpha&lt;/math&gt; is a formula.
* The classical binary connectives &lt;math&gt;\land, \lor, \to, \leftrightarrow&lt;/math&gt;. Thus, for example, if &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; are formulas, so is &lt;math&gt;(\alpha \to \beta)&lt;/math&gt;.
* Other binary connectives, such as NAND, NOR, and XOR
* The ternary connective IF … THEN … ELSE …
* Constant 0-ary connectives ⊤ and ⊥ (alternately, constants { T, F }, { 1, 0 } etc. )
* The "theory-extension" connective EQUALS (alternately, IDENTITY, or the sign " = " as distinguished from the "logical connective" &lt;math&gt;\leftrightarrow&lt;/math&gt;)

=== Connectives of rhetoric, philosophy and mathematics ===
The following are the connectives common to rhetoric, philosophy and mathematics together with their [[truth table]]s. The symbols used will vary from author to author and between fields of endeavor. In general the abbreviations "T" and "F" stand for the evaluations TRUTH and FALSITY applied to the variables in the propositional formula (e.g. the assertion: "That cow is blue" will have the truth-value "T" for Truth or "F" for Falsity, as the case may be.).

The connectives go by a number of different word-usages, e.g. "a IMPLIES b" is also said "IF a THEN b". Some of these are shown in the table.

{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
| width="48" Height="12" | 
| width="43.5" | 
| width="45" | 
| width="42" | 
| width="60" | 
| width="57.75" | 
|style="background-color:#E5E0EC" width="114.75" | b only if a
| width="187.5" | 
| width="93" | 
| width="87.75" | 
| width="48" | 
| width="63" | 
|- style="font-size:9pt" align="center"
| Height="12" | 
| 
| 
| 
| 
| 
|style="background-color:#E5E0EC" | b IS SUFFICIENT FOR a
|style="background-color:#F2F2F2" | b PRECISELY WHEN a
| 
| 
| 
| 
|- style="font-size:9pt" align="center"
| Height="12" | 
| 
| 
| 
| 
| 
|style="background-color:#E5E0EC" | a IS NECESSARY FOR b
|style="background-color:#F2F2F2" | b IF AND ONLY IF a;  b IFF a
| 
| 
| 
| 
|- style="font-size:9pt" align="center"
| Height="12" | 
| 
| 
| 
| 
|style="background-color:#FDE9D9" | inclusive OR
|style="background-color:#E5E0EC" | IF b THEN a
|style="background-color:#F2F2F2" | b IS NECESSARY AND SUFFICIENT FOR a
| 
| 
| 
| 
|- style="font-size:9pt" align="center"
| Height="12" | 
| 
|style="background-color:#EAF1DD" | negation
|style="background-color:#EAF1DD" | negation
|style="background-color:#DBE5F1" | conjunction
|style="background-color:#FDE9D9" | disjunction
|style="background-color:#E5E0EC" | implication
|style="background-color:#F2F2F2" | biconditional
| 
| 
| 
| 
|- style="font-size:9pt" align="center"
! Height="12" colspan="2" | variables
|style="background-color:#EAF1DD" | NOT b
|style="background-color:#EAF1DD" | NOT a
|style="background-color:#DBE5F1" | b AND a
|style="background-color:#FDE9D9" | b OR a
|style="background-color:#E5E0EC" | b IMPLIES a
|style="background-color:#F2F2F2" | b IS [[Logical equivalence|logically equivalent]] TO a ***
| f IS A tautology
| NEITHER a NOR b
| b stroke a
| exclusive OR
|- style="font-size:9pt" align="center"
|style="font-weight:bold" Height="12" | b
|style="font-weight:bold" | a
|style="background-color:#EAF1DD;font-weight:bold" | &amp;not;(b)
|style="background-color:#EAF1DD;font-weight:bold" | &amp;not;(a)
|style="background-color:#DBE5F1;font-weight:bold" | (b &amp;and; a)
|style="background-color:#FDE9D9;font-weight:bold" | (b &amp;or; a)
|style="background-color:#E5E0EC;font-weight:bold" | (b &amp;rarr; a)
|style="background-color:#F2F2F2;font-weight:bold" | (b &amp;harr; a)
| (f = formula)
| (a NOR b)
|style="font-weight:bold" | (b|a)
|style="font-weight:bold" | various
|-  align="center"
| Height="12" | F
| F
|style="background-color:#EAF1DD" | T
|style="background-color:#EAF1DD" | T
|style="background-color:#DBE5F1" | F
|style="background-color:#FDE9D9" | F
|style="background-color:#E5E0EC;font-size:9pt" | T
|style="background-color:#F2F2F2;font-size:9pt" | T
|style="font-size:9pt" | T
|style="font-size:9pt" | T
| T
|style="font-size:9pt" | F
|-  align="center"
| Height="12" | F
|style="font-size:9pt" | T
|style="background-color:#EAF1DD" | T
|style="background-color:#EAF1DD;font-size:9pt" | F
|style="background-color:#DBE5F1" | F
|style="background-color:#FDE9D9;font-size:9pt" | T
|style="background-color:#E5E0EC;font-size:9pt" | T
|style="background-color:#F2F2F2;font-size:9pt" | F
|style="font-size:9pt" | T
|style="font-size:9pt" | F
| T
|style="font-size:9pt" | T
|-  align="center"
|style="font-size:9pt" Height="12" | T
| F
|style="background-color:#EAF1DD" | F
|style="background-color:#EAF1DD" | T
|style="background-color:#DBE5F1" | F
|style="background-color:#FDE9D9;font-size:9pt" | T
|style="background-color:#E5E0EC;font-size:9pt" | F
|style="background-color:#F2F2F2;font-size:9pt" | F
|style="font-size:9pt" | T
|style="font-size:9pt" | F
| T
|style="font-size:9pt" | T
|-  align="center"
|style="font-size:9pt" Height="12" | T
|style="font-size:9pt" | T
|style="background-color:#EAF1DD" | F
|style="background-color:#EAF1DD;font-size:9pt" | F
|style="background-color:#DBE5F1;font-size:9pt" | T
|style="background-color:#FDE9D9;font-size:9pt" | T
|style="background-color:#E5E0EC;font-size:9pt" | T
|style="background-color:#F2F2F2;font-size:9pt" | T
|style="font-size:9pt" | T
|style="font-size:9pt" | F
|style="font-size:9pt" | F
|style="font-size:9pt" | F
|}

=== Engineering connectives ===
[[File:Propositional formula connectives 1.png|313px|thumb|right| Engineering symbols have varied over the years, but these are commonplace. Sometimes they appear simply as boxes with symbols in them. "a" and "b" are called "the inputs" and "c" is called "the output". An output will typically "connect to" an input (unless it is the final connective); this accomplishes the mathematical notion of '''substitution'''.]]

In general, the engineering connectives are just the same as the mathematics connectives excepting they tend to evaluate with "1" = "T" and "0" = "F". This is done for the purposes of analysis/minimization and synthesis of formulas by use of the notion of ''minterms'' and [[Karnaugh map]]s (see below). Engineers also use the words '''logical product''' from [[Boole]]'s notion (a*a = a) and '''logical sum''' from [[William Stanley Jevons|Jevons]]' notion (a+a = a).&lt;ref&gt;While the notion of logical product is not so peculiar (e.g. 0*0=0, 0*1=0, 1*0=0, 1*1=1), the notion of (1+1=1 ''is'' peculiar; in fact (a "+" b) = (a + (b - a*b)) where "+" is the "logical sum" but + and - are the true arithmetic counterparts. Occasionally all four notions do appear in a formula: A AND B = 1/2*( A plus B minus ( A XOR B ) ] (cf p. 146 in John Wakerly 1978, ''Error Detecting Codes, Self-Checking Circuits and Applications, North-Holland, New York, {{isbn|0-444-00259-6}} pbk.)&lt;/ref&gt;

{|class="wikitable" style="text-align:center"
|- style="font-size:9pt" 
|  Height="12" | 
|  | 
|  | 
|  | 
|  | 
! rowspan="2"  | logical product
! rowspan="2"  | logical sum
|  | 
|  | 
!  | half-adder (no carry)
|- style="font-size:9pt" 
| Height="12" | 
| 
| 
| 
| 
| 
| 
! exclusive OR
|- style="font-size:9pt" 
! Height="12" | row number
! colspan="2" | variables
|style="background-color:#EAF1DD" | NOT
|style="background-color:#EAF1DD" | NOT
|style="background-color:#DBE5F1" | AND
|style="background-color:#FDE9D9" | OR
| NAND
| NOR
| XOR
|-  
|style="font-size:9pt" Height="12" | b*2&lt;sup&gt;1&lt;/sup&gt;+a*2&lt;sup&gt;0&lt;/sup&gt;
|style="font-size:9pt;font-weight:bold" | b
|style="font-size:9pt;font-weight:bold" | a
|style="background-color:#EAF1DD;font-size:9pt;font-weight:bold" | ~(b)
|style="background-color:#EAF1DD;font-size:9pt;font-weight:bold" | ~(a)
|style="background-color:#DBE5F1;font-size:9pt;font-weight:bold" | (b &amp; a)
|style="background-color:#FDE9D9;font-size:9pt;font-weight:bold" | (b &amp;or; a)
|style="font-size:9pt;font-weight:bold" | ~(b &amp; a)
|style="font-size:9pt;font-weight:bold" | ~(b &amp;or; a)
|style="font-size:14pt" | ⊕
|-  
|style="font-size:9pt" Height="12" | 0
| 0
| 0
|style="background-color:#EAF1DD" | 1
|style="background-color:#EAF1DD" | 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#FDE9D9" | 0
|style="font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="font-size:9pt" | 0
|-  
|style="font-size:9pt" Height="12" | 1
| 0
|style="font-size:9pt" | 1
|style="background-color:#EAF1DD" | 1
|style="background-color:#EAF1DD;font-size:9pt" | 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#FDE9D9;font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="font-size:9pt" | 0
|style="font-size:9pt" | 1
|-  
|style="font-size:9pt" Height="12" | 2
|style="font-size:9pt" | 1
| 0
|style="background-color:#EAF1DD" | 0
|style="background-color:#EAF1DD" | 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#FDE9D9;font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="font-size:9pt" | 0
|style="font-size:9pt" | 1
|-  
|style="font-size:9pt" Height="12" | 3
|style="font-size:9pt" | 1
|style="font-size:9pt" | 1
|style="background-color:#EAF1DD" | 0
|style="background-color:#EAF1DD" | 0
|style="background-color:#DBE5F1;font-size:9pt" | 1
|style="background-color:#FDE9D9;font-size:9pt" | 1
|style="font-size:9pt" | 0
|style="font-size:9pt" | 0
|style="font-size:9pt" | 0
|}

===  CASE connective: IF … THEN … ELSE … ===
The IF … THEN … ELSE … connective appears as the simplest form of CASE operator of [[recursion theory]] and [[computation theory]] and is the connective responsible for conditional goto's (jumps, branches). From this one connective all other connectives can be constructed (see more below). Although " IF c THEN b ELSE a " sounds like an implication it is, in its most reduced form, a '''switch''' that makes a decision and offers as outcome only one of two alternatives "a" or "b" (hence the name [[switch statement]] in the [[C (programming language)|C]] programming language).&lt;ref&gt;A careful look at its Karnaugh map shows that IF...THEN...ELSE can also be expressed, in a rather round-about way, in terms of two exclusive-ORs: ( (b AND (c XOR a)) OR (a AND (c XOR b)) ) = d.&lt;/ref&gt;

The following three propositions are equivalent (as indicated by the logical equivalence sign ≡ ):

# ( IF 'counter is zero' THEN 'go to instruction ''b'' ' ELSE 'go to instruction ''a'' ') ≡
# ( (c → b) &amp; (~c → a) ) ≡  ( ( IF 'counter is zero' THEN 'go to instruction ''b'' ' ) AND ( IF 'It is NOT the case that counter is zero' THEN 'go to instruction ''a'' ) "  ≡
# ( (c &amp; b) &amp;or; (~c &amp; a) ) ≡  " ( 'Counter is zero' AND 'go to instruction ''b'' ) OR ( 'It is NOT the case that 'counter is zero' AND 'go to instruction ''a'' ) "

Thus IF … THEN … ELSE—unlike implication—does not evaluate to an ambiguous "TRUTH" when the first proposition is false i.e. c = F in (c → b). For example, most people would reject the following compound proposition as a nonsensical ''non sequitur'' because the second sentence is ''not connected in meaning'' to the first.&lt;ref&gt;Robbin p. 3.&lt;/ref&gt;
: Example: The proposition " IF 'Winston Churchill was Chinese' THEN 'The sun rises in the east' " evaluates as a TRUTH given that 'Winston Church was Chinese' is a FALSEHOOD and 'The sun rises in the east' evaluates as a TRUTH.

In recognition of this problem, the sign → of formal implication in the propositional calculus is called [[material conditional|material implication]] to distinguish it from the everyday, intuitive implication.&lt;ref&gt;Rosenbloom p. 30 and p. 54ff discusses this problem of implication at some length. Most philosophers and mathematicians just accept the material definition as given above. But some do not, including the [[Intuitionism|intuitionists]]; they consider it a form of the law of excluded middle misapplied.&lt;/ref&gt;

The use of the IF … THEN … ELSE construction avoids controversy because it offers a completely deterministic choice between two stated alternatives; it offers two "objects" (the two alternatives b and a), and it ''selects'' between them exhaustively and unambiguously.&lt;ref&gt;Indeed, exhaustive selection between alternatives -- '''mutual exclusion''' -- is required by the definition that Kleene gives the CASE operator (Kleene 1952229)&lt;/ref&gt; In the truth table below, d1 is the formula: ( (IF c THEN b) AND (IF NOT-c THEN a) ). Its fully reduced form d2 is the formula: ( (c AND b) OR (NOT-c AND a). The two formulas are equivalent as shown by the columns "=d1" and "=d2". Electrical engineers call the fully reduced formula the AND-OR-SELECT operator. The CASE (or SWITCH) operator is an extension of the same idea to ''n'' possible, but mutually exclusive outcomes. Electrical engineers call the CASE operator a [[multiplexer]].

{|
|- style="font-size:9pt" align="center"
| width="27.75" Height="12" | 
| width="20.25" | 
| width="18.75" | 
| width="18.75" | 
| width="6.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="16.5" | 
| width="12.75" | 
| width="12.75" | 
|style="background-color:#FDE9D9" width="17.25" | d1
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="18" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="24.75" | 
| width="5.25" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
|style="background-color:#FDE9D9" width="15.75" | d2
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="12.75" | 
| width="27" | 
|- style="font-size:9pt;font-weight:bold" align="center"
!style="background-color:#F2F2F2" Height="12" | row
! c
! b
! a
|style="background-color:#A5A5A5" | 
| (
| (
| c
| →
| b
| )
|style="background-color:#FDE9D9" | &amp;
| (
|style="background-color:#EAF1DD" | ~
| (
| c
| )
| →
| a
| )
| )
|style="background-color:#FDE9D9" |  =d1
|style="background-color:#A5A5A5" | 
| (
| (
| c
|style="background-color:#DBEEF3" | &amp;
| b
| )
|style="background-color:#FDE9D9" | &amp;or;
| (
|style="background-color:#EAF1DD" | ~
| (
| c
| )
|style="background-color:#DBE5F1" | &amp;
| a
| )
| )
|style="background-color:#FDE9D9" |  =d2
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 0
| 0
| 0
|style="background-color:#C5D9F1" | 0
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 1
| 0
| 
|style="background-color:#B8CCE4" | 0
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
| 
| 
|style="background-color:#B8CCE4" | 0
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 0
| 0
| 
|style="background-color:#B8CCE4" | 0
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
| 
| 
|style="background-color:#B8CCE4" | 0
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 1
| 0
| 0
|style="background-color:#C5D9F1" | 1
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 1
| 0
| 
|style="background-color:#B8CCE4" | 1
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
| 
| 
|style="background-color:#B8CCE4" | 1
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 0
| 0
| 
|style="background-color:#B8CCE4" | 1
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
| 
| 
|style="background-color:#B8CCE4" | 1
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 2
| 0
| 1
|style="background-color:#C5D9F1" | 0
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 1
| 1
| 
|style="background-color:#B8CCE4" | 0
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
| 
| 
|style="background-color:#B8CCE4" | 0
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 0
| 1
| 
|style="background-color:#B8CCE4" | 0
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 0
|style="background-color:#B8CCE4" | 0
| 
| 
|style="background-color:#B8CCE4" | 0
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 3
| 0
| 1
|style="background-color:#C5D9F1" | 1
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 1
| 1
| 
|style="background-color:#B8CCE4" | 1
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
| 
| 
|style="background-color:#B8CCE4" | 1
|style="background-color:#A5A5A5" | 
| 
| 
| 0
| 0
| 1
| 
|style="background-color:#B8CCE4" | 1
| 
| 1
| 
| 0
| 
|style="background-color:#B8CCE4" | 1
|style="background-color:#B8CCE4" | 1
| 
| 
|style="background-color:#B8CCE4" | 1
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 4
| 1
|style="background-color:#DBEEF3" | 0
| 0
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
| 
|style="background-color:#DBEEF3" | 0
| 
| 0
| 
| 1
| 
| 1
| 0
| 
| 
|style="background-color:#DBEEF3" | 0
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
| 
|style="background-color:#DBEEF3" | 0
| 
| 0
| 
| 1
| 
| 0
| 0
| 
| 
|style="background-color:#DBEEF3" | 0
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 5
| 1
|style="background-color:#DBEEF3" | 0
| 1
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
| 
|style="background-color:#DBEEF3" | 0
| 
| 0
| 
| 1
| 
| 1
| 1
| 
| 
|style="background-color:#DBEEF3" | 0
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 0
|style="background-color:#DBEEF3" | 0
| 
|style="background-color:#DBEEF3" | 0
| 
| 0
| 
| 1
| 
| 0
| 1
| 
| 
|style="background-color:#DBEEF3" | 0
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 6
| 1
|style="background-color:#DBEEF3" | 1
| 0
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
| 
|style="background-color:#DBEEF3" | 1
| 
| 0
| 
| 1
| 
| 1
| 0
| 
| 
|style="background-color:#DBEEF3" | 1
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
| 
|style="background-color:#DBEEF3" | 1
| 
| 0
| 
| 1
| 
| 0
| 0
| 
| 
|style="background-color:#DBEEF3" | 1
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 7
| 1
|style="background-color:#DBEEF3" | 1
| 1
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
| 
|style="background-color:#DBEEF3" | 1
| 
| 0
| 
| 1
| 
| 1
| 1
| 
| 
|style="background-color:#DBEEF3" | 1
|style="background-color:#A5A5A5" | 
| 
| 
| 1
|style="background-color:#DBEEF3" | 1
|style="background-color:#DBEEF3" | 1
| 
|style="background-color:#DBEEF3" | 1
| 
| 0
| 
| 1
| 
| 0
| 1
| 
| 
|style="background-color:#DBEEF3" | 1
|}

=== IDENTITY and evaluation ===

The first table of this section stars *** the entry logical equivalence to note the fact that "[[Logical equivalence]]" is not the same thing as "identity". For example, most would agree that the assertion "That cow is blue" is identical to the assertion "That cow is blue". On the other hand, ''logical'' equivalence sometimes appears in speech as in this example: " 'The sun is shining' means 'I'm biking' " Translated into a propositional formula the words become: "IF 'the sun is shining' THEN 'I'm biking', AND IF 'I'm biking' THEN 'the sun is shining'":&lt;ref&gt;The use of quote marks around the expressions is not accidental. Tarski comments on the use of quotes in his "18. Identity of things and identity of their designations; use of quotation marks" p. 58ff.&lt;/ref&gt;
: "IF 's' THEN 'b' AND IF 'b' THEN 's' " is written as ((s → b) &amp; (b → s)) or in an abbreviated form as (s ↔ b). As the rightmost symbol string is a '''definition''' for a new symbol in terms of the symbols on the left, the use of the IDENTITY sign = is appropriate:
:: ((s → b) &amp; (b → s)) = (s ↔ b)

Different authors use different signs for logical equivalence: ↔ (e.g. Suppes, Goodstein, Hamilton), ≡ (e.g. Robbin), ⇔ (e.g. Bender and Williamson). Typically identity is written as the equals sign =. One exception to this rule is found in ''Principia Mathematica''. For more about the philosophy of the notion of IDENTITY see [[Identity of indiscernibles|Leibniz's law]].

As noted above, Tarski considers IDENTITY to lie outside the propositional calculus, but he asserts that without the notion, "logic" is insufficient for mathematics and the deductive sciences. In fact the sign comes into the propositional calculus when a formula is to be evaluated.&lt;ref&gt;Hamilton p. 37. Bender and Williamson p. 29 state "In what follows, we'll replace "equals" with the symbol " ⇔ " (equivalence) which is usually used in logic. We use the more familiar " = " for assigning meaning and values."&lt;/ref&gt;

In some systems there are no truth tables, but rather just formal axioms (e.g. strings of symbols from a set { ~, →, (, ), variables p&lt;sub&gt;1&lt;/sub&gt;, p&lt;sub&gt;2&lt;/sub&gt;, p&lt;sub&gt;3&lt;/sub&gt;, … } and formula-formation rules (rules about how to make more symbol strings from previous strings by use of e.g. substitution and [[modus ponens]]). the result of such a calculus will be another formula (i.e. a well-formed symbol string). Eventually, however, if one wants to use the calculus to study notions of validity and truth, one must add axioms that define the behavior of the symbols called "the truth values" {T, F} ( or {1, 0}, etc.) relative to the other symbols.

For example, Hamilton uses two symbols = and ≠ when he defines the notion of a '''valuation v''' of any wffs ''A'' and ''B'' in his "formal statement calculus" L. A valuation '''v''' is a ''[[Function (mathematics)|function]]'' from the wffs of his system L to the range (output) { T, F }, given that each variable  p&lt;sub&gt;1&lt;/sub&gt;, p&lt;sub&gt;2&lt;/sub&gt;, p&lt;sub&gt;3&lt;/sub&gt; in a wff is assigned an arbitrary truth value { T, F }.
{{NumBlk|*|  '''v'''(''A'') ≠ '''v'''(~''A'')|{{EquationRef|i}}}}
{{NumBlk|*|  '''v'''(''A'' → ''B'') {{=}} F if and only if '''v'''(''A'') {{=}} T and '''v'''(''B'') {{=}} F|{{EquationRef|ii}}}}

The two definitions ({{EquationNote|i}}) and ({{EquationNote|ii}}) define the equivalent of the truth tables for the ~ (NOT) and → (IMPLICATION) connectives of his system. The first one derives F ≠ T and T ≠ F, in other words " '''v'''(''A'') does not '''mean''' '''v'''(~''A'')". Definition ({{EquationNote|ii}}) specifies the third row in the truth table, and the other three rows then come from an application of definition ({{EquationNote|i}}). In particular ({{EquationNote|ii}}) '''assigns''' the value F (or a meaning of "F") to the entire expression. The definitions also serve as formation rules that allow substitution of a value previously derived into a formula:
{|
|- style="font-size:9pt" align="center"
| width="8.25" Height="12" | 
| width="25.5" | 
|style="background-color:#E5E0EC" width="50" | v(A→B)
| width="29.25" | 
| width="6.75" | 
|- style="font-size:9pt" align="center"
| Height="12" | (
| v(A)
|style="background-color:#E5E0EC" |  →
| v(B)
| )
|- style="font-size:9pt" align="center"
| Height="12" | 
| F
|style="background-color:#E5E0EC" | T
| F
| 
|- style="font-size:9pt" align="center"
| Height="12" | 
| F
|style="background-color:#E5E0EC" | T
| T
| 
|- style="font-size:9pt" align="center"
| Height="12" | 
| T
|style="background-color:#CCC0DA" | F
| F
| 
|- style="font-size:9pt" align="center"
| Height="12" | 
| T
|style="background-color:#E5E0EC" | T
| T
| 
|}

Some [[formal system]]s specify these valuation axioms at the outset in the form of certain formulas such as the [[law of contradiction]] or laws of identity and nullity. The choice of which ones to use, together with laws such as commutation and distribution, is up to the system's designer as long as the set of axioms is '''complete''' (i.e. sufficient to form and to evaluate any well-formed formula created in the system).

== More complex formulas ==
As shown above, the CASE (IF c THEN b ELSE a ) connective is constructed either from the 2-argument connectives IF … THEN … and AND or from OR and AND and the 1-argument NOT. Connectives such as the n-argument AND (a &amp; b &amp; c &amp; … &amp; n), OR (a &amp;or; b &amp;or; c &amp;or; … &amp;or; n) are constructed from strings of two-argument AND and OR and written in abbreviated form without the parentheses. These, and other connectives as well, can then used as building blocks for yet further connectives. Rhetoricians, philosophers, and mathematicians use truth tables and the various theorems to analyze and simplify their formulas.

Electrical engineering uses drawn symbols and connect them with lines that stand for the mathematicals act of '''substitution''' and '''replacement'''. They then verify their drawings with truth tables and simplify the expressions as shown below by use of [[Karnaugh map]]s or the theorems. In this way engineers have created a host of "combinatorial logic" (i.e. connectives without feedback) such as "decoders", "encoders", "mutifunction gates", "majority logic", "binary adders", "arithmetic logic units", etc.

=== Definitions ===
A definition creates a new symbol and its behavior, often for the purposes of abbreviation. Once the definition is presented, either form of the equivalent symbol or formula can be used. The following symbolism =&lt;sub&gt;Df&lt;/sub&gt; is following the convention of Reichenbach.&lt;ref&gt;Reichenbach p. 20-22 and follows the conventions of PM. The symbol =&lt;sub&gt;Df&lt;/sub&gt; is in the [[metalanguage]] and is not a formal symbol with the following meaning: "by symbol ' s ' is to have the same meaning as the formula '(c &amp; d)' ".&lt;/ref&gt; Some examples of convenient definitions drawn from the symbol set { ~, &amp;, (, ) } and variables. Each definition is producing a logically equivalent formula that can be used for substitution or replacement.
:* definition of a new variable: (c &amp; d) =&lt;sub&gt;Df&lt;/sub&gt; s
:* OR: ~(~a &amp; ~b) =&lt;sub&gt;Df&lt;/sub&gt; (a &amp;or; b)
:* IMPLICATION: (~a &amp;or; b) =&lt;sub&gt;Df&lt;/sub&gt; (a → b)
:* XOR: (~a &amp; b) &amp;or; (a &amp; ~b) =&lt;sub&gt;Df&lt;/sub&gt; (a ⊕ b)
:* LOGICAL EQUIVALENCE: ( (a → b) &amp; (b → a) ) =&lt;sub&gt;Df&lt;/sub&gt; ( a ≡ b )

===Axiom and definition ''schemas''===
The definitions above for OR, IMPLICATION, XOR, and logical equivalence are actually [[axiom schema|schema]]s (or "schemata"), that is, they are ''models'' (demonstrations, examples) for a general formula ''format'' but shown (for illustrative purposes) with specific letters a, b, c for the variables, whereas any variable letters can go in their places as long as the letter substitutions follow the rule of substitution below.
: Example: In the definition (~a &amp;or; b) =&lt;sub&gt;Df&lt;/sub&gt; (a → b), other variable-symbols such as "SW2" and "CON1" might be used, i.e. formally:
:: a =&lt;sub&gt;Df&lt;/sub&gt; SW2, b =&lt;sub&gt;Df&lt;/sub&gt; CON1, so we would have as an ''instance'' of the definition schema (~SW2 &amp;or; CON1) =&lt;sub&gt;Df&lt;/sub&gt; (SW2 → CON1)

=== Substitution versus replacement ===
'''Substitution''': The variable or sub-formula to be substituted with another variable, constant, or sub-formula must be replaced in all instances throughout the overall formula.
: Example: (c &amp; d) &amp;or; (p &amp; ~(c &amp; ~d)), but  (q1 &amp; ~q2) ≡ d. Now wherever variable "d" occurs, substitute (q&lt;sub&gt;1&lt;/sub&gt; &amp; ~q&lt;sub&gt;2&lt;/sub&gt;):
:: (c &amp; (q&lt;sub&gt;1&lt;/sub&gt; &amp; ~q&lt;sub&gt;2&lt;/sub&gt;)) &amp;or; (p &amp; ~(c &amp; ~(q&lt;sub&gt;1&lt;/sub&gt; &amp; ~q&lt;sub&gt;2&lt;/sub&gt;)))

'''Replacement''': (i) the formula to be replaced must be within a tautology, i.e. ''logically equivalent'' ( connected by ≡ or ↔) to the formula that replaces it, and (ii) unlike substitution its permissible for the replacement to occur only in one place (i.e. for one formula).
: Example: Use this set of formula schemas/equivalences: 
:# ( (a &amp;or; 0) ≡ a ). 
:# ( (a &amp; ~a) ≡ 0 ). 
:# ( (~a &amp;or; b) =&lt;sub&gt;Df&lt;/sub&gt; (a → b) ). 
:# &lt;li value="6"&gt; ( ~(~a) ≡ a )&lt;/li&gt;
:{{ordered list|list-style-type=lower-alpha
| start with "a": a
| Use 1 to replace "a" with (a &amp;or; 0): (a &amp;or; 0)
| Use the notion of "schema" to substitute b for a in 2: ( (a &amp; ~a) ≡ 0 )
| Use 2 to replace 0 with (b &amp; ~b): ( a &amp;or; (b &amp; ~b) )
| (see below for how to distribute "a &amp;or;" over (b &amp; ~b), etc.)
}}

== Inductive definition ==

The classical presentation of propositional logic (see [[Herbert Enderton|Enderton]] 2002) uses the connectives &lt;math&gt;\lnot, \land, \lor, \to, \leftrightarrow&lt;/math&gt;. The set of formulas over a given set of propositional variables is [[inductive definition|inductively defined]] to be the smallest set of expressions such that:
* Each propositional variable in the set is a formula,
* &lt;math&gt;(\lnot \alpha)&lt;/math&gt; is a formula whenever &lt;math&gt;\alpha&lt;/math&gt; is, and
* &lt;math&gt; (\alpha\,\Box\,\beta)&lt;/math&gt; is a formula whenever &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; are formulas and &lt;math&gt;\Box&lt;/math&gt; is one of the binary connectives &lt;math&gt;\land, \lor, \to, \leftrightarrow&lt;/math&gt;.
This inductive definition can be easily extended to cover additional connectives.

The inductive definition can also be rephrased in terms of a [[closure (mathematics)|closure]] operation (Enderton 2002). Let ''V'' denote a set of propositional variables and let ''X&lt;sub&gt;V&lt;/sub&gt;'' denote the set of all strings from an alphabet including symbols in ''V'', left and right parentheses, and all the logical connectives under consideration. Each logical connective corresponds to a formula building operation, a function from ''XX&lt;sub&gt;V&lt;/sub&gt;'' to ''XX&lt;sub&gt;V&lt;/sub&gt;'':
* Given a string ''z'', the operation &lt;math&gt;\mathcal{E}_\lnot(z)&lt;/math&gt; returns &lt;math&gt;(\lnot z)&lt;/math&gt;.
* Given strings ''y'' and ''z'', the operation &lt;math&gt;\mathcal{E}_\land(y,z)&lt;/math&gt; returns &lt;math&gt;(y\land x)&lt;/math&gt;. There are similar operations &lt;math&gt;\mathcal{E}_\lor&lt;/math&gt;, &lt;math&gt;\mathcal{E}_\to&lt;/math&gt;, and &lt;math&gt;\mathcal{E}_\leftrightarrow&lt;/math&gt; corresponding to the other binary connectives.
The set of formulas over ''V'' is defined to be the smallest subset of ''XX&lt;sub&gt;V&lt;/sub&gt;'' containing ''V'' and closed under all the formula building operations.

== Parsing formulas ==
The following "laws" of the propositional calculus are used to "reduce" complex formulas. The "laws" can be verified easily with truth tables. For each law, the principal (outermost) connective is associated with logical equivalence ≡ or identity =. A complete analysis of all 2&lt;sup&gt;n&lt;/sup&gt; combinations of truth-values for its ''n'' distinct variables will result in a column of 1's (T's) underneath this connective. This finding makes each law, by definition, a tautology. And, for a given law, because its formula on the left and right are equivalent (or identical) they can be substituted for one another.
* Example: The following truth table is De Morgan's law for the behavior of NOT over OR: ~(a &amp;or; b) ≡ (~a &amp; ~b). To the left of the principal connective ≡ (yellow column labelled "taut") the formula ~(b &amp;or; a) evaluates to (1, 0, 0, 0) under the label "P". On the right of "taut" the formula (~(b) &amp;or; ~(a)) also evaluates to (1, 0, 0, 0) under the label "Q". As the two columns have equivalent evaluations, the logical equivalence ≡ under "taut" evaluates to (1, 1, 1, 1), i.e. P ≡ Q. Thus either formula can be substituted for the other if it appears in a larger formula.
{| style="margin-left: auto; margin-right: auto; border: none;"
|- style="font-size:9pt; text-align:center"
| width="18.75" Height="12" | 
| width="18.75" | 
| width="4.5" | 
| width="10.5" | 
|style="background-color:#D7E4BC" width="10.5" | P
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="11.25" | 
|style="background-color:#FFFF99" width="21.75" | taut
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="12" | 
|style="background-color:#DBE5F1" width="12.75" | Q
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
|- style="font-weight:bold" align="center"
|style="font-size:9pt" Height="15" | b
|style="font-size:9pt" | a
|style="background-color:#A5A5A5;font-size:9pt" | 
|style="font-size:9pt" | (
|style="background-color:#D7E4BC;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | b
|style="background-color:#FDE9D9;font-size:9pt" | V
|style="font-size:9pt" | a
|style="font-size:9pt" | )
|style="background-color:#FFFF99" | ≡
|style="font-size:9pt" | (
|style="background-color:#EAF1DD;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | b
|style="font-size:9pt" | )
|style="background-color:#DBE5F1;font-size:9pt" | &amp;
|style="background-color:#EAF1DD;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="font-size:9pt" | )
|style="font-size:9pt" | )
|style="font-size:9pt" | )
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 0
|style="background-color:#A5A5A5" | 
| 
|style="background-color:#D7E4BC" | 1
| 
| 0
|style="background-color:#FDE9D9" | 0
| 0
| 
|style="background-color:#FFFF99" | 1
| 
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 1
|style="background-color:#A5A5A5" | 
| 
|style="background-color:#D7E4BC" | 0
| 
| 0
|style="background-color:#FDE9D9" | 1
| 1
| 
|style="background-color:#FFFF99" | 1
| 
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
| 
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 0
|style="background-color:#A5A5A5" | 
| 
|style="background-color:#D7E4BC" | 0
| 
| 1
|style="background-color:#FDE9D9" | 1
| 0
| 
|style="background-color:#FFFF99" | 1
| 
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 1
|style="background-color:#A5A5A5" | 
| 
|style="background-color:#D7E4BC" | 0
| 
| 1
|style="background-color:#FDE9D9" | 1
| 1
| 
|style="background-color:#FFFF99" | 1
| 
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
| 
|}

Enterprising readers{{Who|date=December 2015}} might challenge themselves to invent an "axiomatic system" that uses the symbols { &amp;or;, &amp;, ~, (, ), variables a, b, c }, the formation rules specified above, and as few as possible of the laws listed below, and then derive as theorems the others as well as the truth-table valuations for &amp;or;, &amp;, and ~. One set attributed to Huntington (1904) (Suppes:204) uses eight of the laws defined below.

Note that if used in an axiomatic system, the symbols 1 and 0 (or T and F) are considered to be wffs and thus obey all the same rules as the variables. Thus the laws listed below are actually [[axiom schema]]s, that is, they stand in place of an infinite number of instances. Thus ( x &amp;or; y ) ≡ ( y &amp;or; x ) might be used in one instance, ( p &amp;or; 0 ) ≡ ( 0 &amp;or; p ) and in another instance ( 1 &amp;or; q ) ≡ ( q &amp;or; 1 ), etc.

=== Connective seniority (symbol rank) ===
In general, to avoid confusion during analysis and evaluation of propositional formulas make liberal use parentheses. However, quite often authors leave them out. To parse a complicated formula one first needs to know the '''seniority''', or '''rank''', that each of the connectives (excepting *) has over the other connectives. To "well-form" a formula, start with the connective with the highest rank and add parentheses around its components, then move down in rank (paying close attention to the connective's '''scope''' over which the it is working). From most- to least-senior, with the predicate signs ∀x and ∃x, the IDENTITY = and arithmetic signs added for completeness:&lt;ref&gt;Rosenbloom 1950:32. Kleene 1952:73-74 ranks all 11 symbols.&lt;/ref&gt;
:; ≡: (LOGICAL EQUIVALENCE)
:; →: (IMPLICATION)
:; &amp;: (AND)
:; &amp;or;: (OR)
:; ~: (NOT)
:; ∀x: (FOR ALL x)
:; ∃x: (THERE EXISTS AN x)
:; =: (IDENTITY)
:; +: (arithmetic sum)
:;&lt;nowiki&gt;*&lt;/nowiki&gt;: (arithmetic multiply)
:; ' : (s, arithmetic successor).

Thus the formula can be parsed—but note that, because NOT does not obey the distributive law, the parentheses around the inner formula (~c &amp; ~d) is mandatory:
: Example: " d &amp; c &amp;or; w " rewritten is ( (d &amp; c) &amp;or; w )
: Example: " a &amp; a → b ≡ a &amp; ~a &amp;or; b " rewritten (rigorously) is
::* ≡ has seniority: ( ( a &amp; a → b ) ≡ ( a &amp; ~a &amp;or; b ) )
::* → has seniority: ( ( a &amp; (a → b) ) ≡ ( a &amp; ~a &amp;or; b ) )
::* &amp; has seniority both sides: ( ( ( (a) &amp; (a → b) ) ) ≡ ( ( (a) &amp; (~a &amp;or; b) ) )
::* ~ has seniority: ( ( ( (a) &amp; (a → b) ) ) ≡ ( ( (a) &amp; (~(a) &amp;or; b) ) )
::* check 9 ( -parenthesis and 9 ) -parenthesis: ( ( ( (a) &amp; (a → b) ) ) ≡ ( ( (a) &amp; (~(a) &amp;or; b) ) )
: Example:
:: d &amp; c &amp;or; p &amp; ~(c &amp; ~d) ≡ c &amp; d &amp;or; p &amp; c &amp;or; p &amp; ~d rewritten is ( ( (d &amp; c) &amp;or; ( p &amp; ~((c &amp; ~(d)) ) ) ) ≡ ( (c &amp; d) &amp;or; (p &amp; c) &amp;or; (p &amp; ~(d)) ) )

=== Commutative and associative laws ===

Both AND and OR obey the [[commutative law]] and [[associative law]]:
* Commutative law for OR: ( a &amp;or; b ) ≡ ( b &amp;or; a )
* Commutative law for AND: ( a &amp; b ) ≡ ( b &amp; a )
* Associative law for OR: (( a &amp;or; b ) &amp;or; c ) ≡ ( a &amp;or; (b &amp;or; c) )
* Associative law for AND: (( a &amp; b ) &amp; c ) ≡ ( a &amp; (b &amp; c) )

'''Omitting parentheses in strings of AND and OR''': The connectives are considered to be unary (one-variable, e.g. NOT) and binary (i.e. two-variable AND, OR, IMPLIES). For example:
: ( (c &amp; d) &amp;or; (p &amp; c) &amp;or; (p &amp; ~d) ) above should be written ( ((c &amp; d) &amp;or; (p &amp; c)) &amp;or; (p &amp; ~(d) ) ) or possibly ( (c &amp; d) &amp;or; ( (p &amp; c) &amp;or; (p &amp; ~(d)) ) )
However, a truth-table demonstration shows that the form without the extra parentheses is perfectly adequate.

'''Omitting parentheses with regards to a single-variable NOT''': While ~(a) where a is a single variable is perfectly clear, ~a is adequate and is the usual way this [[literal (mathematical logic)|literal]] would appear. When the NOT is over a formula with more than one symbol, then the parentheses are mandatory, e.g. ~(a &amp;or; b).

=== Distributive laws ===
OR distributes over AND and AND distributes over OR. NOT does not distribute over AND or OR. See below about De Morgan's law:
* Distributive law for OR: ( c &amp;or; ( a &amp; b) ) ≡ ( (c &amp;or; a) &amp; (c &amp;or; b) )
* Distributive law for AND: ( c &amp; ( a &amp;or; b) ) ≡ ( (c &amp; a) &amp;or; (c &amp; b) )

=== De Morgan's laws ===
NOT, when distributed over OR or AND, does something peculiar (again, these can be verified with a truth-table):
* De Morgan's law for OR: ¬(a &amp;or; b) ≡ (¬a ^ ¬b)
* De Morgan's law for AND: ¬(a ^ b) ≡ (¬a &amp;or; ¬b)

=== Laws of absorption ===
Absorption, in particular the first one, causes the "laws" of logic to differ from the "laws" of arithmetic:
* Absorption (idempotency) for OR: (a &amp;or; a) ≡ a
* Absorption (idempotency) for AND: (a &amp; a) ≡ a

=== Laws of evaluation: Identity, nullity, and complement ===
The sign " = " (as distinguished from logical equivalence ≡, alternately ↔ or ⇔) symbolizes the assignment of value or meaning. Thus the string (a &amp; ~(a)) symbolizes "1", i.e. it '''means''' the same thing as symbol "1" ". In some "systems" this will be an axiom (definition) perhaps shown as ( (a &amp; ~(a)) =&lt;sub&gt;Df&lt;/sub&gt; 1 ); in other systems, it may be derived in the truth table below:
{| style="margin-left: auto; margin-right: auto; border: none;"
|- style="font-size:9pt; text-align:center"
| width="18.75" Height="12" | 
| width="4.5" | 
| width="9" | 
| width="9" | 
| width="10.5" | 
|style="background-color:#C5D9F1" width="10.5" | c
| width="9.75" | 
| width="9.75" | 
| width="15.75" | 
| width="8.25" | 
| width="8.25" | 
|style="background-color:#FFFF99" width="18" | taut
| width="13.5" | c
| width="11.25" | 
|- style="font-weight:bold" align="center"
|style="font-size:9pt" Height="15" | a
|style="font-size:9pt" | 
|style="font-size:9pt" | (
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="background-color:#C5D9F1;font-size:9pt" | &amp;
|style="background-color:#EAF1DD;font-size:9pt" | ~
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="font-size:9pt" | )
|style="font-size:9pt" | )
|style="background-color:#FFFF99" | ≡
|style="font-size:9pt" | 0
|style="font-size:9pt" | )
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 
| 
| 
| 0
|style="background-color:#C5D9F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
|style="background-color:#FFFF99" | 1
| 0
| 
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 
| 
| 
| 1
|style="background-color:#C5D9F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
|style="background-color:#FFFF99" | 1
| 0
| 
|}

* Commutation of equality: (a = b) ≡ (b = a)
* Identity for OR: (a &amp;or; 0) = a or (a &amp;or; F) = a
* Identity for AND: (a &amp; 1) = a or (a &amp; T) = a
* Nullity for OR: (a &amp;or; 1) = 1  or (a &amp;or; T) = T
* Nullity for AND: (a &amp; 0) = 0  or (a &amp; F) = F
* Complement for OR: (a &amp;or; ~a) = 1 or (a &amp;or; ~a) = T, [[law of excluded middle]]
* Complement for AND: (a &amp; ~a) = 0 or (a &amp; ~a) = F, [[law of contradiction]]

=== Double negative (involution) ===
* ¬(¬a) ≡ a

== Well-formed formulas (wffs) ==
A key property of formulas is that they can be uniquely parsed to determine the structure of the formula in terms of its propositional variables and logical connectives. When formulas are written in [[infix notation]], as above, unique readability is ensured through an appropriate use of parentheses in the definition of formulas. Alternatively, formulas can be written in [[Polish notation]] or [[reverse Polish notation]], eliminating the need for parentheses altogether.

The inductive definition of infix formulas in the previous section can be converted to a [[formal grammar]] in [[Backus-Naur form]]:

&lt;source lang="bnf"&gt;
&lt;formula&gt; ::= &lt;propositional variable&gt;
| ( ¬ &lt;formula&gt; )
| ( &lt;formula&gt; ∧ &lt;formula&gt;)
| ( &lt;formula&gt; ∨ &lt;formula&gt; )
| ( &lt;formula&gt; → &lt;formula&gt; )
| ( &lt;formula&gt; ↔ &lt;formula&gt; )
&lt;/source&gt;
It can be shown that any expression matched by the grammar has a balanced number of left and right parentheses, and any nonempty initial segment of a formula has more left than right parentheses.&lt;ref&gt;cf Minsky 1967:75, section 4.2.3 "The method of parenthesis counting". Minsky presents a state machine that will do the job, and by use of induction (recursive definition) Minsky proves the "method" and presents a theorem as the result. A fully generalized "parenthesis grammar" requires an infinite state machine (e.g. a Turing machine) to do the counting.&lt;/ref&gt; This fact can be used to give an algorithm for parsing formulas. For example, suppose that an expression ''x'' begins with &lt;math&gt;( \lnot&lt;/math&gt;. Starting after the second symbol, match the shortest subexpression ''y'' of ''x'' that has balanced parentheses. If ''x'' is a formula, there is exactly one symbol left after this expression, this symbol is a closing parenthesis, and ''y'' itself is a formula. This idea can be used to generate a [[recursive descent parser]] for formulas.

'''Example of parenthesis counting''':

This method locates as "1" the '''principal connective''' {{--}} the connective under which the overall evaluation of the formula occurs for the outer-most parentheses (which are often omitted).&lt;ref&gt;Robbin p. 7&lt;/ref&gt; It also locates the inner-most connective where one would begin evaluatation of the formula without the use of a truth table, e.g. at "level 6".
{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
| width="32.25" Height="12" | 
! width="27.75" | start
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
| width="12" | c
| width="12" | &amp;
| width="12" | d
|style="background-color:#FFC000" width="12" | )
| width="12" | V
|style="background-color:#99FF99" width="12" | (
| width="12" | p
| width="12" | &amp;
| width="12" | ~
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
| width="12" | c
| width="12" | &amp;
| width="12" | ~
|style="background-color:#99FF99" width="12" | (
| width="12" | d
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
| width="12" | = 
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
|style="background-color:#99FF99" width="12" | (
| width="12" | c
| width="12" | &amp;
| width="12" | d
|style="background-color:#FFC000" width="12" | )
| width="12" | V
|style="background-color:#99FF99" width="12" | (
| width="12" | p
| width="12" | &amp;
| width="12" | d
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
| width="12" | V
|style="background-color:#99FF99" width="12" | (
| width="12" | p
| width="12" | &amp;
| width="12" | ~
|style="background-color:#99FF99" width="12" | (
| width="12" | c
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|style="background-color:#FFC000" width="12" | )
|- style="font-size:9pt"
! Height="13.5" align="right" valign="bottom" | count
| align="center" valign="bottom" | 0
|style="background-color:#99FF99" align="center" valign="bottom" | 1
|style="background-color:#99FF99" align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 2
| align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 4
|style="background-color:#99FF99" align="center" valign="bottom" | 5
| align="center" valign="bottom" | 5
| align="center" valign="bottom" | 5
| align="center" valign="bottom" | 5
|style="background-color:#99FF99;font-weight:bold" align="center" valign="bottom" | 6
| align="center" valign="bottom" | 6
|style="background-color:#FFC000" align="center" valign="bottom" | 5
|style="background-color:#FFC000" align="center" valign="bottom" | 4
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
|style="background-color:#99FF99" align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
|style="background-color:#FFC000" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
| align="center" valign="bottom" | 4
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 2
| align="center" valign="bottom" | 2
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#99FF99" align="center" valign="bottom" | 3
| align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 3
|style="background-color:#FFC000" align="center" valign="bottom" | 2
|style="background-color:#FFC000" align="center" valign="bottom" | 1
|style="background-color:#FFC000" align="center" valign="bottom" | 0
|}

=== Wffs versus valid formulas in inferences ===
The notion of '''valid argument''' is usually applied to [[inference]]s in arguments, but arguments reduce to propositional formulas and can be evaluated the same as any other propositional formula. Here a '''valid''' inference means: "The formula that represents the inference evaluates to "truth" beneath its principal connective, no matter what truth-values are assigned to its variables", i.e. the formula is a tautology.&lt;ref&gt;cf Reichenbach p. 68 for a more involved discussion: "If the inference is valid and the premises are true, the inference is called ''conclusive''.&lt;/ref&gt;
Quite possibly a formula will be ''well-formed'' but not '''valid'''. Another way of saying this is: "Being well-formed is ''necessary'' for a formula to be valid but it is not ''sufficient''." The only way to find out if it is ''both'' well-formed ''and'' valid is to submit it to verification with a truth table or by use of the "laws":

* Example 1: What does one make of the following difficult-to-follow assertion? Is it valid? "If it's sunny, but if the frog is croaking then it's not sunny, then it's the same as saying that the frog isn't croaking." Convert this to a propositional formula as follows:
*:: " IF (a AND (IF b THEN NOT-a) THEN NOT-a" where " a " represents "its sunny" and " b " represents "the frog is croaking":
*:: ( ( (a) &amp; ( (b) → ~(a) ) ≡ ~(b) )
*: This is well-formed, but is it ''valid''? In other words, when evaluated will this yield a tautology (all T) beneath the logical-equivalence symbol ≡ ? The answer is NO, it is not valid. However, if reconstructed as an ''implication'' then the argument ''is'' valid.
*: "Saying it's sunny, but if the frog is croaking then it's not sunny, ''implies'' that the frog isn't croaking."
*: Other circumstances may be preventing the frog from croaking: perhaps a crane ate it.

* Example 2 (from Reichenbach via Bertrand Russell):
*: "If pigs have wings, some winged animals are good to eat. Some winged animals are good to eat, so pigs have wings."
*: ( ((a) → (b)) &amp; (b) → (a) ) is well formed, but an invalid argument as shown by the red evaluation under the principal implication:
{|style="margin-left: auto; margin-right: auto; border: none;"
|- style="font-size:9pt" align="center"
| width="18.75" Height="12" | W
| width="18.75" | G
| width="4.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="10.5" | 
| width="16.5" | 
| width="10.5" | 
| width="11.25" | 
| width="16.5" | 
| width="10.5" | 
| width="10.5" | 
|style="background-color:#CCC0DA" width="19.5" | arg
| width="14.25" | 
| width="12" | 
|- style="font-weight:bold" align="center"
|style="font-size:9pt" Height="12.75" | a
|style="font-size:9pt" | b
|style="font-size:9pt" | 
|style="font-size:9pt" | (
|style="font-size:9pt" | (
|style="font-size:9pt" | (
|style="font-size:9pt" | a
|style="background-color:#F2DDDC;font-size:9pt" |  -&gt;
|style="font-size:9pt" | b
|style="font-size:9pt" | )
|style="background-color:#DBE5F1" | &amp;
|style="font-size:9pt" | b
|style="font-size:9pt" | )
|style="background-color:#CCC0DA;font-size:9pt" |  -&gt;
|style="font-size:9pt" | a
|style="font-size:9pt" | )
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 0
| 
| 
| 
| 
| 0
|style="background-color:#F2DDDC" | 1
| 0
| 
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#CCC0DA" | 1
| 0
| 
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 1
| 
| 
| 
| 
| 0
|style="background-color:#F2DDDC" | 1
| 1
| 
|style="background-color:#DBE5F1" | 1
| 1
| 
|style="background-color:red" | 0
| 0
| 
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 0
| 
| 
| 
| 
| 1
|style="background-color:#F2DDDC" | 0
| 0
| 
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#CCC0DA" | 1
| 1
| 
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 1
| 
| 
| 
| 
| 1
|style="background-color:#F2DDDC" | 1
| 1
| 
|style="background-color:#DBE5F1" | 1
| 1
| 
|style="background-color:#CCC0DA" | 1
| 1
| 
|}

== Reduced sets of connectives ==

[[File:Propositional formula NANDs.png|400px|thumb|right|The engineering symbol for the NAND connective (the 'stroke') can be used to build any propositional formula. The notion that truth (1) and falsity (0) can be defined in terms of this connective is shown in the sequence of NANDs on the left, and the derivations of the four evaluations of a NAND b are shown along the bottom. The more common method is to use the definition of the NAND from the truth table.]]

A set of logical connectives is called '''complete''' if every propositional formula is tautologically equivalent to a formula with just the connectives in that set. There are many complete sets of connectives, including &lt;math&gt;\{\land, \lnot\}&lt;/math&gt;, &lt;math&gt;\{\lor, \lnot\}&lt;/math&gt;, and &lt;math&gt;\{\to, \lnot\}&lt;/math&gt;. There are two binary connectives that are complete on their own, corresponding to NAND and NOR, respectively.&lt;ref&gt;As well as the first three, Hamilton pp.19-22 discusses logics built from only | (NAND), and ↓ (NOR).&lt;/ref&gt; Some pairs are not complete, for example &lt;math&gt;\{\land, \lor\}&lt;/math&gt;.

=== The stroke (NAND) ===
The binary connective corresponding to NAND is called the [[Sheffer stroke]], and written with a vertical bar | or vertical arrow ↑. The completeness of this connective was noted in ''Principia Mathematica'' (1927:xvii). Since it is complete on its own, all other connectives can be expressed using only the stroke. For example, where the symbol " ≡ " represents ''logical equivalence'':
: ~p ≡ p|p
: p → q ≡ p|~q
: p &amp;or; q ≡ ~p|~q
: p &amp; q ≡ ~(p|q)
In particular, the zero-ary connectives &lt;math&gt;\top&lt;/math&gt; (representing truth) and &lt;math&gt;\bot&lt;/math&gt; (representing falsity) can be expressed using the stroke:
: &lt;math&gt;\top \equiv (a|(a|a))&lt;/math&gt;
: &lt;math&gt;\bot \equiv (\top | \top)&lt;/math&gt;

===  IF … THEN … ELSE ===

This connective together with { 0, 1 }, ( or { F, T } or { &lt;math&gt;\bot&lt;/math&gt;, &lt;math&gt;\top&lt;/math&gt; } ) forms a complete set. In the following the IF...THEN...ELSE [[Relation (mathematics)|relation]] (c, b, a) = d represents ( (c → b) &amp;or; (~c → a) ) ≡ ( (c &amp; b) &amp;or; (~c &amp; a) ) = d
: (c, b, a):
: (c, 0, 1) ≡ ~c
: (c, b, 1) ≡ (c → b)
: (c, c, a) ≡ (c &amp;or; a)
: (c, b, c) ≡ (c &amp; b)

Example: The following shows how a theorem-based proof of "(c, b, 1) ≡ (c → b)" would proceed, below the proof is its truth-table verification. ( Note: (c → b) is ''defined'' to be (~c &amp;or; b) ):
:* Begin with the reduced form: ( (c &amp; b) &amp;or; (~c &amp; a) )
:* Substitute "1" for a: ( (c &amp; b) &amp;or; (~c &amp; 1) )
:* Identity (~c &amp; 1) = ~c: ( (c &amp; b) &amp;or; (~c) )
:* Law of commutation for V:  ( (~c) &amp;or; (c &amp; b)  )
:* Distribute "~c V" over (c &amp; b): ( ((~c) &amp;or; c ) &amp; ((~c) &amp;or; b )
:* Law of excluded middle (((~c) &amp;or; c ) = 1 ): ( (1) &amp; ((~c) &amp;or; b ) )
:* Distribute "(1) &amp;" over ((~c) &amp;or; b): ( ((1) &amp; (~c)) &amp;or; ((1) &amp; b )) )
:* Commutivity and Identity (( 1 &amp; ~c) = (~c &amp; 1) = ~c, and (( 1 &amp; b) ≡ (b &amp; 1) ≡ b: ( ~c &amp;or; b )
:* ( ~c &amp;or; b ) is defined as '''c → b''' Q. E. D.

In the following truth table the column labelled "taut" for tautology evaluates '''logical equivalence''' (symbolized here by ≡) between the two columns labelled d. Because all four rows under "taut" are 1's, the equivalence indeed represents a tautology.
{|style="margin-left: auto; margin-right: auto; border: none;"
|- style="font-size:9pt; text-align:center"
| width="27.75" Height="12" | 
| width="20.25" | 
| width="18.75" | 
| width="18.75" | 
| width="6.75" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
|style="background-color:#FDE9D9" width="11.25" | d
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="12.75" | 
|style="background-color:#DDD9C3" width="19.5" | taut
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
| width="11.25" | 
|style="background-color:#FDE9D9" width="11.25" | d
| width="11.25" | 
| width="12.75" | 
| width="12.75" | 
|- style="font-size:9pt;font-weight:bold" align="center"
|style="background-color:#F2F2F2" Height="12" | rows
| c
| b
| a
|style="background-color:#A5A5A5" | 
| (
| (
| (
| c
|style="background-color:#DBE5F1" | &amp;
| b
| )
|style="background-color:#FDE9D9" | V
| (
|style="background-color:#EAF1DD" | ~
| (
| c
| )
|style="background-color:#DBE5F1" | &amp;
| a
| )
| )
|style="background-color:#DDD9C3" |  ≡
| (
|style="background-color:#EAF1DD" | ~
| (
| c
| )
|style="background-color:#FDE9D9" | V
| b
| )
| )
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 0,1
| 0
| 0
| 1
|style="background-color:#A5A5A5" | 
| 
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 1
| 
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
|style="background-color:#DBE5F1" | 1
| 1
| 
| 
|style="background-color:#DDD9C3" | 1
| 
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
|style="background-color:#FDE9D9" | 1
| 0
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 2,3
| 0
| 1
| 1
|style="background-color:#A5A5A5" | 
| 
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 1
| 
|style="background-color:#FDE9D9" | 1
| 
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
|style="background-color:#DBE5F1" | 1
| 1
| 
| 
|style="background-color:#DDD9C3" | 1
| 
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
|style="background-color:#FDE9D9" | 1
| 1
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 4,5
| 1
| 0
| 1
|style="background-color:#A5A5A5" | 
| 
| 
| 
| 1
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
|style="background-color:#DBE5F1" | 0
| 1
| 
| 
|style="background-color:#DDD9C3" | 1
| 
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
|style="background-color:#FDE9D9" | 0
| 0
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 6,7
| 1
| 1
| 1
|style="background-color:#A5A5A5" | 
| 
| 
| 
| 1
|style="background-color:#DBE5F1" | 1
| 1
| 
|style="background-color:#FDE9D9" | 1
| 
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
|style="background-color:#DBE5F1" | 0
| 1
| 
| 
|style="background-color:#DDD9C3" | 1
| 
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
|style="background-color:#FDE9D9" | 1
| 1
| 
| 
|}

== Normal forms ==

An arbitrary propositional formula may have a very complicated structure. It is often convenient to work with formulas that have simpler forms, known as '''normal forms'''. Some common normal forms include [[conjunctive normal form]] and [[disjunctive normal form]]. Any propositional formula can be reduced to its conjunctive or disjunctive normal form.

=== Reduction to normal form ===

[[File:Propositional formula maps 1.png|450px|thumb|right| A truth table will contain 2&lt;sup&gt;n&lt;/sup&gt; rows, where n is the number of variables (e.g. three variables "p", "d", "c" produce 2&lt;sup&gt;3&lt;/sup&gt; rows). Each row represents a minterm. Each minterm can be found on the Hasse diagram, on the Veitch diagram, and on the Karnaugh map. (The evaluations of "p" shown in the truth table are not shown in the Hasse, Veitch and Karnaugh diagrams; these are shown in the Karnaugh map of the following section.)&lt;!-- For example, row 2 represents the minterm (~p &amp; d &amp; ~c). If "~v" (where v is any variable) is thought of as "0" and "v" is thought of as "1", then the minterm can be thought of as a binary number, e.g. (~p &amp; d &amp; ~c) = 010&lt;sub&gt;2&lt;/sub&gt; = 2&lt;sub&gt;10&lt;/sub&gt;. A formula (e.g. the formula for q) evaluated for variabiles ''p'' = 0, ''d'' = 1, ''c'' = 0 will produce an output (e.g. q). --&gt;]]

Reduction to normal form is relatively simple once a truth table for the formula is prepared. But further attempts to minimize the number of '''literals''' (see below) requires some tools: reduction by De Morgan's laws and [[truth table]]s can be unwieldy, but [[Karnaugh map]]s are very suitable a small number of variables (5 or less). Some sophisticated tabular methods exist for more complex circuits with multiple outputs but these are beyond the scope of this article; for more see [[Quine&amp;ndash;McCluskey algorithm]].

==== Literal, term and alterm ====

In electrical engineering a variable x or its negation ~(x) is lumped together into a single notion called a [[literal (mathematical logic)|literal]]. A string of literals connected by ANDs is called a '''term'''. A string of literals connected by OR is called an '''alterm'''. Typically the literal ~(x) is abbreviated ~x. Sometimes the &amp;-symbol is omitted altogether in the manner of algebraic multiplication.

* Examples
*# a, b, c, d are variables. ((( a &amp; ~(b) ) &amp; ~(c)) &amp; d) is a term. This can be abbreviated as (a &amp; ~b &amp; ~c &amp; d), or a~b~cd.
*# p, q, r, s are variables. (((p &amp; ~(q) ) &amp; r) &amp; ~(s) ) is an alterm. This can be abbreviated as (p &amp;or; ~q &amp;or; r &amp;or; ~s).

==== Minterms ====
In the same way that a 2&lt;sup&gt;n&lt;/sup&gt;-row truth table displays the evaluation of a propositional formula for all 2&lt;sup&gt;n&lt;/sup&gt; possible values of its variables, n variables produces a 2&lt;sup&gt;n&lt;/sup&gt;-square Karnaugh map (even though we cannot draw it in its full-dimensional realization). For example, 3 variables produces 2&lt;sup&gt;3&lt;/sup&gt; = 8 rows and 8 Karnaugh squares; 4 variables produces 16 truth-table rows and 16 squares and therefore 16 [[minterms]]. Each Karnaugh-map square and its corresponding truth-table evaluation represents one minterm.

Any propositional formula can be reduced to the "logical sum" (OR) of the active (i.e. "1"- or "T"-valued) minterms. When in this form the formula is said to be in [[disjunctive normal form]]. But even though it is in this form, it is not necessarily minimized with respect to either the number of terms or the number of literals.

In the following table, observe the peculiar numbering of the rows: (0, 1, 3, 2, 6, 7, 5, 4, 0). The first column is the decimal equivalent of the binary equivalent of the digits "cba", in other words:
* Example
*: cba&lt;sub&gt;2&lt;/sub&gt; = c*2&lt;sup&gt;2&lt;/sup&gt; + b*2&lt;sup&gt;1&lt;/sup&gt; + a*2&lt;sup&gt;0&lt;/sup&gt;:
*: cba = (c=1, b=0, a=0) = 101&lt;sub&gt;2&lt;/sub&gt; = 1*2&lt;sup&gt;2&lt;/sup&gt; + 0*2&lt;sup&gt;1&lt;/sup&gt; + 1*2&lt;sup&gt;0&lt;/sup&gt; = 5&lt;sub&gt;10&lt;/sub&gt;

This numbering comes about because as one moves down the table from row to row only one variable at a time changes its value. [[Gray code]] is derived from this notion. This notion can be extended to three and four-dimensional [[hypercube]]s called [[Hasse diagram]]s where each corner's variables change only one at a time as one moves around the edges of the cube. Hasse diagrams (hypercubes) flattened into two dimensions are either [[Veitch diagram]]s or [[Karnaugh map]]s (these are virtually the same thing).

When working with Karnaugh maps one must always keep in mind that the top edge "wrap arounds" to the bottom edge, and the left edge wraps around to the right edge—the Karnaugh diagram is really a three- or four- or n-dimensional flattened object.

{|class="wikitable"
|- style="font-size:9pt" align="center" valign="bottom"
! width="60" Height="39" | decimal equivalent of (c, b, a)
! c
! b
! a
! minterm
|- style="font-size:9pt" align="center" valign="bottom"
| Height="15" | 0
| 0
| 0
| 0
|style="background-color:#FDE9D9" | (~c  &amp;  ~b  &amp;  ~a)
|- style="font-size:9pt" align="center" valign="bottom"
| Height="15" | 1
| 0
| 0
| 1
|style="background-color:#FDE9D9" | (~c  &amp;  ~b  &amp;  a)
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | 3
| 0
| 1
| 1
|style="background-color:#FDE9D9" | (~c  &amp;  b  &amp;  a)
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | 2
| 0
| 1
| 0
|style="background-color:#FDE9D9" | (~c &amp;  b  &amp;  ~a)
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | 6
| 1
| 1
| 0
|style="background-color:#FDE9D9" | (c  &amp;  b  &amp;  ~a)
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | 7
| 1
| 1
| 1
|style="background-color:#FDE9D9" | (c &amp;  b &amp;  a)
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | 5
| 1
| 0
| 1
|style="background-color:#FDE9D9" | (c  &amp;  ~b  &amp;  a)
|- style="font-size:9pt" align="center" valign="bottom"
| Height="12" | 4
| 1
| 0
| 0
|style="background-color:#FDE9D9" | (c  &amp;  ~b  &amp;  ~a)
|- style="font-size:9pt;color:#A5A5A5" align="center" valign="bottom"
| Height="12" | 0
|style="font-weight:bold" | 0
| 0
| 0
| (~a  &amp;  ~b  &amp;  ~c)
|}

=== Reduction by use of the map method (Veitch, Karnaugh) ===
Veitch improved the notion of [[Venn diagram]]s by converting the circles to abutting squares, and Karnaugh simplified the Veitch diagram by converting the minterms, written in their literal-form (e.g. ~abc~d) into numbers.&lt;ref&gt;Wickes 1967:36ff. Wickes offers a good example of 8 of the 2 x 4 (3-variable maps) and 16 of the 4 x 4 (4-variable) maps. As an arbitrary 3-variable map could represent any one of 2&lt;sup&gt;8&lt;/sup&gt;=256 2x4 maps, and an arbitrary 4-variable map could represent any one of 2&lt;sup&gt;16&lt;/sup&gt; = 65,536 different formula-evaluations, writing down every one is infeasible.&lt;/ref&gt; The method proceeds as follows:

==== Produce the formula's truth table ====

Produce the formula's truth table. Number its rows using the binary-equivalents of the variables (usually just sequentially 0 through n-1) for n variables.

: ''Technically, the [[propositional function]] has been reduced to its (unminimized) conjunctive normal form: each row has its minterm expression and these can be OR'd to produce the formula in its (unminimized) conjunctive normal form.''

Example: ((c &amp; d) &amp;or; (p &amp; ~(c &amp; (~d)))) = q in conjunctive normal form is:
::: ( (~p &amp; d &amp; c ) &amp;or; (p &amp; d &amp; c) &amp;or; (p &amp; d &amp; ~c) &amp;or; (p &amp; ~d &amp; ~c) ) = q

However, this formula be reduced both in the number of terms (from 4 to 3) and in the total count of its literals (12 to 6).

{|
|- style="font-size:9pt;font-weight:bold" align="center"
!style="background-color:#F2F2F2" width="25.5" Height="24" | row
! Minterms
! width="21" | p
! width="21" | d
! width="21" | c
! width="10.5" | (
! width="10.5" | (
! width="10.5" | c
! width="10.5" | &amp;
! width="10.5" | d
! width="10.5" | )
!style="background-color:#FDE9D9" width="10.5" | &amp;or;
! width="10.5" | (
! width="10.5" | p
! width="10.5" | &amp;
! width="10.5" | ~
! width="10.5" | (
! width="10.5" | (
! width="10.5" | c
! width="10.5" | &amp;
! width="10.5" | ~
! width="10.5" | (
! width="10.5" | d
! width="10.5" | )
! width="10.5" | )
! width="10.5" | )
! width="10.5" | )
! width="10.5" | )
! {{Active}} minterms
! Formula in conjunctive normal form
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 0
| align="center" valign="bottom" | ( ~p &amp; ~d &amp; ~c )
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
|style="background-color:#FDE9D9" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 1
| align="center" valign="bottom" | ( ~p &amp; ~d &amp; c)
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
|style="background-color:#FDE9D9" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 1
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 2
| align="center" valign="bottom" | ( ~p &amp; d &amp; ~c )
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
|style="background-color:#FDE9D9" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 3
| align="center" valign="bottom" | ( ~p &amp; d &amp; c )
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" | (~p &amp; d &amp; c)
|  valign="bottom" | 
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 4
| align="center" valign="bottom" | ( p &amp; ~d &amp; ~c )
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 1
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" | (~p &amp; d &amp; c)
|  valign="bottom" | 
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 5
| align="center" valign="bottom" | ( p &amp; ~d &amp; c )
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
|style="background-color:#FDE9D9" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 1
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" | 
|  valign="bottom" | 
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 6
| align="center" valign="bottom" | ( p &amp; d &amp; ~c )
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 1
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" | (p &amp; d &amp; ~c)
|  valign="bottom" | 
|- style="font-size:9pt"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" align="center" valign="bottom" | 7
| align="center" valign="bottom" | ( p &amp; d &amp; c )
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 0
|style="background-color:#DBE5F1" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 1
|style="background-color:#EAF1DD" align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
|style="background-color:#DBE5F1" align="center" valign="bottom" | 0
|style="background-color:#EAF1DD" align="center" valign="bottom" | 0
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 1
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
| align="center" valign="bottom" | 
|style="background-color:#FCD5B4" align="center" | ( p &amp; d &amp; c )
|  valign="bottom" | 
|- style="font-size:9pt"
| Height="16.5"  valign="bottom" | 
| align="center" valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|style="background-color:#FFA7A9;font-weight:bold" align="center" | q
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|style="background-color:#FFA7A9" align="center" |  = (~p&amp;d&amp;c) &amp;or; (~p&amp;d&amp;c) &amp;or; (p&amp;d&amp;~c ) &amp;or; (p&amp;d&amp;c )
|}

==== Create the formula's Karnaugh map ====

[[File:Propositional formula maps 2.png|400px|thumb|right| Steps in the reduction using a Karnaugh map. The final result is the OR (logical "sum") of the three reduced terms.]]

Use the values of the formula (e.g. "p") found by the truth-table method and place them in their into their respective (associated) Karnaugh squares (these are numbered per the Gray code convention). If values of "d" for "don't care" appear in the table, this adds flexibility during the reduction phase.

==== Reduce minterms ====

Minterms of adjacent (abutting) 1-squares (T-squares) can be reduced with respect to the number of their [[literal (mathematical logic)|literal]]s, and the number terms also will be reduced in the process. Two abutting squares (2 x 1 horizontal or 1 x 2 vertical, even the edges represent abutting squares) lose one literal, four squares in a 4 x 1 rectangle (horizontal or vertical) or 2 x 2 square (even the four corners represent abutting squares) lose two literals, eight squares in a rectangle lose 3 literals, etc. (One seeks out the largest square or rectangles and ignores the smaller squares or rectangles contained totally within it. ) This process continues until all abutting squares are accounted for, at which point the propositional formula is minimized.

For example, squares #3 and #7 abut. These two abutting squares can lose one literal (e.g. "p" from squares #3 and #7), four squares in a rectangle or square lose two literals, eight squares in a rectangle lose 3 literals, etc. (One seeks out the largest square or rectangles.) This process continues until all abutting squares are accounted for, at which point the propositional formula is said to be minimized.

Example:  The map method usually is done by inspection. The following example expands the algebraic method to show the "trick" behind the combining of terms on a Karnaugh map:
: Minterms #3 and #7 abut, #7 and #6 abut, and #4 and #6 abut (because the table's edges wrap around). So each of these pairs can be reduced.

Observe that by the Idempotency law (A &amp;or; A) = A, we can create more terms. Then by association and distributive laws the variables to disappear can be paired, and then "disappeared" with the Law of contradiction (x &amp; ~x)=0. The following uses brackets [ and ] only to keep track of the terms; they have no special significance:
* Put the formula in conjunctive normal form with the formula to be reduced:
::: '''q = ( (~p &amp; d &amp; c ) &amp;or; (p &amp; d &amp; c) &amp;or; (p &amp; d &amp; ~c) &amp;or; (p &amp; ~d &amp; ~c) )''' = ( #3 &amp;or; #7 &amp;or; #6 &amp;or; #4 )
* Idempotency (absorption) [ A &amp;or; A) = A:
::: ( #3 &amp;or; [ #7 &amp;or; #7 ] &amp;or; [ #6 &amp;or; #6 ] &amp;or; #4 )
* Associative law (x &amp;or; (y &amp;or; z)) = ( (x &amp;or; y) &amp;or; z )
::: ( [ #3 &amp;or; #7 ] &amp;or; [ #7 &amp;or; #6 ] &amp;or; [ #6 &amp;or; #4]  )
::: '''[''' (~p &amp; d &amp; c ) &amp;or; (p &amp; d &amp; c) ''']''' &amp;or; '''[''' (p &amp; d &amp; c) &amp;or; (p &amp; d &amp; ~c) ''']''' &amp;or; '''[''' (p &amp; d &amp; ~c) &amp;or; (p &amp; ~d &amp; ~c) ''']'''.
* Distributive law ( x &amp; (y &amp;or; z) ) = ( (x &amp; y) &amp;or; (x &amp; z) ) :
::: ( [ (d &amp; c) &amp;or; (~p &amp; p) ]  &amp;or; [ (p &amp; d) &amp;or; (~c &amp; c) ] &amp;or; [ (p &amp; ~c) &amp;or; (c &amp; ~c) ] )
* Commutative law and law of contradiction (x &amp; ~x) = (~x &amp; x) = 0:
::: ( [ (d &amp; c) &amp;or; (0) ] &amp;or; [ (p &amp; d) &amp;or; (0) ] &amp;or; [ (p &amp; ~c) &amp;or; (0) ] )
* Law of identity ( x &amp;or; 0 ) = x leading to the reduced form of the formula:
::: '''q = ( (d &amp; c) &amp;or; (p &amp; d)  &amp;or; (p &amp; ~c) )'''

==== Verify reduction with a truth table ====

{|
|- style="font-size:9pt;font-weight:bold" align="center"
|style="background-color:#F2F2F2" width="25.5" Height="12" | row
! Minterms
! width="21" | p
! width="21" | d
! width="21" | c
! width="10.5" | (
! width="10.5" | (
! width="10.5" | d
!style="background-color:#DBE5F1" width="10.5" | &amp;
! width="10.5" | c
! width="10.5" | )
!style="background-color:#FDE9D9" width="10.5" | &amp;or;
! width="10.5" | (
! width="10.5" | p
!style="background-color:#DBE5F1" width="10.5" | &amp;
! width="10.5" | d
! width="10.5" | )
!style="background-color:#FDE9D9" width="10.5" | &amp;or;
! width="10.5" | (
! width="10.5" | p
!style="background-color:#DBE5F1" width="10.5" | &amp;
!style="background-color:#EAF1DD" width="10.5" | ~
! width="10.5" | (
! width="10.5" | c
! width="10.5" | )
! width="10.5" | )
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 0
| ( ~p &amp; ~d &amp; ~c )
| 0
| 0
| 0
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 1
| ( ~p &amp; ~d &amp; c)
| 0
| 0
| 1
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 1
| 
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 2
| ( ~p &amp; d &amp; ~c )
| 0
| 1
| 0
| 
| 
| 1
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
| 1
| 
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 3
| ( ~p &amp; d &amp; c )
| 0
| 1
| 1
| 
| 
| 1
|style="background-color:#DBE5F1" | 1
| 1
| 
|style="background-color:#FDE9D9" | 1
| 
| 0
|style="background-color:#DBE5F1" | 0
| 1
| 
|style="background-color:#FAC090" | 1
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 4
| ( p &amp; ~d &amp; ~c )
| 1
| 0
| 0
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
| 1
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FAC090" | 1
| 
| 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 5
| ( p &amp; ~d &amp; c )
| 1
| 0
| 1
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 1
| 
|style="background-color:#FDE9D9" | 0
| 
| 1
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
| 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 6
| ( p &amp; d &amp; ~c )
| 1
| 1
| 0
| 
| 
| 1
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 1
| 
| 1
|style="background-color:#DBE5F1" | 1
| 1
| 
|style="background-color:#FAC090" | 1
| 
| 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 7
| ( p &amp; d &amp; c )
| 1
| 1
| 1
| 
| 
| 1
|style="background-color:#DBE5F1" | 1
| 1
| 
|style="background-color:#FDE9D9" | 1
| 
| 1
|style="background-color:#DBE5F1" | 1
| 1
| 
|style="background-color:#FAC090" | 1
| 
| 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
|- style="font-size:9pt"
| Height="12"  valign="bottom" | 
| align="center" valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|style="background-color:#FAC090;font-weight:bold" align="center" | q
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|  valign="bottom" | 
|}

== Impredicative propositions ==

Given the following examples-as-definitions, what does one make of the subsequent reasoning:
: (1) "This sentence is simple." (2) "This sentence is complex, and it is conjoined by AND."

Then assign the variable "s" to the left-most sentence "This sentence is simple". Define "compound" c = "not simple" ~s, and assign c = ~s to "This sentence is compound"; assign "j" to "It [this sentence] is conjoined by AND". The second sentence can be expressed as:
: ( NOT(s) AND j )

If truth values are to be placed on the sentences c = ~s and j, then all are clearly FALSEHOODS: e.g. "This sentence is complex" is a FALSEHOOD (it is ''simple'', by definition). So their conjunction (AND) is a falsehood. But when taken in its assembed form, the sentence a TRUTH.

This is an example of the [[paradox]]es that result from an [[impredicative definition]]—that is, when an object m has a property P, but the object m is defined in terms of property P.&lt;ref&gt;This definition is given by [[Stephen Kleene]]. Both [[Kurt Gödel]] and Kleene believed that the classical paradoxes are uniformly examples of this sort of definition. But Kleene went on to assert that the problem has not been solved satisfactorily and impredicative definitions can be found in [[analysis]]. He gives as example the definition of the [[least upper bound]] (l.u.b) '''u''' of '''M'''. Given a [[Dedekind cut]] of the number line '''C''' and the two parts into which the number line is cut, i.e. '''M''' and ('''C''' - '''M'''), l.u.b. = '''u''' is defined in terms of the notion '''M''', whereas '''M''' is defined in terms of '''C'''. Thus the definition of '''u''', an element of '''C''', is defined in terms of the totality '''C''' and this makes its definition impredicative. Kleene asserts that attempts to argue this away can be used to uphold the impredicative definitions in the paradoxes.(Kleene 1952:43).&lt;/ref&gt; The best advice for a rhetorician or one involved in deductive analysis is avoid impredicative definitions but at the same time be on the lookout for them because they can indeed create paradoxes. Engineers, on the other hand, put them to work in the form of propositional formulas with feedback.

== Propositional formula with "feedback" ==

The notion of a propositional formula appearing as one of its own variables requires a formation rule that allows the assignment of the formula to a variable. In general there is no stipulation (either axiomatic or truth-table systems of objects and relations) that forbids this from happening.&lt;ref&gt;McCluskey comments that "it could be argued that the analysis is still incomplete because the word statement "The outputs are equal to the previous values of the inputs" has not been obtained"; he goes on to dismiss such worries because "English is not a formal language in a mathematical sense, [and] it is not really possible to have a ''formal'' procedure for obtaining word statements" (p. 185).&lt;/ref&gt;

The simplest case occurs when an OR formula becomes one its own inputs e.g. p = q. Begin with (p &amp;or; s) = q, then let p = q. Observe that q's "definition" depends on itself "q" as well as on "s" and the OR connective; this definition of q is thus '''impredicative'''.
Either of two conditions can result:&lt;ref&gt;More precisely, given enough "loop gain", either '''oscillation''' or '''memory''' will occur (cf McCluskey p. 191-2). In abstract (idealized) mathematical systems adequate loop gain is not a problem.&lt;/ref&gt; oscillation or memory.

It helps to think of the formula as a [[black box]]. Without knowledge of what is going on "inside" the formula-"box" from the outside it would appear that the output is no longer a [[Function (mathematics)|function]] of the inputs alone. That is, sometimes one looks at q and sees 0 and other times 1. To avoid this problem one has to know the '''state''' (condition) of the "hidden" variable p inside the box (i.e. the value of q fed back and assigned to p). When this is known the apparent inconsistency goes away.

To understand [predict] the behavior of formulas with feedback requires the more sophisticated analysis of [[sequential circuit]]s. Propositional formulas with feedback lead, in their simplest form, to state machines; they also lead to memories in the form of Turing tapes and counter-machine counters. From combinations of these elements one can build any sort of bounded computational model (e.g. [[Turing machine]]s, [[counter machine]]s, [[register machine]]s, [[Macintosh computer]]s, etc.).

=== Oscillation ===

In the abstract (ideal) case the simplest oscillating formula is a NOT fed back to itself: ~(~(p=q)) = q. Analysis of an abstract (ideal) propositional formula in a truth-table reveals an inconsistency for both p=1 and p=0 cases: When p=1, q=0, this cannot be because p=q; ditto for when p=0 and q=1.

{|
|- style="font-size:9pt" align="center"
!  width="14.25" Height="12" | 
!  width="5.25" | 
! style="background-color:#EAF1DD;font-weight:bold" width="14.25" | q
! style="font-weight:bold" width="12.75" | 
!  width="14.25" | 
!  width="12.75" | 
!  width="23.25" | 
!  width="111" | 
|- style="font-size:9pt" align="center"
! style="font-weight:bold" Height="12" | p
!  
! style="background-color:#EAF1DD;font-weight:bold" | ~
! style="font-weight:bold" | (
! style="font-weight:bold" | p
! style="font-weight:bold" | )
! style="font-weight:bold" |  = q
!  
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 
|style="background-color:red" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:red" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 
|style="background-color:red" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:red" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|}

[[File:Propositional formula oscillator 1.png|400px|thumb|right]]

'''Oscillation with delay''': If an delay&lt;ref&gt;The notion of delay and the principle of local causation as caused ultimately by the speed of light appears in Robin Gandy (1980), "Church's thesis and Principles for Mechanisms", in J. Barwise, H. J. Keisler and K. Kunen, eds., ''The Kleene Symposium'', North-Holland Publishing Company (1980) 123-148. Gandy considered this to be the most important of his principles: "Contemporary physics rejects the possibility of instantaneous action at a distance" (p. 135). Gandy was [[Alan Turing]]'s student and close friend.&lt;/ref&gt; (ideal or non-ideal) is inserted in the abstract formula between p and q then p will oscillate between 1 and 0: 101010...101... ''ad infinitum''. If either of the delay and NOT are not abstract (i.e. not ideal), the type of analysis to be used will be dependent upon the exact nature of the objects that make up the oscillator; such things fall outside mathematics and into engineering.

Analysis requires a delay to be inserted and then the loop cut between the delay and the input "p". The delay must be viewed as a kind of proposition that has "qd" (q-delayed) as output for "q" as input. This new proposition adds another column to the truth table. The inconsistency is now between "qd" and "p" as shown in red; two stable states resulting:

{|
|- style="font-size:9pt" align="center"
!  width="16.5" Height="12" | 
!  width="14.25" | 
!  width="8.25" | 
! style="background-color:#EAF1DD;font-weight:bold" width="14.25" | q
! style="font-weight:bold" width="12.75" | 
!  width="14.25" | 
!  width="12.75" | 
!  width="23.25" | 
!  width="111" | 
|- style="font-size:9pt" align="center"
! style="font-weight:bold" Height="12" | qd
! style="font-weight:bold" | p
! style="font-weight:bold" | (
! style="background-color:#EAF1DD;font-weight:bold" | ~
! style="font-weight:bold" | (
! style="font-weight:bold" | p
! style="font-weight:bold" | )
! style="background-color:#EAF1DD;font-weight:bold" |  = q
!  
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 0
| 
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
|style="background-color:#EAF1DD" | 1
| state 1
|- style="font-size:9pt" align="center"
|style="background-color:red" Height="12" | 0
|style="background-color:red" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | qd &amp; p inconsistent
|- style="font-size:9pt" align="center"
|style="background-color:red" Height="12" | 1
|style="background-color:red" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | qd &amp; p inconsistent
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 1
| 
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
|style="background-color:#EAF1DD" | 0
| state 0
|}

=== Memory ===
[[File:Propositional formula flip flops 1.png|400px|thumb|right| About the simplest memory results when the output of an OR feeds back to one of its inputs, in this case output "q" feeding back into "p". The next simplest is the "flip-flop" shown below the once-flip. Analysis of these sorts of formulas can be done by either cutting the feedback path(s) or inserting (ideal) delay in the path. A cut path and an assumption that no delay occurs anywhere in the "circuit" results in inconsistencies for some of the '''total states''' (combination of inputs and outputs, e.g. (p=0, s=1, r=1) results in an inconsistency). When delay is present these inconsistencies are merely '''transient''' and expire when the delay(s) expire. The drawings on the right are called [[state diagram]]s.]]

[[File:Propositional formula 3.png|400px|thumb|right| A "clocked flip-flop" memory ("c" is the "clock" and "d" is the "data"). The data can change at any time when clock c=0; when clock c=1 the output q "tracks" the value of data d. When c goes from 1 to 0 it "traps" d = q's value and this continues to appear at q no matter what d does (as long as c remains 0).]]

Without delay, inconsistencies must be eliminated from a truth table analysis. With the notion of "delay", this condition presents itself as a momentary inconsistency between the fed-back output variable q and p = q&lt;sub&gt;delayed&lt;/sub&gt;.

A truth table reveals the rows where inconsistencies occur between p = q&lt;sub&gt;delayed&lt;/sub&gt; at the input and q at the output. After "breaking" the feed-back,&lt;ref&gt;McKlusky p. 194-5 discusses "breaking the loop" and inserts "amplifiers" to do this; Wickes (p. 118-121) discuss inserting delays. McCluskey p. 195ff discusses the problem of "races" caused by delays.&lt;/ref&gt; the truth table construction proceeds in the conventional manner. But afterwards, in every row the output q is compared to the now-independent input p and any inconsistencies between p and q are noted (i.e. p=0 together with q=1, or p=1 and q=0); when the "line" is "remade" both are rendered impossible by the Law of contradiction ~(p &amp; ~p)). Rows revealing inconsistencies are either considered '''transient states''' or just eliminated as inconsistent and hence "impossible".

==== Once-flip memory ====
About the simplest memory results when the output of an OR feeds back to one of its inputs, in this case output "q" feeds back into "p". Given that the formula is first evaluated (initialized) with p=0 &amp; q=0, it will "flip" once when "set" by s=1. Thereafter, output "q" will sustain "q" in the "flipped" condition (state q=1). This behavior, now time-dependent, is shown by the [[state diagram]] to the right of the once-flip.

{|
|- style="font-size:9pt" align="center"
!  width="16.5" Height="12" | 
!  width="14.25" | 
!  width="14.25" | 
!  width="14.25" | 
! style="background-color:#FDE9D9;font-weight:bold" width="14.25" | q
!  width="14.25" | 
!  width="14.25" | 
!  width="23.25" | 
!  width="153" | 
|- style="font-size:9pt" align="center"
! style="font-weight:bold" Height="12" | p
! style="font-weight:bold" | s
! style="font-weight:bold" | (
! style="background-color:#FCFF7F;font-weight:bold" | s
! style="background-color:#FDE9D9;font-weight:bold" | &amp;or;
! style="font-weight:bold" | p
! style="font-weight:bold" | )
! style="background-color:#FDE9D9;font-weight:bold" |  = q
!  
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 0
| 
| 0
|style="background-color:#FDE9D9" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| state 0, s=0
|- style="font-size:9pt" align="center"
|style="background-color:#BFBFBF" Height="12" | 0
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 1
|style="background-color:red" | 1
|style="background-color:red" | 0
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 0
| 
| 0
|style="background-color:#FDE9D9" | 1
| 1
| 
|style="background-color:#FDE9D9" | 1
| state 1 with s = 0
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 1
| 
|style="background-color:#FCFF7F" | 1
|style="background-color:#FDE9D9" | 1
| 1
| 
|style="background-color:#FDE9D9" | 1
| state 1 with s = 1
|}

==== Flip-flop memory ====
The next simplest case is the "set-reset" [[Flip-flop (electronics)|flip-flop]] shown below the once-flip. Given that r=0 &amp; s=0 and q=0 at the outset, it is "set" (s=1) in a manner similar to the once-flip. It however has a provision to "reset" q=0 when "r"=1. And additional complication occurs if both set=1 and reset=1. In this formula, the set=1 ''forces'' the output q=1 so when and if (s=0 &amp; r=1) the flip-flop will be reset. Or, if (s=1 &amp; r=0) the flip-flop will be set. In the abstract (ideal) instance in which s=1 &amp;rArr; s=0 &amp; r=1 &amp;rArr; r=0 simultaneously, the formula q will be indeterminate (undecidable). Due to delays in "real" OR, AND and NOT the result will be unknown at the outset but thereafter predicable.

{|
|- style="font-size:9pt" align="center"
!  width="19.5" Height="12" | 
!  width="19.5" | 
!  width="19.5" | 
!  width="14.25" | 
!  width="14.25" | 
! style="background-color:#FDE9D9;font-weight:bold" width="14.25" | q
!  width="14.25" | 
!  width="14.25" | 
!  width="16.5" | 
!  width="14.25" | 
!  width="14.25" | 
!  width="14.25" | 
!  width="14.25" | 
!  width="14.25" | 
!  width="14.25" | 
!  width="23.25" | 
!  width="153" | 
|- style="font-size:9pt" align="center"
! style="font-weight:bold" Height="12" | p
! style="font-weight:bold" | s
! style="font-weight:bold" | r
! style="font-weight:bold" | (
! style="background-color:#FCFF7F;font-weight:bold" | s
! style="background-color:#FDE9D9;font-weight:bold" | &amp;or;
! style="font-weight:bold" | (
! style="font-weight:bold" | p
! style="background-color:#DBE5F1;font-weight:bold" | &amp;
! style="background-color:#EAF1DD;font-weight:bold" | ~
! style="font-weight:bold" | (
! style="background-color:#FCFF7F;font-weight:bold" | r
! style="font-weight:bold" | )
! style="font-weight:bold" | )
! style="font-weight:bold" | )
! style="background-color:#FDE9D9;font-weight:bold" |  = q
!  
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 0
| 0
| 
| 0
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
|style="background-color:#FDE9D9" | 0
| state 0 with ( s=0 &amp; r=0 )
|- style="font-size:9pt" align="center"
| Height="12" | 0
| 0
| 1
| 
| 0
|style="background-color:#FDE9D9" | 0
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
|style="background-color:#FCFF7F" | 1
| 
| 
| 
|style="background-color:#FDE9D9" | 0
| state 0 with ( s=0 &amp; r=1 )
|- style="font-size:9pt" align="center"
|style="background-color:#D8D8D8" Height="12" | 0
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:red" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:red" | 0
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|- style="font-size:9pt" align="center"
|style="background-color:#D8D8D8" Height="12" | 0
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:red" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:red" | 0
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 0
| 0
| 
| 0
|style="background-color:#FDE9D9" | 1
| 
| 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
|style="background-color:#FDE9D9" | 1
| state 1 with ( s=0 &amp; r=0 )
|- style="font-size:9pt" align="center"
|style="background-color:#D8D8D8" Height="12" | 1
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 0
|style="background-color:red" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:red" | 1
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 0
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 1
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | 
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|- style="font-size:9pt" align="center"
| Height="12" | 1
| 1
| 0
| 
|style="background-color:#FCFF7F" | 1
|style="background-color:#FDE9D9" | 1
| 
| 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
|style="background-color:#FDE9D9" | 1
| state 1 with ( s=1 &amp; r=0 )
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2" Height="12" | 1
|style="background-color:#F2F2F2" | 1
|style="background-color:#F2F2F2" | 1
|style="background-color:#F2F2F2" | 
|style="background-color:#FCFF7F" | 1
|style="background-color:#FDE9D9" | 1
|style="background-color:#F2F2F2" | 
|style="background-color:#F2F2F2" | 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
|style="background-color:#F2F2F2" | 
|style="background-color:#FCFF7F" | 1
|style="background-color:#F2F2F2" | 
|style="background-color:#F2F2F2" | 
|style="background-color:#F2F2F2" | 
|style="background-color:#FDE9D9" | 1
|style="background-color:#F2F2F2" | state 1 with s &amp; r simultaneously 1
|}

==== Clocked flip-flop memory ====
The formula known as "clocked flip-flop" memory ("c" is the "clock" and "d" is the "data") is given below. It works as follows: When c = 0 the data d (either 0 or 1) cannot "get through" to affect output q. When c = 1 the data d "gets through" and output q "follows" d's value. When c goes from 1 to 0 the last value of the data remains "trapped" at output "q". As long as c=0, d can change value without causing q to change.

* Examples
*# ( ( c &amp; d ) &amp;or; ( '''p''' &amp; ( ~( c &amp; ~( d ) ) ) ) = '''q''', but now let p = q:
*# ( ( c &amp; d ) &amp;or; ( '''q''' &amp; ( ~( c &amp; ~( d ) ) ) ) = '''q'''

The state diagram is similar in shape to the flip-flop's state diagram, but with different labelling on the '''transitions'''.

{|
|- style="font-size:9pt"
!  width="26.25" Height="12" align="center" | 
!  width="16.5" align="center" | 
!  width="16.5" align="center" | 
!  width="16.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
! style="background-color:#DBE5F1" width="10.5" align="center" | s
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
! style="background-color:#FDE9D9;font-weight:bold" width="10.5" align="center" | q
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
! style="background-color:#DBE5F1" width="10.5" align="center" | w
! style="background-color:#EAF1DD" width="10.5" align="center" | v
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
! style="background-color:#DBE5F1" width="10.5" align="center" | r
! style="background-color:#EAF1DD" width="10.5" align="center" | u
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="10.5" align="center" | 
!  width="17.25" align="center" | 
!  width="201"  | 
|- style="font-size:9pt" align="center"
! style="background-color:#F2F2F2" Height="14.25" | row
! style="font-weight:bold" | q
! style="font-weight:bold" | d
! style="font-weight:bold" | c
! style="font-weight:bold" | (
! style="font-weight:bold" | (
! style="font-weight:bold" | c
! style="background-color:#DBE5F1;font-weight:bold" | &amp;
! style="font-weight:bold" | d
! style="font-weight:bold" | )
! style="background-color:#FDE9D9;font-weight:bold" | &amp;or;
! style="font-weight:bold" | (
! style="background-color:#FDE9D9;font-weight:bold" | q
! style="background-color:#DBE5F1;font-weight:bold" | &amp;
! style="background-color:#EAF1DD;font-weight:bold" | ~
! style="font-weight:bold" | (
! style="font-weight:bold" | (
! style="font-weight:bold" | c
! style="background-color:#DBE5F1;font-weight:bold" | &amp;
! style="background-color:#EAF1DD;font-weight:bold" | ~
! style="font-weight:bold" | (
! style="font-weight:bold" | d
! style="font-weight:bold" | )
! style="font-weight:bold" | )
! style="font-weight:bold" | )
! style="font-weight:bold" | )
! style="font-weight:bold" | )
! style="background-color:#FDE9D9;font-weight:bold" |  =q
! style="font-weight:bold" | Description
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 0
| 0
| 0
| 0
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
|style="background-color:#FDE9D9" | 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
| 
| 
|style="background-color:#FDE9D9" | 0
| state 0 with ( s=0 &amp; r=0 ), 0 is trapped
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 1
| 0
| 0
| 1
| 
| 
|style="background-color:#FCFF7F" | 1
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 0
| 
|style="background-color:#FDE9D9" | 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 
|style="background-color:#FCFF7F" | 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
| 
| 
|style="background-color:#FDE9D9" | 0
| state 0 with ( d=0 &amp; c=1 ):&lt;br/&gt;q=0 is following d=0
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 2
| 0
| 1
| 0
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 1
| 
|style="background-color:#FDE9D9" | 0
| 
|style="background-color:#FDE9D9" | 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
| 
| 
| 
|style="background-color:#FDE9D9" | 0
| state 0 with ( d=1 &amp; r=0 ), 0 is trapped
|- style="font-size:9pt" align="center"
|style="background-color:#BFBFBF;font-weight:bold" Height="12" | 3
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:red" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:red" | 0
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 4
| 1
| 0
| 0
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 0
| 
|style="background-color:#FDE9D9" | 1
| 
|style="background-color:#FDE9D9" | 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 1
| 
| 0
| 
| 
| 
| 
| 
|style="background-color:#FDE9D9" | 1
| state 1 with (d =0 &amp; c=0 ),  1 is trapped
|- style="font-size:9pt" align="center"
|style="background-color:#BFBFBF;font-weight:bold" Height="12" | 5
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 
|style="background-color:red" | 0
|style="background-color:#BFBFBF" | 
|style="background-color:red" | 1
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 1
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 0
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#BFBFBF" | 
|style="background-color:#D8D8D8" | q &amp; p inconsistent
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 6
| 1
| 1
| 0
| 
| 
| 0
|style="background-color:#DBE5F1" | 0
| 1
| 
|style="background-color:#FDE9D9" | 1
| 
|style="background-color:#FDE9D9" | 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
|style="background-color:#EAF1DD" | 
| 
| 0
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
| 1
| 
| 
| 
| 
| 
|style="background-color:#FDE9D9" | 1
| state 1 with (d =1 &amp; c=0 ), 1 is trapped
|- style="font-size:9pt" align="center"
|style="background-color:#F2F2F2;font-weight:bold" Height="12" | 7
| 1
| 1
| 1
| 
| 
|style="background-color:#FCFF7F" | 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#FCFF7F" | 1
| 
|style="background-color:#FDE9D9" | 1
| 
|style="background-color:#FDE9D9" | 1
|style="background-color:#DBE5F1" | 1
|style="background-color:#EAF1DD" | 1
| 
| 
|style="background-color:#FCFF7F" | 1
|style="background-color:#DBE5F1" | 0
|style="background-color:#EAF1DD" | 0
| 
|style="background-color:#FCFF7F" | 1
| 
| 
| 
| 
| 
|style="background-color:#FDE9D9" | 1
| state 1 with ( d=1 &amp; c=1 ):&lt;br/&gt;q=1 is following d=1
|}

== Historical development ==
[[Bertrand Russell]] (1912:74) lists three laws of thought that derive from [[Aristotle]]: (1) The law of identity: "Whatever is, is.", (2) The [[law of contradiction]]: "Nothing cannot both be and not be", and (3) The [[law of excluded middle]]: "Everything must be or not be."
* Example: Here O is an expression about an objects BEING or QUALITY:
*# Law of Identity: O = O
*# Law of contradiction: ~(O &amp; ~(O))
*# Law of excluded middle: (O &amp;or; ~(O))

The use of the word "everything" in the law of excluded middle renders Russell's expression of this law open to debate. If restricted to an expression about BEING or QUALITY with reference to a finite collection of objects (a finite "universe of discourse") -- the members of which can be investigated one after another for the presence or absence of the assertion—then the law is considered intuitionistically appropriate. Thus an assertion such as: "This object must either BE or NOT BE (in the collection)", or "This object must either have this QUALITY or NOT have this QUALITY (relative to the objects in the collection)" is acceptable. See more at [[Venn diagram]].

Although a propositional calculus originated with Aristotle, the notion of an ''algebra'' applied to propositions had to wait until the early 19th century. In an (adverse) reaction to the 2000 year tradition of Aristotle's [[syllogism]]s, [[John Locke]]'s ''Essay concerning human understanding (1690)'' used the word [[semiotics]] (theory of the use of symbols). By 1826 [[Richard Whately]] had critically analyzed the syllogistic logic with a sympathy toward Locke's semiotics. [[George Bentham]]'s work (1827) resulted in the notion of "quantification of the predicate" (1827) (nowadays symbolized as ∀ ≡ "for all"). A "row" instigated by [[Sir William Hamilton, 9th Baronet|William Hamilton]] over a priority dispute with [[Augustus De Morgan]] "inspired [[George Boole]] to write up his ideas on logic, and to publish them as MAL [Mathematical Analysis of Logic] in 1847" (Grattin-Guinness and Bornet 1997:xxviii).

About his contribution Grattin-Guinness and Bornet comment:
: "Boole's principal single innovation was [the] law [ x&lt;sup&gt;n&lt;/sup&gt; = x ] for logic: it stated that the mental acts of choosing the property x and choosing x again and again is the same as choosing x once... As consequence of it he formed the equations x•(1-x)=0 and x+(1-x)=1 which for him expressed respectively the law of contradiction and the law of excluded middle" (p. xxviiff). For Boole "1" was the [[universe of discourse]] and "0" was nothing.

[[Gottlob Frege]]'s massive undertaking (1879) resulted in a formal calculus of propositions, but his symbolism is so daunting that it had little influence excepting on one person: [[Bertrand Russell]]. First as the student of [[Alfred North Whitehead]] he studied Frege's work and suggested a (famous and notorious) emendation with respect to it (1904) around the problem of an [[antinomy]] that he discovered in Frege's treatment ( cf [[Russell's paradox]] ). Russell's work led to a collatoration with Whitehead that, in the year 1912, produced the first volume of ''Principia Mathematica'' (PM). It is here that what we consider "modern" propositional logic first appeared. In particular, PM introduces NOT and OR and the assertion symbol ⊦ as primitives. In terms of these notions they define IMPLICATION → ( def. *1.01: ~p &amp;or; q ), then AND (def. *3.01: ~(~p &amp;or; ~q) ), then EQUIVALENCE p ←→ q (*4.01: (p → q) &amp; ( q → p ) ).

* [[Henry M. Sheffer]] (1921) and [[Jean Nicod]] demonstrate that only one connective, the "stroke" | is sufficient to express all propositional formulas.
* [[Emil Post]] (1921) develops the truth-table method of analysis in his "Introduction to a general theory of elementary propositions". He notes Nicod's stroke | .
* Whitehead and Russell add an introduction to their 1927 re-publication of PM adding, in part, a favorable treatment of the "stroke".

'''Computation and switching logic''':
* [[William Eccles]] and [[F. W. Jordan]] (1919) describe a "trigger relay" made from a vacuum tube.
* [[George Stibitz]] (1937) invents the binary adder using mechanical relays. He builds this on his kitchen table.
: Example: Given binary [[bit]]s a&lt;sub&gt;i&lt;/sub&gt; and b&lt;sub&gt;i&lt;/sub&gt; and carry-in ( c_in&lt;sub&gt;i&lt;/sub&gt;), their summation Σ&lt;sub&gt;i&lt;/sub&gt; and carry-out (c_out&lt;sub&gt;i&lt;/sub&gt;) are:
:* ( ( a&lt;sub&gt;i&lt;/sub&gt; XOR b&lt;sub&gt;i&lt;/sub&gt; ) XOR c_in&lt;sub&gt;i&lt;/sub&gt; )= Σ&lt;sub&gt;i&lt;/sub&gt;
:* ( a&lt;sub&gt;i&lt;/sub&gt; &amp; b&lt;sub&gt;i&lt;/sub&gt; ) &amp;or; c_in&lt;sub&gt;i&lt;/sub&gt; ) = c_out&lt;sub&gt;i&lt;/sub&gt;;
* [[Alan Turing]] builds a multiplier using relays (1937–1938). He has to hand-wind his own relay coils to do this.
* Textbooks about "switching circuits" appear in early 1950s.
* [[Willard Quine]] 1952 and 1955, [[Edward W. Veitch|E. W. Veitch]] 1952, and [[Maurice Karnaugh|M. Karnaugh]] (1953) develop map-methods for simplifying propositional functions.
* [[George H. Mealy]] (1955) and [[Edward F. Moore]] (1956) address the theory of sequential (i.e. switching-circuit) "machines".
* E. J. McCluskey and H. Shorr develop a method for simplifying propositional (switching) circuits (1962).

== Footnotes ==
{{reflist}}

== References ==
* {{aut|Bender, Edward A.}} and {{aut|Williamson, S. Gill}}, 2005, ''A Short Course in Discrete Mathematics'', Dover Publications, Mineola NY, {{isbn|0-486-43946-1}}. This text is used in a "lower division two-quarter [computer science] course" at UC San Diego.
* {{aut|[[Herbert Enderton|Enderton, H. B.]]}},  2002, ''A Mathematical Introduction to Logic.'' Harcourt/Academic Press. {{isbn|0-12-238452-0}}
* {{aut|Goodstein, R. L.}}, (Pergamon Press 1963), 1966, (Dover edition 2007), ''Boolean Algebra'', Dover Publications, Inc. Minola, New York, {{isbn|0-486-45894-6}}. Emphasis on the notion of "algebra of classes" with set-theoretic symbols such as ∩, ∪, ' (NOT), ⊂ (IMPLIES). Later Goldstein replaces these with &amp;, ∨, ￢, → (respectively) in his treatment of "Sentence Logic" pp.&amp;nbsp;76–93.
* {{aut|[[Ivor Grattan-Guinness]]}} and Gérard Bornet 1997, ''George Boole: Selected Manuscripts on Logic and its Philosophy'', Birkhäuser Verlag, Basil, {{isbn|978-0-8176-5456-6}} (Boston).
* {{aut|A. G. Hamilton}} 1978, ''Logic for Mathematicians'', Cambridge University Press, Cambridge UK, {{isbn|0-521-21838-1}}.
* {{aut|E. J. [[McCluskey]]}} 1965, ''Introduction to the Theory of Switching Circuits'', McGraw-Hill Book Company, New York. No ISBN. Library of Congress Catalog Card Number 65-17394. McCluskey was a student of [[Willard Quine]] and developed some notable theorems with Quine and on his own. For those interested in the history, the book contains a wealth of references.
* {{aut|[[Marvin L. Minsky]]}} 1967, ''Computation: Finite and Infinite Machines'', Prentice-Hall, Inc, Englewood Cliffs, N.J.. No ISBN. Library of Congress Catalog Card Number 67-12342. Useful especially for computability, plus good sources.
* {{aut|[[Paul C. Rosenbloom]]}} 1950, Dover edition 2005, ''The Elements of Mathematical Logic'', Dover Publications, Inc., Mineola, New York, {{isbn|0-486-44617-4}}.
* {{aut|[[Joel W. Robbin]]}} 1969, 1997, ''Mathematical Logic: A First Course'', Dover Publications, Inc., Mineola, New York, {{isbn|0-486-45018-X}} (pbk.).
* {{aut|[[Patrick Suppes]]}} 1957 (1999 Dover edition), ''Introduction to Logic'', Dover Publications, Inc., Mineola, New York. {{isbn|0-486-40687-3}} (pbk.). This book is in print and readily available.
* On his page 204 in a footnote he references his set of axioms to [[Edward Vermilye Huntington|E. V. Huntington]], "Sets of Independent Postulates for the Algebra of Logic", ''Transactions of the American Mathematical Society, Vol. 5 91904) pp. 288-309.
* {{aut|[[Alfred Tarski]]}} 1941 (1995 Dover edition), ''Introduction to Logic and to the Methodology of Deductive Sciences'', Dover Publications, Inc., Mineola, New York. {{isbn|0-486-28462-X}} (pbk.). This book is in print and readily available.
* {{aut|[[Jean van Heijenoort]]}} 1967, 3rd printing with emendations 1976, ''From Frege to Gödel: A Source Book in Mathematical Logic, 1879-1931'', Harvard University Press, Cambridge, Massachusetts. {{isbn|0-674-32449-8}} (pbk.) Translation/reprints of Frege (1879), Russell's letter to Frege (1902) and Frege's letter to Russell (1902), Richard's paradox (1905), Post (1921) can be found here.
* {{aut|[[Alfred North Whitehead]]}} and {{aut|[[Bertrand Russell]]}} 1927 2nd edition, paperback edition to *53 1962, ''Principia Mathematica'', Cambridge University Press, no ISBN. In the years between the first edition of 1912 and the 2nd edition of 1927, H. M. [[Sheffer]] 1921 and M. Jean [[Nicod]] (no year cited) brought to Russell's and Whitehead's attention that what they considered their primitive propositions (connectives) could be reduced to a single |, nowadays known as the "stroke" or NAND (NOT-AND, NEITHER ... NOR...). Russell-Whitehead discuss this in their "Introduction to the Second Edition" and makes the definitions as discussed above.
* {{aut|William E. Wickes}} 1968, ''Logic Design with Integrated Circuits'', John Wiley &amp; Sons, Inc., New York. No ISBN. Library of Congress Catalog Card Number: 68-21185. Tight presentation of engineering's analysis and synthesis methods, references McCluskey 1965. Unlike Suppes, Wickes' presentation of "Boolean algebra" starts with a set of postulates of a truth-table nature and then derives the customary theorems of them (p.&amp;nbsp;18ff).

{{Mathematical logic}}

{{DEFAULTSORT:Propositional Formula}}
[[Category:Propositional calculus]]
[[Category:Boolean algebra]]
[[Category:Statements]]
[[Category:Syntax (logic)]]
[[Category:Propositions]]
[[Category:Logical expressions]]</text>
      <sha1>48yey1798ivw9vypfgvkrilla9k040r</sha1>
    </revision>
  </page>
  <page>
    <title>Set theory</title>
    <ns>0</ns>
    <id>27553</id>
    <revision>
      <id>871235978</id>
      <parentid>869521903</parentid>
      <timestamp>2018-11-29T20:03:15Z</timestamp>
      <contributor>
        <username>Jflopezfernandez</username>
        <id>31649685</id>
      </contributor>
      <comment>Added reference to the arithmetic of set operations</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33161">{{otheruses4|the branch of mathematics|musical set theory|Set theory (music)}}
&lt;!-- Brief summary of article; talks about sets as collections of distinct objects, mentions that they have many uses in mathematics and that mathematics can be coded in set theory, and that enough of set theory can be axiomatized to do most of mathematics. Remains neutral on whether the subject is defined by its axioms or by its intended interpretation. If the antinomies are mentioned, should not assert that axiomatization is the solution, but should mention that some consider them to have been solved by axiomatization, others by the cumulative hierarchy.
--&gt;
[[Image:Venn A intersect B.svg|thumb|right|A [[Venn diagram]] illustrating the [[intersection (set theory)|intersection]] of two [[set (mathematics)|sets]].]]
'''Set theory''' is a branch of [[mathematical logic]] that studies [[Set (mathematics)|sets]], which informally are collections of objects. Although any type of object can be collected into a set, set theory is applied most often to objects that are relevant to mathematics. The language of set theory can be used to define nearly all [[mathematical object]]s.

The modern study of set theory was initiated by [[Georg Cantor]] and [[Richard Dedekind]] in the 1870s. After the discovery of [[Paradoxes of set theory|paradoxes]] in [[naive set theory]], such as [[Russell's paradox]], numerous [[Axiomatic system|axiom systems]] were proposed in the early [[twentieth century]], of which the [[Zermelo–Fraenkel set theory|Zermelo–Fraenkel axioms]], with or without the [[axiom of choice]], are the best-known.

Set theory is commonly employed as a [[Foundations of mathematics|foundational system for mathematics]], particularly in the form of Zermelo–Fraenkel set theory with the axiom of choice. Beyond its foundational role, set theory is a branch of [[mathematics]] in its own right, with an active research community. Contemporary research into set theory includes a diverse collection of topics, ranging from the structure of the [[real number]] line to the study of the [[consistency]] of [[large cardinal]]s.

==History==
[[File:Georg Cantor 1894.jpg|thumb|160px|[[Georg Cantor]].]]
Mathematical topics typically emerge and evolve through interactions among many researchers. Set theory, however, was founded by a single paper in 1874 by [[Georg Cantor]]: "[[On a Property of the Collection of All Real Algebraic Numbers]]".&lt;ref name="cantor1874"&gt;{{citation |first=Georg |last=Cantor|author-link=Georg Cantor |title=Ueber eine Eigenschaft des Inbegriffes aller reellen algebraischen Zahlen |journal=[[Journal für die reine und angewandte Mathematik|J. Reine Angew. Math.]] |volume=77 |year=1874 |issue= |pages=258–262 |url = http://www.digizeitschriften.de/main/dms/img/?PPN=GDZPPN002155583 |doi=10.1515/crll.1874.77.258 }}&lt;/ref&gt;&lt;ref&gt;{{citation |first=Philip |last=Johnson |year=1972 |title=A History of Set Theory |publisher=Prindle, Weber &amp; Schmidt |isbn=0-87150-154-6 }}&lt;/ref&gt;

Since the 5th century BC, beginning with [[Greek mathematics|Greek]] mathematician [[Zeno of Elea]] in the West and early [[Indian mathematics|Indian mathematicians]] in the East, mathematicians had struggled with the concept of [[infinity]]. Especially notable is the work of [[Bernard Bolzano]] in the first half of the 19th century.&lt;ref&gt;{{Citation|last=Bolzano|first=Bernard|author-link=Bernard Bolzano|editor-last=Berg|editor-first=Jan|title=Einleitung zur Größenlehre und erste Begriffe der allgemeinen Größenlehre|page=152|series=Bernard-Bolzano-Gesamtausgabe, edited by Eduard Winter et al.|volume=Vol. II, A, 7|publisher=Friedrich Frommann Verlag|location=Stuttgart, Bad Cannstatt|isbn=3-7728-0466-7|year=1975}}&lt;/ref&gt; Modern understanding of infinity began in 1870–1874 and was motivated by Cantor's work in [[real analysis]].&lt;ref&gt;{{Citation|last=Dauben|first=Joseph|author-link=Joseph Dauben|title=Georg Cantor: His Mathematics and Philosophy of the Infinite|publisher=Harvard University Press|year=1979|isbn=0-674-34871-0|pp=30-54}}.&lt;/ref&gt; An 1872 meeting between Cantor and [[Richard Dedekind]] influenced Cantor's thinking and culminated in Cantor's 1874 paper.

Cantor's work initially polarized the mathematicians of his day. While [[Karl Weierstrass]] and Dedekind supported Cantor, [[Leopold Kronecker]], now seen as a founder of [[mathematical constructivism]], did not. Cantorian set theory eventually became widespread, due to the utility of Cantorian concepts, such as [[one-to-one correspondence]] among sets, his proof that there are more [[real number]]s than integers, and the "infinity of infinities" ("[[Cantor's paradise]]") resulting from the [[power set]] operation. This utility of set theory led to the article "Mengenlehre" contributed in 1898 by [[Arthur Schoenflies]] to [[Klein's encyclopedia]].

The next wave of excitement in set theory came around 1900, when it was discovered that some interpretations of Cantorian set theory gave rise to several contradictions, called [[Antinomy|antinomies]] or [[Logical paradox|paradoxes]]. [[Bertrand Russell]] and [[Ernst Zermelo]] independently found the simplest and best known paradox, now called [[Russell's paradox]]: consider "the set of all sets that are not members of themselves", which leads to a contradiction since it must be a member of itself and not a member of itself. In 1899 Cantor had himself posed the question "What is the [[cardinal number]] of the set of all sets?", and obtained a related paradox. Russell used his paradox as a theme in his 1903 review of continental mathematics in his ''[[The Principles of Mathematics]]''.

In 1906 English readers gained the book ''Theory of Sets of Points''&lt;ref&gt;[[William Henry Young]] &amp; [[Grace Chisholm Young]] (1906) [https://archive.org/stream/theoryofsetsofpo00youniala#page/n3/mode/2up ''Theory of Sets of Points''], link from [[Internet Archive]]&lt;/ref&gt; by husband and wife [[William Henry Young]] and [[Grace Chisholm Young]], published by [[Cambridge University Press]].

The momentum of set theory was such that debate on the paradoxes did not lead to its abandonment. The work of [[Zermelo]] in 1908 and the work of [[Abraham Fraenkel]] and [[Thoralf Skolem]] in 1922 resulted in the set of axioms [[ZFC]], which became the most commonly used set of axioms for set theory. The work of [[real analysis|analysts]] such as [[Henri Lebesgue]] demonstrated the great mathematical utility of set theory, which has since become woven into the fabric of modern mathematics. Set theory is commonly used as a foundational system, although in some areas—such as algebraic geometry and algebraic topology—[[category theory]] is thought to be a preferred foundation.

==Basic concepts and notation==
{{Main|Set (mathematics)|Algebra of sets}}

Set theory begins with a fundamental [[binary relation]] between an object {{math|''o''}} and a set {{math|''A''}}. If {{math|''o''}} is a '''[[set membership|member]]''' (or '''element''') of {{math|''A''}}, the notation {{math|''o'' ∈ ''A''}} is used. Since sets are objects, the membership relation can relate sets as well.

A derived [[binary relation]] between two sets is the subset relation, also called '''set inclusion'''. If all the members of set {{math|''A''}} are also members of set {{math|''B''}}, then {{math|''A''}} is a '''[[subset]]''' of {{math|''B''}}, denoted {{math|''A'' ⊆ ''B''}}. For example, {{math|{1, 2} }} is a subset of {{math|{1, 2, 3} }}, and so is {{math|{2} }} but {{math|{1, 4} }} is not. As insinuated from this definition, a set is a subset of itself. For cases where this possibility is unsuitable or would make sense to be rejected, the term '''[[proper subset]]''' is defined. {{math|''A''}} is called a '''proper subset''' of {{math|''B''}} if and only if {{math|''A''}} is a subset of {{math|''B''}}, but {{math|''A''}} is not equal to {{math|''B''}}. Note also that 1, 2, and 3 are members (elements) of the set {{math|{1, 2, 3} }} but are not subsets of it; and in turn, the subsets, such as {1}, are not members of the set {1, 2, 3}.

Just as [[arithmetic]] features [[binary operation]]s on [[number]]s, set theory features binary operations on sets.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/1527264|title=Introductory real analysis|last=Kolmogorov|first=A.N.|date=1970|publisher=Dover Publications|others=Fomin, S. V.|year=1970|isbn=0486612260|edition=Rev. English ed|location=New York|pages=2-3|oclc=1527264}}&lt;/ref&gt; The:
*'''[[union (set theory)|Union]]''' of the sets {{math|''A''}} and {{math|''B''}}, denoted {{math|''A'' ∪ ''B''}}, is the set of all objects that are a member of {{math|''A''}}, or {{math|''B''}}, or both. The union of {{math|{1, 2, 3} }} and {{math|{2, 3, 4} }} is the set {{math|{1, 2, 3, 4} }}.
*'''[[intersection (set theory)|Intersection]]''' of the sets {{math|''A''}} and {{math|''B''}}, denoted {{math|''A'' ∩ ''B''}}, is the set of all objects that are members of both {{math|''A''}} and {{math|''B''}}. The intersection of {{math|{1, 2, 3} }} and {{math|{2, 3, 4} }} is the set {{math|{2, 3} }}.
*'''[[Set difference]]''' of {{math|''U''}} and {{math|''A''}}, denoted {{math|''U'' \ ''A''}}, is the set of all members of {{math|''U''}} that are not members of {{math|''A''}}. The set difference {{math|{1, 2, 3} \ {2, 3, 4} }} is {{math|{1} }}, while, conversely, the set difference {{math|{2, 3, 4} \ {1, 2, 3} }} is {{math|{4} }}. When {{math|''A''}} is a subset of {{math|''U''}}, the set difference {{math|''U'' \ ''A''}} is also called the '''[[complement (set theory)|complement]]''' of {{math|''A''}} in {{math|''U''}}. In this case, if the choice of {{math|''U''}} is clear from the context, the notation {{math|''A''&lt;sup&gt;''c''&lt;/sup&gt;}} is sometimes used instead of {{math|''U'' \ ''A''}}, particularly if {{math|''U''}} is a [[universal set]] as in the study of [[Venn diagram]]s.
*'''[[Symmetric difference]]''' of sets {{math|''A''}} and {{math|''B''}}, denoted {{math|''A'' △ ''B''}} or {{math|''A'' ⊖ ''B''}}, is the set of all objects that are a member of exactly one of {{math|''A''}} and {{math|''B''}} (elements which are in one of the sets, but not in both). For instance, for the sets {{math|{1, 2, 3} }} and {{math|{2, 3, 4} }}, the symmetric difference set is {{math|{1, 4} }}. It is the set difference of the union and the intersection, {{math|(''A'' ∪ ''B'') \ (''A'' ∩ ''B'')}} or {{math|(''A'' \ ''B'') ∪ (''B'' \ ''A'')}}.
*'''[[Cartesian product]]''' of {{math|''A''}} and {{math|''B''}}, denoted {{math|''A'' × ''B''}}, is the set whose members are all possible [[ordered pair]]s {{math|(''a'', ''b'')}} where {{math|''a''}} is a member of {{math|''A''}} and {{math|''b''}} is a member of {{math|''B''}}. The cartesian product of {{nowrap|1={1, 2} and {red, white} is {(1, red), (1, white), (2, red), (2, white)}.}}
*'''[[Power set]]''' of a set {{math|''A''}} is the set whose members are all of the possible subsets of {{math|''A''}}. For example, the power set of {{math|{1, 2} }} is {{math|{ {}, {1}, {2}, {1, 2} } }}.

Some basic sets of central importance are the [[empty set]] (the unique set containing no elements; occasionally called the ''null set'' though this name is ambiguous), the set of [[natural number]]s, and the set of [[real number]]s.

==Some ontology==
{{Main|von Neumann universe}}
[[Image:Von Neumann Hierarchy.svg|thumb|right|300px|An initial segment of the von Neumann hierarchy.]]

A set is [[pure set|pure]] if all of its members are sets, all members of its members are sets, and so on. For example, the set {{math|&lt;nowiki&gt;{{}}&lt;/nowiki&gt;}} containing only the empty set is a nonempty pure set. In modern set theory, it is common to restrict attention to the '''[[von Neumann universe]]''' of pure sets, and many systems of axiomatic set theory are designed to axiomatize the pure sets only. There are many technical advantages to this restriction, and little generality is lost, because essentially all mathematical concepts can be modeled by pure sets. Sets in the von Neumann universe are organized into a [[cumulative hierarchy]], based on how deeply their members, members of members, etc. are nested. Each set in this hierarchy is assigned (by [[transfinite recursion]]) an [[ordinal number]] α, known as its '''rank'''. The rank of a pure set X is defined to be the [[least upper bound]] of all [[Successor ordinal|successors]] of ranks of members of X. For example, the empty set is assigned rank 0, while the set {{math| &lt;nowiki&gt;{{}}&lt;/nowiki&gt; }} containing only the empty set is assigned rank 1. For each ordinal α, the set ''V''&lt;sub&gt;α&lt;/sub&gt; is defined to consist of all pure sets with rank less than α. The entire von Neumann universe is denoted&amp;nbsp;''V''.

==Axiomatic set theory==
Elementary set theory can be studied informally and intuitively, and so can be taught in primary schools using [[Venn diagram]]s. The intuitive approach tacitly assumes that a set may be formed from the class of all objects satisfying any particular defining condition. This assumption gives rise to paradoxes, the simplest and best known of which are [[Russell's paradox]] and the [[Burali-Forti paradox]]. Axiomatic set theory was originally devised to rid set theory of such paradoxes.&lt;ref&gt;In his 1925, [[John von Neumann]] observed that "set theory in its first, "naive" version, due to Cantor, led to contradictions. These are the well-known [[antinomy|antinomies]] of the set of all sets that do not contain themselves (Russell), of the set of all transfinte ordinal numbers (Burali-Forti), and the set of all finitely definable real numbers (Richard)." He goes on to observe that two "tendencies" were attempting to "rehabilitate" set theory. Of the first effort, exemplified by [[Bertrand Russell]], [[Julius König]], [[Hermann Weyl]] and [[L. E. J. Brouwer]], von Neumann called the "overall effect of their activity . . . devastating". With regards to the axiomatic method employed by second group composed of [[Zermelo]], [[Abraham Fraenkel]] and [[Arthur Moritz Schoenflies]], von Neumann worried that "We see only that the known modes of inference leading to the antinomies fail, but who knows where there are not others?" and he set to the task, "in the spirit of the second group", to "produce, by means of a finite number of purely formal operations . . . all the sets that we want to see formed" but not allow for the antinomies. (All quotes from von Neumann 1925 reprinted in van Heijenoort, Jean (1967, third printing 1976), ''From Frege to Gödel: A Source Book in Mathematical Logic, 1879–1931'', Harvard University Press, Cambridge MA, {{isbn|0-674-32449-8}} (pbk). A synopsis of the history, written by van Heijenoort, can be found in the comments that precede von Neumann's 1925.&lt;/ref&gt;

The most widely studied systems of axiomatic set theory imply that all sets form a [[cumulative hierarchy]]. Such systems come in two flavors, those whose [[ontology]] consists of:
*''Sets alone''. This includes the most common axiomatic set theory, '''[[Zermelo–Fraenkel set theory]] (ZFC)''', which includes the [[axiom of choice]]. Fragments of ZFC include:
** [[Zermelo set theory]], which replaces the [[axiom schema of replacement]] with that of [[axiom schema of separation|separation]];
** [[General set theory]], a small fragment of [[Zermelo set theory]] sufficient for the [[Peano axioms]] and [[finite set]]s;
** [[Kripke–Platek set theory]], which omits the axioms of infinity, [[axiom of power set|powerset]], and [[axiom of choice|choice]], and weakens the axiom schemata of [[axiom schema of separation|separation]] and [[axiom schema of replacement|replacement]].
*''Sets and [[proper class]]es''. These include [[Von Neumann–Bernays–Gödel set theory]], which has the same strength as [[ZFC]] for theorems about sets alone, and [[Morse–Kelley set theory]] and [[Tarski–Grothendieck set theory]], both of which are stronger than ZFC.
The above systems can be modified to allow '''[[urelement]]s''', objects that can be members of sets but that are not themselves sets and do not have any members.

The systems of '''[[New Foundations]] NFU''' (allowing [[urelement]]s) and '''NF''' (lacking them) are not based on a cumulative hierarchy. NF and NFU include a "set of everything, " relative to which every set has a complement. In these systems urelements matter, because NF, but not NFU, produces sets for which the [[axiom of choice]] does not hold.

Systems of [[constructive set theory]], such as CST, CZF, and IZF, embed their set axioms in [[intuitionistic logic|intuitionistic]] instead of [[classical logic]]. Yet other systems accept classical logic but feature a nonstandard membership relation. These include [[Rough set|rough set theory]] and [[fuzzy set theory]], in which the value of an [[atomic formula]] embodying the membership relation is not simply '''True''' or '''False'''. The [[Boolean-valued model]]s of [[ZFC]] are a related subject.

An enrichment of [[ZFC]] called [[internal set theory]] was proposed by [[Edward Nelson]] in 1977.

==Applications==
Many mathematical concepts can be defined precisely using only set theoretic concepts. For example, mathematical structures as diverse as [[graph (discrete mathematics)|graph]]s, [[manifolds]], [[ring (mathematics)|rings]], and [[vector space]]s can all be defined as sets satisfying various (axiomatic) properties. [[equivalence relation|Equivalence]] and [[order relation]]s are ubiquitous in mathematics, and the theory of mathematical [[relation (mathematics)|relations]] can be described in set theory.

Set theory is also a promising foundational system for much of mathematics. Since the publication of the first volume of ''[[Principia Mathematica]]'', it has been claimed that most or even all mathematical theorems can be derived using an aptly designed set of axioms for set theory, augmented with many definitions, using [[first order logic|first]] or [[second order logic]]. For example, properties of the [[natural number|natural]] and [[real number]]s can be derived within set theory, as each number system can be identified with a set of [[equivalence class]]es under a suitable [[equivalence relation]] whose field is some [[infinite set]].

Set theory as a foundation for [[mathematical analysis]], [[topology]], [[abstract algebra]], and [[discrete mathematics]] is likewise uncontroversial; mathematicians accept that (in principle) theorems in these areas can be derived from the relevant definitions and the axioms of set theory. Few full derivations of complex mathematical theorems from set theory have been formally verified, however, because such formal derivations are often much longer than the natural language proofs mathematicians commonly present. One verification project, [[Metamath]], includes human-written, computer‐verified derivations of more than 12,000 theorems starting from [[ZFC]] set theory, [[first order logic]] and [[propositional logic]].

==Areas of study==
Set theory is a major area of research in mathematics, with many interrelated subfields.

===Combinatorial set theory===
{{Main|Infinitary combinatorics}}

'''Combinatorial set theory''' concerns extensions of finite [[combinatorics]] to infinite sets. This includes the study of [[cardinal arithmetic]] and the study of extensions of [[Ramsey's theorem]] such as the [[Erdős–Rado theorem]].

===Descriptive set theory===
{{Main|Descriptive set theory}}

'''Descriptive set theory''' is the study of subsets of the [[real line]] and, more generally, subsets of [[Polish space]]s. It begins with the study of [[pointclass]]es in the [[Borel hierarchy]] and extends to the study of more complex hierarchies such as the [[projective hierarchy]] and the [[Wadge hierarchy]]. Many properties of [[Borel set]]s can be established in ZFC, but proving these properties hold for more complicated sets requires additional axioms related to determinacy and large cardinals.

The field of [[effective descriptive set theory]] is between set theory and [[recursion theory]]. It includes the study of [[lightface pointclass]]es, and is closely related to [[hyperarithmetical theory]]. In many cases, results of classical descriptive set theory have effective versions; in some cases, new results are obtained by proving the effective version first and then extending ("relativizing") it to make it more broadly applicable.

A recent area of research concerns [[Borel equivalence relation]]s and more complicated definable [[equivalence relation]]s. This has important applications to the study of [[invariant (mathematics)|invariants]] in many fields of mathematics.

===Fuzzy set theory===
{{Main|Fuzzy set theory}}

In set theory as [[Georg Cantor|Cantor]] defined and [[Zermelo]] and [[Fraenkel]] axiomatized, an object is either a member of a set or not. In [[fuzzy set theory]] this condition was relaxed by [[Lotfi A. Zadeh]] so an object has a ''degree of membership'' in a set, a number between 0 and 1. For example, the degree of membership of a person in the set of "tall people" is more flexible than a simple yes or no answer and can be a real number such as 0.75.

===Inner model theory===
{{Main|Inner model theory}}

An '''inner model''' of Zermelo–Fraenkel set theory (ZF) is a transitive [[proper class|class]] that includes all the ordinals and satisfies all the axioms of ZF. The canonical example is the [[constructible universe]] ''L'' developed by Gödel.
One reason that the study of inner models is of interest is that it can be used to prove consistency results. For example, it can be shown that regardless of whether a model ''V'' of ZF satisfies the [[continuum hypothesis]] or the [[axiom of choice]], the inner model ''L'' constructed inside the original model will satisfy both the generalized continuum hypothesis and the axiom of choice. Thus the assumption that ZF is consistent (has at least one model) implies that ZF together with these two principles is consistent.

The study of inner models is common in the study of [[axiom of determinacy|determinacy]] and [[large cardinal]]s, especially when considering axioms such as the axiom of determinacy that contradict the axiom of choice. Even if a fixed model of set theory satisfies the axiom of choice, it is possible for an inner model to fail to satisfy the axiom of choice. For example, the existence of sufficiently large cardinals implies that there is an inner model satisfying the axiom of determinacy (and thus not satisfying the axiom of choice).&lt;ref&gt;{{Citation | last1=Jech | first1=Thomas | author1-link=Thomas Jech | title=Set Theory | edition=Third Millennium | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Springer Monographs in Mathematics | isbn=978-3-540-44085-7 | year=2003 | zbl=1007.03002 | page=642 }}&lt;/ref&gt;

===Large cardinals===
{{Main|Large cardinal property}}

A '''large cardinal''' is a cardinal number with an extra property. Many such properties are studied, including [[inaccessible cardinal]]s, [[measurable cardinal]]s, and many more. These properties typically imply the cardinal number must be very large, with the existence of a cardinal with the specified property unprovable in Zermelo-Fraenkel set theory.

===Determinacy===
{{Main|Determinacy}}

'''Determinacy''' refers to the fact that, under appropriate assumptions, certain two-player games of perfect information are determined from the start in the sense that one player must have a winning strategy. The existence of these strategies has important consequences in descriptive set theory, as the assumption that a broader class of games is determined often implies that a broader class of sets will have a topological property. The [[axiom of determinacy]] (AD) is an important object of study; although incompatible with the axiom of choice, AD implies that all subsets of the real line are well behaved (in particular, measurable and with the perfect set property). AD can be used to prove that the [[Wadge degree]]s have an elegant structure.

===Forcing===
{{Main|Forcing (mathematics)}}

[[Paul Cohen (mathematician)|Paul Cohen]] invented the method of [[forcing (mathematics)|forcing]] while searching for a [[model theory|model]] of [[ZFC]] in which the [[continuum hypothesis]] fails, or a model of ZF in which the [[axiom of choice]] fails. Forcing adjoins to some given model of set theory additional sets in order to create a larger model with properties determined (i.e. "forced") by the construction and the original model. For example, Cohen's construction adjoins additional subsets of the [[natural number]]s without changing any of the [[cardinal number]]s of the original model. Forcing is also one of two methods for proving [[consistency (mathematical logic)|relative consistency]] by finitistic methods, the other method being [[Boolean-valued model]]s.

===Cardinal invariants===
{{Main|Cardinal invariant}}

A '''cardinal invariant''' is a property of the real line measured by a cardinal number. For example, a well-studied invariant is the smallest cardinality of a collection of [[meagre set]]s of reals whose union is the entire real line. These are invariants in the sense that any two isomorphic models of set theory must give the same cardinal for each invariant. Many cardinal invariants have been studied, and the relationships between them are often complex and related to axioms of set theory.

===Set-theoretic topology===
{{Main|Set-theoretic topology}}

'''Set-theoretic topology''' studies questions of [[general topology]] that are set-theoretic in nature or that require advanced methods of set theory for their solution. Many of these theorems are independent of ZFC, requiring stronger axioms for their proof. A famous problem is the [[Moore space (topology)|normal Moore space question]], a question in general topology that was the subject of intense research. The answer to the normal Moore space question was eventually proved to be independent of ZFC.

==Objections to set theory as a foundation for mathematics==
From set theory's inception, some mathematicians [[controversy over Cantor's theory|have objected to it]] as a [[foundations of mathematics|foundation for mathematics]]. The most common objection to set theory, one [[Leopold Kronecker|Kronecker]] voiced in set theory's earliest years, starts from the [[mathematical constructivism|constructivist]] view that mathematics is loosely related to computation. If this view is granted, then the treatment of infinite sets, both in [[naive set theory|naive]] and in axiomatic set theory, introduces into mathematics methods and objects that are not computable even in principle. The feasibility of constructivism as a substitute foundation for mathematics was greatly increased by [[Errett Bishop]]'s influential book ''Foundations of Constructive Analysis''.&lt;ref&gt;Bishop, Errett 1967. ''Foundations of Constructive Analysis'', New York: Academic Press. {{isbn|4-87187-714-0}}&lt;/ref&gt;

A different objection put forth by [[Henri Poincaré]] is that defining sets using the axiom schemas of [[Axiom schema of specification|specification]] and [[Axiom schema of replacement|replacement]], as well as the axiom of [[Axiom of power set|power set]], introduces [[impredicativity]], a type of [[Circular definition|circularity]], into the definitions of mathematical objects. The scope of predicatively founded mathematics, while less than that of the commonly accepted Zermelo-Fraenkel theory, is much greater than that of constructive mathematics, to the point that [[Solomon Feferman]] has said that "all of scientifically applicable analysis can be developed [using predicative methods]".&lt;ref&gt;Solomon Feferman, 1998, In the Light of Logic, Oxford Univ. Press (New York), p.280-283 and 293-294&lt;/ref&gt;

[[Ludwig Wittgenstein]] condemned set theory. He wrote that "set theory is wrong", since it builds on the "nonsense" of fictitious symbolism, has "pernicious idioms", and that it is nonsensical to talk about "all numbers".&lt;ref&gt;{{cite book |last=Wittgenstein |first=Ludwig |year=1975 |title=Philosophical Remarks, §129, §174 |publisher=Oxford: Basil Blackwell |isbn=0631191305 }}&lt;/ref&gt; Wittgenstein's views about the foundations of mathematics were later criticised by [[Georg Kreisel]] and [[Paul Bernays]], and investigated by [[Crispin Wright]], among others.

[[category theory|Category theorists]] have proposed [[topos theory]] as an alternative to traditional axiomatic set theory. Topos theory can interpret various alternatives to that theory, such as [[mathematical constructivism|constructivism]], finite set theory, and [[Turing Machine|computable]] set theory.&lt;ref&gt;{{citation |last=Ferro |first=A. |last2=Omodeo |first2=E. G. |last3=Schwartz |first3=J. T. |year=1980 |title=Decision procedures for elementary sublanguages of set theory. I. Multi-level syllogistic and some extensions |journal=[[Communications on Pure and Applied Mathematics|Comm. Pure Appl. Math.]] |volume=33 |issue=5 |pages=599–608 |doi=10.1002/cpa.3160330503 }}&lt;/ref&gt;&lt;ref&gt;{{citation |last=Cantone |first=D. |last2=Ferro |first2=A. |last3=Omodeo |first3=E. G. |title=Computable Set Theory | publisher=[[Clarendon Press]] | location=Oxford, UK |series=International Series of Monographs on Computer Science, Oxford Science Publications | isbn=0-19-853807-3 | year=1989 | page=xii, 347 }}&lt;/ref&gt; Topoi also give a natural setting for forcing and discussions of the independence of choice from ZF, as well as providing the framework for [[pointless topology]] and [[Stone space]]s.&lt;ref&gt;[[Saunders Mac Lane]] and Ieke Moerdijk (1992) ''Sheaves in Geometry and Logic: a First Introduction to Topos Theory''. Springer Verlag.&lt;/ref&gt;

An active area of research is the [[univalent foundations]] and related to it [[homotopy type theory]]. Within homotopy type theory, a set may be regarded as a homotopy 0-type, with [[universal properties]] of sets arising from the inductive and recursive properties of [[higher inductive type]]s. Principles such as the [[axiom of choice]] and the [[law of the excluded middle]] can be formulated in a manner corresponding to the classical formulation in set theory or perhaps in a spectrum of distinct ways unique to type theory. Some of these principles may be proven to be a consequence of other principles. The variety of formulations of these axiomatic principles allows for a detailed analysis of the formulations required in order to derive various mathematical results.&lt;ref&gt;{{nlab|id=homotopy+type+theory|title=homotopy type theory}}&lt;/ref&gt;&lt;ref&gt;[http://homotopytypetheory.org/book/ ''Homotopy Type Theory: Univalent Foundations of Mathematics'']. The Univalent Foundations Program. [[Institute for Advanced Study]].&lt;/ref&gt;

==See also==
{{Portal|Set theory|Mathematics}}
* [[Glossary of set theory]]
* [[Category theory]]
* [[List of set theory topics]]
* [[Relational model]]&amp;nbsp;– borrows from set theory

==Notes==
{{Reflist}}

==Further reading==
* [[Keith Devlin|Devlin, Keith]], 1993. ''The Joy of Sets'' (2nd ed.). Springer Verlag, {{isbn|0-387-94094-4}}
* Ferreirós, Jose, 2007 (1999). ''Labyrinth of Thought: A history of set theory and its role in modern mathematics''. Basel, Birkhäuser. {{isbn|978-3-7643-8349-7}}
* Johnson, Philip, 1972. ''A History of Set Theory''. Prindle, Weber &amp; Schmidt {{isbn|0-87150-154-6}}
* [[Kenneth Kunen|Kunen, Kenneth]], 1980. ''[[Set Theory: An Introduction to Independence Proofs]]''. North-Holland, {{isbn|0-444-85401-0}}.
* Potter, Michael, 2004. ''Set Theory and Its Philosophy: A Critical Introduction''. [[Oxford University Press]].
* Tiles, Mary, 2004 (1989). ''The Philosophy of Set Theory: An Historical Introduction to Cantor's Paradise''. [[Dover Publications]]. {{isbn|978-0-486-43520-6}}
* Raymond M. Smullyan, Melvin Fitting, 2010, ''Set Theory And The Continuum Problem''. Dover Publications {{isbn|978-0-486-47484-7}}. Complete foundation in modern set theory with an emphasis on mathematical logic.

==External links==
{{Wikibooks|Set Theory}}
{{Wikibooks|Discrete mathematics/Set theory}}
* [[Matthew Foreman|Foreman, Matthew]], [[Akihiro Kanamori]], eds. ''[http://handbook.assafrinot.com/ Handbook of Set Theory.]'' 3 vols., 2010. Each chapter surveys some aspect of contemporary research in set theory. Does not cover established elementary set theory, on which see Devlin (1993).
* {{Springer |title=Axiomatic set theory |id=p/a014310}}
* {{Springer |title=Set theory |id=p/s084750}}
* [[Thomas Jech|Jech, Thomas]] (2002). "[http://plato.stanford.edu/entries/set-theory/ Set Theory]", ''Stanford Encyclopedia of Philosophy''.
* [[Arthur Schoenflies|Schoenflies, Arthur]] (1898). [https://archive.org/stream/encyklomath101encyrich#page/n229 Mengenlehre] in [[Klein's encyclopedia]].
* {{Library resources about |onlinebooks=yes |lcheading=Set theory |label=set theory}}

{{Set theory |expanded}}&lt;!--Keep first (eponymous template)--&gt;
{{Areas of mathematics |collapsed}}
{{Mathematical logic}}
{{Computer science}}

{{Authority control}}

[[Category:Set theory| ]]&lt;!--Keep first (eponymous category)--&gt;
[[Category:Mathematical logic| S]]
[[Category:Formal methods]]
[[Category:Georg Cantor]]</text>
      <sha1>q0cwmqwokct1uh96etbhn19r9fpqx6o</sha1>
    </revision>
  </page>
  <page>
    <title>Slow-growing hierarchy</title>
    <ns>0</ns>
    <id>25264092</id>
    <revision>
      <id>772371476</id>
      <parentid>742852337</parentid>
      <timestamp>2017-03-26T22:07:02Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* References */ [[Jean Gallier]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5996">In [[computability theory]], [[computational complexity theory]] and [[proof theory]], the '''slow-growing hierarchy''' is an ordinal-indexed family of slowly increasing functions ''g''&lt;sub&gt;α&lt;/sub&gt;: '''N''' → '''N''' (where '''N''' is the set of [[natural numbers]], {0, 1, ...}). It contrasts with the [[fast-growing hierarchy]].

== Definition ==
Let μ be a [[large countable ordinal]] such that a [[fundamental sequence (ordinals)|fundamental sequence]] is assigned to every [[limit ordinal]] less than μ.  The '''slow-growing hierarchy''' of functions ''g''&lt;sub&gt;α&lt;/sub&gt;: '''N''' → '''N''', for α &lt; μ, is then defined as follows:

*&lt;math&gt; g_0(n) = 0 &lt;/math&gt;
*&lt;math&gt; g_{k+1}(n) = g_k(n) + 1 &lt;/math&gt;
*&lt;math&gt; g_\alpha(n) = g_{\alpha[n]}(n)&lt;/math&gt; for limit ordinal α.

Here α[''n''] denotes the ''n''&lt;sup&gt;th&lt;/sup&gt; element of the fundamental sequence assigned to the limit ordinal α.

The article on the [[Fast-growing hierarchy#Definition|Fast-growing hierarchy]] describes a standardized choice for fundamental sequence for all α &lt; ε&lt;sub&gt;0&lt;/sub&gt;.

== Relation to fast-growing hierarchy ==
The slow-growing hierarchy grows much more slowly than the fast-growing hierarchy. Even ''g''&lt;sub&gt;[[epsilon zero (mathematics)|ε&lt;sub&gt;0&lt;/sub&gt;]]&lt;/sub&gt; is only equivalent to ''f''&lt;sub&gt;3&lt;/sub&gt; and ''g''&lt;sub&gt;α&lt;/sub&gt; only attains the growth of ''f''&lt;sub&gt;ε&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; (the first function that [[Peano arithmetic]] cannot prove [[total function|total]] in the hierarchy) when α is the [[Bachmann–Howard ordinal]].&lt;ref name="girard81"&gt;{{Cite journal | last1=Girard | first1=Jean-Yves | author1-link=Jean-Yves Girard | title=Π&lt;sup&gt;1&lt;/sup&gt;&lt;sub&gt;2&lt;/sub&gt;-logic. I. Dilators | doi=10.1016/0003-4843(81)90016-4 | mr=656793 | year=1981 | journal=Annals of Mathematical Logic | issn=0003-4843 | volume=21 | issue=2 | pages=75–219 | postscript={{inconsistent citations}}}}&lt;/ref&gt;&lt;ref name="cichon"&gt;{{cite book|last=Cichon|title=Proof Theory|year=1992|publisher=Cambridge University Press|pages=173–193|editor1=P. Aczel |editor2=H. Simmons |editor3=S. Wainer |chapter=Termination Proofs and Complexity Characterisations}}&lt;/ref&gt;&lt;ref name="wainer83"&gt;{{Cite journal | last1=Cichon | first1=E. A. | last2=Wainer | first2=S. S. | title=The slow-growing and the Grzegorczyk hierarchies | doi=10.2307/2273557 | mr=704094 | year=1983 | journal=The Journal of Symbolic Logic | issn=0022-4812 | volume=48 | issue=2 | pages=399–408 | postscript={{inconsistent citations}}}}&lt;/ref&gt;

However, Girard proved that the slow-growing hierarchy eventually ''catches up'' with the fast-growing one.&lt;ref name="girard81" /&gt; Specifically, that there exists an ordinal α such that for all integers ''n''
:''g''&lt;sub&gt;α&lt;/sub&gt;(''n'') &lt; ''f''&lt;sub&gt;α&lt;/sub&gt;(''n'') &lt; ''g''&lt;sub&gt;α&lt;/sub&gt;(''n'' + 1)
where ''f''&lt;sub&gt;α&lt;/sub&gt; are the functions in the fast-growing hierarchy. He further showed that the first α this holds for is the ordinal of the theory ''ID''&lt;sub&gt;&lt;ω&lt;/sub&gt; of arbitrary finite iterations of an inductive definition.&lt;ref name="wainer89"&gt;{{cite journal |jstor=2274873 |pages=608–614 |last1=Wainer |first1=S. S. |title=Slow Growing Versus Fast Growing |volume=54 |issue=2 |journal=The Journal of Symbolic Logic |year=1989 |doi=10.2307/2274873}}&lt;/ref&gt; However, for the assignment of fundamental sequences found in &lt;ref name="cichon" /&gt; the first match up occurs at the level ε&lt;sub&gt;0&lt;/sub&gt;.&lt;ref name="weier1997"&gt;{{cite journal |doi=10.1016/S0168-0072(97)00033-X |title=Sometimes slow growing is fast growing |year=1997 |last1=Weiermann |first1=A |journal=Annals of Pure and Applied Logic |volume=90 |pages=91}}&lt;/ref&gt; For Buchholz style tree ordinals it could be shown that the first match up even occurs at &lt;math&gt;\omega^2&lt;/math&gt;.

Extensions of the result proved&lt;ref name="wainer89" /&gt; to considerably larger ordinals show that there are very few ordinals below the ordinal of transfinitely iterated &lt;math&gt;\Pi^1_1&lt;/math&gt;-comprehension where the slow- and fast-growing hierarchy match up.&lt;ref name="weier1995"&gt;{{cite journal |last=Weiermann |first=A. |year=1995 |title= |journal=Archives of Mathematical Logic |volume= 34 |pages=313–330 |doi= }}&lt;/ref&gt;

The slow-growing hierarchy depends extremely sensitively on the choice of the underlying fundamental sequences.&lt;ref name="weier1997" /&gt;&lt;ref name="weier1999"&gt;Weiermann, A. (1999), [https://books.google.com/books?id=2IHm3RT2bBoC&amp;lpg=PP1&amp;pg=PA403#v=onepage&amp;q=&amp;f=false "What makes a (pointwise) subrecursive hierarchy slow growing?"] Cooper, S. Barry (ed.) et al., Sets and proofs. Invited papers from the Logic colloquium '97, European meeting of the Association for Symbolic Logic, Leeds, UK, July 6–13, 1997. Cambridge: Cambridge University Press. Lond. Math. Soc. Lect. Note Ser. 258; 403-423.&lt;/ref&gt;&lt;ref name="weier2001" /&gt;&lt;ref name="weier2001"&gt;Weiermann, A. (2001)
$\Gamma_0$ may be minimal subrecursively inaccessible. Mathematical Logic Quarterly 47 (2001) 397-408.&lt;/ref&gt;

== Relation to term rewriting ==
Cichon provided an interesting connection between the slow-growing hierarchy and derivation length for term rewriting.&lt;ref name="cichon" /&gt;

== References ==

*{{Cite journal|mr=1129778|last= Gallier|first= Jean H.|authorlink= Jean Gallier |title= What's so special about Kruskal's theorem and the ordinal Γ&lt;sub&gt;0&lt;/sub&gt;? A survey of some results in proof theory|journal=  Ann. Pure Appl. Logic|volume=  53  |year=1991|issue=  3|pages= 199–260|url=http://stinet.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA290387|doi=10.1016/0168-0072(91)90022-E|postscript={{inconsistent citations}}}} PDF's: [ftp://ftp.cis.upenn.edu/pub/papers/gallier/kruskal1.pdf part 1] [ftp://ftp.cis.upenn.edu/pub/papers/gallier/kruskal2.pdf 2] [ftp://ftp.cis.upenn.edu/pub/papers/gallier/kruskal3.pdf 3]. (In particular part 3, Section 12, pp.&amp;nbsp;59–64, "A Glimpse at Hierarchies of Fast and Slow Growing Functions".)

== Notes ==
&lt;references /&gt;

[[Category:Computability theory]]
[[Category:Proof theory]]
[[Category:Hierarchy of functions]]</text>
      <sha1>2u0mi7kfmpvi8wd4hb0vjk3904bcnqz</sha1>
    </revision>
  </page>
  <page>
    <title>Strangulated graph</title>
    <ns>0</ns>
    <id>36971277</id>
    <revision>
      <id>785983631</id>
      <parentid>785983080</parentid>
      <timestamp>2017-06-16T15:36:42Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* See also */ odd</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2743">[[File:Strangulated graph.svg|thumb|330px|A strangulated graph, formed by using [[clique-sum]]s to glue together a [[Planar graph|maximal planar graph]] (yellow) and two [[chordal graph]]s (red and blue). The red chordal graph can in turn be decomposed into clique-sums of four maximal planar graphs (two edges and two triangles).]]
In [[graph theory|graph theoretic mathematics]], a '''strangulated graph''' is a graph in which deleting the edges of any [[induced cycle]] of length greater than three would [[connected graph|disconnect]] the remaining graph. That is, they are the graphs in which every [[peripheral cycle]] is a triangle.

==Examples==
In a [[maximal planar graph]], or more generally in every [[polyhedral graph]], the peripheral cycles are exactly the faces of a planar embedding of the graph, so a polyhedral graph is strangulated if and only if all the faces are triangles, or equivalently it is maximal planar. Every [[chordal graph]] is strangulated, because the only induced cycles in chordal graphs are triangles, so there are no longer cycles to delete.

==Characterization==
A [[clique-sum]] of two graphs is formed by identifying together two equal-sized [[clique (graph theory)|cliques]] in each graph, and then possibly deleting some of the clique edges. For the version of clique-sums relevant to strangulated graphs, the edge deletion step is omitted. A clique-sum of this type between two strangulated graphs results in another strangulated graph, for every long induced cycle in the sum must be confined to one side or the other (otherwise it would have a chord between the vertices at which it crossed from one side of the sum to the other), and the disconnected parts of that side formed by deleting the cycle must remain disconnected in the clique-sum. Every chordal graph can be decomposed in this way into a clique-sum of [[complete graph]]s, and every maximal planar graph can be decomposed into a clique-sum of [[k-vertex-connected graph|4-vertex-connected]] maximal planar graphs.

As {{harvtxt|Seymour|Weaver|1984}} show, these are the only possible building blocks of strangulated graphs: the strangulated graphs are exactly the graphs that can be formed as clique-sums of complete graphs and maximal planar graphs.

==See also==
*[[Line perfect graph]], a graph in which every odd cycle is a triangle

==References==
*{{citation
 | last1 = Seymour | first1 = P. D. | author1-link = Paul Seymour (mathematician)
 | last2 = Weaver | first2 = R. W.
 | doi = 10.1002/jgt.3190080206
 | issue = 2
 | journal = Journal of Graph Theory
 | mr = 742878
 | pages = 241–251
 | title = A generalization of chordal graphs
 | volume = 8
 | year = 1984}}.

[[Category:Graph families]]
[[Category:Planar graphs]]</text>
      <sha1>pvmyfs3mey5a735k9c4n2b1x5mw16pf</sha1>
    </revision>
  </page>
  <page>
    <title>The Book of Squares</title>
    <ns>0</ns>
    <id>4688530</id>
    <revision>
      <id>863798751</id>
      <parentid>861648616</parentid>
      <timestamp>2018-10-13T03:31:45Z</timestamp>
      <contributor>
        <username>Seahawk01</username>
        <id>34873291</id>
      </contributor>
      <minor/>
      <comment>added category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2038">{{italic title}}
'''''The Book of Squares''''', '''''(Liber Quadratorum'''''&lt;ref&gt;Fibonacci, Leonardo Pisano . The Book of Squares (Liber Quadratorum). An annotated translation into modern English by L. E. Sigler. (1987) Orlando, FL: Academic Press. {{ISBN|978-0-12-643130-8}}&lt;/ref&gt; in the original [[Latin]]) is a book on [[algebra]] by [[Leonardo Fibonacci]], published in 1225. It was dedicated to [[Frederick II, Holy Roman Emperor]].&lt;ref&gt;{{Cite web|url=https://archive.org/stream/jstor-2974039/2974039_djvu.txt|title=Full text of "Leonardo of Pisa and his Liber Quadratorum"|website=archive.org|access-date=2016-10-04}}&lt;/ref&gt; [[Brahmagupta–Fibonacci identity|Fibonacci's identity]], establishing that the set of all sums of two squares is closed under multiplication, appears in it. The book anticipated the works of later mathematicians like [[Pierre de Fermat|Fermat]] and [[Leonhard Euler|Euler]].&lt;ref&gt;Berlinghoff, William P. and [[Fernando Q. Gouvêa]] (2004). ''Math through the ages: a gentle history for teachers and others''. MAA, p. 34. {{ISBN|0-88385-736-7}}&lt;/ref&gt; The book examines several topics in [[number theory]],&lt;ref&gt;McClenon, R. B., "Leonardo of Pisa and his Liber Quadratorum", ''American Mathematical Monthly'', Vol. 26, No. 1, January 1919, pp. 1–8.&lt;/ref&gt; among them an inductive method for finding [[Pythagorean triple]]s based on the sequence of odd integers, the fact that the sum of the first &lt;math&gt;n&lt;/math&gt; odd integers is &lt;math&gt;n^2&lt;/math&gt;, and the solution to the [[Congruum|congruum problem]].

==Notes==
{{reflist}}

==External links==
*[https://web.archive.org/web/20070930014601/http://mathdl.maa.org/convergence/1/?pa=content&amp;sa=viewDocument&amp;nodeId=1296&amp;bodyId=1433 Fibonacci and Square Numbers] at [http://www.maa.org/press/periodicals/convergence/fibonacci-and-square-numbers-introduction]

{{Fibonacci}}

{{DEFAULTSORT:Book of squaress}}
[[Category:1225 books]]
[[Category:13th-century Latin books]]
[[Category:Mathematics books]]
[[Category:Squares in number theory]]


{{mathematics-lit-stub}}</text>
      <sha1>3oxm9if44ate020k0jba0lv0tsyyaj6</sha1>
    </revision>
  </page>
  <page>
    <title>The Code (2011 TV series)</title>
    <ns>0</ns>
    <id>32542924</id>
    <revision>
      <id>846672524</id>
      <parentid>845716782</parentid>
      <timestamp>2018-06-20T06:24:51Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v485)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7817">{{Use British English|date=May 2015}}
{{about|the documentary film on mathematics broadcast on [[BBC Two]]|the Australian television fictional drama series, ''The Code'' broadcast on [[BBC Four]]|The Code (2014 TV series)}}
{{Use dmy dates|date=December 2012}}
{{Infobox television
| show_name            = The Code
| image                = &lt;!-- include ALT text per [[WP:ALT]] guideline --&gt;
| caption              = 
| show_name_2          = 
| genre                = [[Mathematics]] [[Documentary film|documentary]]
| creator              = 
| developer            = 
| writer               = 
| director             = Stephen Cooter&lt;br /&gt;Michael Lachmann
| creative_director    = 
| presenter            = [[Marcus du Sautoy]]
| starring             = 
| judges               = 
| voices               = 
| narrated             = 
| theme_music_composer = 
| opentheme            = 
| endtheme             = 
| composer             = Carl Harms
| country              = United Kingdom
| language             = English
| num_series           = 1
| num_episodes         = 3
| list_episodes        = 
| executive_producer   = Sacha Baveystock
| producer             = Stephen Cooter&lt;br /&gt;Peter Leonard
| editor               = 
| location             = 
| cinematography       = 
| camera               = 
| runtime              = 60 minutes
| company              = [[Open University|The Open University]] for [[BBC]]
| distributor          = 
| channel              = [[BBC Two]]
| picture_format       = [[16:9]] [[1080i]]
| audio_format         = [[Stereophonic sound|Stereo]]
| first_run            = 
| first_aired          = {{Start date|2011|7|27|df=y}}
| last_aired           = {{End date|2011|8|10|df=y}}
| preceded_by          = 
| followed_by          = 
| related              = 
| website              = http://www.bbc.co.uk/programmes/b00zs6sl
| website_title        = Official website
| production_website   = 
}}

'''''The Code''''' is a [[mathematics]]-based [[Documentary film|documentary]] for [[BBC Two]] presented by [[Marcus du Sautoy]], beginning on 27 July 2011 and ended on 10 August 2011. Each episode covers a different branch of mathematics. As well as being a documentary, ''The Code'' is also a series of online challenges forming a [[Treasure hunt (game)|treasure hunt]], with clues to finding the treasure being included in the episodes, online games and other challenges.&lt;ref name="FAQ"&gt;{{cite web|url=https://www.bbc.co.uk/tv/features/code/about/faq|title=The Code: Frequently Asked Questions|publisher=[[BBC]]|accessdate=26 July 2011}}&lt;/ref&gt;

==Episodes==
{{Episode table |background=#DEDDE2 |overall=|title= |airdate= |episodes=
{{Episode list
 |EpisodeNumber=1
 |Title=Numbers
 |OriginalAirDate={{Start date|2011|7|27|df=y}}
 |ShortSummary=Du Sautoy reveals a hidden numerical code that underpins all nature. A code that has the power to explain everything, from the numbers and shapes we see all around us to the rules that govern our own lives. In this first episode, he reveals how significant numbers appear throughout the natural world. They're part of a hidden mathematical world that contains the rules that govern everything on our planet and beyond.&lt;ref name="About"&gt;{{cite web|url=http://www.bbc.co.uk/programmes/b012xppj|title=The Code: Numbers|publisher=[[BBC]]|accessdate=26 July 2011}}&lt;/ref&gt;
 |LineColor=DEDDE2
}}
{{ Episode list
 |EpisodeNumber=2
 |Title=Shapes
 |OriginalAirDate={{Start date|2011|8|3|df=y}}
 |ShortSummary=Du Sautoy searches for natural patterns, beginning with the hexagonal columns of [[Northern Ireland]]'s [[Giant's Causeway]], and moving on to everything from honeycombs to soap bubbles, claiming such formations are far from random but part of a hidden code that governs the world. He also applies the theory to mountains, clouds and trees, and reveals how it could have helped in the creation of movie animations - with a visit to the [[Pixar]] studios - and abstract paintings.
 |LineColor=DEDDE2
}}
{{ Episode list
 |EpisodeNumber=3
 |Title=Prediction
 |OriginalAirDate={{Start date|2011|8|10|df=y}}
 |ShortSummary=Du Sautoy looks at what happens next. He looks at the ability to predict a [[lunar eclipse]], overturns the [[lemming]]'s suicidal reputation, avoids being crushed to death, reveals how to catch a serial killer and discovers that the [[answer to life, the universe and everything]] isn't 42 after all - it's 1.15.
 |LineColor=DEDDE2
}}
}}

==Treasure hunt==
The treasure hunt is a series of online mathematical challenges. The BBC planned to offer the challenges to 1000 participants selected from among people who applied to participate via [[Twitter]] or email.&lt;ref&gt;{{citation|url=https://www.wired.com/magazine/2011/06/get-clued-in-to-the-bbc-code-challenge/ |work=Wired |title=Get Clued In to ''The BBC Code Challenge'' |author=Nordgren, Kris |date=29 June 2011}}&lt;/ref&gt; There are three stages to the treasure hunt: The Codebreakers, the Ultimate Challenge, and the Finale.&lt;ref name="About"/&gt;

===Stage 1: The Codebreakers===
The first puzzles are "The Codebreakers". These consist of three wheels, one relating to each episode. Each Codebreaker has six different questions and challenges relating to it, the answers to which surround the wheel. Answers to these questions can be found by watching the episode for clues, completing a [[flash game]], solving a puzzle on the programme's [[blog]] or reaching a milestone in a mass community challenge, which involves trying to find examples of all the [[prime number]]s between 2 and 2011 in the real world. Once a clue is found, the challenger can enter it into the Codebreaker by moving the correct "hand" around the Codebreaker. Each time a hand is moved, the password given changes. Each possible outcome of the Codebreaker produces a different [[password]] to the ultimate challenge. Entering the correct solutions into each of the three Codebreakers will result in the challenger getting the three correct passwords. Once these are entered, the Ultimate Challenge is accessible.&lt;ref name="About"/&gt;&lt;ref&gt;{{cite web|url=http://www.bbc.co.uk/programmes/p00j8k8t|title=How to Play The Code|publisher=[[BBC]]|date=19 July 2011|accessdate=27 July 2011}}&lt;/ref&gt;

===Stage 2: The Ultimate Challenge===
The Ultimate Challenge will be made accessible after all three episodes have been broadcast, and can only be accessed if the challenger enters all three passwords correctly. Once it is accessed, the first three eligible people to solve the Ultimate Challenge go through to the Finale.&lt;ref name="About"/&gt;

===Stage 3: The Finale===
The Finale took place at [[Bletchley Park]] during the weekend of 10 September 2011. The prize, a specially commissioned mathematical sculpture of the [[platonic solids]] , was won by Pete Ryland.&lt;ref name="About"/&gt;&lt;ref&gt;{{cite web|last=du Sautoy|first=Marcus|authorlink=Marcus du Sautoy|url=https://www.bbc.co.uk/news/magazine-14305667|title=Nature's hidden prime number code|publisher=[[BBC]]|date=27 July 2011|accessdate=27 July 2011}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last=Nordgren|first=Kris|authorlink=|url=https://www.wired.com/2011/11/cracking_the_bbc_code_at_bletchley_park/|title=Cracking the BBC’s Code at Bletchley Park|publisher=[[Wired (website)|Wired]]|date=17 Nov 2011|accessdate=19 Feb 2015}}&lt;/ref&gt;

==References==
{{Reflist|30em}}

==External links==
*{{IMDb title|id=2060305|title=The Code}}
*{{BBC Online|tv/features/code/|''The Code''}}
*{{BBC programme}}
*{{Twitter|name=''The Code''}}

{{DEFAULTSORT:Code, The}}
[[Category:2011 British television programme debuts]]
[[Category:2011 British television programme endings]]
[[Category:2010s British documentary television series]]
[[Category:BBC television documentaries]]
[[Category:Documentary television series about mathematics]]
[[Category:English-language television programs]]</text>
      <sha1>bq6j6358weuxwv7rih71dk5vx6ljeqx</sha1>
    </revision>
  </page>
  <page>
    <title>Vojtěch Rödl</title>
    <ns>0</ns>
    <id>29407873</id>
    <revision>
      <id>842818469</id>
      <parentid>833155676</parentid>
      <timestamp>2018-05-24T21:52:40Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* Books */ [[Algorithms and Combinatorics]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2183">'''Vojtěch Rödl''' is a [[Czechs|Czech]] mathematician, currently the [[Samuel Candler Dobbs]] Professor at [[Emory University]] in [[Atlanta]], known for his work in [[combinatorics]]. 

==Education and career==
Rödl received his [[Ph.D.]] from [[Charles University]], [[Prague]] in 1976; his advisor was Zdenek Hedrlin.  Significant contributions include his work with [[Jaroslav Nešetřil]] on [[Ramsey theory]], his proof of the [[Packing in a hypergraph|Erdős–Hanani conjecture]] on hypergraph packing&lt;ref&gt;Vojtěch Rödl: On a packing and covering problem, ''European Journal of Combinatorics'', '''6''' (1985), 69–78.&lt;/ref&gt; and his development, together with Brendan Nagle, [[Mathias Schacht]], and Jozef Skokan (and independently of [[Timothy Gowers]]), of the [[hypergraph]] [[regularity lemma]].&lt;ref&gt;Vojtěch Rödl, Jozef Skokan: Regularity lemma for uniform hypergraphs, ''Random Structures &amp; Algorithms'', '''25''' (2004), 1–42.&lt;/ref&gt;&lt;ref&gt;Brendan Nagle, Vojtěch Rödl, [[Mathias Schacht]]: The Counting Lemma for regular k-uniform hypergraphs, ''Random Structures &amp; Algorithms'', '''28''' (2006), 113–179&lt;/ref&gt; 

In 2012, Rödl and his former student Schacht were awarded the [[George Pólya Prize]] by the [[Society for Industrial and Applied Mathematics]], for their work on hypergraph regularity.&lt;ref&gt;{{cite web| url=http://www.siam.org/prizes/sponsored/polya.php|title=George Pólya Prize}}&lt;/ref&gt;

==Books==
* {{cite book |last1=Nešetřil|first1=Jaroslav |author1-link=Jaroslav Nešetřil|last2=Rödl| first2=Vojtěch|publisher=Springer |title=Mathematics of Ramsey Theory|series=[[Algorithms and Combinatorics]]|volume=5|year=1991 |isbn=0-387-18191-1}}

==See also==
*[[Frankl–Rödl graph]]

==References==
&lt;references/&gt;

==External links==
* {{MathGenealogy|id=11701}}
* {{cite web|url=http://www.mathcs.emory.edu/~rodl/|title=Vojtěch Rödl's home page}}

{{Authority control}}
{{DEFAULTSORT:Rodl, Vojtech}}
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Czech mathematicians]]
[[Category:Combinatorialists]]
[[Category:Charles University in Prague alumni]]</text>
      <sha1>trypdgw3nblzaaedfk0avha91pmlmg0</sha1>
    </revision>
  </page>
  <page>
    <title>Well-separated pair decomposition</title>
    <ns>0</ns>
    <id>42316777</id>
    <revision>
      <id>812554178</id>
      <parentid>788623906</parentid>
      <timestamp>2017-11-28T14:22:59Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>{{math}} |abs|</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13281">In [[computational geometry]], a '''well-separated pair decomposition (WSPD)''' of a set of points &lt;math&gt;S \subset \mathbb{R}^d&lt;/math&gt;, is a sequence of pairs of sets &lt;math&gt;(A_i, B_i)&lt;/math&gt;, such that each pair is '''well-separated''', and for each two distinct points &lt;math&gt;p, q \in S&lt;/math&gt;, there exists precisely one pair which separates the two.

The graph induced by a well-separated pair decomposition can serve as a [[Graph spanner|k-spanner]] of the [[complete graph|complete]] [[Euclidean graph]], and is useful in approximating solutions to several problems pertaining to this.&lt;ref name="smid"&gt;{{cite web | url=http://people.scs.carleton.ca/~michiel/aa-handbook.pdf | title=The well-separated pair decomposition and its applications | date=16 August 2005 | accessdate=26 March 2014 | author=Smid, Michiel}}&lt;/ref&gt;

== Definition ==
[[File:Visual representation of well-separated pair.svg|thumbnail|right|Visual representation of well-separated pair]]

Let &lt;math&gt;A, B&lt;/math&gt; be two disjoint sets of points in &lt;math&gt;\mathbb{R}^d&lt;/math&gt;, &lt;math&gt;R(X)&lt;/math&gt; denote the [[minimum bounding box#Axis-aligned minimum bounding box|axis-aligned minimum bounding box]] for the points in &lt;math&gt;X&lt;/math&gt;, and &lt;math&gt;s &gt; 0&lt;/math&gt; denote the '''separation factor'''.

We consider &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; to be '''well-separated''', if for each of &lt;math&gt;R(A)&lt;/math&gt; and &lt;math&gt;R(B)&lt;/math&gt; there exists a [[n-ball|d-ball]] of radius &lt;math&gt;\rho&lt;/math&gt; containing it, such that the two spheres have a minimum distance of at least &lt;math&gt;s \rho&lt;/math&gt;.&lt;ref name="callahan-kosaraju"&gt;{{cite journal | title=A Decomposition of Multidimensional Point Sets with Applications to k-Nearest-Neighbors and n-Body Potential Fields |author1=Callahan, P. B.  |author2=Kosaraju, S. R.  |lastauthoramp=yes | journal=Journal of the ACM |date=January 1995  | volume=42 | issue=1 | pages=67–90 | doi=10.1145/200836.200853}}&lt;/ref&gt;

We consider a sequence of well-separated pairs of subsets of &lt;math&gt;S&lt;/math&gt;, &lt;math&gt;(A_1, B_1), (A_2, B_2), \ldots, (A_m,B_m)&lt;/math&gt; to be a '''well-separated pair decomposition (WSPD)''' of &lt;math&gt;S&lt;/math&gt; if for any two distinct points &lt;math&gt;p, q \in S&lt;/math&gt;, there exists precisely one &lt;math&gt;i&lt;/math&gt;, &lt;math&gt;1 \leq i \leq m&lt;/math&gt;, such that either

* &lt;math&gt;p \in A_i&lt;/math&gt; and &lt;math&gt;q \in B_i&lt;/math&gt;, or
* &lt;math&gt;q \in A_i&lt;/math&gt; and &lt;math&gt;p \in B_i&lt;/math&gt;.&lt;ref name="smid"/&gt;

== Construction ==

=== Split tree ===

By way of constructing a [[fair split tree]], it is possible to construct a WSPD of size &lt;math&gt;O(s^d n)&lt;/math&gt; in &lt;math&gt;O(n \lg n)&lt;/math&gt; time.&lt;ref name="callahan-kosaraju"/&gt;

The general principle of the split tree of a point set {{math|S}} is that each node {{math|u}} of the tree represents a set of points {{math|S&lt;sub&gt;u&lt;/sub&gt;}} and that the bounding box {{math|R(S&lt;sub&gt;u&lt;/sub&gt;)}} of {{math|S&lt;sub&gt;u&lt;/sub&gt;}} is split along its longest side in two equal parts which form the two children of {{math|u}} and their point set. It is done recursively until there is only one point in the set.

Let {{math|L&lt;sub&gt;max&lt;/sub&gt;(R(X))}} denote the size of the longest interval of the bounding hyperrectangle of point set {{math|X}} and let {{math|L&lt;sub&gt;i&lt;/sub&gt;(R(X))}} denote the size of the ''i''-th dimension of the bounding hyperrectangle of point set {{math|X}}. We give pseudocode for the Split tree computation below.

 {{math|SplitTree(S)}}
   Let {{math|u}} be the node for {{math|S}}
   '''if''' {{math|{{!}}S{{!}} {{=}} 1}}
      {{math|R(u) :{{=}} R(S)}} // {{math|R(S)}} is a hyperrectangle which each side has a length of zero.
      Store in {{math|u}} the only point in S.
   '''else'''
     Compute {{math|R(S)}}
     Let the ''i''-th dimension be the one where {{math|L&lt;sub&gt;max&lt;/sub&gt;(R(S)) {{=}} L&lt;sub&gt;i&lt;/sub&gt;(R(S))}}
     Split {{math|R(S)}} along the ''i''-th dimension in two same-size hyperrectangles and take the points contained in these hyperrectangles to form the two sets {{math|S&lt;sub&gt;v&lt;/sub&gt;}} and {{math|S&lt;sub&gt;w&lt;/sub&gt;}}.
     {{math|v :{{=}} SplitTree(S&lt;sub&gt;v&lt;/sub&gt;)}}
     {{math|w :{{=}} SplitTree(S&lt;sub&gt;w&lt;/sub&gt;)}}
     Store {{math|v}} and {{math|w}} as, respectively, the left and right children of {{math|u}}.
     {{math|R(u) :{{=}} R(S)}}
   '''return''' {{math|u}}

This algorithm runs in &lt;math&gt;O(n^2)&lt;/math&gt; time.

We give  a more efficient algorithm that runs in &lt;math&gt;O(n \lg n)&lt;/math&gt; time below. The goal is to loop over the list in only &lt;math&gt;O(n)&lt;/math&gt; operations per step of the recursion but only call the recursion on at most half the points each time.

Let {{math|S&lt;sub&gt;i&lt;/sub&gt;&lt;sup&gt;j&lt;/sup&gt;}} be the ''j''-th coordinate of the ''i''-th point in {{math|S}} such that {{math|S}} is sorted for each dimension and {{math|p(S&lt;sub&gt;i&lt;/sub&gt;&lt;sup&gt;j&lt;/sup&gt;)}} be the point. Also, let {{math|h(R(S))}} be the hyperplane that splits the longest side of {{math|R(S)}} in two. Here is the algorithm in pseudo-code:

 {{math|SplitTree(S, u)}}
   '''if''' {{math|{{!}}S{{!}} {{=}} 1}}
     {{math|R(u) :{{=}} R(S)}} // {{math|R(S)}} is a hyperrectangle which each side has a length of zero.
     Store in {{math|u}} the only point in {{math|S}}.
   '''else'''
     {{math|size :{{=}} {{!}}S{{!}}}}
     '''repeat'''
       Compute {{math|R(S)}}
       {{math|R(u) :{{=}} R(S)}}
       {{math|j : {{=}} 1}}
       {{math|k : {{=}} {{!}}S{{!}}}}
       Let the ''i''-th dimension be the one where {{math|L&lt;sub&gt;max&lt;/sub&gt;(R(S)) {{=}} L&lt;sub&gt;i&lt;/sub&gt;(R(S))}}
       {{math|S&lt;sub&gt;v&lt;/sub&gt; : {{=}} ∅}}
       {{math|S&lt;sub&gt;w&lt;/sub&gt; : {{=}} ∅}}
       '''while''' {{math|S&lt;sub&gt;i&lt;/sub&gt;&lt;sup&gt;j+1&lt;/sup&gt; &lt; h(R(S))}} '''and''' {{math|S&lt;sub&gt;i&lt;/sub&gt;&lt;sup&gt;k-1&lt;/sup&gt; &gt; h(R(S))}}
         {{math|size :{{=}} size - 1}}
         {{math|S&lt;sub&gt;v&lt;/sub&gt; : {{=}} S&lt;sub&gt;v&lt;/sub&gt; ∪ {p(S_i^j)}}}
         {{math|S&lt;sub&gt;w&lt;/sub&gt; : {{=}} S&lt;sub&gt;w&lt;/sub&gt; ∪ {p(S_i^k)}}}
         {{math|j :{{=}} j + 1}}
         {{math|k :{{=}} k - 1}}
       
       Let {{math|v}} and {{math|w}} be respectively, the left and right children of {{math|u}}.
       '''if''' {{math|S&lt;sub&gt;i&lt;/sub&gt;&lt;sup&gt;j+1&lt;/sup&gt; &gt; h(R(S))}}
         {{math|S&lt;sub&gt;w&lt;/sub&gt; :{{=}} S \ S&lt;sub&gt;v&lt;/sub&gt;}}
         {{math|u :{{=}} w}}
         {{math|S :{{=}} S&lt;sub&gt;w&lt;/sub&gt;}}
         {{math|SplitTree(S&lt;sub&gt;v&lt;/sub&gt;,v)}}
       '''else if''' {{math|S&lt;sub&gt;i&lt;/sub&gt;&lt;sup&gt;k-1&lt;/sup&gt; &lt; h(R(S))}}
         {{math|S&lt;sub&gt;v&lt;/sub&gt; :{{=}} S \ S&lt;sub&gt;w&lt;/sub&gt;}}
         {{math|u :{{=}} v}}
         {{math|S :{{=}} S&lt;sub&gt;v&lt;/sub&gt;}}
         {{math|SplitTree(S&lt;sub&gt;w&lt;/sub&gt;,w)}}
     '''until''' {{math|size ≤ {{frac|n|2}}}}
     {{math|SplitTree(S,u)}}

To be able to maintain the sorted lists for each node, linked lists are used. Cross-pointers are kept for each list to the others to be able to retrieve a point in constant time. In the algorithm above, in each iteration of the loop, a call to the recursion is done. In reality, to be able to reconstruct the list without the overhead of resorting the points, it is necessary to rebuild the sorted lists once all points have been assigned to their nodes. To do the rebuilding, walk along each list for each dimension, add each point to the corresponding list of its nodes, and add cross-pointers in the original list to be able to add the cross-pointers for the new lists. Finally, call the recursion on each node and his set.

=== WSPD computation ===

[[File:Visual representation of a well-separated pair computed with the bounding boxes.svg|thumbnail|right|Visual representation of a well-separated pair computed with the bounding boxes]]

The WSPD can be extracted from such a split tree by calling the recursive {{math|FindPairs(v,w)}} function on the children of ''every'' node in the split tree. Let {{math|u&lt;sub&gt;l&lt;/sub&gt;}} / {{math|u&lt;sub&gt;r&lt;/sub&gt;}} denote the children of the node {{math|u}}. We give pseudocode for the {{math|FindWSPD(T, s)}} function below.

 {{math|FindWSPD(T,s)}}
   '''for each''' node {{math|u}} that is not a leaf in the split tree {{math|T}} '''do'''
     {{math|FindPairs(u&lt;sub&gt;l&lt;/sub&gt;, u&lt;sub&gt;r&lt;/sub&gt;)}}

We give pseudocode for the {{math|FindPairs(v,w)}} function below.

 {{math|FindPairs(v,w)}}
   '''if''' {{math|S&lt;sub&gt;v&lt;/sub&gt;}} and {{math|S&lt;sub&gt;w&lt;/sub&gt;}} are well-separated with respect to {{math|s}} 
     report {{math|pair(S&lt;sub&gt;v&lt;/sub&gt;,S&lt;sub&gt;w&lt;/sub&gt;)}}
   '''else'''
     '''if'''( {{math|L&lt;sub&gt;max&lt;/sub&gt;(R(v)) ≤ L&lt;sub&gt;max&lt;/sub&gt;(R(w))}} )
       Recursively call {{math|FindPairs(v,w&lt;sub&gt;l&lt;/sub&gt;)}} and {{math|FindPairs(v,w&lt;sub&gt;r&lt;/sub&gt;)}}
     '''else'''
       Recursively call {{math|FindPairs(v&lt;sub&gt;l&lt;/sub&gt;,w)}} and {{math|FindPairs(v&lt;sub&gt;r&lt;/sub&gt;,w)}}

Combining the {{math|s}}-well-separated pairs from all the calls of {{math|FindPairs(v,w)}} gives the WSPD for separation {{math|s}}.

{{collapse top|title=Proof of correctness of the algorithm}}
It is clear that the pairs returned by the algorithm are well-separated because of the return condition of the function {{math|FindPairs}}.

Now, we have to prove that for any distinct points &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; in &lt;math&gt;S&lt;/math&gt;, there is a unique pair &lt;math&gt;\{A, B\}&lt;/math&gt; so that (i) &lt;math&gt;p \in A&lt;/math&gt; and &lt;math&gt;q \in B&lt;/math&gt; or (ii) &lt;math&gt;p \in B&lt;/math&gt; and &lt;math&gt;q \in A&lt;/math&gt;. Assume without loss of generality that (i) holds.

Let &lt;math&gt;u&lt;/math&gt; be the lowest common ancestor of &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; in the split tree and let &lt;math&gt;v&lt;/math&gt; and &lt;math&gt;w&lt;/math&gt; be the children of &lt;math&gt;u&lt;/math&gt;. Because of the last assumption, &lt;math&gt;p&lt;/math&gt; is in the subtree of &lt;math&gt;v&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; in the subtree of &lt;math&gt;w&lt;/math&gt;. A call to {{math|FindPairs(v,w)}} is necessarily done in {{math|FindWSPD}}. Because, each time there is a recursion, the recursion tree creates two branches that contain all the points of the current recursion call, there will be a sequence of call to {{math|FindPairs}} leading to having &lt;math&gt;p&lt;/math&gt; in &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; in &lt;math&gt;B&lt;/math&gt;.

Because &lt;math&gt;u&lt;/math&gt; is the lowest common ancestor of &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt;, calling {{math|FindPairs}} on the children of a higher node would result of &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; not being in a pair and calling {{math|FindPairs}} on the children in one of the nodes of one of the subtrees of &lt;math&gt;u&lt;/math&gt; would result by &lt;math&gt;p&lt;/math&gt; or &lt;math&gt;q&lt;/math&gt; not being in any pair. Thus, the pair &lt;math&gt;\{A, B\}&lt;/math&gt; is the unique one separating &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt;.
{{collapse bottom}}

Each time the recursion tree split in two, there is one more pair added to the decomposition. So, the algorithm run-time is in the number of pairs in the final decomposition.

Callahan and Kosaraju proved that this algorithm finds a Well-separated pair decomposition (WSPD) of size &lt;math&gt;O(s^d n)&lt;/math&gt;.&lt;ref name="callahan-kosaraju"/&gt;

== Properties ==

'''Lemma 1''': Let &lt;math&gt;\{A, B\}&lt;/math&gt; be a well-separated pair with respect to &lt;math&gt;s&lt;/math&gt;. Let &lt;math&gt;p, p' \in A&lt;/math&gt; and &lt;math&gt;q \in B&lt;/math&gt;. Then, &lt;math&gt;|pp'| \leq (2/s)|pq|&lt;/math&gt;.

'''Proof''': Because &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;p'&lt;/math&gt; are in the same set, we have that &lt;math&gt;|pp'| \leq 2\rho&lt;/math&gt; where &lt;math&gt;\rho&lt;/math&gt; is the radius of the enclosing circle of &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;. Because &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt; are in two well-separated sets, we have that &lt;math&gt;|pq| \geq s\rho&lt;/math&gt;. We obtain that:

&lt;math&gt;\begin{align}
 &amp; \frac{|pp'|}{2} \leq \rho \leq \frac{|pq|}{s} \\
\Leftrightarrow &amp; \\
 &amp; \frac{|pp'|}{2} \leq \frac{|pq|}{s} \\
\Leftrightarrow &amp; \\
 &amp; |pp'| \leq \frac{2}{s}|pq| \\
\end{align}&lt;/math&gt;

'''Lemma 2''': Let &lt;math&gt;\{A, B\}&lt;/math&gt; be a well-separated pair with respect to &lt;math&gt;s&lt;/math&gt;. Let &lt;math&gt;p, p' \in A&lt;/math&gt; and &lt;math&gt;q, q' \in B&lt;/math&gt;. Then, &lt;math&gt;|p'q'| \leq (1+ 4/s)|pq|&lt;/math&gt;.

'''Proof''': By the triangle inequality, we have:

&lt;math&gt;|p'q'| \leq |p'p| + |pq| + |qq'|&lt;/math&gt;

From Lemma 1, we obtain:

&lt;math&gt;\begin{align}
|p'q'| &amp; \leq (2/s)|pq| + |pq| + (2/s)|pq| \\
       &amp; = (1+4/s)|pq|
\end{align}&lt;/math&gt;

== Applications ==

The well-separated pair decomposition has application in solving a number of problems. WSPD can be used to:

* Solve the [[closest pair problem]] in &lt;math&gt;O(n \lg n)&lt;/math&gt; time.&lt;ref name="smid"/&gt;
* Solve the k-closest pairs problem in &lt;math&gt;O(n \lg n + k)&lt;/math&gt; time.&lt;ref name="smid"/&gt;
* Solve the [[Nearest neighbor search#All nearest neighbors|all-nearest neighbors problem]] in &lt;math&gt;O(n \lg n)&lt;/math&gt; time.&lt;ref name="smid"/&gt;
* Provide a &lt;math&gt;(1-\epsilon)&lt;/math&gt;-[[approximation algorithm|approximation]] of the [[diameter]] of a point set in &lt;math&gt;O(n \lg n)&lt;/math&gt; time.&lt;ref name="smid"/&gt;
* Directly induce a [[Geometric spanner|t-spanner]] of a point set.&lt;ref name="smid"/&gt;
* Provide a t-approximation of the [[Euclidean minimum spanning tree]] in d dimensions in &lt;math&gt;O(n \lg n)&lt;/math&gt; time.&lt;ref name="smid"/&gt;
* Provide a &lt;math&gt;(1+\epsilon)&lt;/math&gt;-approximation of the [[Euclidean minimum spanning tree]] in d dimensions in &lt;math&gt;O(n \lg n + (\epsilon^{-2} \lg ^2 \frac{1}{\epsilon})n)&lt;/math&gt; time.&lt;ref&gt;{{cite journal|last1=Arya|first1=Sunil|last2=Mount|first2=David M.|title=A fast and simple algorithm for computing approximate euclidean minimum spanning trees.|journal=Proceedings of the Twenty-Seventh Annual ACM-SIAM Symposium on Discrete Algorithms|date=2016}}&lt;/ref&gt;

== References ==
{{reflist}}

[[Category:Computational geometry]]</text>
      <sha1>kq0xa8o5q4dqmf417ihflb2bw6auvag</sha1>
    </revision>
  </page>
</mediawiki>
