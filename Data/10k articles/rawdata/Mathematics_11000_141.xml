<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Arif Salimov</title>
    <ns>0</ns>
    <id>30829236</id>
    <revision>
      <id>868693367</id>
      <parentid>857346205</parentid>
      <timestamp>2018-11-13T20:53:43Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2782">[[File:A.A.Salimov.JPG.2011.JPG|300px|thumb|right|'''''A.A.Salimov''''']]
'''Arif Salimov''' (A.A. Salimov, born 1956, {{lang-az|Arif Səlimov}}) is an [[Azerbaijani people|Azerbaijani]]/[[Soviet Union|Soviet]] mathematician, known for his research in [[differential geometry]]. He obtained a [[B.Sc.]] degree from [[Baku State University]], [[Azerbaijan]] in 1978, a [[PhD]] and [[Doctor of Sciences]] ([[Habilitation]]) degrees in geometry from [[Kazan State University]], [[Russia]] in 1984 and 1998, respectively. His advisor was Vladimir Vishnevskii.&lt;ref&gt;[http://www.ksu.ru/persons/5101.ru.html V.V.Vishnevskii]&lt;/ref&gt;  Salimov is currently a full professor in the department of mathematics at [[Ataturk University]], [[Turkey]]. He is an author and co-author of more than 100 articles.&lt;ref&gt;[[:az:Arif Səlimov|A.A.Salimov, Selected publications]]&lt;/ref&gt;&lt;ref&gt;[http://www.ams.org/mathscinet/search/author.html?return=viewitems&amp;mrauthid=223558 A.A.Salimov, Personal webpage on MathSciNet]{{dead link|date=October 2016 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;&lt;ref&gt;[https://scholar.google.com/scholar?q=author%3A%22%D0%B0%20%D0%B0%20%D1%81%D0%B0%D0%BB%D0%B8%D0%BC%D0%BE%D0%B2%22%20OR%20author%3A%22a%20a%20salimov%22 A.A.Salimov, List of publications on Google Scholar]&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://www.novapublishers.com/catalog/product_info.php?products_id=34438# |title=A. Salimov, Tensor operators and their applications |access-date=2013-07-21 |archive-url=https://web.archive.org/web/20151208234851/https://www.novapublishers.com/catalog/product_info.php?products_id=34438# |archive-date=2015-12-08 |dead-url=yes |df= }}&lt;/ref&gt; His primary areas of research are:
* theory of [[lift (mathematics)|lift]]s in [[tensor]] [[bundle (mathematics)|bundle]]s
* geometrical applications of [[tensor]] [[Operator (mathematics)|operators]]
* special [[Riemannian manifolds]], indefinite [[metric (mathematics)|metric]]s
* general geometric structures on manifolds ([[almost complex]], almost product, hypercomplex, Norden structures etc.)

==References==
{{reflist}}

== External links ==
* http://www.atauni.edu.tr/#personel=arif-salimov
* [http://mechmath.bsu.edu.az/en/content/algebra_and_geometry_514 Dep. of Algebra and Geometry]


{{authority control}}

{{DEFAULTSORT:Salimov, Arif}}
[[Category:Living people]]
[[Category:1956 births]]
[[Category:Azerbaijani scientists]]
[[Category:Azerbaijani mathematicians]]
[[Category:Azerbaijani academics]]
[[Category:Soviet mathematicians]]
[[Category:Turkish mathematicians]]
[[Category:Differential geometers]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Atatürk University faculty]]
[[Category:Baku State University alumni]]


{{mathematician-stub}}
{{Azerbaijan-bio-stub}}</text>
      <sha1>cekskx8g7ypzs04x005xbmnujblfdf5</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetic logic unit</title>
    <ns>0</ns>
    <id>27046146</id>
    <revision>
      <id>864363613</id>
      <parentid>861956554</parentid>
      <timestamp>2018-10-16T18:39:54Z</timestamp>
      <contributor>
        <username>Lambtron</username>
        <id>6010417</id>
      </contributor>
      <comment>/* Implementation */ simplified (no process needed); cleaned "others"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20092">[[File:ALU block.gif|thumb|A symbolic representation of an ALU and its input and output signals, indicated by arrows pointing into or out of the ALU, respectively. Each arrow represents one or more signals. Control signals enter from the left and status signals exit on the right; data flows from top to bottom.]]

An '''arithmetic logic unit''' ('''ALU''') is a [[Combinational logic|combinational]] [[digital electronic circuit]] that performs [[arithmetic]] and [[bitwise operation]]s on [[integer]] [[binary number]]s. This is in contrast to a [[floating-point unit]] (FPU), which operates on [[floating point]] numbers. An ALU is a fundamental building block of many types of computing circuits, including the [[central processing unit]] (CPU) of computers, FPUs, and [[graphics processing unit]]s (GPUs). A single CPU, FPU or GPU may contain multiple ALUs.

The inputs to an ALU are the data to be operated on, called [[operand]]s, and a code indicating the operation to be performed; the ALU's output is the result of the performed operation. In many designs, the ALU also has status inputs or outputs, or both, which convey information about a previous operation or the current operation, respectively, between the ALU and external [[status register]]s.

==Signals==
An ALU has a variety of input and output [[net (electronics)|nets]], which are the [[electrical conductors]] used to convey [[Digital signal (electronics)|digital signal]]s between the ALU and external circuitry. When an ALU is operating, external circuits apply signals to the ALU inputs and, in response, the ALU produces and conveys signals to external circuitry via its outputs.

===Data===
A basic ALU has three parallel data [[Bus (computing)|buses]] consisting of two input [[operand]]s (''A'' and ''B'') and a result output (''Y''). Each data bus is a group of signals that conveys one binary integer number. Typically, the A, B and Y bus widths (the number of signals comprising each bus) are identical and match the native [[word size]] of the external circuitry (e.g., the encapsulating CPU or other processor).

===Opcode===
The ''opcode'' input is a parallel bus that conveys to the ALU an operation selection code, which is an enumerated value that specifies the desired arithmetic or logic operation to be performed by the ALU. The opcode size (its bus width) determines the maximum number of different operations the ALU can perform; for example, a four-bit opcode can specify up to sixteen different ALU operations. Generally, an ALU opcode is not the same as a [[opcode|machine language opcode]], though in some cases it may be directly encoded as a bit field within a machine language opcode.

===Status===
====Outputs====
The status outputs are various individual signals that convey supplemental information about the result of the current ALU operation. General-purpose ALUs commonly have status signals such as:
* ''Carry-out'', which conveys the [[carry (arithmetic)|carry]] resulting from an addition operation, the borrow resulting from a subtraction operation, or the overflow bit resulting from a binary shift operation.
* ''Zero'', which indicates all bits of Y are logic zero.
* ''Negative'', which indicates the result of an arithmetic operation is negative.
* ''[[arithmetic overflow|Overflow]]'', which indicates the result of an arithmetic operation has exceeded the numeric range of Y.
* ''[[parity flag|Parity]]'', which indicates whether an even or odd number of bits in Y are logic one.

At the end of each ALU operation, the status output signals are usually stored in external registers to make them available for future ALU operations (e.g., to implement [[multiple-precision arithmetic]]) or for controlling [[Branch (computer science)|conditional branching]]. The collection of bit registers that store the status outputs are often treated as a single, multi-bit register, which is referred to as the "status register" or "condition code register".

====Inputs====
The status inputs allow additional information to be made available to the ALU when performing an operation. Typically, this is a single "carry-in" bit that is the stored carry-out from a previous ALU operation.

==Circuit operation==
[[File:74181aluschematic.png|thumb|right|upright=1.8|The [[combinational logic]] circuitry of the [[74181]] integrated circuit, which is a simple four-bit ALU]]

An ALU is a [[combinational logic]] circuit, meaning that its outputs will change asynchronously in response to input changes. In normal operation, stable signals are applied to all of the ALU inputs and, when enough time (known as the "[[propagation delay]]") has passed for the signals to propagate through the ALU circuitry, the result of the ALU operation appears at the ALU outputs. The external circuitry connected to the ALU is responsible for ensuring the stability of ALU input signals throughout the operation, and for allowing sufficient time for the signals to propagate through the ALU before sampling the ALU result.

In general, external circuitry controls an ALU by applying signals to its inputs. Typically, the external circuitry employs [[sequential logic]] to control the ALU operation, which is paced by a [[clock signal]] of a sufficiently low frequency to ensure enough time for the ALU outputs to settle under worst-case conditions.

For example, a CPU begins an ALU addition operation by routing operands from their sources (which are usually registers) to the ALU's operand inputs, while the [[control unit]] simultaneously applies a value to the ALU's opcode input, configuring it to perform addition. At the same time, the CPU also routes the ALU result output to a destination register that will receive the sum. The ALU's input signals, which are held stable until the next clock, are allowed to propagate through the ALU and to the destination register while the CPU waits for the next clock. When the next clock arrives, the destination register stores the ALU result and, since the ALU operation has completed, the ALU inputs may be set up for the next ALU operation.

==Functions==
A number of basic arithmetic and bitwise logic functions are commonly supported by ALUs. Basic, general purpose ALUs typically include these operations in their repertoires:

===Arithmetic operations===
* ''[[Binary number#Addition|Add]]'': A and B are summed and the sum appears at Y and carry-out.
* ''Add with carry'': A, B and carry-in are summed and the sum appears at Y and carry-out.
* ''[[Binary number#Subtraction|Subtract]]'': B is subtracted from A (or vice versa) and the difference appears at Y and carry-out. For this function, carry-out is effectively a "borrow" indicator. This operation may also be used to compare the magnitudes of A and B; in such cases the Y output may be ignored by the processor, which is only interested in the status bits (particularly zero and negative) that result from the operation.
* ''Subtract with borrow'': B is subtracted from A (or vice versa) with borrow (carry-in) and the difference appears at Y and carry-out (borrow out).
* ''Two's complement (negate)'': A (or B) is subtracted from zero and the difference appears at Y.
* ''Increment'': A (or B) is increased by one and the resulting value appears at Y.
* ''Decrement'': A (or B) is decreased by one and the resulting value appears at Y.
* ''Pass through'': all bits of A (or B) appear unmodified at Y. This operation is typically used to determine the parity of the operand or whether it is zero or negative, or to load the operand into a processor register.

===Bitwise logical operations===
* ''[[Bitwise operation#AND|AND]]'': the bitwise AND of A and B appears at Y.
* ''[[Bitwise operation#OR|OR]]'': the bitwise OR of A and B appears at Y.
* ''[[Bitwise operation#XOR|Exclusive-OR]]'': the bitwise XOR of A and B appears at Y.
* ''[[Bitwise operation#NOT|Ones' complement]]'': all bits of A (or B) are inverted and appear at Y.

===Bit shift operations===
{| class="wikitable floatright" style="margin-left: 1.5em;"
|+ Bit shift examples for an eight-bit ALU
! Type
! Left
! Right
|- style="text-align:center"
| Arithmetic shift
| [[Image:Rotate left logically.svg|150px]]
| [[Image:Rotate right arithmetically.svg|130px]]
|- style="text-align:center"
| Logical shift
| [[Image:Rotate left logically.svg|150px]]
| [[Image:Rotate right logically.svg|150px]]
|- style="text-align:center"
| Rotate
| [[Image:Rotate left.svg|130px]]
| [[Image:Rotate right.svg|130px]]
|- style="text-align:center"
| Rotate through carry
| [[Image:Rotate left through carry.svg|150px]]
| [[Image:Rotate right through carry.svg|150px]]
|}

ALU shift operations cause operand A (or B) to shift left or right (depending on the opcode) and the shifted operand appears at Y. Simple ALUs typically can shift the operand by only one bit position, whereas more complex ALUs employ [[barrel shifter]]s that allow them to shift the operand by an arbitrary number of bits in one operation. In all single-bit shift operations, the bit shifted out of the operand appears on carry-out; the value of the bit shifted into the operand depends on the type of shift.
* ''[[Bitwise operation#Arithmetic shift|Arithmetic shift]]'': the operand is treated as a [[two's complement]] integer, meaning that the most significant bit is a "sign" bit and is preserved.
* ''[[Bitwise operation#Logical shift|Logical shift]]'': a logic zero is shifted into the operand. This is used to shift unsigned integers.
* ''[[Bitwise operation#Rotate no carry|Rotate]]'': the operand is treated as a circular buffer of bits so its least and most significant bits are effectively adjacent.
* ''[[Bitwise operation#Rotate through carry|Rotate through carry]]'': the carry bit and operand are collectively treated as a circular buffer of bits.

==Applications==

===Multiple-precision arithmetic===
In integer arithmetic computations, '''multiple-precision arithmetic''' is an algorithm that operates on integers which are larger than the ALU word size. To do this, the algorithm treats each operand as an ordered collection of ALU-size fragments, arranged from most-significant (MS) to least-significant (LS) or vice versa. For example, in the case of an 8-bit ALU, the 24-bit integer &lt;code&gt;0x123456&lt;/code&gt; would be treated as a collection of three 8-bit fragments: &lt;code&gt;0x12&lt;/code&gt; (MS), &lt;code&gt;0x34&lt;/code&gt;, and &lt;code&gt;0x56&lt;/code&gt; (LS). Since the size of a fragment exactly matches the ALU word size, the ALU can directly operate on this "piece" of operand.

The algorithm uses the ALU to directly operate on particular operand fragments and thus generate a corresponding fragment (a "partial") of the multi-precision result. Each partial, when generated, is written to an associated region of storage that has been designated for the multiple-precision result. This process is repeated for all operand fragments so as to generate a complete collection of partials, which is the result of the multiple-precision operation.

In arithmetic operations (e.g., addition, subtraction), the algorithm starts by invoking an ALU operation on the operands' LS fragments, thereby producing both a LS partial and a carry out bit. The algorithm writes the partial to designated storage, whereas the processor's state machine typically stores the carry out bit to an ALU status register. The algorithm then advances to the next fragment of each operand's collection and invokes an ALU operation on these fragments along with the stored carry bit from the previous ALU operation, thus producing another (more significant) partial and a carry out bit. As before, the carry bit is stored to the status register and the partial is written to designated storage. This process repeats until all operand fragments have been processed, resulting in a complete collection of partials in storage, which comprise the multi-precision arithmetic result.

In multiple-precision shift operations, the order of operand fragment processing depends on the shift direction. In left-shift operations, fragments are processed LS first because the LS bit of each partial—which is conveyed via the stored carry bit—must be obtained from the MS bit of the previously left-shifted, less-significant operand. Conversely, operands are processed MS first in right-shift operations because the MS bit of each partial must be obtained from the LS bit of the previously right-shifted, more-significant operand.

In bitwise logical operations (e.g., logical AND, logical OR), the operand fragments may be processed in any arbitrary order because each partial depends only on the corresponding operand fragments (the stored carry bit from the previous ALU operation is ignored).

===Complex operations===
Although an ALU can be designed to perform complex functions, the resulting higher circuit complexity, cost, power consumption and larger size makes this impractical in many cases. Consequently, ALUs are often limited to simple functions that can be executed at very high speeds (i.e., very short propagation delays), and the external processor circuitry is responsible for performing complex functions by orchestrating a sequence of simpler ALU operations.

For example, computing the square root of a number might be implemented in various ways, depending on ALU complexity:

* ''Calculation in a [[Clock cycle|single clock]]'': a very complex ALU that calculates a square root in one operation.
* ''[[Pipeline (computing)|Calculation pipeline]]'': a group of simple ALUs that calculates a square root in stages, with intermediate results passing through ALUs arranged like a factory [[Assembly line|production line]]. This circuit can accept new operands before finishing the previous ones and produces results as fast as the very complex ALU, though the results are delayed by the sum of the propagation delays of the ALU stages. For more information, see the article on [[instruction pipelining]].
* ''Iterative calculation'': a simple ALU that calculates the square root through several steps under the direction of a [[control unit]].

The implementations above transition from fastest and most expensive to slowest and least costly. The square root is calculated in all cases, but processors with simple ALUs will take longer to perform the calculation because multiple ALU operations must be performed.

{{Clear}}

==Implementation==

An ALU is usually implemented either as a stand-alone [[integrated circuit]] (IC), such as the [[74181]], or as part of a more complex IC. In the latter case, an ALU is typically instantiated by synthesizing it from a description written in [[VHDL]], [[Verilog]] or some other [[hardware description language]]. For example, the following VHDL code describes a very simple [[8-bit]] ALU:

&lt;source lang="VHDL"&gt;
entity alu is
port (  -- the alu connections to external circuitry:
  A  : in  signed(7 downto 0);   -- operand A
  B  : in  signed(7 downto 0);   -- operand B
  OP : in  unsigned(2 downto 0); -- opcode
  Y  : out signed(7 downto 0));  -- operation result
end alu;

architecture behavioral of alu is
begin
  case OP is  -- decode the opcode and perform the operation:
    when "000" =&gt;  Y &lt;= A + B;   -- add
    when "001" =&gt;  Y &lt;= A - B;   -- subtract
    when "010" =&gt;  Y &lt;= A - 1;   -- decrement
    when "011" =&gt;  Y &lt;= A + 1;   -- increment
    when "100" =&gt;  Y &lt;= not A;   -- 1's complement
    when "101" =&gt;  Y &lt;= A and B; -- bitwise AND
    when "110" =&gt;  Y &lt;= A or B;  -- bitwise OR
    when "111" =&gt;  Y &lt;= A xor B; -- bitwise XOR
    when others =&gt; Y &lt;= (others =&gt; 'X');
  end case; 
end behavioral;
&lt;/source&gt;

== History ==
Mathematician [[John von Neumann]] proposed the ALU concept in 1945 in a report on the foundations for a new computer called the [[EDVAC]].&lt;ref&gt;{{cite web
 | url = http://www.cs.berkeley.edu/~christos/classics/paper.pdf
 | title = Jonathan von Neumann and EDVAC
 | date = November 8, 2004 | accessdate = January 20, 2015
 | author = Philip Levis | website = cs.berkeley.edu
 | format = PDF | pages = 1, 3
}}&lt;/ref&gt;

The cost, size, and power consumption of electronic circuitry was relatively high throughout the infancy of the [[information age]]. Consequently, all [[serial computer]]s and many early computers, such as the [[PDP-8]], had a simple ALU that operated on one data bit at a time, although they often presented a wider word size to programmers. One of the earliest computers to have multiple discrete single-bit ALU circuits was the 1948 [[Whirlwind&amp;nbsp;I]], which employed sixteen of such "math units" to enable it to operate on 16-bit words.

In 1967, Fairchild introduced the first ALU implemented as an integrated circuit, the Fairchild 3800, consisting of an eight-bit ALU with accumulator.&lt;ref&gt;{{cite web
 |url=http://inst-tech.engin.umich.edu/leccap/view/ece-inv-lectures/1036 
 |title=Making Your First Million (and other tips for aspiring entrepreneurs) 
 |author=Lee Boysel 
 |date=2007-10-12 
 |work=U. Mich. EECS Presentation / ECE Recordings 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20121115072151/http://inst-tech.engin.umich.edu/leccap/view/ece-inv-lectures/1036 
 |archivedate=2012-11-15 
}}&lt;/ref&gt; Other integrated-circuit ALUs soon emerged, including four-bit ALUs such as the [[AMD Am2900|Am2901]] and [[74181]]. These devices were typically "[[Bit slicing|bit slice]]" capable, meaning they had "carry look ahead" signals that facilitated the use of multiple interconnected ALU chips to create an ALU with a wider word size. These devices quickly became popular and were widely used in bit-slice minicomputers.

Microprocessors began to appear in the early 1970s. Even though transistors had become smaller, there was often insufficient die space for a full-word-width ALU and, as a result, some early microprocessors employed a narrow ALU that required multiple cycles per machine language instruction. Examples of this includes the popular [[Zilog Z80]], which performed eight-bit additions with a four-bit ALU.&lt;ref&gt;
Ken Shirriff.
[http://www.righto.com/2013/09/the-z-80-has-4-bit-alu-heres-how-it.html "The Z-80 has a 4-bit ALU. Here's how it works."]
2013.
&lt;/ref&gt; Over time, transistor geometries shrank further, following [[Moore's law]], and it became feasible to build wider ALUs on microprocessors.

Modern integrated circuit (IC) transistors are orders of magnitude smaller than those of the early microprocessors, making it possible to fit highly complex ALUs on ICs. Today, many modern ALUs have wide word widths, and architectural enhancements such as [[barrel shifter]]s and [[binary multiplier]]s that allow them to perform, in a single clock cycle, operations that would have required multiple operations on earlier ALUs.

==See also==
{{Portal|Information technology}}

* [[Adder (electronics)]]
* [[Address generation unit]] (AGU)
* [[Binary multiplier]]
* [[Execution unit]]

==References==
&lt;!--This article uses the Cite.php citation mechanism. If you would like more information on how to add footnotes to this article, please see http://meta.wikimedia.org/wiki/Cite/Cite.php --&gt;
{{Reflist}}

==Further reading==
*{{Cite book | first=Enoch| last=Hwang| year=2006| title=Digital Logic and Microprocessor Design with VHDL| publisher=Thomson| isbn=0-534-46593-5| url=http://faculty.lasierra.edu/~ehwang/digitaldesign}}
*{{Cite book | first=William| last=Stallings| year=2006| title=Computer Organization &amp; Architecture: Designing for Performance |edition=7th |publisher=Pearson Prentice Hall| isbn=0-13-185644-8| url=http://williamstallings.com/COA/COA7e.html| authorlink=William Stallings}}

==External links==
{{Commons category|Arithmetic logic units}}

* [http://www.fullchipdesign.com/tyh/alu_arithmetic_logical_unit.htm ALU and its Micro-operations: Bitwise, Arithmetic and Shift]
* [http://www.mathworks.com/matlabcentral/fileexchange/loadFile.do?objectId=12762&amp;objectType=FILE A Simulator of Complex ALU in MATLAB]

{{CPU technologies|state=collapsed}}
{{Basic computer components}}

{{DEFAULTSORT:Arithmetic Logic Unit}}
[[Category:Digital circuits]]
[[Category:Central processing unit]]
[[Category:Computer arithmetic]]</text>
      <sha1>aspac4g4o4gr70hokj7jqpuarztzxwx</sha1>
    </revision>
  </page>
  <page>
    <title>Bitcoin Gold</title>
    <ns>0</ns>
    <id>55539504</id>
    <revision>
      <id>869585588</id>
      <parentid>869584001</parentid>
      <timestamp>2018-11-19T15:19:00Z</timestamp>
      <contributor>
        <username>David Gerard</username>
        <id>36389</id>
      </contributor>
      <comment>rm uncited [[WP:OR]] claims</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5457">{{multiple issues|
{{Notability|date=November 2018}}
{{more citations needed|date=December 2017}}
{{too technical|date=January 2018}}
}}

{{infobox cryptocurrency
| currency_name = Bitcoin Gold
| image_1 = Logo-Bitcoin-Gold-RGB-300x100.png
| image_2 = 
| image_title_1 = 
| symbol = 
| ticker_symbol = BTG
| coin_definition = 
| white_paper = 
| implementations = 
| initial_release_version = 0.15.0.1
| initial_release_date = {{Start date and age|df=yes|2017|11|12|p=y}}
| code_repository = {{URL|https://github.com/BTCGPU/BTCGPU}}
| status = Active
| latest_release_version = 0.15.0.2
| latest_release_date = {{Start date and age|df=yes|2018|1|6|p=y}}
| forked_from = Bitcoin
| programming_languages = [[C++]], [[Qt (software)|Qt]]
| operating_system = [[Microsoft Windows|Windows]], [[OS X]], [[Linux]]
| author = 
| developer = Bitcoin Gold Organization
| source_model = [[Open source model|Open source]]
| license = [[MIT License]]
| website = [https://bitcoingold.org/ bitcoingold.org]
| block_explorer = [https://explorer.bitcoingold.org/insight/ BitcoinGold Explorer] [https://btgexplorer.com/ BTG EXPLORER]  [https://btgexp.com/ BTGexp.com]
| ledger_start = {{Start date and age|df=yes|2009|1|3|p=y}}
| ledger_genesis = 
| hash_function = [[Equihash]]
| supply_limit = 21,000,000 BTG
| issuance = 
| timestamping = [[Proof-of-work system|Proof-of-work]]
| block_time = 10 minutes
| block_reward = 12.5 BTG (approximately to mid 2020), halved approximately every four years
| value =
| exchange_rate = 
}}

'''Bitcoin Gold''' is a distributed [[digital currency]]. It is a [[Bitcoin scalability problem#Hard fork|hard fork]] of [[Bitcoin]], the [[Open-source software|open source]] [[cryptocurrency]]. The stated purpose of the hard fork is to restore the mining functionality with common Graphics Processing Units [[Graphics processing unit|(GPU)]], in place of mining with specialized [[Application-specific integrated circuit|ASIC]] (customized chipsets), used to mine Bitcoin.

ASIC resistant GPU powered mining provides a solution, as this kind of hardware is ubiquitous, and anyone can start mining with a standard, off-the-shelf laptop computer.

Bitcoin Gold was hit by [[Double-spending|double-spending attack]] on May 18, 2018.&lt;ref&gt;''"According to a post on the Bitcoin Gold forums, the attacks have started taking place since last Friday, May 18."'', https://www.bleepingcomputer.com/news/security/hacker-makes-over-18-million-in-double-spend-attack-on-bitcoin-gold-network/&lt;/ref&gt;

== The fork ==
The hard fork occurred on October 24, 2017, at [[Blockchain|block height]] 491407. The Bitcoin Gold team used ‘post-mine’ - a mining of 100,000 coins after the fork had already occurred. The team did this via a rapid mining of approximately 8,000 blocks at 12.5 BTG per block. The bulk of premined coins have been placed into an ‘endowment’, and according to the developers will be used to grow and maintain the BTG ecosystem. However, of the 100K coins, some five percent were set aside as a bonus for the team, or about 833 coins for each of the six members.

== Differences from Bitcoin==
Bitcoin Gold uses the memory hard [[equihash]] as its [[Proof-of-work system|proof-of-work]] algorithm instead of [[SHA-2|SHA-256]].&lt;ref&gt;{{cite news|url=https://bitcoinmagazine.com/articles/bitcoin-gold-about-trial-asic-resistant-bitcoin-fork/|title=Bitcoin Gold Is About to Trial an ASIC-Resistant Bitcoin Fork|date=Oct 11, 2017|author= Aaron van Wirdum|publisher=BitcoinMagazine}}&lt;/ref&gt; Otherwise, the project follows the guidelines of the Bitcoin core project.

==May 2018 attack==
{{Main|2018 double-spend attacks on Equihash-based cryptocurrencies}}
In 2018, Bitcoin Gold (and two other cryptocurrencies) were hit a by a successful 51% hashing attack by an unknown actor.&lt;ref name="CCN"&gt;{{Cite news|url=https://www.ccn.com/bitcoin-gold-hit-by-double-spend-attack-exchanges-lose-millions/|title=Bitcoin Gold Hit by Double Spend Attack, Exchanges Lose Millions|date=2018-05-23|work=CCN|access-date=2018-05-24|language=en-US}}&lt;/ref&gt; The attackers successfully committed a double spend attack on Bitcoin Gold, a cryptocurrency forked from [[Bitcoin]] in 2017. Approximately $18.6 million USD worth of Bitcoin Gold was transferred to a [[cryptocurrency exchange]] (typically as part of a pair transaction in exchange of a fiat currency or another cryptocurrency) and then reverted in the public ledger maintained by consensus of [[Proof-of-Work]] by exercising a &gt;51% mine power.&lt;ref name="CCN"/&gt;&lt;ref&gt;{{Cite news|url=https://www.fastcompany.com/40577194/bitcoin-gold-loses-millions-as-its-hit-by-a-double-spend-attack|title=Bitcoin Gold loses millions as it is hit by a double spend attack|date=2018-05-24|work=Fast Company|access-date=2018-05-27|language=en-US}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.zdnet.com/article/bitcoin-gold-hit-with-double-spend-attacks-18-million-lost/|title=Bitcoin Gold suffers double spend attacks, $17.5 million lost {{!}} ZDNet|last=Osborne|first=Charlie|work=ZDNet|access-date=2018-05-27|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.ccn.com/bitcoin-gold-responds-to-recent-double-spend-attack/|title=Bitcoin Gold Responds to Recent Double Spend Attack|date=2018-05-25|work=CCN|access-date=2018-05-27|language=en-US}}&lt;/ref&gt;

== References ==
{{Reflist}}

{{Cryptocurrencies}}

{{Bitcoin|state=expanded}}

[[Category:Cryptography]]
[[Category:Bitcoin]]
[[Category:Bitcoin clients]]
[[Category:Currency]]</text>
      <sha1>2fumpkzizyrqvr0q32qhir1wbgu1bst</sha1>
    </revision>
  </page>
  <page>
    <title>Characterization (mathematics)</title>
    <ns>0</ns>
    <id>780886</id>
    <revision>
      <id>839803069</id>
      <parentid>836514643</parentid>
      <timestamp>2018-05-05T19:39:39Z</timestamp>
      <contributor>
        <username>Kizerkizer</username>
        <id>32069315</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2686">{{Unreferenced|date=December 2009}}
In [[mathematics]], the statement that "Property ''P'' '''characterizes''' object ''X''" means that not only does ''X'' have [[property (philosophy)|property]] ''P'', but that ''X'' is the ''only'' thing that has property ''P''. In other words, ''P'' is a defining property of ''X''. It is also common to find statements such as "Property ''Q'' characterises ''Y'' [[up to]] [[isomorphism]]". The first type of statement says in different words that the [[extension (semantics)|extension]] of ''P'' is a [[singleton (mathematics)|singleton]] set. The second says that the extension of ''Q'' is a single [[equivalence class]] (for isomorphism, in the given example &amp;mdash; depending on how ''up to'' is being used, some other [[equivalence relation]] might be involved).

==Examples==
* A [[parallelogram]] is a [[quadrilateral]] with opposite sides parallel. One of its characterizations is that the diagonals bisect each other. This means that the diagonals in all parallelograms bisect each other, and conversely, that any quadrilateral where the diagonals bisect each other must be a parallelogram. The latter statement is only true if inclusive definitions of quadrilaterals are used (so that, for example, [[rectangle]]s count as parallelograms), which is the dominant way of defining objects in mathematics nowadays.
* "Among [[probability distribution]]s on the interval from 0 to ∞ on the real line, [[memorylessness]] characterizes the [[exponential distribution]]s."  This statement means that the exponential distributions are the only such probability distributions that are memoryless. (See also [[Characterization of probability distributions]].)
* "According to [[Bohr–Mollerup theorem]], among all functions ''f'' such that ''f''(1) = 1 and ''x f''(''x'') = ''f''(''x'' + 1) for ''x'' &gt; 0, log-convexity characterizes the [[gamma function]]."  This means that among all such functions, the gamma function is the ''only'' one that is log-convex.  (A function ''f'' is ''log-convex'' [[iff]] log(''f'') is a [[convex function]].  The base of the logarithm does not matter as long as it is more than 1, but conventionally mathematicians take "log" with no subscript to mean the [[natural logarithm]], whose base is ''e''.)
* The circle is characterized as a [[manifold]] by being one-dimensional, [[compact space|compact]] and [[connected space|connected]]; here the characterization, as a smooth manifold, is [[up to]] [[diffeomorphism]].

== See also ==

* [[Characterization of probability distributions]]

{{DEFAULTSORT:Characterization (Mathematics)}}
[[Category:Mathematical terminology]]
[[Category:Equivalence (mathematics)]]</text>
      <sha1>gacx700deetcwpx88p1qx4ho7ause2x</sha1>
    </revision>
  </page>
  <page>
    <title>Colin Adams (mathematician)</title>
    <ns>0</ns>
    <id>3499637</id>
    <revision>
      <id>835649549</id>
      <parentid>808324001</parentid>
      <timestamp>2018-04-09T23:23:14Z</timestamp>
      <contributor>
        <username>Fiveslats</username>
        <id>33471311</id>
      </contributor>
      <comment>/* Selected publications */ added "Bounds on Ubercrossing and Petal Number for Knots"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5373">{{About|the mathematician|the TV executive|Colin Adams (executive)}}
[[File:ColinAdamsphoto.jpg|thumb|alt=A photograph of Colin Adams.|Colin Adams.]]
'''Colin Conrad Adams''' (born October 13, 1956) is a [[mathematician]] primarily working in the areas of [[hyperbolic 3-manifold]]s and [[knot theory]].  His book, ''The Knot Book'', has been praised for its accessible approach to advanced topics in [[knot theory]].  He is currently Francis Christopher Oakley Third Century Professor of Mathematics at [[Williams College]], where he has been since 1985.  He writes "Mathematically Bent", a column of math humor for the ''[[Mathematical Intelligencer]]''.

== Academic career ==
Adams received a [[B.Sc.]] from [[MIT]] in 1978 and a [[Ph.D.]] in [[mathematics]] from the [[University of Wisconsin–Madison]] in 1983.  His dissertation was entitled "Hyperbolic Structures on Link Complements" and supervised by [[James W. Cannon|James Cannon]].

In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-03.&lt;/ref&gt;

==Work==
Among his earliest contributions is his theorem that the [[Gieseking manifold]] is the unique cusped [[hyperbolic 3-manifold]] of smallest volume.  The proof utilizes [[horoball]]-packing arguments.  Adams is known for his clever use of such arguments utilizing horoball patterns and his work would be used in the later proof by Cao and Meyerhoff that the smallest cusped orientable hyperbolic 3-manifolds are precisely the [[figure-eight knot (mathematics)|figure-eight knot]] [[knot complement|complement]] and its sibling manifold. 

Adams has investigated and defined a variety of geometric invariants of [[hyperbolic link]]s and hyperbolic 3-manifolds in general.  He developed techniques for working with volumes of special classes of hyperbolic links.  He proved augmented alternating links, which he defined, were hyperbolic.  In addition, he has defined almost alternating and toroidally alternating links.  He has often collaborated and published this research with students from SMALL, an undergraduate summer research program at Williams.

== Books ==
* C. Adams, ''The Knot Book: An elementary introduction to the mathematical theory of knots.'' Revised reprint of the 1994 original. American Mathematical Society, Providence, RI, 2004. xiv+307 pp.&amp;nbsp;{{ISBN|0-8218-3678-1}}
* C. Adams, [[Joel Hass|J. Hass]], [[Abigail Thompson|A. Thompson]], ''How to Ace Calculus: The Streetwise Guide.'' W. H. Freeman and Company, 1998.  {{ISBN|0-7167-3160-6}}
* C. Adams, [[Joel Hass|J. Hass]], [[Abigail Thompson|A. Thompson]], ''How to Ace the Rest of Calculus: The Streetwise Guide.'' W. H. Freeman and Company, 2001.  {{ISBN|0-7167-4174-1}}
* C. Adams, ''Why Knot?: An Introduction to the Mathematical Theory of Knots.''  Key College, 2004.  {{ISBN|1-931914-22-2}}
* C. Adams, R. Franzosa, "Introduction to Topology: Pure and Applied." Prentice Hall, 2007. {{ISBN|0-13-184869-0}}
* C. Adams, "Riot at the Calc Exam and Other Mathematically Bent Stories." American Mathematical Society, 2009. {{ISBN|0-8218-4817-8}}
* C. Adams,"Zombies &amp; Calculus." Princeton University Press, 2014. {{ISBN|978-0691161907}}
* C. Adams, J. Rogawski, "Calculus." W. H. Freeman, 2015. {{ISBN|978-1464125263}}

== Selected publications ==
* C. Adams, ''Thrice-punctured spheres in hyperbolic $3$-manifolds.''  Trans. Am. Math. Soc. 287 (1985), no. 2, 645—656.
* C. Adams, ''Augmented alternating link complements are hyperbolic.''  Low-dimensional topology and Kleinian groups (Coventry/Durham, 1984), 115—130,  London Math. Soc. Lecture Note Ser., 112, Cambridge Univ. Press, Cambridge, 1986.
* C. Adams, ''The noncompact hyperbolic $3$-manifold of minimal volume.''  Proc. Am. Math. Soc. 100  (1987),  no. 4, 601—606.
* C. Adams and A. Reid, ''Systoles of hyperbolic $3$-manifolds.'' Math. Proc. Camb. Philos. Soc. 128 (2000), no. 1, 103—110.
* C. Adams; A. Colestock; J. Fowler; W. Gillam; E. Katerman. ''Cusp size bounds from singular surfaces in hyperbolic 3-manifolds.''  Trans. Am. Math. Soc. 358 (2006), no. 2, 727—741
* C. Adams; O. Capovilla-Searle, J. Freeman, D. Irvine, S. Petti, D.Vitek, A. Weber, S. Zhang. ''Bounds on Ubercrossing and Petal Number for Knots.'' Journal of Knot Theory and its Ramifications,Vol. 24, No. 2 (2015) 1550012 (16 pages).

== References ==
{{reflist}}
* [http://www.eurekalert.org/pub_releases/1998-02/WC-MPWD-120298.php Math Prof. Wins Distinguished Teaching Award]

== External links ==
* [http://sites.williams.edu/cadams/ Faculty page] at Williams
* [http://genealogy.math.ndsu.nodak.edu/html/id.phtml?id=9763 Mathematical genealogy]
* [http://www.msri.org/publications/ln/msri/1996/conv/adams/1/index.html MSRI talk by Slugbate]
* [http://euclid.colorado.edu/~jnc/MelSlugbate.html A typical announcement for a Slugbate talk with a photo]

{{Authority control}}
{{DEFAULTSORT:Adams, Colin}}
[[Category:1956 births]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Topologists]]
[[Category:University of Wisconsin–Madison alumni]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Williams College faculty]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>t8ykr4ei4g80d2dh1testoa6vfcazs8</sha1>
    </revision>
  </page>
  <page>
    <title>Compactly generated group</title>
    <ns>0</ns>
    <id>594682</id>
    <revision>
      <id>743601072</id>
      <parentid>621579055</parentid>
      <timestamp>2016-10-10T10:23:52Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1688">In [[mathematics]], a '''compactly generated (topological) group''' is a [[topological group]] ''G'' which is [[generating set of a group|algebraically generated]] by one of its [[compact space|compact]] subsets.&lt;ref&gt;{{citation|title=Locally Compact Groups|first=Markus|last=Stroppel|publisher=European Mathematical Society|year=2006|isbn=9783037190166|page=44|url=https://books.google.com/books?id=3_BPupMDRr8C&amp;pg=PA44}}.&lt;/ref&gt; This should not be confused with the unrelated notion (widely used in [[algebraic topology]]) of a [[compactly generated space]] -- one whose [[topology]] is generated (in a suitable sense) by its compact subspaces.

== Definition ==

A [[topological group]] ''G'' is said to be '''compactly generated''' if there exists a compact subset ''K'' of ''G'' such that

:&lt;math&gt;\langle K\rangle = \bigcup_{n \in \mathbb{N}} (K \cup K^{-1})^n = G.&lt;/math&gt;

So if ''K'' is symmetric, i.e. ''K'' = ''K''&lt;sup&gt; &amp;minus;1&lt;/sup&gt;, then 

:&lt;math&gt;G = \bigcup_{n \in \mathbb{N}} K^n.&lt;/math&gt;

== Locally compact case ==

This property is interesting in the case of [[Locally compact space|locally compact]] topological groups, since locally compact compactly generated topological groups can be approximated by locally compact, [[separable space|separable]] [[metric space|metric]] factor groups of ''G''. More precisely, for a sequence 

:''U''&lt;sub&gt;''n''&lt;/sub&gt; 

of open identity neighborhoods, there exists a [[normal subgroup]] ''N'' contained in the intersection of that sequence, such that 

:''G''/''N'' 

is locally compact metric separable (the [[Kakutani-Kodaira-Montgomery-Zippin theorem]]).

==References==
{{reflist}}

[[Category:Topological groups]]
{{topology-stub}}</text>
      <sha1>fts35du3yf5rf3hyhfe78n4qqp45nhd</sha1>
    </revision>
  </page>
  <page>
    <title>Computational Statistics (journal)</title>
    <ns>0</ns>
    <id>27743220</id>
    <revision>
      <id>869559937</id>
      <parentid>842028032</parentid>
      <timestamp>2018-11-19T10:55:06Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: title. Add: title-link. Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1972">{{about|the journal Computational Statistics|computational statistics (the subject)|Computational statistics}}
{{Infobox journal
| title = Computational Statistics
| formernames = Computational Statistics Quarterly
| cover = 
| abbreviation = Comput. Stat.

| mathscinet=Comput. Statist.
| discipline = [[Computational statistics]]
| editor = Yuichi Mori
| publisher = [[Springer Science+Business Media]]
| country =
| history = 1986–present
| frequency = Quarterly
| impact = 0.520
| impact-year = 2015
| website = https://www.springer.com/statistics/journal/180
| link1 = https://link.springer.com/journal/volumesAndIssues/180
| link1-name = Online access
| ISSN = 0943-4062
| eISSN = 1613-9658
| CODEN = CSTAEB
| LCCN = 95641008
| OCLC = 288979187
}}
'''''Computational Statistics''''' is a quarterly [[peer-reviewed]] [[scientific journal]] that publishes applications and research in the field of [[computational statistics]], as well as reviews of hardware, software, and books. According to the ''[[Journal Citation Reports]]'', the journal has a 2012 [[impact factor]] of 0.482.&lt;ref name=WoS&gt;{{cite book |year=2013 |chapter=Computational Statistics |title=2012 Journal Citation Reports |publisher=[[Thomson Reuters]] |edition=Science |series=[[Web of Science]] |title-link=Journal Citation Reports }}&lt;/ref&gt; It was established in 1986 as ''Computational Statistics Quarterly'' and obtained its current title in 1992. The journal is published by [[Springer Science+Business Media]] and the [[editor-in-chief]] is Yuichi Mori ([[Okayama University of Science]]).

== See also ==
*[[List of statistics journals]]

== References ==
{{Reflist}}

== External links ==
* {{Official website| https://www.springer.com/statistics/journal/180}}

{{Statistics journals}}

{{DEFAULTSORT:Computational Statistics}}
[[Category:Computational statistics journals]]
[[Category:Quarterly journals]]
[[Category:English-language journals]]


{{Statistics-stub}}
{{compu-journal-stub}}</text>
      <sha1>h6b3hm7x6jlwoujr0xpxy4gcj1zmoww</sha1>
    </revision>
  </page>
  <page>
    <title>Cox–Zucker machine</title>
    <ns>0</ns>
    <id>16273876</id>
    <revision>
      <id>841672393</id>
      <parentid>839488670</parentid>
      <timestamp>2018-05-17T08:43:20Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* top */Journal cites, added 1 DOI</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1364">The '''Cox–Zucker machine''' is an [[algorithm]] created by [[David A. Cox]] and [[Steven Zucker]]. This algorithm determines if a given set of sections provides a basis (up to torsion) for the [[Mordell–Weil group]] of an [[elliptic surface]] ''E'' → ''S'' where ''S'' is isomorphic to the [[projective line]].&lt;ref name="Schwartz-1984"&gt;{{Cite journal |last=Schwartz |first=Charles F. |date=1984 |title=A Mordell–Weil Group of Rank 8, and a Subgroup of Finite Index |url=https://projecteuclid.org/euclid.nmj/1118787426 |journal=[[Nagoya Mathematical Journal]] |volume=93 |pages=17–26 |mr=0738915 |zbl=0504.14031 |doi=10.1017/S0027763000020705}}&lt;/ref&gt;

The algorithm was first published in the 1979 paper "Intersection numbers of sections of [[elliptic surface]]s" by Cox and Zucker&lt;ref&gt;{{Cite journal |last=Cox |first=David A. |last2=Zucker |first2=Steven |date=1979-02-01 |title=Intersection numbers of sections of elliptic surfaces |journal=[[Inventiones mathematicae]] |language=en |volume=53 |issue=1 |pages=1–44 |doi=10.1007/BF01403189 |issn=0020-9910}}&lt;/ref&gt; and it was later named the "Cox–Zucker machine" by Charles Schwartz in 1984.&lt;ref name="Schwartz-1984" /&gt;

== References ==
{{Reflist}}

{{DEFAULTSORT:Cox-Zucker machine}}
[[Category:Complex manifolds]]
[[Category:Birational geometry]]
[[Category:Algebraic surfaces]]

{{geometry-stub}}</text>
      <sha1>o6nsy5fesrlesv7sctjdr9rgt0wqe4c</sha1>
    </revision>
  </page>
  <page>
    <title>Crystal system</title>
    <ns>0</ns>
    <id>456410</id>
    <revision>
      <id>869312662</id>
      <parentid>869312130</parentid>
      <timestamp>2018-11-17T20:36:15Z</timestamp>
      <contributor>
        <username>IronGargoyle</username>
        <id>820190</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/Water867|Water867]] ([[User talk:Water867|talk]]) ([[WP:HG|HG]]) (3.3.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28772">{{short description|Classification of crystalline materials by their three dimensional structural geometry}}
[[File:Carbon lattice diamond.png|thumb|The [[Diamond cubic|diamond crystal structure]] belongs to the face-centered [[cubic crystal system|cubic lattice]], with a repeated two-atom pattern.]]
In [[crystallography]], the terms '''crystal system''', '''crystal family''', and '''lattice system''' each refer to one of several classes of [[space group]]s, [[Bravais lattice|lattice]]s, [[point group]]s, or [[crystal]]s. Informally, two crystals are in the same crystal system if they have similar symmetries, although there are many exceptions to this.

Crystal systems, crystal families and lattice systems are similar but slightly different, and there is widespread confusion between them: in particular the [[trigonal crystal system]] is often confused with the [[rhombohedral lattice system]], and the term "crystal system" is sometimes used to mean "lattice system" or "crystal family".

Space groups and crystals are divided into seven crystal systems according to their point groups, and into seven lattice systems according to their [[Bravais lattice]]s. Five of the crystal systems are essentially the same as five of the lattice systems, but the hexagonal and trigonal crystal systems differ from the hexagonal and rhombohedral lattice systems. The six crystal families are formed by combining the hexagonal and trigonal crystal systems into one [[hexagonal crystal family|hexagonal family]], in order to eliminate this confusion.

==Overview==
[[File:Hanksite.JPG|thumb|Hexagonal [[hanksite]] crystal, with threefold ''c''-axis symmetry]]
A '''lattice system''' is a class of lattices with the same set of lattice [[Point groups in three dimensions|point groups]], which are subgroups of the [[Space group|arithmetic crystal classes]]. The 14 [[Bravais lattice]]s are grouped into seven lattice systems: triclinic, monoclinic, orthorhombic, tetragonal, rhombohedral, hexagonal, and cubic.

In a '''crystal system''', a set of point groups and their corresponding space groups are assigned to a lattice system. Of the 32 point groups that exist in three dimensions, most are assigned to only one lattice system, in which case both the crystal and lattice systems have the same name. However, five point groups are assigned to two lattice systems, rhombohedral and hexagonal, because both exhibit threefold rotational symmetry. These point groups are assigned to the trigonal crystal system. In total there are seven crystal systems: triclinic, monoclinic, orthorhombic, tetragonal, trigonal, hexagonal, and cubic.

A '''crystal family''' is determined by lattices and point groups. It is formed by combining crystal systems which have space groups assigned to a common lattice system. In three dimensions, the crystal families and  systems are identical, except the hexagonal and trigonal crystal systems, which are combined into one hexagonal crystal family. In total there are six crystal families: triclinic, monoclinic, orthorhombic, tetragonal, hexagonal, and cubic.

Spaces with less than three dimensions have the same number of crystal systems, crystal families and lattice systems. In one-dimensional space, there is one crystal system. In 2D space, there are four crystal systems: oblique, rectangular, square, and hexagonal.

The relation between three-dimensional crystal families, crystal systems and lattice systems is shown in the following table: 
{|class="wikitable" cellpadding=0 style="margin: 1em auto; text-align: center;"
|-
!Crystal family (6)
!Crystal system (7)
!Required symmetries of point group
![[Crystallographic point group|Point groups]]
![[Space group]]s
![[Bravais lattice]]s
![[Lattice system]]
|-
|colspan=2|[[Triclinic crystal system|Triclinic]] 
|None
|2
|2
|1
|[[Triclinic crystal system|Triclinic]]
|-
|colspan=2|[[Monoclinic crystal system|monoclinic]] 
|1 twofold [[rotational symmetry|axis of rotation]] or 1 [[reflection symmetry|mirror plane]]
|3
|13
|2
|[[Monoclinic crystal system|monoclinic]]
|-
|colspan=2|[[Orthorhombic crystal system|Orthorhombic]]
| 3 twofold axes of rotation or 1 twofold axis of rotation and 2 mirror planes. 
|3
|59
|4
|[[Orthorhombic crystal system|Orthorhombic]]
|-
|colspan=2|[[Tetragonal crystal system|Tetragonal]]
| 1 fourfold axis of rotation
|7
|68
|2
|[[Tetragonal crystal system|Tetragonal]]
|-
|rowspan=3|[[Hexagonal crystal family|Hexagonal]]
|rowspan=2|Trigonal
|rowspan=2|1 threefold axis of rotation
|rowspan=2|5
|7
|1
|Rhombohedral
|-
|18
|rowspan=2|1
|rowspan=2|Hexagonal
|-
|Hexagonal
|1 sixfold axis of rotation
|7
|27
|-
|colspan=2|[[cubic crystal system|Cubic]] 
|4 threefold axes of rotation
|5
|36
|3
|[[cubic crystal system|Cubic]]
|- bgcolor=#e0e0e0
| 6
|7
|'''Total'''
|32
|230
|14
|7
|}

:''Note: there is no "trigonal" lattice system. To avoid confusion of terminology, the term "trigonal lattice" is not used.''

==Crystal classes==
{{main|Crystallographic point group}}
The 7 crystal systems consist of 32 crystal classes (corresponding to the 32 crystallographic point groups) as shown in the following table:

{| class=wikitable
|-
! Crystal family
! Crystal system
! [[Point group]] / Crystal class
! [[Schönflies notation|Schönflies]]
! [[Hermann–Mauguin notation|Hermann–Mauguin]]
! [[Orbifold notation|Orbifold]]
! [[Coxeter notation|Coxeter]]
! Point symmetry
! [[Symmetry number|Order]]
! [[Group theory#Abstract groups|Abstract group]]
|-
| rowspan=2 colspan=2| [[triclinic crystal system|triclinic]]
| pedial	
| C&lt;sub&gt;1&lt;/sub&gt;
| 1
| 11
| [&amp;nbsp;]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]] [[Polar point group|polar]]
| 1
| trivial &lt;math&gt;\mathbb{Z}_1&lt;/math&gt;
|-
| pinacoidal
| C&lt;sub&gt;i&lt;/sub&gt; (S&lt;sub&gt;2&lt;/sub&gt;)
| {{overline|1}}
| 1x
| [2,1&lt;sup&gt;+&lt;/sup&gt;]
| [[centrosymmetric]]
| 2
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_2&lt;/math&gt;
|-
| rowspan=3 colspan=2 | [[monoclinic crystal system|monoclinic]]
| sphenoidal
| C&lt;sub&gt;2&lt;/sub&gt;
| 2
| 22	
| [2,2]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]] [[Polar point group|polar]]
| 2
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_2&lt;/math&gt;
|-
| domatic
| C&lt;sub&gt;s&lt;/sub&gt; (C&lt;sub&gt;1h&lt;/sub&gt;)
| m
| *11
| [&amp;nbsp;]
| [[Polar point group|polar]]
| 2
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_2&lt;/math&gt;
|-
| [[prism (geometry)|prismatic]]
| C&lt;sub&gt;2h&lt;/sub&gt;	
| 2/m
| 2*
| [2,2&lt;sup&gt;+&lt;/sup&gt;]
| [[centrosymmetric]]
| 4
| [[Klein four-group|Klein four]] &lt;math&gt;\mathbb{V} = \mathbb{Z}_2\times\mathbb{Z}_2&lt;/math&gt;
|-
| rowspan=3 colspan=2| [[orthorhombic crystal system|orthorhombic]]
| rhombic-disphenoidal
| D&lt;sub&gt;2&lt;/sub&gt; (V)
| 222
| 222	
| [2,2]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]]
| 4
| [[Klein four-group|Klein four]] &lt;math&gt;\mathbb{V} = \mathbb{Z}_2\times\mathbb{Z}_2&lt;/math&gt;
|-
| rhombic-[[Pyramid (geometry)|pyramidal]]
| C&lt;sub&gt;2v&lt;/sub&gt;	
| mm2
| *22
| [2]
| [[Polar point group|polar]]
| 4
| [[Klein four-group|Klein four]] &lt;math&gt;\mathbb{V} = \mathbb{Z}_2\times\mathbb{Z}_2&lt;/math&gt;
|-
| rhombic-[[dipyramid]]al
| D&lt;sub&gt;2h&lt;/sub&gt; (V&lt;sub&gt;h&lt;/sub&gt;)	
| mmm
| *222
| [2,2]
| [[centrosymmetric]]
| 8
| &lt;math&gt;\mathbb{V}\times\mathbb{Z}_2&lt;/math&gt;
|-
| rowspan=7 colspan=2| [[tetragonal crystal system|tetragonal]]
| tetragonal-pyramidal	
| C&lt;sub&gt;4&lt;/sub&gt;
| 4
| 44
| [4]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]] [[Polar point group|polar]]
| 4
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_4&lt;/math&gt;
|-
| tetragonal-disphenoidal
| S&lt;sub&gt;4&lt;/sub&gt;	
| {{overline|4}}
| 2x
| [2&lt;sup&gt;+&lt;/sup&gt;,2]
| [[non-centrosymmetric]]
| 4
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_4&lt;/math&gt;
|-
| tetragonal-dipyramidal
| C&lt;sub&gt;4h&lt;/sub&gt;	
| 4/m
| 4*
| [2,4&lt;sup&gt;+&lt;/sup&gt;]
| [[centrosymmetric]]
| 8
| &lt;math&gt;\mathbb{Z}_4\times\mathbb{Z}_2&lt;/math&gt;
|-
| tetragonal-trapezohedral
| D&lt;sub&gt;4&lt;/sub&gt;	
| 422
| 422
| [2,4]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]]
| 8
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_8 = \mathbb{Z}_4\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| ditetragonal-pyramidal
| C&lt;sub&gt;4v&lt;/sub&gt;	
| 4mm
| *44
| [4]
| [[Polar point group|polar]]
| 8
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_8 = \mathbb{Z}_4\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| tetragonal-scalenohedral
| D&lt;sub&gt;2d&lt;/sub&gt; (V&lt;sub&gt;d&lt;/sub&gt;)
| {{overline|4}}2m or {{overline|4}}m2
| 2*2
| [2&lt;sup&gt;+&lt;/sup&gt;,4]
| [[non-centrosymmetric]]
| 8
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_8 = \mathbb{Z}_4\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| ditetragonal-dipyramidal
| D&lt;sub&gt;4h&lt;/sub&gt;	
| 4/mmm
| *422
| [2,4]
| [[centrosymmetric]]
| 16
| &lt;math&gt;\mathbb{D}_8\times\mathbb{Z}_2&lt;/math&gt;
|-
| rowspan=12|[[hexagonal crystal family|hexagonal]] || rowspan=5 | trigonal 
| trigonal-pyramidal	
| C&lt;sub&gt;3&lt;/sub&gt;
| 3
| 33
| [3]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]] [[Polar point group|polar]]
| 3
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_3&lt;/math&gt;
|-
| rhombohedral
| C&lt;sub&gt;3i&lt;/sub&gt; (S&lt;sub&gt;6&lt;/sub&gt;)
| {{overline|3}}
| 3x
| [2&lt;sup&gt;+&lt;/sup&gt;,3&lt;sup&gt;+&lt;/sup&gt;]
| [[centrosymmetric]]
| 6
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_6 = \mathbb{Z}_3\times\mathbb{Z}_2&lt;/math&gt;
|-
| trigonal-trapezohedral
| D&lt;sub&gt;3&lt;/sub&gt;	
| 32 or 321 or 312
| 322
| [3,2]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]]
| 6
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_6 = \mathbb{Z}_3\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| ditrigonal-pyramidal
| C&lt;sub&gt;3v&lt;/sub&gt;	
| 3m or 3m1 or 31m
| *33
| [3]
| [[Polar point group|polar]]
| 6
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_6 = \mathbb{Z}_3\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| ditrigonal-scalenohedral
| D&lt;sub&gt;3d&lt;/sub&gt;	
| {{overline|3}}m or {{overline|3}}m1 or {{overline|3}}1m
| 2*3
| [2&lt;sup&gt;+&lt;/sup&gt;,6]
| [[centrosymmetric]]
| 12
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_{12} = \mathbb{Z}_6\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| rowspan=7 | hexagonal
| hexagonal-pyramidal	
| C&lt;sub&gt;6&lt;/sub&gt;
| 6
| 66
| [6]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]] [[Polar point group|polar]]
| 6
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_6 = \mathbb{Z}_3\times\mathbb{Z}_2&lt;/math&gt;
|-
| trigonal-dipyramidal
| C&lt;sub&gt;3h&lt;/sub&gt;
| {{overline|6}}
| 3*
| [2,3&lt;sup&gt;+&lt;/sup&gt;]
| [[non-centrosymmetric]]
| 6
| [[Cyclic group|cyclic]] &lt;math&gt;\mathbb{Z}_6 = \mathbb{Z}_3\times\mathbb{Z}_2&lt;/math&gt;
|-
| hexagonal-dipyramidal
| C&lt;sub&gt;6h&lt;/sub&gt;	
| 6/m
| 6*
| [2,6&lt;sup&gt;+&lt;/sup&gt;]
| [[centrosymmetric]]
| 12
| &lt;math&gt;\mathbb{Z}_6\times\mathbb{Z}_2&lt;/math&gt;
|-
| hexagonal-trapezohedral
| D&lt;sub&gt;6&lt;/sub&gt;	
| 622
| 622
| [2,6]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]]
| 12
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_{12} = \mathbb{Z}_6\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| dihexagonal-pyramidal
| C&lt;sub&gt;6v&lt;/sub&gt;	
| 6mm
| *66
| [6]
| [[Polar point group|polar]]
| 12
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_{12} = \mathbb{Z}_6\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| ditrigonal-dipyramidal
| D&lt;sub&gt;3h&lt;/sub&gt;	
| {{overline|6}}m2 or {{overline|6}}2m
| *322
| [2,3]
| [[non-centrosymmetric]]
| 12
| [[Dihedral group|dihedral]] &lt;math&gt;\mathbb{D}_{12} = \mathbb{Z}_6\rtimes\mathbb{Z}_2&lt;/math&gt;
|-
| dihexagonal-dipyramidal
| D&lt;sub&gt;6h&lt;/sub&gt;	
| 6/mmm
| *622
| [2,6]
| [[centrosymmetric]]
| 24
| &lt;math&gt;\mathbb{D}_{12}\times\mathbb{Z}_2&lt;/math&gt; 
|-
| rowspan=5 colspan=2 | [[cubic crystal system|cubic]]
| tetartoidal
| T || 	23
| 332
| [3,3]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]]
| 12
| [[alternating group|alternating]] &lt;math&gt;\mathbb{A}_4&lt;/math&gt;
|-
| diploidal
| T&lt;sub&gt;h&lt;/sub&gt;	
| m{{overline|3}}
| 3*2
| [3&lt;sup&gt;+&lt;/sup&gt;,4]
| [[centrosymmetric]]
| 24
| &lt;math&gt;\mathbb{A}_4\times\mathbb{Z}_2&lt;/math&gt; 
|-
| gyroidal
| O
| 432
| 432
| [4,3]&lt;sup&gt;+&lt;/sup&gt;
| [[Chirality (chemistry)|enantiomorphic]]
| 24
| [[symmetric group|symmetric]] &lt;math&gt;\mathbb{S}_4&lt;/math&gt;
|-
| [[tetrakis hexahedron|hextetrahedral]]
| T&lt;sub&gt;d&lt;/sub&gt;	
| {{overline|4}}3m
| *332
| [3,3]
| [[non-centrosymmetric]]
| 24
| [[symmetric group|symmetric]] &lt;math&gt;\mathbb{S}_4&lt;/math&gt;
|-
| [[disdyakis dodecahedron|hexoctahedral]]
| O&lt;sub&gt;h&lt;/sub&gt;	
| m{{overline|3}}m
| *432
| [4,3]
| [[centrosymmetric]]
| 48
| &lt;math&gt;\mathbb{S}_4\times\mathbb{Z}_2&lt;/math&gt; 
|}

Point symmetry can be thought of in the following fashion: consider the coordinates which make up the structure, and project them all through a single point, so that (''x'',''y'',''z'') becomes (−''x'',−''y'',−''z''). This is the 'inverted structure'. If the original structure and inverted structure are identical, then the structure is ''centrosymmetric''. Otherwise it is ''non-centrosymmetric''. Still, even for non-centrosymmetric case, inverted structure in some cases can be rotated to align with the original structure. This is the case of non-centrosymmetric achiral structure. If the inverted structure cannot be rotated to align with the original structure, then the structure is chiral (enantiomorphic) and its symmetry group is ''enantiomorphic''.&lt;ref&gt;{{cite journal|first=Howard D.|last=Flack|year=2003|title=Chiral and Achiral Crystal Structures|journal=Helvetica Chimica Acta|volume=86|issue=4|pages= 905–921|doi=10.1002/hlca.200390109|citeseerx=10.1.1.537.266}}&lt;/ref&gt;

A direction (meaning a line without an arrow) is called ''polar'' if its two directional senses are geometrically or physically different. A polar symmetry{{clarify|date=October 2014}} direction of a crystal is called a polar axis.&lt;ref&gt;{{harvp|Hahn|2002|p=804}}&lt;/ref&gt; Groups containing a polar axis are called ''[[polar point group|polar]]''. A polar crystal possess a "unique" axis (found in no other directions) such that some geometrical or physical property is different at the two ends of this axis. It may develop a [[Polarization density|dielectric polarization]], e.g. in [[Pyroelectricity|pyroelectric crystals]]. A polar axis can occur only in non-centrosymmetric structures. There should also not be a mirror plane or twofold axis perpendicular to the polar axis, because they will make both directions of the axis equivalent.

The [[crystal structure]]s of chiral biological molecules (such as [[protein]] structures) can only occur in the 65 [[Chirality (chemistry)|enantiomorphic]] space groups (biological molecules are usually [[Chirality (chemistry)|chiral]]). 
&lt;!--The protein assemblies themselves may have symmetries other than those given above, because they are not intrinsically restricted by the [[Crystallographic restriction theorem]]. For example the [[Rad52]] DNA binding protein has an 11-fold rotational symmetry (in human), however, it must form crystals in one of the 65 [[Chirality (chemistry)|enantiomorphic]] space groups given above. --&gt;

==Bravais lattices==
{{main|Bravais lattice}}
The distribution of the 14 Bravais lattices into lattice systems and crystal families is given in the following table.

{| class=wikitable
!rowspan=2|Crystal family
!rowspan=2|Lattice system
!rowspan=2|[[Schoenflies notation|Schönflies]]
!colspan=4|14 Bravais Lattices
|-
! Primitive || Base-centered || Body-centered || Face-centered
|- align=center
|colspan=2|[[triclinic crystal system|triclinic]]
|C&lt;sub&gt;i&lt;/sub&gt;
| [[File:Triclinic.svg|80px|Triclinic]]
|
|
|
|- align=center
|colspan=2|[[monoclinic crystal system|monoclinic]]
|C&lt;sub&gt;2h&lt;/sub&gt;
| [[File:Monoclinic.svg|80px|Monoclinic, simple]]
| [[File:Monoclinic-base-centered.svg|80px|Monoclinic, centered]]
|
|
|- align=center
|colspan=2|[[orthorhombic crystal system|orthorhombic]]
|D&lt;sub&gt;2h&lt;/sub&gt;
| [[File:Orthorhombic.svg|80px|Orthorhombic, simple]]
| [[File:Orthorhombic-base-centered.svg|80px|Orthorhombic, base-centered]]
| [[File:Orthorhombic-body-centered.svg|80px|Orthorhombic, body-centered]]
| [[File:Orthorhombic-face-centered.svg|80px|Orthorhombic, face-centered]]
|- align=center
|colspan=2|[[tetragonal crystal system|tetragonal]]
|D&lt;sub&gt;4h&lt;/sub&gt;
| [[File:Tetragonal.svg|80px|Tetragonal, simple]]
|
| [[File:Tetragonal-body-centered.svg|80px|Tetragonal, body-centered]]
|
|- align=center
|rowspan=2|[[hexagonal crystal family|hexagonal]]
|rhombohedral
|D&lt;sub&gt;3d&lt;/sub&gt;
| [[File:Rhombohedral.svg|80px|Rhombohedral]]
|
|
|
|- align=center
|hexagonal
|D&lt;sub&gt;6h&lt;/sub&gt;
| [[File:Hexagonal latticeFRONT.svg|80px|Hexagonal]]
|
|
|
|- align=center
|colspan=2|[[cubic crystal system|cubic]]
|O&lt;sub&gt;h&lt;/sub&gt;
| [[File:Cubic.svg|80px|Cubic, simple]]
|
| [[File:Cubic-body-centered.svg|80px|Cubic, body-centered]]
| [[File:Cubic-face-centered.svg|80px|Cubic, face-centered]]
|}
{{Clear}}

In [[geometry]] and [[crystallography]], a '''Bravais lattice''' is a category of [[symmetry group]]s for [[translational symmetry]] in three directions, or correspondingly, a category of translation [[Lattice (group)|lattice]]s.

Such symmetry groups consist of translations by vectors of the form

:'''R''' = ''n''&lt;sub&gt;1&lt;/sub&gt;'''a'''&lt;sub&gt;1&lt;/sub&gt; + ''n''&lt;sub&gt;2&lt;/sub&gt;'''a'''&lt;sub&gt;2&lt;/sub&gt; + ''n''&lt;sub&gt;3&lt;/sub&gt;'''a'''&lt;sub&gt;3&lt;/sub&gt;,

where ''n''&lt;sub&gt;1&lt;/sub&gt;, ''n''&lt;sub&gt;2&lt;/sub&gt;, and ''n''&lt;sub&gt;3&lt;/sub&gt; are [[integer]]s and '''a'''&lt;sub&gt;1&lt;/sub&gt;, '''a'''&lt;sub&gt;2&lt;/sub&gt;, and '''a'''&lt;sub&gt;3&lt;/sub&gt; are three non-coplanar vectors, called ''primitive vectors''.

These lattices are classified by [[space group]] of the translation lattice itself; there are 14 Bravais lattices in three dimensions; each can apply in one lattice system only. They represent the maximum symmetry a structure with the translational symmetry concerned can have.

All crystalline materials must, by definition fit in one of these arrangements (not including [[quasicrystal]]s).

For convenience a Bravais lattice is depicted by a unit cell which is a factor 1, 2, 3 or 4 larger than the [[primitive cell]]. Depending on the symmetry of a crystal or other pattern, the [[fundamental domain]] is again smaller, up to a factor 48.

The Bravais lattices were studied by [[Moritz Ludwig Frankenheim]] in 1842, who found that there were 15 Bravais lattices. This was corrected to 14 by [[Auguste Bravais|A. Bravais]] in 1848&lt;!-- or 1849 or 1850, Britannica has two different years--&gt;.

==In four-dimensional space==

‌The four-dimensional unit cell is defined by four edge lengths (''a'', ''b'', ''c'', ''d'') and six interaxial angles (''α'', ''β'', ''γ'', ''δ'', ''ε'', ''ζ''). The following conditions for the lattice parameters define 23 crystal families
{|class="wikitable" cellpadding=4 cellspacing=0 style="text-align:center"
|+Crystal families in 4D space
!No.!!Family!!Edge lengths!!Interaxial angles
|-
|1|| Hexaclinic|| ''a'' ≠ ''b'' ≠ ''c'' ≠ ''d''|| ''α'' ≠ ''β'' ≠ ''γ'' ≠ ''δ'' ≠ ''ε'' ≠ ''ζ'' ≠ 90°
|-
|2|| Triclinic|| ''a'' ≠ ''b'' ≠ ''c'' ≠ ''d''|| ''α'' ≠ ''β'' ≠ ''γ'' ≠ 90°&lt;br&gt;''δ'' = ''ε'' = ''ζ'' = 90°
|-
|3|| Diclinic|| ''a'' ≠ ''b'' ≠ ''c'' ≠ ''d''|| ''α'' ≠ 90°&lt;br&gt;''β'' = ''γ'' = ''δ'' = ''ε'' = 90°&lt;br&gt;''ζ'' ≠ 90°
|-
|4|| Monoclinic|| ''a'' ≠ ''b'' ≠ ''c'' ≠ ''d''|| ''α'' ≠ 90°&lt;br&gt;''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ'' = 90°
|-
|5|| Orthogonal|| ''a'' ≠ ''b'' ≠ ''c'' ≠ ''d''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ'' = 90°
|-
|6|| Tetragonal monoclinic|| ''a'' ≠ ''b'' = ''c'' ≠ ''d''|| ''α'' ≠ 90°&lt;br&gt;''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ'' = 90°
|-
|7|| Hexagonal monoclinic|| ''a'' ≠ ''b'' = ''c'' ≠ ''d''|| ''α'' ≠ 90°&lt;br&gt;''β'' = ''γ'' = ''δ'' = ''ε'' = 90°&lt;br&gt;''ζ'' = 120°
|-
|8|| Ditetragonal diclinic|| ''a'' = ''d'' ≠ ''b'' = ''c''|| ''α'' = ''ζ'' = 90°&lt;br&gt;''β'' = ''ε'' ≠ 90°&lt;br&gt;''γ'' ≠ 90°&lt;br&gt;''δ'' = 180° − ''γ''
|-
|9|| Ditrigonal (dihexagonal) diclinic|| ''a'' = ''d'' ≠ ''b'' = ''c''|| ''α'' = ''ζ'' = 120°&lt;br&gt;''β'' = ''ε'' ≠ 90°&lt;br&gt;''γ'' ≠ ''δ'' ≠ 90°&lt;br&gt;cos ''δ'' = cos ''β'' − cos ''γ''
|-
|10|| Tetragonal orthogonal|| ''a'' ≠ ''b'' = ''c'' ≠ ''d''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ'' = 90°
|-
|11|| Hexagonal orthogonal|| ''a'' ≠ ''b'' = ''c'' ≠ ''d''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = 90°, ''ζ'' = 120°
|-
|12|| Ditetragonal monoclinic|| ''a'' = ''d'' ≠ ''b'' = ''c''|| ''α'' = ''γ'' = ''δ'' = ''ζ'' = 90°&lt;br&gt;''β'' = ''ε'' ≠ 90°
|-
|13|| Ditrigonal (dihexagonal) monoclinic|| ''a'' = ''d'' ≠ ''b'' = ''c''|| ''α'' = ''ζ'' = 120°&lt;br&gt;''β'' = ''ε'' ≠ 90°&lt;br&gt;''γ'' = ''δ'' ≠ 90°&lt;br&gt;cos ''γ'' = −{{sfrac|1|2}}cos ''β''
|-
|14|| Ditetragonal orthogonal|| ''a'' = ''d'' ≠ ''b'' = ''c''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ'' = 90°
|-
|15|| Hexagonal tetragonal|| ''a'' = ''d'' ≠ ''b'' = ''c''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = 90°&lt;br&gt;''ζ'' = 120°
|-
|16|| Dihexagonal orthogonal|| ''a'' = ''d'' ≠ ''b'' = ''c''|| ''α'' = ''ζ'' = 120°&lt;br&gt;''β'' = ''γ'' = ''δ'' = ''ε'' = 90°
|-
|17|| Cubic orthogonal|| ''a'' = ''b'' = ''c'' ≠ ''d''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ'' = 90°
|-
|18|| Octagonal|| ''a'' = ''b'' = ''c'' = ''d''|| ''α'' = ''γ'' = ''ζ'' ≠ 90°&lt;br&gt;''β'' = ''ε'' = 90°&lt;br&gt;''δ'' = 180° − ''α''
|-
|19|| Decagonal|| ''a'' = ''b'' = ''c'' = ''d''|| ''α'' = ''γ'' = ''ζ'' ≠ ''β'' = ''δ'' = ''ε''&lt;br&gt;cos ''β'' = −{{sfrac|1|2}} − cos ''α''
|-
|20|| Dodecagonal|| ''a'' = ''b'' = ''c'' = ''d''|| ''α'' = ''ζ'' = 90°&lt;br&gt;''β'' = ''ε'' = 120°&lt;br&gt;''γ'' = ''δ'' ≠ 90°
|-
|21|| Diisohexagonal orthogonal|| ''a'' = ''b'' = ''c'' = ''d''|| ''α'' = ''ζ'' = 120°&lt;br&gt;''β'' = ''γ'' = ''δ'' = ''ε'' = 90°
|-
|22|| Icosagonal (icosahedral)|| ''a'' = ''b'' = ''c'' = ''d''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ''&lt;br&gt;cos ''α'' = −{{sfrac|1|4}}
|-
|23|| Hypercubic|| ''a'' = ''b'' = ''c'' = ''d''|| ''α'' = ''β'' = ''γ'' = ''δ'' = ''ε'' = ''ζ'' = 90°
|}
The names here are given according to Whittaker.&lt;ref name="Whittaker"&gt;{{cite book|first=E. J. W.|last=Whittaker|title=An Atlas of Hyperstereograms of the Four-Dimensional Crystal Classes|publisher=Clarendon Press|location=Oxford &amp; New York|date=1985}}&lt;/ref&gt; They are almost the same as in Brown ''et al'',&lt;ref name="Brown"&gt;{{cite book|first1=H.|last1=Brown|first2=R.|last2=Bülow|first3=J.|last3=Neubüser|first4=H.|last4=Wondratschek|first5=H.|last5=Zassenhaus|title=Crystallographic Groups of Four-Dimensional Space|publisher=Wiley|location=New York|date=1978}}&lt;/ref&gt; with exception for names of the crystal families 9, 13, and 22. The names for these three families according to Brown ''et al'' are given in parenthesis.

The relation between four-dimensional crystal families, crystal systems, and lattice systems is shown in the following table.&lt;ref name="Whittaker"/&gt;&lt;ref name="Brown"/&gt; Enantiomorphic systems are marked with an asterisk. The number of enantiomorphic pairs are given in parentheses. Here the term "enantiomorphic" has a different meaning than in the table for three-dimensional crystal classes. The latter means, that enantiomorphic point groups describe chiral (enantiomorphic) structures. In the current table, "enantiomorphic" means that a group  itself (considered as a geometric object) is enantiomorphic, like enantiomorphic pairs of three-dimensional space groups P3&lt;sub&gt;1&lt;/sub&gt; and P3&lt;sub&gt;2&lt;/sub&gt;, P4&lt;sub&gt;1&lt;/sub&gt;22 and P4&lt;sub&gt;3&lt;/sub&gt;22. Starting from four-dimensional space, point groups also can be enantiomorphic in this sense.
{|class="wikitable" cellpadding=4 cellspacing=0 style="text-align:center"
|+Crystal systems in 4D space
!No. of &lt;br /&gt;crystal family
!Crystal family
!Crystal system
!No. of &lt;br&gt;crystal system
!Point groups
!width=120|Space groups
!Bravais lattices
!Lattice system
|-
| I ||colspan=2| Hexaclinic|| 1
|2
|2
|1
|Hexaclinic P
|-
| II || colspan=2| Triclinic|| 2
|3
|13
|2
|Triclinic P, S
|-
| III ||colspan=2| Diclinic|| 3
|2
|12
|3
|Diclinic P, S, D
|-
|IV || colspan=2| Monoclinic|| 4
|4
|207
|6
|Monoclinic P, S, S, I, D, F
|-
|rowspan=3| V ||rowspan=3| Orthogonal
|rowspan=2|Non-axial orthogonal|| rowspan=2| 5
|rowspan=2|2
|2
|1
|Orthogonal KU
|-
|112
|rowspan=2|8
|rowspan=2|Orthogonal P, S, I, Z, D, F, G, U
|-
|Axial orthogonal|| 6
|3
|887
|-
| VI || colspan=2| Tetragonal monoclinic || 7
|7
|88
|2
|Tetragonal monoclinic P, I
|-
|rowspan=3| VII ||rowspan=3| Hexagonal monoclinic
|rowspan=2|Trigonal monoclinic ||rowspan=2| 8
|rowspan=2|5
|9
|1
|Hexagonal monoclinic R
|-
|15
|rowspan=2|1
|rowspan=2|Hexagonal monoclinic P
|-
|Hexagonal monoclinic || 9
|7
|25
|-
| VIII || colspan=2| Ditetragonal diclinic* ||10
|1 (+1)
|1 (+1)
|1 (+1)
|Ditetragonal diclinic P*
|-
|IX || colspan=2| Ditrigonal diclinic* ||11
|2 (+2)
|2 (+2)
|1 (+1)
|Ditrigonal diclinic P*
|-
|rowspan=3| X ||rowspan=3| Tetragonal orthogonal
|rowspan=2|Inverse tetragonal orthogonal ||rowspan=2| 12
|rowspan=2|5
|7
|1
|Tetragonal orthogonal KG
|-
|351
|rowspan=2|5
|rowspan=2|Tetragonal orthogonal P, S, I, Z, G
|-
|Proper tetragonal orthogonal || 13
|10
|1312
|-
|rowspan=3|XI ||rowspan=3| Hexagonal orthogonal
|rowspan=2|Trigonal orthogonal ||rowspan=2| 14
|rowspan=2|10
|81
|2
|Hexagonal orthogonal R, RS
|-
|150
|rowspan=2|2
|rowspan=2|Hexagonal orthogonal P, S
|-
|Hexagonal orthogonal || 15
|12
|240
|-
| XII || colspan=2| Ditetragonal monoclinic* || 16
|1 (+1)
|6 (+6)
|3 (+3)
|Ditetragonal monoclinic P*, S*, D*
|-
| XIII || colspan=2| Ditrigonal monoclinic* || 17
|2 (+2)
|5 (+5)
|2 (+2)
|Ditrigonal monoclinic P*, RR*
|-
|rowspan=3| XIV ||rowspan=3| Ditetragonal orthogonal
|rowspan=2|Crypto-ditetragonal orthogonal ||rowspan=2| 18
|rowspan=2|5
|10
|1
|Ditetragonal orthogonal D
|-
|165 (+2)
|rowspan=2|2
|rowspan=2|Ditetragonal orthogonal P, Z
|-
|Ditetragonal orthogonal ||19
|6
|127
|-
|XV ||colspan=2| Hexagonal tetragonal || 20
|22
|108
|1
|Hexagonal tetragonal P
|-
|rowspan=5| XVI || rowspan=5| Dihexagonal orthogonal
|rowspan=2| Crypto-ditrigonal orthogonal* || rowspan=2|21
|rowspan=2|4 (+4)
|5 (+5)
|1 (+1)
|Dihexagonal orthogonal G*
|-
|5 (+5)
|rowspan=3|1
|rowspan=3|Dihexagonal orthogonal P
|-
|Dihexagonal orthogonal || 23
|11
|20
|-
|rowspan=2| Ditrigonal orthogonal || rowspan=2| 22
|rowspan=2| 11
|41
|-
|16
|1
|Dihexagonal orthogonal RR
|-
|rowspan=3| XVII ||rowspan=3| Cubic orthogonal
|rowspan=2|Simple cubic orthogonal ||rowspan=2| 24
|rowspan=2|5
|9
|1
|Cubic orthogonal KU
|-
|96
|rowspan=2|5
|rowspan=2|Cubic orthogonal P, I, Z, F, U
|-
|Complex cubic orthogonal || 25
|11
|366
|-
| XVIII ||colspan=2| Octagonal* || 26
|2 (+2)
|3 (+3)
|1 (+1)
| Octagonal P*
|-
| XIX ||colspan=2| Decagonal || 27
|4
|5
|1
| Decagonal P
|-
| XX ||colspan=2| Dodecagonal* ||28
|2 (+2)
|2 (+2)
|1 (+1)
| Dodecagonal P*
|-
|rowspan=3| XXI ||rowspan=3| Diisohexagonal orthogonal
|rowspan=2| Simple diisohexagonal orthogonal || rowspan=2| 29
|rowspan=2|9 (+2)
|19 (+5)
|1
|Diisohexagonal orthogonal RR
|-
|19 (+3)
|rowspan=2|1
|rowspan=2|Diisohexagonal orthogonal P
|-
|Complex diisohexagonal orthogonal ||30
|13 (+8)
|15 (+9)
|-
|XXII ||colspan=2| Icosagonal|| 31
|7
|20
|2
| Icosagonal P, SN
|-
|rowspan=3| XXIII ||rowspan=3| Hypercubic
|rowspan=2| Octagonal hypercubic||rowspan=2|32
|rowspan=2|21 (+8)
|73 (+15)
|1
|Hypercubic P
|-
|107 (+28)
|rowspan=2|1
|rowspan=2|Hypercubic Z
|-
|Dodecagonal hypercubic|| 33
|16 (+12)
|25 (+20)
|- bgcolor=#e0e0e0
|'''Total'''
|23 (+6)
|33 (+7)
|
|227 (+44)
|4783 (+111)
|64 (+10)
|33 (+7)
|}

==See also==
*{{annotated link|Crystal cluster}}
*{{annotated link|Crystal structure}}
*{{annotated link|List of space groups}}
*{{annotated link|Polar point group}}

==References==
{{Lacking ISBN|date=August 2017}}
{{reflist}}
*{{cite book |editor1-last=Hahn |editor1-first=Theo |title=International Tables for Crystallography, Volume A: Space Group Symmetry |url=http://it.iucr.org/A/ |publisher=[[Springer-Verlag]] |location=Berlin, New York |edition=5th |isbn=978-0-7923-6590-7 |doi=10.1107/97809553602060000100 |year=2002 |volume=A|series=International Tables for Crystallography }}

==External links==
*[http://newton.ex.ac.uk/research/qsystems/people/goss/symmetry/Solids.html Overview of the 32 groups]
*[https://web.archive.org/web/20050624024940/http://mineral.galleries.com/minerals/symmetry/symmetry.htm Mineral galleries – Symmetry]
*[http://www.ifg.uni-kiel.de/kubische_Formen all cubic crystal classes, forms, and stereographic projections (interactive java applet)]
*[http://reference.iucr.org/dictionary/Crystal_system Crystal system] at the [http://reference.iucr.org/dictionary/Main_Page Online Dictionary of Crystallography]
*[http://reference.iucr.org/dictionary/Crystal_family Crystal family] at the [http://reference.iucr.org/dictionary/Main_Page Online Dictionary of Crystallography]
*[http://reference.iucr.org/dictionary/Lattice_system Lattice system] at the [http://reference.iucr.org/dictionary/Main_Page Online Dictionary of Crystallography]
*[http://materials.duke.edu/awrapper.html Conversion Primitive to Standard Conventional for VASP input files]
*[http://www.xtal.iqfr.csic.es/Cristalografia/index-en.html Learning Crystallography]

{{Crystal systems}}
{{Mineral identification}}

[[Category:Symmetry]]
[[Category:Euclidean geometry]]
[[Category:Crystallography]]
[[Category:Morphology]]
[[Category:Mineralogy]]
[[Category:Crystal systems]]</text>
      <sha1>rk3mpf99jkuou6si68iz4ujog94msl4</sha1>
    </revision>
  </page>
  <page>
    <title>Feld-Tai lemma</title>
    <ns>0</ns>
    <id>3465544</id>
    <redirect title="Reciprocity (electromagnetism)" />
    <revision>
      <id>103433618</id>
      <parentid>32151197</parentid>
      <timestamp>2007-01-26T18:57:06Z</timestamp>
      <contributor>
        <username>David Haslam</username>
        <id>162756</id>
      </contributor>
      <minor/>
      <comment>[[Category:Lemmas]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="65">#REDIRECT [[Reciprocity (electromagnetism)]]

[[Category:Lemmas]]</text>
      <sha1>4syjlp6tcr55ro6w1fvvwnm4ebhh9nf</sha1>
    </revision>
  </page>
  <page>
    <title>Free-form deformation</title>
    <ns>0</ns>
    <id>36017481</id>
    <revision>
      <id>820574259</id>
      <parentid>765889635</parentid>
      <timestamp>2018-01-15T12:06:29Z</timestamp>
      <contributor>
        <username>Tino</username>
        <id>7872133</id>
      </contributor>
      <comment>It falls in the previous point, it is just one particular case among many applications of FFD registration in medical image analysis.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2298">In [[computer graphics]], '''free-form deformation (FFD)''' is a geometric technique used to model simple [[deformation (engineering)|deformation]]s of rigid objects. It is based on the idea of enclosing an object within a [[cube]] or another hull object, and transforming the object within the hull as the hull is deformed. Deformation of the hull is based on the concept of so-called ''hyper-patches'', which are three-dimensional analogs of [[parametric curve]]s such as [[Bézier curve]]s, [[B-spline]]s, or [[NURB]]s. The technique was first described by Thomas W. Sederberg and Scott R. Parry in 1986,&lt;ref&gt;{{cite journal|author1=Sederberg, Thomas W.|author2=Parry, Scott R.|title=Free-form deformation of solid geometric models|journal=SIGGRAPH Computer Graphics|volume=20|issue=4|pages=151–160|publisher=ACM|year=1986|doi=10.1145/15886.15903}}&lt;/ref&gt; and is based on an earlier technique by Alan Barr.&lt;ref&gt;{{cite journal|author=Barr, A. H.|title=Global and local deformations of solid primitives|journal=SIGGRAPH Computer Graphics|volume=18|issue=3|date=July 1984|pages=21–30|doi=10.1145/800031.808573}}&lt;/ref&gt;  It was extended by Coquillart to a technique described as ''extended free-form deformation'', which refines the hull object by introducing additional geometry or by using different hull objects such as cylinders and prisms.&lt;ref&gt;{{cite journal|author=Coquillart, S.|title=Extended free-form deformation: a sculpturing tool for 3D geometric modeling|journal=SIGGRAPH Computer Graphics|volume=24|issue=4|date=September 1990|pages=187–196|publisher=ACM|doi=10.1145/97880.97900}}&lt;/ref&gt;


== Applications ==
* Free-Form Deformation is used in [[computer graphics]] for solid geometric models. For example, the Lattice Modifier in [[Blender (software)]].
* It is used in the [[image registration]] in both rigid and non-rigid [[geometric transformation|transformation]].&lt;ref&gt;[http://www.na-mic.org/publications/item/view/903 Nonrigid Registration Using Free-Form Deformations: Application to Breast MR Images]&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* [http://web.cs.wpi.edu/~matt/courses/cs563/talks/smartin/ffdeform.html 3D Free-form Deformation]

[[Category:Geometry in computer vision]]
[[Category:Graphic design]]
[[Category:Curves]]


{{Compu-graphics-stub}}</text>
      <sha1>hh872hnz9a3jq755tzl9s2fyj4si17k</sha1>
    </revision>
  </page>
  <page>
    <title>Froda's theorem</title>
    <ns>0</ns>
    <id>22278053</id>
    <revision>
      <id>831332384</id>
      <parentid>790708602</parentid>
      <timestamp>2018-03-20T01:28:34Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>copy-edit, wikify</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6647">{{Use dmy dates|date=July 2013}}
In [[mathematics]], '''Darboux–Froda's theorem''', named after [[Alexandru Froda]], a Romanian mathematician, describes the set of [[Discontinuity (mathematics)|discontinuities]] of a [[Monotonic function#Monotonicity in calculus and analysis|monotone]] [[real-valued function]] of a real variable. Usually, this theorem appears in literature without a name. It was written in  A. Froda' thesis in 1929.&lt;ref&gt;Alexandre Froda, [http://archive.numdam.org/ARCHIVE/THESE/THESE_1929__102_/THESE_1929__102__1_0/THESE_1929__102__1_0.pdf Sur la Distribution des Propriétés de Voisinage des Fonctions de Variables Réelles], Thèse, [[Éditions Hermann]], Paris, 3 December 1929&lt;/ref&gt;&lt;ref&gt;''Alexandru Froda – Collected Papers (Opera Matematica), Vol.1'', Editor Academiei Române, 2000&lt;/ref&gt;{{Dubious|Is this really Froda's Theorem?|date=September 2012}}. As it is acknowledged in the thesis, the theorem is in fact due to [[Jean Gaston Darboux]].&lt;ref&gt; [[Jean Gaston Darboux]], [http://archive.numdam.org/ARCHIVE/ASENS/ASENS_1875_2_4_/ASENS_1875_2_4__57_0/ASENS_1875_2_4__57_0.pdf Mémoire sur les fonctions discontinues], [[Annales Scientifiques de l'École Normale Supérieure]], 2-ème série, t. IV, 1875, Chap VI.&lt;/ref&gt;

==Definitions==
#Consider a function {{math|''f''}} of real variable {{math|''x''}} with real values defined in a neighborhood of a point &lt;math&gt;x_0&lt;/math&gt; and the function {{math|''f''}} is discontinuous at the point on the real axis &lt;math&gt;x = x_0&lt;/math&gt;. We will call a '''[[Classification_of_discontinuities#Classification_of_discontinuities|removable discontinuity]]''' or a '''[[Classification_of_discontinuities#Classification_of_discontinuities|jump discontinuity]]''' a '''discontinuity of the first kind'''.&lt;ref&gt;[[Walter Rudin]], ''Principles of Mathematical Analysis'', McGraw-Hill 1964, (Def. 4.26, pp. 81–82)&lt;/ref&gt;
#Denote &lt;math&gt;f(x+0):=\lim_{h\searrow0}f(x+h)&lt;/math&gt; and &lt;math&gt;f(x-0):=\lim_{h\searrow0}f(x-h)&lt;/math&gt;. Then if &lt;math&gt;f(x_0+0)&lt;/math&gt; and &lt;math&gt;f(x_0-0)&lt;/math&gt; are finite we will call the difference &lt;math&gt;f(x_0+0)-f(x_0-0)&lt;/math&gt; the ''' jump'''&lt;ref&gt;[[Miron Nicolescu|M. Nicolescu]], N. Dinculeanu, [[Solomon Marcus|S. Marcus]], ''Mathematical Analysis'' (Bucharest 1971), Vol.1, Pg.213, [in Romanian]&lt;/ref&gt; of f at &lt;math&gt;x_0&lt;/math&gt;.

If the function is continuous at &lt;math&gt;x_0&lt;/math&gt; then the jump at &lt;math&gt;x_0&lt;/math&gt; is zero. Moreover, if &lt;math&gt;f&lt;/math&gt; is not continuous at &lt;math&gt;x_0&lt;/math&gt;, the jump can be zero at &lt;math&gt;x_0&lt;/math&gt; if &lt;math&gt;f(x_0+0)=f(x_0-0)\neq f(x_0)&lt;/math&gt;.

==Precise statement==

Let ''f'' be a real-valued [[Monotonic_function#Monotonicity_in_calculus_and_analysis|monotone]] function defined on an [[Interval_(mathematics)#Notations_for_intervals|interval]] ''I''. Then the set of discontinuities of the first kind is [[Countable|at most countable]].

One can prove&lt;ref&gt;W. Rudin, ''Principles of Mathematical Analysis'', McGraw–Hill 1964 (Corollary, p.83)&lt;/ref&gt;&lt;ref&gt;[[Miron Nicolescu|M. Nicolescu]], N. Dinculeanu, [[Solomon Marcus|S. Marcus]], ''Mathematical Analysis'' (Bucharest 1971), Vol.1, Pg.213, [in Romanian]&lt;/ref&gt; that all points of discontinuity of a monotone real-valued function defined on an interval are jump discontinuities and hence, by our definition, of the first kind. With this remark Froda's theorem takes the stronger form:

Let ''f'' be a monotone function defined on an [[Interval_(mathematics)#Notations_for_intervals|interval]] &lt;math&gt;I&lt;/math&gt;. Then the set of discontinuities is [[Countable|at most countable]].

==Proof==
Let &lt;math&gt;I:=[a,b]&lt;/math&gt; be an interval and &lt;math&gt;f&lt;/math&gt; defined on &lt;math&gt;I&lt;/math&gt; an [[Monotonic function|increasing]] function. We have

:&lt;math&gt;f(a)\leq f(a+0)\leq f(x-0)\leq f(x+0)\leq f(b-0)\leq f(b)&lt;/math&gt;

for any &lt;math&gt;a&lt;x&lt;b&lt;/math&gt;. Let &lt;math&gt;\alpha &gt;0&lt;/math&gt; and let &lt;math&gt;x_1&lt;x_2&lt;\cdots&lt;x_n&lt;/math&gt; be &lt;math&gt;n&lt;/math&gt; points inside &lt;math&gt;I&lt;/math&gt; at which the jump of &lt;math&gt;f&lt;/math&gt; is greater or equal to &lt;math&gt;\alpha&lt;/math&gt;:

:&lt;math&gt;f(x_i+0)-f(x_i-0)\geq \alpha,\ i=1,2,\ldots,n&lt;/math&gt;

We have &lt;math&gt;f(x_i+0)\leq f(x_{i+1}-0)&lt;/math&gt; or &lt;math&gt;f(x_{i+1}-0)-f(x_i+0)\geq 0,\ i=1,2,\ldots,n&lt;/math&gt;.
Then
:&lt;math&gt;f(b)-f(a)\geq f(x_n+0)-f(x_1-0)=\sum_{i=1}^n [f(x_i+0)-f(x_i-0)]+&lt;/math&gt;

:&lt;math&gt;+\sum_{i=1}^{n-1}[f(x_{i+1}-0)-f(x_i+0)]\geq \sum_{i=1}^n[f(x_i+0)-f(x_i-0)]\geq n\alpha&lt;/math&gt;

and hence: &lt;math&gt;n\leq \frac{f(b)-f(a)}{\alpha}&lt;/math&gt;.

Since &lt;math&gt;f(b)-f(a) &lt;\infty&lt;/math&gt; we have that the number of points at which the jump is greater than &lt;math&gt;\alpha&lt;/math&gt; is finite or zero.

We define the following sets:

:&lt;math&gt;S_1:=\{x:x\in I, f(x+0)-f(x-0)\geq 1\}&lt;/math&gt;,

:&lt;math&gt;S_n:=\{x:x\in I, \frac{1}{n}\leq f(x+0)-f(x-0)&lt;\frac{1}{n-1}\},\ n\geq 2.&lt;/math&gt;

We have that each set &lt;math&gt;S_n&lt;/math&gt; is finite or the [[empty set]]. The union
&lt;math&gt;S=\cup_{n=1}^\infty S_n&lt;/math&gt; contains all points at which the jump is positive and hence contains all points of discontinuity. Since every &lt;math&gt;S_i,\ i=1,2,\ldots&lt;/math&gt; is at most countable, we have that &lt;math&gt;S&lt;/math&gt; is at most countable.

If &lt;math&gt;f&lt;/math&gt; is [[Monotonic function|decreasing]] the proof is similar.

If the interval &lt;math&gt;I&lt;/math&gt; is not [[Closed set|closed]] and [[Bounded set|bounded]] (and hence by [[Heine–Borel theorem]] not [[Compact set|compact]]) then the interval can be written as a countable union of closed and bounded intervals &lt;math&gt;I_n&lt;/math&gt; with the property that any two consecutive intervals have an [[Interval_(mathematics)#Notations_for_intervals|endpoint]] in common: &lt;math&gt;I=\cup_{n=1}^\infty I_n.&lt;/math&gt;

If &lt;math&gt;I=(a,b],\ a\geq -\infty &lt;/math&gt; then &lt;math&gt;I_1=[\alpha_1,b],\ I_2=[\alpha_2,\alpha_1],\ldots,\ I_n=[\alpha_n,\alpha_{n-1}],\ldots &lt;/math&gt; where &lt;math&gt;\{\alpha_n\}_n&lt;/math&gt; is a strictly decreasing [[sequence]] such that &lt;math&gt;\alpha_n\rightarrow a.&lt;/math&gt; In a similar way if &lt;math&gt;I=[a,b),\ b\leq+\infty&lt;/math&gt; or if &lt;math&gt;I=(a,b)\ -\infty\leq a&lt;b\leq \infty&lt;/math&gt;.

In any interval &lt;math&gt;I_n&lt;/math&gt; we have at most countable many points of discontinuity, and since a countable union of at most countable sets is at most countable, it follows that the set of all discontinuities is at most countable.

==See also==
*[[Continuous function]]
*[[Classification of discontinuities]]

==Notes==
&lt;references/&gt;

==References==
*Bernard R. Gelbaum, John M. H. Olmsted, ''Counterexamples in Analysis'', Holden–Day, Inc., 1964. (18. Page 28)
*John M. H. Olmsted, ''Real Variables'', Appleton–Century–Crofts, Inc., New York (1956), (Page 59, Ex. 29).

{{DEFAULTSORT:Froda's Theorem}}
[[Category:Articles containing proofs]]
[[Category:Theorems in real analysis]]</text>
      <sha1>0mx31mql7c535a3qh0iguxq6dg8sonr</sha1>
    </revision>
  </page>
  <page>
    <title>Gábor Korchmáros</title>
    <ns>0</ns>
    <id>46826337</id>
    <revision>
      <id>867801915</id>
      <parentid>867801813</parentid>
      <timestamp>2018-11-08T02:54:57Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Removing from [[Category:Hungarian mathematicians]] parent category using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3208">'''Gábor Korchmáros'''&lt;ref&gt;G. Korchmáros has also published under the name "Gabriele Korchmáros".&lt;/ref&gt; (born 1948) is a Hungarian mathematician, who works on [[finite geometry]].

==Biography==
Korchmáros received in 1972 from the [[University of Budapest]] a Ph.D. in mathematics. In 1973 on a postdoc grant, he studied at the Research Center of the [[Accademia dei Lincei]] in Rome. In 1976 he was awarded the Grunwald Prize of the [[János Bolyai Mathematical Society]]. In 1980 he received the [[Candidate of Sciences]] degree and in 2000 the [[Doctor of Sciences]] degree from the János Bolyai Mathematical Society. In 1987 he became a professor at the Università della Basilicata.&lt;ref&gt;[http://www.gaborkorchmaros.com/index.php?option=com_content&amp;view=article&amp;id=55:curriculum-vitae&amp;catid=29:categoria-generale&amp;Itemid=34 C.V. – Gábor Korchmáros]&lt;/ref&gt; He was a visiting professor at several universities, including the [[University of Sussex]], the [[University of Delaware]] and the [[University of Szeged (Hungary)]].

His research involves the theory of [[oval]]s and their higher-dimensional generalizations over [[finite field]]s. One topic of his research is the [[collineation group]]s of ovals and embedding problems for arcs in ovals; these investigations have applications in [[coding theory]] and are related to the [[Hasse's theorem on elliptic curves#Hasse-Weil Bound|Hasse-Weil bound]] for elliptic curves. He also works on [[algebraic curve]]s over finite fields and their automorphism groups, [[translation plane]]s, finite [[Möbius plane]]s, finite [[Minkowski plane]]s, and [[elliptic curve cryptography]]. In the late 1970s he worked with [[Beniamino Segre]].&lt;ref&gt;{{cite journal|author=Korchmaros, G.|author2=Segre, B.|title=Una proprietà degli insiemi di punti di un piano di Galois caratterizzante quelli formati dai punti delle singole rette esterne ad una conica|journal=Atti Accad. Naz. Lincei Rend. Cl. Sci. Fis. Mat. Natur.|year=1977|pages=613–619}}&lt;/ref&gt;

He was awarded the [[Euler Medal]] of ICA in 2008, and in 2014 the [[Doctor Honoris Casusa degree]] at the University of Szeged.

==Selected works==
* 1979: ''Questioni relative ad ovali astratte''
* 1998: (as editor with E. Ballico) ''Recent Progress in Geometry'', [[Circolo Matematico di Palermo]]
* 2008: (with [[J. W. P. Hirschfeld]] &amp; F. Torres), ''Algebraic Curves over a Finite Field'', [[Princeton University Press]], [https://books.google.com/books/about/Algebraic_Curves_Over_a_Finite_Field.html?id=_HJX2SLN-dYC Google books link]
* 2010: (with M. Giulietti) {{cite journal|title=Algebraic curves with a large non-tame automorphism group fixing no point|journal=[[Transactions of the American Mathematical Society]]|volume=362|pages=5983–6001|mr=2661505|doi=10.1090/s0002-9947-2010-05025-1}}

==References==
{{reflist}}

==External links==
* {{Official website}}
* {{zbMATH|name=Korchmáros, Gábor}}

{{Authority control}}

{{DEFAULTSORT:Korchmaros, Gabor}}
[[Category:1948 births]]
[[Category:20th-century Hungarian mathematicians]]
[[Category:21st-century Hungarian mathematicians]]
[[Category:Eötvös Loránd University alumni]]
[[Category:Combinatorialists]]
[[Category:Living people]]</text>
      <sha1>2s1svop8k8fcprlws2jay99btl9x54y</sha1>
    </revision>
  </page>
  <page>
    <title>Hasse–Weil zeta function</title>
    <ns>0</ns>
    <id>1157842</id>
    <revision>
      <id>862709306</id>
      <parentid>857631112</parentid>
      <timestamp>2018-10-06T05:20:04Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6471">In [[mathematics]], the '''Hasse–Weil zeta function''' attached to an [[algebraic variety]] ''V'' defined over an [[algebraic number field]] ''K'' is one of the two most important types of [[L-function]]. Such ''L''-functions are called 'global', in that they are defined as [[Euler product]]s in terms of [[local zeta-function|local zeta functions]]. They form one of the two major classes of global ''L''-functions, the other being the ''L''-functions associated to [[automorphic representations]]. Conjecturally there is just one essential type of global ''L''-function, with two descriptions (coming from an algebraic variety, coming from an automorphic representation); this would be a vast generalisation of the [[Taniyama–Shimura conjecture]], itself a very deep and recent result ({{As of|2009|lc=on}}) in [[number theory]].

The description of the Hasse–Weil zeta function ''up to finitely many factors of its Euler product'' is relatively simple. This follows the initial suggestions of [[Helmut Hasse]] and [[André Weil]], motivated by the case in which ''V'' is a single point, and the [[Riemann zeta function]] results.

Taking the case of ''K'' the [[rational number]] field '''Q''', and ''V'' a [[non-singular]] [[projective variety]], we can for [[almost all]] [[prime number]]s ''p'' consider the reduction of ''V'' modulo ''p'', an algebraic variety ''V''&lt;sub&gt;''p''&lt;/sub&gt; over the [[finite field]] '''F'''&lt;sub&gt;''p''&lt;/sub&gt; with ''p'' elements, just by reducing equations for ''V''. Again for almost all ''p'' it will be non-singular. We define

:&lt;math&gt;Z_{V,Q}(s)&lt;/math&gt;

to be the [[Dirichlet series]] of the [[complex variable]] ''s'', which is the [[infinite product]] of the [[local zeta-function|local zeta functions]]

:&lt;math&gt;\zeta_{V,p}\left(p^{-s}\right).&lt;/math&gt;

Then ''Z''(''s''), according to our definition, is [[well-defined]] only up to multiplication by [[rational function]]s in a finite number of &lt;math&gt;p^{-s}&lt;/math&gt;. 

Since the indeterminacy is relatively harmless, and has [[meromorphic continuation]] everywhere, there is a sense in which the properties of ''Z(s)'' do not essentially depend on it. In particular, while the exact form of the [[functional equation (L-function)|functional equation]] for ''Z''(''s''), reflecting in a vertical line in the complex plane, will definitely depend on the 'missing' factors, the existence of some such functional equation does not.

A more refined definition became possible with the development of [[étale cohomology]]; this neatly explains what to do about the missing, 'bad reduction' factors. According to general principles visible in [[Ramification (mathematics)|ramification theory]], 'bad' primes carry good information (theory of the ''conductor''). This manifests itself in the étale theory in the [[Ogg–Néron–Shafarevich criterion]] for [[good reduction]]; namely that there is good reduction, in a definite sense, at all primes ''p'' for which the [[Galois representation]] ρ on the étale cohomology groups of ''V'' is ''unramified''. For those, the definition of local zeta function can be recovered in terms of the [[characteristic polynomial]] of 

:&lt;math&gt;\rho(\operatorname{Frob}(p)),&lt;/math&gt;

Frob(''p'') being a [[Frobenius element]] for ''p''. What happens at the ramified ''p'' is that ρ is non-trivial on the [[inertia group]] ''I''(''p'') for ''p''. At those primes the definition must be 'corrected', taking the largest quotient of the representation ρ on which the inertia group acts by the [[trivial representation]]. With this refinement, the definition of ''Z''(''s'') can be upgraded successfully from 'almost all' ''p'' to ''all'' ''p'' participating in the Euler product. The consequences for the functional equation were worked out by [[Jean-Pierre Serre|Serre]] and [[Deligne]] in the later 1960s; the functional equation itself has not been proved in general.

==Example: elliptic curve over Q==
Let ''E'' be an [[Elliptic curve#Elliptic curves over a general field|elliptic curve over '''Q''']] of [[Conductor of an abelian variety|conductor]] ''N''. Then, ''E'' has good reduction at all primes ''p'' not dividing ''N'', it has [[Semistable elliptic curve|multiplicative reduction]] at the primes ''p'' that ''exactly'' divide ''N'' (i.e. such that ''p'' divides ''N'', but ''p''&lt;sup&gt;2&lt;/sup&gt; does not; this is written ''p'' || ''N''), and it has [[additive reduction]] elsewhere (i.e. at the primes where ''p''&lt;sup&gt;2&lt;/sup&gt; divides ''N''). The Hasse–Weil zeta function of ''E'' then takes the form

:&lt;math&gt;Z_{E,\mathbf Q}(s)= \frac{\zeta(s)\zeta(s-1)}{L(s,E)}. \,&lt;/math&gt;

Here, ζ(''s'') is the usual [[Riemann zeta function]] and ''L''(''s'',&amp;nbsp;''E'') is called the ''L''-function of ''E''/'''Q''', which takes the form&lt;ref&gt;Section C.16 of {{Citation
| last=Silverman
| first=Joseph H.
| author-link=Joseph H. Silverman
| title=The arithmetic of elliptic curves
| publisher=[[Springer-Verlag]]
| location=New York
| series=[[Graduate Texts in Mathematics]]
| isbn=978-0-387-96203-0
| mr=1329092
| year=1992
| volume=106
}}&lt;/ref&gt;

:&lt;math&gt;L(s,E)=\prod_pL_p(s,E)^{-1}\,&lt;/math&gt;

where, for a given prime ''p'',

:&lt;math&gt;L_p(s,E)=\begin{cases}
            (1-a_pp^{-s}+p^{1-2s}), &amp; \text{if } p\nmid N \\
            (1-a_pp^{-s}), &amp; \text{if }p\mid N \text{ and } p^2 \nmid N \\
            1, &amp; \text{if }p^2\mid N
       \end{cases}&lt;/math&gt;

where, in the case of good reduction ''a''&lt;sub&gt;''p''&lt;/sub&gt; is ''p''&amp;nbsp;+&amp;nbsp;1&amp;nbsp;&amp;minus;&amp;nbsp;(number of points of ''E''&amp;nbsp;mod&amp;nbsp;''p''), and in the case of multiplicative reduction ''a''&lt;sub&gt;''p''&lt;/sub&gt; is ±1 depending on whether ''E'' has split or non-split multiplicative reduction at&amp;nbsp;''p''.

==Hasse–Weil conjecture==

The Hasse–Weil conjecture states that the Hasse–Weil zeta function should extend to a meromorphic function for all complex ''s'', and should satisfy a functional equation similar to that of the [[Riemann zeta function]]. For elliptic curves over the rational numbers, the Hasse–Weil conjecture follows from the [[modularity theorem]].

==See also==

*[[Arithmetic zeta function]]

==References==
&lt;references/&gt;

==Bibliography==
*[[Jean-Pierre Serre|J.-P. Serre]], ''Facteurs locaux des fonctions zêta des variétés algébriques (définitions et conjectures)'', 1969/1970, Sém. Delange–Pisot–Poitou, exposé 19

{{L-functions-footer}}

{{DEFAULTSORT:Hasse-Weil zeta function}}
[[Category:Zeta and L-functions]]
[[Category:Algebraic geometry]]</text>
      <sha1>mkdcnpbtlhywi5ndz6ia017uts6k232</sha1>
    </revision>
  </page>
  <page>
    <title>Higgs sector</title>
    <ns>0</ns>
    <id>4044234</id>
    <revision>
      <id>830741584</id>
      <parentid>674896848</parentid>
      <timestamp>2018-03-16T17:27:14Z</timestamp>
      <contributor>
        <username>Comp.arch</username>
        <id>18779361</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="798">{{Refimprove|date=January 2015}}
In [[particle physics]], the '''Higgs sector''' is the collection of [[quantum field]]s and/or [[particle]]s that are responsible for the [[Higgs mechanism]], i.e. for the [[spontaneous symmetry breaking]] of the [[Higgs field]]. The word "sector" refers to a subgroup of the total set of fields and particles.&lt;ref name=GunionEtAl&gt;{{cite book
 | last1 = Gunion
 | first1 = John
 | last2 = Haber
 | first2 = Howard
 | last3 = Kane
 | first3 = Gordon
 | last4 = Dawson
 | first4 = Sally
 | title = The Higgs Hunter's Guide
 | publisher = Westview Press
 | edition = illustrated, reprint
 | year = 2000
 | isbn = 9780738203058
}}&lt;/ref&gt;

==See also==
* [[Higgs boson]]

==References==
{{reflist}}

[[Category:Particle physics]]
[[Category:Symmetry]]


{{Particle-stub}}</text>
      <sha1>gy4agpkmwwsganjja5qtbs25c145b0t</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert–Poincaré series</title>
    <ns>0</ns>
    <id>17006296</id>
    <revision>
      <id>863040612</id>
      <parentid>863039373</parentid>
      <timestamp>2018-10-08T09:56:39Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* Chain complex */ better categorization</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4919">{{see also|Hilbert series and Hilbert polynomial}}
{{unreferenced|date=January 2013}}
In [[mathematics]], and in particular in the field of [[algebra]], a '''Hilbert–Poincaré series''' (also known under the name '''[[Hilbert series]]'''), named after [[David Hilbert]] and [[Henri Poincaré]], is an adaptation of the notion of [[dimension]] to the context of [[graded algebra|graded]] algebraic structures (where the dimension of the entire structure is often infinite). It is a [[formal power series]] in one indeterminate, say ''t'', where the coefficient of ''t''&lt;sup&gt;''n''&lt;/sup&gt; gives the dimension (or rank) of the sub-structure of elements homogeneous of degree&amp;nbsp;''n''.  It is closely related to the [[Hilbert polynomial]] in cases when the latter exists; however, the Hilbert–Poincaré series describes the rank in every degree, while the Hilbert polynomial describes it only in all but finitely many degrees, and therefore provides less information. In particular the Hilbert–Poincaré series cannot be deduced from the Hilbert polynomial even if the latter exists. In good cases, the Hilbert–Poincaré series can be expressed as a [[rational function]] of its argument&amp;nbsp;''t''.

== Definition ==

Let ''K'' be a field, and let &lt;math&gt;V=\textstyle\bigoplus_{i\in\mathbf{N}}V_i&lt;/math&gt; be a '''N'''-[[graded vector space]] over ''K'', where each subspace ''V''&lt;sub&gt;''i''&lt;/sub&gt; of vectors of degree ''n'' is finite-dimensional. Then the Hilbert–Poincaré series of ''V'' is the [[formal power series]]
:&lt;math&gt;\sum_{i\in\mathbf{N}}\dim_K(V_i)t^i.&lt;/math&gt;
A similar definition can be given for an '''N'''-graded ''R''-module over any [[commutative ring]] ''R'' in which each submodule of elements homogeneous of a fixed degree ''n'' is [[Free module|free]] of finite rank; it suffices to replace the dimension by the rank. Often the graded vector space or module of which the Hilbert–Poincaré series is considered has additional structure, for instance that of a ring, but the Hilbert–Poincaré series is independent of the multiplicative or other structure.

Example: Since there are &lt;math&gt;\binom {n+k}{n}&lt;/math&gt; monomials of degree ''k'' in variables &lt;math&gt;X_0, \dots, X_n&lt;/math&gt; (by induction, say), it follows immediately that the Hilbert–Poincaré series of ''K''[''X''&lt;sub&gt;0&lt;/sub&gt;,''X''&lt;sub&gt;1&lt;/sub&gt;,…,''X''&lt;sub&gt;''n''&lt;/sub&gt;] is &lt;math&gt;(1-t)^{-n-1}&lt;/math&gt;

== Hilbert–Serre theorem ==
Suppose ''M'' is a finitely generated graded module over &lt;math&gt;A[x_1, \dots, x_n], \operatorname{deg}x_i = d_i&lt;/math&gt; with an [[Artinian ring]] (e.g., a field) ''A''. Then the Poincaré series of ''M'' is a polynomial with integral coefficients divided by &lt;math&gt;\prod (1-t^{d_i})&lt;/math&gt;. The standard proof today is an induction on ''n''. Hilbert's original proof made a use of [[Hilbert's syzygy theorem]] (a [[projective resolution]] of ''M''), which gives more homological information.&lt;!-- OR? and is essential in an extension to noncommutative rings.--&gt;

Here is a proof by induction on the number ''n'' of indeterminates. If &lt;math&gt;n = 0&lt;/math&gt;, then, since ''M'' has finite length, &lt;math&gt;M_k = 0&lt;/math&gt; if ''k'' is large enough. Next, suppose the theorem is true for &lt;math&gt;n - 1&lt;/math&gt; and consider the exact sequence of [[graded module]]s (exact degree-wise), with the notation &lt;math&gt;N(l)_k = N_{k+l}&lt;/math&gt;,
:&lt;math&gt;0 \to K(-d_n) \to M(-d_n) \overset{x_n} \to M \to C \to 0&lt;/math&gt;.
Since the length is additive, Poincaré series are also additive. Hence, we have:
:&lt;math&gt;P(M, t) = -P(K(-d_n), t) + P(M(-d_n), t) - P(C, t)&lt;/math&gt;.
We can write &lt;math&gt;P(M(-d_n), t) = t^{d_n} P(M, t)&lt;/math&gt;. Since ''K'' is killed by &lt;math&gt;x_n&lt;/math&gt;, we can regard it as a graded module over &lt;math&gt;A[x_0, \dots, x_{n-1}]&lt;/math&gt;; the same is true for ''C''. The theorem thus now follows from the inductive hypothesis.

== Chain complex ==

An example of graded vector space is associated to a [[chain complex]], or cochain complex ''C'' of vector spaces; the latter takes the form

:&lt;math&gt; 0\to C^0 \stackrel{d_0}{\longrightarrow} C^1\stackrel{d_1}{\longrightarrow} C^2 \stackrel{d_2}{\longrightarrow} \cdots \stackrel{d_{n-1}}{\longrightarrow} C^n \longrightarrow 0. &lt;/math&gt;

The Hilbert–Poincaré series (here often called the Poincaré polynomial) of the graded vector space &lt;math&gt;\bigoplus_iC^i&lt;/math&gt; for this complex is

:&lt;math&gt;P_C(t) = \sum_{j=0}^n \dim(C^j)t^j.&lt;/math&gt;

The Hilbert–Poincaré polynomial of the [[cohomology]], with cohomology spaces ''H''&lt;sup&gt;''j''&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''H''&lt;sup&gt;''j''&lt;/sup&gt;(''C''), is 

:&lt;math&gt;P_H(t) = \sum_{j=0}^n \dim(H^j)t^j.&lt;/math&gt;

A famous relation between the two is that there is a polynomial &lt;math&gt;Q(t)&lt;/math&gt; with non-negative coefficients, such that &lt;math&gt;P_C(t) - P_H(t) = (1+t)Q(t).&lt;/math&gt;

{{DEFAULTSORT:Hilbert-Poincare series}}
[[Category:Homological algebra]]
[[Category:Linear algebra]]
[[Category:Commutative algebra]]
[[Category:Mathematical series]]</text>
      <sha1>rfgrlvgi2rizf8cvs5h0qtrfo5wrpfr</sha1>
    </revision>
  </page>
  <page>
    <title>Idris Assani</title>
    <ns>0</ns>
    <id>44770467</id>
    <revision>
      <id>825347744</id>
      <parentid>808425183</parentid>
      <timestamp>2018-02-12T21:58:33Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>am math cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2782">'''Idris Assani''' is a [[Beninese people|Beninese]] and [[List of African-American mathematicians|African-American mathematician]], who works as a professor of mathematics at the [[University of North Carolina at Chapel Hill]].

Although born in [[Niger]], Assani is Beninese.&lt;ref name="mad"&gt;{{citation|url=http://www.math.buffalo.edu/mad/PEEPS/assani_idris.html|title=Idris Assani|website=Mathematicians of the African Disapora|first=Scott W.|last=Williams|accessdate=2014-12-18|publisher=State University of New York at Buffalo, Mathematics Department}}&lt;/ref&gt; He was educated in France, earning a bachelor's degree in commerce from [[Paris Dauphine University]] in 1981, a doctorate of the third cycle in mathematics from [[Pierre and Marie Curie University]] in 1981, and a doctor of science from Pierre and Marie Curie University in 1986, under the supervision of Antoine Brunel.&lt;ref name="mad"/&gt;&lt;ref&gt;{{mathgenealogy|id=89804}}&lt;/ref&gt; He joined the UNC mathematics department in 1988 but, allegedly for racist reasons, was turned down for tenure. He appealed through the courts, won his case and gained tenure in 1995, and was promoted to full professor one year later. In doing so he became the first African-American tenured associate professor and the first African-American full professor at UNC, as well as the only mathematician there to be promoted from associate to full so quickly.&lt;ref name="mad"/&gt;

Assani's research concerns [[ergodic theory]]. He is the author of the research monograph ''Wiener Wintner Ergodic Theorems'' (World Scientific, 2003),&lt;ref&gt;Review of ''Wiener Wintner Ergodic Theorems'' by U. Krengel (2004), {{mr|1995517}}.&lt;/ref&gt; about mathematics related to the [[Wiener–Wintner theorem]], and is also the editor of several volumes of collected papers.

In 2012, Assani was named as one of the inaugural [[fellow]]s of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2014-12-18.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://www.unc.edu/math/Faculty/assani/ Home page]
*[https://scholar.google.com/citations?user=458dsV0AAAAJ Google scholar profile]
{{Authority control}}

{{DEFAULTSORT:Assani, Idris}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:African-American mathematicians]]
[[Category:Beninese academics]]
[[Category:Paris Dauphine University alumni]]
[[Category:Pierre and Marie Curie University alumni]]
[[Category:University of North Carolina at Chapel Hill faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:American people of Beninese descent]]</text>
      <sha1>8fa8kyv3i6fesrdtpbijs9ptrk0r7kj</sha1>
    </revision>
  </page>
  <page>
    <title>Internal category</title>
    <ns>0</ns>
    <id>31813104</id>
    <revision>
      <id>826275015</id>
      <parentid>774799722</parentid>
      <timestamp>2018-02-18T06:04:03Z</timestamp>
      <contributor>
        <username>IvanPerez</username>
        <id>29551433</id>
      </contributor>
      <comment>Adds link to 'ambient category'.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2217">In [[mathematics]], more specifically in [[category theory]] - internal categories are a generalisation of the notion of [[small category]], and are defined with respect to a fixed [[ambient category]]. If the ambient category is taken to be the [[category of sets]] then one recovers the theory of small categories. In general, internal categories consist of a pair of objects in the ambient category - thought of as the 'object of objects' and 'object of morphisms', together with a collection of morphisms in the ambient category satisfying certain identities. [[Group object]]s, are common examples of internal categories.

There are notions of internal functors and natural transformations which make the collection of internal categories in a fixed category into a [[2-category]].

==Definitions==

Let &lt;math&gt; C&lt;/math&gt; be a category with [[Pullback (category theory)|pullback]]s. An internal category in &lt;math&gt;C&lt;/math&gt; consists of the following data: two &lt;math&gt;C&lt;/math&gt;-objects &lt;math&gt;C_0,C_1&lt;/math&gt; named "object of objects" and "object of morphisms" respectively and four &lt;math&gt;C&lt;/math&gt;-arrows &lt;math&gt;d_0,d_1:C_1\rightarrow C_0, e:C_0\rightarrow C_1,m:C_1\times_{C_0}C_1\rightarrow C_1&lt;/math&gt; subject to coherence conditions expressing the axioms of category theory. See 
&lt;ref&gt;{{cite book|last1=Moerdijk|first1=Ieke|last2=Mac Lane|first2=Saunders|title=Sheaves in geometry and logic : a first introduction to topos theory|date=1992|publisher=Springer-Verlag|location=New York|isbn=0-387-97710-4|edition=2nd corr. print., 1994.}}&lt;/ref&gt;
&lt;ref&gt;{{cite book|last1=MacLane|first1=Saunders|title=Categories for the working mathematician|date=1998|publisher=Springer|location=New York|isbn=0-387-98403-8|edition=2.}}&lt;/ref&gt;
&lt;ref&gt;{{cite book|last1=Borceux|first1=Francis|title=Handbook of categorical algebra|date=1994|publisher=Cambridge University Press|location=Cambridge|isbn=0-521-44178-1}}&lt;/ref&gt;
&lt;ref&gt;{{cite book|last1=Johnstone|first1=P.T.|title=Topos theory|date=1977|publisher=Academic Press|location=London|isbn=0-12-387850-0}}&lt;/ref&gt;
.

==See also==
* [[Enriched category]]

==References==
{{Reflist}}
*{{nlab|id=internal+category|title=Internal category}}

[[Category:Category theory]]


{{categorytheory-stub}}</text>
      <sha1>71njq9ffj7q99p86y6cjkj1cvgx3s35</sha1>
    </revision>
  </page>
  <page>
    <title>JH (hash function)</title>
    <ns>0</ns>
    <id>20442598</id>
    <revision>
      <id>847173092</id>
      <parentid>847172997</parentid>
      <timestamp>2018-06-23T12:29:07Z</timestamp>
      <contributor>
        <username>Danski454</username>
        <id>23050153</id>
      </contributor>
      <comment>Undid revision 847172997 by [[Special:Contributions/119.93.253.162|119.93.253.162]] ([[User talk:119.93.253.162|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2441">{{Infobox cryptographic hash function
| name           = JH
| image          = 
| caption        = 
&lt;!-- General --&gt;
| designers      = [[Hongjun Wu]]
| publish date   = 
| series         = 
| derived from   =
| derived to     = 
| related to     = 
| certification  = SHA-3 finalist
&lt;!-- Detail --&gt;
| digest size    = 224, 256, 384, 512
| structure      = 
| rounds         =
| speed          = 16.1 [[cycles per byte|cpb]] on [[Core 2]]  in 64-bit mode using SSE2; 37.3 cpb using ANSI C.
| cryptanalysis  = 
}}

'''JH''' is a  [[cryptographic hash function]] submitted to the [[NIST hash function competition]] by Hongjun Wu. Though chosen as one of the five finalists of the competition, JH ultimately lost to NIST hash candidate [[Keccak]].&lt;ref&gt;{{cite press release|url=https://www.nist.gov/itl/csd/sha-100212.cfm|title=NIST Selects Winner of Secure Hash Algorithm (SHA-3) Competition|date=2012-10-02|publisher=[[NIST]]|accessdate=2012-10-02}}&lt;/ref&gt; JH has a 1024-bit state, and works on 512-bit input blocks.  Processing an input block consists of three steps:
# XOR the input block into the left half of the state.
# Apply a 42-round unkeyed permutation (encryption function) to the state.  This consists of 42 repetitions of:
## Break the input into 256 4-bit blocks, and map each through one of two 4-bit [[S-box]]es, the choice being made by a 256-bit round-dependent key schedule.  Equivalently, combine each input block with a key bit, and map the result through a 5→4 bit S-box.
## Mix adjacent 4-bit blocks using a [[maximum distance separable code]] over [[Finite field|GF(2&lt;sup&gt;4&lt;/sup&gt;)]].
## Permute 4-bit blocks so that they will be adjacent to different blocks in following rounds.
# XOR the input block into the right half of the state.
The resulting digest is the first 224, 256, 384 or 512 bits from the 1024-bit final value.
It is well suited to a [[bit slicing]] implementation using the [[SSE2]] instruction set, giving speeds of 16.8 [[cycles per byte]].

==References==
{{reflist}}

== External links ==
* [http://www3.ntu.edu.sg/home/wuhj/research/jh/index.html The JH web site]
* [http://ehash.iaik.tugraz.at/wiki/JH JH page on the SHA-3 Zoo]
* [http://cryptography.gmu.edu/athena/index.php?id=source_codes VHDL source code developed by the Cryptographic Engineering Research Group (CERG) at George Mason University]

{{Cryptography navbox | hash}}

[[Category:NIST hash function competition]]


{{crypto-stub}}</text>
      <sha1>44k2dugbj46hfdbqtvrw4j3q65gglxv</sha1>
    </revision>
  </page>
  <page>
    <title>Joan Hutchinson</title>
    <ns>0</ns>
    <id>40343127</id>
    <revision>
      <id>857361442</id>
      <parentid>804372475</parentid>
      <timestamp>2018-08-31T05:37:19Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10543">'''Joan Prince Hutchinson''' (born 1945) is an American mathematician and Professor Emerita of Mathematics from [[Macalester College]].{{r|nw|cv}}

==Education==
Joan Hutchinson was born in [[Philadelphia]], [[Pennsylvania]]; her father was a demographer and university professor, and her mother a high school mathematics teacher. She studied at [[Smith College]] in Northampton, Massachusetts, graduating in 1967 summa cum laude with an honors paper directed by Prof. Alice Dickinson.
After graduation she worked as a [[computer programmer]] at the [[Woods Hole Oceanographic Institute]] and at the [[Harvard University]] Computing Center then studied mathematics (and English change ringing on tower bells)  at the [[University of Warwick]] in Coventry England.{{r|nw}} Returning  to the United States, Hutchinson did graduate work at the [[University of Pennsylvania]] earning a Ph.D. in mathematics in 1973 under the supervision of [[Herbert S. Wilf]].{{r|mg}}

==Career==
She was a John Wesley Young research instructor at [[Dartmouth College]], 1973–1975.  
She and her husband, fellow mathematician [[Stan Wagon]], taught at [[Smith College]], 1975-1990, and at [[Macalester College]], 1990-2007. At both colleges they shared a full-time position in mathematics. She spent sabbaticals, taught, and held visiting positions at [[Tufts University]], [[Carleton College]], [[University of Colorado Boulder]], [[University of Washington]], [[University of Michigan]], [[Mathematical Sciences Research Institute]] in [[Berkeley, California]], and [[University of Colorado Denver]].{{r|cv}}

She has served on committees of the [[American Mathematical Society]], the [[Mathematical Association of America]] (MAA), SIAM Special Interest Group on Discrete Math (SIAM-DM), and the [[Association for Women in Mathematics]], involved with the latter organization since a graduate student during its founding days in 1971. Mentoring women students and younger colleagues has been an important concern of her professional life. She served as the vice-chair of SIAM-DM, 2000-2002. She was a member of the editorial board of the ''[[American Mathematical Monthly]]'', 1986-1996, and continues on the board of the ''[[Journal of Graph Theory]]''{{r|jgt}} since 1993.

==Research==
Her research has focused on [[graph theory]] and [[discrete mathematics]], specializing mainly in topological and chromatic graph theory and on visibility graphs;{{r|cv}}
for overviews of this work see {{harvtxt|Hutchinson|2009}} and {{harvtxt|Dean|Hutchinson|2014}}.{{ran|H09}}{{ran|DH14}}

She has published over 75 research and expository papers in graph theory, many with the late Michael O. Albertson,{{r|albertson}} formerly of Smith College.
In one of their most cited works, Albertson and Hutchinson completed work of [[Gabriel Andrew Dirac]] related to the [[Heawood conjecture]] by proving that, on any surface other than the sphere or Klein bottle, the only graphs meeting Heawood's bound on the [[chromatic number]] of [[graph embedding|surface-embedded graphs]] are the [[complete graph]]s.{{ran|AH79}}
She has also considered algorithmic aspects in these areas, for example, generalizing the [[planar separator theorem]] to surfaces.{{ran|GHT84}}
With S. Wagon she has co-authored papers on algorithmic aspects of the [[four color theorem]].{{ran|HW98}}

Albertson and Hutchinson also wrote together the textbook ''Discrete Mathematics with Algorithms''.{{ran|AH88}}{{r|nw|klarner}}

==Awards and honors==
In 1994 she received the [[Carl B. Allendoerfer Award]]{{r|allendoerfer}} of the Mathematical Association of America for the expository article  ''Coloring ordinary maps, maps of empires, and maps of the moon'' in ''[[Mathematics Magazine]]''.{{ran|H93}}
The work of this paper was also included in an issue of ''What’s Happening in the Mathematical Sciences''{{r|cipra}} and in the Mathematical Recreations column{{r|stewart}} of ''[[Scientific American]]''.

In 1998 she was a winner of the MAA North Central Section Teaching Award,{{r|maa}}
and in 1999  she was a winner of the Deborah and Franklin Tepper Haimo Award for Excellence in College or University Teaching.{{r|haimo}}
On the occasion of her 60th birthday, she was the honoree at the Graph Theory with Altitude conference{{r|altitude}} at the University of Colorado Denver, organized by her former student Ellen Gethner, professor of computer science.

==Selected publications==
{{rma|AH79|{{cite journal|last1=Albertson|first1=Michael O.|last2=Hutchinson|first2=Joan P.|title=The three excluded cases of Dirac’s map-color theorem|journal=Ann. N. Y. Acad. Sci.|date=1979|volume=319|pages=7–17|department=Second International Conference on Combinatorial Mathematics (New York, 1978)|publisher=New York Acad, Sci.|location=New York |mr = 0556001|doi=10.1111/j.1749-6632.1979.tb32768.x|bibcode=1979NYASA.319....7A}}
|tw=4em}}

{{rma|GHT84|{{cite journal
 | last1 = Gilbert | first1 = John R.
 | last2 = Hutchinson | first2 = Joan P.
 | last3 = Tarjan | first3 = Robert Endre | author3-link = Robert Tarjan
 | doi = 10.1016/0196-6774(84)90019-1
 | issue = 3
 | journal = Journal of Algorithms
 | mr = 756165
 | pages = 391–407
 | title = A separator theorem for graphs of bounded genus
 | volume = 5
 | year = 1984}}
|tw=4em}}

{{rma|AH88|{{cite book|last1=Albertson|first1=Michael O.|last2=Hutchinson|first2=Joan P.|title=Discrete Mathematics with Algorithms|date=1988|publisher=Wiley|location=New York|isbn=0-471-84902-2 |mr= 0950858}}
|tw=4em}}

{{rma|H93|{{cite journal
 | last = Hutchinson | first = Joan P.
 | doi = 10.2307/2690733
 | issue = 4
 | journal = [[Mathematics Magazine]]
 | mr = 1240669
 | pages = 211–226
 | title = Coloring ordinary maps, maps of empires and maps of the moon
 | url = http://www.maa.org/programs/maa-awards/writing-awards/coloring-ordinary-maps-maps-of-empires-and-maps-of-the-moon
 | volume = 66
 | year = 1993}}
|tw=4em}}

{{rma|HW98|{{cite journal
 | last1 = Hutchinson | first1 = Joan
 | last2 = Wagon | first2 = Stan | author2-link = Stan Wagon
 | doi = 10.2307/2589650
 | issue = 2
 | journal = [[American Mathematical Monthly]]
 | mr = 1605875
 | pages = 170–174
 | title = Kempe revisited
 | volume = 105
 | year = 1998}}
|tw=4em}}

{{rma|H09|{{cite book
| last1=Hutchinson
| first1=Joan P.
| editor1-last=Beineke|editor1-first=L. W.
| editor2-last=Wilson|editor2-first=R.J.
| series=Encyclopedia of Mathematics and Its Applications 
| volume = 128
| title= Colouring graphs on surfaces
|date=2009
|publisher=[[Cambridge University Press]]
|location=Cambridge
|pages=111–132
|chapter=C6: Topics in Topological Graph Theory
| mr = 2581543
| ref=harv}}
|tw=4em}}

{{rma|DH14|{{cite book
|last1=Dean|first1=Alice M.
|last2=Hutchinson|first2=Joan P.
|editor1-last=Gross|editor1-first=J. L.|editor2-last=Yellen|editor2-first=J.|editor3-last=Zhang|editor3-first=J.
|title=Handbook of Graph Theory
|date=2014|url=https://www.crcpress.com/Handbook-of-Graph-Theory-Second-Edition/Gross-Yellen-Zhang/9781439880180#googlePreviewContainer
|publisher=CRC Press|location=Boca Raton|edition=2nd|chapter=Section 10.7 Visibility Graphs|isbn=9781439880180
|ref=harv}}
|tw=4em}}

==References==
{{reflist|30em|refs=

&lt;ref name=albertson&gt;{{cite web|title=Celebrating the Mathematical Inspirations of Michael O. Albertson|url=http://www.math.smith.edu/cone/|website=CoNE Revisited|publisher=Smith College|accessdate=27 February 2016}}&lt;/ref&gt;

&lt;ref name=allendoerfer&gt;{{cite web|title=Carl. B. Allendoerfer Awards|url=http://www.maa.org/programs/maa-awards/writing-awards/carl-b-allendoerfer-awards|website=Mathematical Association of America|publisher=MAA|accessdate=26 February 2016}}&lt;/ref&gt;

&lt;ref name=altitude&gt;{{cite web|title=Graph Theory with Altitude|url=http://at.yorku.ca/cgi-bin/calendar/d/facq77|website=Topology Atlas|publisher=York University|accessdate=26 February 2016}}&lt;/ref&gt;

&lt;ref name=cipra&gt;{{cite book|last= Cipra  |first= Barry A.  |author-link = Barry A. Cipra|title=What's Happening in the Mathematical Sciences|date=1993|publisher=Amer. Math. Soc.coume=1|isbn=978-0821889992|pages=43–46}}&lt;/ref&gt;

&lt;ref name=cv&gt;[http://www.macalester.edu/~hutchinson/JPHvitae.pdf Curriculum vitae], retrieved 2014-06-17.&lt;/ref&gt;

&lt;ref name=haimo&gt;{{cite web|title=Deborah and Franklin Tepper Haimo Award|url=http://www.maa.org/programs/maa-awards/teaching-awards/haimo-award-distinguished-teaching|website=Mathematical Association of America|publisher=MAA|accessdate=26 February 2016}}&lt;/ref&gt;

&lt;ref name=jgt&gt;{{cite web|title=Editorial Board|url=http://onlinelibrary.wiley.com/journal/10.1002/(ISSN)1097-0118/homepage/EditorialBoard.html|website=Journal of Graph Theory|publisher=Wiley|accessdate=27 February 2016}}&lt;/ref&gt;

&lt;ref name=klarner&gt;Review of ''Discrete Mathematics with Algorithms'' by [[David A. Klarner]] (1989), {{MR|0950858}}&lt;/ref&gt;

&lt;ref name=maa&gt;{{cite web|title=Section Teaching Awards|url=http://sections.maa.org/northcen/awards/teaching/teaching.html#awards|website=Mathematical Association of America|publisher=MAA|accessdate=26 February 2016}}&lt;/ref&gt;

&lt;ref name=mg&gt;{{mathgenealogy|name=Joan Prince Hutchinson|id=15209}}&lt;/ref&gt;

&lt;ref name=nw&gt;''Notable Women in Mathematics, a Biographical Dictionary'', edited by Charlene Morrow and Teri Perl, Greenwood Press, 1998. pp 90–93.&lt;/ref&gt;

&lt;ref name=stewart&gt;{{cite journal|last1=Stewart|first1=I.|title=Mathematical Recreations|journal=Scientific American|date=August   1997|volume=277|issue=2|pages=86–88|url=http://www.scientificamerican.com/magazine/sa/1997/08-01/|publisher=Nature Publishing Group |accessdate=27 February 2016|doi=10.1038/scientificamerican0897-86}}
{{cite journal|last1=Stewart|first1=I.|title=Mathematical Recreations|journal=Scientific American|date=September  1997|volume=227|issue=3|pages=92–94|url=http://www.scientificamerican.com/magazine/sa/1997/09-01/|publisher=Nature Publishing Group |accessdate=27 February 2016}}&lt;/ref&gt;

}}

{{authority control}}

{{DEFAULTSORT:Hutchinson, Joan}}
[[Category:1945 births]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Graph theorists]]
[[Category:Smith College alumni]]
[[Category:University of Pennsylvania alumni]]
[[Category:Dartmouth College faculty]]
[[Category:Tufts University faculty]]
[[Category:Carleton College faculty]]
[[Category:University of Colorado faculty]]
[[Category:Smith College faculty]]
[[Category:Macalester College faculty]]
[[Category:Living people]]
[[Category:Mathematicians from Pennsylvania]]</text>
      <sha1>df642xim7zd10gjy2h1cij21bqadnho</sha1>
    </revision>
  </page>
  <page>
    <title>Joint spectral radius</title>
    <ns>0</ns>
    <id>25140222</id>
    <revision>
      <id>812715936</id>
      <parentid>808835874</parentid>
      <timestamp>2017-11-29T13:08:50Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 0 sources and tagging 1 as dead. #IABot (v1.6.1)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10426">In mathematics, the '''joint spectral radius''' is a generalization of the classical notion of [[spectral radius]] of a matrix, to sets of matrices. In recent years this notion has found applications in a large number of engineering fields and is still a topic of active research.

==General description==

The joint spectral radius of a set of matrices is the maximal asymptotic growth rate of products of matrices taken in that set.  For a finite (or more generally compact) set of matrices &lt;math&gt;\mathcal M=\{A_1,\dots, A_m\} \subset \mathbb R^{n \times n},&lt;/math&gt; the joint spectral radius is defined as follows:

: &lt;math&gt;\rho (\mathcal M)= \lim_{k \to
\infty}\max{\{ \|A_{i_1}\cdots A_{i_k}\|^{1/k}:A_i\in\mathcal M\}}. \, &lt;/math&gt;

It can be proved that the limit exists and that the quantity actually does not depend on the chosen matrix norm  (this is true for any norm but particularly easy to see if the norm is [[Matrix norm|sub-multiplicative]]).   The joint spectral radius was introduced in 1960 by [[Gian-Carlo Rota]] and [[Gilbert Strang]],&lt;ref&gt;G. C. Rota and G. Strang. "A note on the joint spectral radius." Proceedings of the Netherlands Academy, 22:379–381, 1960. [https://books.google.com/books?id=x7zKLGu3g9IC&amp;lpg=RA1-PA40&amp;ots=rxuCbvNTxI&amp;dq=a%20note%20on%20the%20joint%20spectral%20radius%20rota%20strang&amp;lr&amp;pg=PA74#v=onepage&amp;q&amp;f=false]&lt;/ref&gt; two mathematicians from [[Massachusetts Institute of Technology|MIT]], but started attracting  attention with the work of [[Ingrid Daubechies]] and [[Jeffrey Lagarias]].&lt;ref&gt;Vincent D. Blondel. The birth of the joint spectral radius: an interview with Gilbert Strang. Linear Algebra and its Applications, 428:10, pp. 2261–2264, 2008.&lt;/ref&gt; They showed that the joint spectral radius can be used to describe smoothness properties of certain [[Wavelet#Wavelet function|wavelet functions]].&lt;ref&gt;I. Daubechies and J. C. Lagarias. "Two-scale difference equations. ii. local regularity, infinite products of matrices and fractals." SIAM Journal of Mathematical Analysis, 23, pp. 1031–1079, 1992.&lt;/ref&gt;  A wide number of applications have been proposed since then.   It is known  that the joint spectral radius quantity is [[NP-hard]] to compute or to approximate, even when the set &lt;math&gt;\mathcal M&lt;/math&gt; consists of only two matrices with all nonzero entries of the two
matrices which are constrained to be equal.&lt;ref&gt;J. N. Tsitsiklis and V. D. Blondel. "Lyapunov Exponents of Pairs of Matrices, a Correction." ''[[Mathematics of Control, Signals, and Systems]]'', 10, p. 381, 1997.&lt;/ref&gt;  Moreover, the question "&lt;math&gt;\rho\leq 1 ?&lt;/math&gt;" is an [[undecidable problem]].&lt;ref&gt;Vincent D. Blondel, John N. Tsitsiklis. "The boundedness of all products of a pair of matrices is undecidable." Systems and Control Letters, 41:2, pp. 135&amp;ndash;140, 2000.&lt;/ref&gt; Nevertheless, in recent years much progress has been done on its understanding, and it appears that in practice the joint spectral radius can often be computed to satisfactory precision, and that it moreover can bring interesting insight in engineering and mathematical problems.

==Computation==

===Approximation algorithms===

In spite of the negative theoretical results on the joint spectral radius computability, methods have been proposed that perform well in practice. Algorithms are even known, which can reach an arbitrary accuracy in an a priori computable amount of time. These algorithms can be seen as trying to approximate the unit ball of a particular vector norm, called the extremal norm.&lt;ref&gt;N. Barabanov. "Lyapunov indicators of discrete inclusions i&amp;ndash;iii." Automation and Remote Control, 49:152–157, 283–287, 558–565, 1988.&lt;/ref&gt; One generally distinguishes between two families of such algorithms: the first family, called '''polytope norm methods''', construct the extremal norm by computing long trajectories of points.&lt;ref&gt;V. Y. Protasov. "The joint spectral radius and invariant sets of linear operators." Fundamentalnaya i prikladnaya matematika, 2(1):205–231, 1996.&lt;/ref&gt;&lt;ref&gt;N. Guglielmi, F. Wirth, and M. Zennaro. "Complex polytope extremality results for families of matrices." SIAM Journal on Matrix Analysis and Applications, 27(3):721–743, 2005.&lt;/ref&gt; An advantage of these methods is that in the favorable cases it can find the exact value of the joint spectral radius and provide a certificate that this is the exact value.

The second methods approximate the extremal norm with '''modern optimization techniques''', like ellipsoid norm approximation,&lt;ref&gt;Vincent D. Blondel, Yurii Nesterov and Jacques Theys, On the accuracy of the ellipsoid norm approximation of the joint spectral radius, Linear Algebra and its Applications, 394:1, pp. 91–107, 2005.&lt;/ref&gt; [[semidefinite programming]],&lt;ref&gt;T. Ando and M.-H. Shih. "Simultaneous contractibility." SIAM Journal on Matrix Analysis and Applications, 19(2):487–498, 1998.&lt;/ref&gt;&lt;ref&gt;V. D. Blondel and Y. Nesterov. "Computationally efficient approximations of the joint spectral radius." SIAM Journal of Matrix Analysis, 27(1):256–272, 2005.&lt;/ref&gt; [[Polynomial SOS|Sum Of Squares]],&lt;ref&gt;P. Parrilo and A. Jadbabaie. "Approximation of the joint spectral radius using sum of squares." Linear Algebra and its Applications, 428(10):2385–2402, 2008.&lt;/ref&gt; [[Conic optimization|conic programming]].&lt;ref&gt;V. Protasov, R. M. Jungers, and V. D. Blondel. "Joint spectral characteristics of matrices: a conic programming approach." SIAM Journal on Matrix Analysis and Applications, 2008.&lt;/ref&gt; The advantage of these methods is that they are easy to implement, and in practice, they provide in general the best bounds on the joint spectral radius.

===The finiteness conjecture===

Related to the computability of the joint spectral radius is the following conjecture:&lt;ref&gt;J. C. Lagarias and Y. Wang. "The finiteness conjecture for the generalized spectral radius of a set of matrices." Linear Algebra and its Applications, 214:17–42, 1995.&lt;/ref&gt;

"For any finite set of matrices &lt;math&gt;\mathcal M \subset \mathbb R^{n \times n},&lt;/math&gt; there is a product &lt;math&gt; A_1\dots A_t&lt;/math&gt; of matrices in this set such that 
:&lt;math&gt;\rho(\mathcal M) = \rho(A_1 \dots A_t)^{1/t}.&lt;/math&gt;"
In the above equation "&lt;math&gt; \rho(A_1 \dots A_t)&lt;/math&gt;" refers to the classical [[spectral radius]] of the matrix &lt;math&gt;A_1 \dots A_t.&lt;/math&gt;

This conjecture, proposed in 1995, has been proved to be false in 2003,.&lt;ref&gt;T. Bousch and J. Mairesse. "Asymptotic height optimization for topical IFS, Tetris heaps, and the finiteness conjecture." Journal of the American Mathematical Society, 15(1):77–111, 2002.&lt;/ref&gt; The counterexample provided in that reference uses advanced measure-theoretical ideas. Subsequently, many other counterexamples have been provided, including an elementary counterexample that uses simple combinatorial properties  matrices &lt;ref&gt;V. D. Blondel, J. Theys and A. A. Vladimirov, An elementary counterexample to the finiteness conjecture, SIAM Journal on Matrix Analysis, 24:4, pp. 963–970, 2003.&lt;/ref&gt; and a counterexample based on dynamical systems properties.&lt;ref&gt;V. Kozyakin
Structure of Extremal Trajectories of Discrete Linear Systems and the Finiteness Conjecture, Automat. Remote Control, 68 (2007), no. 1, 174–209/&lt;/ref&gt; Recently an explicit counterexample has been proposed in.&lt;ref&gt;Kevin G. Hare, Ian D. Morris, Nikita Sidorov, Jacques Theys. An explicit counterexample to the Lagarias–Wang finiteness conjecture, Advances in Mathematics, 226, pp. 4667-4701, 2011.&lt;/ref&gt; Many questions related to this conjecture are still open, as for instance the question of knowing whether it holds for pairs of [[Binary matrix|binary matrices]].&lt;ref&gt;A. Cicone, N. Guglielmi, S. Serra Capizzano, and M. Zennaro. "Finiteness property of pairs of
2&amp;nbsp;×&amp;nbsp;2 sign-matrices via real extremal polytope norms." Linear Algebra and its Applications, 2010.&lt;/ref&gt;&lt;ref&gt;R. M. Jungers and V. D. Blondel. "On the finiteness property for rational matrices." Linear Algebra and its Applications, 428(10):2283–2295, 2008.&lt;/ref&gt;

==Applications==

The joint spectral radius was introduced for its interpretation as a stability condition for discrete-time switching [[dynamical system]]s.  Indeed, the system defined by the equations
:&lt;math&gt;x_{t+1}=A_tx_{t}, \quad A_t\in \mathcal M \, \forall t&lt;/math&gt;
is [[Lyapunov stability|stable]] if and only if &lt;math&gt;\rho(\mathcal M)&lt;1.&lt;/math&gt;

The joint spectral radius became popular when [[Ingrid Daubechies]] and [[Jeffrey Lagarias]] showed that it rules the continuity of certain wavelet functions.  Since then, it has found many applications, ranging from number theory to information theory, [[autonomous agent]]s consensus, [[combinatorics on words]],...

==Related notions==

The joint spectral radius is the generalization of the [[spectral radius]] of a matrix for a set of several matrices.  However, much more quantities can be defined when considering a set of matrices: The '''joint spectral subradius''' characterizes the minimal rate of growth of products in the semigroup generated by &lt;math&gt;\mathcal M&lt;/math&gt;.  
The '''p-radius''' characterizes the rate of growth of the &lt;math&gt;L_p&lt;/math&gt; average of the norms of the products in the semigroup.
The '''Lyapunov exponent''' of the set of matrices characterizes the rate of growth of the geometric average.

== References ==
{{Reflist}}

== Further reading ==
*{{cite book
 | author = Raphael M. Jungers
 | year = 2009
 | title = The joint spectral radius, Theory and applications
 | publisher = Springer
 | isbn = 978-3-540-95979-3
}}

*{{cite book
 |editor1=Vincent D. Blondel |editor2=Michael Karow |editor3=Vladimir Protassov |editor4=Fabian R. Wirth | year = 2008
 | journal = Linear Algebra and its Applications
 | title = Linear Algebra and its Applications: special issue on the joint spectral radius
 | publisher = Elsevier
 | volume = 428
 | issue = 10
}}

*{{cite web
 |url=http://www.math.msu.edu/~cicone/papers/AntonioCiconeThesis.pdf
 |title=PhD thesis. Spectral Properties of Families of Matrices. Part III
 |author=Antonio Cicone
 |year=2011
}}

*{{cite web
 |url    = http://www.inma.ucl.ac.be/~blondel/05thesetheys.pdf
 |title  = PhD thesis. Joint Spectral Radius: Theory and approximations.
 |author = Jacques Theys
 |year   = 2005
}}{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}

&lt;!--- Categories ---&gt;
[[Category:Control theory]]
[[Category:Linear algebra]]</text>
      <sha1>9kuq0robiv8piiddq6fwe9qegqq8qxd</sha1>
    </revision>
  </page>
  <page>
    <title>Korn–Kreer–Lenssen model</title>
    <ns>0</ns>
    <id>32160213</id>
    <revision>
      <id>840345393</id>
      <parentid>798155545</parentid>
      <timestamp>2018-05-09T08:41:28Z</timestamp>
      <contributor>
        <ip>141.228.114.99</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3154">{{Orphan|date=May 2014}}

The '''Korn–Kreer–Lenssen model''' ('''KKL model''') is a discrete [[Trinomial tree|trinomial model]] proposed in 1998 by Ralf Korn, Markus Kreer and Mark Lenssen&lt;ref&gt;{{cite journal|doi=10.1080/15326349808807493 | volume=14 | title=Pricing of european options when the underlying stock price follows a linear birth-death process | journal=Communications in Statistics. Stochastic Models | pages=647–662}}&lt;/ref&gt; to model [[illiquid securities]] and to value [[Derivative (finance)|financial derivatives]] on these. It generalizes the binomial [[Cox-Ross-Rubinstein model]] in a natural way as the stock in a given time interval can either rise one unit up, fall one unit down or remain unchanged. In contrast to [[Black–Scholes]] or [[Cox-Ross-Rubinstein model]] the [[Market (economics)|market]] consisting of stock and cash is not complete yet. To value and replicate a financial derivative an additional traded security related to the original security needs to be added. This  might be a Low Exercise Price Option (or short [[LEPO]]). The mathematical proof of arbitrage free pricing is based on [[Martingale representation theorem|martingale representations]] for point processes pioneered in the 1980s and 1990 by [[Albert Shiryaev]], Robert Liptser and [[Marc Yor]].

The dynamics is based on continuous time linear [[birth-death process]]es and analytic formulae for option prices and Greeks can be stated. Later work looks at market completion with general calls or puts.&lt;ref&gt;http://www.wilmott.com/pdfs/101130_chen.pdf&lt;/ref&gt;  A comprehensive introduction may be found in the attached MSc-thesis.&lt;ref&gt;http://resources.aims.ac.za/archive/2010/obeng.pdf&lt;/ref&gt;

The model belongs to the class of [[Trinomial tree|trinomial models]] and the difference to the standard [[trinomial tree]] is the following: if &lt;math&gt; \Delta t &lt;/math&gt; denotes the waiting time between two movements of the stock price then in the KKL-model &lt;math&gt; \Delta t &lt;/math&gt; remains finite and exponentially distributed whereas in [[trinomial tree]]s the time is discrete and the limit &lt;math&gt; \Delta t \rightarrow 0&lt;/math&gt; is taken by numerical extrapolation afterwards.

==See also==
*[[Binomial options pricing model]]
*[[Trinomial tree]]
*[[Valuation of options]]
*[[Option (finance)#Model implementation|Option: Model implementation]]

== References ==
&lt;references /&gt;
&lt;!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. ---&gt;
*
*
*
*

== Literature ==
* Ralf Korn, Markus Kreer and Mark Lenssen: "Pricing of european options when the underlying stock price follows a linear birth-death process", Stochastic Models Vol. 14(3), 1998, pp 647 – 662
* Xiong Chen: "The Korn-Kreer-Lenssen Model as an alternative for option pricing", Willmott Magazine June 2004, pp 74–80

{{DEFAULTSORT:Korn-Kreer-Lenssen model}}
[[Category:Financial models]]
[[Category:Mathematical finance]]
[[Category:Options (finance)]]
[[Category:Models of computation]]
[[Category:Trees (data structures)]]</text>
      <sha1>mtk9vtgjvddcpfmrgi99hbg68q3ewig</sha1>
    </revision>
  </page>
  <page>
    <title>Kurepa tree</title>
    <ns>0</ns>
    <id>8267820</id>
    <revision>
      <id>813155723</id>
      <parentid>717192538</parentid>
      <timestamp>2017-12-02T03:22:37Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: J. Symbolic Logic → Journal of Symbolic Logic using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3736">In [[set theory]], a '''Kurepa tree''' is a [[tree (set theory)|tree]] (''T'',&amp;nbsp;&lt;) of height [[First uncountable ordinal|ω&lt;sub&gt;1&lt;/sub&gt;]], each of whose levels is at most countable, and has at least [[Aleph number|ℵ&lt;sub&gt;2&lt;/sub&gt;]] many branches. This concept was introduced by {{harvs|txt|authorlink=Đuro Kurepa|last=Kurepa|year=1935}}. The existence of a Kurepa tree (known as the '''Kurepa hypothesis''', though Kurepa originally conjectured that this was false) is consistent with the axioms of [[ZFC]]: [[Robert M. Solovay|Solovay]] showed in unpublished work that there are Kurepa trees in [[Kurt Gödel|Gödel]]'s [[constructible universe]] {{harv|Jech|1971}}. More precisely, the existence of Kurepa trees follows from the [[diamond principle|diamond plus principle]], which holds in the constructible universe. On the other hand, {{harvs|txt|authorlink=Jack Silver|last=Silver|year= 1971}} showed that if a [[strongly inaccessible cardinal]] is [[List of forcing notions#Levy collapsing|Lévy collapsed]] to ω&lt;sub&gt;2&lt;/sub&gt; then, in the resulting model, there are no Kurepa trees. The existence of an inaccessible cardinal is in fact equiconsistent with the failure of the Kurepa hypothesis, because if the Kurepa hypothesis is false then the cardinal ω&lt;sub&gt;2&lt;/sub&gt; is inaccessible in the constructible universe.

A Kurepa tree with fewer than 2&lt;sup&gt;ℵ&lt;sub&gt;1&lt;/sub&gt;&lt;/sup&gt; branches is known as a [[Jech–Kunen tree]].

More generally if κ is an infinite cardinal, then a κ-Kurepa tree is a tree of height κ with more than κ branches but at most |α| elements of each infinite level α&lt;κ, and the Kurepa hypothesis for κ is the statement that there is a κ-Kurepa tree. Sometimes the tree is also assumed to be binary. The existence of a binary κ-Kurepa tree is equivalent to the existence of a '''Kurepa family''': a set of more than κ subsets of κ such that their intersections with any infinite ordinal α&lt;κ form a set of cardinality at most α. The Kurepa hypothesis is false if κ is an [[ineffable cardinal]], and conversely Jensen showed that in the constructible universe for any uncountable regular cardinal κ there is a κ-Kurepa tree unless κ is ineffable.

== Specializing a Kurepa tree ==

A Kurepa tree can be "killed" by [[Forcing (mathematics)|forcing]] the existence of a function whose value on any non-root node is an ordinal less than the rank of the node, such that whenever three nodes, one of which is a lower bound for the other two, are mapped to the same ordinal, then the three nodes are comparable.  This can be done without [[Ordinal collapsing function|collapsing]] ℵ&lt;sub&gt;1&lt;/sub&gt;, and results in a tree with exactly ℵ&lt;sub&gt;1&lt;/sub&gt; branches.

== See also ==
* [[Aronszajn tree]]
* [[Suslin tree]]

== References ==

*{{citation|mr=0284331 | zbl=0245.02054 | doi=10.2307/2271510
|last=Jech|first= Thomas J. | authorlink=Thomas Jech
|title=Trees
|journal=Journal of Symbolic Logic|volume= 36|year= 1971|pages= 1–14|jstor=2271510}}
* {{cite book|last=Jech|first= Thomas|title=Set Theory|publisher=Springer-Verlag|year=2002|isbn=3-540-44085-2}}
*{{citation|last=Kurepa|first=G.|year=1935|title=Ensembles ordonnés et ramifiés|journal=Publ. math. Univ. Belgrade |volume=4|pages=1–138|url=http://elibrary.matf.bg.ac.rs/handle/123456789/326 | zbl=0014.39401 | JFM=61.0980.01 }}
*{{citation|MR=0277379 | zbl=0255.02068
|last=Silver|first= Jack
|chapter=The independence of Kurepa's conjecture and two-cardinal conjectures in model theory|year= 1971 |title=Axiomatic Set Theory |series=Proc. Sympos. Pure Math.|volume= XIII |pages= 383–390 |publisher=Amer. Math. Soc.|place= Providence, R.I.}}

[[Category:Trees (set theory)]]
[[Category:Independence results]]


{{settheory-stub}}</text>
      <sha1>eom94ascv4arptto77tbwvrivd99lxs</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Felix Klein</title>
    <ns>0</ns>
    <id>39491072</id>
    <revision>
      <id>714361943</id>
      <parentid>697336906</parentid>
      <timestamp>2016-04-09T08:09:37Z</timestamp>
      <contributor>
        <username>Andy M. Wang</username>
        <id>516856</id>
      </contributor>
      <minor/>
      <comment>/* top */cleanup and small fixes using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1180">These are '''things named after [[Felix Klein]]''' (1849 – 1925), a German mathematician.
{{expand list|date=May 2013}}
*[[Beltrami–Klein model]]
*[[Cayley–Klein metric]]
*[[Klein bottle]]
*[[Klein configuration]]
*[[Klein four-group]]
*[[Klein geometry]]
*[[Klein model]]
*[[Klein quadric]]
*[[Kleinian group]]
*[[Kleinian integer]]
*[[Kleinian ring]]
*[[Schottky–Klein prime form]]
*[[Felix Klein Protocols|The Felix Klein Protocols]]
*[[International Commission on Mathematical Instruction#Awards|Felix Klein medal]], named after the first president of the [[International Commission on Mathematical Instruction|ICMI]] (1908–1920), honours a lifetime achievement in mathematics education research.
* The [http://www.mathunion.org/icmi/other-activities/klein-project/introduction/ Klein project] of the [[International Mathematical Union|IMU]] and [[International Commission on Mathematical Instruction|ICMI]] aims to produce a book for upper secondary teachers that communicates the breadth and vitality of the research discipline of mathematics and connects it to the senior secondary school curriculum.

[[Category:Lists of things named after mathematicians|Klein]]</text>
      <sha1>dc7icp7buy5x4e3oube5nwscmw61hut</sha1>
    </revision>
  </page>
  <page>
    <title>Littlewood–Richardson rule</title>
    <ns>0</ns>
    <id>16004359</id>
    <revision>
      <id>869327260</id>
      <parentid>866999567</parentid>
      <timestamp>2018-11-17T22:37:01Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; reformat 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26123">In [[mathematics]], the '''Littlewood–Richardson rule''' is a combinatorial description of the coefficients that arise when decomposing a product of two [[Schur polynomial|Schur functions]] as a linear combination of other Schur functions. These coefficients are natural numbers, which the Littlewood–Richardson rule describes as counting certain [[skew tableau]]x. They occur in many other mathematical contexts, for instance as [[Multiplicity (mathematics)|multiplicity]] in the decomposition of [[tensor product]]s of [[irreducible representation]]s of [[general linear group]]s (or related groups like the [[special linear group|special linear]] and [[special unitary group]]s), or in the decomposition of certain [[induced representations]] in the [[representation theory of the symmetric group]], or in the area of [[algebraic combinatorics]] dealing with [[Young tableaux]] and [[symmetric polynomials]].

Littlewood–Richardson coefficients depend on three [[integer partition|partition]]s, say &lt;math&gt;\lambda,\mu,\nu&lt;/math&gt;, of which &lt;math&gt;\lambda&lt;/math&gt; and &lt;math&gt;\mu&lt;/math&gt; describe the Schur functions being multiplied, and &lt;math&gt;\nu&lt;/math&gt; gives the Schur function of which this is the coefficient in the linear combination; in other words they are the coefficients &lt;math&gt;c_{\lambda,\mu}^\nu&lt;/math&gt; such that
:&lt;math&gt;s_\lambda s_\mu=\sum_\nu c_{\lambda,\mu}^\nu s_\nu.&lt;/math&gt;
The Littlewood–Richardson rule states that &lt;math&gt;c_{\lambda,\mu}^\nu&lt;/math&gt; is equal to the number of Littlewood–Richardson tableaux of [[Skew tableau|skew shape]] &lt;math&gt;\nu/\lambda&lt;/math&gt; and of weight &lt;math&gt;\mu&lt;/math&gt;.

== History ==

{{quote box
|align=right
|width=33%
|quote=Unfortunately the Littlewood–Richardson rule is much harder to prove than was at first suspected. The author was once told that the Littlewood–Richardson rule helped to get men on the moon but was not proved until after they got there. 
|source={{harvs|txt|first=Gordon|last=James|year=1987}}
}}
The Littlewood–Richardson rule was first stated by {{harvs|txt|author1-link=Dudley E. Littlewood|author2-link=Archibald Read Richardson|year= 1934|last=Littlewood |first=D. E.|last2= Richardson |first2=A. R.|loc=theorem III p. 119}} but though they claimed it as a theorem they only proved it in some fairly simple special cases. 
{{harvs|txt|authorlink=Gilbert de Beauregard Robinson|last=Robinson|year=1938}} claimed to complete their proof, but his argument had gaps, though it was so obscurely written that these gaps were not noticed for some time, and his argument is reproduced in the book  {{harv|Littlewood|1950}}. Some of the gaps were later filled by {{harvtxt|Macdonald|1995}}. The first rigorous proofs of the rule were given four decades after it was found, by {{harvs|txt|last=Schützenberger|year1=1977}} and {{harvtxt|Thomas|1974}}, after the necessary combinatorial theory was developed by {{harvs|txt|authorlink=Craige Schensted|last=Schensted|first= C.|year=1961}}, {{harvs|txt|last=Schützenberger|year1=1963}}, and {{harvs|txt|authorlink=Donald Knuth|last=Knuth|year=1970}} in their work on the [[Robinson–Schensted correspondence]]. 
There are now several short proofs of the rule, such as {{harv|Gasharov|1998}},  and {{harv|Stembridge|2002}} using [[Bender-Knuth involution]]s.
{{harvtxt|Littelmann|1994}} used the  [[Littelmann path model]] to generalize the Littlewood–Richardson rule to other semisimple Lie  groups.

The Littlewood–Richardson rule is notorious for the number of errors that appeared prior to its complete, published proof. Several published attempts to prove it are incomplete, and it is particularly difficult to avoid errors when doing hand calculations with it: even the original example in {{harvs|txt|year= 1934|last=Littlewood |first=D. E.|last2= Richardson |first2=A. R.}} contains an error.

=== Littlewood–Richardson tableaux ===

[[Image:LR tableau of shape (4,3,2)-(2,1) word 112123.svg|thumb|right|A Littlewood–Richardson tableau]]
A Littlewood–Richardson tableau is a skew [[Young tableau#Definitions|semistandard tableau]] with the additional property that the sequence obtained by concatenating its reversed rows is a [[lattice word]] (or lattice permutation), which means that in every initial part of the sequence any number &lt;math&gt;i&lt;/math&gt; occurs at least as often as the number &lt;math&gt;i+1&lt;/math&gt;. Another equivalent (though not quite obviously so) characterization is that the tableau itself, and any tableau obtained from it by removing some number of its leftmost columns, has a weakly decreasing weight. Many other combinatorial notions have been found that turn out to be in bijection with Littlewood–Richardson tableaux, and can therefore also be used to define the Littlewood–Richardson coefficients.

[[Image:LR tableau of shape (4,3,2)-(2,1) word 112213.svg|thumb|right|Another Littlewood–Richardson tableau]]

=== Example ===

Consider the case that &lt;math&gt;\lambda=(2,1)&lt;/math&gt;, &lt;math&gt;\mu=(3,2,1)&lt;/math&gt; and &lt;math&gt;\nu=(4,3,2)&lt;/math&gt;. Then the fact that &lt;math&gt;c_{\lambda,\mu}^\nu=2&lt;/math&gt; can be deduced from the fact that the two tableaux shown at the right are the only two Littlewood–Richardson tableaux of shape &lt;math&gt;\nu/\lambda&lt;/math&gt; and weight &lt;math&gt;\mu&lt;/math&gt;. Indeed, since the last box on the first nonempty line of the skew diagram can only contain an entry 1, the entire first line must be filled with entries 1 (this is true for any Littlewood–Richardson tableau); in the last box of the second row we can only place a 2 by column strictness and the fact that our lattice word cannot contain any larger entry before it contains a 2. For the first box of the second row we can now either use a 1 or a 2. Once that entry is chosen, the third row must contain the remaining entries to make the weight (3,2,1), in a weakly increasing order, so we have no choice left any more; in both case it turns out that we do find a Littlewood–Richardson tableau.

=== A more geometrical description ===

The condition that the sequence of entries read from the tableau in a somewhat peculiar order form a lattice word can be replaced by a more local and geometrical condition. Since in a semistandard tableau equal entries never occur in the same column, one can number the copies of any value from right to left, which is their order of occurrence in the sequence that should be a lattice word. Call the number so associated to each entry its index, and write an entry ''i'' with index ''j'' as ''i''[''j'']. Now if some Littlewood–Richardson tableau contains an entry &lt;math&gt;i&gt;1&lt;/math&gt; with index ''j'', then that entry ''i''[''j''] should occur in a row strictly below that of &lt;math&gt;(i-1)[j]&lt;/math&gt; (which certainly also occurs, since the entry ''i''&amp;nbsp;−&amp;nbsp;1 occurs as least as often as the entry ''i'' does). In fact the entry ''i''[''j''] should also occur in a column no further to the right than that same entry &lt;math&gt;(i-1)[j]&lt;/math&gt; (which at first sight appears to be a stricter condition). If the weight of the Littlewood–Richardson tableau is fixed beforehand, then one can form a fixed collection of indexed entries, and if these are placed in a way respecting those geometric restrictions, in addition to those of [[Young tableau#Definitions|semistandard tableaux]] and the condition that indexed copies of the same entries should respect right-to-left ordering of the indexes, then the resulting tableaux are guaranteed to be Littlewood–Richardson tableaux.

== An algorithmic form of the rule ==

The Littlewood–Richardson as stated above gives a combinatorial expression for individual Littlewood–Richardson coefficients, but gives no indication of a practical method to enumerate the Littlewood–Richardson tableaux in order to find the values of these coefficients. Indeed, for given &lt;math&gt;\lambda,\mu,\nu&lt;/math&gt; there is no simple criterion to determine whether any Littlewood–Richardson tableaux of shape &lt;math&gt;\nu/\lambda&lt;/math&gt; and of weight &lt;math&gt;\mu&lt;/math&gt; exist at all (although there are a number of necessary conditions, the simplest of which is &lt;math&gt;|\lambda|+|\mu|=|\nu|&lt;/math&gt;); therefore it seems inevitable that in some cases one has to go through an elaborate search, only to find that no solutions exist.

Nevertheless, the rule leads to a quite efficient procedure to determine the full decomposition of a product of Schur functions, in other words to determine all coefficients &lt;math&gt;c_{\lambda,\mu}^\nu&lt;/math&gt; for fixed λ and μ, but varying ν. This fixes the weight of the Littlewood–Richardson tableaux to be constructed and the "inner part" λ of their shape, but leaves the "outer part" ν free. Since the weight is known, the set of indexed entries in the geometric description is fixed. Now for successive indexed entries, all possible positions allowed by the geometric restrictions can be tried in a [[backtracking]] search. The entries can be tried in increasing order, while among equal entries they can be tried by ''decreasing'' index. The latter point is the key to efficiency of the search procedure: the entry ''i''[''j''] is then restricted to be in a column to the right of &lt;math&gt;i[j+1]&lt;/math&gt;, but no further to the right than &lt;math&gt;i-1[j]&lt;/math&gt; (if such entries are present). This strongly restricts the set of possible positions, but ''always leaves at least one valid position for &lt;math&gt;i[j]&lt;/math&gt;''; thus every placement of an entry will give rise to at least one complete Littlewood–Richardson tableau, and the [[search tree]] contains no dead ends.

A similar method can be used to find  all coefficients &lt;math&gt;c_{\lambda,\mu}^\nu&lt;/math&gt; for fixed λ and ν, but varying μ.

==Littlewood–Richardson coefficients==

The Littlewood–Richardson coefficients ''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp;  appear in the following interrelated ways:
*They are the structure constants for the product in the [[ring of symmetric functions]] with respect to the basis of Schur functions
::&lt;math&gt;s_\lambda s_\mu =\sum c_{\lambda\mu}^\nu s_\nu&lt;/math&gt;
:or equivalently ''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp; is the inner product of ''s''&lt;sub&gt;''&amp;nu;''&lt;/sub&gt; and ''s''&lt;sub&gt;''&amp;lambda;''&lt;/sub&gt;''s''&lt;sub&gt;''&amp;mu;''&lt;/sub&gt;.
*They express [[skew Schur function]]s in terms of Schur functions
::&lt;math&gt;s_{\nu/\lambda} =\sum _\mu c_{\lambda\mu}^\nu s_\mu.&lt;/math&gt;
*The ''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp; appear as intersection numbers on a [[Grassmannian]]:
::&lt;math&gt;\sigma_\lambda \sigma_\mu =\sum c_{\lambda\mu}^\nu \sigma_\nu&lt;/math&gt;
:where ''&amp;sigma;''&lt;sub&gt;''μ''&lt;/sub&gt; is the class of the [[Schubert variety]] of a Grassmannian corresponding to&amp;nbsp;''μ''.
*''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp;  is the number of times the irreducible representation ''V''&lt;sub&gt;''&amp;lambda;''&lt;/sub&gt; &amp;otimes; ''V''&lt;sub&gt;''&amp;mu;''&lt;/sub&gt; of the product of symmetric groups ''S''&lt;sub&gt;|''&amp;lambda;''|&lt;/sub&gt; &amp;times; ''S''&lt;sub&gt;|''&amp;mu;''|&lt;/sub&gt; appears in the restriction of the representation ''V''&lt;sub&gt;''&amp;nu;''&lt;/sub&gt; of ''S''&lt;sub&gt;|''&amp;nu;''|&lt;/sub&gt; to ''S''&lt;sub&gt;|''&amp;lambda;''|&lt;/sub&gt; &amp;times; ''S''&lt;sub&gt;|''&amp;mu;''|&lt;/sub&gt;. By [[Frobenius reciprocity]] this is also the number of times that ''V''&lt;sub&gt;''&amp;nu;''&lt;/sub&gt; occurs in the representation of ''S''&lt;sub&gt;|''&amp;nu;''|&lt;/sub&gt; induced from ''V''&lt;sub&gt;''&amp;lambda;''&lt;/sub&gt;&amp;nbsp;&amp;otimes;&amp;nbsp;''V''&lt;sub&gt;''&amp;mu;''&lt;/sub&gt;.
*The ''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp; appear in the decomposition of the tensor product {{harv|Fulton|1997}} of two [[Schur module]]s (irreducible representations of special linear groups)
::&lt;math&gt;E^\lambda \otimes E^\mu =\bigoplus_\nu (E^\nu)^{\oplus c_{\lambda\mu}^\nu}.&lt;/math&gt;
*''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp;  is the number of standard Young tableaux of shape ''&amp;nu;''/''&amp;mu;'' that are [[jeu de taquin]] equivalent to some fixed standard Young tableau of shape&amp;nbsp;''&amp;lambda;''.
*''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp; is the number of Littlewood–Richardson tableaux of shape ''ν''/''λ'' and of weight&amp;nbsp;''μ''.
*''c''{{sup sub|''ν''|''λμ''}}&amp;nbsp;&amp;nbsp; is the number of [[picture (mathematics)|pictures]] between μ and ν/λ.

==Generalizations and special cases==
{{harvtxt|Zelevinsky|1981}} extended the Littlewood–Richardson rule to skew Schur functions as follows:
:&lt;math&gt;s_\lambda s_{\mu/\nu} = \sum_{\lambda+\omega(T_{\ge j})\in P}s_{\lambda+\omega(T)}&lt;/math&gt;
where the sum is over all tableaux ''T'' on &amp;mu;/&amp;nu; such that for all ''j'', the sequence of integers &amp;lambda;+&amp;omega;(''T''&lt;sub&gt;&amp;ge;''j''&lt;/sub&gt;) is non-increasing, and &amp;omega; is the weight.

[[Pieri's formula]], which is the special case of the Littlewood–Richardson rule in the case when one of the partitions has only '''one part''', states that 
*&lt;math&gt;\displaystyle S_\mu S_n=\sum_\lambda S_\lambda&lt;/math&gt;
where ''S''&lt;sub&gt;''n''&lt;/sub&gt; is the Schur function of a partition with one row and the sum is over all partitions &amp;lambda; obtained from &amp;mu; by adding ''n'' elements to its [[Ferrers diagram]], no two in the same column.

If both partitions are '''rectangular''' in shape, the sum is also multiplicity free {{harv|Okada|1998}}. Fix ''a'', ''b'', ''p'', and ''q'' positive integers with ''p'' &lt;math&gt;\geq&lt;/math&gt; ''q''. Denote by &lt;math&gt;(a^p)&lt;/math&gt; the partition with ''p'' parts of length ''a''. The partitions indexing nontrivial components of &lt;math&gt;s_{(a^p)}s_{(b^q)}&lt;/math&gt; are those partitions &lt;math&gt;\lambda&lt;/math&gt; with length &lt;math&gt;\leq p+q&lt;/math&gt; such that 
*&lt;math&gt;\lambda_{q+1} = \lambda_{q+2} = \cdots = \lambda_p = a,&lt;/math&gt;
*&lt;math&gt;\lambda_q \geq \mathrm{max}(a,b)&lt;/math&gt;
*&lt;math&gt;\lambda_i + \lambda_{p+q - i + 1} = a+b, \quad {i = 1, \dots, q}.&lt;/math&gt;
For example,
[[File:Schur functions rectangular example.png|center|400px]].

==Examples==

The examples of Littlewood-Richardson coefficients below are given in terms of products of Schur polynomials ''S''&lt;sub&gt;&amp;pi;&lt;/sub&gt;, indexed by partitions &amp;pi;, using the formula 
:&lt;math&gt;S_\lambda S_\mu =\sum c_{\lambda\mu}^\nu S_\nu.&lt;/math&gt;

All coefficients with &amp;nu; at most 4 are given by:
*''S''&lt;sub&gt;0&lt;/sub&gt;''S''&lt;sub&gt;&amp;pi;&lt;/sub&gt; = ''S''&lt;sub&gt;&amp;pi;&lt;/sub&gt; for any &amp;pi;. where ''S''&lt;sub&gt;0&lt;/sub&gt;=1 is the Schur polynomial of the empty partition
*''S''&lt;sub&gt;1&lt;/sub&gt;''S''&lt;sub&gt;1&lt;/sub&gt; = ''S''&lt;sub&gt;2&lt;/sub&gt; + ''S''&lt;sub&gt;11&lt;/sub&gt;
*''S''&lt;sub&gt;2&lt;/sub&gt;''S''&lt;sub&gt;1&lt;/sub&gt; = ''S''&lt;sub&gt;3&lt;/sub&gt; + ''S''&lt;sub&gt;21&lt;/sub&gt;
*''S''&lt;sub&gt;11&lt;/sub&gt;''S''&lt;sub&gt;1&lt;/sub&gt; = ''S''&lt;sub&gt;111&lt;/sub&gt; + ''S''&lt;sub&gt;21&lt;/sub&gt;
*''S''&lt;sub&gt;3&lt;/sub&gt;''S''&lt;sub&gt;1&lt;/sub&gt; = ''S''&lt;sub&gt;4&lt;/sub&gt; + ''S''&lt;sub&gt;31&lt;/sub&gt;
*''S''&lt;sub&gt;21&lt;/sub&gt;''S''&lt;sub&gt;1&lt;/sub&gt; = ''S''&lt;sub&gt;31&lt;/sub&gt; + ''S''&lt;sub&gt;22&lt;/sub&gt; + ''S''&lt;sub&gt;211&lt;/sub&gt;
*''S''&lt;sub&gt;2&lt;/sub&gt;''S''&lt;sub&gt;2&lt;/sub&gt; = ''S''&lt;sub&gt;4&lt;/sub&gt; + ''S''&lt;sub&gt;31&lt;/sub&gt; + ''S''&lt;sub&gt;22&lt;/sub&gt;
*''S''&lt;sub&gt;2&lt;/sub&gt;''S''&lt;sub&gt;11&lt;/sub&gt; = ''S''&lt;sub&gt;31&lt;/sub&gt; + ''S''&lt;sub&gt;211&lt;/sub&gt;
*''S''&lt;sub&gt;111&lt;/sub&gt;''S''&lt;sub&gt;1&lt;/sub&gt; = ''S''&lt;sub&gt;1111&lt;/sub&gt; + ''S''&lt;sub&gt;211&lt;/sub&gt;
*''S''&lt;sub&gt;11&lt;/sub&gt;''S''&lt;sub&gt;11&lt;/sub&gt; = ''S''&lt;sub&gt;1111&lt;/sub&gt; + ''S''&lt;sub&gt;211&lt;/sub&gt; + ''S''&lt;sub&gt;22&lt;/sub&gt;

Most of the coefficients for small partitions are 0 or 1, which happens in particular whenever one of the factors is of the form ''S&lt;sub&gt;n&lt;/sub&gt;'' or ''S''&lt;sub&gt;11...1&lt;/sub&gt;, because of [[Pieri's formula]] and its transposed counterpart. The simplest example with a coefficient larger than 1 happens when neither of the factors has this form:
*''S''&lt;sub&gt;21&lt;/sub&gt;''S''&lt;sub&gt;21&lt;/sub&gt; = ''S''&lt;sub&gt;42&lt;/sub&gt; + ''S''&lt;sub&gt;411&lt;/sub&gt; + ''S''&lt;sub&gt;33&lt;/sub&gt; + 2''S''&lt;sub&gt;321&lt;/sub&gt; + ''S''&lt;sub&gt;3111&lt;/sub&gt; + ''S''&lt;sub&gt;222&lt;/sub&gt; + ''S''&lt;sub&gt;2211&lt;/sub&gt;.
For larger partitions the coefficients become more complicated. For example,
*''S''&lt;sub&gt;321&lt;/sub&gt;''S''&lt;sub&gt;321&lt;/sub&gt; = ''S''&lt;sub&gt;642&lt;/sub&gt; +''S''&lt;sub&gt;6411&lt;/sub&gt; +''S''&lt;sub&gt;633&lt;/sub&gt; +2''S''&lt;sub&gt;6321&lt;/sub&gt; +''S''&lt;sub&gt;63111&lt;/sub&gt; +''S''&lt;sub&gt;6222&lt;/sub&gt; +''S''&lt;sub&gt;62211&lt;/sub&gt; +''S''&lt;sub&gt;552&lt;/sub&gt; +''S''&lt;sub&gt;5511&lt;/sub&gt; +2''S''&lt;sub&gt;543&lt;/sub&gt; +4''S''&lt;sub&gt;5421&lt;/sub&gt; +2''S''&lt;sub&gt;54111&lt;/sub&gt;  +3''S''&lt;sub&gt;5331&lt;/sub&gt; +3''S''&lt;sub&gt;5322&lt;/sub&gt; +4''S''&lt;sub&gt;53211&lt;/sub&gt; +''S''&lt;sub&gt;531111&lt;/sub&gt; +2''S''&lt;sub&gt;52221&lt;/sub&gt; +''S''&lt;sub&gt;522111&lt;/sub&gt; +''S''&lt;sub&gt;444&lt;/sub&gt; +3''S''&lt;sub&gt;4431&lt;/sub&gt; +2''S''&lt;sub&gt;4422&lt;/sub&gt; +3''S''&lt;sub&gt;44211&lt;/sub&gt; +''S''&lt;sub&gt;441111&lt;/sub&gt; +3''S''&lt;sub&gt;4332&lt;/sub&gt; +3''S''&lt;sub&gt;43311&lt;/sub&gt; +4''S''&lt;sub&gt;43221&lt;/sub&gt; +2''S''&lt;sub&gt;432111&lt;/sub&gt; +''S''&lt;sub&gt;42222&lt;/sub&gt; +''S''&lt;sub&gt;422211&lt;/sub&gt; +''S''&lt;sub&gt;3333&lt;/sub&gt; +2''S''&lt;sub&gt;33321&lt;/sub&gt; +''S''&lt;sub&gt;333111&lt;/sub&gt; +''S''&lt;sub&gt;33222&lt;/sub&gt; +''S''&lt;sub&gt;332211&lt;/sub&gt; with 34  terms and total multiplicity 62, and the largest coefficient is 4
*''S''&lt;sub&gt;4321&lt;/sub&gt;''S''&lt;sub&gt;4321&lt;/sub&gt; is a sum of 206  terms with total multiplicity is 930, and the largest coefficient is 18.
*''S''&lt;sub&gt;54321&lt;/sub&gt;''S''&lt;sub&gt;54321&lt;/sub&gt; is a sum of 1433  terms with total multiplicity  26704, and the largest coefficient (that of ''S''&lt;sub&gt;86543211&lt;/sub&gt;) is 176.
*''S''&lt;sub&gt;654321&lt;/sub&gt;''S''&lt;sub&gt;654321&lt;/sub&gt; is a sum of 10873 terms with total multiplicity is 1458444 (so the average value of the coefficients is more than 100, and they can be as large as 2064).

The original example given by {{harvtxt|Littlewood|Richardson|1934|loc=p. 122-124}} was (after correcting for 3 tableaux they found but forgot to include in the final sum) 
*''S''&lt;sub&gt;431&lt;/sub&gt;''S''&lt;sub&gt;221&lt;/sub&gt; =  ''S''&lt;sub&gt;652&lt;/sub&gt; + ''S''&lt;sub&gt;6511&lt;/sub&gt;  + ''S''&lt;sub&gt;643&lt;/sub&gt; + 2''S''&lt;sub&gt;6421&lt;/sub&gt; + ''S''&lt;sub&gt;64111&lt;/sub&gt; + ''S''&lt;sub&gt;6331&lt;/sub&gt; + ''S''&lt;sub&gt;6322&lt;/sub&gt; + ''S''&lt;sub&gt;63211&lt;/sub&gt; + ''S''&lt;sub&gt;553&lt;/sub&gt; + 2''S''&lt;sub&gt;5521&lt;/sub&gt; + ''S''&lt;sub&gt;55111&lt;/sub&gt; + 2''S''&lt;sub&gt;5431&lt;/sub&gt; + 2''S''&lt;sub&gt;5422&lt;/sub&gt; + 3''S''&lt;sub&gt;54211&lt;/sub&gt;  + ''S''&lt;sub&gt;541111&lt;/sub&gt; + ''S''&lt;sub&gt;5332&lt;/sub&gt; + ''S''&lt;sub&gt;53311&lt;/sub&gt; + 2''S''&lt;sub&gt;53221&lt;/sub&gt; + ''S''&lt;sub&gt;532111&lt;/sub&gt; + ''S''&lt;sub&gt;4432&lt;/sub&gt; + ''S''&lt;sub&gt;44311&lt;/sub&gt; + 2''S''&lt;sub&gt;44221&lt;/sub&gt; + ''S''&lt;sub&gt;442111&lt;/sub&gt; + ''S''&lt;sub&gt;43321&lt;/sub&gt; + ''S''&lt;sub&gt;43222&lt;/sub&gt; + ''S''&lt;sub&gt;432211&lt;/sub&gt;
with 26 terms coming from the following 34 tableaux:

&lt;pre&gt;
....11 ....11 ....11 ....11 ....11 ....11 ....11 ....11 ....11    
...22  ...22  ...2   ...2   ...2   ...2   ...    ...    ...
.3     .      .23    .2     .3     .      .22    .2     .2     
       3             3      2      2      3      23     2      
                                   3                    3

....1  ....1  ....1  ....1  ....1  ....1  ....1  ....1  ....1   
...12  ...12  ...12  ...12  ...1   ...1   ...1   ...2   ...1
.23    .2     .3     .      .23    .22    .2     .1     .2      
       3      2      2      2      3      23     23     2
                     3                                  3

....1  ....1  ....1  ....1  ....1  ....1  ....1  ....1   
...2   ...2   ...2   ...    ...    ...    ...    ...    
.1     .3     .      .12    .12    .1     .2     .2      
2      1      1      23     2      22     13     1
3      2      2             3      3      2      2
              3                                  3

....   ....   ....   ....   ....   ....   ....   ....   
...1   ...1   ...1   ...1   ...1   ...    ...    ...    
.12    .12    .1     .2     .2     .11    .1     .1      
23     2      22     13     1      22     12     12
       3      3      2      2      3      23     2
                            3                    3
&lt;/pre&gt;

Calculating skew Schur functions is similar. 
For example, the 15 Littlewood–Richardson tableaux for ν=5432 and λ=331 are 
&lt;pre&gt;
...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11 ...11
...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2  ...2
.11   .11   .11   .12   .11   .12   .13   .13   .23   .13   .13   .12   .12   .23   .23
12    13    22    12    23    13    12    24    14    14    22    23    33    13    34
&lt;/pre&gt;
so ''S''&lt;sub&gt;5432/331&lt;/sub&gt; = &amp;Sigma;''c''{{sup sub|ν|λμ}}&amp;nbsp;&amp;nbsp;''S''&lt;sub&gt;μ&lt;/sub&gt; = ''S''&lt;sub&gt;52&lt;/sub&gt; + ''S''&lt;sub&gt;511&lt;/sub&gt; + ''S''&lt;sub&gt;4111&lt;/sub&gt; + ''S''&lt;sub&gt;2221&lt;/sub&gt; + 2''S''&lt;sub&gt;43&lt;/sub&gt; + 2''S''&lt;sub&gt;3211&lt;/sub&gt; + 2''S''&lt;sub&gt;322&lt;/sub&gt; + 2''S''&lt;sub&gt;331&lt;/sub&gt; + 3''S''&lt;sub&gt;421&lt;/sub&gt; {{harv|Fulton|1997|p=64}}.

== References ==
*{{Citation | last1=Fulton | first1=William | author1-link=William Fulton (mathematician) | title=Young tableaux | publisher=[[Cambridge University Press]] | series=London Mathematical Society Student Texts | isbn=978-0-521-56144-0|mr=1464693 | year=1997 | volume=35 | page=121}}
*{{Citation | last1=Gasharov | first1=Vesselin | title=A short proof of the Littlewood-Richardson rule | doi=10.1006/eujc.1998.0212     |mr=1630540 | year=1998 | journal=European Journal of Combinatorics | issn=0195-6698 | volume=19 | issue=4 | pages=451–453 | url=http://www.math.cornell.edu/~vesko/papers/lrrule.ps }}
*{{Citation | last1=James | first1=Gordon | title=The Arcata Conference on Representations of Finite Groups (Arcata, Calif., 1986) | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=Proc. Sympos. Pure Math. |mr=933355 | year=1987 | volume=47 | chapter=The representation theory of the symmetric groups | pages=111–126}}
*{{Citation | last1=Knuth | first1=Donald E. | author1-link=Donald Knuth | title=Permutations, matrices, and generalized Young tableaux | url=http://projecteuclid.org/euclid.pjm/1102971948 |mr=0272654 | year=1970 | journal=[[Pacific Journal of Mathematics]] | issn=0030-8730 | volume=34 | pages=709–727 | doi=10.2140/pjm.1970.34.709}}
*{{citation|last=Littelmann|first=Peter|title=A Littlewood-Richardson rule for symmetrizable Kac-Moody algebras|journal= Invent. Math.|volume= 116|year=1994|pages=329–346|doi=10.1007/BF01231564 |url=http://www.mi.uni-koeln.de/~littelma/papers/Inventmath.pdf}}
*{{Citation | last1=Littlewood | first1=Dudley E. | title=The theory of group characters and matrix representations of groups | url=http://www.ams.org/bookstore?fn=20&amp;arg1=alggeom&amp;item=CHEL-357-H | publisher=AMS Chelsea Publishing, Providence, RI | isbn=978-0-8218-4067-2 |mr=0002127 | year=1950}}
*{{Citation | last1=Littlewood | first1=D. E. | last2=Richardson | first2=A. R. | title=Group Characters and Algebra | jstor=91293 | publisher=The Royal Society | year=1934 | journal=Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character | issn=0264-3952 | volume=233 | pages=99–141 | doi=10.1098/rsta.1934.0015 | issue=721–730}}
*{{Citation|last1=Macdonald |first1=I. G. |author1-link=Ian G. Macdonald |title=Symmetric functions and Hall polynomials |url=http://www.oup.com/uk/catalogue/?ci=9780198504504 |archive-url=https://archive.is/20121211053838/http://www.oup.com/uk/catalogue/?ci=9780198504504 |dead-url=yes |archive-date=2012-12-11 |publisher=The Clarendon Press Oxford University Press |edition=2nd |series=Oxford Mathematical Monographs |isbn=978-0-19-853489-1 |mr=1354144 |year=1995 }}
*{{Citation | last1=Okada | first1=Soichi | title=Applications of minor summation formulas to rectangular-shaped representations of classical groups | doi=10.1006/jabr.1997.7408 |mr=1632816 | year=1998 | journal=[[Journal of Algebra]] | issn=0021-8693 | volume=205 | issue=2 | pages=337–367 }}
*{{Citation | last1=Robinson | first1=G. de B. | title=On the Representations of the Symmetric Group | publisher=The Johns Hopkins University Press | year=1938 | journal=[[American Journal of Mathematics]] | issn=0002-9327 | volume=60 | issue=3 | pages=745–760 | doi=10.2307/2371609 | jstor=2371609}} [[Zentralblatt MATH|Zbl]][http://www.zentralblatt-math.org/zmath/en/search/?q=an:0019.25102 0019.25102]
*{{Citation | last1=Schensted | first1=C. | title=Longest increasing and decreasing subsequences |mr=0121305 | year=1961 | journal=Canadian Journal of Mathematics | issn=0008-414X | volume=13 | pages=179–191|url=https://books.google.com/books?id=G3sZ2zG8AiMC | doi=10.4153/CJM-1961-015-3}}
*{{Citation | last1=Schützenberger | first1=M. P. | title=Quelques remarques sur une construction de Schensted | url=http://gdz.sub.uni-goettingen.de/no_cache/dms/load/img/?IDDOC=221996 | mr=0190017 | year=1963 | journal=Mathematica Scandinavica | issn=0025-5521 | volume=12 | pages=117–128 | doi=10.7146/math.scand.a-10676 }}{{Dead link|date=November 2018 |bot=InternetArchiveBot |fix-attempted=yes }}
*{{Citation | last1=Schützenberger | first1=Marcel-Paul | title=Combinatoire et représentation du groupe symétrique (Actes Table Ronde CNRS, Univ. Louis-Pasteur Strasbourg, Strasbourg, 1976) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | doi=10.1007/BFb0090012 |mr=0498826 | year=1977 | volume=579 | chapter=La correspondance de Robinson | pages=59–113 | isbn=978-3-540-08143-2 | url=http://www-igm.univ-mlv.fr/~berstel/Mps/Travaux/A/1977-4CorrespRobinsonStrasbourg.pdf}}
*{{Citation | last1=Stembridge | first1=John R. | title=A concise proof of the Littlewood-Richardson rule | url=http://www.emis.de/journals/EJC/Volume_9/PDF/v9i1n5.pdf |mr=1912814 | year=2002 | journal=Electronic Journal of Combinatorics | issn=1077-8926 | volume=9 | issue=1 | pages=Note 5, 4 pp. (electronic)}}
*{{citation|last=Thomas|first= Glânffrwd P.
|title=Baxter algebras and Schur functions|series= Ph.D. Thesis|publisher= University College of Swansea|place= Swansea|year= 1974}}
*{{Citation | last1=van Leeuwen | first1=Marc A. A. | title=Interaction of combinatorics and representation theory | url=http://www-math.univ-poitiers.fr/~maavl/pdf/lrr.pdf | publisher=Math. Soc. Japan | location=Tokyo | series=MSJ Mem. |mr=1862150 | year=2001 | volume=11 | chapter=The Littlewood-Richardson rule, and related combinatorics | pages=95–145}}
*{{Citation | last1=Zelevinsky | first1=A. V. | title=A generalization of the Littlewood-Richardson rule and the Robinson-Schensted-Knuth correspondence | doi=10.1016/0021-8693(81)90128-9     |mr=613858 | year=1981 | journal=Journal of Algebra | issn=0021-8693 | volume=69 | issue=1 | pages=82–94}}

== External links ==
* [http://young.sp2mi.univ-poitiers.fr/cgi-bin/form-prep/marc/LiE_form.act?action=LRR An online program], decomposing products of Schur functions using the Littlewood–Richardson rule

{{DEFAULTSORT:Littlewood-Richardson rule}}
[[Category:Algebraic combinatorics]]
[[Category:Invariant theory]]
[[Category:Representation theory]]
[[Category:Symmetric functions]]</text>
      <sha1>at7bljc6ss34746brmlk617hu5lailf</sha1>
    </revision>
  </page>
  <page>
    <title>Loewner order</title>
    <ns>0</ns>
    <id>46706590</id>
    <revision>
      <id>721581847</id>
      <parentid>684844924</parentid>
      <timestamp>2016-05-22T20:29:47Z</timestamp>
      <contributor>
        <ip>2001:18E8:2:1093:F000:0:0:5CB</ip>
      </contributor>
      <comment>/* Properties */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2572">In mathematics, '''Loewner order''' is the [[Convex cone#Partial order defined by a convex cone|partial order defined by the convex cone]] of [[Positive definite matrix#Negative-definite, semidefinite and indefinite matrices|positive semi-definite matrices]]. This order is usually employed to generalize the definitions of monotone and concave/convex scalar functions to [[Matrix function#Classes of matrix functions|monotone and concave/convex Hermitian valued functions]]. These functions arise naturally in matrix and operator theory and have applications in many areas of physics and engineering.

== Definition ==
Let ''A'' and ''B'' be two [[Hermitian matrices]] of order ''n''. We say that ''A ≥ B'' if ''A''&amp;nbsp;&amp;minus;&amp;nbsp;''B'' is [[Positive definite matrix#Negative-definite, semidefinite and indefinite matrices|positive semi-definite]]. Similarly, we say that ''A &gt; B'' if ''A''&amp;nbsp;&amp;minus;&amp;nbsp;''B'' is [[positive definite]].

== Properties ==
When ''A'' and ''B'' are real scalars (i.e. ''n'' = 1), the Loewner order reduces to the usual ordering of '''R'''.  Although some familiar properties of the usual order of '''R''' are also valid when ''n'' ≥ 2, several properties are no longer valid. For instance, the [[total relation|comparability]] of two matrices may no longer be valid. In fact, if
&lt;math&gt;
A = 
\begin{bmatrix}
1 &amp; 0 \\
0 &amp; 0
\end{bmatrix}\ 
&lt;/math&gt; and &lt;math&gt;
B = 
\begin{bmatrix}
0 &amp; 0 \\
0 &amp; 1
\end{bmatrix}\ 
&lt;/math&gt; then neither ''A'' ≥ ''B'' or ''B'' ≥ ''A'' holds true.

Moreover, since ''A'' and ''B'' are Hermitian matrices, their [[eigenvalues]] are all real numbers.
If ''λ''&lt;sub&gt;1&lt;/sub&gt;(''B'') is the maximum eigenvalue of ''B'' and ''λ''&lt;sub&gt;''n''&lt;/sub&gt;(''A'') the minimum eigenvalue of ''A'', a sufficient criterion to have ''A'' ≥ ''B'' is that ''λ''&lt;sub&gt;''n''&lt;/sub&gt;(''A'') ≥ ''λ''&lt;sub&gt;1&lt;/sub&gt;(''B'').  If ''A'' or ''B'' is a multiple of the [[identity matrix]], then this criterion is also necessary.

== See also ==
* [[Trace inequalities]]

== References ==
* {{cite book|last1=Pukelsheim|first1=Friedrich|title=Optimal design of experiments|date=2006|publisher=Society for Industrial and Applied Mathematics|isbn=9780898716047|pages=11–12}}
* {{cite book|last1=Bhatia|first1=Rajendra|title=Matrix Analysis|date=1997|publisher=Springer|location=New York, NY|isbn=9781461206538}}
* {{cite book|last1=Zhan|first1=Xingzhi|title=Matrix inequalities|date=2002|publisher=Springer|location=Berlin|isbn=9783540437987|pages=1–15}}

&lt;!--- Categories ---&gt;
[[Category:Linear algebra]]
[[Category:Matrix theory]]</text>
      <sha1>bsa2kjoi945jh966k9fbf96svv6ssym</sha1>
    </revision>
  </page>
  <page>
    <title>Lubell–Yamamoto–Meshalkin inequality</title>
    <ns>0</ns>
    <id>748686</id>
    <revision>
      <id>634685421</id>
      <parentid>621102532</parentid>
      <timestamp>2014-11-20T12:48:48Z</timestamp>
      <contributor>
        <ip>50.65.99.31</ip>
      </contributor>
      <comment>/* Lubell's proof */ Clarify how permutations are meant here. (Not a selfbijective function, but the resulting order of the elements.)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3502">In [[combinatorics|combinatorial]] [[mathematics]], the '''Lubell–Yamamoto–Meshalkin inequality''', more commonly known as the '''LYM inequality''', is an inequality on the sizes of sets in a [[Sperner family]], proved by {{harvtxt|Bollobás|1965}}, {{harvtxt|Lubell|1966}}, {{harvtxt|Meshalkin|1963}}, and  {{harvtxt|Yamamoto|1954}}. It is named for the initials of three of its discoverers.

This inequality belongs to the field of [[combinatorics]] of sets, and has many applications in combinatorics. In particular, it can be used to prove [[Sperner's theorem]]. Its name is also used for similar inequalities.

==Statement of the theorem==
Let ''U'' be an ''n''-element set, let ''A'' be a family of subsets of ''U'' such that no set in ''A'' is a subset of another set in ''A'', and let ''a&lt;sub&gt;k&lt;/sub&gt;'' denote the number of sets of size ''k'' in ''A''. Then
: &lt;math&gt;\sum_{k=0}^n\frac{a_k}{{n \choose k}} \le 1.&lt;/math&gt;

==Lubell's proof==
{{harvtxt|Lubell|1966}} proves the Lubell–Yamamoto–Meshalkin inequality by a [[double counting (proof technique)|double counting argument]] in which he counts the [[permutation]]s of ''U'' in two different ways. First, by counting all permutations of ''U'' directly, one finds that there are ''n''! of them. But secondly, one can generate a permutation (i.e., an order) of the elements of ''U'' by selecting a set ''S'' in ''A'' and concatenating a permutation of the elements of ''S'' with a permutation of the nonmembers (elements of ''U\S''). If |''S''|&amp;nbsp;=&amp;nbsp;''k'', it will be associated in this way with ''k''!(''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k'')! permutations, and in each of them the first ''k'' elements will be just the elements of ''S''. Each permutation can only be associated with a single set in ''A'', for if two prefixes of a permutation both formed sets in ''A'' then one would be a subset of the other. Therefore, the number of permutations that can be generated by this procedure is
:&lt;math&gt;\sum_{S\in A}|S|!(n-|S|)!=\sum_{k=0}^n a_k k! (n-k)!.&lt;/math&gt;
Since this number is at most the total number of all permutations,
:&lt;math&gt;\sum_{k=0}^n a_k k! (n-k)!\le n!.&lt;/math&gt;
Finally dividing the above inequality by ''n''! leads to the result.

== References ==

*{{citation
 | first = B. | last = Bollobás | authorlink = Béla Bollobás
 | title = On generalized graphs
 | journal = Acta Mathematica Academiae Scientiarum Hungaricae
 | volume = 16 | issue = 3–4 | pages = 447–452 | year = 1965
 | doi = 10.1007/BF01904851 |mr=0183653 }}.

*{{citation
 | last = Lubell | first = D.
 | year = 1966
 | title = A short proof of Sperner's lemma
 | journal = Journal of Combinatorial Theory
 | volume = 1 | issue = 2 | pages = 299
 | doi = 10.1016/S0021-9800(66)80035-2 |mr=0194348 }}.

*{{citation
 | last = Meshalkin | first = L. D.
 | year = 1963
 | title = Generalization of Sperner's theorem on the number of subsets of a finite set
 | journal = Theory of Probability and its Applications
 | volume = 8 | issue = 2 | pages = 203–204
 | doi = 10.1137/1108023 |mr=0150049 }}.

*{{citation
 | last = Yamamoto | first = Koichi
 | year = 1954
 | title = Logarithmic order of free distributive lattice
 | journal = Journal of the Mathematical Society of Japan
 | volume = 6 | pages = 343–353
 |mr=0067086
 | doi=10.2969/jmsj/00630343}}.

{{DEFAULTSORT:Lubell-Yamamoto-Meshalkin inequality}}
[[Category:Combinatorics]]
[[Category:Inequalities]]
[[Category:Order theory]]
[[Category:Set families]]
[[Category:Articles containing proofs]]</text>
      <sha1>5t7r1b2x9csoojr54xuo93flru12uh9</sha1>
    </revision>
  </page>
  <page>
    <title>Luopan</title>
    <ns>0</ns>
    <id>11564906</id>
    <revision>
      <id>861626435</id>
      <parentid>855779700</parentid>
      <timestamp>2018-09-28T20:03:17Z</timestamp>
      <contributor>
        <username>A garbage person</username>
        <id>32251677</id>
      </contributor>
      <comment>Tagged all chinese language text; fixed references</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7589">{{redirect|Lupan}}
{{Chinese|pic=Luopan.jpg|piccap=Luopan|t=羅盤|s=罗盘|j=lo&lt;sup&gt;4&lt;/sup&gt; pun&lt;sup&gt;4*2&lt;/sup&gt;|p=luópăn|wuu=lu boe|poj=lô-pôaⁿ}}
The '''luopan''' or '''geomantic compass''' is a Chinese [[magnetism|magnetic]] compass, also known as a [[Feng Shui]] [[compass]]. It is used by a Feng Shui practitioner to determine the precise direction of a structure or other item. Since the invention of the compass for use in Feng Shui,{{sfn|Campbell|2001}} traditional feng shui has required its use.

==Form and function==
Like a conventional compass, a luopan is a direction finder. However, a luopan differs from a compass in several important ways. The most obvious difference is the Feng Shui formulas embedded in up to 40 concentric rings on the surface. This is a metal or wooden plate known as the ''heaven dial''. The circular metal or wooden plate typically sits on a wooden base known as the ''earth plate''. The heaven dial rotates freely on the earth plate.

A red wire or thread that crosses the earth plate and heaven dial at 90-degree angles is the ''Heaven Center Cross Line'', or ''Red Cross Grid Line''.{{sfn|Cheng|Fernandes-Gonçalves|1998|page=25}} This line is used to find the direction and note position on the rings. 

A conventional compass has markings for four or eight directions, while a luopan typically contains markings for [[Earthly Branches#Directions|24 directions]]. This translates to 15 degrees per direction. The Sun takes approximately 15.2 days to traverse a [[solar term]], a series of 24 points on the [[ecliptic]]. Since there are 360 degrees on the luopan and approximately 365.25 days in a mean solar year, each degree on a luopan approximates a terrestrial day.

Unlike a typical compass, a luopan does not point to the [[north magnetic pole]] of Earth. The needle of a luopan points to the [[south magnetic pole]] (it does not point to the geographic [[south pole]]). The Chinese word for ''compass'' translates to “south-pointing needle.”

==Types==
Since the [[Ming dynasty|Ming]] and [[Qing dynasty|Qing]] dynasties, three types of luopan have been popular. They have some formula rings in common, such as the 24 directions and the early and later heaven arrangements.

===San He===
This luopan was said to have been used in the [[Tang dynasty]].{{sfn|Cheng|Fernandes-Gonçalves|1998|page=21}} The San He contains three basic 24-direction rings. Each ring relates to a different method and formula. (The techniques grouped under the name "Three Harmonies" are San He methods.)

===San Yuan===
This luopan, also known as the ''jiang pan'' (after Jiang Da Hong) or the ''Yi Pan'' (because of the presence of [[I Ching|Yijing]] hexagrams){{sfn|Cheng|Fernandes-Gonçalves|1998|page=21}} incorporates many formulas used in San Yuan (Three Cycles).  It contains one 24-direction ring, known as the Earth Plate Correct Needle, the ring for the 64 [[Hexagram (I Ching)|hexagrams]], and others. (The techniques grouped under the name "Flying Stars" are an example of San Yuan methods.)

===Zong He===
This luopan combines rings from the San He and San Yuan. It contains three 24-direction-rings and the 64 trigrams ring.

===Other types===
Each Feng Shui master may design a luopan to suit preference and to offer students. Some designs incorporate the [[Bagua|bagua (trigram)]] numbers, directions from the Eight Mansions ({{zh|labels=no|c=八宅|p= bāzhái}}) methods, and English equivalents.

==History and development==
[[File:Chinese Geomantic Compass c. 1760, National Maritime Museum.JPG|thumb|right|Chinese geomantic compass c. 1760 from the [[National Maritime Museum]] in London]]
The luopan is an image of the cosmos (a world model) based on tortoise plastrons used in divination.{{sfn|Allan|1991}} At its most basic level it serves as a means to assign proper positions in time and space, like the Ming Tang (Hall of Light).{{sfn|Lewis|2006|pages=248, 251, 274}} The markings are similar to those on a [[liubo]] board.

The oldest precursors of the luopan are the {{zh|labels=no|c=式|p=shì}} or {{zh|labels=no|t=式盤|s=式盘|p=shìpán}}, meaning ''astrolabe'' or ''diviner's board''—also sometimes called  ''liuren'' astrolabes{{sfn|Kalinowski|Brooks|1998}}—unearthed from tombs that date between 278 [[BCE]] and 209 BCE. These astrolabes consist of a lacquered, two-sided board with [[Chinese astronomy|astronomical]] sightlines. Along with [[divination]] for [[Da Liu Ren]] the boards were commonly used to chart the motion of [[Taiyi (Chinese astronomy)|Taiyi]] through the nine palaces.{{sfn|Yin|1978}}{{sfn|Yan|1978}} The markings are virtually unchanged from the ''shi'' to the first magnetic compasses.{{sfn|Kalinowski|Brooks|1998}} The schematic of earth plate, heaven plate, and grid lines is part of the "two cords and four hooks" ({{zh|labels=no|c=二繩四鉤|p=èrshéngsìgōu}}) geometrical diagram in use since at least the [[Warring States]] period.{{sfn|Kalinowski|Brooks|1998}}
The ''zhinan zhen'' or south-pointing needle, is the original [[magnetic]] [[compass]], and was developed for Feng Shui.{{sfn|Campbell|2001}} It featured the two cords and four hooks diagram, direction markers, and a magnetized spoon in the center.

==See also==
* [[Chu Silk Manuscript]]

==References==
{{Reflist}}
==Bibliography==
*{{cite book |last1=Cheng |first1=Jian Jun |first2=Adriana |last2=Fernandes-Gonçalves |title=Chinese Feng Shui Compass: Step by Step Guide |isbn=9787539014302 |publisher=Jianxi Science and Technology Publishing House |location=Nanchang, Jianxi |date=1998 |ref=harv}}
*{{cite book |first1=Wallace H. |last1=Campbell. |title=Earth Magnetism: A Guided Tour Through Magnetic Fields |publisher=Academic Press |location=San Diego |date=2001 |isbn=9780121581640 |ref=harv}}
*{{cite journal |first1=Mark |last1=Kalinowski |first2=Phyllis |last2=Brooks |title=The Xingde {{zh|labels=no|c=刑德}} Texts from Mawangdui |journal=Early China |volume=23 |date=1998 |pages=125-202 |doi=10.1017/S0362502800000973 |ref=harv}}
*{{cite journal |last=Yin |first=Difei |title=Xi-Han Ruyinhou de zhanpan he tianwen yiqi |script-title=zh:西漢汝陰侯的占盤和天文儀器 |trans-title=Western Han Lord of Runyin's divining plate and astrological apparatus |journal=Kaogu |date=1978 |volume=5 |pages=338-343 |issn=0453-2899 |ref=harv}}
*{{cite journal |last=Yan |first=Dunjie |title=Guanyu Xi-Han chuqi de shipan he zhanpan |script-title=zh:關於西漢初期的式盤和占盤 |trans-title=Regarding Western Han's early shìpán and divining plates |journal=Kaogu |date=1978 |volume=5 |pages=334-37 |issn=0453-2899 |ref=harv}}
*{{cite book |first=Mark Edward |last=Lewis |date=2006 |title=The Construction of Space in Early China |publisher=State University of New York Press |location=Albany, NY |series=SUNY series in Chinese philosophy and culture |ref=harv}}
*{{cite book |last=Allan |first=Sarah |authorlink=Sarah Allan |date=1991 |title=The Shape of the Turtle: Myth, Art, and Cosmos in Early China |chapter=The shape of the cosmos |publisher=State University of New York Press |location=Albany, NY |series=SUNY series in Chinese philosophy and culture |ref=harv}}

==Further reading==
* {{cite book |last=Skinner |first=Stephen |title=Guide to the Feng Shui Compass: a Compendium of Classical Feng Shui |location=Singapore |publisher=Golden Hoard Press |date=2008 |isbn=9780954763992}}
**An account of the various types of luo pan, and details of 75 separate rings. 

[[Category:Orientation (geometry)]]
[[Category:Chinese inventions]]
[[Category:Magnetic devices]]
[[Category:Geomancy]]</text>
      <sha1>hnc1h7gzrepyqrt29pwkfbihyw1v6do</sha1>
    </revision>
  </page>
  <page>
    <title>MacMahon Master theorem</title>
    <ns>0</ns>
    <id>25567675</id>
    <revision>
      <id>856858983</id>
      <parentid>837320067</parentid>
      <timestamp>2018-08-28T00:07:52Z</timestamp>
      <contributor>
        <username>Saung Tadashi</username>
        <id>16809467</id>
      </contributor>
      <minor/>
      <comment>/* Precise statement */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8246">In mathematics, the '''MacMahon Master theorem''' ('''MMT''') is a result in [[enumerative combinatorics]] and [[linear algebra]].  It was discovered by [[Percy Alexander MacMahon|Percy MacMahon]] and proved in his monograph ''Combinatory analysis'' (1916).  It is often used to derive binomial identities, most notably [[Dixon's identity]].

== Background ==
In the monograph, MacMahon found so many applications of his result, he called it "a master theorem in the Theory of Permutations."  He explained the title as follows: "a Master Theorem from the masterly and rapid fashion in which it deals with various questions otherwise troublesome to solve."

The result was re-derived (with attribution) a number of times, most notably by  [[I. J. Good]] who derived it from his multilinear generalization of the [[Lagrange inversion theorem]].  MMT was also popularized by [[Leonard Carlitz|Carlitz]] who found an [[Exponential generating function#Exponential generating function|exponential]] [[power series]]  version.  In 1962, Good found a short proof of Dixon's identity from MMT.  In 1969, [[Pierre Cartier (mathematician)|Cartier]] and [[Dominique Foata|Foata]] found a new proof of MMT by combining [[algebra]]ic and [[bijective proof|bijective]] ideas (built on Foata's thesis) and further applications to [[combinatorics on words]], introducing the concept of [[trace monoid|trace]]s.  Since then, MMT has become a standard tool in enumerative combinatorics.

Although various ''q''-Dixon identities have been known for decades, except for a Krattenthaler–Schlosser extension (1999), the proper [[q-analog]] of MMT remained elusive.  After Garoufalidis–Lê–Zeilberger's [[Quantum algebra|quantum]] extension (2006), a number of [[Noncommutative geometry|noncommutative]] extensions were developed by Foata–Han, Konvalinka–Pak, and Etingof–Pak.  Further connections to [[Koszul algebra]] and [[quasideterminant]]s were also found by Hai–Lorentz, Hai–Kriegk–Lorenz, Konvalinka–Pak, and others.

Finally, according to J. D. Louck, [[theoretical physicist]] [[Julian Schwinger]] re-discovered the MMT in the context of his [[generating function]] approach to the [[angular momentum]] theory of [[many-particle system]]s.  Louck writes:

{{quote|It is the MacMahon Master Theorem that unifies the angular momentum properties of composite systems in the binary build-up of such systems from more elementary constituents.&lt;ref&gt;{{cite book|last1=Louck|first1=James D.|title=Unitary symmetry and combinatorics|date=2008|publisher=World Scientific|location=Singapore|isbn=978-981-281-472-2|pages=viii}}&lt;/ref&gt;}}

== Precise statement ==
Let &lt;math&gt;A = (a_{ij})_{m\times m}&lt;/math&gt; be a complex matrix, and let &lt;math&gt;x_1,\ldots,x_m&lt;/math&gt; be formal variables.  Consider a [[coefficient]]
:&lt;math&gt;
G(k_1,\dots,k_m) \, = \, \bigl[x_1^{k_1}\cdots x_m^{k_m}\bigr] \,
\prod_{i=1}^m \bigl(a_{i1}x_1 + \dots + a_{im}x_m \bigl)^{k_i}.
&lt;/math&gt;
(Here the notation &lt;math&gt;[f]g&lt;/math&gt; means "the coefficient of monomial &lt;math&gt;f&lt;/math&gt; in &lt;math&gt;g&lt;/math&gt;".)  Let &lt;math&gt;t_1,\ldots,t_m&lt;/math&gt; be another set of formal variables, and let &lt;math&gt;T = (\delta_{ij}t_i)_{m\times m}&lt;/math&gt; be a [[diagonal matrix]].  Then
:&lt;math&gt;
\sum_{(k_1,\dots,k_m)} G(k_1,\dots,k_m) \, t_1^{k_1}\cdots t_m^{k_m} \, = \,
\frac{1}{\det (I_m - TA)},
&lt;/math&gt;
where the sum runs over all nonnegative integer vectors &lt;math&gt;(k_1,\dots,k_m)&lt;/math&gt;,
and &lt;math&gt;I_m&lt;/math&gt; denotes the [[identity matrix]] of size &lt;math&gt;m&lt;/math&gt;.

== Derivation of Dixon's identity ==
Consider a matrix
:&lt;math&gt;
A = \begin{pmatrix}
0 &amp; 1 &amp; -1 \\
-1 &amp; 0 &amp; 1 \\
1 &amp; -1 &amp; 0
\end{pmatrix}.
&lt;/math&gt;
Compute the coefficients ''G''(2''n'',&amp;nbsp;2''n'',&amp;nbsp;2''n'') directly from the definition:

:&lt;math&gt;
\begin{align}
G(2n,2n,2n) &amp; = \bigl[x_1^{2n}x_2^{2n}x_3^{2n}\bigl] (x_2 - x_3)^{2n} (x_3 - x_1)^{2n} (x_1 - x_2)^{2n} \\[6pt]
&amp; = \, \sum_{k=0}^{2n} (-1)^k \binom{2n}{k}^3,
\end{align}
&lt;/math&gt;

where the last equality follows from the fact that on the right-hand side we have the product of the following coefficients:
:&lt;math&gt;[x_2^k x_3^{2n-k}](x_2 - x_3)^{2n}, \ \  [x_3^k x_1^{2n-k}](x_3 - x_1)^{2n}, \ \  [x_1^k x_2^{2n-k}](x_1 - x_2)^{2n},&lt;/math&gt;
which are computed from the [[binomial theorem]]. On the other hand, we can compute the [[determinant]] explicitly:
:&lt;math&gt;
\det(I - TA) \, = \, \det \begin{pmatrix}
1 &amp; -t_1 &amp; t_1 \\
t_2 &amp; 1 &amp; -t_2 \\
-t_3 &amp; t_3 &amp; 1
\end{pmatrix}  \, = \, 1 + \bigl(t_1 t_2 + t_1 t_3 +t_2t_3\bigr).
&lt;/math&gt;
Therefore, by the MMT, we have a new formula for the same coefficients:

: &lt;math&gt;
\begin{align}
G(2n,2n,2n) &amp; = \bigl[t_1^{2n}t_2^{2n}t_3^{2n}\bigl] (-1)^{3n} \bigl(t_1 t_2 + t_1 t_3 +t_2t_3\bigr)^{3n} \\[6pt]
&amp; = (-1)^{n} \binom{3n}{n,n,n},
\end{align}
&lt;/math&gt;

where the last equality follows from the fact that we need to use an equal number of times all three terms in the power.  Now equating the two formulas for coefficients ''G''(2''n'',&amp;nbsp;2''n'',&amp;nbsp;2''n'') we obtain an equivalent version of Dixon's identity:

:&lt;math&gt; \sum_{k=0}^{2n} (-1)^k \binom{2n}{k}^3 = (-1)^{n} \binom{3n}{n,n,n}.
&lt;/math&gt;

==See also==
*[[Permanent (mathematics)|Permanent]]

== References ==
{{Reflist}}
* P.A. MacMahon, ''[http://www.hti.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=ABU9009 Combinatory analysis]'', vols 1 and 2, Cambridge University Press, 1915–16.
* {{cite journal | zbl=0108.25104  | authorlink=I. J. Good | first=I.J. | last=Good | title=A short proof of MacMahon's ‘Master Theorem’ | journal=[[Proc. Cambridge Philos. Soc.]] | volume=58 | year=1962 | page=160 }}
* {{cite journal | zbl=0108.25105  | authorlink=I. J. Good | first=I.J. | last=Good | title=Proofs of some `binomial' identities by means of MacMahon's ‘Master Theorem’ | journal=[[Proc. Cambridge Philos. Soc.]] | volume=58 | year=1962 | pages=161–162 }}
* [[Pierre Cartier (mathematician)|P. Cartier]] and D. Foata, [http://www.mat.univie.ac.at/~slc/books/cartfoa.html Problèmes combinatoires de commutation et réarrangements], ''Lecture Notes in Mathematics'', no. 85, Springer, Berlin, 1969.
* [[Leonard Carlitz|L. Carlitz]], An Application of MacMahon's Master Theorem, ''SIAM Journal on Applied Mathematics'' 26 (1974), 431–436.
* I.P. Goulden and [[David M. Jackson|D. M. Jackson]], ''Combinatorial Enumeration'', John Wiley, New York, 1983.
* C. Krattenthaler and M. Schlosser, [http://radon.mat.univie.ac.at/users/kratt/public_html/artikel/minv.ps.gz A new multidimensional matrix inverse with applications to multiple ''q''-series], ''Discrete Math.'' 204 (1999), 249–279.
* S. Garoufalidis, T. T. Q. Lê and [[Doron Zeilberger|D. Zeilberger]], [http://www.pnas.org/content/103/38/13928.full The Quantum MacMahon Master Theorem], ''Proc. Natl. Acad. of Sci.'' 103  (2006),  no. 38, 13928–13931 ([https://arxiv.org/abs/math/0303319 eprint]).
* M. Konvalinka and [[Igor Pak|I. Pak]], Non-commutative extensions of the MacMahon Master Theorem, ''Adv. Math.'' 216 (2007), no. 1. ([https://arxiv.org/abs/math/0607737 eprint]).
* D. Foata and G.-N. Han, A new proof of the Garoufalidis-Lê-Zeilberger Quantum MacMahon Master Theorem,  ''J. Algebra''  307  (2007),  no. 1, 424–431 ([https://arxiv.org/abs/math/0603464 eprint]).
* D. Foata and G.-N. Han, Specializations and extensions of the quantum MacMahon Master Theorem, ''Linear Algebra Appl'' 423  (2007),  no. 2–3, 445–455 ([https://arxiv.org/abs/math.CO/0603466 eprint]).
* P.H. Hai and M. Lorenz, Koszul algebras and the quantum MacMahon master theorem,  ''Bull. Lond. Math. Soc.''  39  (2007),  no. 4, 667–676. ([https://arxiv.org/abs/math/0603169 eprint]).
* P. Etingof and I. Pak, An algebraic extension of the MacMahon master theorem,  ''Proc. Amer. Math. Soc.''  136  (2008),  no. 7, 2279–2288 ([https://arxiv.org/abs/math/0608005  eprint]).
* P.H. Hai, B. Kriegk and M. Lorenz, ''N''-homogeneous superalgebras, ''J. Noncommut. Geom.'' 2 (2008) 1–51 ([https://arxiv.org/abs/0704.1888 eprint]).
* J.D. Louck, ''Unitary symmetry and combinatorics'', World Sci., Hackensack, NJ, 2008.

[[Category:Enumerative combinatorics]]
[[Category:Factorial and binomial topics]]
[[Category:Articles containing proofs]]
[[Category:Theorems in combinatorics]]
[[Category:Theorems in linear algebra]]</text>
      <sha1>n153ssvy9nzom02webrsm077p6ouxwv</sha1>
    </revision>
  </page>
  <page>
    <title>Mario Szegedy</title>
    <ns>0</ns>
    <id>4291061</id>
    <revision>
      <id>870340260</id>
      <parentid>837381924</parentid>
      <timestamp>2018-11-24T03:44:46Z</timestamp>
      <contributor>
        <username>Alaney2k</username>
        <id>209266</id>
      </contributor>
      <minor/>
      <comment>/* top */US =&gt; Americans; reduce overlinking</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2281">{{use mdy dates|date=June 2014}}
{{Infobox scientist
| name                    = Mario Szegedy
| image = Mario_Szegedy_at_Rutgers_2008.jpg
| caption                 =
| birth_date              = {{b-da|October 23, 1960}}
| birth_place             =
| death_date              = 
| death_place             = 
| residence               = [[United States|U.S.]] 
| nationality             = [[Hungary|Hungarian]]-[[Americans|American]]
| field                   = [[Computer Science]]
| work_institution        = [[Rutgers University]]
| alma_mater              = [[University of Chicago]]
| doctoral_advisor        = [[László Babai]], Janos  Simon
| awards                  = [[Gödel Prize]] (2001, 2005)
}}

'''Mario Szegedy''' (born  October 23, 1960) is a Hungarian-American [[computer scientist]], [[professor]] of [[computer science]] at [[Rutgers University]]. He received his [[Ph.D.]] in computer science in 1989 from the [[University of Chicago]].&lt;ref&gt;{{MathGenealogy|id=98045}}&lt;/ref&gt; He held a [[Lady Davis Fellowship|Lady Davis Postdoctoral Fellowship]] at the Hebrew University, Jerusalem (1989–90), a postdoc at the University of Chicago, 1991–92, and a postdoc at Bell Laboratories (1992).

Szegedy's research areas include [[computational complexity theory]] and [[quantum computing]].

He was awarded the [[Gödel Prize]] twice, in 2001 and 2005, for his work on [[probabilistically checkable proof]]s and on the space complexity of approximating the frequency moments in streamed data.&lt;ref&gt;[http://www.sigact.org/Prizes/Godel/ Gödel Prize website with list of winners]  {{webarchive|url=https://wayback.archive-it.org/all/20161007181643/http://www.sigact.org/Prizes/Godel/ |date=October 7, 2016 }}&lt;/ref&gt;

==References==
&lt;references/&gt;

==External links==
* [http://www.cs.rutgers.edu/~szegedy/ Home page]

{{Gödel winners}}
{{Authority control}}

{{DEFAULTSORT:Szegedy, Mario}}
[[Category:American academics]]
[[Category:1960 births]]
[[Category:Living people]]
[[Category:Hungarian emigrants to the United States]]
[[Category:Hungarian computer scientists]]
[[Category:Hungarian mathematicians]]
[[Category:Gödel Prize laureates]]
[[Category:Rutgers University faculty]]
[[Category:University of Chicago alumni]]
[[Category:Theoretical computer scientists]]</text>
      <sha1>eohftldx14exth1vcgpl26npmokav7m</sha1>
    </revision>
  </page>
  <page>
    <title>McMullen problem</title>
    <ns>0</ns>
    <id>35695532</id>
    <revision>
      <id>819712576</id>
      <parentid>819712545</parentid>
      <timestamp>2018-01-10T21:50:49Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <minor/>
      <comment>ce/* Results */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4578">{{unsolved|mathematics|For how many points is it always possible to projectively transform the points into convex position?}}
The '''McMullen problem''' is an open problem in [[discrete geometry]] named after [[Peter McMullen]].

==Statement==
In 1972, McMullen has proposed the following problem:&lt;ref name="L"&gt;D. G. Larman (1972), "On Sets Projectively Equivalent to the Vertices of a Convex Polytope", ''[[Bulletin of the London Mathematical Society]]'' '''4''', pp.6&amp;ndash;12&lt;/ref&gt;
: Determine the largest number &lt;math&gt;\nu(d)&lt;/math&gt; such that for any given &lt;math&gt;\nu(d)&lt;/math&gt; points in [[general position]] in affine ''d''-space '''[[real number|R]]'''&lt;sup&gt;''d''&lt;/sup&gt; there is a [[projective transformation]] mapping these points into [[convex position]] (so they form the vertices of a [[convex polytope]]).

==Equivalent formulations==

===Gale transform===
Using the [[Gale transform]], this problem can be reformulated as:
: Determine the smallest number &lt;math&gt;\mu(d)&lt;/math&gt; such that every set of &lt;math&gt;\mu(d)&lt;/math&gt; points ''X'' = {''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''&amp;mu;''(''d'')&lt;/sub&gt;} in linearly general position on '''S'''&lt;sup&gt;''d'' − 1&lt;/sup&gt; it is possible to choose a set ''Y'' = {''&amp;epsilon;''&lt;sub&gt;1&lt;/sub&gt;''x''&lt;sub&gt;1&lt;/sub&gt;, ''&amp;epsilon;''&lt;sub&gt;2&lt;/sub&gt;''x''&lt;sub&gt;2&lt;/sub&gt;, ..., ''&amp;epsilon;''&lt;sub&gt;''&amp;mu;''(''d'')&lt;/sub&gt;''x''&lt;sub&gt;''&amp;mu;''(''d'')&lt;/sub&gt;} where ''&amp;epsilon;''&lt;sub&gt;''i''&lt;/sub&gt; = &amp;plusmn;1 for ''i'' = 1, 2, ..., ''&amp;mu;''(''d''), such that every open hemisphere of '''S'''&lt;sup&gt;''d'' − 1&lt;/sup&gt; contains at least two members of Y.

The number &lt;math&gt;\mu(k)&lt;/math&gt;, &lt;math&gt;\nu(d)&lt;/math&gt; are connected by the relationships

: &lt;math&gt;\mu(k)=\min\{w \mid w\leq\nu(w-k-1)\} \, &lt;/math&gt;
: &lt;math&gt;\nu(d)=\max\{w \mid w\geq\mu(w-d-1)\} \, &lt;/math&gt;

===Partition into nearly-disjoint hulls===
Also, by simple geometric observation, it can be reformulated as:
: Determine the smallest number &lt;math&gt;\lambda(d)&lt;/math&gt; such that for every set ''X'' of &lt;math&gt;\lambda(d)&lt;/math&gt; points in '''[[real number|R]]'''&lt;sup&gt;''d''&lt;/sup&gt; there exists a [[Partition of a set|partition]] of ''X'' into two sets ''A'' and ''B'' with

:: &lt;math&gt;\operatorname{conv}(A\backslash \{x\})\cap \operatorname{conv}(B\backslash \{x\})\not=\varnothing,\forall x\in X. \, &lt;/math&gt;

The relation between &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\lambda&lt;/math&gt; is

: &lt;math&gt;\mu(d+1)=\lambda(d),\qquad  d\geq1 \, &lt;/math&gt;

===Projective duality===
[[File:Pentagon dual arrangement.svg|thumb|300px|An [[arrangement of lines]] dual to the regular pentagon. Every five-line projective arrangement, like this one, has a cell touched by all five lines. However, adding the [[line at infinity]] produces a six-line arrangement with six pentagon faces and ten triangle faces; no face is touched by all of the lines. Therefore, the solution to the McMullen problem for ''d''&amp;nbsp;=&amp;nbsp;2 is ''&amp;nu;''&amp;nbsp;=&amp;nbsp;5.]]
The equivalent [[projective dual]] statement to the McMullen problem is to determine the largest number &lt;math&gt;\nu(d)&lt;/math&gt; such that every set of &lt;math&gt;\nu(d)&lt;/math&gt; [[hyperplane]]s in general position in ''d''-dimensional [[real projective space]] form an [[arrangement of hyperplanes]] in which one of the cells is bounded by all of the hyperplanes.

==Results==
This problem is still open. However, the bounds of &lt;math&gt;\nu(d)&lt;/math&gt; are in the following results:
*David Larman proved that &lt;math&gt;2d+1\leq\nu(d)\leq(d+1)^2&lt;/math&gt;. (1972)&lt;ref name="L" /&gt;
*[[Michel Las Vergnas]] proved that &lt;math&gt;\nu(d)\leq\frac{(d+1)(d+2)}{2}&lt;/math&gt;. (1986)&lt;ref name="LV"&gt;[[Michel Las Vergnas|M. Las Vergnas]] (1986), "Hamilton Paths in Tournaments and a Problem McMullen on Projective Transformations in '''R'''&lt;sup&gt;d&lt;/sup&gt;", ''[[Bulletin of the London Mathematical Society]]'' '''18''', pp.571&amp;ndash;572&lt;/ref&gt;
*Jorge Luis Ramírez Alfonsín proved that &lt;math&gt;\nu(d)\leq2d+\lceil\frac{d+1}{2}\rceil&lt;/math&gt;. (2001)&lt;ref name="A"&gt;J. L. Ram&amp;iacute;rez Alfons&amp;iacute;n (2001), "Lawrence Oriented Matroids and a Problem of McMullen on Projective Equivalences of Polytopes", ''[[European Journal of Combinatorics]]'' '''22''', pp.723&amp;ndash;731&lt;/ref&gt;

The conjecture of this problem is &lt;math&gt;\nu(d)=2d+1&lt;/math&gt;, and it is true for ''d'' = 2, 3, 4.&lt;ref name="L" /&gt;&lt;ref name="F"&gt;D. Forge, M. Las Vergnas and P. Schuchert (2001), "A Set of 10 Points in Dimension 4 not Projectively Equivalent to the Vertices of Any Convex Polytope", ''[[European Journal of Combinatorics]]'' '''22''', pp.705&amp;ndash;708&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Discrete geometry]]
[[Category:Unsolved problems in mathematics]]</text>
      <sha1>qkvrr406sd82p82qxxxvwtmkd8gbr4a</sha1>
    </revision>
  </page>
  <page>
    <title>NAS Award in Mathematics</title>
    <ns>0</ns>
    <id>28306582</id>
    <revision>
      <id>859229479</id>
      <parentid>823499689</parentid>
      <timestamp>2018-09-12T16:53:20Z</timestamp>
      <contributor>
        <username>T0mpr1c3</username>
        <id>3427765</id>
      </contributor>
      <comment>category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3885">The '''NAS Award in Mathematics''' is awarded by the U.S. [[United States National Academy of Sciences|National Academy of Sciences]]  "for excellence of research in the mathematical sciences published within the past ten years." It has been awarded every four years since 1988.&lt;ref name="nas"&gt;{{citation|url=http://www.nasonline.org/programs/awards/mathematics.html|title=NAS Award in Mathematics|publisher=National Academy of Sciences|accessdate=2015-12-10}}.&lt;/ref&gt;

==Award winners ==
Source: [http://www.nasonline.org/programs/awards/mathematics.html NAS]
*[[Michael J. Hopkins]] (2012) "For his leading role in the development of homotopy theory, which has both reinvigorated algebraic topology as a central field in mathematics and led to the resolution of the Kervaire invariant problem for framed manifolds."&lt;ref name="nas"/&gt;&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201205/rtx120500678p.pdf | title=Hopkins Receives NAS Award in Mathematics|first=Elaine|last=Kehoe|journal=[[Notices of the American Mathematical Society]]|volume=59|issue=5|page=678|date=May 2012}}.&lt;/ref&gt;
*[[Clifford Taubes|Clifford H. Taubes]] (2008) "For groundbreaking work relating to Seiberg-Witten and Gromov-Witten invariants of symplectic 4-manifolds, and his proof of Weinstein conjecture for all contact 3-manifolds."&lt;ref name="nas"/&gt;&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200805/tx080500596p.pdf | title=Taubes Receives NAS Award in Mathematics|first=Allyn|last=Jackson|journal=[[Notices of the American Mathematical Society]]|volume=55|issue=5|pages=596–597|date=May 2008}}.&lt;/ref&gt;
*[[Dan-Virgil Voiculescu]] (2004) "For the theory of free probability, in particular, using random matrices and a new concept of entropy to solve several hitherto intractable problems in von Neumann algebras."&lt;ref name="nas"/&gt;&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200405/comm-nas.pdf | journal=[[Notices of the American Mathematical Society]]|date=May 2004|volume=51|issue=5|title=Voiculescu Receives NAS Award in Mathematics|page=547|first=Allyn|last=Jackson}}.&lt;/ref&gt;
*[[Ingrid Daubechies]] (2000) "For fundamental discoveries on wavelets and wavelet expansions and for her role in making wavelet methods a practical basic tool of applied mathematics."&lt;ref name="nas"/&gt;&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200005/comm-nas.pdf|title=Ingrid Daubechies Receives NAS Award in Mathematics|journal=[[Notices of the American Mathematical Society]]|date=May 2000|page=571|volume=47|issue=5|first=Allyn|last=Jackson}}.&lt;/ref&gt;
*[[Andrew J. Wiles]] (1996) "For his proof of Fermat's Last Theorem by discovering a beautiful strategy to establish a major portion of the Shimura-Taniyama conjecture, and for his courage and technical power in bringing his idea to completion."&lt;ref name="nas"/&gt;&lt;ref&gt;{{citation|url=http://www.ams.org/notices/199607/comm-wiles.pdf|title=Wiles Receives NAS Award in Mathematics|journal=[[Notices of the American Mathematical Society]]|volume=43|issue=7|pages=760–763|date=July 1996|first=John|last=Coates|authorlink=John H. Coates}}.&lt;/ref&gt;
*[[Robert MacPherson (mathematician)|Robert MacPherson]] (1992) "For his role in the introduction and application of radically new approaches to the topology of singular spaces, including characteristics classes, intersection homology, perverse sheaves, and stratified Morse theory."&lt;ref name="nas"/&gt;
*[[Robert P. Langlands]] (1988) "For his extraordinary vision, which has brought the theory of group representations into a revolutionary new relationship with the theory of automorphic forms and number theory."&lt;ref name="nas"/&gt;

==See also==
* [[List of science and technology awards]]

==References==
{{reflist}}

{{National Academy of Sciences|state=collapsed}}

[[Category:Awards established in 1988]]
[[Category:Mathematics awards]]
[[Category:Awards of the United States National Academy of Sciences]]

{{award-stub}}</text>
      <sha1>jzp6b8tyj6vbnxh9xi3bppxb6t2vluo</sha1>
    </revision>
  </page>
  <page>
    <title>Noncrossing partition</title>
    <ns>0</ns>
    <id>695026</id>
    <revision>
      <id>803363647</id>
      <parentid>671531200</parentid>
      <timestamp>2017-10-02T01:57:35Z</timestamp>
      <contributor>
        <username>Darij</username>
        <id>9540940</id>
      </contributor>
      <comment>/* Definition */ this one is the more common</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5051">[[File:Noncrossing partitions 5.svg|thumb|There are 42 noncrossing and 10 crossing partitions of a 5-element set]]
[[File:Noncrossing partitions 4; Hasse.svg|thumb|The 14 noncrossing partitions of a 4-element set ordered in a [[Hasse diagram]] ]]

In [[combinatorial mathematics]], the topic of '''noncrossing partitions''' has assumed some importance because of (among other things) its application to the theory of [[free probability]]. The set of all noncrossing partitions is one of many sets enumerated by the [[Catalan number]]s. The number of noncrossing partitions of an ''n''-element set with ''k'' blocks is found in the [[Narayana number]] triangle.

==Definition==

A [[partition of a set]] ''S'' is a pairwise disjoint set of non-empty subsets, called "parts" or "blocks", whose union is all of ''S''.  Consider a finite set that is linearly ordered, or (equivalently, for purposes of this definition) arranged in a [[cyclic order]] like the vertices of a regular ''n''-gon.  No generality is lost by taking this set to be ''S'' = { 1, ..., ''n'' }.  A '''noncrossing partition''' of ''S'' is a partition in which no two blocks "cross" each other, i.e., if ''a'' and ''b'' belong to one block and ''x'' and ''y'' to another, they are not arranged in the order ''a x b y''. If one draws an arch based at ''a'' and ''b'', and another arch based at ''x'' and ''y'', then the two arches cross each other if the order is ''a x b y'' but not if it is ''a x y b'' or ''a b x y''. In the latter two orders the partition { { ''a'', ''b'' }, { ''x'', ''y'' } } is noncrossing.

{|
|Crossing:     
|''a x b y''
|-
|Noncrossing:
|''a x y b''
|-
|Noncrossing:
|''a b x y''
|}

Equivalently, if we label the vertices of a regular ''n''-gon with the numbers 1 through ''n'', the [[convex hull]]s of different blocks of the partition are disjoint from each other, i.e., they also do not "cross" each other.
The set of all non-crossing partitions of ''S'' are denoted &lt;math&gt;\text{NC}(S)&lt;/math&gt;. There is an obvious order isomorphism between &lt;math&gt;\text{NC}(S_1)&lt;/math&gt; and &lt;math&gt;\text{NC}(S_2)&lt;/math&gt; for two finite sets &lt;math&gt; S_1,S_2&lt;/math&gt; with the same size. That is, &lt;math&gt;\text{NC}(S)&lt;/math&gt; depends essentially only on the size of &lt;math&gt; S&lt;/math&gt; and we denote by &lt;math&gt;\text{NC}(n)&lt;/math&gt; the non-crossing partitions on ''any'' set of size ''n''.

==Lattice structure==

Like the set of all partitions of the set { 1, ..., ''n'' }, the set of all noncrossing partitions is a [[lattice (order)|lattice]] when [[partially ordered set|partially ordered]] by saying that a finer partition is "less than" a coarser partition.  However, although it is a subset of the lattice of all partitions, it is ''not'' a sublattice of the lattice of all partitions, because the join operations do not agree.  In other words, the finest partition that is coarser than both of two noncrossing partitions is not always the finest ''noncrossing'' partition that is coarser than both of them.

Unlike the lattice of all partitions of the set, the lattice of all noncrossing partitions of a set is self-dual, i.e., it is order-isomorphic to the lattice that results from inverting the partial order ("turning it upside-down").  This can be seen by observing that each noncrossing partition has a complement.  Indeed, every interval within this lattice is self-dual.

==Role in free probability theory==

The lattice of noncrossing partitions plays the same role in defining [[Cumulant#free cumulants|free cumulants]] in [[free probability]] theory that is played by the lattice of ''all'' partitions in defining joint cumulants in classical [[probability theory]].  To be more precise, let &lt;math&gt;(\mathcal{A},\phi)&lt;/math&gt; be a [[non-commutative probability space]] (See [[free probability]] for terminology.), &lt;math&gt;a\in\mathcal{A}&lt;/math&gt; a [[non-commutative random variable]] with free cumulants &lt;math&gt;(k_n)_{n\in\mathbb{N}}&lt;/math&gt;. Then

:&lt;math&gt;\phi(a^n) = \sum_{\pi\in\text{NC}(n)} \prod_{j} k_j^{N_j(\pi)}&lt;/math&gt;

where &lt;math&gt;N_j(\pi)&lt;/math&gt; denotes the number of blocks of length &lt;math&gt; j&lt;/math&gt; in the non-crossing partition &lt;math&gt;\pi&lt;/math&gt;.
That is, the moments of a non-commutative random variable can be expressed as a sum of free cumulants over the sum non-crossing partitions. This is the free analogue of the [[Cumulant#Cumulants and set-partitions|moment-cumulant formula]] in classical probability.
See also [[Wigner semicircle distribution]].

==References==
*Germain Kreweras, "Sur les partitions non croisées d'un cycle", ''[[Discrete Mathematics (journal)|Discrete Mathematics]]'', volume 1, number 4, pages 333–350, 1972.
*[[Rodica Simion]], "Noncrossing partitions", ''Discrete Mathematics'', volume 217, numbers 1–3, pages 367–409, April 2000.
*[http://www.emis.de/journals/SLC/wpapers/s39speicher.html Roland Speicher, "Free probability and noncrossing partitions"], ''[http://www.emis.de/journals/SLC Séminaire Lotharingien de Combinatoire]'', B39c (1997), 38 pages, 1997

[[Category:Set families]]
[[Category:Enumerative combinatorics]]</text>
      <sha1>qai6w87l95irwo5b8lhk8mxtyxn6dzh</sha1>
    </revision>
  </page>
  <page>
    <title>Number sentence</title>
    <ns>0</ns>
    <id>11877586</id>
    <revision>
      <id>868701113</id>
      <parentid>853339933</parentid>
      <timestamp>2018-11-13T21:49:44Z</timestamp>
      <contributor>
        <ip>2601:244:4080:32B5:C18F:DC33:E303:8AFF</ip>
      </contributor>
      <comment>Explained something that some may have questions about</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2450">{{Orphan|date=December 2012}}

In [[mathematics education]],  a '''number sentence''' is typically an [[equation]] or [[inequality (mathematics)|inequality]] expressed using [[number]]s and mathematical symbols. The term is used in [[primary education|primary level]] mathematics teaching in the US,&lt;ref&gt;[http://www.glc.k12.ga.us/BuilderV03/LPTools/LPShared/lpdisplay.asp?LPID=14967 Show Me That Number Sentence&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; Canada, UK,&lt;ref&gt;http://www.qca.org.uk/downloads/3420_maths_glossary_ks1_4.pdf&lt;/ref&gt; Australia, New Zealand&lt;ref&gt;http://www.mceetya.edu.au/verve/_resources/SOL_Mathematics_2006.pdf&lt;/ref&gt; and South Africa.&lt;ref&gt;[http://www.education.gov.za/Curriculum/GET/doc/maths.pdf Mathematics Final&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

==Usage==
The term is used as means of asking students to write down equations using simple mathematical symbols (numerals, the four main basic mathematical operators, equality symbol).&lt;ref&gt;[http://www.harcourtschool.com/glossary/math2/define/gr3/number_sentence3.html number sentence&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; Sometimes boxes or shapes are used to indicate unknown values. As such, number sentences are used to introduce students to notions of structure and [[elementary algebra]] prior to a more formal treatment of these concepts.

A number sentence without unknowns is equivalent to a logical proposition expressed using the notation of arithmetic.

==Examples==

* A valid number sentence that is true: 3+10=13. 
* A valid number sentence that is false: 1 + 1 = 3. 
* A valid number sentence using a 'less than' symbol: 3 + 6 &lt; 10.
* A valid number sentence using a 'more than' symbol: 3 + 9 &gt; 11.

* An example from a lesson plan:&lt;ref&gt;[http://www.education.vic.gov.au/studentlearning/teachingresources/maths/mathscontinuum/structure/ST40004P.htm Mathematics Continuum - Structure - Equivalence - Learning and Teaching Resources - Prep to Year 10 - Student Learning - Department of Education and Early Childhood Development&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;
&lt;blockquote&gt;
Some students will use a direct computational approach. They will carry out the addition 26 + 39 = 65, put 65 = 26 + &lt;math&gt;\Box&lt;/math&gt;, and then find that &lt;math&gt;\Box&lt;/math&gt; = 39.
&lt;/blockquote&gt;

==See also==
*[[Expression (mathematics)]]
*[[Equation]]
*[[Inequality (mathematics)]]
*[[Open sentence]]
*[[Sentence (mathematical logic)]]

==References==
{{reflist}}

[[Category:Mathematics education]]</text>
      <sha1>7n62p81hw4me0qzwhx8i78ggtjd1vjk</sha1>
    </revision>
  </page>
  <page>
    <title>Oversampling</title>
    <ns>0</ns>
    <id>1339640</id>
    <revision>
      <id>870956685</id>
      <parentid>867228378</parentid>
      <timestamp>2018-11-28T01:16:40Z</timestamp>
      <contributor>
        <username>Kvng</username>
        <id>910180</id>
      </contributor>
      <comment>review: define and use acronyms. terminology improvements. rm unnec editorializing. rm unnec parens.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8973">{{about|oversampling in signal processing|oversampling in data analysis|Oversampling and undersampling in data analysis}}

In [[signal processing]], '''oversampling''' is the process of [[sampling (signal processing)|sampling]] a signal at a sampling frequency significantly higher than the [[Nyquist rate]]. Theoretically, a bandwidth-limited signal can be perfectly reconstructed if sampled at the Nyquist rate or above it. The Nyquist rate is defined as twice the highest [[frequency component]] in the signal. Oversampling is capable of improving [[Resolution (audio)|resolution]], reducing [[noise]] and can be helpful in avoiding [[aliasing]] and [[phase distortion]] by relaxing [[anti-aliasing filter]] performance requirements.

A signal is said to be oversampled by a factor of ''N'' if it is sampled at ''N'' times the Nyquist rate.

==Motivation==
There are three main reasons for performing oversampling:

===Anti-aliasing===
Oversampling can make it easier to realize analog [[anti-aliasing filter]]s.&lt;ref name=AD-oversample&gt;{{cite web|last1=Kester|first1=Walt|title=Oversampling Interpolating DACs|url=http://www.analog.com/static/imported-files/tutorials/MT-017.pdf|publisher=Analog Devices|access-date=17 January 2015}}&lt;/ref&gt; Without oversampling, it is very difficult to implement filters with the sharp cutoff necessary to maximize use of the available bandwidth without exceeding the [[Nyquist limit]]. By increasing the bandwidth of the sampling system, design constraints for the anti-aliasing filter may be relaxed.&lt;ref&gt;{{cite journal |url=http://www.audioholics.com/education/audio-formats-technology/upsampling-vs-oversampling-for-digital-audio |title=Upsampling vs. Oversampling for Digital Audio |quote=Without increasing the sample rate, we would need to design a very sharp filter that would have to cutoff &amp;#91;sic&amp;#93; at just past 20kHz and be 80-100dB down at 22kHz. Such a filter is not only very difficult and expensive to implement, but may sacrifice some of the audible spectrum in its rolloff. |author=Nauman Uppal |date=30 August 2004 |access-date=6 October 2012}}&lt;/ref&gt; Once sampled, the signal can be [[digital filter|digitally filtered]] and [[downsampling|downsampled]] to the desired sampling frequency. In modern [[integrated circuit]] technology, the digital filter associated with this downsampling are easier to implement than a comparable [[analog filter]] required by a non-oversampled system.

===Resolution===
In practice, oversampling is implemented in order to reduce cost and improve performance of an [[analog-to-digital converter]] (ADC) or [[digital-to-analog converter]] (DAC).&lt;ref name="AD-oversample" /&gt; When oversampling by a factor of N, the [[dynamic range]] also increases a factor of N because there are N times as many possible values for the sum. However, the [[signal-to-noise ratio]] (SNR) increases by &lt;math alt="Square root of N"&gt;\sqrt{N}&lt;/math&gt;, because summing up uncorrelated noise increases its amplitude by &lt;math alt="Square root of N"&gt;\sqrt{N}&lt;/math&gt;, while summing up a coherent signal increases its average by N. As a result, the SNR increases by &lt;math alt="Square root of N"&gt;\sqrt{N}&lt;/math&gt;. 

For instance, to implement a 24-bit converter, it is sufficient to use a 20-bit converter that can run at 256 times the target sampling rate. Combining 256 consecutive 20-bit samples can increase the [[signal-to-noise ratio]] (SNR) by a factor of 16, effectively adding 4 bits to the resolution and producing a single sample with 24-bit resolution.&lt;ref name=sillabs&gt;{{cite web|title=Improving ADC Resolution by Oversampling and Averaging |url=https://www.silabs.com/Support%20Documents/TechnicalDocs/an118.pdf |publisher=Silicon Laboratories Inc |accessdate=17 January 2015}}&lt;/ref&gt; While with N=256 there is an increase in dynamic range by 8 bits, and the level of coherent signal increases by a factor of N, the noise changes by a factor of &lt;math alt="Square root of N"&gt;\sqrt{N}&lt;/math&gt;=16, so the net SNR improves by a factor of 16, 4 bits or 24&amp;nbsp;dB.

The number of samples required to get &lt;math&gt;n&lt;/math&gt; bits of additional data precision is

:&lt;math&gt;\mbox{number of samples} = (2^n)^2 = 2^{2n}.&lt;/math&gt;

To get the mean sample scaled up to an integer with &lt;math&gt;n&lt;/math&gt; additional bits, the sum of &lt;math&gt;2^{2n}&lt;/math&gt; samples is divided by &lt;math&gt;2^n&lt;/math&gt;:

:&lt;math&gt;\mbox{scaled mean} = \frac{ \sum\limits^{2^{2n}-1}_{i=0} 2^n \text{data}_i}{2^{2n}} = \frac{\sum\limits^{2^{2n}-1}_{i=0} \text{data}_i}{2^n}.&lt;/math&gt;

This averaging is only effective if the [[signal]] contains sufficient [[uncorrelated noise]] to be recorded by the ADC.&lt;ref name="sillabs" /&gt; If not, in the case of a stationary input signal, all &lt;math&gt;2^n&lt;/math&gt; samples would have the same value and the resulting average would be identical to this value; so in this case, oversampling would have made no improvement.  In similar cases where the ADC records no noise and the input signal is changing over time, oversampling improves the result, but to an inconsistent and unpredictable extent.  Adding some [[dither]]ing noise to the input signal can actually improve the final result because the dither noise allows oversampling to work to improve resolution.  In many practical applications, a small increase in noise is well worth a substantial increase in measurement resolution. In practice, the dithering noise can often be placed outside the frequency range of interest to the measurement, so that this noise can be subsequently filtered out in the digital domain—resulting in a final measurement, in the frequency range of interest, with both higher resolution and lower noise.&lt;!--[[User:Kvng/RTH]]--&gt;

===Noise===
If multiple samples are taken of the same quantity with [[uncorrelated]] noise added to each sample, then averaging ''N'' samples reduces the [[noise power]] by a factor of 1/''N''.&lt;ref&gt;See [[standard error (statistics)]]&lt;/ref&gt;  If, for example, we oversample by a factor of 4, the [[signal-to-noise ratio]] in terms of power improves by factor of 4 which corresponds to a factor of 2 improvement in terms of voltage.&lt;ref group=note&gt;A system's signal-to-noise ratio cannot necessarily be increased by simple over-sampling, since noise samples are partially correlated (only some portion of the noise due to sampling and analog-to-digital conversion will be uncorrelated).&lt;/ref&gt;

Certain kinds of A/D converters known as [[Delta-sigma modulation|delta-sigma converter]]s produce disproportionately more [[Quantization (signal processing)|quantization]] noise in the upper portion of their output spectrum. By running these converters at some multiple of the target sampling rate, and [[low-pass filter]]ing the oversampled signal down to half the target sampling rate, a final result with ''less'' noise (over the entire band of the converter) can be obtained. Delta-sigma converters use a technique called [[noise shaping]] to move the quantization noise to the higher frequencies.

==Example==
Consider a signal with a bandwidth or highest frequency of ''B'' = 100 [[Hertz|Hz]]. The [[Nyquist-Shannon sampling theorem|sampling theorem]] states that sampling frequency would have to be greater than 200&amp;nbsp;Hz. Sampling at four times that rate requires a sampling frequency of 800&amp;nbsp;Hz. This gives the anti-aliasing filter a [[transition band]] of 300&amp;nbsp;Hz ((''f''&lt;sub&gt;s&lt;/sub&gt;/2) − ''B'' = (800&amp;nbsp;Hz/2) − 100&amp;nbsp;Hz = 300&amp;nbsp;Hz) instead of 0&amp;nbsp;Hz if the sampling frequency was 200&amp;nbsp;Hz.

Achieving an anti-aliasing filter with 0&amp;nbsp;Hz transition band is unrealistic whereas an anti-aliasing filter with a transition band of 300&amp;nbsp;Hz is not difficult to create.

==Oversampling in reconstruction==
The term oversampling is also used to denote a process used in the reconstruction phase of [[digital-to-analog conversion]], in which an intermediate high sampling rate is used between the digital input and the analogue output. Here, samples are interpolated in the digital domain to add additional samples in between, thereby converting the data to a higher sample rate, which is a form of [[upsampling]]. When the resulting higher-rate samples are converted to analog, a less complex/expensive analog low pass filter is required to remove the high-frequency content, which will consist of reflected images of the real signal created by the [[zero-order hold]] of the [[digital-to-analog converter]]. Essentially, this is a way to shift some of the complexity of the filtering into the digital domain and achieves the same benefit as oversampling in analog-to-digital conversion.

== See also ==
*[[Upsampling]]
*[[Undersampling]]
*[[Oversampling and undersampling in data analysis]]
*[[Oversampled binary image sensor]]

==Notes==
{{reflist|group=note}}

==References==
{{Reflist}}

==Further reading==
*{{cite book |author=John Watkinson |title=The Art of Digital Audio |ISBN=0-240-51320-7}}

{{DSP}}

[[Category:Digital signal processing]]
[[Category:Information theory]]</text>
      <sha1>1ql82kscvyhvupfm3r5ir6w4gmen0hx</sha1>
    </revision>
  </page>
  <page>
    <title>Passphrase</title>
    <ns>0</ns>
    <id>152420</id>
    <revision>
      <id>818378350</id>
      <parentid>818344928</parentid>
      <timestamp>2018-01-03T05:37:26Z</timestamp>
      <contributor>
        <username>Guy Macon</username>
        <id>1590599</id>
      </contributor>
      <comment>/* External links */ Spam.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11562">A '''passphrase''' is a sequence of words or other text used to [[access control|control access]] to a computer system, program or data. A passphrase is similar to a [[password]] in usage, but is generally longer for added security. Passphrases are often used to control both access to, and operation of, [[cryptographic]] programs and systems, especially those that derive an [[key (cryptography)|encryption key]] from a passphrase. The origin of the term is by analogy with ''password''. The modern concept of passphrases is believed to have been invented by Sigmund N. Porter&lt;ref&gt;Sigmund N. Porter.  "A password extension for improved human factors".  Computers and Security, 1(1):54-56, January 1982.&lt;/ref&gt; in 1982.

==Security==
{{See also|Password strength}}

Considering that the [[information entropy|entropy]] of written English is less than 1.1 bits per character,&lt;ref name=entropy&gt;{{cite web | url = http://cs.fit.edu/~mmahoney/dissertation/entropy1.html | title = Refining the Estimated Entropy of English by Shannon Game Simulation | publisher = Florida Institute of Technology | author= Matt Mahoney | accessdate = March 27, 2008}}&lt;/ref&gt; passphrases can be relatively weak. [[NIST]] has estimated that the 23-character passphrase "IamtheCapitanofthePina4" contains a 45-bit strength. The equation employed here is:&lt;ref name=NIST&gt;{{cite web | url = http://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-63-2.pdf | title = Electronic Authentication Guideline | format = [[PDF]] | publisher = NIST | accessdate = September 26, 2016}}&lt;/ref&gt;

: 4 bits (1st character) + 14 bits (characters 2&amp;ndash;8) + 18 bits (characters 9&amp;ndash;20) + 3 bits (characters 21&amp;ndash;23) + 6 bits (bonus for upper case, lower case, and alphanumeric) = 45 bits

(This calculation does not take into account that this is a well-known quote from the operetta [[H.M.S. Pinafore]]. An MD5 hash of this passphrase can be cracked in 4 seconds using crackstation.net, indicating that the phrase is found in password cracking databases.)

Using this guideline, to achieve the 80-bit strength recommended for high security (non-military) by NIST, a passphrase would need to be 58 characters long, assuming a composition that includes uppercase and alphanumeric.

There is room for debate regarding the applicability of this equation, depending on the number of bits of entropy assigned. For example, the characters in five-letter words each contain 2.3 bits of entropy{{fact|date=March 2014}}, which would mean only a 35-character passphrase is necessary to achieve 80 bit strength.&lt;ref name=entropy2&gt;{{cite web | url = http://www.microsoft.com/technet/security/secnews/articles/itproviewpoint100504.mspx | title = The Great Debates: Pass Phrases vs. Passwords. Part 2 of 3 | publisher = Microsoft Corporation | author= Jesper M. Johansson | accessdate = March 27, 2008}}&lt;/ref&gt;

If the words or components of a passphrase may be found in a language dictionary—especially one available as electronic input to a software program—the passphrase is rendered more vulnerable to [[dictionary attack]]. This is a particular issue if the entire phrase can be found in a book of quotations or phrase compilations. However, the required effort (in time and cost) can be made impracticably high if there are enough words in the passphrase and how [[random]]ly they are chosen and ordered in the passphrase. The number of combinations which would have to be tested under sufficient conditions make a dictionary attack so difficult as to be infeasible. These are difficult conditions to meet, and selecting at least one word that cannot be found in ''any'' dictionary significantly increases passphrase strength.

If passphrases are chosen by humans they are usually biased by frequency of particular words in natural language. In the case of four word phrases, actual entropy rarely exceeds 30 bits. On the other hand, user-selected passwords tend to be much weaker than that and encouraging users to use even 2-word passphrases may be able to raise entropy from below 10 bits to over 20 bits.&lt;ref&gt;Joseph Bonneau, Ekaterina Shutova, [https://www.cl.cam.ac.uk/~jcb82/doc/BS12-USEC-passphrase_linguistics.pdf Linguistic properties of multi-word passphrases], University of Cambridge&lt;/ref&gt;

For example, the widely used cryptography standard [[OpenPGP]] requires that a user make up a passphrase that must be entered whenever decrypting or signing messages. Internet services like [[Hushmail]] provide free encrypted e-mail or file sharing services, but the security present depends almost entirely on the quality of the chosen passphrase.{{Citation needed|date=July 2010}}

==Compared to passwords==
Passphrases differ from passwords. A [[password]] is usually short&amp;mdash;six to ten characters. Such passwords may be adequate for various applications (if frequently changed, if chosen using an appropriate policy, if not found in dictionaries, if sufficiently random, and/or if the system prevents online guessing, etc.) such as:
* Logging onto computer systems
* Negotiating keys in an interactive setting (e.g. using [[password-authenticated key agreement]])
* Enabling a smart-card or PIN for an [[ATM card]] (e.g. where the password data (hopefully) cannot be extracted)

But passwords are typically not safe to use as keys for standalone security systems (e.g., encryption systems) that expose data to enable offline password guessing by an attacker.{{Citation needed|date=December 2010}} Passphrases are theoretically stronger, and so should make a better choice in these cases. First, they usually are (and always should be) much longer&amp;mdash;20 to 30 characters or more is typical&amp;mdash;making some kinds of brute force attacks entirely impractical. Second, if well chosen, they will not be found in any phrase or quote dictionary, so such dictionary attacks will be almost impossible. Third, they can be structured to be more easily memorable than passwords without being written down, reducing the risk of hardcopy theft.{{Citation needed|date=December 2010}} However, if a passphrase is not protected appropriately by the authenticator and the clear-text passphrase is revealed its use is no better than other passwords. For this reason it is recommended that passphrases not be reused across different or unique sites and services.

In 2012, two Cambridge University researchers analyzed passphrases from the [[Amazon PayPhrase]] system and found that a significant percentage are easy to guess due to common cultural references such as movie names and sports teams, losing much of the potential of using long passwords.&lt;ref&gt;{{cite web|last1=Godwin|first1=Dan |date={{date|2012-03-14}} |title=Passphrases only marginally more secure than passwords because of poor choices |url=https://arstechnica.com/business/2012/03/passphrases-only-marginally-more-secure-than-passwords-because-of-poor-choices/|accessdate=9 December 2014}}&lt;/ref&gt;

When used in cryptography, commonly the password protects a long (machine generated) [[key (cryptography)|key]], and the key protects the data. The key is so long a brute force attack (directly on the data) is impossible. A [[key derivation function]] is used, involving many thousands of iterations (salted &amp; hashed), to slow down [[password cracking]] attacks.

==Passphrase selection==

Typical advice about choosing a passphrase includes suggestions that it should be:&lt;ref name="SS2"&gt;{{cite web| last=Lundin|first=Leigh |title= PINs and Passwords, Part 2 | url=http://www.sleuthsayers.org/2013/08/pins-and-passwords-part-2.html |work=Passwords| publisher=SleuthSayers| location=Orlando| date=2013-08-11}}&lt;/ref&gt;
* Long enough to be hard to guess
* Not a famous quotation from literature, holy books, et cetera
* Hard to guess by intuition—even by someone who knows the user well
* Easy to remember and type accurately
* For better security, any easily memorable encoding at the user's own level can be applied.
* Not reused between sites, applications and other different sources.

==Example methods==

One method to create a strong passphrase is to use [[dice]] to select words at random from a long list, a technique often referred to as [[diceware]]. While such a collection of words might appear to violate the "not from any dictionary" rule, the security is based entirely on the large number of possible ways to choose from the list of words and not from any secrecy about the words themselves. For example, if there are 7776 words in the list and six words are chosen randomly, then there are ''7776&lt;sup&gt;6&lt;/sup&gt;&amp;nbsp;= 221073919720733357899776'' combinations, providing about 78 bits of [[entropy (information theory)|entropy]]. (The number ''7776'' was chosen to allow words to be selected by throwing five dice. ''7776&amp;nbsp;=&amp;nbsp;6&lt;sup&gt;5&lt;/sup&gt;'')   Random word sequences may then be memorized using techniques such as the [[memory palace]].

Another is to choose two phrases, turn one into an [[acronym]], and include it in the second, making the final passphrase. For instance, using two English language typing exercises, we have the following. ''The quick brown fox jumps over the lazy dog'', becomes ''tqbfjotld''. Including it in, ''Now is the time for all good men to come to the aid of their country'', might produce, ''Now is the time for all good tqbfjotld to come to the aid of their country'' as the passphrase.

There are several points to note here, all relating to why this example passphrase is not a good one.
* It has appeared in public and so should be avoided by everyone.
* It is long (which is a considerable virtue in theory) and requires a good typist as typing errors are much more likely for extended phrases.
* Individuals and organizations serious about cracking computer security have compiled lists of passwords derived in this manner from the most common quotations, song lyrics, and so on.

The PGP Passphrase FAQ&lt;ref name="passphrasefaq"&gt;{{cite web |date=1997-01-13 |author=Randall T. Williams |title=The Passphrase FAQ |url=http://www.iusmentis.com/security/passphrasefaq/ |accessdate=2006-12-11}}&lt;/ref&gt; suggests a procedure that attempts a better balance between theoretical security and practicality than this example. All procedures for picking a passphrase involve a tradeoff between security and ease of use; security should be at least "adequate" while not "too seriously" annoying users. Both criteria should be evaluated to match particular situations.

Another supplementary approach to frustrating brute-force attacks is to derive the key from the passphrase using a [[key derivation function|deliberately slow hash function]], such as [[PBKDF2]] as described in RFC 2898.

{{main|Key stretching}}

==Windows support==
If backward compatibility with [[Microsoft LAN Manager]] is not needed, in versions of [[Windows NT]] (including [[Windows 2000]], [[Windows XP]] and later), a passphrase can be used as a substitute for a Windows password. If the passphrase is longer than 14 characters, this will also avoid the generation of a ''very'' weak [[LM hash]].

==Unix support==
In recent versions of [[Unix-like]] operating systems such as [[Linux]], [[OpenBSD]], [[NetBSD]], [[Solaris (operating system)|Solaris]] and [[FreeBSD]], up to 255-character passphrases can be used.

==See also==
*[[Keyfile]]
*[[Password-based cryptography]]

==References==
&lt;references /&gt;

==External links==
* [http://www.diceware.com Diceware page]
* [http://xkcd.com/936/ xkcd Password Strength] common-viewed explanation of concept

[[Category:Cryptography]]
[[Category:Password authentication]]</text>
      <sha1>3h1pgsytp9wsw0pfzjbikv7lu0q2yv8</sha1>
    </revision>
  </page>
  <page>
    <title>Peter B. Andrews</title>
    <ns>0</ns>
    <id>4132316</id>
    <revision>
      <id>829665508</id>
      <parentid>821094083</parentid>
      <timestamp>2018-03-10T01:04:38Z</timestamp>
      <contributor>
        <username>Wqwt</username>
        <id>21740901</id>
      </contributor>
      <comment>Cite</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3068">{{other people|Peter Andrews}}
[[Image:Peter Andrews IMG 0397.jpg|thumb|Peter Andrews in 2012]]
'''Peter Bruce Andrews''' (born 1937) is an [[United States|American]] [[mathematician]] and Professor of Mathematics, Emeritus at [[Carnegie Mellon University]] in [[Pittsburgh, Pennsylvania]],&lt;ref&gt;{{Cite web|url=http://gtps.math.cmu.edu/andrews.html|title=Peter B. Andrews|website=gtps.math.cmu.edu|access-date=2018-03-10}}&lt;/ref&gt; and the creator of the [[Q0 (mathematical logic)|mathematical logic Q&lt;sub&gt;0&lt;/sub&gt;]]. He received his Ph.D. from [[Princeton University]] in 1964 under the tutelage of [[Alonzo Church]].&lt;ref&gt;{{Cite web|url=https://www.genealogy.math.ndsu.nodak.edu/id.php?id=8011|title=Alonzo Church - The Mathematics Genealogy Project|website=www.genealogy.math.ndsu.nodak.edu|access-date=2018-03-10}}&lt;/ref&gt; He received the [[Herbrand Award]] in 2003.&lt;ref&gt;{{Cite journal|last=Andrews|first=Peter B.|date=2003-10-01|title=Herbrand Award Acceptance Speech|url=https://link.springer.com/article/10.1023/B:JARS.0000009552.54063.f3|journal=Journal of Automated Reasoning|language=en|volume=31|issue=2|pages=169–187|doi=10.1023/b:jars.0000009552.54063.f3|issn=0168-7433}}&lt;/ref&gt; His research group designed the [[TPS (Theorem Proving System)|TPS]] [[automated theorem prover]]. A subsystem ETPS (Educational Theorem Proving System) of TPS is used to help students learn logic by interactively constructing natural deduction proofs.

==Publications==

*Andrews, Peter B. (1971). "Resolution in type theory". ''[[Journal of Symbolic Logic]]'' '''36''', 414–432.
*Andrews, Peter B. (1981). "Theorem proving via general matings". ''[[Journal of the ACM|J. Assoc. Comput.]]'' March. '''28''', no. 2, 193–214.
*Andrews, Peter B. (1986). ''An introduction to mathematical logic and type theory: to truth through proof''. Computer Science and Applied Mathematics. {{ISBN|978-0-1205-8535-9}}. Academic Press, Inc., Orlando, FL.
*Andrews, Peter B. (1989). "On connections and higher-order logic". ''[[Journal of Automated Reasoning|J. Automat. Reason.]]'' '''5''', no. 3, 257–291.
*Andrews, Peter B.; Bishop, Matthew; Issar, Sunil; Nesmith, Dan; [[Frank Pfenning|Pfenning, Frank]]; Xi, Hongwei (1996). "TPS: a theorem-proving system for classical type theory". ''[[Journal of Automated Reasoning|J. Automat. Reason.]]'' '''16''', no. 3, 321–353.
*Andrews, Peter B. (2002). ''An introduction to mathematical logic and type theory: to truth through proof''. Second edition. Applied Logic Series, 27. {{ISBN|978-1-4020-0763-7}}. Kluwer Academic Publishers, Dordrecht.

== References ==
{{Reflist}}

==External links==
*[http://gtps.math.cmu.edu/andrews.html Peter B. Andrews]

{{Authority control}}

{{DEFAULTSORT:Andrews, Peter}}
[[Category:1937 births]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:American logicians]]
[[Category:Mathematical logicians]]
[[Category:Carnegie Mellon University faculty]]
[[Category:Princeton University alumni]]


{{US-mathematician-stub}}</text>
      <sha1>9z3kytqlz8c6d6f531j4l6oowg4c8w5</sha1>
    </revision>
  </page>
  <page>
    <title>Peter van Emde Boas</title>
    <ns>0</ns>
    <id>48473330</id>
    <revision>
      <id>769397205</id>
      <parentid>730799529</parentid>
      <timestamp>2017-03-09T07:54:08Z</timestamp>
      <contributor>
        <username>FWDekker</username>
        <id>15220667</id>
      </contributor>
      <minor/>
      <comment>Correct capitalisation of tussenvoegsel</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1291">'''Peter van Emde Boas''' (born 3 April 1945, [[Amsterdam]])&lt;ref&gt;[http://www.albumacademicum.uva.nl Dr. P. van Emde Boas, 1945 -] at the University of Amsterdam Album Academicum online&lt;/ref&gt; is a [[Dutch people|Dutch]] [[computer scientist]] and [[professor]] at the [[University of Amsterdam]].&lt;ref&gt;{{cite web|url= https://www.illc.uva.nl/People/show_person.php?Person_id=Emde+Boas+P.+van|title=Prof.dr Peter van Emde Boas|access-date=5 November 2015}}&lt;/ref&gt; He gained his doctorate in 1974 under [[Adriaan van Wijngaarden]].&lt;ref&gt;{{MathGenealogyProject|id=51477}}&lt;/ref&gt;

The [[Van Emde Boas tree]] is named after him.&lt;ref&gt;Peter van Emde Boas '' Preserving order in a forest in less than logarithmic time'', Proceedings of the 16th Annual Symposium on Foundations of Computer Science, 1975, S. 75-84 - doi:10.1109/SFCS.1975.26&lt;/ref&gt;

==References==
{{reflist}}

==External links==
* [https://staff.fnwi.uva.nl/p.vanemdeboas/ Homepage]

{{Authority control}}

{{DEFAULTSORT:Emde Boas, Peter van}}
[[Category:1945 births]]
[[Category:Living people]]
[[Category:Dutch computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:University of Amsterdam faculty]]
[[Category:University of Amsterdam alumni]]
[[Category:Scientists from Amsterdam]]

{{Netherlands-scientist-stub}}</text>
      <sha1>8h1to6r8c5s3mqfkje3vfh3q5s59ddp</sha1>
    </revision>
  </page>
  <page>
    <title>Polar sine</title>
    <ns>0</ns>
    <id>17101042</id>
    <revision>
      <id>868860521</id>
      <parentid>799269078</parentid>
      <timestamp>2018-11-14T22:35:39Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6861">In [[geometry]], the '''polar sine''' generalizes the [[sine]] function of [[angle]] to the [[vertex angle]] of a [[polytope]]. It is denoted by '''psin'''.

==Definition==

=== ''n'' vectors in ''n''-dimensional space ===
[[File:3dvol.svg|280px|thumb|The interpretations of [[three-dimensional space|3d]] volumes for '''left:''' a [[parallelepiped]] (Ω in polar sine definition) and '''right:''' a [[cuboid]] (Π in definition). The interpretation is similar in higher dimensions.]]

Let '''v'''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;'''v'''&lt;sub&gt;''n''&lt;/sub&gt;, for ''n''&amp;nbsp;≥&amp;nbsp;2, be non-zero [[Euclidean vector]]s in [[n-dimensional space|''n''-dimensional space]] (ℝ&lt;sup&gt;''n''&lt;/sup&gt;) that are directed from a [[Vertex (geometry)|vertex]] of a [[Parallelepiped#Parallelotope|parallelotope]], forming the edges of the parallelotope. The polar sine of the vertex angle is:

:&lt;math&gt; \operatorname{psin}(\mathbf{v}_1,\dots,\mathbf{v}_n) = \frac{\Omega}{\Pi}, &lt;/math&gt;

where the numerator is the [[determinant]]

:&lt;math&gt; \begin{align}
\Omega &amp; = \det\begin{bmatrix}\mathbf{v}_1 &amp; \mathbf{v}_2 &amp; \cdots &amp; \mathbf{v}_n \end{bmatrix} =
\begin{vmatrix}
v_{11} &amp; v_{21} &amp; \cdots &amp; v_{n1} \\
v_{12} &amp; v_{22} &amp; \cdots &amp; v_{n2} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
v_{1n} &amp; v_{2n} &amp; \cdots &amp; v_{nn} \\
\end{vmatrix}
\end{align}&lt;/math&gt;

equal to the hyper [[volume]] of the parallelotope with vector edges&lt;ref&gt;{{cite journal|url = http://www.sciencedirect.com/science/article/pii/S0021904508001123 | doi=10.1016/j.jat.2008.03.005 | volume=156 | title=  On d-dimensional d-semimetrics and simplex-type inequalities for high-dimensional sine functions | year=2009 | journal=Journal of Approximation Theory | pages=52–81 | last1 = Lerman | first1 = Gilad | last2 = Whitehouse | first2 = J. Tyler}}&lt;/ref&gt;
:&lt;math&gt; \begin{align}
\mathbf{v}_1 &amp; = ( v_{11}, v_{12}, \cdots v_{1n} )^T \\
\mathbf{v}_2 &amp; = ( v_{21}, v_{22}, \cdots v_{2n} )^T \\
&amp; \,\,\,\vdots \\
\mathbf{v}_n &amp; = ( v_{n1}, v_{n2}, \cdots v_{nn} )^T \\
\end{align}&lt;/math&gt;

and in the denominator the ''n''-fold [[Multiplication#Capital Pi notation|product]]

:&lt;math&gt; \Pi = \prod_{i=1}^n \|\mathbf{v}_i\|&lt;/math&gt;

of the [[Norm (mathematics)|magnitude]]s ||'''v'''&lt;sub&gt;''i''&lt;/sub&gt;|| of the vectors equals the hypervolume of the ''n''-dimensional [[hyperrectangle]], with edges equal to the magnitudes of the vectors ||'''v'''&lt;sub&gt;1&lt;/sub&gt;||, ||'''v'''&lt;sub&gt;2&lt;/sub&gt;||, ... ||'''v'''&lt;sub&gt;''n''&lt;/sub&gt;|| (not the vectors themselves). Also see Ericksson.&lt;ref&gt;{{cite journal | last1 = Eriksson | first1 = F | year = 1978 | title = The Law of Sines for Tetrahedra and ''n''-Simplices | url = | journal = Geometriae Dedicata | volume = 7 | issue = | pages = 71–80 | doi=10.1007/bf00181352}}&lt;/ref&gt;

The parallelotope is like a "squashed hyperrectangle", so it has less hypervolume than the hyperrectangle, meaning (see image for the 3d case):

:&lt;math&gt;\Omega \leq \Pi \Rightarrow \frac{\Omega}{\Pi} \leq 1&lt;/math&gt;

and since this ratio can be negative, psin is always [[Bounded function|bounded]] between −1 and +1 by the [[inequality (mathematics)|inequalities]]:

:&lt;math&gt;-1 \leq \operatorname{psin}(\mathbf{v}_1,\dots,\mathbf{v}_n) \leq 1,\,&lt;/math&gt;
as for the ordinary sine, with either bound only being reached in case all vectors are mutually [[orthogonal]].

In case ''n''&amp;nbsp;=&amp;nbsp;2, the polar sine is the ordinary [[sine]] of the angle between the two vectors.

=== {{math|''n''}} vectors in {{math|''m''}}-dimensional space for {{math|''m'' ≥ ''n''}}===

A non-negative version of the polar sine exists, which works in any {{math|''m''}}-dimensional space for {{math|''m'' ≥ ''n''}}.  In this case, the numerator in the definition is given as
:&lt;math&gt;
\Omega  = \sqrt{\det \left(\begin{bmatrix}\mathbf{v}_1 &amp; \mathbf{v}_2 &amp; \cdots &amp; \mathbf{v}_n \end{bmatrix}^T
\begin{bmatrix}\mathbf{v}_1 &amp; \mathbf{v}_2 &amp; \cdots &amp; \mathbf{v}_n \end{bmatrix} \right)} \,,
&lt;/math&gt;
where the superscript T indicates [[matrix transposition]].  In the case that ''m''=''n'', the value of Ω for this non-negative definition of the polar sine is the absolute value of the Ω from the signed version of the polar sine given previously.

==Properties==

;Interchange of vectors

If the dimension of the space is more than ''n'' then the polar sine is non-negative and is unchanged whenever two of the vectors '''v'''&lt;sub&gt;''j''&lt;/sub&gt; and '''v'''&lt;sub&gt;''k''&lt;/sub&gt; are interchanged.  Otherwise, it changes sign whenever two vectors are interchanged - due to the antisymmetry of [[Row operations|row-exchanging]] in the determinant:

:&lt;math&gt; \begin{align} 
\Omega &amp; = \det\begin{bmatrix}\mathbf{v}_1 &amp; \mathbf{v}_2 &amp; \cdots &amp; \mathbf{v}_i &amp; \cdots &amp; \mathbf{v}_j &amp; \cdots &amp; \mathbf{v}_n \end{bmatrix} \\
&amp; = - \det\begin{bmatrix}\mathbf{v}_1 &amp; \mathbf{v}_2 &amp; \cdots &amp; \mathbf{v}_j &amp; \cdots &amp; \mathbf{v}_i &amp; \cdots &amp; \mathbf{v}_n \end{bmatrix} \\
&amp; = - \Omega
\end{align}&lt;/math&gt;

;Invariance under [[scalar multiplication]] of vectors

The polar sine does not change if all of the vectors '''v'''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;'''v'''&lt;sub&gt;''n''&lt;/sub&gt; are multiplied by positive constants ''c&lt;sub&gt;i&lt;/sub&gt;'', due to [[factorization]]:

:&lt;math&gt; \begin{align} 
\operatorname{psin}(c_1 \mathbf{v}_1,\dots, c_n \mathbf{v}_n) &amp; = \frac{\det\begin{bmatrix}c_1\mathbf{v}_1 &amp; c_2\mathbf{v}_2 &amp; \cdots &amp; c_n\mathbf{v}_n \end{bmatrix}}{\prod_{i=1}^n \|c_i \mathbf{v}_i\|} \\[6pt]
&amp; = \frac{\prod_{i=1}^n c_i}{\prod_{i=1}^n |c_i|} \cdot \frac{\det\begin{bmatrix} \mathbf{v}_1 &amp; \mathbf{v}_2 &amp; \cdots &amp; \mathbf{v}_n \end{bmatrix}}{\prod_{i=1}^n \|\mathbf{v}_i\|} \\[6pt]
&amp; = \operatorname{psin}(\mathbf{v}_1,\dots, \mathbf{v}_n)
\end{align}&lt;/math&gt;

If an odd number of these constants are instead negative, then the sign of the polar sine will change; however, its absolute value will remain unchanged.

;Vanishes with linear dependences

If the vectors are not [[linearly independent]], the polar sine will be zero.  This will always be so in the [[degenerate case]] that the number of dimensions {{math|''m''}} is strictly less than the number of vectors {{math|''n''}}.

==History==

Polar sines were investigated by [[Leonhard Euler|Euler]] in the 18th century.&lt;ref&gt;{{cite journal | last1 = Euler | first1 = Leonhard | year = | title = De mensura angulorum solidorum | url = | journal = Leonhardi Euleri Opera Omnia | volume = 26 | issue = | pages = 204–223 }}&lt;/ref&gt;

==See also==

* [[Trigonometric functions]]
* [[List of trigonometric identities]]
* [[Solid angle]]
* [[Simplex]]
* [[Law of sines]]
* [[Cross product]] and [[Seven-dimensional cross product]]
* [[Graded algebra]]
* [[Exterior derivative]]
* [[Differential geometry]]
* [[Volume integral]]
* [[Measure (mathematics)]]
* [[Product integral]]

== References ==
&lt;references/&gt;

== External links ==
* {{MathWorld|PolarSine|Polar Sine}}

[[Category:Polytopes]]
[[Category:Trigonometry]]</text>
      <sha1>hwk48vc3ojju1tbz8eb0d3spd3mkqq9</sha1>
    </revision>
  </page>
  <page>
    <title>Proof of impossibility</title>
    <ns>0</ns>
    <id>3710507</id>
    <revision>
      <id>863726751</id>
      <parentid>813247618</parentid>
      <timestamp>2018-10-12T16:30:52Z</timestamp>
      <contributor>
        <username>Clinamental</username>
        <id>26093074</id>
      </contributor>
      <minor/>
      <comment>**Enigma</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27765">A '''proof of impossibility''', also known as '''negative proof''', proof of an '''impossibility theorem''', or '''negative result''', is a [[Mathematical proof|proof]] demonstrating that a particular problem cannot be solved, or cannot be solved in general. Often proofs of impossibility have put to rest decades or centuries of work attempting to find a solution. To prove that something is impossible is usually much harder than the opposite task; it is necessary to develop a theory.&lt;ref&gt;Pudlák, pp. 255–256.&lt;/ref&gt; Impossibility theorems are usually expressible as universal propositions in logic (see [[universal quantification]]).

One of the most famous proofs of impossibility was the 1882 proof of [[Ferdinand von Lindemann]], showing that the ancient problem of [[squaring the circle]] cannot be solved, because the number [[Pi|{{math|π}}]] is [[Transcendental number|transcendental]] (non-algebraic) and only a subset of the [[algebraic numbers]] can be constructed by compass and straightedge. Two other classical problems—[[trisection|trisecting the general angle]] and [[doubling the cube]]—were also proved impossible in the nineteenth century.

A problem arising in the sixteenth century was that of creating a general formula using radicals expressing the solution of any polynomial equation of fixed degree ''k'', where ''k'' ≥ 5. In the 1820s, the [[Abel–Ruffini theorem]] showed this to be impossible using concepts such as [[solvable group]]s from [[Galois theory]], a new subfield of [[abstract algebra]].

Among the most important proofs of impossibility of the 20th century, were those related to [[undecidable problem|undecidability]], which showed that there are problems that cannot be solved in general by any algorithm at all. The most famous is the [[halting problem]].

In [[computational complexity theory]], techniques like relativization (see [[oracle machine]]) provide "weak" proofs of impossibility excluding certain proof techniques. Other techniques like proofs of [[Completeness (logic)|completeness]] for a [[complexity class]] provide evidence for the difficulty of problems by showing them to be just as hard to solve as other known problems that have proved [[Intractability (complexity)|intractable]].

==Types of impossibility proof==
{{See also|Types of proof}}

===Proof by contradiction===
One widely used type of impossibility proof is [[proof by contradiction]]. In this type of proof it is shown that if something, such as a solution to a particular class of equations, were possible, then two mutually contradictory things would be true, such as a number being both even and odd. The contradiction implies that the original premise is impossible.

====Proof by descent====
{{Main|Proof by infinite descent}}

One type of proof by contradiction is proof by [[infinite descent|descent]]. Here it is postulated that something is possible, such as a solution to a class of equations, and that therefore there must be a smallest solution; then starting from the allegedly smallest solution, it is shown that a smaller solution can be found, contradicting the premise that the former solution was the smallest one possible. Thus the premise that a solution exists must be false.

This method of proof can also be interpreted slightly differently, as the method of ''infinite descent''. One postulates that a positive integer solution exists, whether or not it is the smallest one, and one shows that based on this solution a smaller solution must exist. But by [[mathematical induction]] it follows that a still smaller solution must exist, then a yet smaller one, and so on for an infinite number of steps. But this contradicts the fact that one cannot find smaller and smaller positive integers indefinitely; the contradiction implies that the premise that a solution exists is wrong.

==Types of disproof of impossibility conjectures==
There are two alternative methods of proving wrong a conjecture that something is impossible: by counterexample ([[constructive proof]]) and by logical contradiction ([[non-constructive proof]]).

The obvious way to disprove an impossibility conjecture by providing a single [[counterexample]]. For example, [[Euler's sum of powers conjecture|Euler proposed]] that at least ''n'' different ''n''&lt;sup&gt;th&lt;/sup&gt; powers were necessary to sum to yet another ''n''&lt;sup&gt;th&lt;/sup&gt; power. The conjecture was disproved in 1966 with a counterexample involving a count of only four different 5th powers summing to another fifth power:
:27&lt;sup&gt;5&lt;/sup&gt; + 84&lt;sup&gt;5&lt;/sup&gt; + 110&lt;sup&gt;5&lt;/sup&gt; + 133&lt;sup&gt;5&lt;/sup&gt; = 144&lt;sup&gt;5&lt;/sup&gt;.
A proof by counterexample is a [[constructive proof]].

In contrast, a [[non-constructive proof]] that something is ''not'' impossible proceeds by showing it is logically contradictory for ''all'' possible counterexamples to be invalid: At least ''one'' of the items on a list of possible counterexamples must actually be a valid counterexample to the impossibility conjecture. For example, a conjecture that it is impossible for an irrational power raised to an irrational power to be rational [[Irrational number#Irrational powers|was disproved]] by showing that one of two possible counterexamples must be a valid counterexample, without showing which one it is.

==The existence of irrational numbers: The Pythagoreans' proof==
The proof by [[Pythagoras]] (or more likely one of his students) about 500&amp;nbsp;[[BCE]] has had a profound effect on mathematics. It shows that the [[square root of 2]] cannot be expressed as the ratio of two integers (counting numbers). The proof bifurcated "the numbers" into two non-overlapping collections—the [[rational numbers]] and the [[irrational numbers]]. This bifurcation was used by [[Georg Cantor|Cantor]] in his [[Cantor's diagonal argument|diagonal method]], which in turn was used by Turing in his proof that the ''[[Entscheidungsproblem]]'' (the [[decision problem]] of [[David Hilbert|Hilbert]]) is undecidable.

{{quote|text=It is unknown when, or by whom, the "theorem of Pythagoras" was discovered. The discovery can hardly have been made by Pythagoras himself, but it was certainly made in his school. Pythagoras lived about 570&amp;ndash;490&amp;nbsp;BCE. Democritus, born about 470&amp;nbsp;BCE, wrote ''on irrational lines and solids''&amp;nbsp;...|source={{citation needed|date=July 2017}}|author=Heath}}

Proofs followed for various square roots of the primes up to 17.
&lt;blockquote&gt;
There is a famous passage in [[Plato]]'s ''[[Theaetetus (dialogue)|Theaetetus]]'' in which it is stated that [[Teodorus]] (Plato's teacher) proved the irrationality of
:&lt;math&gt;\sqrt{3}, \sqrt{5}, ...,&lt;/math&gt;
taking all the separate cases up to the root of 17&amp;nbsp;square feet&amp;nbsp;...&amp;thinsp;.&lt;ref&gt;Hardy and Wright, p.&amp;nbsp;42&lt;/ref&gt;
&lt;/blockquote&gt;

A more general proof now exists that:

:The ''m''th root of an integer ''N'' is irrational, unless ''N'' is the ''m''th power of an integer ''n''".&lt;ref&gt;Hardy and Wright, p.&amp;nbsp;40&lt;/ref&gt;

That is,  it is impossible to express the ''m''th root of an integer ''N'' as the ratio {{frac|''a''|''b''}} of two integers ''a'' and ''b'' that share no common [[prime factor]] except in cases in which ''b''&amp;nbsp;=&amp;nbsp;1.

==Impossible constructions sought by the ancient Greeks==
Three famous questions of [[compass and straightedge constructions|Greek geometry]] were how:

# ...&amp;nbsp;with compass and straight-edge to [[trisect any angle]],
# to construct a cube with a volume [[Doubling the cube|twice the volume of a given cube]]
# to construct a square [[squaring the circle|equal in area]] to that of a given circle.

For more than 2,000&amp;nbsp;years unsuccessful attempts were made to solve these problems; at last, in the 19th&amp;nbsp;century it was proved that the desired constructions are logically impossible.&lt;ref&gt;Nagel and Newman p.&amp;nbsp;8&lt;/ref&gt;

A fourth problem of the ancient Greeks was to construct an [[equilateral polygon]] with a specified number ''n'' of sides, beyond the basic cases ''n''&amp;nbsp;=&amp;nbsp;3, 4, 5 that they knew how to construct.

All of these are problems in [[Constructible number|Euclidean construction]], and Euclidean constructions can be done only if they involve only [[Euclidean number]]s (by definition of the latter) (Hardy and Wright p.&amp;nbsp;159). Irrational numbers can be Euclidean. A good example is the irrational number the square root of 2. It is simply the length of the hypotenuse of a right triangle with legs both one unit in length, and it can be constructed with straightedge and compass. But it was proved centuries after Euclid that Euclidean numbers cannot involve any operations other than addition, subtraction, multiplication, division, and the extraction of square roots.

===Angle trisection and doubling the cube===
Both [[trisecting the angle|trisecting the general angle]] and [[doubling the cube]] require taking [[cube root]]s, which are not [[constructible numbers]] by compass and straightedge.

===Squaring the circle===
&lt;blockquote&gt;&lt;math&gt;\pi&lt;/math&gt; is not a [[Euclidean number]] ... and therefore it is impossible to construct, by Euclidean methods a length equal to the circumference of a circle of unit diameter&lt;ref&gt;Hardy and Wright p.&amp;nbsp;176&lt;/ref&gt;&lt;/blockquote&gt;

A proof exists to demonstrate that any Euclidean number is an [[algebraic number]]—a number that is the solution to some [[polynomial equation]]. Therefore, because &lt;math&gt;\pi&lt;/math&gt; was proved in 1882 to be a [[transcendental number]] and thus by definition not an algebraic number, it is not a Euclidean number. Hence the construction of a length &lt;math&gt;\pi&lt;/math&gt; from a unit circle is impossible&lt;ref&gt;Hardy and Wright p.&amp;nbsp;159 referenced by E. Hecke. (1923). ''Vorlesungen über die Theorie der algebraischen Zahlen''. Leipzig: Akademische Verlagsgesellschaft&lt;/ref&gt;, and the circle cannot be squared.

===Constructing an equilateral ''n''-gon===
The [[Constructible polygon#Conditions for constructibility|Gauss-Wantzel theorem]] showed in 1837 that constructing an equilateral ''n''-gon is impossible for most values of ''n''.

==Euclid's parallel axiom==
{{Main|Non-Euclidean geometry}}
Nagel and Newman consider the question raised by the [[parallel postulate]] to be "...perhaps the most significant development in its long-range effects upon subsequent mathematical history" (p.&amp;nbsp;9).

The question is: can the axiom that two parallel lines "...will not meet even 'at infinity'" (footnote, ibid) be derived from the other axioms of Euclid's geometry? It was not until work in the nineteenth century by "... Gauss, Bolyai, Lobachevsky, and Riemann, that the impossibility of deducing the parallel axiom from the others was demonstrated. This outcome was of the greatest intellectual importance. ...a ''proof'' can be given of the ''impossibility of proving'' certain propositions [in this case, the parallel postlate] within a given system [in this case, Euclid's first four postulates]". (p.&amp;nbsp;10)

==Fermat's Last Theorem==
{{Main|Fermat's Last Theorem}}

[[Fermat's Last Theorem]] was conjectured by [[Pierre de Fermat]] in the 1600s, states the impossibility of finding solutions in positive integers for the equation &lt;math&gt;x^n+y^n=z^n&lt;/math&gt; with &lt;math&gt;n&gt;2&lt;/math&gt;. [[Pierre de Fermat|Fermat]] himself gave a proof for the ''n''&amp;nbsp;=&amp;nbsp;4 case using his technique of [[infinite descent]], and other special cases were subsequently proved, but the general case was not proved until 1994 by [[Andrew Wiles]].

==Richard's paradox==
{{Main|Richard's paradox}}
This profound paradox presented by [[Jules Richard]] in 1905 informed the work of [[Kurt Gödel]] (cf Nagel and Newman p.&amp;nbsp;60ff) and Alan Turing. A succinct definition is found in ''[[Principia Mathematica]]''&lt;ref&gt;[http://quod.lib.umich.edu/u/umhistmath/AAT3201.0001.001/86?rgn=full+text;view=pdf ''Principia Mathematica'', 2nd edition 1927, p.&amp;nbsp;61, 64] in [http://quod.lib.umich.edu/cgi/t/text/text-idx?c=umhistmath;idno=AAT3201.0001.001 ''Principia Mathematica online'', Vol.1] at University of Michigan Historical Math Collection&lt;/ref&gt;:
{{quote|text=Richard's paradox ... is as follows. Consider all decimals that can be defined by means of a '''finite number of''' '''''words''''' &lt;small&gt;[“words” are symbols; boldface added for emphasis]&lt;/small&gt;; let ''E'' be the class of such decimals. Then ''E'' has &lt;math&gt;\aleph_0&lt;/math&gt; &lt;small&gt;[an infinite number of]&lt;/small&gt; terms; hence its members can be ordered as the 1st, 2nd, 3rd, ... Let ''X'' be a number defined as follows &lt;small&gt;[Whitehead &amp; Russell now employ the Cantor diagonal method]&lt;/small&gt;.
&lt;br/&gt;If the ''n''-th figure in the ''n''-th decimal is ''p'', let the ''n''-th figure in ''X'' be ''p''&amp;nbsp;+&amp;nbsp;1 (or 0, if ''p''&amp;nbsp;=&amp;nbsp;9). Then ''X'' is different from all the members of ''E'', since, whatever finite value ''n'' may have, the ''n''-th figure in ''X'' is different from the ''n''-th figure in the ''n''-th of the decimals composing ''E'', and therefore ''X'' is different from the ''n''-th decimal. Nevertheless we have defined ''X'' in a finite number of words &lt;small&gt;[i.e. this very definition of “word” above.]&lt;/small&gt; and therefore ''X'' ought to be a member of ''E''. Thus ''X'' both is and is not a member of E.|source=''Principia Mathematica'', 2nd edition 1927, p.&amp;nbsp;61}}

Kurt Gödel considered his proof to be “an analogy” of Richard's paradox, which he called “''Richard's antinomy''”.&lt;ref&gt;Gödel in ''Undecidable'', p.&amp;nbsp;9&lt;/ref&gt; See more below about Gödel's proof.

[[Alan Turing]] constructed this paradox with a machine and proved that this machine could not answer a simple question: will this machine be able to determine if any machine (including itself) will become trapped in an unproductive ‘[[infinite loop]]’ (i.e. it fails to continue its computation of the diagonal number).

==Can this theorem be proved from these axioms? Gödel's proof==
{{Main|Gödel's incompleteness theorems}}
To quote Nagel and Newman (p.&amp;nbsp;68), "Gödel's paper is difficult. Forty-six preliminary definitions, together with several important preliminary theorems, must be mastered before the main results are reached" (p.&amp;nbsp;68). In fact, Nagel and Newman required a 67-page introduction to their exposition of the proof. But if the reader feels strong enough to tackle the paper, Martin Davis observes that "This remarkable paper is not only an intellectual landmark, but is written with a clarity and vigor that makes it a pleasure to read" (Davis in Undecidable, p.&amp;nbsp;4). It is recommended{{By whom|date=August 2010}} that most readers see Nagel and Newman first.

So what did Gödel prove? In his own words:

: "It is reasonable... to make the conjecture that ...[the] axioms [from [[Principia Mathematica]] and [[Peano]] ] are ... sufficient to decide all mathematical questions which can be formally expressed in the given systems. In what follows it will be shown that this is not the case, but rather that ... there exist relatively simple problems of the theory of ordinary whole numbers which cannot be decided on the basis of the axioms" (Gödel in Undecidable, p. 4).

Gödel compared his proof to "Richard's antinomy" (an "[[antinomy]]" is a contradiction or a paradox; for more see [[Richard's paradox]]):

: "The analogy of this result with Richard's antinomy is immediately evident; there is also a close relationship [14] with the [[Liar Paradox]] (Gödel's footnote 14: Every [[epistemological]] antinomy can be used for a similar proof of undecidability)... Thus we have a proposition before us which asserts its own unprovability [15]. (His footnote 15: Contrary to appearances, such a proposition is not circular, for, to begin with, it asserts the unprovability of a quite definite formula)" (Gödel in Undecidable, p.9).

==Will this computing machine lock in a "circle"? Turing's first proof==
* The ''[[Entscheidungsproblem]]'', the [[decision problem]], was first answered by Church in April 1935 and preempted Turing by over a year, as Turing's paper was received for publication in May 1936. (Also received for publication in 1936—in October, later than Turing's—was a short paper by Emil Post that discussed the reduction of an algorithm to a simple machine-like "method" very similar to Turing's computing machine model (see [[Post–Turing machine]] for details).
* Turing's proof is made difficult by number of definitions required and its subtle nature. See [[Turing machine]] and [[Turing's proof]] for details.
* Turing's first proof (of three) follows the schema of Richard's Paradox: Turing's computing machine is an algorithm represented by a string of seven letters in a "computing machine". Its "computation" is to test ''all'' computing machines (including itself) for "circles", and form a diagonal number from the computations of the non-circular or "successful" computing machines. It does this, starting in sequence from 1, by converting the numbers (base 8) into strings of seven letters to test. When it arrives at its own number, it creates ''its own'' letter-string. It decides it is the letter-string of a successful machine, but when it tries to do this machine's (''its own'') computation it locks in a circle and can't continue. Thus we have arrived at Richard's paradox. (If you are bewildered see Turing's proof for more).

A number of similar undecidability proofs appeared soon before and after Turing's proof:

# April 1935: Proof of [[Alonzo Church]] (''An Unsolvable Problem of Elementary Number Theory''). His proof was to "...propose a definition of effective calculability ... and to show, by means of an example, that not every problem of this class is solvable" (Undecidable p.&amp;nbsp;90))
# 1946: [[Post correspondence problem]] (cf Hopcroft and Ullman&lt;ref name="Hopcroft.Ullman.1979"&gt;{{cite book| author=[[John E. Hopcroft]], [[Jeffrey D. Ullman]]| title=Introduction to Automata Theory, Languages, and Computation| year=1979| publisher=Addison-Wesley| isbn=0-201-02988-X}}&lt;/ref&gt; p.&amp;nbsp;193ff, p.&amp;nbsp;407 for the reference)
# April 1947: Proof of [[Emil Post]] (''Recursive Unsolvability of a Problem of Thue'') (Undecidable p.&amp;nbsp;293). This has since become known as "The Word problem of Thue" or "Thue's Word Problem" ([[Axel Thue]] proposed this problem in a paper of 1914 (cf References to Post's paper in Undecidable, p.&amp;nbsp;303)).
# [[Rice's theorem]]: a generalized formulation of Turing's second theorem (cf Hopcroft and Ullman&lt;ref name="Hopcroft.Ullman.1979"/&gt; p.&amp;nbsp;185ff)&lt;ref&gt;"...there can be no machine E which ... will determine whether M [an arbitrary machine] ever prints a given symbol (0 say)" (Undecidable p. 134). Turing makes an odd assertion at the end of this proof that sounds remarkably like Rice's Theorem:
:"...each of these "general process" problems can be expressed as a problem concerning a general process for determining whether a given integer n has a property G(n)... and this is equivalent to computing a number whose nth figure is 1 if G(n) is true and 0 if it is false" (Undecidable p 134). Unfortunately he doesn't clarify the point further, and the reader is left confused.
&lt;/ref&gt;
# [[Greibach's theorem]]: undecidability in language theory (cf Hopcroft and Ullman&lt;ref name="Hopcroft.Ullman.1979"/&gt; p.&amp;nbsp;205ff and reference on p.&amp;nbsp;401 ibid: [[Sheila Greibach|Greibach]] [1963] "The undecidability of the ambiguity problem for minimal lineal grammars," ''Information and Control'' 6:2, 117–125, also reference on p.&amp;nbsp;402 ibid: Greibach [1968] "A note on undecidable properties of formal languages", Math Systems Theory 2:1, 1–6.)
# [[Penrose tiling]] questions
# Question of solutions for [[Diophantine equations]] and the resultant answer in the MRDP Theorem; see entry below.

==Can this string be compressed? Chaitin's proof==
{{Main|Chaitin's incompleteness theorem}}
For an exposition suitable for non-specialists see Beltrami p.&amp;nbsp;108ff. Also see Franzen Chapter 8 pp.&amp;nbsp;137–148, and Davis pp.&amp;nbsp;263–266. Franzén's discussion is significantly more complicated than Beltrami's and delves into Ω—[[Gregory Chaitin]]'s so-called "halting probability". Davis's older treatment approaches the question from a [[Turing machine]] viewpoint. Chaitin has written a number of books about his endeavors and the subsequent philosophic and mathematical fallout from them.

A string is [[Kolmogorov complexity#Kolmogorov randomness|called]] ''(algorithmically) random'' if it cannot be produced from any shorter computer program. While [[Kolmogorov complexity#Compression|most strings are random]], no particular one can be proved so, except for finitely many short ones:

: "A paraphrase of Chaitin's result is that there can be no formal proof that a sufficiently long string is random..." (Beltrami p. 109)

Beltrami observes that "Chaitin's proof is related to a paradox posed by Oxford librarian G. Berry early in the twentieth century that asks for 'the smallest positive integer that cannot be defined by an English sentence with fewer than 1000 characters.' Evidently, the shortest definition of this number must have at least 1000 characters. However, the sentence within quotation marks, which is itself a definition of the alleged number is less than 1000 characters in length!" (Beltrami, p.&amp;nbsp;108)

==Does this Diophantine equation have an integer solution? Hilbert's tenth problem==
{{Main|Matiyasevich's theorem|Hilbert's problems}}

The question "Does any arbitrary "Diophantine equation" have an integer solution?" is [[Undecidable problem|undecidable]].That is, it is impossible to answer the question for all cases.

Franzén introduces [[Hilbert's tenth problem]] and the [[Matiyasevich's theorem|MRDP theorem]] (Matiyasevich-Robinson-Davis-Putnam theorem) which states that "no algorithm exists which can decide whether or not a Diophantine equation has ''any'' solution at all".  MRDP uses the undecidability proof of Turing: "... the set of solvable Diophantine equations is an example of a computably enumerable but not decidable set, and the set of unsolvable Diophantine equations is not computably enumerable" (p.&amp;nbsp;71).

==In social science==
In [[political science]], [[Arrow's impossibility theorem]] states that it is impossible to devise a [[voting system]] that satisfies a set of five specific axioms. This theorem is proved by showing that four of the axioms together imply the opposite of the fifth.

In [[economics]], [[Holmström's theorem]] is an impossibility theorem proving that no incentive system for a team of agents can satisfy all of three desirable criteria.

==In natural science==
In [[natural science]], impossibility assertions (like other assertions) come to be widely accepted as overwhelmingly probable rather than considered proved to the point of being unchallengeable. The basis for this strong acceptance is a combination of extensive evidence of something not occurring, combined with an underlying theory, very successful in making predictions, whose assumptions lead logically to the conclusion that something is impossible.

Two examples of widely accepted impossibilities in [[physics]] are [[perpetual motion machine]]s, which violate the law of [[conservation of energy]], and exceeding the [[speed of light]], which violates the implications of [[special relativity]]. Another is the [[uncertainty principle]] of [[quantum mechanics]], which asserts the impossibility of simultaneously knowing both the position and the momentum of a particle. Also [[Bell's theorem]]: no physical theory of local hidden variables can ever reproduce all of the predictions of quantum mechanics.

While an impossibility assertion in science can never be absolutely proved, it could be refuted by the observation of a single [[counterexample]]. Such a counterexample would require that the assumptions underlying the theory that implied the impossibility be re-examined.

==See also==
* [[List of unsolved problems in mathematics]]{{snd}}Solutions of these problems are still searched for. In contrast, the above problems are ''known'' to have no solution.
* [[No-go theorem]], the corresponding physical notion.

==Notes==
{{Reflist}}

==References==
{{refbegin|30em}}
* [[G. H. Hardy]] and [[E. M. Wright]], ''An Introduction to the Theory of Numbers'', Fifth Edition, Clarendon Press, Oxford England, 1979, reprinted 2000 with General Index (first edition: 1938). The proofs that e and pi are transcendental are not trivial, but a mathematically adept reader will be able to wade through them.
* [[Alfred North Whitehead]] and [[Bertrand Russell]], ''Principia Mathematica'' to *56, Cambridge at the University Press, 1962, reprint of 2nd edition 1927, first edition 1913. Chap. 2.I. "The Vicious-Circle Principle" p.&amp;nbsp;37ff, and Chap. 2.VIII. "The Contradictions" p.&amp;nbsp;60ff.
*  {{ Citation | last= Turing | first= A.M. | publication-date = 1937 | year = 1936 | title = On Computable Numbers, with an Application to the Entscheidungsproblem | periodical = Proceedings of the London Mathematical Society | series = 2 | volume = 42 | issue= 1 | pages = 230–65 | doi= 10.1112/plms/s2-42.1.230 }} (and {{Citation | last = Turing | first = A.M. | publication-date = 1937 | title = On Computable Numbers, with an Application to the Entscheidungsproblem: A correction | periodical = Proceedings of the London Mathematical Society | series = 2 | volume = 43 | issue = 6 | pages = 544–6 | doi = 10.1112/plms/s2-43.6.544 | year = 1938 }}). [http://www.turingarchive.org/browse.php/B/12 online version] This is the epochal paper where Turing defines [[Turing machine]]s and shows that it (as well as the [[Entscheidungsproblem]]) is unsolvable.
* [[Martin Davis]], ''The Undecidable, Basic Papers on Undecidable Propositions, Unsolvable Problems And Computable Functions'', Raven Press, New York, 1965. Turing's paper is #3 in this volume. Papers include those by Godel, Church, Rosser, Kleene, and Post.
* Martin Davis's chapter "What is a Computation" in Lynn Arthur Steen's ''Mathematics Today'', 1978, Vintage Books Edition, New York, 1980. His chapter describes Turing machines in the terms of the simpler [[Post–Turing machine]], then proceeds onward with descriptions of Turing's first proof and Chaitin's contributions.
* [[Andrew Hodges]], ''Alan Turing: The Enigma'', Simon and Schuster, New York. Cf Chapter "The Spirit of Truth" for a history leading to, and a discussion of, his proof.
* [[Hans Reichenbach]], ''Elements of Symbolic Lo''gic, Dover Publications Inc., New York, 1947. A reference often cited by other authors.
* [[Ernest Nagel]] and [[James R. Newman|James Newman]], [https://archive.org/details/gdelsproof00nage ''Gödel's Proof''], New York University Press, 1958.
* [[Edward Beltrami]], ''What is Random? Chance and Order in Mathematics and Life'', Springer-Verlag New York, Inc., 1999.
* [[Torkel Franzén]], ''Godel's Theorem, An Incomplete Guide to Its Use and Abuse'', A.K. Peters, Wellesley Mass, 2005. A recent take on Gödel's Theorems and the abuses thereof. Not so simple a read as the author believes it is. Franzén's (blurry) discussion of Turing's 3rd proof is useful because of his attempts to clarify terminology. Offers discussions of Freeman Dyson's, Stephen Hawking's, Roger Penrose's and Gregory Chaitin's arguments (among others) that use Gödel's theorems, and useful criticism of some philosophic and metaphysical Gödel-inspired dreck that he's found on the web.
* Pavel Pudlák, ''Logical Foundations of Mathematics and Computational Complexity. A Gentle Introduction'', Springer 2013. (See Chapter 4 "Proofs of impossibility".)
{{refend}}

{{DEFAULTSORT:Proof Of Impossibility}}
[[Category:Mathematical logic]]
[[Category:Mathematical proofs]]
[[Category:Possibility]]
[[Category:Methods of proof]]</text>
      <sha1>3n6uwl6hihknbcytahyu1drhm0m3m68</sha1>
    </revision>
  </page>
  <page>
    <title>Quadratic integral</title>
    <ns>0</ns>
    <id>518991</id>
    <revision>
      <id>786987807</id>
      <parentid>707287093</parentid>
      <timestamp>2017-06-22T19:18:24Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words for MathSciNet per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3538">In [[mathematics]], a '''quadratic integral''' is an [[integral]] of the form

:&lt;math&gt;\int \frac{dx}{a+bx+cx^2}. &lt;/math&gt;

It can be evaluated by [[completing the square]] in the [[denominator]].

:&lt;math&gt;\int \frac{dx}{a+bx+cx^2} = \frac{1}{c} \int  \frac{dx}{\left( x+ \frac{b}{2c} \right)^2 + \left( \frac{a}{c} - \frac{b^2}{4c^2} \right)}. &lt;/math&gt;

==Positive-discriminant case==

Assume that the [[discriminant]] ''q'' = ''b''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;4''ac'' is positive. In that case, define ''u'' and ''A'' by

:&lt;math&gt;u = x + \frac{b}{2c} &lt;/math&gt;,

and

:&lt;math&gt; -A^2 = \frac{a}{c} - \frac{b^2}{4c^2} = \frac{1}{4c^2} \left( 4ac - b^2 \right). &lt;/math&gt;

The quadratic integral can now be written as

:&lt;math&gt; \int \frac{dx}{a+bx+cx^2} = \frac1c \int \frac{du}{u^2-A^2} = \frac1c \int \frac{du}{(u+A)(u-A)}. &lt;/math&gt;

The [[partial fraction decomposition]]

:&lt;math&gt; \frac{1}{(u+A)(u-A)} = \frac{1}{2A} \left( \frac{1}{u-A} - \frac{1}{u+A} \right) &lt;/math&gt;

allows us to evaluate the integral:

:&lt;math&gt; \frac1c \int \frac{du}{(u+A)(u-A)} = \frac{1}{2Ac} \ln \left( \frac{u - A}{u + A} \right) + \text{constant}. &lt;/math&gt;

The final result for the original integral, under the assumption that ''q'' &gt; 0, is

:&lt;math&gt; \int \frac{dx}{a+bx+cx^2} = \frac{1}{ \sqrt{q}} \ln \left( \frac{2cx + b - \sqrt{q}}{2cx+b+ \sqrt{q}} \right) + \text{constant, where } q = b^2 - 4ac. &lt;/math&gt;

==Negative-discriminant case==

:''This (hastily written) section may need attention.''

In case the [[discriminant]] ''q'' = ''b''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;4''ac'' is negative, the second term in the denominator in

:&lt;math&gt;\int \frac{dx}{a+bx+cx^2} = \frac{1}{c} \int  \frac{dx}{\left( x+ \frac{b}{2c} \right)^2 + \left( \frac{a}{c} - \frac{b^2}{4c^2} \right)}. &lt;/math&gt;

is positive.  Then the integral becomes

:&lt;math&gt;
\begin{align}
&amp; {} \qquad \frac{1}{c} \int \frac{ du} {u^2 + A^2} \\[9pt]
&amp; = \frac{1}{cA} \int \frac{du/A}{(u/A)^2 + 1 } \\[9pt]
&amp; = \frac{1}{cA} \int \frac{dw}{w^2 + 1} \\[9pt]
&amp; = \frac{1}{cA} \arctan(w) + \mathrm{constant} \\[9pt]
&amp; = \frac{1}{cA} \arctan\left(\frac{u}{A}\right) + \text{constant} \\[9pt]
&amp; = \frac{1}{c\sqrt{\frac{a}{c} - \frac{b^2}{4c^2}}} \arctan
\left(\frac{x + \frac{b}{2c}}{\sqrt{\frac{a}{c} - \frac{b^2}{4c^2}}}\right) + \text{constant} \\[9pt]
&amp; = \frac{2}{\sqrt{4ac - b^2\, }}
\arctan\left(\frac{2cx + b}{\sqrt{4ac - b^2}}\right) + \text{constant}.
\end{align}
&lt;/math&gt;

==References==
*Weisstein, Eric W. "[http://mathworld.wolfram.com/QuadraticIntegral.html Quadratic Integral]." From ''MathWorld''--A Wolfram Web Resource, wherein the following is referenced:
*{{cite book |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |author-first5=Alan |author-last5=Jeffrey |editor-first1=Daniel |editor-last1=Zwillinger |editor-first2=Victor Hugo |editor-last2=Moll |translator=Scripta Technica, Inc. |title=Table of Integrals, Series, and Products |publisher=[[Academic Press, Inc.]] |date=2015 |orig-year=October 2014 |edition=8 |language=English |isbn=0-12-384933-0 |id={{isbn|978-0-12-384933-5}} |lccn=2014010276 &lt;!-- |url=http://books.google.com/books?id=NjnLAwAAQBAJ |access-date=2016-02-21--&gt;|title-link=Gradshteyn and Ryzhik}}

[[Category:Integral calculus]]</text>
      <sha1>inreyeal8b8o1ec1kdkljem33y8g8e8</sha1>
    </revision>
  </page>
  <page>
    <title>Seriation (statistics)</title>
    <ns>0</ns>
    <id>55283391</id>
    <revision>
      <id>814593780</id>
      <parentid>814593738</parentid>
      <timestamp>2017-12-09T19:37:15Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <minor/>
      <comment>/* References */ removed sort key</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="628">In [[combinatorial data analysis]], '''seriation''' is the process of finding an arrangement of all objects in a set, in a [[linear order]], given a [[loss function]].&lt;ref&gt;{{cite journal |doi=10.18637/jss.v025.i03 |title=Getting Things in Order: An Introduction to the R Package seriation |journal=Journal of Statistical Software |volume=25 |issue=3 |year=2008 |last1=Hahsler |first1=Michael |last2=Hornik |first2=Kurt |last3=Buchta |first3=Christian}}&lt;/ref&gt; The main goal is exploratory, to reveal structural information.

== References ==
{{reflist}}

{{statistics-stub}}

[[Category:Combinatorics]]
[[Category:Data analysis]]</text>
      <sha1>edjnia6z3thd8khlz547y9b3ja069q5</sha1>
    </revision>
  </page>
  <page>
    <title>Sherry Gong</title>
    <ns>0</ns>
    <id>30696913</id>
    <revision>
      <id>870763013</id>
      <parentid>866171419</parentid>
      <timestamp>2018-11-26T21:21:19Z</timestamp>
      <contributor>
        <username>Zanhe</username>
        <id>10400497</id>
      </contributor>
      <comment>added [[Category:American scientists of Chinese descent]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4815">'''Sherry Gong''' is an American mathematician specializing in [[low-dimensional topology]] and known for her performance on [[mathematics competition]]s. She is a Hedrick Assistant Adjunct Professor at the [[University of California, Los Angeles]].&lt;ref&gt;{{cite web|url=https://www.math.ucla.edu/people/visiting/sgongli|title=Sherry Gong|publisher=UCLA Mathematics|accessdate=2018-10-28}}&lt;/ref&gt;

==Early life and education==
Gong was born in [[New York City]] as the daughter of two mathematics professors, Guihua Gong and Liangqing Li, both affiliated with the University of Puerto Rico. She grew up in [[Toronto]], [[Puerto Rico]], and [[New Hampshire]].&lt;ref name=claymath1&gt;{{cite web|url=http://www.claymath.org/news/olympiad2005.php|archive-url=https://web.archive.org/web/20120511053020/http://claymath.org/news/olympiad2005.php|archive-date=2012-05-11|title=Sherry Gong named Clay Olympiad Scholar|date=June 27, 2005|publisher=[[Clay Mathematics Institute]]}}&lt;/ref&gt;

She received her AB in Mathematics from Harvard College, and 
became a graduate student in mathematics at [[MIT]]. She completed her Ph.D. there in 2018; her dissertation, ''Results on Spectral Sequences for Monopole and Singular Instanton Floer Homologies'', was supervised by [[Tomasz Mrowka]].&lt;ref&gt;{{mathgenealogy|id=239371}}&lt;/ref&gt;

==Mathematics competitions==
Gong is the second U.S. woman (after [[Alison Miller]] won in 2004&lt;ref&gt;[http://mathforum.org/announce/congrats_alison.html Math Forum @ Drexel: Congratulations, Alison!&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;) to win a gold medal in the [[International Mathematical Olympiad]], which Gong won in 2007, earning a tie for seventh place out of 536 participants&lt;ref name="Maa.org"&gt;{{cite web|url=http://www.maa.org/news/091907gong.html |title=Math Competitions: Sherry Gong's Striking Success |publisher=Maa.org |date=2007-09-19 |accessdate=2011-04-09}}&lt;/ref&gt; (she scored a 32).  She was the only woman on the U.S. team that year, and also one of only three women ever to make the U.S. team.&lt;ref name="Maa.org"/&gt; She also tied for first place in the China Mathematical Olympiad for Girls in 2007.&lt;ref name="Maa.org"/&gt; Gong attended a mathematics Olympiad for the first time when she was in the sixth grade — the 3rd Olympiada Matematica de Centroamerica y el Caribe, in [[Colombia]].&lt;ref name=claymath1/&gt; There she received a silver medal and also a special award for the most original solution. It was the first such award in the history of that Olympiad.&lt;ref name=claymath1/&gt;

Gong participated in IMO five times, winning HM in 2002, bronze in 2003, silver in 2004 and 2005 and gold in 2007. In 2005 she was named the 2005 Clay Olympiad Scholar; the Clay Olympiad Scholar Award recognizes the most original solution to a problem on the US American Mathematics Olympiad (USAMO).&lt;ref name="claymath1"/&gt; In 2006 she earned a silver medal at the 2006 International Physics Olympiad.&lt;ref&gt;[http://www.aps.org/publications/capitolhillquarterly/200611/olympiad.cfm American Physical Society website, article title "US Team Garners 4 Gold, 1 Silver at Physics Olympiad in Singapore."]&lt;/ref&gt; She was a winner (top twelve) at the United States of America Mathematical Olympiad in 2005, 2006, and 2007, including placing 2nd in 2007.

As a Harvard freshman, Gong scored over 100 in Harvard’s famous problem solving course, [[Math 55]], which required perfect scores on all assignments, tests, bonus problems, and the final exam.&lt;ref name="thecrimson1"&gt;{{cite web|last=Timmerman |first=Michelle B. |url=http://www.thecrimson.com/article/2010/12/10/math-gong-hristov-gongs/ |title=Sherry Gong &amp;#124; FM &amp;#124; The Harvard Crimson |publisher=Thecrimson.com |date=2010-12-10 |accessdate=2011-04-09}}&lt;/ref&gt; In 2010 Gong helped coach the U.S. team that competed in the China Girls’ Mathematical Olympiad; five team members won gold medals.&lt;ref name="autogenerated1"&gt;{{cite web|url=http://mathdl.maa.org/mathDL?pa=mathNews&amp;sa=view&amp;newsId=1030 |title=Math In The News |publisher=Mathdl.maa.org |date= |accessdate=2011-04-09}}&lt;/ref&gt; In 2011 she won the Alice T. Schafer Prize for Excellence in Mathematics by an Undergraduate Woman.&lt;ref name="autogenerated1"/&gt;

== References ==
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

{{authority control}}

{{DEFAULTSORT:Gong, Sherry}}
[[Category:Living people]]
[[Category:Year of birth missing (living people)]]
[[Category:Articles created via the Article Wizard]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Harvard University alumni]]
[[Category:Massachusetts Institute of Technology people]]
[[Category:International Mathematical Olympiad participants]]
[[Category:American scientists of Chinese descent]]</text>
      <sha1>jn430dggux806yd5pgdbbifm2gsqzgv</sha1>
    </revision>
  </page>
  <page>
    <title>Special Interest Group</title>
    <ns>0</ns>
    <id>318060</id>
    <revision>
      <id>839681598</id>
      <parentid>827920483</parentid>
      <timestamp>2018-05-05T00:37:44Z</timestamp>
      <contributor>
        <username>Emguzy</username>
        <id>33441347</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5175">{{About|technical or social associations|other uses|Interest group (disambiguation)}}
{{redirects here|Special interest group|political advocacy groups|Special interests}}
A '''Special Interest Group''' ('''SIG''') is a community within a larger organization with a shared interest in advancing a specific area of knowledge, learning or technology where members cooperate to affect or to produce solutions within their particular field, and may communicate, meet, and organize [[business conference|conferences]]. The term was used in 1961 by the [[Association for Computing Machinery]] (ACM), an academic and professional computer society.&lt;ref&gt;{{cite web|title=Sig conference community|url=http://historywiki.acm.org/sigs/Main_Page|website=historywiki.acm.org|language=en}}&lt;/ref&gt; SIG was later popularized on [[CompuServe]], an early [[online service provider]], where SIGs were a section of the service devoted to particular interests.&lt;ref&gt;[http://www.trs-80.org/compuserve/ CompuServe]. Trs-80.org (1980-07-01). Retrieved on 2014-06-16.&lt;/ref&gt;&lt;ref&gt;[http://www.gsbrown.org/compuserve/sigs-1982-04/ SIGs]. Gsbrown.org (2010-04-08). Retrieved on 2014-06-16.&lt;/ref&gt;&lt;ref&gt;[http://www.computercraft.com/docs/modem.html Modems - The Secret Guide to Computers]. Computercraft.com. Retrieved on 2014-06-16.&lt;/ref&gt;

==Technical SIGs==
The ACM includes many [[Association for Computing Machinery#Special Interest Groups|SIGs]], some starting as smaller "Special Interest Committees" (SICs) and formed the first group in 1961. ACM supports further subdivision within SIGs for more impromptu informal discussion groups at conferences which are called [[Birds of a feather (computing)|Birds of a Feather]] (BoF).&lt;ref&gt;{{cite web|title=Birds-of-a-feather FAQ|url=http://sc17.supercomputing.org/submitters/birds-of-a-feather-faq/|website=SC17|date=14 October 2016}}&lt;/ref&gt;
&lt;blockquote&gt;ACM's Special Interest Groups (SIGs) represent major areas of computing, addressing the interests of technical communities that drive innovation. SIGs offer a wealth of conferences, publications and activities focused on specific computing sub-disciplines. They enable members to share expertise, discovery and best practices.&lt;ref&gt;{{cite web|title=Special Interest Groups|url=https://www.acm.org/special-interest-groups|website=www.acm.org|language=en}}&lt;/ref&gt;&lt;/blockquote&gt;
The [[Mathematical Association of America]] has 14 SIGs ranging from the Arts to the Web (for instruction).&lt;ref&gt;
{{cite web |url=http://www.maa.org/SIGMAA/ |title=SIGMAA: Special Interest Groups of the MAA |accessdate=2009-01-19 |work= |publisher=Mathematical Association of America |date=2008-08-22 }}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=History of SIGMAAs {{!}} Mathematical Association of America|url=http://www.maa.org/community/sigmaas/history-of-sigmaas|website=www.maa.org}}&lt;/ref&gt;

==Non-technical SIGs==
Organizations that are not technical may also have Special Interest Groups, which are normally focused on a mutual interest&lt;ref name="The Community Discovered Special Interest Groups"&gt;[http://communitydisc.westside66.org/HTML/sigs/ The Community Discovered Special Interest Groups], groups for specific interests within an educational organization.&lt;/ref&gt; or shared characteristic of a subset of members of the organization.&lt;ref name="FGC Summer Gathering AYF Program"&gt;[http://fgcquaker.org/gathering/overview/kids-teens-young-adults/adult-young-friends Friends General Conference Summer Gathering Adult Young Friends Program], a young adult-focused SIG in a [[Quaker]] organization.&lt;/ref&gt; An important example for this are [[trade unions]]. For identity-based advocacy groups, see [[identity politics]]. The [[Japan Association for Language Teaching]] (JALT) has several SIGs. Together they organize a Pan-SIG conference each year.

&lt;big&gt;Political Interest Groups&lt;/big&gt;

These interest groups represent interests that support and lobby for areas of special need. For example, the ''Sierra Club'' focuses on protecting the environment as well as the wild places on earth. The focus also on the education of people on preservation of the environment. Groups like this advocate for their special interest and form a base of support that will assist them in moving along their public issue. These political "entrepreneurs" are the classic view of the policy maker. An also much needed to these special interest groups is the patron. These patrons provide capital as well as support for the interest groups. The cause has to be one that many support and can get behind due to the quantity of other causes that lobby their patrons for support. Many of these dominant groups have sub-supporting groups that lobby for more specific issues, but assist in the overall cause.

==See also==
* [[Birds of a feather (computing)]]
* [[Issue advocacy ads|Interest versus express advocacy]]
* [[Linux User Group]]
* [[Lobbying]]
* [[Organizational structure]]

== References ==
{{Reflist|30em}}

==External links==
* [http://www.acm.org/special-interest-groups ACM: Special Interest Groups]
* [http://www.maa.org/community/sigmaas MAA: Special Interest Groups]

[[Category:Information technology organizations]]
[[Category:Mathematics organizations]]</text>
      <sha1>4lzu4m2kusyjmgrcsvyrnqh5hxc3y9w</sha1>
    </revision>
  </page>
  <page>
    <title>Structure from motion</title>
    <ns>0</ns>
    <id>5386671</id>
    <revision>
      <id>870467369</id>
      <parentid>870452382</parentid>
      <timestamp>2018-11-25T00:53:49Z</timestamp>
      <contributor>
        <ip>87.223.155.179</ip>
      </contributor>
      <comment>I added a reference.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22604">'''Structure from motion''' ('''SfM''') is a [[photogrammetry|photogrammetric]] [[range imaging]] technique for estimating three-dimensional structures from two-dimensional image sequences that may be coupled with local [[motion perception|motion signals]]. It is studied in the fields of [[computer vision]] and [[visual perception]]. In biological vision, SfM refers to the phenomenon by which humans (and other living creatures) can recover 3D structure from the projected 2D (retinal) motion field of a moving object or scene.

==Principle==
[[File:DSM construction site.jpg|thumb|Digital surface model of [[motorway]] [[Interchange (road)|interchange]] [[construction site]]]]
[[File:SfM PPT GUI vs PHOTO.png|thumb|Real photo x SfM with texture color x SfM with simple shader. Made with Python Photogrammetry Toolbox GUI and rendered in Blender with Cycles.]]
[[File:Bezmiechowa DSM 3D 2010-05-29 Pteryx UAV.jpg|thumb|Bezmiechowa airfield 3D [[digital surface model]] extracted from data collected during 30min flight of [[Pteryx UAV]] ]]

Humans perceive a lot of information about the three-dimensional structure in their environment by moving through it.  When the observer moves and the objects around the observer move, information is obtained from images sensed over time.&lt;ref&gt;{{cite book | title = Computer Vision |author1=[[Linda Shapiro|Linda G. Shapiro]] |author2=George C. Stockman | publisher = Prentice Hall | year = 2001 | isbn = 0-13-030796-3 }}&lt;/ref&gt;

Finding structure from motion presents a similar problem to finding structure from [[stereo vision]]. In both instances, the correspondence between images and the reconstruction of 3D object needs to be found.

To find correspondence between images, features such as corner points (edges with gradients in multiple directions) are tracked from one image to the next. One of the most widely used feature detectors is the [[scale-invariant feature transform]] (SIFT). It uses the maxima from a [[Difference of Gaussians|difference-of-Gaussians]] (DOG) pyramid as features. The first step in SIFT is finding a dominant gradient direction. To make it rotation-invariant, the descriptor is rotated to fit this orientation.&lt;ref&gt;{{Cite journal | journal = International Journal of Computer Vision  | title = Distinctive image features from scale-invariant keypoints | author = D. G. Lowe | year = 2004 | doi=10.1023/b:visi.0000029664.99615.94 | volume=60 | pages=91–110}}&lt;/ref&gt;  Another common feature detector is the [[Speeded up robust features|SURF]] (''speeded-up robust features'').&lt;ref&gt;{{Cite journal | journal = 9th European Conference on Computer Vision  | title = Surf: Speeded up robust features |author1=H. Bay |author2=T. Tuytelaars |author3=L. Van Gool  |last-author-amp=yes | year = 2006 }}&lt;/ref&gt; In SURF, the DOG is replaced with a [[Hessian matrix]]-based blob detector. Also, instead of evaluating the gradient histograms, SURF computes for the sums of gradient components and the sums of their absolute values.&lt;ref&gt;{{Cite journal | journal = Kybernetika  | title = The structure-from-motion reconstruction pipeline – a survey with focus on short image sequences |author1=K. Häming  |author2=G. Peters |lastauthoramp=yes | year = 2010 | url = http://dml.cz/dmlcz/141400 }}&lt;/ref&gt; The features detected from all the images will then be matched. One of the matching algorithms that track features from one image to another is the [[Kanade–Lucas–Tomasi feature tracker|Lukas–Kanade tracker]].&lt;ref&gt;{{Cite journal | journal = IJCAI81  | title = An iterative image registration technique with an application to stereo vision |author1=B. D. Lucas  |author2=T. Kanade  |lastauthoramp=yes }}&lt;/ref&gt;

Sometimes some of the matched features are incorrectly matched. This is why the matches should also be filtered. [[RANSAC]] (random sample consensus)  is the algorithm that is usually used to remove the outlier correspondences.  In the paper of Fischler and Bolles, RANSAC is used to solve the ''location determination problem'' (LDP), where the objective is to determine the points in space that project onto an image into a set of landmarks with known locations.&lt;ref&gt;{{Cite journal | journal = Commun. ACM  | title = Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography |author1=M. A. Fischler  |author2=R. C. Bolles |lastauthoramp=yes | year = 1981 | doi=10.1145/358669.358692 | volume=24 | pages=381–395}}&lt;/ref&gt;

The feature trajectories over time are then used to reconstruct their 3D positions and the camera's motion.&lt;ref&gt;{{Cite journal | journal = IEEE Computer Society Conference on Computer Vision and Pattern Recognition  | title = Structure from Motion without Correspondence |author1=F. Dellaert |author2=S. Seitz |author3=C. Thorpe |author4=S. Thrun  |last-author-amp=yes | year = 2000 | url = http://www.ri.cmu.edu/pub_files/pub2/dellaert_frank_2000_1/dellaert_frank_2000_1.pdf }}&lt;/ref&gt;
An alternative is given by so-called direct approaches, where geometric information (3D structure and camera motion) is directly estimated from the images, without intermediate abstraction to features or corners.&lt;ref&gt;{{Cite conference | last1  = Engel | first1 = Jakob | last2  = Schöps | first2 = Thomas | last3  = Cremers | first3 = Daniel | contribution = LSD-SLAM: Large-Scale Direct Monocular SLAM | year  = 2014 | title = European Conference on Computer Vision (ECCV) 2014 | url       = https://vision.in.tum.de/_media/spezial/bib/engel14eccv.pdf | format    = PDF}}&lt;/ref&gt;

There are several approaches to structure from motion. In incremental SFM&lt;ref&gt;{{Cite journal | journal = IEEE Computer Society Conference on Computer Vision and Pattern Recognition  | title = Structure-from-Motion Revisited |author1=J.L. Schönberger |author2=J.M. Frahm |last-author-amp=yes | year = 2016 | url = https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Schonberger_Structure-From-Motion_Revisited_CVPR_2016_paper.pdf }}&lt;/ref&gt;, camera poses are solved for and added one by one to the collection. In global SFM &lt;ref&gt;{{Cite journal | journal = International Journal of Computer Vision  | title = Shape and motion from image streams under orthography: a factorization method |author1=C. Tomasi |author2=T. Kanade |last-author-amp=yes | year = 1992 | url = https://link.springer.com/article/10.1007%2FBF00129684 }}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | journal = IEEE Computer Society Conference on Computer Vision and Pattern Recognition  | title = Combining two-view constraints for motion estimation |author1=V.M. Govindu |last-author-amp=yes | year = 2001 | url = https://ieeexplore.ieee.org/document/990963/ }}&lt;/ref&gt;, the poses of all cameras are solved for at the same time. A somewhat intermediate approach is [[Out-of-core algorithm|out-of-core]] SFM, where several partial reconstructions are computed that are then integrated into a global solution.

==Applications==

===Geosciences===
Structure from Motion photogrammetry with multi-view stereo provides hyperscale landform models using images acquired from a range of digital cameras and optionally a network of ground control points. The technique is not limited in temporal frequency and can provide point cloud data comparable in density and accuracy to those generated by terrestrial and airborne laser scanning at a fraction of the cost.&lt;ref&gt;{{Cite journal|last=Westoby|first=M. J.|last2=Brasington|first2=J.|last3=Glasser|first3=N. F.|last4=Hambrey|first4=M. J.|last5=Reynolds|first5=J. M.|date=2012-12-15|title=‘Structure-from-Motion’ photogrammetry: A low-cost, effective tool for geoscience applications|url=http://www.sciencedirect.com/science/article/pii/S0169555X12004217|journal=Geomorphology|volume=179|pages=300–314|doi=10.1016/j.geomorph.2012.08.021}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=James|first=M. R.|last2=Robson|first2=S.|date=2012-09-01|title=Straightforward reconstruction of 3D surfaces and topography with a camera: Accuracy and geoscience application|url=http://onlinelibrary.wiley.com/doi/10.1029/2011JF002289/abstract|journal=Journal of Geophysical Research: Earth Surface|language=en|volume=117|issue=F3|pages=F03017|doi=10.1029/2011jf002289|issn=2156-2202}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Fonstad|first=Mark A.|last2=Dietrich|first2=James T.|last3=Courville|first3=Brittany C.|last4=Jensen|first4=Jennifer L.|last5=Carbonneau|first5=Patrice E.|date=2013-03-30|title=Topographic structure from motion: a new development in photogrammetric measurement|url=http://onlinelibrary.wiley.com/doi/10.1002/esp.3366/abstract|journal=[[Earth Surface Processes and Landforms]]|language=en|volume=38|issue=4|pages=421–430|doi=10.1002/esp.3366|issn=1096-9837}}&lt;/ref&gt;. Structure from motion is also useful in remote or rugged environments where terrestrial laser scanning is limited by equipment portability and airborne laser scanning is limited by terrain roughness causing loss of data and image foreshortening.The technique has been applied in many settings such as rivers&lt;ref&gt;{{Cite journal|last=Javernick|first=L.|last2=Brasington|first2=J.|last3=Caruso|first3=B.|title=Modeling the topography of shallow braided rivers using Structure-from-Motion photogrammetry|url=https://doi.org/10.1016/j.geomorph.2014.01.006|journal=Geomorphology|volume=213|pages=166–182|doi=10.1016/j.geomorph.2014.01.006}}&lt;/ref&gt;, badlands&lt;ref&gt;{{Cite journal|last=Smith|first=Mark William|last2=Vericat|first2=Damià|date=2015-09-30|title=From experimental plots to experimental landscapes: topography, erosion and deposition in sub-humid badlands from Structure-from-Motion photogrammetry|url=http://onlinelibrary.wiley.com/doi/10.1002/esp.3747/abstract|journal=Earth Surface Processes and Landforms|language=en|volume=40|issue=12|pages=1656–1671|doi=10.1002/esp.3747|issn=1096-9837}}&lt;/ref&gt;, sandy coastlines&lt;ref&gt;{{Cite journal|last=Goldstein|first=Evan B|last2=Oliver|first2=Amber R|last3=deVries|first3=Elsemarie|last4=Moore|first4=Laura J|last5=Jass|first5=Theo|date=2015-10-22|title=Ground control point requirements for structure-from-motion derived topography in low-slope coastal environments|url=https://doi.org/10.7287/peerj.preprints.1444v1|journal=PeerJ PrePrints|language=en|doi=10.7287/peerj.preprints.1444v1|issn=2167-9843}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Mancini|first=Francesco|last2=Dubbini|first2=Marco|last3=Gattelli|first3=Mario|last4=Stecchi|first4=Francesco|last5=Fabbri|first5=Stefano|last6=Gabbianelli|first6=Giovanni|date=2013-12-09|title=Using Unmanned Aerial Vehicles (UAV) for High-Resolution Reconstruction of Topography: The Structure from Motion Approach on Coastal Environments|url=http://www.mdpi.com/2072-4292/5/12/6880|journal=Remote Sensing|language=en|volume=5|issue=12|pages=6880–6898|doi=10.3390/rs5126880}}&lt;/ref&gt;, fault zones&lt;ref&gt;{{Cite journal|last=Johnson|first=Kendra|last2=Nissen|first2=Edwin|last3=Saripalli|first3=Srikanth|last4=Arrowsmith|first4=J. Ramón|last5=McGarey|first5=Patrick|last6=Scharer|first6=Katherine|last7=Williams|first7=Patrick|last8=Blisniuk|first8=Kimberly|date=2014-10-01|title=Rapid mapping of ultrafine fault zone topography with structure from motion|url=https://pubs.geoscienceworld.org/geosphere/article-abstract/10/5/969/132199/rapid-mapping-of-ultrafine-fault-zone-topography|journal=Geosphere|volume=10|issue=5|pages=969–986|doi=10.1130/GES01017.1}}&lt;/ref&gt;, landslides&lt;ref&gt;{{Cite journal|last=Del Soldato|first=M.|last2=Riquelme|first2=A.|last3=Bianchini|first3=S.|last4=Tomàs|first4=R.|last5=Di Martire|first5=D.|last6=De Vita|first6=P.|last7=Moretti|first7=S.|last8=Calcaterra|first8=D.|date=2018-06-06|title=Multisource data integration to investigate one century of evolution for the Agnone landslide (Molise, southern Italy)|url=http://dx.doi.org/10.1007/s10346-018-1015-z|journal=Landslides|volume=15|issue=11|pages=2113–2128|doi=10.1007/s10346-018-1015-z|issn=1612-510X}}&lt;/ref&gt;, and coral reef settings&lt;ref&gt;{{Cite journal|last=Bryson|first=Mitch|last2=Duce|first2=Stephanie|last3=Harris|first3=Dan|last4=Webster|first4=Jody M.|last5=Thompson|first5=Alisha|last6=Vila-Concejo|first6=Ana|last7=Williams|first7=Stefan B.|title=Geomorphic changes of a coral shingle cay measured using Kite Aerial Photography|url=https://doi.org/10.1016/j.geomorph.2016.06.018|journal=Geomorphology|volume=270|pages=1–8|doi=10.1016/j.geomorph.2016.06.018}}&lt;/ref&gt;. SfM has been also successfully applied for the characterization of rock masses through the determination of some properties a the orientation, persistence, etc. of discontinuities&lt;ref&gt;{{Cite journal|date=2017-01-01|title=Identification of Rock Slope Discontinuity Sets from Laser Scanner and Photogrammetric Point Clouds: A Comparative Analysis|url=https://www.sciencedirect.com/science/article/pii/S1877705817323913|journal=Procedia Engineering|language=en|volume=191|pages=838–845|doi=10.1016/j.proeng.2017.05.251|issn=1877-7058}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|date=2017-09-01|title=Comparing manual and remote sensing field discontinuity collection used in kinematic stability assessment of failed rock slopes|url=https://www.sciencedirect.com/science/article/pii/S1365160916302726|journal=International Journal of Rock Mechanics and Mining Sciences|language=en|volume=97|pages=24–32|doi=10.1016/j.ijrmms.2017.06.004|issn=1365-1609}}&lt;/ref&gt;. A full range of digital cameras can be utilized, including digital SLR's, compact digital cameras and even smart phones. Generally though, higher accuracy data will be achieved with more expensive cameras, which include lenses of higher optical quality. The technique therefore offers exciting opportunities to characterize surface topography in unprecedented detail and, with multi-temporal data, to detect elevation, position and volumetric changes that are symptomatic of earth surface processes . Structure from Motion can be placed in the context of other digital surveying methods.

===Cultural heritage===

Cultural heritage is present everywhere. Its structural control, documentation and conservation is one of humanity's main duties ([[UNESCO]]). Under this point of view, SfM is used in order to properly estimate situations as well as planning and maintenance efforts and costs, control and restoration.
Because serious constraints often exist connected to the accessibility of the site and impossibility to install invasive surveying pillars that did not permit the use of traditional surveying routines (like total stations), SfM provides a non-invasive approach for the structure, without the direct interaction between the structure and any operator. The use is accurate as only qualitative considerations are needed. It is fast enough to respond to the monument’s immediate management needs.&lt;ref&gt;Guidi. G.; Beraldin, J.A.; Atzeni, C. High accuracy 3D modelling of cultural heritage: The digitizing of Donatello. IEEE Trans. Image Process. 2004, 13, 370–380&lt;/ref&gt;
The first operational phase is an accurate preparation of the photogrammetric surveying where is established the relation between best distance from the object, focal length, the ground sampling distance (GSD) and the sensor’s resolution. With this information the programmed photographic acquisitions must be made using vertical overlapping of at least 60% (figure 02).&lt;ref&gt;Kraus, K., 2007. Photogrammetry: Geometry from Image and  Laser Scans. Walter de Gruyter, 459 pp. {{ISBN|978-3-11-019007-6}}&lt;/ref&gt;

==See also==
&lt;div style='-moz-column-count:3; -moz-column-gap:10px;'&gt;
* [[3D reconstruction from multiple images]]
* [[Bundle adjustment]]
* [[Epipolar geometry]]
* [[Kinetic depth effect]]
* [[Match moving]]
* [[Motion field]]
* [[Motion parallax]]
* [[Simultaneous localization and mapping]]
* [[Stereophotogrammetry]]
* [[Tomasi–Kanade factorization]]
* [[2D to 3D conversion]]
&lt;/div&gt;

== Further reading ==

* Jonathan L. Carrivick, Mark W. Smith, Duncan J. Quincey (2016). ''Structure from Motion in the Geosciences''. Wiley-Blackwell. 208 pages. {{ISBN|978-1-118-89584-9}}
* {{cite book |author1=Richard Hartley  |author2=Andrew Zisserman  |lastauthoramp=yes |
title=Multiple View Geometry in Computer Vision |
publisher=Cambridge University Press|
year=2003 |
isbn=0-521-54051-8}}

* {{cite book |
author=[[Olivier Faugeras]] and Quang-Tuan Luong and Theodore Papadopoulo |
title=The Geometry of Multiple Images |
publisher=MIT Press|
year=2001 |
isbn=0-262-06220-8}}
*{{cite book |
title=An Invitation to 3-D Vision: From Images to Geometric Models |author1=Yi Ma |author2=S. Shankar Sastry|author2-link=S. Shankar Sastry |author3=Jana Kosecka|author3-link=Jana Košecká |author4=Stefano Soatto |author4-link=Stefano Soatto  |
publisher=Springer-Verlag New York, LLC |date=November 2003|
isbn=0-387-00893-4|
series=Interdisciplinary Applied Mathematics Series, #26
}}

==References==
&lt;references/&gt;

==External links==

===Structure from motion software toolboxes===

====Open source solutions====
* Trying all the free Photogrammetry-Tools&lt;ref&gt;{{Cite web|url=https://pfalkingham.wordpress.com/2016/09/14/trying-all-the-free-photogrammetry/|title=Trying all the free Photogrammetry!|last=pfalkingham|date=2016-09-14|website=Dr Peter L. Falkingham|access-date=2017-05-16}}&lt;/ref&gt;
C++
*[http://phototour.cs.washington.edu/bundler/ Bundler – Structure from Motion for Unordered Photo Collections] by Noah Snavely
*[https://github.com/openMVG/openMVG openMVG] An Open Multiple View Geometry library + Structure from Motion demonstrators
*[https://cdcseacave.github.io/openMVS openMVS] Multi-View Reconstruction Software
*[https://developer.blender.org/project/profile/59/ Libmv – A Structure from Motion library]
*[http://www.theia-sfm.org/ Theia]: A Fast and scalable structure-from-motion library released under the BSD license
*[https://colmap.github.io/ COLMAP]: General-purpose Structure-from-Motion pipeline with a graphical and command-line interface, licensed under the GPL.
*[http://logiciels.ign.fr/?Telechargement,20 MicMac, a SFM open-source code released] by the [[Institut national de l'information géographique et forestière]]
*[https://vision.in.tum.de/lsdslam LSD-SLAM]: Large-Scale Direct Monocular SLAM in real-time, by Jakob Engel
*[https://web.archive.org/web/20141014235855/http://www.gris.informatik.tu-darmstadt.de/projects/multiview-environment/ MVE – The Multi-View Environment] by Simon Fuhrmann, TU Darmstadt.
*[http://ceres-solver.org/ ceres-solver for general non-linear least squares]. Has features for bundle adjustment. Previously used by Google internally for google maps.  Released to the public in 2012.
*[https://www.ics.forth.gr/~lourakis/sba SBA] for generic bundle adjustment by Manolis Lourakis.
*[http://www.visual-experiments.com/demos/sfmtoolkit/ SFMToolkit a complete photogrammetry solution based on open-source software]
*[https://alicevision.github.io/ AliceVision] an open-source (MPLv2) Photogrammetric Computer Vision Framework (SfM+MVS)

Matlab
*[https://web.archive.org/web/20080524044956/http://vision.ucsd.edu/~vrabaud/toolbox/doc/overview.html Structure from Motion toolbox for Matlab] by Vincent Rabaud
*[http://www.robots.ox.ac.uk/~vgg/hzbook/code/ Matlab Functions for Multiple View Geometry] by Andrew Zissermann
*[https://web.archive.org/web/20090731180952/http://cms.brookes.ac.uk/staff/PhilipTorr/Code/code_page_4.htm Structure and Motion Toolkit] by Phil Torr
*[http://www.cs.dartmouth.edu/~lorenzo/projects/learning-nr-shape/em-sfm.zip Matlab Code for Non-Rigid Structure from Motion] by Lorenzo Torresani

Python
*[https://web.archive.org/web/20130104194856/http://www.arc-team.homelinux.com/arcteam/ppt.php Python Photogrammetry Toolbox GUI]  – an open-source SFM GUI (Easy SfM and dense point cloud estimation launcher) by Pierre Moulon and Arc-Team 
*[https://github.com/mapillary/OpenSfM OpenSfM], a Structure from Motion library written in Python on top of [[OpenCV]], used by [[Mapillary]], [[Simplified BSD License]].
*[https://archive.is/20140402020553/http://catena.googlecode.com/ Catena] Python Abstract Workflow Framework with SfM components.

====Closed source software====
*[http://www.agisoft.com/ Agisoft Photoscan], a photogrammetry solution by Agisoft integrating SfM and ground control. Supports editing/classifying, batch operations, Python scripting, and import/export other formats.
*[http://www.capturingreality.com/ RealityCapture], a photogrammetry solution by Capturing Reality that can process images and/or laser-scans automatically. It can also export SFM to bundle.out and other formats.
*[http://www.acute3d.com/ Smart3DCapture], a complete photogrammetry solution by Acute3D.
*[http://www.3dflow.net/technology/samantha-structure-from-motion/ 3DF Samantha – Command line structure from Motion pipeline for Windows], by 3Dflow srl. Free for non-commercial purposes.
*[http://zephyr.3dflow.net/ 3DF Zephyr], a photogrammetry solution by 3Dflow srl, based on 3DF Samantha.
*[http://www.zjucvg.net/acts/acts.html Automatic Camera Tracking System (ACTS)], a structure-from-motion with dense depth recovery system for Microsoft Windows, by Vision Group of State Key Lab of CAD&amp;CG, Zhejiang University.
*[http://www.zjucvg.net/ls-acts/ls-acts.html Large-Scale Automatic Camera Tracking System (LS-ACTS)], a large-scale structure-from-motion system for Microsoft Windows, by Vision Group of State Key Lab of CAD&amp;CG, Zhejiang University.
*[http://ccwu.me/vsfm VisualSFM: A Visual Structure from Motion System], by Changchang Wu
*[http://www.digitalsurf.fr/en/mntsem.html MountainsMap SEM] software for [[Scanning Electron Microscope]]s. 3D is obtained by tilting the specimen + photogrammetry.
*[http://www.viscoda.com/index.php/en/products/non-commercial/voodoo-camera-tracker Voodoo Camera Tracker], non-commercial tool for the integration of virtual and real scenes. &lt;br /&gt;Original site, archived: [https://web.archive.org/web/20120423112957/http://www.digilab.uni-hannover.de/docs/manual.html Laboratorium für Informationstechnologie, University of Hannover]
*[https://web.archive.org/web/20140224230522/http://dev.metaio.com/sdk/toolbox/ MetaIO Toolbox] SfM for augmented reality on mobile devices. 
*[http://www.2d3sensing.com/content/tacitview TacitView] by [[2d3|2d3 Sensing]]
*[https://web.archive.org/web/20160304130300/http://ptak.felk.cvut.cz/sfmservice/websfm.pl?menu=cmpmvs CMPMVS] Multi-View Reconstruction Software
*[http://www.ifp.uni-stuttgart.de/publications/software/sure/index-lib.en.html University of Stuttgart's LibTSgm library]

[[Category:Geometry in computer vision]]
[[Category:Emerging technologies]]
[[Category:3D imaging]]
[[Category:Photogrammetry]]
[[Category:Motion in computer vision]]</text>
      <sha1>eo748p7is9d97s9o00yyn7sd2jti83q</sha1>
    </revision>
  </page>
  <page>
    <title>Subjective logic</title>
    <ns>0</ns>
    <id>12413580</id>
    <revision>
      <id>864362489</id>
      <parentid>857463990</parentid>
      <timestamp>2018-10-16T18:31:56Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <minor/>
      <comment>convert HTML entity and punctuation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17903">'''Subjective logic''' is a type of [[probabilistic logic]] that explicitly takes [[uncertainty]] and source trust into account. In general, subjective logic is suitable for modeling and analysing situations involving uncertainty and relatively unreliable sources.&lt;ref name="Jos16-Springer"&gt;A. Jøsang. ''[https://books.google.com/books?id=nqRlDQAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Subjective Logic: A formalism for reasoning under uncertainty]''. Springer Verlag, 2016&lt;/ref&gt;&lt;ref name="J97"&gt;A. Jøsang. Artificial Reasoning with Subjective Logic. ''Proceedings of the Second Australian Workshop on Commonsense Reasoning'', Perth 1997. [http://www.unik.no/people/josang/papers/Jos1997-AWCR.pdf PDF]&lt;/ref&gt;&lt;ref name="J01"&gt;A. Jøsang. A Logic for Uncertain Probabilities. ''[[International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems]].'' 9(3), pp. 279–311, June 2001. [http://www.unik.no/people/josang/papers/Jos2001-IJUFKS.pdf PDF]&lt;/ref&gt; For example, it can be used for modeling and analysing [[trust metric|trust networks]] and [[Bayesian network]]s.

Arguments in subjective logic are subjective opinions about state variables which can take values from a domain (aka state space), where a state value can be thought of as a proposition which can be true or false. A binomial opinion applies to a binary state variable, and can be represented as a [[beta distribution|Beta PDF]] (Probability Density Function). A multinomial opinion applies to a state variable of multiple possible values, and can be represented as a [[Dirichlet distribution|Dirichlet PDF]] (Probability Density Function). Through the correspondence between opinions and Beta/Dirichlet distributions, subjective logic provides an algebra for these functions. Opinions are also related to the belief representation in [[Dempster–Shafer theory|Dempster–Shafer belief theory]].

A fundamental aspect of the human condition is that nobody can ever determine with absolute certainty whether a proposition about the world is true or false. In addition, whenever the truth of a proposition is expressed, it is always done by an individual, and it can never be considered to represent a general and objective belief. These philosophical ideas are directly reflected in the mathematical formalism of subjective logic.

==Subjective opinions==
Subjective opinions express subjective beliefs about the truth of state values/propositions with degrees of uncertainty, and can explicitly indicate the source of belief whenever required. An opinion is usually denoted as &lt;math&gt;\omega^{A}_{X}&lt;/math&gt; where &lt;math&gt;A\,\!&lt;/math&gt; is the source of the opinion, and &lt;math&gt;X\,\!&lt;/math&gt; is the state variable to which the opinion applies. The variable &lt;math&gt;X\,\!&lt;/math&gt; can take values from a domain (also called state space) e.g. denoted as &lt;math&gt;\mathbb{X}&lt;/math&gt;. The values of a domain are assumed to be exhaustive and mutually disjoint, and sources are assumed to have a common semantic interpretation of a domain. The source and variable are attributes of an opinion. Indication of the source can be omitted whenever irrelevant.

===Binomial opinions===
Let &lt;math&gt;x\,\!&lt;/math&gt; be a value in a binary domain. A binomial opinion about the truth of value &lt;math&gt;x\,\!&lt;/math&gt; is the ordered quadruple &lt;math&gt;\omega_{x} = (b_x,d_x,u_x,a_x)\,\!&lt;/math&gt; where:

{|
| &lt;math&gt;b_x\,\!&lt;/math&gt;: belief mass
| is the belief that &lt;math&gt;x\,\!&lt;/math&gt; is true.
|-
| &lt;math&gt;d_x\,\!&lt;/math&gt;: disbelief mass
| is the belief that &lt;math&gt;x\,\!&lt;/math&gt; is false.
|-
| &lt;math&gt;u_x\,\!&lt;/math&gt;: uncertainty mass
| is the amount of uncommitted belief.
|-
| &lt;math&gt;a_x\,\!&lt;/math&gt;: base rate
| is the ''prior'' probability in the absence of belief or disbelief.
|}

These components satisfy &lt;math&gt;b_x+d_x+u_x=1\,\!&lt;/math&gt; and &lt;math&gt;b_x,d_x,u_x,a_x \in [0,1]\,\!&lt;/math&gt;. The characteristics of various opinion classes are listed below.

{|
| An opinion
| where &lt;math&gt;b_x=1\,\!&lt;/math&gt;
| is an absolute opinion that is equivalent to Boolean TRUE,
|-
|
| where &lt;math&gt;d_x=1\,\!&lt;/math&gt;
| is an absolute opinion that is equivalent to Boolean FALSE,
|-
|
| where &lt;math&gt;b_x + d_x =1\,\!&lt;/math&gt;
| is a dogmatic opinion which is equivalent to a traditional probability,
|-
|
| where &lt;math&gt;b_x + d_x &lt; 1\,\!&lt;/math&gt;
| is an uncertain opinion which expresses degrees of uncertainty, and
|-
|
| where &lt;math&gt;b_x + d_x = 0\,\!&lt;/math&gt;
| is a vacuous opinion which expresses total uncertainty.
|}

The projected probability of a binomial opinion is defined as &lt;math&gt;\mathrm{P}_{x}=b_{x} + a_{x} u_{x}\,\!&lt;/math&gt;.

Binomial opinions can be represented on an equilateral triangle as shown below. A point inside the triangle represents a &lt;math&gt;(b_x,d_x,u_x)\,\!&lt;/math&gt; triple. The ''b'',''d'',''u''-axes run from one edge to the opposite vertex indicated by the Belief, Disbelief or Uncertainty label. For example, a strong positive opinion is represented by a point towards the bottom right Belief vertex. The base rate, also called the prior probability, is shown as a red pointer along the base line, and the projected probability, &lt;math&gt;\mathrm{P}_{x}\,\!&lt;/math&gt;, is formed by projecting the opinion onto the base, parallel to the base rate projector line. Opinions about three values/propositions X, Y and Z are visualized on the triangle to the left, and their equivalent Beta PDFs (Probability Density Functions) are visualized on the plots to the right. The numerical values and verbal qualitative descriptions of each opinion are also shown.
[[Image:subjective-opinion.jpg|600 px|Example binomial opinions with corresponding Beta PDFs]]

The [[beta distribution|Beta PDF]] is normally denoted as &lt;math&gt;\mathrm{Beta}(p(x);\alpha,\beta)\,\!&lt;/math&gt; where &lt;math&gt;\alpha\,\!&lt;/math&gt; and &lt;math&gt;\beta\,\!&lt;/math&gt; are its two strength parameters. The Beta PDF of a binomial opinion &lt;math&gt;\omega_x = (b_x,d_x,u_x,a_x)\,\!&lt;/math&gt; is the function
&lt;math&gt;
\mathrm{Beta}(p(x);\alpha,\beta) \mbox{ where }
\begin{cases}
\alpha &amp;= \frac{2b_x}{u_x}+2a_x\\
\beta  &amp;= \frac{2d_x}{u_x}+2(1-a_x)
\end{cases}
\,\!
&lt;/math&gt;

===Multinomial opinions===

Let &lt;math&gt;X\,\!&lt;/math&gt; be a variable which can take values &lt;math&gt;x\in\mathbb{X}\,\!&lt;/math&gt;. A multinomial opinion over &lt;math&gt;X\,\!&lt;/math&gt; is the composite
tuple &lt;math&gt;\omega_{X}=(b_{X}, u_{X}, a_{X})\,\!&lt;/math&gt;, where &lt;math&gt;b_{X}\,\!&lt;/math&gt; is a belief mass distribution over the possible values of &lt;math&gt;X\,\!&lt;/math&gt;, &lt;math&gt;u_{X}\,\!&lt;/math&gt; is the uncertainty mass, and &lt;math&gt;a_{X}\,\!&lt;/math&gt; is a base rate distribution over the possible values of &lt;math&gt;X\,\!&lt;/math&gt;. These parameters satisfy &lt;math&gt;u_{X}+\sum b_{X}(x) = 1\,\!&lt;/math&gt; and &lt;math&gt;\sum a_{X}(x) = 1\,\!&lt;/math&gt; as well as &lt;math&gt;b_{X}(x),u_{X},a_{X}(x) \in [0,1]\,\!&lt;/math&gt;.

Visualising multinomial opinions can be challenging. Trinomial opinions can be simply visualised as points inside a [[tetrahedron]]. Opinions with dimensions larger than trinomial do not lend themselves to simple visualisation.

[[Dirichlet distribution|Dirichlet PDF]]s are normally denoted as &lt;math&gt;\mathrm{Dir}(p_{X};\alpha_{X})\,\!&lt;/math&gt; where &lt;math&gt;p_{X}\,\!&lt;/math&gt; is a probability distribution over the values of &lt;math&gt;X&lt;/math&gt;, and &lt;math&gt;\alpha_{X}\,\!&lt;/math&gt; are the strength parameters. The Dirichlet PDF of a multinomial opinion &lt;math&gt;\omega_{X} = (b_{X},u_{X},a_{X})\,\!&lt;/math&gt; is the function
&lt;math&gt;
\mathrm{Dir}(p_{X};\alpha_{X})&lt;/math&gt; where the strength parameters are given by &lt;math&gt;\alpha_{X}(x) = \frac{2b_{X}(x)}{u_{X}}+2a_{X}(x)\,\!
&lt;/math&gt;.

==Operators==
Most operators in the table below are generalisations of binary logic and probability operators. For example ''addition'' is simply a generalisation of addition of probabilities. Some operators are only meaningful for combining binomial opinions, and some also apply to multinomial opinion. &lt;ref name="J07"&gt;A. Jøsang. Probabilistic Logic Under Uncertainty. ''Proceedings of Computing: The Australian Theory Symposium (CATS'07)'', Ballarat, January 2007. [http://www.unik.no/people/josang/papers/Jos2007-CATS.pdf PDF]&lt;/ref&gt; Most operators are binary, but ''complement'' is unary, and ''abduction'' is ternary. See the referenced puplications for mathematical details of each operator.
{| class="wikitable"
|+ Subjective logic operators, notations, and corresponding propositional/binary logic operators
|-
! Subjective logic operator
! Operator notation
! Propositional/binary logic operator
|-
| Addition&lt;ref name="MJ04"&gt;D. McAnally and A. Jøsang. Addition and Subtraction of Beliefs. ''Proceedings of the conference on Information Processing and Management of Uncertainty in Knowledge-Based Systems (IPMU2004)'', Perugia, July, 2004.&lt;/ref&gt;
| &lt;math&gt;\omega^{A}_{x\cup y}=\omega^{A}_{x}+\omega^{A}_{y}\,\!&lt;/math&gt;
| Union
|-
| Subtraction&lt;ref name="MJ04"/&gt;
| &lt;math&gt;\omega^{A}_{x\backslash y}=\omega^{A}_{x}-\omega^{A}_{y}\,\!&lt;/math&gt;
| Difference
|-
| Multiplication&lt;ref name="JM03"&gt;A. Jøsang, and D. McAnally. Multiplication and Comultiplication of Beliefs. ''International Journal of Approximate Reasoning'', 38/1, pp. 19–51, 2004.&lt;/ref&gt;
| &lt;math&gt;\omega^A_{x\land y}=\omega^A_x \cdot \omega^A_y\,\!&lt;/math&gt;
| [[Logical conjunction|Conjunction / AND]]
|-
| Division&lt;ref name="JM03"/&gt;
| &lt;math&gt;\omega^A_{x\overline{\land} y}=\omega^A_x/\omega^A_y\,\!&lt;/math&gt;
| Unconjunction / UN-AND
|-
| Comultiplication&lt;ref name="JM03"/&gt;
| &lt;math&gt;\omega^{A}_{x\lor y}=\omega^{A}_{x}\sqcup \omega^{A}_{y}\,\!&lt;/math&gt;
| [[Logical disjunction|Disjunction / OR]]
|-
| Codivision&lt;ref name="JM03"/&gt;
| &lt;math&gt;\omega^{A}_{x\overline{\lor} y}=\omega^{A}_{x}\;\overline{\sqcup}\;\omega^{A}_{y}\,\!&lt;/math&gt;
| Undisjunction / UN-OR
|-
| Complement&lt;ref name="J97"/&gt;&lt;ref name="J01"/&gt;
| &lt;math&gt;\omega^{A}_{\overline{x}}\;\;=\lnot\omega^{A}_{x}\,\!&lt;/math&gt;
| [[Negation|NOT]]
|-
| Deduction&lt;ref name="Jos16-Springer"/&gt;
| &lt;math&gt;\omega^{A}_{Y\|X}= \omega^{A}_{Y|X}\circledcirc \omega^{A}_{X}\,\!&lt;/math&gt;
| [[Modus ponens]]
|-
| Subjective [[Bayes' theorem]]&lt;ref name="Jos16-Springer"/&gt; &lt;ref name="Jos16-MFI"&gt;A. Jøsang. [http://folk.uio.no/josang/papers/Josang2016-MFI.pdf Generalising Bayes' Theorem in Subjective Logic]. ''2016 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI 2016)'', Baden-Baden, Germany, 2016.&lt;/ref&gt;
| &lt;math&gt;\omega^{A}_{X\tilde{|}Y}=\omega^{A}_{Y|X}\;\widetilde{\phi\,}\;a_{X}\,\!&lt;/math&gt;
| [[Contraposition]]
|-
| Abduction&lt;ref name="Jos16-Springer"/&gt;
| &lt;math&gt;\omega^{A}_{X\widetilde{\|}Y}=\omega^{A}_{Y|X}\;\widetilde{\circledcirc}\;(a_{X},\omega^{A}_{Y})\,\!&lt;/math&gt;
| [[Modus tollens]]
|-
| Transitivity / discounting&lt;ref name="Jos16-Springer"/&gt;
| &lt;math&gt;\omega^{A;B}_{X}=\omega^{A}_{B}\otimes\omega^{B}_{X}\,\!&lt;/math&gt;
| n.a.
|-
| Cumulative fusion &lt;ref name="Jos16-Springer"/&gt;
| &lt;math&gt;\omega^{A\diamond B}_{X}=\omega^{A}_{X}\oplus \omega^{B}_{X}\,\!&lt;/math&gt;
| n.a.
|-
| Constraint fusion&lt;ref name="Jos16-Springer"/&gt;
| &lt;math&gt;\omega^{A\&amp; B}_{X}=\omega^{A}_{X}\;\odot\; \omega^{B}_{X}\,\!&lt;/math&gt;
| n.a.
|}


Transitive source combination can be denoted in a compact or expanded form. For example, the transitive trust path from analyst/source &lt;math&gt;A\,\!&lt;/math&gt; via source &lt;math&gt;B\,\!&lt;/math&gt; to the variable &lt;math&gt;X\,\!&lt;/math&gt; can be denoted as &lt;math&gt;[A;B,X]\,\!&lt;/math&gt; in compact form, or as &lt;math&gt;[A;B]:[B,X]\,\!&lt;/math&gt; in expanded form. Here, &lt;math&gt;[A;B]\,\!&lt;/math&gt; expresses that &lt;math&gt;A&lt;/math&gt; has some trust/distrust in source &lt;math&gt;B&lt;/math&gt;, whereas &lt;math&gt;[B,X]\,\!&lt;/math&gt; expresses that &lt;math&gt;B&lt;/math&gt; has an opinion about the state of variable &lt;math&gt;X&lt;/math&gt; which is given as an advice to &lt;math&gt;A&lt;/math&gt;. The expanded form is the most general, and corresponds directly to the way subjective logic expressions are formed with operators.

==Properties==

In case the argument opinions are equivalent to Boolean TRUE or FALSE, the result of any subjective logic operator is always equal to that of the corresponding propositional/binary logic operator. Similarly, when the argument opinions are equivalent to traditional probabilities, the result of any subjective logic operator is always equal to that of the corresponding probability operator (when it exists).

In case the argument opinions contain degrees of uncertainty, the operators involving multiplication and division (including deduction, abduction and Bayes' theorem) will produce derived opinions that always have correct projected [[probability]] but possibly with approximate [[variance]] when seen as Beta/Dirichlet PDFs.&lt;ref name="Jos16-Springer"/&gt;
All other operators produce opinions where the projected probabilities and the variance are always analytically correct.

Different logic formulas that traditionally are equivalent in propositional logic do not necessarily have equal opinions. For example &lt;math&gt;\omega_{x\land (y\lor z)} \neq \omega_{(x \land y)\lor (x\land z)}\,\!&lt;/math&gt; in general although the [[distributivity]] of conjunction over disjunction, expressed as &lt;math&gt;x\land (y\lor z) \Leftrightarrow (x \land y)\lor (x\land z)\,\!&lt;/math&gt;, holds in binary propositional logic. This is no surprise as the corresponding probability operators are also non-distributive. However, multiplication is distributive over addition, as expressed by &lt;math&gt;\omega_{x\land (y\cup z)} = \omega_{(x \land y)\cup (x\land z)}\,\!&lt;/math&gt;. [[De Morgan's laws]] are also satisfied as e.g. expressed by &lt;math&gt;\omega_{\overline{x\land y}} = \omega_{\overline{x} \lor \overline{y}}\,\! &lt;/math&gt;.

Subjective logic gives very efficient computation of mathematically complex models. This is possible by approximating the analytically correct functions whenever needed. While it is relatively simple to analytically multiply two Beta PDFs in the form of a [[joint distribution|joint Beta PDF]], anything more complex than that quickly becomes intractable. When combining two Beta PDFs with some operator/connective, the analytical result is not always a Beta PDF and can involve [[hypergeometric series]]. In such cases, subjective logic always approximates the result as an opinion that is equivalent to a Beta PDF.

==Applications==

Subjective logic is applicable when the situation to be analysed is characterised by considerable uncertainty and incomplete knowledge. In this way, subjective logic becomes a probabilistic logic for uncertain probabilities. The advantage is that  uncertainty is preserved throughout the analysis and is made explicit in the results so that it is possible to distinguish between certain and uncertain conclusions.

The modelling of [[Trust metric|trust networks]] and [[Bayesian network|Bayesian networks]] are typical applications of subjective logic.

===Subjective trust networks===

Subjective trust networks can be modelled with a combination of the transitivity and fusion operators. Let &lt;math&gt;[A;B]\,\!&lt;/math&gt; express the referral trust edge from &lt;math&gt;A\,\!&lt;/math&gt; to &lt;math&gt;B\,\!&lt;/math&gt;, and let &lt;math&gt;[B,X]\,\!&lt;/math&gt; express the belief edge from &lt;math&gt;B\,\!&lt;/math&gt; to &lt;math&gt;X\,\!&lt;/math&gt;. A subjective trust network can for example be expressed as &lt;math&gt;([A;B]:[B,X])\diamond([A;C]:[C,X])\,\!&lt;/math&gt; as illustrated in the figure below.

[[Image:Subjective-trust-network.jpg|450 px|Subjective trust network]]

The indices 1, 2 and 3 indicate the chronological order in which the trust edges and advices are formed. Thus, given the set of trust edges with index 1, the origin trustor &lt;math&gt;A\,\!&lt;/math&gt; receives advice from &lt;math&gt;B\,\!&lt;/math&gt; and &lt;math&gt;C\,\!&lt;/math&gt;, and is thereby able to derive belief in variable &lt;math&gt;X\,\!&lt;/math&gt;. By expressing each trust edge and belief edge as an opinion, it is possible for &lt;math&gt;A\,\!&lt;/math&gt; to derive belief in &lt;math&gt;X\,\!&lt;/math&gt; expressed as &lt;math&gt;\omega^{A}_{X} = \omega^{[A;B]\diamond[A;C]}_{X} = (\omega^{A}_{B}\otimes \omega^{B}_{X}) \oplus (\omega^{A}_{C}\otimes \omega^{C}_{X})\,\!&lt;/math&gt;.

Trust networks can express the reliability of information sources, and can be used to determine subjective opinions about variables that the sources provide information about.

===Subjective Bayesian networks===

In the Bayesian network below, &lt;math&gt;X\,\!&lt;/math&gt; and &lt;math&gt;Y\,\!&lt;/math&gt; are parent variables and &lt;math&gt;Z\,\!&lt;/math&gt; is the child variable.  The analyst must learn the set of joint conditional opinions &lt;math&gt;\omega_{Z|XY}&lt;/math&gt; in order to apply the deduction operator and derive the marginal opinion &lt;math&gt;\omega_{Z\|XY}&lt;/math&gt; on the variable &lt;math&gt;Z&lt;/math&gt;. The conditional opinions express a conditional relationship between the parent variables and the child variable.

[[Image:Subjective_Bayesian_Network.jpg|450 px|Subjective Bayesian network]]

The deduced opinion is computed as &lt;math&gt;\omega_{Z\|XY} = \omega_{Z|XY} \circledcirc \omega_{XY}&lt;/math&gt;. 
The joint evidence opinion &lt;math&gt;\omega_{XY}&lt;/math&gt; can be computed as the product of independent evidence opinions on &lt;math&gt;X\,\!&lt;/math&gt; and &lt;math&gt;Y\,\!&lt;/math&gt;, or as the joint product of partially dependent evidence opinions.

===Subjective networks===
The combination of a subjective trust network and a subjective Bayesian network is a subjective network. The subjective trust network can be used to obtain from various sources the opinions to be used as input opinions to the subjective Bayesian network, as illustrated in the figure below.

[[Image:Subjective_network.jpg|400 px|Subjective network]]

Traditional Bayesian network typically do not take into account the reliability of the sources. In subjective networks, the trust in sources is explicitly taken into account.

== See also==
* [[Evidence-based subjective logic]]

==References==
{{reflist}}

==External links==
* [http://folk.uio.no/josang/sl/ Subjective Logic] by Audun Jøsang
* [https://sourceforge.net/projects/slef/ Subjective Logic Experimentation Framework] based on Subjective Logic Operators in Trust Assessment: An Empirical Study by F. Cerutti, L. M. Kaplan, T. J. Norman, N. Oren, and A. Toniolo


{{DEFAULTSORT:Subjective Logic}}
[[Category:Bayesian statistics]]
[[Category:Non-classical logic]]</text>
      <sha1>mvwrcs1e38mf59qlwtlo6pweqnykbj9</sha1>
    </revision>
  </page>
  <page>
    <title>Time translation symmetry</title>
    <ns>0</ns>
    <id>54016907</id>
    <revision>
      <id>871301165</id>
      <parentid>848003823</parentid>
      <timestamp>2018-11-30T04:09:58Z</timestamp>
      <contributor>
        <ip>2600:1700:5D80:2730:ED0A:8E83:47F6:4ADE</ip>
      </contributor>
      <comment>Spelling fix (spacial -&gt; spatial)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10235">{{about|time translation symmetry (TTS)|time reversal symmetry|T-symmetry}}
{{Time sidebar |science}}
'''Time translation symmetry''' or '''temporal translation symmetry''' ('''TTS''') is a [[mathematical transformation]] in [[physics]] that moves the times of events through a common interval. Time translation symmetry is the hypothesis that the [[laws of physics]] are unchanged, (i.e. invariant) under such a transformation. Time translation symmetry is a rigorous way to formulate the idea that the laws of physics are the same throughout history. Time translation symmetry is closely connected via the [[Noether theorem]], to [[conservation of energy]].&lt;ref name=Wilczek&gt;{{cite book|last1=Wilczek|first1=Frank|title=A Beautiful Question: Finding Nature's Deep Design|url=https://books.google.com/books?id=Oh3ICAAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false|date=16 July 2015|publisher=Penguin Books Limited|isbn=978-1-84614-702-9|chapter=3}}&lt;/ref&gt; In mathematics, the set of all time translations on a given system form a [[Lie group]].

There are many symmetries in nature besides time translation, such as [[Translational symmetry|spatial translation]] or [[rotational symmetries]]. These symmetries can be broken and explain diverse phenomena such as [[crystals]], [[superconductivity]], and the [[Higgs mechanism]].&lt;ref&gt;{{cite web|last1=Richerme|first1=Phil|title=Viewpoint: How to Create a Time Crystal|url=http://physics.aps.org/articles/v10/5|website=physics.aps.org|publisher=APS Physics|archiveurl=https://archive.is/eXKGV|archivedate=2 Feb 2017|date=18 January 2017 }}&lt;/ref&gt; However, it was thought until very recently that time translation symmetry could not be broken.&lt;ref&gt;{{cite journal|last1=Else|first1=Dominic V.|last2=Bauer|first2=Bela|last3=Nayak|first3=Chetan|title=Floquet Time Crystals|journal=Physical Review Letters|volume=117|issue=9|year=2016|issn=0031-9007|doi=10.1103/PhysRevLett.117.090402|arxiv=1603.08001v4|bibcode=2016PhRvL.117i0402E|url=https://arxiv.org/pdf/1603.08001v4.pdf|pmid=27610834|page=090402}}&lt;/ref&gt; [[Time crystals]], a state of matter first observed in 2017, break time translation symmetry.&lt;ref name=Gibney/&gt;

==Overview==
{{Lie groups}}
[[Symmetry (physics)|Symmetries]] are of prime importance in physics and are closely related to the hypothesis that certain physical quantities are only relative and [[unobservable]].&lt;ref name=feng&gt;{{cite book|last1=Feng|first1=Duan|last2=Jin|first2=Guojun|title=Introduction to Condensed Matter Physics|url=https://books.google.com/books?id=-iuYN5arHwoC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false|year=2005|publisher=[[World Scientific]]|location=singapore|isbn=978-981-238-711-0|page=18}}&lt;/ref&gt; Symmetries apply to the equations that govern the physical laws (e.g. to a [[Hamiltonian mechanics|Hamiltonian]] or [[Lagrangian mechanics|Lagrangian]]) rather than the initial conditions, values or magnitudes of the equations themselves and state that the laws remain unchanged under a transformation.&lt;ref name=Wilczek/&gt; If a symmetry is preserved under a transformation it is said to be ''invariant''. Symmetries in nature lead directly to conservation laws, something which is precisely formulated by the [[Noether theorem]].&lt;ref name=Cao&gt;{{cite book|last1=Cao|first1=Tian Yu|title=Conceptual Foundations of Quantum Field Theory|url=https://books.google.com/books?id=d0wS0EJHZ3MC&amp;printsec=frontcover#v=onepage&amp;q&amp;f=falseC|date=25 March 2004|publisher=[[Cambridge University Press]]|isbn=978-0-521-60272-3|location=Cambridge}}&lt;/ref&gt;
{| class="wikitable" style="text-align: center;
|+ [[Symmetry (physics)|Symmetries in physics]]&lt;ref name=feng/&gt;
! Symmetry
! Transformation
! Unobservable
! Conservation law
|-
! [[Space translation symmetry|Space-translation]]
|| &lt;math&gt;\mathbf{r} \rightarrow \mathbf{r} + \delta\mathbf{r}&lt;/math&gt; || absolute position in space|| [[Conservation of momentum|momentum]]
|-
! Time-translation
|| &lt;math&gt;t \rightarrow t + \delta t&lt;/math&gt; || absolute time || [[Conservation of energy|energy]]
|-
! [[Rotational symmetry|Rotation]]
|| &lt;math&gt;\mathbf{r} \rightarrow \mathbf{r}'&lt;/math&gt;  || absolute direction in space || [[Conservation of angular momentum|angular momentum]]
|-
! [[Parity (physics)|Space inversion]]
|| &lt;math&gt;\mathbf{r} \rightarrow - \mathbf{r}&lt;/math&gt;  || absolute left or right || [[Conservation of parity|parity]]
|-
! [[T-symmetry|Time-reversal]]
|| &lt;math&gt;t \rightarrow - t &lt;/math&gt; || absolute sign of time || [[Kramers degeneracy]]
|-
! [[C-symmetry|Sign reversion of charge]]
|| &lt;math&gt;e \rightarrow - e&lt;/math&gt;|| absolute sign of electric charge || [[charge conjugation]]
|-
! [[Identical particles|Particle substitution]]
||  || distinguishability of identical particles || [[Bose–Einstein statistics|Bose]] or [[Fermi statistics]]
|-
! [[Gauge transformation]]
|| &lt;math&gt;\psi \rightarrow e^{iN\theta}\psi&lt;/math&gt; || relative phase between different normal states || [[particle number]]
|}

===Newtonian mechanics===

To formally describe time translation symmetry we say the equations, or laws, that describe a system at times &lt;math&gt;t&lt;/math&gt; and &lt;math&gt; t + \tau&lt;/math&gt; are the same for any value of &lt;math&gt;t&lt;/math&gt; and &lt;math&gt;\tau&lt;/math&gt;.

For example, considering Newton's equation:

: &lt;math&gt;m\ddot{x}=-\frac{dV}{dx}(x)&lt;/math&gt;

One finds for its solutions &lt;math&gt;x=x(t)&lt;/math&gt; the combination:

: &lt;math&gt;\frac{1}{2}m\dot{x}(t)^2 + V(x(t))&lt;/math&gt;

does not depend on the variable &lt;math&gt;t&lt;/math&gt;. Of course, this quantity describes the total energy whose conservation is due to the time translation invariance of the equation of motion. By studying the composition of symmetry transformations, e.g. of geometric objects, one reaches the conclusion that they form a group and, more specifically, a [[Lie algebra|Lie transformation group]] if one considers continuous, finite symmetry transformations. Different symmetries form different groups with different geometries. Time independent Hamiltonian systems form a group of time translations that is described by the non-compact, [[Abelian group|abelian]], [[Lie group]] &lt;math&gt;\mathbb R&lt;/math&gt;. TTS is therefore a dynamical or Hamiltonian dependent symmetry rather than a kinematical symmetry which would be the same for the entire set of Hamiltonians at issue. Other examples can be seen in the study of [[time evolution]] equations of classical and quantum physics.

Many [[differential equations]] describing time evolution equations are expressions of invariants associated to some [[Lie group]] and the theory of these groups provides a unifying viewpoint for the study of all special functions and all their properties. In fact, [[Sophus Lie]] invented the theory of Lie groups when studying the symmetries of differential equations. The integration of a (partial) differential equation by the method of separation of variables or by Lie algebraic methods is intimately connected with the existence of symmetries. For example, the exact solubility of the [[Schrodinger equation]] in quantum mechanics can be traced back to the underlying invariances. In the latter case, the investigation of symmetries allows for an interpretation of the [[Quantum degeneracy|degeneracies]], where different configurations to have the same energy, which generally occur in the energy spectrum of quantum systems. Continuous symmetries in physics are often formulated in terms of infinitesimal rather than finite transformations, i.e. one considers the [[Lie algebra]] rather than the Lie group of transformations

===Quantum mechanics===
{{main article|Operator (physics)|Translation operator (quantum mechanics)|Energy operator|Symmetry in quantum mechanics}}
The invariance of a Hamiltonian &lt;math&gt;\hat{H}&lt;/math&gt; of an isolated system under time translation implies its energy does not change with the passage of time. Conservation of energy implies, according to the Heisenberg equations of motion, that &lt;math&gt;[ \hat{H}, \hat{H} ]=0&lt;/math&gt;.

: &lt;math&gt;[ e^{i\hat{H}t/\hbar}, \hat{H} ]=0&lt;/math&gt;

or:

:  &lt;math&gt;[ \hat{T}(t), \hat{H} ]=0&lt;/math&gt;

Where &lt;math&gt;\hat{T}(t)=e^{i\hat{H}t/\hbar}&lt;/math&gt; is the time translation operator which implies invariance of the Hamiltonian under the time translation operation and leads to the conservation of energy.

===Nonlinear systems===
In many nonlinear field theories like [[general relativity]] or [[Yang-Mills theory|Yang-Mills theories]], the basic field equations are highly nonlinear and exact solutions are only known for ‘sufficiently symmetric’ distributions of matter (e.g. rotationally or axially symmetric configurations). Time translation symmetry is guaranteed only in [[spacetimes]] where the [[Metric tensor (general relativity)|metric]] is static: that is, where there is a coordinate system in which the metric coefficients contain no time variable. Many [[general relativity]] systems are not static in any frame of reference so no conserved energy can be defined.

==Time translation symmetry breaking (TTSB)==
{{main article|Time crystal}}
[[Time crystals]], a state of matter first observed in 2017, break time translation symmetry.&lt;ref name="Gibney"&gt;{{cite journal|year=2017|title=The quest to crystallize time|url=http://www.nature.com/news/the-quest-to-crystallize-time-1.21595|journal=Nature|volume=543|issue=7644|pages=164–166|doi=10.1038/543164a|issn=0028-0836|last1=Gibney|first1=Elizabeth|archiveurl=https://archive.is/WRq8v|archivedate=13 Mar 2017|bibcode=2017Natur.543..164G}}&lt;/ref&gt;

==See also==
{{div col|colwidth=18em}}
* [[Absolute time and space]]
* [[Mach's principle]]
* [[Spacetime]]
* [[Time reversal symmetry]]
{{div col end}}
{{Portal bar|Astronomy|Mathematics|Physics|Time}}

== References ==

{{Reflist|30em}}

==External links==
* [http://www.feynmanlectures.caltech.edu/I_52.html The Feynman Lectures on Physics - Time Translation]

{{Time Topics}}
{{Time measurement and standards}}
{{Relativity}}
{{Dimension topics}}

[[Category:Concepts in physics]]
[[Category:Conservation laws]]
[[Category:Energy (physics)]]
[[Category:Laws of thermodynamics]]
[[Category:Particle physics]]
[[Category:Quantum field theory]]
[[Category:Quantum mechanics]]
[[Category:Spacetime]]
[[Category:Symmetry]]
[[Category:Time in physics]]
[[Category:Theory of relativity]]
[[Category:Thermodynamics]]</text>
      <sha1>p810t2vvrjm374keih0dxc0yghlmec3</sha1>
    </revision>
  </page>
  <page>
    <title>Traité de mécanique céleste</title>
    <ns>0</ns>
    <id>54423179</id>
    <revision>
      <id>860774505</id>
      <parentid>854559980</parentid>
      <timestamp>2018-09-22T23:51:39Z</timestamp>
      <contributor>
        <username>Joe Kress</username>
        <id>45685</id>
      </contributor>
      <comment>/* External links */ translation by Bowditch</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8282">{{italic title}}
'''''Traité de mécanique céleste''''' ({{lang-en|"Treatise of celestial mechanics"}}) is a five-volume [[treatise]] on [[celestial mechanics]] written by [[Pierre-Simon Laplace]] and published from 1798 to 1825 with a second edition in 1829.&lt;ref&gt;{{cite book|title=Traité de mécanique céleste, ''1798–1825''|url=http://catalog.hathitrust.org/Record/100242426}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Oeuvres de Laplace|location=Paris|publisher=Imprimerie royale|url=http://catalog.hathitrust.org/Record/008629833|postscript=; 1843–1847}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=Laplace, Pierre Simon, marquis de|location=Paris|title=Traité de mécanique céleste, ''1799–1825''|url=http://catalog.hathitrust.org/Record/100900122}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=Laplace, Pierre Simon, marquis de|title=Traité de mécanique céleste|edition=deuxième|year=1829|url=http://catalog.hathitrust.org/Record/012304177}}&lt;/ref&gt; In 1842, the government of Louis Philippe gave a grant of 40,000 francs for a 7-volume national edition of the ''Oeuvres de Laplace'' (1843–1847); the ''Traité de mécanique céleste'' with its four supplements occupies the first 5 volumes.&lt;ref&gt;{{cite EB1911|author=Clerke, Agnes Mary|authorlink=Agnes Mary Clerke|wstitle=Laplace, Pierre Simon|volume=16|pages=200–203}}&lt;/ref&gt;

{{blockquote|Newton laid the foundations of Celestial Mechanics, at the close of the seventeenth century, by the discovery of the principle of universal gravitation. Even in his own hands, this discovery led to important consequences, but it has required a century and a half, and a regular succession of intellects the most powerful, to fill up the outline sketched by him. Of these, Laplace himself was the last, and, perhaps after Newton, the greatest; and the task commenced in the ''Principia'' of the former, is completed in the ''Mécanique Celéste'' of the latter. In this last named work, the illustrious author has proposed to himself his object, to unite all the theories scattered throughout the various channels of publication, employed by his predecessors, to reduce them to one common method, and present them all in the same point of view.&lt;ref&gt;{{cite journal|title=Review: ''Traité de Mécanique Céleste'' par M. Le Marquis de Laplace, Tome V. Paris, Bachelier|journal=The American Quarterly Review|volume=5|date=June 1829|pages=310–343|url=https://books.google.com/books?id=yNYRAAAAYAAJ&amp;pg=PA310}}&lt;/ref&gt;}}

{{blockquote|If one were asked to name the two most important works in the progress of mathematics and physics, the answer would undoubtedly be, the ''Principia'' of Newton and the ''Mécanique Céleste'' of Laplace. In their historical and philosophical aspects these works easily outrank all others, and furnish thus the standard by which all others must be measured. The distinguishing feature of the ''Principia'' is its clear and exhaustive enunciation of fundamental principles. The ''Mécanique Céleste'', on the other hand, is conspicuous for the development of principles and for the profound generality of its methods. The ''Principia'' gives the plans and specifications of the foundations; the ''Mécanique Céleste'' affords the key to the vast and complex superstructure.&lt;ref&gt;{{cite journal|author=Woodward, R. S.|title=Review of Tisserand's ''Mecånique Céleste''|journal=The Annals of Mathematics|date=August 1891|volume=6|issue=2|pages=49–56|jstor=1967235}}&lt;/ref&gt;}}

==Tome I. (1798)==
===Livre I. Des lois générales de l'équilibre et du mouvement===
* Chap. I. De l'équilibre et de la composition des forces qui agissent sur un point matériel
* Chap. II. Du mouvement d'un point matériel
* Chap. III. De l'équilibre d'un système de corps
* Chap. IV. De l'équilibre des fluides
* Chap. V. Principes généraux du mouvement d'un système de corps
* Chap. VI. Des lois du mouvement d'un système de corps, dans toutes les relations mathématiquement possibles entre la force et la vitesse
* Chat. VII. Des mouvemens d'un corps solide de figure quelconque
* Chap. VIII. Du mouvement des fluides

===Livre II. De la loi pesanteur universelle, et du mouvement des centres de gravité des corps célestes===

==Tome II. (1798)==
===Livre III. De la figure des corps céleste===
===Livre IV. Des oscillations de la mer et de l'atmosphère===
===Livre V. Des mouvemens des corps célestes, autour de leurs propre centres de gravité===

==Tome III. (1802)==
===Livre VI. Théorie particulières des mouvemens célestes===
===Livre VII. Théorie de la lune===

==Tome IV. (1805)==
===Livre VIII. Théorie des satellites de Jupiter, de Saturne et d'Uranus===
===Livre IX. Théorie des comètes===
===Livre X. Sur différens points relatifs au système du monde===

==Tome V. (1825)==
===Livre XI. De la figure et de la rotation de la terre===
===Livre XII. De l'attraction et de la répulsion des sphères, et des lois de l'equilibre et du mouvement des fluides élastiques===
===Livre XIII. Des oscillations des fluides qui recouvrent les planètes===
===Livre XIV. Des mouvemens des corps célestes autour de leurs centres de gravité===
===Livre XV. Du mouvement des planètes et des comètes===
===Livre XVI. Du mouvement des satellites===

==Bowditch's translation==
The famous American mathematician [[Nathaniel Bowditch]] translated the first four volumes of the ''Traité de mécanique céleste'' but not the fifth volume;&lt;ref&gt;{{cite book|author=Gillispie, Charles Coulston|author2=Grattan-Guinness, Ivor|title=Pierre-Simon Laplace, 1749-1827: a life in exact science|publisher=[[Princeton University Press]]|year=2000|page=283|url=https://books.google.com/books?id=iohJomX0IWgC&amp;pg=PA283}}&lt;/ref&gt; however, Bowditch did make use of relevant portions of the fifth volume in his extensive commentaries for the first four volumes.&lt;ref name=MacTbio&gt;{{MacTutor Biography|id=Bowditch|title=Nathaniel Bowditch}}&lt;/ref&gt;

{{blockquote|The first four volumes of Dr. Bowditch's Translation and Commentary were published successively, in 1828, 1832, 1834, and 1839, at the sacrifice of one quarter of his whole property. The expense was largely increased by the voluminous commentary. This was really of the nature of an original work, and was rendered necessary by the frequent gaps which Laplace had left in his own publication. Mr. N. I. Bowditch says, in his biography of his father, that Dr. Bowditch was accustomed to remark, "Whenever I meet in Laplace with the words, ''Thus it plainly appears'', I am sure that hours, and perhaps days, of hard study will alone enable me to discover ''how'' it plainly appears."&lt;ref&gt;{{cite journal|title=The "Mécanique Céleste" of Laplace, and Its Translation, with a Commentary by Bowditch|author=Lovering, Joseph|journal=Proceedings of the American Academy of Arts and Sciences|volume= 24, |date=May 1888 – May 1889|pages=185–201|doi=10.2307/20021561|jstor=20021561|url=http://babel.hathitrust.org/cgi/pt?id=njp.32101050585932;view=1up;seq=197}} (See p. 196 for quote.)&lt;/ref&gt;}}

{{blockquote|Bowditch's translation of the first four volumes of Laplace's ''Traité de mécanique céleste'' was completed by 1818 but he would not publish it for many years. Almost certainly the cost of publication caused the delay, but Bowditch did not just put the work on one side after 1818 but continued to improve it over the succeeding years. Bowditch was helped by [[Benjamin Peirce]] in this project and his commentaries doubled the length of the book. His purpose was more than just an English translation. He wanted to supply steps omitted in the original text; to incorporate later results into the translation; and to give credits omitted by Laplace.&lt;ref name=MacTbio/&gt;}}

==References==
{{reflist}}

==External links==
Translation by Nathaniel Bowditch
* [https://archive.org/details/mcaniquecles01laplrich Volume I, 1829]
* [https://archive.org/details/mcaniquecles02laplrich Volume II, 1832]
* [https://archive.org/details/mcaniquecles03laplrich Volume III, 1834]
* [https://archive.org/details/mcaniquecles04laplrich Volume IV, 1839] with a memoir of the translator by his son

{{DEFAULTSORT:Traite de mecanique celeste}}
[[Category:Physics books]]
[[Category:Mathematics books]]
[[Category:1798 books]]
[[Category:French books]]
[[Category:Celestial mechanics]]

{{physics-book-stub}}</text>
      <sha1>cltnlr4trni4ys4b3hduo7347l6v3so</sha1>
    </revision>
  </page>
  <page>
    <title>Turing tarpit</title>
    <ns>0</ns>
    <id>46633</id>
    <revision>
      <id>853809426</id>
      <parentid>849812605</parentid>
      <timestamp>2018-08-07T03:05:37Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; reformat 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3889">{{Use dmy dates|date=April 2018}}
A '''Turing tarpit''' (or '''Turing tar-pit''') is any [[programming language]] or [[computer interface]] that allows for flexibility in function but is difficult to learn and use because it offers little or no support for common tasks.&lt;ref&gt;{{cite web| url=http://c2.com/cgi/wiki?TuringTarpit | title=Turing Tarpit | website=c2.com | date=10 March 2010 | accessdate=7 November 2012 }}&lt;/ref&gt; The phrase was coined in 1982 by [[Alan Perlis]] in the ''[[Epigrams on Programming]]'':&lt;ref&gt;{{cite journal|last1=Perlis|first1=A|journal=ACM SIGPLAN Notices|volume=17|issue=9|pages=7–13|title=Epigrams on Programming|date=September 1982|isbn=|url=http://dl.acm.org/citation.cfm?id=1083808|archiveurl=http://pu.inf.uni-tuebingen.de/users/klaeren/epigrams.html|archivedate=1996-03-26|publisher=Yale University|doi=10.1145/947955.1083808|accessdate=28 August 2015}}&lt;/ref&gt;

{{quote|54. Beware of the Turing tar-pit in which everything is possible but nothing of interest is easy.}}

In any [[Turing completeness|Turing complete]] language, it is possible to write any computer program, so in a very rigorous sense nearly all programming languages are equally capable. Showing that theoretical ability is not the same as usefulness in practice, Turing tarpits are characterized by having a simple [[abstract machine]] that requires the user to deal with many details in the solution of a problem.&lt;ref&gt;{{cite web | url=https://practicingruby.com/articles/shared/bwgflabwncjv | title=Exploring the depths of a Turing tarpit | website=practicingruby.com | date=7 February 2013 | deadurl=yes | archiveurl=https://web.archive.org/web/20120204180904/http://practicingruby.com/articles/shared/bwgflabwncjv | archivedate=4 February 2012 | df=dmy-all }}&lt;/ref&gt; At the extreme opposite are interfaces that can perform very complex tasks with little human intervention but become obsolete if requirements change slightly.

Some [[esoteric programming languages]], such as [[Brainfuck]], are specifically referred to as "Turing tarpits"&lt;ref name=chandra2014geek&gt;{{cite book|last1=Chandra|first1=V|title=Geek Sublime: The Beauty of Code, the Code of Beauty|date=2014|publisher=Graywolf Press|isbn=9781555973261|url=https://books.google.com/books?id=-4eBAwAAQBAJ&amp;q=turing%20tarpit|accessdate=28 August 2015}}&lt;/ref&gt; because they deliberately implement the minimum functionality necessary to be classified as Turing complete languages.  Using such languages is a form of [[mathematical recreation]]: programmers can work out how to achieve basic programming constructs in an extremely difficult but mathematically Turing-equivalent language.&lt;ref&gt;[https://web.archive.org/web/20020609152409/http://www.catseye.mb.ca/esoteric/index.html Esoteric Topics in Computer Programming], Cat's Eye Technologies, Canada. (''"They present the programmer with the challenge, intrigue, and entertainment of looking at known algorithms and concepts in a whole new light."'')&lt;/ref&gt;

==See also==
{{Portal|Computer programming}}

* [[Greenspun's tenth rule]]
* [[Zawinski's law of software envelopment]]

==References==
{{Reflist}}

==Further reading==
* G. Fischer, A.C. Lemke, [http://www.cs.colorado.edu/department/publications/reports/docs/CU-CS-369-87.pdf "Constrained Design Processes: Steps Toward Convivial Computing"], Technical Report CU-CS-369-87, [[Colorado University]], USA.
* E.L. Hutchins, J.D. Hollan, D.A. Norman, [https://web.archive.org/web/20100613062436/http://cleo.ics.uci.edu/teaching/Winter10/231/readings/1-HutchinsHollanNorman-DirectManipulation-HCI.pdf "Direct Manipulation Interfaces"]. In ''User Centered System Design. New Perspectives on Human–Computer Interaction'' (1986).

[[Category:Computer-related introductions in 1982]]
[[Category:Alan Turing]]
[[Category:Recreational mathematics]]
[[Category:Theory of computation]]
[[Category:Software engineering folklore]]</text>
      <sha1>hs23zkw9ztp212opaf763im5ovkbjzs</sha1>
    </revision>
  </page>
  <page>
    <title>Walk forward optimization</title>
    <ns>0</ns>
    <id>30260760</id>
    <revision>
      <id>820141865</id>
      <parentid>745284018</parentid>
      <timestamp>2018-01-13T08:01:47Z</timestamp>
      <contributor>
        <username>Meini</username>
        <id>1874949</id>
      </contributor>
      <minor/>
      <comment>in sample, changed to in-sample, for easier reading</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11555">'''Walk forward optimization''' is a method used in [[finance]] for determining the best parameters to use in a [[trading strategy]].  The trading strategy is optimized with in-sample data for a time window in a data series.  The remainder of the data are reserved for [[out of sample testing]].  A small portion of the reserved data following the in-sample data is tested with the results recorded.  The in-sample time window is shifted forward by the period covered by the out of sample test, and the process repeated.  At the end, all of the recorded results are used to assess the trading strategy.&lt;ref name="KirkpatrickDahlquist2010"&gt;{{cite book|last1=Kirkpatrick|first1=Charles D.|last2=Dahlquist|first2=Julie R.|title=Technical Analysis: The Complete Resource for Financial Market Technicians|url=https://books.google.com/books?id=I5SgX5q5sQEC&amp;pg=PA548|accessdate=13 June 2011|date=2010-11-15|publisher=FT Press|isbn=978-0-13-705944-7|page=548}}&lt;/ref&gt;

It means to get the most suitable/stable parameters of the system and run the system with these parameters using another segment of data and these two segments of data do not overlap each other. It is the culmination of the following methods and helps in creation of robust systems.

'''''[[Backtesting]]''''' is using past data to test a trading system. It's useful because, if a system was not profitable in the past, that's a strong sign it won't be profitable in the future. It refers to applying a trading system to historical data to verify how a system would have performed during the specified time period.&lt;ref name=bt&gt;[http://www.investopedia.com/articles/trading/10/backtesting-walkforward-important-correlation.asp  Investopedia: Backtesting And Forward Testing]&lt;/ref&gt;

'''''Forward testing''''' is also known as '''''Walk forward testing''''' is the simulation of the real markets data on paper only. It means that though you are moving along the markets live, but you are not actually putting in real money, but doing virtual trading in the markets to understand the movements of markets better. Hence, it is also called '''''Paper Trading'''''. Forward performance testing is a simulation of actual trading and involves following the system's logic in a live market.&lt;ref name=bt /&gt;

==Overview==
One of the biggest issues with system development is that many systems do not hold up into the future. There are several reasons for this. The first is that the system is not based on a valid premise. Another is that the testing is not sound  for reasons such as:
* Lack of robustness in a system due to improper parameters. A system is considered robust if it runs well in any market conditions.
* Inconsistent rules and improper testing of the system using ‘out-of-sample’ and ‘in-sample’ data.

'''''Walk Forward Analysis''''' does optimization on a training set; test on a period after the set and then rolls it all forward and repeats the process. We have multiple out-of-sample periods and look at these results combined. Walk forward analysis was originally discussed by [[Robert E. Pardo]]. Walking forward can keep a trading model a step ahead.&lt;ref&gt;[http://www.allbusiness.com/business-finance/equity-funding-stock/166504-1.html Walking forward can keep a trading model a step ahead]&lt;/ref&gt; Walk forward is so called, as we have multiple walk training and testing periods is less likely to suffer from [[overfitting]].

''Walk forward testing allows us to develop a trading system while maintaining a reasonable ‘degree of freedom’''. Walk-forward testing carries the idea of ‘out-of-sample’ testing to the next level. It is a specific application of a technique known as [[Cross-validation (statistics)|Cross-validation]]. It means to take a segment of your data to optimize a system, and another segment of data to validate. Hence, here you optimize a window of data say past 1000 bars, and then test it on next 200 bars. Then roll the whole thing forward 200 bars and repeat the process. This gives you a large out of sample period and allows you to see how stable the system is over time.

Suppose you consider a strategy around a moving average. You take the first 3 months of data, and find that for that period a 20-minute moving average was optimal (using tick data). You then validate this rule by assessing its performance for the 4th month (i.e. profit, reward/risk or any other statistic of interest). Next, you repeat the optimization using data from month 2-4, and validate using month 5, and keep repeating this until you've reached the end of the data. The performance you get for the validation months (4-13) are your out-of-sample performance.

===The basics behind the data used===
Before doing the backtesting or optimization, one needs to set up the data required which is the historical data of a  specific time period. This historical data segment is divided into the following two types:
* '''''In-Sample Data''''': It is a past segment of market data (historical data) reserved for testing purposes. This data is used for the initial testing and any optimization and is the original parameters of a system under test.
* '''''Out-of-Sample Data''''': It is the reserved data set (historical data) which is not a part of the in-sample data. It is important as this ensures that the system is tested on another period of historical data not earlier thus removing any bias or influences in the checking of the system's performance.

The process is to first develop a trading system using in-sample data and then apply the out-of-sample data to the system. The results of both cases can then be compared and tested.

==Explanation==
The concept for walk-forward testing is similar to using ‘in-sample’ and ‘out-of-sample’ testing periods. Instead of optimizing on twenty years of data and using the last four years of data for testing, the optimization is done across ten years and the system is tested on the eleventh. Once this test is completed, move the whole time window forward one year and run the test-run on the next year. Find the optimum set of parameters for each of the 10-year windows and use that set of parameters to trade for the next year. Move the time window forward one year and run the test on the next year until all of the years in the data series have been tested.

When the system performance is evaluated, all of the one-year windows are consolidated to compose the out-of-sample periods for each of the optimal windows. The out-of-sample performance is used to judge how good the system is.

Walk-forward testing works like this. Let’s say that you have twelve years of data extending from 1998 to 2009 for the markets that you want to trade. Let’s also assume that your trading strategy needs a minimum of three years of data for testing and optimization.

To begin, start by developing and optimizing the system using only the first three years of data – in this example, 1998–2000. On these three years of data, try as many ideas as you like and optimize parameters in as many ways as you can think of. It is important not to look at any data after 2000! When you think you have found the ‘Holy Grail’ of trading systems, record the rules for the system with the optimum parameters. These rules and optimized parameters are to be used later for the final testing with new data starting with 2000.

Slide the three-year time window of data forward a little – say one month. Now, the data that you are working with runs from the 2nd month of 1998 to the 2nd month of 2000. Repeat the analysis, including optimization and record the rules and optimized parameters. In the final pass, these parameters will be used for the 2nd month of 2000.

Continue with ‘walking forward’ and optimizing the three-year data periods. Record the results for use in the first month following the three-year optimization period. When your data finally runs out in 2009, go back, and test the system for the entire period from 2000 to 2009. Switch the rules and parameters each month to use the ones that you found and recorded.  In effect, you are performing a new out-of-sample test for each month. The system performance for these nine out-of-sample years (108 out-of-sample months) is a much better indication of how a system will perform in real time than the performance of any single time period used for optimization.

There is nothing magic about the assumed time-periods – three years for system development and one month for the walk-forward interval. Picking these two time parameters is a trade-off between optimization time and statistical validity of the results. In practice, I have found that using about 20% of the optimization period for the walk- forward window works fairly well. Which window sizes work best is also affected by the given system, for different systems the optimal training and out-of-sample window size will be different.

If the results for the ‘out-of-sample’ months look good, continue the walk-forward process in real time to find the parameters to use with real money. ''Another advantage'' to this method of system development and trading is that your system will better adapt to changes in market behavior over time. Markets do change with time – we have all seen systems that have made money for several years and then simply stopped working because the markets have changed how often these changes affect the system is related to the best size for the training and out-of-sample set. Manual in-sample and out-of-sample walk forward testing as described is useful, but automated walk forward testing with automated parameter selection is the best way to avoid [[curve fitting]].

===Conclusion===
For a better understanding, please see the example here.&lt;ref&gt;[http://www.futuresmag.com/Issues/2010/April-2010/Pages/Can-your-system-do-the-walk.aspx Can your system do the walk]&lt;/ref&gt;

In order to evaluate any system, one should check out its performance when using the "Out-of-Sample Data" (test data) and not the "In-Sample Data" (data used for optimization of the system). Thus, walk forward test determines the optimized system performance as follows:
* ''Was it realistic?'' It is considered realistic if it could fit to the entire test data (or at least to a larger segment of the test data) used. It implies that the system has the characteristics of the real time markets and is robust.
* ''Is it [[overfitting]]?'' If the system does not perform well using the test data and seems to fit only chance characteristics (not necessarily part of the test data), the system is considered to be overfitting. It is neither a robust nor reliable one and ought not to be used for trading.

Hence, the out-of-sample data plays a crucial role in determining the validity and reliability of the system and is a realistic estimate of how a system should work in real markets.

==See also==
*[[Backtesting]]
*[[Trading strategy]]
*[[Optimization (mathematics)]]
*[[Overfitting]]

== References ==
{{Reflist}}

== Literature ==
* Katz, Jeffrey Owen, and McCormick, Donna L.  "The Encyclopedia of Trading Strategies."  McGraw-Hill, 2000.
* Essential technical analysis: tools and techniques to spot market trends By Leigh Stevens
* The encyclopedia of technical market indicators By Robert W. Colby

== External links ==
* [http://findarticles.com/p/articles/mi_qa5282/is_200504/ai_n24296459/ Out-of-sample and walk-forward testing]

{{Use dmy dates|date=February 2011}}

[[Category:Mathematical finance]]
[[Category:Stock market]]
[[Category:Technical analysis]]</text>
      <sha1>edgofav1ur4y142xu3funkag4yx0bnv</sha1>
    </revision>
  </page>
</mediawiki>
