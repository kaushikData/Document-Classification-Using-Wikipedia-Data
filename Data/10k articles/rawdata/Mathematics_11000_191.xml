<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>231 (number)</title>
    <ns>0</ns>
    <id>6317392</id>
    <revision>
      <id>811538202</id>
      <parentid>811384999</parentid>
      <timestamp>2017-11-22T07:33:13Z</timestamp>
      <contributor>
        <username>Alexf</username>
        <id>55327</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/203.71.175.142|203.71.175.142]] ([[User talk:203.71.175.142|talk]]) to last version by Paintspot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2055">{{Infobox number
| number = 231
}}
'''231''' ('''two hundred [and] thirty-one''') is the [[natural number]] following [[230 (number)|230]] and preceding [[232 (number)|232]].
==In mathematics==
Two hundred [and] thirty-one 231 = 3·7·11, sphenic number, [[triangular number]], [[hexagonal number]], [[octahedral number]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A005900|title=Sloane's A005900 : Octahedral numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-24}}&lt;/ref&gt; [[centered octahedral number]],&lt;ref&gt;{{Cite web|url=https://oeis.org/A001845|title=Sloane's A001845 : Centered octahedral numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-24}}&lt;/ref&gt; the number of integer [[partition (number theory)|partitions]] of 16, [[Mertens function]] returns 0,&lt;ref&gt;{{Cite web|url=https://oeis.org/A028442|title=Sloane's A028442 : Numbers n such that Mertens' function is zero|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-24}}&lt;/ref&gt; and is the number of cubic inches in a U.S. liquid [[gallon]].

==In chemistry==
* [[Actinium-231|Ac-231]]  is an [[isotope]] of [[actinium]]. 
* [[Americium-231|Am-231]]  is an artificial [[isotope]] of [[americium]]. 
* [[Protactinium-231|Pa-231]]  is a naturally occurring [[isotope]] of [[protactinium]]. 
* [[Radium-231|Ra-231]]  is an [[isotope]] of [[radium]]. 
* [[Thorium-231|Th-231]]  is an [[isotope]] of [[thorium]]. 
==In other fields==
231 is:
* The year A.D. [[231]] or [[231 BC]].
* +231 is the [[Telephone numbers in Liberia|country code]] for [[Liberia]].
* ''[[Pacific 231]]'', an orchestral work by French composer [[Arthur Honegger]].
* ''[[Pacific 231 (film)|Pacific 231]]'', a 1949 short film directed by [[Jean Mitry]].
* [[M-231 (Michigan highway)]], a highway in Michigan

== References ==
{{Reflist}}
{{Integers|2}}

{{DEFAULTSORT:231 (Number)}}
[[Category:Integers]]

{{Num-stub}}</text>
      <sha1>7f90qlwtnm8vblpl34fg79k5sff5i7e</sha1>
    </revision>
  </page>
  <page>
    <title>Anatolii Goldberg</title>
    <ns>0</ns>
    <id>34278093</id>
    <revision>
      <id>842799860</id>
      <parentid>842761656</parentid>
      <timestamp>2018-05-24T18:54:36Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <minor/>
      <comment>remove [[:Category:Jewish mathematicians]]. [[WP:G4]] per [[:WP:Categories for discussion/Log/2007 May 14#Category:Jewish_mathematicians]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4046">{{Distinguish|Anatol Goldberg}}

[[File:Anatolii Goldberg.jpg|thumb|A. A. Goldberg in Leningrad, 1982 (photo by D. Drasin)]]
'''Anatolii Asirovich Goldberg''' ({{lang-ru|Анатолий Асирович Гольдберг}}, {{lang-ua|Анатолій Асірович Гольдберг}}, {{lang-he|אנטולי גולדברג}}, April 2, 1930 in [[Kyiv]] &amp;ndash; October 11, 2008 in [[Netanya]]) was a [[Soviet]] and [[Israel]]i [[mathematician]] working in [[complex analysis]]. His main area of research was the theory of [[entire function|entire]] and [[meromorphic]] functions.&lt;ref&gt;{{cite journal|mr=2502930|last1=Zarīchniĭ|first1=M. M.|last2=Skaskīv|first2=O. B.|last3=Sheremeta|first3=M. M.|title=Anatolīĭ Asīrovich Golʹdberg (April 2, 1930&amp;ndash;October 11, 2008)|journal=Mat. Stud.|volume=30|year=2008|issue=2|page=214|language=Ukrainian|url=http://www.vntl.com/im/pdf/30_2_214_214.pdf}}&lt;/ref&gt;

==Life and work==

Goldberg received his PhD in 1955 from [[Lvov University]] under the direction
of Lev Volkovyski. He worked as a docent in [[Uzhhorod National University|Uzhgorod University]] (1955&amp;ndash;1963), then in Lvov University (1963&amp;ndash;1997), where he became a full professor in 1965, and in [[Bar Ilan University]] (1997&amp;ndash;2008). Goldberg, jointly with I.V.&amp;nbsp;Ostrovskii and B.Ya.&amp;nbsp;Levin, was awarded the State Prize of Ukraine
in 1992.

Among his main achievements are:
* construction of meromorphic functions with infinitely many deficient values,
* solution of the inverse problem of [[Nevanlinna theory]] for finitely many deficient values,
* development of the integral with respect to a semi-additive measure.

He authored a book {{harvtxt|Goldberg|Ostrovskii|2008}} and over 150 research papers.

Several things are named after him: Goldberg's examples,&lt;ref name="Hayman"&gt;{{cite book|mr=0164038|first=W. K.|last=Hayman|author-link=Walter Hayman|title=Meromorphic functions|location=Oxford|publisher=Clarendon Press|year=1964}}&lt;/ref&gt;
Goldberg's constants,&lt;ref name="be"&gt;W. Bergweiler and A. Eremenko, 
[https://arxiv.org/abs/1111.2296 Goldberg's constants]&lt;/ref&gt; and Goldberg's conjecture.&lt;ref name="langley"&gt;{{cite journal|last=Langley|first=J.K.|mr=1447956|title=On the zeros of the second derivative|journal=Proc. Roy. Soc. Edinburgh Sect. A|volume=127|year=1997|issue=2|pages=359&amp;ndash;368|doi=10.1017/S0308210500023672}}&lt;/ref&gt;
&lt;ref name="yamanoi"&gt;{{cite journal|last=Yamanoi|first=K.|mr=3056292|title=Zeros of higher derivatives of meromorphic functions in the complex plane|journal=Proc. London Math. Soc.|volume=106|year=2013|issue=4|pages=703&amp;ndash;780|doi=10.1112/plms/pds051 }}&lt;/ref&gt;

==Selected publications==

* {{cite book|first1=A. A.|last1=Goldberg|first2=I. V.|last2= Ostrovskii|title=Distribution of values of meromorphic functions|mr=0280720|language=Russian|publisher=Nauka|location=Moscow|year=1970|ref=harv}}, translated as {{cite book|first1=A. A.|last1=Goldberg|first2=I. V.|last2= Ostrovskii|title=Distribution of values of meromorphic functions|publisher=Amer. Math. Soc.|year=2008|url=http://www.ams.org/publications/authors/books/postpub/mmono-236|mr=2435270|ref=harv|location=Providence, RI|isbn=978-0-8218-4265-2}}

== References ==
&lt;references/&gt;

== External links ==
*{{cite journal|title=McTutor history of mathematics archive|url=http://www-history.mcs.st-and.ac.uk/Biographies/Goldberg.html}}
* {{MathGenealogy|id=58900|title=Anatolii Goldberg}}
* {{cite journal|first1=A.|last1=Eremenko|first2=I.|last2=Ostrovskii|first3=M.|last3=Sodin|year=1998|title=Anatolii Asirovich Gol'dberg|journal=Complex Variables, Theory and Application|volume=37|issue=1&amp;ndash;4|pages=1&amp;ndash;51|doi=10.1080/17476939808815121|url=http://www.math.purdue.edu/~eremenko/dvi/official.pdf}}

{{Authority control}}

{{DEFAULTSORT:Goldberg, Anatolii}}
[[Category:Ukrainian Jews]]
[[Category:Ukrainian mathematicians]]
[[Category:Israeli Jews]]
[[Category:Israeli mathematicians]]
[[Category:1930 births]]
[[Category:2008 deaths]]
[[Category:Complex analysts]]
[[Category:Mathematical analysts]]</text>
      <sha1>guixg6r23tq7tjjypviis5oi4tghadq</sha1>
    </revision>
  </page>
  <page>
    <title>Arboricity</title>
    <ns>0</ns>
    <id>2476311</id>
    <revision>
      <id>802150732</id>
      <parentid>789964276</parentid>
      <timestamp>2017-09-24T09:04:49Z</timestamp>
      <contributor>
        <username>Syp</username>
        <id>91052</id>
      </contributor>
      <comment>/* Related concepts */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8980">The '''arboricity''' of an [[undirected graph]] is the minimum number of [[Tree (graph theory)|forests]] into which its edges can be [[graph partition|partitioned]]. Equivalently it is the minimum number of [[spanning tree (mathematics)|spanning forests]] needed to cover all the edges of the graph.

==Example==
[[Image:K44 arboricity.svg|thumb|A partition of the [[complete bipartite graph]] ''K''&lt;sub&gt;4,4&lt;/sub&gt; into three forests, showing that it has arboricity three.]]
The figure shows the [[complete bipartite graph]] ''K''&lt;sub&gt;4,4&lt;/sub&gt;, with the colors indicating a partition of its edges into three forests. ''K''&lt;sub&gt;4,4&lt;/sub&gt; cannot be partitioned into fewer forests, because any forest on its eight vertices has at most seven edges, while the overall graph has sixteen edges, more than double the number of edges in a single forest. Therefore, the arboricity of ''K''&lt;sub&gt;4,4&lt;/sub&gt; is three.

==Arboricity as a measure of density==
The arboricity of a graph is a measure of how [[dense graph|dense]] the graph is: graphs with many edges have high arboricity, and graphs with high arboricity must have a dense subgraph.

In more detail, as any n-vertex forest has at most n-1 edges, the arboricity of a graph with n vertices and m edges is at least &lt;math&gt;\lceil m/(n-1)\rceil&lt;/math&gt;. Additionally, the subgraphs of any graph cannot have arboricity larger than the graph itself, or equivalently the arboricity of a graph must be at least the maximum arboricity of any of its subgraphs. [[Crispin St. J. A. Nash-Williams|Nash-Williams]] proved that these two facts can be combined to characterize arboricity: if we let n&lt;sub&gt;S&lt;/sub&gt; and m&lt;sub&gt;S&lt;/sub&gt; denote the number of vertices and edges, respectively, of any subgraph S of the given graph, then the arboricity of the graph equals &lt;math&gt;\max\{\lceil m_S/(n_S-1)\rceil\}.&lt;/math&gt;

Any [[planar graph]] with &lt;math&gt;n&lt;/math&gt; vertices has at most &lt;math&gt;3n-6&lt;/math&gt; edges, from which it follows by Nash-Williams' formula that planar graphs have arboricity at most three. Schnyder used a special decomposition of a planar graph into three forests called a '''Schnyder wood''' to find a [[Fáry's theorem|straight-line embedding]] of any planar graph into a grid of small area.

==Algorithms==
The arboricity of a graph can be expressed as a special case of a more general [[matroid partitioning]] problem, in which one wishes to express a set of elements of a matroid as a union of a small number of independent sets. As a consequence, the arboricity can be calculated by a polynomial-time algorithm {{Harv|Gabow|Westermann|1992}}.

== Related concepts ==

The '''anarboricity''' of a graph is the maximum number of edge-disjoint nonacyclic subgraphs into which the edges of the graph can be partitioned.

The '''star arboricity''' of a graph is the size of the minimum forest, each tree of which is a [[Star (graph theory)|star]] (tree with at most one non-leaf node), into which the edges of the graph can be partitioned. If a tree is not a star itself, its star arboricity is two, as can be seen by partitioning the edges into two subsets at odd and even distances from the tree root respectively. Therefore, the star arboricity of any graph is at least equal to the arboricity, and at most equal to twice the arboricity.

The '''[[linear arboricity]]''' of a graph is the minimum number of [[linear forest]]s (a collection of paths) into which the edges of the graph can be partitioned. The linear arboricity of a graph is closely related to its maximum [[Degree (graph theory)|degree]] and its [[slope number]].

The '''[[pseudoarboricity]]''' of a graph is the minimum number of [[pseudoforest]]s into which its edges can be partitioned. Equivalently, it is the maximum ratio of edges to vertices in any subgraph of the graph, rounded up to an integer. As with the arboricity, the pseudoarboricity has a matroid structure allowing it to be computed efficiently {{Harv|Gabow|Westermann|1992}}.

The '''[[Thickness (graph theory)|thickness]]''' of a graph is the minimum number of planar subgraphs into which its edges can be partitioned. As any planar graph has arboricity three, the thickness of any graph is at least equal to a third of the arboricity, and at most equal to the arboricity.

The '''[[Degeneracy (graph theory)|degeneracy]]''' of a graph is the maximum, over all [[induced subgraph]]s of the graph, of the minimum [[Degree (graph theory)|degree]] of a vertex in the subgraph.  The degeneracy of a graph with arboricity &lt;math&gt;a&lt;/math&gt; is at least equal to &lt;math&gt;a&lt;/math&gt;, and at most equal to &lt;math&gt;2a-1&lt;/math&gt;. The coloring number of a graph, also known as its Szekeres-Wilf number {{Harv|Szekeres|Wilf|1968}} is always equal to its degeneracy plus 1 {{Harv|Jensen|Toft|1995|p=77f.}}.

The '''[[Strength_of_a_graph|strength]]''' of a graph is a fractional value whose integer part gives the maximum number of disjoint spanning trees that can be drawn in a graph. It is the packing problem that is dual to the covering problem raised by the arboricity. The two parameters have been studied together by Tutte and Nash-Williams.

The '''fractional arboricity''' is a refinement of the arboricity, as it is defined for a graph &lt;math&gt;G&lt;/math&gt; as &lt;math&gt;\max\{m_S/(n_S-1) | S \subseteq G\}.&lt;/math&gt; In other terms, the arboricity of a graph is the ceiling of the fractional arboricity. 

The '''[[(a,b)-decomposability]]''' generalizes the arboricity. A graph is &lt;math&gt;(a,b)&lt;/math&gt;-decomposable if its edges can be partitioned into &lt;math&gt;a+1&lt;/math&gt; sets, each one of them inducing a forest, except one who induces a graph with maximum degree &lt;math&gt;b&lt;/math&gt;. A graph with arboricity &lt;math&gt;a&lt;/math&gt; is &lt;math&gt;(a,0)&lt;/math&gt;-decomposable.

The '''tree number''' is the minimal number of trees covering the edges of a graph.

== References ==
{{refbegin}}
* {{Cite journal|authorlink=Noga Alon|first=N.|last=Alon|title=The linear arboricity of graphs|journal=[[Israel Journal of Mathematics]]|volume=62|issue=3|year=1988|pages=311–325|doi=10.1007/BF02783300|mr=0955135|ref=harv}}
*{{cite journal|first1=B.|last1=Chen|first2=M.|last2=Matsumoto|first3=J.|last3=Wang|first4=Z.|last4=Zhang|first5= J.|last5=Zhang|title=A short proof of Nash-Williams' theorem for the arboricity of a graph|journal=[[Graphs and Combinatorics]]|volume=10|issue=1|year=1994|pages=27–28|doi=10.1007/BF01202467|mr=1273008|ref=harv}}
*{{Cite journal|first1=P.|last1=Erdős|author1-link=Paul Erdős|first2=A.|last2=Hajnal|author2-link=András Hajnal|title=On chromatic number of graphs and set-systems|journal=[[Acta Mathematica Hungarica]]|volume=17|issue=1–2|pages=61–99|year=1966|url=http://www.math-inst.hu/~p_erdos/1966-07.pdf|doi=10.1007/BF02020444|mr=0193025|ref=harv}}
*{{Cite journal|first1=H. N.|last1=Gabow|first2=H. H.|last2=Westermann|title=Forests, frames, and games: Algorithms for matroid sums and applications|journal=[[Algorithmica]]|volume=7|issue=1|year=1992|pages=465–497|mr=1154585|doi=10.1007/BF01758774|ref=harv}}
*{{cite journal|first1=S. L.|last1=Hakimi|author1-link=S. L. Hakimi |first2=J.|last2=Mitchem|first3=E. E.|last3=Schmeichel|title=Star arboricity of graphs|journal=[[Discrete Mathematics (journal)|Discrete Mathematics]]|volume=149|year=1996|pages=93–98|mr=1375101|doi=10.1016/0012-365X(94)00313-8|ref=harv}}
*{{Cite book
 | last1 = Jensen | first1 = T. R.
 | last2 = Toft | first2 = B.
 | title = Graph Coloring Problems
 | publisher = Wiley-Interscience
 | location = New York
 | year = 1995
 | isbn = 0-471-02865-7
 | mr = 1304254
 | ref = harv}}
*{{cite journal|author=C. St. J. A. Nash-Williams|authorlink=Crispin St. J. A. Nash-Williams|title=Edge-disjoint spanning trees of finite graphs|journal=[[Journal of the London Mathematical Society]]|volume=36|issue=1|year=1961|pages=445–450|doi=10.1112/jlms/s1-36.1.445|mr=0133253|ref=harv}}
*{{cite journal|author=C. St. J. A. Nash-Williams|authorlink=Crispin St. J. A. Nash-Williams|title=Decomposition of finite graphs into forests|journal=[[Journal of the London Mathematical Society]]|volume=39|issue=1|year=1964|pages=12|doi=10.1112/jlms/s1-39.1.12|mr=0161333|ref=harv}}
*{{cite conference|author=W. Schnyder|url=http://portal.acm.org/citation.cfm?id=320176.320191|title=Embedding planar graphs on the grid|booktitle=Proc. 1st ACM/SIAM Symposium on Discrete Algorithms (SODA)|year=1990|pages=138–148}}
*{{Cite journal|first1=G.|last1=Szekeres|author1-link=George Szekeres|first2=H. S.|last2=Wilf|author2-link=Herbert Wilf|title=An inequality for the chromatic number of a graph|journal=[[Journal of Combinatorial Theory]]|year=1968|ref=harv|mr=0218269|doi=10.1016/s0021-9800(68)80081-x }}
*{{cite journal|first=W. T.|last=Tutte|authorlink=W. T. Tutte|title=On the problem of decomposing a graph into n connected factors|journal=[[Journal of the London Mathematical Society]]|volume=36|issue=1|year=1961|pages=221–230|doi=10.1112/jlms/s1-36.1.221|mr=0140438|ref=harv}}
{{refend}}

[[Category:Graph invariants]]
[[Category:Spanning tree]]</text>
      <sha1>1xnyt14st55r2z6q876x61scsntaqxg</sha1>
    </revision>
  </page>
  <page>
    <title>BIT Numerical Mathematics</title>
    <ns>0</ns>
    <id>40118816</id>
    <revision>
      <id>840850151</id>
      <parentid>840850094</parentid>
      <timestamp>2018-05-12T15:48:22Z</timestamp>
      <contributor>
        <ip>189.103.192.127</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2878">{{Infobox Journal
| title = BIT Numerical Mathematics
| cover = BIT Numerical Mathematics.jpg
| editor = Lars Eldén
| discipline = [[Numerical analysis]]
| language = 
| abbreviation = BIT Numer. Math.
| mathscinet = BIT
| publisher = [[Springer Science+Business Media]]
| country =
| frequency = Quarterly
| history = 1961–present
| openaccess = 
| license =
| impact = 0.977
| impact-year = 2012
| website = http://www.csc.kth.se/BIT/
| link1 = https://www.springer.com/mathematics/computational+science+%26+engineering/journal/10543
| link1-name = Journal page at publisher's website
| link2 = https://link.springer.com/journal/10543
| link2-name = Online access
| JSTOR = 
| OCLC = 51522871
| LCCN = sn95029245
| CODEN = 
| ISSN = 0006-3835
| eISSN = 1572-9125
}}
'''''BIT Numerical Mathematics''''' is a quarterly [[Peer review|peer-reviewed]] [[mathematics journal]] that covers research in [[numerical analysis]]. It was established in 1961 by [[Carl Erik Fröberg]] and is published by [[Springer Science+Business Media]]. The name "BIT" is a reverse acronym of ''Tidskrift för Informationsbehandling'' ([[Swedish language|Swedish]]: ''Journal of Information Processing'').&lt;ref name="history"&gt;{{cite web |url=http://www.csc.kth.se/BIT/BIT_History.html |title=BIT - A Nordic computer related journal |last=Fröberg |first=Carl Erik |accessdate=31 July 2013}}&lt;/ref&gt;

Previous [[editors-in-chief]] have been Carl Erik Fröberg (1961-1992), Åke Björck (1993-2002), [[Axel Ruhe]] (2003-2015), and [[Lars Eldén]] (2016). Since 2017, the editor-in-chief position is shared between [[Gunilla Kreiss]] and [[Lars Eldén]].

== Abstracting and indexing ==
The journal is abstracted and indexed in:
{{columns-list|colwidth=30em|
* [[Science Citation Index]]
* [[Scopus]]
* [[Zentralblatt Math]]
* [[EBSCO Publishing|EBSCO databases]]
* [[Academic OneFile]]
* [[ACM Digital Library]]
* [[Computer Abstracts International Database]]
* [[Computer Science Index]]
* [[Current Contents]]/Physical, Chemical and Earth Sciences
* [[Current Index to Statistics]]
* [[International Bibliography of Book Reviews]]
* [[International Bibliography of Periodical Literature]]
* [[Mathematical Reviews]]
* [[PASCAL (database)|PASCAL]]
}}
According to the ''[[Journal Citation Reports]]'', the journal has a 2016 [[impact factor]] of 1.670.&lt;ref name=WoS&gt;{{cite book |year=2016 |chapter=BIT Numerical Mathematics |title=2016 [[Journal Citation Reports]] |publisher=[[Thomson Reuters]] |edition=Science |series=[[Web of Science]] |postscript=.}}&lt;/ref&gt;

== References ==
{{reflist}}

== External links ==
* {{Official website|http://www.csc.kth.se/BIT/}}

[[Category:Mathematics journals]]
[[Category:Publications established in 1961]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:English-language journals]]
[[Category:Quarterly journals]]


{{math-journal-stub}}</text>
      <sha1>1rykffffp9qariwfzlx9sr4x6u4shpn</sha1>
    </revision>
  </page>
  <page>
    <title>Chaos computing</title>
    <ns>0</ns>
    <id>14158490</id>
    <revision>
      <id>805366437</id>
      <parentid>797167613</parentid>
      <timestamp>2017-10-14T22:12:03Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */clean up |journal= parameter per [[User:JCW-CleanerBot#Logic|task]], replaced: Int. J. of → International Journal of using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7344">{{context|date=June 2011}}

'''Chaos computing''' is the idea of using [[chaos theory|chaotic systems]] for [[computation]]. In particular, chaotic systems can be made to produce all types of [[logic gates]] and further allow them to be morphed into each other.

== Introduction ==

Chaotic systems generate large numbers of patterns of behavior and are irregular because they switch between these patterns. They exhibit sensitivity to initial conditions which, in practice, means that chaotic systems can switch between patterns extremely fast.

Modern digital [[computer]]s perform computations based upon digital logic operations implemented at the lowest level as [[logic gates]].  There are essentially seven basic logic functions implemented as logic gates: [[AND gate|AND]], [[OR gate|OR]], [[NOT gate|NOT]], [[NAND gate|NAND]], [[NOR gate|NOR]], [[XOR gate|XOR]] and [[XNOR gate|XNOR]].

A chaotic morphing logic gate consists of a generic [[Nonlinear system|nonlinear circuit]] that exhibits chaotic dynamics producing various patterns. A control mechanism is used to select patterns that correspond to different logic gates. The sensitivity to initial conditions is used to switch between different patterns extremely fast (well under a computer clock cycle).

== Chaotic Morphing ==

As an example of how chaotic morphing works, consider a generic chaotic system known as the [[Logistic map]]. This nonlinear map is very well studied for its chaotic behavior and its functional representation is given by:

:&lt;math&gt;\qquad x_{n+1} = r x_n (1-x_n) &lt;/math&gt;

In this case, the value of {{math|''x''}} is chaotic when {{math|''r''}} &gt;~ 3.57... and rapidly switches between different patterns in the value of {{math|''x''}} as one iterates the value of {{math|''n''}}. A simple threshold controller can control or direct the chaotic map or system to produce one of many patterns. The controller basically sets a threshold on the map such that if the iteration ("chaotic update") of the map takes on a value of {{math|''x''}} that lies above a given threshold value, {{math|''x''}}*,then the output corresponds to a 1, otherwise it corresponds to a 0. One can then reverse engineer the chaotic map to establish a lookup table of thresholds that robustly produce any of the logic gate operations.&lt;ref&gt;Sudeshna Sinha and William L. Ditto, "Dynamics Based Computation", Physical Review Letters, vol. 81 (1998) pp. 2156-2159&lt;/ref&gt;&lt;ref&gt;Sudeshna Sinha and William L. Ditto, "Computing with Distributed Chaos", Physical Review E, vol. 60 (1999) pp. 363-377.&lt;/ref&gt;&lt;ref&gt;Toshinori Munakata, Sudeshna Sinha and William L. Ditto, "Chaos Computing: Implementation of Fundamental Logical and Arithmetic Operations and Memory by Chaotic Elements", IEEE Transactions on Circuits and Systems, vol. 49 (2002) pp. 1629-1633.&lt;/ref&gt; Since the system is chaotic, we can then switch between various gates ("patterns") exponentially fast.

== ChaoGate ==

[[File:Ditto Chaos Computing Example 1.jpg|thumb]]
The ''ChaoGate'' is an implementation of a chaotic morphing logic gate developed by the inventor of the technology William Ditto, along with [[Sudeshna Sinha]] and K. Murali.&lt;ref&gt;{{cite web| url=http://news.techeye.net/chips/scientists-use-chaos-theory-to-create-new-chip |
title=Scientists use chaos theory to create new chip Chaogate holds exciting processing prospects |
date =16 Nov 2010 | author= Matthew Finnegan | publisher=TechEYE.net | accessdate=October 15, 2012}}&lt;/ref&gt;&lt;ref&gt;"Method and apparatus for a chaotic computing module," W. Ditto, S. Sinha and K. Murali, US Patent Number 07096347 (August 22, 2006). {{US Patent|8,520,191}}&lt;/ref&gt;

A Chaotic computer, made up of a lattice of ChaoGates, has been demonstrated by Chaologix Inc.

==Research==

Recent research has shown how chaotic computers can be recruited in Fault Tolerant applications, by introduction of dynamic based fault detection methods.&lt;ref&gt;"Fault tolerance and detection in chaotic Computers" M.R. Jahed-Motlagh, B. Kia, W.L. Ditto and S. Sinha, International Journal of Bifurcation and Chaos 17, 1955-1968(2007)&lt;/ref&gt; Also it has been demonstrated that multidimensional dynamical states available in a single ChaoGate can be exploited to implement parallel chaos computing,&lt;ref name="Chua 2005"&gt;"Chaos-based computation via Chua's circuit: parallel computing with application to the SR flip-flop"D. Cafagna, G. Grassi, International Symposium on Signals, Circuits and Systems, ISSCS 2005, Volume: 2, 749-752 (2005)&lt;/ref&gt;&lt;ref&gt;
"Parallel computing with extended dynamical systems" S. Sinha, T. Munakata and W.L. Ditto
Physical Review E, 65 036214 [1-7](2002)&lt;/ref&gt; and as an example, this parallel architecture can lead to constructing an SR like memory element through one ChaoGate.&lt;ref name="Chua 2005" /&gt; As another example, it has been proved that any logic function can be constructed directly from just one ChaoGate.&lt;ref&gt;"Reconfigurable logic blocks Based on a chaotic Chua circuit," H. R. Pourshaghaghi, B. Kia, W. Ditto and M. R. Jahed-Motlagh, to be published in CHAOS, SOLITONS &amp; FRACTALS&lt;/ref&gt;

== See also ==
* [[Chua's circuit]]

== References ==

{{reflist}}
*"The 10 Coolest Technologies You’ve Never Heard Of – Chaos Computing," PC Magazine, Vol. 25, No. 13, page p.&amp;nbsp;66, August 8, 2006. [https://www.pcmag.com/article2/0,2704,1990288,00.asp]
*"Logic from Chaos," MIT Technology Review, June 15, 2006. [http://www.technologyreview.com/Biztech/16989/]
*"Exploiting the controlled responses of chaotic elements to design configurable hardware," W. L. Ditto and S. Sinha, Philosophical Transactions of the Royal Society London A, 364, pp.&amp;nbsp;2483–2494 (2006) {{doi|10.1098/rsta.2006.1836}}.
*"Chaos Computing: ideas and implementations" William L. Ditto, K. Murali and S. Sinha, Philosophical Transactions of the Royal Society London A, (2007) {{doi|10.1098/rsta.2007.2116}}.
*"Experimental realization of the fundamental NOR Gate using a chaotic circuit," K. Murali, Sudeshna Sinha and William L. Ditto Phys. Rev. E 68, 016205 (2003). {{doi|10.1103/PhysRevE.68.016205}}
*"Implementation of NOR gate by a chaotic Chua’s circuit," K. Murali, Sudeshna Sinha and William L. Ditto, International Journal of Bifurcation and Chaos, Vol. 13, No. 9, pp.&amp;nbsp;1–4, (2003). {{doi|10.1142/S0218127403008053}}
*"Fault tolerance and detection in chaotic Computers" M.R. Jahed-Motlagh, B. Kia, W.L. Ditto and S. Sinha, International Journal of Bifurcation and Chaos 17, 1955-1968(2007){{doi|10.1142/S0218127407018142}}
*"Chaos-based computation via Chua's circuit: parallel computing with application to the SR flip-flop"D. Cafagna, G. Grassi, International Symposium on Signals, Circuits and Systems, ISSCS 2005, Volume: 2, 749-752 (2005) {{doi|10.1109/ISSCS.2005.1511349}}
*"Parallel computing with extended dynamical systems" S. Sinha, T. Munakata and W.L. Ditto; Physical Review E, 65 036214 [1-7](2002) {{doi|10.1103/PhysRevE.65.036214}}
*"Reconfigurable logic blocks Based on a chaotic Chua circuit," H. R. Pourshaghaghi, B. Kia, W. Ditto and M. R. Jahed-Motlagh, to be published in CHAOS, SOLITONS &amp; FRACTALS {{doi|10.1016/j.chaos.2007.11.030}}

== External links ==
* [http://www.chaologix.com/ www.chaologix.com]

{{DEFAULTSORT:Chaos Computing}}
[[Category:Classes of computers]]
[[Category:Models of computation]]
[[Category:Theoretical computer science]]</text>
      <sha1>ahr79rm7feic3834155yilj61pm7yfh</sha1>
    </revision>
  </page>
  <page>
    <title>Chicago school (mathematical analysis)</title>
    <ns>0</ns>
    <id>13328208</id>
    <revision>
      <id>834498673</id>
      <parentid>770762655</parentid>
      <timestamp>2018-04-06T01:32:11Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */HTTP→HTTPS for [[National Science Foundation]], replaced: http://www.nsf.gov/ → https://www.nsf.gov/ using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1164">{{Refimprove
| date = February 2017
}}{{Expand section|date=February 2017}}

In mathematics, the '''Chicago school of mathematical analysis''' is a [[school of thought]] which emphasizes the applications of [[Fourier analysis]] to the study of [[partial differential equations]]. Mathematician [[Antoni Zygmund]] cofounded the school with his doctoral student [[Alberto Calderón]] at the [[University of Chicago]] in the 1950s.{{Citation needed|date=February 2017|reason=Good info - where did it come from and where could a reader find out more?}}

In 1986 Zygmund received the [[National Medal of Science]], in part for his "creation and leadership of the strongest school of analytical research in the contemporary mathematical world."&lt;ref name="USNSF"&gt;{{cite web | title=The President's National Medal of Science: Recipient Details | year=2006 | publisher=The National Science Foundation | url=https://www.nsf.gov/od/nms/recip_details.cfm?recip_id=411}}&lt;/ref&gt;

== See also ==
* [[Joseph Fourier]]
* [[Mathematical analysis]]

==References==
{{reflist}}

[[Category:University of Chicago]]
[[Category:Philosophical schools and traditions]]
{{Mathanalysis-stub}}</text>
      <sha1>k2037pnjepbmpjezio9eu9gjj60pwzn</sha1>
    </revision>
  </page>
  <page>
    <title>Convolution (computer science)</title>
    <ns>0</ns>
    <id>1463083</id>
    <revision>
      <id>849220931</id>
      <parentid>845801342</parentid>
      <timestamp>2018-07-07T11:56:46Z</timestamp>
      <contributor>
        <username>Neils51</username>
        <id>16416757</id>
      </contributor>
      <minor/>
      <comment>/* In programming languages */ grammar/usage - 'lists' is a countable noun</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10273">{{Original research|date=May 2014}}

In [[computer science]], specifically [[formal language]]s, '''convolution''' (sometimes referred to as '''zip''')  is a function which maps a [[tuple]] of [[sequence]]s into a [[sequence]] of [[tuple]]s.

== Example ==
Given the three words ''cat'', ''fish'' and ''be'' where |''cat''| is 3, |''fish''| is 4 and |''be''| is 2. Let &lt;math&gt;\ell&lt;/math&gt; denote the length of the longest word which is ''fish''; &lt;math&gt;\ell = 4&lt;/math&gt;. The convolution of ''cat'', ''fish'', ''be'' is then 4 tuples of elements:

: &lt;math&gt; (c,f,b)(a,i,e)(t,s,\#)(\#,h,\#)&lt;/math&gt;

where ''#'' is a symbol not in the original alphabet. In [[Haskell (programming language)|Haskell]] this truncates to shortest sequence &lt;math&gt;\underline{\ell}&lt;/math&gt;, where &lt;math&gt;\underline{\ell} = 2&lt;/math&gt;:

&lt;source lang="haskell"&gt;
zip3 "cat" "fish" "be"
-- [('c','f','b'),('a','i','e')]
&lt;/source&gt;

== Definition ==
Let &amp;Sigma; be an [[Alphabet (computer science)|alphabet]], # a symbol not in &amp;Sigma;.

Let ''x''&lt;sub&gt;1&lt;/sub&gt;''x''&lt;sub&gt;2&lt;/sub&gt;... ''x''&lt;sub&gt;|''x''|&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;''y''&lt;sub&gt;2&lt;/sub&gt;... ''y''&lt;sub&gt;|''y''|&lt;/sub&gt;, ''z''&lt;sub&gt;1&lt;/sub&gt;''z''&lt;sub&gt;2&lt;/sub&gt;... ''z''&lt;sub&gt;|''z''|&lt;/sub&gt;, ... be ''n'' [[word (mathematics)|words]] (i.e. finite [[sequence]]s) of elements of &amp;Sigma;. Let &lt;math&gt;\ell&lt;/math&gt; denote the length of the longest word, i.e. the maximum of |''x''|, |''y''|, |''z''|, ... .

The convolution of these words is a finite sequence of ''n''-tuples of elements of (&amp;Sigma; ∪ {#}), i.e. an element of &lt;math&gt;((\Sigma\cup\{\# \})^n)^*&lt;/math&gt;:

:&lt;math&gt; (x_1,y_1,\ldots)(x_2,y_2,\ldots)\ldots(x_\ell,y_\ell,\ldots)&lt;/math&gt;,

where for any index ''i'' &gt; |''w''|, the ''w&lt;sub&gt;i''&lt;/sub&gt; is #.

The convolution of ''x, y, z, ...'' is denoted conv( ''x, y, z, ...''), zip( ''x, y, z, ...'') or ''x'' ⋆ ''y'' ⋆ ''z'' ⋆ ...

The inverse to convolution is sometimes denoted unzip.

A variation of the convolution operation is defined by:

:&lt;math&gt; (x_1,y_1,\ldots)(x_2,y_2,\ldots)\ldots(x_{\underline{\ell}},y_{\underline{\ell}},\ldots)&lt;/math&gt;
 
where &lt;math&gt;\underline{\ell}&lt;/math&gt; is the ''minimum'' length of the input words.  It avoids the use of an adjoined element &lt;math&gt;\#&lt;/math&gt;, but destroys information about elements of the input sequences beyond &lt;math&gt;\underline{\ell}&lt;/math&gt;.

== In programming languages ==
Convolution [[Subroutine|functions]] are often available in [[programming language]]s, often referred to as &lt;tt&gt;zip&lt;/tt&gt;. In [[Lisp (programming language)|Lisp]]-dialects one can simply &lt;tt&gt;[[Map (higher-order function)|map]]&lt;/tt&gt; the desired function over the desired lists, &lt;tt&gt;map&lt;/tt&gt; is [[Variadic function|variadic]] in Lisp so it can take an arbitrary number of lists as argument. An example from [[Clojure]]:&lt;ref&gt;[http://clojuredocs.org/clojure_core/1.2.0/clojure.core/map map] from ClojureDocs&lt;/ref&gt;

&lt;source lang="clojure"&gt;
;; `nums' contains an infinite list of numbers (0 1 2 3 ...)
(def nums (range))
(def tens [10 20 30])
(def firstname "Alice")

;; To convolve (0 1 2 3 ...) and [10 20 30] into a vector, invoke `map vector' on them; same with list
(map vector nums tens)           ; ⇒ ([1 10] [2 20] [3 30])
(map list nums tens)             ; ⇒ ((1 10) (2 20) (3 30))
(map str nums tens)              ; ⇒ ("110" "220" "330")

;; `map' truncates to the shortest sequence; note missing \c and \e from "Alice"
(map vector nums tens firstname) ; ⇒ ([1 10 \A] [2 20 \l] [3 30 \i])
(map str nums tens firstname)    ; ⇒ ("110A" "220l" "330i")

;; To unzip, apply `map vector' or `map list'
(apply map list (map vector nums tens firstname))
;; ⇒ ((0 1 2) (10 20 30) (\A \l \i))
&lt;/source&gt;

In [[Common Lisp]]:
&lt;source lang="lisp"&gt;
(defparameter nums '(1 2 3))
(defparameter tens '(10 20 30))
(defparameter firstname "Alice")

(mapcar #'list nums tens)
;; ⇒ ((1 10) (2 20) (3 30))

(mapcar #'list nums tens (coerce firstname 'list))
;; ⇒ ((1 10 #\A) (2 20 #\l) (3 30 #\i)) — truncates on shortest list

;; Unzips
(apply #'mapcar #'list (mapcar #'list nums tens (coerce firstname 'list)))
;; ⇒ ((1 2 3) (10 20 30) (#\A #\l #\i))
&lt;/source&gt;

Languages such as [[Python (programming language)|Python]] provide a &lt;tt&gt;zip()&lt;/tt&gt; function, older version (Python 2.*) allowed mapping &lt;tt&gt;None&lt;/tt&gt; over lists to get a similar effect.&lt;ref name="pydocs"&gt;[https://docs.python.org/library/functions.html#map map(function, iterable, ...)] from section Built-in Functions from Python v2.7.2 documentation&lt;/ref&gt; &lt;tt&gt;zip()&lt;/tt&gt; in conjunction with the &lt;tt&gt;*&lt;/tt&gt; operator unzips a list:&lt;ref name="pydocs"/&gt;
&lt;source lang="python"&gt;
&gt;&gt;&gt; nums = [1, 2, 3]
&gt;&gt;&gt; tens = [10, 20, 30]
&gt;&gt;&gt; firstname = 'Alice'

&gt;&gt;&gt; zipped = zip(nums, tens)
&gt;&gt;&gt; zipped
[(1, 10), (2, 20), (3, 30)] 

&gt;&gt;&gt; zip(*zipped) # unzip
[(1, 2, 3), (10, 20, 30)]

&gt;&gt;&gt; zipped2 = zip(nums, tens, list(firstname))
&gt;&gt;&gt; zipped2 # zip, truncates on shortest
[(1, 10, 'A'), (2, 20, 'l'), (3, 30, 'i')] 
&gt;&gt;&gt; zip(*zipped2) # unzip
[(1, 2, 3), (10, 20, 30), ('A', 'l', 'i')]

&gt;&gt;&gt; # mapping with `None' doesn't truncate; deprecated in Python 3.*
&gt;&gt;&gt; map(None,nums, tens, list(firstname))
[(1, 10, 'A'), (2, 20, 'l'), (3, 30, 'i'), (None, None, 'c'), (None, None, 'e')]
&lt;/source&gt;

[[Haskell (programming language)|Haskell]] has a method of convolving sequences but requires a specific function for each [[arity]] (&lt;tt&gt;zip&lt;/tt&gt; for two sequences, &lt;tt&gt;zip3&lt;/tt&gt; for three etc.),&lt;ref&gt;[http://hackage.haskell.org/packages/archive/base/latest/doc/html/Prelude.html#v:zip zip :: &lt;nowiki&gt;[a] -&gt; [b] -&gt; [(a, b)]&lt;/nowiki&gt;] from Prelude, Basic libraries&lt;/ref&gt; similarly the functions &lt;tt&gt;unzip&lt;/tt&gt; and &lt;tt&gt;unzip3&lt;/tt&gt; are available for unzipping:
&lt;source lang="haskell"&gt;
-- nums contains an infinite list of numbers [1, 2, 3,...] 
nums = [1..]
tens = [10, 20, 30]
firstname = "Alice"

zip nums tens
-- ⇒ [(1,10),(2,20),(3,30)] — zip, truncates infinite list
unzip $ zip nums tens
-- ⇒ ([1,2,3],[10,20,30]) — unzip

zip3 nums tens firstname
-- ⇒ [(1,10,'A'),(2,20,'l'),(3,30,'i')] — zip, truncates
unzip3 $ zip3 nums tens firstname
-- ⇒ ([1,2,3],[10,20,30],"Ali") — unzip
&lt;/source&gt;

==Language comparison==
List of languages by support of convolution:

{| class="wikitable"
|+ Zip in various languages
! Language !! Zip !! Zip 3 lists !! Zip ''n'' lists !! Notes
|-
| [[Clojure]]
| &lt;tt&gt;(map list ''list1'' ''list2'')&lt;br/&gt; (map vector ''list1'' ''list2'') &lt;/tt&gt;
| &lt;tt&gt;(map vector ''list1'' ''list2'' ''list3'')&lt;br/&gt; (map vector ''list1'' ''list2'' ''list3'') &lt;/tt&gt;
| &lt;tt&gt;(map list ''list1'' … ''listn'')&lt;br/&gt; (map vector ''list1'' … ''listn'') &lt;/tt&gt;
| Stops after the length of the shortest list.
|-
| [[Common Lisp]]
| &lt;tt&gt;(mapcar #'list ''list1'' ''list2'')&lt;/tt&gt;
| &lt;tt&gt;(mapcar #'list ''list1'' ''list2'' ''list3'')&lt;/tt&gt;
| &lt;tt&gt;(mapcar #'list ''list1'' ...  ''listn'')&lt;/tt&gt;
| Stops after the length of the shortest list.
|-
| [[D (programming language)|D]]
| &lt;tt&gt;zip(''range1'',''range2'')&lt;br/&gt; ''range1''.zip(''range2'')&lt;/tt&gt;
| &lt;tt&gt;zip(''range1'',''range2'',''range3'')&lt;br/&gt; ''range1''.zip(range2,range3)&lt;/tt&gt;
| &lt;tt&gt;zip(''range1'',…,''rangeN'')&lt;br/&gt; ''range1''.zip(…,rangeN)&lt;/tt&gt;
| The stopping policy defaults to shortest and can be optionally provided as shortest, longest, or requiring the same length.&lt;ref&gt;http://dlang.org/phobos/std_range.html#zip&lt;/ref&gt; The second form is an example of [[Uniform Function Call Syntax|UFCS]].
|-
| [[F Sharp (programming language)|F#]]
| &lt;tt&gt;List.zip ''list1'' ''list2''&lt;br/&gt;Seq.zip ''source1'' ''source2''&lt;br/&gt;Array.zip ''array1'' ''array2''&lt;/tt&gt;
| &lt;tt&gt;List.zip3 ''list1'' ''list2'' ''list3''&lt;br/&gt;Seq.zip3 ''source1'' ''source2'' ''source3''&lt;br/&gt;Array.zip3 ''array1'' ''array2'' ''array3''&lt;/tt&gt;
| 
| 
|-
| [[Haskell (programming language)|Haskell]]
| &lt;tt&gt;zip ''list1'' ''list2''&lt;/tt&gt;
| &lt;tt&gt;zip3 ''list1'' ''list2'' ''list3''&lt;/tt&gt;
| &lt;tt&gt;zip''n'' ''list1'' … ''listn''&lt;/tt&gt;
| &lt;tt&gt;zipn&lt;/tt&gt; for ''n'' &gt; 3 is available in the module ''Data.List''. Stops after the shortest list ends.
|-
| [[Python (programming language)|Python]]
| &lt;tt&gt;zip(''list1'', ''list2'')&lt;/tt&gt;
| &lt;tt&gt;zip(''list1'', ''list2'', ''list3'')&lt;/tt&gt;
| &lt;tt&gt;zip(''list1'', …, ''listn'')&lt;/tt&gt;
| &lt;tt&gt;''zip()''&lt;/tt&gt; and &lt;tt&gt;''map()''&lt;/tt&gt; (3.x) stops after the shortest list ends, whereas &lt;tt&gt;''map()''&lt;/tt&gt; (2.x) and &lt;tt&gt;''itertools.zip_longest()''&lt;/tt&gt; (3.x) extends the shorter lists with &lt;tt&gt;''None''&lt;/tt&gt; items
|-
| [[Ruby (programming language)|Ruby]]
| &lt;tt&gt;''list1''.zip(''list2'')&lt;/tt&gt;
| &lt;tt&gt;''list1''.zip(''list2'', ''list3'')&lt;/tt&gt;
| &lt;tt&gt;''list1''.zip(''list1'', .., ''listn'')&lt;/tt&gt;
| When the list being executed upon (list1) is shorter than the lists being zipped the resulting list is the length of list1. If list1 is longer nil values are used to fill the missing values&lt;ref&gt;http://www.ruby-doc.org/core-2.0/Array.html#method-i-zip&lt;/ref&gt;
|}

{| class="wikitable"
|+ Unzip in various languages
! Language !! Unzip !! Unzip 3 tuples !! Unzip ''n'' tuples !! Notes
|-
| [[Clojure]]
| &lt;tt&gt;(apply map vector ''convlist'')&lt;/tt&gt;
| &lt;tt&gt;(apply map vector ''convlist'')&lt;/tt&gt;
| &lt;tt&gt;(apply map vector ''convlist'')&lt;/tt&gt;
| 
|-
| [[Common Lisp]]
| &lt;tt&gt;(apply #'mapcar #'list ''convlist'')&lt;/tt&gt;
| &lt;tt&gt;(apply #'mapcar #'list ''convlist'')&lt;/tt&gt;
| &lt;tt&gt;(apply #'mapcar #'list ''convlist'')&lt;/tt&gt;
| 
|-
| [[F Sharp (programming language)|F#]]
| &lt;tt&gt;List.unzip ''list1'' ''list2''&lt;br/&gt;Seq.unzip ''source1'' ''source2''&lt;br/&gt;Array.unzip ''array1'' ''array2''&lt;/tt&gt;
| &lt;tt&gt;List.unzip3 ''list1'' ''list2'' ''list3''&lt;br/&gt;Seq.unzip3 ''source1'' ''source2'' ''source3''&lt;br/&gt;Array.unzip3 ''array1'' ''array2'' ''array3''&lt;/tt&gt;
| 
| 
|-
| [[Haskell (programming language)|Haskell]]
| &lt;tt&gt;unzip ''convlist''&lt;/tt&gt;
| &lt;tt&gt;unzip3 ''convlist''&lt;/tt&gt;
| &lt;tt&gt;unzip''n'' ''convlist''&lt;/tt&gt;
| &lt;tt&gt;unzipn&lt;/tt&gt; for ''n'' &gt; 3 is available in the module &lt;tt&gt;''Data.List''.&lt;/tt&gt;
|-
| [[Python (programming language)|Python]]
| &lt;tt&gt;zip(*''convvlist'')&lt;/tt&gt;
| &lt;tt&gt;zip(*''convvlist'')&lt;/tt&gt;
| &lt;tt&gt;zip(*''convvlist'')&lt;/tt&gt;
| 
|}

== See also ==
* [[Map (higher-order function)]]

==References==
&lt;references/&gt;

{{PlanetMath attribution|id=5734|title=convolution}}

[[Category:Formal languages]]
[[Category:Articles with example Haskell code]]
[[Category:Articles with example Lisp code]]
[[Category:Articles with example Clojure code]]
[[Category:Articles with example Python code]]
[[Category:Higher-order functions]]</text>
      <sha1>m6bkns84mj71b0r5h0iwwg33fmlm48m</sha1>
    </revision>
  </page>
  <page>
    <title>Coordinate singularity</title>
    <ns>0</ns>
    <id>25269252</id>
    <revision>
      <id>794197820</id>
      <parentid>775977084</parentid>
      <timestamp>2017-08-06T13:58:39Z</timestamp>
      <contributor>
        <username>Lambiam</username>
        <id>745100</id>
      </contributor>
      <comment>/* top */ ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1513">A '''coordinate singularity''' occurs when an apparent [[mathematical singularity|singularity]] or discontinuity occurs in one coordinate frame, which can be removed by choosing a different frame. 

An example is the apparent (longitudinal) singularity at the 90 degree latitude in spherical coordinates. An object moving due north (for example, along the line [[Greenwich meridian|0 degrees longitude]]) on the surface of a sphere will suddenly experience an instantaneous change in longitude at the pole (i.e., jumping from longitude 0 to longitude 180 degrees). In fact, longitude is not uniquely defined at the poles. This discontinuity, however, is only apparent; it is an artifact of the coordinate system chosen, which is singular at the poles. A different coordinate system would eliminate the apparent discontinuity, e.g. by replacing the latitude/longitude representation with an [[n-vector|{{mvar|n}}-vector]] representation.
 
Stephen Hawking aptly summed this up, when once asking the question, "What lies north of the North Pole?".&lt;ref&gt;[http://www.wisegeek.com/what-is-cosmology.htm What is Cosmology?], wiseGEEK.com. Accessed 15 Feb 2013. In a related discussion, he mentions this again : [http://www.hawking.org.uk/the-beginning-of-time.html The Beginning of Time - Stephen Hawking]; accessed 15 Feb 2013.&lt;/ref&gt;

==See also==
*[[Chronometric singularity]]
*[[Imaginary time]]
* [[Mathematical singularity]]
* [[No-boundary proposal]]

==References==
{{reflist}}

[[Category:Mathematical analysis]]</text>
      <sha1>533g6vtigrcphnaplyop0ok2vfn3mau</sha1>
    </revision>
  </page>
  <page>
    <title>Counting problem (complexity)</title>
    <ns>0</ns>
    <id>1471307</id>
    <revision>
      <id>829385183</id>
      <parentid>817927361</parentid>
      <timestamp>2018-03-08T09:05:31Z</timestamp>
      <contributor>
        <username>Mhym</username>
        <id>635181</id>
      </contributor>
      <comment>+GapP</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1567">{{unreferenced|date=October 2014}}
In [[computational complexity theory]] and [[computability theory]], a '''counting problem''' is a type of [[computational problem]]. If ''R'' is a [[search problem]] then 

:&lt;math&gt;c_R(x)=\vert\{y\mid R(x,y)\}\vert \,&lt;/math&gt;

is the corresponding [[counting function]] and

:&lt;math&gt;\#R=\{(x,y)\mid y\leq c_R(x)\}&lt;/math&gt;

denotes the corresponding counting problem. 

Note that ''c&lt;sub&gt;R''&lt;/sub&gt; is a search problem while #''R'' is a decision problem, however ''c&lt;sub&gt;R''&lt;/sub&gt; can be '''''C''''' Cook reduced to #''R'' (for appropriate '''''C''''') using a [[binary search]] (the reason #''R'' is defined the way it is, rather than being the graph of ''c&lt;sub&gt;R''&lt;/sub&gt;, is to make this binary search possible).

==Counting complexity class==
If ''NX'' is a complexity class associated with [[nondeterministic algorithm|non-deterministic]] machines then ''#X'' = {''#R'' | ''R'' &amp;isin; ''NX''} is the set of counting problems associated with each [[search problem]] in ''NX''. In particular, '''[[Sharp-P|#P]]''' is the class of counting problems associated with '''[[NP (complexity)|NP]]''' search problems.
Just as NP has [[NP-complete]] problems via [[many-one reduction]]s, #P has complete problems via [[parsimonious reduction]]s, problem transformations that preserve the number of solutions.

== See also == 
* [[GapP]]

==External links==
* {{PlanetMath reference|id=3439|title=counting problem}}
* {{PlanetMath reference|id=3444|title=counting complexity class}}

{{Comp-sci-theory-stub}}

[[Category:Computational problems]]</text>
      <sha1>8lma0kawf13puvlukw05h0k2zbpby9c</sha1>
    </revision>
  </page>
  <page>
    <title>Cryptography</title>
    <ns>0</ns>
    <id>18934432</id>
    <revision>
      <id>871461577</id>
      <parentid>871461340</parentid>
      <timestamp>2018-12-01T06:31:41Z</timestamp>
      <contributor>
        <username>Peaceray</username>
        <id>11630810</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/DaemoniumDeVitaEtMors|DaemoniumDeVitaEtMors]] ([[User talk:DaemoniumDeVitaEtMors|talk]]): Puzzles or problems are not typically considered encyclopedic. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="77489">{{Redirect|Secret code|the Aya Kamiki album|Secret Code}}
{{Redirect|Cryptology|the David S. Ware album|Cryptology (album)}}
{{pp-move-indef|small=yes}}
{{Use dmy dates|date=September 2015}}
[[File:Lorenz-SZ42-2.jpg|thumb|alt=Lorenz cipher machine twelve rotors with mechanism|German [[Lorenz cipher]] machine, used in [[World War&amp;nbsp;II]] to encrypt very-high-level [[general staff]] messages]]

'''Cryptography''' or '''cryptology''' (from {{lang-grc|{{wikt-lang|grc|κρυπτός}}|translit=kryptós}} "hidden, secret"; and {{wikt-lang|grc|γράφειν}} ''graphein'', "to write", or {{wikt-lang|grc|-λογία}} ''[[-logy|-logia]]'', "study", respectively&lt;ref&gt;{{Cite book|last=Liddell|first=Henry George|authorlink=Henry George Liddell|last2=Scott|first2=Robert|last3=Jones|first3=Henry Stuart|authorlink3=Henry Stuart Jones|last4=McKenzie|first4=Roderick|title=A Greek-English Lexicon|publisher=[[Oxford University Press]]|year=1984|title-link=A Greek-English Lexicon}}&lt;/ref&gt;) is the practice and study of techniques for [[secure communication]] in the presence of third parties called [[adversary (cryptography)|adversaries]].&lt;ref name="rivest90"&gt;{{cite book|first=Ronald L.|last=Rivest|authorlink=Ron Rivest|editor=J. Van Leeuwen|title=Handbook of Theoretical Computer Science|chapter=Cryptography|volume=1|publisher=Elsevier|year=1990}}&lt;/ref&gt; More generally, cryptography is about constructing and analyzing [[communications protocol|protocols]] that prevent third parties or the public from reading private messages;&lt;ref name="modern-crypto"&gt;{{Cite book|first1=Mihir|last1=Bellare|first2=Phillip|last2=Rogaway|title=Introduction to Modern Cryptography|chapter=Introduction|page=10|date=21 September 2005}}&lt;/ref&gt; various aspects in [[information security]] such as data [[confidentiality]], [[data integrity]], [[authentication]], and [[non-repudiation]]&lt;ref name="hac"/&gt; are central to modern cryptography. Modern cryptography exists at the intersection of the disciplines of [[mathematics]], [[computer science]], [[electrical engineering]], [[communication science]], and [[physics]]. Applications of cryptography include [[electronic commerce]], [[Credit card chip|chip-based payment cards]], [[digital currencies]], [[password|computer passwords]], and [[military communications]].

Cryptography prior to the modern age was effectively synonymous with ''[[encryption]]'', the conversion of information from a readable state to apparent [[nonsense]]. The originator of an encrypted message shares the decoding technique only with intended recipients to preclude access from adversaries. The cryptography literature often uses the name Alice ("A") for the sender, Bob ("B") for the intended recipient, and Eve ("[[eavesdropper]]") for the adversary.&lt;ref name="codesintro"&gt;{{cite book|first=Norman|last=Biggs|title=Codes: An introduction to Information Communication and Cryptography|publisher=Springer|year=2008|page=171}}&lt;/ref&gt; Since the development of [[Rotor machine|rotor cipher machines]] in [[World War&amp;nbsp;I]] and the advent of [[computer]]s in [[World War&amp;nbsp;II]], the methods used to carry out cryptology have become increasingly complex and its application more widespread.

{{Anchor|infeasible}}Modern cryptography is heavily based on mathematical theory and computer science practice; cryptographic algorithms are designed around [[computational hardness assumption]]s, making such algorithms hard to break in practice by any adversary. It is theoretically possible to break such a system, but it is infeasible to do so by any known practical means. These schemes are therefore termed computationally secure; theoretical advances, e.g., improvements in [[integer factorization]] algorithms, and faster computing technology require these solutions to be continually adapted. There exist [[Information theoretic security|information-theoretically secure]] schemes that {{not a typo|probably}} cannot be broken even with unlimited computing power—an example is the [[one-time pad]]—but these schemes are more difficult to implement than the best theoretically breakable but computationally secure mechanisms.

The growth of cryptographic technology has raised a number of legal issues in the information age. Cryptography's potential for use as a tool for [[espionage]] and [[sedition]] has led many governments to classify it as a weapon and to limit or even prohibit its use and export.&lt;ref name="cryptolaw"/&gt; In some jurisdictions where the use of cryptography is legal, laws permit investigators to [[Key disclosure law|compel the disclosure]] of encryption keys for documents relevant to an investigation.&lt;ref name="UK law"/&gt;&lt;ref name="RangerSteve1"&gt;{{cite web | url=http://www.techrepublic.com/article/the-undercover-war-on-your-internet-secrets-how-online-surveillance-cracked-our-trust-in-the-web/ | title=The undercover war on your internet secrets: How online surveillance cracked our trust in the web | last=Ranger | first=Steve | website= | publisher=TechRepublic  | date=24 March 2015| archive-url=https://web.archive.org/web/20160612190952/http://www.techrepublic.com/article/the-undercover-war-on-your-internet-secrets-how-online-surveillance-cracked-our-trust-in-the-web/ | archive-date=2016-06-12| access-date=2016-06-12 }}&lt;/ref&gt; Cryptography also plays a major role in [[digital rights management]] and [[copyright infringement]] of digital media.&lt;ref name="AACS"/&gt;

==Terminology==

[[File:Caesar cipher left shift of 3.svg|Caesar cipher left shift of 3|thumb|alt=diagram showing shift three alphabetic cypher D becomes A and E becomes B|Alphabet shift ciphers are believed to have been used by [[Julius Caesar]] over 2,000 years ago.&lt;ref name="codesintro" /&gt; This is an example with k=3. In other words, the letters in the alphabet are shifted three in one direction to encrypt and three in the other direction to decrypt.]]
The first use of the term ''cryptograph'' (as opposed to ''cryptogram'') dates back to the 19th century—it originated in ''[[The Gold-Bug]]'', a novel by [[Edgar Allan Poe]].&lt;ref&gt;{{harvnb|Rosenheim|1997|p=20}}&lt;/ref&gt;

Until modern times, cryptography referred almost exclusively to ''encryption'', which is the process of converting ordinary information (called [[plaintext]]) into unintelligible form (called [[ciphertext]]).&lt;ref name="kahnbook" /&gt; Decryption is the reverse, in other words, moving from the unintelligible ciphertext back to plaintext. A ''[[cipher]]'' (or ''cypher'') is a pair of [[algorithm]]s that create the encryption and the reversing decryption. The detailed operation of a cipher is controlled both by the algorithm and in each instance by a "[[key (cryptography)|key]]". The key is a secret (ideally known only to the communicants), usually a short string of characters, which is needed to decrypt the ciphertext.  Formally, a "[[cryptosystem]]" is the ordered list of elements of finite possible plaintexts, finite possible cyphertexts, finite possible keys, and the encryption and decryption algorithms which correspond to each key.  Keys are important both formally and in actual practice, as ciphers without variable keys can be trivially broken with only the knowledge of the cipher used and are therefore useless (or even counter-productive) for most purposes.

Historically, ciphers were often used directly for encryption or decryption without additional procedures such as [[authentication]] or integrity checks. There are two kinds of cryptosystems: [[Symmetric-key algorithm|symmetric]] and [[Public-key cryptography|asymmetric]]. In symmetric systems the same key (the secret key) is used to encrypt and decrypt a message. Data manipulation in symmetric systems is faster than asymmetric systems as they generally use shorter key lengths. Asymmetric systems use a public key to encrypt a message and a private key to decrypt it. Use of asymmetric systems enhances the security of communication.&lt;ref&gt;{{Cite web|url = https://www.giac.org/paper/gsec/2604/introduction-modern-cryptosystems/104482|title = An Introduction to Modern Cryptosystems|date = |accessdate = |website = |publisher = |last = |first = }}&lt;/ref&gt; Examples of asymmetric systems include RSA ([[Rivest-Shamir-Adleman]]), and ECC ([[Elliptic Curve Cryptography]]). Symmetric models include the commonly used AES ([[Advanced Encryption Standard]]) which replaced the older DES ([[Data Encryption Standard]]).&lt;ref&gt;{{Cite book|title = Quantum cryptography: An emerging technology in network security|url = http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6107841&amp;isnumber=6107829|journal = 2011 IEEE International Conference on Technologies for Homeland Security (HST)|date = 2011-11-01|pages = 13–19|doi = 10.1109/THS.2011.6107841|first = M.S.|last = Sharbaf|isbn = 978-1457713767}}&lt;/ref&gt;

In [[colloquial]] use, the term "[[code (cryptography)|code]]" is often used to mean any method of encryption or concealment of meaning. However, in cryptography, ''code'' has a more specific meaning. It means the replacement of a unit of plaintext (i.e., a meaningful word or phrase) with a [[code word]] (for example, "wallaby" replaces "attack at dawn").

[[Cryptanalysis]] is the term used for the study of methods for obtaining the meaning of encrypted information without access to the key normally required to do so; i.e., it is the study of how to crack encryption algorithms or their implementations.

Some use the terms ''cryptography'' and ''cryptology'' interchangeably in English, while others (including US military practice generally) use ''cryptography'' to refer specifically to the use and practice of cryptographic techniques and ''cryptology'' to refer to the combined study of cryptography and cryptanalysis.&lt;ref name="goldreichbook"&gt;[[Oded Goldreich]], ''Foundations of Cryptography, Volume 1: Basic Tools'', Cambridge University Press, 2001, {{ISBN|0521791723}}&lt;/ref&gt;&lt;ref name="websters"&gt;{{cite encyclopedia |encyclopedia=[[Merriam-Webster's Collegiate Dictionary]] |title=Cryptology (definition) |url=http://www.merriam-webster.com/dictionary/cryptology |accessdate=26 March 2015 |edition=11th |publisher=[[Merriam-Webster]]}}&lt;/ref&gt; English is more flexible than several other languages in which ''cryptology'' (done by cryptologists) is always used in the second sense above. {{IETF RFC|2828}} advises that [[steganography]] is sometimes included in cryptology.&lt;ref&gt;{{Cite web|rfc=2828|title=Internet Security Glossary|website=[[Internet Engineering Task Force]]|date=May 2000|url=https://tools.ietf.org/html/rfc2828|accessdate=26 March 2015}}&lt;/ref&gt;

The study of characteristics of languages that have some application in cryptography or cryptology (e.g. frequency data, letter combinations, universal patterns, etc.) is called cryptolinguistics.

==History of cryptography and cryptanalysis==
{{Main|History of cryptography}}
Before the modern era, cryptography focused on message confidentiality (i.e., encryption)—conversion of [[information|messages]] from a comprehensible form into an incomprehensible one and back again at the other end, rendering it unreadable by interceptors or eavesdroppers without secret knowledge (namely the key needed for decryption of that message). Encryption attempted to ensure [[secrecy]] in [[communications]], such as those of [[spy|spies]], military leaders, and [[diplomat]]s. In recent decades, the field has expanded beyond confidentiality concerns to include techniques for message integrity checking, sender/receiver identity [[authentication]], [[digital signature]]s, [[Interactive proof system|interactive proofs]] and [[secure multiparty computation|secure computation]], among others.

===Classic cryptography===
[[File:Skytala&amp;EmptyStrip-Shaded.png|thumb|alt=Skytala stick with strip of paper wound around in spiral|Reconstructed [[ancient Greek]] ''[[scytale]]'', an early cipher device]]
The main classical cipher types are [[transposition cipher]]s, which rearrange the order of letters in a message (e.g., 'hello world' becomes 'ehlol owrdl' in a trivially simple rearrangement scheme), and [[substitution cipher]]s, which systematically replace letters or groups of letters with other letters or groups of letters (e.g., 'fly at once' becomes 'gmz bu podf' by replacing each letter with the one following it in the [[Latin alphabet]]). Simple versions of either have never offered much confidentiality from enterprising opponents. An early substitution cipher was the [[Caesar cipher]], in which each letter in the plaintext was replaced by a letter some fixed number of positions further down the alphabet. [[Suetonius]] reports that [[Julius Caesar]] used it with a shift of three to communicate with his generals. [[Atbash]] is an example of an early Hebrew cipher. The earliest known use of cryptography is some carved ciphertext on stone in [[Egypt]] (ca 1900 BCE), but this may have been done for the amusement of literate observers rather than as a way of concealing information.

The [[Ancient Greece|Greeks of Classical times]] are said to have known of ciphers (e.g., the scytale transposition cipher claimed to have been used by the [[Sparta]]n military).&lt;ref&gt;{{Cite book|first=V.V.|last=I︠A︡shchenko|title=Cryptography: an introduction|year=2002|url={{Google books|cH-NGrpcIMcC|page=6|plainurl=yes}}|publisher=AMS Bookstore|page=6|isbn=978-0821829868}}&lt;/ref&gt; [[Steganography]] (i.e., hiding even the existence of a message so as to keep it confidential) was also first developed in ancient times. An early example, from [[Herodotus]], was a message tattooed on a slave's shaved head and concealed under the regrown hair.&lt;ref name="kahnbook"&gt;{{Cite book|last=Kahn|first=David|authorlink=David Kahn (writer)|title=The Codebreakers|year=1967|isbn=978-0684831305|title-link=The Codebreakers}}&lt;/ref&gt; More modern examples of steganography include the use of [[invisible ink]], [[microdot]]s, and [[digital watermark]]s to conceal information.

In India, the 2000-year-old [[Kamasutra]] of [[Vātsyāyana]] speaks of two different kinds of ciphers called Kautiliyam and Mulavediya. In the Kautiliyam, the cipher letter substitutions are based on phonetic relations, such as vowels becoming consonants. In the Mulavediya, the cipher alphabet consists of pairing letters and using the reciprocal ones.&lt;ref name="kahnbook" /&gt;

In [[Sassanid Persia]], there were two secret scripts, according to the Muslim author [[Ibn al-Nadim]]: the ''šāh-dabīrīya'' (literally "King's script") which was used for official correspondence, and the ''rāz-saharīya'' which was used to communicate secret messages with other countries.&lt;ref&gt;{{cite web|url=http://www.iranicaonline.org/articles/codes-romuz-sg|title=CODES – Encyclopaedia Iranica|last=electricpulp.com|date=|website=www.iranicaonline.org}}&lt;/ref&gt;

[[File:Al-kindi cryptographic.png|thumb|alt=Arabic text of a book by Al-Kindi|First page of a book by [[Al-Kindi]] which discusses encryption of messages]]

Ciphertexts produced by a [[classical cipher]] (and some modern ciphers) will reveal statistical information about the plaintext, and that information can often be used to break the cipher. After the discovery of [[frequency analysis]], perhaps by the [[mathematics in medieval Islam|Arab mathematician]] and [[polymath]] [[Al-Kindi]] (also known as ''Alkindus'') in the 9th century,&lt;ref name="Singh14-20"&gt;{{cite book |first=Simon |last=Singh |authorlink=Simon Singh |title=The Code Book |pages=14–20 |location=New York |publisher=[[Anchor Books]] |year=2000 |isbn=978-0385495325|title-link=The Code Book }}&lt;/ref&gt; nearly all such ciphers could be broken by an informed attacker. Such classical ciphers still enjoy popularity today, though mostly as [[puzzle]]s (see [[cryptogram]]). Al-Kindi wrote a book on cryptography entitled ''Risalah fi Istikhraj al-Mu'amma'' (''Manuscript for the Deciphering Cryptographic Messages''), which described the first known use of frequency analysis [[cryptanalysis]] techniques.&lt;ref name="Singh14-20"/&gt;&lt;ref name=Kadi&gt;{{Cite journal|first=Ibrahim A.|last=Al-Kadi|date=April 1992|title=The origins of cryptology: The Arab contributions|journal=[[Cryptologia]]|volume=16|number=2|pages=97–126|doi=10.1080/0161-119291866801}}&lt;/ref&gt;

[[File:16th century French cypher machine in the shape of a book with arms of Henri II.jpg|thumb|alt=book sized metal machine with large dial left page and nineteen small dials right page|16th-century book-shaped [[France|French]] cipher machine, with arms of [[Henri II of France]]]]
[[File:Encoded letter of Gabriel Luetz d Aramon after 1546 with partial deciphering.jpg|thumb|alt=manuscript from Gabriel de Luetz d'Aramon in bound volume|Enciphered letter from [[Gabriel de Luetz d'Aramon]], [[French Ambassador to the Ottoman Empire]], after 1546, with partial decipherment]]

Language letter frequencies may offer little help for some extended historical encryption techniques such as [[Substitution cipher#Homophonic substitution|homophonic cipher]] that tend to flatten the frequency distribution. For those ciphers, language letter group (or n-gram) frequencies may provide an attack.

Essentially all ciphers remained vulnerable to cryptanalysis using the frequency analysis technique until the development of the polyalphabetic cipher, most clearly by [[Leon Battista Alberti]] around the year 1467, though there is some indication that it was already known to Al-Kindi.&lt;ref name=Kadi/&gt; Alberti's innovation was to use different ciphers (i.e., substitution alphabets) for various parts of a message (perhaps for each successive plaintext letter at the limit). He also invented what was probably the first automatic [[Alberti Cipher Disk|cipher device]], a wheel which implemented a partial realization of his invention. In the [[Vigenère cipher]], a [[polyalphabetic cipher]], encryption uses a ''key word'', which controls letter substitution depending on which letter of the key word is used. In the mid-19th century [[Charles Babbage]] showed that the Vigenère cipher was vulnerable to [[Kasiski examination]], but this was first published about ten years later by [[Friedrich Kasiski]].&lt;ref&gt;{{cite journal|last=Schrödel |first=Tobias|date=October 2008|title=Breaking Short Vigenère Ciphers |journal=[[Cryptologia]]|volume=32|issue=4|pages=334–337|doi=10.1080/01611190802336097}}&lt;/ref&gt;

Although frequency analysis can be a powerful and general technique against many ciphers, encryption has still often been effective in practice, as many a would-be cryptanalyst was unaware of the technique. Breaking a message without using frequency analysis essentially required knowledge of the cipher used and perhaps of the key involved, thus making espionage, bribery, burglary, defection, etc., more attractive approaches to the cryptanalytically uninformed. It was finally explicitly recognized in the 19th century that secrecy of a cipher's algorithm is not a sensible nor practical safeguard of message security; in fact, it was further realized that any adequate cryptographic scheme (including ciphers) should remain secure even if the adversary fully understands the cipher algorithm itself. Security of the key used should alone be sufficient for a good cipher to maintain confidentiality under an attack. This fundamental principle was first explicitly stated in 1883 by [[Auguste Kerckhoffs]] and is generally called [[Kerckhoffs's Principle]]; alternatively and more bluntly, it was restated by [[Claude Shannon]], the inventor of [[information theory]] and the fundamentals of theoretical cryptography, as ''Shannon's Maxim''—'the enemy knows the system'.

Different physical devices and aids have been used to assist with ciphers. One of the earliest may have been the scytale of [[ancient Greece]], a rod supposedly used by the Spartans as an aid for a transposition cipher (see image above). In medieval times, other aids were invented such as the [[grille (cryptography)|cipher grille]], which was also used for a kind of steganography. With the invention of polyalphabetic ciphers came more sophisticated aids such as Alberti's own [[cipher disk]], [[Johannes Trithemius]]' [[tabula recta]] scheme, and [[Thomas Jefferson]]'s [[Jefferson disk|wheel cypher]] (not publicly known, and reinvented independently by [[Bazeries]] around 1900). Many mechanical encryption/decryption devices were invented early in the 20th century, and several patented, among them [[rotor machine]]s—famously including the [[Enigma machine]] used by the German government and military from the late 1920s and during [[World War II]].&lt;ref&gt;{{cite book| last = Hakim | first = Joy | authorlink = Joy Hakim | title = A History of US: War, Peace and all that Jazz | publisher = [[Oxford University Press]] | year = 1995 | location = New York | isbn = 978-0195095142 | title-link = A History of US }}&lt;/ref&gt; The ciphers implemented by better quality examples of these machine designs brought about a substantial increase in cryptanalytic difficulty after WWI.&lt;ref&gt;{{Cite book|last=Gannon|first=James|authorlink=James Gannon|title=Stealing Secrets, Telling Lies: How Spies and Codebreakers Helped Shape the Twentieth Century|location=Washington, D.C.|publisher=Brassey's|year=2001|isbn=978-1574883671}}&lt;/ref&gt;

===Computer era===
[[Cryptanalysis]] of the new mechanical devices proved to be both difficult and laborious. In the United Kingdom, cryptanalytic efforts at [[Bletchley Park]] during WWII spurred the development of more efficient means for carrying out repetitious tasks. This culminated in the development of the [[Colossus computer|Colossus]], the world's first fully electronic, digital, [[computer programming|programmable]] computer, which assisted in the decryption of ciphers generated by the German Army's [[Lorenz SZ40/42]] machine.

Just as the development of digital computers and electronics helped in cryptanalysis, it made possible much more complex ciphers. Furthermore, computers allowed for the encryption of any kind of data representable in any binary format, unlike classical ciphers which only encrypted written language texts; this was new and significant. Computer use has thus supplanted linguistic cryptography, both for cipher design and cryptanalysis. Many computer ciphers can be characterized by their operation on [[binary numeral system|binary]] [[bit]] sequences (sometimes in groups or blocks), unlike classical and mechanical schemes, which generally manipulate traditional characters (i.e., letters and digits) directly. However, computers have also assisted cryptanalysis, which has compensated to some extent for increased cipher complexity. Nonetheless, good modern ciphers have stayed ahead of cryptanalysis; it is typically the case that use of a quality cipher is very efficient (i.e., fast and requiring few resources, such as memory or CPU capability), while breaking it requires an effort many orders of magnitude larger, and vastly larger than that required for any classical cipher, making cryptanalysis so inefficient and impractical as to be effectively impossible.

Extensive open academic research into cryptography is relatively recent; it began only in the mid-1970s. In recent times, IBM personnel designed the algorithm that became the Federal (i.e., US) [[Data Encryption Standard]]; [[Whitfield Diffie]] and [[Martin Hellman]] published [[Diffie-Hellman|their key agreement algorithm]];&lt;ref name="dh2"&gt;{{cite journal|first=Whitfield|last=Diffie|authorlink=Whitfield Diffie|first2=Martin|last2=Hellman|authorlink2=Martin Hellman|title=New Directions in Cryptography|journal=IEEE Transactions on Information Theory|volume=IT-22|issue=6|date=November 1976|pages=644–654|url=http://www-ee.stanford.edu/~hellman/publications/24.pdf|doi=10.1109/tit.1976.1055638|citeseerx=10.1.1.37.9720}}&lt;/ref&gt; and the [[RSA (algorithm)|RSA]] algorithm was published in [[Martin Gardner]]'s ''[[Scientific American]]'' column. Following their work in 1976, it became popular to consider cryptography systems based on mathematical problems that are easy to state but have been found difficult to solve.&lt;ref&gt;{{cite book|last=Wolfram|first=Stephen|title=A New Kind of Science|publisher=Wolfram Media, Inc.|year=2002|page=1089|isbn=978-1579550080}}&lt;/ref&gt; Since then, cryptography has become a widely used tool in communications, [[computer network]]s, and [[computer security]] generally. Some modern cryptographic techniques can only keep their keys secret if certain mathematical problems are [[Computational complexity theory#Intractability|intractable]], such as the [[integer factorization]] or the [[discrete logarithm]] problems, so there are deep connections with [[abstract mathematics]]. There are very few cryptosystems that are proven to be unconditionally secure. The [[one-time pad]] is one, and was proven to be so by Claude Shannon. There are a few important algorithms that have been proven secure under certain assumptions. For example, the infeasibility of factoring extremely large integers is the basis for believing that [[RSA (cryptosystem)|RSA]] is secure, and some other systems, but even so proof of unbreakability is unavailable since the underlying mathematical problem remains open. In practice, these are widely used, and are believed unbreakable in practice by most competent observers.  There are systems similar to RSA, such as one by [[Michael O. Rabin]] that are provably secure provided factoring  ''n = pq'' is impossible;  it is quite unusable in practice. The [[discrete logarithm problem]] is the basis for believing some other cryptosystems are secure, and again, there are related, less practical systems that are provably secure relative to the solvability or insolvability discrete log problem.&lt;ref&gt;''Cryptography: Theory and Practice'', Third Edition (Discrete Mathematics and Its Applications), 2005, by Douglas R. Stinson, Chapman and Hall/CRC&lt;/ref&gt;

As well as being aware of cryptographic history, cryptographic algorithm and system designers must also sensibly consider probable future developments while working on their designs. For instance, continuous improvements in computer processing power have increased the scope of [[brute-force attack]]s, so when specifying [[key length]]s, the required key lengths are similarly advancing.&lt;ref name="fortify"&gt;{{cite web|url=http://www.fortify.net/related/cryptographers.html|title=Minimal key lengths for symmetric ciphers to provide adequate commercial security|first1=Matt|last1=Blaze|authorlink1=Matt Blaze|first2=Whitefield|last2=Diffie|authorlink2=Whitfield Diffie|first3=Ronald L.|last3=Rivest|authorlink3=Ron Rivest|first4=Bruce|last4=Schneier|authorlink4=Bruce Schneier|first5=Tsutomu|last5=Shimomura|authorlink5=Tsutomu Shimomura|first6=Eric|last6=Thompson|first7=Michael|last7=Wiener| date=January 1996 |publisher=[[Fortify (Netscape)|Fortify]]|accessdate=26 March 2015}}&lt;/ref&gt; The potential effects of [[quantum computing]] are already being considered by some cryptographic system designers developing [[post-quantum cryptography]]; the announced imminence of small implementations of these machines may be making the need for preemptive caution rather more than merely speculative.&lt;ref name="hac"&gt;{{cite book|first=A.J. |last=Menezes |first2=P.C. |last2=van Oorschot |first3=S.A. |last3=Vanstone |url=http://www.cacr.math.uwaterloo.ca/hac/ |title=Handbook of Applied Cryptography |publisher= |isbn=978-0849385230 |deadurl=yes |archiveurl=https://web.archive.org/web/20050307081354/http://www.cacr.math.uwaterloo.ca/hac/ |archivedate=7 March 2005 |year=1997 }}&lt;/ref&gt;

Essentially, prior to the early 20th century, cryptography was chiefly concerned with [[language|linguistic]] and [[lexicographic code|lexicographic]] patterns. Since then the emphasis has shifted, and cryptography now makes extensive use of mathematics, including aspects of [[information theory]], [[computational complexity theory|computational complexity]], [[statistics]], [[combinatorics]], [[abstract algebra]], [[number theory]], and finite mathematics generally. Cryptography is also a branch of [[engineering]], but an unusual one since it deals with active, intelligent, and malevolent opposition (see [[cryptographic engineering]] and [[security engineering]]); other kinds of engineering (e.g., civil or chemical engineering) need deal only with neutral natural forces. There is also active research examining the relationship between cryptographic problems and [[quantum physics]] (see [[quantum cryptography]] and [[quantum computer]]).

==Modern cryptography==
The modern field of cryptography can be divided into several areas of study. The chief ones are discussed here; see [[Topics in Cryptography]] for more.

===Symmetric-key cryptography===
{{Main|Symmetric-key algorithm}}
[[File:Symmetric key encryption.svg|thumb|upright=1.15|alt=diagram showing encrypt with a key and decrypt process|Symmetric-key cryptography, where a single key is used for encryption and decryption]]
Symmetric-key cryptography refers to encryption methods in which both the sender and receiver share the same key (or, less commonly, in which their keys are different, but related in an easily computable way). This was the only kind of encryption publicly known until June 1976.&lt;ref name="dh2"/&gt;
[[File:International Data Encryption Algorithm InfoBox Diagram.svg|thumb|alt=logic diagram showing International Data Encryption Algorithm cypher process|One round (out of 8.5) of the [[International Data Encryption Algorithm|IDEA]] cipher, used in some versions of [[Pretty Good Privacy|PGP]] for high-speed encryption of, for instance, [[electronic mail|e-mail]]]]
Symmetric key ciphers are implemented as either [[block ciphers]] or [[stream ciphers]]. A block cipher enciphers input in blocks of plaintext as opposed to individual characters, the input form used by a stream cipher.

The [[Data Encryption Standard]] (DES) and the [[Advanced Encryption Standard]] (AES) are block cipher designs that have been designated [[cryptography standards]] by the US government (though DES's designation was finally withdrawn after the AES was adopted).&lt;ref name="aes"&gt;{{Cite web|url=http://www.csrc.nist.gov/publications/fips/fips197/fips-197.pdf|title=FIPS PUB 197: The official Advanced Encryption Standard|publisher=[[National Institute of Standards and Technology]]|website=Computer Security Resource Center|accessdate=26 March 2015}}&lt;/ref&gt; Despite its deprecation as an official standard, DES (especially its still-approved and much more secure [[triple-DES]] variant) remains quite popular; it is used across a wide range of applications, from ATM encryption&lt;ref name="atm"&gt;{{Cite web|url=http://www.ncua.gov/Resources/Documents/LCU2004-09.pdf|title=NCUA letter to credit unions|website=[[National Credit Union Administration]]|format=PDF|date=July 2004|accessdate=26 March 2015}}&lt;/ref&gt; to [[e-mail privacy]]&lt;ref name="opgp"&gt;{{Cite web |title=Open PGP Message Format|rfc=2440|website=[[Internet Engineering Task Force]]|url=https://tools.ietf.org/html/rfc2440|date=November 1998|accessdate=26 March 2015}}&lt;/ref&gt; and [[Secure Shell|secure remote access]].&lt;ref name="ssh"&gt;{{Cite web|url=http://www.windowsecurity.com/articles/SSH.html|title=SSH|website=WindowSecurity|first=Pawel|last=Golen|date=19 July 2002|accessdate=26 March 2015}}&lt;/ref&gt; Many other block ciphers have been designed and released, with considerable variation in quality. Many, even some designed by capable practitioners, have been thoroughly broken, such as [[FEAL]].&lt;ref name="hac" /&gt;&lt;ref name="schneierbook"&gt;{{Cite book|first=Bruce|last=Schneier|authorlink=Bruce Schneier|title=Applied Cryptography|edition=2nd|publisher=[[John Wiley &amp; Sons|Wiley]]|year=1996|isbn=978-0471117094}}&lt;/ref&gt;

Stream ciphers, in contrast to the 'block' type, create an arbitrarily long stream of key material, which is combined with the plaintext bit-by-bit or character-by-character, somewhat like the [[one-time pad]]. In a stream cipher, the output stream is created based on a hidden internal state that changes as the cipher operates. That internal state is initially set up using the secret key material. [[RC4]] is a widely used stream cipher; see [[:Category:Stream ciphers]].&lt;ref name="hac" /&gt; Block ciphers can be used as stream ciphers; see [[Block cipher modes of operation]].

[[Cryptographic hash functions]] are a third type of cryptographic algorithm. They take a message of any length as input, and output a short, fixed length [[hash function|hash]], which can be used in (for example) a digital signature. For good hash functions, an attacker cannot find two messages that produce the same hash. [[MD4]] is a long-used hash function that is now broken; [[MD5]], a strengthened variant of MD4, is also widely used but broken in practice. The US [[National Security Agency]] developed the Secure Hash Algorithm series of MD5-like hash functions: SHA-0 was a flawed algorithm that the agency withdrew; [[SHA-1]] is widely deployed and more secure than MD5, but cryptanalysts have identified attacks against it; the [[SHA-2]] family improves on SHA-1, but it isn't yet widely deployed; and the US standards authority thought it "prudent" from a security perspective to develop a new standard to "significantly improve the robustness of [[National Institute of Standards and Technology|NIST]]'s overall hash algorithm toolkit."&lt;ref&gt;{{Cite journal|title=Notices|journal=[[Federal Register]]|volume=72|number=212|date=2 November 2007}}&lt;br /&gt;{{webarchive |url=https://web.archive.org/web/20080228075550/http://csrc.nist.gov/groups/ST/hash/documents/FR_Notice_Nov07.pdf |date=28 February 2008 }}&lt;/ref&gt; Thus, a [[NIST hash function competition|hash function design competition]] was meant to select a new U.S. national standard, to be called [[SHA-3]], by 2012. The competition ended on October 2, 2012 when the NIST announced that [[Keccak]] would be the new SHA-3 hash algorithm.&lt;ref&gt;{{cite web|url=https://www.nist.gov/itl/csd/sha-100212.cfm|title=NIST Selects Winner of Secure Hash Algorithm (SHA-3) Competition|website=Tech Beat|publisher=[[National Institute of Standards and Technology]]|date=October 2, 2012|accessdate=26 March 2015}}&lt;/ref&gt; Unlike block and stream ciphers that are invertible, cryptographic hash functions produce a hashed output that cannot be used to retrieve the original input data. Cryptographic hash functions are used to verify the authenticity of data retrieved from an untrusted source or to add a layer of security.

[[Message authentication code]]s (MACs) are much like cryptographic hash functions, except that a secret key can be used to authenticate the hash value upon receipt;&lt;ref name="hac" /&gt; this additional complication blocks an attack scheme against bare [[Md5|digest algorithms]], and so has been thought worth the effort.

===Public-key cryptography===
{{Main|Public-key cryptography}}
[[File:Public key encryption.svg|thumb|upright=1.15|alt=diagram of Public-key cryptography showing public key and private key|Public-key cryptography, where different keys are used for encryption and decryption.]]
[[File:TLS indicator in Firefox 34.png|thumb|250px|alt=padlock icon in the internet browser line next to the url|Padlock icon from the [[Firefox]] [[Web browser]], which indicates that [[Transport Layer Security|TLS]], a public-key cryptography system, is in use.]]
Symmetric-key cryptosystems use the same key for encryption and decryption of a message, although a message or group of messages can have a different key than others. A significant disadvantage of symmetric ciphers is the [[key management]] necessary to use them securely. Each distinct pair of communicating parties must, ideally, share a different key, and perhaps for each ciphertext exchanged as well. The number of keys required increases as the [[square (algebra)|square]] of the number of network members, which very quickly requires complex key management schemes to keep them all consistent and secret. The difficulty of securely establishing a secret key between two communicating parties, when a [[secure channel]] does not already exist between them, also presents a [[chicken-and-egg problem]] which is a considerable practical obstacle for cryptography users in the real world.{{fact|date=August 2018}}

{{stack|[[File:Diffie and Hellman.jpg|thumb|alt=headshots of Whitfield Diffie and Martin Hellman|[[Whitfield Diffie]] and [[Martin Hellman]], authors of the first published paper on public-key cryptography.]]}}
In a groundbreaking 1976 paper, Whitfield Diffie and Martin Hellman proposed the notion of ''public-key'' (also, more generally, called ''asymmetric key'') cryptography in which two different but mathematically related keys are used—a ''public'' key and a ''private'' key.&lt;ref&gt;{{Cite journal|first=Whitfield|last=Diffie|authorlink=Whitfield Diffie|first2=Martin|last2=Hellman|authorlink2=Martin Hellman|title=Multi-user cryptographic techniques|journal=AFIPS Proceedings|volume=45|pages=109–112|date=8 June 1976}}&lt;/ref&gt; A public key system is so constructed that calculation of one key (the 'private key') is computationally infeasible from the other (the 'public key'), even though they are necessarily related. Instead, both keys are generated secretly, as an interrelated pair.&lt;ref&gt;[[Ralph Merkle]] was working on similar ideas at the time and encountered publication delays, and Hellman has suggested that the term used should be Diffie–Hellman–Merkle aysmmetric key cryptography.&lt;/ref&gt; The historian [[David Kahn (writer)|David Kahn]] described public-key cryptography as "the most revolutionary new concept in the field since polyalphabetic substitution emerged in the Renaissance".&lt;ref&gt;{{Cite journal|first=David|last=Kahn|title=Cryptology Goes Public|journal=[[Foreign Affairs]]|volume=58|number=1|date=Fall 1979|page=153|doi=10.2307/20040343|jstor=20040343}}&lt;/ref&gt;

In public-key cryptosystems, the public key may be freely distributed, while its paired private key must remain secret. In a public-key encryption system, the ''public key'' is used for encryption, while the ''private'' or ''secret key'' is used for decryption. While Diffie and Hellman could not find such a system, they showed that public-key cryptography was indeed possible by presenting the [[Diffie–Hellman key exchange]] protocol, a solution that is now widely used in secure communications to allow two parties to secretly agree on a [[symmetric-key algorithm|shared encryption key]].&lt;ref name="dh2"/&gt;

Diffie and Hellman's publication sparked widespread academic efforts in finding a practical public-key encryption system. This race was finally won in 1978 by [[Ronald Rivest]], [[Adi Shamir]], and [[Len Adleman]], whose solution has since become known as the [[RSA (algorithm)|RSA algorithm]].&lt;ref&gt;{{Cite journal|first=Ronald L.|last=Rivest|authorlink=Ronald L. Rivest|first2=A.|last2=Shamir|first3=L.|last3=Adleman|title=A Method for Obtaining Digital Signatures and Public-Key Cryptosystems|journal=Communications of the ACM|volume=21|number=2|pages=120–126|year=1978|doi=10.1145/359340.359342|citeseerx=10.1.1.607.2677}}&lt;br /&gt;{{webarchive |url=https://web.archive.org/web/20011116122233/http://theory.lcs.mit.edu/~rivest/rsapaper.pdf |date=16 November 2001 }}&lt;br /&gt;Previously released as an [[MIT]] "Technical Memo" in April 1977, and published in [[Martin Gardner]]'s ''[[Scientific American]]'' [[Mathematical recreations]] column&lt;/ref&gt;

The Diffie–Hellman and RSA algorithms, in addition to being the first publicly known examples of high quality public-key algorithms, have been among the most widely used. Other [[:Category:Asymmetric-key algorithms|asymmetric-key algorithms]] include the [[Cramer–Shoup cryptosystem]], [[ElGamal encryption]], and various [[Elliptic curve cryptography|elliptic curve techniques]].{{fact|date=August 2018}}

To much surprise, a document published in 1997 by the Government Communications Headquarters ([[GCHQ]]), a British intelligence organization, revealed that cryptographers at GCHQ had anticipated several academic developments.&lt;ref name="nytimes"&gt;{{cite news|last=Wayner|first=Peter|url=https://www.nytimes.com/library/cyber/week/122497encrypt.html|title=British Document Outlines Early Encryption Discovery|date=24 December 1997|accessdate=2015-03-26|newspaper=[[The New York Times]]}}&lt;/ref&gt; Reportedly, around 1970, [[James H. Ellis]] had conceived the principles of asymmetric key cryptography. In 1973, [[Clifford Cocks]] invented a solution that essentially resembles the RSA algorithm.&lt;ref name="nytimes"/&gt;&lt;ref&gt;{{Cite journal|url=http://www.fi.muni.cz/usr/matyas/lecture/paper2.pdf|first=Clifford|last=Cocks|title=A Note on 'Non-Secret Encryption'|journal=CESG Research Report|date=20 November 1973}}&lt;/ref&gt; And in 1974, [[Malcolm J. Williamson]] is claimed to have developed the Diffie–Hellman key exchange.&lt;ref name=singh&gt;{{ cite book | first=Simon | last=Singh | title=The Code Book | publisher=[[Doubleday (publisher)|Doubleday]] | year=1999 | pages=279–292 }}&lt;/ref&gt;

[[File:Private key signing.png|thumb|250px|In this example the message is only signed and not encrypted.
1) Alice signs a message with her private key.
2) Bob can verify that Alice sent the message and that the message has not been modified.]]
Public-key cryptography can also be used for implementing [[digital signature]] schemes. A digital signature is reminiscent of an ordinary [[signature]]; they both have the characteristic of being easy for a user to produce, but difficult for anyone else to [[forgery|forge]]. Digital signatures can also be permanently tied to the content of the message being signed; they cannot then be 'moved' from one document to another, for any attempt will be detectable. In digital signature schemes, there are two algorithms: one for ''signing'', in which a secret key is used to process the message (or a hash of the message, or both), and one for ''verification'', in which the matching public key is used with the message to check the validity of the signature. RSA and [[Digital Signature Algorithm|DSA]] are two of the most popular digital signature schemes. Digital signatures are central to the operation of [[public key infrastructure]]s and many network security schemes (e.g., [[Transport Layer Security|SSL/TLS]], many [[VPN]]s, etc.).&lt;ref name="schneierbook" /&gt;

Public-key algorithms are most often based on the [[computational complexity theory|computational complexity]] of "hard" problems, often from [[number theory]]. For example, the hardness of RSA is related to the [[integer factorization]] problem, while Diffie–Hellman and DSA are related to the [[discrete logarithm]] problem. More recently, [[elliptic curve cryptography]] has developed, a system in which security is based on number theoretic problems involving [[elliptic curve]]s. Because of the difficulty of the underlying problems, most public-key algorithms involve operations such as [[modular arithmetic|modular]] multiplication and exponentiation, which are much more computationally expensive than the techniques used in most block ciphers, especially with typical key sizes. As a result, public-key cryptosystems are commonly [[hybrid cryptosystem]]s, in which a fast high-quality symmetric-key encryption algorithm is used for the message itself, while the relevant symmetric key is sent with the message, but encrypted using a public-key algorithm. Similarly, hybrid signature schemes are often used, in which a cryptographic hash function is computed, and only the resulting hash is digitally signed.&lt;ref name="hac" /&gt;

===Cryptanalysis===
{{Main|Cryptanalysis}}
[[File:Enigma.jpg|thumb|left|alt=Enigma machine typewriter keypad over many rotors in a wood box|Variants of the [[Enigma machine]], used by Germany's military and civil authorities from the late 1920s through [[World War II]], implemented a complex electro-mechanical polyalphabetic [[cipher]]. [[Cryptanalysis of the Enigma|Breaking and reading of the Enigma cipher]] at Poland's [[Biuro Szyfrów|Cipher Bureau]], for 7 years before the war, and subsequent decryption at [[Bletchley Park]], was important to Allied victory.&lt;ref name="kahnbook" /&gt;]]
The goal of cryptanalysis is to find some weakness or insecurity in a cryptographic scheme, thus permitting its subversion or evasion.

It is a common misconception that every encryption method can be broken. In connection with his WWII work at [[Bell Labs]], [[Claude Shannon]] proved that the [[one-time pad]] cipher is unbreakable, provided the key material is truly [[Statistical randomness|random]], never reused, kept secret from all possible attackers, and of equal or greater length than the message.&lt;ref&gt;{{Cite book|first=Claude|last=Shannon|first2=Warren|last2=Weaver|title=The Mathematical Theory of Communication|publisher=[[University of Illinois Press]]|year=1963|isbn=978-0252725487}}&lt;/ref&gt; Most [[cipher]]s, apart from the one-time pad, can be broken with enough computational effort by [[brute force attack]], but the amount of effort needed may be [[exponential time|exponentially]] dependent on the key size, as compared to the effort needed to make use of the cipher. In such cases, effective security could be achieved if it is proven that the effort required (i.e., "work factor", in Shannon's terms) is beyond the ability of any adversary. This means it must be shown that no efficient method (as opposed to the time-consuming brute force method) can be found to break the cipher. Since no such proof has been found to date, the one-time-pad remains the only theoretically unbreakable cipher.

There are a wide variety of cryptanalytic attacks, and they can be classified in any of several ways. A common distinction turns on what Eve (an attacker) knows and what capabilities are available. In a [[ciphertext-only attack]], Eve has access only to the ciphertext (good modern cryptosystems are usually effectively immune to ciphertext-only attacks). In a [[known-plaintext attack]], Eve has access to a ciphertext and its corresponding plaintext (or to many such pairs). In a [[chosen-plaintext attack]], Eve may choose a plaintext and learn its corresponding ciphertext (perhaps many times); an example is [[gardening (cryptanalysis)|gardening]], used by the British during WWII. In a [[chosen-ciphertext attack]], Eve may be able to ''choose'' ciphertexts and learn their corresponding plaintexts.&lt;ref name="hac" /&gt; Finally in a [[Man-in-the-middle attack|man-in-the-middle]] attack Eve gets in between Alice (the sender) and Bob (the recipient), accesses and modifies the traffic and then forwards it to the recipient.&lt;ref&gt;{{Cite web|url = http://www8.cs.umu.se/education/examina/Rapporter/MattiasEriksson.pdf|title = An Example of a Man-in-the-middle Attack Against Server Authenticated SSL-sessions|date = |accessdate = |website = |publisher = |last = |first = }}&lt;/ref&gt; Also important, often overwhelmingly so, are mistakes (generally in the design or use of one of the [[cryptographic protocol|protocols]] involved; see [[Cryptanalysis of the Enigma]] for some historical examples of this).
[[File:2008-09 Kaiserschloss Kryptologen.JPG|thumb|alt=Kaiserschloss Kryptologen monument numbers on stele|[[Poznań]] monument (''center'') to Polish cryptologists whose breaking of Germany's Enigma machine ciphers, beginning in 1932, altered the course of World War II]]
Cryptanalysis of symmetric-key ciphers typically involves looking for attacks against the block ciphers or stream ciphers that are more efficient than any attack that could be against a perfect cipher. For example, a simple brute force attack against DES requires one known plaintext and 2&lt;sup&gt;55&lt;/sup&gt; decryptions, trying approximately half of the possible keys, to reach a point at which chances are better than even that the key sought will have been found. But this may not be enough assurance; a [[linear cryptanalysis]] attack against DES requires 2&lt;sup&gt;43&lt;/sup&gt; known plaintexts and approximately 2&lt;sup&gt;43&lt;/sup&gt; DES operations.&lt;ref name="junod"&gt;{{Cite journal|first=Pascal|last=Junod|url=http://citeseer.ist.psu.edu/cache/papers/cs/22094/http:zSzzSzeprint.iacr.orgzSz2001zSz056.pdf/junod01complexity.pdf|title=On the Complexity of Matsui's Attack|journal=[[Selected Areas in Cryptography]]|year=2001}}&lt;/ref&gt; This is a considerable improvement on brute force attacks.

Public-key algorithms are based on the computational difficulty of various problems. The most famous of these is [[integer factorization]] (e.g., the RSA algorithm is based on a problem related to integer factoring), but the [[discrete logarithm]] problem is also important. Much public-key cryptanalysis concerns numerical algorithms for solving these computational problems, or some of them, efficiently (i.e., in a practical time). For instance, the best known algorithms for solving the [[elliptic curve cryptography|elliptic curve-based]] version of discrete logarithm are much more time-consuming than the best known algorithms for factoring, at least for problems of more or less equivalent size. Thus, other things being equal, to achieve an equivalent strength of attack resistance, factoring-based encryption techniques must use larger keys than elliptic curve techniques. For this reason, public-key cryptosystems based on elliptic curves have become popular since their invention in the mid-1990s.

While pure cryptanalysis uses weaknesses in the algorithms themselves, other attacks on cryptosystems are based on actual use of the algorithms in real devices, and are called ''[[side-channel attack]]s''. If a cryptanalyst has access to, for example, the amount of time the device took to encrypt a number of plaintexts or report an error in a password or PIN character, he may be able to use a [[timing attack]] to break a cipher that is otherwise resistant to analysis. An attacker might also study the pattern and length of messages to derive valuable information; this is known as [[traffic analysis]]&lt;ref name="SWT"&gt;{{Cite journal|first=Dawn|last=Song|first2=David A.|last2=Wagner|authorlink2=David A. Wagner|first3=Xuqing|last3=Tian|url=http://citeseer.ist.psu.edu/cache/papers/cs/22094/http:zSzzSzeprint.iacr.orgzSz2001zSz056.pdf/junod01complexity.pdf|title=Timing Analysis of Keystrokes and Timing Attacks on SSH|journal=Tenth USENIX Security Symposium|year=2001}}&lt;/ref&gt; and can be quite useful to an alert adversary. Poor administration of a cryptosystem, such as permitting too short keys, will make any system vulnerable, regardless of other virtues. [[social engineering (security)|Social engineering]] and other attacks against the personnel who work with cryptosystems or the messages they handle (e.g., [[bribery]], [[extortion]], [[blackmail]], [[espionage]], [[torture]], ...) may be the most productive attacks of all.

===Cryptographic primitives===
Much of the theoretical work in cryptography concerns [[cryptographic primitive|cryptographic ''primitives'']]—algorithms with basic cryptographic properties—and their relationship to other cryptographic problems. More complicated cryptographic tools are then built from these basic primitives. These primitives provide fundamental properties, which are used to develop more complex tools called ''cryptosystems'' or ''cryptographic protocols'', which guarantee one or more high-level security properties. Note however, that the distinction between cryptographic ''primitives'' and cryptosystems, is quite arbitrary; for example, the [[RSA (algorithm)|RSA]] algorithm is sometimes considered a cryptosystem, and sometimes a primitive. Typical examples of cryptographic primitives include [[pseudorandom function]]s, [[one-way function]]s, etc.

===Cryptosystems===
One or more cryptographic primitives are often used to develop a more complex algorithm, called a cryptographic system, or ''cryptosystem''. Cryptosystems (e.g., [[ElGamal encryption|El-Gamal encryption]]) are designed to provide particular functionality (e.g., public key encryption) while guaranteeing certain security properties (e.g., [[Chosen-plaintext attack|chosen-plaintext attack (CPA)]] security in the [[random oracle model]]). Cryptosystems use the properties of the underlying cryptographic primitives to support the system's security properties. As the distinction between primitives and cryptosystems is somewhat arbitrary, a sophisticated cryptosystem can be derived from a combination of several more primitive cryptosystems. In many cases, the cryptosystem's structure involves back and forth communication among two or more parties in space (e.g., between the sender of a secure message and its receiver) or across time (e.g., cryptographically protected [[backup]] data). Such cryptosystems are sometimes called ''[[cryptographic protocol]]s''.

Some widely known cryptosystems include [[RSA (algorithm)|RSA encryption]], [[Schnorr signature]], [[ElGamal encryption|El-Gamal encryption]], [[Pretty Good Privacy|PGP]], etc. More complex cryptosystems include [[electronic cash]]&lt;ref&gt;{{Cite journal|first=S. |last=Brands |url=http://ftp.se.kde.org/pub/security/docs/ecash/crypto93.ps.gz |title=Untraceable Off-line Cash in Wallets with Observers |journal=Advances in Cryptology—Proceedings of CRYPTO |year=1994 |deadurl=yes |archiveurl=https://web.archive.org/web/20110726214409/http://ftp.se.kde.org/pub/security/docs/ecash/crypto93.ps.gz |archivedate=26 July 2011 }}&lt;/ref&gt; systems, [[signcryption]] systems, etc. Some more 'theoretical' cryptosystems include [[interactive proof system]]s,&lt;ref&gt;{{Cite book|first=László|last=Babai|url=http://portal.acm.org/citation.cfm?id=22192|title=Trading group theory for randomness|journal=Proceedings of the Seventeenth Annual Symposium on the Theory of Computing|pages=421–429|year=1985|doi=10.1145/22145.22192|isbn=978-0897911511|citeseerx=10.1.1.130.3397}}&lt;/ref&gt; (like [[zero-knowledge proof]]s),&lt;ref&gt;{{Cite journal|authorlink=Shafi Goldwasser|first=S.|last=Goldwasser|authorlink2=Silvio Micali|first2=S.|last2=Micali|authorlink3=Charles Rackoff|first3=C.|last3=Rackoff|title=The Knowledge Complexity of Interactive Proof Systems|journal=[[SIAM Journal on Computing]]|volume=18|number=1|pages=186–208|year=1989|doi=10.1137/0218012|citeseerx=10.1.1.397.4002}}&lt;/ref&gt; systems for [[secret sharing]],&lt;ref&gt;{{Cite journal|authorlink=George Blakley|first=G.|last=Blakley|title=Safeguarding cryptographic keys|journal=Proceedings of AFIPS 1979|volume=48|pages=313–317|date=June 1979}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|first=A.|last=Shamir|title=How to share a secret|journal=Communications of the ACM|volume=22|issue=11|pages=612–613|year=1979|doi=10.1145/359168.359176}}&lt;/ref&gt; etc.

Until recently{{Clarify timeframe|date=November 2018}} most security properties of most cryptosystems were demonstrated using empirical techniques or using ad hoc reasoning. Recently{{Clarify timeframe|date=November 2018}} there has been considerable effort to develop formal techniques for establishing the security of cryptosystems; this has been generally called ''[[provable security]]''. The general idea of provable security is to give arguments about the computational difficulty needed to compromise some security aspect of the cryptosystem (i.e., to any adversary).

The study of how best to implement and integrate cryptography in software applications is itself a distinct field (see [[Cryptographic engineering]] and [[Security engineering]]).

==Legal issues==
{{See also|Cryptography laws in different nations}}

===Prohibitions===
Cryptography has long been of interest to intelligence gathering and [[law enforcement agency|law enforcement agencies]].&lt;ref name="RangerSteve1"/&gt; Secret communications may be criminal or even [[treason]]ous {{citation needed|date=April 2016}}&lt;!--it is not clear how secure communication might be construed as treason--&gt;. Because of its facilitation of [[privacy]], and the diminution of privacy attendant on its prohibition, cryptography is also of considerable interest to civil rights supporters. Accordingly, there has been a history of controversial legal issues surrounding cryptography, especially since the advent of inexpensive computers has made widespread access to high quality cryptography possible.

In some countries, even the domestic use of cryptography is, or has been, restricted. Until 1999, [[France]] significantly restricted the use of cryptography domestically, though it has since relaxed many of these rules. In [[People's Republic of China|China]] and [[Islamic Republic of Iran|Iran]], a license is still required to use cryptography.&lt;ref name="cryptolaw"&gt;{{cite web|url=http://www.cryptolaw.org/cls2.htm |title=Overview per country|website=Crypto Law Survey|date=February 2013|accessdate=26 March 2015}}&lt;/ref&gt; Many countries have tight restrictions on the use of cryptography. Among the more restrictive are laws in [[Belarus]], [[Kazakhstan]], [[Mongolia]], [[Pakistan]], [[Singapore]], [[Tunisia]], and [[Vietnam]].&lt;ref&gt;{{cite web|url=http://www.emc.com/emc-plus/rsa-labs/standards-initiatives/cryptographic-policies-countries.htm|title=6.5.1 What Are the Cryptographic Policies of Some Countries?|publisher=[[RSA Laboratories]]|accessdate=26 March 2015}}&lt;/ref&gt;

In the [[United States]], cryptography is legal for domestic use, but there has been much conflict over legal issues related to cryptography.&lt;ref name="RangerSteve1"/&gt; One particularly important issue has been the [[export of cryptography]] and cryptographic software and hardware. Probably because of the importance of cryptanalysis in [[World War II]] and an expectation that cryptography would continue to be important for national security, many Western governments have, at some point, strictly regulated export of cryptography. After World War II, it was illegal in the US to sell or distribute encryption technology overseas; in fact, encryption was designated as auxiliary military equipment and put on the [[United States Munitions List]].&lt;ref name="cyberlaw"&gt;{{Cite web|title=Cryptography &amp; Speech|last=Rosenoer|first=Jonathan|website=CyberLaw|date=1995}}&lt;br /&gt;{{webarchive |url=https://web.archive.org/web/20051201184530/http://www.cyberlaw.com/cylw1095.html |date=1 December 2005 }}&lt;/ref&gt; Until the development of the [[personal computer]], asymmetric key algorithms (i.e., public key techniques), and the [[Internet]], this was not especially problematic. However, as the Internet grew and computers became more widely available, high-quality encryption techniques became well known around the globe.

===Export controls===
{{Main|Export of cryptography}}
In the 1990s, there were several challenges to US export regulation of cryptography. After the [[source code]] for [[Philip Zimmermann]]'s [[Pretty Good Privacy]] (PGP) encryption program found its way onto the Internet in June 1991, a complaint by [[RSA Security]] (then called RSA Data Security, Inc.) resulted in a lengthy criminal investigation of Zimmermann by the US Customs Service and the [[Federal Bureau of Investigation|FBI]], though no charges were ever filed.&lt;ref name="zim"&gt;{{Cite web|url=http://www.ieee-security.org/Cipher/Newsbriefs/1996/960214.zimmerman.html|title=Case Closed on Zimmermann PGP Investigation|website=[[IEEE Computer Society]]'s Technical Committee on Security and Privacy|date=14 February 1996|accessdate=26 March 2015}}&lt;/ref&gt;&lt;ref name="levybook"&gt;{{cite book |last=Levy |first=Steven |authorlink=Steven Levy |title=Crypto: How the Code Rebels Beat the Government—Saving Privacy in the Digital Age |publisher=[[Penguin Books]] |year=2001 |isbn=978-0140244328 |page=56 |oclc=244148644}}&lt;/ref&gt; [[Daniel J. Bernstein]], then a graduate student at [[UC Berkeley]], brought a lawsuit against the US government challenging some aspects of the restrictions based on [[1st Amendment|free speech]] grounds. The 1995 case [[Bernstein v. United States]] ultimately resulted in a 1999 decision that printed source code for cryptographic algorithms and systems was protected as [[freedom of speech|free speech]] by the United States Constitution.&lt;ref name="b v us"&gt;{{Cite web|title=Bernstein v USDOJ|url=http://www.epic.org/crypto/export_controls/bernstein_decision_9_cir.html|publisher=[[United States Court of Appeals for the Ninth Circuit]]|website=[[Electronic Privacy Information Center]]|date=6 May 1999|accessdate=26 March 2015}}&lt;/ref&gt;

In 1996, thirty-nine countries signed the [[Wassenaar Arrangement]], an arms control treaty that deals with the export of arms and "dual-use" technologies such as cryptography. The treaty stipulated that the use of cryptography with short key-lengths (56-bit for symmetric encryption, 512-bit for RSA) would no longer be export-controlled.&lt;ref name="wa"&gt;{{cite web|url=https://www.bis.doc.gov/index.php/documents/regulations-docs/445-category-5-part-2-information-security/file|format=PDF|title=Dual-use List – Category 5 – Part 2 – "Information Security"|website=[[Wassenaar Arrangement]]|accessdate=26 March 2015}}&lt;/ref&gt; Cryptography exports from the US became less strictly regulated as a consequence of a major relaxation in 2000;&lt;ref&gt;{{Cite web|title=.4 United States Cryptography Export/Import Laws|website=[[RSA Laboratories]]|url=http://www.emc.com/emc-plus/rsa-labs/standards-initiatives/united-states-cryptography-export-import.htm|accessdate=26 March 2015}}&lt;/ref&gt; there are no longer very many restrictions on key sizes in US-[[Export of cryptography|exported]] mass-market software. Since this relaxation in US export restrictions, and because most personal computers connected to the [[Internet]] include US-sourced [[web browser]]s such as [[Firefox]] or [[Internet Explorer]], almost every Internet user worldwide has potential access to quality cryptography via their browsers (e.g., via [[Transport Layer Security]]). The [[Mozilla Thunderbird]] and [[Microsoft Outlook]] [[E-mail client]] programs similarly can transmit and receive emails via TLS, and can send and receive email encrypted with [[S/MIME]]. Many Internet users don't realize that their basic application software contains such extensive [[cryptosystem]]s. These browsers and email programs are so ubiquitous that even governments whose intent is to regulate civilian use of cryptography generally don't find it practical to do much to control distribution or use of cryptography of this quality, so even when such laws are in force, actual enforcement is often effectively impossible.{{citation needed|date=August 2013}}

===NSA involvement===
[[File:National Security Agency headquarters, Fort Meade, Maryland.jpg|thumb|right|NSA headquarters in Fort Meade, Maryland]]
{{See also|Clipper chip}}
Another contentious issue connected to cryptography in the United States is the influence of the [[National Security Agency]] on cipher development and policy.&lt;ref name="RangerSteve1"/&gt; The NSA was involved with the design of [[Data Encryption Standard|DES]] during its development at [[IBM]] and its consideration by the [[National Bureau of Standards]] as a possible Federal Standard for cryptography.&lt;ref name="cryptogram"&gt;{{Cite web|url=http://www.schneier.com/crypto-gram-0006.html#DES|title=The Data Encryption Standard (DES)|authorlink=Bruce Schneier|first=Bruce|last=Schneier|website=Crypto-Gram|date=15 June 2000|accessdate=26 March 2015}}&lt;/ref&gt; DES was designed to be resistant to [[differential cryptanalysis]],&lt;ref name="coppersmith-des"&gt;{{cite journal| last = Coppersmith| first = D.|date=May 1994| title = The Data Encryption Standard (DES) and its strength against attacks| journal = IBM Journal of Research and Development| volume = 38| issue = 3| pages = 243–250| url = http://domino.watson.ibm.com/tchjr/journalindex.nsf/0/94f78816c77fc77885256bfa0067fb98?OpenDocument| format = PDF| doi = 10.1147/rd.383.0243|accessdate=26 March 2015}}&lt;/ref&gt; a powerful and general cryptanalytic technique known to the NSA and IBM, that became publicly known only when it was rediscovered in the late 1980s.&lt;ref&gt;{{Cite journal|authorlink=Eli Biham|first=E.|last=Biham|first2=A.|last2=Shamir|url=http://www.springerlink.com/index/K54H077NP8714058.pdf|format=PDF|title=Differential cryptanalysis of DES-like cryptosystems|journal=Journal of Cryptology|volume=4|number=1|pages=3–72|year=1991|accessdate=26 March 2015|doi=10.1007/bf00630563}}&lt;/ref&gt; According to [[Steven Levy]], IBM discovered differential cryptanalysis,&lt;ref name="levybook"/&gt; but kept the technique secret at the NSA's request. The technique became publicly known only when Biham and Shamir re-discovered and announced it some years later. The entire affair illustrates the difficulty of determining what resources and knowledge an attacker might actually have.

Another instance of the NSA's involvement was the 1993 [[Clipper chip]] affair, an encryption microchip intended to be part of the [[Capstone (cryptography)|Capstone]] cryptography-control initiative. Clipper was widely criticized by cryptographers for two reasons. The cipher algorithm (called [[Skipjack (cipher)|Skipjack]]) was then classified (declassified in 1998, long after the Clipper initiative lapsed). The classified cipher caused concerns that the NSA had deliberately made the cipher weak in order to assist its intelligence efforts. The whole initiative was also criticized based on its violation of [[Kerckhoffs's Principle]], as the scheme included a special [[key escrow|escrow key]] held by the government for use by law enforcement, for example in wiretaps.&lt;ref name="levybook"/&gt;

===Digital rights management===
{{Main|Digital rights management}}
Cryptography is central to digital rights management (DRM), a group of techniques for technologically controlling use of [[copyright]]ed material, being widely implemented and deployed at the behest of some copyright holders. In 1998, [[U.S. President]] [[Bill Clinton]] signed the [[Digital Millennium Copyright Act]] (DMCA), which criminalized all production, dissemination, and use of certain cryptanalytic techniques and technology (now known or later discovered); specifically, those that could be used to circumvent DRM technological schemes.&lt;ref name="DMCA"&gt;{{cite web|url=http://www.copyright.gov/legislation/dmca.pdf |title=The Digital Millennium Copyright Act of 1998 |format=PDF |website=[[United States Copyright Office]]|accessdate=26 March 2015}}&lt;/ref&gt; This had a noticeable impact on the cryptography research community since an argument can be made that ''any'' cryptanalytic research violated, or might violate, the DMCA. Similar statutes have since been enacted in several countries and regions, including the implementation in the [[Directive on the harmonisation of certain aspects of copyright and related rights in the information society|EU Copyright Directive]]. Similar restrictions are called for by treaties signed by [[World Intellectual Property Organization]] member-states.

The [[United States Department of Justice]] and [[Federal Bureau of Investigation|FBI]] have not enforced the DMCA as rigorously as had been feared by some, but the law, nonetheless, remains a controversial one. [[Niels Ferguson]], a well-respected cryptography researcher, has publicly stated that he will not release some of his research into an [[Intel Corporation|Intel]] security design for fear of prosecution under the DMCA.&lt;ref&gt;{{Cite web|title=Censorship in action: why I don't publish my HDCP results|last=Ferguson|first=Niels|date=15 August 2001}}&lt;br /&gt;{{webarchive |url=https://web.archive.org/web/20011201184919/http://www.macfergus.com/niels/dmca/cia.html |date=1 December 2001 }}&lt;/ref&gt; Cryptanalyst [[Bruce Schneier]] has argued that the DMCA encourages [[vendor lock-in]], while inhibiting actual measures toward cyber-security.&lt;ref&gt;{{cite web |url=https://www.schneier.com/essays/archives/2001/08/arrest_of_computer_r.html |title=Arrest of Computer Researcher Is Arrest of First Amendment Rights |last=Schneier |first=Bruce |authorlink=Bruce Schneier |publisher=InternetWeek |date=2001-08-06 |accessdate=2017-03-07 }}&lt;/ref&gt; Both [[Alan Cox]] (longtime [[Linux kernel]] developer) and [[Edward Felten]] (and some of his students at Princeton) have encountered problems related to the Act. [[Dmitry Sklyarov]] was arrested during a visit to the US from Russia, and jailed for five months pending trial for alleged violations of the DMCA arising from work he had done in Russia, where the work was legal. In 2007, the cryptographic keys responsible for [[Blu-ray]] and [[HD DVD]] content scrambling were [[AACS encryption key controversy|discovered and released onto the Internet]]. In both cases, the [[MPAA]] sent out numerous DMCA takedown notices, and there was a massive Internet backlash&lt;ref name="AACS"&gt;{{cite web|url=http://boingboing.net/2007/05/02/digg-users-revolt-ov.html|title=Digg users revolt over AACS key|accessdate=26 March 2015|date=2 May 2007|first=Cory|last=Doctorow|website=[[Boing Boing]]}}&lt;/ref&gt; triggered by the perceived impact of such notices on [[fair use]] and [[free speech]].

===Forced disclosure of encryption keys===
{{Main|Key disclosure law}}
In the United Kingdom, the [[Regulation of Investigatory Powers Act 2000|Regulation of Investigatory Powers Act]] gives UK police the powers to force suspects to decrypt files or hand over passwords that protect encryption keys. Failure to comply is an offense in its own right, punishable on conviction by a two-year jail sentence or up to five years in cases involving national security.&lt;ref name="UK law"&gt;{{cite web|url=http://www.pcworld.com/article/137881/uk_data_encryption_disclosure_law_takes_effect.html |title=UK Data Encryption Disclosure Law Takes Effect |website=[[PC World]] |date=1 October 2007 |accessdate=26 March 2015}}&lt;/ref&gt; Successful prosecutions have occurred under the Act; the first, in 2009,&lt;ref&gt;{{cite web|url=https://www.theregister.co.uk/2009/08/11/ripa_iii_figures/ |title=Two convicted for refusal to decrypt data|first=Christopher|last=Williams |website=[[The Register]] |date=11 August 2009|accessdate=26 March 2015}}&lt;/ref&gt; resulted in a term of 13 months' imprisonment.&lt;ref&gt;{{cite web|url=https://www.theregister.co.uk/2009/11/24/ripa_jfl/ |title=UK jails schizophrenic for refusal to decrypt files|first=Christopher|last=Williams |website=[[The Register]] |date=24 November 2009 |accessdate=26 March 2015}}&lt;/ref&gt; Similar forced disclosure laws in Australia, Finland, France, and India compel individual suspects under investigation to hand over encryption keys or passwords during a criminal investigation.

In the United States, the federal criminal case of [[United States v. Fricosu]] addressed whether a search warrant can compel a person to reveal an [[encryption]] [[passphrase]] or password.&lt;ref&gt;{{cite news |url=http://www.denverpost.com/news/ci_19669803 |title=Password case reframes Fifth Amendment rights in context of digital world |newspaper=[[The Denver Post]] |date=January 4, 2012 |first=John |last=Ingold |accessdate=26 March 2015}}&lt;/ref&gt; The [[Electronic Frontier Foundation]] (EFF) argued that this is a violation of the protection from self-incrimination given by the [[Fifth Amendment to the United States Constitution|Fifth Amendment]].&lt;ref&gt;{{cite web|last=Leyden |first=John |url=https://www.theregister.co.uk/2011/07/13/eff_piles_in_against_forced_decryption/ |title=US court test for rights not to hand over crypto keys |website=[[The Register]] |date=13 July 2011 |accessdate=26 March 2015}}&lt;/ref&gt; In 2012, the court ruled that under the [[All Writs Act]], the defendant was required to produce an unencrypted hard drive for the court.&lt;ref&gt;{{Cite web|title=Order Granting Application under the All Writs Act Requiring Defendant Fricosu to Assist in the Execution of Previously Issued Search Warrants|publisher=[[United States District Court for the District of Colorado]]|url=https://www.wired.com/images_blogs/threatlevel/2012/01/decrypt.pdf|format=PDF|accessdate=26 March 2015}}&lt;/ref&gt;

In many jurisdictions, the legal status of forced disclosure remains unclear.

The 2016 [[FBI–Apple encryption dispute]] concerns the ability of courts in the United States to compel manufacturers' assistance in unlocking cell phones whose contents are cryptographically protected.

As a potential counter-measure to forced disclosure some cryptographic software supports [[plausible deniability]], where the encrypted data is indistinguishable from unused random data (for example such as that of a [[Data remanence|drive which has been securely wiped]]).

==See also==
* [[Outline of cryptography]]
* [[List of cryptographers]]
* [[Encyclopedia of Cryptography and Security]]
* [[List of important publications in cryptography]]
* [[List of multiple discoveries#20th century|List of multiple discoveries]] (see "RSA")
* [[List of unsolved problems in computer science]]
* [[Crypto Wars]]
* [[Global surveillance]]
* [[Strong cryptography]]
* [[Comparison of cryptography libraries]]
* [[A Syllabical and Steganographical table]] – first cryptography chart
* [[W3C]]'s [[Web cryptography API]]

==References==
{{Reflist}}

==Further reading==
{{further|Books on cryptography}}
{{Refbegin|30em}}
* {{cite book | author=Becket, B | title=Introduction to Cryptology | publisher=Blackwell Scientific Publications | year=1988 | isbn=978-0632018369 | oclc=16832704}} Excellent coverage of many classical ciphers and cryptography concepts and of the "modern" DES and RSA systems.
* ''Cryptography and Mathematics'' by [[Bernhard Esslinger]], 200 pages, part of the free open-source package [[CrypTool]], {{webarchive |url=https://web.archive.org/web/20110722183013/http://www.cryptool.org/download/CrypToolScript-en.pdf |date=22 July 2011 |title=PDF download }}. CrypTool is the most widespread e-learning program about cryptography and cryptanalysis, open source.
* ''In Code: A Mathematical Journey'' by [[Sarah Flannery]] (with David Flannery). Popular account of Sarah's award-winning project on public-key cryptography, co-written with her father.
* [[James Gannon]], ''Stealing Secrets, Telling Lies: How Spies and Codebreakers Helped Shape the Twentieth Century'', Washington, D.C., Brassey's, 2001, {{isbn|1574883674}}.
* [[Oded Goldreich]], [http://www.wisdom.weizmann.ac.il/~oded/foc-book.html ''Foundations of Cryptography''], in two volumes, Cambridge University Press, 2001 and 2004.
* ''[http://www.cs.umd.edu/~jkatz/imc.html Introduction to Modern Cryptography]'' by Jonathan Katz and Yehuda Lindell.
* ''Alvin's Secret Code'' by [[Clifford B. Hicks]] (children's novel that introduces some basic cryptography and cryptanalysis).
* Ibrahim A. Al-Kadi, "The Origins of Cryptology: the Arab Contributions," Cryptologia, vol. 16, no. 2 (April 1992), pp.&amp;nbsp;97–126.
* [https://web.archive.org/web/20060709111152/http://www.crypto.rub.de/en_paar.html Christof Paar], Jan Pelzl, [http://www.cryptography-textbook.com/ ''Understanding Cryptography, A Textbook for Students and Practitioners''.] Springer, 2009. (Slides, online cryptography lectures and other information are available on the companion web site.) Very accessible introduction to practical cryptography for non-mathematicians.
* ''Introduction to Modern Cryptography'' by [[Phillip Rogaway]] and [[Mihir Bellare]], a mathematical introduction to theoretical cryptography including reduction-based security proofs. [http://www.cs.ucdavis.edu/~rogaway/classes/227/spring05/book/main.pdf PDF download].
* Johann-Christoph Woltag, 'Coded Communications (Encryption)' in Rüdiger Wolfrum (ed) ''Max Planck Encyclopedia of Public International Law'' (Oxford University Press 2009).
* {{cite web|url=http://www.mpepil.com|title=Max Planck Encyclopedia of Public International Law}}, giving an overview of international law issues regarding cryptography.
* Jonathan Arbib &amp; John Dwyer, ''Discrete Mathematics for Cryptography'', 1st Edition {{isbn|978-1907934018}}.
* {{cite book|last=Stallings |first=William |author-link=William Stallings |title=Cryptography and Network Security: Principles and Practice |publisher=Prentice Hall |date=March 2013 |edition=6th |isbn=978-0133354690}}
{{Refend}}

==External links==
{{Wikiquote}}
{{Wikibooks}}
{{WVD}}
{{EB1911 poster|Cryptography}}
{{Library resources box|onlinebooks=yes}}
* {{Wiktionary-inline}}
* {{Commons category-inline|Cryptography}}
* {{In Our Time|Cryptography|p004y272|Cryptography}}
* [http://ciphersbyritter.com/GLOSSARY.HTM Crypto Glossary and Dictionary of Technical Cryptography]
* [http://www.nsa.gov/kids/ NSA's CryptoKids].
* [http://www.cryptool.org/images/ct1/presentations/CrypToolPresentation-en.pdf Overview and Applications of Cryptology] by the CrypTool Team; PDF; 3.8&amp;nbsp;MB. July 2008
* [http://www.cs.cornell.edu/courses/cs4830/2010fa/lecnotes.pdf A Course in Cryptography] by Raphael Pass &amp; Abhi Shelat – offered at Cornell in the form of lecture notes.
* For more on the use of cryptographic elements in fiction, see: {{cite web |url=http://faculty.knox.edu/jdooley/Crypto/CryptoFiction.htm | title = Cryptology in Fiction  |last1= Dooley |first1=John F.,  William and Marilyn Ingersoll Professor of Computer Science, Knox College |date=23 August 2012}}
* [https://www.loc.gov/rr/rarebook/coll/073.html The George Fabyan Collection] at the [[Library of Congress]] has early editions of works of seventeenth-century English literature, publications relating to cryptography.

{{Cryptography navbox}}
{{Espionage}}
{{Hidden messages}}
{{Intelligence cycle management}}

{{Portal bar|Cryptography|Computer security}}

&lt;!-- Please respect alphabetical order --&gt;

[[Category:Cryptography| ]]
[[Category:Banking technology]]
[[Category:Formal sciences]]
[[Category:Applied mathematics]]</text>
      <sha1>md6x40ijc00vi96cl5zqpdl3vu38od1</sha1>
    </revision>
  </page>
  <page>
    <title>Double counting (fallacy)</title>
    <ns>0</ns>
    <id>6233627</id>
    <revision>
      <id>831152645</id>
      <parentid>784198493</parentid>
      <timestamp>2018-03-19T01:22:28Z</timestamp>
      <contributor>
        <username>Grutness</username>
        <id>117878</id>
      </contributor>
      <comment>removed [[Category:Logical fallacies]]; added [[Category:Informal fallacies]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2491">{{refimprove|date=September 2016}}

'''Double counting''' is a [[fallacy]] in which, when counting events or occurrences in [[probability]] or in other areas, a solution counts events two or more times, resulting in an erroneous number of events or occurrences which is higher than the true result. This results in the calculated sum of probabilities for all possible outcomes to be higher than 100%, which is impossible.

For example, what is the probability of seeing at least one 5 when throwing a pair of dice? An erroneous argument goes as follows: The first die shows a 5 with probability 1/6; the second die shows a 5 with probability 1/6; therefore the probability of seeing a 5 on at least one of the dice is 1/6 + 1/6 = 1/3 = 12/36. However, the correct answer is 11/36, because the erroneous argument has double-counted the event where both dice show 5s.

In mathematical terms, the previous example calculated the probability of P(A or B) as P(A)+P(B). However, by the [[inclusion-exclusion]] principle, P(A or B) = P(A) + P(B) - P(A and B). The principle is used to compensate for double counting by subtracting those objects which were double counted.

Another example is made in the joke where a man explains to his boss why he has to be an hour late to work every day:
* There are 8760 (365*24) hours in a year, 
* He needs 8 hours sleep daily (365*8) 2920 hours leaving 5840 hours.
* He uses 30 minutes per meal, (1.5*365) or 547.5 hours, leaving 5250.5.
* He needs 20 minutes a day to bathe, 109.5 leaving 5183.
* Weekends use 2 days a week, 52 weeks, 2496, leaving 2687.
* Vacation uses two weeks, 336 hours, leaving 2361.
* The company celebrates 5 holidays a year, 120, leaving 2231.
* He commutes to work 1 hour each way, 2 hours a day, 5 days a week, 50 weeks a year, 500, leaving 1731.
* The work week is 8 hours a day, 5 days a week, 50 weeks a year, 2000 hours, leaving him short by 269 hours, or roughly 1 hour of each work day.

All of the numbers are correct, but the man is counting them incorrectly. Sleeping, bathing and eating are part of the weekends, holidays and vacation time that are also being included, making these hours double counted.

== Further reading ==
* Stephen Campbell, ''Flaws and Fallacies in Statistical Thinking'' (2012), in series ''Dover Books on Mathematics'', [[Courier Corporation]], {{ISBN|9780486140513}}

{{Informal fallacy}}

[[Category:Informal fallacies]]
[[Category:Misuse of statistics]]

{{statistics-stub}}
{{logic-stub}}</text>
      <sha1>imotpykwc542j0rxnemhyd3lh7rg6wo</sha1>
    </revision>
  </page>
  <page>
    <title>Essential range</title>
    <ns>0</ns>
    <id>18380182</id>
    <revision>
      <id>829263149</id>
      <parentid>737040457</parentid>
      <timestamp>2018-03-07T15:53:38Z</timestamp>
      <contributor>
        <ip>2003:F3:2BCF:1C00:91CA:DF30:F0B6:692B</ip>
      </contributor>
      <comment>/* Properties */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3650">In [[mathematics]], particularly [[measure theory]], the '''essential range''' of a [[Function (mathematics)|function]] is intuitively the 'non-negligible' range of the function: It does not change between two functions that are equal [[almost everywhere]]. One way of thinking of the essential range of a function is the [[Set (mathematics)|set]] on which the range of the function is most 'concentrated'.  The essential range can be defined for [[measurable function|measurable]] real or complex-valued functions on a [[measure space]].

==Formal definition==

Let ''f'' be a [[measurable function|Borel-measurable]], complex-valued function defined on a [[measure space]] &lt;math&gt;(X,\mathfrak{A},\mu)&lt;/math&gt;. Then the essential range of ''f'' is defined to be the set:

:&lt;math&gt;\operatorname{ess.im}(f) = \left\{z \in \mathbb{C} \mid \text{for all}\ \varepsilon &gt; 0: \mu(\{x : |f(x) - z| &lt; \varepsilon\}) &gt; 0\right\}&lt;/math&gt;

In other words: The essential range of a complex-valued function is the set of all complex numbers ''z'' such that the inverse image of each ε-neighbourhood of ''z'' under ''f'' has positive measure.

==Properties==

* The essential range of a measurable function is always closed.
* The essential range ess.im(f) of a measurable function is always a subset of &lt;math&gt;\overline{\operatorname{im}(f)}&lt;/math&gt;.
* The essential image cannot be used to distinguish functions that are almost everywhere equal: If &lt;math&gt;f=g&lt;/math&gt; holds &lt;math&gt;\mu&lt;/math&gt;-[[almost everywhere]], then &lt;math&gt;\operatorname{ess.im}(f)=\operatorname{ess.im}(g)&lt;/math&gt;.
* These two facts characterise the essential image: It is the biggest set contained in the closures of &lt;math&gt;\operatorname{im}(g)&lt;/math&gt; for all g that are a.e. equal to f:
::&lt;math&gt;\operatorname{ess.im}(f) = \bigcap_{f=g\,\text{a.e.}} \overline{\operatorname{im}(g)}&lt;/math&gt;.
* The essential range satisfies &lt;math&gt;\forall A\subseteq X: f(A) \cap \operatorname{ess.im}(f) = \emptyset \implies \mu(A) = 0&lt;/math&gt;.
* This fact characterises the essential image: It is the ''smallest'' closed subset of &lt;math&gt;\mathbb{C}&lt;/math&gt; with this property.
* The [[essential supremum]] of a real valued function equals the supremum of its essential image and the essential infimum equals the infimum of its essential range. Consequently, a function is essentially bounded if and only if its essential range is bounded.
* The essential range of an essentially bounded function f is equal to the [[Spectrum (functional analysis)#Spectrum of a unital Banach algebra|spectrum]] &lt;math&gt;\sigma(f)&lt;/math&gt; where f is considered as an element of the [[C*-algebra]] &lt;math&gt;L^\infty(\mu)&lt;/math&gt;.

== Examples ==

* If &lt;math&gt;\mu&lt;/math&gt; is the zero measure, then the essential image of all measurable functions is empty.
* This also illustrates that even though the essential range of a function is a subset of the closure of the range of that function, equality of the two sets need not hold.
* If &lt;math&gt;X\subseteq\mathbb{R}^n&lt;/math&gt; is open, &lt;math&gt;f:X\to\mathbb{C}&lt;/math&gt; and &lt;math&gt;\mu&lt;/math&gt; the Lebesgue measure, then &lt;math&gt;\operatorname{ess.im}(f)=\overline{\operatorname{im}(f)}&lt;/math&gt; holds. This holds more generally for all Borel measures that assign non-zero measure to every non-empty open set.

==See also==

* [[Essential supremum and essential infimum]]
* [[Measure (mathematics)|measure]]
* [[Lp space|L&lt;sup&gt;p&lt;/sup&gt; space]]

==References==

* {{cite book
 | author = [[Walter Rudin]]
 | year = 1974
 | title = Real and Complex Analysis
 | edition = 2nd
 | publisher = [[McGraw-Hill]]
 | isbn = 978-0-07-054234-1
}}

{{DEFAULTSORT:Essential Range}}
[[Category:Real analysis]]
[[Category:Measure theory]]</text>
      <sha1>ojzpq8pb0l9gr4l95xvqzrrthp9mvje</sha1>
    </revision>
  </page>
  <page>
    <title>Euclid–Mullin sequence</title>
    <ns>0</ns>
    <id>10456890</id>
    <revision>
      <id>841539736</id>
      <parentid>811480628</parentid>
      <timestamp>2018-05-16T13:19:51Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7562">The '''Euclid–Mullin sequence''' is an infinite sequence of distinct [[prime number]]s, in which each element is the least [[prime factor]] of one plus the product of all earlier elements. They are named after the ancient Greek mathematician [[Euclid]], because their definition relies on an idea in [[Euclid's theorem|Euclid's proof that there are infinitely many primes]], and after [[Albert A. Mullin]], who asked about the sequence in 1963.&lt;ref&gt;{{citation|first=Albert A.|last=Mullin|title=Recursive function theory (A modern look at a Euclidean idea)|department=Research problems|journal=[[Bulletin of the American Mathematical Society]]|volume=69|issue=6|year=1963|page=737|doi=10.1090/S0002-9904-1963-11017-4 }}.&lt;/ref&gt;

The first 51 elements of the sequence are

:2, 3, 7, 43, 13, 53, 5, 6221671, 38709183810571, 139, 2801, 11, 17, 5471, 52662739, 23003, 30693651606209, 37, 1741, 1313797957, 887, 71, 7127, 109, 23, 97, 159227, 643679794963466223081509857, 103, 1079990819, 9539, 3143065813, 29, 3847, 89, 19, 577, 223, 139703, 457, 9649, 61, 4357, 87991098722552272708281251793312351581099392851768893748012603709343, 107, 127, 3313, 227432689108589532754984915075774848386671439568260420754414940780761245893, 59, 31, 211... {{OEIS|id=A000945}}

These are the only known elements {{As of|2012|9|lc=on}}. Finding the next one requires finding the least prime factor of a 335-digit number (which is known to be [[composite number|composite]]).

==Definition==
The &lt;math&gt;n&lt;/math&gt;th element of the sequence, &lt;math&gt;a_n&lt;/math&gt;, is the least prime factor of

:&lt;math&gt;\Bigl(\prod_{i &lt; n} a_i\Bigr)+1\,.&lt;/math&gt;

The first element is therefore the least prime factor of the [[empty product]] plus one, which is&amp;nbsp;2. The element 13 in the sequence is the least prime factor of 2&amp;nbsp;×&amp;nbsp;3&amp;nbsp;×&amp;nbsp;7&amp;nbsp;×&amp;nbsp;43&amp;nbsp;+&amp;nbsp;1 =&amp;nbsp;1806&amp;nbsp;+&amp;nbsp;1 =&amp;nbsp;1807 =&amp;nbsp;13&amp;nbsp;×&amp;nbsp;139.

==Properties==
The sequence is infinitely long and does not contain repeated elements. This can be proved using the method of [[Euclid]]'s proof that [[Euclid's theorem|there are infinitely many primes]]. That proof is [[Constructive proof|constructive]], and the sequence is the result of performing a version of that construction.

==Conjecture==
{{unsolved|mathematics|Does every prime number appear in the Euclid–Mullin sequence?}}
{{harvtxt|Mullin|1963}} asked whether every prime number appears in the Euclid–Mullin sequence and, if not, whether the problem of testing a given prime for membership in the sequence is [[Computable function|computable]]. {{harvs|last=Shanks|first=Daniel|authorlink=Daniel Shanks|year=1991|txt}} conjectured, on the basis of heuristic assumptions that the distribution of primes is random, that every prime does appear in the sequence.&lt;ref&gt;{{citation
 | last = Shanks | first = Daniel | authorlink = Daniel Shanks
 | journal = Bulletin of the Institute of Combinatorics and its Applications
 | mr = 1103634
 | pages = 33–36
 | title = Euclid's primes
 | volume = 1
 | year = 1991}}.&lt;/ref&gt;
However, although similar recursive sequences over other domains do not contain all primes,&lt;ref&gt;{{citation
 | last1 = Kurokawa | first1 = Nobushige
 | last2 = Satoh | first2 = Takakazu
 | issue = 2
 | journal = Experimental Mathematics
 | mr = 2433881
 | pages = 145–152
 | title = Euclid prime sequences over unique factorization domains
 | url = http://projecteuclid.org/euclid.em/1227118967
 | volume = 17
 | year = 2008}}.&lt;/ref&gt;
these problems both remain open for the original Euclid–Mullin sequence.&lt;ref&gt;{{citation
 | last = Booker | first = Andrew R.
 | issue = 6
 | journal = Journal of Integer Sequences
 | mr = 3546618
 | page = Article 16.6.4, 6
 | title = A variant of the Euclid-Mullin sequence containing every prime
 | volume = 19
 | year = 2016}}.&lt;/ref&gt; The least prime number not known to be an element of the sequence is 41.

The positions of the prime numbers from 2 to 97 are:
: 2:1, 3:2, 5:7, 7:3, 11:12, 13:5, 17:13, 19:36, 23:25, 29:33, 31:50, 37:18, 41:?, 43:4, 47:?, 53:6, 59:49, 61:42, 67:?, 71:22, 73:?, 79:?, 83:?, 89:35, 97:26 {{OEIS|id=A056756}}
where ? indicates that the position (or whether it exists at all) is unknown as of 2012.&lt;ref&gt;The listing with the question marks is given in the Extensions field of the OEIS entry, whereas the main listing stops at 33 and has no question marks.&lt;/ref&gt;

==Related sequences==
A related sequence of numbers determined by the largest prime factor of one plus the product of the previous numbers (rather than the smallest prime factor) is also known as the Euclid–Mullin sequence. It grows more quickly, but is not monotonic.&lt;ref&gt;{{citation
 | last = Naur | first = Thorkil
 | doi = 10.2307/2044665
 | issue = 1
 | journal = Proceedings of the American Mathematical Society
 | mr = 722412
 | pages = 43–44
 | title = Mullin's sequence of primes is not monotonic
 | volume = 90
 | year = 1984}}.&lt;/ref&gt; The numbers in this sequence are
:2, 3, 7, 43, 139, 50207, 340999, 2365347734339, 4680225641471129, 1368845206580129, 889340324577880670089824574922371, … {{OEIS|id=A000946}}.
Not every prime number appears in this sequence,&lt;ref&gt;{{citation
 | last1 = Cox | first1 = C. D.
 | last2 = Van der Poorten | first2 = A. J.
 | journal = Australian Mathematical Society
 | mr = 0228417
 | pages = 571–574
 | title = On a sequence of prime numbers
 | volume = 8
 | year = 1968}}&lt;/ref&gt; and the sequence of missing primes,
:5, 11, 13, 17, 19, 23, 29, 31, 37, 41, 47, 53, 59, 61, 67, 71, 73, ... {{OEIS|id= A216227}}
has been proven to be infinite.&lt;ref&gt;{{citation
 | last = Booker | first = Andrew R.
 | doi = 10.1515/integers-2012-0034
 | issue = 6
 | journal = Integers
 | mr = 3011555
 | pages = 1167–1177
 | title = On Mullin's second sequence of primes
 | volume = 12
 | year = 2012| arxiv = 1107.3318
 }}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Pollack | first1 = Paul
 | last2 = Treviño | first2 = Enrique
 | doi = 10.4169/amer.math.monthly.121.05.433
 | issue = 5
 | journal = American Mathematical Monthly
 | mr = 3193727
 | pages = 433–437
 | title = The primes that Euclid forgot
 | volume = 121
 | year = 2014}}.&lt;/ref&gt;

It is also possible to generate modified versions of the Euclid–Mullin sequence by using the same rule of choosing the smallest prime factor at each step, but beginning with a different prime than&amp;nbsp;2.&lt;ref&gt;{{citation|title=The Logic of Infinity|first=Barnaby|last=Sheppard|publisher=Cambridge University Press|year=2014|isbn=9781139952774|page=26|url=https://books.google.com/books?id=mxZEBAAAQBAJ&amp;pg=PA26}}&lt;/ref&gt;

Alternatively, taking each number to be one plus the product of the previous numbers (rather than factoring it) gives [[Sylvester's sequence]]. The sequence constructed by repeatedly appending all factors of one plus the product of the previous numbers is the same as the sequence of prime factors of Sylvester's sequence. Like the Euclid–Mullin sequence, this is a non-monotonic sequence of primes, but it is known not to include all primes.&lt;ref&gt;{{citation
 | last1 = Guy | first1 = Richard
 | last2 = Nowakowski | first2 = Richard
 | issue = 2
 | journal = Delta (Waukesha)
 | mr = 0384675
 | pages = 49–63
 | title = Discovering primes with Euclid
 | volume = 5
 | year = 1975}}.&lt;/ref&gt;

==See also==
*[[Euclid number]]

==References==
{{reflist|30em}}

==External links==
*{{MathWorld |title=Euclid–Mullin Sequence |urlname=Euclid-MullinSequence}}

{{DEFAULTSORT:Euclid-Mullin sequence}}
[[Category:Integer sequences]]
[[Category:Prime numbers]]
[[Category:Unsolved problems in mathematics]]</text>
      <sha1>puhwb3ewd4h8ld9ajtgnhnmc0xqe97k</sha1>
    </revision>
  </page>
  <page>
    <title>Gabriel's Horn</title>
    <ns>0</ns>
    <id>332256</id>
    <revision>
      <id>870782139</id>
      <parentid>870748158</parentid>
      <timestamp>2018-11-26T23:35:22Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>Undid revision 870747136 by [[Special:Contributions/2001:985:783F:1:6D0B:CBC0:CEE7:C1C4|2001:985:783F:1:6D0B:CBC0:CEE7:C1C4]] ([[User talk:2001:985:783F:1:6D0B:CBC0:CEE7:C1C4|talk]]) revert vandalism</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8040">[[File:GabrielHorn.png|thumb|3D illustration of Gabriel's horn.]]

'''Gabriel's horn'''&lt;!--see MOS:CAPS--&gt; (also called '''Torricelli's trumpet''') is a [[geometry|geometric]] figure which has [[infinity|infinite]] [[surface area]] but finite [[volume]]. The name refers to the biblical tradition identifying the [[Gabriel|Archangel Gabriel]] as the angel who blows the horn to announce [[Judgment Day]], associating the divine, or infinite, with the finite. The properties of this figure were first studied by [[Italy|Italian]] physicist and mathematician [[Evangelista Torricelli]] in the 17th century.

==Mathematical definition==
[[File:Rectangular hyperbola.svg|thumb|Graph of &lt;math&gt;x\mapsto\tfrac{1}{x}&lt;/math&gt;]]
Gabriel's horn is formed by taking the [[Graph of a function|graph]] of
:&lt;math&gt;x \mapsto \frac{1} {x},&lt;/math&gt;
with the [[Domain of a function|domain]] {{math|''x'' &gt; 0}} (thus avoiding the [[asymptote]] at {{math|1=''x'' = 0}}) and [[surface of revolution|rotating]] it in three [[dimension]]s about the {{mvar|x}}-axis. The discovery was made using [[Cavalieri's principle]] before the invention of [[calculus]], but today calculus can be used to calculate the volume and surface area of the horn between {{math|1=''x'' = 1}} and {{math|1=''x'' = ''a''}}, where {{math|''a'' &gt; 1}}. Using integration (see [[Solid of revolution]] and [[Surface of revolution]] for details), it is possible to find the volume {{mvar|V}} and the surface area {{mvar|A}}:

:&lt;math&gt;V=\pi\int\limits_1^a\left(\frac{1}{x}\right)^2\mathrm{d}x=\pi\left(1-\frac{1}{a}\right)&lt;/math&gt;

:&lt;math&gt;A=2\pi\int\limits_1^a {\frac{1}{x}}\sqrt{1+\left(-\frac{1}{x^2}\right)^2}\mathrm{d}x &gt; 2\pi\int\limits_1^a \frac{\mathrm{d}x}{x}=2\pi\ln(a).&lt;/math&gt;

{{mvar|a}} can be as large as required, but it can be seen from the equation that the volume of the part of the horn between {{math|1=''x'' = 1}} and {{math|1=''x'' = ''a''}} will never exceed {{pi}}; however, it ''will'' get closer and closer to {{pi}} as {{mvar|a}} becomes larger. Mathematically, the volume ''approaches {{pi}} as {{mvar|a}} approaches infinity''. Using the [[Limit of a function|limit]] notation of calculus:

:&lt;math&gt;\lim_{a\to\infty}V=\lim_{a\to\infty}\pi\left(1-\frac{1}{a}\right)=\pi\cdot\lim_{a\to\infty}\left(1-\frac{1}{a}\right)=\pi.&lt;/math&gt;

The surface area formula above gives a lower bound for the area as 2{{pi}} times the [[natural logarithm]] of {{mvar|a}}. There is no [[upper bound]] for the natural logarithm of {{mvar|a}} as {{mvar|a}} approaches infinity. That means, in this case, that the horn has an infinite surface area. That is to say;

:&lt;math&gt;\lim_{a\to\infty}A\ge\lim_{a\to\infty}2\pi\ln(a)=\infty.&lt;/math&gt;

==Apparent paradox==
When the properties of Gabriel's horn were discovered, the fact that the rotation of an infinitely large section of the {{mvar|xy}}-plane about the {{mvar|x}}-axis generates an object of finite volume was considered [[paradox]]ical. While the section lying in the {{mvar|xy}}-plane has an infinite area, any other section parallel to it has a finite area. Thus the volume, being calculated from the 'weighted sum' of sections, is finite.

Another approach is to treat the horn as a stack of disks with diminishing radii.  The sum of the radii produces a harmonic series that goes to infinity. However, the correct calculation is the sum of their squares. Every disk has a radius {{math|1=''r'' = {{sfrac|1|''x''}}}} and an area {{math|π''r''&lt;sup&gt;2&lt;/sup&gt;}} or {{math|{{sfrac|π|''x''&lt;sup&gt;2&lt;/sup&gt;}}}}. The series {{math|{{sfrac|1|''x''}}}} diverges but {{math|{{sfrac|1|''x''&lt;sup&gt;2&lt;/sup&gt;}}}} converges. In general, for any real {{math|''ε'' &gt; 0}}, {{math|{{sfrac|1|''x''&lt;sup&gt;1+''ε''&lt;/sup&gt;}}}} converges.

The apparent paradox formed part of a dispute over the nature of infinity involving many of the key thinkers of the time including [[Thomas Hobbes]], [[John Wallis]] and [[Galileo Galilei]].&lt;ref&gt;{{cite book|title=Nonplussed!: mathematical proof of implausible ideas|first=Julian|last=Havil|publisher=Princeton University Press|year=2007|isbn=0-691-12056-0|pages=82–91}}&lt;/ref&gt;

There is a similar phenomenon which applies to lengths and areas in the plane. The area between the curves {{math|{{sfrac|1|''x''&lt;sup&gt;2&lt;/sup&gt;}}}} and {{math|{{sfrac|-1|''x''&lt;sup&gt;2&lt;/sup&gt;}}}} from 1 to infinity is finite, but the lengths of the two curves are clearly infinite.

===Painter's paradox===
Since the horn has finite volume but infinite surface area, there is an apparent paradox that the horn could be filled with a finite quantity of paint, and yet that paint would not be sufficient to coat its inner surface. The "paradox" is resolved by realizing that a finite amount of paint can in fact coat an infinite surface area — it simply needs to get thinner at a fast enough rate. (Much like the series {{sfrac|1|2&lt;sup&gt;N&lt;/sup&gt;}} gets smaller fast enough that its sum is finite.) In the case where the horn is filled with paint, this thinning is accomplished by the increasing reduction in diameter of the throat of the horn.

==Converse==
The converse phenomenon of Gabriel's horn – a surface of revolution that has a ''finite'' surface area but an ''infinite'' volume – cannot occur:

===Theorem===
Let {{math|''f'' : [1,∞) → [0,∞)}} be a continuously differentiable function. Write {{mvar|S}} for the [[solid of revolution]] of the graph {{math|1=''y'' = ''f''(''x'')}} about the {{mvar|x}}-axis. ''If the surface area of {{mvar|S}} is finite, then so is the volume.''

===Proof===

Since the lateral surface area {{mvar|A}} is finite, the [[limit superior]]:
:&lt;math&gt;\begin{align}
\lim_{t\to\infty} \sup_{x\ge t} f(x)^2 ~-~ f(1)^2 &amp;= \limsup_{t\to\infty} \int\limits_1^t \left(f(x)^2\right)'\mathrm{d}x \\
&amp;\le\int\limits_1^{\infty} \left|\left(f(x)^2\right)'\right|\mathrm{d}x=\int\limits_1^{\infty} 2f(x)\left|f'(x)\right|\mathrm{d}x \\
&amp;\le\int\limits_1^{\infty} 2f(x)\sqrt{1+f'(x)^2}\mathrm{d}x=\frac{A}{\pi} \\
&amp;&lt;\infty. \end{align}&lt;/math&gt;
Therefore, there exists a {{math|''t''&lt;sub&gt;0&lt;/sub&gt;}} such that the [[supremum]] {{math|sup{&amp;thinsp;''f''(''x'') {{!}} ''x'' ≥ ''t''&lt;sub&gt;0&lt;/sub&gt;}}} is finite. Hence,
:{{math|1=''M'' = sup{&amp;thinsp;''f''(''x'') {{!}} ''x'' ≥ 1}}} must be finite since {{mvar|f}} is a [[continuous function]], which implies that {{mvar|f}} is bounded on the interval {{math|[1,∞)}}.
Finally, the volume:
:&lt;math&gt;\begin{align}
V &amp;=\int\limits_1^{\infty} f(x)\cdot\pi f(x)\mathrm{d}x \\
&amp;\le\int\limits_1^{\infty} \frac{M}{2}\cdot 2\pi f(x)\mathrm{d}x \\
&amp;\le\frac{M}{2}\cdot\int\limits_1^{\infty} 2\pi f(x)\sqrt{1+f'(x)^2}\mathrm{d}x =\frac{M}{2}\cdot A.\end{align}&lt;/math&gt;
Therefore: ''if the area {{mvar|A}} is finite, then the volume {{mvar|V}} must also be finite.''

== See also ==
* [[Hyperbola]]
* [[Koch snowflake]]
* [[Picard horn]]
* [[Pseudosphere]]
* [[Shape of the universe]]
* [[Surface of revolution]]
* [[Zeno's paradoxes]]

==References==
{{Reflist}}

== Further reading ==
* ''Gabriel's Other Possessions'', Melvin Royer, {{DOI|10.1080/10511970.2010.517601}}
* [https://web.archive.org/web/20161213085806/https://people.emich.edu/aross15/math121/misc/gabriels-horn-ma044.pdf ''Gabriel's Wedding Cake''], Julian F. Fleron
* [http://www.maa.org/programs/faculty-and-departments/classroom-capsules-and-notes/a-paradoxical-paint-pail ''A Paradoxical Paint Pail''], Mark Lynch
* ''Supersolids: Solids Having Finite Volume and Infinite Surfaces'', William P. Love, {{jstor|27966098}}

==External links==
*[http://planetmath.org/torricellistrumpet Torricelli's trumpet at PlanetMath]
*{{MathWorld|title=Gabriel's Horn|urlname=GabrielsHorn}}
* [http://demonstrations.wolfram.com/GabrielsHorn/ "Gabriel's Horn"] by John Snyder, the [[Wolfram Demonstrations Project]], 2007.
* [http://www.palmbeachstate.edu/honors/Documents/jeansergejoseph.pdf Gabriel's Horn: An Understanding of a Solid with Finite Volume and Infinite Surface Area] by Jean S. Joseph.

[[Category:Mathematics paradoxes]]
[[Category:Paradoxes of infinity]]
[[Category:Calculus]]
[[Category:Gabriel]]
[[Category:Surfaces]]</text>
      <sha1>nnhpqmy9as06a6xmdz10ivu1n2cmhyl</sha1>
    </revision>
  </page>
  <page>
    <title>Generalized Gauss–Bonnet theorem</title>
    <ns>0</ns>
    <id>393115</id>
    <revision>
      <id>869377639</id>
      <parentid>814024666</parentid>
      <timestamp>2018-11-18T06:07:50Z</timestamp>
      <contributor>
        <username>Pingku</username>
        <id>1323877</id>
      </contributor>
      <minor/>
      <comment>/* Further generalizations */ tweak</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4513">In [[mathematics]], the '''generalized Gauss–Bonnet theorem''' (also called '''Chern–Gauss–Bonnet theorem''' after [[Shiing-Shen Chern]], [[Carl Friedrich Gauss]] and [[Pierre Ossian Bonnet]]) presents the [[Euler characteristic]] of a closed even-dimensional Riemannian manifold as an integral of a certain polynomial derived from its curvature. It is a direct generalization of  the [[Gauss–Bonnet theorem]] (named after [[Carl Friedrich Gauss]] and [[Pierre Ossian Bonnet]]) to higher dimensions.

Let ''M'' be a [[compact space|compact]] orientable 2''n''-dimensional [[Riemannian manifold]] without boundary, and let &lt;math&gt;\Omega&lt;/math&gt; be the [[curvature form]] of the [[Levi-Civita connection]]. This means that &lt;math&gt;\Omega&lt;/math&gt; is an &lt;math&gt;\mathfrak s\mathfrak o(2n)&lt;/math&gt;-valued [[2-form]] on ''M''.  So &lt;math&gt;\Omega&lt;/math&gt; can be regarded as a skew-symmetric 2''n'' × 2''n'' matrix whose entries are 2-forms, so it is a matrix over the [[commutative ring]] &lt;math&gt;\wedge^{\hbox{even}}\,T^*M&lt;/math&gt;. One may therefore take the [[Pfaffian]] &lt;math&gt;\mbox{Pf}(\Omega)&lt;/math&gt;, which turns out to be a 2''n''-form.

The '''generalized Gauss–Bonnet theorem''' states that
:&lt;math&gt;\int_M \mbox{Pf}(\Omega)=(2\pi)^n\chi(M)\ &lt;/math&gt;
where &lt;math&gt;\chi(M)&lt;/math&gt; denotes the [[Euler characteristic]] of ''M''.

==Example: four dimensional manifolds==
In dimension &lt;math&gt;2n=4&lt;/math&gt;, for a compact oriented manifold, we get

:&lt;math&gt;\chi(M) = \frac{1}{32\pi^2} \int_M \left( |\text{Riem}|^2 - 4 |\text{Ric}|^2 + R^2 \right) d\mu  &lt;/math&gt;

where &lt;math&gt;\text{Riem}&lt;/math&gt; is the full [[Riemann curvature tensor]], &lt;math&gt;\text{Ric}&lt;/math&gt; is the [[Ricci curvature|Ricci curvature tensor]], and &lt;math&gt;R&lt;/math&gt; is the [[scalar curvature]].

==Further generalizations==
As with the two-dimensional Gauss–Bonnet theorem, there are generalizations when ''M'' is a [[manifold|manifold with boundary]].

The Gauss–Bonnet theorem can be seen as a special instance in the theory of [[characteristic classes]].  The Gauss–Bonnet integrand is the [[Euler class]].  Since it is a top-dimensional differential form, it is closed.  The naturality of the Euler class means that when you change the Riemannian metric, you stay in the same cohomology class.  That means that the integral of the Euler class remains constant as you vary the metric, and so is an invariant of smooth structure.

A far-reaching generalization of the Gauss–Bonnet theorem is the [[Atiyah–Singer index theorem|Atiyah–Singer Index Theorem]].  Let &lt;math&gt;D&lt;/math&gt; be a (weakly) [[elliptic differential operator]] between vector bundles.  That means that the [[Symbol of a differential operator|principal symbol]] is an isomorphism.  (Strong ellipticity would furthermore require the symbol to be [[positive-definite]].)  Let &lt;math&gt;D^*&lt;/math&gt; be the [[adjoint operator]].  Then the index is defined as ''dim(ker(D))-dim(ker(D*))'', and by ellipticity is always finite.  The Index Theorem states that this ''analytical index'' is constant as you vary the elliptic operator smoothly.  It is in fact equal to a ''topological index'', which can be expressed in terms of characteristic classes.  The 2-dimensional Gauss–Bonnet theorem arises as the special case where the topological index is defined in terms of [[Betti number]]s and the analytical index is defined in terms of the Gauss–Bonnet integrand.

==See also==
*[[Chern–Weil homomorphism]]
*[[Pontryagin number]]
*[[Pontryagin class]]

== References ==
* {{Citation | last1=Cycon  | first1=Hans
             | last2=Froese | first2=Richard 
             | last3=Kirsch | first3=Werner 
             | last4=Simon  | first4=Barry 
             | title=Schrödinger operators 
             | publisher=[[Springer-Verlag]] 
             | location=Berlin, New York 
             | edition=1st | isbn=3-540-16758-7 | year=1987}} Chapter 12
* {{Citation | last1=Chern | first1=Shiing-Shen
             | title=On the curvatura integra in Riemannian manifold
             | journal=[[Annals of Mathematics]]
             | volume=46|issue=4
             | year=1945 |jstor=1969203
             | pages=674–684 | doi = 10.2307/1969203 }} This is the historically first time that Chern–Gauss–Bonnet was proven without assuming the manifold to be a hypersurface. For hypersurfaces, the result had been shown first by Allendoerfer and Weil in 1940 which is cited in this paper of Chern.

{{DEFAULTSORT:Generalized Gauss-Bonnet theorem}}
[[Category:Theorems in differential geometry]]</text>
      <sha1>qhw3ri57erwudxlj68hz0wbnrw5j6os</sha1>
    </revision>
  </page>
  <page>
    <title>George Abram Miller</title>
    <ns>0</ns>
    <id>16351599</id>
    <revision>
      <id>862264464</id>
      <parentid>822156620</parentid>
      <timestamp>2018-10-03T07:18:12Z</timestamp>
      <contributor>
        <ip>195.198.246.157</ip>
      </contributor>
      <comment>Removed (unsourced!) claims about his mathematical errors, and toned down criticism of him. It seems asinine to summarize his mathematical career in a few sentences and mostly write about mistakes he made.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4339">{{Infobox scientist
| name        = George A. Miller
| image       =         &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  = {{birth date |1863|7|31|mf=y}}
| birth_place = Lynnville, [[Lehigh County, Pennsylvania]]
| death_date  = {{death date and age |1951|2|10 |1863|7|31|mf=y}}
| death_place = [[Urbana, Illinois]]
| nationality = [[United States|American]]
| fields      = [[Mathematics]]
| workplaces  = [[University of Illinois at Urbana–Champaign|University of Illinois]]
| alma_mater  = [[Cumberland University]]
| doctoral_advisor = [[Frank Nelson Cole]] &lt;!--(or  | doctoral_advisors = )--&gt;
| doctoral_students = [[Henry Louis Rietz]]
| known_for   = 
| awards      = 
}}

'''George Abram Miller''' (31 July 1863 – 10 February 1951) was an early [[group theory|group theorist]]&lt;ref&gt;G. A. Miller. On the multiple holomorphs of a group. Mathematische Annalen 1908, Volume 66, Issue 1, pp 133-142&lt;/ref&gt;&lt;ref&gt;G. A. Miller. Abstract definitions of all the substitution groups whose degrees do not exceed seven. American Journal of Mathematics, 1911.&lt;/ref&gt;. Much of his work consisted of classifying groups satisfying some condition, such as having a small number of prime divisors or small order or having a small permutation representation; although such results were considered important by his contemporaries they have mostly been rendered obsolete by modern computer algebra systems. He was president of the [[Mathematical Association of America]] 1921–1922&lt;ref&gt;[http://www.maa.org/history/presidents/miller.html MAA presidents: George Abram Miller]&lt;/ref&gt; and was an Invited Speaker of the [[International Congress of Mathematicians|ICM]] in 1924 in Toronto.&lt;ref&gt;{{cite book|author=Miller, G. A.|chapter=History of several fundamental mathematical concepts|title=''In:'' Proceedings of the International Congress of Mathematicians in Toronto, August 11–16. 1924|volume=vol. 2|pages=959–968|chapter-url=}}&lt;/ref&gt; Miller's ''Collected Works'' were edited by [[Henry Roy Brahana]] and published by [[University of Illinois Press]], the first two volumes appearing in 1935 and 1939.&lt;ref&gt;J.S. Frame (1940) [http://www.ams.org/mathscinet/pdf/256.pdf Review of ''Collected Works of George Abram Miller''] in [[Mathematical Reviews]]&lt;/ref&gt; The final three volumes were published in 1946, 1955, and 1959. His doctoral students include [[Henry Louis Rietz|H. L. Rietz]].

==Publications==
* 1892: [https://books.google.com/books?id=SZ0KAAAAYAAJ An introduction to the study of Determinants, with examples and applications].
* 1905: ''Groups of subtraction and division''.
* 1911: ''The Algebraic Equation''
* 1916: (with [[H. F. Blichfeldt]], &amp; [[L. E. Dickson]]) [http://quod.lib.umich.edu/u/umhistmath/ACM6867.0001.001?view=toc ''Theory and Application of Finite Groups''] from [[University of Michigan]] Historical Math Collection, original publisher: [[John Wiley &amp; Sons]].
* 1916: [https://books.google.com/books?id=e1UuAAAAYAAJ Historical Introduction to Mathematical Literature] from [[Cornell University]] Historical Math Monographs, original publisher [[Macmillan Publishers]].
** [[G. B. Mathews]] (1917) [http://www.nature.com/nature/journal/v98/n2464/pdf/098387a0.pdf Review: ''A Historical Introduction to the Mathematical Literature''] from [[Nature (journal)|Nature]] 98:387 (#2464)
* 1947: "An Eleventh Lesson in the History of Mathematics", [[Mathematics Magazine]] 21(1): 48-55.

==References==
{{reflist}}

==External links==
{{wikisource author}}
* [[Henry Roy Brahana]] (1957) {{Biographical Memoirs|miller-george-a}}
* [http://archives.library.illinois.edu/archon/?p=collections/controlcard&amp;id=3869 George A. Miller Papers 1895–1947, 1951] from University of Illinois Archives.
* O'Connor, J. J. and Robertson, E. F. [http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Miller.html George Abram Miller], in the MacTutor archive
* {{MathGenealogy|id=4610}}

{{Authority control}}
{{DEFAULTSORT:Miller, George Abram}}
[[Category:1863 births]]
[[Category:1951 deaths]]
[[Category:Cumberland University alumni]]
[[Category:Group theorists]]
[[Category:Historians of mathematics]]
[[Category:Muhlenberg College alumni]]
[[Category:People from Lehigh County, Pennsylvania]]
[[Category:Presidents of the Mathematical Association of America]]</text>
      <sha1>ef088dzmmkayrdvxax69kc7cxq6ch8k</sha1>
    </revision>
  </page>
  <page>
    <title>Graph homomorphism</title>
    <ns>0</ns>
    <id>676328</id>
    <revision>
      <id>846610842</id>
      <parentid>843195278</parentid>
      <timestamp>2018-06-19T20:44:04Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36392">{{Distinguish|graph homeomorphism}}
{{good article}}
[[File:Graph homomorphism into C5.svg|upright=1.2|thumb|Graph homomorphism into C5|A homomorphism from the [[flower snark]] ''J''&lt;sub&gt;5&lt;/sub&gt; into the cycle graph ''C''&lt;sub&gt;5&lt;/sub&gt;.&lt;br/&gt;It is also a retraction onto the subgraph on the central five vertices. Thus ''J''&lt;sub&gt;5&lt;/sub&gt; is in fact {{shy|homo|mor|phi|cally}} equivalent to the [[core (graph theory)|core]] ''C''&lt;sub&gt;5&lt;/sub&gt;.]]
In the [[mathematics|mathematical]] field of [[graph theory]], a '''graph homomorphism''' is a mapping between two [[graph (discrete mathematics)|graph]]s that respects their structure. More concretely, it is a function between the vertex sets of two graphs that maps adjacent [[vertex (graph theory)|vertices]] to adjacent vertices.

Homomorphisms generalize various notions of [[graph coloring]]s and allow the expression of an important class of [[constraint satisfaction problem]]s, such as certain [[Scheduling (production processes)|scheduling]] or [[frequency assignment]] problems.{{sfn|Hell|Nešetřil|2004|p=27}}
The fact that homomorphisms can be composed leads to rich algebraic structures: a [[preorder]] on graphs, a [[distributive lattice]], and a [[category (mathematics)|category]] (one for undirected graphs and one for directed graphs).{{sfn|Hell|Nešetřil|2004|p=109}}
The [[computational complexity]] of finding a homomorphism between given graphs is prohibitive in general, but a lot is known about special cases that are solvable in [[Time complexity#Polynomial time|polynomial time]]. Boundaries between tractable and intractable cases have been an active area of research.{{sfn|Hell|Nešetřil|2008}}

==Definitions==
In this article, unless stated otherwise, ''graphs'' are finite, [[Graph (discrete mathematics)#Undirected graph|undirected graphs]] with [[Loop (graph theory)|loops]] allowed, but [[multiple edges]] (parallel edges) disallowed.
A '''graph homomorphism'''&lt;ref name="intros"&gt;For introductions, see (in order of increasing length): {{harvtxt|Cameron|2006}}; {{harvtxt|Geňa|Tardif|1997}}; {{harvtxt|Hell|Nešetřil|2004}}.&lt;/ref&gt;  ''f''&amp;nbsp; from a graph ''G'' = (''V''(''G''), ''E''(''G'')) to a graph ''H'' = (''V''(''H''), ''E''(''H'')), written
: {{math|''f'' : ''G'' → ''H''}}
is a function from ''V''(''G'') to ''V''(''H'') that maps endpoints of each edge in ''G'' to endpoints of an edge in ''H''. Formally, {''u'',''v''} ∈ ''E''(''G'') implies {''f''(''u''),''f''(''v'')} ∈ ''E''(''H''), for all pairs of vertices ''u'', ''v'' in ''V''(''G'').
If there exists any homomorphism from ''G'' to ''H'', then ''G'' is said to be '''homomorphic''' to ''H'' or ''' ''H''-colorable'''. This is often denoted as just:
: {{math|''G'' → ''H'' .}}

The above definition is extended to directed graphs. Then, for a homomorphism ''f'' : ''G'' → ''H'', (''f''(''u''),''f''(''v'')) is an [[directed edge|arc]] (directed edge) of ''H'' whenever (''u'',''v'') is an arc of ''G''.

There is an [[Injective function|injective]] homomorphism from ''G'' to ''H'' (i.e., one that never maps distinct vertices to one vertex) if and only if ''G'' is a [[Glossary of graph theory terms#subgraph|subgraph]] of ''H''.
If a homomorphism ''f'' : ''G'' → ''H'' is a [[bijection]] (a one-to-one correspondence between vertices of ''G'' and ''H'') whose [[inverse function]] is also a graph homomorphism, then ''f'' is a [[graph isomorphism]].{{sfn|Geňa|Tardif|1997|loc=Observation 2.3}}

[[Covering graph|Covering maps]] are a special kind of homomorphisms that mirror the definition and many properties of [[Covering map|covering maps in topology]].{{sfn|Godsil|Royle|2001|p=115}}
They are defined as [[Surjective function|surjective]] homomorphisms (i.e., something maps to each vertex) that are also locally bijective, that is, a bijection on the [[neighbourhood (graph theory)|neighbourhood]] of each vertex.
An example is the [[bipartite double cover]], formed from a graph by splitting each vertex ''v'' into ''v&lt;sub&gt;0&lt;/sub&gt;'' and ''v&lt;sub&gt;1&lt;/sub&gt;'' and replacing each edge ''u'',''v'' with edges ''u&lt;sub&gt;0&lt;/sub&gt;'',''v&lt;sub&gt;1&lt;/sub&gt;'' and ''v&lt;sub&gt;0&lt;/sub&gt;'',''u&lt;sub&gt;1&lt;/sub&gt;''. The function mapping ''v&lt;sub&gt;0&lt;/sub&gt;'' and ''v&lt;sub&gt;1&lt;/sub&gt;'' in the cover to ''v'' in the original graph is a homomorphism and a covering map.

Graph [[Homeomorphism (graph theory)|homeomorphism]] is a different notion, not related directly to homomorphisms. Roughly speaking, it requires injectivity, but allows mapping edges to paths (not just to edges). [[Graph minor]]s are a still more relaxed notion.

===Cores and retracts===
[[File:Complete graph K7.svg|thumb|upright=0.8|right|''K''&lt;sub&gt;7&lt;/sub&gt;, the complete graph with 7 vertices, is a core.]]
{{main|Core (graph theory)}}

Two graphs ''G'' and ''H'' are '''homomorphically equivalent''' if
''G'' → ''H'' and ''H'' → ''G''.&lt;ref name="intros" /&gt;

A retraction is a homomorphism ''r'' from a graph ''G'' to a [[Glossary of graph theory#Subgraphs|subgraph]] ''H'' of ''G'' such that ''r''(''v'') = ''v'' for each vertex ''v'' of ''H''.
In this case the subgraph ''H'' is called a '''retract''' of ''G''.{{sfn|Hell|Nešetřil|2004|p=19}}

A '''core''' is a graph with no homomorphism to any proper subgraph. Equivalently, a core can be defined as a graph that does not retract to any proper subgraph.{{sfn|Hell|Nešetřil|2004|loc=Proposition 1.31}}
Every graph ''G'' is homomorphically equivalent to a unique core (up to isomorphism), called ''the core'' of ''G''.{{sfnm|1a1=Cameron|1y=2006|1loc=Proposition 2.3|2a1=Hell|2a2=Nešetřil|2y=2004|2loc=Corollary 1.32}} Notably, this is not true in general for infinite graphs.{{sfn|Hell|Nešetřil|2004|p=34}}
However, the same definitions apply to directed graphs and a directed graph is also equivalent to a unique core.
Every graph and every directed graph contains its core as a retract and as an [[induced subgraph]].{{sfn|Hell|Nešetřil|2004|p=19}}

For example, all [[complete graph]]s ''K''&lt;sub&gt;n&lt;/sub&gt; and all odd cycles ([[cycle graph]]s of odd length) are cores.
Every [[graph coloring#vertex coloring|3-colorable]] graph ''G'' that contains a triangle (that is, has the [[complete graph]] ''K''&lt;sub&gt;3&lt;/sub&gt; as a subgraph) is homomorphically equivalent to ''K''&lt;sub&gt;3&lt;/sub&gt;. This is because, on one hand, a 3-coloring of ''G'' is the same as a homomorphism ''G'' → ''K''&lt;sub&gt;3&lt;/sub&gt;, as explained below. On the other hand, every subgraph of ''G'' trivially admits a homomorphism into ''G'', implying ''K''&lt;sub&gt;3&lt;/sub&gt; → ''G''. This also means that ''K''&lt;sub&gt;3&lt;/sub&gt; is the core of any such graph ''G''. Similarly, every [[bipartite graph]] that has at least one edge is equivalent to ''K''&lt;sub&gt;2&lt;/sub&gt;.{{sfn|Cameron|2006|loc=Proposition 2.5|p=4}}

==Connection to colorings==
A [[graph coloring|''k''-coloring]], for some integer ''k'', is an assignment of one of ''k'' colors to each vertex of a graph ''G'' such that the endpoints of each edge get different colors. The ''k''-colorings of ''G'' correspond exactly to homomorphisms from ''G'' to the [[complete graph]] ''K''&lt;sub&gt;''k''&lt;/sub&gt;.{{sfnm|1a1=Cameron|1y=2006|1p=1|2a1=Hell|2a2=Nešetřil|2y=2004|2loc=Proposition 1.7}} Indeed, the vertices of ''K''&lt;sub&gt;''k''&lt;/sub&gt; correspond to the ''k'' colors, and two colors are adjacent as vertices of ''K''&lt;sub&gt;''k''&lt;/sub&gt; if and only if they are different. Hence a function defines a homomorphism to ''K''&lt;sub&gt;''k''&lt;/sub&gt; if and only if it maps adjacent vertices of ''G'' to different colors (i.e., it is a ''k''-coloring). In particular, ''G'' is ''k''-colorable if and only if it is ''K''&lt;sub&gt;''k''&lt;/sub&gt;-colorable.{{sfnm|1a1=Cameron|1y=2006|1p=1|2a1=Hell|2a2=Nešetřil|2y=2004|2loc=Proposition 1.7}}

If there are two homomorphisms ''G'' → ''H'' and ''H'' → ''K''&lt;sub&gt;''k''&lt;/sub&gt;, then their composition ''G'' → ''K''&lt;sub&gt;''k''&lt;/sub&gt; is also a homomorphism.{{sfn|Hell|Nešetřil|2004|loc=§1.7}} In other words, if a graph ''H'' can be colored with ''k'' colors, and there is a homomorphism from ''G'' to ''H'', then ''G'' can also be ''k''-colored. Therefore, ''G'' → ''H'' implies  χ(''G'') ≤  χ(''H''), where ''χ'' denotes the [[chromatic number]] of a graph (the least ''k'' for which it is ''k''-colorable).{{sfn|Hell|Nešetřil|2004|loc=Corollary 1.8}}

===Variants===
General homomorphisms can also be thought of as a kind of coloring: if the vertices of a fixed graph ''H'' are the available ''colors'' and edges of ''H'' describe which colors are ''compatible'', then an ''H''-coloring of ''G'' is an assignment of colors to vertices of ''G'' such that adjacent vertices get compatible colors.
Many notions of graph coloring fit into this pattern and can be expressed as graph homomorphisms into different families of graphs.
[[Circular coloring]]s can be defined using homomorphisms into [[circular clique|circular complete graph]]s, refining the usual notion of colorings.{{sfnm|1a1=Hell|1a2=Nešetřil|1y=2004|1loc=§6.1|2a1=Geňa|2a2=Tardif|2y=1997|2loc=§4.4}}
[[Fractional coloring|Fractional]] and [[Fractional coloring#Definitions|''b''-fold coloring]] can be defined using homomorphisms into [[Kneser graph]]s.{{sfnm|1a1=Hell|1a2=Nešetřil|1y=2004|1loc=§6.2|2a1=Geňa|2a2=Tardif|2y=1997|2loc=§4.5}}
[[T-coloring]]s correspond to homomorphisms into certain infinite graphs.{{sfn|Hell|Nešetřil|2004|loc=§6.3}}
An [[oriented coloring]] of a directed graph is a homomorphism into any [[oriented graph]].{{sfn|Hell|Nešetřil|2004|loc=§6.4}}
An [[L(2,1)-coloring]] is a homomorphism into the [[complement graph|complement]] of the [[path graph]] that is locally injective, meaning it is required to be injective on the neighbourhood of every vertex.&lt;ref&gt;{{citation|first1=J.|last1=Fiala|first2=J.|author2-link=Jan Kratochvíl|last2=Kratochvíl|title=Partial covers of graphs|year=2002|journal=Discussiones Mathematicae Graph Theory|volume=22|issue=1|pages=89–99|doi=10.7151/dmgt.1159}}&lt;/ref&gt;

===Orientations without long paths===
{{main|Gallai–Hasse–Roy–Vitaver theorem}}
Another interesting connection concerns [[Orientation (graph theory)|orientations]] of graphs.
An orientation of an undirected graph ''G'' is any directed graph obtained by choosing one of the two possible orientations for each edge.
An example of an orientation of the complete graph ''K&lt;sub&gt;k&lt;/sub&gt;'' is the transitive tournament ''{{vec|T}}&lt;sub&gt;k&lt;/sub&gt;'' with vertices 1,2,…,''k'' and arcs from ''i'' to ''j'' whenever ''i'' &lt; ''j''.
A homomorphism between orientations of graphs ''G'' and ''H'' yields a homomorphism between the undirected graphs ''G'' and ''H'', simply by disregarding the orientations.
On the other hand, given a homomorphism ''G'' → ''H'' between undirected graphs, any orientation ''{{vec|H}}'' of ''H'' can be pulled back to an orientation ''{{vec|G}}'' of ''G'' so that ''{{vec|G}}'' has a homomorphism to ''{{vec|H}}''.
Therefore, a graph ''G'' is ''k''-colorable (has a homomorphism to ''K&lt;sub&gt;k&lt;/sub&gt;'') if and only if some orientation of ''G'' has a homomorphism to ''{{vec|T}}&lt;sub&gt;k&lt;/sub&gt;''.{{sfn|Hell|Nešetřil|2004|pp=13–14}}

A folklore theorem states that for all ''k'', a directed graph ''G'' has a homomorphism to ''{{vec|T}}&lt;sub&gt;k&lt;/sub&gt;'' if and only if it admits no homomorphism from the directed path ''{{vec|P}}&lt;sub&gt;k + 1&lt;/sub&gt;''.{{sfn|Hell|Nešetřil|2004|loc=Proposition 1.20}}
Here ''{{vec|P}}&lt;sub&gt;n&lt;/sub&gt;'' is the directed graph with vertices 1, 2, …, ''n'' and edges from ''i'' to ''i'' + 1, for ''i'' = 1, 2, …, ''n'' − 1.
Therefore, a graph is ''k''-colorable if and only if it has an orientation that admits no homomorphism from ''{{vec|P}}&lt;sub&gt;k + 1&lt;/sub&gt;''.
This statement can be strengthened slightly to say that a graph is ''k''-colorable if and only if some orientation contains no directed path of length ''k'' (no ''{{vec|P}}&lt;sub&gt;k + 1&lt;/sub&gt;'' as a subgraph). 
This is the [[Gallai–Hasse–Roy–Vitaver theorem]].

==Connection to constraint satisfaction problems==
===Examples===
[[File:Graph of non-adjacent weekdays.svg|thumb|Graph ''H'' of non-consecutive weekdays, isomorphic to the [[complement graph]] of ''C''&lt;sub&gt;7&lt;/sub&gt; and to the [[circular clique]] ''K''&lt;sub&gt;7/2&lt;/sub&gt;]]
Some scheduling problems can be modeled as a question about finding graph homomorphisms.{{sfn|Cameron|2006|p=1}}{{sfn|Hell|Nešetřil|2004|loc=§1.8}} As an example, one might want to assign workshop courses to time slots in a calendar so that two courses attended by the same student are not too close to each other in time. The courses form a graph ''G'', with an edge between any two courses that are attended by some common student. The time slots form a graph ''H'', with an edge between any two slots that are distant enough in time. For instance, if one wants a cyclical, weekly schedule, such that each student gets their workshop courses on non-consecutive days, then ''H'' would be the [[complement graph]] of ''C''&lt;sub&gt;7&lt;/sub&gt;. A graph homomorphism from ''G'' to ''H'' is then a schedule assigning courses to time slots, as specified.{{sfn|Cameron|2006|p=1}} To add a requirement saying that, e.g., no single student has courses on both Friday and Monday, it suffices to remove the corresponding edge from ''H''.

A simple [[frequency allocation]] problem can be specified as follows: a number of transmitters in a [[wireless network]] must choose a frequency channel on which they will transmit data. To avoid [[Electromagnetic interference|interference]], transmitters that are geographically close should use channels with frequencies that are far apart. If this condition is approximated with a single threshold to define 'geographically close' and 'far apart', then a valid channel choice again corresponds to a graph homomorphism. It should go from the graph of transmitters ''G'', with edges between pairs that are geographically close, to the graph of channels ''H'', with edges between channels that are far apart. While this model is rather simplified, it does admit some flexibility: transmitter pairs that are not close but could interfere because of geographical features can added to the edges of ''G''. Those that do not communicate at the same time can be removed from it. Similarly, channel pairs that are far apart but exhibit [[harmonic]] interference can be removed from the edge set of ''H''.{{sfn|Hell|Nešetřil|2004|pp=30–31}}

In each case, these simplified models display many of the issues that have to be handled in practice.{{sfn|Hell|Nešetřil|2004|pp=31–32}} [[Constraint satisfaction problem]]s, which generalize graph homomorphism problems, can express various additional types of conditions (such as individual preferences, or bounds on the number of coinciding assignments). This allows the models to be made more realistic and practical.

===Formal view===
Graphs and directed graphs can be viewed as a special case of the far more general notion called relational [[Structure (mathematical logic)|structure]]s (defined as a set with a tuple of relations on it). Directed graphs are structures with a single binary relation (adjacency) on the domain (the vertex set).&lt;ref name="HN-csp"&gt;{{harvnb|Hell|Nešetřil|2004|p=28}}, note ''relational structures'' are called ''relational systems'' there.&lt;/ref&gt;{{sfn|Hell|Nešetřil|2008}} Under this view, [[Structure (mathematical logic)#Homomorphisms|homomorphisms]] of such structures are exactly graph homomorphisms.
In general, the question of finding a homomorphism from one relational structure to another is a [[constraint satisfaction problem]] (CSP).
The case of graphs gives a concrete first step that helps to understand more complicated CSPs.
Many algorithmic methods for finding graph homomorphisms, like [[backtracking]], [[constraint propagation]] and [[Local search (constraint satisfaction)|local search]], apply to all CSPs.{{sfn|Hell|Nešetřil|2008}}

For graphs ''G'' and ''H'', the question of whether ''G'' has a homomorphism to ''H'' corresponds to a CSP instance with only one kind of constraint,{{sfn|Hell|Nešetřil|2008}} as follows. The ''variables'' are the vertices of ''G'' and the ''domain'' for each variable is the vertex set of ''H''. An ''evaluation'' is a function that assigns to each variable an element of the domain, so a function ''f'' from ''V''(''G'') to ''V''(''H''). Each edge or arc (''u'',''v'') of ''G'' then corresponds to the ''constraint'' ((''u'',''v''), E(''H'')). This is a constraint expressing that the evaluation should map the arc (''u'',''v'') to a pair (''f''(''u''),''f''(''v'')) that is in the relation ''E''(''H''), that is, to an arc of ''H''. A solution to the CSP is an evaluation that respects all constraints, so it is exactly a homomorphism from ''G'' to ''H''.

==Structure of homomorphisms==
Compositions of homomorphisms are homomorphisms.{{sfn|Hell|Nešetřil|2004|loc=§1.7}} 
In particular, the relation → on graphs is transitive (and reflexive, trivially), so it is a [[preorder]] on graphs.{{sfn|Hell|Nešetřil|2004|loc=§3.1}}
Let the [[equivalence class]] of a graph ''G'' under homomorphic equivalence be [''G''].
The equivalence class can also be represented by the unique core in [''G''].
The relation → is a [[partial order]] on those equivalence classes; it defines a [[poset]].{{sfn|Hell|Nešetřil|2004|loc=Theorem 3.1}}

Let ''G'' &lt; ''H'' denote that there is a homomorphism from ''G'' to ''H'', but no homomorphism from ''H'' to ''G''.
The relation → is a [[dense order]], meaning that for all (undirected) graphs ''G'', ''H'' such that ''G'' &lt; ''H'', there is a graph ''K'' such that ''G'' &lt; ''K'' &lt; ''H'' (this holds except for the trivial cases ''G'' = ''K''&lt;sub&gt;0&lt;/sub&gt; or ''K''&lt;sub&gt;1&lt;/sub&gt;).{{sfnm|1a1=Hell|1a2=Nešetřil|1y=2004|1loc=Theorem 3.30|2a1=Geňa|2a2=Tardif|2y=1997|2loc=Theorem 2.33}}&lt;ref&gt;{{citation|first=E.|last=Welzl|title=Color-families are dense|year=1982|journal=[[Theoretical Computer Science (journal)|Theoret. Comput. Sci.]]|volume=17|pages=29–41|doi=10.1016/0304-3975(82)90129-3}}&lt;/ref&gt;
For example, between any two [[complete graph]]s (except ''K''&lt;sub&gt;0&lt;/sub&gt;,  ''K''&lt;sub&gt;1&lt;/sub&gt;) there are infinitely many [[circular clique|circular complete graphs]], corresponding to rational numbers between natural numbers.{{sfnm|1a1=Hell|1a2=Nešetřil|1y=2004|1p=192|2a1=Geňa|2a2=Tardif|2y=1997|2p=127}}

The poset of equivalence classes of graphs under homomorphisms is a [[distributive lattice]], with the [[Join and meet|join]] of  [''G''] and  [''H''] defined as (the equivalence class of) the disjoint union [''G'' ∪ ''H''], and the [[Join and meet|meet]] of [''G''] and  [''H''] defined as the [[tensor product of graphs|tensor product]] [''G'' × ''H''] (the choice of graphs ''G'' and ''H'' representing the equivalence classes [''G''] and [''H''] does not matter).&lt;ref&gt;{{harvnb|Hell|Nešetřil|2004|loc=Proposition 3.2}}, distributivity is stated in Proposition 2.4; {{harvnb|Geňa|Tardif|1997|loc=Theorem 2.37}}.&lt;/ref&gt;
The [[join-irreducible]] elements of this lattice are exactly [[Connectivity (graph theory)|connected]] graphs. This can be shown using the fact that a homomorphism maps a connected graph into one connected component of the target graph.&lt;ref&gt;{{citation
 | last1 = Kwuida | first1 = Léonard
 | last2 = Lehtonen | first2 = Erkko
 | title = On the Homomorphism Order of Labeled Posets
 | doi = 10.1007/s11083-010-9169-x
 | year = 2011
 | arxiv = 0911.0200
 | journal = [[Order (journal)|Order]]
 | volume = 28
 | issue = 2
 | pages = 251–265
 | publisher = Springer
}}&lt;/ref&gt;{{sfn|Gray|2014|loc=Lemma 3.7}}
The [[meet-irreducible]] elements of this lattice are exactly the [[Hedetniemi's conjecture#multiplicative graphs|multiplicative graphs]]. These are the graphs ''K'' such that a product ''G'' × ''H'' has a homomorphism to ''K'' only when one of ''G'' or ''H'' also does. Identifying multiplicative graphs lies at the heart of [[Hedetniemi's conjecture]].&lt;ref&gt;{{citation
 | last = Tardif | first = C.
 | title = Hedetniemi's conjecture, 40 years later
 | url = http://www.mast.queensu.ca/~ctardif/articles/gtn5406rp.pdf
 | pages = 46–57
 | volume = 54
 | journal = Graph Theory Notes of New York
 | mr = 2445666
 | year = 2008}}.&lt;/ref&gt;&lt;ref name="lattices"&gt;{{citation|first1=D.|last1=Dwight|first2=N.|last2=Sauer|title=Lattices arising in categorial investigations of Hedetniemi's conjecture|journal=[[Discrete Mathematics (journal)|Discrete Math.]]|volume=152|issue=1-3|year=1996|pages=125–139|doi=10.1016/0012-365X(94)00298-W}}&lt;/ref&gt;

Graph homomorphisms also form a [[category (mathematics)|category]], with graphs as objects and homomorphisms as arrows.{{sfn|Hell|Nešetřil|2004|p=125}}
The [[Initial and terminal objects|initial object]] is the empty graph, while the [[Initial and terminal objects|terminal object]] is the graph with one vertex and one [[Loop (graph theory)|loop]] at that vertex.
The [[tensor product of graphs]] is the [[Product (category theory)|category-theoretic product]] and 
the [[Hedetniemi's conjecture#Exponential graph|exponential graph]] is the [[exponential object]] for this category.&lt;ref name="lattices"/&gt;{{sfn|Gray|2014}}
Since these two operations are always defined, the category of graphs is a [[cartesian closed category]].
For the same reason, the lattice of equivalence classes of graphs under homomorphisms is in fact a [[Heyting algebra]].&lt;ref name="lattices"/&gt;{{sfn|Gray|2014}}

For directed graphs the same definitions apply. In particular → is a [[partial order]] on equivalence classes of directed graphs. It is distinct from the order → on equivalence classes of undirected graphs, but contains it as a suborder. This is because every undirected graph can be thought of as a directed graph where every arc (''u'',''v'') appears together with its inverse arc (''v'',''u''), and this does not change the definition of homomorphism. The order → for directed graphs is again a distributive lattice and a Heyting algebra, with join and meet operations defined as before. However, it is not dense. There is also a category with directed graphs as objects and homomorphisms as arrows, which is again a [[cartesian closed category]].{{sfn|Brown|Morris|Shrimpton|Wensley|2008}}{{sfn|Gray|2014}}

===Incomparable graphs===
[[File:Groetzsch-graph.svg|thumb|upright=0.8|right|The Grötzsch graph, incomparable to ''K''&lt;sub&gt;3&lt;/sub&gt;]]
There are many incomparable graphs with respect to the homomorphism preorder, that is, pairs of graphs such that neither admits a homomorphism into the other.{{sfn|Hell|Nešetřil|2004|p=7}}
One way to construct them is to consider the [[Girth (graph theory)|odd girth]] of a graph ''G'', the length of its shortest odd-length cycle.
The odd girth is, equivalently, the smallest [[odd number]] ''g'' for which there exists a homomorphism from the [[cycle graph]] on ''g'' vertices to ''G''. For this reason, if ''G'' → ''H'', then the odd girth of ''G'' is greater than or equal to the odd girth of ''H''.{{sfn|Geňa|Tardif|1997|loc=Observation 2.6}}

On the other hand, if ''G'' → ''H'', then the chromatic number of ''G'' is less than or equal to the chromatic number of ''H''. 
Therefore, if ''G'' has strictly larger odd girth than ''H'' and strictly larger chromatic number than ''H'', then ''G'' and ''H'' are incomparable.{{sfn|Hell|Nešetřil|2004|p=7}}
For example, the [[Grötzsch graph]] is 4-chromatic and triangle-free (it has girth 4 and odd girth 5),&lt;ref&gt;{{mathworld | title = Grötzsch Graph | urlname = GroetzschGraph}}&lt;/ref&gt; so it is incomparable to the triangle graph ''K''&lt;sub&gt;3&lt;/sub&gt;.

Examples of graphs with arbitrarily large values of odd girth and chromatic number are [[Kneser graph]]s{{sfn|Geňa|Tardif|1997|loc=Proposition 3.14}} and [[Mycielskian#Cones over graphs|generalized Mycielskians]].&lt;ref&gt;{{citation|
title=On Graphs With Strongly Independent Color-Classes|
first1=A.|last1=Gyárfás|first2=T.|last2=Jensen|first3=M.|last3=Stiebitz|
year=2004|doi=10.1002/jgt.10165|journal=[[Journal of Graph Theory|J. Graph Theory]]|volume=46|issue=1|pages=1–14}}&lt;/ref&gt;
A sequence of such graphs, with simultaneously increasing values of both parameters, gives infinitely many incomparable graphs (an [[antichain]] in the homomorphism preorder).{{sfn|Hell|Nešetřil|2004|loc=Proposition 3.4}}
Other properties, such as [[dense order|density]] of the homomorphism preorder, can be proved using such families.{{sfn|Hell|Nešetřil|2004|p=96}}
Constructions of graphs with large values of chromatic number and girth, not just odd girth, are also possible, but more complicated (see [[Girth (graph theory)#Girth and graph coloring|Girth and graph coloring]]).

Among directed graphs, it is much easier to find incomparable pairs. For example, consider the directed cycle graphs ''{{vec|C}}&lt;sub&gt;n&lt;/sub&gt;'', with vertices 1, 2, …, ''n'' and edges from ''i'' to ''i'' + 1 (for ''i'' = 1, 2, …, ''n'' − 1) and from ''n'' to 1.
There is a homomorphism from ''{{vec|C}}&lt;sub&gt;n&lt;/sub&gt;'' to ''{{vec|C}}&lt;sub&gt;k&lt;/sub&gt;'' (''n'', ''k'' ≥ 3) if and only if ''n'' is a multiple of ''k''. 
In particular, directed cycle graphs ''{{vec|C}}&lt;sub&gt;n&lt;/sub&gt;'' with ''n'' prime are all incomparable.{{sfn|Hell|Nešetřil|2004|p=35}}

==Computational complexity==
In the graph homomorphism problem, an instance is a pair of graphs (''G'',''H'') and a solution is a homomorphism from ''G'' to ''H''. The general [[decision problem]], asking whether there is any solution, is [[NP-complete]].{{sfn|Bodirsky|2007|loc=§1.3}} However, limiting allowed instances gives rise to a variety of different problems, some of which are much easier to solve. Methods that apply when restraining the left side  ''G'' are very different than for the right side ''H'', but in each case a dichotomy (a sharp boundary between easy and hard cases) is known or conjectured.

===Homomorphisms to a fixed graph===
The homomorphism problem with a fixed graph ''H'' on the right side of each instance is also called the ''H''-coloring problem. When ''H'' is the complete graph ''K''&lt;sub&gt;''k''&lt;/sub&gt;, this is the [[Graph coloring#Computational complexity|graph ''k''-coloring problem]], which is solvable in polynomial time for ''k'' = 0, 1, 2, and [[NP-complete]] otherwise.{{sfn|Hell|Nešetřil|2004|loc=§5.1}}
In particular, ''K''&lt;sub&gt;2&lt;/sub&gt;-colorability of a graph ''G'' is equivalent to ''G'' being [[Bipartite graph#Testing bipartiteness|bipartite]], which can be tested in linear time.
More generally, whenever ''H'' is a bipartite graph, ''H''-colorability is equivalent to ''K''&lt;sub&gt;2&lt;/sub&gt;-colorability (or ''K''&lt;sub&gt;''0''&lt;/sub&gt; / ''K''&lt;sub&gt;''1''&lt;/sub&gt;-colorability when ''H'' is empty/edgeless), hence equally easy to decide.{{sfn|Hell|Nešetřil|2004|loc=Proposition 5.1}}
[[Pavol Hell]] and [[Jaroslav Nešetřil]] proved that, for undirected graphs, no other case is tractable:

: '''Hell–Nešetřil theorem''' (1990): The ''H''-coloring problem is in P when ''H'' is bipartite and NP-complete otherwise.{{sfn|Hell|Nešetřil|2004|loc=§5.2}}&lt;ref&gt;{{citation|first1=Pavol|last1=Hell|author1-link=Pavol Hell|first2=Jaroslav|last2=Nešetřil|author2-link=Jaroslav Nešetřil|title=On the complexity of H-coloring|year=1990|journal=[[Journal of Combinatorial Theory, Series B|JCTB]]|volume=48|issue=1|pages=92–110|doi=10.1016/0095-8956(90)90132-J|doi-access=free}}&lt;/ref&gt;

This is also known as the ''dichotomy theorem'' for (undirected) graph homomorphisms, since it divides ''H''-coloring problems into NP-complete or P problems, with no [[NP-intermediate|intermediate]] cases.
For directed graphs, the situation is more complicated and in fact equivalent to the much more general question of characterizing the [[Complexity of constraint satisfaction|complexity of constraint satisfaction problems]].{{sfn|Hell|Nešetřil|2004|loc=§5.3}}
It turns out that ''H''-coloring problems for directed graphs are just as general and as diverse as CSPs with any other kinds of constraints.{{sfn|Hell|Nešetřil|2004|loc=Theorem 5.14}}&lt;ref name="FederVardi"&gt;{{citation|first1=Tomás|last1=Feder|first2=Moshe Y.|last2=Vardi|author2-link=Moshe Y. Vardi|title=The Computational Structure of Monotone Monadic SNP and Constraint Satisfaction: A Study through Datalog and Group Theory|year=1998|journal=[[SIAM Journal on Computing|SIAM J. Comput.]]|volume=28|issue=1|pages=57–104|doi=10.1137/S0097539794266766|url=http://theory.stanford.edu/~tomas/constraint.ps}}&lt;/ref&gt; Formally, a (finite) ''constraint language'' (or ''template'') ''Γ'' is a finite domain and a finite set of relations over this domain. CSP(''Γ'') is the constraint satisfaction problem where instances are only allowed to use constraints in ''Γ''. 
: '''Theorem''' (Feder, [[Moshe Y. Vardi|Vardi]] 1998): For every constraint language ''Γ'', the problem CSP(''Γ'') is equivalent under [[polynomial-time reduction]]s to some ''H''-coloring problem, for some directed graph ''H''.&lt;ref name="FederVardi"/&gt;

Intuitively, this means that every algorithmic technique or complexity result that applies to ''H''-coloring problems for directed graphs ''H'' applies just as well to general CSPs. In particular, one can ask whether the Hell–Nešetřil theorem can be extended to directed graphs. By the above theorem, this is equivalent to the [[Feder–Vardi conjecture]] on CSP dichotomy, which states that for every constraint language ''Γ'', CSP(''Γ'') is NP-complete or in P.{{sfn|Bodirsky|2007|loc=§1.3}}

===Homomorphisms from a fixed family of graphs===
The homomorphism problem with a single fixed graph ''G'' on left side of input instances can be solved by [[Brute-force search|brute-force]] in time |''V''(''H'')|&lt;sup&gt;O(|''V''(''G'')|)&lt;/sup&gt;, so polynomial in the size of the input graph ''H''.&lt;ref&gt;{{cite conference|title=
Tight bounds for graph homomorphism and subgraph isomorphism|authors=Cygan, M.; Fomin, F. V.; Golovnev, A.; Kulikov, A. S.; Mihajlin, I.; Pachocki, J.; Socała, A.;|conference=28th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA 2016)|publisher=[[Society for Industrial and Applied Mathematics|SIAM]]|year=2016|arxiv=1507.03738|pp=1643–1649|ISBN=978-1-611974-33-1|bibcode=2015arXiv150703738F}}&lt;/ref&gt; In other words, the problem is trivially in P for graphs ''G'' of bounded size. The interesting question is then what other properties of ''G'', beside size, make polynomial algorithms possible.

The crucial property turns out to be [[treewidth]], a measure of how tree-like the graph is. For a graph ''G'' of treewidth at most ''k'' and a graph ''H'', the homomorphism problem can be solved in time |''V''(''H'')|&lt;sup&gt;O(''k'')&lt;/sup&gt; with a standard [[dynamic programming]] approach. In fact, it is enough to assume that the core of ''G'' has treewidth at most ''k''. This holds even if the core is not known.&lt;ref&gt;{{cite conference|first1=Víctor|last1=Dalmau|first2=Phokion G.|last2=Kolaitis|first3=Moshe Y.|last3=Vardi|title=Constraint Satisfaction, Bounded Treewidth, and Finite-Variable Logics|conference=8th International Conference on Principles and Practice of Constraint Programming (CP 2002)|pages=310–326|year=2002|doi=10.1007/3-540-46135-3_21}}&lt;/ref&gt;&lt;ref name="Grohe"&gt;{{citation|first=Martin|last=Grohe|title=The complexity of homomorphism and constraint satisfaction problems seen from the other side|volume=54|issue=1|year=2007|journal=[[Journal of the ACM|J. ACM]]|doi=10.1145/1206035.1206036}}&lt;/ref&gt;

The exponent in the |''V''(''H'')|&lt;sup&gt;O(''k'')&lt;/sup&gt;-time algorithm cannot be lowered significantly: no algorithm with running time |''V''(''H'')|&lt;sup&gt;o(tw(''G'') /log tw(''G''))&lt;/sup&gt; exists, assuming the [[exponential time hypothesis]] (ETH), even if the inputs are restricted to any class of graphs of unbounded treewidth.&lt;ref name="marx"&gt;{{citation|first=Dániel|last=Marx|title=Can You Beat Treewidth?|journal=[[Theory of Computing (journal)|Theory of Computing]]|year=2010|volume=6|pages=85–112|doi=10.4086/toc.2010.v006a005|doi-access=free}}&lt;/ref&gt;
The ETH is an unproven assumption similar to [[P versus NP problem|P ≠ NP]], but stronger.
Under the same assumption, there are also essentially no other properties that can be used to get polynomial time algorithms. This is formalized as follows:
: '''Theorem''' (Grohe): For a [[Recursive set|computable]] class of graphs &lt;math&gt;\mathcal{G}&lt;/math&gt;, the homomorphism problem for instances &lt;math&gt;(G,H)&lt;/math&gt; with &lt;math&gt;G \in \mathcal{G}&lt;/math&gt; is in P if and only if graphs in &lt;math&gt;\mathcal{G}&lt;/math&gt; have cores of bounded treewidth (assuming ETH).&lt;ref name="Grohe"/&gt;

One can ask whether the problem is at least solvable in a time arbitrarily highly dependent on ''G'', but with a fixed polynomial dependency on the size of ''H''.
The answer is again positive if we limit ''G'' to a class of graphs with cores of bounded treewidth, and negative for every other class.&lt;ref name="Grohe"/&gt;
In the language of [[parameterized complexity|parameterized]] complexity, this formally states that the homomorphism problem in &lt;math&gt;\mathcal{G}&lt;/math&gt; parameterized by the size (number of edges) of ''G'' exhibits a dichotomy. It is [[fixed-parameter tractable]] if graphs in &lt;math&gt;\mathcal{G}&lt;/math&gt; have cores of bounded treewidth, and [[Parameterized complexity#W.5B1.5D|W[1]]]-complete otherwise.

The same statements hold more generally for constraint satisfaction problems (or for relational structures, in other words). The only assumption needed is that constraints can involve only a bounded number of variables (all relations are of some bounded arity, 2 in the case of graphs). The relevant parameter is then the treewidth of the [[primal constraint graph]].&lt;ref name="marx"/&gt;

== See also ==
* [[Glossary of graph theory terms]]
* [[Homomorphism]], for the same notion on different algebraic structures
* [[Graph rewriting]]
* [[Median graph]]s, definable as the retracts of [[hypercube graph|hypercube]]s

==Notes==
{{reflist}}

== References ==
=== General books and expositions ===
* {{citation|first=P.|last=Cameron|author-link=Peter Cameron (mathematician)|title=Graph Homomorphisms, Combinatorics Study Group Notes|year=2006|url=http://www.maths.qmul.ac.uk/~pjc/csgnotes/hom1.pdf}}
* {{citation |last=Hell |first=Pavol|authorlink=Pavol Hell |author2-link= Jaroslav Nešetřil|last2=Nešetřil | first2=Jaroslav |publisher=Oxford University Press |title=Graphs and Homomorphisms|series=Oxford Lecture Series in Mathematics and Its Applications|volume=28|year=2004 |isbn=0-19-852817-5|url=http://www.cs.sfu.ca/~pavol/hombook.html}}
* {{citation|first1=H.|last1=Geňa|first2=C.|last2=Tardif|contribution=Graph homomorphisms: structure and symmetry|title=Graph Symmetry: Algebraic Methods and Applications|publisher=Springer|year=1997|pages=107–166|doi=10.1007/978-94-015-8937-6_4|url=http://www.mast.queensu.ca/~ctardif/articles/ghss.pdf}}
* {{citation|first1=C.|last1=Godsil|authorlink=Chris Godsil |first2=G.|last2=Royle|author2-link=Gordon Royle|title=Algebraic Graph Theory|doi=10.1007/978-1-4613-0163-9|isbn=978-1-4613-0163-9|year=2001|publisher=Springer–Verlag New York|series=Graduate Texts in Mathematics|volume=207|chapter=6. Homomorphisms}}

=== In constraint satisfaction and universal algebra ===
* {{citation|first1=M.|last1=Bodirsky|title=Graph Homomorphisms and Universal Algebra, Course Notes |url=http://www.math.tu-dresden.de/~bodirsky/Graph-Homomorphisms.pdf |year=2007}}
* {{citation|first1=Pavol|last1=Hell|author1-link=Pavol Hell|first2=Jaroslav|last2=Nešetřil|author2-link=Jaroslav Nešetřil|title=Colouring, constraint satisfaction, and complexity|year=2008|journal=Computer Science Review|volume=2|issue=2|pages=143–163|doi=10.1016/j.cosrev.2008.10.003|url=http://www.cs.sfu.ca/~pavol/cspCCC.pdf}}

=== In lattice theory and category theory ===
* {{citation|first1=R.|last1=Brown|first2=I.|last2=Morris|first3= J.|last3=Shrimpton|first4= C. D.|last4=Wensley| title=Graphs of morphisms of graphs|journal=[[Electronic Journal of Combinatorics]]|year=2008|volume=15|issue=1|page=A1|url=http://www.combinatorics.org/ojs/index.php/eljc/article/view/v15i1a1}}
* {{citation|first=C. T.|last=Gray|title=The Digraph Lattice|year=2014|url=http://vrs.amsi.org.au/wp-content/uploads/sites/6/2014/09/CORRECTED-digraph-lattice-Gray-updated.pdf}} ([[Australian Mathematical Sciences Institute|AMSI]] [http://vrs.amsi.org.au/projects/ Vacation Research Scholarships], student research report supervised by Brian Davey and Jane Pitkethly, [[La Trobe University]]).

[[Category:Graph theory]]
[[Category:Morphisms]]</text>
      <sha1>72ppks5on4ek8fud0h68cirt7xpbng0</sha1>
    </revision>
  </page>
  <page>
    <title>Half time (electronics)</title>
    <ns>0</ns>
    <id>795837</id>
    <revision>
      <id>719664945</id>
      <parentid>499131903</parentid>
      <timestamp>2016-05-11T01:45:55Z</timestamp>
      <contributor>
        <username>Nihiltres</username>
        <id>236191</id>
      </contributor>
      <minor/>
      <comment>/* top */Simplified hatnote syntax using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="401">{{Unreferenced|date=December 2009}}
{{other uses|Half time (disambiguation)}}

[[Image:half time example picture.svg|thumb|&lt;math&gt;t_{half}\;=\;t_2\;-\;t_1\,\!&lt;/math&gt;]]
In [[signal processing]], the '''half time''' is the time it takes for the [[amplitude]] of a [[pulse (signal processing)|pulse]] to drop from 100% to 50% of its peak value.

[[Category:Signal processing]]


{{Signal-processing-stub}}</text>
      <sha1>cj7irhqfir9x6rqipi1afwxxbckap0e</sha1>
    </revision>
  </page>
  <page>
    <title>Hermite spline</title>
    <ns>0</ns>
    <id>270977</id>
    <revision>
      <id>685831249</id>
      <parentid>496610083</parentid>
      <timestamp>2015-10-15T07:17:16Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category Splines to [[:Category:Splines (mathematics)]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="354">In the [[mathematics|mathematical]] subfield of [[numerical analysis]], a '''Hermite spline''' is a [[spline curve]] where each polynomial of the spline is in [[Hermite form]].

==See also==
*[[Cubic Hermite spline]]
*[[Hermite polynomials]]
*[[Hermite interpolation]]

{{mathapplied-stub}}

[[Category:Splines (mathematics)]]

[[Category:Interpolation]]</text>
      <sha1>97bhv4ds0loygup3q9khma4kmqwgafg</sha1>
    </revision>
  </page>
  <page>
    <title>Hermite–Hadamard inequality</title>
    <ns>0</ns>
    <id>17183245</id>
    <revision>
      <id>851744377</id>
      <parentid>851690035</parentid>
      <timestamp>2018-07-24T09:40:55Z</timestamp>
      <contributor>
        <username>Timrollpickering</username>
        <id>32005</id>
      </contributor>
      <minor/>
      <comment>bypass cat redirect</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5046">{{Expert needed|Mathematics|talk=Generalisations - The concept of a sequence of iterated integrals|reason=The whole section was created by User Vezér who self-promoted in many ways his non-notable results in Wikipedia. I think this unnecessary section remained here from his work, and it is not really on the main topic of this article.|date=July 2018}}
{{distinguish|Hadamard's inequality}}

In [[mathematics]], the '''Hermite–Hadamard inequality''', named after [[Charles Hermite]] and [[Jacques Hadamard]] and sometimes also called '''Hadamard's inequality''', states that if a function ƒ&amp;nbsp;:&amp;nbsp;[''a'',&amp;nbsp;''b'']&amp;nbsp;→&amp;nbsp;'''R''' is [[convex function|convex]], then the following chain of inequalities hold:

: &lt;math&gt; f\left( \frac{a+b}{2}\right) \le \frac{1}{b - a}\int_a^b f(x)\,dx \le \frac{f(a) + f(b)}{2}. &lt;/math&gt;

== Generalisations - The concept of a sequence of iterated integrals ==

Suppose that &amp;minus;∞ &lt; ''a'' &lt; ''b'' &lt; ∞, and let ''f'':[''a'', ''b''] → '''ℝ''' be an integrable real function.
Under the above conditions the following sequence of functions is called the sequence of iterated integrals of ''f'',where ''a'' ≤ ''s'' ≤ ''b''.:

: &lt;math&gt;
\begin{align}
F^{(0)}(s) &amp; := f(s), \\
F^{(1)}(s) &amp; := \int^s_a F^{(0)}(u)du=\int^s_a f(u)du, \\
F^{(2)}(s) &amp; := \int^s_a F^{(1)}(u)du=\int^s_a \left( \int^t_a f(u)du \right ) \, dt, \\
&amp; \  \  \vdots \\
F^{(n)}(s) &amp; := \int^s_a F^{(n-1)}(u) \, du, \\
&amp; {}\  \  \vdots
\end{align}
&lt;/math&gt;

===Example 1===

Let [''a'', ''b''] = [0, 1] and ''f''(''s'') ≡ 1. Then the sequence of iterated integrals of 1 is defined on [0, 1], and

: &lt;math&gt;
\begin{align}
F^{(0)}(s) &amp; = 1, \\
F^{(1)}(s) &amp; = \int^s_0 F^{(0)}(u) \, du=\int^s_0 1 \, du=s, \\
F^{(2)}(s) &amp; = \int^s_0 F^{(1)}(u)du=\int^s_0 u \, du={s^2 \over 2}, \\
&amp; {} \ \ \vdots \\
F^{(n)}(s) &amp; := \int^s_0 {u^{n-1}\over (n-1)!}du={s^n \over n!}, \\
&amp; {} \ \ \vdots
\end{align}
&lt;/math&gt;

===Example 2===

Let [a,b] = [&amp;minus;1,1] and ''f''(''s'') ≡ 1. Then the sequence of iterated integrals of 1 is defined on [&amp;minus;1, 1], and

: &lt;math&gt;
\begin{align}
F^{(0)}(s) &amp; = 1, \\
F^{(1)}(s) &amp; = \int^s_{-1} F^{(0)}(u) \, du=\int^s_{-1} 1 du=s+1, \\
F^{(2)}(s) &amp; = \int^s_{-1} F^{(1)}(u)du=\int^s_{-1} (u+1) \, du={s^2 \over 2!}+{s \over 1!}+{1 \over 2!}={(s+1)^2 \over 2!}, \\
&amp; {} \  \vdots \\
F^{(n)}(s) &amp; = {s^n \over n!}+{s^{n-1}\over {(n-1)!1!}}+{s^{n-2} \over (n-2)!2!}+ \dots +{1 \over n!} ={(s+1)^n \over n!}, \\
&amp; {} \  \vdots
\end{align}
&lt;/math&gt;

===Example 3===

Let [''a'', ''b''] = [0, 1] and ''f''(''s'') = ''e''&lt;sup&gt;''s''&lt;/sup&gt;. Then the sequence of iterated integrals of ''f'' is defined on [0, 1], and

: &lt;math&gt;
\begin{align}
F^{(0)}(s) &amp; = e^s, \\
F^{(1)}(s) &amp; = \int^s_0 F^{(0)}(u)du=\int^s_0 e^u du=e^s-1, \\
F^{(2)}(s) &amp; = \int^s_0 F^{(1)}(u)du=\int^s_0 (e^u-1) du=e^s-s-1, \\
&amp; {} \  \vdots \\
F^{(n)}(s) &amp; = e^s-\sum_{i=0}^{n-1}\frac {s^i}{i!} \\
&amp; {}\  \vdots
\end{align}
&lt;/math&gt;

===Theorem===
Suppose that &amp;minus;∞ &lt; ''a'' &lt; ''b'' &lt; ∞, and let '''f:[a,b]→R''' be a convex function, ''a'' &lt; ''x''&lt;sub&gt;''i''&lt;/sub&gt; &lt; ''b'', ''i'' = 1, ..., ''n'', such that ''x''&lt;sub&gt;''i''&lt;/sub&gt; ≠ ''x''&lt;sub&gt;''j''&lt;/sub&gt;, if ''i'' ≠ ''j''. Then the following holds:

: &lt;math&gt;\sum_{i=1}^n \frac {F^{(n-1)}(x_i)}{\Pi_i(x_1,\dots,x_n)}\leq \frac {1}{n!} \sum_{i=1}^n f(x_i)&lt;/math&gt;

where

: &lt;math&gt; \Pi_i(x_1,\dots,x_n):=(x_i-x_1)(x_i-x_2)\cdots(x_i-x_{i-1})(x_i-x_{i+1})\cdots(x_i-x_n),\ \   i=1,\dots,n. &lt;/math&gt;

In the concave case ≤ is changed to ≥.

'''Remark 1.'''  If '''f''' is convex in the strict sense then ≤ is changed to &lt; and equality holds iff '''f''' is linear function.

'''Remark 2.''' The inequality is sharp in the following limit sense: let &lt;math&gt;\underline x =(x_1,\ldots,x_n),\ \underline \alpha = (\alpha, \ldots ,\alpha)&lt;/math&gt; and &lt;math&gt;\ a&lt;\alpha&lt;b. &lt;/math&gt; &lt;br /&gt;
Then the limit of the left side exists and

: &lt;math&gt; \lim_{\underline x \to \underline \alpha} \sum_{i=1}^n \frac{F^{(n-1)}(x_i)}{\Pi_i(x_1,\ldots,x_n)}=\lim_{\underline x \to \underline \alpha}\frac{1}{n!}\sum_{i=1}^n f(x_i)=
\frac{f(\alpha)}{(n-1)!}&lt;/math&gt;

== References ==

* [[Jacques Hadamard]], "Étude sur les propriétés des [[entire function|fonctions entières]] et en particulier d'une fonction considérée par [[Bernhard Riemann|Riemann]]", ''[[Journal de Mathématiques Pures et Appliquées]]'', volume 58, 1893, pages 171&amp;ndash;215.
* Zoltán Retkes, "An extension of the Hermite&amp;ndash;Hadamard [[Inequality (mathematics)|Inequality]]", ''[[Acta Sci. Math. (Szeged)]]'', 74 (2008), pages 95&amp;ndash;106.
* Mihály Bessenyei, "The Hermite&amp;ndash;Hadamard [[Inequality (mathematics)|Inequality]] on [[simplex|Simplices]]", ''[[American Mathematical Monthly]]'', volume 115, April 2008, pages 339&amp;ndash;345.
* Flavia-Corina Mitroi, Eleutherius Symeonidis, "The converse of the Hermite-Hadamard inequality on simplices", Expo. Math. 30 (2012), pp.&amp;nbsp;389–396. DOI:10.1016/j.exmath.2012.08.011; {{ISSN|0723-0869}}

{{DEFAULTSORT:Hermite-Hadamard inequality}}
[[Category:Inequalities]]</text>
      <sha1>homnrchdzimgchlm6qkuvzddmzmfexw</sha1>
    </revision>
  </page>
  <page>
    <title>I. J. Good</title>
    <ns>0</ns>
    <id>404404</id>
    <revision>
      <id>859872202</id>
      <parentid>859204549</parentid>
      <timestamp>2018-09-16T21:03:13Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Moving category People associated with Bletchley Park to [[:Category:Bletchley Park people]] per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 9]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20460">{{EngvarB|date=April 2015}}
{{Use dmy dates|date=April 2015}}
{{Infobox scientist
| image       = I. J. Good.jpg
| name        = I. J. Good
| birth_name  = Isadore Jacob Gudak
| birth_date  = {{Birth date|df=yes|1916|12|09}}
| birth_place = [[London]], [[England]], [[United Kingdom of Great Britain and Ireland|United Kingdom]]
| death_date  = {{Death date and age|df=yes|2009|04|05|1916|12|09}}
| death_place = [[Radford, Virginia]], [[United States]]
| doctoral_advisor = [[G. H. Hardy]]
| fields      = Statistician, [[cryptologist]]
| alma_mater  = [[Jesus College, Cambridge]]
| awards      = [[Smith's Prize]] &lt;small&gt;(1940)&lt;/small&gt;
| workplaces  = [[Trinity College, Oxford]]; [[Virginia Tech]]
}}
'''Irving John''' ("'''I. J.'''"; "'''Jack'''") '''Good''' (9 December 1916 – 5 April 2009)&lt;ref name=Passings&gt;{{cite news|title=Passings|date=13 April 2009|accessdate=13 April 2009|work=[[Los Angeles Times]]|url=http://www.latimes.com/news/obituaries/la-me-passings13-2009apr13,0,3844936.story}}&lt;/ref&gt;&lt;ref name="The Times"&gt;
The Times of 16-apr-09, http://www.timesonline.co.uk/tol/comment/obituaries/article6100314.ece {{subscription required}}&lt;/ref&gt;
was a British mathematician who worked as a [[cryptologist]] at [[Bletchley Park]] with [[Alan Turing]]. After the [[Second World War]], Good continued to work with Turing on the design of computers and [[Bayesian statistics]] at the [[University of Manchester]]. Good moved to the United States where he was professor at [[Virginia Tech]].

He was born '''Isadore Jacob Gudak''' to a [[Polish Jewish]] family in London. He later anglicised his name to Irving John Good and signed his publications "'''I. J. Good'''."

An originator of the concept now known as "[[intelligence explosion]]," Good served as consultant on supercomputers to [[Stanley Kubrick]], director of the 1968 film ''[[2001: A Space Odyssey (film)|2001: A Space Odyssey]]''.&lt;ref name = GuardianObit/&gt;

==Life==
Good was born Isadore Jacob Gudak to Polish [[Jews|Jewish]] parents in London. His father was a watchmaker, who later managed and owned a successful fashionable jewellery shop, and was also a notable Yiddish writer writing under the [[pen name]] of Moshe Oved. Good was educated at [[the Haberdashers' Aske's Boys' School]], at the time in [[Hampstead]] in northwest London, where, according to [[Dan van der Vat]], Good effortlessly outpaced the mathematics [[curriculum]].&lt;ref name = GuardianObit&gt;{{citation |url=https://www.theguardian.com/science/2009/apr/29/jack-good-codebreaker-obituary
|author=Dan van der Vat |title="Jack Good" (obituary) |publisher=''[[The Guardian]]'' |date=29 April 2009 |page= 32 |accessdate=9 October 2013}}&lt;/ref&gt;

Good studied mathematics at [[Jesus College, Cambridge]], graduating in 1938 and winning the [[Smith's Prize]] in 1940.&lt;ref&gt;[http://www.tandfonline.com/doi/pdf/10.1080/000337999296418 Appendix to Barrow-Green, June. "'A corrective to the spirit of too exclusively pure mathematics': Robert Smith (1689-1768) and his prizes at Cambridge University." Annals of science 56.3 (1999): 271-316.]&lt;/ref&gt; He did research under [[G.H. Hardy]] and [[Besicovitch]] before moving to Bletchley Park in 1941 on completing his doctorate.

===Bletchley Park===
On 27 May 1941, having just obtained his doctorate at Cambridge, Good walked into [[Hut 8]], Bletchley's facility for breaking German naval ciphers, for his first shift. This was the day that Britain's [[Royal Navy]] destroyed the {{ship|German battleship|Bismarck||6}} after it had sunk the Royal Navy's {{HMS|Hood|51|6}}. Bletchley had contributed to ''Bismarck''{{'}}s destruction by discovering, through wireless-traffic analysis, that the German flagship was sailing for [[Brest, France]], rather than [[Wilhelmshaven]], from which she had set out.&lt;ref name = GuardianObit /&gt;
Hut 8 had not, however, been able to decrypt on a current basis the 22 German Naval [[Enigma machine|Enigma]] messages that had been sent to ''Bismarck''.  The German Navy's Enigma cyphers were considerably more secure than those of the German Army or Air Force, which had been well penetrated by 1940. Naval messages were taking three to seven days to decrypt, which usually made them operationally useless for the British. This was about to change, however, with Good's help.&lt;ref name = GuardianObit /&gt;

{{blockquote|[[Alan Turing]]... had caught Good sleeping on the floor while on duty during his first night shift. At first, Turing thought Good was ill, but he was cross when Good explained that he was just taking a short nap because he was tired. For days afterwards, Turing would not deign to speak to Good, and he left the room if Good walked in. The new recruit only won Turing's respect after he solved the bigram tables problem. During a subsequent night shift, when there was no more work to be done, it dawned on Good that there might be another chink in the German indicating system. The German telegraphists had to add dummy letters to the trigrams which they selected out of the ''kenngruppenbuch''... Good wondered if their choice of dummy letters was random, or whether there was a bias towards particular letters. After inspecting some messages which had been broken, he discovered that there was a tendency to use some letters more than others. That being the case, all the codebreakers had to do, was to work back from the indicators given at the beginning of each message, and apply each bigram table in turn in the same way as [[Joan Clarke]] had done before. The bigram table which produced one of the popular dummy letters was probably the correct one. When Good mentioned his discovery to Alan Turing, Turing was very embarrassed, and said, 'I could have sworn that I tried that.' It quickly became an important part of the [[Banburismus]] procedure.

Jack Good's refusal to go on working when tired was vindicated by a subsequent incident. During another long night shift, he had been baffled by his failure to break a doubly enciphered ''Offizier'' message. This was one of the messages which was supposed to be enciphered initially with the Enigma set up in accordance with the ''Offizier'' settings, and subsequently with the general Enigma settings in place. However, while he was sleeping before returning for another shift, he dreamed that the order had been reversed; the general settings had been applied before the ''Offizier'' settings. Next day he found that the message had yet to be read, so he applied the theory which had come to him during the night. It worked; he had broken the code in his sleep.&lt;ref&gt;[[Hugh Sebag-Montefiore]], ''Enigma: The Battle for the Code'', p. 189.&lt;/ref&gt;}}

Good served with Turing for nearly two years.&lt;ref name = GuardianObit /&gt;
  
Subsequently, he worked with [[Donald Michie]] in [[Max Newman]]'s group on the [[FISH (cryptography)|Fish]] [[cipher]]s, leading to the development of the [[Colossus computer]].

Good was a member of the Bletchley Chess Club which defeated the [[Oxford University Chess Club]] 8–4 in a twelve-board team match held on 2 December 1944. Good played fourth board for Bletchley Park, with [[C.H.O'D. Alexander]], [[Harry Golombek]] and [[James Macrae Aitken]] in the top three spots.&lt;ref&gt;[http://www.chesshistory.com/winter/winter16.html#4032._The_Polish_Defence_C.N._4014 Chess Notes 4034. The code-breakers] by Edward Winter; based on a report from [[CHESS magazine|''CHESS'']], February 1945, p. 73.&lt;/ref&gt; He won his game against [[Robert Robinson (organic chemist)|Sir Robert Robinson]].&lt;ref&gt;[https://books.google.com/books?id=AwsuAQAAIAAJ&amp;dq=%22Robert+Robinson%22+%22I.+J.+Good%22+chess&amp;focus=searchwithinvolume&amp;q=%22Robert+Robinson%22+ ''British Chess magazine'', February 1945, p36]&lt;/ref&gt;

===Postwar work===
In 1947 Newman invited Good to join him and Turing at [[Manchester University]]. There for three years Good lectured in mathematics and researched computers, including the [[Manchester Mark 1]].&lt;ref name = GuardianObit /&gt;

In 1948 Good was recruited by the Government Communications Headquarters ([[GCHQ]]), successor to [[Bletchley Park]]. He remained there until 1959, while also taking up a brief associate professorship at [[Princeton University]] and a short consultancy with [[IBM]].&lt;ref name = GuardianObit /&gt;

From 1959 until he moved to the US in 1967, Good held government-funded positions and from 1964 a senior research fellowship at [[Trinity College, Oxford]], and the [[Atlas Computer Laboratory]], where he continued his interests in computing, statistics and chess.&lt;ref name="The Times"/&gt; He later left Oxford, declaring it "a little stiff".

===United States===
In 1967 Good moved to the United States, where he was appointed a research professor of statistics at [[Virginia Polytechnic Institute and State University]]. In 1969 he was appointed a University Distinguished Professor at Virginia Tech, and in 1994 Emeritus University Distinguished Professor.&lt;ref&gt;{{Citation | title = Good, Irving John | work = CV | publisher = [[Virginia Polytechnic Institute and State University]] | date =  6 April 2009 | url = https://www.vtnews.vt.edu/articles/2009/04/2009-276.html | accessdate = 9 April 2017 }}&lt;/ref&gt;
In 1973 he was elected as a [[Fellow of the American Statistical Association]].&lt;ref&gt;[http://www.amstat.org/awards/fellowslist.cfm View/Search Fellows of the ASA], accessed 2016-08-20.&lt;/ref&gt;

He later said about his arrival in Virginia (from Britain) in 1967 to start teaching at VPI, where he taught from 1967 to 1994:

{{quote|I arrived in Blacksburg in the seventh hour of the seventh day of the seventh month of the year seven in the seventh decade, and I was put in Apartment 7 of Block 7...all by chance.&lt;ref&gt;{{citation|title=The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century|first=David|last=Salsburg|publisher=Macmillan|year=2002|isbn=9781466801783|page=222|url=https://books.google.com/books?id=VCw_RxBrJc8C&amp;pg=PA222}}.&lt;/ref&gt;}}

==Research and publications==
Good's published work ran to over three million words.&lt;ref name = GuardianObit /&gt;
He was known for his work on [[Bayesian statistics]]. He published a number of books on [[probability theory]]. In 1958 he published an early version of what later became known as the [[fast Fourier transform]]&lt;ref&gt;"The interaction algorithm and practical fourier analysis," [[Journal of the Royal Statistical Society]] Series B, vol. 20, no. 2, pp. 361–372, 1958, addendum: ibid. 22 (2), 373–375 (1960).&lt;/ref&gt;&lt;!--https://ccrma.stanford.edu/~jos/st/Bibliography.html--&gt; but it did not became widely known. He played [[chess]] to county standard and helped popularise [[Go (board game)|Go]], an Asian boardgame, through a 1965 article in ''[[New Scientist]]'' (he had learned the rules from Alan Turing).&lt;ref&gt;[http://www.chilton-computing.org.uk/acl/literature/reports/p019.htm "The mystery of Go"], ''The New Scientist'', January 1965, pp. 172–74.&lt;/ref&gt; In 1965 he originated the concept now known as "[[intelligence explosion]]" or the "[[technological singularity]], which anticipates the eventual advent of [[superhuman intelligence]]:

{{quote|Let an ultraintelligent machine be defined as a machine that can far surpass all the intellectual activities of any man however clever. Since the design of machines is one of these intellectual activities, an ultraintelligent machine could design even better machines; there would then unquestionably be an 'intelligence explosion,' and the intelligence of man would be left far behind. Thus the first ultraintelligent machine is the last invention that man need ever make, provided that the machine is docile enough to tell us how to keep it under control.&lt;ref&gt;I.J. Good, [http://commonsenseatheism.com/wp-content/uploads/2011/02/Good-Speculations-Concerning-the-First-Ultraintelligent-Machine.pdf "Speculations Concerning the First Ultraintelligent Machine"] {{webarchive|url=https://web.archive.org/web/20111128085512/http://commonsenseatheism.com/wp-content/uploads/2011/02/Good-Speculations-Concerning-the-First-Ultraintelligent-Machine.pdf |date=28 November 2011 }} ([http://www.acceleratingfuture.com/pages/ultraintelligentmachine.html HTML]), ''Advances in Computers'', vol. 6, 1965.&lt;/ref&gt;}}

Good's authorship of treatises such as "Speculations Concerning the First Ultraintelligent Machine"&lt;ref&gt;{{citation|title=Speculations Concerning the First Ultraintelligent Machine|year=1965|url=https://exhibits.stanford.edu/feigenbaum/catalog/gz727rg3869|first=I.J.|last=Good}}.&lt;/ref&gt; and "Logic of Man and Machine"&lt;ref&gt;{{Cite magazine|title=Logic of Man and Machine|date=15 April 1965|url=https://books.google.com/books?id=uPSQlgpXeawC&amp;lpg=PP1&amp;pg=PA182#v=onepage&amp;q&amp;f=false|magazine=The New Scientist|pp=182–83|first=I.J.|last=Good}}&lt;/ref&gt; (both 1965) made him the obvious person for [[Stanley Kubrick]] to consult when filming ''[[2001: A Space Odyssey (film)|2001: A Space Odyssey]]'' (1968), one of whose principal characters was the paranoid [[HAL 9000]] [[supercomputer]].&lt;ref name = GuardianObit /&gt; In 1995 Good was elected a member of the [[Academy of Motion Picture Arts and Sciences]].&lt;ref name="The Times"/&gt;

According to his assistant, Leslie Pendleton, in 1998 Good wrote in an unpublished autobiographical statement that he suspected an ultraintelligent machine would lead to [[Existential risk from advanced artificial intelligence|the extinction of man]].&lt;ref&gt;{{cite book|last1=Barrat|first1=James|title=Our final invention : artificial intelligence and the end of the human era|date=2013|publisher=St. Martin's Press|location=New York|isbn=9780312622374|edition=First|quote=In the bio, playfully written in the third person, Good summarized his life's milestones, including a probably never before seen account of his work at Bletchley Park with Turing. But here's what he wrote in 1998 about the first superintelligence, and his late-in-the-game U-turn: [The paper] 'Speculations Concerning the First Ultra-intelligent Machine' (1965) . . . began: 'The survival of man depends on the early construction of an ultra-intelligent machine'. Those were his [Good's] words during the Cold War, and he now suspects that 'survival' should be replaced by 'extinction'. He thinks that, because of international competition, we cannot prevent the machines from taking over. He thinks we are lemmings. He said also that 'probably Man will construct the deus ex machina in his own image.'}}&lt;/ref&gt;

==Personality==
The slender, bushy-moustached Good was blessed with a [[Humour|sense of humour]]. He published a paper under the names IJ Good and "K Caj Doog"—the latter, his own nickname spelled backwards. In a 1988 paper,&lt;ref&gt;I.J. Good, [https://www.jstor.org/stable/2245388 "The Interface Between Statistics and Philosophy of Science,"] ''Statistical Science'', vol. 3, no. 4, 1988, pp. 386–97.&lt;/ref&gt; he introduced its subject by saying, "Many people have contributed to this topic but I shall mainly review the writings of I. J. Good because I have read them all carefully." In [[Virginia]] he chose, as his [[Vanity plate|vanity licence plate]], "007IJG," in subtle reference to his [[Second World War]] [[Intelligence (information gathering)|intelligence]] work.&lt;ref name = GuardianObit /&gt;

Good never married.&lt;ref&gt;http://www.vtnews.vt.edu/story.php?relyear=2009&amp;itemno=276&lt;/ref&gt; After going through ten assistants in his first thirteen years at Virginia, he hired Leslie Pendleton, who proved up to the task of managing his quirks. He wanted to marry her, but she refused. Although there was speculation, they were never more than friends, but she was his assistant, companion, and friend for the rest of his life.&lt;ref&gt;http://io9.com/why-a-superintelligent-machine-may-be-the-last-thing-we-1440091472&lt;/ref&gt;

==Death==
Good died on 5 April 2009 of [[natural causes]] in [[Radford, Virginia|Radford]], Virginia, aged 92.&lt;ref&gt;[http://www.vtnews.vt.edu/story.php?relyear=2009&amp;itemno=276 Virginia Tech news release of Good's death.]&lt;/ref&gt;

==Books==
* {{Citation | last = Good | first = I.J. | author-link = I. J. Good | title = Probability and the Weighing of Evidence | place = London | publisher = Griffin | year =1950 | asin = B0000CHL1R}}
* {{Citation | last = Good | first = Irving John | author-link = I. J. Good | title = The estimation of probabilities: An essay on modern Bayesian methods | publisher = M.I.T. Press | series = Research monograph no. 30 | year = 1965 | asin = B0006BMRMM }}
* {{Citation | last = Good | first = Irving John | author-link = I. J. Good | title = The scientist speculates: An anthology of partly-baked ideas | publisher = Capricorn Books | year = 1965 }}
* {{Citation | last = Osteyee | first = David Bridston | last2 = Good | first2 = Irving John | author2-link = I. J. Good | title = Information, Weight of Evidence: The Singularity Between Probability Measures and Signal Detection | publisher = Springer | year = 1974 | isbn = 978-3-540-06726-9 }}
* {{Citation | last = Good | first = Irving John | author-link = I. J. Good | title = Good Thinking: The Foundations of Probability and Its Applications | publisher = of Minnesota Press (Republished by Dover) | origyear = 1983 | year = 2009 | isbn = 978-0486474380 }}

==See also==
*[[Good–Turing frequency estimation]]
*[[Cryptanalysis of the Enigma]]
* [[MacMahon Master theorem]]

==Notes==
{{reflist|30em}}

==References==
* Dan van der Vat, "Jack Good" (obituary), ''[[The Guardian]]'', 29 April 2009, p.&amp;nbsp;32.
* [[Hugh Sebag-Montefiore]], ''Enigma: The Battle for the Code'', London, Weidenfeld &amp; Nicolson, 2000, {{isbn|978-0-297-84251-4}}.

==External links==
{{Wikiquote}}
* {{MathGenealogy|id=72215}}
* [https://web.archive.org/web/20160605065337/http://www.stat.vt.edu/Good/Good-IJ.html Good's web page] at Virginia Tech
* [https://web.archive.org/web/20100626183616/http://www.web-e.stat.vt.edu/holtzman/IJGood/IJGoodsShorterPubList,Aug19,2003.pdf Bibliography ("Shorter Publications List", running to 2300 items) (PDF)]
* [http://ei.cs.vt.edu/~history/Good.html Biography] focusing on Good's role in the history of computing
* [http://projecteuclid.org/Dienst/UI/1.0/Summarize/euclid.ss/1032209661 Project Euclid] An interview with Good can be downloaded from here
* [http://imagebase.lib.vt.edu/browse.php?folio_ID=/va/fac/good VT Image Base] Photographs
* [http://www.vtnews.vt.edu/story.php?relyear=2009&amp;itemno=276 Obituary], Virginia Tech, 6 April 2009
* [https://www.telegraph.co.uk/news/obituaries/military-obituaries/special-forces-obituaries/5132599/Professor-Jack-Good.html Obituary], ''[[Daily Telegraph]]'', 10 April 2009
* [http://www.timesonline.co.uk/tol/comment/obituaries/article6100314.ece Obituary], ''[[The Times]]'', 16 April 2009
* [https://www.independent.co.uk/news/obituaries/jack-good-cryptographer-whose-work-with-alan-turing-at-bletchley-park-was-crucial-to-the-war-effort-1684506.html Obituary], ''[[The Independent]]'', 14 May 2009
* [http://www.math.rutgers.edu/~zeilberg/mamarim/mamarimhtml/jack.html Eulogy] Mathematical eulogy (with [[Maple (software)|Maple]] code) by [[Doron Zeilberger]], 2 December 2009

{{Authority control}}

{{DEFAULTSORT:Good, I. J.}}
[[Category:1916 births]]
[[Category:2009 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:20th-century American philosophers]]
[[Category:Alan Turing]]
[[Category:Alumni of Jesus College, Cambridge]]
[[Category:American people of British-Jewish descent]]
[[Category:American people of Polish-Jewish descent]]
[[Category:American statisticians]]
[[Category:Artificial intelligence researchers]]
[[Category:Bayesian statisticians]]
[[Category:British cryptographers]]
[[Category:British information theorists]]
[[Category:British Jews]]
[[Category:British people of Polish-Jewish descent]]
[[Category:Disease-related deaths in Virginia]]
[[Category:English emigrants to the United States]]
[[Category:English Jews]]
[[Category:English mathematicians]]
[[Category:English statisticians]]
[[Category:Fellows of the American Statistical Association]]
[[Category:Government Communications Headquarters people]]
[[Category:Modern cryptographers]]
[[Category:Bletchley Park people]]
[[Category:People educated at Haberdashers' Aske's Boys' School]]
[[Category:People from Hampstead]]
[[Category:People from Radford, Virginia]]
[[Category:Singularitarianism]]
[[Category:Theoretical computer scientists]]
[[Category:Amateur chess players]]
[[Category:Foreign Office personnel of World War II]]</text>
      <sha1>g2ncrmeej1g5jjm8ndpbawu0azsa58d</sha1>
    </revision>
  </page>
  <page>
    <title>Icosahedral number</title>
    <ns>0</ns>
    <id>39530422</id>
    <revision>
      <id>739429822</id>
      <parentid>684149214</parentid>
      <timestamp>2016-09-14T16:56:06Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <minor/>
      <comment>[[User:Green Cardamom/WaybackMedic 2|WaybackMedic 2]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="675">An '''icosahedral number''' is a [[figurate number]] that represents an [[icosahedron]]. The ''n''th icosahedral number is given by the formula

:&lt;math&gt;{n(5n^2-5n+2) \over 2}&lt;/math&gt;

The first such numbers are 1, 12, 48, 124, 255, 456, 742, 1128, 1629, 2260, 3036, 3972, 5083, … {{OEIS|id=A006564}}.

==References==
{{Citation | last = Kim | first = Hyun Kwang | title = On Regular Polytope Numbers | url = http://com2mac.postech.ac.kr/papers/2001/01-22.pdf | archiveurl = https://web.archive.org/web/20100307080303/http://com2mac.postech.ac.kr/papers/2001/01-22.pdf | archivedate = 2010-03-07}}

{{Classes of natural numbers}}

[[Category:Figurate numbers]]


{{Num-stub}}</text>
      <sha1>kk7ry92k1djlmbkoonne0nismuq95zc</sha1>
    </revision>
  </page>
  <page>
    <title>Join-based tree algorithms</title>
    <ns>0</ns>
    <id>58462412</id>
    <revision>
      <id>860571675</id>
      <parentid>859392018</parentid>
      <timestamp>2018-09-21T15:51:06Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>Link to DAB page repaired</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18414">In [[computer science]], '''join-based tree algorithms''' are a class of algorithms for [[self-balancing binary search tree]]s.
The algorithmic framework is based on a single operation ''join''.&lt;ref name="join-based"&gt;{{citation
 | last1 = Blelloch | first1 = Guy E.
 | last2 = Ferizovic | first2 = Daniel
 | last3 = Sun | first3 = Yihan
 | contribution = Just Join for Parallel Ordered Sets
 | doi = 10.1145/2935764.2935768
 | isbn = 978-1-4503-4210-0
 | pages = 253–264
 | publisher = ACM
 | title = Symposium on Parallel Algorithms and Architectures, Proc. of 28th ACM Symp. Parallel Algorithms and Architectures (SPAA 2016)
 | year = 2016 | url = https://arxiv.org/pdf/1602.02120}}&lt;/ref&gt; Under this framework, the ''join'' operation captures all balancing criteria of different balancing schemes, and all other functions ''join'' have generic implementation across different balancing schemes. The ''join-based algorithms'' can be applied to at least four balancing schemes: [[AVL tree]]s, [[red-black tree]]s, [[weight-balanced tree]]s and [[treap]]s.

The ''join''&lt;math&gt;(L,k,R)&lt;/math&gt; operation takes as input two binary balanced trees &lt;math&gt;L&lt;/math&gt; and &lt;math&gt;R&lt;/math&gt; of the same balancing scheme, and a key &lt;math&gt;k&lt;/math&gt;, and outputs a new balanced binary tree &lt;math&gt;t&lt;/math&gt; whose [[Tree_traversal#In-order_(LNR)|in-order traversal]] is the in-order traversal of &lt;math&gt;L&lt;/math&gt;, then &lt;math&gt;k&lt;/math&gt; then the in-order traversal of &lt;math&gt;R&lt;/math&gt;. In particular, if the trees are [[Search tree|search trees]], which means that the in-order of the trees maintain a [[total ordering]] on keys, it must satisfy the condition that all keys in &lt;math&gt;L&lt;/math&gt; are smaller than &lt;math&gt;k&lt;/math&gt; and all keys in &lt;math&gt;R&lt;/math&gt; are greater than &lt;math&gt;k&lt;/math&gt;.

==History==
The ''join'' operation was first defined by Tarjan &lt;ref name="join-tarjan"&gt;{{citation
 | last1 = Tarjan | first1 = Robert Endre
 | contribution = Data structures and network algorithms
 | title = Data structures and network algorithms
 | pages = 45-56
 | publisher = Siam
 | year = 1983}}&lt;/ref&gt; on [[red-black tree]]s, which runs in worst-case logarithmic time. Later Sleator and Tarjan &lt;ref name="splaytree"&gt;{{citation
 | last1 = Sleator | first1 = Daniel Dominic
 | last2 = Tarjan | first2 = Robert Endre
 | contribution = Self-adjusting binary search trees
 | publisher = Siam
 | title = Journal of the ACM (JACM)
 | year = 1985}} &lt;/ref&gt; described an ''join'' algorithm for [[splay tree|splay trees]] which runs in amortized logarithmic time. Later Adams &lt;ref name="adams"&gt;{{citation
 | last1 = Adams | first1 = Stephen
 | contribution = Implementing sets efficiently in a functional language
 | title = Implementing sets efficiently in a functional language
 | publisher = Citeseer
 | year = 1992 | url = http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.501.8427}}.&lt;/ref&gt; extended ''join'' to [[weight-balanced tree]]s and used it for fast set-set functions including [[Union (set theory)|union]], [[Intersection (set theory)|intersection]] and [[set difference]]. In 1998, Blelloch and Reid-Miller extended ''join'' on [[treap]]s, and proved the bound of the set functions to be &lt;math&gt;O(m\log (1+\frac{n}{m}))&lt;/math&gt; for two trees of size &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n(\ge m)&lt;/math&gt;, which is optimal in the comparison model. They also brought up parallelism in Adams' algorithm by using a [[Divide and conquer algorithm|divide-and-conquer scheme]]. In 2016, Blelloch et al. formally proposed the join-based algorithms, and formalized the ''join'' algorithm for four different balancing schemes: [[AVL tree]]s, [[red-black tree]]s, [[weight-balanced tree]]s and [[treap]]s. In the same work they proved that Adams' algorithms on union, intersection and difference are work-optimal on all the four balancing schemes.

==Join Algorithms==
The function ''join''&lt;math&gt;(t_1,k,t_2)&lt;/math&gt; considers rebalancing the tree, and thus depends on the input balancing scheme. If the two trees are balanced, ''join'' simply creates a new node with left subtree {{math|''t''&lt;sub&gt;1&lt;/sub&gt;}}, root {{mvar|k}} and right subtree {{math|''t''&lt;sub&gt;2&lt;/sub&gt;}}. Suppose that {{math|''t''&lt;sub&gt;1&lt;/sub&gt;}} is heavier (this "heavier" depends on the balancing scheme) than {{math|''t''&lt;sub&gt;2&lt;/sub&gt;}} (the other case is symmetric). ''Join'' follows the right spine of {{math|''t''&lt;sub&gt;1&lt;/sub&gt;}} until a node {{mvar|c}} which is balanced with {{math|''t''&lt;sub&gt;2&lt;/sub&gt;}}. At this point a new node with left child {{mvar|c}}, root {{mvar| k}} and right child {{math|''t''&lt;sub&gt;2&lt;/sub&gt;}} is created to replace c. The new node may invalidate the balancing invariant. This can be fixed with rotations.

The following is the ''join'' algorithms on different balancing schemes.

The [[AVL tree#Set operations and bulk operations|''join'' algorithm for AVL trees]]:

 '''function''' joinRightAVL(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     (l, k', c) = expose(T&lt;sub&gt;L&lt;/sub&gt;)
     '''if''' (h(c) &lt; h(T&lt;sub&gt;R&lt;/sub&gt;) + 1)
        T'=Node(c, k, T&lt;sub&gt;R&lt;/sub&gt;)
        if (h(T') &lt;= h(l) + 1) then '''return''' Node(l, k', T')
        else '''return''' rotateLeft(Node(l, k', rotateRight(T')))
     '''else''' 
         T' = joinRightAVL(c, k, T&lt;sub&gt;R&lt;/sub&gt;)
         T'' = Node(l, k', T')
         '''if''' (h(T&lt;sub&gt;L&lt;/sub&gt;) &gt; h(T&lt;sub&gt;R&lt;/sub&gt;) + 1) '''return''' T''
         '''else''' '''return''' rotateLeft(T'')
 '''function''' joinLeftAVL(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
   /* symmetric to joinRightAVL */
 '''function''' join(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     '''if''' (h(T&lt;sub&gt;L&lt;/sub&gt;) &gt; h(T&lt;sub&gt;R&lt;/sub&gt;) + 1) '''return''' joinRightAVL(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     '''if''' (h(T&lt;sub&gt;R&lt;/sub&gt;) &gt; h(T&lt;sub&gt;L&lt;/sub&gt;) + 1) '''return''' joinLeftAVL(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     '''return''' Node(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)

Here &lt;math&gt;h(v)&lt;/math&gt; of a node &lt;math&gt;v&lt;/math&gt; the height of &lt;math&gt;v&lt;/math&gt;. expose(v)=(l,k,r) means to extract a tree node &lt;math&gt;v&lt;/math&gt;'s left child &lt;math&gt;l&lt;/math&gt;, the key of the node &lt;math&gt;k&lt;/math&gt;, and the right child &lt;math&gt;r&lt;/math&gt;. Node(l,k,r) means to create a node of left child &lt;math&gt;l&lt;/math&gt;, key &lt;math&gt;k&lt;/math&gt;, and right child &lt;math&gt;r&lt;/math&gt;.

The [[Red-black tree#Set operations and bulk operations|''join'' algorithm for red-black trees]]:

 '''function''' joinRightRB(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     '''if''' r(T&lt;sub&gt;L&lt;/sub&gt;) = ⌊r(T&lt;sub&gt;L&lt;/sub&gt;)/2⌋ × 2:
         '''return''' Node(T&lt;sub&gt;L&lt;/sub&gt;, ⟨k, red⟩, T&lt;sub&gt;R&lt;/sub&gt;)
     '''else''' 
         (L', ⟨k', c'⟩, R') = expose(T&lt;sub&gt;L&lt;/sub&gt;)
         T' = Node(L', ⟨k', c'⟩, joinRightRB(R', k, T&lt;sub&gt;R&lt;/sub&gt;)
         '''if''' (c' = black) and (T'.right.color = T'.right.right.color = red):
              T'.right.right.color = black
              '''return''' rotateLeft(T')
         '''else''' return T'
 '''function''' joinLeftRB(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
   /* symmetric to joinRightRB */
 '''function''' join(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     '''if''' ⌊r(T&lt;sub&gt;L&lt;/sub&gt;)/2⌋ &gt; ⌊r(T&lt;sub&gt;R&lt;/sub&gt;)/2⌋ × 2:
        T' = joinRightRB(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
        '''if''' (T'.color = red) and (T'.right.color = red):
           T'.color = black
        return T'
     '''else if''' ⌊r(T&lt;sub&gt;L&lt;/sub&gt;)/2⌋ &gt; ⌊r(T&lt;sub&gt;L&lt;/sub&gt;)/2⌋ × 2
        /* symmetric */
     '''else if''' (T&lt;sub&gt;L&lt;/sub&gt;.color = black) and (T&lt;sub&gt;R&lt;/sub&gt; = black)
        Node(T&lt;sub&gt;L&lt;/sub&gt;, ⟨k, red⟩, T&lt;sub&gt;R&lt;/sub&gt;)
     '''else'''
        Node(T&lt;sub&gt;L&lt;/sub&gt;, ⟨k, black⟩, T&lt;sub&gt;R&lt;/sub&gt;)

Here &lt;math&gt;r(v)&lt;/math&gt; of a node &lt;math&gt;v&lt;/math&gt; means twice the black height of a black node, and the twice the black height of a red node. expose(v)=(l,⟨k,c⟩,r) means to extract a tree node &lt;math&gt;v&lt;/math&gt;'s left child &lt;math&gt;l&lt;/math&gt;, the key of the node &lt;math&gt;k&lt;/math&gt;, the color of the node &lt;math&gt;c&lt;/math&gt; and the right child &lt;math&gt;r&lt;/math&gt;. Node(l,⟨k,c⟩,r) means to create a node of left child &lt;math&gt;l&lt;/math&gt;, key &lt;math&gt;k&lt;/math&gt;, color &lt;math&gt;c&lt;/math&gt; and right child &lt;math&gt;r&lt;/math&gt;.

The [[Weight-balanced tree#Set operations and bulk operations|''join'' algorithm for weight-balanced trees]]:

 '''function''' joinRightWB(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
    (l, k', c)=expose(T&lt;sub&gt;L&lt;/sub&gt;)
     '''if''' balance(|T&lt;sub&gt;L&lt;/sub&gt;|, |T&lt;sub&gt;L&lt;/sub&gt;|) '''return''' Node(T&lt;sub&gt;L&lt;/sub&gt;,k,T&lt;sub&gt;R&lt;/sub&gt;)
     '''else''' 
         T' = joinRightWB(c, k, T&lt;sub&gt;R&lt;/sub&gt;)
         (l&lt;sub&gt;1&lt;/sub&gt;, k&lt;sub&gt;1&lt;/sub&gt;, r&lt;sub&gt;1&lt;/sub&gt;) = expose(T')
         '''if''' (balance(l, T')) '''return''' Node(l, k', T')
         '''else if''' (balance(|l|, |l&lt;sub&gt;1&lt;/sub&gt;|) and balance(|l|+|l&lt;sub&gt;1&lt;/sub&gt;|, |r&lt;sub&gt;1&lt;/sub&gt;|))
              '''return''' rotateLeft(Node(l, k', T'))
         '''else''' return rotateLeft(Node(l, k', rotateRight(T'))
 '''function''' joinLeftWB(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
   /* symmetric to joinRightWB */
 '''function''' join(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     '''if''' (heavy(T&lt;sub&gt;L&lt;/sub&gt;, T&lt;sub&gt;R&lt;/sub&gt;)) return joinRightWB(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     '''if''' (heavy(T&lt;sub&gt;R&lt;/sub&gt;, T&lt;sub&gt;L&lt;/sub&gt;)) return joinLeftWB(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)
     Node(T&lt;sub&gt;L&lt;/sub&gt;, k, T&lt;sub&gt;R&lt;/sub&gt;)

Here balance&lt;math&gt;(x,y)&lt;/math&gt; means two weigthts &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are balanced. expose(v)=(l,k,r) means to extract a tree node &lt;math&gt;v&lt;/math&gt;'s left child &lt;math&gt;l&lt;/math&gt;, the key of the node &lt;math&gt;k&lt;/math&gt; and the right child &lt;math&gt;r&lt;/math&gt;. Node(l,k,r) means to create a node of left child &lt;math&gt;l&lt;/math&gt;, key &lt;math&gt;k&lt;/math&gt; and right child &lt;math&gt;r&lt;/math&gt;.

==Join-based Algorithms==
In the following, expose(v)=(l,k,r) means to extract a tree node &lt;math&gt;v&lt;/math&gt;'s left child &lt;math&gt;l&lt;/math&gt;, the key of the node &lt;math&gt;k&lt;/math&gt; and the right child &lt;math&gt;r&lt;/math&gt;. Node(l,k,r) means to create a node of left child &lt;math&gt;l&lt;/math&gt;, key &lt;math&gt;k&lt;/math&gt; and right child &lt;math&gt;r&lt;/math&gt;. right(&lt;math&gt;v&lt;/math&gt;) and left(&lt;math&gt;v&lt;/math&gt;) extracts the right child and the left child of a tree node&lt;math&gt;v&lt;/math&gt;, respectively. &lt;math&gt;k(v)&lt;/math&gt; extract the key of a node &lt;math&gt;v&lt;/math&gt;. "&lt;math&gt;s_1 || s_2&lt;/math&gt;" means that two statements &lt;math&gt;s_1&lt;/math&gt; and &lt;math&gt;s_2&lt;/math&gt; can run in parallel.

===Split===
To split a tree into two trees, those smaller than key ''x'', and those larger than key ''x'', we first draw a path from the root by inserting ''x'' into the tree. After this insertion, all values less than ''x'' will be found on the left of the path, and all values greater than ''x'' will be found on the right. By applying ''Join'', all the subtrees on the left side are merged bottom-up using keys on the path as intermediate nodes from bottom to top to form the left tree, and the right part is asymmetric. For some applications, ''Split'' also returns a boolean value denoting if ''x'' appears in the tree. The cost of ''Split'' is &lt;math&gt;O(\log n)&lt;/math&gt;, order of the height of the tree. 

The split algorithm is as follows:

 '''function''' split(T,k)
     '''if''' (T=nil) return (nil,false,nil)
     (L,(m,c),R)=expose(T)
     '''if''' (k=m) return (L,true,R)
     '''if''' (k&lt;m) 
        (L',b,R')=split(L,k)
        '''return''' (L',b,join(R',m,R))
     '''if''' (k&gt;m) 
        (L',b,R')=split(R,k)
        '''return''' (join(L,m,L'),b,R))

===Join2===
This function is defined similarly as ''join'' but without the middle key. It first splits out the last key &lt;math&gt;k&lt;/math&gt; of the left tree, and then join the rest part of the left tree with the right tree with &lt;math&gt;k&lt;/math&gt;.
The algorithm is as follows:

 '''function''' splitLast(T)
    (L,k,R)=expose(T)
     '''if''' (R=nil) '''return''' (L,k)
     (T',k')=splitLast(R)
     '''return''' (join(L,k,T'),k')
 '''function''' join2(L,R)
     '''if''' (L=nil) '''return''' R
     (L',k)=splitLast(L)
     '''return''' join(L',k,R)

The cost is &lt;math&gt;O(\log n)&lt;/math&gt; for a tree of size &lt;math&gt;n&lt;/math&gt;.

===Insert and Delete===
The insertion and deletion algorithms, when making use of ''join'' can be independent of balancing schemes. For an insertion, the algorithm compares the key to be inserted with the key in the root, inserts it to the left/right subtree if the key is smaller/greater than the key in the root, and joins the two subtrees back with the root. A deletion compares the key to be deleted with the key in the root. If they are equal, return join2 on the two subtrees. Otherwise, delete the key from the corresponding subtree, and join the two subtrees back with the root.
The algorithms are as follows:

 '''function''' insert(T,k)
    if (T=nil) '''return''' Node(nil,k,nil)
    (L,k',R)=expose(T)
     '''if''' (k&lt;k') '''return''' join(insert(L,k),k',R)
     '''if''' (k&gt;k') '''return''' join(L,k,insert(R,k))
 '''function''' delete(T,k)
    if (T=nil) '''return''' nil
    (L,k',R)=expose(T)
     '''if''' (k&lt;k') '''return''' join(delete(L,k),k',R)
     '''if''' (k&gt;k') '''return''' join(L,k',delete(R,k))
     return join2(L,R)

Both insertion and deletion requires &lt;math&gt;O(\log n)&lt;/math&gt; time if &lt;math&gt;|T|=n&lt;/math&gt;.

===Set-Set Functions===
Several set operations have been defined on weight-balanced trees: [[Union (set theory)|union]], [[Intersection (set theory)|intersection]] and [[set difference]]. The union of two weight-balanced trees {{math|''t''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''t''&lt;sub&gt;2&lt;/sub&gt;}} representing sets {{mvar|A}} and {{mvar|B}}, is a tree {{mvar|''t''}} that represents {{math|''A'' ∪ ''B''}}. The following recursive function computes this union:

 '''function''' union(t&lt;sub&gt;1&lt;/sub&gt;, t&lt;sub&gt;2&lt;/sub&gt;):
     '''if''' t&lt;sub&gt;1&lt;/sub&gt; = nil:
         '''return''' t&lt;sub&gt;2&lt;/sub&gt;
     '''if''' t&lt;sub&gt;2&lt;/sub&gt; = nil:
         '''return''' t&lt;sub&gt;1&lt;/sub&gt;
     (t&lt;sub&gt;&lt;&lt;/sub&gt;, b, t&lt;sub&gt;&gt;&lt;/sub&gt;) = split t&lt;sub&gt;2&lt;/sub&gt; on t&lt;sub&gt;1&lt;/sub&gt;.root
     nl=union(left(t&lt;sub&gt;1&lt;/sub&gt;), t&lt;sub&gt;&lt;&lt;/sub&gt;) || nr = union(right(t&lt;sub&gt;1&lt;/sub&gt;), t&lt;sub&gt;&gt;&lt;/sub&gt;)
     '''return''' join(nl, t&lt;sub&gt;1&lt;/sub&gt;.root, nr)

Similarly, the algorithms of intersection and set-difference are as follows:

 '''function''' intersection(t&lt;sub&gt;1&lt;/sub&gt;, t&lt;sub&gt;2&lt;/sub&gt;):
     '''if''' (t&lt;sub&gt;1&lt;/sub&gt; = nil or t&lt;sub&gt;2&lt;/sub&gt; = nil) '''return''' nil
     (t&lt;sub&gt;&lt;&lt;/sub&gt;, b, t&lt;sub&gt;&gt;&lt;/sub&gt;) = split t&lt;sub&gt;2&lt;/sub&gt; on t&lt;sub&gt;1&lt;/sub&gt;.root
     nl = t&lt;sub&gt;1&lt;/sub&gt;.root, intersection(left(t&lt;sub&gt;1&lt;/sub&gt;) || nr = intersection(right(t&lt;sub&gt;1&lt;/sub&gt;), t&lt;sub&gt;&gt;&lt;/sub&gt;)
     '''if'''  (b) '''return''' join(nl, t&lt;sub&gt;&lt;&lt;/sub&gt;), nr)
     '''else''' '''return''' join2(nl, nr)
 '''function''' difference(t&lt;sub&gt;1&lt;/sub&gt;, t&lt;sub&gt;2&lt;/sub&gt;):
     '''if''' (t&lt;sub&gt;1&lt;/sub&gt; = nil) '''return''' nil
     '''if''' (t&lt;sub&gt;2&lt;/sub&gt; = nil) '''return''' t&lt;sub&gt;1&lt;/sub&gt;
     (t&lt;sub&gt;&lt;&lt;/sub&gt;, b, t&lt;sub&gt;&gt;&lt;/sub&gt;) = split t&lt;sub&gt;2&lt;/sub&gt; on t&lt;sub&gt;1&lt;/sub&gt;.root
     nl = difference(left(t&lt;sub&gt;1&lt;/sub&gt;), t&lt;sub&gt;&lt;&lt;/sub&gt;) || nr = difference(right(t&lt;sub&gt;1&lt;/sub&gt;), t&lt;sub&gt;&gt;&lt;/sub&gt;)
     '''return''' join2(nl, nr)

The complexity of each of union, intersection and difference is &lt;math&gt;O\left(m \log \left({n\over m}+1\right)\right)&lt;/math&gt; for two weight-balanced trees of sizes &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n(\ge m)&lt;/math&gt;. This complexity is optimal in terms of the number of comparisons. More importantly, since the recursive calls to union, intersection or difference are independent of each other, they can be executed [[parallel programming|in parallel]] with a [[Analysis of parallel algorithms|parallel depth]] &lt;math&gt;O(\log m\log n)&lt;/math&gt;.&lt;ref name="join-based"/&gt; When &lt;math&gt;m=1&lt;/math&gt;, the join-based implementation applies the same computation as in a single-element insertion or deletion if the root of the larger tree is used to split the smaller tree.

===Build===
The algorithm for building a tree can make use of the union algorithm, and use the divide-and-conquer scheme:

 '''function''' build(A[], n):
     '''if''' (n=0) '''return''' nil
     '''if''' (n=1) '''return''' Node(nil,A[0],nil)
     L = build(A,n/2) || R = (A+n/2, n-n/2)
     '''return''' union(L,R)

This algorithm costs &lt;math&gt;O(n\log n)&lt;/math&gt; work and has &lt;math&gt;O(\log^3 n)&lt;/math&gt; depth. A more-efficient algorithm makes use of a parallel sorting algorithm.

 '''function''' buildSorted(A[], n):
     '''if''' (n=0) '''return''' nil
     '''if''' (n=1) '''return''' Node(nil,A[0],nil)
     L = build(A,n/2) || R = (A+n/2+1, n-n/2-1)
     '''return''' join(L,A[n/2],R)
 '''function''' build(A[], n):
     A'=sort(A,n)
     '''return''' buildSorted(A,n)

This algorithm costs &lt;math&gt;O(n\log n)&lt;/math&gt; work and has &lt;math&gt;O(\log n)&lt;/math&gt; depth assuming the sorting algorithm has &lt;math&gt;O(n\log n)&lt;/math&gt; work and &lt;math&gt;O(\log n)&lt;/math&gt; depth.

===Filter===
This function selects all entries in a tree satisfying an indicator &lt;math&gt;f&lt;/math&gt;, and return a tree containing all selected entries. It recursively filters the two subtrees, and join them with the root if the root satisfies &lt;math&gt;f&lt;/math&gt;, otherwise ''join2'' the two subtrees.

 '''function''' filter(T,f):
     '''if''' (T=nil) '''return''' nil
     L = filter(left(T),f) || R = (right(T),f)
     '''if''' (f(k(T)) '''return''' join(L,k(T),R)
     '''else''' '''return''' join2(L,R)

This algorithm costs work &lt;math&gt;O(n)&lt;/math&gt; and depth &lt;math&gt;O(\log n)&lt;/math&gt; on a tree of size &lt;math&gt;n&lt;/math&gt;, assuming &lt;math&gt;f&lt;/math&gt; has constant cost.

==Used in Libraries==
The join-based algorithms are applied to support interface for [[Set (abstract data type)|sets]], [[Map (computer science)|maps]], and [[augmented map|augmented maps]] &lt;ref name="pam"&gt;{{citation
 | last1 = Blelloch | first1 = Guy E.
 | last2 = Ferizovic | first2 = Daniel
 | last3 = Sun | first3 = Yihan
 | contribution = PAM: parallel augmented maps
 | pages = 290-304
 | title = Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming
 | publisher = ACM
 | year = 2018}}&lt;/ref&gt; in libarays such as [[Hackage]], [[SML/NJ]], and [[PAM library|PAM]]&lt;ref name="pam"&gt;{{citation
 | last1 = Blelloch | first1 = Guy E.
 | last2 = Ferizovic | first2 = Daniel
 | last3 = Sun | first3 = Yihan
 | contribution = PAM: parallel augmented maps
 | pages = 290-304
 | title = Proceedings of the 23rd ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming
 | publisher = ACM
 | year = 2018}}&lt;/ref&gt;.

==Notes==
{{notelist}}

==References==
{{reflist|30em}}

== External links ==
* [https://github.com/cmuparlay/PAM PAM], the parallel augmented map library.
* [https://hackage.haskell.org/package/containers Hackage], Containers in Hackage

{{data structures}}

[[Category:Algorithms and data structures]]
[[Category:Algorithms]]
[[Category:Data structures]]</text>
      <sha1>jb5dyofk25e1vbi97roxbkxdqjbw93a</sha1>
    </revision>
  </page>
  <page>
    <title>Jyotirmimamsa</title>
    <ns>0</ns>
    <id>26113571</id>
    <revision>
      <id>813408407</id>
      <parentid>762069622</parentid>
      <timestamp>2017-12-03T15:10:05Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 0 sources and tagging 1 as dead. #IABot (v1.6.1)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5111">In [[Hindu astronomy]], '''Jyotirmimamsa''' (analysis of astronomy)&lt;ref&gt;Jyotirmimamsa (Investigations on astronomical theories) of Nilakantha Somayaji. Edited by [[K.V. Sarma]], Hoshiarpur : Vishveshvaranand Vishva Bandhu Institute of Sanskrit and Indological Studies, Panjab University, 1977. 1st ed.&lt;/ref&gt; is a treatise on the [[methodology]] of astronomical studies authored by [[Nilakantha Somayaji]] (1444–1544) in around 1504 CE. Nilakantha somayaji was an important [[astronomer]]-[[mathematician]] of the [[Kerala school of astronomy and mathematics]] and was the author of the much celebrated astronomical work titled [[Tantrasamgraha]]. This book stresses the necessity and importance of astronomical observations to obtain correct parameters for computations and to develop more and more accurate theories. It even discounts the role of revealed wisdom and divine intuitions in studying astronomical phenomena. Jyotirmimamsa is sometimes cited as proof to establish that modern methodologies of scientific investigations are not unknown to ancient and medieval Indians.&lt;ref&gt;{{cite book|last=Roddam Narasimha|title=Different types of history|editor=Bharati Ray|publisher=Centre for Studies in Civilisation|location=Delhi|date=2009|series=project of History of Science, Philosophy, and Culture in Indian Civilisation|volume=XIV Part 4|pages=96–97|chapter=^ . The Chequered Histories of Epistemology of Science}}&lt;/ref&gt;

The nature of the astronomical and mathematical work, the divine intuition, the experimental details of the science, corrections to the planetary parameters, reasons for the corrections for the planetary revolutions, Vedic authority for inference in astronomy, relative accuracy of different systems, and correction through [[eclipse]]s, true motion, position, etc., of planets are some of the topics discussed in Jyotirmimamsa.&lt;ref name="Dhaara"&gt;{{cite book|last=N. Gopalakrishnan|title=Baharatheeya Vijnana / Saastra Dhaara ( Handbbok of Ancient Indian  Scientific Books)|publisher=Indian Institute of Scientific Heritage|location=Thiruvanannthapuram, India|date=2004|series=Heritage Publication Series|volume=78|pages=18–20|url=http://www.books.user.janyug.com/Pradeesh/data/public/Culture/Ancient/Indian/251.pdf|accessdate=12 January 2010}}{{dead link|date=December 2017 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;

==Synopsis==
The following is an outline of the various topics discussed in Jyotirmimamsa.&lt;ref name="Dhaara"/&gt;

*The necessity of revising the astronomical constants at regular intervals for correcting the parameters connected with astronomy
*The meaning of ''devatha prasada'', which is manifested in the intuition of the astronomers, as a prerequisite for obtaining the accurate values and the correct approach in the astronomy
*The experimental determinations of the astronomical constants and the tools used for these determinations
*The need and the importance of conducting experiments in astronomical studies
*Significance of the astronomical books and the base of collecting data from those books
*Application of corrections, called ''bija correction'', for the astronomical figures 
*The corrections known as the ''Bhatta correction'' 
*Justification of the changes made by the astronomer Lallacharya in his book ''Sishyaddhi vruddhi tantra''
*Reasons for difference in the mean planets though the revolutions are identical
*Vedic authority for inference as a means to derive the number of planetary revolutions
*Different systems of astronomy
*The numbers of planetary revolutions enunciated by Sripati and Brahmagupta
*The numbers of revolutions of planets, apogees and  nodes, number of days,etc., in a [[Kalpa (aeon)|Kalpa]] (in astronomy, a period of 14&amp;times;72&amp;times;4320000 years) 
*Zero points of the planets at the commencement of [[kaliyuga]], corrections to planetary revolutions
*Relative accuracy of the different astronomical systems
*Mean planets according to the Sunrise system of [[Aryabhatiya]], mean planets, Moon's apogee and Moon's node according to ''Siddhantasekhara''
*Application of the values in the astronomical calculations, astronomical corrections given on the bases of the eclipses
*Eclipses observed by Parameswaracharya
*Method of corrections given by other astronomers
*Demonstration of the validity of those corrections through eclipses, precision of  equinoxes, calculation and the correction, correction of the periphery of the manda epicycle, discussion on the precision of the equinoxes, corrections due to the precession of the equinoxes
*Sine table for ''praanakalaantara'', sine table for the ascensional differences
*Derivation of the 36 Rsines
*Graphic proof for the relation of the sides and hypotenuse
*Reason for the reduction of the minutes of arc of the planetary orbital to the visible celestial sphere

==See also==
*[[Indian astronomy]]
*[[Indian mathematics]]
*[[Indian mathematicians]]
*[[History of mathematics]]

==References==
{{reflist}}

{{Scientific Research in Kerala |state=collapsed}}
[[Category:Hindu astronomy]]
[[Category:History of mathematics]]
[[Category:Kerala school]]</text>
      <sha1>mqg5t2ny0iaseb2uve6xd3f4ezatsve</sha1>
    </revision>
  </page>
  <page>
    <title>Karel deLeeuw</title>
    <ns>0</ns>
    <id>2295976</id>
    <revision>
      <id>867488801</id>
      <parentid>858721409</parentid>
      <timestamp>2018-11-06T01:36:22Z</timestamp>
      <contributor>
        <username>Alaney2k</username>
        <id>209266</id>
      </contributor>
      <minor/>
      <comment>/* top */US =&gt; Americans</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6895">{{Infobox scientist
| name        = Karel deLeeuw
| image       =         &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size  = 
| alt         = 
| caption     = 
| birth_date  = {{birth date |1930|2|20|mf=y}}
| birth_place = [[Chicago, Illinois]]
| death_date  = {{death date and age |1978|8|18 |1930|2|20|mf=y}}
| death_place = [[Stanford, California]]
| nationality = [[Americans|American]]
| fields      = [[Mathematics]]
| workplaces  = [[Stanford University]]
| alma_mater  = [[Princeton University]]&lt;br&gt;[[Illinois Institute of Technology]]
| doctoral_advisor = [[Emil Artin]] &lt;!--(or  | doctoral_advisors = )--&gt;
| doctoral_students = [[Haskell Rosenthal]]&lt;br&gt;[[Alan Schoenfeld]] &lt;small&gt;([[:de:Alan H. Schoenfeld|de]])&lt;/small&gt;
| known_for   = [[Choquet theory|Choquet–Bishop–deLeeuw theorem]]
| spouse = Sita deLeeuw
| other_names = Karel de Leeuw
| awards      = 
}}

'''Karel deLeeuw''', or '''de Leeuw''' ({{birth date|1930|02|20}} – {{death date|1978|08|18}}), was a [[mathematics]] professor at [[Stanford University]], specializing in [[harmonic analysis]] and [[functional analysis]].

==Life and career==
Born in [[Chicago, Illinois]], he attended the [[Illinois Institute of Technology]] and the [[University of Chicago]], earning a [[Bachelor of Science|B.S.]] degree in 1950. He stayed at Chicago to earn an [[Master of Science|M.S.]] degree in mathematics in 1951, then went to [[Princeton University]], where he obtained a [[Ph.D.]] degree in 1954.&lt;ref name=memorial_resolution&gt;{{cite web |url=http://histsoc.stanford.edu/pdfmem/deLeeuwK.pdf |title=Memorial resolution: Karel deLeeuw (1930 – 1978) |publisher=Stanford University |accessdate=May 7, 2013 |deadurl=yes |archiveurl=https://web.archive.org/web/20120205223529/http://histsoc.stanford.edu/pdfmem/deLeeuwK.pdf |archivedate=February 5, 2012 |df= }}&lt;/ref&gt; His thesis, titled "The relative cohomology structure of formations", was written under the direction of [[Emil Artin]].

After first teaching mathematics at [[Dartmouth College]] and the [[University of Wisconsin–Madison]], he joined the [[Stanford University]] faculty&lt;ref&gt;{{cite book | title=A century of mathematics in America: Part II | url=https://books.google.com/books?id=Eq5072shy9AC&amp;pg=PA270 | page=270 | editor-last=Duren | editor-first=Peter L. | isbn=0-8218-0130-9 | publisher=American Mathematical Society | year=1989 | accessdate=May 7, 2013}}&lt;/ref&gt; in 1957, becoming a full professor in 1966. During sabbaticals and leaves he also spent time at the [[Institute for Advanced Study]] and at [[Churchill College, Cambridge]] (where he was a [[Fulbright Fellow]]).  He was also a Member-at-Large of the Council of the [[American Mathematical Society]].&lt;ref name=memorial_resolution /&gt;

==Death and legacy==
DeLeeuw was murdered by [[Theodore Streleski]], a Stanford doctoral student for 19 years, whom he briefly advised.&lt;ref&gt;{{cite web | url=http://www.time.com/time/magazine/article/0,9171,959900,00.html | title=American Notes Crime - Unrepentant about Murder | publisher=[[TIME Magazine]] | date=September 23, 1985}}&lt;/ref&gt; DeLeeuw's widow Sita deLeeuw was critical of media coverage of the crime, saying, "The media, in their eagerness to give Streleski a forum, become themselves accomplices in the murder—giving Streleski what he wanted in the first place."&lt;ref name="deLeeuw1985"&gt;{{cite news | url=http://articles.latimes.com/1985-10-05/local/me-1109_1_gory-details-theodore-streleski-stanford-university-mathematics-professor | title=Widow of Slain Professor Speaks Out | newspaper=''[[Los Angeles Times]]'' | date=October 5, 1985}}&lt;/ref&gt;

A memorial lecture series was established in 1978 by the Stanford Department of Mathematics to honor deLeeuw's memory.&lt;ref&gt;{{cite web | url=http://math.stanford.edu/seminars/pastevents/deLeeuw_poster08.pdf | title=Karel deLeeuw Memorial Lecture: "On the Mathematics of Genomic Imprinting" | publisher=Stanford University | date=November 13, 2008 | accessdate=May 7, 2013 }}{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;&lt;ref&gt;{{cite web | url=http://math.stanford.edu/seminars/pastevents/deLeeuw-Netz060612.pdf | archive-url=https://wayback.archive-it.org/all/20120714010339/http://math.stanford.edu/seminars/pastevents/deLeeuw-Netz060612.pdf | dead-url=yes | archive-date=2012-07-14 | title=Karel deLeeuw Memorial Lecture: "Archimedes' Hydrostatics and the Birth of Mathematical Physics" | publisher=Stanford University | date=June 6, 2012 | accessdate=May 7, 2013 | df= }}&lt;/ref&gt;

==Selected publications==
* {{Cite document|last=deLeeuw|first=Karel|title=Calculus|year=1966|publisher=[[Harcourt, Brace]]|postscript=&lt;!--None--&gt;}}&lt;ref&gt;{{Cite journal|last=Dorner|first=George C.|date=1968-01-01|title=Review of Calculus|jstor=27958003|journal=The Mathematics Teacher|volume=61|issue=8|pages=804–805}}&lt;/ref&gt;
* {{Cite journal|last1=Rudin|first1=Walter|author1-link=Walter Rudin|last2=de Leeuw|first2=Karel|title=Extreme points and extremum problems in ''H''&lt;sub&gt;1&lt;/sub&gt;|journal=Pacific Journal of Mathematics|year=1958|volume=8|pages=467–485|url=http://projecteuclid.org/euclid.pjm/1103039893|issue=3|postscript=&lt;!--None--&gt;|doi=10.2140/pjm.1958.8.467}}
* {{cite journal|author=de Leeuw, Karel|journal=Annals of Mathematics |series=Second Series |year=1965|title=On ''L''&lt;sub&gt;''p''&lt;/sub&gt; multipliers|volume=81|issue=2|pages=364–379|doi=10.2307/1970621|publisher=The Annals of Mathematics, Vol. 81, No. 2|jstor=1970621}}
* {{cite journal|author=de Leeuw, Karel|journal=Illinois J. Math.|year=1975|title=An harmonic analysis for operators. I. Formal properties|volume=19|issue=4|pages=593–606|issn=0019-2082}}
* {{cite journal|author=de Leeuw, Karel|journal=Illinois J. Math.|year=1977|title=An harmonic analysis for operators. II. Operators on Hilbert space and analytic operators|volume=21|issue=1|pages=164–175|issn=0019-2082}}
* {{cite journal|author=de Leeuw, Karel |author2=Yitzhak Katznelson |author3=[[Jean-Pierre Kahane]]|journal=Comptes Rendus de l'Académie des Sciences, Série A et B|year=1977|title=Sur les coefficients de Fourier des fonctions continues|volume=285|issue=16|pages=A1001–A1003|issn=0997-4482}}

==References==
{{reflist}}

==External links==
* {{MathGenealogy|id=14684}}

{{Authority control}}

{{DEFAULTSORT:DeLeeuw, Karel}}
[[Category:20th-century mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Stanford University Department of Mathematics faculty]]
[[Category:Princeton University alumni]]
[[Category:Dartmouth College faculty]]
[[Category:University of Wisconsin–Madison faculty]]
[[Category:People from Chicago]]
[[Category:Murdered American scientists]]
[[Category:Murdered educators]]
[[Category:1930 births]]
[[Category:1978 deaths]]
[[Category:People murdered in California]]
[[Category:Deaths by beating in the United States]]
[[Category:Illinois Institute of Technology alumni]]</text>
      <sha1>f4jjpjs8ao4p247aau861fm6vyypl45</sha1>
    </revision>
  </page>
  <page>
    <title>Langlands–Deligne local constant</title>
    <ns>0</ns>
    <id>32103592</id>
    <revision>
      <id>813162705</id>
      <parentid>787068077</parentid>
      <timestamp>2017-12-02T04:23:58Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Lecture notes in mathematics → Lecture Notes in Mathematics using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5737">In mathematics, the '''Langlands–Deligne local constant''' (or '''local Artin root number''' up to an elementary function of ''s'')  is an elementary function associated with a representation of the [[Weil group]] of a [[local field]]. The functional equation 
:L(ρ,''s'') = ε(ρ,''s'')L(ρ&lt;sup&gt;∨&lt;/sup&gt;,1−''s'')
of an [[Artin L-function]] has an elementary function ε(ρ,''s'') appearing in it, equal to a constant called the  [[Artin root number]] times an elementary real function of ''s'', and Langlands discovered that ε(ρ,''s'') can be written in a canonical way as a product
:ε(ρ,''s'') = Π ε(ρ&lt;sub&gt;''v''&lt;/sub&gt;, ''s'', ψ&lt;sub&gt;''v''&lt;/sub&gt;)
of local constants ε(ρ&lt;sub&gt;''v''&lt;/sub&gt;, ''s'', ψ&lt;sub&gt;''v''&lt;/sub&gt;) associated to primes ''v''.

Tate proved the existence of the local constants in the case that ρ is 1-dimensional in [[Tate's thesis]].
{{harvtxt|Dwork|1956}} proved the existence of the local constant ε(ρ&lt;sub&gt;''v''&lt;/sub&gt;, ''s'', ψ&lt;sub&gt;''v''&lt;/sub&gt;) up to sign.
The original proof of the existence of the local constants by {{harvtxt|Langlands|1970}} used local methods and was rather long and complicated, and never published. {{harvtxt|Deligne|1973}} later discovered a simpler proof using global methods.

==Properties==

The local constants ε(ρ, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;) depend on a representation ρ of the Weil group and a choice of character ψ&lt;sub&gt;''E''&lt;/sub&gt; of the additive group of ''E''. They satisfy the following conditions:
*If ρ is 1-dimensional then ε(ρ, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;) is the constant associated to it by Tate's thesis as the constant in the functional equation of the local L-function.
* ε(ρ&lt;sub&gt;1&lt;/sub&gt;⊕ρ&lt;sub&gt;2&lt;/sub&gt;, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;) = ε(ρ&lt;sub&gt;1&lt;/sub&gt;, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;)ε(ρ&lt;sub&gt;2&lt;/sub&gt;, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;).   As a result,   ε(ρ, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;) can also be defined for virtual representations ρ.
*If ρ is a virtual representation of dimension 0 and ''E'' contains ''K'' then ε(ρ, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;) = ε(Ind&lt;sub&gt;''E''/''K''&lt;/sub&gt;ρ, ''s'', ψ&lt;sub&gt;''K''&lt;/sub&gt;)

[[Brauer's theorem on induced characters]] implies that these three properties characterize the local constants.

{{harvtxt|Deligne|1976}} showed that the local constants are trivial for real (orthogonal) representations of the Weil group.

==Notational conventions==

There are several different conventions for denoting the local constants.
*The parameter ''s'' is redundant and can be combined with the representation ρ, because  ε(ρ, ''s'', ψ&lt;sub&gt;''E''&lt;/sub&gt;) =  ε(ρ⊗||&lt;sup&gt;''s''&lt;/sup&gt;, 0, ψ&lt;sub&gt;''E''&lt;/sub&gt;) for a suitable character ||.
*Deligne includes an extra parameter ''dx'' consisting of a choice of Haar measure on the local field. Other conventions omit this parameter by fixing a choice of Haar measure: either the Haar measure that is self dual with respect to ψ (used by Langlands), or the Haar measure that gives the integers of ''E'' measure 1. These different conventions differ by elementary terms that are positive real numbers.

==References==

*{{Citation | last1=Bushnell | first1=Colin J. |authorlink1=Colin J. Bushnell |last2=Henniart | first2=Guy |authorlink2=Guy Henniart | title=The local Langlands conjecture for GL(2) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences] | isbn=978-3-540-31486-8 | id={{ISBN|978-3-540-31486-8}} | doi=10.1007/3-540-31511-X | mr=2234120 | year=2006 | volume=335}}
*{{Citation | last1=Deligne | first1=Pierre | author1-link=Pierre Deligne | title=Modular functions of one variable, II (Proc. Internat. Summer School, Univ. Antwerp, Antwerp, 1972) | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | doi=10.1007/978-3-540-37855-6_7 | mr=0349635 | year=1973 | volume=349 | chapter=Les constantes des équations fonctionnelles des fonctions L | pages=501–597}}
*{{Citation | last1=Deligne | first1=Pierre | author1-link=Pierre Deligne | title=Les constantes locales de l'équation fonctionnelle de la fonction L d'Artin d'une représentation orthogonale | doi=10.1007/BF01390143 | mr=0506172 | year=1976 | journal=[[Inventiones Mathematicae]] | issn=0020-9910 | volume=35 | pages=299–316}}
*{{Citation | last1=Dwork | first1=Bernard | title=On the Artin root number | jstor=2372524 | mr=0082476 | year=1956 | journal=[[American Journal of Mathematics]] | issn=0002-9327 | volume=78 | pages=444–472 | doi=10.2307/2372524}}
*{{citation|last=Langlands|first=Robert|series=Unpublished notes|url=http://publications.ias.edu/rpl/paper/61|title=On the functional equation of the Artin L-functions|year=1970}}
*{{Citation | last1=Tate | first1=John T. | editor1-last=Fröhlich | editor1-first=A. | title=Algebraic number fields: L-functions and Galois properties (Proc. Sympos., Univ. Durham, Durham, 1975) | url=https://books.google.com/books?id=_QDvAAAAMAAJ | publisher=[[Academic Press]] | location=Boston, MA | isbn=978-0-12-268960-4 | mr=0457408 | year=1977 | chapter=Local constants | pages=89–131}}
*{{citation|last=Tate|first= J. |chapter=Number theoretic background |url=http://www.ams.org/online_bks/pspum332/ |title=Automorphic forms, representations, and L-functions Part 2, |pages= 3–26|series=Proc. Sympos. Pure Math.|volume= XXXIII|publisher= Amer. Math. Soc.|publication-place= Providence, R.I.|year=1979|isbn=0-8218-1435-4}}

==External links==
*{{Springer|first=R.|last= Perlis|id=a/a120270|title=Artin root numbers}}

{{L-functions-footer}}

{{DEFAULTSORT:Langlands-Deligne local constant}}
[[Category:Representation theory]]
[[Category:Zeta and L-functions]]
[[Category:Class field theory]]</text>
      <sha1>hta176tngkxv6mvjhlt3u7d2jyxhw6t</sha1>
    </revision>
  </page>
  <page>
    <title>Lebesgue's density theorem</title>
    <ns>0</ns>
    <id>4258134</id>
    <revision>
      <id>809891511</id>
      <parentid>706985146</parentid>
      <timestamp>2017-11-12T04:03:49Z</timestamp>
      <contributor>
        <username>Twin Bird</username>
        <id>312433</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2603">In [[mathematics]], '''Lebesgue's density theorem''' states that for any [[Lebesgue measure|Lebesgue measurable set]] &lt;math&gt;A\subset \R^n&lt;/math&gt;, the "density" of ''A'' is 0 or 1 at [[almost everywhere|almost every]] point in &lt;math&gt;\R^n&lt;/math&gt;. Additionally, the "density" of ''A'' is 1 at almost every point in ''A''.   Intuitively, this means that the "edge" of ''A'', the set of points in ''A'' whose "neighborhood" is partially in ''A'' and partially outside of ''A'', is [[null set|negligible]].

Let μ be the Lebesgue measure on  the [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt; and ''A'' be a Lebesgue measurable subset of '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. Define the '''approximate density''' of ''A'' in a ε-neighborhood of a point ''x''  in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; as

:&lt;math&gt; d_\varepsilon(x)=\frac{\mu(A\cap B_\varepsilon(x))}{\mu(B_\varepsilon(x))}&lt;/math&gt;

where ''B''&lt;sub&gt;ε&lt;/sub&gt; denotes the [[closed ball]] of radius ε centered at ''x''.

'''Lebesgue's density theorem''' asserts that for almost every point ''x'' of ''A'' the '''density'''

:&lt;math&gt; d(x)=\lim_{\varepsilon\to 0} d_{\varepsilon}(x)&lt;/math&gt;

exists and is equal to 1.

In other words, for every measurable set ''A'', the density of ''A'' is 0 or 1 [[almost everywhere]] in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.&lt;ref&gt;{{cite book| last = Mattila| first = Pertti|author-link = Pertti Mattila| title = Geometry of Sets and Measures in Euclidean Spaces: Fractals and Rectifiability| year = 1999| isbn = 978-0-521-65595-8 }}&lt;/ref&gt; However, it is a curious fact that if μ(''A'')&amp;nbsp;&gt;&amp;nbsp;0 and  {{nowrap|μ('''R'''&lt;sup&gt;''n''&lt;/sup&gt;&amp;thinsp;\&amp;thinsp;''A'') &gt; 0}}, then there are always points of  '''R'''&lt;sup&gt;''n''&lt;/sup&gt; where the density is neither 0 nor&amp;nbsp;1.

For example, given a square in the plane, the density at every point inside the square is 1, on the edges is 1/2, and at the corners is 1/4.  The set of points in the plane at which the density is neither 0 nor 1 is non-empty (the square boundary), but it is negligible.

The Lebesgue density theorem is a particular case of the [[Lebesgue differentiation theorem]].

Thus, this theorem is also true for every finite Borel measure on '''R'''&lt;sup&gt;''n''&lt;/sup&gt; instead of Lebesgue measure, see [[Lebesgue differentiation theorem#Discussion|Discussion]].

== See also ==
* [[Lebesgue differentiation theorem]]

== References ==
{{reflist}}
* Hallard T. Croft. Three lattice-point problems of Steinhaus. ''Quart. J. Math. Oxford (2)'', 33:71-83, 1982.

{{PlanetMath attribution|id=3869|title=Lebesgue density theorem}}

[[Category:Theorems in measure theory]]
[[Category:Integral calculus]]</text>
      <sha1>ip2x2woylprtfn5gez0ae8w8o1yjaca</sha1>
    </revision>
  </page>
  <page>
    <title>Leonard Schulman</title>
    <ns>0</ns>
    <id>43532254</id>
    <revision>
      <id>837620155</id>
      <parentid>812250569</parentid>
      <timestamp>2018-04-21T23:44:28Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Authority control|Authority control]]}} (2 sources from Wikidata), [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3648">{{Infobox scientist
| boxwidth          =
| name              = Leonard Schulman
| image             =
| image_size        =
| alt               =
| caption           =
| birth_date        = {{b-da|September 14, 1963}}
| birth_place       = Princeton, New Jersey
| residence         =
| nationality       = [[US|American]]
| fields            = [[Computer Science]], [[Applied mathematics]]
| workplaces        = [[California Institute of Technology]]
| alma_mater        = [[Massachusetts Institute of Technology]]
| doctoral_advisor  = [[Michael Sipser]]
| academic_advisors =
| doctoral_students =
| notable_students  =
| known_for         = [[Algorithms]], [[Information Theory]], [[Coding Theory]], [[Quantum Computation]]
| awards            =
}}

'''Leonard J. Y. Schulman''' (born September 14, 1963) is Professor of [[Computer Science]] in the Computing and Mathematical Sciences Department at the [[California Institute of Technology]]. He is known for work on [[algorithms]], [[information theory]], [[coding theory]], and [[quantum computation]].

==Personal Biography==
Schulman is the son of theoretical physicist [[Lawrence Schulman]].

==Academic Biography==
Schulman studied at the [[Massachusetts Institute of Technology]], where he completed a BS degree in Mathematics in 1988 and a PhD degree in Applied Mathematics in 1992.
He was a faculty member in the College of Computing at the [[Georgia Institute of Technology]] from 1995-2000 before joining the faculty of the [[California Institute of Technology]] in 2000.&lt;ref&gt;[http://directory.caltech.edu/personnel/schulman Leonard Schulman] at the [http://directory.caltech.edu Caltech Directory]&lt;/ref&gt;  He serves as the director of the Center for Mathematics of Information&lt;ref&gt;[http://www.cmi.caltech.edu/index.shtml The Center for the Mathematics of Information at Caltech]&lt;/ref&gt; at Caltech and also participates in the Institute for Quantum Information and Matter.&lt;ref&gt;[http://www.iqim.caltech.edu/ Institute for Quantum Information and Mater at Caltech]&lt;/ref&gt;

==Research==
Schulman's research centers broadly around algorithms and information.  He has made notable contributions to varied areas within this space including clustering, derandomization, quantum information theory, and coding theory.  One example, which was named a Computing Reviews "Notable Paper" in 2012, is his work on quantifying the effectiveness of Lloyd-type methods for the [[k-means]] problem.&lt;ref&gt;[http://www.computingreviews.com/recommend/bestof/notableitems_2012.cfm Computing Reviews Notable Papers and Books of 2012]&lt;/ref&gt;

==Awards and honors==

Schulman received the MIT Bucsela Prize in 1988, an NSF Mathematical Sciences Postdoctoral Fellowship in 1992 and an NSF CAREER award in 1999.  His work received the IEEE S.A. Schelkunoff Prize in 2005.&lt;ref&gt;[http://www.ee.cityu.edu.hk/~ieee_tap/best_papers.php#Schelkunoff IEEE Schelkunoff Prize Recipients]&lt;/ref&gt;  He was named the editor-in-chief of the [[SIAM Journal on Computing]] in 2013.  Schulman was also recognized for the ACM Notable Paper in 2012 and received the UAI Best Paper Award in 2016.

==References==
{{Reflist}}

==External links==
* [http://users.cms.caltech.edu/~schulman/ Leonard Schulman professional home page]

{{Authority control}}

{{DEFAULTSORT:Schulman, Leonard}}
[[Category:American computer scientists]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:California Institute of Technology faculty]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Living people]]
[[Category:Theoretical computer scientists]]
[[Category:1963 births]]</text>
      <sha1>pq4qd18hi2emqjvltxp69dtdqrarquc</sha1>
    </revision>
  </page>
  <page>
    <title>Lightface analytic game</title>
    <ns>0</ns>
    <id>2630881</id>
    <revision>
      <id>631352163</id>
      <parentid>631349928</parentid>
      <timestamp>2014-10-27T18:20:16Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Unreferenced}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="723">{{unreferenced|date=October 2014}}

In [[descriptive set theory]], a '''lightface analytic game''' is a [[Determinacy#Games|game]] whose [[Determinacy#Games|payoff set]] ''A'' is a &lt;math&gt;\Sigma^1_1&lt;/math&gt; [[subset]] of [[Baire space (set theory)|Baire space]]; that is, there is a [[Tree (descriptive set theory)|tree]] ''T'' on &lt;math&gt;\omega\times\omega&lt;/math&gt; which is a [[computable]] subset of &lt;math&gt;(\omega\times\omega)^{&lt;\omega}&lt;/math&gt;, such that ''A'' is the projection of the set of all branches of ''T''.

The [[determinacy]] of all lightface analytic games is  equivalent to the existence of [[Zero sharp|0&lt;sup&gt;#&lt;/sup&gt;]].

[[Category:Effective descriptive set theory]]
[[Category:Determinacy]]


{{mathlogic-stub}}</text>
      <sha1>rj4130e8397y6x0mb44yj6eae4vbpj3</sha1>
    </revision>
  </page>
  <page>
    <title>Manipulability ellipsoid</title>
    <ns>0</ns>
    <id>19852914</id>
    <revision>
      <id>615308375</id>
      <parentid>613480662</parentid>
      <timestamp>2014-07-02T15:32:48Z</timestamp>
      <contributor>
        <username>Markhurd</username>
        <id>16276</id>
      </contributor>
      <minor/>
      <comment>Disambiguate [[Jacobian]] to [[Jacobian matrix and determinant]] using [[:en:Wikipedia:Tools/Navigation_popups|popups]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="320">In [[robotics]], the '''manipulability ellipsoid''' is the geometric interpretation of the scaled [[eigenvector]]s resulting from the [[singular value decomposition]] of the [[Jacobian matrix and determinant|jacobian]] that describes a robot's motion.

[[Category:Robot control]]
[[Category:Geometry]]

{{robotics-stub}}</text>
      <sha1>92hm5nn565yjtbx1rex8iswddsv7k5r</sha1>
    </revision>
  </page>
  <page>
    <title>Marcos Dajczer</title>
    <ns>0</ns>
    <id>46801272</id>
    <revision>
      <id>861381312</id>
      <parentid>820798998</parentid>
      <timestamp>2018-09-27T00:51:57Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3167">'''Marcos Dajczer''' (born 19 November 1948, in [[Buenos Aires]]) is an [[Argentina|Argentine]]-born [[Brazil]]ian [[Mathematics|mathematician]] whose research concerns [[geometry]] and [[topology]].&lt;ref&gt;{{cite web|url=http://www.abc.org.br/~dajczer|title=Academia Brasileira de Ciências: Membros: Marcos Dajczer|language=Portuguese}}&lt;/ref&gt;

Dajczer obtained his Ph.D. from the [[Instituto Nacional de Matemática Pura e Aplicada]] in 1980 under the supervision of [[Manfredo do Carmo]].&lt;ref&gt;{{MathGenealogy|id=53608}}&lt;/ref&gt;

In 2006, he received [[National Order of Scientific Merit (Brazil)|Brazil's National Order of Scientific Merit]] honour for his work in mathematics.&lt;ref&gt;{{cite web|url=http://www.mct.gov.br/index.php/content/view/11199/11199.html?nome=&amp;area=Ci%EAncias+Matem%E1ticas&amp;classificacao=&amp;categoria=vivo|title=Portal do Ministério da Ciência, Tecnologia e Inovação: Ordem Nacional do Mérito Científico|language=Portuguese}}{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; He was a [[Guggenheim Fellowship|Guggenheim Fellow]] in 1985.&lt;ref&gt;{{cite web|url=http://www.gf.org/fellows/all-fellows/marcos-dajczer/|title=John Simon Guggenheim Memorial Foundation: Fellows: Marcos Dajczer}}&lt;/ref&gt;

[[Do Carmo–Dajczer theorem]] is named after his teacher and him.&lt;ref&gt;{{cite arXiv|eprint=1001.5198|last1= Perdomo|first1= Oscar M.|title= A dynamical interpretation of the profile curve of cmc Twizzlers surfaces|year= 2010|class= math.DG}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv|eprint=1205.3306|last1=Lee|first1=Hojoo|title=Isometric deformations of the &lt;math&gt;K^{1/4}&lt;/math&gt;-flow translators in &lt;math&gt;\Bbb R^3&lt;/math&gt; with helicoidal symmetry|year=2012|class=math.DG}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv|eprint=dg-ga/9609010v2|last1=Haak|first1=Guido|title=On a theorem by do Carmo and Dajczer|year=1996}}&lt;/ref&gt;

==Selected publications==
*do Carmo, M. ; Dajczer, M. (1983) . "[http://www.ams.org/journals/tran/1983-277-02/S0002-9947-1983-0694383-X/ Rotation hypersurfaces in spaces of constant curvature]", ''[[Transactions of the American Mathematical Society]]'', Volume 277, Number 2, pp.&amp;nbsp;685–709.
*do Carmo, M. ; Dajczer, M. (1982) . "[https://www.jstage.jst.go.jp/article/tmj1949/34/3/34_3_425/_article Helicoidal surfaces with constant mean curvature]", ''[[Tohoku Mathematical Journal]]'' Second Series, Volume 34, Number 3, pp.&amp;nbsp;425–435.
* ''Submanifolds and Isometric Immersions'' (1990, Mathematics Lecture Series) {{ISBN|9780914098225}}

==References==
{{reflist}}

==External links==
*{{cite web|url=http://www.impa.br/opencms/pt/eventos/store_old/evento_0903|title=IMPA: International Symposium on Differential Geometry "In honor of Marcos Dajczer on his 60th birthday"}}


{{authority control}}

{{DEFAULTSORT:Dajczer, Marcos}}
[[Category:1948 births]]
[[Category:Brazilian mathematicians]]
[[Category:People from Buenos Aires]]
[[Category:Differential geometers]]
[[Category:Topologists]]
[[Category:Guggenheim Fellows]]
[[Category:Living people]]
[[Category:Instituto Nacional de Matemática Pura e Aplicada alumni]]
[[Category:Instituto Nacional de Matemática Pura e Aplicada researchers]]


{{mathematician-stub}}</text>
      <sha1>sjmhrd1q1llw5k0oiietheipd7c1ayd</sha1>
    </revision>
  </page>
  <page>
    <title>Moni Naor</title>
    <ns>0</ns>
    <id>10151043</id>
    <revision>
      <id>858242255</id>
      <parentid>839272208</parentid>
      <timestamp>2018-09-05T22:07:54Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Remove 1 stray access-date. ([[User:GreenC bot/Job 5|GreenC bot job #5]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5032">{{Infobox scientist
| name                    = Moni Naor
| image                   = Moni Naor at the DIMACS Workshop on Cryptography.jpg
| image_size              = 
| caption                 = Moni Naor at the DIMACS Workshop on Cryptography, July 2016.
| birth_date              = 1961
| birth_place             =
| death_date              = 
| death_place             = 
| residence               = 
| citizenship             = Israeli
| nationality             = 
| ethnicity               =
| field                   = [[Computer Science]], [[Cryptography]]
| work_institution        = [[Weizmann Institute of Science]]
| alma_mater              = [[Technion]]&lt;br /&gt;[[University of California, Berkeley]]
| doctoral_advisor        = [[Manuel Blum]]
| doctoral_students       = [[Yehuda Lindell]] &lt;br&gt;[[Omer Reingold]]
| known_for               = 
| prizes                  =  [[Gödel prize]] &lt;small&gt;(2014)&lt;/small&gt;
| religion                = 
| footnotes               = 
}}

'''Moni Naor''' ({{lang-he|מוני נאור}}) is an [[Israelis|Israeli]] [[computer scientist]], currently a professor at the [[Weizmann Institute of Science]]. Naor received his Ph.D. in 1989 at the [[University of California, Berkeley]]. His advisor was [[Manuel Blum]].

He works in various fields of [[computer science]], mainly the foundations of [[cryptography]]. He is notable for initiating research on public key systems secure against [[chosen ciphertext attack]] and creating [[Malleability (cryptography)|non-malleable cryptography]], [[visual cryptography]] (with [[Adi Shamir]]), and suggesting various methods for verifying that users of a computer system are human (leading to the notion of [[CAPTCHA]]).&lt;ref&gt;{{cite web|url=https://www.nytimes.com/2014/01/19/magazine/who-made-that-captcha.html |title=Who Made that CAPTCHA |publisher=[[New York Times]] |accessdate={{Format date|2014|1|17}}}}&lt;/ref&gt; His research on [[Small-bias sample space]], give a general framework for combining small k-wise independent spaces with small &lt;math&gt;\epsilon&lt;/math&gt;-biased spaces to obtain &lt;math&gt;\delta&lt;/math&gt;-almost k-wise independent spaces of small size.&lt;ref name="k-wise"&gt;{{cite journal|author1=Joseph Naor|author2=Moni Naor|title=Small-bias Probability Spaces: efficient constructions and Applications|type=abstract|journal=Proceedings of the 22nd annual ACM symposium on Theory of computing, STOC 1990|series=|volume=|pages=213–223|year=1990|url=http://www.wisdom.weizmann.ac.il/~naor/PAPERS/bias_abs.html}}&lt;/ref&gt; In 1994 he was the first, with [[Amos Fiat]], to formally study the problem of practical [[broadcast encryption]].&lt;ref name="broadcast_encryption"&gt;{{cite journal|author1=Amos Fiat|author2=Moni Naor|title=Broadcast encryption|type=Extended abstract|journal=Proc. Advances in Cryptology – CRYPTO '93|series=Lecture Notes in Computer Science|volume=773|pages=480–491|year=1994|url=http://www.wisdom.weizmann.ac.il/~naor/PAPERS/broad_abs.html}}&lt;/ref&gt; Along with Benny Chor, Amos Fiat, and Benny Pinkas, he made a contribution to the development of [[Traitor tracing]], a [[copyright infringement]] detection system which works by tracing the source of leaked files rather than by direct [[copy protection]].&lt;ref&gt;{{cite journal|last=Naor|first=Moni|author2=Benny Chor |author3=Amos Fiat |author4=Benny Pinkas |title=Tracing Traitors|journal=Information Theory|date=May 2000|volume=46|issue=3|pages=893–910}}&lt;/ref&gt;

==Honours and awards==
* 2016: (with [[Amos Fiat]]) Awarded the [[Paris Kanellakis Theory and Practice Award]] of the [[Association for Computing Machinery]]&lt;ref&gt;{{cite web|url=http://awards.acm.org/kanellakis/|title=ACM Paris Kanellakis Award|publisher= ACM|accessdate= 6 June 2017}}&lt;/ref&gt;
* 2014: Received the [[Gödel Prize]]. 
* 2008: Named an [[International Association for Cryptologic Research|IACR]] fellow

== References ==
{{Reflist}}

== Sources ==
* [http://www.wisdom.weizmann.ac.il/~naor/ Moni Naor's website at the Weizmann Institute]
* [http://www.wisdom.weizmann.ac.il/~naor/PAPERS/human.pdf Verification of a human in the loop or Identification via the Turing Test]
* [http://www.wisdom.weizmann.ac.il/%7Enaor/PAPERS/vis.ps Visual Cryptography]
* {{MathGenealogy|id=58854|title=Moni Naor}}
* [https://www.iacr.org/fellows/2008/Naor.html IACR fellow 2008 announcement]

{{Gödel Prize laureates |state=autocollapse}}
{{Kanellakis Award laureates |state=autocollapse}}
{{Authority control}}

{{DEFAULTSORT:Naor, Moni}}
[[Category:Israeli computer scientists]]
[[Category:Israeli cryptographers]]
[[Category:University of California, Berkeley alumni]]
[[Category:Weizmann Institute faculty]]
[[Category:Theoretical computer scientists]]
[[Category:Researchers in distributed computing]]
[[Category:Technion – Israel Institute of Technology alumni]]
[[Category:People from Haifa]]
[[Category:Living people]]
[[Category:1961 births]]
[[Category:International Association for Cryptologic Research fellows]]
[[Category:Gödel Prize laureates]]


{{compu-scientist-stub}}
{{Israel-scientist-stub}}</text>
      <sha1>6n20glwg0oucxheivq0vfgafgbxxi6k</sha1>
    </revision>
  </page>
  <page>
    <title>O-minimal theory</title>
    <ns>0</ns>
    <id>30865852</id>
    <revision>
      <id>871039527</id>
      <parentid>732045927</parentid>
      <timestamp>2018-11-28T15:12:01Z</timestamp>
      <contributor>
        <ip>2A01:CB1D:1CC:3700:C066:B37F:70A6:12AC</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8975">{{lowercase|title=o-minimal theory}}
In [[mathematical logic]], and more specifically in [[model theory]], an infinite [[structure (mathematical logic)|structure]] (''M'',&amp;lt;,...) which is [[Total order|totally ordered]] by &lt; is called an '''o-minimal structure''' if and only if every [[definable set|definable]] subset ''X''&amp;nbsp;⊂&amp;nbsp;''M'' (with parameters taken from ''M'') is a finite [[union (set theory)|union]] of [[interval (mathematics)|interval]]s and points.

O-minimality can be regarded as a weak form of [[quantifier elimination]]. A structure ''M'' is o-minimal if and only if every formula with one free variable and parameters in ''M'' is equivalent to a quantifier-free formula involving only the ordering, also with parameters in ''M''. This is analogous to the [[strongly minimal theory|minimal]] structures, which are exactly the analogous property down to equality.

A [[Theory (mathematical logic)|theory]] ''T'' is an '''o-minimal theory''' if every [[Model theory|model]] of ''T'' is o-minimal. It is known that the complete theory ''T'' of an o-minimal structure is an o-minimal theory.&lt;ref&gt;Knight, Pillay and Steinhorn (1986), Pillay and Steinhorn (1988).&lt;/ref&gt; This result is remarkable because, in contrast, the [[complete theory]] of a minimal structure need not be a [[strongly minimal theory]], that is, there may be an elementarily equivalent structure which is not minimal.

==Set-theoretic definition==

O-minimal structures can be defined without recourse to model theory.  Here we define a structure on a nonempty set ''M'' in a set-theoretic manner, as a sequence ''S''&amp;nbsp;=&amp;nbsp;(''S''&lt;sub&gt;''n''&lt;/sub&gt;), ''n''&amp;nbsp;=&amp;nbsp;0,1,2,... such that
# ''S''&lt;sub&gt;''n''&lt;/sub&gt; is a [[Boolean algebra (structure)|boolean algebra]] of subsets of ''M''&lt;sup&gt;''n''&lt;/sup&gt;
# if ''A''&amp;nbsp;∈&amp;nbsp;''S''&lt;sub&gt;''n''&lt;/sub&gt; then ''M''&amp;nbsp;&amp;times;&amp;nbsp;''A'' and ''A''&amp;nbsp;&amp;times;''M'' are in ''S''&lt;sub&gt;''n''+1&lt;/sub&gt;
# the set {(''x''&lt;sub&gt;1&lt;/sub&gt;,...,''x''&lt;sub&gt;''n''&lt;/sub&gt;)&amp;nbsp;∈&amp;nbsp;''M''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;:&amp;nbsp;''x''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''x''&lt;sub&gt;''n''&lt;/sub&gt;} is in ''S''&lt;sub&gt;''n''&lt;/sub&gt;
# if ''A''&amp;nbsp;∈&amp;nbsp;''S''&lt;sub&gt;''n''+1&lt;/sub&gt; and ''π''&amp;nbsp;:&amp;nbsp;''M''&lt;sup&gt;''n''+1&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;''M''&lt;sup&gt;''n''&lt;/sup&gt; is the projection map on the first ''n'' coordinates, then ''π''(''A'')&amp;nbsp;∈&amp;nbsp;''S''&lt;sub&gt;''n''&lt;/sub&gt;.

If ''M'' has a dense linear order without endpoints on it, say &lt;, then a structure ''S'' on ''M'' is called o-minimal if it satisfies the extra axioms

&lt;ol start="5"&gt;
&lt;li&gt;the set {(''x'',''y'')&amp;nbsp;∈&amp;nbsp;''M''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;:&amp;nbsp;''x''&amp;nbsp;&lt;&amp;nbsp;''y''} is in ''S''&lt;sub&gt;2&lt;/sub&gt;
&lt;li&gt;the sets in ''S''&lt;sub&gt;1&lt;/sub&gt; are precisely the finite unions of intervals and points.
&lt;/ol&gt;

The "o" stands for "order", since any o-minimal structure requires an ordering on the underlying set.

==Model theoretic definition==

O-minimal structures originated in model theory and so have a simpler &amp;mdash; but equivalent &amp;mdash; definition using the language of model theory.&lt;ref&gt;Marker (2002) p.81&lt;/ref&gt;  Specifically if ''L'' is a language including a binary relation &lt;, and (''M'',&lt;,...) is an ''L''-structure where &lt; is interpreted to satisfy the axioms of a dense linear order,&lt;ref&gt;The condition that the interpretation of &lt; be dense is not strictly necessary, but it is known that discrete orders lead to essentially trivial o-minimal structures, see, for example, {{MR|0899083}} and {{MR|0943306}}.&lt;/ref&gt; then (''M'',&lt;,...) is called an o-minimal structure if for any definable set ''X''&amp;nbsp;⊆&amp;nbsp;''M'' there are finitely many open intervals ''I''&lt;sub&gt;1&lt;/sub&gt;,..., ''I''&lt;sub&gt;''r''&lt;/sub&gt; with endpoints in ''M''&amp;nbsp;∪&amp;nbsp;{±∞} and a finite set ''X''&lt;sub&gt;0&lt;/sub&gt; such that
:&lt;math&gt;X=X_0\cup I_1\cup\ldots\cup I_r.&lt;/math&gt;

==Examples==

Examples of o-minimal theories are:
* The complete theory of dense linear orders in the language with just the ordering.
* RCF, the [[theory]] of [[real closed field]]s.&lt;ref&gt;Marker (2002) p.99&lt;/ref&gt;
* The complete theory of the [[real number|real field]] with restricted [[analytic function]]s added (i.e. analytic functions on a neighborhood of [0,1]&lt;sup&gt;''n''&lt;/sup&gt;, restricted to [0,1]&lt;sup&gt;''n''&lt;/sup&gt;; note that the unrestricted sine function has infinitely many roots, and so cannot be definable in an o-minimal structure.)
* The complete theory of the real field with a symbol for the [[exponential function]] by [[Wilkie's theorem]]. More generally, the complete theory of the real numbers with [[Pfaffian function]]s added.
* The last two examples can be combined: given any o-minimal expansion of the real field (such as the real field with restricted analytic functions), one can define its Pfaffian closure, which is again an o-minimal structure.&lt;ref&gt;Patrick Speisseger, ''Pfaffian sets and o-minimality,'' in: Lecture notes on o-minimal structures and real analytic geometry, C. Miller, J.-P. Rolin, and P. Speissegger (eds.), Fields Institute Communications vol. 62, 2012, pp.&amp;nbsp;179–218. {{doi|10.1007/978-1-4614-4042-0_5}}&lt;/ref&gt; (The Pfaffian closure of a structure is, in particular, closed under Pfaffian chains where arbitrary definable functions are used in place of polynomials.)

In the case of RCF, the definable sets are the [[semialgebraic set]]s. Thus the study of o-minimal structures and theories generalises [[real algebraic geometry]]. A major line of current research is based on discovering expansions of the real ordered field that are o-minimal. Despite the generality of application, one can show a great deal about the geometry of set definable in o-minimal structures. There is a cell decomposition theorem,&lt;ref&gt;Marker (2002) p.103&lt;/ref&gt; [[Hassler Whitney|Whitney]] and [[Jean-Louis Verdier|Verdier]] [[Stratification (mathematics)|stratification]] theorems and a good notion of dimension and Euler characteristic.

==See also==
* [[Semialgebraic set]]
* [[Real algebraic geometry]]
* [[Strongly minimal theory]]
* [[Weakly o-minimal structure]]
* [[C-minimal theory]]

==Notes==
{{Reflist}}

==References==
* {{cite book | first=Lou | last=van den Dries | title=Tame Topology and o-minimal Structures | year=1998 | publisher=[[Cambridge University Press]] | series=London Mathematical Society Lecture Note Series | volume=248 | location=Cambridge | zbl=0953.03045 | isbn=0-521-59838-9 }}
* {{cite journal | journal=[[Bulletin of the American Mathematical Society]] | last=Marker | first=David | volume=37 | year=2000 | pages=351–357 | title=Review of "Tame Topology and o-minimal Structures" | url=http://www.ams.org/bull/2000-37-03/S0273-0979-00-00866-1/S0273-0979-00-00866-1.pdf | doi=10.1090/S0273-0979-00-00866-1 | issue=3 }}
* {{cite book | last=Marker | first=David | title=Model theory: An introduction | series=Graduate Texts in Mathematics | volume=217 | location=New York, NY | publisher=[[Springer-Verlag]] | year=2002 | isbn=0-387-98760-6 | zbl=1003.03034 }}
* {{cite journal |last=Pillay |first=Anand |author2=Steinhorn, Charles  |year=1986 |title=Definable Sets in Ordered Structures I |journal=[[Transactions of the American Mathematical Society]] |volume=295 | issue=2 | pages=565–592 |url=http://www.ams.org/journals/tran/1986-295-02/S0002-9947-1986-0833697-X/S0002-9947-1986-0833697-X.pdf |doi=10.2307/2000052 |jstor=2000052 | zbl=0662.03023 }}
* {{cite journal |author=Knight, Julia | authorlink = Julia F. Knight|author2=Pillay, Anand |author3=Steinhorn, Charles  |year=1986 |title=Definable Sets in Ordered Structures II |journal=[[Transactions of the American Mathematical Society]] |volume=295 |pages=593–605 |doi=10.2307/2000053 |jstor=2000053 |issue=2 | zbl=0662.03024  }}
* {{cite journal |last=Pillay |first=Anand |author2=Steinhorn, Charles  |year=1988 |title=Definable Sets in Ordered Structures III | journal=[[Transactions of the American Mathematical Society]] | volume=309 | pages=469–476 | doi=10.2307/2000920 | jstor=2000920 | issue=2 | zbl=0707.03024 }}
* {{cite journal | last=Wilkie | first=A.J. | authorlink=Alex Wilkie | title=Model completeness results for expansions of the ordered field of real numbers by restricted Pfaffian functions and the exponential function | journal=[[Journal of the American Mathematical Society]] | year=1996 | volume=9 | url=https://www.ams.org/jams/1996-9-04/S0894-0347-96-00216-0/S0894-0347-96-00216-0.pdf | doi=10.1090/S0894-0347-96-00216-0 | pages=1051 | issue=4     }}
* {{cite journal | last1=Denef | first1=J. | last2=van den Dries| first2= L. | title=''p''-adic and real subanalytic sets | journal=[[Annals of Mathematics]] | volume=128 | year=1989 | jstor=1971463 | pages=79–138 | issue=1 | doi = 10.2307/1971463 }}

==External links==
* [http://www.logique.jussieu.fr/modnet/Publications/Preprint%20server/ ''Model Theory preprint server'']
* [http://www.maths.manchester.ac.uk/raag/ ''Real Algebraic and Analytic Geometry Preprint Server'']

[[Category:Model theory]]
[[Category:Topology]]
[[Category:Real algebraic geometry]]</text>
      <sha1>252ymrl96r6gvf3mpfeasts7jz6jow8</sha1>
    </revision>
  </page>
  <page>
    <title>Offered load</title>
    <ns>0</ns>
    <id>22451128</id>
    <revision>
      <id>863425534</id>
      <parentid>863425403</parentid>
      <timestamp>2018-10-10T17:56:01Z</timestamp>
      <contributor>
        <ip>2001:16A2:5289:8500:74BA:EC08:4CE1:B28C</ip>
      </contributor>
      <comment>Anil</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="942">In the mathematical theory of probability, '''offered load''' is a concept in queuing theory. The offered load is a measure of traffic in a queue. The offered load is given by [[Little's law]]: the arrival rate into the queue (symbolized with [[lambda|λ]]) multiplied by the mean holding time (symbolized by [[Tau|τ]]), the average amount of time spent by items in the queue. Offered load is expressed in [[Erlang unit]]s or [[call-second]]s per hour,&lt;ref&gt;{{cite book | title = Fundamentals of Telecommunications | page = 57 | first = Roger L. | last = Freeman | publisher = John Wiley | year = 2005 | isbn = 0471710458}}&lt;/ref&gt; a dimensionless measure. 

==References==
* Robert B. Cooper. [http://www.cse.fau.edu/~bob/publications/IntroToQueueingTheory_Cooper.pdf Introduction to Queuing theory]. North Holland, 1981, Second edition. {{ISBN|0-444-00379-7}}. Chapter 1, page 4.
{{Reflist}}

{{probability-stub}}
[[Category:Queueing theory]]</text>
      <sha1>7ku5bt0trhz3mvln3oxhgxjyidhawsz</sha1>
    </revision>
  </page>
  <page>
    <title>Ordered graph</title>
    <ns>0</ns>
    <id>3934869</id>
    <revision>
      <id>860811944</id>
      <parentid>787435852</parentid>
      <timestamp>2018-09-23T06:45:13Z</timestamp>
      <contributor>
        <ip>100.36.90.194</ip>
      </contributor>
      <comment>Dechter's "Constraint Processing" page 86 uses the word "adjacent" instead. So the sentence now better matches the reference material.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4231">{{No footnotes|date=March 2010}}

An '''ordered graph''' is a [[Graph (discrete mathematics)|graph]] with a [[total order]] over its nodes.

In an ordered graph, the parents of a node are the nodes that are adjacent to it and precede it in the ordering&lt;ref&gt;Page 86 Dechter. (2003). Constraint Processing&lt;/ref&gt;. More precisely, &lt;math&gt;n&lt;/math&gt; is a parent of &lt;math&gt;m&lt;/math&gt; in the ordered graph &lt;math&gt;\langle N,E,&lt; \rangle&lt;/math&gt; if &lt;math&gt;(n,m) \in E&lt;/math&gt; and &lt;math&gt;n &lt; m&lt;/math&gt;. The width of a node is the number of its parents, and the width of an ordered graph is the maximal width of its nodes.

The '''induced graph''' of an ordered graph is obtained by adding some edges to an ordering graph, using the method outlined below. The '''induced width''' of an ordered graph is the width of its induced graph. &lt;ref&gt;Page 87 Dechter. (2003). Constraint Processing&lt;/ref&gt;

Given an ordered graph, its induced graph is another ordered graph obtained by joining some pairs of nodes that are both parents of another node. In particular, nodes are considered in turn according to the ordering, from last to first. For each node, if two of its parents are not joined by an edge, that edge is added. In other words, when considering node &lt;math&gt;n&lt;/math&gt;, if both &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;l&lt;/math&gt; are parents of it and are not joined by an edge, the edge &lt;math&gt;(m,l)&lt;/math&gt; is added to the graph. Since the parents of a node are always connected with each other, the induced graph is always [[Chordal graph|chordal]].

As an example, the induced graph of an ordered graph is calculated. The ordering is represented by the position of its nodes in the figures: a is the last node and d is the first.

{| cellpadding=10 style="border: gray solid thin;"
|-
| [[Image:Induced-1.svg]]
| [[Image:Induced-2.svg]]
| [[Image:Induced-3.svg]]
|-
| The original graph.
| Edge added considering the parents of &lt;math&gt;a&lt;/math&gt;
| Edge added considering the parents of &lt;math&gt;b&lt;/math&gt;
|}

Node &lt;math&gt;a&lt;/math&gt; is considered first. Its parents are &lt;math&gt;b&lt;/math&gt; and &lt;math&gt;c&lt;/math&gt;, as they are both joined to &lt;math&gt;a&lt;/math&gt; and both precede &lt;math&gt;a&lt;/math&gt; in the ordering. Since they are not joined by an edge, one is added.

Node &lt;math&gt;b&lt;/math&gt; is considered second. While this node only has &lt;math&gt;d&lt;/math&gt; as a parent in the original graph, it also has &lt;math&gt;c&lt;/math&gt; as a parent in the partially built induced graph. Indeed, &lt;math&gt;c&lt;/math&gt; is joined to &lt;math&gt;b&lt;/math&gt; and also precede &lt;math&gt;b&lt;/math&gt; in the ordering. As a result, an edge joining &lt;math&gt;c&lt;/math&gt; and &lt;math&gt;d&lt;/math&gt; is added.

Considering &lt;math&gt;d&lt;/math&gt; does not produce any change, as this node has no parents.

Processing nodes in order matters, as the introduced edges may create new parents, which are then relevant to the introduction of new edges. The following example shows that a different ordering produces a different induced graph of the same original graph. The ordering is the same as above but &lt;math&gt;b&lt;/math&gt; and &lt;math&gt;c&lt;/math&gt; are swapped.

{| cellpadding=10 style="border: gray solid thin;"
|-
| [[Image:Induced-4.svg]]
| [[Image:Induced-5.svg]]
|-
| Same graph, but the order of &lt;math&gt;b&lt;/math&gt; and &lt;math&gt;c&lt;/math&gt; is swapped
| Graph after considering &lt;math&gt;a&lt;/math&gt;
|}

As in the previous case, both &lt;math&gt;b&lt;/math&gt; and &lt;math&gt;c&lt;/math&gt; are parents of &lt;math&gt;a&lt;/math&gt;. Therefore, an edge between them is added. According to the new order, the second node that is considered is &lt;math&gt;c&lt;/math&gt;. This node has only one parent (&lt;math&gt;b&lt;/math&gt;). Therefore, no new edge is added. The third considered node is &lt;math&gt;b&lt;/math&gt;. Its only parent is &lt;math&gt;d&lt;/math&gt;. Indeed, &lt;math&gt;b&lt;/math&gt; and &lt;math&gt;c&lt;/math&gt; are not joined this time. As a result, no new edge is introduced. Since &lt;math&gt;d&lt;/math&gt; has no parent as well, the final induced graph is the one above. This induced graph differs from the one produced by the previous ordering.

==See also==

*[[Directed graph]]
*[[Local consistency]]

==References==

*{{cite book
| first=Rina
| last=Dechter
| title=Constraint Processing
| publisher=Morgan Kaufmann
| year=2003
| url=http://www.ics.uci.edu/~dechter/books/index.html
}} {{ISBN|1-55860-890-7}}

[[Category:Constraint programming]]
[[Category:Extensions and generalizations of graphs]]</text>
      <sha1>764rlr81hp26nab81g5xa1f79ytzcb0</sha1>
    </revision>
  </page>
  <page>
    <title>Pierre Boutroux</title>
    <ns>0</ns>
    <id>472456</id>
    <revision>
      <id>828567319</id>
      <parentid>815910890</parentid>
      <timestamp>2018-03-03T10:53:45Z</timestamp>
      <contributor>
        <username>Simon Peter Hughes</username>
        <id>2096716</id>
      </contributor>
      <comment>/* External links */ Commons category and French Wikisource.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6740">{{Infobox scientist
| name        = Pierre Léon Boutroux
| image       = Boutroux 4194445821 f47647d05e o.jpg
| birth_date  = {{birth date|df=y|1880|12|6}}
| birth_place = Paris, France
| death_date  = {{death date and age|df=y|1922|8|15|1880|12|6}}
| death_place = 
| residence   = France
| citizenship = 
| nationality = 
| fields      = [[Mathematics]]
| workplaces  = 
| patrons     = 
| education   = 
| alma_mater  = 
| thesis_title =        &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_year =         &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor =    &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for   = 
| influences  = 
| influenced  = 
| awards      = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse      =         &lt;!--(or | spouses = )--&gt;
| partner     =         &lt;!--(or | partners = )--&gt;
| children    = 
| signature   =         &lt;!--(filename only)--&gt;
| signature_alt = 
| footnotes   = 
}}
'''Pierre Léon Boutroux''' ({{IPA-fr|butʁu|lang}}; 6 December 1880 – 15 August 1922) was a [[French people|French]] [[mathematician]] and historian of science. Boutroux is chiefly known for his work in the history and [[philosophy of mathematics]].

==Biography==
He was born in [[Paris]] on 6 December 1880 into a well connected family of the French intelligentsia. His father was the philosopher [[Émile Boutroux]]. His mother was Aline Catherine Eugénie Poincaré, sister of the scientist and mathematician [[Henri Poincaré]]. A cousin of Aline, [[Raymond Poincaré]] was to be [[President of France]].

He occupied the mathematics chair at [[Princeton University]] from 1913 until 1914.&lt;ref&gt;{{cite news |author= |coauthors= |title=Princeton Gets Prof. Boutroux |url=https://pqasb.pqarchiver.com/csmonitor_historic/access/221753652.html?dids=221753652:221753652&amp;FMT=ABS&amp;FMTS=ABS:AI&amp;date=Apr+26,+1913&amp;author=&amp;pub=Christian+Science+Monitor&amp;desc=PRINCETON+GETS+PROF.+BOUTROUX&amp;pqatl=google |quote=Prof. Pierre Boutroux of Poitiers, France, will join the faculty of Princeton University next fall, according to a cable message received here Friday by Dr. Hibben. |work=[[Christian Science Monitor]] |date=April 26, 1913 |accessdate=2010-11-09 }}&lt;/ref&gt; He occupied the History of sciences chair from 1920 to 1922.

Boutroux published his major work ''Les principes de l'analyse mathématique'' in two volumes; ''Volume 1'' in 1914 and ''Volume 2'' in 1919. This is a comprehensive view of the whole field of mathematics at the time.

He was an Invited Speaker of the [[International Congress of Mathematicians|ICM]] in 1904 at Heidelberg, in 1908 at Rome, and in 1920 at Strasbourg.&lt;ref&gt;{{cite book|chapter-url=http://www.mathunion.org/ICM/ICM1920/Main/icm1920.0271.0299.ocr.pdf|pages=271–299|year=1921|title=Compte rendu du Congrès international des mathématiciens tenu à Strasbourg du 22 au 30 Septembre 1920|chapter=''Sur une équation différentielle et une famille de fonctions entières'' par Pierre Boutroux}}&lt;/ref&gt;

He died on 15 August 1922, aged 41 years.

==Works==
* ''L'Imagination et les mathématiques selon [[René Descartes|Descartes]]'' (1900)
* ''Sur quelques propriétés des fonctions entières'' (1903)
* ''Œuvres de [[Blaise Pascal]], publiées suivant l'ordre chronologique, avec documents complémentaires, introductions et notes, par [[Léon Brunschvicg]] et Pierre Boutroux'' (1908)
* ''Leçons sur les fonctions définies par les équations différentielles du premier ordre, professées au Collège de France'' (1908)&lt;ref&gt;{{cite journal|author=Moore, C. L. E.|authorlink=Clarence Lemuel Elisha Moore|title=Review: ''Leçons sur les Fonctions définies par les Équations différentielles du premier Ordre''. Par Pierre Boutroux|journal=Bull. Amer. Math. Soc.|year=1910|volume=16|issue=6|pages=318–320|url=http://www.ams.org/journals/bull/1910-16-06/S0002-9904-1910-01911-X/S0002-9904-1910-01911-X.pdf|doi=10.1090/s0002-9904-1910-01911-x}}&lt;/ref&gt;
* ''Les Principes de l'analyse mathématique, exposé historique et critique'' (2 volumes, 1914-1919)&lt;ref&gt;{{cite journal|author=Shaw, James Byrnie|title=Review: ''Les Principes de l'Analyse mathématique''. Par Pierre Boutroux. Tome premiere|journal=Bull. Amer. Math. Soc.|
year=1914|volume=24|issue=1|pages=32–36|url=http://www.ams.org/journals/bull/1914-21-01/S0002-9904-1914-02569-8/S0002-9904-1914-02569-8.pdf|doi=10.1090/S0002-9904-1914-02569-8}}&lt;/ref&gt; [http://gallica.bnf.fr/ark:/12148/bpt6k99368f.pdf Texte en ligne 1] [http://gallica.bnf.fr/ark:/12148/bpt6k993762.pdf 2]
:&lt;small&gt;Contient : (I) Les nombres, les grandeurs, les figures, le calcul combinatoire, le calcul algébrique, calcul des fonctions, l'algèbre géométrique. (2) La géométrie algébrique. Extensions de l'algèbre et constructions logiques. Extensions de l'algèbre ; les développements en séries. La méthode analytique en mathématiques. Analyse infinitésimale. Analyse des principes mathématiques. Analyse de la notion de fonction.&lt;/small&gt; 
* ''L'Idéal scientifique des mathématiciens dans l'antiquité et dans les temps modernes'' (1920)&lt;ref&gt;{{cite journal|author=Young, J. W.|authorlink=John Wesley Young|title=Review: L'Idéal Scientifique des Mathématiciens dans l'Antiquité et dans les Temps Modernes''. By Pierre Boutroux|year=1923|volume=29|issue=10|pages=470–473|url=http://www.ams.org/journals/bull/1923-29-10/S0002-9904-1923-03800-7/S0002-9904-1923-03800-7.pdf|doi=10.1090/S0002-9904-1923-03800-7|journal=Bulletin of the American Mathematical Society}}&lt;/ref&gt; [http://gallica.bnf.fr/ark:/12148/bpt6k99369s.pdf Texte en ligne]
* ''Les Mathématiques'' (1922)

==References==
{{reflist}}

==Further reading==
*R S Calinger, Biography in Dictionary of Scientific Biography (New York 1970-1990).
*L Brunschvicg, L'oeuvre de Pierre Boutroux, Revue de métaphysique et de morale 29-30 (1922), 285-289.
*Lettre de M Pierre Boutroux a M Mittag-Leffler, in The mathematical heritage of Henri Poincaré 2 (Providence, R.I., 1983), 441-445.

==External links==
*{{Commonscat-inline}}
*{{wikisourcelang-inline|fr|Auteur:Pierre Boutroux}}
* {{Internet Archive author |sname=Pierre Boutroux}}
* [https://web.archive.org/web/20031210041805/http://www-gap.dcs.st-and.ac.uk/~history/Mathematicians/Boutroux.html Boutroux summary&lt;!-- bot-generated title --&gt;] at www-gap.dcs.st-and.ac.uk

{{Authority control}}

{{DEFAULTSORT:Boutroux, Pierre}}
[[Category:1880 births]]
[[Category:1922 deaths]]
[[Category:Collège de France faculty]]
[[Category:Princeton University faculty]]
[[Category:Mathematical analysts]]
[[Category:19th-century French mathematicians]]
[[Category:20th-century French mathematicians]]


{{france-mathematician-stub}}</text>
      <sha1>ax2qftypbgp8zx434h2figv2273ue0c</sha1>
    </revision>
  </page>
  <page>
    <title>Pseudo-order</title>
    <ns>0</ns>
    <id>17543768</id>
    <revision>
      <id>742702011</id>
      <parentid>537194190</parentid>
      <timestamp>2016-10-05T07:31:16Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2766">In [[constructivism (mathematics)|constructive mathematics]], a '''pseudo-order''' is a constructive generalisation of a [[linear order]] to the continuous case. The usual [[trichotomy (mathematics)|trichotomy law]] does not hold in the constructive continuum because of its [[indecomposability]], so this condition is weakened. 

A pseudo-order is a [[binary relation]] satisfying the following conditions:
# It is not possible for two elements to each be less than the other. That is, &lt;math&gt;\forall x,y: \neg\;(x &lt; y \;\wedge\; y &lt; x)&lt;/math&gt;.
# For all {{mvar|x}}, {{mvar|y}}, and {{mvar|z}}, if {{math|''x'' &lt; ''y''}} then either {{math|''x'' &lt; ''z''}} or {{math|''z'' &lt; ''y''}}. That is, &lt;math&gt;\forall x,y,z: x &lt; y \;\to\; (x &lt; z \;\vee\; z &lt; y)&lt;/math&gt;.
# Every two elements for which neither one is less than the other must be equal. That is, &lt;math&gt;\forall x,y: \neg\;(x &lt; y \;\vee\; y &lt; x) \;\to\; x = y&lt;/math&gt;
This first condition is simply [[antisymmetric relation|antisymmetry]]. It follows from the first two conditions that a pseudo-order is [[transitive relation|transitive]]. The second condition is often called ''co-transitivity'' or ''comparison'' and is the constructive substitute for trichotomy. In general, given two elements of a pseudo-ordered set, it is not always the case that either one is less than the other or else they are equal, but given any nontrivial interval, any element is either above the lower bound, or below the upper bound.

The third condition is often taken as the definition of equality. The natural [[apartness relation]] on a pseudo-ordered set is given by
: &lt;math&gt;x \# y \;\leftrightarrow\; x &lt; y \;\vee\; y &lt; x&lt;/math&gt;
and equality is defined by the negation of apartness.

The negation of the pseudo-order is a [[partial order]] which is close to a [[total order]]: if ''x'' ≤ ''y'' is defined as the negation of ''y'' &lt; ''x'', then we have
: &lt;math&gt; \neg\;(\neg\;(x \le y) \;\wedge\; \neg\;(y \le x)) .&lt;/math&gt;
Using [[classical logic]] one would then conclude that ''x'' ≤ ''y'' or ''y'' ≤ ''x'', so it would be a total order. However, this inference is not valid in the constructive case.

The prototypical pseudo-order is that of the real numbers: one real number is less than another if [[there exists]] (one can construct) a rational number greater than the former and less than the latter. In other words, ''x'' &lt; ''y'' if there exists a rational number ''z'' such that ''x'' &lt; ''z'' &lt; ''y''.

==References==
* [[Arend Heyting]] (1966) Intuitionism: An introduction. Second revised edition North-Holland Publishing Co., Amsterdam.
https://books.google.com/books/about/Intuitionism.html?id=4rhLAAAAMAAJ
&lt;references /&gt;

[[Category:Constructivism (mathematics)]]
[[Category:Order theory]]


{{mathlogic-stub}}</text>
      <sha1>mr330ex1yaoon75qo7ud393b0wpcn8l</sha1>
    </revision>
  </page>
  <page>
    <title>Quillen's lemma</title>
    <ns>0</ns>
    <id>35922668</id>
    <revision>
      <id>678479271</id>
      <parentid>649705189</parentid>
      <timestamp>2015-08-29T17:04:25Z</timestamp>
      <contributor>
        <username>Dexbot</username>
        <id>16752040</id>
      </contributor>
      <minor/>
      <comment>Bot: Deprecating [[Template:Cite doi]] and some minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="922">In [[algebra]], '''Quillen's lemma''' states that an [[endomorphism]] of a [[simple module]] over the enveloping algebra of a finite-dimensional [[Lie algebra]] over a [[field (algebra)|field]] ''k'' is algebraic over&amp;nbsp;''k''. In contrast to a version of [[Schur's lemma]] due to Dixmier, it does not require ''k'' to be uncountable.  [[Daniel Quillen|Quillen]]'s original short proof uses [[generic flatness]].&lt;!-- indeed, we can just give a proof below. Taku --&gt;

== References ==
*{{Cite journal | last1 = Quillen | first1 = D. | authorlink = Daniel Quillen| doi = 10.1090/S0002-9939-1969-0238892-4 | title = On the endomorphism ring of a simple module over an enveloping algebra | journal = Proceedings of the American Mathematical Society | volume = 21 | pages = 171–172 | year = 1969 | pmid =  | pmc = }}

{{algebra-stub}}

[[Category:Lemmas]]
[[Category:Theorems in abstract algebra]]
[[Category:Lie algebras]]</text>
      <sha1>pnx0nqu94kppmu7zufm6sdwh9gas86w</sha1>
    </revision>
  </page>
  <page>
    <title>Ruy de Queiroz</title>
    <ns>0</ns>
    <id>32561553</id>
    <revision>
      <id>857403140</id>
      <parentid>787640561</parentid>
      <timestamp>2018-08-31T13:25:26Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9350">'''Ruy J. Guerra B. de Queiroz''' (born January 11, 1958 in [[Recife]]) is an associate professor at Universidade Federal de Pernambuco and holds significant works in the research fields of Mathematical logic, proof theory, foundations of mathematics and philosophy of mathematics.&lt;ref&gt;
{{cite book
  | last1 = GABBAY
  | first1 = Dov M.
  | last2 = WOODS
  | first2 = John
  | title = The International Directory of Logicians
  | date = 2009-04-27
  | publisher = College Publications
  | url = https://books.google.com/books?id=MUpoPgAACAAJ&amp;dq=international+directory+of+logicians
  | isbn = 978-1-904987-90-1
  | accessdate = 2011-07-28 
}}
&lt;/ref&gt; He is the founder of the [[Workshop on Logic, Language, Information and Computation]] (WoLLIC), which has been organised annually since 1994, typically in June or July.

Ruy de Queiroz received his B.Eng in Electrical Engineering from Escola Politecnica de Pernambuco in 1980, his M.Sc in Informatics from [[Universidade Federal de Pernambuco]] in 1984, and his Ph.D in Computing from the [[Imperial College]], [[London (England)|London]] in 1990, for which he defended the Dissertation ''Proof Theory and Computer Programming. An Essay into the Logical Foundations of Computation''.

== Research profile ==
In the late 1980s, Ruy de Queiroz has offered a reformulation of [[Martin-Löf type theory]] based on a novel reading of [[Ludwig Wittgenstein|Wittgenstein]]’s "meaning-is-use", where the explanation of the consequences of a given proposition gives the meaning to the logical constant dominating the proposition. This amounts to a non-dialogical interpretation of logical constants via the effect of elimination rules over introduction rules, which finds a parallel in [[Paul Lorenzen]]'s and [[Jaakko Hintikka]]'s dialogue/game-semantics. This led to a type theory called "Meaning as Use Type Theory".&lt;ref&gt;de Queiroz, R. "Meaning as grammar plus consequences", in Dialectica 45(1):83-86.&lt;/ref&gt; In reference to the use of Wittgenstein's dictum, he has shown that the aspect concerning the explanation of the consequences of a proposition is present since a very early date when in a letter to [[Bertrand Russell]], where Wittgenstein refers to the universal quantifier only having meaning when one sees what follows from it.&lt;ref&gt;de Queiroz, R. "The mathematical language and its semantics: to show the consequences of a proposition is to give its meaning". In Weingartner, Paul and Schurz, Gerhard, editors, Reports of the Thirteenth International Wittgenstein Symposium 1988, volume 18 of Schriftenreihe der Wittgenstein-Gesellschaft, Vienna, 304pp. Hölder-Pichler-Tempsky, pp. 259–266. Symposium held in Kirchberg/Wechsel, Austria, August 14–21, 1988.&lt;/ref&gt;

Since later in the 1990s, Ruy de Queiroz has been engaged, jointly with [[Dov Gabbay]], in a program of providing a general account of the functional interpretation of classical and non-classical logics via the notion of labeled natural deduction. As a result, novel accounts of the functional interpretation of the existential quantifier, as well as the notion of propositional equality, were put forward, the latter allowing for a recasting of [[Richard Statman]]'s notion of direct computation, and a novel approach to the dichotomy "intensional versus extensional" accounts of propositional equality via the [[Curry-Howard correspondence]].

Since the early 2000s, Ruy de Queiroz has been investigating, jointly with [[Anjolina de Oliveira]], a geometric perspective of natural deduction based on a graph-based account of [[Kneale]]'s symmetric natural deduction.&lt;ref&gt;{{cite arXiv|eprint=1107.1901|title=Propositional equality, identity types, and direct computational paths|language=English|author1=de Queiroz|author2=de Oliveira|class=cs.LO|year=2011}}&lt;/ref&gt;

== Service to the profession ==
* Member of the Advisory Group to the Rolf Schock Prize in Logic and Philosophy (2008 and 2011) Prize Committee (Royal Swedish Academy of Sciences);
* Editor-in-Chief, Logic Journal of the Interest Group in Pure and Applied Logics, Oxford University Press, 1993–present;
* Associate Editor, Journal of Computer System and Sciences, Coordinator and Co-founder (with D. Gabbay), Interest Group in Pure and Applied Logics (IGPL), the clearing house of the European Association for Logic, Language and Information (FoLLI), 1990–present;
* Guest Editor of several volumes (in partnership with several world standing logicians and computer scientists such as John Baldwin, [[Sergei N. Artemov]], Bruno Poizat, Dexter Kozen, Angus Macintyre, Grigori Mints, Wilfrid Hodges, Anuj Dawar, Hiroakira Ono, Makoto Kanzawa, Daniel Leivant, Lev Beklemishev) of Annals of Pure and Applied Logic, Theoretical Computer Science, Information and Computation, Journal of Computer System and Sciences, Fundamenta Informaticae, several volumes of Electronic Notes in Theoretical Computer Science;
* Creator and Prime Organizer of the series of workshops WoLLIC (http://www.cin.ufpe.br/~wollic);
* Member of the Editorial Board of the International Directory of Logicians, D. Gabbay &amp; J. Woods (eds.), College Publications;
* Elected Member, Council, Association for Symbolic Logic, 2006-2008.

== Key publications ==
#(with de Oliveira, A.) The Functional Interpretation of Direct Computations. Electronic Notes in Theoretical Computer Science 269:19-40, 2011.
#On reduction rules, meaning-as-use, and proof-theoretic semantics, Studia Logica 90(2):211-247, November 2008.
#(with de Oliveira, A.) Geometry of Deduction via Graphs of Proof. In Logic for Concurrency and Synchronisation, R. de Queiroz (ed.), volume 18 of the Trends in Logic series, Kluwer Acad. Pub., Dordrecht, July 2003, {{ISBN|1-4020-1270-5}}, pp.&amp;nbsp;3–88.
#Meaning, function, purpose, usefulness, consequences - interconnected concepts. Logic Journal of the Interest Group in Pure and Applied Logics, 9(5):693-734, September 2001, Oxford Univ. Press.
#(with Gabbay, D.) Labelled Natural Deduction. In Logic, Language and Reasoning. Essays in Honor of Dov Gabbay, H.J. Ohlbach and U. Reyle (eds.), volume 5 of Trends in Logic series, Kluwer Academic Publishers, Dordrecht, June 1999, pp.&amp;nbsp;173–250.
#(with de Oliveira, A.) A Normalization Procedure for the Equational Fragment of Labelled Natural Deduction. Logic Journal of the Interest Group in Pure and Applied Logics, 7(2):173-215, 1999, Oxford Univ. Press. Full version of a paper presented at 2nd WoLLIC'95, Recife, Brazil, July 1995. Abstract appeared in Journal of the Interest Group in Pure and Applied Logics 4(2):330-332, 1996.
#(with Gabbay, D.) The Functional Interpretation of the Existential Quantifier, in Bulletin of the Interest Group in Pure and Applied Logics 3(2-3):243-290, 1995. (Special Issue on Deduction and Language, Guest Editor: Ruth Kempson). Full version of a paper presented at Logic Colloquium '91, Uppsala. Abstract in JSL 58(2):753-754, 1993.
#Normalisation and Language-Games. In Dialectica 48(2):83-123, 1994. (Early version presented at Logic Colloquium '88, Padova. Abstract in JSL 55:425, 1990.)
#(with Gabbay, D.) Extending the Curry-Howard interpretation to linear, relevant and other resource logics, in Journal of Symbolic Logic 57(4):1319-1365. Paper presented at Logic Colloquium '90, Helsinki. Abstract in JSL 56(3):1139-1140, 1991.
#(with Maibaum, T.) Abstract Data Types and Type Theory: Theories as Types, in Zeitschrift für mathematische Logik und Grundlagen der Mathematik 37:149-166.
#(with Maibaum, T.) Proof Theory and Computer Programming, in Zeitschrift für mathematische Logik und Grundlagen der Mathematik 36:389-414.
#A Proof-Theoretic Account of Programming and the Rôle of Reduction Rules, in Dialectica 42(4):265-282.
#de Queiroz, R. de Oliveira, A., &amp; Gabbay, D.: 2011, The Functional Interpretation of Logical Deduction. Vol. 5 of Advances in Logic series. Imperial College Press / World Scientific. {{ISBN|978-981-4360-95-1}}.

== Teaching ==
Ruy de Queiroz has taught several disciplines related to logic and theoretical computer science, including Set Theory, Recursion Theory (as a follow-up to a course given by Solomon Feferman), Logic for Computer Science, Discrete Mathematics, Theory of Computation, Proof Theory, Model Theory, Foundations of Cryptography.  He has had seven Ph.D. students in the fields of Mathematical Logic and Theoretical Computer Science.

== Honors and awards ==
* Tinker Visiting Professorship at [[Stanford University]], awarded by The Tinker Foundation, after the nomination given by [[Solomon Feferman]] and [[Grigori Mints]], 2005;
* Overseas Research Student scholarship award, Committee of Vice-Chancellors and Principals, [[University of London]], 1985-1987.

== References ==
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

== External links ==
* [http://www.cin.ufpe.br/~ruy/english.html Ruy Guerra's professional profile home page]

{{authority control}}

{{DEFAULTSORT:Queiroz, Ruy de}}
&lt;!--- Categories ---&gt;
[[Category:Articles created via the Article Wizard]]
[[Category:Brazilian mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Philosophers of mathematics]]
[[Category:Mathematical logicians]]
[[Category:Living people]]
[[Category:1958 births]]</text>
      <sha1>9vaz4iif61i6z5p7qjv7p8zp75yyfwe</sha1>
    </revision>
  </page>
  <page>
    <title>Southeast (disambiguation)</title>
    <ns>0</ns>
    <id>768388</id>
    <revision>
      <id>717864268</id>
      <parentid>717795456</parentid>
      <timestamp>2016-04-30T05:27:06Z</timestamp>
      <contributor>
        <username>Bgwhite</username>
        <id>264323</id>
      </contributor>
      <comment>[[WP:CHECKWIKI]] error fix #97. No content between TOC and first headline per [[WP:TOC]] and [[WP:LEAD]]. This is an accessibility issue for users of screen readers.  Do general fixes and cleanup if needed. - using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2727">{{wiktionary|southeast|southeastern}}
'''[[Southeast]]''' is a compass point.

'''Southeast''', '''south-east''', '''south east''', '''southeastern''', '''south-eastern''', or '''south eastern''' may also refer to:
*[[Southeast (direction)]], an intercardinal direction
{{TOC right}}

== Places ==
* [[South East Asia]]
* [[Limestone Coast|South east of South Australia]]
* [[South-East District, Botswana]]
* [[Southeast Region, Brazil]]
* [[South East England]]
* [[Southeast Township, Indiana]], United States
* [[Southeast Ireland]]
* [[South East London (disambiguation)]]
* [[South Eastern Region]], Malta
* [[Southeast, New York]], United States
* [[Downstate New York|Southeastern New York]], United States
* [[Southeastern, Pennsylvania]], United States
* [[South-East, Russian SFSR]] (1920–1924), a former administrative division
* [[South East San Diego]], United States
* [[South East District, Singapore]]
* [[Southeastern United States]]
* Southeastern Vietnam, or [[Đông Nam Bộ]]
* [[Southeast, Washington, D.C.]], United States

== Schools ==
* [[Southeastern University (disambiguation)]]
* [[Southeastern Louisiana University]]
* [[Southeastern Baptist Theological Seminary]], North Carolina

== Rail transport ==
* [[South Eastern Railway (India)]], an Indian railway zone
* [[Southeastern (train operating company)]], a British train company, in service from 2006 through the present
* [[South Eastern Trains]], a British train company, in public ownership, that provided train services from 2003 to 2006
* [[Connex South Eastern]], a British train company in service from 1996 to 2003
* [[South Eastern Railway (UK)]], a British railway company formed in 1836

== Other uses ==
* [[South East Motor Corporation]], a motor vehicle manufacturer in Fuzhou, China
* [[Southeast (Metro-North station)]], railway station serving Southeast, New York

==See also==
*[[Sud-Est (disambiguation)]], French for "southeast"
*[[Yugo-Vostochny (disambiguation)]], Russian for "southeastern"
*{{Intitle|southeast OR "south-east" OR "south east" OR  southeastern OR  "south-eastern" OR "south eastern"|All articles with "Southeast" (or a variant) in the title}}
*{{Intitle|(southeast OR "south-east" OR "south east" OR  southeastern OR  "south-eastern" OR "south eastern") (university OR college OR school)|All articles with "Southeast" (or a variant) and "University/College/School" in the title}}
*{{Intitle|(southeast OR "south-east" OR "south east" OR  southeastern OR  "south-eastern" OR "south eastern") (region OR district OR province)|All articles with "Southeast" (or a variant) and "Region/District/Province" in the title}}

{{Disambiguation|geo|school}}
[[Category:Orientation (geometry)]]

[[id:Tenggara]]</text>
      <sha1>mzyx70pbe2gc45wjkqe5apm9ins4e51</sha1>
    </revision>
  </page>
  <page>
    <title>Steinhaus–Moser notation</title>
    <ns>0</ns>
    <id>305463</id>
    <revision>
      <id>862680749</id>
      <parentid>862610661</parentid>
      <timestamp>2018-10-05T23:56:55Z</timestamp>
      <contributor>
        <username>Xayahrainie43</username>
        <id>34489455</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6426">In [[mathematics]], '''[[Hugo Steinhaus|Steinhaus]]–[[Leo Moser|Moser]] notation''' is a [[mathematical notation|notation]] for expressing certain extremely [[large number]]s. It is an extension of [[Hugo Steinhaus|Steinhaus]]'s polygon notation.&lt;ref&gt;Hugo Steinhaus, ''Mathematical Snapshots'', Oxford University Press 1969&lt;sup&gt;3&lt;/sup&gt;, {{ISBN|0195032675}}, pp. 28-29&lt;/ref&gt;

== Definitions ==
:[[image:Triangle-n.svg|20px|n in a triangle]] a number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} in a '''triangle''' means {{math|&lt;VAR &gt;n&lt;/VAR &gt;&lt;sup&gt;&lt;VAR &gt;n&lt;/VAR&gt;&lt;/sup&gt;}}.

:[[image:Square-n.svg|20px|n in a square]] a number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} in a '''square''' is equivalent to "the  number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} inside {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} triangles, which are all nested."

:[[image:Pentagon-n.svg|20px|n in a pentagon]] a number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} in a '''pentagon''' is equivalent with "the  number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} inside {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} squares, which are all nested."

etc.: {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} written in an ({{math|&lt;VAR &gt;m&lt;/VAR &gt; + 1}})-sided polygon is equivalent with "the  number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} inside {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} nested {{math|&lt;VAR &gt;m&lt;/VAR &gt;}}-sided polygons". In a series of nested polygons, they are [[Association (mathematics)|associated]] inward. The number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} inside two triangles is equivalent to {{math|&lt;VAR &gt;n&lt;/VAR &gt;&lt;sup&gt;&lt;VAR &gt;n&lt;/VAR &gt;&lt;/sup&gt;}} inside one triangle, which is equivalent to {{math|&lt;VAR &gt;n&lt;/VAR &gt;&lt;sup&gt;&lt;VAR &gt;n&lt;/VAR &gt;&lt;/sup&gt;}} raised to the power of {{math|&lt;VAR &gt;n&lt;/VAR &gt;&lt;sup&gt;&lt;VAR &gt;n&lt;/VAR &gt;&lt;/sup&gt;}}.

Steinhaus defined only the triangle, the square, and the '''circle''' [[image:Circle-n.svg|20px|n in a circle]], which is equivalent to the pentagon defined above.

== Special values ==
Steinhaus defined:
*'''mega''' is the number equivalent to 2 in a circle: {{h:title|&lt;nowiki&gt;C(2) = S(S(2))&lt;/nowiki&gt;|②}}
*'''megiston''' is the number equivalent to 10 in a circle: ⑩

'''Moser's number''' is the number represented by "2 in a megagon", where a '''megagon''' is a polygon with "mega" sides, not to be confused with the [[megagon]], with one million sides.

Alternative notations:
*use the functions square(x) and triangle(x)
*let {{math|M(&lt;VAR &gt;n&lt;/VAR &gt;, &lt;VAR &gt;m&lt;/VAR &gt;, &lt;VAR &gt;p&lt;/VAR &gt;)}} be the number represented by the number {{math|&lt;VAR &gt;n&lt;/VAR &gt;}} in {{math|&lt;VAR &gt;m&lt;/VAR &gt;}} nested {{math|&lt;VAR &gt;p&lt;/VAR &gt;}}-sided polygons; then the rules are:
**&lt;math&gt;M(n,1,3) = n^n&lt;/math&gt;
**&lt;math&gt;M(n,1,p+1) = M(n,n,p)&lt;/math&gt;
**&lt;math&gt;M(n,m+1,p) = M(M(n,1,p),m,p)&lt;/math&gt;
* and
**mega =&amp;nbsp;&lt;math&gt;M(2,1,5)&lt;/math&gt;
**megiston =&amp;nbsp;&lt;math&gt;M(10,1,5)&lt;/math&gt;
**moser =&amp;nbsp;&lt;math&gt;M(2,1,M(2,1,5))&lt;/math&gt;

==Mega==
A mega, ②, is already a very large number, since ② =
square(square(2)) = square(triangle(triangle(2))) =
square(triangle(2&lt;sup&gt;2&lt;/sup&gt;)) = 
square(triangle(4)) =
square(4&lt;sup&gt;4&lt;/sup&gt;) =
square(256) =
triangle(triangle(triangle(...triangle(256)...)))  [256 triangles] =
triangle(triangle(triangle(...triangle(256&lt;sup&gt;256&lt;/sup&gt;)...)))  [255 triangles] ~
triangle(triangle(triangle(...triangle(3.2 &amp;times; 10&lt;sup&gt;616&lt;/sup&gt;)...)))  [254 triangles] =
...

Using the other notation:

mega = M(2,1,5) = M(256,256,3)

With the function &lt;math&gt;f(x)=x^x&lt;/math&gt; we have mega = &lt;math&gt;f^{256}(256)  = f^{258}(2)&lt;/math&gt; where the superscript denotes a [[Iterated function|functional power]], not a numerical power.

We have (note the convention that powers are evaluated from right to left):
*M(256,2,3) = &lt;math&gt;(256^{\,\!256})^{256^{256}}=256^{256^{257}}&lt;/math&gt;
*M(256,3,3) = &lt;math&gt;(256^{\,\!256^{257}})^{256^{256^{257}}}=256^{256^{257}\times 256^{256^{257}}}=256^{256^{257+256^{257}}}&lt;/math&gt;≈&lt;math&gt;256^{\,\!256^{256^{257}}}&lt;/math&gt;
Similarly:
*M(256,4,3) ≈ &lt;math&gt;{\,\!256^{256^{256^{256^{257}}}}}&lt;/math&gt;
*M(256,5,3) ≈ &lt;math&gt;{\,\!256^{256^{256^{256^{256^{257}}}}}}&lt;/math&gt;
etc.

Thus:
*mega = &lt;math&gt;M(256,256,3)\approx(256\uparrow)^{256}257&lt;/math&gt;, where &lt;math&gt;(256\uparrow)^{256}&lt;/math&gt; denotes a functional power of the function &lt;math&gt;f(n)=256^n&lt;/math&gt;.

Rounding more crudely (replacing the 257 at the end by 256), we get mega ≈ &lt;math&gt;256\uparrow\uparrow 257&lt;/math&gt;, using [[Knuth's up-arrow notation]].

After the first few steps the value of &lt;math&gt;n^n&lt;/math&gt; is each time approximately equal to &lt;math&gt;256^n&lt;/math&gt;. In fact, it is even approximately equal to &lt;math&gt;10^n&lt;/math&gt; (see also [[Large numbers#Approximate arithmetic for very large numbers|approximate arithmetic for very large numbers]]). Using base 10 powers we get:
*&lt;math&gt;M(256,1,3)\approx 3.23\times 10^{616}&lt;/math&gt;
*&lt;math&gt;M(256,2,3)\approx10^{\,\!1.99\times 10^{619}}&lt;/math&gt; (&lt;math&gt;\log _{10} 616&lt;/math&gt; is added to the 616)
*&lt;math&gt;M(256,3,3)\approx10^{\,\!10^{1.99\times 10^{619}}}&lt;/math&gt; (&lt;math&gt;619&lt;/math&gt; is added to the &lt;math&gt;1.99\times 10^{619}&lt;/math&gt;, which is negligible; therefore just a 10 is added at the bottom)
*&lt;math&gt;M(256,4,3)\approx10^{\,\!10^{10^{1.99\times 10^{619}}}}&lt;/math&gt;
...
*mega = &lt;math&gt;M(256,256,3)\approx(10\uparrow)^{255}1.99\times 10^{619}&lt;/math&gt;, where &lt;math&gt;(10\uparrow)^{255}&lt;/math&gt; denotes a functional power of the function &lt;math&gt;f(n)=10^n&lt;/math&gt;. Hence &lt;math&gt;10\uparrow\uparrow 257 &lt; \text{mega} &lt; 10\uparrow\uparrow 258&lt;/math&gt;

==Moser's number&lt;!--This section is linked from [[Moser's number]]--&gt;==

It has been proven that in [[Conway chained arrow notation]],

:&lt;math&gt;\mathrm{moser} &lt; 3\rightarrow 3\rightarrow 4\rightarrow 2,&lt;/math&gt;

and, in [[Knuth's up-arrow notation]],

:&lt;math&gt;\mathrm{moser} &lt; f^{3}(4) = f(f(f(4))), \text{ where } f(n) = 3 \uparrow^n 3.&lt;/math&gt;

Therefore, Moser's number, although incomprehensibly large, is vanishingly small compared to [[Graham's number]]:

:&lt;math&gt;\mathrm{moser} \ll  3\rightarrow 3\rightarrow 64\rightarrow 2 &lt; f^{64}(4) = \text{Graham's number}.&lt;/math&gt;

== See also ==
* [[Ackermann function]]

== References ==
&lt;references /&gt;

==External links==
* [http://www.mrob.com/pub/math/largenum.html Robert Munafo's Large Numbers]
* [http://www-users.cs.york.ac.uk/~susan/cyc/b/big.htm Factoid on Big Numbers]
*[http://mathworld.wolfram.com/Megistron.html Megistron at mathworld.wolfram.com] (Note that Steinhaus referred to this number as "megiston" with no "r".)
*[http://mathworld.wolfram.com/CircleNotation.html Circle notation at mathworld.wolfram.com]

{{Hyperoperations}}
{{Large numbers}}

{{DEFAULTSORT:Steinhaus-Moser notation}}
[[Category:Mathematical notation]]
[[Category:Large numbers]]</text>
      <sha1>kv33us30e6odhdntl7f1ar6qdv6p1s5</sha1>
    </revision>
  </page>
  <page>
    <title>Stencil code</title>
    <ns>0</ns>
    <id>18033223</id>
    <revision>
      <id>846756560</id>
      <parentid>804708301</parentid>
      <timestamp>2018-06-20T18:16:01Z</timestamp>
      <contributor>
        <ip>2604:2000:1281:17E:E812:8E05:D1BF:9F01</ip>
      </contributor>
      <comment>Remove extraneous comma</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13629">[[File:3D von Neumann Stencil Model.svg|thumb|right|The shape of a 7-point 3D [[von Neumann neighborhood|von Neumann]] style stencil.]]

'''Stencil codes''' are a class of iterative [[GPGPU#Kernels|kernels]]&lt;ref name="Roth"&gt;
  Roth, Gerald et al. (1997) 
  Proceedings of SC'97: High Performance Networking and Computing. 
  ''[http://citeseer.ist.psu.edu/viewdoc/summary?doi=10.1.1.53.1505 Compiling Stencils in High Performance Fortran.]''
&lt;/ref&gt;
which update [[Array data structure|array elements]] according to some fixed pattern, called a stencil.&lt;ref name="Sloot"&gt;
  Sloot, Peter M.A. et al. (May 28, 2002) 
  ''[https://books.google.com/books?id=qVcLw1UAFUsC&amp;pg=PA843&amp;dq=stencil+array&amp;sig=g3gYXncOThX56TUBfHE7hnlSxJg#PPA843,M1 Computational Science – ICCS 2002: International Conference, Amsterdam, The Netherlands, April 21–24, 2002. Proceedings, Part I.]'' 
  Page 843. Publisher: Springer. {{ISBN|3-540-43591-3}}.
&lt;/ref&gt; 
They are most commonly found in the [[Source code|codes]] of  [[computer simulation]]s, e.g. for [[computational fluid dynamics]] in the context of scientific and engineering applications. 
Other notable examples include solving [[partial differential equations]],&lt;ref name="Roth"/&gt; the [[Jacobi method|Jacobi]] kernel, the [[Gauss–Seidel method]],&lt;ref name="Sloot"/&gt; [[image processing]]&lt;ref name="Roth"/&gt; and [[Cellular automaton|cellular automata]].&lt;ref name="Fey"&gt;
  Fey, Dietmar et al. (2010) 
  ''[https://books.google.com/books?id=RJRZJHVyQ4EC&amp;pg=PA51&amp;dq=fey+grid&amp;hl=de&amp;ei=uGk8TtDAAo_zsgbEoZGpBQ&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CCoQ6AEwAA#v=onepage&amp;q&amp;f=true Grid-Computing: Eine Basistechnologie für Computational Science]''. 
  Page 439. Publisher: Springer. {{ISBN|3-540-79746-7}}&lt;/ref&gt; 
The regular structure of the arrays sets stencil codes apart from other modeling methods such as the [[Finite element method]]. Most [[Finite difference method|finite difference codes]] which operate on regular grids can be formulated as stencil codes.

==Definition==
Stencil codes perform a sequence of sweeps (called timesteps) through a given array.&lt;ref name="Sloot"/&gt; Generally this is a 2- or 3-dimensional regular grid.&lt;ref name="Fey"/&gt; The elements of the arrays are often referred to as cells. In each timestep, the stencil code updates all array elements.&lt;ref name="Sloot"/&gt; Using neighboring array elements in a fixed pattern (called the stencil), each cell's new value is computed. In most cases boundary values are left unchanged, but in some cases (e.g. [[Lattice Boltzmann methods|LBM codes]]) those need to be adjusted during the computation as well. Since the stencil is the same for each element, the pattern of data accesses is repeated.&lt;ref&gt;
  Yang, Laurence T.; Guo, Minyi. (August 12, 2005) 
  ''[https://books.google.com/books?id=qA4DbnFB2XcC&amp;pg=PA221&amp;dq=Stencil+codes&amp;as_brr=3&amp;sig=H8wdKyABXT5P7kUh4lQGZ9C5zDk High-Performance Computing : Paradigm and Infrastructure.]'' 
  Page 221. Publisher: Wiley-Interscience. {{ISBN|0-471-65471-X}}
&lt;/ref&gt;

More formally, we may define stencil codes as a [[N-tuple|5-tuple]] &lt;math&gt;(I, S, S_0, s, T)&lt;/math&gt; with the following meaning:&lt;ref name="Fey"/&gt;

* &lt;math&gt;I = \prod_{i=1}^k [0, \ldots, n_i]&lt;/math&gt; is the index set. It defines the topology of the array.
* &lt;math&gt;S&lt;/math&gt; is the (not necessarily finite) set of states, one of which each cell may take on on any given timestep.
* &lt;math&gt;S_0\colon \Z^k \to S&lt;/math&gt; defines the initial state of the system at time 0.
* &lt;math&gt;s \in \prod_{i=1}^l \Z^k&lt;/math&gt; is the stencil itself and describes the actual shape of the neighborhood. There are &lt;math&gt;l&lt;/math&gt; elements in the stencil.
* &lt;math&gt;T\colon S^l \to S&lt;/math&gt; is the transition function which is used to determine a cell's new state, depending on its neighbors.

Since ''I'' is a ''k''-dimensional integer interval, the array will always have the topology of a finite regular grid. The array is also called simulation space and individual cells are identified by their index &lt;math&gt;c \in I&lt;/math&gt;. The stencil is an ordered set of &lt;math&gt;l&lt;/math&gt; relative coordinates. We can now obtain for each cell &lt;math&gt;c&lt;/math&gt; the tuple of its neighbors indices &lt;math&gt;I_c&lt;/math&gt;

: &lt;math&gt;I_c = \{j \mid \exists x \in s: j = c + x\} \, &lt;/math&gt; 

Their states are given by mapping the tuple &lt;math&gt;I_c&lt;/math&gt; to the corresponding tuple of states &lt;math&gt;N_i(c)&lt;/math&gt;, where &lt;math&gt;N_i\colon I \to S^l&lt;/math&gt; is defined as follows:

: &lt;math&gt;
N_i(c) = (s_1, \ldots, s_l) \text{ with } s_j = S_i(I_c(j)) \, 
&lt;/math&gt;

This is all we need to define the system's state for the following time steps &lt;math&gt;S_{i+1}\colon \Z^k \to S&lt;/math&gt; with &lt;math&gt;i \in \N&lt;/math&gt;:

: &lt;math&gt;
S_{i+1}(c) = \begin{cases}T(N_i(c)), &amp; c \in I\\
                           S_i(c),    &amp; c \in \Z^k \setminus I  \end{cases}
&lt;/math&gt;

Note that &lt;math&gt;S_i&lt;/math&gt; is defined on &lt;math&gt;\Z^k&lt;/math&gt; and not just on &lt;math&gt;I&lt;/math&gt; since the boundary conditions need to be set, too. Sometimes the elements of &lt;math&gt;I_c&lt;/math&gt; may be defined by a vector addition modulo the simulation space's dimension to realize toroidal topologies:

: &lt;math&gt;
I_c = \{j \mid \exists x \in s: j = ((c + x) \mod(n_1, \ldots,  n_k))\}
&lt;/math&gt; 

This may be useful for implementing [[periodic boundary conditions]], which simplifies certain physical models.

=== Example: 2D Jacobi iteration ===

[[File:2D von Neumann Stencil.svg|thumb|right|Data dependencies of a selected cell in the 2D array.]]

To illustrate the formal definition, we'll have a look at how a two dimensional [[Jacobi method|Jacobi]] iteration can be defined. The update function computes the arithmetic mean of a cell's four neighbors. In this case we set off with an initial solution of 0. The left and right boundary are fixed at 1, while the upper and lower boundaries are set to 0. After a sufficient number of iterations, the system converges against a saddle-shape.

: &lt;math&gt;
\begin{align}
I &amp; = [0, \ldots, 99]^2 \\
S &amp; = \R \\
S_0 &amp;: \Z^2 \to \R \\
S_0((x, y)) &amp; = \begin{cases}
1, &amp; x &lt; 0 \\
0, &amp; 0 \le x &lt; 100 \\
1, &amp; x \ge 100
        \end{cases}\\
s &amp; = ((0, -1), (-1, 0), (1, 0), (0, 1)) \\
T &amp;\colon \R^4 \to \R \\
T((x_1, x_2, x_3, x_4)) &amp; = 0.25 \cdot (x_1 + x_2 + x_3 + x_4)
\end{align}
&lt;/math&gt;

{{multiple image
   | width     = 100
   | align     = center
   | footer    = 2D Jacobi Iteration on a &lt;math&gt;100^2&lt;/math&gt; Array
   | image1    = 2D_Jacobi_t_0000.png
   | alt1      = S_0
   | caption1  = &lt;math&gt;S_{0}&lt;/math&gt;
   | image2    = 2D_Jacobi_t_0200.png
   | alt2      = S_200
   | caption2  = &lt;math&gt;S_{200}&lt;/math&gt;
   | image3    = 2D_Jacobi_t_0400.png
   | alt3      = S_400
   | caption3  = &lt;math&gt;S_{400}&lt;/math&gt;
   | image4    = 2D_Jacobi_t_0600.png
   | alt4      = S_600
   | caption4  = &lt;math&gt;S_{600}&lt;/math&gt;
   | image5    = 2D_Jacobi_t_0800.png
   | alt5      = S_800
   | caption5  = &lt;math&gt;S_{800}&lt;/math&gt;
   | image6    = 2D_Jacobi_t_1000.png
   | alt6      = S_1000
   | caption6  = &lt;math&gt;S_{1000}&lt;/math&gt;
  }}

==Stencils==

The shape of the neighborhood used during the updates depends on the application itself. The most common stencils are the 2D or 3D versions of the [[von Neumann neighborhood]] and [[Moore neighborhood]]. The example above uses a 2D von Neumann stencil while LBM codes generally use its 3D variant. [[Conway's Game of Life]] uses the 2D Moore neighborhood. That said, other stencils such as a 25-point stencil for seismic wave propagation&lt;ref&gt;
  Micikevicius, Paulius et al. (2009) 
  ''[http://portal.acm.org/citation.cfm?id=1513905 3D finite difference computation on GPUs using CUDA]'' 
  Proceedings of 2nd Workshop on General Purpose Processing on Graphics Processing Units  
  {{ISBN|978-1-60558-517-8}}
&lt;/ref&gt; can be found, too.

{{multiple image
   | width     = 100
   | align     = center
   | footer    = A selection of stencils used in various scientific applications.
   | image1    = Moore neighborhood (stencil diagram).gif
   | alt1      = 9-point stencil
   | caption1  = 9-point 2D stencil
   | image2    = Von Neumann neighborhood.svg
   | alt2      = 5-point stencil
   | caption2  = 5-point 2D stencil
   | image3    = 3D_von_Neumann_Stencil_Model.svg
   | alt3      = 6-point stencil 
   | caption3  = 7-point 3D stencil
   | image4    = 3D_Earth_Sciences_Stencil_Model.svg
   | alt4      = 25-point stencil
   | caption4  = 25-point 3D stencil
  }}

==Implementation issues==
Many simulation codes may be formulated naturally as stencil codes. Since computing time and memory consumption grow linearly with the number of array elements, parallel implementations of stencil codes are of paramount importance to research.&lt;ref name="Datta"&gt;
  Datta, Kaushik (2009) 
  ''[http://www.cs.berkeley.edu/~kdatta/pubs/EECS-2009-177.pdf Auto-tuning Stencil Codes for Cache-Based Multicore Platforms]'', 
  Ph.D. Thesis
&lt;/ref&gt; 
This is challenging since the computations are tightly coupled (because of the cell updates depending on neighboring cells) and most stencil codes are memory bound (i.e. the ratio of memory accesses to calculations is high).&lt;ref name="Wellein"&gt;
  Wellein, G et al. (2009) 
  ''[http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?arnumber=5254211 Efficient temporal blocking for stencil computations by multicore-aware wavefront parallelization]'', 
  33rd Annual IEEE International Computer Software and Applications Conference, COMPSAC 2009
&lt;/ref&gt; 
Virtually all current parallel architectures have been explored for executing stencil codes efficiently;&lt;ref name="datta2"&gt;
  Datta, Kaushik et al. (2008) 
  ''[http://portal.acm.org/citation.cfm?id=1413375 Stencil computation optimization and auto-tuning on state-of-the-art multicore architectures],'' 
  SC '08 Proceedings of the 2008 ACM/IEEE conference on Supercomputing
&lt;/ref&gt; 
at the moment [[GPGPU]]s have proven to be most efficient.&lt;ref name="schaefer"&gt;
  Schäfer, Andreas and Fey, Dietmar (2011) 
  ''[http://www.sciencedirect.com/science/article/pii/S1877050911002791 High Performance Stencil Code Algorithms for GPGPUs]'', 
  Proceedings of the International Conference on Computational Science, ICCS 2011
&lt;/ref&gt;

==Libraries==
Due to both the importance of stencil codes to [[computer simulation]]s and their high computational requirements, there are a number of efforts which aim at creating reusable libraries to support scientists in implementing new stencil codes. The libraries are mostly concerned with the parallelization, but may also tackle other challenges, such as IO, [[Computational steering|steering]] and [[Application checkpointing|checkpointing]]. They may be classified by their API.

===Patch-based libraries===
This is a traditional design. The library manages a set of ''n''-dimensional scalar arrays, which the user code may access to perform updates. The library handles the synchronization of the boundaries (dubbed ghost zone or halo). The advantage of this interface is that the user code may loop over the arrays, which makes it easy to integrate legacy codes&lt;ref name="walberla"&gt;
  S. Donath, J. Götz, C. Feichtinger, K. Iglberger and U. Rüde (2010)
  ''[http://www.springerlink.com/content/p2583237l2187374/ waLBerla: Optimization for Itanium-based Systems with Thousands of Processors]'',
  High Performance Computing in Science and Engineering, Garching/Munich 2009
&lt;/ref&gt;
. The disadvantage is that the library can not handle cache blocking (as this has to be done within the loops&lt;ref name="35dblocking"&gt;
  Nguyen, Anthony et al. (2010)
  ''[http://dl.acm.org/citation.cfm?id=1884658 3.5-D Blocking Optimization for Stencil Computations on Modern CPUs and GPUs]'',
  SC '10 Proceedings of the 2010 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis
&lt;/ref&gt;)
or wrapping of the code for accelerators (e.g. via CUDA or OpenCL). Notable implementations include [http://cactuscode.org/ Cactus], a physics problem solving environment, and [http://walberla.net/ waLBerla].

===Cell-based libraries===
These libraries move the interface to updating single simulation cells: only the current cell and its neighbors are exposed to the user code, e.g. via getter/setter methods. The advantage of this approach is that the library can control tightly which cells are updated in which order, which is useful not only to implement cache blocking,&lt;ref name=schaefer /&gt; 
but also to run the same code on multi-cores and GPUs.&lt;ref name="physis"&gt;
  Naoya Maruyama, Tatsuo Nomura, Kento Sato, and Satoshi Matsuoka (2011)
  ''Physis: An Implicitly Parallel Programming Model for Stencil Computations on Large-Scale GPU-Accelerated Supercomputers'',
  SC '11 Proceedings of the 2011 ACM/IEEE International Conference for High Performance Computing, Networking, Storage and Analysis
&lt;/ref&gt; This approach requires the user to recompile the source code together with the library. Otherwise a function call for every cell update would be required, which would seriously impair performance. This is only feasible with techniques such as [[Template (programming)|class templates]] or [[metaprogramming]], which is also the reason why this design is only found in newer libraries. Examples are [https://github.com/naoyam/physis Physis] and [http://www.libgeodecomp.org LibGeoDecomp].

==See also==
* [[Advanced Simulation Library]]
* [[Finite difference method]]
* [[Computer simulation]]
* [[Five-point stencil]]
* [[Stencil jumping]]

==References==
{{reflist|33em}}

==External links==
* [https://github.com/naoyam/physis Physis]
* [http://www.libgeodecomp.org LibGeoDecomp]
* [http://walberla.net waLBerla]

[[Category:Computational science]]
[[Category:Scientific modeling]]
[[Category:Simulation software]]</text>
      <sha1>buo2izv2uzy49y260odyco8o2exzs3h</sha1>
    </revision>
  </page>
  <page>
    <title>Subtyping</title>
    <ns>0</ns>
    <id>213508</id>
    <revision>
      <id>863676393</id>
      <parentid>854179868</parentid>
      <timestamp>2018-10-12T08:27:12Z</timestamp>
      <contributor>
        <username>Cedar101</username>
        <id>374440</id>
      </contributor>
      <minor/>
      <comment>/* Examples */ &lt;source lang="vb"&gt;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20290">{{Polymorphism}}
In [[programming language theory]], '''subtyping''' (also '''subtype polymorphism''' or '''inclusion polymorphism''') is a form of [[Polymorphism (computer science)|type polymorphism]] in which a '''subtype''' is a [[datatype]] that is related to another datatype (the '''supertype''') by some notion of [[Liskov substitution principle|substitutability]], meaning that program elements, typically [[subroutines]] or functions, written to operate on elements of the supertype can also operate on elements of the subtype. If S is a subtype of T, the subtyping [[binary relation|relation]] is often written S &lt;: T, to mean that any term of type S can be ''safely used in a context where'' a term of type T is expected. The precise semantics of subtyping crucially depends on the particulars of what "safely used in a context where" means in a given [[programming language]]. The [[type system]] of a programming language essentially defines its own subtyping relation, which may well be [[identity relation|trivial]] should the language support no (or very little) conversion mechanisms.

Due to the subtyping relation, a term may belong to more than one type. Subtyping is therefore a form of type polymorphism. In [[object-oriented programming]] the term 'polymorphism' is commonly used to refer solely to this ''subtype polymorphism'', while the techniques of [[parametric polymorphism]] would be considered ''[[generic programming]]''.

[[Functional programming languages]] often allow the subtyping of [[Record (computer science)|records]]. Consequently, [[simply typed lambda calculus]] extended with record types is perhaps the simplest theoretical setting in which a useful notion of subtyping may be defined and studied {{Citation needed|date=May 2017}}. Because the resulting calculus allows terms to have more than one type, it is no longer a "simple" [[type theory]]. Since functional programming languages, by definition, support [[function literals]], which can also be stored in records, records types with subtyping provide some of the features of object-oriented programming. Typically, functional programming languages also provide some, usually restricted, form of parametric polymorphism. In a theoretical setting, it is desirable to study the interaction of the two features; a common theoretical setting is [[system F-sub|system F&lt;sub&gt;&lt;:&lt;/sub&gt;]]. Various calculi that attempt to capture the theoretical properties of object-oriented programming may be derived from system F&lt;sub&gt;&lt;:&lt;/sub&gt;.

The concept of subtyping is related to the linguistic notions of [[hyponymy]] and [[holonymy]]. It is also related to the concept of [[bounded quantification]] in mathematical logic. Subtyping should not be confused with the notion of (class or object) [[inheritance (computer science)|inheritance]] from object-oriented languages;{{sfn|Cook|Hill|Canning|1990}} subtyping is a relation between types (interfaces in object-oriented parlance) whereas inheritance is a relation between implementations stemming from a language feature that allows new objects to be created from existing ones. In a number of object-oriented languages, subtyping is called '''interface inheritance''',&lt;!-- todo add the insightful example from Mitchell with stack/queue/dequeue in the body --&gt; with inheritance referred to as ''implementation inheritance''.

== Origins ==
The notion of subtyping in programming languages dates back to the 1960s; it was introduced in [[Simula]] derivatives. The first formal treatments of subtyping were given by [[John C. Reynolds]] in 1980 who used [[category theory]] to formalize [[implicit conversion]]s, and [[Luca Cardelli]] (1985).&lt;ref&gt;Pierce, ch. 15 notes&lt;/ref&gt;

The concept of subtyping has gained visibility (and synonymy with polymorphism in some circles) with the mainstream adoption of object-oriented programming. In this context, the principle of safe substitution is often called the [[Liskov substitution principle]], after [[Barbara Liskov]] who popularized it in a [[keynote]] address at a conference on object-oriented programming in 1987. Because it must consider mutable objects, the ideal notion of subtyping defined by Liskov and [[Jeannette Wing]], called [[behavioral subtyping]] is considerably stronger than what can be implemented in a [[type checker]]. (See [[#Function types|Function types]] below for details.)

== Examples ==
[[Image:Inheritance.svg|thumb|right|350px|Example of subtypes: where bird is the supertype and all others are subtypes as denoted by the arrow in [[Unified Modeling Language|UML]] notation]]
A simple practical example of subtypes is shown in the diagram, right. The type "bird" has three subtypes "duck", "cuckoo" and "ostrich". Conceptually, each of these is a variety of the basic "bird" that inherits many "bird" characteristics but has some specific differences. The [[Unified Modeling Language|UML]] notation is used in this diagram, with open-headed arrows showing the direction and type of the relationship between the supertype and its subtypes.

As a more practical example, a language might allow integer values to be used wherever floating point values are expected (&lt;code&gt;Integer&lt;/code&gt; &lt;: &lt;code&gt;Float&lt;/code&gt;), or it might define a generic type &lt;samp&gt;Number&lt;/samp&gt; as a common supertype of integers and the reals. In this second case, we only have &lt;code&gt;Integer&lt;/code&gt; &lt;: &lt;code&gt;Number&lt;/code&gt; and &lt;code&gt;Float&lt;/code&gt; &lt;: &lt;code&gt;Number&lt;/code&gt;, but &lt;code&gt;Integer&lt;/code&gt; and &lt;code&gt;Float&lt;/code&gt; are not subtypes of each other.

Programmers may take advantage of subtyping [[abstraction principle (programming)|to write code in a more abstract manner]] than would be possible without it. Consider the following example:

&lt;source lang="vb"&gt;
function max (x as Number, y as Number) is
  if x &lt; y then
    return y
  else
    return x
end
&lt;/source&gt;

If integer and real are both subtypes of &lt;code&gt;Number&lt;/code&gt;, and an operator of comparison with an arbitrary Number is defined for both types, then values of either type can be passed to this function. However, the very possibility of implementing such an operator highly constrains the Number type (for example, one can't compare an integer with a complex number), and actually only comparing integers with integers and reals with reals makes sense. Rewriting this function so that it would only accept 'x' and 'y' of the same type requires [[bounded polymorphism]].

Subtyping in type theory is characterized by the fact that any expression of type ''A'' may also be given type ''B'' if ''A''&lt;samp&gt;&amp;lt;:&lt;/samp&gt;''B''; the formal [[inference rule|typing rule]] that codifies this is known as the ''subsumption'' rule.&lt;!-- this needs context as it's not a generic notion. --&gt;

== Subtyping schemes ==

Type theorists make a distinction between '''[[nominal type system|nominal subtyping]]''', in which only types declared in a certain way may be subtypes of each other, and '''[[structural type system|structural subtyping]]''', in which the structure of two types determines whether or not one is a subtype of the other.  The class-based object-oriented subtyping described above is nominal; a structural subtyping rule for an object-oriented language might say that if objects of type ''A'' can handle all of the messages that objects of type ''B'' can handle (that is, if they define all the same [[Method (computer science)|method]]s), then ''A'' is a subtype of ''B'' regardless of whether either [[inheritance (computer science)|inherits]] from the other. This so-called ''[[duck typing]]'' is common in dynamically typed object-oriented languages. Sound structural subtyping rules for types other than object types are also well known.{{citation needed|date=June 2012}}

Implementations of programming languages with subtyping fall into two general classes: ''inclusive'' implementations, in which the representation of any value of type ''A'' also represents the same value at type ''B'' if ''A''&lt;samp&gt;&amp;lt;:&lt;/samp&gt;''B'', and ''coercive'' implementations, in which a value of type ''A'' can be ''automatically converted'' into one of type ''B''. The subtyping induced by subclassing in an object-oriented language is usually inclusive; subtyping relations that relate integers and floating-point numbers, which are represented differently, are usually coercive.

In almost all type systems that define a subtyping relation, it is reflexive (meaning ''A''&lt;samp&gt;&amp;lt;:&lt;/samp&gt;''A'' for any type ''A'') and transitive (meaning that if ''A''&lt;samp&gt;&amp;lt;:&lt;/samp&gt;''B'' and ''B''&lt;samp&gt;&amp;lt;:&lt;/samp&gt;''C'' then ''A''&lt;samp&gt;&amp;lt;:&lt;/samp&gt;''C''). This makes it a [[preorder]] on types.

== Record types ==

=== Width and depth subtyping ===

Types of [[Record (computer science)|records]] give rise to the concepts of ''width'' and ''depth'' subtyping. These express two different ways of obtaining a new type of record that allows the same operations as the original record type.

Recall that a record is a collection of (named) fields. Since a subtype is a type which allows all operations allowed on the original type, a record subtype should support the same operations on the fields as the original type supported.

One kind of way to achieve such support, called ''width subtyping'', adds more fields to the record. More formally, every (named) field appearing in the width supertype will appear in the width subtype. Thus, any operation feasible on the supertype will be supported by the subtype.

The second method, called ''depth subtyping'', replaces the various fields with their subtypes. That is, the fields of the subtype are subtypes of the fields of the supertype. Since any operation supported for a field in the supertype is supported for its subtype, any operation feasible on the record supertype is supported by the record subtype. Depth subtyping only makes sense for immutable records: for example, you can assign 1.5 to the 'x' field of a real point (a record with two real fields), but you can't do the same to the 'x' field of an integer point (which, however, is a deep subtype of the real point type) because 1.5 is not an integer (see [[Covariance and contravariance (computer science)|Variance]]).

Subtyping of records can be defined in [[System F-sub|System F&lt;sub&gt;&lt;:&lt;/sub&gt;]], which combines [[parametric polymorphism]] with subtyping of record types and is a theoretical basis for many [[functional programming languages]] that support both features.

Some systems also support subtyping of labeled [[disjoint union]] types (such as [[algebraic data type]]s). The rule for width subtyping is reversed: every tag appearing in the width subtype must appear in the width supertype.

==Function types==

If ''T''&lt;sub&gt;1&lt;/sub&gt; → ''T''&lt;sub&gt;2&lt;/sub&gt; is a function type, then a subtype of it is any function type ''S''&lt;sub&gt;1&lt;/sub&gt; → ''S''&lt;sub&gt;2&lt;/sub&gt; with the property that ''T''&lt;sub&gt;1&lt;/sub&gt; &lt;: ''S''&lt;sub&gt;1&lt;/sub&gt; and ''S''&lt;sub&gt;2&lt;/sub&gt; &lt;: ''T''&lt;sub&gt;2&lt;/sub&gt;. This can be summarised using the following [[type rule|typing rule]]: 

&lt;blockquote&gt;
&lt;math&gt;T_1 \leq: S_1 \quad S_2 \leq: T_2
\over
S_1 \rightarrow S_2 \leq: T_1 \rightarrow T_2
&lt;/math&gt;
&lt;/blockquote&gt;

The argument type of ''S''&lt;sub&gt;1&lt;/sub&gt; → ''S''&lt;sub&gt;2&lt;/sub&gt; is said to be [[Covariance and contravariance (computer science)|contravariant]] because the subtyping relation is reversed for it, whereas the return type is [[Covariance and contravariance (computer science)|covariant]]. Informally, this reversal occurs because the refined type is "more liberal" in the types it accepts and "more conservative" in the type it returns. This is what exactly works in [[Scala_(programming_language) |Scala]]: a ''n''-ary function is internally a class that inherits the '''FunctionN(-A1, -A2, …, -An, +B)''' [[Trait (computer programming) |trait]] (which can be seen as a general [[Application programming interface|interface]] in [[Java (programming language)|Java]]-like languages), where ''A1'', ''A2'', … ''An'' are the parameter types, and ''B'' is its return type; "'''-'''" before the type means the type is contravariant while "'''+'''" means covariant.

In languages that allow side effects, like most object-oriented languages, subtyping is generally not sufficient to guarantee that a function can be safely used in the context of another. Liskov's work in this area focused on [[behavioral subtyping]], which besides the type system safety discussed in this article also requires that subtypes preserve all [[Invariant (computer science)|invariants]] guaranteed by the supertypes in some [[Design by Contract|contract]].&lt;ref name="LSP"&gt;Barbara Liskov, Jeannette Wing, ''[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.1223 A behavioral notion of subtyping]'', ACM Transactions on Programming Languages and Systems, Volume 16, Issue 6 (November 1994), pp. 1811–1841. An updated version appeared as CMU technical report: {{cite web|url=http://reports-archive.adm.cs.cmu.edu/anon/1999/CMU-CS-99-156.ps|title=Behavioral Subtyping Using Invariants and Constraints|last=Liskov|first=Barbara|authorlink=Barbara Liskov|author2=Wing, Jeannette |authorlink2=Jeannette Wing |date=July 1999|format=[[PostScript|PS]]|accessdate=2006-10-05}}&lt;/ref&gt; This definition of subtyping is generally [[undecidable problem|undecidable]], so it cannot be verified by a [[type checker]].

The subtyping of [[Immutable object|mutable reference]]s is similar to the treatment of function arguments and return values. Write-only references (or ''sinks'') are contravariant, like function arguments; read-only references (or ''sources'') are covariant, like return values. Mutable references which act as both sources and sinks are invariant.

==Relationship with inheritance==

Subtyping and inheritance are independent (orthogonal) relationships. They may coincide, but none is a special case of the other. In other words, between two types ''S'' and ''T'', all combinations of subtyping and inheritance are possible:
# ''S'' is neither a subtype nor a derived type of ''T''
# ''S'' is a subtype but is not a derived type of ''T''
# ''S'' is not a subtype but is a derived type of ''T''
# ''S'' is both a subtype and a derived type of ''T''
The first case is illustrated by independent types, such as &lt;code&gt;Boolean&lt;/code&gt; and &lt;code&gt;Float&lt;/code&gt;.

The second case can be illustrated by &lt;code&gt;Int32&lt;/code&gt; and &lt;code&gt;Int64&lt;/code&gt;; in most object oriented programming languages, &lt;code&gt;Int64&lt;/code&gt; is not derived by inheritance from &lt;code&gt;Int32&lt;/code&gt;, however &lt;code&gt;Int64 &lt;: Int32&lt;/code&gt;. Since an &lt;code&gt;Int32&lt;/code&gt; value can always be replaced by an &lt;code&gt;Int64&lt;/code&gt; value, the [[Liskov substitution principle]] is satisfied; therefore &lt;code&gt;Int64&lt;/code&gt; can be considered a subtype of &lt;code&gt;Int32&lt;/code&gt;.

The third case is a consequence of [[Subtyping_of_functions|function subtyping input contravariance]]. Assume a super class of type ''T'' having a method ''m'' returning an object of the same type (''i.e.'' the type of ''m'' is ''T → T'', also note that the first argument of ''m'' is this/self) and a derived class type ''S'' from ''T''. By inheritance, the type of ''m'' in ''S'' is ''S → S''. In order for ''S'' to be a subtype of ''T'' the type of ''m'' in ''S'' must be a subtype of the type of ''m'' in ''T'', in other words: ''S → S ≤: T → T''. By bottom-up application of the function subtyping rule, this means: ''S ≤: T'' and ''T ≤: S'', which is only possible if ''S'' and ''T'' are the same. Since inheritance is an irreflexive relation, ''S'' can't be a subtype of ''T''.

Subtyping and inheritance are compatible when all inherited fields and methods of the derived type have types which are subtypes of the corresponding fields and methods from the inherited type {{sfn|Cook|Hill|Canning|1990}}.

==Coercions==
In coercive subtyping systems, subtypes are defined by implicit [[type conversion]] functions from subtype to supertype. For each subtyping relationship (''S'' &lt;: ''T''), a coercion function ''coerce'': ''S'' → ''T'' is provided, and any object ''s'' of type ''S'' is regarded as the object ''coerce''&lt;sub&gt;''S'' → ''T''&lt;/sub&gt;(''s'') of type ''T''. A coercion function may be defined by composition: if ''S'' &lt;: ''T'' and ''T'' &lt;: ''U'' then ''s'' may be regarded as an object of type ''u'' under the compound coercion (''coerce''&lt;sub&gt;''T'' → ''U''&lt;/sub&gt; ∘ ''coerce''&lt;sub&gt;''S'' → ''T''&lt;/sub&gt;). The [[type coercion]] from a type to itself ''coerce''&lt;sub&gt;''T'' → ''T''&lt;/sub&gt; is the [[identity function]] ''id''&lt;sub&gt;T&lt;/sub&gt;

Coercion functions for records and [[disjoint union]] subtypes may be defined componentwise; in the case of width-extended records, type coercion simply discards any components which are not defined in the supertype. The type coercion for function types may be given by ''f'''(''s'') = ''coerce''&lt;sub&gt;''S''&lt;sub&gt;2&lt;/sub&gt; → ''T''&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;(''f''(''coerce''&lt;sub&gt;''T''&lt;sub&gt;1&lt;/sub&gt; → ''S''&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;(''t''))), reflecting the [[Covariance and contravariance (computer science)|contravariance]] of function arguments and covariance of return values.

The coercion function is uniquely determined given the subtype and [[supertype]]. Thus, when multiple subtyping relationships are defined, one must be careful to guarantee that all type coercions are coherent. For instance, if an integer such as 2 : ''int'' can be coerced to a floating point number (say, 2.0 : ''float''), then it is not admissible to coerce 2.1 : ''float'' to 2 : ''int'', because the compound coercion ''coerce''&lt;sub&gt;''float'' → ''float''&lt;/sub&gt; given by ''coerce''&lt;sub&gt;''int'' → ''float''&lt;/sub&gt; ∘ ''coerce''&lt;sub&gt;''float'' → ''int''&lt;/sub&gt; would then be distinct from the identity coercion ''id''&lt;sub&gt;''float''&lt;/sub&gt;.

== See also ==
{{wikibooks|Ada Programming|Type System|Subtypes}}
* [[Covariance and contravariance (computer science)|Covariance and contravariance]]
* The [[circle-ellipse problem]] (for the perils of subtyping variable-types on the same basis as value-types)
* [[Class-based programming]]
* [[Top type]]
* [[Refinement type]]
* [[Behavioral subtyping]]

==Notes==
{{reflist}}

== References ==
'''Textbooks'''
{{refbegin}}
* Benjamin C. Pierce, ''Types and programming languages'', MIT Press, 2002, {{ISBN|0-262-16209-1}}, chapter 15 (subtyping of record types), 19.3 (nominal vs. structural types and subtyping), and 23.2 (varieties of polymorphism)
* C. Szyperski, D. Gruntz, S. Murer, ''Component software: beyond object-oriented programming'', 2nd ed., Pearson Education, 2002, {{ISBN|0-201-74572-0}}, pp.&amp;nbsp;93–95 (a high-level presentation aimed at programming language users)
{{refend}}
'''Papers'''
{{refbegin}}
* Cardelli, Luca. A semantics of multiple inheritance. In G. Kahn, D. MacQueen, and G. Plotkin, editors, Semantics of Data Types, volume 173 of Lecture Notes in Computer Science, pages 51–67. Springer-Verlag, 1984. Full version in Information and Computation, 76(2/3):138–164, 1988.
* {{Cite conference| last1 = Cook | first1 = William R. | last2 = Hill | first2 = Walter | last3 = Canning | first3 = Peter S. | doi = 10.1145/96709.96721 | title = Inheritance is not subtyping | conference = Proc. 17th ACM SIGPLAN-SIGACT Symp. on Principles of Programming Languages (POPL)| pages = 125–135 | year = 1990 | isbn = 0-89791-343-4 | ref = harv| citeseerx = 10.1.1.102.8635}}
* Reynolds, John C. Using category theory to design implicit conversions and generic operators. In N. D. Jones, editor, Proceedings of the Aarhus Workshop on Semantics-Directed Compiler Generation, number 94 in Lecture Notes in Computer Science. Springer-Verlag, January 1980. Also in Carl A. Gunter and John C. Mitchell, editors, Theoretical Aspects of Object-Oriented Programming: Types, Semantics, and Language Design (MIT Press, 1994).
{{refend}}

== Further reading ==
{{refbegin}}
* [[John C. Reynolds]], ''Theories of programming languages'', Cambridge University Press, 1998, {{ISBN|0-521-59414-6}}, chapter 16.
* [[Martín Abadi]], [[Luca Cardelli]], ''A theory of objects'', Springer, 1996, {{ISBN|0-387-94775-2}}. Section 8.6 contrast the subtyping of records and objects.
{{refend}}

{{data types}}

{{DEFAULTSORT:Subtype Polymorphism}}
[[Category:Data types]]
[[Category:Polymorphism (computer science)]]
[[Category:Type theory]]
[[Category:Object-oriented programming]]</text>
      <sha1>lvwy6g91jth0tqlckym9q4vyhfcupvq</sha1>
    </revision>
  </page>
  <page>
    <title>Sumner's conjecture</title>
    <ns>0</ns>
    <id>28866227</id>
    <revision>
      <id>849768766</id>
      <parentid>750065308</parentid>
      <timestamp>2018-07-11T06:30:26Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>illo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10075">{{unsolved|mathematics|Does every &lt;math&gt;(2n-2)&lt;/math&gt;-vertex tournament contain as a subgraph every &lt;math&gt;n&lt;/math&gt;-vertex oriented tree?}}
[[File:Polytrees in a tournament.svg|thumb|upright=1.3|A 6-vertex tournament, and copies of every 4-vertex oriented tree within it.]]
[[David Sumner]] (a [[graph theory|graph theorist]] at the [[University of South Carolina]]) [[conjecture]]d in 1971 that [[tournament (graph theory)|tournaments]] are [[universal graph]]s for [[polytree]]s. More precisely, '''Sumner's conjecture''' (also called '''Sumner's universal tournament conjecture''') states that every [[Orientation (graph theory)|orientation]] of every &lt;math&gt;n&lt;/math&gt;-vertex [[Tree (graph theory)|tree]] is a [[Glossary of graph theory#Subgraphs|subgraph]] of every &lt;math&gt;(2n-2)&lt;/math&gt;-vertex tournament.&lt;ref&gt;{{harvtxt|Kühn|Mycroft|Osthus|2011a}}. However the earliest published citations given by Kühn et al. are to {{harvtxt|Reid|Wormald|1983}} and {{harvtxt|Wormald|1983}}. {{harvtxt|Wormald|1983}} cites the conjecture as an undated private communication by Sumner.&lt;/ref&gt; The conjecture remains unproven; {{harvtxt|Kühn|Mycroft|Osthus|2011a}} call it "one of the most well-known problems on tournaments."

==Examples==
Let polytree &lt;math&gt;P&lt;/math&gt; be a [[Star (graph theory)|star]] &lt;math&gt;K_{1,n-1}&lt;/math&gt;, in which all edges are oriented outward from the central vertex to the leaves. Then, &lt;math&gt;P&lt;/math&gt; cannot be embedded in the tournament formed from the vertices of a regular &lt;math&gt;2n-3&lt;/math&gt;-gon by directing every edge clockwise around the polygon. For, in this tournament, every vertex has indegree and outdegree equal to &lt;math&gt;n-2&lt;/math&gt;, while the central vertex in &lt;math&gt;P&lt;/math&gt; has larger outdegree &lt;math&gt;n-1&lt;/math&gt;.&lt;ref&gt;This example is from {{harvtxt|Kühn|Mycroft|Osthus|2011a}}.&lt;/ref&gt; Thus, if true, Sumner's conjecture would give the best possible size of a universal graph for polytrees.

However, in every tournament of &lt;math&gt;2n-2&lt;/math&gt; vertices, the average outdegree is &lt;math&gt;n-\frac{3}{2}&lt;/math&gt;, and the maximum outdegree is an integer greater than or equal to the average. Therefore, there exists a vertex of outdegree &lt;math&gt;\left\lceil n-\frac{3}{2}\right\rceil=n-1&lt;/math&gt;, which can be used as the central vertex for a copy of &lt;math&gt;P&lt;/math&gt;.

==Partial results==
The following partial results on the conjecture are known.
*It is true for all sufficiently large values of &lt;math&gt;n&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Kühn|Mycroft|Osthus|2011b}}.&lt;/ref&gt;
*There is a function &lt;math&gt;f(n)&lt;/math&gt; with asymptotic growth rate &lt;math&gt;f(n)=2n+o(n)&lt;/math&gt; with the property that every &lt;math&gt;n&lt;/math&gt;-vertex polytree can be embedded as a subgraph of every &lt;math&gt;f(n)&lt;/math&gt;-vertex tournament. Additionally and more explicitly, &lt;math&gt;f(n)\le 3n-3&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Kühn|Mycroft|Osthus|2011a}} and {{harvtxt|El Sahili|2004}}. For earlier weaker bounds on &lt;math&gt;f(n)&lt;/math&gt;, see {{harvtxt|Chung|1981}}, {{harvtxt|Wormald|1983}}, {{harvtxt|Häggkvist|Thomason|1991}}, {{harvtxt|Havet|Thomassé|2000b}}, and {{harvtxt|Havet|2002}}.&lt;/ref&gt;
*There is a function &lt;math&gt;g(k)&lt;/math&gt; such that tournaments on &lt;math&gt;n+g(k)&lt;/math&gt; vertices are universal for polytrees with &lt;math&gt;k&lt;/math&gt; leaves.&lt;ref&gt;{{harvtxt|Häggkvist|Thomason|1991}}; {{harvtxt|Havet|Thomassé|2000a}}; {{harvtxt|Havet|2002}}.&lt;/ref&gt;
*There is a function &lt;math&gt;h(n,\Delta)&lt;/math&gt; such that every &lt;math&gt;n&lt;/math&gt;-vertex polytree with maximum degree at most &lt;math&gt;\Delta&lt;/math&gt; forms a subgraph of every tournament with &lt;math&gt;h(n,\Delta)&lt;/math&gt; vertices. When &lt;math&gt;\Delta&lt;/math&gt; is a fixed constant, the asymptotic growth rate of &lt;math&gt;h(n,\Delta)&lt;/math&gt; is &lt;math&gt;n+o(n)&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Kühn|Mycroft|Osthus|2011a}}.&lt;/ref&gt;
*Every "near-regular" tournament on &lt;math&gt;2n-2&lt;/math&gt; vertices contains every &lt;math&gt;n&lt;/math&gt;-vertex polytree.&lt;ref name="rw83"&gt;{{harvtxt|Reid|Wormald|1983}}.&lt;/ref&gt;
*Every orientation of an &lt;math&gt;n&lt;/math&gt;-vertex [[caterpillar tree]] with [[diameter (graph theory)|diameter]] at most four can be embedded as a subgraph of every &lt;math&gt;(2n-2)&lt;/math&gt;-vertex tournament.&lt;ref name="rw83"/&gt;
*Every &lt;math&gt;(2n-2)&lt;/math&gt;-vertex tournament contains as a subgraph every &lt;math&gt;n&lt;/math&gt;-vertex [[Arborescence (graph theory)|arborescence]].&lt;ref&gt;{{harvtxt|Havet|Thomassé|2000b}}.&lt;/ref&gt;

==Related conjectures==
{{harvtxt|Rosenfeld|1972}} conjectured that every orientation of an &lt;math&gt;n&lt;/math&gt;-vertex [[path graph]] (with &lt;math&gt;n\ge 8&lt;/math&gt;) can be embedded as a subgraph into every &lt;math&gt;n&lt;/math&gt;-vertex tournament.&lt;ref name="rw83"/&gt; After partial results by {{harvtxt|Thomason|1986}} this was proven by {{harvtxt|Havet|Thomassé|2000a}}.

Havet and Thomassé&lt;ref&gt;In {{harvtxt|Havet|2002}}, but jointly credited to Thomassé in that paper.&lt;/ref&gt; in turn conjectured a strengthening of Sumner's conjecture, that every tournament on &lt;math&gt;n+k-1&lt;/math&gt; vertices contains as a subgraph every polytree with at most &lt;math&gt;k&lt;/math&gt; leaves.

{{harvtxt|Burr|1980}} conjectured that, whenever a graph &lt;math&gt;G&lt;/math&gt; requires &lt;math&gt;2n-2&lt;/math&gt; or more colors in a [[graph coloring|coloring]] of &lt;math&gt;G&lt;/math&gt;, then every orientation of &lt;math&gt;G&lt;/math&gt; contains every orientation of an &lt;math&gt;n&lt;/math&gt;-vertex tree. Because complete graphs require a different color for each vertex, Sumner's conjecture would follow immediately from Burr's conjecture.&lt;ref&gt;This is a corrected version of Burr's conjecture from {{harvtxt|Wormald|1983}}.&lt;/ref&gt; As Burr showed, orientations of graphs whose chromatic number grows quadratically as a function of &lt;math&gt;n&lt;/math&gt; are universal for polytrees.

==Notes==
{{reflist|colwidth=30em}}

==References==
*{{citation
 | last = Burr | first = Stefan A. | author-link = Stefan Burr
 | contribution = Subtrees of directed graphs and hypergraphs
 | series = Congressus Numerantium
 | mr = 608430
 | pages = 227–239
 | title = Proceedings of the Eleventh Southeastern Conference on Combinatorics, Graph Theory and Computing (Florida Atlantic Univ., Boca Raton, Fla., 1980), Vol. I
 | volume = 28
 | year = 1980}}.
*{{citation
 | last = Chung | first = F.R.K. | author-link = Fan Chung
 | publisher = [[Bell Laboratories]]
 | series = Internal Memorandum
 | title = A note on subtrees in tournaments
 | year = 1981}}. As cited by {{harvtxt|Wormald|1983}}.
*{{citation
 | last = El Sahili | first = A.
 | doi = 10.1016/j.jctb.2004.04.002
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 2078502
 | pages = 183–187
 | title = Trees in tournaments
 | volume = 92
 | year = 2004}}.
*{{citation
 | last1 = Häggkvist | first1 = Roland
 | last2 = Thomason | first2 = Andrew
 | doi = 10.1007/BF01206356
 | issue = 2
 | journal = [[Combinatorica]]
 | mr = 1136161
 | pages = 123–130
 | title = Trees in tournaments
 | volume = 11
 | year = 1991}}.
*{{citation
 | last = Havet | first = Frédéric
 | doi = 10.1016/S0012-365X(00)00463-5
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 1874730
 | pages = 121–134
 | title = Trees in tournaments
 | volume = 243
 | year = 2002}}.
*{{citation
 | last1 = Havet | first1 = Frédéric
 | last2 = Thomassé | first2 = Stéphan
 | doi = 10.1006/jctb.1999.1945
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 1750898
 | pages = 243–273
 | title = Oriented Hamiltonian paths in tournaments: a proof of Rosenfeld's conjecture
 | volume = 78
 | year = 2000a}}.
*{{citation
 | last1 = Havet | first1 = Frédéric
 | last2 = Thomassé | first2 = Stéphan
 | doi = 10.1002/1097-0118(200012)35:4&lt;244::AID-JGT2&gt;3.0.CO;2-H
 | issue = 4
 | journal = Journal of Graph Theory
 | mr = 1791347
 | pages = 244–256
 | title = Median orders of tournaments: a tool for the second neighborhood problem and Sumner's conjecture
 | volume = 35
 | year = 2000b}}.
*{{citation
 | last1 = Kühn | first1 = Daniela | author1-link = Daniela Kühn
 | last2 = Mycroft | first2 = Richard
 | last3 = Osthus | first3 = Deryk
 | doi = 10.1016/j.jctb.2010.12.006
 | issue = 6
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 2832810 | zbl=1234.05115
 | pages = 415–447
 | title = An approximate version of Sumner's universal tournament conjecture
 | volume = 101
 | year = 2011a}}.
*{{citation
 | last1 = Kühn | first1 = Daniela | author1-link = Daniela Kühn
 | last2 = Mycroft | first2 = Richard
 | last3 = Osthus | first3 = Deryk
 | arxiv = 1010.4430
 | doi = 10.1112/plms/pdq035
 | issue = 4
 | journal = Proceedings of the London Mathematical Society | series = Third Series
 | mr = 2793448 | zbl=1218.05034 
 | pages = 731–766
 | title = A proof of Sumner's universal tournament conjecture for large tournaments
 | volume = 102
 | year = 2011b}}.
*{{citation
 | last1 = Reid | first1 = K. B.
 | last2 = Wormald | first2 = N. C.
 | issue = 2-4
 | journal = Studia Scientiarum Mathematicarum Hungarica
 | mr = 787942
 | pages = 377–387
 | title = Embedding oriented ''n''-trees in tournaments
 | volume = 18
 | year = 1983}}.
*{{citation
 | last = Rosenfeld | first = M.
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 0285452
 | pages = 93–99
 | title = Antidirected Hamiltonian paths in tournaments
 | volume = 12
 | year = 1972
 | doi=10.1016/0095-8956(72)90035-4}}.
*{{citation
 | last = Thomason | first = Andrew
 | doi = 10.2307/2000567
 | issue = 1
 | journal = Transactions of the American Mathematical Society
 | mr = 837805
 | pages = 167–180
 | title = Paths and cycles in tournaments
 | volume = 296
 | year = 1986}}.
*{{citation
 | last = Wormald | first = Nicholas C.
 | contribution = Subtrees of large tournaments
 | doi = 10.1007/BFb0071535
 | location = Berlin
 | mr = 731598
 | pages = 417–419
 | publisher = Springer
 | series = Lecture Notes in Math.
 | title = Combinatorial mathematics, X (Adelaide, 1982)
 | volume = 1036
 | year = 1983}}.

==External links==
*[http://www.math.uiuc.edu/~west/openp/univtourn.html Sumner's Universal Tournament Conjecture (1971)], D. B. West, updated July 2008.

[[Category:Graph theory]]
[[Category:Conjectures]]</text>
      <sha1>al972qik73u128hexkyjlrrf30t911a</sha1>
    </revision>
  </page>
  <page>
    <title>Taxicab geometry</title>
    <ns>0</ns>
    <id>408354</id>
    <revision>
      <id>867722697</id>
      <parentid>860176312</parentid>
      <timestamp>2018-11-07T15:59:42Z</timestamp>
      <contributor>
        <username>Jeremyb-phone</username>
        <id>19733343</id>
      </contributor>
      <comment>rm comma</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10353">[[File:Manhattan distance.svg|thumb|200px|Taxicab geometry versus Euclidean distance: In taxicab geometry, the red, yellow, and blue paths all have the same shortest path length of 12. In Euclidean geometry, the green line has length &lt;math&gt;6 \sqrt{2} \approx 8.49&lt;/math&gt; and is the unique shortest path.]]

A '''taxicab geometry''' is a form of [[geometry]] in which the usual distance function or [[Metric (mathematics)|metric]] of [[Euclidean geometry]] is replaced by a new metric in which the [[distance]] between two points is the sum of the [[absolute difference]]s of their [[Cartesian coordinate]]s. The '''taxicab metric''' is also known as '''rectilinear distance''', '''''L''&lt;sub&gt;1&lt;/sub&gt; distance''', '''''L''&lt;sup&gt;1&lt;/sup&gt; distance''' or '''&lt;math&gt;\ell_1&lt;/math&gt; norm''' (see [[Lp space|''L''&lt;sup&gt;''p''&lt;/sup&gt; space]]), '''[[Snake (video game)|snake]] distance''', '''city block distance''', '''Manhattan distance''' or '''Manhattan length''', with corresponding variations in the name of the geometry.&lt;ref&gt;[https://xlinux.nist.gov/dads/HTML/manhattanDistance.html Manhattan distance&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; The latter names allude to the [[Commissioners' Plan of 1811|grid layout of most streets]] on the island of [[Manhattan]], which causes the shortest path a car could take between two intersections in the [[Borough (New York City)|borough]] to have length equal to the intersections' distance in taxicab geometry.

The geometry has been used in [[regression analysis]] since the 18th century, and today is often referred to as [[Lasso (statistics)|LASSO]]. The geometric interpretation dates to [[non-Euclidean geometry]] of the 19th century and is due to [[Hermann Minkowski]].

== Formal definition ==
The taxicab distance, &lt;math&gt;d_1&lt;/math&gt;, between two vectors &lt;math&gt;\mathbf{p}, \mathbf{q}&lt;/math&gt; in an ''n''-dimensional [[real number|real]] [[vector space]] with fixed [[Cartesian coordinate system]], is the sum of the lengths of the projections of the [[line segment]] between the points onto the [[coordinate axes]].  More formally,
:&lt;math&gt;d_1(\mathbf{p}, \mathbf{q}) = \|\mathbf{p} - \mathbf{q}\|_1 = \sum_{i=1}^n |p_i-q_i|,&lt;/math&gt;
where &lt;math&gt;(\mathbf{p}, \mathbf{q})&lt;/math&gt; are [[Euclidean vector|vector]]s
:&lt;math&gt;\mathbf{p}=(p_1,p_2,\dots,p_n)\text{ and }\mathbf{q}=(q_1,q_2,\dots,q_n)\,&lt;/math&gt;

For example, in the [[plane (mathematics)|plane]], the taxicab distance between &lt;math&gt;(p_1,p_2)&lt;/math&gt; and &lt;math&gt;(q_1,q_2)&lt;/math&gt; is &lt;math&gt;| p_1 - q_1 | + | p_2 - q_2 |.&lt;/math&gt;

== Properties ==
Taxicab distance depends on the [[rotation]] of the coordinate system, but does not depend on its [[reflection (mathematics)|reflection]] about a coordinate axis or its [[translation (geometry)|translation]]. Taxicab geometry satisfies all of [[Hilbert's axioms]] (a formalization of [[Euclidean geometry]]) except for the [[Congruence (geometry)#Determining congruence|side-angle-side axiom]], as two triangles with equally "long" two sides and an identical angle between them are typically not [[Congruence (geometry)#Congruence of triangles|congruent]] unless the mentioned sides happen to be parallel.

=== Circles ===

[[File:TaxicabGeometryCircle.svg|thumb|100px|right|Circles in discrete and continuous taxicab geometry]]

A [[circle]] is a set of points with a fixed distance, called the ''[[radius]]'', from a point called the ''center''.  In taxicab geometry, distance is determined by a different metric than in Euclidean geometry, and the shape of circles changes as well. Taxicab circles are [[square (geometry)|square]]s with sides oriented at a 45° angle to the coordinate axes. The image to the right shows why this is true, by showing in red the set of all points with a fixed distance from a center, shown in blue. As the size of the city blocks diminishes, the points become more numerous and become a rotated square in a continuous taxicab geometry. While each side would have length &lt;math&gt;\sqrt{2}r&lt;/math&gt; using a [[Euclidean metric]], where ''r'' is the circle's radius, its length in taxicab geometry is 2''r''. Thus, a circle's circumference is 8''r''. Thus, the value of a geometric analog to [[Pi|&lt;math&gt;\pi &lt;/math&gt;]] is 4 in this geometry. The formula for the unit circle in taxicab geometry is &lt;math&gt;|x| + |y| = 1&lt;/math&gt; in [[Cartesian coordinates]] and

:&lt;math&gt;r = \frac{1}{| \sin \theta| + |\cos\theta|}&lt;/math&gt;

in [[polar coordinates]].

A circle of radius 1 (using this distance) is the [[von Neumann neighborhood]] of its center.

A circle of radius ''r'' for the [[Chebyshev distance]] ([[Lp space|L&lt;sub&gt;∞&lt;/sub&gt; metric]]) on a plane is also a square with side length 2''r'' parallel to the coordinate axes, so planar Chebyshev distance can be viewed as equivalent by rotation and scaling to planar taxicab distance. However, this equivalence between L&lt;sub&gt;1&lt;/sub&gt; and L&lt;sub&gt;∞&lt;/sub&gt; metrics does not generalize to higher dimensions.

Whenever each pair in a collection of these circles has a nonempty intersection, there exists an intersection point for the whole collection; therefore, the Manhattan distance forms an [[injective metric space]].

== Applications ==

=== Measures of distances in chess ===
In [[chess]], the distance between squares on the [[chessboard]] for [[rook (chess)|rook]]s is measured in taxicab distance; [[king (chess)|king]]s and [[queen (chess)|queen]]s use [[Chebyshev distance]], and [[bishop (chess)|bishop]]s use the taxicab distance (between squares of the same color) on the chessboard rotated 45 degrees, i.e., with its diagonals as coordinate axes. To reach from one square to another, only kings require the number of moves equal to their respective distance; rooks, queens and bishops require one or two moves (on an empty board, and assuming that the move is possible at all in the bishop's case).

=== Compressed sensing ===

In solving an [[underdetermined system]] of linear equations, the [[Regularization (mathematics)|regularisation]] term for the parameter vector is expressed in terms of the &lt;math&gt;\ell1&lt;/math&gt;-norm (taxicab geometry) of the vector.&lt;ref&gt;For most large underdetermined systems of linear equations the minimal &lt;math&gt;\ell1&lt;/math&gt;-norm solution is also the sparsest solution; See {{cite journal | last= Donoho|first= David L|journal= Communications on pure and applied mathematics|volume= 59|pages= 797–829|year=2006|doi=10.1002/cpa.20132|title=For most large underdetermined systems of linear equations the minimal &lt;math&gt;\ell1&lt;/math&gt;-norm solution is also the sparsest solution}}&lt;/ref&gt; This approach appears in the signal recovery framework called [[compressed sensing]].

=== Differences of frequency distributions ===
Taxicab geometry can be used to assess the differences in discrete frequency distributions. For example, in [[RNA splicing]] positional distributions of [[hexamers]], which plot the probability of each hexamer appearing at each given [[nucleotide]] near a splice site, can be compared with L1-distance. Each position distribution can be represented as a vector where each entry represents the likelihood of the hexamer starting at a certain nucleotide. A large L1-distance between the two vectors indicates a significant difference in the nature of the distributions while a small distance denotes similarly shaped distributions. This is equivalent to measuring the area between the two distribution curves because the area of each segment is the absolute difference between the two curves' likelihoods at that point. When summed together for all segments, it provides the same measure as L1-distance.&lt;ref name="lim"&gt;{{cite journal|last1=Lim|first1=Kian Huat|last2=Ferraris|first2=Luciana|last3=Filloux|first3=Madeleine E.|last4=Raphael|first4=Benjamin J.|last5=Fairbrother|first5=William G.|title=Using positional distribution to identify splicing elements and predict pre-mRNA processing defects in human genes|journal=Proceedings of the National Academy of Sciences of the United States of America|date=5 July 2011|volume=108|issue=27|pages=11093–11098|pmid= 21685335|doi=10.1073/pnas.1101135108|url=http://www.pnas.org/content/108/27/11093?tab=author-info|accessdate=7 June 2016|pmc=3131313}}&lt;/ref&gt;

==History==
The ''L''&lt;sup&gt;1&lt;/sup&gt; metric was used in [[regression analysis]] in 1757 by [[Roger Joseph Boscovich]].&lt;ref name=Stigler1986&gt;{{cite book |last=Stigler |first=S. M. |year=1986 |title=The History of Statistics: The Measurement of Uncertainty Before 1900 |publisher=Harvard University Press |isbn=0674403401 }}&lt;/ref&gt; The geometric interpretation dates to the late 19th century and the development of [[non-Euclidean geometries]], notably by [[Hermann Minkowski]] and his [[Minkowski inequality]], of which this geometry is a special case, particularly used in the [[geometry of numbers]], {{harv|Minkowski|1910}}. The formalization of [[Lp space|''L''&lt;sup&gt;p&lt;/sup&gt; spaces]] is credited to {{harv|Riesz|1910}}.

==See also==
*[[Normed vector space]]
*[[Metric (mathematics)|Metric]]
*[[Orthogonal convex hull]]
*[[Hamming distance]]
*[[Fifteen puzzle]]
*[[Random walk]]
*[[Manhattan wiring]]

==Notes==
{{Reflist}}

==References ==
{{refbegin}}
*{{cite book
 | author     = Eugene F. Krause
 | title      = Taxicab Geometry
 | year       = 1987
 | publisher  = Dover
 | isbn         = 0-486-25202-7
}}
*{{Citation | last1=Minkowski | first1=Hermann | author1-link=Hermann Minkowski | title=Geometrie der Zahlen | url=https://archive.org/details/geometriederzahl00minkrich | publisher=R. G. Teubner | location=Leipzig and Berlin | mr=0249269 | year=1910 | jfm=41.0239.03 | accessdate=2016-02-28}}
*{{citation
|last=Riesz|first=Frigyes|authorlink=Frigyes Riesz
|title=Untersuchungen über Systeme integrierbarer Funktionen|journal=Mathematische Annalen|volume=69|year=1910|pages=449–497
|doi=10.1007/BF01457637
|issue=4}}
{{refend}}

==External links==
*{{mathworld | title = Taxicab Metric | urlname = TaxicabMetric}}
*[https://xlinux.nist.gov/dads/HTML/manhattanDistance.html Manhattan distance]. Paul E. Black, [https://www.nist.gov/dads/ Dictionary of Algorithms and Data Structures], NIST
*[http://www.ams.org/featurecolumn/archive/taxi.html Taxi!] - AMS column about Taxicab geometry

[[Category:Digital geometry]]
[[Category:Metric geometry]]
[[Category:Mathematical chess problems]]
[[Category:Norms (mathematics)]]
[[Category:Similarity and distance measures]]
[[Category:Distance]]</text>
      <sha1>sosciy8rmc36tzabtp35txtw2e623lf</sha1>
    </revision>
  </page>
  <page>
    <title>Tomographic reconstruction</title>
    <ns>0</ns>
    <id>995908</id>
    <revision>
      <id>859412712</id>
      <parentid>858522367</parentid>
      <timestamp>2018-09-13T22:00:52Z</timestamp>
      <contributor>
        <username>Bikingdog</username>
        <id>32836380</id>
      </contributor>
      <comment>/* Iterative Reconstruction Algorithm */ add another example</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17223">'''Tomographic reconstruction''' is a type of multidimensional [[inverse problem]] where the challenge is to yield an estimate of a specific system from a finite number of [[Projection (linear algebra)|projections]]. The mathematical basis for tomographic imaging was laid down by [[Johann Radon]]. A notable example of applications is the [[Operation_of_computed_tomography#Tomographic_reconstruction|reconstruction]] of [[CT scan|computed tomography]] (CT) where cross-sectional images of patients are obtained in non-invasive manner. Recent developments have seen the [[Radon transform]] and its inverse used for tasks related to realistic object insertion required for testing and evaluating [[computed tomography]] use in [[airport security]].&lt;ref name="megherbi13radon"&gt;{{cite book|url=http://breckon.eu/toby/publications/papers/megherbi13radon.pdf|title=Proc. SPIE Optics and Photonics for Counterterrorism, Crime Fighting and Defence|date=October 2013|publisher=SPIE|volume=8901|pages=1–7|chapter=Radon Transform based Metal Artefacts Generation in 3D Threat Image Projection|doi=10.1117/12.2028506|author=Megherbi, N., Breckon, T.P., Flitton, G.T., Mouton, A.|number=B|accessdate=5 November 2013}}&lt;/ref&gt;

This article applies in general to reconstruction methods for all kinds of [[tomography]], but some of the terms and physical descriptions refer directly to the [[Operation_of_computed_tomography#Tomographic_reconstruction|reconstruction of X-ray computed tomography]].

== Introducing formula ==
[[Image:Tomographic fig1.png|thumb|Figure 1: Parallel beam geometry utilized in tomography and tomographic reconstruction. Each projection, resulting from tomography under a specific angle, is made up of the set of line integrals through the object.]]
[[Image:Ct skull.jpg|thumb|Resulting tomographic image from a plastic skull phantom. Projected X-rays are clearly visible on this slice taken with a CT-scan as image [[Visual artifact|artifacts]], due to limited amount of projection slices over angles.]]
The projection of an object, resulting from the tomographic measurement process at a given angle &lt;math&gt;\theta&lt;/math&gt;, is made up of a set of [[line integrals]] (see Fig. 1). A set of many such projections under different angles organized in 2D is called sinogram (see Fig. 3). In X-ray CT, the line integral represents the total attenuation of the beam of [[x-rays]] as it travels in a straight line through the object. As mentioned above, the resulting image is a 2D (or 3D) model of the [[attenuation coefficient]]. That is, we wish to find the image &lt;math&gt;\mu(x,y)&lt;/math&gt;. The simplest and easiest way to visualise the method of scanning is the system of [[parallel projection]], as used in the first scanners. For this discussion we consider the data to be collected as a series of parallel rays, at position, across a projection at angle &lt;math&gt;\theta&lt;/math&gt;. This is repeated for various angles. [[Attenuation]] occurs [[exponential decay|exponentially]] in tissue:

:&lt;math&gt;I = I_0\exp\left({-\int\mu(x,y)\,ds}\right)&lt;/math&gt;

where &lt;math&gt;\mu(x,y)&lt;/math&gt; is the attenuation coefficient as a function of position. Therefore, generally the total attenuation &lt;math&gt;p&lt;/math&gt; of a ray at position, on the projection at angle &lt;math&gt;\theta&lt;/math&gt;, is given by the line integral:

:&lt;math&gt;p_{\theta}(r) = \ln \left(\frac{I}{I_0}\right) = -\int\mu(x,y)\,ds&lt;/math&gt;

Using the coordinate system of Figure 1, the value of &lt;math&gt;r&lt;/math&gt; onto which the point &lt;math&gt;(x,y)&lt;/math&gt; will be projected at angle &lt;math&gt;\theta&lt;/math&gt; is given by:

:&lt;math&gt;x\cos\theta + y\sin\theta = r\ &lt;/math&gt;

So the equation above can be rewritten as

:&lt;math&gt;p_{\theta}(r)=\int^\infty_{-\infty}\int^\infty_{-\infty}f(x,y)\delta(x\cos\theta+y\sin\theta-r)\,dx\,dy&lt;/math&gt;

where &lt;math&gt;f(x,y)&lt;/math&gt; represents &lt;math&gt;\mu(x,y)&lt;/math&gt;. This function is known as the [[Radon transform]] (or ''sinogram'') of the 2D object.

The [[Fourier transform|Fourier Transform]] of the projection can be written as

&lt;math&gt;P_\theta(\omega)=\int^\infty_{-\infty}\int^\infty_{-\infty}f(x,y)\exp[-j\omega(x\cos\theta+y\sin\theta)]\,dx\,dy = F(\Omega_1,\Omega_2)&lt;/math&gt;       where    &lt;math&gt;\Omega_1 =\omega\cos\theta,     \Omega_2 =\omega\sin\theta &lt;/math&gt;&lt;ref name=":0"&gt;{{Cite book|title=Multidimensional digital signal processing|last=Dudgeon and Mersereau|first=|publisher=Prentice-Hall|year=1984|isbn=|location=|pages=|quote=|via=}}&lt;/ref&gt;

&lt;math&gt;P_\theta(\omega)&lt;/math&gt; represents a slice of the 2D Fourier transform of &lt;math&gt;f(x,y)&lt;/math&gt; at angle &lt;math&gt;\theta&lt;/math&gt;. Using the i[[Inverse Fourier transform|nverse Fourier transform]], the inverse Radon transform formula can be easily derived.

&lt;math&gt;f(x,y) = \frac{1}{2\pi} \int\limits_{0}^{\pi} g_\theta(x\cos\theta+y\sin\theta)d\theta&lt;/math&gt;

where &lt;math&gt;g_\theta(x\cos\theta+y\sin\theta) &lt;/math&gt; is the derivative of the [[Hilbert transform]] of &lt;math&gt;p_{\theta}(r)&lt;/math&gt;

In theory, the inverse Radon transformation would yield the original image. The [[projection-slice theorem]]  tells us that if we had an infinite number of one-dimensional projections of an object taken at an infinite number of angles, we could perfectly reconstruct the original object, &lt;math&gt;f(x,y)&lt;/math&gt;. However, there will only be a finite number of projections available in practice.

Assuming &lt;math&gt;f(x,y)&lt;/math&gt; has effective diameter &lt;math&gt;d&lt;/math&gt; and desired resolution is &lt;math&gt;R_s&lt;/math&gt;, rule of thumb number of projections needed for reconstruction is &lt;math&gt;N &gt; \pi d / R_s&lt;/math&gt;&lt;ref name=":0" /&gt;

== Reconstruction algorithms ==
Practical '''reconstruction algorithms''' have been developed to implement the process of reconstruction of a 3-dimensional object from its projections.&lt;ref name="ref1"&gt;Herman, G. T., Fundamentals of computerized tomography: Image reconstruction from projection,  2nd edition, Springer, 2009&lt;/ref&gt;&lt;ref name=":0" /&gt;  These [[algorithms]] are designed largely based on the mathematics of the [[Radon transform]], statistical knowledge of the data acquisition process and geometry of the data imaging system.

=== Fourier-Domain Reconstruction Algorithm&lt;ref name=":1"&gt;{{Cite journal|last=R. Mersereau, A. Oppenheim|first=|year=1974|title=Digital reconstruction of multidimensional signals from their projections|url=|journal=Proceedings of the IEEE|volume=62|pages=1319–1338|via=|doi=10.1109/proc.1974.9625}}&lt;/ref&gt; ===
Reconstruction can be made using interpolation. Assume &lt;math&gt;N&lt;/math&gt;-projections of &lt;math&gt;f(x,y)&lt;/math&gt; are generated at equally spaced angles, each sampled at same rate. The [[Discrete Fourier transform]] on each projection will yield sampling in the frequency domain. Combining all the frequency-sampled projections would generate a polar raster in the frequency domain. The polar raster will be sparse so interpolation is used to fill the unknown DFT points and reconstruction can be done through [[Inverse discrete Fourier transform|inverse Discrete Fourier transform]]. Reconstruction performance may improve by designing methods to change the sparsity of the polar raster, facilitating the effectiveness of interpolation.

For instance, a concentric square raster in the frequency domain can be obtained by changing the angle between each projection as follow:

&lt;math&gt;\theta' = \frac{R_0}{ \max\{|\cos\theta|, |\sin\theta|\}}&lt;/math&gt;

where &lt;math&gt;R_0&lt;/math&gt; is highest frequency to be evaluated.

The concentric square raster improves computational efficiency by allowing all the interpolation positions to be on rectangular DFT lattice. Furthermore, it reduces the interpolation error.&lt;ref name=":1" /&gt; Yet, the Fourier-Transform algorithm has a disadvantage of producing inherently noisy output.

=== Back Projection Algorithm&lt;ref name=":0" /&gt; ===
In practice of tomographic image reconstruction, often a stabilized and [[Discretization|discretized]] version of the inverse Radon transform is used, known as the [[filtered back projection]] algorithm.

With a sampled discrete system, the inverse Radon Transform is

&lt;math&gt;f(x,y) =  \frac{1}{2\pi} \sum_{i=0}^{N-1}\Delta\theta_i g_i(x\cos\theta_i+y\sin\theta_i)&lt;/math&gt;

&lt;math&gt;g_\theta(t) = p_\theta(t) \cdot k(t) &lt;/math&gt;

where &lt;math&gt;\Delta\theta&lt;/math&gt; is the angular spacing between the projections and &lt;math&gt;k(t) &lt;/math&gt; is radon kernel with frequency response &lt;math&gt;|\omega| &lt;/math&gt;.

The name back-projection comes from the fact that 1D projection needs to be filtered by 1D Radon kernel (back-projected) in order to obtain a 2D signal. The filter used does not contain DC gain, thus adding [[DC bias]] may be desirable. Reconstruction using back-projection allows better resolution than interpolation method described above. However, it induces greater noise because the filter is prone to amplify high-frequency content.

=== Iterative Reconstruction Algorithm&lt;ref name=":0" /&gt; ===
{{main|Iterative reconstruction}}
Iterative algorithm is computationally intensive but it allows to include ''a priori'' information about the system &lt;math&gt;f(x,y)&lt;/math&gt;.

Let &lt;math&gt;N&lt;/math&gt; be the number of projections, &lt;math&gt;D_i&lt;/math&gt; be the distortion operator for &lt;math&gt;i&lt;/math&gt;th projection taken at an angle &lt;math&gt;\theta_i&lt;/math&gt;. &lt;math&gt;\{\lambda_i\}&lt;/math&gt; are set of parameters to optimize the conversion of iterations.

&lt;math&gt;f_0(x,y) = \sum_{i=1}^N \lambda_i p_{\theta_i}(r) &lt;/math&gt;
[[File:Fan-beam reconstruction of Shepp-Logan Phantom.jpg|thumb|A fan-beam reconstruction of Shepp-Logan Phantom with different sensor spacing. Smaller spacing between the sensors allow finer reconstruction. The figure was generated by using MATLAB.]]
&lt;math&gt;f_k(x,y) = f_{k-1} (x,y) + \sum_{i=1}^N \lambda_i [p_{\theta_i}(r)-D_if_{k-1}(x,y)]&lt;/math&gt;

An alternative family of recursive tomographic reconstruction algorithms are the [[Algebraic Reconstruction Technique]]&lt;nowiki/&gt;s and [[SAMV (algorithm)|iterative Sparse Asymptotic Minimum Variance]].

=== Fan-Beam Reconstruction ===
Use of a noncollimated fan beam is common since a [[Collimated light|collimated]] beam of radiation is difficult to obtain.  Fan beams will generate series of line integrals, not parallel to each other, as projections. The fan-beam system will require 360 degrees range of angles which impose mechanical constraint, however, it allows faster signal acquisition time which may be advantageous in certain settings such as in the field of medicine. Back projection follows a similar 2 step procedure that yields reconstruction by computing weighted sum back-projections obtained from filtered projections.

== Tomographic reconstruction software ==

For flexible tomographic reconstruction, open source toolboxes are available, such as [https://tomopy.readthedocs.io TomoPy]&lt;ref name="TOMOPY"&gt;{{cite journal| author=Gursoy D, De Carlo F, Xiao X, and Jacobsen C| journal=Journal of Synchrotron Radiation| title=TomoPy: A framework for the analysis of synchrotron tomographic data |date=2014| volume=22| pages=1188–1193| doi=10.1107/S1600577514013939| pmc=4181643}}&lt;/ref&gt;, [https://github.com/odlgroup/odl ODL] or the ASTRA toolbox.&lt;ref name="ASTRAEM"&gt;{{cite journal| author=Van Aarle, W., Palenstijn, W.J., De Beenhouwer, J., Altantzis T., Bals S., Batenburg K. J., and J. Sijbers| journal=Ultramicroscopy| title=The ASTRA Toolbox: a platform for advanced algorithm development in electron tomography |date=October 2015| volume=157| pages=35–47| doi=10.1016/j.ultramic.2015.05.002| pmid=26057688}}&lt;/ref&gt;&lt;ref name="ASTRACT"&gt;{{cite journal| author=W. Van Aarle, W J. Palenstijn, J. Cant, E. Janssens, F. Bleichrodt, A. Dabravolski, J. De Beenhouwer, K. J. Batenburg, and J. Sijbers| journal=Optics Express| title=Fast and flexible X-ray tomography using the ASTRA toolbox |date=2016| volume=24| number=22| pages=35–47| doi=10.1364/OE.24.025129| bibcode=2016OExpr..2425129V}}&lt;/ref&gt; TomoPy is an open-source Python toolbox to perform tomographic data processing and image reconstruction tasks at the [[Advanced Photon Source]] at [[Argonne National Laboratory]]. TomoPy toolbox is specifically designed to be easy to use and deploy at a synchrotron facility beamline. It supports reading many common synchrotron data formats from disk through Scientific Data Exchange,&lt;ref name="DXCHANGE"&gt;{{cite journal| author=De Carlo F, Gursoy D, Marone F, Rivers M, Parkinson YD, Khan F, Schwarz N, Vine DJ, Vogt S, Gleber SC, Narayanan S, Newville M, Lanzirotti T, Sun Y, Hong YP, Jacobsen C| journal=Journal of Synchrotron Radiation| title=Scientific Data Exchange: a schema for HDF5-based storage of raw and analyzed data |date=2014| volume=22| pages=35–47| doi=10.1107/S160057751401604X}}&lt;/ref&gt; and includes several other processing algorithms commonly used for synchrotron data. TomoPy also includes several reconstruction algorithms, which can be run on multi-core workstations and large-scale computing facilities.&lt;ref name="CLUSTER"&gt;{{cite journal| author=Bicer T, Gursoy D, Kettimuthu R, De Carlo F, and Foster I| journal=Journal of Synchrotron Radiation| title=Optimization of tomographic reconstruction workflows on geographically distributed resources |date=2016| volume=23| number=4| pages=997–1005| doi=10.1107/S1600577516007980| pmc=5315096}}&lt;/ref&gt;  The ASTRA Toolbox is a MATLAB toolbox of high-performance GPU primitives for 2D and 3D tomography, from 2009–2014 developed by [http://visielab.uantwerpen.be iMinds-Vision Lab], University of Antwerp and since 2014 jointly developed by iMinds-VisionLab, UAntwerpen and CWI, Amsterdam. The toolbox supports parallel, fan, and cone beam, with highly flexible source/detector positioning. A large number of reconstruction algorithms are available through TomoPy and the ASTRA toolkit, including FBP, Gridrec, [[Algebraic_reconstruction_technique|ART]], SIRT, SART, BART, CGLS, PML, MLEM and OSEM. Recently, the ASTRA toolbox has been integrated in the TomoPy framework.&lt;ref name="ASTRATOMOPY"&gt;{{cite journal| author=Pelt DM, Gursoy D, Batenburg KJ, De Carlo F, Palenstijna WJ, and Sijbers J| journal=Journal of Synchrotron Radiation| title=Integration of TomoPy and the ASTRA toolbox for advanced processing and reconstruction of tomographic synchrotron data |date=2016| volume=23| pages=842–849| doi=10.1107/S1600577516005658| pmc=5315009}}&lt;/ref&gt; By integrating the ASTRA toolbox in the TomoPy framework, the optimized GPU-based reconstruction methods become easily available for synchrotron beamline users, and users of the ASTRA toolbox can more easily read data and use TomoPy’s other functionality for data filtering and artifact correction.

== Gallery ==
Shown in the gallery is the complete process for a simple object tomography and the following tomographic reconstruction based on ART.
&lt;gallery mode="packed" heights="200px" style="text-align:left"&gt;
File:Sinogram Source - Two Squares Phantom.png|Fig. 2: [[Imaging phantom|Phantom]] object, two kitty-corner squares.
File:Sinogram Result - Two Squares Phantom.png|Fig. 3: Sinogram of the phantom object (Fig.2) resulting from tomography. 50 projection slices were taken over 180 degree angle, equidistantly sampled (only by coincidence the x-axis marks displacement at -50/50 units).
File:Algebraic Reconstruction Technique - animated.gif|Fig.4: [[Algebraic Reconstruction Technique|ART]] based tomographic reconstruction of the sinogram of Fig.3, presented as animation over the iterative reconstruction process. The original object could be approximatively reconstructed, as the resulting image has some [[visual artifact]]s.
&lt;/gallery&gt;

== See also ==
* [[Operation of computed tomography#Tomographic reconstruction]]
* [[Cone beam reconstruction]]
* [[Industrial CT scanning]]
* [[Industrial Tomography Systems]]

== References ==
{{Reflist}}

== Further reading ==
*[[Avinash Kak]] &amp; [[Malcolm Slaney]] (1988), Principles of Computerized Tomographic Imaging, IEEE Press, {{ISBN|0-87942-198-3}}.
* Bruyant, P.P. [http://jnm.snmjournals.org/content/43/10/1343.long "Analytic and iterative reconstruction algorithms in SPECT"] Journal of Nuclear Medicine 43(10):1343-1358, 2002

== External links ==
*{{cite web|url=http://www.slaney.org/pct/|title=Principles of  Computerized Tomographic Imaging|first=A. C. Kak and Malcolm|last=Slaney|website=Slaney.org|accessdate=7 September 2018}}
*[http://www.itk.org/ Insight ToolKit; open source tomographic support software]
*{{cite web|url=http://tomopy.readthedocs.org|title=TomoPy — TomoPy 1.1.3 documentation|website=Tomopy.readthedocs.org|accessdate=7 September 2018}}
*[http://visielab.uantwerpen.be/research/tomography ASTRA (All Scales Tomographic Reconstruction Antwerp) toolbox; very flexible, fast and open source software for computed tomographic reconstruction]
*[http://niftyrec.scienceontheweb.net/ NiftyRec; comprehensive open source tomographic reconstruction software; Matlab and Python scriptable]
*[http://tomviz.org/ Open-source tomographic reconstruction and visualization tool]
*{{cite web|url=http://www.itoms.com/|title=ITS plc - Electrical Process Tomography For Industrial Visualization|website=Itoms.com|accessdate=7 September 2018}}

{{Medical imaging}}

[[Category:Radiology]]
[[Category:Medical imaging]]
[[Category:Inverse problems]]
[[Category:Multidimensional signal processing]]
[[Category:Signal processing]]
[[Category:Tomography]]</text>
      <sha1>04lih6jy7ljr69771skrmh2er6tfxoh</sha1>
    </revision>
  </page>
  <page>
    <title>UML-based web engineering</title>
    <ns>0</ns>
    <id>8421352</id>
    <revision>
      <id>570771146</id>
      <parentid>546615590</parentid>
      <timestamp>2013-08-30T06:06:51Z</timestamp>
      <contributor>
        <username>Vegaswikian</username>
        <id>214427</id>
      </contributor>
      <comment>Disambiguated: [[metamodel]] → [[metamodeling]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="899">{{unreferenced|date=November 2012}}
{{advertisement|date=November 2012}}

'''UWE''' ('''UML-based Web Engineering''') is a [[software engineering]] approach for the development of [[Web application]]s. UWE provides a [[Unified Modeling Language|UML]] profile (UML extension), a [[metamodeling|metamodel]], [[model-driven development]] process and tool support (ArgoUWE) for the systematic design of Web applications. UWE follows the [[separation of concerns]] building separate models for requirements, content, [[hypertext]], presentation, process, adaptivity and architecture.    

The key aspects that distinguish UWE are reliance on [[Object Management Group|OMG]] standards and an [[open source]] environment. 

== See also ==
* [[Web engineering]]
* [[Web modeling]]

==External links==
* [http://www.pst.ifi.lmu.de/projekte/uwe UWE site]

[[Category:Unified Modeling Language]]


{{uml-stub}}</text>
      <sha1>hg54hlcbwja97bhqfvalmoelkaz3hj2</sha1>
    </revision>
  </page>
  <page>
    <title>Unique negative dimension</title>
    <ns>0</ns>
    <id>1869181</id>
    <revision>
      <id>823890145</id>
      <parentid>601680300</parentid>
      <timestamp>2018-02-04T01:19:31Z</timestamp>
      <contributor>
        <username>Emk9</username>
        <id>32634809</id>
      </contributor>
      <comment>not an orphaned page</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="763">{{Unreferenced|date=December 2009}}


'''Unique negative dimension''' (UND) is a complexity measure for the model of [[learning from positive examples]].
The unique negative dimension of a class &lt;math&gt;C&lt;/math&gt; of concepts is the size of the maximum subclass &lt;math&gt;D\subseteq C&lt;/math&gt; such that for every concept &lt;math&gt;c\in D&lt;/math&gt;, we have &lt;math&gt;\cap (D\setminus \{c\})\setminus c &lt;/math&gt; is nonempty.

This concept was originally proposed by M. Gereb-Graus in "Complexity of learning from one-side examples", Technical Report TR-20-89, Harvard University Division of Engineering and Applied Science, 1989.

==See also==
* [[Computational learning theory]]

{{DEFAULTSORT:Unique Negative Dimension}}
[[Category:Computational learning theory]]


{{Compu-AI-stub}}</text>
      <sha1>qij12ixw9lvq9sj2w7e9l3ux1ea70w8</sha1>
    </revision>
  </page>
  <page>
    <title>Étale spectrum</title>
    <ns>0</ns>
    <id>54321373</id>
    <revision>
      <id>810715263</id>
      <parentid>793119498</parentid>
      <timestamp>2017-11-17T00:19:57Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <minor/>
      <comment>re-categorisation per [[WP:CFD|CFD]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2002">In [[algebraic geometry]], the '''étale spectrum''' of a [[commutative ring]] or an [[E-infinity ring|'''E'''&lt;sub&gt;∞&lt;/sub&gt;]]-ring, denoted by Spec&lt;sup&gt;ét&lt;/sup&gt; or Spét, is an analog of the [[prime spectrum]] Spec of a commutative ring that is obtained by replacing [[Zariski topology]] with [[étale topology]]. The precise definition depends on one's formalism. But the idea of the definition itself is simple. The usual prime spectrum Spec enjoys the relation: for a scheme (''S'', ''O''&lt;sub&gt;''S''&lt;/sub&gt;) and a commutative ring ''A'',
:&lt;math&gt;\operatorname{Hom}(S, \operatorname{Spec}(A)) \simeq \operatorname{Hom}(A, \Gamma(S, \mathcal{O}_S))&lt;/math&gt;
where Hom on the left is for [[morphism of schemes|morphisms of schemes]] and Hom on the right [[ring homomorphism]]s. This is to say Spec is the [[right adjoint]] to the global section functor &lt;math&gt;(S, \mathcal{O}_S) \mapsto \Gamma(S, \mathcal{O}_S)&lt;/math&gt;. So, roughly, one can (and typically does) simply define the étale spectrum Spét to be the right adjoint to the global section functor on the category of "spaces" with étale topology.&lt;ref&gt;{{harvnb|Lurie|loc=Remark 1.2.3.6.}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Lurie|loc=Remark 1.4.2.7.}}&lt;/ref&gt;

Over a field of characteristic zero, K. Behrend constructs the étale spectrum of a graded algebra called a perfect resolving algebra.&lt;ref&gt;{{cite arxiv|last=Behrend|first=Kai|date=2002-12-16|title=Differential Graded Schemes II: The 2-category of Differential Graded Schemes|eprint=math/0212226}}&lt;/ref&gt; He then defines a [[differential graded scheme]] (a type of a [[derived scheme]]) as one that is étale-locally such an étale spectrum.

The notion makes sense in the usual algebraic geometry but appears more frequently in the context of [[derived algebraic geometry]].

== Notes ==
{{reflist}}

== References ==
*Lurie, J., ''[http://www.math.harvard.edu/~lurie/papers/SAG-rootfile.pdf Spectral Algebraic Geometry (under construction)]''

[[Category:Algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>ckpk7k3x0m9dzd3xz4o2xvtpy9on36h</sha1>
    </revision>
  </page>
  <page>
    <title>Χ-bounded</title>
    <ns>0</ns>
    <id>56030164</id>
    <revision>
      <id>846306491</id>
      <parentid>816263962</parentid>
      <timestamp>2018-06-17T21:27:35Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8684">{{DISPLAYTITLE:''χ''-bounded}}
In [[graph theory]], a '''&lt;math&gt;\chi&lt;/math&gt;-bounded''' family &lt;math&gt;\mathcal{F}&lt;/math&gt; of graphs is one for which there is some function &lt;math&gt;c&lt;/math&gt; such that, for every integer &lt;math&gt;t&lt;/math&gt; the graphs in &lt;math&gt;\mathcal{F}&lt;/math&gt; with no &lt;math&gt;t&lt;/math&gt;-vertex [[clique (graph theory)|clique]] can be [[graph coloring|colored]] with at most &lt;math&gt;c(t)&lt;/math&gt; colors. This concept and its notation were formulated by [[András Gyárfás]].{{r|g87}} The use of the Greek letter [[Chi (letter)|chi]] in the term &lt;math&gt;\chi&lt;/math&gt;-bounded is based on the fact that the [[chromatic number]] of a graph &lt;math&gt;G&lt;/math&gt; is commonly denoted &lt;math&gt;\chi(G)&lt;/math&gt;.

==Nontriviality==
It is not true that the family of all graphs is &lt;math&gt;\chi&lt;/math&gt;-bounded.
As {{harvtxt|Zykov|1949}} and {{harvtxt|Mycielski|1955}} showed, there exist [[triangle-free graph]]s of arbitrarily large chromatic number,{{r|z|m}} so for these graphs it is not possible to define a finite value of &lt;math&gt;t(3)&lt;/math&gt;.
Thus, &lt;math&gt;\chi&lt;/math&gt;-boundedness is a nontrivial concept, true for some graph families and false for others.{{r|pkk}}

==Specific classes==
Every class of graphs of bounded [[chromatic number]] is (trivially) &lt;math&gt;\chi&lt;/math&gt;-bounded, with &lt;math&gt;c(t)&lt;/math&gt; equal to the bound on the chromatic number. This includes, for instance, the [[planar graph]]s, the [[bipartite graph]]s, and the graphs of bounded [[degeneracy (graph theory)|degeneracy]]. Complementarily, the graphs in which the [[independence number]] is bounded are also &lt;math&gt;\chi&lt;/math&gt;-bounded, as [[Ramsey's theorem]] implies that they have large cliques.

[[Vizing's theorem]] can be interpreted as stating that the [[line graph]]s are &lt;math&gt;\chi&lt;/math&gt;-bounded, with &lt;math&gt;c(t)=t&lt;/math&gt;.{{r|cs|km}} The [[claw-free graph]]s more generally are also &lt;math&gt;\chi&lt;/math&gt;-bounded with &lt;math&gt;c(t)\le (t-1)^2&lt;/math&gt;. This can be seen by using Ramsey's theorem to show that, in these graphs, a vertex with many neighbors must be part of a large clique.
This bound is nearly tight in the worst case, but connected claw-free graphs that include three mutually-nonadjacent vertices have even smaller chromatic number, &lt;math&gt;c(t)=2(t-1)&lt;/math&gt;.{{r|cs}}

Other &lt;math&gt;\chi&lt;/math&gt;-bounded graph families include:
*The [[perfect graph]]s, with &lt;math&gt;c(t)=t-1&lt;/math&gt;
*The graphs of [[boxicity]] two{{r|ag60}}
*The graphs of bounded [[clique-width]]{{r|dk12}}
*The [[intersection graph]]s of scaled and translated copies of any compact convex shape in the plane{{r|kkn04}}
*The [[circle graph]]s, and (generalizing circle graphs) the "outerstring graphs", intersection graphs of bounded curves in the plane that all touch the unbounded face of the [[arrangement of lines|arrangement]] of the curves{{r|rw14}}

However, although intersection graphs of convex shapes, circle graphs, and outerstring graphs are all special cases of [[string graph]]s, the string graphs themselves are not &lt;math&gt;\chi&lt;/math&gt;-bounded.
They include as a special case the intersection graphs of [[line segment]]s, which are also not &lt;math&gt;\chi&lt;/math&gt;-bounded.{{r|pkk}}

==Unsolved problems==
{{unsolved|mathematics|Are all tree-free graph classes &lt;math&gt;\chi&lt;/math&gt;-bounded?}}
According to the [[Gyárfás–Sumner conjecture]], for every [[Tree (graph theory)|tree]] &lt;math&gt;T&lt;/math&gt;, the graphs that do not contain &lt;math&gt;T&lt;/math&gt; as an [[induced subgraph]] are &lt;math&gt;\chi&lt;/math&gt;-bounded. 
For instance, this would include the case of claw-free graphs, as a claw is a special kind of tree.
However, the conjecture is known to be true only for certain special trees, including [[Path graph|paths]]{{r|g87}} and radius-two trees.{{r|kp94}}

Another unsolved problem on &lt;math&gt;\chi&lt;/math&gt;-bounded was posed by Louis Esperet, who asked whether every hereditary class of graphs that is &lt;math&gt;\chi&lt;/math&gt;-bounded has a function &lt;math&gt;c(t)&lt;/math&gt; that grows at most polynomially as a function of &lt;math&gt;t&lt;/math&gt;.{{r|km}}
{{unsolved|mathematics|In a hereditary &lt;math&gt;\chi&lt;/math&gt;-bounded graph class, is the chromatic number at most polynomial in the clique size?}}

==References==
{{reflist|30em|refs=

&lt;ref name=ag60&gt;{{citation
 | last1 = Asplund | first1 = E.
 | last2 = Grünbaum | first2 = B. | author2-link = Branko Grünbaum
 | journal = Mathematica Scandinavica
 | mr = 0144334
 | pages = 181–188
 | title = On a coloring problem
 | doi = 10.7146/math.scand.a-10607
 | volume = 8
 | year = 1960}}&lt;/ref&gt;

&lt;ref name=cs&gt;{{citation
 | last1 = Chudnovsky | first1 = Maria | author1-link = Maria Chudnovsky
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | issue = 6
 | journal = Journal of Combinatorial Theory
 | mr = 2718677
 | pages = 560–572
 | series = Series B
 | title = Claw-free graphs VI. Colouring
 | doi = 10.1016/j.jctb.2010.04.005
 | volume = 100
 | year = 2010}}&lt;/ref&gt;

&lt;ref name=dk12&gt;{{citation
 | last1 = Dvořák | first1 = Zdeněk
 | last2 = Král' | first2 = Daniel
 | arxiv = 1107.2161
 | doi = 10.1016/j.ejc.2011.12.005
 | issue = 4
 | journal = [[Electronic Journal of Combinatorics]]
 | mr = 3350076
 | pages = 679–683
 | title = Classes of graphs with small rank decompositions are &lt;math&gt;\chi&lt;/math&gt;-bounded
 | volume = 33
 | year = 2012}}&lt;/ref&gt;

&lt;ref name=g87&gt;{{citation
 | last = Gyárfás | first = A. | authorlink = András Gyárfás
 | department = Proceedings of the International Conference on Combinatorial Analysis and its Applications (Pokrzywna, 1985)
 | issue = 3-4
 | journal = Zastosowania Matematyki
 | mr = 951359
 | pages = 413–441 (1988)
 | title = Problems from the world surrounding perfect graphs
 | volume = 19
 | year = 1987}}&lt;/ref&gt;

&lt;ref name=kkn04&gt;{{citation
 | last1 = Kim | first1 = Seog-Jin
 | last2 = Kostochka | first2 = Alexandr
 | last3 = Nakprasit | first3 = Kittikorn
 | issue = 1
 | journal = [[Electronic Journal of Combinatorics]]
 | mr = 2097318
 | at = R52
 | title = On the chromatic number of intersection graphs of convex sets in the plane
 | url = http://www.combinatorics.org/Volume_11/Abstracts/v11i1r52.html
 | volume = 11
 | year = 2004}}&lt;/ref&gt;
 
&lt;ref name=kp94&gt;{{citation
 | last1 = Kierstead | first1 = H. A.
 | last2 = Penrice | first2 = S. G.
 | issue = 2
 | journal = [[Journal of Graph Theory]]
 | mr = 1258244
 | pages = 119–129
 | title = Radius two trees specify &lt;math&gt;\chi&lt;/math&gt;-bounded classes
 | doi = 10.1002/jgt.3190180203
 | volume = 18
 | year = 1994}}&lt;/ref&gt;

&lt;ref name=km&gt;{{citation
 | last1 = Karthick | first1 = T.
 | last2 = Maffray | first2 = Frédéric
 | doi = 10.1007/s00373-015-1651-1
 | issue = 4
 | journal = Graphs and Combinatorics
 | mr = 3514976
 | pages = 1447–1460
 | title = Vizing bound for the chromatic number on some graph classes
 | volume = 32
 | year = 2016}}&lt;/ref&gt;

&lt;ref name=m&gt;{{citation
 | last = Mycielski | first = Jan | authorlink = Jan Mycielski
 | title = Sur le coloriage des graphs
 | journal = Colloq. Math.
 | language = French
 | volume = 3
 | year = 1955
 | pages = 161–162
 | mr = 0069494}}&lt;/ref&gt;

&lt;ref name=pkk&gt;{{citation
 | last1 = Pawlik | first1 = Arkadiusz
 | last2 = Kozik | first2 = Jakub
 | last3 = Krawczyk | first3 = Tomasz
 | last4 = Lasoń | first4 = Michał
 | last5 = Micek | first5 = Piotr
 | last6 = Trotter | first6 = William T. | author6-link = William T. Trotter
 | last7 = Walczak | first7 = Bartosz
 | doi = 10.1016/j.jctb.2013.11.001
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 3171778
 | pages = 6–10
 | series = Series B
 | title = Triangle-free intersection graphs of line segments with large chromatic number
 | volume = 105
 | year = 2014| arxiv = 1209.1595}}&lt;/ref&gt;

&lt;ref name=rw14&gt;{{citation
 | last1 = Rok | first1 = Alexandre
 | last2 = Walczak | first2 = Bartosz
 | contribution = Outerstring graphs are &lt;math&gt;\chi&lt;/math&gt;-bounded
 | doi = 10.1145/2582112.2582115
 | mr = 3382292
 | pages = 136–143
 | publisher = ACM | location = New York
 | title = Proceedings of the Thirtieth Annual Symposium on Computational Geometry (SoCG'14)
 | year = 2014}}&lt;/ref&gt;

&lt;ref name=z&gt;{{citation
 | last = Zykov | first = A. A.
 | issue = 66
 | journal = Mat. Sbornik N.S.
 | language = Russian
 | mr = 0035428
 | pages = 163–188
 | title = О некоторых свойствах линейных комплексов
 | trans-title = On some properties of linear complexes
 | url = http://mi.mathnet.ru/msb5974
 | volume = 24
 | year = 1949}}. Translated into English in ''Amer. Math. Soc. Translation'', 1952, {{MR|0051516}}. As cited by {{harvtxt|Pawlik|Kozik|Krawczyk|Lasoń|2014}}&lt;/ref&gt;

}}

==External links==
*[http://www.openproblemgarden.org/category/chi_bounded Chi-bounded], Open Problem Garden

[[Category:Graph coloring]]</text>
      <sha1>hmncyjkco4pnwg4ywokb9bha2rdi83k</sha1>
    </revision>
  </page>
</mediawiki>
