<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>169 (number)</title>
    <ns>0</ns>
    <id>467754</id>
    <revision>
      <id>846655291</id>
      <parentid>831285818</parentid>
      <timestamp>2018-06-20T03:29:29Z</timestamp>
      <contributor>
        <username>Kinu</username>
        <id>206667</id>
      </contributor>
      <comment>/* In geography */ Connecticut *has* counties, just not county-level governments.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5620">{{example farm|date=September 2017}}
{{Infobox number
| number = 169
| divisor=1, 13, 169
}}

'''169''' ('''one hundred [and] sixty-nine''') is the natural number following [[168 (number)|168]] and preceding [[170 (number)|170]].

==In mathematics==
169 is an [[odd number]], a [[composite number]], and a [[deficient number]].

169 is a [[square number]]: [[13 (number)|13]] x [[13 (number)|13]] = 169, and if each number is reversed the equation is still true: [[31 (number)|31]] x [[31 (number)|31]] = 961. [[144 (number)|144]] shares this property: 12 x 12 = 144, 21 x 21 = 441.

169 is one of the few squares to also be a [[centered hexagonal number]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A003215|title=Sloane's A003215 : Hex (or centered hexagonal) numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-28}}&lt;/ref&gt; Like all odd squares, it is a [[centered octagonal number]]. 169 is an odd-indexed [[Pell number]], thus it is also a [[Markov number]], appearing in the solutions (2, 169, 985), (2, 29, 169), (29, 169, 14701), etc. 169 is the sum of seven consecutive [[prime number|prime]]s: [[13 (number)|13]] + [[17 (number)|17]] + [[19 (number)|19]] + [[23 (number)|23]] + [[29 (number)|29]] + [[31 (number)|31]]  + [[37 (number)|37]]. 169 is a difference in consecutive cubes, equaling &lt;math&gt;8^3-7^3.&lt;/math&gt;

==In astronomy==
* [[169 Zelia]] is a bright [[Asteroid belt|main belt]] [[asteroid]]
* [[Gliese 169]] is an [[Orange (colour)|orange]], main sequence (K7 V) star in the [[constellation]] [[Taurus (constellation)|Taurus]]
* [[QSO B0307+169]] is a [[quasar]] in the [[constellation]] [[Aries (constellation)|Aries]]
* [[Sayh al Uhaymir 169]] is a 206g [[Moon|lunar]] [[meteorite]] found in [[Oman|Sultanate of Oman]]

==In geography==
* [[Pittville No. 169, Saskatchewan]] is a rural municipality in [[Saskatchewan, Canada]]
* The state of [[Connecticut]], which has no county governments, is divided into 169 towns

==In the military==
* {{USNS|Private Jose F. Valdez|T-AG-169}} was a [[United States Navy]] [[technical research ship]] during the [[1960s]]
* {{USS|Chatham|AK-169}} was a United States Navy {{sclass-|Alamosa|cargo ship}} during [[World War II]]
* {{USS|Gallatin|APA-169}} was a United States Navy {{sclass-|Haskell|attack transport}} during World War II
* {{USS|Foote|DD-169}} was a United States Navy {{sclass-|Wickes|destroyer}} following [[World War I]]
* {{USS|Atherton|DE-169}} was a United States Navy {{sclass-|Cannon|destroyer escort}} during World War II
* {{USS|Dolphin|SS-169}} was a United States Navy [[submarine]] during World War II
* [[169th Battalion, CEF]] unit in the [[Canadian Expeditionary Force]] during the World War I
* [[169th Fires Brigade (United States)|169th Fires Brigade]] the [[Army National Guard|US Army National Guard]] [[artillery brigade]], a part of the [[Colorado Army National Guard]]
* The [[United States Air Force]]'s [[169th Fighter Wing]] fighter unit at [[McEntire Joint National Guard Station]], [[South Carolina]]
* [[169 Squadron (disambiguation)|169 or 169th Squadrons]]
** [[169th Airlift Squadron (United States)|169th Airlift Squadron]], a unit of the [[United States Air Force|U.S. Air Force]]
** [[HMLA-169|Marine Light Attack Helicopter Squadron 169]], [[United States Marine Corps]] Light Attack Helicopter Squadron
** [[No. 169 Squadron RAF]], a unit of the [[United Kingdom]] [[Royal Air Force]]

==In transportation==
* [https://web.archive.org/web/20021002070149/http://transit.metrokc.gov/tops/bus/schedules/s169_0_.html Metro Transit Route 169] in [[Seattle, Washington|Seattle]]
* [[169th Street (IND Queens Boulevard Line)|169th Street]] [[metro station|station]] on the [[IND Queens Boulevard Line]] of the [[New York City Subway]] served by the {{NYCS|E}} and {{NYCS|F}} trains
* [[169th Street (IRT Third Avenue Line)|169th Street]] was a [[metro station|station]] on the demolished [[IRT Third Avenue Line]] of the [[New York City Subway]]

==In TV and radio==
* The [[TV aerial plug#Belling-Lee|IEC 169-2 connector]] TV aerial plug

==In other fields==
'''169''' is also:
* The year [[169|AD 169]] or [[169 BC]]
* The [[atomic number]] of an element temporarily called [http://www.flw.com/datatools/periodic/001.php?id=169 Unhexennium]
* 169 is the number of nonequivalent [[Poker probability (Texas hold 'em)#Starting hands|starting hands]] in the [[card game]] [[Texas hold 'em]]
* 169 is known in the [[computer|computing]] world as the first number of an [[IP address#Address autoconfiguration|automatic IPv4 address]] assigned by [[TCP/IP]] when no external [[Computer network|networking]] device is contactable
* [[Minuscule 169]] is a [[Greek language|Greek]] [[Lower case|minuscule]] [[manuscript]] of the [[New Testament]], on parchment

==See also==
* [[List of highways numbered 169]]
* [[List of United States Supreme Court cases, volume 169|United States Supreme Court cases, Volume 169]]
* [[United Nations Security Council Resolution 169]]
* [[St. Joseph Community Consolidated School District 169]]

==External links==
{{Commons category|169 (number)}}
* [http://athensohio.net/reference/number/169/ Number Facts and Trivia: 169]
* [http://www.positiveintegers.org/169 The Positive Integer 169]
* [http://primes.utm.edu/curios/page.php/169.html Prime curiosities: 169]
* [http://www.numdic.com/169 The Number 169]
* [http://www.virtuescience.com/169.html VirtueScience: 169]
* [http://www.numbergossip.com/169 Number Gossip 169]

== References ==
{{Reflist}}
{{Integers|1}}

{{DEFAULTSORT:169 (Number)}}
[[Category:Integers]]</text>
      <sha1>jkcfdop5x51spyn9w1lwo48mp0thh06</sha1>
    </revision>
  </page>
  <page>
    <title>Alternating permutation</title>
    <ns>0</ns>
    <id>4813617</id>
    <revision>
      <id>843391259</id>
      <parentid>843391205</parentid>
      <timestamp>2018-05-28T21:05:25Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>-}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9320">{{distinguish|text=the [[alternating group]]}}

In [[combinatorics|combinatorial]] [[mathematics]], an '''alternating permutation''' (or '''zigzag permutation''') of the set {1, 2, 3, ..., ''n''} is an arrangement of those numbers so that each entry is alternately greater or less than the preceding entry.  For example, the five alternating permutations of {1, 2, 3, 4} are:
* 1, 3, 2, 4 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;because&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1 &lt; 3 &gt; 2 &lt; 4,
* 1, 4, 2, 3 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;because&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;1 &lt; 4 &gt; 2 &lt; 3,
* 2, 3, 1, 4 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;because&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;2 &lt; 3 &gt; 1 &lt; 4,
* 2, 4, 1, 3 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;because&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;2 &lt; 4 &gt; 1 &lt; 3, and
* 3, 4, 1, 2 &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;because&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;3 &lt; 4 &gt; 1 &lt; 2.
This type of permutation was first studied by [[Désiré André]] in the 19th century.&lt;ref&gt;Jessica Millar, N. J. A. Sloane, Neal E. Young, [https://arxiv.org/abs/math/0205218v3 "A New Operation on Sequences: the Boustrouphedon Transform"] Journal of Combinatorial Theory, Series A 76(1):44–54 (1996)&lt;/ref&gt;

Different authors use the term alternating permutation slightly differently: some require that the second entry in an alternating permutation should be larger than the first (as in the examples above), others require that the alternation should be reversed (so that the second entry is smaller than the first, then the third larger than the second, and so on), while others call both types by the name alternating permutation.

The determination of the number ''A''&lt;sub&gt;''n''&lt;/sub&gt; of alternating permutations of the set {1, ..., ''n''} is called '''André's problem'''. The numbers ''A''&lt;sub&gt;''n''&lt;/sub&gt; are known as '''Euler numbers''', '''zigzag numbers''', or '''up/down numbers'''.  When ''n'' is even the number ''A''&lt;sub&gt;''n''&lt;/sub&gt; is known as a '''secant number''', while if ''n'' is odd it is known as a '''tangent number'''.  These latter names come from the study of the [[generating function]] for the sequence.

==Definitions==

A [[permutation]] {{math|''c''&lt;sub&gt;1&lt;/sub&gt;, ..., ''c''&lt;sub&gt;''n''&lt;/sub&gt;}} is said to be ''alternating'' if its entries alternately rise and descend.  Thus, each entry other than the first and the last should be either larger or smaller than both of its neighbors.  Some authors use the term alternating to refer only to the "up-down" permutations for which {{math|''c''&lt;sub&gt;1&lt;/sub&gt; &lt; ''c''&lt;sub&gt;2&lt;/sub&gt; &gt; ''c''&lt;sub&gt;3&lt;/sub&gt; &lt; ...}}, calling the "down-up" permutations that satisfy {{math|''c''&lt;sub&gt;1&lt;/sub&gt; &gt; ''c''&lt;sub&gt;2&lt;/sub&gt; &lt; ''c''&lt;sub&gt;3&lt;/sub&gt; &gt; ...}} by the name ''reverse alternating''.  Other authors reverse this convention, or use the word "alternating" to refer to both up-down and down-up permutations.

There is a simple [[bijection|one-to-one correspondence]] between the down-up and up-down permutations: replacing each entry {{math|''c''&lt;sub&gt;''i''&lt;/sub&gt;}} with {{math|''n'' + 1 - ''c''&lt;sub&gt;''i''&lt;/sub&gt;}} reverses the relative order of the entries.

By convention, in any naming scheme the unique permutations of length 0 (the permutation of the [[empty set]]) and 1 (the permutation consisting of a single entry 1) are taken to be alternating.

== André's theorem ==

The determination of the number ''A''&lt;sub&gt;''n''&lt;/sub&gt; of alternating permutations of the set {1, ..., ''n''} is called ''André's problem''.  The numbers ''A''&lt;sub&gt;''n''&lt;/sub&gt; are variously known as ''Euler numbers'', ''zigzag numbers'', ''up/down numbers'', or by some combinations of these names.  The name [[Euler number]]s in particular is sometimes used for a closely related sequence. The first few values of ''A''&lt;sub&gt;''n''&lt;/sub&gt; are 1, 1, 1, 2, 5, 16, 61, 272, 1385, 7936, 50521, ... {{OEIS|id=A000111}}.

These numbers satisfy a simple recurrence, similar to that of the [[Catalan number]]s: by splitting the set of alternating permutations (both down-up and up-down) of the set {&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;3,&amp;nbsp;...,&amp;nbsp;''n'',&amp;nbsp;''n''&amp;nbsp;+&amp;nbsp;1&amp;nbsp;} according to the position ''k'' of the largest entry {{math|''n'' + 1}}, one can show that

: &lt;math&gt; 2A_{n+1} = \sum_{k=0}^n \binom{n}{k} A_k A_{n-k}&lt;/math&gt;

for all {{math|''n'' ≥ 1}}.  {{harvtxt|André|1881}} used this recurrence to give a [[differential equation]] satisfied by the [[exponential generating function]]

: &lt;math&gt; A(x) = \sum_{n=0}^\infty A_n \frac{x^n}{n!}&lt;/math&gt;

for the sequence {{math|''A&lt;sub&gt;n&lt;/sub&gt;''}}.  He then solved this equation, establishing that

: &lt;math&gt; A(x) = \sec x + \tan x&lt;/math&gt;,

where {{math|sec ''x''}} and {{math|tan ''x''}} are the [[trigonometric functions]] [[trigonometric functions#Reciprocal functions|secant]] and [[tangent (trigonometry)|tangent]].  This result is known as ''André's theorem''.

It follows from André's theorem that the [[radius of convergence]] of the series {{math|''A''(''x'')}} is&amp;nbsp;{{pi}}/2.  This allows one to compute the [[asymptotic expansion]]

: &lt;math&gt; A_n \sim 2 \left(\frac{2}{\pi}\right)^{n + 1} \cdot n! &lt;/math&gt;

of the sequence {{math|''A&lt;sub&gt;n&lt;/sub&gt;''}}.&lt;ref&gt;{{citation
 | last = Stanley | first = Richard P. | authorlink = Richard P. Stanley
 | arxiv = 0912.4240
 | contribution = A survey of alternating permutations
 | doi = 10.1090/conm/531/10466
 | mr = 2757798
 | pages = 165–196
 | publisher = American Mathematical Society | location = Providence, RI
 | series = Contemporary Mathematics
 | title = Combinatorics and graphs
 | volume = 531
 | year = 2010}}&lt;/ref&gt;

==Related integer sequences==

The odd-indexed zigzag numbers (i.e., the tangent numbers) are closely related to [[Bernoulli numbers]].  The relation is given by the formula

: &lt;math&gt;B_{2n} =(-1)^{n-1}\frac{2n}{4^{2n}-2^{2n}} A_{2n-1}&lt;/math&gt;

for&amp;nbsp;''n''&amp;nbsp;&gt;&amp;nbsp;0.

If ''Z''&lt;sub&gt;''n''&lt;/sub&gt; denotes the number of permutations of {1, ..., ''n''} that are either up-down or down-up (or both, for ''n'' &lt; 2) then it follows from the pairing given above that ''Z''&lt;sub&gt;''n''&lt;/sub&gt; =&amp;nbsp;2''A''&lt;sub&gt;''n''&lt;/sub&gt; for ''n''&amp;nbsp;≥&amp;nbsp;2. The first few values of ''Z''&lt;sub&gt;''n''&lt;/sub&gt; are 1, 1, 2, 4, 10, 32, 122, 544, 2770, 15872, 101042, ... {{OEIS|id=A001250}}.

The Euler zigzag numbers are related to Entringer numbers, from which the zigzag numbers may be computed.  The Entringer numbers can be defined recursively as follows:&lt;ref&gt;Weisstein, Eric W. "Entringer Number." From MathWorld--A Wolfram Web Resource. http://mathworld.wolfram.com/EntringerNumber.html&lt;/ref&gt;
: &lt;math&gt; E(0,0) = 1 &lt;/math&gt;
: &lt;math&gt; E(n,0) = 0 \qquad \mbox{for } n &gt; 0 &lt;/math&gt;
: &lt;math&gt; E(n,k) = E(n, k-1) + E(n-1, n-k) &lt;/math&gt;.
The ''n''&lt;sup&gt;th&lt;/sup&gt; zigzag number is equal to the Entringer number ''E''(''n'', ''n'').

The numbers ''A''&lt;sub&gt;2''n''&lt;/sub&gt; with even indices are called '''secant numbers''' or '''zig numbers''': since the secant function is [[even function|even]] and tangent is [[odd function|odd]], it follows from André's theorem above that they are the numerators in the [[Maclaurin series]] of {{math|sec ''x''}}. The first few values are 1, 1, 5, 61, 1385,  50521, ...  {{OEIS|id=A000364}}.

Secant numbers are related to [[Euler number]]s by the formula ''E''&lt;sub&gt;2''n''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;(&amp;minus;1)&lt;sup&gt;''n''&lt;/sup&gt;''A''&lt;sub&gt;2''n''&lt;/sub&gt;. (''E''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0 when ''n'' is odd.)

Correspondingly, the numbers ''A''&lt;sub&gt;2''n''+1&lt;/sub&gt; with odd indices are called '''tangent numbers''' or '''zag numbers'''. The first few values are 1, 2, 16, 272, 7936, ...  {{OEIS|id=A000182}}.

==See also==
* [[Longest alternating subsequence]]
* [[Boustrophedon transform]]
* [[Fence (mathematics)]], a [[partially ordered set]] that has alternating permutations as its linear extensions

== Citations ==
{{Reflist}}

== References ==

*{{Citation
 | last = André
 | first = Désiré
 | author-link = Désiré André
 | title = Développements de séc x et de tang x
 | journal = [[Comptes rendus de l'Académie des sciences]]
 | volume = 88
 | pages = 965–967
 | year = 1879
 | url = http://gallica.bnf.fr/ark:/12148/bpt6k30457/f961.image
}}.

*{{Citation
 | last = André
 | first = Désiré
 | author-link = Désiré André
 | title = Sur les permutations alternées
 | journal = [[Journal de mathématiques pures et appliquées]]
 | series = 3e série,
 | volume = 7
 | year = 1881
 | pages = 167–184
 | url = http://portail.mathdoc.fr/JMPA/PDF/JMPA_1881_3_7_A10_0.pdf
}}.

*{{Cite book
 | first = Richard P.
 | last = Stanley
 | author-link = Richard P. Stanley
 | title = Enumerative Combinatorics
 | volume = Vol. I
 | edition = 2nd
 | publisher = [[Cambridge University Press]]
 | year = 2011
}}

==External links==
* {{MathWorld |title=Alternating Permutation|urlname=AlternatingPermutation}}
* [http://www.voofie.com/content/117/an-explicit-formula-for-the-euler-zigzag-numbers-updown-numbers-from-power-series/ Ross Tang, "An Explicit Formula for the Euler zigzag numbers (Up/down numbers) from power series"] A simple explicit formula for ''A''&lt;sub&gt;''n''&lt;/sub&gt;.
* [http://www-math.mit.edu/~rstan/papers/altperm.pdf "A Survey of Alternating Permutations"], a preprint by [[Richard P. Stanley]]

[[Category:Permutations]]
[[Category:Enumerative combinatorics]]</text>
      <sha1>7iitzc0s642lbh1qgryq3c6ssb6uyxb</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetical set</title>
    <ns>0</ns>
    <id>2342451</id>
    <revision>
      <id>770035138</id>
      <parentid>770034832</parentid>
      <timestamp>2017-03-13T01:45:04Z</timestamp>
      <contributor>
        <ip>24.85.232.10</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4837">{{refimprove|date=August 2011}}
In [[mathematical logic]], an '''arithmetical set''' (or '''arithmetic set''') is a [[set (mathematics)|set]] of [[natural number]]s that can be defined by a formula of first-order [[Peano arithmetic]]. The arithmetical sets are  classified by the [[arithmetical hierarchy]].

The definition can be extended to an arbitrary [[countable set]] ''A'' (e.g. the set of n-[[tuple]]s of [[integers]], the set of [[rational numbers]], the set of formulas in some [[formal language]], etc.) by using [[Gödel number]]s to represent elements of the set and declaring a [[subset]] of ''A'' to be arithmetical if the set of corresponding Gödel numbers is arithmetical.

A function &lt;math&gt;f:\subseteq \mathbb{N}^k \to \mathbb{N}&lt;/math&gt; is called '''arithmetically definable''' if the [[graph of a function|graph]] of &lt;math&gt;f&lt;/math&gt; is an arithmetical set.

A [[real number]] is called '''arithmetical''' if the set of all smaller rational numbers is arithmetical. A [[complex number]] is called arithmetical if its [[real and imaginary parts]] are both arithmetical.

== Formal definition ==

A set ''X'' of natural numbers is '''arithmetical''' or '''arithmetically definable''' if there is a formula φ(''n'') in the language of Peano arithmetic such that each number ''n'' is in ''X'' if and only if φ(''n'') holds in the standard model of arithmetic.  Similarly, a ''k''-ary relation
&lt;math&gt;R(n_1,\ldots,n_k)&lt;/math&gt; is arithmetical if there is a formula 
&lt;math&gt;\psi(n_1,\ldots,n_k)&lt;/math&gt; such that &lt;math&gt;R(n_1,\ldots,n_k) \Leftrightarrow \psi(n_1,\ldots,n_k)&lt;/math&gt; holds for all ''k''-tuples &lt;math&gt;(n_1,\ldots,n_k)&lt;/math&gt; of natural numbers. 

A [[finitary]] function on the natural numbers is called arithmetical if its graph is an arithmetical binary relation.

A set ''A'' is said to be '''arithmetical in''' a set ''B'' if ''A'' is definable by an arithmetical formula which has ''B'' as a set parameter.

== Examples ==

* The set of all [[prime number]]s is arithmetical.
* Every [[recursively enumerable set]] is arithmetical.
* Every [[computable function]] is arithmetically definable.
* The set encoding the [[Halting problem]] is arithmetical.
* [[Chaitin's constant Ω]] is an arithmetical real number.
* [[Tarski's indefinability theorem]] shows that the set of true formulas of first-order arithmetic is not arithmetically definable.

== Properties ==

* The [[complement (set theory)|complement]] of an arithmetical set is an arithmetical set.
* The [[Turing jump]] of an arithmetical set is an arithmetical set.
* The collection of arithmetical sets is countable, but the [[sequence]] of arithmetical sets is not arithmetically definable. Thus, there is no arithmetical formula &amp;phi;(''n'',''m'') that is true if and only if ''m'' is a member of the ''n''th arithmetical predicates.
:In fact, such a formula would describe a decision problem for all finite [[Turing jump]]s, and hence belongs to 0&lt;sup&gt;(&amp;omega;)&lt;/sup&gt;, which cannot be formalized in [[first-order arithmetic]], as [[Arithmetical_hierarchy#Summary_of_main_results|it does not belong to the first-order arithmetical hierarchy]].
* The set of real arithmetical numbers is [[countable set|countable]], [[Dense order|dense]] and [[order-isomorphic]] to the set of rational numbers.

== Implicitly arithmetical sets ==

Each arithmetical set has an arithmetical formula which tells whether particular numbers are in the set.  An alternative notion of definability allows for a formula that does not tell whether particular numbers are in the set but tells whether the set itself satisfies some arithmetical property. 

A set ''Y'' of natural numbers is '''implicitly arithmetical''' or '''implicitly arithmetically definable''' if it is definable with an arithmetical formula that is able to use ''Y'' as a parameter.  That is, if there is a formula &lt;math&gt;\theta(Z)&lt;/math&gt; in the language of Peano arithmetic with no free number variables and a new set parameter ''Z'' and set membership relation &lt;math&gt;\in&lt;/math&gt; such that ''Y'' is the unique set ''Z'' such that &lt;math&gt;\theta(Z)&lt;/math&gt; holds.

Every arithmetical set is implicitly arithmetical; if ''X'' is arithmetically defined by φ(''n'') then it is implicitly defined by the formula
:&lt;math&gt;\forall n [n \in Z \Leftrightarrow \phi(n)]&lt;/math&gt;.
Not every implicitly arithmetical set is arithmetical, however. In particular, the truth set of first-order arithmetic is implicitly arithmetical but not arithmetical.

== See also ==

* [[Arithmetical hierarchy]]
* [[Computable set]]
* [[Computable number]]

== Further reading ==
*Rogers, H. (1967). ''Theory of recursive functions and effective computability.'' McGraw-Hill. {{oclc|527706}}

{{Number systems}}
[[Category:Effective descriptive set theory]]
[[Category:Mathematical logic hierarchies]]
[[Category:Computability theory]]</text>
      <sha1>ddf34wc932sft1stantcdgz568vhvni</sha1>
    </revision>
  </page>
  <page>
    <title>Axial ratio</title>
    <ns>0</ns>
    <id>1938356</id>
    <revision>
      <id>770464397</id>
      <parentid>757006944</parentid>
      <timestamp>2017-03-15T16:09:37Z</timestamp>
      <contributor>
        <username>Iandiver</username>
        <id>5155195</id>
      </contributor>
      <minor/>
      <comment>Link to Ratio</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1931">{{Unreferenced stub|auto=yes|date=December 2009}}
'''Axial ratio''', for any structure or shape with two or more axes, is the [[ratio]] of the length (or magnitude) of those axes to each other - the longer axis divided by the shorter.

In ''chemistry'' or ''materials science'', the axial ratio (symbol P) is used to describe rigid rod-like [[molecule]]s.  It is defined as the length of the rod divided by the rod diameter.

In ''physics'', the axial ratio describes [[electromagnetic radiation]] with elliptical, or circular, [[Polarization (waves)#Parameterization|polarization]].  The axial ratio is the ratio of the magnitudes of the major and minor axis defined by the [[electric field vector]].

==Polarization and the polarization ellipse==
Any fixed polarization can be described in terms of the shape and orientation of the [[polarization ellipse]], which is defined by two parameters: axial ratio AR and tilt angle &lt;math&gt;\tau&lt;/math&gt;. The axial ratio is the ratio of the lengths of the major and minor axes of the ellipse, and is always greater than or equal to one.

Alternatively, polarization can be represented as a point on the surface of the [[Poincaré sphere (optics)|Poincaré sphere]], with &lt;math&gt;2\times \tau&lt;/math&gt; as the [[longitude]] and &lt;math&gt;2\times \epsilon&lt;/math&gt; as the [[latitude]], where &lt;math&gt;\epsilon=\arccot(\pm AR)&lt;/math&gt;. The sign used in the argument of the &lt;math&gt;\arccot&lt;/math&gt; depends on the handedness of the polarization. Positive indicates left hand polarization, while negative indicates right hand polarization, as defined by IEEE.

For the special case of [[circular polarization]], the axial ratio equals 1 (or 0 dB) and the tilt angle is undefined.  For the special case of [[linear polarization]], the axial ratio is infinite.

==See also==
* [[Degree of polarization]]

{{DEFAULTSORT:Axial Ratio}}
[[Category:Ratios]]
[[Category:Polymer physics]]


{{Polymer-stub}}
{{Physics-stub}}</text>
      <sha1>qft6zmgn6fghqz7h61e9cqmdo5ohppi</sha1>
    </revision>
  </page>
  <page>
    <title>Bayesian tool for methylation analysis</title>
    <ns>0</ns>
    <id>30999724</id>
    <revision>
      <id>852211404</id>
      <parentid>852211339</parentid>
      <timestamp>2018-07-27T10:42:40Z</timestamp>
      <contributor>
        <username>Adkelsey</username>
        <id>16651911</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10068">'''Bayesian tool for methylation analysis''', also known as '''BATMAN''', is a statistical tool for analysing [[methylated DNA immunoprecipitation]] (MeDIP) profiles. It can be applied to large datasets generated using either [[oligonucleotide]] arrays (MeDIP-chip) or [[next-generation sequencing]] (MeDIP-seq), providing a quantitative estimation of absolute [[methylation]] state in a region of interest.&lt;ref&gt;Down, T.A. et al. A Bayesian deconvolution strategy for immunoprecipitation-based DNA methylome analysis. ''Nature Biotechnology'' '''26''', 779–85 (2008).&lt;/ref&gt;

[[File:Batman final diagram.tif|thumb|right|'''Batman workflow''']]

==Theory==
MeDIP (methylated DNA immunoprecipitation) is an experimental technique used to assess [[DNA]] methylation levels by using an [[antibody]] to isolate methylated DNA sequences. The isolated fragments of DNA are either hybridized to a microarray chip (MeDIP-chip) or sequenced by next-generation sequencing (MeDIP-seq). While this tells you what areas of the [[genome]] are methylated, it does not give absolute methylation levels. Imagine two different genomic regions, ''A'' and ''B''. Region ''A'' has six CpGs (DNA methylation in mammalian [[somatic cell]]s generally occurs at CpG [[dinucleotide]]s&lt;ref&gt;Lister, R. ''et al''. Human DNA [[methylome]]s at base resolution show widespread [[epigenomic]] differences. ''Nature'' '''462''', 315–22 (2009).&lt;/ref&gt;), three of which are methylated. Region ''B'' has three CpGs, all of which are methylated. As the antibody simply recognizes [[methylated DNA]], it will bind both these regions equally and subsequent steps will therefore show equal signals for these two regions. This does not give the full picture of methylation in these two regions (in region ''A'' only half the CpGs are methylated, whereas in region ''B'' all the CpGs are methylated). Therefore, to get the full picture of methylation for a given region you have to normalize the signal you get from the MeDIP experiment to the number of CpGs in the region, and this is what the Batman [[algorithm]] does. Analysing the MeDIP signal of the above example would give Batman scores of 0.5 for region ''A'' (i.e. the region is 50% methylated) and 1 for region ''B'' (i.e. The region is 100% methylated). In this way Batman converts the signals from MeDIP experiments to absolute methylation levels.

==Development of Batman==
The core principle of the Batman algorithm is to model the effects of varying density of CpG dinucleotides, and the effect this has on MeDIP enrichment of DNA fragments.
The basic assumptions of Batman:
# Almost all DNA methylation in [[mammal]]s happens at CpG dinucleotides.
# Most CpG-poor regions are constitutively methylated while most CpG-rich regions (CpG islands) are constitutively unmethylated.&lt;ref&gt;Bird, A. DNA methylation patterns and epigenetic memory. ''Genes &amp; Development'' '''16''', 6–21 (2002).&lt;/ref&gt;
# There are no fragment biases in MeDIP experiment (approximate range of DNA fragment sizes is 400–700 bp).
# The errors on the [[microarray]] are normally distributed with precision.
# Only methylated CpGs contribute to the observed signal.
# CpG methylation state is generally highly correlated over hundreds of bases,&lt;ref&gt;Eckhardt, F. ''et al''. DNA methylation profiling of human chromosomes 6, 20 and 22. ''Nature Genetics'' '''38''', 1378–85 (2006).&lt;/ref&gt; so CpGs grouped together in 50- or 100-bp windows would have the same methylation state.

Basic parameters in Batman:
# C&lt;sub&gt;cp&lt;/sub&gt;: coupling factor between probe p and CpG dinucleotide ''c'', is defined as the fraction of DNA [[molecule]]s hybridizing to probe ''p'' that contain the CpG&amp;nbsp;''c''.
# C&lt;sub&gt;tot&lt;/sub&gt; : total CpG influence parameter, is defined as the sum of coupling factors for any given probe, which provides a measure of local CpG density
# m&lt;sub&gt;c&lt;/sub&gt; : the methylation status at position ''c'', which represents the fraction of [[chromosome]]s in the sample on which it is methylated. m&lt;sub&gt;c&lt;/sub&gt; is considered as a [[continuous variable]] since the majority samples used in MeDIP studies contain multiple cell-types.
Based on these assumptions, the signal from the MeDIP channel of the MeDIP-chip or MeDIP-seq experiment depends on the degree of enrichment of DNA fragments overlapping that probe, which in turn depends on the amount of [[antibody binding]], and thus to the number of methylated CpGs on those fragments. In Batman model, the complete dataset from a MeDIP/chip experiment, A, can be represented by a statistical model in the form of the following [[probability distribution]]:

: &lt;math&gt; f(A \mid m) = \prod_p \phi \left(A_p \mid A_\text{base} + r\sum_c C_{cp}, \nu^{-1}  \right) ,&lt;/math&gt;

where &lt;math&gt;\phi&lt;/math&gt;(''x''|''μ'',&amp;nbsp;''σ''&lt;sup&gt;2&lt;/sup&gt;) is a [[normal distribution|Gaussian]] [[probability density function]]. Standard [[Bayesian probability|Bayesian]] techniques can be used to infer ''f''(''m''|''A''), that is, the distribution of likely methylation states given one or more sets of MeDIP-chip/MeDIP-seq outputs. To solve this inference problem, Batman uses [[nested sampling]] (http://www.inference.phy.cam.ac.uk/bayesys/) to generate 100 independent samples from ''f''(''m''|''A'') for each tiled region of the genome, then summarizes the most likely methylation state in 100-bp windows by fitting beta distributions to these samples. The modes of the most likely [[beta distribution]]s were used as final methylation calls.

==Work flow of Batman==
{{howto|section|date=October 2017}}
Batman prerequisites:
# Installation: install Batman(freely available from https://github.com/dasmoth/batman under the [[GNU Lesser General Public License]]), Apache ANT, [[MySQL]] [[database server]], and MySQL database connector.
# Prepare dataset: break your [[dataset]] into small blocks, namely [[Region of interest|regions of interest]] (ROIs), each represented by a small number (typically about 100) probes on a microarray.
# Identify the database server: connect to a MySQL database server using both the MySQL administration tool, and many of the Batman programs.
# Initialize the Batman database: create a database on your database server.
# Register the experiments to be analysed.
# Register the array design: The array design (i.e. complete list of probes, with their genomic locations) should be provided as a GFF file.
# Load the array data.
# Load the genome sequence.

Run Batman:
# Calibrate the Batman model: Before any data can be analysed, it is necessary to calibrate each array by estimating how much extra array signal is produced by each methylated CpG. This step can give you a quick idea whether each of your arrays is giving sensible results.
# Sample methylation states from the Batman model: You’ll often have multiple arrays from the same experiment, and these should normally be analysed together to improve the confidence of the final calls. Each chromosome can take several days to process; therefore, if possible, run several in parallel.
# Summarize methylation states to generate the final calls: The “sample” files generated by Batman contain a large set of plausible methylation states for each region. For most purposes, you’ll actually want a single estimate of the likely methylation state at that position, and perhaps an estimate of how confident you can be that this is actually the correct value.

Visualization of Batman Data:
# The output is in [[General feature format|GFF format]]. For each window, a score (range: 0–1) is given which represents a likely fraction of methylation and the interquartile range is given as an estimate of confidence.
# Several [[genome browser]]s are available, such as [[Ensembl]] genome browser, which uses a colour gradient from 20 (bright yellow) to 80 (dark blue) to show the Batman methylation score for each probe in the ROI.
More details related to Batman procedure can be found in Batman manual freely online from https://web.archive.org/web/20110304143135/http://td-blade.gurdon.cam.ac.uk/software/batman/batmanual-alpha-0.2.3.pdf

==Limitations==
It may be useful to take the following points into account when considering using Batman:

# Batman is not a piece of [[software]]; it is an algorithm performed using the [[Command-line interface#Command prompt|command prompt]]. As such it is not especially user-friendly and is quite a computationally technical process.
# Because it is non-commercial, there is very little support when using Batman beyond what is in the manual.
# It is quite time consuming (it can take several days to analyse one chromosome). (Note: In one government lab, running Batman on a set of 100 Agilent Human DNA Methylation Arrays (about 250,000 probes per array) took less than an hour to complete in Agilent's Genomic Workbench software. Our computer had a 2GHz processor, 24 GB RAM, 64-bit Windows 7.)
# [[Copy number variation]] (CNV) has to be accounted for. For example, the score for a region with a [[CNV value]] of 1.6 in a [[cancer]] (a loss of 0.4 compared to normal) would have to be multiplied by 1.25 (=2/1.6) to compensate for the loss.
# One of the basic assumptions of Batman is that all DNA methylation occurs at CpG dinucleotides. While this is generally the case for [[vertebrate]] somatic cells, there are situations where there is widespread non-CpG methylation, such as in plant cells  and [[embryonic stem cell]]s.&lt;ref&gt;Dodge, J.E., Ramsahoye, B.H., Wo, Z.G., Okano, M. &amp; Li, E. De novo methylation of MMLV provirus in embryonic stem cells: CpG versus non-CpG methylation. ''Gene'' '''289''', 41–8 (2002)&lt;/ref&gt;&lt;ref&gt;Vanyushin, B.F. DNA methylation in plants. ''Current Topics in Microbiology and Immunology'' '''301''', 67–122 (2006)&lt;/ref&gt;

==References==
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

{{DEFAULTSORT:Bayesian Tool For Methylation Analysis (Batman)}}
[[Category:Computational science]]
[[Category:Applications of Bayesian inference|Methylation analysis (Batman)]]</text>
      <sha1>j9k6nkos4ggn801wds6vu2x3i5tupcv</sha1>
    </revision>
  </page>
  <page>
    <title>Bernoulli's inequality</title>
    <ns>0</ns>
    <id>4734</id>
    <revision>
      <id>863782310</id>
      <parentid>863139891</parentid>
      <timestamp>2018-10-13T00:19:36Z</timestamp>
      <contributor>
        <ip>182.239.122.3</ip>
      </contributor>
      <comment>Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8534"> [[File:Bernoulli inequality.svg|right|thumb|An illustration of Bernoulli's inequality, with the graphs of &lt;math&gt;y=(1 + x)^r&lt;/math&gt; and &lt;math&gt;y=1 + rx&lt;/math&gt; shown in red and blue respectively. Here, &lt;math&gt;r=3.&lt;/math&gt;]]
In [[real analysis]], '''Bernoulli's inequality''' (named after [[Jacob Bernoulli]]) is an [[inequality (mathematics)|inequality]] that approximates [[exponentiation]]s of&amp;nbsp;1&amp;nbsp;+&amp;nbsp;''x''.

The inequality states that

:&lt;math&gt;(1 + x)^r \geq 1 + rx&lt;/math&gt;

for every [[integer]] ''r''&amp;nbsp;≥&amp;nbsp;0 and every [[real number]] ''x''&amp;nbsp;≥&amp;nbsp;−1. 
If the exponent ''r'' is [[even number|even]], then the inequality is valid for ''all'' real numbers&amp;nbsp;''x''. The strict version of the inequality reads

:&lt;math&gt;(1 + x)^r &gt; 1 + rx&lt;/math&gt;

for every integer ''r''&amp;nbsp;≥&amp;nbsp;2 and every real number ''x''&amp;nbsp;≥&amp;nbsp;−1 with ''x''&amp;nbsp;≠&amp;nbsp;0.

There is also a generalized version that says for every real number r ≥ 1 and real number x ≥ -1,
:&lt;math&gt;(1 + x)^r \geq 1 + rx,&lt;/math&gt;

while for 0&amp;nbsp;≤&amp;nbsp;''r''&amp;nbsp;≤&amp;nbsp;1 and real number x ≥ -1,

:&lt;math&gt;(1 + x)^r \leq 1 + rx.&lt;/math&gt;

Bernoulli's inequality is often used as the crucial step in the [[proof (math)|proof]] of other inequalities. It can itself be proved using [[mathematical induction]], as shown below.

==History==
Jacob Bernoulli first published the inequality in his treatise “Positiones Arithmeticae de Seriebus Infinitis” (Basel, 1689), where he used the inequality often.&lt;ref name=autogenerated1&gt;[http://hsm.stackexchange.com/a/1891 mathematics - First use of Bernoulli's inequality and its name - History of Science and Mathematics Stack Exchange&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

According to Joseph E. Hofmann, Über die Exercitatio Geometrica des M. A. Ricci (1963), p.&amp;nbsp;177, the inequality is actually due to Sluse in his Mesolabum (1668 edition), Chapter IV "De maximis &amp; minimis".&lt;ref name=autogenerated1 /&gt;

==Proof of the inequality==

For ''r''&amp;nbsp;=&amp;nbsp;0,

:&lt;math&gt;(1+x)^0 \ge 1+0x &lt;/math&gt;

is equivalent to 1&amp;nbsp;≥&amp;nbsp;1 which is true as required.

Now suppose the statement is true for ''r''&amp;nbsp;=&amp;nbsp;''k'':

:&lt;math&gt;(1+x)^k \ge 1+kx. &lt;/math&gt;

Then it follows that

:&lt;math&gt;
\begin{align}
&amp; {} \qquad (1+x)(1+x)^k \ge (1+x)(1+kx)\quad\text{(by hypothesis, since }(1+x)\ge 0) \\
&amp; \implies (1+x)^{k+1} \ge 1+kx+x+kx^2, \\
&amp; \implies (1+x)^{k+1} \ge 1+(k+1)x+kx^2. \\
&amp; \implies (1+x)^{k+1} \ge 1+(k+1)x \\
\end{align}
&lt;/math&gt;

By induction we conclude the statement is true for all&amp;nbsp;''r''&amp;nbsp;≥&amp;nbsp;0.

==Generalization==

The exponent ''r'' can be generalized to an arbitrary real number as follows: if ''x''&amp;nbsp;&gt;&amp;nbsp;−1, then

:&lt;math&gt;(1 + x)^r \geq 1 + rx&lt;/math&gt;

for ''r''&amp;nbsp;≤&amp;nbsp;0 or ''r''&amp;nbsp;≥&amp;nbsp;1, and

:&lt;math&gt;(1 + x)^r \leq 1 + rx&lt;/math&gt;

for 0&amp;nbsp;≤&amp;nbsp;''r''&amp;nbsp;≤&amp;nbsp;1.

This generalization can be proved by comparing [[derivative]]s.
Again, the strict versions of these inequalities require ''x''&amp;nbsp;≠&amp;nbsp;0 and&amp;nbsp;''r''&amp;nbsp;≠&amp;nbsp;0,&amp;nbsp;1.

== Related inequalities ==
The following inequality estimates the ''r''-th power of 1 + ''x'' from the other side. For any real numbers ''x'',&amp;nbsp;''r''&amp;nbsp; with ''r''&amp;nbsp;&gt;&amp;nbsp;0, one has

:&lt;math&gt;(1 + x)^r \le e^{rx},&lt;/math&gt;

where ''e'' = [[e (number)|2.718...]]. This may be proved using the inequality&amp;nbsp;(1&amp;nbsp;+&amp;nbsp;1/''k'')&lt;sup&gt;''k''&lt;/sup&gt;&amp;nbsp;&lt;&amp;nbsp;''e''.

==Alternative form==
An alternative form of Bernoulli's inequality for  &lt;math&gt; t\geq 1 &lt;/math&gt; and  &lt;math&gt; 0\le x\le 1 &lt;/math&gt;  is:

:&lt;math&gt; (1-x)^t \ge 1-xt. &lt;/math&gt;

This can be proved (for integer t) by using the formula for [[geometric series]]: (using y=1-x)

:&lt;math&gt;t=1+1+\dots+1 \ge 1+y+y^2+\ldots+y^{t-1}=\frac{1-y^t}{1-y}&lt;/math&gt;
or equivalently &lt;math&gt;xt \ge 1-(1-x)^t. &lt;/math&gt;

==Alternative Proof==

'''Using AM-GM''' 

An elementary proof for &lt;math&gt;0\le r\le 1&lt;/math&gt; can be given using [[Inequality of arithmetic and geometric means|Weighted AM-GM]]. 

Let &lt;math&gt;\lambda_1, \lambda_2&lt;/math&gt; be two non-negative real constants. By Weighted AM-GM on &lt;math&gt;1,1+x&lt;/math&gt; with weights &lt;math&gt;\lambda_1, \lambda_2&lt;/math&gt; respectively, we get

&lt;math&gt;\dfrac{\lambda_1\cdot 1+\lambda_2\cdot (1+x)}{\lambda_1+\lambda_2}\ge \sqrt[\lambda_1+\lambda_2]{(1+x)^{\lambda_2}}&lt;/math&gt;

Note that 

&lt;math&gt;\dfrac{\lambda_1\cdot 1+\lambda_2\cdot (1+x)}{\lambda_1+\lambda_2}=\dfrac{\lambda_1+\lambda_2+\lambda_2x}{\lambda_1+\lambda_2}=1+\dfrac{\lambda_2}{\lambda_1+\lambda_2}x&lt;/math&gt;

and

&lt;math&gt;\sqrt[\lambda_1+\lambda_2]{(1+x)^{\lambda_2}}=(1+x)^{\frac{\lambda_2}{\lambda_1+\lambda_2}}&lt;/math&gt;

so our inequality is equivalent to

&lt;math&gt;1+\dfrac{\lambda_2}{\lambda_1+\lambda_2}x\ge (1+x)^{\frac{\lambda_2}{\lambda_1+\lambda_2}}&lt;/math&gt;

After substituting &lt;math&gt;r=\dfrac{\lambda_2}{\lambda_1+\lambda_2}&lt;/math&gt; (bearing in mind that this implies &lt;math&gt;0\le r\le 1&lt;/math&gt;) our inequality turns into 

&lt;math&gt;1+rx\ge (1+x)^r&lt;/math&gt; which is Bernoulli's inequality.

'''Using the formula for geometric series'''

Bernoulli's inequality 

{{NumBlk|:|&lt;math&gt;(1+x)^r \ge 1+rx &lt;/math&gt;|1}} 

is equal to

{{NumBlk|:|&lt;math&gt;(1+x)^r -1-rx \ge 0&lt;/math&gt;|2}}
and by the formula for [[geometric series]] (using y=1+x) we get
{{NumBlk|:|&lt;math&gt; (1+x)^r -1 = y^r-1 = \left(\sum^{r-1}_{k=0}y^k\right) \cdot (y-1) = \left(\sum^{r-1}_{k=0}(1+x)^k\right)\cdot x&lt;/math&gt;|3}}  
which leads to
{{NumBlk|:|&lt;math&gt;(1+x)^r -1-rx = \left(\left(\sum^{r-1}_{k=0}(1+x)^k\right) -r\right)\cdot x= \left(\sum^{r-1}_{k=0}\left((1+x)^k-1\right)\right)\cdot x \ge 0&lt;/math&gt;|{{EquationRef|4}}}}

Now if &lt;math&gt; x \ge 0&lt;/math&gt; then by monotony of the powers each summand &lt;math&gt;(1+x)^k-1\ge 0 &lt;/math&gt;, therefore their sum is greater &lt;math&gt;0&lt;/math&gt; and hence the product on the [[Sides of an equation|LHS]] of ({{EquationNote|4}}).

If &lt;math&gt; 0 \ge x\ge -2 &lt;/math&gt; then by the same arguments &lt;math&gt;1\ge(1+x)^k&lt;/math&gt; and thus
all addends &lt;math&gt;(1+x)^k-1&lt;/math&gt; are non-positive and hence their sum. Since the product of two non-positive numbers is non-negative, we get again
({{EquationNote|4}}), which proofs Bernoulli's inequality even for &lt;math&gt;-1\ge x\ge -2&lt;/math&gt;.
 
'''Using Binomial theorem'''

(1) For {{math|''x'' &gt; 0}}, &lt;math&gt;(1+x)^r=1+rx+\tbinom r2 x^2+...+\tbinom rr x^r&lt;/math&gt;
Obviously, &lt;math&gt;\tbinom r2 x^2+...+\tbinom rr x^r \ge0&lt;/math&gt;

Thus, &lt;math&gt;(1+x)^r \ge 1+rx&lt;/math&gt;

(2) For {{math|''x'' {{=}} 0}}, &lt;math&gt;(1+x)^r =1+rx&lt;/math&gt;

(3) For {{math|−1 ≤ ''x'' &lt; 0}}, let {{math|''y'' {{=}} ''−x''}}, then {{math|0 &lt; ''y'' ≤ 1}}

Replace {{math|''x''}} with {{math|''−y''}}, we have &lt;math&gt;(1-y)^r=1-ry+\tbinom r2 y^2+...+(-1)^r\tbinom rr y^r&lt;/math&gt;

Also, according to the binomial theorem, &lt;math&gt;0=1-r+\tbinom r2+...+(-1)^r\tbinom rr &lt;/math&gt;

then&lt;math&gt;\tbinom r2+...+(-1)^r\tbinom rr =r-1\ge 0&lt;/math&gt;

Notice that &lt;math&gt;y^2\ge y^3\ge ... \ge y^r&lt;/math&gt;

Therefore, we can see that each binomial term &lt;math&gt;\tbinom rn&lt;/math&gt; is multiplied by a factor &lt;math&gt;y^n &lt;/math&gt; , and that will make each term smaller than the term before.

For that reason, &lt;math&gt;\tbinom r2 y^2+...+(-1)^r\tbinom rr y^r\ge 0&lt;/math&gt;

Hence, &lt;math&gt;(1-y)^r=1-ry+\tbinom r2 y^2+...+(-1)^r\tbinom rr y^r\ge 1-ry&lt;/math&gt;

Replace {{math|''y''}} with {{math|''−x''}} back, we get &lt;math&gt;(1+x)^r \ge 1+rx&lt;/math&gt;

Notice that by using binomial theorem, we can only prove the cases when r is a positive integer or zero.

==Notes==
{{reflist}}

==References==
* {{cite book|last1=Carothers|first1=N.L.|title=Real analysis|year=2000|publisher=Cambridge University Press|location=Cambridge|isbn=978-0-521-49756-5|page=9}}
* {{cite book|last1=Bullen|first1=P. S.|title=Handbook of means and their inequalities|year=2003|publisher=Kluwer Academic Publ.|location=Dordercht [u.a.]|isbn=978-1-4020-1522-9|page=4}}
* {{cite book|last1=Zaidman|first1=S.|title=Advanced calculus : an introduction to mathematical analysis|year=1997|publisher=World Scientific|location=River Edge, NJ|isbn=978-981-02-2704-3|page=32}}

== External links ==
* {{MathWorld |title= Bernoulli Inequality |urlname= BernoulliInequality}}
* [http://demonstrations.wolfram.com/BernoulliInequality/ Bernoulli Inequality] by Chris Boucher, [[Wolfram Demonstrations Project]].
* {{cite web|title=Introduction to Inequalities|url=http://www.mediafire.com/?1mw1tkgozzu |author=Arthur Lohwater|year=1982|publisher=Online e-book in PDF format}}
* [[doi:10.4236/am.2013.47146|Paper “Some Equivalent Forms of Bernoulli’s Inequality: A Survey“]]

{{DEFAULTSORT:Bernoulli's Inequality}}
[[Category:Inequalities]]</text>
      <sha1>5b61f312j0b75ah2zsuk23y7ahe0kxm</sha1>
    </revision>
  </page>
  <page>
    <title>Blood volume</title>
    <ns>0</ns>
    <id>2546344</id>
    <revision>
      <id>864667084</id>
      <parentid>863270746</parentid>
      <timestamp>2018-10-18T17:53:30Z</timestamp>
      <contributor>
        <username>Llohman</username>
        <id>30908628</id>
      </contributor>
      <minor/>
      <comment>/* Humans */ Fixed typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6573">'''Blood volume''' is the [[volume]] of [[blood]] (both [[red blood cell]]s and [[blood plasma|plasma]]) in the [[circulatory system]] of any individual.

==Humans==
A typical adult has a blood volume of approximately 5 liters, with females and males having approximately the same blood volume.&lt;ref&gt;{{cite web |url=http://hypertextbook.com/facts/1998/LanNaLee.shtml |title=Volume of Blood in a Human |work=The Physics Factbook |first=Lan Na |last=Lee |year=1998 |deadurl=yes |archiveurl=https://www.webcitation.org/6BqsfDDSK?url=http://hypertextbook.com/facts/1998/LanNaLee.shtml |archivedate=2012-11-01 |df= }}&lt;/ref&gt; Blood volume is [[homeostasis#The volume of body water homeostat|regulated]] by the [[kidney]]s.

Blood volume (BV) can be calculated given the [[hematocrit]] (HC; the fraction of blood that is [[red blood cell]]s) and plasma volume (PV), with the hematocrit being regulated via the [[Homeostasis#The blood oxygen content homeostat|blood oxygen content regulator]]:
:&lt;math&gt;BV = \frac{PV}{1-HC}&lt;/math&gt;

Blood volume measurement may be used in people with [[congestive heart failure]], [[chronic hypertension]], [[renal failure]] and critical care.

The use of relative blood volume changes during [[dialysis]] is of questionable utility.&lt;ref&gt;{{cite journal|last1=Dasselaar|first1=JJ|last2=van der Sande|first2=FM|last3=Franssen|first3=CF|title=Critical evaluation of blood volume measurements during hemodialysis.|journal=Blood Purification|date=2012|volume=33|issue=1-3|pages=177–82|pmid=22269777|doi=10.1159/000334142}}&lt;/ref&gt;

Total Blood Volume can be measured manually via the Dual Isotope or Dual Tracer Technique, a classic technique, available since the 1950s.&lt;ref name="ReferenceA"&gt;{{cite journal|last1=Yu|first1=Mihae|title=A Prospective Randomized Trial Using Blood Volume Analysis in Addition to Pulmonary Artery Catheter, Compared with Pulmonary Catheter Alone, to Guide Shock Resuscitation in Critically Ill Surgical Patients|journal=Shock|date=2011|volume=35|issue=3|pages=220–228|doi=10.1097/shk.0b013e3181fc9178}}&lt;/ref&gt; This technique requires double labeling of the blood; that is 2 injections and 2 standards (51Cr-RBC for tagging red blood cells and I-HAS for tagging plasma volume)as well as withdrawing and re-infusing patients with their own blood for blood volume analysis results. This method may take up to 6 hours for accurate results.

===Semi-automated system===
Blood Volume may also be measured semi-automatically. The BVA-100, a product of Daxor Corporation, consists of an automated well counter interfaced with a computer.&lt;ref&gt;{{cite journal|last1=Manzone|first1=T. A.|last2=Dam|first2=H. Q.|last3=Soltis|first3=D.|last4=Sagar|first4=V. V.|title=Blood Volume Analysis: A New Technique and New Clinical Interest Reinvigorate a Classic Study|journal=Journal of Nuclear Medicine Technology|date=11 May 2007|volume=35|issue=2|pages=55–63|doi=10.2967/jnmt.106.035972|doi-access=free|pmid=17496003}}&lt;/ref&gt; It is able to report Total Blood Volume (TBV), Plasma Volume (PV) and Red Cell Volume (RCV) using the [[indicator dilution]] principle, microhematocrit centrifugation and the Ideal Height and Weight Method.&lt;ref name="ReferenceA"/&gt; The indicator or tracer, is an [[I-131]] [[albumin]] injection. An equal amount of the tracer is injected into a known and unknown volume. Clinically, the unknown volume is the patient's blood volume, with the tracer having been injected into the patient's blood stream and tagged to the blood plasma. Once the tracer is injected a technician takes five blood samples which undergo [[microhematocrit]] [[centrifugation]] to extrapolate true blood volume at time 0. The concentration of the I-131 in the blood is determined from the blood radioactivity against the standard, which has a known I-131 dilution in a known volume. The unknown volume is [[inversely proportional]] to the concentration of the indicator in the known volume; the larger the unknown volume, the lower the tracer concentration, thus the unknown volume can be calculated. The microhematocrit data along with the I-131 indicator data provide a normalized hematocrit number, more accurate than hematocrit or peripheral hematocrit measurements.&lt;ref&gt;{{cite journal|last1=Park|first1=Junki|last2=Puri|first2=Sonika|last3=Mattoo|first3=Aditya|last4=Modersitzki|first4=Frank|last5=Goldfarb|first5=David|title=Radioisotope Blood Volume Measurement in Hemodialysis Patients|journal=American Society of Nephrology|date=2012}}&lt;/ref&gt; Measurements are taken 5 times in 6 minute intervals so that the BVA-100 can calculate the albumin [[wiktionary:transudation|transudation]] time to understand the [[flux]] of liquid through [[capillary]] [[membrane]]s.

==Other animals==
{|class="wikitable" align="right"
! Animal !! Blood volume&lt;br&gt; (ml/kg)&lt;ref name=drexel/&gt;
|-
| [[Cat]] || 55 (47-66)
|-
| [[Cow]] || 55 (52-57)&lt;ref&gt;Reynolds, Monica ; Plasma and Blood Volume in the Cow Using the T-1824 Hematocrit Method
[[American Journal of Physiology]] - June 1953 vol. 173 no. 3 421-427&lt;/ref&gt;
|-
| [[Dog]] || 86 (79-90)
|-
| [[Ferret]] || 75
|-
| [[Gerbil]] || 67
|-
| [[Goat]] || 70
|-
| [[Guinea pig]] || 75 (67-92)
|-
| [[Hamster]] || 78
|-
| [[Circulatory system of the horse|Horse]] || 76
|-
| [[Human]] || 77
|-
| [[Rhesus monkey|Monkey (rhesus)]] || 54
|-
| [[Mouse]] || 79 (78-80)
|-
| [[Pig]] || 65
|-
| [[Rabbit]] || 56 (44-70)
|-
| [[Rat]] || 64 (50-70)
|-
| [[Sheep]] || 60
|-
| [[Marmoset]] || 60-70&lt;ref&gt;Wolfensohn &amp; Lloyd, 2003, Handbook of Laboratory Animal Management and Welfare, 3rd Edition&lt;/ref&gt;
|}
The table at right shows circulating blood volumes, given as volume per kilogram, for healthy adults and some animals.&lt;ref name=drexel&gt;[http://www.drexelmed.edu/documents/ULAR/IACUC_drugs.pdf A Compendium of Drugs Used for Laboratory Animal Anesthesia, Analgesia, Tranquilization and Restraint] {{webarchive |url=https://web.archive.org/web/20110606212907/http://www.drexelmed.edu/documents/ULAR/IACUC_drugs.pdf |date=June 6, 2011 }} at Drexel University College of Medicine. Retrieved April 2011&lt;/ref&gt; However, it can be 15% less in obese and old animals.&lt;ref name=drexel/&gt;

==See also==
* [[Volume status]]
* [[Hypovolemia]]
* [[Hypervolemia]]

==References==
{{reflist}}

==External links==
* {{cite web|last1=Klabunde|first1=Richard E.|title=Blood Volume|url=http://www.cvphysiology.com/Blood%20Pressure/BP025|website=Cardiovascular Physiology Concepts|accessdate=4 July 2017|date=25 April 2014}}

{{Cardiovascular physiology}}

{{DEFAULTSORT:Blood Volume}}
[[Category:Blood]]
[[Category:Mathematics in medicine]]</text>
      <sha1>flxj61wllohw22cxok4gaugi76ta50s</sha1>
    </revision>
  </page>
  <page>
    <title>Bochner–Kodaira–Nakano identity</title>
    <ns>0</ns>
    <id>37598916</id>
    <revision>
      <id>836335763</id>
      <parentid>797496479</parentid>
      <timestamp>2018-04-14T04:03:50Z</timestamp>
      <contributor>
        <username>Tiphareth</username>
        <id>1223725</id>
      </contributor>
      <comment>Shigeo, not Hidegoro</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1817">In [[mathematics]], the '''Bochner–Kodaira–Nakano identity''' is an analogue of the [[Weitzenböck identity]] for [[hermitian manifold]]s, giving an expression for the [[Antiholomorphic function|antiholomorphic]] Laplacian of a [[vector bundle]] over a hermitian manifold in terms of its complex conjugate and the curvature of the bundle and the torsion of the metric of the manifold. It is named after [[Salomon Bochner]], [[Kunihiko Kodaira]], and [[Shigeo Nakano]].

==References==

*{{Citation | author1-link=Jean-Pierre Demailly | last1=Demailly | first1=Jean-Pierre | title=Séminaire d'analyse P. Lelong-P. Dolbeault-H. Skoda, années 1983/1984 | url=https://dx.doi.org/10.1007/BFb0077045 | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Math. | doi=10.1007/BFb0077045 |mr=874763 | year=1986 | volume=1198 | chapter=Sur l'identité de Bochner-Kodaira-Nakano en géométrie hermitienne | pages=88–97}}
*{{Citation | author1-link=Jean-Pierre Demailly | last1=Demailly | first1=Jean-Pierre | title=  Complex Analytic and Differential Geometry  | url=http://www-fourier.ujf-grenoble.fr/~demailly/manuscripts/agbook.pdf | year=2012}}
*{{Citation | last1=Kodaira | first1=Kunihiko | authorlink = Kunihiko Kodaira | title=On a differential-geometric method in the theory of analytic stacks |mr=0066693 | year=1953 | journal=[[Proceedings of the National Academy of Sciences|Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=39 | pages=1268–1273 | doi=10.1073/pnas.39.12.1268 | pmid=16589409 | jstor=89226 | pmc=1063947}}

{{DEFAULTSORT:Bochner-Kodaira-Nakano identity}}
[[Category:Theorems in differential geometry]]
[[Category:Vector bundles]]
[[Category:Mathematical identities]]


{{differential-geometry-stub}}</text>
      <sha1>pvh9cathnwpmlx4hyrlbfjkqtl0v10s</sha1>
    </revision>
  </page>
  <page>
    <title>Cartan model</title>
    <ns>0</ns>
    <id>4110341</id>
    <revision>
      <id>532062446</id>
      <parentid>448863350</parentid>
      <timestamp>2013-01-09T01:05:58Z</timestamp>
      <contributor>
        <username>Addbot</username>
        <id>6569922</id>
      </contributor>
      <minor/>
      <comment>[[User:Addbot|Bot:]] Removing Orphan Tag (Nolonger an Orphan) ([[User_talk:Addbot|Report Errors]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="572">In [[mathematics]], the '''Cartan model''' is a [[differential graded algebra]] that computes the [[equivariant cohomology]] of a [[topological space|space]].

==References==

* Stefan Cordes, Gregory Moore, Sanjaye Ramgoolam, ''Lectures on 2D Yang-Mills Theory, Equivariant Cohomology and Topological Field Theories'', {{arxiv|hep-th/9411210}}, 1994.
&lt;!-- I just added the above reference because I like to have a reference, but I don't know the theory at all. Feel free to replace it by something more appropriate --&gt;

[[Category:Algebraic topology]]


{{topology-stub}}</text>
      <sha1>33w4p6uwe5s6h7o9e3ifsijm9ogf5z0</sha1>
    </revision>
  </page>
  <page>
    <title>Chemical reaction model</title>
    <ns>0</ns>
    <id>44307291</id>
    <revision>
      <id>843018969</id>
      <parentid>830688258</parentid>
      <timestamp>2018-05-26T09:06:57Z</timestamp>
      <contributor>
        <username>Noyster</username>
        <id>19396915</id>
      </contributor>
      <comment>copyedit, amend tags</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5167">{{short description|Mathematical modeling of chemical processes}}
{{multiple issues|
{{refimprove|date=November 2014}}
{{confusing|date=May 2018}}
}}

'''Chemical reaction models''' transform physical knowledge into a mathematical formulation that can be utilized in computational [[simulation]] of practical problems in [[chemical engineering]]. Computer simulation provides the flexibility to study chemical processes under a wide range of conditions. Modeling of a [[chemical reaction]] involves solving conservation equations describing [[convection]], [[diffusion]], and reaction source for each component species.

== Species transport equation ==

: &lt;math&gt; \frac{\partial (\rho Y _i)}{\partial t} + \nabla \cdot ( \rho \vec v Y _i) =  - \nabla \cdot \vec J _i + R _i + S _i &lt;/math&gt;

''R''&lt;sub&gt;''i''&lt;/sub&gt; is the net rate of production of species ''i'' by chemical reaction and ''S''&lt;sub&gt;''i''&lt;/sub&gt; is the rate of creation by addition from the dispersed phase and the user defined source. ''J''&lt;sub&gt;''i''&lt;/sub&gt; is the diffusion flux of species ''i'', which arises due to concentration gradients and differs in both laminar and turbulent flows. In turbulent flows, [[computational fluid dynamics]] also considers the effects of [[turbulent]] diffusivity. The net source of chemical species ''i'' due to reaction, ''R''&lt;sub&gt;''i''&lt;/sub&gt; which appeared as the source term in the species transport equation is computed as the sum of the reaction sources over the ''N''&lt;sub&gt;''R''&lt;/sub&gt; reactions among the species.

== Reaction models ==
These reaction rates ''R'' can be calculated by following models:

# [[Laminar flow|Laminar]] finite rate model
# [[Eddy (fluid dynamics)|Eddy]] dissipation model
# Eddy dissipation concept

=== Laminar finite rate model ===
The laminar finite rate model computes the chemical source terms using the [[Carl Axel Arrhenius|Arrhenius]] expressions and ignores turbulence fluctuations. This model provides with the exact solution for laminar flames but gives inaccurate solution for turbulent flames, in which turbulence highly affects the chemistry reaction rates, due to highly non-linear Arrhenius chemical kinetics. However this model may be accurate for combustion with small turbulence fluctuations, for example [[supersonic]] flames.

===  Eddy dissipation model ===
The eddy dissipation model, based on the work of Magnussen and Hjertager, is a turbulent-chemistry reaction model. Most fuels are fast burning and the overall rate of reaction is controlled by turbulence mixing. In the non-premixed flames, turbulence slowly mixes the fuel and oxidizer into the reaction zones where they burn quickly. In premixed flames the turbulence slowly mixes cold reactants and hot products into the reaction zones where reaction occurs rapidly. In such cases the combustion is said to be mixing-limited, and the complex and often unknown chemical kinetics can be safely neglected. In this model, the chemical reaction is governed by large eddy mixing time scale. Combustion initiates whenever there is turbulence present in the flow. It does not need an ignition source to initiate the combustion. This type of model is valid for the non-premixed combustion, but for the premixed flames the reactant is assumed to burn at the moment it enters the [[computation model]], which is a shortcoming of this model as in practice the reactant needs some time to get to the ignition temperature to initiate the combustion.

===  Eddy dissipation concept ===
The eddy dissipation concept (EDC) model is an extension of the eddy dissipation model to include detailed chemical mechanism in turbulent flows. The EDC model attempts to incorporate the significance of fine structures in a turbulent reacting flow in which combustion is important.  EDC has been proven efficient without the need for changing the constants for a great variety of premixed and diffusion controlled combustion problems, both where the chemical kinetics is faster than the overall fine structure mixing as well as in cases where the chemical kinetics has a dominating influence.

== References ==
* [[Ansys]] [[Fluent, Inc.|Fluent]] Help, Chapters 7, 8.
* Henk Kaarle Versteeg, Weeratunge Malalasekera. ''An Introduction to Computational Fluid Dynamics: The Finite Volume Method''.
* Magnussen, B. F. &amp; B. H. Hjertager (1977). "On Mathematical Models of Turbulent Combustion with Special Emphasis on Soot Formation and Combustion". Symposium (International) on Combustion. 16 (1): 719–729. doi:10.1016/S0082-0784(77)80366-4.
* Bjørn F. Magnussen. Norwegian University of Science and Technology Trondheim (Norway), Computational Industry Technologies AS (ComputIT), [http://folk.ntnu.no/ivarse/edc/BFM_ECOMAS2005_Lisboa.pdf THE EDDY DISSIPATION CONCEPT: A BRIDGE BETWEEN SCIENCE AND TECHNOLOGY].
* Schlögl, Friedrich. [https://link.springer.com/article/10.1007/BF01379769#page-1 "Chemical reaction models for non-equilibrium phase transitions."] Zeitschrift für Physik 253.2 (1972): 147–161.
* Levenspiel, Octave. ''Chemical reaction engineering''. Vol. 2. New York etc.: Wiley, 1972.

[[Category:Chemical reaction engineering]]
[[Category:Mathematical modeling]]</text>
      <sha1>3ccy0wd6009jg26owhcsqz5rkpnb52d</sha1>
    </revision>
  </page>
  <page>
    <title>Circumcenter of mass</title>
    <ns>0</ns>
    <id>46449014</id>
    <revision>
      <id>842501246</id>
      <parentid>841534957</parentid>
      <timestamp>2018-05-22T21:27:40Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5640">In [[geometry]], the '''circumcenter of mass''' is a center associated with a [[polygon]] which shares many of the properties of the [[center of mass]]. More generally, the circumcenter of mass may be defined for [[simplicial polytope]]s and also in the [[spherical geometry|spherical]] and [[hyperbolic geometry|hyperbolic]] geometries.

In the special case when the polytope is a [[quadrilateral]] or [[hexagon]], the circumcenter of mass has been called the "quasicircumcenter" and has been used to define an [[Euler line]] of a quadrilateral.&lt;ref&gt;{{citation | last = Myakishev | first = Alexei | journal = Forum Geometricorum | pages = 289–295
 | title = On Two Remarkable Lines Related to a Quadrilateral | url = http://forumgeom.fau.edu/FG2006volume6/FG200634.pdf | volume = 6 | year = 2006}}.&lt;/ref&gt;&lt;ref&gt;{{citation | last = de Villiers | first = Michael | journal = Forum Geometricorum | pages = 233–236 | title = Quasi-circumcenters and a generalization of the quasi-Euler line to a hexagon | url = http://forumgeom.fau.edu/FG2014volume14/FG201421.pdf | volume = 14 | year = 2014}}&lt;/ref&gt; The circumcenter of mass allows us to define an Euler line for simplicial polytopes.

==Definition in the plane==
Let &lt;math&gt;P&lt;/math&gt; be an oriented polygon (with vertices counted countercyclically) in the plane with vertices &lt;math&gt;V_1,V_2,\ldots,V_n&lt;/math&gt;  and let &lt;math&gt;O&lt;/math&gt; be an arbitrary point not lying on the sides (or their [[extended side|extensions]]). Consider the triangulation of &lt;math&gt;P&lt;/math&gt; by the oriented triangles &lt;math&gt;O V_i V_{i+1}&lt;/math&gt; (the index &lt;math&gt;i&lt;/math&gt; is viewed modulo &lt;math&gt;n&lt;/math&gt;). Associate with each of these triangles its circumcenter &lt;math&gt;C_i&lt;/math&gt; with weight equal to its oriented area (positive if its sequence of vertices is countercyclical; negative otherwise). The circumcenter of mass of &lt;math&gt;P&lt;/math&gt; is the [[center of mass]] of these weighted circumcenters. The result is independent of the choice of point &lt;math&gt;O&lt;/math&gt;.&lt;ref&gt;{{citation | last1 = Tabachnikov | first1 = Serge | last2 = Tsukerman | first2 = Emmanuel | date = May 2014 | issue = 51 | journal = [[Discrete and Computational Geometry]] | volume = 51 | pages = 815–836 | title = Circumcenter of Mass and Generalized Euler Line | url = https://link.springer.com/article/10.1007%2Fs00454-014-9597-2| doi = 10.1007/s00454-014-9597-2| arxiv = 1301.0496 }}&lt;/ref&gt;
[[File:PolyCCM.svg|thumb|Circumcenter of mass of a polygon.]]

==Properties==
In the special case when the polygon is [[cyclic polygon|cyclic]], the circumcenter of mass coincides with the [[circumcenter]].

The circumcenter of mass satisfies an analog of Archimedes' Lemma, which states that if a polygon is decomposed into two smaller polygons, then the circumcenter of mass of that polygon is a weighted sum of the circumcenters of mass of the two smaller polygons. As a consequence, any triangulation with nondegenerate triangles may be used to define the circumcenter of mass.

For an [[equilateral polygon]], the circumcenter of mass and center of mass coincide. More generally, the circumcenter of mass and center of mass coincide for a simplicial polytope for which each face has the sum of squares of its edges a constant.&lt;ref&gt;{{citation | last1 = Akopyan| first1 = Arseniy | date = May 2014 | issue = 51 | journal = [[Discrete and Computational Geometry]] | volume = 51 | pages = 837–841 | title = Some Remarks on the Circumcenter of Mass | url = https://link.springer.com/article/10.1007%2Fs00454-014-9596-3| doi = 10.1007/s00454-014-9596-3 | arxiv = 1512.08655 }}&lt;/ref&gt;

The circumcenter of mass is invariant under the operation of "recutting" of polygons.&lt;ref&gt;{{citation | last1 = Adler| first1 = V. | date = 1993 | issue = 27 | journal = Funct. Anal. Appl. | pages = 141–143 | title = Cutting of polygons}}&lt;/ref&gt; and the discrete bicycle (Darboux) transformation; in other words, the image of a polygon under these operations has the same circumcenter of mass as the original polygon. The [[Euler line#Simplicial polytope|generalized Euler line]] makes other appearances in the theory of integrable systems.&lt;ref&gt;{{citation
 | last1 = Schief| first1 = W. K. | date = 2014 | issue = 470 | journal = Proceedings of the Royal Society of London A  | pages = 22 | title = Integrable structure in discrete shell membrane theory}}&lt;/ref&gt;

Let &lt;math&gt;V_i=(x_i,y_i)&lt;/math&gt; be the vertices of &lt;math&gt;P&lt;/math&gt; and let &lt;math&gt;A&lt;/math&gt; denote its area. The circumcenter of mass &lt;math&gt;CCM(P)&lt;/math&gt; of the polygon &lt;math&gt;P&lt;/math&gt; is given by the formula

:&lt;math&gt;
CCM(P)=\frac{1}{4 A}(\sum_{i=0}^{n-1} -y_i y_{i+1}^2+y_i^2 y_{i+1} +x_i^2 y_{i+1}-x_{i+1}^2 y_i, \sum_{i=0}^{n-1} -x_{i+1} y_i^2+x_i y_{i+1}^2+x_i x_{i+1}^2-x_i^2 x_{i+1}).
&lt;/math&gt;

The circumcenter of mass can be extended to smooth curves via a limiting procedure. This continuous limit coincides with the center of mass of the homogeneous [[planar lamina|lamina]] bounded by the curve.

Under natural assumptions, the centers of polygons which satisfy Archimedes' Lemma are precisely the points of its Euler line. In other words, the only "well-behaved" centers which satisfy Archimedes' Lemma are the affine combinations of the circumcenter of mass and center of mass.

==Generalized Euler line==

The circumcenter of mass allows an [[Euler line]] to be defined for any polygon (and more generally, for a simplicial polytope). This [[Euler line#Simplicial polytope|generalized Euler line]] is defined as the affine span of the center of mass and circumcenter of mass of the polytope.

==See also==
*[[Circumcenter]]
*[[Circumscribed sphere]]

==References==
{{reflist|2}}

[[Category:Geometry]]</text>
      <sha1>6q97kmflxyfzvktztuca69a6h34thhs</sha1>
    </revision>
  </page>
  <page>
    <title>Claw-free permutation</title>
    <ns>0</ns>
    <id>3625890</id>
    <revision>
      <id>856584340</id>
      <parentid>810379193</parentid>
      <timestamp>2018-08-26T07:36:43Z</timestamp>
      <contributor>
        <username>Runawayangel</username>
        <id>7340759</id>
      </contributor>
      <minor/>
      <comment>/* Additional reading */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4823">In [[Mathematics|mathematical]] and [[computer science]] field of [[cryptography]], a group of three numbers (''x'',''y'',''z'') is said to be a '''claw''' of two permutations ''f''&lt;sub&gt;0&lt;/sub&gt; and ''f''&lt;sub&gt;1&lt;/sub&gt; if

:''f''&lt;sub&gt;0&lt;/sub&gt;(''x'') = ''f''&lt;sub&gt;1&lt;/sub&gt;(''y'') = ''z''.

A pair of permutations ''f''&lt;sub&gt;0&lt;/sub&gt; and ''f''&lt;sub&gt;1&lt;/sub&gt; are said to be '''claw-free''' if there is no efficient algorithm for computing a claw.

The terminology ''claw free'' was introduced by Goldwasser, Micali, and Rivest in their 1984 paper, "A Paradoxical Solution to the Signature Problem"&lt;ref&gt;{{cite conference | url = http://groups.csail.mit.edu/cis/pubs/shafi/1984-FOCS-GMR.pdf | contribution = A Paradoxical Solution to the Signature Problem | first1 = Shafi | last1 = Goldwasser | author2-link = Silvio Micali | first2 = Silvio | last2 = Micali | first3 = Ronald L. | last3 = Rivest | author3-link = Ronald L. Rivest | title = Proceedings of FOCS | pages = 441–448 | date = 1984 }}&lt;/ref&gt; (and later in a more complete journal paper),&lt;ref&gt;{{cite journal | first1 = Shafi | last1 = Goldwasser | author2-link = Silvio Micali | first2 = Silvio | last2 = Micali | author3-link = Ronald L. Rivest | first3 = Ronald L. | last3 = Rivest | citeseerx = 10.1.1.20.8353 | title = A digital signature scheme secure against adaptive chosen-message attacks | journal = SIAM J. Comput. | volume = 17| issue = 2 | pages = 281–308 | date = April 1988 }}&lt;/ref&gt; where they showed that the existence of '''claw-free pairs of trapdoor permutations''' implies the existence of digital signature schemes secure against [[adaptive chosen-message attack]]. This construction was later superseded by the construction of digital signatures from any one-way trapdoor permutation.&lt;ref&gt;{{cite paper | url = http://portal.acm.org/citation.cfm?id=147508.147537 | title = How to sign given any trapdoor permutation | first1 = Mihir | last1 = Bellare | author2-link = Silvio Micali | first2 = Silvio | last2 = Micali }}&lt;/ref&gt;  The existence of [[trapdoor permutation]]s does not by itself imply claw-free permutations exist;&lt;ref&gt;{{cite paper | citeseerx = 10.1.1.19.6331 | title = On the Power of Claw-Free Permutations | first1 = Yevgeniy | last1 = Dodis | first2 = Leonid | last2 = Reyzin | date = 2002 }}&lt;/ref&gt; however, it has been shown that claw-free permutations do exist if factoring is hard.&lt;ref name="D88"&gt;{{cite conference
 | last = Damgård | first = Ivan Bjerre
 | contribution = Collision free hash functions and public key signature schemes
 | doi = 10.1007/3-540-39118-5_19
 | pages = 203–216
 | publisher = Springer
 | series = Lecture Notes in Computer Science
 | title = Advances in Cryptology — EUROCRYPT’ 87
 | volume = 304
 | year = 1988}}&lt;/ref&gt;

The general notion of claw-free permutation (not necessarily trapdoor) was further studied by [[Ivan Damgård]] in his PhD thesis ''The Application of Claw Free Functions in Cryptography'' (Aarhus University, 1988), where he showed how to construct 
[[Cryptographic hash function|Collision Resistant Hash Functions]] from claw-free permutations.&lt;ref name="D88"/&gt;  The notion of claw-freeness is closely related to that of collision resistance in hash functions.  The distinction is that claw-free permutations are ''pairs'' of functions in which it is hard to create a collision between them, while a collision-resistant hash function is a single function in which it's hard to find a collision, i.e. a function ''H'' is collision resistant if it's hard to find a pair of distinct values ''x'',''y'' such that

:''H''(''x'') = ''H''(''y'').

In the hash function literature, this is commonly termed a [[hash collision]].  A hash function where collisions are difficult to find is said to have [[collision resistance]].

==Bit commitment==
Given a pair of claw-free permutations ''f''&lt;sub&gt;0&lt;/sub&gt; and ''f''&lt;sub&gt;1&lt;/sub&gt; it is straightforward to create a [[commitment scheme]].  To commit to a bit ''b'' the sender chooses a random ''x'', and calculates ''f''&lt;sub&gt;b&lt;/sub&gt;(''x'').  Since both ''f''&lt;sub&gt;0&lt;/sub&gt; and ''f''&lt;sub&gt;1&lt;/sub&gt; share the same domain (and range), the bit ''b'' is statistically hidden from the receiver.  To open the commitment, the sender simply sends the randomness ''x'' to the receiver.  The sender is bound to his bit because opening a commitment to 1&amp;nbsp;&amp;minus;&amp;nbsp;''b'' is exactly equivalent to finding a claw.  Notice that like the construction of Collision Resistant Hash functions, this construction does not require that the claw-free functions have a trapdoor.

==References==
{{reflist}}

==Further reading==
*{{cite paper | first = Takeshi | last = Koshiba | url = http://citeseer.ist.psu.edu/koshiba96selfdefinable.html | title = Self-Definable Claw Free Functions | date = 1996 }}

[[Category:Theory of cryptography]]
[[Category:Permutations]]</text>
      <sha1>hx898fu9hzwh6poiky269z2qil5a645</sha1>
    </revision>
  </page>
  <page>
    <title>Closeness centrality</title>
    <ns>0</ns>
    <id>19959657</id>
    <revision>
      <id>862422356</id>
      <parentid>861189063</parentid>
      <timestamp>2018-10-04T08:18:19Z</timestamp>
      <contributor>
        <username>Latex-yow</username>
        <id>27692366</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8927">In a [[Connected component (graph theory)|connected]] [[Graph (discrete mathematics)|graph]], '''closeness centrality''' (or '''closeness''') of a node is a measure of [[centrality]] in a [[Graph (discrete mathematics)|network]], calculated as the reciprocal of the sum of the length of the [[Shortest path problem|shortest paths]] between the node and all other nodes in the graph. Thus, the more central a node is, the ''closer'' it is to all other nodes.

Closeness was defined by Bavelas (1950) as the [[Multiplicative inverse|reciprocal]] of the '''farness''',&lt;ref&gt;Alex Bavelas. Communication patterns in task-oriented groups. ''J. Acoust. Soc. Am'', '''22'''(6):725–730, 1950.&lt;/ref&gt;&lt;ref&gt;{{cite journal |year= 1966| title=The centrality index of a graph|url=|journal=Psychometrika|volume=31|issue=|pages=581–603| doi= 10.1007/bf02289527| last1= Sabidussi|first1=G}}&lt;/ref&gt; that is:

: &lt;math&gt;C(x)= \frac{1}{\sum_y d(y,x)}.&lt;/math&gt;

where &lt;math&gt;d(y,x)&lt;/math&gt; is the [[Distance (graph theory)|distance]] between vertices &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;. When speaking of closeness centrality, people usually refer to its normalized form which represents the average length of the shortest paths instead of their sum. It is generally given by the previous formula multiplied by &lt;math&gt;N-1&lt;/math&gt;, where &lt;math&gt;N&lt;/math&gt; is the number of nodes in the graph. For large graphs this difference becomes inconsequential so the &lt;math&gt;-1&lt;/math&gt; is dropped resulting in:

: &lt;math&gt;C(x)= \frac{N}{\sum_y d(y,x)}.&lt;/math&gt;

This adjustment allows comparisons between nodes of graphs of different sizes.

Taking distances ''from'' or ''to'' all other nodes is irrelevant in undirected graphs, whereas it can produce totally different results in [[directed graph]]s (e.g. a website can have a high closeness centrality from outgoing link, but low closeness centrality from incoming links).

== In disconnected graphs ==
When a graph is not [[Strongly connected component|strongly connected]], a widespread idea is that of using the sum of reciprocal of distances, instead of the reciprocal of the sum of distances, with the convention &lt;math&gt;1/\infty=0&lt;/math&gt;:

: &lt;math&gt;H(x)= \sum_{y \neq x}\frac{1}{d(y,x)}.&lt;/math&gt;

The most natural modification of Bavelas's definition of closeness is following the general principle proposed by [[Massimo Marchiori|Marchiori]] and [[Vito Latora|Latora]] (2000)&lt;ref name="marchiorilatora2000"&gt;{{citation| journal = Physica A: Statistical Mechanics and its Applications | last1 = Marchiori | first1 = Massimo | last2 = Latora | first2 = Vito | year = 2000 | volume = 285 | issue = 3-4 | pages = 539–546 | title = Harmony in the small-world | url = https://arxiv.org/pdf/cond-mat/0008357.pdf | doi= 10.1016/s0378-4371(00)00311-3| arxiv = cond-mat/0008357 | bibcode = 2000PhyA..285..539M }}&lt;/ref&gt; that in graphs with infinite distances the harmonic mean behaves better than the arithmetic mean. Indeed, Bavelas's closeness can be described as the denormalized reciprocal of the [[arithmetic mean]] of distances, whereas harmonic centrality is the denormalized reciprocal of the [[harmonic mean]] of distances.

This idea was explicitly stated for undirected graphs under the name '''valued centrality''' by Dekker (2005)&lt;ref name="dekker2005"&gt;{{cite journal|first1=Anthony|last1=Dekker|title=Conceptual Distance in Social Network Analysis|journal=Journal of Social Structure|volume=6|issue=3|year=2005|url=http://www.cmu.edu/joss/content/articles/volume6/dekker/index.html}}&lt;/ref&gt; and under the name {{anchor|harmonic centrality}}'''harmonic centrality''' by Rochat (2009),&lt;ref name="rochat2009"&gt;{{cite conference | author = Yannick Rochat | title = Closeness centrality extended to unconnected graphs: The harmonic centrality index | conference = Applications of Social Network Analysis, ASNA 2009 | url = http://infoscience.epfl.ch/record/200525/files/%5bEN%5dASNA09.pdf }}&lt;/ref&gt; axiomatized by Garg (2009)&lt;ref name="garg2009"&gt;{{citation | journal = SSRN Electronic Journal| author = Manuj Garg | title = Axiomatic Foundations of Centrality in Networks | doi=10.2139/ssrn.1372441}}&lt;/ref&gt; and proposed once again later by Opsahl (2010).&lt;ref name="opsahl2010"&gt;{{cite web | author = Tore Opsahl | title = Closeness centrality in networks with disconnected components | url = http://toreopsahl.com/2010/03/20/closeness-centrality-in-networks-with-disconnected-components/ }}&lt;/ref&gt; It was studied on general directed graphs by Boldi and Vigna (2014).&lt;ref name="boldivigna2014"&gt;{{citation| journal = Internet Mathematics | last1 = Boldi | first1 = Paolo | last2 = Vigna | first2 = Sebastiano | year = 2014 | title = Axioms for Centrality | volume = 10 | url = http://www.tandfonline.com/doi/abs/10.1080/15427951.2013.865686 | doi=10.1080/15427951.2013.865686 | pages=222–262}}&lt;/ref&gt; This idea is also quite similar to market potential proposed in Harris (1954)&lt;ref&gt;C. D. Harris. The, market as a factor in the localization of industry in the united states. Annals of the association of American geographers, 44(4):315–348, 1954&lt;/ref&gt; which now often goes by the term market access.&lt;ref&gt;Gutberlet, Theresa. Cheap Coal versus Market Access: The Role of Natural Resources and Demand in Germany's Industrialization. Working Paper. 2014.&lt;/ref&gt;

== Variants ==
Dangalchev (2006),&lt;ref name="Dan"&gt;{{cite journal|year=2006|title=Residual Closeness in Networks|url=|journal=Physica A|volume=365|issue=|page=556|last1=Ch|first1=Dangalchev}}&lt;/ref&gt; in a work on network vulnerability proposes for undirected graphs a different definition:

: &lt;math&gt;D(x)=\sum_{y\neq x}\frac{1}{2^{d(y,x)}}.&lt;/math&gt;

This definition is used effectively for disconnected graphs and allows to create convenient formulae for graph operations. For example:

If a graph &lt;math&gt;G_1 + G_2&lt;/math&gt; is created by linking node &lt;math&gt;p&lt;/math&gt; of graph &lt;math&gt;G_1&lt;/math&gt; to node &lt;math&gt;q&lt;/math&gt; of graph &lt;math&gt;G_2&lt;/math&gt; then the combined closeness is:

:&lt;math&gt;D(G_1+G_2) = D(G_1) + D(G_2) + (1+D(p))(1+D(q)).&lt;/math&gt;

If graph &lt;math&gt;T(G)&lt;/math&gt; is the thorn graph of graph &lt;math&gt;G&lt;/math&gt;, which has &lt;math&gt;n&lt;/math&gt; nodes, then &lt;math&gt;T(G)&lt;/math&gt; closeness is &lt;ref name="Dan2"&gt;{{cite journal|year=2018|title=Residual Closeness of Generalized Thorn Graphs|url=|journal=Fundamenta Informaticae|volume=162|issue=1|page=1-15|last1=Ch|first1=Dangalchev}}&lt;/ref&gt;:

:&lt;math&gt;D(T(G)) = \frac{9}{4} D(G) + n.&lt;/math&gt;

The natural generalization of this definition is 
&lt;ref name="Dan3"&gt;{{cite journal|year=2011|title=Residual Closeness and Generalized Closeness
|url=|journal=IJFCS|volume=22|issue=8|page=1939-1948|last1=Ch|first1=Dangalchev}}&lt;/ref&gt;:

: &lt;math&gt;D(x)=\sum_{y\neq x}\ {\alpha^{d(y,x)}},&lt;/math&gt;

where &lt;math&gt;\alpha&lt;/math&gt; belongs to (0,1). As &lt;math&gt;\alpha&lt;/math&gt; increases from 0 to 1, the generalized closeness changes from local characteristic (degree) to global (number of connected nodes).

The ''information centrality'' of Stephenson and Zelen (1989) is another closeness measure, which computes the [[harmonic mean]] of the resistance distances towards a vertex ''x'', which is smaller if ''x'' has many paths of small resistance connecting it to other vertices.&lt;ref&gt;{{cite journal | last1 = Stephenson | first1 = K. A. | last2 = Zelen | first2 = M. | year = 1989 | title = Rethinking centrality: Methods and examples | url = | journal = Social Networks | volume = 11 | issue = | pages = 1–37 | doi=10.1016/0378-8733(89)90016-6}}&lt;/ref&gt;

In the classic definition of the closeness centrality, the spread of information is modeled by the use of shortest paths. This model might not be the most realistic for all types of communication scenarios. Thus, related definitions have been discussed to measure closeness, like the [[random walk closeness centrality]] introduced by Noh and Rieger (2004). It measures the speed with which randomly walking messages reach a vertex from elsewhere in the graph—a sort of random-walk version of closeness centrality.&lt;ref&gt;{{cite journal | last1 = Noh | first1 = J. D. | last2 = Rieger | first2 = H. | year = 2004 | title = Random Walks on Complex Networks| url = | journal = Phys. Rev. Lett. | volume = 92 | issue = | page = 118701 | doi = 10.1103/physrevlett.92.118701 | arxiv = cond-mat/0307719 | bibcode = 2004PhRvL..92k8701N }}&lt;/ref&gt; [[Hierarchical closeness]] of Tran and Kwon (2014)&lt;ref&gt;Tran, T.-D. and Kwon, Y.-K. Hierarchical closeness efficiently predicts disease genes in a directed signaling network, Computational biology and chemistry.&lt;/ref&gt; is an extended closeness centrality to deal still in another way with the limitation of closeness in graphs that are not strongly connected. The hierarchical closeness explicitly includes information about the range of other nodes that can be affected by the given node.

== See also ==
* [[Centrality]]
* [[Random walk closeness centrality]]
* [[Betweenness centrality]]

== References ==
{{Reflist}}

[[Category:Graph invariants]]
[[Category:Network analysis]]</text>
      <sha1>n6asgo43hujsidapj7vgfrc43hfebl7</sha1>
    </revision>
  </page>
  <page>
    <title>Dedekind discriminant theorem</title>
    <ns>0</ns>
    <id>5078407</id>
    <redirect title="Algebraic number field" />
    <revision>
      <id>457009596</id>
      <parentid>98847169</parentid>
      <timestamp>2011-10-23T17:26:31Z</timestamp>
      <contributor>
        <username>Geometry guy</username>
        <id>3483166</id>
      </contributor>
      <comment>subcat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="75">#REDIRECT[[Algebraic number field]]

[[Category:Theorems in number theory]]</text>
      <sha1>evcaecp9o9noks0uxr03rm9ltmymzfk</sha1>
    </revision>
  </page>
  <page>
    <title>Deterministic system</title>
    <ns>0</ns>
    <id>522958</id>
    <revision>
      <id>869095184</id>
      <parentid>869095147</parentid>
      <timestamp>2018-11-16T11:03:34Z</timestamp>
      <contributor>
        <username>Shellwood</username>
        <id>2366721</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2409:4056:200C:3403:7016:A8F2:8D99:E9B4|2409:4056:200C:3403:7016:A8F2:8D99:E9B4]] ([[User talk:2409:4056:200C:3403:7016:A8F2:8D99:E9B4|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3522">In [[mathematics]], [[computer science]] and [[physics]], a '''deterministic system''' is a system in which no [[randomness]] is involved in the development of future states of the system.&lt;ref&gt;[http://www.daviddarling.info/encyclopedia/D/deterministic_system.html deterministic system] - definition at ''The Internet Encyclopedia of Science''&lt;/ref&gt; A deterministic [[mathematical model |model]] will thus always produce the same output from a given starting condition or initial state.&lt;ref&gt;[http://www.scholarpedia.org/article/Dynamical_systems Dynamical systems] at [[Scholarpedia]]&lt;/ref&gt;

==In physics==

Physical laws that are described by [[differential equations]] represent deterministic systems, even though the state of the system at a given point in time may be difficult to describe explicitly.

In [[quantum mechanics]], the [[Schrödinger equation]], which describes the continuous [[time evolution]] of a system's [[wave function]], is deterministic. However, the relationship between a system's wave function and the [[observable]] properties of the system appears to be non-deterministic.

==In mathematics==
The systems studied in [[chaos theory]] are deterministic. If the initial state were known exactly, then the future state of such a system could theoretically be predicted. However, in practice, knowledge about the future state is limited by the precision with which the initial state can be measured, and chaotic systems are characterized by a strong dependence on the initial conditions.&lt;ref name="Boeing2016Systems"&gt;{{cite journal|url=http://geoffboeing.com/publications/nonlinear-chaos-fractals-prediction/|author=Boeing, G.|title=Visual Analysis of Nonlinear Dynamical Systems: Chaos, Fractals, Self-Similarity and the Limits of Prediction|journal=Systems|date=2016|volume=4|issue=4|pages=37|accessdate=2016-12-02|doi=10.3390/systems4040037}}&lt;/ref&gt; This sensitivity to initial conditions can be measured with [[Lyapunov exponents]].

[[Markov chain]]s and other [[random walk]]s are not deterministic systems, because their development depends on random choices.

==In computer science==

A deterministic [[model of computation]], for example a [[deterministic Turing machine]], is a model of computation such that the successive states of the machine and the operations to be performed are completely determined by the preceding state.

A [[deterministic algorithm]] is an algorithm which, given a particular input, will always produce the same output, with the underlying machine always passing through the same sequence of states. There may be non-deterministic algorithms that run on a deterministic machine, for example, an algorithm that relies on random choices. Generally, for such random choices, one uses a [[pseudorandom number generator]], but one may also use some external physical process, such as the last digits of the time given by the computer clock.

A ''pseudorandom number generator'' is a deterministic algorithm, that is designed to produce sequences of numbers that behave as random sequences. A [[hardware random number generator]], however, may be non-deterministic.

==Others==
In economics, the [[Ramsey–Cass–Koopmans model]] is deterministic. The stochastic equivalent is known as [[Real Business Cycle theory]].

== See also ==
* [[Deterministic system (philosophy)]]
* [[Dynamical system]]
* [[Scientific modelling]]
* [[Statistical model]]
* [[Stochastic process]]

==References==
{{Reflist}}

[[Category:Determinism|System]]
[[Category:Dynamical systems]]</text>
      <sha1>f83xfzsh66bcee9950g1etx05hk3dpm</sha1>
    </revision>
  </page>
  <page>
    <title>Dietrich Mahnke</title>
    <ns>0</ns>
    <id>25782572</id>
    <revision>
      <id>787204019</id>
      <parentid>770179616</parentid>
      <timestamp>2017-06-24T01:45:33Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic_links|magic links]] with templates per [[Special:PermaLink/772743896#Future_of_magic_links|local RfC]] - [[User:PrimeBOT/13|BRFA]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3481">'''Dietrich Mahnke''' (October 17, 1884, [[Verden an der Aller|Verden]] &amp;ndash; July 25, 1939, [[Fürth]]) was a [[German people|German]] [[philosophy|philosopher]] and [[history of mathematics|historian of mathematics]].

From 1902–1906, Mahnke studied at [[University of Göttingen|Göttingen]] under [[Edmund Husserl]] and [[David Hilbert]]. After serving in the First World War (stationed in Lens, France), he graduated from the [[University of Freiburg]] in 1925 with a thesis on Leibniz. The thesis was later published in the [[Jahrbuch für Philosophie und phänomenologische Forschung]] as ''Leibnizens Synthese von Universalmathematik und Individualmetaphysik''. In 1926 he [[Habilitation|habilitated]] at [[University of Greifswald|Greifswald]] with a thesis entitled ''Neue Einblicke in die Entdeckungsgeschichte der höheren Analysis''. In 1927 he became a professor of philosophy at [[University of Marburg|Marburg]].

In 1934 he became a member of the Nazi [[Sturmabteilung|SA]].&lt;ref&gt;George Leaman: ''Heidegger im Kontext: Gesamtüberblick zum NS-Engagement der Universitätsphilosophen'' (= ''Ideologische Mächte im deutschen Faschismus.'' Band 5). Argument, Hamburg 1993, {{ISBN|3-88619-205-9}}, p. 107.&lt;/ref&gt;

Mahnke's work in the history of mathematics focussed primarily on [[Gottfried Wilhelm Leibniz|Leibniz]]'s development of the [[infinitesimal calculus]], and his relationship to [[Neo-Platonism]]. His last book, ''Unendliche Sphäre und Allmittelpunkt, Beiträge zur Genealogie der mathematischen Mystik'' was a study of the use of mathematical symbolism, especially the notion of "infinite spheres", in religious [[mysticism]]. At the time of his death, Mahnke was editing a volume of Leibniz's mathematical correspondence.  This project was then taken over by Joseph Ehrenfried Hofmann.

Mahnke was killed in a car accident.

His ''Nachlass'' is preserved at the University of Marburg.

==Select Bibliography==
''Leibniz als Gegner der Gelehrteneinseitigkeit'' (1912)&lt;br /&gt;
''Der Wille der Ewigkeit'' (1917) &lt;br /&gt;
''Eine Neue Monadologie'' (1917) &lt;br /&gt;
''Die Neubelebung der Leibnizschen Weltanschauung'' (1920)&lt;br /&gt;
''Ewigkeit und Gegenwart, Eine Fichtische Zusammenschau'' (1922)&lt;br /&gt;
''Von Hilbert zu Husserl, Erste Einführung in die Phänomenologie, besonders die formale Mathematik'' (1923)&lt;br /&gt;
''Leibniz und Goethe: die Harmonie ihrer Weltansichten'' (1924)&lt;br /&gt;
''Neue Einblicke in die Entdeckungsgeschichte der höheren Analysis'' (1926) &lt;br /&gt;
''Ein unbekanntes Selbstzeugnis Leibnizens aus seiner Erziehertätigkeit'' (1931)&lt;br /&gt;
''Unendliche Sphäre und Allmittelpunkt, Beiträge zur Genealogie der mathematischen Mystik'' (1937)&lt;br /&gt;
''Die Rationalisierung der Mystik bei Leibniz und Kant'' (1939)

==References==
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}
* [[Joseph W. Dauben]], [[Christoph Scriba|Christoph J. Scriba]] (ed.): ''Writing the History of Mathematics – Its Historical Development''. Birkhäuser, Basel 2002, {{ISBN|978-3-7643-6167-9}}
* {{NDB|15|691|692|Mahnke, Dietrich|Gerhard Biller}}

{{Authority control}}

{{DEFAULTSORT:Mahnke, Dietrich}}
[[Category:1884 births]]
[[Category:1939 deaths]]
[[Category:German philosophers]]
[[Category:Sturmabteilung personnel]]
[[Category:University of Marburg faculty]]
[[Category:Historians of mathematics]]
[[Category:German male writers]]


{{Germany-philosopher-stub}}</text>
      <sha1>cz52t8rhefqe063b4vunfd29dwmzcce</sha1>
    </revision>
  </page>
  <page>
    <title>Differential of a function</title>
    <ns>0</ns>
    <id>23997203</id>
    <revision>
      <id>811794343</id>
      <parentid>775778624</parentid>
      <timestamp>2017-11-24T00:58:27Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Annales Scientifiques de l'École Normale Supérieure. Troisième Série → Annales Scientifiques de l'École Normale Supérieure |series=Série 3 using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29022">{{for|other uses of "differential" in mathematics|Differential (mathematics)}}
{{Calculus |Differential}}

In [[calculus]], the '''differential''' represents the [[principal part#Calculus|principal part]] of the change in a function ''y''&amp;nbsp;=&amp;nbsp;''f''(''x'') with respect to changes in the independent variable. The differential ''dy'' is defined by
:&lt;math&gt;dy = f'(x)\,dx,&lt;/math&gt;
where &lt;math&gt;f'(x)&lt;/math&gt; is the [[derivative]] of ''f'' with respect to ''x'', and ''dx'' is an additional real [[variable (mathematics)|variable]] (so that ''dy'' is a function of ''x'' and ''dx'').  The notation is such that the equation

:&lt;math&gt;dy = \frac{dy}{dx}\, dx&lt;/math&gt;

holds, where the derivative is represented in the [[Leibniz notation]] ''dy''/''dx'', and this is consistent with regarding the derivative as the quotient of the differentials. One also writes

:&lt;math&gt;df(x) = f'(x)\,dx.&lt;/math&gt;

The precise meaning of the variables ''dy'' and ''dx'' depends on the context of the application and the required level of mathematical rigor. The domain of these variables may take on a particular geometrical significance if the differential is regarded as a particular [[differential form]], or analytical significance if the differential is regarded as a [[linear approximation]] to the increment of a function.  Traditionally, the variables ''dx'' and ''dy'' are considered to be very small ([[infinitesimal]]), and this interpretation is made rigorous in [[non-standard analysis]].

==History and usage==
The differential was first introduced via an intuitive or heuristic definition by [[Gottfried Wilhelm Leibniz]], who thought of the differential&amp;nbsp;''dy'' as an infinitely small (or [[infinitesimal]]) change in the value&amp;nbsp;''y'' of the function, corresponding to an infinitely small change&amp;nbsp;''dx'' in the function's argument&amp;nbsp;''x''.  For that reason, the instantaneous rate of change of ''y'' with respect to ''x'', which is the value of the [[derivative]] of the function, is denoted by the fraction

: &lt;math&gt; \frac{dy}{dx} &lt;/math&gt;

in what is called the [[Leibniz notation]] for derivatives. The quotient ''dy''/''dx'' is not infinitely small; rather it is a [[real number]].

The use of infinitesimals in this form was widely criticized, for instance by the famous pamphlet [[The Analyst]] by Bishop Berkeley.  [[Augustin-Louis Cauchy]] ([[#CITEREFCauchy1823|1823]]) defined the differential without appeal to the atomism of Leibniz's infinitesimals.&lt;ref&gt;For a detailed historical account of the differential, see {{harvnb|Boyer|1959}}, especially page 275 for Cauchy's contribution on the subject.  An abbreviated account appears in {{harvnb|Kline|1972|loc=Chapter 40}}.&lt;/ref&gt;&lt;ref&gt;Cauchy explicitly denied the possibility of actual infinitesimal and infinite quantities {{harv|Boyer|1959|pp=273–275}}, and took the radically different point of view that "a variable quantity becomes infinitely small when its numerical value decreases indefinitely in such a way as to converge to zero" ({{harvnb|Cauchy|1823|p=12}};  translation from {{harvnb|Boyer|1959|p=273}}).&lt;/ref&gt; Instead, Cauchy, following [[Jean le Rond d'Alembert|d'Alembert]], inverted the logical order of Leibniz and his successors: the derivative itself became the fundamental object, defined as a [[limit (mathematics)|limit]] of difference quotients, and the differentials were then defined in terms of it.  That is, one was free to ''define'' the differential ''dy'' by an expression
:&lt;math&gt;dy = f'(x)\,dx&lt;/math&gt;
in which ''dy'' and ''dx''  are simply new variables taking finite real values,&lt;ref&gt;{{harvnb|Boyer|1959|p=275}}&lt;/ref&gt; not fixed infinitesimals as they had been for Leibniz.&lt;ref&gt;{{harvnb|Boyer|1959|p=12}}: "The differentials as thus defined are only new ''variables'', and not fixed infinitesimals..."&lt;/ref&gt;

According to {{harvtxt|Boyer|1959|p=12}}, Cauchy's approach was a significant logical improvement over the infinitesimal approach of Leibniz because, instead of invoking the metaphysical notion of infinitesimals, the quantities ''dy'' and ''dx'' could now be manipulated in exactly the same manner as any other real quantities
in a meaningful way.  Cauchy's overall conceptual approach to differentials remains the standard one in modern analytical treatments,&lt;ref&gt;{{harvnb|Courant|1937a|loc=II, §9}}: "Here we remark merely in passing that it is possible to use this approximate representation of the increment &amp;Delta;''y'' by the linear expression ''h&amp;fnof;''(''x'') to construct a logically satisfactory definition of a "differential", as was done by Cauchy in particular."&lt;/ref&gt; although the final word on rigor, a fully modern notion of the limit, was ultimately due to [[Karl Weierstrass]].&lt;ref&gt;{{harvnb|Boyer|1959|p=284}}&lt;/ref&gt;

In physical treatments, such as those applied to the theory of [[thermodynamics]], the infinitesimal view still prevails.  {{harvtxt|Courant|John|1999|p=184}} reconcile the physical use of infinitesimal differentials with the mathematical impossibility of them as follows.  The differentials represent finite non-zero values that are smaller than the degree of accuracy required for the particular purpose for which they are intended.  Thus "physical infinitesimals" need not appeal to a corresponding mathematical infinitesimal in order to have a precise sense.

Following twentieth-century developments in [[mathematical analysis]] and [[differential geometry]], it became clear that the notion of the differential of a function could be extended in a variety of ways.  In [[real analysis]], it is more desirable to deal directly with the differential as the principal part of the increment of a function.  This leads directly to the notion that the differential of a function at a point is a [[linear functional]] of an increment Δ''x''.  This approach allows the differential (as a linear map) to be developed for a variety of more sophisticated spaces, ultimately giving rise to such notions as the [[Fréchet derivative|Fréchet]] or [[Gâteaux derivative]].  Likewise, in [[differential geometry]], the differential of a function at a point is a linear function of a [[tangent vector]] (an "infinitely small displacement"), which exhibits it as a kind of one-form: the [[exterior derivative]] of the function.  In [[non-standard calculus]], differentials are regarded as infinitesimals, which can themselves be put on a rigorous footing (see [[differential (infinitesimal)]]).

==Definition==

[[File:Sentido geometrico del diferencial de una funcion.png|thumb|The differential of a function ''&amp;fnof;''(''x'') at a point&amp;nbsp;''x''&lt;sub&gt;0&lt;/sub&gt;.]]
The differential is defined in modern treatments of differential calculus as follows.&lt;ref&gt;See, for instance, the influential treatises of {{harvnb|Courant|1937a}}, {{harvnb|Kline|1977}}, {{harvnb|Goursat|1904}}, and {{harvnb|Hardy|1905}}.  Tertiary sources for this definition include also {{harvnb|Tolstov|2001}} and {{harvnb|Ito|1993|loc=§106}}.&lt;/ref&gt;  The differential of a function ''f''(''x'') of a single real variable ''x'' is the function ''df'' of two independent real variables ''x'' and ''Δx'' given by

:&lt;math&gt;df(x, \Delta x) \stackrel{\mathrm{def}}{=} f'(x)\,\Delta x.&lt;/math&gt;

One or both of the arguments may be suppressed, i.e., one may see ''df''(''x'') or simply ''df''. If ''y''&amp;nbsp;=&amp;nbsp;''f''(''x''), the differential may also be written as ''dy''.  Since ''dx''(''x'',&amp;nbsp;Δ''x'')&amp;nbsp;=&amp;nbsp;Δ''x'' it is conventional to write ''dx''&amp;nbsp;=&amp;nbsp;Δ''x'', so that the following equality holds:

:&lt;math&gt;df(x) = f'(x) \, dx&lt;/math&gt;
 
This notion of differential is broadly applicable when a [[linear approximation]] to a function is sought, in which the value of the increment Δ''x'' is small enough.  More precisely, if ''f'' is a [[differentiable function]] at ''x'', then the difference in ''y''-values

:&lt;math&gt;\Delta y \stackrel{\rm{def}}{=} f(x+\Delta x) - f(x)&lt;/math&gt;

satisfies

:&lt;math&gt;\Delta y = f'(x)\,\Delta x + \varepsilon = df(x) + \varepsilon\,&lt;/math&gt;

where the error ε in the approximation satisfies ε/Δ''x''&amp;nbsp;→&amp;nbsp;0 as Δ''x''&amp;nbsp;→&amp;nbsp;0.  In other words, one has the approximate identity

:&lt;math&gt;\Delta y \approx dy&lt;/math&gt;

in which the error can be made as small as desired relative to Δ''x'' by constraining ''Δx'' to be sufficiently small; that is to say,
:&lt;math&gt;\frac{\Delta y - dy}{\Delta x}\to 0&lt;/math&gt;
as Δ''x''&amp;nbsp;→&amp;nbsp;0.  For this reason, the differential of a function is known as the [[principal part|principal (linear) part]] in the increment of a function: the differential is a [[linear function]] of the increment Δ''x'', and although the error ε may be nonlinear, it tends to zero rapidly as Δ''x'' tends to zero.

==Differentials in several variables==
Following {{harvtxt|Goursat|1904|loc=I, §15}}, for functions of more than one independent variable,

: &lt;math&gt; y = f(x_1,\dots,x_n), \, &lt;/math&gt;

the '''partial differential''' of ''y'' with respect to any one of the variables&amp;nbsp;''x''&lt;sub&gt;1&lt;/sub&gt; is the principal part of the change in ''y'' resulting from a change&amp;nbsp;''dx''&lt;sub&gt;1&lt;/sub&gt; in that one variable.  The partial differential is therefore

: &lt;math&gt; \frac{\partial y}{\partial x_1} dx_1 &lt;/math&gt;

involving the [[partial derivative]] of ''y'' with respect to&amp;nbsp;''x''&lt;sub&gt;1&lt;/sub&gt;.  The sum of the partial differentials with respect to all of the independent variables is the '''total differential'''

: &lt;math&gt; dy = \frac{\partial y}{\partial x_1} dx_1 + \cdots + \frac{\partial y}{\partial x_n} dx_n, &lt;/math&gt;

which is the principal part of the change in ''y'' resulting from changes in the independent variables&amp;nbsp;''x''&lt;sub&gt;''i''&lt;/sub&gt;.

More precisely, in the context of multivariable calculus, following {{harvtxt|Courant|1937b}}, if ''f'' is a differentiable function, then by the [[Fréchet derivative|definition of the differentiability]], the increment

:&lt;math&gt;\begin{align}
\Delta y &amp;{}\stackrel{\mathrm{def}}{=} f(x_1+\Delta x_1, \dots, x_n+\Delta x_n) - f(x_1,\dots,x_n)\\
&amp;{}= \frac{\partial y}{\partial x_1} \Delta x_1 + \cdots + \frac{\partial y}{\partial x_n} \Delta x_n + \varepsilon_1\Delta x_1 +\cdots+\varepsilon_n\Delta x_n
\end{align}&lt;/math&gt;

where the error terms ε&lt;sub&gt;&amp;nbsp;''i''&lt;/sub&gt; tend to zero as the increments Δ''x''&lt;sub&gt;''i''&lt;/sub&gt; jointly tend to zero.  The total differential is then rigorously defined as

:&lt;math&gt;dy = \frac{\partial y}{\partial x_1} \Delta x_1 + \cdots + \frac{\partial y}{\partial x_n} \Delta x_n.&lt;/math&gt;

Since, with this definition,
:&lt;math&gt;dx_i(\Delta x_1,\dots,\Delta x_n) = \Delta x_i,&lt;/math&gt;
one has
:&lt;math&gt;dy = \frac{\partial y}{\partial x_1}\,d x_1 + \cdots + \frac{\partial y}{\partial x_n}\,d x_n.&lt;/math&gt;

As in the case of one variable, the approximate identity holds

:&lt;math&gt;dy \approx \Delta y&lt;/math&gt;

in which the total error can be made as small as desired relative to &lt;math&gt;\sqrt{\Delta x_1^2+\cdots +\Delta x_n^2}&lt;/math&gt; by confining attention to sufficiently small increments.

=== Application of the total differential to error estimation ===
In measurement, the total differential is used in [[Experimental uncertainty analysis|estimating the error]] Δ''f'' of a function ''f'' based on the errors Δ''x'', Δ''y'', ... of the parameters ''x, y, ...''. Assuming that the interval is short enough for the change to be approximately linear:

:Δ''f''(''x'') = ''f'''(''x'') × Δ''x''

and that all variables are independent, then for all variables,

:&lt;math&gt;\Delta f = f_x \Delta x + f_y \Delta y + \cdots&lt;/math&gt;

This is because the derivative ''f''&lt;sub&gt;x&lt;/sub&gt;  with respect to the particular parameter ''x'' gives the sensitivity of the function ''f'' to a change in ''x'', in particular the error Δ''x''. As they are assumed to be independent, the analysis describes the worst-case scenario. The absolute values of the component errors are used, because after simple computation, the derivative may have a negative sign. From this principle the error rules of summation, multiplication etc. are derived, e.g.:

:Let f(''a'', ''b'') = ''a'' × ''b'';

:Δ''f'' = ''f''&lt;sub&gt;''a''&lt;/sub&gt;Δ''a'' + ''f''&lt;sub&gt;''b''&lt;/sub&gt;Δ''b''; evaluating the derivatives

:Δ''f'' = ''b''Δ''a'' + ''a''Δ''b''; dividing by ''f'', which is ''a'' × ''b''

:Δ''f''/''f'' = Δ''a''/''a'' + Δ''b''/''b''

That is to say, in multiplication, the total [[relative error]] is the sum of the relative errors of the parameters.

To illustrate how this depends on the function considered, consider the case where the function is ''f(a, b) = a ln b'' instead. Then, it can be computed that the error estimate is
:Δ''f''/''f'' = Δ''a''/''a'' + Δ''b''/(''b'' ln ''b'')
with an extra 'ln ''b''' factor not found in the case of a simple product. This additional factor tends to make the error smaller, as ln ''b'' is not as large as a bare ''b''.

==Higher-order differentials==
Higher-order differentials of a function ''y''&amp;nbsp;=&amp;nbsp;''f''(''x'') of a single variable ''x'' can be defined via:&lt;ref&gt;{{harvnb|Cauchy|1823}}. See also, for instance,  {{harvnb|Goursat|1904|loc=I, §14}}.&lt;/ref&gt;
:&lt;math&gt;d^2y = d(dy) = d(f'(x)dx) = (df'(x))dx = f''(x)\,(dx)^2,&lt;/math&gt;
and, in general,
:&lt;math&gt;d^ny = f^{(n)}(x)\,(dx)^n.&lt;/math&gt;
Informally, this justifies Leibniz's notation for higher-order derivatives
:&lt;math&gt;f^{(n)}(x) = \frac{d^n f}{dx^n}.&lt;/math&gt;
When the independent variable ''x'' itself is permitted to depend on other variables, then the expression becomes more complicated, as it must include also higher order differentials in ''x'' itself.  Thus, for instance,
:&lt;math&gt;
\begin{align}
d^2 y &amp;= f''(x)\,(dx)^2 + f'(x)d^2x\\
d^3 y &amp;= f'''(x)\, (dx)^3 + 3f''(x)dx\,d^2x + f'(x)d^3x 
\end{align}&lt;/math&gt;
and so forth.

Similar considerations apply to defining higher order differentials of functions of several variables.  For example, if ''f'' is a function of two variables ''x'' and ''y'', then
:&lt;math&gt;d^nf = \sum_{k=0}^n \binom{n}{k}\frac{\partial^n f}{\partial x^k \partial y^{n-k}}(dx)^k(dy)^{n-k},&lt;/math&gt;
where &lt;math&gt;\scriptstyle{\binom{n}{k}}&lt;/math&gt; is a [[binomial coefficient]].  In more variables, an analogous expression holds, but with an appropriate [[multinomial coefficient|multinomial]] expansion rather than binomial expansion.&lt;ref&gt;{{harvnb|Goursat|1904|loc=I, §14}}&lt;/ref&gt;

Higher order differentials in several variables also become more complicated when the independent variables are themselves allowed to depend on other variables.  For instance, for a function ''f'' of ''x'' and ''y'' which are allowed to depend on auxiliary variables, one has
:&lt;math&gt;d^2f = \left(\frac{\partial^2f}{\partial x^2}(dx)^2+2\frac{\partial^2f}{\partial x\partial y}dx\,dy + \frac{\partial^2f}{\partial y^2}(dy)^2\right) + \frac{\partial f}{\partial x}d^2x + \frac{\partial f}{\partial y}d^2y.&lt;/math&gt;

Because of this notational infelicity, the use of higher order differentials was roundly criticized by {{harvnb|Hadamard|1935}}, who concluded:
:Enfin, que signifie ou que représente l'égalité
::&lt;math&gt;d^2z = r\,dx^2 + 2s\,dx\,dy + t\,dy^2\,?&lt;/math&gt;
:A mon avis, rien du tout.

That is: ''Finally, what is meant, or represented, by the equality [...]? In my opinion, nothing at all.'' In spite of this skepticism, higher order differentials did emerge as an important tool in analysis&lt;ref&gt;In particular to [[infinite dimensional holomorphy]] {{harv|Hille|Phillips|1974}} and [[numerical analysis]] via the calculus of [[finite differences]].&lt;/ref&gt;

In these contexts, the ''n''th order differential of the function ''f'' applied to an increment Δ''x'' is defined by
:&lt;math&gt;d^nf(x,\Delta x) = \left.\frac{d^n}{dt^n} f(x+t\Delta x)\right|_{t=0}&lt;/math&gt;
or an equivalent expression, such as
:&lt;math&gt;\lim_{t\to 0}\frac{\Delta^n_{t\Delta x} f}{t^n}&lt;/math&gt;
where &lt;math&gt;\Delta^n_{t\Delta x} f&lt;/math&gt; is an ''n''th [[forward difference]] with increment ''t''Δ''x''.

This definition makes sense as well if ''f'' is a function of several variables (for simplicity taken here as a vector argument). Then the ''n''th differential defined in this way is a [[homogeneous function]] of degree ''n'' in the vector increment Δ''x''.  Furthermore, the [[Taylor series]] of ''f'' at the point ''x'' is given by
:&lt;math&gt;f(x+\Delta x)\sim f(x) + df(x,\Delta x) + \frac{1}{2}d^2f(x,\Delta x) + \cdots + \frac{1}{n!}d^nf(x,\Delta x) + \cdots&lt;/math&gt;
The higher order [[Gâteaux derivative]] generalizes these considerations to infinite dimensional spaces.

==Properties==
A number of properties of the differential follow in a straightforward manner from the corresponding properties of the derivative, partial derivative, and total derivative.  These include:&lt;ref&gt;{{harvnb|Goursat|1904|loc=I, §17}}&lt;/ref&gt;

* [[Linearity]]:  For constants ''a'' and ''b'' and differentiable functions ''f'' and ''g'',
::&lt;math&gt;d(af+bg) = a\,df + b\,dg.&lt;/math&gt;
* [[Product rule]]:  For two differentiable functions ''f'' and ''g'',
::&lt;math&gt;d(fg) = f\,dg+g\,df.&lt;/math&gt;

An operation ''d'' with these two properties is known in [[abstract algebra]] as a [[derivation (abstract algebra)|derivation]].  They imply the Power rule
::&lt;math&gt; d( f^n ) = n f^{n-1} df &lt;/math&gt;
In addition, various forms of the [[chain rule]] hold, in increasing level of generality:&lt;ref&gt;{{harvnb|Goursat|1904|loc=I, §§14,16}}&lt;/ref&gt;

* If ''y''&amp;nbsp;=&amp;nbsp;''f''(''u'') is a differentiable function of the variable ''u'' and ''u''&amp;nbsp;=&amp;nbsp;''g''(''x'') is a differentiable function of ''x'', then
::&lt;math&gt;dy = f'(u)\,du = f'(g(x))g'(x)\,dx.&lt;/math&gt;

* If ''y''&amp;nbsp;=&amp;nbsp;''f''(''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''x''&lt;sub&gt;''n''&lt;/sub&gt;) and all of the variables&amp;nbsp;''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''x''&lt;sub&gt;''n''&lt;/sub&gt; depend on another variable&amp;nbsp;''t'', then by the [[Chain rule#Chain rule for several variables|chain rule for partial derivatives]], one has

:: &lt;math&gt;\begin{align}
dy &amp;= \frac{dy}{dt}dt \\
&amp;= \frac{\partial y}{\partial x_1} dx_1 + \cdots + \frac{\partial y}{\partial x_n} dx_n\\
&amp;= \frac{\partial y}{\partial x_1} \frac{dx_1}{dt}\,dt + \cdots + \frac{\partial y}{\partial x_n} \frac{dx_n}{dt}\,dt.
\end{align}&lt;/math&gt;

:Heuristically, the chain rule for several variables can itself be understood by dividing through both sides of this equation by the infinitely small quantity ''dt''.

* More general analogous expressions hold, in which the intermediate variables ''x''&lt;sub&gt;&amp;nbsp;''i''&lt;/sub&gt; depend on more than one variable.

==General formulation==
{{See also|Fréchet derivative|Gâteaux derivative}}
A consistent notion of differential can be developed for a function ''f''&amp;nbsp;:&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;'''R'''&lt;sup&gt;''m''&lt;/sup&gt; between two [[Euclidean space]]s.  Let '''x''',Δ'''x'''&amp;nbsp;∈&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt; be a pair of [[Euclidean vector]]s.  The increment in the function ''f'' is
:&lt;math&gt;\Delta f = f(\mathbf{x}+\Delta\mathbf{x}) - f(\mathbf{x}).&lt;/math&gt;
If there exists an ''m''&amp;nbsp;&amp;times;&amp;nbsp;''n'' [[matrix (mathematics)|matrix]] ''A'' such that
:&lt;math&gt;\Delta f = A\Delta\mathbf{x} + \|\Delta\mathbf{x}\|\boldsymbol{\varepsilon}&lt;/math&gt;
in which the vector '''''ε'''''&amp;nbsp;→&amp;nbsp;0 as Δ'''x'''&amp;nbsp;→&amp;nbsp;0, then ''f'' is by definition differentiable at the point '''x'''.  The matrix ''A'' is sometimes known as the [[Jacobian matrix]], and the [[linear transformation]] that associates to the increment Δ'''x'''&amp;nbsp;∈&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt; the vector ''A''Δ'''x'''&amp;nbsp;∈&amp;nbsp;'''R'''&lt;sup&gt;''m''&lt;/sup&gt; is, in this general setting, known as the differential ''df''(''x'') of ''f'' at the point ''x''.  This is precisely the [[Fréchet derivative]], and the same construction can be made to work for a function between any [[Banach space]]s.

Another fruitful point of view is to define the differential directly as a kind of [[directional derivative]]:

:&lt;math&gt;df(\mathbf{x},\mathbf{h}) = \lim_{t\to 0}\frac{f(\mathbf{x}+t\mathbf{h})-f(\mathbf{x})}{t} = \left.\frac{d}{dt}f(\mathbf{x}+t\mathbf{h})\right|_{t=0},&lt;/math&gt;

which is the approach already taken for defining higher order differentials (and is most nearly the definition set forth by Cauchy).  If ''t'' represents time and '''x''' position, then '''h''' represents a velocity instead of a displacement as we have heretofore regarded it.  This yields yet another refinement of the notion of differential: that it should be a linear function of a kinematic velocity.  The set of all velocities through a given point of space is known as the [[tangent space]], and so ''df'' gives a linear function on the tangent space: a [[differential form]].  With this interpretation, the differential of ''f'' is known as the [[exterior derivative]], and has broad application in [[differential geometry]] because the notion of velocities and the tangent space makes sense on any [[differentiable manifold]].  If, in addition, the output value of ''f'' also represents a position (in a Euclidean space), then a dimensional analysis confirms that the output value of ''df'' must be a velocity.  If one treats the differential in this manner, then it is known as the [[pushforward (differential)|pushforward]] since it "pushes" velocities from a source space into velocities in a target space.

==Other approaches==
{{Main|Differential (infinitesimal)}}
Although the notion of having an infinitesimal increment ''dx'' is not well-defined in modern [[mathematical analysis]], a variety of techniques exist for defining the [[differential (infinitesimal)|infinitesimal differential]] so that the differential of a function can be handled in a manner that does not clash with the [[Leibniz notation]].  These include:

* Defining the differential as a kind of [[differential form]], specifically the [[exterior derivative]] of a function.  The infinitesimal increments are then identified with vectors in the [[tangent space]] at a point.  This approach is popular in [[differential geometry]] and related fields, because it readily generalizes to mappings between [[differentiable manifold]]s.
* Differentials as [[nilpotent]] elements of [[commutative ring]]s. This approach is popular in [[algebraic geometry]].&lt;ref&gt;{{Harvnb|Eisenbud|Harris|1998}}.&lt;/ref&gt;
* Differentials in smooth models of set theory. This approach is known as [[synthetic differential geometry]] or [[smooth infinitesimal analysis]] and is closely related to the algebraic geometric approach, except that ideas from [[topos theory]] are used to ''hide'' the mechanisms by which nilpotent infinitesimals are introduced.&lt;ref&gt;See {{Harvnb|Kock|2006}} and {{Harvnb|Moerdijk|Reyes|1991}}.&lt;/ref&gt;
* Differentials as infinitesimals in [[hyperreal number]] systems, which are extensions of the real numbers which contain invertible infinitesimals and infinitely large numbers. This is the approach of [[nonstandard analysis]] pioneered by [[Abraham Robinson]].&lt;ref name="nonstd"&gt;See {{Harvnb|Robinson|1996}} and {{Harvnb|Keisler|1986}}.&lt;/ref&gt;

== Examples and applications ==
Differentials may be effectively used in [[numerical analysis]] to study the propagation of experimental errors in a calculation, and thus the overall [[numerical stability]] of a problem {{harv|Courant|1937a}}.  Suppose that the variable ''x'' represents the outcome of an experiment and ''y'' is the result of a numerical computation applied to ''x''.  The question is to what extent errors in the measurement of ''x'' influence the outcome of the computation of ''y''.  If the ''x'' is known to within Δ''x'' of its true value, then [[Taylor's theorem]] gives the following estimate on the error Δ''y'' in the computation of ''y'':
:&lt;math&gt;\Delta y = f'(x)\Delta x + \frac{(\Delta x)^2}{2}f''(\xi)&lt;/math&gt;
where ξ&amp;nbsp;=&amp;nbsp;''x''&amp;nbsp;+&amp;nbsp;θΔ''x'' for some 0&amp;nbsp;&lt;&amp;nbsp;θ&amp;nbsp;&lt;&amp;nbsp;1.  If Δ''x'' is small, then the second order term is negligible, so that Δ''y'' is, for practical purposes, well-approximated by ''dy''&amp;nbsp;=&amp;nbsp;''f'''(''x'')Δ''x''.

The differential is often useful to rewrite a [[differential equation]]

: &lt;math&gt; \frac{dy}{dx} = g(x) &lt;/math&gt;

in the form

: &lt;math&gt; dy = g(x)\,dx, &lt;/math&gt;

in particular when one wants to [[separation of variables|separate the variables]].

==Notes==
&lt;references/&gt;

== References ==
*{{Citation | last1=Boyer | first1=Carl B. | author1-link=Carl Benjamin Boyer | title=The history of the calculus and its conceptual development | publisher=[[Dover Publications]] | location=New York | mr=0124178  | year=1959}}.
*{{citation|first=Augustin-Louis|last=Cauchy|authorlink=Augustin-Louis Cauchy|chapter=&lt;!--Quatrième leçon: Différentialles des fonctions d'une seule variable--&gt;|title=Résumé des Leçons données à l'Ecole royale polytechnique sur les applications du calcul infinitésimal|year=1823|url=http://math-doc.ujf-grenoble.fr/cgi-bin/oeitem?id=OE_CAUCHY_2_4_9_0}}.
*{{Citation | last1=Courant | first1=Richard |authorlink=Richard Courant | title=Differential and integral calculus. Vol. I | publisher=[[John Wiley &amp; Sons]] | location=New York | series=Wiley Classics Library | isbn=978-0-471-60842-4 | mr=1009558  | year=1937a|publication-date=1988}}.
*{{Citation | last1=Courant | first1=Richard | authorlink=Richard Courant |title=Differential and integral calculus. Vol. II | publisher=[[John Wiley &amp; Sons]] | location=New York | series=Wiley Classics Library | isbn=978-0-471-60840-0 | mr=1009559  | year=1937b|publication-date=1988}}.
*{{Citation | last1=Courant | first1=Richard | authorlink1=Richard Courant| last2=John | first2=Fritz |authorlink2=Fritz John| title=Introduction to Calculus and Analysis Volume 1|series=Classics in Mathematics| publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=3-540-65058-X | year=1999 | mr=1746554  }}
* {{Citation| author1-link=David Eisenbud|first1=David|last1=Eisenbud|author2-link=Joe Harris (mathematician)|first2=Joe|last2=Harris| year = 1998 |title = The Geometry of Schemes| publisher = Springer-Verlag| isbn = 0-387-98637-5}}.
*{{Citation | last1=Fréchet | first1=Maurice | author1-link= Maurice Fréchet | title=La notion de différentielle dans l'analyse générale | mr=1509268  | year=1925 | journal=Annales Scientifiques de l'École Normale Supérieure |series=Série 3 | issn=0012-9593 | volume=42 | pages=293–323}}.
*{{Citation | last1=Goursat | first1=Édouard | authorlink=Édouard Goursat|title=A course in mathematical analysis: Vol 1: Derivatives and differentials, definite integrals, expansion in series, applications to geometry| publisher=[[Dover Publications]] | location=New York | others= E. R. Hedrick | mr=0106155  | year=1904 | publication-date=1959|url=https://archive.org/details/coursemathanalys01gourrich}}.
*{{citation|last=Hadamard|first=Jacques|authorlink=Jacques Hadamard|title=La notion de différentiel dans l'enseignement|journal=Mathematical Gazette|volume=XIX|year=1935|issue=236|pages=341–342|jstor=3606323}}.
*{{Citation | last1=Hardy | first1=Godfrey Harold | author1-link=G. H. Hardy | title=A Course of Pure Mathematics | publisher=[[Cambridge University Press]] | isbn=978-0-521-09227-2 | year=1908}}.
*{{Citation | last1=Hille | first1=Einar | authorlink1=Einar Hille | last2=Phillips | first2=Ralph S. | authorlink2=Ralph Phillips (mathematician) | title=Functional analysis and semi-groups | publisher=[[American Mathematical Society]] | location=Providence, R.I. | mr=0423094  | year=1974}}.
*{{Citation | last1=Ito | first1=Kiyosi | title=Encyclopedic Dictionary of Mathematics | publisher=[[MIT Press]] | edition=2nd | isbn=978-0-262-59020-4 | year=1993}}.
*{{citation|chapter=Chapter 13: Differentials and the law of the mean|title=Calculus: An intuitive and physical approach|first=Morris|last=Kline|authorlink=Morris Kline|publisher=John Wiley and Sons|year=1977}}.
*{{Citation | last1=Kline | first1=Morris | author1-link=Morris Kline | title=Mathematical thought from ancient to modern times | year=1972 | publisher=[[Oxford University Press]] | edition=3rd | isbn=978-0-19-506136-9 | publication-date=1990}}
* {{Citation |author-link=Howard Jerome Keisler|first=H. Jerome|last=Keisler|title=Elementary Calculus: An Infinitesimal Approach|edition=2nd|year=1986|url=http://www.math.wisc.edu/~keisler/calc.html}}.
* {{Citation | first=Anders|last= Kock|url=http://home.imf.au.dk/kock/sdg99.pdf|title= Synthetic Differential Geometry|publisher= Cambridge University Press|edition= 2nd|year=2006}}.
* {{Citation | last1=Moerdijk|first1= I.|authorlink1=Ieke Moerdijk|last2=Reyes|first2=G.E.|title=Models for Smooth Infinitesimal Analysis|publisher= Springer-Verlag|year= 1991}}.
* {{Citation | last1=Robinson | first1=Abraham | author1-link=Abraham Robinson | title=Non-standard analysis | publisher=[[Princeton University Press]] | isbn=978-0-691-04490-3 | year=1996}}.
*{{springer|id=D/d031810|title=Differential|first=G.P.|last=Tolstov}}.

==External links==
*[http://demonstrations.wolfram.com/DifferentialOfAFunction/ Differential Of A Function] at Wolfram Demonstrations Project

{{DEFAULTSORT:Differential Of A Function}}
[[Category:Differential calculus]]
[[Category:Generalizations of the derivative]]
[[Category:Linear operators in calculus]]</text>
      <sha1>i3askxfuty8r21t1erw884qtspt1dig</sha1>
    </revision>
  </page>
  <page>
    <title>Double affine Hecke algebra</title>
    <ns>0</ns>
    <id>32034345</id>
    <revision>
      <id>812477326</id>
      <parentid>812466315</parentid>
      <timestamp>2017-11-28T01:40:29Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <minor/>
      <comment>/* top */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1683">In mathematics, a '''double affine Hecke algebra''', or '''Cherednik algebra''',  is an algebra containing the [[affine Hecke algebra|Hecke algebra]] of an [[affine Weyl group]], given as the quotient of the group ring of a [[double affine braid group]]. They were introduced by [[Ivan Cherednik|Cherednik]], who  used them to prove [[Macdonald's constant term conjecture]] for [[Macdonald polynomial]]s. Infinitesimal Cherednik algebras have significant implications in [[representation theory]], and therefore have important applications in [[particle physics]] and in [[chemistry]].

==References==

*{{Citation | last1=Cherednik | first1=Ivan | title=Double affine Hecke algebras | publisher=[[Cambridge University Press]] | series=London Mathematical Society Lecture Note Series | isbn=978-0-521-60918-0 | mr=2133033 | year=2005 | volume=319}}
*{{citation |mr=2275709
|last=Haiman |first= Mark
|chapter=Cherednik algebras, Macdonald polynomials and combinatorics |title= International Congress of Mathematicians. Vol. III |pages= 843–872 |publisher= Eur. Math. Soc., Zürich |year= 2006 |isbn=978-3-03719-022-7 |url=http://mathunion.org/ICM/ICM2006.3/ |chapter-url=}} 
*A. A. Kirillov [http://www.ams.org/bull/1997-34-03/S0273-0979-97-00727-1/home.html Lectures on affine Hecke algebras and Macdonald's conjectures]  Bull. Amer. Math. Soc. 34 (1997), 251–292.
*[[Ian G. Macdonald|Macdonald, I. G.]] ''Affine Hecke algebras and orthogonal polynomials.'' Cambridge Tracts in Mathematics, 157. Cambridge University Press, Cambridge, 2003. x+175 pp.&amp;nbsp;{{ISBN|0-521-82472-9}} {{DOI|10.2277/0521824729}} {{mr|1976581 }}

[[Category:Algebras]]
[[Category:Representation theory]]</text>
      <sha1>fgybjq37adkswzdehpmlzd704wpq2vb</sha1>
    </revision>
  </page>
  <page>
    <title>Eilenberg–Steenrod axioms</title>
    <ns>0</ns>
    <id>3122600</id>
    <revision>
      <id>862708823</id>
      <parentid>855668774</parentid>
      <timestamp>2018-10-06T05:16:13Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4725">In [[mathematics]], specifically in [[algebraic topology]], the '''Eilenberg–Steenrod axioms''' are properties that [[homology theory|homology theories]] of [[topological space]]s have in common. The quintessential example of a homology theory satisfying the axioms is [[singular homology]], developed by [[Samuel Eilenberg]] and [[Norman Steenrod]].

One can define a homology theory as a [[sequence]] of [[functor]]s satisfying the Eilenberg–Steenrod axioms. The axiomatic approach, which was developed in 1945, allows one to prove results, such as the [[Mayer–Vietoris sequence]], that are common to all homology theories satisfying the axioms.&lt;ref&gt;http://www.math.uiuc.edu/K-theory/0245/survey.pdf&lt;/ref&gt;

If one omits the dimension axiom (described below), then the remaining axioms define what is called an [[extraordinary homology theory]]. Extraordinary cohomology theories first arose in [[K-theory]] and [[cobordism theory|cobordism]].

==Formal definition==

The Eilenberg–Steenrod axioms apply to a sequence of functors &lt;math&gt;H_n&lt;/math&gt; from the [[category (mathematics)|category]] of [[topological pair|pairs]] (''X'',&amp;nbsp;''A'') of topological spaces to the category of abelian [[group (mathematics)|group]]s, together with a [[natural transformation]] &lt;math&gt;\partial : H_{i}(X, A) \to H_{i-1}(A)&lt;/math&gt; called the '''boundary map''' (here ''H''&lt;sub&gt;''i''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt;(''A'') is a shorthand for ''H''&lt;sub&gt;''i''&amp;nbsp;−&amp;nbsp;1&lt;/sub&gt;(''A'',∅)). The axioms are:

# '''Homotopy''': Homotopic maps induce the same map in homology. That is, if  &lt;math&gt;g:(X, A) \rightarrow (Y,B)&lt;/math&gt; is [[homotopic]] to &lt;math&gt;h:(X, A) \rightarrow (Y,B)&lt;/math&gt;, then their induced [[Map (mathematics)|maps]] are the same.
# '''[[Excision theorem|Excision]]''': If (''X'',&amp;nbsp;''A'') is a pair and ''U'' is a subset of ''X'' such that the closure of ''U'' is contained in the interior of ''A'', then the inclusion map &lt;math&gt;i : (X-U, A-U) \to (X, A)&lt;/math&gt; induces an [[isomorphism]] in homology.
# '''Dimension''': Let ''P'' be the one-point space; then &lt;math&gt;H_n(P) = 0&lt;/math&gt; for all &lt;math&gt;n \neq 0&lt;/math&gt;.
# '''Additivity''': If &lt;math&gt;X = \coprod_{\alpha}{X_{\alpha}}&lt;/math&gt;, the disjoint union of a family of topological spaces &lt;math&gt;X_{\alpha}&lt;/math&gt;, then &lt;math&gt;H_n(X) \cong \bigoplus_{\alpha} H_n(X_{\alpha}).&lt;/math&gt;
# '''Exactness''': Each pair ''(X, A)'' induces a [[long exact sequence]] in homology, via the inclusions &lt;math&gt;i: A \to X&lt;/math&gt; and &lt;math&gt;j: X \to (X, A)&lt;/math&gt;:
::&lt;math&gt; \cdots \to H_n(A) \to^{\!\!\!\!\!\! i_*} H_n(X) \to^{\!\!\!\!\!\! j_*} H_n (X,A) \to^{\!\!\!\!\!\!\partial} H_{n-1}(A) \to \cdots.&lt;/math&gt;

If ''P'' is the one point space then  ''H''&lt;sub&gt;0&lt;/sub&gt;(''P'') is called the '''coefficient group'''. For example, singular homology (taken with integer coefficients, as is most common) has as coefficients the integers.

==Consequences==

Some facts about homology groups can be derived directly from the axioms, such as the fact that homotopically equivalent spaces have isomorphic homology groups.

The homology of some relatively simple spaces, such as ''n''-[[sphere]]s, can be calculated directly from the axioms. From this it can be easily shown that the (''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)-sphere is not a [[retract]] of the ''n''-disk. This is used in a proof of the [[Brouwer fixed point theorem]].

==Dimension axiom==

A "homology-like" theory satisfying all of the Eilenberg–Steenrod axioms except the dimension axiom is called an '''[[extraordinary homology theory]]''' (dually, '''[[extraordinary cohomology theory]]'''). Important examples of these were found in the 1950s, such as [[topological K-theory]] and [[cobordism theory]], which are extraordinary ''co''homology theories, and come with homology theories dual to them.

==See also==
* [[Zig-zag lemma]]

==Notes==
{{reflist}}

==References==
* {{cite journal | last1=Eilenberg | first1=Samuel | last2=Steenrod | first2=Norman E. | title=Axiomatic approach to homology theory | journal=[[Proc. Natl. Acad. Sci.]] | volume=31 | pages=117–120 | year=1945 | mr=0012228 | pmc=1078770 | pmid=16578143 | doi=10.1073/pnas.31.4.117}}
* {{cite book | last1=Eilenberg | first1=Samuel | last2=Steenrod | first2=Norman E. | title=Foundations of algebraic topology | publisher=Princeton University Press | location=Princeton, New Jersey | year=1952 | mr=0050886}}
* {{cite book | last=Bredon | first=Glen | mr=1224675 | title=Topology and Geometry | publisher=Springer-Verlag | location=New York | year=1993 | volume=139 | series=Graduate Texts in Mathematics | isbn=0-387-97926-3 | doi=10.1007/978-1-4757-6848-0 }}

{{DEFAULTSORT:Eilenberg-Steenrod axioms}}
[[Category:Homology theory]]
[[Category:Mathematical axioms]]</text>
      <sha1>9uu0j2c68cegnrczfa4z22yf35nl6f9</sha1>
    </revision>
  </page>
  <page>
    <title>Esscher transform</title>
    <ns>0</ns>
    <id>33893714</id>
    <revision>
      <id>716060654</id>
      <parentid>661375500</parentid>
      <timestamp>2016-04-19T17:22:10Z</timestamp>
      <contributor>
        <username>Ian (Wiki Ed)</username>
        <id>22738028</id>
      </contributor>
      <comment>/* See also */ +</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2793">In [[actuarial science]], the '''Esscher transform''' {{harv|Gerber|Shiu|1994}} is a transform that takes a [[probability density function|probability density]] ''f''(''x'') and transforms it to a new probability density ''f''(''x'';&amp;nbsp;''h'') with a parameter ''h''. It was introduced by F. Esscher in 1932 {{harv|Esscher|1932}}.

==Definition==

Let ''f''(''x'') be a probability density. Its Esscher transform is defined as

:&lt;math&gt;f(x;h)=\frac{e^{hx}f(x)}{\int_{-\infty}^\infty e^{hx} f(x) dx}.\,&lt;/math&gt;

More generally, if ''&amp;mu;'' is a [[probability measure]], the Esscher transform of ''&amp;mu;'' is a new probability measure ''E&lt;sub&gt;h&lt;/sub&gt;''(''&amp;mu;'') which has [[Radon–Nikodym derivative|density]]

:&lt;math&gt;\frac{e^{hx}}{\int_{-\infty}^\infty e^{hx} d\mu(x)} &lt;/math&gt;

with respect to ''&amp;mu;''.

== Basic properties ==

; Combination

: The Esscher transform of an Esscher transform is again an Esscher transform: ''E&lt;sub&gt;h&lt;/sub&gt;''&lt;sub&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;/sub&gt;&amp;nbsp;''E&lt;sub&gt;h&lt;/sub&gt;''&lt;sub&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''E&lt;sub&gt;h&lt;/sub&gt;''&lt;sub&gt;&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;+&amp;nbsp;''h''&lt;sub&gt;2&lt;/sub&gt;&lt;/sub&gt;.

; Inverse

: The inverse of the Esscher transform is the Esscher transform with negative parameter: ''E''{{su|b=''h''|p=&amp;minus;1}}&amp;nbsp;=&amp;nbsp;''E''&lt;sub&gt;&amp;minus;''h''&lt;/sub&gt;

; Mean move

: The effect of the Esscher transform on the [[normal distribution]] is moving the mean:

:: &lt;math&gt;E_h(\mathcal{N}(\mu,\,\sigma^2)) =\mathcal{N}(\mu + h\sigma^2,\,\sigma^2).\,&lt;/math&gt;

== Examples ==
{|class="wikitable"
|-
! Distribution
! Esscher transform 
|-
| [[Bernoulli distribution|Bernoulli]] Bernoulli(''p'')
| &amp;nbsp;&lt;math&gt;\,\frac{e^{hk}p^k(1-p)^{n-k}}{1-p+pe^h}&lt;/math&gt;
|-
| [[Binomial distribution|Binomial]] B(''n'',&amp;nbsp;''p'')
| &amp;nbsp;&lt;math&gt;\,\frac{{n\choose k}e^{hk}p^k(1-p)^{n-k}}{(1-p+pe^h)^n}&lt;/math&gt;
|-
| [[Normal distribution|Normal]] ''N''(''μ'', ''σ''&lt;sup&gt;2&lt;/sup&gt;'')
| &amp;nbsp; &lt;math&gt;\,\frac{1}{\sqrt{2 \pi \sigma^2}}e^{-\frac{(x-\mu-\sigma^2 h)^2}{2\sigma ^2}}&lt;/math&gt;
|-
| [[Poisson distribution|Poisson]] Pois(''λ'')
| &amp;nbsp; &lt;math&gt;\,\frac{e^{hk-\lambda e^h}\lambda^k}{k!}&lt;/math&gt;
|- 
|}

==See also==
* [[Esscher principle]]
* [[Exponential tilting]]

== References ==
* {{cite journal
 |title=Option Pricing by Esscher Transforms
 |last=Gerber
 |first=Hans U.
 |first2=Elias S. W.
 |last2=Shiu
 |journal=Transactions of the Society of Actuaries
 |volume=46
 |year= 1994
 |pages=99–191
 | url = http://pages.stern.nyu.edu/~dbackus/Disasters/Gerber_Shiu_94.pdf
 |ref=harv}}

* {{cite journal
 |title=On the Probability Function in the Collective Theory of Risk
 |journal=Skandinavisk Aktuarietidskrift
 |volume=15
 |issue = 3
 |year=1932
 |pages=175–195
 |last=Esscher
 |first=F.
 |doi = 10.1080/03461238.1932.10405883
 |ref=harv}}

[[Category:Actuarial science]]
[[Category:Transforms]]</text>
      <sha1>lkiv9p7yktq4ndipxonvokcuffytltm</sha1>
    </revision>
  </page>
  <page>
    <title>Event structure</title>
    <ns>0</ns>
    <id>34812675</id>
    <revision>
      <id>853172032</id>
      <parentid>852917799</parentid>
      <timestamp>2018-08-02T22:17:34Z</timestamp>
      <contributor>
        <username>Diannaa</username>
        <id>10728040</id>
      </contributor>
      <comment>remove copyright content copied from https://depositonce.tu-berlin.de/bitstream/11303/5801/3/arbach_youssef.pdf</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1352">In [[mathematics]] and [[computer science]], an '''event structure''' represents a [[Set (mathematics)|set]] of events, some of which can only be performed after another (there is a [[dependency (project management)|''dependency'' between the events]]) and some of which might not be performed together (there is a ''conflict'' between the events).

==Formal definition==
An '''event structure''' &lt;math&gt;(E,\leq,\#)&lt;/math&gt; consists of
* a set &lt;math&gt;E&lt;/math&gt; of '''events'''
* a [[partial order]] relation on &lt;math&gt;E&lt;/math&gt; called '''causal dependency''',
* an [[irreflexive]] [[symmetric]] relation &lt;math&gt;\#&lt;/math&gt; called '''incompatibility''' (or '''conflict''')
such that
* ''finite causes'': for every event &lt;math&gt;e\in E&lt;/math&gt;, the set &lt;math&gt;[e]=\{f\in E|f\leq e\}&lt;/math&gt; of predecessors of &lt;math&gt;e&lt;/math&gt; in &lt;math&gt;E&lt;/math&gt; is finite
* ''hereditary conflict'': for every events &lt;math&gt;d,e,f\in E&lt;/math&gt;, if &lt;math&gt;d\leq e&lt;/math&gt; and &lt;math&gt;d\# f&lt;/math&gt; then &lt;math&gt;e\# f&lt;/math&gt;.

==See also==
* [[Binary relation]]
* [[Mathematical structure]]

==References==
* {{cite news | last = Winskel | first = Glynn | url = http://www.cl.cam.ac.uk/~gw104/EvStr.pdf | title = Event Structures | journal = Advances in Petri Nets | publisher = Springer | series = Lecture Notes in Computer Science | year = 1987}}

[[Category:Computing terminology]]


{{math-stub}}</text>
      <sha1>lsplly9upi07b997oycgscpm0pw0qz9</sha1>
    </revision>
  </page>
  <page>
    <title>Extensions of symmetric operators</title>
    <ns>0</ns>
    <id>10858909</id>
    <revision>
      <id>868545152</id>
      <parentid>774193682</parentid>
      <timestamp>2018-11-12T21:51:21Z</timestamp>
      <contributor>
        <username>MMmpds</username>
        <id>27946345</id>
      </contributor>
      <minor/>
      <comment>/* Symmetric operators */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12858">In [[functional analysis]], one is interested in '''extensions of symmetric operators''' acting on a [[Hilbert space]]. Of particular importance is the existence, and sometimes explicit constructions, of [[self-adjoint]] extensions. This problem arises, for example, when one needs to specify domains of self-adjointness for formal expressions of [[observable]]s in [[quantum mechanic]]s. Other applications of solutions to this problem can be seen in various [[moment problem]]s.

This article discusses a few related problems of this type. The unifying theme is that each problem has an operator-theoretic characterization which gives a corresponding parametrization of solutions. More specifically, finding self-adjoint extensions, with various requirements, of [[symmetric operator]]s is equivalent to finding unitary extensions of suitable [[partial isometry|partial isometries]].

== Symmetric operators ==
Let ''H'' be a Hilbert space. A [[linear operator]] ''A'' acting on ''H'' with dense domain Dom(''A'') is '''symmetric''' if

:&lt;''Ax'', ''y''&gt; = &lt;''x'', ''Ay''&gt;, for all ''x'', ''y'' in Dom(''A'').

If Dom(''A'') = ''H'', the [[Hellinger-Toeplitz theorem]] says that ''A'' is a [[bounded operator]], in which case ''A'' is [[self-adjoint operator|self-adjoint]] and the extension problem is trivial. In general, a symmetric operator is self-adjoint if the domain of its adjoint, Dom(''A*''), lies in Dom(''A'').

When dealing with [[unbounded operator]]s, it is often desirable to be able to assume that the operator in question is [[closed operator|closed]]. In the present context, it is a convenient fact that every symmetric operator ''A'' is 
[[closable operator|closable]]. That is, ''A'' has a smallest closed extension, called the ''closure'' of ''A''. This can
be shown by invoking the symmetric assumption and [[Riesz representation theorem]]. Since ''A'' and its closure have the same closed extensions, it can always be assumed that the symmetric operator of interest is closed.

In the sequel, a symmetric operator will be assumed to be [[densely defined]] and closed.

'''Problem''' ''Given a densely defined closed symmetric operator A, find its self-adjoint extensions.''

This question can be translated to an operator-theoretic one. As a heuristic motivation, notice that the [[Cayley transform]] on the complex plane, defined by

:&lt;math&gt;z \mapsto \frac{z-i}{z+i}&lt;/math&gt;

maps the real line to the unit circle. This suggests one define, for a symmetric operator ''A'',

:&lt;math&gt;U_A = (A - i)(A + i)^{-1}\,&lt;/math&gt;

on ''Ran''(''A'' + ''i''), the range of ''A'' + ''i''. The operator ''U&lt;sub&gt;A&lt;/sub&gt;'' is in fact an isometry between closed subspaces that takes (''A'' + ''i'')''x'' to (''A'' - ''i'')''x'' for ''x'' in Dom(''A''). The map

:&lt;math&gt;A \mapsto U_A&lt;/math&gt;

is also called the '''Cayley transform''' of the symmetric operator ''A''. Given ''U&lt;sub&gt;A&lt;/sub&gt;'', ''A'' can be recovered by

:&lt;math&gt;A = - i(U + 1)(U - 1)^{-1} ,\,&lt;/math&gt;

defined on ''Dom''(''A'') = ''Ran''(''U'' - 1). Now if

:&lt;math&gt; \tilde{U} &lt;/math&gt;
 
is an isometric extension of ''U&lt;sub&gt;A&lt;/sub&gt;'', the operator

:&lt;math&gt;\tilde{A} =  - i( \tilde{U} + 1)( \tilde{U} - 1 )^{-1} &lt;/math&gt;

acting on

:&lt;math&gt; Ran (- \frac{i}{2} ( \tilde{U} - 1)) =  Ran ( \tilde{U} - 1) &lt;/math&gt;

is a symmetric extension of ''A''.

'''Theorem''' The symmetric extensions of a closed symmetric operator ''A'' is in one-to-one correspondence with the isometric extensions of its Cayley transform ''U&lt;sub&gt;A&lt;/sub&gt;''.

Of more interest is the existence of ''self-adjoint'' extensions. The following is true.

'''Theorem''' A closed symmetric operator ''A'' is self-adjoint if and only if Ran (''A'' ± ''i'') = ''H'', i.e. when its Cayley transform ''U&lt;sub&gt;A&lt;/sub&gt;'' is a unitary operator on ''H''.

'''Corollary''' The self-adjoint extensions of a closed symmetric operator ''A'' is in one-to-one correspondence with the unitary extensions of its Cayley transform ''U&lt;sub&gt;A&lt;/sub&gt;''.

Define the '''deficiency subspaces''' of ''A'' by

:&lt;math&gt;K_+ = Ran(A+i)^{\perp}&lt;/math&gt;

and

:&lt;math&gt;K_- = Ran(A-i)^{\perp}.&lt;/math&gt;

In this language, the description of the self-adjoint extension problem given by the corollary can be restated as follows: a symmetric operator ''A'' has self-adjoint extensions if and only if its Cayley transform ''U&lt;sub&gt;A&lt;/sub&gt;'' has unitary extensions to ''H'', i.e. the deficiency subspaces ''K''&lt;sub&gt;+&lt;/sub&gt; and ''K''&lt;sub&gt;−&lt;/sub&gt; have the same dimension.

=== An example ===
Consider the Hilbert space ''L''&lt;sup&gt;2&lt;/sup&gt;[0,1]. On the subspace of absolutely continuous function that vanish on the boundary, define the operator ''A'' by

:&lt;math&gt;A f = i \frac{d}{dx} f.&lt;/math&gt;

Integration by parts shows ''A'' is symmetric. Its adjoint ''A*'' is the same operator with Dom(''A*'') being the [[absolutely continuous function]]s with no boundary condition. We will see that extending ''A'' amounts to modifying the boundary conditions, thereby enlarging Dom(''A'') and reducing Dom(''A*''), until the two coincide.

Direct calculation shows that ''K''&lt;sub&gt;+&lt;/sub&gt; and ''K''&lt;sub&gt;−&lt;/sub&gt; are one-dimensional subspaces given by

:&lt;math&gt;K_+ = \operatorname{span} \{\phi_+ = a \cdot e^x \}&lt;/math&gt;

and

:&lt;math&gt;K_- = \operatorname{span}\{ \phi_- = a \cdot e^{-x} \}&lt;/math&gt;

where ''a'' is a normalizing constant. So the self-adjoint extensions of ''A'' are parametrized by the unit circle in the complex plane, {{mset|{{abs|''α''}} {{=}} 1}}. For each unitary ''U&lt;sub&gt;α&lt;/sub&gt;'' : ''K''&lt;sub&gt;−&lt;/sub&gt; → ''K''&lt;sub&gt;+&lt;/sub&gt;, defined by ''U&lt;sub&gt;α&lt;/sub&gt;''(''φ''&lt;sub&gt;−&lt;/sub&gt;) = ''αφ''&lt;sub&gt;+&lt;/sub&gt;, there corresponds an extension ''A''&lt;sub&gt;''α''&lt;/sub&gt; with domain

:&lt;math&gt; \operatorname{Dom}(A_{\alpha}) = \{ f + \beta (\alpha \phi_{-} - \phi_+) | f \in \operatorname{Dom}(A) , \; \beta \in \mathbb{C} \}.&lt;/math&gt;

If ''f'' ∈ Dom(''A''&lt;sub&gt;''α''&lt;/sub&gt;), then ''f'' is absolutely continuous and

:&lt;math&gt;\left|\frac{f(0)}{f(1)}\right| = \left|\frac{e\alpha -1}{\alpha - e}\right| = 1.&lt;/math&gt;

Conversely, if ''f'' is absolutely continuous and ''f''(0) = ''γf''(1) for some complex ''γ'' with |''γ''| = 1, then ''f'' lies in the above domain.

The self-adjoint operators { ''A''&lt;sub&gt;''α''&lt;/sub&gt; } are instances of the [[momentum operator]] in quantum mechanics.

== Self-adjoint extension on a larger space ==
{{Expand section|date=June 2008}}
Every partial isometry can be extended, on a possibly larger space, to a unitary operator. Consequently, every symmetric operator has a self-adjoint extension, on a possibly larger space.

== Positive symmetric operators ==
A symmetric operator ''A'' is called '''positive''' if &lt;''Ax'', ''x''&gt; ≥ 0 for all ''x'' in ''Dom''(''A''). It is known that for every such ''A'', one has dim(''K''&lt;sub&gt;+&lt;/sub&gt;) = dim(''K''&lt;sub&gt;−&lt;/sub&gt;). Therefore, every positive symmetric operator has self-adjoint extensions. The more interesting question in this direction is whether ''A'' has positive self-adjoint extensions.

For two positive operators ''A'' and ''B'', we put ''A'' ≤ ''B'' if

:&lt;math&gt;(A + 1)^{-1} \ge (B + 1)^{-1}&lt;/math&gt;

in the sense of bounded operators.

=== Structure of 2 &amp;times; 2 matrix contractions ===
While the extension problem for general symmetric operators is essentially that of extending partial isometries to unitaries, for positive symmetric operators the question becomes one of extending [[Contraction (operator theory)|contraction]]s: by "filling out" certain unknown entries of a 2 &amp;times; 2 self-adjoint contraction, we obtain the positive self-adjoint extensions of a positive symmetric operator.

Before stating the relevant result, we first fix some terminology. For a contraction Γ, acting on ''H'', we define its ''defect operators'' by

:&lt;math&gt; D_{ \Gamma } = (1 - \Gamma^*\Gamma  )^{\frac{1}{2}} \quad \mbox{and} \quad D_{\Gamma^*} = (1 - \Gamma \Gamma^*)^{\frac{1}{2}}.&lt;/math&gt;

The ''defect spaces'' of Γ are

:&lt;math&gt;\mathcal{D}_{\Gamma} = Ran(  D_{\Gamma} ) \quad \mbox{and} \quad \mathcal{D}_{\Gamma^*} = Ran(  D_{\Gamma^*} ).&lt;/math&gt;

The defect operators indicate the non-unitarity of Γ, while the defect spaces ensure uniqueness in some parameterizations.
Using this machinery, one can explicitly describe the structure of general matrix contractions. We will only need the 2 &amp;times; 2 case. Every 2 &amp;times; 2 contraction Γ can be uniquely expressed as

:&lt;math&gt;
\Gamma =
\begin{bmatrix}
\Gamma_1 &amp; D_{\Gamma_1 ^*} \Gamma_2\\
\Gamma_3 D_{\Gamma_1} &amp; - \Gamma_3 \Gamma_1^* \Gamma_2 + D_{\Gamma_3 ^*} \Gamma_4 D_{\Gamma_2}
\end{bmatrix}
&lt;/math&gt;

where each Γ&lt;sub&gt;''i''&lt;/sub&gt; is a contraction.

=== Extensions of Positive symmetric operators ===
The Cayley transform for general symmetric operators can be adapted to this special case. For every non-negative number ''a'',

:&lt;math&gt;\left|\frac{a-1}{a+1}\right| \le 1.&lt;/math&gt;

This suggests we assign to every positive symmetric operator ''A'' a contraction

:&lt;math&gt;C_A : Ran(A + 1) \rightarrow Ran(A-1) \subset \mathcal{H} &lt;/math&gt;

defined by

:&lt;math&gt;C_A (A+1)x = (A-1)x. \quad \mbox{i.e.} \quad C_A = (A-1)(A+1)^{-1}.\,&lt;/math&gt;

which have matrix representation

:&lt;math&gt;
C_A =
\begin{bmatrix}
\Gamma_1 \\
\Gamma_3 D_{\Gamma_1}
\end{bmatrix}
: Ran(A+1) \rightarrow
\begin{matrix}
Ran(A+1) \\
\oplus \\
Ran(A+1)^{\perp}
\end{matrix}.
&lt;/math&gt;

It is easily verified that the Γ&lt;sub&gt;1&lt;/sub&gt; entry, ''C&lt;sub&gt;A&lt;/sub&gt;'' projected onto ''Ran''(''A'' + 1) = ''Dom''(''C&lt;sub&gt;A&lt;/sub&gt;''), is self-adjoint. The operator ''A'' can be written as

:&lt;math&gt;A = (1+ C_A)(1 - C_A)^{-1} \,&lt;/math&gt;

with ''Dom''(''A'') = ''Ran''(''C&lt;sub&gt;A&lt;/sub&gt;'' - 1). If

:&lt;math&gt; \tilde{C} &lt;/math&gt;

is a contraction that extends ''C&lt;sub&gt;A&lt;/sub&gt;'' and its projection onto its domain is self-adjoint, then it is clear that its inverse Cayley transform

:&lt;math&gt;\tilde{A} = ( 1 + \tilde{C}  ) ( 1 - \tilde{C} )^{-1}  &lt;/math&gt;

defined on

:&lt;math&gt;Ran ( 1 - \tilde{C} )&lt;/math&gt;

is a positive symmetric extension of ''A''. The symmetric property follows from its projection onto its own domain being self-adjoint and positivity follows from contractivity. The converse is also true: given a positive symmetric extension of ''A'', its Cayley transform is a contraction satisfying the stated "partial" self-adjoint property.

'''Theorem''' The positive symmetric extensions of ''A'' are in one-to-one correspondence with the extensions of its Cayley transform where if ''C'' is such an extension, we require ''C'' projected onto ''Dom''(''C'') be self-adjoint.

The unitarity criterion of the Cayley transform is replaced by self-adjointness for positive operators.

'''Theorem''' A symmetric positive operator ''A'' is self-adjoint if and only if its Cayley transform is a self-adjoint contraction defined on all of ''H'', i.e. when ''Ran''(''A'' + 1) = ''H''.

Therefore, finding self-adjoint extension for a positive symmetric operator becomes a "[[matrix completion]] problem". Specifically, we need to embed the column contraction ''C&lt;sub&gt;A&lt;/sub&gt;'' into a 2 &amp;times; 2 self-adjoint contraction. This can always be done and the structure of such contractions gives a parametrization of all possible extensions.

By the preceding subsection, all self-adjoint extensions of ''C&lt;sub&gt;A&lt;/sub&gt;'' takes the form

:&lt;math&gt;
\tilde{C}(\Gamma_4) =
\begin{bmatrix}
\Gamma_1 &amp; D_{\Gamma_1} \Gamma_3 ^* \\
\Gamma_3 D_{\Gamma_1} &amp; - \Gamma_3 \Gamma_1 \Gamma_3^* + D_{\Gamma_3^*} \Gamma_4 D_{\Gamma_3^*}
\end{bmatrix}.
&lt;/math&gt;

So the self-adjoint positive extensions of ''A'' are in bijective correspondence with the self-adjoint contractions Γ&lt;sub&gt;4&lt;/sub&gt; on the defect space

:&lt;math&gt;\mathcal{D}_{\Gamma_3^*}&lt;/math&gt;

of Γ&lt;sub&gt;3&lt;/sub&gt;. The contractions

:&lt;math&gt;\tilde{C}(-1) \quad \mbox{and} \quad \tilde{C}(1)&lt;/math&gt;
 
give rise to positive extensions

:&lt;math&gt;A_0 \quad \mbox{and} \quad A_{\infty}&lt;/math&gt;

respectively. These are the ''smallest'' and ''largest'' positive extensions of ''A'' in the sense that

:&lt;math&gt;A_0 \leq B \leq A_{\infty}&lt;/math&gt;

for any positive self-adjoint extension ''B'' of ''A''. The operator ''A''&lt;sub&gt;∞&lt;/sub&gt; is the '''[[Friedrichs extension]]''' of ''A'' and ''A''&lt;sub&gt;0&lt;/sub&gt; is the '''von Neumann-Krein extension''' of ''A''.

Similar results can be obtained for [[accretive operator]]s.

== References ==
*A. Alonso and B. Simon, The Birman-Krein-Vishik theory of self-adjoint extensions of semibounded operators. ''J. Operator Theory'' '''4''' (1980), 251-270.
*Gr. Arsene and A. Gheondea, Completing matrix contractions, ''J. Operator Theory'' '''7''' (1982), 179-189.
* N. Dunford and J.T. Schwartz, ''Linear Operators'', Part II, Interscience, 1958.
* B.C. Hall, ''Quantum Theory for Mathematicians'', Chapter 9, Springer, 2013.
*M. Reed and B. Simon, ''Methods of Modern Mathematical Physics'', vol. I and II, Academic Press, 1975.

{{DEFAULTSORT:Extensions Of Symmetric Operators}}
[[Category:Functional analysis]]
[[Category:Operator theory]]</text>
      <sha1>k0mod1laz3smui4c3b9l7mjwu205eai</sha1>
    </revision>
  </page>
  <page>
    <title>Frame (linear algebra)</title>
    <ns>0</ns>
    <id>4504771</id>
    <revision>
      <id>861727139</id>
      <parentid>859680091</parentid>
      <timestamp>2018-09-29T15:43:52Z</timestamp>
      <contributor>
        <username>Irancplusplus</username>
        <id>17875629</id>
      </contributor>
      <comment>/* Motivating example: computing a basis from a linearly dependent set */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21019">{{about|a generalization of bases to linearly dependent sets of vectors|a linearly independent set of vectors|k-frame}}

In [[linear algebra]], a '''frame''' of an [[inner product space]] is a generalization of a [[basis of a vector space]] to sets that may be [[linearly dependent]]. In the terminology of [[signal processing]], a frame provides a redundant, stable way of representing a [[signal (electrical engineering)|signal]].{{sfn|Kovačević|Chebira|2008|p=6}} Frames are used in [[error detection and correction]] and the design and analysis of [[filter bank]]s and more generally in [[applied mathematics]], [[computer science]], and [[engineering]].{{sfn|Casazza|Kutyniok|Philipp|2013|p=1}}.

== Definition and motivation ==

=== Motivating example: computing a basis from a linearly dependent set ===
Suppose we have a set of vectors &lt;math&gt;\{\mathbf{e}_k\}&lt;/math&gt; in the vector space ''V'' and we want to express an arbitrary element &lt;math&gt;\mathbf{v} \in V&lt;/math&gt; as a linear combination of the vectors &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt;, that is, we want to find coefficients &lt;math&gt;c_k&lt;/math&gt; such that

:&lt;math&gt; \mathbf{v} = \sum_k c_k \mathbf{e}_k &lt;/math&gt;

If the set &lt;math&gt;\{ \mathbf{e}_{k} \}&lt;/math&gt; does not span &lt;math&gt;V&lt;/math&gt;, then such coefficients do not exist for every such &lt;math&gt;\mathbf{v}&lt;/math&gt;.  If &lt;math&gt;\{ \mathbf{e}_{k} \}&lt;/math&gt; spans &lt;math&gt;V&lt;/math&gt; and also is [[linearly independent]], this set forms a [[Basis (linear algebra)|basis]] of &lt;math&gt;V&lt;/math&gt;, and the coefficients &lt;math&gt;c_{k}&lt;/math&gt; are uniquely determined by &lt;math&gt;\mathbf{v}&lt;/math&gt;.  If, however, &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt; spans &lt;math&gt;V&lt;/math&gt; but is not linearly independent, the question of how to determine the coefficients becomes less apparent, in particular if &lt;math&gt;V&lt;/math&gt; is of infinite dimension.

Given that &lt;math&gt;\{\mathbf{e}_k\}&lt;/math&gt; spans &lt;math&gt;V&lt;/math&gt; and is linearly dependent, one strategy is to remove vectors from the set until it becomes linearly independent and forms a basis.  There are some problems with this plan:

# Removing arbitrary vectors from the set may cause it to be unable to span &lt;math&gt;V&lt;/math&gt; before it becomes linearly independent.
# Even if it is possible to devise a specific way to remove vectors from the set until it becomes a basis, this approach may become unfeasible in practice if the set is large or infinite.
# In some applications, it may be an advantage to use more vectors than necessary to represent &lt;math&gt;\mathbf{v}&lt;/math&gt;.  This means that we want to find the coefficients &lt;math&gt;c_k&lt;/math&gt; without removing elements in &lt;math&gt;\{\mathbf{e}_k\}&lt;/math&gt;. The coefficients &lt;math&gt;c_k&lt;/math&gt; will no longer be uniquely determined by &lt;math&gt;\mathbf{v}&lt;/math&gt;. Therefore, the vector &lt;math&gt;\mathbf{v}&lt;/math&gt; can be represented as a linear combination of &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt; in more than one way.

=== Formal definition ===
Let ''V'' be an [[inner product space]] and &lt;math&gt;\{\mathbf{e}_k\}_{k \in \mathbb{N}}&lt;/math&gt; be a set of vectors in &lt;math&gt;V&lt;/math&gt;. These vectors satisfy the ''frame condition'' if there are positive real numbers ''A'' and ''B'' such that &lt;math&gt; 0&lt;A \le B &lt; \infty &lt;/math&gt; and for each &lt;math&gt;\mathbf{v}&lt;/math&gt; in ''V'',
: &lt;math&gt;A \left\| \mathbf{v} \right\| ^2 \leq \sum_{k \in \mathbb{N}} \left| \langle \mathbf{v}, \mathbf{e}_k \rangle \right| ^2 \leq B \left\| \mathbf{v} \right\| ^2 .&lt;/math&gt;
A set of vectors that satisfies the frame condition is a ''frame'' for the vector space.{{sfn|Casazza|Kutyniok|Philipp|2013|p=14}}

The numbers ''A'' and ''B'' are called the lower and upper ''frame bounds'', respectively.{{sfn|Casazza|Kutyniok|Philipp|2013|p=14}} The frame bounds are not unique because numbers less than ''A'' and greater than ''B'' are also valid frame bounds. The ''optimal lower bound'' is the [[supremum]] of all lower bounds and the ''optimal upper bound'' is the [[infimum]] of all upper bounds.

A frame is called ''overcomplete'' (or ''redundant'') if it is not a [[basis (linear algebra)|basis]] for the vector space.

=== Analysis operator ===
The [[Operator (mathematics)|operator]] mapping &lt;math&gt;\mathbf{v} \in V&lt;/math&gt; to a sequence of coefficients &lt;math&gt;c_k&lt;/math&gt; is called the ''analysis operator'' of the frame. It is defined by:{{sfn|Kovačević|Chebira|2008|p=21}}
: &lt;math&gt; \mathbf{T}: V \mapsto \ell^2, \quad \mathbf{v} \mapsto \{c_k\}_{k \in \mathbb{N}}, \quad c_k = \langle \mathbf{v},\mathbf{e_k}\rangle &lt;/math&gt;
By using this definition we may rewrite the frame condition as
: &lt;math&gt;A \left\| \mathbf{v} \right\| ^2 \leq \left\| \mathbf{T} \mathbf{v} \right\| ^2 \leq B \left\| \mathbf{v} \right\| ^2 &lt;/math&gt;
where the left and right norms denote the norm in &lt;math&gt;V&lt;/math&gt; and the middle norm is the &lt;math&gt;\ell ^2&lt;/math&gt; norm.

=== Synthesis operator ===
The [[Hermitian adjoint|adjoint operator]] &lt;math&gt; \mathbf{T}^*&lt;/math&gt; of the analysis operator is called the ''synthesis operator'' of the frame.{{sfn|Casazza|Kutyniok|Philipp|2013|p=19}} 
: &lt;math&gt; \mathbf{T}^*: \ell^2 \mapsto V, \quad \{c_k\}_{k \in \mathbb{N}} \mapsto \mathbf{v}, \quad \mathbf{v} = \sum_k c_k\mathbf{e_k} &lt;/math&gt;

=== Motivation for the lower frame bound ===
We want that any vector &lt;math&gt; v \in V &lt;/math&gt; can be reconstructed from the coefficients &lt;math&gt; \{ \langle \mathbf{v},\mathbf{e_k}\rangle \}_{k \in \mathbb{N}} &lt;/math&gt;. This is satisfied if there exists a constant &lt;math&gt; A &gt; 0 &lt;/math&gt; such that for all &lt;math&gt; x,y \in V &lt;/math&gt; we have:
:&lt;math&gt; A \| x-y \|^2 \le \| Tx-Ty \|^2 &lt;/math&gt;
By setting &lt;math&gt; v=x-y &lt;/math&gt; and applying the linearity of the analysis operator we get that this condition is equivalent to:
:&lt;math&gt; A \| v \|^2 \le \| Tv \|^2 &lt;/math&gt;
for all &lt;math&gt; v \in V &lt;/math&gt; which is exactly the lower frame bound condition.

== History ==
Because of the various mathematical components surrounding frames, frame theory has roots in [[Harmonic analysis|harmonic and functional analysis]], [[operator theory]], [[linear algebra]], and [[Matrix (mathematics)|matrix theory]].{{sfn|Casazza|Kutyniok|Philipp|2013|p=2}}

The [[Fourier transform]] has been used for over a century as a way of decomposing and expanding signals. However, the Fourier transform masks key information regarding the moment of emission and the duration of a signal.  In 1946, [[Dennis Gabor]] was able to solve this using a technique that simultaneously reduced noise, provided resiliency, and created [[Quantization (signal processing)|quantization]] while encapsulating important signal characteristics.{{sfn|Kovačević|Chebira|2008|p=6}} This discovery marked the first concerted effort towards frame theory.

The frame condition was first described by [[Richard Duffin]] and [[Albert Charles Schaeffer]] in a 1952 article on nonharmonic [[Fourier series]] as a way of computing the coefficients in a linear combination of the vectors of a linearly dependent spanning set (in their terminology, a "[[Hilbert space]] frame").{{sfn|Duffin|Schaeffer|1952}} In the 1980s, [[Stéphane Mallat]], [[Ingrid Daubechies]], and [[Yves Meyer]] used frames to analyze [[wavelets]]. Today frames are associated with wavelets, signal and [[image processing]], and [[data compression]].

== Relation to bases ==

A frame satisfies a generalization of [[Parseval's identity]], namely the frame condition, while still maintaining norm equivalence between a signal and its sequence of coefficients.

If the set &lt;math&gt;\{\mathbf{e}_k\}&lt;/math&gt; is a frame of ''V'', it spans ''V''.  Otherwise there would exist at least one non-zero &lt;math&gt;\mathbf{v} \in V&lt;/math&gt; which would be orthogonal to all &lt;math&gt;\mathbf{e}_k&lt;/math&gt;.  If we insert &lt;math&gt;\mathbf{v}&lt;/math&gt; into the frame condition, we obtain
:&lt;math&gt;
A \left\| \mathbf{v} \right\| ^2 \leq 0 \leq B \left\| \mathbf{v} \right\| ^{2} ;
&lt;/math&gt;
therefore &lt;math&gt;A \leq 0&lt;/math&gt;, which is a violation of the initial assumptions on the lower frame bound.

If a set of vectors spans ''V'', this is not a sufficient condition for calling the set a frame.  As an example, consider &lt;math&gt;V = \mathbb{R}^2&lt;/math&gt; with the [[dot product]], and the infinite set &lt;math&gt;\{\mathbf{e}_k\}&lt;/math&gt; given by

:&lt;math&gt;\left\{ (1,0) , \, (0,1), \, \left(0,\frac{1}{\sqrt{2}}\right) , \, \left(0,\frac{1}{\sqrt{3}}\right), \dotsc \right\}.&lt;/math&gt;

This set spans ''V'' but since &lt;math&gt;\sum_k \left| \langle \mathbf{e}_k , (0,1)\rangle \right| ^2 = 0 + 1 + \frac{1}{2} + \frac{1}{3} +\dotsb = \infty&lt;/math&gt;, we cannot choose a finite upper frame bound ''B''.  Consequently, the set &lt;math&gt;\{\mathbf{e}_k\}&lt;/math&gt; is not a frame.

== Applications ==
In [[signal processing]], each vector is interpreted as a signal. In this interpretation, a vector expressed as a linear combination of the frame vectors is a [[Redundancy (information theory)|redundant]] signal. Using a frame, it is possible to create a simpler, more sparse representation of a signal as compared with a family of elementary signals (that is, representing a signal strictly with a set of linearly independent vectors may not always be the most compact form).{{sfn|Mallat|2009|p=1}} Frames, therefore, provide ''robustness''. Because they provide a way of producing the same vector within a space, signals can be encoded in various ways. This facilitates [[fault tolerance]] and resilience to a loss of signal.  Finally, redundancy can be used to mitigate [[noise (signal processing)|noise]], which is relevant to the restoration, enhancement, and reconstruction of signals.

In signal processing, it is common to assume the vector space is a [[Hilbert space]].

== Special cases {{anchor|Tight frames|Uniform frames|Equiangular frames|Exact frames}} ==

=== Tight frames ===
A frame is a ''tight frame'' if ''A'' = ''B''; in other words, the frame satisfies a generalized version of [[Parseval's identity]]. For example, the union of ''k'' disjoint [[orthonormal basis|orthonormal bases]] of a vector space is a tight frame with ''A'' = ''B'' = ''k''. A tight frame is a ''Parseval frame'' (sometimes called a ''normalized frame'') if ''A'' = ''B'' = 1. Each orthonormal basis is a Parseval frame, but the converse is not always true.

A frame &lt;math&gt;\{\mathbf{e}_k\}_{k \in \mathbb{N}}&lt;/math&gt; for &lt;math&gt;V&lt;/math&gt; is tight with frame bound ''A'' if and only if
: &lt;math&gt; v = \frac{1}{A} \sum_k \langle \mathbf{v},\mathbf{e_k}\rangle \mathbf{e_k} &lt;/math&gt;
for all &lt;math&gt;v \in V&lt;/math&gt;.

=== Equal norm frame ===
A frame is an ''equal norm frame'' (sometimes called a  ''uniform frame'' or a ''normalized frame'') if there is a constant ''c'' such that &lt;math&gt;\|e_i\| = c&lt;/math&gt; for each ''i''. An equal norm frame is a ''unit norm frame'' if ''c'' = 1. A Parseval (or tight) unit norm frame is an orthonormal basis; such a frame satisfies [[Parseval's identity]].

=== Equiangular frames ===
A frame is an ''equiangular frame'' if there is a constant ''c'' such that &lt;math&gt;| \langle e_i, e_j \rangle | = c&lt;/math&gt; for each distinct ''i'' and ''j''.

=== Exact frames ===
A frame is an ''exact frame'' if no proper subset of the frame spans the inner product space. Each basis for an inner product space is an exact frame for the space (so a basis is a special case of a frame).

== Generalizations ==

A ''[[Bessel's inequality|Bessel Sequence]]'' is a set of vectors that satisfies only the upper bound of the frame condition.

=== Continuous Frame ===
Suppose ''H'' is a Hilbert space, X a locally compact space , and &lt;math&gt;\mu&lt;/math&gt; is a locally finite ''[[Borel measure]]'' on X. Then a set of vectors in ''H'', &lt;math&gt;\{f_x\}_{x\in X}&lt;/math&gt; with a measure &lt;math&gt;\mu&lt;/math&gt; is said to be a ''Continuous Frame'' if there exists constants, &lt;math&gt;0&lt;A\leq B&lt;/math&gt; such that &lt;math&gt;A||f||^2\leq \int_{X}|\langle f,f_x\rangle|^2d\mu(x)\leq B||f||^2&lt;/math&gt; for all &lt;math&gt;f\in H&lt;/math&gt;.

====Example====
Given a discrete set &lt;math&gt;\Lambda\subset X&lt;/math&gt; and a measure &lt;math&gt;\mu= \delta_\Lambda&lt;/math&gt; where &lt;math&gt;\delta_\Lambda&lt;/math&gt; is the ''[[Dirac measure]]'' then the continuous frame property:
 &lt;math&gt;A||f||^2\leq \int_{X}|\langle f,f_x\rangle|^2d\mu(x)\leq B||f||^2&lt;/math&gt;
reduces to:
&lt;math&gt;A||f||^2\leq \sum_{\lambda\in \Lambda}|\langle f,f_x\rangle|^2\leq B||f||^2&lt;/math&gt;

and we see that Continuous Frames are indeed the natural generalization of the frames mentioned above.

Just like in the discrete case we can define the Analysis, Synthesis, and Frame operators when dealing with continuous frames.

====Continuous Analysis Operator====
Given a continuous frame &lt;math&gt;\{f_x\}_{x\in X}&lt;/math&gt; the ''Continuous Analysis Operator'' is the operator mapping &lt;math&gt;\{f_x\}_{x\in X}&lt;/math&gt; to a sequence of coefficients &lt;math&gt;\langle f,f_x\rangle _{x\in X}&lt;/math&gt;.

It is defined as follows:

&lt;math&gt;T:H \mapsto L^2(X,\mu)&lt;/math&gt; by &lt;math&gt;f \to \langle f,f_x\rangle _{x\in X}&lt;/math&gt;

====Continuous Synthesis Operator====
The adjoint operator of the Continuous Analysis Operator is the ''Continuous Synthesis Operator'' which is the map:

&lt;math&gt;T^*:L^2(X,\mu) \mapsto H&lt;/math&gt; by &lt;math&gt;a_x \to\int_X a_x f_x d\mu(x)&lt;/math&gt;

====Continuous Frame Operator====
The Composition of the Continuous Analysis Operator and the Continuous Synthesis Operator is known as the ''Continuous Frame Operator''. For a continuous frame &lt;math&gt;\{f_x\}_{x\in X}&lt;/math&gt;, the ''Continuous Frame Operator'' is defined as follows:
&lt;math&gt;S:H\mapsto H&lt;/math&gt; by &lt;math&gt;Sf:=\int_X \langle f,f_x\rangle f_x d\mu(x)&lt;/math&gt;

====Continuous Dual Frame====
Given a continuous frame &lt;math&gt;\{f_x\}_{x\in X}&lt;/math&gt;, and another continuous frame &lt;math&gt;\{g_x\}_{x\in X}&lt;/math&gt;, then &lt;math&gt;\{g_x\}_{x\in X}&lt;/math&gt;  is said to be a ''Continuous Dual Frame'' of &lt;math&gt;\{f_x\}&lt;/math&gt; if it satisfies the following condition for all &lt;math&gt;f, h\in H&lt;/math&gt;:

&lt;math&gt;\langle f, h\rangle =\int_X\langle f,f_x\rangle \langle g_x, h\rangle d\mu(x)&lt;/math&gt;

== Dual frames ==

The frame condition entails the existence of a set of ''dual frame vectors'' &lt;math&gt;\{ \mathbf{\tilde{e}}_{k} \}&lt;/math&gt; with the property that
:&lt;math&gt;
\mathbf{v} = 
\sum_k \langle \mathbf{v} , \mathbf{\tilde{e}}_k \rangle \mathbf{e}_k =
\sum_k \langle \mathbf{v} , \mathbf{e}_k \rangle \mathbf{\tilde{e}}_k
&lt;/math&gt;
for any &lt;math&gt;\mathbf{v} \in V&lt;/math&gt;.  This implies that a frame together with its dual frame has the same property as a basis and its [[dual basis]] in terms of reconstructing a vector from scalar products.

In order to construct a dual frame, we first need the linear mapping &lt;math&gt;\mathbf{S} : V \rightarrow V&lt;/math&gt;, called the '''frame operator''', defined as
: &lt;math&gt;\mathbf{S} \mathbf{v} = \sum_{k} \langle \mathbf{v} , \mathbf{e}_{k} \rangle \mathbf{e}_{k} = \mathbf{T}^*\mathbf{T}\mathbf{v}&lt;/math&gt;.

From this definition of &lt;math&gt;\mathbf{S}&lt;/math&gt; and linearity in the first argument of the inner product,
: &lt;math&gt;\langle \mathbf{S} \mathbf{v} , \mathbf{v} \rangle = \sum_k \left| \langle \mathbf{v} , \mathbf{e}_k \rangle \right| ^2 ,&lt;/math&gt;
which, when substituted in the frame condition inequality, yields
: &lt;math&gt;A \left\| \mathbf{v} \right\| ^2 \leq \langle \mathbf{S} \mathbf{v} , \mathbf{v} \rangle \leq B \left\| \mathbf{v} \right\| ^2 ,&lt;/math&gt;
for each &lt;math&gt;\mathbf{v} \in V&lt;/math&gt;.

The frame operator &lt;math&gt;\mathbf{S}&lt;/math&gt; is [[self-adjoint]], [[positive definite]], and has positive upper and lower bounds. The inverse &lt;math&gt;\mathbf{S}^{-1}&lt;/math&gt; of &lt;math&gt;\mathbf{S}&lt;/math&gt; exists and it, too, is self-adjoint, positive definite, and has positive upper and lower bounds.

The dual frame is defined by mapping each element of the frame with &lt;math&gt;\mathbf{S}^{-1}&lt;/math&gt;:
:&lt;math&gt;
\tilde{\mathbf{e}}_{k} = \mathbf{S}^{-1} \mathbf{e}_{k}
&lt;/math&gt;

To see that this makes sense, let &lt;math&gt;\mathbf{v}&lt;/math&gt; be an element of &lt;math&gt;V&lt;/math&gt; and let
:&lt;math&gt;
\mathbf{u} =
\sum_{k} \langle \mathbf{v} , \mathbf{e}_{k} \rangle \tilde{\mathbf{e}}_{k}
&lt;/math&gt;.

Thus
:&lt;math&gt;
\mathbf{u} =
\sum_{k} \langle \mathbf{v} , \mathbf{e}_{k} \rangle ( \mathbf{S}^{-1} \mathbf{e}_{k} ) = 
\mathbf{S}^{-1} \left ( \sum_{k} \langle \mathbf{v} , \mathbf{e}_{k} \rangle \mathbf{e}_{k} \right ) =
\mathbf{S}^{-1} \mathbf{S} \mathbf{v} = \mathbf{v}
&lt;/math&gt;,

which proves that
:&lt;math&gt;
\mathbf{v} = \sum_{k} \langle \mathbf{v} , \mathbf{e}_{k} \rangle \tilde{\mathbf{e}}_{k}
&lt;/math&gt;.

Alternatively, we can let
:&lt;math&gt;
\mathbf{u} = \sum_{k} \langle \mathbf{v} , \tilde{\mathbf{e}}_{k} \rangle \mathbf{e}_{k}
&lt;/math&gt;.

By inserting the above definition of &lt;math&gt;\tilde{\mathbf{e}}_{k}&lt;/math&gt; and applying the properties of &lt;math&gt;\mathbf{S}&lt;/math&gt; and its inverse,

:&lt;math&gt;
\mathbf{u} =
\sum_{k} \langle \mathbf{v} , \mathbf{S}^{-1} \mathbf{e}_{k} \rangle \mathbf{e}_{k} =
\sum_{k} \langle \mathbf{S}^{-1} \mathbf{v} , \mathbf{e}_{k} \rangle \mathbf{e}_{k} =
\mathbf{S} (\mathbf{S}^{-1} \mathbf{v}) = \mathbf{v}
&lt;/math&gt;

which shows that

:&lt;math&gt;
\mathbf{v} = \sum_{k} \langle \mathbf{v} , \tilde{\mathbf{e}}_{k} \rangle \mathbf{e}_{k}
&lt;/math&gt;.

The numbers &lt;math&gt;\langle \mathbf{v} , \tilde{\mathbf{e}}_{k} \rangle&lt;/math&gt; are called ''frame coefficients''. This derivation of a dual frame is a summary of Section 3 in the article by Duffin and Schaeffer.{{sfn|Duffin|Schaeffer|1952}}  They use the term ''conjugate frame'' for what here is called a dual frame.

The dual frame &lt;math&gt;\{\tilde{\mathbf{e}}_{k}\}&lt;/math&gt; is called the ''canonical dual'' of &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt; because it acts similarly as a [[dual basis]] to a basis.

When the frame &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt; is overcomplete, a vector &lt;math&gt;\mathbf{v}&lt;/math&gt; can be written as a linear combination of &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt; in more than one way. That is, there are different choices of coefficients &lt;math&gt;\{c_{k}\}&lt;/math&gt; such that &lt;math&gt;\mathbf{v} = \sum_{k} c_{k} \mathbf{e}_{k}&lt;/math&gt;. This allows us some freedom for the choice of coefficients &lt;math&gt;\{c_{k}\}&lt;/math&gt; other than &lt;math&gt;\langle \mathbf{v} , \tilde{\mathbf{e}}_{k} \rangle&lt;/math&gt;. It is necessary that the frame &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt; is overcomplete for other such coefficients &lt;math&gt;\{c_{k}\}&lt;/math&gt; to exist. If so, then there exist frames &lt;math&gt;\{\mathbf{g}_{k}\} \neq \{\tilde{\mathbf{e}}_{k}\}&lt;/math&gt; for which 
:&lt;math&gt;
\mathbf{v} = \sum_{k} \langle \mathbf{v} , \mathbf{g}_{k} \rangle \mathbf{e}_{k}
&lt;/math&gt;
for all &lt;math&gt;\mathbf{v} \in V&lt;/math&gt;. We call &lt;math&gt;\{\mathbf{g}_{k}\}&lt;/math&gt; a dual frame of &lt;math&gt;\{\mathbf{e}_{k}\}&lt;/math&gt;.

Canonical duality is a reciprocity relation, i.e. if the frame &lt;math&gt;\{ \mathbf{\tilde{e}}_{k} \}&lt;/math&gt; is the canonical dual frame of &lt;math&gt;\{ \mathbf{e}_{k} \}&lt;/math&gt;, then &lt;math&gt;\{ \mathbf{e}_{k} \}&lt;/math&gt; is the canonical dual frame of &lt;math&gt;\{ \mathbf{\tilde{e}}_{k} \}&lt;/math&gt;.

== See also ==
* [[k-frame|''k''-frame]]
* [[Biorthogonal wavelet]]
* [[Orthogonal wavelet]]
* [[Restricted isometry property]]
* [[Schauder basis]] 
* [[Harmonic analysis]]
* [[Fourier analysis]]
* [[Functional analysis]]

== Notes ==
{{Reflist}}

== References ==
* {{cite encyclopedia | title=Introduction to Finite Frame Theory | last1=Casazza | first1=Peter | author1link=Peter G. Casazza | last2=Kutyniok | first2=Gitta | last3=Philipp | first3=Friedrich | encyclopedia=Finite Frames | pages=1–53 | date=2013 | publisher=Springer | ref=harv}}
* {{cite book | last1=Casazza | first1=Peter | author1link=Peter G. Casazza | last2=Kutyniok | first2=Gitta | last3=Philipp | first3=Friedrich | title=Finite Frames: Theory and Applications | date=2013 | publisher=Birkhäuser | location=Berlin | isbn=978-0-8176-8372-6 | ref=harv}}
* {{cite book | last=Christensen | first=Ole | title=An Introduction to Frames and Riesz Bases | year=2003 | publisher=Birkhäuser | series=Applied  and Numerical Harmonic Analysis | mr=1946982 | doi=10.1007/978-0-8176-8224-8 | ref=harv}}
* {{cite journal | last1=Duffin | first1=Richard James | author1link = Richard Duffin | last2=Schaeffer | first2=Albert Charles | author2link=Albert Charles Schaeffer | title=A class of nonharmonic Fourier series | year=1952 | journal=[[Trans. Amer. Math. Soc.]] | volume=72 | pages=341–366 | doi=10.2307/1990760 | jstor=1990760 | issue=2 | mr=0047179 | ref=harv}}
* {{cite journal|last1=Kovačević|first1=Jelena|last2=Chebira|first2=Amina|title=An Introduction to Frames|journal=Foundations and Trends|date=2008|volume=2|issue=1|pages=1–94|doi=10.1561/2000000006|ref=harv}}&lt;!--|accessdate=1 December 2014--&gt;
* {{cite journal | last1=Kovacevic | first1=Jelena | last2=Dragotti | first2=Pier Luigi | last3=Goyal | first3=Vivek | title=Filter Bank Frame Expansions with Erasures | year=2002 | journal=IEEE Trans. Inf. Theory | volume=48 | issue=6 | pages=1439–1450 | url=http://citeseer.ist.psu.edu/cache/papers/cs/28168/http:zSzzSzlcavwww.epfl.chzSz~dragottizSzpublicationszSzIT_june02.pdf/kovacevic02filter.pdf
| doi=10.1109/TIT.2002.1003832 | ref=harv}}
* {{cite journal | last=Mallat | first=Stéphane | authorlink=Stéphane Mallat | title=A Wavelet Tour of Signal Processing | date=9 October 2008 | ref=harv}}

{{DEFAULTSORT:Frame Of A Vector Space}}
[[Category:Linear algebra]]
[[Category:Differential geometry]]
[[Category:Signal processing]]</text>
      <sha1>0y1h4j17jkdp6g626pzw8vtw5zvyutv</sha1>
    </revision>
  </page>
  <page>
    <title>Fritz Carlson</title>
    <ns>0</ns>
    <id>5094208</id>
    <revision>
      <id>783556195</id>
      <parentid>707659472</parentid>
      <timestamp>2017-06-03T02:34:18Z</timestamp>
      <contributor>
        <username>MainlyTwelve</username>
        <id>1487243</id>
      </contributor>
      <comment>[[Category:20th-century Swedish mathematicians]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2027">{{Infobox scientist
| name              = Fritz Carlson
| image             = &lt;!--(filename only)--&gt;
| image_size        = 
| caption           = 
| birth_date        = {{birth date|1888|7|23|df=y}}
| birth_place       = [[Vimmerby]], [[Sweden]]
| death_date        = {{death date and age|1952|11|28|1888|7|23|df=y}}
| death_place       = [[Stockholm]], Sweden
| nationality       = [[Sweden]]
| fields            = [[Mathematics]]
| workplaces        = [[University of Stockholm]]
| alma_mater        = [[Uppsala University]]
| doctoral_advisor  = [[Anders Wiman]]
| doctoral_students = [[Germund Dahlquist]]&lt;br&gt;[[Tord Ganelius]]&lt;br&gt;[[Hans Rådström]]
| known_for         = 
| awards            = 
}}
'''Fritz David Carlson''' (23 July 1888 &amp;ndash; 28 November 1952) was a [[Swedish people|Swedish]] [[mathematician]].&lt;ref&gt;{{cite journal|mr=0057791|last=Frostman|first=Otto|author-link=Otto Frostman|title=Fritz Carlson in memoriam|journal= Acta Math.|volume=90|year=1953|pages=ix–xii|doi=10.1007/bf02392434}}&lt;/ref&gt; After the death of [[Torsten Carleman]], he headed the [[Mittag-Leffler Institute]].

Carlson's contributions to [[mathematical analysis|analysis]] include [[Carlson's theorem]], the Polyá–Carlson theorem on rational functions, and Carlson's inequality

: &lt;math&gt; \left( \sum_{n=1}^\infty |a_n|\right)^4 \leq \pi^2  \sum_{n=1}^\infty |a_n|^2 \, \sum_{n=1}^\infty n^2 |a_n|^2~.&lt;/math&gt;

In [[number theory]], his results include Carlson's theorem on [[Dirichlet series]].

[[Hans Rådström]], [[Germund Dahlquist]], and [[Tord Ganelius]] were among his students.

==Notes==
{{Reflist}}

==External links==
*{{MathGenealogy |id=20645 }}

{{Authority control}}

{{DEFAULTSORT:Carlson, Fritz David}}
[[Category:1888 births]]
[[Category:1952 deaths]]
[[Category:Swedish mathematicians]]
[[Category:20th-century Swedish mathematicians]]
[[Category:Royal Institute of Technology academics]]
[[Category:Mathematical analysts]]
[[Category:Directors of the Mittag-Leffler Institute]]


{{Sweden-mathematician-stub}}</text>
      <sha1>egpsdo7l84lhqtwmsugqeuxylrm0pby</sha1>
    </revision>
  </page>
  <page>
    <title>Global analysis</title>
    <ns>0</ns>
    <id>42027498</id>
    <revision>
      <id>800970618</id>
      <parentid>787016171</parentid>
      <timestamp>2017-09-16T21:36:43Z</timestamp>
      <contributor>
        <ip>62.98.244.119</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2550">In [[mathematics]], '''global analysis''', also called '''analysis on manifolds''', is the study of the global and topological properties of [[differential equation]]s on [[manifold (mathematics)|manifold]]s and [[Vector bundle|vector bundle]]s.&lt;ref name=Smale1969&gt;{{cite journal|last=Smale|first=S.|title=What is Global Analysis|journal=American Mathematical Monthly|date=January 1969|volume=76|issue=1|pages=4–9|doi=10.2307/2316777}}&lt;/ref&gt;&lt;ref name=Palais1968&gt;{{cite book|last=Richard S. Palais|title=Foundations of Global Non-Linear Analysis|url=http://vmm.math.uci.edu/PalaisPapers/FoundationsOfGlobalNonlinearAnalysis.pdf|date=1968|publisher=W.A. Benjamin, Inc.}}&lt;/ref&gt;  Global analysis uses techniques in infinite-dimensional manifold theory and topological spaces of mappings to classify behaviors of differential equations, particularly nonlinear differential equations.&lt;ref name=Kriegl1991&gt;{{cite book|last=Andreas Kriegl and Peter W. Michor|title=The Convenient  Setting of  Global Analysis|url=http://www.mat.univie.ac.at/~michor/apbookh-ams.pdf|date=1991|publisher=American Mathematical Society|isbn=0-8218-0780-3|pages=1–7}}&lt;/ref&gt; These spaces can include [[Singularity (mathematics)|singularities]] and hence [[catastrophe theory]] is a part of global analysis. [[Optimization problem]]s, such as finding [[geodesic]]s on [[Riemannian manifold]]s, can be solved using differential equations so that the [[calculus of variations]] overlaps with global analysis. Global analysis finds application in [[physics]] in the study of [[dynamical systems]]&lt;ref name=Marsden1974&gt;{{cite book|last=Marsden|first=Jerrold E.|title=Applications of global analysis in mathematical physics|date=1974|publisher=Publish or Perish, Inc.|location=Berkeley, CA.|isbn=0-914098-11-X|page=Chapter 2|url=http://authors.library.caltech.edu/25041/}}&lt;/ref&gt; and [[topological quantum field theory]].

== Journals ==

* [[Annals of Global Analysis and Geometry]]
* [[The Journal of Geometric Analysis]]

== See also ==

* [[Atiyah–Singer index theorem]]
* [[Geometric analysis]]
* [[Lie groupoid]]
* [[Pseudogroup]]
* [[Morse theory]]
* [[Structural stability]]
* [[Harmonic map]]

==References==
{{reflist}}

== Further reading ==
{{Sister project links| wikt=no | commons=no | b=no | n=no | q=Global analysis | s=no | v=no | voy=no | species=no | d=no}}

* [http://www.math.ucsb.edu/~moore/globalanalysisshort.pdf Mathematics 241A: Introduction to Global Analysis]

[[Category:Mathematical analysis]]
[[Category:Manifolds]]
[[Category:Differential equations]]</text>
      <sha1>ckdq27nz27zvyl80a73nizo4lsebebi</sha1>
    </revision>
  </page>
  <page>
    <title>Herbrand's theorem</title>
    <ns>0</ns>
    <id>2518328</id>
    <revision>
      <id>862709329</id>
      <parentid>852550480</parentid>
      <timestamp>2018-10-06T05:20:14Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5037">{{distinguish|Herbrand–Ribet theorem|Ramification_group#Ramification_groups_in_upper_numbering{{!}}Herbrand's theorem on ramification groups}}
'''Herbrand's theorem''' is a fundamental result of [[mathematical logic]] obtained by [[Jacques Herbrand]] (1930).&lt;ref&gt;J. Herbrand: Recherches sur la théorie de la démonstration. ''Travaux de la société des Sciences et des Lettres de Varsovie'', Class III, Sciences Mathématiques et Physiques, 33, 1930.&lt;/ref&gt; It essentially allows a certain kind of reduction of [[first-order logic]] to [[propositional logic]]. Although Herbrand originally proved his theorem for arbitrary formulas of first-order logic,&lt;ref&gt;Samuel R. Buss: "Handbook of Proof Theory". Chapter 1, "An Introduction to Proof Theory". Elsevier, 1998.&lt;/ref&gt; the simpler version shown here, restricted to formulas in [[prenex form]] containing only existential quantifiers, became more popular.

Let 
:&lt;math&gt;(\exists y_1,\ldots,y_n)F(y_1,\ldots,y_n)&lt;/math&gt;

be a formula of first-order logic with &lt;math&gt;F(y_1,\ldots,y_n)&lt;/math&gt; quantifier-free. Then that formula is valid if and only if there exists a finite sequence of terms &lt;math&gt;t_{ij}&lt;/math&gt;, possibly in an expansion of the language, with 
:&lt;math&gt;1 \le i \le k&lt;/math&gt; and &lt;math&gt;1 \le j \le n&lt;/math&gt;,

such that 
:&lt;math&gt;F(t_{11},\ldots,t_{1n}) \vee \ldots \vee F(t_{k1},\ldots,t_{kn})&lt;/math&gt;

is valid. If it is valid, it is called a ''Herbrand disjunction'' for 
:&lt;math&gt;(\exists y_1,\ldots,y_n)F(y_1,\ldots,y_n).&lt;/math&gt;

Informally: a formula &lt;math&gt;A&lt;/math&gt; in [[prenex form]] containing only existential quantifiers is provable (valid) in first-order logic if and only if a disjunction composed of [[substitution instance]]s of the quantifier-free subformula of &lt;math&gt;A&lt;/math&gt; is a [[tautology (logic)|tautology]] (propositionally derivable).

The restriction to formulas in prenex form containing only existential quantifiers does not limit the generality of the theorem, because formulas can be converted to prenex form and their universal quantifiers can be removed by [[Herbrandization]]. Conversion to prenex form can be avoided, if ''structural'' Herbrandization is performed. Herbrandization can be avoided by imposing additional restrictions on the variable dependencies allowed in the Herbrand disjunction.

==Proof sketch==
A proof of the non-trivial direction of the theorem can be constructed according to the following steps:

# If the formula &lt;math&gt;(\exists y_1,\ldots,y_n)F(y_1,\ldots,y_n)&lt;/math&gt; is valid, then by completeness of cut-free [[sequent calculus]], which follows from [[Gentzen]]'s [[cut-elimination]] theorem, there is a cut-free proof of &lt;math&gt;\vdash (\exists y_1,\ldots,y_n)F(y_1,\ldots,y_n)&lt;/math&gt;.
# Starting from above downwards, remove the inferences that introduce existential quantifiers.
# Remove contraction-inferences on previously existentially quantified formulas, since the formulas (now with terms substituted for previously quantified variables) might not be identical anymore after the removal of the quantifier inferences.
# The removal of contractions accumulates all the relevant substitution instances of &lt;math&gt;F(y_1,\ldots,y_n)&lt;/math&gt; in the right side of the sequent, thus resulting in a proof of &lt;math&gt;\vdash F(t_{11},\ldots,t_{1n}), \ldots, F(t_{k1},\ldots,t_{kn})&lt;/math&gt;, from which the Herbrand disjunction can be obtained.

However, [[sequent calculus]] and [[cut-elimination]] were not known at the time of Herbrand's theorem, and Herbrand had to prove his theorem in a more complicated way.

==Generalizations of Herbrand's theorem==
* Herbrand's theorem has been extended to [[higher-order logic]] by using [[expansion-tree proof]]s.&lt;ref&gt;Dale Miller: A Compact Representation of Proofs. ''Studia Logica'', 46(4), pp. 347--370, 1987.&lt;/ref&gt; The deep representation of [[expansion-tree proofs]] corresponds to a Herbrand disjunction, when restricted to first-order logic.
* Herbrand disjunctions and expansion-tree proofs have been extended with a notion of cut. Due to the complexity of cut-elimination, Herbrand disjunctions with cuts can be non-elementarily smaller than a standard Herbrand disjunction.
* Herbrand disjunctions have been generalized to Herbrand sequents, allowing Herbrand's theorem to be stated for sequents: "a Skolemized sequent is derivable iff it has a Herbrand sequent".

==See also==
* [[Herbrand structure]]
* [[Herbrand interpretation]] 
* [[Herbrand universe]]
* [[Compactness theorem]]

==Notes==
{{reflist}}

==References==
* {{Citation | last1=Buss | first1=Samuel R. | editor1-last=Maurice | editor1-first=Daniel | editor2-last=Leivant | editor2-first=Raphaël | title=Logic and Computational Complexity | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Computer Science | isbn=978-3-540-60178-4 | year=1995 | chapter=On Herbrand's Theorem | chapterurl=http://math.ucsd.edu/~sbuss/ResearchWeb/herbrandtheorem/ | pages=195–209}}.

[[Category:Proof theory]]
[[Category:Theorems in the foundations of mathematics]]
[[Category:Metatheorems]]</text>
      <sha1>3oqrkyntqn43jy1z5y9vjpvfqjy5vph</sha1>
    </revision>
  </page>
  <page>
    <title>Irreducible representation</title>
    <ns>0</ns>
    <id>385982</id>
    <revision>
      <id>870689875</id>
      <parentid>869047621</parentid>
      <timestamp>2018-11-26T12:28:06Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: url, isbn, title. Add: title-link, isbn, issue. Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17267">{{Group theory sidebar}}

In [[mathematics]], specifically in the [[representation theory]] of [[group (mathematics)|group]]s and [[algebra over a field|algebras]], an '''irreducible representation''' &lt;math&gt;(\rho, V)&lt;/math&gt; or '''irrep''' of an algebraic structure &lt;math&gt;A&lt;/math&gt; is a nonzero representation that has no proper subrepresentation &lt;math&gt;(\rho|_W,W), W \subset V&lt;/math&gt; closed under the action of &lt;math&gt;\{ \rho(a) : a\in A \}&lt;/math&gt;.

Every finite-dimensional [[unitary representation]] on a [[Hermitian]]{{clarify|pre-text=[[Sesquilinear form]] or|date=July 2016}} vector space &lt;math&gt;V&lt;/math&gt; is the [[direct sum]] of irreducible representations. As irreducible representations are always '''indecomposable''' (i.e. cannot be decomposed further into a direct sum of representations), these terms are often confused; however, in general there are many reducible but indecomposable representations, such as the two-dimensional representation of the real numbers acting by upper triangular unipotent matrices.

==History==

Group representation theory was generalized by [[Richard Brauer]] from the 1940s to give [[modular representation theory]], in which the matrix operators act on a vector space over a [[field (mathematics)|field]] &lt;math&gt;K&lt;/math&gt; of arbitrary [[characteristic (algebra)|characteristic]], rather than a vector space over the field of [[real number]]s or over the field of [[complex number]]s.  The structure analogous to an irreducible representation in the resulting theory is a [[simple module]].{{citation needed|date=July 2013}}

==Overview==

{{details|Group representation}}

Let &lt;math&gt;\rho&lt;/math&gt; be a representation i.e. a [[homomorphism]] &lt;math&gt;\rho: G\to GL(V)&lt;/math&gt; of a group &lt;math&gt;G&lt;/math&gt; where &lt;math&gt;V&lt;/math&gt; is a [[vector space]] over a [[field (mathematics)|field]] &lt;math&gt;F&lt;/math&gt;. If we pick a basis &lt;math&gt;B&lt;/math&gt; for &lt;math&gt;V&lt;/math&gt;, &lt;math&gt;\rho&lt;/math&gt; can be thought of as a function (a homomorphism) from a group into a set of invertible matrices and in this context is called a '''matrix representation'''. However, it simplifies things greatly if we think of the space &lt;math&gt;V&lt;/math&gt; without a basis.

A [[linear subspace]] &lt;math&gt;W\subset V&lt;/math&gt; is called '''&lt;math&gt;G&lt;/math&gt;-invariant''' if &lt;math&gt;\rho(g)w\in W&lt;/math&gt; for all &lt;math&gt;g\in G&lt;/math&gt; and all &lt;math&gt; w\in W&lt;/math&gt;. The [[Restriction (mathematics)|restriction]] of &lt;math&gt;\rho&lt;/math&gt; to a &lt;math&gt;G&lt;/math&gt;-invariant subspace &lt;math&gt;W\subset V&lt;/math&gt; is known as a '''subrepresentation'''. A representation &lt;math&gt;\rho: G\to GL(V)&lt;/math&gt; is said to be '''irreducible''' if it has only [[trivial (mathematics)|trivial]] subrepresentations (all representations can form a subrepresentation with the trivial &lt;math&gt;G&lt;/math&gt;-invariant subspaces, e.g. the whole vector space &lt;math&gt;V&lt;/math&gt;, and [[zero vector space|{0}]]). If there is a proper non-trivial invariant subspace, &lt;math&gt;\rho&lt;/math&gt; is said to be '''reducible'''.

===Notation and terminology of group representations===

Group elements can be represented by [[matrix (mathematics)|matrices]], although the term "represented" has a specific and precise meaning in this context. A representation of a group is a mapping from the group elements to the [[general linear group]] of matrices. As notation, let {{math|''a'', ''b'', ''c''...}} denote elements of a group {{math|''G''}} with group product signified without any symbol, so {{math|''ab''}} is the group product of {{math|''a''}} and {{math|''b''}} and is also an element of {{math|''G''}}, and let representations be indicated by {{math|''D''}}. The '''representation of ''a''''' is written

:&lt;math&gt;D(a) = \begin{pmatrix}
D(a)_{11} &amp; D(a)_{12} &amp; \cdots &amp; D(a)_{1n} \\
D(a)_{21} &amp; D(a)_{22} &amp; \cdots &amp; D(a)_{2n} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
D(a)_{n1} &amp; D(a)_{n2} &amp; \cdots &amp; D(a)_{nn} \\
\end{pmatrix}&lt;/math&gt;

By definition of group representations, the representation of a group product is translated into [[matrix multiplication]] of the representations:

:&lt;math&gt;D(ab) = D(a)D(b) &lt;/math&gt;

If {{math|''e''}} is the [[identity element]] of the group (so that {{math|''ae'' {{=}} ''ea'' {{=}} ''a''}}, etc.), then {{math|''D''(''e'')}} is an [[identity matrix]], or identically a block matrix of identity matrices, since we must have

:&lt;math&gt;D(ea) = D(ae) = D(a)D(e) = D(e)D(a) = D(a) &lt;/math&gt;

and similarly for all other group elements. The last two staments correspond to the requirement that {{math|''D''}} is a [[group homomorphism]].

===Decomposable and Indecomposable representations===

A representation is decomposable if a [[Matrix similarity|similar matrix]] {{math|''P''}} can be found for the [[matrix similarity|similarity transformation]]:&lt;ref name="Wigner p 73"&gt;{{cite book| author=E.P. Wigner|title=Group theory and its application to the quantum mechanics of atomic spectra|year=1959|series=Pure and applied physics|page=73|publisher=Academic press|isbn=}}&lt;/ref&gt;

:&lt;math&gt; D'(a) \equiv P^{-1} D(a) P&lt;/math&gt;

which [[matrix diagonalization|diagonalizes]] every matrix in the representation into the same pattern of [[diagonal matrix|diagonal]] [[block matrix|block]]s&amp;nbsp;– each of the blocks are representation of the group independent of each other. The representations {{math|''D''(''a'')}} and {{math|''D'''(''a'')}} are said to be '''equivalent representations'''.&lt;ref&gt;{{cite book|author= W.K. Tung|title=Group Theory in Physics|page=32|publisher=World Scientific|year=1985|url=https://books.google.com/?id=O89tgpOBO04C&amp;printsec=frontcover&amp;dq=group+theory+in+physics#v=onepage&amp;q=group%20theory%20in%20physics&amp;f=false|isbn=978-997-1966-560}}&lt;/ref&gt; The representation can be decomposed into a [[direct sum of matrices|direct sum of ''k'' matrices]]:

:&lt;math&gt; D'(a) = P^{-1} D(a) P = \begin{pmatrix} 
D^{(1)}(a) &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; D^{(2)}(a) &amp; \cdots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \cdots &amp; D^{(k)}(a) \\
\end{pmatrix} = D^{(1)}(a) \oplus D^{(2)}(a) \oplus \cdots \oplus D^{(k)}(a) &lt;/math&gt;

so {{math|''D''(''a'')}} is '''decomposable''', and it is customary to label the decomposed matrices by a superscript in brackets, as in {{math|''D''&lt;sup&gt;(''n'')&lt;/sup&gt;(''a'')}} for {{math|''n'' {{=}} 1, 2, ..., ''k''}}, although some authors just write the numerical label without parantheses.

The dimension of {{math|''D''(''a'')}} is the sum of the dimensions of the blocks:

:&lt;math&gt; \mathrm{dim}[D(a)] = \mathrm{dim}[D^{(1)}(a)] + \mathrm{dim}[D^{(2)}(a)] + \ldots + \mathrm{dim}[D^{(k)}(a)] &lt;/math&gt;

If this is not possible, i.e. {{math|''k''{{=}}1}}, then the representation is indecomposable.&lt;ref name="Wigner p 73"/&gt;&lt;ref name="Tung 33"&gt;{{cite book|author= W.K. Tung|title=Group Theory in Physics
|page=33|publisher=World Scientific|year=1985|url=https://books.google.com/?id=O89tgpOBO04C&amp;printsec=frontcover&amp;dq=group+theory+in+physics#v=onepage&amp;q=group%20theory%20in%20physics&amp;f=false|isbn=978-997-1966-560}}&lt;/ref&gt;

==Examples of Irreducible Representations==

===Trivial Representation===
All groups &lt;math&gt;G&lt;/math&gt; have a one-dimensional, irreducible trivial representation. More generally, any one-dimensional representation is irreducible by virtue of having no proper nontrivial subspaces.

===Irreducible Complex Representations===

The irreducible complex representations of a finite group G can be characterized using results from [[character theory]]. In particular, all such representations decompose as a direct sum of irreps, and the number of irreps of &lt;math&gt;G&lt;/math&gt; is equal to the number of conjugacy classes of &lt;math&gt;G&lt;/math&gt;.&lt;ref name="Serre"&gt;{{cite book| authorlink=Jean-Pierre Serre| first=Jean-Pierre| last= Serre| title=Linear Representations of Finite Groups | publisher=Springer-Verlag | year=1977 | isbn=978-0387901909}}&lt;/ref&gt;
* The irreducible complex representations of &lt;math&gt;\mathbb{Z}/n\mathbb{Z}&lt;/math&gt; are exactly given by the maps &lt;math&gt;1 \mapsto \gamma&lt;/math&gt;, where &lt;math&gt;\gamma&lt;/math&gt; is an &lt;math&gt;n&lt;/math&gt;th [[root of unity]].
* Let &lt;math&gt;V&lt;/math&gt; be an &lt;math&gt;n&lt;/math&gt;-dimensional complex representation of &lt;math&gt;S_n&lt;/math&gt; with basis &lt;math&gt;\{v_i\}^n_{i=1}&lt;/math&gt;. Then &lt;math&gt;V&lt;/math&gt; decomposes as a direct sum of the irreps &lt;math&gt;V_{triv} = \mathbb{C}( \sum^n_{i=1} v_i)&lt;/math&gt; and the orthogonal subspace given by:
::&lt;math&gt;V_{std} = \{ \sum^n_{i=1} a_i v_i : a_i \in \mathbb{C},  \sum^n_{i=1} a_i = 0 \}&lt;/math&gt;
:The former irrep is one-dimensional and isomorphic to the trivial representation of &lt;math&gt;S_n&lt;/math&gt;. The latter is &lt;math&gt;n-1&lt;/math&gt; dimensional and is known as the standard representation of &lt;math&gt;S_n&lt;/math&gt;.&lt;ref name="Serre"/&gt;
* Let &lt;math&gt;G&lt;/math&gt; be a group. The [[regular representation]] of &lt;math&gt;G&lt;/math&gt; is the free complex vector space on the basis &lt;math&gt;\{e_g\}_{g \in G}&lt;/math&gt; with the group action &lt;math&gt;g \cdot e_{g'} = e_{gg'}&lt;/math&gt;, denoted &lt;math&gt;\mathbb{C}G&lt;/math&gt;. All irreducible representations of &lt;math&gt;G&lt;/math&gt; appear in the decomposition of &lt;math&gt;\mathbb{C}G&lt;/math&gt; as a direct sum of irreps.

==Applications in theoretical physics and chemistry==

{{see also|Symmetry in quantum mechanics|Jahn–Teller effect}}

In [[quantum physics]] and [[quantum chemistry]], each set of [[Degenerate energy levels|degenerate eigenstates]] of the [[Hamiltonian operator]] comprises a vector space {{mvar|V}} for a representation of the symmetry group of the Hamiltonian, a "multiplet", best studied through reduction to its irreducible parts.  Identifying the irreducible representations therefore allows one to label the states, predict how they will [[energy level splitting|split]] under perturbations;  or transition to other states in {{mvar|V}}. Thus, in quantum mechanics, irreducible representations of the symmetry group of the system partially or completely label the energy levels of the system, allowing the [[selection rule]]s to be determined.&lt;ref&gt;{{cite web|publisher=Oxford Dictionary of Chemistry|title=A Dictionary of Chemistry, Answers.com|edition=6th|url=http://www.answers.com/topic/irreducible-representation}}&lt;/ref&gt;

== Lie groups ==

{{main|Representation theory of Lie groups}}

===Lorentz group===

{{main|Representation theory of the Lorentz group}}

The irreps of {{math|''D''('''K''')}} and {{math|''D''('''J''')}}, where {{math|'''J'''}} is the generator of rotations and {{math|'''K'''}} the generator of boosts, can be used to build to spin representations of the Lorentz group, because they are related to the spin matrices of quantum mechanics. This allows them to derive [[relativistic wave equation]]s.&lt;ref&gt;{{cite journal
 |author1=T. Jaroszewicz |author2=P.S Kurzepa | year = 1992
 | title = Geometry of spacetime propagation of spinning particles
 | journal = Annals of Physics
 | doi = 10.1016/0003-4916(92)90176-M 
 | url = http://www.sciencedirect.com/science/article/pii/000349169290176M
 | volume=216
 |issue=2 | pages=226–267
| bibcode=1992AnPhy.216..226J}}&lt;/ref&gt;

==See also==

===Associative algebras===

*[[Simple module]]
*[[Indecomposable module]]
*[[Representation of an associative algebra]]

===Lie groups===

* [[Representation theory of Lie algebras]]
* [[Representation theory of SU(2)]] 
* [[Representation theory of SL2(R)]] 
* [[Representation theory of the Galilean group]]
* [[Representation theory of diffeomorphism groups]]
* [[Representation theory of the Poincaré group]]
* [[Theorem of the highest weight]]

==References==

{{reflist}}

===Books===

*{{cite book|author=[[Hermann Weyl|H. Weyl]]|title=The theory of groups and quantum mechanics|page=203|publisher=Courier Dover Publications|year=1950|url=https://books.google.com/?id=jQbEcDDqGb8C&amp;pg=PA203&amp;dq=magnetic+moments+in+relativistic+quantum+mechanics#v=onepage&amp;q=magnetic%20moments%20in%20relativistic%20quantum%20mechanics&amp;f=false|isbn=9780486602691}}
*{{cite book|author1=A. D. Boardman |author2=D. E. O'Conner |author3=P. A. Young |title=Symmetry and its applications in science|page=|publisher=McGraw Hill|year=1973|isbn=978-0-07-084011-9}}
*{{cite book|author=V. Heine|title=Group theory in quantum mechanics: an introduction to its present usage|page=|publisher=Dover|year=2007 |url=https://archive.org/details/GroupTheoryInQuantumMechanics|isbn=978-0-07-084011-9}}
*{{cite book|author=V. Heine|title=Group Theory in Quantum Mechanics: An Introduction to Its Present Usage
|page=|publisher=Courier Dover Publications|year=1993|url=https://books.google.com/?id=NayFD34uEu0C&amp;pg=PA363&amp;dq=lorentz+group+in+relativistic+quantum+mechanics#v=onepage&amp;q=lorentz%20group%20in%20relativistic%20quantum%20mechanics&amp;f=false|isbn=978-048-6675-855}}

*{{cite book|title=Quantum Mechanics|author=E. Abers|publisher=Addison Wesley|year=2004|page=425|isbn=978-0-13-146100-0}}
*{{cite book| author=B. R. Martin, G.Shaw|title=Particle Physics|edition=3rd|publisher=Manchester Physics Series, John Wiley &amp; Sons|pages=3|isbn=978-0-470-03294-7}}
*{{citation
 |last = Weinberg
 |first = S
 |year = 1995 
 |title = The Quantum Theory of Fields
 |pages=230–231
 |volume = 1
 |publisher=Cambridge university press
 |isbn = 978-0-521-55001-7
}}
*{{citation
 | last = Weinberg
 | first = S
 | year = 1996
 | title = The Quantum Theory of Fields
 | volume = 2
 |publisher=Cambridge university press
 |isbn = 978-0-521-55002-4
}}
*{{citation
 | last = Weinberg
 | first = S
 | year = 2000
 | title = The Quantum Theory of Fields
 | volume = 3
 |publisher=Cambridge university press
 |isbn = 978-0-521-66000-6
}}
*{{cite book |author=R. Penrose| title=The Road to Reality| publisher= Vintage books|page=| year=2007 | isbn=978-0-679-77631-4| title-link=The Road to Reality}}
*{{cite book|title=Molecular Quantum Mechanics (Parts 1 and 2): An introduction to quantum chemistry|volume=1|pages=125–126|author=P. W. Atkins|publisher=Oxford University Press|year=1970|isbn=978-0-19-855129-4}}

===Papers===

*{{cite journal|author1=Bargmann, V.|author2=Wigner, E. P.|title=Group theoretical discussion of relativistic wave equations|year=1948|journal=Proc. Natl. Acad. Sci. U.S.A.|volume=34|pages=211–23|url=http://www.pnas.org/cgi/content/citation/34/5/211|issue=5|bibcode = 1948PNAS...34..211B |doi = 10.1073/pnas.34.5.211|pmid=16578292|pmc=1079095}}
*{{cite journal
 | author = E. Wigner
 | year = 1937
 | title = On Unitary Representations Of The Inhomogeneous Lorentz Group
 | journal = Annals of Mathematics
 | volume = 40
 | number = 1
 | page = 149
 | doi=10.2307/1968551 | bibcode= 1989NuPhS...6....9W | jstor=1968551
 | url = http://courses.theophys.kth.se/SI2390/wigner_1939.pdf
}}

==Further reading==

*{{cite web|last=Artin|first=Michael|title=Noncommutative Rings|url=http://math.mit.edu/~etingof/artinnotes.pdf|year=1999|location=Chapter V}}

==External links==
*{{cite web| url=http://www.crystallography.fr/mathcryst/pdf/nancy2010/Aroyo_reps2010.pdf
  |year=2010 | title=Commission on Mathematical and Theoretical Crystallography, Summer Schools on Mathematical Crystallography}}
* {{cite web|first1=Eef|last1=van Beveren|year=2012| url=http://cft.fis.uc.pt/eef/evbgroups.pdf
   |title=Some notes on group theory}}
* {{cite web| url=http://math.berkeley.edu/~teleman/math/RepThry.pdf | first1=Constantin
   |last1=Teleman | title=Representation Theory | year =2005}}
* {{cite web |url=http://panda.unm.edu/Courses/Finley/p467/handouts/YoungTableauxSubs.pdf |title=Some Notes on Young Tableaux as useful for irreps of su(n) |last1=Finley }}{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}
* {{cite web|url=http://www.huntresearchgroup.org.uk/teaching/teaching_MOs_year2/L2_Addn_Symm_Labels.pdf
   |title=Irreducible Representation (IR) Symmetry Labels |last1=Hunt |year=2008}}
* {{cite web|url=http://www.physics.indiana.edu/~dermisek/QFT_08/qft-I-14-4p.pdf
   |title=Representations of Lorentz Group | year=2008| first1=Radovan | last1=Dermisek}}
* {{cite web|url=http://einrichtungen.ph.tum.de/T30f/lec/QFT/groups.pdf
   |title=Representations of Lorentz and Poincaré groups|first1=Joseph |last1=Maciejko |year=2007}}
* {{cite web|url=http://www.math.columbia.edu/~woit/QM/qmbook.pdf 
  |first1=Peter |last1=Woit| year=2015
  |title=Quantum Mechanics for Mathematicians: Representations of the Lorentz Group}}, see chapter 40
* {{cite web|url=http://pages.cs.wisc.edu/~guild/symmetrycompsproject.pdf
   |title=Representations of the Symmetry Group of Spacetime | year=2009
   |first1=Kyle | last1=Drake|first2=Michael |last2=Feinberg|first3=David|last3=Guild
   |first4=Emma | last4=Turetsky}}
* {{cite web
 |url         = http://panda.unm.edu/Courses/Finley/P495/handouts/PoincareLieAlgebra.pdf
 |title       = Lie Algebra for the Poincaré, and Lorentz, Groups
 |last1       = Finley
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20120617020207/http://panda.unm.edu/Courses/Finley/P495/handouts/PoincareLieAlgebra.pdf
 |archivedate = 2012-06-17
 |df          = 
}}
* {{cite arXiv|eprint=hep-th/0611263
  |title=The unitary representations of the Poincaré group in any spacetime dimension
   |year=2006|first1=Xavier |last1=Bekaert|first2=Niclas|last2=Boulanger}}
*{{cite web|title=McGraw-Hill dictionary of scientific and technical terms|url=http://www.answers.com/topic/irreducible-representation-of-a-group}}

[[Category:Group theory]]
[[Category:Representation theory]]
[[Category:Theoretical physics]]
[[Category:Theoretical chemistry]]
[[Category:Symmetry]]</text>
      <sha1>59lvca3ex04um9ictpy2mydise83lns</sha1>
    </revision>
  </page>
  <page>
    <title>Laplace functional</title>
    <ns>0</ns>
    <id>29220164</id>
    <revision>
      <id>867217707</id>
      <parentid>785613058</parentid>
      <timestamp>2018-11-04T12:20:03Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5059">In [[probability theory]],  a '''Laplace functional''' refers to one of two possible mathematical functions of functions or, more precisely, [[Functional analysis|functional]]s that serve as mathematical tools for studying either [[point process]]es or [[concentration of measure]] properties of [[metric spaces]]. One type of Laplace functional,&lt;ref name="stoyan1995stochastic"&gt;D. Stoyan, W. S. Kendall, and J. Mecke. ''Stochastic geometry and its applications'', volume 2. Wiley, 1995.&lt;/ref&gt;&lt;ref name="daleyPPI2003"&gt;D. J. Daley and D. Vere-Jones. ''An Introduction to the Theory of Point Processes: Volume I: Elementary Theory and Methods'', Springer, New York, second edition, 2003.&lt;/ref&gt; also known as a '''characteristic functional'''{{efn|Kingman&lt;ref name="kingman1992poisson"&gt;{{cite book|title=Poisson Processes|page=28|first=John|last=Kingman|authorlink=John Kingman|publisher=Oxford Science Publications|year=1993|isbn=0-19-853693-3}}&lt;/ref&gt; calls it a "characteristic functional" but Daley and Vere-Jones&lt;ref name="daleyPPI2003"/&gt; and others call it a "Laplace functional",&lt;ref name="stoyan1995stochastic"/&gt;&lt;ref name="BB1"&gt;{{Cite journal | last1 = Baccelli | first1 = F. O. | title = Stochastic Geometry and Wireless Networks: Volume I Theory | doi = 10.1561/1300000006 | journal = Foundations and Trends in Networking | volume = 3 | issue = 3–4 | pages = 249–449 | year = 2009 | pmid =  | pmc = | url = http://hal.archives-ouvertes.fr/docs/00/41/33/93/PDF/FnT1.pdf }}&lt;/ref&gt; reserving the term "characteristic functional" for when &lt;math&gt; \theta&lt;/math&gt; is imaginary.}} is defined in relation to a point process, which can be interpreted as random counting measures, and has applications in characterizing and deriving results on point processes.&lt;ref&gt;Barrett J. F. The use of characteristic functionals and cumulant generating functionals to discuss the effect of noise in linear systems, J. Sound &amp; Vibration 1964 vol.1, no.3, pp. 229-238&lt;/ref&gt; Its definition is analogous to a [[Characteristic function (probability theory)|characteristic function]] for a [[random variable]].

The other Laplace functional is for [[probability space]]s equipped with [[Metric (mathematics)|metric]]s, and is  used to study the [[concentration of measure]] properties of the space.

==Definition for point processes==

For a general point process &lt;math&gt;\textstyle N&lt;/math&gt; defined on &lt;math&gt;\textstyle \textbf{R}^d&lt;/math&gt;, the Laplace functional is defined as:&lt;ref name="baccelli2009stochastic1"&gt;F. Baccelli and B. B{\l}aszczyszyn. ''Stochastic Geometry and Wireless Networks, Volume I - Theory'', volume 3, No 3-4 of ''Foundations and Trends in Networking''. NoW Publishers, 2009.&lt;/ref&gt;

:&lt;math&gt; L_{{N}}(f)=E[e^{-\int_{\textbf{R}^d} f(x){N}(dx)}], &lt;/math&gt;

where &lt;math&gt;\textstyle f&lt;/math&gt; is any [[measurable]] [[non-negative]] function on &lt;math&gt;\textstyle \textbf{R}^d&lt;/math&gt; and

:&lt;math&gt; \int_{\textbf{R}^d} f(x){N}(dx)=\sum\limits_{x_i\in N} f(x_i). &lt;/math&gt;

where the notation &lt;math&gt; N(dx) &lt;/math&gt; interprets the point process as a [[random]] [[counting measure]]; see [[Point process notation]].

===Applications===
The Laplace functional characterizes a point process, and if it is known for a point process, it can be used to prove various results.&lt;ref name="daleyPPI2003"/&gt;&lt;ref name="baccelli2009stochastic1"/&gt;

==Definition for probability measures==

For some metric probability space (''X'',&amp;nbsp;''d'',&amp;nbsp;''μ''), where  (''X'',&amp;nbsp;''d'')  is a [[metric space]] and ''μ'' is a [[probability measure]] on the [[Borel set]]s of (''X'',&amp;nbsp;''d''),  the '''Laplace functional''':

:&lt;math&gt;E_{(X, d, \mu)}(\lambda) := \sup \left\{ \left. \int_{X} e^{\lambda f(x)} \, \mathrm{d} \mu(x) \right| f \colon X \to \mathbb{R} \text{ is bounded, 1-Lipschitz and has } \int_{X} f(x) \, \mathrm{d} \mu(x) = 0 \right\}.&lt;/math&gt;

The Laplace functional maps from the positive real line to the positive (extended) real line, or in mathematical notation:

:&lt;math&gt;E_{(X, d, \mu)} \colon [0, +\infty) \to [0, +\infty]&lt;/math&gt;

===Applications===
The Laplace functional of (''X'',&amp;nbsp;''d'',&amp;nbsp;''μ'') can be used to bound the concentration function of (''X'',&amp;nbsp;''d'',&amp;nbsp;''μ''), which is defined for ''r''&amp;nbsp;&amp;gt;&amp;nbsp;0 by

:&lt;math&gt;\alpha_{(X, d, \mu)}(r) := \sup \{ 1 - \mu(A_{r}) \mid A \subseteq X \text{ and } \mu(A) \geq \tfrac{1}{2} \},&lt;/math&gt;

where

:&lt;math&gt;A_{r} := \{ x \in X \mid d(x, A) \leq r \}.&lt;/math&gt;

The Laplace functional of (''X'',&amp;nbsp;''d'',&amp;nbsp;''μ'')  then gives leads to the upper bound:

:&lt;math&gt;\alpha_{(X, d, \mu)}(r) \leq \inf_{\lambda \geq 0} e^{- \lambda r / 2} E_{(X, d, \mu)}(\lambda).&lt;/math&gt;

==Notes==
{{notelist}}

==References==
{{reflist|29em}}

* {{cite book
| last = Ledoux
| first = Michel
| title = The Concentration of Measure Phenomenon
| series = Mathematical Surveys and Monographs
| volume = 89
| publisher = American Mathematical Society
| location = Providence, RI
| year = 2001
| pages = x+181
| isbn = 0-8218-2864-9
}} {{MathSciNet|id=1849347}}

[[Category:Point processes]]
[[Category:Metric geometry]]</text>
      <sha1>t95dp9cvtpnujpvbveib5ggv8phwfab</sha1>
    </revision>
  </page>
  <page>
    <title>Marshall Hall (mathematician)</title>
    <ns>0</ns>
    <id>7758584</id>
    <revision>
      <id>827669988</id>
      <parentid>824618247</parentid>
      <timestamp>2018-02-26T01:36:25Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Uta Merzbach]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5579">{{Infobox scientist
| name = Marshall Hall, Jr.
| image =Marshall Hall.jpg
| caption = Marshall Hall, Jr.
| birth_date = {{birth date|1910|9|17|df=y}} 
| birth_place = [[St Louis]], [[Missouri]], [[United States|U.S.]]
| residence = [[United States|U.S.]] 
| nationality = American 
| death_date = {{death date and age|1990|7|4|1910|9|17|df=y}} 
| death_place = [[London]], [[United Kingdom|UK]]
| field = [[Mathematician]]
| work_institution = [[Yale University]]&lt;br /&gt;[[Ohio State University]]&lt;br&gt;[[California Institute of Technology]]&lt;br /&gt;[[Emory University]]
| alma_mater = [[Cambridge University]]&lt;br /&gt;[[Yale University]]
| doctoral_advisor = [[Øystein Ore]]
| doctoral_students = [[Robert Calderbank]]&lt;br /&gt;[[Donald Knuth]]&lt;br /&gt;[[Robert McEliece]]&lt;br /&gt;[[E. T. Parker]]
| known_for  = [[Group theory]], [[Combinatorics]]
| prizes = 
| religion = 
}}
'''Marshall Hall, Jr.''' (17 September 1910 &amp;ndash; 4 July 1990) was an American [[mathematician]] who made significant contributions to [[group theory]] and [[combinatorics]].&lt;ref&gt;Ohio State University Obituary says "immense contributions".&lt;/ref&gt;

== Career ==
He studied mathematics at [[Yale University]], graduating in 1932.  He studied for a year at [[Cambridge University]] under a Henry Fellowship working with [[G. H. Hardy]].&lt;ref&gt;{{harvnb|Hall, Jr.|1989|loc=pg. 367}}&lt;/ref&gt; He returned to Yale to take his [[Ph.D.]] in 1936 under the supervision of [[Øystein Ore]].&lt;ref&gt;{{harvtxt|Hall, Jr.|1989}} says that Ore was only his nominal advisor and that he was mostly given help and direction by [[Howard Engstrom]].&lt;/ref&gt;

He worked in [[Office of Naval Intelligence|Naval Intelligence]] during [[World War II]], including six months in 1944 at [[Bletchley Park]], the center of British wartime code breaking. In 1946 he took a position at [[The Ohio State University]]. In 1959 he moved to the [[California Institute of Technology]] where, in 1973, he was named the first IBM Professor at Caltech, the first named chair in mathematics. After retiring from Caltech in 1981, he accepted a post at [[Emory University]] in 1985.

Hall died in 1990 in [[London]] on his way to a conference to mark his 80th birthday.

== Contributions ==
He wrote a number of papers of fundamental importance in group theory, including his solution of [[Burnside's problem]] for groups of exponent 6, showing that a finitely generated group in which the order of every element divides 6 must be finite.

His work in combinatorics includes an important paper of 1943 on [[projective plane]]s, which for many years was one of the most cited mathematics research papers.&lt;ref&gt;Mathematics Department of [[Ohio State University]] [https://web.archive.org/web/20110720025621/http://www.math.osu.edu/history/biographies/mhall/ Marshall Hall Jr.] via [[Wayback machine]]&lt;/ref&gt; In this paper he constructed a family of [[non-Desarguesian plane]]s which are known today as [[Hall plane]]s. He also worked on [[block design]]s and [[coding theory]].

His classic book on group theory was well received when it came out and is still useful today. His book ''Combinatorial Theory'' came out in a second edition in 1986, published by [[John Wiley &amp; Sons]].

He proposed [[Hall's conjecture]] on the differences between [[perfect squares]] and [[perfect cubes]], which remains an open problem as of 2015.

==Publications==
* 1943: "Projective Planes", [[Transactions of the American Mathematical Society]] 54(2): 229–77 {{doi|10.2307/1990331}}
* 1959: ''The Theory of Groups'', Macmillan {{mr|id=103215}}
** [[Wilhelm Magnus]] (1960) [http://projecteuclid.org/euclid.bams/1183523505 Review: Marshall Hall, Jr. ''Theory of Groups''] [[Bulletin of the American Mathematical Society]] 66(3): 144–6. 
* 1964: (with James K. Senior) ''The Groups of Order 2&lt;sup&gt;n&lt;/sup&gt; n ≤ 6)'', [[Macmillan Publishers|Macmillan]] {{mr|id=168631}}
** Preface: "An exhaustive catalog of the 340 groups of order dividing 64 with detailed tables of defining relations, constants, and [[Lattice of subgroups|lattice]] presentations of each group in the notation the text defines. "Of enduring value to those interested in [[finite groups]]".
* 1967: ''Combinatorial Theory'', [[Blaisdell]] {{mr|id=224481}}

==Notes==
{{reflist}}

==References==
* {{citation|last = Hall, Jr. |first = Marshall|chapter=Mathematical Biography: Marshall Hall Jr.|pages=367–374|title=A Century of mathematics in America, vol 1|year=1989|editor1-first=Peter|editor1-last= Duran| editor2-first=Richard|editor2-last= Askey|editor3-first= Uta C.|editor3-last= Merzbach|editor3-link= Uta Merzbach |publisher=American Mathematical Society|place=Providence, RI|isbn=0-8218-0124-4|url=http://www.ams.org/samplings/math-history/hmath1-hall26.pdf}}
*{{Citation | last1=Zassenhaus | first1=Hans | author1-link=Hans Zassenhaus | title=Marshall Hall, Jr.: 1910–1990 |mr=1071446 | year=1990 | journal=[[Notices of the American Mathematical Society]] | issn=0002-9920 | volume=37 | issue=8 | pages=1033}}

==External links==
* {{MacTutor Biography|id=Hall_Marshall|title=Marshall Hall jr}}
* {{MathGenealogy|id=6807}}

{{Authority control}}

{{DEFAULTSORT:Hall, Marshall, Jr}}
[[Category:1910 births]]
[[Category:1990 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:Algebraists]]
[[Category:Group theorists]]
[[Category:Emory University faculty]]
[[Category:Combinatorialists]]
[[Category:Guggenheim Fellows]]
[[Category:California Institute of Technology faculty]]
[[Category:Ohio State University faculty]]
[[Category:Yale University alumni]]
[[Category:People from St. Louis]]</text>
      <sha1>g0uu2h8nxwvsv6aqj1nmzs95h1kt5f5</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical exposure modeling</title>
    <ns>0</ns>
    <id>23236792</id>
    <revision>
      <id>641420921</id>
      <parentid>590058584</parentid>
      <timestamp>2015-01-07T14:23:12Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Tagging using [[Project:AWB|AWB]] (10703)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4648">{{Multiple issues|
{{refimprove|date=June 2009}}
{{no footnotes|date=June 2009}}
{{confusing|date=June 2009}}
}}

'''Mathematical exposure modeling''' is an indirect method of determining [[exposure assessment|exposure]], particularly for human exposure to [[pollution|environmental contaminants]].  It is useful when direct measurement of pollutant concentration is not feasible because direct measurement sometimes requires skilled professionals and complex, expensive laboratory equipment.  The ability to make inferences in the absence of direct measurements, makes exposure modeling a powerful tool for predicting exposures by exploring hypothetical situations.  It allows researchers to ask [[sensitivity analysis|"what if"]] questions about exposure scenarios.

== Modeling indoor air ==

Mathematical modeling is commonly used to determine human exposure to indoor air pollution.  Studies have shown that humans spend about 90% of their time indoors, and contaminant levels may be as high or higher inside than outside, due to the presence of multiple indoor contaminant sources, in combination with poor ventilation.  Indoor air modeling requires information on a number of parameters including the air exchange rate, [[Deposition (Aerosol physics)|deposition rate]], source emission rate, and physical volume of the indoor setting.  Indoor environments can basically be thought of as [[closed systems]], so models describing them are usually based on the "[[mass balance]]" equation.  It is also assumed that a pollutant emitted into an indoor environment instantly spreads uniformly throughout the system, so that the concentration is the same at any point in space at any point in time.  Mathematically, the total pollutant mass emitted inside a chamber during time T can be expressed as&lt;br&gt;
::G&lt;sub&gt;source&lt;/sub&gt;(T) = &lt;math&gt;\int_{0}^{T} g(t)\, dt&lt;/math&gt;
:where
::G&lt;sub&gt;source&lt;/sub&gt;(T) = total mass contributed by the source over time T (e.g., mg)
::g(t) = emission flow rate as a function of time t (e.g., mg/min)

The total mass lost during time T can be expressed as&lt;br&gt;
::Q&lt;sub&gt;lost&lt;/sub&gt;(T) = &lt;math&gt;\int_{0}^{T} wx(t)\, dt&lt;/math&gt;
:where
::Q&lt;sub&gt;lost&lt;/sub&gt;(T) = total mass lost from the chamber over time T (e.g., mg)
::x(t) = concentration of pollutant in the air exiting the chamber (e.g., mg/m&lt;sup&gt;3&lt;/sup&gt;)
::w = flow rate of air exiting the chamber (e.g., m&lt;sup&gt;3&lt;/sup&gt;/min)

Following the principle of the "mass balance" equation, the total mass in the chamber at time T, is the difference between the two equations above, mass generated during time T minus mass lost during time T.  This value may also be calculated from the equation&lt;br&gt;
::Total mass inside the chamber at time T = vx(T)

== Modeling human exposure to air pollution ==
There are two critical pieces of information that are needed to calculate human exposure.  These include data on 1) the whereabouts of the individual or individuals being exposed and 2) the concentration of the pollutants in the different locations.  This can be expressed mathematically as the sum of the products of time spent by a person in those different locations by the time-averaged [[air pollutant concentrations]] occurring in those locations.&lt;br&gt;
::E&lt;sub&gt;''p''&lt;/sub&gt; = &lt;math&gt;\sum_{i=1}^m&lt;/math&gt; C&lt;sub&gt;''pi''&lt;/sub&gt;T&lt;sub&gt;''pi''&lt;/sub&gt;
:where
::T&lt;sub&gt;''pi''&lt;/sub&gt; is the time spent by person ''p'' in microenvironment ''i'', and C&lt;sub&gt;''pi''&lt;/sub&gt; is the concentration of the air pollutant that person ''p'' experiences in microenvironment ''i'', E&lt;sub&gt;''p''&lt;/sub&gt; is the integrated exposure for person ''p'' and ''m'' is the number of different microenvironments.

As mentioned above, knowing the whereabouts of the individual or individuals, is very important when trying to determine air pollution exposure.  In the absence of data obtained from direct observation, human activity pattern data may be used.  This data can be found in several reports conducted by the [[United States Environmental Protection Agency|U.S. Environmental Protection Agency]].  The data was collected through the National Human Activity Pattern Survey (NHAPS), and contains a representative cross-section of 24-hour daily activity patterns.  This data can be used to create inhalation exposure models which can serve as useful public health tools for [[epidemiology]], education, intervention, [[risk assessment]], and creation of air quality guidelines.

==See also==
* [[Predictive intake modelling]]

== References ==
Ott, W.R., Steinemann, A.C., Wallace, L.A.. Exposure Analysis. CRC Press (2007)

The Inside Story: A Guide to Indoor Air Quality. U.S. EPA (2009)

[[Category:Mathematical modeling]]</text>
      <sha1>1n2mynp0cwmn0ly6hib1wjk7st51ggm</sha1>
    </revision>
  </page>
  <page>
    <title>Maximum coverage problem</title>
    <ns>0</ns>
    <id>24221954</id>
    <revision>
      <id>837875513</id>
      <parentid>837875346</parentid>
      <timestamp>2018-04-23T15:34:02Z</timestamp>
      <contributor>
        <ip>130.113.70.9</ip>
      </contributor>
      <comment>/* Greedy algorithm */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10423">The '''maximum coverage problem''' is a classical question in [[computer science]], [[computational complexity theory]], and [[operations research]].
It is a problem that is widely taught in [[approximation algorithms]].

As input you are given several sets and a number &lt;math&gt;k&lt;/math&gt;. 
The sets may have some elements in common. 
You must select at most &lt;math&gt;k&lt;/math&gt; of these sets such that the maximum number of elements are covered, 
i.e. the union of the selected sets has maximal size.

Formally, (unweighted) Maximum Coverage 
: Instance: A number &lt;math&gt; k &lt;/math&gt; and a collection of sets &lt;math&gt; S = \{S_1, S_2, \ldots, S_m\} &lt;/math&gt;.
: Objective: Find a subset &lt;math&gt; S^{'} \subseteq S&lt;/math&gt; of sets, such that &lt;math&gt; \left| S^{'} \right| \leq k&lt;/math&gt; and the number of covered elements &lt;math&gt; \left| \bigcup_{S_i \in S^{'}}{S_i} \right| &lt;/math&gt; is maximized.
The maximum coverage problem is [[NP-hard]], and can be approximated within &lt;math&gt;1 - \frac{1}{e} + o(1) \approx 0.632&lt;/math&gt; under standard assumptions. 
This result essentially matches the approximation ratio achieved by the generic greedy algorithm used for  [[Submodular_set_function#Optimization_problems|maximization of submodular functions with a cardinality constraint]].&lt;ref name="NVF"&gt; [[George Nemhauser|G. L. Nemhauser]], L. A. Wolsey and M. L. Fisher. An analysis of approximations for maximizing submodular set functions I, Mathematical Programming 14 (1978), 265–294&lt;/ref&gt;

==ILP formulation==
The maximum coverage problem can be formulated as the following [[integer linear program]].

{| cellpadding="5"
| maximize   || &lt;math&gt;\sum_{e_j \in E} y_j&lt;/math&gt; || (maximizing the sum of covered elements)
|-
| subject to || &lt;math&gt;\sum{x_i} \leq k&lt;/math&gt; || (no more than &lt;math&gt;k&lt;/math&gt; sets are selected)
|-
|            || &lt;math&gt;\sum_{e_j \in S_i} x_i \geq y_j&lt;/math&gt; || (if &lt;math&gt;y_j &gt; 0 &lt;/math&gt; then at least one set &lt;math&gt;e_j \in S_i&lt;/math&gt; is selected)
|-
|            || &lt;math&gt;y_j \in \{0,1\}&lt;/math&gt; || (if &lt;math&gt;y_j=1&lt;/math&gt; then &lt;math&gt;e_j&lt;/math&gt; is covered)
|-
|            || &lt;math&gt;x_i \in \{0,1\}&lt;/math&gt; || (if &lt;math&gt;x_i=1&lt;/math&gt; then &lt;math&gt;S_i&lt;/math&gt; is selected for the cover)
|}

== Greedy algorithm ==
The [[greedy algorithm]] for maximum coverage chooses sets according to one rule: at each stage, choose a set which contains the largest number of uncovered elements. It can be shown that this algorithm achieves an approximation ratio of &lt;math&gt;1 - \frac{1}{e}&lt;/math&gt;.&lt;ref&gt;{{cite book | last=Hochbaum | first=Dorit S. | authorlink=Dorit S. Hochbaum | editor-first=Dorit S. | editor-last=Hochbaum | year=1997 | chapter=Approximating Covering and Packing Problems: Set Cover, Vertex Cover, Independent Set, and Related Problems | title=Approximation Algorithms for NP-Hard Problems | publisher=PWS Publishing Company | location=Boston | isbn=053494968-1 | pages=94–143}}&lt;/ref&gt; ln-approximability results show that the greedy algorithm is essentially the best-possible polynomial time approximation algorithm for maximum coverage unless &lt;math&gt;P = NP&lt;/math&gt;.&lt;ref&gt;{{cite article | last = Feige | first = Uriel | authorlink = Uriel Feige | title = A Threshold of ln ''n'' for Approximating Set Cover | journal = Journal of the ACM | volume = 45 | number = 4 |date=July 1998 | issn = 0004-5411 | pages = 634–652 | doi = 10.1145/285055.285059 | publisher = Association for Computing Machinery | location = New York, NY, USA}}&lt;/ref&gt;

== Known extensions ==
The inapproximability results apply to all extensions of the maximum coverage problem since they hold the maximum coverage problem as a special case.

The Maximum Coverage Problem can be applied to road traffic situations; one such example is selecting which bus routes in a public transportation network should be installed with pothole detectors to maximise coverage, when only a limited number of sensors is available. This problem is a known extension of the Maximum Coverage Problem and was first explored in literature by Junade Ali and Vladimir Dyo.&lt;ref&gt;{{cite journal|last1=Ali|first1=Junade|last2=Dyo|first2=Vladimir|title=Coverage and Mobile Sensor Placement for Vehicles on Predetermined Routes: A Greedy Heuristic Approach|journal=Proceedings of the 14th International Joint Conference on e-Business and Telecommunications|date=2017|volume=Volume 2: WINSYS|pages=83-88|doi=10.5220/0006469800830088|url=http://www.scitepress.org/DigitalLibrary/PublicationsDetail.aspx?ID=ddWw1NMB3VI%3d}}&lt;/ref&gt;

== Weighted version ==
In the weighted version every element &lt;math&gt; e_j &lt;/math&gt; has a weight  &lt;math&gt;w(e_j)&lt;/math&gt;. The task is to find a maximum coverage which has maximum weight. The basic version is a special case when all weights are &lt;math&gt;1&lt;/math&gt;.

:maximize &lt;math&gt;\sum_{e \in E} w(e_j) \cdot y_j &lt;/math&gt;. (maximizing the weighted sum of covered elements).
:subject to &lt;math&gt; \sum{x_i}  \leq k &lt;/math&gt;; (no more than &lt;math&gt;k&lt;/math&gt; sets are selected).
::&lt;math&gt; \sum_{e_j \in S_i} x_i \geq y_j &lt;/math&gt;; (if &lt;math&gt;y_j &gt; 0 &lt;/math&gt; then at least one set &lt;math&gt;e_j \in S_i&lt;/math&gt; is selected).
::&lt;math&gt;y_j \in \{0,1\}&lt;/math&gt;; (if &lt;math&gt;y_j=1&lt;/math&gt; then &lt;math&gt;e_j&lt;/math&gt; is covered)
::&lt;math&gt;x_i \in \{0,1\}&lt;/math&gt; (if &lt;math&gt;x_i=1&lt;/math&gt; then &lt;math&gt;S_i&lt;/math&gt; is selected for the cover).

The greedy algorithm for the weighted maximum coverage at each stage chooses a set that contains the maximum weight of uncovered elements. This algorithm achieves an approximation ratio of &lt;math&gt;1 - \frac{1}{e}&lt;/math&gt;.&lt;ref name="NVF"/&gt;

== Budgeted maximum coverage  ==
In the budgeted maximum coverage version, not only does every element &lt;math&gt; e_j &lt;/math&gt; have a weight &lt;math&gt;w(e_j)&lt;/math&gt;, but also every set &lt;math&gt;S_i&lt;/math&gt; has a cost &lt;math&gt;c(S_i)&lt;/math&gt;. Instead of &lt;math&gt;k&lt;/math&gt; that limits the number of sets in the cover a budget &lt;math&gt;B&lt;/math&gt; is given. This budget &lt;math&gt;B&lt;/math&gt; limits the total cost of the cover that can be chosen.

:maximize &lt;math&gt;\sum_{e \in E} w(e_j) \cdot y_j &lt;/math&gt;. (maximizing the weighted sum of covered elements).
:subject to &lt;math&gt; \sum{c(S_i) \cdot x_i}  \leq B &lt;/math&gt;; (the cost of the selected sets cannot exceed &lt;math&gt;B&lt;/math&gt;).
::&lt;math&gt; \sum_{e_j \in S_i} x_i \geq y_j &lt;/math&gt;; (if &lt;math&gt;y_j &gt; 0 &lt;/math&gt; then at least one set &lt;math&gt;e_j \in S_i&lt;/math&gt; is selected).
::&lt;math&gt;y_j \in \{0,1\}&lt;/math&gt;; (if &lt;math&gt;y_j=1&lt;/math&gt; then &lt;math&gt;e_j&lt;/math&gt; is covered)
::&lt;math&gt;x_i \in \{0,1\}&lt;/math&gt; (if &lt;math&gt;x_i=1&lt;/math&gt; then &lt;math&gt;S_i&lt;/math&gt; is selected for the cover).

A greedy algorithm will no longer produce solutions with a performance guarantee. Namely, the worst case behavior of this algorithm might be very far from the optimal solution. The approximation algorithm is extended by the following way. First, define a modified greedy algorithm, that selects the set &lt;math&gt;S_i&lt;/math&gt; that has the best ratio of weighted uncovered elements to cost. Second, among covers of cardinality &lt;math&gt;1, 2, ..., k-1&lt;/math&gt;, find the best cover that does not violate the budget. Call this cover &lt;math&gt;H_1&lt;/math&gt;. Third, find all covers of cardinality &lt;math&gt;k&lt;/math&gt; that do not violate the budget. Using these covers of cardinality &lt;math&gt;k&lt;/math&gt; as starting points, apply the modified greedy algorithm, maintaining the best cover found so far. Call this cover &lt;math&gt;H_2&lt;/math&gt;. At the end of the process, the approximate best cover will be either &lt;math&gt;H_1&lt;/math&gt; or &lt;math&gt;H_2&lt;/math&gt;. This algorithm achieves an approximation ratio of &lt;math&gt;1- {1 \over e}&lt;/math&gt; for values of &lt;math&gt;k \geq 3&lt;/math&gt;. This is the best possible approximation ratio unless &lt;math&gt;NP \subseteq DTIME(n^{O(\log\log n)})&lt;/math&gt;.&lt;ref&gt;Khuller, S., Moss, A., and Naor, J. 1999. [https://dx.doi.org/10.1016/S0020-0190(99)00031-9 The budgeted maximum coverage problem]. ''Inf. Process. Lett''. 70, 1 (Apr. 1999), 39-45.&lt;/ref&gt;

== Generalized maximum coverage  ==
In the generalized maximum coverage version every set &lt;math&gt;S_i&lt;/math&gt; has a cost &lt;math&gt;c(S_i)&lt;/math&gt;, 
element &lt;math&gt; e_j &lt;/math&gt; has a different weight and cost depending on which set covers it.
Namely, if &lt;math&gt; e_j &lt;/math&gt; is covered by set &lt;math&gt;S_i&lt;/math&gt; the weight of &lt;math&gt; e_j &lt;/math&gt;
is &lt;math&gt;w_i(e_j)&lt;/math&gt; and its cost is &lt;math&gt;c_i(e_j)&lt;/math&gt;. 
A budget &lt;math&gt; B &lt;/math&gt; is given for the total cost of the solution.

:maximize &lt;math&gt;\sum_{e \in E, S_i} w_i(e_j) \cdot y_{ij} &lt;/math&gt;. (maximizing the weighted sum of covered elements in the sets in which they are covered).
:subject to &lt;math&gt; \sum{c_i(e_j) \cdot y_{ij}} + \sum{c(S_i) \cdot x_i}  \leq B &lt;/math&gt;; (the cost of the selected sets cannot exceed &lt;math&gt;B&lt;/math&gt;).
::&lt;math&gt; \sum_{i} y_{ij} \leq 1 &lt;/math&gt;; (element &lt;math&gt;e_j=1&lt;/math&gt; can only be covered by at most one set).
::&lt;math&gt; \sum_{S_i} x_i \geq y_{ij} &lt;/math&gt;; (if &lt;math&gt;y_j &gt; 0 &lt;/math&gt; then at least one set &lt;math&gt;e_j \in S_i&lt;/math&gt; is selected).
::&lt;math&gt;y_{ij} \in \{0,1\} &lt;/math&gt;; (if &lt;math&gt;y_{ij}=1&lt;/math&gt; then &lt;math&gt;e_j&lt;/math&gt; is covered by set &lt;math&gt;S_i&lt;/math&gt;)
::&lt;math&gt;x_i \in \{0,1\}&lt;/math&gt; (if &lt;math&gt;x_i=1&lt;/math&gt; then &lt;math&gt;S_i&lt;/math&gt; is selected for the cover).

=== Generalized maximum coverage algorithm ===
The algorithm uses the concept of residual cost/weight. The residual cost/weight is measured against a tentative solution and it is the difference of the cost/weight from the cost/weight gained by a tentative solution.

The algorithm has several stages. First, find a solution using greedy algorithm. In each iteration of the greedy algorithm the tentative solution is added the set which contains the maximum residual weight of elements divided by the residual cost of these elements along with the residual cost of the set. Second, compare the solution gained by the first step to the best solution which uses a small number of sets. Third, return the best out of all examined solutions. This algorithm achieves an approximation ratio of &lt;math&gt;1-1/e - o(1)&lt;/math&gt;.&lt;ref&gt;Cohen, R. and Katzir, L. 2008. [https://dx.doi.org/10.1016/j.ipl.2008.03.017 The Generalized Maximum Coverage Problem]. ''Inf. Process. Lett''. 108, 1 (Sep. 2008), 15-22.&lt;/ref&gt;

== Related problems ==
* [[Set cover problem]] is to cover all elements with as few sets as possible.

== Notes ==
{{Reflist}}

== References ==
* {{Cite book | last=Vazirani | first=Vijay V. | authorlink=Vijay Vazirani | title=Approximation Algorithms | year=2001 | publisher=Springer-Verlag | isbn=3-540-65367-8 | pages=}}

== External links ==

[[Category:Set families]]
[[Category:NP-complete problems]]</text>
      <sha1>7tdxoih2zm1oei1f69hhlzubnryvgss</sha1>
    </revision>
  </page>
  <page>
    <title>Measure of non-compactness</title>
    <ns>0</ns>
    <id>212935</id>
    <revision>
      <id>608150708</id>
      <parentid>607163572</parentid>
      <timestamp>2014-05-12T00:55:58Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>not unreferenced</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3141">In [[functional analysis]], two '''measures of non-compactness''' are commonly used; these associate numbers to sets in such a way that [[Compact space|compact]] sets all get the measure 0, and other sets get measures that are bigger according to "how far" they are removed from compactness.

The underlying idea is the following: a bounded set can be covered by a single ball of some radius. Sometimes several balls of a smaller radius can also cover the set. A compact set in fact can be covered by finitely many balls of arbitrary small radius, because it is [[totally bounded]]. So one could ask: what is the smallest radius that allows to cover the set with finitely many balls?

Formally, we start with a [[metric space]] ''M'' and a subset ''X''. The '''ball measure of non-compactness''' is defined as
:&amp;alpha;(''X'') = [[infimum|inf]] {''r'' &gt; 0 : there exist finitely many balls of radius ''r'' which cover ''X''}
and the '''Kuratowski measure of non-compactness''' is defined as
:&amp;beta;(''X'') = inf {''d'' &gt; 0 : there exist finitely many sets of diameter at most ''d'' which cover ''X''}

Since a ball of radius ''r'' has diameter at most 2''r'', we have α(''X'') ≤ β(''X'') ≤ 2α(''X'').

The two measures α and β share many properties, and we will use γ in the sequel to denote either one of them. Here is a collection of facts:
* ''X'' is bounded if and only if γ(''X'') &lt; ∞. 
* γ(''X'') = γ(''X''&lt;sup&gt;cl&lt;/sup&gt;), where ''X''&lt;sup&gt;cl&lt;/sup&gt; denotes the [[closure (topology)|closure]] of ''X''. 
* If ''X'' is compact, then γ(''X'') = 0. Conversely, if γ(''X'') = 0 and ''X'' is [[complete space|complete]], then ''X'' is compact. 
* γ(''X'' ∪ ''Y'') = max(γ(''X''), γ(''Y'')) for any two subsets ''X'' and ''Y''.
* γ is continuous with respect to the [[Hausdorff distance]] of sets.

Measures of non-compactness are most commonly used if ''M'' is a [[normed vector space]]. In this case, we have in addition:
* γ(''aX'') = |''a''| γ(''X'') for any [[scalar (mathematics)|scalar]] ''a''
* γ(''X'' + ''Y'') ≤ γ(''X'') + γ(''Y'')
* γ(conv(''X'')) = γ(''X''), where conv(''X'') denotes the [[convex hull]] of ''X''

Note that these measures of non-compactness are useless for subsets of [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt;: by the [[Heine–Borel theorem]], every bounded closed set is compact there, which means that γ(''X'') = 0 or ∞ according to whether ''X'' is bounded or not.

Measures of non-compactness are however useful in the study of infinite-dimensional [[Banach space]]s, for example. In this context, one can prove that any ball ''B'' of radius ''r'' has α(''B'') = ''r'' and β(''B'') = 2''r''.

== References ==
# Józef Banaś, [[Kazimierz Goebel]]: ''Measures of noncompactness in Banach spaces'', Institute of Mathematics, Polish Academy of Sciences, Warszawa 1979
# [[Kazimierz Kuratowski]]: ''Topologie Vol I'', PWN. Warszawa 1958
# R.R. Akhmerov, M.I. Kamenskii, A.S. Potapova, A.E. Rodkina and B.N. Sadovskii, ''Measure of Noncompactness and Condensing Operators'', Birkhäuser, Basel 1992

{{DEFAULTSORT:Measure Of Non-Compactness}}
[[Category:Functional analysis]]</text>
      <sha1>gydetr8qv1q76uc3r5j8pt6vs7d93p3</sha1>
    </revision>
  </page>
  <page>
    <title>Modal logic</title>
    <ns>0</ns>
    <id>333365</id>
    <revision>
      <id>868858378</id>
      <parentid>856210369</parentid>
      <timestamp>2018-11-14T22:18:14Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="51459">'''Modal logic''' is a type of [[mathematical logic#Formal logic|formal logic]] primarily developed in the 1960s that extends classical [[Propositional logic|propositional]] and [[predicate logic]] to include operators expressing [[Linguistic modality|modality]]. A modal—a word that expresses a modality—qualifies a statement. For example, the statement "John is happy" might be qualified by saying that John is [[usually]] happy, in which case the term "usually" is functioning as a modal. The traditional [[alethic modality|alethic modalities]], or modalities of truth, include [[Logical possibility|possibility]] ("Possibly, ''p''", "It is possible that ''p''"), necessity ("Necessarily, ''p''", "It is necessary that ''p''"), and impossibility ("Impossibly, ''p''", "It is impossible that ''p''").&lt;ref&gt;"Formal Logic", by A. N. Prior, Oxford Univ. Press, 1962, p. 185&lt;/ref&gt; Other modalities that have been formalized in modal logic include [[Temporal Logic|temporal]] modalities, or modalities of time (notably, "It was the case that ''p''", "It has always been that ''p''", "It will be that ''p''", "It will always be that ''p''"),&lt;ref&gt;"Temporal Logic", by Rescher and Urquhart, Springer-Verlag, 1971, p. 52&lt;/ref&gt;&lt;ref&gt;"Past, Present and Future", by A. N. Prior, Oxford Univ. Press, 1967&lt;/ref&gt; [[Deontic logic|deontic]] modalities (notably, "It is obligatory that ''p''", and "It is permissible that ''p''"), [[Epistemic logic|epistemic]] modalities, or modalities of knowledge ("It is known that ''p''")&lt;ref&gt;"Knowledge and Belief", by Jaakko Hinntikka, Cornell Univ. Press, 1962&lt;/ref&gt; and [[Doxastic logic|doxastic]] modalities, or modalities of belief ("It is believed that ''p''").&lt;ref&gt;"Topics in Philosophical Logic", by N. Rescher, Humanities Press, 1968, p. 41&lt;/ref&gt;

A formal modal logic represents modalities using [[modal operator]]s. For example, "It might rain today" and "It is possible that rain will fall today" both contain the notion of possibility. In a modal logic this is represented as an operator, "Possibly", attached to the sentence "It will rain today".

It is fallacious to confuse necessity and possibility. In particular, this is known as the [[modal fallacy]].

The basic [[Unary operation|unary]] (1-place) modal operators are usually written "□" for "Necessarily" and "◇" for "Possibly". In a [[classical modal logic]], each can be expressed by the other with [[negation]]:

:&lt;math&gt;\Diamond P \leftrightarrow \lnot \Box \lnot P;&lt;/math&gt;
:&lt;math&gt;\Box P \leftrightarrow \lnot \Diamond \lnot P.&lt;/math&gt;

Thus it is ''possible'' that it will rain today if and only if it is ''not necessary'' that it will ''not'' rain today, and it is ''necessary'' that it will rain today if and only if it is ''not possible'' that it will ''not'' rain today. Alternative symbols used for the modal operators are "L" for "Necessarily" and "M" for "Possibly".&lt;ref&gt;So in the standard work ''A New Introduction to Modal Logic'', by G. E. Hughes and  M. J. Cresswell, Routledge, 1996, ''passim''.&lt;/ref&gt;

==Development of modal logic==
In addition to his non-modal syllogistic, [[Aristotle]] also developed a modal syllogistic in Book I of his ''[[Prior Analytics]]'' (chs 8–22), which [[Theophrastus]] attempted to improve.&lt;ref&gt;{{cite SEP |url-id=logic-ancient |title=Ancient Logic |last=Bobzien |first=Susanne}}&lt;/ref&gt; There are also passages in Aristotle's work, such as the famous [[problem of future contingents|sea-battle argument]] in ''[[De Interpretatione]]'' §9, that are now seen as anticipations of the connection of modal logic with [[potentiality]] and time. In the Hellenistic period, the logicians [[Diodorus Cronus]], [[Philo the Dialectician]] and the Stoic [[Chrysippus]] each developed a modal system that accounted for the interdefinability of possibility and necessity, accepted axiom '''T''' (see [[#Axiomatic systems|below]]), and combined elements of modal logic and [[temporal logic]] in attempts to solve the notorious [[Diodorus Cronus#Master Argument|Master Argument]].&lt;ref&gt;Bobzien, S. (1993). "Chrysippus' Modal Logic and its Relation to Philo and Diodorus", in K. Doering &amp; Th. Ebert (eds), ''Dialektiker und Stoiker'', Stuttgart 1993, pp. 63–84.&lt;/ref&gt; The earliest formal system of modal logic was developed by [[Avicenna]], who ultimately developed a theory of "[[Temporal logic|temporally]] modal" syllogistic.&lt;ref name=Britannica&gt;[http://www.britannica.com/ebc/article-65928 History of logic: Arabic logic], ''[[Encyclopædia Britannica]]''.&lt;/ref&gt; Modal logic as a self-aware subject owes much to the writings of the [[Scholastics]], in particular [[William of Ockham]] and [[John Duns Scotus]], who reasoned informally in a modal manner, mainly to analyze statements about [[essence]] and [[accident (philosophy)|accident]].

[[C. I. Lewis]] founded modern modal logic in his 1910 Harvard thesis&lt;ref&gt;{{cite thesis | type=Ph.D. thesis | url= | author=Clarence Irving Lewis | title=The Place of Intuition in Knowledge | institution=Harvard University | year=1910 }}&lt;/ref&gt; and in a series of scholarly articles beginning in 1912. This work culminated in his 1932 book ''Symbolic Logic'' (with [[Cooper Harold Langford|C. H. Langford]]),&lt;ref&gt;{{cite book | url= | isbn= | author=Clarence Irving Lewis and Cooper Harold Langford | title=Symbolic Logic  | location= | publisher=Dover Publications | edition=1st | year=1932 }}&lt;/ref&gt; which introduced the five systems ''S1'' through ''S5''.

Ruth C. Barcan (later [[Ruth Barcan Marcus]]) developed the first axiomatic systems of quantified modal logic — first and second order extensions of Lewis' ''S2'', ''S4'', and ''S5''.&lt;ref&gt;{{cite journal | author=Ruth C. Barcan | title=A Functional Calculus of First Order  Based on Strict Implication | journal=Journal of Symbolic Logic | volume=11 | number=1 | pages=1&amp;mdash;16 | date=Mar 1946 | doi=10.2307/2269159}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | author=Ruth C. Barcan | title=The Deduction Theorem in a Functional Calculus  of First Order Based on Strict Implication | journal=Journal of Symbolic Logic | volume=11 | number=4 | pages=115&amp;mdash;118 | date=Dec 1946 | doi=10.2307/2268309}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | author=Ruth C. Barcan | title=The Identity of Individuals in a  Strict Functional Calculus of Second Order | journal=Journal of Symbolic Logic | volume=12 | number=1 | pages=12&amp;mdash;15 | date=Mar 1947 | doi=10.2307/2267171}}&lt;/ref&gt;

The contemporary era in modal semantics began in 1959, when [[Saul Kripke]] (then only a 19-year-old [[Harvard University]] undergraduate) introduced the now-standard [[Kripke semantics]] for modal logics. These are commonly referred to as "possible worlds" semantics. Kripke and [[A. N. Prior]] had previously corresponded at some length. Kripke semantics is basically simple, but proofs are eased using semantic-tableaux or [[analytic tableaux]], as explained by [[Evert Willem Beth|E. W. Beth]].

[[A. N. Prior]] created modern [[temporal logic]], closely related to modal logic, in 1957 by adding modal operators [F] and [P] meaning "eventually" and "previously". [[Vaughan Pratt]] introduced [[dynamic logic (modal logic)|dynamic logic]] in 1976. In 1977, [[Amir Pnueli]] proposed using temporal logic to formalise the behaviour of continually operating concurrent programs. Flavors of temporal logic include [[propositional dynamic logic]] (PDL), [[propositional linear temporal logic]] (PLTL), [[linear temporal logic]] (LTL), [[computation tree logic]] (CTL), [[Hennessy–Milner logic]], and ''T''.{{clarify|reason=Add a wikilink, give a longer name, or give a reference for the 'T' logic.|date=November 2016}}

The mathematical structure of modal logic, namely [[Boolean algebra (structure)|Boolean algebra]]s augmented with [[unary operation]]s (often called [[modal algebra]]s), began to emerge with [[J.C.C. McKinsey|J. C. C. McKinsey]]'s 1941 proof that ''S2'' and ''S4'' are decidable,&lt;ref&gt;{{cite journal|author=McKinsey, J. C. C.|title=A Solution of the Decision Problem for the Lewis Systems S2 and S4, with an Application to Topology|journal=J. Symb. Log.|year=1941|volume=6|issue=4|pages=117–134|jstor=2267105}}&lt;/ref&gt; and reached full flower in the work of [[Alfred Tarski]] and his student [[Bjarni Jónsson]] (Jónsson and Tarski 1951–52). This work revealed that ''S4'' and ''S5'' are models of [[interior algebra]], a proper extension of Boolean algebra originally designed to capture the properties of the [[interior operator|interior]] and [[closure operator]]s of [[topology]]. Texts on modal logic typically do little more than mention its connections with the study of [[Boolean algebra (structure)|Boolean algebra]]s and [[topology]]. For a thorough survey of the history of formal modal logic and of the associated mathematics, see [[Robert Goldblatt]] (2006).&lt;ref&gt;Robert Goldbaltt, [http://www.mcs.vuw.ac.nz/~rob/papers/modalhist.pdf Mathematical Modal Logic: A view of it evolution]&lt;/ref&gt;

==Semantics==

===Model theory===
The semantics for modal logic are usually given as follows:&lt;ref&gt;Fitting and Mendelsohn. ''First-Order Modal Logic''. Kluwer Academic Publishers, 1998. Section 1.6&lt;/ref&gt; First we define a ''frame'', which consists of a non-empty set, ''G'', whose members are generally called possible worlds, and a binary relation, ''R'', that holds (or not) between the possible worlds of ''G''. This binary relation is called the ''[[accessibility relation]]''.  For example, ''w R u'' means that the  world ''u'' is accessible from world ''w''. That is to say, the state of affairs known as ''u'' is a live possibility for ''w''. This gives a pair, &lt;math&gt;\langle G, R\rangle&lt;/math&gt;. Some formulations of modal logic also include a constant term in ''G'', conventionally called "the actual world", which is often symbolized as &lt;math&gt;w*&lt;/math&gt;.

Next, the ''frame'' is extended to a ''model'' by specifying the [[truth-value]]s of all propositions at each of the worlds in ''G''. We do so by defining a relation ''v'' between possible worlds and positive literals. If there is a world ''w'' such that &lt;math&gt;v(w, P)&lt;/math&gt;, then ''P'' is true at ''w''. A model is thus an ordered triple, &lt;math&gt;\langle G, R, v \rangle&lt;/math&gt;.

Then we recursively define the truth of a formula at a world in a model:

* if &lt;math&gt;v(w, P)&lt;/math&gt; then &lt;math&gt;w \models P&lt;/math&gt;
* &lt;math&gt;w \models \neg P&lt;/math&gt; if and only if &lt;math&gt;w \not \models P&lt;/math&gt;
* &lt;math&gt;w \models (P \wedge Q) &lt;/math&gt; if and only if &lt;math&gt;w \models P&lt;/math&gt; and &lt;math&gt;w \models Q&lt;/math&gt;
* &lt;math&gt;w \models \Box P&lt;/math&gt; if and only if for every element ''u'' of ''G'', if ''w R u'' then &lt;math&gt;u \models P&lt;/math&gt;
* &lt;math&gt;w \models \Diamond P&lt;/math&gt; if and only if for some element ''u'' of ''G'', it holds that ''w R u'' and &lt;math&gt;u \models P&lt;/math&gt;
* &lt;math&gt;\models P&lt;/math&gt; if and only if &lt;math&gt;w* \models P&lt;/math&gt;

According to these semantics, a truth is ''necessary'' with respect to a possible world ''w'' if it is true at every world that is accessible to ''w'', and ''possible'' if it is true at some world that is accessible to ''w''. Possibility thereby depends upon the accessibility relation ''R'', which allows us to express the relative nature of possibility. For example, we might say that given our laws of physics it is not possible for humans to travel faster than the speed of light, but that given other circumstances it could have been possible to do so. Using the accessibility relation we can translate this scenario as follows: At all of the worlds accessible to our own world, it is not the case that humans can travel faster than the speed of light, but at one of these accessible worlds there is ''another'' world accessible from ''those'' worlds but not accessible from our own at which humans can travel faster than the speed of light.

It should also be noted that the definition of □ makes vacuously true certain sentences, since when it speaks of "every world that is accessible to ''w''" it takes for granted the usual mathematical interpretation of the word "every" (see [[vacuous truth]]). Hence, if a world ''w'' doesn't have any accessible worlds, any sentence beginning with □ is true.

The different systems of modal logic are distinguished by the properties of their corresponding accessibility relations. There are several systems that have been espoused (often called ''frame conditions''). An accessibility relation is:

* '''[[reflexive relation|reflexive]]''' [[iff]] ''w R w'', for every ''w'' in ''G''
* '''[[symmetric relation|symmetric]]''' iff ''w R u'' implies ''u R w'', for all ''w'' and ''u'' in ''G''
* '''[[transitive relation|transitive]]''' iff ''w R u'' and ''u R q'' together imply ''w R q'', for all ''w'', ''u'', ''q'' in ''G''.
* '''[[serial relation|serial]]''' iff, for each ''w'' in ''G'' there is some ''u'' in ''G'' such that ''w R u''.
* '''[[euclidean relation|Euclidean]]''' iff, for every ''u'', ''t'', and ''w'', ''w R u'' and ''w R t'' implies ''u R t'' (note that it also implies: ''t R u'')

The logics that stem from these frame conditions are:
*'''K''' := no conditions
*'''D''' := serial
*'''T''' := reflexive
*'''B''' := reflexive and symmetric
*'''S4''' := [[preorder|reflexive and transitive]]
*'''S5''' := reflexive and [[euclidean relation|Euclidean]]

The Euclidean property along with reflexivity yields symmetry and transitivity. (The Euclidean property can be obtained, as well, from symmetry and transitivity.) Hence if the accessibility relation ''R'' is reflexive and Euclidean, ''R'' is provably [[symmetric relation|symmetric]] and [[transitive relation|transitive]] as well. Hence for models of S5, ''R'' is an [[equivalence relation]], because ''R'' is reflexive, symmetric and transitive.

We can prove that these frames produce the same set of valid sentences as do the frames where all worlds can see all other worlds of ''W'' (''i.e.'', where ''R'' is a "total" relation). This gives the corresponding ''modal graph'' which is total complete (''i.e.'', no more edges (relations) can be added). For example, in any modal logic based on frame conditions:
: &lt;math&gt;w \models \Diamond P&lt;/math&gt; if and only if for some element ''u'' of ''G'', it holds that &lt;math&gt;u \models P&lt;/math&gt; and ''w R u''.

If we consider frames based on the total relation we can just say that
: &lt;math&gt;w \models \Diamond P&lt;/math&gt; if and only if for some element ''u'' of ''G'', it holds that &lt;math&gt;u \models P&lt;/math&gt;.
We can drop the accessibility clause from the latter stipulation because in such total frames it is trivially true of all ''w'' and ''u'' that ''w R u''. But note that this does not have to be the case in all S5 frames, which can still consist of multiple parts that are fully connected among themselves but still disconnected from each other.

All of these logical systems can also be defined axiomatically, as is shown in the next section. For example, in S5, the axioms &lt;math&gt;P \implies \Box\Diamond P&lt;/math&gt;, &lt;math&gt;\Box P \implies \Box\Box P&lt;/math&gt; and &lt;math&gt;\Box P \implies P&lt;/math&gt; (corresponding to ''symmetry'', ''transitivity'' and ''reflexivity'', respectively) hold, whereas at least one of these axioms does not hold in each of the other, weaker logics.

===Axiomatic systems===
The first formalizations of modal logic were axiomatic. Numerous variations with very different properties have been proposed since [[C. I. Lewis]] began working in the area in 1910. [[George Edward Hughes|Hughes]] and [[Max John Cresswell|Cresswell]] (1996), for example, describe 42 [[normal modal logic|normal]] and 25 non-normal modal logics. Zeman (1973) describes some systems Hughes and Cresswell omit.

Modern treatments of modal logic begin by augmenting the [[propositional calculus]] with two unary operations, one denoting "necessity" and the other "possibility". The notation of [[Clarence Irving Lewis|C. I. Lewis]], much employed since, denotes "necessarily ''p''" by a prefixed "box" (□''p'') whose scope is established by parentheses. Likewise, a prefixed "diamond" (◇''p'') denotes "possibly ''p''". Regardless of notation, each of these operators is definable in terms of the other in classical modal logic:
* □''p'' (necessarily ''p'') is equivalent to {{math|¬◇¬''p''}} ("not possible that not-''p''")
* ◇''p'' (possibly ''p'') is equivalent to {{math|¬□¬''p''}} ("not necessarily not-''p''")
Hence □ and ◇ form a [[duality (mathematics)#Duality in logic and set theory|dual pair]] of operators.

In many modal logics, the necessity and possibility operators satisfy the following analogues of [[de Morgan's laws]] from [[Boolean algebra (logic)|Boolean algebra]]:

:"It is '''not necessary that''' ''X''" is [[Logical equivalence|logically equivalent]] to "It is '''possible that not''' ''X''".
:"It is '''not possible that''' ''X''" is logically equivalent to "It is '''necessary that not''' ''X''".

Precisely what axioms and rules must be added to the [[propositional calculus]] to create a usable system of modal logic is a matter of philosophical opinion, often driven by the theorems one wishes to prove; or, in computer science, it is a matter of what sort of computational or deductive system one wishes to model.  Many modal logics, known collectively as [[normal modal logic]]s, include the following rule and axiom:
* '''N''', '''Necessitation Rule''': If ''p'' is a [[theorem]] (of any system invoking '''N'''), then □''p'' is likewise a theorem.
* '''K''', '''Distribution Axiom''': {{math|□(''p'' → ''q'') → (□''p'' → □''q'').}}

The weakest [[normal modal logic]], named ''K'' in honor of [[Saul Kripke]], is simply the [[propositional calculus]] augmented by □, the rule '''N''', and the axiom '''K'''. ''K'' is weak in that it fails to determine whether a proposition can be necessary but only contingently necessary. That is, it is not a theorem of ''K'' that if □''p'' is true then □□''p'' is true, i.e., that necessary truths are "necessarily necessary". If such perplexities are deemed forced and artificial, this defect of ''K'' is not a great one. In any case, different answers to such questions yield different systems of modal logic.

Adding axioms to ''K'' gives rise to other well-known modal systems. One cannot prove in ''K'' that if "''p'' is necessary" then ''p'' is true. The axiom '''T''' remedies this defect:
*'''T''', '''Reflexivity Axiom''': {{math|□''p'' → ''p''}} (If ''p'' is necessary, then ''p'' is the case.) 
'''T''' holds in most but not all modal logics. Zeman (1973) describes a few exceptions, such as ''S1&lt;sup&gt;0&lt;/sup&gt;''.

Other well-known elementary axioms are:
*'''4''': &lt;math&gt; \Box p \to \Box \Box p&lt;/math&gt;
*'''B''': &lt;math&gt; p \to \Box \Diamond p&lt;/math&gt;
*'''D''': &lt;math&gt; \Box p \to \Diamond p&lt;/math&gt;
*'''5''': &lt;math&gt; \Diamond p \to \Box \Diamond p &lt;/math&gt;

These yield the systems (axioms in bold, systems in italics):
*''K'' := '''K''' + '''N'''
*''T'' := ''K'' + '''T'''
*''S4'' := ''T'' + '''4'''
*''S5'' :=  ''S4'' + '''5'''
*''D'' := ''K'' + '''D'''.
''K'' through ''S5'' form a nested hierarchy of systems, making up the core of [[normal modal logic]]. But specific rules or sets of rules may be appropriate for specific systems. For example, in deontic logic, &lt;math&gt; \Box p \to \Diamond p&lt;/math&gt; (If it ought to be that ''p'', then it is permitted that ''p'') seems appropriate, but we should probably not include that &lt;math&gt; p \to \Box \Diamond p&lt;/math&gt;. In fact, to do so is to commit the [[naturalistic fallacy]] (i.e. to state that what is natural is also good, by saying that if ''p'' is the case, ''p'' ought to be permitted).

The commonly employed system ''S5'' simply makes all modal truths necessary. For example, if ''p'' is possible, then it is "necessary" that ''p'' is possible. Also, if ''p'' is necessary, then it is necessary that ''p'' is necessary. Other systems of modal logic have been formulated, in part because ''S5'' does not describe every kind of modality of interest.

===Structural proof theory===
Sequent calculi and systems of natural deduction have been developed for several modal logics, but it has proven hard to combine generality with other features expected of good [[structural proof theories]], such as purity (the proof theory does not introduce extra-logical notions such as labels) and analyticity (the logical rules support a clean notion of [[analytic proof]]).  More complex calculi have been applied to modal logic to achieve generality.

===Decision methods===
[[Analytic tableaux]] provide the most popular decision method for modal logics.

==Alethic logic==
{{main|Alethic modality}}
Modalities of necessity and possibility are called ''alethic'' modalities.  They are also sometimes called ''special'' modalities, from the [[Latin]] ''species''. Modal logic was first developed to deal with these concepts, and only afterward was extended to others.  For this reason, or perhaps for their familiarity and simplicity, necessity and possibility are often casually treated as ''the'' subject matter of modal logic. Moreover, it is easier to make sense of relativizing necessity, e.g. to legal, physical, nomological, epistemic, and so on, than it is to make sense of relativizing other notions.

In [[classical modal logic]], a proposition is said to be
*'''possible''' if it is ''not necessarily false'' (regardless of whether it is actually true or actually false);
*'''necessary''' if it is ''not possibly false'' (i.e. true and necessarily true);
*'''contingent''' if it is ''not necessarily false'' and ''not necessarily true'' (i.e. possible but not necessarily true);
*'''impossible''' if it is ''not possibly true'' (i.e. false and necessarily false).

In classical modal logic, therefore, the notion of either possibility or necessity may be taken to be basic, where these other notions are defined in terms of it in the manner of [[De Morgan duality]]. [[Intuitionistic modal logic]] treats possibility and necessity as not perfectly symmetric.

For example, suppose that while walking to the convenience store we pass Friedrich's house, and observe that the lights are off. On the way back, we observe that they have been turned on.
* "Somebody or something turned the lights on" is ''necessary''.
* "Friedrich turned the lights on", "Friedrich's roommate Max turned the lights on" and "A burglar named Adolf broke into Friedrich's house and turned the lights on" are ''contingent''.
* All of the above statements are ''possible''.
* It is ''impossible'' that [[Socrates]] (who has been dead for over two thousand years) turned the lights on.
(Of course, this analogy does not apply alethic modality in a ''truly'' rigorous fashion; for it to do so, it would have to axiomatically make such statements as "human beings cannot rise from the dead", "Socrates was a human being and not an immortal vampire", and "we did not take hallucinogenic drugs which caused us to falsely believe the lights were on", ''ad infinitum''. Absolute certainty of truth or falsehood exists only in the sense of logically constructed abstract concepts such as "it is impossible to draw a triangle with four sides" and "all bachelors are unmarried".)

For those with difficulty with the concept of something being possible but not true, the meaning of these terms may be made more comprehensible by thinking of multiple "possible worlds" (in the sense of [[Gottfried Wilhelm Leibniz|Leibniz]]) or "alternate universes"; something "necessary" is true in all possible worlds, something "possible" is true in at least one possible world.  These "possible world semantics" are formalized with [[Kripke semantics]].

===Physical possibility===
Something is physically, or nomically, possible if it is permitted by the [[physical law|laws of physics]].{{citation needed|date=January 2016}} For example, current theory is thought to allow for there to be an [[atom]] with an [[atomic number]] of 126,&lt;ref&gt;{{cite news|title=Press release: Superheavy Element 114 Confirmed: A Stepping Stone to the Island of Stability|url=http://newscenter.lbl.gov/2009/09/24/114-confirmed/|work=Lawrence Berkeley National Laboratory|date=24 September 2009}}&lt;/ref&gt; even if there are no such atoms in existence.  In contrast, while it is logically possible (i.e. probably via [[Alcubierre drive]] or [[worm holes]]){{Clarify|date=February 2014}} to accelerate beyond the [[speed of light]],&lt;ref name="Feinberg67"&gt;{{cite journal |last=Feinberg |first=G. |year=1967 |title=Possibility of Faster-Than-Light Particles |journal=[[Physical Review]] |volume=159 |issue=5 |pages=1089–1105 |bibcode=1967PhRv..159.1089F |doi=10.1103/PhysRev.159.1089}} See also Feinberg's later paper: Phys. Rev. D 17, 1651 (1978)&lt;/ref&gt; modern science stipulates that it is not physically possible for material particles or information.&lt;ref&gt;{{cite journal | last = Einstein | first = Albert | authorlink = Albert Einstein | title = Zur Elektrodynamik bewegter Körper | journal = Annalen der Physik | volume = 17 | pages = 891–921 | date = 1905-06-30|bibcode = 1905AnP...322..891E |doi = 10.1002/andp.19053221004 | issue = 10 }}&lt;/ref&gt;

===Metaphysical possibility===
[[Philosophers]]{{who|date=April 2012}} ponder the properties that objects have independently of those dictated by scientific laws. For example, it might be metaphysically necessary, as some who advocate [[physicalism]] have thought, that all thinking beings have bodies&lt;ref&gt;{{cite web|last1=Stoljar|first1=Daniel|title=Physicalism|url=http://plato.stanford.edu/entries/physicalism/|website=The Stanford Encyclopedia of Philosophy|accessdate=16 December 2014}}&lt;/ref&gt; and can experience the passage of [[time]]. [[Saul Kripke]] has argued that every person necessarily has the parents they do have: anyone with different parents would not be the same person.&lt;ref&gt;Saul Kripke. ''Naming and Necessity''. Harvard University Press, 1980. pg 113&lt;/ref&gt;

Metaphysical possibility has been thought to be more restricting than bare logical possibility&lt;ref&gt;{{cite book|last1=Thomson|first1=Judith and Alex Byrne|title=Content and Modality : Themes from the Philosophy of Robert Stalnaker|date=2006|publisher=Oxford University Press|location=Oxford|page=107|url=https://books.google.com/books?id=JXeOkXnCwb8C&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false|accessdate=16 December 2014}}&lt;/ref&gt; (i.e., fewer things are metaphysically possible than are logically possible). However, its exact relation (if any) to logical possibility or to physical possibility is a matter of dispute. Philosophers{{who|date=April 2012}} also disagree over whether metaphysical truths are necessary merely "by definition", or whether they reflect some underlying deep facts about the world, or something else entirely.

==Epistemic logic==
{{Main|Epistemic logic}}

'''Epistemic modalities''' (from the Greek ''episteme'', knowledge), deal with the ''certainty'' of sentences.  The □ operator is translated as  "x knows that…", and the ◇ operator is translated as "For all x knows, it may be true that…"  In ordinary speech both metaphysical and epistemic modalities are often expressed in similar words; the following contrasts may help:

A person, Jones, might reasonably say ''both'': (1) "No, it is ''not'' possible that [[Bigfoot]] exists; I am quite certain of that"; ''and'', (2) "Sure, it's ''possible'' that Bigfoots could exist". What Jones means by (1) is that, given all the available information, there is no question remaining as to whether Bigfoot exists. This is an epistemic claim. By (2) he makes the ''metaphysical'' claim that it is ''possible for'' Bigfoot to exist, ''even though he does not'': there is no physical or biological reason that large, featherless, bipedal creatures with thick hair could not exist in the forests of North America (regardless of whether or not they do). Similarly, "it is possible for the person reading this sentence to be fourteen feet tall and named Chad" is ''metaphysically'' true (such a person would not somehow be prevented from doing so on account of their height and name), but not ''alethically'' true unless you match that description, and not ''epistemically'' true if it's known that fourteen-foot-tall human beings have never existed.

From the other direction, Jones might say, (3) "It is ''possible'' that [[Goldbach's conjecture]] is true; but also ''possible'' that it is false", and ''also'' (4) "if it ''is'' true, then it is necessarily true, and not possibly false". Here Jones means that it is ''epistemically possible'' that it is true or false, for all he knows (Goldbach's conjecture has not been proven either true or false), but if there ''is'' a proof (heretofore undiscovered), then it would show that it is not ''logically'' possible for Goldbach's conjecture to be false—there could be no set of numbers that violated it. Logical possibility is a form of ''alethic'' possibility; (4) makes a claim about whether it is possible (i.e., logically speaking) that a mathematical truth to have been false, but (3) only makes a claim about whether it is possible, for all Jones knows, (i.e., speaking of certitude) that the mathematical claim is specifically either true or false, and so again Jones does not contradict himself.  It is worthwhile to observe that Jones is not necessarily correct: It is possible (epistemically) that Goldbach's conjecture is both true and unprovable.&lt;ref&gt;See [[Goldbach's conjecture#Origins|Goldbach's conjecture – Origins]]&lt;/ref&gt;

Epistemic possibilities also bear on the actual world in a way that metaphysical possibilities do not. Metaphysical possibilities bear on ways the world ''might have been,'' but epistemic possibilities bear on the way the world ''may be'' (for all we know). Suppose, for example, that I want to know whether or not to take an umbrella before I leave. If you tell me "it is ''possible that'' it is raining outside" – in the sense of epistemic possibility – then that would weigh on whether or not I take the umbrella. But if you just tell me that "it is ''possible for'' it to rain outside" – in the sense of ''metaphysical possibility'' – then I am no better off for this bit of modal enlightenment.

Some features of epistemic modal logic are in debate. For example, if ''x'' knows that ''p'', does ''x'' know that it knows that ''p''? That is to say, should □''P'' → □□''P'' be an axiom in these systems? While the answer to this question is unclear,&lt;ref&gt;cf. [[Blindsight]] and [[Subliminal perception]] for negative empirical evidence&lt;/ref&gt; there is at least one axiom that is generally included in epistemic modal logic, because it is minimally true of all normal modal logics (see [[Modal logic#Axiomatic systems|the section on axiomatic systems]]):
* '''K''', ''Distribution Axiom'': &lt;math&gt; \Box (p \to q) \to (\Box p \to \Box q)&lt;/math&gt;.

It has been questioned whether the epistemic and alethic modalities should be considered distinct from each other. The criticism states that there is no real difference between "the truth in the world" (alethic) and "the truth in an individual's mind" (epistemic).&lt;ref&gt;{{cite book| last=Eschenroeder |first=Erin |author2=Sarah Mills |author3=Thao Nguyen |title=The Expression of Modality|editor=William Frawley|publisher=Mouton de Gruyter| date=2006-09-30 |series=The Expression of Cognitive Categories|pages=8–9|url=https://books.google.co.uk/books?id=72URszHq2SEC&amp;pg=PT18| isbn=3-11-018436-2 | accessdate=2010-01-03}}&lt;/ref&gt; An investigation has not found a single language in which alethic and epistemic modalities are formally distinguished, as by the means of a [[grammatical mood]].&lt;ref&gt;{{cite book|last=Nuyts|first=Jan|title=Epimestic Modality, Language, and Conceptualization: A Cognitive-pragmatic Perspective|publisher=John Benjamins Publishing Co|date=November 2000|series=Human Cognitive Processing|page=28|isbn=90-272-2357-2}}&lt;/ref&gt;

==Temporal logic==
{{Main|Temporal logic}}

Temporal logic is an approach to the semantics of expressions with [[Grammatical tense|tense]], that is, expressions with qualifications of when.  Some expressions, such as  '2 + 2 = 4', are true at all times, while tensed expressions such as 'John is happy' are only true sometimes.

In temporal logic, tense constructions are treated in terms of modalities, where a standard method for formalizing talk of time is to use ''two'' pairs of operators, one for the past and one for the future (P will just mean 'it is presently the case that P'). For example:

:'''F'''''P'' : It will sometimes be the case that ''P''
:'''G'''''P'' : It will always be the case that ''P''
:'''P'''''P'' : It was sometime the case that ''P''
:'''H'''''P'' : It has always been the case that ''P''

There are then at least three modal logics that we can develop. For example, we can stipulate that,

:&lt;math&gt; \Diamond P &lt;/math&gt; = ''P'' is the case at some time ''t''
:&lt;math&gt; \Box P &lt;/math&gt; = ''P'' is the case at every time ''t''

Or we can trade these operators to deal only with the future (or past). For example,

:&lt;math&gt; \Diamond_1 P &lt;/math&gt; = '''F'''''P''
:&lt;math&gt; \Box_1 P &lt;/math&gt; = '''G'''''P''

or,

:&lt;math&gt; \Diamond_2 P&lt;/math&gt; = ''P'' and/or '''F'''''P''
:&lt;math&gt; \Box_2 P &lt;/math&gt; = ''P'' and '''G'''''P''

The operators '''F''' and '''G''' may seem initially foreign, but they create [[normal modal logic|normal modal systems]]. Note that '''F'''''P'' is the same as ¬'''G'''¬''P''. We can combine the above operators to form complex statements. For example, '''P'''''P'' → □'''P'''''P'' says (effectively), ''Everything that is past and true is necessary''.

It seems reasonable to say that possibly it will rain tomorrow, and possibly it won't; on the other hand, since we can't change the past, if it is true that it rained yesterday, it probably isn't true that it may not have rained yesterday. It seems the past is "fixed", or necessary, in a way the future is not. This is sometimes referred to as [[accidental necessity]]. But if the past is "fixed", and everything that is in the future will eventually be in the past, then it seems plausible to say that future events are necessary too.

Similarly, the [[problem of future contingents]] considers the semantics of assertions about the future: is either of the propositions 'There will be a sea battle tomorrow', or 'There will not be a sea battle tomorrow' now true?  Considering this thesis led [[Aristotle]] to reject the [[principle of bivalence]] for assertions concerning the future.

Additional binary operators are also relevant to temporal logics, ''q.v.'' [[Linear Temporal Logic]].

Versions of temporal logic can be used in [[computer science]] to model computer operations and prove theorems about them. In one version, ◇''P'' means "at a future time in the computation it is possible that the computer state will be such that P is true"; □''P'' means "at all future times in the computation P will be true". In another version, ◇''P'' means "at the immediate next state of the computation, ''P'' might be true"; □''P'' means "at the immediate next state of the computation, P will be true". These differ in the choice of [[Accessibility relation]]. (P always means "P is true at the current computer state".) These two examples involve nondeterministic or not-fully-understood computations; there are many other modal logics specialized to different types of program analysis. Each one naturally leads to slightly different axioms.

==Deontic logic==
{{Main|Deontic logic}}

Likewise talk of morality, or of [[obligation]] and [[norm (philosophy)|norms]] generally, seems to have a modal structure.  The difference between "You must do this" and "You may do this" looks a lot like the difference between "This is necessary" and "This is possible".  Such logics are called ''[[deontic logic|deontic]]'', from the Greek for "duty".

Deontic logics commonly lack the axiom '''T''' semantically corresponding to the reflexivity of the accessibility relation in [[Kripke semantics]]: in symbols, &lt;math&gt;\Box\phi\to\phi&lt;/math&gt;. Interpreting □ as "it is obligatory that", '''T''' informally says that every obligation is true. For example, if it is obligatory not to kill others (i.e. killing is morally forbidden), then '''T''' implies that people actually do not kill others. The consequent is obviously false.

Instead, using [[Kripke semantics]], we say that though our own world does not realize all obligations, the worlds accessible to it do (i.e., '''T''' holds at these worlds). These worlds are called idealized worlds. ''P'' is obligatory with respect to our own world if at all idealized worlds accessible to our world, ''P'' holds. Though this was one of the first interpretations of the formal semantics, it has recently come under criticism.&lt;ref&gt;See, e.g., {{cite journal |first=Sven |last=Hansson |title=Ideal Worlds—Wishful Thinking in Deontic Logic |journal=Studia Logica |volume=82 |issue=3 |pages=329–336 |year=2006 |doi=10.1007/s11225-006-8100-3 }}&lt;/ref&gt;

One other principle that is often (at least traditionally) accepted as a deontic principle is ''D'', &lt;math&gt;\Box\phi\to\Diamond\phi&lt;/math&gt;, which corresponds to the seriality (or extendability or unboundedness) of the accessibility relation. It is an embodiment of the Kantian idea that "ought implies can". (Clearly the "can" can be interpreted in various senses, e.g. in a moral or alethic sense.)

===Intuitive problems with deontic logic===
When we try and formalize ethics with standard modal logic, we run into some problems. Suppose that we have a proposition ''K'': you have stolen some money, and another, ''Q'': you have stolen a small amount of money. Now suppose we want to express the thought that "if you have stolen some money, it ought to be a small amount of money". There are two likely candidates,
: (1) &lt;math&gt;(K \to \Box Q)&lt;/math&gt;
: (2) &lt;math&gt;\Box (K \to Q)&lt;/math&gt;

But (1) and ''K'' together entail □''Q'', which says that it ought to be the case that you have stolen a small amount of money. This surely isn't right, because you ought not to have stolen anything at all. And (2) doesn't work either: If the right representation of "if you have stolen some money it ought to be a small amount" is (2), then the right representation of (3) "if you have stolen some money then it ought to be a large amount" is &lt;math&gt;\Box (K \to (K \land \lnot Q))&lt;/math&gt;. Now suppose (as seems reasonable) that you ought not to steal anything, or &lt;math&gt;\Box \lnot K&lt;/math&gt;. But then we can deduce &lt;math&gt;\Box (K \to (K \land \lnot Q))&lt;/math&gt; via &lt;math&gt;\Box (\lnot K) \to \Box (K \to K \land \lnot K)&lt;/math&gt; and &lt;math&gt;\Box (K \land \lnot K \to (K \land \lnot Q)) &lt;/math&gt; (the [[contrapositive]] of &lt;math&gt;Q \to K&lt;/math&gt;); so sentence (3) follows from our hypothesis (of course the same logic shows sentence (2)). But that can't be right, and is not right when we use natural language. Telling someone they should not steal certainly does not imply that they should steal large amounts of money if they do engage in theft.&lt;ref&gt;Ted Sider's ''Logic for Philosophy'', unknown page. http://tedsider.org/books/lfp.html&lt;/ref&gt;

== Doxastic logic ==
{{Main|Doxastic logic}}

''Doxastic logic'' concerns the logic of belief (of some set of agents). The term doxastic is derived from the [[ancient Greek]] ''doxa'' which means "belief". Typically, a doxastic logic uses □, often written "B", to mean "It is believed that", or when relativized to a particular agent s, "It is believed by s that".

==Other modal logics==
{{See also|Intensional logic}}
Significantly, modal logics can be developed to accommodate most of these idioms; it is the fact of their common logical structure (the use of "intensional" sentential operators) that make them all varieties of the same thing.

== The ontology of possibility ==
{{Further| Accessibility relation|Possible worlds}}
In the most common interpretation of modal logic, one considers "[[logically possible]] worlds". If a statement is true in all [[possible worlds]], then it is a necessary truth. If a statement happens to be true in our world, but is not true in all possible worlds, then it is a contingent truth. A statement that is true in some possible world (not necessarily our own) is called a possible truth.

Under this "possible worlds idiom," to maintain that Bigfoot's existence is possible but not actual, one says, "There is some possible world in which Bigfoot exists; but in the actual world, Bigfoot does not exist". However, it is unclear what this claim commits us to. Are we really alleging the existence of possible worlds, every bit as real as our actual world, just not actual? [[Saul Kripke]] believes that 'possible world' is something of a misnomer – that the term 'possible world' is just a useful way of visualizing the concept of possibility.&lt;ref&gt;Kripke, Saul. ''Naming and Necessity''. (1980; Harvard UP), pp. 43–5.&lt;/ref&gt; For him, the sentences "you could have rolled a 4 instead of a 6" and "there is a possible world where you rolled a 4, but you rolled a 6 in the actual world" are not significantly different statements, and neither commit us to the existence of a possible world.&lt;ref&gt;Kripke, Saul. ''Naming and Necessity''. (1980; Harvard UP), pp. 15–6.&lt;/ref&gt; [[David Lewis (philosopher)|David Lewis]], on the other hand, made himself notorious by biting the bullet, asserting that all merely possible worlds are as real as our own, and that what distinguishes our world as ''actual'' is simply that it is indeed our world – ''[[Indexicality|this]]'' world.&lt;ref&gt;David Lewis, ''On the Plurality of Worlds'' (1986; Blackwell)&lt;/ref&gt; That position is a major tenet of "[[modal realism]]". Some philosophers decline to endorse any version of modal realism, considering it ontologically extravagant, and prefer to seek various ways to paraphrase away these ontological commitments. [[Robert Merrihew Adams|Robert Adams]] holds that 'possible worlds' are better thought of as 'world-stories', or consistent sets of propositions. Thus, it is possible that you rolled a 4 if such a state of affairs can be described coherently.&lt;ref&gt;Adams, Robert M. [https://www.jstor.org/stable/2214751 ''Theories of Actuality'']. Noûs, Vol. 8, No. 3 (Sep., 1974), particularly pp. 225–31.&lt;/ref&gt;

Computer scientists will generally pick a highly specific interpretation of the modal operators specialized to the particular sort of computation being analysed.  In place of "all worlds", you may have "all possible next states of the computer", or "all possible future states of the computer".

==Further applications==
Modal logics have begun to be used in areas of the humanities such as literature, poetry, art and history.&lt;ref&gt;See http://www.estherlederberg.com/EImages/Extracurricular/Dickens%20Universe/Counter%20Factuals.html&lt;/ref&gt;&lt;ref&gt;Andrew H. Miller, "Lives Unled in Realist Fiction", Representations 98, Spring 2007, The Regents of the University of California, {{ISSN|0734-6018}}, pp. 118–134&lt;/ref&gt;&lt;ref&gt;See also http://www.estherlederberg.com/EImages/Extracurricular/Dickens%20Universe/Page%2017%20CounterFactuals.html&lt;/ref&gt;

==Controversies==
[[Nicholas Rescher]] has argued that [[Bertrand Russell]] rejected modal logic, and that this rejection led to the theory of modal logic languishing for decades.&lt;ref&gt;{{cite book|last=Rescher|first=Nicholas|title=Bertrand Russell Memorial Volume|year=1979|publisher=George Allen and Unwin|location=London|pages=146|editor=George W. Roberts|chapter=Russell and Modal Logic}}&lt;/ref&gt; However, [[Jan Dejnozka]] has argued against this view, stating that a modal system which Dejnozka calls ''MDL'' is described in Russell's works, although Russell did believe the concept of modality to "come from confusing propositions with [[propositional function]]s," as he wrote in ''The Analysis of Matter''.&lt;ref&gt;{{cite journal| last=Dejnozka |first=Jan|title=Ontological Foundations of Russell's Theory of Modality|journal=Erkenntnis| year=1990| volume=32| pages=383–418 |url=http://www.members.tripod.com/~Jan_Dejnozka/onto_found_russell_modality.pdf|accessdate=2012-10-22|doi=10.1007/bf00216469}}; quote is cited from {{cite book|last=Russell|first=Bertrand|title=The Analysis of Matter|year=1927|pages=173}}&lt;/ref&gt;

[[Arthur Norman Prior]] warned [[Ruth Barcan Marcus]] to prepare well in the debates concerning quantified modal logic with [[Willard Van Orman Quine]], due to the biases against modal logic.&lt;ref&gt;[[Ruth Barcan Marcus]], ''Modalities: Philosophical Essays'', Oxford University Press, 1993, p. x.&lt;/ref&gt;

==See also==
{{Portal|Logic|Thinking}}
{{div col|colwidth=15em}}
* [[Accessibility relation]]
* [[Conceptual necessity]]
* [[Counterpart theory]]
* [[David Kellogg Lewis]]
* [[De dicto and de re]]
* [[Description logic]]
* [[Doxastic logic]]
* [[Dynamic logic (modal logic)|Dynamic logic]]
* [[Enthymeme]]
* [[Hybrid logic]]
* [[Interior algebra]]
* [[Interpretability logic]]
* [[Kripke semantics]]
* [[Metaphysical necessity]]
* [[Modal verb]]
* [[Multi-valued logic]]
* [[Possible worlds]]
* [[Provability logic]]
* [[Regular modal logic]]
* [[Relevance logic]]
* [[Research Materials: Max Planck Society Archive]]
* [[Rhetoric]]
* [[Strict conditional]]
* [[Two dimensionalism]]
{{div col end}}

==Notes==
{{Reflist|30em}}

==References==
* ''This article includes material from the'' [[Free On-line Dictionary of Computing]], ''used with [[Wikipedia:Foldoc license|permission]] under the'' [[GFDL]].
* Barcan-Marcus, Ruth JSL 11 (1946) and JSL 112 (1947) and "Modalities", OUP, 1993, 1995.
* Beth, Evert W., 1955. "Semantic entailment and formal derivability", Mededlingen van de Koninklijke Nederlandse Akademie van Wetenschappen, Afdeling Letterkunde, N.R. Vol 18, no 13, 1955, pp 309–42. Reprinted in Jaakko Intikka (ed.) The Philosophy of Mathematics, Oxford University Press, 1969 (Semantic Tableaux proof methods).
* Beth, Evert W., "[https://books.google.com/books?id=IE1FBgAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Formal Methods: An Introduction to Symbolic Logic and to the Study of Effective Operations in Arithmetic and Logic]", D. Reidel, 1962 (Semantic Tableaux proof methods).
* Blackburn, P.; [[Johan van Benthem (logician)|van Benthem, J.]]; and Wolter, Frank; Eds. (2006) ''[http://www.csc.liv.ac.uk/~frank/MLHandbook/ Handbook of Modal Logic]''. North Holland.
* Blackburn, Patrick; de Rijke, Maarten; and Venema, Yde (2001) ''Modal Logic''. Cambridge University Press. {{ISBN|0-521-80200-8}}
* Chagrov, Aleksandr; and Zakharyaschev, Michael (1997) ''Modal Logic''. Oxford University Press. {{ISBN|0-19-853779-4}}
* Chellas, B. F. (1980) ''Modal Logic: An Introduction''. Cambridge University Press. {{ISBN|0-521-22476-4}}
* [[Max Cresswell|Cresswell, M. J.]] (2001) "Modal Logic" in Goble, Lou; Ed., ''The Blackwell Guide to Philosophical Logic''. Basil Blackwell: 136–58. {{ISBN|0-631-20693-0}}
* Fitting, Melvin; and Mendelsohn, R. L. (1998) ''First Order Modal Logic''. Kluwer. {{ISBN|0-7923-5335-8}}
* [[James Garson]] (2006) ''Modal Logic for Philosophers''. Cambridge University Press. {{ISBN|0-521-68229-0}}. A thorough introduction to modal logic, with coverage of various derivation systems and a distinctive approach to the use of diagrams in aiding comprehension.
* Girle, Rod (2000) ''Modal Logics and Philosophy''. Acumen (UK). {{ISBN|0-7735-2139-9}}. Proof by [[analytic tableau|refutation trees]]. A good introduction to the varied interpretations of modal logic.
* [http://www.mcs.vuw.ac.nz/~rob/ Goldblatt, Robert] (1992) "Logics of Time and Computation", 2nd ed., CSLI Lecture Notes No. 7. University of Chicago Press.
* —— (1993) ''Mathematics of Modality'', CSLI Lecture Notes No. 43. University of Chicago Press.
* —— (2006) "[http://www.mcs.vuw.ac.nz/~rob/papers/modalhist.pdf Mathematical Modal Logic: a View of its Evolution]", in Gabbay, D. M.; and Woods, John; Eds., ''Handbook of the History of Logic, Vol. 6''. Elsevier BV.
* Goré, Rajeev (1999) "Tableau Methods for Modal and Temporal Logics" in D'Agostino, M.; Gabbay, D.; Haehnle, R.; and Posegga, J.; Eds., ''Handbook of Tableau Methods''. Kluwer: 297–396.
* Hughes, G. E., and Cresswell, M. J. (1996) ''A New Introduction to Modal Logic''. Routledge. {{ISBN|0-415-12599-5}}
* [[Bjarni Jónsson|Jónsson, B.]] and [[Alfred Tarski|Tarski, A.]], 1951–52, "Boolean Algebra with Operators I and II", ''American Journal of Mathematics 73'': 891–939 and ''74'': 129–62.
* Kracht, Marcus (1999) ''Tools and Techniques in Modal Logic'', Studies in Logic and the Foundations of Mathematics No. 142. North Holland.
* [[John Lemmon|Lemmon, E. J.]] (with [[Dana Scott|Scott, D.]]) (1977) ''An Introduction to Modal Logic'', American Philosophical Quarterly Monograph Series, no. 11 (Krister Segerberg, series ed.). Basil Blackwell.
* [[Clarence Irving Lewis|Lewis, C. I.]] (with [[Cooper Harold Langford|Langford, C. H.]]) (1932). ''Symbolic Logic''. Dover reprint, 1959.
* [[Arthur Prior|Prior, A. N.]] (1957) ''Time and Modality''. Oxford University Press.
* Snyder, D. Paul "Modal Logic and its applications", Van Nostrand Reinhold Company, 1971 (proof tree methods).
* Zeman, J. J. (1973) ''[http://www.clas.ufl.edu/users/jzeman/modallogic/ Modal Logic.]'' Reidel. Employs [[Polish notation]].
* History of logic, Encyclopædia Britannica.

==Further reading==
* Ruth Barcan Marcus ''Modalities'', OUP 1993.
* D.M. Gabbay, A. Kurucz, F. Wolter and M. Zakharyaschev, ''Many-Dimensional Modal Logics: Theory and Applications'', Elsevier, Studies in Logic and the Foundations of Mathematics, volume 148, 2003, {{ISBN|0-444-50826-0}}. Covers many varieties of modal logics, e.g. temporal, epistemic, dynamic, description, spatial from a unified perspective with emphasis on computer science aspects, e.g. decidability and complexity.
* Andrea Borghini, ''A Critical Introduction to the Metaphysics of Modality'', New York, Bloomsbury, 2016.

==External links==
* [[Internet Encyclopedia of Philosophy]]:
** "[http://www.iep.utm.edu/modal-lo Modal Logic: A Contemporary View]" – by Johan van Benthem.
** "[http://www.iep.utm.edu/cmlogic Rudolf Carnap's Modal Logic]" – by MJ Cresswell.
* [[Stanford Encyclopedia of Philosophy]]:
** "[http://plato.stanford.edu/entries/logic-modal Modal logic]" – by [[James Garson]].
** "[http://plato.stanford.edu/entries/logic-provability/ Provability Logic]" – by Rineke Verbrugge.
* [[Edward N. Zalta]], 1995, "[http://mally.stanford.edu/notes.pdf Basic Concepts in Modal Logic.]"
* [[John McCarthy (computer scientist)|John McCarthy]], 1996, "[http://www-formal.stanford.edu/jmc/mcchay69/node22.html Modal Logic.]"
* [http://molle.sourceforge.net/ Molle] a Java prover for experimenting with modal logics
* Suber, Peter, 2002, "[http://www.earlham.edu/~peters/courses/logsys/nonstbib.htm#modal Bibliography of Modal Logic.]"
* [http://www.cc.utah.edu/~nahaj/logic/structures/systems/index.html List of Logic Systems] List of many modal logics with sources, by John Halleck.
* [http://aiml.net/ Advances in Modal Logic.] Biannual international conference and book series in modal logic.
* [http://teachinglogic.imag.fr/TableauxS4 S4prover] A tableaux prover for S4 logic
* "[http://www.labri.fr/perso/moot/talks/TopologyNotes.pdf Some Remarks on Logic and Topology]" – by Richard Moot; exposits a [[topology|topological]] [[semantics]] for the modal logic S4.
* [http://www.irit.fr/Lotrec/ LoTREC] The most generic prover for modal logics  from IRIT/Toulouse University

{{Non-classical logic}}

[[Category:Non-classical logic]]
[[Category:Modal logic| ]]
[[Category:Philosophical logic]]
[[Category:Modality]]</text>
      <sha1>k96owlofp10zignr6hfyfggejwmik0l</sha1>
    </revision>
  </page>
  <page>
    <title>Non-compact stencil</title>
    <ns>0</ns>
    <id>18555870</id>
    <revision>
      <id>509359853</id>
      <parentid>227839750</parentid>
      <timestamp>2012-08-27T03:23:21Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>stub sort</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="957">[[Image:NonCompactStencil.svg|thumb|right|150px|A 2D non-compact stencil]]
In numerical mathematics, a '''non-compact [[Stencil (numerical analysis)|stencil]]''' is a type of [[discretization]] method, where any node surrounding the node of interest may be used in the calculation. A non-compact stencil's [[computational time]] increases with an increase of layers of nodes used. Non-compact stencils may be compared to [[Compact stencil]]s.&lt;ref&gt;W. F. Spotz. High-Order Compact Finite Difference Schemes for Computational Mechanics. PhD thesis, University of Texas at Austin, Austin, TX, 1995.&lt;/ref&gt;&lt;ref&gt;Communications in Numerical Methods in Engineering, Copyright © 2008 John Wiley &amp; Sons, Ltd.&lt;/ref&gt;

==See also==
*[[Five-point stencil]]

== Notes ==
{{reflist}}

== External links ==
*[http://www.cisl.ucar.edu/css/staff/spotz/research/hoc.html#stencil High-Order Compact Schemes]

[[Category:Numerical differential equations]]


{{applied-math-stub}}</text>
      <sha1>orqp3y5plx9rtoz68hbcmzd94qdqz78</sha1>
    </revision>
  </page>
  <page>
    <title>Particle filter</title>
    <ns>0</ns>
    <id>1396948</id>
    <revision>
      <id>868197070</id>
      <parentid>868187358</parentid>
      <timestamp>2018-11-10T17:09:26Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Bibliography */clean up, replaced: IEEE Trans. on Pattern Analysis and Machine Intelligence → IEEE Transactions on Pattern Analysis and Machine Intelligence</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="85608">{{About|mathematical algorithms|devices to filter particles from air|Air filter}}
{{technical|date=August 2012}}

'''Particle filters''' or '''Sequential Monte Carlo''' (SMC) methods are a set of [[Genetic Algorithm|genetic]], [[Monte Carlo algorithm|Monte Carlo]] algorithms used to solve [[Filtering problem (stochastic processes)|filtering problems]] arising in [[signal processing]] and [[Bayesian inference|Bayesian statistical inference]]. The '''[[Filtering problem (stochastic processes)|filtering problem]]''' consists of estimating the internal states in [[dynamical systems]] when partial observations are made, and random perturbations are present in the sensors as well as in the dynamical system. The objective is to compute the posterior distributions of the states of some [[Markov process]], given some noisy and partial observations.  The term "particle filters" was first coined in 1996 by Del Moral&lt;ref name="dm962"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|title = Non Linear Filtering: Interacting Particle Solution.|journal = Markov Processes and Related Fields|date = 1996|volume = 2|issue = 4|pages = 555–580|url = http://people.bordeaux.inria.fr/pierre.delmoral/delmoral96nonlinear.pdf}}&lt;/ref&gt; in reference to [[mean field particle methods|mean field interacting particle methods]] used in fluid mechanics since the beginning of the 1960s. The terminology "sequential Monte Carlo" was proposed by Liu and Chen in 1998.

Particle filtering uses a genetic mutation-selection sampling approach, with a set of particles (also called samples) to represent the [[posterior distribution]] of some [[stochastic process]] given noisy and/or partial observations. The state-space model can be nonlinear and the initial state and noise distributions can take any form required. Particle filter techniques provide a well-established methodology&lt;ref name="dm962" /&gt;&lt;ref name=":22"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|title = Measure Valued Processes and Interacting Particle Systems. Application to Non Linear Filtering Problems|journal = Annals of Applied Probability|date = 1998|edition = Publications du Laboratoire de Statistique et Probabilités, 96-15 (1996)|volume = 8|issue = 2|pages = 438–495|url = http://projecteuclid.org/download/pdf_1/euclid.aoap/1028903535|doi = 10.1214/aoap/1028903535}}&lt;/ref&gt;&lt;ref name=":1"&gt;{{Cite book|title = Feynman-Kac formulae. Genealogical and interacting particle approximations.|last = Del Moral|first = Pierre|publisher = Springer. Series: Probability and Applications|year = 2004|isbn = 978-0-387-20268-6|location = https://www.springer.com/gp/book/9780387202686|pages = 556}}&lt;/ref&gt; for generating samples from the required distribution without requiring assumptions about the state-space model or the state distributions. However, these methods do not perform well when applied to very high-dimensional systems.

Particle filters implement the '''prediction-updating''' transitions of the filtering equation directly by using a genetic type '''mutation-selection''' particle algorithm. The samples from the distribution are represented by a set of particles; each particle has a likelihood weight assigned to it that represents the probability of that particle being sampled from the probability density function. Weight disparity leading to weight collapse is a common issue encountered in these filtering algorithms; however it can be mitigated by including a resampling step before the weights become too uneven. Several adaptive resampling criteria can be used, including the variance of the weights and the relative entropy with respect to the uniform distribution.&lt;ref name=":0"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Doucet|first2 = Arnaud|last3 = Jasra|first3 = Ajay|title = On Adaptive Resampling Procedures for Sequential Monte Carlo Methods|journal = Bernoulli|date = 2012|volume = 18|issue = 1|pages = 252–278|url = http://hal.inria.fr/docs/00/33/25/83/PDF/RR-6700.pdf|doi = 10.3150/10-bej335}}&lt;/ref&gt; In the resampling step, the particles with negligible weights are replaced by new particles in the proximity of the particles with higher weights.

From the statistical and probabilistic point of view, particle filters can be interpreted as [[Mean field particle methods|mean field particle]] interpretations of [[Feynman–Kac formula|Feynman-Kac]] probability measures.&lt;ref name="dp042"&gt;{{cite book|last = Del Moral|first = Pierre|title = Feynman-Kac formulae. Genealogical and interacting particle approximations|year = 2004|publisher = Springer|quote = Series: Probability and Applications|url = https://www.springer.com/mathematics/probability/book/978-0-387-20268-6|pages = 575}}&lt;/ref&gt;&lt;ref name="dmm002"&gt;{{cite book|last1 = Del Moral|first1 = Pierre|last2 = Miclo|first2 = Laurent|title = Branching and Interacting Particle Systems Approximations of Feynman-Kac Formulae with Applications to Non-Linear Filtering.|journal = Lecture Notes in Mathematics|date = 2000|volume = 1729|pages = 1–145|url = http://archive.numdam.org/ARCHIVE/SPS/SPS_2000__34_/SPS_2000__34__1_0/SPS_2000__34__1_0.pdf|doi = 10.1007/bfb0103798}}&lt;/ref&gt;&lt;ref name="dmm00m2"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Miclo|first2 = Laurent|title = A Moran particle system approximation of Feynman-Kac formulae.|journal = Stochastic Processes and their Applications|date = 2000|volume = 86|issue = 2|pages = 193–216|doi = 10.1016/S0304-4149(99)00094-0|url = http://www.sciencedirect.com/science/article/pii/S0304414999000940}}&lt;/ref&gt;&lt;ref name="dp13" /&gt;&lt;ref&gt;{{Cite journal|title = Particle methods: An introduction with applications | journal= ESAIM: Proc.| doi = 10.1051/proc/201444001 | volume=44| pages=1–46}}&lt;/ref&gt; These particle integration techniques were developed in [[molecular chemistry]] and computational physics by [[Ted Harris (mathematician)|Theodore E. Harris]] and Herman Kahn in 1951, Marshall N. Rosenbluth and Arianna W. Rosenbluth in 1955&lt;ref name=":5"&gt;{{cite journal|last1 = Rosenbluth|first1 = Marshall, N.|last2 = Rosenbluth|first2 = Arianna, W.|title = Monte-Carlo calculations of the average extension of macromolecular chains|journal = J. Chem. Phys.|date = 1955|volume = 23|pages = 356–359|doi=10.1063/1.1741967|bibcode = 1955JChPh..23..356R}}&lt;/ref&gt;  and more recently by Jack H. Hetherington in 1984.&lt;ref name="h84" /&gt; In computational physics, these Feynman-Kac type path particle integration methods are also used in [[Quantum Monte Carlo]], and more specifically [[Diffusion Monte Carlo|Diffusion Monte Carlo methods]].&lt;ref name="dm-esaim032"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|title = Particle approximations of Lyapunov exponents connected to Schrödinger operators and Feynman-Kac semigroups|journal = ESAIM Probability &amp; Statistics|date = 2003|volume = 7|pages = 171–208|url = http://journals.cambridge.org/download.php?file=%2FPSS%2FPSS7%2FS1292810003000016a.pdf&amp;code=a0dbaa7ffca871126dc05fe2f918880a|doi = 10.1051/ps:2003001}}&lt;/ref&gt;&lt;ref name="caffarel12"&gt;{{cite journal|last1 = Assaraf|first1 = Roland|last2 = Caffarel|first2 = Michel|last3 = Khelif|first3 = Anatole|title = Diffusion Monte Carlo Methods with a fixed number of walkers|journal = Phys. Rev. E|url = http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|date = 2000|volume = 61|pages = 4566–4575|doi = 10.1103/physreve.61.4566|bibcode = 2000PhRvE..61.4566A|deadurl = yes|archiveurl = https://web.archive.org/web/20141107015724/http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|archivedate = 2014-11-07|df = }}&lt;/ref&gt;&lt;ref name="caffarel22"&gt;{{cite journal|last1 = Caffarel|first1 = Michel|last2 = Ceperley|first2 = David|last3 = Kalos|first3 = Malvin|title = Comment on Feynman-Kac Path-Integral Calculation of the Ground-State Energies of Atoms|journal = Phys. Rev. Lett.|date = 1993|volume = 71|doi = 10.1103/physrevlett.71.2159|bibcode = 1993PhRvL..71.2159C|pages=2159|pmid=10054598}}&lt;/ref&gt; Feynman-Kac interacting particle methods are also strongly related to [[Genetic algorithm|mutation-selection genetic algorithms]] currently used in [[Evolutionary computation|evolutionary computing]] to solve complex optimization problems.

The particle filter methodology is used to solve [[Hidden Markov model|Hidden Markov Model]] (HMM) and [[nonlinear filter]]ing problems.  With the notable exception of linear-Gaussian signal-observation models ([[Kalman filter]]) or wider classes of models (Benes filter&lt;ref&gt;{{Cite journal|title = Asymptotic stability of beneš filters|journal = Stochastic Analysis and Applications|date = January 1, 1999|issn = 0736-2994|pages = 1053–1074|volume = 17|issue = 6|doi = 10.1080/07362999908809648|first = D. L.|last = Ocone}}&lt;/ref&gt;) Mireille Chaleyat-Maurel and Dominique Michel proved in 1984 that the sequence of posterior distributions of the random states of the signal given the observations (a.k.a. optimal filter)  have no finitely recursive recursion.&lt;ref&gt;{{Cite journal|title = Des resultats de non existence de filtre de dimension finie|journal = Stochastics|date = January 1, 1984|issn = 0090-9491|pages = 83–102|volume = 13|issue = 1–2|doi = 10.1080/17442508408833312|first = Mireille Chaleyat|last = Maurel|first2 = Dominique|last2 = Michel}}&lt;/ref&gt; Various numerical methods based on fixed grid approximations, [[Markov chain Monte Carlo|Markov Chain Monte Carlo]] techniques (MCMC), conventional linearization, [[extended Kalman filter]]s, or determining the best linear system (in expect cost-error sense) have never really coped with large scale systems, unstable processes or when the nonlinearities are not sufficiently smooth.

Particle filters and Feynman-Kac particle methodologies find application in [[signal processing|signal and image processing]], [[Bayesian inference]], [[machine learning]], [[Rare Event Sampling|risk analysis and rare event sampling]], [[engineering]] [[robotics|and robotics]], [[artificial intelligence]], [[bioinformatics]], [[phylogenetics]], [[computational science]], [[Economics]] [[financial mathematics|and]] [[mathematical finance]], [[molecular chemistry]], [[computational physics]], [[Pharmacokinetics|pharmacokinetic]] and other fields.

==History==

=== Heuristic like algorithms ===
From the statistical and probabilistic viewpoint, particle filters belong to the class of [[Branching process|branching]]/[[genetic algorithms|genetic type algorithms]], and [[Mean field particle methods|mean field type interacting particle methodologies.]] The interpretation of these particle methods depends on the scientific discipline. In [[Evolutionary computation|Evolutionary Computing]], [[Mean field particle methods|mean field genetic type particle]] methodologies are often used as a heuristic and natural search algorithms (a.k.a. [[Metaheuristic]]). In [[computational physics]] and [[molecular chemistry]] they are used to solve Feynman-Kac path integration problems, or they compute Boltzmann-Gibbs measures, top eigenvalues and ground states of [[Schrödinger equation|Schrödinger]] operators. In [[Biology]] and [[Genetics]] they also represent the evolution of a population of individuals or genes in some environment.

The origins of mean field type evolutionary computational techniques can be traced to 1950 and 1954 with the seminal work of [[Alan Turing]] on genetic type mutation-selection learning machines&lt;ref&gt;{{cite journal|last1 = Turing|first1 = Alan M.|title = Computing machinery and intelligence|journal = Mind|volume = LIX|issue = 238|pages = 433–460|doi = 10.1093/mind/LIX.236.433 |url = http://mind.oxfordjournals.org/content/LIX/236/433}}&lt;/ref&gt; and the articles by [[Nils Aall Barricelli]] at the [[Institute for Advanced Study]] in [[Princeton, New Jersey]].&lt;ref&gt;{{cite journal|last = Barricelli|first = Nils Aall|year = 1954|authorlink = Nils Aall Barricelli|title = Esempi numerici di processi di evoluzione|journal = Methodos|pages = 45–68}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last = Barricelli|first = Nils Aall|year = 1957|authorlink = Nils Aall Barricelli|title = Symbiogenetic evolution processes realized by artificial methods|journal = Methodos|pages = 143–182}}&lt;/ref&gt; The first trace of particle filters in [[Statistics|statistical methodology]] dates back to the mid-50's; the 'Poor Man's Monte Carlo',&lt;ref&gt;{{Cite journal|title = Poor Man's Monte Carlo |jstor = 2984008 | volume=16 | pages=23–38}}&lt;/ref&gt; that was proposed by Hammersley et al., in 1954, contained hints of the genetic type particle filtering methods used today.  In 1963, [[Nils Aall Barricelli]] simulated a genetic type algorithm to mimic the ability of individuals to play a simple game.&lt;ref&gt;{{cite journal|last = Barricelli|first = Nils Aall|year = 1963|title = Numerical testing of evolution theories. Part II. Preliminary tests of performance, symbiogenesis and terrestrial life|journal = Acta Biotheoretica|issue = 16|pages = 99–126}}&lt;/ref&gt; In [[Evolutionary computation|evolutionary computing]] literature, genetic type mutation-selection algorithms became popular through the seminal work of John Holland in the early 1970s, and particularly his book&lt;ref&gt;{{Cite web|title = Adaptation in Natural and Artificial Systems {{!}} The MIT Press|url = https://mitpress.mit.edu/index.php?q=books/adaptation-natural-and-artificial-systems|website = mitpress.mit.edu|accessdate = 2015-06-06}}&lt;/ref&gt; published in 1975.

In Biology and [[Genetics]], the Australian geneticist [[Alex Fraser (scientist)|Alex Fraser]] also published in 1957 a series of papers on the genetic type simulation of [[artificial selection]] of organisms.&lt;ref&gt;{{cite journal|last = Fraser|first = Alex|authorlink = Alex Fraser (scientist)|year = 1957|title = Simulation of genetic systems by automatic digital computers. I. Introduction|journal = Aust. J. Biol. Sci.|volume = 10|pages = 484–491}}&lt;/ref&gt; The computer simulation of evolution by biologists became more common in the early 1960s, and the methods were described in books by Fraser and Burnell (1970)&lt;ref&gt;{{cite book|last = Fraser|first = Alex|authorlink = Alex Fraser (scientist)|first2 = Donald|last2 = Burnell|year = 1970|title = Computer Models in Genetics|publisher = McGraw-Hill|location = New York|isbn = 0-07-021904-4}}&lt;/ref&gt; and Crosby (1973).&lt;ref&gt;{{cite book|last = Crosby|first = Jack L.|year = 1973|title = Computer Simulation in Genetics|publisher = John Wiley &amp; Sons|location = London|isbn = 0-471-18880-8}}&lt;/ref&gt; Fraser's simulations included all of the essential elements of modern mutation-selection genetic particle algorithms.

From the mathematical viewpoint, the conditional distribution of the random states of a signal given some partial and noisy observations is described by a Feynman-Kac probability on the random trajectories of the signal weighted by a sequence of likelihood potential functions.&lt;ref name="dp042" /&gt;&lt;ref name="dmm002" /&gt; [[Quantum Monte Carlo]], and more specifically [[Diffusion Monte Carlo|Diffusion Monte Carlo methods]] can also be interpreted as a mean field genetic type particle approximation of Feynman-Kac path integrals.&lt;ref name="dp042" /&gt;&lt;ref name="dmm002" /&gt;&lt;ref name="dmm00m2" /&gt;&lt;ref name="h84"&gt;{{cite journal|last1 = Hetherington|first1 = Jack, H.|title = Observations on the statistical iteration of matrices|journal = Phys. Rev. A|date = 1984|volume = 30|issue = 2713|doi = 10.1103/PhysRevA.30.2713|url = http://journals.aps.org/pra/abstract/10.1103/PhysRevA.30.2713|pages = 2713–2719|bibcode=1984PhRvA..30.2713H}}&lt;/ref&gt;&lt;ref name="dm-esaim032" /&gt;&lt;ref name="caffarel1"&gt;{{cite journal|last1 = Assaraf|first1 = Roland|last2 = Caffarel|first2 = Michel|last3 = Khelif|first3 = Anatole|title = Diffusion Monte Carlo Methods with a fixed number of walkers|journal = Phys. Rev. E|url = http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|date = 2000|volume = 61|pages = 4566–4575|doi = 10.1103/physreve.61.4566|bibcode = 2000PhRvE..61.4566A|deadurl = yes|archiveurl = https://web.archive.org/web/20141107015724/http://qmcchem.ups-tlse.fr/files/caffarel/31.pdf|archivedate = 2014-11-07|df = }}&lt;/ref&gt;&lt;ref name="caffarel2"&gt;{{cite journal|last1 = Caffarel|first1 = Michel|last2 = Ceperley|first2 = David|last3 = Kalos|first3 = Malvin|title = Comment on Feynman-Kac Path-Integral Calculation of the Ground-State Energies of Atoms|journal = Phys. Rev. Lett.|date = 1993|volume = 71|doi = 10.1103/physrevlett.71.2159|bibcode=1993PhRvL..71.2159C|pages=2159|pmid=10054598}}&lt;/ref&gt; The origins of Quantum Monte Carlo methods are often attributed to Enrico Fermi and Robert Richtmyer who developed in 1948 a mean field particle interpretation of neutron-chain reactions,&lt;ref&gt;{{cite journal|last1 = Fermi|first1 = Enrique|last2 = Richtmyer|first2 = Robert, D.|title = Note on census-taking in Monte Carlo calculations|journal = LAM|date = 1948|volume = 805|issue = A|url = http://scienze-como.uninsubria.it/bressanini/montecarlo-history/fermi-1948.pdf|quote = Declassified report Los Alamos Archive}}&lt;/ref&gt; but the first heuristic-like and genetic type particle algorithm (a.k.a. Resampled or Reconfiguration Monte Carlo methods) for estimating ground state energies of quantum systems (in reduced matrix models) is due to Jack H. Hetherington in 1984.&lt;ref name="h84" /&gt; We also quote an earlier seminal works of [[Ted Harris (mathematician)|Theodore E. Harris]] and Herman Kahn in particle physics, published in 1951, using mean field but heuristic-like genetic methods for estimating particle transmission energies.&lt;ref&gt;{{cite journal|last1 = Herman|first1 = Kahn|last2 = Harris|first2 = Theodore, E.|title = Estimation of particle transmission by random sampling|journal = Natl. Bur. Stand. Appl. Math. Ser.|date = 1951|volume = 12|pages = 27–30|url = https://dornsifecms.usc.edu/assets/sites/520/docs/kahnharris.pdf}}&lt;/ref&gt; In molecular chemistry, the use of genetic heuristic-like particle methodologies (a.k.a. pruning and enrichment strategies) can be traced back to 1955 with the seminal work of Marshall. N. Rosenbluth and Arianna. W. Rosenbluth.&lt;ref name=":5" /&gt;

The use of [[Genetic algorithm|genetic particle algorithms]] in advanced [[signal processing]] and [[Bayesian inference]] is more recent. It was in 1993, that Gordon et al., published in their seminal work&lt;ref&gt;{{Cite journal|title = Novel approach to nonlinear/non-Gaussian Bayesian state estimation|url = http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=210672&amp;url=http%25253A%25252F%25252Fieeexplore.ieee.org%25252Fxpls%25252Fabs_all.jsp%25253Farnumber%25253D210672| journal = Radar and Signal Processing, IEE Proceedings F|date = April 1993|issn = 0956-375X|pages = 107–113|volume = 140|issue = 2|first = N.J.|last = Gordon|first2 = D.J.|last2 = Salmond|first3 = A.F.M.|last3 = Smith|doi=10.1049/ip-f-2.1993.0015}}&lt;/ref&gt; the first application of genetic type algorithm in Bayesian statistical inference. The authors named their algorithm 'the bootstrap filter', and demonstrated that compared to other filtering methods, their bootstrap algorithm does not require any assumption about that state-space or the noise of the system. We also quote another pioneering article in this field of Genshiro Kitagawa on a related "Monte Carlo filter",&lt;ref&gt;{{cite journal|last = Kitagawa|first = G.|year = 1996|title = Monte carlo filter and smoother for non-Gaussian nonlinear state space models|volume = 5|issue = 1|journal = Journal of Computational and Graphical Statistics|pages = 1–25|doi = 10.2307/1390750|jstor = 1390750}}
&lt;/ref&gt; and the ones by Pierre Del Moral&lt;ref name="dm962" /&gt; and Himilcon Carvalho, Pierre Del Moral, André Monin and Gérard Salut&lt;ref&gt;{{cite journal|last1 = Carvalho|first1 = Himilcon|last2 = Del Moral|first2 = Pierre|last3 = Monin|first3 = André|last4 = Salut|first4 = Gérard|title = Optimal Non-linear Filtering in GPS/INS Integration.|journal = IEEE-Trans. on Aerospace and electronic systems|date = July 1997|volume = 33|issue = 3|url = http://homepages.laas.fr/monin/Version_anglaise/Publications_files/GPS.pdf}}&lt;/ref&gt; on particle filters published in the mid-1990s. Particle filters were also developed in signal processing in the early 1989-1992 by P. Del Moral, J.C. Noyer, G. Rigal, and G. Salut in the LAAS-CNRS in a series of restricted and classified research reports with STCAN (Service Technique des Constructions et Armes Navales), the IT company DIGILOG, and the [https://www.laas.fr/public/en LAAS-CNRS] (the Laboratory for Analysis and Architecture of Systems) on RADAR/SONAR and GPS signal processing problems.&lt;ref&gt;P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : An unified framework for particle solutions &lt;br&gt;
LAAS-CNRS, Toulouse, Research Report no. 91137, DRET-DIGILOG- LAAS/CNRS contract, April (1991).&lt;/ref&gt;&lt;ref&gt;P. Del Moral, G. Rigal, and G. Salut. Nonlinear and non Gaussian particle filters applied to inertial platform repositioning.&lt;br&gt;
LAAS-CNRS, Toulouse, Research Report no. 92207, STCAN/DIGILOG-LAAS/CNRS Convention STCAN no. A.91.77.013, (94p.) September (1991).&lt;/ref&gt;&lt;ref&gt;P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Experimental results.&lt;br&gt;
Convention DRET no. 89.34.553.00.470.75.01, Research report no.2 (54p.), January (1992).&lt;/ref&gt;&lt;ref&gt;P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. Theoretical results &lt;br&gt;
Convention DRET no. 89.34.553.00.470.75.01, Research report no.3 (123p.), October (1992).&lt;/ref&gt;&lt;ref&gt;P. Del Moral, J.-Ch. Noyer, G. Rigal, and G. Salut. Particle filters in radar signal processing : detection, estimation and air targets recognition.&lt;br&gt;
LAAS-CNRS, Toulouse, Research report no. 92495, December (1992).&lt;/ref&gt;&lt;ref&gt;P. Del Moral, G. Rigal, and G. Salut. Estimation and nonlinear optimal control : Particle resolution in filtering and estimation. &lt;br&gt;
Studies on: Filtering, optimal control, and maximum likelihood estimation. Convention DRET no. 89.34.553.00.470.75.01. Research report no.4 (210p.), January (1993).&lt;/ref&gt;

=== Mathematical foundations ===
From 1950 to 1996, all the publications on particle filters, genetic algorithms, including the pruning and resample Monte Carlo methods introduced in computational physics and molecular chemistry, present natural and heuristic-like algorithms applied to different situations without a single proof of their consistency, nor a discussion on the bias of the estimates and on genealogical and ancestral tree based algorithms.

The mathematical foundations and the first rigorous analysis of these particle algorithms are due to Pierre Del Moral&lt;ref name="dm962" /&gt;&lt;ref name=":22" /&gt; in 1996. The article&lt;ref name="dm962" /&gt; also contains a proof of the unbiased properties of a particle approximations of likelihood functions and unnormalized conditional probability measures. The unbiased particle estimator of the likelihood functions presented in this article is used today in Bayesian statistical inference.

Branching type particle methodologies with varying population sizes were also developed toward the end of the 1990s by Dan Crisan, Jessica Gaines and Terry Lyons,&lt;ref name=":42"&gt;{{cite journal|last1 = Crisan|first1 = Dan|last2 = Gaines|first2 = Jessica|last3 = Lyons|first3 = Terry|title = Convergence of a branching particle method to the solution of the Zakai|journal = SIAM Journal on Applied Mathematics|date = 1998|volume = 58|issue = 5|pages = 1568–1590|doi = 10.1137/s0036139996307371}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1 = Crisan|first1 = Dan|last2 = Lyons|first2 = Terry|title = Nonlinear filtering and measure-valued processes|journal = Probability Theory and Related Fields|date = 1997|volume = 109|issue = 2|pages = 217–244|doi = 10.1007/s004400050131}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1 = Crisan|first1 = Dan|last2 = Lyons|first2 = Terry|title = A particle approximation of the solution of the Kushner–Stratonovitch equation|journal = Probability Theory and Related Fields|date = 1999|volume = 115|issue = 4|pages = 549–578|doi = 10.1007/s004400050249}}&lt;/ref&gt; and by Dan Crisan, Pierre Del Moral and Terry Lyons.&lt;ref name=":52"&gt;{{cite journal|last1 = Crisan|first1 = Dan|last2 = Del Moral|first2 = Pierre|last3 = Lyons|first3 = Terry|title = Discrete filtering using branching and interacting particle systems|journal = Markov Processes and Related Fields|date = 1999|volume = 5|issue = 3|pages = 293–318|url = http://web.maths.unsw.edu.au/~peterdel-moral/crisan98discrete.pdf}}&lt;/ref&gt; Further developments in this field were developed in 2000 by P. Del Moral, A. Guionnet and L. Miclo.&lt;ref name="dmm002" /&gt;&lt;ref name="dg99" /&gt;&lt;ref name="dg01" /&gt; The first central limit theorems are due to Pierre Del Moral and Alice Guionnet&lt;ref name=":2"&gt;{{Cite journal|title = Central limit theorem for nonlinear filtering and interacting particle systems|url = http://projecteuclid.org/euclid.aoap/1029962742|journal = The Annals of Applied Probability|date = 1999|issn = 1050-5164|pages = 275–297|volume = 9|issue = 2|doi = 10.1214/aoap/1029962742|first = P.|last = Del Moral|first2 = A.|last2 = Guionnet}}&lt;/ref&gt; in 1999 and Pierre Del Moral and Laurent Miclo&lt;ref name="dmm002" /&gt; in 2000. The first uniform convergence results with respect to the time parameter for particle filters were developed in the end of the 1990s by Pierre Del Moral and Alice Guionnet.&lt;ref name="dg99"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Guionnet|first2 = Alice|title = On the stability of Measure Valued Processes with Applications to filtering|journal = C. R. Acad. Sci. Paris|date = 1999|volume = 39|issue = 1|pages = 429–434}}&lt;/ref&gt;&lt;ref name="dg01"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Guionnet|first2 = Alice|title = On the stability of interacting processes with applications to filtering and genetic algorithms|journal = Annales de l'Institut Henri Poincaré|date = 2001|volume = 37|issue = 2|pages = 155–194|url = http://web.maths.unsw.edu.au/~peterdel-moral/ihp.ps|doi = 10.1016/s0246-0203(00)01064-5|bibcode=2001AnIHP..37..155D}}&lt;/ref&gt; The first rigorous analysis of genealogical tree based particle filter smoothers is due to P. Del Moral and L. Miclo in 2001&lt;ref name=":4"&gt;{{Cite journal|title = Genealogies and Increasing Propagation of Chaos For Feynman-Kac and Genetic Models|url = http://projecteuclid.org/euclid.aoap/1015345399|journal = The Annals of Applied Probability|date = 2001|issn = 1050-5164|pages = 1166–1198|volume = 11|issue = 4|doi = 10.1214/aoap/1015345399|first = Pierre|last = Del Moral|first2 = Laurent|last2 = Miclo}}&lt;/ref&gt;

The theory on Feynman-Kac particle methodologies and related particle filters algorithms has been developed in 2000 and 2004 in the books.&lt;ref name="dmm002"/&gt;&lt;ref name=":1" /&gt; These abstract probabilistic models encapsulate genetic type algorithms, particle and bootstrap filters, interacting Kalman filters (a.k.a. Rao–Blackwellized particle filter&lt;ref name="rbpf1999"&gt;{{cite conference| citeseerx = 10.1.1.137.5199| title = Rao–Blackwellised particle filtering for dynamic Bayesian networks
| author = Doucet, A.
 |author2=De Freitas, N. |author3=Murphy, K. |author4=Russell, S.
| year          = 2000
| conference    = Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence
| pages         = 176–183
| accessdate    = }}
&lt;/ref&gt;), importance sampling and resampling style particle filter techniques, including genealogical tree based and particle backward methodologies for solving filtering and smoothing problems. Other classes of particle filtering methodologies includes genealogical tree based models,&lt;ref name="dp13"&gt;{{cite book|last = Del Moral|first = Pierre|title = Mean field simulation for Monte Carlo integration|year = 2013|publisher = Chapman &amp; Hall/CRC Press|quote = Monographs on Statistics &amp; Applied Probability|url = http://www.crcpress.com/product/isbn/9781466504059|pages = 626}}&lt;/ref&gt;&lt;ref name=":1" /&gt;&lt;ref name=":3"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Miclo|first2 = Laurent|title = Genealogies and Increasing Propagations of Chaos for Feynman-Kac and Genetic Models|journal = Annals of Applied Probability|date = 2001|volume = 11|issue = 4|pages = 1166–1198|url = http://web.maths.unsw.edu.au/~peterdel-moral/spc.ps}}&lt;/ref&gt; backward Markov particle models,&lt;ref name="dp13" /&gt;&lt;ref name=":6"&gt;{{cite journal|last1 = Del Moral|first1 = Pierre|last2 = Doucet|first2 = Arnaud|last3 = Singh|first3 = Sumeetpal, S.|title = A Backward Particle Interpretation of Feynman-Kac Formulae|journal = M2AN|date = 2010|volume = 44|issue = 5|pages = 947–976|url = http://hal.inria.fr/docs/00/42/13/56/PDF/RR-7019.pdf|doi = 10.1051/m2an/2010048}}&lt;/ref&gt; adaptive mean field particle models,&lt;ref name=":0" /&gt; island type particle models,&lt;ref&gt;{{cite journal|last1 = Vergé|first1 = Christelle|last2 = Dubarry|first2 = Cyrille|last3 = Del Moral|first3 = Pierre|last4 = Moulines|first4 = Eric|title = On parallel implementation of Sequential Monte Carlo methods: the island particle model|journal = Statistics and Computing|date = 2013|doi = 10.1007/s11222-013-9429-x|volume = 25|pages = 243–260|arxiv = 1306.3911}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv|last1 = Chopin|first1 = Nicolas|last2 = Jacob|first2 = Pierre, E.|last3 = Papaspiliopoulos|first3 = Omiros|title = SMC^2: an efficient algorithm for sequential analysis of state-space models|arxiv=1101.1528v3}}&lt;/ref&gt; and particle Markov chain Monte Carlo methodologies.&lt;ref&gt;{{cite journal|last1 = Andrieu|first1 = Christophe|last2 = Doucet|first2 = Arnaud|last3 = Holenstein|first3 = Roman|title = Particle Markov chain Monte Carlo methods|journal = Journal of the Royal Statistical Society, Series B|date = 2010|volume = 72|issue = 3|pages = 269–342|doi = 10.1111/j.1467-9868.2009.00736.x}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv|last1 = Del Moral|first1 = Pierre|last2 = Patras|first2 = Frédéric|last3 = Kohn|first3 = Robert|title = On Feynman-Kac and particle Markov chain Monte Carlo models|arxiv=1404.5733|date = 2014}}&lt;/ref&gt;

== The filtering problem ==

===Objective===
The objective of a particle filter is to estimate the posterior density of the state variables given the observation variables. The particle filter is designed for a [[hidden Markov Model]], where the system consists of hidden and observable variables. The observable variables (observation process) are related to the hidden variables (state-process) by some functional form that is known. Similarly the dynamical system describing the evolution of the state variables is also known probabilistically.

A generic particle filter estimates the posterior distribution of the hidden states using the observation measurement process. Consider a state-space shown in the diagram below.

:&lt;math&gt;\begin{array}{cccccccccc}
X_0&amp;\to &amp;X_1&amp;\to &amp;X_2&amp;\to&amp;X_3&amp;\to &amp;\cdots&amp;\text{signal}\\
\downarrow&amp;&amp;\downarrow&amp;&amp;\downarrow&amp;&amp;\downarrow&amp;&amp;\cdots&amp;\\
Y_0&amp;&amp;Y_1&amp;&amp;Y_2&amp;&amp;Y_3&amp;&amp;\cdots&amp;\text{observation}
\end{array}&lt;/math&gt;
 
The filtering problem is to estimate '''sequentially''' the values of the hidden states &lt;math&gt;X_k&lt;/math&gt;, given the values of the observation process &lt;math&gt;Y_0,\cdots,Y_k,&lt;/math&gt; at any time step ''k''.

All Bayesian estimates of &lt;math&gt;X_k&lt;/math&gt; follow from the [[Posterior probability|posterior density]]  ''p''(''x''&lt;sub&gt;''k''&lt;/sub&gt;&amp;nbsp;|&amp;nbsp;''y''&lt;sub&gt;0&lt;/sub&gt;,''y''&lt;sub&gt;1&lt;/sub&gt;,…,''y''&lt;sub&gt;''k''&lt;/sub&gt;). The particle filter methodology provides an approximation of these conditional probabilities using the empirical measure associated with a genetic type particle algorithm.  In contrast, the [[Markov chain Monte Carlo|MCMC]] or [[importance sampling]] approach would model the full posterior ''p''(''x''&lt;sub&gt;0&lt;/sub&gt;,''x''&lt;sub&gt;1&lt;/sub&gt;,…,''x''&lt;sub&gt;''k''&lt;/sub&gt;&amp;nbsp;|&amp;nbsp;''y''&lt;sub&gt;0&lt;/sub&gt;,''y''&lt;sub&gt;1&lt;/sub&gt;,…,''y''&lt;sub&gt;''k''&lt;/sub&gt;).

===The Signal-Observation Model===
Particle methods often assume &lt;math&gt;X_k&lt;/math&gt; and the observations &lt;math&gt;Y_k&lt;/math&gt; can be modeled in this form:

*&lt;math&gt;X_0, X_1, \cdots&lt;/math&gt; is a [[Markov process]] on &lt;math&gt;\mathbb R^{d_x}&lt;/math&gt; (for some &lt;math&gt;d_x\geqslant 1&lt;/math&gt;) that evolves according to the transition probability density &lt;math&gt;p(x_k|x_{k-1})&lt;/math&gt;. This model is also often written in a synthetic way as 
*:&lt;math&gt;X_k|X_{k-1}=x_k \sim p(x_k|x_{k-1})&lt;/math&gt;
:with an initial probability density &lt;math&gt;p(x_0)&lt;/math&gt;.
*The observations &lt;math&gt;Y_0, Y_1, \cdots&lt;/math&gt;  take values in some state space on &lt;math&gt;\mathbb{R}^{d_y}&lt;/math&gt; (for some &lt;math&gt;d_y\geqslant 1&lt;/math&gt;) and are conditionally independent provided that &lt;math&gt;X_0, X_1, \cdots&lt;/math&gt; are known. In other words, each &lt;math&gt;Y_k&lt;/math&gt; only depends on &lt;math&gt;X_k&lt;/math&gt;. In addition, we assume conditional distribution for &lt;math&gt;Y_k&lt;/math&gt; given &lt;math&gt;X_k=x_k&lt;/math&gt; are absolutely continuous, and in a synthetic way we have
*:&lt;math&gt;Y_k|X_k=y_k \sim p(y_k|x_k)&lt;/math&gt;
An example of system with these properties is:

:&lt;math&gt;X_k = g(X_{k-1}) + W_{k-1}&lt;/math&gt;
:&lt;math&gt;Y_k = h(X_k) + V_k&lt;/math&gt;

where both &lt;math&gt;W_k&lt;/math&gt; and &lt;math&gt;V_k&lt;/math&gt; are mutually independent sequences with known [[probability density function]]s and ''g'' and ''h'' are known functions. These two equations can be viewed as [[state space (controls)|state space]] equations and look similar to the state space equations for the Kalman filter. If the functions ''g'' and ''h'' in the above example are linear, and if both &lt;math&gt;W_k&lt;/math&gt; and &lt;math&gt;V_k&lt;/math&gt; are [[Gaussian]], the Kalman filter finds the exact Bayesian filtering distribution.  If not, Kalman filter based methods are a first-order approximation ([[Extended Kalman filter|EKF]]) or a second-order approximation (UKF in general, but if probability distribution is Gaussian a third-order approximation is possible).

The assumption that the initial distribution and the transitions of the Markov chain are absolutely continuous with respect to the Lebesgue measure can be relaxed. To design a particle filter we simply need to assume that we can sample the transitions &lt;math&gt;X_{k-1} \to X_k&lt;/math&gt; of the Markov chain &lt;math&gt;X_k,&lt;/math&gt; and to compute the likelihood function &lt;math&gt;x_k\mapsto p(y_k|x_k)&lt;/math&gt; (see for instance the genetic selection mutation description of the particle filter given below). The absolutely continuous assumption on the Markov transitions of &lt;math&gt;X_k&lt;/math&gt; are only used to derive in an informal (and rather abusive) way different formulae between posterior distributions using the Bayes' rule for conditional densities.

=== [[Approximate Bayesian computation|Approximate Bayesian Computation models]] ===
In some important problems, the conditional distribution of the observations given the random states of the signal may fail to have a density or may be impossible or too complex to compute. In this situation, we need to resort to an additional level of approximation. One strategy is to replace the signal &lt;math&gt;X_k&lt;/math&gt; by the Markov chain &lt;math&gt;\mathcal X_k=\left(X_k,Y_k\right)&lt;/math&gt; and to introduce a virtual observation of the form

:&lt;math&gt;\mathcal Y_k=Y_k+\epsilon \mathcal V_k\quad\mbox{for some parameter}\quad\epsilon\in [0,1]&lt;/math&gt;

for some sequence of independent sequences with known [[probability density function]]s. The central idea is to observe that

:&lt;math&gt;\text{Law}\left(X_k|\mathcal Y_0=y_0,\cdots, \mathcal Y_k=y_k\right)\approx_{\epsilon\downarrow 0} \text{Law}\left(X_k|Y_0=y_0,\cdots, Y_k=y_k\right)&lt;/math&gt;

The particle filter associated with the Markov process &lt;math&gt;\mathcal X_k=\left(X_k,Y_k\right)&lt;/math&gt; given the partial observations &lt;math&gt;\mathcal Y_0=y_0,\cdots, \mathcal Y_k=y_k,&lt;/math&gt; is defined in terms of particles evolving in &lt;math&gt;\mathbb R^{d_x+d_y}&lt;/math&gt; with a likelihood function given with some obvious abusive notation by &lt;math&gt;p(\mathcal Y_k|\mathcal X_k)&lt;/math&gt;. These probabilistic techniques are closely related to [[Approximate Bayesian Computation]] (ABC). In the context of particle filters, these ABC particle filtering techniques were introduced in 1998 by P. Del Moral, J. Jacod and P. Protter.&lt;ref&gt;{{Cite journal|title = The Monte-Carlo method for filtering with discrete-time observations|url = https://link.springer.com/article/10.1007/PL00008786|journal = Probability Theory and Related Fields|date = 2001-07-01|issn = 0178-8051|pages = 346–368|volume = 120|issue = 3|doi = 10.1007/PL00008786|first = Pierre|last = Del Moral|first2 = Jean|last2 = Jacod|first3 = Philip|last3 = Protter}}&lt;/ref&gt; They were further developed by P. Del Moral, A. Doucet and A. Jasra.&lt;ref&gt;{{Cite journal|title = An adaptive sequential Monte Carlo method for approximate Bayesian computation|url = https://link.springer.com/article/10.1007/s11222-011-9271-y |journal = Statistics and Computing|date = 2011|issn = 0960-3174|pages = 1009–1020|volume = 22|issue = 5|doi = 10.1007/s11222-011-9271-y|first = Pierre|last = Del Moral|first2 = Arnaud|last2 = Doucet|first3 = Ajay|last3 = Jasra}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|title = Approximate Bayesian Computation for Smoothing|journal = Stochastic Analysis and Applications|date = May 4, 2014|issn = 0736-2994|pages = 397–420|volume = 32|issue = 3|doi = 10.1080/07362994.2013.879262|first = James S.|last = Martin|first2 = Ajay|last2 = Jasra|first3 = Sumeetpal S.|last3 = Singh|first4 = Nick|last4 = Whiteley|first5 = Pierre|last5 = Del Moral|first6 = Emma|last6 = McCoy|arxiv = 1206.5208}}&lt;/ref&gt;

=== The nonlinear filtering equation ===
The Bayes' rule for conditional probability gives:

:&lt;math&gt;p(x_0, \cdots, x_k|y_0,\cdots,y_k) =\frac{p(y_0,\cdots,y_k|x_0, \cdots, x_k)  p(x_0,\cdots,x_k)}{p(y_0,\cdots,y_k)}&lt;/math&gt;

where

:&lt;math&gt;\begin{align}
p(y_0,\cdots,y_k) &amp;=\int p(y_0,\cdots,y_k|x_0,\cdots, x_k) p(x_0,\cdots,x_k) dx_0\cdots dx_k \\
p(y_0,\cdots, y_k|x_0,\cdots ,x_k) &amp;=\prod_{l=0}^{k} p(y_l|x_l) \\
p(x_0,\cdots, x_k) &amp;=p_0(x_0)\prod_{l=1}^{k} p(x_l|x_{l-1})
\end{align}&lt;/math&gt;

Particle filters are also an approximation, but with enough particles they can be much more accurate.&lt;ref name="dm962" /&gt;&lt;ref name=":22" /&gt;&lt;ref name=":1" /&gt;&lt;ref name="dg99" /&gt;&lt;ref name="dg01" /&gt; The nonlinear filtering equation is given by the recursion

{{NumBlk|:|
&lt;math&gt;\begin{align} 
p(x_k|y_0,\cdots,y_{k-1}) &amp;\stackrel{\text{updating}}{\longrightarrow} p(x_k|y_0,\cdots,y_k)=\frac{p(y_k|x_k)p(x_k|y_0,\cdots,y_{k-1})}{\int p(y_k|x'_k)p(x'_k|y_0,\cdots,y_{k-1})dx'_k}  \\
&amp;\stackrel{\text{prediction}}{\longrightarrow}p(x_{k+1}|y_0,\cdots,y_k)=\int p(x_{k+1}|x_k) p(x_k|y_0,\cdots,y_k) dx_k
\end{align}&lt;/math&gt;
|Eq. 1}}

with the convention &lt;math&gt;p(x_0|y_0,\cdots,y_{k-1})=p(x_0)&lt;/math&gt; for ''k'' = 0. The nonlinear filtering problem consists in computing these conditional distributions sequentially.

=== [[Feynman–Kac formula|Feynman-Kac formulation]] ===
We fix a time horizon n and a sequence of observations &lt;math&gt;Y_0=y_0,\cdots,Y_n=y_n&lt;/math&gt;, and for each ''k'' = 0, ..., ''n'' we set:

:&lt;math&gt;G_k(x_k)=p(y_k|x_k).&lt;/math&gt;

In this notation, for any bounded function ''F'' on the set of trajectories of &lt;math&gt;X_k&lt;/math&gt; from the origin ''k'' = 0 up to time ''k'' = ''n'', we have the Feynman-Kac formula

:&lt;math&gt;\begin{align}
\int F(x_0,\cdots,x_n) p(x_0,\cdots,x_n|y_0,\cdots,y_n) dx_0\cdots dx_n &amp;= \frac{\int F(x_0,\cdots,x_n) \left\{\prod\limits_{k=0}^{n} p(y_k|x_k)\right\}p(x_0,\cdots,x_n) dx_0\cdots dx_n}{\int \left\{\prod\limits_{k=0}^{n} p(y_k|x_k)\right\}p(x_0,\cdots,x_n) dx_0\cdots dx_n}\\
&amp;=\frac{E\left(F(X_0,\cdots,X_n)\prod\limits_{k=0}^{n} G_k(X_k)\right)}{E\left(\prod\limits_{k=0}^{n} G_k(X_k)\right)}
\end{align}&lt;/math&gt;

These Feynman-Kac path integration models arise in a variety of scientific disciplines, including in computational physics, biology, information theory and computer sciences.&lt;ref name="dmm002" /&gt;&lt;ref name="dp13" /&gt;&lt;ref name=":1" /&gt; Their interpretations depend on the application domain. For instance, if we choose the indicator function &lt;math&gt;G_n(x_n)=1_A(x_n)&lt;/math&gt; of some subset of the state space, they represent the conditional distribution of a Markov chain given it stays in a given tube; that is, we have:

:&lt;math&gt;E\left(F(X_0,\cdots,X_n) | X_0\in A, \cdots, X_n\in A\right) =\frac{E\left(F(X_0,\cdots,X_n)\prod\limits_{k=0}^{n} G_k(X_k)\right)}{E\left(\prod\limits_{k=0}^{n} G_k(X_k)\right)}&lt;/math&gt;
and
:&lt;math&gt;P\left(X_0\in A,\cdots, X_n\in A\right)=E\left(\prod\limits_{k=0}^{n} G_k(X_k)\right)&lt;/math&gt;

as soon as the normalizing constant is strictly positive.

== Particle filters ==

=== A Genetic type particle algorithm===
Initially we start with ''N'' independent random variables &lt;math&gt;\left(\xi^i_0\right)_{1\leqslant i\leqslant N}&lt;/math&gt; with common probability density &lt;math&gt;p(x_0)&lt;/math&gt;. The genetic algorithm selection-mutation transitions

:&lt;math&gt;\xi_k:=\left(\xi^i_{k}\right)_{1\leqslant i\leqslant N}\stackrel{\text{selection}}{\longrightarrow} \widehat{\xi}_k:=\left(\widehat{\xi}^i_{k}\right)_{1\leqslant i\leqslant N}\stackrel{\text{mutation}}{\longrightarrow} \xi_{k+1}:=\left(\xi^i_{k+1}\right)_{1\leqslant i\leqslant N}&lt;/math&gt;

mimic/approximate the updating-prediction transitions of the optimal filter evolution ({{EquationNote|Eq. 1}}):

* '''During the selection-updating transition''' we sample ''N'' (conditionally) independent random variables &lt;math&gt;\widehat{\xi}_k:=\left(\widehat{\xi}^i_{k}\right)_{1\leqslant i\leqslant N}&lt;/math&gt; with common (conditional) distribution
::&lt;math&gt;\sum_{i=1}^N \frac{p(y_k|\xi^i_k)}{\sum_{j=1}^Np(y_k|\xi^j_k)} \delta_{\xi^i_k}(dx_k)&lt;/math&gt;

* '''During the mutation-prediction transition,''' from each selected particle &lt;math&gt;\widehat{\xi}^i_k&lt;/math&gt; we sample independently a transition 
::&lt;math&gt;\widehat{\xi}^i_k \longrightarrow\xi^i_{k+1} \sim p(x_{k+1}|\widehat{\xi}^i_k), \qquad i=1,\cdots,N.&lt;/math&gt;
In the above displayed formulae  &lt;math&gt;p(y_k|\xi^i_k)&lt;/math&gt; stands for the likelihood function &lt;math&gt;x_k\mapsto p(y_k|x_k)&lt;/math&gt; evaluated at &lt;math&gt;x_k=\xi^i_k&lt;/math&gt;, and &lt;math&gt;p(x_{k+1}|\widehat{\xi}^i_k)&lt;/math&gt; stands for the conditional density &lt;math&gt;p(x_{k+1}|x_k)&lt;/math&gt; evaluated at &lt;math&gt;x_k=\widehat{\xi}^i_k&lt;/math&gt;.

At each time ''k'', we have the particle approximations

:&lt;math&gt;\widehat{p}(dx_k|y_0,\cdots,y_k):=\frac{1}{N} \sum_{i=1}^N \delta_{\widehat{\xi}^i_k} (dx_k) \approx_{N\uparrow\infty} p(dx_k|y_0,\cdots,y_k) \approx_{N\uparrow\infty} 
\sum_{i=1}^N \frac{p(y_k|\xi^i_k)}{\sum_{i=1}^N p(y_k|\xi^j_k)} \delta_{\xi^i_k}(dx_k)&lt;/math&gt;

and

:&lt;math&gt;\widehat{p}(dx_k|y_0,\cdots,y_{k-1}):=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^i_k}(dx_k) \approx_{N\uparrow\infty} p(dx_k|y_0,\cdots,y_{k-1})&lt;/math&gt;

A detailed proof of these convergence results can be found in,&lt;ref name="dm962" /&gt;&lt;ref name=":22" /&gt; see also the more recent developments provided in the books.&lt;ref name="dp13" /&gt;&lt;ref name=":1" /&gt; In Genetic algorithms and [[Evolutionary computing]] community, the mutation-selection Markov chain described above is often called the genetic algorithm with proportional selection. Several branching variants, including with random population sizes have also been proposed in the articles.&lt;ref name=":1" /&gt;&lt;ref name=":42" /&gt;&lt;ref name=":52" /&gt;

===[[Monte Carlo method|Monte Carlo principles]]===
Particle methods, like all sampling-based approaches (e.g., [[Markov chain Monte Carlo|MCMC]]), generate a set of samples that approximate the filtering density

:&lt;math&gt;p(x_k|y_0, \cdots, y_k).&lt;/math&gt;

For example, we may have ''N'' samples from the approximate posterior distribution of &lt;math&gt;X_k&lt;/math&gt;, where the samples are labeled with superscripts as

:&lt;math&gt;\widehat{\xi}_k^1, \cdots, \widehat{\xi}_k^{N}.&lt;/math&gt;

Then, expectations with respect to the filtering distribution are approximated by

{{NumBlk|:| &lt;math&gt;\int f(x_k)p(x_k|y_0,\cdots,y_k) \, dx_k\approx_{N\uparrow\infty}\frac{1}{N} \sum_{i=1}^Nf\left(\widehat{\xi}_k^{i}\right)=\int f(x_k) \widehat{p}(dx_k|y_0,\cdots,y_k)&lt;/math&gt;
|Eq. 2}}

with

:&lt;math&gt;\widehat{p}(dx_k|y_0,\cdots,y_k)=\frac{1}{N}\sum_{i=1}^N \delta_{\widehat{\xi}^i_k}(dx_k)&lt;/math&gt;

where &lt;math&gt;\delta_a&lt;/math&gt; stands for the '''[[Dirac measure]]''' at a given state a. The function ''f'', in the usual way for Monte Carlo, can give all the [[moment (mathematics)|moments]] etc. of the distribution up to some approximation error. When the approximation equation  ({{EquationNote|Eq. 2}}) is satisfied for any bounded function ''f'' we write

:&lt;math&gt;p(dx_k|y_0,\cdots,y_k):=p(x_k|y_0,\cdots,y_k) dx_k \approx_{N\uparrow\infty} \widehat{p}(dx_k|y_0,\cdots,y_k)=\frac{1}{N}\sum_{i=1}^N \delta_{\widehat{\xi}^{i}_k}(dx_k)&lt;/math&gt;

Particle filters can be interpreted as a genetic type particle algorithm evolving with mutation and selection transitions. We can keep track of the ancestral lines

:&lt;math&gt;\left(\widehat{\xi}^{i}_{0,k}, \widehat{\xi}^{i}_{1,k},\cdots,\widehat{\xi}^{i}_{k-1,k},\widehat{\xi}^i_{k,k}\right)&lt;/math&gt;

of the particles &lt;math&gt;i=1,\cdots,N&lt;/math&gt;. The random states &lt;math&gt;\widehat{\xi}^{i}_{l,k}&lt;/math&gt;, with the lower indices l=0,...,k, stands for the ancestor of the individual &lt;math&gt;\widehat{\xi}^{i}_{k,k}=\widehat{\xi}^i_k&lt;/math&gt; at level l=0,...,k. In this situation, we have the approximation formula

{{NumBlk|:| &lt;math&gt;\begin{align}
\int F(x_0, \cdots,x_k) p(x_0,\cdots, x_k|y_0,\cdots,y_k) \, dx_0 \cdots dx_k &amp;\approx_{N\uparrow\infty} \frac{1}{N} \sum_{i=1}^NF\left( \widehat{\xi}_{0,k}^{i}, \widehat{\xi}_{1,k}^{i}, \cdots, \widehat{\xi}_{k,k}^{i}\right) \\
&amp; =\int F(x_0, \cdots, x_k)\widehat{p}(d(x_0, \cdots,x_k)|y_0,\cdots,y_k)
\end{align}&lt;/math&gt; |Eq. 3}}

with the [[empirical measure]]

:&lt;math&gt;\widehat{p}(d(x_0,\cdots,x_k)|y_0,\cdots,y_k):=\frac{1}{N}\sum_{i=1}^N \delta_{\left(\widehat{\xi}^{i}_{0,k},\widehat{\xi}^{i}_{1,k},\cdots,\widehat{\xi}^{i}_{k,k}\right)}(d(x_0,\cdots,x_k))&lt;/math&gt;

Here ''F'' stands for any founded function on the path space of the signal. In a more synthetic form ({{EquationNote|Eq. 3}}) is equivalent to

:&lt;math&gt;\begin{align}
p(d(x_0,\cdots,x_k)|y_0,\cdots,y_k)&amp;:=p(x_0,\cdots,x_k|y_0,\cdots,y_k) \, dx_0\cdots dx_k \\
&amp;\approx_{N\uparrow\infty} \widehat{p}(d(x_0,\cdots,x_k)|y_0,\cdots,y_k) \\
&amp;:=\frac{1}{N}\sum_{i=1}^N \delta_{\left(\widehat{\xi}^{i}_{0,k}, \cdots,\widehat{\xi}^{i}_{k,k}\right)}(d(x_0,\cdots,x_k))
\end{align}&lt;/math&gt;

Particle filters can be interpreted in many different ways. From the probabilistic point of view they coincide with a [[Mean field particle methods|mean field particle]] interpretation of the nonlinear filtering equation. The updating-prediction transitions of the optimal filter evolution can also be interpreted as the classical genetic type selection-mutation transitions of individuals. The sequential importance resampling technique provides another interpretation of the filtering transitions coupling importance sampling with the bootstrap resampling step. Last, but not least, particle filters can be seen as an acceptance-rejection methodology equipped with a recycling mechanism.&lt;ref name="dp13" /&gt;&lt;ref name=":1" /&gt;

=== [[Mean field particle methods|Mean field particle simulation]] ===
{{Technical|section|date=June 2017}}

==== The general probabilistic principle ====
The nonlinear filtering evolution can be interpreted as a dynamical system in the set of probability measures of the following form &lt;math&gt;\eta_{n+1}=\Phi_{n+1}\left(\eta_{n}\right)&lt;/math&gt; where &lt;math&gt;\Phi_{n+1}&lt;/math&gt; stands for some mapping from the set of probability distribution into itself. For instance, the evolution of the one-step optimal predictor &lt;math&gt; \eta_n(dx_n) =p(x_n|y_0,\cdots,y_{n-1})dx_n&lt;/math&gt;

satisfies a nonlinear evolution starting with the probability distribution &lt;math&gt;\eta_0(dx_0)=p(x_0)dx_0&lt;/math&gt;. One of the simplest ways to approximate these probability measures is to start with ''N'' independent random variables &lt;math&gt;\left(\xi^i_0\right)_{1\leqslant i\leqslant N}&lt;/math&gt; with common probability distribution  &lt;math&gt;\eta_0(dx_0)=p(x_0)dx_0&lt;/math&gt; . Suppose we have defined a sequence of ''N'' random variables &lt;math&gt;\left(\xi^i_n\right)_{1\leqslant i\leqslant N}&lt;/math&gt; such that

:&lt;math&gt;\frac{1}{N}\sum_{i=1}^N \delta_{\xi^i_n}(dx_n) \approx_{N\uparrow\infty} \eta_n(dx_n)&lt;/math&gt;

At the next step we sample ''N'' (conditionally) independent random variables &lt;math&gt;\xi_{n+1}:=\left(\xi^i_{n+1}\right)_{1\leqslant i\leqslant N}&lt;/math&gt; with common law .

:&lt;math&gt;\Phi_{n+1}\left(\frac{1}{N}\sum_{i=1}^N \delta_{\xi^i_n}\right) \approx_{N\uparrow\infty} \Phi_{n+1}\left(\eta_{n}\right)=\eta_{n+1}&lt;/math&gt;

==== A particle interpretation of the filtering equation ====
We illustrate this mean field particle principle in the context of the evolution of the one step optimal predictors

{{NumBlk|:|
&lt;math&gt;p(x_{k}|y_0,\cdots,y_{k-1}) dx_k \to  p(x_{k+1}|y_0,\cdots,y_k)=\int p(x_{k+1}|x'_{k}) \frac{p(y_k|x_k') p(x'_k|y_0,\cdots,y_{k-1}) dx'_k}{\int p(y_k|x''_k) p(x''_k|y_0,\cdots,y_{k-1}) dx''_{k}}&lt;/math&gt;
|Eq. 4}}

For ''k'' = 0 we use the convention &lt;math&gt;p(x_0|y_0,\cdots,y_{-1}):=p(x_0)&lt;/math&gt;.

By the law of large numbers, we have

:&lt;math&gt;\widehat{p}(dx_0)=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^{i}_0}(dx_0)\approx_{N\uparrow\infty} p(x_0)dx_0&lt;/math&gt;

in the sense that

:&lt;math&gt;\int f(x_0)\widehat{p}(dx_0)=\frac{1}{N}\sum_{i=1}^N f(\xi^i_0)\approx_{N\uparrow\infty} \int f(x_0)p(dx_0)dx_0&lt;/math&gt;

for any bounded function &lt;math&gt;f&lt;/math&gt;. We further assume that we have constructed a sequence of particles &lt;math&gt;\left(\xi^i_k\right)_{1\leqslant i\leqslant N}&lt;/math&gt; at some rank ''k'' such that

:&lt;math&gt;\widehat{p}(dx_k|y_0,\cdots,y_{k-1}):=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^{i}_k}(dx_k)\approx_{N\uparrow\infty}~p(x_k~|~y_0,\cdots,y_{k-1})dx_k&lt;/math&gt;

in the sense that for any bounded function &lt;math&gt;f&lt;/math&gt; we have

:&lt;math&gt;\int f(x_k)\widehat{p}(dx_k|y_0,\cdots,y_{k-1})=\frac{1}{N}\sum_{i=1}^N f(\xi^i_k)\approx_{N\uparrow\infty} \int f(x_k)p(dx_k|y_0,\cdots,y_{k-1})dx_k&lt;/math&gt;

In this situation, replacing &lt;math id="{{EquationRef|1}}"&gt;p(x_k|y_0,\cdots,y_{k-1}) dx_k&lt;/math&gt; by the [[empirical measure]] &lt;math id="{{EquationRef|1}}"&gt;\widehat{p}(dx_k|y_0,\cdots,y_{k-1})&lt;/math&gt; in the evolution equation of the one-step optimal filter stated in ({{EquationNote|Eq. 4}}) we find that

:&lt;math&gt;p(x_{k+1}|y_0,\cdots,y_k)\approx_{N\uparrow\infty} \int p(x_{k+1}|x'_{k}) \frac{p(y_k|x_k') \widehat{p}(dx'_k|y_0,\cdots,y_{k-1})}{ \int p(y_k|x''_k) \widehat{p}(dx''_k|y_0,\cdots,y_{k-1})}&lt;/math&gt;

Notice that the right hand side in the above formula is a weighted probability mixture

:&lt;math&gt;\int p(x_{k+1}|x'_{k}) \frac{p(y_k|x_k') \widehat{p}(dx'_k|y_0,\cdots,y_{k-1})}{\int p(y_k|x''_k) \widehat{p}(dx''_k|y_0,\cdots,y_{k-1})}=\sum_{i=1}^N \frac{p(y_k|\xi^i_k)}{\sum_{i=1}^N p(y_k|\xi^j_k)} p(x_{k+1}|\xi^i_k)=:\widehat{q}(x_{k+1}|y_0,\cdots,y_k)&lt;/math&gt;

where &lt;math&gt;p(y_k|\xi^i_k)&lt;/math&gt; stands for the density &lt;math&gt;p(y_k|x_k)&lt;/math&gt; evaluated at &lt;math&gt;x_k=\xi^i_k&lt;/math&gt;, and &lt;math&gt;p(x_{k+1}|\xi^i_k)&lt;/math&gt; stands for the density &lt;math&gt;p(x_{k+1}|x_k)&lt;/math&gt; evaluated at &lt;math&gt;x_k=\xi^i_k&lt;/math&gt; for &lt;math&gt;i=1,\cdots,N.&lt;/math&gt;

Then, we sample ''N'' independent random variable &lt;math&gt;\left(\xi^i_{k+1}\right)_{1\leqslant i\leqslant N}&lt;/math&gt; with common probability density &lt;math&gt;\widehat{q}(x_{k+1}|y_0,\cdots,y_k)&lt;/math&gt;  so that

:&lt;math&gt;\widehat{p}(dx_{k+1}|y_0,\cdots,y_{k}):=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^{i}_{k+1}}(dx_{k+1})\approx_{N\uparrow\infty} \widehat{q}(x_{k+1}|y_0,\cdots,y_{k}) dx_{k+1} \approx_{N\uparrow\infty} p(x_{k+1}|y_0,\cdots,y_{k})dx_{k+1}&lt;/math&gt;

Iterating this procedure, we design a Markov chain such that

:&lt;math&gt;\widehat{p}(dx_k|y_0,\cdots,y_{k-1}):=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^i_k}(dx_k) \approx_{N\uparrow\infty} p(dx_k|y_0,\cdots,y_{k-1}):=p(x_k|y_0,\cdots,y_{k-1}) dx_k&lt;/math&gt;

Notice that the optimal filter is approximated at each time step k using the Bayes' formulae

:&lt;math&gt;p(dx_{k}|y_0,\cdots,y_{k}) \approx_{N\uparrow\infty} \frac{p(y_{k}|x_{k}) \widehat{p}(dx_{k}|y_0,\cdots,y_{k-1})}{\int p(y_{k}|x'_{k})\widehat{p}(dx'_{k}|y_0,\cdots,y_{k-1})}=\sum_{i=1}^N \frac{p(y_k|\xi^i_k)}{\sum_{j=1}^Np(y_k|\xi^j_k)}~\delta_{\xi^i_k}(dx_k)&lt;/math&gt;

The terminology "mean field approximation" comes from the fact that we replace at each time step the probability measure &lt;math&gt;p(dx_k|y_0,\cdots,y_{k-1})&lt;/math&gt; by the empirical approximation &lt;math&gt;\widehat{p}(dx_k|y_0,\cdots,y_{k-1})&lt;/math&gt;. The mean field particle approximation of the filtering problem is far from being unique. Several strategies are developed in the books.&lt;ref name="dp13" /&gt;&lt;ref name=":1" /&gt;

=== Some convergence results ===
The analysis of the convergence of particle filters was started in 1996&lt;ref name="dm962" /&gt;&lt;ref name=":22" /&gt; and in 2000 in the book&lt;ref name="dmm002" /&gt; and the series of articles.&lt;ref name=":52" /&gt;&lt;ref name="dg99" /&gt;&lt;ref name="dg01" /&gt;&lt;ref name=":2" /&gt;&lt;ref name=":4" /&gt;&lt;ref&gt;{{Cite journal|title = Concentration inequalities for mean field particle models|url = http://projecteuclid.org/euclid.aoap/1307020390|journal = The Annals of Applied Probability|date = 2011|issn = 1050-5164|pages = 1017–1052|volume = 21|issue = 3|doi = 10.1214/10-AAP716|first = Pierre|last = Del Moral|first2 = Emmanuel|last2 = Rio|arxiv = 1211.1837}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title = On the Concentration Properties of Interacting Particle Processes|url = http://dl.acm.org/citation.cfm?id=2222549|publisher = Now Publishers Inc.|date = 2012|location = Hanover, MA, USA|isbn = 1601985126|first = Pierre|last = Del Moral|first2 = Peng|last2 = Hu|first3 = Liming|last3 = Wu}}&lt;/ref&gt; More recent developments can be found in the books,&lt;ref name="dp13" /&gt;&lt;ref name=":1" /&gt; When the filtering equation is stable (in the sense that it corrects any erroneous initial condition), the bias and the variance of the particle particle estimates

:&lt;math&gt;I_k(f):=\int f(x_k) p(dx_k|y_0,\cdots,y_{k-1}) \approx_{N\uparrow\infty} \widehat{I}_k(f):=\int f(x_k) \widehat{p}(dx_k|y_0,\cdots,y_{k-1})&lt;/math&gt;

are controlled by the non asymptotic uniform estimates

:&lt;math&gt;\sup_{k\geqslant 0}\left\vert E\left(\widehat{I}_k(f)\right)-I_k(f)\right\vert\leqslant \frac{c_1}{N}&lt;/math&gt;
:&lt;math&gt;\sup_{k\geqslant 0}E\left(\left[\widehat{I}_k(f)-I_k(f)\right]^2\right)\leqslant \frac{c_2}{N}&lt;/math&gt;

for any function ''f'' bounded by 1, and for some finite constants &lt;math&gt;c_1,c_2.&lt;/math&gt;  In addition, for any &lt;math&gt;x\geqslant 0&lt;/math&gt;:

:&lt;math&gt;\mathbf{P} \left ( \left| \widehat{I}_k(f)-I_k(f)\right|\leqslant c_1 \frac{x}{N}+c_2 \sqrt{\frac{x}{N}}\land \sup_{0\leqslant k\leqslant n}\left| \widehat{I}_k(f)-I_k(f)\right|\leqslant c \sqrt{\frac{x\log(n)}{N}} \right ) &gt; 1-e^{-x}&lt;/math&gt;

for some finite constants &lt;math&gt;c_1, c_2&lt;/math&gt; related to the asymptotic bias and variance of the particle estimate, and some finite constant ''c''. The same results are satisfied if we replace the one step optimal predictor by the optimal filter approximation.

== Genealogical trees and Unbiasedness properties ==
{{Technical|section|date=June 2017}}

=== Genealogical tree based particle smoothing ===

Tracing back in time the ancestral lines

:&lt;math&gt;\left(\widehat{\xi}^i_{0,k},\widehat{\xi}^i_{1,k},\cdots,\widehat{\xi}^i_{k-1,k},\widehat{\xi}^i_{k,k}\right), \quad \left(\xi^i_{0,k},\xi^i_{1,k},\cdots,\xi^i_{k-1,k},\xi_{k,k}\right)&lt;/math&gt;

of the individuals &lt;math&gt;\widehat{\xi}^i_{k}\left(=\widehat{\xi}^i_{k,k}\right)&lt;/math&gt; and &lt;math&gt;\xi^i_{k}\left(={\xi}^i_{k,k}\right)&lt;/math&gt; at every time step ''k'', we also have the particle approximations

:&lt;math&gt;\begin{align}
\widehat{p}(d(x_0,\cdots,x_k)|y_0,\cdots,y_k) &amp;:=\frac{1}{N}\sum_{i=1}^N \delta_{\left(\widehat{\xi}^i_{0,k},\cdots,\widehat{\xi}^i_{0,k}\right)}(d(x_0,\cdots,x_k)) \\
&amp;\approx_{N\uparrow\infty} p(d(x_0,\cdots,x_k)|y_0,\cdots,y_k) \\
&amp;\approx_{N\uparrow\infty} \sum_{i=1}^N \frac{p(y_k|\xi^i_{k,k})}{\sum_{j=1}^Np(y_k|\xi^j_{k,k})} \delta_{\left(\xi^i_{0,k},\cdots,\xi^i_{0,k}\right)}(d(x_0,\cdots,x_k)) \\
&amp; \ \\
\widehat{p}(d(x_0,\cdots,x_k)|y_0,\cdots,y_{k-1}) &amp;:=\frac{1}{N}\sum_{i=1}^N \delta_{\left(\xi^i_{0,k},\cdots,\xi^i_{k,k}\right)}(d(x_0,\cdots,x_k)) \\
&amp;\approx_{N\uparrow\infty} p(d(x_0,\cdots,x_k)|y_0,\cdots,y_{k-1}) \\
&amp;:=p(x_0,\cdots,x_k|y_0,\cdots,y_{k-1}) dx_0,\cdots,dx_k
\end{align}&lt;/math&gt;

These empirical approximations are equivalent to the particle integral approximations

:&lt;math&gt;\begin{align}
\int F(x_0,\cdots,x_n) \widehat{p}(d(x_0,\cdots,x_k)|y_0,\cdots,y_k) &amp;:=\frac{1}{N}\sum_{i=1}^N F\left(\widehat{\xi}^i_{0,k},\cdots,\widehat{\xi}^i_{0,k}\right) \\
&amp;\approx_{N\uparrow\infty} \int F(x_0,\cdots,x_n) p(d(x_0,\cdots,x_k)|y_0,\cdots,y_k) \\
&amp;\approx_{N\uparrow\infty} \sum_{i=1}^N \frac{p(y_k|\xi^i_{k,k})}{\sum_{j=1}^N p(y_k|\xi^j_{k,k})} F\left(\xi^i_{0,k}, \cdots,\xi^i_{k,k} \right) \\
&amp; \ \\
\int F(x_0,\cdots,x_n) \widehat{p}(d(x_0,\cdots,x_k)|y_0,\cdots,y_{k-1}) &amp;:=\frac{1}{N} \sum_{i=1}^N F\left(\xi^i_{0,k},\cdots,\xi^i_{k,k}\right) \\
&amp;\approx_{N\uparrow\infty} \int F(x_0,\cdots,x_n) p(d(x_0,\cdots,x_k)|y_0,\cdots,y_{k-1})
\end{align}&lt;/math&gt;

for any bounded function ''F'' on the random trajectories of the signal. As shown in&lt;ref name=":3" /&gt; the evolution of the genealogical tree coincides with a mean field particle interpretation of the evolution equations associated with the posterior densities of the signal trajectories. For more details on these path space models, we refer to the books.&lt;ref name="dp13" /&gt;&lt;ref name=":1" /&gt;

=== Unbiased particle estimates of likelihood functions ===

We use the product formula

:&lt;math&gt;p(y_0,\cdots,y_n)=\prod_{k=0}^n p(y_k|y_0,\cdots,y_{k-1})&lt;/math&gt;

with

:&lt;math&gt;p(y_k|y_0,\cdots,y_{k-1})=\int p(y_k|x_k) p(dx_k|y_0,\cdots,y_{k-1})&lt;/math&gt;

and  the conventions &lt;math&gt;p(y_0|y_0,\cdots,y_{-1})=p(y_0)&lt;/math&gt; and &lt;math&gt;p(x_0|y_0,\cdots,y_{-1})=p(x_0),&lt;/math&gt; for ''k'' = 0. Replacing &lt;math&gt;p(x_k|y_0,\cdots,y_{k-1})dx_k&lt;/math&gt; by the [[empirical measure|empirical]] approximation

:&lt;math&gt;\widehat{p}(dx_k|y_0,\cdots,y_{k-1}):=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^i_k}(dx_k) \approx_{N\uparrow\infty} p(dx_k|y_0,\cdots,y_{k-1})&lt;/math&gt;

in the above displayed formula, we design the following unbiased particle approximation of the likelihood function

:&lt;math&gt;p(y_0,\cdots,y_n) \approx_{N\uparrow\infty} \widehat{p}(y_0,\cdots,y_n)=\prod_{k=0}^n \widehat{p}(y_k|y_0,\cdots,y_{k-1}) &lt;/math&gt;

with

:&lt;math&gt;\widehat{p}(y_k|y_0,\cdots,y_{k-1})=\int p(y_k|x_k) \widehat{p}(dx_k|y_0,\cdots,y_{k-1})=\frac{1}{N}\sum_{i=1}^N p(y_k|\xi^i_k)&lt;/math&gt;

where &lt;math&gt;p(y_k|\xi^i_k)&lt;/math&gt; stands for the density &lt;math&gt;p(y_k|x_k)&lt;/math&gt; evaluated at &lt;math&gt;x_k=\xi^i_k&lt;/math&gt;. The design of this particle estimate and the unbiasedness property has been proved in 1996 in the article.&lt;ref name="dm962"/&gt; Refined variance estimates can be found in&lt;ref name=":1" /&gt; and.&lt;ref name="dp13" /&gt;

=== Backward particle smoothers ===
Using Bayes' rule, we have the formula

:&lt;math&gt;p(x_0,\cdots,x_n|y_0,\cdots,y_{n-1}) = p(x_n | y_0,\cdots,y_{n-1}) p(x_{n-1}|x_n, y_0,\cdots,y_{n-1} ) \cdots p(x_1|x_2,y_0,y_1) p(x_0|x_1,y_0)&lt;/math&gt;

Notice that

:&lt;math&gt; \begin{align} 
p(x_{k-1}|x_{k},(y_0,\cdots,y_{k-1})) &amp;\propto p(x_{k}|x_{k-1})p(x_{k-1}|(y_0,\cdots,y_{k-1})) \\
p(x_{k-1}|(y_0,\cdots,y_{k-1}) &amp;\propto p(y_{k-1}|x_{k-1})p(x_{k-1}|(y_0,\cdots,y_{k-2})
\end{align}&lt;/math&gt;

This implies that

:&lt;math&gt;p(x_{k-1}|x_k, (y_0,\cdots,y_{k-1}))=\frac{p(y_{k-1}|x_{k-1})p(x_{k}|x_{k-1})p(x_{k-1}|y_0,\cdots,y_{k-2})}{\int p(y_{k-1}|x'_{k-1})p(x_{k}|x'_{k-1})p(x'_{k-1}|y_0,\cdots,y_{k-2}) dx'_{k-1}}&lt;/math&gt;

Replacing the one-step optimal predictors &lt;math&gt;p(x_{k-1}|(y_0,\cdots,y_{k-2}))dx_{k-1}&lt;/math&gt; by the particle [[empirical measure]]s

:&lt;math&gt;\widehat{p}(dx_{k-1}|(y_0,\cdots,y_{k-2}))=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^i_{k-1}}(dx_{k-1}) \left(\approx_{N\uparrow\infty} p(dx_{k-1}|(y_0,\cdots,y_{k-2})):={p}(x_{k-1}|(y_0,\cdots,y_{k-2})) dx_{k-1}\right)&lt;/math&gt;

we find that

:&lt;math&gt;\begin{align}
p(dx_{k-1}| x_{k},(y_0,\cdots,y_{k-1})) &amp;\approx_{N\uparrow\infty} \widehat{p}(dx_{k-1}|x_{k},(y_0,\cdots,y_{k-1})) \\
&amp;:= \frac{p(y_{k-1}|x_{k-1}) p(x_{k}|x_{k-1}) \widehat{p}(dx_{k-1}|y_0,\cdots,y_{k-2})}{\int p(y_{k-1}|x'_{k-1})~p(x_{k}| x'_{k-1}) \widehat{p}(dx'_{k-1}|y_0,\cdots,y_{k-2})}\\
&amp;= \sum_{i=1}^{N} \frac{p(y_{k-1}|\xi^i_{k-1}) p(x_{k}|\xi^i_{k-1})}{\sum_{j=1}^{N} p(y_{k-1}|\xi^j_{k-1}) p(x_{k}|\xi^j_{k-1})} \delta_{\xi^i_{k-1}}(dx_{k-1})
\end{align}&lt;/math&gt;

We conclude that

:&lt;math&gt;p(d(x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1})) \approx_{N\uparrow\infty} \widehat{p}_{backward}(d(x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1}))&lt;/math&gt;

with the backward particle approximation

:&lt;math&gt;\begin{align}
\widehat{p}_{backward} (d(x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1})) = \widehat{p}(dx_n|(y_0,\cdots,y_{n-1})) \widehat{p}(dx_{n-1}|x_n,(y_0,\cdots,y_{n-1})) \cdots \widehat{p}(dx_1|x_2,(y_0,y_1)) \widehat{p}(dx_0|x_1,y_0)
\end{align}&lt;/math&gt;

The probability measure

:&lt;math&gt;\widehat{p}_{backward}(d(x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1}))&lt;/math&gt;

is the probability of the random paths of a Markov chain &lt;math&gt;\left(\mathbb X^{\flat}_{k,n}\right)_{0\leqslant k\leqslant n}&lt;/math&gt;running backward in time from time k=n to time k=0, and evolving at each time step k in the state space associated with the population of particles &lt;math&gt;\xi^i_k,  i=1,\cdots,N.&lt;/math&gt;
* Initially (at time k=n) the chain &lt;math&gt;\mathbb X^{\flat}_{n,n}&lt;/math&gt; chooses randomly a state with the distribution
::&lt;math&gt;\widehat{p}(dx_{n}|(y_0,\cdots,y_{n-1}))=\frac{1}{N}\sum_{i=1}^N \delta_{\xi^i_{n}}(dx_{n})&lt;/math&gt;
* From time k to the time (k-1), the chain starting at some state &lt;math&gt;\mathbb X^{\flat}_{k,n}=\xi^i_k&lt;/math&gt; for some &lt;math&gt; i=1,\cdots,N&lt;/math&gt; at time k moves at time (k-1) to a random state &lt;math&gt;\mathbb{X}^{\flat}_{k-1,n}&lt;/math&gt; chosen with the discrete weighted probability

:&lt;math&gt;\widehat{p}(dx_{k-1}|\xi^i_{k},(y_0,\cdots,y_{k-1}))= \sum_{j=1}^N\frac{p(y_{k-1}|\xi^j_{k-1}) p(\xi^i_{k}|\xi^j_{k-1})}{\sum_{l=1}^Np(y_{k-1}|\xi^l_{k-1}) p(\xi^i_{k}|\xi^l_{k-1})}~\delta_{\xi^j_{k-1}}(dx_{k-1})&lt;/math&gt;

In the above displayed formula, &lt;math&gt;\widehat{p}(dx_{k-1}|\xi^i_{k},(y_0,\cdots,y_{k-1}))&lt;/math&gt;  stands for the conditional distribution &lt;math&gt;\widehat{p}(dx_{k-1}|x_k, (y_0,\cdots,y_{k-1}))&lt;/math&gt; evaluated at &lt;math&gt;x_k=\xi^i_{k}&lt;/math&gt;. In the same vein, &lt;math&gt;p(y_{k-1}|\xi^j_{k-1})&lt;/math&gt; and &lt;math&gt;p(\xi^i_k|\xi^j_{k-1})&lt;/math&gt; stand for the conditional densities &lt;math&gt;p(y_{k-1}|x_{k-1})&lt;/math&gt; and &lt;math&gt;p(x_k|x_{k-1})&lt;/math&gt; evaluated at &lt;math&gt;x_k=\xi^i_{k}&lt;/math&gt; and &lt;math&gt;x_{k-1}=\xi^j_{k-1}.&lt;/math&gt; These models allows to reduce integration with respect to the densities &lt;math&gt;p((x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1}))&lt;/math&gt; in terms of matrix operations with respect to the Markov transitions of the chain described above.&lt;ref name=":6" /&gt; For instance, for any function &lt;math&gt;f_k&lt;/math&gt; we have the particle estimates

:&lt;math&gt;\begin{align}
\int p(d(x_0,\cdots,x_n)&amp;|(y_0,\cdots,y_{n-1}))f_k(x_k) \\
&amp;\approx_{N\uparrow\infty} \int \widehat{p}_{backward}(d(x_0,\cdots,x_n)| (y_0,\cdots,y_{n-1})) f_k(x_k) \\
&amp;=\int \widehat{p}(dx_n| (y_0,\cdots,y_{n-1})) \widehat{p}(dx_{n-1}|x_n,(y_0,\cdots,y_{n-1})) \cdots \widehat{p}(dx_k| x_{k+1},(y_0,\cdots,y_k)) f_k(x_k) \\
&amp;=\underbrace{\left[\tfrac{1}{N},\cdots,\tfrac{1}{N}\right]}_{N \text{ times}}\mathbb{M}_{n-1} \cdots\mathbb M_{k} \begin{bmatrix} f_k(\xi^1_k)\\
\vdots\\ f_k(\xi^N_k) \end{bmatrix}
\end{align}&lt;/math&gt;

where

:&lt;math&gt;\mathbb M_k= (\mathbb M_k(i,j))_{1\leqslant i,j\leqslant N}: \qquad \mathbb M_k(i,j)=\frac{p(\xi^i_{k}|\xi^j_{k-1})~p(y_{k-1}|\xi^j_{k-1})}{\sum\limits_{l=1}^{N} p(\xi^i_{k}|\xi^l_{k-1}) p(y_{k-1}|\xi^l_{k-1})}&lt;/math&gt;

This also shows that if

:&lt;math&gt;\overline{F}(x_0,\cdots,x_n):=\frac{1}{n+1}\sum_{k=0}^n f_k(x_k)&lt;/math&gt;

then

:&lt;math&gt;\begin{align} 
\int \overline{F}(x_0,\cdots,x_n) p(d(x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1})) &amp;\approx_{N\uparrow\infty} \int \overline{F}(x_0,\cdots,x_n) \widehat{p}_{backward}(d(x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1})) \\
&amp;=\frac{1}{n+1} \sum_{k=0}^n \underbrace{\left[\tfrac{1}{N},\cdots,\tfrac{1}{N}\right]}_{N \text{ times}}\mathbb M_{n-1}\mathbb M_{n-2}\cdots\mathbb{M}_k \begin{bmatrix} f_k(\xi^1_k)\\ \vdots\\ f_k(\xi^N_k) \end{bmatrix}
\end{align}&lt;/math&gt;

=== Some convergence results ===
We shall assume that filtering equation is stable, in the sense that it corrects any erroneous initial condition.

In this situation, the '''particle approximations of the likelihood functions''' are unbiased and the relative variance is controlled by

:&lt;math&gt;E\left(\widehat{p}(y_0,\cdots,y_n)\right)= p(y_0,\cdots,y_n), \qquad E\left(\left[\frac{\widehat{p}(y_0,\cdots,y_n)}{p(y_0,\cdots,y_n)}-1\right]^2\right)\leqslant \frac{cn}{N},&lt;/math&gt;

for some finite constant ''c''. In addition, for any &lt;math&gt;x\geqslant 0&lt;/math&gt;:

:&lt;math&gt;\mathbf{P} \left ( \left\vert \frac{1}{n}\log{\widehat{p}(y_0,\cdots,y_n)}-\frac{1}{n}\log{p(y_0,\cdots,y_n)}\right\vert \leqslant c_1 \frac{x}{N}+c_2 \sqrt{\frac{x}{N}} \right ) &gt; 1-e^{-x} &lt;/math&gt;

for some finite constants &lt;math&gt;c_1, c_2&lt;/math&gt; related to the asymptotic bias and variance of the particle estimate, and for some finite constant ''c''.

The bias and the variance of  '''the particle particle estimates based on the ancestral lines of the genealogical trees'''

:&lt;math&gt;\begin{align}
I^{path}_k(F) &amp;:=\int F(x_0,\cdots,x_k) p(d(x_0,\cdots,x_k)|y_0,\cdots,y_{k-1}) \\
&amp;\approx_{N\uparrow\infty} \widehat{I}^{path}_k(F) \\
&amp;:=\int F(x_0,\cdots,x_k) \widehat{p}(d(x_0,\cdots,x_k)|y_0,\cdots,y_{k-1}) \\
&amp;=\frac{1}{N}\sum_{i=1}^N F\left(\xi^i_{0,k},\cdots,\xi^i_{k,k}\right)
\end{align}&lt;/math&gt;

are controlled by the non asymptotic uniform estimates

:&lt;math&gt;\left| E\left(\widehat{I}^{path}_k(F)\right)-I_k^{path}(F)\right|\leqslant \frac{c_1 k}{N}, \qquad E\left(\left[\widehat{I}^{path}_k(F)-I_k^{path}(F)\right]^2\right)\leqslant \frac{c_2 k}{N},&lt;/math&gt;

for any function ''F'' bounded by 1, and for some finite constants &lt;math&gt;c_1, c_2.&lt;/math&gt; In addition, for any &lt;math&gt;x\geqslant 0&lt;/math&gt;:

:&lt;math&gt;\mathbf{P} \left ( \left|  \widehat{I}^{path}_k(F)-I_k^{path}(F)\right | \leqslant c_1 \frac{kx}{N}+c_2 \sqrt{\frac{kx}{N}} \land \sup_{0\leqslant k\leqslant n}\left| \widehat{I}_k^{path}(F)-I^{path}_k(F)\right| \leqslant c \sqrt{\frac{xn\log(n)}{N}} \right ) &gt; 1-e^{-x}&lt;/math&gt;

for some finite constants &lt;math&gt;c_1, c_2&lt;/math&gt; related to the asymptotic bias and variance of the particle estimate, and for some finite constant ''c''. The same type of bias and variance estimates hold for the backward particle smoothers. For additive functionals of the form

:&lt;math&gt;\overline{F}(x_0,\cdots,x_n):=\frac{1}{n+1}\sum_{0\leqslant k\leqslant n}f_k(x_k)&lt;/math&gt;

with

:&lt;math&gt;I^{path}_n(\overline{F}) \approx_{N\uparrow\infty} I^{\flat, path}_n(\overline{F}):=\int \overline{F}(x_0,\cdots,x_n) \widehat{p}_{backward}(d(x_0,\cdots,x_n)|(y_0,\cdots,y_{n-1}))&lt;/math&gt;

with functions &lt;math&gt;f_k&lt;/math&gt; bounded by 1, we have

:&lt;math&gt;\sup_{n\geqslant 0}{\left\vert E\left(\widehat{I}^{\flat,path}_n(\overline{F})\right)-I_n^{path}(\overline{F})\right\vert} \leqslant \frac{c_1}{N}&lt;/math&gt;

and

:&lt;math&gt;E\left(\left[\widehat{I}^{\flat,path}_n(F)-I_n^{path}(F)\right]^2\right)\leqslant \frac{c_2}{nN}+ \frac{c_3}{N^2}&lt;/math&gt;

for some finite constants &lt;math&gt;c_1,c_2,c_3.&lt;/math&gt; More refined estimates including exponentially small probability of errors are developed in.&lt;ref name="dp13" /&gt;

== Sequential Importance Resampling (SIR) ==

=== The bootstrap filter ===
''Sequential importance [[Resampling (statistics)|Resampling]] (SIR)'', the original bootstrap filtering algorithm (Gordon et al. 1993), is also a very commonly used filtering algorithm, which approximates the filtering probability density &lt;math&gt;p(x_k|y_0,\cdots,y_k)&lt;/math&gt; by a weighted set of ''N'' samples

: &lt;math&gt; \left \{ \left (w^{(i)}_k,x^{(i)}_k \right ) \ : \ i\in\{1,\cdots,N\} \right \}.&lt;/math&gt;

The ''importance weights'' &lt;math&gt;w^{(i)}_k&lt;/math&gt; are approximations to the relative posterior probabilities (or densities) of the samples such that

:&lt;math&gt;\sum_{i=1}^N w^{(i)}_k = 1.&lt;/math&gt;

Sequential importance sampling (SIS) is a sequential (i.e., recursive) version of [[importance sampling]]. As in importance sampling, the expectation of a function ''f'' can be approximated as a weighted average

: &lt;math&gt; \int f(x_k) p(x_k|y_0,\dots,y_k) dx_k \approx \sum_{i=1}^N w_k^{(i)} f(x_k^{(i)}).&lt;/math&gt;

For a finite set of samples, the algorithm performance is dependent on the choice of the ''proposal distribution''

: &lt;math&gt;\pi(x_k|x_{0:k-1},y_{0:k})\, &lt;/math&gt;.

The "''optimal" proposal distribution'' is given as the ''target distribution''
: &lt;math&gt;\pi(x_k|x_{0:k-1},y_{0:k}) = p(x_k|x_{k-1},y_{k})=\frac{p(y_k|x_k)}{\int p(y_k|x_k)p(x_k|x_{k-1})dx_k}~p(x_k|x_{k-1}).&lt;/math&gt;

This particular choice of proposal transition has been proposed by P. Del Moral in 1996 and 1998.&lt;ref name=":22"/&gt; When it is difficult to sample transitions according to the distribution  &lt;math&gt; p(x_k|x_{k-1},y_{k})&lt;/math&gt; one natural strategy is to use the following particle approximation

:&lt;math&gt;\begin{align} 
\frac{p(y_k|x_k)}{\int p(y_k|x_k)p(x_k|x_{k-1})dx_k} p(x_k|x_{k-1})dx_k &amp;\simeq_{N\uparrow\infty} \frac{p(y_k|x_k)}{\int p(y_k|x_k)\widehat{p}(dx_k|x_{k-1})} \widehat{p}(dx_k|x_{k-1}) \\
&amp;= \sum_{i=1}^N \frac{p(y_k|X^i_k(x_{k-1}))}{\sum_{j=1}^N p(y_k|X^j_k(x_{k-1}))} \delta_{X^i_k(x_{k-1})}(dx_k)
\end{align}&lt;/math&gt;

with the empirical approximation

:&lt;math&gt; \widehat{p}(dx_k|x_{k-1})= \frac{1}{N}\sum_{i=1}^{N} \delta_{X^i_k(x_{k-1})}(dx_k)~\simeq_{N\uparrow\infty} p(x_k|x_{k-1})dx_k &lt;/math&gt;

associated with ''N'' (or any other large number of samples) independent random samples &lt;math&gt;X^i_k(x_{k-1}), i=1,\cdots,N &lt;/math&gt;with the conditional distribution of the random state &lt;math&gt;X_k&lt;/math&gt; given &lt;math&gt;X_{k-1}=x_{k-1}&lt;/math&gt;. The consistency of the resulting particle filter of this approximation and other extensions are developed in.&lt;ref name=":22"/&gt; In the above display &lt;math&gt;\delta_a&lt;/math&gt; stands for the '''[[Dirac measure]]''' at a given state a.

However, the transition prior probability distribution is often used as importance function, since it is easier to draw particles (or samples) and perform subsequent importance weight calculations:
: &lt;math&gt;\pi(x_k|x_{0:k-1},y_{0:k}) = p(x_k|x_{k-1}).&lt;/math&gt;
''Sequential Importance Resampling'' (SIR) filters with transition prior probability distribution as importance function are commonly known as [[Resampling (statistics)#Bootstrap|bootstrap filter]] and [[condensation algorithm]].

''Resampling'' is used to avoid the problem of degeneracy of the algorithm, that is, avoiding the situation that all but one of the importance weights are close to zero. The performance of the algorithm can be also affected by proper choice of resampling method. The ''[[stratified sampling]]'' proposed by Kitagawa (1996) is optimal in terms of variance.

A single step of sequential importance resampling is as follows:

:1) For &lt;math&gt;i=1,\cdots,N&lt;/math&gt; draw samples from the ''proposal distribution''
:: &lt;math&gt;x^{(i)}_k \sim \pi(x_k|x^{(i)}_{0:k-1},y_{0:k})&lt;/math&gt;

:2) For &lt;math&gt;i=1,\cdots,N&lt;/math&gt; update the importance weights up to a normalizing constant:
::&lt;math&gt;\hat{w}^{(i)}_k = w^{(i)}_{k-1} \frac{p(y_k|x^{(i)}_k) p(x^{(i)}_k|x^{(i)}_{k-1})} {\pi(x_k^{(i)}|x^{(i)}_{0:k-1},y_{0:k})}.&lt;/math&gt;
: Note that when we use the transition prior probability distribution as the importance function, 
::&lt;math&gt; \pi(x_k^{(i)}|x^{(i)}_{0:k-1},y_{0:k}) = p(x^{(i)}_k|x^{(i)}_{k-1}),&lt;/math&gt;
:this simplifies to the following :
::&lt;math&gt; \hat{w}^{(i)}_k = w^{(i)}_{k-1} p(y_k|x^{(i)}_k), &lt;/math&gt;

:3) For &lt;math&gt;i=1,\cdots,N&lt;/math&gt; compute the normalized importance weights:
:: &lt;math&gt;w^{(i)}_k = \frac{\hat{w}^{(i)}_k}{\sum_{j=1}^N \hat{w}^{(j)}_k}&lt;/math&gt;

:4) Compute an estimate of the effective number of particles as
:: &lt;math&gt;\hat{N}_\mathit{eff} = \frac{1}{\sum_{i=1}^N\left(w^{(i)}_k\right)^2} &lt;/math&gt;
:This criterion reflects the variance of the weights, other criteria can be found in the article,&lt;ref name=":0"/&gt; including their rigorous analysis and central limit theorems.

:5) If the effective number of particles is less than a given threshold &lt;math&gt;\hat{N}_\mathit{eff} &lt; N_{thr}&lt;/math&gt;, then perform resampling:
::a) Draw ''N'' particles from the current particle set with probabilities proportional to their weights. Replace the current particle set with this new one.
::b) For &lt;math&gt;i=1,\cdots,N&lt;/math&gt; set &lt;math&gt;w^{(N)}_k = 1/N.&lt;/math&gt;

The term ''Sampling Importance Resampling'' is also sometimes used when referring to SIR filters.

=== Sequential importance sampling (SIS) ===
* Is the same as sequential importance resampling, but without the resampling stage.

=== "direct version" algorithm ===
{{confusing section|date=October 2011}}
The "direct version" algorithm {{citation needed|date=October 2011}} is rather simple (compared to other particle filtering algorithms) and it uses composition and rejection. To generate a single sample ''x'' at ''k'' from &lt;math&gt;p_{x_k|y_{1:k}}(x|y_{1:k})&lt;/math&gt;:

:1) Set n=0 (This will count the number of particles generated so far)

:2) [[Uniform distribution (discrete)|Uniformly]] choose an index i from the range &lt;math&gt;\{1,..., N\}&lt;/math&gt;

:3) Generate a test &lt;math&gt;\hat{x}&lt;/math&gt; from the distribution &lt;math&gt;p(x_k|x_{k-1})&lt;/math&gt; with &lt;math&gt; x_{k-1}=x_{k-1|k-1}^{(i)}&lt;/math&gt;

:4) Generate the probability of &lt;math&gt;\hat{y}&lt;/math&gt; using &lt;math&gt;\hat{x}&lt;/math&gt; from &lt;math&gt;p(y_k|x_k),~\mbox{with}~x_k=\hat{x}&lt;/math&gt; where &lt;math&gt;y_k&lt;/math&gt; is the measured value

:5) Generate another [[Uniform distribution (continuous)|uniform]] u from &lt;math&gt;[0, m_k]&lt;/math&gt; where &lt;math&gt;m_k = \sup_{x_k} p(y_k|x_k) &lt;/math&gt;

:6) Compare u and &lt;math&gt;p\left(\hat{y}\right)&lt;/math&gt;

::6a) If u is larger then repeat from step 2

::6b) If u is smaller then save &lt;math&gt;\hat{x}&lt;/math&gt; as &lt;math&gt;x_{k|k}^{(i)}&lt;/math&gt; and increment n

:7) If n == N then quit

The goal is to generate P "particles" at ''k'' using only the particles from &lt;math&gt;k-1&lt;/math&gt;. This requires that a Markov equation can be written (and computed) to generate a &lt;math&gt;x_k&lt;/math&gt; based only upon &lt;math&gt;x_{k-1}&lt;/math&gt;. This algorithm uses composition of the P particles from &lt;math&gt;k-1&lt;/math&gt; to generate a particle at ''k'' and repeats (steps 2–6) until P particles are generated at ''k''.

This can be more easily visualized if ''x'' is viewed as a two-dimensional array. One dimension is ''k'' and the other dimensions is the particle number. For example, &lt;math&gt;x(k,i)&lt;/math&gt; would be the i&lt;sup&gt;th&lt;/sup&gt; particle at &lt;math&gt;k&lt;/math&gt; and can also be written &lt;math&gt;x_k^{(i)}&lt;/math&gt; (as done above in the algorithm). Step 3 generates a ''potential'' &lt;math&gt;x_k&lt;/math&gt; based on a randomly chosen particle (&lt;math&gt;x_{k-1}^{(i)}&lt;/math&gt;) at time &lt;math&gt;k-1&lt;/math&gt; and rejects or accepts it in step 6. In other words, the &lt;math&gt;x_k&lt;/math&gt; values are generated using the previously generated &lt;math&gt;x_{k-1}&lt;/math&gt;.

==Other particle filters==
* [[Exponential Natural Particle Filter]]&lt;ref name="xnpf2015"&gt;{{cite arXiv
 | author = Zand, G.
 | author2= Taherkhani, M. |author3=Safabakhsh, R. 
 | year = 2015
 | title = Exponential Natural Particle Filter
 | arxiv = 1511.06603
}}&lt;/ref&gt;
* [[Auxiliary particle filter]]&lt;ref name="apf1999"&gt;{{cite journal
 | author = Pitt, M.K.
 |author2=Shephard, N.
 | year = 1999
 | title = Filtering Via Simulation: Auxiliary Particle Filters
 | journal = Journal of the American Statistical Association
 | volume = 94
 | issue = 446
 | pages = 590–591
 | url = https://www.questia.com/PM.qst?a=o&amp;se=gglsc&amp;d=5002321997 
 | accessdate = 2008-05-06
 | doi = 10.2307/2670179
 | jstor = 2670179
 | publisher = American Statistical Association
}}&lt;/ref&gt;
* [[Regularized auxiliary particle filter]]&lt;ref name="jliu2011"&gt;{{cite journal
 | author = Liu, J.
 |author2=Wang, W. |author3=Ma, F. 
 | year = 2011
 | title = A Regularized Auxiliary Particle Filtering Approach for System State Estimation and Battery Life Prediction
 | journal = Smart Materials and Structures
 | volume = 20
 | issue = 7
 | pages = 1–9
 | doi = 10.1088/0964-1726/20/7/075021
| bibcode = 2011SMaS...20g5021L}}&lt;/ref&gt;
* Gaussian particle filter
* Unscented particle filter
* Gauss–Hermite particle filter
* Cost Reference particle filter
* Hierarchical/Scalable particle filter&lt;ref name="Canton2011"&gt;{{cite journal
 | author = Canton-Ferrer, C.
 |author2=Casas, J.R. |author3=Pardàs, M. 
 | year = 2011
 | title = Human Motion Capture Using Scalable Body Models
 | journal = Computer Vision and Image Understanding
 | volume = 115
 | issue = 10
 | pages = 1363–1374
 | doi = 10.1016/j.cviu.2011.06.001
 | publisher = Elsevier
}}&lt;/ref&gt;
* Rao–Blackwellized particle filter&lt;ref name="rbpf1999"/&gt;
* [[Rejection sampling|Rejection-sampling]] based optimal particle filter&lt;ref name="optrj2008"&gt;{{cite conference
| citeseerx           = 10.1.1.190.7092
| title         = An Optimal Filtering Algorithm for Non-Parametric Observation Models in Robot Localization
| author        = Blanco, J.L. |author2=Gonzalez, J. |author3=Fernandez-Madrigal, J.A.
| year          = 2008
| conference    = IEEE International Conference on Robotics and Automation (ICRA'08)
| pages         = 461–466
}}
&lt;/ref&gt;&lt;ref name="optrj2010"&gt;{{cite journal
| url           = http://ijr.sagepub.com/content/29/14/1726.full.pdf
| title         = Optimal Filtering for Non-Parametric Observation Models: Applications to Localization and SLAM
| author        = Blanco, J.L. |author2=Gonzalez, J. |author3=Fernandez-Madrigal, J.A.
| year          = 2010
| journal       = The International Journal of Robotics Research (IJRR)
| volume        = 29
| number        = 14
| pages         = 1726–1742
| doi           = 10.1177/0278364910364165
}}
&lt;/ref&gt;
* Feynman-Kac and mean field particle methodologies&lt;ref name="dm962"/&gt;&lt;ref name="dp13" /&gt;&lt;ref name=":1" /&gt;
* Particle Markov-Chain Monte-Carlo

==See also==
* [[Mean field particle methods]]
* [[Genetic algorithm]]
* [[Ensemble Kalman filter]]
* [[Generalized filtering]]
* [[Moving horizon estimation]]
* [[Recursive Bayesian estimation]]
* [[Monte Carlo localization]]

==References==
{{Reflist}}

== Bibliography ==
* {{cite journal | last1 = Del Moral | first1 = Pierre | year = 1996 | title = Non Linear Filtering: Interacting Particle Solution | url = http://web.maths.unsw.edu.au/~peterdel-moral/mprfs.pdf | format = PDF | journal = Markov Processes and Related Fields | volume = 2 | issue = 4| pages = 555–580 }}
* Del Moral, Pierre (2004). ''[https://www.springer.com/us/book/9780387202686#reviews Feynman-Kac formulae. Genealogical and interacting particle approximations]''. Springer. p.&amp;nbsp;575. &lt;q&gt;Series: Probability and Applications&lt;/q&gt;
* Del Moral, Pierre (2013). ''[https://www.crcpress.com/product/isbn/9781466504059 Mean field simulation for Monte Carlo integration]''[https://www.crcpress.com/product/isbn/9781466504059 .] Chapman &amp; Hall/CRC Press. p.&amp;nbsp;626. &lt;q&gt;Monographs on Statistics &amp; Applied Probability&lt;/q&gt;
* {{cite book
 | author = Cappe, O. |author2=Moulines, E. |author3=Ryden, T.
 | year = 2005
 | title = Inference in Hidden Markov Models
 | publisher = Springer
 | isbn = 
}}
*{{cite journal
 | author = Liu, J.S.,
 |author2=Chen, R.
 | year = 1998
 | title = Sequential Monte Carlo methods for dynamic systems
 | journal = Journal of the American Statistical Association
 | publisher = Taylor &amp; Francis Group
 | volume = 93
 | issue = 443
 | pages = 1032–1044
 | url = http://www.people.fas.harvard.edu/~junliu/TechRept/98folder/liu&amp;chen98_2.pdf
 | doi = 10.1080/01621459.1998.10473765
}}
* {{cite book
 | author = Liu, J.S.
 | year = 2001
 | title = Monte Carlo strategies in Scientific Computing
 | publisher = Springer
 | isbn = 
}}
*{{cite journal
 | author = Kong, A.
 |author2=Liu, J.S. |author3=Wong, W.H. 
 | year = 1994
 | title = Sequential imputations and Bayesian missing data problems
 | journal = Journal of the American Statistical Association
 | publisher = Taylor &amp; Francis Group
 | volume = 89
 | issue = 425
 | pages = 278–288
 | url = http://www.people.fas.harvard.edu/~junliu/TechRept/94folder/klw94.pdf
 | doi = 10.1080/01621459.1994.10476469
}}
*{{cite journal
 | author = Liu, J.S.
 |author2=Chen, R.
 | year = 1995
 | title = Blind deconvolution via sequential imputations
 | journal = Journal of the American Statistical Association
 | publisher = Taylor &amp; Francis Group
 | volume = 90
 | issue = 430
 | pages = 567–576
 | url = http://www.people.fas.harvard.edu/~junliu/TechRept/95folder/liu&amp;chen95_s.pdf
 | doi = 10.2307/2291068
}}
* {{cite book
 | author = Ristic, B. |author2=Arulampalam, S. |author3=Gordon, N.
 | year = 2004
 | title = Beyond the Kalman Filter: Particle Filters for Tracking Applications
 | publisher = Artech House
 | isbn = 
}}
* {{cite journal
 | author = Doucet, A.
 |author2=Johansen, A.M.
 | year = December 2008
 | title = A tutorial on particle filtering and smoothing: fifteen years later
 | journal = Technical report
 | publisher = Department of Statistics, University of British Columbia
 | volume = 
 | issue = 
 | pages = 
 | url = http://www.cs.ubc.ca/%7Earnaud/doucet_johansen_tutorialPF.pdf
 | doi = 
}}
* {{cite journal
 | author = Doucet, A. |author2=Godsill, S. |author3=Andrieu, C.
 | year = 2000
 | title = On sequential Monte Carlo sampling methods for Bayesian filtering
 | journal = Statistics and Computing
 | volume = 10
 | issue = 3
 | pages = 197–208
 | url = http://www.springerlink.com/content/q6452k2x37357l3r/
 | doi = 10.1023/A:1008935410038
}}
* {{cite journal
 | author = Arulampalam, M.S. |author2=Maskell, S. |author3=Gordon, N. |author4=Clapp, T.
 | year = 2002
 | title = A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking
 | journal = IEEE Transactions on Signal Processing
 | volume = 50
 | issue = 2
 | pages = 174–188
 | url = http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=978374
 | doi = 10.1109/78.978374 
| bibcode = 2002ITSP...50..174A}}
* {{cite journal
 | author = Cappe, O. |author2=Godsill, S. |author3=Moulines, E.
 | year = 2007
 | title = An overview of existing methods and recent advances in sequential Monte Carlo
 | journal = Proceedings of the IEEE
 | volume = 95
 | issue = 5
 | doi = 10.1109/JPROC.2007.893250
 | pages = 899–924
}}
* {{cite journal
 | author = Kitagawa, G.
 | year = 1996
 | title =Monte carlo filter and smoother for non-Gaussian nonlinear state space models
 | volume = 5
 | issue = 1
 | journal = Journal of Computational and Graphical Statistics
 | pages = 1–25
 | doi = 10.2307/1390750
 | jstor = 1390750
}}
* {{cite journal
 | author = Kotecha, J.H.
 |author2=Djuric, P.
 | year = 2003
 | title =Gaussian Particle filtering
 | volume = 51
 | issue = 10
 | journal = IEEE Transactions on Signal Processing
}}
* {{cite journal
 | author = Haug, A.J.
 | year = 2005
 | title = A Tutorial on Bayesian Estimation and Tracking Techniques Applicable to Nonlinear and Non-Gaussian Processes
 | journal = [[MITRE Corporation|The MITRE Corporation]], USA, Tech. Rep., Feb
 | url = http://www.mitre-corporation.net/work/tech_papers/tech_papers_05/05_0211/05_0211.pdf 
 | accessdate = 2008-05-06
}}
* {{cite journal
 | author = Pitt, M.K.
 |author2=Shephard, N.
 | year = 1999
 | title = Filtering Via Simulation: Auxiliary Particle Filters
 | journal = Journal of the American Statistical Association
 | volume = 94
 | issue = 446
 | pages = 590–591
 | url = https://www.questia.com/PM.qst?a=o&amp;se=gglsc&amp;d=5002321997 
 | accessdate = 2008-05-06
 | doi = 10.2307/2670179
 | jstor = 2670179
 | publisher = Journal of the American Statistical Association, Vol. 94, No. 446
}}
* {{cite journal
 | author = Gordon, N. J. |author2=Salmond, D. J. |author3=Smith, A. F. M.
 | year = 1993
 | title = Novel approach to nonlinear/non-Gaussian Bayesian state estimation
 | journal = IEE Proceedings F on Radar and Signal Processing
 | volume = 140
 | issue = 2
 | pages = 107–113
 | url = http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=210672 
 | accessdate = 2009-09-19
 | doi = 10.1049/ip-f-2.1993.0015
}}
* {{cite journal
 | author = Chen, Z.
 | year = 2003
 | title = Bayesian Filtering: From Kalman Filters to Particle Filters, and Beyond
 | citeseerx = 10.1.1.107.7415
 | doi = 
 | accessdate = }}
* {{cite journal
  | author = Vaswani, N.
 |author2=Rathi, Y. |author3=Yezzi, A. |author4=Tannenbaum, A.
  | year = 2007
  | title = Tracking deforming objects using particle filtering for geometric active contours
  | journal = IEEE Transactions on Pattern Analysis and Machine Intelligence
  | volume = 29
  | issue = 8
  | pages = 1470–1475
  | doi=10.1109/tpami.2007.1081
}}

==External links==
{{refbegin}}
* [http://web.maths.unsw.edu.au/~peterdel-moral/simulinks.html Feynman–Kac models and interacting particle algorithms (a.k.a. Particle Filtering)] Theoretical aspects and a list of application domains of particle filters
* [http://www-sigproc.eng.cam.ac.uk/smc/ Sequential Monte Carlo Methods (Particle Filtering)] homepage on University of Cambridge
* [https://web.archive.org/web/20060612210237/http://www.cs.washington.edu/ai/Mobile_Robotics/mcl/ Dieter Fox's MCL Animations]
* [http://blogs.oregonstate.edu/hess/code/particles/ Rob Hess' free software]
* [http://www.jstatsoft.org/v30/i06/ SMCTC: A Template Class for Implementing SMC algorithms in C++]
* [http://www.oursland.net/projects/particlefilter/ Java applet on particle filtering]
* [https://zhouyan.github.io/vSMC/ vSMC : Vectorized Sequential Monte Carlo]
* [https://www.youtube.com/watch?v=bO_GajDgGJ4/ Particle filter explained in the context of self driving car]
{{refend}}

{{Stochastic processes}}

{{Statistics}}

{{DEFAULTSORT:Particle Filter}}
[[Category:Monte Carlo methods]]
[[Category:Computational statistics]]
[[Category:Control theory|*]]
[[Category:Nonlinear filters]]
[[Category:Robot control]]
[[Category:Statistical mechanics]]
[[Category:Sampling techniques]]
[[Category:Stochastic simulation]]</text>
      <sha1>kd2smqgaphf3wobwl01z51tv1e1pn40</sha1>
    </revision>
  </page>
  <page>
    <title>Perfect number</title>
    <ns>0</ns>
    <id>23670</id>
    <revision>
      <id>868933163</id>
      <parentid>867661787</parentid>
      <timestamp>2018-11-15T09:24:08Z</timestamp>
      <contributor>
        <username>Deryni</username>
        <id>17616659</id>
      </contributor>
      <comment>Another illustration.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="29173">{{About||the 2012 film|Perfect Number (film)}}
[[File:6 är det första perfekta talet.jpg|thumb|Six is the first perfect number]]
[[File:Perfect number Cuisenaire rods 6.png|thumb|Illustration of the perfect number status of the number 6]]

In [[number theory]], a '''perfect number''' is a [[positive integer]] that is equal to the sum of its proper positive [[divisor]]s, that is, the sum of its positive divisors excluding the number itself (also known as its [[aliquot sum]]). Equivalently, a perfect number is a number that is half the sum of all of its positive divisors (including itself) i.e. [[divisor function|''σ''&lt;sub&gt;1&lt;/sub&gt;]](''n'')&amp;nbsp;=&amp;nbsp;2''n''.

This definition is ancient, appearing as early as [[Euclid's Elements]] (VII.22) where it is called {{lang|grc|τέλειος ἀριθμός}} (''perfect'', ''ideal'', or ''complete number''). [[Euclid]] also proved a formation rule (IX.36) whereby &lt;math&gt;q(q+1)/2&lt;/math&gt; is an even perfect number whenever &lt;math&gt;q&lt;/math&gt; is a prime of the form &lt;math&gt;2^p -1&lt;/math&gt; for prime &lt;math&gt;p&lt;/math&gt;—what is now called a [[Mersenne prime]]. Two millenia later, [[Euler]] proved that all even perfect numbers are of this form.&lt;ref name="The Euclid–Euler theorem"&gt;Caldwell, Chris, [https://primes.utm.edu/notes/proofs/EvenPerfect.html "A proof that all even perfect numbers are a power of two times a Mersenne prime"].&lt;/ref&gt; This is known as the [[Euclid–Euler theorem]].

It is not known whether there are any odd perfect numbers, nor whether infinitely many perfect numbers exist.

==Examples==
The first perfect number is [[6 (number)|6]]. Its proper divisors are 1, 2, and 3, and 1 + 2 + 3 = 6. Equivalently, the number 6 is equal to half the sum of all its positive divisors:  ( 1 + 2 + 3 + 6 ) ÷ 2 = 6. The next perfect number is [[28 (number)|28]]: 28 = 1 + 2 + 4 + 7 + 14. This is followed by the perfect numbers [[496 (number)|496]] and [[8128 (number)|8128]] {{OEIS|id=A000396}}.

==History==

In about 300&amp;nbsp;BC Euclid showed that if 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 is prime then 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) is perfect.
The first four perfect numbers were the only ones known to early [[Greek mathematics]], and the mathematician [[Nicomachus]] had noted 8128 as early as 100&amp;nbsp;AD.&lt;ref name="Dickinson LE (1919)"&gt;{{cite book|last=Dickson|first=L. E. | authorlink = L. E. Dickson|title=History of the Theory of Numbers, Vol. I|page=4|year=1919|publisher=Carnegie Institution of Washington|location=Washington|url=https://archive.org/stream/historyoftheoryo01dick#page/4/}}&lt;/ref&gt; [[Philo of Alexandria]] in his first-century book "On the creation" mentions perfect numbers, claiming that the world was created in 6 days and the moon orbits in 28 days because 6 and 28 are perfect. Philo is followed by [[Origen]],&lt;ref&gt;Commentary on the Gospel of John 28.1.1-4, with further references in the [[Sources Chrétiennes]] edition: vol. 385, 58–61.&lt;/ref&gt; and by [[Didymus the Blind]],  who adds the observation that there are only four perfect numbers that are less than 10,000. (Commentary on Genesis 1. 14-19).&lt;ref&gt;http://torreys.org/sblpapers2015/S22-05_philonic_arithmological_exegesis.pdf&lt;/ref&gt; St Augustine defines perfect numbers in [[City of God (book)|City of God]] (Part XI, Chapter 30) in the early 5th century AD, repeating the claim that God created the world in 6 days because 6 is the smallest perfect number. The Egyptian mathematician Ismail ibn Fallūs (1194–1252) mentioned the next three perfect numbers (33,550,336; 8,589,869,056; and 137,438,691,328) and listed a few more which are now known to be incorrect.&lt;ref&gt;Roshdi Rashed, ''The Development of Arabic Mathematics: Between Arithmetic and Algebra'' (Dordrecht: Kluwer Academic Publishers, 1994), pp.&amp;nbsp;328–329.&lt;/ref&gt; In a manuscript written between 1456 and 1461, an unknown mathematician recorded the earliest European reference to a fifth perfect number, with 33,550,336 being correctly identified for the first time.&lt;ref&gt;[[Munich]], [[Bayerische Staatsbibliothek]], Clm 14908&lt;/ref&gt;&lt;ref name="Smith DE (1958)"&gt;{{cite book|last=Smith|first=DE|title=The History of Mathematics: Volume II|year=1958|publisher=Dover|location=New York|isbn=0-486-20430-8|pages=21|url=https://archive.org/stream/historyofmathema031897mbp#page/n35/mode/2up}}&lt;/ref&gt; In 1588, the Italian mathematician [[Pietro Cataldi]] also identified the sixth (8,589,869,056) and the seventh (137,438,691,328) perfect numbers, and also proved that every perfect number obtained from Euclid's rule ends with a 6 or an 8.&lt;ref&gt;{{cite book|last=Dickson|first=L. E. | authorlink = L. E. Dickson|title=History of the Theory of Numbers, Vol. I|year=1919|publisher=Carnegie Institution of Washington|location=Washington|page=10|url=https://archive.org/stream/historyoftheoryo01dick#page/10/}}&lt;/ref&gt;&lt;ref name="Pickover C (2001)"&gt;{{cite book|last=Pickover|first=C|title=Wonders of Numbers: Adventures in Mathematics, Mind, and Meaning|year=2001|publisher=Oxford University Press|location=Oxford|isbn=0-19-515799-0|pages=360|url=https://books.google.com/books?id=52N0JJBspM0C&amp;pg=PA360}}&lt;/ref&gt;&lt;ref name="Peterson I (2002)"&gt;{{cite book|last=Peterson|first=I|title=Mathematical Treks: From Surreal Numbers to Magic Circles|year=2002|publisher=Mathematical Association of America|location=Washington|isbn=88-8358-537-2|pages=132|url=https://books.google.com/books?id=4gWSAraVhtAC&amp;pg=PA132}}&lt;/ref&gt;

==Even perfect numbers==
{{See also|Euclid–Euler theorem}}
{{unsolved|mathematics|Are there infinitely many perfect numbers?}}

[[Euclid]] proved that 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) is an even perfect number whenever 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 is prime (Elements, Prop. IX.36).

For example, the first four perfect numbers are generated by the formula 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1), with ''p'' a [[prime number]], as follows:

:for ''p'' = 2: &amp;nbsp; 2&lt;sup&gt;1&lt;/sup&gt;(2&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) = 2 × 3 = 6
:for ''p'' = 3: &amp;nbsp; 2&lt;sup&gt;2&lt;/sup&gt;(2&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) = 4 × 7 = 28
:for ''p'' = 5: &amp;nbsp; 2&lt;sup&gt;4&lt;/sup&gt;(2&lt;sup&gt;5&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) = 16 × 31 = 496
:for ''p'' = 7: &amp;nbsp; 2&lt;sup&gt;6&lt;/sup&gt;(2&lt;sup&gt;7&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) = 64 × 127 = 8128.

Prime numbers of the form 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 are known as [[Mersenne prime]]s, after the seventeenth-century monk [[Marin Mersenne]], who studied [[number theory]] and perfect numbers. For 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 to be prime, it is necessary that ''p'' itself be prime. However, not all numbers of the form 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 with a prime ''p'' are prime; for example, 2&lt;sup&gt;11&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 = 2047 = 23 × 89 is not a prime number.&lt;ref&gt;All factors of 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 are congruent to 1 mod 2''p''. For example, 2&lt;sup&gt;11&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 = 2047 = 23 × 89, and both 23 and 89 yield a remainder of 1 when divided by 11. Furthermore, whenever ''p'' is a [[Sophie Germain prime]]—that is, 2''p''&amp;nbsp;+&amp;nbsp;1 is also prime—and 2''p''&amp;nbsp;+&amp;nbsp;1 is congruent to 1 or 7 mod 8, then 2''p''&amp;nbsp;+&amp;nbsp;1 will be a factor of 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1, which is the case for ''p'' = 11, 23, 83, 131, 179, 191, 239, 251,&amp;nbsp;... {{oeis|id=A002515}}.&lt;/ref&gt; In fact, Mersenne primes are very rare—of the 2,610,944 prime numbers ''p'' up to 43,112,609,&lt;ref&gt;{{cite web |url=http://www.wolframalpha.com/input/?i=Number+of+primes+%3C%3D+43112609 |title=Number of primes &lt;= 43112609 |publisher=[[Wolfram Alpha]] |accessdate=2018-10-28}}&lt;/ref&gt; 
2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 is prime for only 47 of them.

[[Nicomachus]] (60–120 AD) conjectured that every perfect number is of the form 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) where 2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1 is prime.&lt;ref&gt;{{cite web|url=http://www-groups.dcs.st-and.ac.uk/history/HistTopics/Perfect_numbers.html|title=Perfect numbers|author=|date=|website=www-groups.dcs.st-and.ac.uk|accessdate=9 May 2018}}&lt;/ref&gt; [[Ibn al-Haytham]] (Alhazen) circa 1000 AD conjectured that every ''even'' perfect number is of that form.&lt;ref&gt;{{MacTutor Biography|id=Al-Haytham|title=Abu Ali al-Hasan ibn al-Haytham}}&lt;/ref&gt; It was not until the 18th century that [[Leonhard Euler]] proved that the formula 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) will yield all the even perfect numbers. Thus, there is a [[bijection|one-to-one correspondence]] between even perfect numbers and Mersenne primes; each Mersenne prime generates one even perfect number, and vice versa. This result is often referred to as the [[Euclid–Euler theorem]].

An exhaustive search by the [[GIMPS]] distributed computing project has shown that the first 47 even perfect numbers are 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) for
:''p'' = 2, 3, 5, 7, 13, 17, 19, 31, 61, 89, 107, 127, 521, 607, 1279, 2203, 2281, 3217, 4253, 4423, 9689, 9941, 11213, 19937, 21701, 23209, 44497, 86243, 110503, 132049, 216091, 756839, 859433, 1257787, 1398269, 2976221, 3021377, 6972593, 13466917, 20996011, 24036583, 25964951, 30402457, 32582657, 37156667, 42643801 and 43112609 {{OEIS|id=A000043}}.&lt;ref&gt;[http://www.mersenne.org/report_milestones/ GIMPS Milestones Report]. Retrieved 2018-02-27&lt;/ref&gt;
Three higher perfect numbers have also been discovered, namely those for which ''p'' = 57885161, 74207281, and 77232917, though there may be others within this range. {{As of|2018|1}}, 50 Mersenne primes are known,&lt;ref name="mersenne"&gt;{{cite web |url=http://www.mersenne.org/ |title=GIMPS Home |publisher=Mersenne.org |accessdate=2018-01-03}}&lt;/ref&gt; and therefore 50 even perfect numbers (the largest of which is 2&lt;sup&gt;77232916&lt;/sup&gt; × (2&lt;sup&gt;77232917&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) with 46,498,850 digits). It is [[List of unsolved problems in mathematics|not known]] whether there are [[infinite set|infinitely many]] perfect numbers, nor whether there are infinitely many Mersenne primes.

As well as having the form 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1), each even perfect number is the {{nowrap|(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1)th}} [[triangular number]] (and hence equal to the sum of the integers from 1 to {{nowrap|2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1}}) and the {{nowrap|2&lt;sup&gt;''p''−1&lt;/sup&gt;th}} [[hexagonal number]]. Furthermore, each even perfect number except for 6 is the {{nowrap|((2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;1)/3)th}} [[centered nonagonal number]] and is equal to the sum of the first {{nowrap|2&lt;sup&gt;(''p''−1)/2&lt;/sup&gt;}} odd cubes:

:&lt;math&gt;
\begin{align}
6 &amp; = 2^1(2^2-1) &amp; &amp; = 1+2+3, \\[8pt]
28 &amp; = 2^2(2^3-1) &amp; &amp; = 1+2+3+4+5+6+7 = 1^3+3^3, \\[8pt]
496 &amp; = 2^4(2^5-1) &amp; &amp; = 1+2+3+\cdots+29+30+31 \\
&amp; &amp; &amp; = 1^3+3^3+5^3+7^3, \\[8pt]
8128 &amp; = 2^6(2^7-1) &amp; &amp; = 1+2+3+\cdots+125+126+127 \\
&amp; &amp; &amp; = 1^3+3^3+5^3+7^3+9^3+11^3+13^3+15^3, \\[8pt]
33550336 &amp; = 2^{12}(2^{13}-1) &amp; &amp; = 1+2+3+\cdots+8189+8190+8191 \\
&amp; &amp; &amp; = 1^3+3^3+5^3+\cdots+123^3+125^3+127^3.
\end{align}
&lt;/math&gt;

Even perfect numbers (except&amp;nbsp;6) are of the form
:&lt;math&gt;T_{2^p - 1} = 1 + \frac{(2^p-2) \times (2^p+1)}{2} = 1 + 9 \times T_{(2^p - 2)/3}&lt;/math&gt;

with each resulting triangular number T&lt;sub&gt;7&lt;/sub&gt; = 28, T&lt;sub&gt;31&lt;/sub&gt; = 496, T&lt;sub&gt;127&lt;/sub&gt; = 8128 (after subtracting 1 from the perfect number and dividing the result by 9) ending in 3 or 5, the sequence starting with T&lt;sub&gt;2&lt;/sub&gt; = 3, T&lt;sub&gt;10&lt;/sub&gt; = 55, T&lt;sub&gt;42&lt;/sub&gt; = 903, 3727815,&amp;nbsp;...&lt;ref name="mathworld"&gt;{{Mathworld|urlname=PerfectNumber|title=Perfect Number}}&lt;/ref&gt; This can be reformulated as follows: adding the digits of any even perfect number (except&amp;nbsp;6), then adding the digits of the resulting number, and repeating this process until a single digit (called the [[digital root]]) is obtained, always produces the number&amp;nbsp;1. For example, the digital root of 8128 is 1, because 8&amp;nbsp;+&amp;nbsp;1&amp;nbsp;+&amp;nbsp;2&amp;nbsp;+&amp;nbsp;8&amp;nbsp;=&amp;nbsp;19, 1&amp;nbsp;+&amp;nbsp;9&amp;nbsp;=&amp;nbsp;10, and&amp;nbsp;1&amp;nbsp;+&amp;nbsp;0&amp;nbsp;=&amp;nbsp;1. This works with all perfect numbers 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) with odd prime ''p'' and, in fact, with '''all''' numbers of the form 2&lt;sup&gt;''m''−1&lt;/sup&gt;(2&lt;sup&gt;''m''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1) for odd integer (not necessarily prime) ''m''.

Owing to their form, 2&lt;sup&gt;''p''−1&lt;/sup&gt;(2&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1), every even perfect number is represented in binary form as ''p'' ones followed by&amp;nbsp;''p''&amp;nbsp;−&amp;nbsp;1&amp;nbsp;&amp;nbsp;zeros; for example,
:6&lt;sub&gt;10&lt;/sub&gt; = 2&lt;sup&gt;2&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt; = 110&lt;sub&gt;2&lt;/sub&gt;
:28&lt;sub&gt;10&lt;/sub&gt; = 2&lt;sup&gt;4&lt;/sup&gt; + 2&lt;sup&gt;3&lt;/sup&gt; + 2&lt;sup&gt;2&lt;/sup&gt; = 11100&lt;sub&gt;2&lt;/sub&gt;
:496&lt;sub&gt;10&lt;/sub&gt; = 2&lt;sup&gt;8&lt;/sup&gt; + 2&lt;sup&gt;7&lt;/sup&gt; + 2&lt;sup&gt;6&lt;/sup&gt; + 2&lt;sup&gt;5&lt;/sup&gt; + 2&lt;sup&gt;4&lt;/sup&gt; = 111110000&lt;sub&gt;2&lt;/sub&gt;
and
:8128&lt;sub&gt;10&lt;/sub&gt; = 2&lt;sup&gt;6&lt;/sup&gt; × (2&lt;sup&gt;6&lt;/sup&gt; + 2&lt;sup&gt;5&lt;/sup&gt; + 2&lt;sup&gt;4&lt;/sup&gt; + 2&lt;sup&gt;3&lt;/sup&gt; + 2&lt;sup&gt;2&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt; + 1) = 1111111000000&lt;sub&gt;2&lt;/sub&gt;.
Thus every even perfect number is a [[pernicious number]].

Note that every even perfect number is also a [[practical number]] (c.f. [[#Related concepts|Related concepts]]).

==Odd perfect numbers==&lt;!-- This section is linked from [[Unsolved problems in mathematics]] --&gt;
{{unsolved|mathematics|Are there any odd perfect numbers?}}
It is unknown whether there is any odd perfect number, though various results have been obtained. In 1496, [[Jacques Lefèvre d'Étaples|Jacques Lefèvre]] stated that Euclid's rule gives all perfect numbers,&lt;ref&gt;{{cite book|last=Dickson|first=L. E. | authorlink = L. E. Dickson|title=History of the Theory of Numbers, Vol. I|year=1919|publisher=Carnegie Institution of Washington|location=Washington|page=6|url=https://archive.org/stream/historyoftheoryo01dick#page/6/}}&lt;/ref&gt; thus implying that no odd perfect number exists. Euler stated: "Whether (...) there are any odd perfect numbers is a most difficult question".&lt;ref&gt;http://www.math.harvard.edu/~knill/seminars/perfect/handout.pdf&lt;/ref&gt;&lt;br&gt;
More recently, [[Carl Pomerance]] has presented a [[heuristic argument]] suggesting that indeed no odd perfect number should exist.&lt;ref name="oddperfect"&gt;[http://oddperfect.org/pomerance.html Oddperfect.org].&lt;/ref&gt; All perfect numbers are also [[Ore's harmonic number]]s, and it has been conjectured as well that there are no odd Ore's harmonic numbers other than 1.

Any odd perfect number ''N'' must satisfy the following conditions:
* ''N'' &gt; 10&lt;sup&gt;1500&lt;/sup&gt;.&lt;ref name="Ochem and Rao (2012)"&gt;{{cite journal | last1=Ochem | first1=Pascal | last2=Rao | first2=Michaël | title=Odd perfect numbers are greater than 10&lt;sup&gt;1500&lt;/sup&gt; | journal=[[Mathematics of Computation]] | year=2012 | volume=81 | issue=279 | doi=10.1090/S0025-5718-2012-02563-4 | url=http://www.lirmm.fr/~ochem/opn/opn.pdf | pages=1869–1877 | zbl=1263.11005 | issn=0025-5718 }}&lt;/ref&gt;
* ''N'' is not divisible by 105.&lt;ref name="Kühnel U (1494)"&gt;{{cite journal|last=Kühnel|first=U|title=Verschärfung der notwendigen Bedingungen für die Existenz von ungeraden vollkommenen Zahlen|journal=Mathematische Zeitschrift|year=1949|volume=52|pages=201–211|doi=10.1515/crll.1941.183.98|url=http://www.reference-global.com/doi/abs/10.1515/crll.1941.183.98|accessdate=30 March 2011}}{{dead link|date=March 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;
* ''N'' is of the form ''N'' ≡ 1 (mod 12), ''N'' ≡ 117 (mod 468), or ''N'' ≡ 81 (mod 324).&lt;ref name="Roberts T (2008)"&gt;{{cite journal|last=Roberts|first=T|title=On the Form of an Odd Perfect Number|journal=Australian Mathematical Gazette|year=2008|volume=35|issue=4|pages=244|url=http://www.austms.org.au/Publ/Gazette/2008/Sep08/CommsRoberts.pdf}}&lt;/ref&gt;
* ''N'' is of the form
::&lt;math&gt;N=q^{\alpha} p_1^{2e_1} \cdots p_k^{2e_k}, &lt;/math&gt;
:where:
:* ''q'',&amp;nbsp;''p''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''p''&lt;sub&gt;''k''&lt;/sub&gt; are distinct primes (Euler).
:* ''q'' ≡&amp;nbsp;α ≡&amp;nbsp;1 ([[Modular arithmetic|mod]] 4) (Euler).
:* The smallest prime factor of ''N'' is less than (2''k''&amp;nbsp;+&amp;nbsp;8)&amp;nbsp;/&amp;nbsp;3.&lt;ref name="Grün (1952)"&gt;{{cite journal|last=Grün|first=O|title=Über ungerade vollkommene Zahlen|journal=Mathematische Zeitschrift|year=1952|volume=55|issue=3|pages=353–354|doi=10.1007/BF01181133|url=http://www.springerlink.com/content/u6n2338x7mw10027/|accessdate=30 March 2011}}&lt;/ref&gt;
:* Either ''q''&lt;sup&gt;α&lt;/sup&gt;&amp;nbsp;&gt;&amp;nbsp;10&lt;sup&gt;62&lt;/sup&gt;, or ''p''&lt;sub&gt;''j''&lt;/sub&gt;&lt;sup&gt;2''e''&lt;sub&gt;''j''&lt;/sub&gt;&lt;/sup&gt; &amp;nbsp;&gt;&amp;nbsp;10&lt;sup&gt;62&lt;/sup&gt; for some ''j''.&lt;ref name="Ochem and Rao (2012)"/&gt;
:* ''N''&amp;nbsp;&lt;&amp;nbsp;2&lt;sup&gt;4&lt;sup&gt;''k''+1&lt;/sup&gt;&lt;/sup&gt;.&lt;ref name="Nielsen (2003)"&gt;{{cite journal|last=Nielsen|first=PP|title=An upper bound for odd perfect numbers|journal=Integers|year=2003|volume=3|pages=A14–A22|url=http://www.westga.edu/~integers/vol3.html|archive-url=https://web.archive.org/web/20030221192536/http://www.westga.edu/~integers/vol3.html|dead-url=yes|archive-date=21 February 2003|accessdate=30 March 2011}}&lt;/ref&gt;
:* &lt;math&gt;\alpha + 2e_1 + 2e_2 + 2e_3 + \cdots + 2e_k \geq (21k-18)/8 &lt;/math&gt; &lt;ref name="Zelinsky (2018)"&gt;{{cite journal|last1=Zelinsky|first1=Joshua|title=An improvement of an inequality of Ochem and Rao concerning odd perfect numbers|journal=INTEGERS|date=25 May 2018|volume=18|accessdate=23 May 2018|url=http://math.colgate.edu/~integers/vol18.html}}&lt;/ref&gt;&lt;ref name="Ochem and Rao (2014)"&gt;{{cite journal | last1=Ochem | first1=Pascal | last2=Rao | first2=Michaël | title=On the number of prime factors of an odd perfect number. &lt;/sup&gt; | journal=[[Mathematics of Computation]] | year=2014 | volume=83 | issue=289 | url=http://www.ams.org/journals/mcom/2014-83-289/S0025-5718-2013-02776-7/S0025-5718-2013-02776-7.pdf | pages=2435–2439  }}&lt;/ref&gt;
* The largest prime factor of ''N'' is greater than 10&lt;sup&gt;8&lt;/sup&gt;&lt;ref name="Goto and Ohno (2008)"&gt;{{cite journal|last=Goto|first=T|author2=Ohno, Y|title=Odd perfect numbers have a prime factor exceeding 10&lt;sup&gt;8&lt;/sup&gt;|journal=Mathematics of Computation|year=2008|volume=77|issue=263|pages=1859–1868|doi=10.1090/S0025-5718-08-02050-9|url=http://www.ma.noda.tus.ac.jp/u/tg/perfect/perfect.pdf|accessdate=30 March 2011|bibcode=2008MaCom..77.1859G}}&lt;/ref&gt; and less than (3''N'')&lt;sup&gt;1/3&lt;/sup&gt;&lt;ref&gt;{{cite journal |last1=Konyagin |first1=Sergei |last2=Acquaah |first2=Peter |title=On Prime Factors of Odd Perfect Numbers |journal=International Journal of Number Theory |date=2012 |volume=8 |issue=6 |page=1537-1540}}&lt;/ref&gt;
* The second largest prime factor is greater than 10&lt;sup&gt;4&lt;/sup&gt;, and the third largest prime factor is greater than 100.&lt;ref name="Ianucci DE (1999)"&gt;{{cite journal|last=Iannucci|first=DE|title=The second largest prime divisor of an odd perfect number exceeds ten thousand|journal=Mathematics of Computation|year=1999|volume=68|issue=228|pages=1749–1760|url=http://www.ams.org/journals/mcom/1999-68-228/S0025-5718-99-01126-6/S0025-5718-99-01126-6.pdf|accessdate=30 March 2011|doi=10.1090/S0025-5718-99-01126-6}}&lt;/ref&gt;&lt;ref name="Ianucci DE (2000)"&gt;{{cite journal|last=Iannucci|first=DE|title=The third largest prime divisor of an odd perfect number exceeds one hundred|journal=Mathematics of Computation|year=2000|volume=69|issue=230|pages=867–879|url=http://www.ams.org/journals/mcom/2000-69-230/S0025-5718-99-01127-8/S0025-5718-99-01127-8.pdf|accessdate=30 March 2011|doi=10.1090/S0025-5718-99-01127-8}}&lt;/ref&gt;
* ''N'' has at least 101 prime factors and at least 10 distinct prime factors.&lt;ref name="Ochem and Rao (2012)"/&gt;&lt;ref name="Nielsen PP (2015)"&gt;{{cite journal|last=Nielsen|first=PP|title=Odd perfect numbers, Diophantine equations, and upper bounds|journal=Mathematics of Computation|year=2015|volume=84|pages=2549–2567|url=https://math.byu.edu/~pace/BestBound_web.pdf|accessdate=13 August 2015|doi=10.1090/S0025-5718-2015-02941-X|issue=0}}&lt;/ref&gt; If 3 is not one of the factors of ''N'', then ''N'' has at least 12 distinct prime factors.&lt;ref name="Nielsen PP (2007)"&gt;{{cite journal|last=Nielsen|first=PP|title=Odd perfect numbers have at least nine distinct prime factors|journal=Mathematics of Computation|year=2007|volume=76|pages=2109–2126|url=https://math.byu.edu/~pace/NotEight_web.pdf|accessdate=30 March 2011|doi=10.1090/S0025-5718-07-01990-4|issue=260|arxiv=math/0602485|bibcode=2007MaCom..76.2109N}}&lt;/ref&gt;

In 1888, [[James Joseph Sylvester|Sylvester]] stated:&lt;ref&gt;The Collected Mathematical Papers of James Joseph Sylvester p. 590, tr. from "Sur les nombres dits de Hamilton", ''Compte Rendu de l'Association Française'' (Toulouse, 1887), pp. 164–168.&lt;/ref&gt;
{{quote|...a prolonged meditation on the subject has satisfied me that the existence of any one such [odd perfect number]&amp;nbsp;— its escape, so to say, from the complex web of conditions which hem it in on all sides&amp;nbsp;— would be little short of a miracle.}}

==Minor results==
All even perfect numbers have a very precise form; odd perfect numbers either do not exist or are rare. There are a number of results on perfect numbers that are actually quite easy to prove but nevertheless superficially impressive; some of them also come under [[Richard K. Guy|Richard Guy]]'s [[strong law of small numbers]]:
* The only even perfect number of the form ''x''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;1 is 28 {{harv|Makowski|1962}}.&lt;ref&gt;{{cite journal|first=A.|last=Makowski|title=Remark on perfect numbers|journal=Elem. Math.|volume=17|year=1962|issue=5|page=109|ref=harv}}&lt;/ref&gt;
* 28 is also the only even perfect number that is a sum of two positive cubes of integers {{harv|Gallardo|2010}}.&lt;ref&gt;{{cite journal|first=Luis H.|last=Gallardo|title=On a remark of Makowski about perfect numbers|journal=Elem. Math.|volume=65|year=2010|pages=121–126|ref=harv}}.&lt;/ref&gt;
* The [[multiplicative inverse|reciprocals]] of the divisors of a perfect number ''N'' must add up to 2 (to get this, take the definition of a perfect number, &lt;math&gt;\sigma_1(n) = 2n&lt;/math&gt;, and divide both sides by ''n''):
** For 6, we have &lt;math&gt;1/6 + 1/3 + 1/2 + 1/1 = 2&lt;/math&gt;;
** For 28, we have &lt;math&gt;1/28 + 1/14 + 1/7 + 1/4 + 1/2 + 1/1 = 2&lt;/math&gt;, etc.
* The number of divisors of a perfect number (whether even or odd) must be even, because ''N'' cannot be a perfect square.&lt;ref&gt;{{citation|title=Computational Number Theory and Modern Cryptography|first=Song Y.|last=Yan|publisher=John Wiley &amp; Sons|year=2012|isbn=9781118188613|at=Section 2.3, Exercise 2(6)|url=https://books.google.com/books?id=eLAV586iF-8C&amp;pg=PA30}}.&lt;/ref&gt;
** From these two results it follows that every perfect number is an [[Ore's harmonic number]].
* The even perfect numbers are not [[trapezoidal number]]s; that is, they cannot be represented as the difference of two positive non-consecutive [[triangular number]]s. There are only three types of non-trapezoidal numbers: even perfect numbers, powers of two, and the numbers of the form &lt;math&gt;2^{n-1}(2^n+1)&lt;/math&gt; formed as the product of a [[Fermat prime]] &lt;math&gt;2^n+1&lt;/math&gt; with a power of two in a similar way to the construction of even perfect numbers from Mersenne primes.&lt;ref&gt;{{Cite journal|title=Characterising non-trapezoidal numbers|first1=Chris|last1=Jones|first2=Nick|last2=Lord|journal=The Mathematical Gazette|volume=83|issue=497|year=1999|pages=262–263|doi=10.2307/3619053|jstor=3619053|publisher=The Mathematical Association|postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}}}&lt;/ref&gt;
* The number of perfect numbers less than ''n'' is less than &lt;math&gt;c\sqrt{n}&lt;/math&gt;, where ''c'' &gt; 0 is a constant.&lt;ref name="Hornfeck (1955)"&gt;{{cite journal|last=Hornfeck|first=B|title=Zur Dichte der Menge der vollkommenen zahlen|journal=Arch. Math.|year=1955|volume=6|pages=442–443|doi=10.1007/BF01901120|issue=6}}&lt;/ref&gt; In fact it is &lt;math&gt;o(\sqrt{n})&lt;/math&gt;, using [[little-o notation]].&lt;ref&gt;{{cite journal|last=Kanold|first=HJ|title=Eine Bemerkung ¨uber die Menge der vollkommenen zahlen|journal=Math. Ann.|year=1956|volume=131|pages=390–392|doi=10.1007/BF01350108|issue=4}}&lt;/ref&gt;
* Every even perfect number ends in 6 or 28, base ten; and, with the only exception of 6, ends in 1, base 9.&lt;ref&gt;H. Novarese. ''Note sur les nombres parfaits'' Texeira J. VIII (1886), 11–16.&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Dickson|first=L. E. | authorlink = L. E. Dickson|title=History of the Theory of Numbers, Vol. I|year=1919|publisher=Carnegie Institution of Washington|location=Washington|page=25|url=https://archive.org/stream/historyoftheoryo01dick#page/25/}}&lt;/ref&gt; Therefore in particular the [[digital root]] of every even perfect number other than 6 is 1. 
* The only [[Square-free integer|square-free]] perfect number is 6.&lt;ref&gt;{{cite book|title=Number Theory: An Introduction to Pure and Applied Mathematics|volume=201|series=Chapman &amp; Hall/CRC Pure and Applied Mathematics|first=Don|last=Redmond|publisher=CRC Press|year=1996|isbn=9780824796969|at=Problem 7.4.11, p.&amp;nbsp;428|url=https://books.google.com/books?id=3ffXkusQEC0C&amp;pg=PA428}}.&lt;/ref&gt;

==Related concepts==
The sum of proper divisors gives various other kinds of numbers. Numbers where the sum is less than the number itself are called [[deficient number|deficient]], and where it is greater than the number, [[abundant number|abundant]]. These terms, together with ''perfect'' itself, come from Greek [[numerology]]. A pair of numbers which are the sum of each other's proper divisors are called [[amicable number|amicable]], and larger cycles of numbers are called [[sociable number|sociable]]. A positive integer such that every smaller positive integer is a sum of distinct divisors of it is a [[practical number]].

By definition, a perfect number is a [[fixed point (mathematics)|fixed point]] of the [[restricted divisor function]] {{nowrap|1=''s''(''n'') = ''σ''(''n'') − ''n''}}, and the [[aliquot sequence]] associated with a perfect number is a constant sequence.  All perfect numbers are also &lt;math&gt;\mathcal{S}&lt;/math&gt;-perfect numbers, or [[Granville number]]s.

A [[semiperfect number]] is a natural number that is equal to the sum of all or some of its proper divisors.  A semiperfect number that is equal to the sum of all its proper divisors is a perfect number.  Most abundant numbers are also semiperfect; abundant numbers which are not semiperfect are called [[weird number]]s.

==See also==
* [[Leinster group]]
* [[List of perfect numbers]]
* [[Multiply perfect number]]
* [[Superperfect number]]s

==Notes==
{{Reflist|30em}}

==References==
{{refbegin}}
* Euclid, ''[[Euclid's Elements|Elements]]'', Book IX, Proposition 36. See [http://aleph0.clarku.edu/~djoyce/java/elements/bookIX/propIX36.html D.E. Joyce's website] for a translation and discussion of this proposition and its proof.
* {{cite journal | last1 = Kanold | first1 = H.-J. | year = 1941 | title = Untersuchungen über ungerade vollkommene Zahlen | url = | journal = Journal für die Reine und Angewandte Mathematik | volume = 183 | issue = | pages = 98–109 }}
* {{cite journal | last1 = Steuerwald | first1 = R. | year = | title = Verschärfung einer notwendigen Bedingung für die Existenz einer ungeraden vollkommenen Zahl | url = | journal = S.-B. Bayer. Akad. Wiss. | volume = 1937 | issue = | pages = 69–72 }}
{{refend}}

==Further reading==
&lt;!-- From http://mathforum.org/library/drmath/view/51516.html --&gt;
* Nankar, M.L.: "History of perfect numbers," Ganita Bharati 1, no. 1–2 (1979), 7–8.
* {{cite journal | last1 = Hagis | first1 = P. | year = 1973 | title = A Lower Bound for the set of odd Perfect Prime Numbers | url = | journal = [[Mathematics of Computation]] | volume = 27 | issue = | pages = 951–953 | doi=10.2307/2005530}}
* Riele, H.J.J. "Perfect Numbers and Aliquot Sequences" in H.W. Lenstra and R. Tijdeman (eds.): ''Computational Methods in Number Theory'', Vol. 154, Amsterdam, 1982, pp.&amp;nbsp;141–157.
* Riesel, H. ''Prime Numbers and Computer Methods for Factorisation'', Birkhauser, 1985.
* {{cite book | last1=Sándor | first1=Jozsef | last2=Crstici | first2=Borislav | title=Handbook of number theory II | location=Dordrecht | publisher=Kluwer Academic | year=2004 | isbn=1-4020-2546-7 | zbl=1079.11001 | pages=15–98 }}

== External links ==
* {{springer|title=Perfect number|id=p/p072090}}
* David Moews: [http://djm.cc/amicable.html Perfect, amicable and sociable numbers]
* [http://www-history.mcs.st-andrews.ac.uk/HistTopics/Perfect_numbers.html Perfect numbers – History and Theory]
* {{Mathworld|urlname=PerfectNumber|title=Perfect Number}}
* {{OEIS el|sequencenumber=A000396|name=Perfect numbers|formalname=Perfect numbers n: n is equal to the sum of the proper divisors of n}}
* [http://www.oddperfect.org OddPerfect.org] A projected distributed computing project to search for odd perfect numbers.
* [https://www.mersenne.org/ Great Internet Mersenne Prime Search] (GIMPS)
* [http://mathforum.org/dr.math/faq/faq.perfect.html Perfect Numbers], math forum at Drexel.
* {{cite web|last=Grimes|first=James|title=8128: Perfect Numbers|url=http://www.numberphile.com/videos/8128.html|work=Numberphile|publisher=[[Brady Haran]]}}

{{Divisor classes}}
{{Classes of natural numbers}}

{{DEFAULTSORT:Perfect Number}}
[[Category:Divisor function]]
[[Category:Integer sequences]]
[[Category:Unsolved problems in mathematics]]</text>
      <sha1>ntjbil6yeako8qya17rw7f9amv7suws</sha1>
    </revision>
  </page>
  <page>
    <title>Reeb vector field</title>
    <ns>0</ns>
    <id>10761147</id>
    <revision>
      <id>834084239</id>
      <parentid>696583356</parentid>
      <timestamp>2018-04-03T21:08:19Z</timestamp>
      <contributor>
        <ip>174.34.207.104</ip>
      </contributor>
      <comment>added two references</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="697">{{unreferenced|date=December 2015}}
In mathematics, the '''Reeb [[vector field]]''', named after the French mathematician [[Georges Reeb]], is a notion that appears in various domains of [[contact geometry]] including:

* in a [[contact manifold]], given a contact 1-form &lt;math&gt;\alpha&lt;/math&gt;, the Reeb vector field satisfies &lt;math&gt;R \in \mathrm{ker }\ d\alpha, \ \alpha (R)  = 1 &lt;/math&gt;&lt;ref&gt;http://people.math.gatech.edu/%7Eetnyre/preprints/papers/phys.pdf &lt;/ref&gt; &lt;ref&gt;http://www2.im.uj.edu.pl/katedry/K.G/AutumnSchool/Monday.pdf &lt;/ref&gt;,
* in particular, in the context of [[Sasakian manifold#The Reeb vector field]].

== References ==
{{Reflist}}

[[Category:Contact geometry]]

{{geometry-stub}}</text>
      <sha1>bainowewmeqo7txn58n3j38gm2n3nrs</sha1>
    </revision>
  </page>
  <page>
    <title>Reich Technologies</title>
    <ns>0</ns>
    <id>4281673</id>
    <revision>
      <id>702080835</id>
      <parentid>692140969</parentid>
      <timestamp>2016-01-28T09:01:16Z</timestamp>
      <contributor>
        <username>FranckBarbier64</username>
        <id>27434048</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3259">'''Reich Technologies''' was one of the [[UML Partners]], a consortium that was instrumental to the development of standards for the [[Unified Modeling Language]] (UML). The [[Chief executive officer|CEO]] for the company ([[Georges-Pierre Reich]]) represented Reich Technologies on the committee, and was involved in the development of the proposal. The proposal was submitted to the [[Object Management Group]] (OMG), which approved the proposal, circa late 1997.

==Profile==
Reich Technologies is an international group of companies, providing a coordinated suite of products and services to support [[object-oriented]] (OO) [[software development]] in large corporations. With a presence throughout [[Europe]] and [[North America]], Reich Technologies occupies leading positions in the world markets for integrated OO [[CASE tool]]s, fine-grained object repositories and OO team [[Integrated development environment|programming environments]].

The Intelligent Software Factory (ISF) offers an integrated [[object-oriented]] [[CASE tool]] suite. It is built on the concept of [[model-driven development]] in which the work done at the beginning of a project creates an environment for configuration management and cost containment for software maintenance. ISF has been originally built by Franck Barbier, a French researcher on OO modeling.

The Intelligent Artifact Repository (IAR) provides an enterprise-wide resource for the management and reuse of [[Informations systems|Information System]] assets. This concept is so powerful that the development team uses ISF and IAR for production, making ISF the first [[CASE tool]] to be self-generated. Recognizing the impact of introducing tools, Reich Technologies offers success oriented services including training, consulting and tool customizations. Corporations combine tools, services and processes with their own organizations to implement a Corporate Software Ecology.

Reich Technologies worked with [[Alistair Cockburn]] (special advisor to the [[Central Bank of Norway]]) and [[Ralph Hodgson]] (founder of [[TopQuadrant]]) to flesh out the concept of [[Use Case]] and integrate it in the context of [[URDAD|Responsibility-Driven Design]]. Several large companies have built systems upon these constructs since 1992. Structured Use Cases and detailed Responsibility models proved to be a relevant answer to the challenge of gathering and organizing thousands of requirements, defining the scope of the system, and designing an architecture for objects. A methodology with processes and identified deliverables has been created in a joint effort. 

As tool builders, Reich Technologies adds the knowledge of implementing lifecycle management for the meta-model objects. Reich Technologies has also extensive experience designing the [[Meta-modeling|meta-models]] that implement in ISF the modeling notations of diverse methodologists.

Reich Technologies sells off-the-shelf and tailored versions of their [[CASE tool]]s.

==References==
{{reflist}}

==External links==
*[http://www.projexion.com Official Site]
*[http://www.jeckle.de/umlPartners.html UML Partners List]
*[http://www.FranckBarbier.com Creator of Intelligent Software Factory]

[[Category:Unified Modeling Language]]

{{uml-stub}}</text>
      <sha1>9wszzmy5aemtycoqq200lw5misa6dc7</sha1>
    </revision>
  </page>
  <page>
    <title>Reinsurance Actuarial Premium</title>
    <ns>0</ns>
    <id>44347068</id>
    <revision>
      <id>693247138</id>
      <parentid>693246579</parentid>
      <timestamp>2015-12-01T09:36:11Z</timestamp>
      <contributor>
        <username>MPG IRA</username>
        <id>18196951</id>
      </contributor>
      <comment>/* XS premium using Lognormal cost distribution */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4408">{{Orphan|date=November 2014}}

Actuarial reinsurance premium calculation uses the similar mathematical tools as actuarial insurance premium. Nevertheless, [[Catastrophe modeling]], [[Systematic risk]] or risk aggregation statistics tools are more important.

== Burning Cost ==
Typically burning cost is the estimated cost of claims in the forthcoming insurance period, calculated from previous years’ experience adjusted for changes in the numbers insured, the nature of cover and medical inflation.

# Historical (aggregate) data extraction
# Adjustments to obtain 'as if' data:
## present value adjustment using actuarial rate, prices index,...
## base insurane premium correction,
## underwriting policy evolution,
# clauses application 'as if' data, calcul of the 'as if' historical reinsurance indemnity,
# Reinsurance pure premium rate computing,
# add charges, taxes and reduction of treaty

'As if' is term used to describe the recalculation of prior years of loss experience to demonstrate what the underwriting results of a particular program would have been if the proposed program had been in force during that period.&lt;ref name="GlossaryGuyCarpenter"&gt;[http://www.guycarp.com/content/guycarp/en/home/the-company/media-resources/glossary/a.html], http://www.guycarp.com/&lt;/ref&gt;

== Probabilist Methods ==


=== Premium formulation ===
Let us note &lt;math&gt;p&lt;/math&gt; the and   &lt;math&gt;f&lt;/math&gt; the deductible of XS or XL, with the limite &lt;math&gt;l=p+f&lt;/math&gt; (&lt;math&gt;p&lt;/math&gt; XS &lt;math&gt;f&lt;/math&gt;).

The premium :
&lt;math&gt;\mathbb{E}\left[S_N\right]=\mathbb{E}\left[\sum_{i=1}^{N} Y_{i}\right]=\mathbb{E}[N]\times \mathbb{E}[Y]
&lt;/math&gt;

where
&lt;math&gt;\mathbb{E}[Y]= l \mathbb{P}[X&gt;l] - f \times \mathbb{P}[X\geq f] + \mathbb{E}[X\mid f\geq x\geq l]
&lt;/math&gt;
===XS or XL premium formulation with Pareto ===

If &lt;math&gt;l=\infty&lt;/math&gt; and &lt;math&gt;\alpha \neq 1&lt;/math&gt; :
&lt;math&gt;
\mathbb{E}[S_N] = \lambda \frac{t^{\alpha}}{\alpha -1}f^{1-\alpha} 
&lt;/math&gt;$

if  &lt;math&gt;l=\infty&lt;/math&gt; and &lt;math&gt;\alpha = 1&lt;/math&gt; il n'y a pas de solution.
  
If &lt;math&gt;l&lt;\infty&lt;/math&gt; and &lt;math&gt;\alpha \neq 1&lt;/math&gt; :
&lt;math&gt;
\mathbb{E}[S_N] = \lambda \frac{t^{\alpha}}{\alpha -1}\left( f^{1-\alpha} -l^{1-\alpha} \right)
&lt;/math&gt;
  
If &lt;math&gt;l&lt;\infty&lt;/math&gt; and &lt;math&gt;\alpha = 1&lt;/math&gt; :
&lt;math&gt;
\mathbb{E}[S_N] = \lambda t \ln \left(  \frac{1}{f}\right)
&lt;/math&gt;

=== XS premium using Lognormal cost distribution ===


If &lt;math&gt;X&lt;/math&gt; follows &lt;math&gt;LN(x_\mathrm{m}, \mu, \sigma)&lt;/math&gt; then &lt;math&gt;X-x_\mathrm{m}&lt;/math&gt; follows &lt;math&gt;LN(\mu, \sigma)&lt;/math&gt;

Then:
&lt;math&gt;
\mathbb{P}[X&gt;f]=\mathbb{P}[X-x_\mathrm{m}&gt;f-x_\mathrm{m}]=1-\Phi\left(\frac{\ln(f-x_\mathrm{m})-\mu}{\sigma}\right)
&lt;/math&gt;

&lt;math&gt;
\begin{align}
 \mathbb{E}[X\mid X&gt;f] 
= &amp; \mathbb{E}\left[ X-x_\mathrm{m}\mid X-x_\mathrm{m}&gt;f-x_\mathrm{m} \right]+x_\mathrm{m} \mathbb{P}[X&gt;f]\\
= &amp; e ^{m+\sigma^2/2} \left[1-\Phi\left(\frac{\ln(f-x_\mathrm{m})-(\mu+\sigma^2)}{\sigma}\right) \right]\\
	&amp; +x_\mathrm{m} \left( 1-\Phi\left(\frac{\ln(f-x_\mathrm{m})-\mu}{\sigma}\right) \right)
\end{align}
&lt;/math&gt;

With deductible and without limit :

&lt;math&gt;\begin{align}
 \mathbb{E}[S_N] 
= &amp; \lambda \left(\mathbb{E}\left[ X-x_\mathrm{m}\mid X-x_\mathrm{m}&gt;f-x_\mathrm{m} \right]+x_\mathrm{m} \mathbb{P}[X&gt;f]-f\mathbb{P}[X&gt;f]\right)\\
= &amp; \lambda \left(  e ^{m+\sigma^2/2} \left[1-\Phi\left(\frac{\ln(f-x_\mathrm{m})-(\mu+\sigma^2)}{\sigma}\right) \right]\right)\\
	&amp; +\lambda (x_\mathrm{m}-l) \left( 1-\Phi\left(\frac{\ln(f-x_\mathrm{m})-\mu}{\sigma}\right) \right)
\end{align}&lt;/math&gt;

== Monte Carlo Estimation ==

{{Empty section|date=November 2014}}

== Vulnerability curve ==

{{Empty section|date=November 2014}}

== Regression Estimation ==

{{This method uses data along the x-y axis to compute fitted values. It is actually based on the equation for a straight line, y=bx+a.(2)}}

== Includes Reinsurances specificities ==

=== Clauses ===

=== Long-Term Indemnity Claims ===
Actuarial reserves modellisation.

==See also==
{{Div col}} 
*[[Reinsurance]]
*[[Insurance]]
*[[Actuarial Science]]
*[[Ruin Theory]]
{{Div col end}}

== References ==
	&lt;references group="Regression Estimation Reference http://www.r-tutor.com/elementary-statistics/simple-linear-regression/estimated-simple-regression-equation" /&gt;

[[Category:Actuarial science]]
[[Category:Reinsurance|*]]
2.  [2] http://www.r-tutor.com/elementary-statistics/simple-linear-regression/estimated-simple-regression-equation</text>
      <sha1>sx6dma7ulpr46b9izd123husl5nr8yi</sha1>
    </revision>
  </page>
  <page>
    <title>Sequent calculus</title>
    <ns>0</ns>
    <id>252329</id>
    <revision>
      <id>869306990</id>
      <parentid>869292327</parentid>
      <timestamp>2018-11-17T19:44:22Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Citation needed}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="52878">'''Sequent calculus''' is, in essence, a style of formal logical [[argument]]ation where every line of a proof is a conditional [[tautology (logic)|tautology]] (called a [[sequent]] by [[Gerhard Gentzen]]) instead of an unconditional tautology. Each conditional tautology is inferred from other conditional tautologies on earlier lines in a formal argument according to rules and procedures of [[inference]], giving a better approximation to the style of natural deduction used by mathematicians than [[David Hilbert|David Hilbert's]] earlier style of formal logic where every line was an unconditional tautology. There may be more subtle distinctions to be made; for example, there may be non-logical axioms upon which all propositions are implicitly dependent. Then sequents signify conditional [[theorem]]s in a [[first-order logic|first-order language]] rather than conditional tautologies.

Sequent calculus is one of several extant styles of [[proof calculus]] for expressing line-by-line logical arguments.
* [[Hilbert system|Hilbert style]]. Every line is an unconditional tautology (or theorem).
* Gentzen style. Every line is a conditional tautology (or theorem) with zero or more conditions on the left.
** [[Natural deduction]]. Every (conditional) line has exactly one asserted proposition on the right.
** Sequent calculus. Every (conditional) line has zero or more asserted propositions on the right.
In other words, natural deduction and sequent calculus systems are particular distinct kinds of Gentzen-style systems. Hilbert-style systems typically have a very small number of inference rules, relying more on sets of axioms. Gentzen-style systems typically have very few axioms, if any, relying more on sets of rules.

Gentzen-style systems have significant practical and theoretical advantages compared to Hilbert-style systems. For example, both natural deduction and sequent calculus systems facilitate the elimination and introduction of universal and existential [[Quantification (logic)|quantifiers]] so that unquantified logical expressions can be manipulated according to the much simpler rules of [[propositional calculus]]. In a typical argument, quantifiers are eliminated, then propositional calculus is applied to unquantified expressions (which typically contain free variables), and then the quantifiers are reintroduced. This very much parallels the way in which mathematical proofs are carried out in practice by mathematicians. Predicate calculus proofs are generally much easier to discover with this approach, and are often shorter. Natural deduction systems are more suited to practical theorem-proving. Sequent calculus systems are more suited to theoretical analysis.

==Overview&lt;!--'Gentzen system' and 'Gentzen systems' redirect here--&gt;==

In [[proof theory]] and [[mathematical logic]], sequent calculus is a family of [[formal system]]s sharing a certain style of inference and certain formal properties.  The first sequent calculi systems, '''LK''' and '''LJ''', were introduced in 1934/1935 by Gerhard Gentzen&lt;ref name=gentzen19341935&gt;{{harvnb|Gentzen|1934}}, {{harvnb|Gentzen|1935}}.&lt;/ref&gt; as a tool for studying [[natural deduction]] in [[first-order logic]] (in [[Classical logic|classical]] and [[Intuitionistic logic|intuitionistic]] versions, respectively).  Gentzen's so-called "Main Theorem" (''Hauptsatz'') about LK and LJ was the [[cut-elimination theorem]],&lt;ref name=curry_cut_elimination&gt;{{harvnb|Curry|1977|pp=208–213}}, gives a 5-page proof of the elimination theorem. See also pages 188, 250.&lt;/ref&gt;&lt;ref name=kleene_cut_elimination&gt;{{harvnb|Kleene|2009|pp=453}}, gives a very brief proof of the cut-elimination theorem.&lt;/ref&gt; a result with far-reaching [[Metatheory|meta-theoretic]] consequences, including [[consistency]].  Gentzen further demonstrated the power and flexibility of this technique a few years later, applying a cut-elimination argument to give a (transfinite) [[Gentzen's consistency proof|proof of the consistency of Peano arithmetic]], in surprising response to [[Gödel's incompleteness theorems]].  Since this early work, sequent calculi, also called '''Gentzen systems'''&lt;!--boldface per WP:R#PLA--&gt;,&lt;ref&gt;{{harvnb|Curry|1977|pp=189–244}}, calls Gentzen systems LC systems. Curry's emphasis is more on theory than on practical logic proofs.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Kleene|2009|pp=440–516}}. This book is much more concerned with the theoretical, metamathematical implications of Gentzen-style sequent calculus than applications to practical logic proofs.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Kleene|2002|pp=283–312, 331–361}}, defines Gentzen systems and proves various theorems within these systems, including Gödel's completeness theorem and Gentzen's theorem.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Smullyan|1995|pp=101–127}}, gives a brief theoretical presentation of Gentzen systems. He uses the tableau proof layout style.&lt;/ref&gt; and the general concepts relating to them, have been widely applied in the fields of proof theory, mathematical logic, and [[automated deduction]].

===Hilbert-style deduction systems===

One way to classify different styles of deduction systems is to look at the form of ''[[Judgment (mathematical logic)|judgments]]'' in the system, ''i.e.'', which things may appear as the conclusion of a (sub)proof. The simplest judgment form is used in [[Hilbert-style deduction system]]s, where a judgment has the form
:&lt;math&gt;B&lt;/math&gt;
where &lt;math&gt;B&lt;/math&gt; is any [[Well-formed formula|formula]] of first-order-logic (or whatever logic the deduction system applies to, ''e.g.'', propositional calculus or a [[higher-order logic]] or a [[modal logic]]). The theorems are those formulae that appear as the concluding judgment in a valid proof. A Hilbert-style system needs no distinction between formulae and judgments; we make one here solely for comparison with the cases that follow.

The price paid for the simple syntax of a Hilbert-style system is that complete formal proofs tend to get extremely long. Concrete arguments about proofs in such a system almost always appeal to the [[deduction theorem]]. This leads to the idea of including the deduction theorem as a formal rule in the system, which happens in [[natural deduction]].

===Natural deduction systems===

In natural deduction, judgments have the shape
:&lt;math&gt;A_1, A_2, \ldots, A_n \vdash B&lt;/math&gt;
where the &lt;math&gt;A_i&lt;/math&gt;'s and &lt;math&gt;B&lt;/math&gt; are again formulae and &lt;math&gt;n\geq 0&lt;/math&gt;. Permutations of the &lt;math&gt;A_i&lt;/math&gt;'s are immaterial. In other words, a judgment consists of a list (possibly empty) of formulae on the left-hand side of a [[Turnstile (symbol)|turnstile]] symbol "&lt;math&gt;\vdash&lt;/math&gt;", with a single formula on the right-hand side.&lt;ref&gt;{{harvnb|Curry|1977|pp=184–244}}, compares natural deduction systems, denoted LA, and Gentzen systems, denoted LC. Curry's emphasis is more theoretical than practical.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Suppes|1999|pp=25–150}}, is an introductory presentation of practical natural deduction of this kind. This became the basis of [[System L]].&lt;/ref&gt;&lt;ref&gt;{{harvnb|Lemmon|1965}} is an elementary introduction to practical natural deduction based on the convenient abbreviated proof layout style [[System L]] based on {{harvnb|Suppes|1999|pp=25–150}}.&lt;/ref&gt; The theorems are those formulae &lt;math&gt;B&lt;/math&gt; such that &lt;math&gt;\vdash B&lt;/math&gt; (with an empty left-hand side) is the conclusion of a valid proof.
(In some presentations of natural deduction, the &lt;math&gt;A_i&lt;/math&gt;s and the turnstile are not written down explicitly; instead a two-dimensional notation from which they can be inferred is used.)

The standard semantics of a judgment in natural deduction is that it asserts that whenever&lt;ref&gt;Here, "whenever" is used as an informal abbreviation "for every assignment of values to the free variables in the judgment"&lt;/ref&gt; &lt;math&gt;A_1&lt;/math&gt;, &lt;math&gt;A_2&lt;/math&gt;, etc., are all true, &lt;math&gt;B&lt;/math&gt; will also be true. The judgments
:&lt;math&gt;A_1, \ldots, A_n \vdash B&lt;/math&gt;
and
:&lt;math&gt;\vdash (A_1 \land \cdots \land A_n) \rightarrow B&lt;/math&gt;
are equivalent in the strong sense that a proof of either one may be extended to a proof of the other.

===Sequent calculus systems===

Finally, sequent calculus generalizes the form of a natural deduction judgment to
: &lt;math&gt;A_1, \ldots, A_n \vdash B_1, \ldots, B_k,&lt;/math&gt;
a syntactic object called a sequent. The formulas on left-hand side of the [[Turnstile (symbol)|turnstile]] are called the ''antecedent'', and the formulas on right-hand side are called the ''succedent'' or ''consequent''; together they are called ''cedents'' or ''sequents''.&lt;ref name="pvs-prover"&gt;{{cite web |url=http://pvs.csl.sri.com/doc/pvs-prover-guide.pdf |format=PDF |title=PVS Prover Guide |last=Shankar |first=Natarajan |authorlink=Natarajan Shankar |last2=Owre |first2=Sam |last3=Rushby |first3=John M. |authorlink3=John Rushby |last4=Stringer-Calvert |first4=David W. J. |work=User guide |publisher=[[SRI International]] |date=2001-11-01 |accessdate=2015-05-29 }}&lt;/ref&gt; Again, &lt;math&gt;A_i&lt;/math&gt; and &lt;math&gt;B_i&lt;/math&gt; are formulae, and &lt;math&gt;n&lt;/math&gt; and &lt;math&gt;k&lt;/math&gt; are nonnegative integers, that is, the left-hand-side or the right-hand-side (or neither or both) may be empty. As in natural deduction, theorems are those &lt;math&gt;B&lt;/math&gt; where &lt;math&gt;\vdash B&lt;/math&gt; is the conclusion of a valid proof.

The standard semantics of a sequent is an assertion that whenever ''every''  &lt;math&gt; A_i&lt;/math&gt; is true, ''at least one'' &lt;math&gt;B_i&lt;/math&gt; will also be true.&lt;ref&gt;For explanations of the disjunctive semantics for the right side of sequents, see {{harvnb|Curry|1977|pp=189–190}}, {{harvnb|Kleene|2002|pp=290, 297}}, {{harvnb|Kleene|2009|p=441}}, {{harvnb|Hilbert|Bernays|1970|p=385}}, {{harvnb|Smullyan|1995|pp=104–105}} and {{harvnb|Gentzen|1934|p=180}}.&lt;/ref&gt; Thus the empty sequent, having both cedents empty, is false.&lt;ref&gt;{{harvnb|Buss|1998|p=10}}&lt;/ref&gt; One way to express this is that a comma to the left of the turnstile should be thought of as an "and", and a comma to the right of the turnstile should be thought of as an (inclusive) "or". The sequents
:&lt;math&gt;A_1, \ldots, A_n \vdash B_1, \ldots, B_k&lt;/math&gt;
and
:&lt;math&gt;\vdash (A_1 \land\cdots\land A_n)\rightarrow(B_1 \lor\cdots\lor B_k)&lt;/math&gt;
are equivalent in the strong sense that a proof of either one may be extended to a proof of the other.

At first sight, this extension of the judgment form may appear to be a strange complication — it is not motivated by an obvious shortcoming of natural deduction, and it is initially confusing that the comma seems to mean entirely different things on the two sides of the turnstile. However, in a [[Classical logic|classical context]] the semantics of the sequent can also (by propositional tautology) be expressed either as
: &lt;math&gt;\vdash \neg A_1 \lor \neg A_2 \lor \cdots \lor \neg A_n \lor B_1 \lor B_2 \lor\cdots\lor B_k&lt;/math&gt;
(at least one of the As is false, or one of the Bs is true) or as
: &lt;math&gt;\vdash \neg(A_1 \land A_2 \land \cdots \land A_n \land \neg B_1 \land \neg B_2 \land\cdots\land \neg B_k)&lt;/math&gt;
(it cannot be the case that all of the As are true and all of the Bs are false).  In these formulations, the only difference between formulae on either side of the turnstile is that one side is negated. Thus, swapping left for right in a sequent corresponds to negating all of the constituent formulae. This means that a symmetry such as [[De Morgan's laws]], which manifests itself as logical negation on the semantic level, translates directly into a left-right symmetry of sequents — and indeed, the inference rules in sequent calculus for dealing with conjunction (∧) are mirror images of those dealing with disjunction (∨).

Many logicians feel {{Citation needed|date=November 2018}} that this symmetric presentation offers a deeper insight in the structure of the logic than other styles of proof system, where the classical duality of negation is not as apparent in the rules.

===Distinction between natural deduction and sequent calculus===

Gentzen asserted a sharp distinction between his single-output natural deduction systems (NK and NJ) and his multiple-output sequent calculus systems (LK and LJ). He wrote that the intuitionistic natural deduction system NJ was somewhat ugly.&lt;ref&gt;{{harvnb|Gentzen|1934|p=188}}. "Der Kalkül ''NJ'' hat manche formale Unschönheiten."&lt;/ref&gt; He said that the special role of the [[law of excluded middle|excluded middle]] in the classical natural deduction system NK is removed in the classical sequent calculus system LK.&lt;ref&gt;{{harvnb|Gentzen|1934|p=191}}. "In dem klassischen Kalkül ''NK'' nahm der Satz vom ausgeschlossenen Dritten eine Sonderstellung unter den Schlußweisen ein [...], indem er sich der Einführungs- und Beseitigungssystematik nicht einfügte. Bei dem im folgenden anzugebenden logistischen klassichen Kalkül ''LK'' wird diese Sonderstellung aufgehoben."&lt;/ref&gt; He said that the sequent calculus LJ gave more symmetry than natural deduction NJ in the case of intuitionistic logic, as also in the case of classical logic (LK versus NK).&lt;ref&gt;{{harvnb|Gentzen|1934|p=191}}. "Die damit erreichte Symmetrie erweist sich als für die klassische Logik angemessener."&lt;/ref&gt; Then he said that in addition to these reasons, the sequent calculus with multiple succedent formulas is intended particularly for his principal theorem ("Hauptsatz").&lt;ref&gt;{{harvnb|Gentzen|1934|p=191}}. "Hiermit haben wir einige Gesichtspunkte zur Begründung der Aufstellung der folgenden Kalküle angegeben. Im wesentlichen ist ihre Form jedoch durch die Rücksicht auf den nachher zu beweisenden 'Hauptsatz' bestimmt und kann daher vorläufig nicht näher begründet werden."&lt;/ref&gt;

===Origin of word "sequent"===

The word "sequent" is taken from the word "Sequenz" in Gentzen's 1934 paper.&lt;ref name=gentzen19341935 /&gt; Kleene makes the following comment on the translation into English: "Gentzen says 'Sequenz', which we translate as 'sequent', because we have already used 'sequence' for any succession of objects, where the German is 'Folge'."&lt;ref&gt;{{harvnb|Kleene|2002|p=441}}.&lt;/ref&gt;

== Proving logical formulas ==
[[File:Sequent calculus proof tree example.png|thumb|A rooted tree describing a proof finding procedure by sequent calculus]]

=== Reduction trees&lt;!--'Reduction tree', 'Reduction trees', 'Inference line' and 'Inference lines' redirect here--&gt; ===
Sequent calculus can be seen as a tool for proving formulas in [[propositional logic]], similar to the [[method of analytic tableaux]]. It gives a series of steps which allows one to reduce the problem of proving a logical formula to simpler and simpler formulas until one arrives at trivial ones.&lt;ref name = "Cornell09"&gt;[http://www.cs.cornell.edu/courses/cs4860/2009sp/lec-09.pdf Applied Logic, Univ. of Cornell: Lecture 9]. Last Retrieved: 2016-06-25&lt;/ref&gt;

Consider the following formula:
:&lt;math&gt;((p\rightarrow r)\lor (q\rightarrow r))\rightarrow ((p\land q)\rightarrow r)&lt;/math&gt;

This is written in the following form, where the proposition that needs to be proven is to the right of the [[Turnstile (symbol)|turnstile symbol]] &lt;math&gt;\vdash&lt;/math&gt;:
:&lt;math&gt;\vdash((p\rightarrow r)\lor (q\rightarrow r))\rightarrow ((p\land q)\rightarrow r)&lt;/math&gt;

Now, instead of proving this from the axioms, it is enough to assume the premise of the [[Logical consequence|implication]] and then try to prove its conclusion.&lt;ref name=Wadler&gt;"Remember, the way that you [[Proof (truth)|prove]]  an [[logical consequence|implication]] is by assuming the [[hypothesis]]." —[[Philip Wadler]], [https://www.youtube.com/watch?v=OGF-TGd-CIo&amp;list=PLWbHc_FXPo2jB6IZ887vLXsPoympL3KEy&amp;index=11 on 2 November 2015, in his  Keynote: "Propositions as Types". Minute 14:36 /55:28 of Code Mesh video clip ]&lt;/ref&gt; Hence one moves to the following sequent:
:&lt;math&gt;(p\rightarrow r)\lor (q\rightarrow r)\vdash (p\land q)\rightarrow r&lt;/math&gt;

Again the right hand side includes an implication, whose premise can further be assumed so that only its conclusion needs to be proven:
:&lt;math&gt;(p\rightarrow r)\lor (q\rightarrow r), (p\land q)\vdash r&lt;/math&gt;

Since the arguments in the left-hand side are assumed to be related by [[Logical conjunction|conjunction]], this can be replaced by the following:
:&lt;math&gt;(p\rightarrow r)\lor (q\rightarrow r), p, q\vdash r&lt;/math&gt;

This is equivalent to proving the conclusion in both cases of the [[Logical disjunction|disjunction]] on the first argument on the left. Thus we may split the sequent to two, where we now have to prove each separately:
:&lt;math&gt;p\rightarrow r, p, q\vdash r&lt;/math&gt;
:&lt;math&gt;q\rightarrow r, p, q\vdash r&lt;/math&gt;

In the case of the first judgment, we rewrite &lt;math&gt;p\rightarrow r&lt;/math&gt; as &lt;math&gt;\lnot p \lor r&lt;/math&gt; and split the sequent again to get:
:&lt;math&gt;\lnot p, p, q \vdash r&lt;/math&gt;
:&lt;math&gt;r, p, q \vdash r&lt;/math&gt;

The second sequent is done; the first sequent can be further simplified into:
:&lt;math&gt;p, q \vdash p, r&lt;/math&gt;

This process can always be continued until there are only atomic formulas in each side. 
The process can be graphically described by a [[Tree (graph theory)|rooted tree graph]], as depicted on the right. The root of the tree is the formula we wish to prove; the leaves consist of atomic formulas only. The tree is known as a '''reduction tree'''&lt;!--boldface per WP:R#PLA--&gt;.&lt;ref name = "Cornell09"/&gt;&lt;ref name = "Tait"&gt;{{cite book| vauthors = Tait WW | title = Gentzen's Centenary: The Quest for Consistency |chapter= Gentzen's original consistency proof and the Bar Theorem |chapter-url= http://home.uchicago.edu/~wwtx/Gentzen.original.pdf | veditors = Kahle R, Rathjen M |pages= 213–228 |location= New York |publisher= Springer |year= 2010}}&lt;/ref&gt;

The items to the left of the turnstile are understood to be connected by conjunction, and those to the right by disjunction. Therefore, when both consist only of atomic symbols, the sequent is provable (and always true) if and only if at least one of the symbols on the right also appears on the left.

Following are the rules by which one proceeds along the tree. Whenever one sequent is split into two, the tree vertex has three edges (one coming from the vertex closer to the root), and the tree is branched. Additionally, one may freely change the order of the arguments in each side; &amp;Gamma; and &amp;Delta; stand for possible additional arguments.&lt;ref name = "Cornell09"/&gt;

The usual term for the horizontal line used in Gentzen-style layouts for natural deduction is '''inference line'''&lt;!--boldface per WP:R#PLA--&gt;.&lt;ref&gt;Jan von Plato, ''Elements of Logical Reasoning'', Cambridge University Press, 2014, p. 32.&lt;/ref&gt;

{| border="0" cellpadding="20" style="text-align:center"
|-
| Left: 
| Right:
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;L\land&lt;/math&gt; rule: &lt;math&gt;  \quad\cfrac{\Gamma, A \land B\vdash \Delta} {\Gamma, A, B \vdash \Delta}
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;R\land &lt;/math&gt; rule: &lt;math&gt;  \cfrac{\Gamma\vdash \Delta, A \land B} {\Gamma \vdash \Delta, A \qquad \Gamma \vdash \Delta, B}
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;L\lor&lt;/math&gt; rule: &lt;math&gt;  \cfrac{\Gamma, A \lor B\vdash \Delta} {\Gamma, A \vdash \Delta \qquad \Gamma, B \vdash \Delta}
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;R\lor &lt;/math&gt; rule: &lt;math&gt;  \quad\cfrac{\Gamma\vdash \Delta, A \lor B} {\Gamma \vdash \Delta, A, B}
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;L\rightarrow&lt;/math&gt; rule: &lt;math&gt; \cfrac{\Gamma, A \rightarrow B\vdash \Delta} {\Gamma \vdash \Delta,A \qquad \Gamma, B \vdash \Delta}
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;R\rightarrow &lt;/math&gt; rule: &lt;math&gt;  \quad\cfrac{\Gamma\vdash \Delta, A \rightarrow B} {\Gamma, A \vdash \Delta, B}
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;L\lnot&lt;/math&gt; rule: &lt;math&gt;  \quad\cfrac{\Gamma, \lnot A \vdash \Delta} {\Gamma \vdash \Delta,A }
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;R\lnot &lt;/math&gt; rule: &lt;math&gt;  \quad\cfrac{\Gamma\vdash \Delta, \lnot A} {\Gamma, A \vdash \Delta}
 &lt;/math&gt;
|-
| Axiom: 
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;  p,r \vdash q,r &lt;/math&gt;

|}

Starting with any formula in propositional logic, by a series of steps, the right side of the turnstile can be processed until it includes only atomic symbols. Then, the same is done for the left side. Since every logical operator appears in one of the rules above, and is omitted by the rule, the process terminates when no logical operators remain: The formula has been ''decomposed''.

Thus, the sequents in the leaves of the trees include only atomic symbols, which are either provable by the axiom or not, according to whether one of the symbols on the right also appears on the left.

It is easy to see that the steps in the tree preserve the semantic truth value of the formulas implied by them, with conjunction understood between the tree's different branches whenever there is a split. It is also obvious that an axiom is provable if and only if it is true for every truth values of the atomic symbols. Thus this system is [[soundness|sound]] and [[completeness (logic)|complete]] in propositional logic.

=== Relation to standard axiomatizations ===

Sequent calculus is related to other axiomatizations of propositional calculus, such as [[Frege's propositional calculus]] or [[Propositional calculus#Example 1. Simple axiom system|Jan Łukasiewicz's axiomatization]] (itself a part of the standard [[Hilbert system]]): Every formula that can be proven in these has a reduction tree.

This can be shown as follows: Every proof in propositional calculus uses only axioms and the inference rules. Each use of an axiom scheme yields a true logical formula, and can thus be proven in sequent calculus; examples for these are [[Sequent calculus#Example derivations|shown below]]. The only inference rule in the systems mentioned above is modus ponens, which is implemented by the cut rule.

==The system LK==

This section introduces the rules of the sequent calculus '''LK''' (which just stands for “'''k'''lassische Prädikaten'''l'''ogik”), as introduced by Gentzen in 1934.{{sfn|Gentzen|1934|pp=190–193}}
A (formal) proof in this calculus is a sequence of sequents, where each of the sequents is derivable from sequents appearing earlier in the sequence by using one of the [[rule of inference|rules]] below.

===Inference rules===

The following notation will be used:
* &lt;math&gt;\vdash&lt;/math&gt; known as the [[Turnstile (symbol)|turnstile]], separates the ''assumptions'' on the left from the ''propositions'' on the right
* &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; denote formulae of first-order predicate logic (one may also restrict this to propositional logic),
* &lt;math&gt;\Gamma, \Delta, \Sigma&lt;/math&gt;, and &lt;math&gt;\Pi&lt;/math&gt; are finite (possibly empty) sequences of formulae (in fact, the order of formulae does not matter; see subsection [[Sequent calculus#Structural rules|Structural Rules]]),  called contexts,
** when on the ''left'' of the &lt;math&gt;\vdash&lt;/math&gt;, the sequence of formulas is considered ''conjunctively'' (all assumed to hold at the same time),
** while on the ''right'' of the &lt;math&gt;\vdash&lt;/math&gt;, the sequence of formulas is considered ''disjunctively'' (at least one of the formulas must hold for any assignment of variables),
* &lt;math&gt;t&lt;/math&gt; denotes an arbitrary term,
* &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; denote variables.
* a variable is said to occur [[Free variables and bound variables|free]] within a formula if it occurs outside the scope of quantifiers &lt;math&gt;\forall&lt;/math&gt; or &lt;math&gt;\exists&lt;/math&gt;.
* &lt;math&gt;A[t/x]&lt;/math&gt; denotes the formula that is obtained by substituting the term &lt;math&gt;t&lt;/math&gt; for every free occurrence of the variable &lt;math&gt;x&lt;/math&gt; in formula &lt;math&gt;A&lt;/math&gt; with the restriction that the term &lt;math&gt;t&lt;/math&gt; must be free for the variable &lt;math&gt;x&lt;/math&gt; in &lt;math&gt;A&lt;/math&gt; (i.e., no occurrence of any variable in &lt;math&gt;t&lt;/math&gt; becomes bound in &lt;math&gt;A[t/x]&lt;/math&gt;).
* &lt;math&gt;WL&lt;/math&gt; and &lt;math&gt;WR&lt;/math&gt; stand for ''Weakening Left/Right'', &lt;math&gt;CL&lt;/math&gt; and &lt;math&gt;CR&lt;/math&gt; for ''Contraction'', and &lt;math&gt;PL&lt;/math&gt; and &lt;math&gt;PR&lt;/math&gt; for ''Permutation''.

Note that, contrary to the rules for proceeding along the reduction tree presented above, the following rules are for moving in the opposite directions, from axioms to theorems. Thus they are exact mirror-images of the rules above, except that here symmetry is not implicitly assumed, and rules regarding [[quantifier (logic)|quantification]] are added.

{| border="0" cellpadding="20" style="text-align:center"
|-
| Axiom: 
| Cut:
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; \cfrac{\qquad }{ A \vdash A} \quad (I) &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; 
   \cfrac{\Gamma \vdash \Delta, A \qquad A, \Sigma \vdash \Pi} {\Gamma, \Sigma \vdash \Delta, \Pi} \quad (\mathit{Cut})
 &lt;/math&gt;
|-
| Left logical rules: 
| Right logical rules:
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; \cfrac{\Gamma, A \vdash \Delta} {\Gamma, A \land B \vdash \Delta} \quad ({\land}L_1)
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; \cfrac{\Gamma \vdash A, \Delta}{\Gamma \vdash A \lor B, \Delta} \quad  ({\lor}R_1)
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; \cfrac{\Gamma, B \vdash \Delta}{\Gamma, A \land B \vdash \Delta}  \quad ({\land}L_2)
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; \cfrac{\Gamma \vdash B, \Delta}{\Gamma \vdash A \lor B, \Delta} \quad ({\lor}R_2)
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; \cfrac{\Gamma, A \vdash \Delta \qquad \Sigma, B \vdash \Pi}{\Gamma, \Sigma, A \lor B \vdash \Delta, \Pi} \quad ({\lor}L)
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt; \cfrac{\Gamma \vdash A, \Delta \qquad \Sigma \vdash B, \Pi}{\Gamma, \Sigma \vdash A \land B, \Delta, \Pi} \quad ({\land}R)
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash A, \Delta \qquad \Sigma, B \vdash \Pi}{\Gamma, \Sigma, A\rightarrow B \vdash \Delta, \Pi} \quad  ({\rightarrow }L)
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
   \cfrac{\Gamma, A \vdash B, \Delta}{\Gamma \vdash A \rightarrow B, \Delta} \quad ({\rightarrow}R)
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash A, \Delta}{\Gamma, \lnot A \vdash \Delta} \quad  ({\lnot}L)
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma, A \vdash \Delta}{\Gamma \vdash \lnot A, \Delta} \quad ({\lnot}R)
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma, A[t/x] \vdash \Delta}{\Gamma, \forall x A \vdash \Delta} \quad  ({\forall}L)
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash A[y/x], \Delta}{\Gamma \vdash \forall x A, \Delta} \quad  ({\forall}R) 
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma, A[y/x] \vdash \Delta}{\Gamma, \exists x A \vdash \Delta} \quad  ({\exists}L)
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash A[t/x], \Delta}{\Gamma \vdash \exists x A, \Delta} \quad  ({\exists}R)
 &lt;/math&gt;
|-
| Left structural rules:
| Right structural rules:
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash \Delta}{\Gamma, A \vdash \Delta} \quad (\mathit{WL})
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash \Delta}{\Gamma \vdash A, \Delta} \quad (\mathit{WR})
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma, A, A \vdash \Delta}{\Gamma, A \vdash \Delta} \quad (\mathit{CL})
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash A, A, \Delta}{\Gamma \vdash A, \Delta} \quad (\mathit{CR})
 &lt;/math&gt;
|-
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma_1, A, B, \Gamma_2 \vdash \Delta}{\Gamma_1, B, A, \Gamma_2 \vdash \Delta} \quad (\mathit{PL})
 &lt;/math&gt;
| style="background:#fafafa; border:1px #ccc solid;" | 
&lt;math&gt;
  \cfrac{\Gamma \vdash \Delta_1, A, B, \Delta_2}{\Gamma \vdash \Delta_1, B, A, \Delta_2} \quad (\mathit{PR})
 &lt;/math&gt;
|}

''Restrictions: In the rules &lt;math&gt;({\forall}R)&lt;/math&gt; and &lt;math&gt;({\exists}L)&lt;/math&gt;, the variable &lt;math&gt;y&lt;/math&gt; must not occur free anywhere in the respective lower sequents.''

===An intuitive explanation===

The above rules can be divided into two major groups: ''logical'' and ''structural'' ones. Each of the logical rules introduces a new logical formula either on the left or on the right of the [[Turnstile (symbol)|turnstile]] &lt;math&gt;\vdash&lt;/math&gt;. In contrast, the structural rules operate on the structure of the sequents, ignoring the exact shape of the formulae. The two exceptions to this general scheme are the axiom of identity (I) and the rule of (Cut).

Although stated in a formal way, the above rules allow for a very intuitive reading in terms of classical logic. Consider, for example, the rule &lt;math&gt;({\land}L_1)&lt;/math&gt;. It says that, whenever one can prove that &lt;math&gt;\Delta&lt;/math&gt; can be concluded from some sequence of formulae that contain &lt;math&gt;A&lt;/math&gt;, then one can also conclude &lt;math&gt;\Delta&lt;/math&gt; from the (stronger) assumption that &lt;math&gt;A \land B&lt;/math&gt; holds. Likewise, the rule &lt;math&gt;({\neg}R)&lt;/math&gt; states that, if &lt;math&gt;\Gamma&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt; suffice to conclude &lt;math&gt;\Delta&lt;/math&gt;, then from &lt;math&gt;\Gamma&lt;/math&gt; alone one can either still conclude &lt;math&gt;\Delta&lt;/math&gt; or &lt;math&gt;A&lt;/math&gt; must be false, i.e. &lt;math&gt;{\neg}A&lt;/math&gt; holds. All the rules can be interpreted in this way.

For an intuition about the quantifier rules, consider the rule &lt;math&gt;({\forall}R)&lt;/math&gt;. Of course concluding that &lt;math&gt;\forall{x} A&lt;/math&gt; holds just from the fact that &lt;math&gt;A[y/x]&lt;/math&gt; is true is not in general possible. If, however, the variable y is not mentioned elsewhere (i.e. it can still be chosen freely, without influencing the other formulae), then one may assume, that &lt;math&gt;A[y/x]&lt;/math&gt; holds for any value of y. The other rules should then be pretty straightforward.

Instead of viewing the rules as descriptions for legal derivations in predicate logic, one may also consider them as instructions for the construction of a proof for a given statement. In this case the rules can be read bottom-up; for example, &lt;math&gt;({\land}R)&lt;/math&gt; says that, to prove that &lt;math&gt;A \land B&lt;/math&gt; follows from the assumptions &lt;math&gt;\Gamma&lt;/math&gt; and &lt;math&gt;\Sigma&lt;/math&gt;, it suffices to prove that &lt;math&gt;A&lt;/math&gt; can be concluded from &lt;math&gt;\Gamma&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; can be concluded from &lt;math&gt;\Sigma&lt;/math&gt;, respectively. Note that, given some antecedent, it is not clear how this is to be split into &lt;math&gt;\Gamma&lt;/math&gt; and &lt;math&gt;\Sigma&lt;/math&gt;. However, there are only finitely many possibilities to be checked since the antecedent by assumption is finite. This also illustrates how proof theory can be viewed as operating on proofs in a combinatorial fashion: given proofs for both &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;, one can construct a proof for &lt;math&gt;A \land B&lt;/math&gt;.

When looking for some proof, most of the rules offer more or less direct recipes of how to do this. The rule of cut is different: it states that, when a formula &lt;math&gt;A&lt;/math&gt; can be concluded and this formula may also serve as a premise for concluding other statements, then the formula &lt;math&gt;A&lt;/math&gt; can be "cut out" and the respective derivations are joined. When constructing a proof bottom-up, this creates the problem of guessing &lt;math&gt;A&lt;/math&gt; (since it does not appear at all below). The [[cut-elimination theorem]] is thus crucial to the applications of sequent calculus in [[automated deduction]]: it states that all uses of the cut rule can be eliminated from a proof, implying that any provable sequent can be given a ''cut-free'' proof.

The second rule that is somewhat special is the axiom of identity (I). The intuitive reading of this is obvious: every formula proves itself.  Like the cut rule, the axiom of identity is somewhat redundant: the [[completeness of atomic initial sequents]] states that the rule can be restricted to [[atomic formula]]s without any loss of provability.

Observe that all rules have mirror companions, except the ones for implication. This reflects the fact that the usual language of first-order logic does not include the "is not implied by" connective &lt;math&gt;\not\leftarrow&lt;/math&gt; that would be the De Morgan dual of implication. Adding such a connective with its natural rules would make the calculus completely left-right symmetric.

===Example derivations===

Here is the derivation of "&lt;math&gt; \vdash A \lor \lnot A &lt;/math&gt;", known as
the ''[[Law of excluded middle]]'' (''tertium non datur'' in Latin).
{| align=center border=0 cellspacing=0 cellpadding=0
|-
| &amp;nbsp;
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (I)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      A \vdash A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\lnot R)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash \lnot A , A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\lor R_2)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash A \lor \lnot A , A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (PR)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash A , A \lor \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\lor R_1)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash A \lor \lnot A , A \lor \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (CR)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash A \lor \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}

Next is the proof of a simple fact involving quantifiers. Note that the converse is not true, and its falsity can be seen when attempting to derive it bottom-up, because an existing free variable cannot be used in substitution in the rules &lt;math&gt;(\forall R)&lt;/math&gt; and &lt;math&gt;(\exists L)&lt;/math&gt;.
{| align=center border=0 cellspacing=0 cellpadding=0
|-
| &amp;nbsp;
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (I)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      p(x,y) \vdash p(x,y)
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\forall L)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \forall x \left( p(x,y) \right) \vdash p(x,y)
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\exists R)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \forall x \left( p(x,y) \right) \vdash \exists y \left( p(x,y) \right)
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\exists L)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \exists y \left( \forall x \left( p(x,y) \right) \right) \vdash \exists y \left( p(x,y) \right)
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\forall R)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \exists y \left( \forall x \left( p(x,y) \right) \right) \vdash \forall x \left( \exists y \left( p(x,y) \right) \right)
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}

For something more interesting we shall prove &lt;math&gt;{\left( \left( A \rightarrow \left( B \lor C \right) \right) \rightarrow \left( \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) \rightarrow \lnot A \right) \right)}&lt;/math&gt;. It is straightforward to find the derivation, which exemplifies the usefulness of LK in automated proving.
{| align=center border=0 cellspacing=0 cellpadding=0
|-
|
{| align=center border=0 cellspacing=0 cellpadding=0
|-
| valign=bottom |
{| align=center border=0 cellspacing=0 cellpadding=0
|-
| &amp;nbsp;
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (I)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      A \vdash A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\lnot R)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash \lnot A , A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (PR)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash A , \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}
| &amp;nbsp;&amp;nbsp;
| valign=bottom |
{| align=center border=0 cellspacing=0 cellpadding=0
|-
|
{| align=center border=0 cellspacing=0 cellpadding=0
|-
| valign=bottom |
{| align=center border=0 cellspacing=0 cellpadding=0
|-
|
{| align=center border=0 cellspacing=0 cellpadding=0
|-
| valign=bottom |
{| align=center border=0 cellspacing=0 cellpadding=0
|-
|
|  | &amp;nbsp;
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (I)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      B \vdash B
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}
| &amp;nbsp;&amp;nbsp;
| valign=bottom |
{| align=center border=0 cellspacing=0 cellpadding=0
|-
|
|  | &amp;nbsp;
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (I)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      C \vdash C
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}
|}
| &amp;nbsp;
| rowspan=2 valign=bottom | &lt;math&gt;
      (\lor L)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      B \lor C \vdash B , C
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (PR)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      B \lor C \vdash C , B
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\lnot L)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      B \lor C , \lnot C \vdash B
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}
| &amp;nbsp;&amp;nbsp;
| valign=bottom |
{| align=center border=0 cellspacing=0 cellpadding=0
|-
| &amp;nbsp;
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (I)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \lnot A \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}
|}
| &amp;nbsp;
| rowspan=2 valign=bottom | &lt;math&gt;
      (\rightarrow L)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( B \lor C \right) , \lnot C , \left( B \rightarrow \lnot A \right) \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\land L_1)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( B \lor C \right) , \lnot C , \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (PL)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( B \lor C \right) , \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) , \lnot C \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\land L_2)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( B \lor C \right) , \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) , \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (CL)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( B \lor C \right) , \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (PL)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) , \left( B \lor C \right) \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}
|}
| &amp;nbsp;
| rowspan=2 valign=bottom | &lt;math&gt;
      (\rightarrow L)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) , \left( A \rightarrow \left( B \lor C \right) \right) \vdash \lnot A , \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (CR)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) , \left( A \rightarrow \left( B \lor C \right) \right) \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (PL)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( A \rightarrow \left( B \lor C \right) \right) , \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) \vdash \lnot A
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\rightarrow R)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \left( A \rightarrow \left( B \lor C \right) \right) \vdash \left( \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) \rightarrow \lnot A \right)
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| rowspan=2 | &lt;math&gt;
      (\rightarrow R)
    &lt;/math&gt;
|-
| align=center style='border-top:1px solid black;' rowspan=2 | &lt;math&gt;
      \vdash \left( \left( A \rightarrow \left( B \lor C \right) \right) \rightarrow \left( \left( \left( B \rightarrow \lnot A \right) \land \lnot C \right) \rightarrow \lnot A \right) \right)
    &lt;/math&gt;
| &amp;nbsp;
|-
| &amp;nbsp;
| &amp;nbsp;
|}

These derivations also emphasize the strictly formal structure of the sequent calculus. For example, the logical rules as defined above always act on a formula immediately adjacent to the turnstile, such that the permutation rules are necessary. Note, however, that this is in part an artifact of the presentation, in the original style of Gentzen. A common simplification involves the use of [[multiset]]s of formulas in the interpretation of the sequent, rather than sequences, eliminating the need for an explicit permutation rule. This corresponds to shifting commutativity of assumptions and derivations outside the sequent calculus, whereas LK embeds it within the system itself.

===Relation to analytic tableaux===
For certain formulations (i.e. variants) of the sequent calculus, a proof in such a calculus is isomorphic to an upside-down, closed [[method of analytic tableaux|analytic tableau]].&lt;ref&gt;{{harvnb|Smullyan|1995|p=107}}&lt;/ref&gt;

===Structural rules===

The structural rules deserve some additional discussion.

Weakening (W) allows the addition of arbitrary elements to a sequence.  Intuitively, this is allowed in the antecedent because we can always restrict the scope of our proof (if all cars have wheels, then it's safe to say that all black cars have wheels); and in the succedent because we can always allow for alternative conclusions (if all cars have wheels, then it's safe to say that all cars have either wheels or wings).

Contraction (C) and Permutation (P) assure that neither the order (P) nor the multiplicity of occurrences (C) of elements of the sequences matters. Thus, one could instead of [[sequence]]s also consider [[Set (mathematics)|sets]].

The extra effort of using sequences, however, is justified since part or all of the structural rules may be omitted. Doing so, one obtains the so-called [[substructural logic]]s.

===Properties of the system LK===

This system of rules can be shown to be both [[soundness|sound]] and [[completeness (logic)|complete]] with respect to first-order logic, i.e. a statement &lt;math&gt;A&lt;/math&gt; follows [[semantics|semantically]] from a set of premises &lt;math&gt;\Gamma&lt;/math&gt; &lt;math&gt;(\Gamma \vDash A)&lt;/math&gt; [[iff]] the sequent &lt;math&gt;\Gamma \vdash A&lt;/math&gt; can be derived by the above rules.&lt;ref&gt;{{harvnb|Kleene|2002|p=336}}, wrote in 1967 that "it was a major logical discovery by Gentzen 1934–5 that, when there is any (purely logical) proof of a proposition, there is a direct proof. The implications of this discovery are in theoretical logical investigations, rather than in building collections of proved formulas."&lt;/ref&gt;

In the sequent calculus, the rule of [[cut-elimination|cut is admissible]]. This result is also referred to as Gentzen's ''Hauptsatz'' ("Main Theorem").&lt;ref name=curry_cut_elimination /&gt;&lt;ref name=kleene_cut_elimination /&gt;

==Variants==

The above rules can be modified in various ways:

===Minor structural alternatives===

There is some freedom of choice regarding the technical details of how sequents and structural rules are formalized. As long as every derivation in LK can be effectively transformed to a derivation using the new rules and vice versa, the modified rules may still be called LK.

First of all, as mentioned above, the sequents can be viewed to consist of sets or [[multiset]]s. In this case, the rules for permuting and (when using sets) contracting formulae are obsolete.

The rule of weakening will become admissible, when the axiom (I) is changed, such that any sequent of the form &lt;math&gt;\Gamma , A \vdash A , \Delta&lt;/math&gt; can be concluded. This means that &lt;math&gt;A&lt;/math&gt; proves &lt;math&gt;A&lt;/math&gt; in any context. Any weakening that appears in a derivation can then be performed right at the start. This may be a convenient change when constructing proofs bottom-up.

Independent of these one may also change the way in which contexts are split within the rules: In the cases &lt;math&gt;({\land}R), ({\lor}L)&lt;/math&gt;, and &lt;math&gt;({\rightarrow}L)&lt;/math&gt; the left context is somehow split into &lt;math&gt;\Gamma&lt;/math&gt; and &lt;math&gt;\Sigma&lt;/math&gt; when going upwards. Since contraction allows for the duplication of these, one may assume that the full context is used in both branches of the derivation. By doing this, one assures that no important premises are lost in the wrong branch. Using weakening, the irrelevant parts of the context can be eliminated later.

===Absurdity===
One can introduce &lt;math&gt;\bot&lt;/math&gt;, the [[principle of explosion|absurdity constant]] representing ''false'', with the axiom:

:&lt;math&gt;
  \cfrac{}{\bot \vdash \quad }
&lt;/math&gt;

Or if, as described above, weakening is to be an admissible rule, then with the axiom:

:&lt;math&gt;
  \cfrac{}{\Gamma, \bot \vdash \Delta}
&lt;/math&gt;

With &lt;math&gt;\bot&lt;/math&gt;, negation can be subsumed as a special case of implication, via the definition &lt;math&gt;\neg A \iff A \to \bot&lt;/math&gt;.

===Substructural logics===
{{main article|Substructural logic}}

Alternatively, one may restrict or forbid the use of some of the structural rules. This yields a variety of [[substructural logic]] systems. They are generally weaker than LK (''i.e.'', they have fewer theorems), and thus not complete with respect to the standard semantics of first-order logic. However, they have other interesting properties that have led to applications in theoretical [[computer science]] and [[artificial intelligence]].

===Intuitionistic sequent calculus: System LJ===

Surprisingly, some small changes in the rules of LK suffice to turn it into a proof system for [[intuitionistic logic]].&lt;ref&gt;{{harvnb|Gentzen|1934|p=194}}, wrote: "Der Unterschied zwischen ''intuitionistischer'' und ''klassischer'' Logik ist bei den Kalkülen ''LJ'' und ''LK'' äußerlich ganz anderer Art als bei ''NJ'' und ''NK''. Dort bestand er in Weglassung bzw. Hinzunahme des Satzes vom ausgeschlossenen Dritten, während er hier durch die Sukzedensbedingung ausgedrückt wird." English translation: "The difference between ''intuitionistic'' and ''classical'' logic is in the case of the calculi ''LJ'' and ''LK'' of an extremely, totally different kind to the case of ''NJ'' and ''NK''. In the latter case, it consisted of the removal or addition respectively of the excluded middle rule, whereas in the former case, it is expressed through the succedent conditions."&lt;/ref&gt; To this end, one has to restrict to sequents with exactly one formula on the right-hand side, and modify the rules to maintain this invariant.  For example, &lt;math&gt;({\lor}L)&lt;/math&gt; is reformulated as follows (where C is an arbitrary formula):

:&lt;math&gt;
  \cfrac{\Gamma, A \vdash C \qquad \Sigma, B \vdash C }{\Gamma, \Sigma, A \lor B \vdash C} \quad ({\lor}L)
&lt;/math&gt;

The resulting system is called LJ. It is sound and complete with respect to intuitionistic logic and admits a similar cut-elimination proof. This can be used in proving [[disjunction and existence properties]].

In fact, the only two rules in LK that need to be restricted to single-formula consequents are &lt;math&gt;({\to}R)&lt;/math&gt; and &lt;math&gt;(\neg R)&lt;/math&gt;&lt;ref&gt;Structural Proof Theory (CUP, 2001), Sara Negri and Jan van Plato&lt;/ref&gt; (and the latter can be seen as a special case of the former, via &lt;math&gt;\bot&lt;/math&gt; as described above). When multi-formula consequents are interpreted as disjunctions, all of the other inference rules of LK are actually derivable in LJ, while the offending rule is

:&lt;math&gt;
  \cfrac{\Gamma, A \vdash B \lor C}{\Gamma \vdash (A \to B) \lor C} 
&lt;/math&gt;

This amounts to the propositional formula &lt;math&gt;(A \to (B \lor C)) \to ((A \to B) \lor C)&lt;/math&gt;, a classical tautology that is not constructively valid.

==See also==
* [[Cirquent calculus]]
* [[Nested sequent calculus]]
* [[Resolution (logic)]]

==Notes==
{{Reflist}}

==References==
* {{cite book|ref=harv|last1=Buss|first1=Samuel R.|chapter=An introduction to proof theory | editor = Samuel R. Buss | title=Handbook of proof theory | pages = 1–78 | url = http://math.ucsd.edu/~sbuss/ResearchWeb/handbookI/ | publisher = Elsevier | year = 1998 | isbn = 0-444-89840-9 }}
* {{cite book|ref=harv|last1=Curry|first1=Haskell Brooks|author1-link=Haskell Curry|title=Foundations of mathematical logic|origyear=1963|year=1977|publisher=Dover Publications Inc.|location=New York|isbn=978-0-486-63462-3}}
* {{Cite journal|ref=harv|last1=Gentzen|first1=Gerhard Karl Erich|author1-link=Gerhard Gentzen|title=Untersuchungen über das logische Schließen. I|journal=Mathematische Zeitschrift|volume=39|issue=2|year=1934|publisher=|doi=10.1007/BF01201353|pages=176–210|url=http://gdz.sub.uni-goettingen.de/dms/resolveppn/?PPN=GDZPPN002375508}}
* {{Cite journal|ref=harv|last1=Gentzen|first1=Gerhard Karl Erich|author1-link=Gerhard Gentzen|title=Untersuchungen über das logische Schließen. II|journal=Mathematische Zeitschrift|volume=39|issue=3|year=1935|publisher=|pages=405–431|url=http://gdz.sub.uni-goettingen.de/dms/resolveppn/?PPN=GDZPPN002375605|doi=10.1007/bf01201363}}
* {{cite book | first=Jean-Yves | last=Girard | authorlink=Jean-Yves Girard |author2=Paul Taylor |author3=Yves Lafont  | title=Proofs and Types | publisher=Cambridge University Press (Cambridge Tracts in Theoretical Computer Science, 7) | year=1990 | origyear=1989 | isbn=0-521-37181-3 | url= http://www.paultaylor.eu/stable/Proofs%2BTypes.html}}
* {{cite book|ref=harv|last1=Hilbert|first1=David| author1-link=David Hilbert | last2=Bernays | first2=Paul |author2-link=Paul Bernays|title=Grundlagen der Mathematik II|origyear=1939|year=1970|publisher=Springer-Verlag|location=Berlin, New York|isbn=978-3-642-86897-9|edition=Second}}
* {{cite book|ref=harv|last1=Kleene|first1=Stephen Cole|author1-link=Stephen Cole Kleene|title=Introduction to metamathematics|origyear=1952|year=2009|publisher=Ishi Press International|isbn=978-0-923891-57-2}} 
* {{cite book|ref=harv|last1=Kleene|first1=Stephen Cole|author1-link=Stephen Cole Kleene|title=Mathematical logic|origyear=1967|year=2002|publisher=Dover Publications|location=Mineola, New York|isbn=978-0-486-42533-7}} 
* {{cite book|ref=harv|last1=Lemmon|first1=Edward John|author1-link=John Lemmon|title=Beginning logic|year=1965|publisher=Thomas Nelson|isbn=0-17-712040-1}} 
* {{cite book|ref=harv|last1=Smullyan|first1=Raymond Merrill|author1-link=Raymond Smullyan|year=1995|origyear=1968|title=First-order logic|publisher=Dover Publications|location=New York|isbn=978-0-486-68370-6}}
* {{cite book|ref=harv|last1=Suppes|first1=Patrick Colonel|author1-link=Patrick Suppes|year=1999|origyear=1957|title=Introduction to logic|publisher=Dover Publications|location=Mineola, New York|isbn=978-0-486-40687-9}}

==External links==
* {{springer|title=Sequent calculus|id=p/s084580}}
* [http://scienceblogs.com/goodmath/2006/07/17/a-brief-diversion-sequent-calc/ A Brief Diversion: Sequent Calculus]
* [http://logitext.mit.edu/logitext.fcgi/tutorial Interactive tutorial of the Sequent Calculus]

[[Category:Proof theory]]
[[Category:Logical calculi]]
[[Category:Automated theorem proving]]</text>
      <sha1>iyoucu2glez6crxgd4rjrotqxnxkfht</sha1>
    </revision>
  </page>
  <page>
    <title>Sixth power</title>
    <ns>0</ns>
    <id>54558894</id>
    <revision>
      <id>852055581</id>
      <parentid>826906273</parentid>
      <timestamp>2018-07-26T09:59:42Z</timestamp>
      <contributor>
        <username>Aeonx</username>
        <id>12314833</id>
      </contributor>
      <minor/>
      <comment>clean up, removed stub tag using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6009">In [[arithmetic]] and [[algebra]] the '''sixth [[power (algebra)|power]]''' of a number ''n'' is the result of multiplying six instances of ''n'' together. So:
:{{math|size=120%|1=''n''&lt;sup&gt;6&lt;/sup&gt; = ''n'' × ''n'' × ''n'' × ''n'' × ''n'' × ''n''}}.

Sixth powers are also formed by multiplying a number by its [[fifth power (algebra)|fifth power]], the [[square number|square]] of a number by its [[fourth power]], or the [[cube number|cube]] of a number by itself,
by taking a square to the third power, or by squaring a cube.

The sequence of sixth powers of [[integer]]s is:

:0, 1, 64, 729, 4096, 15625, 46656, 117649, 262144, 531441, 1000000, 1771561, 2985984, 4826809, 7529536, 11390625, 16777216, 24137569, 34012224, 47045881, 64000000, 85766121, 113379904, 148035889, 191102976, 244140625, 308915776, 387420489, 481890304, ... {{OEIS|id=A001014}}
They include the significant [[decimal]] numbers 10&lt;sup&gt;6&lt;/sup&gt; (a [[million]]), 100&lt;sup&gt;6&lt;/sup&gt; (a [[Trillion (short scale)|short-scale trillion]] and long-scale billion), and 1000&lt;sup&gt;6&lt;/sup&gt; (a [[Trillion (long scale)|long-scale trillion]]).

==Squares and cubes==
The sixth powers of integers can be characterized as the numbers that are simultaneously squares and cubes.&lt;ref&gt;{{citation|magazine=Mechanics' Magazine and Journal of Science, Arts, and Manufactures|volume=4|publisher=Knight and Lacey|date=April 30, 1825|issue=88|first=Richard|last=Dowden|page=54|url=https://books.google.com/books?id=ivs-AQAAMAAJ&amp;pg=PA50|title=(untitled)}}&lt;/ref&gt; 
In this way, they are related to two other classes of [[figurate number]]s: the [[square triangular number]]s, which are simultaneously square and triangular,
and the solutions to the [[cannonball problem]], which are simultaneously square and square-pyramidal.

Because of their connection to squares and cubes, sixth powers play an important role in the study of the [[Mordell curve]]s, which are [[elliptic curve]]s of the form
:&lt;math&gt;y^2=x^3+k.&lt;/math&gt;
When &lt;math&gt;k&lt;/math&gt; is divisible by a sixth power, this equation can be reduced by dividing by that power to give a simpler equation of the same form.
A well-known result in number theory, proven by [[Rudolf Fueter]] and [[Louis J. Mordell]], states that, when &lt;math&gt;k&lt;/math&gt; is an integer that is not divisible by a sixth power (other than the exceptional cases &lt;math&gt;k=1&lt;/math&gt; and &lt;math&gt;k=-432&lt;/math&gt;), this equation either has no rational solutions with both &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; nonzero or infinitely many of them.&lt;ref&gt;{{citation
 | last1 = Ireland | first1 = Kenneth F.
 | last2 = Rosen | first2 = Michael I.
 | isbn = 0-387-90625-8
 | mr = 661047
 | page = 289
 | publisher = Springer-Verlag, New York-Berlin
 | series = Graduate Texts in Mathematics
 | title = A classical introduction to modern number theory
 | url = https://books.google.com/books?id=RDzrBwAAQBAJ&amp;pg=PA289
 | volume = 84
 | year = 1982}}.&lt;/ref&gt;

In the [[Zenzizenzizenzic|archaic notation]] of [[Robert Recorde]], the sixth power of a number was called the "zenzicube", meaning the square of a cube. Similarly, the notation for sixth powers used in 12th century [[Indian mathematics]] by [[Bhāskara II]] also called them either the square of a cube or the cube of a square.&lt;ref&gt;{{citation|title=A History of Mathematical Notations|series=Dover Books on Mathematics|first=Florian|last=Cajori|authorlink=Florian Cajori|publisher=Courier Corporation|year=2013|isbn=9780486161167|page=80|url=https://books.google.com/books?id=_byqAAAAQBAJ&amp;pg=PA80}}&lt;/ref&gt;

==Sums==

There are numerous known examples of sixth powers that can be expressed as the sum of seven other sixth powers, but no examples are yet known of a sixth power expressible as the sum of just six sixth powers.&lt;ref name=meyrignac&gt;Quoted in {{cite web
| last = Meyrignac
| first = Jean-Charles
| url = http://euler.free.fr/records.htm
| title = Computing Minimal Equal Sums Of Like Powers: Best Known Solutions
| date = 14 February 2001
| accessdate = 17 July 2017
}}&lt;/ref&gt; This makes it unique among the powers with exponent ''k'' = 1, 2, ... , 8, the others of which can each be expressed as the sum of ''k'' other ''k''-th powers, and some of which (in violation of [[Euler's sum of powers conjecture]]) can be expressed as a sum of even fewer ''k''-th powers.

In connection with [[Waring's problem]], every sufficiently large integer can be represented as a sum of at most 24 sixth powers of integers.&lt;ref&gt;{{citation
 | last1 = Vaughan | first1 = R. C.
 | last2 = Wooley | first2 = T. D.
 | doi = 10.1215/S0012-7094-94-07626-6
 | issue = 3
 | journal = Duke Mathematical Journal
 | mr = 1309326
 | pages = 683–710
 | title = Further improvements in Waring's problem. II. Sixth powers
 | volume = 76
 | year = 1994}}&lt;/ref&gt;

There are infinitely many different nontrivial solutions to the [[Diophantine equation]]&lt;ref&gt;{{citation
 | last = Brudno | first = Simcha
 | doi = 10.2307/2005335
 | issue = 135
 | journal = Mathematics of Computation
 | mr = 0406923
 | pages = 646–648
 | title = Triples of sixth powers with equal sums
 | volume = 30
 | year = 1976}}&lt;/ref&gt;
:&lt;math&gt;a^6+b^6+c^6=d^6+e^6+f^6.&lt;/math&gt;
It has not been proven whether the equation
:&lt;math&gt;a^6+b^6=c^6+d^6&lt;/math&gt;
has a nontrivial solution,&lt;ref&gt;{{citation
 | last1 = Bremner | first1 = Andrew
 | last2 = Guy | first2 = Richard K.
 | doi = 10.2307/2323442
 | issue = 1
 | journal = American Mathematical Monthly
 | mr = 1541235
 | pages = 31–36
 | title = Unsolved Problems: A Dozen Difficult Diophantine Dilemmas
 | volume = 95
 | year = 1988}}&lt;/ref&gt; but the [[Lander, Parkin, and Selfridge conjecture]] would imply that it does not.

==See also==
*[[Sextic equation]]
*[[Seventh power]]

==References==
{{reflist}}

==External links==
*{{mathworld|id=DiophantineEquation6thPowers|title=Diophantine Equation—6th Powers}}

{{Classes of natural numbers}}

[[Category:Integers]]
[[Category:Number theory]]
[[Category:Elementary arithmetic]]
[[Category:Integer sequences]]
[[Category:Unary operations]]

{{algebra-stub}}</text>
      <sha1>in2lmqia1nakai1xv5a2ldl5h6se2tc</sha1>
    </revision>
  </page>
  <page>
    <title>Skew gradient</title>
    <ns>0</ns>
    <id>34484092</id>
    <revision>
      <id>700833716</id>
      <parentid>522185639</parentid>
      <timestamp>2016-01-20T22:20:58Z</timestamp>
      <contributor>
        <username>Crowsnest</username>
        <id>6054452</id>
      </contributor>
      <comment>add link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1422">In [[mathematics]], a '''skew gradient''' of a [[harmonic function]] over a [[simply connected domain]] with two real dimensions is a [[vector field]] that is everywhere [[orthogonal]] to the [[gradient]] of the function and that has the same [[Magnitude (mathematics)|magnitude]] as the gradient.

==Definition==
The skew gradient can be defined using complex analysis and the [[Cauchy–Riemann equations]].

Let &lt;math&gt; f(z(x,y))=u(x,y)+iv(x,y) &lt;/math&gt; be a complex-valued analytic function, where ''u'',''v'' are real-valued scalar functions of the real variables&amp;nbsp;''x'',&amp;nbsp;''y''.

A skew gradient is defined as:

: &lt;math&gt;\nabla^\perp u(x,y)=\nabla v(x,y)&lt;/math&gt;

and from the [[Cauchy–Riemann equations]], it is derived that

: &lt;math&gt;\nabla^\perp u(x,y)=(-\frac{\partial u}{\partial y},\frac{\partial u}{\partial x})&lt;/math&gt;

==Properties==
The skew gradient has two interesting properties. It is everywhere orthogonal to the gradient of u, and of the same length:

: &lt;math&gt;\nabla u(x,y) \cdot \nabla^\perp u(x,y)=0 ,  \rVert \nabla u\rVert =\rVert \nabla^\perp u\rVert&lt;/math&gt;

==References==

{{Refbegin}}
* [[Peter J. Olver|Peter Olver]], [http://www.math.umn.edu/~olver/pdn.html Introduction to Partial Differential Equations, ch. 7, p. 232] 
{{Refend}}

[[Category:Differential calculus]]
[[Category:Generalizations of the derivative]]
[[Category:Linear operators in calculus]]
[[Category:Vector calculus]]</text>
      <sha1>jq2pe44pjq77faq01fw78wscphpsely</sha1>
    </revision>
  </page>
  <page>
    <title>Staden Package</title>
    <ns>0</ns>
    <id>22369901</id>
    <revision>
      <id>871746795</id>
      <parentid>789684920</parentid>
      <timestamp>2018-12-03T04:34:17Z</timestamp>
      <contributor>
        <username>GoingBatty</username>
        <id>11555324</id>
      </contributor>
      <minor/>
      <comment>clean up, replaced: [[open source]] → [[open-source software|open-source]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4718">{{Infobox software
| name = Staden Package
| logo = 
| screenshot = 
| caption = 
| author = Rodger Staden
| developer = James Bonfield, ''et al.''
| released = {{Start date and age|1977}}
| latest release version = 2.0.0b9
| latest release date    = {{Start date and age|2012|01|24|df=yes}}
| latest preview version = 2.0.0b11
| latest preview date = {{Start date and age|2016|04|25|df=yes}}
| programming language = [[C (programming language)|C]], [[C++]], [[Fortran]], [[Tcl]]
| operating system = [[Unix]], [[Linux]], [[macOS]], [[Microsoft Windows|Windows]]
| platform = [[IA-32]], [[x86-64]]
| size = 
| language = English
| genre = [[Bioinformatics]]
| license = [[BSD licenses|BSD]] 3-clause
| website = {{URL|staden.sourceforge.net}}
| repo = {{URL|sourceforge.net/projects/staden}}
| standard = 
| AsOf = 
}}
The '''Staden Package''' is computer [[software]], a set of tools for DNA [[sequence assembly]], editing, and sequence analysis. It is [[open-source software]], released under a [[BSD licenses|BSD]] 3-clause license.

== Package components ==

The Staden package consists of several different programs. The main components are:

* pregap4 – base calling with [[Phred base calling|Phred]], end clipping, and vector trimming
* trev – trace viewing and editing
* gap4 – sequence assembly, contig editing, and finishing
* gap5 – assembly visualising, editing, and finishing of NGS data&lt;ref name="Bonfield2010"&gt;{{cite journal |doi=10.1093/bioinformatics/btq268|vauthors=Bonfield JK, Whitwham A |year=2010|title=Gap5—editing the billion fragment sequence assembly|journal=Bioinformatics|volume=26|pages=1699–1703|pmid=20513662|issue=14|pmc=2894512}}&lt;/ref&gt;
* Spin – DNA and protein sequence analysis

== History ==

The Staden Package was developed by Rodger Staden's group at the [[Medical Research Council (United Kingdom)|Medical Research Council]] (MRC) [[Laboratory of Molecular Biology]], Cambridge, England, since 1977.&lt;ref name="Staden1979ay"&gt;{{cite journal |doi=10.1093/nar/6.7.2601 |author=Staden R|year=1979|title=A strategy of DNA sequencing employing computer programs. |pmc=327874|journal=Nucleic Acids Res|volume=6 |issue=7|pages=2601–2610|pmid=461197}}&lt;/ref&gt;&lt;ref name="Staden1984to"&gt;{{cite journal |author=Staden R|year=1984|title=Computer methods to aid the determination and analysis of DNA sequences.|journal=Biochem Soc Trans|volume=12|pages=1005–1008|pmid=6397374|issue=6|doi=10.1042/bst0121005}}&lt;/ref&gt;&lt;ref name="Staden2000xp"&gt;{{cite journal |vauthors=Staden R, Beal KF, Bonfield JK |year=2000|title=The Staden package, 1998.|journal=Methods Mol Biol|volume=132|pages=115–130|pmid=10547834|doi=10.1385/1-59259-192-2:115}}&lt;/ref&gt; The package was available free to academic users, with 2,500 licenses issued in 2003 and an estimated 10,000 users, when funding for further development ended.&lt;ref&gt;{{cite web |url=http://www.genomeweb.com/informatics/uk-s-mrc-ends-support-staden-package-first-sign-post-hgp-funding-priority-shift |title=UK s MRC Ends Support for Staden Package: First Sign of Post-HGP Funding Priority Shift? |author=&lt;!--Staff writer(s); no by-line.--&gt; |date=5 May 2003 |website=Genomeweb |publisher=Genomeweb LLC |access-date=15 November 2016}}&lt;/ref&gt; The package was converted to [[open-source software|open-source]] in 2004, and several new versions have been released since.

During the years of active development, the Staden group published a number of widely used file formats and ideas, including the SCF file format,&lt;ref name="Dear1992il"&gt;{{cite journal |vauthors=Dear S, Staden R |year=1992|title=A standard file format for data from DNA sequencing instruments.|journal=DNA Seq|volume=3|pages=107–110|pmid=1457811|doi=10.3109/10425179209034003|issue=2}}&lt;/ref&gt; the use of sequence quality scores to generate accurate consensus sequences,&lt;ref name="Bonfield1995jx"&gt;{{cite journal |doi=10.1093/nar/23.8.1406 |vauthors=Bonfield JK, Staden R |year=1995|title=The application of numerical estimates of base calling accuracy to DNA sequencing projects.|journal=Nucleic Acids Res|volume=23|pages=1406–1410 |pmid=7753633 |pmc=306869}}&lt;/ref&gt; and the ZTR file format.&lt;ref name="Bonfield2002rf"&gt;{{cite journal |doi=10.1093/bioinformatics/18.1.3 |vauthors=Bonfield JK, Staden R |year=2002|title=ZTR: a new format for DNA sequence trace data.|journal=Bioinformatics|volume=18|pages=3–10|pmid=11836205}}&lt;/ref&gt;

== See also ==
{{Portal|Free software}}
*[[Genome Compiler]]
*[[Phred base calling]]
*[[Phrap]]
*[[Consed]]
*[[CodonCode Aligner]]
*[[MacVector]]
*[[UGENE]]
*[[Vector NTI]]

== References ==
{{Reflist}}

== External links ==
*{{Official website|staden.sourceforge.net}}

[[Category:Bioinformatics software]]
[[Category:Computational science]]</text>
      <sha1>f7v75qes2eidai0stw6d5syj02hu4z0</sha1>
    </revision>
  </page>
  <page>
    <title>Suzan Rose Benedict</title>
    <ns>0</ns>
    <id>44157166</id>
    <revision>
      <id>863271002</id>
      <parentid>863270690</parentid>
      <timestamp>2018-10-09T18:58:49Z</timestamp>
      <contributor>
        <username>Waffles19</username>
        <id>34853665</id>
      </contributor>
      <minor/>
      <comment>changed mathematics to have a capital letter</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6603">{{ Infobox scientist
| name              = Suzan Rose Benedict
| image             = Photo of Suzan Benedict 1922 Smith College Yearbook with Signature.jpg
| image_size        = 
| caption           = 
| birth_date        = {{Birth date|1873|11|29}}  
| birth_place       = [[Norwalk, OH]]
| death_date        = {{Death date and age|1942|04|08|1873|11|29}}
| death_place       = [[Northampton, Massachusetts]]
| nationality       = American
| fields            = [[Mathematics]]
| workplaces        = [[Smith College]]
| alma_mater        = [[Smith College]]&lt;br /&gt;[[Columbia University]]&lt;br /&gt;[[University of Michigan]]
| thesis_title      = A Comparative Study of the Early Treatises Introducing into Europe the Hindu Art of Reckoning
| thesis_url        = 
| thesis_year       = 1914
| doctoral_advisor  = [[Louis Charles Karpinski]]
| doctoral_students = 
| awards            = 
}}

'''Suzan Rose Benedict''' (November 29, 1873 – April 8, 1942) was the first woman awarded a Ph.D. in Mathematics from the [[University of Michigan]] and had a long teaching career at [[Smith College]].&lt;ref&gt;{{cite book | url=https://books.google.de/books?id=IRbOAwAAQBAJ | isbn=978-0-8218-4376-5 | first1 = Judy | last1 = Green | author1-link = Judy Green (mathematician) | first2 = Jeanne | last2 = LaDuke | author2-link = Jeanne LaDuke | title=Pioneering Women in American Mathematics &amp;mdash; The Pre-1940 PhD's | location= | publisher=[[American Mathematical Society]], The [[London Mathematical Society]] | series=History of Mathematics | volume=34 | year = 2009 |page=10}}&lt;/ref&gt;

==Early life and education==

Suzan Benedict was born in [[Norwalk, Ohio]], the youngest of seven children of David DeForrest Benedict, MD and Harriott Melvina Benedict (née Deaver). Dr. Benedict had been a Union Surgeon in the American Civil War.&lt;ref name="Green and LaDuke, p141"&gt;Green and LaDuke (2009), p. 141&lt;/ref&gt; She was a niece of oil magnate and [[Philanthropy|philanthropist]], [[Louis Severance]].&lt;ref&gt;"Mother was Former Norwalk Resident", ''Sandusky Daily Register'', January 19, 1936, p. 9, C-2&lt;/ref&gt;

After graduating high school in Norwalk, Suzan Benedict entered Smith College in 1891. She graduated in 1895 with a major in Chemistry and minors in Mathematics, German, and Physics, then returned to Norwalk and taught Mathematics until 1905, when she began graduate studies at Teacher’s College, [[Columbia University]]. She received a M.A. in Mathematics from Columbia in 1906. That same year she joined the Mathematics Department at Smith College as an assistant in Mathematics and rose to become an instructor the following year.

The summers of 1911 through 1913 she resumed her graduate studies at the University of Michigan and in 1913–14 she took a leave of absence from Smith to finish her dissertation directed by [[Louis Charles Karpinski]]: “A Comparative Study of the Early Treatises Introducing into Europe the Hindu Art of Reckoning.” She received her PhD in 1914.

== Career at Smith College ==

Suzan returned to Smith as an associate professor after receiving her PhD. She was promoted to professor in 1921. From 1918 to 1928 she was Dean of Students and she served as chairman of the Mathematics department from 1928 to 1934.

Her first love was teaching. In May 1940 she wrote to [http://www.agnesscott.edu/lriddle/women/owens.htm Helen Owens], an instructor in mathematics at [[Pennsylvania State College]]: "it was not modesty that prevented my sending you a long list of published papers, but a scarcity of such papers. I have lost track of the very few I have written, as I have been much more interested in teaching and administration than in research."&lt;ref name="ams.org"/&gt;

In February 1942 she retired as professor emeritus, intending to support the war effort by volunteering with the Red Cross.&lt;ref name="Green and LaDuke, p141" /&gt; Two months later, she was stricken with a heart attack and died.&lt;ref&gt;“Dr Susan Benedict of Smith is Dead,” ''The New York Times'', April 10, 1942, 18.&lt;/ref&gt;

Suzan Benedict never married. From 1918 she shared a home with [[Susan Miller Rambo]], a colleague in the Mathematics Department at Smith College and the second woman to receive a PhD from the University of Michigan.&lt;ref&gt;Green and LaDuke (2009), pp. 10, 141&lt;/ref&gt;

== Memberships ==

* [[American Mathematical Society]]&lt;ref&gt;“Members of the Society,” (''American Mathematical Society Annual Register'', Published by the Society, 1913), 14.  https://books.google.com/books?id=jFBaAAAAYAAJ&amp;dq=american+mathematical+society+suzan+benedict&amp;source=gbs_navlinks_s&lt;/ref&gt;
* [[Mathematical Association of America]]&lt;ref&gt;“Fourth Summer Meeting of the Mathematical Society of America,” (''The American Mathematical Monthly'', Volume 26, No. 9, Oct., 1919), 373. https://www.jstor.org/stable/2971911&lt;/ref&gt;
* [[Daughters of the American Revolution]]&lt;ref name="ams.org"/&gt;

== Publications ==

* 1909: “The Development of Algebraic Symbolism from Paciuolo to Newton.” ''School Science and Mathematics''. Published version of MA thesis.&lt;ref name="ams.org"&gt;Judy Green and Jeanne LaDuke, “Supplementary Material for Pioneering Women in American Mathematics: The Pre-1940 PhD’s,” 76:  http://www.ams.org/publications/authors/books/postpub/hmath-34-PioneeringWomen.pdf&lt;/ref&gt;
* 1929: “The Algebra of Francesco Ghaligai”, ''American Mathematical Monthly''.&lt;ref name="ams.org"/&gt;

== Legacy ==

The [http://www.math.smith.edu/benedict.php Suzan R. Benedict Prize] was established after her death by the college president and others at Smith College to be awarded to sophomores who had done exceptional work in differential and integral calculus.&lt;ref name="Green and LaDuke, p141" /&gt;

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using&lt;ref&gt;&lt;/ref&gt; tags, these references will then appear here automatically --&gt;
{{Reflist}}

== External links ==
* [http://www.agnesscott.edu/lriddle/women/benedict.htm Biographies of Women Mathematicians, Agnes Scott College]
* [http://genealogy.math.ndsu.nodak.edu/id.php?id=5301 Mathematics Genealogy Project]
* [https://archive.org/details/comparativestudy00bene A comparative study of the early treatises introducing into Europe the Hindu art of reckoning]
* {{findagrave|73929571}}

{{Authority control}}

{{DEFAULTSORT:Benedict, Suzan Rose}}
[[Category:1873 births]]
[[Category:1942 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:American women academics]]
[[Category:Smith College faculty]]
[[Category:Women mathematicians]]
[[Category:University of Michigan alumni]]</text>
      <sha1>ffcmlo9sqnatlmi8ivu4iccksacj8j8</sha1>
    </revision>
  </page>
  <page>
    <title>Symmetric cone</title>
    <ns>0</ns>
    <id>39156141</id>
    <revision>
      <id>845163582</id>
      <parentid>800737387</parentid>
      <timestamp>2018-06-09T21:23:17Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="110805">In [[mathematics]], '''symmetric cones''', sometimes called '''domains of positivity''', are open convex self-dual cones in Euclidean space which have a transitive group of symmetries, i.e. invertible operators that take the cone onto itself. By the [[Koecher–Vinberg theorem]] these correspond to the cone of squares in finite-dimensional [[Jordan algebra#Formally real Jordan algebras|real Euclidean Jordan algebra]]s, originally studied and classified by {{harvtxt|Jordan|von Neumann|Wigner|1933}}. The [[tube domain]] associated with a symmetric cone is a noncompact [[Hermitian symmetric space]] of '''tube type'''. All the algebraic and geometric structures associated with the symmetric space can be expressed naturally in terms of the Jordan algebra. The other irreducible Hermitian symmetric spaces of noncompact type correspond to [[Siegel domain]]s of the second kind. These can be described in terms of more complicated structures called [[Jordan triple system]]s, which generalize Jordan algebras without identity.&lt;ref&gt;This article uses as its main sources {{harvtxt|Jordan|von Neumann|Wigner|1934}}, {{harvtxt|Koecher|1999}} and {{harvtxt|Faraut|Koranyi|1994}}, adopting the terminology and some simplifications from the latter.&lt;/ref&gt;

==Definitions==
A [[convex cone]] ''C'' in a finite-dimensional real [[inner product space]] ''V'' is a convex set invariant under multiplication by positive scalars. It spans the subspace ''C'' – ''C'' and the largest subspace it contains is ''C'' ∩ (−''C''). It spans the whole space if and only if it contains a basis. Since the [[convex hull]] of the basis is a polytope with non-empty interior, this happens if and only if ''C'' has non-empty interior. The interior in this case is also a convex cone. Moreover, an open convex cone coincides with the interior of its closure, since any interior point in the closure must lie in the interior of some polytope in the original cone. A convex cone is said to be ''proper'' if its closure, also a cone, contains no subspaces.

Let ''C'' be an open convex cone. Its '''dual''' is defined as

:&lt;math&gt;\displaystyle{C^*=\{X: (X,Y) &gt; 0\,\,\mathrm{for}\,\,Y \in \overline{C}\}.}&lt;/math&gt;

It is also an open convex cone and ''C''** = ''C''.&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|pp=2–4}}&lt;/ref&gt; An open convex cone ''C'' is said to be '''self-dual''' if ''C''* = ''C''. It is necessarily proper, since
it does not contain 0, so cannot contain both ''X'' and −''X''.

The '''automorphism group''' of an open convex cone is defined by

:&lt;math&gt;\displaystyle{\mathrm{Aut}\,C =\{g\in \mathrm{GL}(V)| gC=C\}.}&lt;/math&gt;

Clearly ''g'' lies in Aut ''C'' if and only if ''g'' takes the closure of ''C'' onto itself. So Aut ''C'' is a closed subgroup of GL(''V'') and hence a [[Lie group]]. Moreover, Aut ''C''* = (Aut ''C'')*, where ''g''* is the adjoint of ''g''. ''C'' is said to be '''homogeneous''' if Aut ''C'' acts transitively on ''C''.

The open convex cone ''C'' is called a '''symmetric cone''' if it is self-dual and homogeneous.

==Group theoretic properties==
*If ''C'' is a symmetric cone, then Aut ''C'' is closed under taking adjoints.
*The identity component Aut&lt;sub&gt;0&lt;/sub&gt; ''C'' acts transitively on ''C''.
*The stabilizers of points are [[maximal compact subgroup]]s, all conjugate, and exhaust the maximal compact subgroups of Aut ''C''.
*In Aut&lt;sub&gt;0&lt;/sub&gt; ''C'' the stabilizers of points are [[maximal compact subgroup]]s, all conjugate, and exhaust the maximal compact subgroups of Aut&lt;sub&gt;0&lt;/sub&gt; ''C''.
*The maximal compact subgroups of Aut&lt;sub&gt;0&lt;/sub&gt; ''C'' are connected.
*The component group of Aut ''C'' is isomorphic to the component group of a maximal compact subgroup and therefore finite.
*Aut ''C'' ∩ O(V) and Aut&lt;sub&gt;0&lt;/sub&gt; ''C'' ∩ O(V) are maximal compact subgroups in Aut ''C'' and Aut&lt;sub&gt;0&lt;/sub&gt; ''C''.
* ''C'' is naturally a [[Riemannian symmetric space]] isomorphic to ''G'' / ''K'' where ''G'' = Aut&lt;sub&gt;0&lt;/sub&gt; ''C''. The Cartan involution is defined by σ(''g'')=(''g''*)&lt;sup&gt;−1&lt;/sup&gt;, so that ''K'' = ''G'' ∩ O(V).

==Spectral decomposition in a Euclidean Jordan algebra==
[[File:Jordan,Pascual 1963 Kopenhagen.jpg|thumb|120px|[[Pascual Jordan]]]]
[[File:JohnvonNeumann-LosAlamos.gif|thumb|120px|[[John von Neumann]]]]
[[File:Wigner.jpg|thumb|120px|[[Eugene Wigner]]]]
{{see also|Formally real Jordan algebra}}
In their classic paper, {{harvtxt|Jordan|von Neumann|Wigner|1934}} studied and completely classified a class of finite-dimensional Jordan algebras, that are now called either '''Euclidean Jordan algebras''' or '''formally real Jordan algebras'''.

===Definition===
Let ''E'' be a finite-dimensional real vector space with a symmetric bilinear product operation

:&lt;math&gt;\displaystyle{E\times E \rightarrow E,\,\,\, a,b\mapsto ab =ba,}&lt;/math&gt;

with an identity element 1 such that ''a''1 = ''a'' for ''a'' in ''A'' and a real inner product (''a'',''b'') for which the multiplication operators ''L''(''a'') defined by ''L''(''a'')''b'' = ''ab'' on ''E'' are self-adjoint and satisfy the Jordan relation

:&lt;math&gt;\displaystyle{L(a)L(a^2)=L(a^2)L(a).}&lt;/math&gt;

As will turn out below, the condition on adjoints can be replaced by the equivalent condition that
the trace form Tr ''L''(''ab'') defines an inner product. The trace form has the advantage of being manifestly invariant under automorphisms of the Jordan algebra, which is thus a closed subgroup of O(''E'') and thus a compact Lie group. In practical examples, however, it is often easier to produce an inner product for which the ''L''(''a'') are self-adjoint than verify directly positive-definiteness of the trace form. (The equivalent original condition of Jordan, von Neumann and Wigner was that if a sum of squares of elements vanishes then each of those elements has to vanish.&lt;ref&gt;For a proof of equivalence see:
*{{harvnb|Koecher|1999|p=118}}, Theorem 12
*{{harvnb|Faraut|Koranyi|1994|pp=42,153–154}}&lt;/ref&gt;)

===Power associativity===
From the Jordan condition it follows that the Jordan algebra is [[Power associativity|'''power associative''']], i.e. the Jordan subalgebra generated by any single element ''a'' in ''E'' is actually an associative commutative algebra. Thus, defining ''a''&lt;sup&gt;''n''&lt;/sup&gt; inductively by ''a''&lt;sup&gt;''n''&lt;/sup&gt; = ''a'' (''a''&lt;sup&gt;''n''−1&lt;/sup&gt;), the following associativity relation holds:

:&lt;math&gt;\displaystyle{a^m a^n = a^{m+n},}&lt;/math&gt;

so the subalgebra can be identified with '''R'''[''a''], polynomials in ''a''. In fact [[Polarization of an algebraic form|polarizing]] of the Jordan relation—replacing ''a'' by ''a'' + ''tb'' and taking the coefficient of ''t''—yields

:&lt;math&gt;\displaystyle{2L(ab)L(a) + L(a^2)L(b)=2L(a)L(b)L(a) + L(a^2b).}&lt;/math&gt;

This identity implies that ''L''(''a''&lt;sup&gt;''m''&lt;/sup&gt;) is a polynomial in ''L''(''a'') and ''L''(''a''&lt;sup&gt;2&lt;/sup&gt;) for all ''m''. In fact, assuming the result for lower exponents than ''m'',

:&lt;math&gt;\displaystyle{a^2 a^{m-1} =a^{m-1}(a^2)=L(a^{m-1})L(a)a=L(a)L(a^{m-1})a=L(a)a^m=a^{m+1}.}&lt;/math&gt;

Setting ''b'' = ''a''&lt;sup&gt;''m'' – 1&lt;/sup&gt; in the polarized Jordan identity gives:

:&lt;math&gt;\displaystyle{L(a^{m+1})=2L(a^m)L(a)+L(a^2)L(a^{m-1})-2L(a)^2L(a^{m-1}),}&lt;/math&gt;

a [[recurrence relation]] showing inductively that ''L''(''a''&lt;sup&gt;''m'' + 1&lt;/sup&gt;) is a polynomial in ''L''(''a'') and ''L''(''a''&lt;sup&gt;2&lt;/sup&gt;).

Consequently, if power-associativity holds when the first exponent is  ≤ ''m'', then it also holds for ''m''+1 since

:&lt;math&gt;\displaystyle{L(a^{m+1})a^n=2L(a)L(a^m)a^n+ L(a^2)L(a^{m-1})a^n -2L(a)^2L(a^{m-1})a^n
=a^{m+n+1}.}&lt;/math&gt;

===Idempotents and rank===
An element ''e'' in ''E'' is called an [[idempotent]] if ''e''&lt;sup&gt;2&lt;/sup&gt; = ''e''. Two idempotents are said to be orthogonal if ''ef'' = 0. This is equivalent to orthogonality with respect to the inner product,  since (''ef'',''ef'') = (''e'',''f''). In this case ''g'' = ''e'' + ''f'' is also an idempotent. An idempotent ''g'' is called ''primitive'' or ''minimal'' if it cannot be written as a sum of non-zero orthogonal idempotents. If ''e''&lt;sub&gt;1&lt;/sub&gt;, ..., ''e''&lt;sub&gt;''m''&lt;/sub&gt; are pairwise orthogonal idempotents then their sum is also an idempotent and the algebra they generate consists of all linear combinations of the ''e''&lt;sub&gt;''i''&lt;/sub&gt;. It is an associative algebra. If ''e'' is an idempotent, then 1 − ''e'' is an orthogonal idempotent. An orthogonal set of idempotents with sum 1 is said to be a ''complete set'' or a ''partition of 1''. If each idempotent in the set is minimal it is called a ''Jordan frame''. Since the number of elements in any orthogonal set of idempotents is bounded by dim ''E'', Jordan frames exist. The maximal number of elements in a Jordan frame is called the '''rank''' ''r'' of ''E''.

===Spectral decomposition===
The spectral theorem states that any element ''a'' can be uniquely written as

:&lt;math&gt;\displaystyle{a=\sum \lambda_i e_i,}&lt;/math&gt;

where the idempotents ''e''&lt;sub&gt;''i''&lt;/sub&gt;'s are a partition of 1 and the λ&lt;sub&gt;''i''&lt;/sub&gt;, the ''eigenvalues'' of ''a'', are real and distinct. In fact let ''E''&lt;sub&gt;0&lt;/sub&gt; = '''R'''[a] and let ''T'' be the restriction of ''L''(''a'') to ''E''&lt;sub&gt;0&lt;/sub&gt;. ''T'' is self-adjoint and has 1 as a cyclic vector. So the [[commutant]] of ''T'' consists of polynomials in ''T'' (or ''a''). By the [[spectral theorem]] for self-adjoint operators,

:&lt;math&gt;\displaystyle{T=\sum \lambda_i P_i}&lt;/math&gt;

where the ''P''&lt;sub&gt;''i''&lt;/sub&gt; are orthogonal projections on ''E''&lt;sub&gt;0&lt;/sub&gt; with sum ''I'' and the λ&lt;sub&gt;''i''&lt;/sub&gt;'s are the distinct real eigenvalues of ''T''. Since the   ''P''&lt;sub&gt;''i''&lt;/sub&gt;'s commute with ''T'' and are self-adjoint, they are given by multiplication elements ''e''&lt;sub&gt;''i''&lt;/sub&gt; of  '''R'''[a] and thus form a partition of 1. Uniqueness follows because if ''f''&lt;sub&gt;''i''&lt;/sub&gt; is a partition of 1 and ''a'' = ∑ μ&lt;sub&gt;''i''&lt;/sub&gt; ''f''&lt;sub&gt;''i''&lt;/sub&gt;, then with ''p''(''t'')=∏ (''t'' - μ&lt;sub&gt;''j''&lt;/sub&gt;) and ''p''&lt;sub&gt;''i''&lt;/sub&gt; = ''p''/(''t'' − μ&lt;sub&gt;''i''&lt;/sub&gt;), ''f''&lt;sub&gt;''i''&lt;/sub&gt; = ''p''&lt;sub&gt;''i''&lt;/sub&gt;(''a'')/''p''&lt;sub&gt;''i''&lt;/sub&gt;(μ&lt;sub&gt;''i''&lt;/sub&gt;). So the ''f''&lt;sub&gt;''i''&lt;/sub&gt;'s are polynomials in ''a'' and uniqueness follows from uniqueness of the spectral decomposition of ''T''.

The spectral theorem implies that the rank is independent of the Jordan frame. For a Jordan frame with ''k'' minimal idempotents can be used to construct an element ''a'' with ''k'' distinct eigenvalues. As above the minimal polynomial ''p'' of ''a'' has degree ''k'' and '''R'''[''a''] has dimension ''k''. Its dimension is also the largest ''k'' such that ''F''&lt;sub&gt;''k''&lt;/sub&gt;(''a'') ≠ 0 where ''F''&lt;sub&gt;''k''&lt;/sub&gt;(''a'') is the determinant of a [[Gram matrix]]:

:&lt;math&gt;\displaystyle{F_k(a)=\det_{0\le m,n&lt; k} (a^m,a^n).}&lt;/math&gt;

So the rank ''r'' is the largest integer ''k'' for which ''F''&lt;sub&gt;''k''&lt;/sub&gt; is not identically zero on ''E''. In this case, as a non-vanishing polynomial, ''F''&lt;sub&gt;''r''&lt;/sub&gt; is non-zero on an open dense subset of ''E''. the ''regular elements''. Any other ''a'' is a limit of regular elements ''a''&lt;sup&gt;(''n'')&lt;/sup&gt;. Since the operator norm of ''L''(''x'') gives an equivalent norm on ''E'', a standard compactness argument shows that, passing to a subsequence if necessary, the spectral idempotents of the ''a''&lt;sup&gt;(''n'')&lt;/sup&gt; and their corresponding eigenvalues are convergent. The limit of Jordan frames is a Jordan frame, since a limit of non-zero idempotents yields a non-zero idempotent by continuity of the operator norm. It follows that every Jordan frame is made up of ''r'' minimal idempotents.

If ''e'' and ''f'' are orthogonal idempotents, the spectral theorem shows that ''e'' and ''f'' are polynomials in ''a'' = ''e'' − ''f'', so that ''L''(''e'') and ''L''(''f'') commute. This can be seen directly from the polarized Jordan identity which implies ''L''(''e'')''L''(''f'') = 2 ''L''(''e'')''L''(''f'')''L''(''e''). Commutativity follows by taking adjoints.

===Spectral decomposition for an idempotent===
If ''e'' is a non-zero idempotent then the eigenvalues of ''L''(''e'') can only be 0, 1/2 and 1, since taking ''a'' = ''b'' = ''e'' in the polarized Jordan identity yields

:&lt;math&gt;\displaystyle{2L(e)^3-3L(e)^2 +L(e)=0.}&lt;/math&gt;

In particular the operator norm of ''L''(''e'') is 1 and its trace is strictly positive.

There is a corresponding orthogonal eigenspace decomposition of ''E''

:&lt;math&gt;\displaystyle{E=E_0(e)\oplus E_{1/2}(e) \oplus E_1(e),}&lt;/math&gt;

where, for ''a'' in ''E'', ''E''&lt;sub&gt;λ&lt;/sub&gt;(''a'') denotes the λ-eigenspace of ''L''(''a''). In this decomposition ''E''&lt;sub&gt;1&lt;/sub&gt;(''e'') and ''E''&lt;sub&gt;0&lt;/sub&gt;(''e'') are Jordan algebras with identity elements ''e'' and 1 − ''e''. Their sum ''E''&lt;sub&gt;1&lt;/sub&gt;(''e'') ⊕ ''E''&lt;sub&gt;0&lt;/sub&gt;(''e'') is a direct sum of Jordan algebras in that any product between them is zero. It is the ''centralizer subalgebra'' of ''e'' and consists of all ''a'' such that ''L''(''a'') commutes with ''L''(''e''). The subspace ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''e'') is a module for the centralizer of ''e'', the ''centralizer module'', and the product of any two elements in it lies in the centralizer subalgebra. On the other hand, if

:&lt;math&gt;\displaystyle{U=8L(e)^2 -8L(e) +I,}&lt;/math&gt;

then ''U'' is self-adjoint equal to 1 on the centralizer algebra and −1 on the centralizer module. So ''U''&lt;sup&gt;2&lt;/sup&gt; = ''I'' and the properties above show that

:&lt;math&gt;\displaystyle{\sigma(x) = Ux}&lt;/math&gt;

defines an involutive Jordan algebra automorphism σ of ''E''.

:&lt;small&gt;In fact the Jordan algebra and module properties follow by replacing ''a'' and ''b'' in the polarized Jordan identity by ''e'' and ''a''. If ''ea'' = 0, this gives ''L''(''e'')''L''(''a'') = 2''L''(''e'')''L''(''a'')''L''(''e''). Taking adjoints it follows that ''L''(''a'') commutes with ''L''(''e''). Similarly if (1 − ''e'')''a'' = 0, ''L''(''a'') commutes with ''I'' − ''L''(''e'') and hence ''L''(''e''). This implies the Jordan algebra and module properties. To check that a product of elements in the module lies in the algebra, it is enough to check this for squares: but if ''L''(''e'')''a'' = ½ ''a'', then ''ea'' = ½ ''a'', so ''L''(''a'')&lt;sup&gt;2&lt;/sup&gt; + ''L''(''a''&lt;sup&gt;2&lt;/sup&gt;)''L''(''e'') = 2''L''(''a'')''L''(''e'')''L''(''a'') + ''L''(''a''&lt;sup&gt;2&lt;/sup&gt;''e''). Taking adjoints it follows that ''L''(''a''&lt;sup&gt;2&lt;/sup&gt;) commutes with ''L''(''e''), which implies the property for squares.&lt;/small&gt;

===Trace form===
The trace form is defined by

:&lt;math&gt;\displaystyle{\tau(a,b) = \mathrm{Tr}\, L(ab).}&lt;/math&gt;

It is an inner product since, for non-zero ''a'' = ∑ λ&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt;,

:&lt;math&gt;\displaystyle{\tau(a,a)=\sum \lambda_i^2 \mathrm{Tr}\,L(e_i) &gt; 0.}&lt;/math&gt;

The polarized Jordan identity can be polarized again by replacing ''a'' by ''a'' + ''tc'' and taking the coefficient of ''t''. A further anyisymmetrization in ''a'' and ''c'' yields:

:&lt;math&gt;\displaystyle{L(a(bc) -(ab)c)=[[L(a),L(b)],L(c)].}&lt;/math&gt;

Applying the trace to both sides

:&lt;math&gt;\displaystyle{\tau(a,bc)=\tau(ba,c),}&lt;/math&gt;

so that ''L''(''b'') is self-adjoint for the trace form.

==Simple Euclidean Jordan algebras==
[[File:Adolf Hurwitz.jpg|thumb|150px|[[Adolf Hurwitz]] (1855–1919), whose work on [[composition algebra]]s was published posthumously in 1923.]]
The classification of simple Euclidean Jordan algebras was accomplished by {{harvtxt|Jordan|von Neumann|Wigner|1934}}, with details of the one exceptional algebra provided in the article immediately following theirs by {{harvtxt|Albert|1934}}. Using the [[Peirce decomposition]], they reduced the problem to an algebraic problem involving [[Hurwitz's theorem (composition algebras)|multiplicative quadratic forms]] already solved by [[Adolf Hurwitz|Hurwitz]]. The presentation here, following {{harvtxt|Faraut|Koranyi|1994}}, using [[composition algebra]]s or '''Euclidean Hurwitz algebras,''' is a shorter version of the original derivation.

===Central decomposition===
If ''E'' is a Euclidean Jordan algebra an '''ideal''' ''F'' in ''E'' is a linear subspace closed under multiplication by elements of ''E'', i.e. ''F'' is invariant under the operators ''L''(''a'') for ''a'' in ''E''. If ''P'' is the orthogonal projection onto ''F'' it commutes with the operators ''L''(''a''), In particular ''F''&lt;sup&gt;⊥&lt;/sup&gt; = (''I'' − ''P'')''E'' is also an ideal and ''E'' = ''F'' ⊕ ''F''&lt;sup&gt;⊥&lt;/sup&gt;. Furthermore, if ''e'' = ''P''(1), then ''P'' = ''L''(''e''). In fact for ''a'' in ''E''

:&lt;math&gt;\displaystyle{ea=ae=L(a)P(1)=P(L(a)1)=P(a),}&lt;/math&gt;

so that ''ea'' = ''a'' for ''a'' in ''F'' and 0 for ''a'' in ''F''&lt;sup&gt;⊥&lt;/sup&gt;. In particular ''e'' and 1 − ''e'' are orthogonal idempotents with ''L''(''e'') = ''P'' and ''L''(1 − ''e'') = ''I'' − ''P''. ''e'' and 1 − ''e'' are the identities in the Euclidean Jordan algebras  ''F'' and ''F''&lt;sup&gt;⊥&lt;/sup&gt;. The idempotent ''e'' is ''central'' in ''E'', where the '''center''' of ''E'' is defined to be the set of all ''z'' such that ''L''(''z'') commutes with ''L''(''a'') for all ''a''. It forms a commutative associative subalgebra.

Continuing in this way ''E'' can be written as a direct sum of minimal ideals

:&lt;math&gt;\displaystyle{E=\oplus E_i.}&lt;/math&gt;

If ''P''&lt;sub&gt;''i''&lt;/sub&gt; is the projection onto ''E''&lt;sub&gt;''i''&lt;/sub&gt; and ''e''&lt;sub&gt;''i''&lt;/sub&gt; = ''P''&lt;sub&gt;''i''&lt;/sub&gt;(1) then ''P''&lt;sub&gt;''i''&lt;/sub&gt; = ''L''(''e''&lt;sub&gt;''i''&lt;/sub&gt;). The ''e''&lt;sub&gt;''i''&lt;/sub&gt;'s are orthogonal with sum 1 and are the identities in ''E''&lt;sub&gt;''i''&lt;/sub&gt;. Minimality forces ''E''&lt;sub&gt;''i''&lt;/sub&gt; to be '''simple''', i.e. to have no non-trivial ideals. For since ''L''(''e''&lt;sub&gt;''i''&lt;/sub&gt;) commutes with all ''L''(''a'')'s, any ideal ''F'' ⊂ ''E''&lt;sub&gt;''i''&lt;/sub&gt;
would be invariant under ''E'' since ''F'' = ''e''&lt;sub&gt;''i''&lt;/sub&gt;''F''. Such a decomposition into a direct sum of simple Euclidean algebras is unique. If ''E'' = ⊕ ''F''&lt;sub&gt;''j''&lt;/sub&gt; is another decomposition, then ''F''&lt;sub&gt;''j''&lt;/sub&gt;=⊕ e&lt;sub&gt;''i''&lt;/sub&gt;''F''&lt;sub&gt;''j''&lt;/sub&gt;. By minimality only one of the terms here is non-zero so equals ''F''&lt;sub&gt;''j''&lt;/sub&gt;. By minimality the corresponding ''E''&lt;sub&gt;''i''&lt;/sub&gt; equals ''F''&lt;sub&gt;''j''&lt;/sub&gt;, proving uniqueness.

In this way the classification of Euclidean Jordan algebras is reduced to that of simple ones. For a simple algebra ''E'' all inner products for which the operators ''L''(''a'') are self adjoint are proportional. Indeed, any other product has the form (''Ta'', ''b'') for some positive self-adjoint operator commuting with the ''L''(''a'')'s. Any non-zero eigenspace of ''T'' is an ideal in ''A'' and therefore by simplicity ''T'' must act on the whole of ''E'' as a positive scalar.

===List of all simple Euclidean Jordan algebras===

* Let ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''R''') be the space of real symmetric ''n'' by ''n'' matrices with inner product (''a'',''b'') = Tr ''ab'' and Jordan product ''a'' ∘ ''b'' = ½(''ab'' + ''ba''). Then ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''R''') is a simple Euclidean Jordan algebra of rank ''n'' for ''n'' ≥ 3.
* Let ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''C''') be the space of complex self-adjoint ''n'' by ''n'' matrices with inner product (''a'',''b'') = Re Tr ''ab''* and Jordan product ''a'' ∘ ''b'' = ½(''ab'' + ''ba''). Then ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''C''') is a simple Euclidean Jordan algebra of rank ''n'' ≥ 3.
* Let ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''H''') be the space of self-adjoint ''n'' by ''n'' matrices with entries in the [[quaternion]]s, inner product (''a'',''b'') = Re Tr ''ab''* and Jordan product ''a'' ∘ ''b'' = ½(''ab'' + ''ba''). Then ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''H''') is a simple Euclidean Jordan algebra of rank ''n'' ≥ 3.
* Let ''V'' be a finite dimensional real inner product space and set ''E'' = ''V'' ⊕ '''R''' with inner product (''u''⊕λ,''v''⊕μ) =(''u'',''v'') + λμ and product (u⊕λ)∘(v⊕μ)=( μ''u'' + λ''v'') ⊕ [(''u'',''v'') + λμ]. This is a Euclidean Jordan algebra of rank 2.
*The above examples in fact give all the simple Euclidean Jordan algebras, except for one exceptional case ''H''&lt;sub&gt;3&lt;/sub&gt;('''O'''), the self-adjoint matrices over the [[octonion]]s or [[Cayley number]]s, another rank 3 simple Euclidean Jordan algebra of dimension 27 (see below).

===Peirce decomposition===
{{see also|Peirce decomposition}}
Let ''E'' be a simple Euclidean Jordan algebra with inner product given by the trace form τ(''a'')= Tr ''L''(''a''). The proof that ''E'' has the above form rests on constructing an analogue of matrix units for a Jordan frame in ''E''. The following properties of idempotents hold in ''E''.

*An idempotent ''e'' is minimal in ''E'' if and only if ''E''&lt;sub&gt;1&lt;/sub&gt;(''e'') has dimension one (so equals '''R'''''e''). Moreover ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''e'') ≠ (0).  In fact the spectral projections of any element of ''E''&lt;sub&gt;1&lt;/sub&gt;(''e'') lie in ''E'' so if non-zero must equal ''e''. If the 1/2 eigenspace vanished then  ''E''&lt;sub&gt;1&lt;/sub&gt;(''e'') = '''R'''''e'' would be an ideal.
*If ''e'' and ''f'' are non-orthogonal minimal idempotents, then there is a period 2 automorphism σ of ''E'' such that σ''e''=''f'', so that ''e'' and ''f'' have the same trace.
*If ''e'' and ''f'' are orthogonal minimal idempotents then ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''e'') ∩ ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''f'') ≠ (0). Moreover, there is a period 2 automorphism σ of ''E'' such that σ''e''=''f'', so that ''e'' and ''f'' have the same trace, and for any ''a'' in this intersection, ''a''&lt;sup&gt;2&lt;/sup&gt; = ½ τ(''e'') |''a''|&lt;sup&gt;2&lt;/sup&gt; (''e'' + ''f'').
*All minimal idempotents in ''E'' are in the same orbit of the automorphism group so have the same trace τ&lt;sub&gt;0&lt;/sub&gt;.
*If ''e'', ''f'', ''g'' are three minimal orthogonal idempotents, then for ''a'' in ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''e'') ∩ ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''f'') and ''b'' in ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''f'') ∩ ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''g''), ''L''(''a'')&lt;sup&gt;2&lt;/sup&gt; ''b'' = ⅛ τ&lt;sub&gt;0&lt;/sub&gt; |''a''|&lt;sup&gt;2&lt;/sup&gt; ''b'' and |''ab''|&lt;sup&gt;2&lt;/sup&gt; =  ⅛ τ&lt;sub&gt;0&lt;/sub&gt; |''a''|&lt;sup&gt;2&lt;/sup&gt;|''b''|&lt;sup&gt;2&lt;/sup&gt;. Moreover, ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''e'') ∩ ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''f'') ∩ ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''g'') = (0).
*If ''e''&lt;sub&gt;''1''&lt;/sub&gt;, ..., ''e''&lt;sub&gt;''r''&lt;/sub&gt; and ''f''&lt;sub&gt;''1''&lt;/sub&gt;, ..., ''f''&lt;sub&gt;''r''&lt;/sub&gt; are Jordan frames in ''E'', then there is an automorphism α such that α''e''&lt;sub&gt;''i''&lt;/sub&gt; = ''f''&lt;sub&gt;''i''&lt;/sub&gt;.
*If (''e''&lt;sub&gt;''i''&lt;/sub&gt;) is a Jordan frame and ''E''&lt;sub&gt;''ii''&lt;/sub&gt; = ''E''&lt;sub&gt;1&lt;/sub&gt;(''e''&lt;sub&gt;''i''&lt;/sub&gt;) and ''E''&lt;sub&gt;''ij''&lt;/sub&gt; = ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''e''&lt;sub&gt;''i''&lt;/sub&gt;) ∩ ''E''&lt;sub&gt;1/2&lt;/sub&gt;(''e''&lt;sub&gt;''j''&lt;/sub&gt;), then ''E'' is the orthogonal direct sum the ''E''&lt;sub&gt;''ii''&lt;/sub&gt;'s and ''E''&lt;sub&gt;''ij''&lt;/sub&gt;'s. Since ''E'' is simple, the ''E''&lt;sub&gt;''ii''&lt;/sub&gt;'s are one-dimensional and the subspaces ''E''&lt;sub&gt;''ij''&lt;/sub&gt; are all non-zero for ''i'' ≠ ''j''.
*If ''a'' = ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; for some Jordan frame (''e''&lt;sub&gt;''i''&lt;/sub&gt;), then ''L''(''a'') acts as  α&lt;sub&gt;''i''&lt;/sub&gt; on ''E''&lt;sub&gt;''ii''&lt;/sub&gt; and (α&lt;sub&gt;''i''&lt;/sub&gt; + α&lt;sub&gt;''i''&lt;/sub&gt;)/2 on ''E''&lt;sub&gt;''ij''&lt;/sub&gt;.

===Reduction to Euclidean Hurwitz algebras===
{{Main article|Euclidean Hurwitz algebra}}
Let ''E'' be a simple Euclidean Jordan algebra. From the properties of the Peirce decomposition it follows that:

*If ''E'' has rank 2, then it has the form ''V'' ⊕ '''R''' for some inner product space ''V'' with Jordan product as described above.
*If ''E'' has rank ''r'' &gt; 2, then there is a non-associative unital algebra ''A'', associative if ''r'' &gt; 3, equipped with an inner product satisfying (ab,ab)= (a,a)(b,b) and such that ''E'' = ''H''&lt;sub&gt;''r''&lt;/sub&gt;(''A''). (Conjugation in ''A'' is defined by ''a''* = −a + 2(a,1)1.)

Such an algebra ''A'' is called a '''Euclidean Hurwitz algebra'''.  In ''A'' if  λ(''a'')''b'' =  ''ab'' and ρ(''a'')''b'' = ''ba'', then:

* the involution is an antiautomorphism, i.e. {{math|1=(''a b'')*=''b''* ''a''*}}
* {{math|1=''a a''* = ‖ ''a'' ‖&lt;sup&gt;2&lt;/sup&gt; 1 = ''a''* ''a''}}
* {{math|1= λ(''a''*) = λ(''a'')*}}, {{math|1=ρ(''a''*) = ρ(''a'')*}}, so that the involution on the algebra corresponds to taking [[adjoint operator|adjoints]]
* {{math|1=Re(''a b'') = Re(''b a'')}} if {{math|1=Re ''x'' = (''x'' + ''x''*)/2 = (''x'', 1)1}}
* {{math|1=Re(''a b'') ''c'' = Re ''a''(''b c'')}}
* {{math|1=λ(''a''&lt;sup&gt;2&lt;/sup&gt;) = λ(''a'')&lt;sup&gt;2&lt;/sup&gt;}}, {{math|1= ρ(''a''&lt;sup&gt;2&lt;/sup&gt;) = ρ(''a'')&lt;sup&gt;2&lt;/sup&gt;}}, so that {{mvar|A}} is an [[alternative algebra]].

By [[Hurwitz's theorem (normed division algebras)|Hurwitz's theorem]] ''A'' must be isomorphic to '''R''', '''C''', '''H''' or '''O'''. The first three are associative division algebras. The octonions do not form an associative algebra, so ''H''&lt;sub&gt;''r''&lt;/sub&gt;('''O''') can only give a Jordan algebra for ''r'' = 3. Because ''A'' is associative when ''A'' = '''R''', '''C''' or '''H''', it is immediate that ''H''&lt;sub&gt;''r''&lt;/sub&gt;(''A'') is a Jordan algebra for ''r'' ≥ 3. A separate argument, given originally by {{harvtxt|Albert|1934}}, is required to show that ''H''&lt;sub&gt;3&lt;/sub&gt;('''O''') with Jordan product ''a''∘''b'' = ½(''ab'' + ''ba'') satisfies the Jordan identity [''L''(''a''),''L''(''a''&lt;sup&gt;2&lt;/sup&gt;)] = 0. There is a later more direct proof using the [[Freudenthal diagonalization theorem]] due to {{harvtxt|Freudenthal|1951}}: he proved that given any matrix in the algebra ''H''&lt;sub&gt;''r''&lt;/sub&gt;('''A''') there is an algebra automorphism carrying the matrix onto a diagonal matrix with real entries; it is then straightforward to check that [''L''(''a''),''L''(''b'')] = 0 for real diagonal matrices.&lt;ref&gt;See:
*{{harvnb|Freudenthal|1985}}
*{{harvnb|Postnikov|1986}}
*{{harvnb|Faraut|Koranyi|1994}}
*{{harvnb|Springer|Veldkamp|2000}}&lt;/ref&gt;

===Exceptional and special Euclidean Jordan algebras===
The '''exceptional''' Euclidean Jordan algebra ''E''= ''H''&lt;sub&gt;3&lt;/sub&gt;('''O''') is called the [[Albert algebra]]. The Cohn–Shirshov theorem implies that it cannot be generated by two elements (and the identity). This can be seen directly. For by Freudenthal's diagonalization theorem one element ''X'' can be taken to be a diagonal matrix with real entries and the other  ''Y'' to be orthogonal to the Jordan subalgebra generated by ''X''. If all the diagonal entries of ''X'' are distinct, the Jordan subalgebra generated by ''X'' and ''Y'' is generated by the diagonal matrices and three elements

:&lt;math&gt;\displaystyle{Y_1=\begin{pmatrix} 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; y_1\\0 &amp; y_1^* &amp; 0\end{pmatrix},\,\,\,
Y_2=\begin{pmatrix} 0 &amp; 0 &amp; y_2^*\\ 0 &amp; 0 &amp; 0\\y_2 &amp; 0 &amp; 0\end{pmatrix},\,\,\,
Y_3=\begin{pmatrix} 0 &amp; y_3 &amp; 0\\ y_3^* &amp; 0 &amp; 0\\0 &amp; 0 &amp; 0\end{pmatrix}.}&lt;/math&gt;

It is straightforward to verify that the real linear span of the diagonal matrices, these matrices and similar matrices with real entries form a unital Jordan subalgebra. If the diagonal entries of ''X'' are not distinct, ''X'' can be taken to be the primitive idempotent ''e''&lt;sub&gt;1&lt;/sub&gt; with diagonal entries 1, 0 and 0. The analysis in {{harvtxt|Springer|Veldkamp|2000}} then shows that the unital Jordan subalgebra generated by ''X'' and ''Y'' is proper. Indeed, if, if 1 − ''e''&lt;sub&gt;1&lt;/sub&gt; is the sum of two primitive idempotents in the subalgebra, then, after applying an automorphism of ''E'' if necessary, the subalgebra will be generated by the diagonal matrices and a matrix orthogonal to the diagonal matrices. By the previous argument it will be proper. If 1 - ''e''&lt;sub&gt;1&lt;/sub&gt; is a primitive idempotent, the subalgebra must be proper, by the properties of the rank in ''E''.

A Euclidean algebra is said to be ''special'' if its central decomposition contains no copies of the Albert algebra. Since the Albert algebra cannot be generated by two elements, it follows that a Euclidean Jordan algebra generated by two elements is special. This is the '''[[Shirshov–Cohn theorem]]''' for Euclidean Jordan algebras.&lt;ref&gt;See:
*{{harvnb|Freudenthal|1985}}
*{{harvnb|Jacobson|1968}}
*{{harvnb|Zhevlakov|Slinko|Shestakov|Shirshov|1982}}
*{{harvnb|Hanche-Olsen|Størmer|1984}}
*{{harvnb|Springer|Veldkamp|2000|pp=117–141}}&lt;/ref&gt;

The classification shows that each non-exceptional simple Euclidean Jordan algebra is a subalgebra of some ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''R'''). The same is therefore true of any special algebra.

On the other hand, as {{harvtxt|Albert|1934}} showed, the Albert algebra ''H''&lt;sub&gt;3&lt;/sub&gt;('''O''') cannot be realized as a subalgebra of ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''R''') for any ''n''.&lt;ref&gt;See:
*{{harvnb|Hanche-Olsen|Størmer|1984|pp=58–59}}
*{{harvnb|Faraut|Koranyi|1994|pp=74–75}}
*{{harvnb|Jacobson|1968}}
*{{harvnb|Clerc|1992|pp=49–52}}
&lt;/ref&gt;

Indeed, let π is a real-linear map of ''E'' = ''H''&lt;sub&gt;3&lt;/sub&gt;('''O''') into the self-adjoint operators on ''V'' = '''R'''&lt;sup&gt;''n''&lt;/sup&gt; with π(''ab'') = ½(π(''a'')π(''b'') + π(''b'')π(''a'')) and π(1) = ''I''. If ''e''&lt;sub&gt;1&lt;/sub&gt;, ''e''&lt;sub&gt;2&lt;/sub&gt;, ''e''&lt;sub&gt;3&lt;/sub&gt; are the diagonal minimal idempotents then ''P''&lt;sub&gt;''i''&lt;/sub&gt; = π(''e''&lt;sub&gt;''i''&lt;/sub&gt; are mutually orthogonal projections on ''V'' onto orthogonal subspaces ''V''&lt;sub&gt;''i''&lt;/sub&gt;. If ''i'' ≠ ''j'', the elements ''e''&lt;sub&gt;''ij''&lt;/sub&gt; of ''E'' with 1 in the (''i'',''j'') and (''j'',''i'') entries and 0 elsewhere satisfy ''e''&lt;sub&gt;''ij''&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; = ''e''&lt;sub&gt;''i''&lt;/sub&gt; + ''e''&lt;sub&gt;''j''&lt;/sub&gt;. Moreover, ''e''&lt;sub&gt;''ij''&lt;/sub&gt;''e''&lt;sub&gt;''jk''&lt;/sub&gt; = ½ ''e''&lt;sub&gt;''ik''&lt;/sub&gt; if ''i'', ''j'' and ''k'' are distinct. The operators ''T''&lt;sub&gt;''ij''&lt;/sub&gt; are zero on ''V''&lt;sub&gt;''k''&lt;/sub&gt; (''k'' ≠ ''i'', ''j'') and restrict to involutions on ''V''&lt;sub&gt;''i''&lt;/sub&gt; ⊕ ''V''&lt;sub&gt;''j''&lt;/sub&gt; interchanging ''V''&lt;sub&gt;''i''&lt;/sub&gt; and ''V''&lt;sub&gt;''j''&lt;/sub&gt;. Letting ''P''&lt;sub&gt;''ij''&lt;/sub&gt; = ''P''&lt;sub&gt;''i''&lt;/sub&gt; ''T''&lt;sub&gt;''ij''&lt;/sub&gt; ''P''&lt;sub&gt;''j''&lt;/sub&gt; and setting ''P''&lt;sub&gt;''ii''&lt;/sub&gt; = ''P''&lt;sub&gt;''i''&lt;/sub&gt;, the (''P''&lt;sub&gt;''ij''&lt;/sub&gt;) form a system of [[matrix unit]]s on ''V'', i.e. ''P''&lt;sub&gt;''ij''&lt;/sub&gt;* = ''P''&lt;sub&gt;''ji''&lt;/sub&gt;, ∑ ''P''&lt;sub&gt;''ii''&lt;/sub&gt; = ''I'' and ''P''&lt;sub&gt;''ij''&lt;/sub&gt;''P''&lt;sub&gt;''km''&lt;/sub&gt; = δ&lt;sub&gt;''jk''&lt;/sub&gt; ''P''&lt;sub&gt;''im''&lt;/sub&gt;. Let ''E''&lt;sub&gt;''i''&lt;/sub&gt; and ''E''&lt;sub&gt;''ij''&lt;/sub&gt; be the subspaces of the Peirce decomposition of ''E''. For ''x'' in '''O''', set π&lt;sub&gt;''ij''&lt;/sub&gt; =  ''P''&lt;sub&gt;''ij''&lt;/sub&gt; π(x''e''&lt;sub&gt;''ij''&lt;/sub&gt;), regarded as an operator on ''V''&lt;sub&gt;''i''&lt;/sub&gt;. This does not depend on ''j'' and for ''x'', ''y'' in '''O'''

:&lt;math&gt;\displaystyle{\pi_{ij}(xy) =\pi_{ij}(x)\pi_{ij}(y),\,\,\, \pi_{ij}(1)= I.}&lt;/math&gt;

Since every ''x'' in '''O''' has a right inverse ''y'' with ''xy'' = 1, the map π&lt;sub&gt;''ij''&lt;/sub&gt; is injective. On the other hand, it is an algebra homomorphism from the nonassociative algebra '''O''' into the associative algebra End ''V''&lt;sub&gt;''i''&lt;/sub&gt;, a contradiction.&lt;ref&gt;{{harvnb|Clerc|1992|pp=49–52}}&lt;/ref&gt;

==Positive cone in a Euclidean Jordan algebra==
[[File:Max Koecher 2.jpeg|thumb|150px|[[Max Koecher]] pioneered the use of Jordan algebras in studying symmetric spaces]]

===Definition===
When (''e''&lt;sub&gt;''i''&lt;/sub&gt;) is a partition of 1 in a Euclidean Jordan algebra ''E'', the self-adjoint operators L(''e''&lt;sub&gt;''i''&lt;/sub&gt;) commute and there is a decomposition into simultaneous eigenspaces. If ''a'' = ∑ λ&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; the eigenvalues of ''L''(''a'') have the form ∑ ε&lt;sub&gt;''i''&lt;/sub&gt; λ&lt;sub&gt;''i''&lt;/sub&gt; is 0, 1/2 or 1. The ''e''&lt;sub&gt;''i''&lt;/sub&gt; themselves give the eigenvalues λ&lt;sub&gt;''i''&lt;/sub&gt;. In particular an element ''a'' has non-negative spectrum if and only if ''L''(''a'') has non-negative spectrum. Moreover, ''a'' has positive spectrum if and only if ''L''(''a'') has positive spectrum. For if ''a'' has positive spectrum, ''a'' - ε1 has non-negative spectrum for some ε &gt; 0.

The '''positive cone''' ''C'' in ''E'' is defined to be the set of elements ''a'' such that ''a'' has positive spectrum. This condition is equivalent to the operator ''L''(''a'') being a [[positive operator|positive]] self-adjoint operator on ''E''.

*''C'' is a convex cone in ''E'' because positivity of a self-adjoint operator ''T''— the property that its eigenvalues be strictly positive—is equivalent to (''Tv'',''v'') &gt; 0 for all ''v'' ≠ 0.
*''C'' is an open because the positive matrices are open in the self-adjoint matrices and ''L'' is a continuous map: in fact, if the lowest eigenvalue of ''T'' is ε &gt;0, then ''T'' + ''S'' is positive whenever ||''S''|| &lt; ε.
*The closure of ''C'' consists of all ''a'' such that ''L''(''a'') is non-negative or equivalently ''a'' has non-negative spectrum. From the elementary properties of convex cones, ''C'' is the interior of its closure and is a proper cone. The elements in the closure of ''C'' are precisely the square of elements in ''E''.
*''C'' is self-dual. In fact the elements of the closure of ''C'' are just set of all squares ''x''&lt;sup&gt;2&lt;/sup&gt; in ''E'', the dual cone is given by all ''a'' such that (''a'',''x''&lt;sup&gt;2&lt;/sup&gt;) &gt; 0. On the other hand, (''a'',''x''&lt;sup&gt;2&lt;/sup&gt;) = (''L''(''a'')''x'',''x''), so this is equivalent to the positivity of ''L''(''a'').&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|pp=46–49}}&lt;/ref&gt;

===Quadratic representation===
To show that the positive cone ''C'' is homogeneous, i.e. has a transitive group of automorphisms, a generalization of the quadratic action of self-adjoint matrices on themselves given by ''X'' ↦ ''YXY'' has to be defined. If ''Y'' is invertible and self-adjoint, this map is invertible and carries positive operators onto positive operators.

For ''a'' in ''E'', define an endomorphism of ''E'', called the '''[[quadratic representation]]''', by&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|pp=32–35}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{Q(a)=2L(a)^2 -L(a^2).}&lt;/math&gt;

Note that for self-adjoint matrices ''L''(''X'')''Y'' = ½(''XY'' + ''YX''), so that ''Q''(''X'')''Y'' = ''XYX''.

An element ''a'' in ''E'' is called ''invertible'' if it is invertible in '''R'''[''a'']. If ''b'' denotes the inverse, then the spectral decomposition of ''a'' shows that ''L''(''a'') and ''L''(''b'') commute.

In fact ''a'' is invertible if and only if ''Q''(''a'') is invertible. In that case

{{quote box|align=left|::&lt;math&gt;\displaystyle{Q(a)^{-1}a=a^{-1},\,\,\, Q(a^{-1})=Q(a)^{-1}.}&lt;/math&gt;}}
{{Clear}}
Indeed, if ''Q''(''a'') is invertible it carries '''R'''[''a''] onto itself. On the other hand, ''Q''(''a'')1 = ''a''&lt;sup&gt;2&lt;/sup&gt;, so

:&lt;math&gt;\displaystyle{(Q(a)^{-1} a)a=a Q(a)^{-1} a=L(a)Q(a)^{-1}a=Q(a)^{-1}a^2 =1.}&lt;/math&gt;

Taking ''b'' = ''a''&lt;sup&gt;−1&lt;/sup&gt; in the polarized Jordan identity, yields

:&lt;math&gt;\displaystyle{Q(a)L(a^{-1})=L(a).}&lt;/math&gt;

Replacing ''a'' by its inverse, the relation follows if ''L''(''a'') and ''L''(''a''&lt;sup&gt;−1&lt;/sup&gt;) are invertible. If not it holds for ''a'' + ε1 with ε arbitrarily small and hence also in the limit.

{{quote box|align=left|*If ''a'' and ''b'' are invertible then so is ''Q''(''a'')''b'' and it satisfies the inverse identity:

::&lt;math&gt;\displaystyle{(Q(a)b)^{-1}=Q(a^{-1})b^{-1}.}&lt;/math&gt;

*The quadratic representation satisfies the following fundamental identity:

::&lt;math&gt;\displaystyle{Q(Q(a)b)=Q(a)Q(b)Q(a).}&lt;/math&gt;

*In particular, taking ''b'' to be non-negative powers of ''a'', it follows by induction that

::&lt;math&gt;\displaystyle{Q(a^m)=Q(a)^m.}&lt;/math&gt;}}
{{Clear}}
These identities are easy to prove in a finite-dimensional (Euclidean) Jordan algebra (see below) or in a [[special Jordan algebra]], i.e. the Jordan algebra defined by a unital associative algebra.&lt;ref&gt;
See:
*{{harvnb|Koecher|1999|pp=72–76}}
*{{harvnb|Faraut|Koranyi|pp=32–34}}&lt;/ref&gt; They are valid in any Jordan algebra. This was conjectured by [[Nathan Jacobson|Jacobson]] and proved in {{harvtxt|Macdonald|1960}}: [[Ian G. Macdonald|Macdonald]] showed that if a polynomial identity in three variables, linear in the third, is valid in any special Jordan algebra, then it holds in all Jordan algebras.&lt;ref&gt;See:
*{{harvnb|Jacobson|1968|pp=40–47,52}}
*{{harvnb|Hanche-Olson|Størmer|1984|pp=36–44}}
&lt;/ref&gt;

In fact for ''c'' in ''A'' and ''F''(''a'') a function on ''A'' with values in End ''A'', let
''D''&lt;sub&gt;''c''&lt;/sub&gt;''F''(''a'') be the derivative at ''t'' = 0 of ''F''(''a'' + ''tc''). Then

:&lt;math&gt;\displaystyle{c=D_c(Q(a)a^{-1})=2[(L(a)L(c)+L(c)L(a)-L(ac))a^{-1}] +Q(a)D_c(a^{-1})=2c +Q(a)D_c(a^{-1}).}&lt;/math&gt;

The expression in square brackets simplifies to ''c'' because ''L''(''a'') commutes with ''L''(''a''&lt;sup&gt;−1&lt;/sup&gt;).

Thus

{{quote box|align=left|::&lt;math&gt;\displaystyle{D_c(a^{-1})= - Q(a)^{-1}c.}&lt;/math&gt;}}
{{Clear}}
Applying ''D''&lt;sub&gt;''c''&lt;/sub&gt; to ''L''(''a''&lt;sup&gt;−1&lt;/sup&gt;)''Q''(''a'') = ''L''(''a'') and acting on ''b'' = ''c''&lt;sup&gt;−1&lt;/sup&gt; yields

:&lt;math&gt;\displaystyle{(Q(a)b)(Q(a^{-1})b^{-1})=1.}&lt;/math&gt;

On the other hand, ''L''(''Q''(''a'')''b'') is invertible on an open dense set where ''Q''(''a'')''b'' must also be invertible with

:&lt;math&gt;\displaystyle{(Q(a)b)^{-1}=Q(a^{-1})b^{-1}.}&lt;/math&gt;

Taking the derivative ''D''&lt;sub&gt;''c''&lt;/sub&gt; in the variable ''b'' in the expression above gives

:&lt;math&gt;\displaystyle{-Q(Q(a)b)^{-1}Q(a)c =-Q(a)^{-1}Q(b)^{-1}c.}&lt;/math&gt;

This yields the fundamental identity for a dense set of invertible elements, so it follows in general by continuity. The fundamental identity implies that ''c'' = ''Q''(''a'')''b'' is invertible if ''a'' and ''b'' are invertible and gives a formula for the inverse of ''Q''(''c''). Applying it to ''c'' gives the inverse identity in full generality.

Finally it can be verified immediately from the definitions that, if ''u'' = 1 − 2''e'' for some idempotent ''e'', then ''Q''(''u'') is the period 2 automorphism constructed above for the centralizer algebra and module of ''e''.

===Homogeneity of positive cone===
{{quote box|align=left|'''If''' '''''a''''' '''is an invertible operator and''' '''''b''''' '''is in the positive cone''' '''''C''''', '''then so is''' '''''Q'''''('''''a''''')'''''b'''''.}}
{{Clear}}
The proof of this relies on elementary continuity properties of eigenvalues of self-adjoint operators.&lt;ref&gt;See:
*{{harvnb|Koecher|1999|p=111}}
*{{harvnb|Hanche-Olsen|Størmer|1984|p=83}}
*{{harvnb|Farat|Koranyi|1994|p=48}}
&lt;/ref&gt;

Let ''T''(''t'') (α ≤ ''t'' ≤ β) be a continuous family of self-adjoint operators on ''E'' with ''T''(α) positive and ''T''(β) having a negative eiegenvalue. Set ''S''(''t'')= –''T''(''t'') + ''M'' with ''M'' &gt; 0 chosen so large that ''S''(''t'') is positive for all ''t''. The operator norm ||''S''(''t'')|| is continuous. It is less than ''M'' for ''t'' = α and greater than ''M'' for ''t'' = β. So for some α &lt; ''s'' &lt; β, ||''S''(''s'')|| = M and there is a vector ''v'' ≠ 0 such that ''S''(''s'')''v'' = ''Mv''. In particular ''T''(''s'')''v'' = 0, so that ''T''(''s'') is not invertible.

Suppose that ''x'' = ''Q''(''a'')''b'' does not lie in ''C''. Let ''b''(''t'') = (1 − ''t'') + ''tb'' with 0 ≤ ''t'' ≤ 1. By convexity ''b''(''t'') lies in ''C''. Let ''x''(''t'') = ''Q''(''a'')''b''(''t'') and ''X''(''t'') = ''L''(''x''(''t'')). If ''X''(''t'') is invertible for all ''t'' with 0 ≤ ''t'' ≤ 1, the eigenvalue argument gives a contradiction since it is positive at ''t'' = 0 and has negative eigenvalues at ''t'' = 1. So ''X''(''s'') has a zero eigenvalue for some ''s'' with 0 &lt; ''s'' ≤ 1: ''X''(''s'')''w'' = 0 with ''w'' ≠ 0. By the properties of the quadratic representation, ''x''(''t'') is invertible for all ''t''. Let ''Y''(''t'') = ''L''(''x''(''t'')&lt;sup&gt;2&lt;/sup&gt;). This is a positive operator since ''x''(''t'')&lt;sup&gt;2&lt;/sup&gt; lies in ''C''. Let ''T''(''t'') = ''Q''(''x''(''t'')), an invertible self-adjoint operator by the invertibility of ''x''(''t'').  On the other hand, ''T''(''t'') = 2''X''(''t'')&lt;sup&gt;2&lt;/sup&gt; - ''Y''(''t''). So (''T''(''s'')''w'',''w'') &lt; 0 since ''Y''(''s'') is positive and ''X''(''s'')''w'' = 0. In particular ''T''(''s'') has some negative eigenvalues. On the other hand, the operator ''T''(0) = ''Q''(''a''&lt;sup&gt;2&lt;/sup&gt;) = ''Q''(''a'')&lt;sup&gt;2&lt;/sup&gt; is positive. By the eigenvalue argument, ''T''(''t'') has eigenvalue 0 for some ''t'' with 0 &lt; ''t'' &lt; ''s'', a contradiction.

It follows that the linear operators ''Q''(''a'') with ''a'' invertible, and their inverses, take the cone ''C'' onto itself. Indeed, the inverse of ''Q''(''a'') is just ''Q''(''a''&lt;sup&gt;−1&lt;/sup&gt;). Since ''Q''(''a'')1 = ''a''&lt;sup&gt;2&lt;/sup&gt;, there is thus a transitive group of symmetries:

{{quote box|align=left|'''''C''''' '''is a symmetric cone.'''}}
{{Clear}}

==Euclidean Jordan algebra of a symmetric cone==

===Construction===
Let ''C'' be a symmetric cone in the Euclidean space ''E''. As above, Aut ''C'' denotes the closed subgroup of GL(''E'') taking ''C'' (or equivalently its closure) onto itself. Let ''G'' = Aut&lt;sub&gt;0&lt;/sub&gt; ''C'' be its identity component. ''K'' = ''G'' ∩ O(''E''). It is a maximal compact subgroup of ''G'' and the stabilizer of a point ''e'' in ''C''. It is connected. The group ''G'' is invariant under taking adjoints. Let σ''g'' =(''g''*)&lt;sup&gt;−1&lt;/sup&gt;,  period 2 automorphism. Thus ''K'' is the fixed point subgroup of σ. Let &lt;math&gt;\mathfrak{g}&lt;/math&gt; be the Lie algebra of ''G''. Thus σ induces an involution of &lt;math&gt;\mathfrak{g}&lt;/math&gt; and hence a ±1 eigenspace decomposition

:&lt;math&gt;\displaystyle{\mathfrak{g}=\mathfrak{k} \oplus \mathfrak{p},}&lt;/math&gt;

where &lt;math&gt;\mathfrak{k}&lt;/math&gt;, the +1 eigenspace, is the Lie algebra of ''K'' and &lt;math&gt;\mathfrak{p}&lt;/math&gt; is the −1 eigenspace. Thus &lt;math&gt;\mathfrak{p}&lt;/math&gt;⋅''e'' is an affine subspace of dimension dim &lt;math&gt;\mathfrak{p}&lt;/math&gt;. Since ''C'' = ''G''/''K'' is an open subspace of ''E'', it follows that dim ''E'' = dim &lt;math&gt;\mathfrak{p}&lt;/math&gt; and hence &lt;math&gt;\mathfrak{p}&lt;/math&gt;⋅''e'' = ''E''. For ''a'' in ''E'' let ''L''(''a'') be the unique element of  &lt;math&gt;\mathfrak{p}&lt;/math&gt; such that ''L''(''a'')''e'' = ''a''. Define
''a'' ∘ ''b'' = ''L''(''a'')''b''. Then ''E'' with its Euclidean structure and this bilinear product is a Euclidean Jordan algebra with identity 1 = ''e''. The convex cone coincides ''C'' with the positive cone of ''E''.&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|pp=49–50}}&lt;/ref&gt;

Since the elements of  &lt;math&gt;\mathfrak{p}&lt;/math&gt; are self-adjoint, ''L''(''a'')*  = ''L''(''a''). The product is commutative since
[&lt;math&gt;\mathfrak{p}&lt;/math&gt;, &lt;math&gt;\mathfrak{p}&lt;/math&gt;] ⊆ &lt;math&gt;\mathfrak{k}&lt;/math&gt; annihilates ''e'', so that ''ab'' = ''L''(''a'')''L''(''b'')''e'' = ''L''(''b'')''L''(''a'')''e'' = ''ba''. It remains to check the Jordan identity [''L''(''a''),''L''(''a''&lt;sup&gt;2&lt;/sup&gt;)] = 0.

The [[associator]] is given by [''a'',''b'',''c''] = [''L''(''a''),''L''(''c'')]''b''. Since [''L''(''a''),''L''(''c'')] lies in
&lt;math&gt;\mathfrak{k}&lt;/math&gt; it follows that [[''L''(''a''),''L''(''c'')],''L''(''b'')] = ''L''([''a'',''b'',''c'']). Making both sides act on ''c'' yields

:&lt;math&gt;\displaystyle{[a,b^2,c] = 2[a,b,c]b.}&lt;/math&gt;

On the other hand,

:&lt;math&gt;\displaystyle{([b^2,a,b],c)=(b^2(ba)-b(b^2a),c) =-(b^2,[a,b,c])}&lt;/math&gt;

and likewise

:&lt;math&gt;\displaystyle{([b^2,a,b],c)=(b,[a,b^2,c]).}&lt;/math&gt;

Combining these expressions gives

:&lt;math&gt;\displaystyle{([b^2,a,b],c) =0,}&lt;/math&gt;

which implies the Jordan identity.

Finally the positive cone of ''E'' coincides with ''C''. This depends on the fact that in any Euclidean Jordan algebra ''E''

:&lt;math&gt;\displaystyle{Q(e^a)=e^{2L(a)}.}&lt;/math&gt;

In fact ''Q''(''e''&lt;sup&gt;''a''&lt;/sup&gt;) is a positive operator,
''Q''(''e''&lt;sup&gt;''ta''&lt;/sup&gt;) is a one-parameter group of positive operators: this follows by continuity for rational ''t'', where it is a consequence of the behaviour of powers So it has the form exp ''tX'' for some self-adjoint operator ''X''. Taking the derivative at 0 gives ''X'' = 2''L''(''a'').

Hence the positive cone is given by all elements

:&lt;math&gt;\displaystyle{e^{2a} =Q(e^{a})1= e^{2L(a)}1 = e^X\cdot 1,}&lt;/math&gt;

with ''X'' in &lt;math&gt;\mathfrak{p}&lt;/math&gt;. Thus the positive cone of ''E'' lies inside ''C''. Since both are self-dual,
they must coincide.

===Automorphism groups and trace form===
Let ''C'' be the positive cone in a simple Euclidean Jordan algebra ''E''. Aut ''C'' is the closed subgroup of GL(''E'') taking ''C'' (or its closure) onto itself. Let ''G'' = Aut&lt;sub&gt;0&lt;/sub&gt; ''C'' be the identity component of Aut ''C'' and let ''K'' be the closed subgroup of ''G'' fixing 1. From the group theoretic properties of cones, ''K'' is a connected compact subgroup of ''G'' and equals the identity component of the compact Lie group Aut ''E''. Let &lt;math&gt;\mathfrak{g}&lt;/math&gt; and &lt;math&gt;\mathfrak{k}&lt;/math&gt; be the Lie algebras of ''G'' and ''K''. ''G'' is closed under taking adjoints and ''K'' is the fixed point subgroup of the period 2 automorphism σ(''g'') = (''g''*)&lt;sup&gt;−1&lt;/sup&gt;. Thus ''K'' = ''G'' ∩ SO(''E'').  Let &lt;math&gt;\mathfrak{p}&lt;/math&gt; be the −1 eigenspace of σ.

*&lt;math&gt;\mathfrak{k}&lt;/math&gt; consists of derivations of ''E'' that are skew-adjoint for the inner product defined by the trace form.
*[[''L''(''a''),''L''(''c'')],''L''(''b'')] = ''L''([''a'',''b'',''c'']).
*If ''a'' and ''b'' are in ''E'', then ''D'' = [''L''(''a''),''L''(''b'')] is a derivation of ''E'', so lies in &lt;math&gt;\mathfrak{k}&lt;/math&gt;. These derivations span  &lt;math&gt;\mathfrak{k}&lt;/math&gt;.
* If ''a'' is in ''C'', then ''Q''(''a'') lies in ''G''.
*''C'' is the connected component of the open set of invertible elements of ''E'' containing 1. It consists of exponentials of elements of ''E'' and the exponential map gives a diffeomorphism of ''E'' onto ''C''.
* The map ''a'' ↦ ''L''(''a'') gives an isomorphism of ''E'' onto &lt;math&gt;\mathfrak{p}&lt;/math&gt; and ''e''&lt;sup&gt;''L''(''a'')&lt;/sup&gt; = ''Q''(''e''&lt;sup&gt;''a''/2&lt;/sup&gt;). This space of such exponentials coincides with ''P'' the positive self-adjoint elements in ''G''.
* For ''g'' in ''G'' and ''a'' in ''E'', ''Q''(''g''(''a'')) = ''g'' ''Q''(''a'') ''g''*.

===Cartan decomposition===
* ''G'' = ''P'' ⋅ ''K'' = ''K'' ⋅ ''P'' and the decomposition ''g'' = ''pk'' corresponds to the [[polar decomposition]] in GL(''E'').
* If (''e''&lt;sub&gt;''i''&lt;/sub&gt;) is a Jordan frame in ''E'', then the subspace &lt;math&gt;\mathfrak{a}&lt;/math&gt; of &lt;math&gt;\mathfrak{p}&lt;/math&gt; spanned by ''L''(''e''&lt;sub&gt;''i''&lt;/sub&gt;) is maximal Abelian in &lt;math&gt;\mathfrak{p}&lt;/math&gt;. ''A'' = exp &lt;math&gt;\mathfrak{a}&lt;/math&gt; is the Abelian subgroup of operators ''Q''(''a'') where ''a'' = Σ λ&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; with λ&lt;sub&gt;''i''&lt;/sub&gt; &gt; 0. ''A'' is closed in ''P'' and hence ''G''. If ''b'' =Σ μ&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; with μ&lt;sub&gt;''i''&lt;/sub&gt; &gt; 0, then ''Q''(''ab'')=''Q''(''a'')''Q''(''b'').
* &lt;math&gt;\mathfrak{p}&lt;/math&gt; and ''P'' are the union of the ''K'' translates of &lt;math&gt;\mathfrak{a}&lt;/math&gt; and ''A''.

===Iwasawa decomposition for cone===
If ''E'' has Peirce decomposition relative to the Jordan frame (''e''&lt;sub&gt;''i''&lt;/sub&gt;)

:&lt;math&gt;\displaystyle{E=\bigoplus_{i\le j} E_{ij},}&lt;/math&gt;

then  &lt;math&gt;\mathfrak{a}&lt;/math&gt; is diagonalized by this decomposition with ''L''(''a'') acting as (α&lt;sub&gt;''i''&lt;/sub&gt; + α&lt;sub&gt;''j''&lt;/sub&gt;)/2 on ''E''&lt;sub&gt;''ij''&lt;/sub&gt;, where ''a'' = ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt;.

Define the closed subgroup ''S'' of ''G'' by

:&lt;math&gt;\displaystyle{S=\{g\in G|gE_{ij}\subseteq \bigoplus_{(p,q)\ge (i,j)} E_{pq}\},}&lt;/math&gt;

where the ordering on pairs ''p'' ≤  ''q'' is [[lexicographic order|lexicographic]]. ''S'' contains the group ''A'', since it acts as scalars on ''E''&lt;sub&gt;''ij''&lt;/sub&gt;. If ''N'' is the closed subgroup of ''S'' such that ''nx'' = ''x'' modulo ⊕&lt;sub&gt;(''p'',''q'') &gt; (''i'',''j'')&lt;/sub&gt; ''E''&lt;sub&gt;''pq''&lt;/sub&gt;, then ''S'' = ''AN'' = ''NA'', a [[semidirect product]] with ''A'' normalizing ''N''. Moreover, ''G'' has the following [[Iwasawa decomposition]]:

:&lt;math&gt;\displaystyle{G=KAN.}&lt;/math&gt;

For ''i'' ≠ ''j'' let

:&lt;math&gt;\displaystyle{\mathfrak{g}_{ij} =\{X\in \mathfrak{g}:[L(a),X]={1\over 2}(\alpha_i-\alpha_j)X, \,\,\,\mathrm{for}\,\,\, a=\sum \alpha_i e_i\}.}&lt;/math&gt;

Then the Lie algebra of ''N'' is

:&lt;math&gt;\displaystyle{\mathfrak{n}=\bigoplus_{i&lt;j}  \mathfrak{g}_{ij},\,\,\,\, \mathfrak{g}_{ij} = \{L(a) +2[L(a),L(e_i)]:a\in E_{ij}\}.}&lt;/math&gt;

Taking ordered orthonormal bases of the ''E''&lt;sub&gt;''ij''&lt;/sub&gt; gives a basis of ''E'', using the lexicographic order on pairs (''i'',''j''). The group ''N'' is lower unitriangular and its Lie algebra lower triangular. In particular the exponential map is a polynomial mapping of &lt;math&gt;\mathfrak{n}&lt;/math&gt; onto ''N'', with polynomial inverse given by the logarithm.

==Complexification of a Euclidean Jordan algebra==

===Definition of complexification===
Let ''E'' be a Euclidean Jordan algebra. The complexification ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; = ''E'' ⊕ ''iE'' has a natural conjugation operation (''a'' + ''ib'')* = ''a'' − ''ib'' and a natural complex inner product and norm. The Jordan product on ''E'' extends bilinearly to ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;, so that (''a'' + ''ib'')(''c'' + ''id'') = (''ac'' − ''bd'') + ''i''(''ad'' + ''bc''). If multiplication is defined by ''L''(''a'')''b'' = ''ab'' then the Jordan axiom

:&lt;math&gt;\displaystyle{[L(a),L(a^2)]=0}&lt;/math&gt;

still holds by analytic continuation. Indeed, the identity above holds when ''a'' is replaced by ''a'' + ''tb'' for ''t'' real; and since the left side is then a polynomial with values in End ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; vanishing for real ''t'', it vanishes also ''t'' complex. Analytic continuation also shows that all for the formulas involving power-associativity for a single element ''a'' in ''E'', including recursion formulas for ''L''(''a''&lt;sup&gt;''m''&lt;/sup&gt;), also hold in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;. Since for ''b'' in ''E'', ''L''(''b'') is still self-adjoint on ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;, the adjoint relation ''L''(''a''*) = ''L''(''a'')* holds for ''a'' in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;. Similarly the symmetric bilinear form β(''a'',''b'') = (''a'',''b''*) satisfies β(''ab'',''c'') = β(''b'',''ac''). If the inner product comes from the trace form, then  β(''a'',''b'') = Tr ''L''(''ab'').

For ''a'' in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;, the quadratic representation is defined as before by  ''Q''(''a'')=2''L''(''a'')&lt;sup&gt;2&lt;/sup&gt; − ''L''(''a''&lt;sup&gt;2&lt;/sup&gt;). By analytic continuation the fundamental identity still holds:

:&lt;math&gt;\displaystyle{Q(Q(a)b)=Q(a)Q(b)Q(a),\,\,\,Q(a^m)=Q(a)^m \,\,(m\ge 0).}&lt;/math&gt;

An element ''a'' in ''E'' is called ''invertible'' if it is invertible in '''C'''[''a'']. Power associativity shows that ''L''(''a'') and ''L''(''a''&lt;sup&gt;−1&lt;/sup&gt;) commute. Moreover, ''a''&lt;sup&gt;−1&lt;/sup&gt; is invertible with inverse ''a''.

As in ''E'', ''a'' is invertible if and only if ''Q''(''a'') is invertible. In that case

:&lt;math&gt;\displaystyle{Q(a)^{-1}a=a^{-1},\,\,\, Q(a^{-1})=Q(a)^{-1}.}&lt;/math&gt;

Indeed, as for ''E'', if ''Q''(''a'') is invertible it carries '''C'''[''a''] onto itself, while ''Q''(''a'')1 = ''a''&lt;sup&gt;2&lt;/sup&gt;, so

:&lt;math&gt;\displaystyle{(Q(a)^{-1} a)a=a Q(a)^{-1} a=L(a)Q(a)^{-1}a=Q(a)^{-1}a^2 =1,}&lt;/math&gt;

so ''a'' is invertible. Conversely if ''a'' is invertible, taking ''b'' = ''a''&lt;sup&gt;−2&lt;/sup&gt; in the fundamental identity shows that ''Q''(''a'') is invertible. Replacing ''a'' by ''a''&lt;sup&gt;−1&lt;/sup&gt; and ''b'' by ''a'' then shows that its inverse is ''Q''(''a''&lt;sup&gt;−1&lt;/sup&gt;). Finally if ''a'' and ''b'' are invertible then so is  ''c'' = ''Q''(''a'')''b'' and it satisfies the inverse identity:

:&lt;math&gt;\displaystyle{(Q(a)b)^{-1}=Q(a^{-1})b^{-1}.}&lt;/math&gt;

Invertibility of ''c'' follows from the fundamental formula which gives ''Q''(''c'') = ''Q''(''a'')''Q''(''b'')''Q''(''a''). Hence

:&lt;math&gt;\displaystyle{c^{-1}=Q(c)^{-1}c=Q(a)^{-1}Q(b)^{-1} b= Q(a)^{-1}b^{-1}.}&lt;/math&gt;

The formula

:&lt;math&gt;\displaystyle{Q(e^a) = e^{2L(a)}}&lt;/math&gt;

also follows by analytic continuation.

===Complexification of automorphism group===
Aut ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; is the [[complexification (Lie group)|complexification]] of the compact Lie group Aut ''E'' in GL(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;). This follows because the Lie algebras of Aut ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; and Aut ''E'' consist of derivations of the complex and real Jordan algebras ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; and ''E''. Under the isomorphism identifying End ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; with the complexification of End ''E'', the complex derivations is identified with the complexification of the real derivations.&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|pp=145–146}}&lt;/ref&gt;

===Structure groups===
The Jordan operator ''L''(''a'') are symmetric with respect to the trace form, so that ''L''(''a'')&lt;sup&gt;''t''&lt;/sup&gt; = ''L''(''a'') for ''a'' in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;. The automorphism groups of ''E'' and ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;  consist of invertible real and complex linear operators  ''g'' such that ''L''(''ga'') = ''gL''(''a'')''g''&lt;sup&gt;−1&lt;/sup&gt; and ''g1'' = 1. Aut ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; is the complexification of Aut ''E''. Since an automorphism ''g'' preserves the trace form, ''g''&lt;sup&gt;−1&lt;/sup&gt; = ''g''&lt;sup&gt;''t''&lt;/sup&gt;.

The '''structure groups''' of ''E'' and ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; consist of invertible real and complex linear operators  ''g'' such that

:&lt;math&gt;\displaystyle{Q(ga)=gQ(a)g^t.}&lt;/math&gt;

They form groups  Γ(''E'') and Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) with Γ(''E'') ⊂ Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;).

*The structure group is closed under taking transposes ''g'' ↦ ''g''&lt;sup&gt;''t''&lt;/sup&gt; and adjoints  ''g'' ↦ ''g''*.
*The structure group contains the automorphism group. The automorphism group can be identified with the stabilizer of 1 in the structure group.
*If ''a'' is invertible, ''Q''(''a'') lies in the structure group.
*If ''g'' is in the structure group and ''a'' is invertible, ''ga'' is also invertible with (''ga'')&lt;sup&gt;−1&lt;/sup&gt; = (''g''&lt;sup&gt;''t''&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt;''a''&lt;sup&gt;−1&lt;/sup&gt;.
* If ''E'' is simple, Γ(''E'') = Aut ''C'' × {±1},  Γ(''E'') ∩ O(''E'') = Aut ''E'' × {±1} and the identity component of Γ(''E'') acts transitively on ''C''.
* Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) is the complexification of  Γ(''E''), which has Lie algebra &lt;math&gt;\mathfrak{k}\oplus  \mathfrak{p}&lt;/math&gt;.
* The structure group Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;)  acts transitively on the set of invertible elements in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;.
* Every ''g'' in Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) has the form ''g'' = ''h'' ''Q''(''a'') with ''h'' an automorphism and ''a'' invertible.

The '''unitary structure group''' Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) is the subgroup of Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) consisting of unitary operators, so that Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) = Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) ∩ U(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;).

* The stabilizer of 1 in Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) is Aut ''E''.
* Every ''g'' in  Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) has the form ''g'' = ''h'' ''Q''(''u'') with ''h'' in Aut ''E'' and ''u'' invertible in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; with ''u''* = ''u''&lt;sup&gt;−1&lt;/sup&gt;.
* Γ(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) is the complexification of Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;), which has Lie algebra &lt;math&gt;\mathfrak{k}\oplus i \mathfrak{p}&lt;/math&gt;.
* The set ''S'' of invertible elements ''u'' such that  ''u''* = ''u''&lt;sup&gt;−1&lt;/sup&gt; can be characterized equivalently either as those ''u'' for which ''L''(''u'') is a normal operator with ''uu''* = 1 or as those ''u'' of the form exp ''ia'' for some ''a'' in ''E''. In particular ''S'' is connected.
* The identity component of Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) acts transitively on ''S''
* ''g'' in GL(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) is in the unitary structure group if and only if ''gS'' = ''S''
* Given a Jordan frame (''e''&lt;sub&gt;''i''&lt;/sub&gt;) and ''v'' in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;, there is an operator ''u'' in the identity component of Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) such that ''uv'' = ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; with α&lt;sub&gt;''i''&lt;/sub&gt; ≥ 0. If ''v'' is invertible, then α&lt;sub&gt;''i''&lt;/sub&gt; &gt; 0.

Given a frame {{math|1=(''e''&lt;sub&gt;''i''&lt;/sub&gt;)}} in a Euclidean Jordan algebra ''E'', the [[restricted Weyl group]] can be identified with the group of operators on {{math|1=⊕ '''R''' ''e''&lt;sub&gt;''i''&lt;/sub&gt;}} arising from elements in the identity component of Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) that leave {{math|1=⊕ '''R''' ''e''&lt;sub&gt;''i''&lt;/sub&gt;}} invariant.

===Spectral norm===
Let ''E'' be a Euclidean Jordan algebra with the inner product given by the trace form. Let (''e''&lt;sub&gt;''i''&lt;/sub&gt;) be a fixed Jordan frame in ''E''.  For given ''a'' in ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;  choose ''u'' in Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;) such that
''ua'' = ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; with α&lt;sub&gt;''i''&lt;/sub&gt; ≥ 0. Then the '''spectral norm''' ||''a''|| = max α&lt;sub&gt;''i''&lt;/sub&gt; is independent of all choices. It is a norm on ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; with

:&lt;math&gt;\displaystyle{\|a^*\| = \|a\|,\,\,\, \|\{a,a^*,a\}\| =\|a\|^3.}&lt;/math&gt;

In addition ||''a''||&lt;sup&gt;2&lt;/sup&gt; is given by the [[operator norm]] of ''Q''(''a'') on the inner product space ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;. The fundamental identity for the quadratic representation implies that ||''Q''(''a'')''b''|| ≤ ||''a''||&lt;sup&gt;2&lt;/sup&gt;||''b''||. The spectral norm of an element ''a'' is defined in terms of '''C'''[''a''] so depends only on ''a'' and not the particular Euclidean Jordan algebra in which it is calculated.&lt;ref&gt;{{harvnb|Loos|1977|p=3.15-3.16}}&lt;/ref&gt;

The compact set ''S'' is the set of [[extreme point]]s of the closed unit ball ||''x''|| ≤ 1.  Each ''u'' in ''S'' has norm one. Moreover, if ''u'' = ''e''&lt;sup&gt;''ia''&lt;/sup&gt; and ''v'' = ''e''&lt;sup&gt;''ib''&lt;/sup&gt;, then ||''uv''|| ≤ 1. Indeed, by the Cohn–Shirshov theorem the unital Jordan subalgebra of ''E'' generated by ''a'' and ''b'' is special. The inequality is easy to establish in non-exceptional simple Euclidean Jordan algebras, since each such Jordan algebra and its complexification can be realized as a subalgebra of some H&lt;sub&gt;''n''&lt;/sub&gt;('''R''') and its complexification ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''C''') ⊂ ''M''&lt;sub&gt;''n''&lt;/sub&gt;('''C'''). The spectral norm in  ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''C''') is the usual operator norm. In that case, for unitary matrices ''U'' and ''V'' in ''M''&lt;sub&gt;''n''&lt;/sub&gt;('''C'''), clearly ||½(''UV'' + ''VU'')|| ≤ 1.  The inequality therefore follows in any special Euclidean Jordan algebra and hence in general.&lt;ref&gt;{{harvnb|Wright|1977|pp=296–297}}
&lt;/ref&gt;

On the other hand, by the [[Krein–Milman theorem]], the closed unit ball is the (closed) [[convex span]] of ''S''.&lt;ref&gt;See {{harvtxt|Faraut|Koranyi|1994|pp=73,202–203}} and  {{harvtxt|Rudin|1973|pp=270–273}}. By finite-dimensionality, every point in the convex span of ''S'' is the convex combination of ''n'' + 1 points, where ''n'' = 2 dim ''E''. So the convex span of ''S'' is already compact and equals the closed unit ball.&lt;/ref&gt; It follows that ||''L''(''u'')|| = 1, in the operator norm corresponding to either the inner product norm or spectral norm. Hence ||''L''(''a'')|| ≤ ||''a''|| for all ''a'', so that the spectral norm satisfies

:&lt;math&gt;\displaystyle{\|ab\|\le \|a\|\cdot \|b\|.}&lt;/math&gt;

It follows that ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; is a [[Jordan operator algebra#JB* algebras|'''Jordan C* algebra''']].&lt;ref&gt;{{harvnb|Wright|1977|pp=296–297}}
&lt;/ref&gt;

===Complex simple Jordan algebras===
The complexification of a simple Euclidean Jordan algebra is a simple complex Jordan algebra which is also '''separable''', i.e. its trace form is non-degenerate. Conversely, using the existence of a [[complexification (Lie group)|real form]] of the Lie algebra of the structure group, it can be shown that every complex separable simple Jordan algebra is the complexification of a simple Euclidean Jordan algebra.&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|pp=154–158}}&lt;/ref&gt;

To verify that the complexification of a simple Euclidean Jordan algebra ''E'' has no ideals, note that if ''F'' is an ideal in ''E''&lt;sup&gt;'''C'''&lt;/sup&gt; then so too is ''F''&lt;sup&gt;⊥&lt;/sup&gt;, the orthogonal complement for the trace norm. As in the real case, ''J'' = ''F''&lt;sup&gt;⊥&lt;/sup&gt; ∩ ''F'' must equal (0). For the associativity property of the trace form shows that ''F''&lt;sup&gt;⊥&lt;/sup&gt; is an ideal and that ''ab'' = 0 if ''a'' and ''b'' lie in ''J''. Hence ''J'' is an ideal.  But if ''z'' is in ''J'', ''L''(''z'') takes ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; into ''J'' and ''J'' into (0). Hence Tr ''L''(''z'') = 0.  Since ''J'' is an ideal and the trace form degenerate, this forces ''z'' = 0.  It follows that ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; = ''F'' ⊕ ''F''&lt;sup&gt;⊥&lt;/sup&gt;. If ''P'' is the corresponding projection onto ''F'', it commutes with the operators ''L''(''a'') and ''F''&lt;sup&gt;⊥&lt;/sup&gt; = (''I'' − ''P'')''E''&lt;sub&gt;'''C'''&lt;/sub&gt;. is also an ideal and ''E'' = ''F'' ⊕ ''F''&lt;sup&gt;⊥&lt;/sup&gt;. Furthermore, if ''e'' = ''P''(1), then ''P'' = ''L''(''e''). In fact for ''a'' in ''E''

:&lt;math&gt;\displaystyle{ea=ae=L(a)P(1)=P(L(a)1)=P(a),}&lt;/math&gt;

so that ''ea'' = ''a'' for ''a'' in ''F'' and 0 for ''a'' in ''F''&lt;sup&gt;⊥&lt;/sup&gt;. In particular ''e'' and 1 − ''e'' are orthogonal ''central'' idempotents with ''L''(''e'') = ''P'' and ''L''(1 − ''e'') = ''I'' − ''P''.

So simplicity follows from the fact that the center of ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; is the complexification of the center of ''E''.

==Symmetry groups of bounded domain and tube domain==
According to the "elementary approach" to bounded symmetric space of Koecher,&lt;ref&gt;See:
*{{harvnb|Koecher|1999}}
*{{harvnb|Koecher|1969}}
&lt;/ref&gt; Hermitian symmetric spaces of noncompact type can be realized in the complexification of a Euclidean Jordan algebra ''E'' as either the open unit ball for the spectral norm, a bounded domain, or as the open tube domain {{math|1=''T'' = ''E'' + ''iC''}}, where ''C'' is the positive open cone in ''E''. In the simplest case where ''E'' = '''R''', the complexification of ''E'' is just '''C''', the bounded domain corresponds to the open unit disk and the tube domain to the upper half plane. Both these spaces have transitive groups of biholomorphisms given by Möbius transformations, corresponding to matrices in {{math|SU(1,1)}} or {{math|SL(2,'''R''')}}. They both lie in the Riemann sphere {{math|1='''C''' ∪ {∞}}}, the standard one-point compactification of '''C'''. Moreover, the symmetry groups are all particular cases of Möbius transformations corresponding to matrices in {{math|SL(2,'''C''')}}. This complex Lie group and its maximal compact subgroup {{math|SU(2)}} act transitively on the Riemann sphere. The groups are also algebraic. They have distinguished generating subgroups and have an explicit description in terms of generators and relations. Moreover, the Cayley transform gives an explicit Möbius transformation from the open disk onto the upper half plane.  All these features generalize to arbitrary Euclidean Jordan algebras.&lt;ref&gt;See:
*{{harvnb|Loos|1977}}
*{{harvnb|Faraut|Koranyi|1994}}&lt;/ref&gt; The compactification and complex Lie group are described in the next section and correspond to the dual Hermitian symmetric space of compact type. In this section only the symmetries of and between the bounded domain and tube domain are described.

Jordan frames provide one of the main Jordan algebraic techniques to describe the symmetry groups. Each Jordan frame gives rise to a product of copies of '''R''' and '''C'''. The symmetry groups of the corresponding open domains and the compactification—polydisks and polyspheres—can be deduced from the case of the unit disk, the upper halfplane and Riemann sphere. All these symmetries extend to the larger Jordan algebra and its compactification. The analysis can also be reduced to this case because all points in the complex algebra (or its compactification) lie in an image of the polydisk (or polysphere) under the unitary structure group.

===Definitions===
Let {{math|''E''}} be a Euclidean Jordan algebra with complexification {{math|1=''A'' = ''E''&lt;sub&gt;'''C'''&lt;/sub&gt; = ''E'' + ''iE''}}.

The unit ball or disk ''D'' in {{math|''A''}} is just the convex bounded open set of elements
{{math|''a''}} such the ||''a''|| &lt; 1, i.e. the unit ball for the spectral norm.

The tube domain ''T'' in {{math|''A''}} is the unbounded convex open set {{math|1=''T'' = ''E'' + ''iC''}}, where ''C'' is the open positive cone in {{math|''E''}}.

===Möbius transformations===
The group SL(2,'''C''') acts by [[Möbius transformation]]s on the [[Riemann sphere]] '''C''' ∪ {∞}, the [[one-point compactification]] of '''C'''. If ''g'' in SL(2,'''C''') is given by the matrix

:&lt;math&gt;\displaystyle{g=\begin{pmatrix}\alpha &amp; \beta \\ \gamma &amp; \delta\end{pmatrix},}&lt;/math&gt;

then

:&lt;math&gt;\displaystyle{g(z)=(\alpha z +\beta)(\gamma z +\delta)^{-1}.}&lt;/math&gt;

Similarly the group SL(2,'''R''') acts by Möbius transformations on the circle '''R''' ∪ {∞}, the one-point compactification of '''R'''.

Let ''k'' = '''R''' or '''C'''. Then SL(2,''k'') is generated by the three subgroups of lower and upper unitriangular matrices, '''L''' and '''U'''', and the diagonal matrices '''D'''. It is also generated by the lower (or upper) unitriangular matrices, the diagonal matrices and the matrix

:&lt;math&gt;\displaystyle{J=\begin{pmatrix}0 &amp; 1 \\ -1 &amp; 0\end{pmatrix}.}&lt;/math&gt;

The matrix ''J'' corresponds to the Möbius transformation {{math|1= ''j''(''z'') = −''z''&lt;sup&gt;−1&lt;/sup&gt;}} and can be written

:&lt;math&gt;\displaystyle{J=\begin{pmatrix}1 &amp; 0 \\ -1 &amp; 1\end{pmatrix}\begin{pmatrix}1 &amp; 1 \\ 0 &amp; 1\end{pmatrix}
\begin{pmatrix}1 &amp; 0 \\ -1 &amp; 1\end{pmatrix}.}&lt;/math&gt;

The Möbius transformations fixing ∞ are just the upper triangular matrices '''B''' = '''UD''' = '''DU'''. If ''g'' does not fix ∞, it sends ∞ to a finite point ''a''. But then ''g'' can be composed with an upper unitriangular matrix to send ''a'' to 0 and then with ''J'' to send 0 to infinity. This argument gives the one of the simplest examples of the [[Bruhat decomposition]]:

:&lt;math&gt;\displaystyle{\mathbf{SL}(2,k) = \mathbf{B} \cup \mathbf{B}\cdot J\cdot \mathbf{B},}&lt;/math&gt;

the double coset decomposition of {{math|SL(2,''k'')}}. In fact the union is disjoint and can be written more precisely as

:&lt;math&gt;\displaystyle{\mathbf{SL}(2,k) = \mathbf{B} \cup  \mathbf{B} \cdot J\cdot\mathbf{U},}&lt;/math&gt;

where the product occurring in the second term is direct.

Now let

:&lt;math&gt;\displaystyle{T(\beta)=\begin{pmatrix}1 &amp; \beta \\ 0 &amp; 1\end{pmatrix}.}&lt;/math&gt;

Then

:&lt;math&gt;\displaystyle{\begin{pmatrix}\alpha &amp; 0 \\ 0 &amp; \alpha^{-1}\end{pmatrix} = JT(\alpha^{-1}) JT(\alpha)JT(\alpha^{-1}).}&lt;/math&gt;

It follows {{math|SL(2,''k'')}} is generated by the group of operators {{math|''T''(β)}} and ''J'' subject to the following relations:

*{{math|1= β ↦ ''T''(β)}} is an additive homomorphism
*{{math|1= α ↦ ''D''(α) = ''JT''(α&lt;sup&gt;−1&lt;/sup&gt;)''JT''(α)''JT''(α&lt;sup&gt;−1&lt;/sup&gt;)}} is a multiplicative homomorphism
*{{math|1=''D''(−1) = ''J''}}
*{{math|1=''D''(α)''T''(β)''D''(α)&lt;sup&gt;−1&lt;/sup&gt; = ''T''(α&lt;sup&gt;2&lt;/sup&gt;β)}}
*{{math|1=''JD''(α)''J''&lt;sup&gt;−1&lt;/sup&gt; = ''D''(α)&lt;sup&gt;−1&lt;/sup&gt;}}

The last relation follows from the definition of {{math|1=''D''(α)}}. The generator and relations above is fact gives a presentation of {{math|SL(2,''k'')}}. Indeed, consider the free group Φ generated by ''J'' and {{math|''T''(β)}} with ''J'' of order 4 and its square central. This consists of all products
{{math|1=''T''(β&lt;sub&gt;1&lt;/sub&gt;)''JT''(β&lt;sub&gt;2&lt;/sub&gt;)''JT''(β&lt;sub&gt;3&lt;/sub&gt;)''J'' ... ''T''(β&lt;sub&gt;''m''&lt;/sub&gt;)''J''}} for {{math|1=''m'' ≥ 0}}. There is a natural homomorphism of Φ onto {{math|SL(2,''k'')}}. Its kernel contain the normal subgroup Δ generated by the relations above. So there is a natural homomorphism of Φ/Δ onto {{math|SL(2,''k'')}}. To show that it is injective it suffices to show that the Bruhat decomposition also holds in {{math|1= Φ/Δ}}. It is enough to prove the first version, since the more precise version follows from the commutation relations between ''J'' and
{{math|''D''(α)}}. The set {{math|1='''B''' ∪ '''B''' ''J'' '''B'''}} is invariant under inversion, contains operators {{math|''T''(β)}} and ''J'', so it is enough to show it is invariant under multiplication. By construction it is invariant under multiplication by '''B'''. It is invariant under multiplication by ''J'' because of the defining equation for {{math|1=''D''(α)}}.&lt;ref&gt;{{harvnb|Lang|1985|pp=209–210}}&lt;/ref&gt;

In particular the center of  {{math|SL(2,''k'')}} consists of the scalar matrices {{math|1=±''I''}}  and it is the only non-trivial normal subgroup of {{math|SL(2,''k'')}}, so that {{math|1=PSL(2,''k'') = SL(2,''k'')/{±''I''}}} is [[simple group|simple]].&lt;ref&gt;{{harvnb|Bourbaki|1981|pp=30–32}}&lt;/ref&gt; In fact if {{math|1='''K'''}} is a normal subgroup, then the Bruhat decomposition implies that {{math|'''B'''}} is a maximal subgroup, so that either {{math|'''K'''}} is contained in {{math|'''B'''}} or
{{math|1='''KB''' = SL(2,''k'')}}. In the first case {{math|'''K'''}} fixes one point and hence every point of {{math|1= ''k'' ∪ {∞}}}, so lies in the center. In the second case, the [[commutator subgroup]] of {{math|SL(2,''k'')}} is the whole group, since it the group is generated by lower and upper unitriangular matrices and the fourth relation shows that all such matrices are commutators
since {{math|1=[''T''(β),''D''(α)] = ''T''(β − α&lt;sup&gt;2&lt;/sup&gt;β)}}. Writing {{math|1=''J'' = ''kb''}} with {{math|''k''}} in {{math|'''K'''}} and {{math|''b''}} in {{math|'''B'''}}, it follows that {{math|1='''L''' = ''k'' '''U''' ''k''&lt;sup&gt;−1&lt;/sup&gt;}}. Since {{math|'''U'''}} and {{math|'''L'''}} generate the whole group, {{math|1=SL(2,''k'') = '''KU'''}}. But then {{math|1=SL(2,''k'')/'''K''' ≅ '''U'''/'''U''' ∩ '''K'''}}. The right hand side here is Abelian while the left hand side is its own commutator subgroup. Hence this must be the trivial group and {{math|1='''K''' = SL(2,''k'')}}.

Given an element ''a'' in the complex Jordan algebra {{math|1=''A'' = ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;}}, the unital Jordan subalgebra {{math|1='''C'''[''a'']}} is associative and commutative. Multiplication by ''a'' defines an operator on  {{math|1='''C'''[''a'']}} which has a spectrum, namely its set of complex eigenvalues. If {{math|''p''(''t'')}} is a complex polynomial, then {{math|''p''(''a'')}} is defined in {{math|1='''C'''[''a'']}}. It is invertible in {{math|''A''}} if and only if it is invertible in
{{math|1='''C'''[''a'']}}, which happen precisely when {{math|''p''}} does not vanish on the spectrum of {{math|''a''}}. This permits [[rational function]]s of {{math|''a''}} to be defined whenever the function is defined on the spectrum of {{math|''a''}}. If {{math|''F''}} and {{math|''G''}} are rational functions with {{math|''G''}} and {{math|1=''F''∘''G''}} defined on {{math|''a''}}, then
{{math|''F''}} is defined on {{math|''G''(''a'')}} and {{math|1=''F''(''G''(''a'')) = (''F''∘''G'')(''a'')}}. This applies in particular to complex Möbius transformations which can be defined by
{{math|1=''g''(''a'') = (α''a'' + β1)(γ''a'' + δ1)&lt;sup&gt;−1&lt;/sup&gt;}}. They leave {{math|1='''C'''[''a'']}} invariant and, when defined, the group composition law holds. (In the next section complex Möbius transformations will be defined on the compactification of {{math|''A''}}.)&lt;ref&gt;See:
*{{harvnb|Koecher|1999}}
*{{harvnb|Faraut|Koranyi|1994|pp=150–153}}&lt;/ref&gt;

Given a primitive idempotent {{math|''e''}} in {{math|''E''}} with Peirce decomposition

:&lt;math&gt;\displaystyle{E=E_1(e)\oplus E_{1/2}(e)\oplus E_0(e),\,\,\,\, A=A_1(e)\oplus A_{1/2}(e)\oplus A_0(e).}&lt;/math&gt;

the action of {{math|SL(2,'''C''')}} by Möbius transformations on {{math|1=''E''&lt;sub&gt;1&lt;/sub&gt;(''e'') = '''C''' ''e''}} can be extended to an action on ''A'' so that the action leaves invariant the components {{math|1=''A''&lt;sub&gt;''i''&lt;/sub&gt;(''e'')}} and in particular acts trivially on {{math|1=''E''&lt;sub&gt;0&lt;/sub&gt;(''e'')}}.&lt;ref&gt;{{harvnb|Loos|1977|pp=9.4–9.5}}&lt;/ref&gt; If {{math|1=''P''&lt;sub&gt;0&lt;/sub&gt;}} is the projection onto {{math|1=''A''&lt;sub&gt;0&lt;/sub&gt;(''e'')}}, the action is given be the formula

:&lt;math&gt;\displaystyle{g(z e\oplus x_{1/2} \oplus x_0)={\alpha z +\beta \over \gamma z +\delta}\cdot e \oplus (\gamma z +\delta)^{-1} x_{1/2} \oplus x_0 - (\gamma z + \delta)^{-1}P_0(x_{1/2}^2).}&lt;/math&gt;

For a Jordan frame of primitive idempotents {{math|1=''e''&lt;sub&gt;1&lt;/sub&gt;, ..., ''e''&lt;sub&gt;''m''&lt;/sub&gt;}}, the actions of  {{math|SL(2,'''C''')}} associated with different {{math|1=''e''&lt;sub&gt;''i''&lt;/sub&gt;}} commute, thus giving an action of {{math|SL(2,'''C''')&lt;sup&gt;''m''&lt;/sup&gt;}}. The diagonal copy of  {{math|SL(2,'''C''')}} gives again the action by Möbius transformations on {{math|''A''}}.

===Cayley transform===
{{see also|Cayley transform}}
The Möbius transformation defined by

:&lt;math&gt;\displaystyle{C(z)=i{1+z\over 1-z}=-i +{2i\over 1 - z}}&lt;/math&gt;

is called the [[Cayley transform]]. Its inverse is given by

:&lt;math&gt;\displaystyle{P(w)={w-i\over w+i} = 1 -{2i\over w+i}.}&lt;/math&gt;

The inverse Cayley transform carries the real line onto the circle with the point 1 omitted. It carries the upper halfplane onto the unit disk and the lower halfplane onto the complement of the closed unit disk. In [[operator theory]] the mapping {{math|1=''T'' ↦ ''P''(''T'')}} takes self-adjoint operators ''T'' onto unitary operators ''U'' not containing 1 in their spectrum. For matrices this follows because unitary and self-adjoint matrices can be diagonalized and their eigenvalues lie on the unit circle or real line. In this finite-dimensional setting the Cayley transform and its inverse establish a bijection between the matrices of operator norm less than one and operators with imaginary part a positive operator. This is the special case for {{math|1=''A'' = M&lt;sub&gt;''n''&lt;/sub&gt;('''C''')}} of the Jordan algebraic result, explained below, which asserts that the Cayley transform and its inverse establish a bijection between the bounded domain {{math|''D''}} and the tube domain {{math|''T''}}.

In the case of matrices, the bijection follows from resolvant formulas.&lt;ref&gt;{{harvnb|Folland|1989|pp=203–204}}&lt;/ref&gt; In fact if the imaginary part of {{math|''T''}} is positive, then {{math|1=''T'' + ''iI''}} is invertible since

:&lt;math&gt;\displaystyle{\|(T+iI)x\|^2= \|(T-iI)x\|^2 + 4(\mathrm{Im}(T)x,x).}&lt;/math&gt;

In particular, setting {{math|1=''y'' = (''T'' + ''iI'')''x''}},

:&lt;math&gt;\displaystyle{\|y\|^2= \|P(T)y\|^2 + 4(\mathrm{Im}(T)x,x).}&lt;/math&gt;

Equivalently

:&lt;math&gt;\displaystyle{I-P(T)^*P(T) =
4 (T^* -iI)^{-1}[\mathrm{Im}\,T] (T+iI)^{-1}}&lt;/math&gt;

is a positive operator, so that ||''P''(''T'')|| &lt; 1. Conversely if ||''U''|| &lt; 1 then {{math|''I''
− ''U''}} is invertible and

:&lt;math&gt;\displaystyle{\mathrm{Im}\,C(U)=(2i)^{-1}[C(U)-C(U)^*] =
(1-U^*)^{-1}[I -U^*U](I-U)^{-1}.}&lt;/math&gt;

Since the Cayley transform and its inverse commute with the transpose, they also establish a bijection for symmetric matrices. This corresponds to the Jordan algebra of symmetric complex matrices, the complexification of {{math|''H''&lt;sub&gt;''n''&lt;/sub&gt;('''R''')}}.

In {{math|1=''A'' = ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;}} the above resolvant identities take the following form:&lt;ref&gt;See:
*{{harvnb|Koecher|1999}}
*{{harvnb|Faraut|Koranyi|1994|pp=200–201}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{Q(1-u^*)Q(C(u)+C(u^*))Q(1-u)=-4B(u^*,u)}&lt;/math&gt;

and equivalently

:&lt;math&gt;\displaystyle{  4Q(\mathrm{Im} \,a) = Q(a^*-i)B(P(a)^*,P(a))Q(a+i),}&lt;/math&gt;

where the Bergman operator  {{math|1=''B''(''x'',''y'')}} is defined by {{math|1=''B''(''x'',''y'') = ''I'' − 2''R''(''x'',''y'') + ''Q''(''x'')''Q''(''y'')}} with {{math|1=''R''(''x'',''y'') = [''L''(''x''),''L''(''y'')] + ''L''(''xy'')}}. The inverses here are well defined. In fact in one direction {{math|1=1 − ''u''}} is invertible for ||''u''|| &lt; 1: this follows either using the fact that the norm satisfies ||''ab''|| ≤ ||''a''|| ||''b''||; or using the resolvant identity and the invertibility of {{math|1=''B''(''u''*,''u'')}} (see below). In the other direction if the imaginary part of {{math|''a''}} is in {{math|''C''}} then the imaginary part of {{math|''L''(''a'')}} is positive definite so that {{math|''a''}} is invertible. This argument can be applied to {{math|''a'' + ''i''}}, so it also invertible.

To establish the correspondence, it is enough to check it when {{math|''E''}} is simple. In that case it follows from the connectivity of {{math|''T''}} and {{math|''D''}} and because:

{{quote box|align=left|* For {{math|''x''}} in {{math|''E''}}, {{math|1=''Q''(''x'')}} is a positive operator if and only if {{math|''x''}} or {{math|1=−''x''}} lies in {{math|1=''C''}}
* {{math|1=''B''(''a''*,''a'')}} is a positive operator if and only if {{math|''a''}} or its inverse (if invertible) lies in {{math|''D''}}}}
{{Clear}}

The first criterion follows from the fact that the eigenvalues of {{math|1=''Q''(''x'')}} are exactly {{math|1=λ&lt;sub&gt;''i''&lt;/sub&gt;λ&lt;sub&gt;''j''&lt;/sub&gt;}} if the eigenvalues of {{math|''x''}} are {{math|1=λ&lt;sub&gt;''i''&lt;/sub&gt;}}. So the {{math|1=λ&lt;sub&gt;''i''&lt;/sub&gt;}} are either all positive or all negative. The second criterion follows from the fact that if
{{math|1=''a'' = ''u'' ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; = ''ux''}} with {{math|1=α&lt;sub&gt;''i''&lt;/sub&gt; ≥ 0}} and ''u'' in {{math|1=Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;)}}, then {{math|1=''B''(''a''*,''a'') = ''u''*''Q''(1 − ''x''&lt;sup&gt;2&lt;/sup&gt;)''u''}} has eigenvalues {{math|1=(1 − α&lt;sub&gt;''i''&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;)(1 − α&lt;sub&gt;''j''&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;)}}. So the {{math|1=α&lt;sub&gt;''i''&lt;/sub&gt;}} are either all less than one or all greater than one.

The resolvant identity is a consequence of the following identity for {{math|''a''}} and {{math|''b''}}  invertible

:&lt;math&gt;\displaystyle{Q(a)Q(a^{-1}+b^{-1})Q(b)=Q(a+b).}&lt;/math&gt;

In fact in this case the [[Quadratic Jordan algebra#Linear Jordan algebra defined by a quadratic Jordan algebra|relations for a quadratic Jordan algebra]] imply

:&lt;math&gt;\displaystyle{R(a,b)=2Q(a)Q(a^{-1},b)=2Q(a,b^{-1})Q(b)}&lt;/math&gt;

so that

:&lt;math&gt;\displaystyle{B(a,b)=Q(a)Q(a^{-1}-b)=Q(b^{-1} -a)Q(b).}&lt;/math&gt;

The equality of the last two terms implies the identity, replacing {{math|''b''}} by {{math|1=−''b''&lt;sup&gt;−1&lt;/sup&gt;}}.

Now set {{math|1=''a'' = 1 − ''x''}} and {{math|1=''b'' = 1 − ''y''}}. The resolvant identity is a special case of the more following more general identity:

:&lt;math&gt;\displaystyle{Q(1-x)Q(C(x)+C(y))Q(1-y)=-4B(x,y).}&lt;/math&gt;

In fact

:&lt;math&gt;\displaystyle{C(x)+C(y)=-2i(1-a^{-1} -b^{-1}),}&lt;/math&gt;

so the identity is equivalent to

:&lt;math&gt;\displaystyle{Q(a)Q(1-a^{-1} -b^{-1})Q(b)=B(1-a,1-b).}&lt;/math&gt;

Using the identity above together with {{math|1=''Q''(''c'')''L''(''c''&lt;sup&gt;−1&lt;/sup&gt;) = ''L''(''c'')}}, the left hand side equals {{math|1=''Q''(''a'')''Q''(''b'') + ''Q''(''a'' + ''b'') − 2''L''(''a'')''Q''(''b'') − 2''Q''(''a'')''L''(''b'')}}. The right hand side equals {{math|1=2''L''(''a'')''L''(''b'') + 2''L''(''b'')''L''(''a'') − 2''L''(''ab'') − 2''L''(''a'')''Q''(''b'') − 2''Q''(''a'')''L''(''b'') + ''Q''(''a'')''Q''(''b'') + ''Q''(''a'') + ''Q''(''b'')}}. These are equal because of the formula {{math|1=½[''Q''(''a'' + ''b'') − ''Q''(''a'') − ''Q''(''b'')] = ''L''(''a'')''L''(''b'') + ''L''(''b'')''L''(''a'') − ''L''(''ab'')}}.

===Automorphism group of bounded domain===
{{quote box|align=left|'''''The Möbius transformations in''''' {{math|SU(1,1)}} '''''carry the bounded domain''''' {{math|''D''}} '''''onto itself.'''''}}
{{Clear}}
If {{math|''a''}} lies in the bounded domain {{math|''D''}}, then {{math|1=''a'' − 1}} is invertible. Since {{math|''D''}} is invariant under multiplication by scalars of modulus ≤ 1, it follows that
{{math|1=''a'' − λ}} is invertible for |λ| ≥ 1. Hence for ||''a''|| ≤ 1,  {{math|1=''a'' − λ}} is invertible for |λ| &gt; 1. It follows that the Möbius transformation {{math|''ga''}} is defined for ||''a''|| ≤ 1 and {{math|''g''}} in {{math|SU(1,1)}}. Where defined it is injective. It is holomorphic on {{math|''D''}}. By the [[maximum modulus principle]], to show that {{math|''g''}} maps {{math|''D''}} onto {{math|''D''}} it suffices to show it maps {{math|''S''}} onto itself. For in that case {{math|''g''}} and its inverse preserve {{math|''D''}} so must be surjective. If {{math|1=''u'' = ''e''&lt;sup&gt;''ix''&lt;/sup&gt;}} with {{math|1=''x'' = ∑ ξ&lt;sub&gt;''i''&lt;/sub&gt;''e''&lt;sub&gt;''i''&lt;/sub&gt;}} in {{math|''E''}}, then {{math|''gu''}} lies in {{math|1=⊕ '''C''' ''e''&lt;sub&gt;''i''&lt;/sub&gt;}}. This is a commutative associative algebra and the spectral norm is the supremum norm. Since {{math|1=''u'' = ∑ ς&lt;sub&gt;''i''&lt;/sub&gt;''e''&lt;sub&gt;''i''&lt;/sub&gt;}} with |ς&lt;sub&gt;''i''&lt;/sub&gt;| = 1, it follows that {{math|1=''gu'' = ∑ ''g''(ς&lt;sub&gt;''i''&lt;/sub&gt;)''e''&lt;sub&gt;''i''&lt;/sub&gt;}} where |''g''(ς&lt;sub&gt;''i''&lt;/sub&gt;)| = 1. So {{math|''gu''}} lies in {{math|''S''}}.
{{quote box|align=left|'''''The unitary structure group of''''' {{math|1=''E''&lt;sub&gt;'''C'''&lt;/sub&gt;}} '''''carries''''' {{math|''D''}} '''''onto itself.'''''}}
{{Clear}}
This is a direct consequence of the definition of the spectral norm.
{{quote box|align=left|'''''The group of transformations''''' {{math|1=SU(1,1)&lt;sup&gt;''m''&lt;/sup&gt;}} '''''corresponding to a Jordan frame carries''''' {{math|''D''}} '''''onto itself.'''''}}
{{Clear}}
This is already known for the Möbius transformations, i.e. the diagonal in {{math|1=SU(1,1)&lt;sup&gt;''m''&lt;/sup&gt;}}. It follows for diagonal matrices in a fixed component in {{math|1=SU(1,1)&lt;sup&gt;''m''&lt;/sup&gt;}} because they correspond to transformations in the unitary structure group. Conjugating by a Möbius transformation is equivalent to conjugation by a matrix in that component. Since the only non-trivial normal subgroup of {{math|1=SU(1,1)}} is its center, every matrix in a fixed component carries {{math|''D''}} onto itself.
{{quote box|align=left|{{math|''D''}} '''''is a [[bounded symmetric domain]].'''''}}
{{Clear}}
Given an element in {{math|''D''}} an transformation in the identity component of the unitary structure group carries it in an element in {{math|1=⊕ '''C''' ''e''&lt;sub&gt;''i''&lt;/sub&gt;}} with supremum norm less than 1. An transformation in {{math|1=SU(1,1)&lt;sup&gt;''m''&lt;/sup&gt;}} the carries it onto zero. Thus there is a transitive group of biholomorphic transformations of {{math|''D''}}. The symmetry {{math|1=''z'' ↦ −''z''}} is a biholomorphic Möbius transformation fixing only 0.
{{quote box|align=left|'''''The biholomorphic mappings of''''' {{math|''D''}} '''''onto itself that fix the origin are given by the unitary structure group.'''''}}
{{Clear}}
If {{math|''f''}} is a biholomorphic self-mapping of {{math|''D''}} with {{math|1=''f''(0) = 0}} and derivative {{math|''I''}} at 0, then {{math|''f''}} must be the identity.&lt;ref&gt;{{harvnb|Faraut|Koranyi|1996|pp=204–205}}&lt;/ref&gt; If not, {{math|''f''}} has Taylor series expansion {{math|1=''f''(''z'') = ''z'' + ''f''&lt;sub&gt;''k''&lt;/sub&gt;  + ''f''&lt;sub&gt;''k'' + 1&lt;/sub&gt;(''z'') + ⋅⋅⋅}} with {{math|1=''f''&lt;sub&gt;''i''&lt;/sub&gt;}} homogeneous of degree {{math|''i''}}and {{math|1=''f''&lt;sub&gt;''k''&lt;/sub&gt; ≠ 0}}. But then {{math|1=''f''&lt;sup&gt;''n''&lt;/sup&gt;(''z'') = ''z'' + ''n'' ''f''&lt;sub&gt;''k''&lt;/sub&gt;(''z'')}}. Let {{math|ψ}} be a functional in {{math|''A''*}} of norm one. Then for fixed {{math|''z''}} in {{math|''D''}}, the holomorphic functions of a complex variable {{math|''w''}} given by {{math|1= ''h''&lt;sub&gt;''n''&lt;/sub&gt;(''w'') = ψ(''f''&lt;sup&gt;''n''&lt;/sup&gt;(''wz''))}} must have modulus less than 1 for |''w''| &lt; 1. By [[Cauchy's integral formula#Consequences|Cauchy's inequality]], the coefficients of {{math|1=''w''&lt;sup&gt;''k''&lt;/sup&gt;}} must be uniformly bounded independent of {{math|''n''}}, which is not possible if {{math|1=''f''&lt;sub&gt;''k''&lt;/sub&gt; ≠ 0}}.

If {{math|''g''}} is a biholomorphic mapping of {{math|''D''}} onto itself just fixing 0 then
if {{math|1= ''h''(''z'') = ''e''&lt;sup&gt;''i''α&lt;/sup&gt; ''z''}}, the mapping {{math|1=''f'' = ''g'' ∘ ''h'' ∘ ''g''&lt;sup&gt;−1&lt;/sup&gt; ∘ ''h''&lt;sup&gt;−α&lt;/sup&gt;}} fixes 0 and has derivative {{math|''I''}} there. It is therefore the identity map. So {{math|1=''g''(''e''&lt;sup&gt;''i''α&lt;/sup&gt; ''z'') = ''e''&lt;sup&gt;''i''α&lt;/sup&gt;''g''(''z'')}} for any α. This implies ''g'' is a linear mapping. Since it maps {{math|''D''}} onto itself it maps the closure onto itself. In particular it must map the Shilov boundary {{math|''S''}} onto itself. This forces {{math|''g''}} to be in the unitary structure group.

{{quote box|align=left|'''''The group''''' {{math|1=''G''&lt;sub&gt;''D''&lt;/sub&gt;}}  '''''of biholomorphic automorphisms of''''' {{math|''D''}} '''''is generated by the unitary structure group''''' {{math|''K''&lt;sub&gt;''D''&lt;/sub&gt;}} '''''and the Möbius transformations associated to a Jordan frame. If''''' {{math|1=''A''&lt;sub&gt;''D''&lt;/sub&gt;}} '''''denotes the subgroup of such Möbius transformations fixing''''' {{math|1=±1}}''''', then the Cartan decomposition formula holds:''''' {{math|1=''G''&lt;sub&gt;''D''&lt;/sub&gt; = ''K''&lt;sub&gt;''D''&lt;/sub&gt; ''A''&lt;sub&gt;''D''&lt;/sub&gt; ''K''&lt;sub&gt;''D''&lt;/sub&gt;}}.}}
{{Clear}}
The orbit of 0 under ''A''&lt;sub&gt;''D''&lt;/sub&gt; is the set of all points {{math|1= ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt;}} with {{math|1=−1 &lt; α&lt;sub&gt;''i''&lt;/sub&gt; &lt; 1}}. The orbit of these points under the unitary structure group is the whole of {{math|''D''}}. The Cartan decomposition follows because {{math|1=''K''&lt;sub&gt;''D''&lt;/sub&gt;}} is the stabilizer of 0 in {{math|1=''G''&lt;sub&gt;''D''&lt;/sub&gt;}}.

{{quote box|align=left|'''''The center of''''' {{math|1=''G''&lt;sub&gt;''D''&lt;/sub&gt;}} '''''is trivial.'''''}}
{{Clear}}
 
In fact the only point fixed by (the identity component of) ''K''&lt;sub&gt;''D''&lt;/sub&gt; in ''D'' is 0. Uniqueness implies that the [[Center (geometry)|center]] of ''G''&lt;sub&gt;''D''&lt;/sub&gt; must fix 0. It follows that the center of ''G''&lt;sub&gt;''D''&lt;/sub&gt; lies in ''K''&lt;sub&gt;''D''&lt;/sub&gt;. The center of ''K''&lt;sub&gt;''D''&lt;/sub&gt; is isomorphic to the circle group: a rotation through θ corresponds to multiplication by ''e''&lt;sup&gt;''i''θ&lt;/sup&gt; on ''D'' so lies in {{math|SU(1,1)/{±1}}}. Since this group has trivial center, the center of ''G''&lt;sub&gt;''D''&lt;/sub&gt; is trivial.&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|p=208}}&lt;/ref&gt;

{{quote box|align=left|''K''&lt;sub&gt;''D''&lt;/sub&gt; '''''is a maximal compact subgroup of''''' ''G''&lt;sub&gt;''D''&lt;/sub&gt;.}}
{{Clear}}
In fact any larger compact subgroup would intersect ''A''&lt;sub&gt;''D''&lt;/sub&gt; non-trivially and it has no non-trivial compact subgroups.

Note that ''G''&lt;sub&gt;''D''&lt;/sub&gt; is a Lie group (see below), so that the above three statements hold with ''G''&lt;sub&gt;''D''&lt;/sub&gt; and ''K''&lt;sub&gt;''D''&lt;/sub&gt; replaced by their identity components, i.e. the subgroups generated by their one-parameter cubgroups. Uniqueness of the maximal compact subgroup up to conjugacy follows from [[maximal compact subgroup#Proof of uniqueness for semisimple groups|a general argument]] or can be deduced for classical domains directly using [[Sylvester's law of inertia]] following {{harvtxt|Sugiura|1982}}.&lt;ref&gt;Note that the elementary argument in {{harvtxt|Igusa|1972|p=23}} cited in  {{harvtxt|Folland|1989}} is incomplete.&lt;/ref&gt; For the example of Hermitian matrices over '''C''', this reduces to proving that {{math|1=U(''n'') × U(''n'')}} is up to conjugacy the unique maximal compact subgroup in {{math|1=U(''n'',''n'')}}. In fact if {{math|1=''W'' = '''C'''&lt;sup&gt;''n''&lt;/sup&gt; ⊕ (0)}}, then {{math|1=U(''n'') × U(''n'')}} is the subgroup of {{math|1=U(''n'',''n'')}} preserving ''W''. The restriction of the hermitian form given by the inner product on {{math|''W''}} minus the inner product on {{math|1= (0) ⊕ '''C'''&lt;sup&gt;''n''&lt;/sup&gt;}}.
On the other hand, if {{math|''K''}} is a compact subgroup of {{math|1=U(''n'',''n'')}}, there is a {{math|''K''}}-invariant inner product on {{math|1='''C'''&lt;sup&gt;2''n''&lt;/sup&gt;}} obtained by averaging any inner product with respect to Haar measure on {{math|''K''}}. The Hermitian form corresponds to an orthogonal decomposition into two subspaces of dimension {{math|''n''}} both invariant under {{math|''K''}} with the form positive definite on one and negative definite on the other. By Sylvester's law of inertia,  given two subspaces of dimension {{math|''n''}} on which the Hermitian form is positive definite, one is carried onto the other by an element of {{math|1=U(''n'',''n'')}}. Hence there is an element {{math|''g''}} of  {{math|1=U(''n'',''n'')}} such that the positive definite subspace is given by {{math|''gW''}}. So {{math|1=''gKg''&lt;sup&gt;−1&lt;/sup&gt;}} leaves {{math|''W''}} invariant and {{math|1=''gKg''&lt;sup&gt;−1&lt;/sup&gt; ⊆ U(''n'') × U(''n'')}}.

A similar argument. with [[quaternion]]s replacing the complex numbers, shows uniquess for the symplectic group, which corresponds to Hermitian matrices over '''R'''. This can also been see more directly by using [[Complex manifold|complex structures]]. A complex structure is an invertible operator ''J'' with ''J''&lt;sup&gt;2&lt;/sup&gt; = −''I''. preserving the symplectic form ''B'' and such that −''B''(''Jx'',''y'') is a real inner product. The symplectic group acts transitively on complex structures by conjugation. Moreover, the subgroup commuting with ''J'' is naturally identified with the unitary group for the corresponding complex inner product space. Uniqueness follows by showing that any compact subgroup ''K'' commutes with some complex structure ''J''. In fact, averaging over Haar measure, there is a ''K''-invariant inner product on the underlying space. The symplectic form yields an invertible skew-adjoint operator ''T'' commuting with ''K''. The operator ''S'' = −''T''&lt;sup&gt;2&lt;/sup&gt; is positive, so has a unique positive square root, which commutes with ''K''. So ''J'' = ''S''&lt;sup&gt;−1/2&lt;/sup&gt;''T'', the phase of ''T'', has square −''I'' and commutes with ''K''.

===Automorphism group of tube domain===
There is an [[Cartan decomposition]] for ''G''&lt;sub&gt;''T''&lt;/sub&gt; corresponding to the action on the tube ''T'' = ''E'' + ''iC'':

:&lt;math&gt;\displaystyle{G_T=K_T A_T K_T.}&lt;/math&gt;

*''K''&lt;sub&gt;''T''&lt;/sub&gt; is the stabilizer of ''i'' in ''iC'' ⊂ ''T'', so a maximal compact subgroup of ''G''&lt;sub&gt;''T''&lt;/sub&gt;. Under the Cayley transform, ''K''&lt;sub&gt;''T''&lt;/sub&gt; corresponds to ''K''&lt;sub&gt;''D''&lt;/sub&gt;, the stabilizer of 0 in the bounded symmetric domain, where it acts linearly. Since ''G''&lt;sub&gt;''T''&lt;/sub&gt; is semisimple, every [[Maximal compact subgroup#Proof of uniqueness for semisimple groups|maximal compact subgroup]] is conjugate to ''K''&lt;sub&gt;''T''&lt;/sub&gt;.
*The center of ''G''&lt;sub&gt;''T''&lt;/sub&gt; or ''G''&lt;sub&gt;''D''&lt;/sub&gt; is trivial. In fact the only point fixed by ''K''&lt;sub&gt;''D''&lt;/sub&gt; in ''D'' is 0. Uniqueness implies that the [[Center (geometry)|center]] of ''G''&lt;sub&gt;''D''&lt;/sub&gt; must fix 0. It follows that the center of ''G''&lt;sub&gt;''D''&lt;/sub&gt; lies in ''K''&lt;sub&gt;''D''&lt;/sub&gt; and hence that the center of ''G''&lt;sub&gt;''T''&lt;/sub&gt; lies in ''K''&lt;sub&gt;''T''&lt;/sub&gt;. The center of ''K''&lt;sub&gt;''D''&lt;/sub&gt; is isomorphic to the circle group: a rotation through θ corresponds to multiplication by ''e''&lt;sup&gt;''i''θ&lt;/sup&gt; on ''D''. In Cayley transform it corresponds to the [[Möbius transformation]] ''z'' ↦ (''cz'' + ''s'')(−''sz''  + ''c'')&lt;sup&gt;−1&lt;/sup&gt; where ''c'' = cos θ/2 and ''s'' = sin θ/2. (In particular, when θ = π, this gives the symmetry ''j''(''z'') = −''z''&lt;sup&gt;−1&lt;/sup&gt;.) In fact all Möbius transformations  ''z'' ↦ (α''z'' + β)(−γ''z''  +  δ)&lt;sup&gt;−1&lt;/sup&gt; with αδ − βγ = 1 lie in ''G''&lt;sub&gt;''T''&lt;/sub&gt;. Since PSL(2,'''R''') has trivial center, the center of ''G''&lt;sub&gt;''T''&lt;/sub&gt; is trivial.&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|p=208}}&lt;/ref&gt;
* ''A''&lt;sub&gt;''T''&lt;/sub&gt; is given by the linear operators ''Q''(''a'') with ''a'' = ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; with  α&lt;sub&gt;''i''&lt;/sub&gt; &gt; 0.

In fact the Cartan decomposition for {{math|1=''G''&lt;sub&gt;''T''&lt;/sub&gt;}} follows from the decomposition for {{math|1=''G''&lt;sub&gt;''D''&lt;/sub&gt;}}. Given {{math|1=''z''}} in {{math|1=''D''}}, there is an element {{math|''u''}} in {{math|1=''K''&lt;sub&gt;''D''&lt;/sub&gt;}}, the identity component of {{math|1=Γ&lt;sub&gt;''u''&lt;/sub&gt;(''E''&lt;sub&gt;'''C'''&lt;/sub&gt;)}}, such that {{math|1=''z'' = ''u'' ∑ α&lt;sub&gt;''j''&lt;/sub&gt;''e''&lt;sub&gt;''j''&lt;/sub&gt;}} with {{math|1=α&lt;sub&gt;''j''&lt;/sub&gt; ≥ 0}}. Since ||''z''|| &lt; 1, it follows that {{math|1=α&lt;sub&gt;''j''&lt;/sub&gt; &lt; 1}}. Taking the Cayley transform of ''z'', it follows that every {{math|''w''}} in {{math|''T''}} can be written {{math|1=''w'' = ''k''∘ ''C'' ∑ α&lt;sub&gt;''j''&lt;/sub&gt;''e''&lt;sub&gt;''j''&lt;/sub&gt;}}, with {{math|''C''}} the Cayley transform and {{math|''k''}} in {{math|1=''K''&lt;sub&gt;''T''&lt;/sub&gt;}}. Since
{{math|1=''C'' ∑ α&lt;sub&gt;''i''&lt;/sub&gt;''e''&lt;sub&gt;''i''&lt;/sub&gt; = ∑ β&lt;sub&gt;''j''&lt;/sub&gt;''e''&lt;sub&gt;''j''&lt;/sub&gt; ''i''}} with
{{math|1=β&lt;sub&gt;''j''&lt;/sub&gt; = (1 + α&lt;sub&gt;''j''&lt;/sub&gt;)(1 − α&lt;sub&gt;''j''&lt;/sub&gt;)&lt;sup&gt;−1&lt;/sup&gt;}}, the point {{math|''w''}} is of the form {{math|1=''w'' =''ka''(''i'')}} with {{math|''a''}} in {{math|''A''}}. Hence {{math|1=''G''&lt;sub&gt;''T''&lt;/sub&gt; = ''K''&lt;sub&gt;''T''&lt;/sub&gt;''A''&lt;sub&gt;''T''&lt;/sub&gt;''K''&lt;sub&gt;''T''&lt;/sub&gt;}}.

===3-graded Lie algebras===

===Iwasawa decomposition===
There is an [[Iwasawa decomposition]] for ''G''&lt;sub&gt;''T''&lt;/sub&gt; corresponding to the action on the tube ''T'' = ''E'' + ''iC'':&lt;ref&gt;{{harvnb|Faraut|Koranyi|1994|p=334}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle{G_T=K_T A_T N_T.}&lt;/math&gt;

*''K''&lt;sub&gt;''T''&lt;/sub&gt; is the stabilizer of ''i'' in ''iC'' ⊂ ''T''.
* ''A''&lt;sub&gt;''T''&lt;/sub&gt; is given by the linear operators ''Q''(''a'') where ''a'' = ∑ α&lt;sub&gt;''i''&lt;/sub&gt; ''e''&lt;sub&gt;''i''&lt;/sub&gt; with  α&lt;sub&gt;''i''&lt;/sub&gt; &gt; 0.
* ''N''&lt;sub&gt;''T''&lt;/sub&gt; is a lower unitriangular group on ''E''&lt;sub&gt;'''C'''&lt;/sub&gt;. It is the semidirect product of the unipotent triangular group ''N'' appearing in the Iwasawa decomposition of ''G'' (the symmetry group of ''C'') and ''N''&lt;sub&gt;0&lt;/sub&gt; = ''E'', group of translations ''x'' ↦ ''x'' + ''b''.

The group ''S'' = ''AN'' acts on ''E'' linearly and conjugation on ''N''&lt;sub&gt;0&lt;/sub&gt; reproduces this action. Since the group ''S'' acts simply transitively on ''C'', it follows that ''AN''&lt;sub&gt;''T''&lt;/sub&gt;=''S''⋅''N''&lt;sub&gt;0&lt;/sub&gt; acts simply transitively on ''T'' = ''E'' + ''iC''.  Let ''H''&lt;sub&gt;''T''&lt;/sub&gt; be the group of [[biholomorphism]]s of the tube ''T''. The Cayley transform shows that is isomorphic to the group ''H''&lt;sub&gt;''D''&lt;/sub&gt; of biholomorphisms of the bounded domain ''D''. Since ''AN''&lt;sub&gt;''T''&lt;/sub&gt; acts simply transitively on the tube ''T'' while ''K''&lt;sub&gt;''T''&lt;/sub&gt; fixes ''ic'', they have trivial intersection.

Given ''g'' in ''H''&lt;sub&gt;''T''&lt;/sub&gt;, take ''s'' in  ''AN''&lt;sub&gt;''T''&lt;/sub&gt; such that ''g''&lt;sup&gt;−1&lt;/sup&gt;(''i'')=''s''&lt;sup&gt;−1&lt;/sup&gt;(''i''). then ''gs''&lt;sup&gt;−1&lt;/sup&gt;  fixes ''i'' and therefore lies in ''K''&lt;sub&gt;''T''&lt;/sub&gt;. Hence ''H''&lt;sub&gt;''T''&lt;/sub&gt; = ''K''&lt;sub&gt;''T''&lt;/sub&gt; ⋅''A''⋅''N''&lt;sub&gt;''T''&lt;/sub&gt;. So the product is a group.

===Lie group structure===
By a result of [[Henri Cartan]], ''H''&lt;sub&gt;''D''&lt;/sub&gt; is a Lie group. Cartan's original proof is presented in {{harvtxt|Narasimhan|1971}}. It can also be deduced from the fact the ''D'' is complete for the [[Bergman metric]], for which the isometries form a Lie group; by [[Montel's theorem]], the group of biholomorphisms is a closed subgroup.&lt;ref&gt;See:
*{{harvnb|Cartan|1935}}
*{{harvnb|Helgason|1978}}
*{{harvnb|Kobayashi|Nomizu|1963}}
*{{harvnb|Faraut|Koranyi|1994}}&lt;/ref&gt;

That ''H''&lt;sub&gt;''T''&lt;/sub&gt; is a Lie group can be seen directly in this case.  In fact there is a finite-dimensional 3-graded Lie algebra  &lt;math&gt;\mathfrak{g}_T&lt;/math&gt; of vector fields with an involution σ. The Killing form is negative definite on the +1 eigenspace of σ  and positive definite on the −1 eigenspace. As a group ''H''&lt;sub&gt;''T''&lt;/sub&gt;  normalizes &lt;math&gt;\mathfrak{g}_T&lt;/math&gt; since the two subgroups ''K''&lt;sub&gt;''T''&lt;/sub&gt; and ''AN''&lt;sub&gt;''T''&lt;/sub&gt; do. The +1 eigenspace corresponds to the Lie algebra of ''K''&lt;sub&gt;''T''&lt;/sub&gt;. Similarly the Lie algebras of the linear group ''AN'' and the affine group ''N''&lt;sub&gt;0&lt;/sub&gt; lie in &lt;math&gt;\mathfrak{g}_T&lt;/math&gt;. Since the group ''G''&lt;sub&gt;''T''&lt;/sub&gt; has trivial center, the map into GL(&lt;math&gt;\mathfrak{g}_T&lt;/math&gt;) is injective. Since ''K''&lt;sub&gt;''T''&lt;/sub&gt; is compact, its image in GL(&lt;math&gt;\mathfrak{g}_T&lt;/math&gt;) is compact. Since the Lie algebra &lt;math&gt;\mathfrak{g}_T&lt;/math&gt; is compatible with that of ''AN''&lt;sub&gt;''T''&lt;/sub&gt;, the image of ''AN''&lt;sub&gt;''T''&lt;/sub&gt; is closed. Hence the image of the product is closed, since the image of ''K''&lt;sub&gt;''T''&lt;/sub&gt; is compact. Since it is a closed subgroup, it follows that ''H''&lt;sub&gt;''T''&lt;/sub&gt; is a Lie group.

==Generalizations==
Euclidean Jordan algebras can be used to construct Hermitian symmetric spaces of tube type. The remaining Hermitian symmetric spaces are Siegel domains of the second kind. They can be constructed using Euclidean [[Jordan triple system]]s, a generalization of Euclidean Jordan algebras. In fact for a Euclidean Jordan algebra ''E'' let

:&lt;math&gt;\displaystyle{L(a,b)=2([L(a),L(b)] + L(ab)).}&lt;/math&gt;

Then ''L''(''a'',''b'') gives a bilinear map into End ''E'' such that

:&lt;math&gt;\displaystyle{L(a,b)^*=L(b,a)},\,\,\, L(a,b)c=L(c,b)a&lt;/math&gt;

and

:&lt;math&gt;\displaystyle{[L(a,b),L(c,d)]=L(L(a,b)c,d)-L(c,L(b,a)d).}&lt;/math&gt;

Any such bilinear system is called a '''Euclidean Jordan triple system'''. By definition the operators ''L''(''a'',''b'') form a Lie subalgebra of End ''E''.

The [[Kantor–Koecher–Tits construction]] gives a one-one correspondence between Jordan triple systems and 3-graded Lie algebras

:&lt;math&gt;\displaystyle{\mathfrak{g}=\mathfrak{g}_{-1}\oplus\mathfrak{g}_0\oplus\mathfrak{g}_1,}&lt;/math&gt;

satisfying

:&lt;math&gt;\displaystyle{[\mathfrak{g}_p,\mathfrak{g}_q]\subseteq \mathfrak{g}_{p+q}}&lt;/math&gt;

and equipped with an involutive automorphism σ reversing the grading. In this case

:&lt;math&gt;\displaystyle{L(a,b) = \mathrm{ad}\,[a,\sigma(b)]}&lt;/math&gt;

defines a Jordan triple system on &lt;math&gt;\mathfrak{g}_{-1}&lt;/math&gt;. In the case of Euclidean Jordan algebras or triple systems the Kantor–Koecher–Tits construction can be identified with the Lie algebra of the Lie group of all homomorphic automorphisms of the corresponding [[bounded symmetric domain]].
The Lie algebra is constructed by taking &lt;math&gt;\mathfrak{g}_0&lt;/math&gt; to be the Lie subalgebra &lt;math&gt;\mathfrak{h}&lt;/math&gt; of End ''E'' generated by the L(''a'',''b'') and &lt;math&gt;\mathfrak{g}_{\pm 1}&lt;/math&gt; to be copies of ''E''. The Lie bracket is given by

:&lt;math&gt;\displaystyle{[(a_1,T_1,b_1),(a_2,T_2,b_2)]=(T_1a_2-T_2a_1,[T_1,T_2]+L(a_1,b_2)-L(a_2,b_1),T_2^*b_1-T_1^*b_2)}&lt;/math&gt;

and the involution by

:&lt;math&gt;\displaystyle{\sigma(a,T,b)=(b,-T^*,a).}&lt;/math&gt;

The [[Killing form]] is given by

:&lt;math&gt;\displaystyle{B((a_1,T_1,b_1),(a_2,T_2,b_2))= (a_1,b_2) + (b_1,a_2) +  \beta(T_1,T_2),}&lt;/math&gt;

where β(''T''&lt;sub&gt;1&lt;/sub&gt;,''T''&lt;sub&gt;2&lt;/sub&gt;) is the symmetric bilinear form defined by

:&lt;math&gt;\displaystyle{\beta(L(a,b),L(c,d))=(L(a,b)c,d)=(L(c,d)a,b).}&lt;/math&gt;

These formulas, originally derived for Jordan algebras, work equally well for Jordan triple systems.&lt;ref&gt;See:
*{{harvnb|Koecher|1967}}
*{{harvnb|Koecher|1968}}
*{{harvnb|Koecher|1969}}
*{{harvnb|Faraut|Koranyi|1994|pp=218–219}}&lt;/ref&gt;
The account in {{harvtxt|Koecher|1969}} develops the theory of [[bounded symmetric domain]]s starting from the standpoint of 3-graded Lie algebras. For a given finite-dimensional vector space ''E'', Koecher considers finite-dimensional Lie algebras &lt;math&gt;\mathfrak{g}&lt;/math&gt; of vector fields on ''E'' with polynomial coefficients of degree ≤ 2. &lt;math&gt;\mathfrak{g}_{-1}&lt;/math&gt; consists of the constant vector fields ∂&lt;sub&gt;''i''&lt;/sub&gt; and &lt;math&gt;\mathfrak{g}_{0}&lt;/math&gt; must contain the [[Euler operator]] ''H'' = ∑ ''x''&lt;sub&gt;''i''&lt;/sub&gt;⋅∂&lt;sub&gt;''i''&lt;/sub&gt; as a central element. Requiring the existence of an involution σ leads directly to a Jordan triple structure on ''V'' as above. As for all Jordan triple structures, fixing ''c'' in ''E'',
the operators ''L''&lt;sub&gt;''c''&lt;/sub&gt;(''a'') = ''L''(''a'',''c'') give ''E'' a Jordan algebra structure, determined by ''e''. The operators ''L''(''a'',''b'') themselves come from a Jordan algebra structure as above if and only if there are additional operators ''E''&lt;sub&gt;±&lt;/sub&gt; in  &lt;math&gt;\mathfrak{g}_{\pm 1}&lt;/math&gt; so that ''H'', ''E''&lt;sub&gt;±&lt;/sub&gt; give a copy of &lt;math&gt;\mathfrak{sl}_2&lt;/math&gt;. The corresponding Weyl group element implements the involution σ. This case corresponds to that of Euclidean Jordan algebras.

The remaining cases are constructed uniformly by Koecher using involutions of simple Euclidean Jordan algebras.&lt;ref&gt;{{harvnb|Koecher|1969|p=85}}&lt;/ref&gt; Let ''E'' be a simple Euclidean Jordan algebra and τ a Jordan algebra automorphism of ''E'' of period 2. Thus ''E'' = ''E''&lt;sub&gt;+1&lt;/sub&gt; ⊕ ''E''&lt;sub&gt;−1&lt;/sub&gt; has an eigenspace decomposition for τ with ''E''&lt;sub&gt;+1&lt;/sub&gt; a Jordan subalgebra and ''E''&lt;sub&gt;−1&lt;/sub&gt; a module. Moreover, a product of two elements in ''E''&lt;sub&gt;−1&lt;/sub&gt; lies in ''E''&lt;sub&gt;+1&lt;/sub&gt;. For ''a'', ''b'', ''c'' in ''E''&lt;sub&gt;−1&lt;/sub&gt;, set

:&lt;math&gt;\displaystyle{L_0(a,b)c=L(a,b)c}&lt;/math&gt;

and (''a'',''b'')= Tr ''L''(''ab''). Then ''F'' = ''E''&lt;sub&gt;−1&lt;/sub&gt; is a simple Euclidean Jordan triple system, obtained by restricting the triple system on ''E'' to ''F''.  Koecher exhibits explicit involutions of simple Euclidean Jordan algebras directly (see below). These Jordan triple systems correspond to irreducible Hermitian symmetric spaces given by Siegel domains of the second kind. In Cartan's listing, their compact duals are SU(''p'' + ''q'')/S(U(''p'') × U(''q'')) with ''p'' ≠ ''q'' (AIII), SO(2''n'')/U(''n'') with ''n'' odd (DIII) and E&lt;sub&gt;6&lt;/sub&gt;/SO(10) × U(1) (EIII).

'''Examples'''
*''F'' is the space of ''p'' by ''q'' matrices over '''R''' with ''p'' ≠ ''q''. In this case ''L''(''a'',''b'')''c''= ''ab''&lt;sup&gt;''t''&lt;/sup&gt;''c'' + ''cb''&lt;sup&gt;''t''&lt;/sup&gt;''a'' with inner product (''a'',''b'') = Tr ''ab''&lt;sup&gt;''t''&lt;/sup&gt;. This is Koecher's construction for the involution on ''E'' = ''H''&lt;sub&gt;''p'' + ''q''&lt;/sub&gt;('''R''') given by conjugating by the diagonal matrix with ''p'' digonal entries equal to 1 and ''q'' to −1.
*''F'' is the space of real skew-symmetric ''m'' by ''m'' matrices. In this case ''L''(''a'',''b'')''c'' = ''abc'' + ''cba'' with inner product (''a'',''b'') = −Tr ''ab''. After removing a factor of √(-1), this is Koecher's construction applied to complex conjugation on ''E'' = ''H''&lt;sub&gt;''n''&lt;/sub&gt;('''C''').
*''F'' is the direct sum of two copies of the Cayley numbers, regarded as 1 by 2 matrices. This triple system is obtained by Koecher's construction for the canonical involution defined by any minimal idempotent in ''E'' = ''H''&lt;sub&gt;3&lt;/sub&gt;('''O''').

The classification of Euclidean Jordan triple systems has been achieved by generalizing the methods of Jordan, von Neumann and Wigner, but the proofs are more involved.&lt;ref&gt;See:
*{{harvnb|Loos|1977}}
*{{harvnb|Neher|1979}}
*{{harvnb|Neher|1980}}
*{{harvnb|Neher|1981}}
*{{harvnb|Neher|1987}}
&lt;/ref&gt; Prior differential geometric methods of {{harvtxt|Kobayashi|Nagano|1965}}, invoking a 3-graded Lie algebra, and of {{harvtxt|Loos|1971}}, {{harvtxt|Loos|1985}} lead to a more rapid classification.

==Notes==
{{reflist|3}}

==References==
*{{citation|last=Albert|first= A. A.|title= On a certain algebra of quantum mechanics|journal= Annals of Mathematics|volume= 35|year=1934|pages=65–73|jstor=1968118|doi=10.2307/1968118}}
*{{citation|first=N.|last=Bourbaki|series=Éléments de Mathématique|title=Groupes et Algèbres de Lie (Chapitres 4,5 et 6)|publisher=Masson|year=1981|isbn=2225760764}}
*{{citation|title=Sur les groupes de transformations analytiques|first=Henri|last= Cartan|publisher= Hermann|year= 1935|
series=Actualités scientifiques et industrielles}}
*{{citation|last=Clerc|first= J.|title= Représentation d'une algèbre de Jordan, polynômes invariants et harmoniques de Stiefel| journal= J. Reine Angew. Math.|volume= 423|year= 1992|pages= 47–71|url=http://www.degruyter.com/view/j/crll.1992.issue-423/crll.1992.423.47/crll.1992.423.47.xml|doi=10.1515/crll.1992.423.47}}
*{{citation|last=Faraut|first= J.|last2= Koranyi|first2= A. | author2-link = Ádám Korányi|title= Analysis on symmetric cones|series= Oxford Mathematical Monographs|publisher= Oxford University Press|year= 1994|isbn= 0198534779}}
*{{citation|first=G. B.|last=Folland|title=Harmonic analysis in phase space|series=Annals of Mathematics Studies|volume=122|year=1989|publisher=Princeton University Press|isbn=9780691085289}}
*{{citation|last=Freudenthal|first=Hans|title=Oktaven, Ausnahmegruppen und Oktavengeometrie|year=1951|
publisher= Mathematisch Instituut der Rijksuniversiteit te Utrecht}}
*{{citation|last=Freudenthal|first=Hans|title=Oktaven, Ausnahmegruppen und Oktavengeometrie|journal= Geom. Dedicata|volume=19|year=1985|
pages=7–63|url=https://link.springer.com/article/10.1007%2FBF00233101|doi=10.1007/bf00233101}} (reprint of 1951 article)
*{{citation|last=Hanche-Olsen|first=Harald|last2= Størmer|first2= Erling|title= Jordan operator algebras|series= Monographs and Studies in Mathematics|volume= 21|publisher= Pitman|year= 1984|isbn=0273086197|url=http://www.math.ntnu.no/~hanche/joa/}}
*{{citation | last = Helgason|first = Sigurdur | authorlink=Sigurdur Helgason (mathematician)| title=Differential Geometry， Lie Groups, and Symmetric Spaces | publisher= Academic Press, New York| year=1978 | isbn = 0-12-338460-5  }}
*{{citation|last=Igusa|first=J.|title=Theta functions|series=Die Grundlehren der mathematischen Wissenschaften|volume= 194|publisher=Springer-Verlag|year=1972}}
*{{citation|last=Jacobson|first= N.|title= Structure and representations of Jordan algebras|series= American Mathematical Society Colloquium Publications|volume=39|publisher= American Mathematical Society|year= 1968}}
*{{citation|last=Jordan|first=P.|last2=von Neumann|first2= J.|last3= Wigner|first3= E.|title=
On an algebraic generalization of the quantum mechanical formalism|journal=Annals of Mathematics|volume= 35| year=1934|pages= 29–64|jstor=1968117|doi=10.2307/1968117}}
*{{citation|first1=Shoshichi|last1=Kobayashi|first2=Katsumi|last2=Nomizu|title=[[Foundations of Differential Geometry]], Vol. I|publisher=Wiley Interscience|year=1963|isbn=0-470-49648-7}}
*{{citation|last=Kobayashi|first= Shoshichi|last2= Nagano|first2= Tadashi|title=
On filtered Lie algebras and geometric structures. I. |journal=J. Math. Mech.|volume= 13|year= 1964| pages=875–907}}
*{{citation|last=Koecher|first= M.|title=Imbedding of Jordan algebras into Lie algebras. I|journal= 
Amer. J. Math.|volume= 89|year= 1967|pages= 787–816|doi=10.2307/2373242}}
*{{citation|last=Koecher|first= M.|title=Imbedding of Jordan algebras into Lie algebras. II|journal= 
Amer. J. Math.|volume= 90|year= 1968|pages= 476–510|doi=10.2307/2373540}}
* {{citation|first=M.|last= Koecher|year=1969|title= An elementary approach to bounded symmetric domains|series= Lecture Notes|publisher=Rice University}}
*{{citation|title=The Minnesota Notes on Jordan Algebras and Their Applications|first=M.|last= Koecher|series=Lecture Notes in Mathematics|volume=1710|publisher=Springer|isbn=3540663606|year=1999}}
*{{citation|last=Koecher|first= M.|chapter=Jordan algebras and differential geometry|title= Actes du Congrès International des Mathématiciens (Nice, 1970), Tome I|pages= 279–283|publisher=Gauthier-Villars|year= 1971|url=http://www.mathunion.org/ICM/ICM1970.1/Main/icm1970.1.0279.0284.ocr.pdf}}
*{{citation|first=S.|last= Lang|title=SL&lt;sub&gt;2&lt;/sub&gt;(R)|series=Graduate Texts in Mathematics|volume=105|publisher=Springer-Verlag|year=1985|isbn=0-387-96198-4}}
* {{citation|first=Ottmar|last= Loos|year=1975|title=Jordan pairs|series= Lecture Notes in Mathematics|volume=460|publisher= Springer-Verlag}}
*{{citation|last=Loos|first= Ottmar|title= A structure theory of Jordan pairs|journal= Bull. Amer. Math. Soc. |volume=80|year=1971|pages= 67–71|doi=10.1090/s0002-9904-1974-13355-0}}
*{{citation|last=Loos|first=Ottmar|title=Bounded symmetric domains and Jordan pairs|series=Mathematical lectures|publisher=University of California, Irvine|year=1977|url=http://molle.fernuni-hagen.de/~loos/jordan/archive/irvine/irvine.pdf|deadurl=yes|archiveurl=https://web.archive.org/web/20160303234008/http://molle.fernuni-hagen.de/~loos/jordan/archive/irvine/irvine.pdf|archivedate=2016-03-03|df=}}
*{{citation|last=Loos|first= Ottmar|title= Charakterisierung symmetrischer R-Räume durch ihre Einheitsgitter|journal= Math. Z.|volume= 189 |year=1985|pages= 211–226|doi=10.1007/bf01175045}}
*{{citation|last=Macdonald|first= I. G.|title=Jordan algebras with three generators|journal=
Proc. London Math. Soc.|volume= 10|year= 1960|pages=395–408|doi=10.1112/plms/s3-10.1.395 |url=http://plms.oxfordjournals.org/content/s3-10/1/395}}
*{{citation|last=Narasimhan|first=Raghavan|title=Several complex variables|series=Chicago Lectures in Mathematics|publisher= University of Chicago Press|year=1971|isbn=0-226-56817-2}}
*{{citation|last=Neher|first=Erhard|title=Cartan-Involutionen von halbeinfachen reellen Jordan-Tripelsystemen|journal= Math. Z. |volume=169|year=1979|pages= 271–292|doi=10.1007/bf01214841}}
*{{citation|last= Neher|first= Erhard|title= Klassifikation der einfachen reellen speziellen Jordan-Tripelsysteme|journal=Manuscripta Math.|volume= 31|year=1980|pages= 197–215|doi=10.1007/bf01303274}}
*{{citation|last=Neher|first=Erhard |title=Klassifikation der einfachen reellen Ausnahme-Jordan-Tripelsysteme|journal= J. Reine Angew. Math. |volume=322|year=1981|pages =145–169|doi=10.1515/crll.1981.322.145}}
*{{citation|last=Neher|first= Erhard|title= Jordan triple systems by the grid approach|series= Lecture Notes in Mathematics|volume= 1280|publisher= Springer-Verlag|year= 1987|isbn= 3540183620}}
*{{citation|last=Postnikov|first=M.|title= Lie groups and Lie algebras. Lectures in geometry. Semester V |publisher=[[Mir Publishers|Mir]]|year= 1986}}
*{{citation|last=Rudin|first= Walter|title=Functional analysis|publisher= 
McGraw-Hill|year= 1973}}
*{{citation| first= T. A.| last = Springer| authorlink = T. A. Springer
 |first2= F. D.|last2= Veldkamp| year = 2000| title= Octonions, Jordan Algebras and Exceptional Groups| publisher  = [[Springer-Verlag]]| isbn = 3540663371}}, originally lecture notes from a course given in the [[University of Göttingen]] in 1962
*{{citation|last=Sugiura|first= Mitsuo|title=The conjugacy of maximal compact subgroups for orthogonal, unitary and unitary symplectic groups|journal=Sci. Papers College Gen. Ed. Univ. Tokyo|volume= 32| year=1982|pages=101–108}}
*{{citation|last=Wright|first= J. D. M.|title=Jordan C∗-algebras|journal= 
Michigan Math. J.|volume= 24|year=1977|pages= 291–302|doi=10.1307/mmj/1029001946}}
*{{citation|last=Zhevlakov|first= K. A.|last2= Slinko|first2= A. M.|last3= Shestakov|first3= I. P.|last4= Shirshov|first4= A. I.| title=Rings that are nearly associative|series= Pure and Applied Mathematics|volume= 104|publisher=Academic Press|year= 1982|isbn= 0127798501}}

[[Category:Convex geometry]]
[[Category:Non-associative algebras]]
[[Category:Lie algebras]]
[[Category:Lie groups]]
[[Category:Several complex variables]]</text>
      <sha1>7efhkbm46wvj9ie4r9fmbwc5u7xhzx7</sha1>
    </revision>
  </page>
  <page>
    <title>Tallyman</title>
    <ns>0</ns>
    <id>5052341</id>
    <revision>
      <id>856469340</id>
      <parentid>856468980</parentid>
      <timestamp>2018-08-25T12:56:13Z</timestamp>
      <contributor>
        <username>Largoplazo</username>
        <id>2766075</id>
      </contributor>
      <comment>Revert to revision 822339026 dated 2018-01-25 20:19:34 by Rayqwerty using [[:en:Wikipedia:Tools/Navigation_popups|popups]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3239">{{For|the comic character|Tally Man}}
A '''tallyman'''  is an individual who keeps a numerical record with [[tally marks]], historically often on [[tally stick]]s.
The heavy metal singer [[Udo Dirkschneider]] produced a song called Tallyman.

==Vote counter==
{{main|Counting agent}}
In [[Ireland]], it is common for political parties to provide private observers when ballot boxes are opened.  These ''tallymen'' keep a [[tally (voting)|tally]] of the preferences of visible voting papers and allow an early initial estimate of which candidates are likely to win in the drawn-out [[single transferable vote]] counting process.&lt;ref&gt;{{cite news| url=http://www.irishtimes.com/newspaper/ireland/2011/0216/1224289935648.html | work=The Irish Times | title=Art of the tallyman extolled at columnist's book launch | date=2011-02-02}}&lt;/ref&gt;  Since the public voting process is by then complete, it is usual for tallymen from different parties to share information.

==Head counter==
Another possible definition is a person who called to literally do a head count, presumably on behalf of either the town council or the house owners. This is rumoured to have occurred in [[Liverpool]], in the years after the [[First World War]]. Mechanical [[tally counter]]s can make such head counts easier, by removing the need to make any marks.

==Debt collector==
In poorer parts of [[England]] (including the north and the [[East End]] of [[London]]), the tallyman was the [[hire purchase]] collector, who visited each week to collect the payments for goods purchased on the 'never never', or hire purchase. These people still had such employment up until the 1960s. 

The title ''tallyman'' extended to the keeper of a village [[pound (village)|pound]] as animals were often held against debts, and tally sticks were used to prove they could be released. 

The credit information company Experian Tallyman markets [[debt collection]] management software called ''Tallyman'', a product originally purchased from Talgentra&lt;ref&gt;{{Cite web
  |title=Tallyman
  |url=http://www.experian-da.com/solutions/tallyman.html
  |publisher=Experian Decision Analytics
}}&lt;/ref&gt;&lt;ref&gt;[http://www.insidearm.com/daily/debt-collection-news/debt-collection/experian-acquires-tallyman-collections-software/ Experian Acquires Tallyman Collections Software]. Retrieved on 2009-01-23&lt;/ref&gt;

In 1967 [[Graham Gouldman]] wrote a song called ''Tallyman'', which was recorded by [[Jeff Beck]] and reached #30 on the British charts.

==Bananas==
"'The tallyman,' Mum told me, 'slice off the top of the stems of the bunches as they take them in. Then him count the little stubs he just sliced off and pay the farmer.'" explains a Ms. Wade in Andrea Levy’s novel "Fruit of the Lemon".&lt;ref&gt;[http://www.andrealevy.co.uk/bibliography/index.php]&lt;/ref&gt; [[Harry Belafonte]] addresses the tallyman in his [[The Banana Boat Song|Banana Boat Song]].

==Comic character==
The ''[[Tally Man]]'' is the name of two super villains in the [[DC Universe]], usually enemies of [[Batman]].  The original was a "collector" of human lives, having killed a criminal debt collecter in his boyhood.

==See also==
*[[Tally (disambiguation)|Tally]]

==References==
&lt;references/&gt;


[[Category:Numeral systems]]</text>
      <sha1>ox0nslg0kmmlaz8lzs1998rqjpw73ch</sha1>
    </revision>
  </page>
  <page>
    <title>Triangulation (computer vision)</title>
    <ns>0</ns>
    <id>12891058</id>
    <revision>
      <id>862204631</id>
      <parentid>862204513</parentid>
      <timestamp>2018-10-02T20:49:20Z</timestamp>
      <contributor>
        <ip>165.91.13.178</ip>
      </contributor>
      <comment>/* Introduction */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12130">{{broader|Computer stereo vision}}
{{Other uses|Triangulation (disambiguation)}}

In [[computer vision]] '''triangulation''' refers to the process of determining a point in 3D space given its projections onto two, or more, images.  In order to solve this problem it is necessary to know the parameters of the camera projection function from 3D to 2D for the cameras involved, in the simplest case represented by the [[camera matrix|camera matrices]].  Triangulation is sometimes also referred to as '''reconstruction'''.

The triangulation problem is in theory trivial. Since each point in an image corresponds to a line in 3D space, all points on the line in 3D are projected to the point in the image.  If a pair of [[Correspondence problem|corresponding points]] in two, or more images, can be found it must be the case that they are the projection of a common 3D point '''x'''.  The set of lines generated by the image points must intersect at '''x'''  (3D point) and the algebraic formulation of the coordinates of '''x''' (3D point) can be computed in a variety of ways, as is presented below.

In practice, however, the coordinates of image points cannot be measured with arbitrary accuracy.  Instead, various types of noise, such as geometric noise from lens distortion or interest point detection error, lead to inaccuracies in the measured image coordinates.  As a consequence, the lines generated by the corresponding image points do not always intersect in 3D space.  The problem, then, is to find a 3D point which optimally fits the measured image points.  In the literature there are multiple proposals for how to define optimality and how to find the optimal 3D point.  Since they are based on different optimality criteria, the various methods produce different estimates of the 3D point '''x''' when noise is involved.

== Introduction ==

In the following, it is assumed that triangulation is made on corresponding image points from two views generated by [[pinhole camera model|pinhole cameras]].  Generalization from these assumptions are discussed [[#More than two views|here]].

[[File:TriangulationIdeal.svg|thumb|380px|left|The ideal case of epipolar geometry. A 3D point '''x''' is projected onto two camera images through lines (green) which intersect with each camera's focal point, '''O&lt;sub&gt;1&lt;/sub&gt;''' and '''O&lt;sub&gt;2&lt;/sub&gt;'''. The resulting image points are '''y&lt;sub&gt;1&lt;/sub&gt;''' and '''y&lt;sub&gt;2&lt;/sub&gt;'''. The green lines intersect at '''x'''.]]
[[File:TriangulationReal.svg|thumb|380px|right|In practice, the image points '''y&lt;sub&gt;1&lt;/sub&gt;''' and '''y&lt;sub&gt;2&lt;/sub&gt;''' cannot be measured with arbitrary accuracy. Instead points '''y'&lt;sub&gt;1&lt;/sub&gt;''' and '''y'&lt;sub&gt;2&lt;/sub&gt;''' are detected and used for the triangulation. The corresponding projection lines (blue) do not, in general, intersect in 3D space and may also not intersect with point '''x'''.]]

The image to the left illustrates the [[epipolar geometry]] of a pair of stereo cameras of [[pinhole camera model|pinhole model]].  A point '''x''' (3D point) in 3D space is projected onto the respective image plane along a line (green) which goes through the camera's [[Focus (optics)|focal point]], &lt;math&gt; \mathbf{O}_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{O}_{2} &lt;/math&gt;, resulting in the two corresponding image points &lt;math&gt; \mathbf{y}_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}_{2} &lt;/math&gt;.  If &lt;math&gt; \mathbf{y}_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}_{2} &lt;/math&gt; are given and the geometry of the two cameras are known, the two projection lines (green lines) can be determined and it must be the case that they intersect at point '''x''' (3D point).Using basic [[linear algebra]] that intersection point can be determined in a straightforward way.

The image to the right shows the real case.  The position of the image points &lt;math&gt; \mathbf{y}_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}_{2} &lt;/math&gt; cannot be measured exactly.  The reason is a combination of factors such as 

* Geometric distortion, for example [[Distortion (optics)|lens distortion]], which means that the 3D to 2D mapping of the camera deviates from the [[pinhole camera model]].  To some extent these errors can be compensated for, leaving a residual geometric error.
* A single ray of light from '''x''' (3D point) is dispersed in the lens system of the cameras according to a [[point spread function]].  The recovery of the corresponding image point from measurements of the dispersed intensity function in the images gives errors.
* In digital camera the image intensity function is only measured in discrete sensor elements.  Inexact interpolation of the discrete intensity function have to be used to recover the true one.
* The image points '''y&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;'&lt;/sup&gt;''' and '''y&lt;sub&gt;2&lt;/sub&gt;'''' used for triangulation are often found using various types of feature extractors, for example of corners or interest points in general.  There is an inherent localization error for any type of feature extraction based on [[neighborhood operation]]s.

As a consequence, the measured image points are &lt;math&gt; \mathbf{y}'_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}'_{2} &lt;/math&gt; instead of &lt;math&gt; \mathbf{y}_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}_{2} &lt;/math&gt;.  However, their projection lines (blue) do not have to intersect in 3D space or come close to '''x'''.  In fact, these lines intersect if and only if &lt;math&gt; \mathbf{y}'_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}'_{2} &lt;/math&gt; satisfy the [[epipolar constraint]] defined by the [[fundamental matrix (computer vision)|fundamental matrix]].  Given the measurement noise in &lt;math&gt; \mathbf{y}'_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}'_{2} &lt;/math&gt; it is rather likely that the epipolar constraint is not satisfied and the projection lines do not intersect.

This observation leads to the problem which is solved in triangulation.  Which 3D point '''x&lt;sub&gt;est&lt;/sub&gt;''' is the best estimate of '''x''' given &lt;math&gt; \mathbf{y}'_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}'_{2} &lt;/math&gt; and the geometry of the cameras?  The answer is often found by defining an error measure which depends on '''x&lt;sub&gt;est&lt;/sub&gt;''' and then minimize this error.  In the following some of the various methods for computing '''x&lt;sub&gt;est&lt;/sub&gt;''' presented in the literature are briefly described.

All triangulation methods produce '''x&lt;sub&gt;est&lt;/sub&gt;''' = '''x''' in the case that &lt;math&gt; \mathbf{y}_{1} = \mathbf{y}'_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}_{2} = \mathbf{y}'_{2} &lt;/math&gt;, that is, when the epipolar constraint is satisfied (except for singular points, see below).  It is what happens when the constraint is not satisfied which differs between the methods.

== Properties of triangulation methods ==

A triangulation method can be described in terms of a function &lt;math&gt; \tau \, &lt;/math&gt; such that

:&lt;math&gt; \mathbf{x} \sim \tau(\mathbf{y}'_{1}, \mathbf{y}'_{2}, \mathbf{C}_{1}, \mathbf{C}_{2}) &lt;/math&gt;

where &lt;math&gt; \mathbf{y}'_{1}, \mathbf{y}'_{2} &lt;/math&gt; are the homogeneous coordinates of the detected image points and &lt;math&gt; \mathbf{C}_{1}, \mathbf{C}_{2} &lt;/math&gt; are the camera matrices.  '''x''' (3D point) is the homogeneous representation of the resulting 3D point.  The &lt;math&gt; \sim \, &lt;/math&gt; sign implies that &lt;math&gt; \tau \, &lt;/math&gt; is only required to produce a vector which is equal to '''x''' up to a multiplication by a non-zero scalar since homogeneous vectors are involved.

Before looking at the specific methods, that is, specific functions &lt;math&gt; \tau \, &lt;/math&gt;, there are some general concepts related to the methods that need to be explained.  Which triangulation method is chosen for a particular problem depends to some extent on these characteristics.

=== Singularities ===

Some of the methods fail to correctly compute an estimate of '''x''' (3D point) if it lies in a certain subset of the 3D space, corresponding to some combination of &lt;math&gt; \mathbf{y}'_{1}, \mathbf{y}'_{2}, \mathbf{C}_{1}, \mathbf{C}_{2} &lt;/math&gt;.  A point in this subset is then a ''singularity'' of the triangulation method.  The reason for the failure can be that some equation system to be solved is under-determined or that the projective representation of '''x&lt;sub&gt;est&lt;/sub&gt;''' becomes the zero vector for the singular points.

=== Invariance ===

In some applications, it is desirable that the triangulation is independent of the coordinate system used to represent 3D points; if the triangulation problem is formulated in one coordinate system and then transformed into another the resulting estimate '''x&lt;sub&gt;est&lt;/sub&gt;''' should transform in the same way.  This property is commonly referred to as ''invariance''.  Not every triangulation method assures invariance, at least not for general types of coordinate transformations.

For a homogeneous representation of 3D coordinates, the most general transformation is a projective transformation, represented by a &lt;math&gt; 4 \times 4 &lt;/math&gt; matrix &lt;math&gt; \mathbf{T} &lt;/math&gt;.  If the homogeneous coordinates are transformed according to

:&lt;math&gt; \mathbf{\bar x} \sim \mathbf{T} \, \mathbf{x} &lt;/math&gt;

then the camera matrices must transform as ('''C&lt;sub&gt;k&lt;/sub&gt;''')

:&lt;math&gt; \mathbf{\bar C}_{k} \sim \mathbf{C}_{k} \, \mathbf{T}^{-1} &lt;/math&gt;

to produce the same homogeneous image coordinates ('''y&lt;sub&gt;k&lt;/sub&gt;''')

:&lt;math&gt; \mathbf{y}_{k} \sim \mathbf{\bar C}_{k} \, \mathbf{\bar x} = \mathbf{C}_{k} \, \mathbf{x} &lt;/math&gt;

If the triangulation function &lt;math&gt; \tau &lt;/math&gt; is invariant to &lt;math&gt; \mathbf{T} &lt;/math&gt; then the following relation must be valid

:&lt;math&gt; \mathbf{\bar x}_{\rm est} \sim \mathbf{T} \, \mathbf{x}_{\rm est} &lt;/math&gt;

from which follows that

:&lt;math&gt; \tau(\mathbf{y}'_{1}, \mathbf{y}'_{2}, \mathbf{C}_{1}, \mathbf{C}_{2}) \sim \mathbf{T}^{-1} \, \tau(\mathbf{y}'_{1}, \mathbf{y}'_{2}, \mathbf{C}_{1} \, \mathbf{T}^{-1}, \mathbf{C}_{2} \, \mathbf{T}^{-1}), &lt;/math&gt; &amp;nbsp; for all &lt;math&gt; \mathbf{y}'_{1}, \mathbf{y}'_{2} &lt;/math&gt;

For each triangulation method, it can be determined if this last relation is valid.  If it is, it may be satisfied only for a subset of the projective transformations, for example, rigid or affine transformations.

=== Computational complexity ===

The function &lt;math&gt; \tau &lt;/math&gt; is only an abstract representation of a computation which, in practice, may be relatively complex.  Some methods result in a &lt;math&gt; \tau &lt;/math&gt; which is a closed-form continuous function while others need to be decomposed into a series of computational steps involving, for example, [[singular value decomposition|SVD]] or finding the roots of a polynomial.  Yet another class of methods results in &lt;math&gt; \tau &lt;/math&gt; which must rely on iterative estimation of some parameters.  This means that both the computation time and the complexity of the operations involved may vary between the different methods.

== Some triangulation methods found in the literature ==

=== Mid-point method ===

Each of the two image points &lt;math&gt; \mathbf{y}'_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{y}'_{2} &lt;/math&gt; has a corresponding projection line (blue in the right image above), here denoted as &lt;math&gt; \mathbf{L}'_{1} &lt;/math&gt; and &lt;math&gt; \mathbf{L}'_{2} &lt;/math&gt;, which can be determined given the camera matrices &lt;math&gt; \mathbf{C}_{1}, \mathbf{C}_{2} &lt;/math&gt;.  Let &lt;math&gt; d\, &lt;/math&gt; be a distance function between a (3D line) '''L&lt;sub&gt;1&lt;/sub&gt;'''' and a '''x''' (3D point) such that

:&lt;math&gt; d(\mathbf{L}, \mathbf{x}) = &lt;/math&gt; &amp;nbsp; the Euclidean distance between &lt;math&gt; \mathbf{L} &lt;/math&gt; and &lt;math&gt; \mathbf{x} &lt;/math&gt;.

The midpoint method finds the point '''x&lt;sub&gt;est&lt;/sub&gt;''' which minimizes

:&lt;math&gt; d(\mathbf{L}'_{1}, \mathbf{x})^{2} + d(\mathbf{L}'_{2}, \mathbf{x})^{2} &lt;/math&gt;

It turns out that '''x&lt;sub&gt;est&lt;/sub&gt;''' lies exactly at the middle of the shortest line segment which joins the two projection lines.

=== Direct linear transformation ===
{{main|Direct linear transformation}}

=== Via the essential matrix ===

=== Optimal triangulation ===

== References ==

* {{cite book
| author=Richard Hartley and Andrew Zisserman
| title=Multiple View Geometry in computer vision
| publisher=Cambridge University Press
| year=2003
| isbn=978-0-521-54051-3}}

[[Category:Geometry in computer vision]]
[[Category:Stereophotogrammetry]]</text>
      <sha1>6h9q0kr4vwhopm2vyg1l8jotju2y6fx</sha1>
    </revision>
  </page>
  <page>
    <title>Whittaker and Watson</title>
    <ns>0</ns>
    <id>47264026</id>
    <redirect title="A Course of Modern Analysis" />
    <revision>
      <id>703919359</id>
      <parentid>671900389</parentid>
      <timestamp>2016-02-08T13:01:51Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cats</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="165">#REDIRECT [[A Course of Modern Analysis]] {{R from alternative title}}

[[Category:1902 books]]
[[Category:Mathematics textbooks]]
[[Category:Mathematical analysis]]</text>
      <sha1>2466xcqb6jnts7t5i7yeh52pbpadver</sha1>
    </revision>
  </page>
  <page>
    <title>Yutaka Taniyama</title>
    <ns>0</ns>
    <id>1077843</id>
    <revision>
      <id>850690236</id>
      <parentid>847400415</parentid>
      <timestamp>2018-07-17T13:17:40Z</timestamp>
      <contributor>
        <username>Myasuda</username>
        <id>1187538</id>
      </contributor>
      <minor/>
      <comment>/* Depression and death */ sp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6659">{{ Infobox scientist
|name = Yutaka Taniyama
|image = Yutaka_Taniyama.png
|birth_date = {{Birth date|df=yes|1927|11|12}}
|birth_place = [[Kisai]] near [[Tokyo]], [[Japan]]
|death_date = {{Death date and age|df=yes|1958|11|17|1927|11|12}}
|death_place = [[Tokyo]], [[Japan]]
|fields = [[Mathematics]]
}}
'''Yutaka Taniyama''' (Japanese: 谷山 豊 ''Taniyama Yutaka'';&lt;ref&gt;Taniyama's given name 豊 was intended to be read as ''Toyo'', but was frequently misread as the more common form ''Yutaka'', which he eventually adopted as his own name.&lt;/ref&gt; 12 November 1927, [[Kisai]] near Tokyo – 17 November 1958, Tokyo) was a Japanese [[mathematician]] known for the [[Modularity theorem|Taniyama–Shimura conjecture]].

==Contribution==
Taniyama was best known for conjecturing, in modern language, automorphic properties of [[L-function]]s of [[elliptic curves]] over any number field. A partial and refined case of this conjecture for elliptic curves over rationals is called the Taniyama–Shimura conjecture or the [[modularity theorem]] whose statement he subsequently refined in collaboration with [[Goro Shimura]]. The names Taniyama, Shimura and [[André Weil|Weil]] have all been attached to this conjecture, but the idea is essentially due to Taniyama.

In 1986 [[Kenneth Alan Ribet|Ribet]] proved that if the [[Taniyama–Shimura conjecture]] held, then so would [[Fermat's last theorem]], which inspired [[Andrew Wiles]] to work for a number of years in secrecy on it, and to prove enough of it to prove Fermat's Last Theorem. Owing to the pioneering contribution of Wiles and the efforts of a number of mathematicians the Taniyama–Shimura conjecture was finally proven in 1999. The original Taniyama conjecture for elliptic curves over arbitrary number fields remains open.

==Depression and death==
In 1958, Taniyama worked for University of Tokyo as an assistant (joshu), was engaged, and was offered a position at the Institute for Advanced Study, Princeton, New Jersey. On 17 November 1958, Taniyama committed suicide. He left a note explaining how far he had progressed with his teaching duties, and apologizing to his colleagues for the trouble he was causing them. His suicide note read:
&lt;blockquote&gt;Until yesterday I had no definite intention of killing myself. But more than a few must have noticed that lately I have been tired both physically and mentally. As to the cause of my suicide, I don't quite understand it myself, but it is not the result of a particular incident, nor of a specific matter. Merely may I say, I am in the frame of mind that I lost confidence in my future. There may be someone to whom my suicide will be troubling or a blow to a certain degree. I sincerely hope that this incident will cast no dark shadow over the future of that person. At any rate, I cannot deny that this is a kind of betrayal, but please excuse it as my last act in my own way, as I have been doing my own way all my life.&lt;/blockquote&gt;

Although his note is mostly enigmatic it does mention tiredness and a loss of confidence in his future. Taniyama's ideas had been criticized as unsubstantiated and his behavior had occasionally been deemed peculiar. Goro Shimura mentioned that he suffered from depression. Taniyama also mentioned in the note his concern that some might be harmed by his suicide and his hope that the act would not cast "a dark shadow over that person."

About a month later, Misako Suzuki, the woman whom he was planning to marry, also committed suicide, leaving a note reading:
"We promised each other that no matter where we went, we would never be separated. Now that he is gone, I must go too in order to join him."

After Taniyama's death, [[Goro Shimura]] stated that:
&lt;blockquote&gt;He was always kind to his colleagues, especially to his juniors, and he genuinely cared about their welfare. He was the moral support of many of those who came into mathematical contact with him, including of course myself. Probably he was never conscious of this role he was playing. But I feel his noble generosity in this respect even more strongly now than when he was alive. And yet nobody was able to give him any support when he desperately needed it. Reflecting on this, I am overwhelmed by the bitterest grief.&lt;/blockquote&gt;

In a 2011 [[TED (conference)|TED]] talk by English economist [[Tim Harford]] titled, "Trial, error and the God complex," Taniyama is referenced as a mathematician who was ultimately unable to prove his conjecture during his lifetime. Reflecting on Taniyama's work, Goro Shimura stated:
&lt;blockquote&gt;He was not a very careful person as a mathematician. He made a lot of mistakes. But he made mistakes in a good direction. I tried to imitate him. But I've realized that it's very difficult to make good mistakes.  &lt;"Fermat's Last Theorem," Horizon, 1995&gt;&lt;/blockquote&gt;

==See also==

*[[Taniyama group]]

==Notes==
&lt;references /&gt;

==Publications==

*{{citation|mr=0125113 |last=Shimura|first= Goro|last2= Taniyama|first2= Yutaka |title=Complex multiplication of abelian varieties and its applications to number theory|series= Publications of the Mathematical Society of Japan|volume= 6|publisher= The Mathematical Society of Japan|place= Tokyo|year= 1961}} This book is hard to find, but an expanded version was later published as {{Cite book|first=Goro|last=Shimura|year=1997|title=Abelian Varieties with Complex Multiplication and Modular Functions|edition=Hardcover|publisher=Princeton University Press |isbn=978-0-691-01656-6|url=http://press.princeton.edu/titles/6242.html}}

==References==

*{{citation |  last1=Shimura | first1=Goro | title=Yutaka Taniyama and his time. Very personal recollections | doi=10.1112/blms/21.2.186 | year=1989 | journal=The Bulletin of the London Mathematical Society | issn=0024-6093 | volume=21 | issue=2 | pages=186–196 |  mr=976064}}
* [[Simon Singh|Singh, Simon]] (hardcover, 1998). ''[[Fermat's Enigma]]''. Bantam Books. {{isbn|0-8027-1331-9}} (previously published under the title ''Fermat's Last Theorem'').
*{{Citation | last1=Weil | first1=André | author1-link=André Weil | title=Y. Taniyama | id=Reprinted in Weil's collected works, volume II | journal=Sugaku-no Ayumi | volume=6 | issue=4 | pages=21–22}}

==External links==
* {{MacTutor Biography|id=Taniyama}}

{{Authority control}}
{{DEFAULTSORT:Taniyama, Yutaka}}
[[Category:1927 births]]
[[Category:1958 deaths]]
[[Category:People from Saitama Prefecture]]
[[Category:20th-century Japanese mathematicians]]
[[Category:Number theorists]]
[[Category:Mathematicians who committed suicide]]
[[Category:Japanese scientists]]
[[Category:University of Tokyo alumni]]
[[Category:Suicides in Japan]]</text>
      <sha1>nr9vr43f7or0b65f1icv4zfso2posfq</sha1>
    </revision>
  </page>
  <page>
    <title>Ψ₀(Ωω)</title>
    <ns>0</ns>
    <id>24632336</id>
    <revision>
      <id>791438244</id>
      <parentid>791437239</parentid>
      <timestamp>2017-07-20T08:03:28Z</timestamp>
      <contributor>
        <username>JRSpriggs</username>
        <id>1026643</id>
      </contributor>
      <comment>revert two edits by 115.64.145.102 as vandalism and spam</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1627">{{DISPLAYTITLE:Ψ₀(Ω&lt;sub&gt;ω&lt;/sub&gt;)}}
{{No footnotes|date=July 2016}}
In mathematics, '''Ψ&lt;sub&gt;0&lt;/sub&gt;(Ω&lt;sub&gt;ω&lt;/sub&gt;)''' is a [[large countable ordinal]] that is used to measure the [[proof-theoretic strength]] of some mathematical systems.  In particular, it is the proof theoretic ordinal of the subsystem &lt;math&gt;\Pi_1^1&lt;/math&gt;-CA&lt;sub&gt;0&lt;/sub&gt; of [[second-order arithmetic]]; this is one of the "big five" subsystems studied in [[reverse mathematics]] (Simpson 1999).

==Definition==
{{Main article|Ordinal collapsing function}}
* &lt;math&gt;\Omega_0 = 0&lt;/math&gt;, and &lt;math&gt;\Omega_n  = \aleph_n&lt;/math&gt; for ''n'' &gt; 0.
* &lt;math&gt;C_i(\alpha)&lt;/math&gt; is the smallest set of ordinals that contains &lt;math&gt;\Omega_n&lt;/math&gt; for ''n'' finite, and contains all ordinals less than &lt;math&gt;\Omega_i&lt;/math&gt;, and is closed under ordinal addition and exponentiation, and contains &lt;math&gt;\Psi_j(\xi)&lt;/math&gt; if ''j'' ≥ ''i'' and &lt;math&gt;\xi \in C_i(\alpha)&lt;/math&gt; and &lt;math&gt;\xi &lt; \alpha&lt;/math&gt;.
* &lt;math&gt;\Psi_i(\alpha)&lt;/math&gt; is the smallest ordinal not in &lt;math&gt;C_i(\alpha)&lt;/math&gt;

==References==
* G. Takeuti, ''Proof theory'', 2nd edition 1987 {{isbn|0-444-10492-5}}
* K. Schütte, ''Proof theory'', Springer 1977 {{isbn|0-387-07911-4}}
* {{Citation | last1=Simpson | first1=Stephen G. | title=Subsystems of second order arithmetic | url=http://www.math.psu.edu/simpson/sosoa/ | publisher=[[Cambridge University Press]] | edition=2nd | series=Perspectives in Logic | isbn=978-0-521-88439-6 |mr=2517689 | year=2009}}

{{countable ordinals}}

{{DEFAULTSORT:Psi0(Omega Omega)}}
[[Category:Ordinal numbers]]
[[Category:Proof theory]]


{{Settheory-stub}}</text>
      <sha1>asd0w4ffag85vxyfa2tduy6w94xaix9</sha1>
    </revision>
  </page>
</mediawiki>
