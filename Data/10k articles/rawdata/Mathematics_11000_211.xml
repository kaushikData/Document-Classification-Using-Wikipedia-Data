<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>9</title>
    <ns>0</ns>
    <id>173457</id>
    <revision>
      <id>870456362</id>
      <parentid>869405665</parentid>
      <timestamp>2018-11-24T23:05:31Z</timestamp>
      <contributor>
        <username>Amanouz</username>
        <id>15535549</id>
      </contributor>
      <comment>/* Places and thoroughfares */ Expanding article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24923">{{About|the number|the year|AD 9|other uses|9 (disambiguation)|and|Number nine (disambiguation)}}
{{Infobox number
|number=9
|numeral=[[nonary]]
|divisor=1, 3, 9
|unicode=Ⅸ, ⅸ

|greek prefix=[[Wiktionary:ennea-|ennea-]]
|latin prefix=[[Wiktionary:nona-|nona-]]
|lang1=[[Amharic language|Amharic]]
|lang1 symbol=&lt;span style="font-size:100%;"&gt;፱&lt;/span&gt;
|lang2=[[Arabic language|Arabic]] &amp; [[Central Kurdish|Kurdish]]
|lang2 symbol=&lt;span style="font-size:150%;"&gt;٩&lt;/span&gt;
|lang3=[[Urdu]]
|lang3 symbol={{Urdu numeral|9|20}}
|lang4=[[Armenian numerals|Armenian numeral]]
|lang4 symbol=&lt;span style="font-size:150%;"&gt;Թ&lt;/span&gt;
|lang5=[[Bengali language|Bengali]]
|lang5 symbol=&lt;span style="font-size:150%;"&gt;৯&lt;/span&gt;
|lang6=[[Chinese numerals|Chinese/Japanese&lt;br/&gt;/Korean numeral]]
|lang6 symbol=九&lt;br/&gt;玖
|lang7=[[Devanāgarī]]
|lang7 symbol=&lt;span style="font-size:150%;"&gt;९&lt;/span&gt;
|lang8=[[Greek numerals|Greek numeral]]
|lang8 symbol=θ´
|lang9=[[Hebrew numerals|Hebrew numeral]]
|lang9 symbol=&lt;span style="font-size:150%;"&gt;ט&lt;/span&gt;
|lang10=[[Tamil numerals]]
|lang10 symbol=&lt;span style="font-size:150%;"&gt;௯&lt;/span&gt;
|lang11=[[Khmer numerals|Khmer]]
|lang11 symbol=៩
|lang12=[[Telugu language|Telugu numeral]]
|lang12 symbol=&lt;span style="font-size:150%;"&gt;౯&lt;/span&gt;
|lang13=[[Thai numerals|Thai numeral]]
|lang13 symbol=&lt;span style="font-size:150%;"&gt;๙&lt;/span&gt;}}
{{Wiktionary|nine}}
'''9''' ('''nine''') is the [[natural number]] following {{num|8}} and preceding {{num|10}}.

==Mathematics==
9 is a [[composite number]], its proper [[divisor]]s being {{num|1}} and {{num|3}}. It is 3 times 3 and hence the third [[square number]]. Nine is a [[Motzkin number]].&lt;ref&gt;{{Cite web |url=https://oeis.org/A001006 |title=Sloane's A001006 : Motzkin numbers |last= |first= |date= |website=The On-Line Encyclopedia of Integer Sequences |publisher=OEIS Foundation |access-date=2016-06-01}}&lt;/ref&gt; It is the first composite [[lucky number]], along with the first composite odd number and only single-digit composite odd number.

9 is the only positive [[perfect power]] that is one more than another positive perfect power, by [[Catalan conjecture|Mihăilescu's Theorem]].

9 is the highest single-digit number in the [[decimal|decimal system]]. It is the second non-unitary square [[prime number|prime]] of the form (''p''&lt;sup&gt;2&lt;/sup&gt;) and the first that is odd. All subsequent squares of this form are odd.

Since {{nowrap|1=9 = 3&lt;sup&gt;2&lt;sup&gt;1&lt;/sup&gt;&lt;/sup&gt;}}, 9 is an [[exponential factorial]].&lt;ref&gt;{{Cite web |url=https://oeis.org/A049384 |title=Sloane's A049384 : a(0)=1, a(n+1) = (n+1)^a(n) |last= |first= |date= |website=The On-Line Encyclopedia of Integer Sequences |publisher=OEIS Foundation |access-date=2016-06-01}}&lt;/ref&gt;

A [[polygon]] with nine sides is called a [[nonagon]] or enneagon.&lt;ref&gt;Robert Dixon, ''Mathographics''. New York: Courier Dover Publications: 24&lt;/ref&gt; A group of nine of anything is called an ennead.

In [[decimal|base 10]] a positive number is divisible by 9 [[if and only if]] its [[digital root]] is 9.&lt;ref&gt;[[Martin Gardner]], ''A Gardner's Workout: Training the Mind and Entertaining the Spirit''. New York: A. K. Peters (2001): 155&lt;/ref&gt; That is, if any [[natural number]] is multiplied by 9, and the digits of the answer are repeatedly added until it is just one digit, the sum will be nine:
*2 × 9 = 18 (1 + 8 = 9)
*3 × 9 = 27 (2 + 7 = 9)
*9 × 9 = 81 (8 + 1 = 9)
*121 × 9 = 1089 (1 + 0 + 8 + 9 = 18; 1 + 8 = 9)
*234 × 9 = 2106 (2 + 1 + 0 + 6 = 9)
*578329 × 9 = 5204961 (5 + 2 + 0 + 4 + 9 + 6 + 1 = 27; 2 + 7 = 9)
*482729235601 × 9 = 4344563120409 (4 + 3 + 4 + 4 + 5 + 6 + 3 + 1 + 2 + 0 + 4 + 0 + 9 = 45; 4 + 5 = 9)

There are other interesting patterns involving multiples of nine:
*12345679 × 9 = 111111111
*12345679 × 18 = 222222222
*12345679 × 81 = 999999999

This works for all the multiples of 9. {{nowrap|1=''n'' = {{num|3}}}} is the only other {{nowrap|''n'' &gt; 1}} such that a number is divisible by ''n'' if and only if its digital root is divisible by ''n''. In [[positional notation|base-''N'']], the [[divisor]]s of {{nowrap|''N'' − 1}} have this property. Another consequence of 9 being {{nowrap|10 − 1}}, is that it is also a [[Kaprekar number]].

The difference between a base-10 positive integer and the sum of its digits is a whole multiple of nine. Examples:
*The sum of the digits of 41 is 5, and 41 − 5 = 36. The digital root of 36 is 3 + 6 = 9, which, as explained above, demonstrates that it is divisible by nine.
*The sum of the digits of 35967930 is 3 + 5 + 9 + 6 + 7 + 9 + 3 + 0 = 42, and 35967930 − 42 = 35967888. The digital root of 35967888 is 3 + 5 + 9 + 6 + 7 + 8 + 8 + 8 = 54, 5 + 4 = 9.

[[Casting out nines]] is a quick way of testing the calculations of sums, differences, products, and quotients of integers, known as long ago as the 12th&amp;nbsp;century.&lt;ref&gt;[[Cajori, Florian]] (1991, 5e) ''A History of Mathematics'', AMS. {{ISBN|0-8218-2102-4}}. p.91&lt;/ref&gt;

Six recurring nines appear in the decimal places 762 through 767 of [[pi|{{pi}}]], see [[Six nines in pi]].

If dividing a number by the amount of 9s corresponding to its number of digits, the number is turned into a [[repeating decimal]]. (e.g. {{nowrap|1={{sfrac|274|999}} = 0.274274274274...}})

There are nine [[Heegner number]]s.&lt;ref&gt;Bryan Bunch, ''The Kingdom of Infinite Number''. New York: W. H. Freeman &amp; Company (2000): 93&lt;/ref&gt;

===Probability===
In [[probability]], the '''nine''' is a [[logarithmic measure]] of the probability of an event, defined as the negative of the base-{{num|10}} [[logarithm]] of the probability of the event's [[Probability axioms|complement]].{{citation needed|date=October 2016}} For example, an event that is 99% likely to occur has an unlikelihood of 1% or 0.01, which amounts to {{nowrap|1=−log&lt;sub&gt;10&lt;/sub&gt; 0.01 = 2 nines}} of probability. [[Zero]] probability gives zero nines {{nowrap|1=(−log&lt;sub&gt;10&lt;/sub&gt; 1 = 0)}}. A 100% probability is considered to be impossible in most circumstances: that results in [[infinite improbability]]. The effectivity of processes and the [[availability]] of [[systems]] can be expressed (as a rule of thumb, not explicitly) as a series of "nines". For example, [[5 nines|"five nines" (99.999%)]] availability implies a total [[downtime]] of no more than five minutes per year&amp;nbsp;– typically a very high degree of [[:wikt:reliability|reliability]]; but never 100%.

==List of basic calculations==
{|class="wikitable" style="text-align: center; background: white"
|-
! style="width:105px;"|[[Multiplication]]
!1
!2
!3
!4
!5
!6
!7
!8
!9
!10
! style="width:5px;"|
!20
!25
!50
!100
!1000
|-
|'''9 × ''x'''''
|'''9'''
|[[18 (number)|18]]
|[[27 (number)|27]]
|[[36 (number)|36]]
|[[45 (number)|45]]
|[[54 (number)|54]]
|[[63 (number)|63]]
|[[72 (number)|72]]
|[[81 (number)|81]]
|[[90 (number)|90]]
!
|[[180 (number)|180]]
|[[225 (number)|225]]
|450
|[[900 (number)|900]]
|[[9000 (number)|9000]]
|}

{|class="wikitable" style="text-align: center; background: white"
|-
! style="width:105px;"|[[Division (mathematics)|Division]]
!1
!2
!3
!4
!5
!6
!7
!8
!9
!10
! style="width:5px;"|
!11
!12
!13
!14
!15
|-
|'''9 ÷ ''x'''''
|'''9'''
|4.5
|3
|2.25
|1.8
|1.5
|1.{{overline|285714}}
|1.125
|1
|0.9
!
|0.{{overline|81}}
|0.75
|0.{{overline|692307}}
|0.6{{overline|428571}}
|0.6
|-
|''''x'' ÷ 9'''
|0.{{overline|1}}
|0.{{overline|2}}
|0.{{overline|3}}
|0.{{overline|4}}
|0.{{overline|5}}
|0.{{overline|6}}
|0.{{overline|7}}
|0.{{overline|8}}
|1
|1.{{overline|1}}
!
|1.{{overline|2}}
|1.{{overline|3}}
|1.{{overline|4}}
|1.{{overline|5}}
|1.{{overline|6}}
|}

{|class="wikitable" style="text-align: center; background: white"
|-
! style="width:105px;"|[[Exponentiation]]
!1
!2
!3
!4
!5
!6
!7
!8
!9
!10
|-
|'''9{{sup|''x''}}'''
|'''9'''
|81
|729
|6561
|59049
|531441
|4782969
|43046721
|387420489
|3486784401
|-
|'''''x''{{sup|9}}'''
|1
|[[512 (number)|512]]
|19683
|262144
|1953125
|10077696
|40353607
|134217728
|387420489
|[[1000000000 (number)|1000000000]]
|}

{|class="wikitable" style="text-align: center; background: white"
|-
! rowspan="2" style="width:105px;"|[[Radix]]
!1
!5
!10
!15
!20
!25
!30
&lt;!--
!35
--&gt;
!40
&lt;!--
!45
--&gt;
!50
!60
!70
!80
!90
!100
|-
!110
!120
!130
!140
!150
&lt;!--
!160
!170
!180
!190
--&gt;
!200
!250
!500
!1000
!10000
!100000
!1000000
|
|
|-
|rowspan="2"|'''''x''{{sub|9}}
|1
|5
|11&lt;sub&gt;9&lt;/sub&gt;
|16&lt;sub&gt;9&lt;/sub&gt;
|22&lt;sub&gt;9&lt;/sub&gt;
|27&lt;sub&gt;9&lt;/sub&gt;
|33&lt;sub&gt;9&lt;/sub&gt;
|44&lt;sub&gt;9&lt;/sub&gt;
|55&lt;sub&gt;9&lt;/sub&gt;
|66&lt;sub&gt;9&lt;/sub&gt;
|77&lt;sub&gt;9&lt;/sub&gt;
|88&lt;sub&gt;9&lt;/sub&gt;
|110&lt;sub&gt;9&lt;/sub&gt;
|121&lt;sub&gt;9&lt;/sub&gt;
|-
|132&lt;sub&gt;9&lt;/sub&gt;
|143&lt;sub&gt;9&lt;/sub&gt;
|154&lt;sub&gt;9&lt;/sub&gt;
|165&lt;sub&gt;9&lt;/sub&gt;
|176&lt;sub&gt;9&lt;/sub&gt;
|242&lt;sub&gt;9&lt;/sub&gt;
|307&lt;sub&gt;9&lt;/sub&gt;
|615&lt;sub&gt;9&lt;/sub&gt;
|1331&lt;sub&gt;9&lt;/sub&gt;
|14641&lt;sub&gt;9&lt;/sub&gt;
|162151&lt;sub&gt;9&lt;/sub&gt;
|1783661&lt;sub&gt;9&lt;/sub&gt;
|}

==Evolution of the glyph==
{{See also|Hindu-Arabic numeral system}}
According to Georges Ifrah, the origin of the 9 integers can be attributed to ancient Indian civilization, and was adopted by subsequent civilizations in conjunction with the {{num|0}}.&lt;ref&gt;{{cite book |title=From One to Zero: A Universal History of Numbers |year=1985 |author=Georges Ifrah |publisher=Viking |isbn=0-670-37395-8}}&lt;/ref&gt;

[[File:Evo9glyph.svg|x50px|right]]
In the beginning, various Indians wrote 9 similar to the modern closing question mark without the bottom dot. The Kshatrapa, Andhra and Gupta started curving the bottom vertical line coming up with a {{num|3}}-look-alike. The Nagari continued the bottom stroke to make a circle and enclose the 3-look-alike, in much the same way that the ''@'' character encircles a lowercase ''a''. As time went on, the enclosing circle became bigger and its line continued beyond the circle downwards, as the 3-look-alike became smaller. Soon, all that was left of the 3-look-alike was a squiggle. The Arabs simply connected that squiggle to the downward stroke at the middle and subsequent European change was purely cosmetic.

While the shape of the 9 character has an [[Ascender (typography)|ascender]] in most modern [[typeface]]s, in typefaces with [[text figures]] the character usually has a [[descender]], as, for example, in [[File:TextFigs196.png]].

This numeral resembles an inverted ''6''. To disambiguate the two on objects and documents that can be inverted, the 9 is often underlined, as is done for the 6. Another distinction from the 6 is that it is sometimes handwritten with a straight stem, resembling a raised lower-case letter '''q'''.

==Alphabets and codes==
*In the [[NATO phonetic alphabet]], the digit 9 is called "Niner".
*Five-digit [[produce]] [[Price Look-Up code|PLU codes]] that begin with 9 are [[Organic food|organic]].

==Commerce==
*Common terminal digit in [[psychological pricing]].

==Culture and mythology==
===Indian culture===
{{unreferenced section|date=April 2015}}
Nine is a number that appears often in [[Indian culture]] and mythology. Some instances are enumerated below.
*Nine [[Navagraha|influencers]] are attested in [[Indian astrology]].
*In the [[Vaisheshika]] branch of [[Hindu philosophy]], there are nine universal substances or elements: [[Prithvi|Earth]], [[Ap (water)|Water]], [[Vayu|Air]], [[Agni|Fire]], [[Akasha|Ether]], [[Kāla (time)|Time]], [[Vaisheshika#The Categories or Pad.C4.81rtha|Space]], [[Ātman (Hinduism)|Soul]], and [[Manas (early Buddhism)|Mind]].
*[[Navaratri]] is a nine-day festival dedicated to the [[Navadurga|nine]] forms of [[Durga]].
*[[Navaratna]], meaning "nine jewels" may also refer to [[Navaratnas]] – accomplished courtiers, [[Korma#Navratan korma|Navratan]] – a kind of dish, or a form of [[Navaratna (architecture)|architecture]].
*According to [[Yoga]], the human body has nine doors – two eyes, two ears, the mouth, two nostrils, and the openings for defecation and procreation.
*In [[Indian aesthetics]], there are nine kinds of [[Rasa (aesthetics)|Rasa]].

===Chinese culture===
*Nine ({{lang|zh|九}} [[pinyin]] jiǔ) is considered a good [[Numbers in Chinese culture|number in Chinese culture]] because it sounds the same as the word "long-lasting" ({{lang|zh|久}} [[pinyin]] jiǔ).{{Citation needed|date=April 2008}}
*Nine is strongly associated with the [[Chinese dragon]], a symbol of magic and power. There are nine forms of the dragon, it is described in terms of nine attributes, and it has nine children. It has 117 scales&amp;nbsp;– 81 [[yin and yang|yang]] (masculine, heavenly) and 36 [[yin and yang|yin]] (feminine, earthly). All three numbers are multiples of 9 ({{nowrap|1=9 × 13 = 117}}, {{nowrap|1=9 × 9 = 81}}, {{nowrap|1=9 × 4 = 36}})&lt;ref&gt;{{cite book |title=Myths of China And Japan |author=Donald Alexander Mackenzie |url=https://books.google.com/books?id=vzbeLy4TBa4C&amp;pg=PA46&amp;dq=chinese+dragon+scales+yin+36 |publisher=Kessinger |year=2005 |isbn=1-4179-6429-4}}&lt;/ref&gt; as well as having the same [[digital root]] of 9.
*The dragon often symbolizes the [[Emperor of China|Emperor]], and the number nine can be found in many ornaments in the [[Forbidden City]].
*The circular altar platform (''Earthly Mount'') of the [[Temple of Heaven]] has one circular marble plate in the center, surrounded by a ring of nine plates, then by a ring of 18 plates, and so on, for a total of nine rings, with the outermost having {{nowrap|1=81 = 9 × 9 plates.}}
*The name of the area called ''[[Kowloon]]'' in [[Hong Kong]] literally means: ''nine [[Chinese dragon|dragons]]''.
*The [[nine-dotted line]] ({{zh|c=南海九段线|p=nánhǎi jiǔduàn xiàn|l=Nine-segment line of the South China Sea}}) delimits certain island [[Territorial disputes in the South China Sea|claims by China]] in the South China Sea.
*The [[nine-rank system]] was a civil service nomination system used during certain Chinese dynasties.
*9 Points of the [[Heart]] ([[Healing|Heal]]) / Heart Master ([[Immortality]]) Channels in [[Traditional Chinese Medicine]].

===Ancient Egypt===
*The [[nine bows]] is a term used in Ancient Egypt to represent the traditional enemies of Egypt.
*The [[Ennead]] is a group of nine Egyptian deities, who, in some versions of the [[Osiris myth]], judged whether [[Horus]] or [[Set (mythology)|Set]] should inherit Egypt.

===European culture===
*The [[Nine Worthies]] are nine historical, or semi-legendary figures who, in the Middle Ages, were believed to personify the ideals of chivalry.
*In [[Norse mythology]], the universe is divided into [[Norse cosmology|nine worlds]] which are all connected by the [[world tree]] [[Yggdrasil]]
*In [[Norse mythology]] as well, the number nine is associated with [[Odin]], as that is how many days he hung from the [[world tree]] [[Yggdrasil]] before attaining knowledge of the [[runes]].

===Greek mythology===
*The nine [[Muse]]s in Greek mythology are [[Calliope]] (epic poetry), [[Clio]] (history), [[Erato]] (erotic poetry), [[Euterpe]] (lyric poetry), [[Melpomene]] (tragedy), [[Polyhymnia]] (song), [[Terpsichore]] (dance), [[Thalia (muse)|Thalia]] (comedy), and [[Urania]] (astronomy).
*It takes nine days (for an anvil) to fall from heaven to earth, and nine more to fall from earth to [[Tartarus]].
*[[Leto]] labored for nine days and nine nights for [[Apollo]], according to the [[Homeric Hymn|Homeric Hymn to Delian Apollo]].

===Mesoamerican mythology===
* The [[Lords of the Night]], is a group of nine deities who each ruled over every ninth night forming a calendrical cycle

===Aztec mythology===
* [[Mictlan]] the underworld in Aztec mythology, consists of nine levels.

===Mayan mythology===
* The Mayan underworld [[Xibalba]] consists of nine levels. 
* [[El Castillo, Chichen_Itza|El Castillo]] the Mayan step-pyramid in [[Chichén Itzá]], consists of nine steps. It is said that this was done to represent the nine levels of [[Xibalba]].

==Anthropology==
===Idioms===
*"to go the whole nine yards-"
*"A [[cat-o'-nine-tails]] suggests perfect punishment and atonement." – [[Robert Ripley]].
*"A cat has nine lives"
*"to be on cloud nine"
*"A stitch in time saves nine"
*"found true 9 out of 10 times"
*"possession is nine tenths of the law"
*The word "K-9" pronounces the same as ''canine'' and is used in many [[United States|U.S.]] police departments to denote the [[police dog]] unit. Despite not sounding like the translation of the word ''canine'' in other languages, many police and military units around the world use the same designation.
*Someone dressed "to the nines" is dressed up as much as they can be.
*In North American [[urban culture]], "nine" is a [[slang]] word for a [[9mm]] [[pistol]] or [[homicide]], the latter from the Illinois Criminal Code for homicide.

===Society===
*''[[The 9 on Yahoo!]]'', hosted by [[Maria Sansone]], was a daily video compilation show, or vlog, on Yahoo! featuring the nine top "web finds" of the day.
*Nine justices sit on the [[United States Supreme Court]].

===Technique===
[[Image:ICS Niner.svg|right|thumb|100px|[[International maritime signal flag]] for 9]]
[[Image:9 playing cards.jpg|thumb|250px|[[Playing card]]s showing the 9 of all four suits]]
*[[Stanine]]s, a method of scaling test scores, range from 1 to 9.
*There are 9 [[Square foot|square feet]] in a [[square yard]].

==Literature==
*There are [[Divine Comedy#The Circles of Hell|nine circles of Hell]] in Dante's ''[[Divine Comedy]]''.
*The [[Nine Bright Shiners]], characters in Garth Nix's [[Old Kingdom trilogy]]. ''The Nine Bright Shiners'' was a 1930s book of poems by Anne Ridler&lt;ref&gt;{{cite book |title=Women's Poetry of the 1930s: A Critical Anthology |author=Jane Dowson |year=1996 |publisher=Routledge |isbn=0-415-13095-6 |url=https://books.google.com/books?id=fVTQPI3ZIHcC&amp;pg=RA1-PA103&amp;dq=nine-bright-shiners+ridler&amp;ie=ISO-8859-1#PRA1-PA103,M1}}&lt;/ref&gt; and a 1988 fiction book by Anthea Fraser;&lt;ref&gt;{{cite book |title=The Nine Bright Shiners |author=Anthea Fraser |publisher=Doubleday |year=1988 |isbn=0-385-24323-5 |url=}}&lt;/ref&gt; the name derives from "a very curious old semi-pagan, semi-Christian" song.&lt;ref&gt;{{cite book |title=Recollections of an Eton Colleger, 1898-1902 |author=Charles Herbert Malden |publisher=Spottiswoode |year=1905 |url=https://books.google.com/books?id=EKB9T4pPcfkC&amp;pg=PA182&amp;dq=nine-bright-shiners#PPA180,M1}}&lt;/ref&gt;
*''[[The Nine Tailors]]'' is a 1934 [[mystery novel]] by [[United Kingdom|British]] writer [[Dorothy L. Sayers]], her ninth featuring sleuth [[Lord Peter Wimsey]].
*[[Nine Unknown Men]] are, in occult legend, the custodians of the sciences of the world since ancient times.
*In [[J.R.R. Tolkien's]] [[Middle-earth]], there are nine rings of power given to men, and consequently, nine [[Nazgul|ringwraiths]]. Additionally, [[The Fellowship of the Ring#Members of the Fellowship of the Ring|The Fellowship of the Ring]] consists of nine companions.
*In ''[[Lorien Legacies]]'' there are nine Garde sent to Earth.
*Number Nine is a character in ''[[Lorien Legacies]]''.
*In the series ''[[A Song of Ice and Fire]]'', there are nine regions of Westeros (the Crownlands, the North, the Riverlands, the Westerlands, the Reach, the Stormlands, the Vale of Arryn, the Iron Islands and Dorne). Additionally, there is a group of nine city-states in western Essos known collectively as the Free Cities (Braavos, Lorath, Lys, Myr, Norvos, Pentos, Qohor, Tyrosh and Volantis).

==Organizations==
*Divine Nine – The [[National Pan-Hellenic Council]] (NPHC) is a collaborative organization of nine historically African American, international Greek-lettered fraternities and sororities.

==Places and thoroughfares==
*[[List of highways numbered 9]]
*[[Ninth Avenue (Manhattan)|Ninth Avenue]] is a major avenue in Manhattan.
*[[Provinces of South Africa|South Africa]] has 9 provinces

==Religion and philosophy==
[[Image:Bahai star.svg|150px|right|A nine-pointed star]]
*Nine, as the highest single-digit number (in [[decimal|base ten]]), symbolizes completeness in the [[Bahá'í Faith]]. In addition, the word Bahá' in the [[Abjad numerals|Abjad notation]] has a value of 9, and a 9-pointed star is used to [[Bahá'í symbols|symbolize]] the religion.
*The number 9 is revered in Hinduism and considered a complete, perfected and divine number because it represents the end of a cycle in the [[decimal]] system, which originated from the Indian subcontinent as early as [[30th century BC|3000 BC]].
*In Buddhism, [[Gautama Buddha]], was believed to have nine virtues, which he was (1) Accomplished, (2) Perfectly Enlightened, (3) Endowed with knowledge and Conduct or Practice, (4) Well-gone or Well-spoken, (5) the Knower of worlds, (6) the Guide Unsurpassed of men to be tamed, (7) the Teacher of gods and men, (8) Enlightened, and (9) Blessed.
*Important Buddhist rituals usually involve nine monks.
*The first nine days of the [[Hebrew calendar|Hebrew month]] of [[Av (month)|Av]] are collectively known as "The Nine Days" (''Tisha HaYamim''), and are a period of semi-mourning leading up to [[Tisha B'Av]], the ninth day of Av on which both [[Temple in Jerusalem|Temples in Jerusalem]] were destroyed.
*Nine is a significant number in [[Norse Mythology]]. [[Odin]] hung himself on an ash tree for nine days to learn the runes.
*The [[Fourth Way Enneagram]] is one system of knowledge which shows the correspondence between the 9 integers and the circle.
*In the [[Christian angelic hierarchy]] there are 9 choirs of angels.
*[[Ramadan (calendar month)|Ramadan]], the month of fasting and prayer, is the ninth month of the [[Islamic calendar]].
*Tian's Trigram Number, of Feng Shui, in [[Taoism]].

==Science==
===Astronomy===
*Before 2006 (when Pluto was [[Pluto#2006: IAU classification|officially designated as a non-planet]]), there were nine [[planet]]s in the [[solar system]].
*[[Messier object]] [[Messier 9|M9]] is a magnitude 9.0 [[globular cluster]] in the constellation [[Ophiuchus]].
*The [[New General Catalogue]] [http://www.ngcic.org/ object] [[NGC 9]], a [[spiral galaxy]] in the [[constellation]] [[Pegasus (constellation)|Pegasus]].

===Chemistry===
*The purity of chemicals (see [[Nine (purity)]]).
*Nine is the [[atomic number]] of [[fluorine]].

===Physiology===
A human [[pregnancy]] normally lasts nine months, the basis of [[Naegele's rule]].

==Sports==
[[File:9ball rack 2.jpg|thumb|right|200px|Billiards: A [[Nine-ball]] [[Rack (billiards)|rack]] with the no. 9 ball at the center]]
*[[Nine-ball]] is the standard professional pocket [[billiards]] variant played in the United States.
*In [[association football]] (soccer), the centre-forward/striker traditionally (since at least the fifties) wears the number 9 shirt.
*In [[baseball]]:
**There are nine players on the field including the pitcher.
**There are nine innings in a standard game.
**9 represents the [[right fielder]]'s position.
**''NINE: A Journal of Baseball History and Culture'', published by the [[University of Nebraska Press]]&lt;ref&gt;{{cite web |url=http://nine.iweb.bsu.edu/ |title=Web site for NINE: A Journal of Baseball History &amp; Culture |accessdate=20 February 2013 |archive-url=https://web.archive.org/web/20091104001109/http://nine.iweb.bsu.edu/ |archive-date=2009-11-04 |dead-url=yes |df= }}&lt;/ref&gt;
*In [[rugby league]], the jersey number assigned to the [[Hooker (rugby league)|hooker]] in most competitions. (An exception is the European [[Super League]], which uses static squad numbering.)
*In [[rugby union]], the number worn by the starting [[Scrum-half (rugby union)|scrum-half]].

==Technology==
[[Image:Seven-segment 9.svg|25px|right]]
[[Image:Seven-segment 9 alt.svg|25px|right]]
*[[ISO 9]] is the [[International Organization for Standardization|ISO]]'s standard for the transliteration of [[Cyrillic]] characters into [[Latin]] characters
*In the [[Rich Text Format]] specification, 9 is the language code for the [[English language]]. All codes for regional variants of English are congruent to 9 mod 256.
*The [[seven-segment display]] allows the number 9 to be constructed two ways, either with a hook at the end of its stem or without one. Most [[liquid crystal display|LCD]] calculators use the former, but some [[vacuum fluorescent display|VFD]] models use the latter.
*[[The9]] Limited (owner of [http://the9.com the9.com]) is a company in the video-game industry, including former ties to the extremely popular [[MMORPG]] [[World of Warcraft]].

==Music==
*"[[Revolution 9]]", a sound collage which appears on The Beatles' eponymous 1968 album [[The Beatles (album)|''The Beatles'' (aka ''The White Album'')]], prominently features a loop of a man's voice repeating the phrase "Number nine".
*There are 9 semitones in a [[Major 6th]] interval in music.

==See also==
{{Portal|Mathematics}}
*[[9 (disambiguation)]]
*[[0.999...]]
*[[wikt:cloud nine|Cloud Nine]]

==References==
{{Reflist|35em}}

==Further reading==
*Cecil Balmond, "Number 9, the search for the sigma code" 1998, Prestel 2008, {{ISBN|3-7913-1933-7}}, {{ISBN|978-3-7913-1933-9}}

{{Integers|zero}}

{{DEFAULTSORT:9 (Number)}}
[[Category:Integers]]
[[Category:9 (number)]]
[[Category:Superstitions about numbers]]</text>
      <sha1>og3nuy10d9g81wg37bzleep0oug9wis</sha1>
    </revision>
  </page>
  <page>
    <title>Abbe error</title>
    <ns>0</ns>
    <id>18584082</id>
    <revision>
      <id>864714987</id>
      <parentid>859065212</parentid>
      <timestamp>2018-10-19T00:05:02Z</timestamp>
      <contributor>
        <ip>86.26.109.27</ip>
      </contributor>
      <comment>More concise explanation of abbe errors as they concern  precision alignment in machine tool members (lathes).</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1407">'''Abbe error''', named after [[Ernst Abbe]], also called '''[[Abbe sine condition|sine error]]''', describes the magnification of angular error over distance. For example, when one measures a point that is 1 meter away at 45 degrees, an angular error of 1 degree corresponds to a positional error of over 1.745&amp;nbsp;cm, equivalent to a distance-measurement error of 1.745%. &lt;ref&gt;{{Cite book |doi = 10.1007/978-3-642-35950-7_16793-1|chapter = Abbe Error/Offset|title = CIRP Encyclopedia of Production Engineering|pages = 1–4|year = 2014|last1 = Leach|first1 = Richard|isbn = 978-3-642-35950-7}}&lt;/ref&gt;

In machine design, some components are particularly sensitive to angular errors. For example, slight deviations from parallelism of the spindle axis of a [[lathe]] to the tool motion along the bed of the machine can lead to relatively large (undesired) taper along the part (i.e a non-cylindrical part). Vernier calipers are not free from abbe error, while screw gauges are free from abbe error. Abbe error is the product of the abbe offset and the sine of angular error in the system.

Abbe error can be detrimental to [[dead reckoning]].

Formula: 
: &lt;math&gt;\epsilon = h \sin \theta&lt;/math&gt;

&lt;math&gt;\epsilon&lt;/math&gt; the error.

&lt;math&gt;h&lt;/math&gt; the distance.

&lt;math&gt;\theta&lt;/math&gt; the angle.

==References==
{{reflist}}

== External links ==

[[Category:Error]]
[[Category:Trigonometry]]


[[de: Kippfehler]]</text>
      <sha1>df7wmjvnwirwk6t948c1uxqq42exh18</sha1>
    </revision>
  </page>
  <page>
    <title>Alexander Schrijver</title>
    <ns>0</ns>
    <id>35280549</id>
    <revision>
      <id>868908678</id>
      <parentid>863350221</parentid>
      <timestamp>2018-11-15T05:31:31Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; reformat 2 links. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8732">[[File:Alexander Schrijver 2010.jpg|thumb|alt=Headshot of Schrijver|Lex Schrijver at [[Mathematical Research Institute of Oberwolfach|Oberwolfach]] in 2010]]
'''Alexander (Lex) Schrijver''' (born 4 May 1948 in [[Amsterdam]])&lt;ref&gt;[http://www.nwo.nl/nwohome.nsf/pages/NWOP_8KLHM8 Biography]{{Dead link|date=October 2018 |bot=InternetArchiveBot |fix-attempted=yes }} at the [[Nederlandse Organisatie voor Wetenschappelijk Onderzoek|NWO]] website&lt;/ref&gt; is a Dutch mathematician and computer scientist, a professor of discrete mathematics and optimization at the [[University of Amsterdam]] and a fellow at the [[Centrum Wiskunde &amp; Informatica]] in [[Amsterdam]].&lt;ref name="profile"&gt;[http://www.cwi.nl/people/102 Profile], CWI, retrieved 2012-03-30.&lt;/ref&gt; Since 1993 he has been co-editor in chief of the journal ''[[Combinatorica]]''.&lt;ref name="profile"/&gt;&lt;ref name="combinatorica"&gt;[http://springer.com/journal/493 ''Combinatorica'' journal home page], Springer, retrieved 2012-03-30.&lt;/ref&gt;

==Biography==
Schrijver earned his Ph.D. in 1977 from the [[Vrije Universiteit]] in Amsterdam, under the supervision of Pieter Cornelis Baayen.&lt;ref&gt;{{mathgenealogy|id=59207}}&lt;/ref&gt; He worked for the Centrum Wiskunde &amp; Informatica (under its former name as the Mathematisch Centrum) in pure mathematics from 1973 to 1979, and was a professor at [[Tilburg University]] from 1983 to 1989. In 1989 he rejoined the Centrum Wiskunde &amp; Informatica, and in 1990 he also became a professor at the University of Amsterdam. In 2005, he stepped down from management at CWI and instead became a CWI Fellow.&lt;ref name="profile"/&gt;&lt;ref name="lion"/&gt;

==Awards and honors==
Schrijver was one of the winners of the [[Fulkerson Prize|Delbert Ray Fulkerson Prize]] of the [[American Mathematical Society]] in 1982 for his work with [[Martin Grötschel]] and [[László Lovász]] on applications of the [[ellipsoid method]] to [[combinatorial optimization]]; he won the same prize in 2003 for his research on minimization of [[Submodular set function|submodular functions]].&lt;ref&gt;[http://www.ams.org/profession/prizes-awards/pabrowse AMS Awards], retrieved 2012-03-30.&lt;/ref&gt;&lt;ref name="ppa"/&gt; He won the [[Institute for Operations Research and the Management Sciences|INFORMS]] [[Frederick W. Lanchester Prize]] in 1986 for his book ''Theory of Linear and Integer Programming'', and again in 2004 for his book ''Combinatorial Optimization: Polyhedra and Efficiency''. In 2003, he won the George B. Dantzig Prize of the [[Mathematical Programming Society]] and [[Society for Industrial and Applied Mathematics|SIAM]] for "deep and fundamental research contributions to discrete optimization".&lt;ref name="ppa"&gt;[http://www.cwi.nl/news/2003/Prestigious-prizes-awarded-to-Lex-Schrijver-and-Bert-Gerards Prestigious prizes awarded to Lex Schrijver and Bert Gerards], CWI, retrieved 2012-03-30.&lt;/ref&gt; In 2006, he was a joint winner of the INFORMS John von Neumann Theory Prize with Grötschel and Lovász for their work in combinatorial optimization, and in particular for their joint work in the book ''Geometric Algorithms and Combinatorial Optimization'' showing the polynomial-time equivalence of separation and optimization.&lt;ref name="informs"&gt;[http://www.informs.org/Recognize-Excellence/Award-Recipients/Alexander-Schrijver INFORMS Awards for Alexander Schrijver] {{Webarchive|url=https://web.archive.org/web/20120524110753/http://informs.org/Recognize-Excellence/Award-Recipients/Alexander-Schrijver |date=2012-05-24 }}, retrieved 2012-03-30.&lt;/ref&gt; In 2008, his work with Adri Steenbeek on scheduling the [[Nederlandse Spoorwegen|Dutch train system]] was honored with INFORMS' [[Franz Edelman Award for Achievement in Operations Research and the Management Sciences]].&lt;ref name="hondoc"/&gt;&lt;ref&gt;[http://www.informs.org/Recognize-Excellence/Award-Recipients/Netherlands-Railways2 2008 Franz Edelman Award Winner] {{Webarchive|url=https://web.archive.org/web/20120402140807/http://www.informs.org/Recognize-Excellence/Award-Recipients/Netherlands-Railways2 |date=2012-04-02 }}, INFORMS, retrieved 2012-03-30.&lt;/ref&gt; He won the SIGMA prize of the Dutch [[SURFnet|SURF foundation]] in 2008, for a mathematics education project.&lt;ref&gt;[http://www.cwi.nl/news/SIGMA-prize-2008-for-DisWis SIGMA prize 2008 for DisWis], CWI, August 20, 2008, retrieved 2012-03-30.&lt;/ref&gt; In 2015 he won the [[EURO Gold Medal]], the highest distinction within [[Operations Research]] in Europe.

In 2005 Schrijver won the [[Spinoza Prize]] of the [[Nederlandse Organisatie voor Wetenschappelijk Onderzoek|NWO]], the highest scientific award in the Netherlands, for his research in combinatorics and algorithms.&lt;ref&gt;[http://www.science.uva.nl/english/news.cfm/6FCE3861-37AF-40C6-BAE84239142F90BF Spinoza Prize for mathematician Lex Schrijver] {{Webarchive|url=https://archive.is/20120910223820/http://www.science.uva.nl/english/news.cfm/6FCE3861-37AF-40C6-BAE84239142F90BF |date=2012-09-10 }}, University of Amsterdam, June 7, 2005, retrieved 2012-03-30.&lt;/ref&gt; Later in the same year he became a Knight of the [[Order of the Netherlands Lion]].&lt;ref name="lion"&gt;[http://www.english.uva.nl/news/archive.cfm/5B0E650A-643C-4DEC-9CF82D6B401E1F26 Royal honours for mathematician Alexander Schrijver] {{Webarchive|url=https://archive.is/20130222164512/http://www.english.uva.nl/news/archive.cfm/5B0E650A-643C-4DEC-9CF82D6B401E1F26 |date=2013-02-22 }}, University of Amsterdam, September 21, 2005, retrieved 2012-03-30.&lt;/ref&gt; In 2002, Schrijver received an honorary doctorate from the [[University of Waterloo]] in [[Canada]], and in 2011 he received another one from [[Eötvös Loránd University]] in [[Hungary]].&lt;ref name="hondoc"&gt;[http://www.cwi.nl/news/2011/mathematician-lex-schrijver-receives-honorary-doctorate Mathematician Lex Schrijver receives honorary doctorate], CWI, May 9, 2011, retrieved 2012-03-30.&lt;/ref&gt;

Schrijver became a member of the [[Royal Netherlands Academy of Arts and Sciences]] in 1995.&lt;ref&gt;[http://knaw.nl/Pages/DEF/26/641.bGFuZz1FTkc.html KNAW member profile] {{Webarchive|url=http://webarchive.loc.gov/all/20110513035549/http://www.knaw.nl/Pages/DEF/26/641.bGFuZz1FTkc.html |date=2011-05-13 }}, retrieved 2012-03-30.&lt;/ref&gt; He became a corresponding member of the [[North Rhine-Westphalia Academy for Sciences and Arts]] in 2005,&lt;ref&gt;[http://www.awk.nrw.de/awk/mitglieder/mitgliedschaft/klasse_nm/index.php## NRW members for natural science and medicine] {{Webarchive|url=https://web.archive.org/web/20120113044657/http://www.awk.nrw.de/awk/mitglieder/mitgliedschaft/klasse_nm/index.php |date=2012-01-13 }}, retrieved 2012-03-30.&lt;/ref&gt;  joined the [[German Academy of Sciences Leopoldina]] in 2006,&lt;ref&gt;[http://www.leopoldina.org/de/akademie/organisation/mitglieder/mitgliederverzeichnis.html?tx_leomemberlist_pi1%5BshowUid%5D=1157 Leopoldina member profile]{{Dead link|date=October 2018 |bot=InternetArchiveBot |fix-attempted=yes }}, retrieved 2012-03-30.&lt;/ref&gt; and was elected to the [[Academia Europaea]] in 2008.&lt;ref&gt;[http://www.ae-info.org/ae/User/Schrijver_Alexander AE member profile], retrieved 2012-03-30.&lt;/ref&gt; In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-07-14.&lt;/ref&gt;

==Books==
*''Theory of Linear and Integer Programming'' (Wiley, 1986, reprinted 1998, {{ISBN|9780471982326}})
*''Geometric Algorithms and Combinatorial Optimization'' (Springer, 1988, {{ISBN|9783540136248}})
*''Combinatorial Optimization'' (with [[William J. Cook]], William H. Cunningham, and [[William R. Pulleyblank]], Wiley and Sons, Wiley Series in Discrete Mathematics and Optimization 33, 1998, reprinted 2011, {{ISBN|9781118031391}})
*''Combinatorial Optimization: Polyhedra and Efficiency'' (Springer, Algorithms and Combinatorics 24, 2003, {{ISBN|9783540443896}})

==References==
{{reflist|colwidth=30em}}

{{John von Neumann Theory Prize recipients}}
{{Authority control}}

{{DEFAULTSORT:Schrijver, Alexander}}
[[Category:1948 births]]
[[Category:Living people]]
[[Category:Dutch mathematicians]]
[[Category:Dutch computer scientists]]
[[Category:Combinatorialists]]
[[Category:Dutch operations researchers]]
[[Category:Theoretical computer scientists]]
[[Category:Vrije Universiteit Amsterdam alumni]]
[[Category:Tilburg University faculty]]
[[Category:University of Amsterdam faculty]]
[[Category:Knights of the Order of the Netherlands Lion]]
[[Category:Members of Academia Europaea]]
[[Category:Scientists from Amsterdam]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Spinoza Prize winners]]
[[Category:Members of the Royal Netherlands Academy of Arts and Sciences]]
[[Category:John von Neumann Theory Prize winners]]</text>
      <sha1>16npxj6cvgakm9pzrtci2v205tz50o9</sha1>
    </revision>
  </page>
  <page>
    <title>Almost periodic function</title>
    <ns>0</ns>
    <id>405512</id>
    <revision>
      <id>809434370</id>
      <parentid>793529480</parentid>
      <timestamp>2017-11-09T02:21:36Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: C.R. Acad. Sci. Paris → C. R. Acad. Sci. Paris using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15743">In [[mathematics]], an '''almost periodic function''' is, loosely speaking, a function of a real number that is [[periodic function|periodic]] to within any desired level of accuracy, given suitably long, well-distributed "almost-periods". The concept was first studied by [[Harald Bohr]] and later generalized by [[Vyacheslav Stepanov]], [[Hermann Weyl]] and [[Abram Samoilovitch Besicovitch]], amongst others. There is also a notion of almost periodic functions on [[locally compact abelian group]]s, first studied by [[John von Neumann]].

'''Almost periodicity''' is a property of [[dynamical system]]s that appear to retrace their paths through [[phase space]], but not exactly. An example would be a [[planetary system]], with [[planet]]s in [[orbit]]s moving with [[Orbital period|period]]s that are not [[commensurability (mathematics)|commensurable]] (i.e., with a period vector that is not [[Proportionality (mathematics)|proportional]] to a [[vector space|vector]] of [[integers]]). A [[Kronecker's theorem on diophantine approximation|theorem of Kronecker]] from [[diophantine approximation]] can be used to show that any particular configuration that occurs once, will recur to within any specified accuracy: if we wait long enough we can observe the planets all return to within a [[second of arc]] to the positions they once were in.

==Motivation==

There are several inequivalent definitions of almost periodic functions. The first was given by [[Harald Bohr]]. His interest was initially in finite [[Dirichlet series]]. In fact by truncating the series for the [[Riemann zeta function]] ''ζ''(''s'') to make it finite, one gets finite sums of terms of the type

:&lt;math&gt;e^{(\sigma+it)\log n}\,&lt;/math&gt;

with ''s'' written as (''σ''&amp;nbsp;+&amp;nbsp;''it'') &amp;ndash; the sum of its real part ''σ'' and imaginary part ''it''.  Fixing ''σ'', so restricting attention to a single vertical line in the complex plane, we can see this also as

:&lt;math&gt;n^\sigma e^{(\log n)it}.\,&lt;/math&gt;

Taking a ''finite'' sum of such terms avoids difficulties of [[analytic continuation]] to the region σ&amp;nbsp;&lt;&amp;nbsp;1. Here the 'frequencies' log&amp;nbsp;''n'' will not all be commensurable (they are as linearly independent over the rational numbers as the integers ''n'' are multiplicatively independent &amp;ndash; which comes down to their prime factorizations).

With this initial motivation to consider types of [[trigonometric polynomial]] with independent frequencies, [[mathematical analysis]] was applied to discuss the closure of this set of basic functions, in various [[norm (mathematics)|norm]]s.

The theory was developed using other norms by [[Abram Samoilovitch Besicovitch|Besicovitch]], [[Vyacheslav Stepanov|Stepanov]], [[Hermann Weyl|Weyl]], [[John von Neumann|von Neumann]], [[Alan Turing|Turing]], [[Salomon Bochner|Bochner]] and others in the 1920s and 1930s.

===Uniform or Bohr or Bochner  almost periodic functions===

{{harvtxt|Bohr|1925}} defined the '''uniformly almost-periodic functions''' as the closure of the trigonometric polynomials with respect to the [[uniform norm]] 
:&lt;math&gt;\|f\|_\infty = \sup_x|f(x)|&lt;/math&gt;
(on bounded functions ''f'' on '''R''').  In other words, a function ''f'' is uniformly almost periodic if for every ''ε'' &gt; 0 there is a finite linear combination of sine and cosine waves that is of distance less than ''ε'' from ''f'' with respect to the uniform norm.  Bohr proved that this definition was equivalent to the existence of a [[relatively dense set]] of '''''ε''&amp;nbsp;almost-periods''', for all ''ε''&amp;nbsp;&gt;&amp;nbsp;0: that is, [[translation]]s ''T''(''ε'')&amp;nbsp;=&amp;nbsp;''T'' of the variable ''t''  making

:&lt;math&gt;\left|f(t+T)-f(t)\right|&lt;\varepsilon.&lt;/math&gt;

An alternative definition due to Bochner (1926) is equivalent to that of Bohr and is relatively simple to state:
&lt;blockquote&gt;A function ''f'' is almost periodic if every [[sequence]] {''&amp;fnof;''(''t''&amp;nbsp;+&amp;nbsp;''T''&lt;sub&gt;''n''&lt;/sub&gt;)} of translations of ''f'' has a [[subsequence]] that [[uniform convergence|converges uniformly]] for ''t'' in (&amp;minus;&amp;infin;,&amp;nbsp;+&amp;infin;).&lt;/blockquote&gt;

The Bohr almost periodic functions are essentially the same as continuous functions on the [[Bohr compactification]] of the reals.

===Stepanov almost periodic functions===
The space ''S''&lt;sup&gt;''p''&lt;/sup&gt; of Stepanov almost periodic functions (for ''p''&amp;nbsp;≥&amp;nbsp;1) was introduced by V.V. {{harvtxt|Stepanov|1925}}. It contains the space of Bohr almost periodic functions. It is the closure of the trigonometric polynomials under the norm

:&lt;math&gt;\|f\|_{S,r,p}=\sup_x \left({1\over r}\int_x^{x+r} |f(s)|^p \, ds\right)^{1/p}&lt;/math&gt;

for any fixed positive value of ''r''; for different values of ''r'' these norms give the same topology and so the same space of almost periodic functions (though the norm on this space depends on the choice of&amp;nbsp;''r'').

===Weyl almost periodic functions===
The space ''W''&lt;sup&gt;''p''&lt;/sup&gt; of Weyl almost periodic functions (for ''p''&amp;nbsp;≥&amp;nbsp;1) was introduced by {{harvtxt|Weyl|1927}}. It contains the space ''S''&lt;sup&gt;''p''&lt;/sup&gt; of Stepanov almost periodic functions. 
It is the closure of the trigonometric polynomials under the seminorm

:&lt;math&gt;\|f\|_{W,p}=\lim_{r\to\infty}\|f\|_{S,r,p}&lt;/math&gt;

Warning: there are nonzero functions ''&amp;fnof;'' with ||''&amp;fnof;''||&lt;sub&gt;''W'',''p''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0, such as any bounded function of compact support, so to get a Banach space one has to quotient out by these functions.

===Besicovitch almost periodic functions===
The space ''B''&lt;sup&gt;''p''&lt;/sup&gt; of Besicovitch almost periodic functions was introduced by {{harvtxt|Besicovitch|1926}}.
It is the closure of the trigonometric polynomials under the seminorm

:&lt;math&gt;\|f\|_{B,p}=\limsup_{x \to\infty}\left({1\over 2x} \int_{-x}^x |f(s)|^p \, ds \right)^{1/p}&lt;/math&gt;

Warning: there are nonzero functions ''&amp;fnof;'' with ||''&amp;fnof;''||&lt;sub&gt;B,''p''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0, such as any bounded function of compact support, so to get a Banach space one has to quotient out by these functions.

The Besicovitch almost periodic functions in ''B''&lt;sup&gt;2&lt;/sup&gt; have an expansion (not necessarily convergent) as

:&lt;math&gt;\sum a_ne^{i\lambda_n t}&lt;/math&gt;

with Σ''a''{{supsub|2|''n''}} finite and ''λ''&lt;sub&gt;''n''&lt;/sub&gt; real. Conversely every such series is the expansion of some Besicovitch periodic function (which is not unique).

The space ''B''&lt;sup&gt;''p''&lt;/sup&gt; of Besicovitch almost periodic functions (for ''p''&amp;nbsp;≥&amp;nbsp;1) contains the space ''W''&lt;sup&gt;''p''&lt;/sup&gt; of Weyl almost periodic functions. If one quotients out a subspace of "null" functions, it can be identified with the space of ''L''&lt;sup&gt;''p''&lt;/sup&gt; functions on the Bohr compactification of the reals.

===Almost periodic functions on a locally compact abelian group===
With these theoretical developments and the advent of abstract methods (the [[Peter&amp;ndash;Weyl theorem]], [[Pontryagin duality]] and [[Banach algebra]]s) a general theory became possible. The general idea of almost-periodicity in relation to a [[locally compact abelian group]] ''G'' becomes that of a function ''F'' in ''L''&lt;sup&gt;∞&lt;/sup&gt;(''G''), such that its translates by ''G'' form a [[relatively compact]] set.
Equivalently, the space of almost periodic functions is the norm closure of the finite linear combinations of characters of&amp;nbsp;''G''. If ''G'' is compact the almost periodic functions are the same as the continuous functions.

The [[Bohr compactification]] of ''G'' is the  compact abelian group  of all possibly discontinuous characters of the dual group of ''G'', and is a compact group containing ''G'' as a dense subgroup. The space of uniform almost periodic functions on ''G'' can be identified with the space of all continuous functions on the Bohr compactification of&amp;nbsp;''G''. More generally the Bohr compactification can be defined for any topological group&amp;nbsp;''G'', and the spaces of continuous or ''L''&lt;sup&gt;''p''&lt;/sup&gt; functions on the Bohr compactification can be considered as almost periodic functions on&amp;nbsp;''G''.
For locally compact connected groups ''G'' the map from ''G'' to its Bohr compactification is injective if and only if ''G'' is a central extension of a compact group,  or equivalently the product of a compact group and a finite-dimensional vector space.

== Quasiperiodic signals in audio and music synthesis ==

In [[speech processing]], [[audio signal processing]], and [[synthesizer|music synthesis]], a '''quasiperiodic''' signal, sometimes called a '''quasiharmonic''' signal, is a [[waveform]] that is virtually [[Frequency|periodic]] microscopically, but not necessarily periodic macroscopically. This does not give a [[quasiperiodic function]] in the sense of the Wikipedia article of that name, but something more akin to an almost periodic function, being a nearly periodic function where any one period is virtually identical to its adjacent periods but not necessarily similar to periods much farther away in time.  This is the case for musical tones (after the initial attack transient) where all [[Harmonic series (music)#Partial|partial]]s or [[overtone]]s are [[harmonic]] (that is all overtones are at frequencies that are an integer multiple of a [[fundamental frequency]] of the tone).

When a signal &lt;math&gt; x(t) \ &lt;/math&gt; is '''fully periodic''' with period &lt;math&gt; T \ &lt;/math&gt;, then the signal exactly satisfies

: &lt;math&gt; x(t) = x(t + T) \ &lt;/math&gt;

or

: &lt;math&gt; \left| x(t) - x(t + T) \right| = 0 \text{ for all } t. \ &lt;/math&gt;

The [[Fourier series]] representation would be

: &lt;math&gt;x(t) = \frac{1}{2}a_0 + \sum_{n=1}^\infty\left[a_n\cos(2 \pi n f_0 t) - b_n\sin(2 \pi n f_0 t)\right]&lt;/math&gt;

or

: &lt;math&gt;x(t) = \frac{1}{2}a_0 + \sum_{n=1}^\infty\left[r_n\cos(2 \pi n f_0 t + \varphi_n)\right]&lt;/math&gt;

where &lt;math&gt; f_0 = \frac{1}{T} &lt;/math&gt; is the fundamental frequency and the Fourier coefficients are

:&lt;math&gt;a_n = r_n \cos \left( \varphi_n \right) = \frac{2}{T} \int_{t_0}^{t_0+T} x(t) \cos(2 \pi n f_0 t) \, dt  \ &lt;/math&gt;

:&lt;math&gt;b_n = r_n \sin \left( \varphi_n \right)  = - \frac{2}{T} \int_{t_0}^{t_0+T} x(t) \sin(2 \pi n f_0 t) \, dt \ &lt;/math&gt;

:where  &lt;math&gt; t_0 \ &lt;/math&gt; can be any time:  &lt;math&gt; -\infty &lt; t_0 &lt; +\infty \ &lt;/math&gt;.

The [[fundamental frequency]] &lt;math&gt; f_0 \ &lt;/math&gt;, and Fourier [[coefficient]]s &lt;math&gt; a_n \ &lt;/math&gt;,  &lt;math&gt; b_n \ &lt;/math&gt;, &lt;math&gt; r_n \ &lt;/math&gt;, or &lt;math&gt; \varphi_n \ &lt;/math&gt;,  are constants, i.e. they are not functions of time. The harmonic frequencies are exact integer multiples of the fundamental frequency.

When &lt;math&gt; x(t) \ &lt;/math&gt; is '''quasiperiodic''' then

: &lt;math&gt; x(t) \approx x \left( t + T(t) \right) \ &lt;/math&gt;

or

: &lt;math&gt; \left| x(t) - x \left( t + T(t) \right) \right| &lt; \varepsilon \ &lt;/math&gt;

where

: &lt;math&gt; 0 &lt; \epsilon \ll \left \Vert x \right \| = \sqrt{\overline{x^2}} = \sqrt{ \lim_{\tau \to \infty} \frac{1}{\tau} \int_{-\tau/2}^{\tau/2} x^2(t)\, dt }. \ &lt;/math&gt;

Now the Fourier series representation would be

: &lt;math&gt;x(t) = \frac{1}{2}a_0(t) \ + \ \sum_{n=1}^\infty \left[a_n(t)\cos \left(2 \pi n \int_{0}^{t} f_0(\tau)\, d\tau \right) - b_n(t)\sin \left( 2 \pi n \int_0^t  f_0(\tau)\, d\tau \right) \right]&lt;/math&gt;

or

: &lt;math&gt;x(t) = \frac{1}{2}a_0(t) \ + \ \sum_{n=1}^\infty\left[r_n(t)\cos \left( 2 \pi n \int_0^t f_0(\tau)\, d\tau + \varphi_n(t) \right) \right]&lt;/math&gt;

or

: &lt;math&gt;x(t) = \frac{1}{2}a_0(t) + \sum_{n=1}^\infty \left[r_n(t)\cos \left( 2 \pi \int_0^t f_n(\tau)\, d\tau + \varphi_n(0) \right) \right]&lt;/math&gt;

where &lt;math&gt; f_0(t) = \frac{1}{T(t)} &lt;/math&gt; is the possibly ''time-varying'' fundamental frequency and the Fourier coefficients are

:&lt;math&gt;a_n(t) = r_n(t) \cos(\varphi_n(t)) \ &lt;/math&gt;

:&lt;math&gt;b_n(t) = r_n(t) \sin(\varphi_n(t)) \ &lt;/math&gt;

and the [[instantaneous phase#Instantaneous frequency|instantaneous frequency]] for each [[Harmonic series (music)#Partial|partial]] is

:&lt;math&gt; f_n(t) = n f_0(t) + \frac{1}{2 \pi} \varphi_n^\prime(t). \, &lt;/math&gt;

Whereas in this quasiperiodic case, the fundamental frequency &lt;math&gt; f_0(t) \ &lt;/math&gt;, the harmonic frequencies &lt;math&gt; f_n(t) \ &lt;/math&gt;, and the Fourier coefficients &lt;math&gt; a_n(t) \ &lt;/math&gt;,  &lt;math&gt; b_n(t) \ &lt;/math&gt;,  &lt;math&gt; r_n(t) \ &lt;/math&gt;, or &lt;math&gt; \varphi_n(t) \ &lt;/math&gt; are '''not''' necessarily constant, and '''are''' functions of time albeit ''slowly varying'' functions of time.  Stated differently these functions of time are [[bandlimited]] to much less than the fundamental frequency for &lt;math&gt; x(t) \ &lt;/math&gt; to be considered to be quasiperiodic.

The partial frequencies &lt;math&gt; f_n(t) \ &lt;/math&gt; are very nearly harmonic but not necessarily exactly so.  The time-derivative of &lt;math&gt; \varphi_n(t) \ &lt;/math&gt;, that is &lt;math&gt; \varphi_n^\prime(t) \ &lt;/math&gt;, has the effect of detuning the partials from their exact integer harmonic value &lt;math&gt; n f_0(t) \ &lt;/math&gt;.  A rapidly changing &lt;math&gt; \varphi_n(t) \ &lt;/math&gt; means that the instantaneous frequency for that partial is severely detuned from the integer harmonic value which would mean that &lt;math&gt; x(t) \ &lt;/math&gt; is not quasiperiodic.

==See also==
*[[Quasiperiodic function]]
*[[Aperiodic function]]
*[[Quasiperiodic tiling]]
*[[Fourier series]]
*[[Additive synthesis]]
*[[Harmonic series (music)]]
*[[Computer music]]

==Notes==
&lt;references /&gt;

==References==
*{{Citation
 | last =Amerio
 | first =Luigi
 | author-link =Luigi Amerio
 | last2 =Prouse
 | first2 =Giovanni
 | author2-link =Giovanni Prouse
 | title =Almost-periodic functions and functional equations
 | place =New York–Cincinnati–Toronto–London–Melbourne
 | publisher =[[Van Nostrand Reinhold]]
 | series =[[The University Series in Higher Mathematics]]
 | year =1971
 | pages =viii+184
 | url =
 | doi =
 | id =
 | isbn =0-442-20295-4  
 | mr =275061
 | zbl =0215.15701
}}.
*A.S. Besicovitch,   "On generalized almost periodic functions"  Proc. London Math. Soc. (2), 25  (1926)  pp.&amp;nbsp;495–512
*A.S. Besicovitch,   "Almost periodic functions", Cambridge Univ. Press  (1932)
* {{citation | first=S.|last= Bochner | title=Beitrage zur Theorie der fastperiodischen Funktionen | journal=Math. Annalen | year=1926 | volume=96 | issue= | pages=119&amp;ndash;147 | doi=10.1007/BF01209156 }}
*S. Bochner and J. von Neumann, "Almost Periodic Function in a Group II", Trans. Amer. Math. Soc., 37 no. 1 (1935)  pp.&amp;nbsp;21–50
*H. Bohr,   "Zur Theorie der fastperiodischen Funktionen I"  Acta Math., 45  (1925)  pp.&amp;nbsp;29–127
* H. Bohr,   "Almost-periodic functions", Chelsea, reprint  (1947) 
*{{springer|id=A/a011970|first=E.A.|last= Bredikhina}}
*{{springer|id=b/b015820|title=Besicovitch almost periodic functions|first=E.A.|last= Bredikhina}}
*{{springer|id=b/b016770|title=Bohr almost periodic functions|first=E.A.|last= Bredikhina}}
*{{springer|id=s/s087720|title=Stepanov almost periodic functions|first=E.A.|last= Bredikhina}}
*{{springer|id=w/w097680|title=Weyl almost periodic functions|first=E.A.|last= Bredikhina}}
*J. von Neumann, "Almost Periodic Functions in a Group I", Trans. Amer. Math. Soc., 36 no. 3 (1934)  pp.&amp;nbsp;445–492
*W.  Stepanoff(=V.V. Stepanov),   "Sur quelques généralisations des fonctions presque périodiques"  C. R. Acad. Sci. Paris, 181  (1925)  pp.&amp;nbsp;90–92
*W.  Stepanoff(=V.V. Stepanov),   "Ueber einige Verallgemeinerungen der fastperiodischen Funktionen"  Math. Ann., 45  (1925)  pp.&amp;nbsp;473–498
*H. Weyl,   "Integralgleichungen und fastperiodische Funktionen"  Math. Ann., 97  (1927)  pp.&amp;nbsp;338–356

==External links==
*{{planetmath reference|id=7214|title=Almost periodic function (equivalent definition)}}

[[Category:Complex analysis]]
[[Category:Digital signal processing]]
[[Category:Audio engineering]]
[[Category:Real analysis]]
[[Category:Topological groups]]
[[Category:Fourier analysis]]
[[Category:Types of functions]]</text>
      <sha1>b50mzr7hg131be6ryzloln3rgd947rg</sha1>
    </revision>
  </page>
  <page>
    <title>Alpha (finance)</title>
    <ns>0</ns>
    <id>1736486</id>
    <revision>
      <id>863857561</id>
      <parentid>843941134</parentid>
      <timestamp>2018-10-13T14:54:16Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6851">{{other uses|Alpha (disambiguation)}}
{{refimprove|date=March 2016}}
'''Alpha''' is a measure of the [[active return]] on an [[investment]], the performance of that investment compared with a suitable [[stock market index|market index]]. An alpha of 1% means the investment's [[return on investment]] over a selected period of time was 1% better than the market during that same period; a negative alpha means the investment underperformed the market. Alpha, along with [[Beta (finance)|beta]], is one of two key coefficients in the [[capital asset pricing model]] used in [[modern portfolio theory]] and is closely related to other important quantities such as [[Standard deviation#Finance|standard deviation]], [[R-squared]] and the [[Sharpe ratio#Use in finance|Sharpe ratio]].&lt;ref&gt;* Loth, Richard, "[http://www.investopedia.com/articles/mutualfund/112002.asp 5 Ways To Measure Mutual Fund Risk]" ''Investopedia''&lt;/ref&gt;

In modern financial markets, where [[index fund]]s are widely available for purchase, alpha is commonly used to judge the performance of [[mutual fund]]s and similar investments. As these funds include various fees normally expressed in percent terms, the fund has to maintain an alpha greater than its fees in order to provide positive gains compared with an index fund. Historically, the vast majority of traditional funds have had negative alphas, which has led to a [[flight of capital]] to index funds and non-traditional [[hedge fund]]s.

It is also possible to analyze a portfolio of investments and calculate a theoretical performance, most commonly using the [[capital asset pricing model]] (CAPM). Returns on that portfolio can be compared with the theoretical returns, in which case the measure is known as [[Jensen's alpha]]. This is useful for non-traditional or highly focused funds, where a single stock index might not be representative of the investment's holdings.

==Definition in CAPM==
The '''alpha coefficient''' (&lt;math&gt;\alpha_i&lt;/math&gt;) is a parameter in the [[single index model]] (SIM). It is the [[root of a function|intercept]] of the [[security characteristic line]] (SCL), that is, the coefficient of the constant in a market model regression.
:&lt;math&gt;\mathrm{SCL} : R_{i,t} - R_{f} = \alpha_i + \beta_i\,  ( R_{M,t} - R_{f} ) + \epsilon_{i,t} \frac{}{}&lt;/math&gt;

It can be shown that in an [[Efficient-market hypothesis|efficient market]], the expected value of the alpha coefficient is zero. Therefore, the alpha coefficient indicates how an investment has performed after accounting for the risk it involved:

*&lt;math&gt;\alpha_i &lt; 0 &lt;/math&gt;: the investment has earned too little for its risk (or, was too risky for the return)
*&lt;math&gt;\alpha_i = 0 &lt;/math&gt;: the investment has earned a return adequate for the risk taken
*&lt;math&gt;\alpha_i &gt; 0 &lt;/math&gt;: the investment has a return in excess of the reward for the assumed risk

For instance, although a return of 20% may appear good, the investment can still have a negative alpha if it's involved in an excessively risky position.

In this context, because returns are being compared with the theoretical return of CAPM and not to a market index, it would be more accurate to use the term of [[Jensen's alpha]].

==Origin of the concept==
A belief in efficient markets spawned the creation of market capitalization weighted index funds that seek to replicate the performance of investing in an entire market in the weights that each of the equity securities comprises in the overall market.{{Citation needed|date=March 2008}}  The best examples for the US are the [[S&amp;P 500]] and the [[Wilshire 5000]] which approximately represent the 500 most widely held equities and the largest 5000 securities respectively, accounting for approximately 80%+ and 99%+ of the total market capitalization of the US market as a whole.

In fact, to many investors,{{Citation needed|date=March 2008}} this phenomenon created a new standard of performance that must be matched: an investment manager should not only avoid losing money for the client and should  make a certain amount of money, but in fact should make more money than the passive strategy of investing in everything equally (since this strategy appeared to be statistically more likely to be successful than the strategy of any one investment manager).  The name for the additional return above the [[expected return]] of the beta adjusted return of the market is called "Alpha".

==Relation to beta==
{{main|Beta (finance)}}
Besides an investment manager simply making more money than a passive strategy, there is another issue:
although the strategy of investing in every stock appeared to perform better than 75 percent of investment managers (see [[index fund]]), the price of the stock market as a whole [[conjuncture|fluctuates]] up and down, and could be on a downward decline for many years before returning to its previous price.

The passive strategy appeared to generate the market-beating return over periods of 10 years or more. This strategy may be risky for those who feel they might need to withdraw their money before a 10-year holding period, for example. Thus investment managers who employ a strategy which is less likely to lose money in a particular year are often chosen by those investors who feel that they might need to withdraw their money sooner.

Investors can use both alpha and beta to judge a manager's performance. If the manager has had a high alpha, but also a high beta, investors might not find that acceptable, because of the chance they might have to withdraw their money when the investment is doing poorly.

These concepts not only apply to investment managers, but to any kind of investment.

==References==
{{reflist}}

==Further reading==
* Bruce J. Feibel. ''Investment Performance Measurement''. New York: Wiley, 2003. {{ISBN|0-471-26849-6}}

==External links==
* [http://www.businessvaluation.us International Association of CPAs, Attorneys, and Management (IACAM) (Free Business Valuation E-Book Guidebook)]
* [http://financial-dictionary.thefreedictionary.com/Alpha The financial-dictionary entry on alpha]
* [http://www.investopedia.com/terms/a/alpha.asp Investopedia Alpha Definition]
* [https://web.archive.org/web/20111112055425/http://www.forexbasecamp.com/advanced-forex-concepts/five-technical-risk-ratios-in-forex-trading Five Technical Risk Ratios]
* [http://www.macroaxis.com/invest/alphaSearch/GOOG Alpha analysis for global equities] Free alpha look-up
* [http://www.tradersmagazine.com/issues/26_353/hedge-fund-lake-hill-creates-value-trading-index-options-111339-1.html Traders Magazine] Seeking Alpha - New York hedge fund creates value trading index options

{{stock market}}
{{Hedge funds}}

{{DEFAULTSORT:Alpha (Investment)}}
[[Category:Investment]]
[[Category:Mathematical finance]]
[[Category:Finance theories]]
[[Category:Financial ratios]]</text>
      <sha1>rkxjr92lxqma91gsioxlr11i93tsv9k</sha1>
    </revision>
  </page>
  <page>
    <title>Brunn–Minkowski theorem</title>
    <ns>0</ns>
    <id>7500545</id>
    <revision>
      <id>840099963</id>
      <parentid>834507129</parentid>
      <timestamp>2018-05-07T18:36:07Z</timestamp>
      <contributor>
        <username>Boriaj</username>
        <id>14665977</id>
      </contributor>
      <comment>/* Remarks */ The characterization of cases of equality was incorrect. Fixed.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3995">In [[mathematics]], the '''Brunn–Minkowski theorem''' (or '''Brunn–Minkowski inequality''') is an inequality relating the volumes (or more generally [[Lebesgue measure]]s) of [[compact space|compact]] [[subset]]s of [[Euclidean space]]. The original version of the Brunn–Minkowski theorem ([[Hermann Brunn]] 1887; [[Hermann Minkowski]] 1896) applied to convex sets; the generalization to compact nonconvex sets stated here is due to [[Lazar Lyusternik]] (1935).

==Statement of the theorem==
Let ''n'' ≥ 1 and let ''μ'' denote the [[Lebesgue measure]] on '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. Let ''A'' and ''B'' be two nonempty compact subsets of '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. Then the following [[inequality (mathematics)|inequality]] holds:

:&lt;math&gt;[ \mu (A + B) ]^{1/n} \geq [\mu (A)]^{1/n} + [\mu (B)]^{1/n},&lt;/math&gt;

where ''A'' + ''B'' denotes the [[Minkowski sum]]:

:&lt;math&gt;A + B := \{\, a + b \in \mathbb{R}^{n} \mid a \in A,\ b \in B \,\}.&lt;/math&gt;

==Remarks==
The proof of the Brunn–Minkowski theorem establishes that the function

:&lt;math&gt;A \mapsto [\mu (A)]^{1/n}&lt;/math&gt;

is [[concave function|concave]] in the sense that, for every pair of nonempty compact subsets ''A'' and ''B'' of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; and every 0 ≤ ''t'' ≤ 1,

:&lt;math&gt;\left[ \mu (t A + (1 - t) B ) \right]^{1/n} \geq t [ \mu (A) ]^{1/n} + (1 - t) [ \mu (B) ]^{1/n}.&lt;/math&gt;

For [[convex set|convex]] sets ''A'' and ''B'' of positive measure, the inequality in the theorem is strict
for 0 &lt; ''t'' &lt; 1 unless ''A'' and ''B'' are positive [[Homothetic transformation|homothetic]], i.e. are equal up to [[translation (geometry)|translation]] and [[Scaling (geometry)|dilation]] by a positive factor.

==See also==
* [[Isoperimetric inequality]]
* [[Milman's reverse Brunn–Minkowski inequality]]
* [[Minkowski–Steiner formula]]
* [[Prékopa–Leindler inequality]]
* [[Vitale's random Brunn–Minkowski inequality]]
* [[Mixed volume]]

==References==
* {{cite journal | author=Brunn, H. | author-link=Hermann Brunn | title=Über Ovale und Eiflächen | year = 1887 | version=Inaugural Dissertation, München}}
*{{cite book
 | last=Fenchel
 | first=Werner
 | author-link = Werner Fenchel
 |author2=Bonnesen, Tommy
 | title=Theorie der konvexen Körper
 | series=Ergebnisse der Mathematik und ihrer Grenzgebiete
 | volume=3
 | publisher=1. Verlag von Julius Springer
 | location=Berlin
 | year=1934
}}
*{{cite book
 | last=Fenchel
 | first=Werner
 | author-link=Werner Fenchel
 |author2=Bonnesen, Tommy
 | title=Theory of convex bodies
 | publisher=L. Boron, C. Christenson and B. Smith. BCS Associates
 | location=Moscow, Idaho
 | year=1987
}}
* {{cite book | last=Dacorogna | first=Bernard | title=Introduction to the Calculus of Variations | publisher=Imperial College Press | location=London | year=2004 | isbn=1-86094-508-2}}
* [[Heinrich Guggenheimer]] (1977) ''Applicable Geometry'', page 146, Krieger, Huntington {{ISBN|0-88275-368-1}} .
* {{cite journal | last=Lyusternik | first=Lazar A. | authorlink=Lazar Lyusternik | title=Die Brunn–Minkowskische Ungleichnung für beliebige messbare Mengen | journal = Comptes Rendus de l'Académie des Sciences de l'URSS |series=Nouvelle Série | volume = III | year = 1935 | pages = 55&amp;ndash;58}}
* {{cite book | last=Minkowski | first=Hermann | authorlink=Hermann Minkowski | title = Geometrie der Zahlen | location = Leipzig | publisher = Teubner | year = 1896}}
* {{cite news|last=Ruzsa|first=Imre&amp;nbsp;Z.|authorlink=Imre Z. Ruzsa|title=The Brunn–Minkowski inequality and nonconvex sets|journal=Geometriae Dedicata|volume=67|doi=10.1023/A:1004958110076|year=1997|number=3|pages=337–348|mr=1475877}}
* [[Rolf Schneider]], ''Convex bodies: the Brunn–Minkowski theory,'' Cambridge University Press, Cambridge, 1993.

{{DEFAULTSORT:Brunn-Minkowski theorem}}
[[Category:Theorems in measure theory]]
[[Category:Theorems in convex geometry]]
[[Category:Calculus of variations]]
[[Category:Geometric inequalities]]
[[Category:Sumsets]]
[[Category:Hermann Minkowski]]</text>
      <sha1>qkfq0eutmgvfex0edb9shnwcbllmsly</sha1>
    </revision>
  </page>
  <page>
    <title>Clarkson's inequalities</title>
    <ns>0</ns>
    <id>13409455</id>
    <revision>
      <id>790697673</id>
      <parentid>655542490</parentid>
      <timestamp>2017-07-15T13:54:24Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Statement of the inequalities */LaTeX spacing clean up, replaced: \, &lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2436">In [[mathematics]], '''Clarkson's inequalities''', named after [[James A. Clarkson]], are results in the theory of [[Lp space|''L''&lt;sup&gt;''p''&lt;/sup&gt; spaces]].  They give bounds for the ''L''&lt;sup&gt;''p''&lt;/sup&gt;-[[norm (mathematics)|norm]]s of the sum and difference of two [[measurable function]]s in ''L''&lt;sup&gt;''p''&lt;/sup&gt; in terms of the ''L''&lt;sup&gt;''p''&lt;/sup&gt;-norms of those functions individually.

==Statement of the inequalities==

Let (''X'',&amp;nbsp;Σ,&amp;nbsp;''&amp;mu;'') be a [[measure space]]; let ''f'',&amp;nbsp;''g''&amp;nbsp;:&amp;nbsp;''X''&amp;nbsp;→&amp;nbsp;'''R''' be measurable functions in ''L''&lt;sup&gt;''p''&lt;/sup&gt;.  Then, for 2&amp;nbsp;≤&amp;nbsp;''p''&amp;nbsp;&lt;&amp;nbsp;+∞,

:&lt;math&gt;\left\| \frac{f + g}{2} \right\|_{L^p}^p + \left\| \frac{f - g}{2} \right\|_{L^p}^p \le \frac{1}{2} \left( \| f \|_{L^p}^p + \| g \|_{L^p}^p \right).&lt;/math&gt;

For 1&amp;nbsp;&lt;&amp;nbsp;''p''&amp;nbsp;&lt;&amp;nbsp;2,

:&lt;math&gt;\left\| \frac{f + g}{2} \right\|_{L^p}^q + \left\| \frac{f - g}{2} \right\|_{L^p}^q \le \left( \frac{1}{2} \| f \|_{L^p}^p +\frac{1}{2} \| g \|_{L^p}^p \right)^\frac{q}{p},&lt;/math&gt;

where

:&lt;math&gt;\frac1{p} + \frac1{q} = 1,&lt;/math&gt;

i.e., ''q''&amp;nbsp;=&amp;nbsp;''p''&amp;nbsp;⁄&amp;nbsp;(''p''&amp;nbsp;&amp;minus;&amp;nbsp;1).

The case ''p''&amp;nbsp;≥&amp;nbsp;2 is somewhat easier to prove, being a simple application of the [[triangle inequality]] and the [[convex function|convexity]] of

:&lt;math&gt;x \mapsto x^p. &lt;/math&gt;

==References==
*{{citation
 | last = Clarkson | first = James A. | authorlink = James A. Clarkson
 | doi = 10.2307/1989630
 | issue = 3
 | journal = [[Transactions of the American Mathematical Society]]
 | mr = 1501880
 | pages = 396–414
 | title = Uniformly convex spaces
 | volume = 40
 | year = 1936}}.
*{{citation
 | last = Hanner | first = Olof | authorlink = Olof Hanner
 | doi = 10.1007/BF02589410
 | issue = 3
 | journal = [[Arkiv för Matematik]]
 | mr = 0077087
 | pages = 239–244
 | title = On the uniform convexity of ''L''&lt;sup&gt;''p''&lt;/sup&gt; and ''ℓ''&lt;sup&gt;''p''&lt;/sup&gt;
 | volume = 3
 | year = 1956}}.
*{{citation
 | last = Friedrichs | first = K. O. | authorlink = Kurt O. Friedrichs
 | doi = 10.1002/cpa.3160230405
 | journal = [[Communications on Pure and Applied Mathematics]]
 | mr = 0264372
 | pages = 603–607
 | title = On Clarkson's inequalities
 | volume = 23
 | year = 1970}}.

==External links==
* {{PlanetMath|urlname=ClarksonInequality|title=Clarkson inequality}}

[[Category:Banach spaces]]
[[Category:Inequalities]]
[[Category:Measure theory]]</text>
      <sha1>16w2dzr16pzdxagq8ag1viod7d4mk34</sha1>
    </revision>
  </page>
  <page>
    <title>Commutative property</title>
    <ns>0</ns>
    <id>294390</id>
    <revision>
      <id>864356295</id>
      <parentid>863532407</parentid>
      <timestamp>2018-10-16T17:42:15Z</timestamp>
      <contributor>
        <username>Swpb</username>
        <id>1921264</id>
      </contributor>
      <comment>/* Symmetry */clean up - [[WP:ACCIM]] rule #6</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20439">{{Other uses|Commute (disambiguation)}}
{{Use dmy dates|date=July 2013}}
[[File:Commutativity of binary operations (without question mark).svg|thumb|An operation &lt;math&gt;\circ&lt;/math&gt; is commutative [[If and only if|iff]] &lt;math&gt;x\circ y = y \circ x&lt;/math&gt; for each &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;. This image illustrates this property with the concept of an operation as a "calculation machine". It doesn't matter for the output &lt;math&gt;x\circ y&lt;/math&gt; or &lt;math&gt;y \circ x&lt;/math&gt; respectively which order the arguments &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; have – the final outcome is the same.]]
In [[mathematics]], a [[binary operation]] is '''commutative''' if changing the order of the [[operand]]s does not change the result. It is a fundamental property of many [[binary operations]], and many [[mathematical proof]]s depend on it. Most familiar as the name of the property that says {{nowrap|1="3 + 4 = 4 + 3"}} or {{nowrap|1="2 × 5 = 5 × 2"}}, the property can also be used in more advanced settings. The name is needed because there are operations, such as  [[division (mathematics)|division]] and [[subtraction]], that do not have it (for example, {{nowrap|"3 − 5 ≠ 5 − 3"}}); such operations are ''not'' commutative, and so are referred to as ''noncommutative operations''. The idea that simple operations such as the [[multiplication (mathematics)|multiplication]] and [[addition]] of numbers are commutative, was for many years implicitly assumed. Thus, this property was not named until the 19th century, when mathematics started to become formalized.&lt;ref name="ReferenceA" /&gt;&lt;ref name=":0" /&gt; A corresponding property exists for [[binary relation]]s; a binary relation is said to be [[symmetric relation|symmetric]] if the relation applies regardless of the order of its operands; for example, [[Equality (mathematics)|equality]] is symmetric as two equal mathematical objects are equal regardless of their order.&lt;ref&gt;{{MathWorld|id=SymmetricRelation|title=Symmetric Relation}}&lt;/ref&gt;

==Common uses==
The ''commutative property'' (or ''commutative law'') is a property generally associated with binary operations and [[Function (mathematics)|functions]].  If the commutative property holds for a pair of elements under a certain binary operation then the two elements are said to ''commute'' under that operation.

==Mathematical definitions==
{{Further|Symmetric function}}
The term "commutative" is used in several related senses.&lt;ref name="Krowne, p.1"&gt;Krowne, p.1&lt;/ref&gt;&lt;ref&gt;Weisstein, ''Commute'', p.1&lt;/ref&gt;

{{ordered list|1=
A binary operation &lt;math&gt;*&lt;/math&gt; on a [[Set (mathematics)|set]] ''S'' is called ''commutative'' if:
:&lt;math&gt;x * y = y * x\qquad\mbox{for all }x,y\in S&lt;/math&gt;

An operation that does not satisfy the above property is called ''non-commutative''.
|2=
One says that ''x commutes'' with ''y'' under &lt;math&gt;*&lt;/math&gt; if:
:&lt;math&gt; x * y = y * x &lt;/math&gt;
|3=
A [[binary function]] &lt;math&gt;f \colon A \times A \to B&lt;/math&gt; is called ''commutative'' if:
:&lt;math&gt;f(x, y) = f(y, x)\qquad\mbox{for all }x,y\in A&lt;/math&gt;
}}

== Examples ==

===Commutative operations in everyday life===
[[File:Commutative Addition.svg|thumb|The cumulation of apples, which can be seen as an addition of natural numbers, is commutative.]]
*Putting on socks resembles a commutative operation since which sock is put on first is unimportant. Either way, the result (having both socks on), is the same. In contrast, putting on underwear and trousers is not commutative.
*The commutativity of addition is observed when paying for an item with cash.  Regardless of the order the bills are handed over in, they always give the same total.

===Commutative operations in mathematics===
[[File:Vector Addition.svg|thumb|The addition of vectors is commutative, because &lt;math&gt;\vec a+\vec b=\vec b+ \vec a&lt;/math&gt;.]]
Two well-known examples of commutative binary operations:&lt;ref name="Krowne, p.1"/&gt;
* The [[addition]] of [[real number]]s is commutative, since
::&lt;math&gt;y + z = z + y \qquad\mbox{for all }y,z\in \mathbb{R}&lt;/math&gt;
:For example 4 + 5 = 5 + 4, since both [[Expression (mathematics)|expression]]s equal 9.
* The [[multiplication]] of [[real number]]s is commutative, since
::&lt;math&gt;y z = z y \qquad\mbox{for all }y,z\in \mathbb{R}&lt;/math&gt;
:For example, 3 × 5 = 5 × 3, since both expressions equal 15.
* Some binary [[truth function]]s are also commutative, since the [[truth table]]s for the functions are the same when one changes the order of the operands. 
:For example, the [[logical biconditional]] function p ↔ q is equivalent to q ↔ p. This function is also written as p [[If and only if|IFF]] q, or as p ≡ q, or as E''pq''. 
:The last form is an example of the most concise notation in the article on truth functions, which lists the sixteen possible binary truth functions of which eight are commutative: V''pq'' = V''qp''; A''pq'' (OR) = A''qp''; D''pq'' (NAND) = D''qp''; E''pq'' (IFF) = E''qp''; J''pq'' = J''qp''; K''pq'' (AND) = K''qp''; X''pq'' (NOR) = X''qp''; O''pq'' = O''qp''.
* Further examples of commutative binary operations include addition and multiplication of [[complex number]]s, addition and [[scalar product|scalar multiplication]] of [[vector space|vectors]], and [[intersection (set theory)|intersection]] and [[union (set theory)|union]] of [[Set (mathematics)|sets]].

===Noncommutative operations in daily life===

*[[Concatenation]], the act of joining character strings together, is a noncommutative operation. For example,
:{{nowrap|1=EA + T = EAT &amp;ne; TEA = T + EA}}
*Washing and drying clothes resembles a noncommutative operation; washing and then drying produces a markedly different result to drying and then washing.
*Rotating a book 90° around a vertical axis then 90° around a horizontal axis produces a different orientation than when the rotations are performed in the opposite order.
*The twists of the [[Rubik's Cube]] are noncommutative. This can be studied using [[group theory]].
*Thought processes are noncommutative: A person asked a question (A) and then a question (B) may give different answers to each question than a person asked first (B) and then (A), because asking a question may change the person's state of mind.
*The act of dressing is either commutative or non-commutative, depending on the items. Putting on underwear and normal clothing is noncommutative. Putting on left and right socks is commutative.

===Noncommutative operations in mathematics===
Some noncommutative binary operations:&lt;ref&gt;Yark, p.1.&lt;/ref&gt;

====Subtraction and division====

[[Subtraction]] is noncommutative, since &lt;math&gt;0 - 1 \neq 1 - 0&lt;/math&gt;.

[[Division (mathematics)|Division]] is noncommutative, since &lt;math&gt;1 \div 2 \neq 2 \div 1&lt;/math&gt;.

====Truth functions====

Some [[truth function]]s are noncommutative, since the [[truth table]]s for the functions are different when one changes the order of the operands. For example, the truth tables for ''f'' (A, B) {{=}} A Λ ¬B (A AND NOT B) and ''f'' (B, A) {{=}} B Λ ¬A are
:{{aligned table
 | class=wikitable
 | style=text-align:center; width:20%;
 | cols=4
 | col3style=width:30%;
 | col4style=width:30%;
 | row1header=yes
 | A | B | ''f''&amp;nbsp;(A, B) | ''f''&amp;nbsp;(B, A)
 | F | F | F | F
 | F | T | F | T
 | T | F | T | F
 | T | T | F | F
 }}

For the eight noncommutative functions, B''qp'' = C''pq''; M''qp'' = L''pq''; C''qp'' = B''pq''; L''qp'' = M''pq''; F''qp'' = G''pq''; I''qp'' = H''pq''; G''qp'' = F''pq''; H''qp'' = I''pq''.&lt;ref&gt;[[Jozef Maria Bochenski]] (1959), ''Precis of [[Mathematical Logic]]'', rev., Albert Menne, ed. and trans., Otto Bird, New York:  Gordon and Breach, Part II, Sec. 3.32, "16 dyadic truth functors", ([[truth tables]]), p. 11.&lt;/ref&gt;

====Matrix multiplication====

[[Matrix (mathematics)|Matrix]] multiplication is almost always noncommutative, for example:
:&lt;math&gt;
  \begin{bmatrix}
    0 &amp; 2 \\
    0 &amp; 1
  \end{bmatrix} =
  \begin{bmatrix}
    1 &amp; 1 \\
    0 &amp; 1
  \end{bmatrix} \cdot
  \begin{bmatrix}
    0 &amp; 1 \\
    0 &amp; 1
  \end{bmatrix} \neq
  \begin{bmatrix}
    0 &amp; 1 \\
    0 &amp; 1
  \end{bmatrix} \cdot
  \begin{bmatrix}
    1 &amp; 1 \\
    0 &amp; 1
  \end{bmatrix} =
  \begin{bmatrix}
    0 &amp; 1 \\
    0 &amp; 1
  \end{bmatrix}
&lt;/math&gt;

====Vector product====

The vector product (or [[cross product]]) of two vectors in three dimensions is [[anticommutativity|anti-commutative]]; i.e., ''b'' × ''a'' =  −(''a'' × ''b'').

==History and etymology==
[[File:Commutative Word Origin.PNG|right|thumb|250px|The first known use of the term was in a French Journal published in 1814]]

Records of the implicit use of the commutative property go back to ancient times.  The [[Egypt]]ians used the commutative property of [[multiplication]] to simplify computing [[Product (mathematics)|products]].&lt;ref&gt;Lumpkin, p.11&lt;/ref&gt;&lt;ref&gt;Gay and Shute, p.?&lt;/ref&gt; [[Euclid]] is known to have assumed the commutative property of multiplication in his book [[Euclid's Elements|''Elements'']].&lt;ref&gt;O'Conner and Robertson, ''Real Numbers''&lt;/ref&gt;  Formal uses of the commutative property arose in the late 18th and early 19th centuries, when mathematicians began to work on a theory of functions.  Today the commutative property is a well-known and basic property used in most branches of mathematics.

The first recorded use of the term ''commutative'' was in a memoir by [[François-Joseph Servois|François Servois]] in 1814,&lt;ref name="ReferenceA"&gt;Cabillón and Miller, ''Commutative and Distributive''&lt;/ref&gt;&lt;ref&gt;O'Conner and Robertson, ''Servois''&lt;/ref&gt; which used the word ''commutatives'' when describing functions that have what is now called the commutative property.  The word is a combination of the French word ''commuter'' meaning "to substitute or switch" and the suffix ''-ative'' meaning "tending to" so the word literally means "tending to substitute or switch."  The term then appeared in English in 1838&lt;ref name=":0"&gt;{{cite book|title=Mathematics in Victorian Britain|editor1-first=Raymond|editor1-last=Flood|editor2-first=Adrian|editor2-last=Rice|editor3-first=Robin|editor3-last=Wilson|editor3-link=Robin Wilson (mathematician)|publisher=[[Oxford University Press]]|year=2011|url=https://books.google.com/books?id=YruifIx88AQC&amp;pg=PA4|page=4}}&lt;/ref&gt; in [[Duncan Farquharson Gregory]]'s article entitled "On the real nature of symbolical algebra" published in 1840 in the [[Royal Society of Edinburgh|Transactions of the Royal Society of Edinburgh]].&lt;ref&gt;{{Cite journal|author=D. F. Gregory|title=On the real nature of symbolical algebra|periodical=Transactions of the Royal Society of Edinburgh|volume=14|pages=208–216|year=1840|url=https://archive.org/details/transactionsofro14royal}}&lt;/ref&gt;

== Propositional logic ==
{{Transformation rules}}

=== Rule of replacement ===
In truth-functional propositional logic, ''commutation'',&lt;ref&gt;Moore and Parker&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Copi |first=Irving M. |last2=Cohen |first2=Carl |title=Introduction to Logic |publisher=Prentice Hall |year=2005}}&lt;/ref&gt; or ''commutativity''&lt;ref&gt;{{cite book |title=A Concise Introduction to Logic 4th edition |last=Hurley |first=Patrick  |coauthors= |year=1991 |publisher=Wadsworth Publishing }}&lt;/ref&gt; refer to two [[Validity (logic)|valid]] [[rule of replacement|rules of replacement]]. The rules allow one to transpose [[propositional variable]]s within [[well-formed formula|logical expressions]] in [[formal proof|logical proofs]]. The rules are:

:&lt;math&gt;(P \lor Q) \Leftrightarrow (Q \lor P)&lt;/math&gt;
and 
:&lt;math&gt;(P \land Q) \Leftrightarrow (Q \land P)&lt;/math&gt;

where "&lt;math&gt;\Leftrightarrow&lt;/math&gt;" is a [[metalogic]]al [[Symbol (formal)|symbol]] representing "can be replaced in a [[Formal proof|proof]] with."

=== Truth functional connectives ===

''Commutativity'' is a property of some [[logical connective]]s of truth functional [[propositional logic]]. The following [[logical equivalence]]s demonstrate that commutativity is a property of particular connectives. The following are truth-functional [[tautology (logic)|tautologies]].

;Commutativity of conjunction:&lt;math&gt;(P \land Q) \leftrightarrow (Q \land P)&lt;/math&gt;
;Commutativity of disjunction:&lt;math&gt;(P \lor Q) \leftrightarrow (Q \lor P)&lt;/math&gt;
;Commutativity of implication (also called the law of permutation):&lt;math&gt;(P \to (Q \to R)) \leftrightarrow (Q \to (P \to R))&lt;/math&gt;
;Commutativity of equivalence (also called the complete commutative law of equivalence):&lt;math&gt;(P \leftrightarrow Q) \leftrightarrow (Q \leftrightarrow P)&lt;/math&gt;

== Set theory ==
In [[group theory|group]] and [[set theory]], many algebraic structures are called commutative when certain operands satisfy the commutative property.  In higher branches of mathematics, such as [[Mathematical analysis|analysis]] and [[linear algebra]] the commutativity of well-known operations (such as [[addition]] and [[multiplication]] on real and complex numbers) is often used (or implicitly assumed) in proofs.&lt;ref&gt;Axler, p.2&lt;/ref&gt;&lt;ref name="Gallian, p.34"&gt;Gallian, p.34&lt;/ref&gt;&lt;ref&gt;p. 26,87&lt;/ref&gt;

==Mathematical structures and commutativity==
* A [[commutative semigroup]] is a set endowed with a total, [[associativity|associative]] and commutative operation.
* If the operation additionally has an [[identity element]], we have a [[commutative monoid]]
* An [[abelian group]], or ''commutative group'' is a [[group (mathematics)|group]] whose group operation is commutative.&lt;ref name="Gallian, p.34"/&gt;
* A [[commutative ring]] is a [[ring (mathematics)|ring]] whose [[multiplication]] is commutative. (Addition in a ring is always commutative.)&lt;ref&gt;Gallian p.236&lt;/ref&gt;
* In a [[field (mathematics)|field]] both addition and multiplication are commutative.&lt;ref&gt;Gallian p.250&lt;/ref&gt;

==Related properties==

===Associativity===
{{Main|Associative property}}

The associative property is closely related to the commutative property.  The associative property of an expression containing two or more occurrences of the same operator states that the order operations are performed in does not affect the final result, as long as the order of terms doesn't change. In contrast, the commutative property states that the order of the terms does not affect the final result.

Most commutative operations encountered in practice are also associative. However, commutativity does not imply associativity. A counterexample is the function

:&lt;math&gt;f(x, y) = \frac{x + y}{2},&lt;/math&gt;

which is clearly commutative (interchanging ''x'' and ''y'' does not affect the result), but it is not associative (since, for example, &lt;math&gt;f(-4, f(0, +4)) = -1&lt;/math&gt; but &lt;math&gt;f(f(-4, 0), +4) = +1&lt;/math&gt;).
More such examples may be found in [[commutative non-associative magmas]].

===Distributive===
{{Main|Distributive property}}

===Symmetry===
[[File:Symmetry Of Addition.svg|right|thumb|200px|Graph showing the symmetry of the addition function]]
{{Main|Symmetry in mathematics}}

Some forms of symmetry can be directly linked to commutativity.  When a commutative operator is written as a binary function then the resulting function is symmetric across the line ''y = x''.  As an example, if we let a function ''f'' represent addition (a commutative operation) so that ''f''(''x'',''y'') = ''x'' + ''y'' then ''f'' is a symmetric function, which can be seen in the adjacent image.

For relations, a [[symmetric relation]] is analogous to a commutative operation, in that if a relation ''R'' is symmetric, then &lt;math&gt;a R b \Leftrightarrow b R a&lt;/math&gt;.

==Non-commuting operators in quantum mechanics==
{{Main|Canonical commutation relation}}

In [[Introduction to quantum mechanics|quantum mechanics]] as formulated by [[Erwin Schrödinger|Schrödinger]], physical variables are represented by [[linear operators]] such as ''x'' (meaning multiply by ''x''), and &lt;math&gt;\frac{d}{dx}&lt;/math&gt;. These two operators do not commute as may be seen by considering the effect of their [[Function composition|compositions]] &lt;math&gt;x \frac{d}{dx}&lt;/math&gt; and &lt;math&gt;\frac{d}{dx} x&lt;/math&gt; (also called products of operators) on a one-dimensional [[wave function]] &lt;math&gt;\psi(x)&lt;/math&gt;:

::&lt;math&gt; x\cdot {\mathrm{d}\over \mathrm{d}x}\psi = x\cdot \psi' \ \neq \ \psi + x\cdot \psi' = {\mathrm{d}\over \mathrm{d}x}\left( x\cdot \psi \right) &lt;/math&gt;

According to the [[uncertainty principle]] of [[Werner Heisenberg|Heisenberg]], if the two operators representing a pair of variables do not commute, then that pair of variables are mutually [[complementarity (physics)|complementary]], which means they cannot be simultaneously measured or known precisely. For example, the position and the linear [[momentum]] in the ''x''-direction of a particle are represented by the operators &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;-i \hbar \frac{\partial}{\partial x}&lt;/math&gt;, respectively (where &lt;math&gt;\hbar&lt;/math&gt; is the [[Planck constant|reduced Planck constant]]). This is the same example except for the constant &lt;math&gt;-i \hbar&lt;/math&gt;, so again the operators do not commute and the physical meaning is that the position and linear momentum in a given direction are complementary.

==See also==
{{Wiktionary}}
*[[Anticommutativity]]
*[[Centralizer|Centralizer and normalizer]] (also called a commutant)
*[[Commutative diagram]]
*[[Commutative (neurophysiology)]]
*[[Commutator]]
*[[Parallelogram law]]
*[[Particle statistics]] (for commutativity in [[physics]])
*[[Quasi-commutative property]]
*[[Trace monoid]]
*[[Commuting probability]]

==Notes==
{{Reflist|2}}

==References==

=== Books ===

*{{Cite book| first=Sheldon | last=Axler | title=Linear Algebra Done Right, 2e | publisher=Springer | year=1997 | isbn=0-387-98258-2}}
:''Abstract algebra theory.  Covers commutativity in that context.  Uses property throughout book.

*{{Cite book |ref=harv |last=Copi |first=Irving M. |last2=Cohen |first2=Carl |title=Introduction to Logic |publisher=Prentice Hall |year=2005}}
*{{Cite book|first=Joseph|last=Gallian|title=Contemporary Abstract Algebra, 6e|year=2006|isbn=0-618-51471-6|publisher=Houghton Mifflin|location=Boston, Mass.}}
:''Linear algebra theory.  Explains commutativity in chapter 1, uses it throughout.''

*{{Cite book| first=Frederick | last=Goodman | title=Algebra: Abstract and Concrete, Stressing Symmetry, 2e | publisher=Prentice Hall | year=2003 | isbn=0-13-067342-0}}
:''Abstract algebra theory.  Uses commutativity property throughout book.

*{{Cite book |title=A Concise Introduction to Logic 4th edition |last=Hurley |first=Patrick  |coauthors= |year=1991 |publisher=Wadsworth Publishing }}

===Articles===
*https://web.archive.org/web/20070713072942/http://www.ethnomath.org/resources/lumpkin1997.pdf Lumpkin, B. (1997). The Mathematical Legacy Of Ancient Egypt - A Response To Robert Palter. Unpublished manuscript.
:''Article describing the mathematical ability of ancient civilizations.''
*Robins, R. Gay, and Charles C. D. Shute. 1987. ''The Rhind Mathematical Papyrus: An Ancient Egyptian Text''. London: British Museum Publications Limited. {{isbn|0-7141-0944-4}}
:''Translation and interpretation of the [[Rhind Mathematical Papyrus]].''

===Online resources===
*{{springer|title=Commutativity|id=p/c023420|ref=none}}
*Krowne, Aaron, {{PlanetMath|title=Commutative|urlname=Commutative}}, Accessed 8 August 2007.
:''Definition of commutativity and examples of commutative operations''
*{{MathWorld|title=Commute|urlname=Commute}}, Accessed 8 August 2007.
:''Explanation of the term commute''
*[http://planetmath.org/?op=getuser&amp;id=2760 Yark]. {{PlanetMath|title=Examples of non-commutative operations|urlname=ExampleOfCommutative}}, Accessed 8 August 2007
:''Examples proving some noncommutative operations''
*O'Conner, J J and Robertson, E F. [http://www-history.mcs.st-andrews.ac.uk/HistTopics/Real_numbers_1.html MacTutor history of real numbers], Accessed 8 August 2007
:''Article giving the history of the real numbers''
*Cabillón, Julio and Miller, Jeff. [http://jeff560.tripod.com/c.html Earliest Known Uses Of Mathematical Terms], Accessed 22 November 2008
:''Page covering the earliest uses of mathematical terms''
*O'Conner, J J and Robertson, E F. [http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Servois.html MacTutor biography of François Servois], Accessed 8 August 2007
:''Biography of Francois Servois, who first used the term''

{{Good article}}

[[Category:Abstract algebra]]
[[Category:Elementary algebra]]
[[Category:Rules of inference]]
[[Category:Symmetry]]
[[Category:Binary operations|*Commutativity]]
[[Category:Concepts in physics]]
[[Category:Functional analysis]]</text>
      <sha1>euesbuzgt47pg66oa4li6s1if0xlu5v</sha1>
    </revision>
  </page>
  <page>
    <title>Complex dimension</title>
    <ns>0</ns>
    <id>2783513</id>
    <revision>
      <id>831535771</id>
      <parentid>744764601</parentid>
      <timestamp>2018-03-21T02:14:59Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>author links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2709">In [[mathematics]], '''complex dimension''' usually refers to the dimension of a [[complex manifold]] ''M'', or a complex [[dimension of an algebraic variety|algebraic variety]] ''V''.&lt;ref&gt;{{citation|title=Dictionary of Classical and Theoretical Mathematics|first1=Catherine|last1=Cavagnaro|first2=William T., II|last2=Haight|publisher=CRC Press|year=2001|isbn=9781584880509|page=22|url=https://books.google.com/books?id=ljvmahfSDtwC&amp;pg=PA22}}.&lt;/ref&gt; If the complex dimension is ''d'', the '''real dimension''' will be 2''d''.&lt;ref&gt;{{citation|title=Introduction to Mechanics and Symmetry: A Basic Exposition of Classical Mechanical Systems|volume=17|series=Texts in Applied Mathematics|first1=Jerrold E.|last1=Marsden|author1-link=Jerrold E. Marsden| first2=Tudor S.|last2=Ratiu|author2-link=Tudor Ratiu| publisher=Springer|year=1999|isbn=9780387986432|page=152|url=https://books.google.com/books?id=I2gH9ZIs-3AC&amp;pg=PA152}}.&lt;/ref&gt; That is, the [[smooth manifold]] ''M'' has dimension 2''d''; and away from any [[Singular point of an algebraic variety|singular point]] ''V'' will also be a smooth manifold of dimension 2''d''. 

However, for a  [[real algebraic variety]] (that is a variety defined by equations with real coefficients), its [[dimension of an algebraic variety|dimension]] refers commonly to its complex dimension, and its [[Dimension of an algebraic variety#Real dimension|real dimension]] refers to the maximum of the dimensions of the manifolds contained in the set of its real points. The real dimension is not greater than the dimension, and equals it if the variety is irreducible and has real points that are [[Singular point of an algebraic variety|nonsingular]].
For example, the equation &lt;math&gt;x^2+y^2+z^2=0&lt;/math&gt; defines a variety of (complex) dimension 2 (a surface), but of real dimension 0 — it has only one real point, (0, 0, 0), which is singular.&lt;ref&gt;{{citation|title=Numerically Solving Polynomial Systems with Bertini|volume=25|series=Software, Environments, and Tools|first1=Daniel J.|last1=Bates|first2=Jonathan D.|last2=Hauenstein|first3=Andrew J.|last3=Sommese|first4=Charles W.|last4=Wampler|publisher=SIAM|year=2013|isbn=9781611972702|page=225|url=https://books.google.com/books?id=gHYXAgAAQBAJ&amp;pg=PA225}}.&lt;/ref&gt;

The same points apply to [[codimension]]. For example a smooth [[complex hypersurface]] in [[complex projective space]] of dimension ''n'' will be a manifold of dimension 2(''n'' &amp;minus; 1). A complex [[hyperplane]] does not separate a complex projective space into two components, because it has real codimension 2.

==References==
{{reflist}}

[[Category:Complex manifolds]]
[[Category:Algebraic geometry]]
[[Category:Dimension]]
{{mathanalysis-stub}}</text>
      <sha1>ljrjjlpttbcpxa2pvrdoi6zocomy01o</sha1>
    </revision>
  </page>
  <page>
    <title>Davenport–Schinzel sequence</title>
    <ns>0</ns>
    <id>20232529</id>
    <revision>
      <id>846559297</id>
      <parentid>790348981</parentid>
      <timestamp>2018-06-19T14:14:02Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12730">In [[combinatorics]], a '''Davenport–Schinzel sequence''' is a [[sequence]] of symbols in which the number of times any two symbols may appear in alternation is limited. The maximum possible length of a Davenport–Schinzel sequence is bounded by the number of its distinct symbols multiplied by a small but nonconstant factor that depends on the number of alternations that are allowed. Davenport–Schinzel sequences were first defined in 1965 by [[Harold Davenport]] and [[Andrzej Schinzel]] to analyze [[linear differential equation]]s. Following {{harvtxt|Atallah|1985}} these sequences and their length bounds have also become a standard tool in [[discrete geometry]] and in the analysis of [[Computational geometry|geometric algorithms]].&lt;ref&gt;{{harvtxt|Sharir|Agarwal|1995}}, pp. x and 2.&lt;/ref&gt;

==Definition==
A finite sequence ''U'' = ''u''&lt;sub&gt;1&lt;/sub&gt;, ''u''&lt;sub&gt;2&lt;/sub&gt;, ''u''&lt;sub&gt;3&lt;/sub&gt;, is said to be a Davenport–Schinzel sequence of order ''s'' if it satisfies the following two properties:
#No two consecutive values in the sequence are equal to each other.
#If ''x'' and ''y'' are two distinct values occurring in the sequence, then the sequence does not contain a subsequence ... ''x'', ... ''y'', ..., ''x'', ..., ''y'', ... consisting of ''s''&amp;nbsp;+&amp;nbsp;2 values alternating between ''x'' and ''y''.

For instance, the sequence
:1, 2, 1, 3, 1, 3, 2, 4, 5, 4, 5, 2, 3
is a Davenport–Schinzel sequence of order 3: it contains alternating subsequences of length four, such as ...1, ... 2, ... 1, ... 2, ... (which appears in four different ways as a subsequence of the whole sequence) but it does not contain any alternating subsequences of length five.

If a Davenport–Schinzel sequence of order ''s'' includes ''n'' distinct values, it is called an (''n'',''s'') Davenport–Schinzel sequence, or a ''DS''(''n'',''s'')-sequence.&lt;ref&gt;See {{harvtxt|Sharir|Agarwal|1995}}, p. 1, for this notation.&lt;/ref&gt;

==Length bounds==
The complexity of ''DS''(''n'',''s'')-sequence has been analyzed [[asymptotics|asymptotically]] in the limit as ''n'' goes to infinity, with the assumption that ''s'' is a fixed constant, and nearly tight bounds are known for all ''s''. Let λ&lt;sub&gt;''s''&lt;/sub&gt;(''n'') denote the length of the longest ''DS''(''n'',''s'')-sequence. The best bounds known on λ&lt;sub&gt;''s''&lt;/sub&gt; involve the [[Ackermann function#Inverse|inverse Ackermann function]]
:&amp;alpha;(''n'') = min { ''m'' | ''A''(''m'',''m'') ≥ ''n'' },
where ''A'' is the Ackermann function. Due to the very rapid growth of the Ackermann function, its inverse α grows very slowly, and is at most four for problems of any practical size.&lt;ref&gt;{{harvtxt|Sharir|Agarwal|1995}}, p.14.&lt;/ref&gt;

Using [[big O notation|big O and big &amp;Theta; notation]], the following bounds are known:
*&lt;math&gt;\lambda_0(n)=1&lt;/math&gt;.
*&lt;math&gt;\lambda_1(n)=n&lt;/math&gt;.&lt;ref name="DS12"&gt;{{harvtxt|Sharir|Agarwal|1995}}, p.6.&lt;/ref&gt;
*&lt;math&gt;\lambda_2(n)=2n-1&lt;/math&gt;.&lt;ref name="DS12" /&gt;
*&lt;math&gt;\lambda_3(n) = 2n\alpha(n)+O(n)&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Sharir|Agarwal|1995}}, Chapter 2, pp. 12–42; {{harvtxt|Hart|Sharir|1986}}; {{harvtxt|Komjáth|1988}}; {{harvtxt|Klazar|1999}}; {{harvtxt|Nivasch|2009}}; {{harvtxt|Pettie|2015}}.&lt;/ref&gt; This complexity bound can be realized to within a factor of 2 by line segments: there exist arrangements of ''n'' line segments in the plane whose lower envelopes have complexity Ω(''n''&amp;nbsp;α(''n'')).&lt;ref&gt;{{harvtxt|Sharir|Agarwal|1995}}, Chapter 4, pp. 86–114; {{harvtxt|Wiernik|Sharir|1988}}.&lt;/ref&gt;
*&lt;math&gt;\lambda_4(n) = \Theta(n2^{\alpha(n)})&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Sharir|Agarwal|1995}}, Chapter 3, pp. 43–85; {{harvtxt|Agarwal|Sharir|1989}}; {{harvtxt|Nivasch|1999}}; {{harvtxt|Pettie|2015}}.&lt;/ref&gt;
*&lt;math&gt;\lambda_5(n) = \Theta(n\alpha(n)2^{\alpha(n)})&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Pettie|2015}}.&lt;/ref&gt;
*For both even and odd values of ''s'' ≥ 6,
::&lt;math&gt;\lambda_s(n)=n\cdot 2^{\frac{1}{t!}\alpha(n)^t + O(\alpha(n)^{t-1})}&lt;/math&gt;, where &lt;math&gt;t = \left\lfloor\frac{s-2}{2}\right\rfloor&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Sharir|Agarwal|1995}}, Chapter 3, pp. 43–85; {{harvtxt|Agarwal|Sharir|1989}}; {{harvtxt|Nivasch|1999}}; {{harvtxt|Pettie|2015}}.&lt;/ref&gt;

The value of λ&lt;sub&gt;''s''&lt;/sub&gt;(''n'') is also known when ''s'' is variable but ''n'' is a small constant:&lt;ref&gt;{{harvtxt|Roselle|Stanton|1970/71}}.&lt;/ref&gt;
:&lt;math&gt;\lambda_s(1)=1\,&lt;/math&gt;
:&lt;math&gt;\lambda_s(2)=s+1\,&lt;/math&gt;
:&lt;math&gt;\lambda_s(3)=3s-2+(s\, \bmod \, 2)&lt;/math&gt;
:&lt;math&gt;\lambda_s(4)=6s-2+(s\, \bmod\, 2).&lt;/math&gt;

When ''s'' is a function of ''n'' the upper and lower bounds on Davenport-Schinzel sequences are not tight.
*When &lt;math&gt;s &gt; n^{1/t}(t-1)!&lt;/math&gt;, &lt;math&gt;\lambda_s(n) = \Omega(n^2s/(t-1)!)&lt;/math&gt; and &lt;math&gt;\lambda_s(n) = O(n^2s)&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Roselle|Stanton|1970/71}}; {{harvtxt|Wellman|Pettie|2016}}.&lt;/ref&gt;
*When &lt;math&gt;\log\log n &lt; s = n^{o(1)}&lt;/math&gt;,  &lt;math&gt;\lambda_s(n) = \Omega\left(n\left(\frac{s}{2\log\log_s n}\right)^{\log\log_s n}\right)&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Wellman|Pettie|2016}}.&lt;/ref&gt;
*When &lt;math&gt;s \le \log\log n&lt;/math&gt;, &lt;math&gt;\lambda_s(n) = \Omega(n2^s)&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Wellman|Pettie|2016}}.&lt;/ref&gt;

==Application to lower envelopes==
[[Image:Line segment lower envelope.svg|thumb|300px|A Davenport–Schinzel sequence of order 3 formed by the lower envelope of line segments.]]
The ''lower envelope'' of a set of functions ƒ&lt;sub&gt;''i''&lt;/sub&gt;(''x'') of a [[Function of a real variable|real variable]] ''x'' is the function given by their pointwise minimum:
:&amp;fnof;(''x'')&amp;nbsp;=&amp;nbsp;min&lt;sub&gt;''i''&lt;/sub&gt;&amp;fnof;&lt;sub&gt;''i''&lt;/sub&gt;(''x'').
Suppose that these functions are particularly well behaved: they are all [[continuous function|continuous]], and any two of them are equal on at most ''s'' values. With these assumptions, the real line can be partitioned into finitely many [[interval (mathematics)|intervals]] within which one function has values smaller than all of the other functions. The sequence of these intervals, labeled by the minimizing function within each interval, forms a Davenport–Schinzel sequence of order ''s''. Thus, any upper bound on the complexity of a Davenport–Schinzel sequence of this order also bounds the number of intervals in this representation of the lower envelope.

In the original application of Davenport and Schinzel, the functions under consideration were a set of different solutions to the same homogeneous [[linear differential equation]] of order ''s''. Any two distinct solutions can have at most ''s'' values in common, so the lower envelope of a set of ''n'' distinct solutions forms a ''DS''(''n'',''s'')-sequence.

The same concept of a lower envelope can also be applied to functions that are only [[piecewise]] continuous or that are defined only over intervals of the real line; however, in this case, the points of discontinuity of the functions and the endpoints of the interval within which each function is defined add to the order of the sequence. For instance, a non-vertical line segment in the plane can be interpreted as the [[graph of a function]] mapping an interval of ''x'' values to their corresponding ''y'' values, and the lower envelope of a collection of line segments forms a Davenport–Schinzel sequence of order three because any two line segments can form an alternating subsequence with length at most four.

== See also ==
* [[Squarefree word]]

==Notes==
{{reflist|2}}

==References==
*{{citation
 | last1 = Agarwal | first1 = P. K. | author1-link = Pankaj K. Agarwal
 | last2 = Sharir | first2 = Micha | authorlink2 = Micha Sharir
 | last3 = Shor | first3 = P. | authorlink3 = Peter Shor
 | title = Sharp upper and lower bounds on the length of general Davenport–Schinzel sequences
 | journal = Journal of Combinatorial Theory, Series A
 | volume = 52 | issue = 2 | year = 1989 | pages = 228–274
 | mr = 1022320 | doi = 10.1016/0097-3165(89)90032-0}}.
*{{citation
 | last = Atallah | first = Mikhail J.
 | authorlink = Mikhail Atallah
 | title = Some dynamic computational geometry problems
 | journal = Computers and Mathematics with Applications
 | mr = 0822083 | doi = 10.1016/0898-1221(85)90105-1
 | volume = 11 | pages = 1171–1181 | year = 1985}}.
*{{citation
 | last1 = Davenport | first1 = H. | authorlink1 = Harold Davenport
 | last2 = Schinzel | first2 = Andrzej | authorlink2 = Andrzej Schinzel
 | title = A combinatorial problem connected with differential equations
 | journal = American Journal of Mathematics
 | volume = 87 | year = 1965 | pages = 684–694
 | mr = 0190010 | doi = 10.2307/2373068
 | jstor = 2373068
 | issue = 3
 | publisher = The Johns Hopkins University Press}}.
*{{citation
 | last1 = Hart | first1 = S.
 | last2 = Sharir | first2 = Micha | authorlink2 = Micha Sharir
 | title = Nonlinearity of Davenport–Schinzel sequences and of generalized path compression schemes
 | journal = Combinatorica
 | volume = 6 | issue = 2 | year = 1986 | pages = 151–177
 | mr = 0875839 | doi = 10.1007/BF02579170}}.
*{{citation
 | last = Klazar | first = M.
 | contribution = On the maximum lengths of Davenport–Schinzel sequences
 | pages = 169–178
 | publisher = American Mathematical Society
 | series = DIMACS Series in Discrete Mathematics and Theoretical Computer Science
 | title = Contemporary Trends in Discrete Mathematics
 | volume = 49
 | year = 1999}}.
*{{citation
 | authorlink = Péter Komjáth
 | last = Komjáth | first = Péter
 | title = A simplified construction of nonlinear Davenport–Schinzel sequences
 | journal = Journal of Combinatorial Theory, Series A
 | volume = 49 | year = 1988 | issue = 2 | pages = 262–267
 | mr = 0964387 | doi = 10.1016/0097-3165(88)90055-6}}.
*{{citation
 | last1 = Mullin | first1 = R. C.
 | last2 = Stanton | first2 = R. G.
 | title = A map-theoretic approach to Davenport-Schinzel sequences.
 | journal = Pacific Journal of Mathematics
 | volume = 40 | year = 1972 | pages = 167–172
 | url = http://projecteuclid.org/getRecord?id=euclid.pjm/1102968831
 | mr = 0302601 | doi=10.2140/pjm.1972.40.167}}.
*{{citation
 | last = Nivasch | first = Gabriel
 | contribution = Improved bounds and new techniques for Davenport–Schinzel sequences and their generalizations
 | arxiv = 0807.0484 | pages = 1–10
 | title = Proc. 20th ACM-SIAM Symp. Discrete Algorithms
 | url = http://www.siam.org/proceedings/soda/2009/SODA09_001_nivaschg.pdf
 | year = 2009| bibcode = 2008arXiv0807.0484N}}.
*{{citation
 | last1 = Roselle | first1 = D. P. | author1-link = David Roselle
 | last2 = Stanton | first2 = R. G.
 | title = Some properties of Davenport-Schinzel sequences
 | journal = Acta Arithmetica
 | volume = 17 | year = 1970/71 | pages = 355–362
 | mr = 0284414 }}.
*{{citation
 | last1 = Sharir | first1 = Micha | authorlink1 = Micha Sharir
 | last2 = Agarwal | first2 = Pankaj K.
 | title = Davenport–Schinzel Sequences and Their Geometric Applications
 | publisher = Cambridge University Press
 | year = 1995
 | isbn = 0-521-47025-0}}.
*{{citation
 | last1 = Stanton | first1 = R. G.
 | last2 = Dirksen | first2 = P. H.
 | title = Davenport-Schinzel sequences.
 | journal = Ars Combinatoria
 | volume = 1 | year = 1976 | issue = 1 | pages = 43–51
 | mr = 0409347 }}.
*{{citation
 | last1 = Stanton | first1 = R. G.
 | last2 = Roselle | first2 = D. P. | author2-link = David Roselle
 | contribution = A result on Davenport-Schinzel sequences
 | title = Combinatorial theory and its applications, III (Proc. Colloq., Balatonfüred, 1969)
 | pages = 1023–1027
 | publisher = North-Holland | location = Amsterdam | year = 1970
 | mr = 0304189 }}.
*{{citation
 | last1 = Wiernik | first1 = Ady
 | last2 = Sharir | first2 = Micha | authorlink2 = Micha Sharir
 | title = Planar realizations of nonlinear Davenport–Schinzel sequences by segments
 | journal = Discrete &amp; Computational Geometry
 | volume = 3 | issue = 1 | year = 1988 | pages = 15–47
 | mr = 0918177 | doi = 10.1007/BF02187894}}.
*{{citation
| last = Pettie | first = Seth
| title = Sharp bounds on Davenport-Schinzel sequences of every order
| journal = J. ACM
| volume = 62 | issue = 5 | year = 2015
| doi = 10.1145/2794075}}.
*{{citation
| last1 = Wellman | first1 = Julian
| last2 = Pettie | first2 = Seth
| title = Lower bounds on Davenport-Schinzel sequences via rectangular Zarankiewicz matrices
| date = 2016
| arxiv = 1610.09774| bibcode = 2016arXiv161009774W}}.

== External links ==
* [http://mathworld.wolfram.com/Davenport-SchinzelSequence.html Davenport-Schinzel Sequence], from [[MathWorld]].
* [http://planning.cs.uiuc.edu/node304.html  Davenport-Schinzel Sequences], a section in the book ''Motion Planning'', by Steven M. LaValle.

{{DEFAULTSORT:Davenport-Schinzel sequence}}
[[Category:Sequences and series]]
[[Category:Combinatorics on words]]
[[Category:Discrete geometry]]</text>
      <sha1>m10o11vpighaewcrdd9cje3gm3mh43d</sha1>
    </revision>
  </page>
  <page>
    <title>Demonic non-determinism</title>
    <ns>0</ns>
    <id>39975535</id>
    <revision>
      <id>764734544</id>
      <parentid>712710083</parentid>
      <timestamp>2017-02-10T17:05:32Z</timestamp>
      <contributor>
        <ip>168.96.15.8</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="458">{{orphan|date=July 2013}}
{{see also|Angelic non-determinism}}

A term coined by [[Tony Hoare|C.A.R Hoare]]{{Cn|date=August 2014}}, which describes the execution of a [[non-deterministic program]] where all choices that are made favour non-termination.{{Cn|date=August 2014}}


==References==
* R.J.R. Back and J. von Wright. Refinement Calculus: A Systematic Introduction. Springer, 1998.

[[Category:Theoretical computer science]]

{{comp-sci-theory-stub}}</text>
      <sha1>e8lnjyr7sewexdyi1ddn7x8yxzo74ki</sha1>
    </revision>
  </page>
  <page>
    <title>Denormal number</title>
    <ns>0</ns>
    <id>141163</id>
    <revision>
      <id>849381101</id>
      <parentid>849261310</parentid>
      <timestamp>2018-07-08T16:04:18Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12123">[[File:Denormalized_numbers_on_a_line.svg|thumb|400px|right|An unaugmented floating point system would contain only normalized numbers (indicated in red). Allowing denormalized numbers (blue) extends the system's range.]]

In [[computer science]], '''denormal numbers''' or '''denormalized numbers''' (now often called '''subnormal numbers''') fill the [[arithmetic underflow|underflow]] gap around [[0 (number)|zero]] in [[floating-point]] arithmetic. Any non-zero number with [[magnitude (mathematics)#Numbers|magnitude]] smaller than the smallest [[normal number (computing)|normal number]] is 'subnormal'.

In a normal floating-point value, there are no leading zeros in the [[significand]]; instead leading zeros are moved to the exponent. So 0.0123 would be written as 1.23 × 10&lt;sup&gt;−2&lt;/sup&gt;. Denormal numbers are numbers where this representation would result in an exponent that is below the minimum exponent (the exponent usually having a limited range).
Such numbers are represented using leading zeros in the significand.

The [[significand]] (or mantissa) of an [[IEEE floating point]] number is the part of a floating-point number that represents the significant digits. For a positive normalised number it can be represented as ''m''&lt;sub&gt;0&lt;/sub&gt;.''m''&lt;sub&gt;1&lt;/sub&gt;''m''&lt;sub&gt;2&lt;/sub&gt;''m''&lt;sub&gt;3&lt;/sub&gt;...''m''&lt;sub&gt;''p''−2&lt;/sub&gt;''m''&lt;sub&gt;''p''−1&lt;/sub&gt; (where ''m'' represents a significant digit and ''p'' is the precision, and ''m''&lt;sub&gt;0&lt;/sub&gt; is non-zero).  Notice that for a binary [[radix]], the leading binary digit is always 1. In a '''denormal number''', since the exponent is the least that it can be, zero is the leading significand digit (0.''m''&lt;sub&gt;1&lt;/sub&gt;''m''&lt;sub&gt;2&lt;/sub&gt;''m''&lt;sub&gt;3&lt;/sub&gt;...''m''&lt;sub&gt;''p''−2&lt;/sub&gt;''m''&lt;sub&gt;''p''−1&lt;/sub&gt;), allowing the representation of numbers closer to zero than the smallest normal number. A floating point number may be recognized as denormal whenever its exponent is the least value possible.

By filling the underflow gap like this, significant digits are lost, but not as abruptly as when using the ''flush to zero on underflow'' approach (discarding all significant digits when  underflow is reached). Hence the production of a denormal number is sometimes called '''gradual underflow''' because it allows a calculation to lose precision slowly when the result is small.

In [[IEEE 754-2008]], denormal numbers are renamed ''subnormal numbers'', and are supported in both binary and decimal formats. In binary interchange formats, subnormal numbers are encoded with a [[Exponent bias|biased exponent]] of 0, but are interpreted with the value of the smallest allowed exponent, which is one greater (i.e., as if it were encoded as a 1).  In decimal interchange formats they require no special encoding because the format supports unnormalized numbers directly.

Mathematically speaking, the normalized floating point numbers of a given [[sign (mathematics)|sign]] are roughly [[logarithm]]ically spaced, and as such any finite-sized normal float [[asymptotic|cannot include zero]]. The denormal floats are a linearly-spaced set of values which span the gap between the negative and positive normal floats.

{{floating-point}}

== Background ==
Denormal numbers provide the guarantee that addition and subtraction of floating-point numbers never underflows; two nearby floating-point numbers always have a representable non-zero difference. Without gradual underflow, the subtraction ''a''−''b'' can underflow and produce zero even though the values are not equal.  This can, in turn, lead to [[division by zero]] errors that cannot occur when gradual underflow is used.&lt;ref&gt;{{cite web|url=http://grouper.ieee.org/groups/754/meeting-minutes/02-09-19.html#underflow|title=IEEE 754R meeting minutes, 2002|author=William Kahan|accessdate=29 Dec 2013}}&lt;/ref&gt;

Denormal numbers were implemented in the [[Intel 8087]] while the IEEE 754 standard was being written.  They were by far the most controversial feature in the [[K-C-S format]] proposal that was eventually adopted,&lt;ref&gt;{{cite web|url=http://www.eecs.berkeley.edu/~wkahan/ieee754status/754story.html|title=An Interview with the Old Man of Floating-Point|publisher=University of California, Berkeley}}&lt;/ref&gt; but this implementation demonstrated that denormals could be supported in a practical implementation.  Some implementations of [[floating point unit]]s do not directly support denormal numbers in hardware, but rather trap to some kind of software support.  While this may be transparent to the user, it can result in calculations which produce or consume denormal numbers being much slower than similar calculations on normal numbers.

== Performance issues ==
Some systems handle denormal values in hardware, in the same way as normal values. Others leave the handling of denormal values to system software, only handling normal values and zero in hardware. Handling denormal values in software always leads to a significant decrease in performance. When denormal values are entirely computed in hardware, implementation techniques exist to allow their processing at speeds comparable to normal numbers;&lt;ref&gt;{{cite journal|last1=Schwarz|first1=E.M.|last2=Schmookler|first2=M.|last3=Son Dao Trong|title=FPU Implementations with Denormalized Numbers|journal=IEEE Transactions on Computers|date=July 2005|volume=54|issue=7|pages=825–836|doi=10.1109/TC.2005.118|url=http://www.acsel-lab.com/arithmetic/arith16/papers/ARITH16_Schwarz.pdf}}&lt;/ref&gt; however, the speed of computation is significantly reduced on many modern processors; in extreme cases, [[Instruction (computer science)|instructions]] involving denormal operands may run as much as 100 times slower.&lt;ref&gt;{{cite web|url=http://charm.cs.uiuc.edu/papers/SubnormalOSIHPA06.pdf|author2=Kale, Laxmikant|first1=Isaac|last1=Dooley|date=2006-09-12|accessdate=2010-11-30|title=Quantifying the Interference Caused by Subnormal Floating-Point Values}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.agner.org/optimize/instruction_tables.pdf|first=Agner|last=Fog|accessdate=2011-01-25|title=Instruction tables: Lists of instruction latencies, throughputs and microoperation breakdowns for Intel, AMD and VIA CPUs}}&lt;/ref&gt;

This speed difference can be a security risk.  Researchers showed that it provides a [[Side-channel attack|timing side channel]] that allows a malicious web site to extract page content from another site inside a web browser.&lt;ref&gt;{{cite web|url=https://cseweb.ucsd.edu/~dkohlbre/papers/subnormal.pdf|title=On Subnormal Floating Point and Abnormal Timing|first=Marc|last=Andrysco|first2=David|last2=Kohlbrenner|first3=Keaton|last3=Mowery|first4=Ranjit|last4=Jhala|first5=Sorin|last5=Lerner|first6=Hovav|last6=Shacham|accessdate=2015-10-05}}&lt;/ref&gt;

Some applications need to contain code to avoid denormal numbers, either to maintain accuracy, or in order to avoid the performance penalty in some processors. For instance, in audio processing applications, denormal values usually represent a signal so quiet that it is out of the human hearing range. Because of this, a common measure to avoid denormals on processors where there would be a performance penalty is to cut the signal to zero once it reaches denormal levels or mix in an extremely quiet noise signal.&lt;ref&gt;{{cite web|url=http://phonophunk.com/articles/pentium4-denormalization.php |title=Pentium 4 denormalization: CPU spikes in audio applications |last=Serris |first=John |date=2002-04-16 |accessdate=2015-04-29 |deadurl=yes |archiveurl=https://web.archive.org/web/20120225091101/http://phonophunk.com/articles/pentium4-denormalization.php |archivedate=February 25, 2012 }}&lt;/ref&gt; Other methods of preventing denormal numbers include adding a DC offset, quantizing numbers, adding a nyquist signal, etc.&lt;ref&gt;{{cite web|url=http://ldesoras.free.fr/doc/articles/denormal-en.pdf|last=de Soras| first=Laurent| date=2005-04-19| title=Denormal numbers in floating point signal processing applications}}&lt;/ref&gt; Since the [[Streaming SIMD Extensions|SSE2]] processor extension, [[Intel]] has provided such a functionality in CPU hardware, which rounds denormalized numbers to zero.&lt;ref&gt;{{cite web|url=http://software.intel.com/en-us/articles/x87-and-sse-floating-point-assists-in-ia-32-flush-to-zero-ftz-and-denormals-are-zero-daz/|last=Casey|first=Shawn|date=2008-10-16|accessdate=2010-09-03|title=x87 and SSE Floating Point Assists in IA-32: Flush-To-Zero (FTZ) and Denormals-Are-Zero (DAZ)}}&lt;/ref&gt;

== Disabling denormal floats at the code level ==

Intel's C and Fortran compilers enable the denormals-are-zero (DAZ) and flush-to-zero (FTZ) flags for [[Streaming_SIMD_Extensions|SSE]] by default for optimization levels higher than -O0.&lt;ref&gt;{{cite web|url=http://software.intel.com/sites/products/documentation/hpc/composerxe/en-us/2011Update/fortran/win/fpops/common/fpops_reduce_denorm.htm|title=Intel® MPI Library - Documentation|publisher=Intel}}&lt;/ref&gt; The effect of DAZ is to treat denormal input arguments to floating point operations as zero, and the effect of FTZ is to return zero instead of a denormal float for operations which would result in a denormal float, even if the input arguments are not themselves denormal. [[clang]] and [[GNU Compiler Collection|gcc]] have varying default states depending on platform and optimization level. A non-[[C99]]-compliant method of enabling the DAZ and FTZ flags on targets supporting SSE is given below, but is not widely supported. It is known to work on [[Mac OS X]] since at least 2006.&lt;ref&gt;{{cite web|url=http://lists.apple.com/archives/perfoptimization-dev/2006/May/msg00013.html|title=Re: Macbook pro performance issue|publisher=Apple Inc.}}&lt;/ref&gt;

&lt;source lang="c"&gt;
#include &lt;fenv.h&gt;
fesetenv(FE_DFL_DISABLE_SSE_DENORMS_ENV);
&lt;/source&gt;

For other SSE instruction-set platforms where the C library has not yet implemented the above flag, the following may work:&lt;ref&gt;{{cite web|url=http://lists.apple.com/archives/perfoptimization-dev/2007/Jun/msg00025.html|title=Re: Changing floating point state (Was: double vs float performance)|publisher=Apple Inc.}}&lt;/ref&gt;

&lt;source lang="c"&gt;
#include &lt;xmmintrin.h&gt;
_mm_setcsr( _mm_getcsr() | 0x8040 );
&lt;/source&gt;

The _MM_SET_DENORMALS_ZERO_MODE macro wraps a better interface for the code above. It allows for switching the mode on or off, while preserving any other configuration in the CSR.
&lt;source lang="c"&gt;
_MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);
&lt;/source&gt;

Most compilers will already provide the previous macro by default, otherwise the following code snippet can be used.
&lt;source lang="c"&gt;
#define _MM_DENORMALS_ZERO_MASK   0x0040
#define _MM_DENORMALS_ZERO_ON     0x0040
#define _MM_DENORMALS_ZERO_OFF    0x0000

#define _MM_SET_DENORMALS_ZERO_MODE(mode)                                   \
            _mm_setcsr((_mm_getcsr() &amp; ~_MM_DENORMALS_ZERO_MASK) | (mode))
#define _MM_GET_DENORMALS_ZERO_MODE()                                       \
            (_mm_getcsr() &amp; _MM_DENORMALS_ZERO_MASK)
&lt;/source&gt;
The default denormal behavior is [[Application_binary_interface|ABI]] and therefore well behaved software should save and restore the denormal mode before returning to the caller or calling out to unsuspecting library/OS code.

== See also ==
*[[Logarithmic number system]]

== References ==
{{reflist|30em}}

== Further reading ==
*{{cite conference
 |     author = Eric Schwarz, Martin Schmookler and Son Dao Trong
 |      title = Hardware Implementations of Denormalized Numbers
 |date=June 2003
 | conference = 16th IEEE Symposium on Computer Arithmetic
 | conferenceurl = http://www.dec.usc.es/arith16/
 |  booktitle = Proceedings 16th IEEE Symposium on Computer Arithmetic (Arith16)
 |  publisher = [[IEEE Computer Society]]
 |      pages = 104–111
 |        url = http://www.ece.ucdavis.edu/acsel/arithmetic/arith16/papers/ARITH16_Schwarz.pdf
 | accessdate = 
 |       isbn = 0-7695-1894-X
 }}

See also various papers on [[William Kahan]]'s web site [http://www.cs.berkeley.edu/~wkahan/] for examples of where denormal numbers help improve the results of calculations.

{{DEFAULTSORT:Denormal Number}}
[[Category:Computer arithmetic]]</text>
      <sha1>d57j5vbnbnlpmbnm4nbq0ffl02t89u3</sha1>
    </revision>
  </page>
  <page>
    <title>Dynkin system</title>
    <ns>0</ns>
    <id>2549191</id>
    <revision>
      <id>871065713</id>
      <parentid>829730242</parentid>
      <timestamp>2018-11-28T18:28:45Z</timestamp>
      <contributor>
        <username>Paul August</username>
        <id>87355</id>
      </contributor>
      <comment>Reviewed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4942">A '''Dynkin system''', named after [[Eugene Dynkin]], is a [[class (set theory)|collection]] of [[subset]]s of another universal [[Set (mathematics)|set]] &lt;math&gt;\Omega&lt;/math&gt; satisfying a set of [[axiom]]s weaker than those of [[sigma algebra|σ-algebra]].    Dynkin systems are sometimes referred to as '''λ-systems''' (Dynkin himself used this term) or '''d-system'''.&lt;ref&gt;{{cite book |title=Infinite Dimensional Analysis: a Hitchhiker's Guide |edition=Third |first=Charalambos |last=Aliprantis |first2=Kim C. |last2=Border |publisher=Springer |year=2006 |url=https://books.google.com/books?id=4vyXtR3vUhoC&amp;pg=PA135 |accessdate=August 23, 2010 }}&lt;/ref&gt; These set families have applications in [[measure theory]] and [[probability]].

A major application of λ-systems is the π-λ theorem, see below.

== Definitions ==
Let Ω be a [[nonempty]] set, and let &lt;math&gt;D&lt;/math&gt; be a collection of subsets of Ω (i.e., &lt;math&gt;D&lt;/math&gt; is a subset of the [[power set]] of Ω). Then &lt;math&gt;D&lt;/math&gt; is a Dynkin system if
# Ω ∈ &lt;math&gt;D&lt;/math&gt;,
# if ''A'', ''B'' ∈ &lt;math&gt;D&lt;/math&gt; and ''A'' ⊆ ''B'', then ''B'' \ ''A'' ∈ &lt;math&gt;D&lt;/math&gt;,
# if ''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ''A''&lt;sub&gt;3&lt;/sub&gt;, ... is a sequence of subsets in &lt;math&gt;D&lt;/math&gt; and ''A''&lt;sub&gt;''n''&lt;/sub&gt; ⊆ ''A''&lt;sub&gt;''n''+1&lt;/sub&gt; for all ''n'' ≥ 1, then &lt;math&gt;\bigcup_{n=1}^\infty A_n\in D&lt;/math&gt;.

Equivalently, &lt;math&gt;D&lt;/math&gt; is a Dynkin system if
# Ω ∈ &lt;math&gt;D&lt;/math&gt;,
# if ''A'' ∈ ''D'', then ''A''&lt;sup&gt;c&lt;/sup&gt; ∈ ''D'',
# if ''A''&lt;sub&gt;1&lt;/sub&gt;, ''A''&lt;sub&gt;2&lt;/sub&gt;, ''A''&lt;sub&gt;3&lt;/sub&gt;, ... is a sequence of subsets in &lt;math&gt;D&lt;/math&gt; such that ''A''&lt;sub&gt;''i''&lt;/sub&gt; ∩ ''A''&lt;sub&gt;''j''&lt;/sub&gt; = Ø for all ''i'' ≠ ''j'', then &lt;math&gt;\bigcup_{n=1}^\infty A_n\in D&lt;/math&gt;.

The second definition is generally preferred as it usually is easier to check.

An important fact is that a Dynkin system which is also a [[pi system|π-system]] (i.e., closed under finite intersection) is a [[sigma algebra|σ-algebra]]. This can be verified by noting that condition 3 and closure under finite intersection implies closure under countable unions.

Given any collection &lt;math&gt;\mathcal{J}&lt;/math&gt; of subsets of &lt;math&gt;\Omega&lt;/math&gt;, there exists a unique Dynkin system denoted &lt;math&gt;D\{\mathcal J\}&lt;/math&gt; which is minimal with respect to containing &lt;math&gt;\mathcal J&lt;/math&gt;. That is, if &lt;math&gt;\tilde D&lt;/math&gt; is any Dynkin system containing &lt;math&gt;\mathcal J&lt;/math&gt;, then &lt;math&gt;D\{\mathcal J\}\subseteq\tilde D&lt;/math&gt;. &lt;math&gt;D\{\mathcal J\}&lt;/math&gt; is called the Dynkin system generated by &lt;math&gt;\mathcal{J}&lt;/math&gt;. Note &lt;math&gt;D\{\emptyset\}=\{\emptyset,\Omega\}&lt;/math&gt;. For another example, let &lt;math&gt;\Omega=\{1,2,3,4\}&lt;/math&gt; and &lt;math&gt;\mathcal J=\{1\}&lt;/math&gt;; then &lt;math&gt;D\{\mathcal J\}=\{\emptyset,\{1\},\{2,3,4\},\Omega\}&lt;/math&gt;.

== Dynkin's π-λ theorem ==
If &lt;math&gt;P&lt;/math&gt; is a [[pi-system|π-system]] and &lt;math&gt;D&lt;/math&gt; is a Dynkin system with &lt;math&gt;P\subseteq D&lt;/math&gt;, then &lt;math&gt;\sigma\{P\}\subseteq D&lt;/math&gt;. In other words, the σ-algebra generated by &lt;math&gt;P&lt;/math&gt; is contained in &lt;math&gt;D&lt;/math&gt;.

One application of Dynkin's π-λ theorem is the uniqueness of a measure that evaluates the length of an interval (known as the [[Lebesgue measure]]):

Let (Ω, ''B'', ''λ'') be the [[unit interval]] [0,1] with the Lebesgue measure on [[Borel sets]].  Let μ be another [[Measure (mathematics)|measure]] on Ω satisfying μ[(''a'',''b'')] = ''b''&amp;nbsp;−&amp;nbsp;''a'', and let ''D'' be the family of sets ''S'' such that μ[S] = λ[S].  Let ''I'' = { (''a'',''b''),[''a'',''b''),(''a'',''b''],[''a'',''b''] : 0 &lt; ''a'' ≤ ''b'' &lt; 1 }, and observe that ''I'' is closed under finite intersections, that ''I'' ⊂ ''D'', and that ''B'' is the σ-algebra generated by ''I''.  It may be shown that ''D'' satisfies the above conditions for a Dynkin-system.  From Dynkin's π-λ Theorem it follows that ''D'' in fact includes all of ''B'', which is equivalent to showing that the Lebesgue measure is unique on ''B''.

Additional applications are in the article on [[pi system|π-systems]].

== Notes ==
{{Reflist}}

== References ==
* {{cite book
  | last       = Gut
  | first      = Allan
  | title      = Probability: A Graduate Course
  | publisher  = Springer
  | year       = 2005
  | location   = New York
  | doi        = 10.1007/b138932
  | isbn       = 0-387-22833-0
}}
* {{cite book
  | last       = Billingsley
  | first      = Patrick
  | title      = Probability and Measure
  | publisher  = John Wiley &amp; Sons, Inc.
  | year       = 1995
  | location   = New York
  | isbn       = 0-471-00710-2
}}
* {{cite book | first=David |last=Williams | year=2007 | title=Probability with Martingales | publisher=Cambridge University Press | isbn=0-521-40605-6 | page=193 |url=https://books.google.com/books?id=e9saZ0YSi-AC&amp;pg=PA193 }}

{{PlanetMath attribution|id=2024|title=Dynkin system}}
[[Category:Set families]]
[[Category:Probability theory]]
[[Category:Lemmas]]</text>
      <sha1>arwt3dsi3k8v3z5nktoe0irc9s2x8o1</sha1>
    </revision>
  </page>
  <page>
    <title>EURO Gold Medal</title>
    <ns>0</ns>
    <id>56912030</id>
    <revision>
      <id>853867249</id>
      <parentid>851117838</parentid>
      <timestamp>2018-08-07T13:16:08Z</timestamp>
      <contributor>
        <username>PavKls</username>
        <id>31376232</id>
      </contributor>
      <comment>/* List of recipients */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2958">{{Infobox award
| image       =
| image_size  = 140
| name        = EURO Gold Medal
| description = outstanding contribution to the development of [[operations research]]
| country     = 
| year        = 1985
| website     = [https://www.euro-online.org/web/pages/606/guidelines]
}}

The '''EURO Gold medal''' of the [[Association of European Operational Research Societies]] (EURO) is the most important European scientific prize for [[operations research]].&lt;ref name="EURO Online"&gt;{{cite web|title=EURO Gold Medal|url=https://www.euro-online.org/web/pages/212/gold-medal-egm|publisher=EURO - The Association of European Operational ResearchSocieties - Gold Medal (EGM)|accessdate=23 March 2018|language=en}}  [[File:CC-BY-SA icon.svg|50px]] Material was copied from this source, which is available under a [https://creativecommons.org/licenses/by-sa/3.0/ Creative Commons Attribution-ShareAlike 3.0 Unported] license and the [https://www.gnu.org/copyleft/fdl.html GNU Free Documentation License] (unversioned, with no invariant sections, front-cover texts, or back-cover texts)&lt;/ref&gt;

The Prize is awarded when a EURO Conference is held (usually twice every three years), to an individual (or sometimes a group) for an outstanding contribution 
to the field of [[operations research]]. The Prize is intended to reflect contributions that have stood the test of time, and hence it is awarded for a body of work, rather than a single piece.&lt;ref name="EURO Online"/&gt;

The award is a medal in gold, a diploma, and a citation. The Prize has been awarded since 1985. 

== List of recipients ==
* 2018 Silvano Martello
* 2016 [[Yurii Nesterov]] and Maurice Queyranne
* 2015 [[Alexander Schrijver]]&lt;ref&gt;[https://ercim-news.ercim.eu/en103/ib/lex-schrijver-receives-euro-gold-medal-2015], [[:fr:European Research Consortium for Informatics and Mathematics|ERCIM]] News&lt;/ref&gt;
* 2013 [[Panos M. Pardalos]]
* 2012 Boris Polyak
* 2011 Rolf Möhring
* 2009 [[Jacques Benders]] and [[Frank Kelly (professor)|Frank Kelly]]
* 2007 Aharon Ben-Tal
* 2006 [[Luk Van Wassenhove]]
* 2004 [[Martin Grötschel]]
* 2003 [[András Prékopa]]
* 2001 [[Egon Balas]]
* 1998 Paolo Toth
* 1997 [[Rainer Burkard]] and [[Jan Karel Lenstra]]
* 1995 Dominique de Werra
* 1994 Jean-Pierre Brans and [[Laurence Wolsey]]
* 1992 [[Bernard Roy]]
* 1991 [[Jacek Błażewicz]], [[:pl:Roman Słowiński|Roman Słowiński]], and [[Jan Węglarz]]
* 1989 [[Claude Berge]]
* 1988 [[Martin Beale]] (posthumously)
* 1986 Pierre Hansen and [[Alexander Rinnooy Kan]]
* 1985 [[:de:Hans-Jürgen Zimmermann (Wirtschaftswissenschaftler)|Hans-Jürgen Zimmermann]]

== See also ==
* [[Frederick W. Lanchester Prize|Lanchester Prize]]
* [[John von Neumann Theory Prize]]
* [[List of science and technology awards]]

== References ==
{{reflist}}

== External links ==
* {{Official website|https://www.euro-online.org/web/pages/606/guidelines}}

[[Category:Awards established in 1985]]
[[Category:Mathematics awards]]</text>
      <sha1>cz7542u1ww7u9pn1nitlwsqq3jdcigj</sha1>
    </revision>
  </page>
  <page>
    <title>Effective dimension</title>
    <ns>0</ns>
    <id>10978612</id>
    <revision>
      <id>859390225</id>
      <parentid>842503953</parentid>
      <timestamp>2018-09-13T19:09:41Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Kolmogorov complexity definition */[[User:JCW-CleanerBot#Logic|task]], replaced: Journal of Computer and System Science → Journal of Computer and System Sciences</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12238">{{One source|text=The article relies on sources from one research group.|date=November 2013}}

In [[mathematics]], '''effective dimension''' is a modification of [[Hausdorff dimension]] and other [[fractal dimension]]s which places it in a [[computability theory]] setting. There are several horse Wang's  variations (various notions of effective dimension) of which the most common is '''effective Hausdorff dimension'''. [[Dimension]], in mathematics, is a particular way of describing the size of an object (contrasting with measure and other, different, notions of size). Hausdorff dimension generalizes the well-known integer dimensions assigned to points, lines, planes, etc. by allowing one to distinguish between objects of intermediate size between these integer-dimensional objects. For example, [[List of fractals by Hausdorff dimension|fractal]] subsets of the plane may have intermediate dimension between 1 and 2, as they are "larger" than lines or curves, and yet "smaller" than filled circles or rectangles. Effective dimension modifies Hausdorff dimension by requiring that objects with small effective dimension be not only small but also locatable (or partially locatable) in a computable sense. As such, objects with large Hausdorff dimension also have large effective dimension, and objects with small effective dimension have small Hausdorff dimension, but an object can have small Hausdorff but large effective dimension. An example is an [[algorithmically random sequence|algorithmically random]] point on a line, which has Hausdorff dimension 0 (since it is a point) but effective dimension 1 (because, roughly speaking, it can't be effectively localized any better than a small interval, which has Hausdorff dimension 1).

== Rigorous definitions ==
This article will define effective dimension for subsets of [[Cantor space]] '''2'''&lt;sup&gt;ω&lt;/sup&gt;; closely related definitions exist for subsets of [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. We will move freely between considering a set ''X'' of natural numbers, the infinite sequence &lt;math&gt;\chi_X&lt;/math&gt; given by the characteristic function of ''X'', and the real number with binary expansion 0.''X''.

=== Martingales and other gales ===
&lt;!-- This isn't properly part of the article on effective dimension, but is necessary background information. It could, potentially be moved to a different article (perhaps on algorithmic randomness? That whole area of Wikipedia seems somewhat disorganized and I didn't want to redo it.) --&gt;

A ''[[martingale (probability theory)|martingale]]'' on Cantor space '''2'''&lt;sup&gt;ω&lt;/sup&gt; is a function ''d'': '''2'''&lt;sup&gt;ω&lt;/sup&gt; → '''R'''&lt;sup&gt;≥&amp;nbsp;0&lt;/sup&gt; from Cantor space to nonnegative reals which satisfies the fairness condition:

: &lt;math&gt;d(\sigma)=\frac12 (d(\sigma 0)+d(\sigma 1))&lt;/math&gt;

A martingale is thought of as a betting strategy, and the function &lt;math&gt;d(\sigma)&lt;/math&gt; gives the capital of the better after seeing a sequence σ of 0s and 1s. The fairness condition then says that the capital after a sequence σ is the average of the capital after seeing σ0 and σ1; in other words the martingale gives a betting scheme for a bookie with 2:1 odds offered on either of two "equally likely" options, hence the name fair.

(Note that this is subtly different from the probability theory notion of [[martingale (probability theory)|martingale]].&lt;ref name=wccrsm&gt;{{cite journal |author1=John M. Hitchcock |author2=Jack H. Lutz | title = Why computational complexity requires stricter martingales | journal = Theory of Computing Systems | year = 2006}}&lt;/ref&gt; That definition of martingale has a similar fairness condition, which also states that the expected value after some observation is the same as the value before the observation, given the prior history of observations. The difference is that in probability theory, the prior history of observations just refers to the capital history, whereas here the history refers to the exact sequence of 0s and 1s in the string.)

A ''supermartingale'' on Cantor space is a function ''d'' as above which satisfies a modified fairness condition:

: &lt;math&gt;d(\sigma) \geq \frac12 (d(\sigma 0)+d(\sigma 1))&lt;/math&gt;

A supermartingale is a betting strategy where the expected capital after a bet is no more than the capital before a bet, in contrast to a martingale where the two are always equal. This allows more flexibility, and is very similar in the non-effective case, since whenever a supermartingale ''d'' is given, there is a modified function ''d''' which wins at least as much money as ''d'' and which is actually a martingale. However it is useful to allow the additional flexibility once one starts talking about actually giving algorithms to determine the betting strategy, as some algorithms lend themselves more naturally to producing supermartingales than martingales.

An ''s''-''gale'' is a function ''d'' as above of the form

: &lt;math&gt;d(\sigma) = \frac{e(\sigma)}{2^{(1-s)|\sigma|}}&lt;/math&gt;

for ''e'' some martingale.

An ''s''-''supergale'' is a function ''d'' as above of the form

: &lt;math&gt;d(\sigma) = \frac{e(\sigma)}{2^{(1-s)|\sigma|}}&lt;/math&gt;

for ''e'' some supermartingale.

An ''s''-(super)gale is a betting strategy where some amount of capital is lost to inflation at each step.  Note that ''s''-gales and ''s''-supergales are examples of supermartingales, and the 1-gales and 1-supergales are precisely the martingales and supermartingales.

Collectively, these objects are known as "gales".

A gale ''d'' ''succeeds'' on a subset ''X'' of the natural numbers if &lt;math&gt;\limsup_n d(X|n)=\infty&lt;/math&gt; where &lt;math&gt;X|n&lt;/math&gt; denotes the ''n''-digit string consisting of the first ''n'' digits of ''X''.

A gale ''d'' ''succeeds strongly'' on ''X'' if &lt;math&gt;\liminf_n d(X|n)=\infty&lt;/math&gt;.

All of these notions of various gales have no effective content, but one must necessarily restrict oneself to a small class of gales, since some gale can be found which succeeds on any given set. After all, if one knows a sequence of coin flips in advance, it is easy to make money by simply betting on the known outcomes of each flip. A standard way of doing this is to require the gales to be either computable or close to computable:

A gale ''d'' is called ''constructive'', ''c.e.'', or ''lower semi-computable'' if the numbers &lt;math&gt;d(\sigma)&lt;/math&gt; are uniformly left-c.e. reals (i.e. can uniformly be written as the limit of an increasing computable sequence of rationals).

The '''effective Hausdorff dimension''' of a set of natural numbers ''X'' is &lt;math&gt;\inf \{s : \mathrm{some\ c.e.}\ s\mathrm{-gale\ succeeds\ on\ } X \}&lt;/math&gt;.&lt;ref name=dicc&gt;{{cite journal | author = Jack H. Lutz | title = Dimension in complexity classes | journal = SIAM Journal on Computing | year = 2003|doi=10.1137/s0097539701417723 | arxiv = cs/0203016 }}&lt;/ref&gt;

The '''effective packing dimension''' of ''X'' is &lt;math&gt;\inf \{s : \mathrm{some\ c.e.}\ s\mathrm{-gale\ succeeds\ strongly\ on\ } X\}&lt;/math&gt;.&lt;ref name=efsdiaiacc&gt;{{cite journal |author1=Krishna B. Athreya |author2=John M. Hitchcock |author3=Jack H. Lutz |author4=Elvira Mayordomo | title = Effective strong dimension in algorithmic information and computational complexity | journal = SIAM Journal on Computing | year = 2007|doi=10.1137/s0097539703446912 |arxiv=cs/0211025 }}&lt;/ref&gt;

=== Kolmogorov complexity definition ===
[[Kolmogorov complexity]] can be thought of as a lower bound on the algorithmic compressibility of a finite sequence (of characters or binary digits). It assigns to each such sequence ''w'' a natural number ''K(w)'' that, intuitively, measures the minimum length of a computer program (written in some fixed programming language) that takes no input and will output ''w'' when run.

The '''effective Hausdorff dimension''' of a set of natural numbers ''X'' is &lt;math&gt;\liminf_n \frac{K(X|n)}n&lt;/math&gt;.&lt;ref name=caha&gt;{{cite journal | author1 =  Jin-yi Cai| author2 = Juris Hartmanis| title = On Hausdorff and Topological Dimensions of the Kolmogorov Complexity of the Real Line.|doi= 10.1016/S0022-0000(05)80073-X | journal = Journal of Computer and System Sciences | year = 1994}}&lt;/ref&gt;&lt;ref name=koha&gt;{{cite journal | author = Ludwig Staiger | title = Kolmogorov complexity and Hausdorff dimension.|doi= 10.1006/inco.1993.1017 | journal = Information and Computation | year = 1993}}&lt;/ref&gt;&lt;ref name=akccochd&gt;{{cite journal | author = Elvira Mayordomo | title = A Kolmogorov complexity characterization of constructive Hausdorff dimension.|doi=10.1016/S0020-0190(02)00343-5  | journal = Information Processing Letters | year = 2002}}&lt;/ref&gt;&lt;ref name=cdko&gt;{{cite journal | author = Ludwig Staiger | title = Constructive dimension equals Kolmogorov complexity.|doi=  10.1016/j.ipl.2004.09.023| journal = Information Processing Letters | year = 2005}}&lt;/ref&gt;

The '''effective packing dimension''' of a set ''X'' is &lt;math&gt;\limsup_n \frac{K(X|n)}n&lt;/math&gt;.&lt;ref name="efsdiaiacc" /&gt;&lt;ref name="caha"/&gt;&lt;ref name="koha"/&gt;

From this one can see that both the effective Hausdorff dimension and the effective packing dimension of a set are between 0 and 1, with the effective packing dimension always at least as large as the effective Hausdorff dimension.  Every [[algorithmically random sequence|random sequence]] will have effective Hausdorff and packing dimensions equal to 1, although there are also nonrandom sequences with effective Hausdorff and packing dimensions of 1.

== Comparison to classical dimension ==

If ''Z'' is a subset of '''2'''&lt;sup&gt;ω&lt;/sup&gt;, its Hausdorff dimension is &lt;math&gt;\inf \{s : \mathrm{some}\ s\mathrm{-gale\ succeeds\ on\ all\ elements\ of\ } Z \}&lt;/math&gt;.&lt;ref name="dicc" /&gt;

The packing dimension of ''Z'' is &lt;math&gt;\inf \{s : \mathrm{some}\ s\mathrm{-gale\ succeeds\ strongly\ on\ all\ elements\ of\ } Z \}&lt;/math&gt;.&lt;ref name="efsdiaiacc" /&gt;

Thus the effective Hausdorff and packing dimensions of a set &lt;math&gt;X&lt;/math&gt; are simply the classical Hausdorff and packing dimensions of &lt;math&gt;\{X\}&lt;/math&gt; (respectively) when we restrict our attention to c.e. gales.

Define the following:
:&lt;math&gt;H_{\beta} := \{X \in 2^\omega : X\ \mathrm{has\ effective\ Hausdorff\ dimension\ } \beta \}&lt;/math&gt;
:&lt;math&gt;H_{\leq \beta} := \{X \in 2^\omega : X\ \mathrm{has\ effective\ Hausdorff\ dimension\ } \leq \beta \}&lt;/math&gt;
:&lt;math&gt;H_{&lt; \beta} := \{X \in 2^\omega : X\ \mathrm{has\ effective\ Hausdorff\ dimension\ } &lt; \beta \}&lt;/math&gt;
:&lt;math&gt;P_{\beta} := \{X \in 2^\omega : X\ \mathrm{has\ effective\ packing\ dimension\ } \beta \}&lt;/math&gt;
:&lt;math&gt;P_{\leq \beta} := \{X \in 2^\omega : X\ \mathrm{has\ effective\ packing\ dimension\ } \leq \beta \}&lt;/math&gt;
:&lt;math&gt;P_{&lt; \beta} := \{X \in 2^\omega : X\ \mathrm{has\ effective\ packing\ dimension\ } &lt; \beta \}&lt;/math&gt;
A consequence of the above is that these all have Hausdorff dimension &lt;math&gt;\beta&lt;/math&gt;.&lt;ref name=rya&gt;{{cite journal | author = Boris Ryabko | title = Coding of combinatorial sources and Hausdorff dimension.| journal = Soviet Mathematics - Doklady | year = 1994}}&lt;/ref&gt;

&lt;math&gt;H_{\beta}, H_{\leq \beta}&lt;/math&gt; and &lt;math&gt;H_{&lt; \beta}&lt;/math&gt; all have packing dimension 1.

&lt;math&gt;P_{\beta}, P_{\leq \beta}&lt;/math&gt; and &lt;math&gt;P_{&lt; \beta}&lt;/math&gt; all have packing dimension &lt;math&gt;\beta&lt;/math&gt;.

== References ==
{{reflist}}
*{{cite journal
| author = J. H. Lutz
| title = Effective fractal dimensions
| journal = Mathematical Logic Quarterly
| volume = 51
| issue = 1
| pages = 62–72
| year = 2005
| doi = 10.1002/malq.200310127}} [http://www.cs.iastate.edu/~lutz/papers.html]
*{{Cite journal
| author = J. Reimann
| title = Computability and fractal dimension, PhD thesis
| publisher = Ruprecht-Karls Universität Heidelberg
| year = 2004
| postscript = &lt;!--None--&gt;}} [https://web.archive.org/web/20070609152905/http://math.uni-heidelberg.de/logic/reimann/publications.html]
*{{Cite journal
| author = L. Staiger
| title = The Kolmogorov complexity of infinite words
| journal = Theoretical Computer Science
| volume = 383
| issue = 2-3
| pages = 187–199
| year = 2007
| doi = 10.1016/j.tcs.2007.04.013}} [https://www.cs.auckland.ac.nz/research/groups/CDMTCS/researchreports/]

[[Category:Fractals]]
[[Category:Measure theory]]
[[Category:Metric geometry]]
[[Category:Dimension theory]]
[[Category:Computable analysis]]</text>
      <sha1>7ay3vgyincsohc336lvnej2bch38um2</sha1>
    </revision>
  </page>
  <page>
    <title>Eric Katz</title>
    <ns>0</ns>
    <id>54434627</id>
    <revision>
      <id>862334733</id>
      <parentid>862334646</parentid>
      <timestamp>2018-10-03T18:24:22Z</timestamp>
      <contributor>
        <username>Qzd</username>
        <id>26906394</id>
      </contributor>
      <comment>Reverted to revision 854826844 by [[Special:Contributions/Calbaer|Calbaer]] ([[User talk:Calbaer|talk]]). ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2996">{{Infobox scientist
|name              = Eric Katz
|birth_place       = [[Cleveland]], [[Ohio]]
|alma_mater        = {{plainlist}}
* [[Ohio State University]] &lt;small&gt;([[Bachelor of Science|BS]])&lt;/small&gt;
* [[Stanford University]] &lt;small&gt;([[Doctor of Philosophy|PhD]])&lt;/small&gt;
{{endplainlist}}
|thesis_title      = A Formalism for Relative Gromov-Witten Invariants
|thesis_year       = 2004
|doctoral_advisors  = [[Yakov Eliashberg]] &lt;br&gt; [[Ravi Vakil]]
|known_for         = [[Heron–Rota–Welsh conjecture]]
|website = {{URL|https://people.math.osu.edu/katz.60/}}
|field             = Mathematics
|work_institutions = [[Ohio State University]] &lt;br&gt; [[University of Waterloo]] 
}}

'''Eric Katz''' is a mathematician working in combinatorial algebraic geometry and arithmetic geometry. He is currently an [[assistant professor]] in the Department of Mathematics at [[Ohio State University]].&lt;ref&gt;{{Cite web|url=http://people.math.osu.edu/katz.60/|title=Eric Katz|website=people.math.osu.edu/katz.60/|access-date=2017-07-03}}&lt;/ref&gt;

In joint work with [[Karim Adiprasito]] and [[June Huh]], he resolved the Heron–Rota–Welsh conjecture on the log-concavity of the characteristic polynomial of matroids.&lt;ref&gt;{{cite web|url=https://gilkalai.wordpress.com/2015/08/14/updates-and-plans-iii/|title=Combinatorics and more}}&lt;/ref&gt;&lt;ref&gt;{{Cite news|url=https://www.quantamagazine.org/a-path-less-taken-to-the-peak-of-the-math-world-20170627/|title=A Path Less Taken to the Peak of the Math World {{!}} Quanta Magazine|work=Quanta Magazine|access-date=2017-07-01}}&lt;/ref&gt;&lt;ref&gt;{{Cite citation|url=http://www.ams.org/journals/notices/201701/rnoti-p26.pdf|title=Hodge theory of matroids|work=Notices of the AMS|access-date=2017-07-03}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.ams.org/meetings/lectures/2017-CEB-Booklet-Final.pdf|author=Baker, Matt|title=Hodge Theory and Combinatorics|work=2017 AMS Current Events Bulletin|access-date=2017-07-04}}&lt;/ref&gt; With Joseph Rabinoff and David Zureick-Brown, he has given bounds on rational and torsion points on curves.&lt;ref&gt;{{Cite citation|arxiv=1606.09618|title=Diophantine and tropical geometry, and uniformity of rational points on curves|bibcode=2016arXiv160609618K}}&lt;/ref&gt;

== Education ==
Katz went to [[Beachwood High School]].  He obtained his [[Ph.D.]] from [[Stanford University]] in 2004 with a thesis written under the direction of [[Yakov Eliashberg]] and [[Ravi Vakil]].&lt;ref&gt;{{MathGenealogy|id=85162}}&lt;/ref&gt;

== References ==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Katz, Eric}}
[[Category:Year of birth missing (living people)]]
[[Category:1970s births]]
[[Category:Living people]]
[[Category:Ohio State University faculty]]
[[Category:University of Waterloo faculty]]
[[Category:Stanford University alumni]]
[[Category:People from Cleveland]]
[[Category:Mathematicians from Ohio]]
[[Category:Algebraic geometers]]
[[Category:Combinatorialists]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]</text>
      <sha1>r8sgcz975p7by228al43sfyo1p8uj68</sha1>
    </revision>
  </page>
  <page>
    <title>Financial risk management</title>
    <ns>0</ns>
    <id>1526304</id>
    <revision>
      <id>864181303</id>
      <parentid>864181158</parentid>
      <timestamp>2018-10-15T16:40:23Z</timestamp>
      <contributor>
        <ip>2405:204:442B:207:85DB:2414:7FF3:5EEC</ip>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14186">'''Financial risk management''' is the practice of economic value in a [[business|firm]] by using [[financial instruments]] to manage exposure to [[risk]]: [[operational risk]], [[credit risk]] and [[market risk]], [[foreign exchange risk]], [[shape risk]], [[volatility risk]], [[liquidity risk]], [[inflation risk]], [[business risk]], [[legal risk]], [[reputational risk]], sector risk etc. Similar to general [[risk management]], financial risk management requires identifying its sources, measuring it, and plans to address them.&lt;ref name="Christoffersen2011"&gt;{{cite book|author=Peter F. Christoffersen|title=Elements of Financial Risk Management|url=https://books.google.com/books?id=YkcMBGYbRasC|date=22 November 2011|publisher=Academic Press|isbn=978-0-12-374448-7}}&lt;/ref&gt;

Financial risk management can be qualitative and quantitative. As a specialization of [[risk]] management, financial risk management focuses on when and how to [[Hedge (finance)|hedge]] using financial instruments to manage costly exposures to risk.&lt;ref name="Malz2011"&gt;{{cite book|author=Allan M. Malz|title=Financial Risk Management: Models, History, and Institutions|url=https://books.google.com/books?id=rFX2f6AxH1QC|date=13 September 2011|publisher=John Wiley &amp; Sons|isbn=978-1-118-02291-7}}&lt;/ref&gt;

In the banking sector worldwide, the [[Basel Accords]] are generally adopted by internationally active banks for tracking, reporting and exposing operational, credit and market risks.&lt;ref&gt;Van Deventer, Donald R., and Kenji Imai. Credit risk models and the Basel Accords. Singapore: John Wiley &amp; Sons (Asia), 2003.&lt;/ref&gt;&lt;ref&gt;Drumond, Ines. "Bank capital requirements, business cycle fluctuations and the Basel Accords: a synthesis." Journal of Economic Surveys 23.5 (2009): 798-830.&lt;/ref&gt;

==Uses of financial risk management==
Finance theory (i.e., [[financial economics]]) prescribes that a firm should take on a project if it increases [[shareholder]] value. Finance theory also shows that [[management|firm managers]] cannot create value for shareholders, also called its [[investment|investors]], by taking on projects that shareholders could do for themselves at the same cost.&lt;ref name="KUMAH"&gt;{{cite book|author=EMMANUEL ATTAH KUMAH|title=COST OF CAPITAL (A FINANCIAL TOOL TO CREATE AND MAXIMIZE SHAREHOLDER VALUE)|url=https://books.google.com/books?id=mK2nBQAAQBAJ&amp;pg=PA39|publisher=Lulu.com|isbn=978-1-304-26045-1|pages=39–}}&lt;/ref&gt;

When applied to financial risk management, this implies that firm managers should not hedge risks that investors can hedge for themselves at the same cost. This notion was captured by the so-called "hedging irrelevance proposition":&lt;ref name="CHANDRASEKHAR"&gt;{{cite book|author1=KRISHNAMURTI CHANDRASEKHAR|author2=Krishnamurti &amp; Viswanath (eds.) "|author3=Vishwanath S. R.|title=Advanced Corporate Finance|url=https://books.google.com/books?id=BNFX-gh6LlAC&amp;pg=PA178|publisher=PHI Learning Pvt. Ltd.|isbn=978-81-203-3611-7|pages=178–}}&lt;/ref&gt; ''In a [[perfect market]], the firm cannot create value by hedging a risk when the price of bearing that [[risk]] within the firm is the same as the [[price]] of bearing it outside of the firm.'' In practice, financial markets are not likely to be perfect markets.&lt;ref name="Hampton1982"&gt;{{cite book|author=John J. Hampton|title=Modern Financial Theory: Perfect and Imperfect Markets|url=https://books.google.com/books?id=3NsJAQAAMAAJ|year=1982|publisher=Reston Publishing Company|isbn=978-0-8359-4553-0}}&lt;/ref&gt;&lt;ref name="Hoque2005"&gt;{{cite book|author=Zahirul Hoque|title=Handbook of Cost and Management Accounting|url=https://books.google.com/books?id=-Wh0PQv0iYUC&amp;pg=PA201|year=2005|publisher=Spiramus Press Ltd|isbn=978-1-904905-01-1|pages=201–}}&lt;/ref&gt;&lt;ref name="Butler2012"&gt;{{cite book|author=Kirt C. Butler|title=Multinational Finance: Evaluating Opportunities, Costs, and Risks of Operations|url=https://books.google.com/books?id=ymRYTqoOkrYC&amp;pg=PT37|date=28 August 2012|publisher=John Wiley &amp; Sons|isbn=978-1-118-28276-2|pages=37–}}&lt;/ref&gt;&lt;ref name="Franzen2012"&gt;{{cite book|author=Dietmar Franzen|title=Design of Master Agreements for OTC Derivatives|url=https://books.google.com/books?id=xHwQBwAAQBAJ&amp;pg=PA7|date=6 December 2012|publisher=Springer Science &amp; Business Media|isbn=978-3-642-56932-6|pages=7–}}&lt;/ref&gt;

This suggests that firm managers likely have many opportunities to create value for shareholders using financial risk management, wherein they have to determine which risks are cheaper for the firm to manage than the shareholders. [[Market risk]]s that result in unique risks for the firm are commonly the best candidates for financial risk management.&lt;ref&gt;{{cite book|title=Corporate Finance: Part I|url=https://books.google.com/books?id=8Q6kvC8YenwC&amp;pg=PA32|publisher=Bookboon|isbn=978-87-7681-568-4|pages=32–}}&lt;/ref&gt;

The concepts of financial risk management change dramatically in the international realm. [[Multinational Corporation]]s are faced with many different obstacles in overcoming these challenges. There has been some research on the risks firms must consider when operating in many countries, such as the three kinds of foreign exchange exposure for various future time horizons: transactions exposure,&lt;ref&gt;http://www.emeraldinsight.com/Insight/viewContentItem.do;jsessionid=EFA8D4FB63329F2C94F48279646551BF?contentType=Article&amp;contentId=1649008 (contrary to conventional wisdom it may be rational to hedge translation exposure. Empirical evidence of agency costs and the managerial tendency to report higher levels of translated income, based on the early adoption of Financial Accounting Standard No. 52).&lt;/ref&gt; accounting exposure,&lt;ref&gt;Aggarwal, Raj, "The Translation Problem in International Accounting: Insights for Financial Management." Management International Review 15 (Nos. 2-3, 1975): 67-79. (Proposed accounting framework for evaluating and developing translation procedures for multinational corporations).&lt;/ref&gt; and economic exposure.&lt;ref&gt;http://www.iijournals.com/doi/abs/10.3905/jpm.1997.409611 (Discusses the benefits for hedging in foreign currencies for MNCs).&lt;/ref&gt;

== Financial risk manager ==

'''FRM® (Certified Financial Risk Manager Program)''' is an international professional certification offered by GARP (The Global Association of Risk Professionals).&lt;ref name="SEC"&gt;SEC(Securities and Exchange Commission), https://www.sec.gov/comments/s7-16-15/s71615-33.pdf&lt;/ref&gt;&lt;ref name="GARP"&gt;The Global Association of Risk Professionals, http://garp.org/#!/frm/&lt;/ref&gt;&lt;ref name="linkedin"&gt;Linkedin, https://www.linkedin.com/company/global-association-of-risk-professionals&lt;/ref&gt; FRM certificants are to be found in more than 190 countries and territories worldwide.&lt;ref name="FRM Curriculum"/&gt;  Successful candidates take an average of two years to earn their '''FRM Certification'''.&lt;ref name="FRM Q/A"&gt; GARP Frequently-Asked-Questions -EXAM regulations-, http://www.garp.org/#!/frm/frequently-asked-questions&lt;/ref&gt; FRMs are employed at major banks ([[Bank of America]], [[Bank of China]], [[ICBC]]...) and corporates ([[Goldman Sachs]], [[KPMG]], [[Deloitte]], [[PIMCO]], [[JP Morgan]], [[BlackRock]]..).&lt;ref name="GARP"/&gt;&lt;ref name="Wallstreetmojo"&gt;Wallstreetmojo official FRM salary, http://www.wallstreetmojo.com/frm-salary/&lt;/ref&gt;&lt;ref name="Chen, Liyan. 2015 Global 2000: The World's Largest Banks. Forbes. Forbes Magazine, 6 May 2015. Web. 23 July 2015."&gt;Chen, Liyan. "2015 Global 2000: The World's Largest Banks", Forbes Magazine.  https://www.forbes.com/sites/liyanchen/2015/05/06/2015-global-2000-the-worlds-largest-banks/&lt;/ref&gt;&lt;ref name=Certification&gt;The Benefits of Professional
Certification, William May William May Senior Vice President, http://www.garp.org/newmedia/presentations/frmerprecognitionceremony_williammay_021014.pdf&lt;/ref&gt;&lt;ref name=iactglobal&gt;iactglobal(2010. 5.) http://www.iactglobal.in/images/FRM_Companies.pdf&lt;/ref&gt;&lt;ref name=tongii&gt;2012 Financial RiskManager Roadshow, http://sem.tongji.edu.cn/semen_data/attachments/month_1206/201265155126.pdf&lt;/ref&gt;

&lt;!-- ARTICLE NOT ABOUT GARP
GARP is a not-for-profit organization and aims at "creating a cultural environment of risk awareness and management at every organizational level", &lt;ref name="SEC"/&gt;&lt;ref name="GARP"/&gt;&lt;ref name="blackrock"&gt;BLACKROCK, Speech at GARP 16th Annual Risk Management Conference, https://www.blackrock.com/corporate/en-in/literature/publication/2nd-nbni-gsifi-fsb-iosco-052915.pdf&lt;/ref&gt;&lt;ref name="linkedin"/&gt;&lt;ref name="什么是FRM"/&gt;&lt;ref name="edupristine"&gt;Edupristine, http://www.edupristine.com/frm/about-garp&lt;/ref&gt; aimed at enabling the risk community to make better informed risk decisions through "creating a culture of risk awareness®".&lt;ref name="SEC"/&gt;&lt;ref name="GARP"/&gt;&lt;ref name="brighttalk"&gt;Brighttalk, https://www.brighttalk.com/channel/10797/garp&lt;/ref&gt;&lt;ref name="linkedin"/&gt;&lt;ref name="什么是FRM"/&gt;

There are half a million members across 195 countries of the GARP. Central banks, commercial banks, investment banks, corporations, asset management firms, academic institutions and government agencies employ the members of GARP.&lt;ref name="SEC"/&gt;&lt;ref name="HKMA"&gt;HKMA GARP GLOBAL RISK FORUM(2013 5.28-5.29), https://fisher.osu.edu/supplements/10/9608/HKMA-GARP-Forum-20130430.pdf&lt;/ref&gt;

The corporate headquarters of GARP is located in Jersey City, New Jersey with a regional office in London, England. 
 --&gt;
The FRM curriculum is updated annually by risk professionals employed internationally at major banks, asset management firms, hedge funds, consulting firms, and regulators.&lt;ref name="FRM Curriculum"&gt;Official Candidate Guide, http://storage.pardot.com/39542/121486/FRM_2017_CandidateGuide_V8.2_AG.pdf&lt;/ref&gt; The Exam curriculum:&lt;ref name="GARP Buy Side Risk Managers Forum"&gt;GARP Buy Side Risk Managers Forum –
Risk Principles for Asset Managers(2015.6.11) http://www.ermsymposium.org/2015/presentations/C-19.pdf&lt;/ref&gt;&lt;ref name="FRM Curriculum"/&gt;
* The FRM Exam Part I covers the tools used to assess financial risk : Foundations of Risk Management, Quantitative Analysis, Financial Markets and Products, Valuation and Risk Models.
* The FRM Exam Part II focuses on the application of the tools acquired in the FRM Exam Part I through a deeper exploration of: Market Risk Measurement and Management, Credit Risk Measurement and Management, Operational and Integrated Risk Management, Risk Management and Investment Management, Current Issues in Financial Markets.

== See also ==
{{Columns-list|colwidth=30em|
'''Discussion'''
* [[Asset liability management]]
* [[cash management]]
* [[Cash flow hedge]]
* [[Corporate governance]]
* [[Credit risk]] 
* [[Default (finance)]]
* [[Enterprise risk management]]
* [[Financial risk]]
* [[Financial engineering]]
* [[Foreign exchange hedge]]
* [[Interest rate risk]]
* [[Insurance]]
* [[Investment risk]]
* [[Liquidity risk]]
* [[Market risk]]
* [[Operational risk]]
* [[Risk adjusted return on capital]]
* [[Risk modeling]]
* [[Risk pool]]
* [[Settlement risk]]
* [[Treasury management]]
* [[Value at risk]]
* [[Volatility risk]]

'''Institutions'''
*[[American Risk and Insurance Association]]
*[[Association of Insurance and Risk Managers in Industry and Commerce]]
*Global Association of Risk Professionals
*Institute of Risk Management
*[[Professional Risk Managers' International Association]]
*[[Risk and Insurance Management Society]]
'''Certifications'''
*[[Certified Risk Analyst]] (CRA)
*Certified Risk Manager (CRM)
*[[Chartered Enterprise Risk Analyst]] (CERA; [[Society of Actuaries]] credential)
*[[Financial Risk Manager]] (FRM)
*[[Institute and Faculty of Actuaries#Chartered Enterprise Risk Actuary .28CERA.29|Chartered Enterprise Risk Actuary]] (CERA; [[Institute and Faculty of Actuaries]] credential) 
*Institute of Risk Management#IRM Courses (MIRM designation; [[Enterprise Risk Management|ERM]] focused)
*[[Professional Risk Manager]] (PRM)
}}

==Bibliography==
* {{cite book | author=Crockford, Neil | title=An Introduction to Risk Management (2nd ed.) | publisher=Woodhead-Faulkner | year=1986 | isbn=0-85941-332-2}}
* {{cite book | author=Charles, Tapiero| title=Risk and Financial Management: Mathematical and Computational Methods| publisher=John Wiley &amp; Son | year=2004 | isbn=0-470-84908-8}}
* Conti, Cesare &amp; Mauri, Arnaldo (2008). "Corporate Financial Risk Management: Governance and Disclosure post IFRS 7", ''Icfai Journal of Financial Risk Management'', {{ISSN|0972-916X}}, Vol. V, n. 2, pp.&amp;nbsp;20–27.
* {{cite book | author=Lam, James | title=Enterprise Risk Management: From Incentives to Controls | publisher=John Wiley | year=2003 | isbn=978-0-471-43000-1}}
* {{Citation
  | last = McNeil
  | first = Alexander J.
  | last2 = Frey
  | first2 = Rüdiger
  | last3 = Embrechts
  | first3 = Paul
  | title = Quantitative Risk Management. Concepts, Techniques and Tools
  | place = Princeton, NJ
  | publisher = Princeton University Press
  | series = Princeton Series in Finance
  | year = 2005
  | url = https://books.google.com/books?id=f5J_OZPeq50C
  | isbn = 0-691-12255-5
  | mr = 2175089
  | zbl = 1089.91037}}
* {{cite book |author1=van Deventer |author2=Donald R. |author3=Kenji Imai |author4=Mark Mesler | title=Advanced Financial Risk Management: Tools and Techniques for Integrated Credit Risk and Interest Rate Risk Management | publisher=John Wiley| year=2004 | isbn= 978-0-470-82126-8}}

== References ==
{{Reflist|refs=http://www.iplaneducation.com/product/frm-online-classes/}}

== External links ==
* [http://www.ceranalyst.org/ CERA - The Chartered Enterprise Risk Analyst Credential - Society of Actuaries (SOA)]
* [http://www.garp.com Financial Risk Manager Certification Program - Global Association of Risk Professional (GARP)]
* [http://www.primia.org/ Professional Risk Manager Certification Program - Professional Risk Managers' International Association (PRMIA)]
* [http://www.sigmadewe.com/portfoliomanagement.html?&amp;L=1 Managing a portfolio of stock and risk-free investments: a tutorial for risk-sensitive investors]
*[http://www.risk.net/journal/ Risk Journals]
{{Financial risk}}

{{DEFAULTSORT:Financial Risk Management}}
[[Category:Mathematical science occupations]]
[[Category:Financial risk management| ]]</text>
      <sha1>9cm6rn3qxkdh0ou2y538q9zmbwclqs1</sha1>
    </revision>
  </page>
  <page>
    <title>Flip graph</title>
    <ns>0</ns>
    <id>47526601</id>
    <revision>
      <id>841537372</id>
      <parentid>828551574</parentid>
      <timestamp>2018-05-16T12:59:52Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10530">[[File:Flip_graphs.svg|The flip graphs of a quadrilateral (top-left), a pentagon (top-right), and a hexagon (bottom).|thumb]]
[[File:flips2d3d.svg|Examples of flips in dimension 1 (top-right), 2 (top-left and central row), and 3 (bottom row).|thumb]]
A '''flip graph''' is a [[Graph (discrete mathematics)|graph]] whose [[Vertex (graph theory)|vertices]] are [[Combinatorics|combinatorial]] or [[Geometry|geometric]] objects, and whose [[Edge (graph theory)|edges]] link two of these objects when they can be obtained from one another by an elementary operation called a flip. Flip graphs are special cases of [[Geometric graph theory|geometric graphs]].

Among noticeable flip graphs, one finds the [[N-skeleton|1-skeleton]] of polytopes such as [[Associahedron|associahedra]]&lt;ref name="CL"&gt;{{citation
 | last = Lee | first = Carl
 | mr = 1022776
 | title = The Associahedron and Triangulations of the &lt;math&gt;n&lt;/math&gt;-gon
 | journal = [[European Journal of Combinatorics]]
 | pages = 551–560
 | volume = 10
 | issue = 6
 | year = 1989
 | doi=10.1016/S0195-6698(89)80072-1}}&lt;/ref&gt; or [[Cyclohedron|cyclohedra]].&lt;ref name="RS"&gt;{{citation
 | last = Simion | first = Rodica | author-link1 = Rodica Simion
 | mr = 1979780
 | title = A type-B associahedron
 | journal = [[Advances in Applied Mathematics]]
 | pages = 2–25
 | volume = 30
 | issue = 1-2
 | year = 2003
 | doi=10.1016/S0196-8858(02)00522-5}}&lt;/ref&gt;

== Examples ==

A prototypical flip graph is that of a convex &lt;math&gt;n&lt;/math&gt;-gon &lt;math&gt;\pi&lt;/math&gt;. The vertices of this graph are the [[Polygon triangulation|triangulations]] of &lt;math&gt;\pi&lt;/math&gt;, and two triangulations are [[Glossary of graph theory#adjacent|adjacent]] in it whenever they differ by a single interior edge. In this case, the flip operation consists in exchanging the diagonals of a convex quadrilateral. These diagonals are the interior edges by which two triangulations adjacent in the flip graph differ. The resulting flip graph is both the [[Hasse diagram]] of the [[Tamari lattice]]&lt;ref&gt;{{citation
 | last = Tamari | first = Dov | author-link = Dov Tamari (mathematician)
 | mr = 0146227
 | journal = Nieuw Archief voor Wiskunde, Ser. 3
 | pages = 131–146
 | title = The algebra of bracketings and their enumeration
 | volume = 10
 | year = 1962}}
&lt;/ref&gt; and the [[N-skeleton|1-skeleton]] of the &lt;math&gt;(n-3)&lt;/math&gt;-dimensional [[associahedron]].&lt;ref name="CL"/&gt;

This basic construction can be generalized in a number of ways.

=== Finite sets of points in Euclidean space ===

Let &lt;math&gt;T&lt;/math&gt; be a [[Triangulation (geometry)|triangulation]] of a finite set of points &lt;math&gt;\mathcal{A}\subset\mathbb{R}^d&lt;/math&gt;. Under some conditions, one may transform &lt;math&gt;T&lt;/math&gt; into another triangulation of &lt;math&gt;\mathcal{A}&lt;/math&gt; by a flip. This operation consists in modifying the way &lt;math&gt;T&lt;/math&gt; triangulates a [[Matroid|circuit]] (a minimally [[Affine space|affinely dependent]] subset of &lt;math&gt;\mathcal{A}&lt;/math&gt;). More precisely, if some triangulation &lt;math&gt;\tau^-&lt;/math&gt; of a circuit &lt;math&gt;z\subset\mathcal{A}&lt;/math&gt; is a subset of &lt;math&gt;T&lt;/math&gt;, and if all the cells (faces of maximal dimension) of &lt;math&gt;\tau^-&lt;/math&gt; have the same link &lt;math&gt;\lambda&lt;/math&gt; in &lt;math&gt;T&lt;/math&gt;, then one can perform a flip within &lt;math&gt;T&lt;/math&gt; by replacing &lt;math&gt;\lambda\mathord{\star}\tau^-&lt;/math&gt; by &lt;math&gt;\lambda\mathord{\star}\tau^+&lt;/math&gt;, where

: &lt;math&gt;
X\mathord{\star}{Y}=\{x\cup{y}:(x,y)\in{X\mathord{\times}{Y}}\},
&lt;/math&gt;

and &lt;math&gt;\tau^+&lt;/math&gt; is, by [[Radon's theorem|Radon's partition theorem]], the unique other triangulation of &lt;math&gt;z&lt;/math&gt;. The conditions just stated, under which a flip is possible, make sure that this operation results in a triangulation of &lt;math&gt;\mathcal{A}&lt;/math&gt;.&lt;ref name="DRS"&gt;{{cite book
 | last1 = De Loera | first1 = Jesús A. | author-link1 = Jesús A. De Loera
 | last2 = Rambau | first2 = Jörg
 | last3 = Santos | first3 = Francisco | author-link3 = Francisco Santos Leal
 | year = 2010
 | title = Triangulations, Structures for Algorithms and Applications
 | series = Algorithms and Computation in Mathematics
 | volume = 25
 | publisher = Springer}}&lt;/ref&gt; The corresponding flip graph, whose vertices are the triangulations of &lt;math&gt;\mathcal{A}&lt;/math&gt; and whose edges correspond to flips between them, is a natural generalization of the flip graph of a convex polygon, as the two flip graphs coincide when &lt;math&gt;\mathcal{A}&lt;/math&gt; is the set of the vertices of a convex &lt;math&gt;n&lt;/math&gt;-gon.

=== Topological surfaces ===

Another kind of flip graphs is obtained by considering the [[Triangulation (topology)|triangulations]] of a [[Surface (topology)|topological surface]]:&lt;ref&gt;{{citation
 | last = Negami | first = Seiya
 | mr = 1310882
 | title = Diagonal flips in triangulations of surfaces
 |journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 225–232
 | volume = 135
 | issue = 1-3
 | year = 1994
 | doi=10.1016/0012-365X(93)E0101-9}}&lt;/ref&gt; consider such a surface &lt;math&gt;\mathcal{S}&lt;/math&gt;, place a finite number &lt;math&gt;n&lt;/math&gt; of points on it, and connect them by arcs in such a way that any two arcs never cross. When this set of arcs is maximal, it decomposes &lt;math&gt;\mathcal{S}&lt;/math&gt; into triangles. If in addition there are no [[Multiple edges|multiple arcs]] (distinct arcs with the same pair of vertices), nor [[Loop (topology)|loops]], this set of arcs defines a [[Triangulation (topology)|triangulation]] of &lt;math&gt;\mathcal{S}&lt;/math&gt;.

In this setting, two triangulations of &lt;math&gt;\mathcal{S}&lt;/math&gt; that can be obtained from one another by a continuous transformation are identical.

Two triangulations are related by a flip when they differ by exactly one of the arcs they are composed of. Note that, these two triangulations necessarily have the same number of vertices. As in the Euclidean case, the flip graph of &lt;math&gt;\mathcal{S}&lt;/math&gt; is the graph whose vertices are the triangulations of &lt;math&gt;\mathcal{S}&lt;/math&gt; with &lt;math&gt;n&lt;/math&gt; vertices and whose edges correspond to flips between them. This definition can be straightforwardly extended to [[Surface (topology)#Surfaces with boundary|bordered topological surfaces]].
 
The flip graph of a surface generalises that of a &lt;math&gt;n&lt;/math&gt;-gon, as the two coincide when the surface is a topological disk with &lt;math&gt;n&lt;/math&gt; points placed on its boundary.

=== Other flip graphs ===

A number of other flip graphs can be defined using alternative definitions of a triangulation. For instance, the flip graph whose vertices are the centrally-symmetric triangulations of a &lt;math&gt;(2d+2)&lt;/math&gt;-gon and whose edges correspond to the operation of doing two centrally-symmetric flips is the [[N-skeleton|1-skeleton]] of the &lt;math&gt;d&lt;/math&gt;-dimensional [[cyclohedron]].&lt;ref name="RS"/&gt; One can also consider an alternative flip graph of a topological surface, defined by allowing multiple arcs and loops in the triangulations of this surface.

Flip graphs may also be defined using combinatorial objects other than triangulations. An example of such combinatorial objects are the [[domino tiling]]s of a given region in the plane. In this case, a flip can be performed when two adjacent dominos cover a square: it consists in rotating these dominos by 90 degrees around the center of the square, resulting in a different domino tiling of the same region.

== Properties ==

=== Polytopality ===

Apart from [[Associahedron|associahedra]] and [[Cyclohedron|cyclohedra]], a number of [[Convex polytope|polytopes]] have the property that their [[N-skeleton|1-skeleton]] is a flip graph. For instance, if &lt;math&gt;\mathcal{A}&lt;/math&gt; is a finite set of points in &lt;math&gt;\mathbb{R}^d&lt;/math&gt;, the [[Point set triangulation#Regular triangulations|regular triangulations]] of &lt;math&gt;\mathcal{A}&lt;/math&gt; are the ones that can be obtained by [[Projection (linear algebra)|projecting]] some faces of a &lt;math&gt;(d+1)&lt;/math&gt;-dimensional [[Convex polytope|polytope]] on &lt;math&gt;\mathbb{R}^d&lt;/math&gt;. The subgraph induced by these triangulations in the flip graph of &lt;math&gt;\mathcal{A}&lt;/math&gt; is the [[N-skeleton|1-skeleton]] of a [[Convex polytope|polytope]], the secondary polytope of &lt;math&gt;\mathcal{A}&lt;/math&gt;.&lt;ref name="GZK"&gt;{{citation
 | last1 = Gel'fand  | first1 = Izrail M. | author-link1 = Israel Gelfand
 | mr = 1020882
 | last2 = Zelevinskiĭ  | first2 = Andrei V. | author-link2 = Andrei Zelevinsky
 | last3 = Kapranov  | first3 = Mikhail M.
 | title = Newton polytopes of principal A-determinants
 | journal = [[Soviet Mathematics - Doklady]]
 | pages = 278–281
 | volume = 40
 | year = 1990}}&lt;/ref&gt;

=== Connectedness ===

Polytopal flip graphs are, by this property, [[Connectivity (graph theory)|connected]]. As shown by [[Klaus Wagner]] in the 1930s, the flip graph of the topological sphere is connected.&lt;ref&gt;{{citation
 | last1 = Wagner | first1 = Klaus | author-link1 = Klaus Wagner
 | title = Bemerkungen zum Vierfarbenproblem
 | journal = [[Jahresbericht der Deutschen Mathematiker-Vereinigung]]
 | pages = 26–32
 | volume = 46
 | year = 1936}}
&lt;/ref&gt; Among the connected flip graphs, one also finds the flip graphs of any finite 2-dimensional set of points.&lt;ref&gt;{{citation
 | last1 = Lawson | first1 = Charles L.
 | mr = 0311491
 | title = Transforming triangulations
 |journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 365–372
 | volume = 3
 | year = 1972
 | doi = 10.1016/0012-365X(72)90093-3}}
&lt;/ref&gt; In higher dimensional Euclidean spaces, the situation is much more complicated. Finite sets of points of &lt;math&gt;\mathbb{R}^d&lt;/math&gt; with disconnected flip graphs have been found whenever &lt;math&gt;d&lt;/math&gt; is at least 5.&lt;ref name="DRS"/&gt;
&lt;ref&gt;{{citation
 | last1 = Santos | first1 = Francisco | author-link1 = Francisco Santos Leal
 | mr = 1758756
 | title = A point set whose space of triangulations is disconnected
 | journal = [[Journal of the American Mathematical Society]]
 | pages = 611–637
 | volume = 13
 | year = 2000
 | doi = 10.1090/S0894-0347-00-00330-1}}
&lt;/ref&gt;
&lt;ref&gt;{{citation
 | last1 = Santos | first1 = Francisco | author-link1 = Francisco Santos Leal
 | mr = 2181765
 | title = Non-connected toric Hilbert schemes
 | journal = [[Mathematische Annalen]]
 | pages = 645–665
 | volume = 332
 | year = 2005
 | doi = 10.1007/s00208-005-0643-5| arxiv = math/0204044}}
&lt;/ref&gt;

It is yet unknown whether the flip graphs of finite 3- and 4-dimensional sets of points are always connected or not.&lt;ref name="DRS"/&gt;

== References ==
{{Reflist}}

[[Category:Application-specific graphs]]
[[Category:Geometric graph theory]]</text>
      <sha1>7qb0ciqgy8m1q16wif773qlsqzv3k9q</sha1>
    </revision>
  </page>
  <page>
    <title>Fundamental theorem of algebra</title>
    <ns>0</ns>
    <id>51414</id>
    <revision>
      <id>865489165</id>
      <parentid>865488986</parentid>
      <timestamp>2018-10-24T08:06:04Z</timestamp>
      <contributor>
        <username>Latex-yow</username>
        <id>27692366</id>
      </contributor>
      <minor/>
      <comment>/* History */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="44091">{{Distinguish|Fundamental theorem of arithmetic}}

The '''[[fundamental theorem]] of [[algebra]]''' states that every non-[[constant polynomial|constant]] single-variable [[polynomial]] with [[Complex number|complex]] [[coefficient]]s has at least one complex [[root of a function|root]]. This includes polynomials with real coefficients, since every real number is a complex number with an [[imaginary part]] equal to zero.

Equivalently (by definition), the theorem states that the [[field (mathematics)|field]] of [[complex number]]s is [[algebraically closed field|algebraically closed]].

The theorem is also stated as follows: every non-zero, single-variable, [[Degree of a polynomial|degree]] ''n'' polynomial with complex coefficients has, counted with [[Multiplicity (mathematics)#Multiplicity of a root of a polynomial|multiplicity]], exactly ''n'' complex roots. The equivalence of the two statements can be proven through the use of successive [[polynomial division]].

In spite of its name, there is no purely algebraic proof of the theorem, since any proof must use some form of [[Completeness of the real numbers|completeness]], which is not an algebraic concept. Additionally, it is not fundamental for [[modern algebra]]; its name was given at a time when algebra was synonymous with [[theory of equations]].

==History==
Peter Roth, in his book ''Arithmetica Philosophica'' (published in 1608, at Nürnberg, by Johann Lantzenberger),&lt;ref&gt;[http://www.e-rara.ch/doi/10.3931/e-rara-4843 Rare books]&lt;/ref&gt; wrote that a polynomial equation of degree ''n'' (with real coefficients) ''may'' have ''n'' solutions. [[Albert Girard]], in his book ''L'invention nouvelle en l'Algèbre'' (published in 1629), asserted that a polynomial equation of degree ''n'' has ''n'' solutions, but he did not state that they had to be real numbers. Furthermore, he added that his assertion holds "unless the equation is incomplete", by which he meant that no coefficient is equal to 0. However, when he explains in detail what he means, it is clear that he actually believes that his assertion is always true; for instance, he shows that the equation &lt;math&gt;x^4 = 4x-3,&lt;/math&gt; although incomplete, has four solutions (counting multiplicities): 1 (twice), &lt;math&gt;-1+i\sqrt{2},&lt;/math&gt; and &lt;math&gt;-1-i\sqrt{2}.&lt;/math&gt;

As will be mentioned again below, it follows from the fundamental theorem of algebra that every non-constant polynomial with real coefficients can be written as a product of polynomials with real coefficients whose degree are either 1 or 2. However, in 1702 [[Gottfried Leibniz|Leibniz]] said that no polynomial of the type ''x''&lt;sup&gt;4&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''a''&lt;sup&gt;4&lt;/sup&gt; (with ''a'' real and distinct from 0) can be written in such a way. Later, [[Nicolaus I Bernoulli|Nikolaus Bernoulli]] made the same assertion concerning the polynomial ''x''&lt;sup&gt;4&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;4''x''&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;2''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;4''x''&amp;nbsp;+&amp;nbsp;4, but he got a letter from [[Leonhard Euler|Euler]] in 1742&lt;ref&gt;See section ''Le rôle d'Euler'' in C. Gilain's article ''Sur l'histoire du théorème fondamental de l'algèbre: théorie des équations et calcul intégral''.&lt;/ref&gt; in which he was told that his polynomial happened to be equal to

:&lt;math&gt;\left (x^2-(2+\alpha)x+1+\sqrt{7}+\alpha \right ) \left (x^2-(2-\alpha)x+1+\sqrt{7}-\alpha \right ), \qquad \alpha = \sqrt{4+2\sqrt{7}}.&lt;/math&gt;

Also, Euler mentioned that

:&lt;math&gt;x^4+a^4= \left (x^2+a\sqrt{2}\cdot x+a^2 \right ) \left (x^2-a\sqrt{2}\cdot x+a^2 \right ).&lt;/math&gt;

A first attempt at proving the theorem was made by [[Jean le Rond d'Alembert|d'Alembert]] in 1746, but his proof was incomplete. Among other problems, it assumed implicitly a theorem (now known as [[Puiseux's theorem]]) which would not be proved until more than a century later, and furthermore the proof assumed the fundamental theorem of algebra. Other attempts were made by [[Leonhard Euler|Euler]] (1749), [[François Daviet de Foncenex|de Foncenex]] (1759), [[Joseph Louis Lagrange|Lagrange]] (1772), and [[Pierre-Simon Laplace|Laplace]] (1795). These last four attempts assumed implicitly Girard's assertion; to be more precise, the existence of solutions was assumed and all that remained to be proved was that their form was ''a''&amp;nbsp;+&amp;nbsp;''bi'' for some real numbers ''a'' and ''b''. In modern terms, Euler, de Foncenex, Lagrange, and Laplace were assuming the existence of a [[splitting field]] of the polynomial ''p''(''z'').

At the end of the 18th century, two new proofs were published which did not assume the existence of roots, but neither of which was complete. One of them, due to James Wood and mainly algebraic, was published in 1798 and it was totally ignored. Wood's proof had an algebraic gap.&lt;ref&gt;Concerning Wood's proof, see the article ''A forgotten paper on the fundamental theorem of algebra'', by Frank Smithies.&lt;/ref&gt; The other one was published by [[Carl Friedrich Gauss|Gauss]] in 1799 and it was mainly geometric, but it had a topological gap, filled by [[Alexander Ostrowski]] in 1920, as discussed in Smale 1981 [http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.bams/1183547848] (Smale writes, "...I wish to point out what an immense gap Gauss' proof contained. It is a subtle point even today that a real algebraic plane curve cannot enter a disk without leaving. In fact even though Gauss redid this proof 50 years later, the gap remained. It was not until 1920 that Gauss' proof was completed. In the reference Gauss, A. Ostrowski has a paper which does this and gives an excellent discussion of the problem as well..."). A rigorous proof was first published by [[Jean-Robert Argand|Argand]] in 1806 (and revisited in 1813);&lt;ref&gt; {{MacTutor Biography|id=Argand|title=Jean-Robert Argand}}&lt;/ref&gt; it was here that, for the first time, the fundamental theorem of algebra was stated for polynomials with complex coefficients, rather than just real coefficients. Gauss produced two other proofs in 1816 and another version of his original proof in 1849.

The first textbook containing a proof of the theorem was [[Cauchy]]'s ''Cours d'analyse de l'École Royale Polytechnique'' (1821). It contained Argand's proof, although [[Jean Robert Argand|Argand]] is not credited for it.

None of the proofs mentioned so far is [[Constructivism (mathematics)|constructive]]. It was [[Weierstrass]] who raised for the first time, in the middle of the 19th century, the problem of finding a [[constructive proof]] of the fundamental theorem of algebra. He presented his solution, that amounts in modern terms to a combination of the [[Durand–Kerner method]] with the [[homotopy continuation]] principle, in 1891. Another proof of this kind was obtained by [[Hellmuth Kneser]] in 1940 and simplified by his son [[Martin Kneser]] in 1981.

Without using [[countable choice]], it is not possible to constructively prove the fundamental theorem of algebra for complex numbers based on the [[construction of the real numbers|Dedekind real numbers]] (which are not constructively equivalent to the Cauchy real numbers without countable choice&lt;ref&gt;For the minimum necessary to prove their equivalence, see Bridges, Schuster, and Richman; 1998; &lt;cite&gt;A weak countable choice principle&lt;/cite&gt;; available from [http://math.fau.edu/richman/HTML/DOCS.HTM].&lt;/ref&gt;). However, [[Fred Richman]] proved a reformulated version of the theorem that does work.&lt;ref&gt;See Fred Richman; 1998; &lt;cite&gt;The fundamental theorem of algebra: a constructive development without choice&lt;/cite&gt;; available from [http://math.fau.edu/richman/HTML/DOCS.HTM].&lt;/ref&gt;

==Proofs==
All proofs below involve some [[mathematical analysis|analysis]], or at least the [[Topology|topological]] concept of [[continuous function|continuity]] of real or complex functions. Some also use [[Derivative|differentiable]] or even [[Analytic function|analytic]] functions. This fact has led to the remark that the Fundamental Theorem of Algebra is neither fundamental, nor a theorem of algebra.{{Citation needed|reason=Who made the remark?|date=February 2016}}

Some proofs of the theorem only prove that any non-constant polynomial with '''real''' coefficients has some complex root. This is enough to establish the theorem in the general case because, given a non-constant polynomial ''p''(''z'') with complex coefficients, the polynomial

:&lt;math&gt;q(z)=p(z)\overline{p(\overline z)}&lt;/math&gt;

has only real coefficients and, if ''z'' is a zero of ''q''(''z''), then either ''z'' or its conjugate is a root of ''p''(''z'').

A large number of non-algebraic proofs of the theorem use the fact (sometimes called "growth lemma") that an ''n''-th degree polynomial function ''p''(''z'') whose dominant coefficient is 1 behaves like ''z&lt;sup&gt;n&lt;/sup&gt;'' when |''z''| is large enough. A more precise statement is: there is some positive real number ''R'' such that:

:&lt;math&gt;\tfrac{1}{2}|z^n|&lt;|p(z)|&lt;\tfrac{3}{2}|z^n|&lt;/math&gt;

when |''z''|&amp;nbsp;&gt;&amp;nbsp;''R''.

===Complex-analytic proofs===
Find a closed [[disk (mathematics)|disk]] ''D'' of radius ''r'' centered at the origin such that |''p''(''z'')|&amp;nbsp;&gt;&amp;nbsp;|''p''(0)| whenever |''z''|&amp;nbsp;≥&amp;nbsp;''r''. The minimum of |''p''(''z'')| on ''D'', which must exist since ''D'' is [[compact set|compact]], is therefore achieved at some point ''z''&lt;sub&gt;0&lt;/sub&gt; in the interior of ''D'', but not at any point of its boundary. The [[Maximum modulus principle]] (applied to 1/''p''(''z'')) implies then that ''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)&amp;nbsp;=&amp;nbsp;0. In other words, ''z''&lt;sub&gt;0&lt;/sub&gt; is a zero of ''p''(''z'').

'''A variation of this proof''' does not require the use of the maximum modulus principle (in fact, the same argument with minor changes also gives a proof of the maximum modulus principle for holomorphic functions). If we assume by contradiction that ''a'' := ''p''(''z''&lt;sub&gt;0&lt;/sub&gt;) ≠ 0, then, expanding ''p''(''z'') in powers of ''z'' − ''z''&lt;sub&gt;0&lt;/sub&gt; we can write

:&lt;math&gt;p(z) = a + c_k (z-z_0)^k + c_{k+1} (z-z_0)^{k+1} + \cdots + c_n (z-z_0)^n.&lt;/math&gt;

Here, the ''c&lt;sub&gt;j&lt;/sub&gt;'' are simply the coefficients of the polynomial ''z'' → ''p''(''z'' + ''z''&lt;sub&gt;0&lt;/sub&gt;), and we let ''k'' be the index of the first coefficient following the constant term that is non-zero. But now we see that for ''z'' sufficiently close to ''z''&lt;sub&gt;0&lt;/sub&gt; this has behavior asymptotically similar to the simpler polynomial &lt;math&gt;q(z) = a+c_k (z-z_0)^k&lt;/math&gt;, in the sense that (as is easy to check) the function:

:&lt;math&gt;\left|\frac{p(z)-q(z)}{(z-z_0)^{k+1}}\right|&lt;/math&gt; 

is bounded by some positive constant ''M'' in some neighborhood of ''z''&lt;sub&gt;0&lt;/sub&gt;. Therefore if we define &lt;math&gt;\theta_0 = (\arg(a)+\pi-\arg(c_k)) /k&lt;/math&gt; and let &lt;math&gt;z = z_0 + r e^{i \theta_0}&lt;/math&gt;, then for any sufficiently small positive number ''r'' (so that the bound ''M'' mentioned above holds), using the triangle inequality we see that

:&lt;math&gt;\begin{align}
|p(z)| &amp;\le |q(z)| + r^{k+1} \left|\frac{p(z)-q(z)}{r^{k+1}}\right|\\[4pt]
&amp;\le \left|a +(-1)c_k r^k e^{i(\arg(a)-\arg(c_k))}\right| + M r^{k+1} \\[4pt]
&amp;= |a|-|c_k|r^k + M r^{k+1}
\end{align}&lt;/math&gt;

When ''r'' is sufficiently close to 0 this upper bound for |''p''(''z'')| is strictly smaller than |''a''|, in contradiction to the definition of ''z''&lt;sub&gt;0&lt;/sub&gt;. (Geometrically, we have found an explicit direction θ&lt;sub&gt;0&lt;/sub&gt; such that if one approaches ''z''&lt;sub&gt;0&lt;/sub&gt; from that direction one can obtain values ''p''(''z'') smaller in absolute value than |''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)|.)

'''Another''' analytic proof can be obtained along this line of thought observing that, since |''p''(''z'')|&amp;nbsp;&gt;&amp;nbsp;|''p''(0)| outside ''D'', the minimum of |''p''(''z'')| on the whole complex plane is achieved at ''z''&lt;sub&gt;0&lt;/sub&gt;. If |''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)|&amp;nbsp;&gt;&amp;nbsp;0, then 1/''p'' is a bounded [[holomorphic function]] in the entire complex plane since, for each complex number ''z'', |1/''p''(''z'')|&amp;nbsp;≤&amp;nbsp;|1/''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)|. Applying [[Liouville's theorem (complex analysis)|Liouville's theorem]], which states that a bounded entire function must be constant, this would imply that 1/''p'' is constant and therefore that ''p'' is constant. This gives a contradiction, and hence ''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)&amp;nbsp;=&amp;nbsp;0.

'''Yet another''' analytic proof uses the [[argument principle]]. Let ''R'' be a positive real number large enough so that every root of ''p''(''z'') has absolute value smaller than ''R''; such a number must exist because every non-constant polynomial function of degree ''n'' has at most ''n'' zeros. For each ''r''&amp;nbsp;&gt;&amp;nbsp;''R'', consider the number

:&lt;math&gt;\frac{1}{2\pi i}\int_{c(r)}\frac{p'(z)}{p(z)}\,dz,&lt;/math&gt;

where ''c''(''r'') is the circle centered at 0 with radius ''r'' oriented counterclockwise; then the [[argument principle]] says that this number is the number ''N'' of zeros of ''p''(''z'') in the open ball centered at 0 with radius ''r'', which, since ''r''&amp;nbsp;&gt;&amp;nbsp;''R'', is the total number of zeros of ''p''(''z''). On the other hand, the integral of ''n''/''z'' along ''c''(''r'') divided by 2π''i'' is equal to ''n''. But the difference between the two numbers is

:&lt;math&gt;\frac{1}{2\pi i}\int_{c(r)}\left(\frac{p'(z)}{p(z)}-\frac{n}{z}\right)dz=\frac{1}{2\pi i}\int_{c(r)}\frac{zp'(z)-np(z)}{zp(z)}\,dz.&lt;/math&gt;

The numerator of the rational expression being integrated has degree at most ''n''&amp;nbsp;-&amp;nbsp;1 and the degree of the denominator is ''n''&amp;nbsp;+&amp;nbsp;1. Therefore, the number above tends to 0 as ''r'' → +∞. But the number is also equal to ''N''&amp;nbsp;−&amp;nbsp;''n'' and so ''N''&amp;nbsp;=&amp;nbsp;''n''.

'''Still another''' complex-analytic proof can be given by combining [[linear algebra]] with the [[Cauchy's integral theorem|Cauchy theorem]]. To establish that every complex polynomial of degree ''n''&amp;nbsp;&gt;&amp;nbsp;0 has a zero, it suffices to show that every [[complex square matrix]] of size ''n''&amp;nbsp;&gt;&amp;nbsp;0 has a (complex) [[eigenvalue]].&lt;ref&gt;A proof of the fact that this suffices can be seen [[Algebraically closed field#Every endomorphism of Fn has some eigenvector|here]].&lt;/ref&gt; The proof of the latter statement is [[Proof by contradiction|by contradiction]].

Let ''A'' be a complex square matrix of size ''n''&amp;nbsp;&gt;&amp;nbsp;0 and let ''I&lt;sub&gt;n&lt;/sub&gt;'' be the unit matrix of the same size. Assume ''A'' has no eigenvalues. Consider the [[resolvent formalism|resolvent]] function

:&lt;math&gt; R(z)=(zI_n-A)^{-1},&lt;/math&gt;

which is a [[meromorphic function]] on the complex plane with values in the vector space of matrices. The eigenvalues of ''A'' are precisely the poles of ''R''(''z''). Since, by assumption, ''A'' has no eigenvalues, the function ''R''(''z'') is an [[entire function]] and [[Cauchy's integral theorem|Cauchy theorem]] implies that

:&lt;math&gt; \int_{c(r)} R(z) dz =0.&lt;/math&gt;

On the other hand, ''R''(''z'') expanded as a geometric series gives:

:&lt;math&gt;R(z)=z^{-1}(I_n-z^{-1}A)^{-1}=z^{-1}\sum_{k=0}^{\infty}\frac{1}{z^k}A^k\cdot&lt;/math&gt;

This formula is valid outside the closed [[disc (mathematics)|disc]] of radius &lt;math&gt;\|A\|&lt;/math&gt; (the [[operator norm]] of ''A''). Let &lt;math&gt;r&gt;\|A\|.&lt;/math&gt; Then

:&lt;math&gt;\int_{c(r)}R(z)dz=\sum_{k=0}^{\infty}\int_{c(r)}\frac{dz}{z^{k+1}}A^k=2\pi iI_n&lt;/math&gt;

(in which only the summand ''k''&amp;nbsp;=&amp;nbsp;0 has a nonzero integral). This is a contradiction, and so ''A'' has an eigenvalue.

'''Finally''', [[Rouché's theorem]] gives perhaps the shortest proof of the theorem.

===Topological proofs===
Suppose the minimum of |''p''(''z'')| on the whole complex plane is achieved at ''z''&lt;sub&gt;0&lt;/sub&gt;; it was seen at the proof which uses Liouville's theorem that such a number must exist. We can write ''p''(''z'') as a polynomial in ''z''&amp;nbsp;−&amp;nbsp;''z''&lt;sub&gt;0&lt;/sub&gt;: there is some natural number ''k'' and there are some complex numbers ''c&lt;sub&gt;k&lt;/sub&gt;'', ''c''&lt;sub&gt;''k''&amp;nbsp;+&amp;nbsp;1&lt;/sub&gt;, ..., ''c&lt;sub&gt;n&lt;/sub&gt;'' such that ''c&lt;sub&gt;k&lt;/sub&gt;''&amp;nbsp;≠&amp;nbsp;0 and:

:&lt;math&gt;p(z)=p(z_0)+c_k(z-z_0)^k+c_{k+1}(z-z_0)^{k+1}+ \cdots +c_n(z-z_0)^n.&lt;/math&gt;

If ''p''(''z''&lt;sub&gt;0&lt;/sub&gt;) is nonzero, it follows that if ''a'' is a ''k''&lt;sup&gt;th&lt;/sup&gt; root of −''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)/''c&lt;sub&gt;k&lt;/sub&gt;'' and if ''t'' is positive and sufficiently small, then |''p''(''z''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;+&amp;nbsp;''ta'')|&amp;nbsp;&lt;&amp;nbsp;|''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)|, which is impossible, since |''p''(''z''&lt;sub&gt;0&lt;/sub&gt;)| is the minimum of |''p''| on ''D''.

For another topological proof by contradiction, suppose that the polynomial ''p''(''z'') has no roots, and consequently is never equal to 0. Think of the polynomial as a map from the complex plane into the complex plane. It maps any circle |''z''|&amp;nbsp;=&amp;nbsp;''R'' into a closed loop, a curve ''P''(''R''). We will consider what happens to the [[winding number]] of ''P''(''R'') at the extremes when ''R'' is very large and when ''R'' = 0. When ''R'' is a sufficiently large number, then the leading term ''z&lt;sup&gt;n&lt;/sup&gt;'' of ''p''(''z'') dominates all other terms combined; in other words, 

:&lt;math&gt;\left | z^n \right | &gt; \left | a_{n-1} z^{n-1} + \cdots + a_0 \right |.&lt;/math&gt;

When ''z'' traverses the circle &lt;math&gt;Re^{i\theta}&lt;/math&gt; once counter-clockwise &lt;math&gt;(0\leq \theta \leq 2\pi),&lt;/math&gt; then &lt;math&gt;z^n=Re^{in\theta}&lt;/math&gt; winds ''n'' times counter-clockwise &lt;math&gt;(0\leq \theta \leq 2\pi n)&lt;/math&gt; around the origin (0,0), and ''P''(''R'') likewise. At the other extreme, with |''z''|&amp;nbsp;=&amp;nbsp;0, the curve ''P''(0) is merely the single point ''p''(0), which must be nonzero because ''p''(''z'') is never zero. Thus ''p''(0) must be distinct from the origin (0,0), which denotes 0 in the complex plane. The winding number of ''P''(0) around the origin (0,0) is thus 0. Now changing ''R'' continuously will [[homotopy | deform the loop continuously]]. At some ''R'' the winding number must change. But that can only happen if the curve ''P''(''R'') includes the origin (0,0) for some ''R''. But then for some ''z'' on that circle |''z''|&amp;nbsp;=&amp;nbsp;''R'' we have ''p''(''z'') = 0, contradicting our original assumption. Therefore, ''p''(''z'') has at least one zero.

===Algebraic proofs===
These proofs use two facts about real numbers that require only a small amount of analysis (more precisely, the [[intermediate value theorem]]):
* every polynomial with odd degree and real coefficients has some real root;
* every non-negative real number has a square root.

The second fact, together with the [[quadratic formula]], implies the theorem for real quadratic polynomials. In other words, algebraic proofs of the fundamental theorem actually show that if ''R'' is any [[real-closed field]], then its extension ''C'' = ''R''({{radic|−1}}) is algebraically closed.

As mentioned above, it suffices to check the statement "every non-constant polynomial ''p''(''z'') with real coefficients has a complex root". This statement can be proved by induction on the greatest non-negative integer ''k'' such that 2&lt;sup&gt;''k''&lt;/sup&gt; divides the degree ''n'' of ''p''(''z''). Let ''a'' be the coefficient of ''z&lt;sup&gt;n&lt;/sup&gt;'' in ''p''(''z'') and let ''F'' be a [[splitting field]] of ''p''(''z'') over ''C''; in other words, the field ''F'' contains ''C'' and there are elements ''z''&lt;sub&gt;1&lt;/sub&gt;, ''z''&lt;sub&gt;2&lt;/sub&gt;, ..., ''z&lt;sub&gt;n&lt;/sub&gt;'' in ''F'' such that

:&lt;math&gt;p(z)=a(z-z_1)(z-z_2) \cdots (z-z_n).&lt;/math&gt;

If ''k''&amp;nbsp;=&amp;nbsp;0, then ''n'' is odd, and therefore ''p''(''z'') has a real root. Now, suppose that ''n''&amp;nbsp;=&amp;nbsp;2''&lt;sup&gt;k&lt;/sup&gt;m'' (with ''m'' odd and ''k''&amp;nbsp;&gt;&amp;nbsp;0) and that the theorem is already proved when the degree of the polynomial has the form 2&lt;sup&gt;''k''&amp;nbsp;−&amp;nbsp;1&lt;/sup&gt;''m''′ with ''m''′ odd. For a real number ''t'', define:

:&lt;math&gt;q_t(z)=\prod_{1\le i&lt;j\le n}\left(z-z_i-z_j-tz_iz_j\right).&lt;/math&gt;

Then the coefficients of ''q&lt;sub&gt;t&lt;/sub&gt;''(''z'') are [[symmetric polynomial]]s in the ''z&lt;sub&gt;i&lt;/sub&gt;'' with real coefficients. Therefore, they can be expressed as polynomials with real coefficients in the [[elementary symmetric polynomial]]s, that is, in −''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;, ..., (−1)''&lt;sup&gt;n&lt;/sup&gt;a&lt;sub&gt;n&lt;/sub&gt;''. So ''q&lt;sub&gt;t&lt;/sub&gt;''(''z'') has in fact ''real'' coefficients. Furthermore, the degree of ''q&lt;sub&gt;t&lt;/sub&gt;''(''z'') is ''n''(''n''&amp;nbsp;−&amp;nbsp;1)/2&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;''k''−1&lt;/sup&gt;''m''(''n''&amp;nbsp;−&amp;nbsp;1), and ''m''(''n''&amp;nbsp;−&amp;nbsp;1) is an odd number. So, using the induction hypothesis, ''q&lt;sub&gt;t&lt;/sub&gt;'' has at least one complex root; in other words, ''z&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''z&lt;sub&gt;j&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''tz&lt;sub&gt;i&lt;/sub&gt;z&lt;sub&gt;j&lt;/sub&gt;'' is complex for two distinct elements ''i'' and ''j'' from {1, ..., ''n''}. Since there are more real numbers than pairs (''i'', ''j''), one can find distinct real numbers ''t'' and ''s'' such that ''z&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''z&lt;sub&gt;j&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''tz&lt;sub&gt;i&lt;/sub&gt;z&lt;sub&gt;j&lt;/sub&gt;'' and ''z&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''z&lt;sub&gt;j&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''sz&lt;sub&gt;i&lt;/sub&gt;z&lt;sub&gt;j&lt;/sub&gt;'' are complex (for the same ''i'' and ''j''). So, both ''z&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''z&lt;sub&gt;j&lt;/sub&gt;'' and ''z&lt;sub&gt;i&lt;/sub&gt;z&lt;sub&gt;j&lt;/sub&gt;'' are complex numbers. It is easy to check that every complex number has a complex square root, thus every complex polynomial of degree 2 has a complex root by the quadratic formula. It follows that ''z&lt;sub&gt;i&lt;/sub&gt;'' and ''z&lt;sub&gt;j&lt;/sub&gt;'' are complex numbers, since they are roots of the quadratic polynomial ''z''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;−&amp;nbsp; (''z&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''z&lt;sub&gt;j&lt;/sub&gt;'')''z''&amp;nbsp;+&amp;nbsp;''z&lt;sub&gt;i&lt;/sub&gt;z&lt;sub&gt;j&lt;/sub&gt;''.

Joseph Shipman showed in 2007 that the assumption that odd degree polynomials have roots is stronger than necessary; any field in which polynomials of prime degree have roots is algebraically closed (so "odd" can be replaced by "odd prime" and furthermore this holds for fields of all characteristics). For axiomatization of algebraically closed fields, this is the best possible, as there are counterexamples if a single prime is excluded. However, these counterexamples rely on −1 having a square root. If we take a field where −1 has no square root, and every polynomial of degree ''n''&amp;nbsp;∈&amp;nbsp;''I'' has a root, where ''I'' is any fixed infinite set of odd numbers, then every polynomial ''f''(''x'') of odd degree has a root (since {{nowrap|(''x''&lt;sup&gt;2&lt;/sup&gt; + 1)&lt;sup&gt;''k''&lt;/sup&gt;''f''(''x'')}} has a root, where ''k'' is chosen so that {{nowrap|deg(''f'') + 2''k'' ∈ ''I''}}). Mohsen Aliabadi generalized Shipman's result for any field in 2013, proving that the sufficient condition for an arbitrary field (of any characteristic) to be algebraically closed is having a root for any polynomial of prime degree.&lt;ref&gt;M. Aliabadi, M. R. Darafsheh, On maximal and minimal linear matching property, ''Algebra and discrete mathematics'', Volume 15 (2013). Number 2. pp. 174–178&lt;/ref&gt;

Another algebraic proof of the fundamental theorem can be given using [[Galois theory]]. It suffices to show that '''C''' has no proper finite [[field extension]].&lt;ref&gt;A proof of the fact that this suffices can be seen [[Algebraically closed field#The field has no proper finite extension|here]].&lt;/ref&gt; Let ''K''/'''C''' be a finite extension. Since the [[Normal extension#Normal closure|normal closure]] of ''K'' over '''R''' still has a finite degree over '''C''' (or '''R'''), we may assume [[without loss of generality]] that ''K'' is a [[normal extension]] of '''R''' (hence it is a [[Galois extension]], as every algebraic extension of a field of [[characteristic (algebra)|characteristic]] 0 is [[separable extension|separable]]). Let ''G'' be the [[Galois group]] of this extension, and let ''H'' be a [[Sylow theorems|Sylow]] 2-subgroup of ''G'', so that the [[order (group theory)|order]] of ''H'' is a power of 2, and the [[index of a subgroup|index]] of ''H'' in ''G'' is odd. By the [[fundamental theorem of Galois theory]], there exists a subextension ''L'' of ''K''/'''R''' such that Gal(''K''/''L'')&amp;nbsp;=&amp;nbsp;''H''. As [''L'':'''R''']&amp;nbsp;=&amp;nbsp;[''G'':''H''] is odd, and there are no nonlinear irreducible real polynomials of odd degree, we must have ''L''&amp;nbsp;= '''R''', thus [''K'':'''R'''] and [''K'':'''C'''] are powers of 2. Assuming by way of contradiction that [''K'':'''C''']&amp;nbsp;&gt;&amp;nbsp;1, we conclude that the [[p-group|2-group]] Gal(''K''/'''C''') contains a subgroup of index 2, so there exists a subextension ''M'' of '''C''' of degree&amp;nbsp;2. However, '''C''' has no extension of degree&amp;nbsp;2, because every quadratic complex polynomial has a complex root, as mentioned above. This shows that [''K'':'''C'''] = 1, and therefore ''K'' = '''C''', which completes the proof.

===Geometric proofs===
There exists still another way to approach the fundamental theorem of algebra, due to J. M. Almira and A. Romero: by [[Riemannian geometry|Riemannian geometric]] arguments. The main idea here is to prove that the existence of a non-constant polynomial ''p''(''z'') without zeros implies the existence of a [[Flat manifold|flat Riemannian metric]] over the sphere '''S'''&lt;sup&gt;2&lt;/sup&gt;. This leads to a contradiction, since the sphere is not flat.

A Riemannian surface (''M'', ''g'') is said to be flat if its Gaussian curvature, which we denote by ''K&lt;sub&gt;g&lt;/sub&gt;'', is identically null. Now, [[Gauss–Bonnet theorem]], when applied to the sphere '''S'''&lt;sup&gt;2&lt;/sup&gt;, claims that

:&lt;math&gt;\int_{\mathbf{S}^2}K_g=4\pi,&lt;/math&gt;

which proves that the sphere is not flat.

Let us now assume that ''n'' &gt; 0 and 

:&lt;math&gt;p(z) = a_0 + a_1 z + \cdots + a_n z^n \neq 0&lt;/math&gt;

for each complex number ''z''. Let us define 

:&lt;math&gt;p^*(z) = z^n p \left ( \tfrac{1}{z} \right ) = a_0 z^n + a_1 z^{n-1} + \cdots + a_n.&lt;/math&gt;

Obviously, ''p*''(''z'')&amp;nbsp;≠ 0 for all ''z'' in '''C'''. Consider the polynomial ''f''(''z'')&amp;nbsp;=&amp;nbsp;''p''(''z'')''p*''(''z''). Then ''f''(''z'')&amp;nbsp;≠ 0 for each ''z'' in '''C'''. Furthermore,

:&lt;math&gt;f(\tfrac{1}{w}) = p \left (\tfrac{1}{w} \right )p^* \left (\tfrac{1}{w} \right ) = w^{-2n}p^*(w)p(w) = w^{-2n}f(w).&lt;/math&gt;

We can use this functional equation to prove that ''g'', given by

:&lt;math&gt;g=\frac{1}{|f(w)|^{\frac{2}{n}}}\,|dw|^2 &lt;/math&gt;

for ''w'' in '''C''', and

:&lt;math&gt;g=\frac{1}{\left |f\left (\tfrac{1}{w} \right ) \right |^{\frac{2}{n}}}\left |d\left (\tfrac{1}{w} \right ) \right |^2 &lt;/math&gt;

for ''w''&amp;nbsp;∈&amp;nbsp;'''S'''&lt;sup&gt;2&lt;/sup&gt;\{0}, is a well defined Riemannian metric over the sphere '''S'''&lt;sup&gt;2&lt;/sup&gt; (which we identify with the extended complex plane '''C'''&amp;nbsp;∪&amp;nbsp;{∞}).

Now, a simple computation shows that

:&lt;math&gt;\forall w\in\mathbf{C}: \qquad  \frac{1}{|f(w)|^{\frac{1}{n}}} K_g=\frac{1}{n}\Delta \log|f(w)|=\frac{1}{n}\Delta \text{Re}(\log f(w))=0,&lt;/math&gt;

since the real part of an analytic function is harmonic. This proves that ''K&lt;sub&gt;g&lt;/sub&gt;''&amp;nbsp;=&amp;nbsp;0.

==Corollaries==
Since the fundamental theorem of algebra can be seen as the statement that the field of complex numbers is [[algebraically closed field|algebraically closed]], it follows that any theorem concerning algebraically closed fields applies to the field of complex numbers. Here are a few more consequences of the theorem, which are either about the field of real numbers or about the relationship between the field of real numbers and the field of complex numbers:

* The field of complex numbers is the [[algebraic closure]] of the field of real numbers.

* Every polynomial in one variable ''z'' with complex coefficients is the product of a complex constant and polynomials of the form ''z''&amp;nbsp;+&amp;nbsp;''a'' with ''a'' complex.

* Every polynomial in one variable ''x'' with real coefficients can be uniquely written as the product of a constant, polynomials of the form ''x''&amp;nbsp;+&amp;nbsp;''a'' with ''a'' real, and polynomials of the form ''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''ax''&amp;nbsp;+&amp;nbsp;''b'' with ''a'' and ''b'' real and ''a''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;4''b''&amp;nbsp;&lt;&amp;nbsp;0 (which is the same thing as saying that the polynomial ''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''ax''&amp;nbsp;+&amp;nbsp;''b'' has no real roots). (By the [[Abel–Ruffini theorem]], the real numbers ''a'' and ''b'' are not necessarily expressible in terms of the coefficients of the polynomial, the basic arithmetic operations and the extraction of ''n''-th roots.) This implies that the number of non-real complex roots is always even and remains even when counted with their multiplicity.

* Every [[rational function]] in one variable ''x'', with real coefficients, can be written as the sum of a polynomial function with rational functions of the form ''a''/(''x''&amp;nbsp;−&amp;nbsp;''b'')&lt;sup&gt;''n''&lt;/sup&gt; (where ''n'' is a natural number, and ''a'' and ''b'' are real numbers), and rational functions of the form (''ax''&amp;nbsp;+&amp;nbsp;''b'')/(''x''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''cx''&amp;nbsp;+&amp;nbsp;''d'')&lt;sup&gt;''n''&lt;/sup&gt; (where ''n'' is a natural number, and ''a'', ''b'', ''c'', and ''d'' are real numbers such that ''c''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;4''d''&amp;nbsp;&lt;&amp;nbsp;0). A [[corollary]] of this is that every rational function in one variable and real coefficients has an [[elementary function (differential algebra)|elementary]] [[Antiderivative|primitive]].

* Every [[algebraic extension]] of the real field is isomorphic either to the real field or to the complex field.

==Bounds on the zeros of a polynomial==
{{main|Properties of polynomial roots}}
While the fundamental theorem of algebra states a general existence result, it is of some interest, both from the theoretical and from the practical point of view, to have information on the location of the zeros of a given polynomial. The simpler result in this direction is a bound on the modulus: all zeros ζ of a monic polynomial &lt;math&gt;z^n+a_{n-1}z^{n-1}+\cdots+a_1z +a_0&lt;/math&gt; satisfy an inequality |ζ| ≤ ''R''&lt;sub&gt;∞&lt;/sub&gt;, where

:&lt;math&gt;R_{\infty}:= 1+\max\{|a_0|,\ldots,|a_{n-1}|\}. &lt;/math&gt;

Notice that, as stated, this is not yet an existence result but rather an example of what is called an [[a priori and a posteriori|a priori]] bound: it says that ''if there are solutions'' then they lie inside the closed disk of center the origin and radius ''R''&lt;sub&gt;∞&lt;/sub&gt;. However, once coupled with the fundamental theorem of algebra it says that the disk contains in fact at least one solution. More generally, a bound can be given directly in terms of any [[p-norm]] of the ''n''-vector of coefficients &lt;math&gt;a:=( a_0, a_1, \ldots, a_{n-1}),&lt;/math&gt; that is |ζ| ≤ ''R&lt;sub&gt;p&lt;/sub&gt;'', where ''R&lt;sub&gt;p&lt;/sub&gt;'' is precisely the ''q''-norm of the 2-vector &lt;math&gt;(1, \|a\|_p),&lt;/math&gt; ''q'' being the conjugate exponent of ''p'', &lt;math&gt;\tfrac{1}{p} + \tfrac{1}{q} =1,&lt;/math&gt; for any 1 ≤ ''p'' ≤ ∞. Thus, the modulus of any solution is also bounded by

:&lt;math&gt; R_1:= \max\left \{ 1 , \sum_{0\leq k&lt;n} |a_k|\right \},&lt;/math&gt;
:&lt;math&gt; R_p:= \left[ 1 + \left(\sum_{0\leq k&lt;n}|a_k|^p\right )^{\frac{q}{p}}\right ]^{\frac{1}{q}},&lt;/math&gt;

for 1 &lt; ''p'' &lt; ∞, and in particular

:&lt;math&gt; R_2:= \sqrt{\sum_{0\leq k\leq n} |a_k|^2 }&lt;/math&gt;

(where we define ''a&lt;sub&gt;n&lt;/sub&gt;'' to mean 1, which is reasonable since 1 is indeed the ''n''-th coefficient of our polynomial). The case of a generic polynomial of degree ''n'', 

:&lt;math&gt;P(z):= a_n z^n+a_{n-1}z^{n-1}+\cdots+a_1z +a_0,&lt;/math&gt;

is of course reduced to the case of a monic, dividing all coefficients by ''a&lt;sub&gt;n&lt;/sub&gt;'' ≠ 0. Also, in case that 0 is not a root, i.e. ''a''&lt;sub&gt;0&lt;/sub&gt; ≠ 0, bounds from below on the roots ζ follow immediately as bounds from above on &lt;math&gt;\tfrac{1}{\zeta}&lt;/math&gt;, that is, the roots of 

:&lt;math&gt;a_0 z^n+a_1z^{n-1}+\cdots+a_{n-1}z +a_n.&lt;/math&gt; 

Finally, the distance &lt;math&gt;|\zeta-\zeta_0|&lt;/math&gt; from the roots ζ to any point &lt;math&gt;\zeta_0&lt;/math&gt; can be estimated from below and above, seeing &lt;math&gt;\zeta-\zeta_0&lt;/math&gt; as zeros of the polynomial &lt;math&gt;P(z+\zeta_0)&lt;/math&gt;, whose coefficients are the [[Taylor expansion]] of ''P''(''z'') at &lt;math&gt;z=\zeta_0.&lt;/math&gt;

Let ζ be a root of the polynomial 

:&lt;math&gt;z^n+a_{n-1}z^{n-1}+\cdots+a_1z +a_0;&lt;/math&gt;

in order to prove the inequality |ζ| ≤ ''R&lt;sub&gt;p&lt;/sub&gt;'' we can assume, of course, |ζ| &gt; 1. Writing the equation as 

:&lt;math&gt;-\zeta^n=a_{n-1}\zeta^{n-1}+\cdots+a_1\zeta+a_0,&lt;/math&gt; 

and using the [[Hölder's inequality]] we find 

:&lt;math&gt;|\zeta|^n\leq \|a\|_p \left \| \left (\zeta^{n-1},\ldots,\zeta, 1 \right ) \right \|_q.&lt;/math&gt;

Now, if ''p'' = 1, this is 

:&lt;math&gt;|\zeta|^n\leq\|a\|_1\max \left \{|\zeta|^{n-1},\ldots,|\zeta|,1 \right \} =\|a\|_1|\zeta|^{n-1},&lt;/math&gt;

thus 

:&lt;math&gt;|\zeta|\leq \max\{1, \|a\|_1\}.&lt;/math&gt; 

In the case 1 &lt; ''p'' ≤ ∞, taking into account the summation formula for a [[geometric progression]], we have

:&lt;math&gt;|\zeta|^n\leq \|a\|_p \left(|\zeta|^{q(n-1)}+\cdots+|\zeta|^q +1\right)^{\frac{1}{q}}=\|a\|_p \left(\frac{|\zeta|^{qn}-1}{|\zeta|^q-1}\right)^{\frac{1}{q}}\leq\|a\|_p \left(\frac{|\zeta|^{qn}}{|\zeta|^q-1}\right)^{\frac{1}{q}},&lt;/math&gt;

thus 

:&lt;math&gt;|\zeta|^{nq}\leq \|a\|_p^q \frac{|\zeta|^{qn}}{|\zeta|^q-1}&lt;/math&gt; 

and simplifying, 

:&lt;math&gt;|\zeta|^q\leq 1+\|a\|_p^q.&lt;/math&gt; 

Therefore 

:&lt;math&gt;|\zeta|\leq \left \| \left (1,\|a\|_p \right ) \right \|_q=R_p &lt;/math&gt; 

holds, for all 1 ≤ ''p'' ≤ ∞.

==References==
{{Reflist}}

===Historic sources===
*{{Citation|last = Cauchy|first = Augustin-Louis|author-link = Augustin-Louis Cauchy|publication-date = 1992|year = 1821|title = Cours d'Analyse de l'École Royale Polytechnique, 1&lt;sup&gt;ère&lt;/sup&gt; partie: Analyse Algébrique|url = http://gallica.bnf.fr/ark:/12148/bpt6k29058v|place = Paris|publisher = Éditions Jacques Gabay|isbn = 2-87647-053-5}} (tr. Course on Analysis of the [[École Polytechnique|Royal Polytechnic Academy]], part 1: Algebraic Analysis)
* {{citation|last = Euler|first = Leonhard|author-link = Leonhard Euler|year = 1751|title = Recherches sur les racines imaginaires des équations|periodical = Histoire de l'Académie Royale des Sciences et des Belles-Lettres de Berlin|publication-place = Berlin|volume = 5|pages = 222–288|url = http://bibliothek.bbaw.de/bbaw/bibliothek-digital/digitalequellen/schriften/anzeige/index_html?band=02-hist/1749&amp;seite:int=228}}. English translation: {{citation|last = Euler|first = Leonhard|author-link = Leonhard Euler|year = 1751|title = Investigations on the Imaginary Roots of Equations|periodical = Histoire de l'Académie Royale des Sciences et des Belles-Lettres de Berlin|publication-place = Berlin|volume = 5|pages = 222–288|url = http://eulerarchive.maa.org/docs/translations/E170en.pdf|format=PDF}}
* {{citation|last = Gauss|first = Carl Friedrich|author-link = Carl Friedrich Gauss|year = 1799|title = Demonstratio nova theorematis omnem functionem algebraicam rationalem integram unius variabilis in factores reales primi vel secundi gradus resolvi posse|place = [[Helmstedt]]|publisher = C.&amp;nbsp;G.&amp;nbsp;Fleckeisen}} (tr. New proof of the theorem that every integral rational algebraic function of one variable can be resolved into real factors of the first or second degree).
* {{Citation|last=Gauss|first=Carl Friedrich|year=1866|title=Carl Friedrich Gauss Werke|publisher=Königlichen Gesellschaft der Wissenschaften zu Göttingen|volume=Band III|url={{Google books|WFxYAAAAYAAJ|Werke: Analysis|plainurl=yes}}}}
*#{{Google books|WFxYAAAAYAAJ|Demonstratio nova theorematis omnem functionem algebraicam rationalem integram unius variabilis in factores reales primi vel secundi gradus resolvi posse (1799), pp.1-31.|page=1}} - first proof.
*#{{Google books|WFxYAAAAYAAJ|Demonstratio nova altera theorematis omnem functionem algebraicam rationalem integram unius variabilis in factores reales primi vel secundi gradus resolvi posse (1815 Dec), pp.32-56.|page=32}} - second proof.
*#{{Google books|WFxYAAAAYAAJ|Theorematis de resolubilitate functionum algebraicarum integrarum in factores reales demonstratio tertia Supplementum commentationis praecedentis (1816 Jan), pp.57-64.|page=57}} - third proof.
*#{{Google books|WFxYAAAAYAAJ|Beiträge zur Theorie der algebraischen Gleichungen (1849 Juli), pp.71-103.|page=71}} - fourth proof.
* {{citation|last = Kneser|first = Hellmuth|author-link = Hellmuth Kneser|year = 1940|title = Der Fundamentalsatz der Algebra und der Intuitionismus|url = http://www-gdz.sub.uni-goettingen.de/cgi-bin/digbib.cgi?PPN266833020_0046|periodical = Mathematische Zeitschrift|volume = 46|pages = 287–302|issn = 0025-5874|doi = 10.1007/BF01181442}} (The Fundamental Theorem of Algebra and [[Intuitionism]]).
* {{citation|last = Kneser|first = Martin|year = 1981|title = Ergänzung zu einer Arbeit von Hellmuth Kneser über den Fundamentalsatz der Algebra|url = http://www-gdz.sub.uni-goettingen.de/cgi-bin/digbib.cgi?PPN266833020_0177|periodical = Mathematische Zeitschrift|volume = 177|pages = 285–287|issn = 0025-5874|doi = 10.1007/BF01214206|issue = 2}} (tr. An extension of a work of [[Hellmuth Kneser]] on the Fundamental Theorem of Algebra).
* {{citation|last = Ostrowski|first = Alexander | author-link = Alexander Ostrowski | year = 1920 | chapter = Über den ersten und vierten Gaußschen Beweis des Fundamental-Satzes der Algebra | title = Carl Friedrich Gauss ''Werke'' Band X Abt. 2 | url = http://gdz.sub.uni-goettingen.de/dms/load/img/?PPN=PPN236019856&amp;DMDID=dmdlog53}} (tr. On the first and fourth Gaussian proofs of the Fundamental Theorem of Algebra).
* {{cite conference|last=Weierstraß|first= Karl|authorlink=Karl Weierstrass|title=Neuer Beweis des Satzes, dass jede ganze rationale Function einer Veränderlichen dargestellt werden kann als ein Product aus linearen Functionen derselben Veränderlichen|booktitle=Sitzungsberichte der königlich preussischen Akademie der Wissenschaften zu Berlin|pages = 1085–1101|year=1891|url=http://bibliothek.bbaw.de/bibliothek-digital/digitalequellen/schriften/anzeige?band=10-sitz/1891-2&amp;seite:int=00000565}} (tr. New proof of the theorem that every integral rational function of one variable can be represented as a product of linear functions of the same variable).

===Recent literature===
* {{citation|last = Almira|first = J.M.|last2 = Romero|first2 = A. |year = 2007|title = Yet another application of the Gauss-Bonnet Theorem for the sphere|periodical = [[Bulletin of the Belgian Mathematical Society]]|volume = 14|pages = 341–342| url = http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?handle=euclid.bbms/1179839226&amp;view=body&amp;content-type=pdf_1}}
* {{citation|last = Almira|first = J.M.|last2 = Romero|first2 = A. |year = 2012|title = Some Riemannian geometric proofs of the Fundamental Theorem of Algebra|periodical = Differential Geometry - Dynamical Systems|volume = 14|pages = 1–4| url = http://www.mathem.pub.ro/dgds/v14/D14-al.pdf}}
* {{citation|last = de Oliveira|first = O.R.B.|year = 2011|title = The Fundamental Theorem of Algebra: an elementary and direct proof|periodical = Mathematical Intelligencer|volume = 33|issue = 2|pages = 1–2| url = https://dx.doi.org/10.1007/s00283-011-9199-2|doi=10.1007/s00283-011-9199-2}}
* {{citation|last = de Oliveira|first = O.R.B.|year = 2012|title = The Fundamental Theorem of Algebra: from the four basic operations|periodical = American Mathematical Monthly|volume = 119|issue = 9|pages = 753–758| url = https://dx.doi.org/10.4169/amer.math.monthly.119.09.753|doi=10.4169/amer.math.monthly.119.09.753|arxiv = 1110.0165}}
* {{citation|last = Fine|first = Benjamin|last2 = Rosenberger|first2 = Gerhard|title = The Fundamental Theorem of Algebra|publisher = [[Springer Science+Business Media|Springer-Verlag]]|place = Berlin|year = 1997|isbn = 978-0-387-94657-3|series = [[Undergraduate Texts in Mathematics]]|mr = 1454356}}
* {{citation|last = Gersten|first = S.M.|last2 = Stallings|first2 = John R.|year = 1988|title = On Gauss's First Proof of the Fundamental Theorem of Algebra|jstor = 2047574|periodical = Proceedings of the AMS|volume = 103|issue = 1|pages = 331–332|issn = 0002-9939|doi = 10.2307/2047574}}
* {{citation|last = Gilain|first = Christian|year = 1991|title = Sur l'histoire du théorème fondamental de l'algèbre: théorie des équations et calcul intégral|periodical = Archive for History of Exact Sciences|volume = 42|issue = 2|pages = 91–136|issn = 0003-9519|doi = 10.1007/BF00496870}} (tr. On the history of the fundamental theorem of algebra: [[theory of equations]] and [[integral calculus]].)
* {{citation|last = Netto|first = Eugen|last2 = Le Vavasseur|first2 = Raymond|author-link = Eugen Netto|year = 1916|chapter = Les fonctions rationnelles §80–88: Le théorème fondamental|editor-last = Meyer|editor-first = François|editor2-last = Molk|editor2-first = Jules|title = Encyclopédie des Sciences Mathématiques Pures et Appliquées, tome&amp;nbsp;I, vol.&amp;nbsp;2|publication-date = 1992|publisher = Éditions Jacques Gabay|isbn = 2-87647-101-9}} (tr. The rational functions §80–88: the fundamental theorem).
* {{citation|last = Remmert|first = Reinhold|author-link = Reinhold Remmert|year = 1991|chapter = The Fundamental Theorem of Algebra|editor-last = Ebbinghaus|editor-first = Heinz-Dieter|editor2-last = Hermes|editor2-first = Hans|editor3-last = Hirzebruch|editor3-first = Friedrich|title = Numbers|series = Graduate Texts in Mathematics 123|editor3-link = Friedrich Hirzebruch|place = Berlin|publisher = [[Springer Science+Business Media|Springer-Verlag]]|isbn = 978-0-387-97497-2}}
* {{citation|last = Shipman|first = Joseph|year = 2007|title = Improving the Fundamental Theorem of Algebra|periodical = Mathematical Intelligencer|volume = 29|issue = 4|pages = 9–14|doi=10.1007/BF02986170|issn = 0343-6993}}
* {{citation|last = Smale|first = Steve|year = 1981|title=The Fundamental Theorem of Algebra and Complexity Theory|author-link = Stephen Smale|periodical = Bulletin (new series) of the American Mathematical Society|volume = 4 | issue = 1}} [http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.bams/1183547848]
* {{citation|last= Smith|first = David Eugene|author-link = David Eugene Smith|title = A Source Book in Mathematics|publisher = [[Dover Publications|Dover]]|isbn = 0-486-64690-4|year = 1959}}
* {{citation|last = Smithies|first = Frank|year = 2000|title = A forgotten paper on the fundamental theorem of algebra|periodical = Notes &amp; Records of the Royal Society|volume = 54|issue = 3|pages = 333–341|issn = 0035-9149|doi = 10.1098/rsnr.2000.0116}}
* {{citation|last = Taylor|first = Paul|date = 2 June 2007|title = Gauss's second proof of the fundamental theorem of algebra|url = http://www.paultaylor.eu/misc/gauss-web.php}} - English translation of Gauss's second proof.
* {{citation | last = van der Waerden | first = Bartel Leendert | author-link = Bartel Leendert van der Waerden | title = Algebra | volume = I | edition = 7th | year = 2003 | publisher = [[Springer Science+Business Media|Springer-Verlag]] | isbn = 0-387-40624-7}}

{{Wikisourcelang|la|Demonstratio nova theorematis omnem functionem algebraicam rationalem integram unius variabilis in factores reales primi vel secundi gradus resolvi posse|Gauss's first proof}}

==External links==
* [http://www.encyclopediaofmath.org/index.php/Algebra,_fundamental_theorem_of ''Algebra, fundamental theorem of'' at Encyclopaedia of Mathematics]
* [http://www.cut-the-knot.org/do_you_know/fundamental2.shtml Fundamental Theorem of Algebra]&amp;nbsp;— a collection of proofs
* D. J. Velleman: ''The Fundamental Theorem of Algebra: A Visual Approach'', [http://www.cs.amherst.edu/~djv/ PDF (unpublished paper)], visualisation of d'Alembert's, Gauss's and the winding number proofs
* [http://www.ams.org/notices/200806/tx080600666p.pdf ''From the Fundamental Theorem of Algebra to Astrophysics: A "Harmonious" Path'']
* {{Google books|g3VaAAAAcAAJ|Gauss's first proof (in Latin)}}
* {{Google books|Svc7AQAAMAAJ|Gauss's first proof (in Latin)}}
* [[Mizar system]] proof: http://mizar.org/version/current/html/polynom5.html#T74

{{Fundamental theorems}}

{{DEFAULTSORT:Fundamental Theorem Of Algebra}}
[[Category:Articles containing proofs]]
[[Category:Field theory]]
[[Category:Fundamental theorems|Algebra]]
[[Category:Theorems in algebra]]
[[Category:Theorems in complex analysis]]</text>
      <sha1>0l4rgcu5xesjzwapumkp3ig2bdjgayw</sha1>
    </revision>
  </page>
  <page>
    <title>Fuzzy-trace theory</title>
    <ns>0</ns>
    <id>27864034</id>
    <revision>
      <id>855747767</id>
      <parentid>853576016</parentid>
      <timestamp>2018-08-20T15:19:39Z</timestamp>
      <contributor>
        <ip>200.131.56.8</ip>
      </contributor>
      <comment>added link to Charles Brainerd's wiki bio</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="58246">'''Fuzzy-trace theory''' ('''FTT''') is a theory of [[cognition]] originally proposed by [[Charles Brainerd]] and [[Valerie F. Reyna]]&lt;ref&gt;{{cite journal |last1= Reyna |first1= V.F. |last2= Brainerd |first2= C.J. |title= Fuzzy-trace theory: An interim synthesis |journal= Learning and Individual Differences |date= 1995 |volume= 7 |pages= 1–75 |doi= 10.1016/1041-6080(95)90031-4 }}&lt;/ref&gt; that draws upon dual-trace{{clarify|date=October 2017}} conceptions to predict and explain cognitive phenomena, particularly in the memory and reasoning domains.  The theory has been used in areas such as [[cognitive psychology]], [[developmental psychology|human development]], and [[social psychology]] to explain, for instance, [[Confabulation|false memory]]&lt;ref name= "Fuzzy-trace theory and false memory"&gt;{{cite journal |last1= Brainerd |first1= C.J. |last2= Reyna |first2= V.F. |title= Fuzzy-trace theory and false memory |journal= Current Directions in Psychological Science |date= 2002 |volume= 11 |pages= 164–169 |doi= 10.1111/1467-8721.00192 }}&lt;/ref&gt; and its development,&lt;ref name="DPDR"&gt;{{cite book |last1= Gomes |first1= C.F.A. |last2= Brainerd |first2= C.J. |editor1-first= J. |editor1-last= Gauffroy |editor2-first= P. |editor2-last= Barrouillet |title= The Development of Thinking and Reasoning |publisher= Psychology Press |date= 2012 |chapter= Dual processes in the development of reasoning: The memory side of the story }}&lt;/ref&gt; [[probability]] judgments,&lt;ref&gt;{{cite book |last1= Reyna |first1= V.F. |last2= Brainerd |first2= C. J. |editor1-first= G. |editor1-last= Wright |editor2-first= P. |editor2-last= Ayton |title= Subjective Probability |publisher= Wiley |date= 1994 |pages= 239–272 |chapter= The origins of probability judgment: A review of data and theories }}&lt;/ref&gt; medical decision making,&lt;ref name="MDM_28_6"&gt;{{cite journal |last= Reyna |first= V.F. |title= A theory of medical decision making and health: Fuzzy trace theory |journal= Medical Decision Making |date= 2008 |volume= 28 |issue= 6 |pages= 850–865 |doi= 10.1177/0272989x08327066 |pmid= 19015287 |pmc= 2617718 }}&lt;/ref&gt; risk perception and estimation, and biases and fallacies in [[decision making]].&lt;ref name="Dual processes in decision making and developmental neuroscience"&gt;{{cite journal|last=Reyna|first=V.F.|author2=Brainerd, C.J.|title=Dual processes in decision making and developmental neuroscience: A fuzzy-trace model|journal=Developmental Review|year=2011|volume=31|issue=2|pages=180–206|doi=10.1016/j.dr.2011.07.004|pmc=3214669}}&lt;/ref&gt;&lt;ref name="Fuzzy-trace theory"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V.F.|title=Fuzzy-trace theory: Dual processes in memory, reasoning, and cognitive neuroscience|journal=Advances in Child Development and Behavior|year=2002|volume=28|pages=41–100|doi=10.1016/S0065-2407(02)80062-3}}&lt;/ref&gt;

==History==
FTT was initially proposed in the 1990s as an attempt to unify findings from the [[memory]] and reasoning domains that could not be predicted or explained by earlier approaches to cognition and its development (e.g., [[constructivism (learning theory)|constructivism]]&lt;ref&gt;{{cite journal |last1= Bransford |first1= J.D. |last2= Franks |first2=J.J. |title= The abstraction of linguistic ideas |journal= Cognitive Psychology |date= 1971 |volume= 2 |issue= 4 |pages= 331–350 |doi= 10.1016/0010-0285(71)90019-3 }}&lt;/ref&gt;&lt;ref&gt;{{cite book |last1= Piaget |first1= J |last2= Inhelder |first2= B |title= Memory and Intelligence |date= 1973 |publisher= Basic Books |location= New York |isbn= 0-465-04445-X }}&lt;/ref&gt;  and information processing). One of such challenges was the statistical independence between memory and reasoning, that is, memory for background facts of problem situations is often unrelated to accuracy in reasoning tasks.&lt;ref&gt;{{cite journal |last1= Hastie |first1= R. |last2= Park |first2= B. |title= The relationship between memory and judgment depends on whether the judgment task is memory-based or on-line |journal= Psychological Review |date= 1986 |volume= 93 |issue= 3 |pages= 258–268 |doi=  10.1037/0033-295x.93.3.258}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1= Brainerd |first1= C.J. |last2= Kingma |first2= J. |title= Do children have to remember to reason? A fuzzy-trace theory of transitivity development |journal= Developmental Review |date= 1984 |volume= 4 |issue= 4 |pages= 311–377 |doi= 10.1016/0273-2297(84)90021-2 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1= Brainerd |first1= C.J. |last2= Kingma |first2= J. |title= On the independence of short-term memory and working memory in cognitive development |journal= Cognitive Psychology |date= 1985 |volume= 17 |issue= 2 |pages= 210–247 |doi=10.1016/0010-0285(85)90008-8 }}&lt;/ref&gt; Such findings called for a rethinking of the memory-reasoning relation, which in FTT took the form of a dual-process theory linking basic concepts from [[psycholinguistic]] and [[Gestalt psychology|Gestalt theory]] to memory and reasoning. More specifically, FTT posits that people form two types of mental representations about a past event, called verbatim and gist traces. Gist traces are fuzzy representations of a past event (e.g., its bottom-line meaning), hence the name fuzzy-trace theory, whereas verbatim traces are detailed representations of a past event. Although people are capable of processing both verbatim and gist information, they prefer to reason with gist traces rather than verbatim. This implies, for example, that even if people are capable of understanding ratio concepts like probabilities and prevalence rates, which are the standard for the presentation of health- and risk-related data, their choice in decision situations will usually be governed by the bottom-line meaning of it (e.g., "the risk is high" or "the risk is low"; "the outcome is bad" or "the outcome is good") rather than the actual numbers.&lt;ref name="MDM_28_6" /&gt; More importantly, in FTT, memory-reasoning independence can be explained in terms of preferred modes of processing when one performs a memory task (e.g., retrieval of verbatim traces) relative to when one performs a reasoning task (e.g., preference for reasoning with gist traces).&lt;ref&gt;{{cite journal |last1= Brainerd |first1= C.J. |last2= Reyna |first2= V.F. |title= Explaining "memory free" reasoning |journal= Psychological Science |date= 1992 |volume= 3 |issue= 6 |pages= 332–339 |doi= 10.1111/j.1467-9280.1992.tb00042.x }}&lt;/ref&gt;

In 1999, a similar approach was applied to human vision.&lt;ref&gt;{{cite journal |last1= Barghout - Stein |first1= L. |first2= C. W. |last2= Tyler |first3= S. A. |last3= Klein |title= Are local filtering and contour integration complementary visual process |journal= Investigative Ophthalmology &amp; Visual Science |volume= 40 |issue= 4 |location= 9650 Rockville Pike, Bethesda, MD 20814-3998 |publisher= Assoc Research Vision Ophthalmology |date= 1999 }}&lt;/ref&gt;  It suggested that human vision has two types of processing: one that aggregates local spatial receptive fields, and one that parses the local receptive field. People used prior experience, gists, to decide which process dominates a perceptual decision.  The work attempted to link Gestalt theory and [[psychophysics]] (i.e., independent linear filters).  This theory was further developed into fuzzy image processing&lt;ref&gt;{{cite book |last= Barghout-Stein |first= Lauren |title= How Global Perceptual Context Changes Local Contrast Processing |publisher= University of California |location= Berkeley |date= 2003 }}&lt;/ref&gt;&lt;ref&gt;{{cite patent |invent1= Barghout, Lauren |invent2= Lee, Lawrence W. |title= Perceptual information processing system |assign1= Paravue |country= US |status= application |number= 2004059754 }}&lt;/ref&gt; and used in information processing technology and edge detection.&lt;ref&gt;{{cite patent |invent1= Larcheveque, Jean-Marie H. |invent2= et al. |title= Structural editing with schema awareness |country= US |number= 7496837 |assign1= Google |pubdate= 2009-02-24 }}&lt;/ref&gt;&lt;ref&gt;{{cite patent |title= System and method for designing electronic forms and hierarchical schemas |country= US |number= 7275216 |assign1= Microsoft }}&lt;/ref&gt;&lt;ref&gt;{{cite patent |title= Techniques for enhancing the functionality of file systems |assign1= Hitache  |country= US |number= 7853822 }}&lt;/ref&gt;

==Memory==
FTT posits two types of memory processes (verbatim and gist) and, therefore, it is often referred to as a [[dual process theory]] of memory. According to FTT, retrieval of verbatim traces (recollective retrieval) is characterized by mental reinstatement of the contextual features of a past event, whereas retrieval of gist traces (nonrecollective retrieval) is not. In fact, gist processes form representations of an event's [[semantic]] features rather than its surface details, the latter being a property of verbatim processes. In the memory domain, FTT's notion of verbatim and gist representations has been influential in explaining true memories (i.e., memories about events that actually happened) as well as false memories (i.e., memories about events that never happened).&lt;ref name="Fuzzy-trace theory and false memory" /&gt;&lt;ref name="Fuzzy trace theory and memory development"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V.F.|title=Fuzzy trace theory and memory development|journal=Developmental Review|year=2004|volume=24|issue=4|pages=396–439|doi=10.1016/j.dr.2004.08.005}}&lt;/ref&gt; The following five principles have been used to predict and explain true and false memory phenomena:

===Principles===

====Process independence====

=====Parallel storage=====
The principle of parallel storage asserts that the encoding and storage of verbatim and gist information operate in parallel rather than in a [[Serial memory processing|serial fashion]]. For instance, suppose that a person is presented with the word "apple" in red color.  On the one hand, according to the principle of parallel storage of verbatim and gist traces, verbatim features of the target item (e.g., the word was apple, it was presented in red, printed in boldface and italic, and all but the first letter were presented in lowercase) and gist features (e.g., the word was a type of fruit) would be encoded and stored simultaneously via distinct pathways.  Conversely, if verbatim and gist traces are stored in a serial fashion, then gist features of the target item (the word was a type of fruit) would be derived from its verbatim features and, therefore, the formation of gist traces would depend on the encoding and storage of verbatim traces.  The latter idea was often assumed by early memory models.&lt;ref name="A retrieval model for both recognition and recall"&gt;{{cite journal|last=Gillund|first=G|author2=Shiffrin, R.M.|title=A retrieval model for both recognition and recall|journal=Psychological Review|year=1984|volume=91|issue=1|pages=1–67|doi=10.1037/0033-295x.91.1.1}}&lt;/ref&gt;&lt;ref name="Judgment of frequency and recognition memory in a multiple-trace memory model"&gt;{{cite journal|last=Hintzman|first=D.I.|title=Judgment of frequency and recognition memory in a multiple-trace memory model|journal=Psychological Review|year=1988|volume=95|issue=4|pages=528–551|doi=10.1037/0033-295x.95.4.528}}&lt;/ref&gt;&lt;ref name="A theory for storage and retrieval of items and associative information"&gt;{{cite journal|last=Murdock|first=B.B.|title=A theory for storage and retrieval of items and associative information|journal=Psychological Review|year=1982|volume=89|issue=6|pages=609–626|doi=10.1037/0033-295x.89.6.609}}&lt;/ref&gt; However, despite the intuitive appeal of the serial processing approach, research suggests that the encoding and storage of gist traces do not depend on verbatim ones.  Several studies have converged on the finding that the meaning of target items is encoded independently of, and even prior to, the encoding of the surface form of the same items.&lt;ref name="Effect of meaning on letter detection"&gt;{{cite journal|last=Moravcski|first=J.E.|author2=Healy, A.F.|title=Effect of meaning on letter detection|journal=Journal of Experimental Learning, Memory, and Cognition|year=1995|volume=21|issue=1|pages=82–95|doi=10.1037/0278-7393.21.1.82}}&lt;/ref&gt;&lt;ref name="Replicable unconscious semantic priming"&gt;{{cite journal|last=Draine|first=S.C.|author2=Greenwald, A.G.|title=Replicable unconscious semantic priming|journal=Journal of Experimental Psychology|year=1998|volume=127|issue=3|pages=286–303|doi=10.1037/0096-3445.127.3.286}}&lt;/ref&gt;&lt;ref name="The judgment of previous occurrence"&gt;{{cite journal|last=Mandler|first=G.|title=The judgment of previous occurrence|journal=Psychological Review|year=1980|volume=87|issue=3|pages=252–271|doi=10.1037/0033-295x.87.3.252}}&lt;/ref&gt;&lt;ref name="Recognition memory errors produced by implicit activation"&gt;{{cite journal|last=Wallace|first=W.P.|author2=Steward, M.T.|author3=Malcone, C.P.|title=Recognition memory errors produced by implicit activation of word candidates during the processing of spoken words|journal=Journal of Memory and Language|year=1995|volume=34|issue=4|pages=417–439|doi=10.1006/jmla.1995.1019}}&lt;/ref&gt;&lt;ref name="Are false recognitions influenced by precognition processing"&gt;{{cite journal|last=Wallace|first=W.P.|author2=Stewart, M.T.|author3= Schaffer, T.R.|author4= Barry, C.R.|title=Are false recognitions influenced by precognition processing?|journal=Journal of Psychology: Learning, Memory, and Cognition|year=1998|volume=24|issue=2|pages=299–315|doi=10.1037/0278-7393.24.2.299}}&lt;/ref&gt; Ankrum and Palmer,&lt;ref name="The perception and memory of objects and their parts"&gt;{{cite journal|last=Ankrum|first=C|author2=Palmer, J.|title=The perception and memory of objects and their parts|journal=Bulletin of the Psychonomic Society|year=1985|volume=27|issue=6|pages=496}}&lt;/ref&gt; for example, found that when participants are presented with a familiar word (e.g., apple) for a very brief period (100 milliseconds), they are able to identify the word itself ("was it apple?") better than its letters ("did it contain the letter L?").

=====Dissociated retrieval=====
Similar to the principle of parallel storage, retrieval of verbatim and gist traces also occur via dissociated pathways. According to the principle of dissociated retrieval, recollective and nonrecollective retrieval processes are independent of each other.  Consequently, this principle allows verbatim and gist processes to be differentially influenced by factors such as the type of retrieval cues and the availability of each form of representation. In connection with [[Endel Tulving#Encoding Specificity Principle|Tulving's encoding specificity principle]], items that were actually presented in the past are better cues for verbatim traces than items that were not. Similarly, items that were not presented in the past but preserve the meaning of presented items are usually better cues for gist traces. Suppose, for example, that subjects of an experiment are presented with a word list containing several dog breeds, such as poodle, bulldog, greyhound, doberman, beagle, collie, boxer, mastif, husky, and terrier.  During a recognition test, the words poodle, spaniel, and chair are presented. According to the principle of dissociated retrieval, retrieval of verbatim and gist traces does not depend on each other and, therefore, different types of test probes might serve as better cues to one type of trace than another. In this example, test probes such as poodle (targets, or studied items) will be better retrieval cues for verbatim traces than gist, whereas test probes such as spaniel (related distractors, non-studied items but related to targets) will be better retrieval cues for gist traces than verbatim.  Chair, on the other hand, would neither be a better cue for verbatim traces nor for gist traces because it was not presented and is not related to dogs.  If verbatim and gist processes were dependent, then factors that affect one process would also affect the other in the same direction. However, several experiments showing, for example, differential forgetting rates between memory for the surface details and memory for the bottom-line meaning of past events&lt;ref name="Surface information loss in comprehension"&gt;{{cite journal|last=Gernsbacher|first=M.A.|title=Surface information loss in comprehension|journal=Cognitive Psychology|year=1985|volume=17|issue=3|pages=324–363|doi=10.1016/0010-0285(85)90012-X|pmc=4191867}}&lt;/ref&gt;&lt;ref name="Sentence memory"&gt;{{cite journal|last=Kintsch|first=W.|author2=Welsch, D.|author3= Schmalhofer, F.|author4= Zimny, S.|title=Sentence memory: A theoretical analysis|journal=Journal of Memory and Language|year=1990|volume=29|issue=2|pages=133–159|doi=10.1016/0749-596x(90)90069-C}}&lt;/ref&gt;&lt;ref name="Forgetting of verbatim information in discourse"&gt;{{cite journal|last=Murphy|first=G.L.|author2=Shapiro, A.M.|title=Forgetting of verbatim information in discourse|journal=Memory and Cognition|year=1994|volume=22|issue=1|pages=85–94|doi=10.3758/BF03202764}}&lt;/ref&gt;&lt;ref name="Reasoning, remembering, and their relationship"&gt;{{cite book|last=Reyna|first=V.F.|editor1-first=M.L.|editor1-last=Howe|editor2-first=C.J.|editor2-last=Brainerd|editor3-first=V.F.|editor3-last=Reyna|title=Development of long-term retention|year=1992|publisher=Springer-Verlag|location=NY|pages=103–127|chapter=Reasoning, remembering, and their relationship: Social, cognitive, and developmental issues|isbn=0-387-97734-1}}&lt;/ref&gt;  favor the notion of dissociated retrieval of verbatim and gist traces.&lt;ref&gt;{{cite book|last=Brainerd|first=C.J.|author2=Reyna, V.F.|title=The Science of False Memory|year=2005|publisher=Oxford University Press|location=New York|isbn=0-19-515405-3}}&lt;/ref&gt; In the case of forgetting rates, those experiments have shown that, over time, verbatim traces become inaccessible at a faster rate than gist traces. Brainerd, Reyna, and Kneer,&lt;ref name="False-recognition reversal"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V.F.|author3=Kneer, R.|title=False-recognition reversal: When is similarity distinctive?|journal=Journal of Memory and Language|year=1995|volume=34|issue=2|pages=157–185|doi=10.1006/jmla.1995.1008}}&lt;/ref&gt; for instance, found that delay drives true recognition rates (supported by both verbatim and gist traces) and false recognition rates (supported by gist and suppressed by verbatim traces) in opposite directions, namely true memory decays over time while false memory increases.

====Opponent processes in false memory====
The principle of opponent processes describes the interaction between verbatim and gist processes in creating true and false memories. Whereas true memory is supported by both verbatim and gist processes, false memory is supported by gist processes and suppressed by verbatim processes.  In other words, verbatim and gist processes work in opposition to one another when it comes to false memories.&lt;ref name = "Fuzzy-trace theory and false memory" /&gt;  Suppose, for example, that one is presented with a word list such as lemon, apple, pear, and citrus. During a recognition test, the items lemon (target), orange (related distractor), and fan (unrelated distractor) are shown. In this case, retrieval of a gist trace (fruits) supports acceptance of both test probes lemon (true memory) and orange (false memory), whereas retrieval of a verbatim trace (lemon) only supports acceptance of the test probe lemon.  In addition, retrieval of an exclusory verbatim trace ("I saw only the words lemon, apple, pear, and citrus") suppresses acceptance of false but related items such as orange through an operation known as recollection rejection.&lt;ref name="Recollection rejection"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V.F.|author3= Wright, R.|author4= Mojardin, A.H.|title=Recollection rejection: False-memory editing in children and adults|journal=Psychological Review|year=2003|volume=110|issue=4|pages=762–784|doi=10.1037/0033-295x.110.4.762}}&lt;/ref&gt;&lt;ref name="Recollection rejection: Gist cuing"&gt;{{cite journal|last=Oedgard|first=T.N.|author2=Lampinen, J.M.|title=Recollection rejection: Gist cuing of verbatim memory|journal=Memory &amp; Cognition|year=2005|volume=33|issue=8|pages=1422–1430|doi=10.3758/BF03193375}}&lt;/ref&gt; If neither verbatim nor gist traces are retrieved, then one might accept any test probe on the basis of response bias.&lt;br&gt;
This principle plays a key role in FTT's explanation of experimental dissociations between true and false memories (e.g., when a variable affects one type of memory without affecting the other, or when it produces opposite effects on them). The time of exposure of each word during study and the number of repetitions have been shown to produce such dissociations.&lt;ref name="The rise and fall of false recall"&gt;{{cite journal|last=McDermott|first=K.B.|author2=Watson, J.M.|title=The rise and fall of false recall: The impact of presentation duration|journal=Journal of Memory and Language|year=2001|volume=45|issue=1|pages=160–176|doi=10.1006/jmla.2000.2771}}&lt;/ref&gt;&lt;ref name="Repetition can have similar or different effects on accurate and false recognition"&gt;{{cite journal|last=Seamon|first=J.G.|author2=Luo, C.R.|author3= Schwartz, M.A.|author4= Jones, K.J.|author5= Lee, D.M.|author6= Jones, S.J.|title=Repetition can have similar or different effects on accurate and false recognition|journal=Journal of Memory and Language|year=2000|volume=46|issue=2|pages=323–340|doi=10.1006/jmla.2001.2811}}&lt;/ref&gt; More specifically, while true memory follows a [[Monotonic function|monotonically increasing function]] when plotted against presentation duration, false memory rates exhibit an inverted-U pattern when plotted as a function of presentation duration. Similarly, repetition is monotonically related to true memory (true memory increases as a function of the number of repetitions) and is non-monotonically related to false memory (repetition produces an inverted-U relation with false memory).

====Retrieval phenomenology====
Retrieval phenomenologies are spontaneous mental experiences associated with the act of remembering.  It was first systematically characterized by E. K. Strong in the early 1900s.&lt;ref name="The effect of time-interval upon recognition memory"&gt;{{cite journal|last=Strong|first=E.K.|title=The effect of time-interval upon recognition memory|journal=Psychological Review|year=1913|volume=20|issue=5|pages=339–372|doi=10.1037/h0072087}}&lt;/ref&gt;  Strong identified two distinct types of introspective phenomena associated with memory retrieval that have since been termed recollection (or remembrance) and familiarity.  Whereas the former is characterized as retrieval associated with recollection of past experiences, the latter lacks such association.  The two forms of experiences can be illustrated by everyday expressions such as "I remember that!" (recollection) and "That seems familiar..." (familiarity).  In FTT, retrieval of verbatim traces often produces recollective phenomenology and thus is frequently referred to as recollective retrieval.&lt;ref name = "Fuzzy-trace theory and false memory" /&gt;&lt;ref name="Fuzzy trace theory and memory development" /&gt; However, one feature of FTT is that recollective phenomenology is not particular to one type of memory process as posited by other dual-process theories of memory.  Instead, FTT posits that retrieval of gist traces can also produce recollective phenomenology under some circumstances.  When gist resemblance between a false item and memory is high and compelling, this gives rise to a phenomenon called phantom recollection,&lt;ref name="Phantom recall"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Payne, D.G.|author3= Wright, R.|author4= Reyna, V.F.|title=Phantom recall|journal=Journal of Memory and Language|year=2003|volume=48|issue=3|pages=445–467|doi=10.1016/S0749-596x(02)00501-6}}&lt;/ref&gt;&lt;ref name="Phantom ROC"&gt;{{cite journal|last=Lampinen|first=J.M.|author2=Watkins, K.N.|author3=Odegard, T.N.|title=Phantom ROC: Recollection rejection in a hybrid conjoint recognition signal detection model|journal=Memory|year=2006|volume=14|issue=6|pages=655–671|doi=10.1080/09658210600648431}}&lt;/ref&gt; which is a vivid, but false, memory deemed to be true.

====Developmental variability in dual processes====
The principle of developmental variability in dual processes posits that verbatim and gist processes show variability across the [[Developmental psychology#Life stages of psychological development|lifespan]].  More specifically, verbatim and gist processes have been shown to improve between early childhood and young adulthood.&lt;ref name="DPDR" /&gt;&lt;ref name="Fuzzy-trace theory" /&gt;&lt;ref name="Fuzzy-trace theory and children's false memories"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V.F.|title=Fuzzy-trace theory and children's false memories|journal=Journal of Experimental Child Psychology|year=1998|volume=71|issue=2|pages=81–129|doi=10.1006/jecp.1998.2464}}&lt;/ref&gt;&lt;ref name="Developmental reversals in false memory"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V.F.|author3=Ceci, S.J.|title=Developmental reversals in false memory: A review of data and theory|journal=Psychological Bulletin|year=2008|volume=134|issue=3|pages=343–382|doi=10.1037/0033-2909.134.3.343|pmid=18444700}}&lt;/ref&gt; Regarding verbatim processes, older children are better at retrieval of verbatim traces than younger children, although even very young children (4-year-olds) are able to retrieve verbatim information at above chance level.  For instance, source memory accuracy greatly increases between 4-year-olds and 6-year-olds,&lt;ref name="Developmental changes in source memory"&gt;{{cite journal|last=Drummey|first=A|author2=Newcombe|title=Developmental changes in source memory|journal=Developmental Science|year=2002|volume=5|issue=4|pages=502–513|doi=10.1111/1467-7687.00243}}&lt;/ref&gt; and memory for nonsense words (i.e., words without a meaning, such as neppez) has been shown to increase between 7- and 10-year-olds.&lt;ref name="On the development of conscious and unconscious memory."&gt;{{cite journal|last=Brainerd|first=CJ|author2=Stein, L |author3=Reyna, VF |title= On the development of conscious and unconscious memory|journal=Developmental Psychology|year=1998|volume=34|pages=342–357|doi=10.1037/0012-1649.34.2.342}}&lt;/ref&gt;  Gist processes also improve with age.  For example, semantic clustering in free recall increases from 8-year-olds to 14-year-olds,&lt;ref name="A developmental examination of ratings of associative strength"&gt;{{cite journal|last=Bjorklund|first=D.F.|author2=Jacobs, J.W.|title=A developmental examination of ratings of associative strength|journal=Behavior Research Methods|year=1984|volume=16|issue=6|pages=568–569|doi=10.3758/BF03200850}}&lt;/ref&gt; and meaning connection across words and sentences has been shown to improve between 6- and 9-year-olds.&lt;ref name="Development of gist versus verbatim memory in sentence recognition: Effects of lexical familiarity, semantic content, encoding instructions, and retention interval"&gt;{{cite journal|last=Reyna|first=V.F.|author2=Kiernan, B|title=Development of gist versus verbatim memory in sentence recognition: Effects of lexical familiarity, semantic content, encoding instructions, and retention interval|journal=Developmental Psychology|year=1994|volume=30|issue=2|pages=178–191|doi=10.1037/0012-1649.30.2.178}}&lt;/ref&gt;&lt;ref name="Children's memory and metaphorical interpretation"&gt;{{cite journal|last=Reyna|first=V.F.|author2=Kiernan, B|title=Children's memory and metaphorical interpretation|journal=Metaphor and Symbolic Activity|year=1995|volume=10|issue=4|pages=309–331|doi=10.1207/s15327868ms1004_5}}&lt;/ref&gt; In particular, the notion that gist memory improves with age plays a central role in FTT's prediction of age increases in false memory, a counterintuitive pattern that has been called developmental reversal.&lt;ref name="DPDR" /&gt;

Regarding old age, several studies suggest that verbatim memory declines between early and late adulthood, while gist memory remains fairly stable. Experiments indicate that older adults perform worse on tasks that require retrieval of surface features from studied items relative to younger adults.&lt;ref name="Age differences in source forgetting: Effects on reality monitoring and on eyewitness testimony."&gt;{{cite journal|last=Cohen|first=G|author2=Faulkner, D.|title=Age differences in source forgetting: Effects on reality monitoring and on eyewitness testimony.|journal=Psychology and Aging|year=1989|volume=4|issue=1|pages=10–17|doi=10.1037/0882-7974.4.1.10|pmid=2803602}}&lt;/ref&gt;&lt;ref name="Aging and source monitoring"&gt;{{cite journal|last=Hashtroudi|first=S|author2=Johnson, M |author3=Chrosniak, L. D. |title=Aging and source monitoring|journal=Psychology and Aging|year=1989|volume=4|issue=1|pages=106–12I|doi=10.1037/0882-7974.4.1.106}}&lt;/ref&gt;&lt;ref name="The relation between source memory and aging."&gt;{{cite journal|last=Schacter|first=D.L.|author2=Kaszniak, A.W. |author3=Kihlstrom, J.F. |author4=Valdiserri, M. |title= The relation between source memory and aging|journal=Psychology and Aging|year=1991|volume=6|issue=4|pages=559–568|doi=10.1037/0882-7974.6.4.559}}&lt;/ref&gt;&lt;ref name="False recollection induced by photographs:  A comparison of older and younger adults. "&gt;{{cite journal|last=Schacter|first=D.L.|author2=Koutstaal, W. |author3=Johnson, M. K. |author4=Gross, M. S. |author5=Angell, K. E. |title=False recollection induced by photographs:  A comparison of older and younger adults|journal=Psychology and Aging|year=1997|volume=12|issue=2|pages=203–215|doi=10.1037/0882-7974.12.2.203}}&lt;/ref&gt;  In addition, results with measurement models that quantify verbatim and gist processes indicate that older adults are less able to use verbatim traces during recall than younger adults.&lt;ref name="Trichotomous processes in early memory development, aging, and neurocognitive impairment: A unified theory."&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V. |author3=Howe, M. |title=Trichotomous processes in early memory development, aging, and neurocognitive impairment: A unified theory|journal=Psychological Review|year=2009|volume=116|issue=4|pages=783–832|doi=10.1037/a0016963|pmid=19839684}}&lt;/ref&gt;

===False memories===
When people try to remember past events (e.g., a birthday party or the last dinner), they often commit two types of errors: errors of omission and errors of commission. The former is known as [[forgetting]], while the latter is better known as false memories. False memories can be separated into spontaneous and implanted false memories. Spontaneous false memories result from endogenous (internal) processes, such as meaning processing, while implanted false memories are the result of exogenous (external) processes, such as the suggestion of false information by an outside source (e.g., an interviewer asking misleading questions). Research had first suggested that younger children are more susceptible to suggestion of false information than adults.&lt;ref name="Fuzzy trace theory and memory development" /&gt;  However, research has since indicated that younger children are much less likely to form false memories than older children and adults.&lt;ref&gt;{{cite journal | last1 = Howe | first1 = M.L. | year = 2005 | title = Children (but Not Adults) Can Inhibit False Memories | url = | journal = Psychological Science | volume = 16 | issue = 12| pages = 927–931 | doi=10.1111/j.1467-9280.2005.01638.x | pmid=16313654}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Brainerd | first1 = C.J. | last2 = Reyna | first2 = V.F. | last3 = Forrest | first3 = T.J. | year = 2002 | title = Are young children susceptible to the false-memory illusion? | url = | journal = Child Development | volume = 73 | issue = 5| pages = 1363–1377 | doi=10.1111/1467-8624.00477}}&lt;/ref&gt; Moreover, in opposition to common sense, true memories are not more stable than false ones. Studies have shown that false memories are actually more persistent than true memories.&lt;ref name="Fuzzy-trace theory and false memory" /&gt; According to FTT, such pattern arises because false memories are supported by memory traces that are less susceptible to interference and forgetting (gist traces) than traces that suppress them and also support true memories (verbatim traces).

==Reasoning and decision-making==

FTT, as it applies to reasoning, is adapted from [[dual process theory|dual process models]] of human cognition. It differs from the traditional dual process model in that it makes a distinction between [[impulsivity]] and [[intuition (psychology)|intuition]]—which are combined in [[Dual process theory#System 1|System 1]] according to traditional dual process theories—and then makes the claim that expertise and advanced cognition relies on intuition.&lt;ref name="smdm newsletter"&gt;[http://us4.campaign-archive2.com/?u=956a82e2db9a38b2c53183eb2&amp;id=8ead005323&amp;e=c6a6ba2f60#Fuzzy-Trace%20Theory Society for Medical Decision Making Spring Newsletter] (2012)&lt;/ref&gt; The distinction between intuition and analysis depends on what kind of representation is used to process information. The mental representations described by FTT are categorized as either ''gist'' or ''verbatim'' representations:
* ''Gist'' representations are bottom-line understandings of the meaning of information or experience, and are used in intuitive gist processing.
* ''Verbatim'' representations are the precise and detailed representations of the exact information or experience, and are used in analytic verbatim processing.
Generally, most adults display what is called a "fuzzy processing preference,"&lt;ref name="Fuzzy-trace theory" /&gt; meaning that they rely on the least precise gist representations necessary to make a decision, despite parallel processing of both gist and verbatim representations. Both processes increase with age, though the verbatim process develops sooner than the gist, and is thus more heavily relied on in adolescence.

In this regard, the theory expands on research that has illustrated the role of memory representations in reasoning processes,&lt;ref name="Support theory: A nonextensional representation of subjective probability."&gt;{{cite journal|last=Tversky|first=A.|author2=Koehler, D. J.|title=Support theory: A nonextensional representation of subjective probability.|journal=Psychological Review|year=1994|volume=101|pages=547–567|doi=10.1037/0033-295X.101.4.547}}&lt;/ref&gt; the intersection of which has been previously underexplored.&lt;ref name="Mindful judgment and decision making."&gt;{{cite journal|last=Weber|first=E.U.|author2=Johnson, E. J.|title=Mindful judgment and decision making.|journal=Annual Review of Psychology|year=2009|volume=60|pages=53–85|doi=10.1146/annurev.psych.60.110707.163633|pmid=18798706}}&lt;/ref&gt; However, it should be noted that in certain circumstances, FTT predicts independence between memory and reasoning, specifically between reasoning tasks that rely on gist representations and memory tests that rely on verbatim representations. An example of this is research between the [[Framing effect (psychology)|risky choice framing task]] and [[working memory]], in which better working memory is not associated with a reduction in bias.&lt;ref name="Memory reflected in our decisions: Higher working memory capacity predicts greater bias in risky choice."&gt;{{cite journal|last=Corbin|first=J.C.|author2=McElroy, T. |author3=Black, C. |title=Memory reflected in our decisions: Higher working memory capacity predicts greater bias in risky choice.|journal=Judgment and Decision Making|year=2010|volume=5|issue=2|pages=110–115}}&lt;/ref&gt;

FTT thus explains inconsistencies or [[Cognitive bias|biases]] in reasoning to be dependent on retrieval cues that access stored values and principles that are gist representations, which can be filtered through experience and cultural, affective, and developmental factors.&lt;ref name="Memory, development, and rationality: An integrative theory of judgment and decision making."&gt;{{cite journal|last=Reyna|first=V.F.|title=Memory, development, and rationality: An integrative theory of judgment and decision making.|editor=S. Schneider|editor2=J. Shanteau|journal=Emerging perspectives on judgment and decision research|year=2003|pages=201–245}}&lt;/ref&gt; This dependence on gist results in a vulnerability of reasoning to processing interference from overlapping classes of events, but can also explain expert reasoning in that a person can treat superficially different reasoning problems in the same way if the problems share an underlying gist.&lt;ref name="How people make decisions that involve risk: A dual process approach."&gt;{{cite journal|last=Reyna|first=V.F.|author2=Lloyd, F. J. |author3=Brainerd, C. J. |title=How people make decisions that involve risk: A dual process approach.|journal=Current Directions in Psychological Science|year=2004|volume=13|pages=60–66|doi=10.1111/j.0963-7214.2004.00275.x}}&lt;/ref&gt;

===Risk perception and probability judgments===

FTT posits that when people are presented with statistical information, they extract representations of the gist of the information (qualitatively) as well as the exact verbatim information (quantitatively). The gist that is encoded is often a basic categorical distinction between ''no risk'' and ''some risk.'' However, in situations when both choices in the decision have a level of uncertainty or risk, then another level of precision would be required, e.g., ''low risk'' or ''high risk.''&lt;ref name="reyna brainerd 1991"&gt;{{cite journal|last=Reyna|first=V.F.|author2=Brainerd, C.J.|title=Fuzzy-trace theory and framing effects in choice: Gist extraction, truncation, and conversion|journal=Journal of Behavior and Decision Making|year=1991|volume=4|pages=249–262|doi=10.1002/bdm.3960040403}}&lt;/ref&gt; An illustration of this principle can be found in FTT's explanation of the common [[Framing effect (psychology)|framing effect]].

====Framing effects====
{{Main|Framing effect (psychology)}}
Framing effects occur when linguistically different descriptions of equivalent options lead to inconsistent choices. A famous example of a risky choice framing task is the Asian Disease Problem.&lt;ref name="tversky kahneman"&gt;{{cite journal|last=Tversky|first=A|author2=Kahneman, D|title=The framing of decisions and the psychology of choice|journal=Science|date=30 January 1981|volume=211|issue=4481|pages=453–458|doi=10.1126/science.7455683|pmid=7455683}}&lt;/ref&gt;  This task requires the participants to imagine that their country is about to face a disease which is expected to kill 600 people. They have to choose among two programs to combat this disease. Subjects are presented with options that are framed as either gains (lives saved) or losses (lives lost). The possible options, as well as the categorical gists that are posited to be encoded by FTT are displayed below.

{| style="float: left;" class="wikitable"
|-
! width="100" |
! width="200" | Gain frame
! width="200" | Loss frame
|-
| Sure option
| "If program A is adopted, 200 people will be saved."
| "If program C is adopted, 400 people will die."
|-
| Risky option
| "If program B is adopted, there is 1/3 probability that 600 people will be saved, and 2/3 probability that no people will be saved."
| "If program D is adopted, there is 1/3 probability that nobody will die, and 2/3 probability that 600 people will die."
|-
| Encoded gist of sure option
| Some people will be saved
| Some people will die
|-
| Encoded gist of risky option
| Some people will be saved or no one will be saved
| Some people will die or no one will die&lt;ref name="risky choice framing"&gt;{{cite journal|last=Kühberger|first=Anton|author2=Tanner, Carmen|title=Risky choice framing: Task versions and a comparison of prospect theory and fuzzy-trace theory|journal=Journal of Behavioral Decision Making|year=2010|volume=23|issue=3|pages=314–329|doi=10.1002/bdm.656}}&lt;/ref&gt;
|}

It is commonly found that people prefer the sure option when the options are framed as gains (program A) and the risky option when they are framed as losses (program D),&lt;ref name="tversky kahneman" /&gt; despite the fact that the expected values for all the programs are equivalent. This is in contrast to a normative point of view that would indicate that if respondents prefer the sure option in the positive frame, they should also prefer the sure option in the negative frame.&lt;ref name="tversky kahneman" /&gt;

The explanation for this effect according to FTT is that people will tend to operate on the simplest gist that is permitted to make a decision. In the case of this framing question, the gain frame presents a situation in which people prefer the gist of some people being saved to the possibility that some are saved or no one could be saved, and conversely, that the possibility of some people dying or no one dying is preferable to the option that some people will surely die.&lt;ref name="risky choice framing" /&gt;

Critical tests have been conducted to provide evidence in support of this explanation in favor of other theoretical explanations (i.e., [[Prospect theory]]) by presenting a modified version of this task that eliminates some mathematically redundant wording, e.g., program B would instead indicate that "If program B is adopted, there is 1/3 probability that 600 people will be saved." FTT predicts, in this case, that the elimination of the additional gist (the explicit possible death in program B) would result in indifference and eliminate the framing effect, which is indeed what was found.&lt;ref name="risky choice framing" /&gt;

====Probability judgments and risk====
The dual-process assumption of FTT has also been used to explain common biases of probability judgment, including the conjunction and disjunction fallacies. The [[conjunction fallacy]] occurs when people mistakenly judge a specific set of circumstances to be more probable than a more general set that includes the specific set. This fallacy is famously demonstrated by the [[conjunction fallacy|Linda problem]]: that given a description of a woman named Linda who is an outspoken philosophy major who is concerned about discrimination and social justice, people will judge "Linda is a bank teller and is active in the feminist movement" to be more probable than "Linda is a bank teller", despite the fact that the latter statement is entirely inclusive of the former.&lt;ref name="linda problem"&gt;{{cite journal|last=Tversky|first=A.|author2=Kahneman, D.|title=Extensional versus intuitive reasoning: The conjunction fallacy in probability judgment|journal=Psychological Review|year=1983|volume=90|pages=293–315|doi=10.1037/0033-295X.90.4.293}}&lt;/ref&gt; FTT explains this phenomenon to not be a matter of encoding, given that priming participants to understand the inclusive nature of the categories tends not to reduce the bias. Instead, this is the result of the salience of relational gist, which contributes to a tendency to judge relative numerosity instead of merely applying the principle of class inclusion.&lt;ref name="conjunction fallacy"&gt;{{cite journal|last=Reyna|first=V.F.|title=Class inclusion, the conjunction fallacy and other cognitive illusions|journal=Developmental Review|year=1991|volume=11|pages=317–336|doi=10.1016/0273-2297(91)90017-I}}&lt;/ref&gt;

Errors of probability perception are also associated with the theory's predictions of contradictory relationships between risk perception and risky behavior. Specifically, that endorsement of accurate principles of objective risk is actually associated with greater risk-taking, whereas measures that assess global, gist-based judgments of risk had a protective effect (consistent with other predictions from FTT in the field of [[#Medical decision-making|medical decision making]]). Since gist processing develops after verbatim processing as people age, this finding lends explanation to the increase in risk-taking that occurs during adolescence.&lt;ref name="mills et al"&gt;{{cite journal|last=Mills|first=B.|author2=Reyna, V.F. |author3=Estrada, S. |title=Explaining contradictory relations between risk perception and risk taking|journal=Psychological Science|year=2008|volume=19|pages=429–33|doi=10.1111/j.1467-9280.2008.02104.x|pmid=18466401}}&lt;/ref&gt;

===Management and economics===
FTT has also been applied in the domains of [[consumer behavior]] and [[economics]]. For example, since the theory posits that people rely primarily on gist representations in making decisions, and that culture and experience can affect consumers' gist representations, factors such as cultural similarity and personal relevance have been used to explain consumers' perceptions of the risk of food-borne contamination and their intentions to reduce consumption of certain foods. In other words, one's evaluation of how "at-risk" he or she is can be inﬂuenced both by specific information learned as well as by the fuzzy representations of culture experience, and perceived proximity. In practice this resulted in greater consumer concern when the threat of a food-borne-illness was described in a culturally similar location, regardless of geographical proximity or other verbatim details.&lt;ref name="Risk perception and risk avoidance: the role of cultural identity and personal relevance."&gt;{{cite journal|last=Carvalho|first=S.W.|author2=Block, L.G. |author3=Sivaramakrishnan, S. |author4=Manchanda, R.V. |author5=Mitakakis, C. |title=Risk perception and risk avoidance: the role of cultural identity and personal relevance.|journal=International Journal of Research in Marketing|year=2008|volume=25|pages=319–326|doi=10.1016/j.ijresmar.2008.06.005}}&lt;/ref&gt;

Evidence was also found in consumer research in support of FTT's "editing" hypothesis, namely that extremely low-probability risks can be simplified by gist processing to be represented as "essentially nil." For example, one study found that people were willing to pay more for a safer product if safety was expressed relatively (i.e., product A is safer than product B) than they were if safety was expressed with statistics of actual incidence of safety hazards.
This result is in contrast to most prescriptive decision rules that predict that formally equivalent methods of communicating risk information should have identical effects on risk-taking behavior, even if the pertinent displays are different. These findings are predicted by FTT (and related models), which suggest that people reason on the basis of simplified representations rather than on the literal information available.&lt;ref name="Risk communication: absolute versus relative expressions of low-probability risks."&gt;{{cite journal|last=Stone|first=E.R.|author2=Yates, J.F. |author3=Parker, A.M. |title=Risk communication: absolute versus relative expressions of low-probability risks.|journal=Organizational Behavior and Human Decision Processes|year=1994|volume=60|pages=387–408|doi=10.1006/obhd.1994.1091}}&lt;/ref&gt;

===Medical decision-making===
Like other people, clinicians apply [[Heuristic#Theorized psychological heuristics|cognitive heuristics]] and fall into systematic errors which affect decisions in everyday life. Research has shown that patients and their physicians have difficulty understanding a host of numerical concepts, especially risks and probabilities, and this often implies some problems with [[numeracy]], or mathematical proficiency.&lt;ref name="How numeracy influences risk comprehension and medical decision making"&gt;{{cite journal|last=Reyna|first=V.F.|author2=Nelson, W. |author3=Han, P. |author4=Dieckmann, N. F. |title=How numeracy influences risk comprehension and medical decision making|journal=Psychological Bulletin|year=2009|volume=135|pages=943–973|doi=10.1037/a0017327|pmid=19883143|pmc=2844786}}&lt;/ref&gt; For example, physicians and patients both demonstrate great difficulty understanding the probabilities of certain genetic risks and were prone to the same errors, despite vast differences in medical knowledge.&lt;ref name="Genetic testing and medical decision making"&gt;{{cite journal |last1= Reyna |first1=V.F. |last2= Lloyd |first2= F. |last3= Whalen |first3= P. |title= Genetic testing and medical decision making |journal= Archives of Internal Medicine |date= 2001 |volume= 161 |pages= 2406–2408 |doi= 10.1001/archinte.161.20.2406 }}&lt;/ref&gt;
Though traditional [[dual process theory]] generally predicts that decisions made by computation are superior to those made by intuition, FTT assumes the opposite: that intuitive processing is more sophisticated and is capable of making better decisions, and that increases in expertise are accompanied by reliance on intuitive, gist-based reasoning rather than on literal, verbatim reasoning.&lt;ref name="The importance of mathematics in health and human judgment: Numeracy, risk communication, and medical decision making"&gt;{{cite journal|last=Reyna|first=V.R.|author2=Brainerd, C.J.|title=The importance of mathematics in health and human judgment: Numeracy, risk communication, and medical decision making|journal=Learning and Individual Differences|year=2007|volume=17|issue=2|pages=147–159|doi=10.1016/j.lindif.2007.03.010}}&lt;/ref&gt;
FTT predicts that simply educating people with statistics regarding risk factors can hinder prevention efforts. Due to low prevalence of HIV or cancer, for example, people tend to overestimate their risks, and consequently interventions stressing the actual numbers may move people toward complacency as opposed to risk reduction.&lt;ref name="Risk and rationality in adolescent decision making: Implications for theory, practice, and public policy"&gt;{{cite journal|last=Reyna|first=V.R.|author2=Farley, F.|title=Risk and rationality in adolescent decision making: Implications for theory, practice, and public policy|journal=Psychological Science in the Public Interest|year=2006|volume=7|pages=1–44|doi=10.1111/j.1529-1006.2006.00026.x}}&lt;/ref&gt; When women learn that their actual risks for breast cancer are lower than they thought, they return for screening at a lower rate.&lt;ref name="How making a risk estimate can change the feel of that risk: Shifting attitudes toward breast cancer risk in a general public survey"&gt;{{cite journal|last=Fagerlin|first=A.|author2=Zikmund-Fisher, B.J. |author3=Ubel, P. |title=How making a risk estimate can change the feel of that risk: Shifting attitudes toward breast cancer risk in a general public survey|journal=Patient Education &amp; Counseling|year=2005|volume=57|pages=294–299|doi=10.1016/j.pec.2004.08.007}}&lt;/ref&gt; Also, some interventions to discourage adolescent drug use by presenting the risks have been shown to be ineffective or can even backfire.&lt;ref name="Psychological treatments that cause harm"&gt;{{cite journal|last=Lilienfeld|first=S.O.|title=Psychological treatments that cause harm|journal=Perspectives on Psychological Science|year=2007|volume=2|pages=53–70|doi=10.1111/j.1745-6916.2007.00029.x}}&lt;/ref&gt;

The conclusion drawn from this evidence is that health-care professionals and health policymakers need to package, present, and explain information in more meaningful ways that facilitate forming an appropriate gist. Such strategies would include explaining quantities qualitatively, displaying information visually, and tailoring the format to trigger the appropriate gist and to cue the retrieval of health-related knowledge and values.&lt;ref name="MDM_28_6" /&gt; Web-based interventions have been designed using these principles, which have been found to increase the patient's willingness to escalate care, as well as gain knowledge and make an informed choice.&lt;ref name="smdm newsletter" /&gt;

==Implications==
Theory-driven research using principles from FTT provides empirically supported recommendations that can be applied in many fields.  For example, it provides specific recommendations regarding interventions aiming at reducing adolescent risk taking.&lt;ref name="Risk and rationality in adolescent decision making. Implications for theory, practice, and public policy"&gt;{{cite journal|last=First Author's Reyna|first=V.F.|author2=Farley, F.|title=Risk and rationality in adolescent decision making. Implications for theory, practice, and public policy|journal=Psychological Science in the Public Interest|year=2006|volume=7|pages=1–44|doi=10.1111/j.1529-1006.2006.00026.x}}&lt;/ref&gt; Moreover, according to FTT, precise information does not necessarily work to communicate health-related information, which has obvious implications to public policy and procedures for improving treatment adherence in particular.&lt;ref name="How numeracy influences risk comprehension and medical decision making" /&gt;&lt;ref name="Numeracy, ratio bias, and denominator neglect in judgments of risk and probability."&gt;{{cite journal|last=Reyna|first=V.F.|author2=Brainerd, C. J. |title=Numeracy, ratio bias, and denominator neglect in judgments of risk and probability.|journal=Learning and Individual Differences|year=2008|volume=18|pages=89–107|doi=10.1016/j.lindif.2007.03.011}}&lt;/ref&gt; Specifically, FTT principles suggest examples of how to display risk proportions in order to be comprehensible for both patients and health care professionals:&lt;ref name="MDM_28_6" /&gt;

* Explain quantities qualitatively. Do not rely solely on numbers when presenting information.
* Explain quantities, percentages, and probabilities verbally, stressing conceptual understanding (the bottom-line meaning of information) over precise memorization of verbatim facts or numbers (e.g., a 20% of breast cancer is actually a "high" risk).
* Provide verbal guidance in disentangling classes and class-inclusion relationships.
* Display information visually. When it is necessary to present information numerically, arrange numbers so that meaningful patterns or relationships among them are obvious.
* Make use of graphical displays which help people extract the relevant gist. Useful formats for conveying relative risks and other comparative information include simple bar graphs and risk ladders. Pie charts are good for representing relative proportions. Line graphs are optimal for conveying the gist of a linear trend, such as survival and mortality curves or the effectiveness of a drug over time. [[Stacked bar graph]]s are useful for showing absolute risks; and Venn diagrams, two-by-two grids, and 100-square grids are useful for disentangling numerators and denominators and for eliminating errors from probability judgments.
* Avoid distracting gists. The class-inclusion confusion is especially likely to produce errors when visually or emotionally salient details, a story, or a stereotype draws attention away from the relevant data in the direction of extraneous information. For example, given a display of seven cows and three horses, children are asked whether there are more cows or more animals. Until the age of ten, children often respond that there are more cows than animals, even after counting the number in each class aloud correctly. However, young children in the previous example are more likely to answer the problem correctly when they are not shown a picture with the visually hard-to-ignore detail, that is, several figures of cows.
* Facilitate reexamination of problems. Encourage people to reexamine problems and edit their initial judgments. Although gist for quantities tends to be more available than the numbers verbatim, people can and do attend to the numbers to correct their first gist-based impressions when cued to do so and when they are given the time and opportunity, which can help reducing errors.

In addition, memory principles in FTT provide recommendations to [[eyewitness testimony]].&lt;ref&gt;Reyna, V. F., Mills, B., Estrada, S., &amp; Brainerd, C. J. (2006). False memory in children: Data, theory, and legal implications. In M. Toglia &amp; D. Read, D. F. Ross, &amp; R. C. L.Lindsay (Eds.), ''The handbook of eyewitness psychology: Memory for events'' (pp.&amp;nbsp;473–510). Mahwah, NJ: Erlbaum.&lt;/ref&gt;&lt;ref&gt;Brainerd, C.J., Reyna, V. F., &amp; Poole, D. A. (2000). Fuzzy-trace theory and false memory: Memory theory in the courtroom. In D. F. Bjorklund (Ed.), ''False memory creation in children and adults'' (pp.&amp;nbsp;93–127). Mahwah, NJ: Erlbaum.&lt;/ref&gt; Children are often called upon to testify in courts, most commonly in cases of maltreatment, divorce, and child custody. Contrary to common sense, FTT posits that children can be reliable witnesses as long as they are encouraged to report verbatim memories and their reports are protected from suggestion of false information.  More specifically:

* Children should be interviewed as soon as possible after the target event to reduce exposure to false suggestions and to facilitate retrieval of verbatim memories before their rapid decay.
* When reminding a witness of a target event, interviewers should present pictures or photos rather than words to describe it. Pictures of the actual target event help to increase retrieval of true memories as they are better cues to verbatim memories than words.
* Avoid repeated questioning. FTT predicts, for example, that the repetition of questions that restate the gist of a false information can increase the probability of false memories during subsequent interviews.&lt;ref name="Mere memory testing creates false memories in children"&gt;{{cite journal|last=Brainerd|first=C.J.|author2=Reyna, V. F.|title=Mere memory testing creates false memories in children|journal=Developmental Psychology|year=1996|volume=32|pages=467–476|doi=10.1037/0012-1649.32.3.467}}&lt;/ref&gt;&lt;ref name="Memory illusions: Recalling, recognizing, and recollecting events that never occurred"&gt;{{cite journal|last=Payne|first=D.G.|author2=Elie, C. J. |author3=Blackwell, J. M. |author4=Neuschatz, J. S. |title=Memory illusions: Recalling, recognizing, and recollecting events that never occurred|journal=Journal of Memory and Language|year=1996|volume=35|pages=261–285|doi=10.1006/jmla.1996.0015}}&lt;/ref&gt;
* Do not give children negative feedback about their performance during an interview. This procedure prompts children to provide additional information that is often false rather than true.

==See also==
* [[Behavioral economics]]
* [[Cognitive development]]
* [[Decision-making]]
* [[Developmental psychology]]
* [[Framing (social sciences)|Framing]]
* [[Reason]]
* [[Risk]]

{{memory}}

== References ==
{{reflist|30em}}

[[Category:Cognitive psychology]]
[[Category:Applied probability]]
[[Category:Decision theory]]</text>
      <sha1>duj60jj9u2397ltl6xcx2ytultcuk6t</sha1>
    </revision>
  </page>
  <page>
    <title>Georgia Benkart</title>
    <ns>0</ns>
    <id>38764823</id>
    <revision>
      <id>870730984</id>
      <parentid>870448238</parentid>
      <timestamp>2018-11-26T18:03:46Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>birth year in main text with source</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13518">{{infobox scientist
  | name        = Georgia Benkart
  | image       = 
  | birth_date  = 1949
  | birth_place = [[Youngstown]], [[Ohio]], U.S.
  | nationality       = American
  | fields            = [[Lie algebras]], [[Representation Theory]], [[Combinatorics]]
  | workplaces        = [[University of Wisconsin&amp;ndash;Madison]]
    | alma_mater  = B.S., [[Ohio State University]], 1970&lt;br&gt; Ph.D., [[Yale University]], 1974
 | doctoral_advisor  = [[Nathan Jacobson]]
  | known_for   = Classification of simple modular Lie algebras
| awards      = {{ublist |President of [[Association for Women in Mathematics]]
| Fellow of the [[American Mathematical Society]]
| AWM-AMS [[Noether Lecture]]r
|ICM Noether Lecturer
|MAA Polya Lecturer
}}

  }}

'''Georgia McClure Benkart''' (born 1949)&lt;ref&gt;Birth year from [http://www.isni.org/isni/0000000110365132 ISNI authority control file], accessed 2018-11-26.&lt;/ref&gt; is an American mathematician who is known for her work in the structure and representation theory of [[Lie algebra]]s and related algebraic structures.
She has published over 100 journal articles&lt;ref name="MathSciResearchInst"&gt;{{Cite web |url=https://www.msri.org/people/2676 |title=Personal Profile of Dr. Georgia M. Benkart |publisher=Mathematical Sciences Research Institute |access-date=14 March 2017}}&lt;/ref&gt; and co-authored 3 American Mathematical Society Memoirs&lt;ref name="Memoir2002"&gt;{{cite book|last1=Allison|first1=Bruce|last3=Gao|first3=Yun|last2=Benkart|first2=Georgia|title=Lie algebras graded by the root systems BC&lt;sub&gt;r&lt;/sub&gt;, r&amp;nbsp;≥&amp;nbsp;2|date=2002|series=Memoirs of the American Mathematical Society|volume=158|publisher=American Mathematical Society|mr=1902499|isbn=978-0-8218-2811-3}}&lt;/ref&gt;&lt;ref name="Stability Memoir"&gt;{{cite book|last1=Benkart|first1=Georgia M.|last2=Britten|first2=Daniel|last3=Lemire|first3=Frank|title=Stability in Modules for Classical Lie Algebras: A Constructive Approach|date=May 1990|series=Memoirs of the American Mathematical Society|volume=85|publisher=American Mathematical Society|location=Providence, R.I.|mr=2488391|isbn=978-0-8218-2492-4|url=http://www.ams.org/books/memo/year/1990/|accessdate=10 June 2014}}&lt;/ref&gt;&lt;ref name="Memoir2009"&gt;{{cite book|last1=Benkart|first1=Georgia|last2=Gregory|first2=Thomas|last3=Premet|first3=Alexander|title=The recognition theorem for graded Lie algebras in prime characteristic|date=2009|series=Memoirs of the American Mathematical Society|volume=197|publisher=American Mathematical Society|isbn=978-0-8218-4226-3}}&lt;!--|accessdate=27 May 2014--&gt;&lt;/ref&gt; in four broad categories: [[Modular Lie algebra|modular Lie algebras]]; combinatorics of [[Lie algebra representation|Lie algebra representations]]; [[Graded algebra|graded algebras]] and [[Superalgebra|superalgebras]]; and [[Quantum group|quantum groups]] and related structures.

==Research==
Benkart has made a contribution to the classification of simple modular [[Lie algebras]]. Her work with J. M. Osborn on toroidal rank-one Lie algebras&lt;ref name="rank one Lie algebras"&gt;{{cite journal|last=Benkart|first=Georgia|author2=J. Marshall Osborn |title=Toral rank one Lie algebras|journal=Journal of Algebra|date=1988|volume=115|issue=1|pages=238–250|url=http://www.sciencedirect.com/science/article/pii/0021869388902931|accessdate=27 May 2014|doi=10.1016/0021-8693(88)90293-1}}&lt;/ref&gt; became one of the building blocks of the classification. The complete description of [[Hamiltonian Lie algebras]] (with Gregory, Osborn, Strade, Wilson) can stand alone, and also has applications in the theory of [[pro-p group]]s.

In 2009 she published, jointly with T. Gregory and A. Premet,&lt;ref name="Memoir2009"/&gt; the first complete proof of the recognition theorem for graded Lie algebras in characteristics at least&amp;nbsp;5.&lt;ref name=MR2488391&gt;Review of ''The recognition theorem for graded Lie algebras in prime characteristic'' by Murray R. Bremner (2009), {{MR|2488391}}&lt;/ref&gt;

In the early 90s Benkart and [[Efim Zelmanov]] started to work on classification of root-graded Lie algebras and intersection matrix algebras. The latter were introduced by P. Slodowy in his work on singularities. Berman and Moody recognized that these algebras (generalizations of affine [[Kac–Moody algebra]]s ) are universal root graded Lie algebras and classified them for simply laced root systems. Benkart and Zelmanov tackled the remaining cases involving the so-called Magic Freudenthal–Tits  “Square” and extended this square to exceptional [[Lie superalgebra|Lie superalgebras]].

Later Benkart extended these results in two directions. In a series of papers with A. Elduque she developed the theory of root graded Lie superalgebras. In a second series of works with B. Allison, A. Pianzola, E. Neher, et al. she determined the universal central covers of these algebras.

One of the pillars of the representation theory of [[quantum group]]s (and applications to combinatorics) is Kashiwara's theory of [[crystal basis|crystal bases]]. These are highly invariant bases which are well suited for decompositions of tensor products.  In a paper with S.-J. Kang and M. Kashiwara, Benkart extended the theory of crystal bases to quantum superalgebras.

Benkart's work on [[noncommutative algebra]]s related to [[algebraic combinatorics]] became a basic tool in the construction of [[tensor category|tensor categories]].

==Education and career==
Benkart received her B.S. from the [[Ohio State University]] in 1970 and an M. Phil. in Mathematics from  [[Yale University]] in 1973. She completed her doctoral work at Yale under [[Nathan Jacobson]]  and wrote a dissertation entitled ''Inner Ideals and the Structure of Lie Algebras.'' She was awarded a Ph.D. in Mathematics from the Yale University in 1974.

Upon completing her doctoral degree, Benkart began her long career at the [[University of Wisconsin&amp;ndash;Madison]], first as a MacDuffee Instructor and eventually as a E. B. Van Vleck Professor of Mathematics until she retired from teaching in 2006.&lt;ref name="Women Mathematicians at Wisconsin"&gt;{{cite web|title=A Brief History of Women Mathematicians at Wisconsin |url=https://www.math.wisc.edu/history_women_mathematicians |archive-url=https://web.archive.org/web/20140529151009/https://www.math.wisc.edu/history_women_mathematicians |dead-url=yes |archive-date=29 May 2014 |publisher=University of Wisconsin Math Department |accessdate=21 May 2014 }}&lt;/ref&gt;  She held visiting positions at the [[Mathematical Sciences Research Institute]] in [[Berkeley, California|Berkeley]], [[California]], the [[Institute for Advanced Study]] in [[Princeton, New Jersey|Princeton]], [[New Jersey]], the [[Aspen Center for Physics]], and the [[University of Virginia]].

==Honors==
Benkart received a Woodrow Wilson Fellowship from the [[Woodrow Wilson National Fellowship Foundation]]. Her work at Wisconsin was recognized by a Romnes Fellowship in 1985, a Distinguished Teaching Award in 1987, and a WARF Mid-Career Faculty Research Award in 1996.&lt;ref name="University of Wisconsin Honors and Awards"&gt;{{cite web|title=University of Wisconsin Honors and Awards|url=http://www.math.wisc.edu/oldhome/news/2001/awards.htm|publisher=University of Wisconsin |accessdate=23 May 2014}}&lt;/ref&gt; In 2008 the University of California Lie Groups and Lie Algebras meeting was held in Benkart's honor.  She has given numerous talks and series of lectures throughout the U.S., Canada, France, Germany, Hong Kong, Korea, Mexico, and Spain, including two invited lectures at the Joint Mathematics Meetings&lt;ref name="JMM AMS-MAA Invited Address"&gt;{{cite web|title=Joint Mathematics Meeting AMS-MAA Invited Address|url=http://jointmathematicsmeetings.org/meetings/national/jmm/1889_program_wednesday.html#1889:BENKART|publisher=American Mathematical Society|accessdate=23 May 2014}}&lt;/ref&gt; and a plenary lecture at a meeting of the Canadian Mathematical Society.&lt;ref name="CMS Plenary"&gt;{{cite web|title=2001 CMS Summer Meeting|url=https://cms.math.ca/Events/summer01/photos/CMSindex.html#plenary|website=Photos from the 2001 CMS Summer Meeting|publisher=Canadian Mathematical Society|accessdate=10 June 2014}}&lt;/ref&gt;

In 2000–2002 Benkart was named a Polya Lecturer&lt;ref name="Polya Lectures"&gt;{{cite web|title=Pólya Lectures|url=http://www.maa.org/programs/maa-awards/lecture-awards/pólya-lecturers|publisher=Mathematical Association of America|accessdate=21 May 2014}}&lt;/ref&gt; by the [[Mathematical Association of America]].  
She was elected a Fellow of the [[American Mathematical Society]] (AMS)&lt;ref name="AMS Fellows"&gt;{{cite web|title=List of Fellows of the American Mathematical Society|url=http://www.ams.org/profession/fellows-list|publisher=American Mathematical Society|accessdate=21 May 2014}}&lt;/ref&gt; in the inaugural class of 2013.

She has served on the editorial boards of the American Mathematical Society for Surveys and Monographs and Abstracts,&lt;ref name="AMS Ed Boards"&gt;{{cite web|title=AMS Editorial Boards|url=http://www.ams.org/about-us/governance/committees/comm-edit.html|publisher=American Mathematical Society|accessdate=21 May 2014}}&lt;/ref&gt; the Journal of Algebra,&lt;ref name="Journal of Algebra Editorial Board"&gt;{{cite web|title=Journal of Algebra|url=http://ac.els-cdn.com/S0021869303007300/1-s2.0-S0021869303007300-main.pdf?_tid=abf760a4-e5e1-11e3-9693-00000aacb35e&amp;acdnat=1401224497_1714f5042255828bc40cf11994837975|publisher=Elsevier|accessdate=27 May 2014}}&lt;/ref&gt; the Korean Mathematical Colloquium, the Nova Journal of Algebra and Geometry, Communications in Algebra, and Algebras, Groups, and Geometries.  She served as the Associate Secretary of the American Mathematical Society for the Central Section from 2010–2016.&lt;ref name="AMS Council Members"&gt;{{cite web|title=AMS Council Members|url=http://www.ams.org/about-us/governance/council/member-council|publisher=American Mathematical Society|accessdate=22 May 2014}}&lt;/ref&gt;
 
Benkart has been active in the [[Association for Women in Mathematics]] (AWM). She was elected and served as President of the AWM from 2009–2011.&lt;ref name="AWM President"&gt;{{cite journal|title=President's Report|journal=AWM Newsletter|date=March–April 2009|volume=39|issue=2|pages=1–5|accessdate=27 May 2014|url=http://www.drivehq.com/file/df.aspx/isGallarytrue/shareID8755087/fileID929339010?1=1}}&lt;/ref&gt; In 2014 she was selected to deliver the AWM-AMS [[Noether Lecture]].&lt;ref name=NoetherList&gt;{{cite web|title=List of Noether Lecturers|url=https://sites.google.com/site/awmmath/programs/noether-lectures/noether-lecturers|accessdate=22 May 2014}}&lt;/ref&gt;  The title of her talk was Walking on Graphs the Representation Theory Way.&lt;ref name="Noether Lecture Profile"&gt;{{cite web|title=Noether Lecture Profile|url=https://sites.google.com/site/awmmath/programs/noether-lectures/noether-lecturers/noether-profiles/georgiabenkart|publisher=Association for Women in Mathematics|accessdate=22 May 2014}}&lt;/ref&gt;

In 2014 at the International Congress of Mathematicians held in Seoul, she delivered the ICM Emmy Noether Lecture.&lt;ref name="ICM Emmy Noether Lecture"&gt;{{cite web|title=ICM Emmy Noether Lecture |url=http://www.icm2014.org/en/program/scientific/speciallectures |publisher=the organizing committee of Seoul ICM 2014 |accessdate=2 October 2014 |deadurl=yes |archiveurl=https://web.archive.org/web/20141006121521/http://www.icm2014.org/en/program/scientific/speciallectures |archivedate=6 October 2014 |df= }}&lt;/ref&gt;

In 2017 she was selected as a fellow of the Association for Women in Mathematics in the inaugural class.&lt;ref&gt;{{cite web|title=Launch of the AWM Fellows Program|url=https://sites.google.com/site/awmmath/awm-fellows|website=sites.google.com/site/awmmath/|publisher=Association for Women in Mathematics|accessdate=7 November 2017}}&lt;/ref&gt;

==Selected publications==
*with Daniel Britten, Frank Lemire: {{cite book|title=Stability in Modules for Classical Lie Algebras: A Constructive Approach|series=Memoirs of the American Mathematical Society|volume=85|location=Providence, R.I.|publisher=American Mathematical Society|year=1990|url=https://books.google.com/books/about/Stability_in_Modules_for_Classical_Lie_A.html?id=d0F-R0eZSqkC|MR=1010997}}
*with Bruce Allison, Yun Gao: {{cite book|title=Lie algebras graded by the root systems BC&lt;sub&gt;r&lt;/sub&gt;, r ≥ 2|series=Memoirs of the American Mathematical Society|volume=158|publisher=American Mathematical Society|year=2002|url=https://books.google.com/books/about/Lie_Algebras_Graded_by_the_Root_Systems.html?id=Wb48-RBngkYC|MR=1902499}}
*with Thomas Gregory, Alexander Premet: {{cite book|title=The recognition theorem for graded Lie algebras in prime characteristic|series=Memoirs of the American Mathematical Society|volume=197|publisher=American Mathematical Society|year=2009|MR=2488391}}

==External links==
* Georgia Benkart's [http://www.ams.org/mathscinet/MRAuthorID/34650 Author Profile Page] on MathSciNet

==References==
{{reflist|30em}}

{{authority control}}

{{DEFAULTSORT:Benkart, Georgia}}
[[Category:1949 births]]
[[Category:Living people]]
[[Category:People from Youngstown, Ohio]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Guggenheim Fellows]]
[[Category:Yale University alumni]]
[[Category:University of Wisconsin&amp;ndash;Madison faculty]]
[[Category:Ohio State University alumni]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:American women mathematicians]]
[[Category:Mathematicians from Ohio]]
[[Category:Fellows of the Association for Women in Mathematics]]</text>
      <sha1>4z4vhjdej8eh4vbxr6zv3ip9nru7pam</sha1>
    </revision>
  </page>
  <page>
    <title>Giovanni Battista Nicolai</title>
    <ns>0</ns>
    <id>49917455</id>
    <revision>
      <id>861374935</id>
      <parentid>747649310</parentid>
      <timestamp>2018-09-26T23:51:35Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* Works */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1396">[[File:Nicolai_-_Della_possibilità_della_reale_soluzione_analitica_del_caso_irreducibile,_1783_-_723652.tif|thumb|''Della possibilità della reale soluzione analitica del caso irreducibile'', 1783]]
'''Giovanni Battista Nicolai''' (1726 – 1793) was an [[Italians|Italian]] [[mathematician]].

He was a priest, analyst and scholar in [[Padua]].

== Works ==
* {{Cite book|publisher=Tipografia del Seminario Padova|last=Nicolai|first=Giovanni Battista|title=Della possibilità della reale soluzione analitica del caso irreducibile|location=Padova|year=1783|url=http://gutenberg.beic.it/webclient/DeliveryManager?pid=723652&amp;search_terms=DTL6}}
* {{Cite book|publisher=Tipografia del Seminario Padova, Tommaso Bettinelli|last=Nicolai|first=Giovanni Battista|title=Nova analyseos elementa. 1|location=Patavii ; prostat Venetiis|year=1786|url=http://gutenberg.beic.it/webclient/DeliveryManager?pid=788473&amp;search_terms=DTL6}}
* {{Cite book|publisher=Tipografia del Seminario Padova, Tommaso Bettinelli|last=Nicolai|first=Giovanni Battista|title=Nova analyseos elementa. 2|location=Patavii ; prostat Venetiis|year=1793|url=http://gutenberg.beic.it/webclient/DeliveryManager?pid=789732&amp;search_terms=DTL8}}

{{authority control}}

[[Category:Mathematical analysis]]
[[Category:Equations]]
[[Category:Italian mathematicians]]
[[Category:1793 deaths]]
[[Category:1726 births]]
[[Category:Complex numbers]]</text>
      <sha1>ei0c74dqtdrw5dyumje6kd1dag0ymwb</sha1>
    </revision>
  </page>
  <page>
    <title>Graph (discrete mathematics)</title>
    <ns>0</ns>
    <id>325806</id>
    <revision>
      <id>869633580</id>
      <parentid>869348789</parentid>
      <timestamp>2018-11-19T20:41:56Z</timestamp>
      <contributor>
        <ip>149.32.224.41</ip>
      </contributor>
      <comment>Added definition of n.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26588">{{about|sets of vertices connected by edges|graphs of mathematical functions|Graph of a function|other uses|Graph (disambiguation)}}
[[File:6n-graf.svg|thumb|250px|A [[graph drawing|drawing]] of a [[labeled graph]] on 6 vertices and 7 edges.]]

In [[mathematics]], and more specifically in [[graph theory]], a '''graph''' is a structure amounting to a set of objects in which some pairs of the objects are in some sense "related". The objects correspond to mathematical abstractions called ''[[Vertex (graph theory)|vertices]]'' (also called ''nodes'' or ''points'') and each of the related pairs of vertices is called an ''edge'' (also called an ''arc'' or ''line'').&lt;ref&gt;{{cite book|last=Trudeau|first=Richard J.|title=Introduction to Graph Theory|year=1993|publisher=Dover Pub.|location=New York|isbn=978-0-486-67870-2|pages=19|url=http://store.doverpublications.com/0486678709.html|edition=Corrected, enlarged republication.|accessdate=8 August 2012|quote=A graph is an object consisting of two sets called its ''vertex set'' and its ''edge set''.}}&lt;/ref&gt; Typically, a graph is depicted in [[diagrammatic form]] as a set of dots for the vertices, joined by lines or curves for the edges. Graphs are one of the objects of study in [[discrete mathematics]].

The edges may be directed or undirected. For example, if the vertices represent people at a party, and there is an edge between two people if they shake hands, then this graph is undirected because any person ''A'' can shake hands with a person ''B'' only if ''B'' also shakes hands with ''A''. In contrast, if any edge from a person ''A'' to a person ''B'' corresponds to ''A'''s admiring ''B'', then this graph is directed, because admiration is not necessarily reciprocated. The former type of graph is called an ''undirected graph'' and the edges are called ''undirected edges'' while the latter type of graph is called a ''directed graph'' and the edges are called ''directed edges''.

Graphs are the basic subject studied by [[graph theory]]. The word "graph" was first used in this sense by [[James Joseph Sylvester]] in 1878.&lt;ref&gt;See:
* J. J. Sylvester (February 7, 1878) [https://books.google.com/books?id=KcoKAAAAYAAJ&amp;vq=Sylvester&amp;pg=PA284#v=onepage&amp;q&amp;f=false "Chemistry and algebra,"] ''Nature'', ''17'' : 284. {{doi|10.1038/017284a0}}. From page 284: "Every invariant and covariant thus becomes expressible by a ''graph'' precisely identical with a Kekuléan diagram or chemicograph."
* J. J. Sylvester (1878) [https://books.google.com/books?id=1q0EAAAAYAAJ&amp;pg=PA64#v=onepage&amp;q&amp;f=false "On an application of the new atomic theory to the graphical representation of the invariants and covariants of binary quantics, — with three appendices,"] ''American Journal of Mathematics, Pure and Applied'', ''1'' (1) : 64–90. {{doi|10.2307/2369436}}. {{JSTOR|2369436}}. The term "graph" first appears in this paper on page 65.&lt;/ref&gt;&lt;ref&gt;{{Cite book
 | title = Handbook of graph theory
 | first1 = Jonathan L.
 | last1 = Gross
 | first2 = Jay
 | last2 = Yellen
 | publisher = [[CRC Press]]
 | year = 2004
 | page = [https://books.google.com/books?id=mKkIGIea_BkC&amp;pg=PA35&amp;lpg=PA35 35]
 | isbn = 978-1-58488-090-5
 | url = https://books.google.com/?id=mKkIGIea_BkC
 | postscript = &lt;!--None--&gt;}}&lt;/ref&gt;

==Definitions==
Definitions in graph theory vary. The following are some of the more basic ways of defining graphs and related [[mathematical structure]]s.

===Graph===
In one very common sense of the term,&lt;ref&gt;See, for instance, Iyanaga and Kawada, ''69 J'', p. 234 or Biggs, p. 4.&lt;/ref&gt; a ''graph'' is an [[ordered pair]] {{nobreak|1=''G'' = (''V'', ''E'')}} comprising a [[set (mathematics)|set]] ''V'' of ''vertices'', ''nodes'' or ''points'' together with a set ''E'' of ''edges'', ''arcs'' or ''lines'', which are 2-element subsets of ''V'' (i.e., an edge is associated with two vertices, and the association takes the form of the unordered pair of the vertices). To avoid ambiguity, this type of graph may be described precisely as ''[[Graph (discrete mathematics)#Undirected graph|undirected]]'' and ''[[Graph (discrete mathematics)#Simple graph|simple]]''.

Other senses of ''graph'' stem from different conceptions of the edge set. In one more general conception,&lt;ref&gt;See, for instance, Graham et al., p. 5.&lt;/ref&gt; ''E'' is a set together with a relation of ''incidence'' that associates with each edge two vertices. In another generalized notion, ''E'' is a [[multiset]] of unordered pairs of (not necessarily distinct) vertices. Many authors call these types of object [[multigraph]]s or pseudographs.

All of these variants and others are described more fully below.

The vertices belonging to an edge are called the ''ends'' or ''end vertices'' of the edge. A vertex may exist in a graph and not belong to an edge.

''V'' and ''E'' are usually taken to be finite, and many of the well-known results are not true (or are rather different) for ''infinite graphs'' because many of the arguments fail in the [[infinite graph|infinite case]]. Moreover, ''V'' is often assumed to be non-empty, but ''E'' is allowed to be the empty set. The ''order'' of a graph is |''V''|, its number of vertices. The ''size'' of a graph is |''E''|, its number of edges. The ''degree'' or ''valency'' of a vertex is the number of edges that connect to it, where an edge that connects to the vertex at both ends (a [[Loop (graph theory)|loop]]) is counted twice.

For an edge {{nobreak|{''x'', ''y''}}}, graph theorists usually use the somewhat shorter notation ''xy''.

===Adjacency relation===
The edges ''E'' of an undirected graph ''G'' induce a symmetric binary relation ~ on ''V'' that is called the ''adjacency relation'' of ''G''. Specifically, for each edge {{nobreak|{''x'', ''y''}}}, the vertices ''x'' and ''y'' are said to be ''adjacent'' to one another, which is denoted {{nobreak|''x'' ~ ''y''}}.

==Types of graphs==

===Distinction in terms of the main definition===
As stated above, in different contexts it may be useful to refine the term ''graph'' with different degrees of generality. Whenever it is necessary to draw a strict distinction, the following terms are used. Most commonly, in modern texts in graph theory, unless stated otherwise, ''graph'' means "undirected simple finite graph" (see the definitions below).

{{multiple image
  | right
  | footer = 
  | width1 = 125
  | image1 = Directed.svg
  | caption1 = A directed graph.
  | width2 = 125
  | image2 = Undirected.svg
  | caption2 = A [[Graph (discrete mathematics)#Simple graph|simple]] undirected graph with three vertices and three edges. Each vertex has degree two, so this is also a regular graph.
}}

====Undirected graph====
An ''undirected graph'' is a graph in which edges have no orientation. The edge {{nobreak|(''x'', ''y'')}} is identical to the edge {{nobreak|(''y'', ''x'')}}. That is, they are not ordered pairs, but unordered pairs—i.e., sets of two vertices {{nobreak|{''x'', ''y''}}} (or 2-[[multiset]]s in the case of [[Loop (graph theory)|loops]]). The maximum number of edges in an undirected graph without a loop is {{nobreak|''n''(''n'' − 1)/2}}, where ''n'' is the number of nodes in the graph.

====Directed graph====
{{main|Directed graph}}
A ''directed graph'' or ''digraph'' is a graph in which edges have orientations. It is written as an ordered pair {{nobreak|1=''G'' = (''V'', ''A'')}} (sometimes {{nobreak|1=''G'' = (''V'', ''E'')}}) with
* ''V'' a [[Set (mathematics)|set]] whose [[Element (mathematics)|elements]] are called ''vertices'', ''nodes'', or ''points'';
* ''A'' a set of [[ordered pair]]s of vertices, called ''arrows'', ''directed edges'' (sometimes simply ''edges'' with the corresponding set named ''E'' instead of ''A''), ''directed arcs'', or ''directed lines''.

An arrow {{nobreak|(''x'', ''y'')}} is considered to be directed ''from'' ''x'' ''to'' ''y''; ''y'' is called the ''head'' and ''x'' is called the ''tail'' of the arrow; ''y'' is said to be a ''direct successor'' of ''x'' and ''x'' is said to be a ''direct predecessor'' of ''y''. If a [[Path (graph theory)|path]] leads from ''x'' to ''y'', then ''y'' is said to be a ''successor'' of ''x'' and ''reachable'' from ''x'', and ''x'' is said to be a ''predecessor'' of ''y''. The arrow {{nobreak|(''y'', ''x'')}} is called the ''inverted arrow'' of {{nobreak|(''x'', ''y'')}}.

A directed graph ''G'' is called ''symmetric'' if, for every arrow in ''G'', the corresponding inverted arrow also belongs to ''G''. A symmetric loopless directed graph {{nobreak|1=''G'' = (''V'', ''A'')}} is equivalent to a simple undirected graph {{nobreak|1=''G′'' = (''V'', ''E'')}}, where the pairs of inverse arrows in ''A'' correspond one-to-one with the edges in ''E''; thus the number of edges in ''G′'' is {{nobreak|1={{abs|''E'' }} = {{abs|''A'' }}/2}}, that is half the number of arrows in ''G''.

====Oriented graph====
An ''oriented graph'' is a directed graph in which at most one of {{nobreak|(''x'', ''y'')}} and {{nobreak|(''y'', ''x'')}} may be arrows of the graph. That is, it is a directed graph that can be formed as an [[orientation (graph theory)|orientation]] of an undirected graph. However, some authors use "oriented graph" to mean the same as "directed graph".

====Mixed graph====
{{main|Mixed graph}}
A ''mixed graph'' is a graph in which some edges may be directed and some may be undirected. It is written as an ordered triple {{nobreak|1=''G'' = (''V'', ''E'', ''A'')}} with ''V'', ''E'', and ''A'' defined as above. Directed and undirected graphs are special cases.

====Multigraph====
{{main|Multigraph}}
''[[Multiple edge]]s'' are two or more edges that connect the same two vertices. A ''[[Loop (graph theory)|loop]]'' is an edge (directed or undirected) that connects a vertex to itself; it may be permitted or not, according to the application. In this context, an edge with two different ends is called a ''link''.

A ''multigraph'', as opposed to a [[#Simple graphs|simple graph]], is an undirected graph in which multiple edges (and sometimes loops) are allowed.

Where graphs are defined so as to ''disallow'' both multiple edges and loops, a multigraph is often defined to mean a graph which can have both multiple edges and loops,&lt;ref&gt;For example, see. Bollobás, p. 7 and Diestel, p. 25.&lt;/ref&gt; although many use the term ''[[pseudograph]]'' for this meaning.&lt;ref&gt;Gross (1998), p. 3, Gross (2003), p. 205, Harary, p.10, and Zwillinger, p. 220.&lt;/ref&gt; Where graphs are defined so as to ''allow'' both multiple edges and loops, a multigraph is often defined to mean a graph without loops.&lt;ref&gt;For example, see Balakrishnan, p. 1, Gross (2003), p. 4, and Zwillinger, p. 220.&lt;/ref&gt;

====Simple graph====
A simple graph is an undirected graph with neither [[multiple edges]] nor [[Loop (graph theory)|loops]]. In a simple graph the edges form a ''set'' (rather than a [[multiset]]) and each edge is an unordered pair of ''distinct'' vertices.  Thus, we can define a '''simple graph''' to be a set ''V'' of vertices together with a set ''E'' of edges, which are 2-element subsets of ''V''.

In a simple graph with ''n'' vertices, the degree of every vertex is at most {{nobreak|''n'' − 1}}.

====Quiver====
{{main|Quiver (mathematics)}}
A ''quiver'' or ''multidigraph'' is a directed multigraph. A quiver may have directed loops in it.  Thus, a quiver is a set ''V'' of vertices, a set ''E'' of edges, and two functions &lt;math&gt;s: E \to V&lt;/math&gt;, &lt;math&gt;t: E \to V&lt;/math&gt;.  The map ''s'' assigns to each edge its ''source'' (or ''tail''), while the map ''t'' assigns to each edge its ''target'' (or ''head'').

====Weighted graph====
A ''weighted graph'' is a graph in which a number (the weight) is assigned to each edge.&lt;ref&gt;{{cite book|last1=Fletcher|first1=Peter|last2=Hoyle|first2=Hughes|last3=Patty|first3=C. Wayne|title=Foundations of Discrete Mathematics|year=1991|publisher=PWS-KENT Pub. Co.| location=Boston| isbn=0-53492-373-9| pages=463 | edition=International student|quote=A ''weighted graph'' is a graph in which a number ''w(e)'', called its ''weight'', is assigned to each edge ''e''.}}&lt;/ref&gt; Such weights might represent for example costs, lengths or capacities, depending on the problem at hand. Some authors call such a graph a ''network''.&lt;ref&gt;{{Citation | last=Strang | first=Gilbert | title=Linear Algebra and Its Applications | publisher=Brooks Cole | edition=4th | year=2005 | isbn=0-03-010567-6 | url=https://books.google.com/books?vid=ISBN0030105676 }}&lt;/ref&gt;&lt;ref&gt;{{Citation | last=Lewis | first=John | title=Java Software Structures | publisher=Pearson | edition=4th | year=2013 | isbn=0133250121 | page=405 | url=https://www.amazon.com/Java-Software-Structures-Designing-Using/dp/0133250121 }}&lt;/ref&gt; [[Weighted correlation network analysis|Weighted correlation networks]] can be defined by soft-thresholding the pairwise correlations among variables (e.g. gene measurements). Such graphs arise in many contexts, for example in [[shortest path problem]]s such as the [[traveling salesman problem]].

====Half-edges, loose edges====
In certain situations it can be helpful to allow edges with only one end, called ''half-edges'', or no ends, called ''loose edges''; see the articles [[Signed graph]]s and [[Biased graph]]s.

===Important classes of graph===

====Regular graph====
{{main|Regular graph}}
A ''regular graph'' is a graph in which each vertex has the same number of neighbours, i.e., every vertex has the same degree. A regular graph with vertices of degree ''k'' is called a ''k''‑regular graph or regular graph of degree ''k''.

====Complete graph====
{{main|Complete graph}}
[[File:Complete graph K5.svg|thumb|125px|A complete graph with 5 vertices. Each vertex has an edge to every other vertex.]]

A ''complete graph'' is a graph in which each pair of vertices is joined by an edge. A complete graph contains all possible edges.

====Finite graph====
A ''finite graph'' is a graph in which the vertex set and the edge set are [[finite set]]s. Otherwise, it is called an ''infinite graph''.

Most commonly in graph theory it is implied that the graphs discussed are finite. If the graphs are infinite, that is usually specifically stated.

====Connected graph====
{{main|Connectivity (graph theory)}}
In an undirected graph, an unordered pair of vertices {{nobreak|{''x'', ''y''}}} is called ''connected'' if a path leads from ''x'' to ''y''. Otherwise, the unordered pair is called ''disconnected''.

A ''connected graph'' is an undirected graph in which every unordered pair of vertices in the graph is connected. Otherwise, it is called a ''disconnected graph''.

In a directed graph, an ordered pair of vertices {{nobreak|(''x'', ''y'')}} is called ''strongly connected'' if a directed path leads from ''x'' to ''y''. Otherwise, the ordered pair is called ''weakly connected'' if an undirected path leads from ''x'' to ''y'' after replacing all of its directed edges with undirected edges. Otherwise, the ordered pair is called ''disconnected''.

A ''strongly connected graph'' is a directed graph in which every ordered pair of vertices in the graph is strongly connected. Otherwise, it is called a ''weakly connected graph'' if every ordered pair of vertices in the graph is weakly connected. Otherwise it is called a ''disconnected graph''.

A ''[[k-vertex-connected graph]]'' or ''[[k-edge-connected graph]]'' is a graph in which no set of {{nobreak|''k'' − 1}} vertices (respectively, edges) exists that, when removed, disconnects the graph. A ''k''-vertex-connected graph is often called simply a ''k-connected graph''.

====Bipartite graph====
{{main|Bipartite graph}}
A ''[[bipartite graph]]'' is a graph in which the vertex set can be [[Partition of a set|partitioned]] into two sets, ''W'' and ''X'', so that no two vertices in ''W'' share a common edge and no two vertices in ''X'' share a common edge. Alternatively, it is a graph with a [[chromatic number]] of 2.

In a [[complete bipartite graph]], the vertex set is the union of two disjoint sets, ''W'' and ''X'', so that every vertex in ''W'' is adjacent to every vertex in ''X'' but there are no edges within ''W'' or ''X''.

====Path graph====
{{main|Path graph}}
A ''path graph'' or ''linear graph'' of order {{nobreak|''n'' ≥ 2}} is a graph in which the vertices can be listed in an order ''v''&lt;sub&gt;1&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt;, …, ''v''&lt;sub&gt;''n''&lt;/sub&gt; such that the edges are the {{nobreak|{''v''&lt;sub&gt;''i''&lt;/sub&gt;, ''v''&lt;sub&gt;''i''+1&lt;/sub&gt;}}} where ''i'' = 1, 2, …, ''n'' − 1. Path graphs can be characterized as connected graphs in which the degree of all but two vertices is 2 and the degree of the two remaining vertices is 1. If a path graph occurs as a [[Glossary of graph theory#Subgraphs|subgraph]] of another graph, it is a [[Path (graph theory)|path]] in that graph.

====Planar graph====
{{main|Planar graph}}
A ''planar graph'' is a graph whose vertices and edges can be drawn in a plane such that no two of the edges intersect.

====Cycle graph====
{{main|Cycle graph}}
A ''cycle graph'' or ''circular graph'' of order {{nobreak|''n'' ≥ 3}} is a graph in which the vertices can be listed in an order ''v''&lt;sub&gt;1&lt;/sub&gt;, ''v''&lt;sub&gt;2&lt;/sub&gt;, …, ''v''&lt;sub&gt;''n''&lt;/sub&gt; such that the edges are the {{nobreak|{''v''&lt;sub&gt;''i''&lt;/sub&gt;, ''v''&lt;sub&gt;''i''+1&lt;/sub&gt;}}} where ''i'' = 1, 2, …, ''n'' − 1, plus the edge {{nobreak|{''v''&lt;sub&gt;''n''&lt;/sub&gt;, ''v''&lt;sub&gt;1&lt;/sub&gt;}}}. Cycle graphs can be characterized as connected graphs in which the degree of all vertices is 2. If a cycle graph occurs as a subgraph of another graph, it is a cycle or circuit in that graph.

====Tree====
{{main|Tree (graph theory)}}
A ''tree'' is a connected graph with no cycles.

A ''forest'' is a graph with no cycles, i.e. the disjoint union of one or more trees.

====Advanced classes====
More advanced kinds of graphs are:
* [[Petersen graph]] and its generalizations;
* [[perfect graph]]s;
* [[cograph]]s;
* [[chordal graph]]s;
* other graphs with large [[Graph automorphism|automorphism groups]]: [[Vertex-transitive graph|vertex-transitive]], [[Arc-transitive graph|arc-transitive]], and [[distance-transitive graph]]s;
* [[strongly regular graph]]s and their generalizations [[distance-regular graph]]s.

==Properties of graphs==
{{see also|Glossary of graph theory|Graph property}}
Two edges of a graph are called ''adjacent'' if they share a common vertex. Two arrows of a directed graph are called ''consecutive'' if the head of the first one is the tail of the second one. Similarly, two vertices are called ''adjacent'' if they share a common edge (''consecutive'' if the first one is the tail and the second one is the head of an arrow), in which case the common edge is said to ''join'' the two vertices. An edge and a vertex on that edge are called ''incident''.

The graph with only one vertex and no edges is called the ''trivial graph''. A graph with only vertices and no edges is known as an ''edgeless graph''. The graph with no vertices and no edges is sometimes called the ''[[null graph]]'' or ''empty graph'', but the terminology is not consistent and not all mathematicians allow this object.

Normally, the vertices of a graph, by their nature as elements of a set, are distinguishable. This kind of graph may be called ''vertex-labeled''. However, for many questions it is better to treat vertices as indistinguishable. (Of course, the vertices may be still distinguishable by the properties of the graph itself, e.g., by the numbers of incident edges.) The same remarks apply to edges, so graphs with labeled edges are called ''edge-labeled''. Graphs with labels attached to edges or vertices are more generally designated as ''labeled''. Consequently, graphs in which vertices are indistinguishable and edges are indistinguishable are called ''unlabeled''. (Note that in the literature, the term ''labeled'' may apply to other kinds of labeling, besides that which serves only to distinguish different vertices or edges.)

The [[category theory|category]] of all graphs is the [[slice category]] Set ↓ ''D'' where ''D'': Set → Set is the [[functor]] taking a set ''s'' to ''s'' × ''s''.

==Examples==
[[File:6n-graf.svg|thumb|A graph with six nodes.]]

* The diagram at right is a graphic representation of the following graph:
:: {{nobreak|1=''V'' = {1, 2, 3, 4, 5, 6}}};
:: {{nobreak|1=''E'' = {{1, 2}, {1, 5}, {2, 3}, {2, 5}, {3, 4}, {4, 5}, {4, 6}}}}.
* In [[category theory]], a [[category (mathematics)|small category]] can be represented by a directed multigraph in which the objects of the category are represented as vertices and the [[morphism]]s as directed edges. Then, the [[functor]]s between categories induce some, but not necessarily all, of the [[digraph morphism]]s of the graph.
* In [[computer science]], directed graphs are used to represent knowledge (e.g., [[conceptual graph]]), [[finite state machine]]s, and many other discrete structures.
* A [[binary relation]] ''R'' on a set ''X'' defines a directed graph. An element ''x'' of ''X'' is a direct predecessor of an element ''y'' of ''X'' if and only if ''xRy''.
* A directed graph can model information networks such as [[Twitter]], with one user following another.&lt;ref name="snatwitter"&gt;{{Cite journal | volume = 3| issue = 1| last = Grandjean| first = Martin| title = A social network analysis of Twitter: Mapping the digital humanities community| journal =Cogent Arts &amp; Humanities| date = 2016| pages = 1171458| url = http://cogentoa.tandfonline.com/doi/full/10.1080/23311983.2016.1171458| doi=10.1080/23311983.2016.1171458}}&lt;/ref&gt;&lt;ref name="twitterwtf"&gt;Pankaj Gupta, Ashish Goel, Jimmy Lin, Aneesh Sharma, Dong Wang, and Reza Bosagh Zadeh [http://dl.acm.org/citation.cfm?id=2488433 WTF: The who-to-follow system at Twitter], ''Proceedings of the 22nd international conference on World Wide Web''. {{doi|10.1145/2488388.2488433}}.&lt;/ref&gt;
*Particularly regular examples of directed graphs are given by the [[Cayley graph]]s of finitely-generated groups, as well as [[Schreier coset graph]]s

==Graph operations==
{{main|Graph operations}}
There are several operations that produce new graphs from initial ones, which might be classified into the following categories:
* ''unary operations'', which create a new graph from an initial one, such as:
** [[edge contraction]],
** [[line graph]],
** [[dual graph]],
** [[complement graph]],
** [[graph rewriting]];
* ''binary operations'', which create a new graph from two initial ones, such as:
** [[disjoint union of graphs]],
** [[cartesian product of graphs]],
** [[tensor product of graphs]],
** [[strong product of graphs]],
** [[lexicographic product of graphs]],
** [[series-parallel graph]]s.

==Generalizations==
In a [[hypergraph]], an edge can join more than two vertices.

An undirected graph can be seen as a [[simplicial complex]] consisting of 1-[[simplex|simplices]] (the edges) and 0-simplices (the vertices). As such, complexes are generalizations of graphs since they allow for higher-dimensional simplices.

Every graph gives rise to a [[matroid]].

In [[model theory]], a graph is just a [[structure (model theory)|structure]]. But in that case, there is no limitation on the number of edges: it can be any [[cardinal number]], see [[continuous graph]].

In [[computational biology]], [[power graph analysis]] introduces power graphs as an alternative representation of undirected graphs.

In [[geographic information systems]], [[geometric networks]] are closely modeled after graphs, and borrow many concepts from [[graph theory]] to perform spatial analysis on road networks or utility grids.

==See also==
* [[Conceptual graph]]
* [[Dual graph]]
* [[Graph (abstract data type)]]
* [[Graph database]]
* [[Graph drawing]]
* [[List of graph theory topics]]
* [[List of publications in mathematics#Graph theory|List of publications in graph theory]]
* [[Network theory]]

==Notes==
{{reflist|30em}}

==References==
* {{cite book|last=Balakrishnan|first=V. K.|title=Graph Theory|publisher=McGraw-Hill|date=1997-02-01|edition=1st|isbn=0-07-005489-4}}
* {{cite book|last=Berge|first=Claude|title=Théorie des graphes et ses applications|publisher=Collection Universitaire de Mathématiques, II|location=Dunod, Paris|year=1958|pages=viii+277|language=French|authorlink=Claude Berge}} Translation: {{cite book|publisher=Wiley|location=Dover, New York|year=2001|origyear=1962|title=-}}
* {{cite book|last=Biggs|first=Norman|title=Algebraic Graph Theory|publisher=Cambridge University Press|year=1993|edition=2nd|isbn=0-521-45897-8}}
* {{cite book|last=Bollobás|first=Béla|title=Modern Graph Theory|publisher=Springer|date=2002-08-12|edition=1st|isbn=0-387-98488-7}}
* {{cite book|last=Bang-Jensen|first=J.|author2=Gutin, G.|title=Digraphs: Theory, Algorithms and Applications|publisher=Springer|year=2000|url=http://www.cs.rhul.ac.uk/books/dbook/}}
* {{Cite book | last1=Diestel | first1=Reinhard | title=Graph Theory | url=http://diestel-graph-theory.com/GrTh.html | publisher=Springer-Verlag | location=Berlin, New York | edition=3rd | isbn=978-3-540-26183-4 | year=2005 | postscript=&lt;!--None--&gt; }}.
* {{cite book|title=Handbook of Combinatorics|editor=Graham, R.L. |editor2=Grötschel, M.|editor2-link= Martin Grötschel |editor3=Lovász, L|publisher=MIT Press|year=1995|isbn=0-262-07169-X}}
* {{cite book|last=Gross|first=Jonathan L.|author2=Yellen, Jay|title=Graph Theory and Its Applications|publisher=CRC Press|date=1998-12-30|isbn=0-8493-3982-0}}
* {{cite book|title=Handbook of Graph Theory|editor=Gross, Jonathan L. |editor2=Yellen, Jay|publisher=CRC|date=2003-12-29|isbn=1-58488-090-2}}
* {{cite book|last=Harary|first=Frank|title=Graph Theory|publisher=Addison Wesley Publishing Company|date=January 1995|isbn=0-201-41033-8}}
* {{cite book|last=Iyanaga|first=Shôkichi|author2=Kawada, Yukiyosi|title=Encyclopedic Dictionary of Mathematics|publisher=MIT Press|year=1977|isbn=0-262-09016-3}}
* {{cite book|last=Zwillinger|first=Daniel|title=CRC Standard Mathematical Tables and Formulae|publisher=Chapman &amp; Hall/CRC|date=2002-11-27|edition=31st|isbn=1-58488-291-3}}

==Further reading==
*{{cite book|last=Trudeau|first=Richard J.|title=Introduction to Graph Theory|year=1993|publisher=[[Dover Publications]]|location=New York|isbn=978-0-486-67870-2|url=http://store.doverpublications.com/0486678709.html|edition=Corrected, enlarged republication.|accessdate=8 August 2012}}

==External links==
{{Library resources box
|by=no
|onlinebooks=no
|others=no
|about=yes
|label=Graph(mathematics)}}

* {{MathWorld | urlname=Graph | title = Graph}}

{{DEFAULTSORT:Graph (Discrete mathematics)}}
[[Category:Graph theory]]</text>
      <sha1>4tomkce14dvrvk0577jveqrzd6r0oh4</sha1>
    </revision>
  </page>
  <page>
    <title>Homological integration</title>
    <ns>0</ns>
    <id>23029956</id>
    <revision>
      <id>764394117</id>
      <parentid>764393386</parentid>
      <timestamp>2017-02-08T18:13:24Z</timestamp>
      <contributor>
        <username>Daniele.tampieri</username>
        <id>2630372</id>
      </contributor>
      <minor/>
      <comment>Minor additions</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2195">{{about|an extension of the theory of the [[Lebesgue integral]] to [[manifold]]s|numerical method|geometric integrator}}
In the [[mathematics|mathematical]] fields of [[differential geometry]] and [[geometric measure theory]], '''homological integration''' or '''geometric integration''' is a method for extending the notion of the [[integral]] to [[manifold]]s.  Rather than functions or [[differential form]]s, the integral is defined over [[current (mathematics)|currents]] on a manifold.

The theory is "homological" because currents themselves are defined by duality with differential forms.  To wit, the space {{math|''D''&lt;sup&gt;''k''&lt;/sup&gt;}} of {{mvar|k}}-currents on a manifold {{mvar|M}} is defined as the [[dual space]], in the sense of [[distribution (mathematics)|distributions]], of the space of {{mvar|k}}-forms {{math|Ω&lt;sup&gt;''k''&lt;/sup&gt;}} on {{mvar|M}}.  Thus there is a pairing between {{mvar|k}}-currents {{mvar|T}} and {{mvar|k}}-forms {{mvar|α}}, denoted here by
:&lt;math&gt;\langle T, \alpha\rangle.&lt;/math&gt;
Under this duality pairing, the [[exterior derivative]] 
:&lt;math&gt;d : \Omega^{k-1} \to \Omega^k&lt;/math&gt;
goes over to a [[boundary operator]]
:&lt;math&gt;\partial : D^k \to D^{k-1} &lt;/math&gt;
defined by
:&lt;math&gt;\langle\partial T,\alpha\rangle = \langle T, d\alpha\rangle&lt;/math&gt;
for all {{math|''α''&amp;nbsp;∈&amp;nbsp;Ω&lt;sup&gt;''k''&lt;/sup&gt;}}.  This is a homological rather than [[cohomology theory|cohomological]] construction.

==References==
*{{citation
|last = Federer
|first = Herbert
|authorlink = Herbert Federer
|title = Geometric measure theory
|publisher = Springer-Verlag New York Inc.
|location = New York
|year = 1969
|pages = xiv+676
|isbn = 978-3-540-60656-7
|series = Die Grundlehren der mathematischen Wissenschaften
|volume = 153 
|mr=0257325
|zbl=0176.00801}}.
*{{citation
|first=H.
|last=Whitney
|author-link=Hassler Whitney
|title=Geometric Integration Theory
|series=Princeton Mathematical Series
|volume=21
|publisher=[[Princeton University Press]] and [[Oxford University Press]]
|place=Princeton, NJ and London
|year=1957
|pages= XV+387
|mr=0087148
|zbl=0083.28204
}}.

[[Category:Definitions of mathematical integration]]
[[Category:Measure theory]]


{{geometry-stub}}</text>
      <sha1>npqhj82rsn2epb15rwoe8ideioiqpvk</sha1>
    </revision>
  </page>
  <page>
    <title>Hyers–Ulam–Rassias stability</title>
    <ns>0</ns>
    <id>30656533</id>
    <revision>
      <id>804403351</id>
      <parentid>801784554</parentid>
      <timestamp>2017-10-08T19:55:12Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>[[Aequationes Mathematicae]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7876">The stability problem of [[functional equation]]s originated from a question of [[Stanisław Ulam]], posed in 1940, concerning the stability of [[group homomorphism]]s. In the next year, Donald H. Hyers&lt;ref&gt;D. H. Hyers, [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1078310/pdf/pnas01627-0030.pdf ''On the stability of the linear functional Equation''], Proc. Natl. Acad. Sci. USA, '''27'''(1941), 222-224.&lt;/ref&gt; gave a partial affirmative answer to the question of Ulam in the context of [[Banach space]]s in the case of ''additive'' mappings, that was the first significant breakthrough and a step toward more solutions in this area. Since then, a large number of papers have been published in connection with various generalizations of Ulam’s problem and Hyers’s theorem. In 1978, [[Themistocles M. Rassias]]&lt;ref&gt;Th. M. Rassias, [https://www.jstor.org/stable/2042795?seq=1 ''On the stability of the linear mapping in Banach spaces''], Proc. Amer. Math. Soc. '''72'''(1978), 297–300.&lt;/ref&gt; succeeded in extending Hyers’s theorem for mappings between Banach spaces by considering an unbounded Cauchy difference&lt;ref&gt;D. H. Hyers, G. Isac and Th. M. Rassias, [http://www.zentralblatt-math.org/zmath/en/advanced/?q=an:0907.39025&amp;format=complete ''Stability of Functional Equations in Several Variables''], [[Birkhäuser Verlag]], Boston, Basel, Berlin, 1998.&lt;/ref&gt; subject to a continuity condition upon the mapping. He was the first to prove the stability of the ''linear mapping''. This result of Rassias attracted several mathematicians worldwide who began to be stimulated to investigate the stability problems of functional equations.

By regarding a large influence of [[Stanislaw Ulam|S. M. Ulam]], D. H. Hyers, and [[Th. M. Rassias]] on the study of stability problems of functional equations, the stability phenomenon proved by Th. M. Rassias led to the development of what is now known as Hyers–Ulam–Rassias stability&lt;ref&gt;''Hyers-Ulam-Rassias stability'', in: Encyclopaedia of Mathematics, Supplement III, M. Hazewinkel (ed.), Kluwer Academic Publishers,  Dordrecht, 2001, pp.194-196.&lt;/ref&gt; of [[functional equation]]s. For an extensive presentation of the stability of functional equations in the context of Ulam's problem, the interested reader is referred to the books by S.-M. Jung&lt;ref&gt;S.-M. Jung, ''Hyers-Ulam-Rassias Stability of Functional Equations in Nonlinear Analysis'', Springer, New York (2011) {{isbn|978-1-4419-9636-7}}.&lt;/ref&gt;, S. Czerwik&lt;ref&gt;S.Czerwik, ''Functional Equations and Inequalities in Several Variables'', World Scientific Publishing Co, Singapore (2002).&lt;/ref&gt;, Y.J. Cho, C. Park, Th.M. Rassias and R. Saadati&lt;ref&gt;Y.J. Cho, C. Park, Th.M. Rassias and R. Saadati, ''Stability of Functional Equations in Banach algebras'', Springer, New York (2015).&lt;/ref&gt;, Y.J. Cho, Th.M. Rassias and R. Saadati&lt;ref&gt;Y.J. Cho, Th.M. Rassias and R. Saadati, ''Stability of Functional Equations in Random Normed Spaces'', Springer, New York (2013).&lt;/ref&gt;, and Pl. Kannappan&lt;ref&gt;Pl. Kannappan, ''Functional Equations and Inequalities with Applications'', Springer, New York (2009).&lt;/ref&gt;, as well as to the following papers &lt;ref&gt;S.-M. Jung, ''Hyers-Ulam-Rassias stability of Jensen's equation and its application'', Proc. Amer. Math. Soc. 126(1998), 3137-3143.&lt;/ref&gt;&lt;ref&gt;S.-M. Jung, ''On the Hyers-Ulam-Rassias stability of a quadratic functional equation'', J. Math. Anal. Appl. 232(1999), 384-393.&lt;/ref&gt;&lt;ref&gt;G.-H. Kim, ''A generalization of Hyers-Ulam-Rassias stability of the G-functional equation'', Math. Inequal. Appl. 10(2007), 351-358.&lt;/ref&gt;&lt;ref&gt;Y.-H. Lee and K.-W. Jun, ''A generalization of the Hyers-Ulam-Rassias stability of the pexider equation'', J. Math. Anal. Appl. 246(2000), 627-638.&lt;/ref&gt;. In 1950, T. Aoki&lt;ref&gt;T. Aoki, [http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.jmsj/1261735234 ''On the stability of the linear transformation in Banach spaces''], J. Math. Soc. Japan, '''2'''(1950), 64-66.&lt;/ref&gt; considered an unbounded Cauchy difference which was generalised later by Rassias to the linear case. This result is known as Hyers–Ulam–Aoki stability of the additive mapping.&lt;ref&gt;L. Maligranda, A result of Tosio Aoki about a generalization of Hyers-Ulam stability of additive functions–a question of priority, [[Aequationes Mathematicae]] 75 (2008), 289-296.&lt;/ref&gt; Aoki (1950) had not considered continuity upon the mapping, whereas Rassias (1978) imposed extra continuity hypothesis which yielded a formally stronger conclusion. 

== References ==
{{Reflist}}

==See also==

* Th. M. Rassias, [http://www.springerlink.com/content/j7660635qh228m81/ ''On the stability of functional equations and a problem of Ulam''], Acta Applicandae Mathematicae, '''62'''(1)(2000), 23-130.
* P. Gavruta,  [http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6WK2-45NSHPB-8F&amp;_user=83473&amp;_coverDate=06%2F15%2F1994&amp;_rdoc=1&amp;_fmt=high&amp;_orig=search&amp;_origin=search&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_acct=C000059671&amp;_version=1&amp;_urlVersion=0&amp;_userid=83473&amp;md5=4ec5782709fa38bc1fe5fa4dd37c83bd&amp;searchtype=a ''A generalization of the Hyers-Ulam-Rassias stability of approximately additive mappings''], J. Math. Anal. Appl. '''184'''(1994), 431–436.
* P. Gavruta and L. Gavruta, ''A new method for the generalized Hyers–Ulam–Rassias stability'', Int. J. Nonlinear Anal. Appl. '''1'''(2010), No. 2, 6 pp.
* J. Chung, [http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6WK2-4DSPR9R-6&amp;_user=83473&amp;_coverDate=12%2F15%2F2004&amp;_rdoc=1&amp;_fmt=high&amp;_orig=search&amp;_origin=search&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_searchStrId=1633114773&amp;_rerunOrigin=google&amp;_acct=C000059671&amp;_version=1&amp;_urlVersion=0&amp;_userid=83473&amp;md5=32f25b33ce19cdf5b0fdf58031a327fc&amp;searchtype=a ''Hyers-Ulam-Rassias stability of Cauchy equation in the space of Schwartz distributions''], J. Math. Anal. Appl. '''300'''(2)(2004), 343 – 350.
* T. Miura,  S.-E. Takahasi, and  G. Hirasawa,  [http://www.emis.de/journals/HOA/JIA/Volume2005_4/441.pdf ''Hyers-Ulam-Rassias stability of Jordan homomorphisms on Banach algebras''],  J.  Inequal. Appl. '''4'''(2005), 435–441.
* A. Najati and C. Park, [http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6WK2-4N25W07-C&amp;_user=83473&amp;_coverDate=11%2F15%2F2007&amp;_rdoc=1&amp;_fmt=high&amp;_orig=search&amp;_origin=search&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_acct=C000059671&amp;_version=1&amp;_urlVersion=0&amp;_userid=83473&amp;md5=cbaa154e49b04219c17b1d34fb1d8a00&amp;searchtype=a ''Hyers–Ulam-Rassias stability of homomorphisms in quasi-Banach algebras associated to the Pexiderized Cauchy functional equation''], J. Math. Anal. Appl. '''335'''(2007), 763–778.
* Th. M. Rassias and J. Brzdek (eds.), ''Functional Equations in Mathematical Analysis'', Springer, New York, 2012, {{isbn|978-1-4614-0054-7}}.
* D. Zhang  and J. Wang, ''On the Hyers-Ulam-Rassias stability of Jensen’s equation'', Bull. Korean Math. Soc.  '''46'''(4)(2009), 645–656.
* T. Trif,  [http://www.sciencedirect.com/science?_ob=ArticleURL&amp;_udi=B6WK2-45F4YP5-4R&amp;_user=83473&amp;_coverDate=10%2F15%2F2000&amp;_rdoc=1&amp;_fmt=high&amp;_orig=search&amp;_origin=search&amp;_sort=d&amp;_docanchor=&amp;view=c&amp;_acct=C000059671&amp;_version=1&amp;_urlVersion=0&amp;_userid=83473&amp;md5=0f0a94d79a0f7952e1b542260130d730&amp;searchtype=a ''Hyers-Ulam-Rassias stability of a Jensen type functional equation''], J. Math. Anal. Appl. '''250'''(2000), 579–588.
* Pl. Kannappan, ''Functional Equations and Inequalities with Applications'', Springer, New York, 2009, {{isbn|978-0-387-89491-1}}.
* P. K. Sahoo and Pl. Kannappan, ''Introduction to Functional Equations'', CRC Press, Chapman &amp; Hall Book, Florida, 2011, {{isbn|978-1-4398-4111-2}}.
* W. W. Breckner and T. Trif, ''Convex Functions and Related Functional Equations. Selected Topics'',  Cluj University Press, Cluj, 2008.

{{DEFAULTSORT:Hyers-Ulam-Rassias Stability}}
[[Category:Mathematical analysis]]
[[Category:Functional equations]]
[[Category:Functional analysis]]</text>
      <sha1>5c8mkia9htzj80kpwqw7yffc6zst5az</sha1>
    </revision>
  </page>
  <page>
    <title>Illumination problem</title>
    <ns>0</ns>
    <id>30115275</id>
    <revision>
      <id>867594342</id>
      <parentid>837539569</parentid>
      <timestamp>2018-11-06T18:56:52Z</timestamp>
      <contributor>
        <ip>130.63.92.248</ip>
      </contributor>
      <comment>Added positive result about rational polygons.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3515">[[File:Penrose_unilluminable_room.svg|thumb|250px|Roger Penrose's solution of the illumination problem using elliptical arcs (blue) and straight line segments (green), with 3 positions of the single light source (red spot). The purple crosses are the foci of the larger arcs. Lit and unlit regions are shown in yellow and grey, respectively.]]
The '''illumination problem''' is a resolved mathematical problem first posed by [[Ernst Straus]] in the 1950s.&lt;ref name="Weisstein"&gt;{{Cite web
  | last = Weisstein
  | first = Eric W.
  | authorlink = Eric W. Weisstein
  | title = Illumination Problem
  | publisher = Wolfram Research
  | url = http://mathworld.wolfram.com/IlluminationProblem.html
  | accessdate = 19 December 2010}}&lt;/ref&gt; Straus asked if a room with mirrored walls can always be illuminated by a single [[point light source]], allowing for repeated reflection of light off the mirrored walls. Alternatively, the question can be stated as asking that if a [[billiard table]] can be constructed in any required shape, is there a shape possible such that there is a point where it is impossible to {{Cuegloss|Pot|pot}} the [[cue ball|billiard ball]] in a {{Cuegloss|Pocket|pocket}} at another point, assuming the ball is point-like and continues infinitely rather than stopping due to [[friction]].

The problem was first solved in 1958 by [[Roger Penrose]] using ellipses to form the ''Penrose unilluminable room''.&lt;ref name="Weisstein"/&gt; He showed there exists a room with curved walls that must always have dark regions if lit only by a single point source. This problem was also solved for [[polygonal]] rooms by George Tokarsky in 1995 for 2 dimensions, which showed there exists an unilluminable polygonal 26-sided room with a "dark spot" which is not illuminated from another point in the room, even allowing for repeated reflections.&lt;ref&gt;{{Cite journal
  | last = Tokarsky
  | first = George
  | title = Polygonal Rooms Not Illuminable from Every Point
  | journal = American Mathematical Monthly
  | volume = 102
  | issue = 10
  | pages = 867–879
  | publisher = Mathematical Association of America
  | location = University of Alberta, Edmonton, Alberta, Canada
  | date = December 1995
  | jstor = 2975263
  | doi=10.2307/2975263}}&lt;/ref&gt; This was a borderline case, however, since a finite number of dark ''points'' (rather than regions) are unilluminable from any given position of the point source. An improved solution was put forward by D. Castro in 1997, with a 24-sided room with the same properties.&lt;ref&gt;{{Cite journal
  | last = Castro
  | first = David
  | title = Corrections
  | journal = [[Quantum Magazine]]
  | volume = 7
  | issue = 3
  | pages = 42
  | publisher = Springer-Verlag
  | location = Washington DC
  | date = January–February 1997}}&lt;/ref&gt;

[[Image:Tokarsky_Castro_illumination_problem.svg|thumb|center| Solutions to the illumination problem by George W Tokarsky (26 sides) and D Castro (24 sides).]]

In 2016, Lelièvre, Monteil and Weiss showed that a light source in a polygonal room whose angles (in degrees) are all rational numbers will illuminate the entire polygon, with the possible exception of a finite number of points.&lt;ref&gt;{{cite journal |last1=Lelièvre |first1=Samuel |last2=Monteil |first2=Thierry |last3=Weiss |first3=Barak |title=Everything is illuminated |journal=Geometry &amp; Topology |date=4 July 2016 |volume=20 |issue=3 |pages=1737–1762 |doi=10.2140/gt.2016.20.1737 }}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Mathematical problems]]</text>
      <sha1>3xxi7qct602p69l0bqg1k2x0vljm3iy</sha1>
    </revision>
  </page>
  <page>
    <title>Iverson bracket</title>
    <ns>0</ns>
    <id>1721092</id>
    <revision>
      <id>863348852</id>
      <parentid>842586394</parentid>
      <timestamp>2018-10-10T06:30:10Z</timestamp>
      <contributor>
        <username>Daviddwd</username>
        <id>14327137</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7394">In [[mathematics]], the '''Iverson bracket''', named after [[Kenneth E. Iverson]]&lt;!-- mentioned here so it's clear that it's an upper-case 'i' not an 'l'. --&gt;, is a notation that 
generalises the [[Kronecker delta]]. It converts any [[Logic|logical proposition]] into a number that is 1 if the proposition is satisfied, and 0 otherwise, and is generally written 
by putting the proposition inside square brackets:
:&lt;math&gt;[P] = \begin{cases} 1 &amp; \text{if } P \text{ is true;} \\ 0 &amp; \text{otherwise,} \end{cases}&lt;/math&gt;
where {{math|''P''}} is a [[statement (logic)|statement]] that can be true or false.

In the context of [[summation]], the notation can be used to write any sum as an infinite sum without limits: 
If &lt;math&gt;P(k)&lt;/math&gt; is any
property of the integer &lt;math&gt;k&lt;/math&gt;,

:&lt;math&gt;\sum_kf(k)\,[P(k)] = \sum_{P(k)}f(k).&lt;/math&gt;

Note that by this convention, a summand &lt;math&gt;f(k)[\textbf{false}]&lt;/math&gt; must evaluate to 0 regardless of whether &lt;math&gt;f(k)&lt;/math&gt; is defined.
Likewise for [[Product (mathematics)|products]]:

:&lt;math&gt;\prod_kf(k)^{[P(k)]} = \prod_{P(k)}f(k).&lt;/math&gt;

The notation was originally introduced by [[Kenneth E. Iverson]] in his programming language [[APL (programming language)|APL]],&lt;ref name=APL&gt;{{cite book|author=Kenneth E. Iverson|date=1962|title=A Programming Language|page=11|publisher=Wiley|url=http://www.jsoftware.com/papers/APL.htm|accessdate=7 April 2016}}&lt;/ref&gt;&lt;ref&gt;[[Ronald Graham]], [[Donald Knuth]], and [[Oren Patashnik]]. ''[[Concrete Mathematics]]'', Section 2.2: Sums and Recurrences.&lt;/ref&gt; though restricted to single relational operators enclosed in parentheses, while the generalisation to arbitrary statements,  notational restriction to square brackets, and applications to summation, was advocated by [[Donald Knuth]] to avoid ambiguity in parenthesized logical expressions.&lt;ref name=TNN&gt;Donald Knuth, "Two Notes on Notation", ''[[American Mathematical Monthly]]'', Volume 99, Number 5, May 1992, pp.&amp;nbsp;403–422. ([http://www-cs-faculty.stanford.edu/~knuth/papers/tnn.tex.gz TeX], {{arxiv|math/9205211}}).&lt;/ref&gt;

==Properties==
There is a direct correspondence between arithmetic on Iverson brackets, logic, and set operations. For instance, let ''A'' and ''B'' be sets and &lt;math&gt;P(k_1,\dots)&lt;/math&gt; any property of integers; then we have

:&lt;math&gt;[P \land Q] = [P][Q], \qquad [ \neg P ] = 1 - [P].&lt;/math&gt;

:&lt;math&gt;[P \lor Q] = [P] + [Q] - [P][Q].&lt;/math&gt;

:&lt;math&gt;[k\in A]+[k\in B]=[k\in A\cup B]+[k\in A\cap B].&lt;/math&gt;

:&lt;math&gt;[x \in A \cap B] = [x \in A] [x \in B].&lt;/math&gt;

:&lt;math&gt;[\forall m \ . \ P(k,m)]= \prod_m [P(k,m)].&lt;/math&gt;

:&lt;math&gt;[\exists m \ . \ P(k,m)]=\min \Bigl(1,\sum_m [P(k,m)]\Bigr) = 1 - \prod_m \Bigl( 1-[P(k,m)] \Bigr).&lt;/math&gt;

:&lt;math&gt;\# \{ m \mid P(k,m)\} =\sum_m [P(k,m)].&lt;/math&gt;

==Examples==

The notation allows moving boundary conditions of summations (or integrals) as a separate factor into the summand, freeing up space around the summation operator, but more importantly allowing it to be manipulated algebraically.

===Double-counting rule=== &lt;!-- is there a better name for this ? might be confused with combinatorics... --&gt;
We mechanically derive a well-known sum manipulation rule using Iverson brackets:

:&lt;math&gt;\begin{align}
\sum_{k\in A}f(k)+\sum_{k\in B}f(k)
&amp;=\sum_kf(k)\,[k\in A]+\sum_kf(k)\,[k\in B]\\
&amp;=\sum_kf(k)\,([k\in A]+[k\in B])
\\&amp;=\sum_kf(k)\,([k\in A\cup B]+[k\in A\cap B])
\\&amp;=\sum_{k\in A\cup
B}f(k)\ +\sum_{k\in A\cap B}f(k).
\end{align}
&lt;/math&gt;

===Summation interchange===
The well-known rule &lt;math&gt;\textstyle\sum_{j=1}^n\,\sum_{k=1}^jf(j,k)=\sum_{k=1}^n\,\sum_{j=k}^nf(j,k)&lt;/math&gt; is likewise easily derived:
:&lt;math&gt;\begin{align}
\sum_{j=1}^n\,\sum_{k=1}^jf(j,k)
  &amp;=\sum_{j,k}f(j,k)\,[1\leq j\leq n]\,[1\leq k\leq j]
\\&amp;=\sum_{j,k}f(j,k)\,[1\leq k\leq j\leq n]
\\&amp;=\sum_{j,k}f(j,k)\,[1\leq k\leq n]\,[k\leq j\leq n]

\\&amp;=\sum_{k=1}^n\,\sum_{j=k}^nf(j,k).
\end{align}
&lt;/math&gt;

===Counting===
For instance, the [[Euler phi function]] that counts the number of positive integers up to ''n'' which are [[coprime]] to ''n'' can be expressed by
: &lt;math&gt; \phi(n)=\sum_{i=1}^{n}[\gcd(i,n)=1],\qquad\text{for }n\in\mathbb N^+.&lt;/math&gt;

===Simplification of special cases===
Another use of the Iverson bracket is to simplify equations with special cases. For example, the formula
:&lt;math&gt;\sum_{1\le k\le n \atop \gcd(k,n)=1}\!\!k = \frac{1}{2}n\varphi(n)&lt;/math&gt;

is valid for {{math|''n'' &amp;gt; 1}} but is off by {{sfrac|1|2}} for {{math|''n'' {{=}} 1}}. To get an identity valid for all positive integers {{math|''n''}} (i.e., all values for which &lt;math&gt;\phi(n)&lt;/math&gt; is defined), a correction term involving the Iverson bracket may be added:

:&lt;math&gt;\sum_{1\le k\le n \atop \gcd(k,n)=1}\!\!k = \frac{1}{2}n(\varphi(n)+[n=1])&lt;/math&gt;

===Common functions===

Many common functions, especially those with a natural piecewise definition, may be expressed in terms of the Iverson bracket.  The [[Kronecker delta]] notation is a specific case of Iverson notation when the condition is equality. That is,
: &lt;math&gt;\delta_{ij} = [i=j].&lt;/math&gt;

The [[indicator function]], often denoted &lt;math&gt;\mathbf{1}_A(x)&lt;/math&gt;, &lt;math&gt;\mathbf{I}_A(x)&lt;/math&gt; or &lt;math&gt;\chi_A(x)&lt;/math&gt;, is an Iverson bracket with set membership as its condition:
: &lt;math&gt;\mathbf{I}_A(x) = [x\in A]&lt;/math&gt;.

The [[Heaviside step function]], [[sign function]],&lt;ref name=APL/&gt; and absolute value function and are also easily expressed in this notation:
: &lt;math&gt; H(x) = [x &gt; 0]&lt;/math&gt;,
: &lt;math&gt; \sgn(x) = [x &gt; 0] - [x &lt; 0]&lt;/math&gt;,
and
: &lt;math&gt;\begin{align} |x| &amp;= x[x&gt;0]-x[x&lt;0] \\ &amp;= x([x&gt;0]-[x&lt;0]) \\ &amp;= x\cdot\sgn(x).\end{align}&lt;/math&gt;

The comparison functions max and min (returning the larger or smaller of two arguments) may be written as
:&lt;math&gt; \max(x,y) = x[x&gt;y]+y[x\leq y]&lt;/math&gt; and
:&lt;math&gt; \min(x,y) = x[x\leq y]+y[x&gt; y]&lt;/math&gt;.

The [[floor and ceiling functions]] can be expressed as
: &lt;math&gt; \lfloor x \rfloor = \sum_{n} n\cdot [n \le x &lt; n+1]&lt;/math&gt;
and
: &lt;math&gt; \lceil x \rceil = \sum_{n} n\cdot [n-1 &lt; x \le n],&lt;/math&gt;
where the index &lt;math&gt;n&lt;/math&gt; of summation is understood to range over all the integers.

The [[ramp function]] can be expressed
:&lt;math&gt;R(x) = x\cdot[x\geq 0].&lt;/math&gt;

The [[Trichotomy (mathematics)|trichotomy]] of the reals is equivalent to the following identity:
:&lt;math&gt;[a &lt; b] + [a = b] + [a &gt; b] = 1. &lt;/math&gt;

The [[Möbius function]] has the property (and can be defined by recurrence as&lt;ref&gt;[[Ronald Graham]], [[Donald Knuth]], and [[Oren Patashnik]]. ''[[Concrete Mathematics]]'', Section 4.9: Phi and Mu.&lt;/ref&gt;)

:&lt;math&gt;\sum_{d|n} \mu(d) \ = \  [n=1].&lt;/math&gt;

==Formulation in terms of usual functions==

In the 1830s, [[Guglielmo Libri Carucci dalla Sommaja]] used &lt;math&gt;0^{0^x}&lt;/math&gt; as a replacement for what would now be written &lt;math&gt;[x&gt;0]&lt;/math&gt;, as well as variants
such as &lt;math&gt;(1-0^{0^{-x}})(1-0^{0^{x-a}})&lt;/math&gt; for &lt;math&gt;[0\leq x\leq a]&lt;/math&gt;.&lt;ref name=TNN/&gt; Indeed, following the [[Zero to the power of zero|usual conventions]], those quantities are equal where defined: &lt;math&gt;0^{0^x}&lt;/math&gt; is 1 if ''x'' &gt; 0, 0 if ''x'' = 0, and undefined otherwise.

==See also ==
* [[Boolean function]]
*[[Type conversion]] in computer programming: many [[Programming language|languages]] allow numeric or [[Pointer (computer programming)|pointer]] quantities to be used as [[Boolean data type|boolean quantities]]

==References==
{{reflist}}

[[Category:Mathematical notation]]</text>
      <sha1>heypw6wxpdw81xrphpgdwezcan5i49e</sha1>
    </revision>
  </page>
  <page>
    <title>Kubilius model</title>
    <ns>0</ns>
    <id>57124645</id>
    <revision>
      <id>836635795</id>
      <parentid>836635755</parentid>
      <timestamp>2018-04-15T23:40:34Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>/* top */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2367">{{See also|Probabilistic number theory}}

In mathematics, the '''Kubilius model''' relies on a clarification and extension of a finite probability space on which the behaviour of [[additive arithmetic function]]s can be modeled by sum of [[independence (probability theory)|independent]] [[random variable]]s.&lt;ref&gt;Edited by B. Grigelionis, J. Kubilius, H. Pragarauskas and V. Statulevicius {{Google books|9UMOvAsTXVkC|keywords="Kubilius model"|Probability Theory and Mathematical Statistics. Proceedings of the Sixth Vilnius Conference(1993)|page=674}}&lt;/ref&gt;

The method was introduced in [[Jonas Kubilius]]'s monograph ''Tikimybiniai metodai skaičių teorijoje'' (published in Lithuanian in 1959)&lt;ref&gt;{{cite web|url=http://old.mii.lt/?siteaction=pages.browse&amp;page=istorija_skerus|title=MATEMATIKA LIETUVOS MOKSLŲ AKADEMIJOJE|accessdate=14 April 2018}}&lt;/ref&gt; / ''Probabilistic Methods in the Theory of Numbers'' (published in English in 1964) .&lt;ref&gt;J.Kubilius {{Google books|2TEJAQAAQBAJ|Probabilistic methods in the Theory of Numbers}}&lt;/ref&gt;

Eugenijus Manstavičius and Fritz Schweiger wrote about Kubilius's work in 1992, "the most impressive work has been done on the statistical theory of arithmetic functions which almost created a new research area called Probabilistic Number Theory. A monograph (''Probabilistic Methods in the Theory of Numbers'') devoted to this topic was translated into English in 1964 and became very influential."&lt;ref&gt;{{cite book |editor1-first=Eugenijus |editor1-last=Manstavičius |editor2-first=Fritz |editor2-last=Schweiger |title=Analytic and probabilistic methods in number theory |url=https://books.google.com/?id=PewI8EsBTWEC |accessdate=2009-04-17 |series=New Trends in Probability and Statistics |volume=2 |year=1992 |publisher=VSP |location=Utrecht |isbn=978-90-6764-094-7 |author=Editors, F. Schweiger and E. Manstavičius. }}&lt;/ref&gt;{{Rp|xi}}

==References==
{{Reflist}}

==Further reading==
* {{cite web | title=Selected publications of Professor Jonas Kubilius | url=http://www.mif.vu.lt/ttsk/bylos/ku/kpubla.html | work= | publisher=Vilnius University | date=March 5, 2001 | accessdate=14 April 2018}}
* {{cite web | title=Biography: Jonas Kubilius | url=http://www-history.mcs.st-andrews.ac.uk/Biographies/Kubilius.html | website=www-history.mcs.st-andrews.ac.uk | accessdate=14 April 2018}}

[[Category:Number theory]]</text>
      <sha1>4xzmevdmugnkeebltywp8ml31570h6w</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Srinivasa Ramanujan</title>
    <ns>0</ns>
    <id>8269328</id>
    <revision>
      <id>866266554</id>
      <parentid>842115456</parentid>
      <timestamp>2018-10-29T09:34:00Z</timestamp>
      <contributor>
        <ip>2401:4900:2671:4D79:B17E:B352:3AFF:4502</ip>
      </contributor>
      <comment>/* Institutions and societies */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1452">{{sources |date=May 2018}}
[[Srinivasa Ramanujan]] (1887 – 1920) is the eponym of all of the topics listed below.

==Mathematics==
*[[Brocard–Ramanujan Diophantine equation]]
*[[Dougall–Ramanujan identity]]
*[[Landau–Ramanujan constant]]
*[[Ramanujan's congruences]]
*[[Hardy–Ramanujan number]]
*[[Ramanujan–Nagell equation]]
*[[Ramanujan–Peterssen conjecture]]
*[[Ramanujan–Skolem theorem]]
*[[Ramanujan–Soldner constant]]
*[[Ramanujan summation]]
*[[Ramanujan theta function]]
*[[Ramanujan graph]]
*[[Ramanujan's tau function]]
*[[Ramanujan's ternary quadratic form]]
*[[Ramanujan prime]]
*[[Ramanujan's constant]]
*[[Ramanujan's lost notebook]]
*[[Ramanujan's sum]]
*[[Rogers–Ramanujan identity]]
*[[Ramanujan magic square]]

==Journals==
*[[Hardy–Ramanujan Journal]]
*[[Journal of the Ramanujan Mathematical Society]]
*[[Ramanujan Journal]]

==Institutions and societies==
*[[Ramanujan College]], [[University of Delhi]]
*[[Ramanujan Institute for Advanced Study in Mathematics]]
*[[Srinivasa Ramanujan Institute of Technology]]
*[[Ramanujan Mathematical Society]]
*[[Srinivasa Ramanujan Centre]]
*[[Srinivasa Ramanujan Concept School]]
*[Ramanujan IT Park, Chennai]]

==Prizes and awards==
*[[Srinivasa Ramanujan Medal]]
*[[SASTRA Ramanujan Prize]]

==Other==
*[[Ramanujan IT City]], [[Chennai]]

==References==
{{reflist}}

[[Category:Lists of things named after mathematicians|Ramanujan]]
[[Category:Srinivasa Ramanujan|*]]</text>
      <sha1>timyy7jzgtevryxhmxx63poiy2fybg0</sha1>
    </revision>
  </page>
  <page>
    <title>Liénard–Chipart criterion</title>
    <ns>0</ns>
    <id>40735675</id>
    <revision>
      <id>843316097</id>
      <parentid>759512664</parentid>
      <timestamp>2018-05-28T09:54:40Z</timestamp>
      <contributor>
        <ip>185.24.187.196</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2354">In [[Control theory|control system theory]], the '''Liénard–Chipart criterion''' is a [[stability criterion]] modified from the [[Routh–Hurwitz stability criterion]], proposed by [[Alfred-Marie Liénard|A. Liénard]] and M. H. Chipart.&lt;ref name="LC14" &gt;{{cite journal |last=Liénard |first=A. |last2=Chipart |first2=M. H. |year=1914 |title=Sur le signe de la partie réelle des racines d’une équation algébrique |journal=[[Journal de Mathématiques Pures et Appliquées|J. Math. Pures Appl]] |volume=10 |issue=6 |pages=291–346 |doi= }}&lt;/ref&gt; This criterion has a computational advantage over the Routh–Hurwitz criterion because it involves only about half the number of [[determinant]] computations.&lt;ref name="Gantmacher"&gt;{{cite book
|author=[[Felix Gantmacher]]
|title=The Theory of Matrices
|url={{Google books|cyX32q8ZP5cC|The Theory of Matrices|page=220|plainurl=yes}}
|year=2000
|publisher=American Mathematical Society
|isbn=0-8218-2664-6
|pages=221–225}}&lt;/ref&gt;

== Algorithm ==

The Routh–Hurwitz stability criterion says that a [[necessary and sufficient]] condition for all the roots of the polynomial with real coefficients

::&lt;math&gt;f(z) = a_0 z^n + a_1 z^{n-1} + \cdots + a_n \, (a_0 &gt; 0) &lt;/math&gt;

to have negative real parts (i.e. &lt;math&gt;f&lt;/math&gt; is Hurwitz stable) is that

::&lt;math&gt; \Delta_1 &gt; 0,\, \Delta_2 &gt; 0, \ldots, \Delta_n &gt; 0, &lt;/math&gt;

where &lt;math&gt; \Delta_i &lt;/math&gt; is the ''i''-th [[principal minor]] of the [[Hurwitz matrix]] associated with &lt;math&gt;f&lt;/math&gt;.

Using the same notation as above, the Liénard–Chipart criterion is that &lt;math&gt;f&lt;/math&gt; is Hurwitz-stable if and only if any one of the four conditions is satisfied:
# &lt;math&gt; a_n&gt;0,a_{n-2}&gt;0, \ldots;\, \Delta_{1}&gt;0,\Delta_3&gt;0,\ldots&lt;/math&gt;
# &lt;math&gt; a_n&gt;0,a_{n-2}&gt;0, \ldots;\, \Delta_{2}&gt;0,\Delta_4&gt;0,\ldots&lt;/math&gt;
# &lt;math&gt; a_n&gt;0,a_{n-1}&gt;0,a_{n-3} &gt;0, \ldots;\, \Delta_1&gt;0,\Delta_3&gt;0,\ldots&lt;/math&gt;
# &lt;math&gt; a_n&gt;0,a_{n-1}&gt;0,a_{n-3} &gt;0, \ldots;\, \Delta_2&gt;0,\Delta_4&gt;0,\ldots&lt;/math&gt;

Hence one can see that by choosing one of these conditions, the number of determinants required to be evaluated is reduced.

== References ==

{{reflist}}

== External links ==

* {{SpringerEOM|id=Li%C3%A9nard-Chipart_criterion&amp;oldid=23382|title=Liénard–Chipart criterion}}

{{DEFAULTSORT:Lienard-Chipart criterion}}
[[Category:Stability theory]]


{{applied-math-stub}}</text>
      <sha1>k25tj3leuhpkabcgzugcpml163dw4f1</sha1>
    </revision>
  </page>
  <page>
    <title>Lucky numbers of Euler</title>
    <ns>0</ns>
    <id>14557383</id>
    <revision>
      <id>869651089</id>
      <parentid>869642912</parentid>
      <timestamp>2018-11-19T22:46:19Z</timestamp>
      <contributor>
        <username>PrimeHunter</username>
        <id>551300</id>
      </contributor>
      <comment>Undid revision 869642912 by [[Special:Contributions/Clrclr|Clrclr]] ([[User talk:Clrclr|talk]]). [[OEIS:A196230 ]] mixes in other primes so it doesn't support this list, k^2+k+41 and k^2-k+41 generate the same numbers (for k values off by one) so [[OEIS:A005846]] works as reference for list of prime values</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1852">'''Euler's “lucky” numbers''' are [[positive number|positive]] [[integers]] ''n'' such that for all integers ''k'' with {{nowrap|1 ≤ ''k'' &lt; ''n''}}, the polynomial {{nowrap|''k''&lt;sup&gt;2&lt;/sup&gt; − ''k'' + ''n''}} produces a [[prime number]].

When ''k'' is equal to ''n'', the value cannot be prime anymore since {{nowrap|''n''&lt;sup&gt;2&lt;/sup&gt; − ''n'' + ''n'' &amp;#x3D; ''n''&lt;sup&gt;2&lt;/sup&gt;}} is [[divisible]] by ''n''. Since the polynomial can be rewritten as {{nowrap|''k'' (''k''−1) + ''n''}}, using the integers ''k'' with {{nowrap|−(''n''−1) &lt; ''k'' ≤ 0}} produces the same set of numbers as {{nowrap|1 ≤ ''k'' &lt; ''n''}}.

[[Leonhard Euler]] published the polynomial {{nowrap|''k''&lt;sup&gt;2&lt;/sup&gt; − ''k'' + [[41 (number)|41]]}} which produces prime numbers for all integer values of ''k'' from 1 to 40. Only 7 lucky numbers of Euler exist, namely 1, 2, 3, 5, 11, 17 and 41 {{OEIS|id=A014556}}.

The primes of the form ''k''&lt;sup&gt;2&lt;/sup&gt; - ''k'' + 41 are
:41, 43, 47, 53, 61, 71, 83, 97, 113, 131, 151, 173, 197, 223, 251, 281, 313, 347, 383, 421, 461, 503, 547, 593, 641, 691, 743, 797, 853, 911, 971, ... {{OEIS|id=A005846}}

These numbers are not related to the [[lucky number]]s generated by a sieve algorithm. In fact, the only number which is both lucky and Euler-lucky is 3, since all other Euler-lucky numbers are congruent to 2 mod 3, but no lucky numbers are congruent to 2 mod 3.

==See also==
*[[Heegner number]]
*[[List of topics named after Leonhard Euler]]
*[[Formula for primes]]
*[[Ulam spiral]]

==References==
* [[François Le Lionnais|Le Lionnais, F.]] ''Les Nombres Remarquables''. Paris: Hermann, pp.&amp;nbsp;88 and 144, 1983.

==External links==
* {{MathWorld|urlname=LuckyNumberofEuler|title=Lucky Number of Euler}}

{{Classes of natural numbers}}

[[Category:Integer sequences]]
[[Category:Prime numbers]]
{{number-stub}}</text>
      <sha1>fr0cwjwzisykpi95o367j81sirwpb2f</sha1>
    </revision>
  </page>
  <page>
    <title>Matrix Chernoff bound</title>
    <ns>0</ns>
    <id>34063376</id>
    <revision>
      <id>866931928</id>
      <parentid>855917408</parentid>
      <timestamp>2018-11-02T14:19:46Z</timestamp>
      <contributor>
        <username>Gehenna1510</username>
        <id>34982813</id>
      </contributor>
      <minor/>
      <comment>CS1 error fixed</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24792">For certain applications in [[linear algebra]], it is useful to know properties of the [[probability distribution]] of the largest [[eigenvalue]] of a [[Matrix addition#Entrywise sum|finite sum]] of [[Random matrix|random matrices]].  Suppose &lt;math&gt;\{\mathbf{X}_k\}&lt;/math&gt; is a finite sequence of random matrices.  Analogous to the well-known [[Chernoff bound]] for sums of scalars, a bound on the following is sought for a given parameter&amp;nbsp;''t'':
:&lt;math&gt; \Pr \left \{ \lambda_\max \left ( \sum_k \mathbf{X}_k \right ) \geq t \right \}&lt;/math&gt;
The following theorems answer this general question under various assumptions; these assumptions are named below by analogy to their classical, scalar counterparts.  All of these theorems can be found in {{Harv|Tropp|2010}}, as the specific application of a general result which is derived below.  A summary of related works is given.

==Matrix Gaussian and Rademacher series==

===Self-adjoint matrices case===
Consider a finite sequence &lt;math&gt;\{\mathbf{A}_k\}&lt;/math&gt; of fixed,
self-adjoint matrices with dimension &lt;math&gt;d&lt;/math&gt;, and let &lt;math&gt;\{\xi_k\}&lt;/math&gt; be a finite sequence of [[Independence (probability theory)|independent]] standard [[Normal distribution|normal]] or independent [[Rademacher distribution|Rademacher]] random variables.

Then, for all &lt;math&gt;t\geq0&lt;/math&gt;,
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}} \left( \sum_k \xi_k \mathbf{A}_k \right) \geq t \right\} \leq d \cdot e^{-t^2/2\sigma^2}
&lt;/math&gt;
where
:&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;

===Rectangular case===
Consider a finite sequence &lt;math&gt;\{\mathbf{B}_k\}&lt;/math&gt; of fixed, self-adjoint matrices with dimension &lt;math&gt;d_1\times d_2&lt;/math&gt;, and let &lt;math&gt;\{\xi_k\}&lt;/math&gt; be a finite sequence of independent standard normal or independent Rademacher random variables.
Define the variance parameter
:&lt;math&gt;
\sigma^2 = \max \left\{ \bigg\Vert \sum_k \mathbf{B}_k\mathbf{B}_k^* \bigg\Vert, \bigg\Vert \sum_k \mathbf{B}_k^*\mathbf{B}_k \bigg\Vert \right\}.
&lt;/math&gt;

Then, for all &lt;math&gt;t\geq0&lt;/math&gt;,
:&lt;math&gt;
\Pr \left\{ \bigg\Vert \sum_k \xi_k \mathbf{B}_k \bigg\Vert \geq t \right\} \leq (d_1+d_2) \cdot e^{-t^2/2\sigma^2}.
&lt;/math&gt;

==Matrix Chernoff inequalities==
The classical [[Chernoff bounds]] concern the sum of independent, nonnegative, and uniformly bounded random variables.
In the matrix setting, the analogous theorem concerns a sum of [[positive-semidefinite matrix|positive-semidefinite]] random matrices subjected to a uniform eigenvalue bound.

===Matrix Chernoff I===
Consider a finite sequence &lt;math&gt;\{\mathbf{X}_k\}&lt;/math&gt; of independent, random, self-adjoint matrices with dimension &lt;math&gt;d&lt;/math&gt;.
Assume that each random matrix satisfies
:&lt;math&gt;
\mathbf{X}_k \succeq \mathbf{0} \quad \text{and} \quad \lambda_{\text{max}}(\mathbf{X}_k) \leq R
&lt;/math&gt;
almost surely.

Define
:&lt;math&gt;
\mu_{\text{min}} = \lambda_{\text{min}}\left( \sum_k \mathbb{E}\, \mathbf{X}_k \right) \quad \text{and} \quad
\mu_{\text{max}} = \lambda_{\text{max}}\left( \sum_k \mathbb{E}\, \mathbf{X}_k \right).
&lt;/math&gt;
Then
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{min}}\left( \sum_k \mathbf{X}_k \right) \leq (1-\delta)\mu_{\text{min}}  \right\} \leq d \cdot \left[ \frac{e^{-\delta}}{(1-\delta)^{1-\delta}} \right]^{\mu_{\text{min}}/R} \quad \text{for } \delta\in [0,1]\text{, and}
&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}}\left( \sum_k \mathbf{X}_k \right) \geq (1+\delta)\mu_{\text{max}}  \right\} \leq d \cdot \left[ \frac{e^{\delta}}{(1+\delta)^{1+\delta}} \right]^{\mu_{\text{max}}/R} \quad \text{for } \delta \geq 0.
&lt;/math&gt;

===Matrix Chernoff II===
Consider a sequence &lt;math&gt;\{\mathbf{X}_k:k=1,2,\ldots,n\}&lt;/math&gt; of independent, random, self-adjoint matrices that satisfy
:&lt;math&gt;
\mathbf{X}_k \succeq \mathbf{0} \quad \text{and} \quad \lambda_{\text{max}}(\mathbf{X}_k) \leq 1
&lt;/math&gt;
almost surely.

Compute the minimum and maximum eigenvalues of the average expectation,
:&lt;math&gt;
\bar{\mu}_{\text{min}} = \lambda_{\text{min}}\left( \frac{1}{n} \sum_{k=1}^n \mathbb{E}\, \mathbf{X}_k \right) \quad \text{and} \quad
\bar{\mu}_{\text{max}} = \lambda_{\text{max}}\left( \frac{1}{n} \sum_{k=1}^n \mathbb{E}\, \mathbf{X}_k \right).
&lt;/math&gt;
Then
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{min}}\left( \frac{1}{n} \sum_{k=1}^n \mathbf{X}_k \right) \leq \alpha \right\} \leq d \cdot e^{-nD(\alpha \Vert \bar{\mu}_{\text{min}})} \quad \text{for } 0 \leq \alpha \leq \bar{\mu}_{\text{min}}\text{, and}
&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}}\left( \frac{1}{n} \sum_{k=1}^n \mathbf{X}_k \right) \geq \alpha \right\} \leq d \cdot e^{-nD(\alpha \Vert \bar{\mu}_{\text{max}})} \quad \text{for } \bar{\mu}_{\text{max}} \leq \alpha \leq 1.
&lt;/math&gt;
The binary information divergence is defined as
:&lt;math&gt;
D(a\Vert u) = a \left( \log a - \log u \right) + (1-a)\left( \log(1-a)-\log(1-u) \right)
&lt;/math&gt;
for &lt;math&gt;a,u\in[0,1]&lt;/math&gt;.

==Matrix Bennett and Bernstein inequalities==
In the scalar setting, [[Bernstein inequalities (probability theory)|Bennett and Bernstein inequalities]] describe the upper tail of a sum of independent, zero-mean random variables that are either bounded or [[Heavy-tailed distribution#Subexponential distributions|subexponential]]. In the matrix
case, the analogous results concern a sum of zero-mean random matrices.

===Bounded case===
Consider a finite sequence &lt;math&gt;\{\mathbf{X}_k\}&lt;/math&gt; of independent, random, self-adjoint matrices with dimension &lt;math&gt;d&lt;/math&gt;.
Assume that each random matrix satisfies
:&lt;math&gt;
\mathbf{X}_k \succeq \mathbf{0} \quad \text{and} \quad \lambda_{\text{max}}(\mathbf{X}_k) \leq R
&lt;/math&gt;
almost surely.

Compute the norm of the total variance,
:&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbb{E}\, (\mathbf{X}^2_k) \bigg\Vert.
&lt;/math&gt;

Then, the following chain of inequalities holds for all &lt;math&gt; t \geq 0&lt;/math&gt;:
:&lt;math&gt;
\begin{align}
\Pr \left\{ \lambda_{\text{max}} \left( \sum_k \mathbf{X}_k \right) \geq t \right\} 
&amp; \leq d \cdot \exp \left( -\frac{\sigma^2}{R^2} \cdot h\left( \frac{Rt}{\sigma^2} \right) \right) \\
&amp; \leq d \cdot \exp \left( \frac{-t^2} {\sigma^2+Rt/3} \right) \\
&amp; \leq 
\begin{cases}
d \cdot \exp ( -3t^2/8\sigma^2 ) \quad &amp; \text{for } t\leq \sigma^2/R; \\
d \cdot \exp ( -3t/8R ) \quad &amp; \text{for } t\geq \sigma^2/R. \\
\end{cases}
\end{align}
&lt;/math&gt;
The function &lt;math&gt; h(u) &lt;/math&gt; is defined as &lt;math&gt; h(u) = (1+u) \log (1+u)-u &lt;/math&gt; for &lt;math&gt;u \geq 0&lt;/math&gt;.

===Subexponential case===
Consider a finite sequence &lt;math&gt;\{\mathbf{X}_k\}&lt;/math&gt; of independent, random, self-adjoint matrices with dimension &lt;math&gt;d&lt;/math&gt;.
Assume that 
:&lt;math&gt;
\mathbb{E}\,\mathbf{X}_k = \mathbf{0} \quad \text{and} \quad \mathbb{E}\,(\mathbf{X}_k^p) \preceq \frac{p!}{2}\cdot R^{p-2} \mathbf{A}_k^2
&lt;/math&gt;
for &lt;math&gt;p=2,3,4,\ldots&lt;/math&gt;.

Compute the variance parameter,
:&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;

Then, the following chain of inequalities holds for all &lt;math&gt; t \geq 0&lt;/math&gt;:
:&lt;math&gt;
\begin{align}
\Pr \left\{ \lambda_{\text{max}} \left( \sum_k \mathbf{X}_k \right) \geq t \right\} 
&amp; \leq d \cdot \exp \left( \frac{-t^2/2}{\sigma^2+Rt} \right) \\
&amp; \leq 
\begin{cases}
d \cdot \exp ( -t^2/4\sigma^2 ) \quad &amp; \text{for } t\leq \sigma^2/R; \\
d \cdot \exp ( -t/4R ) \quad &amp; \text{for } t\geq \sigma^2/R. \\
\end{cases}
\end{align}
&lt;/math&gt;

===Rectangular case===
Consider a finite sequence &lt;math&gt;\{\mathbf{Z}_k\}&lt;/math&gt; of independent, random, matrices with dimension &lt;math&gt;d_1\times d_2&lt;/math&gt;.
Assume that each random matrix satisfies
:&lt;math&gt;
\mathbb{E}\,\mathbf{Z}_k = \mathbf{0} \quad \text{and} \quad \Vert \mathbf{Z}_k \Vert \leq R
&lt;/math&gt;
almost surely.
Define the variance parameter
:&lt;math&gt;
\sigma^2 = \max \left\{ \bigg\Vert \sum_k \mathbb{E}\,(\mathbf{Z}_k\mathbf{Z}_k^*) \bigg\Vert, \bigg\Vert \sum_k \mathbb{E}\, (\mathbf{Z}_k^*\mathbf{Z}_k) \bigg\Vert \right\}.
&lt;/math&gt;

Then, for all &lt;math&gt; t \geq 0&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{  \bigg\Vert \sum_k \mathbf{Z}_k \bigg\Vert \geq t \right\} \leq (d_1+d_2) \cdot \exp \left( \frac{-t^2 / 2} {\sigma^2+Rt/3} \right)
&lt;/math&gt;

holds.&lt;ref&gt;'''[[arxiv:1004.4389|User-friendly tail bounds for sums of random matrices]]'''&lt;/ref&gt;

==Matrix Azuma, Hoeffding, and McDiarmid inequalities==

===Matrix Azuma===
The scalar version of [[Azuma's inequality]] states that a scalar [[Martingale (probability theory)|martingale]] exhibits normal concentration about its mean value, and the scale for deviations is controlled by the total maximum squared range of the difference sequence.
The following is the extension in matrix setting.

Consider a finite adapted sequence &lt;math&gt;\{\mathbf{X}_k\}&lt;/math&gt; of self-adjoint matrices with dimension &lt;math&gt;d&lt;/math&gt;, and a fixed sequence &lt;math&gt;\{\mathbf{A}_k\}&lt;/math&gt; of self-adjoint matrices that satisfy
:&lt;math&gt;
\mathbb{E}_{k-1}\,\mathbf{X}_k = \mathbf{0} \quad \text{and} \quad \mathbf{X}_k^2 \preceq \mathbf{A}_k^2 
&lt;/math&gt;
almost surely.

Compute the variance parameter
:&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;

Then, for all &lt;math&gt; t \geq 0&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}} \left( \sum_k \mathbf{X}_k \right) \geq t \right\} \leq d \cdot e^{-t^2/8\sigma^2}
&lt;/math&gt;

The constant 1/8 can be improved to 1/2 when there is additional information available. One case occurs when each summand &lt;math&gt; \mathbf{X}_k &lt;/math&gt; is conditionally symmetric.
Another example requires the assumption that &lt;math&gt; \mathbf{X}_k &lt;/math&gt; commutes almost surely with &lt;math&gt; \mathbf{A}_k &lt;/math&gt;.

===Matrix Hoeffding===
Placing addition assumption that the summands in Matrix Azuma are independent gives a matrix extension of [[Hoeffding's inequality|Hoeffding's inequalities]].

Consider a finite sequence &lt;math&gt;\{\mathbf{X}_k\}&lt;/math&gt; of independent, random, self-adjoint matrices with dimension &lt;math&gt;d&lt;/math&gt;, and let &lt;math&gt;\{\mathbf{A}_k\}&lt;/math&gt; be a sequence of fixed self-adjoint matrices.
Assume that each random matrix satisfies
:&lt;math&gt;
\mathbb{E}\,\mathbf{X}_k = \mathbf{0} \quad \text{and} \quad \mathbf{X}_k^2 \preceq \mathbf{A}_k^2 
&lt;/math&gt;
almost surely.

Then, for all &lt;math&gt; t \geq 0&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}} \left( \sum_k \mathbf{X}_k \right) \geq t \right\} \leq d \cdot e^{-t^2/8\sigma^2}
&lt;/math&gt;
where
:&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;

An improvement of this result was established in {{Harv|Mackey|Jordan|Chen|Farrell|2012}}:
for all &lt;math&gt; t \geq 0&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}} \left( \sum_k \mathbf{X}_k \right) \geq t \right\} \leq d \cdot e^{-t^2/2\sigma^2}
&lt;/math&gt;
where
:&lt;math&gt;
\sigma^2 = \frac{1}{2}\bigg\Vert \sum_k \mathbf{A}^2_k + \mathbb{E}\,\mathbf{X}^2_k  \bigg\Vert
\leq \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;

===Matrix bounded difference (McDiarmid)===
In scalar setting, [[McDiarmid's inequality#McDiarmid's inequality|McDiarmid's inequality]] provides one common way of bounding the differences by applying [[Azuma's inequality]] to a [[Doob martingale]].  A version of the bounded differences inequality holds in the matrix setting.

Let &lt;math&gt;\{Z_k:k=1,2,\ldots,n\}&lt;/math&gt; be an independent, family of random variables, and let &lt;math&gt;\mathbf{H}&lt;/math&gt; be a function that maps &lt;math&gt;n&lt;/math&gt; variables to a self-adjoint matrix of dimension &lt;math&gt;d&lt;/math&gt;.
Consider a sequence &lt;math&gt;\{\mathbf{A}_k\}&lt;/math&gt; of fixed self-adjoint matrices that satisfy
:&lt;math&gt;
\left( \mathbf{H}(z_1,\ldots,z_k,\ldots,z_n) - \mathbf{H}(z_1,\ldots,z'_k,\ldots,z_n) \right)^2 \preceq \mathbf{A}_k^2,
&lt;/math&gt;
where &lt;math&gt;z_i&lt;/math&gt; and &lt;math&gt;z'_i&lt;/math&gt; range over all possible values of &lt;math&gt;Z_i&lt;/math&gt; for each index &lt;math&gt;i&lt;/math&gt;.
Compute the variance parameter
:&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;

Then, for all &lt;math&gt; t \geq 0&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}} \left( \mathbf{H}(\mathbf{z}) - \mathbb{E}\,\mathbf{H}(\mathbf{z}) \right) \geq t \right\} \leq d \cdot e^{-t^2/8\sigma^2},
&lt;/math&gt;
where &lt;math&gt;\mathbf{z}=(Z_1,\ldots,Z_n)&lt;/math&gt;.

An improvement of this result was established in {{harv|Paulin|Mackey|Tropp|2013}} (see also {{harv|Paulin|Mackey|Tropp|2016}}):
for all &lt;math&gt; t \geq 0&lt;/math&gt;
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}} \left( \mathbf{H}(\mathbf{z}) - \mathbb{E}\,\mathbf{H}(\mathbf{z}) \right) \geq t \right\} \leq d \cdot e^{-t^2/\sigma^2},
&lt;/math&gt;
where &lt;math&gt;\mathbf{z}=(Z_1,\ldots,Z_n)&lt;/math&gt; and
&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;

==Survey of related theorems==
The first bounds of this type were derived by {{Harv|Ahlswede| Winter|2003}}.  Recall the [[#Matrix Gaussian and Rademacher series|theorem above for self-adjoint matrix Gaussian and Rademacher bounds]]:
For a finite sequence &lt;math&gt;\{\mathbf{A}_k\}&lt;/math&gt; of fixed,
self-adjoint matrices with dimension &lt;math&gt;d&lt;/math&gt; and for &lt;math&gt;\{\xi_k\}&lt;/math&gt; a finite sequence of [[Independence (probability theory)|independent]] standard [[Normal distribution|normal]] or independent [[Rademacher distribution|Rademacher]] random variables, then 
:&lt;math&gt;
\Pr \left\{ \lambda_{\text{max}} \left( \sum_k \xi_k \mathbf{A}_k \right) \geq t \right\} \leq d \cdot e^{-t^2/2\sigma^2}
&lt;/math&gt;
where
:&lt;math&gt;
\sigma^2 = \bigg\Vert \sum_k \mathbf{A}^2_k \bigg\Vert.
&lt;/math&gt;
Ahlswede and Winter would give the same result, except with 
:&lt;math&gt; \sigma_{AW}^2 = \sum_k \lambda_\max \left(\mathbf{A}_k^2 \right ) &lt;/math&gt;.
By comparison, the &lt;math&gt;\sigma^2&lt;/math&gt; in the theorem above commutes &lt;math&gt;\Sigma&lt;/math&gt; and &lt;math&gt; \lambda_\max&lt;/math&gt;; that is, it is the largest eigenvalue of the sum rather than the sum of the largest eigenvalues.  It is never larger than the Ahlswede–Winter value (by the [[Matrix norm|norm]] [[triangle inequality]]), but can be much smaller.  Therefore, the theorem above gives a tighter bound than the Ahlswede–Winter result.

The chief contribution of {{Harv|Ahlswede|Winter|2003}} was the extension of the Laplace-transform method used to prove the scalar Chernoff bound (see [[Chernoff bound#Theorem for additive form (absolute error)]]) to the case of self-adjoint matrices.  The procedure given in the [[#Derivation and proof|derivation]] below.  All of the recent works on this topic follow this same procedure, and the chief differences follow from subsequent steps.  Ahlswede &amp; Winter use the [[Golden–Thompson inequality]] to proceed, whereas Tropp {{Harv|Tropp|2010}} uses [[Matrix exponential#Lieb's theorem|Lieb's Theorem]].

Suppose one wished to vary the length of the series (''n'') and the dimensions of the
matrices (''d'') while keeping the right-hand side approximately constant.  Then
n must vary approximately as the log of&amp;nbsp;''d''.  Several papers have attempted to establish a bound without a dependence on dimensions.  Rudelson and Vershynin {{Harv|Rudelson|Vershynin|2007}} give a result for matrices which are the outer product of two vectors.  {{Harv|Magen|Zouzias|2010}} [[Chernoff bound#Theorem without the dependency on the dimensions|provide a result without the dimensional dependence for low rank matrices]].  The original result was derived independently from the Ahlswede–Winter approach, but {{Harv|Oliveira|2010b}} proves a similar result using the Ahlswede–Winter approach.

Finally, Oliveira {{Harv|Oliviera|2010a}} proves a result for matrix martingales independently from the Ahlswede–Winter framework.  Tropp {{Harv|Tropp|2011}} slightly improves on the result using the Ahlswede–Winter framework.  Neither result is presented in this article.

==Derivation and proof==

===Ahlswede and Winter===
The Laplace transform argument found in {{Harv|Ahlswede|Winter|2003}} is a significant result in its own right:
Let &lt;math&gt;\mathbf{Y}&lt;/math&gt; be a random self-adjoint matrix.  Then
:&lt;math&gt; \Pr \left \{ \lambda_{\max} ( Y ) \geq t \right \} \leq \inf_{\theta &gt; 0}
\left \{ e^{-\theta t } \cdot \operatorname{E} \left [ \operatorname{tr} e^{\theta \mathbf{Y}} \right ] \right \}.
&lt;/math&gt;

To prove this, fix  &lt;math&gt;\theta &gt; 0&lt;/math&gt;.  Then
:&lt;math&gt; \begin{align} \Pr \left \{ \lambda_{\max} (\mathbf{Y}) \geq t \right \} &amp;= \Pr \left \{ \lambda_{\max} (\mathbf{\theta Y}) \geq \theta t \right \} \\
&amp;= \Pr \left \{ e^{\lambda_{\max} (\theta \mathbf{Y})} \geq e^{\theta t} \right \}\\
&amp;\leq e^{-\theta t} \operatorname{E} e^{\lambda_{\max} (\theta \mathbf{Y})}\\
&amp;\leq e^{-\theta t} \operatorname{E} \operatorname{tr} e^{(\theta \mathbf{Y})}
\end{align}
&lt;/math&gt;
The second-to-last inequality is [[Markov's inequality]].  The last inequality holds since &lt;math&gt; e^{\lambda_{\max} \theta \mathbf{Y}} = \lambda_{\max} e^{\theta \mathbf{Y}} \leq \operatorname{tr} e^{\theta \mathbf{Y}}&lt;/math&gt;.  Since the left-most quantity is independent of &lt;math&gt;\theta&lt;/math&gt;, the infimum over &lt;math&gt;\theta&gt;0&lt;/math&gt; remains an upper bound for it.

Thus, our task is to understand &lt;math&gt;\operatorname{E} \operatorname{tr} e^{\theta \mathbf{Y}}&lt;/math&gt;  Nevertheless, since trace and expectation are both linear, we can commute them, so it is sufficient to consider &lt;math&gt;\operatorname{E} e^{\theta \mathbf{Y}} := \mathbf{M}_\mathbf{Y}(\theta)&lt;/math&gt;, which we call the matrix generating function.  This is where the methods of {{Harv|Ahlswede|Winter|2003}} and {{Harv|Tropp|2010}} diverge.  The immediately following presentation follows {{Harv|Ahlswede|Winter|2003}}.

The [[Golden–Thompson inequality]] implies that 
:&lt;math&gt; \operatorname{tr} \mathbf{M}_{\mathbf{X}_1 + \mathbf{X}_2}(\theta) \leq \operatorname{tr} \left [ \left ( \operatorname{E} e^{\theta \mathbf{X}_1} \right )
\left ( \operatorname{E} e^{\theta \mathbf{X}_2} \right ) \right ] = 
\operatorname{tr} \mathbf{M}_{\mathbf{X}_1} (\theta) \mathbf{M}_{\mathbf{X}_2}(\theta) &lt;/math&gt;, where we used the linearity of expectation several times.
Suppose &lt;math&gt;\mathbf{Y} = \sum_k \mathbf{X}_k&lt;/math&gt;.  We can find an upper bound for &lt;math&gt;\operatorname{tr} \mathbf{M}_{\mathbf{Y}} (\theta)&lt;/math&gt; by iterating this result.  Noting that &lt;math&gt;\operatorname{tr}(\mathbf{AB}) \leq \operatorname{tr}(\mathbf{A}) \lambda_{\max}(\mathbf{B})&lt;/math&gt;, then
:&lt;math&gt; \operatorname{tr} \mathbf{M}_\mathbf{Y} (\theta) \leq 
\operatorname{tr} \left [ \left ( \operatorname{E} e^{\sum_{k=1}^{n-1} \theta \mathbf{X}_k} \right ) \left( \operatorname{E} e^{\theta \mathbf{X}_n} \right ) \right ]
\leq \operatorname{tr} \left ( \operatorname{E} e^{\sum_{k=1}^{n-1} \theta \mathbf{X}_k} \right ) \lambda_{\max} ( \operatorname{E} e^{\theta \mathbf{X}_n}).
&lt;/math&gt;
Iterating this, we get
:&lt;math&gt; \operatorname{tr} \mathbf{M}_\mathbf{Y} (\theta) \leq 
(\operatorname{tr} \mathbf{I}) \left [ \Pi_k \lambda_{\max} (\operatorname{E} e^{\theta \mathbf{X}_k}) \right ] =
d e^{\sum_k \lambda_\max \left ( \log \operatorname{E} e^{\theta \mathbf{X}_k} \right ) } &lt;/math&gt;

So far we have found a bound with an infimum over &lt;math&gt;\theta&lt;/math&gt;.  In turn, this can be bounded.  At any rate, one can see how the Ahlswede–Winter bound arises as the sum of largest eigenvalues.

===Tropp===
The major contribution of {{Harv|Tropp|2010}} is the application of [[Matrix exponential#Lieb's theorem|Lieb's theorem]] where {{Harv|Ahlswede|Winter|2003}} had applied the [[Golden–Thompson inequality]].  Tropp's corollary is the following: If &lt;math&gt;H&lt;/math&gt; is a fixed self-adjoint matrix and &lt;math&gt;X&lt;/math&gt; is a random self-adjoint matrix, then
:&lt;math&gt; \operatorname{E} \operatorname{tr} e^{\mathbf{H}+\mathbf{X}} 
\leq \operatorname{tr} e^{\mathbf{H} + \log( \operatorname{E} e^{\mathbf{X} })} &lt;/math&gt;
Proof: Let &lt;math&gt; \mathbf{Y} = e^\mathbf{X}&lt;/math&gt;.  Then Lieb's theorem tells us that
:&lt;math&gt; f(\mathbf{Y}) = \operatorname{tr} e^{\mathbf{H} + \log(\mathbf{Y})} &lt;/math&gt;
is concave.
The final step is to use [[Jensen's inequality]] to move the expectation inside the function:
:&lt;math&gt; \operatorname{E} \operatorname{tr} e^{\mathbf{H} + \log(\mathbf{Y})} 
\leq \operatorname{tr} e^{\mathbf{H} + \log(\operatorname{E} \mathbf{Y})}. &lt;/math&gt;

This gives us the major result of the paper: the subadditivity of the log of the matrix generating function.

====Subadditivity of log mgf====
Let &lt;math&gt;\mathbf{X}_k&lt;/math&gt; be a finite sequence of independent, random self-adjoint matrices.  Then for all &lt;math&gt;\theta \in \mathbb{R}&lt;/math&gt;,
:&lt;math&gt; \operatorname{tr} \mathbf{M}_{\sum_k \mathbf{X}_k} (\theta)
\leq \operatorname{tr} e^{\sum_k \log \mathbf{M}_{\mathbf{X}_k} (\theta)} &lt;/math&gt;

Proof:  It is sufficient to let &lt;math&gt;\theta=1&lt;/math&gt;.  Expanding the definitions, we need to show that 
:&lt;math&gt; \operatorname{E} \operatorname{tr} e^{\sum_k \theta \mathbf{X}_k } 
  \leq \operatorname{tr} e^{\sum_k \log \operatorname{E} e^{\theta \mathbf{X}_k} }. &lt;/math&gt;

To complete the proof, we use the [[law of total expectation]].  Let &lt;math&gt;\operatorname{E}_k&lt;/math&gt; be the expectation conditioned on &lt;math&gt; \mathbf{X}_1, \ldots, \mathbf{X}_k &lt;/math&gt;.  Since we assume all the &lt;math&gt;\mathbf{X}_i&lt;/math&gt; are independent, 
:&lt;math&gt; \operatorname{E}_{k-1} e^{\mathbf{X}_k} = \operatorname{E} e^{\mathbf{X}_k}. &lt;/math&gt;
Define &lt;math&gt;\mathbf{\Xi}_k = \log \operatorname{E}_{k-1} e^{\mathbf{X}_k} = \log \mathbf{M}_{\mathbf{X}_k}(\theta) &lt;/math&gt;.

Finally, we have
:&lt;math&gt; \begin{align}
\operatorname{E} \operatorname{tr} e^{\sum_{k=1}^n \mathbf{X}_k} &amp; = \operatorname{E}_0 \cdots \operatorname{E}_{n-1} \operatorname{tr} e^{\sum_{k=1}^{n-1} \mathbf{X}_k + \mathbf{X}_n }\\
&amp;\leq \operatorname{E}_0 \cdots \operatorname{E}_{n-2} \operatorname{tr} e^{\sum_{k=1}^{n-1} \mathbf{X}_k + \log(\operatorname{E}_{n-1} e^{\mathbf{X}_n} ) }\\
&amp;= \operatorname{E}_0 \cdots \operatorname{E}_{n-2} \operatorname{tr} e^{\sum_{k=1}^{n-2} \mathbf{X}_k + \mathbf{X}_{n-1} + \mathbf{\Xi}_n} \\
&amp; \vdots\\
&amp; = \operatorname{tr} e^{\sum_{k=1}^n \mathbf{\Xi}_k}
 \end{align} &lt;/math&gt;
where at every step m we use Tropp's corollary with 
:&lt;math&gt; \mathbf{H}_m = \sum_{k=1}^{m-1} \mathbf{X}_k + \sum_{k=m+1}^n \mathbf{\Xi}_k &lt;/math&gt;

====Master tail bound====
The following is immediate from the previous result:
:&lt;math&gt;
\Pr \left \{ \lambda_\max \left ( \sum_k \mathbf{X}_k \right ) \geq t \right \}
\leq \inf_{\theta &gt; 0} \left \{ e^{-\theta t} \operatorname{tr} e^{\sum_k \log \mathbf{M}_{\mathbf{X}_k} (\theta) } \right \}
&lt;/math&gt;
All of the theorems given above are derived from this bound; the theorems consist in various ways to bound the infimum.  These steps are significantly simpler than the proofs given.

==References==
{{Reflist}}
* {{cite journal
 |last1=Ahlswede |first1=R.
 |last2=Winter |first2=A.
 |year=2003
 |title=Strong Converse for Identification via Quantum Channels
 |volume=48 |issue=3 |pages=569–579
 |journal=[[IEEE Transactions on Information Theory]]
 |arxiv=quant-ph/0012127
 |doi=10.1109/18.985947
 |ref=harv
}}
* {{cite journal
|last1=Mackey
|first1=L.
|title=Matrix Concentration Inequalities via the Method of Exchangeable Pairs
|last2= Jordan
|first2=M. I.
|last3= Chen
|first3=R. Y.
|last4=Farrell
|first4=B.
|last5= Tropp
|first5=J. A.
|year=2012
|arxiv=1201.6002
|ref=harv
|doi=10.1214/13-AOP892
|volume=42
|journal=The Annals of Probability
|pages=906–945
}}
* {{cite arxiv
|last1=Magen
|first1=A. | author1-link = Avner Magen
|last2=Zouzias
|first2=A.
|title=Low-Rank Matrix-valued Chernoff Bounds and Approximate Matrix Multiplication
|year=2010
|eprint=1005.2724
|ref=harv
}}
* {{cite arxiv
|last1=Oliveira 
|first1=R.I. 
|year=2010 
|title=Concentration of the adjacency matrix and of the Laplacian in random graphs with independent edges
|eprint=0911.0600
|ref=harv
}}
* {{cite arxiv
|last1=Oliveira
|first1=R.I.
|year=2010
|title=Sums of random Hermitian matrices and an inequality by Rudelson
|eprint=1004.3821
|ref=harv
}}
* {{cite arxiv
|last1=Paulin |first1=D. |last2=Mackey |first2=L. |last3=Tropp |first3=J. A.
|year=2013
|title=Deriving Matrix Concentration Inequalities from Kernel Couplings
|eprint=1305.0612
|ref=harv
}}
* {{cite journal |last1=Paulin |first1=D. |last2=Mackey |first2=L. |last3=Tropp |first3=J. A. |title=Efron–Stein inequalities for random matrices |journal=The Annals of Probability |date=2016 |volume=44 |issue=5 |pages=3431–3473 |doi=10.1214/15-AOP1054 |ref=harv|arxiv=1408.3470 }}
* {{cite journal
|last1=Rudelson
|first1=M.
|last2=Vershynin
|first2=R.
|title=Sampling from large matrices: an approach through geometric functional analysis
|journal=J. Assoc. Comput. Mach.
|volume=54
|edition=4
|year=2007
|arxiv=math/9608208
|ref=harv
|bibcode=1996math......8208R
}}
* {{cite arxiv
|last1=Tropp
|first1=J.
|year=2011
|title=Freedman's inequality for matrix martingales
|eprint=1101.3039
|ref=harv
}}
* {{cite journal
 |last1=Tropp |first1=J.
 |year=2010
 |title=User-friendly tail bounds for sums of random matrices
 |arxiv=1004.4389
 |ref=harv
 |doi=10.1007/s10208-011-9099-z
 |volume=12
 |journal=Foundations of Computational Mathematics
 |pages=389–434
}}

[[Category:Linear algebra]]</text>
      <sha1>rlqqeausnxuwg6us05qm0ksolhvjwcc</sha1>
    </revision>
  </page>
  <page>
    <title>Mean dependence</title>
    <ns>0</ns>
    <id>24836552</id>
    <revision>
      <id>856533676</id>
      <parentid>833105138</parentid>
      <timestamp>2018-08-25T22:25:43Z</timestamp>
      <contributor>
        <username>Loraof</username>
        <id>22399950</id>
      </contributor>
      <comment>Edition number matters since specific pages are given in text.  Undid revision 833105138 by [[Special:Contributions/211.19.65.127|211.19.65.127]] ([[User talk:211.19.65.127|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1680">In [[probability theory]], a [[random variable]] ''Y'' is said to be '''mean independent''' of random variable ''X'' [[if and only if]] its [[conditional mean]] E(''Y''&amp;nbsp;|&amp;nbsp;''X''=''x'') equals its (unconditional) [[expected value|mean]] E(''Y'') for all ''x'' such that the probability that ''X'' = ''x'' is not zero.  ''Y'' is said to be '''mean dependent''' on ''X'' if ''E''(''Y''&amp;nbsp;|&amp;nbsp;''X''=''x'') is not constant for all ''x'' for which the probability is non-zero.

According to {{Harvtxt|Cameron and Trivedi|2009|p=23}} and {{Harvtxt|Wooldridge|2010|pp=54, 907}}, [[independence (probability theory)|stochastic independence]] implies mean independence, but the converse is not true.

Moreover, mean independence implies uncorrelatedness while the converse is not true.

The concept of mean independence is often used in [[econometrics]]{{citation needed|date=February 2016}} to have a middle ground between the strong assumption of independent random variables (&lt;math&gt;X_1 \perp X_2&lt;/math&gt;) and the weak assumption of uncorrelated random variables &lt;math&gt;(\operatorname{Cov}(X_1,X_2)=0).&lt;/math&gt;

==References==
*{{cite book |last=Cameron |first=A. Colin |first2=Pravin K. |last2=Trivedi |year=2009 |title=Microeconometrics: Methods and Applications |location=New York |publisher=Cambridge University Press |edition=8th |isbn=9780521848053 |ref=harv }}
*{{cite book |last=Wooldridge |first=Jeffrey M. |year=2010 |title=Econometric Analysis of Cross Section and Panel Data |location=London |publisher=The MIT Press |edition=2nd |isbn=9780262232586 |ref=harv }}

{{DEFAULTSORT:Mean dependence}}
[[Category:Independence (probability theory)]]

{{Probability-stub}}</text>
      <sha1>e5qdn65uh5fjx9wbbycm2ouo03o81ox</sha1>
    </revision>
  </page>
  <page>
    <title>Measure (mathematics)</title>
    <ns>0</ns>
    <id>19873</id>
    <revision>
      <id>871088926</id>
      <parentid>868651531</parentid>
      <timestamp>2018-11-28T21:22:15Z</timestamp>
      <contributor>
        <ip>150.164.21.32</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20461">{{distinguish|Metric (mathematics)}}
{{For|the coalgebraic concept|measuring coalgebra}}
[[File:Measure illustration.png|right|thumb|Informally, a measure has the property of being [[Monotone function|monotone]] in the sense that if ''A'' is a [[subset]] of ''B'', the measure of ''A'' is less than or equal to the measure of ''B''. Furthermore, the measure of the [[empty set]] is required to be 0.]]

In [[mathematical analysis]], a '''measure''' on a [[set (mathematics)|set]] is a systematic way to assign a number to each suitable [[subset]] of that set, intuitively interpreted as its size. In this sense, a measure is a generalization of the concepts of length, area, and volume. A particularly important example is the [[Lebesgue measure]] on a [[Euclidean space]], which assigns the conventional [[length]], [[area]], and [[volume]] of [[Euclidean geometry]] to suitable subsets of the {{math|''n''}}-[[Dimension (mathematics and physics)|dimensional]] Euclidean space {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}}. For instance, the Lebesgue measure of the [[Interval (mathematics)|interval]] {{math|[0, 1]}} in the [[real line|real numbers]] is its length in the everyday sense of the word – specifically, 1.

Technically, a measure is a [[Function (mathematics)|function]] that assigns a non-negative real number or [[Extended real number line|{{math|+∞}}]] to (certain) subsets of a set {{mvar|X}} (''see'' [[#Definition|Definition]] below). It must further be [[Sigma additivity|countably additive]]: the measure of a 'large' subset that can be decomposed into a finite (or countably infinite) number of 'smaller' disjoint subsets is equal to the sum of the measures of the "smaller" subsets. In general, if one wants to associate a ''consistent'' size to ''each'' subset of a given set while satisfying the other axioms of a measure, one only finds trivial examples like the [[counting measure]]. This problem was resolved by defining measure only on a sub-collection of all subsets; the so-called ''measurable'' subsets, which are required to form a [[Sigma-algebra|{{math|σ}}-algebra]]. This means that countable [[union (set theory)|unions]], countable [[intersection (set theory)|intersections]] and [[complement (set theory)|complements]] of measurable subsets are measurable. [[Non-measurable set]]s in a Euclidean space, on which the Lebesgue measure cannot be defined consistently, are necessarily complicated in the sense of being badly mixed up with their complement.&lt;ref&gt;[[Paul Halmos|Halmos, Paul]] (1950), ''Measure theory'', Van Nostrand and Co.&lt;/ref&gt; Indeed, their existence is a non-trivial consequence of the [[axiom of choice]].

Measure theory was developed in successive stages during the late 19th and early 20th centuries by [[Émile Borel]], [[Henri Lebesgue]], [[Johann Radon]], and [[Maurice Fréchet]], among others. The main applications of measures are in the foundations of the [[Lebesgue integral]], in [[Andrey Kolmogorov]]'s [[axiomatisation]] of [[probability theory]] and in [[ergodic theory]]. In integration theory, specifying a measure allows one to define [[integral]]s on spaces more general than subsets of Euclidean space; moreover, the integral with respect to the Lebesgue measure on Euclidean spaces is more general and has a richer theory than its predecessor, the [[Riemann integral]]. Probability theory considers measures that assign to the whole set the size 1, and considers measurable subsets to be events whose probability is given by the measure. [[Ergodic theory]] considers measures that are invariant under, or arise naturally from, a [[dynamical system]].

==Definition==
[[File:Countable additivity of a measure.svg|thumb|300px|Countable additivity of a measure {{mvar|μ}}: The measure of a countable disjoint union is the same as the sum of all measures of each subset.]]

Let {{mvar|X}} be a set and {{mvar|Σ}} a [[Sigma-algebra|{{math|σ}}-algebra]] over {{mvar|X}}. A function {{mvar|μ}} from {{mvar|Σ}} to the [[extended real number line]] is called a '''measure''' if it satisfies the following properties:

*'''Non-negativity''': For all {{math|''E''}} in Σ: {{math|''μ''(''E'') ≥ 0}}.
*'''Null empty set''': &lt;math&gt;\mu(\varnothing)=0&lt;/math&gt;.
*'''Countable additivity''' (or [[sigma additivity|{{math|σ}}-additivity]]): For all [[countable]] collections &lt;math&gt;\{E_i\}_{i=1}^\infty&lt;/math&gt; of pairwise [[disjoint sets]] in Σ:
:&lt;math&gt;\mu\left(\bigcup_{k=1}^\infty E_k\right)=\sum_{k=1}^\infty \mu(E_k)&lt;/math&gt;

One may require that at least one set {{math|''E''}} has finite measure. Then the empty set automatically has measure zero because of countable additivity, because
:&lt;math&gt;\mu(E)=\mu(E \cup \varnothing \cup \varnothing \cup \dots) = \mu(E) + \mu(\varnothing) + \mu(\varnothing) + \dots,&lt;/math&gt;
which implies (since the sum on the right thus converges to a finite value) that &lt;math&gt;\mu(\varnothing)=0&lt;/math&gt;.

If only the second and third conditions of the definition of measure above are met, and {{mvar|μ}} takes on at most one of the values {{math|±∞}}, then {{mvar|μ}} is called a '''[[signed measure]]'''.

The pair {{math|(''X'', Σ)}} is called a [[measurable space]], the members of Σ are called '''measurable sets'''. If &lt;math&gt;\left(X,  \Sigma_X\right)&lt;/math&gt; and &lt;math&gt;\left(Y,  \Sigma_Y\right)&lt;/math&gt; are two measurable spaces, then a function &lt;math&gt;f : X \to Y&lt;/math&gt; is called '''measurable''' if for every {{math|''Y''}}-measurable set &lt;math&gt;B \in  \Sigma_Y&lt;/math&gt;, the [[Image (mathematics)#Inverse image|inverse image]] is {{mvar|X}}-measurable – i.e.: &lt;math&gt;f^{(-1)}(B) \in  \Sigma_X&lt;/math&gt;. In this setup, the [[Function composition|composition]] of measurable functions is measurable, making the measurable spaces and measurable functions a [[Category (mathematics)|category]], with the measurable spaces as objects and the set of measurable functions as arrows. See also [[Measurable function#Term usage variations]] about another setup.

A [[tuple|triple]] {{math|(''X'', Σ, ''μ'')}} is called a [[measure space]]. A [[probability measure]] is a measure with total measure one – i.e. {{math|''μ''(''X'') {{=}} 1}}. A [[probability space]] is a measure space with a probability measure.

For measure spaces that are also [[topological space]]s various compatibility conditions can be placed for the measure and the topology. Most measures met in practice in [[analysis (mathematics)|analysis]] (and in many cases also in [[probability theory]]) are [[Radon measure]]s. Radon measures have an alternative definition in terms of linear functionals on the [[locally convex space]] of [[continuous function]]s with [[support (mathematics)#Compact support|compact support]]. This approach is taken by [[Nicolas Bourbaki|Bourbaki]] (2004) and a number of other sources. For more details, see the article on [[Radon measure]]s.

==Examples==
Some important measures are listed here.

* The [[counting measure]] is defined by {{math|''μ''(''S'')}} = number of elements in {{math|''S''}}.
* The [[Lebesgue measure]] on {{math|'''R'''}} is a [[Complete measure|complete]] [[translational invariance|translation-invariant]] measure on a ''σ''-algebra containing the [[interval (mathematics)|interval]]s in {{math|'''R'''}} such that {{math|''μ''([0, 1]) {{=}} 1}}; and every other measure with these properties extends Lebesgue measure.
* Circular [[angle]] measure is invariant under [[rotation]], and [[hyperbolic angle]] measure is invariant under [[squeeze mapping]].
* The [[Haar measure]] for a [[Locally compact space|locally compact]] [[topological group]] is a generalization of the Lebesgue measure (and also of counting measure and circular angle measure) and has similar uniqueness properties.
* The [[Hausdorff measure]] is a generalization of the Lebesgue measure to sets with non-integer dimension, in particular, fractal sets.
* Every [[probability space]] gives rise to a measure which takes the value 1 on the whole space (and therefore takes all its values in the [[unit interval]] [0, 1]). Such a measure is called a ''probability measure''. See [[probability axioms]].
* The [[Dirac measure]] δ&lt;sub&gt;''a''&lt;/sub&gt; (cf. [[Dirac delta function]]) is given by δ&lt;sub&gt;''a''&lt;/sub&gt;(''S'') = χ&lt;sub&gt;''S''&lt;/sub&gt;(a), where χ&lt;sub&gt;''S''&lt;/sub&gt; is the [[Indicator function|indicator function]] of {{math|''S''}}. The measure of a set is 1 if it contains the point {{math|''a''}} and 0 otherwise.

Other 'named' measures used in various theories include: [[Borel measure]], [[Jordan measure]], [[ergodic measure]], [[Euler measure]], [[Gaussian measure]], [[Baire measure]], [[Radon measure]], [[Young measure]], and [[Loeb measure]].
 
In physics an example of a measure is spatial distribution of [[mass]] (see e.g., [[gravity potential]]), or another non-negative [[extensive property]], [[conserved quantity|conserved]] (see [[Conservation law (physics)|conservation law]] for a list of these) or not. Negative values lead to signed measures, see "generalizations" below.

* [[Liouville's theorem (Hamiltonian)#Symplectic geometry|Liouville measure]], known also as the natural volume form on a symplectic manifold, is useful in classical statistical and Hamiltonian mechanics.
* [[Gibbs measure]] is widely used in statistical mechanics, often under the name [[canonical ensemble]].

==Basic properties==
Let {{mvar|μ}} be a measure.

===Monotonicity===
If {{math|''E''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''E''&lt;sub&gt;2&lt;/sub&gt;}} are measurable sets with {{math|''E''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;⊆&amp;nbsp;''E''&lt;sub&gt;2&lt;/sub&gt;}} then
:&lt;math&gt;\mu(E_1) \leq \mu(E_2).&lt;/math&gt;

===Measure of countable unions and intersections===
====Subadditivity====
For any [[countable]] [[Sequence (mathematics)|sequence]] {{math|''E''&lt;sub&gt;1&lt;/sub&gt;, ''E''&lt;sub&gt;2&lt;/sub&gt;, ''E''&lt;sub&gt;3&lt;/sub&gt;, ...}} of (not necessarily disjoint) measurable sets {{math|''E&lt;sub&gt;n&lt;/sub&gt;''}} in Σ:
:&lt;math&gt;\mu\left( \bigcup_{i=1}^\infty E_i\right) \le \sum_{i=1}^\infty \mu(E_i).&lt;/math&gt;

====Continuity from below====
If {{math|''E''&lt;sub&gt;1&lt;/sub&gt;, ''E''&lt;sub&gt;2&lt;/sub&gt;, ''E''&lt;sub&gt;3&lt;/sub&gt;, ...}} are measurable sets and {{math|''E&lt;sub&gt;n&lt;/sub&gt;''}} is a subset of {{math|''E''&lt;sub&gt;''n'' + 1&lt;/sub&gt;}} for all {{math|''n''}}, then the [[Union (set theory)|union]] of the sets {{math|''E&lt;sub&gt;n&lt;/sub&gt;''}} is measurable, and
:&lt;math&gt; \mu\left(\bigcup_{i=1}^\infty E_i\right) = \lim_{i\to\infty}  \mu(E_i).&lt;/math&gt;

====Continuity from above====
If {{math|''E''&lt;sub&gt;1&lt;/sub&gt;, ''E''&lt;sub&gt;2&lt;/sub&gt;, ''E''&lt;sub&gt;3&lt;/sub&gt;, ...}} are measurable sets and for all {{math|''n'', ''E''&lt;sub&gt;''n'' + 1&lt;/sub&gt; ⊂ ''E&lt;sub&gt;n&lt;/sub&gt;''}}, then the [[Intersection (set theory)|intersection]] of the sets {{math|''E&lt;sub&gt;n&lt;/sub&gt;''}} is measurable; furthermore, if at least one of the {{math|''E&lt;sub&gt;n&lt;/sub&gt;''}} has finite measure, then

:&lt;math&gt; \mu\left(\bigcap_{i=1}^\infty E_i\right) = \lim_{i\to\infty} \mu(E_i).&lt;/math&gt;

This property is false without the assumption that at least one of the {{math|''E&lt;sub&gt;n&lt;/sub&gt;''}} has finite measure. For instance, for each {{math|''n'' ∈ '''N'''}}, let {{math|''E&lt;sub&gt;n&lt;/sub&gt;'' {{=}} [''n'', ∞) ⊂ '''R'''}}, which all have infinite Lebesgue measure, but the intersection is empty.

==Sigma-finite measures==
{{Main|Sigma-finite measure}}

A measure space {{math|(''X'', Σ, ''μ'')}} is called finite if {{math|''μ''(''X'')}} is a finite real number (rather than ∞). Nonzero finite measures are analogous to probability measures in the sense that any finite measure {{mvar|μ}} is proportional to the probability measure &lt;math&gt;\frac{1}{\mu(X)}\mu&lt;/math&gt;. A measure {{mvar|μ}} is called ''σ-finite'' if {{mvar|X}} can be decomposed into a countable union of measurable sets of finite measure. Analogously, a set in a measure space is said to have a ''σ-finite measure'' if it is a countable union of sets with finite measure.

For example, the [[real number]]s with the standard [[Lebesgue measure]] are σ-finite but not finite. Consider the [[closed interval]]s {{math|[''k'', ''k''+1]}} for all [[integer]]s {{math|''k''}}; there are countably many such intervals, each has measure 1, and their union is the entire real line. Alternatively, consider the [[real number]]s with the [[counting measure]], which assigns to each finite set of reals the number of points in the set. This measure space is not σ-finite, because every set with finite measure contains only finitely many points, and it would take uncountably many such sets to cover the entire real line. The σ-finite measure spaces have some very convenient properties; σ-finiteness can be compared in this respect to the [[Lindelöf space|Lindelöf property]] of topological spaces. They can be also thought of as a vague generalization of the idea that a measure space may have 'uncountable measure'.


==s-finite measures==
{{Main|s-finite measure}}

A measure is said to be s-finite if it is a countable sum of bounded measures. S-finite measures are more general than sigma-finite ones and have applications in the theory of [[stochastic processes]].

==Completeness==
{{Main|Complete measure}}

A measurable set {{mvar|X}} is called a ''[[null set]]'' if {{math|''μ''(''X'') {{=}} 0}}. A subset of a null set is called a ''negligible set''. A negligible set need not be measurable, but every measurable negligible set is automatically a null set. A measure is called ''complete'' if every negligible set is measurable.

A measure can be extended to a complete one by considering the σ-algebra of subsets {{math|''Y''}} which differ by a negligible set from a measurable set {{mvar|X}}, that is, such that the [[symmetric difference]] of {{mvar|X}} and {{math|''Y''}} is contained in a null set. One defines {{math|''μ''(''Y'')}} to equal {{math|''μ''(''X'')}}.

==Additivity==
Measures are required to be countably additive. However, the condition can be strengthened as follows.
For any set &lt;math&gt;I&lt;/math&gt; and any set of nonnegative &lt;math&gt;r_i,i\in I&lt;/math&gt; define:
:&lt;math&gt;\sum_{i\in I} r_i=\sup\left\lbrace\sum_{i\in J} r_i : |J|&lt;\aleph_0, J\subseteq I\right\rbrace.&lt;/math&gt;
That is, we define the sum of the &lt;math&gt;r_i&lt;/math&gt; to be the supremum of all the sums of finitely many of them.

A measure &lt;math&gt;\mu&lt;/math&gt; on &lt;math&gt;\Sigma&lt;/math&gt; is &lt;math&gt;\kappa&lt;/math&gt;-additive if for any &lt;math&gt;\lambda&lt;\kappa&lt;/math&gt; and any family of disjoint sets &lt;math&gt;X_\alpha,\alpha&lt;\lambda&lt;/math&gt; the following hold:
:&lt;math&gt;\bigcup_{\alpha\in\lambda} X_\alpha \in  \Sigma&lt;/math&gt;
:&lt;math&gt;\mu\left(\bigcup_{\alpha\in\lambda} X_\alpha\right)=\sum_{\alpha\in\lambda}\mu\left(X_\alpha\right).&lt;/math&gt;
Note that the second condition is equivalent to the statement that the [[Ideal (set theory)|ideal]] of null sets is &lt;math&gt;\kappa&lt;/math&gt;-complete.

==Non-measurable sets==
{{Main|Non-measurable set}}

If the [[axiom of choice]] is assumed to be true, it can be proved that not all subsets of [[Euclidean space]] are [[Lebesgue measurable]]; examples of such sets include the [[Vitali set]], and the non-measurable sets postulated by the [[Hausdorff paradox]] and the [[Banach–Tarski paradox]].

==Generalizations==
For certain purposes, it is useful to have a "measure" whose values are not restricted to the non-negative reals or infinity. For instance, a countably additive [[set function]] with values in the (signed) real numbers is called a ''[[signed measure]]'', while such a function with values in the [[complex number]]s is called a ''[[complex measure]]''. Measures that take values in [[Banach spaces]] have been studied extensively.&lt;ref&gt;{{citation
 | last = Rao | first = M. M.
 | isbn = 978-981-4350-81-5
 | mr = 2840012
 | publisher = [[World Scientific]]
 | series = Series on Multivariate Analysis
 | title = Random and Vector Measures
 | volume = 9
 | year = 2012}}.&lt;/ref&gt; A measure that takes values in the set of self-adjoint projections on a [[Hilbert space]] is called a ''[[projection-valued measure]]''; these are used in [[functional analysis]] for the [[spectral theorem]]. When it is necessary to distinguish the usual measures which take non-negative values from generalizations, the term '''positive measure''' is used. Positive measures are closed under [[conical combination]] but not general [[linear combination]], while signed measures are the linear closure of positive measures.

Another generalization is the ''finitely additive measure'', which are sometimes called [[Content (measure theory)|contents]]. This is the same as a measure except that instead of requiring ''countable'' additivity we require only ''finite'' additivity. Historically, this definition was used first. It turns out that in general, finitely additive measures are connected with notions such as [[Banach limit]]s, the dual of [[lp space|''L''&lt;sup&gt;∞&lt;/sup&gt;]] and the [[Stone–Čech compactification]]. All these are linked in one way or another to the [[axiom of choice]].

A [[signed measure|charge]] is a generalization in both directions: it is a finitely additive, signed measure.

==See also==
{{div col|colwidth=20em}}
* [[Abelian von Neumann algebra]]
* [[Almost everywhere]]
* [[Carathéodory's extension theorem]]
* [[Content (measure theory)]]
* [[Fubini's theorem]]
* [[Fatou's lemma]]
* [[Fuzzy measure theory]]
* [[Geometric measure theory]]
* [[Hausdorff measure]]
* [[Inner measure]]
* [[Lebesgue integration]]
* [[Lebesgue measure]]
* [[Lorentz space]]
* [[Lifting theory]]
* [[Measurable cardinal]]
* [[Measurable function]]
* [[Measure topology]]
* [[Minkowski content]]
* [[Noncommutative integration]]
* [[Outer measure]]
* [[Product measure]]
* [[Pushforward measure]]
* [[Regular measure]]
* [[Vector measure]]
* [[Valuation (measure theory)]]
* [[Volume form]]
{{div col end}}

==References==
{{reflist}}

==Bibliography==
{{refbegin}}
* [[Robert G. Bartle]] (1995) ''The Elements of Integration and Lebesgue Measure'', Wiley Interscience.
* {{citation | last=Bauer|first=H.|title=Measure and Integration Theory|year=2001|publisher=de Gruyter|location=Berlin|isbn=978-3110167191}}
* {{citation | last=Bear|first=H.S.|title=A Primer of Lebesgue Integration|year=2001|publisher=Academic Press|location=San Diego|isbn=978-0120839711}}
* {{citation | last=Bogachev|first=V. I.|title=Measure theory|year=2006|publisher=Springer|location=Berlin|isbn=978-3540345138}}
* {{citation | last=Bourbaki| first=Nicolas | title=Integration I |  year=2004 | publisher=[[Springer Verlag]] | isbn=3-540-41129-1}} Chapter III.
* R. M. Dudley, 2002. ''Real Analysis and Probability''. Cambridge University Press.
* {{citation | last=Folland | first=Gerald B.| title=Real Analysis: Modern Techniques and Their Applications | year = 1999 | publisher = John Wiley and Sons | isbn=0471317160 }} Second edition.
* D. H. Fremlin, 2000. ''[http://www1.essex.ac.uk/maths/people/fremlin/mt.htm Measure Theory]''. Torres Fremlin.
* {{citation | last=Jech| first=Thomas | title=Set Theory: The Third Millennium Edition, Revised and Expanded |  year=2003 | publisher=[[Springer Verlag]] | isbn=3-540-44085-2}}
* [[R. Duncan Luce]] and Louis Narens (1987). "measurement, theory of," ''The [[New Palgrave: A Dictionary of Economics]]'', v. 3, pp.&amp;nbsp;428–32.
* M. E. Munroe, 1953. ''Introduction to Measure and Integration''. Addison Wesley.
* {{Citation|author=K. P. S. Bhaskara Rao and M. Bhaskara Rao|title=Theory of Charges: A Study of Finitely Additive Measures| publisher=Academic Press|location=London|year=1983|pages=x + 315|isbn=0-12-095780-9}}
* Shilov, G. E., and Gurevich, B. L., 1978. ''Integral, Measure, and Derivative: A Unified Approach'', Richard A. Silverman, trans. Dover Publications. {{isbn|0-486-63519-8}}. Emphasizes the [[Daniell integral]].
* {{citation | last = Teschl| first = Gerald| authorlink = Gerald Teschl| title = Topics in Real and Functional Analysis| url = http://www.mat.univie.ac.at/~gerald/ftp/book-fa/index.html|publisher = (lecture notes)}}
* {{cite book|last1=Tao|first1=Terence|authorlink=Terence Tao|title=An Introduction to Measure Theory|date=2011|publisher=American Mathematical Society|location=Providence, R.I.|isbn=9780821869192}}
* {{cite book|last1=Weaver|first1=Nik|title=Measure Theory and Functional Analysis|date=2013|publisher= [[World Scientific]]|isbn=9789814508568}}
{{refend}}

==External links==
{{Wiktionary|measurable}}
*{{springer|title=Measure|id=p/m063240}}
*[https://vannevar.ece.uw.edu/techsite/papers/documents/UWEETR-2006-0008.pdf Tutorial: Measure Theory for Dummies]

{{Authority control}}

[[Category:Measure theory| ]]
[[Category:Measures (measure theory)| ]]</text>
      <sha1>eejs8y1lm07xv9nwof4tc9o5dhnowes</sha1>
    </revision>
  </page>
  <page>
    <title>Menger space</title>
    <ns>0</ns>
    <id>51474451</id>
    <revision>
      <id>842559344</id>
      <parentid>841542299</parentid>
      <timestamp>2018-05-23T06:38:55Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4714">{{refimprove|date=August 2016}}

In mathematics, a '''Menger space''' is a [[topological space]] that satisfies a certain a basic [[selection principle]] that generalizes [[σ-compact space|σ-compactness]]. A Menger space is a space in which for every sequence of open covers &lt;math&gt;\mathcal{U}_1, \mathcal{U}_2, \ldots&lt;/math&gt; of the space there are finite sets &lt;math&gt; \mathcal{F}_1 \subset \mathcal{U}_1, \mathcal{F}_2 \subset \mathcal{U}_2, \ldots&lt;/math&gt; such that the family &lt;math&gt;\mathcal{F}_1 \cup  \mathcal{F}_2 \cup \cdots&lt;/math&gt; covers the space.

==History==

In 1924, [[Karl Menger]] 
&lt;ref name="Karl Menger"&gt;{{cite journal|last1=Menger|first1=Karl|
title=Einige Überdeckungssätze der punktmengenlehre|
journal=Sitzungsberichte der Wiener Akademie|date=1924|volume=133|
pages=421–444|url=https://link.springer.com/chapter/10.1007%2F978-3-7091-6110-4_14|doi=10.1007/978-3-7091-6110-4_14}}&lt;/ref&gt; 
introduced the following basis property for metric spaces: 
Every basis of the topology contains a countable family of sets with vanishing 
diameters that covers the space. Soon thereafter, 
Witold Hurewicz &lt;ref&gt;{{cite journal|last1=Hurewicz|first1=Witold|
title=Über eine verallgemeinerung des Borelschen Theorems|
journal=Mathematische Zeitschrift|date=1926|volume=24.1|pages=401–421|
url=https://link.springer.com/article/10.1007%2FBF01216792|doi=10.1007/bf01216792}}&lt;/ref&gt; 
observed that Menger's basis property can be reformulated to the above form using sequences of open covers.

==Menger's conjecture==

Menger conjectured that in [[ZFC]] every Menger metric space is σ-compact. 
Fremlin and Miller 
&lt;ref&gt;{{cite journal|last1=Fremlin|first1=David|last2=Miller|first2=Arnold|
title=On some properties of Hurewicz, Menger and Rothberger|
journal=Fundamenta Mathematicae|date=1988|volume=129|pages=17–33|
url=http://matwbn.icm.edu.pl/ksiazki/fm/fm129/fm12913.pdf}}&lt;/ref&gt; 
proved that Menger's conjecture is false, by showing that there is,
in ZFC, a set of real numbers that is Menger but not σ-compact. 
The Fremlin-Miller proof was dichotomic, and the set witnessing the failure
of the conjecture heavily depends on whether a certain (undecidable) axiom
holds or not.

Bartoszyński and [[Boaz_Tsaban|Tsaban]]
&lt;ref&gt;{{cite journal|last1=Bartoszyński|first1=Tomek|last2=Tsaban|first2=Boaz|
title=Hereditary topological diagonalizations and the Menger–Hurewicz Conjectures|
journal=Proceedings of the American Mathematical Society|date=2006|volume=134|pages=605–615|
url=http://www.ams.org/journals/proc/2006-134-02/S0002-9939-05-07997-9/|doi=10.1090/s0002-9939-05-07997-9|arxiv=math/0208224}}&lt;/ref&gt; 
gave a uniform ZFC example of a Menger subset of the real line that is not σ-compact.

==Combinatorial characterization==

For subsets of the real line, the Menger property can be characterized using continuous functions into the [[Baire space]] &lt;math&gt;\mathbb{N}^\mathbb{N}&lt;/math&gt;.
For functions &lt;math&gt;f,g\in \mathbb{N}^\mathbb{N}&lt;/math&gt;, write &lt;math&gt;f\leq^* g&lt;/math&gt; if &lt;math&gt; f(n)\leq g(n)&lt;/math&gt; for all but finitely many natural numbers &lt;math&gt; n&lt;/math&gt;. A subset &lt;math&gt;A&lt;/math&gt; of &lt;math&gt;\mathbb{N}^\mathbb{N}&lt;/math&gt; is dominating if for each function &lt;math&gt; f\in\mathbb{N}^\mathbb{N}&lt;/math&gt; there is a function &lt;math&gt;g\in A&lt;/math&gt; such that &lt;math&gt; f\leq^* g&lt;/math&gt;. Hurewicz proved that a subset of the real line is Menger iff every continuous image of that space into the Baire space is not dominating. In particular, every subset of the real line of cardinality less than the [[Cichoń's diagram|dominating number &lt;math&gt;\mathfrak{d}&lt;/math&gt;]] is Menger.

The cardinality of Bartoszyński and Tsaban's counter-example to Menger's conjecture is
&lt;math&gt;\mathfrak{d}&lt;/math&gt;.

==Properties==

* Every compact, and even σ-compact, space is Menger.
* Every Menger space is a [[Lindelöf space]]
* Continuous image of a Menger space is Menger
* The Menger property is closed under taking &lt;math&gt;F_\sigma&lt;/math&gt; subsets
* Menger's property characterizes filters whose [[Mathias forcing]] notion does not add dominating functions.&lt;ref&gt;{{Cite journal|last=Chodounský|first=David|last2=Repovš|first2=Dušan|last3=Zdomskyy|first3=Lyubomyr|date=2015-12-01|title=MATHIAS FORCING AND COMBINATORIAL COVERING PROPERTIES OF FILTERS|url=https://www.cambridge.org/core/journals/journal-of-symbolic-logic/article/div-classtitlemathias-forcing-and-combinatorial-covering-properties-of-filtersdiv/725F31CB4B307A544531F56682D06B6D|journal=The Journal of Symbolic Logic|volume=80|issue=4|pages=1398–1410|doi=10.1017/jsl.2014.73|issn=0022-4812|arxiv=1401.2283}}&lt;/ref&gt;

==References==
{{reflist}}

&lt;!--
==External links==
--&gt;
{{Topology}}

[[Category:Properties of topological spaces]]
[[Category:Topology]]</text>
      <sha1>ov801idsvlwmc2op2j9loo5cry287ba</sha1>
    </revision>
  </page>
  <page>
    <title>Model K</title>
    <ns>0</ns>
    <id>14766741</id>
    <revision>
      <id>857450298</id>
      <parentid>802990114</parentid>
      <timestamp>2018-08-31T19:34:09Z</timestamp>
      <contributor>
        <ip>89.25.210.104</ip>
      </contributor>
      <comment>Changed to relay binary adder; refs</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1394">{{About|an early digital calculator|the automobile|Ford Model K}}
The '''Model K''' was an early relay binary adder&lt;ref&gt;{{Cite web|url=http://www.computerhistory.org/collections/catalog/102627225|title=Stibitz Model K Adder {{!}} 102627225 {{!}} Computer History Museum|website=www.computerhistory.org|language=en|access-date=2018-08-31}}&lt;/ref&gt; built in 1937 by [[George Stibitz|George Robert Stibitz]], a scientist at [[Bell Laboratories]].&lt;ref&gt;{{Cite web|url=http://www.maxmon.com/1937ad.htm|title=George Robert Stibitz's Complex Number Calculator|last=|first=|date=|website=|archive-url=https://web.archive.org/web/20080704191226/http://www.maxmon.com/1937ad.htm|archive-date=2008-07-04|dead-url=|access-date=2017-09-29}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.computerhistory.org/revolution/birth-of-the-computer/4/85/346|title="Model K" Adder (replica) - CHM Revolution|website=www.computerhistory.org|access-date=2018-08-31}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Irvine|first=M. M.|date=July 2001|others=[http://www.iuma.ulpgc.es/~lopez/asig2.html pdf]|title=Early digital computers at Bell Telephone Laboratories|url=http://ieeexplore.ieee.org/document/948904/|journal=IEEE Annals of the History of Computing|volume=23|issue=3|pages=22–42|doi=10.1109/85.948904|issn=1058-6180|via=}}&lt;/ref&gt;

== References ==
&lt;references/&gt;

[[Category:American inventions]]
[[Category:Calculators]]


{{Tech-stub}}</text>
      <sha1>njev5d03vm94tf2vbgzmgxc13g9n80c</sha1>
    </revision>
  </page>
  <page>
    <title>Philip Hartman</title>
    <ns>0</ns>
    <id>35263118</id>
    <revision>
      <id>822508538</id>
      <parentid>797726697</parentid>
      <timestamp>2018-01-26T19:51:03Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3098">{{for|the actor and comedian|Phil Hartman}}
{{Infobox scientist
| name              = Philip Hartman
| image             = 
| alt               = 
| caption           = 
| birth_date        = {{Birth date|df=yes|1915|5|16}} 
| birth_place       = [[Baltimore]]&lt;ref&gt;[[James McKeen Cattell]], ''American Men of Science'', 1966&lt;/ref&gt;
| death_date        = {{Death date and age|df=yes|2015|8|28|1915|5|16}} 
| death_place       = 
| nationality       = [[United States|American]]
| fields            = [[Mathematics]]
| workplaces        = [[Johns Hopkins University]]&lt;br/&gt; [[Queens College, City University of New York|Queens College]]
| alma_mater        = [[Johns Hopkins University]]&lt;ref&gt;[https://jscholarship.library.jhu.edu/bitstream/handle/1774.2/36753/commencement1938.pdf?sequence=1  Conferring of Degrees, The Johns Hopkins University, Baltimore, June 14 1938].&lt;/ref&gt;
| doctoral_advisor  = [[Aurel Wintner]]&lt;ref name=genealogy&gt;{{MathGenealogy|id=11479}}&lt;/ref&gt;
| doctoral_students = 
| awards            = [[Guggenheim Fellowship]] (Mathematics, 1950),&lt;ref name=guggenheim&gt;[http://www.gf.org/fellows/all-fellows/philip-hartman/ Philip Hartman, John Simon Guggenheim Memorial Foundation].&lt;/ref&gt; &lt;br/&gt; Honorary Member of the [[American Mathematical Society|AMS]]&lt;ref name=ams&gt;[http://www.ams.org/notices/200011/from.pdf Honorary Members of the AMS]&lt;/ref&gt;
| known_for         = [[Hartman–Grobman theorem]]
}}

'''Philip Hartman''' (May 16, 1915 &amp;ndash; August 28, 2015) was an American mathematician at [[Johns Hopkins University]] working on [[differential equation]]s who introduced the [[Hartman–Grobman theorem]]. He served as Chairman of the Mathematics Department at Johns Hopkins for several years. He has an Erdös number of 2.&lt;ref&gt;{{Cite web|url=https://oakland.edu/enp/compute/|title=Compute your Erdös number - The Erdös Number Project- Oakland University|website=oakland.edu|language=en|access-date=2017-08-15}}&lt;/ref&gt;

His book gives a necessary and sufficient condition for solutions of ordinary initial value problems to be unique and to depend on a class C&lt;sup&gt;1&lt;/sup&gt; manner on the initial conditions for solutions.

He died in August 2015 at the age of 100.&lt;ref&gt;https://arxiv.org/pdf/1510.03779.pdf&lt;/ref&gt;

== Publications ==
*{{Citation | last1=Hartman | first1=Philip | title=Ordinary differential equations | origyear=1964 | url=https://books.google.com/books?id=CENAPMUEpfoC | publisher=[[Society for Industrial and Applied Mathematics]] | location=Philadelphia | series=Classics in Applied Mathematics | isbn=978-0-89871-510-1 |mr=1929104 | year=2002 | volume=38}}

== References ==
{{reflist}}

== External links ==
*{{MathGenealogy|id=11479}}

{{Authority control}}

{{DEFAULTSORT:Hartman, Philip}}
[[Category:1915 births]]
[[Category:2015 deaths]]
[[Category:People from Baltimore]]
[[Category:20th-century American mathematicians]]
[[Category:American centenarians]]
[[Category:Johns Hopkins University alumni]]
[[Category:Johns Hopkins University faculty]]
[[Category:Guggenheim Fellows]]
[[Category:Dynamical systems theorists]]
[[Category:Mathematical analysts]]</text>
      <sha1>1ocdeio0z587xf4trvierg6bps9ispq</sha1>
    </revision>
  </page>
  <page>
    <title>Pohlke's theorem</title>
    <ns>0</ns>
    <id>52991874</id>
    <revision>
      <id>787520193</id>
      <parentid>778904354</parentid>
      <timestamp>2017-06-25T21:32:44Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic_links|magic links]] with templates per [[Special:PermaLink/772743896#Future_of_magic_links|local RfC]] - [[User:PrimeBOT/13|BRFA]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5091">'''Pohlke's theorem''' is the fundamental theorem of [[axonometry]]. It was established 1853 by the German painter and teacher of [[descriptive geometry]] [[Karl Wilhelm Pohlke]]. The first proof of the theorem was published 1864 by the German mathematician [[Hermann Amandus Schwarz]], who was a student of Pohlke. Therefore the theorem is sometimes called '''theorem of Pohlke and Schwarz''', too.

== The theorem ==
[[File:Axonom-pohlke.svg|thumb|Pohlke's theorem]]
*Three arbitrary line sections &lt;math&gt;\overline O\overline U,\overline O\overline V,\overline O\overline W&lt;/math&gt; in a plane originating at point &lt;math&gt; \overline O&lt;/math&gt;, which are not contained in a line, can be considered as the [[parallel projection]] of three edges &lt;math&gt;OU,OV,OW&lt;/math&gt; of a [[cube]].
For a mapping of a unit cube, one has to apply an additional scaling either in the space or in the plane. Because a parallprojection and a scaling preserves ratios one can map an arbitrary point &lt;math&gt;P=(x,y,z)&lt;/math&gt; by the axonometric procedure below.

Pohlke's theorem can be stated in terms of linear algebra as:
*Any [[Affine transformation|affine mapping]] of the 3-dimesional space onto a plane can be considered as the composition of a [[Similarity (geometry)|similarity]] and a parallel projection.&lt;ref&gt;G. Pickert: ''Vom Satz von Pohlke zur linearen Algebra'', Didaktik der Mathematik 11 (1983), 4, pp. 297–306.&lt;/ref&gt;

== Application to axonometry ==
[[File:Axonom-def.svg|thumb|the principle of axonometric projection]]
Pohlke's theorem is the justification for the following easy procedure to construct a scaled parallel projection of a 3-dimensional object using coordinates,:&lt;ref&gt;Ulrich Graf, Martin Barner: ''Darstellende Geometrie.'' Quelle &amp; Meyer, Heidelberg 1961, {{ISBN|3-494-00488-9}}, p.144.&lt;/ref&gt;&lt;ref&gt;Roland Stärk: ''Darstellende Geometrie'', Schöningh, 1978, {{ISBN|3-506-37443-5}}, p.156.&lt;/ref&gt;
#Choose the images of the coordinate axes, not contained in a line.
#Choose for any coordinate axis forshortenings &lt;math&gt;v_x,v_y,v_z &gt;0 .&lt;/math&gt;
#The image &lt;math&gt;\overline P&lt;/math&gt; of a point &lt;math&gt;P=(x,y,z)&lt;/math&gt; is determined by the three steps, starting at point &lt;math&gt;\overline O&lt;/math&gt;:
::go &lt;math&gt;v_x\cdot x&lt;/math&gt; in &lt;math&gt;\overline x&lt;/math&gt;-direction, then
::go &lt;math&gt;v_y\cdot y&lt;/math&gt; in &lt;math&gt;\overline y&lt;/math&gt;-direction, then
::go &lt;math&gt;v_z\cdot z&lt;/math&gt; in &lt;math&gt;\overline z&lt;/math&gt;-direction and 
:4. mark the point as &lt;math&gt;\overline P&lt;/math&gt;.
In order to get undistorted pictures, one has to choose the images of the axes and the forshortenings carefully (see [[Axonometry]]). In order to get an [[orthographic projection]] only the images of the axes are free and the forshortenings are determined. (see [[:de:orthogonale Axonometrie]]).

== Remarks on Schwarz's proof ==
Schwarz formulated and proved the more general statement:
*The vertices of any [[quadrilateral]] can be considered as an oblique parallel projection of the vertices of a [[tetrahedron]] that is [[Similarity (geometry)|similar]] to a given tetrahedron.&lt;ref&gt;{{cite journal |url=http://math.unipa.it/~grim/quad17_sklenarikova-pemova_07.pdf |first1=Zita |last1=Sklenáriková |first2=Marta |last2=Pémová |title=The Pohlke–Schwarz Theorem and its Relevancy in the Didactics of Mathematics|journal=Quaderni di Ricerca in Didattica|publisher=G.R.I.M. (Department of Mathematics, University of Palermo, Italy)|year=2007|number=17|page=155}}&lt;/ref&gt;

and used a theorem of [[Lhuilier|L’Huilier]]: 
*Every triangle can be considered as the orthographic projection of a triangle of a given shape.

==Notes==
{{Reflist}}

== References ==
* [[Karl Pohlke|K. Pohlke]]: ''Zehn Tafeln zur darstellenden Geometrie.'' Gaertner-Verlag, Berlin 1876 [https://books.google.com/books?id=V17kAAAAMAAJ&amp;dq=Karl+Pohlke&amp;source=gbs_navlinks_s (Google Books.)]
*[[Hermann Schwarz|Schwarz, H. A.]]:''Elementarer Beweis des Pohlkeschen Fundamentalsatzes der Axonometrie'',J. reine angew. Math. 63, 309–314, 1864. 
*Arnold Emch: ''Proof of Pohlke's Theorem and Its Generalizations by Affinity'', American Journal of Mathematics, Vol. 40, No. 4 (Oct., 1918), pp.&amp;nbsp;366–374

==External links ==
* [https://books.google.com/books?id=3IqQDAAAQBAJ&amp;pg=PA97&amp;lpg=PA97&amp;dq=pohlke%27s+theorem&amp;source=bl&amp;ots=kzxDMs21D8&amp;sig=rfzf8Mst5V95a1oJn1AblH1mCzw&amp;hl=de&amp;sa=X&amp;ved=0ahUKEwjcuIfqmN3RAhWGhiwKHXloBQo4ChDoAQgkMAE#v=onepage&amp;q=pohlke%27s%20theorem&amp;f=false F. Klein: ''The fundamental Theorem of Pohlke'', in ''Elementary Mathematics from a Higher Standpoint: Volume II: Geometry'', p. 97,]
*[https://books.google.com/books?id=6Kp9CAAAQBAJ&amp;pg=PA398&amp;lpg=PA398&amp;dq=pohlke%27s+theorem&amp;source=bl&amp;ots=6lswbRT-GX&amp;sig=MLSnMEY3mIMxKeXPkkpgX4e_93Y&amp;hl=de&amp;sa=X&amp;ved=0ahUKEwjcuIfqmN3RAhWGhiwKHXloBQo4ChDoAQgwMAM#v=onepage&amp;q=pohlke%27s%20theorem&amp;f=false Christoph J. Scriba,Peter Schreiber: 5000 Years of Geometry: Mathematics in History and Culture, p. 398.]
* [https://www.encyclopediaofmath.org/index.php/Pohlke-Schwarz_theorem ''Pohlke–Schwarz theorem'', Encyclopedia of Mathematics. ]

[[Category:Graphical projections]]
[[Category:Linear algebra]]</text>
      <sha1>ja4bovxp93zk7ycqrmaxjy8ay6iex9h</sha1>
    </revision>
  </page>
  <page>
    <title>Polyvector field</title>
    <ns>0</ns>
    <id>30067072</id>
    <revision>
      <id>674719183</id>
      <parentid>650510073</parentid>
      <timestamp>2015-08-05T18:10:56Z</timestamp>
      <contributor>
        <username>Steel1943</username>
        <id>2952402</id>
      </contributor>
      <comment>Undid revision 650510073 by [[Special:Contributions/AHusain3141|AHusain3141]] ([[User talk:AHusain3141|talk]]) malformed redirect - also, term not mentioned in the other article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="639">{{Multiple issues|
{{confusing|date=February 2011}}
{{context|date=February 2011}}
{{jargon|date=February 2011}}
{{orphan|date=December 2010}}
{{unreferenced|date=September 2012}}
}}
In [[mathematics]], a '''multivector field''', '''polyvector field''' of '''degree ''k'' ''', or ''' ''k''-vector field''', on a [[manifold]] ''M'', is a section of the ''k''th [[exterior power]] of the [[tangent bundle]], &lt;math&gt;\Lambda^k TM&lt;/math&gt;.  Polyvector fields of degree ''k'' are dual to ''k''-[[differential forms|forms]].

==See also==
* [[Multivector]]
* [[Blade (geometry)]]


[[Category:Differential topology]]

{{differential-geometry-stub}}</text>
      <sha1>j05f7jion6kig1kvm5jz5um7dv00jmn</sha1>
    </revision>
  </page>
  <page>
    <title>Predictable σ-algebra</title>
    <ns>0</ns>
    <id>58580529</id>
    <redirect title="Predictable process" />
    <revision>
      <id>861257837</id>
      <parentid>861257352</parentid>
      <timestamp>2018-09-26T05:18:23Z</timestamp>
      <contributor>
        <username>NikelsenH</username>
        <id>18120325</id>
      </contributor>
      <comment>+ set families</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="94">#REDIRECT [[Predictable process]]

[[Category:Stochastic processes]]
[[Category:Set families]]</text>
      <sha1>nworvzz7ufdfsjzt2bc3tqeoi60ztq0</sha1>
    </revision>
  </page>
  <page>
    <title>Process validation</title>
    <ns>0</ns>
    <id>44224167</id>
    <revision>
      <id>826548078</id>
      <parentid>826043686</parentid>
      <timestamp>2018-02-19T19:27:30Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category Process management to [[:Category:Business process management]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7722">'''Process Validation''' is the analysis of data gathered throughout the design and manufacturing of a product in order to confirm that the process can reliably output products of a determined standard. Regulatory authorities like [[European Medicines Agency|EMA]] and [[FDA]] have published guidelines relating to process validation.&lt;ref&gt;{{cite web|title=Guidance for Industry Process Validation: General Principles and Practices|url=http://www.fda.gov/downloads/Drugs/Guidances/UCM070336.pdf|publisher=Food and Drug Administration|accessdate=16 December 2014}}&lt;/ref&gt; The purpose of process validation is to ensure varied inputs lead to consistent and high quality outputs. Process validation is an ongoing process that must be frequently adapted as manufacturing feedback is gathered. End-to-end validation of production processes is essential in determining product quality because quality cannot always be determined by finished-product inspection. Process validation can be broken down into 3 steps: process design, process qualification, and continued process verification.

==Process Design==
In this stage data from the development phase are gathered and analyzed to define the commercial manufacturing process. By understanding the commercial process a framework for quality specifications can be established and used as the foundation of a control strategy. [[Process design]] is the first of three stages of process validation. Data from the development phase is gathered and analyzed to understand end-to-end system processes. These data are used to establish benchmarks for quality and production control.

===Design of Experiment (DOE)===
Design of experiments is used to discover possible relationships and sources of variation as quickly as possible. A cost benefit analysis should be conducted to determine if such an operation is necessary.&lt;ref&gt;{{cite web|title=A Case for Stage 3 Continued Process Verification|url=http://www.pharmamanufacturing.com/articles/2014/stage3-continued-process-verification/|publisher=Pharma Manufacturing|accessdate=22 November 2014}}&lt;/ref&gt;

===Quality by Design (QBD)===
[[Quality by Design]] is an approach to pharmaceutical manufacturing that stresses quality should be built into products rather than tested into products; that product quality should be considered at the earliest possible stage rather than at the end of the manufacturing process. Input variables are isolated in order to identify the root cause of potential quality issues and the manufacturing process is adapted accordingly.

===Process Analytical Technology (PAT)===
[[Process Analytical Technology]] is used to measure critical process parameters (CPP) and critical quality attributes (CQA).  PAT facilitates measurement of quantitative production variables in real time and allows access to relevant manufacturing feedback. PAT can also be used in the design process to generate a process qualification.&lt;ref&gt;{{cite web|title=PAT - A Framework for Innovative Pharmaceutical Development, Manufacturing, and Quality Assurance|url=http://www.fda.gov/downloads/Drugs/Guidances/ucm070305.pdf|publisher=Food and Drug Administration|accessdate=10 December 2014}}&lt;/ref&gt;

===Critical Process Parameters (CPP)===
[[Critical Process Parameters]] Operating parameters that are considered essential to maintaining product output within specified quality target guidelines.&lt;ref&gt;{{cite web|title=PROCESS VALIDATION (P2V)|url=http://www.validation-online.net/process-validation.html|publisher=Validation Online|accessdate=22 November 2014}}&lt;/ref&gt;

===Critical Quality Attributes (CQA)===
'''Critical Quality Attributes''' (CQA) are chemical, physical, biological and microbiological attributes that can be defined, measured, and continually monitored to ensure final product outputs remain within acceptable quality limits.&lt;ref&gt;{{cite web|title=Defining Critical Quality Attributes in the Pharmaceutical Manufacturing Process|url=http://www.gxp-cc.com/news/fda-european-regulations-for-life-sciences/2014/07/15/defining-critical-quality-attributes-in-the-pharmaceutical-manufacturing-process/|publisher=GXP-CC|accessdate=10 November 2014}}&lt;/ref&gt; CQA are an essential aspect of a manufacturing control strategy and should be identified in stage 1 of [[Process Validation]]: [[Process design]]. During this stage acceptable limits, baselines, and data collection and measurement protocols should be established. Data from the design process and data collected during production should be kept by the manufacturer and used to evaluated [[product quality]] and [[process control]].&lt;ref&gt;{{cite web|title=Critical Quality Attributes (CQA)|url=http://www.atris-systems.com/cms/index.php?id=228|publisher=Atris Information Systems|accessdate=10 November 2014}}&lt;/ref&gt; Historical data can also help manufacturers better understand operational process and input variables as well as better identify true deviations from quality standards compared to false positives. Should a serious product quality issue arise, historical data would be essential in identifying the sources of errors and implementing corrective measures.

==Process Qualification==
In this stage the process design is assessed to conclude if the process is able to meet determined manufacturing targets. In this stage all production processes and manufacturing equipment is proofed to confirm quality and output capabilities. Critical quality attributes are evaluated and critical process parameters taken into account to confirm product quality. Once the process qualification stage has been successfully accomplished production can begin. [[Process Qualification]] is the second phase of process validation....

==Continued Process Verification==
[[Continued Process Verification]] is the ongoing monitoring of all aspects of the production cycle.&lt;ref&gt;[http://www.atris-systems.com/216.0.html Continued Process Verification]&lt;/ref&gt; It aims to ensure that all levels of production are controlled and regulated. Deviations from prescribed output methods and final product irregularities are flagged by a process analytics database system. The FDA requires production data be recorded (FDA requirements (§ 211.180(e)). Continued process verification is stage 3 of process validation.

The [[European Medicines Agency]] defines a similar process known as Ongoing Process Verification. This alternative method of process validation is recommended by the EMA for validating processes on a continuous basis. Continuous Process Verification analyses [[Critical Process Parameters]] and [[Critical Quality Attributes]] in real time to confirm production remain within acceptable levels and meet standards set by ICH Q8, Pharmaceutical Quality Systems, and [[Good manufacturing practice]].&lt;ref&gt;{{cite web|title=Continuous Process Verification|url=http://www.atris-systems.com/219.0.html|publisher=Atris Information Systems|accessdate=17 November 2014}}&lt;/ref&gt;

== See also ==
* [[Business process validation]]
* [[Cleaning validation]]
* [[Process qualification]]
* [[Verification and validation]]

== References ==
{{Reflist}}

==External links==
{{Commons category|HTML}}
* [http://www.fda.gov/ FDA – U.S. Food and Drug Administration]
* [http://www.ema.europa.eu/ema/ EMA – European Medicines Agency]
* [http://www.pda.org/docs/default-source/website-document-library/chapters/presentations/australia/fdas-process-validation-guidance-12-may-2011---presentation-three.pdf?sfvrsn=6 Parental Drug Association]
* [http://www.atris-systems.com/210.0.html Process Validation according FDA Guidances ]

[[Category:Software testing]]
[[Category:Formal methods]]
[[Category:Software quality]]
[[Category:Enterprise modelling]]
[[Category:Business process management]]</text>
      <sha1>9oflkjev987gyiveb0od73gz67ldinh</sha1>
    </revision>
  </page>
  <page>
    <title>Salvatore Pincherle</title>
    <ns>0</ns>
    <id>11950956</id>
    <revision>
      <id>859563648</id>
      <parentid>859563428</parentid>
      <timestamp>2018-09-14T20:58:04Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Adding [[Category:Italian mathematicians]] using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4236">{{Infobox scientist
| name = Salvatore Pincherle
| image = Salvatore Pincherle.jpg
| image_size = 220px
| caption = 
| birth_date = March 11, 1853
| birth_place = [[Trieste]], [[Austrian Empire]]
| death_date = {{d-da|July 10, 1936|March 11, 1853}}
| death_place = [[Bologna]], [[Italy]]
| residence = [[Italy]]
| nationality = Italian
| field = [[Functional analysis]]
| work_institution = {{plainlist|
*[[University of Palermo]]
*[[University of Bologna]]
*[[Italian Mathematical Union]]}}
| doctoral_advisor = 
| doctoral_students = {{plainlist|
*[[Carlo Severini]]}}
| prizes = [[Royal Society of Edinburgh|Fellow of the Royal Society of Edinburgh]]
| religion =
| footnotes =
}}

'''Salvatore Pincherle''' (March 11, 1853 &amp;ndash; July 10, 1936) was an [[Italy|Italian]] [[mathematician]]. He contributed significantly to (and arguably helped to found) the field of [[functional analysis]], established the [[Italian Mathematical Union]] ([[Italian language|Italian]]: "''Unione Matematica Italiana''"), and was president of the Third [[International Congress of Mathematicians]]. The [[Pincherle derivative]] is named after him.

Pincherle was born into a [[Jew]]ish family in [[Trieste]] (then part of the [[Austrian Littoral]]) and spent his childhood in [[Marseille]], [[France]]. After completing his basic schooling in Marseille, he left in 1869 to study mathematics at the [[University of Pisa]], where he was a student under both [[Enrico Betti]] and [[Ulisse Dini]]. After he graduated in 1874, he taught at a school in [[Pavia]] until he received a scholarship in 1877.

After winning the scholarship and studying abroad at the [[Humboldt University of Berlin|University of Berlin]], Pincherle met [[Karl Weierstrass]]. Pincherle contributed to Weierstrass' theory of [[analytic function]]s, and in 1880, influenced by Weierstrass, he wrote an expository paper in the ''[[Giornale di Matematiche]]'', which proved to be a significant paper in the field of analysis. Throughout his life, Pincherle's work greatly reflected the influence that Weierstrass had on him. He later collaborated with [[Vito Volterra]] and explored [[Laplace transform]]s and other parts of functional analysis.

From 1880 until 1928, Pincherle was a Professor of Mathematics at the [[University of Bologna]].  In 1901, collaborating with [[Ugo Amaldi (mathematician)|Ugo Amaldi]], he published his main scientific book, ''Le Operazioni Distributive e loro Applicazioni all'Analisi''.

In Bologna in 1922, he established the Italian Mathematical Union and became its first President and held the position until 1936. In 1924, he attended the Second International Congress of Mathematicians in [[Toronto|Toronto, Ontario]], [[Canada]]. Four years later, he became President of the Third International Congress and played a significant role in re-admitting German mathematicians after a ban imposed because of [[World War I]]. At this Congress, [[Jacques Hadamard]] declared in his review lecture {{lang|fr|Le développement et le rôle scientifique du Calcul fonctionnel}} that Pincherle was one of the most prominent founders of functional analysis. Following the Third Congress, Pincherle retired from university.

In honor of the centenary of his birth, the Italian Mathematical Union edited a selection of 62 of his notes and [[treatise]]s; they were published in 1954 in [[Rome]].

==References==
* {{MacTutor Biography|id=Pincherle}} &lt;!-- accessdate = 2007-06-25 --&gt;
* {{cite journal |last= Mainardi|first= Francesco |authorlink= |author2=Gianni Pagnini |date=April 2003|title= Salvatore Pincherle: the pioneer of the Mellin-Barnes integrals|journal=Journal of Computational and Applied Mathematics|volume= 153|issue= 1|pages=331–342 |arxiv= math/0702520 |doi= 10.1016/S0377-0427(02)00609-X|bibcode=2003JCoAM.153..331M}}

{{Authority control}}

{{DEFAULTSORT:Pincherle, Salvatore}}
[[Category:1853 births]]
[[Category:1936 deaths]]
[[Category:People from Trieste]]
[[Category:Italian Jews]]
[[Category:19th-century Italian mathematicians]]
[[Category:20th-century Italian mathematicians]]
[[Category:Historians of mathematics]]
[[Category:Mathematical analysts]]
[[Category:University of Palermo faculty]]
[[Category:Italian mathematicians]]</text>
      <sha1>ewngr1yr416hpgf8917j4v4nba8sa6h</sha1>
    </revision>
  </page>
  <page>
    <title>Saturation arithmetic</title>
    <ns>0</ns>
    <id>1830167</id>
    <revision>
      <id>867823531</id>
      <parentid>845271704</parentid>
      <timestamp>2018-11-08T06:29:52Z</timestamp>
      <contributor>
        <ip>2600:1700:7261:3361:6C38:BA9B:FA7:3739</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6666">'''Saturation arithmetic''' is a version of [[arithmetic]] in which all operations such as addition and multiplication are limited to a fixed range between a minimum and maximum value. 

If the result of an operation is greater than the maximum, it is set ("clamped") to the maximum; if it is below the minimum, it is clamped to the minimum. The name comes from how the value becomes "saturated" once it reaches the extreme values; further additions to a maximum or subtractions from a minimum will not change the result.

For example, if the valid range of values is from -100 to 100, the following operations produce the following values:
* 60 + 30 = 90
* 60 + 43 = 100
* (60 + 43) − (75 + 75) = －47
* 10 × 11 = 100
* 99 × 99 = 100
* 30 × (5 − 1) = 100
* 30 × 5 − 30 × 1 = 70

As can be seen from these examples, familiar properties like [[associativity]] and [[distributivity]] may fail in saturation arithmetic.&lt;ref&gt;In fact, ''non''-saturation arithmetic can also suffer associativity and distributivity failures in limited-precision environments, but such failures tend to be less obvious.&lt;/ref&gt; This makes it unpleasant to deal with in abstract mathematics, but it has an important role to play in [[digital hardware]] and algorithms.

== Modern use ==
Typically, general-purpose [[microprocessor]]s do not implement integer arithmetic operations using saturation arithmetic; instead, they use the easier-to-implement [[modular arithmetic]], in which values exceeding the maximum value "[[Integer overflow|wrap around]]" to the minimum value, like the hours on a clock passing from 12 to 1. In hardware, modular arithmetic with a minimum of zero and a maximum of r&lt;sup&gt;''n''&lt;/sup&gt;-1, where r is the radix can be implemented by simply discarding all but the lowest ''n'' digits.  For binary hardware, which the vast majority of modern hardware is, the radix is 2 and the digits are bits.

However, although more difficult to implement, saturation arithmetic has numerous practical advantages. The result is as numerically close to the true answer as possible; for 8-bit binary signed arithmetic, when the correct answer is 130, it is considerably less surprising to get an answer of 127 from saturating arithmetic than to get an answer of −126 from modular arithmetic.  Likewise, for 8-bit binary unsigned arithmetic, when the correct answer is 258, it is less surprising to get an answer of 255 from saturating arithmetic than to get an answer of 2 from modular arithmetic.

Saturation arithmetic also enables overflow of additions and multiplications to be detected consistently without an overflow bit or excessive computation, by simple comparison with the maximum or minimum value (provided the datum is not permitted to take on these values).

Additionally, saturation arithmetic enables efficient algorithms for many problems, particularly in [[digital signal processing]]. For example, adjusting the volume level of a sound signal can result in overflow, and saturation causes significantly less distortion to the sound than wrap-around. In the words of researchers G. A. Constantinides et al.:

{{quote|When adding two numbers using two’s complement representation, overflow results in a ‘wrap-around’ phenomenon. The result can be a catastrophic loss in signal-to-noise ratio in a DSP system. Signals in DSP designs are therefore usually either scaled appropriately to avoid overflow for all but the most extreme input vectors, or produced using saturation arithmetic components.&lt;ref&gt;G. A. Constantinides, P. Y. K. Cheung, and W. Luk. ''[http://portal.acm.org/citation.cfm?id=785411.785415 Synthesis of Saturation Arithmetic Architectures]''&lt;/ref&gt;}}

Saturation arithmetic operations are available on many modern platforms, and in particular was one of the extensions made by the Intel [[MMX (instruction set)|MMX]] platform, specifically for such signal processing applications. This functionality is also available in wider versions in the SSE2 and AVX2 integer instruction sets.

Saturation arithmetic for integers has also been implemented in software for a number of programming languages including [[C (programming language)|C]], [[C++]], such as the [[GNU Compiler Collection]],&lt;ref&gt;
{{cite web|title=GNU Compiler Collection (GCC) Internals: Arithmetic|url=https://gcc.gnu.org/onlinedocs/gccint/Arithmetic.html|website=gcc.gnu.org}}
&lt;/ref&gt;
and [[Eiffel (programming language)|Eiffel]]. This helps programmers anticipate and understand the effects of overflow better. On the other hand, saturation is challenging to implement efficiently in software on a machine with only modular arithmetic operations, since simple implementations require branches that create huge pipeline delays.  However, it is possible to implement saturating addition and subtraction in software without branches, using only modular arithmetic and bitwise logical operations that are available on all modern CPUs and their predecessors, including all x86 CPUs (back to the original [[Intel 8086]]) and some popular 8-bit CPUs (some of which, such as the [[Zilog Z80]], are still in production).  (However, on simple 8-bit and 16-bit CPUs, a branching algorithm might actually be faster if programmed in assembly, since there are no pipelines to stall and each instruction always takes multiple clock cycles.)

Although saturation arithmetic is less popular for integer arithmetic in hardware, the [[IEEE floating-point standard]], the most popular abstraction for dealing with approximate real numbers, uses a form of saturation in which overflow is converted into "infinity" or "negative infinity", and any other operation on this result continues to produce the same value. This has the advantage over simple saturation that later operations which decrease the value will not end up producing a misleadingly "reasonable" result, such as in the computation &lt;math&gt;\sqrt{x^2-y^2}&lt;/math&gt;. Alternatively, there may be special states such as "exponent overflow" (and "exponent underflow") that will similarly persist through subsequent operations, or cause immediate termination, or be tested for as in &lt;code&gt;IF ACCUMULTOR OVERFLOW ...&lt;/code&gt; as in FORTRAN for the IBM704 (October 1956)

== DSP &amp; GPU Support ==

* The [[VideoCore]] GPU system used on many mobile telephones implements saturation arithmetic. The support is mainly for video decoding, so as to avoid visual defects.

==Notes==
{{reflist}}

== External links ==
* [http://compilers.iecc.com/comparch/article/00-02-022 SARITH: Safe ARITHmetic – A Progress Report]: Report on a saturation arithmetic component for [[Eiffel (programming language)|Eiffel]].

[[Category:Computer arithmetic]]</text>
      <sha1>f6vi5gr7unlh1q8gwxfzmz9mnnjoqtu</sha1>
    </revision>
  </page>
  <page>
    <title>Scott continuity</title>
    <ns>0</ns>
    <id>743106</id>
    <revision>
      <id>832349164</id>
      <parentid>772719950</parentid>
      <timestamp>2018-03-25T12:57:37Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <minor/>
      <comment>diacritics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5786">In [[mathematics]], given two [[partially ordered set]]s ''P'' and ''Q'', a [[Function (mathematics)|function]] &lt;math&gt;f \colon P \rightarrow Q&lt;/math&gt; between them is '''Scott-continuous''' (named after the mathematician [[Dana Scott]]) if it [[limit preserving function (order theory)|preserves]] all directed suprema, i.e. if for every [[directed set|directed subset]] ''D'' of ''P'' with [[supremum]] in ''P'' its [[image (mathematics)|image]] has a supremum in ''Q'', and that supremum is the image of the supremum of ''D'': that is, &lt;math&gt;\sqcup f[D] = f(\sqcup D)&lt;/math&gt;, where &lt;math&gt;\sqcup&lt;/math&gt; is the [[directed join]].{{nowrap end}}&lt;ref name="Vickers1989"&gt;{{Cite book |last=Vickers |first=Steven |authorlink=Steve Vickers (academia) |title=Topology via Logic |publisher=[[Cambridge University Press]] |year=1989 |isbn=0-521-36062-5}}&lt;/ref&gt; When &lt;math&gt;Q&lt;/math&gt; is the poset of truth values, i.e. [[Sierpiński space]], then the &lt;math&gt;f&lt;/math&gt; are [[Indicator function|characteristic functions]], and thus, Sierpiński space is the [[classifying topos]] for open sets.&lt;ref&gt;{{nlab|id=Scott+topology|title=Scott topology}}&lt;/ref&gt;

A subset ''O'' of a partially ordered set ''P'' is called '''Scott-open''' if it is an [[upper set]] and if it is '''inaccessible by directed joins''', i.e. if all directed sets ''D'' with supremum in ''O'' have non-empty [[intersection (set theory)|intersection]] with ''O''. The Scott-open subsets of a partially ordered set ''P'' form a [[topological space|topology]] on ''P'', the '''Scott topology'''. A function between partially ordered sets is Scott-continuous if and only if it is [[continuous function (topology)|continuous]] with respect to the Scott topology.&lt;ref name="Vickers1989"/&gt;

The Scott topology was first defined by Dana Scott for [[complete lattice]]s and later defined for arbitrary partially ordered sets.&lt;ref name="Scott1972"&gt;{{cite book |last1=Scott |first1=Dana |authorlink1=Dana Scott |editor1-last=Lawvere |editor1-first=Bill |editor1-link=Bill Lawvere |title=Toposes, Algebraic Geometry and Logic |series=Lecture Notes in Mathematics |volume=274 |year=1972 |publisher=Springer-Verlag |chapter=Continuous lattices}}&lt;/ref&gt;

Scott-continuous functions show up in the study of models for [[lambda calculi]]&lt;ref name=Scott1972 /&gt; and the [[denotational semantics]] of computer programs.

==Properties==
A Scott-continuous function is always [[monotone function|monotonic]].

A subset of a partially ordered set is [[closed set|closed]] with respect to the Scott topology induced by the partial order if and only if it is a [[lower set]]  and closed under suprema of directed subsets.&lt;ref name="AbramskyJung1994"/&gt;

A [[directed complete partial order]] (dcpo) with the Scott topology is always a [[Kolmogorov space]] (i.e., it satisfies the [[T0 separation axiom|T&lt;sub&gt;0&lt;/sub&gt; separation axiom]]).&lt;ref name="AbramskyJung1994"/&gt; However, a dcpo with the Scott topology is a [[Hausdorff space]] if and only if the order is trivial.&lt;ref name="AbramskyJung1994"/&gt; The Scott-open sets form a [[complete lattice]] when ordered by [[inclusion (set theory)|inclusion]].&lt;ref name="BauerTaylor2009"/&gt;

For any topological space satisfying the T&lt;sub&gt;0&lt;/sub&gt; separation axiom, the topology induces an order relation on that space, the [[specialization order]]: {{nowrap|''x'' ≤ ''y''}} if and only if every [[open neighbourhood]] of ''x'' is also an open neighbourhood of ''y''. The order relation of a dcpo ''D'' can be reconstructed from the Scott-open sets as the specialization order induced by the Scott topology. However, a dcpo equipped with the Scott topology need not be [[sober space|sober]]: the specialization order induced by the topology of a sober space makes that space into a dcpo, but the Scott topology derived from this order is finer than the original topology.&lt;ref name="AbramskyJung1994"&gt;{{cite book |last1=Abramsky |first1=S. |last2=Jung |first2=A. |editor1-first=S. |editor1-last=Abramsky |editor2-first=D.M. |editor2-last=Gabbay |editor3-first=T.S.E. |editor3-last=Maibaum |title=Handbook of Logic in Computer Science |series= |volume=Vol. III |year=1994 |publisher=Oxford University Press |isbn=0-19-853762-X |chapter=Domain theory |chapterurl=http://www.cs.bham.ac.uk/~axj/pub/papers/handy1.pdf }}&lt;/ref&gt;

==Examples==
The open sets in a given topological space when ordered by [[inclusion (set theory)|inclusion]] form a [[lattice (order)|lattice]] on which the Scott topology can be defined. A subset ''X'' of a topological space ''T'' is [[compact space|compact]] with respect to the topology on ''T'' (in the sense that every [[open cover]] of ''X'' contains a [[finite subcover]] of ''X'') if and only if the set of [[open neighbourhood]]s of ''X'' is open with respect to the Scott topology.&lt;ref name="BauerTaylor2009"&gt;{{cite journal |author1=Bauer, Andrej  |author2=Taylor, Paul  |lastauthoramp=yes |year=2009 |title=The Dedekind Reals in Abstract Stone Duality |journal=Mathematical Structures in Computer Science |volume=19 |pages=757–838 |publisher=[[Cambridge University Press]] |doi=10.1017/S0960129509007695 |url=http://PaulTaylor.EU/ASD/dedras/ |accessdate=October 8, 2010 }}&lt;/ref&gt;

For '''CPO''', the [[cartesian closed category]] of dcpo's, two particularly notable examples of Scott-continuous functions are [[currying|curry]] and [[apply]].&lt;ref&gt;{{cite book |last1=Barendregt |first1=H.P. |authorlink1=Henk Barendregt |title=The Lambda Calculus |year=1984 |publisher=North-Holland |isbn=0-444-87508-5}} ''(See theorems 1.2.13, 1.2.14)''&lt;/ref&gt;

==See also==
* [[Alexandrov topology]]
* [[Upper topology]]

==Footnotes==
&lt;references/&gt;

==References==
* {{planetmath reference|id=9063|title=Scott Topology}}

[[Category:Order theory]]
[[Category:General topology]]
[[Category:Domain theory]]</text>
      <sha1>cneolv5kh8wi7tf4rsmpuag05n7jvz7</sha1>
    </revision>
  </page>
  <page>
    <title>Segre's theorem</title>
    <ns>0</ns>
    <id>49713321</id>
    <revision>
      <id>840560217</id>
      <parentid>815236921</parentid>
      <timestamp>2018-05-10T17:32:18Z</timestamp>
      <contributor>
        <username>LilHelpa</username>
        <id>8024439</id>
      </contributor>
      <minor/>
      <comment>/* Definition of an oval */typo and general fixes, replaced: commom → common using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10000">{{more footnotes|date=March 2016}}
[[File:Oval-def-fin.svg|thumb|to the definition of a finite oval: &lt;math&gt;t&lt;/math&gt; tangent, &lt;math&gt;s_1,...s_n&lt;/math&gt; secants, &lt;math&gt;n&lt;/math&gt; is the order of the projective plane (number of points on a line -1)]]
In projective geometry '''Segre's theorem''', named after the Italian mathematician [[Beniamino Segre]], is the statement:
*Any [[Oval (projective plane)|oval]] in a ''finite [[Pappus's hexagon theorem|pappian]]'' [[projective plane]] of ''odd'' order is a nondegenerate projective [[conic section]].

This statement was assumed 1949 by the two Finnish mathematicians [[Gustaf Järnefelt|G. Järnefelt]] and [[Paul Kustaanheimo|P. Kustaanheimo]] and its proof was published in 1955 by B. Segre.

A finite pappian projective plane can be imagined as the projective closure of the real plane (by a line at infinity), where the [[real numbers]] are replaced by a [[finite field]] {{mvar|K}}. ''Odd order'' means that {{math|1={{!}}''K''{{!}} = ''n''}} is odd. An oval is a curve similar to a [[circle]] (see definition below): any line meets it in at most 2 points and through any point of it there is exactly one tangent. The standard examples are the nondegenerate projective conic sections.

For pappian projective planes of ''even'' order there are always ovals which are not conics. In an infinite plane there exist ovals, which are not conics. In the real plane one just glues a half of a circle and a suitable [[ellipse]] [[smoothness|smoothly]].

The proof of Segre's theorem, shown below, uses the 3-point version of [[Pascal theorem|Pascal's theorem]] and a property of a finite field of odd order, namely, that the product of all the nonzero elements equals -1.

== Definition of an oval ==
{{main|Oval (projective plane)}}
*In a projective plane a set &lt;math&gt;\mathfrak o&lt;/math&gt; of points is called '''oval''', if:
:(1) Any line &lt;math&gt;g&lt;/math&gt; meets &lt;math&gt;\mathfrak o&lt;/math&gt; in at most two points.
If &lt;math&gt;|g\cap\mathfrak o|=0&lt;/math&gt; the line &lt;math&gt;g&lt;/math&gt; is an ''exterior'' (or ''passing'') line; in case &lt;math&gt;|g\cap\mathfrak o|=1&lt;/math&gt; a ''tangent line'' and if &lt;math&gt;|g\cap\mathfrak o|=2&lt;/math&gt; the line is a ''secant line''.
:(2) For any point &lt;math&gt;P \in \mathfrak o&lt;/math&gt; there exists exactly one tangent &lt;math&gt;t&lt;/math&gt; at {{mvar|P}}, i.e., &lt;math&gt; t\cap\mathfrak o=\{P\}&lt;/math&gt;.

For ''finite'' planes (i.e. the set of points is finite) we have a more convenient characterization:
* For a finite projective plane of ''order'' {{mvar|n}} (i.e. any line contains {{math|''n'' + 1}} points) a set &lt;math&gt;\mathfrak o&lt;/math&gt; of points is an oval if and only if &lt;math&gt;|\mathfrak o|=n+1&lt;/math&gt; and no three points are [[collinear]] (on a common line).

== Pascal's 3-point version ==
[[File:Pascal-3p.svg|thumb|for the proof &lt;math&gt;g_\infty&lt;/math&gt; is the tangent at &lt;math&gt;P_3&lt;/math&gt;]]
;Theorem:
Let be &lt;math&gt;\mathfrak o&lt;/math&gt; an oval in a pappian projective plane of [[Characteristic (algebra)|characteristic]] &lt;math&gt;\ne 2&lt;/math&gt;. &lt;br /&gt;
&lt;math&gt;\mathfrak o&lt;/math&gt; is a nondegenerate conic if and only if statement '''(P3)'''
holds:
 
:'''(P3): ''' Let be &lt;math&gt;P_1,P_2,P_3&lt;/math&gt; any triangle on &lt;math&gt;\mathfrak o&lt;/math&gt; and &lt;math&gt;\overline {P_iP_i}&lt;/math&gt; the tangent at point &lt;math&gt;P_i&lt;/math&gt; to &lt;math&gt;\mathfrak o&lt;/math&gt;, then the points 
:::&lt;math&gt;P_4:= \overline {P_1P_1} \cap \overline {P_2P_3},\  P_5:= \overline {P_2P_2} \cap \overline {P_1P_3}, \ P_6:= \overline {P_3P_3} \cap \overline {P_1P_2}&lt;/math&gt; 
:::are collinear.&lt;ref&gt;E. Hartmann: ''[http://www.mathematik.tu-darmstadt.de/~ehartmann/circlegeom.pdf Planar Circle Geometries, an Introduction to Moebius-, Laguerre- and Minkowski Planes.]'' Skript, TH Darmstadt (PDF; 891&amp;nbsp;kB), p.&amp;nbsp;34.&lt;/ref&gt;

[[File:Pascal-3p-proof.svg|thumb|to the proof of the 3-point Pascal theorem]]
;Proof:
Let the projective plane be coordinatized [[Homogeneous coordinates|inhomogeneously]] over a field &lt;math&gt;K&lt;/math&gt; 
such that &lt;math&gt;P_3=(0), \; g_\infty&lt;/math&gt; is the tangent at &lt;math&gt;P_3 , \ (0,0) \in \mathfrak o&lt;/math&gt;, the x-axis is the tangent at the point &lt;math&gt;(0,0)&lt;/math&gt;  and  &lt;math&gt;\mathfrak o&lt;/math&gt; contains the point &lt;math&gt;(1,1)&lt;/math&gt;. Furthermore, we set &lt;math&gt;P_1=(x_1,y_1), \; P_2=(x_2,y_2)\ .&lt;/math&gt; (s. image)&lt;br /&gt;
The oval &lt;math&gt;\mathfrak o&lt;/math&gt; can be described by a function &lt;math&gt;f: K \mapsto K&lt;/math&gt; such that:
:&lt;math&gt;\mathfrak o=\{(x,y)\in K^2 \;|\; y=f(x)\} \ \cup \{(\infty)\}\; .&lt;/math&gt;
The tangent at point &lt;math&gt;(x_0,f(x_0))&lt;/math&gt; will be described using a function &lt;math&gt;f' &lt;/math&gt; such that its equation is
:&lt;math&gt;y=f'(x_0)(x-x_0) +f(x_0)&lt;/math&gt; 
Hence (s. image)
:&lt;math&gt;P_5=(x_1,f'(x_2)(x_1-x_2)+f(x_2))&lt;/math&gt; and  &lt;math&gt;P_4=(x_2,f'(x_1)(x_2-x_1)+f(x_1))\; .&lt;/math&gt;
'''I:''' if &lt;math&gt;\mathfrak o&lt;/math&gt; is a non degenerate conic we have &lt;math&gt;f(x)=x^2&lt;/math&gt; and &lt;math&gt;f'(x)=2x&lt;/math&gt; and one calculates easily that &lt;math&gt;P_4,P_5,P_6&lt;/math&gt; are collinear.

'''II:''' If &lt;math&gt;\mathfrak o&lt;/math&gt; is an oval with property '''(P3)''', the slope of the line &lt;math&gt;\overline{P_4P_5}&lt;/math&gt; is equal to the slope of the line &lt;math&gt;\overline{P_1P_2}&lt;/math&gt;, that means:
:&lt;math&gt;f'(x_2)+f'(x_1) - \frac{f(x_2)-f(x_1)}{x_2-x_1}=\frac{f(x_2)-f(x_1)}{x_2-x_1}&lt;/math&gt; and hence
:'''(i):''' &lt;math&gt; (f'(x_2)+f'(x_1))(x_2-x_1)=2(f(x_2)-f(x_1))&lt;/math&gt; for all  &lt;math&gt;x_1,x_2 \in K&lt;/math&gt;. 
With &lt;math&gt;f(0)=f'(0)=0&lt;/math&gt;  one gets
:(ii): &lt;math&gt;f'(x_2)x_2=2f(x_2)&lt;/math&gt; and from &lt;math&gt;f(1)=1&lt;/math&gt; we get 
:(iii): &lt;math&gt;f'(1)=2 \; .&lt;/math&gt; 
(i) and (ii) yield
:(iv): &lt;math&gt;f'(x_2)x_1=f'(x_1)x_2&lt;/math&gt; and with (iii) at least we get 
:(v): &lt;math&gt;f'(x_2)=2x_2&lt;/math&gt; for all &lt;math&gt;x_2 \in K&lt;/math&gt;. 
A consequence of (ii) and (v) is   
:&lt;math&gt;f(x_2)=x_2^2, \; x_2 \in K&lt;/math&gt;. 
Hence &lt;math&gt;\mathfrak o&lt;/math&gt; is a nondegenerate conic.

''Remark:''
Property (P3) is fulfilled for any oval in a pappian projective plane of characteristic '''2''' with a nucleus (all tangents meet at the nucleus). Hence in this case (P3) is also true for non-conic ovals.&lt;ref&gt;E. Hartmann: ''[http://www.mathematik.tu-darmstadt.de/~ehartmann/circlegeom.pdf Planar Circle Geometries, an Introduction to Moebius-, Laguerre- and Minkowski Planes.]'' Skript, TH Darmstadt (PDF; 891&amp;nbsp;kB), p.&amp;nbsp;35.&lt;/ref&gt;

== Segre's theorem and its proof ==
;Theorem:
Any oval &lt;math&gt;\mathfrak o&lt;/math&gt; in a ''finite pappian'' projective plane of ''odd'' order is a nondegenerate conic section.
[[File:Pascal-3p.svg|thumb|3-point version of Pascal's theorem, for the proof we assume &lt;math&gt;g_\infty=\overline{P_2P_3}&lt;/math&gt;]]
[[File:Segre-proof.svg|thumb|Segre's theorem: to its proof]]
;Proof:&lt;ref&gt;E. Hartmann: ''[http://www.mathematik.tu-darmstadt.de/~ehartmann/circlegeom.pdf Planar Circle Geometries, an Introduction to Moebius-, Laguerre- and Minkowski Planes.]'' Skript, TH Darmstadt (PDF; 891&amp;nbsp;kB), p.&amp;nbsp;41.&lt;/ref&gt;
For the proof we show that the oval has property '''(P3)''' of the 3-point version of Pascal's theorem.

Let be &lt;math&gt;P_1,P_2,P_3&lt;/math&gt; any triangle on &lt;math&gt;\mathfrak o&lt;/math&gt; and &lt;math&gt;P_4,P_5,P_6&lt;/math&gt; defined as described in '''(P3)'''. 
The pappian plane will be coordinatized inhomogeneously over a finite field 
&lt;math&gt;K&lt;/math&gt;, such that&lt;math&gt;P_3=(\infty),\; P_2=(0),\; P_1=(1,1)&lt;/math&gt; and &lt;math&gt; (0,0)&lt;/math&gt; is the common point of the tangents at &lt;math&gt;P_2&lt;/math&gt; and &lt;math&gt;P_3&lt;/math&gt;. The oval &lt;math&gt;\mathfrak o&lt;/math&gt; can be described using a [[bijective]] function &lt;math&gt;f: K^*:=K\cup \setminus \{0\} \mapsto K^*&lt;/math&gt;:
:&lt;math&gt;\mathfrak o=\{(x,y)\in K^2\; | \; y=f(x), \; x\ne 0\}\; \cup \; \{(0),(\infty)\}\; .&lt;/math&gt;
For a point &lt;math&gt;P=(x,y), \; x\in K\setminus\{0,1\}&lt;/math&gt;, the expression  &lt;math&gt;m(x)=\tfrac{f(x)-1}{x-1}&lt;/math&gt; is the slope of the secant &lt;math&gt;\overline{PP_1}\; .&lt;/math&gt; Because both the functions &lt;math&gt;x\mapsto f(x)-1&lt;/math&gt; and &lt;math&gt;x\mapsto x-1&lt;/math&gt; are bijections from
&lt;math&gt;K\setminus\{0,1\}&lt;/math&gt; to &lt;math&gt;K\setminus\{0,-1\}&lt;/math&gt;, and &lt;math&gt;x\mapsto m(x)&lt;/math&gt; a bijection  from &lt;math&gt;K\setminus\{0,1\}&lt;/math&gt; onto  &lt;math&gt;K\setminus\{0,m_1\}&lt;/math&gt;, where &lt;math&gt;m_1&lt;/math&gt; is the slope of the tangent at  &lt;math&gt;P_1&lt;/math&gt;, for &lt;math&gt;K^{**}:=K\setminus\{0,1\}\; :&lt;/math&gt;  we get
:&lt;math&gt;\prod_{x\in K^{**}}(f(x)-1)=\prod_{x\in K^{**}}(x-1)=1 \quad \text{und}\quad
m_1\cdot\prod_{x\in K^{**}}\frac{f(x)-1}{x-1}=-1\; .&lt;/math&gt;
(Remark: For &lt;math&gt;K^*:= K\setminus\{0\}&lt;/math&gt; we have: 
&lt;math&gt;\displaystyle \prod_{k\in K^*}k=-1\; .&lt;/math&gt;)&lt;br /&gt;
Hence
:&lt;math&gt;-1=m_1\cdot\prod_{x\in K^{**}}\frac{f(x)-1}{x-1}=
m_1\cdot\frac{
\displaystyle \prod_{x\in K^{**}}(f(x)-1)}{
\displaystyle \prod_{x\in K^{**}}(x-1)}=m_1\; .&lt;/math&gt;
Because the slopes of line &lt;math&gt;\overline{P_5P_6}&lt;/math&gt;  and tangent
&lt;math&gt;\overline{P_1P_1}&lt;/math&gt; both are &lt;math&gt;-1&lt;/math&gt;, it follows that
&lt;math&gt;\overline{P_1P_1}\cap \overline{P_2P_3}=P_4 \in\overline{P_5P_6} &lt;/math&gt;.
This is true for any triangle &lt;math&gt;P_1,P_2,P_3 \in \mathfrak o&lt;/math&gt;.

So: '''(P3)''' of the 3-point Pascal theorem holds and the oval is a non degenerate conic.

== References ==
{{reflist}}
* [[Beniamino Segre|B. Segre]]: ''Ovals in a finite projective plane'', Canadian Journal of Mathematics 7 (1955), pp.&amp;nbsp;414–416.
* [[Gustaf Järnefelt|G. Järnefelt]] &amp; [[Paul Kustaanheimo|P. Kustaanheimo]]: ''An observation on finite Geometries'', Den 11 te Skandinaviske Matematikerkongress, Trondheim (1949), pp.&amp;nbsp;166–182.
* [[Albrecht Beutelspacher]], Ute Rosenbaum: ''Projektive Geometrie.'' 2. Auflage. Vieweg, Wiesbaden 2004, {{ISBN|3-528-17241-X}}, p.&amp;nbsp;162.
* [[Peter Dembowski|P. Dembowski]]: ''Finite Geometries.'' Springer-Verlag, 1968, {{ISBN|3-540-61786-8}}, p.&amp;nbsp;149

== External links ==
* Simeon Ball and Zsuzsa Weiner: ''An Introduction to Finite Geometry'' [http://www-ma4.upc.es/~simeon/IFG.pdf] p.&amp;nbsp;17.

[[Category:Conic sections]]
[[Category:Theorems in projective geometry]]
[[Category:Articles containing proofs]]
[[Category:Theorems in plane geometry]]
[[Category:Theorems in geometry]]
[[Category:Projective geometry]]
[[Category:Incidence geometry]]</text>
      <sha1>ktm3k6sc9h17cpoxi0dqxfqik2xel8a</sha1>
    </revision>
  </page>
  <page>
    <title>Square (algebra)</title>
    <ns>0</ns>
    <id>659942</id>
    <revision>
      <id>868873106</id>
      <parentid>868872994</parentid>
      <timestamp>2018-11-15T00:09:59Z</timestamp>
      <contributor>
        <username>Gilded Snail</username>
        <id>21753329</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/96.255.75.78|96.255.75.78]] ([[User talk:96.255.75.78|talk]]) to last revision by Joel B. Lewis. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13912">{{Redirect|²|typography of superscripts|subscript and superscript}}
{{no footnotes|date=August 2015}}
[[Image:Five Squared.svg|thumb|right|168px&lt;!-- at 160px and 200px lines render with unequal widths 
--&gt;|{{math|5&amp;sdot;5}}, or {{math|5&lt;sup&gt;2&lt;/sup&gt;}} (5 squared), can be shown graphically using a [[square]]. Each block represents one unit, {{math|1&amp;sdot;1}}, and the entire square represents {{math|5&amp;sdot;5}}, or the area of the square.]]
In [[mathematics]], a '''square''' is the result of [[multiplication|multiplying]] a [[number]] by itself. The verb "to square" is used to denote this operation. Squaring is the same as [[exponentiation|raising to]] the power&amp;nbsp;[[2 (number)|2]], and is denoted by a [[superscript]] 2; for instance, the square of 3 may be written as 3&lt;sup&gt;2&lt;/sup&gt;, which is the number 9.
In some cases when superscripts are not available, as for instance in [[programming language]]s or [[plain text]] files, the notations &lt;kbd&gt;''x''^2&lt;/kbd&gt; or &lt;kbd&gt;''x''**2&lt;/kbd&gt; may be used in place of &lt;kbd&gt;''x''&lt;sup&gt;2&lt;/sup&gt;&lt;/kbd&gt;.

The adjective which corresponds to squaring is ''[[wikt:quadratic|quadratic]]''.

The square of an [[integer]] may also be called a [[square number]] or a perfect square. In [[algebra]], the operation of squaring is often generalized to [[polynomial]]s, other [[expression (mathematics)|expressions]], or values in systems of mathematical values other than the numbers. For instance, the square of the [[linear function (calculus)|linear polynomial]] {{math|''x'' + 1}} is the [[quadratic polynomial]] {{math|1=(''x''+1)&lt;sup&gt;2&lt;/sup&gt; = ''x''&lt;sup&gt;2&lt;/sup&gt; + 2''x'' + 1}}.

One of the important properties of squaring, for numbers as well as in many other mathematical systems, is that (for all numbers {{mvar|x}}), the square of {{mvar|x}} is the same as the square of its [[additive inverse]] {{math|&amp;minus;''x''}}. That is,  the square function satisfies the identity {{math|1=''x''&lt;sup&gt;2&lt;/sup&gt; = (−''x'')&lt;sup&gt;2&lt;/sup&gt;}}. This can also be expressed by saying that the squaring function is an [[even function]].

== In real numbers ==
[[Image:Parabola2.svg|thumb|240px|{{math|1=''y'' = ''x''&lt;sup&gt;2&lt;/sup&gt;}}. The graph of a [[quadratic function]] has a [[parabola|parabolic]] shape. The squares of numbers make a [[power law]].]]
The squaring function preserves the order of positive numbers: larger numbers have larger squares. In other words, squaring is a [[monotonic function]] on the interval {{closed-open|0, +∞}}. On the negative numbers, numbers with greater absolute value have greater squares, so squaring is a monotonically decreasing function on {{open-closed|−∞,0}}. Hence, [[zero]] is the (global) [[minimum]] of the square function.
The square {{math|''x''&lt;sup&gt;2&lt;/sup&gt;}} of a number {{math|''x''}} is less than {{mvar|x}} (that is {{math|''x''&lt;sup&gt;2&lt;/sup&gt; &lt; ''x''}}) if and only if {{math|0 &lt; ''x'' &lt; 1}}, that is, if {{mvar|x}} belongs to the [[open interval]] {{open-open|0,1}}. This implies that the square of an integer is never less than the original number {{mvar|x}}.

Every positive [[real number]] is the square of exactly two numbers, one of which is strictly positive and the other of which is strictly negative. Zero is the square of only one number, itself. For this reason, it is possible to define the [[square root]] function, which associates with a non-negative real number the non-negative number whose square is the original number.

No square root can be taken of a negative number within the system of [[real number]]s, because squares of all real numbers are [[non-negative]]. The lack of real square roots for the negative numbers can be used to expand the real number system to the [[complex number]]s, by postulating the [[imaginary unit]] {{mvar|i}}, which is one of the square roots of&amp;nbsp;&amp;minus;1.

The property "every non negative real number is a square" has been generalized to the notion of a [[real closed field]], which is an [[ordered field]] such that every non negative element is a square and every polynomial of odd degree has a root. The real closed fields cannot be distinguished from the field of real numbers by their algebraic properties: every property of the real numbers, which may be expressed in [[first-order logic]] (that is expressed by a formula in which the variables that are quantified by ∀ or ∃ represent elements, not sets), is true for every real closed field, and conversely every property of the first-order logic, which is true for a specific real closed field is also true for the real numbers.

== In geometry ==
There are several major uses of the squaring function in geometry.

The name of the squaring function shows its importance in the definition of the [[area]]:  it comes from the fact that the area of a [[square]] with sides of length &amp;nbsp;{{mvar|l}} is equal to {{math|''l''&lt;sup&gt;2&lt;/sup&gt;}}. The area depends quadratically on the size: the area of a shape {{mvar|n}}&amp;nbsp;times larger is {{math|''n''&lt;sup&gt;2&lt;/sup&gt;}}&amp;nbsp;times greater. This holds for areas in three dimensions as well as in the plane: for instance, the surface area of a [[sphere]] is proportional to the square of its radius, a fact that is manifested physically by the [[inverse-square law]] describing how the strength of physical forces such as gravity varies according to distance.

{{anchor|r²}}[[Image:Zonenplatte Cosinus.png|thumb|right|Fresnel's [[zone plate]]s have rings with [[arithmetic progression|equally spaced]] squared distances to the center]]
The squaring function is related to [[distance]] through the [[Pythagorean theorem]] and its generalization, the [[parallelogram law]]. [[Euclidean geometry|Euclidean]] distance is not a [[smooth function]]: the [[graph of a function of two variables|three-dimensional graph]] of distance from a fixed point forms a [[cone]], with a non-smooth point at the tip of the cone. However, the square of the distance (denoted {{math|''d''&lt;sup&gt;2&lt;/sup&gt;}} or {{math|''r''&lt;sup&gt;2&lt;/sup&gt;}}), which has a [[paraboloid]] as its graph, is a smooth and [[analytic function]]. The [[dot product]] of a [[Euclidean vector]] with itself is equal to the square of its length: {{math|1='''v'''&amp;sdot;'''v''' = v&lt;sup&gt;2&lt;/sup&gt;}}. This is further generalised to [[quadratic form]]s in [[linear space]]s. The [[inertia tensor]] in [[mechanics]] is an example of a quadratic form. It demonstrates a quadratic relation of the [[moment of inertia]] to the size ([[length]]).

There are infinitely many [[Pythagorean triple]]s, sets of three positive integers such that the sum of the squares of the first two equals the square of the third. Each of these triples gives the integer sides of a right triangle.

==In abstract algebra and number theory==
The squaring function is defined in any [[field (mathematics)|field]] or [[ring (mathematics)|ring]]. An element in the image of this function is called a ''square'', and the inverse images of a square are called ''[[square root]]s''.

The notion of squaring is particularly important in the [[finite field]]s  '''Z'''/''p'''''Z''' formed by the numbers modulo an odd [[prime number]] {{mvar|p}}. A non-zero element of this field is called a [[quadratic residue]] if it is a square in '''Z'''/''p'''''Z''', and otherwise, it is called a quadratic non-residue. Zero, while a square, is not considered to be a quadratic residue. Every finite field of this type has exactly {{math|(''p'' − 1)/2}} quadratic residues and exactly {{math|(''p'' − 1)/2}} quadratic non-residues. The quadratic residues form a [[group (mathematics)|group]] under multiplication. The properties of quadratic residues are widely used in [[number theory]].

More generally, in rings, the squaring function may have different properties that are sometimes used to classify rings.

Zero may be the square of some non-zero elements. A [[commutative ring]] such that the square of a non zero element is never zero is called a [[reduced ring]]. More generally, in a commutative ring, a [[radical ideal]] is an ideal&amp;nbsp;{{mvar|I}} such that &lt;math&gt;x^2 \in I&lt;/math&gt; implies &lt;math&gt;x \in I&lt;/math&gt;. Both notions are important in [[algebraic geometry]], because of [[Hilbert's Nullstellensatz]].

An element of a ring that is equal to its own square is called an [[idempotent]]. In any ring, 0 and 1 are idempotents. {{anchor|integral domains}}There are no other idempotents in fields and more generally in [[integral domain]]s. However, 
the ring of the integers [[modular arithmetic|modulo]]&amp;nbsp;{{mvar|n}} has [[power of two|{{math|2&lt;sup&gt;''k''&lt;/sup&gt;}}]] idempotents, where {{mvar|k}} is the number of distinct [[integer factorization|prime factors]] of&amp;nbsp;{{mvar|n}}.
A commutative ring in which every element is equal to its square (every element is idempotent) is called a [[Boolean ring]]; an example from [[computer science]] is the ring whose elements are [[binary number]]s, with [[Bitwise operation|bitwise AND]] as the multiplication operation and bitwise XOR as the addition operation.

In a [[supercommutative algebra]] ([[away from 2]]), the square of any ''odd'' element equals to zero.

If ''A'' is a [[commutative property|commutative]] [[semigroup]], then one has
:&lt;math&gt;\forall x, y \isin A \quad (xy)^2 = xy xy = xx yy = x^2 y^2  .&lt;/math&gt;
In the language of [[quadratic form]]s, this equality says that the squaring function is a "form permitting composition". In fact, the squaring function is the foundation upon which other quadratic forms are constructed which also permit composition. The procedure was introduced by [[L. E. Dickson]] to produce the [[octonion]]s out of [[quaternion]]s by doubling. The doubling method was formalized by [[A. A. Albert]] who started with the [[real number]] [[field (mathematics)|field]] ℝ and the squaring function, doubling it to obtain the [[complex number]] field with quadratic form x&lt;sup&gt;2&lt;/sup&gt; + y&lt;sup&gt;2&lt;/sup&gt;, and then doubling again to obtain quaternions. The doubling procedure is called the [[Cayley–Dickson process]] and the structures produced are [[composition algebra]]s.

The squaring function can be used with ℂ as the start for another use of the Cayley–Dickson process leading to bicomplex, biquaternion, and bioctonion composition algebras.

==In complex numbers and related algebras over the reals==
{{anchor|In complex analysis}}
{{see also|Exponentiation #Powers of complex numbers}}
The [[complex numbers|complex]] square function&amp;nbsp;{{math|''z''&lt;sup&gt;2&lt;/sup&gt;}} is a twofold cover of the [[complex plane]], such that each non-zero complex number has exactly two square roots. This map is related to [[parabolic coordinates]].&lt;!-- unfortunately, incompatible coefficients and orientation conventions hinder a simple explanation such as σ+iτ → (σ,τ)-parabolic --&gt;

== Other uses ==
Squares are ubiquitous in algebra, more generally, in almost every branch of mathematics, and also in [[physics]] where many [[unit of measurement|units]] are defined using squares and [[multiplicative inverse|inverse]] squares: see [[#Related physical quantities|below]].

[[Least squares]] is the standard method used with [[overdetermined system]]s.

Squaring is used in [[statistics]] and [[probability theory]] in determining the [[standard deviation]] of a set of values, or a [[random variable]]. The deviation of each value&amp;nbsp;{{mvar|x&lt;sub&gt;i&lt;/sub&gt;}} from the [[mean]]&amp;nbsp;&lt;math&gt;\overline{x}&lt;/math&gt; of the set is defined as the difference &lt;math&gt;x_i - \overline{x}&lt;/math&gt;. These deviations are squared, then a mean is taken of the new set of numbers (each of which is positive). This mean is the [[variance]], and its square root is the standard deviation. In [[finance]], the [[volatility (finance)|volatility]] of a financial instrument is the standard deviation of its values.

==See also==
&lt;!--
* [[von Neumann regular ring]], a ring such that every ideal is generated by an idempotent
 too remote from the topic? --&gt;
* [[Exponentiation by squaring]]
* [[Polynomial SOS]], the representation of a non-negative polynomial as the sum of squares of polynomials
* [[Hilbert's seventeenth problem]], for the representation of [[positive polynomial]]s as a sum of squares of [[rational function]]s
* [[Square-free polynomial]]
* [[Cube (algebra)]]
* [[Metric tensor]]
* [[Quadratic equation]]
* [[Polynomial ring]]
* [[Sums of squares (disambiguation)|Sums of squares]] (disambiguation page with various relevant links)

=== Related identities ===
; Algebraic&lt;span style="font-weight:400"&gt; (need a [[commutative ring]])&lt;/span&gt;:
* [[Difference of two squares]]
* [[Brahmagupta–Fibonacci identity]], related to complex numbers [[#.7Cz.7C²|in the sense discussed above]]
* [[Euler's four-square identity]], related to [[quaternion]]s in the same way
* [[Degen's eight-square identity]], related to [[octonion]]s in the same way
* [[Lagrange's identity]]
; Other
* [[Pythagorean trigonometric identity]]
* [[Parseval's identity]]

=== Related physical quantities ===
* [[acceleration]], length per square time
* [[cross section (physics)]], an area-dimensioned quantity
* [[coupling constant]] (has square charge in the denominator, and may be expressed with square distance in the numerator)
* [[kinetic energy]] (quadratic dependence on velocity)
* [[specific energy]], a (square velocity)-dimensioned quantity

== Footnotes ==
{{reflist}}

==Further reading==
* Marshall, Murray Positive polynomials and sums of squares. Mathematical Surveys and Monographs, 146. American Mathematical Society, Providence, RI, 2008. xii+187 pp. {{isbn|978-0-8218-4402-1}}, {{isbn|0-8218-4402-4}}
* {{cite book | title=Squares | volume=171 | series=London Mathematical Society Lecture Note Series | first=A. R. | last=Rajwade | publisher=[[Cambridge University Press]] | year=1993 | isbn=0-521-42668-5 | zbl=0785.11022 }}

[[Category:Algebra]]
[[Category:Elementary arithmetic]]
[[Category:Exponentials|2]]
[[Category:Squares in number theory]]
[[Category:Unary operations]]</text>
      <sha1>gq1ki3vzobbx466zr7y9kr3um6hagqj</sha1>
    </revision>
  </page>
  <page>
    <title>Squashed entanglement</title>
    <ns>0</ns>
    <id>5577596</id>
    <revision>
      <id>866516337</id>
      <parentid>863460308</parentid>
      <timestamp>2018-10-30T20:30:12Z</timestamp>
      <contributor>
        <username>User-duck</username>
        <id>28568042</id>
      </contributor>
      <comment>Remove |class=. Move image a little.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14337">'''Squashed entanglement''', also called '''CMI entanglement''' (CMI can be  pronounced "see me"), is an information theoretic measure of [[quantum entanglement]] for a bipartite quantum system. If &lt;math&gt;\varrho_{A, B}&lt;/math&gt; is the [[density matrix]] of a system &lt;math&gt;(A,B)&lt;/math&gt; composed of two subsystems &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;, then the CMI entanglement &lt;math&gt;E_{CMI}&lt;/math&gt; of system &lt;math&gt;(A,B)&lt;/math&gt; is defined by

{{NumBlk|1=:|2=&lt;math&gt;
E_{CMI}(\varrho_{A, B}) = \frac{1}{2}\min_{\varrho_{A,B,\Lambda}\in K}S(A:B | \Lambda) 
&lt;/math&gt;,|3='''Eq.(1)'''|RawN=.}}

where &lt;math&gt;K&lt;/math&gt; is the set of all density matrices &lt;math&gt;\varrho_{A, B, \Lambda}&lt;/math&gt; for a tripartite system &lt;math&gt;(A,B,\Lambda)&lt;/math&gt; such that &lt;math&gt;\varrho_{A, B}=tr_\Lambda (\varrho_{A, B, \Lambda})&lt;/math&gt;. Thus, CMI entanglement is defined as an extremum of a [[Functional (mathematics)|functional]] &lt;math&gt;S(A:B | \Lambda)&lt;/math&gt; of &lt;math&gt;\varrho_{A, B, \Lambda}&lt;/math&gt;. We define  &lt;math&gt;S(A:B | \Lambda)&lt;/math&gt;, the quantum '''Conditional Mutual Information (CMI)''', below. A more general version of Eq.(1) replaces the ``min" (minimum) in Eq.(1) by an ``inf" ([[infimum]]). When &lt;math&gt;\varrho_{A, B}&lt;/math&gt; is a pure state, 
&lt;math&gt;E_{CMI}(\varrho_{A, B})=S(\varrho_{A})=S(\varrho_{B})&lt;/math&gt;, in agreement with the definition of [[entanglement of formation]] for pure states. Here &lt;math&gt;S(\varrho)&lt;/math&gt; is the [[Von Neumann entropy]] of density matrix &lt;math&gt;\varrho&lt;/math&gt;.

==Motivation for definition of CMI entanglement==

CMI entanglement has its roots in [[Information theory|classical (non-quantum) information theory]], as we explain next.

Given any two [[random variables]] &lt;math&gt;A,B&lt;/math&gt;, classical information theory defines the [[mutual information]], a measure of correlations, as

{{NumBlk|1=:|2=&lt;math&gt;
H(A:B) =H(A) + H(B) - H(A, B)\,
&lt;/math&gt;.|3='''Eq.(2)'''|RawN=.}}

For three random variables &lt;math&gt;A,B,\Lambda&lt;/math&gt;, it defines the CMI as
{{NumBlk|1=:|2=&lt;math&gt;
\begin{matrix}
H(A : B | \Lambda)&amp;=&amp; H(A|\Lambda)+ H(B | \Lambda)- H(A, B | \Lambda)\\
&amp;=&amp;H(A, \Lambda)+H(B, \Lambda)-H(\Lambda)-H(A, B, \Lambda)
\end{matrix}
&lt;/math&gt;.|3='''Eq.(3)'''|RawN=.}}

It can be shown that &lt;math&gt;H(A : B | \Lambda)\geq 0&lt;/math&gt;.

Now suppose &lt;math&gt;\varrho_{A, B, \Lambda}&lt;/math&gt; is the density matrix for a tripartite system &lt;math&gt;(A,B,\Lambda)&lt;/math&gt;. We will represent the [[partial trace]] of &lt;math&gt;\varrho_{A, B, \Lambda}&lt;/math&gt; with respect to one or two of its subsystems by &lt;math&gt;\varrho_{A, B, \Lambda}&lt;/math&gt; with the symbol for the traced system erased. For example, &lt;math&gt;\varrho_{A, B}= trace_\Lambda(\varrho_{A, B, \Lambda})&lt;/math&gt;. One can define a quantum analogue of Eq.(2) by

{{NumBlk|1=:|2=&lt;math&gt;
S(A:B) = S(\varrho_{A}) + S(\varrho_{B}) -S(\varrho_{A, B})
\,&lt;/math&gt;,|3='''Eq.(4)'''|RawN=.}}

and a quantum analogue of Eq.(3) by

{{NumBlk|1=:|2=&lt;math&gt;
S(A:B|\Lambda) =
S(\varrho_{A, \Lambda})
+S(\varrho_{B, \Lambda})
-S(\varrho_\Lambda)
-S(\varrho_{A, B, \Lambda})
\,&lt;/math&gt;.|3='''Eq.(5)'''|RawN=.}}

It can be shown that &lt;math&gt;S(A : B | \Lambda)\geq 0&lt;/math&gt;. This inequality is often called the '''[[Strong Subadditivity of Quantum Entropy|strong-subadditivity]]''' property of quantum entropy.

Consider three random variables &lt;math&gt;A,B, \Lambda&lt;/math&gt; with probability distribution &lt;math&gt;P_{A,B,\Lambda}(a,b, \lambda)&lt;/math&gt;, which we will abbreviate as &lt;math&gt;P(a,b, \lambda)&lt;/math&gt;. For those special &lt;math&gt;P(a, b, \lambda)&lt;/math&gt; of the form

{{NumBlk|1=:|2=&lt;math&gt;
P(a, b, \lambda) = P(a| \lambda) P(b | \lambda) P(\lambda)\,
&lt;/math&gt;,|3='''Eq.(6)'''|RawN=.}}

[[Image:Bnet fan2.png|frame|Fig.1: Bayesian Network representation of Eq.(6)]]
it can be shown that &lt;math&gt;H(A: B |\Lambda)=0&lt;/math&gt;. Probability distributions of the form Eq.(6) are in fact described by the [[Bayesian network]] shown in Fig.1.

One can define a classical CMI entanglement by

{{NumBlk|1=:|2=&lt;math&gt;
E_{CMI}( P_{A,B}) = \min_{P_{A, B, \Lambda}\in K} H(A: B |\Lambda)
&lt;/math&gt;,|3='''Eq.(7)'''|RawN=.}}

where &lt;math&gt;K&lt;/math&gt; is the set of all probability distributions &lt;math&gt;P_{A,B,\Lambda}&lt;/math&gt; in three random variables &lt;math&gt;A,B,\Lambda&lt;/math&gt;, such that &lt;math&gt;\sum_\lambda P_{A,B,\Lambda}(a, b,\lambda)=P_{A,B}(a,b)\,&lt;/math&gt;for all &lt;math&gt;a,b&lt;/math&gt;. Because, given a probability distribution &lt;math&gt;P_{A,B}&lt;/math&gt;, one can always extend it to a probability distribution &lt;math&gt;P_{A,B, \Lambda}&lt;/math&gt; that satisfies Eq.(6), it follows that the classical CMI entanglement, &lt;math&gt;E_{CMI}( P_{A,B})&lt;/math&gt;, is zero for all &lt;math&gt;P_{A,B}&lt;/math&gt;. The fact that &lt;math&gt;E_{CMI}( P_{A,B})&lt;/math&gt; always vanishes is an important motivation for the definition of &lt;math&gt;E_{CMI}( \varrho_{A,B})&lt;/math&gt;. We want a measure of quantum entanglement that vanishes in the classical regime.

Suppose &lt;math&gt;w_\lambda&lt;/math&gt; for &lt;math&gt;\lambda=1,2,...,dim(\Lambda)&lt;/math&gt; is a set of non-negative numbers that add up to one, and &lt;math&gt;|\lambda\rangle&lt;/math&gt; for &lt;math&gt;\lambda=1,2,...,dim(\Lambda)&lt;/math&gt; is an orthonormal basis for the Hilbert space associated with a quantum system &lt;math&gt;\Lambda&lt;/math&gt;. Suppose &lt;math&gt;\varrho_A^\lambda&lt;/math&gt; and &lt;math&gt;\varrho_B^\lambda&lt;/math&gt;, for &lt;math&gt;\lambda=1,2,...,dim(\Lambda)&lt;/math&gt; are density matrices for the systems &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;, respectively. It can be shown that the following density matrix

{{NumBlk|1=:|2=&lt;math&gt;
\varrho_{A, B, \Lambda}=\sum_\lambda \varrho_A^\lambda \varrho_B^\lambda w_\lambda |\lambda\rangle\langle\lambda|
\,&lt;/math&gt;|3='''Eq.(8)'''|RawN=.}}

satisfies &lt;math&gt;S(A: B |\Lambda)=0&lt;/math&gt;. Eq.(8) is the quantum counterpart of Eq.(6). Tracing the density matrix of Eq.(8) over &lt;math&gt;\Lambda&lt;/math&gt;, we get &lt;math&gt;\varrho_{A,B} = \sum_\lambda \varrho_A^\lambda \varrho_B^\lambda w_\lambda \,&lt;/math&gt;, which is a [[Separable states|separable state]]. Therefore, &lt;math&gt;E_{CMI}(\varrho_{A, B})&lt;/math&gt; given by Eq.(1) vanishes for all separable states.

When &lt;math&gt;\varrho_{A, B}&lt;/math&gt; is a pure state, one gets
&lt;math&gt;E_{CMI}(\varrho_{A, B})=S(\varrho_{A})=S(\varrho_{B})&lt;/math&gt;. This
agrees with the definition of [[entanglement of formation]] for pure states, as given  in '''Ben96'''.

Next suppose &lt;math&gt;|\psi_{A,B}^\lambda\rangle&lt;/math&gt; for &lt;math&gt;\lambda=1,2,...,dim(\Lambda)&lt;/math&gt; are some states in the Hilbert space associated with a quantum system &lt;math&gt;(A,B)&lt;/math&gt;. Let &lt;math&gt;K&lt;/math&gt; be the set of density matrices defined previously for Eq.(1). Define &lt;math&gt;K_o&lt;/math&gt; to be the set of all density matrices &lt;math&gt;\varrho_{A, B, \Lambda}&lt;/math&gt; that are elements of &lt;math&gt;K&lt;/math&gt; and have the special form &lt;math&gt;\varrho_{A, B, \Lambda} = \sum_\lambda|\psi_{A,B}^\lambda\rangle \langle \psi_{A,B}^\lambda| w_\lambda  |\lambda\rangle\langle\lambda|\, &lt;/math&gt;. It can be shown that if  we replace in Eq.(1) the set &lt;math&gt;K&lt;/math&gt; by its proper subset &lt;math&gt;K_o&lt;/math&gt;, then Eq.(1) reduces to the definition of entanglement of formation for mixed states, as given in '''Ben96'''. &lt;math&gt;K&lt;/math&gt; and &lt;math&gt;K_o&lt;/math&gt; represent different degrees of knowledge as to how &lt;math&gt;\varrho_{A, B, \Lambda}&lt;/math&gt; was created. &lt;math&gt;K&lt;/math&gt; represents total ignorance.

Since CMI entanglement reduces to [[entanglement of formation]] if one minimizes over &lt;math&gt;K_o&lt;/math&gt; instead of &lt;math&gt;K&lt;/math&gt;, one expects that CMI entanglement inherits many desirable properties from entanglement of formation.

==History==

The important inequality &lt;math&gt;S(A : B | \Lambda)\geq 0&lt;/math&gt; was first proved by Lieb and Ruskai in '''LR73'''.

Classical CMI, given by Eq.(3), first entered [[information theory]] lore, shortly after Shannon's seminal 1948 paper and at least as early as 1954 in '''McG54'''. The quantum CMI, given by Eq.(5), was first defined by Cerf and Adami in '''Cer96'''. However, it appears that Cerf and Adami did not realize the relation of CMI to entanglement or the possibility of obtaining a measure of quantum entanglement based on CMI; this can be inferred, for example, from a later paper, '''Cer97''', where they try to use &lt;math&gt;S(A|B)&lt;/math&gt; instead of CMI to understand entanglement. The first paper to explicitly point out a connection between CMI and quantum entanglement appears to be '''Tuc99'''.

The final definition Eq.(1) of CMI entanglement was first given by Tucci in a series of 6 papers. (See, for example, Eq.(8) of '''Tuc02''' and Eq.(42) of '''Tuc01a'''). In '''Tuc00b''', he pointed out the classical probability motivation of Eq.(1), and its connection to the definitions of entanglement of formation for pure and mixed states. In '''Tuc01a''', he presented an algorithm and computer program, based on the [[Rate distortion theory|Arimoto-Blahut method]] of information theory, for calculating CMI entanglement numerically. In '''Tuc01b''', he calculated CMI entanglement analytically, for a mixed state of two  [[qubits]].

In '''Hay03''', Hayden, Jozsa, Petz and Winter explored the connection between  quantum CMI and [[separable states|separability]].

It was not however, until '''Chr03''', that it was shown that CMI entanglement is in fact an entanglement measure, i.e. that it does not increase under Local Operations and Classical Communication (LOCC).  The proof adapted '''Ben96''' arguments about entanglement of formation. In '''Chr03''', they also proved many other interesting inequalities concerning CMI entanglement, including that it was additive, and explored its connection to other measures of entanglement.  The name '''squashed entanglement''' first appeared in '''Chr03'''.  In '''Chr05''', Christandl and Winter calculated analytically the CMI entanglement of some interesting states.

In '''Ali03''', Alicki and Fannes proved the continuity of CMI entanglement.  In '''BCY10''', Brandao, Christandl and Yard showed that CMI entanglement is zero if and only if the state is separable. In '''Hua14''', Huang proved that computing squashed entanglement is NP-hard.

==References==

*'''Ali03''' {{cite journal|last1=Alicki | first1=R.|last2=Fannes | first2=M.|title=Continuity of quantum mutual information|year=2003|volume=37|issue=55|journal=J. Phys. A |arxiv=quant-ph/0312081|bibcode = 2004JPhA...37L..55A |doi = 10.1088/0305-4470/37/5/L01 |pages=L55–L57}}
*'''BCY10''' {{cite journal|journal=Communications in Mathematical Physics|volume=306|issue=3|pages=805–830|first1=F.|last1=Brandao| first2=M.| last2=Christandl| last3=Yard|first3=J. | title=Faithful Squashed Entanglement |year=September 2011|arxiv = 1010.1750 |bibcode = 2011CMaPh.306..805B |doi = 10.1007/s00220-011-1302-1 }}
*'''Ben96''' {{cite journal|doi=10.1103/PhysRevA.54.3824|arxiv=quant-ph/9604024|last1=Bennett | first1=Charles H.|last2=DiVincenzo | first2=David P.|last3=Smolin | first3=John A.|last4=Wootters | first4=William K.|title=Mixed State Entanglement and Quantum Error Correction|year=1996|journal=Physical Review A|volume=54|pages=3824–3851|pmid=9913930|issue=5|bibcode = 1996PhRvA..54.3824B }}
*'''Cer96''' {{cite arXiv|eprint=quant-ph/9605002|last1=Cerf | first1=N. J.|last2=Adami | first2=C.|title=Quantum Mechanics of Measurement|year=1996}}
*'''Cer97''' {{cite journal|doi=10.1103/PhysRevA.60.893|arxiv=quant-ph/9710001|last1=Cerf | first1=N. J.|last2=Adami | first2=C.|last3=Gingrich | first3=R. M.|title=Quantum conditional operator and a criterion for separability|year=1999|journal=Physical Review A|volume=60|pages=893–898|bibcode = 1999PhRvA..60..893C|issue=2 }}
*'''Chr03''' {{cite journal|arxiv=quant-ph/0308088|doi=10.1063/1.1643788|author1=Matthias Christandl|author2=Andreas Winter|title="Squashed Entanglement": An Additive Entanglement Measure|year=2003|journal=Journal of Mathematical Physics|volume=45|pages=829–840|bibcode = 2004JMP....45..829C|issue=3 }}
*'''Chr05''' {{cite journal|doi= 10.1109/TIT.2005.853338|arxiv=quant-ph/0501090|author1=Matthias Christandl|author2=Andreas Winter|title=Uncertainty, Monogamy, and Locking of Quantum Correlations|year=2005|journal= IEEE Transactions on Information Theory|volume= 51|pages= 3159–3165|issue= 9}}
*'''Chr06''' {{cite arXiv|eprint=quant-ph/0604183|author1=Matthias Christandl|title=The Structure of Bipartite Quantum States - Insights from Group Theory and Cryptography|year=2006}} Cambridge PhD thesis.
*'''Hay03''' {{cite journal|doi=10.1007/s00220-004-1049-z|arxiv=quant-ph/0304007|author1=Patrick Hayden|author2=Richard Jozsa|author3=Denes Petz|author4=Andreas Winter|title=Structure of states which satisfy strong subadditivity of quantum entropy with equality|year=2004|journal=Communications in Mathematical Physics|volume=246|pages=359–374|bibcode = 2004CMaPh.246..359H|issue=2 }}
*'''Hua14''' {{cite journal|last1=Huang|first1=Yichen|title=Computing quantum discord is NP-complete|journal=New Journal of Physics|date=21 March 2014|volume=16|issue=3|pages=033027|doi=10.1088/1367-2630/16/3/033027 |url=http://iopscience.iop.org/1367-2630/16/3/033027/article |arxiv = 1305.5941 |bibcode = 2014NJPh...16c3027H }}
*'''LR73''' Elliott H. Lieb, Mary Beth Ruskai, "Proof of the Strong Subadditivity of Quantum-Mechanical Entropy", Journal of Mathematical Physics '''14''' (1973) 1938-1941.
*'''McG54''' W.J. McGill, "Multivariate Information Transmission", IRE Trans. Info. Theory '''4''' (1954) 93-111.
*'''Tuc99''' {{cite arXiv|eprint=quant-ph/9909041|last1=Tucci | first1=Robert R.|title=Quantum Entanglement and Conditional Information Transmission|year=1999}}
*'''Tuc00a''' {{cite arXiv|eprint=quant-ph/0005119|last1=Tucci | first1=Robert R.|title=Separability of Density Matrices and Conditional Information Transmission|year=2000}}
*'''Tuc00b''' {{cite arXiv|eprint=quant-ph/0010041|last1=Tucci | first1=Robert R.|title=Entanglement of Formation and Conditional Information Transmission|year=2000}}
*'''Tuc01a''' {{cite arXiv|eprint=quant-ph/0101123|last1=Tucci | first1=Robert R.|title=Relaxation Method for Calculating Quantum Entanglement |year=2001}}
*'''Tuc01b''' {{cite arXiv|eprint=quant-ph/0103040|last1=Tucci | first1=Robert R.|title=Entanglement of Bell Mixtures of Two Qubits|year=2001}}
*'''Tuc02''' {{cite arXiv|eprint=quant-ph/0202144|last1=Tucci | first1=Robert R.|title=Entanglement of Distillation and Conditional Mutual Information|year=2002}}

==External links==
* [http://qip2011.quantumlah.org/scientificprogramme/movie.php?id=1010.1750 Faithful squashed entanglement]

[[Category:Quantum information science]]</text>
      <sha1>tf0r40uctfr6io67lfpjinfqnjf1ojt</sha1>
    </revision>
  </page>
  <page>
    <title>Standard part function</title>
    <ns>0</ns>
    <id>19145800</id>
    <revision>
      <id>822452022</id>
      <parentid>786530494</parentid>
      <timestamp>2018-01-26T13:11:24Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6560">In [[non-standard analysis]], the '''standard part function''' is a function from the limited (finite) [[hyperreal number]]s to the real numbers.  Briefly, the standard part function "rounds off" a finite hyperreal to the nearest real.  It associates to every such hyperreal &lt;math&gt;x&lt;/math&gt;, the unique real &lt;math&gt;x_0&lt;/math&gt; infinitely close to it, i.e. &lt;math&gt;x-x_0&lt;/math&gt; is [[infinitesimal]].  As such, it is a mathematical implementation of the historical concept of [[adequality]] introduced by [[Pierre de Fermat]],&lt;ref&gt;Karin Usadi Katz and [[Mikhail Katz|Mikhail G. Katz]] (2011) A Burgessian Critique of Nominalistic Tendencies in Contemporary Mathematics and its Historiography. [[Foundations of Science]]. {{doi|10.1007/s10699-011-9223-1}} [http://www.springerlink.com/content/tj7j2810n8223p43/] See [https://arxiv.org/abs/1104.0375 arxiv]. The authors refer to the Fermat-Robinson standard part.&lt;/ref&gt; as well as [[Leibniz]]'s [[Transcendental law of homogeneity]].

The standard part function was first defined by [[Abraham Robinson]] who used the notation &lt;math&gt;{}^{\circ}x&lt;/math&gt; for the standard part of a hyperreal &lt;math&gt;x&lt;/math&gt; (see Robinson 1974). This concept plays a key role in defining the concepts of the calculus, such as continuity, the derivative, and the integral, in [[non-standard analysis]].  The latter theory is a rigorous formalisation of calculations with [[infinitesimal]]s.  The standard part of ''x'' is sometimes referred to as its '''shadow'''.

==Definition==
[[File:Standard part function with two continua.svg|360px|thumb|right|The standard part function "rounds off" a finite hyperreal to the nearest real number. The "infinitesimal microscope" is used to view an infinitesimal neighborhood of a standard real.]]

Nonstandard analysis deals primarily with the pair &lt;math&gt;\mathbb{R}\subset{}^{\ast}\mathbb{R}&lt;/math&gt;, where the [[hyperreal number|hyperreal]]s &lt;math&gt;{}^{\ast}\mathbb{R}&lt;/math&gt; are an [[ordered field]] extension of the reals &lt;math&gt;\mathbb{R}&lt;/math&gt;, and contain infinitesimals, in addition to the reals.  In the hyperreal line every real number has a collection of numbers (called a [[monad (non-standard analysis)|monad]], or '''halo''') of hyperreals infinitely close to it.  The standard part function associates to a [[Wikt:finite|finite]] [[hyperreal number|hyperreal]] ''x'', the unique standard real number ''x&lt;sub&gt;0&lt;/sub&gt;'' which is infinitely close to it.  The relationship is expressed symbolically by writing

:&lt;math&gt;\,\mathrm{st}(x)=x_0.&lt;/math&gt;

The standard part of any [[infinitesimal]] is 0.  Thus if ''N'' is an infinite [[hypernatural]], then  1/''N'' is infinitesimal, and st(1/''N'')&amp;nbsp;=&amp;nbsp;0.

If a hyperreal &lt;math&gt;u&lt;/math&gt; is represented by a Cauchy sequence &lt;math&gt;\langle u_n:n\in\mathbb{N} \rangle&lt;/math&gt; in the [[ultrapower]] construction, then 
:&lt;math&gt;\text{st}(u)=\lim_{n\to\infty}u_n.&lt;/math&gt;
More generally, each finite &lt;math&gt;u\in{}^{\ast}\mathbb{R}&lt;/math&gt; defines a [[Dedekind cut]] on the subset &lt;math&gt;\mathbb{R}\subset{}^{\ast}\mathbb{R}&lt;/math&gt; (via the total order on &lt;math&gt;{}^{\ast}\mathbb{R}&lt;/math&gt;) and the corresponding real number is the standard part of ''u''.

==Not internal==
The standard part function "st" is not defined by an [[internal set]]. There are several ways of explaining this. Perhaps the simplest is that its domain L, which is the collection of limited (i.e. finite) hyperreals, is not an internal set. Namely, since L is bounded (by any infinite hypernatural, for instance), L would have to have a least upper bound if L were internal, but L doesn't have a least upper bound. Alternatively, the range of "st" is &lt;math&gt;\mathbb{R}\subset {}^*\mathbb{R}&lt;/math&gt; which is not internal; in fact every internal set in &lt;math&gt;{}^\ast\mathbb{R}&lt;/math&gt; which is a subset of &lt;math&gt;\mathbb{R}&lt;/math&gt; is necessarily ''finite'', see (Goldblatt, 1998).

==Applications==
All the traditional notions of calculus are expressed in terms of the standard part function, as follows.
===Derivative===
The standard part function is used to define the derivative of a function ''f''.  If ''f'' is a real function, and ''h'' is infinitesimal, and if ''f''&amp;prime;(''x'') exists, then
:&lt;math&gt;f'(x) = \operatorname{st}\left(\frac {f(x+h)-f(x)}h\right).&lt;/math&gt;
Alternatively, if &lt;math&gt;y=f(x)&lt;/math&gt;, one takes an infinitesimal increment &lt;math&gt;\Delta x&lt;/math&gt;, and computes the corresponding &lt;math&gt;\Delta y=f(x+\Delta x)-f(x)&lt;/math&gt;.  One forms the ratio &lt;math&gt;\frac{\Delta y}{\Delta x}&lt;/math&gt;.  The derivative is then defined as the standard part of the ratio:
:&lt;math&gt;\frac{dy}{dx}=\mathrm{st}\left( \frac{\Delta y}{\Delta x}  \right)&lt;/math&gt;.
===Integral===
Given a function &lt;math&gt;f&lt;/math&gt; on &lt;math&gt;[a,b]&lt;/math&gt;, one defines the integral &lt;math&gt;\int_a^b f(x)dx&lt;/math&gt; as the standard part of an infinite Riemann sum &lt;math&gt;S(f,a,b,\Delta x)&lt;/math&gt; when the value of &lt;math&gt;\Delta x&lt;/math&gt; is taken to be infinitesimal, exploiting a [[hyperfinite set|hyperfinite]] partition of the interval [a,b].
===Limit===
Given a sequence &lt;math&gt;(u_n)&lt;/math&gt;, its limit is defined by &lt;math&gt;\lim_{n\to\infty}u_n=\text{st}(u_H)&lt;/math&gt; where &lt;math&gt;H\in{}^\ast\mathbb{N}\setminus\mathbb{N}&lt;/math&gt; is an infinite index.  Here the limit is said to exist if the standard part is the same regardless of the infinite index chosen.
===Continuity===
A real function &lt;math&gt;f&lt;/math&gt; is continuous at a real point &lt;math&gt;x&lt;/math&gt; if and only if the composition &lt;math&gt;\text{st}\circ f&lt;/math&gt; is ''constant'' on the [[halo (mathematics)|halo]] of &lt;math&gt;x&lt;/math&gt;. See [[microcontinuity]] for more details.

==See also==
*[[Adequality]]
*[[Non-standard calculus]]

==Notes==
{{Reflist}}

== References ==
*[[H. Jerome Keisler]]. ''[[Elementary Calculus: An Infinitesimal Approach]]''. First edition 1976; 2nd edition 1986. (This book is now out of print. The publisher has reverted the copyright to the author, who has made available the 2nd edition in .pdf format available for downloading at http://www.math.wisc.edu/~keisler/calc.html.)
*[[Robert Goldblatt|Goldblatt, Robert]]. ''Lectures on the [[hyperreal number|hyperreals]]''. An introduction to nonstandard analysis. [[Graduate Texts in Mathematics]], 188. Springer-Verlag, New York, 1998.
*[[Abraham Robinson]]. Non-standard analysis. Reprint of the second (1974) edition. With a foreword by [[Wilhelmus A. J. Luxemburg]]. Princeton Landmarks in Mathematics. Princeton University Press, Princeton, NJ, 1996. xx+293 pp. {{isbn|0-691-04490-2}}

{{Infinitesimals}}

[[Category:Calculus]]
[[Category:Non-standard analysis]]
[[Category:Real closed field]]</text>
      <sha1>jptp2343smmyjulx9e6vpccdfr77i8i</sha1>
    </revision>
  </page>
  <page>
    <title>Thiele's interpolation formula</title>
    <ns>0</ns>
    <id>4031908</id>
    <revision>
      <id>668934764</id>
      <parentid>647680786</parentid>
      <timestamp>2015-06-27T18:19:15Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* Implementation */ remove original research, in a language seemingly chosen for its uselessness</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="961">In [[mathematics]], '''Thiele's interpolation formula''' is a formula that defines a [[rational function]] &lt;math&gt;f(x)&lt;/math&gt; from a [[finite set]] of inputs &lt;math&gt;x_i&lt;/math&gt; and their function values &lt;math&gt;f(x_i)&lt;/math&gt;. The problem of generating a function whose graph passes through a given set of function values is called [[interpolation]]. This interpolation formula is named after the [[Danish people|Danish]] mathematician [[Thorvald N. Thiele]]. It is expressed as a [[continued fraction]], where ρ represents the [[reciprocal difference]]:

:&lt;math&gt; f(x) = f(x_1) + \cfrac{x-x_1}{\rho(x_1,x_2) + \cfrac{x-x_2}{\rho_2(x_1,x_2,x_3) - f(x_1) + \cfrac{x-x_3}{\rho_3(x_1,x_2,x_3,x_4) - \rho(x_1,x_2) + \cdots}}} &lt;/math&gt;

==References==
* {{mathworld|urlname=ThielesInterpolationFormula|title=Thiele's Interpolation Formula}}

[[Category:Finite differences]]
[[Category:Articles with example ALGOL 68 code]]
[[Category:Interpolation]]


{{mathanalysis-stub}}</text>
      <sha1>ksy7ua1ujh7t81e1ppsbvbb8u0ujtgc</sha1>
    </revision>
  </page>
  <page>
    <title>William Kolakoski</title>
    <ns>0</ns>
    <id>54550463</id>
    <revision>
      <id>832700540</id>
      <parentid>832633084</parentid>
      <timestamp>2018-03-27T14:34:33Z</timestamp>
      <contributor>
        <username>DePiep</username>
        <id>199625</id>
      </contributor>
      <minor/>
      <comment>OEIS in section external links: use dedicated {{OEIS el}} (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7908">{{Infobox artist
| name = William George Kolakoski 
| image = Detail_of_a_self-portrait_by_William_Kolakoski.jpg
| caption=Self-portrait by William Kolakoski
| birth_date = {{birth date|df=yes|1944|9|17}}
| birth_place = [[Pittsburgh|Pittsburgh, PA]]
| death_date = {{death date and age|df=yes|1997|7|26|1944|9|17}} 
| death_place = [[Fairmont,_West_Virginia|Fairmont, WV]]
| nationality = American
| field = [[Abstract art]], [[Portrait]]s, [[Kolakoski sequence]]
| training = [[Carnegie Mellon University|Carnegie Institute of Technology]]
}}

'''William George Kolakoski''' (Sept 17, 1944 – July 26, 1997), known as '''Bill''' to family and friends, was an [[United States of America|American]] artist and [[recreational mathematics|recreational mathematician]] who is most famous for devising and giving his name to the [[Kolakoski sequence]], a self-generating sequence of integers that has been extensively studied by [[mathematician]]s since he first described it in the ''[[American Mathematical Monthly]]'' in 1965.

==Life and education==

Kolakoski was born Sept 17, 1944, in [[Pittsburgh|Pittsburgh, PA]], the son of George Leon Kolakoski and his wife Eleanor (n&amp;eacute;e Gale). He had many interests as a boy, including art, philosophy and mathematics, but chose to study fine art at the Carnegie Institute of Technology (CIT) (now [[Carnegie Mellon University]]) because he felt that, while he could study mathematics and philosophy independently, he needed the support of others to make a career in art. His fellow students were struck by his sharp intelligence, breadth of knowledge and skills in many different fields, including the ability to play good [[chess]] without making a particular study of the game.&lt;ref name=Jim_Vargo&gt;&lt;/ref&gt;

He graduated from CIT with honors as a Bachelor of Fine Arts in painting in 1967 and worked for a time at [[United States Steel]] as a draftsman. However, because he suffered from [[schizophrenia]] and had to take constant medication to avoid psychosis and delusions, he was unable to keep in steady employment or to develop his artistic career as he wanted. He eventually moved to [[West Virginia]], where he met his wife Loretta and found a position as an artist-in-residence in [[Fairmont,_West_Virginia|Fairmont]]. In 1996, he was diagnosed with [[lung cancer]] and he passed away July 26, 1997, at the Fairmont General Hospital.&lt;ref name=Jim_Vargo&gt;&lt;/ref&gt;

==The Kolakoski sequence==

===Definition of sequence===

This sequence of integers was first discussed by the professional mathematician [[Rufus Oldenburger]] in 1939, but attracted little attention at that time. It consists of an infinite series of 1s and 2s that begins like this:

:1,2,2,1,1,2,1,2,2,1,2,2,1,1,2,1,1,2,2,1,2,1,1,2,1,2,2,1,1,… {{OEIS|A000002}}

Each symbol occurs in a "run" of either one or two consecutive terms and writing down the lengths of these runs gives exactly the same sequence:

:1,&lt;u&gt;2,2&lt;/u&gt;,&lt;u&gt;1,1&lt;/u&gt;,2,1,&lt;u&gt;2,2&lt;/u&gt;,1,&lt;u&gt;2,2&lt;/u&gt;,&lt;u&gt;1,1&lt;/u&gt;,2,&lt;u&gt;1,1&lt;/u&gt;,&lt;u&gt;2,2&lt;/u&gt;,1,2,&lt;u&gt;1,1&lt;/u&gt;,2,1,&lt;u&gt;2,2&lt;/u&gt;,&lt;u&gt;1,1&lt;/u&gt;,2,&lt;u&gt;1,1&lt;/u&gt;,2,1,&lt;u&gt;2,2&lt;/u&gt;,1,&lt;u&gt;2,2&lt;/u&gt;,&lt;u&gt;1,1&lt;/u&gt;,2,1,&lt;u&gt;2,2&lt;/u&gt;,...

:1,&amp;nbsp;2&amp;nbsp;,&amp;nbsp;2&amp;nbsp;,1,1,&amp;nbsp;2&amp;nbsp;,1,&amp;nbsp;2&amp;nbsp;,&amp;nbsp;2&amp;nbsp;,1,&amp;nbsp;2&amp;nbsp;,&amp;nbsp;2&amp;nbsp;,1,1,&amp;nbsp;2&amp;nbsp;,1,1,&amp;nbsp;2&amp;nbsp;,&amp;nbsp;2&amp;nbsp;,1,&amp;nbsp;2&amp;nbsp;,1,1,&amp;nbsp;2&amp;nbsp;,1,&amp;nbsp;2&amp;nbsp;,&amp;nbsp;2&amp;nbsp;,1,1,&amp;nbsp;2&amp;nbsp;,...

Conversely, one can say that each term of the Kolakoski sequence generates a run of one or two future terms. The first 1 of the sequence generates a run of "1", i.e. itself; the first 2 generates a run of "22", which includes itself; the second 2 generates a run of "11"; and so on. This animation illustrates the process:

[[File:Kolakoski animated.gif|800px|center|An animated gif illustrating how later terms of the Kolakoski sequence are generated by earlier terms.]]

===Kolakoski's role in popularizing the sequence===

William Kolakoski devised the sequence independently of Oldenburger and introduced it to his fellow students while at the Carnegie Institute of Technology. He submitted it to the ''[[American Mathematical Monthly]]'' (AMM) and it was published as "Advanced Problem 5304" in the following form:

:5304. ''Proposed by William Kolakoski, Carnegie Institute of Technology''

:Describe a simple rule for constructing the sequence

:1 2 2 1 1 2 1 2 2 1 2 2 1 1 2 1 1 2 2 1 2 1 1 2 1 2 2 1 1 2 1 1 2 1 2 2 1 2 2 1 1...

:What is the ''n''th term? Is the sequence periodic? (''AMM'', Vol. 72, No. 6, June–July 1965)

It was then called the Kolakoski sequence as mathematicians investigated it further.

===Analysis by mathematicians===

Despite the simplicity with which the sequence can be described and generated, it poses several interesting and complex mathematical problems, some of which remain unsolved after more than fifty years of analysis. Until almost the end of his life, Kolakoski himself was not aware of how much attention it had received from professional mathematicians after he had published notice of it in the ''AMM''. However, he eventually received a letter from an architect called William Huff that mentioned the sequence. The letter prompted Loretta Kolakoski to ask her husband's friend Mike Vargo, a writer who had first met him at CIT, to carry out further research when Kolakoski was in hospital during his final illness. Vargo discovered many references to the Kolakoski sequence on the internet and was able to inform his friend before Kolakoski passed away. Vargo felt that Kolakoski had been quietly pleased by the news, feeling that it vindicated his belief in the importance and beauty of the sequence.&lt;ref name=Jim_Vargo&gt;&lt;/ref&gt;

==Personal significance of sequence to Kolakoski==

Because he suffered from schizophrenia, Kolakoski was preoccupied with the topics of [[free will]] and [[determinism]] throughout his life. Despite his high intelligence and ability to master many different skills with little effort, his illness was, in the words of Mike Vargo, "this thing living within him that was always threatening to literally ''take over'' his mind and transport it into regions of chaos and delusion." While wanting to feel himself free, Kolakoski was well aware that he could not control his own brain without pharmaceutical help and was forced to accept determinism. Vargo therefore deduced that his friend searched for a benevolent order in the universe, of which the Kolakoski sequence was one possible expression. The sequence is entirely deterministic, yet behaves in an unpredictable and strangely beautiful way.&lt;ref name=Jim_Vargo&gt;&lt;/ref&gt; Kolakoski continued to explore the sequence for many years, creating a corpus of material that is now held as the William Kolakoski Collection at Carnegie Mellon University Libraries and overseen by the mathematician [[Clark Kimberling]].

==See also==

* [[s:William Kolakoski|William Kolakoski]] &amp;mdash; writing about William Kolakoski by his friend Mike Vargo, including the eulogy delivered at William Kolakoski's funeral, July 29, 1997

==Note==
{{reflist|refs=
&lt;ref name=Jim_Vargo&gt;Personal communication from Jim Vargo to [[Clark Kimberling]] in 2001&lt;/ref&gt;
}}
==External links==

* [https://libwebspace.library.cmu.edu/Research/Archives/UnivArchives/ead/WilliamKolakoskiCollection.xml The William Kolakoski Collection] at [http://www.library.cmu.edu/ Carnegie Mellon University Libraries]
* {{OEIS el|1=A000002|2=Kolakoski sequence|formalname=Kolakoski sequence: a(n) is length of n-th run; a(1) = 1; sequence consists just of 1's and 2's}}
* {{MathWorld|id=KolakoskiSequence|title=Kolakoski Sequence}}

{{Authority control}}
{{DEFAULTSORT:Kolakoski, William G.}}
[[Category:1944 births]]
[[Category:1997 deaths]]
[[Category:20th-century American artists]]
[[Category:Carnegie Mellon University alumni]]
[[Category:People with schizophrenia]]
[[Category:Recreational mathematics]]
[[Category:People from Pittsburgh]]</text>
      <sha1>9hejiqkv6sc88t1jq1waxesn6n9obyi</sha1>
    </revision>
  </page>
</mediawiki>
