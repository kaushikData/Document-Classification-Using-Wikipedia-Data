<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>ASTOS</title>
    <ns>0</ns>
    <id>3205518</id>
    <revision>
      <id>834449914</id>
      <parentid>787229115</parentid>
      <timestamp>2018-04-05T20:08:25Z</timestamp>
      <contributor>
        <username>Tom.Bot</username>
        <id>28901961</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:Bots/Requests for approval/Tom.Bot 4|Task 4]]: fix [[:Category:Pages using deprecated image syntax]]; [[WP:GenFixes]] on, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3919">{{Infobox Software
| name                   = ASTOS
| screenshot             = ASTOS screenshot.png
| screenshot size        = 300px
| caption                = ASTOS running on Windows 7 showing GRACE mission
| developer              = Astos Solutions GmbH
| latest_release_version = 8.0.6
| latest_release_date    = {{release date|2015|12|07}}
| operating_system       = [[Cross-platform]]
| genre                  = [[List of numerical analysis software|Technical computing]]
| license                = [[Proprietary software|Proprietary]]
| website                = [http://www.astos.de/products/astos ASTOS product website]
}}

'''ASTOS''' is a tool dedicated to mission analysis, [[Trajectory optimization]], vehicle design and [[Computer simulation|simulation]] for space scenarios, i.e. [[Launch vehicle|launch]], [[Atmospheric reentry|re-entry]] missions, [[Orbital maneuver|orbit transfers]], Earth observation, navigation, coverage and re-entry safety assessments. It solves [[Aerospace]] problems with a data driven interface and automatic initial guesses. Since 1989, with the support of the [[European Space Agency]], it has developed, and improved this trajectory optimization environment to compute optimal trajectories for a variety of complex multi-phase [[Optimal control]] problems. ASTOS is being extensively used at ESA and aerospace industry community to calculate mission analysis, optimal launch and entry trajectories and was one of the tools used by ESA to assess the risk due to the [[Automated Transfer Vehicle|ATV]] [[Jules Verne ATV|'Jules Verne']] re-entry. ASTOS is compatible with [[Microsoft Windows|Windows]] and [[Linux]] platforms and is maintained and commercialized by Astos Solutions GmbH.

==History==
The development of ASTOS (formerly named ALTOS) started in 1989 at the DLR in Oberpfaffenhofen and MBB (now Astrium).
In 1991 the Institute of Flight Mechanics and Control (IFR) at the [[University of Stuttgart]] under the head of Prof. Klaus Well took the responsibility for the development of ASTOS. In 1999 the commercialization of ASTOS began. In the period 2001-2006 ASTOS was sold by Technology Transfer Initiative of the University of Stuttgart (TTI). Since September 2006 the newly founded company Astos Solutions GmbH is responsible for development and sales of ASTOS.

==Projects==
ASTOS is being extensively used at aerospace agencies and industry since 1998, hereafter a not complete list of project is presented where the software was involved during the design or accomplishment of the space mission.
* Performance map of conventional launch vehicle: [[Ariane 6]], [[Ariane 5]], [[Vega (rocket)|Vega]], [[Soyuz (rocket family)|Soyuz]] from [[Guiana Space Centre]], several [[FLPP]] concepts, [[VLM (rocket)|VLM]]
* Feasibility study of reusable launch vehicle: [[Hopper (spacecraft)|Hopper]], [[Skylon (spacecraft)|Skylon]], [[SpaceLiner]], [[Fast 20XX]] ALPHA. 
* Earth Atmospheric re-entry: [[X-38]], [[Atmospheric Reentry Demonstrator]], [[IXV]], EXPERT.
* Safety aspect related to the [[Automated Transfer Vehicle|ATV]] re-entry.
* Planetary re-entry: [[Beagle 2]], [[ExoMars]], [[Huygens (spacecraft)|Huygens]].
* Orbit transfer and [[Space rendezvous]]: [[ConeXpress]], [[German Aerospace Center|DLR]] DEOS, [[OHB SE]] Electra.
* [[Sounding rocket]]: [[Sharp Edge Flight Experiment|SHEFEX]] II and III, [[Maser (rocket)|Maser]]11.
* Mission Analysis: [[STE-QUEST]],

==See also==
* [[Trajectory optimization]]
* [[General Mission Analysis Tool]]

==External links==
* [http://www.astos.de Astos Solutions website]
* [https://web.archive.org/web/20081201120944/http://www.ifr.uni-stuttgart.de/index_en.html Website of the Institute of Flight Mechanics and Control, University of Stuttgart]

{{DEFAULTSORT:Astos}}
[[Category:Astronomy software]]
[[Category:Mathematical software]]
[[Category:Physics software]]
[[Category:Mathematical optimization software]]</text>
      <sha1>i9a0xc17zkc5zn76pahvpkj053yi6mu</sha1>
    </revision>
  </page>
  <page>
    <title>Applicative computing systems</title>
    <ns>0</ns>
    <id>16957829</id>
    <revision>
      <id>782476328</id>
      <parentid>781354237</parentid>
      <timestamp>2017-05-27T04:18:01Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3481">'''Applicative computing systems''', or '''ACS''' are the systems of object calculi founded on [[combinatory logic]] and [[lambda calculus]].&lt;ref&gt;Wolfengagen V.E. ''Methods and means for computations with objects. Applicative Computational Systems.'' — M.: JurInfoR Ltd., «Center JurInfoR», 2004. — xvi+789 pp. {{ISBN|5-89158-100-0}}.&lt;/ref&gt; 
The only essential notion which is under consideration in these systems is the representation of [[object (computer science)|object]]. In [[combinatory logic]] the only metaoperator is [[function application|application]] in a sense of applying one object to other. In [[lambda calculus]] two metaoperators are used: [[function application|application]] – the same as in combinatory logic, and [[functional abstraction]] which binds the only variable in one object.

== Features ==

The objects generated in these systems are the functional entities with the following features:

# the number of argument places, or object arity is not fixed but is enabling step by step in interoperations with other objects;
# in a process of generating the compound object one of its counterparts—function—is applied to other one—argument—but in other contexts they can change their roles, i.e. functions and arguments are considered on the equal rights;
# the self-applying of functions is allowed, i.e. any object can be applied to itself.

ACS give a sound ground for [[applicative programming language|applicative approach]] to programming.

== Research challenge ==

Applicative computing systems' lack of storage and history sensitivity is the basic reason they have not provided a foundation for computer design. Moreover, most applicative systems employ the substitution operation of the [[lambda calculus]] as their basic operation. This operation is one of virtually unlimited power, but its complete and efficient realization presents great difficulties to the machine designer.&lt;ref&gt;1977 Turing Award Lecture: [[John Backus|Backus J.]] [http://www.stanford.edu/class/cs242/readings/backus.pdf  ''Can Programming Be Liberated from the von Neumann Style?] A Functional Style and Its Algebra of Programs''. – Comm. of the ACM, Vol. 2, No 8, 1978. -- pp. 613-641&lt;/ref&gt;

== See also ==

* [[Applicative programming language]]
* [[Categorical abstract machine]]
* [[Combinatory logic]]
* [[Functional programming]]
* [[Lambda calculus]]

== References ==
&lt;references/&gt;

== Further reading ==

*{{citation
 | editor1-first = J. Roger | editor1-last = Hindley
 | editor2-first = Jonathan P. | editor2-last = Seldin
 | editor1-link = J. Roger Hindley
 | editor2-link = Jonathan P. Seldin
 | title = To H. B. Curry: Essays on combinatory logic, lambda calculus and formalism
 | publisher = [[Academic Press]]
 | location=Boston, MA
 | isbn = 978-0-12-349050-6
 |date=September 1980
}} [This volume reflects the research program and philosophy of [[Haskell Curry|H. Curry]], one of the founders of [[computational models]] and the deductive framework for reasoning in terms of objects.]

* Wolfengagen, V.E. ''[http://vew.0catch.com/books/Wolfengagen_CLP-2003-En.djvu Combinatory logic in programming.] Computations with objects through examples and exercises''. -- 2-nd ed. -- M.: "Center JurInfoR" Ltd., 2003. -- x+337 с. {{ISBN|5-89158-101-9}}.

{{DEFAULTSORT:Applicative Computing Systems}}
[[Category:Applicative computing systems|*]]
[[Category:Models of computation]]
[[Category:Combinatory logic]]
[[Category:Lambda calculus]]</text>
      <sha1>o1d23cmb1t4tzg2dg5foxfb9z9fq0qd</sha1>
    </revision>
  </page>
  <page>
    <title>Arason invariant</title>
    <ns>0</ns>
    <id>39484059</id>
    <revision>
      <id>635370630</id>
      <parentid>622555420</parentid>
      <timestamp>2014-11-25T12:04:07Z</timestamp>
      <contributor>
        <username>K9re11</username>
        <id>19647483</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3035">In [[mathematics]], the '''Arason invariant''' is a [[cohomological invariant]] associated to a [[quadratic form]] of even rank and trivial [[Discriminant#Discriminant of a quadratic form|discriminant]] and [[Clifford invariant]] over a [[Field (mathematics)|field]] ''k'' of [[Characteristic (algebra)|characteristic]] not 2, taking values in H&lt;sup&gt;3&lt;/sup&gt;(''k'','''Z'''/2'''Z'''). It was introduced by {{harvs|last=Arason|year=1975|loc=Theorem 5.7}}.

The [[Rost invariant]] is a generalization of the Arason invariant to other algebraic groups.

==Definition==

Suppose that ''W''(''k'') is the [[Witt ring (forms)|Witt ring]] of quadratic forms over a field ''k'' and ''I'' is the ideal of forms of even dimension. The Arason invariant is a [[group homomorphism]] from ''I''&lt;sup&gt;3&lt;/sup&gt; to the [[Galois cohomology]] group H&lt;sup&gt;3&lt;/sup&gt;(''k'','''Z'''/2'''Z'''). It is determined by the property that on the 8-dimensional diagonal form with entries 1, –''a'', –''b'', ''ab'', -''c'', ''ac'', ''bc'', -''abc'' (the 3-fold [[Pfister form]]«''a'',''b'',''c''») it is given by the [[cup product]] of the classes of ''a'', ''b'', ''c'' in H&lt;sup&gt;1&lt;/sup&gt;(''k'','''Z'''/2'''Z''') = ''k''*/''k''*&lt;sup&gt;2&lt;/sup&gt;. The Arason invariant vanishes on ''I''&lt;sup&gt;4&lt;/sup&gt;, and it follows from the [[Milnor conjecture]] proved by Voevodsky that it is an [[Group isomorphism|isomorphism]] from ''I''&lt;sup&gt;3&lt;/sup&gt;/''I''&lt;sup&gt;4&lt;/sup&gt; to H&lt;sup&gt;3&lt;/sup&gt;(''k'','''Z'''/2'''Z''').

==References==

*{{citation|mr=0389761|last=Arason|first= Jón Kr.|title=Cohomologische Invarianten quadratischer Formen|journal=J. Algebra |volume=36 |year=1975|issue= 3|pages= 448–491|doi=10.1016/0021-8693(75)90145-3 | zbl=0314.12104 | language=German | issn=0021-8693}}
*{{citation|first1= Hélène|last1= Esnault|first2= Bruno |last2=Kahn|first3=Marc|last3=Levine|first4= Eckart|last4= Viehweg |journal= J. Amer. Math. Soc.|volume= 11 | number=1 |year=1998|pages= 73–118 |mr=1460391 |doi=10.1090/S0894-0347-98-00248-3 |title=The Arason invariant and mod 2 algebraic cycles | zbl=1025.11009| issn=0894-0347}}
* {{citation | last1=Garibaldi | first1=Skip | author1-link=Skip Garibaldi | last2=Merkurjev | first2=Alexander | author2-link=Alexander Merkurjev | last3=Serre | first3=Jean-Pierre | author3-link=Jean-Pierre Serre | title=Cohomological invariants in Galois cohomology | series=University Lecture Series | volume=28 | location=Providence, RI | publisher=[[American Mathematical Society]] | year=2003 | isbn=0-8218-3287-5 | zbl=1159.12311 | mr=1999383 }}
* {{citation | last1=Knus | first1=Max-Albert | last2=Merkurjev | first2=Alexander | author2-link=Alexander Merkurjev | last3=Rost | first3=Markus | author3-link=Markus Rost | last4=Tignol | first4=Jean-Pierre | title=The book of involutions | others=With a preface by J. Tits | zbl=0955.16001 | series=Colloquium Publications | publisher=[[American Mathematical Society]] | volume=44 | location=Providence, RI | year=1998 | isbn=0-8218-0904-0 | page=436 }}

[[Category:Algebraic groups]]

{{algebra-stub}}</text>
      <sha1>l4xozwyfwd08g1orlrh7nvdxdx177o3</sha1>
    </revision>
  </page>
  <page>
    <title>Arc (projective geometry)</title>
    <ns>0</ns>
    <id>5744937</id>
    <revision>
      <id>712712333</id>
      <parentid>712709098</parentid>
      <timestamp>2016-03-30T18:08:00Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>/* {{mvar|k}}-arcs in a projective plane */ added link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4493">[[File:Hyperoval in Fano plane.svg|thumb|A 4-arc (red points) in the projective plane of order 2 (Fano plane).]]

An (''simple'') '''arc''' in finite [[projective geometry]] is a set of points which satisfies, in an intuitive way, a feature of ''curved'' figures in [[continuous geometry|continuous geometries]]. Loosely speaking, they are sets of points that are far from "line-like" in a plane or far from "plane-like" in a three-dimensional space. In this finite setting it is typical to include the number of points in the set in the name, so these simple arcs are called {{math|'''''k'''''}}-'''arcs'''. An important generalization of the {{mvar|k}}-arc concept, also referred to as arcs in the literature, are the ({{mvar|k, d}})-arcs.

=={{mvar|k}}-arcs in a projective plane==

In a finite [[projective plane]] {{pi}} (not necessarily [[Desarguesian]]) a set {{mvar|A}} of {{math|''k'' (''k'' ≥ 3)}} points such that no three points of {{mvar|A}} are [[Collinear points|collinear]] (on a line) is called a {{math|'''''k'' - arc'''}}. If the plane {{pi}} has order {{mvar|q}} then {{math|''k'' ≤ ''q'' + 2}}, however the maximum value of {{mvar|k}} can only be achieved if {{mvar|q}} is even.&lt;ref&gt;{{harvnb|Hirschfeld|1979|loc=p. 164, Theorem 8.1.3}}&lt;/ref&gt; In a plane of order {{mvar|q}}, a {{math|(''q'' + 1)}}-arc is called an '''[[Oval (projective plane)|oval]]''' and, if {{mvar|q}} is even, a {{math|(''q'' + 2)}}-arc is called a '''[[Oval (projective plane)|hyperoval]]'''.

Every conic in the Desarguesian projective plane PG(2,{{mvar|q}}), i.e., the set of zeros of an irreducible homogeneous quadratic equation, is an oval. A celebrated result of [[Beniamino Segre]] states that when {{mvar|q}} is odd, every {{math|(''q'' + 1)}}-arc in PG(2,{{mvar|q}}) is a conic ([[Segre's theorem]]). This is one of the pioneering results in [[finite geometry]].

If {{mvar|q}} is even and {{mvar|A}} is a {{math|(''q'' + 1)}}-arc in {{pi}}, then it can be shown via combinatorial arguments that there must exist a unique point in {{pi}} (called the '''nucleus''' of {{mvar|A}}) such that the union of {{mvar|A}} and this point is a ({{mvar|q}} + 2)-arc. Thus, every oval can be uniquely extended to a hyperoval in a finite projective plane of even order.

A {{mvar|k}}-arc which can not be extended to a larger arc is called a '''''complete arc'''''. In the Desarguesian projective planes, PG(2,{{mvar|q}}), no {{mvar|q}}-arc is complete, so they may all be extended to ovals.&lt;ref&gt;{{harvnb|Dembowski|1968|loc=p. 150, result 28}}&lt;/ref&gt;

=={{mvar|k}}-arcs in a projective space==

In the finite [[projective space]] PG({{math|''n'', ''q''}}) with {{math|''n'' ≥ 3}}, a set {{mvar|A}} of {{math|''k'' ≥ ''n'' + 1}} points such that no {{math|''n'' + 1}}  points lie in a common [[Hyperplane (geometry)|hyperplane]] is called a (spatial) {{math|'''''k'''''}}-'''arc'''. This definition generalizes the definition of a {{mvar|k}}-arc in a plane (where {{math|1=''n'' = 2}}).

==({{math|''k'', ''d''}})-arcs in a projective plane==

A ({{math|''k'', ''d''}})-'''arc''' ({{math|''k'', ''d'' &gt; 1}}) in a finite [[projective plane]] {{pi}} (not necessarily [[Desarguesian]]) is a set, {{mvar|A}} of {{mvar|k}} points of {{pi}} such that each line intersects {{mvar|A}} in at most {{mvar|d}} points, and there is at least one line that does intersect {{mvar|A}} in {{mvar|d}} points. A ({{math|''k'', 2}})-arc is a '''{{mvar|k}}-arc''' and may be referred to as simply an '''arc''' if the size is not a concern.

The number of points {{mvar|k}} of a ({{math|''k'', ''d''}})-arc {{mvar|A}} in a projective plane of order {{mvar|q}} is at most {{math|''qd'' + ''d'' − ''q''}}.  When equality occurs, one calls {{mvar|A}} a '''[[maximal arc]]'''.

Hyperovals are maximal arcs. Complete arcs need not be maximal arcs.

==See also==

* [[Normal rational curve]]

==Notes==
{{reflist}}

==References==
* {{Citation | last1=Dembowski | first1=Peter | title=Finite geometries | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=[[Ergebnisse der Mathematik und ihrer Grenzgebiete]], Band 44 | mr=0233275  | year=1968 | isbn=3-540-61786-8}}
* {{citation|last=Hirschfeld|first=J.W.P.|title=Projective Geometries over Finite Fields|year=1979|publisher=Oxford University Press|location=New York|isbn=0-19-853526-0}}

==External links==
*{{springer|id=Arc_(projective_geometry)&amp;oldid=25358|title=Arc|author=C.M. O'Keefe}}

[[Category:Projective geometry]]
[[Category:Incidence geometry]]</text>
      <sha1>7ju3vs39y11i0tteyk64h6fetfhp2n8</sha1>
    </revision>
  </page>
  <page>
    <title>Asker Abiyev</title>
    <ns>0</ns>
    <id>57536639</id>
    <revision>
      <id>863662565</id>
      <parentid>861644477</parentid>
      <timestamp>2018-10-12T05:22:50Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>[[User:AnomieBOT/docs/TemplateSubster|Substing templates]]: {{Incomplete}}. See [[User:AnomieBOT/docs/TemplateSubster]] for info.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5997">{{Multiple issues|{{POV|date=June 2018}}{{BLP sources|date=June 2018}}}}

{{Infobox scientist
| honorific_prefix = Dr.
| name = Asker Ali Abiyev
| honorific_suffix = 
| native_name = Asker Ali Abiyev
| native_name_lang = tr
| image = &lt;!--(filename only, i.e. without "File:" prefix)--&gt;Asker abiyev.jpg
| image_size = 200px
| image_upright = 
| alt = Asker Ali Abiyev
| caption = Asker Ali Abiyev in a press meeting
| birth_name = &lt;!-- if different from "name" --&gt;
| birth_date = &lt;!--{{birth date |YYYY|MM|DD}}--&gt;{{birth date and age|1934|6|28}}&lt;ref name="own web"&gt;{{Cite web|url=http://www.askeraliabiyev.com/en/bio.html|title=Asker Ali Abiyev - Balanced (Magic) Squares and Cubes|website=www.askeraliabiyev.com|language=en|access-date=2018-03-16}}&lt;/ref&gt;
| birth_place = [[Baku]], [[Azerbaijan Soviet Socialist Republic|Azerbaijan SSR]], [[Soviet Union]]&lt;br /&gt;(now Baku, [[Azerbaijan]])
| death_date = &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place = 
| death_cause = 
| resting_place = 
| resting_place_coordinates = &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names = 
| pronounce = 
| residence = {{flag|Azerbaijan}}
| citizenship = {{flag|Azerbaijan}}
| nationality = {{flag|Azerbaijan}}
| fields = [[Physics]]&lt;br&gt;[[Mathematics]]
| workplaces = * Institute of Physics of [[Azerbaijan National Academy of Sciences]] (1961-1963 &amp; 1966-1969)&lt;br&gt;
* Laboratory of the Radiation and semiconductors in [[Azerbaijan National Academy of Sciences]] (1966-1991)
*[[Yavuz Sultan Private Science Lyceum]] (1993-2000)
*Department of Mathematics at [[Gaziantep University]],[[Turkey]] (2000-2007)
| patrons = 
| education = * Doctor of Physical-Mathematical Sciences&lt;br&gt;
* Doctor of Physical-Mathematical Sciences
| alma_mater = * [[Baku State University]] (1954-1957)&lt;br&gt; 
* [[Moscow State University]] (1957-1961)
* [[Kurchatov Institute]] (1963-1966)
| thesis1_title = Identification of new technical application fields of the aforementioned [[semiconductor]]s. &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url = &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year = &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor = &lt;!--(or  | doctoral_advisors = )--&gt;
| academic_advisors = 
| doctoral_students = 
| notable_students = 
| known_for = The discovery of [[algorithm]]s of [[Magic square]] and [[Magic cube]]&lt;br&gt;
| influences = 
| influenced = 
| awards = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| spouse = &lt;!--(or | spouses = )--&gt;
| partner = 
| children = 
| signature = &lt;!--(filename only)--&gt;
| signature_alt = 
| website = {{URL|www.askeraliabiyev.com}}
| footnotes = 
}}
'''Asker Ali Abiyev''' (born June 28, 1934), the inventor of Abiyev's [[Magic square]]s and [[Magic cube|Cubes]],&lt;ref name="own web"/&gt; was born in [[Baku]], [[Azarbaijan]].&lt;ref name="bio"&gt;{{Cite web|url=http://www.askeraliabiyev.com/en/bio.html|title= Biography of Dr. Asker Ali Abiyev|website=www.askeraliabiyev.com|language=en|access-date=2018-05-28}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://web.archive.org/web/20080415134429/http://www1.gantep.edu.tr:80/~abiyev/ozgecmis.htm|title=Prof. Dr. Asker Ali Abiyev|date=2008-04-15|access-date=2018-05-29}}&lt;/ref&gt;

==Academic life==
Abiyev studied in Physics-Mathematics faculty in [[Baku State University]] from 1954 to 1957, and then, in the faculty of Physics in [[Moscow State University]] from 1957 to 1961. After some years of working, he continued his education from 1963 until 1966 as a post-graduate in [[Kurchatov Institute]].

==Scientific career==
In 1961–1963, Aliyev worked in the Institute of Physics of [[Azerbaijan National Academy of Sciences]]. After his post-graduation from [[Kurchatov Institute]], he returned to the [[Azerbaijan National Academy of Sciences|National Academy]] in 1966.

After 1969, he worked as a researcher in the Radiation Problems Sector of [[Azerbaijan National Academy of Sciences|National Academy]], and then, from 1976 until 1993, he worked as the head of the Laboratory of "Radiation Physics of Semiconductors".

He went to [[Ankara]], [[Turkey]], as a professor of [[Yavuz Sultan Private Science Lyceum]] in 1993 (until 2000). From 2000 to 2007, he was a professor in the Department of Mathematics at [[Gaziantep University]] in [[Gaziantep]], [[Turkey]].&lt;ref name="bio"/&gt;

===Achievements===
In 1970 and 1988, Abiyev defended dissertations in the field of "Physics of [[Semiconductor]]s" he  obtained his ''Candidate of Physical-Mathematical Sciences'' title and in the field of [[Dielectrics]], he got ''Doctor of Physical-Mathematical Sciences'' title. Later, in 1990, he obtained the title of Professor of Physical-Mathematical Sciences.
&lt;!--His main scientific achievements in [[physics]] are:
* Research of creation and annealing [[kinetics]] of radiation defects in semiconductors in impulse [[electron]] accelerator{{refn|group=note|In a specifically made device, for the first time ever}}
* Idefication of new technical application fields of the aforementioned semiconductors.

In 1996, Abiyev discovered an algorithm for writing Magic Squares and Cubes. This algorithm allows the creation of Magic Squares and Cubes of any order from any numbers or symbols. It can open great new perspectives on optimization problems, cryptology, genetic engineering and information technology. Using this algorithm, the pattern of the order of elements in the periodic table was discovered. In this table, the atomic number of the last element was discovered as well.
---&gt;

==See also==
*[[Magic square]]
*[[Magic cube]]

&lt;!-- ==Notes==
{{reflist|group=note}}
--&gt;

==References==
{{reflist}}

==External links==
*{{Official website}}


{{authority control}}

[[Category:Azerbaijani mathematicians]]
[[Category:Moscow State University alumni]]
[[Category:Biography articles by importance]]
[[Category:Living people]]
[[Category:1934 births]]
[[Category:Azerbaijani scientists]]


{{Mathematician-stub}}</text>
      <sha1>kpnjzawbp986aj04byhd4fbdhxtrdk5</sha1>
    </revision>
  </page>
  <page>
    <title>BEST theorem</title>
    <ns>0</ns>
    <id>1455603</id>
    <revision>
      <id>867429396</id>
      <parentid>838351424</parentid>
      <timestamp>2018-11-05T17:35:55Z</timestamp>
      <contributor>
        <username>Yahya Abdal-Aziz</username>
        <id>313039</id>
      </contributor>
      <minor/>
      <comment>/* Precise statement */ - copy-edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4651">In [[graph theory]], a part of [[discrete mathematics]], the '''BEST theorem''' gives a product formula for the number of [[Eulerian circuit]]s in [[directed graph|directed]] (oriented) [[Graph (discrete mathematics)|graphs]].  The name is an acronym of the names of people who discovered it: [[N. G. de Bruijn|de '''B'''ruijn]], [[Tatyana Pavlovna Ehrenfest|van Aardenne-'''E'''hrenfest]], [[Cedric Smith (statistician)|'''S'''mith]] and [[W. T. Tutte|'''T'''utte]].  

== Precise statement == 
Let ''G''&amp;nbsp;=&amp;nbsp;(''V'',&amp;nbsp;''E'') be a directed graph.  An Eulerian circuit is a directed closed path which visits each edge exactly once.  In 1736, [[Leonhard Euler|Euler]] showed that ''G'' has an Eulerian circuit if and only if ''G'' is [[connected graph|connected]] and the [[Directed_graph#Indegree_and_outdegree|indegree]] is equal to [[Directed_graph#Indegree_and_outdegree|outdegree]] at every vertex.  In this case ''G'' is called Eulerian.  We denote the indegree of a vertex ''v'' by deg(''v''). 

The BEST theorem states that the number ec(''G'') of Eulerian circuits in a connected Eulerian graph ''G'' is given by the formula

:&lt;math&gt;
\operatorname{ec}(G) = t_w(G) \prod_{v\in V} \bigl(\deg(v)-1\bigr)!.
&lt;/math&gt;

Here ''t''&lt;sub&gt;''w''&lt;/sub&gt;(''G'') is the number of [[Arborescence (graph theory)|arborescences]], which are [[tree (graph theory)|trees]] directed towards the root at a fixed vertex ''w'' in ''G''. The number ''t&lt;sub&gt;w&lt;/sub&gt;(G)'' can be computed as a [[determinant]], by the version of the [[matrix tree theorem]] for directed graphs.  It is a property of Eulerian graphs that ''t''&lt;sub&gt;''v''&lt;/sub&gt;(''G'')&amp;nbsp;=&amp;nbsp;''t''&lt;sub&gt;''w''&lt;/sub&gt;(''G'') for every two vertices ''v'' and ''w'' in a connected Eulerian graph ''G''.

== Applications ==
The BEST theorem shows that the number of Eulerian circuits in directed graphs can be computed in [[polynomial time]], a problem which is [[Sharp-P-complete|#P-complete]] for undirected graphs.&lt;ref&gt;Brightwell and [[Peter Winkler|Winkler]], "[http://www.cdam.lse.ac.uk/Reports/Files/cdam-2004-12.pdf Note on Counting Eulerian Circuits]", CDAM Research Report LSE-CDAM-2004-12, 2004.&lt;/ref&gt;  It is also used in the asymptotic enumeration of Eulerian circuits of [[complete graph|complete]] and [[complete bipartite graph]]s.&lt;ref&gt;[[Brendan McKay]] and Robert W. Robinson, [http://cs.anu.edu.au/~bdm/papers/euler.pdf Asymptotic enumeration of eulerian circuits in the complete graph], ''[[Combinatorica]]'', 10 (1995), no. 4, 367–377.&lt;/ref&gt;&lt;ref&gt;M.I. Isaev, [http://www.mipt.ru/nauka/52conf/materialy/07-FUPM1-site.pdf#page=56 Asymptotic number of Eulerian circuits in complete bipartite graphs] (in [[Russian language|Russian]]), Proc. 52-nd MFTI Conference (2009), Moscow.&lt;/ref&gt;

== History ==
The BEST theorem was first stated in this form in a "note added in proof" to the paper of van Aardenne-Ehrenfest and de Bruijn (1951).  The original proof was [[bijective proof|bijective]] and generalized the [[de Bruijn sequence]]s.  It is a variation on an earlier result by Smith and Tutte (1941).

== Notes ==
{{reflist}}

== References ==
*{{citation|last=Euler|first=L.|authorlink=Leonhard Euler|url=http://www.math.dartmouth.edu/~euler/pages/E053.html|title=Solutio problematis ad geometriam situs pertinentis|language=Latin|journal=Commentarii Academiae Scientiarum Petropolitanae|volume=8|year=1736|pages=128–140}}.
*{{citation|first1=W. T.|last1=Tutte|author1-link=W. T. Tutte|first2=C. A. B.|last2=Smith|author2-link=Cedric Smith (statistician)|title=On unicursal paths in a network of degree 4|journal=[[American Mathematical Monthly]]|volume=48|year=1941|pages=233–237|jstor=2302716|doi=10.2307/2302716}}.
*{{citation|author1-link=Tatyana Pavlovna Ehrenfest|first1=T.|last1=van Aardenne-Ehrenfest|author2-link=Nicolaas Govert de Bruijn|first2=N. G.|last2=de Bruijn|title=Circuits and trees in oriented linear graphs|journal=[[Simon Stevin (journal)|Simon Stevin]]|volume=28|year=1951|pages=203–217|url=http://repository.tue.nl/597493}}.
*{{citation|first=W. T.|last=Tutte|authorlink=W. T. Tutte|title=Graph Theory|publisher=Addison-Wesley|location=Reading, Mass.|year=1984}}.
*{{citation|authorlink=Richard P. Stanley|last=Stanley|first=Richard P.|year=1999|url=http://www-math.mit.edu/~rstan/ec/|title=Enumerative Combinatorics|volume=Vol. 2|publisher=[[Cambridge University Press]]|isbn=0-521-56069-1}}.
*{{citation|authorlink=Martin Aigner|last=Aigner|first=Martin|title=A Course in Enumeration|year=2007|isbn=3-540-39032-4|series=Graduate Texts in Mathematics|volume=238|publisher=Springer}}. 


[[Category:Directed graphs]]
[[Category:Theorems in graph theory]]</text>
      <sha1>l8h1igp3p0l9g5mhkay8ib8564ic1vg</sha1>
    </revision>
  </page>
  <page>
    <title>Background subtraction</title>
    <ns>0</ns>
    <id>38561540</id>
    <redirect title="Foreground detection" />
    <revision>
      <id>854014926</id>
      <parentid>850102932</parentid>
      <timestamp>2018-08-08T11:32:50Z</timestamp>
      <contributor>
        <username>Klbrain</username>
        <id>11677590</id>
      </contributor>
      <comment>Merge to [[Foreground detection]] following unopposed 2017 proposal; see [[Talk:Foreground detection#Background subtraction merge proposal]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="146">#REDIRECT [[Foreground detection]] {{R from merge}}

[[Category:Mathematical examples]]
[[Category:Image processing]]
[[Category:Computer vision]]</text>
      <sha1>2s3k80pnpbz1fehjjp6fkghas68jxuq</sha1>
    </revision>
  </page>
  <page>
    <title>Bipolar cylindrical coordinates</title>
    <ns>0</ns>
    <id>5007452</id>
    <revision>
      <id>659859295</id>
      <parentid>622691511</parentid>
      <timestamp>2015-04-29T12:00:57Z</timestamp>
      <contributor>
        <ip>157.136.60.23</ip>
      </contributor>
      <comment>correction</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5103">[[File:Bipolar cylindrical coordinates.png|thumb|350px|right|[[Coordinate system#Coordinate surface|Coordinate surfaces]] of the bipolar cylindrical coordinates.  The yellow crescent corresponds to σ, whereas the red tube corresponds to τ and the blue plane corresponds to ''z''=1.  The three surfaces intersect at the point '''P''' (shown as a black sphere).]]

'''Bipolar cylindrical coordinates''' are a three-dimensional [[orthogonal coordinates|orthogonal]] [[coordinate system]] that results from projecting the two-dimensional [[bipolar coordinates|bipolar coordinate system]] in the
perpendicular &lt;math&gt;z&lt;/math&gt;-direction.  The two lines of [[Focus (geometry)|foci]] 
&lt;math&gt;F_{1}&lt;/math&gt; and &lt;math&gt;F_{2}&lt;/math&gt; of the projected [[Apollonian circles]] are generally taken to be 
defined by &lt;math&gt;x=-a&lt;/math&gt; and &lt;math&gt;x=+a&lt;/math&gt;, respectively, (and by &lt;math&gt;y=0&lt;/math&gt;) in the [[Cartesian coordinate system]].

The term "bipolar" is often used to describe other curves having two singular points (foci), such as [[ellipse]]s, [[hyperbola]]s, and [[Cassini oval]]s.  However, the term ''bipolar coordinates'' is never used to describe coordinates associated with those curves, e.g., [[elliptic coordinates]].

==Basic definition==

The most common definition of bipolar cylindrical coordinates &lt;math&gt;(\sigma, \tau, z)&lt;/math&gt; is

:&lt;math&gt;
x = a \ \frac{\sinh \tau}{\cosh \tau - \cos \sigma}
&lt;/math&gt;

:&lt;math&gt;
y = a \ \frac{\sin \sigma}{\cosh \tau - \cos \sigma}
&lt;/math&gt;

:&lt;math&gt;
z = \ z
&lt;/math&gt;

where the &lt;math&gt;\sigma&lt;/math&gt; coordinate of a point &lt;math&gt;P&lt;/math&gt;
equals the angle &lt;math&gt;F_{1} P F_{2}&lt;/math&gt; and the 
&lt;math&gt;\tau&lt;/math&gt; coordinate equals the [[natural logarithm]] of the ratio of the distances &lt;math&gt;d_{1}&lt;/math&gt; and &lt;math&gt;d_{2}&lt;/math&gt; to the focal lines

:&lt;math&gt;
\tau = \ln \frac{d_{1}}{d_{2}}
&lt;/math&gt;

(Recall that the focal lines &lt;math&gt;F_{1}&lt;/math&gt; and &lt;math&gt;F_{2}&lt;/math&gt; are located at &lt;math&gt;x=-a&lt;/math&gt; and &lt;math&gt;x=+a&lt;/math&gt;, respectively.) 

Surfaces of constant &lt;math&gt;\sigma&lt;/math&gt; correspond to cylinders of different radii

:&lt;math&gt;
x^{2} +
\left( y - a \cot \sigma \right)^{2} = \frac{a^{2}}{\sin^{2} \sigma}
&lt;/math&gt;

that all pass through the focal lines and are not concentric.  The surfaces of constant &lt;math&gt;\tau&lt;/math&gt; are non-intersecting cylinders of different radii

:&lt;math&gt;
y^{2} +
\left( x - a \coth \tau \right)^{2} = \frac{a^{2}}{\sinh^{2} \tau}
&lt;/math&gt;

that surround the focal lines but again are not concentric.  The focal lines and all these cylinders are parallel to the &lt;math&gt;z&lt;/math&gt;-axis (the direction of projection).  In the &lt;math&gt;z=0&lt;/math&gt; plane, the centers of the constant-&lt;math&gt;\sigma&lt;/math&gt; and constant-&lt;math&gt;\tau&lt;/math&gt; cylinders lie on the &lt;math&gt;y&lt;/math&gt; and &lt;math&gt;x&lt;/math&gt; axes, respectively.
 
==Scale factors==

The scale factors for the bipolar coordinates &lt;math&gt;\sigma&lt;/math&gt; and  &lt;math&gt;\tau&lt;/math&gt; are equal

:&lt;math&gt;
h_{\sigma} = h_{\tau} = \frac{a}{\cosh \tau - \cos\sigma}
&lt;/math&gt;

whereas the remaining scale factor &lt;math&gt;h_{z}=1&lt;/math&gt;.  
Thus, the infinitesimal volume element equals

:&lt;math&gt;
dV = \frac{a^{2}}{\left( \cosh \tau - \cos\sigma \right)^{2}} d\sigma d\tau dz
&lt;/math&gt;

and the Laplacian is given by 

:&lt;math&gt;
\nabla^{2} \Phi =
\frac{1}{a^{2}} \left( \cosh \tau - \cos\sigma \right)^{2}
\left( 
\frac{\partial^{2} \Phi}{\partial \sigma^{2}} + 
\frac{\partial^{2} \Phi}{\partial \tau^{2}} 
\right) + 
\frac{\partial^{2} \Phi}{\partial z^{2}} 
&lt;/math&gt;

Other differential operators such as &lt;math&gt;\nabla \cdot \mathbf{F}&lt;/math&gt; 
and &lt;math&gt;\nabla \times \mathbf{F}&lt;/math&gt; can be expressed in the coordinates &lt;math&gt;(\sigma, \tau)&lt;/math&gt; by substituting 
the scale factors into the general formulae 
found in [[orthogonal coordinates]].

==Applications==
The classic applications of bipolar coordinates are in solving [[partial differential equations]], 
e.g., [[Laplace's equation]] or the [[Helmholtz equation]], for which bipolar coordinates allow a 
[[separation of variables]] (in 2D).  A typical example would be the [[electric field]] surrounding two 
parallel cylindrical conductors.

==Bibliography==
*{{cite book | author = [[Henry Margenau|Margenau H]], Murphy GM | year = 1956 | title = The Mathematics of Physics and Chemistry | publisher = D. van Nostrand | location = New York | pages = 187&amp;ndash;190 | lccn = 55010911 }}
*{{cite book | author = Korn GA, Korn TM |year = 1961 | title = Mathematical Handbook for Scientists and Engineers | publisher = McGraw-Hill | location = New York | id = ASIN B0000CKZX7 | page = 182 | lccn = 59014456}}
*{{cite book | author = Moon P, Spencer DE | year = 1988 | chapter = Conical Coordinates (r, θ, λ) | title = Field Theory Handbook, Including Coordinate Systems, Differential Equations, and Their Solutions | edition = corrected 2nd ed., 3rd print | publisher = Springer-Verlag | location = New York | isbn = 978-0-387-18430-2 | nopp = true | page = unknown}}

==External links==
*[http://mathworld.wolfram.com/BipolarCylindricalCoordinates.html MathWorld description of bipolar cylindrical coordinates]

{{Orthogonal coordinate systems}}

[[Category:Coordinate systems]]</text>
      <sha1>128lkeukm2d3ldthmvqp01n4vzzasmb</sha1>
    </revision>
  </page>
  <page>
    <title>Cipolla's algorithm</title>
    <ns>0</ns>
    <id>25766973</id>
    <revision>
      <id>840739694</id>
      <parentid>836677369</parentid>
      <timestamp>2018-05-11T21:09:27Z</timestamp>
      <contributor>
        <ip>174.216.6.34</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13353">In [[computational number theory]], '''Cipolla's algorithm''' is a technique for solving a [[Congruence relation|congruence]] of the form

:&lt;math&gt;x^2\equiv n \pmod{p},&lt;/math&gt;

where &lt;math&gt;x,n \in \mathbf{F}_{p}&lt;/math&gt;, so ''n'' is the square of ''x'', and where &lt;math&gt;p&lt;/math&gt; is an [[Parity (mathematics)|odd]] [[Prime number|prime]]. Here &lt;math&gt;\mathbf{F}_p&lt;/math&gt; denotes the finite [[Field (mathematics)|field]] with &lt;math&gt;p&lt;/math&gt; [[Element (mathematics)|elements]]; &lt;math&gt;\{0,1,\dots,p-1\}&lt;/math&gt;. The [[algorithm]] is named after [[Michele Cipolla]], an [[Italy|Italian]] [[Mathematics|mathematician]] who discovered it in 1907.

According to
&lt;ref name="dickson"&gt;
"History of the Theory of Numbers" Volume 1 by Leonard Eugene Dickson, p218
&lt;!-- url=https://archive.org/details/historyoftheoryo01dick --&gt;
[https://archive.org/stream/historyoftheoryo01dick#page/218/mode/2up read online]
&lt;/ref&gt;
Cipolla's algorithm is also able to take square roots of powers of prime modula as well as prime modula.

==Algorithm==

'''Inputs:'''
* &lt;math&gt;p&lt;/math&gt;, an odd prime,
* &lt;math&gt;n \in \mathbf{F}_p&lt;/math&gt;, which is a square.

'''Outputs:'''
* &lt;math&gt;x \in \mathbf{F}_p&lt;/math&gt;, satisfying &lt;math&gt; x^2= n . &lt;/math&gt;

Step 1 is to find an &lt;math&gt;a \in \mathbf{F}_p&lt;/math&gt; such that &lt;math&gt;a^2 - n&lt;/math&gt; is not a square. There is no known algorithm for finding such an &lt;math&gt;a&lt;/math&gt;, except the [[trial and error]] method. Simply pick an &lt;math&gt;a&lt;/math&gt; and by computing the [[Legendre symbol]] &lt;math&gt;(a^2-n|p)&lt;/math&gt; one can see whether &lt;math&gt;a&lt;/math&gt; satisfies the condition. The chance that a random &lt;math&gt;a&lt;/math&gt; will satisfy is &lt;math&gt;(p-1)/2p&lt;/math&gt;. With &lt;math&gt;p&lt;/math&gt; large enough this is about &lt;math&gt;1/2&lt;/math&gt;.&lt;ref&gt;R. Crandall, C. Pomerance Prime Numbers: A Computational Perspective Springer-Verlag, (2001) p. 157&lt;/ref&gt; Therefore, the expected number of trials before finding a suitable ''a'' is about 2.

Step 2 is to compute ''x'' by computing &lt;math&gt;x=\left( a  + \sqrt{a^2-n} \right)^{(p+1)/2}&lt;/math&gt; within the field &lt;math&gt;\mathbf{F}_{p^2} = \mathbf{F}_p(\sqrt{a^2-n})&lt;/math&gt;. This ''x'' will be the one satisfying &lt;math&gt; x^2 =n .&lt;/math&gt;

If &lt;math&gt;x^2 = n&lt;/math&gt;, then &lt;math&gt;(-x)^2 = n&lt;/math&gt; also holds. And since ''p'' is odd, &lt;math&gt; x \neq -x &lt;/math&gt;. So whenever a solution ''x'' is found, there's always a second solution, ''-x''.

==Example==

(Note: All elements before step two are considered as an element of &lt;math&gt;\mathbf{F}_{13}&lt;/math&gt; and all elements in step two are considered as elements of &lt;math&gt;\mathbf{F}_{13^2}&lt;/math&gt;).

Find all ''x'' such that &lt;math&gt;x^2 = 10.&lt;/math&gt;

Before applying the algorithm, it must be checked that &lt;math&gt;10&lt;/math&gt; is indeed a square in &lt;math&gt;\mathbf{F}_{13}&lt;/math&gt;. Therefore, the Legendre symbol &lt;math&gt;(10 | 13)&lt;/math&gt; has to be equal to 1. This can be computed using [[Euler's criterion]]; &lt;math&gt;(10 | 13) \equiv 10^6 \equiv 1 \bmod 13.&lt;/math&gt; This confirms 10 being a square and hence the algorithm can be applied.
* Step 1: Find an ''a'' such that &lt;math&gt;a^2 - n&lt;/math&gt; is not a square. As stated, this has to be done by trial and error. Choose &lt;math&gt;a=2&lt;/math&gt;. Then &lt;math&gt;a^2 - n&lt;/math&gt; becomes 7. The Legendre symbol &lt;math&gt;(7 | 13)&lt;/math&gt; has to be -1. Again this can be computed using Euler's criterion. &lt;math&gt;7^6 = 343^2 \equiv 5^2 \equiv 25 \equiv -1 \bmod 13.&lt;/math&gt; So &lt;math&gt;a=2&lt;/math&gt; is a suitable choice for ''a''.
* Step 2: Compute &lt;math&gt;x = \left( a  + \sqrt{a^2-n} \right)^{(p+1)/2} = \left( 2 + \sqrt{-6}\right)^7 .&lt;/math&gt;

:&lt;math&gt;\left(2+\sqrt{-6}\right)^2 = 4 + 4\sqrt{-6} - 6 = -2 + 4 \sqrt{-6} .&lt;/math&gt;
:&lt;math&gt;\left(2+\sqrt{-6}\right)^4 = \left(-2+4\sqrt{-6}\right)^2 = -1-3\sqrt{-6} .&lt;/math&gt;
:&lt;math&gt;\left(2+\sqrt{-6}\right)^6 = \left(-2 + 4\sqrt{-6}\right)\left(-1-3\sqrt{-6}\right) = 9+2\sqrt{-6} .&lt;/math&gt;
:&lt;math&gt;\left(2+\sqrt{-6}\right)^7 = \left(9+2\sqrt{-6}\right)\left(2+ \sqrt{-6}\right) = 6 .&lt;/math&gt;

So &lt;math&gt;x = 6 &lt;/math&gt; is a solution, as well as &lt;math&gt;x = -6 \bmod 13 = (-6+13) \bmod 13 = 7.&lt;/math&gt; Indeed, &lt;math&gt;\ 6^2 = 36 \bmod 13 = 10&lt;/math&gt; and &lt;math&gt; 7^2 = 49 \bmod 13 = 10 .&lt;/math&gt;

==Proof==
The first part of the proof is to verify that &lt;math&gt;\mathbf{F}_{p^2} = \mathbf{F}_p(\sqrt{a^2-n}) = \{x + y\sqrt{a^2-n} : x,y \in \mathbf{F}_p\}&lt;/math&gt; is indeed a field. For the sake of notation simplicity, &lt;math&gt;\omega&lt;/math&gt; is defined as &lt;math&gt;\sqrt{a^2-n}&lt;/math&gt;. Of course, &lt;math&gt;a^2-n&lt;/math&gt; is a quadratic non-residue, so there is no [[square root]] in &lt;math&gt;\mathbf{F}_p&lt;/math&gt;. This &lt;math&gt;\omega&lt;/math&gt; can roughly be seen as analogous to the complex number [[Imaginary unit|i]].
The field arithmetic is quite obvious. [[Addition]] is defined as
:&lt;math&gt;\left(x_1 + y_1 \omega \right) + \left(x_2 + y_2 \omega \right) = \left(x_1 + x_2 \right) + \left(y_1 + y_2\right) \omega&lt;/math&gt;.
[[Multiplication]] is also defined as usual. With keeping in mind that &lt;math&gt;\omega^2 = a^2-n&lt;/math&gt;, it becomes
:&lt;math&gt;\left(x_1 + y_1 \omega \right)\left(x_2 + y_2 \omega \right) = x_1 x_2 + x_1 y_2 \omega + y_1 x_2 \omega + y_1 y_2 \omega^2 = \left( x_1 x_2 + y_1 y_2 \left(a^2-n\right)\right) + \left(x_1 y_2 + y_1 x_2 \right) \omega&lt;/math&gt;.
Now the field properties have to be checked.
The properties of closure under addition and multiplication, [[associativity]], [[commutativity]] and [[distributivity]] are easily seen. This is because in this case the field &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt; is somewhat resembles the field of [[complex number]]s (with &lt;math&gt;\omega&lt;/math&gt; being the analogon of ''i'').&lt;br&gt;
The additive [[Identity element|identity]] is &lt;math&gt;0&lt;/math&gt;, or more formally &lt;math&gt;0 + 0\omega&lt;/math&gt;: Let &lt;math&gt;\alpha \in \mathbf{F}_{p^2}&lt;/math&gt;, then
:&lt;math&gt;\alpha + 0 = (x+y\omega) + (0 + 0\omega) = (x + 0) + (y + 0)\omega = x+y\omega = \alpha&lt;/math&gt;.
The multiplicative identity is &lt;math&gt;1&lt;/math&gt;, or more formally &lt;math&gt; 1 + 0\omega&lt;/math&gt;:
:&lt;math&gt;\alpha \cdot 1 = (x+y\omega)(1 + 0\omega) = \left(x\cdot 1 + 0 \cdot y \left(a^2-n\right)\right) + (x\cdot 0 + 1 \cdot y)\omega = x+y\omega = \alpha&lt;/math&gt;.
The only thing left for &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt; being a field is the existence of additive and multiplicative [[Inverse element|inverses]]. It is easily seen that the additive inverse of &lt;math&gt;x+y\omega&lt;/math&gt; is &lt;math&gt;-x-y\omega&lt;/math&gt;, which is an element of &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt;, because &lt;math&gt;-x,-y \in \mathbf{F}_p&lt;/math&gt;. In fact, those are the additive inverse elements of ''x'' and ''y''. For showing that every non-zero element &lt;math&gt;\alpha&lt;/math&gt; has a multiplicative inverse, write down &lt;math&gt;\alpha = x_1 + y_1 \omega&lt;/math&gt; and &lt;math&gt;\alpha^{-1} = x_2 + y_2 \omega&lt;/math&gt;. In other words,
:&lt;math&gt;(x_1 + y_1 \omega)(x_2 + y_2 \omega) = \left( x_1 x_2 + y_1 y_2 \left(a^2-n\right)\right) + \left(x_1 y_2 + y_1 x_2 \right) \omega = 1&lt;/math&gt;.
So the two equalities &lt;math&gt;x_1x_2 + y_1y_2(a^2-n) = 1&lt;/math&gt; and &lt;math&gt;x_1y_2 + y_1x_2 = 0&lt;/math&gt; must hold. Working out the details gives expressions for &lt;math&gt;x_2&lt;/math&gt; and &lt;math&gt;y_2&lt;/math&gt;, namely
:&lt;math&gt;x_2 = -y_1^{-1}x_1\left(y_1\left(a^2-n\right)-x_1^2y_1^{-1}\right)^{-1}&lt;/math&gt;,
:&lt;math&gt;y_2 = \left( y_1 \left(a^2-n\right) - x_1^2y_1^{-1}\right)^{-1}&lt;/math&gt;.
The inverse elements which are shown in the expressions of &lt;math&gt;x_2&lt;/math&gt; and &lt;math&gt;y_2&lt;/math&gt; do exist, because these are all elements of &lt;math&gt;\mathbf{F}_p&lt;/math&gt;. This completes the first part of the proof, showing that &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt; is a field.

The second and middle part of the proof is showing that for every element &lt;math&gt;x+y\omega \in \mathbf{F}_{p^2} : (x+y\omega)^p = x - y\omega&lt;/math&gt;.
By definition, &lt;math&gt;\omega^2=a^2-n&lt;/math&gt; is not a square in &lt;math&gt;\mathbf{F}_p&lt;/math&gt;. Euler's criterion then says that
:&lt;math&gt;\omega^{p-1} = \left(\omega^2\right)^{\frac{p-1}{2}} = -1&lt;/math&gt;.
Thus &lt;math&gt;\omega^p = -\omega&lt;/math&gt;. This, together with [[Fermat's little theorem]] (which says that &lt;math&gt;x^p = x&lt;/math&gt; for all &lt;math&gt;x \in \mathbf{F}_{p}&lt;/math&gt;) and the knowledge that in fields of [[Characteristic (algebra)|characteristic]] ''p'' the equation &lt;math&gt;\left(a+b\right)^p = a^p + b^p&lt;/math&gt; holds, a relationship sometimes called the [[Freshman's_dream#Prime_characteristic|Freshman's dream]], shows the desired result
:&lt;math&gt;(x+y\omega)^p = x^p + y^p \omega^p = x - y\omega&lt;/math&gt;.

The third and last part of the proof is to show that if &lt;math&gt;x_0=\left(a+\omega \right)^{\frac{p+1}{2}} \in \mathbf{F}_{p^2}&lt;/math&gt;, then &lt;math&gt;x_0^2=n \in \mathbf{F}_p&lt;/math&gt;.&lt;br&gt;
Compute
:&lt;math&gt;x_0^2 = \left(a+\omega \right)^{p+1} = (a+\omega)(a+\omega)^{p}=(a+\omega)(a-\omega)=a^2 - \omega^2 = a^2 - \left(a^2 - n \right) = n&lt;/math&gt;.
Note that this computation took place in &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt;, so this &lt;math&gt;x_0 \in \mathbf{F}_{p^2}&lt;/math&gt;. But with [[Lagrange's theorem (number theory)|Lagrange's theorem]], stating that a non-zero [[Integer polynomial|polynomial]] of degree ''n'' has at most ''n'' roots in any field ''K'', and the knowledge that &lt;math&gt;x^2-n&lt;/math&gt; has 2 roots in &lt;math&gt;\mathbf{F}_p&lt;/math&gt;, these roots must be all of the roots in &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt;. It was just shown that &lt;math&gt;x_0&lt;/math&gt; and &lt;math&gt;-x_0&lt;/math&gt; are roots of &lt;math&gt;x^2-n&lt;/math&gt; in &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt;, so it must be that &lt;math&gt;x_0, -x_0 \in \mathbf{F}_p&lt;/math&gt;.&lt;ref&gt;[http://people.math.gatech.edu/~mbaker/pdf/cipolla2011.pdf M. Baker ''Cipolla's Algorithm for finding square roots mod p'']&lt;/ref&gt;

==Speed==
After finding a suitable ''a'', the number of operations required for the algorithm is &lt;math&gt;4m  + 2k - 4&lt;/math&gt; multiplications, &lt;math&gt;4m-2&lt;/math&gt; sums, where ''m'' is the number of [[Numerical digit|digits]] in the [[Binary numeral system|binary representation]] of ''p'' and ''k'' is the number of ones in this representation. To find ''a'' by trial and error, the expected number of computations of the Legendre symbol is 2. But one can be lucky with the first try and one may need more than 2 tries. In the field &lt;math&gt;\mathbf{F}_{p^2}&lt;/math&gt;, the following two equalities hold
:&lt;math&gt;(x+y\omega)^2 = \left(x^2 + y^2 \omega^2 \right) + \left(\left(x+y\right)^2-x^2-y^2\right)\omega,&lt;/math&gt;
where &lt;math&gt;\omega^2 = a^2-n&lt;/math&gt; is known in advance. This computation needs 4 multiplications and 4 sums.
:&lt;math&gt;\left(x+y\omega\right)^2\left(c + \omega \right) = \left( cd - b\left(x+d\right)\right) + \left(d^2 - by\right)\omega,&lt;/math&gt;
where &lt;math&gt;d=(x+yc)&lt;/math&gt; and &lt;math&gt;b=ny&lt;/math&gt;. This operation needs 6 multiplications and 4 sums.

Assuming that &lt;math&gt;p \equiv 1 \pmod 4,&lt;/math&gt; (in the case &lt;math&gt;p \equiv 3 \pmod 4&lt;/math&gt;, the direct computation &lt;math&gt;x \equiv \pm n^{\frac{p+1}{4}}&lt;/math&gt; is much faster) the binary expression of &lt;math&gt;(p+1)/2&lt;/math&gt; has &lt;math&gt;m-1&lt;/math&gt; digits, of which ''k'' are ones. So for computing a &lt;math&gt;(p+1)/2&lt;/math&gt; power of &lt;math&gt;\left(a + \omega \right)&lt;/math&gt;, the first formula has to be used &lt;math&gt;n-k-1&lt;/math&gt; times and the second &lt;math&gt;k-1&lt;/math&gt; times.

For this, Cipolla's algorithm is better than the [[Tonelli–Shanks algorithm]] if and only if &lt;math&gt;S(S-1) &gt; 8m+20&lt;/math&gt;, with &lt;math&gt;2^{S}&lt;/math&gt; being the maximum power of 2 which divides &lt;math&gt;p-1&lt;/math&gt;.&lt;ref&gt;[http://www.springerlink.com/content/xgxe68edy03la96p/fulltext.pdf Gonzalo Tornaria  ''Square roots modulo p'']&lt;/ref&gt;

== Cipolla's algorithm is able to find square roots of powers of prime modula ==

According to Dickson's "History Of Numbers", the following formula of Cipolla will find square roots of powers of prime modula:
&lt;ref name="dickson1"&gt;
"History of the Theory of Numbers" Volume 1 by Leonard Eugene Dickson, p218
&lt;!-- url=https://archive.org/details/historyoftheoryo01dick --&gt;
[https://archive.org/stream/historyoftheoryo01dick#page/218/mode/2up read online]
&lt;/ref&gt;

:&lt;math&gt;2^{-1}*q^{t}((k+\sqrt{k^{2}-q})^{s}+(k-\sqrt{k^{2}-q})^{s})\bmod{p^{\lambda}}&lt;/math&gt;
: where &lt;math&gt;t=(p^{\lambda}-2*p^{\lambda-1}+1)/2&lt;/math&gt; and &lt;math&gt;s=p^{\lambda-1}*(p+1)/2&lt;/math&gt;
: where &lt;math&gt;q=10&lt;/math&gt;,&lt;math&gt;k=2&lt;/math&gt; as in this article's example

Taking the example in the wiki article we can see that this formula above does indeed take square roots of prime power modula.



As
:&lt;math&gt;\sqrt{10}\bmod{ 13^{3}}\equiv 1046&lt;/math&gt;

Now solve for &lt;math&gt; 2^{-1}*q^{t}&lt;/math&gt; via: 

:&lt;math&gt;2^{-1}*10^{(13^{3} - 2* 13^{2} + 1)/2} \bmod{13^{3}}\equiv 1086&lt;/math&gt;

Now create the &lt;math&gt;(2+ \sqrt{2^{2}-10})^{13^{2}* 7}\bmod{13^{3}}&lt;/math&gt; and &lt;math&gt;(2- \sqrt{2^{2}-10})^{13^{2}* 7}\bmod{13^{3}}&lt;/math&gt;
(See [[Talk:Cipolla%27s_algorithm | here]] for mathematica code showing this above computation, remembering
that something close to complex modular arithmetic is going on here) 

As such:

:&lt;math&gt;(2+\sqrt{2^{2}-10})^{13^{2}* 7}\bmod{13^{3}}\equiv 1540&lt;/math&gt;   and &lt;math&gt;(2-\sqrt{2^{2}-10})^{13^{2}* 7}\bmod{13^{3}}\equiv 1540&lt;/math&gt;

and the final equation is:

:&lt;math&gt;1086* (1540+1540)\bmod{ 13^{3}}\equiv 1046&lt;/math&gt;  which is the answer.

==References==
&lt;references /&gt;

==Sources==
* E. Bach, J.O. Shallit ''Algorithmic Number Theory: Efficient algorithms'' MIT Press, (1996)
* Leonard Eugene Dickson ''History of the Theory of Numbers'' Volume 1 p218 &lt;ref name="dickson"&gt;
"History of the Theory of Numbers" Volume 1 by Leonard Eugene Dickson, p218
url=https://archive.org/details/historyoftheoryo01dick
&lt;/ref&gt;

{{number theoretic algorithms}}

[[Category:Modular arithmetic]]
[[Category:Number theoretic algorithms]]
[[Category:Articles containing proofs]]</text>
      <sha1>1786ca14de8a61t2blfro23u0sxi7ux</sha1>
    </revision>
  </page>
  <page>
    <title>Defensive expenditures</title>
    <ns>0</ns>
    <id>42732578</id>
    <revision>
      <id>808348445</id>
      <parentid>765245449</parentid>
      <timestamp>2017-11-02T10:04:32Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v475)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1276">{{distinguish|Military budget}}
In [[environmental accounting]], '''defensive expenditures''' are expenditures that seek to minimise potential damage to oneself.  Examples include defence and insurance.&lt;ref&gt;{{cite web|url=http://glossary.eea.europa.eu/terminology/concept_html?term=defensive%20expenditure |title=defensive expenditure — Environmental Terminology Discovery Service — EEA |publisher=Glossary.eea.europa.eu |date= |accessdate=2014-05-17}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.appstate.edu/~whiteheadjc/eco3660/boardman/ch13.htm |title=Chapter 13 |publisher=Appstate.edu |date= |accessdate=2014-05-17}}&lt;/ref&gt;&lt;ref&gt;http://www.econ-pol.unisi.it/pubdocenti/TiezziAE.pdf&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.researchgate.net/profile/Angelo_Antoci/publication/4729489_Negative_externalities_defensive_expenditures_and_labour_supply_in_an_evolutionary_context/file/e0b495196843e62b8e.pdf |title=Negative externalities, defensive expenditures and labour supply in an evolutionary context |publisher=ResearchGate |date=2014-05-12 |accessdate=2014-05-17}}&lt;/ref&gt;

==References==
{{reflist}}

{{econ-term-stub}}
{{DEFAULTSORT:Defensive expenditures}}
[[Category:Risk management]]
[[Category:Actuarial science]]
[[Category:Environmental economics]]
[[Category:Expenditure]]</text>
      <sha1>9zejc19winmiju6ds21qp0b99adx6s0</sha1>
    </revision>
  </page>
  <page>
    <title>Demiregular tiling</title>
    <ns>0</ns>
    <id>46891994</id>
    <revision>
      <id>810931180</id>
      <parentid>810930868</parentid>
      <timestamp>2017-11-18T11:34:49Z</timestamp>
      <contributor>
        <username>Tomruen</username>
        <id>63601</id>
      </contributor>
      <comment>ok, I see SVGs updated Undid revision 810930868 by [[Special:Contributions/Tomruen|Tomruen]] ([[User talk:Tomruen|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9487">In [[geometry]], the ''demiregular tilings'' are a set of Euclidean [[tessellation]]s made from 2 or more [[regular polygon]] faces. Different authors have listed different sets of tilings. A more systematic approach looking at [[symmetry orbit]]s are the [[2-uniform tiling]]s of which there are 20. Some of the demiregular ones are actually [[3-uniform tiling]]s.

== 20 2-uniform tilings==
Grünbaum and Shephard enumerated the full list of 20 2-uniform tilings in ''Tilings and Paterns'', 1987:
{| class=wikitable
|+ 2-uniform tilings
|- align=center valign=top
|cmm, 2*22&lt;br/&gt;[[File:2-uniform n4.svg|120px]]&lt;br/&gt;(4&lt;sup&gt;4&lt;/sup&gt;; 3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;)&lt;sub&gt;1&lt;/sub&gt;
|cmm, 2*22&lt;br/&gt;[[File:2-uniform n3.svg|120px]]&lt;br/&gt;(4&lt;sup&gt;4&lt;/sup&gt;; 3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;)&lt;sub&gt;2&lt;/sub&gt;
|pmm, *2222&lt;br/&gt;[[File:2-uniform n14.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;)&lt;sub&gt;1&lt;/sub&gt;
|cmm, 2*22&lt;br/&gt;[[File:2-uniform n15.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;)&lt;sub&gt;2&lt;/sub&gt;
|cmm, 2*22&lt;br/&gt;[[File:2-uniform n6.svg|120px]]&lt;br/&gt;(3.4&lt;sup&gt;2&lt;/sup&gt;.6; (3.6)&lt;sup&gt;2&lt;/sup&gt;)&lt;sub&gt;2&lt;/sub&gt;
|pmm, *2222&lt;br/&gt;[[File:2-uniform n7.svg|120px]]&lt;br/&gt;(3.4&lt;sup&gt;2&lt;/sup&gt;.6; (3.6)&lt;sup&gt;2&lt;/sup&gt;)&lt;sub&gt;1&lt;/sub&gt;
|pmm, *2222&lt;br/&gt;[[File:2-uniform n11.svg|120px]]&lt;br/&gt;((3.6)&lt;sup&gt;2&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.6&lt;sup&gt;2&lt;/sup&gt;)
|- align=center valign=top
|p4m, *442&lt;br/&gt;[[File:2-uniform n2.svg|120px]]&lt;br/&gt;(3.12.12; 3.4.3.12)
|p4g, 4*2&lt;br/&gt;[[File:2-uniform n16.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.4.3.4)&lt;sub&gt;1&lt;/sub&gt;
|pgg, 2×&lt;br/&gt;[[File:2-uniform n17.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.4.3.4)&lt;sub&gt;2&lt;/sub&gt;
|p6m, *632&lt;br/&gt;[[File:2-uniform n10.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.6&lt;sup&gt;2&lt;/sup&gt;)
|p6m, *632&lt;br/&gt;[[File:2-uniform n19.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;4&lt;/sup&gt;.6)&lt;sub&gt;1&lt;/sub&gt;
|p6, 632&lt;br/&gt;[[File:2-uniform n20.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;4&lt;/sup&gt;.6)&lt;sub&gt;2&lt;/sub&gt;
|cmm, 2*22&lt;br/&gt;[[File:2-uniform n12.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;2&lt;/sup&gt;.6&lt;sup&gt;2&lt;/sup&gt;; 3&lt;sup&gt;4&lt;/sup&gt;.6)
|- align=center valign=top
|p6m, *632&lt;br/&gt;[[File:2-uniform n18.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.4.3.4)
|p6m, *632&lt;br/&gt;[[File:2-uniform n9.svg|120px]]&lt;br/&gt;(3.4.6.4; 3&lt;sup&gt;2&lt;/sup&gt;.4.3.4)
|p6m, *632&lt;br/&gt;[[File:2-uniform n8.svg|120px]]&lt;br/&gt;(3.4.6.4; 3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;)
|p6m, *632&lt;br/&gt;[[File:2-uniform n5.svg|120px]]&lt;br/&gt;(3.4.6.4; 3.4&lt;sup&gt;2&lt;/sup&gt;.6)
|p6m, *632&lt;br/&gt;[[File:2-uniform n1.svg|120px]]&lt;br/&gt;(4.6.12; 3.4.6.4)
|p6m, *632&lt;br/&gt;[[File:2-uniform n13.svg|120px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.4.12)
|}

== Ghyka's list (1946) ==

Ghyka lists 10 of them with 2 or 3 vertex types, calling them semiregular polymorph partitions.&lt;ref&gt;Ghyka (1946) pp. 73-80&lt;/ref&gt;
{| class=wikitable
|[[File:2-uniform n1.svg|120px]]
|
|
|[[File:2-uniform n8.svg|120px]]
|[[File:2-uniform n9.svg|120px]]
|- align=center valign=top
|Plate XXVII&lt;br/&gt;No. 12&lt;br/&gt;4.6.12&lt;br/&gt;3.4.6.4
|No. 13&lt;br/&gt;3.4.6.4&lt;br/&gt;3.3.3.4.4
|No. 13 bis.&lt;br/&gt;3.4.4.6&lt;br/&gt;3.3.4.3.4
|No. 13 ter.&lt;br/&gt;3.4.4.6&lt;br/&gt;3.3.3.4.4
|Plate XXIV&lt;br/&gt;No. 13 quatuor.&lt;br/&gt;3.4.6.4&lt;br/&gt;3.3.4.3.4
|- align=center valign=top
|
|
|
|[[File:2-uniform n13.svg|120px]]
|[[File:3-uniform 48.svg|120px]]
|- align=center valign=top
|No. 14 &lt;br/&gt;3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;&lt;br/&gt;3&lt;sup&gt;6&lt;/sup&gt;
|Plate XXVI&lt;br/&gt;No. 14 bis.&lt;br/&gt;3.3.4.3.4&lt;br/&gt;3.3.3.4.4&lt;br/&gt;3&lt;sup&gt;6&lt;/sup&gt;
|No. 14 ter.&lt;br/&gt;3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;&lt;br/&gt;3&lt;sup&gt;6&lt;/sup&gt;
|No. 15&lt;br/&gt;3.3.4.12&lt;br/&gt;3&lt;sup&gt;6&lt;/sup&gt;
|Plate XXV&lt;br/&gt;No. 16&lt;br/&gt;3.3.4.12&lt;br/&gt;3.3.4.3.4&lt;br/&gt;3&lt;sup&gt;6&lt;/sup&gt;
|}

== Steinhaus's list (1969) ==
Steinhaus gives 5 examples of non-homogeneous tessellations of regular polygons beyond the 11 regular and semiregular ones.&lt;ref&gt;Steinhaus, 1969, p.79-82.&lt;/ref&gt; (All of them have 2 types of vertices, while one is 3-uniform.)
{| class=wikitable
!colspan=4|2-uniform
!3-uniform
|-
|[[File:2-uniform n8.svg|120px]]
|[[File:2-uniform n9.svg|120px]]
|[[File:2-uniform n13.svg|120px]]
|[[File:2-uniform n16.svg|120px]]
|[[File:3-uniform 9.svg|120px]]
|- align=center
|Image 85&lt;br/&gt;3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;&lt;br/&gt;3.4.6.4
|Image 86&lt;br/&gt;3&lt;sup&gt;2&lt;/sup&gt;.4.3.4&lt;br/&gt;3.4.6.4
|Image 87&lt;br/&gt;3.3.4.12&lt;br/&gt;3&lt;sup&gt;6&lt;/sup&gt;
|Image 89&lt;br/&gt;3&lt;sup&gt;3&lt;/sup&gt;.4&lt;sup&gt;2&lt;/sup&gt;&lt;br/&gt;3&lt;sup&gt;2&lt;/sup&gt;.4.3.4
|Image 88&lt;br/&gt;3.12.12&lt;br/&gt;3.3.4.12
|}

==Critchlow's list (1970)==
Critchlow identifies 14 demi-regular tessellations, with 7 being 2-uniform, and 7 being 3-uniform.

He codes letter names for the vertex types, with superscripts to distinguish face orders. He recognizes A, B, C, D, F, and J can't be a part of continuous coverings of the whole plane.
{| class=wikitable
!A&lt;br/&gt;(none)||B&lt;br/&gt;(none)||C&lt;br/&gt;(none)||D&lt;br/&gt;(none)||E&lt;br/&gt;(semi)||F&lt;br/&gt;(none)||G&lt;br/&gt;(semi)||H&lt;br/&gt;(semi)||J&lt;br/&gt;(none)||K (2)&lt;br/&gt;(reg)
|- align=center valign=bottom
|BGCOLOR="#e0e0e0"|[[File:Regular polygons meeting at vertex 3 3 7 42.svg|40px]]&lt;br/&gt;3.7.42
|BGCOLOR="#e0e0e0"|[[File:Regular polygons meeting at vertex 3 3 8 24.svg|40px]]&lt;br/&gt;3.8.24
|BGCOLOR="#e0e0e0"|[[File:Regular polygons meeting at vertex 3 3 9 18.svg|40px]]&lt;br/&gt;3.9.18
|BGCOLOR="#e0e0e0"|[[File:Regular polygons meeting at vertex 3 3 10 15.svg|40px]]&lt;br/&gt;3.10.15
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 3 3 12 12.svg|40px]]&lt;br/&gt;[[Truncated hexagonal tiling|3.12.12]]
|BGCOLOR="#e0e0e0"|[[File:Regular polygons meeting at vertex 3 4 5 20.svg|40px]]&lt;br/&gt;4.5.20
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 3 4 6 12.svg|40px]]&lt;br/&gt;[[Truncated trihexagonal tiling|4.6.12]]
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 3 4 8 8.svg|40px]]&lt;br/&gt;[[truncated square tiling|4.8.8]]
|BGCOLOR="#e0e0e0"|[[File:Regular polygons meeting at vertex 3 5 5 10.svg|40px]]&lt;br/&gt;5.5.10
|BGCOLOR="#d0ffd0"|[[File:Regular polygons meeting at vertex 3 6 6 6.svg|40px]]&lt;br/&gt;[[hexagonal tiling|6&lt;sup&gt;3&lt;/sup&gt;]]
|-
!L1&lt;br/&gt;(demi)||L2&lt;br/&gt;(demi)||M1&lt;br/&gt;(demi)||M2&lt;br/&gt;(semi)||N1&lt;br/&gt;(demi)||N2&lt;br/&gt;(semi)||P (3)&lt;br/&gt;(reg)||Q1&lt;br/&gt;(semi)||Q2&lt;br/&gt;(semi)||R&lt;br/&gt;(semi)||S (1)&lt;br/&gt;(reg)
|- align=center valign=bottom
|BGCOLOR="#e0e0ff"|[[File:Regular polygons meeting at vertex 4 3 3 4 12.svg|40px]]&lt;br/&gt;3.3.4.12
|BGCOLOR="#e0e0ff"|[[File:Regular polygons meeting at vertex 4 3 4 3 12.svg|40px]]&lt;br/&gt;3.4.3.12
|BGCOLOR="#e0e0ff"|[[File:Regular polygons meeting at vertex 4 3 3 6 6.svg|40px]]&lt;br/&gt;3.3.6.6
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 4 3 6 3 6.svg|40px]]&lt;br/&gt;[[trihexagonal tiling|3.6.3.6]]
|BGCOLOR="#e0e0ff"|[[File:Regular polygons meeting at vertex 4 3 4 4 6.svg|40px]]&lt;br/&gt;3.4.4.6
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 4 3 4 6 4.svg|40px]]&lt;br/&gt;[[rhombitrihexagonal tiling|3.4.6.4]]
|BGCOLOR="#d0ffd0"|[[File:Regular polygons meeting at vertex 4 4 4 4 4.svg|40px]]&lt;br/&gt;[[Square tiling|4&lt;sup&gt;4&lt;/sup&gt;]]
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 5 3 3 4 3 4.svg|40px]]&lt;br/&gt;[[Snub square tiling|3.3.4.3.4]]
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 5 3 3 3 4 4.svg|40px]]&lt;br/&gt;[[elongated triangular tiling|3.3.3.4.4]]
|BGCOLOR="#ffe0e0"|[[File:Regular polygons meeting at vertex 5 3 3 3 3 6.svg|40px]]&lt;br/&gt;[[snub hexagonal tiling|3.3.3.3.6]]
|BGCOLOR="#d0ffd0"|[[File:Regular polygons meeting at vertex 6 3 3 3 3 3 3.svg|40px]]&lt;br/&gt;[[hexagonal tiling|3&lt;sup&gt;6&lt;/sup&gt;]]
|}

{| class=wikitable
|+ 2-uniforms
!1
!2
!4
!6
!7
!10
!14
|- align=center
|[[File:2-uniform n2.svg|100px]]&lt;br/&gt;(3.12.12; 3.4.3.12)
|[[File:2-uniform n13.svg|100px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.4.12)
|[[File:2-uniform n1.svg|100px]]&lt;br/&gt;(4.6.12; 3.4.6.4)
|[[File:2-uniform n11.svg|100px]]&lt;br/&gt;((3.6)&lt;sup&gt;2&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.6&lt;sup&gt;2&lt;/sup&gt;)
|[[File:2-uniform n9.svg|100px]]&lt;br/&gt;(3.4.6.4; 3&lt;sup&gt;2&lt;/sup&gt;.4.3.4)
|[[File:2-uniform n18.svg|100px]]&lt;br/&gt;(3&lt;sup&gt;6&lt;/sup&gt;; 3&lt;sup&gt;2&lt;/sup&gt;.4.3.4)
|[[File:2-uniform n5.svg|100px]]&lt;br/&gt;(3.4.6.4; 3.4&lt;sup&gt;2&lt;/sup&gt;.6)
|-
!E+L2||L1+(1)||N1+G||M1+M2||N2+Q1||Q1+(1)||N1+Q2
|}

{| class=wikitable width=600
|+ 3-uniforms
!3
!5
!8
!9
!11
!12
!13
|-
| (3.3.4.3.4; 3.3.4.12, 3.4.3.12)
| (3&lt;sup&gt;6&lt;/sup&gt;; 3.3.4.12; 3.3.4.3.4)
|(3.3.4.3.4; 3.3.3.4.4, 4.3.4.6)
|(3&lt;sup&gt;6&lt;/sup&gt;, 3.3.4.3.4)
|(3&lt;sup&gt;6&lt;/sup&gt;; 3.3.4.3.4, 3.3.3.4.4)
|(3&lt;sup&gt;6&lt;/sup&gt;; 3.3.4.3.4; 3.3.3.4.4)
|(3.4.6.4; 3.4&lt;sup&gt;2&lt;/sup&gt;.6)
|-
!L1+L2+Q1||L1+Q1+(1)||N1+Q1+Q2||Q1+(1)||Q1+Q2+(1)||Q1+Q2+(1)||N1+N2
|}

== References==
{{Reflist}}
* Ghyka, M. ''The Geometry of Art and Life'', (1946), 2nd edition, New York: Dover, 1977.
* Keith Critchlow, ''Order in Space: A design source book'', 1970, pp.&amp;nbsp;62–67
*{{The Geometrical Foundation of Natural Structure (book)}} pp.&amp;nbsp;35–43
* Steinhaus, H. ''Mathematical Snapshots'' 3rd ed, (1969), Oxford University Press, and (1999) New York: Dover
* {{cite book | ref=harv  | authorlink=Branko Grünbaum | last1=Grünbaum | first1=Branko | last2=Shephard | first2=G. C. | title=Tilings and Patterns | publisher=W. H. Freeman | date=1987 | isbn=0-7167-1193-1}} p.&amp;nbsp;65
* {{cite journal | first=D. |last=Chavey | title=Tilings by Regular Polygons&amp;mdash;II: A Catalog of Tilings | url=https://www.beloit.edu/computerscience/faculty/chavey/catalog/ | journal=Computers &amp; Mathematics with Applications | year=1989 | volume=17 | pages=147&amp;ndash;165 | doi=10.1016/0898-1221(89)90156-9|ref=harv}}
* [http://www.math.nus.edu.sg/aslaksen/papers/Demiregular.pdf In Search of Demiregular Tilings], Helmer Aslaksen

== External links==
* {{MathWorld | urlname=DemiregularTessellation | title=Demiregular tessellation}}
* [http://probabilitysports.com/tilings.html n-uniform tilings] Brian Galebach

[[Category:Tessellation]]</text>
      <sha1>mkzpoqykucmqmsn5xdzub8up60zbm03</sha1>
    </revision>
  </page>
  <page>
    <title>Deontic logic</title>
    <ns>0</ns>
    <id>1343980</id>
    <revision>
      <id>869231512</id>
      <parentid>862405261</parentid>
      <timestamp>2018-11-17T07:22:20Z</timestamp>
      <contributor>
        <username>Polly Feemus</username>
        <id>35160139</id>
      </contributor>
      <comment>/* Jørgensen's dilemma */ I updated this section to make it more clear that there are three classes of possible response.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13066">'''Deontic logic''' is the field of philosophical [[logic]] that is concerned with [[obligation]], [[permission (philosophy)|permission]], and related concepts.  Alternatively, a deontic logic is a formal system that attempts to capture the essential logical features of these concepts.  Typically, a deontic logic uses ''OA'' to mean ''it is obligatory that A'', (or ''it ought to be (the case) that A''), and ''PA'' to mean ''it is permitted (or permissible) that A''.

The term ''deontic'' is derived from the [[Ancient Greek]] δέον ''déon'' (gen.: δέοντος ''déontos''), meaning "that which is binding or proper."

==Standard deontic logic==
In [[Georg Henrik von Wright|von Wright]]'s first system, obligatoriness and permissibility were treated as features of ''acts''.  It was found not much later that a deontic logic of ''propositions'' could be given a simple and elegant [[Kripke semantics|Kripke-style semantics]], and von Wright himself joined this movement.  The deontic logic so specified came to be known as "standard deontic logic," often referred to as '''SDL''', '''KD''', or simply '''D'''.  It can be axiomatized by adding the following axioms to a standard axiomatization of classical [[propositional logic]]:

: &lt;math&gt;O(A \rightarrow B) \rightarrow (OA \rightarrow OB)&lt;/math&gt;
: &lt;math&gt;PA\to\lnot O\lnot A&lt;/math&gt;

In English, these axioms say, respectively:

* If it ought to be that A implies B, then if it ought to be that A, it ought to be that B;
* If A is permissible, then it is not the case that it ought not to be that A.

''FA'', meaning it is forbidden that ''A'', can be defined (equivalently) as &lt;math&gt;O \lnot A&lt;/math&gt; or &lt;math&gt;\lnot PA&lt;/math&gt;.

There are two main extensions of '''SDL''' that are usually considered. The first results by adding an [[Alethic modality|alethic modal operator]] &lt;math&gt;\Box&lt;/math&gt; in order to express the Kantian claim that "ought implies can":

: &lt;math&gt; OA \to \Diamond A. &lt;/math&gt;

where &lt;math&gt;\Diamond\equiv\lnot\Box\lnot&lt;/math&gt;. It is generally assumed that &lt;math&gt;\Box&lt;/math&gt; is at least a '''KT''' operator, but most commonly it is taken to be an '''S5''' operator.

The other main extension results by adding a "conditional obligation" operator O(A/B) read "It is obligatory that A given (or conditional on) B". Motivation for a conditional operator is given by considering the following ("Good Samaritan") case. It seems true that the starving and poor ought to be fed. But that the starving and poor are fed implies that there are starving and poor. By basic principles of '''SDL''' we can infer that there ought to be starving and poor! The argument is due to the basic K axiom of '''SDL''' together with the following principle valid in any [[normal modal logic]]:

:&lt;math&gt;\vdash A\to B\Rightarrow\ \vdash OA\to OB.&lt;/math&gt;

If we introduce an intensional conditional operator then we can say that the starving ought to be fed ''only on the condition that there are in fact starving'': in symbols O(A/B). But then the following argument fails on the usual (e.g. Lewis 73) semantics for conditionals: from O(A/B) and that A implies B, infer OB.

Indeed, one might define the unary operator O in terms of the binary conditional one O(A/B) as &lt;math&gt;OA\equiv O(A/\top)&lt;/math&gt;, where &lt;math&gt;\top&lt;/math&gt; stands for an arbitrary [[tautology (logic)|tautology]] of the underlying logic (which, in the case of '''SDL''', is classical). Similarly Alan R. Anderson (1959) shows how to define O in terms of the alethic operator &lt;math&gt;\Box&lt;/math&gt; and a deontic constant (i.e. 0-ary modal operator) s standing for some sanction (i.e. bad thing, prohibition, etc.): &lt;math&gt;OA\equiv\Box(\lnot A\to s)&lt;/math&gt;. Intuitively, the right side of the biconditional says that A's failing to hold necessarily (or strictly) implies a sanction.

==Dyadic deontic logic==
An important problem of deontic logic is that of how to properly represent conditional obligations, e.g. ''If you smoke (s), then you ought to use an ashtray (a). '' It is not clear that either of the following representations is adequate:

: &lt;math&gt;O(\mathrm{smoke} \rightarrow \mathrm{ashtray})&lt;/math&gt;
: &lt;math&gt;\mathrm{smoke} \rightarrow O(\mathrm{ashtray})&lt;/math&gt;

Under the first representation it is [[vacuously true]] that if you commit a forbidden act, then you ought to commit any other act, regardless of whether that second act was obligatory, permitted or forbidden (Von Wright 1956, cited in Aqvist 1994). Under the second representation, we are vulnerable to the gentle murder paradox, where the plausible statements (1) ''if you murder, you ought to murder gently'', (2) ''you do commit murder'', and (3) ''to murder gently you must murder'' imply the less plausible statement: ''you ought to murder''. Others argue that ''must'' in the phrase ''to murder gently you must murder'' is a mistranslation from the ambiguous English word (meaning either ''implies'' or ''ought''). Interpreting ''must'' as ''implies'' does not allow one to conclude ''you ought to murder'' but only a repetition of the given ''you murder''. Misinterpreting ''must'' as ''ought'' results in a perverse axiom, not a perverse logic. With use of negations one can easily check if the ambiguous word was mistranslated by considering which of the following two English statements is equivalent with the statement ''to murder gently you must murder'': is it equivalent to ''if you murder gently it is forbidden not to murder'' or ''if you murder gently it is impossible not to murder'' ?

Some deontic logicians have responded to this problem by developing dyadic deontic logics, which contain binary deontic operators:

: &lt;math&gt;O(A \mid B)&lt;/math&gt; means ''it is obligatory that A, given B''
: &lt;math&gt;P(A \mid B)&lt;/math&gt; means ''it is permissible that A, given B''.

(The notation is modeled on that used to represent [[conditional probability]].)  Dyadic deontic logic escapes some of the problems of standard (unary) deontic logic, but it is subject to some problems of its own.

==Other variations==
Many other varieties of deontic logic have been developed, including [[Non-monotonic logic|non-monotonic]] deontic logics, [[Paraconsistent logic|paraconsistent]] deontic logics, and [[Dynamic logic (modal logic)|dynamic]] deontic logics.

==History==

===Early deontic logic===
Philosophers from the [[India]]n [[Mimamsa|Mimamsa school]] to those of [[Ancient Greece]] have remarked on the formal logical relations of deontic concepts&lt;ref name=Greece&gt;Huisjes, C. H., 1981, "Norms and logic," Thesis, University of Groningen.&lt;/ref&gt; and philosophers from the late [[Medieval philosophy|Middle Ages]] compared deontic concepts with [[Alethic logic|alethic]] ones.&lt;ref name=ones&gt;Knuuttila, Simo, 1981, "The Emergence of Deontic Logic in the Fourteenth Century," in New Studies in Deontic Logic, Ed. Hilpinen, Risto, pp. 225-248, University of Turku, Turku, Finland: D. Reidel Publishing Company.&lt;/ref&gt; In his ''Elementa juris naturalis'', [[Gottfried Wilhelm Leibniz|Leibniz]] notes the logical relations between the ''licitum'', ''illicitum'', ''debitum'', and ''indifferens'' are equivalent to those between the ''possible'', ''impossible'', ''necessarium'', and ''contingens'' respectively.

===Mally's first deontic logic and von Wright's first ''plausible'' deontic logic===
[[Ernst Mally]], a pupil of [[Alexius Meinong]], was the first to propose a formal system of deontic logic in his ''Grundgesetze des Sollens'' and he founded it on the syntax of Whitehead's and Russell's [[propositional calculus]]. Mally's deontic vocabulary consisted of the logical constants U and ∩, unary connective !, and binary connectives f and ∞.&lt;br/&gt;
: * Mally read !A as "A ought to be the case".&lt;br/&gt;* He read A f B as "A requires B" .&lt;br/&gt;* He read A ∞ B as "A and B require each other."&lt;br/&gt;* He read U as "the unconditionally obligatory" .&lt;br/&gt;* He read ∩ as "the unconditionally forbidden".
Mally defined f, ∞, and ∩ as follows:
: Def. f. 	A f B = A → !B&lt;br/&gt;Def. ∞. 	A ∞ B = (A f B) &amp; (B f A)&lt;br/&gt;Def. ∩. 	∩ = ¬U
Mally proposed five informal principles:
: (i)	If A requires B and if B requires C, then A requires C.&lt;br/&gt;(ii)	If A requires B and if A requires C, then A requires B and C.&lt;br/&gt;(iii)	A requires B if and only if it is obligatory that if A then B.&lt;br/&gt;(iv)	The unconditionally obligatory is obligatory.&lt;br/&gt;(v)	The unconditionally obligatory does not require its own negation.
He formalized these principles and took them as his axioms:
: I. 	((A f B) &amp; (B → C)) → (A f C)&lt;br/&gt;II. 	((A f B) &amp; (A f C)) → (A f (B &amp; C))&lt;br/&gt;III. 	(A f B) ↔ !(A → B)&lt;br/&gt;IV. 	∃U !U&lt;br/&gt;V. 	¬(U f ∩)
From these axioms Mally deduced 35 theorems, many of which he rightly considered strange. [[Karl Menger]] showed that !A ↔ A is a theorem and thus that the introduction of the ! sign is irrelevant and that A ought to be the case if A is the case.&lt;ref name=A&gt;Menger, Karl, 1939, "A logic of the doubtful: On optative and imperative logic," in Reports of a Mathematical Colloquium, 2nd series, 2nd issue, pp. 53-64, Notre Dame, Indiana: Indiana University Press.&lt;/ref&gt; After Menger, philosophers no longer considered Mally's system viable. [[Gert Lokhorst]] lists Mally's 35 theorems and gives a proof for Menger's theorem at the [http://plato.stanford.edu/ Stanford Encyclopedia of Philosophy] under [http://plato.stanford.edu/entries/mally-deontic/ ''Mally's Deontic Logic''].

The first plausible system of deontic logic was proposed by [[Georg Henrik von Wright|G. H. von Wright]] in his paper ''Deontic Logic'' in the philosophical journal ''Mind'' in 1951. (Von Wright was also the first to use the term "deontic" in English to refer to this kind of logic although Mally published the German paper ''Deontik'' in 1926.) Since the publication of von Wright's seminal paper, many philosophers and computer scientists have investigated and developed systems of deontic logic. Nevertheless, to this day deontic logic remains one of the most controversial and least agreed-upon areas of logic.
G. H. von Wright did not base his 1951 deontic logic on the syntax of the propositional calculus as Mally had done, but was instead influenced by alethic [[modal logic]]s, which Mally had not benefited from. In 1964, von Wright published ''A New System of Deontic Logic'', which was a return to the syntax of the propositional calculus and thus a significant return to Mally's system. (For more on von Wright's departure from and return to the syntax of the propositional calculus, see ''Deontic Logic: A Personal View''{{Citation needed|date=June 2011}} and ''A New System of Deontic Logic''{{Citation needed|date=June 2011}}, both by Georg Henrik von Wright.) G. H. von Wright's adoption of the modal logic of possibility and necessity for the purposes of normative reasoning was a return to Leibniz.

==Jørgensen's dilemma==
Deontic logic faces [[Imperative logic#Jørgensen's dilemma|Jørgensen's dilemma]].&lt;ref&gt;{{cite journal|last=Jørgensen|first=Jørgen|title=Imperatives and Logic|journal=Erkenntnis|year=1937-38|volume=7|pages=288-96}}&lt;/ref&gt;.
This problem is best seen as a trilemma. 
The following three claims are incompatible:
* Logical inference requires that the elements (premises and conclusions) have truth-values
* Normative statements do not have truth-values
* There are logical inferences between normative statements
Responses to this problem involve rejecting one of the three premises.
The [http://icr.uni.lu/leonvandertorre/papers/fotfs03.pdf input/output logics] reject the first premise. 
They provide inference mechanism on elements without presupposing that these elements have truth-values. 
Alternatively, one can deny the second premise. One way to do this is to distinguish between the norm itself and a proposition about the norm.
According to this response, only the proposition about the norm has a truth-value. 
Finally, one can deny the third premise. But this is to deny that there is a logic of norms worth investigating.

==See also==
{{Portal|Logic}}
* [[Deontological ethics]]
* [[Imperative logic]]
* [[Modal logic]]
* [[Norm (philosophy)]]

==Notes==
{{Reflist}}

==Bibliography==
* [[Lennart Åqvist]], 1994, "Deontic Logic" in D. Gabbay and F. Guenthner, ed., ''Handbook of Philosophical Logic: Volume II Extensions of Classical Logic'', Dordrecht: Kluwer.
* Dov Gabbay, John Horty, Xavier Parent et al. (eds.)2013, ''Handbook of Deontic Logic and Normative Systems'', London: College Publications, 2013.
* Hilpinen, Risto, 2001, "Deontic Logic," in Goble, Lou, ed., ''The Blackwell Guide to Philosophical Logic''. Oxford: Blackwell.
* {{cite journal|last=von Wright|first=G. H.|authorlink=Georg Henrik von Wright|title=Deontic Logic|journal=Mind|year=1951|volume=60|pages=1-15}}

==External links==
*{{cite SEP |url-id=logic-deontic |title=Deontic Logic |last=McNamara |first=Paul}}
*{{cite SEP |url-id=mally-deontic |title=Mally's Deontic Logic |last=Lokhorst |first=Gert-Jan}}

{{Non-classical logic}}

{{DEFAULTSORT:Deontic Logic}}
[[Category:Modal logic]]
[[Category:Philosophical logic]]</text>
      <sha1>g20jj280kz9ienx0mzq9qx406czfnox</sha1>
    </revision>
  </page>
  <page>
    <title>Enrolled actuary</title>
    <ns>0</ns>
    <id>8586502</id>
    <revision>
      <id>741306038</id>
      <parentid>741039508</parentid>
      <timestamp>2016-09-26T17:25:34Z</timestamp>
      <contributor>
        <username>Famspear</username>
        <id>600513</id>
      </contributor>
      <comment>I believe that people in this field usually use the term EA to denote an Enrolled Agent, not an Enrolled Actuary.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2898">{{refimprove|date=August 2012}}
An '''enrolled actuary''' is an [[actuary]] enrolled by the [[Joint Board for the Enrollment of Actuaries]] under the [[Employee Retirement Income Security Act]] of 1974 (ERISA).&lt;ref&gt;See {{usc|26|7701}}, [https://www.law.cornell.edu/uscode/text/26/7701#a_35 paragraph (a)(35)], and {{usc|29|1242}}.&lt;/ref&gt; Enrolled actuaries, under regulations of the [[United States Department of the Treasury|Department of the Treasury]] and the [[United States Department of Labor|Department of Labor]], perform a variety of tasks with respect to pension plans in the [[United States]] under ERISA. As of August 2016, there were approximately 4,200 enrolled actuaries.&lt;ref&gt;{{cite web |url=https://www.irs.gov/pub/irs-utl/enrolled_actuary_roster.pdf |title=Enrolled Actuary Roster |date=August 23, 2016 |publisher=[[Joint Board for the Enrollment of Actuaries]] |type=PDF |accessdate=September 25, 2016 }}&lt;!-- Note: The roster consists of 183 pages with 23 actuaries per page, except 22 on the first page and 8 on the last. 22 + 181×22 + 8 = 4,193 enrolled actuaries. --&gt;&lt;/ref&gt;

== Qualifications ==

The Joint Board for the Enrollment of Actuaries administers two examinations to prospective enrolled actuaries. Once the two examinations have been passed, and an individual has also obtained sufficient relevant professional experience, that individual becomes an enrolled actuary.

The first exam (EA-1) tests basic knowledge of the mathematics of compound interest, the mathematics of life contingencies, and practical demographic analysis. 

The second (EA-2) examination consists of two segments, which are offered during separate exam sittings in either the fall or the spring. Segment F covers the selection of actuarial assumptions, actuarial cost methods, and the calculation of minimum (required) and maximum (tax-deductible) contributions to pension plans. Segment L tests knowledge of relevant federal pension laws (in particular, the provisions of ERISA) as they affect pension actuarial practice.

== Employers ==

Enrolled actuaries generally work for [[human resource consulting]] firms, investment and insurance brokers, accounting firms, government organizations, and law firms.  Some firms that employ enrolled actuaries combine two or more of these practice specialties.

== Organizations ==

Many enrolled actuaries belong to one or more of the following organizations:  the [[Society of Actuaries]], the [[American Academy of Actuaries]]. the [[Conference of Consulting Actuaries]] or the [[American Society of Pension Professionals &amp; Actuaries]].

== Notes and references ==
{{reflist}}

==External links==
* [https://www.irs.gov/tax-professionals/enrolled-actuaries Joint Board for the Enrollment of Actuaries]

[[Category:Actuarial science|Actuary]]
[[Category:Mathematical science occupations|Actuary]]
[[Category:Employee Retirement Income Security Act]]</text>
      <sha1>1mo8zuuu7ypgoe4urmc4hs4u8r3rqtn</sha1>
    </revision>
  </page>
  <page>
    <title>Estimation of distribution algorithm</title>
    <ns>0</ns>
    <id>3062637</id>
    <revision>
      <id>865353764</id>
      <parentid>847597977</parentid>
      <timestamp>2018-10-23T12:07:19Z</timestamp>
      <contributor>
        <ip>185.10.224.52</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27999">[[Image:Eda mono-variant gauss iterations.svg|thumb|350px|Estimation of distribution algorithm. For each iteration ''i'', a random draw is performed for a population ''P'' in a distribution ''PDu''. The distribution parameters ''PDe'' are then estimated using the selected points ''PS''. The illustrated example optimizes a continuous objective function ''f(X)'' with a unique optimum ''O''. The sampling (following a normal distribution ''N'') concentrates around the optimum as one goes along unwinding algorithm.]]

'''''Estimation of distribution algorithms''''' ('''EDAs'''), sometimes called '''''probabilistic model-building genetic algorithms''''' (PMBGAs),&lt;ref&gt;{{Citation|last=Pelikan|first=Martin|title=Probabilistic Model-Building Genetic Algorithms|date=2005-02-21|url=https://doi.org/10.1007/978-3-540-32373-0_2|work=Hierarchical Bayesian Optimization Algorithm|pages=13–30|publisher=Springer Berlin Heidelberg|language=en|doi=10.1007/978-3-540-32373-0_2|isbn=9783540237747|access-date=2018-06-16}}&lt;/ref&gt; are [[stochastic optimization]] methods that guide the search for the optimum by building and sampling explicit probabilistic models of promising candidate solutions. Optimization is viewed as a series of incremental updates of a probabilistic model, starting with the model encoding the uniform distribution over admissible solutions and ending with the model that generates only the global optima.&lt;ref&gt;{{cite book|author1=Pedro Larrañaga|author2=Jose A. Lozano|title=Estimation of Distribution Algorithms a New Tool for Evolutionary Computation|date=2002|publisher=Springer US|location=Boston, MA|isbn=978-1-4615-1539-5}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author1=Jose A. Lozano|author2=Larrañaga, P.|author3=Inza, I.|author4=Bengoetxea, E.|title=Towards a new evolutionary computation advances in the estimation of distribution algorithms|date=2006|publisher=Springer|location=Berlin|isbn=978-3-540-32494-2}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Pelikan|first1=Martin|last2=Sastry|first2=Kumara|last3=Cantú-Paz|first3=Erick|title=Scalable optimization via probabilistic modeling : from algorithms to applications ; with 26 tables|date=2006|publisher=Springer|location=Berlin|isbn=3540349537}}&lt;/ref&gt;

EDAs belong to the class of [[evolutionary algorithms]]. The main difference between EDAs and most conventional evolutionary algorithms is that evolutionary algorithms generate new candidate solutions using an ''implicit'' distribution defined by one or more variation operators, whereas EDAs use an ''explicit'' probability distribution encoded by a [[Bayesian network]], a [[multivariate normal distribution]], or another model class. Similarly as other evolutionary algorithms, EDAs can be used to solve optimization problems defined over a number of representations from vectors to [[LISP]] style S expressions, and the quality of candidate solutions is often evaluated using one or more objective functions.

The general procedure of an EDA is outlined in the following:
&lt;source lang=python&gt;
t = 0
initialize model M(0) to represent uniform distribution over admissible solutions
while (termination criteria not met)
    P = generate N&gt;0 candidate solutions by sampling M(t)
    F = evaluate all candidate solutions in P
    M(t+1) = adjust_model(P,F,M(t))
    t = t + 1
&lt;/source&gt;

Using explicit probabilistic models in optimization allowed EDAs to feasibly solve optimization problems that were notoriously difficult for most conventional evolutionary algorithms and traditional optimization techniques, such as problems with high levels of [[epistasis]]{{Citation needed|date=September 2017}}.  Nonetheless, the advantage of EDAs is also that these algorithms provide an optimization practitioner with a series of probabilistic models that reveal a lot of information about the problem being solved. This information can in turn be used to design problem-specific neighborhood operators for local search, to bias future runs of EDAs on a similar problem, or to create an efficient computational model of the problem.

For example, if the population is represented by bit strings of length 4, the EDA can represent the population of promising solution using a single vector of four probabilities (p1, p2, p3, p4) where each component of p defines the probability of that position being a 1. Using this probability vector it is possible to create an arbitrary number of candidate solutions.

==Estimation of distribution algorithms (EDAs)==
This section describes the models built by some well known EDAs of different levels of complexity. It is always assumed a population &lt;math&gt;P(t)&lt;/math&gt; at the generation &lt;math&gt;t&lt;/math&gt;, a selection operator &lt;math&gt;S&lt;/math&gt;, a model-building operator &lt;math&gt;\alpha&lt;/math&gt; and a sampling operator &lt;math&gt;\beta&lt;/math&gt;.

==Univariate factorizations==
The most simple EDAs assume that decision variables are independent, i.e. &lt;math&gt;p(X_1,X_2) = p(X_1)\cdot p(X_2)&lt;/math&gt;. Therefore, univariate EDAs rely only on univariate statistics and multivariate distributions must be factorized as the product of &lt;math&gt;N&lt;/math&gt; univariate probability distributions,

&lt;math&gt;
D_\text{Univariate} := p(X_1,\dots,X_N) = \prod_{i=1}^N p(X_i).
&lt;/math&gt;

Such factorizations are used in many different EDAs, next we describe some of them.

===Univariate marginal distribution algorithm (UMDA)===
The UMDA&lt;ref&gt;{{cite journal|last1=Mühlenbein|first1=Heinz|title=The Equation for Response to Selection and Its Use for Prediction|journal=Evol. Computation|date=1 September 1997|volume=5|issue=3|pages=303–346|doi=10.1162/evco.1997.5.3.303|url=http://dl.acm.org/citation.cfm?id=1326756|issn=1063-6560}}&lt;/ref&gt; is a simple EDA that uses an operator &lt;math&gt;\alpha_{UMDA}&lt;/math&gt; to estimate marginal probabilities from a selected population &lt;math&gt;S(P(t))&lt;/math&gt;. By assuming &lt;math&gt;S(P(t))&lt;/math&gt; contain &lt;math&gt;\lambda&lt;/math&gt; elements, &lt;math&gt;\alpha_{UMDA}&lt;/math&gt; produces probabilities:

&lt;math&gt;
p_{t+1}(X_i) = \dfrac{1}{\lambda} \sum_{x\in S(P(t))} x_i,~\forall i\in 1,2,\dots,N.
&lt;/math&gt;

Every UMDA step can be described as follows

&lt;math&gt;
D(t+1) = \alpha_\text{UMDA} \circ S \circ \beta_{\lambda}(D(t)).
&lt;/math&gt;

===[[Population-based incremental learning]] (PBIL)===
The PBIL,&lt;ref&gt;{{cite journal|last1=Baluja|first1=Shummet|title=Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learning|date=1 January 1994|url=http://dl.acm.org/citation.cfm?id=865123|publisher=Carnegie Mellon University}}&lt;/ref&gt; represents the population implicitly by its model, from which it samples new solutions and updates the model. At each generation, &lt;math&gt;\mu&lt;/math&gt; individuals are sampled and &lt;math&gt;\lambda\leq \mu&lt;/math&gt; are selected. Such individuals are then used to update the model as follows

&lt;math&gt;
p_{t+1}(X_i) = (1- \gamma) p_{t}(X_i) + (\gamma/\lambda) \sum_{x\in S(P(t))} x_i,~\forall i\in 1,2,\dots,N,
&lt;/math&gt;

where &lt;math&gt;\gamma\in(0,1]&lt;/math&gt; is a parameter defining the learning rate, a small value determines that the previous model &lt;math&gt;p_t(X_i)&lt;/math&gt; should be only slightly modified by the new solutions sampled. PBIL can be described as

&lt;math&gt;
D(t+1) = \alpha_\text{PIBIL} \circ S \circ \beta_\mu(D(t))
&lt;/math&gt;

===Compact genetic algorithm (cGA)===
The CGA,&lt;ref&gt;{{cite journal|last1=Harik|first1=G.R.|last2=Lobo|first2=F.G.|last3=Goldberg|first3=D.E.|title=The compact genetic algorithm|journal=IEEE Transactions on Evolutionary Computation|date=1999|volume=3|issue=4|pages=287–297|doi=10.1109/4235.797971}}&lt;/ref&gt; also relies on the implicit populations defined by univariate distributions. At each generation &lt;math&gt;t&lt;/math&gt;, two individuals &lt;math&gt;x,y&lt;/math&gt; are sampled, &lt;math&gt;P(t)=\beta_2(D(t))&lt;/math&gt;. The population &lt;math&gt;P(t)&lt;/math&gt; is then sort in decreasing order of fitness, &lt;math&gt;S_{\text{Sort}(f)}(P(t))&lt;/math&gt;, with &lt;math&gt;u&lt;/math&gt; being the best and &lt;math&gt;v&lt;/math&gt; being the worst solution. The CGA estimates univariate probabilities as follows

&lt;math&gt;
p_{t+1}(X_i) = p_t(X_i) + \gamma (u_i - v_i), \quad\forall i\in 1,2,\dots,N,
&lt;/math&gt;

where, &lt;math&gt;\gamma\in(0,1]&lt;/math&gt; is a constant defining the learning rate, usually set to &lt;math&gt;\gamma=1/N&lt;/math&gt;. The CGA can be defined as

&lt;math&gt;
D(t+1) = \alpha_\text{CGA} \circ S_{\text{Sort}(f)} \circ \beta_2(D(t))
&lt;/math&gt;

==Bivariate factorizations==
Although univariate models can be computed efficiently, in many cases they are not representative enough to provide better performance than GAs. In order to overcome such a drawback, the use of bivariate factorizations was proposed in the EDA community, in which dependencies between pairs of variables could be modeled. A bivariate factorization can be defined as follows, where &lt;math&gt;\pi_i&lt;/math&gt; contains a possible variable dependent to &lt;math&gt;X_i&lt;/math&gt;, i.e. &lt;math&gt;|\pi_i|=1&lt;/math&gt;.

&lt;math&gt;
D_\text{Bivariate} := p(X_1,\dots,X_N) = \prod_{i=1}^{N} p(X_i|\pi_i).
&lt;/math&gt;

Bivariate and multivariate distributions are usually represented as Probabilistic [[Graphical Models]] (graphs), in which edges denote statistical dependencies (or conditional probabilities) and vertices denote variables. To learn the structure of a PGM from data linkage-learning is employed.

===Mutual information maximizing input clustering (MIMIC)===
The MIMIC&lt;ref&gt;{{cite journal|last1=Bonet|first1=Jeremy S. De|last2=Isbell|first2=Charles L.|last3=Viola|first3=Paul|title=MIMIC: Finding Optima by Estimating Probability Densities|journal=Advances in Neural Information Processing Systems|date=1 January 1996|pages=424|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.47.6497|publisher=The MIT Press}}&lt;/ref&gt; factorizes the joint probability distribution in a chain-like model representing successive dependencies between variables. It finds a permutation of the decision variables, &lt;math&gt;r : i \mapsto j&lt;/math&gt;, such that &lt;math&gt;x_{r(1)}x_{r(2)},\dots,x_{r(N)}&lt;/math&gt; minimizes the [[Kullback-Leibler divergence]] in relation to the true probability distribution, i.e. &lt;math&gt;\pi_{r(i+1)} = \{X_{r(i)}\}&lt;/math&gt;. MIMIC models a distribution

&lt;math&gt;
p_{t+1}(X_1,\dots,X_N) = p_t(X_{r(N)}) \prod_{i=1}^{N-1} p_t(X_{r(i)}|X_{r(i+1)}).
&lt;/math&gt;

New solutions are sampled from the leftmost to the rightmost variable, the first is generated independently and the others according to conditional probabilities. Since the estimated distribution must be recomputed each generation, MIMIC uses concrete populations in the following way

&lt;math&gt;
P(t+1) = \beta_\mu \circ \alpha_\text{MIMIC} \circ S(P(t)).
&lt;/math&gt;

===Bivariate marginal distribution algorithm (BMDA)===
The BMDA&lt;ref&gt;{{cite journal|last1=Pelikan|first1=Martin|last2=Muehlenbein|first2=Heinz|title=The Bivariate Marginal Distribution Algorithm|journal=Advances in Soft Computing|date=1 January 1999|pages=521–535|doi=10.1007/978-1-4471-0819-1_39|url=https://link.springer.com/chapter/10.1007%2F978-1-4471-0819-1_39|publisher=Springer London}}&lt;/ref&gt; factorizes the joint probability distribution in bivariate distributions. First, a randomly chosen variable is added as a node in a graph, the most dependent variable to one of those in the graph is chosen among those not yet in the graph, this procedure is repeated until no remaining variable depends on any variable in the graph (verified according to a threshold value).

The resulting model is a forest with multiple trees rooted at nodes &lt;math&gt;\Upsilon_t&lt;/math&gt;. Considering &lt;math&gt;I_t&lt;/math&gt; the non-root variables, BMDA estimates a factorized distribution in which the root variables can be sampled independently, whereas all the others must be conditioned to the parent variable &lt;math&gt;\pi_i&lt;/math&gt;.

&lt;math&gt;
p_{t+1}(X_1,\dots,X_N) = \prod_{X_i\in \Upsilon_t} p_t(X_i) \cdot \prod_{X_i\in I_t} p_t(X_i | \pi_i).
&lt;/math&gt;

Each step of BMDA is defined as follows

&lt;math&gt;
P(t+1) = \beta_\mu \circ \alpha_\text{BMDA} \circ S(P(t)).
&lt;/math&gt;

==Multivariate factorizations==
The next stage of EDAs development was the use of multivariate factorizations. In this case, the joint probability distribution is usually factorized in a number of components of limited size &lt;math&gt;|\pi_i| \leq K,~\forall i\in 1,2,\dots,N&lt;/math&gt;.

&lt;math&gt;
p(X_1,\dots,X_N) = \prod_{i=1}^{N} p(X_i|\pi_i)
&lt;/math&gt;

The learning of PGMs encoding multivariate distributions is a computationally expensive task, therefore, it is usual for EDAs to estimate multivariate statistics from bivariate statistics. Such relaxation allows PGM to be built in polynomial time in &lt;math&gt;N&lt;/math&gt;; however, it also limits the generality of such EDAs.

===Extended compact genetic algorithm (eCGA)===
The ECGA&lt;ref&gt;{{cite book|last1=Harik|first1=Georges Raif|title=Learning Gene Linkage to Efficiently Solve Problems of Bounded Difficulty Using Genetic Algorithms|publisher=University of Michigan|url=http://dl.acm.org/citation.cfm?id=269517}}&lt;/ref&gt; was one of the first EDA to employ multivariate factorizations, in which high-order dependencies among decision variables can be modeled. Its approach factorizes the joint probability distribution in the product of multivariate marginal distributions. Assume &lt;math&gt;T_\text{eCGA}=\{\tau_1,\dots,\tau_\Psi\}&lt;/math&gt; is a set of subsets, in which every &lt;math&gt;\tau\in T_\text{eCGA}&lt;/math&gt; is a linkage set, containing &lt;math&gt;|\tau|\leq K&lt;/math&gt; variables. The factorized joint probability distribution is represented as follows

&lt;math&gt;
p(X_1,\dots,X_N) = \prod_{\tau\in T_\text{eCGA}} p(\tau).
&lt;/math&gt;

The ECGA popularized the term "linkage-learning" as denoting procedures that identify linkage sets. Its linkage-learning procedure relies on two measures: (1) the Model Complexity (MC) and (2) the Compressed Population Complexity (CPC). The MC quantifies the model representation size in terms of number of bits required to store all the marginal probabilities

&lt;math&gt;
MC = \log_2 (\lambda+1) \sum_{\tau\in T_\text{eCGA}} (2^{|\tau|-1}),
&lt;/math&gt;

The CPC, on the other hand, quantifies the data compression in terms of entropy of the marginal distribution over all partitions, where &lt;math&gt;\lambda&lt;/math&gt; is the selected population size, &lt;math&gt;|\tau|&lt;/math&gt; is the number of decision variables in the linkage set &lt;math&gt;\tau&lt;/math&gt; and &lt;math&gt;H(\tau)&lt;/math&gt; is the joint entropy of the variables in &lt;math&gt;\tau&lt;/math&gt;

&lt;math&gt;
CPC = \lambda \sum_{\tau\in T_\text{eCGA}} H(\tau).
&lt;/math&gt;

The linkage-learning in ECGA works as follows: (1) Insert each variable in a cluster, (2) compute CCC = MC + CPC of the current linkage sets, (3) verify the increase on CCC provided by joining pairs of clusters, (4) effectively joins those clusters with highest CCC improvement. This procedure is repeated until no CCC improvements are possible and produces a linkage model &lt;math&gt;T_\text{eCGA}&lt;/math&gt;. The ECGA works with concrete populations, therefore, using the factorized distribution modeled by ECGA, it can be described as

&lt;math&gt;
P(t+1) = \beta_\mu \circ \alpha_\text{eCGA} \circ S(P(t))
&lt;/math&gt;

===Bayesian optimization algorithm (BOA)===
The BOA&lt;ref&gt;{{cite journal|last1=Pelikan|first1=Martin|last2=Goldberg|first2=David E.|last3=Cantu-Paz|first3=Erick|title=BOA: The Bayesian Optimization Algorithm|date=1 January 1999|pages=525–532|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.46.8131|publisher=Morgan Kaufmann}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Pelikan|first1=Martin|title=Hierarchical Bayesian optimization algorithm : toward a new generation of evolutionary algorithms|date=2005|publisher=Springer|location=Berlin [u.a.]|isbn=978-3-540-23774-7|edition=1st}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Wolpert|first1=David H.|last2=Rajnarayan|first2=Dev|title=Using Machine Learning to Improve Stochastic Optimization|journal=Proceedings of the 17th AAAI Conference on Late-Breaking Developments in the Field of Artificial Intelligence|date=1 January 2013|pages=146–148|url=http://dl.acm.org/citation.cfm?id=2908286.2908335|publisher=AAAI Press}}&lt;/ref&gt; uses Bayesian networks to model and sample promising solutions. Bayesian networks are directed acyclic graphs, with nodes representing variables and edges representing conditional probabilities between pair of variables. The value of a variable &lt;math&gt;x_i&lt;/math&gt; can be conditioned on a maximum of &lt;math&gt;K&lt;/math&gt; other variables, defined in &lt;math&gt;\pi_i&lt;/math&gt;. BOA builds a PGM encoding a factorized joint distribution, in which the parameters of the network, i.e. the conditional probabilities, are estimated from the selected population using the maximum likelihood estimator.

&lt;math&gt;
p(X_1,X_2,\dots,X_N)=\prod_{i=1}^{N}p(X_i|\pi_{i}).
&lt;/math&gt;

The Bayesian network structure, on the other hand, must be built iteratively (linkage-learning). It starts with a network without edges and, at each step, adds the edge which better improves some scoring metric (e.g. Bayesian information criterion (BIC) or Bayesian-Dirichlet metric with likelihood equivalence (BDe)).&lt;ref&gt;{{cite journal|last1=Larrañaga|first1=Pedro|last2=Karshenas|first2=Hossein|last3=Bielza|first3=Concha|last4=Santana|first4=Roberto|title=A review on probabilistic graphical models in evolutionary computation|journal=Journal of Heuristics|date=21 August 2012|volume=18|issue=5|pages=795–819|doi=10.1007/s10732-012-9208-4}}&lt;/ref&gt; The scoring metric evaluates the network structure according to its accuracy in modeling the selected population. From the built network, BOA samples new promising solutions as follows: (1) it computes the ancestral ordering for each variable, each node being preceded by its parents; (2) each variable is sampled conditionally to its parents. Given such scenario, every BOA step can be defined as

&lt;math&gt;
P(t+1) = \beta_\mu \circ \alpha_\text{BOA} \circ S(P(t))
&lt;/math&gt;

===Linkage-tree Genetic Algorithm (LTGA)===
The LTGA&lt;ref&gt;{{cite journal|last1=Thierens|first1=Dirk|title=The Linkage Tree Genetic Algorithm|journal=Parallel Problem Solving from Nature, PPSN XI|date=11 September 2010|pages=264–273|doi=10.1007/978-3-642-15844-5_27|url=https://link.springer.com/chapter/10.1007%2F978-3-642-15844-5_27#page-1|publisher=Springer Berlin Heidelberg}}&lt;/ref&gt; differs from most EDA in the sense it does not explicitly model a probabilisty distribution but only a linkage model, called linkage-tree. A linkage &lt;math&gt;T&lt;/math&gt; is a set of linkage sets with no probability distribution associated, therefore, there is no way to sample new solutions directly from &lt;math&gt;T&lt;/math&gt;. The linkage model is a linkage-tree produced stored as a [[Family of sets]] (FOS).

&lt;math&gt;
T_\text{LT}  = \{ \{x_1\}, \{x_2\},\{x_3\},\{x_4\},\{x_1,x_2\},\{x_3,x_4\} \}.
&lt;/math&gt;

The linkage-tree learning procedure is a [[hierarchical clustering]] algorithm, which work as follows. At each step the two ''closest'' clusters &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt; are merged, this procedure repeats until only one cluster remains, each subtree is stored as a subset &lt;math&gt;\tau\in T_\text{LT}&lt;/math&gt;.

The LTGA uses &lt;math&gt;T_\text{LT}&lt;/math&gt; to guide an "optimal mixing" procedure which resembles a recombination operator but only accepts improving moves. We denote it as &lt;math&gt;R_\text{LTGA}&lt;/math&gt;, where the notation &lt;math&gt;x[\tau]\gets y[\tau]&lt;/math&gt; indicates the transfer of the genetic material indexed by &lt;math&gt;\tau&lt;/math&gt; from &lt;math&gt;y&lt;/math&gt; to &lt;math&gt;x&lt;/math&gt;.

{{algorithm-begin|name=Gene-pool optimal mixing}}
    Input: A family of subsets &lt;math&gt;T_\text{LT}&lt;/math&gt; and a population &lt;math&gt;P(t)&lt;/math&gt;
    Output: A population &lt;math&gt;P(t+1)&lt;/math&gt;.
    '''for each''' &lt;math&gt;x_i&lt;/math&gt; '''in''' &lt;math&gt;P(t)&lt;/math&gt; '''do'''
        '''for each''' &lt;math&gt;\tau&lt;/math&gt; '''in''' &lt;math&gt;T_\text{LT}&lt;/math&gt; '''do'''
            choose a random &lt;math&gt;x_j\in P(t) : x_i\neq x_j&lt;/math&gt;
            &lt;math&gt;f_{x_i}&lt;/math&gt; := &lt;math&gt;f(x_i)&lt;/math&gt;
            &lt;math&gt;x_i[\tau]&lt;/math&gt;:= &lt;math&gt;x_j[\tau]&lt;/math&gt;
            '''if''' &lt;math&gt;f(x_i) \leq f_{x_i}&lt;/math&gt; '''then'''
                &lt;math&gt;x_i[\tau]:= x_j[\tau]&lt;/math&gt; 
    '''return''' &lt;math&gt;P(t)&lt;/math&gt;
{{algorithm-end}}

The LTGA does not implement typical selection operators, instead, selection is performed during recombination. Similar ideas have been usually applied into local-search heuristics and, in this sense, the LTGA can be seen as an hybrid method. In summary, one step of the LTGA is defined as

&lt;math&gt;
P(t+1) = R_{\text{LTGA}}(P(t)) \circ \alpha_\text{LTGA} (P(t))
&lt;/math&gt;

==Other==
* Probability collectives (PC)&lt;ref&gt;{{cite journal|last1=WOLPERT|first1=DAVID H.|last2=STRAUSS|first2=CHARLIE E. M.|last3=RAJNARAYAN|first3=DEV|title=ADVANCES IN DISTRIBUTED OPTIMIZATION USING PROBABILITY COLLECTIVES|journal=Advances in Complex Systems|date=December 2006|volume=09|issue=04|pages=383–436|doi=10.1142/S0219525906000884}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Pelikan|first1=Martin|last2=Goldberg|first2=David E.|last3=Lobo|first3=Fernando G.|title=A Survey of Optimization by Building and Using Probabilistic Models|journal=Computational Optimization and Applications|date=2002|volume=21|issue=1|pages=5–20|doi=10.1023/A:1013500812258}}&lt;/ref&gt;
* Hill climbing with learning (HCwL)&lt;ref&gt;{{Cite journal|last=Rudlof|first=Stephan|last2=Köppen|first2=Mario|date=1997|title=Stochastic Hill Climbing with Learning by Vectors of Normal Distributions|url=http://citeseerx.ist.psu.edu/viewdoc/similar?doi=10.1.1.19.3536&amp;type=ab|language=en}}&lt;/ref&gt;
* Estimation of multivariate normal algorithm (EMNA){{Citation needed|date=June 2018}}
* Estimation of Bayesian networks algorithm (EBNA){{Citation needed|date=June 2018}}
* Stochastic hill climbing with learning by vectors of normal distributions (SHCLVND)&lt;ref&gt;{{Cite journal|last=Rudlof|first=Stephan|last2=Köppen|first2=Mario|date=1997|title=Stochastic Hill Climbing with Learning by Vectors of Normal Distributions|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.19.3536|pages=60––70}}&lt;/ref&gt;
* Real-coded PBIL{{Citation needed|date=June 2018}}
* Selfish Gene Algorithm (SG)&lt;ref&gt;{{Cite journal|last=Corno|first=Fulvio|last2=Reorda|first2=Matteo Sonza|last3=Squillero|first3=Giovanni|date=1998-02-27|title=The selfish gene algorithm: a new evolutionary optimization strategy|url=http://dl.acm.org/citation.cfm?id=330560.330838|publisher=ACM|pages=349–355|doi=10.1145/330560.330838|isbn=0897919696}}&lt;/ref&gt;
* Compact Differential Evolution (cDE)&lt;ref&gt;{{Cite journal|last=Mininno|first=Ernesto|last2=Neri|first2=Ferrante|last3=Cupertino|first3=Francesco|last4=Naso|first4=David|date=2011|title=Compact Differential Evolution|url=http://ieeexplore.ieee.org/document/5675671/|journal=IEEE Transactions on Evolutionary Computation|language=en-US|volume=15|issue=1|pages=32–54|doi=10.1109/tevc.2010.2058120|issn=1089-778X|via=}}&lt;/ref&gt; and its variants&lt;ref&gt;{{Cite journal|last=Iacca|first=Giovanni|last2=Caraffini|first2=Fabio|last3=Neri|first3=Ferrante|date=2012|title=Compact Differential Evolution Light: High Performance Despite Limited Memory Requirement and Modest Computational Overhead|url=https://doi.org/10.1007/s11390-012-1284-2|journal=Journal of Computer Science and Technology|language=en|volume=27|issue=5|pages=1056–1076|doi=10.1007/s11390-012-1284-2|issn=1000-9000|via=}}&lt;/ref&gt;&lt;ref&gt;{{Citation|last=Iacca|first=Giovanni|title=Opposition-Based Learning in Compact Differential Evolution|date=2011|url=https://doi.org/10.1007/978-3-642-20525-5_27|last2=Neri|first2=Ferrante|last3=Mininno|first3=Ernesto|work=Applications of Evolutionary Computation|pages=264–273|publisher=Springer Berlin Heidelberg|language=en|doi=10.1007/978-3-642-20525-5_27|isbn=9783642205248|access-date=2018-06-15}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Mallipeddi|first=Rammohan|last2=Iacca|first2=Giovanni|last3=Suganthan|first3=Ponnuthurai Nagaratnam|last4=Neri|first4=Ferrante|last5=Mininno|first5=Ernesto|date=2011|title=Ensemble strategies in Compact Differential Evolution|url=http://ieeexplore.ieee.org/document/5949857/|journal=2011 IEEE Congress of Evolutionary Computation (CEC)|language=en-US|publisher=IEEE|volume=|pages=|doi=10.1109/cec.2011.5949857|isbn=9781424478347|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Neri|first=Ferrante|last2=Iacca|first2=Giovanni|last3=Mininno|first3=Ernesto|date=2011|title=Disturbed Exploitation compact Differential Evolution for limited memory optimization problems|url=https://doi.org/10.1016/j.ins.2011.02.004|journal=Information Sciences|volume=181|issue=12|pages=2469–2487|doi=10.1016/j.ins.2011.02.004|issn=0020-0255|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Iacca|first=Giovanni|last2=Mallipeddi|first2=Rammohan|last3=Mininno|first3=Ernesto|last4=Neri|first4=Ferrante|last5=Suganthan|first5=Pannuthurai Nagaratnam|date=2011|title=Global supervision for compact Differential Evolution|url=http://ieeexplore.ieee.org/document/5952051/|journal=2011 IEEE Symposium on Differential Evolution (SDE)|language=en-US|publisher=IEEE|volume=|pages=|doi=10.1109/sde.2011.5952051|isbn=9781612840710|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Iacca|first=Giovanni|last2=Mallipeddi|first2=Rammohan|last3=Mininno|first3=Ernesto|last4=Neri|first4=Ferrante|last5=Suganthan|first5=Pannuthurai Nagaratnam|date=2011|title=Super-fit and population size reduction in compact Differential Evolution|url=http://ieeexplore.ieee.org/document/5953633/|journal=2011 IEEE Workshop on Memetic Computing (MC)|language=en-US|publisher=IEEE|volume=|pages=|doi=10.1109/mc.2011.5953633|isbn=9781612840659|via=}}&lt;/ref&gt;
* Compact Particle Swarm Optimization (cPSO)&lt;ref&gt;{{Cite journal|last=Neri|first=Ferrante|last2=Mininno|first2=Ernesto|last3=Iacca|first3=Giovanni|date=2013|title=Compact Particle Swarm Optimization|url=https://doi.org/10.1016/j.ins.2013.03.026|journal=Information Sciences|volume=239|pages=96–121|doi=10.1016/j.ins.2013.03.026|issn=0020-0255|via=}}&lt;/ref&gt;
* Compact Bacterial Foraging Optimization (cBFO)&lt;ref&gt;{{Citation|last=Iacca|first=Giovanni|title=Compact Bacterial Foraging Optimization|date=2012|url=https://doi.org/10.1007/978-3-642-29353-5_10|last2=Neri|first2=Ferrante|last3=Mininno|first3=Ernesto|work=Swarm and Evolutionary Computation|pages=84–92|publisher=Springer Berlin Heidelberg|language=en|doi=10.1007/978-3-642-29353-5_10|isbn=9783642293528|access-date=2018-06-15}}&lt;/ref&gt;
* Probabilistic incremental program evolution (PIPE)&lt;ref&gt;{{Cite journal|last=Salustowicz|first=null|last2=Schmidhuber|first2=null|date=1997|title=Probabilistic incremental program evolution|journal=Evolutionary Computation|volume=5|issue=2|pages=123–141|issn=1530-9304|pmid=10021756}}&lt;/ref&gt;
* Estimation of Gaussian networks algorithm (EGNA){{Citation needed|date=June 2018}}
* Estimation multivariate normal algorithm with thresheld convergence&lt;ref&gt;{{Cite journal|last=Tamayo-Vera|first=Dania|last2=Bolufe-Rohler|first2=Antonio|last3=Chen|first3=Stephen|date=2016|title=Estimation multivariate normal algorithm with thresheld convergence|url=https://doi.org/10.1109/CEC.2016.7744223|journal=2016 IEEE Congress on Evolutionary Computation (CEC)|language=en-US|publisher=IEEE|volume=|pages=|doi=10.1109/cec.2016.7744223|isbn=9781509006236|via=}}&lt;/ref&gt;
*Dependency Structure Matrix Genetic Algorithm (DSMGA)&lt;ref&gt;{{Citation|last=Yu|first=Tian-Li|title=Genetic Algorithm Design Inspired by Organizational Theory: Pilot Study of a Dependency Structure Matrix Driven Genetic Algorithm|date=2003|url=https://doi.org/10.1007/3-540-45110-2_54|work=Genetic and Evolutionary Computation — GECCO 2003|pages=1620–1621|publisher=Springer Berlin Heidelberg|language=en|doi=10.1007/3-540-45110-2_54|isbn=9783540406037|access-date=2018-10-23|last2=Goldberg|first2=David E.|last3=Yassine|first3=Ali|last4=Chen|first4=Ying-Ping}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Hsu|first=Shih-Huan|last2=Yu|first2=Tian-Li|date=2015-07-11|title=Optimization by Pairwise Linkage Detection, Incremental Linkage Set, and Restricted / Back Mixing: DSMGA-II|url=http://dl.acm.org/citation.cfm?id=2739480.2754737|publisher=ACM|pages=519–526|doi=10.1145/2739480.2754737|isbn=9781450334723}}&lt;/ref&gt;

==Related==

* [[CMA-ES]]
* [[Cross-entropy method]]

==References==
{{Reflist}}

{{DEFAULTSORT:Estimation Of Distribution Algorithm}}
[[Category:Evolutionary computation]]
[[Category:Stochastic optimization]]</text>
      <sha1>lo4sjvzjhymufmktd5vq185t7v4jox5</sha1>
    </revision>
  </page>
  <page>
    <title>Ethics in mathematics</title>
    <ns>0</ns>
    <id>54956115</id>
    <revision>
      <id>849657109</id>
      <parentid>834446073</parentid>
      <timestamp>2018-07-10T13:23:41Z</timestamp>
      <contributor>
        <username>Dimadick</username>
        <id>24198</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10079">'''Ethics in mathematics''' is a field of [[applied ethics]], the inquiry into ethical aspects of the applications of [[mathematics]]. It deals with the professional responsibilities of [[mathematicians]] whose work influences decisions with major consequences, such as in law, finance, the military, and environmental science.

==Need for ethics in the mathematics profession==
Mathematicians in industrial, scientific, military and intelligence roles crucially influence decisions with large consequences. For example, complex calculations were needed for the success of the [[Manhattan Project]], while the overextended use of the [[Copula (probability theory)|Gaussian copula]] formula to price derivatives before the [[Global Financial Crisis]] of 2008 has been called "the formula that killed Wall Street",&lt;ref&gt;Felix Salmon, [https://www.wired.com/2009/02/wp-quant/ Recipe for disaster: the formula that killed Wall Street"], ''Wired''23 Feb 2009.&lt;/ref&gt; and the theory of global warming depends on the reliability of [[climate models|mathematical models of climate]]. For the same reason as in [[medical ethics]] and [[engineering ethics]], the high impact of the consequences of decisions imposes serious ethical obligations on practitioners to consider the rights and wrongs of their advice and decisions.

==Disasters and scandals involving the use of mathematics==
These illustrate the major consequences of numerical mistakes and hence the need for ethical care.
* The [[Club of Rome]]'s 1972 mathematical-model based predictions in ''[[The Limits to Growth]]'' of widespread collapse of the world system by the end of the century.
* [[Sally Clark|Wrongful conviction of Sally Clark]] (1999), An English solicitor, Sally Clark, was wrongfully convicted of murdering her two children – each of whom had died due to [[sudden infant death syndrome]] – due to a fundamental statistical error in the testimony of an "expert".&lt;br&gt;The error was further compounded by the "[[prosecutor's fallacy]]".&lt;ref&gt;[https://www.telegraph.co.uk/news/uknews/1432762/Misleading-statistics-were-presented-as-facts-in-Sally-Clark-trial.html Derbyshire, D., "Misleading statistics were presented as facts in Sally Clark trial", ''The Telegraph'', (12 June 2003).]&lt;/ref&gt;

==Ethical issues in the mathematical profession==
Mathematicians in professional roles in finance and similar work have a particular responsibility to ensure they use the best methods and data to reach the right answer, as the prestige of mathematics is high and others rely on mathematical results which they cannot fully understand. Other ethical issues are shared with [[information economy]] professionals in general, such as [[duty of care]], [[confidentiality]] of information, [[whistleblowing]], and avoiding [[conflict of interest]].

==Misuse of statistics==
{{Main|Misuse of statistics}}
Much of mathematics as used in applications involves the drawing of conclusions from quantitative data. It is recognised that there are many difficulties in reaching and communicating such conclusions accurately, honestly and with due regard to the uncertainties that remain. It is easy for a statistician to mislead clients whose understanding of data and inference is less developed, so statisticians have professional responsibilities to act fairly.

==Ethics in pure mathematical research==
The [[American Mathematical Society]] publishes a code of ethical guidelines for mathematical researchers. The responsibilities of researchers include being knowledgeable in the field, avoiding plagiarism and giving credit, to publish without unreasonable delay, and to correct errors.&lt;ref&gt;[http://www.ams.org/about-us/governance/policy-statements/sec-ethics American Mathematical Society Policy Statement on Ethical Guidelines], 2005.&lt;/ref&gt; The [[European Mathematical Society]] Ethics Committee also publishes a code of practice relating to the publication, editing and refereeing of research.&lt;ref&gt;[http://euro-math-soc.eu/system/files/uploads/COP-approved.pdf Code of Practice – European Mathematical Society].&lt;/ref&gt;

It has been argued that as pure mathematical research is relatively harmless, it raises few urgent ethical issues.&lt;ref&gt;
[[Reuben Hersh]], [http://scholarship.claremont.edu/cgi/viewcontent.cgi?article=1068&amp;context=hmnj Mathematics and ethics], ''The Mathematical Intelligencer'' 12 (3) (1990), 13–15.&lt;/ref&gt; However, that raises the question of whether and why pure mathematics is ethically worth doing, given that it consumes the lives of many highly intelligent people who could be making more immediately useful contributions.&lt;ref&gt;[[James Franklin (philosopher)|James Franklin]], [https://link.springer.com/article/10.1007%2FBF03024064 Ethics of mathematics], ''Mathematical Intelligencer'' 13 (1) (1991), 4.&lt;/ref&gt;

==Teaching ethics in mathematics==
Courses in the ethics of mathematics remain rare. The [[University of New South Wales]] taught a compulsory course on Professional Issues and Ethics in Mathematics in its mathematics degrees from 1998 to 2012.&lt;ref&gt;James Franklin, [http://www.austms.org.au/Publ/Gazette/2005/May05/franklin.pdf A “Professional issues and ethics in mathematics” course], ''Gazette of the Australian Mathematical Society'' 32 (2005), 98–100.&lt;/ref&gt;

== See also ==
* [[Essentially contested concept]]
* [[Ethical calculus]]
* [[Misuse of statistics]]
* [[Prosecutor's fallacy]]
* [[Type I and type II errors]]
* [[Type III error]]
* [[Unintended consequences]]

==Notes==
{{Reflist|30em}}

==References==
{{refbegin|30em}}
* [http://www.rss.org.uk/Images/PDF/influencing-change/rss-fundamentals-probability-statistical-evidence.pdf Aitken, C., Roberts, P. &amp; Jackson, G., ''Communicating and Interpreting Statistical Evidence in the Administration of Criminal Justice, Practitioner Guide No.1: Fundamentals of Probability and Statistical Evidence in Criminal Proceedings: Guidance for Judges, Lawyers, Forensic Scientists and Expert Witnesses'', Royal Statistical Society, 2010].
* [[Michel Balinski|Balinski, M.]], [https://www.jstor.org/stable/30037520? "What is just?"], ''American Mathematical Monthly'', Vol.112, No.6, (June-July 2005), pp. 502-511.
* Boylan, M., "Ethical Dimensions of Mathematics Education", ''Educational Studies in Mathematics'', Vol.92, No.3, (July 2016), pp. 395–409.
* [[Gerald Dworkin|Dworkin, G.]], "A Journal of Mathematical Ethics: A Proposal", ''The Philosophical Forum'', Vol.13, No.4, (Summer 1982), pp. 413–415.
* Ernest, P. [http://flm-journal.org/Articles/4F2131EE356F3901F87BE5DC0529.pdf "What is Our First Philosophy in Mathematics Education?"], ''For the Learning of Mathematics'', Vol.32, No.3, (November 2012), pp. 8–14.
* [[Paul Ernest|Ernest, P.]], "A Dialogue on the Ethics of Mathematics", ''The Mathematical Intelligencer'', Vol.38, No.3, (September 2016), pp. 69–77.
* [[James Franklin (philosopher)|Franklin, J.]], [http://web.maths.unsw.edu.au/~jim/matheth.pdf "On the Parallel Between Mathematics and Morals"], ''Philosophy'', Vol.79, No.1, (January 2004), pp. 97–119.
* [http://socialsciences.exeter.ac.uk/education/research/centres/stem/publications/pmej/pome29/Douglas%20Henrich%20%20Mathematical%20EthicsValues%20Valences%20and%20Virtue.doc Henrich, D., "Mathematical Ethics: Values, Valences and Virtue", ''Philosophy of Mathematics Education Journal'', No.29, (July 2015)].
* [https://ww2.amstat.org/publications/JSE/v12n3/lesser.html Lesser, L.M. &amp; Nordenhaug, E., "Ethical statistics and statistical ethics: Making an interdisciplinary module", ''Journal of Statistics Education'', Vol.12, No.3, (November 2004), pp. 50–56].
* [https://www.researchgate.net/profile/David_Levy15/publication/5220992_Inducing_Greater_Transparency_Towards_the_Establishment_of_Ethical_Rules_for_Econometrics/links/0912f506cd1e159e50000000.pdf Levy, D.M. &amp; Peart, S.J., "Inducing Greater Transparency: Towards the Establishment of Ethical Rules for Econometrics", ''Eastern Economic Journal'', Volume 34, Issue 1, (January 2008), pp 103–114].
* [https://nationalethicsresourcecenter.info/resources/452/download/CMJ_Ethics.pdf Shulman, B. J., "Is there enough poison gas to kill the city?: The teaching of ethics in mathematics classes", ''The College Mathematics Journal'', Vol.33, No.2, (March 2002), pp. 128–125].
* [http://scholarworks.gsu.edu/cgi/viewcontent.cgi?article=1054&amp;context=mse_facpub Stinson, D.W., "In Search of Defining Ethics in (Mathematics) Education Research?", ''Journal of Urban Mathematics Education'', Vol.10, No.1, (July 2017), pp. 1–6].
* [https://smw.ch/en/resource/jf/journal/file/view/article/smw.2007.11587/smw.2007.11587.pdf Strasak, A. M, Zaman, Q, Pfeiffer, K. P., Göbel, G. &amp; Ulmer, H., "Statistical errors in medical research — a review of common pitfalls", ''Swiss Medical Weekly'', (2007), 137: 44–49].
*[http://math.arizona.edu/~jwatkins/varmor.pdf Vardeman, S.B. &amp; Morris, M.D., "Statistics and Ethics: Some Advice for Young Statisticians", ''The American Statistician'', Vol.57, No.1, (February 2003), pp. 21–6].
* [https://smw.ch/en/resource/jf/journal/file/view/article/smw.2007.11794/smw.2007.11794.pdf Young, J., "Statistical errors in medical research — a chronic disease?", ''Swiss Medical Weekly'', (2007), 137: 41–43]: editorial commentary (and elaboration) on Strasak, et al. by the ''Swiss Medical Weekly's'' Statistical Advisor.
{{refend}}

==External links==
* [http://cueims.soc.srcf.net/ Cambridge University Ethics in Mathematics Society]
* [http://www.ams.org/about-us/governance/policy-statements/sec-ethics American Mathematical Society: Policy Statement on Ethical Guidelines]
* [http://www.rss.org.uk/RSS/Influencing_Change/Statistics_and_the_law/RSS/Influencing_Change/Current_projects_sub/Statistics_and_the_law.aspx?hkey=e0e099fe-8a21-4e77-883a-bcab1d6ec3cd Royal Statistical Society: Statistics and the Law].

[[Category:Ethics of science and technology]]
[[Category:Philosophy of statistics]]
[[Category:Philosophy of mathematics]]
[[Category:Ethics and statistics]]
[[Category:Business ethics]]
[[Category:Professional ethics]]</text>
      <sha1>4pzh5vri2fjcwjnwdvuhf3tra03sfk3</sha1>
    </revision>
  </page>
  <page>
    <title>Factorial moment generating function</title>
    <ns>0</ns>
    <id>4389572</id>
    <revision>
      <id>753907493</id>
      <parentid>597940824</parentid>
      <timestamp>2016-12-09T20:32:11Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Theory of probability distributions]]; added [[Category:Moment (mathematics)]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2373">{{Refimprove|date=December 2009}}
In [[probability theory]] and [[statistics]], the '''factorial moment generating function''' of the [[probability distribution]] of a [[real number|real-valued]] [[random variable]] ''X'' is defined as 
:&lt;math&gt;M_X(t)=\operatorname{E}\bigl[t^{X}\bigr]&lt;/math&gt;
for all [[complex number]]s ''t'' for which this [[expected value]] exists. This is the case at least for all ''t'' on the [[unit circle]] &lt;math&gt;|t|=1&lt;/math&gt;, see [[characteristic function (probability theory)|characteristic function]]. If&amp;nbsp;''X'' is a discrete random variable taking values only in the set {0,1, ...} of non-negative [[integer]]s, then &lt;math&gt;M_X&lt;/math&gt; is also called [[probability-generating function]] of ''X'' and &lt;math&gt;M_X(t)&lt;/math&gt; is well-defined at least for all ''t'' on the [[closed set|closed]] [[unit disk]] &lt;math&gt;|t|\le1&lt;/math&gt;.

The factorial moment generating function generates the [[factorial moment]]s of the [[probability distribution]].
Provided &lt;math&gt;M_X&lt;/math&gt; exists in a [[neighbourhood (mathematics)|neighbourhood]] of ''t''&amp;nbsp;=&amp;nbsp;1, the ''n''th factorial moment is given by &lt;ref&gt;http://homepages.nyu.edu/~bpn207/Teaching/2005/Stat/Generating_Functions.pdf&lt;/ref&gt;
:&lt;math&gt;\operatorname{E}[(X)_n]=M_X^{(n)}(1)=\left.\frac{\mathrm{d}^n}{\mathrm{d}t^n}\right|_{t=1} M_X(t),&lt;/math&gt;
where the [[Pochhammer symbol]] (''x'')&lt;sub&gt;''n''&lt;/sub&gt; is the [[falling factorial]]
:&lt;math&gt;(x)_n = x(x-1)(x-2)\cdots(x-n+1).\,&lt;/math&gt;
(Many mathematicians, especially in the field of [[special function]]s, use the same notation to represent the [[rising factorial]].)

==Example==
Suppose ''X'' has a [[Poisson distribution]] with [[expected value]] λ, then its factorial moment generating function is
:&lt;math&gt;M_X(t)
=\sum_{k=0}^\infty t^k\underbrace{\operatorname{P}(X=k)}_{=\,\lambda^ke^{-\lambda}/k!}
=e^{-\lambda}\sum_{k=0}^\infty \frac{(t\lambda)^k}{k!} = e^{\lambda(t-1)},\qquad t\in\mathbb{C},
&lt;/math&gt;
(use the [[Exponential_function#Formal_definition|definition of the exponential function]]) and thus we have
:&lt;math&gt;\operatorname{E}[(X)_n]=\lambda^n.&lt;/math&gt;

==See also==
* [[Moment (mathematics)]]
* [[Moment-generating function]]
* [[Cumulant-generating function]]

{{Reflist}}

{{DEFAULTSORT:Factorial Moment Generating Function}}
[[Category:Factorial and binomial topics]]
[[Category:Moment (mathematics)]]
[[Category:Generating functions]]</text>
      <sha1>dbe1oa1czerdlpc9ueku325okpnp2kn</sha1>
    </revision>
  </page>
  <page>
    <title>Farkas' lemma</title>
    <ns>0</ns>
    <id>2480226</id>
    <revision>
      <id>869508096</id>
      <parentid>830067949</parentid>
      <timestamp>2018-11-19T01:54:10Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: issue. Add: chapter-format, chapter-url. Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10604">{{more footnotes|date=October 2011}}

'''Farkas' [[Lemma (mathematics)|lemma]]''' is a solvability  theorem  for a finite system of linear  inequalities  in [[mathematics]]. It was originally proven by the Hungarian mathematician [[Gyula Farkas (natural scientist)|Gyula Farkas]].&lt;ref name=Farkas1902&gt; {{citation | first1 = Julius (Gyula) | last1 = Farkas | author1-link = Gyula Farkas (natural scientist) | year = 1902 | title = Über die Theorie der Einfachen Ungleichungen | url = http://gdz.sub.uni-goettingen.de/en/dms/load/img/?PPN=PPN243919689_0124&amp;DMDID=dmdlog4 | journal = Journal für die Reine und Angewandte Mathematik | volume = 124 | pages = 1–27 | doi = 10.1515/crll.1902.124.1 | issue = 124 }} &lt;/ref&gt;
Farkas' lemma is the key result underpinning the [[linear programming]] duality and has played a central role in the development of [[mathematical optimization]] (alternatively, [[mathematical programming]]). It is used amongst other things in the proof of the [[Karush–Kuhn–Tucker|Karush–Kuhn–Tucker theorem]] in [[nonlinear programming]].

Generalizations of the Farkas' lemma are about the solvability  theorem  for  convex  inequalities,&lt;ref name=Jeyakumar2014&gt; {{Citation| title=Farkas' lemma three decades of generalizations for mathematical optimization | first1=N.|last1=Dinh|author1-link=N. Dinh |first2=V. |last2=Jeyakumar|author2-link=V. Jeyakumar |year=2014 |journal = TOP | volume = 22 | pages = 1–22| doi = 10.1007/s11750-014-0319-y | issue = 1}}&lt;/ref&gt; i.e., infinite system of linear  inequalities. Farkas' lemma belongs to a class of statements called "theorems of the alternative": a theorem stating that exactly one of two systems has a solution.

== Statement of the lemma ==
There are a number of slightly different (but equivalent) formulations of the lemma in the literature. The one given here is due to {{harvtxt|Gale|Kuhn|Tucker|1951}}.
{{math_theorem|name=Farkas' lemma| Let &lt;math&gt;\mathbf{A} \in \mathbb{R}^{m\times n}&lt;/math&gt;  and &lt;math&gt;\mathbf{b} \in \mathbb{R}^{m}&lt;/math&gt; . Then [[Uniqueness quantification|exactly one]] of the following two statements is true:
# There exists an &lt;math&gt;\mathbf{x} \in \mathbb{R}^{n}&lt;/math&gt; such that &lt;math&gt;\mathbf{Ax} = \mathbf{b}&lt;/math&gt; and &lt;math&gt;\mathbf{x} \geq 0&lt;/math&gt;.
# There exists a &lt;math&gt;\mathbf{y} \in \mathbb{R}^{m}&lt;/math&gt; such that &lt;math&gt;\mathbf{A}^{\mathsf{T}}\mathbf{y} \geq 0&lt;/math&gt; and &lt;math&gt;\mathbf{b}^{\mathsf{T}} \mathbf{y}  &lt; 0&lt;/math&gt;. }}
Here, the notation &lt;math&gt;\mathbf{x} \geq 0&lt;/math&gt; means that all components of the vector &lt;math&gt;\mathbf{x}&lt;/math&gt; are nonnegative.  Let the cone generated by the columns of &lt;math&gt;\mathbf{A}&lt;/math&gt; denoted by  &lt;math&gt;C(\mathbf{A})=\{\mathbf{A}\mathbf{x}|\mathbf{x} \geq 0 \}&lt;/math&gt;. Then &lt;math&gt;C(\mathbf{A}) &lt;/math&gt; is a '''closed''' convex cone. The vector &lt;math&gt;\mathbf{x}&lt;/math&gt; proves that &lt;math&gt;\mathbf{b}&lt;/math&gt; lies in &lt;math&gt;C(\mathbf{A})&lt;/math&gt; while the vector &lt;math&gt;\mathbf{y}&lt;/math&gt; gives a linear functional that separates &lt;math&gt;\mathbf{b}&lt;/math&gt; from &lt;math&gt;C(\mathbf{A})&lt;/math&gt;.

Let &lt;math&gt;\mathbf{a}_1,\dots,\mathbf{a}_n \in \mathbb{R}^{m}&lt;/math&gt; denote the columns of &lt;math&gt;\mathbf{A}&lt;/math&gt;. In terms of these vectors, Farkas' lemma states that exactly one of the following two statements is true:
# There exist coefficients &lt;math&gt;x_1,\dots,x_n \in \mathbb{R},x_1,\dots,x_n \geq 0&lt;/math&gt; , such that  &lt;math&gt;\mathbf{b} =x_1\mathbf{a}_1+\dots+x_n \mathbf{a}_n &lt;/math&gt; .
# There exists a vector &lt;math&gt;\mathbf{y} \in \mathbb{R}^{m}&lt;/math&gt;  such that  &lt;math&gt;\mathbf{a}_i^{\mathsf{T}} \mathbf{y} \geq 0 &lt;/math&gt; for &lt;math&gt;i=1,\dots,n &lt;/math&gt;  and &lt;math&gt;\mathbf{b}^{\mathsf{T}} \mathbf{y}  &lt; 0&lt;/math&gt;.

The vectors &lt;math&gt;x_1\mathbf{a}_1+\dots+x_n \mathbf{a}_n &lt;/math&gt; with nonnegative coefficients constitute the [[convex cone]] of the set &lt;math&gt;\{\mathbf{a}_1,\dots,\mathbf{a}_n\}&lt;/math&gt; so the first statement says that &lt;math&gt;\mathbf{b}&lt;/math&gt; is in this cone.

The second statement says that there exists a vector &lt;math&gt;\mathbf{y}&lt;/math&gt;  such that the angle of &lt;math&gt;\mathbf{y}&lt;/math&gt;  with the vectors  &lt;math&gt;\mathbf{a}_i&lt;/math&gt; is at most 90° while the angle of &lt;math&gt;\mathbf{y}&lt;/math&gt;  with the vector &lt;math&gt;\mathbf{b}&lt;/math&gt;  is more than  90°. The hyperplane normal to this vector has the vectors &lt;math&gt;\mathbf{a}_i&lt;/math&gt;  on one side and the vector &lt;math&gt;\mathbf{b}&lt;/math&gt; on the other side. Hence, this hyperplane separates the vectors in the cone of &lt;math&gt;\{\mathbf{a}_1,\dots,\mathbf{a}_n\}&lt;/math&gt; and the vector &lt;math&gt;\mathbf{b}&lt;/math&gt;.

For example, let ''n,m''=2 and ''a''&lt;sub&gt;1&lt;/sub&gt; = (1,0)&lt;sup&gt;T&lt;/sup&gt; and ''a''&lt;sub&gt;2&lt;/sub&gt; = (1,1)&lt;sup&gt;T&lt;/sup&gt;. The convex cone spanned by ''a''&lt;sub&gt;1&lt;/sub&gt; and ''a''&lt;sub&gt;2&lt;/sub&gt; can be seen as a wedge-shaped slice of the first quadrant in the ''x-y'' plane. Now, suppose ''b''&amp;nbsp;=&amp;nbsp;(0,1). Certainly, ''b'' is not in the convex cone ''a''&lt;sub&gt;1&lt;/sub&gt;''x''&lt;sub&gt;1&lt;/sub&gt;+''a''&lt;sub&gt;2&lt;/sub&gt;''x''&lt;sub&gt;2&lt;/sub&gt;. Hence, there must be a separating hyperplane. Let ''y''&amp;nbsp;=&amp;nbsp;(1,−1)&lt;sup&gt;T&lt;/sup&gt;. We can see that ''a''&lt;sub&gt;1&lt;/sub&gt; · ''y'' = 1, ''a''&lt;sub&gt;2&lt;/sub&gt; · ''y'' = 0, and ''b'' · ''y'' = −1. Hence, the hyperplane with normal ''y'' indeed separates the convex cone ''a''&lt;sub&gt;1&lt;/sub&gt;''x''&lt;sub&gt;1&lt;/sub&gt;+''a''&lt;sub&gt;2&lt;/sub&gt;''x''&lt;sub&gt;2&lt;/sub&gt; from ''b''.

== Generalizations ==
{{math_theorem|name=Generalized Farkas' lemma| Let &lt;math&gt;\mathbf{A} \in \mathbb{R}^{m\times n}&lt;/math&gt; , &lt;math&gt;\mathbf{b} \in \mathbb{R}^{m}&lt;/math&gt;, &lt;math&gt; \mathbf{S} &lt;/math&gt; is a closed convex cone in &lt;math&gt; \mathbb{R}^{n}&lt;/math&gt; and the [[dual cone]] of &lt;math&gt; \mathbf{S}&lt;/math&gt; is  &lt;math&gt;\mathbf{S^{*}} =\{ \mathbf{z} \in \mathbb{R}^{n} | \mathbf{z}^{\mathsf{T}} \mathbf{x} \geq 0, \forall \mathbf{x} \in \mathbf{S} \} &lt;/math&gt;. If convex cone &lt;math&gt;C(\mathbf{A})=\{\mathbf{A}\mathbf{x}| \mathbf{x} \in \mathbf{S} \}&lt;/math&gt; is  closed, then exactly one of the following two statements is true:
# There exists an &lt;math&gt;\mathbf{x} \in \mathbb{R}^{n}&lt;/math&gt; such that &lt;math&gt;\mathbf{Ax} = \mathbf{b}&lt;/math&gt; and &lt;math&gt;\mathbf{x} \in \mathbf{S} &lt;/math&gt;.
# There exists a &lt;math&gt;\mathbf{y} \in \mathbb{R}^{m}&lt;/math&gt; such that &lt;math&gt;\mathbf{A}^{\mathsf{T}} \mathbf{y} \in \mathbf{S^{*}} &lt;/math&gt; and &lt;math&gt;\mathbf{b}^{\mathsf{T}} \mathbf{y}  &lt; 0&lt;/math&gt;. }}

Generalized Farkas' lemma can be interpreted geometrically as follows: a vector is either in a given closed [[cone (linear algebra)|convex cone]] or that there exists a [[hyperplane]] separating the vector from the cone—there are no other possibilities. The closedness condition is necessary, see '''Separation theorem I''' in [[Hyperplane separation theorem]]. For original Farkas' lemma, &lt;math&gt; \mathbf{S} &lt;/math&gt; is the nonnegative orthant  &lt;math&gt;\mathbb{R}_{+}^{n}&lt;/math&gt;, hence the closedness condition holds automatically. Indeed, for polyhedral convex cone, i.e., there  exists a &lt;math&gt;\mathbf{B} \in \mathbb{R}^{n\times k}&lt;/math&gt;  such  that  &lt;math&gt; \mathbf{S}=\{\mathbf{B}\mathbf{x}|\mathbf{x} \in \mathbb{R}_{+}^{k} \} &lt;/math&gt;, the closedness condition holds automatically. In [[convex optimization]], various kinds of constraint qualification, e.g. [[Slater's condition]], are responsible for closedness of the underlying convex cone &lt;math&gt;C(\mathbf{A}) &lt;/math&gt;. 

By setting &lt;math&gt; \mathbf{S} =\mathbb{R}^{n}&lt;/math&gt; and &lt;math&gt;\mathbf{S^{*}}=\{0\}&lt;/math&gt;  in Generalized Farkas' lemma, we obtain the following corollary about the solvability for a finite system of linear equalities. 
{{math_theorem|name=Corollary| Let &lt;math&gt;\mathbf{A} \in \mathbb{R}^{m\times n}&lt;/math&gt; and &lt;math&gt;\mathbf{b} \in \mathbb{R}^{m}&lt;/math&gt;. Then exactly one of the following two statements is true:
# There exists an &lt;math&gt;\mathbf{x} \in \mathbb{R}^{n}&lt;/math&gt; such that &lt;math&gt;\mathbf{Ax} = \mathbf{b}&lt;/math&gt;.
# There exists a &lt;math&gt;\mathbf{y} \in \mathbb{R}^{m}&lt;/math&gt; such that &lt;math&gt;\mathbf{A}^{\mathsf{T}}\mathbf{y} = 0 &lt;/math&gt; and &lt;math&gt;\mathbf{b}^{\mathsf{T}}\mathbf{y}  \neq 0&lt;/math&gt;. }}


== Further implications ==
Farkas's lemma can be varied to many further theorems of alternative by simple modifications, such as [[Gordan's theorem]]: Either &lt;math&gt;Ax &lt; 0&lt;/math&gt; has a solution ''x'', or &lt;math&gt;A^{\mathsf{T}} y = 0 &lt;/math&gt; has a nonzero solution ''y'' with ''y'' ≥ 0.

Common applications of Farkas' lemma include proving the strong and weak duality theorem associated with linear programming, game theory at a basic level and the [[Kuhn–Tucker conditions|Kuhn–Tucker]] constraints. An extension of Farkas' lemma can be used to analyze the strong duality conditions for and construct the dual of a semidefinite program. It is sufficient to prove the existence of the Kuhn–Tucker constraints using the [[Fredholm alternative]] but for the condition to be necessary, one must apply Von Neumann's [[minimax theorem]] to show the equations derived by Cauchy are not violated.

A particularly suggestive and easy-to-remember version is the following: if a set of inequalities has no solution, then a contradiction can be produced from it by linear combination with nonnegative coefficients.  In formulas: if &lt;math&gt;Ax&lt;/math&gt; ≤ &lt;math&gt;b&lt;/math&gt; is unsolvable then &lt;math&gt;y^{\mathsf{T}} A = 0&lt;/math&gt;, &lt;math&gt;y^{\mathsf{T}} b = -1&lt;/math&gt;, &lt;math&gt;y&lt;/math&gt; ≥ &lt;math&gt;0&lt;/math&gt; has a solution.&lt;ref&gt;{{Citation|title=Convex Optimization|first1=Stephen P.|last1=Boyd|first2=Lieven|last2=Vandenberghe|year=2004|publisher=Cambridge University Press|isbn=978-0-521-83378-3|chapter-url=http://www.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf|chapter-format=pdf|accessdate=October 15, 2011|chapter=Section 5.8.3}}&lt;/ref&gt; (Note that &lt;math&gt;y^{\mathsf{T}} A&lt;/math&gt; is a combination of the left hand sides, &lt;math&gt;y^{\mathsf{T}} b&lt;/math&gt; a combination of the right hand side of the inequalities.  Since the positive combination produces a zero vector on the left and a −1 on the right, the contradiction is apparent.)

== See also ==
* [[Hyperplane separation theorem]]

== Notes ==
{{reflist}}
== References ==
* {{citation|first = R. T. |last=Rockafellar|author-link=R. T. Rockafellar|title=Convex Analysis|publisher= Princeton University Press|year=1979 |page=200}}

* {{citation|first1=David|last1=Gale|author1-link=David Gale|first2=Harold|last2=Kuhn|author2-link=Harold Kuhn|first3=Albert W.|last3=Tucker|author3-link=Albert W. Tucker|chapter= Linear Programming and the Theory of Games - Chapter XII|title= Activity Analysis of Production and Allocation|editor =Koopmans|publisher= Wiley |year=1951|chapter-url = http://cowles.econ.yale.edu/P/cm/m13/m13-19.pdf }}.  See Lemma 1 on page 318.


[[Category:Lemmas]]
[[Category:Convex analysis]]
[[Category:Linear programming]]</text>
      <sha1>7xphmh73auoh9lv57hzwkexy5azi1ba</sha1>
    </revision>
  </page>
  <page>
    <title>French curve</title>
    <ns>0</ns>
    <id>387931</id>
    <revision>
      <id>866650568</id>
      <parentid>866650220</parentid>
      <timestamp>2018-10-31T17:27:06Z</timestamp>
      <contributor>
        <username>Pbsouthwood</username>
        <id>10044298</id>
      </contributor>
      <comment>/* See also */ convert to annotated links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2480">{{short description|Template made from metal, wood or plastic composed segments of smooth curves}}
A '''French curve''' is a template usually made from [[metal]], [[wood]] or [[plastic]] composed of many different [[curve]]s. It is used in manual [[Technical drawing|drafting]] to draw smooth curves of varying radii. The shapes are segments of the [[Euler spiral]] or clothoid curve. The curve is placed on the drawing material, and a [[pencil]], [[knife]] or other implement is traced around its curves to produce the desired result.

== Modern successors ==
As modern computer-aided design ([[Computer-aided design|CAD]]) systems use vector-based graphics to achieve a precise [[radius]], mechanical templates (and most [[Technical_drawing|mechanical drawing]] techniques) have become obsolete.  Digital computers can also be used to generate a set of coordinates that accurately describe an arbitrary curve, and the points can be connected with line segments to approximate the curve with a high degree of accuracy.  Some computer-graphics systems make use of [[Bézier curve]]s, which allow a curve to be bent in real time on a display screen to follow a set of coordinates, much in the way a French curve would be placed on a set of three or four points on paper.
&lt;gallery&gt;
File:Krzywiki.jpg|French curves
File:L-Zeichnen2.png|A complete [[Ludwig Burmester|Burmester]] set from the ''[[Lexikon der gesamten Technik]]'' (1904)
File:Curve stencils.jpg|This set of the three most common French curves is also known as a [[Ludwig Burmester|Burmester]] set. The one on the far left side is most commonly used for [[hyperbolas]]; the smaller one on the far right side is suited for [[ellipse]]s. The large one below is used most for [[parabolas]].&lt;ref&gt;{{cite web | url = http://www.daube.ch/docu/glossary/drawingtools.html#french_curves | title = Drawing tools – French curves}}&lt;/ref&gt;
&lt;/gallery&gt;

==See also==
*{{annotated link|Flat spline}}
*{{annotated link|Lesbian rule}}
*{{annotated link|Ruler}}
*{{annotated link|Technical drawing tool}}

==References==
{{reflist}}

==External links==
* Weisstein, Eric W. ''[http://mathworld.wolfram.com/FrenchCurve.html French Curve]'' from MathWorld.
* ''[https://web.archive.org/web/20061129051244/http://www.tpub.com/content/engineering/14069/css/14069_92.htm Use of the French Curve]'' from Integrated Publishing.

{{Measuring and alignment tools}}

[[Category:Technical drawing]]
[[Category:Curves]]
[[Category:Mathematical tools]]</text>
      <sha1>sgqnpik2yicp4qf68tr48n32s0j1kqf</sha1>
    </revision>
  </page>
  <page>
    <title>Gauss's lemma (polynomial)</title>
    <ns>0</ns>
    <id>2310971</id>
    <revision>
      <id>860910722</id>
      <parentid>860910443</parentid>
      <timestamp>2018-09-23T22:22:14Z</timestamp>
      <contributor>
        <ip>70.53.111.228</ip>
      </contributor>
      <comment>Fixed grammar</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16974">{{About|Gauss's lemma for polynomials||Gauss's lemma (disambiguation)}}
{{Refimprove|date=December 2009}}

In [[algebra]], in the theory of [[polynomial]]s (a subfield of [[Ring (mathematics)|ring theory]]), '''Gauss's lemma''' is either of two related statements about polynomials with integer coefficients:
* The first result states that the product of two primitive polynomials is primitive (a polynomial with integer coefficients is called ''primitive'' if the [[Content (algebra)|greatest common divisor of its coefficients]] is ''1'').
* The second result states that if a non-constant polynomial with integer [[coefficient]]s is [[irreducible polynomial|irreducible]] over the integers, then it is also irreducible if it is considered as a polynomial over the [[Rational number|rationals]].

This second statement is a consequence of the first (see proof below). The first statement and proof of the lemma are in Article 42 of [[Carl Friedrich Gauss]]'s ''[[Disquisitiones Arithmeticae]]'' (1801). These statements have several generalizations described below.

== Primitive and irreducible polynomials ==

The notion of '''primitive polynomial''' used here (which differs from the [[primitive polynomial (field theory)|notion with the same name]] in the context of finite fields) is defined in any [[polynomial ring]] ''R''[''X''] where ''R'' is a [[commutative ring]]: a polynomial ''P'' in ''R''[''X''] is primitive if the only elements of ''R'' that divide all coefficients of ''P'' at once are the invertible elements of ''R''. In the case where ''R'' is the ring '''Z''' of the integers, this is equivalent to the condition that no [[prime number]] divides all the coefficients of ''P''. The notion of [[irreducible element]] is defined in any [[integral domain]]: an element is irreducible if it is not invertible and cannot be written as a product of two non-invertible elements. If ''R'' is an integral domain then so is the polynomial ring ''R''[''X''] because the leading coefficient of product of non-zero polynomials in ''R''[''X''] is equal to the product of their leading coefficients, hence is nonzero. A non-constant irreducible polynomial in ''R''[''X''] is one that is not a product of two non-constant polynomials ''and'' which is primitive (because being primitive excludes precisely non-invertible constant polynomials as factors). Note that an irreducible element of ''R'' is still irreducible when viewed as constant polynomial in ''R''[''X'']; this explains the need for "non-constant" above, and in the irreducibility statements below.

== Version valid over integers ==

The two properties of polynomials with integer coefficients can now be formulated formally as follows:

'''Primitivity statement:''' The set of primitive polynomials in '''Z'''[''X''] is [[Closure (mathematics)|closed]] under multiplication: if ''P'' and ''Q'' are primitive polynomials then so is their product ''PQ''.

'''Proof:''' Suppose the product of two primitive polynomials ''f''(''x'') and ''g''(''x'') is not primitive, so there exists a prime number ''p'' that is a common divisor of all the coefficients of the product. But since ''f''(''x'') and ''g''(''x'') are primitive, ''p'' cannot divide either all the coefficients of ''f''(''x'') or all those of ''g''(''x'').  Let ''a&lt;sub&gt;r&lt;/sub&gt;x&lt;sup&gt;r&lt;/sup&gt;'' and ''b&lt;sub&gt;s&lt;/sub&gt;x&lt;sup&gt;s&lt;/sup&gt;'' be the first (i.e., highest degree) terms with a coefficient not divisible by ''p'', respectively in ''f''(''x'') and in ''g''(''x''). Now consider the coefficient of ''x&lt;sup&gt;r+s&lt;/sup&gt;'' in the product.  Its value is given by {{nowrap|∑''a&lt;sub&gt;i&lt;/sub&gt;b&lt;sub&gt;j&lt;/sub&gt;''}}, where the sum runs over all pairs of indices ''i,j'' such that {{nowrap|''i'' + ''j'' {{=}} ''r'' + ''s''}}. This sum contains a term ''a''&lt;sub&gt;''r''&lt;/sub&gt;''b''&lt;sub&gt;''s''&lt;/sub&gt; which is not divisible by ''p'' (by [[Euclid's lemma]], because ''p'' is prime), yet all the remaining ones are (because either {{nowrap|''i'' &amp;lt; ''r''}} or {{nowrap|''j'' &amp;lt; ''s''}}), so the entire sum is not divisible by ''p''. But by assumption ''all'' coefficients in the product are divisible by ''p'', leading to a contradiction. Therefore, the coefficients of the product can have no common divisor and the product is primitive. This completes the proof.

Alternatively the statement can be proved as a special case of more general results given below.

'''Irreducibility statement:''' A non-constant polynomial in '''Z'''[''X''] is irreducible in '''Z'''[''X''] if and only if it is both irreducible in '''Q'''[''X''] and primitive in '''Z'''[''X''].

This is a special case for {{nowrap|''R'' {{=}} '''Z'''}} of more general irreducibility statement [[#Version valid over any GCD domain|proved below]].

The second result implies that if a polynomial with integer coefficients can be [[Factorization of polynomials|factored]] over the rational numbers, then there exists a factorization over the integers. This fact is often useful when combined with results such as [[Eisenstein's criterion]].

An application is the [[rational root theorem]].

The second result also implies that the [[Minimal polynomial (field theory)|minimal polynomial]] over the rational numbers of an [[algebraic integer]] has integer coefficients.

== Version valid over any GCD domain ==

Gauss's lemma holds more generally over arbitrary [[GCD domain]]s. There the ''[[content (algebra)|content]]'' {{math|''c''(''P'')}} of a polynomial {{math|''P''}} can be defined as the [[greatest common divisor]] of the coefficients of {{math|''P''}} (like the gcd, the content is actually a class of [[associate elements]]).

'''Primitivity statement:''' If ''R'' is a GCD domain, then the set of primitive polynomials in {{math|''R''[''X'']}} is closed under multiplication. More generally, the content of a product {{math|''ST''}} of polynomials is the product {{math|''c''(''S'')''c''(''T'')}} of their contents.

'''Proof:'''&lt;ref&gt;Adapted from: {{cite book |first=R. |last=Mines |first2=F. |last2=Richman |first3=W. |last3=Ruitenburg |title=A Course in Constructive Algebra |series=Universitext |publisher=Springer-Verlag |year=1988 |isbn=0-387-96640-4 }}&lt;/ref&gt; The latter part follows from the former since {{math|''c''(''S'')''c''(''T'')}} is certainly a common divisor of the coefficients of the product, so one can divide by {{math|''c''(''S'')}} and {{math|''c''(''T'')}} to reduce  {{math|''S''}} and {{math|''T''}} to primitive polynomials. For the proof of the former part we proceed by induction on the total number of nonzero terms of {{math|''S''}} and {{math|''T''}} combined. If one of the polynomials has at most one term, the result is obvious; this covers in particular all cases with fewer than 4 nonzero terms. So let both {{math|''S''}} and {{math|''T''}} have at least 2 terms, and assume the result established for any smaller combined number of terms. By dividing {{math|''S''}} by {{math|''c''(''S'')}} and {{math|''T''}} by {{math|''c''(''T'')}}, we reduce to the case {{math|''c''(''S'') {{=}} ''c''(''T'') {{=}} 1}}. If the content {{math|''c'' {{=}} ''c''(''ST'')}} is not invertible, it has a non-trivial divisor in common with the leading coefficient of at least one of {{math|''S''}} and {{math|''T''}} (since it divides their product, which is the leading coefficient of {{math|''ST''}}). Suppose by symmetry that this is the case for {{math|''S''}}, let {{math|''L''}} be the leading term of {{math|''S''}}, and let {{math|''d'' {{=}} gcd(''c'',''c''(''L''))}} be the mentioned common divisor (here the content {{math|''c''(''L'')}} of {{math|''L''}} is just its unique coefficient). Since {{math|''d''}} is a common divisor of {{math|''ST''}} and {{math|''LT''}}, it also divides {{math|(''S'' − ''L'')''T''}}, in other words it divides its content, which by induction (since {{math|''S'' − ''L''}} has fewer terms than {{math|''S''}}) is {{math|''c''(''S'' − ''L'')''c''(''T'') {{=}} ''c''(''S'' − ''L'')}}. As {{math|''d''}} also divides {{math|''c''(''L'')}}, it divides {{math|''c''(''S'') {{=}} 1}}, which gives a contradiction; therefore {{math|''c''(''ST'')}} is invertible (and can be taken to be&amp;nbsp;1).

'''Irreducibility statement:''' Let ''R'' be a GCD domain and ''F'' its [[field of fractions]]. A non-constant polynomial in ''R''[''X''] is irreducible in ''R''[''X''] if and only if it is both irreducible in ''F''[''X''] and primitive in ''R''[''X''].

'''Proof:''' As mentioned above a non-constant polynomial is irreducible in ''R''[''X''] if and only if it is primitive and not a product of two non-constant polynomials in ''R''[''X'']. Being irreducible in ''F''[''X''] certainly excludes the latter possibility (since those non-constant polynomials would remain non-invertible in ''F''[''X'']), so the essential point left to prove is that if ''P'' is non-constant and irreducible in ''R''[''X''] then it is irreducible in ''F''[''X'']. Note first that in ''F''[''X'']\{0} any class of associate elements (whose elements are related by multiplication by nonzero elements of the field ''F'') meets the set of primitive elements in ''R''[''X'']: starting from an arbitrary element of the class, one can first (if necessary) multiply by a nonzero element of ''R'' to enter into the subset ''R''[''X''] (removing denominators), then divide by the greatest common divisor of all coefficients to obtain a primitive polynomial. Now assume that ''P'' is reducible in ''F''[''X''], so {{nowrap|''P'' {{=}} ''ST''}} with ''S'',''T'' non-constant polynomials in ''F''[''X'']. One can replace ''S'' and ''T'' by associate primitive elements ''S′'', ''T′'', and obtain {{nowrap|''P'' {{=}} α''S′T′''}} for some nonzero α in ''F''. But ''S′T′'' is primitive in ''R''[''X''] by the primitivity statement, so α must lie in ''R'' (if α is written as a fraction ''a/b'', then ''b'' has to divide all coefficients of ''aS′T′'', so ''b'' divides ''c''(''aS′T′'') = ''a'', which means α = ''a/b'' is in ''R'') and the decomposition {{nowrap|''P'' {{=}} α''S′T′''}} contradicts the irreducibility of ''P'' in ''R''[''X''].

The condition that ''R'' is a GCD domain is not superfluous because it implies that every irreducible element of this ring is also a [[prime element]], which in turn implies that every nonzero element of ''R'' has at most one factorization into a product of irreducible elements and a unit up to order and associate relationship. In a ring where factorization is not unique, say {{math|''pa'' {{=}} ''qb''}} with ''p'' and ''q'' irreducible elements that do not divide any of the factors on the other side, the product {{math|(''p'' + ''qX'')(''a'' + ''qX'') {{=}} ''pa'' + (''p''+''a'')''qX'' + ''q&lt;sup&gt;2&lt;/sup&gt;X&lt;sup&gt;2&lt;/sup&gt;'' {{=}} ''q''(''b'' + (''p''+''a'')''X'' + ''qX&lt;sup&gt;2&lt;/sup&gt;'')}} shows the failure of the primitivity statement. For a concrete example one can take {{math|''R'' {{=}} '''Z'''[''i''√''5'']}}, {{math|''p'' {{=}} ''1'' + ''i''√''5''}}, {{math|''a'' {{=}} ''1'' - ''i''√''5''}}, {{math|''q'' {{=}} ''2''}}, {{math|''b'' {{=}} ''3''}}. In this example the polynomial {{math|''3'' + ''2X'' + ''2X&lt;sup&gt;2&lt;/sup&gt;''}} (obtained by dividing the right hand side by {{math|''q'' {{=}} ''2''}}) provides an example of the failure of the irreducibility statement (it is irreducible over ''R'', but reducible over its field of fractions {{math|'''Q'''[''i''√''5'']}}). Another well known example is the polynomial {{math|''X&lt;sup&gt;2&lt;/sup&gt;'' − ''X'' − ''1''}}, whose roots are the [[golden ratio]] {{math|φ {{=}} (''1'' + √''5'')/''2''}} and its conjugate {{math|(''1'' − √''5'')/''2''}} showing that it is reducible over the field {{math|'''Q'''[√''5'']}}, although it is irreducible over the non-UFD {{math|'''Z'''[√''5'']}} which has {{math|'''Q'''[√''5'']}} as field of fractions. In  the latter example the ring can be made into an UFD by taking its [[integral closure]] {{math|'''Z'''[φ]}} in {{math|'''Q'''[√''5'']}} (the ring of [[Dirichlet integers]]), over which {{math|''X&lt;sup&gt;2&lt;/sup&gt;'' − ''X'' − ''1''}} becomes reducible, but in the former example ''R'' is already integrally closed.

In the special case when ''R'' is [[unique factorization domain]] (UFD), the primitivity statement can be proved more easily:

'''Proof:''' Let ''S'',''T'' be primitive polynomials in ''R''[''X''], and assume that their product ''ST'' is not primitive, so that some non-invertible element ''d'' of ''R'' divides all coefficients of ''ST''. There is some irreducible element ''p'' of ''R'' that divides ''d'' (this is where we use that ''R'' is UFD, if ''R'' was only GCD domain then such element wouldn't necessarily exist), and it is also a prime element in ''R'' (since ''R'' is GCD domain). Then the [[principal ideal]] ''pR'' generated by ''p'' is a [[prime ideal]], so ''R''/''pR'' is an integral domain, and (''R''/''pR'')[''X''] is therefore an integral domain as well (because nonzero polynomials over an integral domain cannot be [[zero divisor]]s by consideration of the [[leading coefficient]] of their product). By hypothesis the projection ''R''[''X'']→(''R''/''pR'')[''X''] sends ''ST'' to 0, and since this is the product of the projections of ''S'' and ''T'' (projection is a [[ring homomorphism]]), at least one of those projections is 0 (here one uses that (''R''/''pR'')[''X''] is an integral domain). But this means that ''p'' divides all of the coefficients either of ''S'' or of ''T'', which contradicts its assumed primitivity.

This special case is also sufficient in many applications. For example both primitivity and irreducibility statement for UFD are essential in proving that if ''R'' is UFD, then so is ''R''[''X''] (and by an immediate induction, so is the [[polynomial ring]] over ''R'' in any number of indeterminates). Any factorization of a polynomial ''P'' in ''R''[''X''] can be split into its irreducible factors that are contained in ''R'' (the "constant" factors) and those that are not. The primitivity statement implies that the product ''Q'' of the latter (non-constant) irreducible factors is primitive, so the product of the former (constant) factors give the content ''c''(''P'') of ''P''. This reduces proving uniqueness of factorizations to proving it individually for ''c''(''P'') and for ''Q''. Since the factorization of ''c''(''P'') takes place in ''R'', it is unique by assumption. By the irreducibility statement, the irreducible factors that occur in any factorization of ''Q'' in ''R''[''X''] are primitive representatives of irreducible factors in a factorization of ''Q'' in ''F''[''X'']. But the latter is unique since ''F''[''X''] is a [[principal ideal domain]] and therefore a unique factorization domain. Together this shows that the factorization of ''P'' in ''R''[''X''] is unique.

== Version valid over arbitrary commutative ring ==

As explained above, neither primitivity nor irreducibility statement of Gauss's lemma is valid over general integral domains. However there is a variation of the first statement that is valid even for polynomials over any commutative ring ''R'', which replaces primitivity by the stronger property of co-maximality. Call a polynomial ''P'' in ''R''[''X''] ''co-maximal'' if the ideal of ''R'' generated by the coefficients of the polynomial is the full ring ''R''. Clearly every co-maximal polynomial in ''R''[''X''] is primitive. If ''R'' is a [[Bézout domain]] (so in particular if it's a principal ideal domain) then also every primitive polynomial in ''R'' is co-maximal. However co-maximality is often much more restrictive condition than primitivity even when ''R'' is a UFD. For example let ''k'' be a field and {{nowrap|''R'' {{=}} ''k''[''Y,Z'']}}, which is a UFD as explained above. Then the polynomial {{nowrap|''P'' {{=}} ''Y'' + ''ZX''}} is primitive but not co-maximal in ''R''[''X''] because the ideal {{nowrap|(''Y,Z'')}} in ''R'' generated by the coefficients of ''P'' is proper (primitivity simply means that this ideal isn't contained in any proper principal ideal). We have the following variation of Gauss's lemma:

'''Co-maximality statement:''' Let ''R'' be a commutative ring. Then the product of two co-maximal polynomials in ''R''[''X''] is co-maximal.

'''Proof:''' Let ''S'',''T'' be co-maximal polynomials in ''R''[''X''], and assume that their product ''ST'' is not co-maximal. Then its coefficients generate a proper ideal ''I'', which by [[Krull's theorem]] (which depends on the [[axiom of choice]]) is contained in a [[maximal ideal]] ''m'' of ''R''. Then ''R''/''m'' is a field, and (''R''/''m'')[''X''] is therefore an integral domain. By hypothesis the projection ''R''[''X'']→(''R''/''m'')[''X''] sends ''ST'' to 0, thus also at least one of ''S'',''T'' individually, which means that its coefficients all lie in ''m'', which contradicts the fact that they generate the whole ring as an ideal.

== Notes ==
{{Reflist}}

{{DEFAULTSORT:Gauss's Lemma (Polynomial)}}
[[Category:Polynomials]]
[[Category:Lemmas]]</text>
      <sha1>ith4v2y9iatsdvqvllkc1ik006r3o3v</sha1>
    </revision>
  </page>
  <page>
    <title>Gaussian binomial coefficient</title>
    <ns>0</ns>
    <id>1353729</id>
    <revision>
      <id>862709142</id>
      <parentid>856347330</parentid>
      <timestamp>2018-10-06T05:18:42Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15147">In [[mathematics]], the '''Gaussian binomial coefficients''' (also called '''Gaussian coefficients''', '''Gaussian polynomials''', or '''''q''-binomial coefficients''') are [[q-analog|''q''-analog]]s of the [[binomial coefficients]]. The Gaussian binomial coefficient &lt;math&gt;\textstyle\binom nk_q&lt;/math&gt; is a polynomial in ''q'' with integer coefficients, whose value when ''q'' is set to a prime power counts the number of subspaces of dimension ''k'' in a vector space of dimension ''n'' over a finite field with ''q'' elements.

==Definition==

The Gaussian binomial coefficients are defined by

:&lt;math&gt;{m \choose r}_q
= \begin{cases}
\frac{(1-q^m)(1-q^{m-1})\cdots(1-q^{m-r+1})} {(1-q)(1-q^2)\cdots(1-q^r)} &amp; r \le m \\
0 &amp; r&gt;m \end{cases}&lt;/math&gt;

where ''m'' and ''r'' are non-negative integers. For {{nowrap|''r'' {{=}} 0}} the value is 1 since numerator and denominator are both [[empty product]]s. Although the formula in the first clause appears to involve a [[rational function]], it actually designates a polynomial, because the division is exact in '''Z'''&lt;nowiki&gt;[&lt;/nowiki&gt;''q''&lt;nowiki&gt;]&lt;/nowiki&gt;. Note that the formula can be applied for {{nowrap|''r'' {{=}} ''m'' + 1}}, and gives 0 due to a factor {{nowrap|1 − ''q''&lt;sup&gt;0&lt;/sup&gt; {{=}} 0}} in the numerator, in accordance with the second clause (for even larger ''r'' the factor 0 remains present in the numerator, but its further factors would involve negative powers of ''q'', whence explicitly stating the second clause is preferable). All of the factors in numerator and denominator are divisible by {{nowrap|1 − ''q''}}, with as quotient a [[Q-analog#Introductory examples|''q'' number]]:
:&lt;math&gt;[k]_q=\sum_{0\leq i&lt;k}q^i=1+q+q^2+\cdots+q^{k-1}=
\begin{cases}
\frac{1-q^k}{1-q} &amp; \text{for} &amp; q \neq 1 \\
k &amp; \text{for} &amp; q = 1 
\end{cases},&lt;/math&gt;
dividing out these factors gives the equivalent formula
:&lt;math&gt;{m \choose r}_q=\frac{[m]_q[m-1]_q\cdots[m-r+1]_q}{[1]_q[2]_q\cdots[r]_q}\quad(r\leq m),&lt;/math&gt;
which makes evident the fact that substituting {{nowrap|''q'' {{=}} 1}} into &lt;math&gt;\tbinom mr_q&lt;/math&gt; gives the ordinary binomial coefficient &lt;math&gt;\tbinom mr.&lt;/math&gt; In terms of the [[Q-analog#Introductory examples|''q'' factorial]] &lt;math&gt;[n]_q!=[1]_q[2]_q\cdots[n]_q&lt;/math&gt;, the formula can be stated as
:&lt;math&gt;{m \choose r}_q=\frac{[m]_q!}{[r]_q!\,[m-r]_q!}\quad(r\leq m),&lt;/math&gt;
a compact form (often given as only definition), which however hides the presence of many common factors in numerator and denominator. This form does make obvious the symmetry &lt;math&gt;\tbinom mr_q=\tbinom m{m-r}_q&lt;/math&gt; for {{nowrap|''r'' ≤ ''m''}}.

Unlike the ordinary binomial coefficient, the Gaussian binomial coefficient has finite values for &lt;math&gt;m\rightarrow \infty&lt;/math&gt; (the limit being analytically meaningful for |''q''|&amp;lt;1):

:&lt;math&gt;{\infty \choose r}_q = \lim_{m\rightarrow \infty} {m \choose r}_q = \frac{1}{[r]_q!\,(1-q)^r}&lt;/math&gt;

==Examples==

:&lt;math&gt;{0 \choose 0}_q = {1 \choose 0}_q = 1&lt;/math&gt;

:&lt;math&gt;{1 \choose 1}_q = \frac{1-q}{1-q}=1&lt;/math&gt;

:&lt;math&gt;{2 \choose 1}_q = \frac{1-q^2}{1-q}=1+q&lt;/math&gt;

:&lt;math&gt;{3 \choose 1}_q = \frac{1-q^3}{1-q}=1+q+q^2&lt;/math&gt;

:&lt;math&gt;{3 \choose 2}_q = \frac{(1-q^3)(1-q^2)}{(1-q)(1-q^2)}=1+q+q^2&lt;/math&gt;

:&lt;math&gt;{4 \choose 2}_q = \frac{(1-q^4)(1-q^3)}{(1-q)(1-q^2)}=(1+q^2)(1+q+q^2)=1+q+2q^2+q^3+q^4&lt;/math&gt;

==Combinatorial description==

Instead of these algebraic expressions, one can also give a combinatorial definition of Gaussian binomial coefficients. The ordinary binomial coefficient &lt;math&gt;\tbinom mr&lt;/math&gt; counts the {{math|''r''}}-[[combination]]s chosen from an {{math|''m''}}-element set. If one takes those {{math|''m''}} elements to be the different character positions in a word of length {{math|''m''}}, then each {{math|''r''}}-combination corresponds to a word of length {{math|''m''}} using an alphabet of two letters, say {{math|{0,1},}} with {{math|''r''}} copies of the letter 1 (indicating the positions in the chosen combination) and {{math|''m'' − ''r''}} letters 0 (for the remaining positions).

The &lt;math&gt;{4 \choose 2} = 6&lt;/math&gt; words using 0s and 1s would be 0011, 0101, 0110, 1001, 1010, 1100.

To obtain from this model the Gaussian binomial coefficient &lt;math&gt;\tbinom mr_q&lt;/math&gt;, it suffices to count each word with a factor {{math|''q''&lt;sup&gt;''d''&lt;/sup&gt;}}, where {{math|''d''}} is the number of "inversions" of the word: the number of pairs of positions for which the leftmost position of the pair holds a letter 1 and the rightmost position holds a letter 0 in the word. For example, there is one word with 0 inversions, 0011. There is 1 with only a single inversion, 0101. There are two words with 2 inversions, 0110, and 1001. There is one with 3, 1010, and finally one word with 4 inversions, 1100. This corresponds to the coefficients in &lt;math&gt;{4 \choose 2}_q = 1+q+2q^2+q^3+q^4&lt;/math&gt;.

It can be shown that the polynomials so defined satisfy the Pascal identities given below, and therefore coincide with the polynomials given by the algebraic definitions. A visual way to view this definition is to associate to each word a path across a rectangular grid with sides of height  {{math|''r''}} and width {{math|''m'' − ''r''}}, from the bottom left corner to the top right corner, taking a step right for each letter 0 and a step up for each letter 1. Then the number of inversions of the word equals the area of the part of the rectangle that is to the bottom-right of the path.

==Properties==
Like the ordinary binomial coefficients, the Gaussian binomial coefficients are center-symmetric, i.e., invariant under the reflection &lt;math&gt; r \rightarrow m-r &lt;/math&gt;:

:&lt;math&gt;{m \choose r}_q = {m \choose m-r}_q. &lt;/math&gt;

In particular,

:&lt;math&gt;{m \choose 0}_q ={m \choose m}_q=1 \, ,&lt;/math&gt;

:&lt;math&gt;{m \choose 1}_q ={m \choose m-1}_q=\frac{1-q^m}{1-q}=1+q+ \cdots + q^{m-1} \quad m \ge 1 \, .&lt;/math&gt;

The name ''Gaussian binomial coefficient'' stems from the fact{{citation needed|date=February 2014}} that their evaluation at {{nowrap|''q'' {{=}} 1}} is

:&lt;math&gt;\lim_{q \to 1} {m \choose r}_q = {m \choose r}&lt;/math&gt;

for all ''m'' and ''r''.

The analogs of [[Pascal's triangle|Pascal identities]] for the Gaussian binomial coefficients are

:&lt;math&gt;{m \choose r}_q = q^r {m-1 \choose r}_q + {m-1 \choose r-1}_q&lt;/math&gt;

and

:&lt;math&gt;{m \choose r}_q = {m-1 \choose r}_q + q^{m-r}{m-1 \choose r-1}_q.&lt;/math&gt;

There are analogs of the binomial formula, and of Newton's generalized version of it for negative integer exponents, although for the former the Gaussian binomial coefficients themselves do not appear as coefficients:

:&lt;math&gt;\prod_{k=0}^{n-1} (1+q^kt)=\sum_{k=0}^n q^{k(k-1)/2} 
{n \choose k}_q t^k &lt;/math&gt;

and

:&lt;math&gt;\prod_{k=0}^{n-1} \frac{1}{(1-q^kt)}=\sum_{k=0}^\infty  
{n+k-1 \choose k}_q t^k. &lt;/math&gt;

which, for &lt;math&gt;n\rightarrow\infty&lt;/math&gt; become:

:&lt;math&gt;\prod_{k=0}^{\infty} (1+q^kt)=\sum_{k=0}^\infty \frac{q^{k(k-1)/2}t^k}{[k]_q!\,(1-q)^k}  &lt;/math&gt;

and

:&lt;math&gt;\prod_{k=0}^\infty \frac{1}{(1-q^kt)}=\sum_{k=0}^\infty  
\frac{t^k}{[k]_q!\,(1-q)^k} . &lt;/math&gt;

The first Pascal identity allows one to compute the Gaussian binomial coefficients recursively (with respect to ''m'' ) using the initial "boundary" values

:&lt;math&gt;{m \choose m}_q ={m \choose 0}_q=1 &lt;/math&gt;

and also incidentally shows that the Gaussian binomial coefficients are indeed polynomials (in ''q''). The second Pascal identity follows from the first using the substitution &lt;math&gt; r \rightarrow m-r &lt;/math&gt; and the invariance of the Gaussian binomial coefficients under the reflection &lt;math&gt; r \rightarrow m-r &lt;/math&gt;. Both Pascal identities together imply

:&lt;math&gt;{m \choose r}_q = {{1-q^{m}}\over {1-q^{m-r}}}  {m-1 \choose r}_q &lt;/math&gt;

which leads (when applied iteratively for ''m'', ''m'' − 1, ''m'' − 2,....) to an expression for the Gaussian binomial coefficient as given in the definition above.

==Applications==

Gaussian binomial coefficients occur in the counting of [[symmetric polynomial]]s and in the theory of [[partition (number theory)|partitions]]. The coefficient of ''q''&lt;sup&gt;''r''&lt;/sup&gt; in

:&lt;math&gt;{n+m \choose m}_q&lt;/math&gt;

is the number of partitions of ''r'' with ''m'' or fewer parts each less than or equal to ''n''. Equivalently, it is also the number of partitions of ''r'' with ''n'' or fewer parts each less than or equal to ''m''.

Gaussian binomial coefficients also play an important role in the enumerative theory of [[projective space]]s defined over a finite field. In particular, for every [[finite field]] ''F''&lt;sub&gt;''q''&lt;/sub&gt; with ''q'' elements, the Gaussian binomial coefficient

:&lt;math&gt;{n \choose k}_q&lt;/math&gt;

counts the number of ''k''-dimensional vector subspaces of an ''n''-dimensional [[vector space]] over ''F''&lt;sub&gt;''q''&lt;/sub&gt; (a [[Grassmannian]]).  When expanded as a polynomial in ''q'', it yields the well-known decomposition of the Grassmannian into Schubert cells.  For example, the Gaussian binomial coefficient

:&lt;math&gt;{n \choose 1}_q=1+q+q^2+\cdots+q^{n-1}&lt;/math&gt;

is the number of one-dimensional subspaces in (''F''&lt;sub&gt;''q''&lt;/sub&gt;)&lt;sup&gt;''n''&lt;/sup&gt; (equivalently, the number of points in the associated [[projective space]]).  Furthermore, when ''q'' is 1 (respectively −1), the Gaussian binomial coefficient yields the [[Euler characteristic]] of the corresponding complex (respectively real) Grassmannian.

The number of ''k''-dimensional affine subspaces of ''F''&lt;sub&gt;''q''&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt; is equal to

:&lt;math&gt;q^{n-k} {n \choose k}_q&lt;/math&gt;.

This allows another interpretation of the identity

:&lt;math&gt;{m \choose r}_q = {m-1 \choose r}_q + q^{m-r}{m-1 \choose r-1}_q&lt;/math&gt;

as counting the (''r'' − 1)-dimensional subspaces of (''m'' − 1)-dimensional projective space by fixing a hyperplane, counting such subspaces contained in that hyperplane, and then counting the subspaces not contained in the hyperplane; these latter subspaces are in bijective correspondence with the (''r'' − 1)-dimensional affine subspaces of the space obtained by treating this fixed hyperplane as the hyperplane at infinity.

In the conventions common in applications to [[quantum groups]], a slightly different definition is used; the quantum binomial coefficient there is
:&lt;math&gt;q^{k^2 - n k}{n \choose k}_{q^2}&lt;/math&gt;.
This version of the quantum binomial coefficient is symmetric under exchange of &lt;math&gt;q&lt;/math&gt; and &lt;math&gt;q^{-1}&lt;/math&gt;.

==Triangles==

The Gaussian binomial coefficients can be arranged in a triangle for each ''q'', which is [[Pascal's triangle]] for ''q''=1.&lt;br&gt;
Read line by line these triangles form the following sequences in the [[On-Line Encyclopedia of Integer Sequences|OEIS]]:
* [[oeis:A022166/table|A022166]] for ''q''= 2
* [[oeis:A022167/table|A022167]] for ''q''= 3
* [[oeis:A022168/table|A022168]] for ''q''= 4
* [[oeis:A022169/table|A022169]] for ''q''= 5
* [[oeis:A022170/table|A022170]] for ''q''= 6
* [[oeis:A022171/table|A022171]] for ''q''= 7
* [[oeis:A022172/table|A022172]] for ''q''= 8
* [[oeis:A022173/table|A022173]] for ''q''= 9
* [[oeis:A022174/table|A022174]] for ''q''= 10

==References==
*Exton, H. (1983), ''q-Hypergeometric Functions and Applications'', New York:  Halstead Press, Chichester: Ellis Horwood, 1983, {{ISBN|0853124914}},  {{ISBN|0470274530}}, {{ISBN|978-0470274538}}
* {{cite web
|first1=Eugene
|last1=Mukhin
|url=http://mathcircle.berkeley.edu/BMC3/SymPol.pdf
|title= Symmetric Polynomials and Partitions
|archive-url=https://web.archive.org/web/20160304041707/http://mathcircle.berkeley.edu/BMC3/SymPol.pdf
|archive-date=March 4, 2016
|dead-url=yes
}} (undated, 2004 or earlier).
* Ratnadha Kolhatkar, [http://www.math.mcgill.ca/goren/SeminarOnCohomology/GrassmannVarieties%20.pdf Zeta function of Grassmann Varieties] (dated January 26, 2004)
* {{MathWorld| urlname=q-BinomialCoefficient|title=q-Binomial Coefficient}}
* {{cite journal
|first1=Henry
|last1=Gould
|journal=[[Fibonacci Quarterly]]
|year=1969
|title=The bracket function and Fontene-Ward generalized binomial coefficients with application to Fibonomial coefficients
|mr=0242691
|volume=7
|pages=23–40
}}
* {{cite journal
|first1= G. L.
|last1=Alexanderson|author1-link=Gerald L. Alexanderson
|journal=[[Fibonacci Quarterly]]
|year=1974
|volume=12
|title=A Fibonacci analogue of Gaussian binomial coefficients
|mr=0354537
|pages=129–132
}}
* {{cite journal
|first1=George E.
|last1=Andrews
|author1-link=George Andrews (mathematician)
|title=Applications of basic hypergeometric functions
|journal=SIAM Rev.
|year=1974
|volume=16
|number=4
|jstor=2028690
|mr=0352557
|doi=10.1137/1016081
|pages=441–484
}}
* {{cite journal
|first1=Peter B.
|last1=Borwein
|title=Padé approximants for the q-elementary functions
|journal=Construct. Approx.
|year=1988
|volume=4
|number=1
|pages=391–402
|doi=10.1007/BF02075469
|mr=0956175
}}
* {{cite journal
|first1=John
|last1=Konvalina
|title=Generalized binomial coefficients and the subset-subspace problem
|journal=Adv. Appl. Math.
|year=1998
|doi=10.1006/aama.1998.0598
|volume=21
|pages=228–240
|mr=1634713
}}
* {{cite journal
|first1=A.
|last1=Di Bucchianico
|title=Combinatorics, computer algebra and the Wilcoxon-Mann-Whitney test
|journal=J. Stat. Plann. Inf.
|year=1999
|doi=10.1016/S0378-3758(98)00261-4
|volume=79
|pages=349–364
}}
* {{ cite journal
|first1=John
|last1=Konvalina
|title=A unified interpretation of the Binomial Coefficients, the Stirling numbers, and the Gaussian coefficients
|journal=Amer. Math. Monthly
|jstor=2695583
|year=2000
|pages=901–910
|volume=107
|number=10
|mr=1806919
|doi=10.2307/2695583
}}
* {{cite journal
|first1=Boris A.
|last=Kupershmidt
|title=q-Newton binomial: from Euler to Gauss
|journal=J. Nonlinear Math. Phys.
|year=2000
|volume=7
|number=2
|pages=244–262
|mr=1763640
|bibcode=2000JNMP....7..244K
|arxiv = math/0004187 |doi = 10.2991/jnmp.2000.7.2.11 }}
* {{ cite journal
|first1=Henry
|last1=Cohn
|journal=Amer. Math. Monthly
|year=2004
|title=Projective geometry over '''F'''&lt;sub&gt;1&lt;/sub&gt; and the Gaussian Binomial Coefficients
|volume=111
|number=6
|jstor=4145067
|mr=2076581
|pages=487–495
|url=http://www.maa.org/programs/maa-awards/writing-awards/projective-geometry-over-f1-and-the-gaussian-binomial-coefficients
|doi=10.2307/4145067
}}
* {{cite journal
|first1=T.
|last1=Kim
|title=q-Extension of the Euler formula and trigonometric functions
|journal=Russ. J. Math. Phys.
|volume=14
|number=3
|pages=-275–278
|year=2007
|doi=10.1134/S1061920807030041
|mr=2341775
|bibcode = 2007RJMP...14..275K }}
* {{cite journal
|first1=T.
|last1=Kim
|title=q-Bernoulli numbers and polynomials associated with Gaussian binomial coefficients
|journal = Russ. J. Math. Phys.
|volume=15
|number=1
|pages=51–57
|doi=10.1134/S1061920808010068
|mr=2390694
|year=2008|bibcode = 2008RJMP...15...51K }}
* {{cite journal
|first1=Roberto B.
|last1=Corcino
|title= On p,q-binomial coefficients
|journal=Integers
|volume=8
|year=2008
|pages=#A29
|mr=2425627
}}
* {{cite web
|first1=Gevorg
|last1=Hmayakyan
|url=http://ghmath.files.wordpress.com/2010/06/mobius.pdf
|title= Recursive Formula Related To The Mobius Function
}} (2009).

[[Category:Q-analogs]]
[[Category:Factorial and binomial topics]]</text>
      <sha1>mplmho4ih2x0mu4wpx2utwljdous3jg</sha1>
    </revision>
  </page>
  <page>
    <title>Geometry Expert</title>
    <ns>0</ns>
    <id>28948360</id>
    <revision>
      <id>595121661</id>
      <parentid>539381241</parentid>
      <timestamp>2014-02-12T10:18:12Z</timestamp>
      <contributor>
        <ip>2601:C:A780:961:2C3:51FF:FE74:7AF</ip>
      </contributor>
      <comment>read the journal</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="758">'''Geometry Expert''' ('''GEX''') is a Chinese software for dynamic diagram drawing and automated geometry theorem proving and discovering. 

There's a new Chinese version of Geometry Expert, called [[Mathematics-Mechanization Platform|MMP/Geometer]].

'''Java Geometry Expert''' is free under [[GNU General Public License]].

==External links==
* [http://www.mmrc.iss.ac.cn/gex/ GEX Official website]
* Java GEX ([http://woody.cs.wichita.edu/gex/ old], [http://www.cs.wichita.edu/~ye/ new]) on [[Wichita State University]]
* [http://woody.cs.wichita.edu/help/gex_jgex.html Java GEX Documentation] on [[Wichita State University]]

[[Category:Theorem proving software systems]]
[[Category:Automated theorem proving]]
[[Category:Interactive geometry software]]</text>
      <sha1>hsxq49gm8hpeoy3n5lsgc9t0yhpujnb</sha1>
    </revision>
  </page>
  <page>
    <title>George Pretyman Tomline</title>
    <ns>0</ns>
    <id>12894609</id>
    <revision>
      <id>870574665</id>
      <parentid>845756327</parentid>
      <timestamp>2018-11-25T18:49:39Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category People educated at King Edward VI School (Bury St Edmunds) to [[:Category:People educated at King Edward VI School, Bury St Edmunds]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15304">:''In this name, the [[family name]] is'' Pretyman (before 1803)'', ''Pretyman Tomline (from 1803)'', but commonly called ''Tomline'' thereafter.''
{{Infobox Christian leader
| honorific-prefix = {{pre-nominal styles|RRevd}}
| name             = Sir George Pretyman Tomline
| honorific-suffix = {{post-nominal styles|country=GBR|Bt|FRS}}
| title            = [[Bishop of Winchester]]
| image            = SirGeorgePretymanTomline.jpg
| alt              = An rough oil painting portrait of an old white man with grey hair (or wig), robed as the Prelate of the Order of the Garter, with preaching bands and a blue outer cloak bearing the St George's Cross emblem of the Order.
| caption          = Pretyman Tomline robed as Garter Prelate.
| diocese          = [[Diocese of Winchester]]
| term             = 1820–1827
| predecessor      = [[Brownlow North]]
| successor        = [[Charles Sumner (bishop)|Charles Sumner]]
| other_post       = Private secretary to the Prime Minister (1783–1787)&lt;br /&gt;[[Dean of St Paul's]] (1787–1820)&lt;br /&gt;[[Bishop of Lincoln]] (1787–1820)
&lt;!---------- Orders ----------&gt;
| ordination       = 1774 (deacon); 1776 (priest)
| consecration     = {{circa|1787}}
&lt;!---------- Personal details ----------&gt;
| birth_date       = {{birth date|1750|10|9|df=y}}
| birth_place      = [[Bury St Edmunds]], [[Suffolk]], [[Great Britain]]
| death_date       = {{death date and age|1827|11|14|1750|10|9|df=y}}
| death_place      = [[Wimborne]], [[Dorset]], [[United Kingdom]]
| buried           = [[Winchester Cathedral]]
| nationality      = [[British people|British]]
| religion         = [[Anglicanism|Anglican]]
| residence        = Kingston Hall, near Wimborne (at death)
| parents          = George Pretyman &amp; Susan
| spouse           = Elizabeth Maltby (m. 1784; d. 1826)
| children         = 3 sons
| profession       = [[theologian]]
| alma_mater       = [[Pembroke College, Cambridge]]
}}
'''Sir George Pretyman Tomline, 5th Baronet''' {{post-nominal styles|country=GBR|FRS}} (born '''George Pretyman'''; 9 October 1750 – 14 November 1827) was an [[England|English]] [[clergy]]man, [[theologian]], [[Bishop of Lincoln]] and then [[Bishop of Winchester]], and confidant of [[William Pitt the Younger]]. He was an opponent of [[Catholic emancipation]].

==Early life==
He was born George Pretyman in [[Bury St Edmunds]], [[Suffolk]] to a family claiming to have been influential in the region as far back as the fourteenth century. His father, also George Pretyman (1722–1810) was a [[landowner]] and [[wool]] [[merchant]]. His mother, George's wife, was Susan ''[[née]]'' Hubbard (1720/1721 – 1807).

Pretyman attended [[King Edward VI School (Bury St Edmunds)|Bury St Edmunds Grammar School]] and then [[Pembroke College, Cambridge]], [[graduation|graduating]] in 1772 as [[senior wrangler]] and [[Smith's prize]]winner. He was elected a [[Fellow#Oxford, Cambridge and Dublin|fellow]] of Pembroke in 1773. He was [[ordination|ordained]] [[deacon]] in 1774 and [[priest]] in 1776:&lt;ref name="Venn"&gt;{{acad|id=PRTN767G|name=Pretyman (post Pretyman Tomline), George}}&lt;/ref&gt; by [[Philip Yonge]], [[Bishop of Norwich]] at [[Bishop's Palace, Norwich|his Palace's chapel]] on 14 August 1774&lt;ref&gt;{{CCEd |type=ordination |id=145159 |name=Pretyman, George |accessed=27 July 2015 }}&lt;/ref&gt; and by [[John Hinchliffe]], [[Bishop of Peterborough]] at [[Trinity College, Cambridge]] on 16 June 1776.&lt;ref&gt;{{CCEd |type=ordination |id=64902 |name=Pretyman, George |accessed=27 July 2015 }}&lt;/ref&gt;

[[William Pitt the Younger]] was sent to Pembroke in 1773, at the age of fourteen, and Pretyman became his tutor and gradually his friend and confidant.&lt;ref&gt;Hague (2005) ''p''27&lt;/ref&gt; When Pitt unsuccessfully stood for election as [[Member of Parliament]] for [[Cambridge University (UK Parliament constituency)|Cambridge University]] in the [[British general election, 1780]], Pretyman supported him.

Pitt became [[Prime Minister of Great Britain]] in December 1783 when the [[Fox-North Coalition]] fell but it remained for him to win the [[British general election, 1784]].  On his 1784 victory, Pitt made Pretyman his private secretary, though the title was thought inappropriate for a clergyman. Pretyman's mathematical ability was soon called upon in advising Pitt on the [[sinking fund]] and other technicalities of [[fiscal policy]].

On 3 September 1784, Pretyman married Elizabeth Maltby (died 13 June 1826), cousin of [[Edward Maltby]], the future [[Bishop of Chichester]] and himself eighth wrangler, and appointed Edward his [[domestic chaplain]].&lt;ref&gt;Varley, E. A. (2004) "[http://www.oxforddnb.com/view/article/17900 Maltby, Edward (1770–1859)]", ''[[Oxford Dictionary of National Biography]]'', Oxford University Press, accessed 11 Aug 2007 (subscription required)&lt;/ref&gt; George and Elizabeth were well-matched and he constantly consulted her on church and political issues.

==Bishop of Lincoln==
In 1787, Pitt appointed Pretyman [[Bishop of Lincoln]], having to overcome the opposition of [[George III of the United Kingdom|George III]] who objected to Pretyman's youth. Having already become [[Dean of St Paul's]] (he was instituted to the Portpoole prebend by Robert Lowth, Bishop of London on 21 February 1787),&lt;ref&gt;{{CCEd |type=appointment |id=158739 |name=Pretyman, George |location=St Pauls Cathedral |accessed=27 July 2015 }}&lt;/ref&gt; his [[Canonical election|election]] was [[Confirmation of bishops|confirmed]] by [[John Moore (Archbishop of Canterbury)|John Moore]], [[Archbishop of Canterbury]], at [[St Mary-le-Bow]] on 10 March 1787&lt;ref&gt;{{CCEd |type=appointment |id=308852 |name=Pretyman, George |location=Lincoln |accessed=27 July 2015 }}&lt;/ref&gt; and he was [[Episcopal consecration|consecrated a bishop]] by Moore (assisted by [[Sir William Ashburnham, 4th Baronet|William Ashburnham]], [[Bishop of Chichester]]; [[Shute Barrington]], [[Bishop of Salisbury]] and [[Beilby Porteus]], [[Bishop of Chester]]) at [[Lambeth Palace]] chapel on 11 March 1787.&lt;ref&gt;{{CCEd |type=appointment |id=308853 |name=Pretyman, George |location=Lincoln |accessed=27 July 2015 }}&lt;/ref&gt;

Pretyman maintained on close terms with Pitt, though Lincoln duties kept him from frequent visits to [[London]], and shared [[British Whig Party|Whig]] attitudes. In a [[sermon]] to the [[House of Lords]] on 30 January 1789, Pretyman condemned [[Charles I of England|Charles I]], executed by [[Parliament of England|parliament]] in 1649, and praised his political opponents. [[John Wesley]] wrote to Pretyman in 1790 accusing him of driving the '[[Methodism|people called Methodists]]' out of the established church.&lt;ref&gt;http://wesley.nnu.edu/john-wesley/the-letters-of-john-wesley/wesleys-letters-1790a&lt;/ref&gt; Pretyman continued to advise Pitt on finance and on Pitt's [[Ecclesiastical Plan]]. Pretyman was an opponent of [[Catholic emancipation]] and was against Pitt's 1801 decision to resign when he failed to effect the changes promised to the [[Ireland|Irish]] Catholics in the compromises made over the passage of the [[Act of Union 1800]].

[[Henry Addington, 1st Viscount Sidmouth|Henry Addington]]'s regime was still less to Pretyman's taste and his anti-Catholic sentiments strengthened. However, he remained on good terms with Pitt and was ready to help him out of his debts.

==Pitt's second ministry==
Already wealthy, in 1803 he inherited extensive property from a distant relative, Marmaduke Tomline, and took the name '''Tomline'''. Pitt returned to government in 1804 and, much to Tomline's satisfaction, promoted Tomline as [[Archbishop of Canterbury]], even though there was an earlier provisional agreement with the King that [[Charles Manners-Sutton]] should be appointed. However, the King was not to be manœuvred and exercised his [[royal prerogative]] to appoint Manners-Sutton.

Tomline was offered the post of [[Bishop of London]] in 1813 but declined because he thought the duties too onerous. He was translated to [[Bishop of Winchester]] by the confirmation of his election (by Manners-Sutton) on 15 August 1820.&lt;ref&gt;{{CCEd |type=appointment |id=300347 |name=Pretyman, George |location=Winchester |accessed=27 July 2015 }}&lt;/ref&gt;

==Family and death==
[[File:Memorial to George Tomline in Winchester Cathedral.jpg|thumb|Memorial in [[Winchester Cathedral]]]]
Tomline had inherited further property before he died of [[apoplexy]] at Kingston Hall, near [[Wimborne]], [[Dorset]] and his [[estate (law)|estate]] was worth £200,000 ({{Inflation|UK|200000|1827|fmt=eq|cursign=£}}).{{Inflation-fn|UK}} He was buried in [[Winchester Cathedral]]. His monument was sculpted by [[Richard Westmacott (the younger)]].&lt;ref&gt;Dictionary of British Sculptors 1660–1851, Rupert Gunnis&lt;/ref&gt;

Tomline and his wife had three sons but they relinquished their claim to the baronetcy:
*[[William Edward Tomline]] (1787–1836),&lt;ref&gt;Gooding (2003)&lt;/ref&gt; MP for, successively, [[Christchurch (UK Parliament constituency)|Christchurch]], [[Truro (UK Parliament constituency)|Truro]], and [[Minehead (UK Parliament constituency)|Minehead]].
*George-Thomas Tomline, became [[Chancellor]] of [[Lincoln Cathedral|Lincoln]] and [[prebendary]] of [[Winchester]].
*Richard Tomline, his third son, became [[precentor]] of Lincoln.

==Works==
Tomline published the following works:&lt;ref&gt;{{cite DNB|wstitle=Tomline, George Pretyman|volume=57}}&lt;/ref&gt;

*''Elements of Christian Theology'' (1799), 2 vols., with the 12th and last edition printed in 1826. It was designed for candidates for ordination. [[Henry Stebbing (editor)|Henry Stebbing]] published a revision, in 1843.
*''A Refutation of Calvinism'' (1803), the 8th and final edition printed in 1823. This was a controversial work, causing a debate that involved [[Thomas Scott (commentator)|Thomas Scott]], [[Edward Williams (minister)|Edward Williams]], [[John Chetwode Eustace]], and some anonymous writers.
*''Memoir of the Life of the Right Honorable William Pitt'', 2 vols. (John Murray, Albemarle-Street, London, 1821). It goes no further than 1793.

==Personality==
He was an able administrator to his [[diocese]], conducting eleven [[Canonical visitation|visitation]]s during his thirty three years tenure.

{{quotation | Though to the inferior clergy there was unquestionably something over-awing in his presence, arising from their conscientiousness of his superior attainments, yet it was impossible not to admire the courtliness of his manners and the benevolence of his sentiments | ''[[The Gentleman's Magazine]]'', 1st ser., 98/1 (1828), 204) }}

Though he appeared somewhat aloof in public, Tomline was a devoted family man and genial enough given the right company. From 1806, he was conservative as to his attitudes to church and state but was well respected by someone of as different an outlook as [[Samuel Parr]].

==Offices and honours==
*Sinecure [[rectory]] of [[Corwen]], [[Merioneth]], (1782);
*[[Canon (priest)|Canon]] of [[Westminster]], (1784);
*[[Doctor of Divinity]], University of Cambridge, (1784);
*Rector of [[Sudbourne|Sudbourn-cum-Offord]], (1785);
*[[Fellow of the Royal Society]], (1785);
*[[Dean of St Paul's]], (1787–1820);
*Charles I had originally conferred a [[Pretyman baronets|Nova Scotia baronetcy]] on [[Sir John Pretyman, 1st Baronet|John Pretyman]] but it had been dormant since 1749. In February 1823, Tomline's claim to the baronetcy was confirmed and he became '''Sir George Pretyman Tomline, 5th Baronet'''.

==Styles and titles==
*1750–1774: George Pretyman Esq.
*1774–1784: ''[[The Reverend]]'' George Pretyman
*1784–1787: ''The Reverend'' Canon Dr George Pretyman
*1787–1787: ''[[The Very Reverend]]'' Dr George Pretyman
*1787–1803: ''[[The Right Reverend]]'' Dr George Pretyman
*1803–1823: ''The Right Reverend'' Dr George Pretyman Tomline
*1823–1827: ''The Right Reverend'' Dr Sir George Pretyman Tomline, Baronet

== References ==
{{reflist}}

==Sources==
*Obituary:
**''[[The Gentleman's Magazine]]'', 1st ser., 98/1 (1828), 201–4
----
*{{cite book | author=Burke, Sir Bernard | year=1863 | location=London | publisher=Harrison | title=A Genealogical and Heraldic Dictionary of the Landed Gentry of Great Britain and Ireland | pages=''p.''1518 | url=https://books.google.com/?id=Ni4BAAAAQAAJ&amp;pg=RA21-PA1518&amp;lpg=RA21-PA1518&amp;dq=william+edward+tomline | accessdate=2007-08-22 }}
*{{cite book | authorlink=Stephen Hyde Cassan | last=Cassan | first=S. H. | title=The Lives of the Bishops of Winchester | edition=2 vols. | year=1827 }}
*{{Cite ODNB|id=27520|title=Tomline, Sir George Pretyman}} (Accessed 27 July 2015)
*— (2005) "Sir George Pretyman-Tomline: Ecclesiastical Politician and Theological Polemicist" in {{cite book | author=Gibson, W. &amp; Ingham, R. G. (eds.) | title=Religious Identities in Britain, 1660–1832 | year=2005 | publisher=Ashgate | isbn= 0-7546-3209-1 }}
*{{cite web|title=George Tomline &amp; Relatives |author=Gooding, Roy |year=2003 |accessdate=2007-08-22 |url=http://www.ast.cam.ac.uk/~ipswich/Observatory/Tomline.htm |work=Orwell Astronomical Society |deadurl=yes |archiveurl=https://web.archive.org/web/20050802094829/http://www.ast.cam.ac.uk/~ipswich/Observatory/Tomline.htm |archivedate=2 August 2005 }} 
* {{cite book|last = Hague|first = William|authorlink= William Hague|title= William Pitt the Younger|year= 2005|isbn= 978-0-00-714720-5|publisher= HarperPerennial|ref = CITEREFHague2005}}
*{{cite book | author=Nockles, P. B. | title=The Oxford Movement in Context: Anglican High Churchmanship, 1760–1857 | year=1994 }}
*Payne, R. (2008) [https://web.archive.org/web/20090105221426/http://journal.ccedb.org.uk/archive/cce_a3.html 'George Pretyman, bishop of Lincoln, and the University of Cambridge 1787–1801'], ''CCEd Online Journal'' 3, 2008
*{{ cite book | author=— | title=Ecclesiastical Patronage in England, 1770–1801: A Study of Four Family and Political Networks | year=2010 | publisher=Mellen Press | isbn=0-7734-3789-4 }}
*{{cite book | author=Sack, J. J. | title=From Jacobite to Conservative: Reaction and Orthodoxy in Britain, c. 1760–1832 | year=1993 }}
{{s-start}}
{{s-rel|en}}
{{s-bef|before=[[Thomas Thurlow (bishop)|Thomas Thurlow]]|rows=2}}
{{s-ttl|title=[[Dean of St Paul's]]|years=1787–1820}}
{{s-aft|after=[[William Van Mildert]]}}
{{s-ttl|title=[[Bishop of Lincoln]]|years=1787–1820}}
{{s-aft|after=[[George Pelham (bishop)|George Pelham]]}}
{{s-bef|before=[[Brownlow North]]}}
{{s-ttl|title=[[Bishop of Winchester]]|years=1820–1827}}
{{s-aft|after=[[Charles Sumner (bishop)|Charles Sumner]]}}
{{s-end}}
{{Bishops of Winchester}}
{{Bishops of Lincoln}}
{{Deans of St Paul's}}
{{Use dmy dates|date=January 2011}}
{{Authority control}}

{{DEFAULTSORT:Tomline, George Pretyman}}
[[Category:1750 births]]
[[Category:1827 deaths]]
[[Category:18th-century English Anglican priests]]
[[Category:19th-century English Anglican priests]]
[[Category:Bishops of Lincoln]]
[[Category:Bishops of Winchester]]
[[Category:18th-century Anglican bishops]]
[[Category:19th-century Anglican bishops]]
[[Category:Fellows of the Royal Society]]
[[Category:Alumni of Pembroke College, Cambridge]]
[[Category:Fellows of Pembroke College, Cambridge]]
[[Category:Senior Wranglers]]
[[Category:People educated at King Edward VI School, Bury St Edmunds]]
[[Category:Canons of Westminster]]
[[Category:Deans of St Paul's]]</text>
      <sha1>sdlwq3gs5ew3foxlcaz8qniypurg2tv</sha1>
    </revision>
  </page>
  <page>
    <title>Gradshteyn and Ryzhik</title>
    <ns>0</ns>
    <id>49343041</id>
    <revision>
      <id>841381539</id>
      <parentid>841380969</parentid>
      <timestamp>2018-05-15T14:16:32Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>/* {{anchor|English}}English editions */Journal cites, Added 5 dois to journal cites</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="116344">{{Infobox book | &lt;!-- See Wikipedia:WikiProject_Novels or Wikipedia:WikiProject_Books --&gt;
| name = Table of Integrals, Series, and Products
| image = Gradshteyn Ryzhik 7ed.jpg
| caption = Gradshteyn and Ryzhik, seventh English edition, 2007
| author = [[Iosif Moiseevich Ryzhik|Ryzhik]], [[Izrail Solomonovich Gradshteyn|Gradshteyn]], [[Yuri Veniaminovich Geronimus|Geronimus]], [[Michail Yulyevich Tseytlin|Tseytlin]] et al.
| country = Russia
| language = [[#Russian|Russian]], [[#German|German]], [[#Polish|Polish]], [[#English|English]], [[#Japanese|Japanese]], [[#Chinese|Chinese]]
| genre = [[Math]]
| publisher = [[Academic Press]]
| release_date = 1943, 2015
| isbn = 
| oclc = 
}}
'''''Gradshteyn and Ryzhik''''' ('''GR''') is the informal name of a comprehensive [[table of integrals]] originally compiled by the Russian mathematicians I. S. Gradshteyn and I. M. Ryzhik. Its full title today is '''''Table of Integrals, Series, and Products'''''.

Since its first publication in 1943, it was considerably expanded and it soon became a "classic" and highly regarded reference for mathematicians, scientists and engineers. After the deaths of the original authors, the work was maintained and further expanded by other editors.

At some stage a German and English dual-language translation became available, followed by Polish, English-only and Japanese versions. After several further editions, the Russian and German-English versions went out of print and have not been updated after [[the fall of the Iron Curtain]], but the English version is still being actively maintained and refined by new editors, and it has recently been retranslated back into Russian as well.

==Overview==
One of the valuable characteristics of ''Gradshteyn and Ryzhik'' compared to similar compilations is that most listed integrals are referenced. The literature list contains 92 main entries and 140 additional entries (in the eighth English edition). The integrals are classified by numbers, which haven't changed from the fourth Russian up to the seventh English edition (the numbering in older editions as well as in the eighth English edition is not fully compatible).
The book does not only contain the integrals, but also lists additional properties and related [[special function]]s.
It also includes tables for [[integral transform]]s.
Another advantage of ''Gradshteyn and Ryzhik'' compared to [[computer algebra system]]s is the fact that all special functions and constants used in the evaluation of the integrals are listed in a registry as well, thereby allowing reverse lookup of integrals based on special functions or constants.

On the downsides, ''Gradshteyn and Ryzhik'' has become known to contain a relatively high number of typographical errors even in newer editions, which has repeatedly led to the publication of extensive [[errata]] lists. Earlier English editions were also criticized for their poor translation of mathematical terms&lt;ref name="RMT_85"/&gt;&lt;ref name="REV_153_5"/&gt;&lt;ref name="REV_209_1"/&gt; and mediocre print quality.&lt;ref name="RMT_85"/&gt;&lt;ref name="REV_153_5"/&gt;

=={{anchor|Gradshteyn|Ryzhik|Geronimus|Tseytlin}}History==
&lt;!-- This Anchor tag serves to provide a permanent target for incoming section links. Please do not remove it, nor modify it, except to add another appropriate anchor. If you modify the section title, please anchor the old title. It is always best to anchor an old section header that has been changed so that links to it won't be broken. See [[Template:Anchor]] for details. This template is {{subst:Anchor comment}} --&gt;
The work was originally compiled by the Russian mathematicians Iosif Moiseevich Ryzhik (Russian: {{lang|ru|Иосиф Моисеевич Рыжик}}, German: {{lang|de|Jossif Moissejewitsch Ryschik}})&lt;ref name="Wolfram_2005"/&gt;&lt;ref group="nb" name="Ryzhik_Bio"&gt;[[Iosif Moiseevich Ryzhik]] ({{lang|ru|Иосиф Моисеевич Рыжик}}) (1918?–1941). {{VIAF|15286520}}. {{GND|107340518|1087809320}}. [http://www.stephenwolfram.com/publications/history-future-special-functions/#GRbook&lt;!-- https://web.archive.org/web/20180111235111/http://www.stephenwolfram.com/publications/history-future-special-functions/ --&gt;] [https://books.google.de/books?id=fEGxAAAAIAAJ&amp;pg=PA300&amp;lpg=PA300&lt;!-- https://books.googleusercontent.com/books/content?req=AKW5QafyOJq87k4cVJ0_98_yaR5R_B8G_DWjCpV9X1ZBEOjZ3ucooksxLbhyoq0Do_D0eg-agpeCrgD_91F0G83gnyeR4TIyW_bMAbSlTrvUI37_UQ0S9n38Kl0d5_vod1M_SUYveGI0i4taJ-iX42tTYK6-CW0vNcSBf-CsGQOZ2WaIMZK7AoXohG-j6dBT2TLBgkVb3lpRWm3oXc0JhY5OXAGocStAPsafftWF9PobJpjGZoUG1S6XckYtTROw59Ik4U0Yywge2eImm75vGPQwc0tj-IUFGw  --&gt; ?] [http://jmemory.org/memorial/R/r-6.htm&lt;!-- https://web.archive.org/web/20180111234607/http://jmemory.org/memorial/R/r-6.htm --&gt; ?]&lt;/ref&gt; and Izrail Solomonovich Gradshteyn (Russian: {{lang|ru|Израиль Соломонович Градштейн}}, German: {{lang|de|Israil Solomonowitsch Gradstein}}).&lt;ref name="Wolfram_2005"/&gt;&lt;ref group="nb" name="Gradshteyn_Bio"&gt;[[Izrail Solomonovich Gradshteyn]] ({{lang|ru|Израиль Соломонович Градштейн}}) (1899, Odessa – 1958, Moscow). {{VIAF|20405466}}, {{VIAF|310677818}}, {{VIAF|270418384}}. ISNI&amp;nbsp;0000000116049405. {{GND|11526194X}}.&lt;/ref&gt; While some contents were original, significant portions were collected from other previously existing integral tables like [[David Bierens de Haan]]'s ''{{lang|fr|[[Nouvelles tables d'intégrales définies]]}}'' (1867),&lt;ref name="Wolfram_2005"/&gt;&lt;ref name="Bierens_de_Haan_1867"&gt;{{cite book |author-first=David |author-last=Bierens de Haan |author-link=David Bierens de Haan |title=Nouvelles tables d'intégrales définies&lt;!-- |title-link=Nouvelles tables d'intégrales définies --&gt; |language=French |trans-title=New tables of definite integrals |date=1867 |edition=1 |publisher=P. Engels |location=Leiden, Netherlands |url=https://books.google.com/books?id=UEE-AQAAIAAJ |accessdate=2016-04-17}} (NB. This book had a precursor in 1858 named ''{{lang|fr|[[Tables d'intégrales définies]]}}'' [https://books.google.com/books?id=UzvJnYqWYvkC] (published by C. G. van der Post in Amsterdam) with supplement ''{{lang|fr|[[Supplément aux tables d'intégrales définies]]}}'' [https://books.google.com/books?id=Nexq-LGplu0C] in ca. 1864. Cited as ''BI'' ({{lang|ru|БХ}}) in GR.)&lt;/ref&gt; [[Václav Jan Láska]]'s ''{{lang|de|Sammlung von Formeln der reinen und angewandten Mathematik}}'' (1888-1894)&lt;ref name="Wolfram_2005"/&gt;&lt;ref name="Laska_1888"&gt;{{cite book |author-first=Václav Jan |author-last=Láska |title=Sammlung von Formeln der reinen und angewandten Mathematik |language=German |trans-title=Compilation of formulae of pure and applied mathematics |date=1888–1894 |volume=1-3 |edition=1 |publisher={{Interlanguage link multi|Friedrich Vieweg und Sohn|de}} |location=Braunschweig, Germany |oclc=24624148 |url=https://archive.org/details/sammlungformeln00laskrich |accessdate=2016-04-17}} (NB. The book writes the author's name as {{lang|de|Wenzel&lt;!-- some sources also as Wilhelm: https://books.google.com/books?id=uqevA55MvbwC&amp;pg=PA381&amp;lpg=PA381 --&gt; Láska}}&lt;!-- born 1862 in Prague --&gt;. Cited as ''LA'' ({{lang|ru|Ла}}) in GR.)&lt;/ref&gt; or [[Edwin Plimpton Adams]]' and [[Richard Lionel Hippisley]]'s ''Smithsonian Mathematical Formulae and Tables of Elliptic Functions'' (1922).&lt;ref name="Wolfram_2005"/&gt;&lt;ref name="Adams_Hippisley_1922"&gt;{{cite book |author-first1=Edwin Plimpton |author-last1=Adams |author-link1=Edwin Plimpton Adams |author-first2=Richard Lionel |author-last2=Hippisley |editor-first=Alfred George |editor-last=Greenhill |editor-link=Alfred George Greenhill |title=Smithsonian Mathematical Formulae and Tables of Elliptic Functions |volume=74 |edition=1 |series=Smithsonian Miscellaneous Collections |date=1922 |publisher=[[Smithsonian Institution]] |location=Washington D.C., USA |url=https://books.google.com/books?id=YKSQngEACAAJ |accessdate=2016-04-17}} (NB. Cited as ''AD'' ({{lang|ru|А}}) in GR.)&lt;/ref&gt;

The first edition, which contained about 5&amp;thinsp;000 formulas,&lt;ref name="RMT_219"/&gt;&lt;ref name="ZBL_34-070"/&gt;&lt;ref group="nb" name="Formula_Entry"&gt;Following the sources, this article distinguishes between the documented number of ''formulas'' and the number of ''entries''.&lt;/ref&gt; was authored by Ryzhik,&lt;ref group="nb" name="Ryzhik_Bio"/&gt; who had already published a book on [[special function]]s in 1936&lt;ref name="Wolfram_2005"/&gt;&lt;ref name="Ryzhik_1936"&gt;{{cite book |script-title=ru:Специальные функции: Собрание формул и вспомогательные таблицы |trans-title=Special functions: A collection of formulas and an auxiliary table |language=Russian |author-first=Iosif Moiseevich (Рыжик, Иосиф Моисеевич) |author-last=Ryzhik |author-link=Iosif Moiseevich Ryzhik |date=1936 |edition=1 |contribution=preface |contributor-first=Vyacheslav Vassilievich (Степанов, Вячеслав Васильевич) |contributor-last=Stepanov |contributor-link=Vyacheslav Vassilievich Stepanov |publisher={{lang|ru|[[Объединенное научно-техническое издательство]]}} ({{lang|ru|НТИБ}}), [[ONTI]] ({{lang|ru|[[ОНТИ]]}}). {{lang|ru|Гострансизд-во. Глав. ред. общетехнич. лит-ры и номографии}} |location=Moscow / Leningrad |url=http://search.rsl.ru/en/record/01005303273 |accessdate=2016-04-09 |deadurl=no |archive-url=https://web.archive.org/web/20160409222258/http://search.rsl.ru/en/record/01005303273 |archivedate=2016-04-09}} (160 pages.)&lt;!-- http://www.mccme.ru/ium/books/rbr.html --&gt;&lt;/ref&gt; and died during [[World War II]] in 1941.&lt;ref name="Wolfram_2005"/&gt; Not announcing this fact, his compilation was published posthumously&lt;ref name="Wolfram_2005"/&gt;&lt;ref group="nb" name="Ryzhik_Bio"/&gt; in 1943, followed by a second corrected edition in his name in 1948.&lt;ref group="nb"&gt;The fact that Ryzhik's death was not announced before the third edition of the book in 1951 might indicate that his status was unclear for a number of years, or, in the case of the first edition, that [[hot lead typesetting|typesetting]] had already started, but actual production of the book had to be delayed and was then finalized in his absence as a consequence of the war. In the foreword of the first edition by Ryzhik, the author thanked three mathematicians of the [[Moscow Mathematical Society]] for their suggestions and advice: 
[[Vyacheslav Vassilievich Stepanov]] ({{lang|ru|[[Вячеслав Васильевич Степанов]]}}), {{Interlanguage link multi|Alexei Ivanovich Markushevich|de|3=Alexei Iwanowitsch Markuschewitsch|lt=Alexei Ivanovich Markushevich}} ({{lang|ru|Алексей Иванович Маркушевич}}), and [[Ilya Nikolaevich Bronshtein]] ({{lang|ru|[[Илья Николаевич Бронштейн]]}}).&lt;/ref&gt;

The third edition (1951) was worked on by Gradshteyn, who also introduced the chapter numbering system in [[decimal notation]]. Gradshteyn planned considerable expansion for the fourth edition, a work he could not finish due to his own death.&lt;ref name="Wolfram_2005"&gt;{{cite web |title=The History and Future of Special Functions |at=The story behind Gradshteyn-Ryzhik |author-first=Stephen |author-last=Wolfram |author-link=Stephen Wolfram |date=2005-10-08 |publisher=[[Stephen Wolfram, LLC]] |work=Wolfram Technology Conference, [[Festschrift]] for [[Oleg Marichev]], in honor of his 60th birthday |location=Champaign, IL, USA |type=speech, blog post |url=http://www.stephenwolfram.com/publications/history-future-special-functions/#GRbook |accessdate=2016-04-06 |deadurl=no |archive-url=https://web.archive.org/web/20160407015353/http://www.stephenwolfram.com/publications/history-future-special-functions/#GRbook |archivedate=2016-04-07}}&lt;/ref&gt;&lt;ref group="nb" name="Gradshteyn_Bio"/&gt; Therefore, the fourth (1962/1963) and fifth (1971) editions were continued by [[Yuri Veniaminovich Geronimus]] (Russian: {{lang|ru|Юрий Венеаминович Геронимус}}, German: {{lang|de|Juri Weneaminowitsch Geronimus}})&lt;ref name="Wolfram_2005"/&gt;&lt;ref group="nb" name="Geronimus_Bio"&gt;[[Yuri Veniaminovich Geronimus]] ({{lang|ru|Юрий Венеаминович Геронимус}}) (1923–&lt;!-- alive amd living in Israel in 2005 according to http://www.stephenwolfram.com/publications/history-future-special-functions/#GRbook --&gt;), {{GND|131451812}}.&lt;/ref&gt; and [[Michail Yulyevich Tseytlin]] (Russian: {{lang|ru|Михаил Ю́льевич Цейтлин}}, German: {{lang|de|Michael Juljewitsch Zeitlin}}).&lt;ref group="nb" name="Tseytlin_Bio"&gt;[[Michail Yulyevich Tseytlin]] ({{lang|ru|Михаил Ю́льевич Цейтлин}}), also as M. Yu. Ceitlin and M. Ju. Zeitlin, (?–).&lt;/ref&gt; The fourth edition contained about 12&amp;thinsp;000 formulas already.&lt;ref name="ZBL_103-038"/&gt;&lt;ref group="nb" name="Formula_Entry"/&gt;

Based on the third Russian edition, the first German-English edition with 5&amp;thinsp;400 formulas&lt;ref name="RMT_69"/&gt;&lt;ref group="nb" name="Formula_Entry"/&gt; was published in 1957 by the East-German {{lang|de|[[Deutscher Verlag der Wissenschaften]]}} (DVW) with German translations by {{lang|de|Christa}}&lt;ref group="nb" name="Berg_Ch_Bio"&gt;{{lang|de|Christa Berg}} (1940–), {{GND|122341597}}. [http://www.oz-trauer.de/danksagung/prof-dr-lothar/43432286]&lt;/ref&gt; and {{Interlanguage link multi|Lothar Berg|de|3=Lothar Berg (Mathematiker)}}&lt;ref group="nb" name="Berg_L_Bio"&gt;{{Interlanguage link multi|Lothar Berg|de|3=Lothar Berg (Mathematiker)}} (1930-07-28 to 2015-07-27), {{GND|117708054}}. [http://cpr.uni-rostock.de/metadata/cpr_person_00001546] [http://www.oz-trauer.de/danksagung/prof-dr-lothar/43432286]&lt;/ref&gt; and the English texts by {{lang|de|Martin Strauss}}.&lt;ref group="nb" name="Strauss_Bio"&gt;{{lang|de|Martin Strauss}} (1907–1978), {{GND|139569200}}.&lt;/ref&gt; In {{lang|de|[[Zentralblatt für Mathematik]]}} {{lang|de|[[Karl Prachar]]}} wrote:&lt;ref name="ZBL_80-337"&gt;{{cite journal |author-first=Karl |author-last=Prachar |author-link=Karl Prachar |title=Ryshik, I. M. und I. S. Gradstein: Summen-, Produkt- und Integraltafeln / Tables of series, products and integrals. Berlin: VEB Deutscher Verlag der Wissenschaften, 1957 |type=review |language=German |journal=[[Zentralblatt für Mathematik]] |volume=80 |issue=2 |pages=337–338 |date=1959-09-15 |zbl=0080.33703 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=080&amp;count_=337 |accessdate=2016-02-12}}&lt;/ref&gt;

{{quote|"{{lang|de|Die sehr reichhaltigen Tafeln wurden nur aus dem Russischen ins Deutsche und Englische übersetzt.}}"&lt;br/&gt;(Translation: The very comprehensive tables were only translated into German and English language.)}}

In 1963, it was followed by the second edition, a reprint edition with a four-page inlet listing corrections compiled by [[Eldon Robert Hansen]].

Derived from the 1963 edition, but considerably expanded, the third German-English edition by {{lang|de|Ludwig Boll}}&lt;ref group="nb" name="Boll_Bio"&gt;Ludwig Boll (1906–? or 1951?–1987), {{GND|116236140|1068090308}}?&lt;/ref&gt; was finally published in 1981; it incorporated the material of the fifth Russian edition (1971) as well.

Pending this third German-English edition an English-only edition by Alan Jeffrey&lt;ref group="nb" name="Jeffrey_Bio"&gt;Alan Jeffrey (1929-07-16 to 2010-06-06), {{GND|113118120}}. [http://www.ams.org/notices/201008/rtx100801006p.pdf] [https://dx.doi.org/10.1080/00036811.2012.648369] [http://www.librarything.com/author/jeffreyalan]&lt;/ref&gt; was published in 1965. Lacking a clear designation by itself it was variously known as first, third&lt;!-- as it followed the 2nd German-English edition and because this edition number fits in nicely after the publication of the (actually so called) fifth English edition in 1994 --&gt; or fourth English edition, as it was based on the then-current fourth Russian edition. The formulas were photographically reproduced and the text translated. This still held true for the expanded fourth English edition in 1980, which added chapters 10 to 17.&lt;ref name="ZBL_521-193-1"/&gt;

Both of these editions saw multiple [[print run]]s each incorporating newly found corrections. Starting with the third printing&lt;!-- 1967 or 1969? --&gt;, updated table entries were marked by adding a small superscript number to the entry number indicating the corresponding print run ("3" etc.&lt;!-- print run "7" of 4th edition is documented for 1990 --&gt;), a convention carried over into later editions by continuing to increase the superscript number as kind of a [[revision number]] (no longer directly corresponding with actual print runs).

The fifth edition (1994), which contained close to 20&amp;thinsp;000 formulas,&lt;ref name="ZBL_918-65002"/&gt;&lt;ref group="nb" name="Formula_Entry"/&gt; was electronically reset&lt;ref name="REV_209_1"/&gt; in preparation for a CD-ROM issue of the fifth edition (1996) and in anticipation of further editions. Since the sixth edition (2000), now corresponding with superscript number "10", Daniel Zwillinger&lt;ref group="nb" name="Zwillinger_Bio"&gt;Daniel Zwillinger (1957–), {{GND|172475694}}.&lt;/ref&gt; started contributing as well. The last edition being edited by Jeffrey before his death&lt;ref group="nb" name="Jeffrey_Bio"/&gt; was the seventh English edition published in 2007 (with superscript number "11").&lt;ref name="Jeffrey_2007"&gt;{{cite book |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |editor-first1=Alan |editor-last1=Jeffrey |editor-first2=Daniel |editor-last2=Zwillinger |translator=((Scripta Technica, Inc.)) |title=Table of Integrals, Series, and Products |publisher=[[Academic Press, Inc.]] |date=February 2007 |edition=7 |isbn=978-0-12-373637-6 |id=GR:11 |mr=2360010 |url=https://books.google.com/books?id=aBgFYxKHUjsC |accessdate=2016-02-21}} [http://fisica.ciens.ucv.ve/~svincenz/TISPISGIMR.pdf]&lt;/ref&gt; This edition has been retranslated back into Russian as "seventh Russian edition" in 2011.&lt;ref name="APRU_2011"&gt;{{cite web |script-title=ru:Таблицы интегралов, ряда и продуктов |trans-title=Table of Integrals, Series, and Products |language=Russian |date=2011 |edition=7 |isbn=978-5-9775-0360-0 |publisher=[[:de:bhv (Verlag)|BHV]] (БХВ-Петербург) |url=http://www.apmath.spbu.ru/ru/staff/maximov/publ/publ1.pdf |accessdate=2016-03-16 |deadurl=no |archiveurl=https://web.archive.org/web/20160316120542/http://www.apmath.spbu.ru/ru/staff/maximov/publ/publ1.pdf |archivedate=2016-03-16}}&lt;/ref&gt;

For the eighth edition (2014/2015, with superscript number "12") Zwillinger took over the role of the editor. He was assisted by Victor Hugo Moll.&lt;ref name="Zwillinger_2014"&gt;{{cite book |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |author-first5=Alan |author-last5=Jeffrey |editor-first1=Daniel |editor-last1=Zwillinger |editor-first2=Victor Hugo |editor-last2=Moll |translator=((Scripta Technica, Inc.)) |title=Table of Integrals, Series, and Products |publisher=[[Academic Press, Inc.]] |date=2015 |orig-year=October 2014 |edition=8 |isbn=978-0-12-384933-5 |id=GR:12 |url=https://books.google.com/books?id=NjnLAwAAQBAJ |accessdate=2016-02-21}}&lt;/ref&gt;&lt;ref group="nb" name="Moll_Bio"&gt;Victor Hugo Moll (1956–), {{GND|173099572}}.&lt;/ref&gt; In order to make room for additional information without increasing the size of the book significantly, the former chapters 11 (on [[algebraic inequality|algebraic inequalities]]), chapters 13 to 16 (on [[matrix (mathematics)|matrices]] and related results, [[determinant]]s, [[norm (mathematics)|norm]]s, [[ordinary differential equation]]s) and chapter 18 (on [[z-transform]]s) worth about 50 pages in total were removed and some chapters renumbered (12 to 11, 17 to 12). This edition contains more than 10&amp;thinsp;000 entries.&lt;ref name="Zwillinger_2014"/&gt;&lt;ref group="nb" name="Formula_Entry"/&gt;

=={{anchor|Handbook|Proofs}}Related projects==
In 1995, Alan Jeffrey published his ''Handbook of Mathematical Formulas and Integrals''.&lt;ref name="Jeffrey_1995"/&gt;
It was partially based on the fifth English edition of Gradshteyn and Ryzhik's ''Table of Integrals, Series, and Products'' and meant as an companion, but written to be more accessible for students and practitioners.&lt;ref name="Jeffrey_1995"/&gt; It went through four editions up to 2008.&lt;ref name="Jeffrey_1995"&gt;{{cite book |title=Handbook of Mathematical Formulas and Integrals |author-first=Alan |author-last=Jeffrey |edition=1 |date=1995-01-01 |publisher=[[Academic Press, Inc.]] |isbn=978-0-12-382580-3}}&lt;/ref&gt;&lt;ref name="Jeffrey_2000"&gt;{{cite book |title=Handbook of Mathematical Formulas and Integrals |author-first=Alan |author-last=Jeffrey |edition=2 |date=2000-08-01 |publisher=[[Academic Press, Inc.]] |isbn=978-0-12-382251-2 &lt;!-- correct scan, but wrong photo and data |url=https://books.google.com/books?id=dMnNBQAAQBAJ |accessdate=2016-03-01 --&gt;}}&lt;/ref&gt;&lt;ref name="Jeffrey_2003"&gt;{{cite book |title=Handbook of Mathematical Formulas and Integrals |author-first=Alan |author-last=Jeffrey |edition=3 |date=2004 |publication-date=2003-11-21 |publisher=[[Academic Press, Inc.]] |isbn=978-0-12-382256-7 &lt;!-- correct photo and data, but wrong scan |url=https://books.google.com/books?id=CL-C629xrCIC--&gt; |url=http://www.sciencedirect.com/science/book/9780123822567 |accessdate=2016-03-01}}&lt;/ref&gt;&lt;ref name="Jeffrey_2008"&gt;{{cite book |title=Handbook of Mathematical Formulas and Integrals |author-first1=Alan |author-last1=Jeffrey |author-first2=Hui-Hui |author-last2=Dai |edition=4 |date=2008-02-01 |publisher=[[Academic Press, Inc.]] |isbn=978-0-12-374288-9 |url=https://books.google.com/books/about/Handbook_of_Mathematical_Formulas_and_In.html?id=JokQD5nK4LMC |accessdate=2016-03-01}} (NB. Contents of companion CD-ROM: [http://booksite.elsevier.com/9780123742889/&lt;!-- https://web.archive.org/web/20160803194503/http://booksite.elsevier.com/9780123742889/ --&gt;] [http://booksite.elsevier.com/9780123742889/content/cd_resources.zip&lt;!-- https://web.archive.org/web/*/http://booksite.elsevier.com/9780123742889/content/cd_resources.zip --&gt;])&lt;/ref&gt; The fourth edition also took advantage of changes incorporated into the seventh English edition of Gradshteyn and Ryzhik.&lt;ref name="Jeffrey_2008"/&gt;

Inspired by a 1988 paper in which Ilan Vardi proved several integrals in ''Gradshteyn and Ryzhik''&lt;ref name="Vardi_1988"&gt;{{cite journal|title=Integrals: An Introduction to Analytic Number Theory |author-first=Ilan |author-last=Vardi |date=April 1988 |pages=308–315 |journal=[[American Mathematical Monthly]] |volume=95 |issue=4 |doi=10.2307/2323562 |url=http://www.les-mathematiques.net/phorum/file.php?2,file=4114,filename=ArtRMS.pdf |accessdate=2016-03-14 |dead-url=no |archive-url=https://web.archive.org/web/20160315003619/http://www.les-mathematiques.net/phorum/file.php?2%2Cfile=4114%2Cfilename%3DArtRMS.pdf |archivedate=2016-03-15 |df= }} [http://www.les-mathematiques.net/phorum/file.php?2,file=4114,filename=ArtRMS.pdf]&lt;/ref&gt; Victor Hugo Moll with George Boros started a project to prove all integrals listed in ''Gradshteyn and Ryzhik'' and add additional commentary and references.&lt;ref name="Moll_2010"&gt;{{cite journal |title=Seized Opportunities |journal=[[Notices of the American Mathematical Society]] |author-first=Victor Hugo |author-last=Moll |date=April 2010 |orig-year=2009-08-30 |volume=57 |number=4 |pages=476–484 |url=http://www.ams.org/notices/201004/rtx100400476p.pdf |accessdate=2016-04-08 |dead-url=no |archive-url=https://web.archive.org/web/20160408230355/http://www.ams.org/notices/201004/rtx100400476p.pdf |archivedate=2016-04-08}} [http://www.math.tulane.edu/~vhm/papers_html/seized.pdf]&lt;/ref&gt; In the foreword of the book ''Irresistible Integrals'' (2004), they wrote:&lt;ref name="Boros_2004"&gt;{{cite book |author-first1=George |author-last1=Boros |author-first2=Victor Hugo |author-last2=Moll |title=Irresistible Integrals. Symbolics, Analysis and Experiments in the Evaluation of Integrals |publisher=[[Cambridge University Press]] (CUP) |date=2006 |orig-year=September 2004 |edition=reprinted&lt;!-- 2006 --&gt; 1st |isbn=978-0-521-79186-1|page=xi |url=https://books.google.com/books?id=g9tH8M3NvDIC |accessdate=2016-02-22}} [http://www.cambridge.org/en/academic/subjects/mathematics/abstract-analysis/irresistible-integrals-symbolics-analysis-and-experiments-evaluation-integrals?format=PB&amp;isbn=9780521796361] [http://assets.cambridge.org/97805217/96361/frontmatter/9780521796361_frontmatter.pdf] (NB. This edition contains many typographical errors.)&lt;/ref&gt;
{{quote|It took a short time to realize that this task was monumental.}}
Nevertheless, the efforts have meanwhile resulted in about 900&lt;!-- count of entries in articles 1-30: 10+5+8+44+10+65+30+7+45+76+52+6+21+1+(12[-1])+36+36+(7[+3])+42+26+75+36+54+10+18+41+37+17+(19[+16])+51=897[+18] --&gt; entries from ''Gradshteyn and Ryzhik'' discussed in a series of more than 30 articles&lt;ref name="Moll_Scientia_Part_29"&gt;{{anchor|Moll-29}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 29: Chebyshev polynomials |author-first1=Victor Hugo |author-last1=Moll |author-first2=Christophe |author-last2=Vignat &lt;!-- |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=?? |publicationdate=2016??? |date=|orig-year=|pages=– --&gt;|url=http://www.math.tulane.edu/~vhm/formula_html/final29.pdf |accessdate=2016-03-13 |dead-url=no |archive-url=https://web.archive.org/web/20160313025625/http://129.81.170.14/~vhm/formula_html/final29.pdf |archivedate=2016-03-13}} (NB. This paper discusses 19&lt;!-- +16 --&gt; GR entries: 1.14.2.1, 1.320&lt;!-- 8 entries --&gt;, 2.18.1.9, 3.753.2, 3.771.8, 6.611&lt;!-- 10 entries --&gt;, 7.341.1, 7.341.2, 7.342&lt;!-- 1 entry --&gt;, 7.343.1, 7.344.1, 7.344.2, 7.346&lt;!-- 1 entry --&gt;, 7.348&lt;!-- 1 entry --&gt;, 7.349&lt;!-- 1 entry --&gt;, 7.355.1, 7.355.2, 8.411.1, 8.921&lt;!-- 1 entry --&gt;. [http://www.math.tulane.edu/~vhm/part29-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_30"&gt;{{anchor|Moll-30}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 30: Trigonometric functions |author-first1=Tewodros |author-last1=Amdeberhan |author-first2=Atul |author-last2=Dixit |author-first3=Xiao |author-last3=Guan |author-first4=Lin |author-last4=Jiu |author-first5=Alexey |author-last5=Kuznetsov |author-first6=Victor Hugo |author-last6=Moll |author-first7=Christophe |author-last7=Vignat &lt;!-- |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=?? |publicationdate=2016??? |date=|orig-year=|pages=– --&gt;|url=http://www.math.tulane.edu/~vhm/formula_html/final30.pdf |accessdate=2016-03-13 |dead-url=no |archive-url=https://web.archive.org/web/20160313025646/http://129.81.170.14/~vhm/formula_html/final30.pdf |archivedate=2016-03-13}} (NB. This paper discusses 51 GR entries: 1.320.1, 1.320.3, 1.320.5, 1.320.7, 2.01.5, 2.01.6, 2.01.7, 2.01.8, 2.01.9, 2.01.10, 2.01.11, 2.01.12, 2.01.13, 2.01.14, 2.513.1, 2.513.2, 2.513.3, 2.513.4, 3.231.5, 3.274.2, 3.541.8, 3.611.3, 3.621.3, 3.621.4, 3.624.6, 3.631.16, 3.661.3, 3.661.4, 3.675.1, 3.675.2, 3.688.1, 3.721.1, 3.747.7, 3.761.4, 4.381.1, 4.381.2, 4.381.3, 4.381.4, 4.521.1, 6.671.7, 6.671.8, 7.244.1, 7.244.2, 7.531.1, 7.531.2, 8.230.1, 8.230.2, 8.361.7, 8.370&lt;!-- 1 entry --&gt;, 8.910.2, 8.911.1. It also contains 1 errata for GR entry 3.541.8. [http://www.math.tulane.edu/~vhm/part30-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_X1"&gt;{{anchor|Moll-X1}}{{cite journal |title=Evaluation of entries in Gradshteyn and Ryzhik employing the method of brackets |author-first1=Ivan |author-last1=Gonzalez |author-first2=Karen T. |author-last2=Kohl |author-first3=Victor Hugo |author-last3=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=25 |publication-date=2014 |date=2014-06-13 |orig-year=2014-03-19 |pages=65–84 |url=http://www.mat.utfsm.cl/scientia/archivos/vol25/articulo8.pdf |accessdate=2016-03-13}} (NB. This paper is also incorporated into [[#Moll-V2|volume II]].)&lt;/ref&gt; of which papers 1 to 28&lt;!-- &lt;ref name="Moll_Paper_1"&gt;{{cite paper |title=The Integrals in Gradshteyn and Rhyzik. Part 1: a family of logarithmic integrals |author-first=Victor Hugo |author-last=Moll |date=2006 |url=http://www.math.tulane.edu/~vhm/papers_html/scientia1.pdf |accessdate=2016-03-07}}&lt;/ref&gt;--&gt;&lt;ref name="Moll_Scientia_Part_1"&gt;{{anchor|Moll-1}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 1: A family of logarithmic integrals |author-first=Victor Hugo |author-last=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=14 |publication-date=2007 |date=2006-11-06 |orig-year=2006-07-21 |pages=1–6 |url=http://www.mat.utfsm.cl/scientia/archivos/vol14/a12007.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final1.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 10 GR entries: 3.419.2, 3.419.3, 3.419.4, 3.419.5, 3.419.6, 4.232.3, 4.261.4, 4.262.3, 4.263.1, 4.264.3. [http://www.math.tulane.edu/~vhm/part1-index.pdf])&lt;/ref&gt;&lt;!-- &lt;ref name="Moll_Paper_2"&gt;{{cite paper |title=The Integrals in Gradshteyn and Rhyzik. Part 2: Elementary Logarithmic Integrals |author-first=Victor Hugo |author-last=Moll |date=2006 |url=http://www.math.tulane.edu/~vhm/papers_html/scientia2.pdf |accessdate=2016-03-07}}&lt;/ref&gt; --&gt;&lt;ref name="Moll_Scientia_Part_2"&gt;{{anchor|Moll-2}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 2: Elementary logarithmic integrals |author-first=Victor Hugo |author-last=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=14 |publication-date=2007 |orig-year=2006-06-27 |date=2006-11-06 |pages=7–15 | url=http://www.mat.utfsm.cl/scientia/archivos/vol14/a22007.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final2.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 5 GR entries: 4.231.1, 4.231.5, 4.231.6, 4.232.1, 4.232.2. [http://www.math.tulane.edu/~vhm/part2-index.pdf])&lt;/ref&gt;&lt;!-- &lt;ref name="Moll_Paper_3"&gt;{{cite paper |title=The Integrals in Gradshteyn and Rhyzik. Part 3: Combinations of logarithms and exponentials |author-first=Victor Hugo |author-last=Moll |date=2006 |url=http://www.math.tulane.edu/~vhm/papers_html/scientia3.pdf |accessdate=2016-03-07}}&lt;/ref&gt; --&gt;&lt;ref name="Moll_Scientia_Part_3"&gt;{{anchor|Moll-3}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 3: Combinations of logarithms and exponentials |author-first=Victor Hugo |author-last=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=15 |publication-date=2007 |orig-year=2006-12-27 |date=2007-01-16 |pages=31–36 | url=http://www.mat.utfsm.cl/scientia/archivos/vol15/ar4.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final3.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 8 GR entries: 4.331.1, 4.335.1, 4.335.3, 4.352.1, 4.352.2, 4.352.3, 4.352.4, 4.353.2. [http://www.math.tulane.edu/~vhm/part3-index.pdf])&lt;/ref&gt;&lt;!-- &lt;ref name="Moll_Paper_4"&gt;{{cite paper |title=The Integrals in Gradshteyn and Ryzhik. Part 4: The Gamma function |author-first=Victor Hugo |author-last=Moll |date=2007-05-01 |arxiv=0705.0179v1 |url=http://www.researchgate.net/profile/Victor_Moll3/publication/1888563_The_integrals_in_Gradshteyn_and_Ryzhik._Part_4_The_Gamma_function/links/02bfe51124ba46d842000000.pdf |accessdate=2016-03-08}} [http://www.math.tulane.edu/~vhm/papers_html/scientia4.pdf]&lt;/ref&gt; --&gt;&lt;ref name="Moll_Scientia_Part_4"&gt;{{anchor|Moll-4}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 4: The gamma function |author-first=Victor Hugo |author-last=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=15 |publication-date=2007 |date=2007-01-16 |orig-year=2006-12-27 |pages=37–46 | url=http://www.mat.utfsm.cl/scientia/archivos/vol15/ar5.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final4.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 44 GR entries: 3.324.2, 3.326.1, 3.326.2, 3.328, 3.351.3, 3.371&lt;!-- 1 entry --&gt;, 3.381.4, 3.382.2, 3.434.1, 3.434.2, 3.461.2, 3.461.3, 3.462.9, 3.471.3, 3.478.1, 3.478.2, 3.481.1, 3.481.2, 4.215.1, 4.215.2, 4.215.3, 4.215.4, 4.229.1, 4.229.3, 4.229.4, 4.269.3, 4.272.5, 4.272.6, 4.272.7, 4.325.8, 4.325.11, 4.325.12,, 4.331.1 4.333, 4.335.1, 4.335.3, 4.355.1, 4.355.3, 4.355.4, 4.358.2, 4.358.3, 4.358.4, 4.369.1, 4.369.2. [http://www.math.tulane.edu/~vhm/part4-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_5"&gt;{{anchor|Moll-5}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 5: Some trigonometric integrals |author-first1=Tewodros |author-last1=Amdeberhan |author-first2=Luis A. |author-last2=Medina |author-first3=Victor Hugo |author-last3=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=15 |publication-date=2007 |date=2007-01-16 |orig-year=2006-12-27 |pages=47–60 | url=http://www.mat.utfsm.cl/scientia/archivos/vol15/ar6.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final5.pdf] [http://emmy.uprrp.edu/lmedina/papers/part5/Part5.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 10 GR entries: 3.621.1, 3.621.3, 3.621.4, 3.761.11, 3.764.1, 3.764.2, 3.821.3, 3.821.14, 3.822.1, 3.822.2. [http://www.math.tulane.edu/~vhm/part5-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_6"&gt;{{anchor|Moll-6}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 6: The beta function |author-first=Victor Hugo |author-last=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=16 |publication-date=2008 |date=2007-10-31 |orig-year=2007-08-31 |pages=9–24 |url=http://www.mat.utfsm.cl/scientia/archivos/vol16/ar2.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final6.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 65 GR entries: 3.191.1, 3.191.2, 3.191.3, 3.192.1, 3.192.2, 3.193&lt;!-- 1 entry --&gt;, 3.194.3, 3.194.4, 3.194.6, 3.194.7, 3.196.2, 3.196.3, 3.196.4, 3.196.5, 3.216.1, 3.216.2, 3.217&lt;!-- 1 entry --&gt;, 3.218&lt;!-- 1 entry --&gt;, 3.221.1, 3.221.2, 3.222.2, 3.223.1, 3.223.2, 3.223.3, 3.224&lt;!-- 1 entry --&gt;, 3.225.1, 3.225.2, 3.225.3, 3.226.1, 3.226.2, 3.241.2, 3.241.4, 3.241.5, 3.248.1, 3.248.2, 3.248.3, 3.249.1, 3.249.2, 3.249.5, 3.249.7, 3.249.8, 3.251.1, 3.251.2, 3.251.3, 3.251.4, 3.251.5, 3.251.6, 3.251.8, 3.251.9, 3.251.10, 3.251.11, 3.267.1, 3.267.2, 3.267.3, 3.311.3, 3.311.9, 3.312.1, 3.313.1, 3.313.2, 3.314&lt;!-- 1 entry --&gt;, 3.457.3, 4.251.1, 4.273&lt;!-- 1 entry --&gt;, 4.275.1, 4.321.1. [http://www.math.tulane.edu/~vhm/part6-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_7"&gt;{{anchor|Moll-7}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 7: Elementary examples |author-first1=Tewodros |author-last1=Amdeberhan |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=16 |publication-date=2008 |date=2007-10-31 |orig-year=2007-08-21 |pages=25–39 |url=http://www.mat.utfsm.cl/scientia/archivos/vol16/ar3.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final7.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 30 GR entries: 2.321.1, 2.321.2, 2.322.1, 2.322.2, 2.322.3, 2.322.4, 3.195&lt;!-- 1 entry --&gt;, 3.248.4, 3.248.6, 3.249.1, 3.249.6, 3.252.1, 3.252.2, 3.252.3, 3.268.1, 3.310&lt;!-- 1 entry --&gt;, 3.311.1, 3.351.1, 3.351.2, 3.351.7, 3.351.8, 3.351.9, 3.353.4, 3.411.19, 3.411.20, 3.471.1, 3.622.3, 3.622.4, 4.212.7, 4.222.1. [http://www.math.tulane.edu/~vhm/part7-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_8"&gt;{{anchor|Moll-8}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 8: Combinations of powers, exponentials and logarithms |author-first1=Victor Hugo |author-last1=Moll |author-first2=Jason |author-last2=Rosenberg |author-first3=Armin |author-last3=Straub |author-first4=Pat |author-last4=Whitworth |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=16 |publication-date=2008 |date=2007-10-31 |orig-year=2007-08-31 |pages=41–50 |url=http://www.mat.utfsm.cl/scientia/archivos/vol16/ar4.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final8.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 7 GR entries: 3.351.1, 4.331.1, 4.351.1, 4.351.2, 4.353.3, 4.362.1, 8.350.1. [http://www.math.tulane.edu/~vhm/part8-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_9"&gt;{{anchor|Moll-9}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 9: Combinations of logarithms, rational and trigonometric functions |author-first1=Tewodros |author-last1=Amdeberhan |author-first2=Victor Hugo |author-last2=Moll |author-first3=Jason |author-last3=Rosenberg |author-first4=Armin |author-last4=Straub |author-first5=Pat |author-last5=Whitworth |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=17 |publication-date=2009 |date=2008-11-18 |orig-year=2007-11-29 |pages=27–44 |url=http://www.mat.utfsm.cl/scientia/archivos/vol17/ar5.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final9.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 45 GR entries: 2.148.4, 3.747.7, 4.223.1, 4.223.2, 4.224.1, 4.224.2, 4.224.3, 4.224.4, 4.224.5, 4.224.6, 4.225.1, 4.225.2, 4.227.1, 4.227.2, 4.227.3, 4.227.9, 4.227.10, 4.227.11, 4.227.13, 4.227.14, 4.227.15, 4.231.1, 4.231.2, 4.231.3, 4.231.4, 4.231.8, 4.231.9, 4.231.11, 4.231.12, 4.231.13, 4.231.14, 4.231.15, 4.231.19, 4.231.20, 4.233.1, 4.261.8, 4.291.1, 4.291.2, 4.295.5, 4.295.6, 4.295.11, 4.521.1, 4.531.1, 8.366.3, 8.380.3. [http://www.math.tulane.edu/~vhm/part9-index.pdf])&lt;/ref&gt;&lt;!-- &lt;ref name="Moll_Paper_10"&gt;{{cite paper |title=The Integrals in Gradshteyn and Ryzhik. Part 10: The Digamma Function |author-first1=Luis A. |author-last1=Medina |author-first2=Victor Hugo |author-last2=Moll |date=2007-09-24 |arxiv=0709.3446v2}}&lt;/ref&gt; --&gt;&lt;ref name="Moll_Scientia_Part_10"&gt;{{anchor|Moll-10}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 10: The digamma function |author-first1=Luis A. |author-last1=Medina |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=17 |publication-date=2009 |date=2008-11-18 |orig-year=2007-11-29 |pages=45–66 |url=http://www.mat.utfsm.cl/scientia/archivos/vol17/ar6.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final10.pdf] [http://emmy.uprrp.edu/lmedina/papers/part10/Part10.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 76 GR entries: 3.219&lt;!-- 1 entry --&gt;, 3.231.1, 3.231.3, 3.231.5, 3.231.6, 3.233&lt;!-- 1 entry --&gt;, 3.234.1, 3.235&lt;!-- 1 entry --&gt;, 3.244.2, 3.244.3, 3.265&lt;!-- 1 entry --&gt;, 3.268.2, 3.269.1, 3.269.3, 3.311.5, 3.311.6, 3.311.7, 3.311.8, 3.311.10, 3.311.11, 3.311.12, 3.312.2, 3.316&lt;!-- 1 entry --&gt;, 3.317.1, 3.317.2, 3.427.1, 3.427.2, 3.429&lt;!-- 1 entry --&gt;, 3.434.2, 3.435.3, 3.435.4, 3.442.3, 3.457.1, 3.463&lt;!-- 1 entry --&gt;, 3.467&lt;!-- 1 entry --&gt;, 3.469.2, 3.469.3, 3.471.14, 3.475.1, 3.475.2, 3.475.3, 3.476.1, 3.476.2, 4.241.1, 4.241.2, 4.241.3, 4.241.4, 4.241.5, 4.241.7, 4.241.8, 4.241.9, 4.241.10, 4.241.11, 4.243&lt;!-- 1 entry --&gt;, 4.244.1, 4.244.2, 4.244.3, 4.245.1, 4.245.2, 4.246&lt;!-- 1 entry --&gt;, 4.247.1, 4.247.2, 4.251.4, 4.253.1, 4.254.1, 4.254.6, 4.256&lt;!-- 1 entry --&gt;, 4.271.15, 4.275.2, 4.281.1, 4.281.4, 4.281.5, 4.293.8, 4.293.13, 4.331.1, 8.371.2. [http://www.math.tulane.edu/~vhm/part10-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_11"&gt;{{anchor|Moll-11}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 11: The incomplete beta function |author-first1=Khristo N. |author-last1=Boyadzhiev |author-first2=Luis A. |author-last2=Medina |author-first3=Victor Hugo |author-last3=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=18 |publication-date=2009 |date=2009-03-16 |orig-year=2008-07-02 |pages=61–75 |url=http://www.mat.utfsm.cl/scientia/archivos/vol18/ar6.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final11.pdf] [http://emmy.uprrp.edu/lmedina/papers/part11/Part11.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 52 GR entries: 3.222.1, 3.231.2, 3.231.4, 3.241.1, 3.244.1, 3.249.4, 3.251.7, 3.269.2, 3.311.2, 3.311.13, 3.522.4, 3.541.6, 3.541.7, 3.541.8, 3.622.2, 3.623.2, 3.623.3, 3.624.1, 3.635.1, 3.651.1, 3.651.2, 3.656.1, 3.981.3, 4.231.1, 4.231.6, 4.231.11, 4.231.12, 4.231.14, 4.231.19, 4.231.20, 4.234.1, 4.234.2, 4.251.3, 4.254.4, 4.261.2, 4.261.6, 4.261.11, 4.262.1, 4.262.4, 4.263.2, 4.264.1, 4.265&lt;!-- 1 entry --&gt;, 4.266.1, 4.271.1, 4.271.16, 8.361.7, 8.365.4, 8.366.3, 8.366.11, 8.366.12, 8.366.13, 8.370&lt;!-- 1 entry --&gt;. [http://www.math.tulane.edu/~vhm/part11-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_12"&gt;{{anchor|Moll-12}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 12: Some logarithmic integrals |author-first1=Victor Hugo |author-last1=Moll |author-first2=Ronald A. |author-last2=Posey |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=18 |publication-date=2009 |date=2009-03-16 |orig-year=2008-07-02 |pages=77–84 |url=http://www.mat.utfsm.cl/scientia/archivos/vol18/ar7.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final2.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 6 GR entries: 4.231.1, 4.233.1, 4.233.2, 4.233.3, 4.233.4, 4.261.8. [http://www.math.tulane.edu/~vhm/part12-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_13"&gt;{{anchor|Moll-13}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 13: Trigonometric forms of the beta function |author-first=Victor Hugo |author-last=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=19 |publication-date=2010 |date=2010-10-10 |orig-year=2009-07-07 |pages=91–96 |url=http://www.mat.utfsm.cl/scientia/archivos/vol19/vol19art11.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final3.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 21 GR entries: 3.621.1, 3.621.2, 3.621.3, 3.621.4, 3.621.5, 3.621.6, 3.621.7, 3.622.1, 3.623.1, 3.624.2, 3.624.3, 3.624.4, 3.624.5, 3.625.1, 3.625.2, 3.625.3, 3.625.4, 3.626.1, 3.626.2, 3.627&lt;!-- 1 entry --&gt;, 3.628&lt;!-- 1 entry --&gt;. [http://www.math.tulane.edu/~vhm/part13-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_14"&gt;{{anchor|Moll-14}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 14: An elementary evaluation of entry 3.411.5 |author-first1=Tewodros |author-last1=Amdeberhan |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=19 |publication-date=2010 |date=2010-10-10 |orig-year=2009-07-07 |pages=97–103 |url=http://www.mat.utfsm.cl/scientia/archivos/vol19/vol19art12.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final14.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 1 GR entry: 3.411.5. [http://www.math.tulane.edu/~vhm/part14-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_15"&gt;{{anchor|Moll-15}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 15: Frullani integrals |author-first1=Matthew |author-last1=Albano |author-first2=Tewodros |author-last2=Amdeberhan |author-first3=Erin |author-last3=Beyerstedt |author-first4=Victor Hugo |author-last4=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=19 |publication-date=2010 |date=2010-07-18 |orig-year=2010-04-20 |pages=113–119 |url=http://www.mat.utfsm.cl/scientia/archivos/vol19/vol19art14.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final15.pdf] (NB. This paper (from [[#Moll-V1|volume I]]) discusses 12&lt;!-- -1 --&gt; GR entries: 3.232&lt;!-- 1 entry --&gt;, 3.329&lt;!-- 0 entry --&gt;, 3.412.1, 3.434.2, 3.436&lt;!-- 1 entry --&gt;, 3.476.1, 3.484&lt;!-- 1 entry --&gt;, 4.267.8, 4.297.7, 4.319.3, 4.324.2, 4.536.2. [http://www.math.tulane.edu/~vhm/part15-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_16"&gt;{{anchor|Moll-16}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 16: Complete elliptic integrals |author-first1=Stefan Thomas |author-last1=Boettner |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=20 |publication-date=2010 |date=2010-07-21 |orig-year=2010-03-22 |pages=45–59 |url=http://www.mat.utfsm.cl/scientia/archivos/vol20/vol20art4.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final16.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 36 GR entries: 1.421.1, 3.166.16, 3.166.18, 3.721.1, 3.821.7, 3.841.1, 3.841.2, 3.841.3, 3.841.4, 3.842.3, 3.842.4, 3.844.1, 3.844.2, 3.844.3, 3.844.4, 3.844.5, 3.844.6, 3.844.7, 3.844.8, 3.846.1, 3.846.2, 3.846.3, 3.846.4, 3.846.5, 3.846.6, 3.846.7, 3.846.8, 4.242.1, 4.395.1, 4.414.1, 4.432.1, 4.522.4, 4.522.5, 4.522.6, 4.522.7, 8.129.1. [http://www.math.tulane.edu/~vhm/part16-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_17"&gt;{{anchor|Moll-17}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 17: The Riemann zeta function |author-first1=Tewodros |author-last1=Amdeberhan |author-first2=Khristo N. |author-last2=Boyadzhiev |author-first3=Victor Hugo |author-last3=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=20 |publication-date=2010 |date=2010-07-21 |orig-year=2010-03-22 |pages=61–71 |url=http://www.mat.utfsm.cl/scientia/archivos/vol20/vol20art5.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final17.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 36 GR entries: 3.333.1, 3.333.2, 3.411.1, 3.411.2, 3.411.3, 3.411.4, 3.411.6, 3.411.7, 3.411.8, 3.411.9, 3.411.10, 3.411.11, 3.411.12, 3.411.13, 3.411.14, 3.411.15, 3.411.17, 3.411.18, 3.411.21, 3.411.22, 3.411.25, 3.411.26, 4.231.1, 4.231.2, 4.261.12, 4.261.13, 4.262.1, 4.262.2, 4.262.5, 4.262.6, 4.264.1, 4.264.2, 4.266.1, 4.266.2, 4.271.1, 4.271.2. [http://www.math.tulane.edu/~vhm/part17-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_18"&gt;{{anchor|Moll-18}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 18: Some automatic proofs |author-first1=Christoph |author-last1=Koutschan |author-link1=Christoph Koutschan |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=20 |publication-date=2010&lt;!-- article itself erroneously states 2011 --&gt; |date=2010-08-21 |orig-year=2010-04-26 |pages=93–111 |url=http://www.mat.utfsm.cl/scientia/archivos/vol20/vol20art8.pdf |accessdate=2016-03-14 |deadurl=no |archiveurl=https://web.archive.org/web/20160314005548/http://www.mat.utfsm.cl/scientia/archivos/vol20/vol20art8.pdf |archivedate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final18.pdf] [http://www.koutschan.de/publ/KoutschanMoll11/final18.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 7&lt;!-- +3 --&gt; GR entries: 2.148.3, 3.953&lt;!-- 4 entries --&gt;, 4.535.1, 6.512.1, 7.322&lt;!-- 1 entry --&gt;, 7.349&lt;!-- 1 entry --&gt;, 7.512.5. [http://www.math.tulane.edu/~vhm/part18-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_19"&gt;{{anchor|Moll-19}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 19: The error function |author-first1=Matthew |author-last1=Albano |author-first2=Tewodros |author-last2=Amdeberhan |author-first3=Erin |author-last3=Beyerstedt |author-first4=Victor Hugo |author-last4=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=21 |publication-date=2011 |date=2011-04-13 |orig-year=2010-12-23 |pages=25–42 |url=http://www.mat.utfsm.cl/scientia/archivos/vol21/vol21art3.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final19.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 42 GR entries: 3.321.1, 3.321.2, 3.321.3, 3.321.4, 3.321.5, 3.321.6, 3.321.7, 3.322.1, 3.322.2, 3.323.1, 3.323.2, 3.325&lt;!-- 1 entry --&gt;, 3.361.1, 3.361.2, 3.361.3, 3.362.1, 3.362.2, 3.363.1, 3.363.2, 3.369&lt;!-- 1 entry --&gt;, 3.382.4, 3.461.5, 3.462.5, 3.462.6, 3.462.7, 3.462.8, 3.464&lt;!-- 1 entry --&gt;, 3.466.1, 3.466.2, 3.471.15, 3.471.16, 3.472.1, 6.281.1, 6.282.1, 6.283.1, 6.283.2, 6.294.1, 8.258.1, 8.258.2, 8.258.3, 8.258.4, 8.258.5. [http://www.math.tulane.edu/~vhm/part19-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_20"&gt;{{anchor|Moll-20}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 20: Hypergeometric functions |author-first1=Karen T. |author-last1=Kohl |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=21 |publication-date=2011 |date=2011-04-13 |orig-year=2010-12-23 |pages=43–54 |url=http://www.mat.utfsm.cl/scientia/archivos/vol21/vol21art4.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final20.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 26 GR entries: 3.194.1, 3.194.2, 3.194.5, 3.196.1, 3.197.1, 3.197.2, 3.197.3, 3.197.4, 3.197.5, 3.197.6, 3.197.7, 3.197.8, 3.197.9, 3.197.10, 3.197.11, 3.197.12, 3.198&lt;!-- 1 entry --&gt;, 3.199&lt;!-- 1 entry --&gt;, 3.227.1, 3.254.1, 3.254.2, 3.259.2, 3.312.3, 3.389.1, 9.121.4, 9.131.1. [http://www.math.tulane.edu/~vhm/part20-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_21"&gt;{{anchor|Moll-21}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 21: Hyperbolic functions |author-first1=Khristo N. |author-last1=Boyadzhiev |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=22 |publication-date=2012 |date=2012-10-20 |orig-year=2012-05-15 |pages=109–127 |url=http://www.math.tulane.edu/~vhm/formula_html/final21.pdf |accessdate=2016-03-14 |deadurl=no |archiveurl=https://web.archive.org/web/20160314010129/http://129.81.170.14/~vhm/formula_html/final21.pdf |archivedate=2016-03-14}} (NB. This paper (from [[#Moll-V2|volume II]]) discusses 75 GR entries: 2.423.9, 3.231.2, 3.231.5, 3.265&lt;!-- 1 entry --&gt;, 3.511.1, 3.511.2, 3.511.4, 3.511.5, 3.511.8, 3.512.1, 3.512.2, 3.521.1, 3.521.2, 3.522.3, 3.522.6, 3.522.8, 3.522.10, 3.523.2, 3.523.3, 3.523.4, 3.523.5, 3.523.6, 3.523.7, 3.523.8, 3.523.9, 3.523.10, 3.523.11, 3.523.12, 3.524.2, 3.524.4, 3.524.6, 3.524.8, 3.524.9, 3.524.10, 3.524.11, 3.524.12, 3.524.13, 3.524.14, 3.524.15, 3.524.16, 3.524.17, 3.524.18, 3.524.19, 3.524.20, 3.524.21, 3.524.22, 3.524.23, 3.525.1, 3.525.2, 3.525.3, 3.525.4, 3.525.5, 3.525.6, 3.525.7, 3.525.8, 3.527.1, 3.527.2, 3.527.3, 3.527.4, 3.527.5, 3.527.6, 3.527.7, 3.527.8, 3.527.9, 3.527.10, 3.527.11, 3.527.12, 3.527.13, 3.527.14, 3.527.15, 3.527.16, 3.543.2, 4.113.3, 4.231.12, 8.365.9. [http://www.math.tulane.edu/~vhm/part21-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_22"&gt;{{anchor|Moll-22}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 22: Bessel-K functions |author-first1=Larry |author-last1=Glasser |author-first2=Karen T. |author-last2=Kohl |author-first3=Christoph |author-last3=Koutschan |author-link3=Christoph Koutschan |author-first4=Victor Hugo |author-last4=Moll |author-first5=Armin |author-last5=Straub |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=22 |publication-date=2012 |date=2012-10-20 |orig-year=2012-05-15 |pages=129–151 |url=http://www.math.tulane.edu/~vhm/formula_html/final22.pdf |accessdate=2016-03-14 |deadurl=no |archiveurl=https://web.archive.org/web/20160314010242/http://129.81.170.14/~vhm/formula_html/final22.pdf |archivedate=2016-03-14}} [http://www.koutschan.de/publ/GlasserKohlKoutschanMollStraub12/final22.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 36 GR entries: 3.323.3, 3.324.1, 3.337.1, 3.364.3, 3.365.2, 3.366.2, 3.372&lt;!-- 1 entry --&gt;, 3.383.3, 3.383.8, 3.387.1, 3.387.3, 3.387.6, 3.388.2, 3.389.4, 3.391&lt;!-- 1 entry --&gt;, 3.395.1, 3.461.6, 3.461.7, 3.461.8, 3.461.9, 3.462.20, 3.462.21, 3.462.22, 3.462.23, 3.462.24, 3.462.25, 3.469.1, 3.471.4, 3.471.8, 3.471.9, 3.471.12, 3.478.4, 3.479.1, 3.547.2, 3.547.4, 8.432.6. [http://www.math.tulane.edu/~vhm/part22-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_23"&gt;{{anchor|Moll-23}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 23: Combination of logarithms and rational functions |author-first1=Luis A. |author-last1=Medina |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=23 |publication-date=2012 |date=2012-06-25 |orig-year=2012-02-01 |pages=1–18 |url=http://www.mat.utfsm.cl/scientia/archivos/vol23/articulo1vol23Rev.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final23.pdf] [http://emmy.uprrp.edu/lmedina/papers/part23/Part23.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 54 GR entries: 3.417.1, 3.417.2, 4.212.7, 4.224.5, 4.224.6, 4.225.1, 4.225.2, 4.231.1, 4.231.2, 4.231.8, 4.231.9, 4.231.10, 4.231.11, 4.231.16, 4.231.17, 4.231.18, 4.233.1, 4.234.3, 4.234.6, 4.234.7, 4.234.8, 4.262.7, 4.262.8, 4.262.9, 4.291.1, 4.291.2, 4.291.3, 4.291.4, 4.291.5, 4.291.6, 4.291.7, 4.291.8, 4.291.9, 4.291.10, 4.291.11, 4.291.12, 4.291.13, 4.291.14, 4.291.15, 4.291.16, 4.291.17, 4.291.18, 4.291.19, 4.291.20, 4.291.21, 4.291.22, 4.291.23, 4.291.24, 4.291.25, 4.291.26, 4.291.27, 4.291.28, 4.291.29, 4.291.30. [http://www.math.tulane.edu/~vhm/part23-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_24"&gt;{{anchor|Moll-24}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 24: Polylogarithm functions |author-first1=Kim |author-last1=McInturff |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=23 |publication-date=2012 |date=2012-07-28 |orig-year=2012-02-01 |pages=45–51 |url=http://www.mat.utfsm.cl/scientia/archivos/vol23/articulo5vol23Rev.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final24.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 10 GR entries: 3.418.1, 3.514.1, 3.531.1, 3.531.2, 3.531.3, 3.531.4, 3.531.5, 3.531.6, 3.531.7, 9.513.1. [http://www.math.tulane.edu/~vhm/part24-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_25"&gt;{{anchor|Moll-25}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 25: Evaluation by series |author-first=Victor Hugo |author-last=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=23 |publication-date=2012 |date=2012-07-28 |orig-year=2012-02-01 |pages=53–65 |url=http://www.mat.utfsm.cl/scientia/archivos/vol23/articulo6vol23Rev.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final25.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 18 GR entries: 3.194.8, 3.311.4, 3.342&lt;!-- 1 entry --&gt;, 3.451.1, 3.451.2, 3.466.3, 3.747.7, 4.221.1, 4.221.2, 4.221.3, 4.251.5, 4.251.6, 4.269.1, 4.269.2, 8.339.1, 8.339.2, 8.365.4, 8.366.3. [http://www.math.tulane.edu/~vhm/part25-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_26"&gt;{{anchor|Moll-26}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 26: The exponential integral |author-first1=Khristo N. |author-last1=Boyadzhiev |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=26 |publication-date=2015 |date=2015-01-30 |orig-year=2014-09-19 |pages=19–30 |url=http://www.mat.utfsm.cl/scientia/archivos/vol26/Articulo-3.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final26.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 41 GR entries: 3.327, 3.351.4, 3.351.5, 3.351.6, 3.352.1, 3.352.2, 3.352.3, 3.352.4, 3.352.5, 3.352.6, 3.353.1, 3.353.2, 3.353.3, 3.353.4, 3.353.5, 3.354.1, 3.354.2, 3.354.3, 3.354.4, 3.355.1, 3.355.2, 3.355.3, 3.355.4, 3.356.1, 3.356.2, 3.356.3, 3.356.4, 3.357.1, 3.357.2, 3.357.3, 3.357.4, 3.357.5, 3.357.6, 3.358.1, 3.358.2, 3.358.3, 3.358.4, 4.211.1, 4.211.2, 4.212.1, 4.212.2. [http://www.math.tulane.edu/~vhm/part26-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_27"&gt;{{anchor|Moll-27}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 27: More logarithmic examples |author-first2=Victor Hugo |author-last2=Moll |author-first1=Luis A. |author-last1=Medina |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=26 |publication-date=2015 |date=2015-01-30 |orig-year=2014-09-16 |pages=31–47 |url=http://www.mat.utfsm.cl/scientia/archivos/vol26/Articulo-4.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final27.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 37 GR entries: 3.194.3, 3.231.1, 3.231.5, 3.231.6, 3.241.3, 3.621.3, 3.621.5, 4.224.2, 4.231.1, 4.231.2, 4.231.8, 4.233.5, 4.234.4, 4.234.5, 4.235.1, 4.235.2, 4.235.3, 4.235.4, 4.241.5, 4.241.6, 4.241.7, 4.241.11, 4.251.1, 4.251.2, 4.252.1, 4.252.2, 4.252.3, 4.252.4, 4.254.2, 4.254.3, 4.255.2, 4.255.3, 4.257.1, 4.261.9, 4.261.15, 4.261.16, 4.297.8. [http://www.math.tulane.edu/~vhm/part27-index.pdf])&lt;/ref&gt;&lt;ref name="Moll_Scientia_Part_28"&gt;{{anchor|Moll-28}}{{cite journal |title=The integrals in Gradshteyn and Ryzhik. Part 28: The confluent hypergeometric function and Whittaker functions |author-first1=Atul |author-last1=Dixit |author-first2=Victor Hugo |author-last2=Moll |journal=[[Scientia (UTFSM journal)|Scientia]] |series=Series A: Mathematical Sciences |volume=26 |publication-date=2015 |date=2015-02-01 |orig-year=2014-09-30 |pages=49–61 |url=http://www.mat.utfsm.cl/scientia/archivos/vol26/Articulo-5.pdf |accessdate=2016-03-14}} [http://www.math.tulane.edu/~vhm/formula_html/final28.pdf] (NB. This paper (from [[#Moll-V2|volume II]]) discusses 17 GR entries: 7.612.1, 7.612.2, 7.621.1, 7.621.2, 7.621.3, 7.621.4, 7.621.5, 7.621.6, 7.621.7, 7.621.8, 7.621.9, 7.621.10, 7.621.11, 7.621.12, 8.334.2, 8.703, 9.211.4. [http://www.math.tulane.edu/~vhm/part28-index.pdf])&lt;/ref&gt; have been published in issues 14 to 26&lt;!-- except for 24 --&gt; of [[Scientia (UTFSM journal)|Scientia]], [[Universidad Técnica Federico Santa María]] (UTFSM), between 2007 and 2015&lt;ref name="Moll_Scientia"&gt;{{cite web |title=Index of the papers in Revista Scientia with formulas from GR |author-first=Victor Hugo |author-last=Moll |date=2012 |url=http://www.math.tulane.edu/~vhm/pap-index.html |accessdate=2016-02-17}}&lt;/ref&gt; and compiled into a two-volume book series ''Special Integrals of Gradshteyn and Ryzhik: the Proofs'' (2014–2015) already.&lt;ref name="Moll_SIGR1_2014"&gt;{{anchor|Moll-V1}}{{cite book |author-first=Victor Hugo |author-last=Moll |title=Special Integrals of Gradshteyn and Ryzhik: the Proofs – Volume I |volume=I |edition=1 |work=Series: Monographs and Research Notes in Mathematics |publisher=[[Chapman and Hall]]/[[CRC Press]]/[[Taylor &amp; Francis Group, LLC]] |date=2014-10-01 |publication-date=2014-11-12 |isbn=978-1-4822-5651-2 |url=https://books.google.com/books?id=dRYeBQAAQBAJ&amp;dq=9781482256512 |accessdate=2016-02-12}} (NB. This volume compiles ''[[Scientia (UTFSM journal)|Scientia]]'' papers [[#Moll-1|1]], [[#Moll-2|2]], [[#Moll-3|3]], [[#Moll-4|4]], [[#Moll-5|5]], [[#Moll-6|6]], [[#Moll-7|7]], [[#Moll-8|8]], [[#Moll-9|9]], [[#Moll-10|10]], [[#Moll-11|11]], [[#Moll-12|12]], [[#Moll-13|13]], [[#Moll-14|14]], [[#Moll-15|15]] from issues 14 to 19.)&lt;/ref&gt;&lt;ref name="Moll_SIGR2_2015"&gt;{{anchor|Moll-V2}}{{cite book |author-first=Victor Hugo |author-last=Moll |title=Special Integrals of Gradshteyn and Ryzhik: the Proofs – Volume II |volume=II |edition=1 |work=Series: Monographs and Research Notes in Mathematics |publisher=[[Chapman and Hall]]/[[CRC Press]]/[[Taylor &amp; Francis Group, LLC]] |date=2015-08-24 |publication-date=2015-10-27 |isbn=978-1-4822-5653-6 |url=https://books.google.com/books?id=jSzSCgAAQBAJ&amp;pg=PR6 |accessdate=2016-02-12}} (NB. This volume compiles 14 ''[[Scientia (UTFSM journal)|Scientia]]'' articles from issues 20, 21, 22, 23, 25 and 26 including papers [[#Moll-16|16]], [[#Moll-17|17]], [[#Moll-18|18]], [[#Moll-19|19]], [[#Moll-20|20]], [[#Moll-21|21]], [[#Moll-22|22]], [[#Moll-23|23]], [[#Moll-24|24]], [[#Moll-25|25]], [[#Moll-26|26]], [[#Moll-27|27]], [[#Moll-28|28]] and [[#Moll-X1|one]] unnumbered paper.&lt;!-- number of article "Evaluation of entries in Gradstheyn and Ryzhik employing the method of brackets" in issue 25, pages 65-84 is currently unknown --&gt;)&lt;/ref&gt;

==Editions==

==={{anchor|Russian}}Russian editions===
&lt;!-- ''Tablitsy Integralov, Summ, Riadov i Proizvedenii''
''Tablitsy Integralov, Summ, Riadov i Proizvedeniĭ''
''Tablitsy Integralov, Summ, Ryadov i Proizvedeniy'' --&gt;
* {{anchor|GR-R1}}{{cite book |author-first=И. М. |author-last=Рыжик |author-link=Иосиф Моисеевич Рыжик |script-title=ru:Таблицы интегралов, сумм, рядов и произведений &lt;!-- |title=Tablitsy integralov, summ, rjadov i proizvedenii --&gt; |trans-title=Tables of integrals, sums, series and products |date=1943 |publisher=[[Gosudarstvennoe Izdatel'stvo Tehniko-Teoretičeskoj Literatury]] ([[:ru:Государственное издательство технико-теоретической литературы|Государственное издательство технико-теоретической литературы]]) (GITTL / [[:ru:ГИТТЛ|ГИТТЛ]]) (Tehteoretizdat / Техтеоретиздат) |location=Moscow |edition=1 |language=Russian |lccn=ltf89006085}} 400 pages.&lt;ref name="RMT_219"&gt;{{cite journal |title=Recent Mathematical Tables 219: I. M. Ryzhik, Tablitsy Integralov, Summ, Riadov i Proizvedeniĭ, Leningrad, OGIZ, 1943 |author-first=Raymond Clare |author-last=Archibald |author-link=Raymond Clare Archibald |journal=[[Mathematical Tables and other Aids to Computation]] (MTAG) |publisher=[[American Mathematical Society]] |volume=1 |number=12 |date=October 1945 |pages=442–443 |id=RMT:219 |url=http://www.ams.org/journals/mcom/1945-01-012/S0025-5718-45-99071-5/S0025-5718-45-99071-5.pdf |accessdate=2016-03-04}}&lt;/ref&gt;&lt;ref name="ZBL_60-123"&gt;{{cite journal |title=Ryžik, I. M.: Tafeln von Integralen, Summen, Reihen und Produkten. Moskau-Leningrad: Staatsverlag für technisch-theoretische Literatur, 1943 |type=list |language=German |journal=[[Zentralblatt für Mathematik]] |volume=60 |issue=1 |page=123 |date=1957-04-01 |zbl=0060.12305 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=060&amp;count_=123 |accessdate=2016-02-16}}&lt;/ref&gt;
* {{anchor|GR-R2}}{{cite book |author-first=И. М. |author-last=Рыжик |author-link=Иосиф Моисеевич Рыжик |script-title=ru:Таблицы интегралов, сумм, рядов и произведений &lt;!-- |title=Tablitsy integralov, summ, rjadov i proizvedenii --&gt;|date=1948 |edition=2 |publisher=Gosudarstvennoe Izdatel'stvo Tehniko-Teoretičeskoj Literatury (Государственное издательство технико-теоретической литературы) (GITTL / ГИТТЛ) (Tehteoretizdat / Техтеоретиздат) |language=Russian |location=Moscow}} 400 pages.&lt;ref name="ZBL_34-070"&gt;{{cite journal |author-first=Wolfgang |author-last=Hahn |author-link=Wolfgang Hahn |location=Berlin, Germany |title=Ryd&lt;!-- sic --&gt;zik, I. M.: Tabellen für Integrale, Summen, Reihen und Produkte. 2. Aufl. Moskau, Leningrad: Staatsverlag für techn.-theor. Lit., 1948 |type=review |language=German |journal=[[Zentralblatt für Mathematik]] |volume=34 |issue=1/3 |page=70 |date=1950-07-05 |zbl=0034.07001 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=034&amp;count_=070 |accessdate=2016-02-16}}&lt;/ref&gt;
* {{anchor|GR-R3}}{{cite book |author-first1=И. М. |author-last1=Рыжик |author-link1=Иосиф Моисеевич Рыжик |author-first2=И. С. |author-last2=Градштейн |author-link2=Израиль Соломонович Градштейн |script-title=ru:Таблицы интегралов, сумм, рядов и произведений &lt;!-- |title=Tablitsy integralov, summ, rjadov i proizvedenii --&gt;|date=1951 |edition=3 |publisher=Gosudarstvennoe Izdatel'stvo Tehniko-Teoretičeskoj Literatury (Государственное издательство технико-теоретической литературы) (GITTL / ГИТТЛ) (Tehteoretizdat / Техтеоретиздат) |language=Russian |location=Moscow |lccn=52034158}} 464 pages (+ errata inlet).&lt;ref name="ZBL_60-123"/&gt;&lt;ref name="ZBL_44-133"&gt;{{cite journal |author-first=Karl |author-last=Prachar |author-link=Karl Prachar |title=Ryžik, I. M. und I. S. Gradštejn: Tafeln von Integralen, Summen, Reihen und Produkten. 3. umgearb. Aufl. Moskau-Leningrad: Staatsverlag für technisch-theoretische Literatur, 1951 |type=review |language=German |journal=[[Zentralblatt für Mathematik]] |volume=44 |issue=1/5 |page=133 |date=1952-09-01 |zbl=0044.13303 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=044&amp;count_=133 |accessdate=2016-02-16}}&lt;/ref&gt;&lt;ref name="MTE_293"/&gt;
* {{anchor|GR-R4}}{{cite book |author-first1=И. С. |author-last1=Градштейн |author-link1=Израиль Соломонович Градштейн |author-first2=И. М. |author-last2=Рыжик |author-link2=Иосиф Моисеевич Рыжик |editor-first1=Ю. В. |editor-last1=Геронимус |editor-link1=Юрий Венеаминович Геронимус |editor-first2=М. Ю́. |editor-last2=Цейтлин&lt;!-- Cejtlin --&gt; |editor-link2=Михаил Ю́льевич Цейтлин |script-title=ru:Таблицы интегралов, сумм, рядов и произведений&lt;!-- |title=Tablitsy Integralov, Summ, Ryadov i Proizvedeniy --&gt; |language=Russian |edition=4 |date=1963 |orig-year=1962 |lccn=63027211 |publisher=[[Gosudarstvennoe Izdatel'stvo Fiziko-Matematicheskoy Literatury]] ([[:ru:Государственное издательство физико-математической литературы|Государственное издательство физико-математической литературы]]) (Fizmatgiz&lt;!-- also seen: Fizmatigiz --&gt; / [[:ru:Физматгиз|Физматгиз]]) |location=Moscow |url=https://books.google.com/books/about/Tablitsy_Integralov_Summ_Riadov_I_Proizv.html?id=lDNNmQEACAAJ}} 1100 pages (+ 8 page errata inlet&lt;!-- pages 1101–1108 --&gt; in later print runs).[http://www.vixri.com/d/Gradshtejn,%20Ryzhikov_Tablicy%20Integralov.pdf]&lt;ref name="ZBL_103-038"&gt;{{cite journal |author-first=Evert Marie |author-last=Bruins |title=Gradšteĭn, I. S., und I. M. Ryžik: Integral-, Summen-, Reihen- und Produkttafeln. (Tablicy integralov, summ, rjadov i proizvedeniĭ) 4. Aufl. überarb. unter Mitwirkung von Ju. V. Geronimus und M. Ju. Ceĭtlin. Moskau: Staatsverlag für physikalisch-mathematische Literatur, 1962 |type=list |language=German |journal=[[Zentralblatt für Mathematik]] |volume=103 |issue=1 |page=38 |date=1964-01-02 |zbl=0103.03801 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=103&amp;count_=038 |accessdate=2016-02-16}}&lt;/ref&gt; Errata:&lt;ref name="GR_1971"&gt;{{cite book |chapter=Errata in 4th edition&lt;!-- Actual Russian title TBD --&gt; |author-first1=И. С. |author-last1=Градштейн |author-link1=Израиль Соломонович Градштейн |author-first2=И. М. |author-last2=Рыжик |author-link2=Иосиф Моисеевич Рыжик |editor-first1=Ю. В. |editor-last1=Геронимус |editor-link1=Юрий Венеаминович Геронимус |editor-first2=М. Ю́. |editor-last2=Цейтлин&lt;!-- Cejtlin --&gt; |editor-link2=Михаил Ю́льевич Цейтлин |script-title=ru:Таблицы интегралов, сумм, рядов и произведений&lt;!-- |title=Tablitsy integralov, summ, rjadov i proizvedenii --&gt; |language=Russian |edition=5 |date=1971 |publisher=[[Nauka (publisher)|Nauka]] ([[Наука (publisher)|Наука]]) |pages=1101–1108}} (NB. The 8-page errata list in later print runs of the fourth Russian edition affected 189 table entries.)&lt;/ref&gt;
* {{anchor|GR-R5}}{{cite book |author-first1=И. С. |author-last1=Градштейн |author-link1=Израиль Соломонович Градштейн |author-first2=И. М. |author-last2=Рыжик |author-link2=Иосиф Моисеевич Рыжик |editor-first1=Ю. В. |editor-last1=Геронимус |editor-link1=Юрий Венеаминович Геронимус |editor-first2=М. Ю́. |editor-last2=Цейтлин&lt;!-- Cejtlin --&gt; |editor-link2=Михаил Ю́льевич Цейтлин |script-title=ru:Таблицы интегралов, сумм, рядов и произведений&lt;!-- |title=Tablitsy integralov, summ, rjadov i proizvedenii --&gt; |language=Russian |edition=5 |date=1971 |publisher=[[Nauka (publisher)|Nauka]] ([[Наука (publisher)|Наука]]) |lccn=78876185}} Dark brown&lt;!-- or black --&gt; fake-leather, 1108 pages.
* {{anchor|GR-R7}}{{cite book |author-first1=И. С. |author-last1=Градштейн |author-link1=Израиль Соломонович Градштейн |author-first2=И. М. |author-last2=Рыжик |author-link2=Иосиф Моисеевич Рыжик |author-first3=Ю. В. |author-last3=Геронимус |author-link3=Юрий Венеаминович Геронимус |author-first4=М. Ю́. |author-last4=Цейтлин&lt;!-- Cejtlin --&gt; |author-link4=Михаил Ю́льевич Цейтлин |editor-first1=Alan |editor-last1=Jeffrey |editor-first2=Daniel |editor-last2=Zwillinger |translator-first=Vasily Vasilyevich (Максимов, Василий Васильевич) |translator-last=Maximov |translator-link=:ru:Максимов, Василий Васильевич (профессор)&lt;!-- Vasily Vasilyevich Maximov (mathematician) --&gt; |script-title=ru:Таблицы интегралов, ряда и продуктов |trans-title=Table of Integrals, Series, and Products |edition=7 |date=2011 |language=Russian |publisher=[[:de:bhv (Verlag)|BHV]] (БХВ-Петербург) |location=Saint-Petersburg, Russia |isbn=978-5-9775-0360-0 |id=GR:11}} l+1182&lt;!-- 1232 --&gt; pages.&lt;ref name="APRU_2011"/&gt;

==={{anchor|German}}German editions===
* {{anchor|GR-G1}}{{cite book |date=1957 |author-first1=Jossif Moissejewitsch |author-last1=Ryshik |author-link1=Jossif Moissejewitsch Ryshik |author-first2=Israil Solomonowitsch |author-last2=Gradstein |author-link2=Israil Solomonowitsch Gradstein |title=Tafeln / Tables: Summen-, Produkt- und Integral-Tafeln / Tables of Series, Products, and Integrals |edition=1 |language=German, English |translator-first1=Christa |translator-last1=Berg |translator-first2=Lothar |translator-last2=Berg |translator-link2=:de:Lothar Berg (Mathematiker) |translator-first3=Martin |translator-last3=Strauss |others=Foreword by {{Interlanguage link multi|Kurt Erich Schröder|de|3=Kurt Erich Schröder|lt=Schröder, Kurt Erich}} |publisher=[[Deutscher Verlag der Wissenschaften]]&lt;!-- at least some batches of this edition state "Deutscher Verlag der Wissenschaften" (without "VEB" on the front cover and do not show a "DVW" logo. --&gt; |location=Berlin, Germany |lccn=58028629 |id={{DNB-IDN|454242255}} |url=https://books.google.com/books?id=oP3uAAAAMAAJ |accessdate=2016-02-21}} Gray or green&lt;!-- photos look more like gray, but text states green --&gt; [[linen]], xxiii+438 pages.&lt;ref name="RMT_69"&gt;{{cite journal |title=Reviews and Descriptions of Tables and Books 69: I. M. Ryshik &amp; I. S. Gradstein, Summen-, Produkt- und Integral-Tafeln: Tables of Series, Products, and Integrals, VEB Deutscher Verlag der Wissenschaften, Berlin |author-first=John William |author-last=Wrench, Jr. |author-link=John William Wrench, Jr. |journal=[[Mathematics of Computation]] |volume=14 |number=72 |date=October 1960 |pages=381–382 |jstor=2003905 |doi=10.2307/2003905 |id=RMT:69 |url=http://www.ams.org/journals/mcom/1960-14-072/S0025-5718-60-99227-9/S0025-5718-60-99227-9.pdf |accessdate=2016-03-16 |deadurl=no |archiveurl=https://web.archive.org/web/20160316011319/http://www.ams.org/journals/mcom/1960-14-072/S0025-5718-60-99227-9/S0025-5718-60-99227-9.pdf |archivedate=2016-03-16}}&lt;/ref&gt;&lt;ref name="ZBL_80-337"/&gt; Errata:&lt;ref name="MTE_293"&gt;{{cite journal |title=Table Errata 293: I. M. Ryshik &amp; I. S. Gradstein, Summen-, Produkt- und Integral-Tafeln: Tables of Series, Products, and Integrals, Deutscher Verlag der Wissenschaften, Berlin, 1957 |author-first=John William |author-last=Wrench, Jr. |author-link=John William Wrench, Jr. |journal=[[Mathematics of Computation]] |volume=14 |number=72 |date=October 1960 |pages=401–403 |jstor=2003934 |id=MTE:293 |url=http://www.ams.org/journals/mcom/1960-14-072/S0025-5718-60-99226-7/S0025-5718-60-99226-7.pdf |accessdate=2016-03-16 |deadurl=no |archiveurl=https://web.archive.org/web/20160316011723/http://www.ams.org/journals/mcom/1960-14-072/S0025-5718-60-99226-7/S0025-5718-60-99226-7.pdf |archivedate=2016-03-16}}&lt;/ref&gt;&lt;ref name="ERR_1"&gt;{{cite book |title=Ryshik-Gradstein: Summen-, Produkt- und Integral-Tafeln: Berichtigungen zur 1. Auflage |publisher=[[VEB Deutscher Verlag der Wissenschaften]] |location=Berlin, Germany |language=German |date=1962 |mr=175273 &lt;!--|MR=30:5458--&gt;}} (NB. This brochure was available free of charge from the publisher on request.)&lt;/ref&gt;&lt;ref name="LEM_1963"&gt;{{cite journal |title=Ryshik-Gradstein: Tafeln Summen Produkte Integrale: Berichtigungen zur 1. Auflage |series=Bulletin Bibliographique: Livres Nouveaux |journal=[[L'Enseignement Mathématique]] |language=French, German |volume=9 |date=1963 |page=5 |url=http://retro.seals.ch/cntmng?pid=ens-001:1963:9::80 |accessdate=2016-03-04 |quote=Die Berichtigung wird den Interessenten auf Anfrage kostenlos durch den Verlag geliefert.}}&lt;/ref&gt;&lt;ref name="MTE_326"&gt;{{cite journal |title=Table Errata 326: I. M. Ryshik &amp; I. S. Gradstein, Summen-, Produkt- und Integral-Tafeln, Deutscher Verlag der Wissenschaften, Berlin, 1957 |author-first=Richard B. |author-last=Rodman |journal=[[Mathematics of Computation]] |volume=17 |number=81 |date=January 1963 |page=102 |jstor=2003754 |id=MTE:326 |url=http://www.ams.org/journals/mcom/1963-17-081/S0025-5718-63-99185-3/S0025-5718-63-99185-3.pdf |accessdate=2016-03-16 |deadurl=no |archiveurl=https://web.archive.org/web/20160316013719/http://www.ams.org/journals/mcom/1963-17-081/S0025-5718-63-99185-3/S0025-5718-63-99185-3.pdf |archive-date=2016-03-16}} [http://www.ams.org/journals/mcom/1963-17-081/S0025-5718-1963-1781100-6/S0025-5718-1963-1781100-6.pdf]&lt;/ref&gt;&lt;ref name="MTE_392"&gt;{{cite journal |author-first=Glenn M. |author-last=Schmieg |title=Errata 392: I. M. Ryshik &amp; I. S. Gradstein, Summen-, Produkt- und Integral-Tafeln: Tables of Series, Products, and Integrals, VEB Deutscher Verlag der Wissenschaften, Berlin, 1957 |journal=[[Mathematics of Computation]] |volume=20 |number=95 |date=July 1966 |page=468 |jstor=2003630 |doi=10.2307/2003630 |id=MTE:392 |url=http://www.ams.org/journals/mcom/1966-20-095/S0025-5718-66-99916-9/S0025-5718-66-99916-9.pdf |accessdate=2016-03-16 |deadurl=no |archive-url=https://web.archive.org/web/20160316013758/http://www.ams.org/journals/mcom/1966-20-095/S0025-5718-66-99916-9/S0025-5718-66-99916-9.pdf |archivedate=2016-03-16}}&lt;/ref&gt;&lt;ref name="MTE_456"&gt;{{cite journal |title=Table Errata 456: I. M. Ryshik &amp; I. S. Gradstein, Summen-, Produkt- und Integral-Tafeln, VEB Deutscher Verlag der Wissenschaften, Berlin, 1957 |author-first=James J. |author-last=Filliben |journal=[[Mathematics of Computation]] |volume=24 |number=109 |date=January 1970 |pages=239–242 |jstor=2004912 |id=MTE:456 |url=http://www.ams.org/journals/mcom/1970-24-109/S0025-5718-70-99855-8/S0025-5718-70-99855-8.pdf |accessdate=2016-03-16 |deadurl=no |archiveurl=https://web.archive.org/web/20160316013815/http://www.ams.org/journals/mcom/1970-24-109/S0025-5718-70-99855-8/S0025-5718-70-99855-8.pdf |archivedate=2016-03-16}}&lt;/ref&gt;&lt;ref name="MTE_486"/&gt;
* {{anchor|GR-G2}}{{cite book |date=1963 |author-first1=Jossif Moissejewitsch |author-last1=Ryshik |author-link1=Jossif Moissejewitsch Ryshik |author-first2=Israil Solomonowitsch |author-last2=Gradstein |author-link2=Israil Solomonowitsch Gradstein |title=Tafeln / Tables: Summen-, Produkt- und Integral-Tafeln / Tables of Series, Products, and Integrals |edition=2nd corrected |language=German, English |translator-first1=Christa |translator-last1=Berg |translator-first2=Lothar |translator-last2=Berg |translator-link2=:de:Lothar Berg (Mathematiker) |translator-first3=Martin |translator-last3=Strauss |others=Foreword by {{Interlanguage link multi|Kurt Erich Schröder|de|3=Kurt Erich Schröder|lt=Schröder, Kurt Erich}} |publisher=[[VEB Deutscher Verlag der Wissenschaften]] (DVW)&lt;!-- at least some batches of this edition actually state "VEB Deutscher Verlag der Wissenschaften" on the front cover and show a "DVW" logo. --&gt; |location=Berlin, Germany |lccn=63025905 |id={{DNB-IDN|579497747}} |url=https://books.google.com/books?id=pRsIAQAAIAAJ |accessdate=2016-02-21}} [https://books.google.com/books?id=tI_QAAAAMAAJ] (Distributed in the USA by [[Plenum Press, Inc.]], New York.&lt;!-- Are these samples marked specifically somehow? --&gt;) Green linen, xxiii+438 pages + 4 page errata inlet. Errata:&lt;ref name="MTE_392"/&gt;
* {{anchor|GR-G3}}{{cite book |date=1981 |author-first1=Israil Solomonowitsch |author-last1=Gradstein |author-link1=Israil Solomonowitsch Gradstein |author-first2=Jossif Moissejewitsch |author-last2=Ryshik |author-link2=Jossif Moissejewitsch Ryshik |editor-first1=Juri Weneaminowitsch |editor-last1=Geronimus |editor-link1=Juri Weneaminowitsch Geronimus |editor-first2=Michael Juljewitsch |editor-last2=Zeitlin |editor-link2=Michael Juljewitsch Zeitlin |translator-first=Ludwig |translator-last=Boll |title=Tafeln / Tables: Summen-, Produkt- und Integraltafeln / Tables of Series, Products, and Integrals |edition=3 |language=German, English |publisher=[[Verlag Harri Deutsch]] / [[MIR Moscow]] |location=Berlin / Thun / Frankfurt am Main / Moscow |isbn=3-87144-350-6&lt;!-- ISBN of Harri Deutsch edition (book set) --&gt;|lccn=82202345 |id={{DNB-IDN|551448512|881086274|881086282}}}} Gray linen with [[gilding|gild]]ed [[paper embossing|embossing]] by A. W. Schipow, 2 volumes, 677 + 504 pages.&lt;ref name="ZBL_448-395"&gt;{{cite journal |title=Gradshtejn, I. S.; Ryzhik, I. M.: Summen-, Produkt- und Integraltafeln. Band 1, 2. Deutsch und englisch. Übers. aus dem Russischen auf der Basis der 5. russ. Aufl., überarb. von J. Geronimus und M. Zeitlin. Tables of series, products, and integrals. Volumes 1, 2. German and English Transl. |type=list |language=German |journal=[[Zentralblatt für Mathematik und ihre Grenzgebiete]] |volume=448 |page=395 |zbl=0448.65002 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=448&amp;count_=395 |access-date=2016-02-16}}&lt;/ref&gt;&lt;ref name="ZBL_456-355"&gt;{{cite journal |title=Gradshtejn, I. S.; Ryzhik, I. M.: Summen-, Produkt- und Integraltafeln. Band 1, 2. Deutsch und englisch. Übers. aus dem Russischen auf der Basis der 5. russ. Aufl., überarb. von J. Geronimus und M. Zeitlin. Tables of series, products, and integrals. Volumes 1, 2. German and English Transl. |type=list |language=German |journal=[[Zentralblatt für Mathematik und ihre Grenzgebiete]] |volume=456 |page=355 |zbl=0456.65001 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=456&amp;count_=355 |access-date=2016-02-16}}&lt;/ref&gt;

==={{anchor|Polish}}Polish edition===
* {{anchor|GR-P1}}{{cite book |author-first1=I. M. |author-last1=Ryżyk |author-link1=I. M. Ryżyk&lt;!-- Iosif Moiseevič Ryžik --&gt; |author-first2=I. S. |author-last2=Gradsztejn |author-link2=I. S. Gradsztejn |date=1964 |title=Tablice całek, sum, szeregów i iloczynów |language=Polish |translator-first=Roman |translator-last=Malesiński&lt;!-- viaf=164219536 --&gt; |publisher=[[Państwowe Wydawnictwo Naukowe]] (PWN) |location=Warsaw, Poland |oclc=749996828 |id={{VIAF|309184374}} |edition=1 |url=https://books.google.com/books/about/Tablice_ca%C5%82ek_sum_szereg%C3%B3w_i_iloczyn%C3%B3.html?id=32pmtwAACAAJ |access-date=2016-02-16}} Light grayish&lt;!-- with brownish tint on photo in 2016, possible white originally --&gt; cover, 464 pages.

==={{anchor|English}}English editions===
* {{anchor|GR-E3}}{{cite book |title=Table of Integrals, Series, and Products |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |editor-first1=Alan |editor-last1=Jeffrey |translator=((Scripta Technica, Inc.)) |date=February 1966 |orig-year=1965 |edition=3&lt;!-- Some sources erroneously list this as "4th edition" relating to the 4th Russian edition --&gt; |publisher=[[Academic Press]] |isbn=0-12-294750-9&lt;!-- Some sources give this ISBN, although ISBNs did not exist in 1966. --&gt; &lt;!-- |id=GR:3 --&gt;&lt;!-- only for third printing 1967/1969; superscript numbering first started with "3" for 3rd printing. --&gt; |lccn=65029097 |url=http://catalog.hathitrust.org/Record/000002668&lt;!-- https://books.google.com/books?id=CJUQAQAAIAAJ --&gt; |access-date=2016-02-21}} Black&lt;!-- some sources state: gray --&gt; cloth hardcover with [[gilt (gilding)|gilt]] titles&lt;!-- at least the AP release --&gt;, white dust jacket&lt;!-- unknown release --&gt;, xiv+1086 pages.&lt;ref name="RMT_85"&gt;{{cite journal |title=Reviews and Descriptions of Tables and Books 85: Table of Integrals, Series, and Products by I. S. Gradshteyn, I. M. Ryzhik |type=review |author-first=Daniel |author-last=Shanks |author-link=Daniel Shanks |journal=[[Mathematics of Computation]] |volume=20 |number=96 |date=October 1966 |pages=616–617 |jstor=2003554 |doi=10.2307/2003554 |id=RMT:85 |url=http://www.ams.org/journals/mcom/1966-20-096/S0025-5718-66-99914-5/S0025-5718-66-99914-5.pdf |access-date=2016-03-04}}&lt;/ref&gt; Errata:&lt;ref name="RMT_85"/&gt;&lt;ref name="MTE_486"&gt;{{cite journal |title=Table Errata 486: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Robert F. |author-last=MacKinnon |journal=[[Mathematics of Computation]] |volume=26 |number=117 |date=January 1972 |pages=305–307 |jstor=2004754 |id=MTE:486 |url=http://www.ams.org/journals/mcom/1972-26-117/S0025-5718-1972-0415970-6/S0025-5718-1972-0415970-6.pdf |access-date=2016-03-04 |mr=0415970 |doi=10.1090/s0025-5718-1972-0415970-6}} [http://www.ams.org/journals/mcom/1972-26-117/S0025-5718-72-99109-0/S0025-5718-72-99109-0.pdf]&lt;/ref&gt;&lt;ref name="MTE_408"&gt;{{cite journal |title=Table Errata 408: I. S. Gradshteyn &amp; I. M. Ryzhik, Tables of Integrals, Series and Products, Fourth Edition, Academic Press, New York, 1965 |author-first=Henry E. |author-last=Fettis |journal=[[Mathematics of Computation]] |volume=21 |number=98 |date=April 1967 |pages=293–295 |jstor=2004214 |id=MTE:408 |url=http://www.ams.org/journals/mcom/1967-21-098/S0025-5718-67-99890-0/S0025-5718-67-99890-0.pdf |access-date=2016-03-04}}&lt;/ref&gt;&lt;ref name="MTE_428"&gt;{{anchor|MTE-428}}{{cite journal |title=Table Errata 428: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, fourth edition, prepared by Yu. V. Geronimus &amp; M. Yu. Tseytlin, Academic Press, New York, 1965 |author-first1=J. R. |author-last1=Blake |author-first2=Van E. |author-last2=Wood |author-first3=M. Lawrence |author-last3=Glasser |author-first4=Henry E. |author-last4=Fettis |author-first5=Eldon Robert |author-last5=Hansen |author-link5=Eldon Robert Hansen |author-first6=Merrell R. |author-last6=Patrick |journal=[[Mathematics of Computation]] |volume=22 |number=104 |date=October 1968 |pages=903–907 |jstor=2004606 |id=MTE:428 |mr=0239122 |url=http://www.ams.org/journals/mcom/1968-22-104/S0025-5718-1968-0239122-7/S0025-5718-1968-0239122-7.pdf &lt;!-- http://www.ams.org/journals/mcom/1968-22-104/S0025-5718-1968-0239123-9/S0025-5718-1968-0239123-9.pdf --&gt; |access-date=2016-03-04}} (NB. See 1972 corrigenda by [[#Fettis-1|Fettis]] and 1979 corrigenda by [[#Anderson-1|Anderson]].)&lt;/ref&gt;&lt;ref name="MTE_437"&gt;{{cite journal |title=Table Errata 437: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first1=Murlan S. |author-last1=Corrington |author-first2=Henry E. |author-last2=Fettis |journal=[[Mathematics of Computation]] |volume=23 |number=106 |date=April 1969 |pages=467–472 |jstor=2004471 &lt;!--|MR=0415967. MTE:437--&gt; |url=http://www.ams.org/journals/mcom/1969-23-106/S0025-5718-1969-0415966-4/S0025-5718-1969-0415966-4.pdf |access-date=2016-03-04 |mr=0415966&lt;!--, 0415967--&gt;}} [http://www.ams.org/journals/mcom/1969-23-106/S0025-5718-69-99643-4/S0025-5718-69-99643-4.pdf] [http://www.ams.org/journals/mcom/1969-23-106/S0025-5718-1969-0415967-6/S0025-5718-1969-0415967-6.pdf]&lt;/ref&gt;&lt;ref name="MTE_446"&gt;{{cite journal |title=Table Errata 446: I. S. Gradshteyn &amp; I. M. Ryzhik, Tables of Integrals, Series and Products, 4th edition, Academic Press, New York, 1965 |author-first=Lee C. |author-last=Bradley |journal=[[Mathematics of Computation]] |volume=23 |number=108 |date=October 1969 |pages=891–892, s15–s17 |jstor=2004993 |id=MTE:446 |url=http://www.ams.org/journals/mcom/1969-23-108/S0025-5718-1969-0415968-8/S0025-5718-1969-0415968-8.pdf |access-date=2016-03-04 |mr=0415968 |doi=10.1090/s0025-5718-1969-0415968-8}} [http://www.ams.org/journals/mcom/1969-23-108/S0025-5718-69-99640-9/S0025-5718-69-99640-9.pdf]&lt;/ref&gt;&lt;ref name="MTE_451"&gt;{{cite journal |title=Table Errata 451: A. Erdélyi, W. Magnus, F. Oberhettinger &amp; F. G. Tricomi, Tables of Integral Transforms, McGraw-Hill Book Co., New York, 1954 |author-first=A. T. |author-last=Young |journal=[[Mathematics of Computation]] |volume=24 |number=109 |date=January 1970 |page=239 |jstor=2004912 |id=MTE:451 |mr=0257656 |url=http://www.ams.org/journals/mcom/1970-24-109/S0025-5718-1970-0257656-5/S0025-5718-1970-0257656-5.pdf
 |access-date=2016-03-16 |dead-url=no |archive-url=https://web.archive.org/web/20160316124458/http://www.ams.org/journals/mcom/1970-24-109/S0025-5718-1970-0257656-5/S0025-5718-1970-0257656-5.pdf |archive-date=2016-03-16 |doi=10.2307/2004614}} [http://www.ams.org/journals/mcom/1970-24-109/S0025-5718-70-99855-8/S0025-5718-70-99855-8.pdf] (NB. The error also affects entry 3.252.10 on page 297 in GR.)&lt;/ref&gt;&lt;ref name="MTE_473"&gt;{{cite journal |title=Table Errata 473: I. S. Gradshteyn &amp; I. M. Ryzhik, Tables of Integrals, Series and Products, 4th ed., Academic Press, New York, 1965 |author-first1=Carl W. |author-last1=Muhlhausen |author-first2=Daniel D. |author-last2=Konowalow |journal=[[Mathematics of Computation]] |volume=25 |number=113 |date=January 1971 |pages=199–201 |jstor=2005156 |id=MTE:473 |url=http://www.ams.org/journals/mcom/1971-25-113/S0025-5718-71-99721-3/S0025-5718-71-99721-3.pdf |access-date=2016-03-04 |mr=0415969}} [http://www.ams.org/journals/mcom/1971-25-113/S0025-5718-71-99721-3/S0025-5718-71-99721-3.pdf]&lt;/ref&gt;&lt;ref name="MTE_492"&gt;{{cite journal |title=Table Errata 492: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=John C. |author-last=Nash |journal=[[Mathematics of Computation]] |volume=26 |number=118 |date=April 1972 |pages=597–599 |jstor=2005198 |id=MTE:492 |url=http://www.ams.org/journals/mcom/1972-26-118/S0025-5718-1972-0415971-8/S0025-5718-1972-0415971-8.pdf |access-date=2016-03-04 |mr=0415971}} [http://www.ams.org/journals/mcom/1972-26-118/S0025-5718-72-99106-5/S0025-5718-72-99106-5.pdf]&lt;/ref&gt;&lt;ref name="CORR_118"&gt;{{anchor|Fettis-1}}{{cite journal |title=Corrigendum: MTE 428, Math. Comp., v.22, 1968, pp. 903-907 |author-first=Henry E. |author-last=Fettis |journal=[[Mathematics of Computation]] |volume=26 |number=118 |date=April 1972 |page=601 |jstor=2005199 |doi=10.2307/2005199 |url=http://www.ams.org/journals/mcom/1972-26-118/S0025-5718-1972-0415973-1/S0025-5718-1972-0415973-1.pdf |access-date=2016-03-04 |mr=0415973}} [http://www.ams.org/journals/mcom/1972-26-118/S0025-5718-72-99105-3/S0025-5718-72-99105-3.pdf] (NB. This corrigenda applies to [[#MTE-428|MTE 428]].)&lt;/ref&gt;&lt;ref name="MTE_503"&gt;{{anchor|MTE-503}}{{cite journal |title=Table Errata 503: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first1=Akin |author-last1=Ojo |author-first2=J. |author-last2=Sadiku |journal=[[Mathematics of Computation]] |volume=27 |number=122 |date=April 1973 |pages=451–452 |jstor=2005649 |mr=0415972 |id=MTE:503 |url=http://www.ams.org/journals/mcom/1973-27-122/S0025-5718-1973-0415972-0/S0025-5718-1973-0415972-0.pdf |access-date=2016-03-04 |doi=10.1090/s0025-5718-1973-0415972-0}} [http://www.ams.org/journals/mcom/1973-27-122/S0025-5718-73-99702-0/S0025-5718-73-99702-0.pdf] (NB. See 1982 corrigenda by [[#Fettis-2|Fettis]].)&lt;/ref&gt;&lt;ref name="CORR_158"&gt;{{anchor|Fettis-2}}{{cite journal |title=Corrigenda: Ojo, Akin; Sadiku, J. (1973). Table Errata 503: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Henry E. |author-last=Fettis |journal=[[Mathematics of Computation]] |volume=38 |number=158 |date=April 1982 |mr=645681 |page=657 |jstor=2007312 |url=http://www.ams.org/journals/mcom/1982-38-158/S0025-5718-1982-0645681-X/S0025-5718-1982-0645681-X.pdf |access-date=2016-03-14 |doi=10.1090/S0025-5718-1982-0645681-X}} (NB. This corrigenda applies to [[#MTE-503|MTE 503]].)&lt;/ref&gt;&lt;ref name="MTE_528"&gt;{{cite journal |title=Table Errata 528: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Ann |author-last=Scherzinger |journal=[[Mathematics of Computation]] |volume=30 |number=136 |date=October 1976 |page=899 |jstor=2005420 |id=MTE:528 |url=http://www.ams.org/journals/mcom/1976-30-136/S0025-5718-1976-0408192-X/S0025-5718-1976-0408192-X.pdf |access-date=2016-03-04 |mr=0408192 |doi=10.1090/s0025-5718-1976-0408192-x}} [http://www.ams.org/journals/mcom/1976-30-136/S0025-5718-76-99660-5/S0025-5718-76-99660-5.pdf]&lt;/ref&gt;&lt;ref name="MTE_534"&gt;{{cite journal |title=Table Errata 534: I. S. Gradshteyn &amp; I. M. Ryzhik, Tables of Integrals, Series and Products, 4th ed., Academic Press, New York, 1965 |author-first=Alistair R. |author-last=Carr |journal=[[Mathematics of Computation]] |volume=31 |number=138 |date=April 1977 |pages=614–616 |jstor=2006446 |id=MTE:534 |url=http://www.ams.org/journals/mcom/1977-31-138/S0025-5718-1977-0428676-9/S0025-5718-1977-0428676-9.pdf |access-date=2016-03-04 |mr=0428676 |doi=10.1090/s0025-5718-1977-0428676-9}} [http://www.ams.org/journals/mcom/1977-31-138/S0025-5718-77-99994-X/S0025-5718-77-99994-X.pdf]&lt;/ref&gt;&lt;ref name="MTE_550"&gt;{{cite journal |title=Table Errata 550: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Neville I. |author-last=Robinson |journal=[[Mathematics of Computation]] |volume=32 |number=141 |date=January 1978 |pages=317–320 |jstor=2006287 |id=MTE:550 |mr=0478539 |url=http://www.ams.org/journals/mcom/1978-32-141/S0025-5718-1978-0478539-9/S0025-5718-1978-0478539-9.pdf |access-date=2016-03-04}} [http://www.ams.org/journals/mcom/1978-32-141/S0025-5718-78-99984-2/S0025-5718-78-99984-2.pdf]&lt;/ref&gt;&lt;ref name="MTE_557"&gt;{{cite journal |title=Table Errata 557: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Henry E. |author-last=Fettis |journal=[[Mathematics of Computation]] |volume=33 |number=145 |date=January 1979 |pages=430–431 |jstor=2006060 |id=MTE:557 |url=http://www.ams.org/journals/mcom/1979-33-145/S0025-5718-79-99976-9/S0025-5718-79-99976-9.pdf |access-date=2016-03-04}}&lt;/ref&gt;&lt;ref name="CORR_145"&gt;{{anchor|Anderson-1}}{{cite journal |title=Corrigenda: p. 906 of MTE 428. I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965. |author-first=Michael |author-last=Anderson |journal=[[Mathematics of Computation]] |volume=33 |number=145 |date=January 1979 |pages=432–433 |jstor=2006061 |doi=10.2307/2006061 |url=http://www.ams.org/journals/mcom/1979-33-145/S0025-5718-79-99975-7/S0025-5718-79-99975-7.pdf |access-date=2016-03-04}} (NB. This corrigenda applies to [[#MTE-428|MTE 428]].)&lt;/ref&gt;&lt;ref name="MTE_564"&gt;{{cite journal |title=Table Errata 564: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=John Ross |author-last=McGregor |journal=[[Mathematics of Computation]] |volume=33 |number=146 |date=April 1979 |pages=845–846 |jstor=2006322 |id=MTE:564 |url=http://www.ams.org/journals/mcom/1979-33-146/S0025-5718-79-99973-3/S0025-5718-79-99973-3.pdf |access-date=2016-03-04}}&lt;/ref&gt;&lt;ref name="MTE_565"&gt;{{cite journal |title=Table Errata 565: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=David T. |author-last=Birtwistle |journal=[[Mathematics of Computation]] |volume=33 |number=148 |date=October 1979 |page=1377 |jstor=2006476 |id=MTE:565 |url=http://www.ams.org/journals/mcom/1979-33-148/S0025-5718-79-99969-1/S0025-5718-79-99969-1.pdf |access-date=2016-03-04}}&lt;/ref&gt;&lt;ref name="MTE_572"&gt;{{cite journal |title=Table Errata 572: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Jason A. Carlson |author-last=Gallas |journal=[[Mathematics of Computation]] |volume=35 |number=152 |date=October 1980 |page=1444 |jstor=2006418 |id=MTE:572 |mr=583522 |doi=10.1090/S0025-5718-1980-0583522-8 |url=http://www.ams.org/journals/mcom/1980-35-152/S0025-5718-1980-0583522-8/S0025-5718-1980-0583522-8.pdf |access-date=2016-03-04}} [http://www.ams.org/journals/mcom/1980-35-152/S0025-5718-80-99959-7/S0025-5718-80-99959-7.pdf] [http://www.ams.org/journals/mcom/1980-35-152/S0025-5718-1980-0583523-X/S0025-5718-1980-0583523-X.pdf]&lt;/ref&gt;
* {{anchor|GR-E4}}{{cite book |title=Table of Integrals, Series, and Products |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |editor-first1=Alan |editor-last1=Jeffrey |translator=((Scripta Technica, Inc.)) |date=1980 |edition=4th corrected and enlarged |publisher=[[Academic Press, Inc.]] |isbn=0-12-294760-6 |id=GR:4,5,6,7&lt;!-- known: 4th edfition, 4th printing: 1983, 7th print run in 1990. --&gt; |url=https://books.google.com/books?id=F7jiBQAAQBAJ |access-date=2016-02-21}} xlvi+1160 pages.&lt;ref name="REV_153_5"&gt;{{cite journal |author-first=Yudell Leo |author-last=Luke |author-link=Yudell Leo Luke |title=Reviews and Descriptions of Tables and Books 5: I. S. Gradshteyn and I. M. Ryzhik, Tables of Integrals, Series and Products, Academic Press, New York, 1980 |type=review |journal=[[Mathematics of Computation]] |volume=36 |number=153 |date=January 1981 |pages=310–314 |doi=10.2307/2007757 |id=MSC:7.95,7.100 |jstor=2007757 |url=http://www.ams.org/journals/mcom/1981-36-153/S0025-5718-81-99782-9/S0025-5718-81-99782-9.pdf |access-date=2016-03-04}}&lt;/ref&gt;&lt;ref name="ZBL_521-193-1"&gt;{{cite journal |author-first=Frank J. |author-last=Papp |title=Gradshteyn, I. S.; Ryzhik, I. M.: Tables of integrals, series, and products. Corr. and enl. ed. by Alan Jeffrey. Incorporating the 4th ed. by Yu. V. Geronimus and M. Yu. Tseytlin (M. Yu. Tsejtlin). Transl. from the Russian – New York – London – Toronto. Volumes 1, 2. German and English Transl. |type=review |journal=[[Zentralblatt für Mathematik und ihre Grenzgebiete]] |volume=521 |page=193 |zbl=0521.33001 |mr=582453 &lt;!--|MR=81g:33001 --&gt;|url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=521&amp;count_=193 |accessdate=2016-02-16}}&lt;/ref&gt; Errata:&lt;ref name="REV_153_5"/&gt;&lt;ref name="ZBL_521-193-1"/&gt;&lt;ref name="MTE_577"&gt;{{cite journal |title=Table Errata 577: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Henry E. |author-last=Fettis |journal=[[Mathematics of Computation]] |volume=36 |number=153 |date=January 1981 |pages=317–318 |jstor=2007758 |id=MTE:577 |mr=595074 |doi=10.1090/S0025-5718-1981-0595074-8 |url=http://www.ams.org/journals/mcom/1981-36-153/S0025-5718-1981-0595074-8/S0025-5718-1981-0595074-8.pdf |access-date=2016-03-04}}&lt;/ref&gt;&lt;ref name="MTE_582"&gt;{{anchor|MTE-582}}{{cite journal |title=Table Errata 582: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Henry E. |author-last=Fettis |journal=[[Mathematics of Computation]] |volume=36 |number=153 |date=January 1981 |page=320 |jstor=2007758 |id=MTE:582 |mr=595074 |url=http://www.ams.org/journals/mcom/1981-36-153/S0025-5718-1981-0595074-8/S0025-5718-1981-0595074-8.pdf |access-date=2016-03-04 |dead-url=no |archive-url=https://web.archive.org/web/20160316145212/http://www.ams.org/journals/mcom/1981-36-153/S0025-5718-1981-0595074-8/S0025-5718-1981-0595074-8.pdf |archive-date=2016-03-16}} (NB. See 1982 corrigenda by [[#Fettis-3|Fettis]].)&lt;/ref&gt;&lt;ref name="CORR_157"&gt;{{anchor|Fettis-3}}{{cite journal |title=Corrigenda: Fettis, Henry E. (1981). Table Errata 582: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 4th ed., Academic Press, New York, 1965 |author-first=Henry E. |author-last=Fettis |journal=[[Mathematics of Computation]] |volume=38 |number=157 |date=January 1982 |mr=637313 |page=337 |jstor=2007492 |doi=10.1090/S0025-5718-1982-0637313-1 |id=|url=http://www.ams.org/journals/mcom/1982-38-157/S0025-5718-1982-0637313-1/S0025-5718-1982-0637313-1.pdf |access-date=2016-03-16 |dead-url=no |archive-url=https://web.archive.org/web/20160316144428/http://www.ams.org/journals/mcom/1982-38-157/S0025-5718-1982-0637313-1/S0025-5718-1982-0637313-1.pdf |archive-date=2016-03-16}} (NB. This corrigenda applies to [[#MTE-582|MTE 582]].)&lt;/ref&gt;&lt;ref name="MTE_589"&gt;{{cite journal |author-first1=Hendrik&lt;!-- "Henk" --&gt; |author-last1=van Haeringen |author-first2=Lambrecht P. |author-last2=Kok |title=Table Errata 589: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, Corrected and enlarged edition, Academic Press, New York, First printing, 1980 |journal=[[Mathematics of Computation]] |volume=39 |number=160 |pages=747–757 |date=October 1982 |jstor=2007357 |mr=669666 |id=MTE:589 |doi=10.1090/S0025-5718-1982-0669666-2 |url=http://www.ams.org/journals/mcom/1982-39-160/S0025-5718-1982-0669666-2/S0025-5718-1982-0669666-2.pdf |access-date=2016-02-22}} [http://www.ams.org/journals/mcom/1982-39-160/S0025-5718-82-99823-4/S0025-5718-82-99823-4.pdf] [http://www.ams.org/journals/mcom/1982-39-160/S0025-5718-1982-0669665-0/S0025-5718-1982-0669665-0.pdf]&lt;/ref&gt;&lt;ref name="ZBL_521-193-2"&gt;{{cite journal |author-first1=Hendrik&lt;!-- "Henk" --&gt; |author-last1=van Haeringen |author-first2=Lambrecht P. |author-last2=Kok |title=I. S. Gradshteyn &amp; I. M. Ryzhik, Tables of integrals, series, and products. Math. comput. 39, 747–757 (1982) |type=review |journal=[[Zentralblatt für Mathematik und ihre Grenzgebiete]] |volume=521 |page=193 |zbl=0521.33002 |url=http://www.zentralblatt-math.org/zmath/scans.html?volume_=521&amp;count_=193 |access-date=2016-02-16}}&lt;/ref&gt;&lt;ref name="MTE_601"&gt;{{cite journal |author-first1=Henry E. |author-last1=Fettis |author-first2=Emeric |author-last2=Deutsch |author-first3=Ernst D. |author-last3=Krupnikov |title=Table Errata 601: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series and Products, Corrected and enlarged edition, Academic Press, New York, First Printing, 1980 |journal=[[Mathematics of Computation]] |volume=41 |number=164 |pages=780–783 |date=October 1983 |id=MTE:601 |jstor=2007718 |mr=717727 |url=http://www.ams.org/journals/mcom/1983-41-164/S0025-5718-1983-0717727-2/S0025-5718-1983-0717727-2.pdf |access-date=2016-03-04}} [http://www.ams.org/journals/mcom/1983-41-164/S0025-5718-83-99812-5/S0025-5718-83-99812-5.pdf]&lt;/ref&gt;&lt;ref name="MTE_607"&gt;{{cite journal |author-first=György |author-last=Solt |title=Table Errata 607: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, corrected and enlarged edition prepared by A. Jeffrey, Academic Press, New York, 1980 |journal=[[Mathematics of Computation]] |volume=47 |number=176 |page=768 |jstor=2008202 |date=October 1986 |mr=856719 |id=MTE:607. |doi=10.1090/S0025-5718-1986-0856719-2 |url=http://www.ams.org/journals/mcom/1986-47-176/S0025-5718-1986-0856719-2/S0025-5718-1986-0856719-2.pdf |access-date=2016-03-03}}&lt;/ref&gt;&lt;ref name="Wolfram_2003"&gt;{{cite web |title=Errors in the Integral Tables of Gradshteyn and Ryzhik with Correct Results from Mathematica |work=Mathematica Information Centre / Wolfram Library Archive: Technical Notes |publisher=[[Wolfram Research, Inc.]] |location=Champaign, IL, USA |date=2004 |orig-year=2003 |url=http://library.wolfram.com/infocenter/TechNotes/4196/ |access-date=2016-02-16 |dead-url=no |archive-url=https://web.archive.org/web/20030425211208/http://library.wolfram.com/infocenter/TechNotes/4196/ |archive-date=2003-04-25}}&lt;/ref&gt;&lt;ref name="Wolfram_2004"&gt;{{cite web |title=Errors in the Integral Tables of Gradshteyn and Ryzhik with Correct Results from Mathematica |publisher=[[Wolfram Research, Inc.]] |location=Champaign, IL, USA |type=Technical note |url=http://library.wolfram.com/infocenter/TechNotes/4196/GradshteynRyzhik.txt |date=2004 |orig-year=2003 |access-date=2016-03-04 |dead-url=no |archive-url=https://web.archive.org/web/20040619185253/http://library.wolfram.com/infocenter/TechNotes/4196/GradshteynRyzhik.txt |archive-date=2004-06-19}}&lt;/ref&gt;
* {{anchor|GR-E5}}{{cite book |title=Table of Integrals, Series, and Products |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |editor-first1=Alan |editor-last1=Jeffrey |translator=((Scripta Technica, Inc.)) |date=January 1994 |edition=5 |publisher=[[Academic Press, Inc.]] |isbn=&lt;!--|MR=94g:00008. MSC:00A22,33-00,65-00 ; GR:9 at least &gt;=8 --&gt; |mr=1243179 |url=https://books.google.com/books?id=oDhmngEACAAJ |access-date=2016-02-21}} xlvii+1204 pages.&lt;ref name="REV_209_1"&gt;{{cite journal |author-first=Kurt Siegfried |author-last=Kölbig |title=Reviews and Descriptions of Tables and Books 1: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 5th ed. (Alan Jeffrey, ed.), Academic Press, Boston, 1994 |journal=[[Mathematics of Computation]] |volume=64 |issue=209 |date=January 1995 |pages=439–441 |id=MSC:00A22,33-00,44-00,65-00 |jstor=2153347 |doi=10.2307/2153347 |url=http://www.ams.org/journals/mcom/1995-64-209/S0025-5718-95-99727-0/S0025-5718-95-99727-0.pdf |access-date=2016-03-03}}&lt;/ref&gt;&lt;ref name="ZBL_918-65002"&gt;{{cite journal |title=Gradshteyn, I. S.; Ryzhik, I. M. Table of integrals, series, and products. Transl. from the Russian by Scripta Technica, Inc. 5th ed. Boston, MA: Academic Press, Inc. (1994) |journal=|zbl=0918.65002 |url=http://www.zentralblatt-math.org/zmath/en/advanced/?q=an:0918.65002 |access-date=2016-02-16}}&lt;/ref&gt; (A CD-ROM version with {{ISBN|0-12-294756-8}} / {{ISBN|978-0-12-294756-8}} and {{LCCN|96801532}} was prepared by Lightbinders, Inc. in &lt;!-- one source states May 1996 --&gt;July 1996.&lt;!-- &lt;ref name="CD"&gt;[https://books.google.com/books?id=QVaVmgEACAAJ]&lt;/ref&gt; --&gt;&lt;ref name="ZBL_918-65001"&gt;{{cite journal |title=Table of integrals, series, and products. Ed. by Alan Jeffrey. CD-ROM version 1.0 for PC, MAC, and UNIX computers. 5th ed. (English) San Diego, CA: Academic Press (1996) |journal=|zbl=0918.65001 |url=http://zbmath.org/?q=an:0918.65001 |access-date=2016-02-16}}&lt;/ref&gt;) Errata:&lt;ref name="REV_209_1"/&gt;&lt;ref name="Koelbig_1995"&gt;{{cite web |author-first=Kurt Siegfried |author-last=Kölbig |title=Corrigenda: I. S. Gradshteyn &amp; I. M. Ryzhik; Table of Integrals, Series, and Products, Fifth edition, Academic Press, Boston |date=June 1996 |orig-year=1995 |publisher=[[CERN]] Computing and Networks Division |id=CN/95/15 |url=http://cdsweb.cern.ch/record/291467/files/cn-95-15.pdf |access-date=2016-02-12}}&lt;/ref&gt;&lt;ref name="MTE_617"&gt;{{cite journal |author-first=Kurt Siegfried |author-last=Kölbig |title=Table errata 617: I. S. Gradshteyn &amp; I. M. Ryzhik, Table of Integrals, Series, and Products, 5th ed. (Alan Jeffrey, ed.), Academic Press, Boston, 1994 |journal=[[Mathematics of Computation]] |volume=64 |issue=209 |date=January 1995 |pages=449–460 |jstor=2153354 |mr=1270626 |id=MTE:617. |doi=10.1090/S0025-5718-1995-1270626-0 |url=http://www.ams.org/journals/mcom/1995-64-209/S0025-5718-1995-1270626-0/S0025-5718-1995-1270626-0.pdf |access-date=2016-03-03}} [http://www.ams.org/journals/mcom/1995-64-209/S0025-5718-95-99726-9/S0025-5718-95-99726-9.pdf]&lt;/ref&gt;&lt;ref name="MTE_628"&gt;{{cite journal |title=Table Errata 628 |author-first=Adeline |author-last=Lambert |journal=[[Mathematics of Computation]] |volume=66 |number=217 |date=January 1997 |page=463 |jstor=2153671 |mr=1388890 |id=MTE:628}}&lt;/ref&gt;&lt;ref name="MTE_634"&gt;{{cite journal |author-first=George |author-last=Fikioris |title=Table Errata 634 |journal=[[Mathematics of Computation]] |volume=67 |number=224 |date=October 1998 |pages=1753–1754 |mr=1625064 |jstor=2584882 |id=MTE:634. MSC:00A22,33-00,65-00.}}&lt;/ref&gt;
* {{anchor|GR-E6|Chinese|GR-C1}}{{cite book |title=Table of Integrals, Series, and Products |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |editor-first1=Alan |editor-last1=Jeffrey |editor-first2=Daniel |editor-last2=Zwillinger |translator=((Scripta Technica, Inc.)) |date=July 2000 |edition=6 |publisher=[[Academic Press, Inc.]] |isbn=0-12-294757-6 |mr=1773820 |id=GR:10 |url=https://books.google.com/books?id=h4y-36vKIZgC |access-date=2016-02-21}} Red cover, xlvii+1163 pages.&lt;ref name="ZBL_981-65001"&gt;{{cite journal |author-first=Sarukkai Krishnamachari |author-last=Rangarajan |title=Gradshteyn, I. S.; Ryzhik, I. M. Table of integrals, series, and products. Translated from the Russian. Translation edited and with a preface by Alan Jeffrey and Daniel Zwillinger. 6th ed. San Diego, CA: Academic Press |zbl=0981.65001 |journal=|url=http://www.zentralblatt-math.org/zmath/en/advanced/?q=an:0981.65001 |access-date=2016-02-16}}&lt;/ref&gt; (A reprint edition "积分, 级数和乘积表" by [[World Books Press]] became available in China under {{ISBN|7-5062-6546-X}} / {{ISBN|978-7-5062-6546-1}} in April 2004.) Errata:&lt;ref name="Moll_Scientia_Part_1"/&gt;&lt;ref name="Moll_Scientia_Part_10"/&gt;&lt;ref name="Moll_Scientia_Part_14"/&gt;&lt;ref name="ZBL_981-65001"/&gt;&lt;ref name="MTE_636"&gt;{{cite journal &lt;!-- |author-first=|author-last=--&gt;|title=Table Errata 636 |journal=[[Mathematics of Computation]] |volume=71 |number=239 |date=July 2002 |pages=1335–1336 |jstor=2698918 |id=MTE:636.}}&lt;/ref&gt;&lt;ref name="MTE_637"&gt;{{cite journal &lt;!-- |author-first=|author-last=--&gt;|title=Table Errata 637 |journal=[[Mathematics of Computation]] |volume=71 |number=239 |date=July 2002 |pages=1335–1336 |jstor=2698918 |id=MTE:637.}}&lt;/ref&gt;&lt;ref name="Errata_EN-6"&gt;{{cite web |author-first1=Daniel |author-last1=Zwillinger |author-first2=Alan |author-last2=Jeffrey |title=Errata for Tables of Integrals, Series, and Products, 6th edition by I. S. Gradshteyn and M. Ryzhik edited by Alan Jeffrey and Daniel Zwillinger, Academic Press, Orlando, Florida, 2000, ISBN 0-12-294757-6 |date=2005-11-10 |url=http://www.mathtable.com/errata/gr6_errata.pdf |access-date=2016-03-08 |dead-url=no |archive-url=https://web.archive.org/web/20160308003149/http://www.mathtable.com/errata/gr6_errata.pdf |archive-date=2016-03-08}} (NB. This list of 64 pages has 398 entries. According to Daniel Zwillinger it is incomplete.)&lt;/ref&gt;
* {{anchor|GR-E7|GR-C2}}{{cite book |title=Table of Integrals, Series, and Products |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |editor-first1=Alan |editor-last1=Jeffrey |editor-first2=Daniel |editor-last2=Zwillinger |translator=((Scripta Technica, Inc.)) |date=February 2007 |edition=7 |publisher=[[Academic Press, Inc.]] |isbn=978-0-12-373637-6 |id=GR:11 |mr=2360010 |url=https://books.google.com/books?id=aBgFYxKHUjsC |access-date=2016-02-21}} [http://fisica.ciens.ucv.ve/~svincenz/TISPISGIMR.pdf] xlviii+1171 pages, with CD-ROM.&lt;ref name="Jeffrey_2007"/&gt;&lt;ref name="ZBL_1208-65001"&gt;{{cite journal |title=Gradshteyn, I. S.; Ryzhik, I. M. Table of integrals, series, and products. Translated from the Russian. Translation edited and with a preface by Alan Jeffrey and Daniel Zwillinger. With one CD-ROM (Windows, Macintosh and UNIX). 7th ed. Amsterdam: Elsevier/Academic Press (ISBN 978-0-12-373637-6). |zbl=1208.65001 |journal=|url=http://www.zentralblatt-math.org/zmath/en/advanced/?q=an:1208.65001 |access-date=2016-02-16}}&lt;/ref&gt; (A reprint edition "积分, 级数和乘积表" by [[Beijing World Publishing Corporation&lt;!-- "World Book Publishing Corporation, Beijing" Company" aka "World Book Publishing Corporation Beijing"--&gt;]] ([[:zh:世界图书出版公司|世界图书出版公司]]北京公司 / WPCBJ) became available in China under {{ISBN|7-5062-8235-6}} / {{ISBN|978-7-5062-8235-2}} in May 2007.) Errata:&lt;ref name="Moll_Scientia_Part_10"/&gt;&lt;ref name="Moll_Scientia_Part_14"/&gt;&lt;ref name="Moll_Scientia_Part_16"/&gt;&lt;ref name="Moll_Scientia_Part_20"/&gt;&lt;ref name="Moll_Scientia_Part_22"/&gt;&lt;ref name="Moll_Scientia_Part_26"/&gt;&lt;ref name="Moll_Scientia_Part_28"/&gt;&lt;ref name="Errata_EN-7"&gt;{{cite web |author-first1=Daniel |author-last1=Zwillinger |author-first2=Alan |author-last2=Jeffrey |title=Errata for Tables of Integrals, Series, and Products (7th edition) by I. S. Gradshteyn and M. Ryzhik edited by Alan Jeffrey and Daniel Zwillinger, Academic Press, Orlando, Florida, 2007, ISBN 0-12-373637-4 |date=2008-04-11 |url=http://www.mathtable.com/errata/gr7_errata.pdf |access-date=2016-03-08 |dead-url=no |archive-url=https://web.archive.org/web/20160308003103/http://www.mathtable.com/errata/gr7_errata.pdf |archive-date=2016-03-08}} (NB. This list of 7 pages has 42 entries. According to Daniel Zwillinger it is incomplete.)&lt;/ref&gt;
* {{anchor|GR-E8}}{{cite book |title=Table of Integrals, Series, and Products |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |author-first5=Alan |author-last5=Jeffrey |editor-first1=Daniel |editor-last1=Zwillinger |editor-first2=Victor Hugo |editor-last2=Moll |translator=((Scripta Technica, Inc.)) |date=2015 |orig-year=October 2014&lt;!-- book clearly states 2015, not 2014, but some internet sources state October 2014, so perhaps the electronic issue was published a bit earlier --&gt; |edition=8 |publisher=[[Academic Press, Inc.]] |isbn=978-0-12-384933-5 |id=GR:12 |url=https://books.google.com/books?id=NjnLAwAAQBAJ |access-date=2016-02-21}} xlvi+1133 pages.&lt;!-- Elsevier, 2014, 9780123849342 --&gt;&lt;ref name="Zwillinger_2014"/&gt; Errata:&lt;ref name="Moll_Scientia_Part_30"/&gt;&lt;ref name="Errata_EN-8"&gt;{{cite web |author-first1=Daniel |author-last1=Zwillinger |author-first2=Victor Hugo |author-last2=Moll |title=Errata for Tables of Integrals, Series, and Products (8th edition) by I. S. Gradshteyn and M. Ryzhik edited by Daniel Zwillinger and Victor Moll, Academic Press, 2014, ISBN 0-12-384933-0 |edition=2 |date=2016-05-22 |orig-year=2014-10-06 |url=http://www.mathtable.com/errata/gr8_errata.pdf |access-date=2016-05-24 |dead-url=no |archive-url=https://web.archive.org/web/20160524023756/http://www.mathtable.com/errata/gr8_errata.pdf |archive-date=2016-05-24}} (NB. This list of 2 pages has 12 entries.)&lt;/ref&gt;

==={{anchor|Japanese}}Japanese edition===
* {{anchor|GR-J1}}{{cite book |author-first1=И. С. |author-last1=Градштейн (Guradoshu グラドシュ) |author-link1=И. С. Градштейн |author-first2=И. М. |author-last2=Рыжик (Rijiku リジク) |author-link2=И. М. Рыжик |date=December 1983 |title=Sūgaku daikōshikishū |script-title=ja:数学大公式集 |language=Japanese |trans-title=Large mathematics collection |translator-first=Yoshihiko (大槻 義彦) |translator-last=Otsuki |translator-link=:ja:大槻義彦 |publisher={{Interlanguage link multi|Maruzen|de}} (丸善) |location=Tokyo, Japan |edition=1 |isbn=978-4-621-02796-7 |id={{NCID|BN00561932}}. {{JPNO|JP84018271}} |url=http://libn02.lib.fit.ac.jp/opc/recordID/catalog.bib/BN00561932 |access-date=2016-04-06}} xv+1085 pages.

==See also==
* [[Prudnikov, Brychkov and Marichev]] (PBM)
* [[Bronshtein and Semendyayev]]
* [[Abramowitz and Stegun]] (AS)
* [[NIST Handbook of Mathematical Functions]] (DLMF)

==Notes==
&lt;references group="nb"/&gt;

==References==
&lt;references /&gt;

==External links==
* {{cite web |author-first=Daniel |author-last=Zwillinger |title=Gradshteyn and Ryzhik: Table of Integrals, Series, and Products (Home Page) |url=http://www.mathtable.com/gr/ |access-date=2016-03-08 |dead-url=no |archive-url=https://web.archive.org/web/20160308002609/http://www.mathtable.com/gr/ |archive-date=2016-03-08}}
* {{cite web |author-first=Victor Hugo |author-last=Moll |title=&lt;!-- This is a --&gt;List with the formulas and proofs in GR |url=http://www.math.tulane.edu/~vhm/Table.html |access-date=2016-03-08 |dead-url=no |archive-url=https://web.archive.org/web/20100109035110/http://www.math.tulane.edu/~vhm/Table.html |archive-date=2010-01-09}}
* {{cite web |title=SCIENTIA, Series A: Mathematical Sciences – Official Journal of the Universidad Técnica Federico Santa María
|publisher=[[Universidad Técnica Federico Santa María]] (UTFSM) |url=http://www.mat.utfsm.cl/scientia/ |accessdate=2016-03-08}}

[[Category:1943 books]]
[[Category:Articles about multiple people]]
[[Category:Handbooks and manuals]]
[[Category:Mathematics books]]
[[Category:Mathematical tables]]</text>
      <sha1>lcz1skq9pmyk80dr616jz5nwy33d7j9</sha1>
    </revision>
  </page>
  <page>
    <title>Hopf algebra</title>
    <ns>0</ns>
    <id>325714</id>
    <revision>
      <id>870360953</id>
      <parentid>864325500</parentid>
      <timestamp>2018-11-24T07:40:13Z</timestamp>
      <contributor>
        <username>Kirsion</username>
        <id>11919546</id>
      </contributor>
      <minor/>
      <comment>/* Notes and references */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27125">In [[mathematics]], a '''Hopf algebra''', named after [[Heinz Hopf]], is a structure that is simultaneously an ([[unital algebra|unital]] associative) [[Associative algebra|algebra]] and a (counital coassociative) [[coalgebra]], with these structures' compatibility making it a [[bialgebra]], and that moreover is equipped with an [[antiautomorphism]] satisfying a certain property. The [[representation theory]] of a Hopf algebra is particularly nice, since the existence of compatible comultiplication, counit, and antipode allows for the construction of tensor products of representations, trivial representations, and dual representations.

Hopf algebras occur naturally in [[algebraic topology]], where they originated and are related to the [[H-space]] concept, in [[group scheme]] theory, in [[group theory]] (via the concept of a [[group ring]]), and in numerous other places, making them probably the most familiar type of [[bialgebra]]. Hopf algebras are also studied in their own right, with much work on specific classes of examples on the one hand and classification problems on the other. They have diverse applications ranging from [[Condensed-matter physics]] and [[quantum field theory]]&lt;ref&gt;{{cite journal | last1 = Haldane | first1 = F. D. M. | last2 = Ha | first2 = Z. N. C. | last3 = Talstra | first3 = J. C. | last4 = Bernard | first4 = D. | last5 = Pasquier | first5 = V. | year = 1992 | title = Yangian symmetry of integrable quantum chains with long-range interactions and a new description of states in conformal field theory | url = | journal = Physical Review Letters | volume = 69 | issue = 14| pages = 2021–2025 | doi=10.1103/physrevlett.69.2021 | pmid=10046379| bibcode = 1992PhRvL..69.2021H }}&lt;/ref&gt; to [[string theory]]&lt;ref&gt;{{cite journal | last1 = Plefka | first1 = J. | last2 = Spill | first2 = F. | last3 = Torrielli | first3 = A. | year = 2006 | title = Hopf algebra structure of the AdS/CFT S-matrix | url = | journal = Physical Review D | volume = 74 | issue = 6| page = 066008 | doi = 10.1103/PhysRevD.74.066008 | arxiv = hep-th/0608038 | bibcode = 2006PhRvD..74f6008P }}&lt;/ref&gt; and [[Large Hadron Collider|LHC phenomenology]]&lt;ref&gt;{{Cite journal|last=Abreu|first=Samuel|last2=Britto|first2=Ruth|last3=Duhr|first3=Claude|last4=Gardi|first4=Einan|date=2017-12-01|title=Diagrammatic Hopf algebra of cut Feynman integrals: the one-loop case|url=https://link.springer.com/article/10.1007/JHEP12(2017)090|journal=Journal of High Energy Physics|language=en|volume=2017|issue=12|pages=90|doi=10.1007/jhep12(2017)090|issn=1029-8479|arxiv=1704.07931|bibcode=2017JHEP...12..090A}}&lt;/ref&gt; .

'''Theorem (Hopf)'''&lt;ref name="Hopf, 1941"&gt;{{cite journal|last1=Hopf|first1=Heinz|title=Über die Topologie der Gruppen–Mannigfaltigkeiten und ihre Verallgemeinerungen|journal=Ann. of Math. |series= 2|date=1941|volume=42|pages=22–52|doi=10.2307/1968985|language=German}}&lt;!--|accessdate=7 March 2016--&gt;&lt;/ref&gt; Let ''A'' be a finite-dimensional, [[Graded-commutative|graded commutative]], graded cocommutative Hopf algebra over a field of characteristic 0. Then ''A'' (as an algebra) is a free exterior algebra with generators of odd degree.

==Formal definition==
Formally, a Hopf algebra is a (associative and coassociative) [[bialgebra]] ''H'' over a [[field (mathematics)|field]] ''K'' together with a [[linear transformation|''K''-linear]] map ''S'': ''H'' → ''H'' (called the '''antipode''') such that the following diagram [[commutative diagram|commutes]]:
&lt;div style="text-align: center;"&gt;
[[File:Hopf algebra.svg|250px|antipode commutative diagram]]
&lt;/div&gt;
Here Δ is the comultiplication of the bialgebra, ∇ its multiplication, η its unit and ε its counit. In the sumless [[Sweedler notation]], this property can also be expressed as
:&lt;math&gt;S(c_{(1)})c_{(2)}=c_{(1)}S(c_{(2)})=\varepsilon(c)1\qquad\mbox{ for all }c\in H.&lt;/math&gt;

As for [[associative algebra|algebra]]s, one can replace the underlying field ''K'' with a [[commutative ring]] ''R'' in the above definition.&lt;ref name=Und55&gt;Underwood (2011) p.55&lt;/ref&gt;

The definition of Hopf algebra is [[Dual (category theory)|self-dual]] (as reflected in the symmetry of the above diagram), so if one can define a [[Dual space|dual]] of ''H'' (which is always possible if ''H'' is finite-dimensional), then it is automatically a Hopf algebra.&lt;ref name=Und62&gt;Underwood (2011) p.62&lt;/ref&gt;

=== Structure constants ===
Fixing a basis &lt;math&gt;\{e_k\}&lt;/math&gt; for the underlying vector space, one may define the algebra in terms of [[structure constant]]s for multiplication:
:&lt;math&gt;e_i\nabla e_j = \sum_k \mu^k_{\;ij} e_k&lt;/math&gt;
for co-multiplication:
:&lt;math&gt;\Delta e_i = \sum_{j,k} \nu^{\;jk}_i e_j\otimes e_k&lt;/math&gt;
and the antipode:
:&lt;math&gt;S e_i = \sum_j \tau_i^{\;j} e_j&lt;/math&gt;
Associativity then requires that
:&lt;math&gt;\mu^k_{\;ij}\mu^m_{\;kn}=\mu^k_{\;jn}\mu^m_{\;ik}&lt;/math&gt;
while co-associativity requires that
:&lt;math&gt;\nu_k^{\;ij}\nu_i^{\;mn}=\nu_k^{\;mi}\nu_i^{\;nj}&lt;/math&gt;
The connecting axiom requires that
:&lt;math&gt;\nu_k^{\;ij}\tau_j^{\;m}\mu^n_{\;pm}=\nu_k^{\;jm}\tau_j^{\,\;i}\mu^n_{\;pm}&lt;/math&gt;

===Properties of the antipode===
The antipode ''S'' is sometimes required to have a ''K''-linear inverse, which is automatic in the finite-dimensional case{{clarify|date=May 2018|reason=Either provide a reference or briefly sketch an explanation}}, or if ''H'' is [[commutative]] or [[cocommutative]] (or more generally [[Quasitriangular Hopf algebra|quasitriangular]]).

In general, ''S'' is an [[antihomomorphism]],&lt;ref&gt;{{cite book|author=Dăscălescu, Năstăsescu &amp; Raianu |title=Prop. 4.2.6|booktitle=Hopf Algebra: An Introduction |year=2001|url={{Google books|plainurl=y|id=pBJ6sbPHA0IC|page=153|text=is an antimorphism of algebras}}|page=153}}&lt;/ref&gt; so ''S''&lt;sup&gt;2&lt;/sup&gt; is a [[homomorphism]], which is therefore an automorphism if ''S'' was invertible (as may be required).

If ''S''&lt;sup&gt;2&lt;/sup&gt; = id&lt;sub&gt;''H''&lt;/sub&gt;, then the Hopf algebra is said to be '''involutive''' (and the underlying algebra with involution is a [[*-algebra]]). If ''H'' is finite-dimensional semisimple over a field of characteristic zero, commutative, or cocommutative, then it is involutive.

If a bialgebra ''B'' admits an antipode ''S'', then ''S'' is unique ("a bialgebra admits at most 1 Hopf algebra structure").&lt;ref&gt;{{cite book|author=Dăscălescu, Năstăsescu &amp; Raianu |title=Remarks 4.2.3|booktitle=Hopf Algebra: An Introduction |year=2001|url={{Google books|plainurl=y|id=pBJ6sbPHA0IC|page=151|text=the antipode is unique}}|page=151}}&lt;/ref&gt; Thus, the antipode does not pose any extra structure which we can choose: Being a Hopf algebra is a property of a bialgebra.

The antipode is an analog to the inversion map on a group that sends ''g'' to ''g''&lt;sup&gt;−1&lt;/sup&gt;.&lt;ref&gt;[http://www.mathematik.uni-muenchen.de/~pareigis/Vorlesungen/98SS/Quantum_Groups/LN2_1.PDF Quantum groups lecture notes]&lt;/ref&gt;

===Hopf subalgebras===
A subalgebra ''A'' of a Hopf algebra ''H'' is a Hopf subalgebra if it is a subcoalgebra of ''H'' and the antipode ''S'' maps ''A'' into ''A''. In other words, a Hopf subalgebra A is a Hopf algebra in its own right when the multiplication, comultiplication, counit and antipode of ''H'' is restricted to ''A'' (and additionally the identity 1 of ''H'' is  required to be in A). The Nichols–Zoeller freeness theorem  established (in 1989) that the natural ''A''-module ''H'' is free of finite rank if ''H'' is finite-dimensional: a generalization of [[Lagrange's theorem (group theory)|Lagrange's theorem for subgroups]]. As a corollary of this and integral theory, a Hopf subalgebra of a semisimple finite-dimensional Hopf algebra is automatically semisimple.

A Hopf subalgebra ''A'' is said to be right normal in a Hopf algebra ''H'' if it satisfies the condition of stability, ''ad&lt;sub&gt;r&lt;/sub&gt;''(''h'')(''A'') ⊆ ''A'' for all ''h'' in ''H'', where the right adjoint mapping ''ad&lt;sub&gt;r&lt;/sub&gt;'' is defined by ''ad&lt;sub&gt;r&lt;/sub&gt;''(''h'')(''a'') = ''S''(''h''&lt;sub&gt;(1)&lt;/sub&gt;)''ah''&lt;sub&gt;(2)&lt;/sub&gt; for all ''a'' in ''A'', ''h'' in ''H''. Similarly, a Hopf subalgebra ''A'' is left normal in ''H'' if it is stable under the left adjoint mapping defined by ''ad&lt;sub&gt;l&lt;/sub&gt;''(''h'')(''a'') = ''h''&lt;sub&gt;(1)&lt;/sub&gt;''aS''(''h''&lt;sub&gt;(2)&lt;/sub&gt;). The two conditions of normality are equivalent if the antipode ''S'' is bijective, in which case ''A'' is said to be a normal Hopf subalgebra.

A normal Hopf subalgebra ''A'' in ''H'' satisfies the condition (of equality of subsets of H): ''HA''&lt;sup&gt;+&lt;/sup&gt; = ''A''&lt;sup&gt;+&lt;/sup&gt;''H'' where ''A''&lt;sup&gt;+&lt;/sup&gt; denotes the kernel of the counit on ''K''. This normality condition implies that ''HA''&lt;sup&gt;+&lt;/sup&gt; is a Hopf ideal of ''H'' (i.e. an algebra ideal in the kernel of the counit, a coalgebra coideal and stable under the antipode). As a consequence one has a quotient Hopf algebra ''H''/''HA''&lt;sup&gt;+&lt;/sup&gt; and epimorphism ''H'' → ''H''/''A''&lt;sup&gt;+&lt;/sup&gt;''H'', a theory analogous to that of normal subgroups and quotient groups in [[group theory]].&lt;ref&gt;Montgomery (1993) p.36&lt;/ref&gt;

===Hopf orders===
A '''Hopf order''' ''O'' over an [[integral domain]] ''R'' with [[field of fractions]] ''K'' is an [[Order (ring theory)|order]] in a Hopf algebra ''H'' over ''K'' which is closed under the algebra and coalgebra operations: in particular, the comultiplication Δ maps ''O'' to ''O''⊗''O''.&lt;ref name=Und82&gt;Underwood (2011) p.82&lt;/ref&gt;

===Group-like elements===
A '''group-like element''' is a nonzero element ''x'' such that Δ(''x'') = ''x''⊗''x''. The group-like elements form a group with inverse given by the antipode.&lt;ref&gt;{{cite book | page=149 | title=Algebras, Rings, and Modules: Lie Algebras and Hopf Algebras | volume=168 | series=Mathematical surveys and monographs | first1=Michiel | last1=Hazewinkel | first2=Nadezhda Mikhaĭlovna | last2=Gubareni | first3=Vladimir V. | last3=Kirichenko | publisher=[[American Mathematical Society]] | year=2010 | isbn=0-8218-7549-3 }}&lt;/ref&gt; A '''[[primitive element (co-algebra)|primitive element]]''' ''x'' satisfies Δ(''x'') = ''x''⊗1 + 1⊗''x''.&lt;ref&gt;{{cite book | at=p. 307, C.42  | title=The Concise Handbook of Algebra | editor1-first=Aleksandr Vasilʹevich | editor1-last=Mikhalev | editor2-first=Günter | editor2-last=Pilz | publisher=[[Springer-Verlag]] | year=2002 | isbn=0792370724 }}&lt;/ref&gt;&lt;ref&gt;{{cite book | title=Hopf Algebras | volume=74 | series=Cambridge Tracts in Mathematics | first=Eiichi | last=Abe | publisher=[[Cambridge University Press]] | year=2004 | isbn=0-521-60489-3 | page=59 }}&lt;/ref&gt;

==Representation theory==
Let ''A'' be a Hopf algebra, and let ''M'' and ''N'' be ''A''-modules. Then, ''M'' ⊗ ''N'' is also an ''A''-module, with
:&lt;math&gt;a(m\otimes n):=\Delta(a)(m \otimes n)=(a_1\otimes a_2)(m\otimes n)=(a_1 m \otimes a_2 n)&lt;/math&gt;
for ''m'' ∈ ''M'', ''n'' ∈ ''N'' and Δ(''a'') = (''a''&lt;sub&gt;1&lt;/sub&gt;, ''a''&lt;sub&gt;2&lt;/sub&gt;). Furthermore, we can define the trivial representation as the base field ''K'' with
:&lt;math&gt;a(m):=\epsilon(a)m&lt;/math&gt;
for ''m'' ∈ ''K''. Finally, the dual representation of ''A'' can be defined: if ''M'' is an ''A''-module and ''M*'' is its dual space, then
:&lt;math&gt;(af)(m):=f(S(a)m)&lt;/math&gt;
where ''f'' ∈ ''M*'' and ''m'' ∈ ''M''.

The relationship between Δ, ε, and ''S'' ensure that certain natural homomorphisms of vector spaces are indeed homomorphisms of ''A''-modules. For instance, the natural isomorphisms of vector spaces ''M'' → ''M'' ⊗ ''K'' and ''M'' → ''K'' ⊗ ''M'' are also isomorphisms of ''A''-modules. Also, the map of vector spaces ''M*'' ⊗ ''M'' → ''K'' with ''f'' ⊗ ''m'' → ''f''(''m'') is also a homomorphism of ''A''-modules. However, the map ''M'' ⊗ ''M*'' → ''K'' is not necessarily a homomorphism of ''A''-modules.

== Examples ==
{| class="wikitable"
|-
!  !! Depending on !! Comultiplication !! Counit !! Antipode !! Commutative !! Cocommutative !! Remarks
|-
| [[group ring|group algebra]] ''KG'' || [[group (mathematics)|group]] ''G'' || Δ(''g'') = ''g'' ⊗ ''g'' for all ''g'' in ''G'' || ''ε''(''g'') = 1 for all ''g'' in ''G'' || ''S''(''g'') = ''g''&lt;sup&gt;−1&lt;/sup&gt; for all ''g'' in ''G'' || if and only if ''G'' is abelian || yes ||
|-
| functions ''f'' from a finite&lt;ref&gt;The finiteness of ''G'' implies that ''K&lt;sup&gt;G&lt;/sup&gt;'' ⊗ ''K&lt;sup&gt;G&lt;/sup&gt;'' is naturally isomorphic to ''K''&lt;sup&gt;''G''x''G''&lt;/sup&gt;. This is used in the above formula for the comultiplication. For infinite groups ''G'', ''K&lt;sup&gt;G&lt;/sup&gt;'' ⊗ ''K&lt;sup&gt;G&lt;/sup&gt;'' is a proper subset of ''K''&lt;sup&gt;''G''x''G''&lt;/sup&gt;. In this case the space of functions with finite [[support (mathematics)|support]] can be endowed with a Hopf algebra structure.&lt;/ref&gt; group to ''K'', ''K&lt;sup&gt;G&lt;/sup&gt;'' (with pointwise addition and multiplication) || finite group ''G'' || Δ(''f'')(''x'',''y'') = ''f''(''xy'') || ''ε''(''f'') = ''f''(1&lt;sub&gt;''G''&lt;/sub&gt;)|| ''S''(''f'')(''x'') = ''f''(''x''&lt;sup&gt;−1&lt;/sup&gt;)  || yes || if and only if ''G'' is commutative ||
|- 
|[[Representative function]]s on a compact group||[[compact group]] ''G'' || Δ(''f'')(''x'',''y'') = ''f''(''xy'') || ''ε''(''f'') = ''f''(1&lt;sub&gt;''G''&lt;/sub&gt;)|| ''S''(''f'')(''x'') = ''f''(''x''&lt;sup&gt;−1&lt;/sup&gt;)  || yes || if and only if ''G'' is commutative || Conversely, every commutative involutive [[reduced algebra|reduced]] Hopf algebra over '''C''' with a finite Haar integral arises in this way, giving one formulation of [[Tannaka–Krein duality]].&lt;ref&gt;{{citation|last=Hochschild|first=G|title=Structure of Lie groups|year=1965|pages=14–32|publisher=Holden-Day}}&lt;/ref&gt;
|-
| [[Regular function]]s on an [[algebraic group]] || || Δ(''f'')(''x'',''y'') = ''f''(''xy'') || ''ε''(''f'') = ''f''(1&lt;sub&gt;''G''&lt;/sub&gt;)|| ''S''(''f'')(''x'') = ''f''(''x''&lt;sup&gt;−1&lt;/sup&gt;)  || yes || if and only if ''G'' is commutative || Conversely, every commutative Hopf algebra over a field arises from a [[group scheme]] in this way, giving an [[equivalence (category theory)|antiequivalence]] of categories.&lt;ref&gt;{{Citation | last1=Jantzen | first1=Jens Carsten | author1-link=Jens Carsten Jantzen | title=Representations of algebraic groups | publisher=[[American Mathematical Society]] | location=Providence, R.I. | edition=2nd | series=Mathematical Surveys and Monographs | isbn=978-0-8218-3527-2 | year=2003 | volume=107}}, section 2.3&lt;/ref&gt;
|-
| [[Tensor algebra]] T(''V'') || [[vector space]] ''V'' || Δ(''x'') = ''x'' ⊗ 1 + 1 ⊗ ''x'', ''x'' in ''V'',  Δ(1) = 1 ⊗ 1 || ''ε''(''x'') = 0  || ''S''(''x'') = −''x'' for all ''x'' in 'T&lt;sup&gt;1&lt;/sup&gt;(''V'') (and extended to higher tensor powers) || If and only if dim(''V'')=0,1 || yes || [[symmetric algebra]] and [[exterior algebra]] (which are quotients of the tensor algebra) are also Hopf algebras with this definition of the comultiplication, counit and antipode
|-
| [[Universal enveloping algebra]] U(g) || [[Lie algebra]] ''g'' || Δ(''x'') = ''x'' ⊗ 1 + 1 ⊗ ''x'' for every ''x'' in ''g'' (this rule is compatible with [[commutator]]s and can therefore be uniquely extended to all of ''U'') || ''ε''(''x'') = 0 for all ''x'' in ''g'' (again, extended to ''U'') || ''S''(''x'') = −''x''  || if and only if ''g'' is abelian || yes ||
|-
| [[Sweedler's Hopf algebra]] ''H''=''K''[''c'', ''x'']/''c&lt;sup&gt;2&lt;/sup&gt;'' = 1, ''x''&lt;sup&gt;2&lt;/sup&gt; = 0 and ''xc'' = −''cx''.|| ''K'' is a field with [[Field characteristic|characteristic]] different from 2 || Δ(''c'') = ''c'' ⊗ ''c'',  Δ(''x'') = ''c'' ⊗ ''x'' + ''x'' ⊗ 1, Δ(1) = 1 ⊗ 1 || ''ε''(''c'') = 1 and ''ε''(''x'') = 0 || ''S''(''c'') = ''c''&lt;sup&gt;−1&lt;/sup&gt; = ''c'' and ''S''(''x'') = −''cx'' || no || no || The underlying [[vector space]] is generated by {1, ''c'', ''x'', ''cx''} and thus has dimension 4. This is the smallest example of a Hopf algebra that is both non-commutative and non-cocommutative.
|-
| [[ring of symmetric functions]]&lt;ref&gt;See
    Michiel Hazewinkel, ''Symmetric Functions, Noncommutative Symmetric Functions, and Quasisymmetric Functions'', Acta Applicandae Mathematica, January 2003, Volume 75, Issue 1-3, pp 55–83&lt;/ref&gt; ||   
|| in terms of complete homogeneous symmetric functions ''h''&lt;sub&gt;''k''&lt;/sub&gt; (''k'' &amp;ge; 1):

Δ(''h&lt;sub&gt;k&lt;/sub&gt;'') = 1 ⊗ ''h&lt;sub&gt;k&lt;/sub&gt;'' + ''h''&lt;sub&gt;1&lt;/sub&gt; ⊗ ''h''&lt;sub&gt;''k''−1&lt;/sub&gt; + ... +  ''h''&lt;sub&gt;''k''−1&lt;/sub&gt; ⊗ ''h''&lt;sub&gt;1&lt;/sub&gt; + ''h&lt;sub&gt;k&lt;/sub&gt;'' ⊗ 1.
|| ''ε''(''h&lt;sub&gt;k&lt;/sub&gt;'') = 0
||  ''S''(''h&lt;sub&gt;k&lt;/sub&gt;'') = (−1)&lt;sup&gt;''k''&lt;/sup&gt; ''e&lt;sub&gt;k&lt;/sub&gt;''
|| yes || yes ||
|}

Note that functions on a finite group can be identified with the group ring, though these are more naturally thought of as dual – the group ring consists of ''finite'' sums of elements, and thus pairs with functions on the group by evaluating the function on the summed elements.

== Cohomology of Lie groups ==
The cohomology algebra (over a field &lt;math&gt;K&lt;/math&gt;) of a Lie group &lt;math&gt;G&lt;/math&gt; is a Hopf algebra: the multiplication is provided by the [[cup product]], and the comultiplication 
:&lt;math&gt;H^*(G,K) \rightarrow H^*(G\times G,K) \cong H^*(G,K)\otimes H^*(G,K)&lt;/math&gt;
by the group multiplication &lt;math&gt;G\times G\to G&lt;/math&gt;. This observation was actually a source of the notion of Hopf algebra. Using this structure, Hopf proved a structure theorem for the cohomology algebra of Lie groups.

'''Theorem (Hopf)'''&lt;ref name="Hopf, 1941"/&gt; Let &lt;math&gt;A&lt;/math&gt; be a finite-dimensional, [[Graded-commutative|graded commutative]], graded cocommutative Hopf algebra over a field of characteristic 0. Then &lt;math&gt;A&lt;/math&gt; (as an algebra) is a free exterior algebra with generators of odd degree.

==Quantum groups and non-commutative geometry==
{{Main|quantum group}}

All examples above are either commutative (i.e. the multiplication is [[commutative]]) or co-commutative (i.e.&lt;ref name=Und57&gt;Underwood (2011) p.57&lt;/ref&gt; Δ = ''T'' ∘ Δ where the ''twist map''&lt;ref name=Und36&gt;Underwood (2011) p.36&lt;/ref&gt; ''T'': ''H'' ⊗ ''H'' → ''H'' ⊗ ''H'' is defined by ''T''(''x'' ⊗ ''y'') = ''y'' ⊗ ''x''). Other interesting Hopf algebras are certain "deformations" or "[[quantization (physics)|quantization]]s" of those from example 3 which are neither commutative nor co-commutative. These Hopf algebras are often called ''[[quantum groups]]'', a term that is so far only loosely defined. They are important in [[noncommutative geometry]], the idea being the following: a standard algebraic group is well described by its standard Hopf algebra of regular functions; we can then think of the deformed version of this Hopf algebra as describing a certain "non-standard" or "quantized" algebraic group (which is not an algebraic group at all). While there does not seem to be a direct way to define or manipulate these non-standard objects, one can still work with their Hopf algebras, and indeed one ''identifies'' them with their Hopf algebras. Hence the name "quantum group".

== Related concepts ==
[[Graded algebra|Graded]] Hopf algebras are often used in [[algebraic topology]]: they are the natural algebraic structure on the direct sum of all [[homology (mathematics)|homology]] or [[cohomology]] groups of an [[H-space]].

[[Locally compact quantum group]]s generalize Hopf algebras and carry a [[topological space|topology]]. The algebra of all [[continuous function]]s on a [[Lie group]] is a locally compact quantum group.

[[Quasi-Hopf algebra]]s are generalizations of Hopf algebras, where coassociativity only holds up to a twist. They have been used in the study of the [[Knizhnik–Zamolodchikov equations]].&lt;ref name=Mon203&gt;Montgomery (1993) p.&amp;nbsp;203&lt;/ref&gt;

[[Multiplier Hopf algebra]]s introduced by Alfons Van Daele in 1994&lt;ref&gt;{{cite journal | last1 = Van Daele | first1 = Alfons | year = 1994 | title = Multiplier Hopf algebras | url = http://www.ams.org/tran/1994-342-02/S0002-9947-1994-1220906-5/S0002-9947-1994-1220906-5.pdf| journal = Transactions of the American Mathematical Society | volume = 342 | issue = 2| pages = 917–932 | doi=10.1090/S0002-9947-1994-1220906-5}}&lt;/ref&gt; are generalizations of [[Hopf algebras]] where comultiplication from an algebra (with or without unit) to the [[multiplier algebra]] of tensor product algebra of the algebra with itself.

[[Hopf group-(co)algebra]]s introduced by V. G. Turaev in 2000 are also generalizations of Hopf algebras.

===Weak Hopf algebras===
[[Weak Hopf algebra]]s, or quantum groupoids, are  generalizations of Hopf algebras. Like Hopf algebras, weak Hopf algebras form a self-dual class of algebras; i.e., if ''H'' is a (weak) Hopf algebra, so is ''H''*, the dual space of linear forms on ''H'' (with respect to the algebra-coalgebra structure obtained from  the natural pairing with ''H'' and its coalgebra-algebra structure). A weak Hopf algebra ''H'' is usually taken to be a
*finite-dimensional algebra and coalgebra with coproduct Δ: ''H'' → ''H'' ⊗ ''H''  and counit ε: ''H'' → ''k'' satisfying all the axioms of Hopf algebra except possibly Δ(1) ≠ 1 ⊗ 1 or ε(''ab'') ≠ ε(''a'')ε(''b'') for some ''a,b'' in ''H''. Instead one requires the following:

::&lt;math&gt; (\Delta(1) \otimes 1)(1 \otimes \Delta(1)) = (1 \otimes \Delta(1))(\Delta(1) \otimes 1) = (\Delta \otimes \mbox{Id})\Delta(1)&lt;/math&gt;
::&lt;math&gt; \epsilon(abc) = \sum \epsilon(ab_{(1)})\epsilon(b_{(2)}c) = \sum \epsilon(ab_{(2)})\epsilon(b_{(1)}c)&lt;/math&gt;

:for all ''a'', ''b'', and ''c'' in ''H''.
* ''H'' has a weakened antipode ''S'': ''H'' → ''H'' satisfying the axioms:

#&lt;math&gt;S(a_{(1)})a_{(2)} = 1_{(1)} \epsilon(a 1_{(2)})&lt;/math&gt; for all ''a'' in ''H'' (the right-hand side is the interesting projection usually denoted by Π&lt;sup&gt;''R''&lt;/sup&gt;(''a'') or ε&lt;sub&gt;''s''&lt;/sub&gt;(''a'') with image a separable subalgebra denoted by ''H&lt;sup&gt;R&lt;/sup&gt;'' or ''H&lt;sub&gt;s&lt;/sub&gt;''); 
#&lt;math&gt;a_{(1)}S(a_{(2)}) =  \epsilon(1_{(1)}a)1_{(2)}&lt;/math&gt; for all ''a'' in ''H'' (another interesting projection usually denoted by Π&lt;sup&gt;''R''&lt;/sup&gt;(''a'') or ε&lt;sub&gt;''t''&lt;/sub&gt;(''a'') with image a separable algebra ''H&lt;sup&gt;L&lt;/sup&gt;'' or ''H&lt;sub&gt;t&lt;/sub&gt;'', anti-isomorphic to ''H&lt;sup&gt;L&lt;/sup&gt;'' via ''S'');
#&lt;math&gt;S(a_{(1)})a_{(2)}S(a_{(3)}) = S(a) &lt;/math&gt; for all ''a'' in ''H''.

:Note that if Δ(1) = 1 ⊗ 1, these conditions reduce to the two usual conditions on the antipode of a Hopf algebra.

The axioms are partly chosen so that the category of ''H''-modules is a [[rigid category|rigid monoidal category]]. The unit ''H''-module is the separable algebra ''H&lt;sup&gt;L&lt;/sup&gt;'' mentioned above. 
 
For example, a finite [[groupoid]] algebra is a weak Hopf algebra. In particular, the groupoid algebra on [n] with one pair of invertible arrows ''e&lt;sub&gt;ij&lt;/sub&gt;'' and ''e&lt;sub&gt;ji&lt;/sub&gt;''  between ''i'' and ''j'' in [''n''] is isomorphic to the algebra ''H'' of ''n'' x ''n'' matrices. The weak Hopf algebra structure on this particular ''H'' is given by coproduct Δ(''e&lt;sub&gt;ij&lt;/sub&gt;'') = ''e&lt;sub&gt;ij&lt;/sub&gt;'' ⊗ ''e&lt;sub&gt;ij&lt;/sub&gt;'', counit ε(''e&lt;sub&gt;ij&lt;/sub&gt;'') = 1 and antipode ''S''(''e&lt;sub&gt;ij&lt;/sub&gt;'') = ''e&lt;sub&gt;ji&lt;/sub&gt;''. The separable subalgebras ''H&lt;sup&gt;L&lt;/sup&gt;'' and ''H&lt;sup&gt;R&lt;/sup&gt;'' coincide and are non-central commutative algebras in this particular case (the subalgebra of diagonal matrices).

Early theoretical contributions to weak Hopf algebras are to be found in&lt;ref&gt;{{cite journal | last1 = Böhm | first1 = Gabriella | last2 = Nill | first2 = Florian | last3 = Szlachanyi | first3 = Kornel | year = 1999 | title =  Weak Hopf Algebras| url = | journal = J. Algebra | volume = 221 | issue = | pages = 385–438 | doi=10.1006/jabr.1999.7984}}&lt;/ref&gt; as well as&lt;ref&gt;Dmitri Nikshych, Leonid Vainerman, in: New direction in Hopf algebras, S. Montgomery and H.-J. Schneider, eds., M.S.R.I. Publications, vol. 43, Cambridge, 2002, 211–262.&lt;/ref&gt;

===Hopf algebroids===
See [[Hopf algebroid]]

==Analogy with groups==
Groups can be axiomatized by the same diagrams (equivalently, operations) as a Hopf algebra, where ''G'' is taken to be a set instead of a module. In this case:
* the field ''K'' is replaced by the 1-point set
* there is a natural counit (map to 1 point)
* there is a natural comultiplication (the diagonal map)
* the unit is the identity element of the group
* the multiplication is the multiplication in the group
* the antipode is the inverse
In this philosophy, a group can be thought of as a Hopf algebra over the "[[field with one element]]".&lt;ref&gt;[http://sbseminar.wordpress.com/2007/10/07/group-hopf-algebra/ Group = Hopf algebra « Secret Blogging Seminar&lt;!-- Bot generated title --&gt;], [https://www.youtube.com/watch?v=p3kkm5dYH-w Group objects and Hopf algebras], video of Simon Willerton.&lt;/ref&gt;

== See also ==
* [[Quasitriangular Hopf algebra]]
* [[Algebra/set analogy]]
* [[Representation theory of Hopf algebras]]
* [[Ribbon Hopf algebra]]
* [[Superalgebra]]
* [[Supergroup (physics)|Supergroup]]
* [[Anyonic Lie algebra]]
* [[Sweedler's Hopf algebra]]
* [[Hopf algebra of permutations]]
* [[Milnor–Moore theorem]]

==Notes and references==

=== Notes ===
{{Reflist}}

=== References ===
* {{Citation| last1=Dăscălescu| first1=Sorin| last2=Năstăsescu| first2=Constantin| last3=Raianu| first3=Șerban| year=2001| title=Hopf Algebras. An introduction| edition=1st| volume = 235| series=Pure and Applied Mathematics | publisher=Marcel Dekker| isbn = 0-8247-0481-9 | zbl=0962.16026 }}.
* [[Pierre Cartier (mathematician)|Pierre Cartier]], [http://preprints.ihes.fr/2006/M/M-06-40.pdf ''A primer of Hopf algebras''], IHES preprint, September 2006, 81 pages
* {{citation | last=Fuchs | first=Jürgen | title=Affine Lie algebras and quantum groups. An introduction with applications in conformal field theory | series=Cambridge Monographs on Mathematical Physics | location=Cambridge | publisher=Cambridge University Press | year=1992 | isbn=0-521-48412-X | zbl=0925.17031 }}
* [[Heinz Hopf]], Uber die Topologie der Gruppen-Mannigfaltigkeiten und ihrer Verallgemeinerungen, [[Annals of Mathematics]] 42 (1941), 22–52. Reprinted in Selecta Heinz Hopf, pp.&amp;nbsp;119–151, Springer, Berlin (1964). {{MR|4784}}, {{zbl|0025.09303}}
* {{citation | last=Montgomery | first=Susan | authorlink=Susan Montgomery|title=Hopf algebras and their actions on rings | series=Regional Conference Series in Mathematics | volume=82 | location=Providence, Rhode Island | publisher=[[American Mathematical Society]] | year=1993 | isbn=0-8218-0738-2 | zbl=0793.16029 }}
* {{Citation | last1=Street | first1=Ross | author1-link=Ross Street | title=Quantum groups: A Path To Current Algebra | publisher=Cambridge University Press | series=Australian Mathematical Society Lecture Series | volume=19 | year=2007 | isbn=978-0-521-69524-4 | mr=2294803 | zbl=1117.16031 }}.
*{{Citation | last1=Sweedler | first1=Moss E. | title=Hopf algebras | url=https://books.google.com/books?id=8FnvAAAAMAAJ | publisher=W. A. Benjamin, Inc., New York | series=Mathematics Lecture Note Series | year=1969 | mr=0252485 | zbl=0194.32901  }}
* {{citation | last=Underwood | first=Robert G. | title=An introduction to Hopf algebras | location=Berlin | publisher=Springer-Verlag | year=2011 | isbn=978-0-387-72765-3 | zbl=1234.16022 }}

{{DEFAULTSORT:Hopf Algebra}}
[[Category:Hopf algebras| ]]
[[Category:Monoidal categories]]
[[Category:Representation theory]]</text>
      <sha1>hd0nidiplp6ee0rb8uz8jjirkc18y7h</sha1>
    </revision>
  </page>
  <page>
    <title>Information content</title>
    <ns>0</ns>
    <id>542447</id>
    <revision>
      <id>863260992</id>
      <parentid>863259977</parentid>
      <timestamp>2018-10-09T17:57:03Z</timestamp>
      <contributor>
        <username>Daviddwd</username>
        <id>14327137</id>
      </contributor>
      <minor/>
      <comment>/* Information from frequency of rolls */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23195">{{cleanup|reason=unclear terminology|date=June 2017}}
In [[information theory]], '''information content''', '''self-information''', or '''surprisal''' of a [[random variable]] or [[signal]] is the amount of [[information gain]]ed when it is [[Sampling (statistics)|sampled]].  Formally, information content is a [[random variable]] defined for any [[Event (probability theory)|event in probability theory]] regardless of whether a random variable is being measured or not.  

Information content is expressed in a [[Units of information|unit of information]], as explained below.  The [[expected value]] of self-information is [[Entropy (information theory)|information theoretic entropy]], the average amount of information an observer would expect to gain about a system when [[Sampling (signal processing)|sampling]] the random variable.&lt;ref&gt;Jones, D.S., ''Elementary Information Theory'', Vol., Clarendon Press, Oxford pp 11-15 1979&lt;/ref&gt;

== Definition ==
Given a random variable &lt;math&gt;X&lt;/math&gt; with [[probability mass function]] &lt;math&gt;p_{X}{\left(x\right)}&lt;/math&gt;, the self-information of measuring &lt;math&gt;X&lt;/math&gt; as [[Outcome (probability)|outcome]] &lt;math&gt;x&lt;/math&gt; is defined as &lt;math&gt;\operatorname I_X(x) := 
 - \log{\left[p_{X}{\left(x\right)}\right]}
 = \log{\left(\frac{1}{p_{X}{\left(x\right)}}\right)}. &lt;/math&gt;&lt;ref name=":0"&gt;{{Cite book|url=https://www.worldcat.org/oclc/608622533|title=Quantum Computing Explained|last=McMahon|first=David M.|publisher=Wiley-Interscience|year=2008|isbn=9780470181386|location=Hoboken, NJ|pages=|oclc=608622533}}&lt;/ref&gt;

Broadly given an [[Event (probability theory)|event]] &lt;math&gt;E&lt;/math&gt; with [[probability]] &lt;math&gt;P&lt;/math&gt;, information content is defined analogously:

&lt;math&gt;\operatorname I(E) := 
 - \log{\left[\Pr{\left(E\right)}\right]}
 = -\log{\left(P\right)}. &lt;/math&gt;

In general, the [[Base (exponentiation)|base]] of the logarithmic chosen does not matter for most information-theoretic properties; however, different [[units of information]] are assigned based on popular choices of base. 

If the logarithmic base is 2, the unit is named the [[Shannon (unit)|Shannon]] but "[[bit]]" is also used.  If the base of the logarithm is the [[natural logarithm]] (logarithm to base [[Euler's number]] e ≈ 2.7182818284), the unit is called the [[Nat (unit)|nat]], short for "natural".  If the logarithm is to [[base 10]], the units are called [[Hartley (unit)|hartleys]] or [[decimal]] [[Numerical digit|digits]].

The [[Shannon entropy]] of the random variable &lt;math&gt;X &lt;/math&gt; above is [[Shannon entropy#Definition|defined as]]

&lt;math display="block"&gt;\begin{alignat}{2} 
 \Eta(X) &amp;= \sum_{x} {-p_{X}{\left(x\right)} \log{p_{X}{\left(x\right)}}} \\
 &amp;= \sum_{x} {p_{X}{\left(x\right)} \operatorname{I}_X(x)} \\
 &amp;{\overset{\underset{\mathrm{def}}{}}{=}} \ 
  \mathbb{E}{\left[\operatorname{I}_X (x)\right]},
\end{alignat} &lt;/math&gt;

by definition equal to the [[Expected value|expected]] information content of measurement of &lt;math&gt;X &lt;/math&gt;.&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=Lyte2yl1SPAC&amp;pg=PA11|title=Fundamentals in Information Theory and Coding|author=Borda, Monica|publisher=Springer|year=2011|isbn=978-3-642-20346-6}}&lt;/ref&gt;{{rp|11}}&lt;ref&gt;{{cite book|url=https://books.google.com/books?id=VpRESN24Zj0C&amp;pg=PA19|title=Mathematics of Information and Coding|publisher=American Mathematical Society|year=2002|isbn=978-0-8218-4256-0|authors=Han, Te Sun &amp; Kobayashi, Kingo}}&lt;/ref&gt;{{rp|19-20}}

== Properties ==
{{Expand section|date=October 2018}}

=== Antitonicity for probability ===
For a given [[probability space]], measurement of rarer [[event (probability theory)|event]]s will yield more information content than more common values.  Thus, self-information is [[Antitonicity|antitonic]] in probability for [[event (probability theory)|event]]s under observation.

* Intuitively, more information is gained from observing an unexpected event—it is "surprising". 
** For example, if there is a [[wikt:one in a million|one-in-a-million]] chance of Alice winning the [[lottery]], her friend Bob will gain significantly more information from learning that she [[Winning the lottery|won]] than that she lost on a given day. (See also: [[Lottery mathematics]].)
* This establishes an implicit relationship between the self-information of a [[random variable]] and its [[variance]].

=== Additivity of independent events ===
The information content of two [[independent events]] is the sum of each event's information content. This property is known as [[Additive map|additivity]] in mathematics, and [[sigma additivity]] in particular in [[Measure (mathematics)|measure]] and probability theory. Consider two [[independent random variables]] &lt;math display="inline"&gt;X,\, Y&lt;/math&gt; with [[Probability mass function|probability mass functions]] &lt;math&gt;p_X(x)&lt;/math&gt; and &lt;math&gt;p_Y(y)&lt;/math&gt; respectively. The [[joint probability mass function]] is

&lt;math display="block"&gt; p_{X, Y}\!\left(x, y\right) = \Pr(X = x,\, Y = y) 
 = p_X\!(x)\,p_Y\!(y) 
&lt;/math&gt;

because &lt;math display="inline"&gt;X&lt;/math&gt; and &lt;math display="inline"&gt;Y&lt;/math&gt; are [[Independence (probability theory)|independent]]. The information content of the [[Outcome (probability)|outcome]] &lt;math&gt; (X, Y) = (x, y)
&lt;/math&gt; is&lt;math display="block"&gt; \begin{align}
\operatorname{I}_{X,Y}(x, y) &amp;= -\log_2\left[p_{X,Y}(x, y)\right]
 = -\log_2 \left[p_X\!(x)p_Y\!(y)\right] \\
 &amp;= -\log_2 \left[p_X{(x)}\right] -\log_2 \left[p_Y{(y)}\right] \\
 &amp;= \operatorname{I}_X(x) + \operatorname{I}_Y(y)
\end{align}
&lt;/math&gt;See {{Section link||Two independent, identically distributed dice|nopage=y}} below for an example.

== Notes ==
This measure has also been called '''surprisal''', as it represents the "[[surprise (emotion)|surprise]]" of seeing the outcome (a highly improbable outcome is very surprising). This term (as a log-probability measure) was coined by [[Myron Tribus]] in his 1961 book ''Thermostatics and Thermodynamics''.&lt;ref name="Bernstein1972"&gt;R. B. Bernstein and R. D. Levine (1972) "Entropy and Chemical Change. I. Characterization of Product (and Reactant) Energy Distributions in Reactive Molecular Collisions: Information and Entropy Deficiency", ''The Journal of Chemical Physics'' '''57''', 434-449 [https://aip.scitation.org/doi/abs/10.1063/1.1677983 link].&lt;/ref&gt;&lt;ref name="Tribus1961"&gt;[http://www.eoht.info/page/Myron+Tribus Myron Tribus] (1961) '''Thermodynamics and Thermostatics:''' ''An Introduction to Energy, Information and States of Matter, with Engineering Applications'' (D. Van Nostrand, 24 West 40 Street, New York 18, New York, U.S.A) Tribus, Myron (1961), pp. 64-66 [https://archive.org/details/thermostaticsthe00trib borrow].&lt;/ref&gt;

When the event is a random realization (of a variable) the self-information of the variable is defined as the [[expected value]] of the self-information of the realization.

'''Self-information''' is an example of a [[Scoring rule|proper scoring rule]].{{Clarify|reason=In what context?|date=October 2018}}

==Examples==

=== Fair coin toss ===
Consider the [[Bernoulli trial]] of [[coin flipping|tossing a fair coin]] &lt;math&gt;X&lt;/math&gt;. The [[Probability|probabilities]] of the [[Event (probability theory)|events]] of the coin landing as heads &lt;math&gt;H&lt;/math&gt; and tails &lt;math&gt;T&lt;/math&gt; (see [[fair coin]] and [[obverse and reverse]]) are [[one half]] each, &lt;math display="inline"&gt;p_X{(H)} = p_X{(T)} = \tfrac{1}{2} = 0.5&lt;/math&gt;.  Upon [[Sampling (signal processing)|measuring]] the variable as heads, the associated information gain is&lt;math display="block"&gt;\operatorname{I}_X(H)
 = -\log_2 {p_X{(H)}}
 = -\log_2\!{\tfrac{1}{2}} = 1,&lt;/math&gt;so the information gain of a fair coin landing as heads is 1 [[Shannon (unit)|shannon]].&lt;ref name=":0" /&gt; Likewise, the information gain of measuring &lt;math&gt;T&lt;/math&gt; tails is&lt;math display="block"&gt;\operatorname{I}_X(T)
 = -\log_2 {p_X{(T)}}
 = -\log_2\!{\tfrac{1}{2}} = 1 \text{ shannon}.&lt;/math&gt;

=== Fair dice roll ===
Suppose we have a [[Fair dice|fair six-sided dice]].  The value of a dice roll is a [[Discrete uniform distribution|discrete uniform random variable]] &lt;math&gt;X \sim \mathrm{DU}[1, 6]&lt;/math&gt; with [[probability mass function]] &lt;math display="block"&gt;p_X(k) = \begin{cases} \frac{1}{6}, &amp; k \in \{1, 2, 3, 4, 5, 6\} \\ 0, 
&amp; \text{otherwise} \end{cases}&lt;/math&gt;The probability of rolling a 4 is &lt;math display="inline"&gt;p_X(4) = \frac{1}{6}&lt;/math&gt;, as for any other valid roll. The information content of rolling a 4 is thus&lt;math display="block"&gt;\operatorname{I}_{X}(4) = -\log_2{p_X{(4)}} 
= -\log_2{\tfrac{1}{6}} 
\approx 2.585\; \text{shannons}&lt;/math&gt;of information.

=== Two independent, identically distributed dice ===
Suppose we have two [[Independent and identically distributed random variables|independent, identically distributed random variables]] &lt;math display="inline"&gt;X,\, Y \sim \mathrm{DU}[1, 6]&lt;/math&gt; each corresponding to an [[Independent random variables|independent]] fair 6-sided dice roll.  The [[Joint probability distribution|joint distribution]] of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; is&lt;math display="block"&gt; \begin{align}
 p_{X, Y}\!\left(x, y\right) &amp; {} = \Pr(X = x,\, Y = y) 
 = p_X\!(x)\,p_Y\!(y) \\
 &amp; {} = \begin{cases}
  \displaystyle{1 \over 36}, \ &amp;x, y \in [1, 6] \cap \mathbb{N} \\
  0 &amp; \text{otherwise.} \end{cases}
\end{align}
&lt;/math&gt;

The information content of the [[random variate]] &lt;math&gt; (X, Y) = (2,\, 4)
&lt;/math&gt; is &lt;math display="block"&gt; \begin{align}\operatorname{I}_{X, Y}{(2, 4)} 
 &amp;= -\log_2\!{\left[p_{X,Y}{(2, 4)}\right]}
 = \log_2\!{36} = 2 \log_2\!{6} \\
 &amp; \approx 5.169925 \text{ shannons},
\end{align}
&lt;/math&gt;just as 

&lt;math display="block"&gt; \begin{align}\operatorname{I}_{X, Y}{(2, 4)} 
 &amp;= -\log_2\!{\left[p_{X,Y}{(2, 4)}\right]}
 = -\log_2\!{\left[p_X(2)\right]} -\log_2\!{\left[p_Y(4)\right]} \\
 &amp; = 2\log_2\!{6} \\
 &amp; \approx 5.169925 \text{ shannons},
\end{align}
&lt;/math&gt;as explained in {{Section link||Additivity of independent events||nopage=y}}.

==== Information from frequency of rolls ====
If we receive information about the value of the dice [[Twelvefold way#case fx|without knowledge]] of which die had which value, we can formalize the approach with so-called counting variables

&lt;math display="block"&gt; C_k := \delta_k(X) + \delta_k(Y) = \begin{cases} 
 0, &amp; \neg\, (X = k \vee Y = k) \\
 1, &amp; \quad X = k\, \veebar \, Y = k \\
 2, &amp; \quad X = k\, \wedge \, Y = k
\end{cases}
&lt;/math&gt;

for &lt;math&gt; k \in \{1, 2, 3, 4, 5, 6\}
&lt;/math&gt;, then &lt;math display="inline"&gt; \sum_{k=1}^{6}{C_k} = 2
&lt;/math&gt; and the counts have the [[multinomial distribution]] 

&lt;math display="block"&gt; \begin{align}
 f(c_1,\ldots,c_6) &amp; {} = \Pr(C_1 = c_1 \text{ and } \dots \text{ and } C_6 = c_6) \\
 &amp; {} = \begin{cases} { \displaystyle {1\over{18}}{1 \over c_1!\cdots c_k!}}, 
    \ &amp; \text{when } \sum_{i=1}^6 c_i=2 \\
  0 &amp; \text{otherwise,} \end{cases} \\
 &amp; {} = \begin{cases} {1 \over 18}, 
  \ &amp; \text{when 2 } c_k \text{ are } 1 \\
  {1 \over 36}, \ &amp; \text{when exactly one } c_k = 2 \\
  0, \ &amp; \text{otherwise.}
 \end{cases}
\end{align}
&lt;/math&gt;

To verify this, the 6 outcomes &lt;math display="inline"&gt;(X, Y) \in \left\{(k, k)\right\}_{k = 1}^{6} = \left\{
 (1, 1), (2, 2), (3, 3), (4, 4), (5, 5), (6, 6)
\right\}&lt;/math&gt; correspond to the event &lt;math&gt;C_k = 2&lt;/math&gt; and a [[total probability]] of {{Sfrac|6}}.  These are the only events that are faithfully preserved with identity of which dice rolled which outcome because the outcomes are the same.  Without knowledge to distinguish the dice rolling the other numbers, the other &lt;math display="inline"&gt; \binom{6}{2} = 15
&lt;/math&gt; [[Combination|combinations]] correspond to one die rolling one number and the other die rolling a different number, each having probability {{Sfrac|18}}. Indeed, &lt;math display="inline"&gt; 6 \cdot \tfrac{1}{36} + 15 \cdot \tfrac{1}{18} = 1
&lt;/math&gt;, as required.

Unsurprisingly, the information content of learning that both dice were rolled as the same particular number is more than the information content of learning that one dice was one number and the other was a different number.  Take for examples the events &lt;math&gt; A_k = \{(X, Y) = (k, k)\}
&lt;/math&gt; and &lt;math&gt; B_{j, k} = \{c_j = 1\} \cap \{c_k = 1\}
&lt;/math&gt;for &lt;math&gt; j \ne k, 1 \leq j, k \leq 6
&lt;/math&gt;. For example, &lt;math&gt; A_2 = \{X = 2 \text{ and } Y = 2\}
&lt;/math&gt;and &lt;math&gt; B_{3, 4} = \{(3, 4), (4, 3)\}
&lt;/math&gt;. 

The information contents are 

&lt;math display="block"&gt; \operatorname{I}(A_2) = -\log_2\!{\tfrac{1}{36}}
= 5.169925 \text{ shannons}
&lt;/math&gt;&lt;math display="block"&gt; \operatorname{I}\left(B_{3, 4}\right) = - \log_2 \! \tfrac{1}{18}
= 4.169925 \text{ shannons}
&lt;/math&gt;Let &lt;math display="inline"&gt; Same = \bigcup_{i = 1}^{6}{A_i}
&lt;/math&gt; be the event that both dice rolled the same value and &lt;math&gt; Diff = \overline{Same}
&lt;/math&gt; be the event that the dice differed. Then &lt;math display="inline"&gt; \Pr(Same) = \tfrac{1}{6}
&lt;/math&gt; and &lt;math display="inline"&gt; \Pr(Diff) = \tfrac{5}{6}
&lt;/math&gt;. The information contents of the events are

&lt;math display="block"&gt; \operatorname{I}(Same) = -\log_2\!{\tfrac{1}{6}} = 2.5849625 \text{ shannons}
&lt;/math&gt;&lt;math display="block"&gt; \operatorname{I}(Diff) = -\log_2\!{\tfrac{5}{6}} 
= 0.2630344 \text{ shannons}.
&lt;/math&gt;

==== Information from sum of die ====

The probability mass or density function (collectively [[probability measure]]) of the [[Sum of independent random variables|sum of two independent random variables]] [[Convolution#Convolution of measures|is the convolution of each probability measure]].  In the case of independent fair 6-sided dice rolls, the random variable &lt;math&gt; Z = X + Y
&lt;/math&gt; has probability mass function &lt;math display="inline"&gt; p_Z(z) = p_X(x) * p_Y(y) = {6 - |z - 7| \over 36} 
&lt;/math&gt;, where &lt;math&gt; *
&lt;/math&gt; represents the [[discrete convolution]].  The [[Outcome (probability)|outcome]] &lt;math&gt; Z = 5 
&lt;/math&gt; has probability &lt;math display="inline"&gt; p_Z(5) = \frac{4}{36} = {1 \over 9} 
&lt;/math&gt;. Therefore, the information asserted is&lt;math display="block"&gt; \operatorname{I}_Z(5) = -\log_2{\tfrac{1}{9}} = \log_2{9}
 \approx 3.169925 \text{ shannons.} 
&lt;/math&gt;

=== General discrete uniform distribution ===
Generalizing the {{Section link||Fair dice roll|nopage=y}} example above, consider a general [[discrete uniform random variable]] (DURV) &lt;math&gt;X \sim \mathrm{DU}[a,b]; \quad a, b \in \mathbb{Z}, 
\ b \ge a.&lt;/math&gt; For convenience, define &lt;math display="inline"&gt;N := b - a + 1&lt;/math&gt;. The [[Probability mass function|p.m.f.]] is &lt;math display="block"&gt;p_X(k) = \begin{cases} \frac{1}{N}, &amp; k \in [a, b] \cap \mathbb{Z} 
 \\ 0,  &amp; \text{otherwise} \end{cases}.&lt;/math&gt;In general, the values of the DURV need not be [[Integer|integers]], or for the purposes of information theory even uniformly spaced; they need only be [[equiprobable]].&lt;ref name=":0" /&gt; The information gain of any observation &lt;math&gt;X = k&lt;/math&gt;is&lt;math display="block"&gt;\operatorname{I}_X(k) = -\log_2{\frac{1}{N}} 
 = \log_2{N} \text{ shannons}.&lt;/math&gt;

==== Special case: constant random variable ====
If &lt;math&gt;b = a&lt;/math&gt; above, &lt;math&gt;X&lt;/math&gt; [[Degeneracy (mathematics)|degenerates]] to a [[constant random variable]] with probability distribution deterministically given by &lt;math&gt;X = b&lt;/math&gt; and probability measure the [[Dirac measure]] &lt;math display="inline"&gt;p_X(k) = \delta_{b}(k)&lt;/math&gt;.  The only value &lt;math&gt;X&lt;/math&gt; can take is [[Deterministic system|deterministically]] &lt;math&gt;b&lt;/math&gt;, so the information content of any measurement of &lt;math&gt;X&lt;/math&gt; is&lt;math display="block"&gt;\operatorname{I}_X(b) = - \log_2{1} = 0.&lt;/math&gt;In general, there is no information gained from measuring a known value.&lt;ref name=":0" /&gt;

=== Categorical distribution ===
Generalizing all of the above cases, consider a [[Categorical variable|categorical]] [[discrete random variable]] with [[Support (mathematics)|support]] &lt;math display="inline"&gt;\mathcal{S} = \bigl\{s_i\bigr\}_{i=1}^{N}&lt;/math&gt; and {{Abbr|p.m.f.|probability mass function}} given by 

&lt;math display="block"&gt;p_X(k) = \begin{cases}
 p_i, &amp; k = s_i \in \mathcal{S}
 \\ 0,  &amp; \text{otherwise} 
\end{cases}.&lt;/math&gt;

For the purposes of information theory, the values &lt;math&gt;s \in \mathcal{S}&lt;/math&gt; do not even have to be [[Number|numbers]] at all; they can just be [[Mutually exclusive#Probability|mutually exclusive]] [[Event (probability theory)|events]] on a [[measure space]] of [[finite measure]] that has been [[Normalization (statistics)|normalized]] to a [[probability measure]] &lt;math&gt;p&lt;/math&gt;.  [[Without loss of generality]], we can assume the categorical distribution is supported on the set &lt;math display="inline"&gt;[N] = \left\{1, 2, ..., N \right\}&lt;/math&gt;; the mathematical structure is [[Isomorphism|isomorphic]] in terms of [[probability theory]] and therefore [[information theory]] as well.  

The information of the outcome &lt;math&gt;X = x&lt;/math&gt; is given

&lt;math display="block"&gt;\operatorname{I}_X(x) = -\log_2{p_X(x)}.&lt;/math&gt;

From these examples, it is possible to calculate the information of any set of [[Independent random variables|independent]] [[Discrete Random Variable|DRVs]] with known [[Probability distribution|distributions]] by [[Sigma additivity|additivity]].

==Relationship to entropy==
The [[Entropy (information theory)|entropy]] is the [[expected value]] of the information content of the [[discrete random variable]], with expectation taken over the discrete [[Support (mathematics)|values it takes]].  Sometimes, the entropy itself is called the "self-information" of the random variable, possibly because the entropy satisfies &lt;math&gt;\Eta(X) = \operatorname{I}(X; X)&lt;/math&gt;, where &lt;math&gt;\operatorname{I}(X;X)&lt;/math&gt; is the [[mutual information]] of &lt;math&gt;X&lt;/math&gt; with itself.&lt;ref&gt;Thomas M. Cover, Joy A. Thomas; Elements of Information Theory; p. 20; 1991.&lt;/ref&gt;

==Derivation==
By definition, information is transferred from an originating entity possessing the information to a receiving entity only when the receiver had not known the information [[A priori knowledge|a priori]].  If the receiving entity had previously known the content of a message with certainty before receiving the message, the amount of information of the message received is zero.

For example, quoting a character (the Hippy Dippy Weatherman) of comedian [[George Carlin]], [http://www.goodreads.com/quotes/94336-weather-forecast-for-tonight-dark-continued-dark-overnight-with-widely ''“Weather forecast for tonight: dark. Continued dark overnight, with widely scattered light by morning.”''] Assuming one does not reside near the [[Polar regions of Earth|Earth's poles]] or [[polar circle]]s, the amount of information conveyed in that forecast is zero because it is known, in advance of receiving the forecast, that darkness always comes with the night.

When the content of a message is known [[A priori knowledge|a priori]] with certainty, with [[probability]] of 1, there is no actual information conveyed in the message.  Only when the advance knowledge of the content of the message by the receiver is less than 100% certain does the message actually convey information. 

Accordingly, the amount of self-information contained in a message conveying content informing an occurrence of [[event (probability theory)|event]], &lt;math&gt;\omega_n&lt;/math&gt;, depends only on the probability of that event. 

:&lt;math&gt;\operatorname I(\omega_n) = f(\operatorname P(\omega_n)) &lt;/math&gt;

for some function &lt;math&gt;f(\cdot)&lt;/math&gt; to be determined below.  If &lt;math&gt;\operatorname P(\omega_n) = 1&lt;/math&gt;, then &lt;math&gt;\operatorname I(\omega_n) = 0&lt;/math&gt;.  If &lt;math&gt;\operatorname P(\omega_n) &lt; 1&lt;/math&gt;, then &lt;math&gt;\operatorname I(\omega_n) &gt; 0&lt;/math&gt;.

Further, by definition, the [[Measure_(mathematics)|measure]] of self-information is nonnegative and additive. If a message informing of event &lt;math&gt;C&lt;/math&gt; is the '''intersection''' of two [[statistical independence|independent]] events &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;, then the information of event &lt;math&gt;C&lt;/math&gt; occurring is that of the compound message of both independent events &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; occurring.  The quantity of information of compound message &lt;math&gt;C&lt;/math&gt; would be expected to equal the '''sum''' of the amounts of information of the individual component messages &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; respectively:

:&lt;math&gt;\operatorname I(C) = \operatorname I(A \cap B) = \operatorname I(A) + \operatorname I(B)&lt;/math&gt;.

Because of the independence of events &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt;, the probability of event &lt;math&gt;C&lt;/math&gt; is

:&lt;math&gt;\operatorname P(C) = \operatorname P(A \cap B) = \operatorname P(A) \cdot \operatorname P(B)&lt;/math&gt;.

However, applying function &lt;math&gt;f(\cdot)&lt;/math&gt; results in

:&lt;math&gt;\begin{align}
   \operatorname I(C) &amp; = \operatorname I(A) + \operatorname I(B) \\
f(\operatorname P(C)) &amp; = f(\operatorname P(A)) + f(\operatorname P(B)) \\
                      &amp; = f\big(\operatorname P(A) \cdot \operatorname P(B)\big) \\
\end{align}&lt;/math&gt;

The class of function &lt;math&gt;f(\cdot)&lt;/math&gt; having the property such that

:&lt;math&gt;f(x \cdot y) = f(x) + f(y)&lt;/math&gt;

is the [[logarithm]] function of any base.  The only operational difference between logarithms of different bases is that of different scaling constants.

:&lt;math&gt;f(x) = K \log(x)&lt;/math&gt;

Since the probabilities of events are always between 0 and 1 and the information associated with these events must be nonnegative, that requires that &lt;math&gt;K&lt;0&lt;/math&gt;.

Taking into account these properties, the self-information &lt;math&gt;\operatorname I(\omega_n)&lt;/math&gt; associated with outcome &lt;math&gt;\omega_n&lt;/math&gt; with probability &lt;math&gt;\operatorname P(\omega_n)&lt;/math&gt; is defined as:

:&lt;math&gt;\operatorname I(\omega_n) = -\log(\operatorname P(\omega_n)) = \log \left(\frac{1}{\operatorname P(\omega_n)} \right) &lt;/math&gt;

The smaller the probability of event &lt;math&gt;\omega_n&lt;/math&gt;, the larger the quantity of self-information associated with the message that the event indeed occurred.  If the above logarithm is base 2, the unit of &lt;math&gt;\displaystyle I(\omega_n)&lt;/math&gt; is [[bit]]s.  This is the most common practice.  When using the [[natural logarithm]] of base &lt;math&gt;\displaystyle e&lt;/math&gt;, the unit will be the [[Nat (unit)|nat]]. For the base 10 logarithm, the unit of information is the [[Hartley (unit)|hartley]].

As a quick illustration, the information content associated with an outcome of 4 heads (or any specific outcome) in 4 consecutive tosses of a coin would be 4 bits (probability 1/16), and the information content associated with getting a result other than the one specified would be ~0.09 bits (probability 15/16). See below for detailed examples.
== See also ==

* [[Entropy]]
* [[Surprisal analysis]]

== References ==
&lt;references/&gt;

== Further reading ==

*[[Claude Shannon|C.E. Shannon]], A Mathematical Theory of Communication, ''Bell Systems Technical Journal'', Vol. 27, pp 379–423, (Part I), 1948.

== External links ==
* [http://www.umsl.edu/~fraundor/egsurpri.html Examples of surprisal measures]
* [http://www.lecb.ncifcrf.gov/~toms/glossary.html#surprisal "Surprisal" entry in a glossary of molecular information theory]
* [http://ilab.usc.edu/surprise/ Bayesian Theory of Surprise]

[[Category:Information theory]]
[[Category:Entropy and information]]</text>
      <sha1>6k6nqhe2x0bhk7nzvqzyoygav8peljk</sha1>
    </revision>
  </page>
  <page>
    <title>Information dimension</title>
    <ns>0</ns>
    <id>4705339</id>
    <revision>
      <id>857191022</id>
      <parentid>855564007</parentid>
      <timestamp>2018-08-30T04:04:49Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */clean up, replaced: Acta Mathematica Academiae Scientiarum Hungarica → Acta Mathematica Academiae Scientiarum Hungaricae</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13394">{{Underlinked|date=January 2016}}

In [[information theory]], '''information dimension''' is an information measure for random vectors in [[Euclidean space]], based on the normalized [[Entropy (information theory)|entropy]] of finely quantized versions of the random vectors. This concept was first introduced by [[Alfréd Rényi]] in 1959.&lt;ref&gt;See {{harvnb|Rényi|1959}}.&lt;/ref&gt;

Simply speaking, it is a measure of the [[fractal dimension]] of a [[probability distribution]]. It characterizes the growth rate of the [[Shannon entropy]] given by successively finer discretizations of the space.

In 2010, Wu and Verdú gave an operational characterization of Rényi information dimension as the fundamental limit of almost lossless data compression for analog sources under various regularity constraints of the encoder/decoder.

== Definition and Properties ==

The entropy of a discrete random variable &lt;math&gt;Z&lt;/math&gt; is

:&lt;math&gt;\mathbb{H}_0(Z)=\sum_{z \in supp(P_Z)}P_Z(z)\log_2\frac{1}{P_Z(z)}&lt;/math&gt;

where &lt;math&gt;P_Z(z)&lt;/math&gt; is the [[probability measure]] of &lt;math&gt;Z&lt;/math&gt; when &lt;math&gt;Z=z&lt;/math&gt;, and the &lt;math&gt;supp(P_Z)&lt;/math&gt; denotes a set &lt;math&gt;\{z|z \in\mathcal{Z},P_Z(z)&gt;0\}&lt;/math&gt;.

Let &lt;math&gt;X&lt;/math&gt; be an arbitrary real-valued random variable. Given a positive integer &lt;math&gt;m&lt;/math&gt;, we create a new discrete random variable

:&lt;math&gt;\langle X\rangle_m=\frac{\lfloor mX\rfloor}{m}&lt;/math&gt;

where the &lt;math&gt;\lfloor \cdot \rfloor&lt;/math&gt; is the floor operator which converts a real number to the greatest integer less than it. Then

:&lt;math&gt;\underline{d}(X)=\liminf_{m \rightarrow \infty}\frac{\mathbb{H}_0(\langle X \rangle_m)}{\log_2m}&lt;/math&gt;

and

:&lt;math&gt;\bar{d}(X)=\limsup_{m \rightarrow \infty}\frac{\mathbb{H}_0(\langle X \rangle_m)}{\log_2m}
&lt;/math&gt;

are called lower and upper information dimensions of &lt;math&gt;X&lt;/math&gt; respectively. When &lt;math&gt;\underline{d}(X)=\bar{d}(X)&lt;/math&gt;, we call this value information dimension of &lt;math&gt;X&lt;/math&gt;,

:&lt;math&gt;d(X)=\lim_{m \rightarrow \infty}\frac{\mathbb{H}_0(\langle X \rangle_m)}{\log_2m}&lt;/math&gt;

Some important properties of information dimension &lt;math&gt;d(X)&lt;/math&gt;:
* If the mild condition &lt;math&gt;\mathbb{H}(\lfloor X\rfloor)&lt;\infty&lt;/math&gt; is fulfilled, we have &lt;math&gt;0\leq\underline{d}(X)\leq\bar{d}(X)\leq1&lt;/math&gt;.
* For an &lt;math&gt;n&lt;/math&gt;-dimensional random vector &lt;math&gt;\vec{X}&lt;/math&gt;, the first property can be generalized to &lt;math&gt;0\leq\underline{d}(\vec{X})\leq \bar{d}(\vec{X})\leq n&lt;/math&gt;.
* It is sufficient to calculate the upper and lower information dimensions when restricting to the exponential subsequence &lt;math&gt;m=2^l&lt;/math&gt;.
* &lt;math&gt;\underline{d}(X)&lt;/math&gt; and &lt;math&gt;\bar{d}(X)&lt;/math&gt; are kept unchanged if rounding or ceiling functions are used in quantization.

== &lt;math&gt;d&lt;/math&gt;-Dimensional Entropy ==

If the information dimension &lt;math&gt;d&lt;/math&gt; exists, one can define the &lt;math&gt;d&lt;/math&gt;-dimensional entropy of this distribution by

:&lt;math&gt;\mathbb{H}_{d(X)}(X)=\lim_{n \rightarrow + \infty}(\mathbb{H}_0(\langle X \rangle_n)-d(X)\log_2n)&lt;/math&gt;

provided the limit exists. If &lt;math&gt;d=0&lt;/math&gt;, the zero-dimensional entropy equals the standard [[Shannon entropy]] &lt;math&gt;\mathbb{H}_0(X)&lt;/math&gt;. For integer dimension &lt;math&gt;d=n\ge 1&lt;/math&gt;, the &lt;math&gt;n&lt;/math&gt;-dimensional entropy is the &lt;math&gt;n&lt;/math&gt;-fold integral defining the respective [[differential entropy]].

== Discrete-Continuous Mixture Distributions ==

According to [[Lebesgue's decomposition theorem|Lebesgue decomposition theorem]],&lt;ref&gt;See {{harvnb|Çınlar|2011}}.&lt;/ref&gt; a probability distribution can be uniquely represented by the mixture &lt;blockquote&gt;&lt;math&gt;v=pP_{Xd}+qP_{Xc}+rP_{Xs}&lt;/math&gt;&lt;/blockquote&gt;where &lt;math&gt;p+q+r=1&lt;/math&gt; and &lt;math&gt;p,q,r\geq0&lt;/math&gt;; &lt;math&gt;P_{Xd}&lt;/math&gt; is a purely atomic probability measure (discrete part), &lt;math&gt;P_{Xc}&lt;/math&gt;  is the absolutely continuous probability measure, and &lt;math&gt;P_{Xs}&lt;/math&gt;  is a probability measure singular with respect to Lebesgue measure but with no atoms (singular part).

Let &lt;math&gt;X&lt;/math&gt;  be a random variable such that &lt;math&gt;\mathbb{H}(\lfloor X \rfloor) &lt; \infty&lt;/math&gt;. Assume the distribution of &lt;math&gt;X&lt;/math&gt; can be represented as&lt;blockquote&gt;&lt;math&gt;v=(1-\rho)P_{Xd}+\rho P_{Xc}&lt;/math&gt;&lt;/blockquote&gt;where &lt;math&gt;P_{Xd}&lt;/math&gt; is a discrete measure and &lt;math&gt;P_{Xc}&lt;/math&gt; is the absolutely continuous probability measure with &lt;math&gt;0\leq\rho\leq1&lt;/math&gt;. Then&lt;blockquote&gt;&lt;math&gt;d(X)=\rho&lt;/math&gt;&lt;/blockquote&gt;Moreover, given &lt;math&gt;\mathbb{H}_0(P_{Xd})&lt;/math&gt;  and differential entropy &lt;math&gt;h(P_{Xc})&lt;/math&gt;, the &lt;math&gt;d&lt;/math&gt;-Dimensional Entropy is simply given by&lt;blockquote&gt;&lt;math&gt;\mathbb{H}_\rho(X)=(1-\rho)\mathbb{H}_0(P_{Xd})+\rho h(P_{Xc})+\mathbb{H}_0(\rho)&lt;/math&gt;&lt;/blockquote&gt;where &lt;math&gt;\mathbb{H}_0(\rho)&lt;/math&gt;  is the Shannon entropy of a discrete random variable &lt;math&gt;Z&lt;/math&gt; with &lt;math&gt;P_Z(1)=\rho&lt;/math&gt; and &lt;math&gt;P_Z(0)=1-\rho&lt;/math&gt; and given by&lt;blockquote&gt;&lt;math&gt;\mathbb{H}_0(\rho)=\rho\log_2\frac{1}{\rho}+(1-\rho)\log_2\frac{1}{1-\rho}&lt;/math&gt;&lt;/blockquote&gt;

=== Example ===
[[File:A standard Gaussian distribution for illustration a example.png|right|frameless|391x391px]]
Consider a signal which has a [[Gaussian probability distribution]].

We pass the signal through a half-wave [[Rectifier#Half-wave rectification|rectifier]] which converts all negative value to 0, and maintains all other values. The half-wave rectifier can be characterized by the function&lt;blockquote&gt;&lt;math&gt;f(x)= 
\begin{cases}
    x,&amp; \text{if } x\geq 0\\
    0,&amp;x&lt;0
\end{cases}&lt;/math&gt;&lt;/blockquote&gt;
[[File:Rectified gaussian distribution.png|right|frameless|381x381px]]
Then, at the output of the rectifier, the signal has a [[rectified Gaussian distribution]]. It is characterized by an atomic mass of weight 0.5 and has a Gaussian PDF for all &lt;math&gt;x&gt;0&lt;/math&gt;.

With this mixture distribution, we apply the formula above and get the information dimension &lt;math&gt;d&lt;/math&gt; of the distribution and calculate the &lt;math&gt;d&lt;/math&gt;-dimensional entropy.&lt;blockquote&gt;&lt;math&gt;d(X)=\rho=0.5&lt;/math&gt;&lt;/blockquote&gt;The normalized right part of the zero-mean Gaussian distribution has entropy &lt;math&gt;h(P_{Xc})=\frac{1}{2}\log_2(2\pi e\sigma^2)-1&lt;/math&gt;, hence 
&lt;blockquote&gt;&lt;math&gt;\begin{align}
\mathbb{H}_{0.5}(X)&amp;=(1-0.5)(1\log_21)+0.5h(P_{Xc})+\mathbb{H}_0(0.5)\\
&amp;=0+\frac{1}{2}(\frac{1}{2}\log_2(2\pi e\sigma^2)-1)+1\\
&amp;=\frac{1}{4}\log_2(2\pi e\sigma^2)+\frac{1}{2}\,\text{ bit(s)}
\end{align}&lt;/math&gt;&lt;/blockquote&gt;

== Connection to Differential Entropy ==

It is shown &lt;ref&gt;See {{harvnb|Cover|Thomas|2012}}.&lt;/ref&gt; that information dimension and differential entropy are tightly connected.

Let &lt;math&gt;X&lt;/math&gt; be a positive random variable with density &lt;math&gt;f(x)&lt;/math&gt;. [[File:A simple continuous function which are used to be quantized.png|right|frameless]] Suppose we divide the range of &lt;math&gt;X&lt;/math&gt; into bins of length &lt;math&gt;\Delta
&lt;/math&gt;. By the mean value theorem, there exists a value &lt;math&gt;x_i&lt;/math&gt; within each bin such that

:&lt;math&gt;f(x_i)\Delta=\int_{i\Delta}^{(i+1)\Delta}f(x)\;\mathrm{d}x&lt;/math&gt;

Consider the discretized random variable &lt;math&gt;X^\Delta=x_i&lt;/math&gt; if  &lt;math&gt;i\Delta\leq X&lt; (i+1)\Delta&lt;/math&gt;.
[[File:F(x) which has already been quantized to several dirac function.png|right|frameless]]
The probability of each support point &lt;math&gt;X^\Delta=x_i&lt;/math&gt; is

:&lt;math&gt;P_{X^\Delta}(x_i)=\int_{i\Delta}^{(i+1)\Delta}f(x)\;\mathrm{d}x=f(x_i)\Delta&lt;/math&gt;

The entropy of this variable is

:&lt;math&gt;
\begin{align}
\mathbb{H}_0(X^\Delta)&amp;=-\sum_{x_i \in supp(P_{X^\Delta})}P_{X^\Delta}\log_2P_{X^\Delta}\\
&amp;=-\sum_{x_i \in supp(P_{X^\Delta})}f(x_i)\Delta\log_2(f(x_i)\Delta)\\
&amp;=\sum_{x_i \in supp(P_{X^\Delta})} \Delta f(x_i)\log_2f(x_i)-\sum_{x_i \in supp(P_{X^\Delta})} f(x_i)\Delta \log_2\Delta\\
&amp;=\sum_{x_i \in supp(P_{X^\Delta})} \Delta f(x_i)\log_2f(x_i)-\log_2\Delta\\
\end{align}
&lt;/math&gt;

If we set &lt;math&gt;\Delta=1/m&lt;/math&gt; and &lt;math&gt;x_i=i/m&lt;/math&gt; then we are doing exactly the same quantization as the definition of information dimension. Since relabeling the events of a discrete random variable does not change its entropy, we have

:&lt;math&gt;\mathbb{H}_0(X^{1/m})=\mathbb{H}_0(\langle X\rangle_m).&lt;/math&gt;

This yields

:&lt;math&gt;\mathbb{H}_0(\langle X\rangle_m)=-\sum \frac{1}{m} f(x_i)\log_2f(x_i)+\log_2m&lt;/math&gt;

and when &lt;math&gt;m&lt;/math&gt; is sufficient large,

:&lt;math&gt;-\sum \Delta f(x_i)\log_2f(x_i) \approx \int f(x)\log_2 \frac{1}{f(x)}\mathrm{d}x&lt;/math&gt;

which is the differential entropy &lt;math&gt;h(x)&lt;/math&gt; of the continuous random variable. In particular, if &lt;math&gt;f(x)&lt;/math&gt; is Riemann integrable, then

:&lt;math&gt;h(X)=\lim_{m\rightarrow \infty}\mathbb{H}_0(\langle X\rangle_m)-\log_2(m).&lt;/math&gt;

Comparing this with the &lt;math&gt;d&lt;/math&gt;-dimensional entropy shows that the differential entropy is exactly the one-dimensional entropy

:&lt;math&gt;h(X)=\mathbb{H}_1(X).&lt;/math&gt;

In fact, this can be generalized to higher dimensions. Rényi shows that, if &lt;math&gt;\vec{X}&lt;/math&gt; is a random vector in a &lt;math&gt;n&lt;/math&gt;-dimensional Euclidean space &lt;math&gt;\real^n&lt;/math&gt; with an absolutely continuous distribution with a probability density function &lt;math&gt;f_{\vec{X}}(\vec{x})&lt;/math&gt; and finite entropy of the integer part (&lt;math&gt;H_0(\langle \vec{X} \rangle_m)&lt;\infty&lt;/math&gt;), we have
&lt;math&gt;d(\vec{X})=n&lt;/math&gt;

and

:&lt;math&gt;\mathbb{H}_n(\vec{X})=\int\cdots\int f_{\vec{X}}(\vec{x})\log_2\frac{1}{f_{\vec{X}}(\vec{x})}\mathrm{d}\vec{x},&lt;/math&gt;

if the integral exist.

== Lossless data compression ==

The information dimension of a distribution gives a theoretical upper bound on the compression rate, if one wants to compress a variable coming from this distribution. In the context of lossless data compression, we try to compress real number with less real number which both have infinite precision.

The main objective of the lossless data compression is to find efficient representations for source realizations &lt;math&gt;x^n\in \mathcal{X}^n&lt;/math&gt; by &lt;math&gt;y^n\in\mathcal{Y}^n&lt;/math&gt;. A &lt;math&gt;(n,k)-&lt;/math&gt;code for &lt;math&gt;\{X_i:i\in\mathcal{N}\}&lt;/math&gt; is a pair of mappings:
* encoder: &lt;math&gt;f_n:\mathcal{X}^n\rightarrow \mathcal{Y}^k&lt;/math&gt; which converts information from a source into symbols for communication or storage;
* decoder: &lt;math&gt;g_n:\mathcal{Y}^k\rightarrow\mathcal{X}^n&lt;/math&gt; is the reverse process, converting code symbols back into a form that the recipient understands.
The block error probability is &lt;math&gt;\mathcal{P}\{g_n(f_n(X^n))\neq X^n\}&lt;/math&gt;.

Define &lt;math&gt;r(\epsilon)&lt;/math&gt; to be the infimum of &lt;math&gt;r\geq0&lt;/math&gt; such that there exists a sequence of &lt;math&gt;(n,\lfloor rn\rfloor)-&lt;/math&gt;codes such that &lt;math&gt;\mathcal{P}\{g_n(f_n(X^n))\neq X^n\}\leq\epsilon&lt;/math&gt; for all sufficiently large &lt;math&gt;n&lt;/math&gt;.

So &lt;math&gt;r(\epsilon)&lt;/math&gt; basically gives the ratio between the code length and the source length, it shows how good a specific encoder decoder pair is. The fundamental limits in lossless source coding are as follows.&lt;ref&gt;See {{harvnb|Wu|Verdu|2010}}.&lt;/ref&gt;

Consider a continuous encoder function &lt;math&gt;f(x):\real^n\rightarrow \real^{\lfloor Rn\rfloor}&lt;/math&gt; with its continuous decoder function &lt;math&gt;g(x):\real^{\lfloor Rn\rfloor}\rightarrow \real^n&lt;/math&gt;. If we impose no regularity on &lt;math&gt;f(x)&lt;/math&gt; and &lt;math&gt;g(x)&lt;/math&gt;, due to the rich structure of &lt;math&gt;\real&lt;/math&gt;, we have the minimum &lt;math&gt;\epsilon&lt;/math&gt;-achievable rate &lt;math&gt;R_0(\epsilon)=0&lt;/math&gt; for all &lt;math&gt;0&lt;\epsilon\leq1&lt;/math&gt;. It means that one can build an encoder-decoder pair with infinity compression rate.

In order to get some nontrivial and meaningful conclusions, let &lt;math&gt;R^*(\epsilon )&lt;/math&gt; the minimum &lt;math&gt;\epsilon-&lt;/math&gt;achievable rate for linear encoder and Borel decoder. If random variable &lt;math&gt;X&lt;/math&gt; has a distribution which is a mixture of discrete and continuous part. Then &lt;math&gt;R^*(\epsilon)=d(X)&lt;/math&gt; for all &lt;math&gt;0&lt;\epsilon\leq1&lt;/math&gt; Suppose we restrict the decoder to be a Lipschitz continuous function and &lt;math&gt;\bar{d}(X)&lt;\infty&lt;/math&gt;  holds, then the minimum &lt;math&gt;\epsilon-&lt;/math&gt;achievable rate &lt;math&gt;R(\epsilon)\geq \bar{d}(X)&lt;/math&gt; for all &lt;math&gt;0&lt;\epsilon\leq1&lt;/math&gt;.

==Notes==

{{reflist}}

==References==

*{{Cite book
 | ref = harv
 | first = Erhan
 | last = Çınlar
 | title = Probability and Stochastics
 | publisher = Springer
 | series = Graduate Texts in Mathematics
 | year = 2011
 | volume = 261
 | doi = 10.1007/978-0-387-87859-1
}}

*{{Cite book
 | ref = harv
 | first1 = Thomas M.
 | last1 = Cover
 | first2 = Joy A.
 | last2 = Thomas
 | title = Elements of Information Theory
 | url = https://books.google.com/books?id=VWq5GG6ycxMC
 | publisher = Wiley
 | edition = 2nd
 | date = 2012
 | isbn = 9781118585771
}}

*{{Cite journal
 | ref = harv
 | first = A.
 | last = Rényi
 | title = On the dimension and entropy of probability distributions
 | url = https://link.springer.com/article/10.1007/BF02063299
 | journal = Acta Mathematica Academiae Scientiarum Hungaricae
 | date = March 1959
 | issn = 0001-5954
 | pages = 193–215
 | volume = 10
 | issue = 1-2
 | doi = 10.1007/BF02063299
}}

*{{Cite journal
 | ref = harv
 | first1 = Yihong
 | last1 = Wu
 | first2 = S.
 | last2 = Verdu
 | title = Rényi Information Dimension: Fundamental Limits of Almost Lossless Analog Compression
 | journal = [[IEEE Transactions on Information Theory]]
 | date = August 2010
 | issn = 0018-9448
 | pages = 3721–3748
 | volume = 56
 | issue = 8
 | doi = 10.1109/TIT.2010.2050803
}}

[[Category:Information theory]]</text>
      <sha1>01aftc9v9advra8mdrkppj7wo0lm6zl</sha1>
    </revision>
  </page>
  <page>
    <title>Kuratowski's theorem</title>
    <ns>0</ns>
    <id>54493</id>
    <revision>
      <id>849686128</id>
      <parentid>849682603</parentid>
      <timestamp>2018-07-10T17:11:44Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid good faith revision 849682603 by [[Special:Contributions/RunningToMars|RunningToMars]] ([[User talk:RunningToMars|talk]]); [[WP:PEACOCK]], what little content this sentence has belongs in history section, but it contradicts the dates there.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8692">{{For|the point-set topology theorem|Kuratowski's closure-complement problem}}
[[File:GP92-Kuratowski.svg|thumb|240px|A subdivision of ''K''&lt;sub&gt;3,3&lt;/sub&gt; in the [[generalized Petersen graph]] ''G''(9,2), showing that the graph is nonplanar]]
In [[graph theory]], '''Kuratowski's theorem''' is a mathematical [[forbidden graph characterization]] of [[planar graph]]s, named after [[Kazimierz Kuratowski]].  It states that a finite graph is planar if and only if it does not contain a [[Glossary of graph theory#Subgraphs|subgraph]] that is a [[subdivision (graph theory)|subdivision]] of ''K''&lt;sub&gt;5&lt;/sub&gt; (the [[complete graph]] on five [[vertex (graph theory)|vertices]]) or of ''K''&lt;sub&gt;3,3&lt;/sub&gt; ([[complete bipartite graph]] on six vertices, three of which connect to each of the other three, also known as the [[utility graph]]).

==Statement of the theorem==
A [[planar graph]] is a graph whose vertices can be represented by points in the [[Euclidean plane]], and whose edges can be represented by [[simple curve]]s in the same plane connecting the points representing their endpoints, such that no two curves intersect except at a common endpoint. Planar graphs are often [[graph drawing|drawn]] with straight [[line segment]]s representing their edges, but by [[Fáry's theorem]] this makes no difference to their graph-theoretic characterization.

A [[subdivision (graph theory)|subdivision]] of a graph is a graph formed by subdividing its edges into [[path (graph theory)|paths]] of one or more edges. Kuratowski's theorem states that a finite graph ''G'' is planar, if it is not possible to subdivide the edges of ''K''&lt;sub&gt;5&lt;/sub&gt; or ''K''&lt;sub&gt;3,3&lt;/sub&gt;, and then possibly add additional edges and vertices, to form a graph [[graph isomorphism|isomorphic]] to ''G''. Equivalently, a finite graph is planar if and only if it does not contain a subgraph that is [[homeomorphism (graph theory)|homeomorphic]] to ''K''&lt;sub&gt;5&lt;/sub&gt; or ''K''&lt;sub&gt;3,3&lt;/sub&gt;.

==Kuratowski subgraphs==
If ''G'' is a graph that contains a subgraph ''H'' that is a subdivision of ''K''&lt;sub&gt;5&lt;/sub&gt; or ''K''&lt;sub&gt;3,3&lt;/sub&gt;, then ''H'' is known as a '''Kuratowski subgraph''' of ''G''.&lt;ref&gt;{{citation
 | last = Tutte | first = W. T. | authorlink = W. T. Tutte
 | journal = Proceedings of the London Mathematical Society
 | mr = 0158387
 | pages = 743–767
 | series = Third Series
 | title = How to draw a graph
 | volume = 13
 | year = 1963
 | doi=10.1112/plms/s3-13.1.743}}.&lt;/ref&gt;  With this notation, Kuratowski's theorem can be expressed  succinctly: a graph is planar if and only if it does not have a Kuratowski subgraph.

The two graphs ''K''&lt;sub&gt;5&lt;/sub&gt; and ''K''&lt;sub&gt;3,3&lt;/sub&gt; are nonplanar, as may be shown either by a [[Proof by cases|case analysis]] or an argument involving [[Euler characteristic|Euler's formula]]. Additionally, subdividing a graph cannot turn a nonplanar graph into a planar graph: if a subdivision of a graph ''G'' has a planar drawing, the paths of the subdivision form curves that may be used to represent the edges of ''G'' itself. Therefore, a graph that contains a Kuratowski subgraph cannot be planar. The more difficult direction in proving Kuratowski's theorem is to show that, if a graph is nonplanar, it must contain a Kuratowski subgraph.

==Algorithmic implications==
A Kuratowski subgraph of a nonplanar graph can be found in [[linear time]], as measured by the size of the input graph.&lt;ref&gt;{{citation
 | last = Williamson | first = S. G.
 | date = September 1984
 | doi = 10.1145/1634.322451
 | issue = 4
 | journal = [[J. ACM]]
 | pages = 681–693
 | title = Depth-first search and Kuratowski subgraphs
 | volume = 31}}.&lt;/ref&gt; This allows the correctness of a [[planarity testing]] algorithm to be verified for nonplanar inputs, as it is straightforward to test whether a given subgraph is or is not a Kuratowski subgraph.&lt;ref&gt;{{citation|title=LEDA: A Platform for Combinatorial and Geometric Computing|first1=Kurt|last1=Mehlhorn|author1-link=Kurt Mehlhorn|first2=Stefan|last2=Näher|page=510|url=https://books.google.com/books?id=Q2aXZl3fgvMC&amp;pg=PA510|publisher=Cambridge University Press|year=1999|isbn=9780521563291}}.&lt;/ref&gt;
Usually, non-planar graphs contain a large number of Kuratowski-subgraphs. The extraction of these subgraphs is needed, e.g., in [[branch and cut]] algorithms for crossing minimization. It is possible to extract a large number of Kuratowski subgraphs in time dependent on their total size.&lt;ref&gt;{{citation
 | last1 = Chimani| first1 = Markus
 | last2 = Mutzel| first2 = Petra | author2-link = Petra Mutzel
 | last3 = Schmidt| first3 = Jens M.
 | date = 2007
 | doi = 10.1007/978-3-540-77537-9_17
 | conference = International Symposium on Graph Drawing
 | pages = 159–170
 | title = Efficient Extraction of Multiple Kuratowski Subdivisions}}.&lt;/ref&gt;

==History==
[[Kazimierz Kuratowski]] published his theorem in 1930.&lt;ref&gt;{{citation|first=Kazimierz|last=Kuratowski|authorlink=Kazimierz Kuratowski|year=1930|url=http://matwbn.icm.edu.pl/ksiazki/fm/fm15/fm15126.pdf|title=Sur le problème des courbes gauches en topologie|journal=Fund. Math.|volume=15|pages=271–283|language=French}}.&lt;/ref&gt; The theorem was independently proved by [[Orrin Frink]] and [[Paul Althaus Smith|Paul Smith]], also in 1930,&lt;ref&gt;{{citation
 | last1 = Frink | first1 = Orrin | authorlink1 = Orrin Frink
 | last2 = Smith | first2 = Paul A. | authorlink2 = Paul Althaus Smith
 | title = Irreducible non-planar graphs
 | journal = Bulletin of the AMS
 | volume = 36
 | pages = 214
 | year = 1930 }}&lt;/ref&gt; but their proof was never published.  The special case of [[cubic graph|cubic]] planar graphs (for which the only minimal forbidden subgraph is ''K''&lt;sub&gt;3,3&lt;/sub&gt;) was also independently proved by [[Karl Menger]] in 1930.&lt;ref&gt;{{citation
 | last = Menger | first = Karl | authorlink = Karl Menger
 | title = Über plättbare Dreiergraphen und Potenzen nichtplättbarer Graphen
 | journal =  Anzeiger der Akademie der Wissenschaften in Wien
 | volume = 67
 | pages = 85–86
 | year = 1930}}&lt;/ref&gt;
Since then, several new proofs of the theorem have been discovered.&lt;ref&gt;{{citation
 | last = Thomassen | first = Carsten | authorlink = Carsten Thomassen
 | doi = 10.1002/jgt.3190050304
 | issue = 3
 | journal = Journal of Graph Theory
 | mr = 625064
 | pages = 225–241
 | title = Kuratowski's theorem
 | volume = 5
 | year = 1981}}.&lt;/ref&gt;

In the [[Soviet Union]], Kuratowski's theorem was known as either the '''Pontryagin–Kuratowski theorem''' or the '''Kuratowski–Pontryagin theorem''',&lt;ref&gt;{{citation
 | last1 = Burstein | first1 = Michael
 | doi = 10.1016/0095-8956(78)90024-2
 | title = Kuratowski-Pontrjagin theorem on planar graphs
 | journal = Journal of Combinatorial Theory, Series B
 | volume = 24
 | pages = 228–232
 | year = 1978}}&lt;/ref&gt;
as the theorem was reportedly proved independently by [[Lev Pontryagin]] around 1927.&lt;ref&gt;{{citation
 | last1 = Kennedy | first1 = John W.
 | last2 = Quintas | first2 = Louis V.
 | last3 = Sysło | first3 = Maciej M.
 | doi = 10.1016/0315-0860(85)90045-X
 | title = The theorem on planar graphs
 | journal = Historia Mathematica
 | volume = 12
 | pages = 356–368
 | year = 1985}}&lt;/ref&gt;
However, as Pontryagin never published his proof, this usage has not spread to other places.&lt;ref&gt;{{citation|title=Graphs &amp; Digraphs|edition=5th|first1=Gary|last1=Chartrand|author1-link=Gary Chartrand|first2=Linda|last2=Lesniak|first3=Ping|last3=Zhang|author3-link=Ping Zhang (graph theorist)|publisher=CRC Press|year=2010|isbn=9781439826270|page=237|url=https://books.google.com/books?id=K6-FvXRlKsQC&amp;pg=PA237}}.&lt;/ref&gt;

==Related results==
A closely related result, [[Wagner's theorem]], characterizes the planar graphs by their [[graph minor|minors]] in terms of the same two forbidden graphs ''K''&lt;sub&gt;5&lt;/sub&gt; and ''K''&lt;sub&gt;3,3&lt;/sub&gt;. Every Kuratowski subgraph is a special case of a minor of the same type, and while the reverse is not true, it is not difficult to find a Kuratowski subgraph (of one type or the other) from one of these two forbidden minors; therefore, these two theorems are equivalent.&lt;ref&gt;{{citation|title=Graph Theory|volume=244|series=Graduate Texts in Mathematics|first1=J. A.|last1=Bondy|author1-link=John Adrian Bondy|first2=U.S.R.|last2=Murty|author2-link=U. S. R. Murty|publisher=Springer|year=2008|isbn=9781846289699|page=269|url=https://books.google.com/books?id=HuDFMwZOwcsC&amp;pg=PA269}}.&lt;/ref&gt;

An extension is the [[Robertson-Seymour theorem]].

==See also==
*[[Kelmans–Seymour conjecture]], that 5-connected nonplanar graphs contain a subdivision of {{math|''K''&lt;sub&gt;5&lt;/sub&gt;}}

==References==
{{reflist}}

[[Category:Planar graphs]]
[[Category:Theorems in graph theory]]</text>
      <sha1>4svrid2hz3e5y8tyq5azhws2vc5ftis</sha1>
    </revision>
  </page>
  <page>
    <title>List of Lie groups topics</title>
    <ns>0</ns>
    <id>342038</id>
    <revision>
      <id>806712132</id>
      <parentid>806712105</parentid>
      <timestamp>2017-10-23T18:07:40Z</timestamp>
      <contributor>
        <username>Mathphysman</username>
        <id>19811191</id>
      </contributor>
      <minor/>
      <comment>/* Lie algebras */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3980">This is a '''list of [[Lie group]] topics''', by Wikipedia page.

==Examples==
''See [[Table of Lie groups]] for a list''

*[[General linear group]], [[special linear group]]
**[[SL2(R)|SL&lt;sub&gt;2&lt;/sub&gt;('''R''')]]
**[[SL2(C)|SL&lt;sub&gt;2&lt;/sub&gt;('''C''')]]
*[[Unitary group]], [[special unitary group]]
**[[SU(2)]]
**[[SU(3)]]
*[[Orthogonal group]], [[special orthogonal group]]
**[[Rotation group SO(3)]]
**[[SO(8)]]
**[[Generalized orthogonal group]], [[generalized special orthogonal group]]
***The special unitary group SU(1,1) is the unit sphere in the ring of [[coquaternion]]s. It is the group of [[hyperbolic motion]]s of the Poincaré disk model of the [[Hyperbolic geometry|Hyperbolic plane]].
***[[Lorentz group]]
**[[Spinor group]]
*[[Symplectic group]]
*Exceptional groups
**[[G2 (mathematics)|G&lt;sub&gt;2&lt;/sub&gt;]]
**[[F4 (mathematics)|F&lt;sub&gt;4&lt;/sub&gt;]]
**[[E6 (mathematics)|E&lt;sub&gt;6&lt;/sub&gt;]]
**[[E7 (mathematics)|E&lt;sub&gt;7&lt;/sub&gt;]]
**[[E8 (mathematics)|E&lt;sub&gt;8&lt;/sub&gt;]]
*[[Affine group]]
*[[Euclidean group]]
*[[Poincaré group]]
*[[Heisenberg group]]

==[[Lie algebra]]s==

*[[Commutator]]
*[[Jacobi identity]]
*[[Universal enveloping algebra]]
*[[Baker-Campbell-Hausdorff formula]]
*[[Casimir invariant]]
*[[Killing form]]
*[[Kac–Moody algebra]]
*[[Affine Lie algebra]]
*[[Loop algebra]]
*[[Graded Lie algebra]]

==Foundational results==

*[[One-parameter group]], [[One-parameter subgroup]]
*[[Matrix exponential]]
*[[Infinitesimal transformation]]
*[[Lie's third theorem]]
*[[Maurer–Cartan form]]
*[[Closed subgroup theorem|Cartan's theorem]]
*[[Cartan's criterion]]
*[[Local Lie group]]
*[[Formal group law]]
*[[Hilbert's fifth problem]]
*[[Hilbert-Smith conjecture]]
*[[Lie group decompositions]]
*[[Real form (Lie theory)]]
*[[Complex Lie group]]
*[[Complexification (Lie group)]]

== Semisimple theory==

*[[Simple Lie group]]
*[[Compact Lie group]], [[Compact real form]]
*[[Semisimple Lie algebra]]
*[[Root system]]
*[[Simply laced group]]
**[[ADE classification]]
*[[Maximal torus]]
*[[Weyl group]]
*[[Dynkin diagram]]
*[[Weyl character formula]]

==Representation theory==
{{see also|List of representation theory topics}}

*[[Representation of a Lie group]]
*[[Representation of a Lie algebra]]
*[[Adjoint representation of a Lie group]]
*[[Adjoint representation of a Lie algebra]]
*[[Unitary representation]]
*[[Weight (representation theory)]]
*[[Peter–Weyl theorem]]
*[[Borel–Weil theorem]]
*[[Kirillov character formula]]
*[[Representation theory of SU(2)]]
*[[Representation theory of SL2(R)]]

==Applications==

===Physical theories===
*[[Pauli matrices]]
*[[Gell-Mann matrices]]
*[[Poisson bracket]]
*[[Noether's theorem]]
*[[Wigner's classification]]
*[[Gauge theory]]
*[[Grand unification theory]]
*[[Supergroup (physics)|Supergroup]]
*[[Lie superalgebra]]
*[[Twistor theory]]
*[[Anyon]]
*[[Witt algebra]]
*[[Virasoro algebra]]

===Geometry===
*[[Erlangen programme]]
*[[Homogeneous space]]
**[[Principal homogeneous space]]
*[[Invariant theory]]
*[[Lie derivative]]
*[[Darboux derivative]]
*[[Lie groupoid]]
*[[Lie algebroid]]

===[[Discrete group]]s===
*[[Lattice (group)]]
*[[Lattice (discrete subgroup)]]
*[[Frieze group]]
*[[Wallpaper group]]
*[[Space group]]
*[[Crystallographic group]]
*[[Fuchsian group]]
*[[Modular group]]
*[[Congruence subgroup]]
*[[Kleinian group]]
*[[Discrete Heisenberg group]]
*[[Clifford–Klein form]]

===[[Algebraic group]]s===
*[[Borel subgroup]]
*[[Parabolic subgroup]]
*[[Arithmetic group]]

==[[Special functions]]==

*[[Dunkl operator]]

===Automorphic forms===
*[[Modular form]]
*[[Langlands program]]

==People==

*[[Sophus Lie]] (1842 &amp;ndash; 1899)
*[[Wilhelm Killing]] (1847 &amp;ndash; 1923)
*[[Élie Cartan]] (1869 &amp;ndash; 1951)
*[[Hermann Weyl]] (1885 &amp;ndash; 1955)
*[[Harish-Chandra]] (1923 &amp;ndash; 1983)
*[[Lajos Pukánszky]](1928 &amp;ndash; 1996)
*[[Bertram Kostant]]

[[Category:Mathematics-related lists|Lie groups]]
[[Category:Lie groups| ]]
[[Category:Lie algebras]]
[[Category:Wikipedia outlines|Lie groups]]</text>
      <sha1>i5dstyixk7j87ebkrpjuu3me9fao89m</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Erik Fredholm</title>
    <ns>0</ns>
    <id>49494506</id>
    <redirect title="Erik Ivar Fredholm" />
    <revision>
      <id>705996417</id>
      <parentid>705996326</parentid>
      <timestamp>2016-02-20T20:42:14Z</timestamp>
      <contributor>
        <username>Ema--or</username>
        <id>16005968</id>
      </contributor>
      <minor/>
      <comment>Ema--or moved page [[List of things named after Erik Ivar Fredholm]] to [[List of things named after Erik Fredholm]]: Shorter title</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="99">

#REDIRECT [[Erik Ivar Fredholm]]
[[Category:Lists of things named after mathematicians|Fredholm]]</text>
      <sha1>snx6e0ivi427os1451ipc170c8irukv</sha1>
    </revision>
  </page>
  <page>
    <title>Little q-Jacobi polynomials</title>
    <ns>0</ns>
    <id>32844480</id>
    <revision>
      <id>816082521</id>
      <parentid>655862549</parentid>
      <timestamp>2017-12-19T04:05:19Z</timestamp>
      <contributor>
        <ip>86.130.177.171</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3488">{{DISPLAYTITLE:Little ''q''-Jacobi polynomials}}
In mathematics, the '''little ''q''-Jacobi polynomials'''  ''p''&lt;sub&gt;''n''&lt;/sub&gt;(''x'';''a'',''b'';''q'') are a family of basic hypergeometric [[orthogonal polynomials]] in the basic [[Askey scheme]], introduced by {{harvtxt|Hahn|1949}}. {{harvs|txt | last1=Koekoek | first1=Roelof | last2=Lesky | first2=Peter A. | last3=Swarttouw | first3=René F. | title=Hypergeometric orthogonal polynomials and their q-analogues | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Springer Monographs in Mathematics | isbn=978-3-642-05013-8 | doi=10.1007/978-3-642-05014-5 | mr=2656096 | year=2010|loc=14}} give a detailed list of their properties.

==Definition==

The  little ''q''-Jacobi polynomials are given in terms of [[basic hypergeometric function]]s and the [[Pochhammer symbol]] by 
:&lt;math&gt;\displaystyle  p_n(x;a,b;q) = {}_2\phi_1(q^{-n},abq^{n+1};aq;q,xq)  &lt;/math&gt;

==Orthogonality==
{{Empty section|date=September 2011}}

==Recurrence and difference relations==
{{Empty section|date=September 2011}}

==Rodrigues formula==
{{Empty section|date=September 2011}}

==Generating function==
{{Empty section|date=September 2011}}

==Relation to other polynomials==
{{Empty section|date=September 2011}}

==Gallery==
The following are a set of animation plots for  Little q-Jacobi polynomials, with varying  q;
three  density plots of  imaginary, real and modula  in complex space; three set of complex 3D plots
of  imaginary, real and modulus of the said polynomials.
{|
|[[File:LITTLE Q-JACOBI POLYNOMIALS ABS COMPLEX 3D MAPLE PLOT.gif|thumb|LITTLE Q-JACOBI POLYNOMIALS ABS COMPLEX 3D MAPLE PLOT]]
|[[File:LITTLE Q-JACOBI POLYNOMIALS IM COMPLEX 3D MAPLE PLOT.gif|thumb|LITTLE Q-JACOBI POLYNOMIALS IM COMPLEX 3D MAPLE PLOT]]
|[[File:LITTLE Q-JACOBI POLYNOMIALS RE COMPLEX 3D MAPLE PLOT.gif|thumb|LITTLE Q-JACOBI POLYNOMIALS RE COMPLEX 3D MAPLE PLOT]]
|}
{|
|[[File:LITTLE Q-JACOBI POLYNOMIALS ABS DENSITY MAPLE PLOT.gif|thumb|LITTLE Q-JACOBI POLYNOMIALS ABS DENSITY MAPLE PLOT]]
|[[File:LITTLE Q-JACOBI POLYNOMIALS IM DENSITY MAPLE PLOT.gif|thumb|LITTLE Q-JACOBI POLYNOMIALS IM DENSITY MAPLE PLOT]]
|[[File:LITTLE Q-JACOBI POLYNOMIALS RE DENSITY MAPLE PLOT.gif|thumb|LITTLE Q-JACOBI POLYNOMIALS RE DENSITY MAPLE PLOT]]
|}


==References==

*{{Citation | last1=Gasper | first1=George | last2=Rahman | first2=Mizan | title=Basic hypergeometric series | publisher=[[Cambridge University Press]] | edition=2nd | series=Encyclopedia of Mathematics and its Applications | isbn=978-0-521-83357-8 | doi=10.2277/0521833574 | mr=2128719 | year=2004 | volume=96}}
*{{Citation | last1=Hahn | first1=Wolfgang | title=Über Orthogonalpolynome, die q-Differenzengleichungen genügen | doi=10.1002/mana.19490020103 | mr=0030647 | year=1949 | journal=[[Mathematische Nachrichten]] | issn=0025-584X | volume=2 | pages=4–34}}
*{{Citation | last1=Koekoek | first1=Roelof | last2=Lesky | first2=Peter A. | last3=Swarttouw | first3=René F. | title=Hypergeometric orthogonal polynomials and their q-analogues | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Springer Monographs in Mathematics | isbn=978-3-642-05013-8 | doi=10.1007/978-3-642-05014-5 | mr=2656096 | year=2010}}
*{{dlmf|id=18|first=Tom H. |last=Koornwinder|first2=Roderick S. C.|last2= Wong|first3=Roelof |last3=Koekoek||first4=René F. |last4=Swarttouw}}

[[Category:Orthogonal polynomials]]
[[Category:Q-analogs]]
[[Category:Special hypergeometric functions]]</text>
      <sha1>2ofek4vuof6j6sz9okwqal5f5pg9aws</sha1>
    </revision>
  </page>
  <page>
    <title>Malthusian growth model</title>
    <ns>0</ns>
    <id>3437245</id>
    <revision>
      <id>861154480</id>
      <parentid>861154474</parentid>
      <timestamp>2018-09-25T13:52:21Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/97.105.109.222|97.105.109.222]] to version by Jeftakels. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3485660) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4840">A '''Malthusian growth model''', sometimes called a '''simple exponential''' growth model, is essentially [[exponential growth]] based on the idea of the function being proportional to the speed to which the function grows. The model is named after [[ Thomas Robert Malthus]], who wrote ''[[An Essay on the Principle of Population]]'' (1798), one of the earliest and most influential books on [[population]].&lt;ref name=malthus&gt;"Malthus, An Essay on the Principle of Population: Library of Economics"&lt;/ref&gt;

Malthusian models have the following form:
:&lt;math&gt; P(t) = P_0e^{rt} &lt;/math&gt;
where

* ''P''&lt;sub&gt;0&lt;/sub&gt; = ''P''(0) is the initial population size,
* ''r'' = the population growth rate, sometimes called ''Malthusian parameter'',
* ''t'' = time.

The model can also been written in the form of a differential equation:

dP/dt = rP

with initial condition:
P(0)= P&lt;sub&gt;0&lt;/sub&gt;

This model is often referred to as the ''exponential law''.&lt;ref&gt;Turchin, P. "Complex population dynamics: a theoretical/empirical synthesis" Princeton [http://press.princeton.edu/chapters/s7436.html online]&lt;/ref&gt; It is widely regarded in the field of [[population ecology]] as the [[first principle]] of [[population dynamics]],&lt;ref&gt;Turchin, P. "Does Population Ecology Have General Laws?" Oikos 94:17–26. 2000&lt;/ref&gt; with [[Malthus]] as the founder. The exponential law is therefore also sometimes referred to as the ''Malthusian Law''.&lt;ref&gt;Paul Haemig, "Laws of Population Ecology", 2005&lt;/ref&gt; By now, it is a widely accepted view to analogize Malthusian growth in Ecology to [[Newton's First Law|Newton's First Law of uniform motion]] in physics.&lt;ref&gt;{{Cite journal|last=Ginzburg|first=Lev R.|title=The theory of population dynamics: I. Back to first principles|url=https://dx.doi.org/10.1016/S0022-5193(86)80180-1|journal=Journal of Theoretical Biology|language=en|volume=122|issue=4|pages=385–399|doi=10.1016/s0022-5193(86)80180-1}}&lt;/ref&gt;

Malthus wrote that all life forms, including humans, have a propensity to exponential population growth when resources are abundant but that actual growth is limited by available resources:
{{quote|Through the animal and vegetable kingdoms, nature has scattered the seeds of life abroad with the most profuse and liberal hand.... The germs of existence contained in this spot of earth, with ample food, and ample room to expand in, would fill millions of worlds in the course of a few thousand years. Necessity, that imperious all pervading law of nature, restrains them within the prescribed bounds. The race of plants, and the race of animals shrink under this great restrictive law. And the race of man cannot, by any efforts of reason, escape from it. Among plants and animals its effects are waste of seed, sickness, and premature death. Among mankind, misery and vice. |Thomas Malthus, 1798. ''[[An Essay on the Principle of Population]]''. Chapter I.}}

A model of population growth bounded by resource limitations was developed by [[Pierre Francois Verhulst]] in 1838, after he had read Malthus' essay. Verhulst named the model a [[logistic function]].

==See also==
*[[Albert Allen Bartlett]] – a leading proponent of the Malthusian Growth Model
*[[Exogenous growth model]] – related growth model from [[economics]]
*[[Growth theory]] – related ideas from [[economics]]
*[[Human overpopulation]]
*[[Irruptive growth]] – an extension of the Malthusian model accounting for population explosions and crashes
*[[Malthusian catastrophe]]
*[[Neo-malthusianism]]
*[[The Genetical Theory of Natural Selection]]

==References==
{{reflist}}

==External links==
*[http://www.stolaf.edu/people/mckelvey/envision.dir/malthus.html Malthusian Growth Model] from Steve McKelvey, Department of Mathematics, Saint Olaf College, Northfield, Minnesota
*[http://www.stolaf.edu/people/mckelvey/envision.dir/logistic.html Logistic Model] from Steve McKelvey, Department of Mathematics, Saint Olaf College, Northfield, Minnesota
*[http://www.ecology.info/laws-population-ecology.htm Laws Of Population Ecology] Dr. Paul D. Haemig
*[http://entomology.wsu.edu/personal/alan_berryman/Berryman(3)Principles.pdf On principles, laws and theory of population ecology] Professor of Entomology, Alan Berryman, Washington State University
*[http://urss.ru/cgi-bin/db.pl?cp=&amp;lang=en&amp;blang=en&amp;list=14&amp;page=Book&amp;id=34250 Introduction to Social Macrodynamics] Professor [[Andrey Korotayev]]
*[http://www.arcytech.org/java/population/facts_math.html Interesting Facts about Population Growth Mathematical Models] from Jacobo Bulaevsky, Arcytech.
*[http://www.colyvan.com/book2.html Ecological Orbits] Lev Ginzburg, Mark Colyvan

{{Population}}
{{modelling ecosystems|expanded=none}}

[[Category:Empirical laws]]
[[Category:Mathematical modeling]]
[[Category:Population]]
[[Category:Population ecology]]
[[Category:1798 in economics]]</text>
      <sha1>k2ye0mmx1nzmz5wur48qalvjiul84y0</sha1>
    </revision>
  </page>
  <page>
    <title>Martin T. Barlow</title>
    <ns>0</ns>
    <id>31840693</id>
    <revision>
      <id>747716829</id>
      <parentid>720028260</parentid>
      <timestamp>2016-11-03T23:46:46Z</timestamp>
      <contributor>
        <username>Duncan.Hull</username>
        <id>3507210</id>
      </contributor>
      <comment>Added [[Template:FRS 2005]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3536">'''Martin Thomas Barlow''' [[Royal Society#Fellows|FRS]] [[Royal Society of Canada|FRSC]] (born 16 June 1953 in [[London]]) is a [[United Kingdom|British]] [[mathematician]] who is professor of mathematics at the [[University of British Columbia]] in [[Canada]] since 1992.&lt;ref name=debrett/&gt;

==History==
Barlow is the son of Andrew Dalmahoy Barlow (1916–2006) and his wife Yvonne.&lt;ref name=dpot&gt;{{cite book | title=Debrett's People of Today | year=2011 | page=87 | url=http://www.exacteditions.com/exact/browse/455/1210/7772/3/123 }}&lt;/ref&gt; He is thus the grandson of [[Alan Barlow]], and his wife [[Nora Barlow|Nora (née Darwin)]], through whom he is a great-great-grandson of [[Charles Darwin]]. He is the nephew of [[Horace Barlow]] (also FRS and Fellow of Trinity).  In 1994 he married Colleen McLaughlin.&lt;ref name=dpot/&gt;

He was educated [[Sussex House School]], [[St Paul's School, London]], [[Trinity College, Cambridge]] (BA 1975, Diploma 1976, ScD 1993); [[University College of Swansea]] (PhD).&lt;ref name=debrett&gt;http://www.debretts.co.uk/people/biographies/browse/b/25222/Martin%20Thomas+BARLOW.aspx&lt;/ref&gt;&lt;ref name=dpot/&gt;

Barlow worked as a research fellow of the [[University of Liverpool]] 1978–1980.  He was a Fellow of [[Trinity College, Cambridge]], 1979–1992.  He worked in the [[Statistical Laboratory, University of Cambridge]] 1981–1985 and was a Royal Society University Research Fellow 1985–1992.&lt;ref name=debrett/&gt;

==Work==
His mathematical interests include [[probability]], [[Brownian motion]] and [[fractal sets]].

He was awarded the [[Rollo Davidson Prize]] in 1984.&lt;ref name=debrett/&gt;&lt;ref&gt;{{cite web | url=http://www.statslab.cam.ac.uk/Rollo/award.html | publisher=[[Statistical Laboratory, University of Cambridge]] | accessdate=2011-05-26 | title=Rollo Davidson Awards 1976 - 2010 }}&lt;/ref&gt; He was elected a [[Fellow of the Royal Society of Canada]] in 1998.&lt;ref name=debrett/&gt;  He was elected a [[Fellow of the Royal Society]] in 2005.&lt;ref&gt;{{cite web | url=http://royalsociety.org/about-us/fellowship/fellows/ | publisher=[[Royal Society]] | title=Fellows of the Royal Society | accessdate=2011-05-26 }}&lt;/ref&gt; In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-03.&lt;/ref&gt; His doctoral students include [[Steven Neil Evans|Steven N. Evans]].&lt;ref&gt;{{MathGenealogy|id=44866|name=Martin Thomas Barlow}}&lt;/ref&gt;

== References==
{{reflist}}
* ‘BARLOW, Prof. Martin Thomas’, Who's Who 2011, A &amp; C Black, 2011; online edn, Oxford University Press, Dec 2010 ; online edn, Oct 2010 [http://www.ukwhoswho.com/view/article/oupww/whoswho/U45524, accessed 21 May 2011]

== External links==
* [http://www.math.ubc.ca/~barlow/ Academic homepage]
{{FRS 2005}}
{{Authority control}}
{{Use dmy dates|date=May 2011}}

{{DEFAULTSORT:Barlow, Martin Thomas}}
[[Category:1953 births]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Royal Society]]
[[Category:Fellows of the Royal Society of Canada]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:Living people]]
[[Category:People educated at St Paul's School, London]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:Alumni of Swansea University]]
[[Category:20th-century British mathematicians]]
[[Category:21st-century British mathematicians]]
[[Category:University of British Columbia faculty]]
[[Category:Probability theorists]]


{{UK-mathematician-stub}}</text>
      <sha1>qt7a3g5msr0mquaw5qf08ivglv80hed</sha1>
    </revision>
  </page>
  <page>
    <title>Multivariate kernel density estimation</title>
    <ns>0</ns>
    <id>28831427</id>
    <revision>
      <id>868858659</id>
      <parentid>842554587</parentid>
      <timestamp>2018-11-14T22:20:24Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32371">[[Kernel density estimation]] is a [[nonparametric]] technique for  [[density estimation]] i.e., estimation of [[probability density function]]s, which is one of the fundamental questions in [[statistics]]. It can be viewed as a generalisation of [[histogram]] density estimation with improved statistical properties. Apart from histograms, other types of density estimators include [[parametric statistics|parametric]], [[spline interpolation|spline]], [[wavelet]] and [[Fourier series]]. Kernel density estimators were first introduced in the scientific literature for [[univariate]] data in the 1950s and 1960s&lt;ref&gt;{{Cite journal| doi=10.1214/aoms/1177728190 | last=Rosenblatt | first=M.| title=Remarks on some nonparametric estimates of a density function | journal=Annals of Mathematical Statistics | year=1956 | volume=27 | issue=3 | pages=832–837}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| doi=10.1214/aoms/1177704472| last=Parzen | first=E.| title=On estimation of a probability density function and mode | journal=Annals of Mathematical Statistics| year=1962 | volume=33 | issue=3 | pages=1065–1076}}&lt;/ref&gt; and subsequently have been widely adopted. It was soon recognised that analogous estimators for multivariate data would be an important addition to [[multivariate statistics]]. Based on research carried out in the 1990s and 2000s, '''multivariate kernel density estimation''' has reached a level of maturity comparable to its univariate counterparts.&lt;ref name="simonoff1996"&gt;{{Cite book| author=Simonoff, J.S. | title=Smoothing Methods in Statistics | publisher=Springer | year=1996 | isbn=0-387-94716-7}}&lt;/ref&gt;

==Motivation==
We take an illustrative [[Synthetic data|synthetic]] [[bivariate data|bivariate]] data set of 50 points to illustrate the construction of histograms. This requires the choice of an anchor point (the lower left corner of the histogram grid). For the histogram on the left, we choose (−1.5,&amp;nbsp;−1.5): for the one on the right, we shift the anchor point by 0.125 in both directions to (−1.625,&amp;nbsp;−1.625). Both histograms have a binwidth of 0.5, so any differences are due to the change in the anchor point only. The colour-coding indicates the number of data points which fall into a bin: 0=white, 1=pale yellow, 2=bright yellow, 3=orange, 4=red. The left histogram appears to indicate that the upper half has a higher density than the lower half, whereas the reverse is the case for the right-hand histogram, confirming that histograms are highly sensitive to the placement of the anchor point.&lt;ref&gt;{{Cite book| author=Silverman, B.W. | title=Density Estimation for Statistics and Data Analysis | publisher=Chapman &amp; Hall/CRC | year=1986 | isbn=0-412-24620-1 | pages=7–11}}&lt;/ref&gt;

[[File:Synthetic data 2D histograms.png|thumb|center|500px|alt=Left. Histogram with anchor point at (−1.5,&amp;nbsp;-1.5). Right. Histogram with anchor point at (−1.625,&amp;nbsp;−1.625). Both histograms have a bin width of 0.5, so differences in appearances of the two histograms are due to the placement of the anchor point.|Comparison of 2D histograms. Left. Histogram with anchor point at (−1.5,&amp;nbsp;-1.5). Right. Histogram with anchor point at (−1.625,&amp;nbsp;−1.625). Both histograms have a bin width of 0.5, so differences in appearances of the two histograms are due to the placement of the anchor point.]]

One possible solution to this anchor point placement problem is to remove the histogram binning grid completely. In the left figure below, a kernel (represented by the grey lines) is centred at each of the 50 data points above. The result of summing these kernels is given on the right figure, which is a kernel density estimate. The most striking difference between kernel density estimates and histograms is that the former are easier to interpret since they do not contain artifices induced by a binning grid.
The coloured contours correspond to the smallest region which contains the respective probability mass: red = 25%, orange + red = 50%, yellow + orange + red = 75%, thus indicating that a single central region contains the highest density.

[[File:Synthetic data 2D KDE.png|thumb|center|500px|alt=Left. Individual kernels. Right. Kernel density estimate.|Construction of 2D kernel density estimate. Left. Individual kernels. Right. Kernel density estimate.]]

The goal of density estimation is to take a finite sample of data and to make inferences about the underlying probability density function everywhere, including where no data are observed. In kernel density estimation, the contribution of each data point is smoothed out from a single point into a region of space surrounding it. Aggregating the individually smoothed contributions gives an overall picture of the structure of the data and its density function. In the details to follow, we show that this approach leads to a reasonable estimate of the underlying density function.

==Definition==
The previous figure is a graphical representation of kernel density estimate, which we now define in an exact manner. Let '''x'''&lt;sub&gt;1&lt;/sub&gt;, '''x'''&lt;sub&gt;2&lt;/sub&gt;, …, '''x'''&lt;sub&gt;''n''&lt;/sub&gt; be a [[random sample|sample]] of ''d''-variate [[random vector]]s drawn from a common distribution described by the [[probability density function|density function]] ''ƒ''. The kernel density estimate is defined to be
: &lt;math&gt;
    \hat{f}_\mathbf{H}(\mathbf{x})= \frac1n \sum_{i=1}^n K_\mathbf{H} (\mathbf{x} - \mathbf{x}_i)
  &lt;/math&gt;
where
* {{nowrap|'''x''' {{=}} (''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, …, ''x&lt;sub&gt;d&lt;/sub&gt;'')&lt;sup&gt;''T''&lt;/sup&gt;}}, {{nowrap|'''x'''&lt;sub&gt;''i''&lt;/sub&gt; {{=}} (''x''&lt;sub&gt;''i''1&lt;/sub&gt;, ''x''&lt;sub&gt;''i''2&lt;/sub&gt;, …, ''x&lt;sub&gt;id&lt;/sub&gt;'')&lt;sup&gt;''T''&lt;/sup&gt;, ''i'' {{=}} 1, 2, …, ''n''}} are ''d''-vectors;
* '''H''' is the bandwidth (or smoothing) ''d×d'' matrix which is [[symmetric matrix|symmetric]] and [[positive definite matrix|positive definite]];
* ''K'' is the [[kernel (statistics)|kernel]] function which is a symmetric multivariate density;
* &lt;math&gt;K_\mathbf{H}(\mathbf{x})=|\mathbf{H}|^{-1/2}K(\mathbf{H}^{-1/2}\mathbf{x} )&lt;/math&gt;.

The choice of the kernel function ''K'' is not crucial to the accuracy of kernel density estimators, so we use the standard [[multivariate normal distribution|multivariate normal]] kernel throughout: &lt;math display="inline"&gt;K_\mathbf{H}(\mathbf{x})={(2 \pi)^{-d/2}} \mathbf{|H|}^{-1/2}  e^{ -\frac{1}{2}\mathbf{x^T}\mathbf{H^{-1}}\mathbf{x} }&lt;/math&gt;, where H plays the role of the [[covariance matrix]]. On the other hand, the choice of the bandwidth matrix &lt;strong&gt;H&lt;/strong&gt; is the single most important factor affecting its accuracy since it controls the amount and orientation of smoothing induced.&lt;ref name="WJ1995"&gt;{{Cite book| author1=Wand, M.P | author2=Jones, M.C. | title=Kernel Smoothing | publisher=Chapman &amp; Hall/CRC | location=London | year=1995 | isbn = 0-412-55270-1}}&lt;/ref&gt;{{rp|36–39}} That the bandwidth matrix also induces an orientation is a basic difference between multivariate kernel density estimation from its univariate analogue since orientation is not defined for 1D kernels. This leads to the choice of the parametrisation of this bandwidth matrix. The three main parametrisation classes (in increasing order of complexity) are ''S'', the class of positive scalars times the identity matrix; ''D'', diagonal matrices with positive entries on the main diagonal; and ''F'', symmetric positive definite matrices. The ''S'' class kernels have the same amount of smoothing applied in all coordinate directions, ''D'' kernels allow different amounts of smoothing in each of the coordinates, and ''F'' kernels allow arbitrary amounts and orientation of the smoothing. Historically ''S'' and ''D'' kernels are the most widespread due to computational reasons, but research indicates that important gains in accuracy can be obtained using the more general ''F'' class kernels.&lt;ref&gt;{{cite journal | author1=Wand, M.P. | author2=Jones, M.C. | title=Comparison of smoothing parameterizations in bivariate kernel density estimation | journal=Journal of the American Statistical Association | year=1993 | volume=88 | issue=422 | pages=520–528 | doi=10.1080/01621459.1993.10476303 | jstor=2290332}}&lt;/ref&gt;&lt;ref name="DH2003"&gt;{{Cite journal| doi=10.1080/10485250306039 | author1=Duong, T. | author2=Hazelton, M.L. | title=Plug-in bandwidth matrices for bivariate kernel density estimation | journal=Journal of Nonparametric Statistics | year=2003 | volume=15 | pages=17–30}}&lt;/ref&gt;

[[File:Kernel parametrisation class.png|thumb|center|500px|alt=Comparison of the three main bandwidth matrix parametrisation classes. Left. S positive scalar times the identity matrix. Centre. D diagonal matrix with positive entries on the main diagonal. Right. F symmetric positive definite matrix.|Comparison of the three main bandwidth matrix parametrisation classes. Left. ''S'' positive scalar times the identity matrix. Centre. ''D'' diagonal matrix with positive entries on the main diagonal. Right. ''F'' symmetric positive definite matrix.]]

==Optimal bandwidth matrix selection==
The most commonly used optimality criterion for selecting a bandwidth matrix is the MISE or [[mean integrated squared error]]

: &lt;math&gt;\operatorname{MISE} (\mathbf{H}) = \operatorname{E}\!\left[\, \int (\hat{f}_\mathbf{H} (\mathbf{x}) - f(\mathbf{x}))^2 \, d\mathbf{x} \;\right].&lt;/math&gt;

This in general does not possess a [[closed-form expression]], so it is usual to use its asymptotic approximation (AMISE) as a proxy

: &lt;math&gt;\operatorname{AMISE} (\mathbf{H}) = n^{-1} |\mathbf{H}|^{-1/2} R(K) +  \tfrac{1}{4} m_2(K)^2 
(\operatorname{vec}^T \mathbf{H}) \mathbf{\Psi}_4 (\operatorname{vec} \mathbf{H})&lt;/math&gt;

where
* &lt;math&gt;R(K) = \int K(\mathbf{x})^2 \, d\mathbf{x}&lt;/math&gt;, with {{nowrap|''R''(''K'') {{=}} (4''π'')&lt;sup&gt;''−d''/2&lt;/sup&gt;}} when ''K'' is a normal kernel
* &lt;math&gt;\int \mathbf{x} \mathbf{x}^T K(\mathbf{x}) \, d\mathbf{x} = m_2(K) \mathbf{I}_d&lt;/math&gt;,
:with &lt;strong&gt;I&lt;/strong&gt;&lt;sub&gt;d&lt;/sub&gt; being the ''d × d'' [[identity matrix]], with ''m''&lt;sub&gt;2&lt;/sub&gt; = 1 for the normal kernel
* D&lt;sup&gt;2&lt;/sup&gt;''ƒ'' is the ''d × d'' Hessian matrix of second order partial derivatives of ''ƒ''
* &lt;math&gt;\mathbf{\Psi}_4 = \int (\operatorname{vec} \, \operatorname{D}^2 f(\mathbf{x})) (\operatorname{vec}^T \operatorname{D}^2 f(\mathbf{x})) \, d\mathbf{x}&lt;/math&gt; is a ''d''&lt;sup&gt;2&lt;/sup&gt; × ''d''&lt;sup&gt;2&lt;/sup&gt; matrix of integrated fourth order partial derivatives of ''ƒ''
* vec is the vector operator which stacks the columns of a matrix into a single vector e.g. &lt;math&gt;\operatorname{vec}\begin{bmatrix}a &amp; c \\ b &amp; d\end{bmatrix} = \begin{bmatrix}a &amp; b &amp; c &amp; d\end{bmatrix}^T.&lt;/math&gt;

The quality of the AMISE approximation to the MISE&lt;ref name="WJ1995"/&gt;{{rp|97}} is given by

: &lt;math&gt;\operatorname{MISE} (\mathbf{H}) = \operatorname{AMISE} (\mathbf{H}) + o(n^{-1} |\mathbf{H}|^{-1/2} + \operatorname{tr} \, \mathbf{H}^2)&lt;/math&gt;

where ''o'' indicates the usual [[big O notation|small o notation]]. Heuristically this statement implies that the AMISE is a 'good' approximation of the MISE as the sample size &lt;var&gt;n&lt;/var&gt; → ∞.

It can be shown that any reasonable bandwidth selector '''H''' has '''H''' = ''O''(''n''&lt;sup&gt;−2/(''d''+4)&lt;/sup&gt;) where the [[big O notation]] is applied elementwise. Substituting this into the MISE formula yields that the optimal MISE is ''O''(''n''&lt;sup&gt;−4/(''d''+4)&lt;/sup&gt;).&lt;ref name="WJ1995"/&gt;{{rp|99–100}} Thus as ''n'' → ∞, the MISE → 0, i.e. the kernel density estimate [[convergence in mean|converges in mean square]] and thus also in probability to the true density ''f''. These modes of convergence are confirmation of the statement in the motivation section that kernel methods lead to reasonable density estimators.  An ideal optimal bandwidth selector is

: &lt;math&gt;\mathbf{H}_{\operatorname{AMISE}} = \operatorname{argmin}_{\mathbf{H} \in F} \, \operatorname{AMISE} (\mathbf{H}).&lt;/math&gt;

Since this ideal selector contains the unknown density function ''ƒ'', it cannot be used directly. The many different varieties of data-based bandwidth selectors arise from the different estimators of the AMISE. We concentrate on two classes of selectors which have been shown to be the most widely applicable in practice: smoothed cross validation and plug-in selectors.

===Plug-in===
The plug-in (PI) estimate of the AMISE is formed by replacing '''Ψ'''&lt;sub&gt;4&lt;/sub&gt; by its estimator &lt;math&gt;\hat{\mathbf{\Psi}}_4&lt;/math&gt;

: &lt;math&gt;\operatorname{PI}(\mathbf{H}) = n^{-1} |\mathbf{H}|^{-1/2} R(K) +  \tfrac{1}{4} m_2(K)^2 
(\operatorname{vec}^T \mathbf{H}) \hat{\mathbf{\Psi}}_4 (\mathbf{G}) (\operatorname{vec} \, \mathbf{H})&lt;/math&gt;

where &lt;math&gt;\hat{\mathbf{\Psi}}_4 (\mathbf{G}) = n^{-2} \sum_{i=1}^n 
\sum_{j=1}^n [(\operatorname{vec} \, \operatorname{D}^2) (\operatorname{vec}^T \operatorname{D}^2)] K_\mathbf{G} (\mathbf{X}_i - \mathbf{X}_j)&lt;/math&gt;. Thus &lt;math&gt;\hat{\mathbf{H}}_{\operatorname{PI}} = \operatorname{argmin}_{\mathbf{H} \in F} \, \operatorname{PI} (\mathbf{H})&lt;/math&gt; is the plug-in selector.&lt;ref&gt;{{Cite journal| author1=Wand, M.P. | author2=Jones, M.C. | title=Multivariate plug-in bandwidth selection | journal=Computational Statistics | year=1994 | volume=9 | pages=97–177}}&lt;/ref&gt;&lt;ref name="DH2005" /&gt; These references also contain algorithms on optimal estimation of the pilot bandwidth matrix &lt;strong&gt;G&lt;/strong&gt; and establish that &lt;math&gt;\hat{\mathbf{H}}_{\operatorname{PI}}&lt;/math&gt; [[convergence in probability|converges in probability]] to '''H'''&lt;sub&gt;AMISE&lt;/sub&gt;.

===Smoothed cross validation===
Smoothed cross validation (SCV) is a subset of a larger class of [[cross-validation (statistics)|cross validation]] techniques. The SCV estimator differs from the plug-in estimator in the second term

: &lt;math&gt;\operatorname{SCV}(\mathbf{H}) = n^{-1} |\mathbf{H}|^{-1/2} R(K) + 
n^{-2} \sum_{i=1}^n \sum_{j=1}^n (K_{2\mathbf{H} +2\mathbf{G}} - 2K_{\mathbf{H} +2\mathbf{G}}
+ K_{2\mathbf{G}}) (\mathbf{X}_i - \mathbf{X}_j)&lt;/math&gt;

Thus &lt;math&gt;\hat{\mathbf{H}}_{\operatorname{SCV}} = \operatorname{argmin}_{\mathbf{H} \in F} \, \operatorname{SCV} (\mathbf{H})&lt;/math&gt; is the SCV selector.&lt;ref name="DH2005"&gt;{{Cite journal| doi=10.1111/j.1467-9469.2005.00445.x | author1=Duong, T. | author2=Hazelton, M.L. | title=Cross validation bandwidth matrices for multivariate kernel density estimation | journal=Scandinavian Journal of Statistics | year=2005 | volume=32 | issue=3 | pages=485–506}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal| doi=10.1007/BF01205233 | author1=Hall, P. | author2=Marron, J. | author3=Park, B. | title=Smoothed cross-validation | journal=Probability Theory and Related Fields | year=1992 | volume=92 | pages=1–20}}&lt;/ref&gt;
These references also contain algorithms on optimal estimation of the pilot bandwidth matrix &lt;strong&gt;G&lt;/strong&gt; and establish that &lt;math&gt;\hat{\mathbf{H}}_{\operatorname{SCV}}&lt;/math&gt; converges in probability to '''H'''&lt;sub&gt;AMISE&lt;/sub&gt;.

=== Rule of thumb ===

Silverman's rule of thumb suggests using &lt;math&gt;\sqrt{\mathbf{H}_{ii}} = \left(\frac{4}{d+2}\right)^{\frac{1}{d+4}} n^{\frac{-1}{d+4}} \sigma_i&lt;/math&gt; where &lt;math&gt;\sigma_i&lt;/math&gt; is the standard deviation of the ith variable and &lt;math&gt;\mathbf{H}_{ij} = 0, i\neq j&lt;/math&gt;. Scott's rule is &lt;math&gt;\sqrt{\mathbf{H}_{ii}} =  n^{\frac{-1}{d+4}} \sigma_i&lt;/math&gt;.

==Asymptotic analysis==

In the optimal bandwidth selection section, we introduced the MISE. Its construction relies on the [[expected value]] and the [[variance]] of the density estimator&lt;ref name="WJ1995" /&gt;{{rp|97}}

:&lt;math&gt;\operatorname{E} \hat{f}(\mathbf{x};\mathbf{H}) = K_\mathbf{H} * f (\mathbf{x}) = f(\mathbf{x}) + \frac{1}{2} m_2(K) \int \operatorname{tr} (\mathbf{H} \operatorname{D}^2 f(\mathbf{x})) \, d\mathbf{x} + O(\operatorname{tr} \, \mathbf{H}^2)&lt;/math&gt;

where * is the [[convolution]] operator between two functions, and

:&lt;math&gt;\operatorname{Var} \hat{f}(\mathbf{x};\mathbf{H}) = n^{-1} |\mathbf{H}|^{-1/2} R(K) + o(n^{-1} |\mathbf{H}|^{-1/2}).&lt;/math&gt;

For these two expressions to be well-defined, we require that all elements of '''H''' tend to 0 and that ''n''&lt;sup&gt;−1&lt;/sup&gt; |'''H'''|&lt;sup&gt;−1/2&lt;/sup&gt; tends to 0 as ''n'' tends to infinity. Assuming these two conditions, we see that the expected value tends to the true density ''f'' i.e. the kernel density estimator is asymptotically [[Bias of an estimator|unbiased]]; and that the variance tends to zero. Using the standard mean squared value decomposition

:&lt;math&gt;\operatorname{MSE} \, \hat{f}(\mathbf{x};\mathbf{H}) = \operatorname{Var} \hat{f}(\mathbf{x};\mathbf{H}) + [\operatorname{E} \hat{f}(\mathbf{x};\mathbf{H}) - f(\mathbf{x})]^2&lt;/math&gt;

we have that the MSE tends to 0, implying that the kernel density estimator is (mean square) consistent and hence converges in probability to the true density ''f''. The rate of convergence of the MSE to 0 is the necessarily the same as the MISE rate noted previously ''O''(''n''&lt;sup&gt;−4/(d+4)&lt;/sup&gt;), hence the covergence rate of the density estimator to ''f'' is  ''O&lt;sub&gt;p&lt;/sub&gt;''(n&lt;sup&gt;−2/(''d''+4)&lt;/sup&gt;) where ''O&lt;sub&gt;p&lt;/sub&gt;'' denotes [[Big O in probability notation|order in probability]]. This establishes pointwise convergence. The functional covergence is established similarly by considering the behaviour of the MISE, and noting that under sufficient regularity, integration does not affect the convergence rates.

For the data-based bandwidth selectors considered, the target is the AMISE bandwidth matrix. We say that a data-based selector converges to the AMISE selector at relative rate ''O&lt;sub&gt;p&lt;/sub&gt;''(''n''&lt;sup&gt;−''α''&lt;/sup&gt;), ''α'' &gt; 0 if

:&lt;math&gt;\operatorname{vec} (\hat{\mathbf{H}} - \mathbf{H}_{\operatorname{AMISE}}) = O(n^{-2\alpha}) \operatorname{vec} \mathbf{H}_{\operatorname{AMISE}}.&lt;/math&gt;

It has been established that the plug-in and smoothed cross validation selectors (given a single pilot bandwidth '''G''') both converge at a relative rate of ''O&lt;sub&gt;p&lt;/sub&gt;''(''n''&lt;sup&gt;−2/(''d''+6)&lt;/sup&gt;) &lt;ref name="DH2005" /&gt;&lt;ref&gt;{{Cite journal| doi=10.1016/j.jmva.2004.04.004 | author1=Duong, T. | author2=Hazelton, M.L. | title=Convergence rates for unconstrained bandwidth matrix selectors in multivariate kernel density estimation | journal=Journal of Multivariate Analysis | year=2005 | volume=93 | issue=2 | pages=417–433}}&lt;/ref&gt; i.e., both these data-based selectors are consistent estimators.

==Density estimation with a full bandwidth matrix==
[[File:Old Faithful Geyser KDE with plugin bandwidth.png|thumb|250px|alt=Old Faithful Geyser data kernel density estimate with plug-in bandwidth matrix.|Old Faithful Geyser data kernel density estimate with plug-in bandwidth matrix.]]

The [https://cran.r-project.org/web/packages/ks/index.html ks package]&lt;ref&gt;{{Cite journal| author1=Duong, T. | title=ks: Kernel density estimation and kernel discriminant analysis in R | journal=Journal of Statistical Software | year=2007 | volume=21 | issue = 7  | url=http://www.jstatsoft.org/v21/i07}}&lt;/ref&gt; in [[R programming language|R]] implements the plug-in and smoothed cross validation selectors (amongst others). This dataset (included in the base distribution of R) contains
272 records with two measurements each: the duration time of an eruption (minutes) and the
waiting time until the next eruption (minutes) of the [[Old Faithful Geyser]] in Yellowstone National Park, USA.

The code fragment computes the kernel density estimate with the plug-in bandwidth matrix &lt;math&gt;\hat{\mathbf{H}}_{\operatorname{PI}} = \begin{bmatrix}0.052 &amp; 0.510 \\ 0.510 &amp; 8.882\end{bmatrix}.&lt;/math&gt; Again, the coloured contours correspond to the smallest region which contains the respective probability mass: red = 25%, orange + red = 50%, yellow + orange + red = 75%. To compute the SCV selector, &lt;code&gt;Hpi&lt;/code&gt; is replaced with &lt;code&gt;Hscv&lt;/code&gt;. This is not displayed here since it is mostly similar to the plug-in estimate for this example.

&lt;source lang="rsplus" style="overflow:auto;"&gt;
library(ks)
data(faithful)
H &lt;- Hpi(x=faithful)
fhat &lt;- kde(x=faithful, H=H)
plot(fhat, display="filled.contour2")
points(faithful, cex=0.5, pch=16)
&lt;/source&gt;

==Density estimation with a diagonal bandwidth matrix==

[[File:Bivariate example.png|thumb|250px|alt=Kernel density estimate with diagonal bandwidth for synthetic normal mixture data. |Kernel density estimate with diagonal bandwidth for synthetic normal mixture data.]]

We consider estimating the density of the Gaussian mixture
{{math|(4''π'')&lt;sup&gt;−1&lt;/sup&gt;&amp;thinsp;exp(−{{frac|2}} (''x''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt; + ''x''&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;))
+ (4''π'')&lt;sup&gt;−1&lt;/sup&gt;&amp;thinsp;exp(−{{frac|2}} ((''x''&lt;sub&gt;1&lt;/sub&gt; - 3.5)&lt;sup&gt;2&lt;/sup&gt; + ''x''&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;))}},
from 500 randomly generated points. We employ the Matlab routine  for
[http://www.mathworks.com/matlabcentral/fileexchange/17204 2-dimensional data].
The routine is an automatic bandwidth selection method specifically designed
for  a second order Gaussian kernel.&lt;ref&gt;{{Cite journal
 | author1 = Botev, Z.I. 
 | author2 = Grotowski, J.F. 
 | author3 = Kroese, D.P. 
 | title = Kernel density estimation via diffusion
 | journal = [[Annals of Statistics]]
 | volume =  38
 | issue = 5
 | pages = 2916–2957
 | year = 2010
 | doi = 10.1214/10-AOS799
| arxiv = 1011.2602}}
&lt;/ref&gt;
The figure shows the joint density estimate that results from using the automatically selected bandwidth.

'''Matlab script for the example'''

Type the following commands in Matlab after
[http://www.mathworks.com/matlabcentral/fileexchange/17204 downloading]
and saving the function kde2d.m
in the current directory.

&lt;source lang="matlab" style="overflow:auto;"&gt;
  clear all  
  % generate synthetic data
  data=[randn(500,2);
      randn(500,1)+3.5, randn(500,1);];
  % call the routine, which has been saved in the current directory 
  [bandwidth,density,X,Y]=kde2d(data);
  % plot the data and the density estimate
  contour3(X,Y,density,50), hold on
  plot(data(:,1),data(:,2),'r.','MarkerSize',5)
&lt;/source&gt;

==Alternative optimality criteria==
The MISE is the expected integrated ''L&lt;sub&gt;2&lt;/sub&gt;'' distance between the density estimate and the true density function ''f''. It is the most widely used, mostly due to its tractability and most software implement MISE-based bandwidth selectors. 
There are alternative optimality criteria, which attempt to cover cases where MISE is not an appropriate measure.&lt;ref name="simonoff1996" /&gt;{{rp|34–37,78}} The equivalent ''L&lt;sub&gt;1&lt;/sub&gt;'' measure, Mean Integrated Absolute Error, is

: &lt;math&gt;\operatorname{MIAE} (\mathbf{H}) = \operatorname{E}\, \int |\hat{f}_\mathbf{H} (\mathbf{x}) - f(\mathbf{x})| \, d\mathbf{x}.&lt;/math&gt;

Its mathematical analysis is considerably more difficult than the MISE ones. In practise, the gain appears not to be significant.&lt;ref&gt;{{cite journal | author1=Hall, P. | author2=Wand, M.P. | title=Minimizing L&lt;sub&gt;1&lt;/sub&gt; distance in nonparametric density estimation | journal = Journal of Multivariate Analysis | year=1988 | volume=26 | pages=59–88 | doi=10.1016/0047-259X(88)90073-5}}&lt;/ref&gt; The ''L&lt;sub&gt;∞&lt;/sub&gt;'' norm is the Mean Uniform Absolute Error

: &lt;math&gt;\operatorname{MUAE} (\mathbf{H}) = \operatorname{E}\, \operatorname{sup}_{\mathbf{x}} |\hat{f}_\mathbf{H} (\mathbf{x}) - f(\mathbf{x})|.&lt;/math&gt;
   
which has been investigated only briefly.&lt;ref&gt;{{cite journal | author1=Cao, R. | author2=Cuevas, A. | author3=Manteiga, W.G.| title=A comparative study of several smoothing methods in density estimation | journal = Computational Statistics and Data Analysis | year=1994 | volume=17 | issue=2 | pages=153–176 | doi=10.1016/0167-9473(92)00066-Z}}&lt;/ref&gt; Likelihood error criteria include those based on the Mean [[Kullback-Leibler distance]]

:  &lt;math&gt;\operatorname{MKL} (\mathbf{H}) = \int f(\mathbf{x}) \, \operatorname{log} [f(\mathbf{x})] \, d\mathbf{x} - \operatorname{E} \int f(\mathbf{x}) \, \operatorname{log} [\hat{f}(\mathbf{x};\mathbf{H})] \, d\mathbf{x}&lt;/math&gt;

and the Mean [[Hellinger distance]]

: &lt;math&gt;\operatorname{MH} (\mathbf{H}) = \operatorname{E}  \int (\hat{f}_\mathbf{H} (\mathbf{x})^{1/2} - f(\mathbf{x})^{1/2})^2 \, d\mathbf{x} .&lt;/math&gt;

The KL can be estimated using a cross-validation method, although KL cross-validation selectors can be sub-optimal even if it remains [[Consistent estimator|consistent]] for bounded density functions.&lt;ref&gt;{{cite journal | author=Hall, P. | title=On Kullback-Leibler loss and density estimation | journal=Annals of Statistics | volume=15 | issue=4 | year=1989 | pages=589–605 | doi=10.1214/aos/1176350606}}&lt;/ref&gt; MH selectors have been briefly examined in the literature.&lt;ref&gt;{{cite journal | author1=Ahmad, I.A. | author2=Mugdadi, A.R. | title=Weighted Hellinger distance as an error criterion for bandwidth selection in kernel estimation | journal=Journal of Nonparametric Statistics | volume=18 | issue=2 | year=2006 | pages=215–226 | doi=10.1080/10485250600712008}}&lt;/ref&gt; 
  
All these optimality criteria are distance based measures, and do not always correspond to more intuitive notions of closeness, so more visual criteria have been developed in response to this concern.&lt;ref&gt;{{cite journal | author1=Marron, J.S. | author2=Tsybakov, A. | title=Visual error criteria for qualitative smoothing | journal = Journal of the American Statistical Association | year=1996 | volume=90 | issue=430 | pages=499–507 | doi=10.2307/2291060 | jstor=2291060}}&lt;/ref&gt;

== Objective and data-driven kernel selection ==
[[File:Empirical Characteristic Function.jpg|alt=An x-shaped region of empirical characteristic function in Fourier space.|thumb|Demonstration of the filter function &lt;math&gt;I_{\vec{A}}(\vec{t})&lt;/math&gt;. The square of the empirical distribution function &lt;math&gt;|\hat{\varphi}|^2&lt;/math&gt; from ''N''=10,000 samples of the ‘transition distribution’ discussed in Section  3.2 (and shown in Fig. 4), for &lt;math&gt;|\hat{\varphi}|^2 \ge 4(N-1)N^{-2}&lt;/math&gt;. There are two color schemes present in this figure. The predominantly dark, multicolored colored ‘X-shaped’ region in the center corresponds to values of &lt;math&gt;|\hat{\varphi}|^2&lt;/math&gt; for the lowest contiguous hypervolume (the area containing the origin); the colorbar at right applies to colors in this region. The lightly-colored, monotone areas away from the first contiguous hypervolume correspond to additional contiguous hypervolumes (areas) with &lt;math&gt;|\hat{\varphi}|^2 \ge 4(N-1)N^{-2}&lt;/math&gt;. The colors of these areas are arbitrary and only serve to visually differentiate nearby contiguous areas from one another.]]
Recent research has shown that the kernel and its bandwidth can both be optimally and objectively chosen from the input data itself without making any assumptions about the form of the distribution.&lt;ref name=":0"&gt;{{Cite journal|last = Bernacchia|first = Alberto|last2 = Pigolotti|first2 = Simone|date = 2011-06-01|title = Self-consistent method for density estimation|url = http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2011.00772.x/abstract|journal = Journal of the Royal Statistical Society, Series B|language = en|volume = 73|issue = 3|pages = 407–422|doi = 10.1111/j.1467-9868.2011.00772.x|issn = 1467-9868|arxiv = 0908.3856}}&lt;/ref&gt;  The resulting kernel density estimate converges rapidly to the true probability distribution as samples are added: at a rate close to the &lt;math&gt;n^{-1}&lt;/math&gt; expected for parametric estimators.&lt;ref name=":0" /&gt;&lt;ref name=":1"&gt;{{Cite journal|last = O’Brien|first = Travis A.|last2 = Collins|first2 = William D.|last3 = Rauscher|first3 = Sara A.|last4 = Ringler|first4 = Todd D.|date = 2014-11-01|title = Reducing the computational cost of the ECF using a nuFFT: A fast and objective probability density estimation method|url = http://www.sciencedirect.com/science/article/pii/S016794731400173X|journal = Computational Statistics &amp; Data Analysis|volume = 79|pages = 222–234|doi = 10.1016/j.csda.2014.06.002}}&lt;/ref&gt;&lt;ref name=":22"&gt;{{Cite journal|last = O’Brien|first = Travis A.|last2 = Kashinath|first2 = Karthik|last3 = Cavanaugh|first3 = Nicholas R.|last4 = Collins|first4 = William D.|last5 = O’Brien|first5 = John P.|title = A fast and objective multidimensional kernel density estimation method: fastKDE|url = http://www.sciencedirect.com/science/article/pii/S0167947316300408|journal = Computational Statistics &amp; Data Analysis|volume = 101|pages = 148|doi = 10.1016/j.csda.2016.02.014|year = 2016}}&lt;/ref&gt;  This kernel estimator works for univariate and multivariate samples alike.  The optimal kernel is defined in Fourier space—as the optimal damping function &lt;math&gt;\hat{\psi_h}(\vec{t})&lt;/math&gt; (the Fourier transform of the kernel &lt;math&gt;\hat{K}(\vec{x})&lt;/math&gt; )-- in terms of the Fourier transform of the data &lt;math&gt;\hat{\varphi}(\vec{t})&lt;/math&gt;, the ''[[Characteristic function (probability theory)|empirical characteristic function]]'' (see [[Kernel density estimation]]):

&lt;math&gt;\hat{\psi_h}(\vec{t}) \equiv \frac{N}{2(N-1)} \left[ 1 + \sqrt{1 - \frac{4(N-1)}{N^2 |\hat{\varphi}(\vec{t})|^2}} I_{\vec{A}}(\vec{t}) \right]&lt;/math&gt; &lt;ref name=":22"/&gt;

&lt;math&gt;\hat{f}(x) = \frac{1}{(2\pi)^d} \int \hat\varphi(\vec{t})\psi_h(\vec{t}) e^{-i\vec{t} \cdot \vec{x}}d\vec{t}&lt;/math&gt;

where, ''N'' is the number of data points, ''d'' is the number of dimensions (variables), and &lt;math&gt;I_{\vec{A}}(\vec{t})&lt;/math&gt; is a filter that is equal to 1 for 'accepted frequencies' and 0 otherwise.  There are various ways to define this filter function, and a simple one that works for univariate or multivariate samples is called the 'lowest contiguous hypervolume filter'; &lt;math&gt;I_{\vec{A}}(\vec{t})&lt;/math&gt; is chosen such that the only accepted frequencies are a contiguous subset of frequencies surrounding the origin for which &lt;math&gt;|\hat{\varphi}(\vec{t})|^2 \ge 4(N-1)N^{-2}&lt;/math&gt; (see &lt;ref name=":22"/&gt; for a discussion of this and other filter functions).

Note that direct calculation of the ''empirical characteristic function'' (ECF) is slow, since it essentially involves a direct Fourier transform of the data samples.  However, it has been found that the ECF can be approximated accurately using a [[Non-uniform discrete Fourier transform|non-uniform fast Fourier transform]] (nuFFT) method,&lt;ref name=":1" /&gt;&lt;ref name=":22"/&gt; which increases the calculation speed by several orders of magnitude (depending on the dimensionality of the problem).  The combination of this objective KDE method and the nuFFT-based ECF approximation has been referred to as ''[https://bitbucket.org/lbl-cascade/fastkde fastKDE]'' in the literature.&lt;ref name=":22"/&gt;
[[File:FastKDE_example.jpg|alt=A demonstration of fastKDE relative to a sample PDF. (a) True PDF, (b) a good representation with fastKDE, and (c) a slightly blurry representation.|none|thumb|664x664px|A non-trivial mixture of normal distributions: (a) the underlying PDF, (b) a fastKDE estimate on 1,000,000 samples, and (c) a fastKDE estimate on 10,000 samples.]]

==See also==
* [[Kernel density estimation]]&amp;nbsp;&amp;ndash; univariate kernel density estimation.
* [[Variable kernel density estimation]]&amp;nbsp;&amp;ndash; estimation of multivariate densities using the kernel with variable bandwidth

==References==
{{Reflist}}

==External links==
* [http://www.mvstat.net/tduong/research mvstat.net] A collection of peer-reviewed articles of the mathematical details of multivariate kernel density estimation and their bandwidth selectors on an {{mono|mvstat.net}} web page. 
* [http://www.mathworks.com/matlabcentral/fileexchange/17204-kernel-density-estimation kde2d.m] A [[Matlab]] function for bivariate kernel density estimation.
* [http://libagf.sf.net libagf] A [[C++]] library for multivariate, [[variable bandwidth kernel density estimation]].
* [http://www.mathworks.com/matlabcentral/fileexchange/58312-kernel-density-estimator-for-high-dimensions akde.m] A [[Matlab]] m-file for multivariate, [[variable bandwidth kernel density estimation]]. 
* [https://github.com/thaines/helit/tree/master/ms helit] and [http://pythonhosted.org/PyQt-Fit/mod_kde.html pyqt_fit.kde Module] in the [https://pypi.python.org/packages/source/P/PyQt-Fit/PyQt-Fit-1.3.4.tar.gz PyQt-Fit package] are [[Python (programming language)|Python]] libraries for multivariate kernel density estimation.

[[Category:Estimation of densities]]
[[Category:Nonparametric statistics]]
[[Category:Computational statistics]]
[[Category:Multivariate statistics]]
[[Category:Articles with example MATLAB/Octave code]]</text>
      <sha1>iia9gyuvbaqe0lcgi8gcokb322xq7dh</sha1>
    </revision>
  </page>
  <page>
    <title>Neumann polynomial</title>
    <ns>0</ns>
    <id>24064208</id>
    <revision>
      <id>789258361</id>
      <parentid>787323548</parentid>
      <timestamp>2017-07-06T10:04:41Z</timestamp>
      <contributor>
        <username>Quebec99</username>
        <id>8019410</id>
      </contributor>
      <minor/>
      <comment>fixed reference</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4895">In mathematics, a '''Neumann polynomial''', introduced by [[Carl Neumann]] for the special case &lt;math&gt;\alpha=0&lt;/math&gt;, is a polynomial in 1/''z'' used to expand functions in term of [[Bessel function]]s.&lt;ref&gt;Abramowitz and Stegun, [http://www.math.sfu.ca/~cbm/aands/page_363.htm p. 363, 9.1.82] ff.&lt;/ref&gt;

The first few polynomials are
:&lt;math&gt;O_0^{(\alpha)}(t)=\frac 1 t,&lt;/math&gt;
:&lt;math&gt;O_1^{(\alpha)}(t)=2\frac {\alpha+1}{t^2},&lt;/math&gt;
:&lt;math&gt;O_2^{(\alpha)}(t)=\frac {2+\alpha}{t}+ 4\frac {(2+\alpha)(1+\alpha)}{t^3},&lt;/math&gt;
:&lt;math&gt;O_3^{(\alpha)}(t)=2\frac {(1+\alpha)(3+\alpha)}{t^2}+ 8\frac {(1+\alpha)(2+\alpha)(3+\alpha)}{t^4},&lt;/math&gt;
:&lt;math&gt;O_4^{(\alpha)}(t)=\frac {(1+\alpha)(4+\alpha)}{2t}+ 4\frac {(1+\alpha)(2+\alpha)(4+\alpha)}{t^3}+ 16\frac {(1+\alpha)(2+\alpha)(3+\alpha)(4+\alpha)}{t^5}.&lt;/math&gt;

A general form for the polynomial is
:&lt;math&gt;O_n^{(\alpha)}(t)= \frac{\alpha+n}{2\alpha} \sum_{k=0}^{\lfloor n/2\rfloor} (-1)^{n-k}\frac {(n-k)!} {k!} {-\alpha \choose n-k}\left(\frac 2 t \right)^{n+1-2k},&lt;/math&gt;

they have the generating function 
:&lt;math&gt;\frac{\left(\frac z 2 \right)^\alpha} {\Gamma(\alpha+1)} \frac 1 {t-z}= \sum_{n=0}O_n^{(\alpha)}(t) J_{\alpha+n}(z),&lt;/math&gt;
where ''J'' are [[Bessel function]]s.

To expand a function ''f'' in form 
:&lt;math&gt;f(z)=\sum_{n=0} a_n J_{\alpha+n}(z)\,&lt;/math&gt;
for &lt;math&gt;|z|&lt;c&lt;/math&gt;
compute
:&lt;math&gt;a_n=\frac 1 {2 \pi i} \oint_{|z|=c'} \frac{\Gamma(\alpha+1)}{\left(\frac z 2\right)^\alpha}f(z) O_n^{(\alpha)}(z)\mathrm d z,&lt;/math&gt;
where &lt;math&gt;c'&lt;c &lt;/math&gt; and ''c'' is the distance of the nearest singularity of &lt;math&gt;z^{-\alpha} f(z)&lt;/math&gt; from &lt;math&gt;z=0&lt;/math&gt;.

==Examples==
An example is the extension
:&lt;math&gt;\left(\tfrac{1}{2}z\right)^s= \Gamma(s)\cdot\sum_{k=0}(-1)^k J_{s+2k}(z)(s+2k){-s \choose k}&lt;/math&gt;
or the more general Sonine formula&lt;ref&gt;{{harvnb|Erdélyi|Magnus|Oberhettinger|Tricomi|1955}} II.7.10.1, p.64&lt;/ref&gt;
:&lt;math&gt;e^{i \gamma z}= \Gamma(s)\cdot\sum_{k=0}i^k C_k^{(s)}(\gamma)(s+k)\frac{J_{s+k}(z)}{\left(\frac z 2\right)^s}.&lt;/math&gt;
where &lt;math&gt;C_k^{(s)}&lt;/math&gt; is [[Gegenbauer polynomial|Gegenbauer's polynomial]]. Then,{{fact|date=September 2011}}{{or|date=September 2011}}
:&lt;math&gt;\frac{\left(\frac z 2\right)^{2k}}{(2k-1)!}J_s(z)= \sum_{i=k}(-1)^{i-k}{i+k-1\choose 2k-1}{i+k+s-1\choose 2k-1}(s+2i)J_{s+2i}(z),&lt;/math&gt;
:&lt;math&gt;\sum_{n=0} t^n J_{s+n}(z)= \frac{e^{\frac{t z}2}}{t^s} \sum_{j=0}\frac{\left(-\frac{z}{2t}\right)^j}{j!}\frac{\gamma \left(j+s,\frac{t z}{2}\right)}{\,\Gamma (j+s)}= \int_0^\infty e^{-\frac{z x^2}{2 t}}\frac {z x}{t} \frac{J_s(z\sqrt{1-x^2})}{\sqrt{1-x^2}^s}\,dx,&lt;/math&gt;
the [[confluent hypergeometric function]]
:&lt;math&gt;M(a,s,z)= \Gamma (s) \sum_{k=0}^\infty \left(-\frac{1}{t}\right)^k L_k^{(-a-k)}(t) \frac{J_{s+k-1}\left(2 \sqrt{t z}\right)}{(\sqrt{t z})^{s-k-1}}&lt;/math&gt;
and in particular
:&lt;math&gt;\frac{J_s(2 z)}{z^s}= \frac{4^s \Gamma\left(s+\frac12\right)}{\sqrt\pi}e^{2 i z}\sum_{k=0}L_k^{(-s-1/2-k)}\left(\frac{it}4\right)(4 i z)^k \frac{J_{2s+k}\left(2\sqrt{t z}\right)}{\sqrt{t z}^{2s+k}},&lt;/math&gt;
the index shift formula
:&lt;math&gt;\Gamma(\nu-\mu) J_\nu(z)= \Gamma(\mu+1) \sum_{n=0}\frac{\Gamma(\nu-\mu+n)}{n!\Gamma(\nu+n+1)} \left(\frac z 2\right)^{\nu-\mu+n}J_{\mu+n}(z),&lt;/math&gt;
the Taylor expansion (addition formula)
:&lt;math&gt;\frac{J_s\left(\sqrt{z^2-2uz}\right)}{\left(\sqrt{z^2-2uz}\right)^{\pm s}}= \sum_{k=0}\frac{(\pm u)^k}{k!}\frac{J_{s\pm k}(z)}{z^{\pm s}}&lt;/math&gt;
(cf.&lt;ref name="Zwillinger_2014"&gt;{{cite book |author-first1=Izrail Solomonovich |author-last1=Gradshteyn |author-link1=Izrail Solomonovich Gradshteyn |author-first2=Iosif Moiseevich |author-last2=Ryzhik |author-link2=Iosif Moiseevich Ryzhik |author-first3=Yuri Veniaminovich |author-last3=Geronimus |author-link3=Yuri Veniaminovich Geronimus |author-first4=Michail Yulyevich |author-last4=Tseytlin |author-link4=Michail Yulyevich Tseytlin |author-first5=Alan |author-last5=Jeffrey |editor-first1=Daniel |editor-last1=Zwillinger |editor-first2=Victor Hugo |editor-last2=Moll |translator=Scripta Technica, Inc. |title=Table of Integrals, Series, and Products |publisher=[[Academic Press, Inc.]] |date=2015 |orig-year=October 2014 |edition=8 |language=English |isbn=0-12-384933-0 &lt;!--|ISBN=978-0-12-384933-5 --&gt; |lccn=2014010276 &lt;!-- |url=http://books.google.com/books?id=NjnLAwAAQBAJ |access-date=2016-02-21--&gt;|title-link=Gradshteyn and Ryzhik |chapter=8.515.1. |page=944}}&lt;/ref&gt;{{verification failed|date=September 2011|reason=The referenced identity seems to be only superficially similar. It does not directly support the identity here.}}) and the expansion of the integral of the Bessel function
:&lt;math&gt;\int J_s(z)dz= 2 \sum_{k=0} J_{s+2k+1}(z)&lt;/math&gt;
are of the same type.

==See also==
*[[Bessel function]]
*[[Bessel polynomial]]
*[[Lommel polynomial]]
*[[Hankel transform]]
*[[Fourier–Bessel series]]
*[[Schläfli-polynomial]]

== Notes ==
&lt;references/&gt;

[[Category:Polynomials]]
[[Category:Special functions]]</text>
      <sha1>cyo6foewyx7s1w5aubsqrb3dlmsu1nc</sha1>
    </revision>
  </page>
  <page>
    <title>Number Theory Foundation</title>
    <ns>0</ns>
    <id>13053993</id>
    <revision>
      <id>847619701</id>
      <parentid>827881180</parentid>
      <timestamp>2018-06-26T16:48:08Z</timestamp>
      <contributor>
        <username>MaximeH-ULaval</username>
        <id>28426567</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="796">{{unreferenced|date=August 2012}}
The '''Number Theory Foundation''' ('''NTF''') is a [[non-profit]] organization based in the [[United States]] which supports research and conferences in the field of [[number theory]].

The NTF funds the [[Selfridge prize]] which is awarded at the [[ANTS (conference)|ANTS]] conferences, and is a recurring supporter of the [[West Coast Number Theory]] conference.
The NTF will supply a prize of $500 for a counterexample to [[John Selfridge#Selfridge's Conjecture about Primality Testing|Selfridge's Primality Testing Conjecture]].

==External links==
* [https://math.illinois.edu/research/faculty-research/number-theory/number-theory-foundation NTF web site]

[[Category:Number theory]]
[[Category:Foundations based in the United States]]


{{numtheory-stub}}</text>
      <sha1>ntf57ts157gow0j8q6fpfo1f8t5kbn0</sha1>
    </revision>
  </page>
  <page>
    <title>Ordinal numerical competence</title>
    <ns>0</ns>
    <id>10567836</id>
    <revision>
      <id>871624537</id>
      <parentid>867217676</parentid>
      <timestamp>2018-12-02T10:43:43Z</timestamp>
      <contributor>
        <username>Neils51</username>
        <id>16416757</id>
      </contributor>
      <minor/>
      <comment>/* Infants */   grammar/usage - 'objects' is a countable noun</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13768">In human [[developmental psychology]] or [[non-human primate experiments]], '''ordinal numerical competence''' or '''ordinal numerical knowledge''' is the ability to [[Counting|count]] objects in order and to understand the greater than and less than relationships between numbers. It has been shown that children as young as two can make some ordinal numerical decisions. There are studies indicating that some non-human primates, like [[chimpanzee]]s and [[rhesus monkey]]s have some ordinal numerical competence.

==In humans ==

=== Prenatal ===
There is no evidence to support prenatal ordinal numerical competence.  [[teratology|Teratogens]] such as stress&lt;ref&gt;{{cite journal|last=Tegethoff|first=Marion|author2=Naomi Greene, Jørn Olsen, Emmanuel Schaffner and Gunther Meinlschmidt|title=Stress During Pregnancy and Offspring Pediatrie Disease: A National Cohort Study|journal=Environmental Health Perspectives|date=November 2011|volume=119|issue=11|pages=1647–1652|doi=10.1289/ehp.1003253|pmid=21775267|pmc=3226491}}&lt;/ref&gt; can alter prenatal neural development, leading to diminished competence after birth.  Physical effects of teratogens are common, but endocrine effects are harder to measure.  These are the factors that influence neural development and by extension the development of ordinal numerical competence.  Premature birth is also a risk factor for developmental problems including reduced brain activity.&lt;ref&gt;{{cite journal|last=Duffy|first=Frank H.|author2=Heidelise Als and Gloria B. McAnulty|title=Behavioral and Electrophysiological Evidence for Gestational Age Effects in Healthy Preterm and Fullterm Infants Studied Two Weeks After Expected Due Date|journal=Child Development|date=August 1990|volume=61|issue=4|pages=1271–1286|doi=10.2307/1130893}}&lt;/ref&gt;  Brain activity is measured from outside the body with [[electroencephalography]].

=== Infants ===
There have been a vast number of studies done on infants and their knowledge of numbers.  Most research confirms that infants do in fact have a profound innate sense of number, both in abstract and finite ways.  Infants as young as 49 hours can accurately match up images with a certain number of objects, with sounds that contain the same number ("ra, ra, ra, ra") as the number of objects in the image.&lt;ref name=Izard&gt;{{cite journal|last=Izard|first=Veronique|author2=Coralie Sann |author3=Elizabeth S. Spelke |author4=Arlette Streri |author5=Charles R. Gallistel |title=Newborn Infants Perceive Abstract Numbers|journal=Proceedings of the National Academy of Sciences of the United States of America|year=2009|volume=106|issue=25|pages=10382–10385|doi=10.1073/pnas.0812142106|pmid=19520833|bibcode=2009PNAS..10610382I |pmc=2700913|url=https://dash.harvard.edu/bitstream/handle/1/10139591/Spelke_Newborn.pdf?sequence=1}}&lt;/ref&gt;  Because the sounds are abstract, or visibly there, we can see that infants as young as 49 hours have some abstract numerical sense as well as concrete numerical sense shown by their recognition of the image with the corresponding number of objects.&lt;ref name=Izard /&gt;  Similarly, infants around the age of 7 months can also match up images of random objects.&lt;ref name=Starkey&gt;{{cite journal|last=Starkey|first=Prentice|author2=Elizabeth S. Spelke and Rochel Gelman|title=Detection of Intermodal Numerical Correspondences by Human Infants|journal=Science|year=1983|volume=222|issue=4620|pages=179–181|doi=10.1126/science.6623069|pmid=6623069|last3=Gelman|first3=R|bibcode=1983Sci...222..179S}}&lt;/ref&gt;

Although children as young as 49 hours can match up the number of sounds with the number of objects, they can only do so at certain ratios.&lt;ref name=Izard /&gt;  When 1:3 ratios were used (4 sounds and 4 objects or 12 objects), around 90% of the infants paid more attention to the corresponding image thus showing their recognition.  However, when 1:2 ratios were used, only 68% of infants showed recognition of the correct corresponding image.&lt;ref name=Izard /&gt;  This tells us that although infants can recognize corresponding numbers of sounds and objects, the two images of objects must be visibly different - one must have a much larger number of objects, or a much smaller number of objects.&lt;ref name=Izard /&gt;

Although there has to be a stark difference in the choices for infants to recognize the correct matching set of numbers (1:3 vs 1:2), this seems to prove that infants have an innate numerical sense, but it may not be the same numerical sense as older children.  Around the age of three and a half years children lose some of their numerical sense.  Whereas children younger than three can recognize that four pebbles spread out in a line is less than six pebbles scrunched together in a line, children around the age of three and a half mysteriously lose this ability.&lt;ref name=Mehler&gt;{{cite journal|last=Mehler|first=Jaques|author2=Thomas G. Bever|title=Cognitive Capacity of Very Young Children|journal=Science|year=1967|volume=158|pages=141–142|doi=10.1126/science.158.3797.141|pmid=6054816|issue=3797|bibcode=1967Sci...158..141M}}&lt;/ref&gt;  Researchers believe that this is because children around this age begin to rely heavily on the physical properties of the world and objects within it,&lt;ref name=Mehler /&gt; such that longer equals more.  Although the ability to recognize that six pebbles closely lined up together is more than four pebbles spread out farther from one another goes away around that age, it comes back around four years of age when children begin to count.&lt;ref name=Mehler /&gt;

=== Adults ===
Both behavioral research and brain-imaging research show distinct differences in the way "exact" arithmetic and "approximate" arithmetic are processed.  Exact arithmetic is information that is precise and follows specific rules and patterns such as multiplication tables or geometric formulas, and approximate arithmetic is a general comparison between numbers such as the comparisons of greater than or less than.  Research shows that exact arithmetic is language-based and processed in the left inferior frontal lobe.  Approximate arithmetic is processed much differently in a different part of the brain.  Approximate arithmetic is processed in the bilateral areas of the parietal lobes.  This part of the brain processes visual information to understand how objects are spatially related to each other, for example, understanding that 10 of something is more than two of something.  This difference in brain function can create a difference in how we experience certain types of arithmetic.  Approximate arithmetic can be experienced as intuitive and exact arithmetic experienced as recalled knowledge.&lt;ref name="dehaene"&gt;{{cite journal|last=Dehaene|first=S.|author2=E. Spelke |author3=P. Pinel |author4=R. Stanescu |author5=S. Tsivkin |title=Sources of Mathematical Thinking: Behavioral and Brain-Imaging Evidence|journal=Science, New Series|date=7 May 1999|volume=284|issue=5416|pages=970–974|doi=10.1126/science.284.5416.970 |pmid=10320379|bibcode=1999Sci...284..970D}}&lt;/ref&gt;

The conclusions from behavioral research and brain-imaging research are supported by observations of patients with injuries to certain parts of the brain.  People with left parietal injuries can lose the ability to understand quantities of things, but keep at least some ability to do exact arithmetic, such as multiplication.&lt;ref name=Dehaene2&gt;{{cite journal|last=Dehaene|first=S|author2=L. Cohen|journal=Cortex|year=1997|volume=33|issue=2|pages=219–50|pmid=9220256|title=Cerebral pathways for calculation: Double dissociation between rote verbal and quantitative knowledge of arithmetic|doi=10.1016/s0010-9452(08)70002-9}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Benton|first=A.L.|journal=Arch. Neurol.|year=1992|volume=49|pages=445|doi=10.1001/archneur.1992.00530290027007|title=Gerstmann's Syndrome}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Takayama|first=Y.|author2=M. Sugishita |author3=I. Akiguchi |author4=J. Kimura |journal=Arch. Neurol.|year=1994|volume=51|pages=286|doi=10.1001/archneur.1994.00540150084021 |title=Isolated Acalculia due to Left Parietal Lesion}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Delazer|first=M.|author2=T. Benke|journal=Cortex|year=1997|volume=33|issue=4|pages=697–710|pmid=9444471|title=Arithmetic facts without meaning|doi=10.1016/s0010-9452(08)70727-5}}&lt;/ref&gt;   People with left-hemisphere brain damage can lose the ability to do exact arithmetic, but keep a sense of quantity, including the ability to compare larger and smaller numbers.&lt;ref name=Dehaene2 /&gt;   This information confirms that distinct parts of the brain are used to know and use approximate and exact arithmetic.&lt;ref name="dehaene" /&gt;

Various researchers suggest that the processing of approximate arithmetic could be related to the numerical abilities that have been independently established in various animal species&lt;ref&gt;{{cite book|last=Boysen|first=S.T. and E.J. Capaldi|title=The Development of Numerical Competence: Animal and Human Models|year=1993|publisher=Erlbaum|location=Hillsdale, NJ}}&lt;/ref&gt;&lt;ref name="Brannon"&gt;{{cite journal|last=Brannon|first=E.M.|author2=H.S. Terrace|journal=Science|year=1998|volume=282|issue=5389|pages=746–9|pmid=9784133|title=Ordering of the numerosities 1 to 9 by monkeys|doi=10.1126/science.282.5389.746|bibcode=1998Sci...282..746B}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Dehaene|first=S.|author2=G. Dehaene-Lambertz |author3=L. Cohen |journal=Trends in Neurosciences|year=1998|volume=21|pages=355–61|doi=10.1016/s0166-2236(98)01263-6|pmid=9720604|title=Abstract representations of numbers in the animal and human brain}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Gallistel|first=C.R.|journal=Annual Review of Psychology|year=1989|volume=40|pages=155–89|pmid=2648974|title=Animal cognition: The representation of space, time and number|doi=10.1146/annurev.ps.40.020189.001103}}&lt;/ref&gt;  and in preverbal human infants.&lt;ref&gt;{{cite journal|last=Wynn|first=K.|journal=Trends in Cognitive Sciences|year=1998|volume=2|pages=296–303|doi=10.1016/s1364-6613(98)01203-0|title=Psychological foundations of number: numerical competence in human infants}}&lt;/ref&gt;   This may mean that approximate arithmetic is an adaptive train that humans developed through evolution.&lt;ref&gt;{{cite book|last=Dehaene|first=S.|title=The Number Sense|year=1997|publisher=Oxford University Press|location=New York|isbn=0-19-513240-8}}&lt;/ref&gt;  The combination of this potential evolutionary trait and language-based exact arithmetic may be the reason that humans are able to do advanced mathematics like physics.&lt;ref name="dehaene" /&gt;

== In non-humans ==
{{further|Number sense in animals}}

Animals share a non-verbal system for representing number as analogue magnitudes.&lt;ref&gt;Brannon, 2005; Brannon &amp; Terrace, 1998-2000; Cantlon &amp; Brannon, 2005; Feigenson, Dehaene, &amp; Spelke, 2004; Gelman &amp;Gallistel, 2004; Nieder, Freedman, &amp; Miller, 2002; Nieder &amp; Miller, 2003&lt;/ref&gt;
Animals have been known to base their rationality on [[Weber’s Law]].  This historically important psychological law quantifies the perception of change in a given stimulus.  The law states that the change in a stimulus that will be just noticeable is a constant ratio of the original stimulus.  Weber’s Law describes discriminability between values based on perceptual continua such as line length, brightness, and weight.&lt;ref&gt;http://www.britannica.com/EBchecked/topic/638610/Webers-law&lt;/ref&gt;

=== Rhesus monkeys ===
Studies of rhesus monkeys' foraging decisions indicate that animals spontaneously, and without training, exhibit rudimentary numerical abilities. Most animals can determine numbers in the values 1 through 9, but recent experiments have discovered that rhesus monkeys can quantify values from 1 to 30.  Monkeys' numerical discrimination capacity is imposed by the ratio of the values compared, rather than absolute set size.&lt;ref name="Brannon" /&gt;
This computation process focuses around Weber’s Law and the expectation violation procedure.  This suggests that rhesus monkeys have access to a spontaneous system of representation, which encodes the numerical differences between sets of one, two and three objects, and contrasts three objects from either four or five objects as well. These representations indicate the semantics of an encoded natural language.  These encoded natural languages are also seen in experiments with many animals including pigeons and rats.

=== Rats and pigeons ===
Experiments have shown that rats are able to be trained to press one lever after hearing two bursts of white noise, then press another lever after four bursts of white noise.  The interburst interval is varied between trials so the discrimination is based on number of bursts and not time duration of the sequence.  Studies show that rats as well as pigeons learned to make different responses to both short and long durations of signals.  During testing, rats exhibited a pattern called ''break-run-break''; when it came to responding after a stint of little to no response, they would suddenly respond in high frequency, then return to little or no response activity.&lt;ref name=Roberts&gt;{{cite journal|last=Roberts|first=William A.|title=Simultaneous Numerical and Temporal Processing in the Pigeon|journal=Current Directions in Psychological Science|date=April 1995|volume=4|issue=2|pages=47–51|jstor=20182325|doi=10.1111/1467-8721.ep10771008}}&lt;/ref&gt; 
Data suggests that rats and pigeons are able to process time and number information at the same time.  The Mode Control Model shows that these animals can process number and time information by transmission pulses to accumulators controlled by switches that operate different modes.&lt;ref name=Roberts /&gt;

==References==
{{Reflist}}

==External links==

[[Category:Developmental psychology]]
[[Category:Numeral systems]]</text>
      <sha1>356qxzyfr2loup1fcecxv5cnv0zkidy</sha1>
    </revision>
  </page>
  <page>
    <title>Parent function</title>
    <ns>0</ns>
    <id>38912269</id>
    <revision>
      <id>865538964</id>
      <parentid>865538945</parentid>
      <timestamp>2018-10-24T15:03:01Z</timestamp>
      <contributor>
        <username>CASSIOPEIA</username>
        <id>31051948</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/165.111.3.145|165.111.3.145]] ([[User talk:165.111.3.145|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2629">{{expert-subject|date=March 2013|reason=The definition is not precise, and lacks authoritative references|talk=Ambiguous definition}}

In mathematics, a '''parent function''' is the simplest [[function (mathematics)|function]] of a family of functions that preserves the definition (or shape) of the entire family. For example, for the family of [[quadratic equation|quadratic functions]] having the general form
:&lt;math&gt; y = ax^2 + bx + c\,,&lt;/math&gt;
the simplest function is
:&lt;math&gt; y = x^2&lt;/math&gt;.
This is therefore the parent function of the family of quadratic equations.

For linear and quadratic functions, the graph of any function can be obtained from the graph of the parent function by simple translations and stretches parallel to the axes. For example, the graph of ''y''&amp;nbsp;=&amp;nbsp;''x''{{sup|2}}&amp;nbsp;−&amp;nbsp;4''x''&amp;nbsp;+&amp;nbsp;7 can be obtained from the graph of ''y''&amp;nbsp;=&amp;nbsp;''x''{{sup|2}} by translating +2 units along the X axis and +3 units along Y axis. This is because the equation can also be written as ''y''&amp;nbsp;−&amp;nbsp;3&amp;nbsp;=&amp;nbsp;(''x''&amp;nbsp;−&amp;nbsp;2){{sup|2}}.

For many trigonometric functions, the parent function is usually a basic sin(''x''), cos(''x''), or tan(''x''). For example, the graph of ''y''&amp;nbsp;=&amp;nbsp;''A''&amp;nbsp;sin(''x'')&amp;nbsp;+&amp;nbsp;''B''&amp;nbsp;cos(''x'') can be obtained from the graph of ''y''&amp;nbsp;=&amp;nbsp;sin(''x'') by translating it through an angle α along the positive X axis (where tan(α)&amp;nbsp;=&amp;nbsp;{{frac|''A''|''B''}}), then stretching it parallel to the Y axis using a stretch factor ''R'', where ''R''{{sup|2}}&amp;nbsp;=&amp;nbsp;''A''{{sup|2}}&amp;nbsp;+&amp;nbsp;''B''{{sup|2}}. This is because ''A''&amp;nbsp;sin(''x'')&amp;nbsp;+&amp;nbsp;''B''&amp;nbsp;cos(''x'') can be written as ''R''&amp;nbsp;sin(''x''−α) (see [[List of trigonometric identities]]).

The concept of parent function is less clear for polynomials of higher power because of the extra turning points, but for the family of ''n''-degree [[polynomial]] functions for any given ''n'', the parent function is sometimes taken as ''x''{{sup|''n''}}, or, to simplify further, ''x''{{sup|''2''}} when ''n'' is even and ''x''{{sup|''3''}} for odd ''n''.  [[Stationary point|Turning points]] may be established by [[Derivative|differentiation]] to provide more detail of the graph.

== See also ==
* [[Curve sketching]]

== External links ==
* [http://www.virtualnerd.com/algebra-2/linear-equations-functions/transformations-parent-functions/parent-functions/parent-function-definition Video explanation] at VirtualNerd.com

[[Category:Curves]]
[[Category:Elementary algebra]]
[[Category:Functions and mappings]]

{{math-stub}}</text>
      <sha1>rt7sljadnktquta6bfkml6hxtu3wss0</sha1>
    </revision>
  </page>
  <page>
    <title>Predicative programming</title>
    <ns>0</ns>
    <id>30251309</id>
    <revision>
      <id>790773228</id>
      <parentid>726491813</parentid>
      <timestamp>2017-07-16T00:03:48Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* top */LaTeX spacing clean up, replaced: \,\!&lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1626">'''Predicative programming''' is a methodology for program [[specification language|specification]] and [[program refinement|refinement]]. The central idea of predicative programming is that each specification is a predicate (generally written as a boolean expression) that is true of acceptable behaviours and false of unacceptable behaviours. It follows that refinement is reversed implication universally quantified over behaviours:
:&lt;math&gt;(P\sqsubseteq Q)\equiv (\forall b\cdot Q\Rightarrow P)&lt;/math&gt;
Commands in a programming language are considered to be a special case of specifications—special only because they are compilable. For example, in an environment where the program variables are &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;y&lt;/math&gt;, and &lt;math&gt;z&lt;/math&gt;, the command &lt;math&gt;x:=y+1&lt;/math&gt; is considered equivalent to the predicate (represented here by a boolean expression)
:&lt;math&gt;x' = y+1 \land y'=y \land z'=z&lt;/math&gt;
in which &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;y&lt;/math&gt;, and &lt;math&gt;z&lt;/math&gt; represent the initial values of the program variables and  &lt;math&gt;x'&lt;/math&gt;, &lt;math&gt;y'&lt;/math&gt;, and &lt;math&gt;z'&lt;/math&gt; represent the final values of the program variables. Thus
:&lt;math&gt;x' &gt; y \sqsubseteq x := y+1&lt;/math&gt;

== Bibliography ==
* E.C.R. Hehner, ''a Practical Theory of Programming'', Springer-Verlag 1993. Most recent edition online at [http://www.cs.toronto.edu/~hehner/aPToP a Practical Theory of Programming].

== External links ==

* [http://www.cs.toronto.edu/~hehner/publist.html Publications by [[Eric Hehner]].]

[[Category:Formal methods]]
[[Category:Formal specification languages]]
[[Category:Logical calculi]]


{{formalmethods-stub}}</text>
      <sha1>ka5z2t1kbifl42p3ojbo8c1p2qqed4c</sha1>
    </revision>
  </page>
  <page>
    <title>Probability bounds analysis</title>
    <ns>0</ns>
    <id>34450103</id>
    <revision>
      <id>863616352</id>
      <parentid>852340399</parentid>
      <timestamp>2018-10-11T22:23:55Z</timestamp>
      <contributor>
        <username>Michipedian</username>
        <id>18152852</id>
      </contributor>
      <comment>boldface fix</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25874">{{Use dmy dates|date=April 2013}}
'''Probability bounds analysis''' ('''PBA''') is a collection of methods of uncertainty propagation for making qualitative and quantitative calculations in the face of uncertainties of various kinds. It is used to project partial information about random variables and other quantities through mathematical expressions. For instance, it computes sure bounds on the distribution of a sum, product, or more complex function, given only sure bounds on the distributions of the inputs. Such bounds are called [[probability box]]es, and constrain [[cumulative distribution function|cumulative probability distributions]] (rather than [[probability density function|densities]] or [[probability mass function|mass functions]]).

This [[upper and lower bounds|bounding]] approach permits analysts to make calculations without requiring overly precise assumptions about parameter values, dependence among variables, or even distribution shape. Probability bounds analysis is essentially a combination of the methods of standard [[interval analysis]] and classical [[probability theory]]. Probability bounds analysis gives the same answer as interval analysis does when only range information is available. It also gives the same answers as [[Monte Carlo simulation]] does when information is abundant enough to precisely specify input distributions and their dependencies. Thus, it is a generalization of both interval analysis and probability theory.

The diverse methods comprising probability bounds analysis provide algorithms to evaluate mathematical expressions when there is uncertainty about the input values, their dependencies, or even the form of mathematical expression itself. The calculations yield results that are guaranteed to enclose all possible distributions of the output variable if the input [[probability box|p-boxes]] were also sure to enclose their respective distributions. In some cases, a calculated p-box will also be best-possible in the sense that
the bounds could be no tighter without excluding some of the possible
distributions.

P-boxes are usually merely bounds on possible distributions. The bounds often also enclose distributions that are not themselves possible. For instance, the set of probability distributions that could result from adding random values without the independence assumption from two (precise) distributions is generally a proper [[subset]] of all the distributions enclosed by the p-box computed for the sum. That is, there are distributions within the output p-box that could not arise under any dependence between the two input distributions. The output p-box will, however, always contain all distributions that are possible, so long as the input p-boxes were sure to enclose their respective underlying distributions. This property often suffices for use in [[Probabilistic risk assessment|risk analysis]] and other fields requiring calculations under uncertainty.

==History of bounding probability==
The idea of bounding probability has a very long
tradition throughout the history of probability theory. Indeed, in 1854 [[George Boole]] used the notion of interval bounds on probability in his [[The Laws of Thought]].&lt;ref name="BOOLE1854"&gt;{{cite book
| last = Boole
| first = George
| title = An Investigation of the Laws of Thought on which are Founded the Mathematical Theories of Logic and Probabilities
| publisher = Walton and Maberly
| year = 1854
| location = London
| url = http://www.gutenberg.org/etext/15114
}}&lt;/ref&gt;&lt;ref name=Hailperin86&gt;{{cite book
| last = Hailperin
| first = Theodore
| title = Boole's Logic and Probability
| publisher = North-Holland
| year = 1986
| location = Amsterdam
| isbn = 0-444-11037-2  }}
&lt;/ref&gt; Also dating from the latter half of the 19th century, the [[Chebyshev inequality|inequality]] attributed to [[Chebyshev]] described bounds on a distribution when only the mean and
variance of the variable are known, and the related [[Markov inequality|inequality]] attributed to [[Andrey Markov|Markov]] found bounds on a
positive variable when only the mean is known.
[[Henry E. Kyburg, Jr.|Kyburg]]&lt;ref name="kyburg99"&gt;Kyburg, H.E., Jr. (1999). [http://www.sipta.org/documentation/interval_prob/kyburg.pdf Interval valued probabilities]. SIPTA Documention on Imprecise Probability.&lt;/ref&gt; reviewed the history
of interval probabilities and traced the development of the critical ideas through the 20th century, including the important notion of incomparable probabilities favored by [[John Maynard Keynes|Keynes]].
Of particular note is [[Maurice René Fréchet|Fréchet]]'s derivation in the 1930s of bounds on calculations involving total probabilities without
dependence assumptions. Bounding probabilities has continued to the
present day (e.g., Walley's theory of [[imprecise probability]].&lt;ref name="WALLEY1991"&gt;{{cite book
| last = Walley
| first = Peter
| title = Statistical Reasoning with Imprecise Probabilities
| publisher = Chapman and Hall
| year = 1991
| location = London
| isbn = 0-412-28660-2 }}&lt;/ref&gt;)

The methods of probability bounds analysis that could be routinely used in
risk assessments were developed in the 1980s. Hailperin&lt;ref name=Hailperin86 /&gt; described a computational scheme for bounding logical calculations extending the ideas of Boole. Yager&lt;ref name=Yager&gt;Yager, R.R. (1986). Arithmetic and other operations on Dempster–Shafer structures. ''International Journal of Man-machine Studies'' '''25''': 357–366.&lt;/ref&gt; described the elementary procedures by which bounds on [[convolution of probability distributions|convolutions]] can be computed under an assumption of independence. At about the same time, Makarov,&lt;ref name=Makarov&gt;Makarov, G.D. (1981). Estimates for the distribution function of a sum of two random variables when the marginal distributions are fixed.  ''Theory of Probability and Its Applications'' '''26''': 803–806.&lt;/ref&gt; and independently, Rüschendorf&lt;ref&gt;Rüschendorf, L. (1982). Random variables with maximum sums. ''Advances in Applied Probability'' '''14''': 623–632.&lt;/ref&gt; solved the problem, originally posed by [[Kolmogorov]], of how to find the upper and lower bounds for the probability distribution of a sum of random variables whose marginal distributions, but not their joint distribution, are known. Frank et al.&lt;ref name=Franketal87&gt;Frank, M.J., R.B. Nelsen and B. Schweizer (1987). Best-possible bounds for the distribution of a sum—a problem of Kolmogorov. ''Probability Theory and Related Fields'' '''74''': 199–211.&lt;/ref&gt; generalized the result of Makarov and expressed it in terms of [[Copula (probability theory)|copulas]]. Since that time, formulas and algorithms for sums have been generalized and extended to differences, products, quotients and other binary and unary functions under various dependence assumptions.&lt;ref name=WilliamsonDowns&gt;Williamson, R.C., and T. Downs (1990). Probabilistic arithmetic I: Numerical methods for calculating convolutions and dependency bounds. ''International Journal of Approximate Reasoning'' '''4''': 89–158.&lt;/ref&gt;&lt;ref name=Fersonetal03&gt;Ferson, S., V. Kreinovich, L. Ginzburg, D.S. Myers, and K. Sentz. (2003). [http://www.ramas.com/unabridged.zip ''Constructing Probability Boxes and Dempster–Shafer Structures''] {{webarchive|url=https://web.archive.org/web/20110722073459/http://www.ramas.com/unabridged.zip |date=22 July 2011 }}. SAND2002-4015. Sandia National Laboratories, Albuquerque, NM.&lt;/ref&gt;&lt;ref&gt;Berleant, D. (1993). Automatically verified reasoning with both intervals and probability density functions. ''Interval Computations'' '''1993 (2) ''': 48–70.&lt;/ref&gt;&lt;ref&gt;Berleant, D., G. Anderson, and C. Goodman-Strauss (2008). Arithmetic on bounded families of distributions: a DEnv algorithm tutorial. Pages 183–210 in ''Knowledge Processing with Interval and Soft Computing'', edited by C. Hu, R.B. Kearfott, A. de Korvin and V. Kreinovich, Springer ({{isbn|978-1-84800-325-5}}).&lt;/ref&gt;&lt;ref name=BerleantGoodmanStrauss&gt;Berleant, D., and C. Goodman-Strauss (1998). Bounding the results of arithmetic operations on random variables of unknown dependency using intervals. ''Reliable Computing'' '''4''': 147–165.&lt;/ref&gt;&lt;ref name=Fersonetal04&gt;Ferson, S., R. Nelsen, J. Hajagos, D. Berleant, J. Zhang, W.T. Tucker, L. Ginzburg and W.L. Oberkampf (2004). [http://www.ramas.com/depend.pdf ''Dependence in Probabilistic Modeling, Dempster–Shafer Theory, and Probability Bounds Analysis'']. Sandia National Laboratories, SAND2004-3072, Albuquerque, NM.&lt;/ref&gt;  &lt;!--

It is possible to mix very different kinds of knowledge together in a bounding analysis. For instance,

In some cases, we may not know whether a quantity varies or is a fixed constant. Even if we know a quantity to be a constant, we may not know its value precisely. And, even if we know a quantity to be randomly varying, we may not know the statistical distribution that governs that variation, or the stochastic dependence it may have with other quantities.

In some cases, the shape or family of the distribution of a quantity may be known from mechanistic or physics-based arguments, but its parameters may be in doubt. In others cases, some summary statistical characteristics of a quantity may have been recorded in the scientific literature, but other details and the original data are unavailable so that we do not know the family of the statistical distribution even though we know some of its parameters. In some cases, there may be sample data available but the small sample may be size, or the data values may have non-negligible measurement uncertainty.

Further suppose that sparse data were used to form the 95% confidence limits for the distribution of ''C''. And the variable ''D'' is known to be well described by a precise distribution.

Probability bounds analysis includes the important special case of [[dependency bounds analysis]]&lt;&lt;__Williamson and Downs&gt;&gt; to compute bounds on the cumulative distribution of a function of random variables when only the marginal distributions of the variables are known, which is a problem originally posed by [[Kolmogorov]].
--&gt;

==Arithmetic expressions==
Arithmetic expressions involving operations such as additions, subtractions, multiplications, divisions, minima, maxima, powers, exponentials, logarithms, square roots, absolute values, etc., are commonly used in [[Probabilistic risk assessment|risk analyses]] and uncertainty modeling. Convolution is the operation of finding the probability distribution of a sum of independent random variables specified by probability distributions. We can extend the term to finding distributions of other mathematical functions (products, differences, quotients, and more complex functions) and other assumptions about the intervariable dependencies. There are convenient algorithms for computing these generalized convolutions under a variety of assumptions about the dependencies among the inputs.&lt;ref name=Yager /&gt;&lt;ref name=WilliamsonDowns /&gt;&lt;ref name=Fersonetal03 /&gt;&lt;ref name=Fersonetal04 /&gt;

===Mathematical details===
Let &lt;math&gt;\mathbb{D}&lt;/math&gt; denote the space of distribution functions on the [[real number]]s &lt;math&gt;\R,&lt;/math&gt; i.e., 

:&lt;math&gt; \mathbb{D} = \{ D | D: \R \to [0,1], D(x) \leq D(y) \text{ for all } x &lt; y \}.&lt;/math&gt;

A p-box is a quintuple 

:&lt;math&gt;\left \{ \overline{F}, \underline{F}, m, v, \mathbf{F} \right \},&lt;/math&gt;

where &lt;math&gt;\overline{F}, \underline{F} \in \mathbb{D}, m, v&lt;/math&gt; are real intervals, and &lt;math&gt;\mathbf{F} \subset \mathbb{D}.&lt;/math&gt; This quintuple denotes the set of distribution functions &lt;math&gt;F \in \mathbf{F} \subset \mathbb{D}&lt;/math&gt; such that:

:&lt;math&gt;\begin{align}
\forall x \in \R: \qquad &amp;\overline{F}(x) \leq F(x) \leq \underline{F}(x) \\[6pt]
&amp;\int_\R x dF(x) \in m &amp;&amp; \text{expectation condition} \\
&amp;\int_\R x^2 dF(x) - \left ( \int_\R x dF(x) \right )^2 \in v &amp;&amp; \text{variance condition}
\end{align}&lt;/math&gt;

If a function satisfies all the conditions above it is said to be ''inside'' the p-box. In some cases, there may be no information about the moments or distribution family other than what is encoded in the two distribution functions that constitute the edges of the p-box. Then the quintuple representing the p-box &lt;math&gt;\{B_1, B_2, [-\infty, \infty], [0, \infty], \mathbb{D}\}&lt;/math&gt; can be denoted more compactly as [''B''&lt;sub&gt;1&lt;/sub&gt;, ''B''&lt;sub&gt;2&lt;/sub&gt;]. This notation harkens to that of intervals on the real line, except that the endpoints are distributions rather than points.

The notation &lt;math&gt;X \sim F&lt;/math&gt; denotes the fact that &lt;math&gt;X \in \R&lt;/math&gt; is a random variable governed by the distribution function ''F'', that is, 

:&lt;math&gt;\begin{cases} F: \R \to [0,1] \\ x \mapsto \Pr (X \leq x) \end{cases}&lt;/math&gt;

Let us generalize the tilde notation for use with p-boxes. We will write ''X'' ~ ''B'' to mean that ''X'' is a random variable whose distribution function is unknown except that it is inside ''B''. Thus, ''X'' ~ ''F'' ∈ ''B'' can be contracted to X ~ B without mentioning the distribution function explicitly.

If ''X'' and ''Y'' are independent random variables with distributions ''F'' and ''G'' respectively, then ''X'' + ''Y'' = ''Z'' ~ ''H'' given by

:&lt;math&gt;H(z) = \int_{z=x+y} F(x) G(y) dz = \int_{\R} F(x) G(z-x) dx = F * G.&lt;/math&gt;

This operation is called a [[convolution]] on ''F'' and ''G''. The analogous operation on p-boxes is straightforward for sums. Suppose

:&lt;math&gt;X \sim A = [A_1, A_2], \quad \text{and} \quad Y \sim B = [B_1, B_2].&lt;/math&gt;

If ''X'' and ''Y'' are stochastically independent, then the distribution of ''Z'' = ''X'' + ''Y'' is inside the p-box

:&lt;math&gt; \left [A_1 * B_1, A_2 * B_2 \right ].&lt;/math&gt;

Finding bounds on the distribution of sums ''Z'' = ''X'' + ''Y'' ''without making any assumption about the dependence'' between ''X'' and ''Y'' is actually easier than the problem assuming independence. Makarov&lt;ref name=Makarov/&gt;&lt;ref name=Franketal87/&gt;&lt;ref name=WilliamsonDowns/&gt; showed that

:&lt;math&gt;Z \sim \left [ \sup_{z=x+y} \max ( F(x) +G(y) -1, 0), \inf_{z=x+y} \min (F(x)+G(y), 1) \right ]&lt;/math&gt;

These bounds are implied by the [[copula (probability theory)#Fr.C3.A9chet.E2.80.93Hoeffding copula bounds|Fréchet–Hoeffding]] [[copula (probability theory)|copula]] bounds. The problem can also be solved using the methods of [[mathematical programming]].&lt;ref name=BerleantGoodmanStrauss /&gt;

The convolution under the intermediate assumption that ''X'' and ''Y'' have [[positive quadrant dependence|positive dependence]] is likewise easy to compute, as is the convolution under the extreme assumptions of [[Comonotonicity|perfect positive]] or [[countermonotonicity|perfect negative]] dependency between ''X'' and ''Y''.&lt;ref name=Fersonetal04 /&gt;

Generalized convolutions for other operations such as subtraction, multiplication, division, etc., can be derived using transformations. For instance, p-box subtraction ''A'' − ''B'' can be defined as ''A'' + (−''B''), where the negative of a p-box ''B'' = [''B''&lt;sub&gt;1&lt;/sub&gt;, ''B''&lt;sub&gt;2&lt;/sub&gt;] is [''B''&lt;sub&gt;2&lt;/sub&gt;(−''x''), ''B''&lt;sub&gt;1&lt;/sub&gt;(−''x'')].

==Logical expressions==
Logical or [[Boolean function|Boolean expressions]] involving [[logical conjunction|conjunctions]] ([[AND gate|AND]] operations), [[logical disjunction|disjunctions]] ([[OR gate|OR]] operations), exclusive disjunctions, equivalences, conditionals, etc. arise in the analysis of fault trees and event trees common in risk assessments. If the probabilities of events are characterized by intervals, as suggested by [[George Boole|Boole]]&lt;ref name="BOOLE1854" /&gt; and [[John Maynard Keynes|Keynes]]&lt;ref name="kyburg99" /&gt; among others, these binary operations are straightforward to evaluate. For example, if the probability of an event A is in the interval P(A) = ''a'' = [0.2, 0.25], and the probability of the event B is in P(B) = ''b'' = [0.1, 0.3], then the probability of the [[logical conjunction|conjunction]] is surely in the interval
: &amp;nbsp;&amp;nbsp;P(A &amp; B) = ''a'' × ''b''
:::: = [0.2, 0.25] × [0.1, 0.3]
:::: = [0.2 × 0.1, 0.25 × 0.3]
:::: = [0.02, 0.075]
so long as A and B can be assumed to be independent events. If they are not independent, we can still bound the conjunction using the classical [[Frechet inequalities|Fréchet inequality]]. In this case, we can infer at least that the probability of the joint event A &amp; B is surely within the interval
: &amp;nbsp;&amp;nbsp;P(A &amp; B) = env(max(0, ''a''+''b''−1), min(''a'', ''b''))
:::: = env(max(0, [0.2, 0.25]+[0.1, 0.3]−1), min([0.2, 0.25], [0.1, 0.3]))
:::: = env([max(0, 0.2+0.1–1), max(0, 0.25+0.3–1)], [min(0.2,0.1), min(0.25, 0.3)])
:::: = env([0,0], [0.1, 0.25])
:::: = [0, 0.25]
where env([''x''&lt;sub&gt;1&lt;/sub&gt;,''x''&lt;sub&gt;2&lt;/sub&gt;], [''y''&lt;sub&gt;1&lt;/sub&gt;,''y''&lt;sub&gt;2&lt;/sub&gt;]) is [min(''x''&lt;sub&gt;1&lt;/sub&gt;,''y''&lt;sub&gt;1&lt;/sub&gt;), max(''x''&lt;sub&gt;2&lt;/sub&gt;,''y''&lt;sub&gt;2&lt;/sub&gt;)]. Likewise, the probability of the [[logical disjunction|disjunction]] is surely in the interval
: &amp;nbsp;&amp;nbsp;P(A v B) = ''a'' + ''b'' − ''a'' × ''b'' = 1 − (1 − ''a'') × (1 − ''b'')
:::: = 1 − (1 − [0.2, 0.25]) × (1 − [0.1, 0.3])
:::: = 1 − [0.75, 0.8] × [0.7, 0.9]
:::: = 1 − [0.525, 0.72]
:::: = [0.28, 0.475]
if A and B are independent events. If they are not independent, the Fréchet inequality bounds the disjunction
: &amp;nbsp;&amp;nbsp;P(A v B) = env(max(''a'', ''b''), min(1, ''a'' + ''b''))
:::: = env(max([0.2, 0.25], [0.1, 0.3]), min(1, [0.2, 0.25] + [0.1, 0.3]))
:::: = env([0.2, 0.3], [0.3, 0.55])
:::: = [0.2, 0.55].

It is also possible to compute interval bounds on the conjunction or disjunction under other assumptions about the dependence between A and B. For instance, one might assume they are positively dependent, in which case the resulting interval is not as tight as the answer assuming independence but tighter than the answer given by the Fréchet inequality. Comparable calculations are used for other logical functions such as negation, exclusive disjunction, etc. When the Boolean expression to be evaluated becomes complex, it may be necessary to evaluate it using the methods of mathematical programming&lt;ref name=Hailperin86 /&gt; to get best-possible bounds on the expression. A similar problem one presents in the case of [[probabilistic logic]] (see for example Gerla 1994). If the probabilities of the events are characterized by probability distributions or p-boxes rather than intervals, then analogous calculations can be done to obtain distributional or p-box results characterizing the probability of the top event.    &lt;!--

Prob(A and B) = Prob(A) * Prob(B).

Prob(A or B) = Prob(A) + Prob(B) – Prob(A) * Prob(B)

Operation	Formula
	conjunction   	[ max(0, a+b–1), min(a, b) ],
	disjunction	[ max(a, b), min(1, a+b) ],

a = [0.2, 0.25]
b = [0.1, 0.3]

a |&amp;| b
    [ 0.02, 0.075]
a &amp; b
    [ 0, 0.25]

a ||| b
    [ 0.28, 0.475]
a | b
    [ 0.2, 0.55]

--&gt;

==Magnitude comparisons==
The probability that an uncertain number represented by a p-box ''D'' is less than zero is the interval Pr(''D'' &lt; 0) = [&lt;u&gt;''F&lt;/u&gt;''(0), ''F̅''(0)], where ''F̅''(0) is the left bound of the probability box ''D'' and &lt;u&gt;''F''&lt;/u&gt;(0) is its right bound, both evaluated at zero. Two uncertain numbers represented by probability boxes may then be compared for numerical magnitude with the following encodings:
:''A'' &lt; ''B'' = Pr(''A'' − ''B'' &lt; 0),
:''A'' &gt; ''B'' = Pr(''B'' −  ''A'' &lt; 0),
:''A'' ≤ ''B'' = Pr(''A'' −  ''B'' ≤ 0), and
:''A'' ≥ ''B'' = Pr(''B'' −  ''A'' ≤ 0).
Thus the probability that ''A'' is less than ''B'' is the same as the probability that their difference is less than zero, and this probability can be said to be the value of the expression ''A'' &lt; ''B''.

Like arithmetic and logical operations, these magnitude comparisons generally depend on the stochastic dependence between ''A'' and ''B'', and the subtraction in the encoding should reflect that dependence.  If their dependence is unknown, the difference can be computed without making any assumption using the Fréchet operation.

==Sampling-based computation==
Some analysts&lt;ref&gt;Alvarez, D. A., 2006. On the calculation of the bounds of probability of events using infinite random sets. ''International Journal of Approximate Reasoning'' '''43''': 241–267.&lt;/ref&gt;&lt;ref&gt;Baraldi, P., Popescu, I. C., Zio, E., 2008. Predicting the time to failure of a randomly degrading component by a hybrid Monte Carlo and possibilistic method. ''IEEE Proc. International Conference on Prognostics and Health Management''.&lt;/ref&gt;&lt;ref&gt;Batarseh, O. G., Wang, Y., 2008. Reliable simulation with input uncertainties using an interval-based approach. ''IEEE Proc. Winter Simulation Conference''.&lt;/ref&gt;&lt;ref&gt;Roy, Christopher J., and Michael S. Balch (2012). A holistic approach to uncertainty quantification with application to supersonic nozzle thrust. ''International Journal for Uncertainty Quantification'' '''2''' (4): 363–81 {{doi|10.1615/Int.J.UncertaintyQuantification.2012003562}}.&lt;/ref&gt;&lt;ref&gt;Zhang, H., Mullen, R. L., Muhanna, R. L. (2010). Interval Monte Carlo methods for structural reliability. ''Structural Safety'' '''32''': 183–190.&lt;/ref&gt;&lt;ref&gt;Zhang, H., Dai, H., Beer, M., Wang, W. (2012). Structural reliability analysis on the basis of small samples: an interval quasi-Monte Carlo method. ''Mechanical Systems and Signal Processing'' '''37''' (1–2): 137–51 {{doi|10.1016/j.ymssp.2012.03.001}}.&lt;/ref&gt; use sampling-based approaches to computing probability bounds, including [[Monte Carlo simulation]], [[Latin hypercube]] methods or [[importance sampling]]. These approaches cannot assure mathematical rigor in the result because such simulation methods are approximations, although their performance can generally be improved simply by increasing the number of replications in the simulation. Thus, unlike the analytical theorems or methods based on mathematical programming, sampling-based calculations usually cannot produce [[verified computing|verified computations]]. However, sampling-based methods can be very useful in addressing a variety of problems which are computationally [[NP-hard|difficult]] to solve analytically or even to rigorously bound. One important example is the use of Cauchy-deviate sampling to avoid the [[curse of dimensionality]] in propagating [[Interval (mathematics)|interval]] uncertainty through high-dimensional problems.&lt;ref&gt;Trejo, R., Kreinovich, V. (2001). [http://www.cs.utep.edu/vladik/2000/tr00-17.pdf Error estimations for indirect measurements: randomized vs. deterministic algorithms for ‘black-box’ programs]. ''Handbook on Randomized Computing'', S. Rajasekaran, P. Pardalos, J. Reif, and J. Rolim (eds.), Kluwer, 673–729.&lt;/ref&gt;

==Relationship to other uncertainty propagation approaches==
PBA belongs to a class of methods that use [[imprecise probability|imprecise probabilities]] to simultaneously represent [[Uncertainty quantification|aleatoric and epistemic uncertainties]]. PBA is a generalization of both [[interval analysis]] and probabilistic [[convolution of probability distributions|convolution]] such as is commonly implemented with [[Monte Carlo simulation]]. PBA is also closely related to [[robust Bayes analysis]], which is sometimes called [[Bayesian sensitivity analysis]]. PBA is an alternative to [[second-order Monte Carlo simulation]].

==Applications==

{{main|Applications of p-boxes and probability bounds analysis}}

{{:Applications of p-boxes and probability bounds analysis}}&lt;!--

==Other topics==
===Modeling intervariable dependencies===
===Sensitivity analysis===
Value of information; dilation
===Bayesian inference of p-boxes===
Vicky Montgomery's dissertation
===Analysis of data consisting of intervals===
===Validation===
===Model uncertainty===
Doubt about the family or shape of a distribution
Doubt about the dependence among variables
Doubt about the function that combines inputs
==Limitations and drawbacks==
Loses modal information; Cedric Baudrit's dissertation
==Generalizations==
Destercke's dissertation
--&gt;

==See also==
* [[Probability box]]
* [[Robust Bayes analysis]]
* [[Imprecise probability]]
* [[Second-order Monte Carlo simulation]]
* [[Monte Carlo simulation]]
* [[interval arithmetic|Interval analysis]]
* [[Probability theory]]
* [[Risk analysis]]

==References==
{{Reflist|30em}}

==Further references==
* {{cite book | last1 = Bernardini | first1 = Alberto | last2 = Tonon | first2 = Fulvio | title = Bounding Uncertainty in Civil Engineering: Theoretical Background | publisher = Springer | location = Berlin | year = 2010 | isbn = 3-642-11189-0 }}
* {{cite book | last = Ferson | first = Scott | title = RAMAS Risk Calc 4.0 Software : Risk Assessment with Uncertain Numbers | publisher = Lewis Publishers | location = Boca Raton, Florida | year = 2002 | isbn = 1-56670-576-2 }}
* {{cite journal |first=G. |last=Gerla |title=Inferences in Probability Logic |journal=Artificial Intelligence |volume=70 |issue=1–2 |pages=33–52 |year=1994 |doi=10.1016/0004-3702(94)90102-3 }}
* {{cite book | last1 = Oberkampf | first1 = William L. | last2 = Roy | first2 = Christopher J. | title = Verification and Validation in Scientific Computing | publisher = Cambridge University Press | location = New York | year = 2010 | isbn = 0-521-11360-1 }}&lt;!-- In an email dated 28 March 2011, William Oberkampf stated "PBA is the only UQ method we discuss and apply in our examples in the book." --&gt;

==External links==
* [http://www.ramas.com/pbawhite.pdf Probability bounds analysis in environmental risk assessments]
* [http://ualr.edu/jdberleant/intprob/ Intervals and probability distributions]
* [https://web.archive.org/web/20120210155925/http://www.sandia.gov/epistemic/ Epistemic uncertainty project]
* [http://www.sipta.org/ The Society for Imprecise Probability: Theories and Applications]

[[Category:Probability bounds analysis]]
[[Category:Mathematical analysis]]</text>
      <sha1>g3y659q7i5wv6rddeechh16n3289qqc</sha1>
    </revision>
  </page>
  <page>
    <title>Proth number</title>
    <ns>0</ns>
    <id>3226068</id>
    <revision>
      <id>863407325</id>
      <parentid>863403347</parentid>
      <timestamp>2018-10-10T16:03:05Z</timestamp>
      <contributor>
        <username>Joel B. Lewis</username>
        <id>13974845</id>
      </contributor>
      <comment>Reverted to revision 862028423 by Joel B. Lewis: The article only contains about 4 paragraphs of information; the infobox is larger than the material it is summarizing.  The article was certainly better without it. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2964">In [[number theory]], a '''Proth number''' is a number of the form

:&lt;math&gt;N=k \cdot 2^n+1 &lt;/math&gt;

where &lt;math&gt;k&lt;/math&gt; is an [[odd number|odd]] positive [[integer]] and &lt;math&gt;n&lt;/math&gt; is a positive integer such that &lt;math&gt;2^n &gt; k&lt;/math&gt;.   They are named after the mathematician [[François Proth]].  The first few Proth numbers are

:3, 5, 9, 13, 17, 25, 33, 41, 49, 57, 65, 81, 97, 113, 129, 145, 161, 177, 193, 209, 225, 241 {{OEIS|id=A080075}}.

The [[Cullen number]]s (numbers of the form {{math|''n''·2&lt;sup&gt;''n''&lt;/sup&gt; + 1}}) and [[Fermat number]]s (numbers of the form {{math|2&lt;sup&gt;2&lt;sup&gt;''n''&lt;/sup&gt;&lt;/sup&gt; + 1}}) are special cases of Proth numbers.   Without the condition that &lt;math&gt;2^n &gt; k&lt;/math&gt;, all odd integers greater than 1 would be Proth numbers.&lt;ref&gt;{{MathWorld |title=Proth Number |id=ProthNumber}}&lt;/ref&gt;

== Proth primes ==

{{unsolved|mathematics|Are there infinitely many Proth primes?}}

A '''Proth prime''' is a Proth number which is [[prime number|prime]]. The first few Proth primes are 
:3, 5, 13, 17, 41, 97, 113, 193, 241, 257, 353, 449, 577, 641, 673, 769, 929, 1153, 1217, 1409, 1601, 2113, 2689, 2753, 3137, 3329, 3457, 4481, 4993, 6529, 7297, 7681, 7937, 9473, 9601, 9857 ({{OEIS2C|id=A080076}}).

The primality of a Proth number can be tested with [[Proth's theorem]], which states&lt;ref&gt;{{MathWorld |title=Proth's Theorem |id=ProthsTheorem}}&lt;/ref&gt; that a Proth number &lt;math&gt;p&lt;/math&gt; is prime if and only if there exists an integer &lt;math&gt;a&lt;/math&gt; for which 

:&lt;math&gt;a^{\frac{p-1}{2}}\equiv -1 \pmod{p} .&lt;/math&gt;

The largest known Proth prime {{as of|2016|lc=on}} is &lt;math&gt;10223 \cdot 2^{31172165} + 1&lt;/math&gt;, and is 9,383,761 digits long.&lt;ref&gt;{{Cite web |url=http://primes.utm.edu/top20/page.php?id=66 |title=The Top Twenty: Proth |last=Caldwell |first=Chris |publisher=The [[Prime Pages]]}}&lt;/ref&gt; It was found by Szabolcs Peter in the [[PrimeGrid]] [[distributed computing project]] which announced it on 6 November 2016.&lt;ref&gt;{{Cite web |url=http://www.primegrid.com/forum_thread.php?id=7116 |title=World Record Colbert Number discovered! |author=Van Zimmerman&lt;!-- no way to tell if full name or surname--&gt; |date=30 Nov 2016 |publisher=[[PrimeGrid]] |orig-year=9 Nov 2016}}&lt;/ref&gt; It is also the largest known non-[[Mersenne prime]].&lt;ref&gt;{{Cite web |url=http://primes.utm.edu/top20/page.php?id=3 |title=The Top Twenty: Largest Known Primes |last=Caldwell |first=Chris |publisher=The [[Prime Pages]]}}&lt;/ref&gt;

==See also==
*[[Sierpinski number]]
*[[Pierpont Prime]]s
*[[PrimeGrid]] – a distributed computing project searching for large Proth primes

==References==
{{reflist}}

==External links==
{{cite web|last1=Grime|first1=Dr. James|title=78557 and Proth Primes|url=https://www.youtube.com/watch?v=fcVjitaM3LY|website=YouTube|publisher=[[Brady Haran]]|accessdate=13 November 2017|format=video}}

{{Prime number classes|state=collapsed}}
{{Classes of natural numbers}}

[[Category:Number theory]]
[[Category:Integer sequences]]</text>
      <sha1>pbhicc9wudrmlh7bbv4f1t75zl8ttzq</sha1>
    </revision>
  </page>
  <page>
    <title>Reduction of summands</title>
    <ns>0</ns>
    <id>28430974</id>
    <revision>
      <id>532100342</id>
      <parentid>453080601</parentid>
      <timestamp>2013-01-09T03:09:00Z</timestamp>
      <contributor>
        <username>Addbot</username>
        <id>6569922</id>
      </contributor>
      <minor/>
      <comment>[[User:Addbot|Bot:]] Removing Orphan Tag (Nolonger an Orphan) ([[User_talk:Addbot|Report Errors]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3365">'''Reduction of summands''' is an algorithm for fast [[binary multiplication]] of non-signed binary integers.  It is performed in three steps: production of summands, reduction of summands, and summation.

==Steps==
===Production of summands===
In binary multiplication, each row of the summands will be either zero or one of the numbers to be multiplied.  Consider the following:
    1001
   x1010
   -----
    0000
   1001
  0000
 1001
The second and fourth row of the summands are equivalent to the first term.  Production of the summands requires a simple [[AND gate]] for each summand.  Given enough AND gates, the time to produce the summands will be one cycle of the [[arithmetic logic unit]].

===Reduction of summands===
The summands are reduced using a common 1-bit [[adder (electronics)|full adder]] that accepts two 1-bit terms and a carry-in bit.  It produces a sum and a carry-out.  The full adders are arranged such that the sum remains in the same column of summands, but the carry-out is shifted left.  In each round of reduction, three bits in a single column are used as the two terms and carry-in for the full adder, producing a single sum bit for the column.  This reduces the bits in the column by a factor of 3.  However, the column to the right will shift over carry-out bits, increasing the bits in the column by a third of the number of rows of summands.  At worst, the reduction will be 2/3 the number of rows per round of reduction.

The following shows how the first round of reduction is performed.  Note that all "empty" positions of the summands are considered to be zero (a . is used here as indicator of the "assumed zero values").  In each row, the top three bits are the three inputs to the full adder (two terms and carry-in).  The sum is placed in the top bit of the column.  The carry-out is placed in the second row of the column to the left.  The bottom bit is a single feed into an adder.  The sum of this adder is placed in the third row of the column.  Carry-out is ignored as it will always be zero, but by design it would be placed in the fourth row of the column to the left.  For design, it is important to note that rows 1, 3, 5, ... (counting from the top) are filled with sums from the column itself.  Rows 2, 4, 6, ... are filled with carry-out values from the column to the right.
    1011
   x0110
   -----
 ...0000
 ..1011.
 .1011..
 0000...
 -------
 0111010
 000100.
 00000..
Reduction is performed again in exactly the same way.  This time, only the top three rows of summands are of interest because all other summands must be zero.
 0111010
 000100.
 00000..
 -------
 0110010
 001000.
When there are only two significant rows of summands, the reduction cycles end. A basic full adder normally requires three cycles of the [[arithmetic logic unit]].  Therefore, each cycle of reduction is commonly 3 cycles long.

===Summation===
When there are only two rows of summands remaining, they are added using a fast adder.  There are many designs of fast adders, any of which may be used to complete this algorithm.

==Calculation time==
The calculation time for the reduction of summands algorithm is: ''T'' = 1Δt + r3Δt + FA (where r is the number of reduction cycles and FA is the time for the fast adder at the end of the algorithm).

{{DEFAULTSORT:Reduction Of Summands}}
[[Category:Computer arithmetic]]</text>
      <sha1>i65zm4g4s8z1insydkjybsv2klbzbe8</sha1>
    </revision>
  </page>
  <page>
    <title>Sign convention</title>
    <ns>0</ns>
    <id>293533</id>
    <revision>
      <id>854583708</id>
      <parentid>853561993</parentid>
      <timestamp>2018-08-12T11:23:09Z</timestamp>
      <contributor>
        <username>Jdp407</username>
        <id>11918255</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/2409:4055:501:8346:5024:5A21:F2CA:19F3|2409:4055:501:8346:5024:5A21:F2CA:19F3]] ([[User talk:2409:4055:501:8346:5024:5A21:F2CA:19F3|talk]]) to last revision by 130.132.173.165. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5289">In [[physics]], a '''sign convention''' is a choice of the physical significance of  [[sign (mathematics)|sign]]s (plus or minus) for a set of quantities, in a case where the choice of sign is arbitrary. "Arbitrary" here means that the same physical system can be correctly described using different choices for the signs, as long as one set of definitions is used [[consistent]]ly. The choices made may differ between authors. Disagreement about sign conventions is a frequent source of confusion, frustration, misunderstandings, and even outright errors in scientific work. In general, a sign convention is a special case of a choice of [[coordinate system]]  for the case of one dimension.

Sometimes, the term "sign convention" is used more broadly to include factors of ''[[Imaginary unit|i]]'' and 2[[pi|π]], rather than just choices of sign.

== Relativity ==

===Metric signature===
In [[General relativity|relativity]], the [[metric signature]] can be either (+,−,−,−) or (−,+,+,+). (Note that throughout this article we are displaying the signs of the eigenvalues of the metric in the order that presents the timelike component first, followed by the spacelike components). A similar convention is used in higher-dimensional relativistic theories; that is, (+,−,−,−,...) or (−,+,+,+,...). A choice of signature is associated with a variety of names:

+ − − −:
*''[[Timelike]] convention''
*''[[Particle physics]] convention''
*''[[West Coast of the United States|West coast]] convention''
*''Mostly minuses''
*''[[Lev Landau|Landau]]–[[Evgeny Lifshitz|Lifshitz]] sign convention''.

− + + +:
*''[[Spacelike]] convention''
*''[[General relativity|Relativity]] convention''
*''[[East Coast of the United States|East coast]] convention''
*''Mostly pluses''
*''Pauli convention''

We catalog the choices of various authors of some graduate textbooks:

(+,−,−,−):
*''[[Course_of_Theoretical_Physics#English_editions|Landau &amp; Lifshitz]]''
*''[https://books.google.com/books/about/Gravitation.html?id=3llAAAAAIAAJ Gravitation: an introduction to current research]'' ([[Louis Witten|L. Witten]])
* ''[https://books.google.dk/books?isbn=0198596863 Ray D'Inverno, Introducting Einstein's relativity].''

(−,+,+,+):
*''[[Gravitation (book)|Misner, Thorne and Wheeler]]''
*''[http://spacetimeandgeometry.net/ Spacetime and Geometry: An Introduction to General Relativity]''
*''[[General Relativity (book)|General Relativity (Wald)]]'' (Note that Wald changes signature to the timelike convention for Chapter 13 only.)

The signature + − − − corresponds to the [[metric tensor]]:
:&lt;math&gt;\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; -1 \end{pmatrix} &lt;/math&gt;

whereas the signature − + + + corresponds to:
:&lt;math&gt;\begin{pmatrix} -1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix} &lt;/math&gt;

===Curvature===
The [[Ricci tensor]] is defined as the contraction of the [[Riemann tensor]]. Some authors use the contraction &lt;math&gt;R_{ab} \, = R^c{}_{acb}&lt;/math&gt;, whereas others use the alternative &lt;math&gt;R_{ab} \, = R^c{}_{abc}&lt;/math&gt;. Due to the [[Riemann tensor#Symmetries and identities|symmetries of the Riemann tensor]], these two definitions differ by a minus sign.

In fact, the second definition of the Ricci tensor is &lt;math&gt;R_{ab} \, = {R_{acb}}^c&lt;/math&gt;. The sign of the Ricci tensor does not change, because the two sign conventions concern the sign of the Riemann tensor. The second definition just compensates the sign, and it works together with the second definition of the Riemann tensor (see e.g. Barrett O'Neill's Semi-riemannian geometry).

== Other sign conventions ==

* The sign choice for [[arrow of time|time]] in frames of reference and proper time: '''+''' for future and '''−''' for past is universally accepted.
* The choice of &lt;math&gt;\pm&lt;/math&gt; in the [[Dirac equation]].
* The sign of the [[electric charge]], [[electromagnetic tensor|field strength tensor]] &lt;math&gt;\, F_{ab}&lt;/math&gt; in [[Gauge theory|gauge theories]] and [[Maxwell's equations|classical electrodynamics]].
* Time dependence of a positive-frequency wave (see, e.g., the [[electromagnetic wave equation]]):
** &lt;math&gt;\, e^{-i\omega t}&lt;/math&gt; (mainly used by physicists)
** &lt;math&gt;\, e^{+j\omega t}&lt;/math&gt; (mainly used by engineers)
* The sign for the imaginary part of [[Permittivity#Complex permittivity|permittivity]] (in fact dictated by the choice of sign for time-dependence)
* The signs of distances and [[radius of curvature (optics)|radii of curvature]] of optical surfaces in [[optics]]
* The sign of work in the [[first law of thermodynamics]].
* The sign of the weight of the determinant of the metric tensor when dealing with [[tensor density]].

It is often considered good form to state explicitly which sign convention is to be used at the beginning of each book or article.

== See also ==
* [[Orientation (vector space)]], also known as "handedness"
* [[Symmetry (physics)]]
* [[Gauge theory]]

==References==
{{reflist}}
* {{cite book | author=[[Charles Misner]]; [[Kip S Thorne]] &amp; [[John Archibald Wheeler]] | title=[[Gravitation (book)|Gravitation]] | location=San Francisco | publisher=W. H. Freeman | year=1973 | isbn=0-7167-0344-0|page=cover}}

[[Category:Mathematical physics]]</text>
      <sha1>pedefgvs39umamuxqlm8k9ve50opbks</sha1>
    </revision>
  </page>
  <page>
    <title>Speakeasy (computational environment)</title>
    <ns>0</ns>
    <id>24641580</id>
    <revision>
      <id>859637161</id>
      <parentid>859486335</parentid>
      <timestamp>2018-09-15T09:08:10Z</timestamp>
      <contributor>
        <username>Dexbot</username>
        <id>16752040</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error fix. Section heading problem. Violates [[WP:MOSHEAD]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21665">{{Infobox software
| name                   = Speakeasy
| logo                   = Speakeasy Red Logo.png
| screenshot             =
| caption                =
| developer              = Speakeasy Computing Corporation
| latest_release_version = IV Iota
| latest_release_date    = 2006
| programming language  = [[Mortran]], [[FORTRAN]], [[C (programming language)|C]]{{Citation needed|date=August 2013}}
| operating_system       = [[Windows]], [[macOS]], [[RedHat Linux]], [[SUSE Linux]], [[Mandrake Linux]], [[Debian]], [[Solaris (operating system)|Solaris]], [[HP-UX]]&lt;ref&gt;[http://www.speakeasy.com/about_speakeasy.htm#Platforms Supported platforms]&lt;/ref&gt;
| genre                  = [[List of numerical analysis software|Technical computing]]
| license                = [[Trialware]]
| website                = {{URL|speakeasy.com}}
}}
{{Infobox programming language
| name                   = Speakeasy (the interpreted programming language)
| logo                   =
| paradigm               = [[Imperative programming|imperative]]
| year                   = 1964
| designer               = [[Stanley Cohen (physicist)|Stanley Cohen]]
| developer              = Speakeasy Computing Corporation
| latest_release_version =
| latest_release_date    =
| latest_test_version    =
| latest_test_date       =
| typing                 = [[dynamic typing|dynamic]]
| implementations        =
| dialects               =
| influenced_by          = [[APL (programming language)|APL]]&lt;ref&gt;{{cite thesis |url=http://www.cs.nyu.edu/media/publications/rubinsteyn_alex.pdf |type=Ph.D. |first=Alex |last=Rubinsteyn |title=Runtime Compilation of Array-Oriented Python Programs |publisher=New York University |year=2014 |quote=APL directly inspired Speakeasy}}&lt;/ref&gt;
| influenced             = [[MATLAB]]&lt;ref&gt;{{cite web |url=http://archive.computerhistory.org/resources/access/text/2013/12/102746804-05-01-acc.pdf |title=An interview with CLEVE MOLER Conducted by Thomas Haigh On 8 and 9 March, 2004 Santa Barbara, California |publisher=Computer History Museum |quote=So APL, Speakeasy, LINPACK, EISPACK, and PL0 were the predecessors to MATLAB. |accessdate=2016-12-06}}&lt;/ref&gt;
| operating_system       = 
| license                =
| website                =
}}

'''Speakeasy''' is a [[Numerical analysis|numerical computing]] interactive environment also featuring an interpreted [[programming language]]. It was initially developed for internal use at the Physics Division of [[Argonne National Laboratory]] by the theoretical physicist [[Stanley Cohen (physicist)|Stanley Cohen]].&lt;ref&gt;[https://www.amazon.co.uk/An-introduction-SPEAKEASY-Informal-report/dp/B0006WLCUE "An introduction to Speakeasy - Informal report]&lt;/ref&gt; He eventually founded Speakeasy Computing Corporation to make the program available commercially.

Speakeasy is a very long-lasting numerical package. In fact, the original version of the environment was built around a core dynamic data repository called "Named storage" developed in the early 1960s,&lt;ref&gt;[https://books.google.com/books/about/Named_storage.html?id=UIYL2MSgPSwC "Named storage: a dynamic storage-allocation scheme with manipulative routines", ''AEC research and development report - Volume 7021 ANL (Series)'' - Stanley Cohen, Physics Division, U.S. Atomic Energy Commission, Argonne National Laboratory, 1965.]&lt;/ref&gt;&lt;ref&gt;[http://www.osti.gov/bridge/servlets/purl/4292135-TkCmlk/4292135.pdf "Speakeasy - An evolutionary system", S. Cohen,  ''Proceedings of the ACM SIGPLAN symposium on Very high level languages'' (March 1974)]&lt;/ref&gt; while the most recent version has been released in 2006.

Speakeasy was aimed to make the computational work of the physicists at the Argonne National Laboratory easier.&lt;ref&gt;{{cite journal|url = http://www.sciencedirect.com/science/article/pii/0010465571900087 | doi=10.1016/0010-4655(71)90008-7 | volume=2 | title=The Delphi-speakeasy system. I. Overall description | year=1971 | journal=Computer Physics Communications | pages=1–10 | last1 = Cohen | first1 = Stanley}}&lt;/ref&gt; It was initially conceived to work on [[mainframes]] (the only kind of computers at that time), and was subsequently ported to new platforms ([[minicomputers]], [[personal computers]]) as they became available. The porting of the same code on different platforms was made easier by using [[Mortran]] metalanguage macros to face systems dependencies and compilers deficiencies and differences.&lt;ref&gt;"Using Mortran to translate Fortran programs from one machine to another"
Steven C. Pieper, ''Argonne National Laboratory'', 1976&lt;/ref&gt;
Speakeasy is currently available on several platforms : PCs running [[Windows]], [[macOS]], [[Linux]], departmental computers and workstations running several flavors of Linux, [[AIX]] or [[Solaris (operating system)|Solaris]].

Speakeasy was also among the first{{Citation needed|date=October 2009}} interactive numerical computing environments, having been implemented in such a way on a [[CDC 3600]] system, and later on [[Time Sharing Option|IBM TSO]] machines as one was in beta-testing at the Argonne National Laboratory at the time.

Almost since the beginning (as the dynamic linking functionality was made available in the operating systems) Speakeasy features the capability of expanding its operational vocabulary using separated modules, dynamically linked to the core processor as they are needed. For that reason such modules  were called "linkules" (LINKable-modULES).&lt;ref&gt;[http://portal.acm.org/citation.cfm?id=810231&amp;dl=GUIDE&amp;coll=GUIDE&amp;CFID=55845887&amp;CFTOKEN=77421645 "Speakeasy linkules - plug compatible software" ''ACM - Proceedings of the 1977 annual conference'']&lt;/ref&gt; They are functions with a generalized interface, which can be written in  [[FORTRAN]] or in [[C (programming language)|C]].{{citation needed|date=August 2012}}
The independence of each of the new modules from the others and from the main processor is of great help in improving the system, especially it was in the old days.

This easy way of expanding the functionalities of the main processor was often exploited by the users to develop their own specialized packages. Besides the programs, functions and subroutines the user can write in the Speakeasy's own interpreted language, linkules add functionalities carried out with the typical performances of compiled programs.

Among the packages developed by the users, one of the most important is "Modeleasy", originally developed as "FEDeasy"&lt;ref&gt;"Econometric models via SPEAKEASY/FEDEASY", James M. Condie, John W. Davison, 1975&lt;/ref&gt; in the early 1970s at the research department of the [[Federal Reserve Board]] of Governors in Washington D.C..
Modeleasy implements special objects and functions for large econometric models estimation and simulation.
Its evolution led eventually to its distribution as an independent product.

== Syntax  ==

The symbol ''':_''' (colon+underscore) is both the Speakeasy logo and the prompt of the interactive session.

The dollar sign is used for delimiting comments; the ampersand is used to continue a statement on the following physical line, in which case the prompt becomes ''':&amp;''' (colon+ampersand); a semicolon can separate statements written on the same physical line.
 $ suppose you have a very long statement, 
 $ you can write it on multiple physical lines using "&amp;" 
 $ at the end of the line to be continued:
 
 :_ the_return_value = this_is_a_function_with_many_arguments(argument_1, argument_2, &amp;
 :&amp;                             argument_3, argument_4, argument_5, argument_6)
 
 $ on the other hand, you can collect several short statements 
 $ on a single physical line using ";"
 :_ a=1; b=2; c=3; d=4 
As its own name tells, Speakeasy was aimed to expose a syntax as friendly as possible to the user, and as close as possible to the spoken language. The best example of that is given by the set of commands for reading/writing data from/to the permanent storage. E.g. (the languages keywords are in upper case to clarify the point):
 :_ GET my_data FROM LIBRARY my_project
 :_ KEEP my_data AS a_new_name_for_mydata IN LIBRARY other_project 
Variables (i.e. Speakeasy objects) are given a name up to 255 character long, when LONGNAME option is ON, up to 8 characters otherwise (for backward compatibility). They are dynamically typed, depending on the value assigned to them.
 :_ a=1
 :_ whatis a
 A is a REAL SCALAR.
 :_ a="now a character array"
 :_ whatis a
 A is a 21 element CHARACTER ARRAY.
Arguments of functions are usually not required to be surrounded by parenthesis or separated by commas, provided that the context remains clear and unambiguous. For example:
 :_ sin(grid(-pi,pi,pi/32))    $ fully specified syntax
can be written :
 :_ sin grid(-pi,pi,pi/32)     $ the argument of function sin is not surrounded by parenthesis
or even 
 :_ sin grid(-pi pi pi/32)     $ the arguments of function grid can be separated by spaces
Many other syntax simplifications are possible; for example, to define an object named 'a' valued to a ten-elements array of zeroes, one can write any of the following statements:
 :_ a=array(10:0,0,0,0,0,0,0,0,0,0)
 :_ a=0,0,0,0,0,0,0,0,0,0
 :_ a=0 0 0 0 0 0 0 0 0 0
 :_ a=ints(10)*0
 :_ a=10:
Speakeasy is a '''''vector-oriented''''' language: giving a structured argument to a function of a scalar, the result is usually an object with the same structure of the argument, in which each element is the result of the function applied to the corresponding element of the argument. In the example given above, the result of function '''sin''' applied to the array (let us call it '''x''') generated by the function '''grid''' is the array '''answer''' whose element '''answer'''(i) equals '''sin'''('''x'''(i)) for each i from 1 to '''noels'''(x) (the number of elements of '''x'''). In other words, the statement
 :_ a=sin(grid(-pi pi pi/32))
is equivalent to the following fragment of program: 
 x=grid(-pi pi pi/32) $ generates an array of real numbers from -pi to pi, stepping by pi/32
 for i = 1,noels(x)   $ loops on the elements of x
   a(i) = sin(x(i))   $ evaluates the i-th element of a
 next i               $ increment the loop index
The  '''''vector-oriented''''' statements avoid writing programs for such loops and are much faster than them.

==Work area and objects==
By the very first statement of the session, the user can define the size of the "named storage" (or "work area", or "allocator"), which is allocated once and for all at the beginning of the session. Within this fixed-size work area, the Speakeasy processor dynamically creates and destroys the work objects as needed. A user-tunable &lt;ref&gt;The user can decide how often the garbage collections occur, in terms of number of objects created between two of them. This feature (SLOSH command) is actually aimed to linkules debugging.&lt;/ref&gt; garbage collection mechanism is provided to maximize the size of the free block in the work area, packing the defined objects in the low end or in the high end of the allocator. At any time, the user can ask about used or remaining space in the work area.
 :_ SIZE 100M $ very first statement: the work area will be 100MB
 &lt;nowiki&gt;:&lt;/nowiki&gt;_ SIZE      $ returns the size of the work area in the current session
 &lt;nowiki&gt;:&lt;/nowiki&gt;_ SPACELEFT $ returns the amount of data storage space currently unused
 &lt;nowiki&gt;:&lt;/nowiki&gt;_ SPACENOW  $ returns the amount of data storage space currently used
 &lt;nowiki&gt;:&lt;/nowiki&gt;_ SPACEPEAK $ returns the maximum amount of data storage space used in the current session

==(Raw) Object orientation==
Within reasonable conformity and compatibility constraints, the Speakeasy objects can be operated on using the same algebraic syntax.

From this point of view, and considering the dynamic and structured nature of the data held in the "named storage", it is possible to say that Speakeasy since the beginning implemented  a very raw form of operator overloading, and a pragmatic approach to some features of what was later called "[[Object Oriented Programming]]", although it did not evolve further in that direction.
&lt;center&gt;
{| cellpadding="0" cellspacing="0"
| colspan="2" |
 $ The following example shows how a Matrix-family object and an Array-family object
 $ with the same structure and values are operated on differently although using the 
 $ same "*" and "/" operator: in the first case using the matrix algebra and in the 
 $ second case operating on an element-by-element basis.
|-
|
 :_ a='''matrix'''(2,2:1,2,3,4) ; a
   A (A 2 by 2 '''Matrix''')
   1  2
   3  4
 :_ a'''*'''a
   A*A (A 2 by 2 '''Matrix''')
   7   10
   15  22
 :_ a'''/'''a
   A/A (A 2 by 2 '''Matrix''')
   1  0
   0  1
|
 :_ aa='''array'''(2,2:1,2,3,4) ; aa
   AA (A 2 by 2 '''Array''')
   1  2
   3  4
 :_ aa'''*'''aa
   AA*AA (A 2 by 2 '''Array''')
   1   4
   9   16
 :_ aa'''/'''aa
   AA/AA (A 2 by 2 '''Array''')
   1  1
   1  1
|}
&lt;/center&gt;

== The object families ==
Speakeasy provides a bunch of predefined "families" of data objects: scalars, arrays (up to 15 dimensions), matrices, sets, time series.

The elemental data can be of kind real (8-bytes), complex (2x8-bytes), character-literal or name-literal ( matrices elements can be real or complex, time series values can only be real ).

=== Missing Values ===

For [[time series]] processing, five types of [[missing values]] are provided. They are denoted by N.A. (not available), N.C. (not computable), N.D. (not defined), along with  N.B. and N.E. the meaning of which is not predetermined and is left available for the linkules developer. They are internally represented by specific (and very small) numeric values, acting as codes.

All the time series operations take care of the presence of missing values, propagating them appropriately in the results.

Depending on a specific setting, missing values can be represented by the above notation, by a question mark symbol, or a blank (useful in tables). When used in input the question mark is interpreted as an N.A. missing value.
 :_ b=timeseries(1,2,3,4 : 2010 1 4)
 :_ b
   B (A Time Series with 4 Components)
   1  2  3  4
 :_ b(2010 3) = ? 
 :_ showmval qmark
 :_ b
   B (A Time Series with 4 Components)
   1  2  ?  4
 :_ 1/b
   1/B (A Time Series with 4 Components)
   1    .5   ?    .25
 :_ showmval explain
 :_ b
   B (A Time Series with 4 Components)
   1     2     N.A.  4
 :_ 1/b
   1/B (A Time Series with 4 Components)
   1     .5    N.C.  .25

In numerical objects other than time series, the concept of "missing values" is meaningless, and the numerical operations on them use the actual numeric values regardless they correspond to "missing values codes" or not (although "missing values codes" can be input and shown as such).
  :_ 1+?
   1+? =  1.00
  :_ 1/?
   1/? =  5.3033E36
  :_ 1*?
   1*? = ?

Note that, in other contexts, a question mark may have a different meaning: for example, when used as the first (and possibly only) character of a command line, it means the request to show more pieces of a long error message (which ends with a "+" symbol).
 :_ a=array(10000,10000:)
 ARRAY(10000,10000:) In line "A=ARRAY(10000,10000:)"  Too much data.+
 :_ ?
 Allocator size must be at least     859387 kilobytes.+
 :_ ?
 Use FREE to remove no longer needed data
 or
 use CHECKPOINT to save allocator for later restart.+
 :_ ?
 Use NAMES to see presently defined names.
 Use SIZE &amp; RESTORE to restart with a larger allocator.
 :_ ?
 NO MORE INFORMATION AVAILABLE.

=== Logical Values ===
Some support is provided for logical values, relational operators (the [[Fortran]] syntax can be used) and logical expressions.

Logical values are stored actually as numeric values: with 0 meaning false and non-zero (1 on output) meaning true.
 :_ a = 1 2 3 4 5
 :_ b = 1 3 2 5 4
 :_ a&gt;b
   A&gt;B (A 5 Component Array)
   0  0  1  0  1
 :_ a&lt;=b
   A&lt;=B (A 5 Component Array)
   1  1  0  1  0
 :_ a.eq.b
   A.EQ.B (A 5 Component Array)
   1  0  0  0  0
 :_ logical(2) $ this changes the way logical values are shown
 :_ a&gt;b; a&lt;=b; a.eq.b
   A&gt;B (A 5 Component Array)
  F F T F T
   A&lt;=B (A 5 Component Array)
  T T F T F
   A.EQ.B (A 5 Component Array)
  T F F F F

== Programming ==
Special objects such as "PROGRAM", "SUBROUTINE" and "FUNCTION" objects (collectively referred to as ''procedures'') can be defined for operations automation. Another way for running several instructions with a single command is to store them into a use-file and make the processor read them by mean of the USE command.

=== Use-files ===
"USEing" a use-file is the simplest way for performing several instruction with minimal typed input. (This operation roughly corresponds to what "source-ing" a file is in other scripting languages.)

A use-file is an alternate input source to the standard console and can contain all the commands a user can input by the keyboard (hence no multi-line flow control construct is allowed). The processor reads and executes use-files one line at a time.

Use-file execution can be concatenated but not nested, i.e. the control does not return to the caller at the completion of the called use-file.

=== Procedures ===
Full programming capability is achieved using "procedures". They are actually Speakeasy objects, which must be defined in the work area to be executed. An option is available in order to make the procedures being automatically retrieved and loaded from the external storage as they are needed.

Procedures can contain any of the execution flow control constructs available in the Speakeasy programming language.

==== Programs ====
A program can be run simply invoking its name or using it as the argument of the command EXECUTE. In the latter case, a further argument can identify a label from which the execution will begin.
Speakeasy programs differs from the other procedures for being executed at the same scoping "level" they are referenced to, hence they have full visibility of all the objects defined at that level, and all the objects created during their execution will be left there for subsequent uses. For that reason no argument list is needed.

==== Subroutines and Functions ====
Subroutines and Functions are executed at a new scoping level, which is removed when they finish. The communication with the calling scoping level is carried out through the argument list (in both directions). This implements data hiding, i.e. objects created within a Subroutine or a Function are not visible to other Subroutine and Functions but through argument lists.

A global level is available for storing object which must be visible from within any procedure, e.g. the procedures themselves.

The Functions differ from the Subroutines because they also return a functional value; reference to them can be part of more complex statement and are replaced by the returned functional value when evaluating the statement.

In some extent, Speakeasy Subroutines and Functions are very similar to the Fortran procedures of the same name.

==== Flow control ====
An IF-THEN-ELSE construct is available for conditional execution and two forms of FOR-NEXT construct are provided for looping.
&lt;center&gt;
{| cellpadding="0" border="0" cellspacing=20
|
 IF (''logical-expression'') THEN
    ''true-block''
 [ELSE
    ''false-block'']
 END IF
|
 FOR ''index'' = ''min'', ''max'' [, ''step'']
    ''loop-block''
 NEXT ''index''
|
 FOR ''value'' IN ''set-of-values''
    ''loop-block''
 NEXT ''value''
|}
&lt;/center&gt;

A "GO TO ''label''" statement is provided for jumping, while a Fortran-like computed GO TO statement can be used fort multiple branching.
&lt;center&gt;
{| cellpadding="0" border="0" cellspacing=20
|
 ...
 IF (''logical-expression'') GO TO ''label''
 ...
 ''label'':
 ...
|
 $ In the following statement 
 $ ''selector'' must be &gt;= 1 and &lt;= N
 
 GO TO ''label1'', ''label2'', ..., ''labelN'' : ''selector'' 
 ...
 ''label1'':
 ...
 ''label2'':
 ...
 ...
 ''labelN'':
 ...
|}
&lt;/center&gt;

An ON ERROR mechanism, with several options, provides a means for error handling.

== Linkule writing ==
Linkules are functions usually written in Fortran ( or, unsupportedly, in C ). With the aid of [[Mortran]] or C macros and an API library, they can interface the Speakeasy workarea for retrieving, defining, manipulating any Speakeasy object.

Most of the Speakeasy operational vocabulary is implemented via linkules. They can be statically linked to the core engine, or dynamically loaded as they are needed, provided they are properly compiled as shared objects (unix) or dll (windows).

==External links==
* [http://www.speakeasy.com The Speakasy Computing Corporation web site.]
* {{YouTube|user=gSpeakeasy|title=The Speakasy Computing Corporation}}
* [http://www.emcc.com The Econometric Modeling &amp; Computing Corporation web site.]
* [http://sci.tech-archive.net/Archive/sci.stat.math/2006-11/msg00064.html An interesting conversation with Stan Cohen.]

==Notes==
{{Reflist|2}}

{{-}}

{{Numerical analysis software}}

[[Category:Data analysis software]]
[[Category:Mathematical software]]
[[Category:Physics software]]
[[Category:Proprietary cross-platform software]]
[[Category:Numerical analysis software for Linux]]
[[Category:Numerical analysis software for MacOS]]
[[Category:Numerical analysis software for Windows]]
[[Category:Computer algebra system software for Windows]]
[[Category:Computer algebra system software for MacOS]]
[[Category:Computer algebra system software for Linux]]
[[Category:Array programming languages]]
[[Category:Numerical programming languages]]
[[Category:Numerical linear algebra]]
[[Category:Statistical programming languages]]
[[Category:Simulation programming languages]]
[[Category:Programming languages created in 1964]]</text>
      <sha1>5a3y9kikutp5ui7cl5dq9nd8p4arh11</sha1>
    </revision>
  </page>
  <page>
    <title>Stationary sequence</title>
    <ns>0</ns>
    <id>8199698</id>
    <revision>
      <id>753845078</id>
      <parentid>752811392</parentid>
      <timestamp>2016-12-09T14:49:30Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Speedily moving category Time series analysis to [[:Category:Time series]] per [[WP:CFDS|CFDS]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1143">In [[probability theory]] &amp;ndash; specifically in the theory of [[stochastic process]]es, a '''stationary sequence''' is a [[random sequence]] whose [[joint probability distribution]] is [[Invariant (mathematics)|invariant]] over time.  If a random sequence ''X''&lt;sub&gt;&amp;nbsp;''j''&lt;/sub&gt; is stationary then the following holds:

: &lt;math&gt;
\begin{align}
&amp; {} \quad F_{X_n,X_{n+1},\dots,X_{n+N-1}}(x_n, x_{n+1},\dots,x_{n+N-1}) \\
&amp; = F_{X_{n+k},X_{n+k+1},\dots,X_{n+k+N-1}}(x_n, x_{n+1},\dots,x_{n+N-1}),
\end{align}
&lt;/math&gt;

where ''F'' is the joint [[cumulative distribution function]] of the [[random variable]]s in the subscript.

If a sequence is stationary then it is [[wide-sense stationary]].

If a sequence is stationary then it has a constant [[mean (mathematics)|mean]] (which may not be finite):

: &lt;math&gt;E(X[n]) = \mu \quad \text{for all } n .&lt;/math&gt;

==See also==
*[[Stationary process]]

==References==
* ''Probability and Random Processes with Application to Signal Processing: Third Edition'' by Henry Stark and John W. Woods. Prentice-Hall, 2002.

[[Category:Sequences and series]]
[[Category:Time series]]


{{probability-stub}}</text>
      <sha1>lsvkdgc7qy3g32nr25ep8eojh3g6rd9</sha1>
    </revision>
  </page>
  <page>
    <title>Super-prime</title>
    <ns>0</ns>
    <id>13398615</id>
    <revision>
      <id>859282535</id>
      <parentid>859281934</parentid>
      <timestamp>2018-09-13T00:53:44Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 859281934 by [[Special:Contributions/2600:8803:9403:2700:693C:12B9:8ED3:C3AE|2600:8803:9403:2700:693C:12B9:8ED3:C3AE]] ([[User talk:2600:8803:9403:2700:693C:12B9:8ED3:C3AE|talk]]) that's not the definition of a super-prime</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2959">{{for|the computer program|SuperPrime}}
'''Super-prime numbers''' (also known as '''higher-order primes''' or '''prime-indexed primes''') are the [[subsequence]] of [[prime numbers]] that occupy prime-numbered positions within the sequence of all prime numbers. The subsequence begins
:3, 5, 11, 17, 31, 41, 59, 67, 83, 109, 127, 157, 179, 191, 211, 241, 277, 283, 331, 353, 367, 401, 431, 461, 509, 547, 563, 587, 599, 617, 709, 739, 773, 797, 859, 877, 919, 967, 991, ... {{OEIS|id=A006450}}.
That is, if ''p''(''i'') denotes the ''i''th prime number, the numbers in this sequence are those of the form ''p''(''p''(''i'')). {{harvtxt|Dressler|Parker|1975}} used a computer-aided proof (based on calculations involving the [[subset sum problem]]) to show that every integer greater than 96 may be represented as a sum of distinct super-prime numbers. Their proof relies on a result resembling [[Bertrand's postulate]], stating that (after the larger gap between super-primes 5 and 11) each super-prime number is less than twice its predecessor in the sequence.

{{harvtxt|Broughan|Barnett|2009}} show that there are
:&lt;math&gt;\frac{x}{(\log x)^2} + O\left(\frac{x\log\log x}{(\log x)^3}\right)&lt;/math&gt;
super-primes up to ''x''.
This can be used to show that the set of all super-primes is [[Small set (combinatorics)|small]].

One can also define "higher-order" primeness much the same way and obtain analogous sequences of primes {{harv|Fernandez|1999}}.

A variation on this theme is the sequence of prime numbers with [[palindromic prime]] indices, beginning with
:3, 5, 11, 17, 31, 547, 739, 877, 1087, 1153, 2081, 2381, ... {{OEIS|id=A124173}}.

==References==
*{{citation | last1 = Bayless | first1 = Jonathan | last2 = Klyve | first2 = Dominic | last3 = Oliveira e Silva | first3 = Tomás | journal = Integers | mr = 3097157 | pages = A43:1–A43:21 | title = New bounds and computations on prime-indexed primes | volume = 13 | year = 2013}}
*{{citation
 | last1 = Broughan | first1 = Kevin A.
 | last2 = Barnett | first2 = A. Ross
 | journal = [[Journal of Integer Sequences]]
 | at = article 09.2.3
 | title = On the subsequence of primes having prime subscripts
 | url = http://www.cs.uwaterloo.ca/journals/JIS/VOL12/Broughan/broughan16.html
 | volume = 12
 | year = 2009}}.
*{{citation
 | first1 = Robert E. | last1 = Dressler
 | first2 = S. Thomas | last2 = Parker
 | title = Primes with a prime subscript
 | journal = [[Journal of the ACM]]
 | volume = 22 
 | issue = 3 
 | year = 1975 
 | pages = 380–381
 | doi = 10.1145/321892.321900
 | mr = 0376599}}.
*{{citation
 | first1 =Neil | last1 = Fernandez
 | title = An order of primeness, F(p)
 | url = http://borve.org/primeness/FOP.html 
 | year = 1999}}.

==External links==
*[http://acm.sgu.ru/problem.php?contest=0&amp;problem=116 A Russian programming contest problem related to the work of Dressler and Parker]

{{Prime number classes}}

[[Category:Classes of prime numbers]]

{{numtheory-stub}}</text>
      <sha1>cu7hqm1e3cjik1fle21aswwnv9z3kg5</sha1>
    </revision>
  </page>
  <page>
    <title>Symmetry of second derivatives</title>
    <ns>0</ns>
    <id>412094</id>
    <revision>
      <id>845163990</id>
      <parentid>843210784</parentid>
      <timestamp>2018-06-09T21:27:03Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13980">In [[mathematics]], the '''symmetry of second derivatives''' (also called the '''equality of mixed partials''') refers to the possibility under certain conditions (see below) of interchanging the order of taking [[partial derivative]]s of a function

:&lt;math&gt;f(x_{1},x_{2}, \dots ,x_{n})&lt;/math&gt;

of ''n'' variables. If the partial derivative with respect to &lt;math&gt;x_{i}&lt;/math&gt; is denoted with a subscript &lt;math&gt;i&lt;/math&gt;, then the symmetry is the assertion that the second-order partial derivatives &lt;math&gt;f_{ij}&lt;/math&gt; satisfy the identity

:&lt;math&gt;f_{ij}=f_{ji}&lt;/math&gt;

so that they form an ''n'' × ''n'' [[symmetric matrix]]. This is sometimes known as '''Schwarz's theorem''', '''Clairaut's theorem''', or '''Young's theorem'''.&lt;ref&gt;{{cite web |url=http://are.berkeley.edu/courses/ARE210/fall2005/lecture_notes/Young%27s-Theorem.pdf |title=Archived copy |accessdate=2015-01-02 |deadurl=yes |archiveurl=https://web.archive.org/web/20060518134739/http://are.berkeley.edu/courses/ARE210/fall2005/lecture_notes/Young%27s-Theorem.pdf |archivedate=May 18, 2006 |df= }}&lt;/ref&gt;&lt;ref&gt;{{cite book |last=Allen |first=R. G. D. |title=Mathematical Analysis for Economists |location=New York |publisher=St. Martin's Press |year=1964 |isbn= |pages=300–305 |url=https://books.google.com/books?id=fgm9O6reUcsC&amp;pg=PA300 }}&lt;/ref&gt;

In the context of [[partial differential equation]]s it is called the
'''Schwarz [[integrability conditions for differential systems|integrability]] condition'''. &lt;!-- In physics, however, it is important
for the understanding of many phenomena in nature to remove this restrictions and allow functions to violate the
Schwarz integrability criterion, which makes them multivalued.
The simplest example is the function
&lt;math&gt;\arctan\; y/x&lt;/math&gt;. At first one defines this with a cut
in the complex
&lt;math&gt;(x,y)&lt;/math&gt;-plane running from 0 to infinity.
The cut makes the function single-valued. In complex analysis, however, one thinks of this function as having several 'sheets' (forming a [[Riemann surface]]).
 It is useless until they explain where and how the function violates Schwarz integrability condition --&gt;

== Hessian matrix ==

This matrix of second-order partial derivatives of ''f'' is called the '''[[Hessian matrix]]''' of ''f''. The entries in it off the [[main diagonal]] are the '''mixed derivatives'''; that is, successive partial derivatives with respect to different variables.

In most "real-life" circumstances the Hessian matrix is [[symmetric matrix|symmetric]], although there are a great number of functions that do not have this property. [[Mathematical analysis]] reveals that symmetry requires a hypothesis on ''f'' that goes further than simply stating the existence of the second derivatives at a particular point. [[#Schwarz's theorem|Schwarz' theorem]] gives a sufficient condition on ''f'' for this to occur.

== Formal expressions of symmetry ==
In symbols, the symmetry says that, for example,

:&lt;math&gt;\frac {\partial}{\partial x} \left( \frac { \partial f }{ \partial y} \right) =
       \frac {\partial}{\partial y} \left( \frac { \partial f }{ \partial x} \right).&lt;/math&gt;

This equality can also be written as

:&lt;math&gt;\partial_{xy} f = \partial_{yx} f.&lt;/math&gt;

Alternatively, the symmetry can be written as an algebraic statement involving the [[differential operator]] ''D''&lt;sub&gt;''i''&lt;/sub&gt; which  takes the partial derivative with respect to ''x''&lt;sub&gt;''i''&lt;/sub&gt;:

:''D''&lt;sub&gt;''i''&lt;/sub&gt; . ''D''&lt;sub&gt;''j''&lt;/sub&gt; = ''D''&lt;sub&gt;''j''&lt;/sub&gt; . ''D''&lt;sub&gt;''i''&lt;/sub&gt;.

From this relation it follows that the [[ring (mathematics)|ring]] of differential operators with [[constant coefficients]], generated by the ''D''&lt;sub&gt;''i''&lt;/sub&gt;, is [[commutative]]. But one should naturally specify some domain for these operators. It is easy to check the symmetry as applied to [[monomial]]s, so that one can take [[polynomial]]s in the ''x''&lt;sub&gt;''i''&lt;/sub&gt; as a domain. In fact [[smooth function]]s are possible.

== Schwarz's theorem&lt;!--'Schwarz's theorem' and 'Clairaut's theorem on equality of mixed partials' redirect here--&gt; ==
In [[mathematical]] [[mathematical analysis|analysis]], '''Schwarz's theorem'''&lt;!--boldface per WP:R#PLA--&gt; (or '''Clairaut's theorem on equality of mixed partials'''&lt;!--boldface per WP:R#PLA--&gt;)&lt;ref&gt;{{cite book |last=James |first=R. C. |year=1966 |title=Advanced Calculus |location=Belmont, CA |publisher=Wadsworth |isbn= |url=https://books.google.com/books?id=d5kpAQAAMAAJ }}&lt;/ref&gt; named after [[Alexis Clairaut]] and [[Hermann Schwarz]], states that if

:&lt;math&gt;f \colon \mathbb{R}^n \to \mathbb{R}&lt;/math&gt;

has [[continuous function|continuous]] second [[partial derivatives]] at a given point in &lt;math&gt; \mathbb{R}^n &lt;/math&gt;, say, &lt;math&gt; (a_1, \dots, a_n),&lt;/math&gt; then &lt;math&gt;\forall i, j \in \{ 1,2,\ldots, n\},&lt;/math&gt;

:&lt;math&gt;\frac{\partial^2 f}{\partial x_i\, \partial x_j}(a_1, \dots, a_n) = \frac{\partial^2 f}{\partial x_j\, \partial x_i}(a_1, \dots, a_n).&lt;/math&gt;

The partial differentiations of this function are [[commutative operation|commutative]] at that point. One easy way to establish this theorem (in the case where &lt;math&gt;n = 2&lt;/math&gt;, &lt;math&gt;i = 1&lt;/math&gt;, and &lt;math&gt;j = 2&lt;/math&gt;, which readily entails the result in general) is by applying [[Green's theorem]] to the [[gradient]] of &lt;math&gt;f.&lt;/math&gt;

== Sufficiency of twice-differentiability ==
A weaker condition than the continuity of second partial derivatives (which is implied by the latter) which suffices to ensure symmetry is that all partial derivatives are themselves [[Differentiable function#Differentiability in higher dimensions|differentiable]].&lt;ref&gt;{{cite book|last1=Hubbard|first1=John|last2=Hubbard|first2=Barbara|title=Vector Calculus, Linear Algebra and Differential Forms|publisher=Matrix Editions|pages=732–733|edition=5th}}&lt;/ref&gt; Another strengthening of the theorem, in which ''existence'' of the permuted mixed partial is asserted, was provided by Peano:

''If &lt;math&gt;f:E\to \mathbb{R}&lt;/math&gt; is defined on an open set &lt;math&gt;E\subset \R^2&lt;/math&gt; and &lt;math&gt;D_1f, D_2f, D_{2,1}f&lt;/math&gt; exist everywhere on &lt;math&gt;E&lt;/math&gt; , and &lt;math&gt;D_{2,1}f&lt;/math&gt; is continuous at &lt;math&gt;(a,b)\in E&lt;/math&gt;, then &lt;math&gt;D_{1,2}f&lt;/math&gt; exists at &lt;math&gt;(a,b)&lt;/math&gt; and &lt;math&gt;D_{1,2}f(a,b)=D_{2,1}f(a,b)&lt;/math&gt;.''&lt;ref&gt;{{Cite book|url=https://archive.org/details/1979RudinW|title=Principles of Mathematical Analysis|last=Rudin|first=Walter|publisher=McGraw-Hill|year=1976|isbn=0-07-054235-X|location=New York|pages=235-236}}&lt;/ref&gt;

== History ==
The result of the equality of the mixed partial derivatives under certain conditions has a long history.  [[Nicolaus I Bernoulli]] implicitly assumed the result as early as 1721, but [[Euler]] was the first to provide a proof.  Other proofs followed by [[Alexis Clairaut|Clairaut]] (1740), [[Lagrange]] (1797), [[Cauchy]] (1823) and many others in the 19th century.  None of these proofs were without fault however (for example, Clairaut assumed all definite integrals could be differentiated under the integral sign).  In 1867 [[Ernst Leonard Lindelöf]] published a paper&lt;ref&gt;{{cite journal|last1=Lindelöf|first1=Ernst Leonard|title=Remarques sur les différentes manières d'établir la formule &lt;math&gt;\frac{d^2 z}{d xd y} = \frac{d^2 z}{d yd x}&lt;/math&gt;|journal=Acta Societatis Scientiarum Fennicae|date=1867|volume=8, part 1|pages=205–213|url=https://archive.org/stream/actasocietatissc81suom#page/205/mode/2up}}&lt;/ref&gt; criticizing in detail all the proofs he was familiar with.  Finally, six years later [[Hermann Schwarz]] (1873) gave the first satisfactory proof. This was followed by successive refinements that relaxed the hypotheses in Schwarz's theorem in various ways, among others by [[Ulisse Dini|Dini]], [[Camille Jordan|Jordan]], [[Peano]], [[E. W. Hobson]], [[W. H. Young]]. For a good historical account, see.&lt;ref&gt;{{cite journal|last1=Higgins|first1=Thomas James|title=A note on the history of mixed partial derivatives|journal=Scripta Mathematica|date=1940|volume=7|pages=59–62|url=http://mathforum.org/kb/thread.jspa?forumID=13&amp;threadID=1580215&amp;messageID=5765194|accessdate=19 April 2017}}&lt;/ref&gt;

== Distribution theory formulation ==

The theory of [[distribution (mathematics)|distributions]] (generalized functions) eliminates analytic problems with the symmetry. The derivative of an [[integrable]] function can always be defined as a distribution, and symmetry of mixed partial derivatives always holds as an equality of distributions. The use of formal [[integration by parts]] to define differentiation of distributions puts the symmetry question back onto the [[test function]]s, which are smooth and certainly satisfy this symmetry. In more detail (where ''f'' is a distribution, written as an operator on test functions, and ''φ'' is a test function),
: &lt;math&gt; (D_1D_2f)[\phi] = -(D_2f)[D_1\phi] = f[D_2D_1\phi] = f[D_1D_2\phi] = -(D_1f)[D_2\phi] = (D_2D_1f)[\phi] .&lt;/math&gt;

Another approach, which defines the [[Fourier transform]] of a function, is to note that on such transforms partial derivatives become multiplication operators that commute much more obviously.

== Requirement of continuity ==
The symmetry may be broken if the function fails to have differentiable partial derivatives, which is possible if Clairaut's theorem is not satisfied (the second partial derivatives are not [[Continuous function|continuous]]).

[[File:Graph001.png|thumb|right|The function ''f(x,y)'', as shown in equation ({{EquationNote|1}}), does not have symmetric second derivatives at its origin.]]
An example of non-symmetry is the function
{{NumBlk|:|&lt;math&gt;f(x,y) = \begin{cases}
                     \frac{xy(x^2 - y^2)}{x^2+y^2} &amp; \mbox{ for } (x, y) \ne (0, 0)\\
                      0                            &amp; \mbox{ for } (x, y) = (0, 0).
                \end{cases}&lt;/math&gt;|{{EquationRef|1}}}}
This function is everywhere continuous, but its derivatives at (0,0) cannot be computed algebraically. Rather, the limit of difference quotients shows that &lt;math&gt;\partial_x f|_{(0,0)}=\partial_y f|_{(0,0)} = 0&lt;/math&gt;, so the graph z = f(x,y) has a horizontal tangent plane at (0,0), and the partial derivatives &lt;math&gt;\partial_x f, \partial_y f&lt;/math&gt; exist and are everywhere continuous. However, the second partial derivatives are not continuous at (0,0), and the symmetry fails. In fact, along the ''x''-axis the ''y''-derivative is &lt;math&gt;\partial_y f|_{(x,0)}=x&lt;/math&gt;, and so:
:&lt;math&gt;\partial_x\partial_y f|_{(0,0)} =
\lim_{\epsilon\rightarrow 0} \frac { \partial_y f|_{(\epsilon,0)}-\partial_y f|_{(0,0)} } \epsilon = 1.&lt;/math&gt;
In contrast, along the ''y''-axis the ''x''-derivative &lt;math&gt;\partial_x f|_{(0,y)}=-y&lt;/math&gt;,
and so &lt;math&gt;\partial_y\partial_x f|_{(0,0)} = -1&lt;/math&gt;.
That is, &lt;math&gt;\partial_{xy}f\ne\partial_{yx}f&lt;/math&gt; at (0,&amp;nbsp;0), although the mixed partial derivatives do exist, and at every other point the symmetry does hold.

The above function, written in a cylindrical coordinate system, can be expressed as
:&lt;math&gt;f(r, \theta) = \frac{r^2 \sin{4\theta}}{4},&lt;/math&gt;
showing that the function oscillates four times when traveling once around an arbitrarily small loop containing the origin. Intuitively, therefore, the local behavior of the function at &lt;math&gt;(0, 0)&lt;/math&gt; cannot be described as a quadratic form, and the Hessian matrix thus fails to be symmetric.

In general, the [[interchange of limiting operations]] need not [[Commutative property|commute]]. Given two variables near (0,&amp;nbsp;0) and two limiting processes on
:&lt;math&gt;f(h,k) - f(h,0) - f(0,k) + f(0,0)&lt;/math&gt;
corresponding to making ''h'' → 0 first, and to making ''k'' → 0 first. It can matter, looking at the first-order terms, which is applied first. This leads to the construction of [[Pathological (mathematics)|pathological]] examples in which second derivatives are non-symmetric. This kind of example belongs to the theory of [[real analysis]] where the pointwise value of functions matters.  When viewed as a distribution the second partial derivative's values can be changed at an arbitrary set of points as long as this has Lebesgue measure 0. Since in the example the Hessian is symmetric everywhere except (0,0), there is no contradiction with the fact that the Hessian, viewed as a [[Schwartz distribution]], is symmetric.

== In Lie theory ==
Consider the first-order differential operators ''D''&lt;sub&gt;''i''&lt;/sub&gt; to be [[infinitesimal operator]]s on [[Euclidean space]]. That is, ''D''&lt;sub&gt;''i''&lt;/sub&gt; in a sense generates the [[one-parameter group]] of [[translation]]s parallel to the ''x''&lt;sub&gt;''i''&lt;/sub&gt;-axis. These groups commute with each other, and therefore the [[Lie group#The Lie algebra associated to a Lie group|infinitesimal generators]] do also; the [[Lie bracket]]

:[''D''&lt;sub&gt;''i''&lt;/sub&gt;, ''D''&lt;sub&gt;''j''&lt;/sub&gt;] = 0

is this property's  reflection. In other words, the Lie derivative of one coordinate with respect to another is zero.

== Application to differential forms ==
The Clairaut-Schwarz theorem is the key fact needed to prove that for every &lt;math&gt;C^\infty&lt;/math&gt;(or at least twice continuously differentiable) [[differential form]] &lt;math&gt;\omega\in\Omega^k(M)&lt;/math&gt;, the second exterior derivative vanishes: &lt;math&gt;d^2\omega:=d(d\omega)=0&lt;/math&gt;.  This implies that every [[Exact differential form|exact]] form (i.e., a form &lt;math&gt;\alpha&lt;/math&gt; such that &lt;math&gt;\alpha=d\omega&lt;/math&gt; for some form &lt;math&gt;\omega&lt;/math&gt;) is [[Closed differential form|closed]] (i.e., &lt;math&gt;d\alpha=0&lt;/math&gt;), since &lt;math&gt;d\alpha=d(d\omega)=0&lt;/math&gt;.&lt;ref&gt;{{Cite book|url=https://archive.org/details/TuL.W.AnIntroductionToManifolds2e2010Springer|title=An Introduction to Manifolds|last=Tu|first=Loring W.|publisher=Springer|year=2010|isbn=978-1-4419-7399-3|edition=2nd|location=New York|pages=}}&lt;/ref&gt;

== References ==
{{Reflist}}

== Further reading ==
* {{Springer|id=P/p071620|title=Partial derivative}}

[[Category:Multivariable calculus]]
[[Category:Generalized functions]]
[[Category:Symmetry]]
[[Category:Theorems in analysis]]</text>
      <sha1>ih0j86t5pmsqax0ce43ffumqcp8i3do</sha1>
    </revision>
  </page>
  <page>
    <title>Szegő polynomial</title>
    <ns>0</ns>
    <id>15018472</id>
    <revision>
      <id>859277017</id>
      <parentid>823388898</parentid>
      <timestamp>2018-09-12T23:57:26Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>[[Adhemar Bultheel]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="916">In mathematics, a '''Szegő polynomial''' is one of a family of [[orthogonal polynomials]] for the Hermitian inner product

:&lt;math&gt;\langle f|g\rangle = \int_{-\pi}^{\pi}f(e^{i\theta})\overline{g(e^{i\theta})}\,d\mu&lt;/math&gt;

where d&amp;mu; is a given positive measure on [&amp;minus;&amp;pi;, &amp;pi;]. Writing &lt;math&gt;\phi_n(z)&lt;/math&gt; for the polynomials, they obey a recurrence relation

:&lt;math&gt;\phi_{n+1}(z)=z\phi(z) + \rho_{n+1}\phi^*(z)&lt;/math&gt;

where &lt;math&gt;\rho_{n+1}&lt;/math&gt; is a parameter, called the ''reflection coefficient'' or the ''Szegő parameter''.

== See also ==
* [[Cayley transform]]
* [[Schur class]]
* [[Favard's theorem]]

==References==
*{{springer|title=Szegö polynomial|id=s/s130650|first=A.|last= Bultheel|authorlink= Adhemar Bultheel}}
*[[G. Szegő]], "Orthogonal polynomials", Colloq. Publ., 33, Amer. Math. Soc.  (1967)

{{DEFAULTSORT:Szego polynomial}}
[[Category:Orthogonal polynomials]]


{{math-stub}}</text>
      <sha1>1id7vpiwcyaef2iq8a04ratm1dwleeh</sha1>
    </revision>
  </page>
  <page>
    <title>Toida's conjecture</title>
    <ns>0</ns>
    <id>29249172</id>
    <revision>
      <id>805371245</id>
      <parentid>665947495</parentid>
      <timestamp>2017-10-14T22:56:16Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* top */clean up |journal= parameter per [[User:JCW-CleanerBot#Logic|task]], replaced: J. of → Journal of, added [[CAT:O|orphan]] tag using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1611">{{Orphan|date=October 2017}}

In [[combinatorics|combinatorial]] mathematics, '''Toida's conjecture''', due to [[Shunichi Toida]] in 1977,&lt;ref&gt;*S. Toida: "A note on Adam's conjecture", Journal of Combinatorial Theory (B), pp. 239–246, October–December 1977&lt;/ref&gt; is a refinement of the disproven [[Ádám's conjecture]] in 1967.  Toida's conjecture states formally:

If

:''S'' is a subset of &lt;math&gt;\mathbb{Z}^*_n&lt;/math&gt;

and

:&lt;math&gt; \vec{X} = \vec{X}( \mathbb{Z}_n ; S )&lt;/math&gt;

then ''&lt;math&gt;\vec{X}&lt;/math&gt;'' is a CI-digraph.

==Proofs==

The conjecture was proven in the special case where ''n'' is a prime power by Klin and Poschel in 1978,&lt;ref&gt;*Klin, M.H. and R. Poschel: The Konig problem, the isomorphism problem for cyclic graphs and the method of Schur rings, Algebraic methods in graph theory, Vol. I, II., Szeged, 1978, pp. 405–434.&lt;/ref&gt; and by Golfand, Najmark, and Poschel in 1984.&lt;ref&gt;*Golfand, J.J., N.L. Najmark and R. Poschel: The structure of S-rings over Z2m , preprint (1984).&lt;/ref&gt;

The conjecture was then fully proven by Muzychuk, Klin, and Poschel in 2001 by using [[Schur algebra]],&lt;ref&gt;Klin, M.H., M. Muzychuk and R. Poschel: The isomorphism problem for circulant graphs via Schur ring theory, Codes and Association Schemes, American Math. Society, 2001.&lt;/ref&gt; and simultaneously by Dobson and Morris in 2002 by using the [[classification of finite simple groups]].&lt;ref&gt;*E. Dobson, J. Morris: TOIDA’S CONJECTURE IS TRUE, PhD Thesis, 2002.&lt;/ref&gt;

==Notes==
{{reflist}}

{{DEFAULTSORT:Toida's Conjecture}}
[[Category:Combinatorics]]
[[Category:Conjectures]]


{{numtheory-stub}}</text>
      <sha1>t7onzmz3hfw3fj0u1gmyx82sby0n02q</sha1>
    </revision>
  </page>
  <page>
    <title>Tomahawk (geometry)</title>
    <ns>0</ns>
    <id>1735473</id>
    <revision>
      <id>823551283</id>
      <parentid>823550261</parentid>
      <timestamp>2018-02-01T23:03:14Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 823550261 by [[Special:Contributions/No identd|No identd]] ([[User talk:No identd|talk]]) per [[WP:SEEALSO]] — we should not be listing items that are already prominently linked in the main article text</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9208">[[File:Tomahawk filled.svg|thumb|right|A tomahawk, with its handle and spike thickened]]
The '''tomahawk''' is a tool in [[geometry]] for [[angle trisection]], the problem of splitting an [[angle]] into three equal parts. The boundaries of its shape include a [[semicircle]] and two [[line segment]]s, arranged in a way that resembles a [[Tomahawk (axe)|tomahawk]], a Native American axe.&lt;ref name="yates"/&gt;&lt;ref name="gardner"/&gt; The same tool has also been called the '''shoemaker's knife''',&lt;ref name="dudley"&gt;{{citation|title=The Trisectors|series=MAA Spectrum|first=Underwood|last=Dudley|authorlink=Underwood Dudley|edition=2nd|publisher=Cambridge University Press|year=1996|isbn=9780883855140|pages=14–16}}.&lt;/ref&gt; but that name is more commonly used in geometry to refer to a different shape, the [[arbelos]] (a curvilinear triangle bounded by three mutually tangent semicircles).&lt;ref&gt;{{citation|title=Charming Proofs: A Journey Into Elegant Mathematics|volume=42|series=Dolciani Mathematical Expositions|first1=Claudi|last1=Alsina|first2=Roger B.|last2=Nelsen|publisher=Mathematical Association of America|year=2010|isbn=9780883853481|contribution=9.4 The shoemaker's knife and the salt cellar|pages=147–148}}.&lt;/ref&gt;

==Description==
The basic shape of a tomahawk consists of a semicircle (the "blade" of the tomahawk), with a line segment the length of the radius extending along the same line as the diameter of the semicircle (the tip of which is the "spike" of the tomahawk), and with another line segment of arbitrary length (the "handle" of the tomahawk) perpendicular to the diameter. In order to make it into a physical tool, its handle and spike may be thickened, as long as the line segment along the handle continues to be part of the boundary of the shape.  Unlike a related trisection using a [[Steel square|carpenter's square]], the other side of the thickened handle does not need to be made parallel to this line segment.&lt;ref name="yates"&gt;{{citation
 | last = Yates | first = Robert C.
 | issue = 6
 | journal = National Mathematics Magazine
 | jstor = 3028413
 | mr = 1569903
 | pages = 278–293
 | title = The Trisection Problem, Chapter III: Mechanical trisectors
 | volume = 15
 | year = 1941}}.&lt;/ref&gt;

In some sources a full circle rather than a semicircle is used,&lt;ref name="meserve"/&gt; or the tomahawk is also thickened along the diameter of its semicircle,&lt;ref name="isaacs"/&gt;  but these modifications make no difference to the action of the tomahawk as a trisector.

==Trisection==
[[File:Tomahawk2.svg|thumb|right|300px|A tomahawk [[trisecting an angle]]. The handle ''AD'' forms one trisector and the dotted line ''AC'' to the center of the semicircle forms the other.]]
To use the tomahawk to trisect an angle, it is placed with its handle line touching the apex of the angle, with the blade inside the angle, tangent to one of the two rays forming the angle, and with the spike touching the other ray of the angle. One of the two trisecting lines then lies on the handle segment, and the other passes through the center point of the semicircle.&lt;ref name="yates"/&gt;&lt;ref name="isaacs"&gt;{{citation|title=Geometry for College Students|volume=8|series=Pure and Applied Undergraduate Texts|first=I. Martin|last=Isaacs|publisher=American Mathematical Society|year=2009|isbn=9780821847947|pages=209–210}}.&lt;/ref&gt; If the angle to be trisected is too sharp relative to the length of the tomahawk's handle, it may not be possible to fit the tomahawk into the angle in this way, but this difficulty may be worked around by repeatedly doubling the angle until it is large enough for the tomahawk to trisect it, and then repeatedly bisecting the trisected angle the same number of times as the original angle was doubled.&lt;ref name="gardner"&gt;{{citation|first=Martin|last=Gardner|authorlink=Martin Gardner|title=Mathematical Carnival: from penny puzzles, card shuffles and tricks of lightning calculators to roller coaster rides into the fourth dimension|pages=262–263|publisher=Knopf|year=1975}}.&lt;/ref&gt;

If the apex of the angle is labeled ''A'', the point of tangency of the blade is ''B'', the center of the semicircle is ''C'', the top of the handle is ''D'', and the spike is ''E'', then triangles ''ACD'' and ''ADE'' are both right triangles with a shared base and equal height, so they are [[congruent triangles]]. Because the sides ''AB'' and ''BC'' of triangle ''ABC'' are respectively a tangent and a radius of the semicircle, they are at right angles to each other and ''ABC'' is also a right triangle; it has the same hypotenuse as ''ACD'' and the same side lengths ''BC''&amp;nbsp;=&amp;nbsp;''CD'', so again it is congruent to the other two triangles, showing that the three angles formed at the apex are equal.&lt;ref name="meserve"&gt;{{citation|title=Fundamental Concepts of Algebra|first=Bruce E.|last=Meserve|publisher=Courier Dover Publications|year=1982|isbn=9780486614700|page=244|url=https://books.google.com/books?id=qtuySdnGDtoC&amp;pg=PA244}}.&lt;/ref&gt;&lt;ref name="isaacs"/&gt;

Although the tomahawk may itself be constructed using a [[compass and straightedge]],&lt;ref&gt;{{citation|title=College Geometry|first=Howard Whitley|last=Eves|authorlink=Howard Eves|publisher=Jones &amp; Bartlett Learning|year=1995|isbn=9780867204759|page=191|url=https://books.google.com/books?id=B81gnTjNazMC&amp;pg=PA191}}.&lt;/ref&gt; and may be used to trisect an angle, it does not contradict [[Pierre Wantzel]]'s 1837 theorem that arbitrary angles cannot be trisected by compass and unmarked straightedge alone.&lt;ref&gt;{{citation
 | last = Wantzel | first = L. | author-link = Pierre Wantzel
 | issue = 2
 | journal = Journal de Mathématiques Pures et Appliquées
 | pages = 366–372
 | title = Recherches sur les moyens de reconnaître si un Problème de Géométrie peut se résoudre avec la règle et le compas
 | url = http://visualiseur.bnf.fr/ConsulterElementNum?O=NUMM-16381&amp;Deb=374&amp;Fin=380&amp;E=PDF
 | volume = 1
 | year = 1837
 | language=French}}.&lt;/ref&gt; The reason for this is that placing the constructed tomahawk into the required position is a form of [[Neusis construction|neusis]] that is not allowed in compass and straightedge constructions.&lt;ref&gt;The word "neusis" is described by {{citation
 | last1 = La Nave | first1 = Federica
 | last2 = Mazur | first2 = Barry | author2-link = Barry Mazur
 | doi = 10.1007/BF03025306
 | issue = 1
 | journal = The Mathematical Intelligencer
 | mr = 1889932
 | pages = 12–21
 | title = Reading Bombelli
 | volume = 24
 | year = 2002}} as meaning "a family of constructions dependent  upon  a  single  parameter" in which, as the parameter varies, some combinatorial change in the construction occurs at the desired parameter value. La Nave and Mazur describe other trisections than the tomahawk, but the same description applies here: a tomahawk placed with its handle on the apex, parameterized by the position of the spike on its ray, gives a family of constructions in which the relative positions of the blade and its ray change as the spike is placed at the correct point.&lt;/ref&gt;

==History==
The inventor of the tomahawk is unknown,&lt;ref name="yates"/&gt;&lt;ref&gt;{{citation|title=Episodes from the Early History of Mathematics|volume=13|series=New Mathematical Library|first=Asger|last=Aaboe|authorlink=Asger Aaboe|publisher=Mathematical Association of America|year=1997|isbn=9780883856130|page=87|url=https://books.google.com/books?id=5wGzF0wPFYgC&amp;pg=PA87}}.&lt;/ref&gt; but the earliest references to it come from 19th-century France.  It dates back at least as far as 1835, when it appeared in a book by [[Claude Lucien Bergery]], ''Géométrie appliquée à l'industrie, à l'usage des artistes et des ouvriers'' (3rd edition).&lt;ref name="yates"/&gt; Another early publication of the same trisection was made by [[Henri Brocard]] in 1877;&lt;ref&gt;{{citation|first=H.|last=Brocard|authorlink=Henri Brocard|title=Note sur la division mécanique de l'angle|journal=Bulletin de la Société Mathématique de France|volume=5|year=1877|pages=43–47|language=French|url=http://www.numdam.org/item?id=BSMF_1877__5__43_1}}.&lt;/ref&gt; Brocard in turn attributes its invention to an 1863 memoir by French naval officer Pierre-Joseph Glotin.&lt;ref&gt;{{citation|last=Glotin|title=De quelques moyens pratiques de diviser les angles en parties égales|journal=Mémoires de la Société des Sciences physiques et naturelles de Bordeaux|year=1863|url=https://books.google.com/books?id=FQ9_wRdXYXUC&amp;pg=PA253|pages=253–278|language=French|volume=2}}.&lt;/ref&gt;&lt;ref&gt;{{citation|url=http://math.albany.edu/pers/preface.html |title=PREFACE to Geometric Constructions |author=George E. Martin |year=1998}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Dudley|1996}} incorrectly writes these names as Bricard and Glatin.&lt;/ref&gt;

==References==
{{reflist|30em}}

==External links==
*[http://www.takayaiwamoto.com/Greek_Math/Trisect/Special_Tools/Tomahawk.html Trisection using special tools: "Tomahawk"], Takaya Iwamoto, 2006, featuring a tomahawk tool made from transparent vinyl and comparisons for accuracy against other trisectors
*{{mathworld|title=Tomahawk|urlname=Tomahawk}}
*[https://commons.wikimedia.org/wiki/File:01-Siebeneck-Tomahawk-Animation.gif Construction heptagon with tomahawk, animation]

[[Category:Mathematical tools]]</text>
      <sha1>j6ol2pzgeibzr3wa489f5b1pmaes349</sha1>
    </revision>
  </page>
  <page>
    <title>Tractor bundle</title>
    <ns>0</ns>
    <id>5803388</id>
    <revision>
      <id>527492719</id>
      <parentid>522437486</parentid>
      <timestamp>2012-12-11T08:42:39Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>clean up, References after punctuation per [[WP:REFPUNC]] and [[WP:CITEFOOT]] using [[Project:AWB|AWB]] (8792)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1166">In [[conformal geometry]], the '''tractor bundle''' is a particular [[vector bundle]] constructed on a [[conformal manifold]] whose fibres form an [[group action|effective]] [[group representation|representation]] of the [[conformal group]]  (see [[associated bundle]]).  

The term ''tractor'' is a [[portmanteau]] of "Tracy Thomas" and "twistor", the bundle having been introduced first by [[T. Y. Thomas]] as an alternative formulation of the [[Cartan connection|Cartan]] [[conformal connection]],&lt;ref&gt;Thomas, T. Y., "On conformal differential geometry", ''Proc. N.A.S.'' '''12''' (1926), 352–359; "Conformal tensors", Proc. N.A.S. '''18''' (1931), 103–189.&lt;/ref&gt; and later rediscovered within the formalism of [[local twistor]]s and generalized to [[projective connection]]s by [[Michael Eastwood]] ''et al.'' in &lt;ref&gt;Bailey, T. N.; Eastwood, M. G.; Gover, A. R., "Thomas's structure bundle for conformal, projective and related structures", ''Rocky Mountain J.'' '''24''' (1994), 1191–1217.&lt;/ref&gt;

==References==
&lt;references/&gt;

[[Category:Differential geometry]]
[[Category:Conformal geometry]]
[[Category:Vector bundles]]


{{differential-geometry-stub}}</text>
      <sha1>qme8w8cv6s7cqtv25apwy70bnu5fwu4</sha1>
    </revision>
  </page>
</mediawiki>
