<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Alicia Dickenstein</title>
    <ns>0</ns>
    <id>46808043</id>
    <revision>
      <id>866807343</id>
      <parentid>863597971</parentid>
      <timestamp>2018-11-01T17:48:17Z</timestamp>
      <contributor>
        <username>Lesnail</username>
        <id>635323</id>
      </contributor>
      <comment>AMS Fellow</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3633">'''Alicia Dickenstein''' (born 17 January 1955, in [[Buenos Aires]]) is an [[Argentina|Argentine]] [[Mathematics|mathematician]] known for her work on [[algebraic geometry]], particularly [[toric geometry]] and [[tropical geometry]]. Currently, she is full professor at the [[University of Buenos Aires]] and serves as vice-president of the [[International Mathematical Union]] (2015–2018 term). Her book ''[https://books.google.com/books?id=JXZnzsCs3AwC Mate max: la matemática en todas partes]'' presents [[mathematical problem]]s destined to young children.&lt;ref&gt;[http://www.mathunion.org/fileadmin/IMU/EC/2015-2018/CV-EC03-DICKENSTEIN-Alicia.pdf Bio information from IMU]&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.europeanwomeninmaths.org/women-in-math/portrait/alicia-dickenstein |title=Alicia Dickenstein &amp;#124; European Women in Mathematics |publisher=Europeanwomeninmaths.org |date= |accessdate=2015-05-26}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.mathunion.org/organization/ec/ec-2015-2018/ |title=International Mathematical Union (IMU): EC 2015-2018 |publisher=Mathunion.org |date= |accessdate=2015-05-26 |archive-url=https://web.archive.org/web/20150524232645/http://www.mathunion.org/organization/ec/ec-2015-2018/ |archive-date=2015-05-24 |dead-url=yes |df= }}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www2.warwick.ac.uk/fac/cross_fac/ias/current/visitingfellows/0910alphabetaorder/dickenstein/ |title=Professor Alicia Dickenstein |publisher=.warwick.ac.uk |date=2015-03-20 |accessdate=2015-05-26}}&lt;/ref&gt;&lt;ref&gt;[https://www.ems-ph.org/journals/newsletter/pdf/2012-06-84.pdf Newsletter European Mathematical Society June 2012 Issue 84]&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.sigsam.org/bulletin/articles/190/CCA-190-Full.pdf |title=ACM Communications in Computer Algebra, Vol. 48, No. 4, Issue 190, December 2014 |access-date=2015-05-26 |archive-url=https://web.archive.org/web/20150527010037/http://www.sigsam.org/bulletin/articles/190/CCA-190-Full.pdf |archive-date=2015-05-27 |dead-url=yes |df= }}&lt;/ref&gt;

Dickenstein obtained her Ph.D. from the [[Universidad de Buenos Aires]] in 1982.&lt;ref&gt;{{MathGenealogy|id=152195|title=Alicia Dickenstein}}&lt;/ref&gt; She received the [[TWAS Prize]] in 2015.&lt;ref name="Prizes and Awards"&gt;{{Cite web |url=http://twas.org/article/winners-2015-twas-prizes-announced |title=Prizes and Awards |date=2016 |publisher=The World Academy of Sciences}}&lt;/ref&gt;
She is editor-in-chief of the journal ''Revista de la Unión Matemática Argentina''.&lt;ref&gt;{{citation|url=http://inmabb.criba.edu.ar/revuma/revuma.php?p=board|title=Editorial board|journal=Revista de la Unión Matemática Argentina|accessdate=2018-08-08}}&lt;/ref&gt; In 2018, Dickenstein was elected as a [[Fellow]] of the [[American Mathematical Society]] for "contributions to computational algebra and its applications, especially in systems biology, and for global leadership in supporting underrepresented groups in mathematics."&lt;ref&gt;[http://www.ams.org/profession/ams-fellows/new-fellows Class of the Fellows of the AMS], accessed November 1, 2018.&lt;/ref&gt; 

== References ==
{{reflist}}

== External links ==
*[http://mate.dm.uba.ar/~alidick/ UBA – Alicia Dickenstein]
*[https://scholar.google.com/citations?user=GPut4c0AAAAJ&amp;hl=en Google Scholar – Alicia Dickenstein]

{{authority control}}

{{DEFAULTSORT:Dickenstein, Alicia}}
[[Category:Living people]]
[[Category:1955 births]]
[[Category:Argentine mathematicians]]
[[Category:University of Buenos Aires faculty]]
[[Category:Women mathematicians]]
[[Category:People from Buenos Aires]]
[[Category:Algebraic geometers]]
[[Category:TWAS laureates]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>8evsav85cmoxdu7nxtax549nklhpylm</sha1>
    </revision>
  </page>
  <page>
    <title>Andrew Beal</title>
    <ns>0</ns>
    <id>1395328</id>
    <revision>
      <id>837244912</id>
      <parentid>836661776</parentid>
      <timestamp>2018-04-19T16:20:39Z</timestamp>
      <contributor>
        <username>Red Director</username>
        <id>1261736</id>
      </contributor>
      <minor/>
      <comment>link [[Daniel Negreanu]] using [[:en:User:Edward/Find link|Find link]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15953">{{about|the banker|the musician|King 810}}
{{Infobox person
| name        = Andrew Beal
| birth_name  = Daniel Andrew Beal
| birth_date  = {{Birth date and age| 1952|11|29}}
| birth_place = [[Lansing, Michigan]], U.S.
| ethnicity   =
| occupation  = Banker, businessman, investor, poker player, mathematician
| spouse      = Simona Beal (div.)
| children    = 6
| website     = http://www.andrewbeal.com
| known for   = Founder and chairman, Beal Bank and Beal Bank USA
| networth    = US$11.6 billion (April 2018)&lt;ref name="antoinegara"&gt;{{cite web|url=https://www.forbes.com/profile/andrew-beal/?list=forbes-400|title=Andrew Beal|author=Antoine Gara|work=Forbes}}&lt;/ref&gt;&lt;ref name="forb_Andr_current"&gt;{{Cite web| title = Andrew Beal| work = Forbes| accessdate = 2017-05-08| url = https://www.forbes.com/profile/andrew-beal/}}&lt;/ref&gt;
}}

'''Daniel Andrew "Andy" Beal''' (born November 29, 1952&lt;ref&gt;''U.S. Public Records Index'', Vol 1 &amp; 2 (Provo, UT: Ancestry.com Operations, Inc.), 2010.&lt;/ref&gt;) is an American banker, businessman, investor, poker player, and amateur mathematician. He is a Dallas-based businessman who accumulated wealth in real estate and banking. Born and reared in [[Lansing, Michigan]], Beal is founder and chairman of [[Beal Bank]] and Beal Bank USA, as well as other affiliated companies. Beal has an estimated worth of US$11.6 billion as of April 2018.&lt;ref name="antoinegara"/&gt;&lt;ref name="forb_Andr_current"/&gt;

A [[Number theory|number theorist]], Beal is also known for the [[Beal conjecture]],&lt;ref&gt;{{cite web|url=http://www.bealconjecture.com/|title=index|work=bealconjecture.com}}&lt;/ref&gt; a mathematical generalization of [[Fermat's Last Theorem]]. He has funded a $1 million standing prize for its proof or disproof.&lt;ref&gt;{{cite web|url=http://www.math.unt.edu/~mauldin/beal.html|title=The Beal Conjecture|work=unt.edu}}&lt;/ref&gt; His banks sponsor two annual science and technology fairs affiliated with the International Science &amp; Engineering Fair.&lt;ref&gt;{{cite web|url=http://www.societyforscience.org/isef/|title=Intel ISEF|work=Student Science}}&lt;/ref&gt; Beal participated in some high-stakes poker games in the mid-2000s that were the subject of a book.&lt;ref name="auto"&gt;{{cite web|last=Fletcher|first=Irwin|title=Andy Beal Versus the Corporation|publisher=Poker News|date=24 February 2006|accessdate=September 30, 2006| url=http://www.pokernews.com/news/2006/2/beal-corporation-finished.htm| archiveurl= https://web.archive.org/web/20061109032906/http://www.pokernews.com/news/2006/2/beal-corporation-finished.htm| archivedate= 9 November 2006 &lt;!--DASHBot--&gt;| deadurl= no}}&lt;/ref&gt;

== Background ==
Beal grew up in [[Lansing, Michigan]], where his mother worked in state government and his father was a mechanical engineer. His siblings include an older brother and a younger sister.&lt;ref&gt;{{cite web|url=http://www.dallasnews.com/business/headlines/20100221-Beal-Bank-owner-paved-his-own-2879.ece|title=Beal Bank owner paved his own road to becoming Dallas' richest man|work=dallasnews.com}}&lt;/ref&gt; As a teenager, Beal began earning money by fixing and reselling used televisions with the help of his uncle. While attending high school he also installed apartment security systems. He also started a business moving houses and managed rental properties.&lt;ref&gt;{{cite news| url=https://www.wsj.com/article/SB110556884311724524-search.html | newspaper=The Wall Street Journal | title=Maverick Banker In Texas Chases Distressed Assets | date=January 13, 2005 | first=George | last=Anders|authorlink=George Anders}}&lt;/ref&gt;

==Education==
Beal excelled on his high school debate team at [[J. W. Sexton High School|Lansing Sexton High School]] and went on to enroll at [[Michigan State University]], where he studied mathematics.

==Business ventures and investments==

===Real estate investing===
At age 19, Beal became a [[real estate investor]], where he bought a house in Lansing for $6,500 and started leasing it for $119 per month. Beal became known for buying properties, renovating them and selling them. In 1976, he attended an auction of federal properties in Washington, DC and bid on an apartment building in Waco, TX. His winning bid was $217,500. Three years later he sold the building for more than $1 million. Also in 1976, he enrolled at [[Baylor University]] in Waco, TX, but left school to focus on business endeavors.

In 1981, Beal and a partner bought two housing project buildings in disrepair, the [[Brick Towers]] in [[Newark, New Jersey]], for $25,000. Two years later they sold the repaired buildings for $3.2 million to a private investor.

===Beal Bank and Beal Bank USA===
In 1988, Beal opened a bank in Dallas, and in 2004 another in Las Vegas. Since then, the banks have purchased financial assets and held them as the market improved. The Banks’ purchases have included:

*Power generation and infrastructure bonds during the post-Enron California rolling blackouts and energy-deregulation crisis in 2001
*Debt instruments backed by aircraft after the 9/11 terrorist attacks on the USA
*Commercial and real estate loans during the global credit crisis of 2008

Based on the Uniform Bank Performance Report from the Federal Financial Institutions Examination Council,&lt;ref&gt;{{cite web|url=http://www.ffiec.gov/UBPR.htm|title=FFIEC UBPR Home Page|work=ffiec.gov}}&lt;/ref&gt; Beal Bank’s return on assets (ROA) was 8.1 in 2008, several times in excess of its peer group (insured savings banks with assets greater than $1 billion).&lt;ref name="ffiec.gov"&gt;{{cite web|url=https://cdr.ffiec.gov/public/ManageFacsimiles.aspx?ReportType=283|title=View or download data for individual institutions - FFIEC Central Data Repository's Public Data Distribution|work=ffiec.gov}}&lt;/ref&gt; From 2009-2012 Beal Bank generally exceeded its peer group.&lt;ref&gt;White, Martha C. "Five Banks That Don't Suck." Big Money. 10 04 2009: n. page. Web. 4 Sep. 2012.&lt;/ref&gt;

Beal Bank USA's ROA is generally several times in excess of its peer group (insured commercial banks with assets greater than $3 billion).&lt;ref name="ffiec.gov"/&gt;

Beal Bank and Beal Bank USA report combined total capital in excess of $2.9 billion and combined total assets in excess of $9.5 billion as of September 2012.&lt;ref&gt;[http://www.depositaccounts.com/banks/beal-bank.html#health] Financial summary of Beal Bank and Beal Bank USA on banking industry site depositaccounts.com&lt;/ref&gt;

They have a total of 37 branch locations and offer online banking also. Both banks are members of and are insured by the [[Federal Deposit Insurance Corporation]] (FDIC). They offer deposit products to the public including CDs, money market accounts, statement savings accounts, and IRA CD accounts that are insured by the FDIC. Because they do not offer consumer loans or checking accounts, the banks are considered wholesale banks. Both banks purchase pools of non-agency residential first liens and commercial real estate-secured loans in order to fund commercial loans and participations in loans and syndications, through affiliates.

Beal’s major businesses as of 2013 include:
*[[Beal Bank]], based in Dallas
*Beal Bank USA, based in Las Vegas, NV, and founded in August 2004 (formerly Beal Bank Nevada) 
*CSG Investments. Inc.,&lt;ref&gt;{{cite web|url=http://www.csginvestments.com/|title=CSG Investments, Inc. - Home|work=csginvestments.com}}&lt;/ref&gt; based in Dallas
*Loan Acquisition Corporation,&lt;ref&gt;{{cite web|url=http://loanacquisitioncorp.com/|title=Mortgage Loans - Loan Acquisition Corporation - Home|work=loanacquisitioncorp.com}}&lt;/ref&gt; based in Dallas
*CLG Hedge Fund, LLC,&lt;ref&gt;{{cite web|url=http://www.clghedgefund.com/|title=CLG Hedge Fund - Home|work=clghedgefund.com}}&lt;/ref&gt; based in Dallas

===Beal Aerospace===
{{main article|Beal Aerospace}}
In 1997, as part of a space privatization trend encouraged by the federal government, Beal started an aerospace company to build rockets with the goal of placing communications satellites in orbit. Operating with more than 200 employees from a 163,000-square-foot space in [[Frisco, Texas]], Beal Aerospace focused on a three-stage, 200-foot-tall rocket. Powered by hydrogen peroxide and kerosene, the engine eliminated the need for a separate ignition system because, as the hydrogen peroxide oxidized, it ignited the kerosene.

Facing competition from new NASA-funded group initiatives, Beal closed the company and ceased operations on Oct. 23, 2000, citing the difficulty private companies face when competing with the governmental subsidies of NASA.

===Philanthropy===
Through his banks, Beal is an annual title sponsor of:
*The Dallas Regional Science and Engineering Fair,&lt;ref&gt;{{cite web|url=http://drsef.org/|title=The Dallas Regional Science and Engineering Fair|work=The Dallas Regional Science and Engineering Fair}}&lt;/ref&gt; affiliated with [[Southern Methodist University]]  
*The South Nevada Regional Science and Engineering Fair,&lt;ref&gt;{{cite web|url=http://www.unlv.edu/sciences/science-fair|title=Science Fair - College of Sciences - University of Nevada, Las Vegas|work=unlv.edu}}&lt;/ref&gt; affiliated with the [[University of Nevada, Las Vegas]]

Beal has funded more than $1 million in prizes for the events. Both fairs are sanctioned events of the International Science &amp; Engineering Fair, and open to students in grades 6 through 12 with winners moving on to national and international competitions.

Through Beal Bank, Beal also donated $1 million to the Perot Museum of Nature and Science&lt;ref&gt;{{cite web|url=http://www.perotmuseum.org/giving/major-gifts.html|title=Major Gifts|work=Perot Museum of Nature and Science}}&lt;/ref&gt; in Dallas, which opened in December 2012. Beal’s companies donated more than 200 computers to the Dallas Independent School District &lt;ref&gt;{{cite web|url=http://www.dallasisd.org/site/default.aspx?PageID=1|title=Dallas Independent School District / Dallas ISD Home|work=dallasisd.org}}&lt;/ref&gt; for student use.

==Amateur mathematics==
{{main article|Beal conjecture}}

Beal is self-taught in [[number theory]] in mathematics. In 1993, he publicly stated a new mathematical hypothesis that implies [[Fermat's Last Theorem]] as a [[corollary]]. His hypothesis has become known as the Beal Conjecture. No counterexample has been found to the conjecture.

To encourage research on the conjecture, Beal has personally funded a standing prize of $1 million for its proof or disproof. The funds are held in trust by the American Mathematical Society,&lt;ref&gt;{{cite web|url=http://www.ams.org/home/page|title=American Mathematical Society|work=American Mathematical Society}}&lt;/ref&gt; and an informational website on {{cite web| url=http://www.bealconjecture.com|title=the Beal Conjecture}} is hosted by the [[University of North Texas]].&lt;ref&gt;{{cite web|url=http://www.bealconjecture.com|title=index|work=bealconjecture.com}}&lt;/ref&gt;

As of November 2017, the Beal Conjecture prize remains unclaimed.

==Poker playing==
During visits to [[Las Vegas]] between 2001 and 2004, Beal participated in high-stakes poker games against professional players. The games included $100,000 to $200,000 limit Texas Hold 'Em poker. On May 13, 2004, at the Las Vegas [[Bellagio (disambiguation)|Bellagio]], Beal won one of the largest single hands in poker history, $11.7 million.&lt;ref&gt;{{cite book |last=Craig|first=Michael|title=The Professor, the Banker, and the Suicide King|year=2005|pages=231–237}}&lt;/ref&gt; The games have been chronicled in the Michael Craig book, “[[The Professor, the Banker, and the Suicide King]]: Inside the Richest Poker Game of All Time.”

While the games outlined in Craig's book ended in 2004, Beal returned to Las Vegas from February 1–5, 2006 to again take on "The Corporation" in a $50,000/100,000 Limit Hold 'Em match at the [[Wynn Las Vegas]] Casino.  Opponents included [[Todd Brunson]], [[Jennifer Harman]], [[Ted Forrest]], and others.

On February 5, 2006, Beal was down $3.3 million.  He then returned to the Wynn Casino a week later, and won approximately $13.6 million from the Corporation during daily poker sessions from February 12–15.&lt;ref name="CraigBluff"&gt;{{cite journal|last=Craig|first=Michael|title=The Banker, The Boss, The Junk Man, and The Warrior|journal=Bluff Magazine|date=April 2006|pages=71–06}}&lt;/ref&gt;  The games resumed February 21–23, with world champion poker player [[Phil Ivey]] representing the Corporation against Beal at limits of $30,000/60,000 and $50,000/100,000.  During these three days, Beal lost $16.6 million to Ivey.&lt;ref name="auto"/&gt; According to Jennifer Harman, during an interview on Poker Podcast with [[Daniel Negreanu]] on 26 October 2016, she stated that the games went as high as $100,000/200,000.&lt;ref&gt;{{cite web|url=https://soundcloud.com/user-603347096/fcp-podcast-episode-5-featuring-jennifer-harman|title=Negreanu's podcast|work=soundcloud.com/user-603347096}}&lt;/ref&gt;

==Personal life==
Beal has been married twice. He has two children with his first wife.&lt;ref&gt;[http://www.dallasnews.com/business/headlines/20100221-Beal-Bank-owner-paved-his-own-2879.ece Dallas News: "Beal Bank owner paved his own road to becoming Dallas' richest man" by Brendan Case] November 26, 2010&lt;/ref&gt; In 1996,&lt;ref name=DallasNewsDivorce&gt;[http://www.dallasnews.com/business/headlines/20101210-dallas-billionaire-andy-beal_s-divorce-turns-messy.ece Dallas News: "Dallas billionaire Andy Beal's divorce turns messy" By BRENDAN CASE] December 27, 2010&lt;/ref&gt;  he married [[Estonian people|Estonian]]&lt;ref&gt;[http://www.dallasnews.com/entertainment/restaurants/headlines/20120329-power-tables-where-the-elite-hollywood-superstars-eat-in-dallas.ece?ssimg=516354 Dallas News: "Power tables: Where the elite, Hollywood superstars eat in Dallas" by Alan Peppard] March 29, 2012&lt;/ref&gt; immigrant Simona Beal.&lt;ref name=DallasNewsDivorce /&gt; They have four children.&lt;ref name=DallasNewsDivorce /&gt; Simona filed for divorce in 2010.&lt;ref name=DallasNewsDivorce /&gt;

Beal endorsed [[Donald Trump]] for President of the United States in 2016.&lt;ref name="wsjthreefriends"&gt;{{cite news|last1=Ensign|first1=Rachel Louise|last2=Karmin|first2=Craig|last3=Benoit|first3=David|title=Donald Trump’s Three Friends in Finance|url=https://www.wsj.com/articles/donald-trumps-three-friends-in-finance-1457192917|accessdate=May 10, 2016|work=The Wall Street Journal|date=March 5, 2016}}&lt;/ref&gt; Beal serves as one of the top economic advisers to Trump's campaign.&lt;ref name="jtankersley"&gt;{{cite news|last1=Tankersley|first1=Jim|title=Donald Trump’s new team of billionaire advisers could threaten his populist message|url=https://www.washingtonpost.com/news/wonk/wp/2016/08/05/donald-trumps-economic-team-the-ultra-rich-to-the-rescue/|accessdate=6 August 2016|publisher=Washington Post|date=5 August 2016}}&lt;/ref&gt; Beal donated $2 million to a Trump super PAC in September 2016, and another $1 million for the inaugural festivities according to [https://www.forbes.com/sites/danalexander/2017/04/19/more-than-25-billionaires-poured-millions-into-trumps-inaugural-committee/#7d77608ccb33 Forbes].

== References ==

{{reflist|30em}}
{{authority control}}

{{DEFAULTSORT:Beal, Andrew}}
[[Category:1952 births]]
[[Category:Living people]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Amateur mathematicians]]
[[Category:American aerospace businesspeople]]
[[Category:American bankers]]
[[Category:American billionaires]]
[[Category:American financiers]]
[[Category:American hedge fund managers]]
[[Category:American investors]]
[[Category:American money managers]]
[[Category:American philanthropists]]
[[Category:American poker players]]
[[Category:American real estate businesspeople]]
[[Category:American technology chief executives]]
[[Category:American technology company founders]]
[[Category:Baylor University alumni]]
[[Category:Businesspeople from Texas]]
[[Category:Michigan State University alumni]]
[[Category:Number theorists]]
[[Category:People from Dallas]]
[[Category:Businesspeople from Lansing, Michigan]]</text>
      <sha1>oetnsc26yqkdfp7n63o589k3lom4kw3</sha1>
    </revision>
  </page>
  <page>
    <title>CWC mode</title>
    <ns>0</ns>
    <id>7475344</id>
    <revision>
      <id>869075693</id>
      <parentid>836131247</parentid>
      <timestamp>2018-11-16T06:59:10Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1199">In [[cryptography]], '''CWC Mode''' (Carter–Wegman + [[Block cipher modes of operation|CTR]] mode) is an [[AEAD block cipher modes of operation|AEAD block cipher mode of operation]] that provides both encryption and built-in message integrity, similar to CCM and OCB modes. It combines the use of CTR mode for encryption with an efficient polynomial [[Carter–Wegman MAC]] and is designed by [[Tadayoshi Kohno]], [[John Viega]] and [[Doug Whiting]]. [[NIST]] [https://csrc.nist.gov/projects/block-cipher-techniques/bcm/modes-develoment previously considered] CWC mode for standardization, but opted for the similar [[Galois/Counter_Mode|GCM mode]] instead.

==External links==
* [https://web.archive.org/web/20080302135356/http://www.zork.org/cwc/ CWC mode home page]
* [http://eprint.iacr.org/2003/106 CWC: A high-performance conventional authenticated encryption mode] eprint
* [https://web.archive.org/web/20091227082147/http://gladman.plushost.co.uk/oldsite/AES/index.php Implementation of CWC] on top of [[Advanced Encryption Standard|AES]].

{{Cryptography navbox | block | hash}}

[[Category:Block cipher modes of operation]]
[[Category:Authenticated-encryption schemes]]


{{crypto-stub}}</text>
      <sha1>65zn3i5d85qf08amm848vlxyt3276do</sha1>
    </revision>
  </page>
  <page>
    <title>Cantelli's inequality</title>
    <ns>0</ns>
    <id>36703918</id>
    <revision>
      <id>861291842</id>
      <parentid>783146280</parentid>
      <timestamp>2018-09-26T11:55:55Z</timestamp>
      <contributor>
        <username>Whisper.l</username>
        <id>34747402</id>
      </contributor>
      <minor/>
      <comment>Avoid missleading readers by mixing \mathbb{E}[X] with \mu</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3994">In [[probability theory]], '''Cantelli's inequality''', named after [[Francesco Paolo Cantelli]], is a generalization of [[Chebyshev's inequality]] in the case of a single "tail".&lt;ref&gt;''Research and practice in multiple criteria decision making: proceedings of the XIVth International Conference on Multiple Criteria Decision Making (MCDM), Charlottesville, Virginia, USA, June 8–12, 1998'', edited by Y.Y. Haimes and R.E. Steuer, [[Springer Verlag|Springer]], 2000, {{ISBN|3540672664}}.&lt;/ref&gt;&lt;ref&gt;[http://www.cse.buffalo.edu/~hungngo/classes/2011/Spring-694/lectures/l4.pdf "Tail and Concentration Inequalities" by Hung Q. Ngo]&lt;/ref&gt;&lt;ref&gt;[http://www.econ.upf.edu/~lugosi/anu.pdf "Concentration-of-measure inequalities" by Gábor Lugosi]&lt;/ref&gt; The inequality states that

: &lt;math&gt;
\Pr(X-\mathbb{E}[X]\ge\lambda)\quad\begin{cases}
\le \frac{\sigma^2}{\sigma^2 + \lambda^2} &amp; \text{if } \lambda &gt; 0, \\[8pt]
\ge 1 - \frac{\sigma^2}{\sigma^2 + \lambda^2} &amp; \text{if }\lambda &lt; 0.
\end{cases}
&lt;/math&gt;

where

:&lt;math&gt;X&lt;/math&gt; is a real-valued [[random variable]],
:&lt;math&gt;\Pr&lt;/math&gt; is the [[probability measure]],
:&lt;math&gt;\mathbb{E}[X]&lt;/math&gt; is the [[expected value]] of &lt;math&gt;X&lt;/math&gt;,
:&lt;math&gt;\sigma^2&lt;/math&gt; is the [[variance]] of &lt;math&gt;X&lt;/math&gt;.

Combining the cases of &lt;math&gt;\lambda &gt;0&lt;/math&gt; and &lt;math&gt;\lambda &lt; 0&lt;/math&gt; gives, for &lt;math&gt;\delta &gt;0,&lt;/math&gt;

: &lt;math&gt;
\Pr(| X-\mathbb{E}[X]|\ge\delta)\le \frac{2\sigma^2}{\sigma^2+\delta^2}.
&lt;/math&gt;

The inequality is due to [[Francesco Paolo Cantelli]]. The Chebyshev inequality implies that in any [[sample (statistics)|data sample]] or [[probability distribution]], "nearly all" values are close to the [[expected value|mean]] in terms of the [[absolute value]] of the difference between the points of the data sample and the weighted average of the data sample. The Cantelli inequality (sometimes called the "Chebyshev–Cantelli inequality" or the "one-sided Chebyshev inequality") gives a way of estimating how the points of the data sample are bigger than or smaller than their weighted average without the two tails of the absolute value estimate. The Chebyshev inequality has [[Chebyshev's inequality#Higher moments|"higher moments versions"]] and [[Chebyshev's inequality#Vector version|"vector versions"]], and so does the Cantelli inequality.

==Proof==
* Case &lt;math&gt;\lambda &gt; 0&lt;/math&gt;:

Let &lt;math&gt;X&lt;/math&gt; be a real-valued random variable with finite variance &lt;math&gt;\sigma^2&lt;/math&gt; and expectation &lt;math&gt;\mu&lt;/math&gt;, and define &lt;math&gt;Y = X - \mathbb{E}[X]&lt;/math&gt; (so that &lt;math&gt;\mathbb{E}[Y] = 0&lt;/math&gt; and &lt;math&gt;\operatorname{Var}(Y) = \sigma^2&lt;/math&gt;).

Then, for any &lt;math&gt;u\geq 0&lt;/math&gt;, we have
: &lt;math&gt;
\Pr( X-\mathbb{E}[X]\geq\lambda)
= \Pr( Y  \geq \lambda) 
= \Pr( Y + u  \geq \lambda + u)
\leq  \Pr( (Y + u)^2  \geq (\lambda + u)^2 )
\leq \frac{\mathbb{E}[(Y + u)^2] }{(\lambda + u)^2}
= \frac{\sigma^2 + u^2 }{(\lambda + u)^2}.
&lt;/math&gt;
the last inequality being a consequence of [[Markov's inequality]]. As the above holds for any choice of &lt;math&gt;u\in\mathbb{R}&lt;/math&gt;, we can choose to apply it with the value that minimizes the function &lt;math&gt;u \geq 0 \mapsto \frac{\sigma^2 + u^2 }{(\lambda + u)^2}&lt;/math&gt;. By differentiating, this can be seen to be &lt;math&gt;u_\ast = \frac{\sigma^2}{\lambda}&lt;/math&gt;, leading to
: &lt;math&gt;
\Pr( X-\mathbb{E}[X] \geq\lambda) \leq \frac{\sigma^2 + u_\ast^2 }{(\lambda + u_\ast)^2} = \frac{\sigma^2}{\lambda^2 + \sigma^2}.
&lt;/math&gt;

* Case &lt;math&gt;\lambda &lt; 0&lt;/math&gt;: we proceed as before, writing &lt;math&gt;\alpha = -\lambda &gt; 0&lt;/math&gt; and for any &lt;math&gt;u \geq 0&lt;/math&gt;
: &lt;math&gt;
\Pr( X-\mathbb{E}[X]&lt; \lambda)
= \Pr( -Y  &gt; \alpha) \leq  \frac{\sigma^2}{\alpha^2 + \sigma^2} = \frac{\sigma^2}{\lambda^2 + \sigma^2}
&lt;/math&gt;
using the previous derivation on &lt;math&gt;-Y&lt;/math&gt;. By taking the complement, we obtain
: &lt;math&gt;
\Pr( X-\mathbb{E}[X] \geq \lambda) \geq 1-  \frac{\sigma^2}{\lambda^2 + \sigma^2}.
&lt;/math&gt;

==References==
{{reflist}}


{{probability-stub}}

[[Category:Probabilistic inequalities]]</text>
      <sha1>biciwajws6jica44ins3gjnsqe3mcnt</sha1>
    </revision>
  </page>
  <page>
    <title>Cartan's equivalence method</title>
    <ns>0</ns>
    <id>1841654</id>
    <revision>
      <id>862708484</id>
      <parentid>852440736</parentid>
      <timestamp>2018-10-06T05:13:11Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8403">In [[mathematics]], '''Cartan's equivalence method''' is a technique in [[differential geometry]] for determining whether two geometrical structures are the same up to a [[diffeomorphism]].  For example, if ''M'' and ''N'' are two [[Riemannian manifold]]s with metrics ''g'' and ''h'', respectively, 
when is there a diffeomorphism

:&lt;math&gt;\phi:M\rightarrow N&lt;/math&gt;

such that

:&lt;math&gt;\phi^*h=g&lt;/math&gt;?

Although the answer to this particular question was known in dimension 2 to [[Carl Friedrich Gauss|Gauss]] and in higher dimensions to [[Elwin Bruno Christoffel|Christoffel]] and perhaps [[Riemann]] as well, [[Élie Cartan]] and his intellectual heirs developed a technique for answering similar questions for radically different geometric structures. (For example see the [[Cartan–Karlhede algorithm]].)

Cartan successfully applied his equivalence method to many such structures, including [[projective structure]]s, [[CR structure]]s, and [[Complex manifold|complex structures]], as well as ostensibly non-geometrical structures such as the equivalence of [[Lagrangian mechanics|Lagrangians]] and [[ordinary differential equation]]s.  (His techniques were later developed more fully by many others, such as [[D. C. Spencer]] and [[Shiing-Shen Chern]].)

The equivalence method is an essentially [[algorithm]]ic procedure for determining when two geometric structures are identical.  For Cartan, the primary geometrical information was expressed in a [[coframe]] or collection of coframes on a [[differentiable manifold]]. See [[method of moving frames]].

== Overview ==
Specifically, suppose that ''M'' and ''N'' are a pair of manifolds each carrying a [[G-structure]] for a structure group ''G''.  This amounts to giving a special class of coframes on ''M'' and ''N''.  Cartan's method addresses the question of whether there exists a local diffeomorphism &amp;phi;:''M''&amp;rarr;''N'' under which the ''G''-structure on ''N'' pulls back to the given ''G''-structure on ''M''.  An equivalence problem has been ''"solved"'' if one can give a complete set of structural invariants for the ''G''-structure: meaning that such a diffeomorphism exists if and only if all of the structural invariants agree in a suitably defined sense.

Explicitly, local systems of one-forms &amp;theta;&lt;sup&gt;''i''&lt;/sup&gt; and &amp;gamma;&lt;sup&gt;''i''&lt;/sup&gt; are given on ''M'' and ''N'', respectively, which span the respective cotangent bundles (i.e., are [[coframe]]s).  The question is whether there is a local diffeomorphism &amp;phi;:''M''&amp;rarr;''N'' such that the [[pullback (differential geometry)|pullback]] of the coframe on ''N'' satisfies
:&lt;math&gt;\phi^*\gamma^i(y)=g^i_j(x)\theta^j(x),\ (g^i_j)\in G&lt;/math&gt;  (1)
where the coefficient ''g'' is a function on ''M'' taking values in the [[Lie group]] ''G''.  For example, if ''M'' and ''N'' are Riemannian manifolds, then ''G''=''O''(''n'') is the orthogonal group and &amp;theta;&lt;sup&gt;''i''&lt;/sup&gt; and &amp;gamma;&lt;sup&gt;''i''&lt;/sup&gt; are [[orthonormal]] coframes of ''M'' and ''N'' respectively.  The question of whether two Riemannian manifolds are isometric is then a question of whether there exists a diffeomorphism &amp;phi; satisfying (1).

The first step in the Cartan method is to express the pullback relation (1) in as invariant a way as possible through the use of a "''prolongation''".  The most economical way to do this is to use a ''G''-subbundle ''PM'' of the principal bundle of linear coframes ''LM'', although this approach can lead to unnecessary complications when performing actual calculations.  In particular, later on this article uses a different approach.  But for the purposes of an overview, it is convenient to stick with the principal bundle viewpoint.

The second step is to use the diffeomorphism invariance of the [[exterior derivative]] to try to isolate any other higher-order invariants of the ''G''-structure.  Basically one obtains a connection in the principal bundle ''PM'', with some torsion.  The components of the connection and of the torsion are regarded as invariants of the problem.

The third step is that if the remaining torsion coefficients are not constant in the fibres of the principal bundle ''PM'', it is often possible (although sometimes difficult), to '''normalize''' them by setting them equal to a convenient constant value and solving these normalization equations, thereby reducing the effective dimension of the Lie group ''G''.  If this occurs, one goes back to step one, now having a Lie group of one lower dimension to work with.

=== The fourth step ===
The main purpose of the first three steps was to reduce the structure group itself as much as possible.  Suppose that the equivalence problem has been through the loop enough times that no further reduction is possible.  At this point, there are various possible directions in which the equivalence method leads.  For most equivalence problems, there are only four cases: complete reduction, involution, prolongation, and degeneracy.

'''Complete reduction.'''  Here the structure group has been reduced completely to the [[trivial group]].  The problem can now be handled by methods such as the [[Frobenius theorem (differential topology)|Frobenius theorem]].  In other words, the algorithm has successfully terminated.

On the other hand, it is possible that the torsion coefficients are constant on the fibres of ''PM''.  Equivalently, they no longer depend on the Lie group ''G'' because there is nothing left to normalize, although there may still be some torsion.  The three remaining cases assume this.

'''Involution.'''  The equivalence problem is said to be '''involutive''' (or ''in involution'') if it passes [[Cartan's test]].  This is essentially a rank condition on the connection obtained in the first three steps of the procedure.  The Cartan test generalizes the [[Frobenius theorem (differential topology)|Frobenius theorem]] on the solubility of first-order linear systems of partial differential equations.  If the coframes on ''M'' and ''N'' (obtained by a thorough application of the first three steps of the algorithm) agree and satisfy the Cartan test, then the two ''G''-structures are equivalent.  (Actually, to the best of the author's knowledge, the coframes must be [[real analytic]] in order for this to hold, because the [[Cartan-Kähler theorem]] requires analyticity.)

'''Prolongation.'''  This is the most intricate case.  In fact there are two sub-cases.  In the first sub-case, all of the torsion can be uniquely absorbed into the connection form.  (Riemannian manifolds are an example, since the Levi-Civita connection absorbs all of the torsion).  The connection coefficients and their invariant derivatives form a complete set of invariants of the structure, and the equivalence problem is solved.  In the second subcase, however, it is either impossible to absorb all of the torsion, or there is some ambiguity (as is often the case in [[Gaussian elimination]], for example).  Here, just as in Gaussian elimination, there are additional parameters which appear in attempting to absorb the torsion.  These parameters themselves turn out to be additional invariants of the problem, so the structure group ''G'' must be ''prolonged'' into a subgroup of a [[jet group]].  Once this is done, one obtains a new coframe on the prolonged space and has to return to the first step of the equivalence method.  (See also [[prolongation of G-structures]].)

'''Degeneracy.'''  Because of a non-uniformity of some rank condition, the equivalence method is unsuccessful in handling this particular equivalence problem.  For example, consider the equivalence problem of mapping a manifold ''M'' with a single one-form &amp;theta; to another manifold with a single one-form &amp;gamma; such that &amp;phi;*&amp;gamma;=&amp;theta;.  The zeros of these one forms, as well as the rank of their exterior derivatives at each point need to be taken into account.  The equivalence method can handle such problems if all of the ranks are uniform, but it is not always suitable if the rank changes.  Of course, depending on the particular application, a great deal of information can still be obtained with the equivalence method.

==References==
*{{cite book|author=Olver, P.J.|author-link=Peter J. Olver|title=Equivalence, invariants, and symmetry|publisher=Oxford University Press|year=1995|isbn=0-521-47811-1}}

[[Category:Differential geometry]]
[[Category:Diffeomorphisms]]</text>
      <sha1>renxek9vy9njc241x9d3o99y460yqvq</sha1>
    </revision>
  </page>
  <page>
    <title>Concolic testing</title>
    <ns>0</ns>
    <id>25029425</id>
    <revision>
      <id>868472150</id>
      <parentid>845021622</parentid>
      <timestamp>2018-11-12T11:50:45Z</timestamp>
      <contributor>
        <ip>198.27.190.146</ip>
      </contributor>
      <comment>Fix typo in Klarlund's name</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15793">'''Concolic testing''' (a [[portmanteau]] of ''concrete'' and ''symbolic'') is a hybrid [[software verification]] technique that performs [[symbolic execution]], a classical technique that treats program variables as symbolic variables, along a ''concrete execution'' ([[software testing|testing]] on particular inputs) path.  Symbolic execution is used in conjunction with an [[automated theorem prover]] or constraint solver based on [[constraint logic programming]] to generate new concrete inputs (test cases) with the aim of maximizing [[code coverage]]. Its main focus is finding bugs in real-world software, rather than demonstrating program correctness.

A description and discussion of the concept was introduced in "DART: Directed Automated Random Testing" by Patrice Godefroid, Nils Klarlund, and Koushik Sen.&lt;ref&gt;{{cite conference
| author1 = Patrice Godefroid
| author2 = Nils Klarlund
| author3 = Koushik Sen
| title = DART: Directed Automated Random Testing
| booktitle = Proceedings of the 2005 ACM SIGPLAN conference on Programming language design and implementation
| pages = 213&amp;ndash;223
| publisher = ACM
| year = 2005
| location = New York, NY
| url = http://cm.bell-labs.com/who/god/public_psfiles/pldi2005.pdf
| accessdate = 2009-11-09
| issn=0362-1340
}}
&lt;/ref&gt; The paper "CUTE: A concolic unit testing engine for C",&lt;ref name="cute"&gt;{{cite conference
| author1 = Koushik Sen
| author2 = Darko Marinov
| author3 = Gul Agha
| title = CUTE: a concolic unit testing engine for C
| booktitle = Proceedings of the 10th European software engineering conference held jointly with 13th ACM SIGSOFT international symposium on Foundations of software engineering
| pages = 263&amp;ndash;272  
| publisher = ACM
| year = 2005
| location = New York, NY
| url = http://srl.cs.berkeley.edu/~ksen/papers/C159-sen.pdf
| accessdate = 2009-11-09
| isbn = 1-59593-014-0
}}&lt;/ref&gt; by Koushik Sen, Darko Marinov, and Gul Agha, further extended the idea to data structures, and first coined the term ''concolic testing''.  Another tool, called EGT (renamed to EXE and later improved and renamed to KLEE), based on similar ideas was independently developed by Cristian Cadar and Dawson Engler in 2005, and published in 2005 and 2006.&lt;ref&gt;{{cite conference
| author1 = Cristian Cadar
| author2 = Vijay Ganesh
| author3 = Peter Pawloski
| author4 = David L. Dill
| author5 = Dawson Engler
| title = EXE: Automatically Generating Inputs of Death
| booktitle = Proceedings of the 13th International Conference on Computer and Communications Security (CCS 2006)
| publisher = ACM
| year = 2006
| location = Alexandria, VA, USA
| url = http://www.stanford.edu/~engler/exe-ccs-06.pdf
}}&lt;/ref&gt; PathCrawler&lt;ref&gt;{{cite conference
| author1 = Nicky Williams
| author2 = Bruno Marre
| author3 = Patricia Mouy
| title = On-the-Fly Generation of K-Path Tests for C Functions
| booktitle = Proceedings of the 19th IEEE International Conference on Automated Software Engineering (ASE 2004), 20–25 September 2004, Linz, Austria
| pages = 290&amp;ndash;293
| publisher = IEEE Computer Society
| year = 2004
| isbn = 0-7695-2131-2
}}&lt;/ref&gt;&lt;ref&gt;{{cite conference
| author1 = Nicky Williams
| author2 = Bruno Marre
| author3 = Patricia Mouy
| author4 = Muriel Roger
| title = PathCrawler: Automatic Generation of Path Tests by Combining Static and Dynamic Analysis
| booktitle = Dependable Computing - EDCC-5, 5th European Dependable Computing Conference, Budapest, Hungary, April 20–22, 2005, Proceedings
| pages = 281&amp;ndash;292
| publisher = Springer
| year = 2005
| isbn = 3-540-25723-3
}}&lt;/ref&gt; first proposed to perform symbolic execution along a concrete execution path, but unlike concolic testing PathCrawler does not simplify complex symbolic constraints using concrete values.  These tools (DART and CUTE, EXE) applied concolic testing to unit testing of [[C programming language|C]] programs and concolic testing was originally conceived as a [[white box (software engineering)|white box]] improvement upon established [[random testing]] methodologies. The technique was later generalized to testing multithreaded [[Java programming language|Java]] programs with jCUTE,&lt;ref&gt;
{{cite conference
| author1 = Koushik Sen
| author2 =Gul Agha
| title = CUTE and jCUTE : Concolic Unit Testing and Explicit Path Model-Checking Tools
| booktitle = Computer Aided Verification: 18th International Conference, CAV 2006, Seattle, WA, USA, August 17–20, 2006, Proceedings
| pages = 419&amp;ndash;423
| publisher = Springer
| date = August 2006
| url = http://srl.cs.berkeley.edu/~ksen/pubs/paper/cuteTool.ps
| accessdate = 2009-11-09
| isbn = 978-3-540-37406-0
}}
&lt;/ref&gt; and unit testing programs from their executable codes (tool OSMOSE).&lt;ref&gt;
{{cite conference
| author1 = Sébastien Bardin
| author2 = Philippe Herrmann
| title = Structural Testing of Executables
| booktitle = Proceedings of the 1st IEEE International Conference on Software Testing, Verification, and Validation (ICST 2008), Lillehammer, Norway.
| pages = 22&amp;ndash;31
| publisher = IEEE Computer Society
| date = April 2008
| url = http://sebastien.bardin.free.fr/icst08.pdf
| isbn = 978-0-7695-3127-4 
}},
&lt;/ref&gt; It was also combined with [[fuzz testing]] and extended to detect exploitable security issues in large-scale [[x86]] binaries by [[Microsoft Research]]'s SAGE.&lt;ref&gt;{{cite techreport
| author1 = Patrice Godefroid
| author2 = Michael Y. Levin
| author3 = David Molnar
| title = Automated Whitebox Fuzz Testing
| number = TR-2007-58
| institution = Microsoft Research
| year = 2007
| url = http://research.microsoft.com/en-us/projects/atg/ndss2008.pdf
}}
&lt;/ref&gt;&lt;ref&gt;
{{cite conference
| author1 = Patrice Godefroid
| title = Random testing for security: blackbox vs. whitebox fuzzing
| booktitle = Proceedings of the 2nd international workshop on Random testing: co-located with the 22nd IEEE/ACM International Conference on Automated Software Engineering (ASE 2007)
| pages = 1
| publisher = ACM
| year = 2007
| location = New York, NY
| url = http://research.microsoft.com/en-us/um/people/pg/public_psfiles/abstract-rt2007.pdf
| accessdate = 2009-11-09
| isbn = 978-1-59593-881-7 
}}
&lt;/ref&gt;

The concolic approach is also applicable to [[model checking]]. In a concolic model checker, the model checker traverses states of the model representing the software being checked, while storing both a concrete state and a symbolic state. The symbolic state is used for checking properties on the software, while the concrete state is used to avoid reaching unreachable state. One such tool is ExpliSAT by Sharon Barner, Cindy Eisner, Ziv Glazberg, [[Daniel Kroening]] and Ishai Rabinovitz&lt;ref&gt;Sharon Barner, Cindy Eisner, Ziv Glazberg, Daniel Kroening, Ishai Rabinovitz: ExpliSAT: Guiding SAT-Based Software Verification with Explicit States. Haifa Verification Conference 2006: 138-154&lt;/ref&gt;

== Birth of concolic testing ==

Implementation of traditional symbolic execution based testing requires the implementation of a full-fledged symbolic interpreter for a programming language.  Concolic testing implementors noticed that implementation of full-fledged symbolic execution can be avoided if symbolic execution can be piggy-backed with the normal execution of a program through [[instrumentation (computer programming)|instrumentation]].  This idea of simplifying implementation of symbolic execution gave birth to concolic testing.

=== Development of SMT Solvers ===

An important reason for the rise of concolic testing (and more generally, symbolic-execution based analysis of programs) in the decade since it was introduced in 2005 is the dramatic improvement in the efficiency and expressive power of [[Satisfiability modulo theories|SMT Solvers]]. The key technical developments that lead to the rapid development of SMT solvers include combination of theories, lazy solving, DPLL(T) and the huge improvements in the speed of [[Boolean satisfiability problem#Algorithms for solving SAT|SAT solvers]].  SMT solvers that are particularly tuned for concolic testing include Z3, STP, Z3str2, and Boolector.

== Example ==

Consider the following simple example, written in C:

&lt;source lang="c" line="GESHI_FANCY_LINE_NUMBERS"&gt;
void f(int x, int y) {
    int z = 2*y;
    if (x == 100000) {
        if (x &lt; z) {
            assert(0); /* error */
        }
    }
}
&lt;/source&gt;

[[File:Concolic testing example.svg|thumb|Execution path tree for this example. Three tests are generated corresponding to the three leaf nodes in the tree, and three execution paths in the program.]]
Simple random testing, trying random values of ''x'' and ''y'', would require an impractically large number of tests to reproduce the failure.

We begin with an arbitrary choice for ''x'' and ''y'', for example ''x''&amp;nbsp;=&amp;nbsp;''y''&amp;nbsp;=&amp;nbsp;1. In the concrete execution, line 2 sets ''z'' to 2, and the test in line 3 fails since 1 ≠ 100000. Concurrently, the symbolic execution follows the same path but treats ''x'' and ''y'' as symbolic variables. It sets ''z'' to the expression 2''y'' and notes that, because the test in line 3 failed, ''x'' ≠ 100000. This inequality is called a ''path condition'' and must be true for all executions following the same execution path as the current one.

Since we'd like the program to follow a different execution path on the next run, we take the last path condition encountered, ''x'' ≠ 100000, and negate it, giving ''x'' = 100000. An automated theorem prover is then invoked to find values for the input variables ''x'' and ''y'' given the complete set of symbolic variable values and path conditions constructed during symbolic execution. In this case, a valid response from the theorem prover might be ''x'' = 100000, ''y'' = 0.

Running the program on this input allows it to reach the inner branch on line 4, which is not taken since 100000 (''x'') is not less than 0 (''z'' = 2''y''). The path conditions are ''x'' = 100000 and ''x'' ≥ ''z''. The latter is negated, giving ''x'' &lt; ''z''. The theorem prover then looks for ''x'', ''y'' satisfying ''x'' = 100000, ''x'' &lt; ''z'', and ''z'' = 2''y''; for example, ''x'' = 100000, ''y'' = 50001. This input reaches the error.

== Algorithm ==

Essentially, a concolic testing algorithm operates as follows:

# Classify a particular set of variables as ''input variables''. These variables will be treated as symbolic variables during symbolic execution.  All other variables will be treated as concrete values.
# Instrument the program so that each operation which may affect a symbolic variable value or a path condition is logged to a trace file, as well as any error that occurs.
# Choose an arbitrary input to begin with.
# Execute the program.
# Symbolically re-execute the program on the trace, generating a set of symbolic constraints (including path conditions).
# Negate the last path condition not already negated in order to visit a new execution path. If there is no such path condition, the algorithm terminates.
# Invoke an automated theorem prover to generate a new input. If there is no input satisfying the constraints, return to step 6 to try the next execution path.
# Return to step 4.

There are a few complications to the above procedure:
* The algorithm performs a [[depth-first search]] over an implicit [[tree data structure|tree]] of possible execution paths. In practice programs may have very large or infinite path trees – a common example is testing data structures that have an unbounded size or length. To prevent spending too much time on one small area of the program, the search may be depth-limited (bounded).
* Symbolic execution and automated theorem provers have limitations on the classes of constraints they can represent and solve. For example, a theorem prover based on linear arithmetic will be unable to cope with the nonlinear path condition ''xy'' = 6. Any time that such constraints arise, the symbolic execution may substitute the current concrete value of one of the variables to simplify the problem. An important part of the design of a concolic testing system is selecting a symbolic representation precise enough to represent the constraints of interest.

== Commercial success ==
Symbolic-execution based analysis and testing, in general, has witnessed a significant level of interest from industry {{Citation needed|date=January 2018}}. Perhaps the most famous commercial tool that uses dynamic symbolic execution (aka concolic testing) is the SAGE tool from Microsoft. The KLEE and S2E tools (both of which are open-source tools, and use the STP constraint solver) are widely used in many companies including Micro Focus Fortify, NVIDIA, and IBM {{Citation needed|date=March 2017}}. Increasingly these technologies are being used by many security companies and hackers alike to find security vulnerabilities.

== Limitations ==

Concolic testing has a number of limitations:

* If the program exhibits nondeterministic behavior, it may follow a different path than the intended one. This can lead to nontermination of the search and poor coverage.
* Even in a deterministic program, a number of factors may lead to poor coverage, including imprecise symbolic representations, incomplete theorem proving, and failure to search the most fruitful portion of a large or infinite path tree.
* Programs which thoroughly mix the state of their variables, such as cryptographic primitives, generate very large symbolic representations that cannot be solved in practice. For example, the condition &lt;code&gt;if(sha256_hash(input) == 0x12345678) { ... }&lt;/code&gt; requires the theorem prover to invert [[SHA256]], which is an open problem.

== Tools ==
* [http://pathcrawler-online.com/ pathcrawler-online.com] is a restricted version of the current PathCrawler tool which is publicly available as an online test-case server for evaluation and education purposes.
* [http://osl.cs.illinois.edu/software/jcute/ jCUTE] is available as binary under a research-use only license by Urbana-Champaign for [[Java (programming language)|Java]].
* [http://www.burn.im/crest/ CREST] is an open-source solution for [[C (programming language)|C]] that replaced&lt;ref&gt;http://osl.cs.illinois.edu/software/index.html&lt;/ref&gt;CUTE ([[modified BSD license]]).
* [https://klee.github.io/ KLEE] is an open source solution built on-top of the [[LLVM]] infrastructure ([[University_of_Illinois/NCSA_Open_Source_License|UIUC license]]).
* [https://github.com/ksen007/janala2 CATG] is an open-source solution for [[Java (programming language)|Java]] ([[BSD license]]).
* [https://github.com/SRA-SiliconValley/jalangi Jalangi] is an open-source concolic testing and symbolic execution tool for JavaScript.  Jalangi supports integers and strings.
* [http://research.microsoft.com/en-us/projects/pex/ Microsoft Pex], developed at Microsoft Rise, is publicly available as a [[Microsoft Visual Studio 2010]] Power Tool for the [[NET Framework]].
* [http://triton.quarkslab.com Triton] is an open-source [https://software.intel.com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool Pin]-based concolic execution framework for x86 and x86-64 binaries.
* [https://github.com/aggelgian/cuter/ CutEr] is an open-source concolic testing tool for the Erlang functional programming language.

Many tools, notably DART and SAGE, have not been made available to the public at large. Note however that for instance SAGE is "used daily" for internal security testing at Microsoft.&lt;ref&gt;{{cite web
| url = http://research.microsoft.com/en-us/um/people/pg/public_psfiles/sage-in-one-slide.pdf
| title = Microsoft PowerPoint - SAGE-in-one-slide
| author = SAGE team
| year = 2009
| publisher = Microsoft Research
| accessdate = 2009-11-10
}}&lt;/ref&gt;

== References ==
&lt;references /&gt;

[[Category:Automated theorem proving]]
[[Category:Software testing]]</text>
      <sha1>0g7k59f0psyql3f1sfrywstb1zp9gn9</sha1>
    </revision>
  </page>
  <page>
    <title>Conglomerate (set theory)</title>
    <ns>0</ns>
    <id>48611088</id>
    <revision>
      <id>810059921</id>
      <parentid>749340521</parentid>
      <timestamp>2017-11-13T03:50:21Z</timestamp>
      <contributor>
        <username>Siddharthist</username>
        <id>28122572</id>
      </contributor>
      <comment>Add another category and {{Category theory}} navbar</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1305">In [[mathematics]], a '''conglomerate''' is a collection of [[class (set theory)|classes]], just as a class is a collection of [[set (mathematics)|sets]].&lt;ref name="joyofcats1"&gt;{{cite book|last1=Adamek|first1=Jiri|last2=Herrlich|first2=Horst|last3=Strecker|first3=George|year=1990|title=Abstract and Concrete Categories: The Joy of Cats|publisher=Dover Publications|url=https://books.google.com/books/about/Abstract_and_Concrete_Categories.html?id=rqT4PgAACAAJ|isbn=978-0-486-46934-8}}&lt;/ref&gt; A quasi-category is like a [[category (mathematics)|category]] except that its [[Mathematical object|objects]] and [[morphism]]s form conglomerates instead of classes.&lt;ref name="joyofcats1"&gt;{{cite book|last1=Adamek|first1=Jiri|last2=Herrlich|first2=Horst|last3=Strecker|first3=George|year=1990|title=Abstract and Concrete Categories: The Joy of Cats|publisher=Dover Publications|url=https://books.google.com/books/about/Abstract_and_Concrete_Categories.html?id=rqT4PgAACAAJ|isbn=978-0-486-46934-8}}&lt;/ref&gt; The [[Subclass (set theory)|subclasses]] of any class, and in particular, the collection of all classes (every class is a subclass of the class of all sets), form a conglomerate.

==References==
{{reflist}}

[[Category:Higher category theory]]
[[Category:Set theory]]

{{Category theory}}

{{Settheory-stub}}</text>
      <sha1>rbotllcjerqkgffhf35jyutwhtf6s6v</sha1>
    </revision>
  </page>
  <page>
    <title>Contracted Bianchi identities</title>
    <ns>0</ns>
    <id>57574496</id>
    <revision>
      <id>868052956</id>
      <parentid>844725578</parentid>
      <timestamp>2018-11-09T17:58:56Z</timestamp>
      <contributor>
        <ip>71.246.145.142</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2272">In [[general relativity]] and [[tensor calculus]], the '''contracted Bianchi identities''' are&lt;ref&gt;{{Citation
|author-first=Luigi
|author-last=Bianchi
|author-link =Luigi Bianchi
|title = Sui simboli a quattro indici e sulla curvatura di Riemann
|trans-title= 
|journal = Rend. Acc. Naz. Lincei
|volume =11
|issue=5
|pages =3–7
|year =1902
|language =Italian
|url =https://archive.org/stream/rendiconti51111902acca#page/n9/mode/2up
|doi =
|jfm = 
}}&lt;/ref&gt;:

:&lt;math&gt; \nabla_\rho {R^\rho}_\mu = {1 \over 2} \nabla_{\mu} R,&lt;/math&gt;

where &lt;math&gt;{R^\rho}_\mu&lt;/math&gt; is the [[Ricci tensor]], &lt;math&gt;R&lt;/math&gt; the [[scalar curvature]], and &lt;math&gt;\nabla_\rho&lt;/math&gt; indicates [[covariant differentiation]].

A proof can be found in the entry [[Proofs involving covariant derivatives]].

These identities are named after [[Luigi Bianchi]], although they had been already derived by [[Aurel Voss]] in 1880.&lt;ref name="voss" &gt;{{citation|title=Zur Theorie der Transformation quadratischer Differentialausdrücke und der Krümmung höherer Mannigfaltigketien |last=Voss|first=A.|author-link=Aurel Voss|journal=Mathematische Annalen|volume=16|pages=129–178|year=1880|url=}}&lt;/ref&gt;

==See also==
*[[Einstein tensor]]
*[[Ricci calculus]]
*[[Tensor calculus]]
*[[Riemann curvature tensor]]

==Notes==
{{Reflist}}

==References==
*{{cite book
 | last = Lovelock
 | first = David
 |author2=Hanno Rund
 | title = Tensors, Differential Forms, and Variational Principles
 | year=  1989
 | publisher = Dover
 | isbn = 978-0-486-65840-7
 | origyear = 1975
 }}
* {{cite book |author=Synge J.L., Schild A. |title=Tensor Calculus |publisher=first Dover Publications 1978 edition |year=  1949
|isbn=978-0-486-63612-2}}
* {{citation | author=J.R. Tyldesley| title = An introduction to Tensor Analysis: For Engineers and Applied Scientists| publisher=Longman| year=1975|isbn=0-582-44355-5}}
* {{citation | author=D.C. Kay| title = Tensor Calculus| publisher=Schaum’s Outlines, McGraw Hill (USA)|year=1988|isbn=0-07-033484-6}}
* {{citation | author=T. Frankel| title = The Geometry of Physics| publisher=Cambridge University Press|edition=3rd|year=2012|isbn=978-1107-602601}}

[[Category:Concepts in physics]]
[[Category:Tensors]]
[[Category:General relativity]]

{{physics-stub}}
{{mathematics-stub}}</text>
      <sha1>8fsszn0qzqc4r2w87wzmc49vzp35kkh</sha1>
    </revision>
  </page>
  <page>
    <title>DICING</title>
    <ns>0</ns>
    <id>6338535</id>
    <revision>
      <id>482743440</id>
      <parentid>325697429</parentid>
      <timestamp>2012-03-19T16:18:01Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error  fixes + [[WP:GENFIXES|general fixes]] using [[Project:AWB|AWB]] (8024)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="270">In [[cryptography]], '''DICING''' is a [[stream cipher|stream cypher]] [[algorithm]] developed by [[Li An-Ping]]. It has been submitted to the [[eSTREAM]] Project of the [[eCRYPT]] network.

{{Cryptography navbox | stream}}

[[Category:Stream ciphers]]


{{crypto-stub}}</text>
      <sha1>sie51xrw5obp6uw17d7l5ori9x3pp6l</sha1>
    </revision>
  </page>
  <page>
    <title>DataScene</title>
    <ns>0</ns>
    <id>31316540</id>
    <revision>
      <id>844693728</id>
      <parentid>842677752</parentid>
      <timestamp>2018-06-06T14:10:38Z</timestamp>
      <contributor>
        <username>Arthur MILCHIOR</username>
        <id>9557656</id>
      </contributor>
      <minor/>
      <comment>Removing category "Visualization (graphic)", since it is already in a subcategory</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3656">{{notability|Products|date=April 2014}}
{{Infobox Software
| name = DataScene
| logo = [[File:Wavepacket-animation-small.gif|175x200px]]
| screenshot =
| caption =
| developer = Cyberwit, Inc.
| latest_release_version = 3.0.7
| latest_release_date = March 2011
| operating_system = [[Microsoft Windows|Windows]], [[Linux]], [[Unix-like|Unix/X11]]
| genre = [[technical graphing and analysis package]]
| license = [[Shareware]]
| website = {{url|http://www.cyber-wit.com}}
}}

'''DataScene''' is a scientific graphing, [[Computer Animation|animation]], [[data analysis]], and [[real-time data|real-time]] data monitoring software package.&lt;ref&gt;M. Bedford, "How To Create High-quality Graphs and Charts", ''[[Computer Shopper (UK magazine)|Computer Shopper Magazine]]'', p. 135, Issue 273 (2010).&lt;/ref&gt;&lt;ref&gt;L. G. Rubin. [http://ptonline.aip.org/getpdf/servlet/GetPDFServlet?filetype=pdf&amp;id=PHTOAD000062000007000062000001&amp;idtype=cvips&amp;bypassSSO=1 "Focus On Software: Graphing Software"], ''[[Physics Today]]'', p. 62, 62(7) (2009)&lt;/ref&gt; It was developed with the [[Common Language Infrastructure]] technology and the [[GDI+]] graphics library. With the two [[Common Language Runtime]] engines - the [[.Net Framework|.Net]] and [[Mono (software)|Mono]] frameworks - DataScene runs on all major [[operating systems]].

With DataScene, the user can plot 39 types 2D &amp; 3D graphs (e.g., [[Area graph]], [[Bar graph]], Boxplot graph, [[Pie graph]], [[Line chart|Line graph]], [[Histogram|Histogram graph]], [[Surface (mathematics)|Surface graph]], [[Polar graph]], Water Fall graph, etc.), manipulate, print, and export graphs to various formats (e.g., [[BMP file format|Bitmap]], [[Windows Metafile|WMF/EMF]], [[JPEG]], [[Portable Network Graphics|PNG]], [[GIF]], [[TIFF]], [[PostScript]], and [[PDF]]), analyze data with different mathematical methods ([[Curve Fitting|fitting curves]], calculating [[statics]], [[Fast Fourier transform|FFT]], etc.), create [[Computer Animation|chart animations]] for presentations (e.g. with [[Powerpoint]]), classes, and web pages, and monitor and chart real-time data.

== History ==
DataScene was first released (version 1.0) in March 2009 for the [[Microsoft Windows|Windows]] platform and the .Net 2.0 framework. Since version 2.0, DataScene has been ported to the Mono framework 2.6 and all [[Linux]] and [[Unix|Unix/X11]] [[operating systems]]. The latest version of DataScene is version 3.0.

Cyberwit offers free licensing for the Express edition of DataScene.&lt;ref&gt;[http://www.cyber-wit.com/DataScene_CommunityLicense.html License] for DataScene Express&lt;/ref&gt;

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &amp;lt;ref&gt;&amp;lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

== External links ==
* {{Official website|http://www.cyber-wit.com/|DataScene official website}}
* [http://cyber-wit.com/video_tutorials.html Video tutorials]
{{Portal|Linux}}

{{DEFAULTSORT:Datascene}}
[[Category:Animation software]]
[[Category:Computer animation]]
[[Category:Data analysis software]]
[[Category:Data visualization software]]
[[Category:Earth sciences graphics software]]
[[Category:Educational math software]]
[[Category:Financial charts]]
[[Category:Graphics software]]
[[Category:Plotting software]]
[[Category:Mathematical software]]
[[Category:Regression and curve fitting software]]
[[Category:Science software]]
[[Category:Statistical charts and diagrams]]
[[Category:Web animation]]
[[Category:Graphics-related software for Linux]]
[[Category:Science software for Linux]]
[[Category:Science software for Windows]]


{{science-software-stub}}</text>
      <sha1>8nicx1vky3uu6ngsbxh954ztnkubpa1</sha1>
    </revision>
  </page>
  <page>
    <title>Denjoy's theorem on rotation number</title>
    <ns>0</ns>
    <id>4257408</id>
    <revision>
      <id>674040038</id>
      <parentid>673661418</parentid>
      <timestamp>2015-08-01T05:50:50Z</timestamp>
      <contributor>
        <username>Arcfrk</username>
        <id>3794588</id>
      </contributor>
      <minor/>
      <comment>Undid revision 673661418 by [[Special:Contributions/82.239.65.212|82.239.65.212]] ([[User talk:82.239.65.212|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3191">In [[mathematics]], the '''Denjoy theorem''' gives a sufficient condition for a [[diffeomorphism]] of the circle to be [[topologically conjugate]] to a diffeomorphism of a special kind, namely an [[irrational rotation]]. {{harvs|txt|authorlink=Arnaud Denjoy|last=Denjoy|year=1932}} proved the theorem in the course of his topological classification of [[homeomorphism]]s of the circle. He also gave an example of a ''C''&lt;sup&gt;1&lt;/sup&gt; diffeomorphism with an irrational [[rotation number]] that is not conjugate to a rotation.

== Statement of the theorem ==
Let ''&amp;fnof;'':&amp;nbsp;''S''&lt;sup&gt;1&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;''S''&lt;sup&gt;1&lt;/sup&gt; be an [[orientation-preserving]] diffeomorphism of the circle whose rotation number ''&amp;theta;'' = ''&amp;rho;''(''&amp;fnof;'') is [[irrational number|irrational]]. Assume that it has positive derivative ''&amp;fnof;''&lt;sup&gt;&amp;nbsp;&amp;prime;&lt;/sup&gt;(''x'')&amp;nbsp;&gt;&amp;nbsp;0 that is a [[continuous function]] with [[bounded variation]] on the interval [0,1). Then ''&amp;fnof;'' is topologically conjugate to the irrational rotation by ''&amp;theta;''. Moreover, every orbit is [[dense set|dense]] and every nontrivial interval ''I'' of the circle intersects its forward image ''&amp;fnof;''°&lt;sup&gt;''q''&lt;/sup&gt;(''I''), for some ''q'' &gt; 0 (this means that the [[non-wandering set]] of ''&amp;fnof;'' is the whole circle).

== Complements ==

If ''&amp;fnof;'' is a ''C''&lt;sup&gt;2&lt;/sup&gt; map, then the hypothesis on the derivative holds; however, for any irrational rotation number Denjoy constructed an example showing that this condition cannot be relaxed to ''C''&lt;sup&gt;1&lt;/sup&gt;, [[continuously differentiable|continuous differentiability]] of&amp;nbsp;''&amp;fnof;''.

[[Vladimir Arnold]] showed that the conjugating map need not be [[smooth function|smooth]], even for an [[analytic function|analytic]] diffeomorphism of the circle. Later Michel Herman proved that nonetheless, the conjugating map of an analytic diffeomorphism is itself analytic for "most" rotation numbers, forming a set of full [[Lebesgue measure]], namely, for those that are [[diophantine approximation|badly approximable]] by rational numbers. His results are even more general and specify differentiability class of the conjugating map for ''C''&lt;sup&gt;''r''&lt;/sup&gt; diffeomorphisms with any&amp;nbsp;''r''&amp;nbsp;≥&amp;nbsp;3.

== See also ==
* [[Circle map]]

== References ==
*{{Citation | last1=Denjoy | first1=Arnaud | title=Sur les courbes definies par les équations différentielles à la surface du tore. | url=http://math-doc.ujf-grenoble.fr/JMPA/feuilleter.php?id=JMPA_1932_9_11 | language=French | year=1932 | journal=[[Journal de Mathématiques Pures et Appliquées]] | volume=11 | pages=333–375 | zbl=0006.30501 }}
* {{Citation | first1=M.R. | last1=Herman | title=''Sur la conjugaison différentiable des difféomorphismes du cercle à des rotations''| journal= Publ. Math. IHES| language=French |volume=49|year=1979|pages=5–234|zbl=0448.58019}}
* Kornfeld, Sinai, Fomin, ''Ergodic theory''.

== External links ==
* [[John Milnor]], [http://www.math.sunysb.edu/~jack/DYNOTES/dn15.ps ''Denjoy Theorem'']

[[Category:Dynamical systems]]
[[Category:Diffeomorphisms]]
[[Category:Theorems in topology]]
[[Category:Theorems in dynamical systems]]</text>
      <sha1>fsr3n7iwsyrzysxc37kjcbdpzn0zn6n</sha1>
    </revision>
  </page>
  <page>
    <title>Dupin hypersurface</title>
    <ns>0</ns>
    <id>50665165</id>
    <revision>
      <id>746870548</id>
      <parentid>723450337</parentid>
      <timestamp>2016-10-30T02:19:49Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1469">In [[differential geometry]], a '''Dupin hypersurface''' is a [[submanifold]] in a [[space form]], whose [[principal curvature]]s have globally constant multiplicities.&lt;ref name="Shiohama1989"&gt;{{cite book|author=K. Shiohama|title=Geometry of Manifolds|url=https://books.google.com/books?id=yXvNCgAAQBAJ&amp;pg=PA181|date=4 October 1989|publisher=Elsevier|isbn=978-0-08-092578-3|pages=181–}}&lt;/ref&gt;

==Application==
A [[hypersurface]] is called a Dupin hypersurface if the multiplicity of each principal curvature is constant on hypersurface and each principal curvature is constant along its associated principal directions.&lt;ref name="Rassias1992"&gt;{{cite book|author=Themistocles M. Rassias|title=The Problem of Plateau: A Tribute to Jesse Douglas &amp; Tibor Radó|url=https://books.google.com/books?id=j-O7vMJIIpgC&amp;pg=PA61|year=1992|publisher=World Scientific|isbn=978-981-02-0556-0|pages=61–}}&lt;/ref&gt; All proper Dupin submanifolds arise as focal submanifolds of proper Dupin hypersurfaces.&lt;ref name="GreeneYau1993"&gt;{{cite book|author1=Robert Everist Greene|author2=Shing-Tung Yau|title=Partial Differential Equations on Manifolds|url=https://books.google.com.au/books?id=ulgECAAAQBAJ&amp;pg=PA466&amp;dq=Dupin+hypersurface&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwia6o3Ftf7MAhVGwI8KHUjNDKIQ6AEIMTAD#v=onepage&amp;q=Dupin%20hypersurface&amp;f=false|year=1993|publisher=American Mathematical Soc.|isbn=978-0-8218-1494-9|pages=466–}}&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Multi-dimensional geometry]]</text>
      <sha1>ogcucc4ilikxegfjkc8tpbq1f8tkqnq</sha1>
    </revision>
  </page>
  <page>
    <title>Extinction probability</title>
    <ns>0</ns>
    <id>35777836</id>
    <revision>
      <id>654668912</id>
      <parentid>634510968</parentid>
      <timestamp>2015-04-02T18:43:47Z</timestamp>
      <contributor>
        <username>Wiae</username>
        <id>3495083</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[Trait]] (link changed to [[Phenotypic trait]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="513">{{multiple issues|
{{Orphan|date=September 2014}}
{{unreferenced|date=December 2013}}
}}

'''Extinction probability''' is the chance of an [[inherited trait]] becoming [[extinction|extinct]] as a [[function (mathematics)|function]] of [[time]]&amp;nbsp;''t''.  If ''t''&amp;nbsp;=&amp;nbsp;∞ this may be the complement of the [[probability|chance]] of becoming a universal [[Phenotypic trait|trait]].

[[Category:Statistical genetics]]
[[Category:Stochastic processes]]
[[Category:Population models]]


{{Probability-stub}}</text>
      <sha1>h777jnjf19rj3mx8u4wc0sp26fwus60</sha1>
    </revision>
  </page>
  <page>
    <title>Fano fibration</title>
    <ns>0</ns>
    <id>22965204</id>
    <revision>
      <id>765584334</id>
      <parentid>679270723</parentid>
      <timestamp>2017-02-15T07:06:11Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>{{algebraic-geometry-stub}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="872">In [[algebraic geometry]], a '''Fano fibration''' or '''Fano fiber space''', named after [[Gino Fano]], is a morphism of varieties whose general fiber is a [[Fano variety]] (in other words has ample anticanonical bundle) of positive dimension. The ones arising from extremal contractions in the [[minimal model program]] are called '''Mori fibrations''' or '''Mori fiber spaces''' (for [[Shigefumi Mori]]). They appear  as standard forms for  varieties without a minimal model.

== See also ==
* [[Ample line bundle]]
* [[Fiber bundle]]
* [[Fibration]]
* [[Quasi-fibration]]

==References==
*{{Citation | last1=Matsuki | first1=Kenji | title=Introduction to the Mori program | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Universitext | isbn=978-0-387-98465-0 | mr=1875410  | year=2002}}

[[Category:Algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>i8ktw5r6cx5cfd1cuzjqu1cvj319s8s</sha1>
    </revision>
  </page>
  <page>
    <title>Giulio Ascoli</title>
    <ns>0</ns>
    <id>3855752</id>
    <revision>
      <id>859563693</id>
      <parentid>859563375</parentid>
      <timestamp>2018-09-14T20:58:05Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Adding [[Category:Italian mathematicians]] using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5798">{{distinguish|Guido Ascoli}}
{{Infobox scientist
|name              = Giulio Ascoli
|box_width         =
|image             = 
|image_size         = 220px
|caption           =
|birth_date        = {{Birth date|df=yes|1843|1|20}}
|death_date        = {{Death date and age|df=yes|1896|7|12|1843|1|20}}
|birth_place       = [[Trieste]], Italy
|death_place  	   = [[Milan]], Italy
|nationality       = Italian
|field             = Mathematics
|known_for         =
|notable_students  =
|prizes            =
}}

'''Giulio Ascoli''' (20 January 1843, [[Trieste]] – 12 July 1896, [[Milan]]) was a [[Italian Jews|Jewish-Italian]]&lt;ref&gt;{{JewishEncyclopedia|url=http://www.jewishencyclopedia.com/articles/1900-ascoli-giulio|article=Ascoli, Giulio}}&lt;/ref&gt; mathematician. He was a student of the [[Scuola Normale Superiore di Pisa|Scuola Normale di Pisa]], where he graduated in 1868.

In 1872 he became Professor of Algebra and Calculus of the [[Politecnico di Milano]] University. From 1879 he was professor of mathematics at the Reale Istituto Tecnico Superiore, where, in 1901, was affixed a plaque that remembers him.

He was also corresponding member of Istituto Lombardo.

He made contributions to the [[Functions (mathematics)|theory of functions]] of a real variable and to [[Fourier series]]. For example, Ascoli introduced [[equicontinuity]] in 1884, a topic regarded as one of the fundamental concepts in the theory of real functions.&lt;ref name="Dshalalowp153"&gt;According to {{Harvtxt|Dshalalow|2000|p=153}}.&lt;/ref&gt; In 1889, Italian mathematician [[Cesare Arzelà]] generalized Ascoli's Theorem into the [[Arzelà–Ascoli theorem]], a practical sequential compactness criterion of functions.&lt;ref&gt;See {{Harvtxt|Dshalalow|2000|p=153}}.&lt;/ref&gt;

==See also==
*[[Measure (mathematics)]]
*[[Oscillation (mathematics)]]
*[[Riemann Integral]]

==Notes==
{{Reflist|29em}}

==Biographical references==
* {{Citation
| last = Guerraggio
| first = Angelo
| author-link = Angelo Guerraggio
| last2 = Nastasi
| first2 = Pietro
| author2-link = Pietro Nastasi
| title = Italian mathematics between the two world wars
| place = Basel
| publisher = [[Birkhäuser Verlag]]
| year = 2005
| series = Science Networks. Historical Studies
| volume = 29
| pages = x+299
| url = https://books.google.com/books?id=fl0gL50heXcC&amp;printsec=frontcover#v=onepage&amp;q
| doi = 10.1007/3-7643-7512-4
| mr = 2188015
| zbl = 1084.01010
| isbn = 3-7643-6555-2
}}.
*{{cite book
| first = G. F.
| last = Tricomi
| author-link = Francesco Tricomi
| contribution = Giulio Ascoli
| contribution-url = http://www.dm.unito.it/sism/m_italiani/biografie/tricomi/ascoligiu.html
| title = Matematici italiani del primo secolo dello stato unitario (Italian mathematicians of the first century of the unitary state)
| series = Memorie dell'Accademia delle Scienze di Torino. Classe di Scienze fisiche matematiche e naturali, series IV
| volume = I
| year = 1962
| pages = 120
| zbl = 0132.24405
}} (in [[Italian language|Italian]]). Available from the website of the [https://web.archive.org/web/20110111041253/http://www.dm.unito.it/sism/ Società Italiana di Storia delle Matematiche].

==References==
*{{citation
|title= Real analysis: an introduction to the theory of real functions and integration
|last= Dshalalow
|first= Jewgeni H.
|year= 2001
|series= Studies in Advanced Mathematics
|publisher= [[CRC Press]]
|location= Boca Raton, Florida
|pages=xiv+567
|isbn= 1-58488-073-2
|url=https://books.google.com/books?id=9S09YpoodHIC&amp;pg=PA153
|mr=1788725
|zbl=0978.28001
}}.
*{{Citation
 |last        = Letta
 |first       = Giorgio
 |author-link = Giorgio Letta
 |title       = Le condizioni di Riemann per l'integrabilità e il loro influsso sulla nascita del concetto di misura
 |journal     = [[Rendiconti della Accademia Nazionale delle Scienze detta dei XL, Memorie di Matematica e applicazioni]]
 |volume      = XVIII
 |issue       = 1
 |pages       = 143–169
 |origyear    = 112°
 |year        = 1994
 |language    = Italian
 |url         = http://media.accademiaxl.it/memorie/Serie5_V18_P1.pdf
 |doi         =
 |id          =
 |mr          = 1327463
 |zbl         = 0852.28001
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20140228144250/http://media.accademiaxl.it/memorie/Serie5_V18_P1.pdf
 |archivedate = 2014-02-28
 |df          =
}}. "''Riemann's conditions for integrability and their influence on the birth of the concept of measure''" (English translation of title) is an article on the history of measure theory, analyzing deeply and comprehensively every early contribution to the field, starting from Riemann's work and going to the works of [[Hermann Hankel]], [[Gaston Darboux]], Giulio Ascoli, [[Henry John Stephen Smith]], [[Ulisse Dini]], [[Vito Volterra]], [[Paul David Gustav du Bois-Reymond]] and [[Carl Gustav Axel Harnack]].

==External links==
* [https://web.archive.org/web/20050329000140/http://matematica.uni-bocconi.it/storia/letteraa/biogr-ascoli.htm Biography] in Italian.
* [http://www.jewishencyclopedia.com/view.jsp?artid=1900&amp;letter=A&amp;search=ascoli Ascoli, Julio] in the [[Jewish Encyclopedia]].
* [http://www.cs.vu.nl/~vanmill/papers/papers1999/teun.pdf By Their Fruits Ye Shall Know Them: Some Remarks on the Interaction of General Topology with Other Areas of Mathematics] by T. Koetsier, J. Van Mill, an article containing a history of Ascoli's work on the [[Arzelà-Ascoli theorem]].

{{Authority control}}

{{Use dmy dates|date=March 2018}}

{{DEFAULTSORT:Ascoli, Giulio}}
[[Category:1843 births]]
[[Category:1896 deaths]]
[[Category:Jewish scientists]]
[[Category:19th-century Italian mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Polytechnic University of Milan faculty]]
[[Category:Italian Jews]]
[[Category:Italian mathematicians]]


{{Italy-mathematician-stub}}</text>
      <sha1>lu2crre71vatemec8dr98hh9j2go5rb</sha1>
    </revision>
  </page>
  <page>
    <title>Goldbach's weak conjecture</title>
    <ns>0</ns>
    <id>147164</id>
    <revision>
      <id>868622643</id>
      <parentid>865387057</parentid>
      <timestamp>2018-11-13T11:48:56Z</timestamp>
      <contributor>
        <username>EduardoW</username>
        <id>31080783</id>
      </contributor>
      <comment>clarification of the second formulation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7425">In [[number theory]], '''Goldbach's weak conjecture''', also known as the '''odd Goldbach conjecture''', the '''ternary Goldbach problem''', or the '''3-primes problem''', states that

: Every [[odd number]] greater than 5 can be expressed as the sum of three [[prime number|primes]]. (A prime may be used more than once in the same sum.)

This [[conjecture]] is called "weak" because if [[Goldbach's conjecture|Goldbach's strong conjecture]] (concerning sums of two primes) is proven, it would be true. This is because if every even number greater than 4 is the sum of two odd primes, merely adding 3 to each even number greater than 4 will produce the odd numbers greater than 7 (7 itself is equal to 2+2+3).

In 2013, [[Harald Helfgott]] published a proof of Goldbach's weak conjecture.&lt;ref name=":0" /&gt; As of 2018, the proof is widely accepted in the mathematics community,&lt;ref&gt;{{Cite web|url=https://www.humboldt-professur.de/en/preistraeger/preistraeger-2015/helfgott-harald-andres|title=Alexander von Humboldt-Professur - Harald Andrés Helfgott|website=www.humboldt-professur.de|access-date=2018-06-17}}&lt;/ref&gt; but it has not yet been published in a peer-reviewed journal.

Some state the conjecture as
:Every odd number greater than 7 can be expressed as the sum of three odd primes.&lt;ref&gt;{{MathWorld|title=Goldbach Conjecture|id=GoldbachConjecture}}&lt;/ref&gt;
This version excludes 7 = 2+2+3 because this requires the even prime 2. On odd numbers larger than 7 it is slightly stronger as it also excludes sums like 17 = 2+2+13, which are allowed in the other formulation. Helfgott's proof covers both versions of the conjecture. Like the other formulation, this one also immediately follows from Goldbach's strong conjecture.

==Timeline of results==
In 1923, [[G. H. Hardy|Hardy]] and [[John Edensor Littlewood|Littlewood]] showed that, assuming the [[generalized Riemann hypothesis]], the weak Goldbach conjecture is true for all [[sufficiently large]] odd numbers. In 1937, [[Ivan Matveevich Vinogradov]] eliminated the dependency on the generalised Riemann hypothesis and proved directly (see [[Vinogradov's theorem]]) that all [[sufficiently large]] odd numbers can be expressed as the sum of three primes. Vinogradov's original proof, as it used the ineffective [[Siegel–Walfisz theorem]], did not give a bound for "sufficiently large"; his student K. Borozdin proved that 3&lt;sup&gt;3&lt;sup&gt;15&lt;/sup&gt;&lt;/sup&gt; is large enough.&lt;ref&gt;Golomb gives the date of Borozdin's proof as 1956; in contrast, Tao states that it was "soon after" Vinogradov's 1937 proof. {{citation|title=The invincible primes|first=Solomon W.|last=Golomb|authorlink=Solomon W. Golomb|journal=The Sciences|volume=25|issue=2|pages=50–57|year=1985|doi=10.1002/j.2326-1951.1985.tb02782.x}}; {{citation|doi=10.1007/978-3-642-19533-4_1|contribution=Structure and Randomness in the Prime Numbers|first=Terence|last=Tao|authorlink=Terence Tao|pages=1–7|year=2011|title=An Invitation to Mathematics: From Competitions to Research|editor1-first=Dierk|editor1-last=Schleicher|editor2-first=Malte|editor2-last=Lackmann|publisher=Springer|isbn=978-3-642-19532-7}}, footnote 7, [https://books.google.com/books?id=9TATfteVeVYC&amp;pg=PA1 p.&amp;nbsp;1].&lt;/ref&gt; This number has 6,846,169 decimal digits, so checking every number under this figure would be completely infeasible.

In 1997, [[Jean-Marc Deshouillers|Deshouillers]], Effinger, [[Herman te Riele|te Riele]] and Zinoviev published a result showing&lt;ref&gt;{{cite journal|title=A complete Vinogradov 3-primes theorem under the Riemann hypothesis|last1=Deshouillers | first1=Jean-Marc | last2=Effinger | first2=Gove W. | last3=Te Riele | first3=Herman J. J. | first4=Dmitrii | last4=Zinoviev | mr=1469323 | doi=10.1090/S1079-6762-97-00031-0 |journal=Electronic Research Announcements of the American Mathematical Society|volume=3|pages=99–104|year=1997|issue=15}}&lt;/ref&gt; that the [[generalized Riemann hypothesis]] implies Goldbach's weak conjecture for all numbers. This result combines a general statement valid for numbers greater than 10&lt;sup&gt;20&lt;/sup&gt; with an extensive computer search of the small cases.  Saouter also conducted a computer search covering the same cases at approximately the same time.&lt;ref&gt;{{cite journal|title=Checking the odd Goldbach Conjecture up to 10&lt;sup&gt;20&lt;/sup&gt;|author=Yannick Saouter|journal=[[Math. Comp.]]|volume=67|pages=863–866|year=1998|url=http://www.ams.org/journals/mcom/1998-67-222/S0025-5718-98-00928-4/S0025-5718-98-00928-4.pdf|format=PDF|doi=10.1090/S0025-5718-98-00928-4 |issue=222 | mr=1451327}}&lt;/ref&gt;

[[Olivier Ramaré]] in 1995 showed that every even number ''n'' ≥ 4 is in fact the sum of at most six primes, from which it follows that every odd number ''n'' ≥ 5 is the sum of at most seven primes. [[Leszek Kaniecki]] showed every odd integer is a sum of at most five primes, under the [[Riemann Hypothesis]].&lt;ref&gt;{{cite journal|title=On Šnirelman's constant under the Riemann hypothesis|last=Kaniecki|first=Leszek|journal=[[Acta Arithmetica]]|volume=72|issue=4|year=1995|pages=361–374|url=http://matwbn.icm.edu.pl/ksiazki/aa/aa72/aa7246.pdf|mr=1348203|doi=10.4064/aa-72-4-361-374}}&lt;/ref&gt; In 2012, [[Terence Tao]] proved this without the Riemann Hypothesis; this improves both results.&lt;ref&gt;{{Cite journal|last=Tao |first=Terence|title=Every odd number greater than 1 is the sum of at most five primes |arxiv=1201.6656 |year=2014 | pages=997–1038 | mr=3143702 | journal=[[Math. Comp.]] | number=286 | volume=83 | doi=10.1090/S0025-5718-2013-02733-0}}&lt;/ref&gt;

In 2002, Liu Ming-Chit ([[University of Hong Kong]]) and Wang Tian-Ze lowered this threshold to approximately &lt;math&gt;n&gt;e^{3100}\approx 2 \times 10^{1346}&lt;/math&gt;. The [[exponent]] is still much too large to admit checking all smaller numbers by computer. (Computer searches have only reached as far as 10&lt;sup&gt;18&lt;/sup&gt; for the strong Goldbach conjecture, and not much further than that for the weak Goldbach conjecture.)

In 2012 and 2013, Peruvian mathematician [[Harald Helfgott]] released a pair of papers improving [[Hardy–Littlewood circle method|major and minor arc]] estimates sufficiently to unconditionally prove the weak Goldbach conjecture.&lt;ref&gt;{{cite arXiv |eprint=1305.2897 |title = Major arcs for Goldbach's theorem|last = Helfgott|first = Harald A. |class=math.NT |year=2013}}&lt;/ref&gt;&lt;ref&gt;{{cite arXiv |eprint=1205.5252 |title = Minor arcs for Goldbach's problem |last = Helfgott|first = Harald A.|class=math.NT |year=2012}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{cite arXiv |eprint=1312.7748 |title = The ternary Goldbach conjecture is true|last = Helfgott|first = Harald A. |class=math.NT |year=2013}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv | eprint=1501.05438| last=Helfgoot | first=Harald A. | class = math.NT | year = 2015 | title=The ternary Goldbach problem}}&lt;/ref&gt; Here, the major arcs &lt;math&gt;\mathfrak M&lt;/math&gt; is the union of intervals &lt;math&gt;\left (a/q-cr_0/qx,a/q+cr_0/qx\right )&lt;/math&gt; around the rationals &lt;math&gt;a/q,q&lt;r_0&lt;/math&gt; where &lt;math&gt;c&lt;/math&gt; is a constant. Minor arcs &lt;math&gt;\mathfrak{m}&lt;/math&gt; are defined to be &lt;math&gt;\mathfrak{m}=(\mathbb R/\mathbb Z)\setminus\mathfrak{M}&lt;/math&gt;.

==References==
{{reflist}}

{{Prime number conjectures}}

[[Category:Additive number theory]]
[[Category:Analytic number theory]]
[[Category:Conjectures about prime numbers]]
[[Category:Conjectures that have been proved]]

[[ru:Проблема Гольдбаха#Тернарная проблема Гольдбаха]]</text>
      <sha1>6kdo3zp8ywhyxrxg8j35tfu38wf2mrt</sha1>
    </revision>
  </page>
  <page>
    <title>Hardy hierarchy</title>
    <ns>0</ns>
    <id>25264191</id>
    <revision>
      <id>819968309</id>
      <parentid>818933402</parentid>
      <timestamp>2018-01-12T08:32:55Z</timestamp>
      <contributor>
        <username>Cyberbot II</username>
        <id>16283967</id>
      </contributor>
      <minor/>
      <comment>Removing {{[[Template:Blacklisted-links|Blacklisted-links]]}}.  No blacklisted links were found. ([[en:WP:PEACHY|Peachy 2.0 (alpha 8)]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3330">In [[computability theory]], [[computational complexity theory]] and [[proof theory]], the '''Hardy hierarchy''', named after [[G. H. Hardy]], is an ordinal-indexed family of functions ''h''&lt;sub&gt;α&lt;/sub&gt;:&amp;nbsp;'''N'''&amp;nbsp;→&amp;nbsp;'''N''' (where '''N''' is the set of [[natural numbers]], {0,&amp;nbsp;1,&amp;nbsp;...}). It is related to the [[fast-growing hierarchy]] and [[slow-growing hierarchy]]. The hierarchy was first described in Hardy's 1904 paper, "A theorem concerning the infinite cardinal numbers".

== Definition ==
Let μ be a [[large countable ordinal]] such that a [[fundamental sequence (ordinals)|fundamental sequence]] is assigned to every [[limit ordinal]] less than μ. The '''Hardy hierarchy''' of functions ''h''&lt;sub&gt;α&lt;/sub&gt;:&amp;nbsp;'''N'''&amp;nbsp;→&amp;nbsp;'''N''', for ''α''&amp;nbsp;&lt;&amp;nbsp;''μ'', is then defined as follows:

*&lt;math&gt; h_0(n) = n,&lt;/math&gt;
*&lt;math&gt; h_{\alpha+1}(n) = h_\alpha(n + 1),&lt;/math&gt;
*&lt;math&gt; h_\alpha(n) = h_{\alpha[n]}(n) &lt;/math&gt; if α is a limit ordinal.

Here α[''n''] denotes the ''n''&lt;sup&gt;th&lt;/sup&gt; element of the fundamental sequence assigned to the limit ordinal&amp;nbsp;''α''.  A standardized choice of fundamental sequence for all&amp;nbsp;''α''&amp;nbsp;≤&amp;nbsp;''ε''&lt;sub&gt;0&lt;/sub&gt; is described in the article on the [[Fast-growing hierarchy#The Wainer hierarchy|fast-growing hierarchy]].

Caicedo (2007) defines a modified Hardy hierarchy of functions &lt;math&gt;H_\alpha&lt;/math&gt; by using the standard fundamental sequences, but with α[''n''+1] (instead of α[''n'']) in the third line of the above definition.

== Relation to fast-growing hierarchy ==
The [[fast-growing hierarchy|Wainer hierarchy]] of functions ''f''&lt;sub&gt;α&lt;/sub&gt; and the Hardy hierarchy of functions ''h''&lt;sub&gt;α&lt;/sub&gt; are related by ''f''&lt;sub&gt;α&lt;/sub&gt; = ''h''&lt;sub&gt;ω&lt;sup&gt;α&lt;/sup&gt;&lt;/sub&gt; for all α &lt; ε&lt;sub&gt;0&lt;/sub&gt;.  Thus, for any α &lt; ε&lt;sub&gt;0&lt;/sub&gt;, ''h''&lt;sub&gt;α&lt;/sub&gt; grows much more slowly than does ''f''&lt;sub&gt;α&lt;/sub&gt;.   However, the Hardy hierarchy "catches up" to the Wainer hierarchy at α = ε&lt;sub&gt;0&lt;/sub&gt;, such that ''f''&lt;sub&gt;ε&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; and ''h''&lt;sub&gt;ε&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; have the same growth rate, in the sense that ''f''&lt;sub&gt;ε&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;(''n''-1) ≤ ''h''&lt;sub&gt;ε&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;(''n'') ≤ ''f''&lt;sub&gt;ε&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;(''n''+1) for all ''n'' ≥ 1. {{harv|Gallier|1991}}

== References ==
*{{citation|last= Hardy |first= G.H. |authorlink= G. H. Hardy|title= A theorem concerning the infinite cardinal numbers |journal= Quarterly Journal of Mathematics |volume= 35 |year= 1904 |pages= 87–94}}
*{{citation|mr=1129778|last= Gallier|first= Jean H.|authorlink= Jean Gallier |title= What's so special about Kruskal's theorem and the ordinal Γ&lt;sub&gt;0&lt;/sub&gt;? A survey of some results in proof theory|journal=  Ann. Pure Appl. Logic|volume=  53  |year=1991|issue=  3|pages= 199–260|url=https://www.cis.upenn.edu/~jean/kruskal.pdf|doi=10.1016/0168-0072(91)90022-E}}. (In particular Section 12, pp.&amp;nbsp;59–64, "A Glimpse at Hierarchies of Fast and Slow Growing Functions".)
* {{Citation |last=Caicedo |first=A. |title=Goodstein's function |url=http://andrescaicedo.files.wordpress.com/2008/04/goodstein.pdf |journal=Revista Colombiana de Matemáticas |volume=41 |issue=2 |year=2007 |pages=381–391 }}.

[[Category:Computability theory]]
[[Category:Proof theory]]
[[Category:Hierarchy of functions]]</text>
      <sha1>qcp46cujqk68nypa3d1x81db5v5cswt</sha1>
    </revision>
  </page>
  <page>
    <title>Hattendorf's theorem</title>
    <ns>0</ns>
    <id>44700778</id>
    <revision>
      <id>746302022</id>
      <parentid>737342599</parentid>
      <timestamp>2016-10-26T15:24:56Z</timestamp>
      <contributor>
        <ip>62.119.166.9</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10517">{{Multiple issues|
{{Orphan|date=August 2016}}
{{refimprove|date=December 2014}}
}}

'''Hattendorff's Theorem''', attributed to [[K. Hattendorff]] (1868), is a theorem in [[actuarial science]] that describes the allocation of the variance or risk of the [[Actuarial reserves|loss random variable]] over the lifetime of an [[Actuarial reserves|actuarial reserve]]. In other words, Hattendorff's theorem demonstrates that the variation in the present value of the loss of an issued insurance policy can be allocated to the future years during which the insured is still alive. This, in turn, facilitates the [[Risk management|management of risk]] prevalent in such insurance contracts over short periods of time.&lt;ref&gt;{{cite book | author=Bowers, N.L.| title=Actuarial Mathematics, 2nd Edition | year=1997 | pages=229–245|display-authors=etal}}&lt;/ref&gt;

== Hattendorff's Theorem ==

The main result of the theorem has three equivalent formulations:

{{Equation box 1
|indent=:
|title='''Hattendorff's Theorem'''
|equation=
&lt;math&gt; \begin{align}
&amp;\mathrm{Var}[L_h | K(x) \geq h] \\
&amp;=\sum_{k = h}^{\infty} v^{2(k - h)} \mathrm{Var}[\Lambda_k|K(x) \geq h] \\
&amp;=\mathrm{Var}[\Lambda_h|K(x)\geq h] + v^2 \mathrm{Var}[L_{h+1}|K(x) \geq h] \\
&amp;= \sum_{k = h}^{h + j - 1} v^{2(k - h)} \mathrm{Var}[\Lambda_k|K(x) \geq h] + v^{2 j}\mathrm{Var}[L_{h+j}|K(x)\geq h] 
\end{align}
&lt;/math&gt;
|cellpadding
|border
|border colour = #50C878
|background colour = #ECFCF4}}

where:

{| class="wikitable"
|-
! Variable !! Explanation
|-
| &lt;math&gt;K(x)&lt;/math&gt; || The number of whole years that a life status x survives. &lt;br /&gt;
If &lt;math&gt;T_x&lt;/math&gt; is the distribution of the lifetime of an insured, then &lt;math&gt;K(x)=\lfloor T_x \rfloor&lt;/math&gt;.
|-
| &lt;math&gt;_{k}p_{j}&lt;/math&gt; || Actuarial notation for &lt;math&gt;\mathrm{Pr}(j \leq T_x &lt; j + k)&lt;/math&gt;.
|-
| &lt;math&gt;\pi_j &lt;/math&gt;|| The premium received by the insured in year j.
|-
| &lt;math&gt;b_j&lt;/math&gt;|| The benefit paid to the insured in year j.
|-
| &lt;math&gt;L_h&lt;/math&gt; || The actuarial present value of the total loss over the remaining life of the policy at time h.
|-
| &lt;math&gt;C_h&lt;/math&gt; || The present value of the net cash loss from the policy in the year (h, h+1).
|-
| &lt;math&gt;v&lt;/math&gt; || The discount factor for one year.
|-
| &lt;math&gt;\Lambda_h&lt;/math&gt; || The present value of the net cash loss from the policy plus &lt;br /&gt;
the change in total liabilities in the year (h, h+1).
|-
| &lt;math&gt;V_h&lt;/math&gt; || The benefit reserve at time h, equal to &lt;math&gt;\mathbb{E}[L_h | K(x) \geq h]&lt;/math&gt;.
|}

In its above formulation, and in particular the first result, Hattendorff's theorem states that the variance of &lt;math&gt;L_h&lt;/math&gt;, the insurer's total loss over the remaining life of the policy at time h, can be calculated by discounting the variances of the yearly net losses (cash losses plus changes in net liabilities) &lt;math&gt;\Lambda_k&lt;/math&gt; in future years.

== Background&lt;ref&gt;{{cite news| author=Gerber, H.U., Leung, B.P.K., Shiu, E.S.W. | title=Indicator Function and Hattendorff's Theorem | journal=North American Actuarial Journal, Volume 7, Number 1| pages=41–42}}&lt;/ref&gt; ==

In the most general [[stochastic]] setting in which the analysis of reserves is carried out, consider an insurance policy written at time zero, over which the insured pays yearly premiums &lt;math&gt;\pi_0, \pi_1\dots \pi_{K(x)}&lt;/math&gt; at the beginning of each year starting today until the year of death of the insured. Furthermore, the insured receives a benefit of &lt;math&gt;K(x)+1&lt;/math&gt;, at the end of the year of death, equal to &lt;math&gt;b_{K(x)+1}&lt;/math&gt;. No other payments are received nor paid over the lifetime of the policy.

Suppose an insurance company is interested to know the cash loss from this policy over the year (h, h+1). Of course, if the death of the insured happens prior to time h, or when &lt;math&gt;K(x) &lt; h&lt;/math&gt;, then there is no remaining loss and &lt;math&gt;C_h = 0&lt;/math&gt;. If the death of the insured occurs exactly at time h, or when &lt;math&gt;K(x) = h&lt;/math&gt;, then the loss on the policy is equal to the present value of the benefit paid in the following year, &lt;math&gt;v b_{h+1}&lt;/math&gt;, less the premium paid at time h. Hence in this case &lt;math&gt;C_h = v b_{h + 1} - \pi_h.&lt;/math&gt; Lastly, if the death of the insured occurs after time h, or when &lt;math&gt;K(x) &gt; h&lt;/math&gt;, then the cash loss in the year (h, h+1) is just the negative of the premium received at time h (cash inflows are treated as negative losses). Hence we summarize this result as

:&lt;math&gt;
C_h =
\begin{cases}
0 &amp;\mbox{if } K(x) = 0,1 \dots h-1 \\ 
v b_{h + 1} - \pi_h &amp;\mbox{if } K(x) = h \\ 
-\pi_h &amp;\mbox{if } K(x) = h+1, h+2 \dots \\ 
\end{cases}
&lt;/math&gt;

Furthermore, the actuarial present value of the future cash losses in each year has the explicit formula

:&lt;math&gt;
L_h =
\begin{cases}
0 &amp;\mbox{if } K(x) = 0,1 \dots h-1 \\
v b_{K(x) + 1} - \pi_{K(x)} &amp;\mbox{if } K(x) = h \\
v^{K(x) - h + 1} b_{K(x) + 1} - \sum_{k=h}^{K(x)} v^{k-h} \pi_k &amp;\mbox{if } K(x) = h+1, h+2 \dots
\end{cases}
&lt;/math&gt;

:{| class="toccolours collapsible collapsed" width="80%" style="text-align:left"
!Derivation of the formula for &lt;math&gt;L_h&lt;/math&gt;.
|-
| The present value of the loss on the policy at time h is the present value of all future cash losses

:&lt;math&gt;
L_h = \sum_{k = h}^{\infty} v^{k - h} C_h.
&lt;/math&gt;

Expanding this result, it is easy to see using the definition of &lt;math&gt;C_h&lt;/math&gt; that, when &lt;math&gt;K(x)&gt;h&lt;/math&gt;,

:&lt;math&gt;
\begin{align}
L_h &amp;= \sum_{k = h}^{K(x)-1} v^{k - h} C_h + v^{K(x)-h} C_{K(x)} + \sum_{k = K(x)+1}^{\infty} v^{k-h}C_h \\
&amp;= -\sum_{k=h}^{K(x) - 1} v^{k-h} \pi_k + v^{K(x)-h} \left( v b_{K(x)+1} - \pi_h \right) \\
&amp;= v^{K(x) - h + 1} b_{K(x) + 1} - \sum_{k=h}^{K(x)} v^{k-h} \pi_k.
\end{align}
&lt;/math&gt;

Similarly, when &lt;math&gt;K(x) = h&lt;/math&gt;, then &lt;math&gt;L_h = C_{K(x)}&lt;/math&gt;. Finally, when &lt;math&gt;K(x) &lt; h&lt;/math&gt;, the summation, and hence the loss on the policy, is zero.
|}

In the analysis of reserves, a central quantity of interest is the benefit reserve &lt;math&gt;V_h&lt;/math&gt; at time h, which is the expected loss on the policy at time h given that status x has survived to age h

:&lt;math&gt;V_h = \mathbb{E}[L_h|K(x)\geq h]&lt;/math&gt;

which admits to the closed form expression

:&lt;math&gt;
V_h = \sum_{k = 0}^{\infty} \left( v^{k + 1} b_{k + h + 1} - \sum_{j=0}^{k} v^{j} \pi_{j+h}\right) {_{k}p_{x+h}} q_{x + h + k}
&lt;/math&gt;.

:{| class="toccolours collapsible collapsed" width="80%" style="text-align:left"
!Derivation of the formula for &lt;math&gt;V_h&lt;/math&gt;.
|-
| Here we derive the above formula for the benefit reserve.
:&lt;math&gt;
\begin{align}
V_h &amp;= \mathbb{E}[L_h|K(x)\geq h] \\
&amp;= \mathbb{E}\left[v^{K(x) - h + 1} b_{K(x) + 1} - \sum_{k=h}^{K(x)} v^{k-h} \pi_k | K(x) \geq h\right].
\end{align}
&lt;/math&gt;

In order to proceed, we make the assumption that the remaining lifetime of a life status x that has lived to time h, &lt;math&gt;K(x) - h&lt;/math&gt;, follows the same (kurtate) probability distribution as another randomly chosen individual from the group of insureds but of age &lt;math&gt;x + h&lt;/math&gt;, with distribution &lt;math&gt;K(x+h)&lt;/math&gt;. This means that, in terms of expected values, &lt;math&gt;\mathbb{E}[f(K(x) - h)|K(x) \geq h] = \mathbb{E}[f(K(x+h))]&lt;/math&gt; for any function over which the expectation is defined. Then, using a clever algebraic trick, we can rewrite the benefit reserve as

:&lt;math&gt;
\begin{align}
V_h &amp;= \mathbb{E}\left[v^{(K(x) - h) + 1} b_{(K(x) - h) + h + 1} - \sum_{j=0}^{K(x) - h} v^{j} \pi_{j+h} | K(x) \geq h\right] \\
&amp;= \mathbb{E}\left[v^{K(x+h) + 1} b_{K(x+h) + h + 1} - \sum_{j=0}^{K(x+h)} v^{j} \pi_{j+h}\right] \\
&amp;= \sum_{k = 0}^{\infty} \left( v^{k + 1} b_{k + h + 1} - \sum_{j=0}^{k} v^{j} \pi_{j+h}\right) \mathrm{Pr}(K(x+h) = k) \\
&amp;= {\sum_{k = 0}^{\infty} \left(v^{k + 1} b_{k + h + 1} - \sum_{j=0}^{k} v^{j} \pi_{j+h}\right)} {_{k}p_{x+h}} q_{x + h + k}
\end{align}
&lt;/math&gt;
|}

Lastly, the present value of the net cash loss at time h over the year (h, h+1), denoted &lt;math&gt;\Lambda_h&lt;/math&gt;, is equal to the present value of the cash loss in year h, &lt;math&gt;C_h&lt;/math&gt; (see above), plus the present value of the change in liabilites &lt;math&gt;PV(\Delta V_h)&lt;/math&gt; at time h. In other words, &lt;math&gt;\Lambda_h = C_h + v\Delta Liabilities&lt;/math&gt;. If &lt;math&gt;K(x) &gt; h&lt;/math&gt;, then &lt;math&gt;\Lambda_h = -\pi_h + (v V_{h+1} - V_h)&lt;/math&gt;. Similarly, if &lt;math&gt;K(x) = h&lt;/math&gt;, then &lt;math&gt;\Lambda_h = (v b_{h+1} - \pi_h) - V_h&lt;/math&gt; since there is no reserve after the year of death. Finally, if &lt;math&gt;K(x) &lt; h&lt;/math&gt;, then there is no loss in the future and &lt;math&gt;\Lambda_h = 0&lt;/math&gt;. Summarizing, this yields the following result, which is important in the formulation of Hattendorff's theorem

:&lt;math&gt;
\Lambda_h = 
\begin{cases}
0 &amp;\mbox{if } K(x) = 0,1 \dots h - 1 \\
(v b_{h+1} - \pi_h) - V_h &amp;\mbox{if } K(x) = h \\
(v V_{h+1} - V_h) - \pi_h &amp;\mbox{if } K(x) = h + 1, h + 2 \dots
\end{cases}.
&lt;/math&gt;

== Proofs ==

The proof of the first equality is written as follows. First, by writing the present value of future net losses at time h,

:&lt;math&gt;
\begin{align}
\sum_{k = h}^{\infty} v^{k - h} \Lambda_k &amp;= \sum_{k = h}^{\infty} v^{k - h} [C_k + v\Delta \text{Liabilities in year }(k, k+1)] \\
&amp;= \sum_{k = h}^{\infty} v^{k - h} C_k + \sum_{k = h}^{\infty} v^{k - h + 1} \Delta \text{Liabilities in year }(k, k+1)\\
&amp;= L_h + \sum_{k = h}^{\infty} v^{k - h + 1} (vV_{k+1}- V_k) \\
&amp;= L_h + \sum_{k = h}^{\infty} v^{(k + 1) - h + 1} V_{k+1} - \sum_{k = h}^{\infty} v^{k - h + 1} V_k \\
\end{align}
&lt;/math&gt;

from which it is easy to see that

:&lt;math&gt;
L_h = \sum_{k = h}^{\infty} v^{k - h} \Lambda_k + V_h.
&lt;/math&gt;

It is known that the individual net cash flows in different years are uncorrelated, or &lt;math&gt;\mathrm{Cov}(\Lambda_h\Lambda_j | K(x) \geq k) = 0&lt;/math&gt; when &lt;math&gt;k \leq h &lt; j&lt;/math&gt; (see Bowers et al., 1997, for a proof of this result). Using these two results, we conclude that

&lt;math&gt;
\mathrm{Var}[L_h|K(x)\geq h] = \mathrm{Var}\left[\sum_{k = h}^{\infty} v^{k - h} \Lambda_k + V_h |K(x) \geq h \right] 
= \sum_{k = h}^{\infty} v^{2(k - h)} \mathrm{Var}[\Lambda_k|K(x)\geq h] 
&lt;/math&gt;

which proves the first part of the theorem. The reader is referred to (Bowers et al., pg 241) for the proof of the other equalities.

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags, these references will then appear here automatically --&gt;
{{Reflist}}

== External links ==
* [https://www.youtube.com/watch?v=wk2xg8b_4ug YouTube video explanation]

&lt;!--- Categories ---&gt;
[[Category:Articles created via the Article Wizard]]
[[Category:Actuarial science]]</text>
      <sha1>934e2a2zetd3k3ax2gvm5nuo84jvn03</sha1>
    </revision>
  </page>
  <page>
    <title>Higher residuosity problem</title>
    <ns>0</ns>
    <id>6158260</id>
    <revision>
      <id>864436820</id>
      <parentid>627255269</parentid>
      <timestamp>2018-10-17T05:48:16Z</timestamp>
      <contributor>
        <username>BenKuykendall</username>
        <id>12604315</id>
      </contributor>
      <comment>added computational hardness assumption template</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3801">
In [[cryptography]], most [[Public-key cryptography|public key cryptosystems]] are founded on problems that are believed to be intractable.  The '''higher residuosity problem''' (also called the '''n th-residuosity problem'''&lt;ref name=Zhang1988&gt;{{cite journal|last=Zhang|first=Yuliang|author2=Tsutomu Matsumoto  |author3=Hideki Imai |title=Cryptographic Applications of th-Residuosity Problem with an Odd Integer|journal=Transactions of the IEICE|date=1988|volume=71|issue=8|pages=759-767|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.137.8511|accessdate=14 February 2014}}&lt;/ref&gt;) is one such problem.  This problem is ''easier'' to solve than [[integer factorization]], so the assumption that this problem is hard to solve is ''stronger'' than the assumption that integer factorization is hard.

==Mathematical Background==
If ''n'' is an [[integer]], then the integers [[Modular arithmetic|modulo]] ''n'' form a [[Ring (mathematics)|ring]].  If ''n''=''pq'' where ''p'' and ''q'' are [[Prime number|primes]], then the [[Chinese remainder theorem]] tells us that

:&lt;math&gt;\mathbb{Z}/n\mathbb{Z} \simeq \mathbb{Z}/p\mathbb{Z} \times \mathbb{Z}/q\mathbb{Z}&lt;/math&gt;

The [[Unit (ring theory)|group of units]] of any ring form a [[Group (mathematics)|group]], and the group of units in &lt;math&gt;\mathbb{Z}/n\mathbb{Z}&lt;/math&gt; is traditionally denoted &lt;math&gt;(\mathbb{Z}/n\mathbb{Z})
^*&lt;/math&gt;.

From the isomorphism above, we have

:&lt;math&gt;(\mathbb{Z}/n\mathbb{Z})^* \simeq (\mathbb{Z}/p\mathbb{Z})^* \times (\mathbb{Z}/q\mathbb{Z})^*&lt;/math&gt;

as an isomorphism of ''groups''.  Since ''p'' and ''q'' were assumed to be prime, the groups &lt;math&gt;(\mathbb{Z}/p\mathbb{Z})^*&lt;/math&gt; and &lt;math&gt;(\mathbb{Z}/q\mathbb{Z})^*&lt;/math&gt; are [[Cyclic group|cyclic]] of orders ''p''-1 and ''q''-1 respectively.  If ''d'' is a divisor of ''p''-1, then the set of ''d''th powers in &lt;math&gt;(\mathbb{Z}/p\mathbb{Z})^*&lt;/math&gt; form a subgroup of [[Index of a subgroup|index]] ''d''.  If gcd(''d'',''q''-1) = 1, then ''every'' element in &lt;math&gt;(\mathbb{Z}/q\mathbb{Z})^*&lt;/math&gt; is a ''d''th power, so the set of ''d''th powers in &lt;math&gt;(\mathbb{Z}/n\mathbb{Z})^*&lt;/math&gt; is also a subgroup of index ''d''.  In general, if gcd(''d'',''q''-1) = ''g'', then there are (''q''-1)/(''g'') ''d''th powers in &lt;math&gt;(\mathbb{Z}/q\mathbb{Z})^*&lt;/math&gt;, so the set of ''d''th powers in &lt;math&gt;(\mathbb{Z}/n\mathbb{Z})^*&lt;/math&gt; has index ''dg''.
This is most commonly seen when ''d''=2, and we are considering the subgroup of [[quadratic residues]], it is well known that exactly one quarter of the elements in &lt;math&gt;(\mathbb{Z}/n\mathbb{Z})^*&lt;/math&gt; are
quadratic residues (when ''n'' is the product of exactly two primes, as it is here).

The important point is that for any divisor ''d'' of ''p''-1 (or ''q''-1) the set of ''d''th powers forms a subgroup of &lt;math&gt;(\mathbb{Z}/n\mathbb{Z})^*.&lt;/math&gt;

==Problem Statement==
Given an integer ''n'' = ''pq'' where ''p'' and ''q'' are unknown, an integer ''d'' such that ''d'' divides ''p''-1, and an integer ''x'' &amp;lt; ''n'', it is infeasible to determine whether ''x'' is a ''d''th power (equivalently ''d''th residue) modulo ''n''.

Notice that if ''p'' and ''q'' are known it is easy to determine whether ''x'' is a ''d''th residue modulo ''n'' because ''x'' will be a ''d''th residue modulo ''p'' if and only if

:&lt;math&gt;x^{(p-1)/d} \equiv 1 \pmod p&lt;/math&gt;

When ''d''=2, this is called the [[quadratic residuosity problem]].

==Applications==
The [[semantic security]] of the [[Benaloh cryptosystem]] and the [[Naccache-Stern cryptosystem]] rests on the intractability of this problem.

==References==
{{reflist}}

{{Computational hardness assumptions}}

{{DEFAULTSORT:Higher Residuosity Problem}}
[[Category:Computational number theory]]
[[Category:Computational hardness assumptions]]</text>
      <sha1>8tif6eiti45skvoslxbreiqljc8sah6</sha1>
    </revision>
  </page>
  <page>
    <title>Hilbert–Samuel function</title>
    <ns>0</ns>
    <id>25360121</id>
    <revision>
      <id>860499366</id>
      <parentid>788973036</parentid>
      <timestamp>2018-09-21T02:27:45Z</timestamp>
      <contributor>
        <username>SpecZ</username>
        <id>1597349</id>
      </contributor>
      <minor/>
      <comment>Corrected chi-values in example</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3715">In [[commutative algebra]] the '''Hilbert–Samuel function''', named after [[David Hilbert]] and [[Pierre Samuel]],&lt;ref&gt;H. Hironaka, Resolution of Singularities of an Algebraic Variety Over a Field of Characteristic Zero: I. Ann. of Math. 2nd Ser., Vol. 79, No. 1. (Jan., 1964), pp. 109-203.&lt;/ref&gt; of a nonzero finitely generated [[module (mathematics)|module]] &lt;math&gt;M&lt;/math&gt; over a commutative [[Noetherian]] [[local ring]] &lt;math&gt;A&lt;/math&gt; and a [[primary ideal]] &lt;math&gt;I&lt;/math&gt; of &lt;math&gt;A&lt;/math&gt; is the map &lt;math&gt;\chi_{M}^{I}:\mathbb{N}\rightarrow\mathbb{N}&lt;/math&gt; such that, for all &lt;math&gt;n\in\mathbb{N}&lt;/math&gt;,

:&lt;math&gt;\chi_{M}^{I}(n)=\ell(M/I^{n}M)&lt;/math&gt;

where &lt;math&gt;\ell&lt;/math&gt; denotes the [[length of a module|length]] over &lt;math&gt;A&lt;/math&gt;. It is related to the [[Hilbert function]] of the [[associated graded module]] &lt;math&gt;\operatorname{gr}_I(M)&lt;/math&gt; by the identity

: &lt;math&gt;\chi_M^I (n)=\sum_{i=0}^n H(\operatorname{gr}_I(M),i).&lt;/math&gt;

For sufficiently large &lt;math&gt;n&lt;/math&gt;, it coincides with a polynomial function of degree equal to &lt;math&gt;\dim(\operatorname{gr}_I(M))&lt;/math&gt;.&lt;ref name="ica"&gt;Atiyah, M. F. and MacDonald, I. G. ''Introduction to Commutative Algebra''. Reading, MA: Addison–Wesley, 1969.&lt;/ref&gt;

==Examples==

For the [[ring (mathematics)|ring]] of [[formal power series]] in two variables &lt;math&gt;k[[x,y]]&lt;/math&gt; taken as a module over itself and the ideal &lt;math&gt;I&lt;/math&gt; generated by the monomials ''x''&lt;sup&gt;2&lt;/sup&gt; and ''y''&lt;sup&gt;3&lt;/sup&gt; we have

: &lt;math&gt;\chi(1)=6,\quad \chi(2)=18,\quad \chi(3)=36,\quad \chi(4)=60,\text{ and in general } \chi(n)=3n(n+1)\text{ for }n \geq 0.&lt;/math&gt;&lt;ref name="ica"/&gt;

== Degree bounds ==
Unlike the Hilbert function, the Hilbert–Samuel function is not additive on an exact sequence. However, it is still reasonably close to being additive, as a consequence of the [[Artin–Rees lemma]]. We denote by &lt;math&gt;P_{I, M}&lt;/math&gt; the Hilbert-Samuel polynomial; i.e., it coincides with the Hilbert–Samuel function for large integers.
 
{{math_theorem|Let &lt;math&gt;(R, m)&lt;/math&gt; be a Noethrian local ring and ''I'' an m-[[primary ideal]]. If
:&lt;math&gt;0 \to M' \to M \to M'' \to 0&lt;/math&gt;
is an exact sequence of finitely generated ''R''-modules and if &lt;math&gt;M/I M&lt;/math&gt; has finite length,&lt;ref&gt;This implies that &lt;math&gt;M'/IM'&lt;/math&gt; and &lt;math&gt;M''/IM''&lt;/math&gt; also have finite length.&lt;/ref&gt; then we have:&lt;ref&gt;[[David Eisenbud|Eisenbud, David]], ''Commutative Algebra with a View Toward Algebraic Geometry'', Graduate Texts in Mathematics, 150, Springer-Verlag, 1995, {{ISBN|0-387-94268-8}}. Lemma 12.3.&lt;/ref&gt;
:&lt;math&gt;P_{I, M} = P_{I, M'} + P_{I, M''} - F&lt;/math&gt;
where ''F'' is a polynomial of degree strictly less than that of &lt;math&gt;P_{I, M'}&lt;/math&gt; and having positive leading coefficient. In particular, if &lt;math&gt;M' \simeq M&lt;/math&gt;, then the degree of &lt;math&gt;P_{I, M''}&lt;/math&gt; is strictly less than that of &lt;math&gt;P_{I, M} = P_{I, M'}&lt;/math&gt;.}}

Proof: Tensoring the given exact sequence with &lt;math&gt;R/I^n&lt;/math&gt; and computing the kernel we get the exact sequence:
:&lt;math&gt;0 \to (I^n M \cap M')/I^n M' \to M'/I^n M' \to M/I^n M \to M''/I^n M'' \to 0,&lt;/math&gt;
which gives us:
:&lt;math&gt;\chi_M^I(n-1) = \chi_{M'}^I(n-1) + \chi_{M''}^I(n-1) - \ell((I^n M \cap M')/I^n M')&lt;/math&gt;.
The third term on the right can be estimated by Artin-Rees. Indeed, by the lemma, for large ''n'' and some ''k'',
:&lt;math&gt;I^n M \cap M' = I^{n-k} ((I^k M) \cap M') \subset I^{n-k} M'.&lt;/math&gt;
Thus,
:&lt;math&gt;\ell((I^n M \cap M') / I^n M') \le \chi^I_{M'}(n-1) - \chi^I_{M'}(n-k-1)&lt;/math&gt;.
This gives the desired degree bound.

== See also ==
*[[j-multiplicity]]

==References==
&lt;references/&gt;

{{DEFAULTSORT:Hilbert-Samuel function}}
[[Category:Commutative algebra]]
[[Category:Algebraic geometry]]</text>
      <sha1>s5sbh99p897uoqsqa9ojk8lbawy91ky</sha1>
    </revision>
  </page>
  <page>
    <title>Index notation</title>
    <ns>0</ns>
    <id>320026</id>
    <revision>
      <id>850354317</id>
      <parentid>850354294</parentid>
      <timestamp>2018-07-15T10:36:52Z</timestamp>
      <contributor>
        <username>LW001</username>
        <id>34179896</id>
      </contributor>
      <comment>Undid revision 850354294 by [[Special:Contributions/61.6.152.245|61.6.152.245]] ([[User talk:61.6.152.245|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9751">{{for|''index notation'', or ''indicial notation'' in relativity theory|Einstein notation}}
In [[mathematics]] and [[computer programming]], '''index notation''' is used to specify the elements of an array of numbers. The formalism of how indices are used varies according to the subject.  In particular, there are different methods for referring to the elements of a list, a vector, or a matrix, depending on whether one is writing a formal mathematical paper for publication, or when one is writing a [[computer program]].

==Index notation in mathematics==

{{Main|Ricci calculus|tensor}}

It is frequently helpful in mathematics to refer to the elements of an array using subscripts. The subscripts can be [[integer]]s or [[Variable (mathematics)|variables]]. The array takes the form of [[tensors]] in general, since these can be treated as multi-dimensional arrays. Special (and more familiar) cases are [[vector (geometry)|vectors]] (1d arrays) and [[matrix (mathematics)|matrices]] (2d arrays).

The following is only an introduction to the concept: index notation is used in more detail in mathematics (particularly in the representation and manipulation of [[tensor#Operations|tensor operations]]). See the main article for further details.

===One-dimensional arrays (vectors)===

{{main|Vector (mathematics and physics)}}

A vector treated as an array of numbers by writing as a [[row vector]] or [[column vector]] (whichever is used depends on convenience or context):

:&lt;math&gt;\mathbf{a} = \begin{pmatrix}
    a_1 \\
    a_2 \\
    \vdots \\
    a_n  
  \end{pmatrix}, \quad \mathbf{a} = \begin{pmatrix}
    a_1 &amp; a_2 &amp; \cdots &amp; a_n \\ 
\end{pmatrix}&lt;/math&gt;

Index notation allows indication of the elements of the array by simply writing ''a&lt;sub&gt;i&lt;/sub&gt;'', where the index ''i'' is known to run from 1 to ''n''.&lt;ref&gt;An introduction to Tensor Analysis: For Engineers and Applied Scientists, J.R. Tyldesley, Longman, 1975, {{ISBN|0-582-44355-5}}&lt;/ref&gt;
For example, given the vector:

:&lt;math&gt;\mathbf{a} = \begin{pmatrix}
  10 &amp; 8 &amp; 9 &amp; 6 &amp; 3 &amp; 5 \\ 
\end{pmatrix}&lt;/math&gt;

then some entries are

:&lt;math&gt;a_1 = 10,\, a_2 = 8,\, \cdots,\, a_6 = 5 &lt;/math&gt;.

The notation can be applied to [[vectors in mathematics and physics]]. The following [[vector equation]]

:&lt;math&gt;\mathbf{a} + \mathbf{b} = \mathbf{c}&lt;/math&gt;

can also be written in terms of the elements of the vector (aka components), that is

:&lt;math&gt; a_i + b_i = c_i &lt;/math&gt;

where the indices take a given range of values. This expression represents a set of equations, one for each index. If the vectors each have ''n'' elements, meaning ''i'' = 1,2...''n'', then the equations are explicitly

:&lt;math&gt;\begin{align}
  a_1 + b_1 &amp;= c_1 \\
  a_2 + b_2 &amp;= c_2 \\
            &amp;\ \ \vdots \\
  a_n + b_n &amp;= c_n
\end{align}&lt;/math&gt;

Hence, index notation serves as an efficient shorthand for
#representing the general structure to an equation,
#while applicable to individual components.

===Two-dimensional arrays===
[[File:Matrix.svg|thumb|247px|right|Elements of matrix '''A''' are described with two subscripts or indices.]]
{{main|matrix (mathematics)}}
{{see also|Dyadics}}

More than one index is used to describe arrays of numbers, in two or more dimensions, such as the elements of a matrix, (see also image to right);

:&lt;math&gt;\mathbf{A} = \begin{pmatrix}
  a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n} \\
  a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n} \\
  \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
  a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn} \\
\end{pmatrix}&lt;/math&gt;

The entry of a matrix '''A''' is written using two indices, say ''i'' and ''j'', with or without commas to separate the indices: ''a&lt;sub&gt;ij&lt;/sub&gt;'' or ''a&lt;sub&gt;i,j&lt;/sub&gt;'', where the first subscript is the row number and the second is the column number. [[Multiplication|Juxtaposition]] is also used as notation for multiplication; this may be a source of confusion. For example, if

:&lt;math&gt;\mathbf{A} = \begin{pmatrix}
  9 &amp; 8 &amp; 6 \\
  1 &amp; 2 &amp; 7 \\
  4 &amp; 9 &amp; 2 \\
  6 &amp; 0 &amp; 5 
\end{pmatrix}&lt;/math&gt;

then some entries are

:&lt;math&gt;a_{11} = 9,\, a_{12} = 8,\, a_{21} = 1,\, \cdots,\, a_{23} = 7,\, \cdots &lt;/math&gt;.

For indices larger than 9, the comma-based notation may be superior (e.g., ''a''&lt;sub&gt;3,12&lt;/sub&gt; instead of ''a''&lt;sub&gt;312&lt;/sub&gt;).

[[Matrix equation]]s are written similarly to vector equations, such as

:&lt;math&gt; \mathbf{A} + \mathbf{B} = \mathbf{C} &lt;/math&gt;

in terms of the elements of the matrices (aka components)

:&lt;math&gt; A_{ij} + B_{ij} = C_{ij} &lt;/math&gt;

for all values of ''i'' and ''j''. Again this expression represents a set of equations, one for each index. If the matrices each have ''m'' rows and ''n'' columns, meaning {{nowrap|''i'' {{=}} 1, 2, …, ''m''}} and {{nowrap|''j'' {{=}} 1, 2, …, ''n''}}, then there are ''mn'' equations.

===Multi-dimensional arrays===

{{main|tensors}}
{{see also|classical treatment of tensors}}

The notation allows a clear generalization to multi-dimensional arrays of elements: tensors. For example,

:&lt;math&gt; A_{i_1 i_2 \cdots } + B_{i_1 i_2 \cdots} = C_{i_1 i_2 \cdots} &lt;/math&gt;

representing a set of many equations.

In tensor analysis, superscripts are used instead of subscripts to distinguish covariant from contravariant entities, see [[covariance and contravariance of vectors]] and [[raising and lowering indices]].

==Index notation in computing==
In several programming languages, index notation is a way of addressing elements of an array. This method is used since it is closest to how it is implemented in [[assembly language]] whereby the address of the first element is used as a base, and a multiple (the index) of the element size is used to address inside the array.

For example, if an array of integers is stored in a region of the computer's memory starting at the memory cell with address 3000 (the [[base address]]), and each integer occupies four cells (bytes), then the elements of this array are at memory locations 0x3000, 0x3004, 0x3008, …, 0x3000 + 4(''n'' − 1). In general, the address of the ''i''th element of an array with [[base address]] ''b'' and element size ''s'' is {{nowrap|''b'' + ''is''}}.

==C implementation details==
In the [[C (programming language)|C programming language]], we can write the above as {{code|*(base + i)}} (pointer form) or {{code|base[i]}} (array indexing form), which is exactly equivalent because the C standard defines the array indexing form as a transformation to pointer form. Coincidentally, since pointer addition is commutative, this allows for obscure expressions such as {{code|3[base]}} which is equivalent to {{code|base[3]}}.&lt;ref&gt;Programming with C++, J. Hubbard, Schaum’s Outlines, McGraw Hill (USA), 1996, {{ISBN|0-07-114328-9}}&lt;/ref&gt;

===Multidimensional arrays===
Things become more interesting when we consider arrays with more than one index, for example, a two-dimensional table. We have three possibilities:
* make the two-dimensional array one-dimensional by computing a single index from the two
* consider a one-dimensional array where each element is another one-dimensional array, i.e. an array of arrays
* use additional storage to hold the array of addresses of each row of the original array, and store the rows of the original array as separate one-dimensional arrays
In C, all three methods can be used. When the first method is used, the programmer decides how the elements of the array are laid out in the computer's memory, and provides the formulas to compute the location of each element. The second method is used when the number of elements in each row is the same and known at the time the program is written. The programmer declares the array to have, say, three columns by writing e.g. {{code|elementtype tablename[][3];}}. One then refers to a particular element of the array by writing {{code|tablename[first index][second index]}}.  The compiler computes the total number of memory cells occupied by each row, uses the first index to find the address of the desired row, and then uses the second index to find the address of the desired element in the row. When the third method is used, the programmer declares the table to be an array of pointers, like in {{code|elementtype *tablename[];}}. When the programmer subsequently specifies a particular element {{code|tablename[first index][second index]}}, the compiler generates instructions to look up the address of the row specified by the first index, and use this address as the base when computing the address of the element specified by the second index.

===Example===
This function multiplies two 3x3 floating point matrices together.
&lt;source lang="c"&gt;
 void mult3x3f(float result[][3], const float A[][3], const float B[][3])
 {
   int i, j, k;
   for (i = 0; i &lt; 3; ++i) {
     for (j = 0; j &lt; 3; ++j) {
       result[i][j] = 0;
       for (k = 0; k &lt; 3; ++k)
         result[i][j] += A[i][k] * B[k][j];
     }
   }
 }
&lt;/source&gt;

==In other languages==
In other programming languages such as Pascal, indices may start at 1, so indexing in a block of memory can be changed to fit a start-at-1 addressing scheme by a simple linear transformation - in this scheme, the memory location of the ''i''th element with [[base address]] ''b'' and element size ''s'' is {{nowrap|''b'' + (''i'' − 1)''s''}}.

==References==
{{reflist}}
* ''Programming with C++'', J. Hubbard, Schaum’s Outlines, McGraw Hill (USA), 1996, {{ISBN|0-07-114328-9}}
* ''Tensor Calculus'', D.C. Kay, Schaum’s Outlines, McGraw Hill (USA), 1988, {{ISBN|0-07-033484-6}}
* ''Mathematical methods for physics and engineering'', K.F. Riley, M.P. Hobson, S.J. Bence, Cambridge University Press, 2010, {{ISBN|978-0-521-86153-3}}

==External links==

{{DEFAULTSORT:Index Notation}}
[[Category:Mathematical notation]]
[[Category:Programming constructs]]</text>
      <sha1>caocps7sngz1l6gve678mgim68jij6f</sha1>
    </revision>
  </page>
  <page>
    <title>Inductive type</title>
    <ns>0</ns>
    <id>22778065</id>
    <revision>
      <id>857637686</id>
      <parentid>844871959</parentid>
      <timestamp>2018-09-02T01:25:43Z</timestamp>
      <contributor>
        <username>Rosguill</username>
        <id>32763026</id>
      </contributor>
      <minor/>
      <comment>link [[Induction-induction]] using [[:en:User:Edward/Find link|Find link]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9850">{{More citations needed|date=January 2018}}
{{Merge|Recursive data type|date=January 2018}}

In [[type theory]], a system has '''inductive types''' if it has facilities for creating a new type along with constants and functions that create terms of that type.  The feature serves a role similar to [[data structure]]s in a programming language and allows a type theory to add concepts like [[number]]s, [[Relation (mathematics)|relations]], and [[Tree (graph theory)|trees]].  As the name suggests, inductive types can be self-referential, but usually only in a way that permits [[structural recursion]].

The standard example is encoding the [[natural number]]s using [[Peano axioms|Peano's encoding]].
&lt;source lang="coq"&gt;
 Inductive nat : Type :=
   | 0 : nat
   | S : nat -&gt; nat.
&lt;/source&gt;
Here, a natural number is created either from the constant "0" or by applying the function "S" to another natural number.  "S" is the [[successor function]] which represents adding 1 to a number.  Thus, "0" is zero, "S 0" is one, "S (S 0)" is two, "S (S (S 0))" is three, and so on.

Since their introduction, inductive types have been extended to encode more and more structures, while still being [[Impredicative|predicative]] and supporting structural recursion.

== Elimination ==

Inductive types usually come with a function to prove properties about them.  Thus, "nat" may come with:
&lt;source lang="coq"&gt;
 nat_elim : (forall P : nat -&gt; Prop, (P 0) -&gt; (forall n, P n -&gt; P (S n)) -&gt; (forall n, P n)).
&lt;/source&gt;
This is the expected function for structural recursion for the type "nat".

== Implementations ==

=== W- and M-types ===

W-types are [[Well-founded relation|well-founded]] types in [[intuitionistic type theory]] (ITT).&lt;ref&gt;{{Cite book|url=http://intuitionistic.files.wordpress.com/2010/07/martin-lof-tt.pdf|title=Intuitionistic type theory|last=Martin-Löf|first=Per|date=1984|publisher=Bibliopolis|others=Sambin, Giovanni|isbn=8870881059|location=Napoli|oclc=12731401}}&lt;/ref&gt; They generalize natural numbers, lists, binary trees, and other "tree-shaped" data types. Let {{var|U}} be a [[Universe (mathematics)#In type theory|universe of types]]. Given a type {{var|A}} : {{var|U}} and a [[Dependent type|dependent family]] {{var|B}} : {{var|A}} → {{var|U}}, one can form a W-type &lt;math&gt;\mathsf{W}_{(a:A)} B(a)&lt;/math&gt;. The type {{var|A}} may be thought of as "labels" for the (potentially infinitely many) constructors of the inductive type being defined, whereas {{var|B}} indicates the (potentially infinite) [[arity]] of each constructor. W-types (resp. M-types) may also be understood as well-founded (resp. non-well-founded) trees with nodes labeled by elements {{var|a}} : {{var|A}} and where the node labeled by {{var|a}} has {{var|B}}({{var|a}})-many subtrees.&lt;ref&gt;{{cite arxiv|last=Ahrens|first=Benedikt|last2=Capriotti|first2=Paolo|last3=Spadotti|first3=Régis|date=2015-04-12|title=Non-wellfounded trees in Homotopy Type Theory|eprint=1504.02949|class=cs.LO}}&lt;/ref&gt;

Let '''0''', '''1''', '''2''', etc. be finite types with inhabitants 1&lt;sub&gt;'''1'''&lt;/sub&gt; : '''1''', 1&lt;sub&gt;'''2'''&lt;/sub&gt;, 2&lt;sub&gt;'''2'''&lt;/sub&gt;:'''2''', etc. One may define the natural numbers as the W-type

:&lt;math display="block"&gt;
\mathbb{N}:= \mathsf{W}_{(x:\mathbf{2})} f(x)
&lt;/math&gt;

with {{var|f}} : '''2''' → {{var|U}} is defined by {{var|f}}(1&lt;sub&gt;'''2'''&lt;/sub&gt;) = '''0''' (representing the constructor for zero, which takes no arguments), and {{var|f}}(2&lt;sub&gt;'''2'''&lt;/sub&gt;) = '''1''' (representing the successor function, which takes one argument).

One may define lists over a type {{var|A}} : {{var|U}} as &lt;math&gt;\operatorname{List}(A) := \mathsf{W}_{(x:\mathbf{1}+A)} f(x)&lt;/math&gt; where
:&lt;math display="block"&gt;
\begin{align}
  f(\operatorname{inl}(1_{\mathbf{1}})) &amp;= \mathbf{0} \\
  f(\operatorname{inr}(a)) &amp;= \mathbf{1}
\end{align}
&lt;/math&gt;
and 1&lt;sub&gt;'''1'''&lt;/sub&gt; is the sole inhabitant of '''1'''. The value of &lt;math&gt;f(\operatorname{inl}(1_{\mathbf{1}}))&lt;/math&gt; corresponds to the constructor for the empty list, whereas the value of &lt;math&gt;f(\operatorname{inr}(a))&lt;/math&gt; corresponds to the constructor that appends {{var|a}} to the beginning of another list.

The constructor for elements of a generic W-type &lt;math&gt;\mathsf{W}_{(a:A)} B(a)&lt;/math&gt; has type
:&lt;math display="block"&gt;
\mathsf{sup}:\prod_{(a:A)}\Big(B(a)\to\mathsf{W}_{(x:A)}B(x)\Big)\to \mathsf{W}_{(x:A)} B(x).
&lt;/math&gt;
We can also write this rule in the style of a [[natural deduction]] proof,
:&lt;math displaystyle="block"&gt;
\frac{
  a:A
  \qquad
  f:B(a)\to\mathsf{W}_{a:A}B(a)
}{
  \mathsf{sup}(a,f):\mathsf{W}_{a:A}B(a)
}.
&lt;/math&gt;

The elimination rule for W-types works similarly to [[structural induction]] on trees. If, whenever a property (under the [[Curry–Howard correspondence|propositions-as-types]] interpretation) {{var|C}} : {{var|A}} → {{var|U}} holds for all subtrees of a given tree it also holds for that tree, then it holds for all trees.

:&lt;math displaystyle="block"&gt;
\frac{
  w:\mathsf{W}_{a:A}B(a)
  \qquad
  a:A, \; f:B(a)\to\mathsf{W}_{a:A}B(a), \;
  c:\prod_{b:B(a)} C(f(b))
  \;\vdash\; h(a,f,c):C(\mathsf{sup}(a,f))
}{
  \mathsf{elim}(w, h):C(w)
}
&lt;/math&gt;

In extensional type theories, W-types (resp. M-types) can be defined up to [[isomorphism]] as [[initial algebra]]s (resp. final coalgebras) for [[polynomial functor]]s. In this case, the property of initiality (res. finality) corresponds directly to the appropriate induction principle.&lt;ref&gt;{{Cite journal|last=Dybjer|first=Peter|title=Representing inductively defined sets by wellorderings in Martin-Löf's type theory|url=https://doi.org/10.1016/S0304-3975(96)00145-4|journal=Theoretical Computer Science|volume=176|issue=1–2|pages=329–335|doi=10.1016/s0304-3975(96)00145-4|year=1997}}&lt;/ref&gt; In intensional type theories with the [[univalence axiom]], this correspondence holds up to homotopy (propositional equality).&lt;ref&gt;{{cite arxiv|last=Awodey|first=Steve|last2=Gambino|first2=Nicola|last3=Sojakova|first3=Kristina|date=2012-01-18|title=Inductive types in homotopy type theory|eprint=1201.3898|class=math.LO}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last=Ahrens|first=Benedikt|last2=Capriotti|first2=Paolo|last3=Spadotti|first3=Régis|date=2015-04-12|title=Non-wellfounded trees in Homotopy Type Theory|eprint=1504.02949|class=cs.LO}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|last=Awodey|first=Steve|last2=Gambino|first2=Nicola|last3=Sojakova|first3=Kristina|date=2015-04-21|title=Homotopy-initial algebras in type theory|eprint=1504.05531 |class=math.LO}}&lt;/ref&gt;

M-types are [[Dual (category theory)|dual]] to W-types, they represent [[Coinduction|coinductive]] (potentially infinite) data such as [[Stream (computer science)|streams]].&lt;ref&gt;{{Cite journal|last=van den Berg|first=Benno|last2=Marchi|first2=Federico De|title=Non-well-founded trees in categories|url=https://doi.org/10.1016/j.apal.2006.12.001|journal=Annals of Pure and Applied Logic|volume=146|issue=1|pages=40–59|doi=10.1016/j.apal.2006.12.001|year=2007}}&lt;/ref&gt; M-types can be derived from W-types.&lt;ref&gt;{{Cite journal|last=Abbott|first=Michael|last2=Altenkirch|first2=Thorsten|last3=Ghani|first3=Neil|title=Containers: Constructing strictly positive types|url=https://doi.org/10.1016/j.tcs.2005.06.002|journal=Theoretical Computer Science|volume=342|issue=1|pages=3–27|doi=10.1016/j.tcs.2005.06.002|year=2005}}&lt;/ref&gt;

=== Mutually inductive definitions ===

This technique allows ''some'' definitions of multiple types that depend on each other. For example, defining two [[parity (mathematics)|parity]] predicates on [[natural number]]s using two mutually inductive types in [[Coq]]:

&lt;source lang="coq"&gt;
Inductive even : nat -&gt; Prop :=
  | zero_is_even : even O
  | S_of_odd_is_even : (forall n:nat, odd n -&gt; even (S n))
with odd : nat -&gt; Prop :=
  | S_of_even_is_odd : (forall n:nat, even n -&gt; odd (S n)).
&lt;/source&gt;

=== Induction-recursion ===

[[Induction-recursion (type theory)|Induction-recursion]] started as a study into the limits of ITT.  Once found, the limits were turned into rules that allowed defining new inductive types.  These types could depend upon a function and the function on the type, as long as both were defined simultaneously.

[[Universe type]]s can be defined using induction-recursion.

=== Induction-induction ===

[[Induction-induction]] allows definition of a type and a family of types at the same time.  So, a type {{mvar|A}} and a family of types &lt;math&gt;B : A \to Type&lt;/math&gt;.

=== Higher inductive types ===

This is a current research area in [[Homotopy type theory|Homotopy Type Theory]] (HoTT).  HoTT differs from ITT by its identity type (equality).  Higher inductive types not only define a new type with constants and functions that create the type, but also new instances of the identity type that relate them.

A simple example is the {{mvar|circle}} type, which is defined with two constructors, a basepoint;

:{{math|''base'' : ''circle''}}

and a loop;

:{{math|1=''loop'' : ''base'' = ''base''.}}

The existence of a new constructor for the identity type makes {{mvar|circle}} a higher inductive type.

== See also ==
* [[Coinduction]] permits (effectively) infinite structures in type theory.

== References ==

{{Reflist}}
* {{cite book|author=Univalent Foundations Program|title=Homotopy Type Theory: Univalent Foundations of Mathematics|year=2013|publisher=Institute for Advanced Study|url=http://homotopytypetheory.org/book/}}

== External links ==
* [http://www.cs.swan.ac.uk/~csetzer/slides/dybjer60thBirthdayGothenburgJune2013/dybjer60thBirthdayGothenburgJune2013.pdf Induction-Recursion Slides]
* [http://www.cs.swan.ac.uk/~csetzer/slides/lisbon2012/setzerLisbon2012InductionInductionInduction.pdf Induction-Induction Slides]
* [https://homotopytypetheory.org/2011/04/24/higher-inductive-types-a-tour-of-the-menagerie/ Higher Inductive Types: a tour of the menagerie]

[[Category:Type theory]]</text>
      <sha1>mvdwbr3of5ewpd3d39282iq9suvtqx2</sha1>
    </revision>
  </page>
  <page>
    <title>Inverse demand function</title>
    <ns>0</ns>
    <id>3976717</id>
    <revision>
      <id>865605695</id>
      <parentid>860877916</parentid>
      <timestamp>2018-10-25T00:03:53Z</timestamp>
      <contributor>
        <ip>108.52.142.71</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5003">{{citation style|date=May 2012}}

In [[economics]], an 'inverse demand function', P = f&lt;sup&gt;−1&lt;/sup&gt;(Q), is a function that maps the quantity of output demanded to the market price (dependent variable) for that output. Quantity demanded, Q, is a function of price; the inverse demand function treats price as a function of quantity demanded, and is also called the price function.&lt;ref&gt;Samuelson, W and Marks, S Managerial Economics 4th ed. page 35. Wiley 2003.&lt;/ref&gt; Note that the inverse demand function is not the reciprocal of the demand function&amp;mdash;the word "inverse" refers to the mathematical concept of an [[inverse function]].

==Definition==
In mathematical terms, if the [[demand curve|demand function]] is f(P), then the inverse demand function is f&lt;sup&gt;−1&lt;/sup&gt;(Q), whose value is the highest price that could be charged and still generate the quantity demanded Q.&lt;ref&gt;Varian, H.R (2006) Intermediate Microeconomics, Seventh Edition, W.W Norton &amp; Company: London&lt;/ref&gt; This is to say that the inverse demand function is the [[demand curve|demand function]] with the axes switched. This is useful because economists typically place price ('''P''') on the vertical axis and quantity ('''Q''') on the horizontal axis.

The inverse demand function is the same as the average revenue function, since P = AR.&lt;ref&gt;Chiang &amp; Wainwright, Fundamental Methods of Mathematical Economics 4th ed. Page 172. McGraw-Hill 2005&lt;/ref&gt;

To compute the inverse demand function, simply solve for P from the demand function. For example, if the demand function has the form Q = 240 - 2P then the inverse demand function would be P = 120 - 0.5Q.&lt;ref&gt;Samuelson &amp; Marks, Managerial Economics 4th ed. (Wiley 2003)&lt;/ref&gt;

==Applications==
The inverse demand function can be used to derive the total and marginal revenue functions. Total revenue equals price, P, times quantity, Q, or TR = P×Q. Multiply the inverse demand function by Q to derive the total revenue function: TR = (120 - .5Q) × Q = 120Q - 0.5Q². The marginal revenue function is the first derivative of the total revenue function or MR = 120 - Q. Note that in this linear example the MR function has the same y-intercept as the inverse demand function, the x-intercept of the MR function is one-half the value of the demand function, and the slope of the MR function is twice that of the inverse demand function. This relationship holds true for all linear demand equations. The importance of being able to quickly calculate MR is that the profit-maximizing condition for firms regardless of market structure is to produce where marginal revenue equals marginal cost (MC). To derive MC the first derivative of the total cost function is taken.

For example, assume cost, C, equals 420 + 60Q + Q&lt;sup&gt;2&lt;/sup&gt;. then MC = 60 + 2Q.&lt;ref&gt;Perloff, Microeconomics, Theory &amp; Applications with Calculus (Pearson 2008) 240.{{ISBN|0-321-27794-5}}&lt;/ref&gt; Equating MR to MC and solving for Q gives Q = 20. So 20 is the profit maximizing quantity: to find the profit-maximizing price simply plug the value of Q into the inverse demand equation and solve for P.

The inverse demand function is the form of the demand function that appears in the famous [[Marshallian Scissors]] diagram. The function appears in this form because economists place the independent variable on the y-axis and the dependent variable on the x-axis. The slope of the inverse function is ∆P/∆Q. This fact should be kept in mind when calculating elasticity. The formula for elasticity is (∆Q/∆P) × (P/Q).

==Relation to marginal revenue==
There is a close relationship between any inverse demand function for a linear demand equation and the marginal revenue function. For any linear demand function with an inverse demand equation of the form P = a - bQ, the marginal revenue function has the form MR = a - 2bQ.&lt;ref&gt;Samuelson, W &amp; Marks, S Managerial Economics 4th ed. Page 47. Wiley 2003.&lt;/ref&gt; The marginal revenue function and inverse linear demand function have the following characteristics:
*Both functions are linear.&lt;ref&gt;Perloff, J: Microeconomics Theory &amp; Applications with Calculus page 363. Pearson 2008.&lt;/ref&gt;
*The marginal revenue function and inverse demand function have the same y intercept.&lt;ref&gt;Samuelson, W &amp; Marks, S Managerial Economics 4th ed. Page 47. Wiley 2003.&lt;/ref&gt;
*The x intercept of the marginal revenue function is one-half the x intercept of the inverse demand function.
* The marginal revenue function has twice the slope of the inverse demand function.&lt;ref&gt;Samuelson, W &amp; Marks, S Managerial Economics 4th ed. Page 47. Wiley 2003.&lt;/ref&gt;
* The marginal revenue function is below the inverse demand function at every positive quantity.&lt;ref&gt;Perloff, J: Microeconomics Theory &amp; Applications with Calculus page 362. Pearson 2008.&lt;/ref&gt;

==See also==
*[[Supply and demand]]
*[[Demand]]
*[[Law of demand]]
*[[Profit (economics)]]

==References==
{{Reflist}}

{{DEFAULTSORT:Inverse Demand Function}}
[[Category:Mathematical finance]]
[[Category:Demand]]</text>
      <sha1>j310ol0d5kmdmk373g858469yv7601e</sha1>
    </revision>
  </page>
  <page>
    <title>Jacobi identity</title>
    <ns>0</ns>
    <id>294370</id>
    <revision>
      <id>866141426</id>
      <parentid>862709458</parentid>
      <timestamp>2018-10-28T15:05:03Z</timestamp>
      <contributor>
        <username>J824h</username>
        <id>14504529</id>
      </contributor>
      <comment>/* Examples */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6000">
In [[mathematics]] the '''Jacobi identity''' is a property of a [[binary operation]] which describes how the order of evaluation (the placement of parentheses in a multiple product) affects the result of the operation. By contrast, for operations with the [[associativity|associative property]], any order of evaluation gives the same result (parentheses in a multiple product are not needed).  The identity is named after the [[Germany|German]] [[mathematician]] [[Carl Gustav Jakob Jacobi]].  The [[cross product]] &lt;math&gt;a\times b&lt;/math&gt; and the [[Lie algebra|Lie bracket operation]] &lt;math&gt;[a,b]&lt;/math&gt; both satisfy the Jacobi identity.

== Definition ==
A binary operation ''×''  on a [[Set (mathematics)|set]] ''S''  possessing a binary operation ''+''  with an additive identity denoted by 0 satisfies the Jacobi identity if:
: &lt;math&gt;a \times (b \times c)  \ +\ b \times (c \times a) \ +\ c \times (a \times b)\ =\ 0 \quad \forall\ {a,b,c}\in S.&lt;/math&gt;

That is, if the sum of all even permutations of (''a'',(''b'',''c'')) is zero (where the permutation is performed by leaving the parentheses fixed and interchanging letters an even number of times).

==Interpretation==
The simplest example of a [[Lie algebra]] is constructed from the (associative) ring of &lt;math&gt;n\times n&lt;/math&gt; matrices, which may be thought of as infinitesimal motions of an ''n''-dimensional vector space. The Lie bracket operation is then defined as the [[commutator]], which measures the failure of commutativity in matrix multiplication:
:&lt;math&gt;[A,B]=AB-BA.&lt;/math&gt;

It is then easy to check the Jacobi identity:
{{Equation box 1
 |indent =:
 |equation =&lt;math&gt;[A, [B, C]] + [B, [C, A]] + [C, [A, B]] = 0.&lt;/math&gt;
 |cellpadding= 6
 |border
 |border colour = #0070BF
 |bgcolor=#FAFFFB
}}
More generally, suppose '''A''' is an associative algebra and ''V'' is a subspace of '''A''' with the property that for all ''A'' and ''B'' in '''A''', the element &lt;math&gt;AB-BA&lt;/math&gt; belongs to ''V''. Then the Jacobi identity holds on ''V'' for the bracket operator given by &lt;math&gt;[A,B]=AB-BA&lt;/math&gt;.&lt;ref&gt;{{harvnb|Hall|2015}} Example 3.3&lt;/ref&gt; Thus, if a binary operation satisfies the Jacobi identity, we may say that it ''behaves as if'' it were given by &lt;math&gt;AB-BA&lt;/math&gt; in some associative algebra, even if it is not actually defined that way.

Using the [[anticommutativity|antisymmetry property]] &lt;math&gt;[A,B]=-[B,A]&lt;/math&gt;, the Jacobi identity can be rewritten as a modification of the [[associativity|associative property]]: 
:&lt;math&gt;[[A, B], C] = [A, [B, C]] - [B, [A, C]]~.&lt;/math&gt;

Considering &lt;math&gt;[A,C]&lt;/math&gt; as the action of the infinitesimal motion ''A'' on ''C'', this can be stated as: 
{{quote
 | The action of ''B'' followed by ''A'' (operator &lt;math&gt;[A,[B,\cdot\ ]]&lt;/math&gt;), minus the action of ''A'' followed by ''B'' (operator &lt;math&gt;([B,[A,\cdot\ ]]&lt;/math&gt;), is equal to the action of &lt;math&gt;[A,B]&lt;/math&gt;, (operator &lt;math&gt;[[A,B],\cdot\ ]&lt;/math&gt;).
}}

There is also a plethora of mixed analogs involving anticommutators, such as
:&lt;math&gt;
[\{A,B\},C]+ [\{B,C\},A]+[\{C,A\},B] =0,\qquad
[\{A,B\},C]+ \{[C,B],A\}+\{[C,A],B\} =0,
&lt;/math&gt;
etc. ([[Lie_superalgebra#Properties|Graded Jacobi identities]])
{{see also|Lie bracket of vector fields|Baker–Campbell–Hausdorff formula}}

==Examples==
The majority of common examples of the Jacobi identity come from the bracket multiplication on [[Lie Algebra|Lie algebras]] and [[Lie ring]]s. Because of this the Jacobi identity is often expressed using Lie bracket notation:

: &lt;math&gt;[x,[y,z]] + [z,[x,y]] + [y,[z,x]] = 0.&lt;/math&gt;

Because the bracket multiplication is [[anticommutativity|antisymmetric]], the Jacobi identity admits two equivalent reformulations. Defining the [[adjoint representation of a Lie algebra|adjoint operator]]
&lt;math&gt;\operatorname{ad}_x: y \mapsto [x,y]&lt;/math&gt;, the identity becomes:
:&lt;math&gt;\operatorname{ad}_x[y,z]=[\operatorname{ad}_xy,z]+[y,\operatorname{ad}_xz].&lt;/math&gt;
Thus, the Jacobi identity for Lie algebras simply states that the action of any element on the algebra is a [[derivation (abstract algebra)|derivation]]. This form of the Jacobi identity is also used to define the notion of [[Leibniz algebra]].

Another rearrangement shows that the Jacobi identity is equivalent to the following identity between the operators of the adjoint representation:
:&lt;math&gt;\operatorname{ad}_{[x,y]}=[\operatorname{ad}_x,\operatorname{ad}_y].&lt;/math&gt;
This identity implies that the map sending each element to its adjoint action is a [[Lie algebra homomorphism]] of the original algebra into the Lie algebra of its derivations.

The [[Commutator#Identities (group theory)|Hall–Witt identity]] is the analogous identity for the [[commutator]] operation in a [[group (mathematics)|group]].

In [[analytical mechanics]], the Jacobi identity is satisfied by the [[Poisson bracket]]s. In [[quantum mechanics]], it is satisfied by operator [[Commutator#Ring theory|commutator]]s on a [[Hilbert space]] and, equivalently, in the [[phase space formulation]] of quantum mechanics by the [[Moyal bracket]].

The following identitity follows from anticommutativity and Jacobi identity and holds in arbitrary Lie algebra:&lt;ref&gt;{{cite arXiv
 | first=Ilya |last=Alekseev | first2=Sergei O. |last2=Ivanov |arxiv=1604.05281
 | title       = Higher Jacobi Identities |date=18 April 2016
 }}&lt;/ref&gt;
: &lt;math&gt;[x,[y,[z,w]]] + [y,[x,[w,z]]] + [z,[w,[x,y]]] + [w,[z,[y,x]]] = 0.&lt;/math&gt;

==See also==
* [[Structure constant]]
* [[Super Jacobi identity]]
* [[Three subgroups lemma]] (Hall–Witt identity)

==References==
{{Reflist}}
* {{citation|first=Brian C.|last=Hall|title=Lie Groups, Lie Algebras, and Representations: An Elementary Introduction|edition= 2nd|series=Graduate Texts in Mathematics|volume=222 |publisher=Springer|year=2015|isbn=978-3319134666}}.

== External links ==
*{{MathWorld|JacobiIdentities|Jacobi Identities}}

{{DEFAULTSORT:Jacobi Identity}}
[[Category:Lie algebras]]
[[Category:Mathematical identities]]
[[Category:Non-associative algebra]]</text>
      <sha1>kyzso0v51ohpff01xda4wa7ijoqcoe1</sha1>
    </revision>
  </page>
  <page>
    <title>Kittell graph</title>
    <ns>0</ns>
    <id>57340821</id>
    <revision>
      <id>840348449</id>
      <parentid>839954257</parentid>
      <timestamp>2018-05-09T09:19:44Z</timestamp>
      <contributor>
        <username>Pldx1</username>
        <id>10847608</id>
      </contributor>
      <minor/>
      <comment>reprecating</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1143">{{Infobox graph
 | name= Kittel graph
 | image = Image:Kittell_graph.svg
 | image_size= 250px
 | image_caption = The Kittell graph
 | vertices = 23
 | edges = 63
 | radius = 3
 | diameter = 4
 | girth = 3
}}

In the mathematical field of [[graph theory]], the ''' Kittell graph''' is a [[planar graph]] with 23 vertices and 63 edges. Its unique planar embedding has 42 triangular faces.&lt;ref&gt;{{mathworld|id=KittellGraph|title=Kittell Graph}}&lt;/ref&gt; The Kittell graph is named after Irving Kittell, who used it as a counterexample to [[Alfred Kempe]]'s flawed proof of the [[four-color theorem]].&lt;ref&gt;{{citation
 | last = Kittell | first = Irving
 | doi = 10.1090/S0002-9904-1935-06104-X
 | issue = 6
 | journal = [[Bulletin of the American Mathematical Society]]
 | mr = 1563103
 | pages = 407–413
 | title = A group of operations on a partially colored map
 | volume = 41
 | year = 1935}}&lt;/ref&gt; Simpler counterexamples include the [[Errera graph]] and [[Poussin graph]] (both published earlier than Kittell) and the [[Fritsch graph]] and [[Soifer graph]].

==References==
{{reflist}}

[[Category:Individual graphs]]
[[Category:Planar graphs]]</text>
      <sha1>ok485kocnb6ztpxpk6oiov52b4m3v3r</sha1>
    </revision>
  </page>
  <page>
    <title>Konrad Osterwalder</title>
    <ns>0</ns>
    <id>19188374</id>
    <revision>
      <id>868897576</id>
      <parentid>861642499</parentid>
      <timestamp>2018-11-15T03:55:22Z</timestamp>
      <contributor>
        <username>Good Olfactory</username>
        <id>6454287</id>
      </contributor>
      <comment>removed [[Category:United Nations officials]]; added [[Category:Swiss officials of the United Nations]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17631">{{Infobox officeholder
|name         = Konrad Osterwalder
|image        =
|caption      = 
|office       = Former Rector of [[United Nations University]] (UNU) Rector Emeritus of [[ETH Zurich]]
|deputy       = 
|1blankname2  = Secretary-General
|1namedata2   = [[Ban Ki Moon]]
|term_start   = 1 September 2007
|term_end     = 28 February 2013
|predecessor  = Hans van Ginkel
|successor    = [[David M. Malone]]
|birthname    =
|birth_date   = {{birth date and age|1942|06|03}}
|birth_place  = [[Frauenfeld]], [[Thurgau]], [[Switzerland]]
|death_date   = 
|death_place  = 
|alma_mater   = [[ETH Zurich]]
}}

'''Konrad Osterwalder''' (born June 3, 1942) is a Swiss mathematician and physicist, former [[Undersecretary-General of the United Nations]], former Rector of the [[United Nations University]] (UNU),&lt;ref&gt;http://unu.edu/hq/rector_office/rector-cvL.html&lt;/ref&gt; and Rector Emeritus of the Swiss Federal Institute of Technology Zurich ([[ETH Zurich]]). He is known for the [[Osterwalder–Schrader theorem]].

==United Nations University==
Osterwalder was appointed to the position of United Nations Under Secretary General and United Nations University Rector by [[United Nations Secretary-General]] [[Ban Ki-moon]] May 2007&lt;ref&gt;https://www.un.org/News/Press/docs/2007/sga1063.doc.htm&lt;/ref&gt; and served until 28 February 2013. He succeeded Prof. [[Hans van Ginkel]] from the Netherlands to be the fifth Rector of the United Nations University.

He is credited with turning United Nations University into a world leading institution, ranked #5 &amp; #6 in two categories according to the [[2012 Global Go to Think Tank Rankings]].&lt;ref&gt;{{cite web |url=http://gotothinktank.com/dev1/wp-content/uploads/2013/07/2012_Global_Go_To_Think_Tank_Report_-_FINAL-1.28.13.pdf |title=Archived copy |accessdate=2014-02-18 |deadurl=yes |archiveurl=https://web.archive.org/web/20131014173421/http://gotothinktank.com/dev1/wp-content/uploads/2013/07/2012_Global_Go_To_Think_Tank_Report_-_FINAL-1.28.13.pdf |archivedate=2013-10-14 |df= }}&lt;/ref&gt; He was responsible for ensuring that UNU's charter was amended by the United Nations General Assembly&lt;ref&gt;https://www.un.org/en/ga/search/view_doc.asp?symbol=A/RES/64/225&lt;/ref&gt; in 2009 allowing the United Nations University to grant degrees, introducing UNU's degree programmes and creating a new concept in education, research and development by introducing the twin institute programmes. A concept that is changing the way that development, aid and capacity building is approached both by developed countries and developing and least developed countries.

&lt;gallery&gt;
File:Rector Osterwalder chairing UNU event on the work of the UN SC 1540 committee.jpg|Rector Osterwalder chairing UNU event on the work of the UN SC 1540 committee
File:UNU Rector Osterwalder with UNHCR Commissioner Gutteres.jpg|UNU Rector Osterwalder with UNHCR Commissioner Gutteres at Rio+20 Press Conference
&lt;/gallery&gt;

==Bologna Process==

In March 2000, following the Bologna Declaration by 28 European Education Ministers, the European University Association and the Comite de Liaison within the National Rector's Conference convened the Convention of European Higher Education in salamanca Spain, hereinafter referred to as the "Salamanca Process"with the aim of discussing the Bologna Declaration and delivering an overall, univocal response to the Council of Ministers. Professor Osterwalder, Rector of ETH, was chosen by the conference as the Rapporteur of the Salamanca Process and the voice of Higher Education institutions.  The meeting concluded with a declaration and a report that led to the basis of Higher Education reform within the Bologna process and the EU.  In addition, the two conveners of the conference formed the European University Association.

==Life and career==

Konrad Osterwalder was born in [[Frauenfeld]], [[Thurgau]], [[Switzerland]], in June 1942. He studied at the Swiss Federal Institute of Technology (Eidgenössische Technische Hochschule; ETH) in Zurich, where he earned a Diploma in theoretical physics in 1965 and a Doctorate in theoretical physics in 1970. He is married to Verena Osterwalder-Bollag, an analytical therapist. They have three kids.

After one year with the Courant Institute of Mathematical Sciences, New York University, he accepted a research position at Harvard University in 1971. He remained on the faculty of Harvard for seven years, and was promoted to Assistant Professor for Mathematical Physics in 1973 and Associate Professor for Mathematical Physics in 1976. In 1977, he returned to Switzerland upon being appointed a full Professor for Mathematical Physics at ETH Zurich. His doctoral students include [[Felix Finster]] and [[Emil J. Straube]].

During his tenure at ETH Zurich, Osterwalder served as Head of the Department of Mathematics (1986–1990) and Head of the Planning Committee (1990–1995), and was founder of the Centro Stefano Franscini seminar center in Ascona. He was appointed Rector of ETH in 1995 and held that post for 12 years. From November 2006 through August 2007, he also served concurrently as ETH President pro tempore.

On 1 September 2007, Osterwalder joined the United Nations University as its fifth rector. In that role, he held the rank of Under-Secretary-General of the United Nations.

Osterwalder's research focused on the mathematical structure of relativistic quantum field theory as well as on elementary particle physics and statistical mechanics. During his long and distinguished career, he has been a Visiting Fellow/Guest Professor at several prominent universities around the world, including the Institut des Hautes Études Scientifiques (IHES; Bures-sur-Yvette, France); Harvard University; University of Texas (Austin); Max Planck Institute for Physics and Astrophysics (Munich), Università La Sapienza (Rome); Università di Napoli; Waseda University; and Weizmann Institute of Science (Rehovot, Israel).

Since 2014 - member of International Scientific Council of Tomsk Polytechnic University.&lt;ref&gt;[http://tpu.ru/en/structure/divisions/isc/ International Scientific Council]&lt;/ref&gt;

==Career achievements==
Osterwalder career encompasses service on many advisory boards, committees and associations including as

* Editor of Communications in Mathematical Physics;
* Treasurer and President of the [[International Association of Mathematical Physics]];
* Member of the Visiting Committee of the Harvard Department of Physics;
* President of the IHÉS National Committee of the Swiss Academy of Natural Sciences;
* Member of the Advisory Council of the Euler Institute in St. Petersburg;
* Vice-President of the Conference of Rectors of Swiss Universities;
* President of the Conference of European Schools of Advanced Engineering Education and Research (CESAER);
* Member of the International Academic Advisory Panel of the Government of Singapore;
* President of UNITECH International (a collaboration between several European Technical Universities and more than 20 leading multinational corporations);
* Chairman of the Bologna-Project Group (Swiss Rectors Conference);
* President, Jury of the Brandenberger Foundation;
* Member of the Nucleo di Valutazione (supervisory council) of the Politecnico di Milano;
* Member of the Conseil d'administration of the École Polytechnique de France (Paris);
* Member of the "Comité de l´Enseignement" of the Ecole Nationale Supérieure des Mines de Paris;
* Member of the University Council of the Università della Svizzera Italiana;
* President Chair of the University Council of the Technical University Darmstadt;
* Head of the Evaluationsverbund Darmstadt-Kaiserslautern-Karlsruhe;
* Member, Strategic Council, Free University of Berlin;
* Member, Comitato Scientifico Alta Scuola Politecnica (Politecnici di Milano e di Torino);
* Member, Beirat Robert Bosch Stiftung; and
* Member, Academic Council of the International Council on Systems Engineering (INCOSE)
* Member, Consiglio Fondazione Italian Institute of Technology
* Member, The International Selection committee for the [[Millennium Technology Prize]], the world’s biggest technology prize (1.5 Million US$), awarded by the Technology Academy Finland
* Executive Committee Member, Club of Rome

==Awards and prizes==
Osterwalder has been a recipient of many honours and prizes including:

* having one of the top-cited mathematical physics papers of all time
* Fellow of the Alfred P. Sloan Foundation (1974–1978);
* member of the Swiss Academy of Technical Sciences;
* Honorary degree from the Helsinki Technical University
* Honorary Member of Riga Technical University.
* 2009 Matteo Ricci International Award
* 2010 Leonardo da Vinci Medal (SEFI, European Society for Engineering Education)
* 1987 until 1995 awarded by ETH's students the prize of the best teacher of the term
* Fellow of the [[American Mathematical Society]], 2012.&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-03-20.&lt;/ref&gt;

==Publications==

*Cluster Properties of the S-Matrix, diploma thesis, unpublished
*Boson Fields with the λ ϕ3 Interaction in Two, Three and Four Dimensions,Ph. D. thesis, published by Physikalisches Intitut ETH, Zürich (1970)
*On the Hamiltonian of the Cubic Boson Self-Interaction in Four Dimensional Space Time, Fortschritte der Physik  19, 43-113 (1971)
*On the Spectrum of the Cubic Boson Self-Interaction, ETH Preprint (1971)
*On the Uniqueness of the Hamiltonian and of the Representation of the CCR for the Quartic Boson Interaction in Three Dimensions, Helv. Phys. Acta . 44, 884-909 (1971), with J.-P. Eckmann
*Duality for Free Bose Fields, Comm. Math. Phys. 29, 1-14 (1973)
*On the Uniqueness of the Energy Density in the Infinite Volume Limit for Quantum Field Models, Helv. Phys. Acta. 45, 746-754 (1972), with R. Schrader
*An Application of Tomita’s Theory of Modular Hilbert Algebras: Duality for Free Bose Fields, Jour. Funct. Anal. 13, 1-12 (1973), with J.-P. Eckmann
*Feynman-Kac Formula for Euclidean Fermi and Bose Fields, Phys. Rev. Lett. 29, 1423-1425 (1971), with R. Schrader
*Axioms for Euclidean Green’s Functions, Comm. Math. Phys. 31, 83-113, (1973),with R. Schrader
*Euclidean Fermi Fields and Feynman-Kac Formula for  Boson-Fermion Models, Helv. Phys. Acta.  46, 277-302 (1973), with R. Schrader
*Euclidean Green’s Functions and Wightman Distributions, in Constructive Quantum Field Theory, G. Velo and A. Wightman (eds.), 1973 Erice Lectures,  Vol. 25, Springer-Verlag, Berlin -  Heidelberg - New York (1973); Russian translation, MIR 1977
*Euclidean Fermi Fields, in Constructive Quantum Field Theory, G. Velo and A. Wightman (eds.), 1973 Erice Lectures, Lecture Notes in Physics, Vol 25, Springer Verlag, Berlin-Heidelberg-New York, (1973); Russian translation, MIR 1977
*Axioms for Euclidean Green’s Functions, II, Comm. Math. Phys. 42, 281 (1975), with R. Schrader; Russian translation in: Euclidean Quantum Field Theory, MIR 1978
*Is there a Euclidean Field Theory for Fermions, Helv. Phys. Acta. 47, 781 (1974), with J. Fröhlich
*The Wightman Axioms and the Mass Gap for Weakky Coupled (φ4)3 Quantum Field Theories, Ann. of Phys. 97, 80-135 (1976), with J. Feldman
*The Wightman Axioms and the  Mass Gap for Weakly Coupled  (φ4)3 Quantum Field Theories,  Proc. of the International Symposium on Mathematical Problems in Theoretical Physics, Kyoto Japan, January 23–29, 1975. Lecture Notes in Physics, Springer-Verlag, with Joel Feldman
*Recent Results in Constructive Quantum Field Theory (in Japanese), Kagaku, June 1975
*The Construction of  λ (φ4)3  Quantum Field Models, in Colloques Internationaux C.N.R.S. No. 248, les méthodes mathématiques de la théorie quantique des champs (1975), with J. Feldman
*A Nontrivial Scattering Matrix for Weakly Coupled  P(ϕ)2 Models, Helv. Phys. Acta. 49, 525 (1976), with R. Sénéor
*Time Ordered Operator Products and the Scattering Matrix in P(φ)2  Models, in Quantum Dynamics: Models and Mathematics, ed. L. Streit, Springer Verlag Wien, New York 1976
*Gauge Theories on the Lattice, in  New Developments in Quantum Theory and  Statistical Mechanics, p.&amp;nbsp;173-200, ed. M. Lévy and P. Mitter (Cargèse 1976), Plenum Press New York, London 1977
*Gauge Field Theories on the Lattice, Ann. Phys. 110, 440-471 (1978), with E. Seiler; reprinted in: Lattice Gauge Theories, ed. Y. Iwasaki and T. Yonega, Series of selected papers in physics, Physical Society of Japan
*Lattice Gauge Theories, in Mathematical Problems in Theoretical Physics, ed. G. Dell’Antonio et al., Springer Lecture Notes in Physics, vol. 80, Springer Verlag 1978
*Auf dem Weg zu einer relativistischen Quantenfeldtheorie, in Einstein Symposion Berlin,	Springer Lecture Notes in Physics, vol. 100, Springer Verlag 1979
*Operators, in Encyclopedia of Physics, eds. R.G. Lerner, G.L. Trigg, Addison Wesley (1981)
*Constructive Quantum Field Theories: Scalar Fields, in Gauge Theories, Fundamental Interactions and Rigorous Results, eds. P. Dita, V. Georgescu, R. Purice, Birkhäuser (1982)
*Virtual Representation of Symmetric Spaces and their Analytic Continuation, Ann. of Math., 118, 461 (1983) with J. Fröhlich and E. Seiler
*Constructive Quantum Field Theory: Goals, Methods, Results, Helv. Phys. Acta 59, 220 (1986)
*On the convergence of  inverse functions of operators, J.Func. Anal. 81, 320 - 324, (1988), with  A. Jaffe and A. Lesniewski
*Quantum K-Theory: The Chern Character, Commun. Math. Phys. 118, 1- 14 (1988), with A. Jaffe and A. Lesniewski
*On super-KMS functionals and entire cyclic cohomology, K-Theory 2, 675 - 682, (1989), with  A. Jaffe and A. Lesniewski
*Ward Identities for non-commutative geometry, Commun. Math. Phys. 132, 118 - 130, (1990), with A. Jaffe
*Operators, in Encyclopedia of Physics, eds. R.G. Lerner, G.L. Trigg, second edition, VCH Publishers, New York, Cambridge(UK), 1991
*Stability for a class of bilocal Hamiltonians, Commun. Math. Phys. 155, 183 -197, (1993), with A. Jaffe and A. Lesniewski
*Supersymmetry and the stability of non-local interactions, in Differential Geometric Methods in Theoretical Physics, H.M.Ho, editor, World Scientific (1993)
*Constructing Supersymmetric Quantum Field Theories, in Advances in Dynamical Systems and Quantum Physics, R. Figari, editor, World Scientific (1994)
*Superspace Formulation of the Chern Character of a Theta Summable Fredholm Module, Commun. Math. Phys. 168, 643 (1995),  with A. Lesniewski
*Supersymmetric Quantum Field Theory, in Constructive Results in Field Theory, Statistical Mechanics and Solid State Physics, V. Rivasseau, editor, Springer Verlag 1995
*Unitary Representations of Super Groups, to appear, with A. Lesniewski
*Axioms for Supersymmetric Quantum Field Theories, to appear, with A. Lesniewski
*Mathematical Problems in Theoretical Physics, Springer Lecture Notes in Physics, Vol.116, Springer-Verlag 1980
*Critical Phenomena, Random Systems, Gauge Theories, Parts I/II, Les Houches 1984, Session XLIII, North Holland 1986 (with R. Stora)
*Akademikerproduktionsanlage GmbH? Gedanken zur Positionierung der Hochschulen, NZZ, Bildung und Erziehung, 25.Nov.1993
*Lehre für die Zukunft, Bulletin der ETHZ, 261, 4 - 7, 1996
*The Renaissance Engineer  in face of Unexpected Vulnerabilities, 30th SEFI Annual conference, Firenze 2002
*Worldwide Trends and their Impacts, The 3rd Technology Trends Seminar Sept. 2008
*Was erwartet die Wirtschaft von der Hochschulwelt, ZEIT Konferenz Hochschule und Bildung, Juli 1009
*L’Università delle Nazioni Unite per il dialogo tra le culture, Milano, Università cattolica, Cerimonia per il premio Matteo Ricci

==References==
{{Reflist}}

==External links==
{{Commonscat}}
*[http://portal.unesco.org/fr/ev.php-URL_ID=37728&amp;URL_DO=DO_TOPIC&amp;URL_SECTION=201.html UNESCO]
*[http://www.clubofrome.org/eng/people/executive_committee.asp Club of Rome]
*[http://www.pirelliaward.com/ch3_jurors-07.html Pirelli Technology Award]
*[http://www.arthurjaffe.com/Assets/documents/ETH_First_Visit.htm Arthur Jaffe Harvard University]
*[https://www.un.org/News/Press/docs/2007/sga1063.doc.htm UN Press Release]
*[http://archiv.ethlife.ethz.ch/e/articles/campuslife/osterwalderunouni.html ETH]
*[http://archiv.ethlife.ethz.ch/articles/tages/sechselaeuten05.html ETH]
*[http://archiv.ethlife.ethz.ch/e/articles/campuslife/pkkosterw.html ETH Campus Life]
*[http://www.physics.mcgill.ca/~rhb/sample/Calgary2012c.pdf Mcgill]
*[http://www.technologyacademy.fi/blog/2012/04/14/professor-konrad-osterwalder-switzerland/ Millennium Technology Prize]
*[http://www.systemsx.ch/news/news-2006/ SystemX]
*[http://www.ethlife.ethz.ch/archive_articles/20071003_abschiedsvorlKosengl/index_EN ETH Rector Event]
*[http://www.cattolicanews.it/2354.html Cattolica News]
*[http://www.mtf.stuba.sk/docs//doc/.../SEFI_laudatio_speech_2010-1.doc Matteo Ricci Prize Speech]
*[http://www.sefi.be/?page_id=17 Leonardo Da Vinci Medal]
*[http://genealogy.math.ndsu.nodak.edu/id.php?id=52117 Mathematics Genealogy Project]
*[http://www.iamp.org/page.php?page=page_about  International association of Mathematical Physics IAMP]

{{Authority control}}

{{DEFAULTSORT:Osterwalder, Konrad}}
[[Category:1942 births]]
[[Category:Living people]]
[[Category:Swiss physicists]]
[[Category:Swiss officials of the United Nations]]
[[Category:United Nations University staff]]
[[Category:ETH Zurich alumni]]
[[Category:Swiss mathematicians]]
[[Category:Differential geometers]]
[[Category:ETH Zurich faculty]]
[[Category:Theoretical physicists]]
[[Category:Quantum physicists]]
[[Category:Geometers]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>td8n0vdqd1rt3tizzva9e5kreixlz1l</sha1>
    </revision>
  </page>
  <page>
    <title>Linearity</title>
    <ns>0</ns>
    <id>91591</id>
    <revision>
      <id>856808429</id>
      <parentid>856808411</parentid>
      <timestamp>2018-08-27T17:22:59Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/205.121.0.146|205.121.0.146]] to version by Rjwilmsi. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3456532) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15722">{{Redirect|Linear}}
{{Distinguish|Lineage (disambiguation)}}
{{Refimprove|date=December 2007}}

'''Linearity''' is the property of a mathematical relationship or function which means that it can be graphically represented as a straight [[Line (geometry)|line]]. Examples are the relationship of [[voltage]] and [[Electric current|current]] across a [[resistor]] ([[Ohm's law]]), or the [[mass]] and [[weight]] of an object. [[Proportionality (mathematics)|Proportionality]] implies linearity, but linearity does not imply proportionality.

==In mathematics==
In [[mathematics]], a [[linear map]] or [[linear function]] ''f''(''x'') is a function that satisfies the following two properties:&lt;ref&gt;{{cite book|author=Edwards, Harold M.|title=Linear Algebra|publisher=Springer|year=1995|isbn=9780817637316|page=78|url=https://books.google.com/books?id=ylFR4h5BIDEC&amp;pg=PA78}}&lt;/ref&gt;

* [[Additive map|Additivity]]: {{nowrap|1=''f''(''x'' + ''y'') = ''f''(''x'') + ''f''(''y'')}}.
* [[Homogeneous function|Homogeneity]] of degree 1: {{nowrap|1=''f''(α''x'') = α''f''(''x'')}} for all α.

The homogeneity and additivity properties together are called the superposition principle. It can be shown that additivity implies homogeneity in all cases where α is [[Rational number|rational]]; this is done by proving the case where α is a natural number by [[mathematical induction]] and then extending the result to arbitrary rational numbers. If ''f'' is assumed to be continuous as well, then this can be extended to show homogeneity for any real number α, using the fact that rationals form a dense subset of the reals.

In this definition, ''x'' is not necessarily a [[real number]], but can in general be a member of any [[vector space]]. A more specific definition of [[linear function#As a polynomial function|linear function]], not coinciding with the definition of linear map, is used in elementary mathematics.

The concept of linearity can be extended to linear [[Operator (mathematics)|operator]]s. Important examples of linear operators include the [[derivative]] considered as a [[differential operator]], and many constructed from it, such as [[del]] and the [[Laplacian]].  When a [[differential equation]] can be expressed in linear form, it is generally straightforward to solve by breaking the equation up into smaller pieces, solving each of those pieces, and summing the solutions.

[[Linear algebra]] is the branch of mathematics concerned with the study of vectors, vector spaces (also called linear spaces), linear transformations (also called linear maps), and systems of linear equations.

The word '''linear''' comes from the [[Latin]] word ''linearis'', which means ''pertaining to or resembling a line''.  For a description of linear and nonlinear equations, see ''[[linear equation]]''. [[Nonlinear]] equations and functions are of interest to [[physicist]]s and [[mathematician]]s because they can be used to represent many natural phenomena, including [[chaos theory|chaos]].

===Linear polynomials===
{{main|linear equation}}

In a different usage to the above definition, a [[polynomial]] of degree 1 is said to be linear, because the [[graph of a function]] of that form is a line.&lt;ref&gt;[[James Stewart (mathematician)|Stewart, James]] (2008). ''Calculus: Early Transcendentals'', 6th ed., Brooks Cole Cengage Learning. {{isbn|978-0-495-01166-8}}, Section 1.2&lt;/ref&gt;

Over the reals, a [[linear equation]] is one of the forms:

:&lt;math&gt;f(x) = m x + b\ &lt;/math&gt;

where ''m'' is often called the [[slope]] or [[gradient]]; ''b'' the [[y-intercept]], which gives the point of intersection between the graph of the function and the ''y''-axis.

Note that this usage of the term ''linear'' is not the same as in the section above, because linear polynomials over the real numbers do not in general satisfy either additivity or homogeneity. In fact, they do so [[if and only if]] {{nowrap|1=''b'' = 0}}. Hence, if {{nowrap|''b'' ≠ 0}}, the function is often called an '''affine function''' (see in greater generality [[affine transformation]]).

===Boolean functions===
In [[Boolean algebra (logic)|Boolean algebra]], a linear function is a function &lt;math&gt;f&lt;/math&gt; for which there exist &lt;math&gt;a_0, a_1, \ldots, a_n \in \{0,1\}&lt;/math&gt; such that
:&lt;math&gt;f(b_1, \ldots, b_n) = a_0 \oplus (a_1 \land b_1) \oplus \cdots \oplus (a_n \land b_n)&lt;/math&gt;, where &lt;math&gt;b_1, \ldots, b_n \in \{0,1\}.&lt;/math&gt;

A Boolean function is linear if one of the following holds for the function's [[truth table]]:
# In every row in which the truth value of the function is [[Truth value#Classical logic|T]], there are an odd number of Ts assigned to the arguments, and in every row in which the function is [[Truth value#Classical logic|F]] there is an even number of Ts assigned to arguments. Specifically, {{nowrap|1=''f''(F, F, ..., F) = F}}, and these functions correspond to [[linear map]]s over the Boolean vector space.
# In every row in which the value of the function is T, there is an even number of Ts assigned to the arguments of the function; and in every row in which the [[truth value]] of the function is F, there are an odd number of Ts assigned to arguments. In this case, {{nowrap|1=''f''(F, F, ..., F) = T}}.

Another way to express this is that each variable always makes a difference in the [[truth value]] of the operation or it never makes a difference.

[[Negation]], [[Logical biconditional]], [[exclusive or]], [[tautology (logic)|tautology]], and [[contradiction]] are linear functions.

==Physics==
In [[physics]], ''linearity'' is a property of the [[differential equations]] governing many systems; for instance, the [[Maxwell equations]] or the [[diffusion equation]].&lt;ref&gt;{{Citation | last1=Evans | first1=Lawrence C. | title=Partial differential equations | origyear=1998 | url=http://www.ams.org/journals/bull/2000-37-03/S0273-0979-00-00868-5/S0273-0979-00-00868-5.pdf | publisher=[[American Mathematical Society]] | location=Providence, R.I. | edition=2nd | series=[[Graduate Studies in Mathematics]] | isbn=978-0-8218-4974-3 |mr=2597943 | year=2010 | volume=19 | doi=10.1090/gsm/019}}&lt;/ref&gt;

Linearity of a [[differential equation]] means that if two functions ''f'' and ''g'' are solutions of the equation, then any [[linear combination]] {{nowrap|''af'' + ''bg''}} is, too.

In instrumentation, linearity means that for every change in the variable you are observing, you get the same change in the output of the measurement apparatus - this is highly desirable in scientific work. In general, instruments are close to linear over a useful certain range, and most useful within that range.  In contrast, human senses are highly nonlinear- for instance, the brain totally ignores incoming light unless it exceeds a certain [[absolute threshold]] number of photons.

==Electronics==
In [[electronics]], the linear operating region of a device, for example a [[transistor]], is where a [[dependent variable]] (such as the transistor collector [[Electric current|current]]) is directly [[Proportionality (mathematics)|proportional]] to an [[independent variable]] (such as the base current). This ensures that an analog output is an accurate representation of an input, typically with higher amplitude (amplified). A typical example of linear equipment is a [[high fidelity]] [[audio amplifier]], which must amplify a signal without changing its waveform. Others are [[linear filter]]s, [[linear regulator]]s, and [[linear amplifier]]s in general.

In most [[Science|scientific]] and [[Technology|technological]], as distinct from mathematical, applications, something may be described as linear if the characteristic is approximately but not exactly a straight line; and linearity may be valid only within a certain operating region—for example, a high-fidelity amplifier may distort a small signal, but sufficiently little to be acceptable (acceptable but imperfect linearity); and may distort very badly if the input exceeds a certain value, taking it away from the approximately linear part of the [[transfer function]].&lt;ref name=Whitaker&gt;{{cite book|last=Whitaker|first=Jerry C.|title=The RF transmission systems handbook|year=2002|publisher=CRC Press|isbn=978-0-8493-0973-1|url=https://books.google.com/books?id=G5UHVIqEWdQC&amp;pg=SA11-PA1}}&lt;/ref&gt;

===Integral linearity===
{{main |Integral linearity}}
{{over-quotation |section |lengthy=y |date=September 2014}}
For an electronic device (or other physical device) that converts a quantity to another quantity, Bertram S. Kolts writes:&lt;ref&gt;{{cite web |title=Understanding Linearity and Monotonicity |first=Bertram S. |last=Kolts |publisher=analogZONE |date=2005 |url=http://www.analogzone.com/nett1108.pdf |archiveurl=https://web.archive.org/web/20120204065155/http://www.analogzone.com/nett1108.pdf |archivedate=February 4, 2012 |accessdate=September 24, 2014}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |title=Understanding Linearity and Monotonicity |first=Bertram S. |last=Kolts |journal=Foreign Electronic Measurement Technology |year=2005 |volume=24 |issue=5 |pages=30–31 |url=http://caod.oriprobe.com/articles/9294129/Understanding_Linearity_and_Monotonicity.htm |accessdate=September 25, 2014}}&lt;/ref&gt;

&lt;blockquote&gt;There are three basic definitions for integral linearity in common use: independent linearity, zero-based linearity, and terminal, or end-point, linearity. In each case, linearity defines how well the device's actual performance across a specified operating range approximates a straight line. Linearity is usually measured in terms of a deviation, or non-linearity, from an ideal straight line and it is typically expressed in terms of percent of [[full scale]], or in ppm (parts per million) of full scale. Typically, the straight line is obtained by performing a least-squares fit of the data. The three definitions vary in the manner in which the straight line is positioned relative to the actual device's performance. Also, all three of these definitions ignore any gain, or offset errors that may be present in the actual device's performance characteristics.

Many times a device's specifications will simply refer to linearity, with no other explanation as to which type of linearity is intended. In cases where a specification is expressed simply as linearity, it is assumed to imply independent linearity.

Independent linearity is probably the most commonly used linearity definition and is often found in the specifications for [[Multimeter|DMM]]s and [[Analog-to-digital converter|ADC]]s, as well as devices like [[potentiometer]]s. Independent linearity is defined as the maximum deviation of actual performance relative to a straight line, located such that it minimizes the maximum deviation. In that case there are no constraints placed upon the positioning of the straight line and it may be wherever necessary to minimize the deviations between it and the device's actual performance characteristic.

Zero-based linearity forces the lower range value of the straight line to be equal to the actual lower range value of the device's characteristic, but it does allow the line to be rotated to minimize the maximum deviation. In this case, since the positioning of the straight line is constrained by the requirement that the lower range values of the line and the device's characteristic be coincident, the non-linearity based on this definition will generally be larger than for independent linearity.

For terminal linearity, there is no flexibility allowed in the placement of the straight line in order to minimize the deviations. The straight line must be located such that each of its end-points coincides with the device's actual upper and lower range values. This means that the non-linearity measured by this definition will typically be larger than that measured by the independent, or the zero-based linearity definitions. This definition of linearity is often associated with ADCs, [[Digital-to-analog converter|DAC]]s and various sensors.

A fourth linearity definition, absolute linearity, is sometimes also encountered. Absolute linearity is a variation of terminal linearity, in that it allows no flexibility in the placement of the straight line, however in this case the gain and offset errors of the actual device are included in the linearity measurement, making this the most difficult measure of a device's performance. For absolute linearity the end points of the straight line are defined by the ideal upper and lower range values for the device, rather than the actual values. The linearity error in this instance is the maximum deviation of the actual device's performance from ideal.&lt;/blockquote&gt;

==Military tactical formations==
In [[formation (military)|military tactical formations]], "linear formations" were adapted from phalanx-like formations of [[pike (weapon)|pike]] protected by handgunners towards shallow formations of handgunners protected by progressively fewer pikes. This kind of formation would get thinner until its extreme in the age of Wellington with the '[[The Thin Red Line (1854 battle)|Thin Red Line]]'. It would eventually be replaced by [[skirmisher|skirmish order]] at the time of the invention of the [[breech-loading weapon|breech-loading]] [[rifle]] that allowed soldiers to move and fire independently of the large-scale formations and fight in small, mobile units.

==Art==
'''Linear''' is one of the five categories proposed by Swiss art historian [[Heinrich Wölfflin]] to distinguish "Classic", or [[Renaissance art]], from the [[Baroque]]. According to Wölfflin, painters of the fifteenth and early sixteenth centuries ([[Leonardo da Vinci]], [[Raphael]] or [[Albrecht Dürer]]) are more linear than "[[painterly]]" Baroque painters of the seventeenth century ([[Peter Paul Rubens]], [[Rembrandt]], and [[Diego Velázquez|Velázquez]]) because they primarily use outline to create [[shape]].&lt;ref&gt;{{cite book |title=Principles of Art History: The Problem of the Development of Style in Later Art |last=Wölfflin |first=Heinrich |editor-last=Hottinger |editor-first=M.D. |publisher=Dover |location=New York |year=1950 |pages=18–72}}&lt;/ref&gt; Linearity in art can also be referenced in [[digital art]]. For example, [[hypertext fiction]] can be an example of [[nonlinear narrative]], but there are also websites designed to go in a specified, organized manner, following a linear path.

==Music==
In music the '''linear''' aspect is succession, either [[interval (music)|interval]]s or [[melodic|melody]], as opposed to [[simultaneity (music)|simultaneity]] or the [[Interval (music)|vertical]] aspect.

==Measurement==
In measurement, the term "linear foot" refers to the number of feet in a straight line of material (such as lumber or fabric) generally without regard to the width.  It is sometimes incorrectly referred to as "lineal feet"; however, "lineal" is typically reserved for usage when referring to ancestry or heredity.[http://www.unc.edu/~rowlett/units/dictL.html] The words "linear"[http://www.yourdictionary.com/ahd/l/l0180100.html] &amp; "lineal" [http://www.yourdictionary.com/ahd/l/l0180300.html]
both descend from the same root meaning, the [[Latin]] word for line, which is "linea".
{{expand section|date=March 2013}}
&lt;!--linearity in statistics; error bands etc.--&gt;

==See also==
*[[Linear actuator]]
*[[Linear element]]
*[[Linear system]]
*[[Linear medium]]
*[[Linear programming]]
*[[Linear differential equation]]
*[[Bilinear (disambiguation)|Bilinear]]
*[[Multilinear]]
*[[Linear motor]]
*[[Linear A]] and [[Linear B]] scripts.
*[[Linear interpolation]]

==References==
{{reflist}}

==External links==
*{{wiktionary-inline}}

[[Category:Elementary algebra]]
[[Category:Concepts in physics]]
[[Category:Broad-concept articles]]</text>
      <sha1>plstaurvu9wejckebzbwt06l37038ef</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical statistics</title>
    <ns>0</ns>
    <id>888711</id>
    <revision>
      <id>856544312</id>
      <parentid>855608502</parentid>
      <timestamp>2018-08-26T00:17:02Z</timestamp>
      <contributor>
        <username>Runawayangel</username>
        <id>7340759</id>
      </contributor>
      <minor/>
      <comment>/* Additional reading */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14917">[[Image:Linear regression.svg|thumb|right|300px|Illustration of linear regression on a data set. [[Regression analysis]] is an important part of mathematical statistics.]]

'''Mathematical statistics''' is the application of [[probability theory]], a branch of [[mathematics]], to [[statistics]], as opposed to techniques for collecting statistical data. Specific mathematical techniques which are used for this include [[mathematical analysis]], [[linear algebra]], [[stochastic analysis]], [[differential equations]], and [[measure theory]].&lt;ref&gt;{{cite book|last=Lakshmikantham,|first=ed. by D. Kannan,... V.|title=Handbook of stochastic analysis and applications|date=2002|publisher=M. Dekker|location=New York|isbn=0824706609}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Schervish|first=Mark J.|title=Theory of statistics|date=1995|publisher=Springer|location=New York|isbn=0387945466|edition=Corr. 2nd print.}}&lt;/ref&gt;

==Introduction==
Statistical data collection is concerned with the planning of studies, especially with the [[design of experiments|design of randomized experiments]] and with the planning of [[statistical survey|surveys]] using [[random sampling]]. The initial analysis of the data often follows the study protocol specified prior to the study being conducted. The data from a study can also be analyzed to consider secondary hypotheses inspired by the initial results, or to suggest new studies. A secondary analysis of the data from a planned study uses tools from [[data analysis]], and the process of doing this is mathematical statistics.

Data analysis is divided into:

* [[descriptive statistics]] - the part of statistics that describes data, i.e. summarises the data and their typical properties.
* [[inferential statistics]] - the part of statistics that draws conclusions from data (using some model for the data): For example, inferential statistics involves selecting a model for the data, checking whether the data fulfill the conditions of a particular model, and with quantifying the involved uncertainty (e.g. using [[confidence interval]]s).

While the tools of data analysis work best on data from randomized studies, they are also applied to other kinds of data. For example, from [[natural experiments]] and [[observational studies]], in which case the inference is dependent on the model chosen by the statistician, and so subjective.&lt;ref&gt;[[David A. Freedman (statistician)|Freedman, D.A.]] (2005) ''Statistical Models: Theory and Practice'', Cambridge University Press. {{isbn|978-0-521-67105-7}}&lt;/ref&gt;

==Topics==
The following are some of the important topics in mathematical statistics:&lt;ref&gt;Hogg, R. V., A. Craig, and J. W. McKean. "Intro to Mathematical Statistics." (2005).&lt;/ref&gt;&lt;ref&gt;Larsen, Richard J. and Marx, Morris L. "An Introduction to Mathematical Statistics and Its Applications" (2012). Prentice Hall.&lt;/ref&gt;

===Probability distributions===
{{main|Probability distribution}}
A [[probability distribution]] is a [[function (mathematics)|function]] that assigns a [[probability]] to each [[measure (mathematics)|measurable subset]] of the possible outcomes of a random [[Experiment (probability theory)|experiment]], [[Survey methodology|survey]], or procedure of [[statistical inference]]. Examples are found in experiments whose [[sample space]] is non-numerical, where the distribution would be a [[categorical distribution]]; experiments whose sample space is encoded by discrete [[random variables]], where the distribution can be specified by a [[probability mass function]]; and experiments with sample spaces encoded by continuous random variables, where the distribution can be specified by a [[probability density function]]. More complex experiments, such as those involving [[stochastic processes]] defined in [[continuous time]], may demand the use of more general [[probability measure]]s.

A probability distribution can either be [[Univariate distribution|univariate]] or [[Multivariate distribution|multivariate]]. A univariate distribution gives the probabilities of a single [[random variable]] taking on various alternative values; a multivariate distribution (a joint probability distribution) gives the probabilities of a [[random vector]]—a set of two or more random variables—taking on various combinations of values. Important and commonly encountered univariate probability distributions include the [[binomial distribution]], the [[hypergeometric distribution]], and the [[normal distribution]]. The [[multivariate normal distribution]] is a commonly encountered multivariate distribution.

====Special distributions====
*[[Normal distribution]],  the most common continuous distribution
*[[Bernoulli distribution]], for the outcome of a single Bernoulli trial (e.g. success/failure, yes/no)
*[[Binomial distribution]], for the number of "positive occurrences" (e.g. successes, yes votes, etc.) given a fixed total number of [[independent (statistics)|independent]] occurrences
*[[Negative binomial distribution]], for binomial-type observations but where the quantity of interest is the number of failures before a given number of successes occurs
*[[Geometric distribution]], for binomial-type observations but where the quantity of interest is the number of failures before the first success; a special case of the negative binomial distribution, where the number of successes is one.
*[[Discrete uniform distribution]], for a finite set of values (e.g. the outcome of a fair die)
*[[Continuous uniform distribution]], for continuously distributed values
*[[Poisson distribution]], for the number of occurrences of a Poisson-type event in a given period of time
*[[Exponential distribution]], for the time before the next Poisson-type event occurs
*[[Gamma distribution]], for the time before the next k Poisson-type events occur
*[[Chi-squared distribution]], the distribution of a sum of squared [[standard normal]] variables; useful e.g. for inference regarding the [[sample variance]] of normally distributed samples (see [[chi-squared test]])
*[[Student's t distribution]], the distribution of the ratio of a [[standard normal]] variable and the square root of a scaled [[chi squared distribution|chi squared]] variable; useful for inference regarding the [[mean]] of normally distributed samples with unknown variance (see [[Student's t-test]])
*[[Beta distribution]], for a single probability (real number between 0 and 1); conjugate to the [[Bernoulli distribution]] and [[binomial distribution]]

===Statistical inference===
{{main|Statistical inference}}
[[Statistical inference]] is the process of drawing conclusions from data that are subject to random variation, for example, observational errors or sampling variation.&lt;ref name="Oxford"&gt;Upton, G., Cook, I. (2008) ''Oxford Dictionary of Statistics'', OUP. {{isbn|978-0-19-954145-4}}&lt;/ref&gt; Initial requirements of such a system of procedures for [[inference]] and [[Inductive reasoning|induction]] are that the system should produce reasonable answers when applied to well-defined situations and that it should be general enough to be applied across a range of situations. Inferential statistics are used to test hypotheses and make estimations using sample data. Whereas [[descriptive statistics]] describe a sample, inferential statistics infer predictions about a larger population that the sample represents.

The outcome of statistical inference may be an answer to the question "what should be done next?", where this might be a decision about making further experiments or surveys, or about drawing a conclusion before implementing some organizational or governmental policy.
For the most part, statistical inference makes propositions about populations, using data drawn from the population of interest via some form of random sampling. More generally, data about a random process is obtained from its observed behavior during a finite period of time. Given a parameter or hypothesis about which one wishes to make inference, statistical inference most often uses:
* a [[statistical model]] of the random process that is supposed to generate the data, which is known when randomization has been used, and
* a particular realization of the random process; i.e., a set of data.

===Regression===
{{main|Regression analysis}}

In [[statistics]], '''regression analysis''' is a statistical process for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a [[dependent variable]] and one or more [[independent variable]]s. More specifically, regression analysis helps one understand how the typical value of the dependent variable (or 'criterion variable') changes when any one of the independent variables is varied, while the other independent variables are held fixed. Most commonly, regression analysis estimates the [[conditional expectation]] of the dependent variable given the independent variables – that is, the [[average value]] of the dependent variable when the independent variables are fixed. Less commonly, the focus is on a [[quantile]], or other [[location parameter]] of the conditional distribution of the dependent variable given the independent variables. In all cases, the estimation target is a [[function (mathematics)|function]] of the independent variables called the '''regression function'''. In regression analysis, it is also of interest to characterize the variation of the dependent variable around the regression function which can be described by a [[probability distribution]].

Many techniques for carrying out regression analysis have been developed. Familiar methods, such as [[linear regression]], are [[parametric statistics|parametric]], in that the regression function is defined in terms of a finite number of unknown [[parameter]]s that are estimated from the [[data]] (e.g. using [[ordinary least squares]]). [[Nonparametric regression]] refers to techniques that allow the regression function to lie in a specified set of [[function (mathematics)|functions]], which may be [[dimension|infinite-dimensional]].

===Nonparametric statistics===
{{main|Nonparametric statistics}}
'''Nonparametric statistics''' are values calculated from data in a way that is not based on [[parametrization|parameterized]] families of [[probability distribution]]s. They include both [[descriptive statistics|descriptive]] and [[statistical inference|inferential]] statistics. The typical parameters are the mean, variance, etc. Unlike [[parametric statistics]], nonparametric statistics make no assumptions about the [[probability distribution]]s of the variables being assessed{{citation needed|date=March 2018}}.

Non-parametric methods are widely used for studying populations that take on a ranked order (such as movie reviews receiving one to four stars).  The use of non-parametric methods may be necessary when data have a [[ranking]] but no clear numerical interpretation, such as when assessing [[preferences]]. In terms of [[level of measurement|levels of measurement]], non-parametric methods result in "ordinal" data.

As non-parametric methods make fewer assumptions, their applicability is much wider than the corresponding parametric methods.  In particular, they may be applied in situations where less is known about the application in question.  Also, due to the reliance on fewer assumptions, non-parametric methods are more [[Robust statistics#Introduction|robust]].

Another justification for the use of non-parametric methods is simplicity.  In certain cases, even when the use of parametric methods is justified, non-parametric methods may be easier to use.  Due both to this simplicity and to their greater robustness, non-parametric methods are seen by some statisticians as leaving less room for improper use and misunderstanding.

==Statistics, mathematics, and mathematical statistics==
Mathematical statistics is a key subset of the discipline of [[statistics]]. [[Statisticians|Statistical theorists]] study and improve statistical procedures with mathematics, and statistical research often raises mathematical questions. Statistical theory relies on [[Probability theory|probability]] and [[optimal decision|decision theory]].

Mathematicians and statisticians like [[Gauss]], [[Laplace]], and [[Charles Sanders Peirce|C. S. Peirce]] used [[optimal decision|decision theory]] with [[probability distribution]]s and [[loss function]]s (or [[utility function]]s). The decision-theoretic approach to statistical inference was reinvigorated by [[Abraham Wald]] and his successors,&lt;ref&gt;{{Cite book
 | first = Abraham
 | last = Wald |authorlink=Abraham Wald
 | title = Sequential analysis
 | year = 1947
 | publisher = John Wiley and Sons
 | location = New York
 | isbn = 0-471-91806-7
 | quote = See Dover reprint, 2004: {{isbn|0-486-43912-7}}
}}&lt;/ref&gt;&lt;ref&gt;{{cite book
|first=Abraham
|last=Wald
|authorlink=Abraham Wald
|title=Statistical Decision Functions
|year=1950
|publisher=John Wiley and Sons, New York
}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Lehmann|first=Erich|authorlink=Erich Leo Lehmann
| title=Testing Statistical Hypotheses|year=1997 |edition=2nd
|isbn=0-387-94919-4 }}&lt;/ref&gt;&lt;ref&gt;
{{cite book 
| last1=Lehmann 
| first1=Erich
| last2=Cassella
| first2=George
| authorlink1=Erich Leo Lehmann
| title=Theory of Point Estimation 
| year=1998 |edition=2nd|isbn= 0-387-98502-6}}&lt;/ref&gt;&lt;ref&gt;
{{cite book
| last1=Bickel|first1= Peter J.|last2=Doksum|first2=Kjell A.
| authorlink1=Peter J. Bickel
|title=Mathematical Statistics: Basic and Selected Topics
|volume=1
|edition=Second (updated printing 2007) 
|year=2001
|publisher=Pearson Prentice-Hall
}}&lt;/ref&gt;&lt;ref&gt;{{cite book
|first=Lucien
|last=Le Cam
|authorlink=Lucien Le Cam
|title=Asymptotic Methods in Statistical Decision Theory
|year=1986
|publisher=Springer-Verlag |isbn=0-387-96307-3
}}&lt;/ref&gt;&lt;ref&gt;{{cite book
|author1=Liese, Friedrich  |author2=Miescke, Klaus-J.
 |lastauthoramp=yes |title=Statistical Decision Theory: Estimation, Testing, and Selection
|year=2008
|publisher=Springer
}}
&lt;/ref&gt; and makes extensive use of [[scientific computing]], [[mathematical analysis|analysis]], and [[Optimization (mathematics)|optimization]]; for the [[design of experiments]], statisticians use [[Algebraic statistics|algebra]] and [[Combinatorial design|combinatorics]].

==See also==
*[[Asymptotic theory (statistics)]]

==References==
&lt;references/&gt;

== Further reading ==
* Borovkov, A. A. (1999). ''Mathematical Statistics''. CRC Press.  {{isbn|90-5699-018-7}}
* [http://www.math.uah.edu/stat/ Virtual Laboratories in Probability and Statistics (Univ. of Ala.-Huntsville)]
* [http://www.trigonella.ch/statibot/english/ StatiBot], interactive online expert system on statistical tests.

{{Statistics}}
{{Areas of mathematics}}

{{Authority control}}

{{DEFAULTSORT:Mathematical Statistics}}
[[Category:Statistical theory]]
[[Category:Actuarial science]]</text>
      <sha1>kuw4h32g9r34og3l1dcdrty5n8h9s3c</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematics and the Search for Knowledge</title>
    <ns>0</ns>
    <id>49403913</id>
    <revision>
      <id>787260710</id>
      <parentid>749363195</parentid>
      <timestamp>2017-06-24T11:18:10Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3628">{{primary sources|date=February 2016}}
{{Infobox book
| name             = Mathematics and the Search for Knowledge
| image            = 
| caption          = 
| author           = [[Morris Kline]]
| cover_artist     = 
| country          = 
| language         = 
| series           = 
| subject          = 
| genre            = 
| publisher        = Oxford University Press
| pub_date         = 1985
| media_type       = 
| pages            = 
| isbn =  0-19-503533-X
| oclc             = 
| dewey            = 
| congress         = 
| preceded_by      = [[Mathematics: The Loss of Certainty]]
| followed_by      = 
}}

'''''Mathematics and the Search for Knowledge''''' is a book by [[Morris Kline]] on the developing mathematics ideas, which are partially overlap with his previous book ''[[Mathematics: The Loss of Certainty]]'', as a source of human knowledge about the physical world, starting from astronomical theories of [[Ancient Greek]] to the modern theories.&lt;ref&gt;''Mathematics and the Search for Knowledge'' [https://books.google.ru/books?id=15KsIkh2SXEC&amp;printsec=frontcover&amp;dq=Mathematics+and+the+Search+for+Knowledge&amp;hl=ru&amp;sa=X&amp;ved=0ahUKEwj86vn_2vHKAhUlLZoKHQhRCq8Q6AEIJTAA#v=onepage&amp;q=Mathematics%20and%20the%20Search%20for%20Knowledge&amp;f=false], link from [[Google Books]]&lt;/ref&gt;

In contrast to the numerous theories, that have appeared since the ancient times up to Newton's [[Newton's law of universal gravitation|theory of gravitation]], which are describe different physical phenomena and were often intuitive and can be mechanically explained, but all modern theories, such as [[electromagnetism]], [[theory of relativity]], [[quantum mechanics]], are the mathematical description of reality, which  could not be granted with a clear interpretation, which would be available to human senses.

About the concepts that appear and are used in these theories to describe the physical world, we are the only known - mathematical relationships that they are satisfy (for example, an [[electromagnetic radiation]], [[wave-particle duality]], [[spacetime]], or an [[electron]]).

Due to the limitations of our senses capability (for example, from the whole spectrum of [[electromagnetic radiation]] the human eye perceives only a [[Visible spectrum|small part]]) and the ability to mislead us (for example, [[optical illusion]]), human is forced to use the mathematics as a tool that allows us to not only to compensate the imperfection of our senses, but also to obtain new knowledge, which are not available to our sensory perception.

The author brings us to the idea that the physical world, is not what available to us in our sensation, but rather what human-made mathematical theories say.

==Bibliography==
* Morris Kline, ''Mathematics and the Search for Knowledge'', Oxford University Press, 1985 {{ISBN|0-19-503533-X}}
*{{Cite journal|last = Peak|first = Philip|date = 1987-01-01|title = Review of Mathematics and the Search for Knowledge (L, P)|jstor = 27965470|journal = The Mathematics Teacher|volume = 80|issue = 6|pages = 496–496}}
*{{Cite journal|last = Hersh|first = Reuben|date = 1987-01-01|title = Review of Mathematics and the Search for Knowledge|jstor = 2323410|journal = The American Mathematical Monthly|volume = 94|issue = 3|pages = 314–315|doi = 10.2307/2323410}}
*{{Cite journal|last = Calinger|first = Ronald L.|date = 1990-01-01|title = Review of Mathematics and the Search for Knowledge|jstor = 234091|journal = Isis|volume = 81|issue = 1|pages = 87–88|doi=10.1086/355257}}

==Notes==
{{Reflist}}

[[Category:Mathematics books]]
[[Category:1985 books]]


{{mathematics-lit-stub}}</text>
      <sha1>rwfd2ht0dxnvhmlg3csce33gdv12khd</sha1>
    </revision>
  </page>
  <page>
    <title>Method of Fluxions</title>
    <ns>0</ns>
    <id>252953</id>
    <revision>
      <id>781855085</id>
      <parentid>781745586</parentid>
      <timestamp>2017-05-23T16:39:18Z</timestamp>
      <contributor>
        <username>Spinningspark</username>
        <id>3727527</id>
      </contributor>
      <minor/>
      <comment>/* Newton's development of analysis */ disambiguate [[quadrature]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5438">{{italic title}} 
{{Infobox book
| italic title   = Method of Fluxions
| name           = Method of Fluxions
| image          = The method of fluxions and infinite series cover.jpg
| image_size     = 
| alt            = 
| caption        = Cover of book published in 1736
| author         = Isaac Newton
| audio_read_by  = 
| title_orig     = 
| orig_lang_code = 
| title_working  = 
| translator     = 
| illustrator    = 
| cover_artist   = 
| country        = 
| language       = English
| series         = 
| release_number = 
| subject        = 
| genre          = Mathematics
| set_in         = 
| publisher      = Henry Woodfall
| publisher2     = 
| pub_date       = 1736
| english_pub_date = 
| published      = 
| media_type     = 
| pages          = 339
| awards         = 
| isbn           = 
| isbn_note      = 
| oclc           = 
| dewey          = 
| congress       = 
| preceded_by    = 
| followed_by    = 
| native_wikisource = 
| wikisource     = 
| notes          =
| exclude_cover  = 
| website        =
}}

'''''Method of Fluxions'''''&lt;ref&gt;[https://books.google.com/books?id=WyQOAAAAQAAJ The Method of Fluxions and Infinite Series]: With Its Application to the Geometry of Curve-lines. By Sir Isaac Newton, Translated from the Author's Latin Original Not Yet Made Publick. To which is Subjoin'd, a Perpetual Comment Upon the Whole Work, By John Colson, Sir Isaac Newton. Henry Woodfall; and sold by John Nourse, 1736.&lt;/ref&gt; is a book by [[Isaac Newton]]. The book was completed in 1671, and published in 1736. [[Fluxion (mathematics)|Fluxion]] is Newton's term for a [[derivative]]. He originally developed the method at [[Woolsthorpe Manor]] during the closing of [[University of Cambridge|Cambridge]] during the [[Great Plague of London]] from 1665 to 1667, but did not choose to make his findings known (similarly, his findings which eventually became the ''[[Philosophiae Naturalis Principia Mathematica]]'' were developed at this time and hidden from the world in Newton's notes for many years). [[Gottfried Leibniz]] developed his form of calculus independently around 1673, 7 years after [[Isaac Newton|Newton]] had developed the basis for differential calculus, as seen in surviving documents like “the method of fluxions and [[Fluent (mathematics)|fluents]]..." from 1666. Leibniz however published his discovery of differential calculus in 1684, nine years before Newton formally published his fluxion [[notation]] form of calculus in part during 1693.&lt;ref&gt;http://pages.cs.wisc.edu/~sastry/hs323/calculus.pdf&lt;/ref&gt; The calculus notation in use today is mostly that of Leibniz, although [[Newton's notation|Newton's dot notation]] for differentiation &lt;math&gt;\dot{x}&lt;/math&gt; for denoting derivatives with respect to time is still in current use throughout [[mechanics]] and [[circuit analysis]].

Newton's ''Method of Fluxions'' was formally published posthumously, but following Leibniz's publication of the calculus a [[Newton v. Leibniz calculus controversy|bitter rivalry]] erupted between the two mathematicians over who had developed the calculus first and so Newton no longer hid his knowledge of fluxions.

==Newton's development of analysis==
For a period of time encompassing Newton's working life, the discipline of [[Mathematical Analysis|analysis]] was a subject of controversy in the mathematical community. Although analytic techniques provided solutions to long-standing problems, including problems of [[Quadrature (mathematics)|quadrature]] and the finding of tangents, the proofs of these solutions were not known to be reducible to the synthetic rules of Euclidean geometry. Instead, analysts were often forced to invoke infinitesimal, or "infinitely small", quantities to justify their algebraic manipulations. Some of Newton's mathematical contemporaries, such as [[Isaac Barrow]], were highly skeptical of such techniques, which had no clear geometric interpretation. Although in his early work Newton also used infinitesimals in his derivations without justifying them, he later developed something akin to the modern definition of limits in order to justify his work.&lt;ref&gt;{{cite journal|last=Kitcher|first=Philip|title=Fluxions, Limits, and Infinite Littlenesse. A Study of Newton's Presentation of the Calculus|journal=Isis|date=Mar 1973|volume=64|issue=1|pages=33–49|jstor=229868|doi=10.1086/351042}}&lt;/ref&gt;

==See also==
{{Wikipedia books|Isaac Newton}}
{{Col-begin|width=60%}}
{{Col-break}}
*[[History of calculus]]
* [[Calorimetry]]
* [[George Berkeley]]
* [[Leonhard Euler]]
* [[Non-standard analysis]]
* [[Newton's method]]
* [[Calculus]]
* [[Charles Hayes (mathematician)]]
* [[1736 in science]]
{{Col-break}}

* [[John Landen]]
* [[John Colson]]
* [[Leibniz–Newton calculus controversy]]
* [[Joseph Raphson]]
* [[1736 in Great Britain]]
* [[Time in physics]]
* [[William Lax]]
* [[List of Rees's Cyclopædia articles|List of Rees's ''Cyclopaedia'' articles]]
{{col-end}}

==References and notes==
{{reflist}}

==External links==
{{commons category|Method of Fluxions (book)}}
*[https://archive.org/details/methodoffluxions00newt ''Method of Fluxions''] at the [[Internet Archive]]

{{Isaac Newton}}

{{authoritycontrol}}
[[Category:History of mathematics]]
[[Category:Mathematics books]]
[[Category:Books by Isaac Newton]]
[[Category:1671 books]]
[[Category:1736 books]]
[[Category:Differential calculus]]
[[Category:Mathematics literature]]
[[Category:1736 in science]]</text>
      <sha1>dg45058ljhgej2rdvygc2tozqhefyox</sha1>
    </revision>
  </page>
  <page>
    <title>P-space</title>
    <ns>0</ns>
    <id>41775284</id>
    <revision>
      <id>860503599</id>
      <parentid>835530630</parentid>
      <timestamp>2018-09-21T03:08:13Z</timestamp>
      <contributor>
        <ip>71.162.221.183</ip>
      </contributor>
      <comment>/* Generic use */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3807">{{For|the complexity class|PSPACE}}
{{DISPLAYTITLE:''P''-space}}
In the mathematical field of [[topology]], there are various notions of a '''''P''-space''' and of a '''''p''-space'''.

==Generic use==

The expression ''P-space'' might be used generically to denote a [[topological space]] satisfying some given and previously introduced topological invariant ''P''.&lt;ref&gt;Aisling E. McCluskey, ''Comparison of Topologies (Minimal and Maximal Topologies)'', Chapter a7 in Encyclopedia of General Topology, Edited by Klaas Pieter Hart, Jun-iti Nagata and Jerry E. Vaughan, 2003 Elsevier B.V.&lt;/ref&gt; This might apply also to [[space (mathematics)|spaces]] of a different kind, i.e. non-topological spaces with additional structure.

==''P-spaces'' in the sense of Gillman–Henriksen==

A ''P-space'' in the sense of [[Leonard Gillman|Gillman]]–[[Melvin Henriksen|Henriksen]] is a topological space in which every [[countable]] [[intersection (set theory)|intersection]] of [[open set]]s is open. An equivalent condition is that countable [[union (set theory)|unions]] of [[closed set]]s are closed. In other words, [[Gδ set|G&lt;sub&gt;δ&lt;/sub&gt; sets]] are open and [[Fσ set|F&lt;sub&gt;&amp;sigma;&lt;/sub&gt; sets]] are closed. The letter ''P'' stands for both ''pseudo-discrete'' and ''prime''. Gillman and Henriksen also define a ''P-point'' as a point at which any [[prime ideal]] of the ring of real-valued continuous functions is maximal, and a P-space is a space in which every point is a P-point.&lt;ref&gt;{{cite journal |last1=Gillman |first1=L. |last2=Henriksen |first2=M. |date=1954 |title=Concerning rings of continuous functions |journal=[[Transactions of the American Mathematical Society]] |issue=77 |pages=340–352 |doi=10.2307/1990875}} Cited in 
{{cite encyclopedia |last=Hart |first=K.P. |editor-last=Hazewinkel |editor-first=Michiel |encyclopedia=Encyclopaedia of Mathematics, Supplement III |title=P-point |year=2001 |publisher=Kluwer Academic Publishers |isbn=1-4020-0198-3 |pages=297}}&lt;/ref&gt;

Different authors restrict their attention to topological spaces that satisfy various [[separation axiom]]s. With the right axioms, one may characterize ''P''-spaces in terms of their rings of continuous [[real-valued function]]s.

Special kinds of ''P''-spaces include [[Alexandrov-discrete space]]s, in which arbitrary intersections of open sets are open. These in turn include [[locally finite space]]s, which include [[finite topological space|finite spaces]] and [[discrete space]]s.

==''P-spaces'' in the sense of Morita==

A different notion of a ''P-space'' has been introduced by [[Kiiti Morita]] in 1964, in connection with [[Morita conjectures|his (now solved) conjectures]] (see the relative entry for more information). Spaces satisfying the covering property introduced by Morita are sometimes also called ''Morita P-spaces'' or ''normal P-spaces''.

==''p-spaces''==

A notion of a ''p-space'' has been introduced by [[Alexander Arhangelskii]].&lt;ref&gt;Encyclopedia of General Topology, p. 278.&lt;/ref&gt;

==References==

&lt;references/&gt;

==Further reading==
*{{Citation |first=Leonard |last=Gillman |authorlink=Leonard Gillman |first2=Melvin |last2=Henriksen |date=September 1954 |title=Concerning Rings of Continuous Functions |journal=Transactions of the American Mathematical Society |volume=77 |issue=2 |pages=340–362 |jstor=1990875 |doi=10.2307/1990875}}
*{{Citation |first=Arvind K. |last=Misra |date=December 1972 |title=A topological view of P-spaces |journal=General Topology and its Applications |volume=2 |issue=4 |pages=349–362 |doi=10.1016/0016-660X(72)90026-8}}

==External links==
*{{SpringerEOM |title=P-space |id=P-space |last=Hart |first=K.P.}}
*{{PlanetMath |urlname=pspace |title=P-space}}

[[Category:General topology]]
[[Category:Properties of topological spaces]]


{{topology-stub}}</text>
      <sha1>i2bib1hy8ogeoadhq745ouhqol30e2m</sha1>
    </revision>
  </page>
  <page>
    <title>Peter Cameron (mathematician)</title>
    <ns>0</ns>
    <id>8007266</id>
    <revision>
      <id>840543751</id>
      <parentid>837834408</parentid>
      <timestamp>2018-05-10T15:45:24Z</timestamp>
      <contributor>
        <username>Ken Gallager</username>
        <id>1175300</id>
      </contributor>
      <comment>cat sort</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5726">{{other people||Peter Cameron (disambiguation)}}
{{Infobox scientist
| name              = Peter J. Cameron
| image             = PeterCameron.JPG
| image_size        = 
| alt               = Peter Cameron
| caption           = 
| birth_date        = {{b-da|23 January 1947}}
| birth_place       = [[Toowoomba, Queensland|Toowoomba]], [[Queensland]]
| death_date        = 
| death_place       = 
| residence         = 
| citizenship       = 
| nationality       = [[Australia]]n
| fields            =  [[algebra]], [[group theory]], [[combinatorics]], [[coding theory]], [[model theory]]
| workplaces        = [[University of St Andrews]]&lt;br&gt;[[Queen Mary, University of London]]&lt;br&gt;[[University of Oxford]]
| alma_mater        = [[University of Queensland]]&lt;br&gt;[[University of Oxford]]
| doctoral_advisor  = [[Peter M. Neumann]]
| academic_advisors = 
| doctoral_students = {{plainlist|1=
*[[Eric Lander]]
*[[Dugald Macpherson]]
*[[Sarah Rees]]&lt;ref&gt;[http://www.maths.qmw.ac.uk/~pjc/students.html Peter Camerons DPhil/PhD students]&lt;/ref&gt;
}}
| notable_students  = 
| known_for         = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| influences        = 
| influenced        = 
| awards            = [[Whitehead Prize]], 1979&lt;br&gt;[[Euler Medal]], 2003&lt;br&gt;Forder Lecturer, 2008&lt;ref&gt;[http://www.lms.ac.uk/events/lectures/forder-and-aitken-lectureship LMS-NZM Forder and Aitken Lectureships]&lt;/ref&gt;
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| footnotes         = 
| spouse            = 
}}
'''Peter Jephson Cameron''' [[Fellow of the Royal Society of Edinburgh|FRSE]] (born 23 January 1947) is an Australian mathematician who works in
[[group theory]], [[combinatorics]], [[coding theory]], and [[model theory]]. He is currently half-time Professor of Mathematics at the [[University of St Andrews]], and [[Emeritus Professor]] at [[Queen Mary University of London]].

Cameron received a B.Sc. from the [[University of Queensland]] and a D.Phil. in 1971 from [[University of Oxford]], with [[Peter M. Neumann]] as his supervisor.&lt;ref&gt;[http://genealogy.math.ndsu.nodak.edu/id.php?id=28732 Peter M. Neumann at the Mathematics Genealogy Project]&lt;/ref&gt; Subsequently, he was a Junior Research Fellow and later a Tutorial Fellow at [[Merton College]], Oxford, and also lecturer at [[Bedford College, London|Bedford College]], London. 

==Work==
Cameron specialises in [[algebra]] and combinatorics; he has written books about combinatorics, algebra, [[permutation groups]], and logic, and has produced over 250 academic papers.&lt;ref&gt;[http://www.maths.qmul.ac.uk/~pjc/publ.html Recent publications of Peter J. Cameron]&lt;/ref&gt; He posed the [[Cameron–Erdős conjecture]] with [[Paul Erdős]].

== Honours and awards ==
He was awarded the [[London Mathematical Society]]'s [[Whitehead Prize]] in 1979 and is joint winner of the 2003 [[Euler Medal]].In 2018 he was elected a Fellow of the [[Royal Society of Edinburgh]]&lt;ref&gt;{{Cite news|url=https://www.rse.org.uk/fellow/peter-cameron-2/|title=Professor Peter Jephson Cameron FRSE - The Royal Society of Edinburgh|work=The Royal Society of Edinburgh|access-date=2018-03-14|language=en-GB}}&lt;/ref&gt;.[[File:Peter Cameron lecturing.jpg|thumb|Peter Cameron giving the 2007 Dame [[Kathleen Ollerenshaw]] lecture at the [[School of Mathematics, University of Manchester]]]]

==Books==
* with [[Jack van Lint|J H van Lint]]: ''Graph Theory, Coding Theory and Block Designs'' (1975)
* ''Parallelisms of Complete Designs'' (1976)&lt;ref&gt;{{cite journal|author=Kantor, William M.|title=Review: ''Parallelisms of complete designs'', by Peter J. Cameron|journal=Bull. Amer. Math. Soc.|year=1978|volume=84|issue=3|pages=451–453|url=http://www.ams.org/journals/bull/1978-84-03/S0002-9904-1978-14489-9/|doi=10.1090/s0002-9904-1978-14489-9}}&lt;/ref&gt;
* ''Oligomorphic Permutation Groups'' (1990)
* with [[Jack van Lint|J H van Lint]]: ''Designs, Graphs, Codes and their Links'' (1991)
* [http://www.maths.qmul.ac.uk/~pjc/comb/ ''Combinatorics: Topics, Techniques, Algorithms''] (1994)
* [http://www.maths.qmul.ac.uk/~pjc/slc/ ''Sets, Logic and Categories''] (1999)
* [http://www.maths.qmul.ac.uk/~pjc/permgps/pgbook.html ''Permutation Groups''] (1999)
* [http://www.maths.qmul.ac.uk/~pjc/algebra/algebra.html ''Introduction to Algebra (first edition)''] (1998)
* [http://www.maths.qmul.ac.uk/~pjc/algebra/ ''Introduction to Algebra (second edition)''] (2008)

==Notes==
{{Reflist}}

==References==
*[https://web.archive.org/web/20070303025341/http://www.win.tue.nl/math/eidma/courses/minicourses/cameron/MC-DAG-5.html Short biography]
*[http://www.mas.ncl.ac.uk/~nser/]

==External links==
*[http://www.maths.qmul.ac.uk/~pjc/ Home page] at Queen Mary University of London
*[http://www-circa.mcs.st-andrews.ac.uk/~pjc/ Home page] at University of St Andrews
*[http://www.maths.qmul.ac.uk/~rfb/pjc60/ Peter Cameron's 60th birthday conference]
*[http://www.theoremoftheday.org/Resources/Mathematicians.html#cameron Theorems by Peter Cameron at Theorem of the Day]
*[http://cameroncounts.wordpress.com/ Peter Cameron's blog]
*{{MathGenealogy|id=26487}}

{{commons category|Peter Cameron}}

{{Authority control}}

{{DEFAULTSORT:Cameron, Peter}}
[[Category:Academics of Queen Mary University of London]]
[[Category:1947 births]]
[[Category:Living people]]
[[Category:Australian Rhodes Scholars]]
[[Category:Algebraists]]
[[Category:Coding theorists]]
[[Category:Combinatorialists]]
[[Category:Alumni of Balliol College, Oxford]]
[[Category:University of Queensland alumni]]
[[Category:Whitehead Prize winners]]
[[Category:Model theorists]]
[[Category:20th-century Australian mathematicians]]
[[Category:21st-century Australian mathematicians]]

{{Australia-scientist-stub}}
{{Mathematician-stub}}</text>
      <sha1>o6hpyr87g8r53gqc3csyltnynv8q7g6</sha1>
    </revision>
  </page>
  <page>
    <title>Proofs involving the Laplace–Beltrami operator</title>
    <ns>0</ns>
    <id>1807504</id>
    <revision>
      <id>814628739</id>
      <parentid>814611704</parentid>
      <timestamp>2017-12-09T23:44:06Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Lead}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3470">{{Unreferenced|date=December 2007}}
{{lead|date=December 2017}}
{{main|Laplace operator}}

==&amp;minus;div is adjoint to d==
The claim is made that &amp;minus;div is adjoint to ''d'':

:&lt;math&gt;\int_M df(X) \;\omega  = - \int_M f \, \operatorname{div} X \;\omega &lt;/math&gt;

Proof of the above statement:
:&lt;math&gt;\int_M (f\mathrm{div}(X) + X(f)) \omega = \int_M (f\mathcal{L}_X + \mathcal{L}_X(f)) \omega &lt;/math&gt;

::&lt;math&gt; = \int_M \mathcal{L}_X f\omega = \int_M \mathrm{d} \iota_X f\omega = \int_{\partial M} \iota_X f\omega&lt;/math&gt;

If ''f'' has [[compact support]], then the last integral vanishes, and we have the desired result.

==Laplace&amp;ndash;de Rham operator==
One may prove that the Laplace&amp;ndash;de Rham operator is equivalent to the definition of the Laplace&amp;ndash;Beltrami operator, when acting on a scalar function ''f''. This proof reads as:

:&lt;math&gt;\Delta f = 
\mathrm{d}\delta f + \delta\,\mathrm{d}f = 
\delta\, \mathrm{d}f = 
\delta \, \partial_i f \, \mathrm{d}x^i&lt;/math&gt;

::&lt;math&gt; = 
- {\star}\mathrm{d}{{\star}\partial_i f \, \mathrm{d}x^i} = 
- {\star}\mathrm{d}(\varepsilon_{i J}  \sqrt{|g|}\partial^i f \, \mathrm{d}x^J)&lt;/math&gt;

::&lt;math&gt; =
- {\star}\varepsilon_{i J} \, \partial_j 
(\sqrt{|g|}\partial^i f)\, \mathrm{d} x^j \wedge \mathrm{d}x^J = 
- {\star} \frac{1}{\sqrt{|g|}} \, \partial_i (\sqrt{|g|}\,\partial^i f) \mathrm{vol}_n&lt;/math&gt;

::&lt;math&gt; = -\frac{1}{\sqrt{|g|}}\, \partial_i (\sqrt{|g|}\,\partial^i f),&lt;/math&gt;

where vol{{sub|''n''}}; is the [[volume form]] and ''&amp;epsilon;'' is the completely antisymmetric [[Levi-Civita symbol]]. Note that in the above, the italic lower-case index ''i'' is a single index, whereas the upper-case Roman ''J'' stands for all of the remaining {{nowrap|''n'' &amp;minus; 1}} indices.  Notice that the Laplace&amp;ndash;de Rham operator is actually the negative Laplace&amp;ndash;Beltrami operator; this minus sign follows from the conventional definition of the properties of the [[codifferential]]. Unfortunately, &amp;Delta; is used to denote both; reader beware.

== Properties ==
Given scalar functions ''f'' and ''h'', and a real number ''a'', the Laplacian has the property:

:&lt;math&gt;\Delta(fh) = f \, \Delta h + 2 \partial_i f \, \partial^i h + h \, \Delta f.&lt;/math&gt;

===Proof===
:&lt;math&gt;\Delta(fh) = 
\delta\,\mathrm{d}fh = 
\delta(f\,\mathrm{d}h + h\,\mathrm{d}f) = 
{\star}\mathrm{d}(f{{\star}\mathrm{d}h}) + {\star}\mathrm{d}(h{*\mathrm{d}f})&lt;/math&gt;

:::&lt;math&gt; = {\star}(f\,\mathrm{d}{\star}\mathrm{d}h + 
\mathrm{d}f \wedge {\star}\mathrm{d}h + 
\mathrm{d}h \wedge {\star}\mathrm{d}f + 
h\,\mathrm{d}{\star}\mathrm{d}f) 
&lt;/math&gt;

:::&lt;math&gt; = 
f{\star}\mathrm{d}{\star}\mathrm{d}h + 
{\star}(\mathrm{d}f \wedge {\star}\mathrm{d}h + 
\mathrm{d}h \wedge {\star}\mathrm{d}f) + 
h{\star}\mathrm{d}{\star}\mathrm{d}f&lt;/math&gt;

:::&lt;math&gt; = f\, \Delta h &lt;/math&gt;

::::&lt;math&gt; {} + 
{\star}(\partial_i f \, \mathrm{d}x^i \wedge 
\varepsilon_{jJ} \sqrt{|g|} \partial^j h \, \mathrm{d}x^J + 
\partial_i h \, \mathrm{d}x^i \wedge 
\varepsilon_{jJ} \sqrt{|g|} \partial^j f \, \mathrm{d}x^J) &lt;/math&gt;

::::&lt;math&gt; {} + 
h \, \Delta f&lt;/math&gt;

:::&lt;math&gt; = f \, \Delta h + 
(\partial_i f \, \partial^i h + 
\partial_i h \, \partial^i f){{\star}\mathrm{vol}_n} + 
h \, \Delta f &lt;/math&gt;

:::&lt;math&gt; = f \, \Delta h + 
2 \partial_i f \, \partial^i h + 
h \, \Delta f&lt;/math&gt;

where ''f'' and ''h'' are scalar functions.

{{DEFAULTSORT:Proofs involving the Laplace-Beltrami operator}}
[[Category:Article proofs]]
[[Category:Differential operators]]</text>
      <sha1>d47d5o838gcmryrkg4wdr2kmepe08fl</sha1>
    </revision>
  </page>
  <page>
    <title>Proofs related to chi-squared distribution</title>
    <ns>0</ns>
    <id>24510992</id>
    <revision>
      <id>808151945</id>
      <parentid>808143446</parentid>
      <timestamp>2017-11-01T05:14:35Z</timestamp>
      <contributor>
        <ip>66.75.244.161</ip>
      </contributor>
      <comment>/* Derivation of the pdf for k degrees of freedom */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6513">{{main article|Chi-squared distribution}}

The following are proofs of several characteristics related to the [[chi-squared distribution]].

== Derivations of the pdf ==

===Derivation of the pdf for one degree of freedom===
Let random variable ''Y'' be defined as ''Y'' = ''X''&lt;sup&gt;2&lt;/sup&gt; where ''X'' has [[normal distribution]] with mean 0 and variance 1 (that is ''X''&amp;nbsp;~&amp;nbsp;''N''(0,1)).

Then,&lt;br&gt;
&lt;math&gt;
\begin{alignat}{2}
\text{for} ~ y &lt; 0, &amp; ~~ P(Y&lt;y) = 0 ~~ \text{and} \\
\text{for} ~ y \geq 0, &amp; ~~ P(Y&lt;y) = P(X^2&lt;y) = P(|X|&lt;\sqrt{y}) = P(-\sqrt{y} &lt; X &lt;\sqrt{y})\\ 
~~ &amp; = F_X(\sqrt{y})-F_X(-\sqrt{y})= F_X(\sqrt{y})-(1-F_X(\sqrt{y}))= 2 F_X(\sqrt{y})-1
\end{alignat}
&lt;/math&gt;

: &lt;math&gt;
\begin{align}
f_Y(y) &amp; = 2 \frac{d}{dy} F_X(\sqrt{y}) - 0 = 2 \frac{d}{dy} \left( \int_{-\infty}^\sqrt{y} \frac{1}{\sqrt{2\pi}} e^{\frac{-t^2}{2}} dt \right) \\
&amp; = 2 \frac{1}{\sqrt{2 \pi}} e^{-\frac{y}{2}} (\sqrt{y})'_y = 2 \frac{1}{\sqrt{2}\sqrt{\pi}} e^{-\frac{y}{2}} \left( \frac{1}{2} y^{-\frac{1}{2}} \right) = 
\frac{1}{2^{\frac{1}{2}} \Gamma(\frac{1}{2})}y^{-\frac{1}{2}}e^{-\frac{y}{2}}
\end{align}
&lt;/math&gt;

Where &lt;math&gt;F&lt;/math&gt; and &lt;math&gt;f&lt;/math&gt; are the cdf and pdf of the corresponding random variables.

Then &lt;math&gt;Y = X^2 \sim \chi^2_1.&lt;/math&gt;

====Alternative proof directly using the change of variable formula====
The [[random variable#Functions of random variables|change of variable formula]] (implicitly derived above), for a [[monotonic]] transformation &lt;math&gt;y=g(x)&lt;/math&gt;, is: 
:&lt;math&gt;f_Y(y) = \sum_{i} f_X(g_{i}^{-1}(y)) \left| \frac{d g_{i}^{-1}(y)}{d y} \right|. &lt;/math&gt;

In this case the change is not monotonic, because every value of &lt;math&gt;\scriptstyle Y&lt;/math&gt; has two corresponding values of &lt;math&gt;\scriptstyle X&lt;/math&gt; (one positive and negative).  However, because of symmetry, both halves will transform identically, i.e.

:&lt;math&gt;f_Y(y) = 2f_X(g^{-1}(y)) \left| \frac{d g^{-1}(y)}{d y} \right|.&lt;/math&gt;

In this case, the transformation is: &lt;math&gt;x = g^{-1}(y) = \sqrt{y}&lt;/math&gt;, and its derivative is
&lt;math&gt;\frac{d g^{-1}(y)}{d y} = \frac{1}{2\sqrt{y}} .&lt;/math&gt;

So here:

:&lt;math&gt; f_Y(y) = 2\frac{1}{\sqrt{2\pi}}e^{-y/2} \frac{1}{2\sqrt{y}} = \frac{1}{\sqrt{2\pi y}}e^{-y/2}. &lt;/math&gt;

And one gets the chi-squared distribution, noting the property of the [[gamma function#Particular values|gamma function]]: &lt;math&gt; \Gamma(1/2)=\sqrt{\pi}&lt;/math&gt;.

===Derivation of the pdf for two degrees of freedom===
There are several methods to derive chi-squared distribution with 2 degrees of freedom. Here is one based on the distribution with 1 degree of freedom.

Suppose that &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are two independent variables satisfying &lt;math&gt;x\sim\chi^2_1&lt;/math&gt; and &lt;math&gt;y\sim\chi^2_1&lt;/math&gt;, so that the probability density functions of &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are respectively:

: &lt;math&gt;
f(x)=\frac{1}{2^{\frac{1}{2}}\Gamma(\frac{1}{2})}x^{-\frac{1}{2}}e^{-\frac{x}{2}}
&lt;/math&gt;
and
: &lt;math&gt;
f(y)=\frac{1}{2^{\frac{1}{2}}\Gamma(\frac{1}{2})}y^{-\frac{1}{2}}e^{-\frac{y}{2}}
&lt;/math&gt;

Simply, we can derive the joint distribution of &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt;:

: &lt;math&gt;
f(x,y)=\frac{1}{2\pi}(xy)^{-\frac{1}{2}}e^{-\frac{x+y}{2}}
&lt;/math&gt;

where &lt;math&gt;\Gamma(\frac{1}{2})^2&lt;/math&gt; is replaced by &lt;math&gt;\pi&lt;/math&gt;. Further, let &lt;math&gt;A=xy&lt;/math&gt; and &lt;math&gt;B=x+y&lt;/math&gt;, we can get that:

: &lt;math&gt;
x = \frac{B+\sqrt{B^2-4A}}{2}
&lt;/math&gt;
and
: &lt;math&gt;
y = \frac{B-\sqrt{B^2-4A}}{2}
&lt;/math&gt;

or, inversely

: &lt;math&gt;
x = \frac{B-\sqrt{B^2-4A}}{2}
&lt;/math&gt;
and
: &lt;math&gt;
y = \frac{B+\sqrt{B^2-4A}}{2}
&lt;/math&gt;

Since the two variable change policies are symmetric, we take the upper one and multiply the result by 2. The Jacobian determinant can be calculated as:

: &lt;math&gt;
\operatorname{Jacobian}\left( \frac{x, y}{A, B} \right)
         =\begin{vmatrix}
                 -(B^2-4A)^{-\frac{1}{2}}                     &amp; \frac{1+B(B^2-4A)^{-\frac{1}{2}}}{2}             \\
                 (B^2-4A)^{-\frac{1}{2}}                     &amp; \frac{1-B(B^2-4A)^{-\frac{1}{2}}}{2}             \\
          \end{vmatrix}
       = (B^2-4A)^{-\frac{1}{2}}
&lt;/math&gt;

Now we can change &lt;math&gt;f(x,y)&lt;/math&gt; to &lt;math&gt;f(A,B)&lt;/math&gt;:

: &lt;math&gt;
f(A,B)=2\times\frac{1}{2\pi}A^{-\frac{1}{2}}e^{-\frac{B}{2}}(B^2-4A)^{-\frac{1}{2}}
&lt;/math&gt;

where the leading constant 2 is to take both the two variable change policies into account. Finally, we integrate out &lt;math&gt;A&lt;/math&gt; to get the distribution of &lt;math&gt;B&lt;/math&gt;, i.e. &lt;math&gt;x+y&lt;/math&gt;:

: &lt;math&gt;
f(B)=2\times\frac{e^{-\frac{B}{2}}}{2\pi}\int_0^{\frac{B^2}{4}}A^{-\frac{1}{2}}(B^2-4A)^{-\frac{1}{2}}dA
&lt;/math&gt;

Let &lt;math&gt;A=\frac{B^2}{4}\sin^2(t)&lt;/math&gt;, the equation can be changed to:

: &lt;math&gt;
f(B)=2\times\frac{e^{-\frac{B}{2}}}{2\pi}\int_0^{\frac{\pi}{2}} \, dt
&lt;/math&gt;

So the result is:

: &lt;math&gt;
f(B)=\frac{e^{-\frac{B}{2}}}{2}
&lt;/math&gt;

=== Derivation of the pdf for ''k'' degrees of freedom ===

Consider the ''k'' samples &lt;math&gt;x_i&lt;/math&gt; to represent a single point in a ''k''-dimensional space. The chi square distribution for ''k'' degrees of freedom will then be given by:

:&lt;math&gt;
P(Q) \, dQ = \int_\mathcal{V} \prod_{i=1}^k (N(x_i)\,dx_i) = \int_\mathcal{V} \frac{e^{-(x_1^2 + x_2^2 + \cdots +x_k^2)/2}}{(2\pi)^{k/2}}\,dx_1\,dx_2 \cdots dx_k
&lt;/math&gt;

where &lt;math&gt;N(x)&lt;/math&gt; is the standard [[normal distribution]] and &lt;math&gt;\mathcal{V}&lt;/math&gt; is that elemental shell volume at ''Q''(''x''), which is proportional to the (''k''&amp;nbsp;&amp;minus;&amp;nbsp;1)-dimensional surface in ''k''-space for which

: &lt;math&gt;Q=\sum_{i=1}^k x_i^2&lt;/math&gt;

It can be seen that this surface is the surface of a ''k''-dimensional ball or, alternatively, an [[n-sphere]] where ''n''&amp;nbsp;=&amp;nbsp;''k''&amp;nbsp;-&amp;nbsp;1 with radius &lt;math&gt;R=\sqrt{Q}&lt;/math&gt;, and that the term in the exponent is simply expressed in terms of ''Q''. Since it is a constant, it may be removed from inside the integral.

:&lt;math&gt;
P(Q) \, dQ = \frac{e^{-Q/2}}{(2\pi)^{k/2}} \int_\mathcal{V} dx_1\,dx_2\cdots dx_k
&lt;/math&gt;

The integral is now simply the surface area ''A'' of the (''k''&amp;nbsp;&amp;minus;&amp;nbsp;1)-sphere times the infinitesimal thickness of the sphere which is

:&lt;math&gt;dR=\frac{dQ}{2Q^{1/2}}.&lt;/math&gt;

The area of a [[n-sphere|(''k''&amp;nbsp;&amp;minus;&amp;nbsp;1)-sphere]] is:

:&lt;math&gt;
A=\frac{2R^{k-1}\pi^{k/2}}{\Gamma(k/2)}
&lt;/math&gt;

Substituting, realizing that &lt;math&gt;\Gamma(z+1)=z\Gamma(z)&lt;/math&gt;, and cancelling terms yields:

:&lt;math&gt;
P(Q) \, dQ = \frac{e^{-Q/2}}{(2\pi)^{k/2}}A\,dR= \frac{1}{2^{k/2}\Gamma(k/2)}Q^{k/2-1}e^{-Q/2}\,dQ
&lt;/math&gt;

[[Category:Article proofs]]</text>
      <sha1>2rg16evhn3vg4tbo6m73tw0z3mkzo6s</sha1>
    </revision>
  </page>
  <page>
    <title>Random oracle</title>
    <ns>0</ns>
    <id>451286</id>
    <revision>
      <id>864123450</id>
      <parentid>855487358</parentid>
      <timestamp>2018-10-15T07:23:43Z</timestamp>
      <contributor>
        <username>BenKuykendall</username>
        <id>12604315</id>
      </contributor>
      <comment>add cryptographic models navbox</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10325">{{for|random replies to random questions|Internet Oracle}}

In [[cryptography]], a '''random oracle''' is an [[oracle machine|oracle]] (a theoretical [[black box (systems)|black box]]) that responds to every ''unique query'' with a (truly) [[random]] response chosen [[uniform distribution (discrete)|uniformly]] from its output domain.  If a query is repeated it responds the same way every time that query is submitted.

Stated differently, a random oracle is a [[mathematical function]] chosen uniformly at random, that is, a function mapping each possible query to a (fixed) random response from its output domain.

Random oracles as a mathematical abstraction were firstly used in rigorous cryptographic proofs in the 1993 publication by [[Mihir Bellare]] and [[Phillip Rogaway]] (1993).&lt;ref name="bellrog"&gt;{{cite journal|first=Mihir|last=Bellare|authorlink=Mihir Bellare|first2=Phillip|last2=Rogaway|authorlink2=Phillip Rogaway|title=Random Oracles are Practical: A Paradigm for Designing Efficient Protocols|journal=ACM Conference on Computer and Communications Security|year=1993|pages=62–73|url=http://www.cs.ucsd.edu/users/mihir/papers/ro.html}}&lt;/ref&gt; They are typically used when the proof cannot be carried out using weaker assumptions on the [[cryptographic hash function]]. A system that is proven secure when every hash function is replaced by a random oracle is described as being secure in the '''random oracle model''', as opposed to secure in the [[Standard Model (cryptography)|standard model of cryptography]].

== Applications ==
Random oracles are typically used&lt;!--{{who|date=June 2015}} See talk page "Weasel Words"--&gt; as an [[platonic ideal|ideal]] replacement for [[cryptographic hash function]]s in schemes where strong randomness assumptions are needed of the hash function's output.  Such a proof generally shows{{examples|date=June 2015}} that a system or a protocol is secure by showing that an attacker must require impossible behavior from the oracle, or solve some mathematical problem believed [[List of hard mathematical problems|hard]] in order to break it.

Not all uses of cryptographic hash functions require random oracles: schemes that require only one or more properties having a definition in the [[Standard model (cryptography)|standard model]] (such as [[collision resistance]], [[preimage resistance]], [[second preimage resistance]], etc.) can often be proven secure in the standard model (e.g., the [[Cramer–Shoup cryptosystem]]).

Random oracles have long been considered in [[computational complexity theory]],&lt;ref&gt;{{Citation | last1=Bennett | first1=Charles H. | author1-link=Charles H. Bennett (computer scientist) | last2=Gill | first2=John | title=Relative to a Random Oracle A, P^A != NP^A != co-NP^A with Probability 1 | year=1981 | journal=SIAM Journal on Computing | issn=1095-7111 | volume=10 | issue=1 | pages=96–113 | doi=10.1137/0210008}}&lt;/ref&gt; and many schemes have been proven secure in the random oracle model, for example [[Optimal Asymmetric Encryption Padding]], [[Full Domain Hash|RSA-FDH]] and [[Probabilistic Signature Scheme]]. In 1986, [[Amos Fiat]] and [[Adi Shamir]]&lt;ref&gt;{{cite news|first1=Amos|last1=Fiat|first2=Adi|last2=Shamir|title=How to Prove Yourself: Practical Solutions to Identification and Signature Problems|work=[[CRYPTO]]|year=1986|pages=186–194}}&lt;/ref&gt; showed a major application of random oracles – the removal of interaction from protocols for the creation of signatures.

In 1989, Russell Impagliazzo and Steven Rudich&lt;ref&gt;{{cite journal|first=Russell|last=Impagliazzo|first2=Steven|last2=Rudich|title=Limits on the Provable Consequences of One-Way Permutations|work=[[STOC]]|year=1989|pages=44–61}}&lt;/ref&gt; showed the limitation of random oracles – namely that their existence alone is not sufficient for secret-key exchange.

In 1993, [[Mihir Bellare]] and [[Phillip Rogaway]]&lt;ref name="bellrog"/&gt; were the first to advocate their use in cryptographic constructions. In their definition, the random oracle produces a bit-string of [[infinity|infinite]] length which can be truncated to the length desired.

When a random oracle is used within a security proof, it is made available to all players, including the adversary or adversaries.  A single oracle may be treated as multiple oracles by pre-pending a fixed bit-string to the beginning of each query (e.g., queries formatted as "1|x" or "0|x" can be considered as calls to two separate random oracles, similarly "00|x", "01|x", "10|x" and "11|x" can be used to represent calls to four separate random oracles).

== Limitations ==
According to the [[Church–Turing thesis]], no function computable by a finite algorithm can implement a true random oracle (which by definition requires an infinite description).{{why|date=April 2017}}

In fact, certain [[Pathological (mathematics)|artificial]] signature and encryption schemes are known which are proven secure in the random oracle model, but which are trivially insecure when any real function is substituted for the random oracle.&lt;ref&gt;Ran Canetti, Oded Goldreich and Shai Halevi, The Random Oracle Methodology Revisited, STOC 1998, pp. 209–218 [https://arxiv.org/abs/cs.CR/0010019 (PS and PDF)].&lt;/ref&gt;&lt;ref name="gentry_ramzan"&gt;Craig Gentry and Zulfikar Ramzan. [https://www.iacr.org/cryptodb/archive/2004/ASIACRYPT/218/218.pdf "Eliminating Random Permutation Oracles in the Even-Mansour Cipher"]. 2004.&lt;/ref&gt; Nonetheless, for any more natural protocol a proof of security in the random oracle model gives very strong evidence of the ''practical'' security of the protocol.&lt;ref name=anotherloook&gt;{{cite journal|last1=Koblitz|first1=Neal|last2=Menezes|first2=Alfred J.|title=The Random Oracle Model: A Twenty-Year Retrospective|journal=Another Look|date=2015|url=http://cacr.uwaterloo.ca/~ajmeneze/anotherlook/papers/rom.pdf|accessdate=6 March 2015}}&lt;/ref&gt;

In general, if a protocol is proven secure, attacks to that protocol must either be outside what was proven, or break one of the assumptions in the proof; for instance if the proof relies on the hardness of [[integer factorization]], to break this assumption one must discover a fast integer factorization algorithm. Instead, to break the random oracle assumption, one must discover some unknown and undesirable property of the actual hash function; for good hash functions where such properties are believed unlikely, the considered protocol can be considered secure.

== Random Oracle Hypothesis ==
Although the Baker–Gill–Solovay theorem&lt;ref name="BGS75"&gt;{{cite article| first1 = Theodore | last1 = Baker | first2 = John | last2 = Gill | first3 = Robert | last3 = Solovay | title = Relativizations of the P =? NP Question | year = 1975 | journal =  SIAM J. Comput.  |volume=4|issue=4| publisher = SIAM | pages = 431–442 | doi = 10.1137/0204037 }}&lt;/ref&gt; showed that there exists an oracle A such that P&lt;sup&gt;A&lt;/sup&gt; = NP&lt;sup&gt;A&lt;/sup&gt;, subsequent work by Bennett and Gill,&lt;ref name="BG81"&gt;{{cite article| title = Relative to a Random Oracle A, P != NP != co-NP with Probability 1 | first1 = Charles | last1 = Bennett | first2 = John | last2 = Gill | year = 1981 | publisher = SIAM | journal = SIAM J. Comput.|volume=10|issue=1 | pages = 96–113}}&lt;/ref&gt; showed that for a ''random oracle'' B (a function from {0,1}&lt;sup&gt;n&lt;/sup&gt; to {0,1} such that each input element maps to each of 0 or 1 with probability 1/2, independently of the mapping of all other inputs), P&lt;sup&gt;B&lt;/sup&gt; ⊊ NP&lt;sup&gt;B&lt;/sup&gt; with probability 1. Similar separations, as well as the fact that random oracles separate classes with probability 0 or 1 (as a consequence of the [[Kolmogorov's zero–one law]]), led to the creation of the '''Random Oracle Hypothesis''', that two "acceptable" complexity classes C&lt;sub&gt;1&lt;/sub&gt; and C&lt;sub&gt;2&lt;/sub&gt; are equal if and only if they are equal (with probability 1) under a random oracle (the acceptability of a complexity class is defined in BG81&lt;ref name="BG81" /&gt;). This hypothesis was later shown to be false, as the two acceptable complexity classes [[IP (complexity)|IP]] and [[PSPACE]] were shown to be equal&lt;ref&gt;{{cite article|first=Adi|last=Shamir|url=http://portal.acm.org/citation.cfm?doid=146585.146609|title= IP = PSPACE|journal=Journal of the ACM|volume=39|issue=4|pages=869–877|date=October 1992}}&lt;/ref&gt; despite IP&lt;sup&gt;A&lt;/sup&gt; ⊊ PSPACE&lt;sup&gt;A&lt;/sup&gt; for a random oracle A with probability 1.&lt;ref name="CCGHHRR"&gt;{{cite article|first1=Richard|last1= Chang|first2= Benny Chor|last2= Oded Goldreich|first3= Juris|last3= Hartmanis|first4= Johan|last4= Hastad|first5= Desh|last5= Ranjan|first6= Pankaj|last6= Rohatgi|title= The Random Oracle Hypothesis is False|journal=Journal of Computer and System Sciences|volume= 49|issue=1|pages=24–39|date=August 1994|issn=0022-0000|url= http://citeseer.ist.psu.edu/282397.html}}&lt;/ref&gt;

== Ideal cipher == &lt;!--- [[User:Strew]] checked for possible R to section but not sure on this from search, could mean other ciphers --&gt;

An ''ideal'' cipher is a [[random permutation]] oracle that is used to model an idealized block cipher.
A random permutation decrypts each ciphertext block into one and only one plaintext block and vice versa, so there is a [[one-to-one correspondence]].
Some cryptographic proofs make not only the "forward" permutation available to all players, but also the "reverse" permutation.

Recent works showed that an ideal cipher can be constructed from a random oracle using 10-round&lt;ref name="DKT16"&gt;{{cite conference | first1 = Dana  | last1 = Dachman-Soled | first2 = Jonathan  | last2 = Katz | first3 = Aishwarya  | last3 = Thiruvengadam | title = 10-Round Feistel is Indifferentiable from an Ideal Cipher | year = 2016 | booktitle = EUROCRYPT 2016  | publisher = Springer | pages = 649–678  | doi = 10.1007/978-3-662-49896-5_23 }}&lt;/ref&gt; or even 8-round&lt;ref name="C:DaiSte16"&gt;{{cite conference | first1=Yuanxi | last1=Dai | first2=John | last2=Steinberger | year=2016 | booktitle= CRYPTO 2016 | publisher = Springer | title=Indifferentiability of 8-Round Feistel Networks}}&lt;/ref&gt; [[Feistel network]]s.

== See also ==
* [[Sponge function]]
* [[Oracle machine]]
* [[Topics in cryptography]]

== References ==
{{Reflist|30em}}

{{Template:Cryptographic models}}

[[Category:Cryptography]]
[[Category:Cryptographic hash functions]]
[[Category:Theory of cryptography]]</text>
      <sha1>40m2p10yqet5dvbyv3dxmg6btzd5rln</sha1>
    </revision>
  </page>
  <page>
    <title>Regulus (geometry)</title>
    <ns>0</ns>
    <id>52079701</id>
    <revision>
      <id>787722053</id>
      <parentid>751210343</parentid>
      <timestamp>2017-06-27T04:36:00Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2351">[[Image:Ruled hyperboloid.jpg|thumb|right|300px|A string model of a portion of a regulus and its opposite to show the rules on a hyperboloid of one sheet]]
In three-dimensional space, a '''regulus''' ''R'' is a set of [[skew lines]], every point of which is on a [[transversal (geometry)|transversal]] which intersects an element of ''R'' only once, and such that every point on a transversal lies on a line of ''R'' 

The set of transversals of ''R'' forms an '''opposite regulus''' ''S''. In ℝ&lt;sup&gt;3&lt;/sup&gt; the union ''R'' ∪ ''S'' is the [[ruled surface]] of a [[hyperboloid of one sheet]].

Three skew lines determine a regulus:
:The locus of lines meeting three given skew lines is called a ''regulus''. [[Skew lines#Gallucci's theorem|Gallucci's theorem]] shows that the lines meeting the generators of the regulus (including the original three lines) form another "associated" regulus, such that every generator of either regulus meets every generator of the other. The two reguli are the two systems of generators of a ''ruled quadric''.&lt;ref&gt;[[H. S. M. Coxeter]] (1969) ''Introduction to Geometry'', page 259, [[John Wiley &amp; Sons]]&lt;/ref&gt;

According to [[Charlotte Scott]], "The regulus supplies extremely simple proofs of the properties of a conic...the theorems of Chasles, [[Brianchon's theorem|Brianchon]], and [[Pascal's theorem|Pascal]] ..."&lt;ref&gt;Charlotte Angas Scott (1905) [http://www.ams.org/journals/bull/1905-12-01/S0002-9904-1905-01279-9/S0002-9904-1905-01279-9.pdf The elementary treatment of the conics by means of the regulus], [[Bulletin of the American Mathematical Society]] 12(1): 1–7&lt;/ref&gt;

In a [[finite geometry]] PG(3, ''q''), a regulus has ''q'' + 1 lines. For example, in 1954 [[William Edge (mathematician)|William Edge]] described a pair of reguli of four lines each in PG(3,3).&lt;ref&gt;[[W. L. Edge]] (1954) "Geometry of three dimensions over GF(3)", [[Proceedings of the Royal Society]] A 222: 262–86 {{doi|10.1098/rspa.1954.0068}}&lt;/ref&gt;



==See also==
* [[Translation plane#Reguli and regular spreads]]
* [[Transversal (combinatorics)]]

==References==
{{Reflist}}
* [[Albrecht Beutelspacher]] &amp; Ute Rosenbaum (1998) ''Projective Geometry'', page 72, [[Cambridge University Press]]  {{ISBN|0-521-48277-1}}
* [[H. G. Forder]] (1950) ''Geometry'', page 118, Hutchinson's University Library.

[[Category:Geometry]]</text>
      <sha1>jt0nfrlt8l17zdhytp2hv6c0qwgl1fr</sha1>
    </revision>
  </page>
  <page>
    <title>Robin Wilson (mathematician)</title>
    <ns>0</ns>
    <id>2715277</id>
    <revision>
      <id>844800553</id>
      <parentid>839670243</parentid>
      <timestamp>2018-06-07T07:37:02Z</timestamp>
      <contributor>
        <username>Philip Cross</username>
        <id>124152</id>
      </contributor>
      <comment>ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9872">{{about|the mathematician|the musician|Robin Wilson (musician)}}
{{Infobox scientist
|name              = &lt;small&gt;[[The Honourable]]&lt;/small&gt;&lt;br /&gt; Robin Wilson
|image             = Robin_Wilson_outside_Gresham_College_-_23jun11.JPG
|image_size       = 
|caption           = 
|birth_date        = {{birth date and age|1943|12|5|df=y}}
|birth_place       = [[United Kingdom]]
&lt;!-- |parents           = [[Harold Wilson]]&lt;br/&gt;[[Mary Wilson, Baroness Wilson of Rievaulx|Mary Wilson]] --&gt;
|citizenship       = [[United Kingdom]]
|nationality       = 
|ethnicity         = 
|field             = [[Graph Theory]]
|work_institutions = [[Open University]], &lt;br/&gt; [[Pembroke College, Oxford]],  [[Gresham College]]
|alma_mater        = [[University College School]], Hampstead, London&lt;br/&gt;[[University of Oxford]] ([[Balliol College, Oxford|Balliol College]])&lt;br/&gt;[[University of Pennsylvania]]
|doctoral_advisor  = [[Nesmith Ankeny]]
|known_for         = 
|author_abbrev_bot = 
|author_abbrev_zoo = 
|influences        = 
|influenced        = 
|prizes            = 
|footnotes         = 
|signature         = 
}}

'''Robin James Wilson''' (born 5 December 1943) is an emeritus  professor in the Department of [[Mathematics]] at the [[Open University]], having previously been Head of the Pure Mathematics Department and Dean of the Faculty.&lt;ref name=ou-maths&gt;{{cite web |url=http://www.mathematics.open.ac.uk/People/r.j.wilson |title=Prof Robin Wilson |publisher=[[Open University]], Department of Mathematics And Statistics | location=UK | accessdate=8 December 2013}}&lt;/ref&gt; He was a Stipendiary Lecturer at [[Pembroke College, Oxford]]&lt;ref&gt;[http://www.pmb.ox.ac.uk/Fellows_Staff/Fellow_and_Staff_Profiles.php?profile=259 Pembroke College website]&lt;/ref&gt; and, {{As of|2006|lc=on}}, [[Gresham Professor of Geometry|Professor of Geometry]] at [[Gresham College]], London, where he has also been a [[Visiting Gresham Professor|visiting professor]].&lt;ref name=gresham-webpage&gt;{{cite web |url=http://www.gresham.ac.uk/professors-and-speakers/professor-robin-wilson |title=Professor Robin Wilson |publisher=Gresham College |accessdate=8 December 2013}}&lt;/ref&gt;  On occasion, he guest-teaches at [[Colorado College]] in the United States.&lt;ref&gt;{{cite web|url=https://www.coloradocollege.edu/dotAsset/2a480cfb-31ec-4511-a641-1ab48d054075.pdf|title=Block Visitors|journal=Countable Bits|volume=8|issue=1|date=May 2015|publisher=The Colorado College Department of Mathematics and Computer Science|accessdate=23 June 2017}}&lt;/ref&gt;

From January 1999 to September 2003, Robin Wilson was editor-in-chief of the [[European Mathematical Society]] Newsletter.&lt;ref&gt;''European Mathematical Society Newsletter'', No 49, September 2003, {{ISSN|1027-488X}}&lt;/ref&gt;

Robin Wilson is the son of [[Harold Wilson]], former [[Prime Minister]] of the [[United Kingdom]], and his wife [[Mary Wilson, Baroness Wilson of Rievaulx|Mary Wilson]]. He is married; the couple have two daughters.&lt;ref name="guardian-20081007"&gt;{{cite news |url=https://www.theguardian.com/education/2008/oct/07/academicexperts.maths |title=Serious showman |author=[[John Crace (writer)|John Crace]] |newspaper=[[The Guardian]] |date=7 October 2008 |accessdate=8 December 2013}}&lt;/ref&gt;

==Education==
{{prose|date=June 2018}}
* [[University College School]] in [[Hampstead]], North London.
* [[Bachelor of Arts|BA]] First Class Honours in Mathematics from [[Balliol College]], [[Oxford University|Oxford]]
* [[Master of Arts|MA]] from the [[University of Pennsylvania]]
* [[Doctor of Philosophy|PhD]] from the [[University of Pennsylvania]] (1965–1968)
* [[Bachelor of Arts|BA]] First Class Honours in Humanities with Music from the [[Open University]].

==Mathematics==
Wilson's academic interests lie in [[graph theory]], particularly in [[graph coloring|colouring]] problems, e.g. the [[four color theorem|four colour problem]], and algebraic properties of graphs.

He also researches the [[history of mathematics]], particularly British mathematics and mathematics in the 17th century and the period 1860 to 1940 and the history of [[graph theory]] and [[combinatorics]].

In 1974, he won the [[Lester R. Ford Award]] from the [[Mathematical Association of America]] for his expository article ''An introduction to matroid theory''.&lt;ref&gt;[http://www.maa.org/programs/maa-awards/writing-awards/paul-halmos-lester-ford-awards Paul R. Halmos – Lester R. Ford Awards, Mathematical Association of America]&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Wilson, R. J.|title=An introduction to matroid theory|journal=[[Amer. Math. Monthly]]|volume=80|year=1973|pages=500–525|url=http://www.maa.org/programs/maa-awards/writing-awards/an-introduction-to-matroid-theory|doi=10.2307/2319608}}&lt;/ref&gt;

Due to his collaboration on a 1977 paper&lt;ref&gt;{{cite journal | doi = 10.1016/0095-8956(77)90039-9 | volume=23 | title=On the chromatic index of almost all graphs | journal=[[Journal of Combinatorial Theory, Series B]] | pages=255–257}}&lt;/ref&gt; with the [[Hungarian people|Hungarian]] mathematician [[Paul Erdős]], Wilson has an [[Erdős number]] of 1.

In July 2008, he published a study of the mathematical work of [[Lewis Carroll]], the creator of ''[[Alice's Adventures in Wonderland]]'' and ''[[Through the Looking-Glass]]'' — ''Lewis Carroll in Numberland: His Fantastical Mathematical Logical Life'' (Allen Lane, 2008. {{isbn|978-0-7139-9757-6}}).

He is President of the [[British Society for the History of Mathematics]].&lt;ref name=ou-webpage&gt;{{cite web |url=http://users.mct.open.ac.uk/rjw22/ |title=Professor Robin Wilson |publisher=Open University |accessdate=8 December 2013}}&lt;/ref&gt;

==Other interests==
He has strong interests in music, including the operas of [[Gilbert and Sullivan]], and is the co-author (with [[Frederic Lloyd]]) of ''Gilbert and Sullivan: The Official D'Oyly Carte Picture History''.&lt;ref&gt;Knopf, 1984. {{isbn|978-0-394-54113-6}}&lt;/ref&gt; In 2007, he was a guest on ''[[Private Passions]]'', the biographical music discussion programme on [[BBC Radio 3]].&lt;ref&gt;[http://www.bbc.co.uk/radio3/privatepassions/ BBC Radio 3]&lt;/ref&gt;

==Other publications==
Wilson has written or edited about thirty books, including popular books on [[sudoku]] and the [[Four Color Theorem]]:

*''[[The Turing Guide]]'' (with [[Jack Copeland]], [[Jonathan Bowen]], Mark Sprevak, et al.), [[Oxford University Press]], 2017: {{isbn|978-0198747826}} (hardcover), {{isbn|978-0198747833}} (paperback)&lt;ref&gt;{{cite article| authorlink=W. Andrew Robinson | last=Robinson | first=Andrew | url=https://www.newscientist.com/article/mg23331072-700-the-turing-guide-last-words-on-an-enigmatic-codebreaker/ | title=The Turing Guide: Last words on an enigmatic codebreaker? | journal=[[New Scientist]] | date=4 January 2017 }}&lt;/ref&gt;
*''Combinatorics: Ancient &amp; Modern'' (with John Watkins), Oxford University Press, 2013: {{isbn|0-19-965659-2}} 
*''The Great Mathematicians'' (with [[Raymond Flood (mathematician)|Raymond Flood]]), Arcturus Publishing Ltd, 2011: {{isbn|1-84837-902-1}}
*''Hidden Word Sudoku'', Infinite Ideas Limited 2005: {{isbn|1-904902-74-X}}
*''How to Solve Sudoku'', Infinite Ideas Limited 2005: {{isbn|1-904902-62-6}}
*''Sherlock Holmes in Babylon and Other Tales of Mathematical History'' (co-edited with Marlow Anderson and [[Victor J. Katz]]), The Mathematical Association of America, 2004: {{isbn|0-88385-546-1}}
*''Mathematics and Music: From Pythagoras to Fractals'' (co-edited with John Fauvel &amp; [[Raymond Flood (mathematician)|Raymond Flood]]), Oxford University Press, 2003: {{isbn|0-19-851187-6}}
*''Four Colours Suffice: How the Map Problem Was Solved'', Allen Lane (Penguin), 2002: {{isbn|0-7139-9670-6}}
*''Stamping through Mathematics'', Springer, 2001: {{isbn|0-387-98949-8}} 
*''Oxford Figures: 800 Years of the Mathematical Sciences'' (with John Fauvel &amp; [[Raymond Flood (mathematician)|Raymond Flood]]), Oxford: Clarendon Press, 2000: {{isbn|0-19-852309-2}} 
*''Graphs and Applications: An Introductory Approach'' (with Joan Aldous), Springer, 2000: {{isbn|1-85233-259-X}} 
*''Mathematical Conversations: Selections from the Mathematical Intelligencer'' (with J. Gray), Springer, 2000: {{isbn|0-387-98686-3}}
*''An Atlas of Graphs'' (with Ronald Read), Oxford: Clarendon Press, 1998: {{isbn|0-19-853289-X}} (paperback edition, 2002: {{isbn|0-19-852650-4}})
*''Graph Theory 1736-1936'' (with [[Norman L. Biggs]] and Keith Lloyd), Oxford: Clarendon Press, 1976: {{isbn|0-19-853901-0}}

* ''Combinatorics: A Very Short Introduction,'' Oxford University Press, 2016: {{ISBN|978-0-19-872349-3}}
==References==
{{reflist}}

==External links==
*[http://users.mct.open.ac.uk/rjw22/ Robin Wilson's Page at the Open University]
*[http://www.mathematics.open.ac.uk/People/r.j.wilson Robin Wilson's entry in the Faculty of Mathematics and Computing at the Open University]
*[http://www.gresham.ac.uk/audio_video.asp?pageid=108&amp;frmProfessor=10 Lectures by Robin Wilson] at Gresham College
*[http://genealogy.math.ndsu.nodak.edu/html/id.phtml?id=36152 Robin Wilson's entry at the Mathematics Genealogy Project]
*{{worldcat id|name=Robin Wilson|id=lccn-n79-100488}}
*{{IMDb name|5983237|Robin Wilson}}

{{Harold Wilson}}
{{Authority control}}

{{DEFAULTSORT:Wilson, Robin}}
[[Category:1943 births]]
[[Category:Living people]]
[[Category:British people of English descent]]
[[Category:People educated at University College School]]
[[Category:Alumni of Balliol College, Oxford]]
[[Category:Alumni of the Open University]]
[[Category:University of Pennsylvania alumni]]
[[Category:Fellows of Keble College, Oxford]]
[[Category:Professors of Gresham College]]
[[Category:Historians of mathematics]]
[[Category:20th-century British mathematicians]]
[[Category:21st-century British mathematicians]]
[[Category:Graph theorists]]
[[Category:Eldest sons of barons]]
[[Category:Children of Prime Ministers of the United Kingdom]]
[[Category:Harold Wilson]]</text>
      <sha1>rxn58trk2m17236j8858jqj774ah91x</sha1>
    </revision>
  </page>
  <page>
    <title>SLAM project</title>
    <ns>0</ns>
    <id>2285574</id>
    <revision>
      <id>785710031</id>
      <parentid>671521823</parentid>
      <timestamp>2017-06-15T00:08:47Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* top */HTTP&amp;rarr;HTTPS for [[Ars Technica]], per [[Wikipedia:Bots/Requests for approval/Bender the Bot 8|BRFA 8]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2012">The '''SLAM project''', which was started by [[Microsoft Research]], aimed at verifying some software safety properties using [[model checking]] techniques. It is implemented in OCaml, and has been used to find many bugs in Windows Device Drivers. It is distributed as part of the Microsoft [[Windows Driver Foundation]] development kit as the Static Driver Verifier (SDV).

SLAM uses a technique called counterexample-guided abstraction refinement, which uses progressively better models of the program under test.

"SLAM originally was an acronym but we found it too cumbersome to explain. We now prefer to think of 'slamming' the bugs in a program."&lt;ref &gt;Ball, Thomas; Cook, Byron; Levin, Vladimir; and Rajamani, Sriram K.; [http://research.microsoft.com/pubs/70038/tr-2004-08.pdf ''SLAM and Static Driver Verifier: Technology Transfer of Formal Methods inside Microsoft'']; Lecture Notes in Computer Science (LNCS), Vol. 2999: Boiten, Eerke A.; Derrick, John; and Smith, Graeme; eds.; ''Fourth International Conference on Integrated Formal Methods (IFM 2004), 4–7 April 2004, Canterbury, GB'', Springer, Berlin/Heidelberg, pp. 1–20&lt;/ref&gt; It probably stood for "Software, Languages, Analysis, and Modeling."&lt;ref&gt;Microsoft Windows Hardware Developer Central; [http://www.microsoft.com/whdc/resources/support/glossary.mspx ''Glossary of Acronyms for PC and Server Technologies'']; 2007 February 26&lt;/ref&gt; Note that Microsoft has since re-used SLAM to stand for "Social Location Annotation Mobile".&lt;ref&gt;Mondok, Matt; [https://arstechnica.com/microsoft/news/2006/10/5573.ars ''Microsoft's Slam: stay in touch with, stalk your friends'']; Ars Technica, 2006 October 10&lt;/ref&gt;

==See also==
* [[Abstraction model checking]]
* the [[BLAST model checker]], a model checker similar to SLAM that uses "lazy abstraction"

==References==
&lt;references/&gt;

==External links==
*[http://research.microsoft.com/slam SLAM website]

{{Microsoft Research}}

[[Category:Formal methods]]
[[Category:OCaml software]]

{{compu-stub}}</text>
      <sha1>orfi9roi053fbg5agl3q76v1jlurw4e</sha1>
    </revision>
  </page>
  <page>
    <title>Sacred geometry</title>
    <ns>0</ns>
    <id>46754</id>
    <revision>
      <id>869885858</id>
      <parentid>864630159</parentid>
      <timestamp>2018-11-21T00:45:02Z</timestamp>
      <contributor>
        <username>Rachocki</username>
        <id>34677517</id>
      </contributor>
      <comment>Added subsection to "In Art and Architecture" describing divine architecture in Medieval and Renaissance Europe.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11661">{{Refimprove|date=September 2009}}
[[File:Kepler-solar-system-2.png|thumb|upright|Inner section of Kepler's [[Platonic solid]] model of planetary spacing in the [[Solar System]] from ''[[Mysterium Cosmographicum]]'' (1596)]]

'''Sacred geometry''' ascribes symbolic and [[Sacred|sacred meanings]] to certain geometric shapes and certain geometric [[Proportion (architecture)|proportions]].&lt;ref&gt;[http://www.dartmouth.edu/~matc/math5.geometry/unit5/unit5.html dartmouth.edu: Paul Calter, ''Polygons, Tilings, &amp; Sacred Geometry'']&lt;/ref&gt; It is associated with the belief that a god is the geometer of the world. The geometry used in the design and construction of [[sacred architecture|religious structures]] such as [[Church (building)|churches]], [[temple]]s, [[mosque]]s, religious [[monuments]], [[altar]]s, and [[church tabernacle|tabernacles]] has sometimes been considered sacred. The concept applies also to sacred spaces such as [[temenos|temenoi]], [[sacred grove]]s, [[village green]]s and [[holy well]]s, and the creation of [[sacred art|religious art]].

==As worldview and cosmology==
{{further|Mathematics and art}}

The belief that a god created the universe according to a geometric plan has ancient origins. [[Plutarch]] attributed the belief to [[Plato]], writing that "Plato said god geometrizes continually" (''Convivialium disputationum'', liber 8,2). In modern times, the mathematician [[Carl Friedrich Gauss]] adapted this quote, saying "God arithmetizes".&lt;ref&gt;Cathérine Goldstein, Norbert Schappacher, Joachim Schwermer, ''The shaping of arithmetic'',  [https://books.google.com/books?id=IUFTcOsMTysC&amp;pg=PA235 p. 235].&lt;/ref&gt;

As late as [[Johannes Kepler]] (1571–1630), a belief in the geometric underpinnings of the cosmos persisted among some scientists.&lt;ref name=Calter&gt;{{cite web |last1=Calter |first1=Paul |title=Celestial Themes in Art &amp; Architecture |url=https://www.dartmouth.edu/~matc/math5.geometry/unit10/unit10.html |publisher=[[Dartmouth College]] |accessdate=5 September 2015 |date=1998}}&lt;/ref&gt;

==Natural forms==
{{further|Patterns in nature}}

[[File:NautilusCutawayLogarithmicSpiral.jpg|thumb|left|upright|''[[Nautilus]]'' shell's [[logarithm]]ic growth spiral]]

According to [[Stephen Skinner (author)|Stephen Skinner]], the study of sacred geometry has its roots in the study of nature, and the [[Fibonacci number|mathematical principles]] at work therein.&lt;ref&gt;{{cite book |last=Skinner |first=Stephen |title=Sacred Geometry: Deciphering the Code |publisher=Sterling |date=2009 |isbn=978-1-4027-6582-7}}&lt;/ref&gt; Many [[patterns in nature|forms observed in nature]] can be related to geometry; for example, the [[chambered nautilus]] grows at a constant rate and so its shell forms a [[logarithmic spiral]] to accommodate that growth without changing shape. Also, [[honeybee]]s construct hexagonal cells to hold their honey.  These and other correspondences are sometimes interpreted in terms of sacred geometry and considered to be further proof of the natural significance of geometric forms.

==Art and architecture==
{{further|Mathematics and architecture|Mathematics and art|Islamic geometric patterns}}

Geometric ratios, and geometric figures were often employed in the designs of ancient [[Ancient Egyptian architecture|Egyptian]], ancient Indian, [[Architecture of ancient Greece|Greek]] and [[Roman architecture|Roman]] architecture. Medieval European cathedrals also incorporated symbolic geometry. Indian and Himalayan spiritual communities often constructed temples and [[fortification]]s on design plans of [[mandala]] and [[yantra]].

Many of the sacred geometry principles of the human body and of ancient architecture were compiled into the [[Vitruvian Man]] drawing by [[Leonardo da Vinci]]. The latter drawing was itself based on the much older writings of the Roman architect [[Vitruvius]].

[[Islamic geometric patterns]] are well known too, which are used in the Qu'ran, Mosques and even in the caligraphies of personal names.

===In Hinduism===

[[File:Mandala.jpg|thumb|right|A [[Hindu]] [[Mandala|Maṇḍala]]]]

The [[Āgama (Hinduism)|Agamas]] are a collection of Sanskrit,&lt;ref name=Grimes&gt;Grimes, John A. (1996). ''A Concise Dictionary of Indian Philosophy: Sanskrit Terms Defined in English''. State University of New York Press. {{ISBN|9780791430682}}. LCCN 96012383. [https://books.google.com/books?id=eP5p0ev3nJEC]&lt;/ref&gt; Tamil, and [[Grantha script|Grantha]]&lt;ref name=NagalingamCh1&gt;Nagalingam, Pathmarajah (2009). ''The Religion of the Agamas''. Siddhanta Publications. [http://www.siddha.com.my/forum/religionoftheagamas/chapter1.html]&lt;/ref&gt; scriptures chiefly constituting the methods of temple construction and creation of idols, worship means of deities, philosophical doctrines, meditative practices, attainment of sixfold desires, and four kinds of yoga.&lt;ref name=Grimes/&gt;

Elaborate rules are laid out in the Agamas for Shilpa (the art of [[sculpture]]) describing the quality requirements of such matters as the places where temples are to be built, the kinds of image to be installed, the materials from which they are to be made, their dimensions, proportions, air circulation, and lighting in the temple complex. The [[Manasara]] and Silpasara are works that deal with these rules. The rituals of daily worship at the temple also follow rules laid out in the Agamas.

=== In European Religious Architecture ===
The construction of Medieval European cathedrals was often based on geometries intended to make the viewer see the world through mathematics, and through this understanding, gain a better understanding of the divine.&lt;ref&gt;{{Citation|last=Petersen|first=Toni|title=A(rt and) A(rchitecture) T(hesaurus)|date=2003|url=http://dx.doi.org/10.1093/gao/9781884446054.article.t000037|work=Oxford Art Online|publisher=Oxford University Press|access-date=2018-11-21}}&lt;/ref&gt; These churches frequently featured a [[Latin Cross]] floor-plan.&lt;ref name=":0"&gt;{{Citation|last=CUMMINGS|first=L.A.|title=A RECURRING GEOMETRICAL PATTERN IN THE EARLY RENAISSANCE IMAGINATION|date=1986|url=http://dx.doi.org/10.1016/b978-0-08-033986-3.50067-7|work=Symmetry|pages=981–997|publisher=Elsevier|isbn=9780080339863|access-date=2018-11-21}}&lt;/ref&gt; 

At the beginning of the Renaissance in Europe, views shifted to favor simple and regular geometries. The circle in particular became a central and symbolic shape for the base of buildings, as it represented the perfection of nature and the centrality of man's place in the universe.&lt;ref name=":0" /&gt; The use of the circle and other simple and symmetrical geometric shapes was solidified as a staple of Renaissance religious architecture in [[Leon Battista Alberti]]'s architectural treatise, which described the ideal church in terms of spiritual geometry.&lt;ref&gt;{{Cite book|url=http://worldcat.org/oclc/981109542|title=Architectural principles in the age of humanism.|last=Rudolf.|first=Wittkower,|date=1998|publisher=Academy Editions|isbn=0471977632|oclc=981109542}}&lt;/ref&gt;

==Unanchored geometry==
[[Stephen Skinner (author)|Stephen Skinner]] discusses the tendency of some writers to place a geometric diagram over virtually any image of a natural object or human created structure, find some lines intersecting the image and declare it based on sacred geometry. If the geometric diagram does not intersect major physical points in the image, the result is what Skinner calls "unanchored geometry".&lt;ref&gt;[https://books.google.com/books?id=CG0EeHGl_dQC&amp;pg=PA91 Stephen Skinner, ''Sacred geometry: deciphering the code'', p91]&lt;/ref&gt;

==See also==
* [[Circle dance]]
* [[Harmony of the spheres]]
* [[Lu Ban]] and [[Feng shui]]
* [[Magic circle]]
* [[Shield of the Trinity]]

==References==
{{reflist|30em}}

==Further reading==
* Bain, George. ''Celtic Art: The Methods of Construction''. Dover, 1973. {{ISBN|0-486-22923-8}}.
* {{cite book|last=Bromwell|first=Henry P. H.|author-link=Henry P. H. Bromwell|editor1-first=Kevin|editor1-last=Townley|title=''Restorations of Masonic Geometry and Symbolry: Being a Dissertation on the Lost Knowledges of the Lodge''|url=http://www.kevintownley.com/products/books/restoration-of-masonic-geometry-and-symbolry/|accessdate=Jan 7, 2012|date=2010|publisher=Lovers of the Craft|isbn=0-9713441-5-9|deadurl=yes|archiveurl=https://web.archive.org/web/20120203233504/http://www.kevintownley.com/products/books/restoration-of-masonic-geometry-and-symbolry/|archivedate=2012-02-03|df=}}
* Bamford, Christopher, ''Homage to Pythagoras: Rediscovering Sacred Science'', Lindisfarne Press, 1994, {{ISBN|0-940262-63-0}}
* {{cite book |author=Critchlow, Keith |title=Order In Space: A Design Source Book|location=New York|publisher=Viking|date=1970|authorlink=Keith Critchlow}}
* {{cite book |author=Critchlow, Keith |title=Islamic Patterns: An Analytical and Cosmological Approach |publisher=[[Schocken Books]] |date=1976 |isbn=0-8052-3627-9}}* [[Robert Lawlor|Lawlor, Robert]]. ''Sacred Geometry: Philosophy and practice (Art and Imagination)''. Thames &amp; Hudson, 1989 (1st edition 1979, 1980, or 1982). {{ISBN|0-500-81030-3}}.
* {{cite book |author=Iamblichus |author2=Robin Waterfield |author3=Keith Critchlow |author4=Translated by Robin Waterfield |title=The Theology of Arithmetic: On the Mystical, Mathematical and Cosmological Symbolism of the First Ten Numbers |publisher=[[Phanes Press]]|date=1988|isbn=0-933999-72-0|authorlink=Iamblichus}}
* Johnson, Anthony: ''Solving Stonehenge, the New Key to an Ancient Enigma''. Thames &amp; Hudson 2008 {{ISBN|978-0-500-05155-9}}
* {{cite book |author=Lesser, George |title=Gothic cathedrals and sacred geometry |location=London |publisher=A. Tiranti |date=1957–64}}
* Lippard, Lucy R. ''Overlay: Contemporary Art and the Art of Prehistory''. Pantheon Books  New York 1983 {{ISBN|0-394-51812-8}}
* Mann, A. T. ''Sacred Architecture'', Element Books, 1993, {{ISBN|1-84333-355-4}}.
* [[John Michell (writer)|Michell, John]]. ''City of Revelation''. Abacus, 1972. {{ISBN|0-349-12320-9}}.
* Schneider, Michael S. ''A Beginner's Guide to Constructing the Universe: Mathematical Archetypes of Nature, Art, and Science''. Harper, 1995. {{ISBN|0-06-092671-6}}
* {{cite book |author=Steiner, Rudolf |authorlink=Rudolf Steiner |author2=Creeger, Catherine |title=The Fourth Dimension : Sacred Geometry, Alchemy, and Mathematics |date=2001 |publisher=Anthroposophic Press|isbn=0-88010-472-4}}
* ''The Golden Mean'', [[Parabola (magazine)|Parabola magazine]], v.16, n.4 (1991)
* West, John Anthony, ''Inaugural Lines: Sacred geometry at St. John the Divine'', Parabola magazine, v.8, n.1, Spring 1983.

==External links==
&lt;!--======================== {{No more links}} ============================
    | PLEASE BE CAUTIOUS IN ADDING MORE LINKS TO THIS ARTICLE. Wikipedia  |
    | is not a collection of links nor should it be used for advertising. |
    |                                                                     |
    |           Excessive or inappropriate links WILL BE DELETED.         |
    | See [[Wikipedia:External links]] &amp; [[Wikipedia:Spam]] for details.  |
    |                                                                     |
======================={{No more links}}=============================--&gt;
{{commonscat|Sacred geometry}}
* {{dmoz|Society/Religion_and_Spirituality/Arts/Visual/Sacred_Geometry_and_Art/}}

{{Hidden messages}}
{{Mathematics and art}}

{{DEFAULTSORT:Sacred Geometry}}
[[Category:Astrological aspects]]
[[Category:Architecture]]
[[Category:Esoteric cosmology]]
[[Category:Geometry]]
[[Category:History of astrology]]
[[Category:Mathematics and mysticism]]
[[Category:Pythagorean philosophy]]
[[Category:Numerology]]
[[Category:Holiness]]</text>
      <sha1>8go6nbn4iq00bz9f19qx6nl0ggn14ss</sha1>
    </revision>
  </page>
  <page>
    <title>Segal space</title>
    <ns>0</ns>
    <id>29205627</id>
    <revision>
      <id>848346036</id>
      <parentid>610019953</parentid>
      <timestamp>2018-07-01T10:38:08Z</timestamp>
      <contributor>
        <username>Wikidsp</username>
        <id>5816792</id>
      </contributor>
      <comment>filling out the stub a bit.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1056">In mathematics, a '''Segal space''' is a [[simplicial space]] satisfying some [[pullback]] conditions, making it look like a [[Homotopy|homotopical]] version of a [[Category (mathematics)|category]]. More precisely, a [[simplicial set]], considered as a simplicial discrete space, satisfies the Segal conditions iff it is the [[Nerve (category theory)|nerve]] of a category. The condition for Segal spaces is a homotopical version of this. 

Complete Segal spaces were introduced by {{harvtxt|Rezk|2001}} as models for [[(infinity,1)-category|(∞,&amp;nbsp;1)-categories]].

==References==
*{{Citation | last1=Rezk | first1=Charles | title=A model for the homotopy theory of homotopy theory | doi=10.1090/S0002-9947-00-02653-2 | mr=1804411 | year=2001 | journal=[[Transactions of the American Mathematical Society]] | issn=0002-9947 | volume=353 | issue=3 | pages=973–1007}}

==External links==
*{{nlab|id=Segal+space|title=Segal space}}
*{{nlab|id=complete+Segal+space|title=Complete Segal space}}

[[Category:Category theory]]
[[Category:Simplicial sets]]</text>
      <sha1>315ibz292ocx21l4073kinzpdxurvmx</sha1>
    </revision>
  </page>
  <page>
    <title>Signal magnitude area</title>
    <ns>0</ns>
    <id>44107834</id>
    <revision>
      <id>752944820</id>
      <parentid>731468787</parentid>
      <timestamp>2016-12-04T07:59:32Z</timestamp>
      <contributor>
        <ip>122.108.141.214</ip>
      </contributor>
      <comment>/* Definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1661">{{Other uses|RMS (disambiguation){{!}}RMS}}
In [[mathematics]], the '''signal magnitude area''' (abbreviated '''SMA''' or '''sma''') is a [[statistics|statistical]] measure of the [[magnitude (mathematics)|magnitude]] of a varying quantity.

==Definition==
The SMA value of a set of values (or a [[continuous-time]] [[waveform]]) is the [[Normalization (statistics)|normalized]] [[integral]] of the original values.
&lt;ref&gt;{{cite web|title=Matlab compute Normalized Signal Magnitude area|url=https://stackoverflow.com/questions/19702753/matlab-compute-normalized-signal-magnitude-area}}&lt;/ref&gt;
&lt;ref&gt;{{cite web|title=Frequency domain approach for activity classification using accelerometer, section 3B. ''Detection Algorithm''|url=http://ieeexplore.ieee.org/xpls/icp.jsp?arnumber=4649357}}&lt;/ref&gt;

In the case of a set of ''n'' values &lt;math&gt;\{x_1,x_2,\dots,x_n\}&lt;/math&gt; matching a time length ''T'', the SMA

:&lt;math&gt;
x_\text{sma} = \sum_{i=1}^n x_i
&lt;/math&gt;

In the continuous domain, we have for example, with a 3-axis signal with an offset correction ''a'' for each axis, the following equation:&lt;ref&gt;{{Cite web|url = http://www.rehab.research.va.gov/jour/2013/509/jrrd-2012-12-0233.html|title = Classifying prosthetic use via accelerometry in persons with transtibial amputations|date = 2013|accessdate = 2014-10-14|website = [[Journal of Rehabilitation Research &amp; Development]]|publisher = U.S. Department of Veteran Affairs|last = |first = |last2 = |first2 = }}&lt;/ref&gt;

:&lt;math&gt;
f_\text{sma}= {1 \over T} \int_0^T |x(t)-a_x|+|y(t)-a_y|+|z(t)-a_z| \, dt
&lt;/math&gt;

==See also==
* [[Root mean square]]

==References==
{{Reflist}}

[[Category:Computational statistics]]</text>
      <sha1>ivng5ps30ydogopobm9j32v89rye2cp</sha1>
    </revision>
  </page>
  <page>
    <title>Small-bias sample space</title>
    <ns>0</ns>
    <id>12024508</id>
    <revision>
      <id>836035402</id>
      <parentid>836035334</parentid>
      <timestamp>2018-04-12T08:42:47Z</timestamp>
      <contributor>
        <ip>165.230.225.45</ip>
      </contributor>
      <comment>/* Explicit constructions */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14886">In [[theoretical computer science]], a '''small-bias sample space''' (also known as '''&lt;math&gt;\epsilon&lt;/math&gt;-biased sample space''',  '''&lt;math&gt;\epsilon&lt;/math&gt;-biased generator''', or '''small-bias probability space''') is a [[probability distribution]] that fools [[parity function]]s.
In other words, no parity function can distinguish between a small-bias sample space and the uniform distribution with high probability, and hence, small-bias sample spaces naturally give rise to [[pseudorandom generator]]s for parity functions.

The main useful property of small-bias sample spaces is that they need far fewer truly random bits than the uniform distribution to fool parities.  Efficient constructions of small-bias sample spaces have found many applications in computer science, some of which are [[derandomization]], [[error-correcting code]]s, and [[PCP theorem|probabilistically checkable proofs]].
The connection with [[error-correcting code]]s is in fact very strong since &lt;math&gt;\epsilon&lt;/math&gt;-biased sample spaces are ''equivalent'' to '''&lt;math&gt;\epsilon&lt;/math&gt;-balanced error-correcting codes'''.

==Definition==

===Bias===
Let &lt;math&gt;X&lt;/math&gt; be a [[probability distribution]] over &lt;math&gt;\{0,1\}^n&lt;/math&gt;.
The ''bias'' of &lt;math&gt;X&lt;/math&gt; with respect to a set of indices &lt;math&gt;I \subseteq \{1,\dots,n\}&lt;/math&gt; is defined as&lt;ref&gt;cf., e.g., {{harvtxt|Goldreich|2001}}&lt;/ref&gt;
:&lt;math&gt;
\text{bias}_I(X)
=
\left|
\Pr_{x\sim X} \left(\sum_{i\in I} x_i = 0\right)
-
\Pr_{x\sim X} \left(\sum_{i\in I} x_i = 1\right)
\right|
=
\left|
2 \cdot \Pr_{x\sim X} \left(\sum_{i\in I} x_i = 0\right)
-1
\right|
\,,&lt;/math&gt;
where the sum is taken over &lt;math&gt;\mathbb F_2&lt;/math&gt;, the [[finite field]] with two elements. In other words, the sum &lt;math&gt;\sum_{i\in I} x_i&lt;/math&gt; equals &lt;math&gt;0&lt;/math&gt; if the number of ones in the sample &lt;math&gt;x\in\{0,1\}^n&lt;/math&gt; at the positions defined by &lt;math&gt;I&lt;/math&gt; is even, and otherwise, the sum equals &lt;math&gt;1&lt;/math&gt;.
For &lt;math&gt;I=\emptyset&lt;/math&gt;, the empty sum is defined to be zero, and hence &lt;math&gt;\text{bias}_{\emptyset} (X) = 1&lt;/math&gt;.

=== ϵ-biased sample space ===
A probability distribution &lt;math&gt;X&lt;/math&gt; over &lt;math&gt;\{0,1\}^n&lt;/math&gt; is called an ''&lt;math&gt;\epsilon&lt;/math&gt;-biased sample space'' if
&lt;math&gt;
\text{bias}_I(X) \leq \epsilon
&lt;/math&gt;
holds for all non-empty subsets &lt;math&gt;I \subseteq \{1,2,\ldots,n\}&lt;/math&gt;.

=== ϵ-biased set ===
An &lt;math&gt;\epsilon&lt;/math&gt;-biased sample space &lt;math&gt;X&lt;/math&gt; that is generated by picking a uniform element from a [[multiset]] &lt;math&gt;X\subseteq \{0,1\}^n&lt;/math&gt; is called ''&lt;math&gt;\epsilon&lt;/math&gt;-biased set''.
The ''size'' &lt;math&gt;s&lt;/math&gt; of an &lt;math&gt;\epsilon&lt;/math&gt;-biased set &lt;math&gt;X&lt;/math&gt; is the size of the multiset that generates the sample space.

=== ϵ-biased generator ===
An &lt;math&gt;\epsilon&lt;/math&gt;-biased generator &lt;math&gt;G:\{0,1\}^\ell \to \{0,1\}^n&lt;/math&gt; is a function that maps strings of length &lt;math&gt;\ell&lt;/math&gt; to strings of length &lt;math&gt;n&lt;/math&gt; such that the multiset &lt;math&gt;X_G=\{G(y) \;\vert\; y\in\{0,1\}^\ell \}&lt;/math&gt; is an &lt;math&gt;\epsilon&lt;/math&gt;-biased set. The ''seed length'' of the generator is the number &lt;math&gt;\ell&lt;/math&gt; and is related to the size of the &lt;math&gt;\epsilon&lt;/math&gt;-biased set &lt;math&gt;X_G&lt;/math&gt; via the equation &lt;math&gt;s=2^\ell&lt;/math&gt;.

== Connection with epsilon-balanced error-correcting codes ==
There is a close connection between &lt;math&gt;\epsilon&lt;/math&gt;-biased sets and ''&lt;math&gt;\epsilon&lt;/math&gt;-balanced'' [[linear code|linear error-correcting codes]].
A linear code &lt;math&gt;C:\{0,1\}^n\to\{0,1\}^s&lt;/math&gt; of [[Block code#The message length k|message length]] &lt;math&gt;n&lt;/math&gt; and [[Block code#The block length n|block length]] &lt;math&gt;s&lt;/math&gt; is
''&lt;math&gt;\epsilon&lt;/math&gt;-balanced'' if the [[Hamming weight]] of every nonzero codeword &lt;math&gt;C(x)&lt;/math&gt; is between &lt;math&gt;(\frac{1}{2}-\epsilon)s&lt;/math&gt; and &lt;math&gt;(\frac{1}{2}+\epsilon)s&lt;/math&gt;.
Since &lt;math&gt;C&lt;/math&gt; is a linear code, its [[generator matrix]] is an &lt;math&gt;(n\times s)&lt;/math&gt;-matrix &lt;math&gt;A&lt;/math&gt; over &lt;math&gt;\mathbb F_2&lt;/math&gt; with &lt;math&gt;C(x)=x \cdot A&lt;/math&gt;.

Then it holds that a multiset &lt;math&gt;X\subset\{0,1\}^{n}&lt;/math&gt; is &lt;math&gt;\epsilon&lt;/math&gt;-biased if and only if the linear code &lt;math&gt;C_X&lt;/math&gt;, whose columns are exactly elements of &lt;math&gt;X&lt;/math&gt;, is &lt;math&gt;\epsilon&lt;/math&gt;-balanced.&lt;ref name="BA-TS-09"&gt;cf., e.g., p. 2 of {{harvtxt|Ben-Aroya|Ta-Shma|2009}}&lt;/ref&gt;

== Constructions of small epsilon-biased sets ==
Usually the goal is to find &lt;math&gt;\epsilon&lt;/math&gt;-biased sets that have a small size &lt;math&gt;s&lt;/math&gt; relative to the parameters &lt;math&gt;n&lt;/math&gt; and &lt;math&gt;\epsilon&lt;/math&gt;.
This is because a smaller size &lt;math&gt;s&lt;/math&gt; means that the amount of randomness needed to pick a random element from the set is smaller, and so the set can be used to fool parities using few random bits.

=== Theoretical bounds ===
The probabilistic method gives a non-explicit construction that achieves size &lt;math&gt;s=O(n/\epsilon^2)&lt;/math&gt;.&lt;ref name="BA-TS-09" /&gt;
The construction is non-explicit in the sense that finding the &lt;math&gt;\epsilon&lt;/math&gt;-biased set requires a lot of true randomness, which does not help towards the goal of reducing the overall randomness.
However, this non-explicit construction is useful because it shows that these efficient codes exist.
On the other hand, the best known lower bound for the size of &lt;math&gt;\epsilon&lt;/math&gt;-biased sets is &lt;math&gt;s=\Omega(n/ (\epsilon^2 \log (1/\epsilon))&lt;/math&gt;, that is, in order for a set to be &lt;math&gt;\epsilon&lt;/math&gt;-biased, it must be at least that big.&lt;ref name="BA-TS-09" /&gt;

=== Explicit constructions ===
There are many explicit, i.e., deterministic constructions of &lt;math&gt;\epsilon&lt;/math&gt;-biased sets with various parameter settings:
* {{harvtxt|Naor|Naor|1990}} achieve &lt;math&gt;\displaystyle s= \frac{n}{\text{poly}(\epsilon)}&lt;/math&gt;. The construction makes use of [[Justesen code]]s (which is a concatenation of [[Reed–Solomon code]]s with the [[Wozencraft ensemble]]) as well as [[expander walk sampling]].
* {{harvtxt|Alon|Goldreich|Håstad|Peralta|1992}} achieve &lt;math&gt;\displaystyle s= O\left(\frac{n}{\epsilon \log (n/\epsilon)}\right)^2&lt;/math&gt;. One of their constructions is the concatenation of [[Reed–Solomon code]]s with the [[Hadamard code]]; this concatenation turns out to be an &lt;math&gt;\epsilon&lt;/math&gt;-balanced code, which gives rise to an &lt;math&gt;\epsilon&lt;/math&gt;-biased sample space via the connection mentioned above.
* Concatenating [[Algebraic geometric code]]s with the [[Hadamard code]] gives an &lt;math&gt;\epsilon&lt;/math&gt;-balanced code with &lt;math&gt;\displaystyle s= O\left(\frac{n}{\epsilon^3 \log (1/\epsilon)}\right)&lt;/math&gt;.&lt;ref name="BA-TS-09" /&gt;
* {{harvtxt|Ben-Aroya|Ta-Shma|2009}} achieves &lt;math&gt;\displaystyle s= O\left(\frac{n}{\epsilon^2 \log (1/\epsilon)}\right)^{5/4}&lt;/math&gt;.
* {{harvtxt|Ta-Shma|2017}} achieves &lt;math&gt;\displaystyle s= O\left(\frac{n}{\epsilon^{2+o(1)}}\right)&lt;/math&gt; which is almost optimal because of the lower bound.
These bounds are mutually incomparable. In particular, none of these constructions yields the smallest &lt;math&gt;\epsilon&lt;/math&gt;-biased sets for all settings of &lt;math&gt;\epsilon&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt;.

== Application: almost k-wise independence ==
An important application of small-bias sets lies in the construction of almost k-wise independent sample spaces.

=== k-wise independent spaces ===
A random variable &lt;math&gt;Y&lt;/math&gt; over &lt;math&gt;\{0,1\}^n&lt;/math&gt; is a ''k-wise independent space'' if, for all index sets &lt;math&gt;I\subseteq\{1,\dots,n\}&lt;/math&gt; of size &lt;math&gt;k&lt;/math&gt;, the [[marginal distribution]] &lt;math&gt;Y|_I&lt;/math&gt; is exactly equal to the [[Uniform distribution (discrete)|uniform distribution]] over &lt;math&gt;\{0,1\}^k&lt;/math&gt;.
That is, for all such &lt;math&gt;I&lt;/math&gt; and all strings &lt;math&gt;z\in\{0,1\}^k&lt;/math&gt;, the distribution &lt;math&gt;Y&lt;/math&gt; satisfies &lt;math&gt;\Pr_Y (Y|_I = z) = 2^{-k}&lt;/math&gt;.

==== Constructions and bounds ====
k-wise independent spaces are fairly well understood.
* A simple construction by {{harvtxt|Joffe|1974}} achieves size &lt;math&gt;n^k&lt;/math&gt;.
* {{harvtxt|Alon|Babai|Itai|1986}} construct a k-wise independent space whose size is &lt;math&gt;n^{k/2}&lt;/math&gt;.
* {{harvtxt|Chor|Goldreich|Håstad|Freidmann|1985}} prove that no k-wise independent space can be significantly smaller than &lt;math&gt;n^{k/2}&lt;/math&gt;.

==== Joffe's construction ====
{{harvtxt|Joffe|1974}} constructs a &lt;math&gt;k&lt;/math&gt;-wise independent space &lt;math&gt;Y&lt;/math&gt; over the [[finite field]] with some prime number &lt;math&gt;n&gt;k&lt;/math&gt; of elements, i.e., &lt;math&gt;Y&lt;/math&gt; is a distribution over &lt;math&gt;\mathbb F_n^n&lt;/math&gt;. The initial &lt;math&gt;k&lt;/math&gt; marginals of the distribution are drawn independently and uniformly at random:
:&lt;math&gt;(Y_0,\dots,Y_{k-1}) \sim\mathbb F_n^k&lt;/math&gt;.
For each &lt;math&gt;i&lt;/math&gt; with &lt;math&gt;k \leq i &lt; n&lt;/math&gt;, the marginal distribution of &lt;math&gt;Y_i&lt;/math&gt; is then defined as
:&lt;math&gt;Y_i=Y_0 + Y_1 \cdot i + Y_2 \cdot i^2 + \dots + Y_{k-1} \cdot i^{k-1}\,,&lt;/math&gt;
where the calculation is done in &lt;math&gt;\mathbb F_n&lt;/math&gt;.
{{harvtxt|Joffe|1974}} proves that the distribution &lt;math&gt;Y&lt;/math&gt; constructed in this way is &lt;math&gt;k&lt;/math&gt;-wise independent as a distribution over &lt;math&gt;\mathbb F_n^n&lt;/math&gt;.
The distribution &lt;math&gt;Y&lt;/math&gt; is uniform on its support, and hence, the support of &lt;math&gt;Y&lt;/math&gt; forms a ''&lt;math&gt;k&lt;/math&gt;-wise independent set''.
It contains all &lt;math&gt;n^k&lt;/math&gt; strings in &lt;math&gt;\mathbb F_n^k&lt;/math&gt; that have been extended to strings of length &lt;math&gt;n&lt;/math&gt; using the deterministic rule above.

=== Almost k-wise independent spaces ===
A random variable &lt;math&gt;Y&lt;/math&gt; over &lt;math&gt;\{0,1\}^n&lt;/math&gt; is a ''&lt;math&gt;\delta&lt;/math&gt;-almost k-wise independent space'' if, for all index sets &lt;math&gt;I\subseteq\{1,\dots,n\}&lt;/math&gt; of size &lt;math&gt;k&lt;/math&gt;, the restricted distribution &lt;math&gt;Y|_I&lt;/math&gt; and the uniform distribution &lt;math&gt;U_k&lt;/math&gt; on &lt;math&gt;\{0,1\}^k&lt;/math&gt; are &lt;math&gt;\delta&lt;/math&gt;-close in [[p-norm|1-norm]], i.e., &lt;math&gt;\Big\|Y|_I - U_k\Big\|_1 \leq \delta&lt;/math&gt;.

==== Constructions ====
{{harvtxt|Naor|Naor|1990}} give a general framework for combining small k-wise independent spaces with small &lt;math&gt;\epsilon&lt;/math&gt;-biased spaces to obtain &lt;math&gt;\delta&lt;/math&gt;-almost k-wise independent spaces of even smaller size.
In particular, let &lt;math&gt;G_1:\{0,1\}^h\to\{0,1\}^n&lt;/math&gt; be a [[linear mapping]] that generates a k-wise independent space and let &lt;math&gt;G_2:\{0,1\}^\ell \to \{0,1\}^h&lt;/math&gt; be a generator of an &lt;math&gt;\epsilon&lt;/math&gt;-biased set over &lt;math&gt;\{0,1\}^h&lt;/math&gt;.
That is, when given a uniformly random input, the output of &lt;math&gt;G_1&lt;/math&gt; is a k-wise independent space, and the output of &lt;math&gt;G_2&lt;/math&gt; is &lt;math&gt;\epsilon&lt;/math&gt;-biased.
Then &lt;math&gt;G : \{0,1\}^\ell \to \{0,1\}^n&lt;/math&gt; with &lt;math&gt;G(x) = G_1(G_2(x))&lt;/math&gt; is a generator of an &lt;math&gt;\delta&lt;/math&gt;-almost &lt;math&gt;k&lt;/math&gt;-wise independent space, where &lt;math&gt;\delta=2^{k/2} \epsilon&lt;/math&gt;.&lt;ref&gt;Section 4 in {{harvtxt|Naor|Naor|1990}}&lt;/ref&gt;

As mentioned above, {{harvtxt|Alon|Babai|Itai|1986}} construct a generator &lt;math&gt;G_1&lt;/math&gt; with &lt;math&gt;h=\tfrac{k}{2} \log n&lt;/math&gt;, and {{harvtxt|Naor|Naor|1990}} construct a generator &lt;math&gt;G_2&lt;/math&gt; with &lt;math&gt;\ell=\log s=\log h + O(\log(\epsilon^{-1}))&lt;/math&gt;.
Hence, the concatenation &lt;math&gt;G&lt;/math&gt; of &lt;math&gt;G_1&lt;/math&gt; and &lt;math&gt;G_2&lt;/math&gt; has seed length &lt;math&gt;\ell = \log k + \log \log n + O(\log(\epsilon^{-1}))&lt;/math&gt;.
In order for &lt;math&gt;G&lt;/math&gt; to yield a &lt;math&gt;\delta&lt;/math&gt;-almost k-wise independent space, we need to set &lt;math&gt;\epsilon = \delta 2^{-k/2}&lt;/math&gt;, which leads to a seed length of &lt;math&gt;\ell = \log \log n + O(k+\log(\delta^{-1}))&lt;/math&gt; and a sample space of total size &lt;math&gt;2^\ell \leq \log n \cdot \text{poly}(2^k \cdot\delta^{-1})&lt;/math&gt;.

== Notes ==
{{Reflist}}

== References ==

* {{Citation
 | last1 = Alon
 | first1 = Noga
 | last2 = Babai
 | first2 = László
 | last3 = Itai
 | first3 = Alon
 | title = A fast and simple randomized parallel algorithm for the maximal independent set problem
 | year = 1986
 | volume = 7
 | issue = 4
 | pages = 567–583
 | journal = Journal of Algorithms
 | accessdate = 
 | doi=10.1016/0196-6774(86)90019-2
 | url=http://www.tau.ac.il/~nogaa/PDFS/Publications2/A%20fast%20and%20simple%20randomized%20parallel%20algorithm%20for%20the%20maximal%20independent%20set%20problem.pdf
 | ref=harv}}
* {{Citation
 | last1 = Alon
 | first1 = Noga
 | last2 = Goldreich
 | first2 = Oded
 | last3 = Håstad
 | first3 = Johan
 | last4 = Peralta
 | first4 = René
 | title = Simple Constructions of Almost k-wise Independent Random Variables
 | year = 1992
 | volume = 3
 | issue = 3
 | pages = 289–304
 | journal = Random Structures &amp; Algorithms
 | accessdate = 
 | doi=10.1002/rsa.3240030308
 | url=http://tau.ac.il/~nogaa/PDFS/aghp4.pdf
 | ref=harv}}
* {{Citation
 |first1 = Avraham | last1= Ben-Aroya
 |first2 = Amnon | last2= Ta-Shma
 |ref=harv
 |title=Constructing Small-Bias Sets from Algebraic-Geometric Codes
 |year=2009
 |journal=Proceedings of the 50th Annual Symposium on Foundations of Computer Science, FOCS 2009
 |pages=191–197
 |doi=10.1109/FOCS.2009.44
 |url=http://www.wisdom.weizmann.ac.il/~benaroya/SmallBiasNew.pdf
 |isbn = 978-1-4244-5116-6
}}
* {{Citation
 |first1 = Benny | last1=Chor
 |first2 =Oded | last2=Goldreich
 |first3 =Johan | last3=Håstad
 |first4 =Joel | last4=Freidmann
 |first5 =Steven | last5=Rudich
 |first6 =Roman | last6=Smolensky
 |ref=harv
 |title=The bit extraction problem or t-resilient functions
 |year=1985
 |journal=Proceedings of the 26th Annual Symposium on Foundations of Computer Science, FOCS 1985
 |pages=396–407
 |doi=10.1109/SFCS.1985.55
 |url=
 |isbn = 0-8186-0644-4
}}
* {{Citation
 | last = Goldreich
 | first = Oded
 | author-link =
 | title = Lecture 7: Small bias sample spaces
 | year = 2001
 | url = http://www.wisdom.weizmann.ac.il/~oded/PS/RND/l07.ps
 | accessdate = 
 | ref=harv}}
* {{Citation
 | last=Joffe | first=Anatole
 | title=On a Set of Almost Deterministic k-Independent Random Variables
 | ref=harv
 | year=1974
 | journal=Annals of Probability
 | pages=161–162
 | volume=2
 | issue=1
 | doi=10.1214/aop/1176996762
}}
* {{Citation
 | last1 = Naor
 | first1 = Joseph
 | last2 = Naor
 | first2 = Moni
 | title = Small-bias Probability Spaces: efficient constructions and Applications
 | year = 1990
 | journal = Proceedings of the 22nd annual ACM symposium on Theory of computing, STOC 1990
 | url = http://www.wisdom.weizmann.ac.il/~naor/PAPERS/bias_abs.html
 | accessdate = 
 | pages=213–223
 | doi=10.1145/100216.100244
 | ref=harv
 | isbn = 0897913612}}
* {{Citation
 | last1 = Amnon
 | first1 = Ta-Shma
 | title = Explicit, Almost Optimal, Epsilon-balanced Codes
 | year = 2017
 | journal = Proceedings of the 49th Annual ACM SIGACT Symposium on Theory of Computing
 | url = http://doi.acm.org/10.1145/3055399.3055408
 | accessdate = 
 | pages=238--251
 | doi=10.1145/3055399.3055408
 | ref=harv
 | isbn = 9781450345286}}
[[Category:Pseudorandomness]]
[[Category:Theoretical computer science]]</text>
      <sha1>aokf3tqzh2ko8x8qsv7g2opcz9lao00</sha1>
    </revision>
  </page>
  <page>
    <title>Symmetry breaking</title>
    <ns>0</ns>
    <id>1240378</id>
    <revision>
      <id>862203919</id>
      <parentid>862203746</parentid>
      <timestamp>2018-10-02T20:43:13Z</timestamp>
      <contributor>
        <username>I dream of horses</username>
        <id>9676078</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/Imgoinblind|Imgoinblind]] ([[User talk:Imgoinblind|talk]]): using improper humor in articles ([[WP:NPOV]], [[WP:V]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5003">{{otheruses}}

{{expert|Physics|date=May 2014}}

[[File:Spontaneous symmetry breaking from an instable equilibrium.svg|thumb|A ball is initially located at the top of the central hill (C). This position is an unstable equilibrium: a very small perturbation will cause it to fall to one of the two stable wells left (L) or (R). Even if the hill is symmetric and there is no reason for the ball to fall on either side, the observed final state is not symmetric.]]

In [[physics]], '''symmetry breaking''' is a [[phenomenon]] in which (infinitesimally) small [[Quantum fluctuation|fluctuation]]s acting on a [[system]] crossing a [[critical point (thermodynamics)|critical point]] decide the system's fate, by determining which branch of a [[Bifurcation theory|bifurcation]] is taken. To an outside observer unaware of the fluctuations (or "[[Thermal noise|noise]]"), the choice will appear arbitrary. This process is called [[symmetry (physics)|symmetry]] "breaking", because such transitions usually bring the system from a symmetric but [[randomness|disorderly]] [[Quantum state|state]] into one or more definite states. Symmetry breaking is thought to play a major role in [[pattern formation]].

In 1972, [[Nobel prize in physics|Nobel laureate]] [[Philip Warren Anderson|P.W. Anderson]] used the idea of symmetry breaking to show some of the drawbacks of [[reductionism]] in his paper titled "More is different" in [[Science (journal)|''Science'']].&lt;ref&gt;{{cite journal | last=Anderson | first=P.W. | title=More is Different | journal=Science | volume=177 | issue=4047| pages=393–396 | year=1972 | url=http://robotics.cs.tamu.edu/dshell/cs689/papers/anderson72more_is_different.pdf | doi=10.1126/science.177.4047.393 | pmid=17796623 | format=|bibcode = 1972Sci...177..393A }}&lt;/ref&gt;

Symmetry breaking can be distinguished into two types, [[explicit symmetry breaking]] and [[spontaneous symmetry breaking]], characterized by whether the equations of motion fail to be invariant or the [[Vacuum state|ground state]] fails to be invariant.

==Explicit symmetry breaking==

{{main|Explicit symmetry breaking}}

In explicit symmetry breaking, the [[equations of motion]] describing a system are variant under the broken symmetry.

==Spontaneous symmetry breaking==

{{main|Spontaneous symmetry breaking}}

In spontaneous symmetry breaking, the [[equations of motion]] of the system are invariant, but the system is not because the background ([[spacetime]]) of the system, its [[Vacuum state|vacuum]], is non-invariant. Such a symmetry breaking is parametrized by an [[order parameter]]. A special case of this type of symmetry breaking is [[dynamical symmetry breaking]].

== Examples ==

Symmetry breaking can cover any of the following scenarios:&lt;ref&gt;{{cite web|url=http://www.angelfire.com/stars5/astroinfo/gloss/s.html|title=Astronomical Glossary|author=|date=|website=www.angelfire.com}}&lt;/ref&gt;
:* The breaking of an exact symmetry of the underlying laws of physics by the random formation of some structure; 
:* A situation in physics in which a [[ground state|minimal energy state]] has less symmetry than the system itself; 
:* Situations where the actual state of the system does not reflect the underlying symmetries of the dynamics because the manifestly symmetric state is unstable (stability is gained at the cost of [[local property|local]] asymmetry); 
:* Situations where the equations of a theory may have certain symmetries, though their solutions may not (the symmetries are "hidden").

One of the first cases of broken symmetry discussed in the physics literature is related to the form taken by a uniformly rotating body of [[Incompressible flow|incompressible fluid]] in [[gravitational]] and [[hydrostatic equilibrium]]. [[Carl Gustav Jacob Jacobi|Jacobi]]&lt;ref&gt;{{cite journal| last=Jacobi | first=C.G.J. | title=Über die figur des gleichgewichts | journal=[[Annalen der Physik und Chemie]] | issue=33| pages=229–238 | year=1834}}&lt;/ref&gt; and soon later [[Liouville]],&lt;ref&gt;{{cite journal| last=Liouville | first=J. | title=Sur la figure d'une masse fluide homogène, en équilibre et douée d'un mouvement de rotation| journal=Journal de l'École Polytechnique | issue=14| pages=289–296 | year=1834}}&lt;/ref&gt; in 1834, discussed the fact that a tri-axial ellipsoid was an equilibrium solution for this problem when the kinetic energy compared to the gravitational energy of the rotating body exceeded a certain critical value. The axial symmetry presented by the McLaurin spheroids is broken at this bifurcation point. Furthermore, above this bifurcation point, and for constant angular momentum, the solutions that minimize the kinetic energy are the ''non''-axially symmetric [[Jacobi ellipsoid]]s instead of the [[Maclaurin spheroid]]s.

==See also==

*[[Higgs mechanism]]
*[[QCD vacuum]]
*[[Goldstone boson]]
*[[1964 PRL symmetry breaking papers]]

==References==
{{reflist|colwidth=30em}}

{{DEFAULTSORT:Symmetry Breaking}}
[[Category:Symmetry]]
[[Category:Pattern formation]]</text>
      <sha1>s2gl2hmtfb2vo5md0ft1ilbow6inz8g</sha1>
    </revision>
  </page>
  <page>
    <title>Tanner graph</title>
    <ns>0</ns>
    <id>2382632</id>
    <revision>
      <id>845645846</id>
      <parentid>777624817</parentid>
      <timestamp>2018-06-13T05:44:42Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2866">In [[coding theory]], a '''Tanner graph''', named after Michael Tanner, is a [[bipartite graph]] used to state constraints or equations which specify [[error correcting codes]]. In [[coding theory]], Tanner graphs are used to construct longer codes from smaller ones. Both encoders and decoders employ these graphs extensively.

== Origins ==
Tanner graphs were proposed by Michael Tanner&lt;ref&gt;[http://www.copyright.gov/disted/comments/init040.pdf R. Michael Tanner Professor of Computer Science, School of Engineering University of California, Santa Cruz Testimony before Representatives of the United States Copyright Office February 10, 1999]&lt;/ref&gt; as a means to create larger error correcting codes from smaller ones using recursive techniques. He generalized the techniques of [[Peter Elias|Elias]] for product codes.

Tanner discussed lower bounds on the codes obtained from these graphs irrespective of the specific characteristics of the codes which were being used to construct larger codes.

== Tanner graphs for linear block codes ==
[[Image:Tanner graph example.PNG|right|350px|Tanner graph with subcode and digit nodes]]
Tanner graphs are [[bipartite graph|partitioned]] into subcode nodes and digit nodes. For linear block codes, the subcode nodes denote rows of the [[parity-check matrix]] H. The digit nodes represent the columns of the matrix H. An edge connects a subcode node to a digit node if a nonzero entry exists in the intersection of the corresponding row and column.

== Bounds proved by Tanner ==
Tanner proved the following bounds

Let &lt;math&gt; R &lt;/math&gt; be the rate of the resulting linear code, let the degree of the digit nodes be &lt;math&gt; m &lt;/math&gt; and the degree of the subcode nodes be &lt;math&gt; n &lt;/math&gt;. If each subcode node is associated with a linear code (n,k) with rate r = k/n, then the rate of the code is bounded by

: &lt;math&gt; R \geq 1 - (1 - r)m \, &lt;/math&gt;

== Computational complexity of Tanner graph based methods ==
The advantage of these recursive techniques is that they are computationally tractable.  The coding
algorithm for Tanner graphs is extremely efficient in practice, although it is not
guaranteed to converge except for cycle-free graphs, which are known  not to admit asymptotically
good codes.&lt;ref&gt;T. Etzion, A. Trachtenberg, and [[Alexander Vardy|A. Vardy]], Which Codes have Cycle-Free Tanner Graphs?, IEEE Trans. Inf. Theory, 45:6.&lt;/ref&gt;

== Applications of Tanner graph ==
[[Zemor's decoding algorithm]], which is a recursive low-complexity approach to code construction, is based on Tanner graphs.

== Notes ==
&lt;references/&gt;
*[http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1056404 Michael Tanner's Original paper]
*[https://web.archive.org/web/20071016050422/http://www.uic.edu/index.html/admin_tanner.shtml Michael Tanner's page]

[[Category:Coding theory]]
[[Category:Application-specific graphs]]</text>
      <sha1>4126uq64t31bxejxq6z5pa6yrb9gtc2</sha1>
    </revision>
  </page>
  <page>
    <title>Taylor series</title>
    <ns>0</ns>
    <id>30448</id>
    <revision>
      <id>865867650</id>
      <parentid>865845957</parentid>
      <timestamp>2018-10-26T18:09:37Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>Undid revision 865845957 by [[Special:Contributions/RLGoodwin|RLGoodwin]] ([[User talk:RLGoodwin|talk]]) article has been deleted</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="39492">{{for|other notions of series expansion|Series (mathematics)}}
{{good article}}
[[File:sintay_SVG.svg|thumb|300px|As the degree of the Taylor polynomial rises, it approaches the correct function. This image shows {{math|sin ''x''}} and its Taylor approximations, polynomials of degree &lt;span style="color:red;"&gt;'''1'''&lt;/span&gt;, &lt;span style="color:orange;"&gt;'''3'''&lt;/span&gt;, &lt;span style="color:yellow;"&gt;'''5'''&lt;/span&gt;, &lt;span style="color:lime;"&gt;'''7'''&lt;/span&gt;, &lt;span style="color:blue;"&gt;'''9'''&lt;/span&gt;, &lt;span style="color:indigo;"&gt;'''11'''&lt;/span&gt; and &lt;span style="color:violet;"&gt;'''13'''&lt;/span&gt;.]]
{{Calculus |Series}}

In [[mathematics]], a '''Taylor series''' is a representation of a [[function (mathematics)|function]] as an [[Series (mathematics)|infinite sum]] of terms that are calculated from the values of the function's [[derivative]]s at a single point.

The concept of a Taylor series was formulated by the Scottish mathematician [[James Gregory (mathematician)|James Gregory]] and formally introduced by the English mathematician [[Brook Taylor]] in 1715. If the Taylor series is centered at zero, then that series is also called a '''Maclaurin series''', named after the Scottish mathematician [[Colin Maclaurin]], who made extensive use of this special case of Taylor series in the 18th century.

A function can be approximated by using a finite number of terms of its Taylor series. [[Taylor's theorem]] gives quantitative estimates on the error introduced by the use of such an approximation.  The polynomial formed by taking some initial terms of the Taylor series is called a Taylor polynomial. The Taylor series of a function is the [[limit of a sequence|limit]] of that function's Taylor polynomials as the degree increases, provided that the limit exists. A function may not be equal to its Taylor series, even if its Taylor series [[Convergence (mathematics)|converges]] at every point. A function that is equal to its Taylor series in an [[open interval]] (or a [[Disk (mathematics)|disc]] in the [[complex plane]]) is known as an [[analytic function]] in that interval.

==Definition==
The Taylor series of a [[real-valued function|real]] or [[complex-valued function]] {{math|''f''&amp;thinsp;(''x'')}} that is [[infinitely differentiable function|infinitely differentiable]] at a [[real number|real]] or [[complex number]] {{math|''a''}} is the [[power series]]
&lt;!--

Any changes to the following formula, without first obtaining consensus on the discussion page will be reverted.  In particular, *DO NOT* add f(x)= here.

--&gt;:&lt;math&gt;f(a)+\frac {f'(a)}{1!} (x-a)+ \frac{f''(a)}{2!} (x-a)^2+\frac{f'''(a)}{3!}(x-a)^3+ \cdots, &lt;/math&gt;

which can be written in the more compact [[Summation#Capital-sigma notation|sigma notation]] as

&lt;!--

Any changes to the following formula, without first obtaining consensus on the discussion page will be reverted.  In particular, *DO NOT* add f(x)= here.

--&gt;:&lt;math&gt; \sum_{n=0} ^ {\infty} \frac {f^{(n)}(a)}{n!} (x-a)^{n},&lt;/math&gt;

where {{math|''n''!}} denotes the [[factorial]] of {{mvar|n}} and {{math|''f''{{isup|(''n'')}}(''a'')}} denotes the {{mvar|n}}th [[derivative]] of {{mvar|f}} evaluated at the point {{mvar|a}}. The derivative of order zero of {{mvar|f}} is defined to be {{mvar|f}} itself and {{math|(''x'' − ''a'')&lt;sup&gt;0&lt;/sup&gt;}} and {{math|0!}} are both defined to be&amp;nbsp;1. When {{math|''a'' {{=}} 0}}, the series is also called a [[Colin Maclaurin#Contributions to mathematics|Maclaurin series]].&lt;ref&gt;{{harvnb|Thomas|Finney|1996|loc=§8.9}}&lt;/ref&gt;

==Examples==
The Taylor series for any [[polynomial]] is the polynomial itself.

The Maclaurin series for {{math|{{sfrac|1|1 − ''x''}}}} is the [[geometric series]]

:&lt;math&gt;1+x+x^2+x^3+\cdots&lt;/math&gt;

so the Taylor series for {{math|{{sfrac|1|''x''}}}} at {{math|''a'' {{=}} 1}} is

:&lt;math&gt;1-(x-1)+(x-1)^2-(x-1)^3+\cdots.&lt;/math&gt;

By integrating the above Maclaurin series, we find the Maclaurin series for {{math|[[Natural logarithm|log]](1  − ''x'')}}, where log denotes the [[natural logarithm]]:

:&lt;math&gt;-x-\tfrac{1}{2}x^2-\tfrac{1}{3}x^3-\tfrac{1}{4}x^4-\cdots&lt;/math&gt;

and the corresponding Taylor series for {{math|log ''x''}} at {{math|''a'' {{=}} 1}} is

:&lt;math&gt;(x-1)-\tfrac{1}{2}(x-1)^2+\tfrac{1}{3}(x-1)^3-\tfrac{1}{4}(x-1)^4+\cdots,&lt;/math&gt;

and more generally, the corresponding Taylor series for {{math|log ''x''}} at some {{math|''a'' {{=}} ''x''&lt;sub&gt;0&lt;/sub&gt;}} is:

:&lt;math&gt;\log ( x_0 ) + \frac{1}{x_0} ( x - x_0 ) - \frac{1}{x_0^2}\frac{\left( x - x_0 \right)^2}{2} + \cdots.&lt;/math&gt;

The Taylor series for the [[exponential function]] {{math|''e''&lt;sup&gt;''x''&lt;/sup&gt;}} at {{math|''a'' {{=}} 0}} is

:&lt;math&gt;\frac{x^0}{0!} + \frac{x^1}{1!} + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \frac{x^5}{5!}+ \cdots = 1 + x + \frac{x^2}{2} + \frac{x^3}{6} + \frac{x^4}{24} + \frac{x^5}{120} + \cdots = \sum_{n=0}^\infty \frac{x^n}{n!}.&lt;/math&gt;

The above expansion holds because the derivative of {{math|''e''&lt;sup&gt;''x''&lt;/sup&gt;}} with respect to {{mvar|x}} is also {{math|''e''&lt;sup&gt;''x''&lt;/sup&gt;}} and {{math|''e''&lt;sup&gt;0&lt;/sup&gt;}} equals&amp;nbsp;1. This leaves the terms {{math|(''x'' − 0)&lt;sup&gt;''n''&lt;/sup&gt;}} in the numerator and {{math|''n''!}} in the denominator for each term in the infinite sum.

==History==
The Greek philosopher [[Zeno of Elea|Zeno]] considered the problem of summing an infinite series to achieve a finite result, but rejected it as an impossibility&lt;ref&gt;{{cite book|last1=Lindberg|first1=David|title=The Beginnings of Western Science|date=2007|publisher=University of Chicago Press|isbn=978-0-226-48205-7|page=33|edition=2nd}}&lt;/ref&gt;: the result was [[Zeno's paradox]]. Later, [[Aristotle]] proposed a philosophical resolution of the paradox, but the mathematical content was apparently unresolved until taken up by [[Archimedes]], as it had been prior to Aristotle by the Presocratic Atomist [[Democritus]]. It was through Archimedes's [[method of exhaustion]] that an infinite number of progressive subdivisions could be performed to achieve a finite result.&lt;ref&gt;{{cite book |last=Kline |first=M. |year=1990 |title=Mathematical Thought from Ancient to Modern Times |location=New York |publisher=Oxford University Press |pages=35–37 |isbn=0-19-506135-7 }}&lt;/ref&gt; [[Liu Hui]] independently employed a similar method a few centuries later.&lt;ref&gt;{{cite book |last=Boyer |first=C. |last2=Merzbach |first2=U.|author2-link= Uta Merzbach |year=1991 |title=A History of Mathematics |location= |publisher=John Wiley and Sons |edition=Second revised |pages=202–203 |isbn=0-471-09763-2 }}&lt;!--I'm sure there are better refs than this. Hui gave fairly "rigorous" bounds on the convergence, if I recall. But it isn't addressed here.--&gt;&lt;/ref&gt;

In the 14th century, the earliest examples of the use of Taylor series and closely related methods were given by [[Madhava of Sangamagrama]].&lt;ref name="MAT 314"&gt;{{cite web| publisher=Canisius College| work=MAT 314| url=http://www.pas.rochester.edu/~rajeev/papers/canisiustalks.pdf| title=Neither Newton nor Leibniz – The Pre-History of Calculus and Celestial Mechanics in Medieval Kerala| accessdate=2006-07-09| deadurl=no| archiveurl=https://web.archive.org/web/20150223113517/http://www.pas.rochester.edu/~rajeev/papers/canisiustalks.pdf| archivedate=2015-02-23| df=}}&lt;/ref&gt;&lt;ref name="dani"&gt;{{cite journal| title=Ancient Indian Mathematics – A Conspectus| author= S. G. Dani|journal= Resonance |volume=17|issue=3|year=2012|pages=236–246|doi=10.1007/s12045-012-0022-y}}&lt;/ref&gt; Though no record of his work survives, writings of later [[Indian mathematics|Indian mathematicians]] suggest that he found a number of special cases of the Taylor series, including those for the [[trigonometric function]]s of [[sine]], [[cosine]], [[tangent (trigonometric function)|tangent]], and [[arctangent]]. The [[Kerala School of Astronomy and Mathematics]] further expanded his works with various series expansions and rational approximations until the 16th century.

In the 17th century, [[James Gregory (astronomer and mathematician)|James Gregory]] also worked in this area and published several Maclaurin series. It was not until 1715 however that a general method for constructing these series for all functions for which they exist was finally provided by [[Brook Taylor]],&lt;ref&gt;{{cite book|language=Latin|last=Taylor |first=Brook |title=Methodus Incrementorum Directa et Inversa |trans-title=Direct and Reverse Methods of Incrementation |location=London |date=1715 |at=p. 21–23 (Prop. VII, Thm. 3, Cor. 2)}} Translated into English in {{cite book|first=D. J. |last=Struik|title=A Source Book in Mathematics 1200–1800 |location=Cambridge, Massachusetts |publisher=Harvard University Press |date=1969 |pages= 329–332}}&lt;/ref&gt; after whom the series are now named.

The Maclaurin series was named after [[Colin Maclaurin]], a professor in Edinburgh, who published the special case of the Taylor result in the 18th century.

==Analytic functions==
[[Image:Exp neg inverse square.svg|300px|thumb|right|The function {{math|1=&lt;strong style="color:#803300"&gt;''e''&lt;sup&gt;(−1/''x''&lt;sup&gt;2&lt;/sup&gt;)&lt;/sup&gt;&lt;/strong&gt;}} is not analytic at {{math|1=''x'' {{=}} 0}}: the Taylor series is identically 0, although the function is not.]]
{{main article|analytic function}}
If {{math|''f''&amp;thinsp;(''x'')}} is given by a convergent power series in an open disc (or interval in the real line) centered at {{mvar|b}} in the complex plane, it is said to be [[analytic function|analytic]] in this disc.  Thus for {{mvar|x}} in this disc, {{mvar|f}} is given by a convergent power series
:&lt;math&gt;f(x) = \sum_{n=0}^\infty a_n(x-b)^n.&lt;/math&gt;
Differentiating by {{mvar|x}} the above formula {{mvar|n}} times, then setting {{math|''x'' {{=}} ''b''}} gives:
:&lt;math&gt;\frac{f^{(n)}(b)}{n!} = a_n&lt;/math&gt;
and so the power series expansion agrees with the Taylor series.  Thus a function is analytic in an open disc centered at {{mvar|b}} if and only if its Taylor series converges to the value of the function at each point of the disc.

If {{math|''f''&amp;thinsp;(''x'')}} is equal to its Taylor series for all {{mvar|x}} in the complex plane, it is called [[entire function|entire]]. The polynomials, [[exponential function]] {{math|''e''&lt;sup&gt;''x''&lt;/sup&gt;}}, and the [[trigonometric function]]s sine and cosine, are examples of entire functions. Examples of functions that are not entire include the [[square root]], the [[logarithm]], the [[trigonometric function]] tangent, and its inverse, [[arctan]]. For these functions the Taylor series do not [[convergent series|converge]] if {{mvar|x}} is far from {{mvar|b}}. That is, the Taylor series [[divergent series|diverges]] at {{mvar|x}} if the distance between {{mvar|x}} and {{mvar|b}} is larger than the [[radius of convergence]]. The Taylor series can be used to calculate the value of an entire function at every point, if the value of the function, and of all of its derivatives, are known at a single point.

Uses of the Taylor series for analytic functions include:
# The partial sums (the [[Taylor polynomial]]s) of the series can be used as approximations of the function. These approximations are good if sufficiently many terms are included.
#Differentiation and integration of power series can be performed term by term and is hence particularly easy.
#An [[analytic function]] is uniquely extended to a [[holomorphic function]] on an [[open disk]] in the [[complex number|complex plane]]. This makes the machinery of [[complex analysis]] available.
#The (truncated) series can be used to compute function values numerically, (often by recasting the polynomial into the [[Chebyshev form]] and evaluating it with the [[Clenshaw algorithm]]).
#Algebraic operations can be done readily on the power series representation; for instance, [[Euler's formula]] follows from Taylor series expansions for trigonometric and exponential functions. This result is of fundamental importance in such fields as [[harmonic analysis]].
#Approximations using the first few terms of a Taylor series can make otherwise unsolvable problems possible for a restricted domain; this approach is often used in physics.

==Approximation error and convergence==
{{main|Taylor's theorem}}
[[Image:Taylorsine.svg|300px|thumb|right|The sine function (blue) is closely approximated by its Taylor polynomial of degree 7 (pink) for a full period centered at the origin.]]
[[Image:LogTay.svg|300px|thumb|right|The Taylor polynomials for {{math|log(1 + ''x'')}} only provide accurate approximations in the range {{math|−1 &lt; ''x'' ≤ 1}}. For {{math|''x'' &gt; 1}}, Taylor polynomials of higher degree provide worse approximations.]]
[[Image:Logarithm GIF.gif|300px|thumb|right|The Taylor approximations for {{math|log(1 + ''x'')}} (black). For {{math|''x'' &gt; 1}}, the approximations diverge.]]

Pictured on the right is an accurate approximation of {{math|sin ''x''}} around the point {{math|''x'' {{=}} 0}}. The pink curve is a polynomial of degree seven:

:&lt;math&gt;\sin\left( x \right) \approx x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!}.\!&lt;/math&gt;

The error in this approximation is no more than {{math|{{sfrac|{{abs|''x''}}&lt;sup&gt;9&lt;/sup&gt;|9!}}}}. In particular, for {{math|−1 &lt; ''x'' &lt; 1}}, the error is less than&amp;nbsp;0.000003.

In contrast, also shown is a picture of the natural logarithm function {{math|[[Natural logarithm|log]](1 + ''x'')}} and some of its [[Taylor polynomial]]s around {{math|''a'' {{=}} 0}}. These approximations converge to the function only in the region {{math|−1 &lt; ''x'' ≤ 1}}; outside of this region the higher-degree Taylor polynomials are ''worse'' approximations for the function. This is similar to [[Runge's phenomenon]].{{cn|date=November 2017}}

The ''error'' incurred in approximating a function by its {{mvar|n}}th-degree Taylor polynomial is called the ''remainder'' or ''[[Residual (numerical analysis)|residual]]'' and is denoted by the function {{math|''R''&lt;sub&gt;''n''&lt;/sub&gt;(''x'')}}. [[Taylor's theorem]] can be used to obtain a bound on the size of the remainder.

In general, Taylor series need not be [[convergent series|convergent]] at all. And in fact the set of functions with a convergent Taylor series is a [[meager set]] in the [[Fréchet space]] of [[smooth functions]]. And even if the Taylor series of a function {{mvar|f}} does converge, its limit need not in general be equal to the value of the function {{math|''f''&amp;thinsp;(''x'')}}. For example, the function
:&lt;math&gt;
f(x) = \begin{cases}
e^{-\frac{1}{x^2}}&amp;\text{if } x\neq0\\
0&amp;\text{if } x=0
\end{cases}
&lt;/math&gt;
is [[infinitely differentiable]] at {{math|''x'' {{=}} 0}}, and has all derivatives zero there. Consequently, the Taylor series of {{math|''f''&amp;thinsp;(''x'')}} about {{math|''x'' {{=}} 0}} is identically zero. However, {{math|''f''&amp;thinsp;(''x'')}} is not the zero function, so does not equal its Taylor series around the origin.  Thus, {{math|''f''&amp;thinsp;(''x'')}} is an example of a [[non-analytic smooth function]].

In [[real analysis]], this example shows that there are [[infinitely differentiable function]]s {{math|''f''&amp;thinsp;(''x'')}} whose Taylor series are ''not'' equal to {{math|''f''&amp;thinsp;(''x'')}} even if they converge. By contrast, the [[holomorphic function]]s studied in [[complex analysis]] always possess a convergent Taylor series, and even the Taylor  series of [[meromorphic function]]s, which might have singularities, never converge to a value different from the function itself. The complex function {{math|''e''&lt;sup&gt;−1/''z''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt;}}, however, does not approach 0 when {{mvar|z}} approaches 0 along the imaginary axis, so it is not [[Continuous function|continuous]] in the complex plane and its Taylor series is undefined at 0.

More generally, every sequence of real or complex numbers can appear as [[coefficient]]s in the Taylor series of an infinitely differentiable function defined on the real line, a consequence of [[Borel's lemma]].  As a result, the [[radius of convergence]] of a Taylor series can be zero. There are even infinitely differentiable functions defined on the real line whose Taylor series have a radius of convergence 0 everywhere.&lt;ref&gt;{{Citation | last = Rudin | first = Walter | author-link = Walter Rudin| title = Real and Complex Analysis | place = New Dehli | publisher = McGraw-Hill | year = 1980 | page = 418, Exercise 13 | isbn = 0-07-099557-5 | postscript = &lt;!--none--&gt;}}&lt;/ref&gt;

A function cannot be written as a Taylor series centered at a [[singularity (mathematics)|singularity]]; in these cases, one can often still achieve a series expansion if one allows also negative powers of the variable {{mvar|x}}; see [[Laurent series]]. For example, {{math|''f''&amp;thinsp;(''x'') {{=}} ''e''&lt;sup&gt;−1/''x''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt;}} can be written as a Laurent series.

===Generalization===
There is, however, a generalization&lt;ref&gt;{{citation|first=William|last=Feller|authorlink=William Feller|title=An introduction to probability theory and its applications, Volume 2|edition=3rd|publisher=Wiley|year=1971|pages=230–232}}.&lt;/ref&gt;&lt;ref&gt;{{citation|first1=Einar|last1=Hille|authorlink1=Einar Hille|first2=Ralph S.|last2=Phillips|authorlink2=Ralph S. Phillips|title=Functional analysis and semi-groups|publisher=American Mathematical Society|series=AMS Colloquium Publications|volume=31|year=1957|pages=300–327}}.&lt;/ref&gt; of the Taylor series that does converge to the value of the function itself for any [[bounded function|bounded]] [[continuous function]] on {{math|(0,∞)}}, using the calculus of [[finite differences]].  Specifically, one has the following theorem, due to [[Einar Hille]], that for any {{math|''t'' &gt; 0}},
:&lt;math&gt;\lim_{h\to 0^+}\sum_{n=0}^\infty \frac{t^n}{n!}\frac{\Delta_h^nf(a)}{h^n} = f(a+t).&lt;/math&gt;
Here {{math|Δ{{su|p=''n''|b=''h''}}}} is the {{mvar|n}}th finite difference operator with step size {{mvar|h}}. The series is precisely the Taylor series, except that divided differences appear in place of differentiation: the series is formally similar to the [[Newton series]]. When the function {{mvar|f}} is analytic at {{mvar|a}}, the terms in the series converge to the terms of the Taylor series, and in this sense generalizes the usual Taylor series.

In general, for any infinite sequence {{math|''a''&lt;sub&gt;''i''&lt;/sub&gt;}}, the following power series identity holds:
:&lt;math&gt;\sum_{n=0}^\infty\frac{u^n}{n!}\Delta^na_i = e^{-u}\sum_{j=0}^\infty\frac{u^j}{j!}a_{i+j}.&lt;/math&gt;
So in particular,
:&lt;math&gt;f(a+t) = \lim_{h\to 0^+} e^{-\frac{t}{h}}\sum_{j=0}^\infty f(a+jh) \frac{\left(\frac{t}{h}\right)^j}{j!}.&lt;/math&gt;
The series on the right is the [[expectation value]] of {{math|''f''&amp;thinsp;(''a'' + ''X'')}}, where {{mvar|X}} is a [[Poisson distribution|Poisson-distributed]] [[random variable]] that takes the value {{math|''jh''}} with probability {{math|''e''&lt;sup&gt;−''t''/''h''&lt;/sup&gt;·{{sfrac|(''t''/''h''){{isup|''j''}}|''j''!}}}}. Hence,
:&lt;math&gt;f(a+t) = \lim_{h\to 0^+} \int_{-\infty}^\infty f(a+x)dP_{\frac{t}{h},h}(x).&lt;/math&gt;
The [[law of large numbers]] implies that the identity holds.&lt;ref&gt;{{cite book|authorlink=William Feller|first=William|last=Feller|title=An introduction to probability theory and its applications|volume=2|edition=3|page=231|year=1970}}&lt;/ref&gt;

==List of Maclaurin series of some common functions==
{{see also|List of mathematical series}}
Several important Maclaurin series expansions follow.&lt;ref&gt;Most of these can be found in {{harv|Abramowitz|Stegun|1970}}.&lt;/ref&gt; All these expansions are valid for complex arguments {{mvar|x}}.

=== Exponential function ===
[[File:Exp series.gif|right|thumb|The [[exponential function]] {{math|''e''&lt;sup&gt;''x''&lt;/sup&gt;}} (in blue), and the sum of the first {{math|''n'' + 1}} terms of its Taylor series at 0 (in red).]]
The [[exponential function]] &lt;math&gt;e^x&lt;/math&gt; (with base [[e (mathematics)|{{mvar|e}}]]) has Maclaurin series
:&lt;math&gt;e^{x} = \sum^{\infty}_{n=0} \frac{x^n}{n!} = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots &lt;/math&gt;.
It converges for all {{mvar|x}}.

=== Natural logarithm ===
The [[natural logarithm]] (with base [[e (mathematics)|{{mvar|e}}]]) has Maclaurin series
:&lt;math&gt;\begin{align}
\log(1-x) &amp;= - \sum^{\infty}_{n=1} \frac{x^n}n = -x - \frac{x^2}2 - \frac{x^3}3 - \cdots , \\
\log(1+x) &amp;= \sum^\infty_{n=1} (-1)^{n+1}\frac{x^n}n = x - \frac{x^2}2 + \frac{x^3}3 - \cdots .
\end{align}&lt;/math&gt;
They converge for &lt;math&gt;|x| &lt; 1&lt;/math&gt;.

=== Geometric series ===

The [[geometric series]] and its derivatives have Maclaurin series

:&lt;math&gt;\begin{align}
\frac{1}{1-x} &amp;= \sum^\infty_{n=0} x^n \\
\frac{1}{(1-x)^2} &amp;= \sum^\infty_{n=1} nx^{n-1}\\
\frac{1}{(1-x)^3} &amp;= \sum^\infty_{n=2} \frac{(n-1)n}{2} x^{n-2}.
\end{align}&lt;/math&gt;
All are convergent for &lt;math&gt;|x| &lt; 1&lt;/math&gt;.  These are special cases of the [[#Binomial series|binomial series]] given in the next section.

=== Binomial series ===

The [[binomial series]] is the power series

:&lt;math&gt;(1+x)^\alpha = \sum_{n=0}^\infty \binom{\alpha}{n} x^n&lt;/math&gt;

whose coefficients are the generalized [[binomial coefficient]]s

: &lt;math&gt;\binom{\alpha}{n} = \prod_{k=1}^n \frac{\alpha-k+1}k = \frac{\alpha(\alpha-1)\cdots(\alpha-n+1)}{n!}.&lt;/math&gt;

(If {{math| ''n'' {{=}} 0}}, this product is an [[empty product]] and has value 1.)  It converges for &lt;math&gt;|x| &lt; 1&lt;/math&gt; for any real or complex number {{mvar|α}}.

When {{math|''α'' {{=}} −1}}, this is essentially the infinite geometric series mentioned in the previous section.  The special cases {{math|''α'' {{=}} {{sfrac|1|2}}}} and {{math|''α'' {{=}} −{{sfrac|1|2}}}} give the [[square root]] function and its [[multiplicative inverse|inverse]]:

:&lt;math&gt;\begin{align} 
(1+x)^\frac12 &amp;= 1 + \tfrac{1}{2}x - \tfrac{1}{8}x^2 + \tfrac{1}{16}x^3 - \tfrac{5}{128}x^4 + \tfrac{7}{256}x^5 - \ldots, \\
(1+x)^{-\frac12} &amp;= 1 -\tfrac{1}{2}x + \tfrac{3}{8}x^2 - \tfrac{5}{16}x^3 + \tfrac{35}{128}x^4 - \tfrac{63}{256}x^5 + \ldots.
\end{align}&lt;/math&gt;

=== Trigonometric functions ===
The usual [[trigonometric function]]s and their inverses have the following Maclaurin series:
:&lt;math&gt;\begin{align}
\sin x &amp;= \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n+1)!} x^{2n+1} &amp;&amp;= x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots &amp;&amp; \text{for all } x\\[6pt]
\cos x &amp;= \sum^{\infty}_{n=0} \frac{(-1)^n}{(2n)!} x^{2n} &amp;&amp;= 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots &amp;&amp; \text{for all } x\\[6pt]
\tan x &amp;= \sum^{\infty}_{n=1} \frac{B_{2n} (-4)^n \left(1-4^n\right)}{(2n)!} x^{2n-1} &amp;&amp;= x + \frac{x^3}{3} + \frac{2 x^5}{15} + \cdots &amp;&amp; \text{for }|x| &lt; \frac{\pi}{2}\\[6pt]
\sec x &amp;= \sum^{\infty}_{n=0} \frac{(-1)^n E_{2n}}{(2n)!} x^{2n} &amp;&amp;=1+\frac{x^2}{2}+\frac{5x^4}{24}+\cdots &amp;&amp; \text{for }|x| &lt; \frac{\pi}{2}\\[6pt]
\arcsin x &amp;= \sum^{\infty}_{n=0} \frac{(2n)!}{4^n (n!)^2 (2n+1)} x^{2n+1} &amp;&amp;=x+\frac{x^3}{6}+\frac{3x^5}{40}+\cdots &amp;&amp; \text{for }|x| \le 1\\[6pt]
\arccos x &amp;=\frac{\pi}{2}-\arcsin x\\&amp;=\frac{\pi}{2}- \sum^{\infty}_{n=0} \frac{(2n)!}{4^n (n!)^2 (2n+1)} x^{2n+1}&amp;&amp;=\frac{\pi}{2}-x-\frac{x^3}{6}-\frac{3x^5}{40}+\cdots&amp;&amp; \text{for }|x| \le 1\\[6pt]
\arctan x &amp;= \sum^{\infty}_{n=0} \frac{(-1)^n}{2n+1} x^{2n+1} &amp;&amp;=x-\frac{x^3}{3} + \frac{x^5}{5}-\cdots &amp;&amp; \text{for }|x| \le 1,\ x\neq\pm i
\end{align}&lt;/math&gt;

All angles are expressed in radians. The numbers {{math|''B&lt;sub&gt;k&lt;/sub&gt;''}} appearing in the expansions of {{math|tan ''x''}} are the [[Bernoulli numbers]]. The {{math|''E''&lt;sub&gt;''k''&lt;/sub&gt;}} in the expansion of {{math|sec ''x''}} are [[Euler number]]s.

=== Hyperbolic functions ===
The [[hyperbolic function]]s have Maclaurin series closely related to the series for the corresponding trigonometric functions:
:&lt;math&gt;\begin{align}
\sinh x &amp;= \sum^{\infty}_{n=0} \frac{x^{2n+1}}{(2n+1)!} &amp;&amp;= x + \frac{x^3}{3!} + \frac{x^5}{5!} + \cdots &amp;&amp; \text{for all } x\\[6pt]
\cosh x &amp;= \sum^{\infty}_{n=0} \frac{x^{2n}}{(2n)!} &amp;&amp;= 1 + \frac{x^2}{2!} + \frac{x^4}{4!} + \cdots &amp;&amp; \text{for all } x\\[6pt]
\tanh x &amp;= \sum^{\infty}_{n=1} \frac{B_{2n} 4^n \left(4^n-1\right)}{(2n)!} x^{2n-1} &amp;&amp;= x-\frac{x^3}{3}+\frac{2x^5}{15}-\frac{17x^7}{315}+\cdots &amp;&amp; \text{for }|x| &lt; \frac{\pi}{2}\\[6pt]
\operatorname{arsinh} x &amp;= \sum^{\infty}_{n=0} \frac{(-1)^n (2n)!}{4^n (n!)^2 (2n+1)} x^{2n+1} &amp;&amp; &amp;&amp; \text{for }|x| \le 1\\[6pt]
\operatorname{artanh} x &amp;= \sum^{\infty}_{n=0} \frac{x^{2n+1}}{2n+1} &amp;&amp; &amp;&amp; \text{for }|x| \le 1,\ x\neq\pm 1
\end{align}&lt;/math&gt;

The numbers {{math|''B&lt;sub&gt;k&lt;/sub&gt;''}} appearing in the series for {{math|tanh ''x''}} are the [[Bernoulli numbers]].

==Calculation of Taylor series==
Several methods exist for the calculation of Taylor series of a large number of functions. One can attempt to use the definition of the Taylor series, though this often requires generalizing the form of the coefficients according to a readily apparent pattern. Alternatively, one can use manipulations such as substitution, multiplication or division, addition or subtraction of standard Taylor series to construct the Taylor series of a function, by virtue of Taylor series being power series. In some cases, one can also derive the Taylor series by repeatedly applying [[integration by parts]]. Particularly convenient is the use of [[computer algebra system]]s to calculate Taylor series.

===First example===
In order to compute the 7th degree Maclaurin polynomial for the function
:&lt;math&gt;f(x)=\log(\cos x),\quad x\in\left(-\frac{\pi}{2},\frac{\pi}{2}\right)&lt;/math&gt; ,
one may first rewrite the function as
:&lt;math&gt;f(x)=\log\bigl(1+(\cos x-1)\bigr)\!&lt;/math&gt;.
The Taylor series for the natural logarithm is (using the [[big O notation]])
:&lt;math&gt;\log(1+x) = x - \frac{x^2}2 + \frac{x^3}3 + {O}\left(x^4\right)\!&lt;/math&gt;
and for the cosine function
:&lt;math&gt;\cos x - 1 = -\frac{x^2}2 + \frac{x^4}{24} - \frac{x^6}{720} + {O}\left(x^8\right)\!&lt;/math&gt;.
The latter series expansion has a zero [[constant term]], which enables us to substitute the second series into the first one and to easily omit terms of higher order than the 7th degree by using the big {{mvar|O}} notation:

:&lt;math&gt;\begin{align}f(x)&amp;=\log\bigl(1+(\cos x-1)\bigr)\\
&amp;=(\cos x-1) - \tfrac12(\cos x-1)^2 + \tfrac13(\cos x-1)^3+ {O}\left((\cos x-1)^4\right)\\
&amp;=\left(-\frac{x^2}2 + \frac{x^4}{24} - \frac{x^6}{720} +{O}\left(x^8\right)\right)-\frac12\left(-\frac{x^2}2+\frac{x^4}{24}+{O}\left(x^6\right)\right)^2+\frac13\left(-\frac{x^2}2+O\left(x^4\right)\right)^3 + {O}\left(x^8\right)\\ &amp; =-\frac{x^2}2 + \frac{x^4}{24}-\frac{x^6}{720} - \frac{x^4}8 + \frac{x^6}{48} - \frac{x^6}{24} +O\left(x^8\right)\\
&amp; =- \frac{x^2}2 - \frac{x^4}{12} - \frac{x^6}{45}+O\left(x^8\right). \end{align}\!&lt;/math&gt;
Since the cosine is an [[even function]], the coefficients for all the odd powers {{math|''x'', ''x''&lt;sup&gt;3&lt;/sup&gt;, ''x''&lt;sup&gt;5&lt;/sup&gt;, ''x''&lt;sup&gt;7&lt;/sup&gt;, ...}} have to be zero.

===Second example===
Suppose we want the Taylor series at 0 of the function
: &lt;math&gt;g(x)=\frac{e^x}{\cos x}.\!&lt;/math&gt;
We have for the exponential function
: &lt;math&gt;e^x = \sum^\infty_{n=0} \frac{x^n}{n!} =1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!}+\cdots\!&lt;/math&gt;
and, as in the first example,
: &lt;math&gt;\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots\!&lt;/math&gt;
Assume the power series is
: &lt;math&gt;\frac{e^x}{\cos x} = c_0 + c_1 x + c_2 x^2 + c_3 x^3 + \cdots\!&lt;/math&gt;
Then multiplication with the denominator and substitution of the series of the cosine yields
: &lt;math&gt;\begin{align} e^x &amp;= \left(c_0 + c_1 x + c_2 x^2 + c_3 x^3 + \cdots\right)\cos x\\
&amp;=\left(c_0 + c_1 x + c_2 x^2 + c_3 x^3 + c_4x^4 + \cdots\right)\left(1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots\right)\\&amp;=c_0 - \frac{c_0}{2}x^2 + \frac{c_0}{4!}x^4 + c_1x - \frac{c_1}{2}x^3 + \frac{c_1}{4!}x^5 + c_2x^2 - \frac{c_2}{2}x^4 + \frac{c_2}{4!}x^6 + c_3x^3 - \frac{c_3}{2}x^5 + \frac{c_3}{4!}x^7 + c_4x^4 +\cdots \end{align}\!&lt;/math&gt;
Collecting the terms up to fourth order yields
: &lt;math&gt;e^x =c_0 + c_1x + \left(c_2 - \frac{c_0}{2}\right)x^2 + \left(c_3 - \frac{c_1}{2}\right)x^3+\left(c_4-\frac{c_2}{2}+\frac{c_0}{4!}\right)x^4 + \cdots\!&lt;/math&gt;
The values of &lt;math&gt;c_i&lt;/math&gt; can be found by comparison of coefficients with the top expression for &lt;math&gt;e^x&lt;/math&gt;, yielding:
: &lt;math&gt;\frac{e^x}{\cos x}=1 + x + x^2 + \frac{2x^3}{3} + \frac{x^4}{2} + \cdots.\!&lt;/math&gt;

===Third example===
Here we employ a method called "indirect expansion" to expand the given function. This method uses the known Taylor expansion of the exponential function. In order to expand {{math|(1 + ''x'')''e&lt;sup&gt;x&lt;/sup&gt;''}} as a Taylor series in {{mvar|x}}, we use the known Taylor series of function {{math|''e''&lt;sup&gt;''x''&lt;/sup&gt;}}:
: &lt;math&gt;e^x = \sum^\infty_{n=0} \frac{x^n}{n!} =1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!}+\cdots.&lt;/math&gt;
Thus,
: &lt;math&gt;\begin{align}(1+x)e^x &amp;= e^x + xe^x = \sum^\infty_{n=0} \frac{x^n}{n!} + \sum^\infty_{n=0} \frac{x^{n+1}}{n!} = 1 + \sum^\infty_{n=1} \frac{x^n}{n!} + \sum^\infty_{n=0} \frac{x^{n+1}}{n!} \\ &amp;= 1 + \sum^\infty_{n=1} \frac{x^n}{n!} + \sum^\infty_{n=1} \frac{x^n}{(n-1)!} =1 + \sum^\infty_{n=1}\left(\frac{1}{n!} + \frac{1}{(n-1)!}\right)x^n \\ &amp;= 1 + \sum^\infty_{n=1}\frac{n+1}{n!}x^n\\ &amp;= \sum^\infty_{n=0}\frac{n+1}{n!}x^n.\end{align}&lt;/math&gt;

==Taylor series as definitions==
Classically, [[algebraic function]]s are defined by an algebraic equation, and [[transcendental function]]s (including those discussed above) are defined by some property that holds for them, such as a [[differential equation]]. For example, the [[exponential function]] is the function which is equal to its own derivative everywhere, and assumes the value 1 at the origin. However, one may equally well define an [[analytic function]] by its Taylor series.

Taylor series are used to define functions and "[[operator (mathematics)|operator]]s" in diverse areas of mathematics. In particular, this is true in areas where the classical definitions of functions break down. For example, using Taylor series, one may extend analytic functions to sets of matrices and operators, such as the [[matrix exponential]] or [[matrix logarithm]].

In other areas, such as formal analysis, it is more convenient to work directly with the [[power series]] themselves. Thus one may define a solution of a differential equation ''as'' a power series which, one hopes to prove, is the Taylor series of the desired solution.

==Taylor series in several variables==

The Taylor series may also be generalized to functions of more than one variable with&lt;ref&gt;{{citation|author=[[Lars Hörmander]]|title=The analysis of partial differential operators, volume 1|year=1990|publisher=Springer|at=Eqq. 1.1.7 and 1.1.7′}}&lt;/ref&gt;&lt;ref&gt;{{citation|author1=Duistermaat|author2=Kolk|title=Distributions: Theory and applications|publisher=Birkhauser|year=2010|at=ch. 6}}&lt;/ref&gt;

:&lt;math&gt;\begin{align}
T(x_1,\ldots,x_d) &amp;= \sum_{n_1=0}^\infty \cdots \sum_{n_d = 0}^\infty  \frac{(x_1-a_1)^{n_1}\cdots (x_d-a_d)^{n_d}}{n_1!\cdots n_d!}\,\left(\frac{\partial^{n_1 + \cdots + n_d}f}{\partial x_1^{n_1}\cdots \partial x_d^{n_d}}\right)(a_1,\ldots,a_d) \\
&amp;= f(a_1, \ldots,a_d) + \sum_{j=1}^d \frac{\partial f(a_1, \ldots,a_d)}{\partial x_j} (x_j - a_j) + \frac{1}{2!} \sum_{j=1}^d \sum_{k=1}^d \frac{\partial^2 f(a_1, \ldots,a_d)}{\partial x_j \partial x_k} (x_j - a_j)(x_k - a_k) + \\ 
&amp; \qquad \qquad + \frac{1}{3!} \sum_{j=1}^d\sum_{k=1}^d\sum_{l=1}^d \frac{\partial^3 f(a_1, \ldots,a_d)}{\partial x_j \partial x_k \partial x_l} (x_j - a_j)(x_k - a_k)(x_l - a_l) + \cdots
\end{align}&lt;/math&gt;

For example, for a function &lt;math&gt;f(x,y)&lt;/math&gt; that depends on two variables, {{mvar|x}} and {{mvar|y}}, the Taylor series to second order about the point {{math|(''a'', ''b'')}} is

:&lt;math&gt;f(a,b) +(x-a) f_x(a,b) +(y-b) f_y(a,b) + \frac{1}{2!}\Big( (x-a)^2 f_{xx}(a,b) + 2(x-a)(y-b) f_{xy}(a,b) +(y-b)^2 f_{yy}(a,b) \Big)&lt;/math&gt;

where the subscripts denote the respective [[partial derivative]]s.

A second-order Taylor series expansion of a scalar-valued function of more than one variable can be written compactly as

:&lt;math&gt;T(\mathbf{x}) = f(\mathbf{a}) + (\mathbf{x} - \mathbf{a})^\mathsf{T} D f(\mathbf{a}) + \frac{1}{2!} (\mathbf{x} - \mathbf{a})^\mathsf{T} \left \{D^2 f(\mathbf{a}) \right \} (\mathbf{x} - \mathbf{a}) + \cdots,&lt;/math&gt;

where {{math|''D'' ''f''&amp;thinsp;('''a''')}} is the [[gradient]] of {{mvar|f}} evaluated at {{math|'''x''' {{=}} '''a'''}} and {{math|''D''&lt;sup&gt;2&lt;/sup&gt; ''f''&amp;thinsp;('''a''')}} is the [[Hessian matrix]]. Applying the [[multi-index notation]] the Taylor series for several variables becomes

:&lt;math&gt;T(\mathbf{x}) = \sum_{|\alpha| \geq 0}\frac{(\mathbf{x}-\mathbf{a})^\alpha}{\alpha !} \left({\mathrm{\partial}^{\alpha}}f\right)(\mathbf{a}),&lt;/math&gt;

which is to be understood as a still more abbreviated [[multi-index]] version of the first equation of this paragraph, again in full analogy to the single variable case.

=== Example ===
[[Image:Second Order Taylor.svg|200px|thumb|right|Second-order Taylor series approximation (in orange) of a function {{math|''f''&amp;thinsp;(''x'',''y'') {{=}} ''e&lt;sup&gt;x&lt;/sup&gt;'' log(1 + ''y'')}} around the origin.]]
In order to compute a second-order Taylor series expansion around point {{math|(''a'', ''b'') {{=}} (0, 0)}} of the function
:&lt;math&gt;f(x,y)=e^x\log(1+y),&lt;/math&gt;

one first computes all the necessary partial derivatives:

:&lt;math&gt;\begin{align}
f_x &amp;= e^x\log(1+y) \\[6pt]
f_y &amp;= \frac{e^x}{1+y} \\[6pt]
f_{xx} &amp;= e^x\log(1+y) \\[6pt]
f_{yy}  &amp;= - \frac{e^x}{(1+y)^2}  \\[6pt]
f_{xy} &amp;=f_{yx} =  \frac{e^x}{1+y} .
\end{align}&lt;/math&gt;

Evaluating these derivatives at the origin gives the Taylor coefficients

:&lt;math&gt;\begin{align}
f_x(0,0) &amp;= 0 \\
f_y(0,0) &amp;=1 \\
f_{xx}(0,0) &amp;=0 \\
f_{yy}(0,0) &amp;=-1 \\
f_{xy}(0,0) &amp;=f_{yx}(0,0)=1.
\end{align}&lt;/math&gt;

Substituting these values in to the general formula

:&lt;math&gt;T(x,y) = f(a,b) +(x-a) f_x(a,b) +(y-b) f_y(a,b) +\frac{1}{2!}\Big( (x-a)^2f_{xx}(a,b) + 2(x-a)(y-b)f_{xy}(a,b) +(y-b)^2 f_{yy}(a,b) \Big)+ \cdots&lt;/math&gt;

produces

:&lt;math&gt;\begin{align}
T(x,y) &amp;= 0 + 0(x-0) + 1(y-0) + \frac{1}{2}\Big( 0(x-0)^2 + 2(x-0)(y-0) + (-1)(y-0)^2 \Big) + \cdots \\
&amp;= y + xy - \frac{y^2}{2} + \cdots 
\end{align}&lt;/math&gt;

Since {{math|log(1 + ''y'')}} is analytic in {{math|{{abs|''y''}} &lt; 1}}, we have
:&lt;math&gt;e^x\log(1+y)= y + xy - \frac{y^2}{2} + \cdots, \qquad |y| &lt; 1.&lt;/math&gt;

== Comparison with Fourier series ==
{{main|Fourier series}}
The trigonometric [[Fourier series]] enables one to express a [[periodic function]] (or a function defined on a closed interval {{math|[''a'',''b'']}}) as an infinite sum of [[trigonometric function]]s ([[sine]]s and [[cosine]]s). In this sense, the Fourier series is analogous to Taylor series, since the latter allows one to express a function as an infinite sum of [[power function|powers]]. Nevertheless, the two series differ from each other in several relevant issues:
* Obviously the finite truncations of the Taylor series of {{math|''f''&amp;thinsp;(''x'')}} about the point {{math|''x'' {{=}} ''a''}} are all exactly equal to {{math|''f''}} at {{math|''a''}}. In contrast, the Fourier series is computed by integrating over an entire interval, so there is generally no such point where all the finite truncations of the series are exact.
* Indeed, the computation of Taylor series requires the knowledge of the function on an arbitrary small [[Neighbourhood (mathematics)|neighbourhood]] of a point, whereas the computation of the Fourier series requires knowing the function on its whole domain [[interval (mathematics)|interval]]. In a certain sense one could say that the Taylor series is "local" and the Fourier series is "global".
* The Taylor series is defined for a function which has infinitely many derivatives at a single point, whereas the Fourier series is defined for any [[integrable function|integrable]] function.  In particular, the function could be nowhere differentiable. (For example, {{math|''f''&amp;thinsp;(''x'')}} could be a [[Weierstrass function]].)
* The convergence of both series has very different properties. Even if the Taylor series has positive convergence radius, the resulting series may not coincide with the function; but if the function is analytic then the series converges [[pointwise convergence|pointwise]] to the function, and [[uniform convergence|uniformly]] on every compact subset of the convergence interval. Concerning the Fourier series, if the function is [[Square-integrable function|square-integrable]] then the series converges in [[Convergence in quadratic mean|quadratic mean]], but additional requirements are needed to ensure the pointwise or uniform convergence (for instance, if the function is periodic and of class C&lt;sup&gt;1&lt;/sup&gt; then the convergence is uniform).
* Finally, in practice one wants to approximate the function with a finite number of terms, say with a Taylor polynomial or a partial sum of the trigonometric series, respectively. In the case of the Taylor series the error is very small in a neighbourhood of the point where it is computed, while it may be very large at a distant point. In the case of the Fourier series the error is distributed along the domain of the function.

==See also==
* [[Asymptotic expansion]]
* [[Generating function]]
* [[Laurent series]]
* [[Madhava series]]
* [[Newton polynomial|Newton's divided difference interpolation]]
* [[Padé approximant]]
* [[Puiseux series]]

==Notes==
{{reflist|30em}}

==References==
*{{Citation| last1=Abramowitz| first1=Milton| author1-link=Milton Abramowitz| last2=Stegun| first2=Irene A.| author2-link=Irene Stegun| title=[[Abramowitz and Stegun|Handbook of Mathematical Functions with Formulas, Graphs, and Mathematical Tables]]| publisher=[[Dover Publications]]| location=New York| id=Ninth printing| year=1970| postscript=&lt;!--none--&gt;}}
*{{citation| last1=Thomas|first1=George B., Jr.|last2=Finney|first2=Ross L.| title=Calculus and Analytic Geometry |edition=9th | publisher=Addison Wesley| year=1996| isbn=0-201-53174-7| postscript=&lt;!--none--&gt;}}
*{{citation| last=Greenberg|first=Michael| title=Advanced Engineering Mathematics |edition=2nd | publisher=Prentice Hall| year=1998| isbn=0-13-321431-1| postscript=&lt;!--none--&gt;}}

==External links==
{{Sister project links
|wikt=Taylor series
|commons=Category:Taylor series
|b=Calculus/Taylor series
|v=Taylor's series
|n=no |q=no |s=no |species=no
|d=Q131187}}
* {{springer|title=Taylor series|id=p/t092320}}
* {{MathWorld| urlname= TaylorSeries| title= Taylor Series}}
* [http://blog.ivank.net/taylor-polynomial-clarified.html Taylor polynomial] - practical introduction
* [http://www-groups.dcs.st-and.ac.uk/~history/Projects/Pearce/Chapters/Ch9_3.html Madhava of Sangamagramma ]
* "[http://csma31.csm.jmu.edu/physics/rudmin/ParkerSochacki.htm Discussion of the Parker-Sochacki Method]"
* [https://web.archive.org/web/20070605020930/http://stud3.tuwien.ac.at/~e0004876/taylor/Taylor_en.html Another Taylor visualisation] &amp;mdash; where you can choose the point of the approximation and the number of derivatives
* [http://numericalmethods.eng.usf.edu/topics/taylor_series.html Taylor series revisited for numerical methods] at [http://numericalmethods.eng.usf.edu Numerical Methods for the STEM Undergraduate]
* [http://cinderella.de/files/HTMLDemos/2C02_Taylor.html  Cinderella 2: Taylor expansion]
* [http://www.sosmath.com/calculus/tayser/tayser01/tayser01.html Taylor series]
* [http://www.efunda.com/math/taylor_series/inverse_trig.cfm Inverse trigonometric functions Taylor series]
* {{cite web |title=Essence of Calculus: Taylor series |url=https://www.youtube.com/watch?v=3d6DsjIBzJ4&amp;index=11&amp;list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr |via=[[YouTube]] }}

[[Category:Real analysis]]
[[Category:Complex analysis]]
[[Category:Series expansions]]</text>
      <sha1>lg6q0ghl4per6xv81iwpxpn0im2uu5n</sha1>
    </revision>
  </page>
  <page>
    <title>The Unicist Research Institute</title>
    <ns>0</ns>
    <id>58565905</id>
    <revision>
      <id>868844500</id>
      <parentid>867660899</parentid>
      <timestamp>2018-11-14T20:30:22Z</timestamp>
      <contributor>
        <username>Rosguill</username>
        <id>32763026</id>
      </contributor>
      <comment>Nominated for deletion; see [[:Wikipedia:Articles for deletion/The Unicist Research Institute]]. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10381">&lt;!-- Please do not remove or change this AfD message until the discussion has been closed. --&gt;
{{Article for deletion/dated|page=The Unicist Research Institute|timestamp=20181114203022|year=2018|month=November|day=14|substed=yes|help=off}}
&lt;!-- Once discussion is closed, please place on talk page: {{Old AfD multi|page=The Unicist Research Institute|date=14 November 2018|result='''keep'''}} --&gt;
&lt;!-- End of AfD message, feel free to edit beyond this point --&gt;
{{Infobox company
| name = The Unicist Research Institute
| logo = 
| type = Private [[research institute]]
| industry = {{unbulleted list|[[Research]]|[[Research and Development]]}}
| fate = 
| predecessor = 
| successor = 
| founded = {{Start date and age|1976}}
| former_names  = as an unincorporated association (ASOU – M&amp;T)&lt;br&gt;(1976-2010)
| founder = [[Peter Belohlavek]]
| defunct = &lt;!-- {{End date|YYYY|MM|DD}} --&gt;
| hq_location_city = Adrogue
| hq_location_country = Argentina
| num_locations = 3 research centers
| num_locations_year = 2018
| area_served = Worldwide
| key_people = 
| products = 
| owner = 
| num_employees = 
| num_employees_year = 
| parent = 
| website = {{URL|unicist.org}}
}}

'''The Unicist Research Institute''' is a global decentralized [[research]] boutique, specialized in [[complexity science]], focused on the research of [[complex adaptive systems]] and their applications in the fields of social, institutional and individual [[behavior]]. It was founded in 1976 by [[Peter Belohlavek]] as an unincorporated association that was later transformed into a privately held company.&lt;ref&gt;{{cite web|url=https://www.unicist.org/about-us.php|title=About us|publisher=www.unicist.org|accessdate=2018-09-22}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=https://www.unicist.org/peter-belohlavek.php|title=About the Founder|publisher=www.unicist.org|accessdate=2018-09-22}}&lt;/ref&gt;

With its holding in Delaware, USA and its Research Bunker in Adrogue, Argentina, The Unicist Research Institute has a business arm and an academic arm. Some of its core specialties are the development of [[cognitive systems]], [[social behavior]] labs and educational programs for graduates.&lt;ref&gt;{{cite magazine |last= Ferro|first= María Laura|date=2003-01-05|title= Teoría Unicista: Otra manera de aprender|magazine= Revista Nueva|location= Nº 599, p. 10-12|publisher= Agrupación Diarios del Interior}}&lt;/ref&gt;

==Research==

The framework of the [[complexity science]] [[research]] [[methodology]] used in The Unicist Research Institute is based on [[pragmatism]], [[structuralism]] and [[functionalism (philosophy of mind)|functionalism]].&lt;ref&gt;{{cite magazine |author=&lt;!--Staff writer(s); no by-line.--&gt; |title=Una investigación sobre los impulsores del comportamiento humano|url= |magazine= Mañana Profesional|location=p.27|publisher=Ediciones Mañana Profesional|date= May–June 2013}}&lt;/ref&gt;

The four basic pillars of the [[applied research]] of The Unicist Research Institute were the [[ontogenesis]] of [[evolution]], the anthropological invariables and their evolution, the functionality of the roots of [[human intelligence]], and the double dialectical [[behavior]].&lt;ref&gt;{{cite web |url= https://www.unicist.org/pdf/proceedings_uc091.pdf|title= IX International Unicist Conference: Individual, institutional and social evolution &amp; Strategy|author=&lt;!--Not stated--&gt; |date= January 23–24, 2008|website= www.unicist.org|publisher= The Unicist Research Institute|access-date=2018-09-22|quote=}}&lt;/ref&gt;

==Social applications==

The Future Research Laboratory of The Unicist Research Institute develops future scenarios as the core aspect for social and [[economic development]] plans. In this area, The Unicist Research Institute introduced [[evolutionary economics]] in the [[microeconomics]] driven development program for countries such as [[Argentina]], [[Brazil]], [[Spain]], [[Ukraine]] and the [[United Kingdom]] based on its 40-year [[scenario building]] work in the field.&lt;ref&gt;{{cite news |last= García Bartelt|first= Mercedes|date=2005-05-11|title=Reclaman un mayor apoyo a emprendedores|url=https://www.lanacion.com.ar/703188-reclaman-un-mayor-apoyo-a-emprendedores|work=La Nación|location=Economía|access-date=2018-09-22}}&lt;/ref&gt;&lt;ref&gt;{{cite news |author=&lt;!--Staff writer(s); no by-line.--&gt; |title= Brasil: Sanear para así crecer|url= |work= El Cronista Comercial|location=p.9|date=1990-03-18|access-date= }}&lt;/ref&gt;&lt;ref&gt;{{cite web|url= https://www.unicist-school.org/microeconomics-driven-development/|title= Project on Microeconomics Driven Development - Social Lab|publisher= The Unicist School|accessdate=2018-09-22}}&lt;/ref&gt;&lt;ref&gt;{{cite news |author=&lt;!--Staff writer(s); no by-line.--&gt; |title= Los pueblos cambian gobiernos, y no gobiernos a los pueblos|url= |work= El Día|location= Información Nacional -Uruguay, p.14|date=1989-08-18 |access-date= }}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.adec.org.ar/noticias-institucionales/noticia/1220|title= Conferencia sobre Prospectiva: Construcción de Escenarios Futuros, Regionales y de Negocios|author=&lt;!--Not stated--&gt; |date=2011-10-26|website= |publisher=ADEC: Agencia para el Desarrollo de la ciudad de Córdoba|access-date=2018-09-22}}&lt;/ref&gt;

Some of the main applied researches of the institute include:

* The development of a [[Social Evolution]] Theory that was applied in political strategies. In 1987, the final application was done in the [[political campaign]] for the candidate who won the governors election in the [[San Juan Province, Argentina]].&lt;ref&gt;{{cite book |last= Luchia-Puig|first= Cecilia|date=1989|title= Claves en la conducción empresaria|url= |location= |publisher= Ediciones Macchi|pages=105–116 |isbn=950-537-146-2|author-link= }}&lt;/ref&gt;
* The development of the Unicist Theory of [[Evolution]] that explained the dynamics of [[complex adaptive systems]] allowed developing multiple technologies to deal with [[adaptive behavior]] in social, economic and business entities.&lt;ref&gt;{{cite news |last= Johnson|first= Peter|date=2004-12-16|title= Argentina faces 20-year transition period|url= |work= Buenos Aires Herald|location= |access-date= }}&lt;/ref&gt;&lt;ref&gt;{{cite magazine |author=&lt;!--Staff writer(s); no by-line.--&gt; |title= Peter Belohlavek &amp; The Unicist Research Institute|url= |magazine= Mañana Profesional|location= Segundo Congreso Nacional: Argentina necesita emprendedores. Nº 91, p.9|publisher=Ediciones Mañana Profesional|date= August–September 2005}}&lt;/ref&gt;    In this field, the institute developed social, economic and political scenarios.&lt;ref&gt;{{cite news |author=&lt;!--Staff writer(s); no by-line.--&gt; |title= Economista prevê mudança nos anos 90|url= |work= O Estado de São Paulo|location= Economia, p.4|date=1990-04-05|access-date= }}&lt;/ref&gt;

==The academic arm==

The academic arm of The Unicist Research Institute uses the unicist reflection driven [[education]] approach for graduates, which is homologous to research-based [[learning]] programs, but focused on researching the root causes of complex adaptive environments.&lt;ref&gt;{{cite news |last= Caldas|first= Sérgio Túlio|date=1990-08-30|title= Economista cria centro de estudo empresarial|url= |work= O Estado de São Paulo|location= Economia, p. 9 |access-date= }}&lt;/ref&gt;

In the field of [[Business Education]] this approach is based on learning to manage the concepts and fundamentals that underlie business functions and define the root causes of the problems to manage the root drivers of the solutions.&lt;ref&gt;{{cite magazine |last= Ferro|first= María Laura|date=2003-01-05|title= Teoría Unicista: Otra manera de aprender|magazine= Revista Nueva|location= Nº 599, p. 12|publisher= Agrupación Diarios del Interior}}&lt;/ref&gt;

==The business arm==

Some of the main accomplishments of the institute include:

* The Introduction of an epistemological method to validate [[quantitative research]] results in complex environments. The [[research]] made with American Express on travel expenses in 1988 was the first quantitative research with unicist epistemological validation.&lt;ref&gt;{{cite news |author=&lt;!--Staff writer(s); no by-line.--&gt; |title= Reveladora encuesta de American Express|url= |work= La Nación|location= Economía y Finanzas, p. 15|date=1988-10-31|access-date= }}&lt;/ref&gt;&lt;ref&gt;{{cite news |author=&lt;!--Staff writer(s); no by-line.--&gt; |title= Avanzan los gastos por viajes y representación en Argentina|url= |work= Ambito Financiero|location= p. 7|date=1988-10-28|access-date= }}&lt;/ref&gt;
* The refutation of the traditional [[Law of Demand]] developed at The Unicist Research Institute allowed developing technologies to manage and monitor market [[behavior]].&lt;ref&gt;{{cite magazine |last= Gesualdi|first= Patricia|date= 2013-05-06|title= Refutación a la Teoría de la Demanda|url= |magazine= Mañana University|location= p. 22-23|publisher=Ediciones Mañana Profesional|access-date= }}&lt;/ref&gt;
* The development of predictors in complex market processes to foster growth strategies was included in the first applications of the personalized organization model applied to growth that was used at Diners Club in 1981 &lt;ref&gt;{{cite book |last= Luchia-Puig|first= Cecilia|date=1989|title= Claves en la conducción empresaria|url= |location= |publisher= Ediciones Macchi|pages=25–42|isbn=950-537-146-2|author-link= }}&lt;/ref&gt; and in an adaptive client centered management model in Renault that became a standard for [[business]] optimization in 1985.&lt;ref&gt;{{cite magazine |author=&lt;!--Staff writer(s); no by-line.--&gt; |title= Radiografía del caso Renault|url= |magazine= Noticias|location= Section: Empresas, p. 58-59 |publisher= Editorial Perfil|date=1990-01-14 |access-date= }}&lt;/ref&gt;
* The development of a double dialectical [[logic]] to deal with the dynamics of [[adaptive systems]] led to the development of the unicist [[artificial intelligence]] model as a [[wikt:predictor|predictor]] for [[adaptive behavior]].&lt;ref&gt;{{cite book |last= Belohlavek|first= Peter|date=2006|title= Unicist logic to approach complexity|url= |location= |publisher= Blue Eagle Group|page= |isbn=978-987-1223-57-2|author-link= }}&lt;/ref&gt;

==References==
{{Reflist}}

==External links==

{{commons category|The Unicist Research Institute}}
* [https://www.unicist.org/ The Unicist Research Institute website]

{{DEFAULTSORT:Unicist Research Institute, The}}
[[Category:Research institutes]]
[[Category:Complex systems theory]]
[[Category:Cybernetics]]
[[Category:Think tanks]]</text>
      <sha1>1vujhpzzy5t7b1iso825xcmlyiac56a</sha1>
    </revision>
  </page>
  <page>
    <title>Thomas W. Hawkins Jr.</title>
    <ns>0</ns>
    <id>48152888</id>
    <revision>
      <id>831986786</id>
      <parentid>831863761</parentid>
      <timestamp>2018-03-23T04:11:16Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6388">{{Infobox scientist
| image         = 
| caption       =
| name          = Tom Hawkins
| birth_name    = Thomas William Hawkins Jr.
| birth_date    = {{Birth date and age|1938|1|10|mf=y}}
| birth_place   = [[Flushing, New York]], U.S.
| death_date    = 
| death_place   = 
| nationality   = United States
| work_institution = [[Boston University]]
| alma_mater    = [[University of Wisconsin-Madison]]
| doctoral_advisor = [[Robert Creighton Buck]] &lt;ref name=genealogy&gt;[http://genealogy.math.ndsu.nodak.edu/id.php?id=9057 Tom Hawkins on the Mathematics Genealogy Project.]&lt;/ref&gt;
| major_institutions = 
| fields        = [[History of mathematics]] 
| known_for     = 
| awards        = [[Chauvenet Prize]] &lt;small&gt;(1997)&lt;/small&gt; &lt;ref name=chauvenet&gt;[http://www.maa.org/programs/maa-awards/writing-awards/chauvenet-prizes List of Chauvenet Prize recipients, Mathematical Association of America.]&lt;/ref&gt; &lt;br&gt; [[Albert Leon Whiteman Memorial Prize]] &lt;small&gt;(2001)&lt;/small&gt; &lt;ref name=whiteman&gt;2001 Whiteman Prize [http://www.ams.org/notices/200104/comm-whiteman.pdf (PDF)].&lt;/ref&gt;}}
'''Thomas W. Hawkins Jr.''' (born 10 January 1938 in [[Flushing, New York]]) is an American [[historian of mathematics]].

Hawkins defended his [[Ph.D.]] thesis on ''"The Origins and Early Development of [[Lebesgue integration|Lebesgue's Theory of Integration]]"'' at the [[University of Wisconsin-Madison]] in 1968 under [[Robert Creighton Buck]]. Since 1972 he has been based at [[Boston University]]. Hawkins was an [[invited speaker at the International Congress of Mathematicians]] in 1974 at [[Vancouver]]&lt;ref&gt;{{cite book|author=Hawkins, Thomas|chapter=The theory of matrices in the 19th century|title=''In:'' Proceedings of the International Congress of Mathematicians, Vancouver, 1974|volume=vol. 2|pages=561–570|chapter-url=https://pdfs.semanticscholar.org/fcc9/fd95a28a2f239f16be9d162d155a74fd09e8.pdf}}&lt;/ref&gt; and in 1986 at [[Berkeley, California|Berkeley]].

In 1997 Hawkins was awarded the [[Chauvenet Prize]] for his article ''"The birth of [[Sophus Lie|Lie's]] theory of [[Lie groups|groups]]"'',&lt;ref name=liepaper&gt;{{cite journal |last= Hawkins
|first= Thomas W.
|date= 1994
|title= The birth of Lie's theory of groups
|url= https://dx.doi.org/10.1007/BF03024278
|journal= [[Mathematical Intelligencer]]
|publisher= [[Springer Science+Business Media|Springer]]
|volume= 16
|issue= 2
|pages= 6–17
|doi= 10.1007/BF03024278
|access-date=13 August 2016}}&lt;/ref&gt; published in the [[Mathematical Intelligencer]] in 1994.&lt;ref name=chauvenet/&gt; In fall 2012 Hawkins was elected a Fellow of the [[American Mathematical Society]].

==Selected publications==
===Articles===
* ''The Theory of Matrices in the 19th Century''. In: [[Ralph Duncan James|Ralph D. James]] (ed.): ''Proceedings of the International Congress of Mathematicians, Vancouver, 1974''. CMC, Vancouver 1975, vol. 2, {{ISBN|0-919558-04-6}}, pp. 561–570.
* ''Hypercomplex numbers, Lie groups and the creation of group representation theory''. In: ''Archive for History of Exact Sciences'', vol. 8 (1971/72), {{ISSN|0003-9519}}, pp. 243–287. {{doi|10.1007/BF00328434}}
* ''The origins of the theory of group characters''. In: ''Archive for History of Exact Sciences'', vol. 7 (1970), {{ISSN|0003-9519}}, pp. 142–170. {{jstor|41133320}}
* ''New light on Frobenius creation of the theory of group characters''. In: ''Archive for History of Exact Sciences'', vol. 12 (1974), {{ISSN|0003-9519}}, pp. 217–243. {{doi|10.1007/BF00357245}}
* ''Wilhelm Killing and the structure of Lie algebras''. In: ''Archive for History of Exact Science'', vol. 26 (1982), {{ISSN|0003-9519}}, pp. 126–192. {{doi|10.1007/BF00348350}}
* ''Non-euclidean geometry and Weierstrassian mathematics. The background to Killing's work on Lie algebras''. In: ''[[Historia Mathematica]]'', vol. 7 (1980), {{ISSN|0315-0860}}, pp. 289–342. {{doi|10.1016/0315-0860(80)90027-0}}
===Books===
* [https://books.google.com/books/about/Emergence_of_the_Theory_of_Lie_Groups.html?id=QbB7_YOrruoC ''Emergence of the theory of Lie groups. An Essay in the history of Mathematics 1869-1926''] (Sources and studies in the history of mathematics and physical series). Springer Verlag, New York 2000, {{ISBN|0-387-98963-3}}.&lt;ref&gt;{{cite journal|author=Rowe, David E.|authorlink=David E. Rowe|title=Book Review: ''Emergence of the Theory of Lie Groups''|journal=Notices of the American Mathematical Society|volume=50|issue=6|year=2003|pages=668–677|url=https://www.ams.org/notices/200306/rev-rowe.pdf}}&lt;/ref&gt;
* ''Lebesgue's Theory of Integration. Its Origin and Development''. 2nd edition. AMS Chelsea Books, New York 1979, {{ISBN|0-8284-0282-5}}; reprint with corrections of original edition published by University of Wisconsin Press 1970;&lt;ref&gt;{{cite journal|title=Review of ''Lebesgue's Theory of Integration'' by Thomas Hawkins; ''A History of Vector Analysis'' by Michael J. Crowe; ''The Development of the Foundations of Mathematical Analysis from Euler to Riemann'' by I. Grattan-Guinness; ''Die Genesis des abstrakten Gruppenbegriffes'' by Hans Wussing|authorlink=William C. Waterhouse|author=Waterhouse, William C.|journal=Bull. Amer. Math. Soc. (N.S.)|volume=78|year=1972|pages=385–391|doi=10.1090/S0002-9904-1972-12909-4}}&lt;/ref&gt; {{cite book|title=reprint of 2nd edition|year=2001|publisher=AMS Chelsea Books|url=https://books.google.com/books/about/Lebesgue_s_Theory_of_Integration.html?id=oV1aLqag6WwC}}
* [https://books.google.com/books/about/The_Mathematics_of_Frobenius_in_Context.html?id=UzTBBAAAQBAJ ''The mathematics of Frobenius in context. A journey through 18th to 20th century mathematics'']. Springer, New York 2013, {{ISBN|978-1-4614-6332-0}}.&lt;ref&gt;{{cite web|author=Roberts, David P.|title=Review of ''The mathematics of Frobenius in context''|website=MAA Reviews, Mathematical Association of America|date=12 October 2014|url=https://www.maa.org/press/maa-reviews/the-mathematics-of-frobenius-in-context-a-journey-through-18th-to-20th-century-mathematics}}&lt;/ref&gt;

==References==
{{Reflist}}

{{Chauvenet Prize recipients}}

{{Authority control}}

{{DEFAULTSORT:Hawkins, Thomas W. Jr.}}
[[Category:1938 births]]
[[Category:University of Wisconsin&amp;ndash;Madison alumni]]
[[Category:Boston University faculty]]
[[Category:Historians of mathematics]]
[[Category:Living people]]
[[Category:Fellows of the American Mathematical Society]]


{{US-historian-stub}}</text>
      <sha1>83v3rim6yuwb0ega2pub6khkhp93pyy</sha1>
    </revision>
  </page>
  <page>
    <title>Type checking</title>
    <ns>0</ns>
    <id>333950</id>
    <redirect title="Type system" />
    <revision>
      <id>784026774</id>
      <parentid>309720032</parentid>
      <timestamp>2017-06-06T01:49:29Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{Redirect category shell}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="123">#REDIRECT [[Type system#Type checking]]

{{Redirect category shell|1=
{{R with possibilities}}
}}

[[Category:type theory]]</text>
      <sha1>m8oqzk1di8uf2zt2go58rnusn3ymzcd</sha1>
    </revision>
  </page>
  <page>
    <title>Weird number</title>
    <ns>0</ns>
    <id>321930</id>
    <revision>
      <id>848491573</id>
      <parentid>838385803</parentid>
      <timestamp>2018-07-02T07:27:07Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* Properties */ ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4873">{{Dablink|The term "weird number" also refers to [[Two's complement#Most negative number|a phenomenon in two's complement arithmetic]].}}

In [[number theory]], a '''weird number''' is a [[natural number]] that is [[abundant number|abundant]] but not [[semiperfect number|semiperfect]].&lt;ref&gt;
{{cite journal
  | last =Benkoski
  | first =Stan
  | authorlink =
  | coauthors =
  | title =E2308 (in Problems and Solutions)
  | journal =The American Mathematical Monthly
  | volume =79
  | issue =7
  | page =774
  | date =August–September 1972
  | doi =10.2307/2316276
  | jstor =2316276
}}&lt;/ref&gt;&lt;ref&gt;{{cite book|author=Richard K. Guy|authorlink=Richard K. Guy|title=Unsolved Problems in Number Theory|publisher=[[Springer-Verlag]]|year=2004|isbn=0-387-20860-7|oclc=54611248}}  Section B2.&lt;/ref&gt;
In other words, the sum of the proper [[divisor]]s (divisors including 1 but not itself) of the number is greater than the number, but no [[subset]] of those divisors sums to the number itself.

== Examples ==

The smallest weird number is 70. Its proper divisors are 1, 2, 5, 7, 10, 14, and 35; these sum to 74, but no subset of these sums to 70. The number 12, for example, is abundant but ''not'' weird, because the proper divisors of 12 are 1, 2, 3, 4, and 6, which sum to 16; but 2+4+6 = 12.

The first few weird numbers are 
: [[70 (number)|70]], [[836 (number)|836]], 4030, 5830, 7192, 7912, 9272, 10430, 10570, 10792, 10990, 11410, 11690, 12110, 12530, 12670, 13370, 13510, 13790, 13930, 14770, ... {{OEIS|id=A006037}}.

== Properties ==
{{unsolved|mathematics|Are there any odd weird numbers?}}
Infinitely many weird numbers exist.&lt;ref&gt;{{cite book | editor1-last=Sándor | editor1-first=József | editor2-last=Mitrinović | editor2-first=Dragoslav S. | editor3-last=Crstici |editor3-first=Borislav | title=Handbook of number theory I | location=Dordrecht | publisher=[[Springer-Verlag]] | year=2006 | isbn=1-4020-4215-9 | zbl=1151.11300 | pages=113–114}}&lt;/ref&gt; For example, 70''p'' is weird for all primes ''p'' ≥ 149. In fact, the set of weird numbers has positive [[asymptotic density]].&lt;ref name="benk1"&gt;
{{cite journal
  | last1=Benkoski
  | first1=Stan
  | author2-link=Paul Erdős
  | first2=Paul | last2=Erdős
  | title =On Weird and Pseudoperfect Numbers
  | journal =[[Mathematics of Computation]]
  | volume =28
  | issue =126
  | pages =617–623
  | date=April 1974
  | doi =10.2307/2005938
  | zbl=0279.10005 | mr=347726
}}
&lt;/ref&gt;

It is not known if any odd weird numbers exist. If so, they must be greater than 10&lt;sup&gt;21&lt;/sup&gt;.&lt;ref&gt;{{Cite OEIS|1=A006037|2=Weird numbers: abundant (A005101) but not pseudoperfect (A005835)}} -- comments concerning odd weird numbers&lt;/ref&gt;

[[Sidney Kravitz]] has shown that for ''k'' a positive integer, ''Q'' a [[prime number|prime]] exceeding 2&lt;sup&gt;''k''&lt;/sup&gt;, and
:&lt;math&gt;R=\frac{2^kQ-(Q+1)}{(Q+1)-2^k}&lt;/math&gt;;
also prime and greater than 2&lt;sup&gt;''k''&lt;/sup&gt;, then
:&lt;math&gt;n=2^{k-1}QR&lt;/math&gt;
is a weird number.&lt;ref&gt;
{{cite journal
  | last=Kravitz
  | first=Sidney
  | title=A search for large weird numbers
  | journal=Journal of Recreational Mathematics
  | volume=9
  | issue=2
  | pages=82–85
  | publisher=Baywood Publishing 
  | location=
  | year=1976
  | zbl=0365.10003 
}}&lt;/ref&gt;
With this formula, he found a large weird number
:&lt;math&gt;n=2^{56}\cdot(2^{61}-1)\cdot153722867280912929\ \approx\ 2\cdot10^{52}&lt;/math&gt;.

===Primitive weird numbers===
A property of weird numbers is that if ''n'' is weird, and ''p'' is a prime greater than the sum of divisors σ(''n''), then ''pn'' is also weird.&lt;ref name=benk1/&gt; This leads to the definition of ''primitive weird numbers'', i.e. weird numbers that are not multiple of other weird numbers {{OEIS|id=A002975}}. There are only 24 primitive weird numbers smaller than a million, compared to 1765 weird numbers up to that limit. The construction of Kravitz yields primitive weird numbers, since all weird numbers of the form &lt;math&gt;2^k p q&lt;/math&gt; are primitive, but the existence of infinitely many ''k'' and ''Q'' which yield a prime ''R'' is not guaranteed. It is conjectured that there exist infinitely many primitive numbers, and [[Giuseppe Melfi|Melfi]] has shown that the infiniteness of primitive weird numbers is a consequence of [[Cramér's conjecture]].&lt;ref&gt;
{{cite journal
  | last =Melfi
  | first =Giuseppe
  | title =On the conditional infiniteness of primitive weird numbers
  | journal =Journal of Number Theory
  | volume =147
  | issue =
  | pages = 508–514
  | publisher =Elsevier
  | location =
  | year =2015
  | doi= 10.1016/j.jnt.2014.07.024
  | zbl= 
}}&lt;/ref&gt;

==See also==
* [[Untouchable number]]

==References==
{{Reflist}}

== External links ==
{{portal|Mathematics}}
* {{MathWorld |urlname=WeirdNumber |title=Weird number}}

{{Divisor classes}}

{{DEFAULTSORT:Weird Number}}
[[Category:Divisor function]]
[[Category:Integer sequences]]</text>
      <sha1>qad31r1fmumj8521s6n4azvv1pvcnxn</sha1>
    </revision>
  </page>
  <page>
    <title>Young measure</title>
    <ns>0</ns>
    <id>9659484</id>
    <revision>
      <id>795244318</id>
      <parentid>793686280</parentid>
      <timestamp>2017-08-12T23:37:49Z</timestamp>
      <contributor>
        <username>Quinton Feldberg</username>
        <id>29380370</id>
      </contributor>
      <minor/>
      <comment>fix citations</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4670">In [[mathematical analysis]], a '''Young measure''' is a parameterized [[measure (mathematics)|measure]] that is associated with certain subsequences of a given bounded sequence of measurable functions.  Young measures have applications in the [[calculus of variations]] and the study of [[nonlinear]] [[partial differential equations]], as well as in various [[optimization]] (or [[optimal control]] problems).  They are named after [[Laurence Chisholm Young]] who invented them, however, in terms of linear functionals already in 1937 still before the [[measure theory]] has been developed.

==Definition==

We let &lt;math&gt;\{ f_k \}_{k=1}^\infty&lt;/math&gt; be a bounded sequence in &lt;math&gt;L^\infty (U,\mathbb{R}^m)&lt;/math&gt;, where &lt;math&gt;U&lt;/math&gt; denotes an open bounded subset of &lt;math&gt;\mathbb{R}^n&lt;/math&gt;. Then there exists a subsequence &lt;math&gt;\{ f_{k_j} \}_{j=1}^\infty \subset \{ f_k \}_{k=1}^\infty&lt;/math&gt; and for almost every &lt;math&gt;x \in U&lt;/math&gt; a [[Borel measure|Borel probability measure]] &lt;math&gt;\nu_x&lt;/math&gt; on &lt;math&gt;\mathbb{R}^m&lt;/math&gt; such that for each &lt;math&gt;F \in C(\mathbb{R}^m)&lt;/math&gt; we have &lt;math&gt;F \circ f_{k_j} \overset{\ast}{\rightharpoonup} \int_{\mathbb{R}^m} F(y)d\nu_\cdot(y)&lt;/math&gt; in &lt;math&gt;L^\infty (U)&lt;/math&gt;. The measures &lt;math&gt;\nu_x&lt;/math&gt; are called the Young measures generated by the sequence &lt;math&gt;\{ f_k \}_{k=1}^\infty&lt;/math&gt;.

==Example==

For every minimizing sequence &lt;math&gt;u_n&lt;/math&gt;  of &lt;math&gt;I(u) = \int_0^1 (u_x^2-1)^2 + u^2dx&lt;/math&gt; subject to &lt;math&gt;u(0)=u(1)=0&lt;/math&gt; , the sequence of derivatives &lt;math&gt;u'_n&lt;/math&gt; generates the Young measures &lt;math&gt;\nu_x= \frac{1}{2} \delta_{-1} + \frac{1}{2}\delta_1&lt;/math&gt;. This captures the essential features of all minimizing sequences to this problem, namely developing finer and finer slopes of &lt;math&gt;\pm 1&lt;/math&gt; (or close to
&lt;math&gt;\pm 1&lt;/math&gt;).

==References==

* {{cite book |last1=Ball |first1=J. M. |year=1989 |chapter=A version of the fundamental theorem for Young measures |editor1-last=Rascle |editor1-first=M. |editor2-last=Serre |editor2-first=D. |editor3-last=Slemrod |editor3-first=M. |title=PDEs and Continuum Models of Phase Transition |series=[[Lecture Notes in Physics]] |volume=344 |location=Berlin |publisher=Springer |pages=207–215}}
* {{cite book | author=C.Castaing, P.Raynaud de Fitte, M.Valadier | title=Young measures on topological spaces| publisher=Kluwer |location=Dordrecht | year=2004}}
* {{cite book | author=L.C. Evans | title=Weak convergence methods for nonlinear partial differential equations  | series=Regional conference series in mathematics | publisher=[[American Mathematical Society]] | year=1990 }}
* {{cite book | author=S. Müller | url=http://www.mis.mpg.de/publications/other-series/ln/lecturenote-0298.html |title=Variational models for microstructure and phase transitions  | series=Lecture Notes in Mathematics | publisher=[[Springer Science+Business Media|Springer]] | year=1999 }}
* {{cite book | author=P. Pedregal  | title=Parametrized Measures and Variational Principles| publisher=Birkhäuser |location=Basel|year=1997|isbn=978-3-0348-9815-7}}
* {{cite book|title=Relaxation in Optimization Theory and Variational Calculus
|author=T. Roubíček|publisher=W. de Gruyter|location=Berlin|year=1997|isbn=3-11-014542-1}}

* {{cite book |last1=Valadier |first1=M. |year=1990 |chapter=Young measures |title=Methods of Nonconvex Analysis |series=[[Lecture Notes in Mathematics]] |volume=1446 |location=Berlin |publisher=Springer |pages=152–188}}
*{{Citation
  | last = Young
  | first = L. C.
  | author-link =
  | title = Generalized curves and the existence of an attained absolute minimum in the Calculus of Variations
  | journal = [[Comptes Rendus des Séances de la Société des Sciences et des Lettres de Varsovie]]
  | volume = XXX
  | series =Classe III
  | issue = 7–9
  | pages = 211–234
  | year=1937
  | url=http://rcin.org.pl/dlibra/editions-content?id=69114
  | jfm =63.1064.01
  | zbl =0019.21901
}}, memoir presented by [[Stanisław Saks]] at the session of 16 December 1937 of the [[Warsaw Society of Sciences and Letters]]. The free [[PDF]] copy is made available by the [http://rcin.org.pl/dlibra RCIN –Digital Repository of the Scientifics Institutes].
*{{Citation
 | last = Young
 | first = L. C.
 | author-link = 
 | title = Lectures on the Calculus of Variations and Optimal Control
 | place = Philadelphia–London–Toronto
 | publisher = [[W. B. Saunders]]
 | year = 1969
 | pages = xi+331
 | url = https://books.google.com/?id=YQpRAAAAMAAJ
 | doi =
 | id =
 | isbn =
 | mr = 0259704
 | zbl = 0177.37801
}}.

==External links==
* {{springer|title=Young measure|id=p/y120040}}

[[Category:Measure theory]]</text>
      <sha1>bc8xdj6v5hvakra7uwof1cobca4zw21</sha1>
    </revision>
  </page>
</mediawiki>
