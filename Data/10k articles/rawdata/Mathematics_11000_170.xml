<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>122 (number)</title>
    <ns>0</ns>
    <id>831517</id>
    <revision>
      <id>859047241</id>
      <parentid>859035753</parentid>
      <timestamp>2018-09-11T10:48:29Z</timestamp>
      <contributor>
        <username>Gap9551</username>
        <id>8367391</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/175.157.207.247|175.157.207.247]] ([[User talk:175.157.207.247|talk]]) to last version by Arthur Rubin</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1344">{{Infobox number
| number = 122
| divisor = 1, 2, 61, 122
}}

'''122''' ('''one hundred [and] twenty-two''') is the natural number following [[121 (number)|121]] and preceding [[123 (number)|123]].

==In mathematics==
It is a [[nontotient]] since there is no integer with exactly 122 [[coprime]]s below it. Nor is there an integer with exactly 122 integers with common factors below it, making 122 a [[noncototient]].

==In telephony==
* The fire [[emergency telephone number]] in [[Austria]]&lt;ref&gt;{{cite book |title=Frommer's Austria |last=Porter |first=Darwin |author2=Danforth Prince |year=2009 |publisher=Frommer's |location=Hoboken, New Jersey |isbn=978-0-470-39897-5 |page=482 }}&lt;/ref&gt;
* The police [[emergency telephone number]] in [[Egypt]]
* The traffic [[emergency telephone number]] in [[China]]
* The police [[emergency telephone number]] in [[Bosnia and Herzegovina]]

==In other fields==
122 is also:
* The [[atomic number]] of the [[chemical element]] [[unbibium]] 
* The number of men of [[Michmas]] at the census ([[Bible]], [[Nehemiah]] 7:31)
* The Enroute Flight Advisory Service (EFAS) "[[Flight watch]]" frequency: 122.0 MHz

==See also==
* [[List of highways numbered 122]]
* [[United Nations Security Council Resolution 122]]

==References==

{{reflist}}

{{Integers|1}}

{{DEFAULTSORT:122 (Number)}}
[[Category:Integers]]</text>
      <sha1>1lv0o2w97ymy5yfj4nn7yhmcgvifjye</sha1>
    </revision>
  </page>
  <page>
    <title>Annals of the Institute of Statistical Mathematics</title>
    <ns>0</ns>
    <id>43488947</id>
    <revision>
      <id>869850858</id>
      <parentid>857963690</parentid>
      <timestamp>2018-11-20T19:57:09Z</timestamp>
      <contributor>
        <username>IntoThinAir</username>
        <id>18336458</id>
      </contributor>
      <minor/>
      <comment>update if</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1837">{{Infobox journal
| title = Annals of the Institute of Statistical Mathematics
| editor = [[Tomoyuki Higuchi (statistician)|Tomoyuki Higuchi]]
| discipline = [[Statistics]]
| abbreviation = Ann. Inst. Stat. Math.
| mathscinet= Ann. Inst. Statist. Math.
| publisher = [[Springer Science+Business Media]] on behalf of the [[Institute of Statistical Mathematics]]
| country =
| frequency = Bimonthly
| history = 1949–present
| openaccess = [[Hybrid open access journal|Hybrid]]
| impact = 0.733
| impact-year = 2017
| website = https://www.springer.com/statistics/journal/10463
| link2 = https://link.springer.com/journal/volumesAndIssues/10463
| link2-name = Online archive
| ISSN = 0020-3157
| eISSN = 1572-9052
| OCLC = 41554827
| CODEN =AISXAD
| LCCN = 60018576
}}
'''''Annals of the Institute of Statistical Mathematics''''' is a bimonthly [[peer-reviewed]] [[scientific journal]] covering [[statistics]]. It was established in 1949 and is published by [[Springer Science+Business Media]] on behalf of [[Institute of Statistical Mathematics]]. The [[editor-in-chief]] is Tomoyuki Higuchi (Institute of Statistical Mathematics). According to the ''[[Journal Citation Reports]]'', the journal has a 2017 [[impact factor]] of 0.733.&lt;ref name=WoS&gt;{{cite book |year=2018 |chapter=Annals of the Institute of Statistical Mathematics |title=2017 [[Journal Citation Reports]] |publisher=[[Thomson Reuters]] |edition=Science |series=[[Web of Science]] |postscript=.}}&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* {{Official website|https://www.springer.com/statistics/journal/10463}}

[[Category:Statistics journals]]
[[Category:Publications established in 1949]]
[[Category:Bimonthly journals]]
[[Category:Springer Science+Business Media academic journals]]
[[Category:English-language journals]]


{{mathematics-journal-stub}}</text>
      <sha1>dsezxgt1q55djm98ny8jzik9tv1zhhd</sha1>
    </revision>
  </page>
  <page>
    <title>Apollonian sphere packing</title>
    <ns>0</ns>
    <id>13129755</id>
    <revision>
      <id>772407198</id>
      <parentid>772407091</parentid>
      <timestamp>2017-03-27T02:44:02Z</timestamp>
      <contributor>
        <username>Julyo</username>
        <id>171844</id>
      </contributor>
      <comment>Adding/improving reference(s): switched order of original and archived URLs</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1453">[[Image:Apollonian spheres.jpg|thumb|right|Apollonian sphere packing]]

'''Apollonian [[sphere packing]]''' is the three-dimensional equivalent of the [[Apollonian gasket]]. The principle of construction is very similar: with any four spheres that are cotangent to each other, it is then possible to construct two more spheres that are cotangent to four of them.

The [[fractal dimension]] is approximately 2.473946 (±1 in the last digit).&lt;ref&gt;{{Citation
 | first =M.
 | last =Borkovec
 | first2 = W. 
 | last2 =De Paris
 |first3 = R.
 |last3= Peikert
 | author-link =
 | publication-date =
 | date =
 | year = 1994
 | title =The Fractal Dimension of the Apollonian Sphere Packing
 | periodical = Fractals
 | series =
 | publication-place =
 | place =
 | publisher =
 | volume =2
 | issue =4
 | pages =521–526
 | url = http://www.scivis.ethz.ch/publications/pdf/1994/borkovec1994fractal.pdf
 | archiveurl = https://web.archive.org/web/20160506190118/http://www.scivis.ethz.ch/publications/pdf/1994/borkovec1994fractal.pdf
 | archivedate = 2016-05-06
 | issn =
 | doi =10.1142/S0218348X94000739
 | oclc =
 | accessdate =2008-09-15
}}&lt;/ref&gt;

Software for generating and visualization of the apollonian sphere packing: ApolFrac.&lt;ref&gt;[http://thomasbonner.altervista.org/apolfrac.htm ApolFrac]&lt;/ref&gt;

==References==
&lt;references/&gt;

{{Packing problem}}

[[Category:Fractals]]
[[Category:Hyperbolic geometry]]
[[Category:Packing problems]]

{{geometry-stub}}</text>
      <sha1>du8tns9pib0q762dnmhpn340g0eg9t7</sha1>
    </revision>
  </page>
  <page>
    <title>Artin–Rees lemma</title>
    <ns>0</ns>
    <id>9553854</id>
    <revision>
      <id>801225749</id>
      <parentid>800107400</parentid>
      <timestamp>2017-09-18T13:05:18Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>/* top */ original paper of Rees, as cited by Sharp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4855">In [[mathematics]], the '''Artin&amp;ndash;Rees lemma''' is a basic result about [[module (mathematics)|module]]s over a [[Noetherian ring]], along with results such as the [[Hilbert basis theorem]]. It was proved in the 1950s in independent works by the [[mathematician]]s [[Emil Artin]] and [[David Rees (mathematician)|David Rees]];&lt;ref&gt;{{cite journal|author=David Rees|date=1956 |title=Two classical theorems of ideal theory|journal= Proc. Camb. Phil. Soc.|volume= 52|pages= 155-157}} Here: Lemma 1&lt;/ref&gt;&lt;ref&gt;[https://rsbm.royalsocietypublishing.org/content/roybiogmem/early/2015/06/18/rsbm.2015.0010.full.pdf David Rees' obituary] by R.Y. Sharp, [[Royal Society]]. Here: Sect.7, Lemma 7.2, p.10&lt;/ref&gt; a special case was known to [[Oscar Zariski]] prior to their work.

One consequence of the lemma is the [[Krull intersection theorem]]. The result is also used to prove the exactness property of [[completion (ring theory)|completion]] {{harv|Atiyah|MacDonald|1969|pp=107–109}}.

==Statement ==
Let ''I'' be an [[ideal (ring theory)|ideal]] in a [[Noetherian ring]] ''R''; let ''M'' be a [[finitely generated module|finitely generated ''R''-module]] and let ''N'' a submodule of ''M''. Then there exists an integer ''k''&amp;nbsp;≥&amp;nbsp;1 so that, for ''n''&amp;nbsp;≥&amp;nbsp;''k'',

:&lt;math&gt;I^{n} M \cap N = I^{n - k} ((I^{k} M) \cap N).&lt;/math&gt;

== Proof ==
The lemma immediately follows from the fact that ''R'' is Noetherian once necessary notions and notations are set up.&lt;ref&gt;{{harvnb|Eisenbud|loc=Lemma 5.1}}&lt;/ref&gt;

For any ring ''R'' and an ideal ''I'' in ''R'', we set &lt;math&gt;B_I R = \textstyle\bigoplus_{n=0}^\infty I^n&lt;/math&gt; (''B'' for blow-up.) We say a decreasing sequence of submodules &lt;math&gt;M = M_0 \supset M_1 \supset M_2 \supset \cdots&lt;/math&gt; is an ''I''-filtration if &lt;math&gt;I M_n \subset M_{n+1}&lt;/math&gt;; moreover, it is stable if &lt;math&gt;I M_n = M_{n+1}&lt;/math&gt; for sufficiently large ''n''. If ''M'' is given an ''I''-filtration, we set &lt;math&gt;B_I M = \textstyle\bigoplus_{n=0}^\infty M_n&lt;/math&gt;; it is a [[graded module]] over &lt;math&gt;B_I R&lt;/math&gt;.

Now, let ''M'' be a ''R''-module with the ''I''-filtration &lt;math&gt;M_i&lt;/math&gt; by finitely generated ''R''-modules. We make an observation
:&lt;math&gt;B_I M&lt;/math&gt; is a finitely generated module over &lt;math&gt;B_I R&lt;/math&gt; if and only if the filtration is ''I''-stable.
Indeed, if the filtration is ''I''-stable, then &lt;math&gt;B_I M&lt;/math&gt; is generated by the first &lt;math&gt;k+1&lt;/math&gt; terms &lt;math&gt;M_0, \dots, M_k&lt;/math&gt; and those terms are finitely generated; thus, &lt;math&gt;B_I M&lt;/math&gt; is finitely generated. Conversely, if it is finitely generated, say, by some homogeneous elements in &lt;math&gt;\textstyle\bigoplus_{j=0}^k M_j&lt;/math&gt;, then, for &lt;math&gt;n \ge k&lt;/math&gt;, each ''f'' in &lt;math&gt;M_n&lt;/math&gt; can be written as
:&lt;math&gt;f = \sum a_{j} g_{j}, \quad a_{j} \in I^{n-j}&lt;/math&gt;
with the generators &lt;math&gt;g_{j}&lt;/math&gt; in &lt;math&gt;M_j, j \le k&lt;/math&gt;. That is, &lt;math&gt;f \in I^{n-k} M_k&lt;/math&gt;.

We can now prove the lemma, assuming ''R'' is Noetherian. Let &lt;math&gt;M_n = I^n M&lt;/math&gt;. Then &lt;math&gt;M_n&lt;/math&gt; are an ''I''-stable filtration. Thus, by the observation, &lt;math&gt;B_I M&lt;/math&gt; is finitely generated over &lt;math&gt;B_I R&lt;/math&gt;. But &lt;math&gt;B_I R \simeq R[It]&lt;/math&gt; is a Noetherian ring since ''R'' is. (The ring &lt;math&gt;R[It]&lt;/math&gt; is called the [[Rees algebra]].) Thus, &lt;math&gt;B_I M&lt;/math&gt; is a Noetherian module and any submodule is finitely generated over &lt;math&gt;B_I R&lt;/math&gt;; in particular, &lt;math&gt;B_I N&lt;/math&gt; is finitely generated when ''N'' is given the induced filtration; i.e., &lt;math&gt;N_n = M_n \cap N&lt;/math&gt;. Then the induced filtration is ''I''-stable again by the observation.

== Proof of Krull's intersection theorem ==
Besides the use in completion of a ring, a typical application of the lemma is the proof of the Krull's intersection theorem, which says: &lt;math&gt;\textstyle\bigcap_{n=1}^\infty I^n = 0&lt;/math&gt; for a proper ideal ''I'' in a commutative Noetherian local ring. By the lemma applied to the intersection &lt;math&gt;N&lt;/math&gt;, we find ''k'' such that for &lt;math&gt;n \ge k&lt;/math&gt;,
::&lt;math&gt;I^{n} \cap N = I^{n - k} (I^{k} \cap N).&lt;/math&gt;
But then &lt;math&gt;N = IN&lt;/math&gt; and thus &lt;math&gt;N = 0&lt;/math&gt; by [[Nakayama's lemma|Nakayama]].

==References==
{{reflist}}
*{{Citation | last1=Atiyah | first1=Michael Francis | author1-link=Michael Atiyah | last2=Macdonald | first2=I.G. | author2-link=Ian G. Macdonald | title=Introduction to Commutative Algebra | publisher=Westview Press | isbn=978-0-201-40751-8 | year=1969}}
* [[David Eisenbud|Eisenbud, David]], ''Commutative Algebra with a View Toward Algebraic Geometry'', Graduate Texts in Mathematics, 150, Springer-Verlag, 1995, {{ISBN|0-387-94268-8}}.

==External links==
* {{planetmath reference|id=2963|title=Artin-Rees Theorem}}

{{DEFAULTSORT:Artin-Rees lemma}}
[[Category:Commutative algebra]]
[[Category:Lemmas]]
[[Category:Module theory]]
[[Category:Ring theory]]</text>
      <sha1>fqmq8ltaqpmcz9er95vxf4pw5sbvua2</sha1>
    </revision>
  </page>
  <page>
    <title>Bhaskara I's sine approximation formula</title>
    <ns>0</ns>
    <id>27060913</id>
    <revision>
      <id>863714544</id>
      <parentid>863714512</parentid>
      <timestamp>2018-10-12T14:51:17Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>fix</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11378">{{Use dmy dates|date=June 2013}}
In [[mathematics]], '''Bhaskara I's sine approximation formula''' is a [[rational fraction|rational expression]] in one [[Variable (mathematics)|variable]] for the [[computation]] of the [[approximation|approximate value]]s of the [[sine|trigonometric sine]]s discovered by [[Bhaskara I]] (c. 600 – c. 680), a seventh-century Indian [[mathematician]].&lt;ref name="mcs"&gt;{{Cite web|url=http://www-history.mcs.st-and.ac.uk/Biographies/Bhaskara_I.html|title=Bhaskara I|last=J J O'Connor and E F Robertson|date = November 2000|publisher=School of Mathematics and Statistics University of St Andrews, Scotland |accessdate=22 April 2010| archiveurl= https://web.archive.org/web/20100323052236/http://www-history.mcs.st-and.ac.uk/Biographies/Bhaskara_I.html| archivedate= 23 March 2010 &lt;!--DASHBot--&gt;| deadurl= no}}&lt;/ref&gt;
This [[formula]] is given in his treatise titled ''Mahabhaskariya''. It is not known how Bhaskara I arrived at his approximation formula. However, several [[historian]]s of [[mathematics]] have put forward different hypotheses as to the method Bhaskara might have used to arrive at his formula. The formula is elegant, simple and enables one to compute reasonably accurate values of trigonometric sines without using any geometry whatsoever.&lt;ref name="Brummelen"/&gt;

==The approximation formula==
The formula is given in verses 17 &amp;ndash; 19, Chapter VII, Mahabhaskariya of Bhaskara I. A translation of the verses is given below:&lt;ref name="Gupta"&gt;{{Cite journal|last=R.C. Gupta|year=1967|title=Bhaskara I' approximation to sine|journal=Indian Journal of History of Science|volume=2|issue=2|url=http://www.new.dli.ernet.in/rawdataupload/upload/insa/INSA_1/20005af0_121.pdf|accessdate=20 April 2010|deadurl=yes|archiveurl=https://web.archive.org/web/20120316083451/http://www.new.dli.ernet.in/rawdataupload/upload/insa/INSA_1/20005af0_121.pdf|archivedate=16 March 2012|df=dmy-all}}&lt;/ref&gt;

*(Now) I briefly state the rule (for finding the ''bhujaphala'' and the ''kotiphala'', etc.) without making use of the Rsine-differences 225, etc. Subtract the degrees of a ''bhuja'' (or ''koti'') from the degrees of a half circle (that is, 180 degrees). Then multiply the remainder by the degrees of the ''bhuja'' or ''koti'' and put down the result at two places. At one place subtract the result from 40500. By one-fourth of the remainder (thus obtained),  divide the result at the other place as multiplied by the '''anthyaphala'' (that is, the epicyclic radius). Thus is obtained the entire ''bahuphala'' (or, ''kotiphala'') for the sun, moon or the star-planets. So also are obtained the direct and inverse Rsines.

(The reference "Rsine-differences 225" is an allusion to [[Aryabhata's sine table]].)

In modern mathematical notations, for an angle ''x'' in degrees, this formula gives&lt;ref name="Gupta"/&gt;

:&lt;math&gt; \sin x^\circ = \frac{4 x (180-x)}{40500 - x(180-x)}&lt;/math&gt;

===Equivalent forms of the formula===
Bhaskara I's sine approximation formula can be expressed using the [[radian]] measure of [[angle]]s as follows.&lt;ref name="mcs"/&gt;

:&lt;math&gt;\sin x = \frac{16x (\pi - x)}{5\pi^2 - 4x (\pi - x)}.&lt;/math&gt;

For a positive integer ''n'' this takes the following form:&lt;ref name="Joseph"&gt;{{Cite book|last=George Gheverghese Joseph|title=A passage to infinity : Medieval Indian mathematics from Kerala and its impact|publisher=SAGE Publications India Pvt. Ltd.|location=New Delhi|year=2009|isbn=978-81-321-0168-0|title-link=A Passage to Infinity}} (p.60)&lt;/ref&gt;

:&lt;math&gt; \sin \frac{\pi}{n} =  \frac{16(n-1)}{5n^2-4n+4}.&lt;/math&gt;

The formula acquires an even simpler form when expressed in terms of the cosine rather than the sine. Using radian measure for angle, and putting &lt;math&gt; x = \tfrac{1}{2} \pi + y&lt;/math&gt;, one gets

:&lt;math&gt; \cos y = \frac{\pi^2 - 4 y^2}{\pi^2 + y^2}.&lt;/math&gt;

The assonance of "&lt;math&gt;\pi&lt;/math&gt;" and "&lt;math&gt;y&lt;/math&gt;" makes this expression especially pleasing as a mnemonic. 

Equivalent forms of Bhaskara I's formula have been given by almost all subsequent astronomers and mathematicians of India. For example, [[Brahmagupta]]'s (598 &amp;ndash; 668 [[BCE|CE]])
''Brhma-Sphuta-Siddhanta'' (verses 23 &amp;ndash; 24, Chapter XIV)&lt;ref name="Gupta"/&gt; gives the formula in the following form:

:&lt;math&gt; R \sin x^\circ = \frac{R x(180-x)}{10125 - \frac{1}{4}x(180-x)}&lt;/math&gt;

Also, [[Bhaskara II]]  (1114 &amp;ndash; 1185 [[BCE|CE]]) has given this formula in his [[Lilavati]] (Kshetra-vyavahara, Soka No.48) in the following form:

:&lt;math&gt; 2R\sin x^\circ = \frac{4\times 2R \times 2Rx\times (360R - 2Rx)}{\frac{1}{4}\times 5 \times (360R)^2 - 2Rx\times (360R -2Rx)}&lt;/math&gt;

==Accuracy of the formula==
[[File:BhaskaraSineApproximation3.jpeg|thumb|right|350px|Figure illustrates the level of accuracy of the Bhaskara I's sine approximation formula. The shifted curves 4 ''x'' ( 180 - ''x'' ) / ( 40500 - ''x'' ( 180 - ''x'' ) - 0.2 and sin ( ''x'' ) + 0.2 look like exact copies of the curve sin ( ''x'' ).]]

The formula is applicable for values of ''x''° in the range from 0 to 180. The formula is remarkably accurate in this range. The graphs of sin ( ''x'' ) and the approximation formula are indistinguishable and are nearly identical. One of the accompanying figures gives the graph of the error function, namely the function,
:&lt;math&gt; \sin x^\circ - \frac{4 x (180-x)}{40500 - x(180-x)}&lt;/math&gt;
in using the formula. It shows that the maximum absolute error in using the formula is around 0.0016. From a plot of the percentage value of the absolute error, it is clear  that the maximum percentage error is less than 1.8. The approximation formula thus gives sufficiently accurate values of sines for all practical purposes. However it was not sufficient for the more accurate computational requirements of astronomy. The search for more accurate formulas by Indian astronomers eventually led to the discovery the [[Madhava series|power series]] expansions of sin ''x'' and cos ''x'' by [[Madhava of Sangamagrama]] (c. 1350 – c. 1425), the founder of the [[Kerala school of astronomy and mathematics]].

[[File:BhaskaraSineApproximation.JPG|thumb|right|350px|Graph of the error in Bhaskara I's sine approximation formula]]

[[File:BhaskaraSineApproximation1.png|thumb|right|350px|Graph of the percentage error in Bhaskara I's sine approximation formula]]

==Derivation of the formula==
Bhaskara I had not indicated any method by which he arrived at his formula. Historians have speculated on various possibilities. No definitive answers have as yet been obtained. Beyond its historical importance of being a prime example of the mathematical achievements of ancient Indian astronomers, the formula is of significance from a modern perspective also. Mathematicians have attempted to derive the rule using modern concepts and tools.  Around half a dozen methods have been suggested, each based on a separate set of premises.&lt;ref name="Brummelen"&gt;{{Cite book|last=Glen Van Brummelen|title=The mathematics of the heavens and the earth: the early history of trigonometry|publisher=Princeton University Press|year=2009|isbn=978-0-691-12973-0}} (p.104)&lt;/ref&gt;&lt;ref name="Gupta"/&gt; Most of these derivations use only elementary concepts.

===Derivation based on elementary geometry &lt;ref name="Brummelen"/&gt;&lt;ref name="Gupta"/&gt;===
Let the [[circumference]] of a [[circle]] be measured in [[Degree (angle)|degree]]s and let the [[radius]] ''R'' of the [[circle]] be also measured in [[Degree (angle)|degree]]s. Choosing a fixed diameter ''AB'' and an arbitrary point ''P'' on the circle and dropping the perpendicular ''PM'' to ''AB'', we can compute the area of the triangle ''APB'' in two ways. Equating the two expressions for the area one gets (1/2) ''AB'' &amp;times; ''PM'' = (1/2) ''AP'' &amp;times; ''BP''. This gives
:&lt;math&gt; \frac{1}{PM} = \frac{AB}{AP \times BP}&lt;/math&gt;.
Letting ''x'' be the length of the arc ''AP'',  the length of the arc ''BP'' is 180 - ''x''. These arcs are much bigger than the respective chords. Hence one gets
:&lt;math&gt;\frac{1}{PM} &gt; \frac{2R}{x(180-x)}&lt;/math&gt;.
One now seeks two constants α and β such that
:&lt;math&gt; \frac{1}{PM} = \alpha \frac{2R}{x(180-x)} + \beta&lt;/math&gt;
It is indeed not possible to obtain such constants. However one may choose values for α and β so that the above expression is valid for two chosen values of the arc length ''x''. Choosing 30° and 90° as these values and solving the resulting equations, one immediately gets Bhaskara I's sine approximation formula.

===Derivation starting with a general rational expression===
Assuming that ''x'' is in radians, one may seek an approximation to sin (''x'') in the following form:
:&lt;math&gt; \sin x = \frac{a+bx+cx^2}{p+qx+rx^2}&lt;/math&gt;
The constants ''a'', ''b'', ''c'', ''p'', ''q''  and ''r'' (only five of them are independent) can be determined by assuming that the formula must be exactly valid when ''x'' = 0, π/6, π/2, π,  and further assuming that it has to satisfy the property that sin (''x'') = sin (π - ''x'').&lt;ref name="Brummelen"/&gt;&lt;ref name="Gupta"/&gt; This procedure produces the formula expressed using [[radian]] measure of angles.

===An elementary argument&lt;ref name="Joseph"/&gt;===
[[File:BhaskaraSineApproximation4.jpeg|thumb|right|350px|Comparison of graphs of the parabolas&lt;br&gt; ''x''(180 &amp;minus; ''x'')/8100 and ''x''(180 &amp;minus; ''x'')/9000 &lt;br&gt; with the graph of sin(''x'') (''x'' in degrees).]]
The part of the graph of sin(''x'') in the range from 0° to 180° "looks like" part of a parabola through the points (0,&amp;nbsp;0) and (180,&amp;nbsp;0). The general such parabola is

:&lt;math&gt;k x ( 180 - x ).&lt;/math&gt;

The parabola that also passes through (90,&amp;nbsp;1) (which is the point corresponding to the value sin(90°)&amp;nbsp;=&amp;nbsp;1) is

:&lt;math&gt;\frac{x ( 180 - x )}{ 90 \times 90} = \frac{x ( 180 - x )}{ 8100}.&lt;/math&gt;

The parabola which also passes through (30,&amp;nbsp;1/2) (which is the point corresponding to the value sin(30°)&amp;nbsp;=&amp;nbsp;1/2) is

:&lt;math&gt;\frac{x ( 180 - x )}{2 \times  30 \times 150} = \frac{x(180-x)}{9000}.&lt;/math&gt;

These expressions suggest a varying denominator which takes the value 90&amp;nbsp;&amp;times;&amp;nbsp;90 when ''x''&amp;nbsp;=&amp;nbsp;90 and the value 2&amp;nbsp;&amp;times;&amp;nbsp;30&amp;nbsp;&amp;times;&amp;nbsp;150 when ''x''&amp;nbsp;=&amp;nbsp;30. That this expression should also be symmetrical about the line ' ''x''&amp;nbsp;=&amp;nbsp;90' rules out the possibility of choosing a linear expression in&amp;nbsp;''x''.  Computations involving ''x''(180&amp;nbsp;&amp;minus;&amp;nbsp;''x'') might immediately suggest that the expression could be of the form

:&lt;math&gt;8100a + bx ( 180 - x ).&lt;/math&gt;

A little experimentation (or by setting up and solving two linear equations in ''a'' and ''b'') will yield the values ''a''&amp;nbsp;=&amp;nbsp;5/4, ''b''&amp;nbsp;=&amp;nbsp;&amp;minus;1/4. These give Bhaskara I's sine approximation formula.

==See also==
*[[Aryabhata's sine table]]
*[[Madhava's sine table]]

==References==
{{Reflist}}

==Further references==
# R.C..Gupta, On derivation of Bhaskara I's formula for the sine, Ganita Bharati 8 (1-4) (1986), 39-41.
# T. Hayashi, A note on Bhaskara I's rational approximation to sine, Historia Sci. No. 42 (1991), 45-48.
# K. Stroethoff, Bhaskara's approximation for the sine, The Mathematics Enthusiast, Vol. 11, No. 3 (2014), 485-492.

{{DEFAULTSORT:Bhaskara I's Sine Approximation Formula}}
[[Category:Trigonometry]]
[[Category:Indian mathematics]]
[[Category:History of mathematics]]
[[Category:History of geometry]]</text>
      <sha1>3dvhvrxo6cqkaloc8gifd42efggrxww</sha1>
    </revision>
  </page>
  <page>
    <title>Brahmagupta's interpolation formula</title>
    <ns>0</ns>
    <id>39206504</id>
    <revision>
      <id>871395437</id>
      <parentid>865602744</parentid>
      <timestamp>2018-11-30T19:33:31Z</timestamp>
      <contributor>
        <username>Dragoon17</username>
        <id>5204143</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7749">'''Brahmagupta's interpolation formula''' is a second-order polynomial [[interpolation formula]] developed by the [[India]]n [[mathematician]] and [[astronomer]] [[Brahmagupta]] (598–668 [[Common era|CE]]) in the early 7th century [[Common Era|CE]]. The [[Sanskrit]] couplet describing the formula can be found in the supplementary part of ''Khandakadyaka'' a work of [[Brahmagupta]] completed in 665 CE.&lt;ref name="Gupta"&gt;{{cite journal|last=Gupta|first=R. C. |title=Second-order interpolation in Indian mathematics upto the fifteenth century|journal=Indian Journal of History of Science|volume=4|issue=1 &amp; 2|pages=86–98}}&lt;/ref&gt; The same couplet appears in Brahmagupta's earlier ''Dhyana-graha-adhikara'', which was probably written "near the beginning of the second quarter of the 7th century CE, if not earlier."&lt;ref name="Gupta"/&gt; Brahmagupta was the one of the first to describe and use an [[interpolation formula]] using second-order [[finite difference|differences]].&lt;ref&gt;{{cite book|last=Van Brummelen|first=Glen|authorlink=Glen Van Brummelen|title=The mathematics of the heavens and the earth: the early history of trigonometry|year=2009|publisher=Princeton University Press|isbn=9780691129730|pages=329}} (p.111)&lt;/ref&gt;&lt;ref&gt;{{cite journal|last=Meijering|first=Erik|title=A Chronology of Interpolation From Ancient Astronomy to Modern Signal and Image Processing|journal=Proceedings of the IEEE|date=March 2002|volume=90|issue=3|pages=319–321|doi=10.1109/5.993400}}&lt;!--|accessdate=27 October 2010--&gt;&lt;/ref&gt;

Brahmagupa's interpolation formula is equivalent to modern-day second-order Newton–Stirling [[interpolation formula]].

==Preliminaries==

Given a set of tabulated values of a function {{math|''f''(''x'')}} in the table below, let it be required to compute the value of {{math|''f''(''a'')}}, {{math|''x''&lt;sub&gt;''r''&lt;/sub&gt; &lt; ''a'' &lt; ''x''&lt;sub&gt;''r''+1&lt;/sub&gt;}}.

{| class="wikitable"
|-
|&amp;nbsp; {{math|''x''}} &amp;nbsp; ||&amp;nbsp; {{math|''x''&lt;sub&gt;1&lt;/sub&gt;}}&amp;nbsp; ||&amp;nbsp; {{math|''x''&lt;sub&gt;2&lt;/sub&gt;}}&amp;nbsp; ||&amp;nbsp; ... &amp;nbsp;||&amp;nbsp; {{math|''x''&lt;sub&gt;''r''&lt;/sub&gt;}} &amp;nbsp;||&amp;nbsp; {{math|''x''&lt;sub&gt;''r''+1&lt;/sub&gt;}}&amp;nbsp; ||&amp;nbsp; {{math|''x''&lt;sub&gt;''r''+2&lt;/sub&gt;}}&amp;nbsp; ||&amp;nbsp; ... &amp;nbsp;||&amp;nbsp; {{math|''x''&lt;sub&gt;''n''&lt;/sub&gt;}}&amp;nbsp;
|-
|&amp;nbsp; {{math|''f''(''x''&lt;sub&gt;''r''&lt;/sub&gt;)}} || &amp;nbsp; {{math|''f''&lt;sub&gt;1&lt;/sub&gt;}} ||&amp;nbsp; {{math|''f''&lt;sub&gt;2&lt;/sub&gt;}} ||&amp;nbsp; ... ||&amp;nbsp; {{math|''f''&lt;sub&gt;''r''&lt;/sub&gt;}} || &amp;nbsp; {{math|''f''&lt;sub&gt;''r''+1&lt;/sub&gt;}} || &amp;nbsp; {{math|''f''&lt;sub&gt;''r''+2&lt;/sub&gt;}} ||&amp;nbsp; ... ||&amp;nbsp; {{math|''f''&lt;sub&gt;''n''&lt;/sub&gt;}}
|}

Assuming that the successively tabulated values of {{math|''x''}} are equally spaced with a common spacing of {{math|''h''}}, [[Aryabhata]] had considered the table of first differences of the table of values of a function. Writing

: &lt;math&gt;D_r=f_{r+1}-f_r&lt;/math&gt;

the following table can be formed:

{| class="wikitable"
|-
|&amp;nbsp; {{math|''x''}}&amp;nbsp; ||&amp;nbsp; {{math|''x''&lt;sub&gt;2&lt;/sub&gt;}}&amp;nbsp; ||&amp;nbsp; ... &amp;nbsp; || &amp;nbsp; {{math|''x''&lt;sub&gt;''r''&lt;/sub&gt;}}&amp;nbsp; || &amp;nbsp; {{math|''x''&lt;sub&gt;''r''+1&lt;/sub&gt;}}&amp;nbsp; ||&amp;nbsp; ... &amp;nbsp; ||&amp;nbsp; {{math|''x''&lt;sub&gt;''n''&lt;/sub&gt;}}&amp;nbsp;
|-
|&amp;nbsp; Differences ||&amp;nbsp; {{math|''D''&lt;sub&gt;1&lt;/sub&gt;}} ||&amp;nbsp; ... ||&amp;nbsp; {{math|''D''&lt;sub&gt;''r''&lt;/sub&gt;}} || &amp;nbsp;{{math|''D''&lt;sub&gt;''r''+1&lt;/sub&gt;}} || ... || &amp;nbsp; {{math|''D''&lt;sub&gt;''n''&lt;/sub&gt;}}
|}

Mathematicians prior to Brahmagupta used a simple [[linear interpolation]] formula. The  linear interpolation formula to compute {{math|''f''(''a'')}} is

: &lt;math&gt;f(a)=f_r+ t D_r&lt;/math&gt; where &lt;math&gt;t=\frac{a-x_r}{h}&lt;/math&gt;.

For the computation of {{math|''f''(''a'')}},  Brahmagupta replaces {{math|''D''&lt;sub&gt;''r''&lt;/sub&gt;}}  with another expression which gives more accurate values and which amounts to using a second-order interpolation formula.

==Brahmagupta's description of the scheme==

In Brahmagupta's terminology the difference {{math|''D''&lt;sub&gt;''r''&lt;/sub&gt;}} is the ''gatakhanda'', meaning ''past difference'' or the difference that was crossed over, the difference {{math|''D''&lt;sub&gt;''r''+1&lt;/sub&gt;}} is the ''bhogyakhanda'' which is the ''difference yet to come''. ''Vikala'' is the amount in minutes by which the interval has been covered at the point where we want to interpolate. In the present notations it is {{math|''a'' − ''x''&lt;sub&gt;''r''&lt;/sub&gt;}}. The new expression which replaces {{math|''f''&lt;sub&gt;''r''+1&lt;/sub&gt; − ''f''&lt;sub&gt;''r''&lt;/sub&gt;}} is called ''sphuta-bhogyakhanda''. The description of ''sphuta-bhogyakhanda'' is contained in the following Sanskrit couplet (''Dhyana-Graha-Upadesa-Adhyaya, 17; Khandaka Khadyaka, IX, 8''):&lt;ref name="Gupta"/&gt;

[[File:Brahmagupas Interpolation Formula In Devanagari.jpg]]{{clarify|date=January 2016|reason=This is an image of text and should be replaced by the text itself.|post-text=(text needed)}}

This has been translated using Bhattolpala's (10th century CE) commentary as follows:&lt;ref name="Gupta"/&gt;&lt;ref name="Raju"&gt;{{cite book|last=Raju |first=C K|title=Cultural foundations of mathematics: the nature of mathematical proof and the transmission of the calculus from India to Europe in the 16th c. CE|year=2007|publisher=Pearson Education India|isbn=9788131708712|pages=138–140}}&lt;/ref&gt;

:Multiply the ''vikala'' by the half the difference of the ''gatakhanda'' and the ''bhogyakhanda'' and divide the product by 900. Add the result to half the sum of the ''gatakhanda'' and the ''bhogyakhanda'' if their half-sum is less than the ''bhogyakhanda'', subtract if greater. (The result in each case is ''sphuta-bhogyakhanda'' the correct tabular difference.)

This formula was originally stated for the computation of the values of the sine function for which the common interval in the underlying base table was 900 minutes or 15 degrees. So the reference to 900 is in fact a reference to the common interval {{math|''h''}}.

==In modern notation==
Brahmagupta's method computation of ''shutabhogyakhanda'' can be formulated in modern notation as follows:

:''sphuta-bhogyakhanda'' &lt;math&gt;\displaystyle = \frac{D_r + D_{r-1}}{2} \pm t\frac{|D_r - D_{r-1}|}{2}.&lt;/math&gt;

The [[plus or minus|±]] sign is to be taken according to whether {{math|{{sfrac|1|2}}(''D''&lt;sub&gt;''r''&lt;/sub&gt; + ''D''&lt;sub&gt;''r''+1&lt;/sub&gt;)}} is less than or greater than {{math|''D''&lt;sub&gt;''r''+1&lt;/sub&gt;}}, or equivalently, according to whether {{math|''D''&lt;sub&gt;''r''&lt;/sub&gt; &lt; ''D''&lt;sub&gt;''r''+1&lt;/sub&gt;}} or {{math|''D''&lt;sub&gt;''r''&lt;/sub&gt; &gt; ''D''&lt;sub&gt;''r''+1&lt;/sub&gt;}}. Brahmagupta's expression can be put in the following form:

:''sphuta-bhogyakhanda'' &lt;math&gt; \displaystyle = \frac{D_r + D_{r-1}}{2} + t\frac{D_r-D_{r-1}}{2}.&lt;/math&gt;

This correction factor yields the following approximate value for {{math|''f''(''a'')}}:

: &lt;math&gt; 
\begin{align}
f(a) &amp; = f_r + t\times\text{sphuta-bhogyakhanda}\\
&amp;  = f_r + t \frac{D_r + D_{r-1}}{2} + t^2\frac{D_r - D_{r-1}}{2}.
\end{align}
&lt;/math&gt;

This is Stirling's [[interpolation formula]] truncated at the second-order differences.&lt;ref&gt;{{cite book|last=Milne-Thomson|first=Louis Melville|title=The Calculus of Finite Differences|year=2000|publisher=AMS Chelsea Publishing|isbn=9780821821077|pages=67–68}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Hildebrand|first=Francis Begnaud|title=Introduction to numerical analysis|year=1987|publisher=Courier Dover Publications|isbn=9780486653631|pages=138–139}}&lt;/ref&gt; It is not known how Brahmagupta arrived at his interpolation formula.&lt;ref name="Gupta"/&gt; Brahmagupta has given a separate formula for the case where the values of the independent variable are not equally spaced.

==See also==
* [[Brahmagupta's identity]]
* [[Brahmagupta matrix]]
* [[Brahmagupta–Fibonacci identity]]

==References==
{{reflist}}

[[Category:Interpolation]]
[[Category:Indian mathematics]]
[[Category:History of mathematics]]</text>
      <sha1>4lq2vgz7fteh8l8dhtnyj0flwjkqdre</sha1>
    </revision>
  </page>
  <page>
    <title>Cesàro summation</title>
    <ns>0</ns>
    <id>705600</id>
    <revision>
      <id>856067998</id>
      <parentid>856067229</parentid>
      <timestamp>2018-08-22T17:07:27Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>Undid revision 856067229 by [[Special:Contributions/82.69.14.51|82.69.14.51]] ([[User talk:82.69.14.51|talk]]) it was already correct</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8997">{{For|the song "Cesaro Summability" by the band Tool|Ænima}}

In [[mathematical analysis]], '''Cesàro summation''' (also known as the '''Cesàro mean'''&lt;ref name="Hardy"&gt;
{{cite book | last = Hardy | first = G. H.| title = Divergent Series | publisher = American Mathematical Society | location = Providence | year = 1992 | isbn = 978-0-8218-2649-2 }}&lt;/ref&gt;&lt;ref name="Katznelson"&gt;
{{cite book | last = Katznelson | first = Yitzhak | title = An Introduction to Harmonic Analysis | publisher = Dover Publications | location = New York | year = 1976 | isbn = 978-0-486-63331-2 }}
&lt;/ref&gt;) assigns values to some [[Series (mathematics)|infinite sums]] that are [[Divergent series|not convergent]] in the usual sense. The Cesàro sum is defined as the limit, as ''n'' tends to infinity, of the sequence of arithmetic means of the first ''n'' partial sums of the series.

Cesàro summation is named for the Italian analyst [[Ernesto Cesàro]] (1859–1906).  It is a special case of a [[matrix summability method]].

The term ''summation'' can be misleading, as some statements and proofs regarding Cesàro summation can be said to implicate the [[Eilenberg–Mazur swindle]]. For example, it is commonly applied to [[Grandi's series]] with the conclusion that the ''sum'' of that series is 1/2.

== Definition ==
Let &lt;math&gt;(a_n)_{n=1}^\infty&lt;/math&gt; be a [[sequence]], and let

:&lt;math&gt;s_k = a_1 + \cdots + a_k= \sum_{n=1}^k a_n&lt;/math&gt;

be its {{mvar|k}}th [[partial sum]].

The sequence {{math|(''a''&lt;sub&gt;''n''&lt;/sub&gt;)}} is called '''Cesàro summable''', with Cesàro sum {{math|''A'' ∈ ℝ}}, if, as {{mvar|n}} tends to infinity, the [[arithmetic mean]] of its first ''n'' partial sums {{math|''s''&lt;sub&gt;1&lt;/sub&gt;, ''s''&lt;sub&gt;2&lt;/sub&gt;, ..., ''s''&lt;sub&gt;''n''&lt;/sub&gt;}} tends to {{mvar|A}}:

:&lt;math&gt;\lim_{n\to\infty} \frac{1}{n}\sum_{k=1}^n s_k = A.&lt;/math&gt;

The value of the resulting limit is called the Cesàro sum of the series &lt;math&gt;\textstyle\sum_{n=1}^\infty a_n.&lt;/math&gt;  If this series is ([[conditional convergence|conditionally]]) convergent, then it is Cesàro summable and its Cesàro sum is the usual sum.

==Examples==

===First example===
Let {{math|''a''&lt;sub&gt;''n''&lt;/sub&gt; {{=}} (−1)&lt;sup&gt;''n''&lt;/sup&gt;}} for {{math|''n'' ≥ 0}}. That is, &lt;math&gt;(a_n)_{n=0}^\infty&lt;/math&gt; is the sequence
:&lt;math&gt;(1, -1, 1, -1, \ldots).&lt;/math&gt;
Let {{mvar|G}} denote the series
:&lt;math&gt;G = \sum_{n=0}^\infty a_n = 1-1+1-1+1-\cdots &lt;/math&gt;
The series {{mvar|G}} is known as [[Grandi's series]].

Let &lt;math&gt;(s_k)_{k=0}^\infty&lt;/math&gt; denote the sequence of partial sums of {{mvar|G}}:
:&lt;math&gt;\begin{align}
   s_k &amp;= \sum_{n=0}^k a_n \\
   (s_k) &amp;= (1, 0, 1, 0, \ldots).
 \end{align}&lt;/math&gt;

This sequence of partial sums does not converge, so the series {{mvar|G}} is divergent.  However, {{mvar|G}} {{em|is}} Cèsaro summable.  Let &lt;math&gt;(t_n)_{n=1}^\infty&lt;/math&gt; be the sequence of arithmetic means of the first {{mvar|n}} partial sums:
:&lt;math&gt;\begin{align}
   t_n &amp;= \frac{1}{n}\sum_{k=0}^{n-1} s_k \\
   (t_n) &amp;= \left(\frac{1}{1}, \frac{1}{2}, \frac{2}{3}, \frac{2}{4}, \frac{3}{5}, \frac{3}{6}, \frac{4}{7}, \frac{4}{8}, \ldots\right).
 \end{align}&lt;/math&gt;
Then
:&lt;math&gt;\lim_{n\to\infty} t_n = 1/2,&lt;/math&gt;
and therefore, the Cesàro sum of the series {{mvar|G}} is {{math|1/2}}.

===Second example===
As another example, let {{math|''a''&lt;sub&gt;''n''&lt;/sub&gt; {{=}} ''n''}} for {{math|''n'' ≥ 1}}. That is, &lt;math&gt;(a_n)_{n=1}^\infty&lt;/math&gt; is the sequence

:&lt;math&gt;(1, 2, 3, 4, \ldots).&lt;/math&gt;

Let {{mvar|G}} now denote the series

:&lt;math&gt;G = \sum_{n=1}^\infty a_n = 1+2+3+4+\cdots &lt;/math&gt;

Then the sequence of partial sums &lt;math&gt;(s_k)_{k=1}^\infty&lt;/math&gt; is

:&lt;math&gt;(1, 3, 6, 10, \ldots).&lt;/math&gt;

Since the sequence of partial sums grows without bound, the series {{mvar|G}} diverges to infinity.  The sequence {{math|(''t''&lt;sub&gt;''n''&lt;/sub&gt;)}} of means of partial sums of G is

:&lt;math&gt;\left(\frac{1}{1}, \frac{4}{2}, \frac{10}{3}, \frac{20}{4}, \ldots\right).&lt;/math&gt;

This sequence diverges to infinity as well, so {{mvar|G}} is {{em|not}} Cesàro summable. In fact, for any sequence which diverges to (positive or negative) infinity, the Cesàro method also leads to a sequence that diverges likewise, and hence such a series is not Cesàro summable.

=={{math|(C, ''α'')}} summation==

In 1890, Ernesto Cesàro stated a broader family of summation methods which have since been called {{math|(C, ''α'')}} for non-negative integers {{mvar|α}}. The {{math|(C, 0)}} method is just ordinary summation, and {{math|(C, 1)}} is Cesàro summation as described above.

The higher-order methods can be described as follows: given a series {{math|∑''a''&lt;sub&gt;''n''&lt;/sub&gt;}}, define the quantities

:&lt;math&gt;\begin{align} A_n^{-1}&amp;=a_n \\ A_n^\alpha&amp;=\sum_{k=0}^n A_k^{\alpha-1} \end{align}&lt;/math&gt;

(where the upper indices do not denote exponents) and define {{mvar|E{{su|b=n|p=α}}}} to be {{mvar|A{{su|b=n|p=α}}}} for the series {{nowrap|1 + 0 + 0 + 0 + …}}. Then the {{math|(C, ''α'')}} sum of {{math|∑''a''&lt;sub&gt;''n''&lt;/sub&gt;}} is denoted by {{math|(C, ''α'')-∑''a''&lt;sub&gt;''n''&lt;/sub&gt;}} and has the value

&lt;!-- Note that this is *not* a subtraction.  Here and in the next formula, we use a hyphen to avoid having it interpreted as a minus sign.  --&gt;
:&lt;math&gt;(\mathrm{C},\alpha)\text{-}\sum_{j=0}^\infty a_j=\lim_{n\to\infty}\frac{A_n^\alpha}{E_n^\alpha}&lt;/math&gt;

if it exists {{harv|Shawyer|Watson|1994|loc=pp.16-17}}. This description represents an {{mvar|α}}-times iterated application of the initial summation method and can be restated as

:&lt;math&gt;(\mathrm{C},\alpha)\text{-}\sum_{j=0}^\infty a_j = \lim_{n\to\infty} \sum_{j=0}^n \frac{\binom{n}{j}}{\binom{n+\alpha}{j}} a_j.&lt;/math&gt;

Even more generally, for {{math|''α'' ∈ ℝ \ ℤ&lt;sup&gt;−&lt;/sup&gt;}}, let {{mvar|A{{su|b=n|p=α}}}} be implicitly given by the coefficients of the series

:&lt;math&gt;\sum_{n=0}^\infty A_n^\alpha x^n=\frac{\displaystyle{\sum_{n=0}^\infty a_nx^n}}{(1-x)^{1+\alpha}},&lt;/math&gt;

and {{mvar|E{{su|b=n|p=α}}}} as above.  In particular, {{mvar|E{{su|b=n|p=α}}}} are the [[binomial coefficient#Newton's binomial series|binomial coefficients]] of power {{math|−1 − ''α''}}. Then the {{math|(C, ''α'')}} sum of {{math|∑''a''&lt;sub&gt;''n''&lt;/sub&gt;}} is defined as above.

If {{math|∑''a''&lt;sub&gt;''n''&lt;/sub&gt;}} has a {{math|(C, ''α'')}} sum, then it also has a {{math|(C, ''β'')}} sum for every {{math|''β'' &gt; ''α''}}, and the sums agree; furthermore we have {{math|''a&lt;sub&gt;n&lt;/sub&gt;'' {{=}} ''o''(''n&lt;sup&gt;α&lt;/sup&gt;'')}} if {{math|''α'' &gt; −1}} (see [[Big O notation#Little-o notation|little-{{mvar|o}} notation]]).

== Cesàro summability of an integral ==
Let {{math|''α'' ≥ 0}}. The [[integral]] &lt;math&gt;\textstyle\int_0^\infty f(x)\,dx&lt;/math&gt; is {{math|(C, ''α'')}} summable if

:&lt;math&gt;\lim_{\lambda\to\infty}\int_0^\lambda\left(1-\frac{x}{\lambda}\right)^\alpha f(x)\, dx &lt;/math&gt;

exists and is finite {{harv|Titchmarsh|1948|loc=§1.15}}. The value of this limit, should it exist, is the {{math|(C, ''α'')}} sum of the integral.  Analogously to the case of the sum of a series, if {{math|''α'' {{=}} 0}}, the result is convergence of the [[improper integral]].  In the case {{math|''α'' {{=}} 1}}, {{math|(C, 1)}} convergence is equivalent to the existence of the limit

:&lt;math&gt;\lim_{\lambda\to \infty}\frac{1}{\lambda}\int_0^\lambda \int_0^x f(y)\, dy\,dx&lt;/math&gt;

which is the limit of means of the partial integrals.

As is the case with series, if an integral is {{math|(C, ''α'')}} summable for some value of {{math|''α'' ≥ 0}}, then it is also {{math|(C, ''β'')}} summable for all {{math|''β'' &gt; ''α''}}, and the value of the resulting limit is the same.

== See also ==
{{div col|colwidth=20em}}
* [[Abel summation]]
* [[Abel's summation formula]]
* [[Abel–Plana formula]]
* [[Abelian and tauberian theorems]]
* [[Almost convergent sequence]]
* [[Borel summation]]
* [[Divergent series]]
* [[Euler summation]]
* [[Euler–Boole summation]]
* [[Fejér's theorem]]
* [[Hölder summation]]
* [[Lambert summation]]
* [[Perron's formula]]
* [[Ramanujan summation]]
* [[Riesz mean]]
* [[Silverman–Toeplitz theorem]]
* [[Stolz–Cesàro theorem]]
* [[Summation by parts]]
{{div col end}}

==References==
{{Reflist}}
*{{citation |last1=Shawyer|first1=Bruce|last2=Watson |first2=Bruce|title=Borel's Methods of Summability: Theory and Applications |year=1994 |publisher=Oxford University Press |isbn=0-19-853585-6}}
* {{citation|last=Titchmarsh|first=E. C.|authorlink=Edward Charles Titchmarsh|title=Introduction to the theory of Fourier integrals|edition=2nd|year=1986|origyear=1948|publisher=Chelsea Publishing|location=New York, NY|isbn=978-0-8284-0324-5}}
* {{springer|title=Cesàro summation methods|first=I. I.|last=Volkov|year=2001|id=c/c021360}}
* {{citation|last=Zygmund|first=Antoni|authorlink=Antoni Zygmund|title=Trigonometric series|edition=2nd|year=1988|origyear=1968|publisher=Cambridge University Press|isbn=978-0-521-35885-9}}

{{DEFAULTSORT:Cesaro summation}}
[[Category:Summability methods]]
[[Category:Means]]</text>
      <sha1>k3lbpnv1jip6depvdqjhkon94ezz5t8</sha1>
    </revision>
  </page>
  <page>
    <title>Christine Paulin-Mohring</title>
    <ns>0</ns>
    <id>58716885</id>
    <revision>
      <id>871613046</id>
      <parentid>865820514</parentid>
      <timestamp>2018-12-02T08:13:47Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>more ids, birth year</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2641">{{Infobox scientist
| name = Christine Paulin-Mohring
| image_size = 150px
| birth_name = 
| birth_date = {{birth year|1962}}
| birth_place = 
| death_date = 
| death_place = 
| residence = 
| citizenship = 
| nationality = 
| alma_mater = [[Paris Diderot University]]
| doctoral_advisor = [[Gérard Huet]]
| doctoral_students = 
| known_for = [[Coq]]
| author_abbrev_bot = 
| author_abbrev_zoo = 
| signature = 
| footnotes = 
| ethnicity = 
| field = [[Mathematics]], [[Computer Science]]
| work_institutions = 
| prizes = [[ACM Software System Award]] (2013)
| religion = 
}}

'''Christine Paulin-Mohring''' (born 1962)&lt;ref&gt;Birth year from [http://id.loc.gov/authorities/names/n98084169.html Libary of Congress catalog entry], retrieved 2018-12-01.&lt;/ref&gt; is a [[mathematical logic]]ian and [[computer scientist]], and Professor at [[Paris-Sud 11 University]], best known for developing the interactive theorem prover [[Coq]], for which she and the rest of the development team ([[Thierry Coquand]], [[Gérard Huet]], Bruno Barras, Jean-Christophe Filliâtre, Hugo Herbelin, Chetan Murthy, Yves Bertot and Pierre Castéran) won the 2013 [[ACM Software System Award]] awarded by the [[Association for Computing Machinery]].

== Biography ==

Paulin-Mohring received her PhD in 1989 under the supervision of [[Gérard Huet]].&lt;ref&gt;{{mathgenealogy|id=128359}}&lt;/ref&gt;  She has been professor at [[Paris-Sud 11 University]] since 1997.&lt;ref&gt;{{Cite web|url=https://www.lri.fr/~paulin/bio.html|title=bio|website=www.lri.fr|access-date=2018-10-10}}&lt;/ref&gt;

Between 2012 and 2015 she was the Scientific Coordinator of the Labex DigiCosme.&lt;ref&gt;{{Cite web|url=https://digicosme.lri.fr/tiki-index.php?page=Organisation|title=Labex DigiCosme {{!}} Organisation-EN|website=digicosme.lri.fr|language=en|access-date=2018-10-10}}&lt;/ref&gt;  Currently she is a member of the editorial board of the ''Journal of Formalized Reasoning''.&lt;ref&gt;{{Cite web|url=https://jfr.unibo.it/about/editorialTeam|title=Editorial Team|website=jfr.unibo.it|language=en-US|access-date=2018-10-10}}&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==

* [https://www.lri.fr/~paulin/index.html Home page]
* {{MathGenealogy|id=128359}}

{{Authority control|LCCN=n98084169|VIAF=7513198|BNF=cb127311970|ISNI=000000010951855X|SUDOC=071516689}}

{{DEFAULTSORT:Paulin-Mohring, Christine}}
[[Category:Living people]]
[[Category:Mathematical logicians]]
[[Category:21st-century mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:French mathematicians]]
[[Category:French computer scientists]]
[[Category:Women mathematicians]]
[[Category:French women computer scientists]]</text>
      <sha1>0296ux68hia3h4ohs3xgtotle53wota</sha1>
    </revision>
  </page>
  <page>
    <title>Clique complex</title>
    <ns>0</ns>
    <id>20751674</id>
    <revision>
      <id>841571584</id>
      <parentid>731759319</parentid>
      <timestamp>2018-05-16T17:16:01Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10841">{{redirect|Whitney complex|the Mississippi sports facility|Davey Whitney Complex}}
[[File:VR complex.svg|thumb|300px|The clique complex of a graph. Cliques of size one are shown as small red disks; cliques of size two are shown as black line segments; cliques of size three are shown as light blue triangles; and cliques of size four are shown as dark blue tetrahedra.]]
'''Clique complexes''', '''flag complexes''', and '''conformal hypergraphs''' are closely related [[mathematics|mathematical]] objects in [[graph theory]] and [[geometric topology]] that each describe the [[Clique (graph theory)|cliques]] (complete subgraphs) of an [[undirected graph]].

The clique complex ''X''(''G'') of an undirected graph ''G'' is an [[abstract simplicial complex]] (that is, a family of finite sets closed under the operation of taking subsets), formed by the sets of vertices in the cliques of ''G''. Any subset of a clique is itself a clique, so this family of sets meets the requirement of an abstract simplicial complex that every subset of a set in the family should also be in the family. The clique complex can also be viewed as a topological space in which each clique of ''k'' vertices is represented by a [[simplex]] of dimension ''k''&amp;nbsp;&amp;minus;&amp;nbsp;1. The [[n-skeleton|1-skeleton]] of ''X''(''G'') (also known as the ''underlying graph'' of the complex) is an undirected graph with a vertex for every 1-element set in the family and an edge for every 2-element set in the family; it is isomorphic to&amp;nbsp;''G''.&lt;ref name="bc"&gt;{{harvtxt|Bandelt|Chepoi|2008}}.&lt;/ref&gt;

Clique complexes are also known as '''Whitney complexes'''. A [[Triangulation (topology)|Whitney triangulation]] or clean triangulation of a two-dimensional [[manifold]] is an [[graph embedding|embedding]] of a graph ''G'' onto the manifold in such a way that every face is a triangle and every triangle is a face. If a graph ''G'' has a Whitney triangulation, it must form a cell complex that is isomorphic to the Whitney complex of ''G''. In this case, the complex (viewed as a topological space) is [[homeomorphism|homeomorphic]] to the underlying manifold. A graph ''G'' has a 2-manifold clique complex, and can be embedded as a Whitney triangulation, if and only if ''G'' is [[Neighbourhood (graph theory)|locally cyclic]]; this means that, for every vertex ''v'' in the graph, the [[induced subgraph]] formed by the neighbors of ''v'' forms a single cycle.&lt;ref&gt;{{harvtxt|Hartsfeld|Ringel|1991}}; {{harvtxt|Larrión|Neumann-Lara|Pizaña|2002}}; {{harvtxt|Malnič|Mohar|1992}}.&lt;/ref&gt;

==Independence complex==
The independence complex ''I''(''G'') of a graph ''G'' is formed in the same way as the clique complex from the [[Independent set (graph theory)|independent set]]s of ''G''. It is the clique complex of the [[complement graph]] of ''G''.

==Flag complex==
In an abstract simplicial complex, a set ''S'' of vertices that is not itself part of the complex, but such that each pair of vertices in ''S'' belongs to some simplex in the complex, is called an ''empty simplex''. [[Mikhail Leonidovich Gromov|Mikhail Gromov]] defined the ''no-&amp;Delta; condition'' to be the condition that a complex have no empty simplices. A flag complex is an abstract simplicial complex that has no empty simplices; that is, it is a complex satisfying Gromov's no-Δ condition.
Any flag complex is the clique complex of its 1-skeleton. Thus, flag complexes and clique complexes are essentially the same thing.  However, in many cases it may be convenient to define a flag complex directly from some data other than a graph, rather than indirectly as the clique complex of a graph derived from that data.&lt;ref name="davis"&gt;{{harvtxt|Davis|2002}}.&lt;/ref&gt;

==Conformal hypergraph==
The primal graph ''G(H)'' of a [[hypergraph]] is the graph on the same vertex set that has as its edges the pairs of vertices appearing together in the same [[hyperedge]]. A hypergraph is said to be conformal if every maximal clique of its primal graph is a hyperedge, or equivalently, if every clique of its primal graph is contained in some hyperedge.&lt;ref&gt;{{harvtxt|Berge|1989}}; {{harvtxt|Hodkinson|Otto|2003}}.&lt;/ref&gt; If the hypergraph is required to be downward-closed (so it contains all hyperedges that are contained in some hyperedge) then the hypergraph is conformal precisely when it is a flag complex. This relates the language of hypergraphs to the language of simplicial complexes.

==Examples and applications==
The [[barycentric subdivision]] of any [[CW complex|cell complex]] ''C'' is a flag complex having one vertex per cell of ''C''. A collection of vertices of the barycentric subdivision form a simplex if and only if the corresponding collection of cells of ''C'' form a [[Flag (geometry)|flag]] (a chain in the inclusion ordering of the cells).&lt;ref name="davis"/&gt; In particular, the barycentric subdivision of a cell complex on a 2-manifold gives rise to a Whitney triangulation of the manifold.

The [[order complex]] of a [[partially ordered set]] consists of the chains ([[total order|totally ordered]] subsets) of the partial order. If every pair of some subset is itself ordered, then the whole subset is a chain, so the order complex satisfies the no-Δ condition. It may be interpreted as the clique complex of the [[comparability graph]] of the partial order.&lt;ref name="davis"/&gt;

The [[matching complex]] of a graph consists of the sets of edges no two of which share an endpoint; again, this family of sets satisfies the no-Δ condition. It may be viewed as the clique complex of the [[complement graph]] of the [[line graph]] of the given graph. When the matching complex is referred to without any particular graph as context, it means the matching complex of a [[complete graph]]. The matching complex of a [[complete bipartite graph]] ''K''&lt;sub&gt;''m'',''n''&lt;/sub&gt; is known as a [[chessboard complex]]. It is the clique graph of the complement graph of a [[rook's graph]],&lt;ref&gt;{{harvtxt|Dong|Wachs|2002}}.&lt;/ref&gt; and each of its simplices represents a placement of rooks on an ''m''&amp;nbsp;&amp;times;&amp;nbsp;''n'' chess board such that no two of the rooks attack each other. When ''m''&amp;nbsp;=&amp;nbsp;''n''&amp;nbsp;±&amp;nbsp;1, the chessboard complex forms a [[pseudo-manifold]].

The [[Vietoris–Rips complex]] of a set of points in a metric space is a special case of a clique complex, formed from the [[unit disk graph]] of the points; however, every clique complex ''X(G)'' may be interpreted as the Vietoris–Rips complex of the [[shortest path]] metric on the underlying graph ''G''.

{{harvtxt|Hodkinson|Otto|2003}} describe an application of conformal hypergraphs in the logics of relational structures. In that context, the [[Constraint graph|Gaifman graph]] of a relational structure is the same as the underlying graph of the hypergraph representing the structure, and a structure is [[Guarded logic|guarded]] if it corresponds to a conformal hypergraph.

Gromov showed that a cubical complex (that is, a family of [[hypercubes]] intersecting face-to-face) forms a [[CAT(k) space|CAT(0) space]] if and only if the complex is simply connected and the link of every vertex forms a flag complex. A cubical complex meeting these conditions is sometimes called a [[cubing (topology)|cubing]] or a ''space with walls''.&lt;ref name="bc"/&gt;&lt;ref&gt;{{harvtxt|Chatterji|Niblo|2005}}.&lt;/ref&gt;

==See also==
*[[Simplex graph]], a graph having one node for every clique of the underlying graph
*[[Partition matroid]], a class of [[matroid]]s whose [[Matroid intersection|intersections]] form clique complexes

==Notes==
{{reflist|2}}

==References==
*{{citation
 | last1 = Bandelt | first1 = H.-J.
 | last2 = Chepoi | first2 = V.
 | contribution = Metric graph theory and geometry: a survey
 | editor1-last = Goodman | editor1-first = J. E. | editor1-link = Jacob E. Goodman
 | editor2-last = Pach | editor2-first = J. | editor2-link = János Pach
 | editor3-last = Pollack | editor3-first = R.
 | location = Providence, RI
 | pages = 49–86
 | publisher = AMS
 | series = Contemporary Mathematics
 | title = Surveys on Discrete and Computational Geometry: Twenty Years Later
 | url = http://pageperso.lif.univ-mrs.fr/~victor.chepoi/survey_cm_bis.pdf
 | volume = 453
 | year = 2008}}.
*{{citation
 | last = Berge | first = C. | author-link = Claude Berge
 | isbn = 0-444-87489-5
 | publisher = North-Holland
 | title = Hypergraphs: Combinatorics of Finite Sets
 | year = 1989}}.
*{{citation
 | last1 = Chatterji | first1 = I.
 | last2 = Niblo | first2 = G.
 | doi = 10.1142/S0218196705002669
 | arxiv = math.GT/0309036 | issue = 5–6
 | journal = International Journal of Algebra and Computation
 | pages = 875–885
 | title = From wall spaces to CAT(0) cube complexes
 | volume = 15
 | year = 2005}}.
*{{citation
 | last = Davis | first = M. W.
 | contribution = Nonpositive curvature and reflection groups
 | editor1-last = Daverman | editor1-first = R. J.
 | editor2-last = Sher | editor2-first = R. B.
 | pages = 373–422
 | publisher = Elsevier
 | title = Handbook of Geometric Topology
 | year = 2002}}.
*{{citation
 | last1 = Dong | first1 = X.
 | last2 = Wachs | first2 = M. L. | author2-link = Michelle L. Wachs
 | journal = Electronic Journal of Combinatorics
 | page = R17
 | title = Combinatorial Laplacian of the matching complex
 | url = http://www.combinatorics.org/Volume_9/Abstracts/v9i1r17.html
 | volume = 9
 | year = 2002}}.
*{{citation
 | last = Hartsfeld | first = N.
 | journal = Combinatorica
 | last2 = Ringel
 | pages = 145–155
 | first2 = Gerhard
 | title = Clean triangulations
 | volume = 11
 | year = 1991
 | doi = 10.1007/BF01206358
 | issue = 2}}.
*{{citation
 | last1 = Hodkinson | first1 = I.
 | last2 = Otto | first2 = M.
 | issue = 3
 | journal = The Bulletin of Symbolic Logic
 | pages = 387–405
 | title = Finite conformal hypergraph covers and Gaifman cliques in finite structures
 | volume = 9
 | year = 2003
 | doi = 10.2178/bsl/1058448678| citeseerx = 10.1.1.107.5000}}.
*{{citation
 | last1 = Larrión | first1 = F.
 | last2 = Neumann-Lara | first2 = V. | author2-link = Víctor Neumann-Lara
 | last3 = Pizaña | first3 = M. A.
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 123–135
 | title = Whitney triangulations, local girth and iterated clique graphs
 | url = http://xamanek.izt.uam.mx/map/papers/cuello10_DM.ps
 | volume = 258
 | year = 2002
 | doi = 10.1016/S0012-365X(02)00266-2}}.
*{{citation
 | last1 = Malnič | first1 = A.
 | last2 = Mohar | first2 = B. | author2-link = Bojan Mohar
 | doi = 10.1016/0095-8956(92)90015-P
 | issue = 2
 | journal = Journal of Combinatorial Theory, Series B
 | pages = 147–164
 | title = Generating locally cyclic triangulations of surfaces
 | volume = 56
 | year = 1992}}.

[[Category:Algebraic topology]]
[[Category:Hypergraphs]]
[[Category:Set families]]</text>
      <sha1>4z1q5d71ipy3lmtctyopmvsd9wi5c0b</sha1>
    </revision>
  </page>
  <page>
    <title>Computing the permanent</title>
    <ns>0</ns>
    <id>20749642</id>
    <revision>
      <id>863779117</id>
      <parentid>859020305</parentid>
      <timestamp>2018-10-12T23:44:18Z</timestamp>
      <contributor>
        <username>Mesospheric</username>
        <id>21438879</id>
      </contributor>
      <minor/>
      <comment>/* Balasubramanian–Bax–Franklin–Glynn formula */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28115">In [[linear algebra]], the '''computation of the [[Permanent (mathematics)|permanent]] of a [[matrix (mathematics)|matrix]]''' is a problem that is thought to be more difficult than the computation of the [[determinant]] of a matrix despite the apparent similarity of the definitions.

The permanent is defined similarly to the determinant, as a sum of products of sets of matrix entries that lie in distinct rows and columns. However, where the determinant weights each of these products with a ±1 sign based on the [[Parity of a permutation|parity of the set]], the permanent weights them all with a +1 sign.

While the determinant can be computed in [[polynomial time]] by [[Gaussian elimination]], it is generally believed that the permanent cannot be computed in polynomial time. In [[computational complexity theory]], [[Permanent is sharp-P-complete|a theorem of Valiant]] states that computing permanents is [[sharp-P-complete|#P-hard]], and even [[sharp-P-complete|#P-complete]] for matrices in which all entries are 0 or 1.{{harvtxt|Valiant|1979}}  This puts the computation of the permanent in a class of problems believed to be even more difficult to compute than [[NP (complexity)|NP]]. It is known that computing the permanent is impossible for logspace-uniform [[ACC0|ACC&lt;sup&gt;0&lt;/sup&gt;]] circuits.{{harv|Allender|Gore|1994}}

The development of both exact and approximate algorithms for computing the permanent of a matrix is an active area of research.

==Definition and naive algorithm==
The permanent of an ''n''-by-''n'' matrix ''A'' = (''a''&lt;sub&gt;''i,j''&lt;/sub&gt;) is defined as

: &lt;math&gt; \operatorname{perm}(A)=\sum_{\sigma\in S_n}\prod_{i=1}^n a_{i,\sigma(i)}.&lt;/math&gt;

The sum here extends over all elements σ of the [[symmetric group]] ''S''&lt;sub&gt;''n''&lt;/sub&gt;, i.e. over all [[permutation]]s of the numbers 1, 2, ..., ''n''. This formula differs from the corresponding formula for the determinant only in that, in the determinant, each product is multiplied by the [[Parity of a permutation|sign of the permutation]] σ while in this formula each product is unsigned. The formula may be directly translated into an algorithm that naively expands the formula, summing over all permutations and within the sum multiplying out each matrix entry. This requires ''n!'' ''n'' arithmetic operations.

==Ryser formula==
The best known&lt;ref&gt;As of 2008, see {{harvtxt|Rempala|Wesolowski|2008}}&lt;/ref&gt; general exact algorithm is due to {{harvs|first=H. J.|last=Ryser|authorlink=H. J. Ryser|year=1963|txt}}.
Ryser’s method is based on an [[inclusion–exclusion principle|inclusion–exclusion]] formula that can be given&lt;ref&gt;{{harvtxt|van Lint|Wilson|2001}} [https://books.google.com/books?id=5l5ps2JkyT0C&amp;pg=PA108&amp;dq=permanent+ryser&amp;lr=#PPA99,M1 p. 99]&lt;/ref&gt; as follows: Let &lt;math&gt;A_k&lt;/math&gt; be obtained from ''A'' by deleting ''k'' columns, let &lt;math&gt;P(A_k)&lt;/math&gt; be the product of the row-sums of &lt;math&gt;A_k&lt;/math&gt;, and  let &lt;math&gt;\Sigma_k&lt;/math&gt; be the sum of the values of &lt;math&gt;P(A_k)&lt;/math&gt; over all possible &lt;math&gt;A_k&lt;/math&gt;. Then
:&lt;math&gt; \operatorname{perm}(A)=\sum_{k=0}^{n-1} (-1)^{k}\Sigma_k.&lt;/math&gt;

It may be rewritten in terms of the matrix entries as follows&lt;ref&gt;{{harvtxt|CRC Concise Encyclopedia of Mathematics}}&lt;/ref&gt;
: &lt;math&gt;\operatorname{perm} (A) = (-1)^n \sum_{S\subseteq\{1,\dots,n\}} (-1)^{|S|} \prod_{i=1}^n \sum_{j\in S} a_{ij}.&lt;/math&gt;

Ryser’s formula can be evaluated using &lt;math&gt;O(2^{n-1}n^2)&lt;/math&gt; arithmetic operations, or &lt;math&gt;O(2^{n-1}n)&lt;/math&gt; by processing the sets &lt;math&gt;S&lt;/math&gt; in [[Gray code]] order.&lt;ref&gt;{{harvtxt|Nijenhuis|Wilf|1978}}&lt;/ref&gt;

==Balasubramanian–Bax–Franklin–Glynn formula==
Another formula that appears to be as fast as Ryser's (or perhaps even twice as fast) is to be found in the two Ph.D. theses; see {{harv|Balasubramanian|1980}}, {{harv|Bax|1998}}; also
{{harv|Bax|Franklin|1996}}. The methods to find the formula are quite different, being related to the combinatorics of the Muir algebra, and to finite difference theory respectively.  Another way, connected with invariant theory is via the [[polarization identity]] for a [[symmetric tensor]] {{harv|Glynn|2010}}.  The formula generalizes to infinitely many others, as found by all these authors, although it is not clear if they are any faster than the basic one. See {{harv|Glynn|2013}}.

The simplest known formula of this type (when the characteristic of the field is not two) is
: &lt;math&gt;\operatorname{perm}(A) = \frac{1}{2^{n-1}}\left[\sum_\delta \left(\prod_{k=1}^n \delta_k\right) \prod_{j=1}^n \sum_{i=1}^n \delta_i a_{ij}\right],&lt;/math&gt;
where the outer sum is over all &lt;math&gt;2^{n-1}&lt;/math&gt; vectors &lt;math&gt;\delta=(\delta_1=1,\delta_2,\dots,\delta_n)\in \{\pm1\}^n&lt;/math&gt;.

==Special cases==

===Planar and ''K''&lt;sub&gt;3,3&lt;/sub&gt;-free===
The number of [[perfect matching]]s in a [[bipartite graph]] is counted by the permanent of the graph's [[biadjacency matrix]], and the permanent of any 0-1 matrix can be [[Permanent (mathematics)|interpreted in this way]] as the number of perfect matchings in a graph. For [[planar graph]]s (regardless of bipartiteness), the [[FKT algorithm]] computes the number of perfect matchings in polynomial time by changing the signs of a carefully chosen subset of the entries in the [[Tutte matrix]] of the graph, so that the [[Pfaffian]] of the resulting [[skew-symmetric matrix]] (the [[square root]] of its [[determinant]]) is the number of perfect matchings. This technique can be generalized to graphs that contain no subgraph [[homeomorphism (graph theory)|homeomorphic]] to the [[complete bipartite graph]] ''K''&lt;sub&gt;3,3&lt;/sub&gt;.&lt;ref&gt;{{harvtxt|Little|1974}}, {{harvtxt|Vazirani|1988}}&lt;/ref&gt;

[[George Pólya]] had asked the question&lt;ref&gt;{{harvtxt|Pólya|1913}}, {{harvtxt|Reich|1971}}&lt;/ref&gt; of when it is possible to change the signs of some of the entries of a 01 matrix A so that the determinant of the new matrix is the permanent of A. Not all 01 matrices are "convertible" in this manner; in fact it is known ({{harvtxt|Marcus|Minc|1961}}) that
there is no linear map &lt;math&gt;T&lt;/math&gt; such that &lt;math&gt;\operatorname{per}\,T(A) = \det A&lt;/math&gt; for all &lt;math&gt;n\times n&lt;/math&gt; matrices &lt;math&gt;A&lt;/math&gt;. The characterization of "convertible" matrices was given by {{harvtxt|Little|1975}} who showed that such matrices are precisely those that are the biadjacency matrix of bipartite graphs that have a [[Pfaffian orientation]]: an orientation of the edges such that for every even cycle &lt;math&gt;C&lt;/math&gt; for which &lt;math&gt;G\setminus C&lt;/math&gt; has a perfect matching, there are an odd number of edges directed along C (and thus an odd number with the opposite orientation). It was also shown that these graphs are exactly those that do not contain a subgraph homeomorphic to &lt;math&gt;K_{3,3}&lt;/math&gt;, as above.

===Computation modulo a number===
[[modular arithmetic|Modulo]] 2, the permanent is the same as the determinant, as &lt;math&gt;(-1) \equiv 1 \pmod 2.&lt;/math&gt; It can also be computed modulo &lt;math&gt;2^k&lt;/math&gt; in time &lt;math&gt;O(n^{4k-3})&lt;/math&gt; for &lt;math&gt;k \ge 2&lt;/math&gt;. However, it is [[UP (complexity)|UP-hard]] to compute the permanent modulo any number that is not a power of 2. {{harvtxt|Valiant|1979}}

There are various formulae given by {{harvtxt|Glynn|2010}} for the computation modulo a prime {{mvar|p}}.
Firstly, there is one using symbolic calculations with partial derivatives.

Secondly,  for {{mvar|p}} = 3 there is the following formula  for an nxn-matrix &lt;math&gt;A&lt;/math&gt;, involving the matrix's principal
[[Minor (linear algebra)|minors]] ({{harvtxt|Kogan|1996}}): 
:&lt;math&gt;\operatorname{per} (A) = (-1)^{n}\Sigma_{J\subseteq \{1,\dots,n\}} \det(A_J)\det(A_{\bar J}),&lt;/math&gt;
where &lt;math&gt;A_J&lt;/math&gt; is the submatrix of &lt;math&gt;A&lt;/math&gt; induced by the rows and columns of &lt;math&gt;A&lt;/math&gt;
indexed by &lt;math&gt;J&lt;/math&gt;, and &lt;math&gt;\bar J&lt;/math&gt; is the complement of &lt;math&gt;J&lt;/math&gt; in &lt;math&gt;\{1,\dots,n\}&lt;/math&gt;, while the determinant of the empty submatrix is defined to be 1.

(Actually the above expansion can be generalized in an arbitrary [[Characteristic (linear algebra)|characteristic]] p as the following pair of dual identities:

&lt;math&gt;\operatorname{per} (A) = (-1)^{n}\Sigma_{{J_1},...,{J_{p-1}}} \det(A_{J_1})...\det(A_{J_{p-1}})&lt;/math&gt;

&lt;math&gt;\operatorname{det} (A) = (-1)^{n}\Sigma_{{J_1},...,{J_{p-1}}} \operatorname{per}(A_{J_1})...\operatorname{per}(A_{J_{p-1}})&lt;/math&gt;

where in both formulas the sum is taken over all the (p-1)-tuples &lt;math&gt;{J_1},...,{J_{p-1}}&lt;/math&gt; that are partitions of the set &lt;math&gt;\{1,\dots,n\}&lt;/math&gt; into p-1 subsets, some of them possibly empty.

The former formula possesses an analog for the hafnian of a symmetric &lt;math&gt;A&lt;/math&gt; and an odd p:

&lt;math&gt;\operatorname{haf}^2(A) = (-1)^{n}\Sigma_{{J_1},...,{J_{p-1}}} \det(A_{J_1})...\det(A_{J_{p-1}})(-1)^{|J_1|+...+|J_{(p-1)/2}|}&lt;/math&gt;
 
with the sum taken over the same set of indexes. Moreover, in [[Characteristic (linear algebra)|characteristic]] zero  a similar convolution sum expression involving both the permanent and the determinant yields the [[Hamiltonian path|Hamiltonian cycle]] polynomial (defined as &lt;math&gt; \operatorname{ham}(A)=\sum_{\sigma\in H_n}\prod_{i=1}^n a_{i,\sigma(i)}&lt;/math&gt; where &lt;math&gt;{H_n}&lt;/math&gt; is the set of n-permutations having only one cycle):
&lt;math&gt;\operatorname{ham} (A) = \Sigma_{J\subseteq \{2,\dots,n\}} \det(A_J)\operatorname{per}(A_{\bar J})(-1)^{|J|}&lt;/math&gt; . In [[Characteristic (linear algebra)|characteristic]] 2 the latter equality turns into &lt;math&gt;\operatorname{ham} (A) = \Sigma_{J\subseteq \{2,\dots,n\}} \det(A_J)\operatorname{det}(A_{\bar J})&lt;/math&gt; what therefore provides an opportunity to polynomial-time calculate the [[Hamiltonian path|Hamiltonian cycle]] polynomial of any [[Unitary matrix|unitary]] &lt;math&gt;U&lt;/math&gt; (i.e. such that &lt;math&gt;U^{T} U = I&lt;/math&gt; where &lt;math&gt;I&lt;/math&gt; is the identity nxn-matrix), because each minor of such a matrix coincides with its algebraic complement: &lt;math&gt; \operatorname{ham} (U) = \operatorname{det}^2(U + I_{/1}) &lt;/math&gt; where &lt;math&gt; I_{/1} &lt;/math&gt; is the identity nxn-matrix with the entry of indexes 1,1 replaced by 0. Moreover, it may, in turn, be further generalized for a [[Unitary matrix|unitary]] nxn-matrix &lt;math&gt;U&lt;/math&gt; as &lt;math&gt; \operatorname{ham_K} (U) = \operatorname{det}^2(U + I_{/K}) &lt;/math&gt; where &lt;math&gt;K&lt;/math&gt; is a subset of {1,...,n}, &lt;math&gt; I_{/K} &lt;/math&gt; is the identity nxn-matrix with the entries of indexes k,k replaced by 0 for all k beloning to &lt;math&gt;K&lt;/math&gt;, and we define &lt;math&gt; \operatorname{ham_K}(A)=\sum_{\sigma\in H_n{(K)}}\prod_{i=1}^n a_{i,\sigma(i)}&lt;/math&gt; where &lt;math&gt;{H_n{(K)}}&lt;/math&gt; is the set of n-permutations whose each cycle contains at least one element of &lt;math&gt;K&lt;/math&gt;.)

This formula implies the following identities over fields of [[Characteristic (linear algebra)|characteristic]] 3:

for any [[Invertible matrix|invertible]] &lt;math&gt;A&lt;/math&gt;
:&lt;math&gt;\operatorname{per}(A^{-1})\operatorname{det}^2(A) = \operatorname{per}(A) &lt;/math&gt;;
for any [[Unitary matrix|unitary]] &lt;math&gt;U&lt;/math&gt; , i.e. a square matrix &lt;math&gt;U&lt;/math&gt; such that &lt;math&gt;U^{T} U = I \,&lt;/math&gt;  where &lt;math&gt;I&lt;/math&gt; is the identity matrix of the corresponding size,
:&lt;math&gt;\operatorname{per}^2(U) = \det(U+V)\det(-U) &lt;/math&gt;
where  &lt;math&gt;V&lt;/math&gt; is the matrix whose entries are the cubes of the corresponding entries of &lt;math&gt;U&lt;/math&gt;.

It was also shown ({{harvtxt|Kogan|1996}}) that, if we define a square matrix &lt;math&gt;A&lt;/math&gt; as k-semi-unitary when &lt;math&gt;rank(A^{T} A - I \,)&lt;/math&gt; = {{mvar|k}},
the permanent of a 1-semi-unitary matrix is computable in polynomial time over fields of [[Characteristic (linear algebra)|characteristic]] 3, while for {{mvar|k}} &gt; 1 
the problem becomes [[Sharp-P-complete|#3-P-complete]]. (A parallel theory concerns the [[Hamiltonian path|Hamiltonian cycle]] polynomial in [[Characteristic (linear algebra)|characteristic]] 2: while computing it on the unitary matrices is polynomial-time feasible, the problem is #2-P-complete for the k-semi-unitary ones for any k &gt; 0). The latter result was essentially extended in 2017 ({{harvtxt|Knezevic|Cohen|2017}}) and it was proven that in [[Characteristic (linear algebra)|characteristic]] 3 there is a simple formula relating the permanents of a square matrix and its partial inverse (for &lt;math&gt;A_{11}&lt;/math&gt; and &lt;math&gt;A_{22}&lt;/math&gt; being square, &lt;math&gt;A_{11}&lt;/math&gt; being [[Invertible matrix|invertible]]):

&lt;math&gt;\operatorname{per\left ( \begin{matrix}A_{11} &amp; A_{12}\\ A_{21} &amp; A_{22}\end{matrix}  \right)  = det^{2}\left ( A_{11} \right )per\left ( \begin{matrix}A_{11}^{-1} &amp; A_{11}^{-1}A_{12}\\ A_{21}A_{11}^{-1} &amp; A_{22}-A_{21}A_{11}^{-1}A_{12}\end{matrix} \right )}&lt;/math&gt;

and it allows to polynomial-time reduce the computation of the permanent of an nxn-matrix with a subset of k or k-1 rows expressible as linear combinations of another (disjoint) subset of k rows to the computation of the permanent of an (n-k)x(n-k)- or (n-k+1)x(n-k+1)-matrix correspondingly, hence having introduced a compression operator (analogical to the Gaussian modification applied for calculating the determinant) that "preserves" the permanent in [[Characteristic (linear algebra)|characteristic]] 3. (Analogically, it would be worth noting that the [[Hamiltonian path|Hamiltonian cycle]] polynomial in [[Characteristic (linear algebra)|characteristic]] 2 does possess its invariant matrix compressions as well, taking into account the fact that ham(A) = 0 for any nxn-matrix A having three equal rows or, if n &gt; 2, a pair of indexes i,j such that its i-th and j-th rows are identical and its i-th and j-th columns are identical too.) The closure of that operator defined as the limit of its sequential application together with the transpose transformation (utilized each time the operator leaves the matrix intact) is also an operator mapping, when applied to classes of matrices, one class to another. While the compression operator maps the class of 1-semi-unitary matrices into itself and the classes of [[Unitary matrix|unitary]] and 2-semi-unitary ones, the compression-closure of the 1-semi-unitary class (as well as the class of matrices received from [[Unitary matrix|unitary]] ones through replacing one row by an arbitrary row vector — the permanent of such a matrix is, via the Laplace expansion, the sum of the permanents of 1-semi-unitary matrices and, accordingly, polynomial-time computable) is yet unknown and tensely related to the general problem of the permanent's computational complexity in [[Characteristic (linear algebra)|characteristic]] 3 and the chief question of [[P versus NP problem|P versus NP]]: as it was shown in ({{harvtxt|Knezevic|Cohen|2017}}), if such a compression-closure is the set of all square matrices over a field of [[Characteristic (linear algebra)|characteristic]] 3 or, at least, contains a matrix class the permanent's computation on is [[Sharp-P-complete|#3-P-complete]] (like the class of 2-semi-unitary matrices) then the permanent is computable in polynomial time in this [[Characteristic (linear algebra)|characteristic]].

Besides, the problem of finding and classifying any possible analogs of the permanent-preserving compressions existing in [[Characteristic (linear algebra)|characteristic]] 3 for other prime characteristics was formulated ({{harvtxt|Knezevic|Cohen|2017}}), while giving the following identity for an nxn matrix &lt;math&gt;A&lt;/math&gt; and two n-vectors (having all their entries from the set {0,...,p-1}) &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; such that &lt;math&gt;{\sum_{i=1}^{n}\alpha _{i}} = {\sum_{j=1}^{n}\beta _{j}}&lt;/math&gt;, valid in an arbitrary prime [[Characteristic (linear algebra)|characteristic]] p:

&lt;math&gt;\operatorname{per(A^{ \left( \alpha , \beta \right ) })   = det^{p-1}(A) per\left  ( A^{-1} \right ) ^{\left ( (p-1 \right ){\vec{1}}_{n}-\beta ,\left ( p-1 \right ){\vec{1}}_{n}-\alpha)}(\prod_{i=1}^{n}\alpha _{i}!)(\prod_{j=1}^{n}\beta _{j}!)\left ( -1 \right )^{n+\sum_{i=1}^{n}\alpha _{i}}}&lt;/math&gt;

where for an nxm-matrix &lt;math&gt;M&lt;/math&gt;, an n-vector &lt;math&gt;x&lt;/math&gt; and an m-vector &lt;math&gt;y&lt;/math&gt;, both vectors having all their entries from the set {0,...,p-1}, &lt;math&gt;M^{(x,y)}&lt;/math&gt; denotes the matrix received from &lt;math&gt;M&lt;/math&gt; via repeating &lt;math&gt;x_i&lt;/math&gt; times its i-th row for i = 1,...,n and &lt;math&gt;y_j&lt;/math&gt; times its j-th column for j = 1,...,m (if some row's or column's multiplicity equals zero it would mean that the row or column was removed, and thus this notion is a generalization of the notion of submatrix), and &lt;math&gt;{\vec{1}}_{n}&lt;/math&gt; denotes the n-vector all whose entries equal unity. This identity is an exact analog of the classical formula expressing a matrix's minor through a minor of its inverse and hence demonstrates (once more) a kind of duality between the determinant and the permanent as relative immanants. 
(Actually its own analogue for the hafnian of a symmetric &lt;math&gt;A&lt;/math&gt; and an odd prime p is   
&lt;math&gt;\operatorname{haf^2(A^{ \left( \alpha , \alpha \right ) })   = det^{p-1}(A) haf^2\left ( A^{-1} \right ) ^{\left ( (p-1 \right ){\vec{1}}_{n}-\alpha ,\left ( p-1 \right ){\vec{1}}_{n}-\alpha)} (\prod_{i=1}^{n}\alpha _{i}!)^2( -1)^{n(p-1)/2 + n+ \sum_{i=1}^{n}\alpha _{i}}}&lt;/math&gt; ).

And, as an even wider generalization for the partial inverse case in a prime [[Characteristic (linear algebra)|characteristic]] p, for &lt;math&gt;A_{11}&lt;/math&gt;, &lt;math&gt;A_{22}&lt;/math&gt; being square, &lt;math&gt;A_{11}&lt;/math&gt; being [[Invertible matrix|invertible]] and of size &lt;math&gt;{n_1}&lt;/math&gt;x&lt;math&gt;{n_1}&lt;/math&gt;, and &lt;math&gt;{\sum_{i=1}^{n}\alpha _{i}} = {\sum_{j=1}^{n}\beta _{j}}&lt;/math&gt;, there holds also the identity

&lt;math&gt;\operatorname{per\left ( \begin{matrix}A_{11} &amp; A_{12}\\ A_{21} &amp; A_{22}\end{matrix}   \right)^{ \left( \alpha , \beta \right )}  = det^{p-1}(A_{11}) per \left ( \begin{matrix}A_{11}^{-1} &amp; A_{11}^{-1}A_{12}\\ A_{21}A_{11}^{-1} &amp; A_{22} - A_{21}A_{11}^{-1}A_{12}\end{matrix} \right ) ^{\left ( (p-1 \right ){\vec{1}}_{n}-\beta ,\left ( p-1 \right ){\vec{1}}_{n}-\alpha)}(\prod_{i=1}^{n}\alpha _{1,i}!)(\prod_{j=1}^{n}\beta _{1,j}!)\left ( -1 \right )^{n_{1}+\sum_{i=1}^{n}\alpha _{1,i}}}&lt;/math&gt;

where the common row/column multiplicity vectors &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; for the matrix &lt;math&gt;A&lt;/math&gt; generate the corresponding row/column multiplicity vectors &lt;math&gt;\alpha_s&lt;/math&gt; and &lt;math&gt;\beta_t&lt;/math&gt;, s,t = 1,2, for its blocks (the same concerns &lt;math&gt;A&lt;/math&gt;'s partial inverse in the equality's right side).

==Approximate computation==
When the entries of ''A'' are nonnegative, the permanent can be computed [[approximation algorithm|approximately]] in [[randomized algorithm|probabilistic]] polynomial time, up to an error of ε''M'', where ''M'' is the value of the permanent and ε &gt; 0 is arbitrary. In other words, there exists a [[fully polynomial-time randomized approximation scheme]] (FPRAS) ({{harvtxt|Jerrum|Vigoda|Sinclair|2001}}).

The most difficult step in the computation is the construction of an algorithm to [[Sampling (statistics)|sample]] almost [[discrete uniform distribution|uniformly]] from the set of all perfect matchings in a given bipartite graph: in other words, a fully polynomial almost uniform sampler (FPAUS). This can be done using a [[Markov chain Monte Carlo]] algorithm that uses a [[Metropolis–Hastings algorithm|Metropolis rule]] to define and run a [[Markov chain]] whose distribution is close to uniform, and whose [[Markov chain mixing time|mixing time]] is polynomial.

It is possible to approximately count the number of perfect matchings in a graph via the [[Random self-reducibility|self-reducibility]] of the permanent, by using the FPAUS in combination with a well-known reduction from sampling to counting due to {{harvtxt|Jerrum|Valiant|Vazirani|1986}}. Let &lt;math&gt;M(G)&lt;/math&gt; denote the number of perfect matchings in &lt;math&gt;G&lt;/math&gt;. Roughly, for any particular edge &lt;math&gt;e&lt;/math&gt; in &lt;math&gt;G&lt;/math&gt;, by sampling many matchings in &lt;math&gt;G&lt;/math&gt; and counting how many of them are matchings in &lt;math&gt;G \setminus e&lt;/math&gt;, one can obtain an estimate of the ratio &lt;math&gt;\rho=\frac{M(G)}{M(G\setminus e)}&lt;/math&gt;. The number &lt;math&gt;M(G)&lt;/math&gt; is then &lt;math&gt;\rho M(G \setminus e)&lt;/math&gt;, where &lt;math&gt; M(G \setminus e)&lt;/math&gt; can be approximated by applying the same method recursively.

Another class of matrices for which the permanent can be computed approximately, is the set of [[Positive-definite matrix|positive-semidefinite matrices]] (the complexity-theoretic problem of approximating the permanent of such matrices to within a multiplicative error is considered open&lt;ref&gt;See open problem (4) at {{cite web|title=Shtetl Optimized: Introducing some British people to P vs. NP|url=http://www.scottaaronson.com/blog/?p=2408#comment-757410}}&lt;/ref&gt;). The corresponding randomized algorithm is based on the model of [[boson sampling]] and it uses the tools proper to [[quantum optics]], to represent the permanent of positive-semidefinite matrices as the expected value of a specific random variable. The latter is then approximated by its sample mean.&lt;ref&gt;{{cite journal|last1=Chakhmakhchyan|first1=Levon|last2=Cerf|first2=Nicolas|last3=Garcia-Patron|first3=Raul|title=A quantum-inspired algorithm for estimating the permanent of positive semidefinite matrices| journal = Phys. Rev. A|volume=96 |issue=2|pages=022329 |doi=10.1103/PhysRevA.96.022329|year=2017|bibcode=2017PhRvA..96b2329C|arxiv=1609.02416}}&lt;/ref&gt; This algorithm, for a certain set of positive-semidefinite matrices, approximates their permanent in polynomial time up to an additive error, which is more reliable than that of the standard classical polynomial-time algorithm by Gurvits.&lt;ref&gt;{{cite journal|last1=Gurvits|first1=Leonid|title=On the complexity of mixed discriminants and related problems|journal=Mathematical Foundations of Computer Science|date=2005|pages=447–458}}&lt;/ref&gt;

==Notes==
{{reflist|colwidth=30em}}

==References==
{{refbegin|colwidth=30em}}
*{{Citation
|last1 = Allender | first1= Eric
|last2= Gore | first2= Vivec
|title=A uniform circuit lower bound for the permanent
|journal=[[SIAM Journal on Computing]] |volume=23|number=5|pages=1026–1049|year= 1994 |doi=10.1137/s0097539792233907
|citeseerx=10.1.1.51.3546}}

*{{Citation
  | first = K. | last = Balasubramanian
  | title = Combinatorics and Diagonals of Matrices
  | series = Ph.D. Thesis, Department of Statistics, Loyola College, Madras, India
  | publisher = Indian Statistical Institute, Calcutta
  | volume = T073 |year= 1980
}}

*{{Citation
  | first = Eric | last = Bax
  | title = Finite-difference Algorithms for Counting Problems
  | series = Ph.D. Dissertation
  | publisher = California Institute of Technology
  | volume = 223 |year= 1998
}}

*{{Citation
  | first1 = Eric | last1 = Bax
  | first2 = J. | last2 = Franklin
  | title = A finite-difference sieve to compute the permanent
  | series = Caltech-CS-TR-96-04
  | publisher = California Institute of Technology
  | year = 1996
}}

*{{citation
  | first = David G. | last = Glynn
  | title = The permanent of a square matrix
  | journal = [[European Journal of Combinatorics]]
  | volume = 31
  | pages = 1887–1891
  | year = 2010
  | doi = 10.1016/j.ejc.2010.01.010
  | issue = 7
}}

*{{citation
  | first = David G. | last = Glynn
  | title = Permanent formulae from the Veronesean
  | journal = [[Designs, Codes and Cryptography]]
  | volume = 68
  | pages = 39–47
  | year = 2013
  | doi = 10.1007/s10623-012-9618-1
  | issue = 1-3
}}

*{{Citation
|last1=Jerrum|first1=M.|last2= Sinclair|first2=A.|last3=Vigoda|first3=E.|year=2001|id={{ECCC|2000|00|079}}|contribution= A polynomial-time approximation algorithm for the permanent of a matrix with non-negative entries|title=[[Symposium on Theory of Computing|Proc. 33rd Symposium on Theory of Computing]]|pages=712–721|doi=10.1145/380752.380877
}}
*{{Citation
|author1=Mark Jerrum|author2=Leslie Valiant|author3=Vijay Vazirani|title=Random generation of combinatorial structures from a uniform distribution|journal=Theoretical Computer Science|volume=43|year=1986|pages=169–188|doi=10.1016/0304-3975(86)90174-X|authorlink1=Mark Jerrum|authorlink2=Leslie Valiant|authorlink3=Vijay Vazirani
}}

*{{citation
  | first = Grigoriy |last = Kogan
  | title = Computing permanents over fields of characteristic 3: where and why it becomes difficult
  | journal = 37th Annual Symposium on Foundations of Computer Science (FOCS '96)
  | year = 1996
}}

*{{citation
  | first1 = Anna |last1 = Knezevic
  | first2 = Greg |last2 = Cohen
  | title = Some facts on Permanents in Finite Characteristics
  | arxiv= 1710.01783
  | year = 2017
|bibcode = 2017arXiv171001783K}}

*{{Citation
| last1= van Lint |first1= Jacobus Hendricus
| last2= Wilson |first2= Richard Michale
| title= A Course in Combinatorics | year=2001
|isbn = 0-521-00601-5
}}

*{{Citation
 | last = Little | first = C. H. C.
 | contribution = An extension of Kasteleyn's method of enumerating the 1-factors of planar graphs
 | editor-last = Holton | editor-first = D.
 | pages = 63–72
 | publisher = Springer-Verlag
 | series = Lecture Notes in Mathematics
 | title = Proc. 2nd Australian Conf. Combinatorial Mathematics
 | volume = 403
 | year = 1974
}}

*{{Citation
 | last= Little | first= C. H. C.
 | title=A characterization of convertible (0, 1)-matrices 
 | url= http://www.sciencedirect.com/science/article/B6WHT-4D7K7HW-H5/2/caa9448ac7c4e895fd7845515c7a68d1
 | journal= [[Journal of Combinatorial Theory]] | series = Series B
 | volume= 18 |year=1975
 | pages= 187–208
 | doi= 10.1016/0095-8956(75)90048-9
 | issue= 3
}}

*{{Citation
 | last1= Marcus | first1= M.| last2= Minc | first2= H.
 | title= On the relation between the determinant and the permanent
 | journal= Illinois Journal of Mathematics
 | volume= 5 |year=1961|pages= 376–381
}}

*{{Citation
 | title=Combinatorial Algorithms
 | last1= Nijenhuis |first1= Albert |last2= Wilf | first2= Herbert S.
 | publisher= Academic Press
 | year= 1978
}}

*{{Citation
|last= Pólya | first = G. |authorlink =George Pólya
|title=Aufgabe 424|journal= Arch. Math. Phys. |year= 1913| pages= 27
|volume= 20 |issue= 3
}}

*{{Citation
|last =Reich | first= Simeon
|journal= [[American Mathematical Monthly]]
|volume= 78 |year= 1971|pages=649–650
|jstor= 2316574
|title= Another solution of an old problem of pólya |issue= 6
|doi =10.2307/2316574
}}

*{{Citation
|title=Symmetric Functionals on Random Matrices and Random Matchings Problems
|first1= Grzegorz A. |last1=Rempała|first2=Jacek |last2=Wesolowski|year= 2008|isbn=0-387-75145-9|pages= 4
}}

*{{Citation
|last=Ryser| first= Herbert John|authorlink= H. J. Ryser
|title=Combinatorial Mathematics
|series=The Carus Mathematical Monographs, Vol. 14
|publisher=[[Mathematical Association of America]]
|year= 1963
}}

*{{Citation
 | last = Vazirani | first = Vijay V. | author-link = Vijay Vazirani
 | contribution = NC algorithms for computing the number of perfect matchings in K&lt;sub&gt;3,3&lt;/sub&gt;-free graphs and related problems
 | doi = 10.1007/3-540-19487-8_27
 | pages = 233–242
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = [[SWAT and WADS conferences|Proc. 1st Scandinavian Workshop on Algorithm Theory (SWAT '88)]]
 | volume = 318
 | year = 1988
}}

*{{Citation
  | first = Leslie G. | last = Valiant | authorlink = Leslie Valiant
  | title = The complexity of computing the permanent
  | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
  | volume = 8
  | pages = 189–201
  | publisher = Elsevier
  | location =
  | year = 1979
  | doi = 10.1016/0304-3975(79)90044-6
  | issue = 2
}}

*{{Citation
| title=CRC Concise Encyclopedia of Mathematics
| contribution=Permanent
| publisher= Chapman &amp; Hall/CRC
| year=2002
}}

{{refend}}

==Further reading==
* {{citation| first=A. | last= Barvinok | journal= [[Discrete Analysis]]| year=2017 | title= Approximating permanents and hafnians | doi= 10.19086/da.1244 }}.

{{DEFAULTSORT:Computing The Permanent}}
[[Category:Computational complexity theory]]
[[Category:Linear algebra]]
[[Category:Matrix theory]]
[[Category:Permutations]]
[[Category:Computational problems]]</text>
      <sha1>5ygehl3ujwy8xsfsbk78kedou4cctvg</sha1>
    </revision>
  </page>
  <page>
    <title>Decrement table</title>
    <ns>0</ns>
    <id>7008701</id>
    <revision>
      <id>869200117</id>
      <parentid>869116476</parentid>
      <timestamp>2018-11-17T01:31:35Z</timestamp>
      <contributor>
        <username>Mitch Ames</username>
        <id>6326132</id>
      </contributor>
      <comment>remove items from "See also" that are linked in body text, per [[MOS:NOTSEEALSO]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4436">'''Decrement tables''', also called '''life table methods''', are used to calculate the probability of certain events.&lt;!-- "Certain events"??  Like Hilary Clinton becoming president?  Or getting a "4" when you roll a pair of dice?  Or the probability that the dwarf-planet Pluto is less than 5 billion years old?  Or that more than six new galaxies will be discovered within the next year?  Well I don't think that's what it means.  "Certain events" needs to be made more explicit. --&gt;

==Birth control==
[[Life table]] methods are often used to study birth control effectiveness.  In this role, they are an alternative to the [[Pearl Index]].

As used in birth control studies, a decrement table calculates a separate effectiveness rate for each month of the study, as well as for a standard period of time (usually 12 months). Use of life table methods eliminates time-related biases (i.e. the most fertile couples getting pregnant and dropping out of the study early, and couples becoming more skilled at using the method as time goes on), and in this way is superior to the Pearl Index.

Two kinds of decrement tables are used to evaluate birth control methods. Multiple-decrement (or competing) tables report net effectiveness rates.  These are useful for comparing competing reasons for couples dropping out of a study. Single-decrement (or noncompeting) tables report gross effectiveness rates, which can be used to accurately compare one study to another.&lt;ref&gt;{{cite book | first=John | last=Kippley |author2=Sheila Kippley | year=1996 | title=The Art of Natural Family Planning | edition=4th addition | publisher=The Couple to Couple League | location=Cincinnati, OH | isbn=0-926412-13-2 | pages=140–141 }} which cites:&lt;br/&gt;
:{{cite journal | author= Trussell J | title= A guide to interpreting contraceptive efficacy studies | journal= Obstetrics and Gynecology | year= 1990 | volume= 76 |  pages= 558–567 | pmid=2199875 | issue= 3 Pt 2 |name-list-format=vanc| author2= Hatcher RA | author3= Cates W | display-authors= 3 | last4= Stewart | first4= FH | last5= Kost | first5= K }}
:{{cite journal | author= Potter RG | title= Application of life table techniques to measurement of contraceptive effectiveness | journal=Demography | year=1966 | volume=3 | issue=2 | pages= 297–304 | doi= 10.2307/2060159 | publisher= Demography, Vol. 3, No. 2 | jstor=2060159 | pmid= 21318704}}
:{{cite journal | author= Trussell J | title= Methodological pitfalls in the analysis of contraceptive failure | journal=Statistics in Medicine | year=1991 | volume=10 | pages=201–220 | pmid= 2052800 | doi= 10.1002/sim.4780100206 | issue= 2 }}
:{{cite journal |vauthors=Trussell J, Grummer-Strawn L | title= Further analysis of contraceptive failure of the ovulation method | journal= American Journal of Obstetrics and Gynecology | year= 1991 | volume= 165 | pages= 2054–2059 | pmid= 1755470 | issue= 6 Pt 2 | doi=10.1016/s0002-9378(11)90581-x}}
:{{cite journal | author= Sheps MC | title= Characteristics of a ratio used to estimate failure rates: occurrences per person year of exposure | journal=Biometrics | year= 1966 | volume= 22 |  pages= 310–321 | pmid=5961447 | doi= 10.2307/2528521 | issue= 2 | publisher= Biometrics, Vol. 22, No. 2 | jstor= 2528521 }}
:{{cite journal |vauthors=Trussell J, Kost K | title= Contraceptive failure in the United States: A critical review of the literature | journal= Studies in family planning | year= 1987 | volume= 18 | pages= 237–282 | pmid= 3318006 | doi= 10.2307/1966856 | issue= 5 | publisher= Studies in Family Planning, Vol. 18, No. 5 | jstor= 1966856 }}
:{{cite journal |vauthors=Trussell J, Grummer-Strawn L | title= Contraceptive failure of the ovulation method of periodic abstinence | journal= Family Planning Perspectives | year= 1990 | volume= 22 | pages= 65–75 | pmid= 2189750 | doi= 10.2307/2135511 | issue= 2 | publisher= Family Planning Perspectives, Vol. 22, No. 2 | jstor= 2135511 }}
:{{cite journal |vauthors=Trussell J, Strickler J, Vaughan B | title= Contraceptive efficacy of the diaphragm, the sponge and the cervical cap | journal= Family Planning Perspectives | year=1993 | volume=25 | pages= 100–105, 135 | pmid= 8354373 | doi= 10.2307/2136156 | issue= 3 | publisher= Family Planning Perspectives, Vol. 25, No. 3 | jstor= 2136156 }}&lt;/ref&gt;

==See also==
*[[Survival analysis]]

==Footnotes==
{{reflist}}

[[Category:Birth control]]
[[Category:Actuarial science]]</text>
      <sha1>t4heezmxx8isxtazml6bmedwsty5n8p</sha1>
    </revision>
  </page>
  <page>
    <title>Desuspension</title>
    <ns>0</ns>
    <id>47058944</id>
    <revision>
      <id>808574356</id>
      <parentid>797647591</parentid>
      <timestamp>2017-11-03T18:22:55Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>/* Definition */Follow-up, WL 1 first-publisher; [[WP:GenFixes]] on; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2113">In [[topology]], a field within mathematics, '''desuspension''' is an operation inverse to [[suspension (topology)|suspension]].&lt;ref&gt;{{cite conference|
first1=Luke|last1=Wolcott|first2=Elizabeth|last2=McTernan|
title=Imagining Negative-Dimensional Space|
pages=637–642|
book-title=Proceedings of Bridges 2012: Mathematics, Music, Art, Architecture, Culture|
year=2012|
editor-first1=Robert|editor-last1=Bosch|editor-first2=Douglas|editor-last2=McKenna|editor-first3=Reza|editor-last3=Sarhangi|
isbn=978-1-938664-00-7|
issn=1099-6702|
publisher=Tessellations Publishing|
location=Phoenix, Arizona, USA|
url=http://bridgesmathart.org/2012/cdrom/proceedings/65/paper_65.pdf|accessdate=25 June 2015
}}&lt;/ref&gt;

==Definition==
In general, given an ''n''-dimensional space &lt;math&gt;X&lt;/math&gt;, the suspension &lt;math&gt;\Sigma{X}&lt;/math&gt; has dimension ''n''&amp;nbsp;+&amp;nbsp;1. Thus, the operation of suspension creates a way of moving up in dimension. In the 1950s, to define a way of moving down, mathematicians introduced an inverse operation &lt;math&gt;\Sigma^{-1}&lt;/math&gt;, called desuspension.&lt;ref&gt;{{cite book|title=Spectra and the Steenrod Algebra|author=H. R. Margolis|url=|publisher=[[North-Holland]]|year=1983|page=454}}&lt;/ref&gt; Therefore, given an ''n''-dimensional space &lt;math&gt;X&lt;/math&gt;, the desuspension &lt;math&gt;\Sigma^{-1}{X}&lt;/math&gt; has dimension ''n''&amp;nbsp;–&amp;nbsp;1.

Note that in general &lt;math&gt;\Sigma^{-1}\Sigma{X}\ne X&lt;/math&gt;.

==Reasons==
The reasons to introduce desuspension:
#Desuspension makes the category of spaces a [[triangulated category]].
#If arbitrary [[coproduct]]s were allowed, desuspension would result in all [[cohomology]] [[functor]]s being representable.

==See also==
*[[Cone (topology)]]
*[[Equidimensionality]]
*[[Join (topology)]]
*[[Negative-dimensional space]]

==References==
{{Reflist}}

==External links==
*[https://static-content.springer.com/lookinside/chp%3A10.1007%2FBFb0075577/000.png Desuspension at an Odd Prime]
*[http://mathoverflow.net/questions/4117/when-can-you-desuspend-a-homotopy-cogroup When can you desuspend a homotopy cogroup?]

[[Category:Topology]]
[[Category:Homotopy theory]]</text>
      <sha1>74ce2logzoo17c3u5cvx5xuh8fsec5u</sha1>
    </revision>
  </page>
  <page>
    <title>Dyson's transform</title>
    <ns>0</ns>
    <id>21871152</id>
    <revision>
      <id>790702541</id>
      <parentid>784274445</parentid>
      <timestamp>2017-07-15T14:39:43Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* top */LaTeX spacing clean up, replaced: \ &lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2665">'''Dyson's transform''' is a fundamental technique in [[additive number theory]].&lt;ref name=nathanson&gt;Additive Number Theory: Inverse Problems and the Geometry of Sumsets
 By Melvyn Bernard Nathanson, Springer, Aug 22, 1996, {{ISBN|0-387-94655-1}}, https://books.google.com/books?id=PqlQjNhjkKUC&amp;dq=%22e-transform%22&amp;source=gbs_navlinks_s, p. 42&lt;/ref&gt; It was developed by [[Freeman Dyson]] as part of his proof of [[Mann's theorem]],&lt;ref name="Sequences"&gt;
{{cite book | last1 = Halberstam | first1 = H. |authorlink1 = Heini Halberstam | last2 = Roth | first2 = K. F. | authorlink2 =Klaus Roth | title = Sequences | publisher = Springer-Verlag | location = Berlin | year = 1983 | edition = revised | isbn = 978-0-387-90801-4 }}&lt;/ref&gt;{{Rp|17}} is used to prove such fundamental results of Additive Number Theory as the [[Cauchy-Davenport theorem]],&lt;ref name=nathanson /&gt; and was used by [[Olivier Ramaré]] in his work on the [[Goldbach conjecture]] that proved that every even integer is the sum of at most 6 primes.&lt;ref name="Ramaré"&gt;
{{cite journal | author=O. Ramaré | authorlink=Olivier Ramaré | title=On šnirel'man's constant | journal=Annali della Scuola Normale Superiore di Pisa. Classe di Scienze. Serie IV | volume=22 | year=1995 | issue=4 | pages=645–706 | url = http://www.numdam.org/item?id=ASNSP_1995_4_22_4_645_0 | accessdate = 2009-03-13}}
&lt;/ref&gt;{{Rp|700–701}} The term ''Dyson's transform'' for this technique is used by Ramaré.&lt;ref name="Ramaré" /&gt;{{Rp|700–701}} Halberstam and Roth call it the τ-transformation.&lt;ref name="Sequences"/&gt;{{Rp|58}}

This formulation of the transform is from Ramaré.&lt;ref name="Ramaré" /&gt;{{Rp|700–701}} Let ''A'' be a sequence of natural numbers, and ''x'' be any real number. Write ''A''(''x'') for the number of elements of ''A'' which lie in [1,&amp;nbsp;''x'']. Suppose &lt;math&gt;A= \{a_1&lt;a_2&lt; \cdots\}&lt;/math&gt; and &lt;math&gt;B= \{0=b_1&lt;b_2&lt;\cdots\} &lt;/math&gt; are two sequences of natural numbers. We write ''A''&amp;nbsp;+&amp;nbsp;''B'' for the [[sumset]], that is, the set of all elements ''a''&amp;nbsp;+&amp;nbsp;''b'' where ''a'' is in ''A'' and ''b'' is in B; and similarly ''A''&amp;nbsp;&amp;minus;&amp;nbsp;''B'' for the set of differences ''a''&amp;nbsp;&amp;minus;&amp;nbsp;''b''. For any element ''e'' in ''A'', Dyson's transform consists in forming the sequences &lt;math&gt; A'= A \cup \{B + \{e\}\}&lt;/math&gt;  and  &lt;math&gt;\,B'= B \cap \{A - \{e\}\}&lt;/math&gt;. The transformed sequences have the properties:

* &lt;math&gt;A' + B' \subset A + B &lt;/math&gt;
* &lt;math&gt;\{e\} + B' \subset A' &lt;/math&gt;
* &lt;math&gt;0 \in B' &lt;/math&gt;
* &lt;math&gt;A'(m)+ B'(m-e) = A(m) + B(m-e) &lt;/math&gt;

==References==
{{Reflist}}

[[Category:Sumsets]]
[[Category:Freeman Dyson]]


{{numtheory-stub}}</text>
      <sha1>7pox6mpa6erju5dal7gxnt6kwv2dvpo</sha1>
    </revision>
  </page>
  <page>
    <title>Dénes Kőnig</title>
    <ns>0</ns>
    <id>1327120</id>
    <revision>
      <id>869037617</id>
      <parentid>867801982</parentid>
      <timestamp>2018-11-16T00:43:47Z</timestamp>
      <contributor>
        <username>Wbm1058</username>
        <id>14383484</id>
      </contributor>
      <minor/>
      <comment>spelling (via [[WP:JWB]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7042">{{Infobox scientist
| name              = Dénes Kőnig
| image             = Dénes König.jpg
| image_size        = 200px
| caption           = 
| birth_date        = {{birth date|1884|09|21}}
| birth_place       = [[Budapest]], [[Austria-Hungary]]
| death_date        = {{death date and age|1944|10|19|1884|09|21}}
| death_place       = Budapest, [[Kingdom of Hungary (1920–1946)|Kingdom of Hungary]]
| nationality       = [[Kingdom of Hungary]]
| fields            = [[Mathematics]]
| workplaces        = [[Technical University of Budapest]]
| alma_mater        = Technical University of Budapest 
| doctoral_advisor  = {{plainlist|
*[[József Kürschák]]
*[[Hermann Minkowski]]}}
| doctoral_students = [[Tibor Gallai]]
| known_for         = 
| awards            = 
}}
'''Dénes Kőnig''' (September 21, 1884 – October 19, 1944) was a Hungarian [[mathematician]] of [[Hungarian Jews|Jewish]] heritage who worked in and wrote the first textbook on the field of [[graph theory]].

==Biography==
Kőnig was born in [[Budapest]], the son of mathematician [[Gyula Kőnig]]. In 1907, he received his doctorate&lt;ref name="Richard McCoart"&gt;{{cite book|first=Dénes|last=König|title=Theory of finite and infinite graphs|year=1990|publisher=Birkhäuser|location=Boston|isbn=0-8176-3389-8|page=423}} Translated by Richard McCoart ; with commentary by W.T. Tutte.&lt;/ref&gt; at, and joined the faculty of the Royal Joseph University in Budapest (today [[Budapest University of Technology and Economics]]). His classes were visited by [[Paul Erdős]], who, as a first year student, solved one of his problems. Kőnig became a full professor there in 1935.&lt;ref name="Richard McCoart" /&gt; To honor his fathers' death in 1913, Kőnig and his brother György created the [[Gyula Kőnig]] prize in 1918.&lt;ref name="Richard McCoart" /&gt; This prize was meant to be an endowment for young mathematicians, however was later devaluated. But the prize remained as a medal of high scientific recognition. In 1899, he published his first work while still attending High School&lt;ref name="Richard McCoart" /&gt; in a journal ''Matematikai és Fizikai Lapok''. After his graduation in 1902, he won first place in a mathematical competition "Eötvös Loránd".&lt;ref name="Richard McCoart" /&gt;  Shortly after he wrote the first of two book collections ''Matematikai Mulatságok'' (Mathematical Entertainments). He spent four semesters at the university in Budapest and his last five in Göttingen, during which he studied under the famous mathematicians [[József Kürschák]] and [[Hermann Minkowski]]. He then received his doctorate &lt;ref name="Richard McCoart" /&gt; in 1907 due to his dissertation in geometry, that same year he began working for the Technische Hochschule in [[Budapest]] and remained a part of the faculty till his death in 1944. At first he started as an assistant in problem sessions, in 1910 he was promoted to "oberassistant",&lt;ref name="Richard McCoart" /&gt; and then promoted to "Privatdocent" &lt;ref name="Richard McCoart" /&gt; in 1911 teaching nomography, analysis situs (later to be known as [[topology]]), set theory, real numbers and functions, and graph theory (the name "[[graph theory]]" didn't appear in the university catalogue until 1927). During this time he would be a guest speaker giving mathematics lecture for architecture and chemistry students, in 1920 these lectures made their way into book form.&lt;ref name="Richard McCoart" /&gt; at the Technische Hochschule.

From 1915 to 1942 he was on a committee to judge school contests in mathematics, collecting problems for these contests, and organizing them.&lt;ref name="Richard McCoart" /&gt; Then in 1933 he was elected as secretary of the society &lt;ref name="Richard McCoart" /&gt; and in 1942 he became the chairman of this committee.&lt;ref name="Richard McCoart" /&gt;  He then decided to make edits in the society's journal during his time on the committee till his death. Kőnig's activities and lectures played a vital role in the growth of graph theoretical work of: László Egyed, [[Paul Erdős]], [[Tibor Gallai]], [[György Hajós]], József Kraus, [[Tibor Szele]], [[Pál Turán]], Endre Vázsonyi, and many others.&lt;ref name="Richard McCoart" /&gt; He then went on to write the first book on [[graph theory]] ''Theorie der endlichen und unendlichen Graphen'' in 1936.&lt;ref name="Richard McCoart" /&gt;  This marked the beginning of graph theory as its own branch of mathematics. Then in 1958, [[Claude Berge]] wrote the second book on [[graph theory]], ''Théorie des Graphes et ses applications'',&lt;ref name="Richard McCoart" /&gt; following Kőnig.

After the [[Operation Margarethe|occupation of Hungary]] by the [[Nazi]]s, he worked to help persecuted mathematicians. On October 15, 1944 the National Socialist [[Arrow Cross Party]] took over the country.  Days later on October 19, 1944 he committed suicide to evade persecution from the Nazis being a Hungarian Jew.&lt;ref name="Richard McCoart" /&gt;

==Accomplishments==
:1899 – ''Matematikai és Fizikai Lapok'' written while attending High School&lt;ref name="Richard McCoart" /&gt;
:1902 – First place in "Eötvös Lorád"&lt;ref name="Richard McCoart" /&gt;
:1907 – received his Doctorate Degree&lt;ref name="Richard McCoart" /&gt;
:1910 – promoted to "oberassistant"&lt;ref name="Richard McCoart" /&gt;
:1911 – promoted to "Privatdocent" in 1911 teaching nomography, analysis situs (later to be known as [[topology]]), set theory, real numbers and functions, and graph theory&lt;ref name="Richard McCoart" /&gt;
:1935 – gained full professorship at Technische Hochschule&lt;ref name="Richard McCoart" /&gt;
:1936 – he wrote the first book on [[graph theory]], ''Theorie der endlichen und unendlichen Graphen''&lt;ref name="Richard McCoart" /&gt;

==See also==
*[[Kőnig's theorem (graph theory)]]
*[[Kőnig's theorem (set theory)]] is due to Dénes' father, [[Gyula Kőnig]].
*[[Kőnig's lemma]]
*[[Labyrinth problem]]

==Bibliography==
*{{cite book|last=Chartrand|first=Gary|title=A first course in graph theory|publisher=Dover Publications|location=Mineola, N.Y.|isbn=9780486483689|author2=Zhang, Ping |author2-link=Ping Zhang (graph theorist)}}
*{{Citation |first=Dénes |last=Kőnig |title=Theorie der endlichen und unendlichen Graphen |publisher=Akademische Verlagsgesellschaft |location=[[Leipzig]] |year=1936 }}.  Translated from [[German language|German]] by Richard McCoart, ''Theory of finite and infinite graphs'', Birkhäuser, 1990, {{isbn|0-8176-3389-8}}.

==Notes==
{{reflist}}

==External links==
*{{MacTutor Biography|id=Konig_Denes}}
*{{MathGenealogy |id=76334}}
*[http://www.versenyvizsga.hu/hun/eletrajzok/konigdenes.html a Hungarian biography site]
*[http://www.siam.org/prizes/sponsored/konig.php Dénes König Prize]

{{Authority control}}

{{DEFAULTSORT:Konig, Denes}}
[[Category:1884 births]]
[[Category:1944 deaths]]
[[Category:Jewish scientists]]
[[Category:20th-century Hungarian mathematicians]]
[[Category:Graph theorists]]
[[Category:Mathematicians who committed suicide]]
[[Category:Suicides in Hungary]]
[[Category:Austro-Hungarian mathematicians]]</text>
      <sha1>nov6gl8c4rx0d5pjld9do1tqzvke69j</sha1>
    </revision>
  </page>
  <page>
    <title>Eilenberg–Ganea conjecture</title>
    <ns>0</ns>
    <id>8211999</id>
    <revision>
      <id>829908531</id>
      <parentid>651765399</parentid>
      <timestamp>2018-03-11T15:29:17Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>copy-edit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1671">{{about|the conjecture|the theorem|Eilenberg–Ganea theorem}}

The '''Eilenberg–Ganea conjecture''' is a claim in [[algebraic topology]].  It was formulated by [[Samuel Eilenberg]] and [[Tudor Ganea]] in 1957, in a short, but influential paper.  It states that if a group ''G'' has [[cohomological dimension]]&amp;nbsp;2, then it has a 2-dimensional [[Eilenberg–MacLane space]] &lt;math&gt;K(G,1)&lt;/math&gt;.  For ''n'' different from 2, a group ''G'' of [[cohomological dimension]] ''n'' has an ''n''-dimensional Eilenberg–MacLane space. It is also known that a group of cohomological dimension 2 has a 3-dimensional Eilenberg−MacLane space.

In 1997,  [[Mladen Bestvina]] and Noel Brady constructed a group ''G'' so that either ''G'' is a counterexample to the Eilenberg–Ganea conjecture, or there must be a counterexample to the [[Whitehead conjecture]]; in other words, not both conjectures can be true. 

==References==
*{{Cite journal |first1=Samuel |last1=Eilenberg |authorlink1=Samuel Eilenberg|first2=Tudor |last2=Ganea |authorlink2=Tudor Ganea| title=On the Lusternik–Schnirelmann category of abstract groups |journal=[[Annals of Mathematics]] |series=2nd Ser. |volume=65 |year=1957 |issue=3 |pages=517–518 |doi=10.2307/1970062 |mr=0085510 }}
*{{Cite journal |first1=Mladen |last1=Bestvina |authorlink1=Mladen Bestvina|first2=Noel |last2=Brady |title=Morse theory and finiteness properties of groups |journal=[[Inventiones Mathematicae]] |volume=129 |year=1997 |issue=3 |pages=445–470 |doi=10.1007/s002220050168 |mr=1465330 }}

{{DEFAULTSORT:Eilenberg-Ganea conjecture}}
[[Category:Conjectures]]
[[Category:Theorems in algebraic topology]]

{{topology-stub}}</text>
      <sha1>b558f0nyoxc6kxe6qpzmzufjfdhbms6</sha1>
    </revision>
  </page>
  <page>
    <title>Fabius function</title>
    <ns>0</ns>
    <id>28192039</id>
    <revision>
      <id>842191846</id>
      <parentid>842191484</parentid>
      <timestamp>2018-05-20T21:19:21Z</timestamp>
      <contributor>
        <username>VladimirReshetnikov</username>
        <id>8541403</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4720">[[File:Mplwp Fabius function.svg|thumb|upright=1.35|Graph of the Fabius function on the interval &lt;nowiki&gt;[0,1]&lt;/nowiki&gt;.]]
[[File:Graph of the Fabius function.png|thumb|Extension of the function to the nonnegative real numbers.]]

In mathematics, the '''Fabius function''' is an example of an [[smoothness|infinitely differentiable function]] that is nowhere [[analytic function|analytic]], found by {{harvs|last=Fabius|first=Jaap|year=1966|txt}}. It was also written down as the Fourier transform of
 
:&lt;math&gt; \hat{f}(z) = \prod_{m=1}^\infty \left(\cos\frac{\pi z}{2^m}\right)^m&lt;/math&gt;

by  {{harvs|last1=Jessen|first1=Børge|and|last2=Wintner|first2=Aurel|year=1935|txt}}.

The Fabius function is defined on the unit interval, and is given by the [[cumulative distribution function]] of

:&lt;math&gt;\sum_{n=1}^\infty2^{-n}\xi_n,&lt;/math&gt;

where the {{math|''&amp;xi;''&lt;sub&gt;''n''&lt;/sub&gt;}} are [[independence (probability)|independent]] [[uniform distribution (continuous)|uniformly distributed]] [[random variable]]s on the [[unit interval]].

This function satisfies the initial condition &lt;math&gt;f(0) = 0&lt;/math&gt;, the symmetry condition &lt;math&gt;f(1-x) = 1 - f(x)&lt;/math&gt;  for &lt;math&gt;0 \le x \le 1,&lt;/math&gt; and the [[functional differential equation]] &lt;math&gt;f'(x) = 2 f(2 x)&lt;/math&gt; for &lt;math&gt;0 \le x \le 1/2.&lt;/math&gt; It follows that &lt;math&gt;f(x)&lt;/math&gt; is monotone increasing for &lt;math&gt;0 \le x \le 1,&lt;/math&gt; with &lt;math&gt;f(1/2)=1/2&lt;/math&gt; and &lt;math&gt;f(1)=1.&lt;/math&gt;
There is a unique extension of {{mvar|f}} to the real numbers that satisfies the same equation. This extension can be defined by {{math|1=''f''{{hsp}}(''x'') = 0}} for {{math|''x'' ≤ 0}}, {{math|1=''f''{{hsp}}(''x'' + 1) = 1 − ''f''{{hsp}}(''x'')}} for {{math|0 ≤ ''x'' ≤ 1}}, and {{math|1=''f''{{hsp}}(''x'' + 2&lt;sup&gt;''r''&lt;/sup&gt;) = −''f''{{hsp}}(''x'')}} for {{math|0 ≤ ''x'' ≤ 2&lt;sup&gt;''r''&lt;/sup&gt;}} with {{mvar|r}} a positive integer. The sequence of intervals within which this function is positive or negative follows the same pattern as the [[Thue–Morse sequence]].

==Values==
The Fabius function is constant zero for all negative arguments, and takes rational values at non-negative [[Dyadic rational|dyadic rationals]]. Those values are given by the following formula:
:&lt;math&gt;
f\!\left(\frac n{2^m}\right) = \sum_{\lambda=0}^{\left\lfloor m/2\right\rfloor}\!\sum_{\mu=0}^\lambda\sum_{\nu=1}^n\sum_{\kappa=1}^{2^\mu}\frac{(-1)^{\lambda+s_2(n-\nu)+s_2(\kappa-1)}}{2^{\binom{m+1}2-\binom\mu2+2\lambda\,(\mu+1)}}\cdot\frac{(2\nu-1)^{m-2\lambda}}{(m-2\lambda)!}\cdot\frac{(2\kappa-1)^{2\lambda+\mu+1}}{(2\lambda+\mu+1)!}\!\left(\prod_{\sigma=1}^\mu\frac1{4^\sigma-1}\!\right)\!\!\left(\prod_{\sigma=1}^{\lambda-\mu}\frac1{4^\sigma-1}\!\right)\!,&lt;/math&gt;
where &lt;math&gt;s_2(n)&lt;/math&gt; is the [[Digit sum|sum of digits]] of ''n'' in [[base-2]]. Note that &lt;math&gt;(-1)^{s_2(n)}=f(2n+1)=t_n&lt;/math&gt; is just the signed [[Thue–Morse sequence]], satisfying the recurrence &lt;math&gt;t_0=1,\,\,t_n=(-1)^n\,t_{\lfloor n/2\rfloor}.&lt;/math&gt;

==References==
*{{Citation | last1=Fabius | first1=J. | title=A probabilistic example of a nowhere analytic {{math|''C''{{hsp}}&lt;sup&gt;∞&lt;/sup&gt;}}-function | mr=0197656  | year=1966 | journal=Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete | volume=5 | issue=2 | pages=173–174 | doi=10.1007/bf00536652}}
*{{Citation | last1=Jessen | first1=Børge | last2=Wintner|first2=Aurel| title=Distribution functions and the Riemann zeta function | mr=1501802  | year=1935 | journal=Trans. Amer. Math. Soc. | volume=38 | pages=48–88  | doi=10.1090/S0002-9947-1935-1501802-5 }}
*{{cite thesis|first1=Youri |last1=Dimitrov |title=Polynomially-divided solutions of bipartite self-differential functional equations
|year= 2006 |url= http://rave.ohiolink.edu/etdc/view?acc_num=osu1155149204}}
*{{cite arxiv|first1=Jan Kristian |last1=Haugland |eprint=1609.07999 | title =Evaluating the Fabius function|year=2016|class=math.GM }}
*{{cite arxiv|first1=Juan|last1=Arias de Reyna|eprint=1702.06487|title=Arithmetic of the Fabius function|year=2017|class=math.NT }}
*{{cite arxiv|first1=Juan|last1=Arias de Reyna|eprint=1702.05442|title=An infinitely differentiable function with compact support: Definition and properties|year=2017|class=math.CA}} (an English translation of the author's paper published in Spanish in 1982)
[[Category:Types of functions]]
* Alkauskas, Giedrius  (2001), "Dirichlet series associated with Thue-Morse sequence", [https://web.archive.org/web/20180412220529id_/https://www.pdf-archive.com/2018/04/13/thue-morse/thue-morse.pdf preprint].
* Rvachev, V. L., Rvachev, V. A., "Non-classical methods of the approximation theory in boundary value problems", Naukova Dumka, Kiev (1979) (in Russian).


{{mathanalysis-stub}}</text>
      <sha1>aiunyhwlervkht89z6fv0a07nkcs01g</sha1>
    </revision>
  </page>
  <page>
    <title>Financial economics</title>
    <ns>0</ns>
    <id>63262</id>
    <revision>
      <id>870083942</id>
      <parentid>869050643</parentid>
      <timestamp>2018-11-22T07:39:22Z</timestamp>
      <contributor>
        <ip>169.202.235.1</ip>
      </contributor>
      <comment>/* State prices */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="84528">{{Economics sidebar}}
'''Financial economics''' is the branch of [[economics]] characterized by a "concentration on monetary activities", in which "money of one type or another is likely to appear on ''both sides'' of a trade".&lt;ref name="stanford1"&gt;[[William F. Sharpe]], [http://www.stanford.edu/~wfsharpe/mia/int/mia_int2.htm "Financial Economics"] {{Webarchive|url=https://web.archive.org/web/20040604105441/http://www.stanford.edu/~wfsharpe/mia/int/mia_int2.htm |date=2004-06-04 }}, in {{cite web |url=http://web.stanford.edu/~wfsharpe/mia/MIA.HTM |title=''Macro-Investment Analysis'' |publisher=Stanford University (manuscript) |accessdate=2009-08-06 |archive-url=https://web.archive.org/web/20140714034144/http://web.stanford.edu/~wfsharpe/mia/mia.htm |archive-date=2014-07-14 |dead-url=no |df= }}&lt;/ref&gt; Its concern is thus the interrelation of financial variables, such as prices, [[interest rate]]s and shares, as opposed to those concerning the [[real economy]]. It has two main areas of focus:&lt;ref name="Miller"&gt;[[Merton H. Miller]],  (1999).  The History of Finance: An Eyewitness Account, ''Journal of Portfolio Management''. Summer 1999.&lt;/ref&gt; [[asset pricing]] (or "investment theory") and [[corporate finance]]; the first being the perspective of providers of capital, i.e. investors, and the second of users of capital.

The subject is concerned with "the allocation and deployment of economic resources, both spatially and across time, in an uncertain environment".&lt;ref&gt;[[Robert C. Merton]] {{cite web |url=http://nobelprize.org/nobel_prizes/economics/laureates/1997/merton-lecture.pdf |title=Nobel Lecture |format=PDF |accessdate=2009-08-06 |archive-url=https://web.archive.org/web/20090319202149/http://nobelprize.org/nobel_prizes/economics/laureates/1997/merton-lecture.pdf |archive-date=2009-03-19 |dead-url=no |df= }}&lt;/ref&gt; It therefore centers on decision making under uncertainty in the context of the financial markets, and the resultant economic and financial models and principles, and is concerned with deriving testable or policy implications from acceptable assumptions. It is built on the foundations of [[microeconomics]] and [[decision theory]].

[[Financial econometrics]] is the branch of financial economics that uses econometric techniques to parameterise these relationships. [[Mathematical finance]] is related in that it will derive and extend the mathematical or numerical models suggested by financial economics. Note though that the emphasis there is mathematical consistency, as opposed to compatibility with economic theory. Financial economics has a primarily [[microeconomics|microeconomic]] focus, whereas [[monetary economics]] is primarily [[macroeconomics|macroeconomic]] in nature.

Financial economics is usually taught at the postgraduate level; see [[Master of Financial Economics]]. Recently, specialist undergraduate degrees are offered in the discipline.&lt;ref&gt;e.g.: [http://www.kent.ac.uk/courses/undergraduate/126/financial-economics Kent] {{Webarchive|url=https://web.archive.org/web/20140221212707/http://www.kent.ac.uk/courses/undergraduate/126/financial-economics |date=2014-02-21 }}; [http://www.city.ac.uk/courses/undergraduate/financial-economics City London] {{Webarchive|url=https://web.archive.org/web/20140223090217/http://www.city.ac.uk/courses/undergraduate/financial-economics |date=2014-02-23 }}; [http://undergradbusiness.ucr.edu/major/financial_economics.html UC Riverside] {{Webarchive|url=https://web.archive.org/web/20140222044845/http://undergradbusiness.ucr.edu/major/financial_economics.html |date=2014-02-22 }}; [http://www2.le.ac.uk/departments/economics/undergraduate Leicester] {{Webarchive|url=https://web.archive.org/web/20140222003101/http://www2.le.ac.uk/departments/economics/undergraduate |date=2014-02-22 }}; [http://www.economics.utoronto.ca/index.php/index/undergraduate/load/overview Toronto] {{Webarchive|url=https://web.archive.org/web/20140221102435/http://www.economics.utoronto.ca/index.php/index/undergraduate/load/overview |date=2014-02-21 }}; [http://economics.umbc.edu/bs-in-financial-economics/ UMBC] {{Webarchive|url=https://web.archive.org/web/20141230165120/http://economics.umbc.edu/bs-in-financial-economics/ |date=2014-12-30 }}&lt;/ref&gt;

This article provides an overview and survey of the field: for derivations and more technical discussion, see the specific articles linked.

==Underlying economics==
{| class="wikitable floatright" | width="250"
|- style="text-align:center;"
|JEL classification codes
|-
|In the [[JEL classification codes|Journal of Economic Literature classification codes]], Financial Economics is one of the 19 primary classifications, at JEL: G. It follows [[monetary economics|Monetary]] and [[International economics|International Economics]] and precedes [[public economics|Public Economics]]. For detailed subclassifications see {{sectionlink|JEL classification codes|G. Financial Economics}}.

''[[The New Palgrave Dictionary of Economics]]'' (2008, 2nd ed.) also uses the JEL codes to classify its entries in v. 8, Subject Index, including Financial Economics at pp.&amp;nbsp;863–64. The below have links to entry [[Abstract (summary)|abstracts]] of The New Palgrave [http://www.dictionaryofeconomics.com/dictionary Online] for each primary or secondary JEL category (10 or fewer per page, similar to [[Google]] searches):
:[http://www.dictionaryofeconomics.com/search_results?,q=&amp;field=content&amp;edition=all&amp;topicid=G JEL: G] – [[Financial Economics]]
:[http://www.dictionaryofeconomics.com/search_results?q=&amp;field=content&amp;edition=all&amp;topicid=G0 JEL: G0] – General
:[http://www.dictionaryofeconomics.com/search_results?q=&amp;field=content&amp;edition=all&amp;topicid=G1 JEL: G1] – [[Financial market|General Financial Markets]]
:[http://www.dictionaryofeconomics.com/search_results?q=&amp;field=content&amp;edition=all&amp;topicid=G2 JEL: G2] – [[Financial institution]]s and [[Financial services|Services]]
:[http://www.dictionaryofeconomics.com/search_results?q=&amp;field=content&amp;edition=all&amp;topicid=G3 JEL: G3] – [[Corporate finance]] and [[Corporate governance|Governance]]

Tertiary category entries can also be searched.&lt;ref&gt;For example, http://www.dictionaryofeconomics.com/search_results?q=&amp;field=content&amp;edition=all&amp;topicid=G00 {{Webarchive|url=https://web.archive.org/web/20130529074942/http://www.dictionaryofeconomics.com/search_results?q=&amp;field=content&amp;edition=all&amp;topicid=G00 |date=2013-05-29 }}.&lt;/ref&gt;
|}
As above, the discipline essentially explores how [[homo economicus|rational investors]] would apply [[decision theory]] to the problem of [[investment]]. The subject is thus built on the foundations of [[microeconomics]] and decision theory, and derives several key results for the application of [[decision making]] under uncertainty to the [[financial market]]s.

===Present value, expectation and utility===
Underlying all of financial economics are the concepts of [[present value]] and [[Expected value|expectation]].&lt;ref name="Rubinstein"/&gt;

Calculating their present value allows the decision maker to aggregate the [[cashflow]]s (or other returns) to be produced by the asset in the future, to a single value at the date in question, and to thus more readily compare two opportunities; this concept is therefore the starting point for financial decision making. (Its history is correspondingly early: [[Richard Witt]] discusses [[compound interest]] in depth already in 1613, in his book "Arithmeticall Questions";&lt;ref&gt;C. Lewin (1970). [https://www.actuaries.org.uk/system/files/documents/pdf/0121-0132.pdf An early book on compound interest] {{Webarchive|url=https://web.archive.org/web/20161221163926/https://www.actuaries.org.uk/system/files/documents/pdf/0121-0132.pdf |date=2016-12-21 }}, Institute and Faculty of Actuaries&lt;/ref&gt; further developed by [[Johan de Witt]] and [[Edmond Halley]].)

An immediate extension is to combine probabilities with present value, leading to the [[Expected value|expected value criterion]] which sets asset value as a function of the sizes of the expected payouts and the probabilities of their occurrence. (These ideas originate with [[Blaise Pascal]] and [[Pierre de Fermat]].)

This decision method, however, fails to consider [[risk aversion]] ("as any student of finance knows"&lt;ref name="Rubinstein"/&gt;). In other words, since individuals receive greater [[Utility#Economic definitions|utility]] from an extra dollar when they are poor and less utility when comparatively rich, the approach is to therefore "adjust" the weight assigned to the various outcomes ("states") correspondingly. (Some investors may in fact be [[risk seeking]] as opposed to [[Risk aversion|risk averse]], but the same logic would apply).

Choice under uncertainty here may then be characterized as the maximization of [[expected utility]]. More formally, the resulting [[expected utility hypothesis]] states that, if certain axioms are satisfied, the [[Subjective theory of value|subjective]] value associated with a gamble by an individual is ''that individual''{{'}}s [[Expected value|statistical expectation]] of the valuations of the outcomes of that gamble.

The impetus for these ideas arise from various inconsistencies observed under the expected value framework, such as the [[St. Petersburg paradox]]; see also [[Ellsberg paradox]]. (The development here is originally due to [[Daniel Bernoulli]], and later formalized by [[John von Neumann]] and [[Oskar Morgenstern]].)

===Arbitrage-free pricing and equilibrium===
The concepts of [[arbitrage]]-free, "rational", pricing and equilibrium are then coupled with the above to derive "classical"&lt;ref name="Rubinstein2"&gt;See Rubinstein under "Bibliography".&lt;/ref&gt;  (or "neo-classical"&lt;ref name="Derman"/&gt;) financial economics.

[[Rational pricing]] is the assumption that asset prices (and hence asset pricing models) will reflect the [[Arbitrage-free|arbitrage-free price]] of the asset, as any deviation from this price will be "arbitraged away". This assumption is useful in pricing fixed income securities, particularly bonds, and is fundamental to the pricing of derivative instruments.

[[Economic equilibrium]] is, in general, a state in which economic forces such as supply and demand are balanced, and, in the absence of external influences these equilibrium values of economic variables will not change. [[General equilibrium theory|General equilibrium]] deals with the behavior of supply, demand, and prices in a whole economy with several or many interacting markets, by seeking to prove that a set of prices exists that will result in an overall equilibrium. (This is in contrast to partial equilibrium, which only analyzes single markets.)

The two concepts are linked as follows: where market prices do not allow for profitable arbitrage, i.e. they comprise an arbitrage-free market, then these prices are also said to constitute an "arbitrage equilibrium". Intuitively, this may be seen by considering that where an arbitrage opportunity does exist, then prices can be expected to change, and are therefore not in equilibrium.&lt;ref name="Delbaen_Schachermayer"/&gt; An arbitrage equilibrium is thus a precondition for a general economic equilibrium.

The immediate, and formal, extension of this idea, the [[fundamental theorem of asset pricing]], shows that where markets are as described —and are additionally (implicitly and correspondingly) [[complete market|complete]]—one may then make financial decisions by constructing a [[Risk-neutral measure|risk neutral probability measure]] corresponding to the market.

"Complete" here means that there is a price for every asset in every possible state of the world, and that the complete set of possible bets on future states-of-the-world can therefore be constructed with existing assets (assuming [[Frictionless market|no friction]]), essentially [[System of linear equations|solving simultaneously]] for ''n'' (risk-neutral) probabilities, given ''n'' prices. The formal derivation will proceed by arbitrage arguments.&lt;ref name="Rubinstein"/&gt;&lt;ref name="Delbaen_Schachermayer"&gt;Freddy Delbaen and Walter Schachermayer. (2004). [http://www.ams.org/notices/200405/what-is.pdf "What is... a Free Lunch?"] {{Webarchive|url=https://web.archive.org/web/20160304061252/http://www.ams.org/notices/200405/what-is.pdf |date=2016-03-04 }} (pdf). Notices of the AMS 51 (5): 526–528&lt;/ref&gt; For a worked example see [[Rational pricing#Risk neutral valuation]], where, in a simplified environment, the economy has only two possible states—up and down—and where ''p'' and (1−''p'') are the two corresponding (i.e. implied) probabilities, and in turn, the derived distribution, or [[probability measure|"measure"]].

With this measure in place, the expected, i.e. required, return of any security (or portfolio) will then equal the riskless return, plus an "adjustment for risk",&lt;ref name="Rubinstein"/&gt; i.e. a security-specific [[risk premium]], compensating for the extent to which its cashflows are unpredictable. All pricing models are then essentially variants of this, given specific assumptions and/or conditions.&lt;ref name="Rubinstein"/&gt;&lt;ref name="Cochrane &amp; Culp"/&gt; This approach is consistent with [[#Present value, expectation and utility|the above]], but with the expectation based on "the market" (i.e. arbitrage-free, and, per the theorem, therefore in equilibrium) as opposed to individual preferences.

Thus, continuing the example, to value a specific security, its forecasted cashflows in the up- and down-states are multiplied through by ''p'' and (1-''p'') respectively, and are then [[present value|discounted]] at the risk-free interest rate plus an appropriate premium. In general, this premium may be derived by the [[Capital asset pricing model|CAPM]] (or extensions) as will be seen under [[#Uncertainty]].

===State prices===
With the above relationship established, the further specialized [[Arrow–Debreu model]] may be derived. This important result suggests that, under certain economic conditions, there must be a set of prices such that aggregate supplies will equal aggregate demands for every commodity in the economy. The analysis here is often undertaken assuming a ''[[representative agent]]''.&lt;ref name="Doyne_Geanakoplos"/&gt;

The Arrow–Debreu model applies to economies with maximally [[complete market]]s, in which there exists a market for every time period and forward prices for every commodity at all time periods. A direct extension, then, is the concept of a [[state price]] security (also called an Arrow–Debreu security), a contract that agrees to pay one unit of a [[numeraire]] (a currency or a commodity) if a particular state occurs ("up" and "down" in the simplified example above) at a particular time in the future and pays zero numeraire in all the other states. The price of this security is the state price of this particular state of the world.

In the above example, the state prices would equate to the present values of $p and $(1−p): i.e. what one would pay today, respectively, for the up- and down-state securities; the [[state price vector]] is the vector of state prices for all states.
Applied to valuation, the price of the derivative today would simply be [up-state-price × up-state-payoff + down-state-price × down-state-payoff]; see below regarding the absence of any risk premium here. For a [[continuous random variable]] indicating a continuum of possible states, the value is found by [[integration (mathematics)|integrating]] over the state price density; see [[Stochastic discount factor]]. These concepts are extended to [[martingale pricing]] and the related [[risk-neutral measure]].

State prices find immediate application as a conceptual tool ("[[contingent claim analysis]]");&lt;ref name="Rubinstein"/&gt; but can also be applied to valuation problems.&lt;ref name="corp fin state prices"&gt;See de Matos, as well as Bossaerts and Ødegaard, under bibliography.&lt;/ref&gt; Given the pricing mechanism described, one can decompose the derivative value — true in fact for "every security" &lt;ref name="Miller"/&gt; —  as a linear combination of its state-prices; i.e. back-solve for the state-prices corresponding to observed derivative prices.&lt;ref name="Chance2"/&gt;&lt;ref name="corp fin state prices"/&gt; These recovered state-prices can then be used for valuation of other instruments with exposure to the underlyer, or for other decision making relating to the underlyer itself. (Breeden and Litzenberger's work in 1978 &lt;ref&gt;{{cite journal |title=Prices of State-Contingent Claims Implicit in Option Prices |first=Douglas T. |last=Breeden |first2=Robert H. |last2=Litzenberger |author2-link=Robert Litzenberger |journal=[[Journal of Business]] |volume=51 |issue=4 |year=1978 |pages=621–651 |jstor=2352653 |doi=10.1086/296025}}&lt;/ref&gt; established the use of state prices in financial economics.)

==Resultant models==
[[Image:MM2.png|thumb|right|Modigliani–Miller Proposition II with risky debt. As [[leverage (finance)|leverage]] ([[Debt to equity ratio|D/E]]) increases, the [[weighted average cost of capital|WACC]] (k0) stays constant.]]
[[Image:markowitz frontier.jpg|thumb|right|Efficient Frontier. The hyperbola is sometimes referred to as the 'Markowitz Bullet', and its upward sloped portion is the efficient frontier if no risk-free asset is available. With a risk-free asset, the straight line is the efficient frontier. The graphic displays the CAL, [[Capital allocation line]], formed when the risky asset is a single-asset rather than the market, in which case the line is the CML.]]
[[Image:CML-plot.png|thumb|right|The Capital market line is the tangent line drawn from the point of the risk-free asset to the [[feasible region]] for risky assets. The tangency point M represents the [[market portfolio]]. The CML results from the combination of the market portfolio and the risk-free asset (the point L). Addition of leverage (the point R) creates levered portfolios that are also on the CML.]]
{| class="wikitable floatright" | width="250"
|- style="text-align:center;"
|{{small|The capital asset pricing model (CAPM)
:&lt;math&gt;E(R_i) = R_f + \beta_{i}(E(R_m) - R_f)&lt;/math&gt;}}
|}
[[Image:SML-chart.png|thumb|right|[[Security market line]]: the representation of the CAPM displaying the expected rate of return of an individual security as a function of its systematic, non-diversifiable risk.]]
[[Image:Stockpricesimulation.jpg|thumb|right|Simulated geometric Brownian motions with parameters from market data.]]
{| class="wikitable floatright" | width="250"
|- style="text-align:center;"
|{{small|[[Black–Scholes equation|The Black–Scholes equation]]
:&lt;math&gt;\frac{\partial V}{\partial t} + \frac{1}{2}\sigma^2 S^2 \frac{\partial^2 V}{\partial S^2} + rS\frac{\partial V}{\partial S} - rV = 0&lt;/math&gt;}}
|}
{| class="wikitable floatright" | width="250"
|- style="text-align:center;"
|{{small|[[Black–Scholes model#Black–Scholes formula|The Black–Scholes formula]] for the value of a call option:
:&lt;math&gt;\begin{align}
  C(S, t) &amp;= N(d_1)S - N(d_2) Ke^{-r(T - t)} \\
     d_1 &amp;= \frac{1}{\sigma\sqrt{T - t}}\left[\ln\left(\frac{S}{K}\right) + \left(r + \frac{\sigma^2}{2}\right)(T - t)\right] \\
     d_2 &amp;= d_1 - \sigma\sqrt{T - t} \\
\end{align}&lt;/math&gt;
[[Black–Scholes model#Interpretation|Interpretation]]: &lt;math&gt;N(d_2)&lt;/math&gt; is the probability that the call will be exercised; &lt;math&gt;N(d_1)S&lt;/math&gt; is the present value of the expected asset price at expiration, [[Conditional probability|given that]] the asset price at expiration is above the exercise price.}}
|}
Applying the preceding economic concepts, we may then derive various [[economic model|economic-]] and financial models and principles. As above, the two usual areas of focus are Asset Pricing and Corporate Finance, the first being the perspective of providers of capital, the second of users of capital. Here, and for (almost) all other financial economics models, the questions addressed are typically framed in terms of "time, uncertainty, options, and information",&lt;ref name="stanford1"/&gt;&lt;ref name="Doyne_Geanakoplos"/&gt; as will be seen below.
* Time: money now is traded for money in the future.
* Uncertainty (or risk): The amount of money to be transferred in the future is uncertain.
* [[Option (finance)|Options]]: one party to the transaction can make a decision at a later time that will affect subsequent transfers of money.
* [[Perfect information|Information]]: knowledge of the future can reduce, or possibly eliminate, the uncertainty associated with [[Future value|future monetary value]] (FMV).
Applying this framework, with the above concepts, leads to the required models. This derivation begins with the assumption of "no uncertainty" and is then expanded to incorporate the other considerations. (This division sometimes denoted "[[deterministic]]" and "random",&lt;ref name="Luenberger"/&gt; or "[[stochastic]]".)

===Certainty===
The starting point here is “Investment under certainty". The [[Fisher separation theorem]], asserts that the objective of a corporation will be the maximization of its present value, regardless of the preferences of its shareholders. Related is the [[Modigliani–Miller theorem]], which shows that, under certain conditions, the value of a firm is unaffected by how that firm is financed, and depends neither on its dividend policy nor its decision to raise capital by issuing stock or selling debt. The proof here proceeds using arbitrage arguments, and acts as a benchmark for evaluating the effects of factors outside the model that do affect value.

The mechanism for determining (corporate) value is provided by ''[[The Theory of Investment Value]]'' (John Burr Williams), which proposes that the value of an asset should be calculated using "evaluation by the rule of present worth". Thus, for a common stock, the intrinsic, long-term worth is the present value of its future net cashflows, in the form of [[dividend]]s. What remains to be determined is the appropriate discount rate. Later developments show that, "rationally", i.e. in the formal sense, the appropriate discount rate here will (should) depend on the asset's riskiness relative to the overall market, as opposed to its owners' preferences; see below. [[Net present value]] (NPV) is the direct extension of these ideas typically applied to Corporate Finance decisioning (introduced by [[Joel Dean (economist)|Joel Dean]] in 1951). For other results, as well as specific models developed here, see the list of "Equity valuation" topics under [[Outline of finance#Discounted cash flow valuation]].

[[Bond valuation]], in that cashflows (coupons and return of principal) are deterministic, may proceed in the same fashion.&lt;ref name="Luenberger"&gt;See Luenberger's ''Investment Science'', under Bibliography.&lt;/ref&gt; An immediate extension, [[Bond valuation#Arbitrage-free pricing approach|Arbitrage-free bond pricing]], discounts each cashflow at the market derived rate — i.e. at each coupon's corresponding zero-rate — as opposed to an overall rate.  Note that in many treatments bond valuation precedes [[equity valuation]], under which cashflows (dividends) are not "known" ''per se''. Williams and onward allow for forecasting as to these — based on historic ratios or published policy — and cashflows are then treated as essentially deterministic; see below under [[#Corporate finance theory]].

These "certainty" results are all commonly employed under corporate finance; uncertainty is the focus of "asset pricing models", as follows.

===Uncertainty===
For [[Decision theory#Choice under uncertainty|"choice under uncertainty"]] the twin assumptions of rationality and [[Financial market efficiency|market efficiency]], as more closely defined, lead to [[modern portfolio theory]] (MPT) with its [[capital asset pricing model]] (CAPM)—an ''equilibrium-based'' result—and to the [[Black–Scholes model|Black–Scholes–Merton theory]] (BSM; often, simply Black–Scholes) for [[Valuation of options|option pricing]]—an ''arbitrage-free'' result. Note that the latter derivative prices are calculated such that they are arbitrage-free with respect to the more fundamental, equilibrium determined, securities prices; see [[asset pricing]].

Briefly, and intuitively—and consistent with [[#Arbitrage-free pricing and equilibrium]] above—the linkage is as follows.&lt;ref&gt;For a more formal treatment, see, for example: Eugene F. Fama. 1965. [http://www.cfapubs.org/toc/faj/1965/21/5 Random Walks in Stock Market Prices]. ''[[Financial Analysts Journal]]'', September/October 1965, Vol. 21, No. 5: 55–59.&lt;/ref&gt; Given the ability to profit from private information, self-interested traders are motivated to acquire and act on their private information. In doing so, traders contribute to more and more "correct", i.e. ''efficient'', prices: the [[efficient-market hypothesis]], or EMH ([[Eugene Fama]], 1965). The EMH (implicitly) assumes that average expectations constitute an "optimal forecast", i.e. prices using all available information, are identical to the ''best guess of the future'': the assumption of [[rational expectations]]. The EMH does allow that when faced with new information, some investors may overreact and some may underreact, but what is required, however, is that investors' reactions follow a [[normal distribution]]—so that the net effect on market prices cannot be reliably exploited to make an abnormal profit.
In the competitive limit, then, market prices will reflect all available information and prices can only move in response to news;&lt;ref name="Shiller"/&gt; and this, of course, could be "good" or "bad", major or minor: the [[random walk hypothesis]]. Thus, if prices of financial assets are (broadly) efficient, then deviations from these (equilibrium) values could not last for long. (On Random walks in stock prices: [[Jules Regnault]], 1863; [[Louis Bachelier]], 1900; [[Maurice Kendall]], 1953; [[Paul Cootner]], 1964.)

Under these conditions investors can then be assumed to act rationally: their investment decision must be calculated or a loss is sure to follow; correspondingly, where an arbitrage opportunity presents itself, then arbitrageurs will exploit it, reinforcing this equilibrium.
Here, as under the certainty-case above, the specific assumption as to pricing is that prices are calculated as the present value of expected future dividends,&lt;ref name="Cochrane &amp; Culp"&gt;Christopher L. Culp and [[John H. Cochrane]]. (2003). "[http://faculty.chicagobooth.edu/john.cochrane/research/Papers/cochrane-culp%20asset%20pricing.pdf "Equilibrium Asset Pricing and Discount Factors: Overview and Implications for Derivatives Valuation and Risk Management"] {{Webarchive|url=https://web.archive.org/web/20160304190225/http://faculty.chicagobooth.edu/john.cochrane/research/Papers/cochrane-culp%20asset%20pricing.pdf |date=2016-03-04 }}, in ''Modern Risk Management: A History''. Peter Field, ed. London: Risk Books, 2003. {{ISBN|1904339050}}&lt;/ref&gt;&lt;ref name="Shiller"&gt;{{cite journal|last= Shiller|first= Robert J.|authorlink= Robert J. Shiller|date= 2003|title= From Efficient Markets Theory to Behavioral Finance|journal= [[Journal of Economic Perspectives]]|volume= 17|issue= 1 (Winter 2003)|pages= 83–104|url= http://www.econ.yale.edu/~shiller/pubs/p1055.pdf|accessdate= |doi= 10.1257/089533003321164967|archive-url= https://web.archive.org/web/20150412081613/http://www.econ.yale.edu/~shiller/pubs/p1055.pdf|archive-date= 2015-04-12|dead-url= no|df= }}&lt;/ref&gt;&lt;ref name="Doyne_Geanakoplos"/&gt; as based on currently available information.
What is required though is a theory for determining the appropriate discount rate, i.e. "required return", given this uncertainty: this is provided by the MPT and its CAPM. Relatedly, rationality—in the sense of arbitrage-exploitation—gives rise to Black–Scholes; option values here ultimately consistent with the CAPM.

In general, then, while portfolio theory studies how investors should balance risk and return when investing in many assets or securities, the CAPM is more focused, describing how, in equilibrium, markets set the prices of assets in relation to how risky they are.
Importantly, this result will be independent of the investor's level of risk aversion, and / or assumed utility function, thus providing a readily determined discount rate for corporate finance decision makers [[Financial economics#Certainty|as above]],&lt;ref name ="Jensen&amp;Smith"&gt;[[Michael C. Jensen|Jensen, Michael C.]] and Smith, Clifford W., "The Theory of Corporate Finance: A Historical Overview". In: ''The Modern Theory of Corporate Finance'', New York: McGraw-Hill Inc., pp. 2–20, 1984.&lt;/ref&gt; and for other investors.
The argument proceeds as follows: If one can construct an [[efficient frontier]]—i.e. each combination of assets offering the best possible expected level of return for its level of risk, see diagram—then mean-variance efficient portfolios can be formed simply as a combination of holdings of the [[Risk-free interest rate|risk-free asset]] and the "[[market portfolio]]" (the [[Mutual fund separation theorem]]), with the combinations here plotting as the [[capital market line]], or CML. Then, given this CML, the required return on risky securities will be independent of the investor's [[utility function]], and solely determined by their [[covariance]] ("beta") with aggregate, i.e. market, risk. This is because investors here can then maximize utility through leverage as opposed to pricing; see CML diagram. As can be seen in the formula aside, this result is consistent with [[Financial economics#Arbitrage-free pricing and equilibrium|the preceding]], equaling the riskless return plus an adjustment for risk.&lt;ref name="Cochrane &amp; Culp"/&gt; &lt;!-- See also: [[Security characteristic line]]; [[Security market line]]; [[Capital allocation line]]; [[Capital market line]]; [[Sharpe ratio]]; [[Jensen's alpha]]; [[Portfolio optimization]]. --&gt; (The efficient frontier was introduced by [[Harry Markowitz]] in 1952. The CAPM was derived by [[Jack L. Treynor|Jack Treynor]] (1961, 1962), [[William F. Sharpe]] (1964), [[John Lintner]] (1965) and [[Jan Mossin]] (1966) independently.)

Black–Scholes provides a mathematical model of a financial market containing [[Derivative (finance)|derivative]] instruments, and the resultant formula for the price of [[option style|European-styled options]].
The model is expressed as the Black–Scholes equation, a [[partial differential equation]] describing the changing price of the option over time; it is derived assuming log-normal, [[geometric Brownian motion]] (see [[Brownian model of financial markets]]).
The key financial insight behind the model is that one can perfectly hedge the option by buying and selling the underlying asset in just the right way and consequently "eliminate risk", absenting the risk adjustment from the pricing (&lt;math&gt;V&lt;/math&gt;, the value, or price, of the option, grows at &lt;math&gt;r&lt;/math&gt;, the risk-free rate; see {{sectionlink|Black–Scholes equation|Financial interpretation}}).&lt;ref name="Rubinstein"/&gt;&lt;ref name="Cochrane &amp; Culp"/&gt;
This hedge, in turn, implies that there is only one right price—in an arbitrage-free sense—for the option. And this price is returned by the Black–Scholes option pricing formula. (The formula, and hence the price, is consistent with the equation, as the formula is [[Partial differential equation#Analytical solutions|the solution]] to the equation.)
Since the formula is without reference to the share's expected return, Black–Scholes entails (assumes) risk neutrality, consistent with the "elimination of risk" here. Relatedly, therefore, the pricing formula may also be derived directly via risk neutral expectation.
(BSM -  two seminal 1973 papers
&lt;ref name="BlackScholes_paper"&gt;{{cite journal|title=The Pricing of Options and Corporate Liabilities|last=Black|first=Fischer|author2=Myron Scholes|journal=Journal of Political Economy|year=1973|volume=81|issue=3|pages=637–654|doi=10.1086/260062}} [https://www.jstor.org/stable/1831029]&lt;/ref&gt; 
&lt;ref name="Merton_paper"&gt; {{cite journal|title=Theory of Rational Option Pricing|last=Merton|first=Robert C.|journal=Bell Journal of Economics and Management Science|year=1973|volume=4|issue=1|pages=141–183|doi=10.2307/3003143|publisher=The RAND Corporation|jstor=3003143}} [https://www.jstor.org/stable/3003143]&lt;/ref&gt;
- is consistent with "previous versions of the formula" of [[Louis Bachelier]] and [[Edward O. Thorp]];&lt;ref name="Haug Taleb"&gt;Haug, E. G. and [[Nassim Nicholas Taleb|Taleb, N. N.]] (2008): [http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1012075 Why We Have Never Used the Black-Scholes-Merton Option Pricing Formula] {{Webarchive|url=https://web.archive.org/web/20110503181600/http://papers.ssrn.com/sol3/papers.cfm?abstract_id=1012075 |date=2011-05-03 }}, ''Wilmott Magazine'' January 2008&lt;/ref&gt; although these were more "actuarial" in flavor, and had not established risk-neutral discounting.&lt;ref name="Derman"/&gt; See also [[Paul Samuelson]] (1965).&lt;ref&gt;{{cite journal | author = Samuelson Paul | authorlink = Paul Samuelson | year = 1965 | title = A Rational Theory of Warrant Pricing | url = http://www.dse.unisalento.it/c/document_library/get_file?folderId=1344637&amp;name=DLFE-157230.pdf | format = PDF | journal = Industrial Management Review | volume = 6 | issue =  | page = 2 | access-date = 2017-02-28 | archive-url = https://web.archive.org/web/20170301092720/http://www.dse.unisalento.it/c/document_library/get_file?folderId=1344637&amp;name=DLFE-157230.pdf | archive-date = 2017-03-01 | dead-url = no | df =  }}&lt;/ref&gt; [[Vinzenz Bronzin]] (1908) produced very early results.)

As mentioned, it can be shown that the two models are consistent; then, as is to be expected, "classical" financial economics is thus unified. Here, the Black Scholes equation may alternatively be derived from the CAPM, and the price obtained from the Black–Scholes model is thus consistent with the expected return from the CAPM.&lt;ref name="Chance1"&gt;Don M. Chance (2008). [http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN03-01.pdf "Option Prices and Expected Returns"] {{Webarchive|url=https://web.archive.org/web/20150923195335/http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN03-01.pdf |date=2015-09-23 }}&lt;/ref&gt;&lt;ref name="Derman"&gt;Emanuel Derman, [http://www.emanuelderman.com/media/Scientific_Approach_to_Finance.pdf ''A Scientific Approach to CAPM and Options Valuation''] {{Webarchive|url=https://web.archive.org/web/20160330002200/http://www.emanuelderman.com/media/Scientific_Approach_to_Finance.pdf |date=2016-03-30 }}&lt;/ref&gt; The Black–Scholes theory, although built on Arbitrage-free pricing, is therefore consistent with the equilibrium based capital asset pricing. Both models, in turn, are ultimately consistent with the Arrow–Debreu theory, and may be derived via state-pricing,&lt;ref name="Rubinstein"&gt;[[Mark Rubinstein|Rubinstein, Mark]]. (2005). "Great Moments in Financial Economics: IV. The Fundamental Theorem (Part I)", ''Journal of Investment Management'', Vol. 3, No. 4, Fourth Quarter 2005; ~ (2006). Part II, Vol. 4, No. 1, First Quarter 2006. See under "External links".&lt;/ref&gt; further explaining, and if required demonstrating, this unity.

==Extensions==
More recent work further generalizes and / or extends these models.  As regards [[asset pricing]], developments in equilibrium-based pricing are discussed under "Portfolio theory" below, while "Derivative pricing" relates to risk-neutral, i.e. arbitrage-free, pricing.  As regards the use of capital, "Corporate finance theory" relates, mainly, to the application of these models.

===Portfolio theory===
[[Image:Pareto Efficient Frontier for the Markowitz Portfolio selection problem..png|thumb|right|200px|Plot of two criteria when maximizing return and minimizing risk in [[Portfolio (finance)|financial portfolios]] ([[pareto efficient|Pareto-optimal]] points in red)]]
:''See also: [[Post-modern portfolio theory]] and {{sectionlink|Mathematical finance|Risk and portfolio management: the P world}}.''
The majority of developments here relate to required return, i.e. pricing, extending the basic CAPM. Multi-factor models such as the [[Fama–French three-factor model]] and the [[Carhart four-factor model]], propose factors other than market return as relevant in pricing. The [[intertemporal CAPM]] and [[Consumption-based capital asset pricing model|consumption-based CAPM]] similarly extend the model. With [[intertemporal portfolio choice]], the investor now repeatedly optimizes her portfolio; while the inclusion of [[Consumption (economics)|consumption (in the economic sense)]] then incorporates all sources of wealth, and not just market-based investments, into the investor's calculation of required return.

Whereas the above extend the CAPM, the [[single-index model]] is a more simple model. It assumes, only, a correlation between security and market returns, without (numerous) other economic assumptions. It is useful in that it simplifies the estimation of correlation between securities, significantly reducing the inputs for building the correlation matrix required for portfolio optimization. The [[arbitrage pricing theory]] (APT; [[Stephen Ross (economist)|Stephen Ross]], 1976) similarly differs as regards its assumptions. APT "gives up the notion that there is one right portfolio for everyone in the world, and ...replaces it with an explanatory model of what drives asset returns."&lt;ref&gt;''The Arbitrage Pricing Theory,'' Chapter VI in Goetzmann, under External links.&lt;/ref&gt; It returns the required (expected) return of a financial asset as a linear function of various macro-economic factors, and assumes that arbitrage should bring incorrectly priced assets back into line.

As regards [[portfolio optimization]], the [[Black–Litterman model]] departs from [[Harry Markowitz#Harry Markowitz Model|the original Markowitz approach]] of constructing portfolios via an [[efficient frontier]]. Black–Litterman instead starts with an equilibrium assumption, and is then modified to take into account the 'views' (i.e., the specific opinions about asset returns) of the investor in question to arrive at a bespoke asset allocation. Where factors additional to volatility are considered (kurtosis, skew...) then [[multiple-criteria decision analysis]] can be applied; here deriving a [[Pareto efficient]] portfolio. The [[universal portfolio algorithm]] ([[Thomas M. Cover]]) applies [[machine learning]] to asset selection, learning adaptively from historical data. [[Behavioral portfolio theory]] recognizes that investors have varied aims and create an investment portfolio that meets a broad range of goals.  Copulas have [[Copula (probability theory)#Quantitative finance|lately been applied here]].  See {{sectionlink|Portfolio optimization|Improving portfolio optimization}} for other techniques and / or objectives.

===Derivative pricing===
[[File:Arbre Binomial Options Reelles.png|thumb|right| Binomial Lattice with [[Binomial options pricing model#STEP 1: Create the binomial price tree|CRR formulae]] ]]
{{See also|Mathematical finance#Derivatives pricing: the Q world}}
{| class="wikitable floatright" | width="250"
|- style="text-align:center;"
| {{small|PDE for a zero-coupon bond
:&lt;math&gt;\frac{1}{2}\sigma(r)^{2}\frac{\partial^2 P}{\partial r^2}+[a(r)+\sigma(r)+\varphi(r,t)]\frac{\partial P}{\partial r}+\frac{\partial P}{\partial t} - rP = 0&lt;/math&gt;}}
|}
As regards derivative pricing, the [[binomial options pricing model]] provides a discretized version of Black–Scholes, useful for the valuation of American styled options. Discretized models of this type are built—at least implicitly—using state-prices ([[#State prices|as above]]); relatedly, a large number of researchers have used options to extract state-prices for a variety of other applications in financial economics.&lt;ref name="Rubinstein"/&gt;&lt;ref name="Chance1"/&gt;&lt;ref name="Chance2"&gt;Don M. Chance (2008). [http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN97-13.pdf "Option Prices and State Prices"] {{Webarchive|url=https://web.archive.org/web/20120209215717/http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN97-13.pdf |date=2012-02-09 }}&lt;/ref&gt; For [[Option style#Non-vanilla path-dependent "exotic" options|path dependent derivatives]], [[Monte Carlo methods for option pricing]] are employed; here the modelling is in continuous time, but similarly uses risk neutral expected value. Various [[Option (finance)#Model implementation|other numeric techniques]] have also been developed. The theoretical framework too has been extended such that [[martingale pricing]] is now the standard approach. Developments relating to complexities in return and / or volatility are discussed [[#Departures from normality|below]].

Drawing on these techniques, derivative models for various other underlyings and applications have also been developed, all based off the same logic (using "[[contingent claim analysis]]"). [[Real options valuation]] allows that option holders can influence the option's underlying; models for [[Employee stock option#Valuation|employee stock option valuation]] explicitly assume non-rationality on the part of option holders; [[Credit derivative]]s allow that payment obligations and / or delivery requirements might not be honored. [[Exotic derivative]]s are now routinely valued. Multi-asset underlyers are handled via simulation or [[Copula (probability theory)#Quantitative finance|copula based analysis]].

Similarly, beginning with [[Oldrich Vasicek]] (1977), various [[short rate model]]s, as well as the [[Heath–Jarrow–Morton framework|HJM]] and [[Brace–Gatarek–Musiela model|BGM]] [[forward rate]]-based techniques, allow for an extension of these techniques to [[Fixed income#Derivatives|fixed income-]] and [[interest rate derivative]]s. (The [[Vasicek model|Vasicek]] and [[Cox–Ingersoll–Ross model|CIR]] models are equilibrium-based, while [[Ho–Lee model|Ho–Lee]] and subsequent models are based on arbitrage-free pricing.) Bond valuation is relatedly extended: the [[Bond valuation#Stochastic calculus approach|Stochastic calculus approach]], employing these methods, allows for rates that are "random" (while returning a price that is arbitrage free, [[#Certainty|as above]]); [[Lattice model (finance)#Hybrid securities|lattice models for hybrid securities]] allow for non-deterministic cashflows (and stochastic rates).

As above, ([[over the counter|OTC]]) derivative pricing has relied on the BSM risk neutral pricing framework, under the assumptions of funding at the risk free rate and the ability to perfectly replicate cashflows so as to fully hedge. This, in turn, is built on the assumption of a credit-risk-free environment. Post the [[financial crisis of 2008]], therefore, issues such as [[counterparty credit risk]], funding costs and costs of capital are additionally considered,&lt;ref&gt;[http://pure.au.dk/portal-asb-student/files/96440392/Master_Thesis_Pure.pdf "Post-Crisis Pricing of Swaps using xVAs"] {{Webarchive|url=https://web.archive.org/web/20160917015231/http://pure.au.dk/portal-asb-student/files/96440392/Master_Thesis_Pure.pdf |date=2016-09-17 }}, Christian Kjølhede &amp; Anders Bech, Master thesis, [[Aarhus University]]&lt;/ref&gt; and a [[Credit Valuation Adjustment]], or CVA—and potentially other ''valuation adjustments'', collectively [[xVA]]—is generally added to the risk-neutral derivative value.

A related, and perhaps more fundamental change, is that discounting is now on the [[Overnight index swap|Overnight Index Swap]] (OIS) curve, as opposed to  [[LIBOR]] as used previously. This is because post-crisis, OIS is considered a better proxy for the "risk-free rate".&lt;ref&gt;{{cite journal |title=LIBOR vs. OIS: The Derivatives Discounting Dilemma |first=John  |last=Hull |first2=Alan |last2=White |journal=[[Journal of Investment Management]] |volume=11 |issue=3 |year=2013 |pages=14–27 |jstor=|doi=}}&lt;/ref&gt; (Also, practically, the interest paid on cash [[collateral (finance)|collateral]] is usually the overnight rate; OIS discounting is then, sometimes, referred to as "[[Credit Support Annex|CSA]] discounting".)  [[Swap (finance)#Valuation|Swap pricing]] is further modified: previously, swaps were valued off a single "self discounting" interest rate curve; whereas post crisis, to accommodate OIS discounting, valuation is now under a "multi-curve" framework where "forecast curves" are constructed for ''each'' floating-leg [[Libor#Maturities|LIBOR tenor]], with discounting on a common OIS curve; see {{sectionlink|Interest rate swap|Valuation and pricing}}.

===Corporate finance theory===
[[Image:Manual decision tree.jpg|right|thumb|Project valuation via decision tree.]]
Corporate finance theory has also been extended: mirroring the [[#Certainty|above]] developments, asset-valuation and decisioning no longer need assume "certainty". As discussed, [[Monte Carlo methods in finance]], introduced by [[David B. Hertz]] in 1964, allow financial analysts to construct "[[stochastic]]" or [[probabilistic]] corporate finance models, as opposed to the traditional static and [[deterministic]] models;&lt;ref name="Damodaran_Risk"/&gt; see {{sectionlink|Corporate finance|Quantifying uncertainty}}. Relatedly, Real Options theory allows for owner—i.e. managerial—actions that impact underlying value: by incorporating option pricing logic, these actions are then applied to a distribution of future outcomes, changing with time, which then determine the "project's" valuation today.&lt;ref name="Damodaran"/&gt;

More traditionally, [[decision tree]]s—which are complementary—have been used to evaluate projects, by incorporating in the valuation (all) [[Event (probability theory)|possible events]] (or states) and consequent [[Decision making#Decision making in business and management|management decisions]];&lt;ref&gt;{{cite journal |title=Valuing Risky Projects: Option Pricing Theory and Decision Analysis |first=James E. |last=Smith |first2=Robert F. |last2=Nau |url=https://faculty.fuqua.duke.edu/~jes9/bio/Valuing_Risky_Projects.pdf |journal=Management Science |volume=41 |issue=5 |year=1995 |pages=795–816 |doi=10.1287/mnsc.41.5.795 |access-date=2017-08-17 |archive-url=https://web.archive.org/web/20100612170613/http://faculty.fuqua.duke.edu/%7Ejes9/bio/Valuing_Risky_Projects.pdf |archive-date=2010-06-12 |dead-url=no |df= }}&lt;/ref&gt;&lt;ref name="Damodaran_Risk"&gt;[[Aswath Damodaran]] (2007). [http://www.stern.nyu.edu/~adamodar/pdfiles/papers/probabilistic.pdf "Probabilistic Approaches: Scenario Analysis, Decision Trees and Simulations"]. In ''Strategic Risk Taking: A Framework for Risk Management''. Prentice Hall. {{ISBN|0137043775}}&lt;/ref&gt; the correct discount rate here reflecting each point's "non-diversifiable risk looking forward."&lt;ref name="Damodaran_Risk"/&gt; (This technique predates the use of real options in corporate finance;&lt;ref&gt;See for example: {{cite journal |title= Decision Trees for Decision Making |first= John F. |url= https://hbr.org/1964/07/decision-trees-for-decision-making |last= Magee |journal= [[Harvard Business Review]] |volume= July 1964 |year= 1964 |pages= 795–816 |access-date= 2017-08-16 |archive-url= https://web.archive.org/web/20170816192517/https://hbr.org/1964/07/decision-trees-for-decision-making |archive-date= 2017-08-16 |dead-url= no |df=  }}&lt;/ref&gt; it is borrowed from [[operations research]], and is not a "financial economics development" ''per se''.)

Related to this, is the treatment of forecasted cashflows in [[equity valuation]]. In many cases, following Williams [[#Certainty|above]], the average (or  most likely) cash-flows were discounted,&lt;ref name="Markowitz_interview"&gt;{{cite journal |last= Kritzman |first= Mark |authorlink= |jstor= |title= An Interview with Nobel Laureate Harry M. Markowitz
 |journal=Financial Analysts Journal  |volume=73 |issue= 4|year= 2017|pages= 16–21|url=https://www.cfapubs.org/doi/full/10.2469/faj.v73.n4.3 |doi=10.2469/faj.v73.n4.3}}&lt;/ref&gt; as opposed to a more correct state-by-state treatment under uncertainty; see comments under [[Financial modeling#Accounting|Financial modeling § Accounting]]. In more modern treatments, then, it is the ''expected'' cashflows (in the [[Expected value|mathematical sense]]) combined into an overall value per forecast period which are discounted.&lt;ref name="Kruschwitz and Löffler"/&gt;&lt;ref name="welch"&gt;[http://book.ivo-welch.info/read/chap13.pdf "Capital Budgeting Applications and Pitfalls"] {{Webarchive|url=https://web.archive.org/web/20170815234404/http://book.ivo-welch.info/read/chap13.pdf |date=2017-08-15 }}. Ch 13 in [[Ivo Welch]] (2017). ''Corporate Finance'': 4th Edition&lt;/ref&gt;&lt;ref&gt;George Chacko and Carolyn Evans (2014). ''Valuation: Methods and Models in Applied Corporate Finance''. FT Press. {{ISBN|0132905221}}&lt;/ref&gt;&lt;ref name="Damodaran_Risk"/&gt; And using the CAPM—or extensions—the discounting here is at the risk-free rate plus a premium linked to the uncertainty of the entity or project cash flows.&lt;ref name="Damodaran_Risk"/&gt;&lt;ref name="welch"/&gt;

Other developments here include&lt;ref&gt;See Jensen and Smith under "External links", as well as Rubinstein under "Bibliography".&lt;/ref&gt; [[agency theory]], which analyses the difficulties in motivating corporate management (the "agent") to act in the best interests of shareholders (the "principal"), rather than in their own interests. [[Clean surplus accounting]] and the related [[residual income valuation]] provide a model that returns price as a function of earnings, expected returns, and change in [[book value]], as opposed to dividends. This approach, to some extent, arises due to the implicit contradiction of seeing value as a function of dividends, while also holding that dividend policy cannot influence value per Modigliani and Miller's "[[Irrelevance principle]]"; see {{sectionlink|Dividend policy|Irrelevance of dividend policy}}.

The typical application of real options is to [[capital budgeting]] type problems as described. However, they are also applied to questions of [[capital structure]] and [[dividend policy]], and to the related design of corporate securities;&lt;ref name="Garbade"&gt;Kenneth D. Garbade (2001). ''Pricing Corporate Securities as Contingent Claims.'' [[MIT Press]]. {{ISBN|9780262072236}}&lt;/ref&gt;  and since stockholder and bondholders have different objective functions, in the analysis of the related agency problems.&lt;ref name="Damodaran"&gt;{{cite journal|last=Damodaran|first=Aswath|authorlink=Aswath Damodaran|jstor=|title=The Promise and Peril of Real Options|journal=NYU Working Paper|volume=|issue=S-DRP-05-02|year=2005|pages=|url=http://stern.nyu.edu/~adamodar/pdfiles/papers/realopt.pdf|access-date=2016-12-14|archive-url=https://web.archive.org/web/20010613082802/http://www.stern.nyu.edu/~adamodar/pdfiles/papers/realopt.pdf|archive-date=2001-06-13|dead-url=no|df=}}&lt;/ref&gt; In all of these cases, state-prices can provide the market-implied information relating to the corporate, [[#State prices|as above]], which is then applied to the analysis. For example, [[convertible bond]]s can (must) be priced consistent with the state-prices of the corporate's equity.&lt;ref name="corp fin state prices"/&gt;&lt;ref name="Kruschwitz and Löffler"&gt;See Kruschwitz and Löffler per Bibliography.&lt;/ref&gt;

==Challenges and criticism==
{{see also|Financial mathematics#Criticism|Financial engineering#Criticisms|Financial Modelers' Manifesto|Unreasonable ineffectiveness of mathematics#Economics and finance|Physics envy}}

As above, there is a very close link between (i) the [[random walk hypothesis]], with the associated expectation that price changes should follow a [[normal distribution]], on the one hand, and (ii) market efficiency and [[rational expectations]], on the other. Note, however, that (wide) departures from these are commonly observed, and there are thus, respectively, two main sets of challenges.

===Departures from normality===
[[Image:Ivsrf.gif|thumb|right|Implied volatility surface. The Z-axis represents implied volatility in percent, and X and Y axes represent the option delta, and the days to maturity.]]
{{See also|Capital asset pricing model#Problems|Modern portfolio theory#Criticisms|Black–Scholes model#Criticism and comments}}
As discussed, the assumptions that market prices follow a [[random walk]] and / or that asset returns are normally distributed are fundamental. Empirical evidence, however, suggests that these assumptions may not hold (see [[Kurtosis risk]], [[Skewness risk]], [[Long tail]]) and that in practice, traders, analysts and [[financial risk management|risk managers]] frequently modify the "standard models" (see [[Model risk]]). In fact, [[Benoît Mandelbrot]] had discovered already in the 1960s that changes in financial prices do not follow a [[Gaussian distribution]], the basis for much option pricing theory, although this observation was slow to find its way into mainstream financial economics.

[[Financial models with long-tailed distributions and volatility clustering]] have been introduced to overcome problems with the realism of the above "classical" financial models; while [[Jump diffusion#In economics and finance|jump diffusion models]] allow for (option) pricing incorporating [[jump process|"jumps"]] in the [[spot price]].&lt;ref name="holes"&gt;{{cite journal |title=  How to use the holes in Black-Scholes |first= Fischer |last=Black|first2= |last2=|author-link1=Fischer Black |journal=[[Journal of Applied Corporate Finance]] |volume=1|issue=Jan|year=1989|pages=67–73|jstor=|doi=10.1111/j.1745-6622.1989.tb00175.x}}&lt;/ref&gt; 
Risk managers, similarly, complement (or substitute) the standard [[value at risk]] models with [[Historical simulation (finance)|historical simulations]], [[Mixture model#A financial model|mixture models]], [[principal component analysis]], [[extreme value theory]], as well as models for [[volatility clustering]].&lt;ref&gt;III.A.3 in Carol Alexander, ed. ''The Professional Risk Managers' Handbook: A Comprehensive Guide to Current Theory and Best Practices''. PRMIA Publications (January 2005). {{ISBN|978-0976609704}}&lt;/ref&gt; 
For further discussion see {{sectionlink|Fat-tailed distribution|Applications in economics}}, and {{sectionlink|Value at risk|Criticism}}.
Portfolio managers, likewise, have modified their optimization criteria and algorithms; see [[#Portfolio theory]] above. 

Closely related is the [[volatility smile]], where [[implied volatility]]—the volatility corresponding to the BSM price—is observed to ''differ'' as a function of [[strike price]] (i.e. [[moneyness]]), true only if the price-change distribution is non-normal, unlike that assumed by BSM. The term structure of volatility describes how (implied) volatility differs for related options with different maturities. An implied volatility surface is then a three-dimensional surface plot of volatility smile and term structure. These empirical phenomena negate the assumption of constant volatility—and [[log-normal]]ity—upon which Black–Scholes is built;&lt;ref name="Haug Taleb"/&gt;&lt;ref name="holes"/&gt; see {{sectionlink|Black–Scholes model|The volatility smile}}.

In consequence traders (and risk managers) use "smile-consistent" models, firstly, when valuing derivatives not directly mapped to the surface, facilitating the pricing of other, i.e. non-quoted, strike/maturity combinations, or of non-European derivatives, and generally for hedging purposes.  The two main approaches are [[local volatility]] and [[stochastic volatility]]. The first returns the volatility which is “local” to each spot-time point of the [[Finite difference methods for option pricing|finite difference-]] or [[Monte Carlo methods for option pricing|simulation-based valuation]] — i.e. as opposed to implied volatility, which holds overall.  In this way calculated prices — and numeric structures — are market-consistent in an arbitrage-free sense.  The second approach assumes that the volatility of the underlying price is a stochastic process rather than a constant. Models here are first [[Stochastic volatility#Calibration and estimation|"calibrated"]] to observed prices, and are then applied to the valuation in question; the most common are [[Heston model|Heston]], [[SABR volatility model|SABR]] and [[Constant elasticity of variance model|CEV]]. This approach addresses certain problems identified with hedging under local volatility.&lt;ref&gt;{{cite journal |title=  Managing smile risk |first= Patrick |last=Hagan |first2= |last2=et al|journal=[[Wilmott Magazine]] |volume=|issue=Sep|year=2002 |pages=84–108|jstor=|doi=}}&lt;/ref&gt;

Related to local volatility are the [[Lattice model (finance)|lattice]]-based [[Implied binomial tree|implied-binomial]] and [[Implied trinomial tree|-trinomial trees]] — essentially a discretization of the approach — which are similarly used for pricing; these are built on state-prices recovered from the surface.  [[Edgeworth binomial tree]]s allow for a specified (i.e. non-Gaussian) [[Skewness|skew]] and [[kurtosis]] in the spot price; priced here, options with differing strikes will return differing implied volatilities, and the tree can be calibrated to the smile as required.&lt;ref&gt;See for example Pg 217 of: Jackson, Mary; Mike Staunton (2001). ''Advanced modelling in finance using Excel and VBA''. New Jersey: Wiley. {{ISBN|0-471-49922-6}}.&lt;/ref&gt; Similarly purposed [[Closed-form expression|closed-form models]] have also been developed. &lt;ref&gt; These include: [[Robert A. Jarrow|Jarrow]] and Rudd (1982); Corrado and Su (1996); [[David K. Backus|Backus]], Foresi, and Wu (2004). See: Emmanuel Jurczenko, Bertrand Maillet &amp; Bogdan Negrea, 2002. "Revisited multi-moment approximate option pricing models: a general comparison (Part 1)". Working paper, [[London School of Economics and Political Science]].&lt;/ref&gt;

As above, additional to log-normality in returns, BSM—and, typically, other derivative models—assume(d) the ability to perfectly replicate cashflows so as to fully hedge, and hence to discount at the risk-free rate. This, in turn, is built on the assumption of a credit-risk-free environment. Post crisis, then,  various x-value adjustments are made to the risk-neutral derivative value.  Note that these are ''additional'' to any smile or surface effect: this is valid as the surface is built on price data relating to fully collateralized positions, and there is therefore no "[[double counting (accounting)|double counting]]" of credit risk (etc.) when including xVA. (Also, were this not the case, then each counterparty would have its own surface...)

===Departures from rationality===
{|class="wikitable floatright" | width="200"
|- style="font-size:75%"
|-align="center"
|colspan="1" | [[Market anomaly|Market anomalies]] and [[Economic puzzle]]s
|-
| rowspan="2" |
* [[Calendar effect]]
** [[January effect]]
** [[Santa Claus rally]]
** [[Sell in May]]
* [[Closed-end fund puzzle]]
* [[Dividend puzzle]]
* [[Equity home bias puzzle]]
* [[Equity premium puzzle]]
* [[Forward premium anomaly]]
* [[Low-volatility anomaly]]
* [[Momentum (finance)|Momentum anomaly]]
* [[Post-earnings-announcement drift]]
* [[Real exchange-rate puzzles]]
|}
{{See also|Efficient-market hypothesis#Criticism and behavioral finance|Rational expectations#Criticism}}
As seen, a common assumption is that financial decision makers act rationally; see [[Homo economicus]]. Recently, however, researchers in [[experimental economics]] and [[experimental finance]] have challenged this assumption [[Empirical evidence|empirically]]. These assumptions are also challenged [[Theory|theoretically]], by [[behavioral finance]], a discipline primarily concerned with the limits to rationality of economic agents.

Consistent with, and complementary to these findings, various persistent [[Market anomaly|market anomalies]] have been documented, these being price and/or return distortions—e.g. [[size premium]]s—which appear to contradict the [[efficient-market hypothesis]]; [[calendar effect]]s are the best known group here. Related to these are various of the [[economic puzzle]]s, concerning phenomena similarly contradicting the theory. The ''[[equity premium puzzle]]'', as one example, arises in that the difference between the observed returns on stocks as compared to government bonds is consistently higher than the [[risk premium]] rational equity investors should demand, an "[[abnormal return]]". For further context see [[Random walk hypothesis#A non-random walk hypothesis|Random walk hypothesis § A non-random walk hypothesis]], and sidebar for specific instances.

More generally, and particularly following the [[financial crisis of 2007–2010]], financial economics and [[mathematical finance]] have been subjected to deeper criticism; notable here is [[Nassim Nicholas Taleb]], who claims that the prices of financial assets cannot be characterized by the simple models currently in use, rendering much of current practice at best irrelevant, and, at worst, dangerously misleading; see [[Black swan theory]], [[Taleb distribution]]. A topic of general interest studied in recent years has thus been [[Financial crisis|financial crises]],&lt;ref&gt;From ''[[The New Palgrave Dictionary of Economics]]'', Online Editions, 2011, 2012, with abstract links:&lt;br /&gt;&amp;nbsp;&amp;nbsp; • [http://www.dictionaryofeconomics.com/article?id=pde2012_F000330&amp;edition=1 "regulatory responses to the financial crisis: an interim assessment"] {{Webarchive|url=https://web.archive.org/web/20130529101109/http://www.dictionaryofeconomics.com/article?id=pde2012_F000330&amp;edition=1 |date=2013-05-29 }} by [[Howard Davies (economist)|Howard Davies]]&lt;br /&gt;&amp;nbsp;&amp;nbsp; • [http://www.dictionaryofeconomics.com/article?id=pde2011_C000621&amp;edition= "Credit Crunch Chronology: April 2007–September 2009"] {{Webarchive|url=https://web.archive.org/web/20130529092712/http://www.dictionaryofeconomics.com/article?id=pde2011_C000621&amp;edition= |date=2013-05-29 }} by The Statesman's Yearbook team&lt;br /&gt;&amp;nbsp;&amp;nbsp; • [http://www.dictionaryofeconomics.com/article?id=pde2011_M000430&amp;edition=current&amp;q= "Minsky crisis"] {{Webarchive|url=https://web.archive.org/web/20130529172102/http://www.dictionaryofeconomics.com/article?id=pde2011_M000430&amp;edition=current&amp;q= |date=2013-05-29 }} by [[L. Randall Wray]]&lt;br /&gt;&amp;nbsp;&amp;nbsp; • [http://www.dictionaryofeconomics.com/article?id=pde2011_E000326&amp;edition=current&amp;q= "euro zone crisis 2010"] {{Webarchive|url=https://web.archive.org/web/20130529092726/http://www.dictionaryofeconomics.com/article?id=pde2011_E000326&amp;edition=current&amp;q= |date=2013-05-29 }} by [[Daniel Gros]] and Cinzia Alcidi.&lt;br /&gt;&amp;nbsp;&amp;nbsp; • [[Carmen M. Reinhart]] and [[Kenneth S. Rogoff]], 2009. ''This Time Is Different: Eight Centuries of Financial Folly'', Princeton. [http://press.princeton.edu/titles/8973.html Description] {{Webarchive|url=https://web.archive.org/web/20130118213207/http://press.princeton.edu/titles/8973.html |date=2013-01-18 }}, ch. 1 ("Varieties of Crises and their Dates". pp. [http://press.princeton.edu/chapters/s8973.pdf 3-20)] {{Webarchive|url=https://web.archive.org/web/20120925065855/http://press.princeton.edu/chapters/s8973.pdf |date=2012-09-25 }}, and chapter-preview [https://books.google.com/books?id=ak5fLB24ircC&amp;printsec=frontcover&amp;source=find&amp;pg=PR7gbs_atb#v=onepage&amp;q&amp;f=false links.]&lt;/ref&gt; and the failure of financial economics to model these. (A related problem is [[systemic risk]]: where companies hold securities in each other then this interconnectedness may entail a "valuation chain"—and the performance of one company, or security, here will impact all, a phenomenon not easily modeled, regardless of whether the individual models are correct. See [[Systemic risk#Inadequacy of classic valuation models|Systemic risk § Inadequacy of classic valuation models]]; [[Cascades in financial networks]]; [[Flight-to-quality]].)

Areas of research attempting to explain (or at least model) these phenomena, and crises, include&lt;ref name="Doyne_Geanakoplos"&gt;{{cite journal | author = Farmer J. Doyne, Geanakoplos John | year = 2009 | title = The virtues and vices of equilibrium and the future of financial economics | url = https://campuspress.yale.edu/johngeanakoplos/files/2017/07/63.-The-Virtues-and-Vices-of-Equilbrium-and-the-Future-of-Financial-Economics-2009-26baz0x.pdf | format = PDF | journal = Complexity | volume = 14 | issue = 3 | doi=10.1002/cplx.20261| arxiv = 0803.2996 | bibcode = 2009Cmplx..14c..11F }}&lt;/ref&gt;  [[Noise trader|noise trading]], [[market microstructure]], and [[Heterogeneous agent model]]s. The latter is extended to [[agent-based computational economics]], where price is treated as an [[emergent phenomenon]], resulting from the interaction of the various market participants (agents). The [[noisy market hypothesis]] argues that prices can be influenced by speculators and [[momentum trader]]s, as well as by [[insider trading|insiders]] and institutions that often buy and sell stocks for reasons unrelated to [[fundamental value]]; see [[Noise (economic)]]. The [[adaptive market hypothesis]] is an attempt to reconcile the efficient market hypothesis with behavioral economics, by applying the principles of [[evolution]] to financial interactions. An [[information cascade]], alternatively, shows market participants engaging in the same acts as others ("[[herd behavior]]"), despite contradictions with their private information. [[Copula (probability theory)#Quantitative finance|Copula-based modelling]] has similarly been applied. See also [[Hyman Minsky]]'s [[Hyman Minsky#Minsky's financial instability hypothesis|"financial instability hypothesis"]], as well as [[George Soros]]' approach, [[George Soros#Reflexivity, financial markets, and economic theory|§ Reflexivity, financial markets, and economic theory]].

On the obverse, however, various studies have shown that despite these departures from efficiency, asset prices do typically exhibit a random walk and that one cannot therefore consistently outperform market averages ([[Alpha (investment)|"alpha"]]).&lt;ref&gt;[[William F. Sharpe]] (1991). [http://www.stanford.edu/~wfsharpe/art/active/active.htm "The Arithmetic of Active Management"] {{Webarchive|url=https://web.archive.org/web/20131113071513/http://www.stanford.edu/~wfsharpe/art/active/active.htm |date=2013-11-13 }}. ''Financial Analysts Journal'' Vol. 47, No. 1, January/February&lt;/ref&gt; The practical implication, therefore, is that [[passive investing]] (e.g. via low-cost [[index fund]]s) should, on average, serve better than any other [[active investing|active strategy]].&lt;ref name=two&gt;[[William F. Sharpe]] (2002). [http://www.stanford.edu/~wfsharpe/art/talks/indexed_investing.htm ''Indexed Investing: A Prosaic Way to Beat the Average Investor''] {{Webarchive|url=https://web.archive.org/web/20131114160728/http://www.stanford.edu/~wfsharpe/art/talks/indexed_investing.htm |date=2013-11-14 }}. Presention: [[Monterey Institute of International Studies]]. Retrieved May 20, 2010.&lt;/ref&gt; [[Burton Malkiel]]'s ''[[A Random Walk Down Wall Street]]''—first published in 1973, and in its 11th edition as of 2015—is a widely read popularization of these arguments. (See also [[John C. Bogle]]'s ''[[Common Sense on Mutual Funds]]''; but compare [[Warren Buffett]]'s ''[[The Superinvestors of Graham-and-Doddsville]]''.) Note also that institutionally inherent ''[[limits to arbitrage]]''—as opposed to factors directly contradictory to the theory—are sometimes proposed as an explanation for these departures from efficiency.

==See also==
{{Wikipedia books|Finance}}
{{div col}}
* [[:Category:Finance theories]]
* [[:Category:Financial economists]]
* [[Deutsche Bank Prize in Financial Economics]]
* [[Financial modeling]]
* [[Fischer Black Prize]]
* {{sectionlink|List of unsolved problems in economics|Financial economics}}
* [[Monetary economics]]
* [[Outline of economics]]
* [[Outline of finance]]
{{div col end}}

==References==
{{Reflist|30em}}

==Bibliography==
{{refbegin|30em}}
'''Financial economics'''
* {{cite book | author= Roy E. Bailey | title=The Economics of Financial Markets | publisher=[[Cambridge University Press]] | location= | year=2005| isbn=0521612802}}
* {{cite book | author= Marcelo Bianconi| title= Financial Economics, Risk and Information (2nd Edition) | publisher= [[World Scientific]] | location= | year=2013| isbn=9814355135 }}
* {{cite book | author= [[Zvi Bodie]], [[Robert C. Merton]] and David Cleeton | title=Financial Economics (2nd Edition) | publisher=[[Prentice Hall]] | location= | year=2008| isbn=0131856154 }}
* {{cite book | author= James Bradfield | title= Introduction to the Economics of Financial Markets | publisher= Oxford University Press | location= | year=2007| isbn=978-0-19-531063-4 }}
* {{cite book |author1=Satya R. Chakravarty | title=An Outline of Financial Economics | publisher=Anthem Press | location= | year=2014| isbn=1783083360 }}
* {{cite book | author= [[Jakša Cvitanić]] and Fernando Zapatero| title= Introduction to the Economics and Mathematics of Financial Markets | publisher=MIT Press| location= | year=2004| isbn=978-0262033206}}
* {{cite book | author= [[George Constantinides|George M. Constantinides]], Milton Harris, [[René M. Stulz]] (editors) | url=http://econpapers.repec.org/bookchap/eeefinchp/ | title=Handbook of the Economics of Finance| publisher=[[Elsevier]] | location= | year=2003| isbn=0444513639}}
* {{cite book |author1=Keith Cuthbertson |author2=Dirk Nitzsche | title=Quantitative Financial Economics: Stocks, Bonds and Foreign Exchange | publisher=Wiley | location= | year=2004| isbn=0470091711 }}
* {{cite book | author= [[Jean-Pierre Danthine]], [[John Donaldson (economist)|John B. Donaldson]] | title=Intermediate Financial Theory (2nd Edition)| publisher= [[Academic Press]] | location= | year=2005| isbn=0123693802}}
* {{cite book | author= Louis Eeckhoudt |author2=Christian Gollier, [[American Risk and Insurance Association#Presidents|Harris Schlesinger]] | title=Economic and Financial Decisions Under Risk | publisher=Princeton University Press | location= | year=2005| isbn=978-0-691-12215-1}}
* {{cite book |author1=Jürgen Eichberger |author2=[[Ian Harper|Ian R. Harper]] | title=Financial Economics | publisher= Oxford University Press | location= | year=1997| isbn=0198775407 }}
* {{cite book | author= Igor Evstigneev, Thorsten Hens, and Klaus Reiner Schenk-Hoppé | title=Mathematical Financial Economics: A Basic Introduction  | publisher=Springer | location= | year=2015| isbn=3319165704}}
* {{cite book | author= [[Frank J. Fabozzi]], Edwin H. Neave and Guofu Zhou | title=Financial Economics | publisher= Wiley | location= | year=2011| isbn=0470596201}}
* {{cite book | author= Christian Gollier | title= The Economics of Risk and Time (2nd Edition) | publisher=[[MIT Press]] | location= | year=2004| isbn=978-0-262-57224-8 }}
* {{cite book | author= [[Thorsten Hens]] and Marc Oliver Rieger | title=Financial Economics: A Concise Introduction to Classical and Behavioral Finance| publisher= [[Springer Publishing|Springer]] | location= | year=2010| isbn=3540361464}}
* {{cite book | author= [[Chi-fu Huang]] and [[Robert Litzenberger|Robert H. Litzenberger]] | title=Foundations for Financial Economics | publisher=Prentice Hall | location= | year=1998| isbn=0135006538}}
* {{cite book | author= [[Jonathan E. Ingersoll]] | title=Theory of Financial Decision Making | publisher=Rowman &amp; Littlefield | location= | year=1987| isbn=0847673596}}
* {{cite book | author= [[Robert A. Jarrow]] | title=Finance theory | publisher=Prentice Hall| location= | year=1988| isbn=0133148653}}
* {{cite book | author= Chris Jones | title=Financial Economics| publisher= [[Routledge]] | location= | year=2008| isbn=0415375851 }}
* {{cite book | author= Brian Kettell | title= Economics for Financial Markets | publisher= [[Butterworth-Heinemann]] | location= | year=2002| isbn=978-0-7506-5384-8}}
* {{cite book | author= Yvan Lengwiler | title=Microfoundations of Financial Economics: An Introduction to General Equilibrium Asset Pricing| publisher= Princeton University Press | location= | year=2006| isbn=0691126313 }}
* {{cite book |author1=Stephen F. LeRoy |author2=Jan Werner | title=Principles of Financial Economics| publisher= Cambridge University Press | location= | year=2000| isbn=0521586054}}
* {{cite book |author1=Leonard C. MacLean |author2=William T. Ziemba | title= Handbook of the Fundamentals of Financial Decision Making | publisher= World Scientific | location= | year=2013| isbn=9814417343 }}
* {{cite book | author= [[Frederic S. Mishkin]] | title=The Economics of Money, Banking, and Financial Markets (3rd Edition)| publisher= [[Prentice Hall]] | location= | year=2012| isbn=0132961970}}
* {{cite book | author= [[Harry Panjer|Harry H. Panjer]], ed. | title=Financial Economics with Applications | publisher= Actuarial Foundation | location= | year=1998| isbn=0938959484}}
* {{cite book | editor= Geoffrey Poitras | title= Pioneers of Financial Economics, Volume I
| publisher= [[Edward Elgar Publishing]] | location= | year= 2007 | isbn= 978-1845423810}}; Volume II {{ISBN|978-1845423827}}.
* {{cite book | author= [[Richard Roll]] (series editor)| url=http://www.e-elgar.co.uk/search_results.lasso?series_title=The%20International%20Library%20of%20Critical%20Writings%20in%20Financial%20Economics |title=The International Library of Critical Writings in Financial Economics | publisher=[[Edward Elgar Publishing]] | location= [[Cheltenham]] | year=2006 | isbn=}}

'''Asset pricing'''
* {{cite book | author= Kerry E. Back | title=Asset Pricing and Portfolio Choice Theory| publisher= Oxford University Press | location= | year=2010| isbn=0195380614 }}
* {{cite book | author= Tomas Björk | title= Arbitrage Theory in Continuous Time (3rd Edition)| publisher= Oxford University Press | location= | year=2009| isbn=019957474X}}
* {{cite book | author= [[John H. Cochrane]] | title=Asset Pricing| publisher=[[Princeton University Press]] | location= | year=2005| isbn=0691121370}}
* {{cite book | author= [[Darrell Duffie]] | title=Dynamic Asset Pricing Theory (3rd Edition)| publisher= Princeton University Press | location= | year=2001| isbn=069109022X }}
* {{cite book | author= [[Edwin Elton|Edwin J. Elton]], Martin J. Gruber, Stephen J. Brown, [[William N. Goetzmann]] | title=Modern Portfolio Theory and Investment Analysis (9th Edition)| publisher=[[John Wiley &amp; Sons|Wiley]] | location= | year=2014| isbn=1118469941}}
* {{cite book | author=[[Robert Haugen|Robert A. Haugen]] | title=Modern Investment Theory (5th Edition)| publisher= Prentice Hall | location= | year=2000| isbn=0130191701}}
* {{cite book | author= [[Mark S. Joshi]], Jane M. Paterson | title=Introduction to Mathematical Portfolio Theory| publisher= Cambridge University Press | location= | year=2013| isbn=1107042313 }}
* {{cite book | author=Lutz Kruschwitz, Andreas Loeffler | title=Discounted Cash Flow: A Theory of the Valuation of Firms| publisher= Wiley | location= | year=2005| isbn=978-0470870440 }}
* {{cite book | author= [[David Luenberger|David G. Luenberger]] | title=Investment Science (2nd Edition)| publisher=[[Oxford University Press]] | location= | year=2013| isbn=0199740089}}
* {{cite book | author= [[Harry M. Markowitz]] | title=Portfolio Selection: Efficient Diversification of Investments (2nd Edition)| publisher= Wiley | location= | year=1991| isbn=1557861080 }}
* {{cite book | author= [[Frank Milne]] | title=Finance Theory and Asset Pricing (2nd Edition) | publisher= Oxford University Press | location= | year=2003| isbn=0199261075}}
* {{cite book | author= [[George Pennacchi]] | title=Theory of Asset Pricing| publisher= Prentice Hall | location= | year=2007| isbn=032112720X }}
* {{cite book | author= [[Mark Rubinstein]] | title=A History of the Theory of Investments| publisher= Wiley| location= | year=2006| isbn=0471770566}}
* {{cite book | author= [[William F. Sharpe]] | title=Portfolio Theory and Capital Markets: The Original Edition| publisher= [[McGraw-Hill]] | location= | year=1999| isbn=0071353208}}

'''Corporate finance'''
* {{cite book |author1=Jonathan Berk |author2=Peter DeMarzo | title=Corporate Finance (3rd Edition) | publisher= [[Pearson Education|Pearson]] | location= | year=2013| isbn=0132992477 }}
* {{cite book | author= Peter Bossaerts |author2= Bernt Arne Ødegaard | title= Lectures on Corporate Finance (Second Edition)| publisher= World Scientific | location= | year=2006| isbn=978-981-256-899-1}}
* {{cite book | author= [[Richard Brealey]] |author2=[[Stewart Myers]] |author3=[[Franklin Allen]]| title=[[Principles of Corporate Finance]] | publisher= Mcgraw-Hill | location= | year=2013| isbn=978-0078034763}}
* {{cite book | author=[[Aswath Damodaran]]| title=Corporate Finance: Theory and Practice| publisher=Wiley| location= | year=1996| isbn=978-0471076803}}
* {{cite book | author= João Amaro de Matos | title=Theoretical Foundations of Corporate Finance | publisher= Princeton University Press | location= | year=2001| isbn=9780691087948}}
* {{cite book |author1=Joseph Ogden |author2=Frank C. Jen |author3=Philip F. O'Connor | title= Advanced Corporate Finance | publisher= Prentice Hall| location= | year= 2002 | isbn= 978-0130915689}}
* {{cite book |author1=Pascal Quiry |author2=Yann Le Fur |author3=Antonio Salvi |author4=Maurizio Dallochio |author5=Pierre Vernimmen | title=Corporate Finance: Theory and Practice (3rd Edition)| publisher=Wiley| location= | year=2011| isbn=978-1119975588}}
* {{cite book | author= [[Stephen Ross (economist)|Stephen Ross]], Randolph Westerfield, Jeffrey Jaffe | title=Corporate Finance (10th Edition)| publisher= [[McGraw-Hill]] | location= | year=2012| isbn=0078034779 }}
* {{cite book | author= [[Joel Stern|Joel M. Stern]], ed. | title=The Revolution in Corporate Finance (4th Edition)| publisher=[[Wiley-Blackwell]]| location= | year=2003| isbn=9781405107815}}
* {{cite book | author= [[Jean Tirole]] | title=The Theory of Corporate Finance| publisher= Princeton University Press | location= | year=2006| isbn=0691125562}}
* {{cite book | author= [[Ivo Welch]] | title=Corporate Finance (3rd Edition)| publisher= | location= | year=2014| isbn=978-0-9840049-1-1}}
{{refend}}

==External links==
{|
|-
| valign="top" |
{{refbegin|30em}}
'''Surveys'''
* {{cite journal | doi = 10.1111/j.1745-6622.2000.tb00050.x | volume=13 | title=THE HISTORY OF FINANCE: AN EYEWITNESS ACCOUNT | year=2000 | journal=Journal of Applied Corporate Finance | pages=8–14 | author=Miller Merton H | authorlink = Merton H. Miller}}
* [https://web.archive.org/web/20070628225647/http://www.in-the-money.com/artandpap/I%20Present%20Value.doc Great Moments in Financial Economics I], [https://web.archive.org/web/20070628225647/http://www.in-the-money.com/artandpap/II%20Modigliani-Miller%20Theorem.doc II], [https://web.archive.org/web/20070628225647/http://www.in-the-money.com/artandpap/III%20Short-Sales%20and%20Stock%20Prices.doc III], [https://web.archive.org/web/20070628225647/http://www.in-the-money.com/artandpap/IV%20Fundamental%20Theorem%20-%20Part%20I.doc IVa], [https://web.archive.org/web/20070628225647/http://www.in-the-money.com/artandpap/IV%20Fundamental%20Theorem%20-%20Part%20II.doc IVb] ([[Internet Archive|archived]], 2007-06-27). [[Mark Rubinstein]]
* [https://web.archive.org/web/20030204203936/http://www.finance-and-physics.org/Library/Articles3/scienceandfinance/science.htm The Scientific Evolution of Finance] ([[Internet Archive|archived]], 2003-04-03). Don Chance and Pamela Peterson
* [http://www.econ.boun.edu.tr/content/2017/spring/EC-42701/Lecture%20Note-Markowitz%20(1999)-04-05-2017.pdf The Early History of Portfolio Theory: 1600-1960], Harry M. Markowitz. ''Financial Analysts Journal'', Vol. 55, No. 4 (Jul. - Aug., 1999), pp. 5-16
* [http://papers.ssrn.com/sol3/papers.cfm?abstract_id=244161 The Theory of Corporate Finance: A Historical Overview], [[Michael C. Jensen]] and Clifford W. Smith.
* [http://www.emanuelderman.com/media/Stylized_History.Derman.pdf A Stylized History of Quantitative Finance], Emanuel Derman
* [https://web.archive.org/web/20120326213849/http://www.thederivativesbook.com/Chapters/10Chap.pdf Financial Engineering: Some Tools of the Trade] (discusses historical context of derivative pricing). Ch 10 in [[Phelim Boyle]] and Feidhlim Boyle (2001). "Derivatives: The Tools That Changed Finance".
* [https://www.inkling.com/read/principles-of-corporate-finance-brealey-10th/chapter-34/section-34-1 What We Do Know: The Seven Most Important Ideas in Finance]; [https://www.inkling.com/read/principles-of-corporate-finance-brealey-10th/chapter-34/section-34-2 What We Do Not Know: 10 Unsolved Problems in Finance], [[Richard A. Brealey]], [[Stewart Myers]] and [[Franklin Allen]].
* [https://dspace.mit.edu/handle/1721.1/48732 An Overview of Modern Financial Economics] ([[MIT]] [[Working paper]]). [[Chi-fu Huang]]
{{refend}}

| valign="top" |
{{refbegin|30em}}
'''Course material'''
* [http://pages.stern.nyu.edu/~dbackus/233/notes_econ_assetpricing.pdf Fundamentals of Asset Pricing], Prof. [[David K. Backus]], [[New York University Stern School of Business|NYU, Stern]]
* [http://www.ulb.ac.be/cours/solvay/farber/PhD.htm Microfoundations of Financial Economics] Prof. André Farber, [[Solvay Business School]]
* [http://viking.som.yale.edu/will/web_pages/will/finman540/classnotes/notes.html An introduction to investment theory], Prof. William Goetzmann, [[Yale School of Management]]
* [http://www.stanford.edu/~wfsharpe/mia/MIA.HTM Macro-Investment Analysis]. Prof. [[William F. Sharpe]], [[Stanford Graduate School of Business]]
* [http://ocw.mit.edu/courses/sloan-school-of-management/15-401-finance-theory-i-fall-2008/ Finance Theory] ([[MIT OpenCourseWare]]). Prof. [[Andrew Lo]], [[MIT]].
* [http://oyc.yale.edu/economics/econ-251 Financial Theory] ([[Open Yale Courses]]). Prof. [[John Geanakoplos]], [[Yale University]].
* {{webarchive |url=https://web.archive.org/web/20120621123950/http://homepage.newschool.edu/~het/essays/capital/invest.htm |date=June 21, 2012 |title=The Theory of Investment }}. Prof. G.L. Fonseca, [[New School for Social Research]]
* [https://www.ma.utexas.edu/rtgs/applied/school2009/rtg09_trans.pdf Introduction to Financial Economics]. Gordan Zitkovi, [[University of Texas at Austin]]
* [http://jhqian.org/apt/apbook.pdf An Introduction to Asset Pricing Theory], Junhui Qian, [[Shanghai Jiao Tong University]]
{{refend}}

| valign="top" |
{{refbegin|30em}}
'''Links and portals'''
* [http://www.aeaweb.org/jel/guide/jel.php?class=G JEL Classification Codes Guide]
* [http://rfe.org/showCat.php?cat_id=56 Financial Economics Links on AEA's RFE]
* [http://www.ssrn.com/en/index.cfm/fen/ SSRN Financial Economics Network]
* [http://www.economicsnetwork.ac.uk/subjects/Financial%20Economics Financial Economics listings on economicsnetwork.ac.uk]
* [https://fic.wharton.upenn.edu/policy-briefs/financial-economists-roundtable-fer/ Financial Economists Roundtable]
* [http://www.nber.org/jel/G_index.html NBER Working Papers in Financial Economics]
* [https://web.archive.org/web/20140313133821/http://www.qfinance.com/information-sources?section=financial-economics Financial Economics Resources on QFINANCE] ([[Internet Archive|archived]] 2014-03-13)
* [https://web.archive.org/web/20160324132025/http://www.helsinki.fi/WebEc/webecg.html Financial Economics Links on WebEc] ([[Internet Archive|archived]] 2016-03-24)

'''Actuarial resources'''
* [http://www.soa.org/education/exam-req/edu-exam-mfe-detail.aspx "Models for Financial Economics (MFE)"], [[Society of Actuaries]]
* [http://www.actuaries.org.uk/students/pages/ct8-financial-economics "Financial Economics (CT8)"], [[Institute and Faculty of Actuaries]]
* [http://66.216.104.121/files/sections/prime.pdf "A Primer In Financial Economics"], S. F. Whelan, D. C. Bowie and A. J. Hibbert. ''[[British Actuarial Journal]]'', Volume 8, Issue 1, April 2002, pp.&amp;nbsp;27–65.
* [http://www.soa.org/files/sections/actuary-journal-final.pdf "Pension Actuary's Guide to Financial Economics"]. Gordon Enderle, Jeremy Gold, Gordon Latter and Michael Peskin. [[Society of Actuaries]] and [[American Academy of Actuaries]].
{{refend}}
|}

{{Financial economics awards}}
{{Economics|state=autocollapse}}
{{Finance}}
{{Financial risk}}

{{DEFAULTSORT:Financial Economics}}
[[Category:Financial economics| ]]
[[Category:Actuarial science]]</text>
      <sha1>eh885a1tsx2hrw0l6rgyt1y4oc12okl</sha1>
    </revision>
  </page>
  <page>
    <title>Generator matrix</title>
    <ns>0</ns>
    <id>6133005</id>
    <revision>
      <id>871316516</id>
      <parentid>871315995</parentid>
      <timestamp>2018-11-30T06:54:39Z</timestamp>
      <contributor>
        <username>Polytope4d</username>
        <id>17823290</id>
      </contributor>
      <comment>/* Terminology */LaTeX when possible</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5801">{{For|generator matrices in probability theory|transition rate matrix}}
In [[coding theory]], a '''generator matrix''' is a [[matrix (mathematics)|matrix]] whose rows form a [[Basis (linear algebra)|basis]] for a [[linear code]]. The codewords are all of the [[linear combination]]s of the rows of this matrix, that is, the linear code is the [[row space]] of its generator matrix.

==Terminology==

If '''G''' is a matrix, it generates the [[codeword]]s of a linear code ''C'' by

: &lt;math&gt;w=sG&lt;/math&gt;

where '''w''' is a codeword of the linear code ''C'', and '''s''' is any input vector. Both '''w''' and '''s''' are assumed to be row vectors.&lt;ref name=DrMacKayECC&gt;{{cite book| last=MacKay | first=David, J.C.| authorlink=David J.C. MacKay| title=Information Theory, Inference, and Learning Algorithms |year=2003 | pages=9|publisher=[[Cambridge University Press]]| isbn=9780521642989|url=http://www.inference.phy.cam.ac.uk/itprnn/book.pdf | quote=Because the Hamming code is a linear code, it can be written compactly in terms of matrices as follows. The transmitted codeword &lt;math&gt;\mathbf{t}&lt;/math&gt; is obtained from the source sequence &lt;math&gt;\mathbf{s}&lt;/math&gt; by a linear operation,&lt;blockquote&gt;&lt;math&gt;\mathbf{t} = \mathbf{G}^\intercal\mathbf{s}&lt;/math&gt;&lt;/blockquote&gt; where &lt;math&gt;\mathbf{G}&lt;/math&gt; is the ''generator matrix'' of the code... I have assumed that &lt;math&gt;\mathbf{s}&lt;/math&gt; and &lt;math&gt;\mathbf{t}&lt;/math&gt; are column vectors. If instead they are row vectors, then this equation is replaced by &lt;blockquote&gt;&lt;math&gt;\mathbf{t} = \mathbf{sG}&lt;/math&gt;&lt;/blockquote&gt;... I find it easier to relate to the right-multiplication (...) than the left-multiplication (...). Many coding theory texts use the left-multiplying conventions (...), however. ...The rows of the generator matrix can be viewed as defining the basis vectors.}}&lt;/ref&gt; A generator matrix for a linear &lt;math&gt;[n, k, d]_q&lt;/math&gt;-code has format &lt;math&gt;k \times n&lt;/math&gt;, where ''n'' is the length of a codeword, ''k'' is the number of information bits (the dimension of ''C'' as a vector subspace), ''d'' is the minimum distance of the code, and ''q'' is size of the [[finite field]], that is, the number of symbols in the alphabet (thus, ''q'' = 2 indicates a [[binary code]], etc.).  The number of [[Redundancy (information theory)|redundant bits]] is denoted by &lt;math&gt;r = n - k&lt;/math&gt;.

The ''standard'' form for a generator matrix is,&lt;ref&gt;{{harvnb|Ling|Xing|2004|loc=p. 52}}&lt;/ref&gt;
: &lt;math&gt;G = \begin{bmatrix} I_k | P \end{bmatrix}&lt;/math&gt;,
where &lt;math&gt;I_k&lt;/math&gt; is the &lt;math&gt;k \times k&lt;/math&gt; [[identity matrix]] and P, a &lt;math&gt;k \times (n-k)&lt;/math&gt; matrix. When the generator matrix is in standard form, the code ''C'' is [[Systematic code|systematic]] in its first ''k'' coordinate positions.&lt;ref&gt;{{harvnb|Roman|1992|loc=p. 198}}&lt;/ref&gt;

A generator matrix can be used to construct the [[parity check matrix]] for a code (and vice versa). If the generator matrix ''G'' is in standard form,  &lt;math&gt;G = \begin{bmatrix} I_k | P \end{bmatrix}&lt;/math&gt;, then the parity check matrix for ''C'' is&lt;ref&gt;{{harvnb|Roman|1992|loc=p. 200}}&lt;/ref&gt; 
: &lt;math&gt;H = \begin{bmatrix} -P^{\top} | I_{n-k} \end{bmatrix}&lt;/math&gt;,
where &lt;math&gt;P^{\top}&lt;/math&gt; is the [[transpose]] of the matrix &lt;math&gt;P&lt;/math&gt;. This is a consequence of the fact that a parity check matrix of &lt;math&gt;C&lt;/math&gt; is a generator matrix of the [[dual code]] &lt;math&gt;C^{\perp}&lt;/math&gt;.

It may be noted that G is a &lt;math&gt;k \times n&lt;/math&gt; matrix, while H is a &lt;math&gt;(n-k) \times n&lt;/math&gt; matrix.

==Equivalent Codes==
Codes ''C''&lt;sub&gt;1&lt;/sub&gt; and ''C''&lt;sub&gt;2&lt;/sub&gt; are ''equivalent'' (denoted ''C''&lt;sub&gt;1&lt;/sub&gt; ~ ''C''&lt;sub&gt;2&lt;/sub&gt;) if one code can be obtained from the other via the following two transformations:&lt;ref&gt;{{harvnb|Pless|1998|loc=p. 8}}&lt;/ref&gt;

# arbitrarily permute the components, and
# independently scale by a non-zero element any components.

Equivalent codes have the same minimum distance.

The generator matrices of equivalent codes can be obtained from one another via the following [[Elementary matrix#Operations|elementary operations]]:&lt;ref&gt;{{harvnb|Welsh|1988|loc=pp. 54-55}}&lt;/ref&gt;

# permute rows
# scale rows by a nonzero scalar
# add rows to other rows
# permute columns, and
# scale columns by a nonzero scalar.

Thus, we can perform [[Gaussian Elimination]] on ''G''. Indeed, this allows us to assume that the generator matrix is in the standard form. More precisely, for any matrix ''G'' we can find a [[invertible matrix]] ''U'' such that &lt;math&gt;UG = \begin{bmatrix} I_k | P \end{bmatrix}&lt;/math&gt;, where ''G'' and &lt;math&gt;\begin{bmatrix} I_k | P \end{bmatrix}&lt;/math&gt; generate equivalent codes.

==See also==
* [[Hamming code (7,4)]]

==Notes==
{{reflist|3}}

==References==
* {{citation|first1=San|last1=Ling|first2=Chaoping|last2=Xing|title=Coding Theory / A First Course|publisher=Cambridge University Press|year=2004|isbn=0-521-52923-9}}
* {{citation|first=Vera|last=Pless|author-link=Vera Pless|title=Introduction to the Theory of Error-Correcting Codes|edition=3rd|publisher=Wiley Interscience|year=1998|isbn=0-471-19047-0}}
* {{citation|first=Steven|last=Roman|title=Coding and Information Theory|series=[[Graduate Texts in Mathematics|GTM]]|volume=134|publisher=Springer-Verlag|year=1992|isbn=0-387-97812-7}}
* {{citation|first=Dominic|last=Welsh|title=Codes and Cryptography|year=1988|publisher=Oxford University Press|isbn=0-19-853287-3}}

==Further reading==
* {{citation | first1=F.J.|last1=MacWilliams | author1-link=Jessie MacWilliams | first2=N.J.A.|last2=Sloane|author2-link= Neil Sloane| title=The Theory of Error-Correcting Codes | publisher=North-Holland | date=1977 | isbn=0-444-85193-3 }}

==External links==
* [http://mathworld.wolfram.com/GeneratorMatrix.html Generator Matrix at MathWorld]

{{DEFAULTSORT:Generator Matrix}}
[[Category:Coding theory]]</text>
      <sha1>djumbpk59usbunkan7edhh9dascnvf1</sha1>
    </revision>
  </page>
  <page>
    <title>Genetic and Evolutionary Computation Conference</title>
    <ns>0</ns>
    <id>49305019</id>
    <revision>
      <id>794822432</id>
      <parentid>794722891</parentid>
      <timestamp>2017-08-10T07:18:46Z</timestamp>
      <contributor>
        <username>Peter.A.N.Bosman</username>
        <id>31684507</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2205">{{unreferenced|date=February 2016}}

The '''Genetic and Evolutionary Computation Conference''' (GECCO) is the premier conference in the area of [[Evolutionary computation|genetic and evolutionary computation]]. GECCO has been held every year since 1999, when it was first established as a recombination of the International Conference on Genetic Algorithms (ICGA) and the Annual Genetic Programming Conference (GP).

GECCO presents the latest high-quality results in genetic and evolutionary computation. Topics of interest include: [[genetic algorithms]], [[genetic programming]], [[evolution strategies]], [[evolutionary programming]], [[Estimation of distribution algorithm|estimation of distribution algorithms]], [[memetic algorithms]], [[hyper-heuristics]], [[evolutionary robotics]], [[evolvable hardware]], [[artificial life]], [[ant colony optimization algorithms]], [[swarm intelligence]], [[Artificial immune system|artificial immune systems]], digital [[Entertainment technology|entertainment technologies]],  [[evolutionary art]], evolutionary [[combinatorial optimization]], [[Metaheuristic|metaheuristics]], evolutionary [[multi-objective optimization]], evolutionary [[machine learning]], [[search-based software engineering]], theory, real-world applications, and more.

Other important conferences in the field are [[IEEE Congress on Evolutionary Computation]] (CEC), [[Parallel Problem Solving from Nature]] (PPSN) and [[EvoStar]] (a group name for four co-located conferences, EuroGP, EvoCOP, EvoMUSART, and EvoApplications).

GECCO is the main annual conference of the Special Interest Group on Genetic and Evolutionary Computation (SIGEVO), which is a [[Association for Computing Machinery#Special Interest Groups|Special Interest Group]] (SIG) of the [[Association for Computing Machinery]] (ACM).

==External links==
*[http://sig.sigevo.org/index.html/tiki-index.php SIGEVO]
*[http://sig.sigevo.org/index.html/tiki-index.php?page=GECCOs A list of links to all GECCO websites since 1999]

{{Association for Computing Machinery}}
[[Category:Evolutionary computation]]
[[Category:Association for Computing Machinery conferences]]
[[Category:Computer science conferences]]

{{AI-stub}}</text>
      <sha1>juru8muitzt18s5icmo5d641w0ljzcg</sha1>
    </revision>
  </page>
  <page>
    <title>George Saitoti</title>
    <ns>0</ns>
    <id>4061643</id>
    <revision>
      <id>867974725</id>
      <parentid>852184359</parentid>
      <timestamp>2018-11-09T04:59:58Z</timestamp>
      <contributor>
        <username>Abcbalbuena</username>
        <id>2046264</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="49923">{{Use British English|date=May 2013}}
{{Use dmy dates|date=May 2013}}
{{Infobox officeholder
|honorific-prefix   = [[The Honourable]]
|name        = George Saitoti
|honorific-suffix   = [[State Commendations of Kenya|E.G.H.]]
|image       = George Saitoti (cropped).jpg
|image_size  = 
|order       = 6th
|office      = Vice-President of Kenya
|president   = [[Daniel arap Moi]]
|term_start  = 1 May 1989
|term_end    = 8 January 1998
|predecessor = [[Josephat Karanja]]
|successor   = Himself
|order2      = 6th
|office2     = Vice-President of Kenya
|president2  = [[Daniel arap Moi]]
|term_start2 = 3 April 1999
|term_end2   = 30 August 2002
|predecessor2= Himself
|successor2  = [[Musalia Mudavadi]]
|birth_date  = {{birth date|df=yes|1945|8|3}}&lt;ref name="ref"&gt;{{cite web|title=The Life and Times of Prof. George Saitoti|url=http://www.standardmedia.co.ke/ktn/?videoID=2000058289&amp;video_title=The-Life-and-Times-of-Prof.-George-Saitoti|publisher=The Standard Media Group|accessdate=11 June 2012|date=10 June 2012}}&lt;/ref&gt;&lt;ref name="reuters"&gt;{{cite web|title=Kenya's security minister, Prof. Saitoti confirmed dead|url=http://www.newvision.co.ug/news/631821-kenya-s-security-minister-prof-saitoti-confirmed-dead.html|publisher=New Vision|accessdate=25 June 2012|date=25 June 2012}}&lt;/ref&gt;
|office3     = Minister of State for Internal Security and Provincial Administration
|president3  = [[Mwai Kibaki]]
|term_start3 = 8 January 2008
|term_end3   = 10 June 2012
|predecessor3= [[John Michuki]]&lt;ref&gt;{{cite web|title=Ministry of state of provincial administration and security |url=http://www.afdevinfo.com/htmlreports/org/org_19775.html |publisher=AfDevInfo |accessdate=19 June 2012 |deadurl=yes |archiveurl=https://web.archive.org/web/20120519193229/http://www.afdevinfo.com/htmlreports/org/org_19775.html |archivedate=19 May 2012 |df=dmy }}&lt;/ref&gt;
|successor3  = [[Mohamed Yusuf Haji]]&lt;ref&gt;{{cite web|title=Yusuf haji appointed acting Internal Security Minister|url=http://www.standardmedia.co.ke/?articleID=2000060090&amp;story_title=Yusuf-haji-appointed-acting-Internal-Security-Minister|publisher=Standard Group Limited|accessdate=19 June 2012|author=Martin Mutua|date=18 June 2012}}&lt;/ref&gt;
|birth_place = [[Maasailand]], [[Kenya Colony|Kenya]]&lt;ref&gt;[http://www.newstimeafrica.com/archives/26129 "Shock as Kenya's Interior Minister George Saitoti Dies in a Helicopter Crash"], ''Newstime Africa'', 10 June 2012.&lt;/ref&gt;
|death_date  = {{death date and age|2012|6|10|1945|08|03|df=yes}}
|death_place = [[Ngong, Kenya]]
|party       = [[United Democratic Forum Party]]
|birthname   = George Musengi Saitoti&lt;ref&gt;{{cite web|title=Kenya Diaspora Vote|url=http://www.kenyadiasporavote.com/candidate/george-saitoti/|accessdate=10 June 2012|year=2012}}&lt;/ref&gt;
|nationality = Kenyan
|spouse      = Margaret Saitoti
|relations   = [[Ronald Saitoti]] &lt;small&gt;(brother)&lt;/small&gt;
|children    = Zachary Musengi&lt;ref&gt;{{cite web|title=Son's moving tribute of Saitoti – the great mentor|url=http://www.capitalfm.co.ke/news/2012/06/son-gives-moving-tribute-of-saitoti-the-great-mentor/|publisher=Capital Broadcasting Network|accessdate=17 June 2012|author=LORDRICK MAYABI}}&lt;/ref&gt;
|niece = Penny Musengi
|residence   = 
|alma_mater  = Ololua Primary School&lt;br&gt;[[Mang'u High School]]&lt;br&gt;[[Brandeis University]]&lt;br&gt;[[University of Sussex]]&lt;br&gt;[[University of Warwick]]
|occupation  = Politician
|profession  = Businessman&lt;br&gt;Economist&lt;br&gt;Mathematician
|net worth   = 
|cabinet     = Minister for Finance&lt;br&gt;&lt;small&gt;(1983–1989{{·}}1990–2002)&lt;/small&gt;&lt;br&gt;Minister of Education&lt;br&gt;&lt;small&gt;(2003–07)&lt;/small&gt;&lt;br&gt;Minister of State for Internal Security and Provincial Administration&lt;br&gt;&lt;small&gt;(2008–12)&lt;/small&gt;&lt;br&gt;Acting Minister of Foreign Affairs&lt;br&gt;&lt;small&gt;(2010–11)&lt;/small&gt;
|committees  = 
|portfolio   = 
|religion    = Roman Catholic&lt;ref&gt;{{cite web|title=Banning Chinua Achebe in Kenya|url=http://www.nathanielturner.com/banningachebeinkenya.htm|publisher=BCP Digital printing|accessdate=15 June 2012|date=29 March 2010}}&lt;/ref&gt;
|height      =
|signature   = 
|website     = 
}}

'''George Musengi Saitoti''', [[State Commendations of Kenya|E.G.H.]] (3 August 1945&lt;ref name="ref"/&gt;&lt;ref name="reuters"/&gt; – 10 June 2012) was a [[Kenya]]n politician, businessman and American- and British-trained economist, mathematician and development policy thinker.

As a mathematician, Saitoti served as Head of the Mathematics Department at the [[University of Nairobi]], pioneered the founding of the [[African Mathematical Union]] and served as its Vice-President from 1976 to 1979.

As an economist, Saitoti served as the Executive Chairman of the [[World Bank]] and the [[International Monetary Fund|International Monetary Fund (IMF)]] in 1990–91, and as President of the [[African, Caribbean and Pacific Group of States|African Caribbean and Pacific (ACP)]] Group of States in 1999–2000, at the crucial phase of re-negotiating the new development partnership agreement to replace the expired [[Lomé Convention]] between the ACP bloc and the [[European Union]] (EU). His book ''The Challenges of Economic and Institutional Reforms in Africa''&lt;ref&gt;{{Cite book|url=https://books.google.co.ke/books/about/The_challenges_of_economic_and_instituti.html?id=A-C1AAAAIAAJ&amp;redir_esc=y|title=The Challenges of Economic and Institutional Reforms in Africa|last=Saitoti|first=George|date=2002-01-01|publisher=Ashgate|isbn=9780754619888|language=en}}&lt;/ref&gt; influenced practical policy directions on an array of areas during the turbulent 1980s and 1990s.

Saitoti joined politics as a nominated Member of Parliament and Minister for Finance in 1983, rising to become Kenya's [[Vice-President of Kenya|longest-serving Vice-President]], a proficient Minister for education, Internal Security and Provincial Administration and Foreign Affairs. Few recognise him as a "reformist",{{citation needed|date=September 2012}} but his recommendations as the Chair of the KANU Review Committee, popularly known as the "Saitoti Committee" in 1990–91, opened KANU to internal changes and set the stage for the repeal of [[Constitutional Reforms in Kenya|Section 2A]] and Kenya's return to pluralist democracy. Saitoti left KANU and joined the opposition, becoming a kingpin figure in the negotiations that led to the "[[National Rainbow Coalition|NARC Revolution]]" in 2002. As Minister for Internal Security and Provincial Administration, Acting Minister for Foreign Affairs and key member of the National Security Advisory Committee (NSAC), he later worked closely with the national Ministry of Defence to see through the [[Operation Linda Nchi]] against the [[Al-Shabaab insurgent group]]. In addition, rival factions had for decades invoked the infamous [[Goldenberg scandal|Goldenberg]] fraud to knock Saitoti out of politics, but the legal courts cleared him of the scandal in July 2006.&lt;ref&gt;{{Cite news|url=http://news.bbc.co.uk/2/hi/africa/5232852.stm|title=Kenya's Saitoti escapes charges|date=2006-07-31|access-date=2018-06-12|language=en-GB}}&lt;/ref&gt; Saitoti's dual heritage as a Maasai with Kikuyu family members predisposed him to a pan-Kenyan vision, but also denied him a strong ethnic base unlike his competitors. As one of Kenya's most experienced, unassuming and shrewd politicians, Saitoti was billed{{By whom|date=September 2012}} as a front-runner in the race to succeed President [[Mwai Kibaki]].

==Early life and education==
George Saitoti was born on 3 August 1945&lt;ref name="ref"/&gt;&lt;ref name="reuters"/&gt; and brought up in Maasailand, where he spent his childhood herding cattle in line with the Masai culture, and attending school.&lt;ref&gt;{{Cite web|url=http://anthro.palomar.edu/status/stat_3.htm|title=Social Organization:  Social Groups|website=anthro.palomar.edu|access-date=2018-06-12}}&lt;/ref&gt; He attended Ololua Primary School, [[Kajiado]] where he acquired his basic education in the 1950s. Between 1960 and 1963, he secured a place at [[Mang'u High School]] in [[Thika]] where he attained his high school education. He joined the ranks of Mang'u High School's highly decorated alumni including Kenya's third President, Mwai Kibaki, former Vice-President [[Moody Awori]], Catholic Archbishop Ndingi Mwana-a-Nzeki, the late Environment Minister [[John Michuki]], the late Trade Unionist and former Minister for Justice and Constitutional Affairs, [[Tom Mboya]], and late Cardinal [[Maurice Michael Otunga]].
Saitoti spent a brief while in the United States of America, where he received his undergraduate education at [[Brandeis University]] between 1963 and 1967. During his time there, he was on the prestigious [[Wien Scholarship]], specialising in Mathematics and Economics.&lt;ref name="Wien_profile"&gt;{{cite web |url=http://www.brandeis.edu/wien/profiles/George%20Saitoti.php |work=Wien International Scholarship Program (2005) |title=George Saitoti '67 |publisher=[[Brandeis University]] |archiveurl=https://web.archive.org/web/20100528141654/http://www.brandeis.edu/wien/profiles/George%20Saitoti.php |archivedate=28 May 2010}}&lt;/ref&gt; His colleagues at the time remember that he enjoyed spending time in Cholmondeleys (the coffeehouse in the Castle) and excelled at high jump, ranking as one of the best in [[New England]].&lt;ref name="Wien_profile"/&gt; In 1988, Saitoti received the first Brandeis Alumni Achievement Award, the highest honour the University bestows upon its graduates.&lt;ref name="Wien_profile"/&gt;&lt;ref&gt;[http://alumni.brandeis.edu/web/aassociation/awards/alumni_achievement_award.html Alumni Association Awards] {{webarchive|url=https://web.archive.org/web/20120309223247/http://alumni.brandeis.edu/web/aassociation/awards/alumni_achievement_award.html |date=9 March 2012 }}&lt;/ref&gt;

Saitoti later moved to the United Kingdom where he acquired a Master of Science (MSc) degree in Mathematics from the [[University of Sussex]], Brighton. He enrolled for his doctoral studies at the [[University of Warwick]] where he acquired his PhD in Mathematics in 1972; writing his dissertation under the supervision of Professor Luke Hodgkin in the area of algebraic topology under the topic: ''Mod-2 K-Theory of the Second Iterated Loop Space on a Sphere.''&lt;ref name="math.buffalo"&gt;[http://www.math.buffalo.edu/mad/Africa-today/%20AllAfricanDoctorates.html Africa Mathematics Union], Africa Doctorates in Mathematics (1995).&lt;/ref&gt;

==Academic career==
Upon his graduation, Saitoti returned to [[Kenya]] in 1972, commencing a career as a Mathematics lecturer at the [[University of Nairobi]]. One of his contributions was the institutionalisation of Mathematics as a discipline in Africa. During the first Pan-African Conference of Mathematicians held in [[Rabat, Morocco]], in 1976, Saitoti was involved in the creation of the African Mathematical Union (AMU).&lt;ref&gt;{{Cite web|url=http://www-history.mcs.st-and.ac.uk/Societies/African.html|title=African Mathematical Union|website=www-history.mcs.st-and.ac.uk|access-date=2017-11-16}}&lt;/ref&gt; He was elected the AMU's Vice-President, a post which he held on up to 1979.&lt;ref name="math.buffalo" /&gt; By 1983, Saitoti's academic career was on the rise as associate professor and Head of the Mathematics Department.
Outside the academy, Saitoti received several public appointments. On 3 November 1972, the Minister of Labour appointed him as the chairman of the Agricultural Wages Council (AWC).&lt;ref&gt;[https://books.google.co.ke/books?id=AJ2pr0bxaZcC&amp;printsec=frontcover&amp;source=gbs_ge_summary_r&amp;cad=0#v=onepage&amp;q&amp;f=false ''Kenya Gazette'' (Republic of Kenya)], 17 November 1972.&lt;/ref&gt; On 4 September 1979, the Minister for Tourism and Wildlife, John Ogutu, also appointed him as a committee member of the Natural Sciences Advisory Research Committee (TNSARC) chaired by Professor S. O. Wandiga.&lt;ref&gt;[https://books.google.co.ke/books?id=MwTc8E3OkR8C&amp;pg=PA1167&amp;dq=Kenya+Gazette+4+Sep+1979+saitoti&amp;hl=en&amp;sa=X&amp;ei=vgqfT6r4IpO4hAebnrz8Dg&amp;ved=0CDMQ6AEwAA#v=onepage&amp;q=Kenya%20Gazette%204%20Sep%201979%20saitoti&amp;f=false ''Kenya Gazette'' (Republic of Kenya)], 14 September 1979.&lt;/ref&gt; In September 1983, he was appointed chairperson of the board of directors for the [[Rift Valley Institute of Science and Technology]].&lt;ref&gt;[https://books.google.co.ke/books?id=E3jJJ5zdFx8C&amp;pg=PA1296&amp;dq=saitoti&amp;hl=en&amp;sa=X&amp;ei#v=onepage&amp;q=saitoti&amp;f=false ''Kenya Gazette'' (Republic of Kenya)], 23 September 1983.&lt;/ref&gt; He also served in other public capacities as chairman of [[Mumias Sugar Company]] and the [[Kenya Commercial Bank]].

===Development thinker===
Top decision-makers in government had recognised Saitoti as a policy thinker and technocrat, of whom the [[Kenya African National Union|KANU]] desperately needed to fix its institutions, politics and the economy. His seminal book, ''The Challenges of Economic and Institutional Reforms in Africa'' was widely praised by leading officials as providing practical policy proposals to deal with the various challenges facing Kenya and Africa.&lt;ref name="bare_url"&gt;[https://books.google.co.ke/books/about/The_challenges_of_economic_and_instituti.html?id=A-C1AAAAIAAJ&amp;redir_esc=y ''The Challenges of Economic and Institutional Reforms in Africa'']&lt;/ref&gt;
The book drew from Saitoti's experience as a seasoned scholar, consultant and experienced policy-maker/thinker, presenting a rigorous and multidisciplinary analysis of strategies for poverty alleviation, sustainable development, poverty reduction, combating HIV/AIDS and [[Diplomacy|peace diplomacy]]. Saitoti also emphasised the importance of institutional reforms and sound public policies to sustainable economic growth in Africa.&lt;ref&gt;Saitoti, G. (2002). ''The Challenges of Economic and Institutional Reforms in Africa''. Ashgate Publishers Limited.&lt;/ref&gt;

==Political career==
Long before joining mainstream politics, Saitoti had a stint in the legislative duties. From 1974 to 1977, he represented Kenya in the defunct [[East African Community]] as a member of the [[East African Legislative Assembly]]. {{citation needed|date=June 2012}}

===Dual ancestry and politics of diversity===
[[File:Kenya Poverty Index by Constituecy 2009.jpg|right|Kenya Poverty Index by Constituency 2009]]
In October 1983, [[Daniel arap Moi|President Daniel arap Moi]] nominated Saitoti as a member of parliament and subsequently appointed him to the Cabinet as Minister for Finance. He held the position until 1989.&lt;ref&gt;[http://www.marsgroupkenya.org/multimedia/cache/cache_c21f969b5f03d33d43e04f8f136e7682_c012b78a927d02a4ff1a3bc41f75eb15 "Ruto now takes over Home Affairs docket"], ''The People Daily'' (October 2002).&lt;/ref&gt; During the [[Kenyan general election, 1988|1988 general elections]], Saitoti took the plunge into competitive politics and won the [[Kajiado North Constituency|Kajiado North]] parliamentary seat that was previously held by [[Kajiado North Constituency|Philip Odupoy]]. Prior to the tenure of Adupoy and Saitoti, the Kajiado North multi-ethnic constituency was held by the popular politician, [[Kajiado North Constituency|John Keen]], another half-Maasai who champion a nationalist vision and worked over the years to ensure the advancement of his mother's people.&lt;ref&gt;[[Kajiado North Constituency|Wikipedia, Kajiado North Constituency]] (2010).&lt;/ref&gt;
For more than 25 years, Professor George Saitoti has represented Kajiado North since 1988, recapturing the seat in consecutive elections in 1992, 1997, 2002 and 2007. Building on John Keen's legacy of a cosmopolitan constituency, Saitoti transformed Kajiado North into Kenya's most ethnically integrated multi-ethnic legislative area that also provided a safe haven to Kenyans, forcibly displaced by the 1991–2008 cycles of ethnic violence in neighbouring areas.&lt;ref name=Wachira&gt;Wachira, Charles, [http://allafrica.com/stories/201202132318.html "Kenya: Saitoti—the Dark Horse"], ''The Star'' (Nairobi), 11 February 2012. AllAfrica.&lt;/ref&gt;

The area is also ranked among the top ten wealthiest, economically dynamic and fastest growing regions in Kenya. According to figures released by the Government of Kenya in 2009, Kajiado North has had an average poverty index of 10.66 per cent for the last three years, making it one of the richest constituencies in Kenya (see table 1).&lt;ref&gt;Opiyo, P., [http://www.marsgroupkenya.org/multimedia/?StoryID=308484 "Now We Know Whose Constituency Is Poorest"] (2010).&lt;/ref&gt;

===Kenya's sixth Vice-President===
After the [[Kenyan general election, 1988|1988 General Election]], [[President Moi]] appointed Saitoti as Kenya's sixth Vice-President. Saitoti became Kenya's longest sitting vice-president serving for 13 years under [[President Moi|President Daniel arap Moi]] between May 1989 and January 1998 and again between April 1999 and August 2002 (see table 2).&lt;ref&gt;Rashid, I., [http://www.standardmedia.co.ke/commentaries/InsidePage.php?id=2000034729&amp;cid=15&amp; "Will Kibaki be the only President not to Sack VP?"] {{webarchive|url=https://web.archive.org/web/20110523093305/http://www.standardmedia.co.ke/commentaries/InsidePage.php?id=2000034729&amp;cid=15&amp; |date=23 May 2011 }} (2011).&lt;/ref&gt; At the same time, he served as Minister for Finance.
In 1990–1991, Saitoti was the Executive Chairman of the [[World Bank]] and the [[International Monetary Fund]] (IMF). In 1999–2000, Saitoti also served as president of the [[African, Caribbean and Pacific Group of States]], becoming instrumental in helping negotiate a new development partnership agreement to succeed the previous Lomè Convention that expired in February 2000 between the ACP and the [[European Union]].&lt;ref&gt;[http://intelligencebriefs.com/?p=1713 "ICC Kenya Cases Latest Development And The George Saitoti Presidency Factor"], Intelligence News, 22 February 2012.&lt;/ref&gt;
The hallmarks of Saitoti tenure as Vice-President were efficiency, sobriety and loyalty as President Moi's most trusted lieutenant. Even when President Moi dithered in naming a new deputy after the 1997 elections, Saitoti was still his favoured choice 14 months down the line.&lt;ref name=Chronicle&gt;[http://nairobichronicle.wordpress.com/2009/03/01/saitotis-elusive-presidency/ "Saitoti's Elusive Presidency"], ''Nairobi Chronicle'' (2009).&lt;/ref&gt; The same traits of efficiency, patience and loyalty would make him one of President [[Mwai Kibaki|Mwai Kibaki's]] trusted Ministers.

===Reforming KANU'S one-party system===
When Saitoti was appointed vice-president on 1 May 1989, [[Kenya African National Union|KANU]] was back-pedaling on re-democratizing the country. At the same time, the party was fragmented over the succession divide between a sit-tight "KANU-A" and a more pro-change "KANU-B" led by Saitoti. The new vice-president was, therefore, compelled to walk the tightrope between being the face of change in the ruling party and remaining loyal to his principal who, after re-election as president in 1988, had amended the constitution to increase his power to dismiss judges and widened police powers.
On New Year's Day 1990, the vocal cleric Rev. Timothy Njoya called on all Africans to demand a multiparty system of government. Following the [[Saba Saba Day|Saba Saba riots]] on 7 July 1990, [[President Moi]] announced the formation of the KANU Review Committee under the chairmanship of Prof George Saitoti, popularly known as ''the Saitoti Committee''.&lt;ref name="The Rise of a Party-State in Kenya"&gt;{{Cite web|url=http://publishing.cdlib.org/ucpressebooks/view?docId=ft9h4nb6fv&amp;chunk.id=d0e309&amp;toc.id=&amp;brand=ucpress|title=The Rise of a Party-State in Kenya|website=publishing.cdlib.org|language=en|access-date=2018-06-12}}&lt;/ref&gt;&lt;ref name="The Rise of a Party-State in Kenya"/&gt;

===The Saitoti Review Committee===
The Saitoti Review Committee was mandated to investigate the party's internal electoral and disciplinary conduct.&lt;ref&gt;{{Cite web|url=http://centrum.humanitasafrika.cz/en/library/catalogue/book/247|title=Democratization and Law Reform in Kenya (Wanjala Smokin) - African information centre|website=centrum.humanitasafrika.cz|language=cs|access-date=2018-06-12}}&lt;/ref&gt; The committee traversed the country collecting people's opinions on the party, astounding foe, friend and critics alike and offering a rare forum for direct criticism and outbursts.&lt;ref&gt;The Report of the KANU Review Committee Presented to the President by the Hon. Professor George Saitoti, October 1990. Nairobi, Government Printer.&lt;/ref&gt;
In January 1991, KANU's executive committee adopted the recommendation by George Saitoti, that critics of the party cease being expelled but suspended for one or two years.&lt;ref&gt;{{Cite book|url=https://books.google.co.ke/books?id=_BaFakFwFDMC&amp;pg=PA115&amp;lpg=PA115&amp;dq=KANU%E2%80%99s+executive+committee&amp;source=bl&amp;ots=TA1bo5Z5M0&amp;sig=LwoU1fUwwa57w0HLrtcm0-xtHM4&amp;hl=en&amp;sa=X&amp;ei=2JiiT4buC8LO8QPlzfXqCA&amp;redir_esc=y#v=onepage&amp;q=KANU%E2%80%99s%20executive%20committee&amp;f=false|title=An Introduction to African Politics|last=Thomson|first=Alex|date=2010-05-17|publisher=Taylor &amp; Francis|isbn=9780203857946|language=en}}&lt;/ref&gt;

The recommendations of the report were open for debate during the [[Kenya African National Union|National Delegates Conference]] at Karasani in [[Nairobi]]. President Moi backed the adoption and implementation of the report in ''toto'', against what many speakers at the conference had expected. This opened the reforms gates, eventually setting the stage for the [[Constitutional Reforms in Kenya|repeal of Section 2A]] in 1991 that returned Kenya to back to a multiparty system of government.&lt;ref&gt;Steeves, J., "Re-Democratization in Kenya: 'Unbounded Politics' and the Political Trajectory Towards National Elections", in D. Pal S. Ahuluwalia, Paul F. Lursey – Bray, ''The Post Colonial Condition: Contemporary Politics in Africa''.&lt;/ref&gt; The Saitoti Review Committee thrust the party on the reform path, but also widened internal ideological schisms between "KANU-A" conservatives and "KANU-B" pro-reformers over the Moi succession question.&lt;ref&gt;Throup, D., and Hornsby C., ''Multi-Party Politics in Kenya''. Nairobi: East African Education Publishers, 1998.&lt;/ref&gt;

===KANU'S war on Saitoti===
Saitoti was in the eye of a nasty succession storm that rocked [[Kenya African National Union|KANU]] before and after the [[Kenyan general election, 1997|1997 elections]]. Maasai purists led by Minister [[William Ole Ntimama]] and senior [[Maasai people|Maasai elders]] 're-Kikuyunized' Saitoti's dual ancestry, amplifying his [[Gikuyu language|Kikuyu]] family linkages as a scheme to weaken his political base and to challenge his status as a Maasai elder.
Despite his steadfast loyalty to KANU and President Moi, Saitoti was frequently ignored, humiliated and frustrated by the party and its top echelons. Around the same time [[Robert Ouko (politician)|Foreign Affairs Minister Robert Ouko]] was murdered in February 1990, Saitoti claims that attempts were made on his life.&lt;ref&gt;Ndegwa, A., [http://www.standardmedia.co.ke/archives/InsidePage.php?id=2000025251&amp;cid=4 "Saitoti: When Ouko was killed, Someone wanted me dead"]{{dead link|date=October 2017 |bot=InternetArchiveBot |fix-attempted=yes }}, ''Standard'', 22 October 2012.&lt;/ref&gt; After the [[Kenyan general election, 1997|1997 general elections]], he was dropped as Vice-President, although no replacement was appointed. Even as President Moi reappointed him in April 1999, on the roadside in Limuru, Kiambu he made a scathing remark to the effect that: "I've given back Prof Saitoti the seat of Vice-President, hopefully now your sufurias (pots) will be full of food."&lt;ref name=Wachira /&gt; Months before the [[Kenya general election, 2002|general elections of 2002]], Saitoti's name was deleted from the list of KANU delegates and his ascendancy to the presidency blocked by 'unknown' party members.&lt;ref&gt;Ilado P., and G. Peterson, [http://www.the-star.co.ke/national/national/47122-prof-saitoti-speaks-out "Prof Saitoti Speaks Out"] {{webarchive|url=https://archive.is/20120911132412/http://www.the-star.co.ke/national/national/47122-prof-saitoti-speaks-out |date=11 September 2012 }}. ''Nairobi Star'', 1 November 2011.&lt;/ref&gt;
On 18 March 2002, when KANU held its national delegates conference at the [[Moi International Sports Centre|Kasarani sports complex]], the move to block Saitoti from the succession game was manifest.&lt;ref&gt;Throup D., and Hornsby C., Multi-Party Politics in Kenya. Nairobi: East African Education Publishers 1998.&lt;/ref&gt; The meeting amended the party constitution to allow for the merger between [[Kenya African National Union|KANU]] and [[Raila Odinga|Raila Odinga's]] [[National Development Party (Kenya)|National Development Party (NDP)]] to create the [[Constitutional Reforms in Kenya|"New KANU"]]. But it also introduced four new positions of party Vice-Chairmen primarily to water down Saitoti's position as Vice-President and Moi's most likely successor as president.&lt;ref&gt;Karega, M., 2003, [http://web.peacelink.it/wajibu/18_issue/p3.html "Polarisation of politics in Kenya along Ethnic Lines"], ''Wajibu'', vol.18, no.1- 2, pp. 3–16.&lt;/ref&gt;

===The National Rainbow Coalition (NARC)===
It was clear that Moi did not even want him as one of the four vice-chairmen posts reserved for [[Uhuru Kenyatta]], [[Kalonzo Musyoka]], [[Ganze Constituency|Katana Ngala]] and [[Musalia Mudavadi]]. Moi told Saitoti to his face that he was not "presidential material".&lt;ref name=Chronicle /&gt; As a "Maasai-Kikuyu," Saitoti lacked the ethnic numbers he needed in the political horse-trading in Moi's power game. Instead, Moi finger-pointed as his heir [[Uhuru Kenyatta]], perceived to have a large ethnic base as a pure-bred Kikuyu with the [[Jomo Kenyatta|"Kenyatta" mystique]].
Saitoti gracefully bowed out of the race, living to fight another day, but not without his famous line: ''There comes a time when the nation is much more important than an individual''.&lt;ref&gt;Khamisi, J., ''The Politics of Betrayal: Diary of a Kenyan Legislator'', Trafford Publishing, 2011.&lt;/ref&gt;&lt;ref&gt;[http://www.standardmedia.co.ke/archives/InsidePage.php?id=2000003044&amp;cid=4 “There comes a time when the nation is much more important than an individual”]{{dead link|date=October 2017 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;
But the KANU-NDP marriage came to a tragic end when Moi named Uhuru rather than Raila Odinga as his successor.&lt;ref&gt;[http://www.standardmedia.co.ke/InsidePage.php?id=2000050046&amp;cid=4&amp; KANU-NDP marriage] {{webarchive|url=https://web.archive.org/web/20120310082628/http://www.standardmedia.co.ke/InsidePage.php?id=2000050046&amp;cid=4&amp; |date=10 March 2012 }}&lt;/ref&gt; In August 2002, Odinga left KANU to defeat Moi's "use and dump game,"&lt;ref name="Badejo"&gt;{{cite book |author=B. Badejo |year=2006 |title=Raila Odinga: an Enigma in Kenyan Politics |location=Lagos and Nairobi |publisher=Yintab Books}}&lt;/ref&gt; and joined a group of KANU rebels" coalesced around the "Rainbow Alliance" lobby that later transformed itself into the Liberal Democratic Party (LDP). Saitoti also walking out of KANU and became a key LDP figure. In October 2002, LDP joined the National Alliance of Kenya (NAK) of Mwai Kibaki, Charity Ngilu and Wamalwa Kijana to form the National Rainbow Coalition (NARC).&lt;ref name="Badejo"/&gt; Saitoti became a member of the NARC Summit, the highest organ of the coalition.

==The "NARC revolution"==
When the NARC flag-bearer, [[Mwai Kibaki]], decisively defeated [[Kenya African National Union|KANU]] and [[Uhuru Kenyatta]], Saitoti was appointed to the Ministry of Education. He was the man in charge of implementing NARC's flagship and globally acclaimed free primary education in Kenya.&lt;ref&gt;{{Cite news|url=http://reliefweb.int/node/179676|title=Kenya: Free primary education brings over 1 million into school|work=ReliefWeb|access-date=2018-06-12|language=en}}&lt;/ref&gt;

===The Kibaki stalwart===
After 2004, as the NARC consensus crumbled, Saitoti left the agitating LDP camp and threw his lot behind President Kibaki.&lt;ref&gt;[https://fpc.state.gov/documents/organization/101803.pdf NARC consensus]&lt;/ref&gt; He canvassed for the government-sponsored draft Constitution, which lost to a combined KANU-LDP campaign during the [[Kenyan constitutional referendum, 2005|November 2005 referendum]].&lt;ref&gt;{{Cite web|url=http://www.51voa.com/voa_standard_english/VOA_Standard_3282.html|title=VOA Standard English - Polls Show Majority of Kenyans Do Not Favor Draft Constitution|website=www.51voa.com|access-date=2018-06-12}}&lt;/ref&gt; During the 2007 elections, Saitoti defended his [[Kajiado North Constituency|Kajiado North parliamentary]] seat on the [[Party of National Unity (Kenya)|Party of National Unity (PNU)]] ticket, Kibaki's re-election vehicle, launched three months to the election on 16 September 2007.
The courts ordered a vote recount in [[Kajiado North Constituency|Kajiado North]], but Saitoti beat his closest competitor, Moses Ole Sakuda with close to 20,000 votes.&lt;ref&gt;IREC, 2008. Report of the Independent Review Commission on the General Elections held in Kenya on 27 December 2007.&lt;/ref&gt; Saitoti blamed his re-election glitch on intrigues of power by KANU forces within the PNU campaign which underwrote his rivals to knock him out of politics and potentially out of the [[Kenyan presidential election, 2013|2012 Presidential elections]]. But he had remained reticent about it.

[[File:Kenya Minister of State for Provincial Administration &amp; Internal Security (6375911923).jpg|thumb|left|[[United Kingdom|British]] Foreign Office Minister [[Henry Bellingham (Norfolk MP)|Henry Bellingham]] meeting George Saitoti, the Kenyan Minister of State for Provincial Administration &amp; Internal Security in [[London]], 21 November 2011]]

Saitoti's traits of patience, efficiency and loyalty to Kibaki paid off. On 8 January 2008, he was appointed Minister of State for Internal Security and Provincial Administration in the Office of the President, a position previously occupied by a Kibaki confidant, [[John Michuki]].&lt;ref&gt;[http://allafrica.com/stories/200801080673.html "Kibaki Names Cabinet"], ''The Standard'', 8 January 2008.&lt;/ref&gt; Saitoti retained the Internal Security docket even after President Kibaki and Prime Minister [[Raila Odinga]] established the power-sharing government that ended the [[2007-2008 Kenyan crisis|2008 post-election crisis]]. Between October 2010 and August 2011, Saitoti was appointed Minister for Foreign Affairs on an acting capacity after the incumbent, [[Moses Wetangula]], stepped aside to allow investigations on alleged corruption.&lt;ref&gt;Momanyi, B., [http://69.4.236.48/news/Kenyanews/Saitoti-takes-up-Foreign-Affairs-docket.html "Saitoti Takes up Foreign Affairs Docket"] {{webarchive|url=https://archive.is/20120708140650/http://69.4.236.48/news/Kenyanews/Saitoti-takes-up-Foreign-Affairs-docket.html |date=8 July 2012 }}. 28 October 2010.&lt;/ref&gt;

===Cabinet sub-committee on ICC===
In July 2009, Saitoti was appointed to head a special cabinet sub-committee formed to oversee the affairs of the [[International Criminal Court|International Criminal Court (ICC)]] in Kenya.&lt;ref&gt;Leftie, P., and B. Namunane, [http://www.nation.co.ke/News/-/1056/627744/-/ul1499/-/index.html "Cabinet Team to Weigh Options"], ''Daily Nation'', 21 July 2009.&lt;/ref&gt; Members of this bi-partisan committee include Saitoti, [[Mutula Kilonzo]] and [[Moses Wetangula]] (PNU) and [[James Orengo]], [[Otieno Kajwang]] and [[Amason Kingi Jeffah|Amason Kingi]] (ODM). (Following a cabinet reshuffle in April 2012, [[Eugene Wamalwa]] and [[Sam Ongeri|Prof. Sam Ongeri]] have replaced Kilonzo and Wetangula). The role of the sub-Committee as a liaison and co-ordination body between the ICC and the Kenyan government took a center-stage from December 2010 when the [[Luis Moreno Ocampo|ICC Chief Prosecutor, Luis Moreno Ocampo]], indicted six prominent Kenyans for alleged crimes against humanity relating to the [[2007-2008 Kenyan crisis|2008 post-election violence]].

As the Minister of Internal Security and the chairman of the {{YouTube|iVfO05CJl4o|Cabinet Sub-committee on ICC}} and security matters, Saitoti is the guarantor of the government's commitment to the ICC process. Arising from this, several analysts have claimed the suspects' fate lie with the sub-committee.&lt;ref&gt;Mahamad Fazul, [http://www.the-star.co.ke/opinions/others/67198-uhuru-ruto-future-is-in-saitotis-hands "Uhuru, Ruto Future is in Saitoti Hands"] {{webarchive|url=https://archive.is/20120912044734/http://www.the-star.co.ke/opinions/others/67198-uhuru-ruto-future-is-in-saitotis-hands |date=12 September 2012 }}, 16 March 2012.&lt;/ref&gt; Saitoti came out strongly criticising the invocation of [[Mwai Kibaki|President Kibaki]] in the ICC debate, calling for sobriety from politicians.&lt;ref&gt;Mwilu Aisha, [https://web.archive.org/web/20120209233344/http://ktnkenya.tv/?id=2000051619 "Saitoti Defends Kibaki over ICC"]. 7 February 2012.&lt;/ref&gt; Saitoti has maintained a legal interpretation on whether the suspects can vie for presidency in the coming elections, stressing that only the constitution can bar or let them free to enter the race.&lt;ref&gt;Ongiri Isaac, [http://www.standardmedia.co.ke/m/news.php?id=2000050443 "PNU: Cabinet has no power to decide fate of presidential aspirants"], ''The Standard'', 20 January 2012.&lt;/ref&gt;

===PNU party politics===
On 19 December 2008, [[Mwai Kibaki|President Mwai Kibaki]] who was unanimously endorsed as Party Leader at the PNU National Delegates Conference (NDC) held at [[Moi International Sports Centre|Kasarani sports complex]] in Nairobi.&lt;ref&gt;[http://www.the-star.co.ke/national/national/72319-saitoti-wants-pnu-alliance-banned PNU National Delegates Conference (NDC)] {{webarchive|url=https://web.archive.org/web/20120426080128/http://www.the-star.co.ke/national/national/72319-saitoti-wants-pnu-alliance-banned |date=26 April 2012 }}&lt;/ref&gt;&lt;ref&gt;Munyori, G., and K. Keya, [http://www.capitalfm.co.ke/search/index.php?q=Internal%20Security%20Minister "The Time has come for Saitoti"], Capital FM, 19 December 2008.&lt;/ref&gt; In accordance with the Political Parties Act (2008), Saitoti was elected PNU chairman, becoming the second-in-command in the party hierarchy since he lost as KANU Vice-President in the battle for the Moi succession in March 2002.&lt;ref&gt;{{Cite book|url=https://books.google.com/books/about/The_Moi_succession.html?id=g5COAAAAMAAJ|title=The Moi Succession: The 2002 Elections in Kenya|last=Maupeu|first=Hervâe|last2=Katumanga|first2=Musambayi|last3=Mitullah|first3=W. V.|date=2005|publisher=Transafrica Press|isbn=9789966940131|language=en}}&lt;/ref&gt; His elevation, however, complicated coalition politics and raised the stakes for the Kibaki succession in PNU.&lt;ref&gt;[http://africanpress.me/2008/04/28/5440/ Kibaki succession] {{webarchive|url=https://web.archive.org/web/20130609203243/http://africanpress.me/2008/04/28/5440/ |date=9 June 2013 }}&lt;/ref&gt; Other presidential hopefuls, [[Uhuru Kenyatta]] and [[Kalonzo Musyoka]], shunned the party and embarked on consolidating their respective parties.
In November 2010, Musyoka, Kenyatta and Saitoti signed a protocol to form and transform the PNU Alliance into a common political vehicle for the [[Kenyan presidential election, 2013|2013 presidential race]].&lt;ref&gt;[http://www.standardmedia.co.ke/InsidePage.php?id=2000052552&amp;cid=289 PNU Alliance]{{dead link|date=January 2018 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; But the imperative to comply with the Political Parties Act (2011) forced them to abandon the Alliance and shift attention to their respective parties.&lt;ref&gt;[http://cickenya.org/bills/political-parties-act-2011 Political Parties Act (2011)] {{webarchive|url=https://web.archive.org/web/20120922234325/http://www.cickenya.org/bills/political-parties-act-2011 |date=22 September 2012 }}&lt;/ref&gt;

==Goldenberg scandal==
Saitoti was both [[Vice-President of Kenya|Vice-President]] and Finance Minister at the height of the 1991–1993 [[Goldenberg scandal]]. Even though his own culpability in the fraud has never been established, for decades the [[Goldenberg scandal|Goldenberg]] has become the proverbial [[Sword of Damocles]] used against Saitoti in intra-elite power wars. In early 1999, [[Raila Odinga]] as a presidential contender to succeed Moi as President, sued Saitoti and others over alleged role in the [[Goldenberg scandal]].&lt;ref name="Badejo"/&gt; Three months after his re-appointment as Vice-President on 3 April 1999, [[Otieno Kajwang]]', a Raila ally, moved a private member's motion of no confidence in the Vice-President for his alleged role in the [[Goldenberg scandal|Goldenberg fraud]]. Saitoti survived the onslaught.&lt;ref name="Badejo"/&gt;

The Goldenberg spectre returned to haunt Saitoti in the wake of the fierce political infighting between the LDP/KANU faction and Kibaki supporters in NARC that followed the [[Kenyan constitutional referendum, 2005|2005 referendum]]. On 3 February 2006 a report by the Goldenberg Commission of Inquiry, chaired by Justice [[Samuel Bosire]], recommended that George Saitoti should face criminal charges for his involvement in the Goldenberg scandal.&lt;ref&gt;[http://news.bbc.co.uk/1/low/world/africa/4676690.stm "Moi 'Knew about' Kenya Gold Scam"], BBC News, 3 February 2006.&lt;/ref&gt;&lt;ref&gt;[http://www.assetrecovery.org/kc/node/c800a8aa-dc00-11dd-8d28-f13739c882dc.0;jsessionid=0613A4AE3F34437A9DD1F3BB1063DB41 Goldenberg Commission of Inquiry] {{webarchive|url=https://web.archive.org/web/20150923175438/http://www.assetrecovery.org/kc/node/c800a8aa-dc00-11dd-8d28-f13739c882dc.0%3Bjsessionid%3D0613A4AE3F34437A9DD1F3BB1063DB41 |date=23 September 2015 }}&lt;/ref&gt; On 13 February 2006, Saitoti voluntarily stepped aside from his ministerial docket to pave way for investigations into the allegations.&lt;ref&gt;{{Cite web|url=http://www.marsgroupkenya.org/pages/reports/government/statement_by_Hon_Kibaki_1.php|title=Marsgroupkenya.org|website=www.marsgroupkenya.org|access-date=2018-06-12}}&lt;/ref&gt;
However, on 31 July 2006, a three-judge bench headed by Justice Joseph Nyamu issued a certiorari order clearing Prof Saitoti of any wrongdoing, expunging his name from the Bosire Commission Report and issuing an order on permanent stay of prosecution against Saitoti.&lt;ref name="sudanvisiondaily"&gt;[http://www.sudanvisiondaily.com/modules.php?name=News&amp;file=article&amp;sid=14359 "Saitoti wins 16-year Fight to be Cleared"] {{webarchive|url=https://web.archive.org/web/20070630051356/http://www.sudanvisiondaily.com/modules.php?name=News |date=30 June 2007 }}, ''Sudan Vision'', 5 August 2006.&lt;/ref&gt;

In dismissing the 23 paragraphs of the report, the High Court bench cited three inter-related errors of commission and omission by the Bosire Commission:
* The inquiry into the Goldenberg fraud had created a pyramid of noticeable bias, discriminatory treatment of evidence, submissions and factual errors that undermined the pursuit of justice and fairness.&lt;ref name="sudanvisiondaily"/&gt;
* The factual flaws, biased and unprofessional handling of evidence by Inquiry led to wrong findings. The Inquiry's claim that Prof Saitoti illegally approved the 15 per cent ex-gratia payments as additional payment over and above the 20 per cent export compensation allowed at the time under the law were factually wrong. Indeed, the customs refunds, which Saitoti was accused of approving, were actually passed by Parliament.
* Long delay and wrong findings by the Goldenberg inquiry denied Prof. Saitoti any conceivable chance fair trial and justice.

On 15 November 2006, [[Mwai Kibaki|President Kibaki]] reappointed Saitoti back to Cabinet.&lt;ref&gt;HBB, [http://business.highbeam.com/3548/article-1G1-154528611/saitoti-and-kiraitu-back-cabinet-after-shuffle "Saitoti and Kiraitu Back in Cabinet after Shuffle"], 15 November 2006.&lt;/ref&gt;
In April 2012, the [[Kenya Judges and Magistrates Vetting Board|vetting board]] found Justice [[Samuel Bosire]] unfit to serve in the judiciary citing fails as the Chairman of the [[Goldenberg scandal|Goldenberg Commission of Inquiry]]. He ignored a High Court Order to summon retired President [[Daniel arap Moi]], [[Musalia Mudavadi]] and [[Nicholas Biwott]] as witnesses. The vetting board also accused Justice Nyamu of undermining public confidence in the courts for issuing a [[Stay of proceedings|permanent stay of prosecution]] against Saitoti.

==Linda Nchi==
Starting October 2011, Saitoti worked closely with national Minister of Defence [[Mohamed Yusuf Haji]] to see through [[Operation Linda Nchi|Linda Nchi]],&lt;ref name="Gkdmaaaism"&gt;{{cite news|title=Kenya: Defense Minister appointed as acting Internal Security Minister |url=http://www.garoweonline.com/artman2/publish/Somalia_27/Kenya_Defense_Minister_appointed_as_acting_Internal_Security_Minister.shtml |accessdate=20 June 2012 |newspaper=Garowe Online |date=19 June 2012 |deadurl=yes |archiveurl=https://web.archive.org/web/20121130165830/http://www.garoweonline.com/artman2/publish/Somalia_27/Kenya_Defense_Minister_appointed_as_acting_Internal_Security_Minister.shtml |archivedate=30 November 2012 |df=dmy }}&lt;/ref&gt; a coordinated operation in southern [[Somalia]] between the [[Military of Somalia|Somali military]] and the [[Kenya Defence Forces|Kenyan military]] against the [[Al-Shabaab (militant group)|Al-Shabaab]] group of insurgents.&lt;ref name="Tssgskfm"&gt;{{cite web|url=http://www.standardmedia.co.ke/agriculture/InsidePage.php?id=2000045933&amp;cid=4&amp; |title=Somalia government supports Kenyan forces' mission |publisher=Standardmedia.co.ke |deadurl=yes |archiveurl=https://web.archive.org/web/20120314153558/http://www.standardmedia.co.ke/agriculture/InsidePage.php?id=2000045933&amp;cid=4&amp; |archivedate=14 March 2012 |df=dmy }}&lt;/ref&gt;&lt;ref name="Jointc"&gt;[http://www.mfa.go.ke/index.php?option=com_content&amp;view=article&amp;id=399:joint-communique&amp;catid=35:news Joint Communique – Operation Linda Nchi]&lt;/ref&gt; The mission was officially led by the Somali army, with the Kenyan forces providing a support role.&lt;ref name="Jointc"/&gt; In early June 2012, Haji signed another agreement re-hatting Kenya's deployed military forces in Somalia under the [[AMISOM]] general command.&lt;ref name="Gkdmaaaism"/&gt;

[[File:Foreign Office Minister Henry Bellingham meeting Acting Kenyan Foreign Minister Hon Prof George Saitoti in London, 10 February 2011. (5433279579).jpg|thumb|left|[[United Kingdom|British]] Foreign Office Minister [[Henry Bellingham (Norfolk MP)|Henry Bellingham]] meeting the Acting Kenyan Foreign Minister Hon Prof George Saitoti in [[London]], 10 February 2011]]

==The Kibaki succession race==
In November 2011, Saitoti confirmed that he was in the race to succeed President Kibaki, who is set to retire after the next general election. Saitoti reiterated his candidature in January 2012,&lt;ref&gt;Odalo, B., [https://archive.is/20120714052525/http://mobile.nation.co.ke/I+am+firmly+in++the+State+House+race+says+Saitoti+/-/1292/1315796/-/format/xhtml/-/p4mem4/-/index.html "I am Firmly in the State House Race"], ''Daily Nation'', 28 January 2012.&lt;/ref&gt; continuing to tour Kenya, with meet-the-people excursions to the Rift Valley, Eastern and Central provinces.

It appeared to be history repeating itself in the battle for the soul of the Kikuyu between, Saitoti, a [[Maasai people|Maasai]] with [[Kikuyu people|Kikuyu]] kith and kin, and [[Uhuru Kenyatta]], a thorough-bred Kikuyu. Uhuru is widely thought as the presumptive successor to President Kibaki, but Saitoti was emerging also, as a likely candidate. In the event that Uhuru's run for the presidency is thwarted by the confirmed charges by the ICC, it remains a too-up as to whether Saitoti would have benefited from the spin-off.&lt;ref name=Wachira /&gt;

==Private life==
Saitoti was a businessman who had interests in agriculture, horticulture, real estates, hospitality and pastoralism.

Saitoti's family life rarely made it into the public space. His wife, Margaret Saitoti, was with him when the High Court dropped charges on the 16 years Goldenberg case.&lt;ref name="sudanvisiondaily" /&gt; His brother, Ronald Musengi, has been a banking executive with the [[Kenya Commercial Bank]]. Recently Musengi applied to be a member of the National Police Service Commission.&lt;ref&gt;[http://allafrica.com/stories/201202260146.html "Saitoti's brother on Shortlist for Police Job"], ''The Star'', 25 February 2012.&lt;/ref&gt;

==Death==
{{main|2012 Nairobi Eurocopter AS350 crash}}
Saitoti died on Sunday 10 June 2012 at around 9:00&amp;nbsp;am when a [[Eurocopter AS350]] helicopter belonging to the [[Kenya Police]] Air Wing registration 5Y-CDT,&lt;ref&gt;[http://www.standardmedia.co.ke/?articleID=2000059628&amp;story_title=Helicopter-bought-last-year-after-old-fleet-was-grounded Helicopter bought last year after old fleet was grounded], ''The Standard'', 10 June 2012.&lt;/ref&gt; carrying him and the Assistant Minister for Internal Security, [[Joshua Orwa Ojode]], crashed in the Kibiku area of [[Ngong Hills|Ngong]] forest, killing them and four others.&lt;ref&gt;Patrick Mayoyo and Lucas Barasa, [http://www.nation.co.ke/News/Saitoti+Ojode+killed+in+Police+chopper+crash/-/1056/1424382/-/4kdoyi/-/index.html "Ministers Saitoti, Ojode killed in chopper crash"], ''The Daily Nation'', 10 June 2012.&lt;/ref&gt;&lt;!--&lt;ref name="saitoti"&gt;{{cite web|title=Saitoti, Ojode feared dead in Police chopper crash|url=http://www.nation.co.ke/News/Saitoti+Ojode+killed+in+Police+chopper+crash/-/1056/1424382/-/4kdoyi/-/index.html|publisher=Nation Media Group|accessdate=10 June 2012|date=10 June 2012}}&lt;/ref&gt;--&gt; He was buried on 16 June in Kajiado North constituency. After the Maasai elders agreed to abandon the traditional burial rites and embrace the Catholic way, fifty bulls were slaughtered at the funeral in accordance with Maasai tradition.&lt;ref&gt;{{cite web|title=Fifty bulls to be slaughtered during Saitoti's burial |url=http://www.ntv.co.ke/News/Fifty+bulls+to+be+slaughtered+during+Saitoti+s+burial/-/471778/1427836/-/2wufy1/-/index.html |publisher=Nation Media Group |accessdate=15 June 2012 |date=14 June 2012 }}{{dead link|date=January 2017 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt; Saitoti was to table a ministerial statement in Parliament.&lt;ref&gt;{{YouTube|tsAoiyQ-xDY}}&lt;/ref&gt;

==List of publications==
Saitoti, G. (2005). "Keynote address given during the official opening of the sub-regional seminar for TIVET policy makers and UNESCO UNEVOC Center Coordinators". Nairobi, Kenya.

____________(2004). "Education in Kenya: Challenges and policy responses". Paper presented at the Council on
Foreign Relations, Washington D.C.

____________(2003) "National conference on education and training, Meeting the challenges of education and training during 21st century". Nairobi.

____________(2003). "Reflections on Africa Development", ''Journal of Third World Studies''.

Saitoti, G. and KANU Review Committee(2002), ''Report of the KANU Review Committee, 1990''. The Committee, Nairobi.

____________(2002).''The Challenges of Economic and Institutional Reforms in Afric''. Ashgate Publishers Limited.

____________(1985). i mathematica'', Politechnika Warszawska Technical.

____________ "A remark on Mod 2 K-Theory fundamental classes". ''Ann. Fac. Sci. Univ. Nat''. Zaïre (Kinshasa)Sect. Math.-Phys. 3 (1977), no. 1, 61–63.

____________"Homology of a differential algebra". ''Publ. Math. Debrecen'' 23 (1976), no. 3-4, 235—237.

____________"K-Theory fundamental classes". ''Demonstration Math''. 8 (1975), No. 4, 365–377.

____________A note on the homology of a differential graded algebra. ''Nigerian Journal of Science''. 8 (1974), no. 1-2,127–130.

____________Loop spaces and K-theory. ''Journal of London Mathematics Society''.(2) 9 (1974/75), 423–428.

==Positions==
* Member, National Security Committee (NSAC), Kenya. (2008 – death)
* Chairman, Cabinet Sub-committee on ICC, Kenya. (2009 – death)
* Chairman, Party of National Unity (PNU) (2008 – death)
* Acting Minister for Foreign Affairs (October 2010 – August 2011)
* Minister of State for Provincial Administration and Internal Security (January 2008 – death)
* Minister of Education (November 2006 – January 2008)
* Minister of Education (7 December 2005 – 13 February 2006)
* Minister of Education (January 2003 – November 2005)
* Vice-President (3 April 1999 – 30 August 2002)
* Minister for Planning and National Development (December 1997 – April 1999)
* Vice-President (1 May 1989 – 8 January 1998)
* Minister of Finance (1983–1988)
* Vice-President, African Mathematical Union (1976–1979)

==References==
{{reflist|colwidth=30em}}

==External links==
* https://web.archive.org/web/20070927182239/http://www.parliament.go.ke/MPs/members_saitoti_prof_g.php
* [http://www.math.buffalo.edu/mad/PEEPS/saitoti_george.html Research]
* [http://www.nationmedia.com/dailynation/nmgcontententry.asp?category_id=1&amp;newsid=67199 Goldenberg a tough test for the maths don]{{dead link|date=October 2017 |bot=InternetArchiveBot |fix-attempted=yes }}

{{wikiquote}}
{{s-start}}
{{s-off}}
{{succession box|title=[[Vice-President of Kenya]]|before=[[Josephat Njuguna Karanja]]|after=Vacant|years=1989–1998}}
{{succession box|title=[[Vice-President of Kenya]]|before=Vacant|after=[[Musalia Mudavadi]]|years=1999–2002}}
{{s-end}}

{{Current Kenyan MPs}}
{{KenyaVPs}}
{{Kenya-Ministers of Finance}}

{{Authority control}}

{{DEFAULTSORT:Saitoti, George}}
[[Category:1945 births]]
[[Category:2012 deaths]]
[[Category:Members of the National Assembly (Kenya)]]
[[Category:Vice-Presidents of Kenya]]
[[Category:Brandeis University alumni]]
[[Category:Alumni of the University of Warwick]]
[[Category:National Rainbow Coalition politicians]]
[[Category:Government ministers of Kenya]]
[[Category:Party of National Unity (Kenya) politicians]]
[[Category:Kenya African National Union politicians]]
[[Category:Kenyan mathematicians]]
[[Category:Alumni of Mang'u High School]]
[[Category:Victims of helicopter accidents or incidents]]
[[Category:Victims of aviation accidents or incidents in Kenya]]
[[Category:Maasai]]
[[Category:Kikuyu people]]
[[Category:Ministers of Finance of Kenya]]
[[Category:United Democratic Forum Party politicians]]
[[Category:Mathematician politicians]]</text>
      <sha1>k4wz8eazidq8ldm1u70z1a0j2e971ss</sha1>
    </revision>
  </page>
  <page>
    <title>Gyula Pál</title>
    <ns>0</ns>
    <id>26382071</id>
    <revision>
      <id>857193499</id>
      <parentid>857193370</parentid>
      <timestamp>2018-08-30T04:37:43Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* top */clean up, replaced: Acta Mathematica Academiae Paedagogiace Nyíregyháziensis → Acta Mathematica Academiae Paedagogicae Nyíregyháziensis</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2088">{{Infobox scientist
|name              = Gyula Pál
|image             = Pál Gyula.jpg
|image_size        = 
|caption           = Gyula (date unknown)
|birth_date        = 27 June 1881
|birth_place       = [[Győr]], [[Hungary]]
|death_date        = {{d-da|6 September 1946|27 June 1881}}
|death_place       = [[Copenhagen]], [[Denmark]]
|residence         =
|citizenship       =
|nationality       =
|ethnicity         =
|field             = [[Mathematics]]
|work_institutions =
|alma_mater        =
|doctoral_advisor  =
|doctoral_students =
|known_for         =
|author_abbrev_bot =
|author_abbrev_zoo =
|influences        =
|influenced        =
|prizes            =
|religion          =
|footnotes         =
|signature         =
}}
'''Gyula Pál''' (27 June 1881&amp;ndash; 6 September 1946) was a noted [[Hungary|Hungarian]]-[[Denmark|Danish]] [[mathematician]].&lt;ref name="Acta"&gt;{{cite journal|last2=|first2=|year=2001|title=Erratum to the paper:  Pál Gyula – Julius Pal, (1881-1946), the Hungarian – Danish mathematician|url=http://www.emis.de/journals/AMAPN/vol17/amapn17_7.pdf|journal=Acta Mathematica Academiae Paedagogicae Nyíregyháziensis|volume=17|issue=|pages=31–36|doi=|last1=|first1=}}&lt;/ref&gt;  He is known for his work on [[Jordan curve]]s both in plane and space, and on the [[Kakeya problem]]. He proved that every locally connected planar continuum with at least two points is the  orthogonal projection of a closed Jordan curve of the Euclidean 3-space.

He was born as ''Gyula Perl'' but hungaricized his surname to Pál in 1909. Fleeing the post-war chaos of Hungary after [[World War I]] he moved to [[Denmark]] in 1919, possibly by the invitation of [[Harald Bohr]], where he spent the rest of his life and westernized his name to '''Julius Pal'''.&lt;ref name=Acta /&gt;

==References==
&lt;references/&gt;

{{Authority control}}

{{DEFAULTSORT:Pal, Gyula}}
[[Category:Hungarian mathematicians]]
[[Category:Geometers]]
[[Category:1946 deaths]]
[[Category:1881 births]]
[[Category:Austro-Hungarian mathematicians]]


{{Hungary-scientist-stub}}
{{europe-mathematician-stub}}</text>
      <sha1>hvorse92qqlofz3idsb3aq78kxpiyt3</sha1>
    </revision>
  </page>
  <page>
    <title>Hard-core predicate</title>
    <ns>0</ns>
    <id>1182871</id>
    <revision>
      <id>807549421</id>
      <parentid>772822230</parentid>
      <timestamp>2017-10-28T17:52:06Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:JCW-CleanerBot#Logic|task]], replaced: Journal of the ACM (JACM) → Journal of the ACM using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5976">In [[cryptography]], a '''hard-core predicate''' of a [[one-way function]] ''f'' is a [[Predicate (mathematics)|predicate]] ''b'' (i.e., a function whose output is a single bit) which is easy to compute (as a function of ''x'') but is hard to compute given ''f(x)''.  In formal terms, there is no [[Bounded-error probabilistic polynomial|probabilistic polynomial-time (PPT) algorithm]] that computes ''b(x)'' from ''f(x)'' with probability [[negligible function (cryptography)|significantly greater]] than one half over random choice of ''x''.&lt;ref name=GoldwasserBellare&gt;[[Shafi Goldwasser|Goldwasser, S.]] and [[Mihir Bellare|Bellare, M.]] [http://cseweb.ucsd.edu/~mihir/papers/gb.html "Lecture Notes on Cryptography"]. Summer course on cryptography, MIT, 1996-2001&lt;/ref&gt;{{rp|34}} In other words, if ''x'' is drawn uniformly at random, then given ''f(x)'', any PPT adversary can only distinguish the hard-core bit ''b(x)'' and a uniformly random bit with negligible [[Advantage (cryptography)|advantage]] over the length of ''x''.&lt;ref&gt;Definition 2.4 in {{cite web|last1=Lindell|first1=Yehuda|title=Foundations of Cryptography 89-856|url=http://u.cs.biu.ac.il/~lindell/89-856/complete-89-856.pdf|website=Computer Science, Bar Ilan University|publisher=Bar Ilan University|accessdate=11 January 2016}}&lt;/ref&gt;

A '''hard-core function''' can be defined similarly. That is, if ''x'' is chosen uniformly at random, then given ''f(x)'', any PPT algorithm can only distinguish the hard-core function value ''h(x)'' and uniformly random bits of length ''|h(x)|'' with negligible advantage over the length of ''x''.&lt;ref&gt;Goldreich's FoC, vol 1, def 2.5.5.&lt;/ref&gt;&lt;ref&gt;Definition 3 in {{cite web|last1=Holenstein|first1=Thomas|title=Complete Classification of Bilinear Hard-Core Functions|url=https://www.iacr.org/archive/crypto2004/31520072/HMS_final_1.pdf|website=IACR eprint|publisher=IACR|accessdate=11 January 2016|display-authors=etal}}&lt;/ref&gt;

A hard-core predicate captures "in a concentrated sense" the hardness of inverting ''f''.

While a one-way function is hard to invert, there are no guarantees about the feasibility of computing partial information about the [[preimage]] ''c'' from the image ''f(x)''. For instance, while [[RSA (algorithm)|RSA]] is conjectured to be a one-way function, the [[Jacobi symbol]] of the preimage can be easily computed from that of the image.&lt;ref name=GoldwasserBellare /&gt;{{rp|121}}

It is clear that if a [[injective function|one-to-one function]] has a hard-core predicate, then it must be one way.  [[Oded Goldreich]] and [[Leonid Levin]] (1989) showed how every one-way function can be trivially modified to obtain a one-way function that has a specific hard-core predicate.&lt;ref name=GoldLevin&gt;O. Goldreich and L.A. Levin, [http://citeseer.ist.psu.edu/viewdoc/download?doi=10.1.1.95.2079&amp;rep=rep1&amp;type=pdf A Hard-Core Predicate for all One-Way Functions], STOC 1989, pp25&amp;ndash;32.&lt;/ref&gt;  Let ''f'' be a one-way function. Define ''g(x,r) = (f(x), r)'' where the length of ''r'' is the same as that of ''x''. Let ''x&lt;sub&gt;j&lt;/sub&gt;'' denote the ''j''&lt;sup&gt;th&lt;/sup&gt; bit of ''x'' and  ''r&lt;sub&gt;j&lt;/sub&gt;'' the ''j''&lt;sup&gt;th&lt;/sup&gt; bit of ''r''. Then

&lt;math&gt; b(x,r) := \langle x, r\rangle = \bigoplus_j x_j r_j &lt;/math&gt;

is a hard core predicate of ''g''. Note that ''b(x, r)'' =  &lt;''x, r''&gt; where &lt;·, ·&gt; denotes the standard [[Inner product space|inner product]] on the [[vector space]] ('''Z'''&lt;sub&gt;2&lt;/sub&gt;)&lt;sup&gt;''n''&lt;/sup&gt;.  This predicate is hard-core due to computational issues; that is, it is not hard to compute because ''g(x, r)'' is [[information theory|information theoretically]] lossy.  Rather, if there exists an algorithm that computes this predicate efficiently, then there is another algorithm that can invert ''f'' efficiently.

A similar construction yields a hard-core function with ''O(log |x|)'' output bits. Suppose ''f'' is a strong one-way function. Define ''g(x, r)'' = ''(f(x), r)'' where |''r''| = 2|''x''|. Choose a length function ''l(n)'' = ''O(log n)'' s.t. ''l(n)'' ≤ ''n''. Let

&lt;math&gt; b_i(x, r) = \bigoplus_j x_j r_{i+j}. &lt;/math&gt;

Then ''h(x, r)'' := ''b&lt;sub&gt;1&lt;/sub&gt;(x, r) b&lt;sub&gt;2&lt;/sub&gt;(x, r) ... b&lt;sub&gt;l(|x|)&lt;/sub&gt;(x, r)'' is a hard-core function with output length ''l(|x|)''.&lt;ref&gt;Goldreich's FoC, vol 1, Theorem 2.5.6.&lt;/ref&gt;

It is sometimes the case that an actual bit of the input ''x'' is hard-core. For example, every single bit of inputs to the RSA function is a hard-core predicate of RSA and blocks of ''O(log |x|)'' bits of ''x'' are indistinguishable from random bit strings in polynomial time (under the assumption that the RSA function is hard to invert).&lt;ref name=JohanNaslund&gt;[[Johan Håstad|J. Håstad]], M. Naslund, [http://www.csc.kth.se/tcs/tfrutv99/rsabit.pdf The Security of all RSA and Discrete Log Bits (2004)]: Journal of the ACM, 2004.&lt;/ref&gt;

Hard-core predicates give a way to construct a [[CSPRNG|pseudorandom generator]] from any [[one-way permutation]]. If ''b'' is a hard-core predicate of a one-way permutation ''f'', and ''s'' is a random seed, then

&lt;math&gt; \{ b(f^n(s))\}_n&lt;/math&gt;

is a pseudorandom bit sequence, where ''f&lt;sup&gt;n&lt;/sup&gt;'' means the n-th iteration of applying ''f'' on ''s'', and ''b'' is the generated hard-core bit by each round ''n''.&lt;ref name=GoldwasserBellare /&gt;{{rp|132}}

Hard-core predicates of trapdoor one-way permutations (known as '''trapdoor predicates''') can be used to construct [[semantic security|semantically secure]] public-key encryption schemes.&lt;ref name=GoldwasserBellare /&gt;{{rp|129}}

==See also==
* [[List-decoding]] (describes list decoding; the core of the Goldreich-Levin construction of hard-core predicates from one-way functions can be viewed as an algorithm for list-decoding the [[Hadamard code]]).

==References==
{{reflist}}
* Oded Goldreich, ''Foundations of Cryptography vol 1: Basic Tools'', Cambridge University Press, 2001.

{{DEFAULTSORT:Hard-Core Predicate}}
[[Category:Pseudorandomness]]
[[Category:Theory of cryptography]]</text>
      <sha1>hk2ko9eqq7k3pclplxdf21ur2f0h0hy</sha1>
    </revision>
  </page>
  <page>
    <title>Height of a polynomial</title>
    <ns>0</ns>
    <id>10027538</id>
    <revision>
      <id>813278452</id>
      <parentid>790709913</parentid>
      <timestamp>2017-12-02T21:23:06Z</timestamp>
      <contributor>
        <ip>69.126.23.40</ip>
      </contributor>
      <comment>/* Relation to Mahler measure */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2088">In [[mathematics]], the '''height''' and '''length''' of a polynomial ''P'' with [[complex numbers|complex]] coefficients are measures of its "size".

==Definition==
For a [[polynomial]] ''P'' of degree ''n'' given by

:&lt;math&gt;P = a_0 + a_1 x + a_2 x^2 + \cdots + a_n x^n , &lt;/math&gt;

the '''height''' ''H''(''P'') is defined to be the maximum of the magnitudes of its coefficients:

:&lt;math&gt;H(P) = \underset{i}{\max} \,|a_i| &lt;/math&gt;

and the '''length''' ''L''(''P'') is similarly defined as the sum of the magnitudes of the coefficients:

:&lt;math&gt;L(P) = \sum_{i=0}^n |a_i|.&lt;/math&gt;

==Relation to Mahler measure==
The  [[Mahler measure]] ''M''(''P'')  of ''P'' is also a measure of the size of ''P''. The three functions ''H''(''P''), ''L''(''P'') and ''M''(''P'') 
are related by the  [[inequality (mathematics)|inequalities]]

:&lt;math&gt;\binom{n}{\lfloor n/2 \rfloor}^{-1} H(P) \le M(P) \le H(P) \sqrt{n+1} ; &lt;/math&gt;

:&lt;math&gt;L(p) \le 2^n M(p) \le 2^n L(p) ; &lt;/math&gt;

:&lt;math&gt;H(p) \le L(p) \le (n+1) H(p) &lt;/math&gt;

where &lt;math&gt;\scriptstyle \binom{n}{\lfloor n/2 \rfloor}&lt;/math&gt; is the [[binomial coefficient]].

==References==
*{{cite book | first=Peter | last=Borwein | authorlink=Peter Borwein | title=Computational Excursions in Analysis and Number Theory | series=CMS Books in Mathematics | publisher=[[Springer-Verlag]] | year=2002 | isbn=0-387-95444-9 | zbl=1020.12001 | pages=2,3,142,148 }}
* {{cite journal | first=K. | last=Mahler | authorlink=Kurt Mahler | title=On two extremum properties of polynomials | journal=Illinois J. Math. | volume=7 | pages=681–701 | year= 1963 | zbl=0117.04003 }}
* {{cite book | last=Schinzel | first= Andrzej | authorlink=Andrzej Schinzel | title=Polynomials with special regard to reducibility | zbl=0956.12001 | series=Encyclopedia of Mathematics and Its Applications | volume=77 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2000 | isbn=0-521-66225-7 | page=212 }}

==External links==

* [http://mathworld.wolfram.com/PolynomialHeight.html  Polynomial height at Mathworld]

[[Category:Number theory]]
[[Category:Polynomials]]</text>
      <sha1>5iw9xo51yy829iel3vl2u5i8feghwzf</sha1>
    </revision>
  </page>
  <page>
    <title>IP (complexity)</title>
    <ns>0</ns>
    <id>2197070</id>
    <revision>
      <id>822438700</id>
      <parentid>815799342</parentid>
      <timestamp>2018-01-26T11:09:21Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30534">In [[computational complexity theory]], the class '''IP''' (which stands for Interactive Polynomial time) is the class of problems solvable by an [[interactive proof system]]. It is equal to the class '''[[PSPACE]]'''.&lt;ref&gt;Shamir, Adi. "Ip= pspace." Journal of the ACM 39.4 (1992): 869-877.&lt;/ref&gt; The result is a famous example where the proof does not [[Oracle machine#Complexity classes of oracle machines|relativize]].&lt;ref&gt;{{cite journal | author = Chang Richard ''et al.'' | year = 1994 | title = The random oracle hypothesis is false | url = | journal = Journal of Computer and System Sciences | volume = 49 | issue = 1| pages = 24–39 | doi=10.1016/s0022-0000(05)80084-4}}&lt;/ref&gt;

The concept of an interactive proof system was first introduced by [[Shafi Goldwasser]], [[Silvio Micali]], and [[Charles Rackoff]] in 1985. An interactive proof system consists of two machines, a prover, ''P'', which presents a proof that a given [[String (computer science)|string]] ''n'' is a member of some [[formal language|language]], and a verifier, ''V'', that checks that the presented proof is correct. The prover is assumed to be infinite in computation and storage, while the verifier is a probabilistic polynomial-time machine with access to a random bit string whose length is polynomial on the size of ''n''. These two machines exchange a polynomial number, ''p''(''n''), of messages and once the interaction is completed, the verifier must decide whether or not ''n'' is in the language, with only a 1/3 chance of error. (So any language in '''[[Bounded-error probabilistic polynomial|BPP]]''' is in '''IP''', since then the verifier could simply ignore the prover and make the decision on its own.)

[[File:Interactive proof (complexity).svg|thumb|300px|General representation of an interactive proof protocol.]]

== Definition ==
A language ''L'' belongs to '''IP''' if there exist ''V'', ''P'' such that for all ''Q'', ''w'':

:&lt;math&gt;w \in L \Rightarrow \Pr[V \leftrightarrow P\text{ accepts }w] \ge \tfrac{2}{3}&lt;/math&gt;
:&lt;math&gt;w \not \in L \Rightarrow \Pr[V \leftrightarrow Q\text{ accepts }w] \le \tfrac{1}{3}&lt;/math&gt;

The [[Arthur–Merlin protocol]], introduced by [[László Babai]], is similar in nature, except that the number of rounds of interaction is bounded by a constant rather than a polynomial.

Goldwasser et al. have shown that ''public-coin'' protocols, where the random numbers used by the verifier are provided to the prover along with the challenges, are no less powerful than private-coin protocols. At most two additional rounds of interaction are required to replicate the effect of a private-coin protocol. The opposite inclusion is straightforward, because the verifier can always send to the prover the results of their private coin tosses, which proves that the two types of protocols are equivalent.

In the following section we prove that '''IP''' = '''PSPACE''', an important theorem in computational complexity, which demonstrates that an interactive proof system can be used to decide whether a string is a member of a language in polynomial time, even though the traditional '''[[PSPACE]]''' proof may be exponentially long.

==Proof of IP = PSPACE==
The proof can be divided in two parts, we show that '''IP''' ⊆ '''PSPACE''' and '''PSPACE''' ⊆ '''IP'''.

=== IP ⊆ PSPACE===
In order to demonstrate that '''IP''' ⊆ '''PSPACE''', we present a simulation of an interactive proof system by a polynomial space machine. Now, we can define:

: &lt;math&gt;\Pr[V\text{ accepts }w\text{ starting at }M_j] = \max\nolimits_P \Pr \left [V \leftrightarrow P\text{ accepts }w\text{ starting at }M_j \right ] &lt;/math&gt;

and for every 0 ≤ ''j'' ≤ ''p'' and every message history ''M&lt;sub&gt;j&lt;/sub&gt;'', we inductively define the function ''N&lt;sub&gt;M&lt;sub&gt;j&lt;/sub&gt;&lt;/sub&gt;'':

: &lt;math&gt;N_{M_j} =  \begin{cases}
  0 &amp; j = p\text{ and }m_p = \text{reject}\\
  1 &amp; j = p\text{ and }m_p = \text{accept}\\
  \max_{m_{j+1}} N_{M_{j+1}} &amp; j &lt; p\text{ and }j\text{ is odd} \\
  \text{wt-avg}_{m_{j+1}} N_{M_{j+1}} &amp; j &lt; p\text{ and }j\text{ is even} \\
\end{cases}&lt;/math&gt;

where:

: &lt;math&gt;\text{wt-avg}_{m_{j+1}} N_{M_{j+1}} := \sum\nolimits_{m_{j+1}} \Pr\nolimits_r[V(w,r,M_j)]&lt;/math&gt;

where Pr&lt;sub&gt;''r''&lt;/sub&gt; is the probability taken over the random string ''r'' of length ''p''.  This expression is the average of ''N&lt;sub&gt;M&lt;sub&gt;j+1&lt;/sub&gt;&lt;/sub&gt;'', weighted by the probability that the verifier sent message ''m&lt;sub&gt;j+1&lt;/sub&gt;''.

Take ''M''&lt;sub&gt;0&lt;/sub&gt; to be the empty message sequence, here we will show that ''N&lt;sub&gt;M&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;'' can be computed in polynomial space, and that ''N&lt;sub&gt;M&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;'' = Pr[''V'' accepts ''w''].  First, to compute ''N&lt;sub&gt;M&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;'', an algorithm can recursively calculate the values ''N&lt;sub&gt;M&lt;sub&gt;j&lt;/sub&gt;&lt;/sub&gt;'' for every ''j'' and ''M&lt;sub&gt;j&lt;/sub&gt;''. Since the depth of the recursion is ''p'', only polynomial space is necessary. The second requirement is that we need ''N&lt;sub&gt;M&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;'' = Pr[''V'' accepts ''w''], the value needed to determine whether ''w'' is in A. We use induction to prove this as follows.

We must show that for every 0 ≤ ''j'' ≤ ''p'' and every ''M&lt;sub&gt;j&lt;/sub&gt;'', ''N&lt;sub&gt;M&lt;sub&gt;j&lt;/sub&gt;&lt;/sub&gt;'' = Pr[''V'' accepts ''w'' starting at ''M&lt;sub&gt;j&lt;/sub&gt;''], and we will do this using induction on ''j''.  The base case is to prove for ''j'' = ''p''.  Then we will use induction to go from ''p'' down to 0.

The base case of ''j'' = ''p'' is fairly simple.  Since ''m&lt;sub&gt;p&lt;/sub&gt;'' is either accept or reject, if ''m&lt;sub&gt;p&lt;/sub&gt;'' is accept, ''N&lt;sub&gt;M&lt;sub&gt;p&lt;/sub&gt;&lt;/sub&gt;'' is defined to be 1 and Pr[''V'' accepts ''w'' starting at ''M&lt;sub&gt;j&lt;/sub&gt;''] = 1 since the message stream indicates acceptance, thus the claim is true.  If ''m&lt;sub&gt;p&lt;/sub&gt;'' is reject, the argument is very similar.

For the inductive hypothesis, we assume that for some ''j''+1 ≤ ''p'' and any message sequence ''M&lt;sub&gt;j+1&lt;/sub&gt;'',  ''N&lt;sub&gt;M&lt;sub&gt;j&lt;/sub&gt;&lt;/sub&gt;'' = Pr[''V'' accepts ''w'' starting at ''j''+1] and then prove the hypothesis for ''j'' and any message sequence ''M&lt;sub&gt;j&lt;/sub&gt;''.

If ''j'' is even, ''m&lt;sub&gt;j+1&lt;/sub&gt;'' is a message from ''V'' to ''P''. By the definition of ''N&lt;sub&gt;M&lt;sub&gt;j&lt;/sub&gt;&lt;/sub&gt;'',

:&lt;math&gt;N_{M_j} = \sum\nolimits_{m_{j+1}} \Pr\nolimits_r \left [V(w,r,M_j)=m_{j+1} \right ] N_{M_{j+1}}.&lt;/math&gt;

Then, by the inductive hypothesis, we can say this is equal to

:&lt;math&gt;\sum\nolimits_{m_{j+1}} \Pr\nolimits_r \left [V(w,r,M_j)=m_{j+1} \right ] * \Pr \left [V\text{ accepts }w\text{ starting at }M_{j+1} \right ].&lt;/math&gt;

Finally, by definition, we can see that this is equal to Pr[''V'' accepts ''w'' starting at ''M&lt;sub&gt;j&lt;/sub&gt;''].

If ''j'' is odd, ''m&lt;sub&gt;j+1&lt;/sub&gt;'' is a message from ''P'' to ''V''.  By definition,

:&lt;math&gt;N_{M_j} = \max\nolimits_{m_{j+1}} N_{M_{j+1}}.&lt;/math&gt;

Then, by the inductive hypothesis, this equals

:&lt;math&gt;\max\nolimits_{m_{j+1}} * \Pr[V\text{ accepts }w\text{ starting at }M_{j+1}].&lt;/math&gt;

This is equal to Pr[''V'' accepts ''w'' starting at ''M&lt;sub&gt;j&lt;/sub&gt;''] since:

: &lt;math&gt;\max\nolimits_{m_{j+1}} \Pr[V\text{ accepts }w\text{ starting at }M_{j+1}] \leq \Pr[V\text{ accepts w starting at }M_j]&lt;/math&gt;

because the prover on the right-hand side could send the message ''m&lt;sub&gt;j+1&lt;/sub&gt;'' to maximize the expression on the left-hand side. And:

: &lt;math&gt;\max\nolimits_{m_{j+1}} \Pr\left[V\text{ accepts }w\text{ starting at }M_{j+1} \right] \geq \Pr\left[V\text{ accepts }w\text{ starting at }M_j\right]&lt;/math&gt;

Since the same Prover cannot do any better than send that same message.  Thus, this holds whether ''i'' is even or odd and the proof that '''IP''' ⊆ '''PSPACE''' is complete.

Here we have constructed a polynomial space machine that uses the best prover ''P'' for a particular string ''w'' in language ''A''.  We use this best prover in place of a prover with random input bits because we are able to try every set of random input bits in polynomial space.  Since we have simulated an interactive proof system with a polynomial space machine, we have shown that '''IP''' ⊆ '''PSPACE''', as desired.

===PSPACE ⊆ IP===
In order to illustrate the technique that will be used to prove '''PSPACE''' ⊆ '''IP''', we will first prove a weaker theorem, which was proven by Lund, et al.: #SAT ∈ '''IP'''.  Then using the concepts from this proof we will extend it to show that TQBF ∈ '''IP'''. Since TQBF ∈ '''PSPACE'''-complete, and TQBF ∈ '''IP''' then '''PSPACE''' ⊆ '''IP'''.

====#SAT is a member of IP====
We begin by showing that #SAT is in '''IP''', where:

: &lt;math&gt;\#\text{SAT} = \left \{ \langle \varphi, k \rangle \ : \  \varphi \text{ is a CNF-formula with exactly } k \text{ satisfying assignments} \right \}.&lt;/math&gt;

Note that this is different from the normal definition of [[Sharp-SAT|#SAT]], in that it is a decision problem, rather than a function.

First we use arithmetization to map the boolean formula with ''n'' variables, φ(''b''&lt;sub&gt;1&lt;/sub&gt;, ..., ''b&lt;sub&gt;n&lt;/sub&gt;'') to a polynomial ''p''&lt;sub&gt;φ&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x&lt;sub&gt;n&lt;/sub&gt;''), where ''p''&lt;sub&gt;φ&lt;/sub&gt; mimics φ in that ''p''&lt;sub&gt;φ&lt;/sub&gt; is 1 if φ is true and 0 otherwise provided that the variables of ''p''&lt;sub&gt;φ&lt;/sub&gt; are assigned Boolean values. The Boolean operations ∨, ∧ and ¬ used in φ are simulated in ''p''&lt;sub&gt;φ&lt;/sub&gt; by replacing the operators in φ as shown in the table below.

{| border="1" cellpadding="2"
|''a'' ∧ ''b'' ||  ''ab''
|-
|''a'' ∨ ''b'' || ''a'' ∗ ''b'' := 1 − (1 − ''a'')(1 − ''b'') 
|-
| ¬''a'' || 1 − ''a''
|+ Arithmetization rules for converting a Boolean formula φ(''b''&lt;sub&gt;1&lt;/sub&gt;, ..., ''b&lt;sub&gt;n&lt;/sub&gt;'') to a polynomial ''p''&lt;sub&gt;φ&lt;/sub&gt;(''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x&lt;sub&gt;n&lt;/sub&gt;'')
|}

As an example, φ = ''a'' ∧ ''b'' ∨ ¬''c'' would be converted into a polynomial as follows:

:&lt;math&gt;\begin{align} 
p_\varphi &amp;= a \wedge b \vee \neg c \\
&amp;= a \wedge \left (b * (1-c) \right ) \\
&amp;= a \wedge \left ( 1 - (1-b)(1 - (1-c)) \right ) \\
&amp;= a \left ( 1 - (1-b)(1 - (1-c)) \right ) \\
&amp;= a - (ac-abc) 
\end{align}&lt;/math&gt;

The operations ''ab'' and ''a'' ∗ ''b'' each result in a polynomial with a degree bounded by the sum of the degrees of the polynomials for ''a'' and ''b'' and hence, the degree of any variable is at most the length of φ.

Now let ''F'' be a finite field with order ''q'' &gt; 2&lt;sup&gt;''n''&lt;/sup&gt;; also demand that q be at least 1000. For each 0 ≤ ''i'' ≤ ''n'', define a function ''f&lt;sub&gt;i&lt;/sub&gt;'' on ''F'', having parameters &lt;math&gt;a_1, \dots, a_{i-1}\in F&lt;/math&gt;, and a single variable ''a&lt;sub&gt;i&lt;/sub&gt;'' in ''F'': For 0 ≤ ''i'' ≤ ''n'' and for &lt;math&gt;a_1, \dots, a_i \in F&lt;/math&gt; let 
:&lt;math&gt;f_i(a_1, \dots, a_i) = \sum\nolimits_{a_{i+1}, \dots, a_n \in \{0, 1\}} p(a_1, \dots, a_n).&lt;/math&gt;  
Note that the value of ''f''&lt;sub&gt;0&lt;/sub&gt; is the number of satisfying assignments of φ. ''f''&lt;sub&gt;0&lt;/sub&gt; is a void function, with no variables.

Now the protocol for #SAT works as follows:

* '''Phase 0''': The prover ''P'' chooses a prime ''q'' &gt; 2&lt;sup&gt;''n''&lt;/sup&gt; and computes ''f'', it then sends ''q'' and ''f''&lt;sub&gt;0&lt;/sub&gt; to the verifier ''V''.  ''V'' checks that ''q'' is a prime greater than max(1000, 2&lt;sup&gt;''n''&lt;/sup&gt;) and that ''f''&lt;sub&gt;0&lt;/sub&gt;() = ''k''.
* '''Phase 1''': ''P'' sends the coefficients of ''f''&lt;sub&gt;1&lt;/sub&gt;(''z'') as a polynomial in z. ''V'' verifies that the degree of ''f''&lt;sub&gt;1&lt;/sub&gt; is less than ''n'' and that ''f''&lt;sub&gt;0&lt;/sub&gt; = ''f''&lt;sub&gt;1&lt;/sub&gt;(0) + ''f''&lt;sub&gt;1&lt;/sub&gt;(1).  (If not ''V'' rejects). ''V'' now sends a random number ''r''&lt;sub&gt;1&lt;/sub&gt; from ''F'' to ''P''.
* '''Phase i''': ''P'' sends the coefficients of &lt;math&gt;f_i(r_1, \dots, r_{i-1}, z)&lt;/math&gt; as a polynomial in ''z''. ''V'' verifies that the degree of ''f&lt;sub&gt;i&lt;/sub&gt;'' is less than ''n'' and that &lt;math&gt;f_{i-1}(r_1, \dots, r_{i-1}) = f_i(r_1, \dots, r_{i-1}, 0) + f_i(r_1, \dots, r_{i-1}, 1)&lt;/math&gt;.  (If not ''V'' rejects). ''V'' now sends a random number ''r&lt;sub&gt;i&lt;/sub&gt;'' from ''F'' to ''P''.
* '''Phase n+1''': ''V'' evaluates &lt;math&gt;p(r_1, \dots, r_n)&lt;/math&gt; to compare to the value &lt;math&gt;f_n(r_1, \dots, r_n)&lt;/math&gt;.  If they are equal ''V'' accepts, otherwise ''V'' rejects.

Note that this is a public-coin algorithm.

If φ has ''k'' satisfying assignments, clearly ''V'' will accept.  If φ does not have ''k'' satisfying assignments we assume there is a prover &lt;math&gt;\tilde P&lt;/math&gt; that tries to convince ''V'' that φ does have ''k'' satisfying assignments.  We show that this can only be done with low probability.

To prevent ''V'' from rejecting in phase 0, &lt;math&gt;\tilde P&lt;/math&gt; has to send an incorrect value &lt;math&gt;\tilde f_0()&lt;/math&gt; to ''P''.  Then, in phase 1, &lt;math&gt;\tilde P&lt;/math&gt; must send an incorrect polynomial &lt;math&gt;\tilde f_1&lt;/math&gt; with the property that &lt;math&gt;\tilde f_1(0)+\tilde f_1(1) = \tilde f_0()&lt;/math&gt;. When ''V'' chooses a random ''r''&lt;sub&gt;1&lt;/sub&gt; to send to ''P'', 
:&lt;math&gt;\Pr \left [\tilde f_1(r_1) = f_1(r_1) \right ] &lt; \tfrac{1}{n^2}.&lt;/math&gt; 
This is because a polynomial in a single variable of degree at most ''d'' can have no more than ''d'' roots (unless it always evaluates to 0).  So, any two polynomials in a single variable of degree at most ''d'' can be equal only in ''d'' places.  Since |''F''| &gt; 2&lt;sup&gt;''n''&lt;/sup&gt; the chances of ''r''&lt;sub&gt;1&lt;/sub&gt; being one of these values is at most &lt;math&gt;n/2^n &lt; n/n^3&lt;/math&gt; if ''n'' &gt; 10, or at most (''n''/1000) ≤ (''n''/''n''&lt;sup&gt;3&lt;/sup&gt;) if ''n'' ≤ 10.

Generalizing this idea for the other phases we have for each 1 ≤ ''i'' ≤ ''n'' if 
:&lt;math&gt;\tilde f_{i-1}(r_1, \dots, r_{i-1}) \neq f_{i-1}(r_1, \dots, r_{i-1}),&lt;/math&gt; 
then for ''r&lt;sub&gt;i&lt;/sub&gt;'' chosen randomly from ''F'', 
:&lt;math&gt;\Pr \left [\tilde f(r_1, \dots, r_i) = f_i(r_1, \dots, r_i) \right ] \leq \tfrac{1}{n^2}.&lt;/math&gt; 
There are ''n'' phases, so the probability that &lt;math&gt;\tilde P&lt;/math&gt; is lucky because ''V'' selects at some stage a convenient ''r&lt;sub&gt;i&lt;/sub&gt;'' is at most 1/''n''.  So, no prover can make the verifier accept with probability greater than 1/''n''.  We can also see from the definition that the verifier ''V'' operates in probabilistic polynomial time.  Thus, #SAT ∈ '''IP'''.

====TQBF is a member of IP====
In order to show that '''PSPACE''' is a subset of '''IP''', we need to choose a '''PSPACE-complete''' problem and show that it is in '''IP'''. Once we show this, then it clear that '''PSPACE''' ⊆ '''IP'''.  The proof technique demonstrated here is credited to [[Adi Shamir]].

We know that TQBF is in '''PSPACE-Complete'''.  So let ψ be a quantified boolean expression:

: &lt;math&gt;\psi = \mathsf Q_1 x_1 \dots \mathsf Q_mx_m[\varphi]&lt;/math&gt;

where φ is a CNF formula.  Then ''Q&lt;sub&gt;i&lt;/sub&gt;'' is a quantifier, either ∃ or ∀. Now ''f&lt;sub&gt;i&lt;/sub&gt;'' is the same as in the previous proof, but now it also includes quantifiers.

: &lt;math&gt;f_i(a_1, \dots, a_i) =  \begin{cases}
f_i(a_1, \dots, a_m) =  1 &amp; \mathsf Q_{i+1}x_{i+1}\dots \mathsf Q_mx_m[\varphi(a_1, \dots, a_i)] \text{ is true}\\
0 &amp; \text{otherwise}
\end{cases} &lt;/math&gt;

Here, φ(''a''&lt;sub&gt;1&lt;/sub&gt;, ..., ''a&lt;sub&gt;i&lt;/sub&gt;'') is φ with ''a''&lt;sub&gt;1&lt;/sub&gt; to ''a&lt;sub&gt;i&lt;/sub&gt;'' substituted for ''x''&lt;sub&gt;1&lt;/sub&gt; to ''x&lt;sub&gt;i&lt;/sub&gt;''. Thus ''f''&lt;sub&gt;0&lt;/sub&gt; is the [[truth value]] of ψ. In order to arithmetize ψ we must use the following rules:

:&lt;math&gt; f_i(a_1, \dots,a_i) = \begin{cases} f_{i+1}(a_1, \dots,a_i,0)\cdot f_{i+1}(a_1, \dots,a_i,1) &amp; \mathsf Q_{i+1} = \forall \\
f_{i+1}(a_1, \dots,a_i,0) * f_{i+1}(a_1, \dots,a_i,1) &amp; \mathsf Q_{i+1} = \exists
\end{cases}&lt;/math&gt;

where as before we define ''x'' ∗ ''y'' = 1&amp;nbsp;−&amp;nbsp;(1&amp;nbsp;−&amp;nbsp;''x'')(1&amp;nbsp;−&amp;nbsp;''y'').

By using the method described in #SAT, we must face a problem that for any ''f&lt;sub&gt;i&lt;/sub&gt;'' the degree of the resulting polynomial may double with each quantifier. In order to prevent this, we must introduce a new reduction operator ''R'' which will reduce the degrees of the polynomial without changing their behavior on Boolean inputs.

So now before we arithmetize &lt;math&gt;\psi = \mathsf Q_1x_1\dots \mathsf Q_mx_m[\varphi]&lt;/math&gt; we introduce a new expression:

: &lt;math&gt;\psi' = \mathsf Q_1 \mathrm R x_1 \mathsf Q_2 \mathrm R x_1 \mathrm R x_2\dots \mathsf Q_m \mathrm R x_1 \dots \mathrm R x_m [\varphi]&lt;/math&gt;

or put another way:

: &lt;math&gt;\psi' = \mathsf S_1 y_1\dots \mathsf S_k y_k[\varphi], \qquad \text{ where }\mathsf S_i \in \{ \forall ,\exists , \mathrm R\}, \ y_i \in \{ x_1,\dots,x_m\}&lt;/math&gt;

Now for every ''i'' ≤ ''k'' we define the function ''f&lt;sub&gt;i&lt;/sub&gt;''. We also define &lt;math&gt;f_k(x_1,\dots,x_m)&lt;/math&gt; to be the polynomial ''p''(''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x&lt;sub&gt;m&lt;/sub&gt;'') which is obtained by arithmetizing φ. Now in order to keep the degree of the polynomial low, we define ''f&lt;sub&gt;i&lt;/sub&gt;'' in terms of ''f&lt;sub&gt;i+1&lt;/sub&gt;'':

:&lt;math&gt;\text{If }\mathsf S_{i+1} = \forall, \quad f_i(a_1,\dots,a_i) = f_{i+1}(a_1,\dots,a_i,0) \cdot f_{i+1}(a_1,\dots,a_i,1) &lt;/math&gt;
:&lt;math&gt;\text{If }\mathsf S_{i+1} = \exists, \quad f_i(a_1,\dots,a_i) = f_{i+1}(a_1,\dots,a_i,0) * f_{i+1}(a_1,\dots,a_i,1) &lt;/math&gt;
:&lt;math&gt;\text{If }\mathsf S_{i+1} = \mathrm R, \quad f_i(a_1,\dots,a_i,a) =  (1-a)f_{i+1}(a_1,\dots,a_i,0) + a f_{i+1}(a_1,\dots,a_i,1)&lt;/math&gt;

Now we can see that the reduction operation R, doesn't change the degree of the polynomial. Also it is important to see that the R''&lt;sub&gt;x&lt;/sub&gt;'' operation doesn't change the value of the function on boolean inputs. So ''f''&lt;sub&gt;0&lt;/sub&gt; is still the truth value of ψ, but the R''&lt;sub&gt;x&lt;/sub&gt;'' value produces a result that is linear in ''x''. Also after any &lt;math&gt;\mathsf Q_i x_i&lt;/math&gt; we add &lt;math&gt;\mathrm R_{x_1}\dots \mathrm R_{x_i}&lt;/math&gt; in ψ′ in order to reduce the degree down to 1 after arithmetizing &lt;math&gt;\mathsf Q_i&lt;/math&gt;.

Now let's describe the protocol. If ''n'' is the length of ψ, all arithmetic operations in the protocol are over a field of size at least ''n''&lt;sup&gt;4&lt;/sup&gt; where ''n'' is the length of ψ.

* '''Phase 0''': ''P'' → ''V'': ''P'' sends ''f''&lt;sub&gt;0&lt;/sub&gt; to ''V''.  ''V'' checks that ''f''&lt;sub&gt;0&lt;/sub&gt;= 1 and rejects if not.
* '''Phase 1''': ''P'' → ''V'': ''P'' sends ''f''&lt;sub&gt;1&lt;/sub&gt;(''z'') to ''V''. ''V'' uses coefficients to evaluate ''f''&lt;sub&gt;1&lt;/sub&gt;(0) and ''f''&lt;sub&gt;1&lt;/sub&gt;(1). Then it checks that the polynomial's degree is at most ''n'' and that the following identities are true:
::&lt;math&gt;f_{0}(\varnothing) = \begin{cases}
f_{1}(0)\cdot f_{1}(1) &amp; \text{ if }\mathsf S = \forall \\
f_{1}(0) * f_{1}(1) &amp; \text{ if }\mathsf S = \exists. \\
(1-r)f_{1}(0) + rf_{1}(1) &amp; \text{ if }\mathsf S = \mathrm R.
\end{cases}&lt;/math&gt;
:If either fails then reject.

* '''Phase i''': ''P'' → ''V'': ''P'' sends &lt;math&gt;f_i(r_1,\dots,r_{i-1},z)&lt;/math&gt; as a polynomial in ''z''. ''r''&lt;sub&gt;1&lt;/sub&gt; denotes the previously set random values for &lt;math&gt;r_1,\dots,r_{i-1}&lt;/math&gt;

''V'' uses coefficients to evaluate &lt;math&gt;f_i(r_1,\dots,r_{i-1},0)&lt;/math&gt; and &lt;math&gt;f_i(r_1,\dots,r_{i-1},1)&lt;/math&gt;.  Then it checks that the polynomial degree is at most ''n'' and that the following identities are true:
:&lt;math&gt;f_{i-1}(r_1,\dots,r_{i-1}) = \begin{cases} f_{i}(r_1,\dots,r_{i-1},0)\cdot f_{i}(r_1,\dots, r_{i-1},1) &amp; \mathsf S = \forall \\
f_{i}(r_1,\dots,r_{i-1},0) * f_i(r_1, \dots,r_{i-1},1) &amp; \mathsf S = \exists.
\end{cases}&lt;/math&gt;
:&lt;math&gt;f_{i-1}(r_1\dots r) = (1-r)f_{i}(r_1,\dots,r_{i-1},0) + rf_{i}(r_1,\dots,r_{i-1},1)\text{ if }\mathsf S = \mathrm R.&lt;/math&gt;
If either fails then reject.

''V'' → ''P'': ''V'' picks a random ''r'' in ''F'' and sends it to P. (If &lt;math&gt;\mathsf S=\mathrm R&lt;/math&gt; then this ''r'' replaces the previous ''r'').

Goto phase ''i''&amp;nbsp;+&amp;nbsp;1 where ''P'' must persuade ''V'' that &lt;math&gt;f_i(r_1,\dots,r)&lt;/math&gt; is correct.

* '''Phase ''k'' + 1''': ''V'' evaluates &lt;math&gt;p(r_1,\dots,r_m)&lt;/math&gt;. Then it checks if &lt;math&gt;p(r_1,\dots,r_m) = f_k(r_1,\dots,r_m)&lt;/math&gt; If they are equal then ''V'' accepts, otherwise ''V'' rejects.

This is the end of the protocol description.

If ψ is true then ''V'' will accept when ''P'' follows the protocol. Likewise if &lt;math&gt; \tilde{P} &lt;/math&gt; is a malicious prover which lies, and if ψ is false, then &lt;math&gt; \tilde{P} &lt;/math&gt; will need to lie at phase 0 and send some value for ''f''&lt;sub&gt;0&lt;/sub&gt;. If at phase ''i'', ''V'' has an incorrect value for &lt;math&gt;f_{i-1}(r_1,\dots)&lt;/math&gt; then &lt;math&gt;f_i(r_1,\dots,0)&lt;/math&gt; and &lt;math&gt;f_i(r_1,\dots,1)&lt;/math&gt; will likely also be incorrect, and so forth. The probability for &lt;math&gt; \tilde{P} &lt;/math&gt; to get lucky on some random ''r'' is at most the degree of the polynomial divided by the field size: &lt;math&gt;n/n^4&lt;/math&gt;. The protocol runs through ''O''(''n''&lt;sup&gt;2&lt;/sup&gt;) phases, so the probability that &lt;math&gt; \tilde{P} &lt;/math&gt; gets lucky at some phase is ≤ 1/''n''. If &lt;math&gt;\tilde{P} &lt;/math&gt; is never lucky, then ''V'' will reject at phase ''k''+1.

Since we have now shown that both '''IP''' ⊆ '''PSPACE''' and '''PSPACE''' ⊆ '''IP''', we can conclude that '''IP''' = '''PSPACE''' as desired. Moreover, we have shown that any '''IP''' algorithm may be taken to be public-coin, since the reduction from '''PSPACE''' to '''IP''' has this property.

== Variants ==
There are a number of variants of '''IP''' which slightly modify the definition of the interactive proof system. We summarize some of the better-known ones here.

=== dIP ===
{{main|Interactive proof system}}

A subset of '''IP''' is the '''deterministic Interactive Proof''' class, which is similar to '''IP''' but has a deterministic verifier (i.e. with no randomness).
This class is equal to '''[[NP (complexity)|NP]]'''.

=== Perfect Completeness ===
An ''equivalent'' definition of '''IP''' replaces the condition that the interaction succeeds with high probability on strings in the language with the requirement that it ''always'' succeeds:

:&lt;math&gt;w \in L \Rightarrow \Pr[V \leftrightarrow P\text{ accepts }w] = 1&lt;/math&gt;

This seemingly stronger criterion of "perfect completeness" does not change the complexity class '''IP''', since any language with an interactive proof system may be given an interactive proof system with perfect completeness.&lt;ref&gt;{{cite journal | author = Furer Martin, Goldreich Oded, Mansour Yishay, Sipser Michael, Zachos Stathis | year = 1989 | title = On Completeness and Soundness in Interactive Proof Systems | url = http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.39.9412 | journal = Advances in Computing Research: A Research Annual | volume = 5 | issue = | pages = 429–442 }}&lt;/ref&gt;

===MIP===
{{main|Interactive proof system#MIP}}

In 1988, Goldwasser et al. created an even more powerful interactive proof system based on '''IP''' called '''MIP''' in which there are ''two'' independent provers. The two provers cannot communicate once the verifier has begun sending messages to them. Just as it's easier to tell if a criminal is lying if he and his partner are interrogated in separate rooms, it's considerably easier to detect a malicious prover trying to trick the verifier if there is another prover it can double-check with. In fact, this is so helpful that Babai, Fortnow, and Lund were able to show that '''MIP''' = '''NEXPTIME''', the class of all problems solvable by a [[nondeterministic Turing machine|nondeterministic]] machine in ''exponential time'', a very large class. Moreover, all languages in '''NP''' have zero-knowledge proofs in an '''MIP''' system, without any additional assumptions; this is only known for '''IP''' assuming the existence of one-way functions.

===IPP===
'''IPP''' (''unbounded IP'') is a variant of '''IP''' where we replace the '''[[Bounded-error probabilistic polynomial|BPP]]''' verifier by a '''[[PP (complexity)|PP]]''' verifier. More precisely, we modify the completeness and soundness conditions as follows:

* '''Completeness''': if a string is in the language, the honest verifier will be convinced of this fact by an honest prover with probability at least 1/2.
* '''Soundness''': if the string is not in the language, no prover can convince the honest verifier that it is in the language, except with probability less than 1/2.

Although '''IPP''' also equals '''PSPACE''', '''IPP''' protocols behaves quite differently from '''IP''' with respect to [[oracle machine|oracles]]: '''IPP'''='''PSPACE''' with respect to all oracles, while '''IP''' ≠ '''PSPACE''' with respect to almost all oracles.&lt;ref&gt;R. Chang, B. Chor, Oded Goldreich, J. Hartmanis, J. Håstad, D. Ranjan, and P. Rohatgi. [http://citeseer.ist.psu.edu/chang97random.html The random oracle hypothesis is false]. ''Journal of Computer and System Sciences'', 49(1):24-39. 1994.&lt;/ref&gt;

===QIP===
{{main|Quantum Interactive Protocol}}

'''[[Quantum Interactive Protocol|QIP]]''' is a version of '''IP''' replacing the '''[[Bounded-error probabilistic polynomial|BPP]]''' verifier by a '''[[BQP]]''' verifier, where '''BQP''' is the class of problems solvable by [[quantum computer]]s in polynomial time. The messages are composed of qubits.&lt;ref&gt;J. Watrous. [http://citeseer.ist.psu.edu/watrous99pspace.html PSPACE has constant-round quantum interactive proof systems]. ''Proceedings of IEEE FOCS'99'', pp. 112-119. 1999.&lt;/ref&gt; In 2009, Jain, Ji, Upadhyay, and Watrous proved that '''QIP''' also equals '''PSPACE''',&lt;ref&gt;{{cite arXiv|eprint=0907.4737|author1=Rahul Jain|author2=Zhengfeng Ji|author3=Sarvagya Upadhyay|author4=John Watrous|authorlink4=John Watrous (computer scientist)|title=QIP = PSPACE|class=quant-ph|year=2009}}&lt;/ref&gt; implying that this change gives no additional power to the protocol. This subsumes a previous result of Kitaev and Watrous that '''QIP''' is contained in '''[[EXPTIME]]''' because '''QIP''' = '''QIP'''[3], so that more than three rounds are never necessary.&lt;ref&gt;A. Kitaev and J. Watrous. [https://cs.uwaterloo.ca/~watrous/Papers/QuantumInteractiveProofs.pdf Parallelization, amplification, and exponential time simulation of quantum interactive proof systems]. ''Proceedings of the 32nd ACM Symposium on Theory of Computing'', pp. 608-617. 2000.&lt;/ref&gt;

===compIP===
Whereas '''IPP''' and '''QIP''' give more power to the verifier, a '''compIP''' system (''competitive IP proof system'') weakens the completeness condition in a way that weakens the prover:

* '''Completeness''': if a string is in the language ''L'', the honest verifier will be convinced of this fact by an honest prover with probability at least 2/3. Moreover, the prover will do so in probabilistic polynomial time given access to an oracle for the language ''L''.

Essentially, this makes the prover a '''[[Bounded-error probabilistic polynomial|BPP]]''' machine with access to an oracle for the language, but only in the completeness case, not the soundness case. The concept is that if a language is in '''compIP''', then interactively proving it is in some sense as easy as deciding it. With the oracle, the prover can easily solve the problem, but its limited power makes it much more difficult to convince the verifier of anything. In fact, '''compIP''' isn't even known or believed to contain '''[[NP (complexity)|NP]]'''.

On the other hand, such a system can solve some problems believed to be hard. Somewhat paradoxically, though such a system is not believed to be able to solve all of '''NP''', it can easily solve all '''[[NP-complete]]''' problems due to self-reducibility. This stems from the fact that if the language L is not '''NP'''-hard, the prover is substantially limited in power (as it can no longer decide all '''NP''' problems with its oracle).

Additionally, the [[Graph isomorphism problem|graph nonisomorphism problem]] (which is a classical problem in '''IP''') is also in '''compIP''', since the only hard operation the prover has to do is isomorphism testing, which it can use the oracle to solve. Quadratic non-residuosity and graph isomorphism are also in '''compIP'''.&lt;ref&gt;Shafi Goldwasser and [[Mihir Bellare]]. [http://www.cs.ucsd.edu/users/mihir/papers/compip.pdf The Complexity of Decision versus Search]. ''SIAM Journal on Computing'', Volume 23, No. 1. February 1994.&lt;/ref&gt; Note, Quadratic non-residuosity (QNR) is likely an easier problem than graph isomorphism as QNR is in '''UP''' intersect '''co-UP'''.&lt;ref&gt;{{cite journal | author = Cai JY, Threlfall RA | year = 2004 | title = A note on quadratic residuosity and '''UP''' | url = | journal = Information Processing Letters | volume = 92 | issue = 3| pages = 127–131 | doi=10.1016/j.ipl.2004.06.015}}&lt;/ref&gt;

== Notes ==
&lt;!--See http://en.wikipedia.org/wiki/Wikipedia:Footnotes for an explanation of how to generate footnotes using the &lt;ref(erences/)&gt; tags--&gt;
&lt;references/&gt;

== References ==
* Babai, L. Trading group theory for randomness. In Proceedings of the 17th ACM Symposium on the  Theory of Computation . ACM, New York, 1985, pp.&amp;nbsp;421&amp;ndash;429.
* [[Shafi Goldwasser]], [[Silvio Micali]], and [[Charles Rackoff]]. [http://portal.acm.org/citation.cfm?id=63434 The Knowledge complexity of interactive proof-systems]. ''Proceedings of 17th ACM Symposium on the Theory of Computation'', Providence, Rhode Island. 1985, pp.&amp;nbsp;291&amp;ndash;304. [http://theory.lcs.mit.edu/~cis/pubs/shafi/1985-stoc.pdf Extended abstract]
* Shafi Goldwasser and Michael Sipser. [http://theory.lcs.mit.edu/~cis/pubs/shafi/1986-stoc.pdf Private coins versus public coins in interactive proof systems]. ''Proceedings of the 18th Annual ACM Symposium on Theory of Computation''. ACM, New York, 1986, pp.&amp;nbsp;59&amp;ndash;68.
* Rahul Jain, Zhengfeng Ji, Sarvagya Upadhyay, John Watrous. QIP = PSPACE. [https://arxiv.org/abs/0907.4737]
* [[Carsten Lund|Lund, C.]], [[Lance Fortnow|Fortnow, L.]], Karloff, H., [[Noam Nisan|Nisan, N.]] Algebraic methods for interactive proof systems. In Proceedings of 31st Symposium on the Foundations of Computer Science. IEEE, New York, 1990, pp.&amp;nbsp;2&amp;ndash;90.
* Adi Shamir. [http://portal.acm.org/citation.cfm?doid=146585.146609 IP = PSPACE]. ''Journal of the ACM'', volume 39, issue 4, p.&amp;nbsp;869&amp;ndash;877. October 1992.
* Alexander Shen. [http://doi.acm.org/10.1145/146585.146613 IP=PSpace: Simplified Proof]. J.ACM, v. 39(4), pp.&amp;nbsp;878&amp;ndash;880, 1992.
* {{CZoo|IP|I#ip}}, [http://complexityzoo.uwaterloo.ca/Complexity_Zoo:M#mip MIP], [http://complexityzoo.uwaterloo.ca/Complexity_Zoo:I#ipp IPP], [http://complexityzoo.uwaterloo.ca/Complexity_Zoo:Q#qip QIP], [http://complexityzoo.uwaterloo.ca/Complexity_Zoo:Q#qip2 QIP(2)], [http://complexityzoo.uwaterloo.ca/Complexity_Zoo:C#compip compIP], [http://complexityzoo.uwaterloo.ca/Complexity_Zoo:F#frip frIP]

{{ComplexityClasses}}

[[Category:Probabilistic complexity classes]]
[[Category:Articles containing proofs]]</text>
      <sha1>drumfofbfpcevs1d3wh7x8ua179lmga</sha1>
    </revision>
  </page>
  <page>
    <title>Jessica Sklar</title>
    <ns>0</ns>
    <id>14058925</id>
    <revision>
      <id>871759792</id>
      <parentid>868754579</parentid>
      <timestamp>2018-12-03T06:54:17Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>more ids, birth year</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5092">{{about|the mathematician|the author and philanthropist|Jessica Seinfeld}}
'''Jessica Katherine Sklar''' (born 1973){{r|born}} is a mathematician interested in [[abstract algebra]], [[recreational mathematics]], and the popularization of mathematics. She is a professor of mathematics at [[Pacific Lutheran University]], and the head of the mathematics department at Pacific Lutheran.{{r|profile}}

==Education and career==
As a high school student, Sklar studied poetry at the [[Interlochen Center for the Arts|Interlochen Arts Academy]]. She did her undergraduate studies at [[Swarthmore College]], where her parents Elizabeth S. and [[Lawrence Sklar]] had met and married (she as an English major, later to become an English professor at Wayne State University, he as a professor of the philosophy of science). She completed a double major in English and mathematics in 1995.{{r|1plus1|cv}}

Next, Sklar moved to the [[University of Oregon]] for graduate study in mathematics, earning a master's degree in 1997 and completing her Ph.D. there in 2001.{{r|profile}} Her dissertation, ''Binomial Rings and Algebras'', was supervised by Frank Wylie Anderson.{{r|mgp}}

She has been a faculty member in the mathematics department at Pacific Lutheran since 2001.{{r|cv}}

==Contributions==
Sklar is the author of an [[open textbook]] on [[abstract algebra]], ''First-Semester Abstract Algebra: A Structural Approach'' (2017).

With her mother, Elizabeth S. Sklar,{{r|1plus1}} she is the editor of ''Mathematics in Popular Culture: Essays on Appearances in Film, Literature, Games, Television and Other Media'' (McFarland &amp; Co., 2012).{{r|mpc}}

==Recognition==
Sklar was a winner of the [[Carl B. Allendoerfer Award]] of the [[Mathematical Association of America]] in 2011 for her paper with Gene Abrams, ''The Graph Menagerie: Abstract Algebra and the Mad Veterinarian''.{{r|allendoerfer}}
The paper provides a general solution to a class of [[lattice reduction]] puzzles exemplified by the following one:{{r|1plus1}}
{{quote|"Suppose a mad veterinarian creates a transmogrifier that can convert one cat into two dogs and five mice, or one dog into three cats and three mice, or a mouse into a cat and a dog. It can also do each of these operations in reverse. Can it, through any sequence of operations, convert two cats into a pack of dogs? How about one cat?"}}

==References==
{{reflist|refs=

&lt;ref name=1plus1&gt;{{citation|url=https://bulletin.swarthmore.edu/bulletin-issue-archive/archive_p=988.html|title=1 Plus 1 Makes Engaging Book: Mother and Daughter Bridge Generations and Disciplines|first=Dana|last=Mackenzie|magazine=Swarthmore College Bulletin|date=January 2013}}&lt;/ref&gt;

&lt;ref name=allendoerfer&gt;{{citation|url=http://www.ams.org/notices/201110/rtx111001464p.pdf|journal=Notices of the American Mathematical Society|department=Mathematics People|title=MAA Awards Presented|page=1464|volume=58|issue=10|date=November 2011}}&lt;/ref&gt;

&lt;ref name=born&gt;Birth year from [http://id.loc.gov/authorities/names/n2012002031.html Library of Congress catalog entry], retrieved 2018-12-02.&lt;/ref&gt;

&lt;ref name=cv&gt;{{citation|url=https://community.plu.edu/~sklarjk/sklarcv.pdf|title=Curriculum vitae|accessdate=2018-11-13}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=50506}}&lt;/ref&gt;

&lt;ref name=mpc&gt;Reviews of ''Mathematics in Popular Culture'':
*{{citation|last=Ashbacher|first=Charles|title=Review|url=https://www.maa.org/press/maa-reviews/mathematics-in-popular-culture|date=June 2012|journal=MAA Reviews}}
*{{citation|last=Sterling|first=Chris|journal=Communication Booknotes Quarterly|volume=43|issue=3|page=140|doi=10.1080/10948007.2012.700870|title=none}}
*{{citation|last=Johnson|first=J.|journal=Choice Reviews|date=September 2012|page=201|title=none}}
*{{citation|last=Karaali|first=Gizem|title=Review|url=https://www.drivehq.com/folder/p8755087/11772307136.aspx|journal=AWM Newsletter|volume=43|issue=6|date=November–December 2013|pages=22–25}}
*{{citation|last=Kozek|first=Mark|journal=The American Mathematical Monthly|volume=121|issue=3|date=March 2014|pages=274–278|doi=10.4169/amer.math.monthly.121.03.274|title=none}}
*{{citation|journal=Mathematics Magazine|volume=87|issue=5|date=December 2014|pages=404–405|doi=10.4169/math.mag.87.5.404|title=none}}
&lt;/ref&gt;

&lt;ref name=profile&gt;{{citation|url=https://www.plu.edu/math/staff/jessica-sklar/|title=Jessica Sklar|work=Mathematics Faculty and Staff|publisher=[[Pacific Lutheran University]]|accessdate=2018-11-13}}&lt;/ref&gt;

}}

==External links==
*[https://community.plu.edu/~sklarjk/ Home page]
*[https://community.plu.edu/~sklarjk/fsaa/fsaa.html ''First-Semester Abstract Algebra: A Structural Approach'']
*{{Google Scholar id|jKjVGPAAAAAJ}}

{{Authority control|MGP=50506|LCCN=n2012002031|VIAF=228739078|ISNI=0000000364671738|GND=1023388278|SUDOC=169386392}}
{{DEFAULTSORT:Sklar, Jessica}}
[[Category:1973 births]]
[[Category:Living people]]
[[Category:21st-century American mathematicians]]
[[Category:American women mathematicians]]
[[Category:Algebraists]]
[[Category:Recreational mathematicians]]
[[Category:Mathematics popularizers]]</text>
      <sha1>r6orco8rgu2zsbs80guiq2upacjy6ad</sha1>
    </revision>
  </page>
  <page>
    <title>L-statistic</title>
    <ns>0</ns>
    <id>39109075</id>
    <revision>
      <id>765007408</id>
      <parentid>751005275</parentid>
      <timestamp>2017-02-12T04:11:44Z</timestamp>
      <contributor>
        <username>Gorthian</username>
        <id>15179295</id>
      </contributor>
      <comment>Add stub</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="431">In [[statistics]], an '''L-statistic''' is a [[statistic]] (function of a data set) that is a [[linear combination]] of [[order statistic]]s; the "L" is for "linear". These are more often referred to by narrower terms according to use, namely:

* [[L-estimator]], using L-statistics as estimators for parameters
* [[L-moment]], L-statistic analogs of the conventional moments



[[Category:Summary statistics]]

{{statistics-stub}}</text>
      <sha1>a0hj5ghs5fsow32bji7xgsioquskupb</sha1>
    </revision>
  </page>
  <page>
    <title>Lagrange multiplier</title>
    <ns>0</ns>
    <id>159974</id>
    <revision>
      <id>870239372</id>
      <parentid>870239085</parentid>
      <timestamp>2018-11-23T12:23:42Z</timestamp>
      <contributor>
        <username>Ngs111</username>
        <id>18919823</id>
      </contributor>
      <comment>/* Single constraint */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="39496">In [[mathematical optimization]], the '''method of Lagrange multipliers''' (named after [[Joseph-Louis Lagrange]]&lt;ref&gt;Mécanique Analytique sect. IV, 2 vols. Paris, 1811 https://archive.org/details/mcaniqueanalyt01lagr&lt;/ref&gt;) is a strategy for finding the local [[maxima and minima]] of a [[function (mathematics)|function]] subject to [[constraint (mathematics)|equality constraints]] (i.e., subject to the condition that one or more [[equation]]s have to be satisfied exactly by the chosen values of the variables). The great advantage of this method is that it allows the optimization to be solved without explicit [[parameterization]] in terms of the constraints. As a result, the method of Lagrange multipliers is widely used to solve challenging constrained optimization problems.

The method can be summarized as follows:&lt;ref&gt;{{cite book|last1=Bramanti|first1=Marco|title=Matematica: Calcolo Infinitesimale e Algebra Lineare|date=2004|publisher=Zanichelli|location=Bologna|isbn=978-88-08-07547-5|pages=462–468|edition= 2nd}}&lt;/ref&gt;
# isolate any possible [[Singular point of an algebraic variety|singular point]] of the solution set of the constraining equations,
# find all the [[stationary point]]s of the ''Lagrange function'',
# establish which of those stationary points and singular points are global maxima (or minima, in case of minimization problems) of the objective function.

== Single constraint ==
[[Image:LagrangeMultipliers2D.svg|thumb|right|300px|Figure 1: The red curve shows the constraint &lt;span style="color: DarkRed"&gt;{{math|''g''(''x'', ''y'') {{=}} ''c''}}&lt;/span&gt;. The blue curves are contours of &lt;span style="color:DarkSlateBlue"&gt;{{math|''f''(''x'', ''y'')}}&lt;/span&gt;. The point where the red constraint tangentially touches a blue contour is the maximum of &lt;span style="color:DarkSlateBlue"&gt;{{math|''f''(''x'', ''y'')}}&lt;/span&gt; along the constraint, since {{math|''d''&lt;sub&gt;1&lt;/sub&gt; &gt; ''d''&lt;sub&gt;2&lt;/sub&gt;}}.]]

For the case of only one constraint and only two choice variables (as exemplified in Figure 1), consider the [[optimization problem]]

:maximize  {{math|''f''(''x'', ''y'')}}
:subject to {{math|''g''(''x'', ''y'') {{=}} 0}}.

(Sometimes an additive constant is shown separately rather than being included in ''g'', in which case the constraint is written {{math|''g''(''x'', ''y'') {{=}} ''c''}}, as in Figure 1.) We assume that both {{mvar|f}} and {{mvar|g}} have continuous first [[partial derivative]]s.  We introduce a new variable ({{mvar|λ}}) called a '''Lagrange multiplier''' and study the '''Lagrange function''' (or '''Lagrangian''' or '''Lagrangian expression''') defined by

:&lt;math&gt; \mathcal{L}(x,y,\lambda) = f(x,y) - \lambda \cdot g(x,y),&lt;/math&gt;

where the {{mvar|λ}} term may be either added or subtracted. If {{math|''f''(''x''&lt;sub&gt;0&lt;/sub&gt;, ''y''&lt;sub&gt;0&lt;/sub&gt;)}} is a maximum of {{math|''f''(''x'', ''y'')}} for the original constrained problem, then there exists {{math|''λ''&lt;sub&gt;0&lt;/sub&gt;}} such that {{math|(''x''&lt;sub&gt;0&lt;/sub&gt;, ''y''&lt;sub&gt;0&lt;/sub&gt;, ''λ''&lt;sub&gt;0&lt;/sub&gt;)}} is a [[stationary point]] for the Lagrange function (stationary points are those points where the first partial derivatives of &lt;math&gt;\mathcal{L}&lt;/math&gt; are zero). However, not all stationary points yield a solution of the original problem, as the method of Lagrange multipliers yields only a [[necessary condition]] for optimality in constrained problems.&lt;ref&gt;{{harvnb|Bertsekas|1999}}&lt;/ref&gt;&lt;ref&gt;{{springer | id=Lagrange_multipliers | title=Lagrange multipliers| first=I.B. | last=Vapnyarskii }}.&lt;/ref&gt;&lt;ref&gt;{{harvnb|Lasdon|1970|pages=xi+523}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Hiriart-Urruty|Lemaréchal|1993|pages=136–193 (and Bibliographical comments on pp.&amp;nbsp;334–335)}}&lt;/ref&gt;&lt;ref&gt;{{Cite book |title=Computational combinatorial optimization: Papers from the Spring School held in Schloß Dagstuhl, May&amp;nbsp;15–19,&amp;nbsp;2000 |last=Lemaréchal |first=Claude |publisher=Springer-Verlag |year=2001 |isbn=3-540-42877-1 |editor-last=Jünger |editor-first=Michael |series=Lecture Notes in Computer Science |volume=2241 |location=Berlin |pages=112–156 |chapter=Lagrangian relaxation |doi=10.1007/3-540-45586-8_4 |mr=1900016 |author-link=Claude Lemaréchal |editor-last2=Naddef |editor-first2=Denis}}&lt;/ref&gt; Sufficient conditions for a minimum or maximum [[Bordered Hessian|also exist]], but if a particular [[candidate solution]] satisfies the sufficient conditions, it is only guaranteed that that solution is the best one ''locally'' – that is, it is better than any permissible nearby points. The ''global'' optimum can be found by comparing the values of the original objective function at the points satisfying the necessary and locally sufficient conditions.

The method of Lagrange multipliers relies on the intuition that at a maximum, {{math|''f''(''x'', ''y'')}} cannot be increasing in the direction of any neighboring point where {{math|''g'' {{=}} 0}}. If it were, we could walk along {{math|''g'' {{=}} 0}} to get higher, meaning that the starting point wasn't actually the maximum.

We can visualize [[Contour line|contour]]s of {{mvar|f}} given by {{math|''f''(''x'', ''y'') {{=}} ''d''}} for various values of {{mvar|d}}, and the contour of {{mvar|g}} given by {{math|''g''(''x'', ''y'') {{=}} 0}}.

Suppose we walk along the contour line with {{math|''g'' {{=}} 0}}. We are interested in finding points where {{mvar|f}} does not change as we walk, since these points might be maxima.

There are two ways this could happen: 

# We could be following a contour line of {{mvar|f}}, since by definition {{mvar|f}} does not change as we walk along its contour lines. This would mean that the contour lines of {{mvar|f}} and {{mvar|g}} are parallel here.
# We have reached a "level" part of {{mvar|f}}, meaning that {{mvar|f}} does not change in any direction.

To check the first possibility (we are following a contour line of {{mvar|f}}), notice that since the [[gradient]] of a function is perpendicular to the contour lines, the contour lines of {{mvar|f}} and {{mvar|g}}  are parallel if and only if the gradients of {{mvar|f}} and {{mvar|g}} are parallel. Thus we want points {{math|(''x'', ''y'')}} where {{math|''g''(''x'', ''y'') {{=}} 0}} and

:&lt;math&gt;\nabla_{x,y} f = \lambda \nabla_{x,y} g,&lt;/math&gt;

for some {{mvar|λ}}

where

:&lt;math&gt; \nabla_{x,y} f= \left( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y} \right), \qquad \nabla_{x,y} g= \left( \frac{\partial g}{\partial x}, \frac{\partial g}{\partial y} \right).&lt;/math&gt;

are the respective gradients. The constant {{mvar|λ}} is required because although the two gradient vectors are parallel, the magnitudes of the gradient vectors are generally not equal. This constant is called the Lagrange multiplier. (In some conventions {{mvar|λ}} is preceded by a minus sign).

Notice that this method also solves the second possibility, that {{mvar|f}} is level: if {{mvar|f}} is level, then its gradient is zero, and setting {{math|''λ'' {{=}} 0}} is a solution regardless of &lt;math&gt;\nabla_{x,y}g&lt;/math&gt;.

To incorporate these conditions into one equation, we introduce an auxiliary function

:&lt;math&gt; \mathcal{L}(x,y,\lambda) = f(x,y) - \lambda \cdot g(x,y), &lt;/math&gt;

and solve

:&lt;math&gt; \nabla_{x,y,\lambda} \mathcal{L}(x , y, \lambda)=0. &lt;/math&gt;

Note that this amounts to solving three equations in three unknowns. This is the method of Lagrange multipliers. Note that &lt;math&gt;\nabla_{\lambda} \mathcal{L}(x , y, \lambda)=0&lt;/math&gt; implies {{math|''g''(''x'', ''y'') {{=}} 0}}. To summarize
:&lt;math&gt;
\nabla_{x,y,\lambda} \mathcal{L}(x , y, \lambda)=0 \iff 
\begin{cases}
\nabla_{x,y} f(x , y) = \lambda \nabla_{x,y} g(x , y)\\
 g(x,y) = 0
\end{cases}&lt;/math&gt;

The method generalizes readily to functions on &lt;math&gt;n&lt;/math&gt; variables

:&lt;math&gt; \nabla_{x_1, \dots, x_n,\lambda} \mathcal{L}(x_1, \dots, x_n, \lambda)=0&lt;/math&gt;

which amounts to solving &lt;math&gt;n+1&lt;/math&gt; equations in &lt;math&gt;n+1&lt;/math&gt; unknowns.

The constrained extrema of {{mvar|f}} are ''[[Critical point (mathematics)|critical points]]'' of the Lagrangian &lt;math&gt;\mathcal{L}&lt;/math&gt;, but they are not necessarily ''local extrema'' of &lt;math&gt;\mathcal{L}&lt;/math&gt; (see [[#Example 2|Example 2]] below).

One may [[Hamiltonian mechanics#As a reformulation of Lagrangian mechanics|reformulate the Lagrangian]] as a [[Hamiltonian mechanics|Hamiltonian]], in which case the solutions are local minima for the Hamiltonian. This is done in [[optimal control]] theory, in the form of [[Pontryagin's minimum principle]].

The fact that solutions of the Lagrangian are not necessarily extrema also poses difficulties for numerical optimization. This can be addressed by computing the ''magnitude'' of the gradient, as the zeros of the magnitude are necessarily local minima, as illustrated in the [[#Example 4: Numerical optimization|numerical optimization example]].

== Multiple constraints ==
[[Image:As wiki lgm parab.svg|thumb|right|300px|Figure 2: A paraboloid constrained along two intersecting lines.]]
[[Image:As wiki lgm levelsets.svg|thumb|right|300px|Figure 3: Contour map of Figure 2.]]
The method of Lagrange multipliers can be extended to solve problems with multiple constraints using a similar argument. Consider a [[paraboloid]] subject to two line constraints that intersect at a single point. As the only feasible solution, this point is obviously a constrained extremum. However, the [[level set]] of &lt;math&gt;f&lt;/math&gt; is clearly not parallel to either constraint at the intersection point (see Figure 3); instead, it is a linear combination of the two constraints' gradients. In the case of multiple constraints, that will be what we seek in general: the method of Lagrange seeks points not at which the gradient of &lt;math&gt;f&lt;/math&gt; is multiple of any single constraint's gradient necessarily, but in which it is a linear combination of all the constraints' gradients.

Concretely, suppose we have &lt;math&gt;M&lt;/math&gt; constraints and are walking along the set of points satisfying &lt;math&gt;g_i(\mathbf{x})=0, i=1, \dots, M&lt;/math&gt;. Every point &lt;math&gt;\mathbf{x}&lt;/math&gt; on the contour of a given constraint function &lt;math&gt;g_i&lt;/math&gt; has a space of allowable directions: the space of vectors perpendicular to &lt;math&gt;\nabla g_i(\mathbf{x})&lt;/math&gt;.  The set of directions that are allowed by all constraints is thus the space of directions perpendicular to all of the constraints' gradients.  Denote this space of allowable moves by &lt;math&gt;A&lt;/math&gt; and denote the span of the constraints' gradients by &lt;math&gt;S&lt;/math&gt;.  Then &lt;math&gt;A = S^{\perp}&lt;/math&gt;, the space of vectors perpendicular to every element of &lt;math&gt;S&lt;/math&gt;.

We are still interested in finding points where &lt;math&gt;f&lt;/math&gt; does not change as we walk, since these points might be (constrained) extrema. We therefore seek &lt;math&gt;\mathbf{x}&lt;/math&gt; such that any allowable direction of movement away from &lt;math&gt;\mathbf{x}&lt;/math&gt; is perpendicular to &lt;math&gt;\nabla f(\mathbf{x})&lt;/math&gt; (otherwise we could increase &lt;math&gt;f&lt;/math&gt; by moving along that allowable direction).  In other words, &lt;math&gt;\nabla f(\mathbf{x}) \in A^{\perp} = S&lt;/math&gt;.  Thus there are scalars {{math|''λ''&lt;sub&gt;1&lt;/sub&gt;, ''λ''&lt;sub&gt;2&lt;/sub&gt;, ..., ''λ&lt;sub&gt;M&lt;/sub&gt;''}} such that

: &lt;math&gt;\nabla f(\mathbf{x}) = \sum_{k=1}^M  \lambda_k \nabla g_k (\mathbf{x})  \quad \iff \quad \nabla f(\mathbf{x}) -  \sum_{k=1}^M {\lambda_k \nabla g_k (\mathbf{x})} = 0.&lt;/math&gt;

These scalars are the Lagrange multipliers. We now have &lt;math&gt;M&lt;/math&gt; of them, one for every constraint.

As before, we introduce an auxiliary function

: &lt;math&gt;\mathcal{L}\left( x_1,\ldots , x_n, \lambda_1, \ldots, \lambda _M \right) = f\left( x_1, \ldots, x_n \right) - \sum\limits_{k=1}^M {\lambda_k g_k\left( x_1, \ldots , x_n \right)}&lt;/math&gt;

and solve

:&lt;math&gt; \nabla_{x_1, \ldots , x_n, \lambda_1, \ldots, \lambda _M} \mathcal{L}(x_1, \ldots , x_n, \lambda_1, \ldots, \lambda _M)=0 \iff 
\begin{cases}
\nabla f(\mathbf{x}) - \sum_{k=1}^M {\lambda_k \, \nabla g_k (\mathbf{x})} = 0\\
 g_1(\mathbf{x}) = \cdots = g_M(\mathbf{x}) = 0
\end{cases}&lt;/math&gt;

which amounts to solving &lt;math&gt;n+M&lt;/math&gt; equations in &lt;math&gt;n+M&lt;/math&gt; unknowns.

The method of Lagrange multipliers is generalized by the [[Karush–Kuhn–Tucker conditions]], which can also take into account inequality constraints of the form {{math|''h''('''x''')&amp;nbsp;≤&amp;nbsp;''c''}}.


==Modern formulation via differentiable manifolds==

The problem of finding the local maxima and minima subject to constraints can be generalized to finding local maxima and minima on a [[differentiable manifold]].

===Single constraint===
Let &lt;math&gt;M&lt;/math&gt; be a [[smooth manifold]] of dimension &lt;math&gt;m&lt;/math&gt;. Suppose that we wish to find the stationary points &lt;math&gt;x&lt;/math&gt; of a smooth function &lt;math&gt;f:M\rightarrow \mathbb{R}&lt;/math&gt; when restricted to the submanifold &lt;math&gt;N&lt;/math&gt; defined by &lt;math&gt;g(x)=0&lt;/math&gt;, where &lt;math&gt;g:M\rightarrow \mathbb{R}&lt;/math&gt; is a smooth function for which 0 is a [[regular value]] of &lt;math&gt;g&lt;/math&gt;.

Let &lt;math&gt;df&lt;/math&gt; and &lt;math&gt;dg&lt;/math&gt; be the [[exterior derivative]]s. Stationarity for the restriction &lt;math&gt;f|_{N}&lt;/math&gt; at &lt;math&gt;x\in N&lt;/math&gt; means &lt;math&gt;d(f|_{N})_x=0&lt;/math&gt;. Equivalently, the kernel &lt;math&gt;\operatorname{ker}(df_x)&lt;/math&gt; contains &lt;math&gt;T_x N=\operatorname{ker}(dg_x)&lt;/math&gt;. In other words, &lt;math&gt;df_x&lt;/math&gt; and &lt;math&gt;dg_x&lt;/math&gt; are proportional vectors. For this it is necessary and sufficient that the following system of &lt;math&gt;m(m-1)/2&lt;/math&gt; equations holds:

:&lt;math&gt;df_x \wedge dg_x = 0 \in \Lambda^{2}(T^{*}_{x}M)&lt;/math&gt;

where &lt;math&gt;\wedge&lt;/math&gt; denotes the [[exterior algebra|exterior product]]. The stationary points &lt;math&gt;x&lt;/math&gt; are the solutions of the above system of equations plus the constraint &lt;math&gt;g(x)=0&lt;/math&gt;. Note that the &lt;math&gt;m(m-1)/2&lt;/math&gt; equations are not independent, since the left-hand side of the equation belongs to the subvariety of &lt;math&gt;\Lambda^{2}(T^{*}_{x}M)&lt;/math&gt; consisting of [[exterior algebra|decomposable elements]].

In this formulation, it is not necessary to explicitly find the Lagrange multiplier, a number &lt;math&gt;\lambda&lt;/math&gt; such that &lt;math&gt;df_x = \lambda dg_x&lt;/math&gt;.

===Multiple constraints===
Let &lt;math&gt;M&lt;/math&gt; be a [[smooth manifold]] embedded in &lt;math&gt;\mathbb R^n&lt;/math&gt; with codimension &lt;math&gt;p&lt;/math&gt;. Suppose &lt;math&gt;f\colon \mathbb R^n \to \mathbb{R}&lt;/math&gt; is a differentiable function that we wish to maximize on &lt;math&gt;M&lt;/math&gt;. By an extension of [[Fermat's theorem (stationary points)|Fermat's theorem]] the local maxima occur at points where the [[exterior derivative]] &lt;math&gt;df&lt;/math&gt; vanishes.&lt;ref&gt;{{harvnb|Lafontaine|p=[{{google books|id=KNhJCgAAQBAJ|pg=PA70|plainurl=yes}} 70]}}&lt;/ref&gt; In particular, supposing we have a local [[coordinate chart]] &lt;math&gt;\varphi\colon U \to \mathbb{R}^{n-p}&lt;/math&gt; for &lt;math&gt;U \subseteq M&lt;/math&gt;, the extrema of &lt;math&gt;f&lt;/math&gt; are a subset of the critical points of the function &lt;math&gt;f_\varphi = f \circ \varphi^{-1}\colon V \to \mathbb{R}&lt;/math&gt;, where &lt;math&gt;V&lt;/math&gt; is the image of &lt;math&gt;\varphi&lt;/math&gt;.
However, it is often difficult to compute &lt;math&gt;\varphi^{-1}&lt;/math&gt; explicitly. ''The entire method of Lagrange multipliers reduces to the idea of skipping that step and finding the zeros of &lt;math&gt;df_\varphi&lt;/math&gt; directly.''

It remains to show that this notion of critical point is well defined. Suppose that &lt;math&gt;\varphi&lt;/math&gt; and &lt;math&gt;\psi&lt;/math&gt; are charts on &lt;math&gt;M&lt;/math&gt; whose domains both contain some point &lt;math&gt;y&lt;/math&gt;. The chain rule implies that &lt;math&gt;\varphi(y)&lt;/math&gt; is a critical point of &lt;math&gt;f_\varphi&lt;/math&gt; if and only if &lt;math&gt;\psi(y)&lt;/math&gt; is a critical point of &lt;math&gt;f_\psi&lt;/math&gt;. Indeed,

:&lt;math&gt;f_\varphi=f\circ\varphi^{-1}=f\circ(\psi^{-1}\circ\psi)\circ\varphi^{-1}=f_\psi\circ(\psi\circ\varphi^{-1}).&lt;/math&gt;

The composition &lt;math&gt;\psi\circ\varphi^{-1}&lt;/math&gt; is a [[Atlas (topology)|transition map]] for &lt;math&gt;M&lt;/math&gt; and therefore is a diffeomorphism. It follows that

:&lt;math&gt;D_{\varphi(y)}f_\varphi=D_{\psi(y)}f_\psi\circ D_{\varphi(y)}(\psi\circ\varphi^{-1}),&lt;/math&gt;

so &lt;math&gt;D_{\varphi(y)}f_\varphi&lt;/math&gt; is the &lt;math&gt;0&lt;/math&gt; map if and only if the same is true of &lt;math&gt;D_{\psi(y)}f_\psi&lt;/math&gt;. Formally, we're looking for points &lt;math&gt;y\in M&lt;/math&gt; such that for some (and hence any) chart &lt;math&gt;\varphi&lt;/math&gt; containing &lt;math&gt;y&lt;/math&gt;, &lt;math&gt;\varphi(y)&lt;/math&gt; is a critical point of &lt;math&gt;f_\varphi&lt;/math&gt;.&lt;ref&gt;Lee, Jeffrey M. (2009). ''Manifolds and Differential Geometry.'' Providence: American Mathematical Society. p. 23. {{ISBN|978-0-8218-4815-9}}. Lee discusses a property being true specifically for some "and hence any" chart on a manifold.&lt;/ref&gt;

Suppose the manifold &lt;math&gt;M&lt;/math&gt; is defined by a smooth [[level set]] function &lt;math&gt;g\colon \mathbb{R}^n \to \mathbb{R}^p&lt;/math&gt; as &lt;math&gt;M = \{ x \in\mathbb R^n : g(x) = c \}&lt;/math&gt;, with &lt;math&gt;c \in \mathbb{R}^p&lt;/math&gt; and &lt;math&gt; g&lt;/math&gt; a [[Submersion (mathematics)|submersion]]. It follows from the construction in the level set theorem that the image of &lt;math&gt;D_x \varphi^{-1}&lt;/math&gt; is &lt;math&gt;\ker D_{\varphi^{-1}(x)} g \subseteq \mathbb{R}^n&lt;/math&gt;, where we tacitly identify &lt;math&gt;T_{\varphi^{-1}(x)}M&lt;/math&gt; with a subspace of &lt;math&gt;\mathbb R^n&lt;/math&gt; via the inclusion map on &lt;math&gt;M&lt;/math&gt;. Therefore,

: &lt;math&gt;0 = D_x f_\varphi = D_x (f \circ \varphi^{-1}) = D_{\varphi^{-1}(x)} f \circ D_x \varphi^{-1}&lt;/math&gt;

if and only if
:&lt;math&gt;\ker D_y g \subseteq \ker D_y f&lt;/math&gt;
writing &lt;math&gt;y&lt;/math&gt; for &lt;math&gt;\varphi^{-1}(x)&lt;/math&gt;. Again we can naturally interpret elements of &lt;math&gt;U&lt;/math&gt;, particularly &lt;math&gt;y&lt;/math&gt; itself, as points in &lt;math&gt;\mathbb R^n&lt;/math&gt; via the inclusion map on &lt;math&gt;M&lt;/math&gt;.

By a combination of the first and third [[isomorphism theorems]], the image of &lt;math&gt;D_yf&lt;/math&gt; must be isomorphic to a subspace of the image of &lt;math&gt;D_yg&lt;/math&gt;. It follows that there exists a linear map &lt;math&gt;\mathcal{L}\colon\mathbb{R}^p \to \mathbb{R}&lt;/math&gt; such that &lt;math&gt;\mathcal{L} \circ D_y g = D_y f&lt;/math&gt;. As a linear map, &lt;math&gt;\mathcal L&lt;/math&gt; must satisfy &lt;math&gt;\mathcal{L} (x) = \lambda x&lt;/math&gt; for a fixed &lt;math&gt;\lambda \in \mathbb{R}^p&lt;/math&gt;, so finding a critical point of &lt;math&gt;f_\varphi&lt;/math&gt; is equivalent to solving the system of equations

: &lt;math&gt;\lambda D_y g =  D_y f&lt;/math&gt;
: &lt;math&gt;g(y) = c&lt;/math&gt;

in the variables &lt;math&gt;y \in \mathbb{R}^{n}&lt;/math&gt; and &lt;math&gt;\lambda \in \mathbb{R}^p&lt;/math&gt;. This is in general a non-linear system of &lt;math&gt;n+p&lt;/math&gt; equations and &lt;math&gt;n+p&lt;/math&gt; unknowns.

Finding local maxima of a function &lt;math&gt;f: U \to \mathbb{R}&lt;/math&gt; is done by finding all points &lt;math&gt;x \in U&lt;/math&gt; such that &lt;math&gt;D_x f = 0&lt;/math&gt; then checking whether all the eigenvalues of the Hessian &lt;math&gt;H_x f&lt;/math&gt; are negative. (Note that the maxima may not exist even if &lt;math&gt;f&lt;/math&gt; is continuous because &lt;math&gt;U&lt;/math&gt; is open, and also note that the conditions checked here are sufficient but not necessary for optimality.) Setting &lt;math&gt;D_x f = 0&lt;/math&gt; is a non-linear problem and in general, arbitrarily difficult. After finding the critical points, checking the eigenvalues is a linear problem and thus easy.

==Interpretation of the Lagrange multipliers==
Often the Lagrange multipliers have an interpretation as some quantity of interest.  For example, if the Lagrangian expression is

: &lt;math&gt;
\begin{align}
&amp; \mathcal{L}(x_1, x_2, \ldots;\lambda_1, \lambda_2, \ldots) \\[4pt]
= {} &amp; f(x_1, x_2, \ldots) + \lambda_1(c_1-g_1(x_1, x_2, \ldots))+\lambda_2(c_2-g_2(x_1, x_2, \dots))+\cdots
\end{align}
&lt;/math&gt;

then

:&lt;math&gt;\frac{\partial \mathcal{L}}{\partial c_k} = \lambda_k.&lt;/math&gt;

So, {{math|''λ&lt;sub&gt;k&lt;/sub&gt;''}} is the rate of change of the quantity being optimized as a function of the constraint parameter.
As examples, in [[Lagrangian mechanics]] the equations of motion are derived by finding stationary points of the [[Action (physics)|action]], the time integral of the difference between kinetic and potential energy.  Thus, the force on a particle due to a scalar potential, {{math|''F'' {{=}} −∇''V''}}, can be interpreted as a Lagrange multiplier determining the change in action (transfer of potential to kinetic energy) following a variation in the particle's constrained trajectory.  
In control theory this is formulated instead as [[costate equations]].

Moreover, by the [[envelope theorem]] the optimal value of a Lagrange multiplier has an interpretation as the marginal effect of the corresponding constraint constant upon the optimal attainable value of the original objective function: if we denote values at the optimum with an asterisk, then it can be shown that

:&lt;math&gt;\frac{\text{d} f(x_1^*(c_1, c_2, \dots), x_2^*(c_1, c_2, \dots), \dots)}{\text{d} c_k} = \lambda_k^*.&lt;/math&gt;

For example, in economics the optimal profit to a player is calculated subject to a constrained space of actions, where a Lagrange multiplier is the change in the optimal value of the objective function (profit) due to the relaxation of a given constraint (e.g. through a change in income); in such a context {{math|''λ''*}} is the [[marginal cost]] of the constraint, and is referred to as the [[shadow price]].

==Sufficient conditions==
{{Main|Hessian matrix#Bordered Hessian}}

Sufficient conditions for a constrained local maximum or minimum can be stated in terms of a sequence of principal minors (determinants of upper-left-justified sub-matrices) of the bordered [[Hessian matrix]] of second derivatives of the Lagrangian expression.&lt;ref&gt;{{harvnb|Chiang|1984|p=386}}&lt;/ref&gt;

== Examples ==

=== Example 1===
[[Image:Lagrange very simple.svg|thumb|right|300px|Illustration of the constrained optimization problem]]

====Example 1a====

Suppose we wish to maximize &lt;math&gt;f(x,y)=x+y&lt;/math&gt; subject to the constraint &lt;math&gt;x^2+y^2=1&lt;/math&gt;. The [[Candidate solution|feasible set]] is the unit circle, and the [[level set]]s of {{mvar|f}} are diagonal lines (with slope −1), so we can see graphically that the maximum occurs at &lt;math&gt;\left(\tfrac{\sqrt{2}}{2},\tfrac{\sqrt{2}}{2}\right)&lt;/math&gt;, and that the minimum occurs at &lt;math&gt;\left(-\tfrac{\sqrt{2}}{2},-\tfrac{\sqrt{2}}{2}\right)&lt;/math&gt;.

For the method of Lagrange multipliers, the constraint is

:&lt;math&gt;g(x,y)=x^2+y^2-1,&lt;/math&gt;

hence

:&lt;math&gt;\begin{align} 
\mathcal{L}(x, y, \lambda) &amp;= f(x,y) + \lambda \cdot g(x,y) \\[4pt]
&amp;= x+y +  \lambda (x^2 + y^2 - 1).
\end{align}&lt;/math&gt;

Now we can calculate the gradient:

:&lt;math&gt;\begin{align}
\nabla_{x,y,\lambda} \mathcal{L}(x , y, \lambda) &amp;= \left( \frac{\partial \mathcal{L}}{\partial x}, \frac{\partial \mathcal{L}}{\partial y}, \frac{\partial \mathcal{L}}{\partial \lambda} \right ) \\[4pt]
&amp;= \left ( 1  + 2 \lambda x, 1 + 2 \lambda y, x^2 + y^2 -1 \right)
\end{align}&lt;/math&gt;

and therefore:

:&lt;math&gt;\nabla_{x,y,\lambda} \mathcal{L}(x , y, \lambda)=0 \quad \Leftrightarrow \quad \begin{cases} 1 + 2 \lambda x = 0 \\ 1 + 2 \lambda y = 0 \\ x^2 + y^2 -1  = 0 \end{cases}&lt;/math&gt;

Notice that the last equation is the original constraint.

The first two equations yield

:&lt;math&gt;x= y = - \frac{1}{2\lambda}, \qquad \lambda \neq 0.&lt;/math&gt;

By substituting into the last equation we have:

:&lt;math&gt;\frac{1}{4\lambda^2}+\frac{1}{4\lambda^2} - 1=0, &lt;/math&gt;

so

:&lt;math&gt;\lambda = \pm \frac{1}{\sqrt{2}},&lt;/math&gt;

which implies that the stationary points of &lt;math&gt;\mathcal{L}&lt;/math&gt; are

:&lt;math&gt;\left(\tfrac{\sqrt{2}}{2},\tfrac{\sqrt{2}}{2}, -\tfrac{1}{\sqrt{2}}\right), \qquad \left(-\tfrac{\sqrt{2}}{2}, -\tfrac{\sqrt{2}}{2}, \tfrac{1}{\sqrt{2}}\right).&lt;/math&gt;

Evaluating the objective function {{mvar|f}} at these points yields

:&lt;math&gt;f\left(\tfrac{\sqrt{2}}{2},\tfrac{\sqrt{2}}{2}\right)=\sqrt{2}, \qquad  f\left(-\tfrac{\sqrt{2}}{2}, -\tfrac{\sqrt{2}}{2}\right)=-\sqrt{2}.&lt;/math&gt;

Thus the constrained maximum is &lt;math&gt;\sqrt{2}&lt;/math&gt; and the constrained minimum is &lt;math&gt;-\sqrt{2}&lt;/math&gt;.

====Example 1b====

Now we modify the objective function of Example 1a so that we minimize &lt;math&gt;f(x,y)=(x+y)^2&lt;/math&gt; instead of &lt;math&gt;f(x,y)=x+y,&lt;/math&gt; again along the circle &lt;math&gt;g(x,y)=x^2+y^2-1=0&lt;/math&gt;.  Now the level sets of ''f'' are still lines of slope −1, and the points on the circle tangent to these level sets are again &lt;math&gt;(\sqrt{2}/2,\sqrt{2}/2)&lt;/math&gt; and &lt;math&gt;(-\sqrt{2}/2,-\sqrt{2}/2)&lt;/math&gt;. These tangency points are maxima of&amp;nbsp;''f''.

On the other hand, the minima occur on the level set for ''f''&amp;nbsp;=&amp;nbsp;0 (since by its construction ''f'' cannot take negative values), at &lt;math&gt;(\sqrt{2}/2,-\sqrt{2}/2)&lt;/math&gt; and &lt;math&gt; (-\sqrt{2}/2, \sqrt{2}/2)&lt;/math&gt;, where the level curves of ''f'' are not tangent to the constraint. The condition that &lt;math&gt;\nabla f=\lambda\nabla g&lt;/math&gt; correctly identifies all four points as extrema; the minima are characterized in particular by &lt;math&gt;\lambda =0.&lt;/math&gt;

=== Example 2 ===
[[Image:Lagrange simple.svg|thumb|right|300px| Illustration of the constrained optimization problem]]

In this example we will deal with some more strenuous calculations, but it is still a single constraint problem.

Suppose we want to find the maximum values of

:&lt;math&gt; f(x, y) = x^2 y&lt;/math&gt;

with the condition that the {{mvar|x}} and {{mvar|y}} coordinates lie on the circle around the origin with radius {{radic|3}}, that is, subject to the constraint

:&lt;math&gt; g(x,y) = x^2 + y^2 - 3 = 0.&lt;/math&gt;

As there is just a single constraint, we will use only one multiplier, say {{mvar|λ}}.

The constraint {{math|''g''(''x'', ''y'')}} is identically zero on the circle of radius {{radic|3}}. See that any multiple of {{math|''g''(''x'', ''y'')}} may be added to {{math|''f''(''x'',&amp;nbsp;''y'')}} leaving {{math|''f''(''x'',&amp;nbsp;''y'')}} unchanged in the region of interest (on the circle where our original constraint is satisfied).

Apply the ordinary Langrange multiplier method. Let:

:&lt;math&gt;\begin{align}
\mathcal{L}(x, y, \lambda) &amp;= f(x,y) + \lambda \cdot g(x, y) \\
&amp;= x^2y +  \lambda (x^2 + y^2 - 3)
\end{align}&lt;/math&gt;

Now we can calculate the gradient:

:&lt;math&gt;\begin{align}
\nabla_{x,y,\lambda} \mathcal{L}(x , y, \lambda) &amp;= \left ( \frac{\partial \mathcal{L}}{\partial x}, \frac{\partial \mathcal{L}}{\partial y}, \frac{\partial \mathcal{L}}{\partial \lambda} \right ) \\
&amp;= \left ( 2 x y + 2 \lambda x, x^2 + 2 \lambda y, x^2 + y^2 -3 \right )
\end{align}&lt;/math&gt;

And therefore:

:&lt;math&gt;\nabla_{x,y,\lambda} \mathcal{L}(x , y, \lambda)=0 \quad \Leftrightarrow \quad \begin{cases} 2 x y + 2 \lambda x = 0 \\ x^2 + 2 \lambda y = 0 \\ x^2 + y^2 - 3 = 0 \end{cases} \quad \Leftrightarrow \quad \begin{cases} x (y + \lambda) = 0 &amp; (i) \\ x^2 = -2 \lambda y &amp; (ii) \\ x^2 + y^2 = 3 &amp; (iii) \end{cases} &lt;/math&gt;

Notice that (iii) is just the original constraint. (i) implies {{math|''x'' {{=}} 0}} ''or'' {{math|''λ'' {{=}} −''y''}}. If {{math|''x'' {{=}} 0}} then &lt;math&gt;y = \pm \sqrt{3}&lt;/math&gt; by (iii) and consequently  {{math|''λ'' {{=}} 0}} from (ii). If {{math|''λ'' {{=}} −''y''}}, substituting in (ii) we get {{math|''x''&lt;sup&gt;2&lt;/sup&gt; {{=}} 2''y''&lt;sup&gt;2&lt;/sup&gt;}}. Substituting this in (iii) and solving for {{mvar|y}} gives {{math|''y'' {{=}} ±1}}. Thus there are six critical points of &lt;math&gt;\mathcal{L}&lt;/math&gt;:

:&lt;math&gt; (\sqrt{2},1,-1); \quad (-\sqrt{2},1,-1); \quad (\sqrt{2},-1,1); \quad (-\sqrt{2},-1,1); \quad (0,\sqrt{3}, 0); \quad (0,-\sqrt{3}, 0). &lt;/math&gt;

Evaluating the objective at these points, we find that

:&lt;math&gt; f(\pm\sqrt{2},1) = 2; \quad f(\pm\sqrt{2},-1) = -2; \quad f(0,\pm \sqrt{3})=0. &lt;/math&gt;

Therefore, the  objective function attains the [[global maximum]] (subject to the constraints) at &lt;math&gt;(\pm\sqrt{2},1)&lt;/math&gt; and the [[global minimum]] at &lt;math&gt;(\pm\sqrt{2},-1).&lt;/math&gt; The point &lt;math&gt;(0,\sqrt{3})&lt;/math&gt; is a [[local minimum]] of ''f'' and &lt;math&gt;(0,-\sqrt{3})&lt;/math&gt; is a [[local maximum]] of ''f'', as may be determined by consideration of the [[Hessian (mathematics)#Bordered Hessian|Hessian matrix]] of &lt;math&gt;\mathcal{L}(x,y,0)&lt;/math&gt;.

Note that while &lt;math&gt;(\sqrt{2}, 1, -1)&lt;/math&gt; is a critical point of &lt;math&gt;\mathcal{L}&lt;/math&gt;, it is not a local extremum of &lt;math&gt;\mathcal{L}.&lt;/math&gt; We have

:&lt;math&gt;\mathcal{L} \left (\sqrt{2} + \varepsilon, 1, -1 + \delta \right ) = 2 + \delta \left( \varepsilon^2 + \left (2\sqrt{2} \right)\varepsilon \right ).&lt;/math&gt;

Given any neighborhood of &lt;math&gt;(\sqrt{2}, 1, -1)&lt;/math&gt;, we can choose a small positive &lt;math&gt;\varepsilon&lt;/math&gt; and a small &lt;math&gt;\delta&lt;/math&gt; of either sign to get &lt;math&gt;\mathcal{L}&lt;/math&gt; values both greater and less than &lt;math&gt;2&lt;/math&gt;. This can also be seen from the fact that the Hessian matrix of &lt;math&gt;\mathcal{L}&lt;/math&gt; evaluated at this point (or indeed at any of the critical points) is an [[indefinite matrix]]. Each of the critical points of &lt;math&gt;\mathcal{L}&lt;/math&gt; is a [[saddle point]] of &lt;math&gt;\mathcal{L}.&lt;/math&gt;

=== Example 3: [[Entropy]] ===
Suppose we wish to find the [[Probability distribution#Discrete probability distribution|discrete probability distribution]] on the points &lt;math&gt;\{p_1, p_2, \ldots, p_n\}&lt;/math&gt; with maximal [[information entropy]]. This is the same as saying that we wish to find the [[Principle of maximum entropy|least structured]] probability distribution on the points &lt;math&gt;\{p_1, p_2, \cdots, p_n\}&lt;/math&gt;. In other words, we wish to maximize the [[Shannon entropy]] equation:

:&lt;math&gt;f(p_1,p_2,\ldots,p_n) = -\sum_{j=1}^n p_j\log_2 p_j.&lt;/math&gt;

For this to be a probability distribution the sum of the probabilities &lt;math&gt; p_i &lt;/math&gt; at each point &lt;math&gt;x_i&lt;/math&gt; must equal 1, so our constraint is:

:&lt;math&gt;g(p_1,p_2,\ldots,p_n)=\sum_{j=1}^n p_j = 1.&lt;/math&gt;

We use Lagrange multipliers to find the point of maximum entropy, &lt;math&gt;\vec{p}^{\,*}&lt;/math&gt;, across all discrete probability distributions &lt;math&gt;\vec{p}&lt;/math&gt; on &lt;math&gt;\{x_1,x_2, \ldots, x_n\}&lt;/math&gt;. We require that:

:&lt;math&gt;\left.\frac{\partial}{\partial \vec{p}}(f+\lambda (g-1))\right|_{\vec{p}=\vec{p}^{\,*}}=0,&lt;/math&gt;

which gives a system of {{mvar|n}} equations, &lt;math&gt; k = 1,\ldots,n&lt;/math&gt;, such that:

:&lt;math&gt;\left.\frac{\partial}{\partial p_k}\left\{-\left (\sum_{j=1}^n p_j \log_2 p_j \right ) + \lambda \left(\sum_{j=1}^n p_j - 1\right) \right\}\right|_{p_k=p^*_k} = 0.&lt;/math&gt;

Carrying out the differentiation of these {{mvar|n}} equations, we get

:&lt;math&gt;-\left(\frac{1}{\ln 2}+\log_2 p^*_k \right)  + \lambda = 0.&lt;/math&gt;

This shows that all &lt;math&gt;p^*_k&lt;/math&gt; are equal (because they depend on {{mvar|λ}} only). By using the constraint

:&lt;math&gt;\sum_j p_j =1,&lt;/math&gt;

we find

:&lt;math&gt;p^*_k = \frac{1}{n}.&lt;/math&gt;

Hence, the uniform distribution is the distribution with the greatest entropy, among distributions on {{mvar|n}} points.

=== Example 4: Numerical optimization ===
[[Image:lagnum1.png|thumb|right|300px|Lagrange multipliers cause the critical points to occur at saddle points.]]

[[Image:lagnum2.png|thumb|right|300px|The magnitude of the gradient can be used to force the critical points to occur at local minima.]]

The critical points of Lagrangians occur at [[saddle point]]s, rather than at local maxima (or minima).&lt;ref name="Heath2005"&gt;{{harvnb|Heath|2005|p=[{{google books |id=gwBrMAEACAAJ |page=203 |plainurl=yes}} 203]}}&lt;/ref&gt; Unfortunately, many numerical optimization techniques, such as [[hill climbing]], [[gradient descent]], some of the [[quasi-Newton method]]s, among others, are designed to find local maxima (or minima) and not saddle points. For this reason, one must either modify the formulation to ensure that it's a minimization problem (for example, by extremizing the square of the [[gradient]] of the Lagrangian as below), or else use an optimization technique that finds [[stationary points]] (such as [[Newton's method in optimization|Newton's method]] without an extremum seeking [[line search]]) and not necessarily extrema.

As a simple example, consider the problem of finding the value of {{mvar|x}} that minimizes &lt;math&gt;f(x)=x^2&lt;/math&gt;, constrained such that &lt;math&gt;x^2=1&lt;/math&gt;. (This problem is somewhat pathological because there are only two values that satisfy this constraint, but it is useful for illustration purposes because the corresponding unconstrained function can be visualized in three dimensions.)

Using Lagrange multipliers, this problem can be converted into an unconstrained optimization problem:

:&lt;math&gt;\mathcal{L}(x,\lambda)=x^2+\lambda(x^2-1).&lt;/math&gt;

The two critical points occur at saddle points where {{math|''x'' {{=}} 1}} and {{math|''x'' {{=}} −1}}.

In order to solve this problem with a numerical optimization technique, we must first transform this problem such that the critical points occur at local minima. This is done by computing the magnitude of the gradient of the unconstrained optimization problem.

First, we compute the partial derivative of the unconstrained problem with respect to each variable:

:&lt;math&gt;
\begin{align}
&amp; \frac{\partial \mathcal{L}}{\partial x}=2x+2x\lambda \\[5pt]
&amp; \frac{\partial \mathcal{L}}{\partial \lambda}=x^2-1.
\end{align}
&lt;/math&gt;

If the target function is not easily differentiable, the differential with respect to each variable can be approximated as

: &lt;math&gt;
\begin{align}
\frac{\partial \mathcal{L}}{\partial x}\approx\frac{\mathcal{L}(x+\varepsilon,\lambda)-\mathcal{L}(x,\lambda)}{\varepsilon}, \\[5pt]
\frac{\partial \mathcal{L}}{\partial \lambda}\approx\frac{\mathcal{L}(x,\lambda+\varepsilon)-\mathcal{L}(x,\lambda)}{\varepsilon},
\end{align}
&lt;/math&gt;

where &lt;math&gt;\varepsilon&lt;/math&gt; is a small value.

Next, we compute the magnitude of the gradient, which is the square root of the sum of the squares of the partial derivatives:

: &lt;math&gt;
\begin{align}
h(x,\lambda) &amp; = \sqrt{(2x+2x\lambda)^2+(x^2-1)^2} \\[4pt]
&amp; \approx\sqrt{\left(\frac{\mathcal{L}(x+\varepsilon,\lambda)-\mathcal{L}(x,\lambda)}{\varepsilon}\right)^2+\left(\frac{\mathcal{L}(x,\lambda+\varepsilon)-\mathcal{L}(x,\lambda)}{\varepsilon}\right)^2}.
\end{align}
&lt;/math&gt;

(Since magnitude is always non-negative, optimizing over the squared-magnitude is equivalent to optimizing over the magnitude. Thus, the &lt;nowiki&gt;''&lt;/nowiki&gt;square root" may be omitted from these equations with no expected difference in the results of optimization.)

The critical points of {{mvar|h}} occur at {{math|''x'' {{=}} 1}} and {{math|''x'' {{=}} −1}}, just as in &lt;math&gt;\mathcal{L}&lt;/math&gt;. Unlike the critical points in &lt;math&gt;\mathcal{L}&lt;/math&gt;, however, the critical points in {{mvar|h}} occur at local minima, so numerical optimization techniques can be used to find them.

==Applications==

===Control theory===
In [[optimal control]] theory, the Lagrange multipliers are interpreted as [[costate]] variables, and Lagrange multipliers are reformulated as the minimization of the [[Hamiltonian (control theory)|Hamiltonian]], in [[Pontryagin's minimum principle]].

===Nonlinear programming===
The Lagrange multiplier method has several generalizations. In [[nonlinear programming]] there are several multiplier rules, ''e.g.'', the Carathéodory–John Multiplier Rule and the Convex Multiplier Rule, for inequality constraints.&lt;ref&gt;{{Cite journal |last=Pourciau |first=Bruce H. |date=1980 |title=Modern Multiplier Rules |url=http://www.maa.org/programs/maa-awards/writing-awards/modern-multiplier-rules |journal=The American Mathematical Monthly |volume=87 |issue=6 |pages=433–452 |doi=10.2307/2320250 |jstor=2320250}}&lt;/ref&gt;

==See also==
{{div col}}
* [[Adjustment of observations]]
* [[Duality (optimization)|Duality]]
* [[Gittins index]]
* [[Karush–Kuhn–Tucker conditions]]: generalization of the method of Lagrange multipliers.
* [[Lagrange multipliers on Banach spaces]]: another generalization of the method of Lagrange multipliers.
* [[Lagrangian relaxation]]
{{colend}}

== References ==
{{Reflist}}

===Sources===
* {{cite book  | last = Bertsekas  | first = Dimitri P.| authorlink = Dimitri P. Bertsekas | title = Nonlinear Programming| edition=  Second  | publisher = Athena Scientific | year = 1999  | location = Cambridge, MA.  | isbn = 1-886529-00-0 |ref=harv}}
* {{cite book|authorlink=Alpha Chiang|last=Chiang|first= Alpha C.|title=Fundamental Methods of Mathematical Economics|publisher= McGraw-Hill|edition=  third |date= 1984|isbn=9757860069}}
* {{cite book|first=Michael T.|last= Heath|authorlink=Michael Heath (computer scientist)|title=Scientific Computing: An Introductory Survey|url=https://books.google.com/books?id=gwBrMAEACAAJ|pages=203|year=2005|publisher=McGraw-Hill|isbn=978-0-07-124489-3|ref=harv}}
* {{cite book|last1=Hiriart-Urruty|first1=Jean-Baptiste|last2=Lemaréchal|first2=Claude|chapter=XII&amp;nbsp;Abstract duality for practitioners|title=Convex analysis and minimization algorithms, Volume&amp;nbsp;II: Advanced theory and bundle methods|series=Grundlehren der Mathematischen Wissenschaften [Fundamental Principles of Mathematical Sciences]| volume=306 |publisher=Springer-Verlag |location=Berlin|year=1993| isbn=3-540-56852-2|mr=1295240|authorlink2=Claude Lemaréchal|ref=harv}}
* {{cite book|last1=Lafontaine|first1=Jacques|title=An Introduction to Differential Manifolds|publisher=Springer|isbn=9783319207353|page=70|url={{google books|id=KNhJCgAAQBAJ|plainurl=yes}}|language=en|ref=harv}}
* {{cite book|last=Lasdon|first=Leon&amp;nbsp;S.|title=Optimization theory for large systems|publisher=The Macmillan Company|series=Macmillan series in operations research|location=New York|year=1970|mr=337317|ref=harv}}
** {{cite book|last=Lasdon|first=Leon&amp;nbsp;S.|title=Optimization theory for large systems|publisher=Dover Publications, Inc.|location=Mineola, New York|year=2002|edition= reprint of the 1970 Macmillan|mr=1888251}}

==External links==
{{wikibooks|Calculus optimization methods|Lagrange multipliers}}
Exposition
*[http://www.slimy.com/~steuard/teaching/tutorials/Lagrange.html Conceptual introduction] (plus a brief discussion of Lagrange multipliers in the [[calculus of variations]] as used in physics)
*[http://ece.k-state.edu/people/faculty/carpenter/documents/lagrange.pdf Lagrange Multipliers for Quadratic Forms With Linear Constraints] by Kenneth H. Carpenter
For additional text and interactive applets
*[http://www.umiacs.umd.edu/~resnik/ling848_fa2004/lagrange.html Simple explanation with an example of governments using taxes as Lagrange multipliers]
*[http://nlp.cs.berkeley.edu/tutorials/lagrange-multipliers.pdf Lagrange Multipliers without Permanent Scarring] Explanation with focus on the intuition by Dan Klein
*[http://demonstrations.wolfram.com/GeometricRepresentationOfMethodOfLagrangeMultipliers Geometric Representation of Method of Lagrange Multipliers] Provides compelling insight in 2 dimensions that at a minimizing point, the direction of steepest descent must be perpendicular to the tangent of the constraint curve at that point. [Needs InternetExplorer/Firefox/Safari] ''Mathematica'' demonstration by Shashi Sathyanarayana
*[http://ocw.mit.edu/ans7870/18/18.02/f07/tools/LagrangeMultipliersTwoVariables.html Applet]
*[http://midnighttutor.com/Lagrange_multiplier.html Video Lecture of Lagrange Multipliers]
*[http://ocw.mit.edu/courses/mathematics/18-02-multivariable-calculus-fall-2007/video-lectures/lecture-13-lagrange-multipliers/ MIT OpenCourseware Video Lecture on Lagrange Multipliers from Multivariable Calculus course]
*[http://www.athenasc.com/NLP_Slides.pdf Slides accompanying Bertsekas's nonlinear optimization text], with details on Lagrange multipliers (lectures 11 and 12)
*[http://www-mtl.mit.edu/Courses/6.050/2004/unit9/wyatt.apr.7.pdf Geometric idea behind Lagrange multipliers]

[[Category:Multivariable calculus]]
[[Category:Mathematical optimization]]
[[Category:Mathematical and quantitative methods (economics)]]</text>
      <sha1>lkk7ixoycc37jhzmz8s5p0yrs72nqjn</sha1>
    </revision>
  </page>
  <page>
    <title>Law of the iterated logarithm</title>
    <ns>0</ns>
    <id>496558</id>
    <revision>
      <id>832890411</id>
      <parentid>818091687</parentid>
      <timestamp>2018-03-28T15:02:05Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Removed invisible unicode characters + other fixes ([[User:Yobot/55|Task 55]]), replaced: →   (3) using [[Project:AWB|AWB]] (12151)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6861">[[File:Law of large numbers.gif|thumb|Plot of &lt;math&gt;S_n/n&lt;/math&gt; (red), its standard deviation &lt;math&gt;1/\sqrt{n}&lt;/math&gt; (blue) and its bound &lt;math&gt;\sqrt{2\log\log n/n}&lt;/math&gt; given by LIL (green). Notice the way it randomly switches from the upper bound to the lower bound. Both axes are non-linearly transformed (as explained in figure summary) to make this effect more visible.]]

In [[probability theory]], the '''law of the iterated logarithm''' describes the magnitude of the fluctuations of a [[random walk]]. The original statement of the law of the iterated logarithm is due to [[Aleksandr Khinchin|A. Y. Khinchin]] (1924).&lt;ref&gt;[[Aleksandr Khinchin|A. Khinchine]]. "Über einen Satz der Wahrscheinlichkeitsrechnung", ''[[Fundamenta Mathematicae]]'' 6 (1924): pp. 9–20 ''(The author's name is shown here in an alternate transliteration.)''&lt;/ref&gt; Another statement was given by [[Andrey Kolmogorov|A. N. Kolmogorov]] in 1929.&lt;ref&gt;[[Andrey Kolmogorov|A. Kolmogoroff]]. [http://www-gdz.sub.uni-goettingen.de/cgi-bin/digbib.cgi?PPN235181684_0101 "Über das Gesetz des iterierten Logarithmus"]. ''Mathematische Annalen'', 101: 126–135, 1929. ''(At the [http://gdz.sub.uni-goettingen.de/en/index.html Göttinger DigitalisierungsZentrum web site])''&lt;/ref&gt;

==Statement==
Let {''Y''&lt;sub&gt;''n''&lt;/sub&gt;} be independent, identically distributed [[random variables]] with means zero and unit variances. Let ''S''&lt;sub&gt;''n''&lt;/sub&gt; = ''Y''&lt;sub&gt;1&lt;/sub&gt; + … + ''Y''&lt;sub&gt;''n''&lt;/sub&gt;. Then
: &lt;math&gt;
    \limsup_{n \to \infty} \frac{S_n}{\sqrt{2n \log\log n}} = 1, \quad \text{a. s.},
  &lt;/math&gt;
where “log” is the [[natural logarithm]], “lim sup” denotes the [[limit superior]], and “a. s.” stands for “[[almost surely]]”.&lt;ref&gt;[[Leo Breiman]]. ''Probability''. Original edition published by Addison-Wesley, 1968; reprinted by Society for Industrial and Applied Mathematics, 1992. ''(See Sections 3.9, 12.9, and 12.10; Theorem 3.52 specifically.)''&lt;/ref&gt;&lt;ref&gt;Varadhan, S. R. S. ''Stochastic processes''. Courant Lecture Notes in Mathematics, 16. Courant Institute of Mathematical Sciences, New York; American Mathematical Society, Providence, RI, 2007.&lt;/ref&gt;

==Discussion==
The law of iterated logarithms operates “in between” the [[law of large numbers]] and the [[central limit theorem]]. There are two versions of the law of large numbers — [[weak law of large numbers|the weak]] and [[strong law of large numbers|the strong]] — and they both state that the sums ''S''&lt;sub&gt;''n''&lt;/sub&gt;, scaled by ''n''&lt;sup&gt;−1&lt;/sup&gt;, converge to zero, respectively [[convergence of random variables#Convergence in probability|in probability]] and [[convergence of random variables#Almost sure convergence|almost surely]]:
: &lt;math&gt;
    \frac{S_n}{n} \ \xrightarrow{p}\ 0, \qquad
    \frac{S_n}{n} \ \xrightarrow{a.s.} 0, \qquad \text{as}\ \ n\to\infty.
  &lt;/math&gt;

On the other hand, the central limit theorem states that the sums ''S''&lt;sub&gt;''n''&lt;/sub&gt; scaled by the factor ''n''&lt;sup&gt;−½&lt;/sup&gt; converge in distribution to a standard normal distribution. By [[Kolmogorov's zero–one law]], for any fixed ''M'', the probability that the event
&lt;math&gt; \limsup_n \frac{S_n}{\sqrt{n}} \geq M &lt;/math&gt;
occurs is 0 or 1.
Then

: &lt;math&gt; \Pr\left( \limsup_n \frac{S_n}{\sqrt{n}} \geq M \right) \geqslant \limsup_n \Pr\left( \frac{S_n}{\sqrt{n}} \geq M \right) = \Pr\left( \mathcal{N}(0, 1) \geq M \right) &gt; 0&lt;/math&gt;

so

:&lt;math&gt;\limsup_n \frac{S_n}{\sqrt{n}}=\infty \qquad \text{with probability 1.}&lt;/math&gt;

An identical argument shows that

:&lt;math&gt; \liminf_n \frac{S_n}{\sqrt{n}}=-\infty \qquad \text{with probability 1.}&lt;/math&gt;

This implies that these quantities cannot converge almost surely. In fact, they cannot even converge in probability, which follows from the equality

:&lt;math&gt;\frac{S_{2n}}{\sqrt{2n}}-\frac{S_n}{\sqrt{n}} = \frac1{\sqrt2}\frac{S_{2n}-S_n}{\sqrt{n}} - \left (1-\frac1\sqrt2 \right )\frac{S_n}{\sqrt{n}}&lt;/math&gt;

and the fact that the random variables

:&lt;math&gt;\frac{S_n}{\sqrt{n}}\quad \text{and} \quad \frac{S_{2n}-S_n}{\sqrt{n}}&lt;/math&gt;

are independent and both converge in distribution to &lt;math&gt;\mathcal{N}(0, 1).&lt;/math&gt;

The ''law of the iterated logarithm'' provides the scaling factor where the two limits become different:
: &lt;math&gt;
    \frac{S_n}{\sqrt{2n\log\log n}} \ \xrightarrow{p}\ 0, \qquad
    \frac{S_n}{\sqrt{2n\log\log n}} \ \stackrel{a.s.}{\nrightarrow}\ 0, \qquad \text{as}\ \ n\to\infty.
  &lt;/math&gt;

Thus, although the quantity &lt;math&gt;\left|S_n/\sqrt{2n\log\log n}\right|&lt;/math&gt; is less than any predefined ''ε''&amp;nbsp;&gt; 0 with probability approaching one, the quantity will nevertheless be greater than ''ε'' infinitely often; in fact, the quantity will be visiting the neighborhoods of any point in the interval (-1,1) almost surely.
[[File:LimitTheoremsExhibition.png|thumb|Exhibition of Limit Theorems and their interrelationship]]

==Generalizations and variants==

The law of the iterated logarithm (LIL) for a sum of independent and identically distributed (i.i.d.) random variables with zero mean and bounded increment dates back to [[Khinchin]] and [[Kolmogorov]] in the 1920s.

Since then, there has been a tremendous amount of work on the LIL for various kinds of
dependent structures and for stochastic processes.  Following is a small sample of notable developments.

Hartman–Wintner (1940) generalized LIL to random walks with increments with zero mean and finite variance.

Strassen (1964) studied LIL from the point of view of invariance principles.

Stout (1970) generalized the LIL to stationary ergodic martingales.

De Acosta (1983) gave a simple proof of Hartman–Wintner version of LIL.

Wittmann (1985) generalized Hartman–Wintner version of LIL to random walks satisfying milder conditions.

Vovk (1987) derived a version of LIL valid for a single chaotic sequence (Kolmogorov random sequence). This is notable, as it is outside the realm of classical probability theory.

[[Yongge Wang]] has shown that the law of the iterated logarithm holds for polynomial time pseudorandom sequences also.&lt;ref&gt;Y. Wang: "[http://webpages.uncc.edu/yonwang/papers/CCC96.pdf The law of the iterated logarithm for ''p''-random sequences]". In: Proc. 11th IEEE Conference on Computational Complexity (CCC), pages 180–189. IEEE Computer Society Press, 1996.&lt;/ref&gt;&lt;ref&gt;Y. Wang: [http://webpages.uncc.edu/yonwang/papers/thesis.pdf ''Randomness and Complexity'']. PhD thesis, 1996.&lt;/ref&gt; The Java-based software [http://webpages.uncc.edu/yonwang/liltest/  testing tool] tests whether a pseudorandom generator outputs sequences that satisfy the LIL.

==See also==
* [[Central limit theorem]]
* [[Iterated logarithm]]
* [[Law of large numbers]]
* [[Wiener process|Brownian motion]]

==Notes==
{{reflist}}

[[Category:Asymptotic theory (statistics)]]
[[Category:Statistical theorems]]
[[Category:Stochastic processes]]</text>
      <sha1>1shs36pwshkxyckussmmnxhvk41wxyr</sha1>
    </revision>
  </page>
  <page>
    <title>Learning rule</title>
    <ns>0</ns>
    <id>35699507</id>
    <revision>
      <id>812148952</id>
      <parentid>808057653</parentid>
      <timestamp>2017-11-26T07:10:32Z</timestamp>
      <contributor>
        <username>Eumolpo</username>
        <id>7953109</id>
      </contributor>
      <comment>orthographic</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2179">{{unclear|date=May 2012}}{{sources|date=May 2012}}
'''Learning rule''' or '''Learning process''' is a method or a mathematical logic which improves the [[artificial neural network]]'s performance and usually this rule is applied repeatedly over the network. It is done by updating the [[Backpropagation#Phase_2:_Weight_update|weights and bias]] levels of a network when a network is simulated in a specific data environment.&lt;ref name="Simon Haykin"&gt;{{cite book|title=Neural Networks: A comprehensive foundation|publisher=Prentice Hall|isbn=978-8178083001|pages=50-104|url=https://books.google.com.pk/books?ei=oY2hT8CYE-vT4QSjvemuCQ&amp;id=bX4pAQAAMAAJ&amp;dq=Neural+Networks%3A+A+comprehensive+foundation&amp;q=learn+from+its+environment#search_anchor|author=Simon Haykin|edition=2nd|authorlink=Simon Haykin|accessdate=2 May 2012|chapter=Chapter 2: Learning Processes|date=16 July 1998}}&lt;/ref&gt; A learning rule may accept existing condition ( weights and bias ) of the network and will compare the expected result and actual result of the network to give new and improved values for weights and bias. &lt;ref name="S Russell, P Norvig"&gt;{{cite book|title=Artificial Intelligence: A Modern Approach|publisher=Prentice Hall|isbn=0-13-103805-2
|pages=693-859|url=http://aima.cs.berkeley.edu/|author=S Russell, P Norvig|edition=3rd|authorlink=Peter Norvig|accessdate=20 Nov 2013|chapter=Chapter 18: Learning from Examples}}&lt;/ref&gt; Depending on the complexity of actual model, which is being simulated, the learning rule of the network can be as simple as an [[XOR gate]] or [[Mean Squared Error]] or it can be the result of multiple differential equations. The learning rule is one of the factors which decides how fast or how accurate the artificial network can be developed. Depending upon the process to develop the network there are three main models of machine learning:

# [[Unsupervised learning]]
# [[Supervised learning]]
# [[Reinforcement learning]]

== See also ==
* [[Machine learning]]
* [[Decision tree learning]]
* [[Pattern recognition]]
* [[Bias-variance dilemma]]
* [[Bias of an estimator]]

== References ==
{{Reflist}}

[[Category:Artificial neural networks]]
[[Category:Learning]]</text>
      <sha1>bwlezqb7wih1qjhe6nxyv7zf9hrdh79</sha1>
    </revision>
  </page>
  <page>
    <title>Linear complementarity problem</title>
    <ns>0</ns>
    <id>1470767</id>
    <revision>
      <id>817322223</id>
      <parentid>816791835</parentid>
      <timestamp>2017-12-27T16:58:23Z</timestamp>
      <contributor>
        <ip>82.50.82.201</ip>
      </contributor>
      <comment>rephrased for clarity</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14524">In mathematical [[optimization (mathematics)|optimization theory]], the '''linear complementarity problem (LCP)''' arises frequently in [[computational mechanics]] and encompasses the well-known [[quadratic programming]] as a special case.  It was proposed by Cottle and [[George Dantzig|Dantzig]] {{nowrap|in&amp;nbsp;1968.&lt;ref name="Murty88"/&gt;&lt;ref name="CPS92"/&gt;&lt;ref&gt;R. W. Cottle and [[G. B. Dantzig]]. Complementary pivot theory of mathematical programming. ''Linear Algebra and its Applications'', 1:103-125, 1968.&lt;/ref&gt;}}

== Formulation ==
Given a real matrix ''M'' and vector ''q'', the linear complementarity problem LCP(''M'', ''q'') seeks vectors ''z'' and ''w'' which satisfy the following constraints:

* &lt;math&gt;w, z \geqslant 0,&lt;/math&gt; (that is, each component of these two vectors is non-negative)
* &lt;math&gt;z^Tw = 0&lt;/math&gt; or equivalently &lt;math&gt;\sum\nolimits_i w_i z_i = 0.&lt;/math&gt; This is the [[Complementarity theory|complementarity]] condition, since it implies that, for all &lt;math&gt;i&lt;/math&gt;, at most one of &lt;math&gt;w_i&lt;/math&gt; and &lt;math&gt;z_i&lt;/math&gt; can be positive.
* &lt;math&gt;w = Mz + q&lt;/math&gt;

A sufficient condition for existence and uniqueness of a solution to this problem is that ''M'' be [[Symmetric matrix|symmetric]] [[Positive-definite matrix|positive-definite]]. If ''M'' is such that {{math|LCP(''M'', ''q'')}} have a solution for every ''q'', then ''M'' is a [[Q-matrix]]. If ''M'' is such that {{math|LCP(''M'', ''q'')}} have a unique solution for every ''q'', then ''M'' is a [[P-matrix]]. Both of these characterizations are sufficient and necessary.&lt;ref&gt;{{cite journal|last1=Murty|first1=Katta G.|title=On the number of solutions to the complementarity problem and spanning properties of complementary cones|journal=Linear Algebra and its Applications|date=January 1972|volume=5|issue=1|pages=65–108|doi=10.1016/0024-3795(72)90019-5}}&lt;/ref&gt;

The vector ''w'' is a [[slack variable]],&lt;ref&gt;{{citation|title=Convex Optimization of Power Systems|first=Joshua Adam|last=Taylor|publisher=Cambridge University Press|year=2015| isbn=9781107076877|page=172|url=https://books.google.com/books?id=JBdoBgAAQBAJ&amp;pg=PA172}}.&lt;/ref&gt; and so is generally discarded after ''z'' is found. As such, the problem can also be formulated as:

* &lt;math&gt;Mz+q \geqslant 0&lt;/math&gt;
* &lt;math&gt;z \geqslant 0&lt;/math&gt;
* &lt;math&gt;z^{\mathrm{T}}(Mz+q) = 0&lt;/math&gt; (the complementarity condition)

==Convex quadratic-minimization: Minimum conditions==
Finding a solution to the linear complementarity problem is associated with minimizing the quadratic function

: &lt;math&gt;f(z) = z^T(Mz+q)&lt;/math&gt;

subject to the constraints

: &lt;math&gt;{Mz}+q \geqslant 0&lt;/math&gt;
: &lt;math&gt;z \geqslant 0&lt;/math&gt;

These constraints ensure that ''f'' is always non-negative. The minimum of ''f'' is 0 at ''z'' if and only if ''z'' solves the linear complementarity problem.

If ''M'' is [[Positive-definite matrix|positive definite]], any algorithm for solving (strictly) convex [[Quadratic programming|QPs]] can solve the LCP.  Specially designed basis-exchange pivoting algorithms, such as [[Lemke's algorithm]] and a variant of the [[simplex algorithm|simplex algorithm of Dantzig]] have been used for decades. Besides having polynomial time complexity, interior-point methods are also effective in practice.

Also, a quadratic-programming problem stated as minimize &lt;math&gt;f(x)=c^Tx+\tfrac{1}{2} x^T Qx&lt;/math&gt; subject to &lt;math&gt;Ax \geqslant b&lt;/math&gt; as well as &lt;math&gt;x \geqslant 0&lt;/math&gt; with ''Q'' symmetric

is the same as solving the LCP with

:&lt;math&gt;q = \begin{bmatrix} c \\ -b \end{bmatrix}, \qquad M = \begin{bmatrix} Q &amp; -A^T \\ A &amp; 0 \end{bmatrix}&lt;/math&gt;

This is because the [[Karush–Kuhn–Tucker]] conditions of the QP problem can be written as:

:&lt;math&gt;\begin{cases} 
v = Q x - A^T {\lambda} + c \\ 
s = A x - b \\ 
x, {\lambda}, v, s \geqslant 0 \\ 
x^{T} v+ {\lambda}^T s = 0
\end{cases}&lt;/math&gt;

with ''v'' the Lagrange multipliers on the non-negativity constraints, ''λ'' the &lt;!-- Lagrange  --&gt;multipliers on the inequality constraints, and ''s'' the slack variables for the inequality constraints. The fourth condition derives from the complementarity of each group of variables {{math|(''x'', ''s'')}} with its set of KKT vectors (optimal Lagrange multipliers) being {{math|(''v'', ''λ'')}}. In that case,

: &lt;math&gt;z = \begin{bmatrix} x \\ \lambda \end{bmatrix}, \qquad w = \begin{bmatrix} v \\ s \end{bmatrix}&lt;/math&gt;

If the non-negativity constraint on the ''x'' is relaxed, the dimensionality of the LCP problem can be reduced to the number of the inequalities, as long as ''Q'' is non-singular (which is guaranteed if it is [[Positive-definite matrix|positive definite]]). The multipliers ''v'' are no longer present, and the first KKT conditions can be rewritten as:

: &lt;math&gt;Q x = A^{T} {\lambda} - c&lt;/math&gt;

or:

: &lt;math&gt; x = Q^{-1}(A^{T} {\lambda} - c)&lt;/math&gt;

pre-multiplying the two sides by ''A'' and subtracting ''b'' we obtain:

: &lt;math&gt; A x - b = A Q^{-1}(A^{T} {\lambda} - c) -b \,&lt;/math&gt;

The left side, due to the second KKT condition, is ''s''. Substituting and reordering:

: &lt;math&gt; s = (A Q^{-1} A^{T}) {\lambda} + (- A Q^{-1} c - b )\,&lt;/math&gt;

Calling now

:&lt;math&gt;\begin{align}
M &amp;:= (A Q^{-1} A^{T}) \\
Q &amp;:=  (- A Q^{-1} c - b)
\end{align}&lt;/math&gt;

we have an LCP, due to the relation of complementarity between the slack variables ''s'' and their Lagrange multipliers ''λ''. Once we solve it, we may obtain the value of ''x'' from ''λ''  through the first KKT condition.

Finally, it is also possible to handle additional equality constraints:

: &lt;math&gt;A_{eq}x = b_{eq}&lt;/math&gt;

This introduces a vector of Lagrange multipliers ''μ'', with the same dimension as &lt;math&gt;b_{eq}&lt;/math&gt;.

It is easy to verify that the ''M'' and ''Q'' for the LCP system &lt;math&gt; s = M {\lambda} + Q&lt;/math&gt; are now expressed as:

:&lt;math&gt;\begin{align}
M &amp;:= \begin{bmatrix} A &amp; 0 \end{bmatrix}  \begin{bmatrix} Q &amp; A_{eq}^{T} \\ -A_{eq} &amp; 0 \end{bmatrix}^{-1}  \begin{bmatrix} A^T \\ 0 \end{bmatrix}  \\
Q &amp;:= - \begin{bmatrix} A &amp; 0 \end{bmatrix}  \begin{bmatrix} Q &amp; A_{eq}^{T} \\ -A_{eq} &amp; 0 \end{bmatrix}^{-1} \begin{bmatrix} c \\ b_{eq} \end{bmatrix} - b
\end{align}&lt;/math&gt;

From ''λ'' we can now recover the values of both ''x'' and the Lagrange multiplier of equalities ''μ'':

:&lt;math&gt;\begin{bmatrix} x \\ \mu \end{bmatrix} = \begin{bmatrix} Q &amp; A_{eq}^{T} \\ -A_{eq} &amp; 0 \end{bmatrix}^{-1} \begin{bmatrix} A^T \lambda - c \\ -b_{eq} \end{bmatrix}&lt;/math&gt;

In fact, most QP solvers work on the LCP formulation, including the [[interior point method]], principal / complementarity pivoting, and [[active set]] methods.&lt;ref name="Murty88"&gt;{{harvtxt|Murty|1988}}&lt;/ref&gt;&lt;ref name="CPS92"&gt;{{harvtxt|Cottle|Pang|Stone|1992}}&lt;/ref&gt; LCP problems can be solved also by the [[criss-cross algorithm]],&lt;ref&gt;{{harvtxt|Fukuda|Namiki|1994}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Fukuda|Terlaky|1997}}&lt;/ref&gt;&lt;ref name="HRT"&gt;{{cite journal|first1=D. |last1=den&amp;nbsp;Hertog |first2=C.| last2=Roos |first3=T. |last3=Terlaky|title=The linear complementarity problem, sufficient matrices, and the criss-cross method|journal=Linear Algebra and its Applications|volume=187|date=1 July 1993|pages=1–14|url=http://core.ac.uk/download/pdf/6714737.pdf|doi=10.1016/0024-3795(93)90124-7|format=pdf}}&lt;/ref&gt;&lt;ref name="CIsufficient"&gt;{{cite journal |first1=Zsolt |last1=Csizmadia |first2=Tibor |last2=Illés|title=New criss-cross type algorithms for linear complementarity problems with sufficient matrices|journal=Optimization Methods and Software| volume=21 |year=2006 |number=2 |pages=247–266|doi=10.1080/10556780500095009|url=http://www.cs.elte.hu/opres/orr/download/ORR03_1.pdf|format=pdf|&lt;!-- ref=harv --&gt;}}&lt;/ref&gt; conversely, for linear complementarity problems, the criss-cross algorithm terminates finitely only if the matrix is a sufficient matrix.&lt;ref name="HRT"/&gt;&lt;ref name="CIsufficient"/&gt; A [[sufficient&amp;nbsp;matrix]] is a generalization both of a [[positive-definite matrix]] and of a [[P-matrix]], whose [[principal&amp;nbsp;minor]]s are each positive.&lt;ref name="HRT"/&gt;&lt;ref name="CIsufficient"/&gt;&lt;ref&gt;{{cite journal| last1=Cottle | first1=R.&amp;nbsp;W. |authorlink1=Richard W. Cottle|last2=Pang|first2=J.-S.|last3=Venkateswaran|first3=V.|title=Sufficient matrices and the linear&amp;nbsp;complementarity problem |journal=Linear Algebra and its Applications|volume=114–115|date=March–April 1989|pages=231–249|doi=10.1016/0024-3795(89)90463-1 |url=http://www.sciencedirect.com/science/article/pii/0024379589904631 |mr=986877|ref=harv}}&lt;/ref&gt;
Such LCPs can be solved when they are formulated abstractly using [[oriented matroid|oriented-matroid]] theory.&lt;ref name="Todd" &gt;{{harvtxt|Todd|1985|}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Terlaky|Zhang|1993}}: {{cite journal|last1=Terlaky|first1=Tamás|&lt;!-- authorlink1=Tamás Terlaky --&gt;|last2=Zhang|first2=Shu&amp;nbsp;Zhong|title=Pivot rules for linear programming: A Survey on recent theoretical developments|series=Degeneracy in optimization problems|journal=Annals of Operations Research|volume=46–47|year=1993|issue=1|pages=203–233|doi=10.1007/BF02096264|mr=1260019|citeseerx=10.1.1.36.7658 |publisher=Springer Netherlands|issn=0254-5330|ref=harv}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Björner|first=Anders|last2=Las&amp;nbsp;Vergnas|author2-link=Michel Las Vergnas|first2=Michel|last3=Sturmfels|first3=Bernd|authorlink3=Bernd Sturmfels|last4=White|first4=Neil|last5=Ziegler|first5=Günter|authorlink5=Günter M. Ziegler|title=Oriented Matroids|chapter=10 Linear programming|publisher=Cambridge University Press|year=1999|isbn=978-0-521-77750-6|url=http://ebooks.cambridge.org/ebook.jsf?bid=CBO9780511586507|pages=417–479|doi=10.1017/CBO9780511586507|MR=1744046}}&lt;/ref&gt;

== See also ==
*[[Complementarity theory]]
*[[Physics engine]] Impulse/constraint type physics engines for games use this approach.
*[[Contact dynamics]] Contact dynamics with the nonsmooth approach.
*[[Bimatrix game]]s can be reduced to a LCP.

==Notes==
{{Reflist}}

== References ==

* {{cite book|last1=Cottle|first1=Richard W.|last2=Pang|first2=Jong-Shi|last3=Stone|first3=Richard E.|title=The linear complementarity problem | series=Computer Science and Scientific Computing|publisher=Academic Press, Inc.|location=Boston, MA|year=1992|pages=xxiv+762 pp.|isbn=0-12-192350-9|mr=1150683|ref=harv}}
*{{cite journal|last1=Cottle|first1=R.&amp;nbsp;W.|authorlink1=Richard W. Cottle|last2=Pang|first2=J.-S.|last3=Venkateswaran|first3=V.|title=Sufficient matrices and the linear&amp;nbsp;complementarity problem|journal=Linear Algebra and its Applications|volume=114–115|date=March–April 1989|pages=231–249|doi=10.1016/0024-3795(89)90463-1| url=http://www.sciencedirect.com/science/article/pii/0024379589904631|mr=986877|ref=harv}}
* {{cite journal|first1=Zsolt|last1=Csizmadia|first2=Tibor|last2=Illés|title=New criss-cross type algorithms for linear complementarity problems with sufficient matrices|journal=Optimization Methods and Software|volume=21|year=2006|number=2|pages=247–266|doi=10.1080/10556780500095009|
url=http://www.cs.elte.hu/opres/orr/download/ORR03_1.pdf|format=pdf |&lt;!-- ref=harv --&gt;}}
* {{cite journal|last1=Fukuda|first1=Komei|authorlink1=Komei Fukuda|last2=Namiki|first2=Makoto|title=On extremal behaviors of Murty's least index method|journal=Mathematical Programming|date=March 1994|pages=365–370|volume=64|issue=1|doi=10.1007/BF01582581|ref=harv|mr=1286455}}
* {{cite journal|first1=D. |last1=den&amp;nbsp;Hertog|first2=C.|last2=Roos|first3=T.|last3=Terlaky|title=The linear complementarity problem, sufficient matrices, and the criss-cross method| journal=Linear Algebra and its Applications|volume=187|date=1 July 1993|pages=1–14|url=http://core.ac.uk/download/pdf/6714737.pdf|doi=10.1016/0024-3795(93)90124-7|ref=harv|format=pdf}}
* {{cite book|last=Murty|first=K. G.|title=Linear complementarity, linear and nonlinear programming|series=Sigma Series in Applied Mathematics|volume=3|publisher=Heldermann Verlag|location=Berlin|year=1988|pages=xlviii+629 pp.|isbn=3-88538-403-5|url=http://ioe.engin.umich.edu/people/fac/books/murty/linear_complementarity_webbook/|mr=949214|id=[http://www-personal.umich.edu/~murty/ Updated and free PDF version at Katta G. Murty's website]|ref=harv|deadurl=yes|archiveurl=https://web.archive.org/web/20100401043940/http://ioe.engin.umich.edu/people/fac/books/murty/linear_complementarity_webbook/|archivedate=2010-04-01|df=}}
* {{cite journal|first1=Komei|last1=Fukuda|&lt;!-- authorlink1=Komei Fukuda --&gt;|first2=Tamás|last2=Terlaky|&lt;!-- authorlink2=Tamás Terlaky --&gt;|title=Criss-cross methods: A fresh view on pivot algorithms|journal=Mathematical Programming: Series&amp;nbsp;B|volume=79|issue=1—3| pages=369–395|series=Papers from the&amp;nbsp;16th International Symposium on Mathematical Programming held in Lausanne,&amp;nbsp;1997|editors=Thomas&amp;nbsp;M. Liebling and Dominique de&amp;nbsp;Werra|publisher=North-Holland Publishing&amp;nbsp;Co. | location=Amsterdam |year=1997|doi=10.1007/BF02614325|mr=1464775|ref=harv|id=[http://www.cas.mcmaster.ca/~terlaky/files/crisscross.ps Postscript preprint]}}
*{{cite journal|last=Todd|first=Michael&amp;nbsp;J.|authorlink=Michael J. Todd (mathematician)|title=Linear and quadratic programming in oriented matroids|journal=Journal of Combinatorial Theory|series=Series&amp;nbsp;B|volume=39|year=1985|issue=2|pages=105–133|mr=811116|doi=10.1016/0095-8956(85)90042-5|ref=harv}}
*{{cite web | url=http://www.utdallas.edu/~chandra/documents/6311/bimatrix.pdf | title=Bimatrix games | accessdate=18 December 2015 | author=R. Chandrasekaran | pages=5–7}}

==Further reading==
* R. W. Cottle and [[G. B. Dantzig]]. Complementary pivot theory of mathematical programming. ''Linear Algebra and its Applications'', 1:103-125, 1968.
* {{cite journal|last1=Terlaky|first1=Tamás|&lt;!-- authorlink1=Tamás Terlaky --&gt;|last2=Zhang|first2=Shu&amp;nbsp;Zhong|title=Pivot rules for linear programming: A Survey on recent theoretical developments|series=Degeneracy in optimization problems|journal=Annals of Operations Research|volume=46–47|year=1993|issue=1|pages=203–233|doi=10.1007/BF02096264|mr=1260019|citeseerx=10.1.1.36.7658 |publisher=Springer Netherlands|issn=0254-5330|ref=harv}}

== External links ==
* [https://web.archive.org/web/20041029022008/http://www.american.edu/econ/gaussres/optimize/quadprog.src LCPSolve] &amp;mdash; A simple procedure in GAUSS to solve a linear complementarity problem
* [[Siconos]]/Numerics open-source GPL  implementation in C of Lemke's algorithm and other methods to solve LCPs and MLCPs

{{Mathematical programming}}

[[Category:Linear algebra]]
[[Category:Mathematical optimization]]</text>
      <sha1>ik09rfccgnlry0h63jkpuvh4mm579ar</sha1>
    </revision>
  </page>
  <page>
    <title>Logic of graphs</title>
    <ns>0</ns>
    <id>47857242</id>
    <revision>
      <id>819370688</id>
      <parentid>785167342</parentid>
      <timestamp>2018-01-09T00:29:54Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Doklady Akad. → Doklady Akademii using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27918">In the mathematical fields of [[graph theory]] and [[finite model theory]], the '''logic of graphs''' deals with formal specifications of [[Graph property|graph properties]] using logical formulas. There are several variations in the types of logical operation that can be used in these formulas. The first order logic of graphs concerns formulas in which the variables and predicates concern individual vertices and edges of a graph, while monadic second order graph logic allows quantification over sets of vertices or edges.

A sentence &lt;math&gt;S&lt;/math&gt; may be true for some graphs, and false for others; a graph &lt;math&gt;G&lt;/math&gt; is said to ''model'' &lt;math&gt;S&lt;/math&gt;, written &lt;math&gt;G\models S&lt;/math&gt;, if &lt;math&gt;S&lt;/math&gt; is true of the vertices and adjacency relation of &lt;math&gt;G&lt;/math&gt;. The algorithmic problem of [[model checking]] concerns testing whether a given graph models a given sentence. The algorithmic problem of [[satisfiability]] concerns testing whether there exists a graph that models a given sentence.
Although both model checking and satisfiability are hard in general, several major algorithmic meta-theorems show that properties expressed in this way can be tested efficiently for important classes of graphs.

Other topics of research in the logic of graphs include investigations of the probability that a [[random graph]] has a property specified within a particular type of logic, and methods for [[data compression]] based on finding logical formulae that are modeled by a unique graph.

==First order==
In the [[first-order logic]] of graphs, a graph property is expressed as a quantified logical formula whose variables represent graph [[vertex (graph theory)|vertices]], with [[Predicate (mathematical logic)|predicates]] for equality and adjacency testing.

===Examples===
For instance, the condition that a graph does not have any [[isolated vertex|isolated vertices]] may be expressed by the sentence
:&lt;math&gt;\forall u\exists v(u\sim v)&lt;/math&gt;
where the &lt;math&gt;\sim&lt;/math&gt; symbol indicates the adjacency relation between two vertices. This sentence can be interpreted as meaning that for every vertex &lt;math&gt;u&lt;/math&gt; there is another vertex &lt;math&gt;v&lt;/math&gt; that is adjacent to &lt;math&gt;u&lt;/math&gt;.

The [[subgraph isomorphism problem]] for a fixed subgraph ''H'' asks whether ''H'' appears as a subgraph of a larger graph ''G''. It may be expressed by a sentence that states the existence of vertices (one for each vertex of ''H'') such that, for each edge of ''H'', the corresponding pair of vertices are adjacent. As a special case the [[clique problem]] (for a fixed clique size) may be expressed by a sentence that states the existence of a number of vertices equal to the clique size all of which are adjacent.

===Axioms===
For simple [[undirected graph]]s, the first order theory of graphs includes the [[axiom]]s
:&lt;math&gt;\forall u\bigl(\lnot(u\sim u)\bigr)&lt;/math&gt; (the graph cannot contain any [[Loop (graph theory)|loops]]), and
:&lt;math&gt;\forall u\forall v(u\sim v\Rightarrow v\sim u)&lt;/math&gt; (edges are undirected).{{sfnp|Goldberg|1993}}
Other types of graphs, such as [[directed graph]]s, may involve different axioms, and logical formulations of [[multigraph]] properties require having separate variables for vertices and edges.

===Zero-one law===
[[File:Rado graph.svg|thumb|upright=1.35|The [[Rado graph]], an infinite graph that models exactly the first-order sentences that are almost always true of finite graphs]]
{{harvtxt|Fagin|1976}} proved a [[zero–one law]] for first-order graph logic using the [[compactness theorem]]. According to Fagin's result, every first-order sentence is  either [[almost always]] true or almost always false for [[random graph]]s in the [[Erdős–Rényi model]]. That is, let {{mvar|S}} be a fixed first-order sentence, and choose a random {{mvar|n}}-vertex graph {{mvar|G&lt;sub&gt;n&lt;/sub&gt;}} uniformly at random among all graphs on a set of {{mvar|n}} labeled vertices. Then in the limit as {{mvar|n}} tends to infinity the probability that {{mvar|G&lt;sub&gt;n&lt;/sub&gt;}} models {{mvar|S}} will tend either to zero or to one:
:&lt;math&gt;\lim_{n\to\infty}\operatorname{Pr}[G_n\models S]\in\{0,1\}.&lt;/math&gt;
Moreover, there is a specific infinite graph, the [[Rado graph]] {{mvar|R}}, such that the sentences modeled by the Rado graph are exactly the ones for which the probability of being modeled by a random finite graph tends to one: 
:&lt;math&gt;R\models S \quad \Longleftrightarrow \quad \lim_{n\to\infty}\operatorname{Pr}[G_n\models S] = 1.&lt;/math&gt;
For random graphs in which each edge is included independently of the others with a fixed probability, the same result is true, with the same sentences having probabilities tending to zero or to one.

The [[Computational complexity theory|computational complexity]] of determining whether a given sentence has probability tending to zero or to one is high: the problem is [[PSPACE-complete]].{{sfnp|Grandjean|1983}}
If a first order graph property has probability tending to one on random graphs, then it is possible to list all the ''n''-vertex graphs that model the property, with [[polynomial delay]] (as a function of {{mvar|n}}) per graph.{{sfnp|Goldberg|1993}}

A similar analysis can be performed for non-uniform random graphs, where the probability of including an edge is a function of the number of vertices, and where the decision to include or exclude an edge is made independently with equal probability for all edges. However, for these graphs the situation is more complicated.
In this case, a first-order property may have one or more thresholds, such that when the edge [[inclusion probability]] is bounded away from the threshold then the probability of having the given property tends to zero or one. These thresholds can never be an irrational power of {{mvar|n}}, so random graphs where the edge inclusion probability is an irrational power obey a zero-one law analogous to the one for uniformly random graphs. A similar zero-one law holds for very sparse random graphs that have an edge inclusion probability of {{math|''n''&lt;sup&gt;&amp;minus;''c''&lt;/sup&gt;}} with {{math|''c''&amp;nbsp;&gt;&amp;nbsp;1}}, as long as {{mvar|c}} is not a [[superparticular ratio]].&lt;ref&gt;{{harvtxt|Shelah|Spencer|1988}}; {{harvtxt|Spencer|2001}}.&lt;/ref&gt; If {{mvar|c}} is superparticular, the probability of having a given property may tend to a limit that is not zero or one, but this limit can be calculated efficiently.{{sfnp|Lynch|1992}} There exist first-order sentences that have infinitely many thresholds.{{sfnp|Spencer|1990}}

===Parameterized complexity===
If a first-order sentence includes ''k'' distinct variables, then the property it describes can be tested in graphs of ''n'' vertices by examining all ''k''-tuples of vertices; however, this [[brute force search]] algorithm is not particularly efficient, taking time ''O''(''n''&lt;sup&gt;''k''&lt;/sup&gt;).
The problem of checking whether a graph models a given first-order sentence includes as special cases the [[subgraph isomorphism problem]] (in which the sentence describes the graphs that contain a fixed subgraph) and the [[clique problem]] (in which the sentence describes graphs that contain complete subgraphs of a fixed size).
The clique problem is hard for [[W(1)]], the first level of a hierarchy of hard problems from the point of view of [[parameterized complexity]]. Therefore, it is unlikely to have a fixed-parameter tractable algorithm, one whose running time takes the form ''O''(''f''(''k'')&amp;nbsp;''n''&lt;sup&gt;''c''&lt;/sup&gt;) for a function ''f'' and constant ''c'' that are independent of ''k'' and ''c''.{{sfnp|Downey|Fellows|1995}}
More strongly, if the [[exponential time hypothesis]] is true, then clique-finding and first-order model checking would necessarily take time proportional to a power of ''n'' whose exponent is proportional to ''k''.{{sfnp|Chen|Huang|Kanj|Xia|2006}}

On restricted classes of graphs, model checking of first-order sentences can be much more efficient. In particular, every graph property expressible as a first-order sentence can be tested in [[linear time]] for the graphs of [[bounded expansion]]. These are the graphs in which all [[shallow minor]]s are [[sparse graph]]s, with a ratio of edges to vertices bounded by a function of the depth of the minor. Even more generally, first-order model checking can be performed in near-linear time for nowhere-dense graphs, classes of graphs for which, at each possible depth, there is at least one forbidden shallow minor. Conversely, if model checking is fixed-parameter tractable for any hereditary family of graphs, that family must be nowhere-dense.&lt;ref&gt;{{harvtxt|Nešetřil|Ossona de Mendez|2012}}, 18.3 The Subgraph Isomorphism Problem and Boolean Queries, pp.&amp;nbsp;400–401; {{harvtxt|Dvořák|Kráľ|Thomas|2010}}; {{harvtxt|Grohe|Kreutzer|Siebertz|2014}}.&lt;/ref&gt;

===Data compression and graph isomorphism===
A first order sentence ''S'' in the logic of graphs is said to define a graph ''G'' if ''G'' is the only graph that models ''S''. Every graph may be defined by at least one sentence; for instance, one can define an ''n''-vertex graph ''G'' by a sentence with ''n''&amp;nbsp;+&amp;nbsp;1 variables, one for each vertex of the graph, and one more to state the condition that there is no vertex other than the ''n'' vertices of the graph. Additional clauses of the sentence can be used to ensure that no two vertex variables are equal, that each edge of ''G'' is present, and no edge exists between a pair of non-adjacent vertices of ''G''. However, for some graphs there exist significantly shorter formulas that define the graph.{{sfnp|Pikhurko|Spencer|Verbitsky|2006}}

Several different [[graph invariant]]s can be defined from the simplest sentences (with different measures of simplicity) that define a given graph. In particular the ''logical depth'' of a graph is defined to be the minimum level of nesting of quantifiers (the [[quantifier rank]]) in a sentence defining the graph.{{sfnp|Pikhurko|Verbitsky|2011}} The sentence outlined above nests the quantifiers for all of its variables, so it has logical depth ''n''&amp;nbsp;+&amp;nbsp;1. The ''logical width'' of a graph is the minimum number of variables in a sentence that defines it.{{sfnp|Pikhurko|Verbitsky|2011}} In the sentence outlined above, this number of variables is again ''n''&amp;nbsp;+&amp;nbsp;1. Both the logical depth and logical width can be bounded in terms of the [[treewidth]] of the given graph.{{sfnp|Verbitsky|2005}} The logical length, analogously, is defined as the length of the shortest formula describing the graph.{{sfnp|Pikhurko|Verbitsky|2011}} The sentence described above has length proportional to the square of the number of vertices, but it is possible to define any graph by a formula with length proportional to its number of edges.

All trees, and most graphs, can be described by first order sentences with only two variables, but extended by counting predicates. For graphs that can be described by sentences in this logic with a fixed constant number of variables, it is possible to find a [[graph canonization]] in polynomial time (with the exponent of the polynomial equal to the number of variables). By comparing canonizations, it is possible to solve the [[graph isomorphism problem]] for these graphs in polynomial time.{{sfnp|Immerman|Lander|1990}}

===Satisfiability===
It is [[Undecidable problem|undecidable]] whether a given first-order sentence can be realized by a finite undirected graph.&lt;ref&gt;{{harvtxt|Parys|2014}} writes that this undecidability result is well known, and attributes it to {{harvtxt|Trahtenbrot|1950}} on the undecidability of first order satisfiability for more general classes of finite structures.&lt;/ref&gt;

There exist first-order sentences that are modeled by infinite graphs but not by any finite graph. For instance, the property of having exactly one vertex of [[degree (graph theory)|degree]] one, with all other vertices having degree exactly two, can be expressed by a first order sentence. It is modeled by an infinite [[End (graph theory)|ray]], but violates Euler's [[handshaking lemma]] for finite graphs. However, it follows from the negative solution to the [[Entscheidungsproblem]] (by [[Alonzo Church]] and [[Alan Turing]] in the 1930s) that satisfiability of first-order sentences for graphs that are not constrained to be finite remains undecidable.

==Second order==
In the [[monadic second-order logic]] of graphs, the variables represent objects of up to four types: vertices, edges, sets of vertices, and sets of edges. There are two main variations of monadic second-order graph logic: MSO&lt;sub&gt;1&lt;/sub&gt; in which only vertex and vertex set variables are allowed, and MSO&lt;sub&gt;2&lt;/sub&gt; in which all four types of variables are allowed. The predicates on these variables include equality testing, membership testing, and either vertex-edge incidence (if both vertex and edge variables are allowed) or adjacency between pairs of vertices (if only vertex variables are allowed). Additional variations in the definition allow additional predicates such as modular counting predicates.

===Examples===
As an example, the [[Graph connectivity|connectivity]] of an undirected graph can be expressed in MSO&lt;sub&gt;1&lt;/sub&gt; as the statement that, for every partition of the vertices into two nonempty subsets, there exists an edge from one subset to the other. A partition of the vertices can be described by the subset ''S'' of vertices on one side of the partition, and each such subset should either describe a trivial partition (one in which one or the other side is empty) or be crossed by an edge. That is, a graph is connected when it models the MSO&lt;sub&gt;1&lt;/sub&gt; formula
:&lt;math&gt;\forall S\Bigl( \forall x(x\in S) \vee \forall y\bigl(\lnot(y\in S)\bigr) \vee \exists x\exists y\bigl(x\in S\wedge \lnot(y\in S) \wedge x\sim y\bigr) \Bigr).&lt;/math&gt;
However, connectivity cannot be expressed in first-order graph logic, nor can it be expressed in existential MSO&lt;sub&gt;1&lt;/sub&gt; (the [[Fragment (logic)|fragment]] of MSO&lt;sub&gt;1&lt;/sub&gt; in which all set quantifiers are existential and occur at the beginning of the sentence) nor even existential MSO&lt;sub&gt;2&lt;/sub&gt;.{{sfnp|Fagin|Stockmeyer|Vardi|1995}}

[[Hamiltonian path|Hamiltonicity]] can be expressed in MSO&lt;sub&gt;2&lt;/sub&gt; by the existence of a set of edges that forms a connected 2-regular graph on all the vertices, with connectivity expressed as above and 2-regularity expressed as the incidence of two but not three distinct edges at each vertex. However, Hamiltonicity is not expressible in MSO&lt;sub&gt;1&lt;/sub&gt;, because MSO&lt;sub&gt;1&lt;/sub&gt; is not capable of distinguishing [[complete bipartite graph]]s with equal numbers of vertices on each side of the bipartition (which are Hamiltonian) from unbalanced complete bipartite graphs (which are not).&lt;ref&gt;{{harvtxt|Courcelle|Engelfriet|2012}}; {{harvtxt|Libkin|2004}}, Corollary 7.24, [https://books.google.com/books?id=E0qqCAAAQBAJ&amp;pg=PA126 pp.&amp;nbsp;126–127].&lt;/ref&gt;

Although not part of the definition of MSO&lt;sub&gt;2&lt;/sub&gt;, [[Orientation (graph theory)|orientations]] of undirected graphs can be represented by a technique involving [[Trémaux tree]]s. This allows other graph properties involving orientations to be expressed as well.{{sfnp|Courcelle|1996}}

===Courcelle's theorem===
According to [[Courcelle's theorem]], every fixed MSO&lt;sub&gt;2&lt;/sub&gt; property can be tested in linear time on graphs of bounded [[treewidth]], and every fixed MSO&lt;sub&gt;1&lt;/sub&gt; property can be tested in linear time on graphs of bounded [[clique-width]].{{sfnp|Courcelle|Engelfriet|2012}} The version of this result for graphs of bounded treewidth can also be implemented in [[logarithmic space]].{{sfnp|Elberfeld|Jakoby|Tantau|2010}} Applications of this result include a fixed-parameter tractable algorithm for computing the [[crossing number (graph theory)|crossing number]] of a graph.&lt;ref&gt;{{harvtxt|Grohe|2001}}; {{harvtxt|Kawarabayashi|Reed|2007}}.&lt;/ref&gt;

===Seese's theorem===
The [[satisfiability problem]] for a formula of monadic second-order logic is the problem of determining whether there exists at least one graph (possibly within a restricted family of graphs) for which the formula is true. For arbitrary graph families, and arbitrary formulas, this problem is [[undecidable problem|undecidable]]. However, satisfiability of MSO&lt;sub&gt;2&lt;/sub&gt; formulas is decidable for the graphs of bounded treewidth, and satisfiability of MSO&lt;sub&gt;1&lt;/sub&gt; formulas is decidable for graphs of bounded clique-width. The proof involves using Courcelle's theorem to build an automaton that can test the property, and then examining the automaton to determine whether there is any graph it can accept.

As a partial converse, {{harvtxt|Seese|1991}} proved that, whenever a family of graphs has a decidable MSO&lt;sub&gt;2&lt;/sub&gt; satisfiability problem, the family must have bounded treewidth. The proof is based on a theorem of Robertson and Seymour that the families of graphs with unbounded treewidth have arbitrarily large [[grid graph|grid]] [[graph minor|minors]]. Seese also conjectured that every family of graphs with a decidable MSO&lt;sub&gt;1&lt;/sub&gt; satisfiability problem must have bounded clique-width; this has not been proven, but a weakening of the conjecture that extends MSO&lt;sub&gt;1&lt;/sub&gt; with modular counting predicates is true.{{sfnp|Courcelle|Oum|2007}}

==Notes==
{{reflist|30em}}

==References==
{{refbegin|30em}}
*{{citation |first1=Jianer | last1=Chen |first2=Xiuzhen | last2=Huang |first3=Iyad A. | last3=Kanj |first4=Ge | last4=Xia | title=Strong computational lower bounds via parameterized complexity | journal=[[Journal of Computer and System Sciences]] | volume=72 | year=2006 | pages=1346–1367 | doi=10.1016/j.jcss.2006.04.007 | issue=8}}
*{{citation
 | last = Courcelle | first = Bruno | authorlink = Bruno Courcelle
 | editor1-last = Immerman | editor1-first = Neil | editor1-link = Neil Immerman
 | editor2-last = Kolaitis | editor2-first = Phokion G.
 | contribution = On the expression of graph properties in some fragments of monadic second-order logic
 | contribution-url = http://www.labri.fr/perso/courcell/Textes/DIMACS(1997).pdf
 | mr = 1451381
 | pages = 33–62
 | publisher = Amer. Math. Soc.
 | series = DIMACS
 | title = Proc. Descr. Complex. Finite Models
 | volume = 31
 | year = 1996}}.
*{{citation | title=Graph Structure and Monadic Second-Order Logic: A Language-Theoretic Approach | volume=138 | series=Encyclopedia of Mathematics and its Applications | first1=Bruno | last1=Courcelle | author1-link=Bruno Courcelle | first2=Joost | last2=Engelfriet | publisher=[[Cambridge University Press]] | year=2012 | isbn=9781139644006 | zbl=1257.68006 }}.
*{{citation
 | last1 = Courcelle | first1 = Bruno | author1-link=Bruno Courcelle
 | last2 = Oum | first2 = Sang-il
 | doi = 10.1016/j.jctb.2006.04.003
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 2278126
 | pages = 91–126
 | series = Series B
 | title = Vertex-minors, monadic second-order logic, and a conjecture by Seese
 | url = http://mathsci.kaist.ac.kr/~sangil/pdf/2006co.pdf
 | volume = 97
 | year = 2007}}.
*{{citation |first1=R. G. |last1=Downey | author1-link = Rod Downey |author2-link=Michael Fellows |first2=M. R. |last2=Fellows |title=Fixed-parameter tractability and completeness. II. On completeness for W[1] |journal=[[Theoretical Computer Science (journal)|Theoretical Computer Science]] |volume=141 |issue=1–2 |year=1995 |pages=109–131 |doi=10.1016/0304-3975(94)00097-3}}.
*{{citation
 | last1 = Dvořák | first1 = Zdeněk | author1-link = Zdeněk Dvořák
 | last2 = Kráľ | first2 = Daniel | author2-link = Daniel Kráľ
 | last3 = Thomas | first3 = Robin | author3-link = Robin Thomas (mathematician)
 | contribution = Deciding first-order properties for sparse graphs
 | mr = 3024787
 | pages = 133–142
 | title = [[Symposium on Foundations of Computer Science|Proc. 51st Annual IEEE Symposium on Foundations of Computer Science (FOCS 2010)]]
 | year = 2010}}.
*{{citation
 | last1 = Elberfeld | first1 = Michael
 | last2 = Jakoby | first2 = Andreas
 | last3 = Tantau | first3 = Till
 | contribution = Logspace Versions of the Theorems of Bodlaender and Courcelle
 | contribution-url = http://wwwmayr.in.tum.de/konferenzen/Sommerakademie2010/talks/tantau_paper.pdf
 | date = October 2010
 | doi = 10.1109/FOCS.2010.21
 | pages = 143–152
 | title = [[Symposium on Foundations of Computer Science|Proc. 51st Annual IEEE Symposium on Foundations of Computer Science (FOCS 2010)]]}}.
*{{citation
 | last = Fagin | first = Ronald | authorlink = Ronald Fagin
 | issue = 1
 | journal = [[Journal of Symbolic Logic]]
 | mr = 0476480
 | pages = 50–58
 | title = Probabilities on finite models
 | url = http://researcher.ibm.com/researcher/files/us-fagin/jsl76.pdf
 | volume = 41
 | year = 1976
 | doi=10.1017/s0022481200051756}}.
*{{citation
 | last1 = Fagin | first1 = Ronald | author1-link = Ronald Fagin
 | last2 = Stockmeyer | first2 = Larry J. | author2-link = Larry Stockmeyer
 | last3 = Vardi | first3 = Moshe Y. | author3-link = Moshe Vardi
 | doi = 10.1006/inco.1995.1100
 | issue = 1
 | journal = [[Information and Computation]]
 | mr = 1340807
 | pages = 78–92
 | title = On monadic NP vs monadic co-NP
 | volume = 120
 | year = 1995}}.
*{{citation
 | last = Goldberg | first = Leslie Ann | authorlink = Leslie Ann Goldberg
 | contribution = Polynomial space polynomial delay algorithms for listing families of graphs
 | doi = 10.1145/167088.167160
 | isbn = 0-89791-591-7
 | location = New York, NY, USA
 | pages = 218–225
 | publisher = ACM
 | title = [[Symposium on Theory of Computing|Proceedings of the Twenty-fifth Annual ACM Symposium on Theory of Computing (STOC '93)]]
 | year = 1993}}.
*{{citation
 | last = Grandjean | first = Étienne
 | doi = 10.1016/S0019-9958(83)80043-6
 | issue = 2-3
 | journal = [[Information and Computation|Information and Control]]
 | mr = 742707
 | pages = 180–204
 | title = Complexity of the first-order theory of almost all finite structures
 | volume = 57
 | year = 1983}}.
*{{citation
 | last = Grohe | first = Martin
 | contribution = Computing crossing numbers in quadratic time
 | doi = 10.1145/380752.380805
 | pages = 231–236
 | title = [[Symposium on Theory of Computing|Proceedings of the Thirty-third Annual ACM Symposium on Theory of Computing (STOC '01)]]
 | year = 2001}}.
*{{citation
 | last1 = Grohe | first1 = Martin
 | last2 = Kreutzer | first2 = Stephan
 | last3 = Siebertz | first3 = Sebastian
 | arxiv = 1311.3899
 | contribution = Deciding first-order properties of nowhere dense graphs
 | doi = 10.1145/2591796.2591851
 | isbn = 978-1-4503-2710-7
 | location = New York
 | pages = 89–98
 | publisher = ACM
 | title = Proceedings of the 46th Annual ACM Symposium on Theory of Computing (STOC '14)
 | year = 2014}}.
*{{citation
 | last1 = Immerman | first1 = Neil | author1-link = Neil Immerman
 | last2 = Lander | first2 = Eric | author2-link = Eric Lander
 | editor-last = Selman | editor-first = Alan L.
 | contribution = Describing graphs: a first-order approach to graph canonization
 | doi = 10.1007/978-1-4612-4478-3_5
 | location = New York
 | mr = 1060782
 | pages = 59–81
 | publisher = Springer-Verlag
 | title = Complexity Theory Retrospective: In honor of Juris Hartmanis on the occasion of his sixtieth birthday
 | year = 1990}}.
*{{citation
 | last1 = Kawarabayashi | first1 = Ken-ichi | author1-link = Ken-ichi Kawarabayashi
 | last2 = Reed | first2 = Bruce | author2-link = Bruce Reed (mathematician)
 | contribution = Computing crossing number in linear time
 | doi = 10.1145/1250790.1250848
 | pages = 382–390
 | title = [[Symposium on Theory of Computing|Proceedings of the Thirty-ninth Annual ACM Symposium on Theory of Computing (STOC '07)]]
 | year = 2007}}.
*{{citation
 | last = Libkin | first = Leonid
 | doi = 10.1007/978-3-662-07003-1
 | isbn = 3-540-21202-7
 | mr = 2102513
 | publisher = Springer-Verlag, Berlin
 | series = Texts in Theoretical Computer Science: An EATCS Series
 | title = Elements of finite model theory
 | year = 2004}}.
*{{citation
 | last = Lynch | first = James F.
 | doi = 10.1002/rsa.3240030105
 | issue = 1
 | journal = Random Structures &amp; Algorithms
 | mr = 1139487
 | pages = 33–53
 | title = Probabilities of sentences about very sparse random graphs
 | volume = 3
 | year = 1992}}.
*{{citation
 | last1 = Nešetřil | first1 = Jaroslav | author1-link = Jaroslav Nešetřil
 | last2 = Ossona de Mendez | first2 = Patrice | author2-link = Patrice Ossona de Mendez
 | doi = 10.1007/978-3-642-27875-4
 | isbn = 978-3-642-27874-7
 | mr = 2920058
 | publisher = Springer-Verlag
 | series = Algorithms and Combinatorics
 | title = Sparsity: Graphs, Structures, and Algorithms
 | volume = 28
 | year = 2012}}.
*{{citation
 | last = Parys | first = Paweł
 | contribution = First-order logic on CPDA graphs
 | doi = 10.1007/978-3-319-06686-8_23
 | location = New York
 | mr = 3218557
 | pages = 300–313
 | publisher = Springer-Verlag
 | series = [[Lecture Notes in Computer Science]]
 | title = Computer science—theory and applications
 | volume = 8476
 | year = 2014}}.
*{{citation
 | last1 = Pikhurko | first1 = Oleg
 | last2 = Spencer | first2 = Joel | author2-link = Joel Spencer
 | last3 = Verbitsky | first3 = Oleg
 | doi = 10.1016/j.apal.2005.04.003
 | issue = 1-3
 | journal = Annals of Pure and Applied Logic
 | mr = 2206252
 | pages = 74–109
 | title = Succinct definitions in the first order theory of graphs
 | volume = 139
 | year = 2006}}.
*{{citation
 | last1 = Pikhurko | first1 = Oleg
 | last2 = Verbitsky | first2 = Oleg
 | editor1-last = Grohe | editor1-first = Martin
 | editor2-last = Makowsky | editor2-first = Johann A.
 | contribution = Logical complexity of graphs: a survey
 | pages = 129–180
 | publisher = American Mathematical Society
 | series = Contemporary Mathematics
 | title = Model Theoretic Methods in Finite Combinatorics (AMS-ASL Joint Special Session, January 5-8, 2009, Washington, DC)
 | volume = 558
 | year = 2011}}.
*{{citation
 | last = Seese | first = D.
 | doi = 10.1016/0168-0072(91)90054-P
 | issue = 2
 | journal = Annals of Pure and Applied Logic
 | mr = 1114848
 | pages = 169–195
 | title = The structure of the models of decidable monadic theories of graphs
 | volume = 53
 | year = 1991}}.
*{{citation
 | last1 = Shelah | first1 = Saharon | author1-link = Saharon Shelah
 | last2 = Spencer | first2 = Joel | author2-link = Joel Spencer
 | doi = 10.2307/1990968
 | issue = 1
 | journal = [[Journal of the American Mathematical Society]]
 | mr = 924703
 | pages = 97–115
 | title = Zero-one laws for sparse random graphs
 | volume = 1
 | year = 1988}}.
*{{citation
 | last = Spencer | first = Joel | author-link = Joel Spencer
 | doi = 10.1007/BF02122699
 | issue = 1
 | journal = [[Combinatorica]]
 | mr = 1075070
 | pages = 95–102
 | title = Infinite spectra in the first order theory of graphs
 | volume = 10
 | year = 1990}}.
*{{citation
 | last = Spencer | first = Joel | author-link = Joel Spencer
 | doi = 10.1007/978-3-662-04538-1
 | isbn = 3-540-41654-4
 | mr = 1847951
 | publisher = Springer-Verlag, Berlin
 | series = Algorithms and Combinatorics
 | title = The Strange Logic of Random Graphs
 | volume = 22
 | year = 2001}}.
*{{citation
 | last = Trahtenbrot | first = B. A. | authorlink = Boris Trakhtenbrot
 | journal = Doklady Akademii Nauk SSSR (N.S.)
 | mr = 0033784
 | pages = 569–572
 | title = The impossibility of an algorithm for the decision problem for finite domains
 | volume = 70
 | year = 1950}}.
*{{citation
 | last = Verbitsky | first = Oleg
 | doi = 10.1016/j.tcs.2005.05.003
 | issue = 1-2
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | mr = 2168849
 | pages = 158–176
 | title = The first order definability of graphs with separators via the Ehrenfeucht game
 | volume = 343
 | year = 2005}}.
{{refend}}

[[Category:Graph theory]]
[[Category:Finite model theory]]</text>
      <sha1>h8h2wxw8nuztm5lr2zec27pj0vg5db6</sha1>
    </revision>
  </page>
  <page>
    <title>Lucas sequence</title>
    <ns>0</ns>
    <id>734635</id>
    <revision>
      <id>870808398</id>
      <parentid>867782744</parentid>
      <timestamp>2018-11-27T03:39:03Z</timestamp>
      <contributor>
        <username>LucasBrown</username>
        <id>11487766</id>
      </contributor>
      <comment>/* Specific names */ Added the square roots of the square triangular numbers (U_n(6,-1)) and the corresponding line in the OEIS table</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19173">{{distinguish|text=the sequence of [[Lucas number]]s, which is a particular Lucas sequence}}

In [[mathematics]], the '''Lucas sequences''' &lt;math&gt;U_n(P,Q)&lt;/math&gt; and &lt;math&gt;V_n(P, Q)&lt;/math&gt; are certain [[constant-recursive sequence|constant-recursive]] [[integer sequence]]s that satisfy the [[recurrence relation]]

: &lt;math&gt;x_n = P \cdot x_{n - 1} - Q \cdot x_{n - 2}&lt;/math&gt;

where &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; are fixed integers. Any sequence satisfying this recurrence relation can be represented as a [[linear combination]] of the Lucas sequences &lt;math&gt;U_n(P, Q)&lt;/math&gt; and &lt;math&gt;V_n(P, Q)&lt;/math&gt;.

More generally, Lucas sequences &lt;math&gt;U_n(P, Q)&lt;/math&gt; and &lt;math&gt;V_n(P, Q)&lt;/math&gt; represent sequences of [[polynomial]]s in &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; with integer coefficients.

Famous examples of Lucas sequences include the [[Fibonacci number]]s, [[Mersenne number]]s, [[Pell number]]s, [[Lucas number]]s, [[Jacobsthal number]]s, and a superset of [[Fermat number]]s. Lucas sequences are named after the [[France|French]] [[mathematician]] [[Édouard Lucas]].

== Recurrence relations ==

Given two integer parameters ''P'' and ''Q'', the Lucas sequences of the first kind ''U''&lt;sub&gt;''n''&lt;/sub&gt;(''P'',''Q'') and of the second kind ''V''&lt;sub&gt;''n''&lt;/sub&gt;(''P'',''Q'') are defined by the [[recurrence relation]]s:

:&lt;math&gt;\begin{align}
U_0(P,Q)&amp;=0, \\
U_1(P,Q)&amp;=1, \\
U_n(P,Q)&amp;=P\cdot U_{n-1}(P,Q)-Q\cdot U_{n-2}(P,Q) \mbox{  for }n&gt;1,
\end{align}
&lt;/math&gt;

and

:&lt;math&gt;\begin{align}

V_0(P,Q)&amp;=2, \\
V_1(P,Q)&amp;=P, \\
V_n(P,Q)&amp;=P\cdot V_{n-1}(P,Q)-Q\cdot V_{n-2}(P,Q) \mbox{  for }n&gt;1.
\end{align}&lt;/math&gt;

It is not hard to show  that for &lt;math&gt;n&gt;0&lt;/math&gt;,

:&lt;math&gt;\begin{align}
U_n(P,Q)&amp;=\frac{P\cdot U_{n-1}(P,Q) + V_{n-1}(P,Q)}{2},  \\
V_n(P,Q)&amp;=\frac{(P^2-4Q)\cdot U_{n-1}(P,Q)+P\cdot V_{n-1}(P,Q)}{2}.  
\end{align}&lt;/math&gt;

== Examples ==

Initial terms of Lucas sequences ''U''&lt;sub&gt;''n''&lt;/sub&gt;(''P'',''Q'') and ''V''&lt;sub&gt;''n''&lt;/sub&gt;(''P'',''Q'') are given in the table:
:&lt;math&gt;
\begin{array}{r|l|l}
n &amp; U_n(P,Q) &amp; V_n(P,Q)
\\
\hline
0 &amp; 0 &amp; 2
\\
1 &amp; 1 &amp; P
\\
2 &amp; P &amp; {P}^{2}-2Q
\\
3 &amp; {P}^{2}-Q &amp; {P}^{3}-3PQ
\\
4 &amp; {P}^{3}-2PQ &amp; {P}^{4}-4{P}^{2}Q+2{Q}^{2}
\\
5 &amp; {P}^{4}-3{P}^{2}Q+{Q}^{2} &amp; {P}^{5}-5{P}^{3}Q+5P{Q}^{2}
\\
6 &amp; {P}^{5}-4{P}^{3}Q+3P{Q}^{2} &amp; {P}^{6}-6{P}^{4}Q+9{P}^{2}{Q}^{2}-2{Q}^{3}
\end{array}
&lt;/math&gt;

== Explicit expressions ==

The characteristic equation of the recurrence relation for Lucas sequences &lt;math&gt;U_n(P,Q)&lt;/math&gt; and &lt;math&gt;V_n(P,Q)&lt;/math&gt; is:
:&lt;math&gt;x^2 - Px + Q=0 \,&lt;/math&gt;
&lt;!-- The \, is to keep the formula rendered as PNG instead of HTML. Please don't remove it.--&gt;
It has the [[discriminant]] &lt;math&gt;D=P^2 - 4Q&lt;/math&gt; and the roots:
:&lt;math&gt;a = \frac{P+\sqrt{D}}2\quad\text{and}\quad b = \frac{P-\sqrt{D}}2. \,&lt;/math&gt;

Thus:
:&lt;math&gt;a + b = P\, ,&lt;/math&gt;
:&lt;math&gt;a b = \frac{1}{4}(P^2 - D) = Q\, ,&lt;/math&gt;
:&lt;math&gt;a - b = \sqrt{D}\, .&lt;/math&gt;

Note that the sequence &lt;math&gt;a^n&lt;/math&gt; and the sequence &lt;math&gt;b^n&lt;/math&gt; also satisfy the recurrence relation. However these might not be integer sequences.

=== Distinct roots ===
When &lt;math&gt;D\ne 0&lt;/math&gt;, ''a'' and ''b'' are distinct and one quickly verifies that

:&lt;math&gt;a^n = \frac{V_n + U_n \sqrt{D}}{2}&lt;/math&gt;

:&lt;math&gt;b^n = \frac{V_n - U_n \sqrt{D}}{2}&lt;/math&gt;.

It follows that the terms of Lucas sequences can be expressed in terms of ''a'' and ''b'' as follows

:&lt;math&gt;U_n= \frac{a^n-b^n}{a-b} = \frac{a^n-b^n}{ \sqrt{D}}&lt;/math&gt;

:&lt;math&gt;V_n=a^n+b^n \,&lt;/math&gt;
&lt;!-- The \, is to keep the formula rendered as PNG instead of HTML. Please don't remove it.--&gt;

===Repeated root===

The case &lt;math&gt; D=0 &lt;/math&gt; occurs exactly when &lt;math&gt; P=2S \text{ and }Q=S^2&lt;/math&gt; for some integer ''S'' so that &lt;math&gt;a=b=S&lt;/math&gt;. In this case one easily finds that

:&lt;math&gt;U_n(P,Q)=U_n(2S,S^2) = nS^{n-1}\,&lt;/math&gt;

:&lt;math&gt;V_n(P,Q)=V_n(2S,S^2)=2S^n\,&lt;/math&gt;.

== Properties ==

===Generating functions===

The ordinary [[generating function]]s are
:&lt;math&gt;
\sum_{n\ge 0} U_n(P,Q)z^n = \frac{z}{1-Pz+Qz^2};
&lt;/math&gt;
:&lt;math&gt;
\sum_{n\ge 0} V_n(P,Q)z^n = \frac{2-Pz}{1-Pz+Qz^2}.
&lt;/math&gt;

===Sequences with the same discriminant===

If the Lucas sequences &lt;math&gt;U_n(P, Q)&lt;/math&gt; and &lt;math&gt;V_n(P, Q)&lt;/math&gt; have
discriminant &lt;math&gt;D = P^2 - 4Q&lt;/math&gt;, then the sequences based on &lt;math&gt;P_2&lt;/math&gt; and &lt;math&gt;Q_2&lt;/math&gt; where
:&lt;math&gt; P_2 = P + 2  &lt;/math&gt;
:&lt;math&gt; Q_2 = P + Q + 1  &lt;/math&gt;
have the same discriminant: &lt;math&gt;P_2^2 - 4Q_2 = (P+2)^2 - 4(P + Q + 1) = P^2 - 4Q = D&lt;/math&gt;.

===Pell equations===

When &lt;math&gt;Q=\pm 1&lt;/math&gt;, the Lucas sequences &lt;math&gt;U_n(P, Q)&lt;/math&gt; and &lt;math&gt;V_n(P, Q)&lt;/math&gt; satisfy certain [[Pell equation]]s:
:&lt;math&gt;V_n(P,1)^2 - D\cdot U_n(P,1)^2 = 4,&lt;/math&gt;
:&lt;math&gt;V_{2n}(P,-1)^2 - D\cdot U_{2n}(P,-1)^2 = 4,&lt;/math&gt;
:&lt;math&gt;V_{2n+1}(P,-1)^2 - D\cdot U_{2n+1}(P,-1)^2 = -4.&lt;/math&gt;

== Other relations ==

The terms of Lucas sequences satisfy relations that are generalizations of those between [[Fibonacci number]]s &lt;math&gt;F_n=U_n(1,-1)&lt;/math&gt; and [[Lucas number]]s &lt;math&gt;L_n=V_n(1,-1)&lt;/math&gt;. For example:
:&lt;math&gt;
\begin{array}{r|l}
\text{General case} &amp; (P,Q) = (1,-1)
\\
\hline
(P^2-4Q) U_n = {V_{n+1} - Q V_{n-1}}=2V_{n+1}-P V_n  &amp; 5F_n = {L_{n+1} + L_{n-1}}=2L_{n+1} - L_{n} 
\\
V_n = U_{n+1} - Q U_{n-1}=2U_{n+1}-PU_n  &amp; L_n = F_{n+1} + F_{n-1}=2F_{n+1}-F_n 
\\
U_{2n} = U_n V_n  &amp; F_{2n} = F_n L_n 
\\
V_{2n} = V_n^2 - 2Q^n  &amp; L_{2n} = L_n^2 - 2(-1)^n 
\\
U_{m+n} = U_n U_{m+1} - Q U_m U_{n-1}=\frac{U_mV_n+U_nV_m}{2}  &amp; F_{m+n} = F_n F_{m+1} + F_m F_{n-1}=\frac{F_mL_n+F_nL_m}{2} 
\\
V_{m+n} = V_m V_n - Q^n V_{m-n} = D U_m U_n + Q^n V_{m-n} &amp; L_{m+n} = L_m L_n - (-1)^n L_{m-n} = 5 F_m F_n + (-1)^n L_{m-n} 
\\
V_n^2-DU_n^2=4Q^n &amp; L_n^2-5F_n^2=4(-1)^n 
\\
U_n^2-U_{n-1}U_{n+1}=Q^{n-1} &amp; F_n^2-F_{n-1}F_{n+1}=(-1)^{n-1} 
\\
DU_n=V_{n+1}-QV_{n-1} &amp; F_n=\frac{L_{n+1}+L_{n-1}}{5} 
\\
V_{m+n}=\frac{V_mV_n+DU_mU_n}{2} &amp; L_{m+n}=\frac{L_mL_n+5F_mF_n}{2} 
\\
U_{m+n}=U_mV_n-Q^nU_{m-n} &amp; F_{n+m}=F_mL_n-(-1)^nF_{m-n}
\\
2^{n-1}U_n={n \choose 1}P^{n-1}+{n \choose 3}P^{n-3}D+\cdots &amp; 2^{n-1}F_n={n \choose 1}+5{n \choose 3}+\cdots
\\
2^{n-1}V_n=P^n+{n \choose 2}P^{n-2}D+{n \choose 4}P^{n-4}D^2+\cdots &amp; 2^{n-1}L_n=1+5{n \choose 2}+5^2{n \choose 4}+\cdots
\end{array}
&lt;/math&gt;

Among the consequences is that &lt;math&gt;U_{km}(P,Q)&lt;/math&gt; is a multiple of &lt;math&gt;U_m(P,Q)&lt;/math&gt;, i.e., the sequence &lt;math&gt;(U_m(P,Q))_{m\ge1}&lt;/math&gt;
is a [[divisibility sequence]]. This implies, in particular, that &lt;math&gt;U_n(P,Q)&lt;/math&gt; can be prime only when ''n'' is prime.
Another consequence is an analog of [[exponentiation by squaring]] that allows fast computation of &lt;math&gt;U_n(P,Q)&lt;/math&gt; for large values of ''n''. 
Moreover, if &lt;math&gt;\gcd(P,Q)=1&lt;/math&gt;, then &lt;math&gt;(U_m(P,Q))_{m\ge1}&lt;/math&gt; is a strong divisibility sequence.

Other divisibility properties are as follows:&lt;ref&gt;For such relations and divisibility properties, see {{harv|Carmichael|1913}}, {{harv|Lehmer|1930}} or {{harv|Ribenboim|1996|loc=2.IV}}.&lt;/ref&gt;
* If ''n'' / ''m'' is odd, then &lt;math&gt;V_m&lt;/math&gt; divides &lt;math&gt;V_n&lt;/math&gt;.
* Let ''N'' be an integer relatively prime to 2''Q''.  If the smallest positive integer ''r'' for which ''N'' divides &lt;math&gt;U_r&lt;/math&gt; exists, then the set of ''n'' for which ''N'' divides &lt;math&gt;U_n&lt;/math&gt; is exactly the set of multiples of ''r''.
* If ''P'' and ''Q'' are even, then &lt;math&gt;U_n, V_n&lt;/math&gt; are always even except &lt;math&gt;U_1&lt;/math&gt;.
* If ''P'' is even and ''Q'' is odd, then the parity of &lt;math&gt;U_n&lt;/math&gt; is the same as ''n'' and &lt;math&gt;V_n&lt;/math&gt; is always even.
* If ''P'' is odd and ''Q'' is even, then &lt;math&gt;U_n, V_n&lt;/math&gt; are always odd for &lt;math&gt;n=1, 2, \ldots&lt;/math&gt;.
* If ''P'' and ''Q'' are odd, then &lt;math&gt;U_n, V_n&lt;/math&gt; are even if and only if ''n'' is a multiple of 3.
* If ''p'' is an odd prime, then &lt;math&gt;U_p\equiv\left(\frac{D}{p}\right), V_p\equiv P\pmod{p}&lt;/math&gt; (see [[Legendre symbol]]).
* If ''p'' is an odd prime and divides ''P'' and ''Q'', then ''p'' divides &lt;math&gt;U_n&lt;/math&gt; for every &lt;math&gt;n&gt;1&lt;/math&gt;.
* If ''p'' is an odd prime and divides ''P'' but not ''Q'', then ''p'' divides &lt;math&gt;U_n&lt;/math&gt; if and only if ''n'' is even.
* If ''p'' is an odd prime and divides not ''P'' but ''Q'', then ''p'' never divides &lt;math&gt;U_n&lt;/math&gt; for &lt;math&gt;n=1, 2, \ldots&lt;/math&gt;.
* If ''p'' is an odd prime and divides not ''PQ'' but ''D'', then ''p'' divides &lt;math&gt;U_n&lt;/math&gt; if and only if ''p'' divides ''n''.
* If ''p'' is an odd prime and does not divide ''PQD'', then ''p'' divides &lt;math&gt;U_l&lt;/math&gt;, where &lt;math&gt;l=p-\left(\frac{D}{p}\right)&lt;/math&gt;.

The last fact generalizes [[Fermat's little theorem]].  These facts are used in the [[Lucas–Lehmer primality test]].
The converse of the last fact does not hold, as the converse of Fermat's little theorem does not hold.  There exists a composite ''n'' relatively prime to ''D'' and dividing &lt;math&gt;U_l&lt;/math&gt;, where &lt;math&gt;l=n-\left(\frac{D}{n}\right)&lt;/math&gt;.  Such a composite is called [[Lucas pseudoprime]].

A [[prime factor]] of a term in a Lucas sequence that does not divide any earlier term in the sequence is called '''primitive'''.
[[Carmichael's theorem]] states that all but finitely many of the terms in a Lucas sequence have a primitive [[prime factor]].&lt;ref&gt;{{cite journal |last1=Yabuta |first1=M |title=A simple proof of Carmichael's theorem on primitive divisors |journal=Fibonacci Quarterly |date=2001 |volume=39 |pages=439–443 |url=http://www.fq.math.ca/Scanned/39-5/yabuta.pdf |accessdate=4 October 2018}}&lt;/ref&gt;  Indeed, Carmichael (1913) showed that if ''D'' is positive and ''n'' is not 1, 2 or 6, then &lt;math&gt;U_n&lt;/math&gt; has a primitive prime factor.  In the case ''D'' is negative, a deep result of Bilu, Hanrot, Voutier and Mignotte&lt;ref&gt;{{cite journal | first1=Yuri | last1=Bilu | first2=Guillaume | last2=Hanrot | first3=Paul M. | last3=Voutier | first4=Maurice | last4=Mignotte | title=Existence of primitive divisors of Lucas and Lehmer numbers | journal = J. Reine Angew. Math. | year=2001 | volume=539 |pages= 75–122 | mr=1863855 | doi=10.1515/crll.2001.080}}
&lt;/ref&gt; shows that if ''n'' &amp;gt; 30, then &lt;math&gt;U_n&lt;/math&gt; has a primitive prime factor and determines all cases &lt;math&gt;U_n&lt;/math&gt; has no primitive prime factor.

== Specific names ==

The Lucas sequences for some values of ''P'' and ''Q'' have specific names:

:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(1,&amp;minus;1)}} : [[Fibonacci number]]s
:{{math|''V&lt;sub&gt;n&lt;/sub&gt;''(1,&amp;minus;1)}} : [[Lucas number]]s
:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(2,&amp;minus;1)}} : [[Pell number]]s
:{{math|''V&lt;sub&gt;n&lt;/sub&gt;''(2,&amp;minus;1)}} : [[Pell-Lucas numbers]] (companion Pell numbers)
:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(1,&amp;minus;2)}} : [[Jacobsthal number]]s
:{{math|''V&lt;sub&gt;n&lt;/sub&gt;''(1,&amp;minus;2)}} : [[Jacobsthal-Lucas numbers]]
:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(3, 2)}} : [[Mersenne number]]s 2&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;1
:{{math|''V&lt;sub&gt;n&lt;/sub&gt;''(3, 2)}} :  Numbers of the form 2&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;1, which include the [[Fermat number]]s {{harv|Yabuta|2001}}.
:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(6, 1)}} :  The square roots of the [[square triangular number]]s.
:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(''x'',&amp;minus;1)}} : [[Fibonacci polynomials]]
:{{math|''V&lt;sub&gt;n&lt;/sub&gt;''(''x'',&amp;minus;1)}} : [[Lucas polynomials]]
:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(2''x'', 1)}} : [[Chebyshev polynomials]] of second kind
:{{math|''V&lt;sub&gt;n&lt;/sub&gt;''(2''x'', 1)}} : [[Chebyshev polynomials]] of first kind multiplied by 2
:{{math|''U&lt;sub&gt;n&lt;/sub&gt;''(''x''+1, ''x'')}} : [[Repunit]]s base ''x''
:{{math|''V&lt;sub&gt;n&lt;/sub&gt;''(''x''+1, ''x'')}} : ''x&lt;sup&gt;n&lt;/sup&gt;'' + 1

Some Lucas sequences have entries in the [[On-Line Encyclopedia of Integer Sequences]]:

:{|class="wikitable" style="background: #fff"
|-
!&lt;math&gt;P\,&lt;/math&gt;!!&lt;math&gt;Q\, &lt;/math&gt;!!&lt;math&gt;U_n(P,Q)\, &lt;/math&gt;!! &lt;math&gt;V_n(P,Q)\,&lt;/math&gt;
|- 
| −1 || 3 || {{OEIS2C|A214733}}
|-
| 1 || −1 || {{OEIS2C|A000045}} || {{OEIS2C|A000032}}
|-
| 1 || 1 || {{OEIS2C|A128834}} || {{OEIS2C|A087204}}
|-
| 1 || 2 || {{OEIS2C|A107920}} || {{OEIS2C|A002249}}
|-
| 2 || −1 || {{OEIS2C|A000129}} || {{OEIS2C|A002203}}
|-
| 2 || 1 || {{OEIS2C|A001477}}
|-
| 2 || 2 || {{OEIS2C|A009545}} || {{OEIS2C|A007395}}
|-
| 2 || 3 || {{OEIS2C|A088137}}
|-
| 2 || 4 || {{OEIS2C|A088138}}
|-
| 2 || 5 || {{OEIS2C|A045873}}
|-
| 3 || −5 || {{OEIS2C|A015523}} || {{OEIS2C|A072263}}
|-
| 3 || −4 || {{OEIS2C|A015521}} || {{OEIS2C|A201455}}
|-
| 3 || −3 || {{OEIS2C|A030195}} || {{OEIS2C|A172012}}
|-
| 3 || −2 || {{OEIS2C|A007482}} || {{OEIS2C|A206776}}
|-
| 3 || −1 || {{OEIS2C|A006190}} || {{OEIS2C|A006497}}
|-
| 3 || 1 || {{OEIS2C|A001906}} || {{OEIS2C|A005248}}
|-
| 3 || 2 || {{OEIS2C|A000225}} || {{OEIS2C|A000051}}
|-
| 3 || 5 || {{OEIS2C|A190959}}
|-
| 4 || −3 || {{OEIS2C|A015530}} || {{OEIS2C|A080042}}
|-
| 4 || −2 || {{OEIS2C|A090017}}
|-
| 4 || −1 || {{OEIS2C|A001076}} || {{OEIS2C|A014448}}
|-
| 4 || 1 || {{OEIS2C|A001353}} || {{OEIS2C|A003500}}
|-
| 4 || 2 || {{OEIS2C|A007070}}  || {{OEIS2C|A056236}}
|-
| 4 || 3 || {{OEIS2C|A003462}} || {{OEIS2C|A034472}}
|-
| 4 || 4 || {{OEIS2C|A001787}}
|-
| 5 || −3 || {{OEIS2C|A015536}}
|-
| 5 || −2 || {{OEIS2C|A015535}}
|-
| 5 || −1 || {{OEIS2C|A052918}} || {{OEIS2C|A087130}}
|-
| 5 || 1 || {{OEIS2C|A004254}} || {{OEIS2C|A003501}}
|-
| 5 || 4 ||{{OEIS2C|A002450}} || {{OEIS2C|A052539}}
|-
| 6 || 1 ||{{OEIS2C|A001109}} || {{OEIS2C|A003499}}
|}

==Applications==
* Lucas sequences are used in probabilistic [[Lucas pseudoprime]] tests, which are part of the commonly used [[Baillie-PSW primality test]].
* Lucas sequences are used in some primality proof methods, including the [[Lucas-Lehmer-Riesel test]], and the N+1 and hybrid N-1/N+1 methods such as those in Brillhart-Lehmer-Selfridge 1975&lt;ref name="BLS75"&gt;{{ cite journal|author=[[John Brillhart]]|author2=[[Derrick Henry Lehmer]]|author3=[[John Selfridge]]|title=New Primality Criteria and Factorizations of 2&lt;sup&gt;m&lt;/sup&gt; ± 1|journal=Mathematics of Computation |volume=29|number=130|date=April 1975|pages=620–647|jstor=2005583|doi=10.1090/S0025-5718-1975-0384673-1}}&lt;/ref&gt;
* LUC is a [[public-key cryptosystem]] based on Lucas sequences&lt;ref&gt;{{cite journal |author1=P. J. Smith |author2=M. J. J. Lennon |title=LUC: A new public key system |journal=Proceedings of the Ninth IFIP Int. Symp. on Computer Security |year=1993 |pages=103–117 |url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.32.1835}}&lt;/ref&gt; that implements the analogs of [[ElGamal]] (LUCELG), [[Diffie-Hellman]] (LUCDIF), and [[RSA (algorithm)|RSA]] (LUCRSA). The encryption of the message in LUC is computed as a term of certain Lucas sequence, instead of using [[modular exponentiation]] as in RSA or Diffie-Hellman. However, a paper by Bleichenbacher et al.&lt;ref&gt;{{cite journal |author1=D. Bleichenbacher |author2=W. Bosma |author3=A. K. Lenstra |title=Some Remarks on Lucas-Based Cryptosystems |journal=[[Lecture Notes in Computer Science]] |volume=963 |year=1995 |pages=386–396 |doi=10.1007/3-540-44750-4_31 |url=http://www.math.ru.nl/~bosma/pubs/CRYPTO95.pdf}}&lt;/ref&gt; shows that many of the supposed security advantages of LUC over cryptosystems based on modular exponentiation are either not present, or not as substantial as claimed.

==See also==
*[[Somer–Lucas pseudoprime]]

==Notes==
{{reflist}}

==References==
*{{citation
 | last = Carmichael | first = R. D. | author-link = Robert Daniel Carmichael
 | doi = 10.2307/1967797
 | issue = 1/4
 | journal = Annals of Mathematics
 | pages = 30–70
 | title = On the numerical factors of the arithmetic forms α&lt;sup&gt;''n''&lt;/sup&gt;±β&lt;sup&gt;''n''&lt;/sup&gt;
 | volume = 15
 | year = 1913
 | jstor = 1967797 |ref=harv}}
* {{cite journal| first1=D. H. | last1=Lehmer
|title=An extended theory of Lucas' functions
|journal=Annals of Mathematics |year=1930
|volume=31 | number=3
|jstor=1968235 |pages=419–448 |bibcode=1930AnMat..31..419L | doi=10.2307/1968235
|ref=harv}}
* {{cite journal| first1=Morgan | last1=Ward
|title=Prime divisors of second order recurring sequences
|journal = Duke Math. J. | year=1954 | volume=21 | number=4
|pages=607–614 | mr=0064073 |doi=10.1215/S0012-7094-54-02163-8
|ref=harv}}
* {{cite journal|first1=Lawrence | last1=Somer
|title=The divisibility properties of primary Lucas Recurrences with respect to primes
|year=1980 | journal=Fibonacci Quarterly | pages=316 | volume=18 | url=http://www.fq.math.ca/Scanned/18-4/somer.pdf
|ref=harv}}
* {{cite journal|first1=J. C. | last1=Lagarias
|journal=Pac. J. Math. | title=The set of primes dividing Lucas Numbers has density 2/3
|year=1985 | volume=118 | number=2 | pages=449–461 | mr=789184 | doi=10.2140/pjm.1985.118.449
|ref=harv}}
* {{cite book | title=Prime Numbers and Computer Methods for Factorization | edition=2nd | author=Hans Riesel | authorlink=Hans Riesel | series=Progress in Mathematics | volume=126 | publisher=Birkhäuser | year=1994 | isbn=0-8176-3743-5 | pages=107–121 |ref=harv}}
* {{ cite journal|first1=Paulo | last1=Ribenboim | first2=Wayne L. |last2=McDaniel
|title=The square terms in Lucas Sequences | journal=J. Number Theory |year=1996 | volume=58 | number=1 | pages=104–123 | doi=10.1006/jnth.1996.0068
|ref=harv}}
* {{cite journal | first1=M. | last1=Joye | first2=J.-J. | last2=Quisquater | title=Efficient computation of full Lucas sequences | journal=Electronics Letters | year=1996 | volume=32 | number=6 | pages=537–538 | url=http://www.joye.site88.net/papers/JQ96lucas.pdf | doi=10.1049/el:19960359 | deadurl=yes | archiveurl=https://web.archive.org/web/20150202074230/http://www.joye.site88.net/papers/JQ96lucas.pdf | archivedate=2015-02-02 |ref=harv}}
* {{cite book |first= Paulo |last= Ribenboim |title=The New Book of Prime Number Records | publisher=[[Springer-Verlag]], New York | edition=eBook | isbn=978-1-4612-0759-7 | DOI=10.1007/978-1-4612-0759-7 | year=1996|ref=harv}}
* {{cite book | first=Paulo | last=Ribenboim | authorlink=Paulo Ribenboim | year=2000 | title=My Numbers, My Friends: Popular Lectures on Number Theory | edition= | publisher=[[Springer-Verlag]] | location=New York | isbn=0-387-98911-0 | pages=1–50 |ref=harv}}
* {{cite journal | first1=Florian | last1=Luca
|title=Perfect Fibonacci and Lucas numbers | year=2000
|journal = Rend. Circ Matem. Palermo 
|doi=10.1007/BF02904236 | volume=49 | number=2 | pages=313–318
|ref=harv}}
* {{cite journal
 | last = Yabuta | first = M.
 | journal = Fibonacci Quarterly
 | pages = 439–443
 | title = A simple proof of Carmichael's theorem on primitive divisors
 | url = http://www.fq.math.ca/Scanned/39-5/yabuta.pdf
 | volume = 39
 | year = 2001
 | ref=harv}}
*{{cite book
 | title = Proofs that Really Count: The Art of Combinatorial Proof
 | first1 = Arthur T. | last1 = Benjamin | author1-link = Arthur T. Benjamin
 | first2 = Jennifer J. | last2 = Quinn | author2-link = Jennifer Quinn
 | page = 35
 | publisher = [[Mathematical Association of America]]
 | series = Dolciani Mathematical Expositions
 | volume = 27
 | year = 2003
 | isbn = 978-0-88385-333-7
 | ref=harv}}
* [https://www.encyclopediaofmath.org/index.php/Lucas_sequence ''Lucas sequence''] at [[Encyclopedia of Mathematics]].
* {{MathWorld | urlname=LucasSequence | title=Lucas Sequence}}
* {{cite web| url = http://weidai.com/lucas.html|author=[[Wei Dai]]|title= Lucas Sequences in Cryptography}}

[[Category:Recurrence relations]]
[[Category:Integer sequences]]</text>
      <sha1>aw2lu64pzwcbpa2w4pjjs6mbpr9oae1</sha1>
    </revision>
  </page>
  <page>
    <title>Math 55</title>
    <ns>0</ns>
    <id>22008131</id>
    <revision>
      <id>864418671</id>
      <parentid>860645611</parentid>
      <timestamp>2018-10-17T02:35:15Z</timestamp>
      <contributor>
        <ip>18.40.116.242</ip>
      </contributor>
      <comment>Offered context for the claim that it is the hardest undergrad math course in the country.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17131">'''Math 55''' is a two-semester long [[freshman|first-year]] [[undergraduate]] [[mathematics]] course at [[Harvard University]], founded by [[Lynn Loomis]] and [[Shlomo Sternberg]]. The official titles of the course are '''Honors [[abstract algebra|Abstract Algebra]]''' (Math 55a) and '''Honors [[real analysis|Real]] and [[complex analysis|Complex Analysis]]''' (Math 55b). Previously, the official title was '''Honors Advanced Calculus and Linear Algebra'''.

==Description==
The Harvard University Department of Mathematics describes Math 55 as "probably the most difficult undergraduate math class in the country". &lt;ref name="which2155"&gt;"Harvard Mathematics Department 21, 23, 25, or 55?", 2009&lt;/ref&gt; This claim is debatable, with critics often citing the generous policy of the final exam being take home.&lt;ref&gt;{{cite web |title=Math 55a Syllabus |url=http://www.math.harvard.edu/~ctm/home/text/class/harvard/55a/08/html/syl.html |website=Math 55a: Honors Abstract Algebra |accessdate=17 October 2018}}&lt;/ref&gt;  Formerly, students would begin the year in Math 25 (which was created in 1983 as a lower-level Math 55) and, after three weeks of [[point-set topology]] and special topics (for instance, in 1994, [[p-adic analysis|''p''-adic analysis]] was taught by [[Wilfried Schmid]]), students would take a quiz. As of 2012, students may choose to enroll in either Math 25 or Math 55 but are advised to "shop" both courses and have five weeks to decide on one.&lt;ref name="Lee"&gt;{{cite web|url=http://www.harvardindependent.com/2003/10/math-55-dont-try-this-at-home/|title=Math + 55 = Don't Try This at Home|first=Steve|last=Lee|date=16 October 2003|work=Harvard Independent|deadurl=yes|archiveurl=https://web.archive.org/web/20140121131045/http://www.harvardindependent.com/2003/10/math-55-dont-try-this-at-home/|archivedate=21 January 2014|df=}}&lt;/ref&gt; Depending on the professor teaching the class, the diagnostic exam may still be given after three weeks to help students with their decision.

In 1994, 89 students took the test given after three weeks: students scoring more than 50% on the quiz could enroll in Wilfried Schmid's Math 55 (15 students), students scoring between 10 and 50% could stay in Benedict Gross's Math 25 (55 students), and students scoring less than 10% were advised to enroll in a course such as Math 21, multivariate calculus (19 students).&lt;ref name="Chen"&gt;{{cite news|last=Chen| first=Susan A.| title=In Math Department, It's Mostly Male | url=http://www.thecrimson.com/article/1994/10/20/in-math-department-its-mostly-male/}}&lt;/ref&gt;

===Historical retention rate===
In 1970, Math 55 covered almost four years worth of department coursework in two semesters, and subsequently, it drew only the most diligent of undergraduates. Of the 75 students who enrolled in the 1970 offering, by course end, only 20 remained due to the advanced nature of the material and time-constraints under which students were given to work.&lt;ref name="Williams"&gt;{{cite book|last=[[Sam Williams (American journalist)|Williams, Sam]]|title=[[Free as in Freedom: Richard Stallman's Crusade for Free Software]]|publisher=O'Reilly|year=2002|isbn=0-596-00287-4|page=41}}&lt;/ref&gt; [[David Harbater]], a [[University of Pennsylvania]] mathematics professor/researcher, and survivor of the 1974 Math 55 section at Cambridge, recalled of his experience, "Seventy [students] started it, 20 finished it, and only 10 understood it." Scott D. Kominers, familiar with the stated attrition rates for the course, decided to keep an informal log of his journey through the 2009 section: "...we had 51 students the first day, 31 students the second day, 24 for the next four days, 23 for two more weeks, and then 21 for the rest of the first semester after the fifth Monday." (The beginning of the fifth week being the drop-deadline for students to decide whether to remain in Math 55, or transfer to Math 25 (Linear Algebra and Real Analysis I &amp; II)).&lt;ref name="Logan"&gt;{{cite news | last=Ury | first=Logan | year=2006 | title=Burden of Proof| url=http://www.thecrimson.com/article/2006/12/6/burden-of-proof-at-1002-am}}&lt;/ref&gt;

==Course content==
Through 2006,&lt;ref&gt;Compare Elkies course page (2005) and McMullen course page (2008).&lt;/ref&gt; the instructor had broad latitude in choosing the content of the course.  Though Math 55 bore the official title "Honors Advanced Calculus and Linear Algebra", advanced topics in complex analysis, point set topology, group theory, and/or differential geometry could be covered in depth at the discretion of the instructor, in addition to single and multivariable real analysis and abstract linear algebra. In 1970, for example, students studied the [[differential geometry]] of [[Banach manifold]]s in the second semester of Math 55.&lt;ref name="Williams" /&gt;  In contrast, Math 25, entitled "Honors Multivariable Calculus and Linear Algebra", tended to be more narrowly focused, usually covering real analysis, together with the relevant theory of metric spaces and (multi)linear maps.  These topics typically culminated in the proof of the generalized [[Stokes' theorem]], though, time permitting, other relevant topics (e.g., category theory, de Rham cohomology) might also be covered.&lt;ref name=":0"&gt;{{Cite web|url=https://archive.org/details/MATH25abHonorsMultivariableCalculusAndLinearAlgebraHarvard20042005TextsRudinHalmosSpivak|title=Honors Multivariable Calculus and Linear Algebra, Spring 2005, texts, problem sets, syllabi|last=|first=|date=|website=|access-date=9 Jul 2017}}&lt;/ref&gt;  Although both courses presented calculus from a rigorous point of view and emphasized theory and proof writing, Math 55 was generally faster paced, more abstract, and demanded a higher level of mathematical sophistication.  

Loomis and Sternberg's textbook ''Advanced Calculus'',&lt;ref&gt;{{Cite book|url=https://archive.org/details/LoomisL.H.SternbergS.AdvancedCalculusRevisedEditionJonesAndBartlett|title=Advanced Calculus|last=Loomis|first=Lynn H.|last2=Sternberg|first2=Shlomo|publisher=Jones and Bartlett|year=1990|isbn=0-86720-122-3|edition=Revised|location=Boston|pages=|orig-year=1968}}&lt;/ref&gt; an abstract treatment of calculus in the setting of [[normed vector spaces]] and on [[differentiable manifold]]s, was tailored to the authors' Math 55 syllabus and served for many years as an assigned textbook.  Over the years, instructors for Math 55&lt;ref&gt;{{Cite web|url=http://isites.harvard.edu/fs/docs/icb.topic92739.files/descr.pdf|title=Math 55 Course Description, 2006-2007|last=|first=|date=|website=|access-date=9 Jul 2017}}{{dead link|date=January 2018|bot=medic}}{{cbignore|bot=medic}}&lt;/ref&gt; and Math 25&lt;ref name=":0" /&gt; have also selected [[Walter Rudin|Rudin]]'s ''Principles of Mathematical Analysis'',&lt;ref&gt;{{Cite book|url=https://archive.org/details/1979RudinW|title=Principles of Mathematical Analysis|last=Rudin|first=Walter|publisher=McGraw-Hill|year=1976|isbn=0-07-054235-X|edition=3rd|location=New York|pages=|orig-year=1953}}&lt;/ref&gt; [[Michael Spivak|Spivak]]'s ''[[Calculus on Manifolds (book)|Calculus on Manifolds]]'',&lt;ref&gt;{{Cite book|url=https://archive.org/details/SpivakM.CalculusOnManifolds_201703|title=Calculus on Manifolds|last=Spivak|first=Michael|publisher=Addison-Wesley|year=1965|isbn=0-8053-9021-9|location=Reading, Massachusetts|pages=}}&lt;/ref&gt; Axler's ''Linear Algebra Done Right'',&lt;ref&gt;{{Cite book|title=Linear Algebra Done Right|last=Axler|first=Sheldon|publisher=Springer|year=2005|isbn=0387982582|edition=2nd|location=New York|pages=}}&lt;/ref&gt; and [[Paul Halmos|Halmos]]'s ''Finite-Dimensional Vector Spaces''&lt;ref&gt;{{Cite book|url=https://archive.org/details/HalmosP.R.FiniteDimensionalVectorSpaces.SpringerVerlag205s_201703|title=Finite-Dimensional Vector Spaces|last=Halmos|first=Paul R.|publisher=D. Van Nostrand Company|year=1958|isbn=0-387-90093-4|edition=2nd|location=New York|pages=|orig-year=1942}}&lt;/ref&gt; as textbooks or references.

From 2007 onwards, the scope of the course (along with that of Math 25) was changed to more strictly cover the contents of four semester-long courses in two semesters: Math 25a (linear algebra) and Math 122 (group theory) in Math 55a; and Math 25b (calculus, real analysis) and Math 113 (complex analysis) in Math 55b. The name was also changed to "Honors Abstract Algebra" (Math 55a) and "Honors Real and Complex Analysis" (Math 55b).  Fluency in formulating and writing mathematical proofs is listed as a course prerequisite for Math 55, while such experience is considered "helpful" but not required for Math 25.&lt;ref name="which2155" /&gt; In practice, students of Math 55 have usually had extensive experience in proof writing and abstract mathematics, and many are winners of prestigious national or international mathematical olympiads (e.g., [[United States of America Mathematical Olympiad|USAMO]] or [[International Mathematical Olympiad|IMO]]), while typical students of Math 25 have also had previous exposure to proof writing through mathematical contests or university level proof-based courses.

==Notable alumni==
[[Problem set]]s are expected to take from 24 to 60 hours per week to complete,&lt;ref name="which2155" /&gt; although some claim that it is closer to 20 hours.&lt;ref&gt;http://www.thecrimson.com/article/1999/1/6/math-55-rite-of-passage-for/?page=4&lt;/ref&gt; Of those students who could handle the workload, some became math or physics professors,&lt;ref name="Williams" /&gt; including members of the Harvard Math Department such as [[Benedict Gross]] and [[Joe Harris (mathematician)|Joe Harris]]; also, Harvard physics professor [[Lisa Randall]] '84&lt;ref name="Rosenman"&gt;{{cite news|url=http://www.thecrimson.com/article/2009/6/2/class-of-1984-lisa-randall-as/ |title=Class of 1984: Lisa Randall |quote=As a college freshman, Lisa J. Randall '84 stood out for many reasons. In her first semester, she enrolled in Math 55 and Physics 55, the most difficult freshman math and physics classes offered.|date=June 2, 2009}}&lt;/ref&gt; and Harvard economics professor [[Andrei Shleifer]] '82.&lt;ref name="Bhayani"&gt;{{cite news|url=http://www.thecrimson.com/article/2007/6/4/andrei-shleifer-and-j-bradford-delong/|title=Andrei Shleifer and J. Bradford DeLong |quote=“Math 55 permanently disabused me of the idea of becoming a mathematician,” Shleifer says. Though he would tough the class out and remain a math major, he says he became drawn to economics—a subject he knew nothing of in high school—after taking some introductory courses in the field.  |date=June 4, 2007}}&lt;/ref&gt; Although a 2006 ''[[Harvard Crimson]]'' article alleged that only 17 women completed the class between 1990 and 2006,&lt;ref name="Logan"/&gt; in fact 39 women completed 55a (the first of the two semesters), and 26 completed 55b.&lt;ref name="registrar"&gt;{{cite web | title = Registrar data for Math 55 | url=http://www.math.berkeley.edu/~williams/55.xls}}, hosted by [[Lauren Williams]]&lt;/ref&gt; [[Math 25]] has more women: in 1994–95, Math 55 had no women, while Math 25 had about 10 women in the 55 person course.&lt;ref name="Chen"/&gt;

There are also Math 55 alumni who went on to be professors in other universities. These include Fields-medalist [[Manjul Bhargava]], who is now a professor at [[Princeton University]], as well as [[Kiran Kedlaya]], now at the [[University of California, San Diego]].

In addition to these professors, past students of Math 55 include [[Bill Gates]]&lt;ref&gt;{{cite book|last=Manes|first=Stephen|author2=Paul Andrews|title=Gates: how Microsoft's mogul reinvented an industry--and made himself the richest man in America|publisher=[[Doubleday (publisher)|Doubleday]]|year=1993|pages=58|isbn=0-385-42075-7}}&lt;/ref&gt; and [[Richard Stallman]].&lt;ref name="Williams" /&gt;

Demographics of students taking this course over the years has been used to study causes of gender and race differences in the fields of mathematics and technology.&lt;ref&gt;{{cite news|url=http://www.aei.org/publication/why-cant-a-woman-be-more-like-a-man-3/|title=Why Can’t a Woman Be More Like a Man?|first=Christina Hoff|date=March–April 2008|work=[[The American (magazine)|The American]]|quote=Math 55 is advertised in the Harvard catalog as “probably the most difficult undergraduate math class in the country.” It is legendary among high school math prodigies, who hear terrifying stories about it in their computer camps and at the Math Olympiads. Some go to Harvard just to have the opportunity to enroll in it. Its formal title is “Honors Advanced Calculus and Linear Algebra,” but it is also known as “math boot camp” and “a cult.” The two-semester freshman course meets for three hours a week, but, as the catalog says, homework for the class takes between 24 and 60 hours a week.|author-link=Christina Hoff Sommers|via=|author=Sommers|accessdate=2009-08-13}}&lt;/ref&gt; 

==Historical instances of Math 55==
{| class="wikitable"
|-
!Year !! Instructor !! Course materials
|-
|1996–1997 || Alexander Polishchuk ||
|-
|1997–1998 || [[Pavel Etingof]] ||
|-
|1998–1999 || [[Pavel Etingof]] ||
|-
|1999-2000
|[[Noam Elkies]]
|
|-
|2000–2001 || [[Wilfried Schmid]] ||

|-
|2002–2003 || [[Noam Elkies]] || 55a&lt;ref&gt;{{cite web |url=http://www.math.harvard.edu/~elkies/M55a.02/index.html |title=Math 55a: Honors Advanced Calculus and Linear Algebra (Fall 2002)}}&lt;/ref&gt; b&lt;ref&gt;{{cite web |url=http://www.math.harvard.edu/~elkies/M55b.02/index.html |title=Math 55b: Honors Advanced Calculus and Linear Algebra (Spring 200[2-]3)}}&lt;/ref&gt;
|-
|2003–2004 || [[Yum-Tong Siu]] || 55a&lt;ref&gt;{{cite web |url=http://abel.math.harvard.edu/archive/55a_fall_03/syllabus/index.html |title=Mathematics 55a Syllabus}}&lt;/ref&gt;
|-
|2005–2006 || [[Noam Elkies]] || 55a&lt;ref&gt;{{cite web |url=http://www.math.harvard.edu/~elkies/M55a.05/index.html |title=Math 55a: Honors Advanced Calculus and Linear Algebra (Fall 2005)}}&lt;/ref&gt; b
|-
|2008–2009 || [[Curtis T. McMullen]] || 55a&lt;ref&gt;{{cite web|url = http://www.math.harvard.edu/~ctm/home/text/class/harvard/55a/08/html/index.html |title=Math 55a}}&lt;/ref&gt; b&lt;ref&gt;{{cite web|url = http://www.math.harvard.edu/~ctm/home/text/class/harvard/55b/09/html/index.html |title=Math 55b}}&lt;/ref&gt;
|-
|2009–2010 || Curtis T. McMullen || 55a&lt;ref&gt;{{cite web|url = http://www.math.harvard.edu/~ctm/home/text/class/harvard/55a/09/html/index.html |title=Math 55a}}&lt;/ref&gt; b&lt;ref&gt;{{cite web|url = http://www.math.harvard.edu/~ctm/home/text/class/harvard/55b/10/html/index.html |title=Math 55b}}&lt;/ref&gt;
|-
|2010–2011 || [[Noam Elkies]] || 55a&lt;ref&gt;{{cite web|url = http://www.math.harvard.edu/~elkies/M55a.10/index.html |title=Math 55a: Honors Abstract Algebra (Fall 2010)}}&lt;/ref&gt; b&lt;ref&gt;{{cite web|url = http://www.math.harvard.edu/~elkies/M55b.10/index.html |title=Math 55b: Honors Real and Complex Analysis (Spring [2010–]2011)}}&lt;/ref&gt;
|-
|2011–2012 || [[Yum-Tong Siu]] ||
|-
|2014–2015 || [[Dennis Gaitsgory]] ||
|-
|2015–2016 || [[Yum-Tong Siu]] ||
|-
|2016-2018 || [[Noam Elkies]] || 55a&lt;ref&gt;{{cite web|url = http://www.math.harvard.edu/~elkies/M55a.16/index.html |title=Math 55a: Honors Abstract Algebra (Fall 2016)}}&lt;/ref&gt;
|-
|2018-2019
|[[Joe Harris (mathematician)]]
|
|}

==Fictional references==
Math 55, along with several other high-level mathematics courses, were brought up by [[Spencer Reid|Dr. Spencer Reid]] in a 2015 episode of ''[[Criminal Minds]]'' entitled "Mr. Scratch."&lt;ref&gt;{{cite web|title=Criminal Minds Season 10 Episode 21: "Mr. Scratch" Quotes|url=http://www.tvfanatic.com/quotes/shows/criminal-minds/episodes/mr-scratch/|website=TV Fanatic|accessdate=16 December 2015}}&lt;/ref&gt;

==References==
{{reflist|2}}

{{refbegin|2}}
* [http://www.math.harvard.edu/~shlomo/docs/Advanced_Calculus.pdf Advanced_Calculus-Lynn Loomis and Shlomo Sternberg]
* [http://www.math.harvard.edu/pamphlets/freshmenguide.html Harvard Mathematics Department 21, 23, 25, or 55?] – Harvard Math Freshmen Guide pamphlet
* [http://www.ajorza.org/courses/math/m55/ Problem sets from Math 55 from 1999-2006]
* 1983: [http://www.thecrimson.com/article/1983/2/14/math-faculty-committee-proposes-curriculum-revision/ Harvard Crimson, Feb 14, 1983]
* 1994: [http://www.thecrimson.com/article/1994/10/20/in-math-department-its-mostly-male/ In Math Department, It's Mostly Male, Harvard Crimson, Oct. 20, 1994]
* 1999: [http://www.thecrimson.com/article/1999/1/6/math-55-rite-of-passage-for/]
* 2000: [http://www.hcs.harvard.edu/~satirev/old/vol1no2-math.html Math 55 student gets laid, considered for Fields Medal, Satire V (humor magazine), 2000]
* 2006: [http://www.thecrimson.com/article/2006/12/6/burden-of-proof-at-1002-am Burden of Proof, December 2006, Harvard Crimson]
* 2005: [http://www.math.harvard.edu/~elkies/M55a.05/ Math 55a] – [[Noam Elkies]]
* 2009/10: [http://www.math.harvard.edu/~ctm/home/text/class/harvard/55a/09/html/index.html Math 55a], [http://www.math.harvard.edu/~ctm/home/text/class/harvard/55b/10/html/index.html Math 55b] – [[Curtis McMullen]]
* 2010/11: [http://www.math.harvard.edu/~elkies/M55a.10/ Math 55a], [http://www.math.harvard.edu/~elkies/M55b.10/ Math 55b] – [[Noam Elkies]]
{{refend}}

[[Category:Harvard University]]
[[Category:Mathematics education]]
[[Category:Undergraduate education in the United States]]</text>
      <sha1>j6axtjw2wlbyxjzl0iuxhwiikoaq4ir</sha1>
    </revision>
  </page>
  <page>
    <title>Multinomial distribution</title>
    <ns>0</ns>
    <id>1045553</id>
    <revision>
      <id>868858606</id>
      <parentid>867183644</parentid>
      <timestamp>2018-11-14T22:19:54Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13686">{{Probability distribution|
  pdf_image  =|
  cdf_image  =|
  name       =Multinomial|
  type       =mass|
  parameters =&lt;math&gt;n &gt; 0&lt;/math&gt; number of trials ([[integer]])&lt;br /&gt;&lt;math&gt;p_1, \ldots, p_k&lt;/math&gt; event probabilities (&lt;math&gt;\Sigma p_i = 1&lt;/math&gt;)|
  support    =&lt;math&gt;x_i \in \{0, \dots, n\}, \,\,\,\,i \in \{1,\dots,k\}&lt;/math&gt;&lt;br&gt;&lt;math&gt;\Sigma x_i = n\!&lt;/math&gt;|
  pdf        =&lt;math&gt;\frac{n!}{x_1!\cdots x_k!} p_1^{x_1} \cdots p_k^{x_k}&lt;/math&gt;|
  cdf        =|
  mean       =&lt;math&gt;E\{X_i\} = np_i&lt;/math&gt;|
  median     =|
  mode       =|
  variance   =&lt;math&gt;\textstyle{\mathrm{Var}}(X_i) = n p_i (1-p_i)&lt;/math&gt;&lt;br&gt;&lt;math&gt;\textstyle {\mathrm{Cov}}(X_i,X_j) = - n p_i p_j~~(i\neq j)&lt;/math&gt;|
  skewness   =|
  kurtosis   =|
  mgf        =&lt;math&gt;\biggl( \sum_{i=1}^k p_i e^{t_i} \biggr)^n&lt;/math&gt;|
  char       =&lt;math&gt; \left(\sum_{j=1}^k p_je^{it_j}\right)^n&lt;/math&gt; where &lt;math&gt;i^2= -1&lt;/math&gt;|
  pgf = &lt;math&gt;\biggl( \sum_{i=1}^k p_i z_i \biggr)^n\text{ for }(z_1,\ldots,z_k)\in\mathbb{C}^k&lt;/math&gt;|
  conjugate  =[[Dirichlet distribution|Dirichlet]]: &lt;math&gt;\mathrm{Dir}(\alpha+\beta)&lt;/math&gt;|
  entropy = &lt;math&gt; -\log(n!) - n\sum_{i=1}^kp_i\log(p_i)+\sum_{i=1}^k\sum_{x_i=0}^n\binom{n}{x_i}p_i^{x_i}(1-p_i)^{n-x_i}\log(x_i!)&lt;/math&gt;|
}}
In [[probability theory]], the '''multinomial distribution''' is a generalization of the [[binomial distribution]]. For example, it models the probability of counts for rolling a ''k''-sided die ''n'' times. For ''n'' [[statistical independence|independent]] trials each of which leads to a success for exactly one of ''k'' categories, with each category having a given fixed success probability, the multinomial distribution gives the probability of any particular combination of numbers of successes for the various categories.

When ''k'' is 2 and ''n'' is 1, the multinomial distribution is the [[Bernoulli distribution]]. When ''k'' is 2 and ''n'' is bigger than 1, it is the [[binomial distribution]]. When k is bigger than 2 and ''n'' is 1, it is the [[categorical distribution]].

The [[Bernoulli distribution]] models the outcome of a single [[Bernoulli trial]]. In other words, it models whether flipping a (possibly [[Fair coin|biased]]) coin one time will result in either a success (obtaining a head) or failure (obtaining a tail). The [[binomial distribution]] generalizes this to the number of heads from performing ''n'' independent flips (Bernoulli trials) of the same coin. The multinomial distribution models the outcome of ''n'' experiments, where the outcome of each trial has a [[categorical distribution]], such as rolling a ''k''-sided die ''n'' times.

Let ''k'' be a fixed finite number. Mathematically, we have ''k'' possible mutually exclusive outcomes, with corresponding probabilities ''p''&lt;sub&gt;1&lt;/sub&gt;, ..., ''p''&lt;sub&gt;''k''&lt;/sub&gt;, and ''n'' independent trials. Since the ''k'' outcomes are mutually exclusive and one must occur we have ''p''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;≥&amp;nbsp;0 for ''i''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;...,&amp;nbsp;''k'' and &lt;math&gt;\sum_{i=1}^k p_i = 1&lt;/math&gt;.  Then if the random variables ''X''&lt;sub&gt;''i''&lt;/sub&gt; indicate the number of times outcome number ''i'' is observed over the ''n'' trials, the vector ''X''&amp;nbsp;=&amp;nbsp;(''X''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''X''&lt;sub&gt;''k''&lt;/sub&gt;) follows a multinomial distribution with parameters ''n'' and '''p''', where '''p'''&amp;nbsp;=&amp;nbsp;(''p''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''p''&lt;sub&gt;''k''&lt;/sub&gt;). While the trials are independent, their outcomes ''X'' are dependent because they must be summed to n.

In some fields such as [[natural language processing]], categorical and multinomial distributions are synonymous and it is common to speak of a multinomial distribution when a [[categorical distribution]] is actually meant. This stems from the fact that it is sometimes convenient to express the outcome of a categorical distribution as a "1-of-K" vector (a vector with one element containing a 1 and all other elements containing a 0) rather than as an integer in the range &lt;math&gt;1 \dots K&lt;/math&gt;; in this form, a categorical distribution is equivalent to a multinomial distribution over a single trial.

==Specification==

===Probability mass function===
Suppose one does an experiment of extracting ''n'' balls of ''k'' different colors from a bag, replacing the extracted ball after each draw. Balls from the same color are equivalent. Denote the variable which is the number of extracted balls of color ''i'' (''i'' = 1, ..., ''k'') as ''X''&lt;sub&gt;''i''&lt;/sub&gt;, and denote as ''p''&lt;sub&gt;''i''&lt;/sub&gt; the probability that a given extraction will be in color ''i''. The [[probability mass function]] of this multinomial distribution is:

: &lt;math&gt; \begin{align}
f(x_1,\ldots,x_k;n,p_1,\ldots,p_k) &amp; {} = \Pr(X_1 = x_1 \text{ and } \dots \text{ and } X_k = x_k) \\
&amp; {} = \begin{cases} { \displaystyle {n! \over x_1!\cdots x_k!}p_1^{x_1}\times\cdots\times p_k^{x_k}}, \quad &amp;
\text{when } \sum_{i=1}^k x_i=n \\  \\
0 &amp; \text{otherwise,} \end{cases}
\end{align}
&lt;/math&gt;

for non-negative integers ''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''k''&lt;/sub&gt;.

The probability mass function can be expressed using the [[gamma function]] as:

:&lt;math&gt;f(x_1,\dots, x_{k}; p_1,\ldots, p_k) = \frac{\Gamma(\sum_i x_i + 1)}{\prod_i \Gamma(x_i+1)} \prod_{i=1}^k p_i^{x_i}.&lt;/math&gt;

This form shows its resemblance to the [[Dirichlet distribution]] which is its [[conjugate prior]].

==Visualization==

=== As slices of generalized Pascal's triangle ===

Just like one can interpret the [[binomial distribution]] as (normalized) one-dimensional (1D) slices of [[Pascal's triangle]], so too can one interpret the multinomial distribution as 2D (triangular) slices of [[Pascal's pyramid]], or 3D/4D/+ (pyramid-shaped) slices of higher-dimensional analogs of Pascal's triangle. This reveals an interpretation of the [[Range (mathematics)|range]] of the distribution: discretized equilaterial "pyramids" in arbitrary dimension—i.e. a [[simplex]] with a grid.

=== As polynomial coefficients ===

Similarly, just like one can interpret the [[binomial distribution]] as the polynomial coefficients of &lt;math&gt;(p x_1 + (1-p) x_2)^n&lt;/math&gt; when expanded, one can interpret the multinomial distribution as the coefficients of &lt;math&gt;(p_1 x_1 + p_2 x_2 + p_3 x_3 + \cdots + p_k x_k)^n&lt;/math&gt; when expanded. (Note that just like the binomial distribution, the coefficients must sum to 1.) This is the origin of the name "''multinomial'' distribution".

==Properties==

The [[Expected value|expected]] number of times the outcome ''i'' was observed over ''n'' trials is

:&lt;math&gt;\operatorname{E}(X_i) = n p_i.\,&lt;/math&gt;

The [[covariance matrix]] is as follows.  Each diagonal entry is the [[variance]] of a binomially distributed random variable, and is therefore

:&lt;math&gt;\operatorname{var}(X_i)=np_i(1-p_i).\,&lt;/math&gt;

The off-diagonal entries are the [[covariance]]s:

:&lt;math&gt;\operatorname{cov}(X_i,X_j)=-np_i p_j\,&lt;/math&gt;

for ''i'', ''j'' distinct.

All covariances are negative because for fixed ''n'', an increase in one component of a multinomial vector requires a decrease in another component.

When these expressions are combined into a matrix with ''i, j'' element &lt;math&gt;\operatorname{cov} (X_i,X_j),&lt;/math&gt; the result is a ''k'' &amp;times; ''k'' [[Positive-definite matrix#Negative-definite, semidefinite and indefinite matrices|positive-semidefinite]] [[covariance matrix]] of rank ''k''&amp;nbsp;&amp;minus;&amp;nbsp;1. In the special case where ''k''&amp;nbsp;=&amp;nbsp;''n'' and where the ''p''&lt;sub&gt;''i''&lt;/sub&gt; are all equal, the covariance matrix is the [[centering matrix]].

The entries of the corresponding [[Correlation matrix#Correlation matrices|correlation matrix]] are

:&lt;math&gt;\rho(X_i,X_i) = 1.&lt;/math&gt;

:&lt;math&gt;\rho(X_i,X_j) = \frac{\operatorname{cov}(X_i,X_j)}{\sqrt{\operatorname{var}(X_i)\operatorname{var}(X_j)}} = \frac{-p_i  p_j}{\sqrt{p_i(1-p_i) p_j(1-p_j)}} = -\sqrt{\frac{p_i  p_j}{(1-p_i)(1-p_j)}}.&lt;/math&gt;

Note that the sample size drops out of this expression.

Each of the ''k'' components separately has a binomial distribution with parameters ''n'' and ''p''&lt;sub&gt;''i''&lt;/sub&gt;, for the appropriate value of the subscript ''i''.

The [[Support (mathematics)|support]] of the multinomial distribution is the set

: &lt;math&gt;\{(n_1,\dots,n_k)\in \mathbb{N}^k \mid  n_1+\cdots+n_k=n\}.\,&lt;/math&gt;

Its number of elements is

: &lt;math&gt;{n+k-1 \choose k-1}.&lt;/math&gt;

=== Matrix notation ===

In matrix notation, 
:&lt;math&gt;\operatorname{E}(\mathbf{X}) = n \mathbf{p},\,&lt;/math&gt;

and 
:&lt;math&gt;\operatorname{var}(\mathbf{X}) = n \lbrace \operatorname{diag}(\mathbf{p}) - \mathbf{p} \mathbf{p}^{\rm T} \rbrace ,\,&lt;/math&gt;

with {{math|'''p'''&lt;sup&gt;T&lt;/sup&gt;}} = the row vector transpose of the column vector {{math|'''p'''}}.

==Example==

Suppose that in a three-way election for a large country, candidate A received 20% of the votes, candidate B received 30% of the votes, and candidate C received 50% of the votes.  If six voters are selected randomly, what is the probability that there will be exactly one supporter for candidate A, two supporters for candidate B and three supporters for candidate C in the sample?

''Note: Since we’re assuming that the voting population is large, it is reasonable and permissible to think of the probabilities as unchanging once a voter is selected for the sample.  Technically speaking this is sampling without replacement, so the correct distribution is the [[Hypergeometric distribution#Multivariate hypergeometric distribution|multivariate hypergeometric distribution]], but the distributions converge as the population grows large.''

: &lt;math&gt; \Pr(A=1,B=2,C=3) = \frac{6!}{1! 2! 3!}(0.2^1) (0.3^2) (0.5^3) = 0.135 &lt;/math&gt;

==Sampling from a multinomial distribution==

First, reorder the parameters &lt;math&gt;p_1, \ldots, p_k&lt;/math&gt; such that they are sorted in descending order (this is only to speed up computation and not strictly necessary). Now, for each trial, draw an auxiliary variable ''X'' from a uniform (0,&amp;nbsp;1) distribution. The resulting outcome is the component

: &lt;math&gt;j = \min \left\{ j' \in \{1,\dots,k\} : \left(\sum_{i=1}^{j'} p_i\right) - X \geq 0 \right\}.&lt;/math&gt;

{''X''&lt;sub&gt;''j''&lt;/sub&gt; = 1, ''X''&lt;sub&gt;''k''&lt;/sub&gt; = 0 for ''k''&amp;nbsp;≠&amp;nbsp;''j'' } is one observation from the multinomial distribution with &lt;math&gt;p_1, \ldots, p_k&lt;/math&gt; and ''n''&amp;nbsp;=&amp;nbsp;1.  A sum of independent repetitions of this experiment is an observation from a multinomial distribution with ''n'' equal to the number of such repetitions.

==To simulate a multinomial distribution==

Various methods may be used to simulate a multinomial distribution. A very simple one is to use a random number generator to generate numbers between 0 and&amp;nbsp;1. First, we divide the interval from 0 to 1 in&amp;nbsp;''k'' subintervals equal in size to the probabilities of the ''k'' categories. Then, we generate a random number for each of n trials and use a logical test to classify the virtual measure or observation in one of the categories.

'''Example'''

If we have :

{| class="wikitable"
|-
| '''Categories''' || 1|| 2|| 3|| 4|| 5|| 6
|-
| '''Probabilities'''|| 0.15|| 0.20 || 0.30|| 0.16|| 0.12|| 0.07
|-
| '''Superior limits of subintervals'''|| 0.15|| 0.35|| 0.65|| 0.81|| 0.93|| 1.00
|}

Then, with a software like Excel, we may use the following recipe:

{| class="wikitable"
|-
| '''Cells :'''|| Ai|| Bi|| Ci|| ... || Gi
|-
| '''Formulae :''' || Rand()|| =If($Ai&lt;0.15;1;0)|| =If(And($Ai&gt;=0.15;$Ai&lt;0.35);1;0)|| ... || =If($Ai&gt;=0.93;1;0)
|}

After that, we will use functions such as SumIf to accumulate the observed results by category and to calculate the estimated covariance matrix for each simulated sample.

Another way is to use a discrete random number generator. In that case, the categories must be labeled or relabeled with numeric values.

In the two cases, the result is a multinomial distribution with ''k'' categories. This is equivalent, with a continuous random distribution, to simulate ''k'' independent standardized normal distributions, or a multinormal distribution N(0,I) having ''k'' components identically distributed and statistically independent.

Since the counts of all categories have to sum to the number of trials, the counts of the categories are always negatively correlated.&lt;ref&gt;{{Cite web|url=https://onlinecourses.science.psu.edu/stat504/node/40|title=1.7 - The Multinomial Distribution {{!}} STAT 504|website=onlinecourses.science.psu.edu|access-date=2016-09-11}}&lt;/ref&gt;

==Related distributions==
* When ''k'' = 2, the multinomial distribution is the [[binomial distribution]].
* [[Categorical distribution]], the distribution of each trial; for ''k'' = 2, this is the [[Bernoulli distribution]].
* The [[Dirichlet distribution]] is the [[conjugate prior]] of the multinomial in [[Bayesian statistics]].
* [[Dirichlet-multinomial distribution]].
* [[Beta-binomial model]].
* [[Negative multinomial distribution]]
* [[Hardy–Weinberg principle]] (it is a trinomial distribution with probabilities &lt;math&gt;(\theta^2, 2 \theta (1-\theta), (1-\theta)^2) &lt;/math&gt;)

==References==
{{Reflist}}

*{{cite book
| last1 = Evans
| first1 = Morton
|last2= Hastings |first2=Nicholas
|last3= Peacock |first3= Brian
| title = Statistical Distributions
| publisher = Wiley
| year = 2000
| location = New York
| pages = 134–136
| id = 3rd ed.
| isbn = 0-471-37124-6 }}
* Weisstein, Eric W. "Multinomial Distribution." From MathWorld--A Wolfram Web Resource [http://mathworld.wolfram.com/MultinomialDistribution.html]
{{ProbDistributions|multivariate}}

{{DEFAULTSORT:Multinomial Distribution}}
[[Category:Discrete distributions]]
[[Category:Multivariate discrete distributions]]
[[Category:Factorial and binomial topics]]
[[Category:Exponential family distributions]]</text>
      <sha1>rpv8sswjd96pltbajyoobuxl6qp8x9d</sha1>
    </revision>
  </page>
  <page>
    <title>Newman–Penrose formalism</title>
    <ns>0</ns>
    <id>6176811</id>
    <revision>
      <id>868881351</id>
      <parentid>867229363</parentid>
      <timestamp>2018-11-15T01:35:13Z</timestamp>
      <contributor>
        <username>Cherkash</username>
        <id>10363</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26453">The '''Newman–Penrose''' ('''NP''') '''formalism'''&lt;ref name=NP1&gt;{{cite journal | author= Ezra T. Newman and Roger Penrose | title=An Approach to Gravitational Radiation by a Method of Spin Coefficients | journal=Journal of Mathematical Physics | year=1962 | volume=3 | issue=3 | pages=566–768 | doi=10.1063/1.1724257 |bibcode = 1962JMP.....3..566N }}  The original paper by Newman and Penrose, which introduces the formalism, and uses it to derive example results.&lt;/ref&gt;&lt;ref name=NP2&gt;Ezra T Newman, Roger Penrose. ''Errata: An Approach to Gravitational Radiation by a Method of Spin Coefficients''.  Journal of Mathematical Physics, 1963, '''4'''(7): 998.&lt;/ref&gt; is a set of notation developed by [[Ezra T. Newman]] and [[Roger Penrose]] for [[general relativity]] (GR).  Their notation is an effort to treat general relativity in terms of [[spinor]] notation, which introduces [[complex number|complex]] forms of the usual variables used in GR. The NP formalism is itself a special case of the [[tetrad formalism]],&lt;ref&gt;{{cite book |last=Chandrasekhar |first=S. |authorlink=Subrahmanyan Chandrasekhar |title=The Mathematical Theory of Black Holes |year=1998 |publisher=Oxford University Press |isbn=0-19850370-9 |edition=Reprinted |url=http://www.oup.com/us/catalog/general/subject/Physics/Relativity/?view=usa&amp;ci=9780198503705 |accessdate=13 May 2013 |page=40 |quote=The Newman–Penrose formalism is a tetrad formalism with a special choice of the basis vectors.}}&lt;/ref&gt;  where the tensors of the theory are projected onto a complete vector basis at each point in spacetime. Usually this vector basis is chosen to reflect some symmetry of the space-time, leading to simplified expressions for physical observables. In the case of the NP formalism, the vector basis chosen is a [[null tetrad]]: a set of four null vectors—two real, and a complex-conjugate pair. The two real members asymptotically point radially inward and radially outward, and the formalism is well adapted to treatment of the propagation of radiation in curved spacetime. The most often-used variables in the formalism are the [[Weyl scalars]], derived from the [[Weyl tensor]].  In particular, it can be shown that one of these scalars--&lt;math&gt;\Psi_4&lt;/math&gt; in the appropriate frame—encodes the outgoing [[gravitational radiation]] of an asymptotically flat system.&lt;ref&gt;{{cite journal | author=Saul Teukolsky | title=Perturbations of a rotating black hole | journal=Astrophysical Journal | year=1973 | volume=185 | pages=635–647 | doi=10.1086/152444 | bibcode=1973ApJ...185..635T}}&lt;/ref&gt;

Newman and Penrose introduced the following functions as primary quantities using this tetrad:&lt;ref name="NP1"/&gt;&lt;ref name="NP2"/&gt;
* Twelve complex spin coefficients (in three groups) which describe the change in the tetrad from point to point: &lt;math&gt;\kappa, \rho, \sigma, \tau\,;  \lambda, \mu, \nu, \pi\,; \epsilon, \gamma, \beta, \alpha. &lt;/math&gt;.
* Five complex functions encoding Weyl tensors in the tetrad basis: &lt;math&gt;\Psi_0, \ldots, \Psi_4&lt;/math&gt;.
* Ten functions encoding [[Ricci tensor]]s in the tetrad basis: &lt;math&gt; \Phi_{00}, \Phi_{11}, \Phi_{22}, \Lambda &lt;/math&gt; (real); &lt;math&gt; \Phi_{01}, \Phi_{10}, \Phi_{02}, \Phi_{20}, \Phi_{12}, \Phi_{21} &lt;/math&gt; (complex).

In many situations—especially algebraically special spacetimes or vacuum spacetimes—the Newman–Penrose formalism simplifies dramatically, as many of the functions go to zero.  This simplification allows for various theorems to be proven more easily than using the standard form of Einstein's equations.

In this article, we will only employ the [[tensor]]ial rather than [[spinor]]ial version of NP formalism, because the former is easier to understand and more popular in relevant papers. One can refer to ref.&lt;ref name=ODonnell&gt;Peter O'Donnell. ''Introduction to 2-Spinors in General Relativity''. Singapore: World Scientific, 2003.&lt;/ref&gt; for a unified formulation of  these two versions.

==Null tetrad and sign convention==
The formalism is developed for four-dimensional spacetime, with a Lorentzian-signature metric.  At each point, a [[Cartan connection applications|tetrad]] (set of four vectors) is introduced.  The first two vectors, &lt;math&gt;l^\mu&lt;/math&gt; and &lt;math&gt;n^\mu&lt;/math&gt; are just a pair of standard (real) [[null vectors]] such that &lt;math&gt;l^a n_a = -1&lt;/math&gt;.  For example, we can think in terms of spherical coordinates, and take &lt;math&gt;l^a&lt;/math&gt; to be the outgoing null vector, and &lt;math&gt;n^a&lt;/math&gt; to be the ingoing null vector.  A complex null vector is then constructed by combining a pair of real, orthogonal unit space-like vectors.  In the case of spherical coordinates, the standard choice is
:&lt;math&gt;m^\mu = \frac{1}{\sqrt{2}}\left( \hat{\theta} + i \hat{\phi} \right)^\mu\ .&lt;/math&gt;
The complex conjugate of this vector then forms the fourth element of the tetrad.

Two sets of signature and normalization conventions are in use for NP formalism: &lt;math&gt;\{(+,-,-,-); l^a n_a=1\,,m^a \bar{m}_a=-1\}&lt;/math&gt; and &lt;math&gt;\{(-,+,+,+); l^a n_a=-1\,,m^a \bar{m}_a=1\}&lt;/math&gt;. The former is the original one that was adopted when NP formalism was developed&lt;ref name="NP1"/&gt;&lt;ref name="NP2"/&gt; and has been widely used&lt;ref name=NP3&gt;Subrahmanyan Chandrasekhar. ''The Mathematical Theory of Black Holes''. Chicago: University of Chikago Press, 1983.&lt;/ref&gt;&lt;ref name=GWaveNP&gt;J B Griffiths. ''Colliding Plane Waves in General Relativity''. Oxford: Oxford University Press, 1991.&lt;/ref&gt; in black-hole physics, gravitational waves and various other areas in general relativity. However, it is the latter convention that is usually employed in contemporary study of black holes from quasilocal perspectives&lt;ref&gt;Ivan Booth. ''Black hole boundaries''. Canadian Journal of Physics, 2005, '''83'''(11): 1073-1099. [arxiv.org/abs/gr-qc/0508107 arXiv:gr-qc/0508107v2]&lt;/ref&gt; (such as isolated horizons&lt;ref name=refIH&gt;Abhay Ashtekar, Christopher Beetle, Jerzy Lewandowski. ''Geometry of generic isolated horizons''.  Classical and Quantum Gravity, 2002, '''19'''(6): 1195-1225. [https://arxiv.org/abs/gr-qc/0111067 arXiv:gr-qc/0111067v2]&lt;/ref&gt; and dynamical horizons&lt;ref&gt;Abhay Ashtekar, Badri Krishnan. ''Dynamical horizons: energy, angular momentum, fluxes and balance laws''. Physical Review Letters, 2002, '''89'''(26): 261101. [arxiv.org/abs/gr-qc/0207080 arXiv:gr-qc/0207080v3]&lt;/ref&gt;&lt;ref&gt;Abhay Ashtekar, Badri Krishnan. ''Dynamical horizons and their properties''. Physical Review D, 2003, '''68'''(10): 104030. [arxiv.org/abs/gr-qc/0308033 arXiv:gr-qc/0308033v4]&lt;/ref&gt;). In this article, we will utilize &lt;math&gt;\{(-,+,+,+); l^a n_a=-1\,,m^a \bar{m}_a=1\}&lt;/math&gt; for a systematic review of the NP formalism (see also refs.&lt;ref name=refNP1&gt;Jeremy Bransom Griffiths, Jiri Podolsky. ''Exact Space-Times in Einstein's General Relativity''. Cambridge: Cambridge University Press, 2009. Chapter 2.&lt;/ref&gt;&lt;ref name=refNP2&gt;Valeri P Frolov, Igor D Novikov. ''Black Hole Physics: Basic Concepts and New Developments''. Berlin: Springer, 1998. Appendix E.&lt;/ref&gt;&lt;ref name=refNP3&gt;Abhay Ashtekar, Stephen Fairhurst, Badri Krishnan. ''Isolated horizons: Hamiltonian evolution and the first law''. Physical Review D, 2000, '''62'''(10): 104025. Appendix B. [https://arxiv.org/abs/gr-qc/0005083 gr-qc/0005083]&lt;/ref&gt;).

It's important to note that, when switching from &lt;math&gt;\{(+,-,-,-)\,,l^a n_a=1\,,m^a \bar{m}_a=-1\}&lt;/math&gt; to &lt;math&gt;\{(-,+,+,+)\,,l^a n_a=-1\,,m^a \bar{m}_a=1\}&lt;/math&gt;, definitions of the spin coefficients,  Weyl-NP scalars &lt;math&gt;\Psi_{i}&lt;/math&gt; and Ricci-NP scalars &lt;math&gt;\Phi_{ij}&lt;/math&gt; need to change their signs; this way, the Einstein-Maxwell equations can be left unchanged.

In NP formalism, the complex null tetrad contains two real null (co)vectors &lt;math&gt;\{\ell\,,n\}&lt;/math&gt; and two complex null (co)vectors &lt;math&gt;\{m\,, \bar m\}&lt;/math&gt;. Being ''null'' (co)vectors, ''self''-normalization of &lt;math&gt;\{\ell\,,n\}&lt;/math&gt; are naturally vanishes,

&lt;br /&gt;
&lt;math&gt;l_a l^a=n_a n^a=m_a m^a=\bar{m}_a \bar{m}^a=0&lt;/math&gt;,

so the following two pairs of ''cross''-normalization are adopted

&lt;br /&gt;
&lt;math&gt;l_a n^a=-1=l^a n_a\,,\quad m_a \bar{m}^a=1=m^a \bar{m}_a\,,&lt;/math&gt;

while  contractions between the two pairs are also vanishing,

&lt;br /&gt;
&lt;math&gt;l_a m^a=l_a \bar{m}^a=n_a m^a=n_a \bar{m}^a=0&lt;/math&gt;.

Here the indices can be raised and lowered by the global [[Metric tensor|metric]] &lt;math&gt;g_{ab}&lt;/math&gt;  which in turn can be obtained via

&lt;br /&gt;
&lt;math&gt;g_{ab}=-l_a  n_b - n_a  l_b +m_a  \bar{m}_b +\bar{m}_a  m_b\,,  \quad g^{ab}=-l^a  n^b - n^a  l^b +m^a  \bar{m}^b +\bar{m}^a  m^b\,.&lt;/math&gt;

== NP quantities and tetrad equations ==

=== Four directional derivatives ===
First of all, there are four [[Directional derivative|directional]] [[covariant derivative]]s along with each tetrad vector,

&lt;br /&gt;
&lt;math&gt;D:= \nabla_\ell=l^a\nabla_a\,,\; \Delta:= \nabla_\mathbf{n}=n^a\nabla_a\,, \;\delta := \nabla_\mathbf{m}=m^a\nabla_a\,, \;\bar{\delta} := \nabla_\mathbf{\bar{m}}=\bar{m}^a\nabla_a\,,&lt;/math&gt;

which are reduced to &lt;math&gt;\{D=l^a\partial_a\,, \Delta=n^a\partial_a\,,\delta=m^a\partial_a\,,\bar{\delta}=\bar{m}^a\partial_a \}&lt;/math&gt; when acting on ''scalar'' functions.

=== Twelve spin coefficients ===
In NP formalism, instead of using index notations as in [[orthogonal tetrad]]s,  each [[Christoffel symbols#Ricci rotation coefficients (asymmetric definition)|Ricci rotation coefficient]] &lt;math&gt;\gamma_{ijk}&lt;/math&gt; in the null tetrad is assigned a lower-case Greek letter, which constitute the 12 complex ''spin coefficients'' (in three groups),

&lt;br /&gt;
&lt;math&gt; \kappa:= -m^aDl_a=-m^a l^b \nabla_b l_a\,,\quad \tau:= -m^a\Delta l_a=-m^a n^b \nabla_b l_a\,,&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;  \sigma:= -m^a\delta l_a=-m^a m^b\nabla_b l_a\,, \quad  \rho := -m^a\bar{\delta} l_a=-m^a \bar{m}^b \nabla_b l_a\,; &lt;/math&gt;

&lt;math&gt;\pi:= \bar{m}^aDn_a=\bar{m}^al^b\nabla_b n_a\,, \quad \nu:= \bar{m}^a\Delta n_a=\bar{m}^a n^b\nabla_b n_a\,, &lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\mu:= \bar{m}^a\delta n_a=\bar{m}^a m^b\nabla_b n_a\,, \quad \lambda:= \bar{m}^a\bar{\delta} n_a=\bar{m}^a \bar{m}^b \nabla_b n_a\,;&lt;/math&gt;

&lt;math&gt;\varepsilon:= -\frac{1}{2}\big(n^aDl_a-\bar{m}^aDm_a \big)=-\frac{1}{2}\big(n^al^b\nabla_b l_a-\bar{m}^al^b\nabla_b m_a \big)\,,&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\gamma:= -\frac{1}{2}\big(n^a\Delta l_a-\bar{m}^a\Delta m_a \big)= -\frac{1}{2}\big(n^a n^b\nabla_b l_a-\bar{m}^a n^b\nabla_b m_a \big)\,,&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\beta:= -\frac{1}{2}\big(n^a\delta l_a-\bar{m}^a\delta m_a \big)=-\frac{1}{2}\big(n^a m^b\nabla_b l_a-\bar{m}^am^b\nabla_b m_a \big)\,,&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\alpha:= -\frac{1}{2}\big(n^a\bar{\delta} l_a-\bar{m}^a\bar{\delta}m_a \big)=-\frac{1}{2}\big(n^a\bar{m}^b\nabla_b l_a-\bar{m}^a\bar{m}^b\nabla_b m_a \big)\,.&lt;/math&gt;

Spin coefficients are the primary quantities in NP formalism, with which all other NP quantities (as defined below) could be calculated indirectly using the NP field equations. Thus, NP formalism is sometimes referred to as ''spin-coefficient formalism'' as well.

=== Transportation equations ===
Apply the directional derivative operators to tetrad vectors and one could obtain the ''transportation/propagation equations'':&lt;ref name="ODonnell"/&gt;&lt;ref name="refNP2"/&gt;

&lt;br /&gt;
&lt;math&gt;D l^a=(\varepsilon+\bar{\varepsilon})l^a-\bar{\kappa}m^a-\kappa\bar{m}^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta l^a=(\gamma+\bar{\gamma})l^a-\bar{\tau}m^a-\tau\bar{m}^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta l^a =(\bar{\alpha}+\beta)l^a-\bar{\rho}m^a-\sigma\bar{m}^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\bar{\delta} l^a=(\alpha+\bar{\beta})l^a-\bar{\sigma}m^a-\rho\bar{m}^a\,;&lt;/math&gt;

&lt;math&gt;D n^a=\pi m^a+\bar{\pi}\bar{m}^a-(\varepsilon+\bar{\varepsilon})n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta n^a=\nu m^a+\bar{\nu}\bar{m}^a-(\gamma+\bar{\gamma})n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta n^a=\mu m^a+\bar{\lambda}\bar{m}^a-(\bar{\alpha}+\beta)n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\bar{\delta} n^a=\lambda m^a+\bar{\mu}\bar{m}^a-(\alpha+\bar{\beta})n^a\,;&lt;/math&gt;

&lt;math&gt;D m^a=(\varepsilon-\bar{\varepsilon})m^a+\bar{\pi}l^a-\kappa n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta m^a=(\gamma-\bar{\gamma})m^a+\bar{\nu}l^a-\tau n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta m^a=(\beta-\bar{\alpha})m^a+\bar{\lambda}l^a-\sigma n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\bar{\delta} m^a=(\alpha-\bar{\beta})m^a+\bar{\mu}l^a-\rho n^a\,;&lt;/math&gt;

&lt;math&gt;D \bar{m}^a=(\bar{\varepsilon}-\varepsilon)\bar{m}^a+\pi l^a-\bar{\kappa} n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta \bar{m}^a=(\bar{\gamma}-\gamma)\bar{m}^a+\nu l^a-\bar{\tau} n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta \bar{m}^a=(\beta-\bar{\alpha})\bar{m}^a+\mu l^a-\bar{\rho} n^a\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\bar{\delta} \bar{m}^a=(\alpha-\bar{\beta})\bar{m}^a+\lambda l^a-\bar{\sigma} n^a\,.&lt;/math&gt;

=== Commutators ===
The [[Metric compatibility|metric-compatibility]] or [[Torsion tensor|torsion-freeness]] of the covariant derivative is recast into the ''[[commutator]]s of the directional derivatives'',

&lt;br /&gt;
&lt;math&gt;\Delta D-D\Delta=(\gamma+\bar{\gamma})D+(\varepsilon+\bar{\varepsilon})\Delta-(\bar{\tau}+\pi)\delta-(\tau+\bar{\pi})\bar{\delta}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta D-D\delta=(\bar{\alpha}+\beta-\bar{\pi})D+\kappa\Delta-(\bar{\rho}+\varepsilon-\bar{\varepsilon})\delta-\sigma\bar{\delta}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta\Delta-\Delta\delta=-\bar{\nu}D+(\tau-\bar{\alpha}-\beta)\Delta+(\mu-\gamma+\bar{\gamma})\delta+\bar{\lambda}\bar{\delta}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\bar{\delta}\delta-\delta\bar{\delta}=(\bar{\mu}-\mu)D+(\bar{\rho}-\rho)\Delta+(\alpha-\bar{\beta})\delta-(\bar{\alpha}-\beta)\bar{\delta}\,,&lt;/math&gt;

which imply that

&lt;br /&gt;
&lt;math&gt;\Delta l^a-D n^a=(\gamma+\bar{\gamma})l^a+(\varepsilon+\bar{\varepsilon})n^a-(\bar{\tau}+\pi)m^a-(\tau+\bar{\pi})\bar{m}^a\,,&lt;/math&gt;&lt;br /&gt; 
&lt;math&gt;\delta l^a-D m^a=(\bar{\alpha}+\beta-\bar{\pi})l^a+\kappa n^a-(\bar{\rho}+\varepsilon-\bar{\varepsilon}) m^a-\sigma\bar{m}^a\,,&lt;/math&gt;&lt;br /&gt; 
&lt;math&gt;\delta n^a-\Delta m^a=-\bar{\nu}l^a+(\tau-\bar{\alpha}-\beta)n^a+(\mu-\gamma+\bar{\gamma})m^a+\bar{\lambda}\bar{m}^a\,,&lt;/math&gt;&lt;br /&gt; 
&lt;math&gt;\bar{\delta}m^a-\delta\bar{m}^a=(\bar{\mu}-\mu)l^a+(\bar{\rho}-\rho)n^a+(\alpha-\bar{\beta})m^a-(\bar{\alpha}-\beta)\bar{m}^a\,.&lt;/math&gt;

Note: (i) The above equations can be regarded either as implications of the commutators or combinations of the transportation equations; (ii) In these implied equations, the vectors &lt;math&gt;\{l^a,n^a,m^a,\bar{m}^a\}&lt;/math&gt; can be replaced by the covectors and the equations still hold.

=== Weyl–NP and Ricci–NP scalars ===
The 10 independent components of the [[Weyl tensor]] can be encoded into 5 complex [[Weyl scalar|Weyl-NP scalars]],

&lt;br /&gt;
&lt;math&gt;\Psi_0:= C_{abcd} l^a m^b l^c m^d\,,\quad \Psi_1:= C_{abcd} l^a n^b l^c m^d\,,\quad \Psi_2:= C_{abcd} l^a m^b\bar{m}^c n^d\,,&lt;/math&gt;
&lt;math&gt;\Psi_3:= C_{abcd} l^a n^b\bar{m}^c n^d\,,\quad \Psi_4:= C_{abcd} n^a \bar{m}^b n^c \bar{m}^d\,.&lt;/math&gt;

The 10 independent components of the [[Ricci tensor]] are encoded into 4 ''real'' scalars &lt;math&gt;\{\Phi_{00}&lt;/math&gt;, &lt;math&gt;\Phi_{11}&lt;/math&gt;, &lt;math&gt;\Phi_{22}&lt;/math&gt;, &lt;math&gt;\Lambda\}&lt;/math&gt; and 3 ''complex'' scalars &lt;math&gt;\{\Phi_{10},\Phi_{20},\Phi_{21} \}&lt;/math&gt; (with their complex conjugates),

&lt;br /&gt;
&lt;math&gt;\Phi_{00}:=\frac{1}{2}R_{ab}l^a l^b\,, \quad \Phi_{11}:=\frac{1}{4}R_{ab}(\,l^a n^b+m^a\bar{m}^b)\,, \quad\Phi_{22}:=\frac{1}{2}R_{ab}n^a n^b\,, \quad\Lambda:=\frac{R}{24}\,;&lt;/math&gt;

&lt;math&gt;\Phi_{01}:=\frac{1}{2}R_{ab}l^a m^b\,, \quad\; \Phi_{10}:=\frac{1}{2}R_{ab}l^a \bar{m}^b=\overline{\Phi_{01}}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Phi_{02}:=\frac{1}{2}R_{ab}m^a m^b\,, \quad \Phi_{20}:=\frac{1}{2}R_{ab}\bar{m}^a \bar{m}^b=\overline{\Phi_{02}}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Phi_{12}:=\frac{1}{2}R_{ab} m^a n^b\,, \quad\; \Phi_{21}:=\frac{1}{2}R_{ab} \bar{m}^a n^b=\overline{\Phi_{12}}\,.&lt;/math&gt;

In these definitions, &lt;math&gt;R_{ab}&lt;/math&gt; could be replaced by its [[Trace-free Ricci tensor|trace-free]] part &lt;math&gt;\displaystyle Q_{ab}=R_{ab}-\frac{1}{4}g_{ab}R&lt;/math&gt;&lt;ref name="refNP2"/&gt; or by the [[Einstein tensor]] &lt;math&gt;\displaystyle G_{ab}=R_{ab}-\frac{1}{2}g_{ab}R&lt;/math&gt; because of the normalization relations. Also, &lt;math&gt;\Phi_{11}&lt;/math&gt; is reduced to &lt;math&gt;\Phi_{11}=\frac{1}{2}R_{ab}l^a n^b=\frac{1}{2}R_{ab}m^a\bar{m}^a&lt;/math&gt; for [[Electrovacuum solution|electrovacuum]] (&lt;math&gt;\Lambda=0&lt;/math&gt;).

==Einstein–Maxwell–NP equations==

===NP field equations===
In a complex null tetrad, Ricci identities give rise to the following NP field equations connecting spin coefficients, Weyl-NP and Ricci-NP scalars (recall that in an orthogonal tetrad, Ricci rotation coefficients would respect [[Riemannian connection on a surface#Cartan structural equations|Cartan's first and second structure equations]]),&lt;ref name="ODonnell"/&gt;&lt;ref name="refNP2"/&gt;

&lt;br /&gt;
&lt;math&gt;D\rho -\bar{\delta}\kappa=(\rho^2+\sigma\bar{\sigma})+(\varepsilon+\bar{\varepsilon})\rho-\bar{\kappa}\tau-\kappa(3\alpha+\bar{\beta}-\pi)+\Phi_{00}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;D\sigma-\delta\kappa=(\rho+\bar{\rho})\sigma+(3\varepsilon-\bar{\varepsilon})\sigma-(\tau-\bar{\pi}+\bar{\alpha}+3\beta)\kappa+\Psi_0\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;D\tau-\Delta\kappa=(\tau+\bar{\pi})\rho+(\bar{\tau}+\pi)\sigma+(\varepsilon-\bar{\varepsilon})\tau-(3\gamma+\bar{\gamma})\kappa+\Psi_1+\Phi_{01}\,,&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;D\alpha-\bar{\delta}\varepsilon=(\rho+\bar{\varepsilon}-2\varepsilon)\alpha+\beta\bar{\sigma}-\bar{\beta}\varepsilon-\kappa\lambda-\bar{\kappa}\gamma+(\varepsilon+\rho)\pi+\Phi_{10}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;D\beta-\delta\varepsilon=(\alpha+\pi)\sigma+(\bar{\rho}-\bar{\varepsilon})\beta-(\mu+\gamma)\kappa-(\bar{\alpha}-\bar{\pi})\varepsilon+\Psi_1\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;D\gamma-\Delta\varepsilon=(\tau+\bar{\pi})\alpha+(\bar{\tau}+\pi)\beta-(\varepsilon+\bar{\varepsilon})\gamma-(\gamma+\bar{\gamma})\varepsilon+\tau\pi-\nu\kappa+\Psi_2+\Phi_{11}-\Lambda\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;D\lambda-\bar{\delta}\pi=(\rho\lambda+\bar{\sigma}\mu)+\pi^2+(\alpha-\bar{\beta})\pi-\nu\bar{\kappa}-(3\varepsilon-\bar{\varepsilon})\lambda+\Phi_{20}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;D\mu-\delta\pi=(\bar{\rho}\mu+\sigma\lambda)+\pi\bar{\pi}-(\varepsilon+\bar{\varepsilon})\mu-(\bar{\alpha}-\beta)\pi-\nu\kappa+\Psi_2+2\Lambda\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;D\nu-\Delta\pi=(\pi+\bar{\tau})\mu+(\bar{\pi}+\tau)\lambda+(\gamma-\bar{\gamma})\pi-(3\varepsilon+\bar{\varepsilon})\nu+\Psi_3+\Phi_{21}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta\lambda-\bar{\delta}\nu=-(\mu+\bar{\mu})\lambda-(3\gamma-\bar{\gamma})\lambda+(3\alpha+\bar{\beta}+\pi-\bar{\tau})\nu-\Psi_4\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta\rho-\bar{\delta}\sigma=\rho(\bar{\alpha}+\beta)-\sigma(3\alpha-\bar{\beta})+(\rho-\bar{\rho})\tau+(\mu-\bar{\mu})\kappa-\Psi_1+\Phi_{01}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta\alpha-\bar{\delta}\beta=(\mu\rho-\lambda\sigma)+\alpha\bar{\alpha}+\beta\bar{\beta}-2\alpha\beta+\gamma(\rho-\bar{\rho})+\varepsilon(\mu-\bar{\mu})-\Psi_2+\Phi_{11}+\Lambda\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta\lambda-\bar{\delta}\mu=(\rho-\bar{\rho})\nu+(\mu-\bar{\mu})\pi+(\alpha+\bar{\beta})\mu+(\bar\alpha-3\beta)\lambda-\Psi_3+\Phi_{21}\,,&lt;/math&gt;&lt;br /&gt;
&lt;math&gt;\delta\nu-\Delta\mu=(\mu^2+\lambda\bar{\lambda})+(\gamma+\bar{\gamma})\mu-\bar{\nu}\pi+(\tau-3\beta-\bar{\alpha})\nu+\Phi_{22}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta\gamma-\Delta\beta=(\tau-\bar{\alpha}-\beta)\gamma+\mu\tau-\sigma\nu-\varepsilon\bar{\nu}-(\gamma-\bar{\gamma}-\mu)\beta+\alpha\bar{\lambda}+\Phi_{12}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\delta\tau-\Delta\sigma=(\mu\sigma+\bar{\lambda}\rho)+(\tau+\beta-\bar{\alpha})\tau-(3\gamma-\bar{\gamma})\sigma-\kappa\bar{\nu}+\Phi_{02}\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta\rho-\bar{\delta}\tau=-(\rho\bar{\mu}+\sigma\lambda)+(\bar{\beta}-\alpha-\bar{\tau})\tau+(\gamma+\bar{\gamma})\rho+\nu\kappa-\Psi_2-2\Lambda\,,&lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta\alpha-\bar{\delta}\gamma=(\rho+\varepsilon)\nu-(\tau+\beta)\lambda+(\bar{\gamma}-\bar{\mu})\alpha+(\bar{\beta}-\bar{\tau})\gamma-\Psi_3\,.&lt;/math&gt;

Also, the Weyl-NP scalars &lt;math&gt;\Psi_{i}&lt;/math&gt; and the Ricci-NP scalars &lt;math&gt;\Phi_{ij}&lt;/math&gt; can be calculated indirectly from the above NP field equations after obtaining the spin coefficients rather than directly using their definitions.

===Maxwell–NP scalars, Maxwell equations in NP formalism===
The six independent components of the Faraday-Maxwell 2-form (i.e. the [[Electromagnetic tensor|electromagnetic field strength tensor]]) &lt;math&gt;F_{ab}&lt;/math&gt; can be encoded into three complex Maxwell-NP scalars&lt;ref name="refNP1"/&gt;

&lt;br /&gt;
&lt;math&gt;\phi_0:= F_{ab}l^a m^b \,,\quad \phi_1:= \frac{1}{2} F_{ab}\big(l^an^b + \bar{m}^a m^b \big)\,, \quad \phi_2 := F_{ab} \bar{m}^a n^b\,,&lt;/math&gt;

and therefore the eight real [[Maxwell equations]] &lt;math&gt;d\mathbf{F}=0&lt;/math&gt; and &lt;math&gt;d^{\star}\mathbf{F}=0&lt;/math&gt;  (as &lt;math&gt;\mathbf{F}=dA&lt;/math&gt;) can be transformed into four complex equations,

&lt;br /&gt;
&lt;math&gt;D\phi_1 -\bar{\delta}\phi_0=(\pi-2\alpha)\phi_0+2\rho\phi_1-\kappa\phi_2\,,  &lt;/math&gt;&lt;br /&gt; &lt;math&gt; D\phi_2 -\bar{\delta}\phi_1=-\lambda\phi_0+2\pi\phi_1+(\rho-2\varepsilon)\phi_2\,, &lt;/math&gt;&lt;br /&gt; &lt;math&gt;  \Delta\phi_0-\delta\phi_1=(2\gamma-\mu)\phi_0-2\tau\phi_1+\sigma\phi_2\,, &lt;/math&gt;&lt;br /&gt; &lt;math&gt;\Delta\phi_1-\delta\phi_2=\nu\phi_0-2\mu\phi_1+(2\beta-\tau)\phi_2\,, &lt;/math&gt;

&lt;br /&gt;
with the Ricci-NP scalars &lt;math&gt;\Phi_{ij}&lt;/math&gt; related to Maxwell scalars by&lt;ref name="refNP1"/&gt;

&lt;br /&gt;
&lt;math&gt;\Phi_{ij}=\,2\,\phi_i\,\overline{\phi_j}\,,\quad (i,j\in\{0,1,2\})\,.&lt;/math&gt;

It is worthwhile to point out that, the supplementary equation &lt;math&gt;\Phi_{ij}=2\,\phi_i\, \overline{\phi_j}&lt;/math&gt; is only valid for electromagnetic fields; for example, in the case of Yang-Mills fields there will be &lt;math&gt;\Phi_{ij}=\,\text{Tr}\,(\digamma_i \,\bar{\digamma}_j)&lt;/math&gt;  where &lt;math&gt;\digamma_i (i\in\{0,1,2 \})&lt;/math&gt; are Yang-Mills-NP scalars.&lt;ref&gt;E T Newman, K P Tod. ''Asymptotically Flat Spacetimes'', Appendix A.2. In A Held (Editor): ''General Relativity and Gravitation: One Hundred Years After the Birth of Albert Einstein''. Vol(2), page 27.  New York and London:  Plenum Press, 1980.&lt;/ref&gt;

To sum up, the aforementioned transportation equations, NP field equations and Maxwell-NP equations together constitute the Einstein-Maxwell equations in Newman–Penrose formalism.

==Applications of NP formalism to gravitational radiation field==
The Weyl scalar &lt;math&gt;\Psi_4&lt;/math&gt; was defined by Newman &amp; Penrose as
:&lt;math&gt;\Psi_4 = -C_{\alpha\beta\gamma\delta} n^\alpha \bar{m}^\beta n^\gamma \bar{m}^\delta&lt;/math&gt;
(note, however, that the overall sign is [[sign convention|arbitrary]], and that Newman &amp; Penrose worked with a "timelike" metric signature of &lt;math&gt;(+,-,-,-)&lt;/math&gt;).
In empty space, the [[Einstein Field Equations]] reduce to &lt;math&gt;R_{\alpha\beta}=0&lt;/math&gt;.  From the definition of the Weyl tensor, we see that this means that it equals the [[Riemann tensor]], &lt;math&gt;C_{\alpha\beta\gamma\delta} = R_{\alpha\beta\gamma\delta}&lt;/math&gt;.  We can make the standard choice for the tetrad at infinity:
:&lt;math&gt;l^{\mu} = \frac{1}{\sqrt{2}} \left( \hat{t} + \hat{r} \right)\ ,&lt;/math&gt;
:&lt;math&gt;n^{\mu} = \frac{1}{\sqrt{2}} \left( \hat{t} - \hat{r} \right)\ ,&lt;/math&gt;
:&lt;math&gt;m^{\mu} = \frac{1}{\sqrt{2}} \left( \hat{\theta} + i\hat{\phi} \right)\ .&lt;/math&gt;

In transverse-traceless gauge, a simple calculation shows that linearized [[gravitational waves]] are related to components of the Riemann tensor as
:&lt;math&gt; \frac{1}{4}\left( \ddot{h}_{\hat{\theta}\hat{\theta}} - \ddot{h}_{\hat{\phi}\hat{\phi}} \right) = -R_{\hat{t}\hat{\theta}\hat{t}\hat{\theta}} = -R_{\hat{t}\hat{\phi}\hat{r}\hat{\phi}} = -R_{\hat{r}\hat{\theta}\hat{r}\hat{\theta}} = R_{\hat{t}\hat{\phi}\hat{t}\hat{\phi}} = R_{\hat{t}\hat{\theta}\hat{r}\hat{\theta}} = R_{\hat{r}\hat{\phi}\hat{r}\hat{\phi}}\ ,&lt;/math&gt;
:&lt;math&gt; \frac{1}{2} \ddot{h}_{\hat{\theta}\hat{\phi}} = -R_{\hat{t}\hat{\theta}\hat{t}\hat{\phi}} = -R_{\hat{r}\hat{\theta}\hat{r}\hat{\phi}} = R_{\hat{t}\hat{\theta}\hat{r}\hat{\phi}} = R_{\hat{r}\hat{\theta}\hat{t}\hat{\phi}}\ ,&lt;/math&gt;
assuming propagation in the &lt;math&gt;\hat{r}&lt;/math&gt; direction.  Combining these, and using the definition of &lt;math&gt;\Psi_4&lt;/math&gt; above, we can write
:&lt;math&gt; \Psi_4 = \frac{1}{2}\left( \ddot{h}_{\hat{\theta} \hat{\theta}} - \ddot{h}_{\hat{\phi} \hat{\phi}} \right) + i \ddot{h}_{\hat{\theta}\hat{\phi}} = -\ddot{h}_+ + i \ddot{h}_\times\ . &lt;/math&gt;
Far from a source, in nearly flat space, the fields &lt;math&gt;h_+&lt;/math&gt; and &lt;math&gt;h_\times&lt;/math&gt; encode everything about gravitational radiation propagating in a given direction.  Thus, we see that &lt;math&gt;\Psi_4&lt;/math&gt; encodes in a single complex field everything about (outgoing) gravitational waves.

===Radiation from a finite source===
Using the wave-generation formalism summarised by Thorne,&lt;ref&gt;{{cite journal|title=Multipole expansions of gravitational radiation | author=Thorne, Kip S. | journal=Rev. Mod. Phys. | volume=52 |  issue=2 | pages=299–339 |date=April 1980|doi=10.1103/RevModPhys.52.299 | bibcode=1980RvMP...52..299T|url=http://authors.library.caltech.edu/11159/1/THOrmp80a.pdf }} A broad summary of the mathematical formalism used in the literature on gravitational radiation.&lt;/ref&gt; we can write the radiation field quite compactly in terms of the [[mass multipole]], [[current multipole]], and [[spin-weighted spherical harmonics]]:
:&lt;math&gt;\Psi_4(t,r,\theta,\phi) = - \frac{1}{r\sqrt{2}} \sum_{l=2}^{\infty} \sum_{m=-l}^l \left[ {}^{(l+2)}I^{lm}(t-r) -i\ {}^{(l+2)}S^{lm}(t-r) \right] {}_{-2}Y_{lm}(\theta,\phi)\ . &lt;/math&gt;
Here, prefixed superscripts indicate time derivatives.  That is, we define
:&lt;math&gt;{}^{(l)}G(t) = \left( \frac{d}{dt} \right)^l G(t)\ .&lt;/math&gt;
The components &lt;math&gt;I^{lm}&lt;/math&gt; and &lt;math&gt;S^{lm}&lt;/math&gt; are the mass and current multipoles, respectively.  &lt;math&gt;{}_{-2}Y_{lm}&lt;/math&gt; is the spin-weight -2 spherical harmonic.

== See also ==

* [[Light cone coordinates]]
* [[GHP formalism]]
* [[Tetrad formalism]]
* [[Goldberg–Sachs theorem]]

==References==
&lt;references/&gt;
* {{cite book
  | last = Wald
  | first = Robert
  | authorlink = Robert Wald
  | title = General Relativity
  | publisher = [[University of Chicago Press]]
  | year = 1984
  | isbn = 0-226-87033-2 }} Wald treats the more succinct version of the Newman–Penrose formalism in terms of more modern spinor notation.
* {{cite book
  | author = S. W. Hawking and G. F. R. Ellis
  | title = The large scale structure of space-time
  | publisher = [[Cambridge University Press]]
  | year = 1973
  | isbn = 0-226-87033-2 }} Hawking and Ellis use the formalism in their discussion of the final state of a collapsing star.

==External links==
*[http://www.scholarpedia.org/article/Spin-coefficient_formalism Newman–Penrose formalism on Scholarpedia]

{{DEFAULTSORT:Newman-Penrose Formalism}}
[[Category:Theory of relativity]]
[[Category:Mathematical notation]]</text>
      <sha1>msvsxoi7g58c1udgmpz0glwo9kffbev</sha1>
    </revision>
  </page>
  <page>
    <title>Outline of discrete mathematics</title>
    <ns>0</ns>
    <id>355814</id>
    <revision>
      <id>855711025</id>
      <parentid>852428561</parentid>
      <timestamp>2018-08-20T09:08:46Z</timestamp>
      <contributor>
        <username>Ddmmyyy8</username>
        <id>19655214</id>
      </contributor>
      <comment>/* Discrete mathematical disciplines */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8161">'''[[Discrete mathematics]]''' is the study of [[Mathematics|mathematical]] [[Mathematical structure|structures]] that are fundamentally [[discrete space|discrete]] rather than [[Continuous function|continuous]].  In contrast to [[real number]]s that have the property of varying "smoothly", the objects studied in discrete mathematics – such as [[integer]]s,  [[Graph (discrete mathematics)|graphs]], and statements in [[Mathematical logic|logic]]&lt;ref&gt;Richard Johnsonbaugh, ''Discrete Mathematics'', Prentice Hall, 2008; James Franklin, [http://scholarship.claremont.edu/jhm/vol7/iss2/18/ Discrete and continuous: a fundamental dichotomy in mathematics], ''Journal of Humanistic Mathematics'' 7 (2017), 355-378..&lt;/ref&gt; – do not vary smoothly in this way, but have distinct, separated values.&lt;ref&gt;{{MathWorld |title=Discrete mathematics |urlname=DiscreteMathematics}}&lt;/ref&gt; Discrete mathematics therefore excludes topics in "continuous mathematics" such as [[calculus]] and [[Mathematical analysis|analysis]].

Included below are many of the standard terms used routinely in university-level courses and in research papers. This is not, however, intended as a complete list of mathematical terms; just a selection of typical ''[[term of art|terms of art]]'' that may be encountered.

{{TOC limit|limit=2}}

==Subjects in discrete mathematics==

* [[Logic]] &amp;ndash; a study of reasoning
* [[Set theory]] &amp;ndash; a study of collections of elements
* [[Number theory]] &amp;ndash;
* [[Combinatorics]] &amp;ndash; a study of counting
* [[Graph theory]] &amp;ndash; 
* [[Digital geometry]] and [[digital topology]]
* [[Algorithmics]] &amp;ndash; a study of methods of calculation
* [[Information theory]] &amp;ndash;
* [[Computability]] and [[complexity]] theories &amp;ndash; dealing with theoretical and practical limitations of algorithms
* Elementary [[probability theory]] and [[Markov chain]]s
* [[Linear algebra]] &amp;ndash; a study of related linear equations
* [[Function (mathematics)|Functions]] &amp;ndash;
* [[Partially ordered set]] &amp;ndash;
* [[Probability]] &amp;ndash;
* [[Mathematical proof|Proofs]] &amp;ndash;
* [[Counting]] &amp;ndash;
* [[Relation (mathematics)|Relation]] &amp;ndash;

==Discrete mathematical disciplines==

For further reading in discrete mathematics, beyond a basic level, see these pages. Many of these disciplines are closely related to [[computer science]].

* [[Automata theory]] &amp;ndash;
* [[Coding theory]] &amp;ndash;
* [[Combinatorics]]  &amp;ndash;
* [[Computational geometry]]  &amp;ndash;
* [[Digital geometry]]  &amp;ndash;
* [[Discrete geometry]]  &amp;ndash;
* [[Graph theory]] &amp;ndash;
* [[Mathematical logic]] &amp;ndash;
* [[Optimization (mathematics)|Discrete_optimization]]  &amp;ndash;
* [[Set theory]] &amp;ndash;
* [[Topology|Combinatorial topology]] &amp;ndash;
* [[Number theory]] &amp;ndash;
* [[Information theory]] &amp;ndash;
* [[Game theory]] &amp;ndash;

==Concepts in discrete mathematics==
===Sets===

*[[Set (mathematics)]] &amp;ndash;
**[[Element (mathematics)]] &amp;ndash;
**[[Venn diagram]] &amp;ndash;
**[[Empty set]] &amp;ndash;
**[[Subset]] &amp;ndash;
**[[Union (set theory)]] &amp;ndash;
***[[Disjoint union]] &amp;ndash;
**[[Intersection (set theory)]] &amp;ndash;
***[[Disjoint sets]] &amp;ndash;
**[[Complement (set theory)]] &amp;ndash;
**[[Symmetric difference]] &amp;ndash;
*[[Ordered pair]] &amp;ndash;
*[[Cartesian product]] &amp;ndash;
*[[Power set]] &amp;ndash;
*[[Simple theorems in the algebra of sets]] &amp;ndash;
*[[Naive set theory]] &amp;ndash;
*[[Multiset]] &amp;ndash;

===Functions===

* [[Function (mathematics)|Function]] &amp;ndash;
* [[Domain of a function]] &amp;ndash;
* [[Codomain]] &amp;ndash;
* [[Range of a function]] &amp;ndash;
* [[Image (mathematics)]] &amp;ndash;
* [[Injective function]] &amp;ndash;
* [[Surjection]] &amp;ndash;
* [[Bijection]] &amp;ndash;
* [[Function composition]] &amp;ndash;
* [[Partial function]] &amp;ndash;
* [[Multivalued function]] &amp;ndash;
* [[Binary function]] &amp;ndash;
* [[Floor function]] &amp;ndash;
* [[Sign function]] &amp;ndash;
* [[Inclusion map]] &amp;ndash;
* [[Pigeonhole principle]] &amp;ndash;
* [[Relation composition]] &amp;ndash;
* [[Permutations]] &amp;ndash;
* [[Symmetry]] &amp;ndash;

===Arithmetic===

:[[Decimal]] &amp;ndash;
* [[Binary numeral system]] &amp;ndash;
* [[Divisor]] &amp;ndash;
* [[Division by zero]] &amp;ndash;
* [[Indeterminate form]] &amp;ndash;
* [[Empty product]] &amp;ndash;
* [[Euclidean algorithm]] &amp;ndash;
* [[Fundamental theorem of arithmetic]] &amp;ndash;
* [[Modular arithmetic]] &amp;ndash;
* [[Successor function]]

===Elementary algebra===

[[Elementary algebra]]
:[[Left-hand side and right-hand side of an equation]] &amp;ndash;
* [[Linear equation]] &amp;ndash;
* [[Quadratic equation]] &amp;ndash;
* [[Solution point]] &amp;ndash;
* [[Arithmetic progression]] &amp;ndash;
* [[Recurrence relation]] &amp;ndash;
* [[Finite difference]] &amp;ndash;
* [[Difference operator]] &amp;ndash;
* [[Group (mathematics)|Groups]] &amp;ndash;
* [[Group isomorphism]] &amp;ndash;
* [[Subgroups]] &amp;ndash;
* [[Fermat's little theorem]] &amp;ndash;
* [[Cryptography]] &amp;ndash;
* [[Faulhaber's formula]] &amp;ndash;

===Mathematical relations===

*[[Binary relation]] &amp;ndash;
*[[Heterogeneous relation]] &amp;ndash;
*[[Reflexive relation]] &amp;ndash;
*[[Reflexive property of equality]] &amp;ndash;
*[[Symmetric relation]] &amp;ndash;
*[[Symmetric property of equality]] &amp;ndash;
*[[Antisymmetric relation]] &amp;ndash;
*[[Transitive relation|Transitivity (mathematics)]] &amp;ndash;
**[[Transitive closure]] &amp;ndash;
**[[Transitive property of equality]] &amp;ndash;
*''Equivalence and identity''
**[[Equivalence relation]] &amp;ndash;
**[[Equivalence class]] &amp;ndash;
**[[Equality (mathematics)]] &amp;ndash;
*** [[Inequation]] &amp;ndash;
*** [[Inequality (mathematics)]] &amp;ndash;
**[[Similarity (geometry)]] &amp;ndash;
**[[Congruence (geometry)]] &amp;ndash;
**[[Equation]] &amp;ndash;
**[[Identity (mathematics)]] &amp;ndash;
*** [[Identity element]] &amp;ndash;
*** [[Identity function]] &amp;ndash;
**[[Substitution property of equality]] &amp;ndash;
**[[Graphing equivalence]] &amp;ndash;
**[[Extensionality]] &amp;ndash;
**[[Uniqueness quantification]] &amp;ndash;

===Mathematical phraseology===

* [[If and only if]]  &amp;ndash;
* [[Necessary and sufficient]] ([[Sufficient condition]]) &amp;ndash;
* [[Distinct (mathematics)|Distinct]] &amp;ndash;
* [[Subtraction|Difference]] &amp;ndash;
* [[Absolute value]] &amp;ndash;
* [[Up to]] &amp;ndash;
* [[Modular arithmetic]] &amp;ndash;
* [[Characterization (mathematics)]] &amp;ndash;
* [[Normal form (mathematics)|Normal form]] &amp;ndash;
* [[Canonical form]] &amp;ndash;
* [[Without loss of generality]] &amp;ndash;
* [[Vacuous truth]] &amp;ndash;
* [[Contradiction]], [[Reductio ad absurdum]] &amp;ndash;
* [[Counterexample]] &amp;ndash;
* [[Sufficiently large]] &amp;ndash;
* [[Pons asinorum]] &amp;ndash;
* [[Table of mathematical symbols]] &amp;ndash;
* [[Contrapositive]] &amp;ndash;
* [[Mathematical induction]] &amp;ndash;

===Combinatorics===

[[Combinatorics]]
*[[Permutations and combinations]] &amp;ndash;
*[[Permutation]] &amp;ndash;
*[[Combination]] &amp;ndash;
*[[Factorial]] &amp;ndash;
**[[Empty product]] &amp;ndash;
*[[Pascal's triangle]] &amp;ndash;
*[[Combinatorial proof]] &amp;ndash;
**[[Bijective proof]] &amp;ndash;
**[[Double counting (proof technique)]] &amp;ndash;

===Probability===

[[Probability]]
* [[Average]] &amp;ndash;
* [[Expected value]] &amp;ndash;
* [[Discrete random variable]] &amp;ndash;
* [[Sample space]] &amp;ndash;
* [[Event (probability theory)|Event]] &amp;ndash;
* [[Conditional Probability]] &amp;ndash;
* [[Independence (probability theory)|Independence]] &amp;ndash;
* [[Random variables]] &amp;ndash;

===Propositional logic===

:[[Logical operator]] &amp;ndash;
* [[Truth table]] &amp;ndash;
* [[De Morgan's laws]] &amp;ndash;
* [[Open sentence]] &amp;ndash;
* [[List of topics in logic]] &amp;ndash;

==Mathematicians associated with discrete mathematics==
{{expand section|date=January 2016}}
* [[Paul Erdős]]
* [[Ronald Graham]]
* [[George Szekeres]]

==See also==
{{Portal|Discrete mathematics}}
{{clear}}

==References==
{{Reflist}}

==External links==
*[http://archives.math.utk.edu/topics/discreteMath.html Archives]
* Jonathan Arbib &amp; John Dwyer, Discrete Mathematics for Cryptography, 1st Edition {{ISBN|978-1-907934-01-8}}.
* John Dwyer &amp; Suzy Jagger, Discrete Mathematics'' for Business &amp; Computing, 1st Edition 2010 {{ISBN|978-1-907934-00-1}}.

{{Outline footer}}

[[Category:Wikipedia outlines|Discrete mathematics]]
[[Category:Discrete mathematics|*]]
[[Category:Mathematics-related lists|Discrete mathematics]]</text>
      <sha1>0u9yam9c1fnprp6224gfkbmffu58zh1</sha1>
    </revision>
  </page>
  <page>
    <title>Peter Roquette</title>
    <ns>0</ns>
    <id>41199245</id>
    <revision>
      <id>839104074</id>
      <parentid>799512107</parentid>
      <timestamp>2018-05-01T08:28:23Z</timestamp>
      <contributor>
        <username>Melcous</username>
        <id>20472590</id>
      </contributor>
      <comment>remove names with no evidence of notability</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4079">[[File:Peter Roquette.jpeg|thumb|Peter Roquette at Workshop “The Arithmetic of Fields” in Oberwolfach, 2006]]
'''Peter Roquette''' (born October 8 1927 in [[Königsberg]]) is a German mathematician working in [[algebraic geometry]], [[algebra]], and [[number theory]].

Roquette studied in [[Erlangen]], [[Berlin]], and [[Hamburg]]. In 1951 he defended a dissertation at the [[University of Hamburg]] under [[Helmut Hasse]], providing a new proof of the [[Riemann hypothesis]] for algebraic function fields over a [[finite field]] (the first proof was given by [[André Weil]] in 1940). In 1951/1952 he was an assistant at the Mathematical Research Institute at [[Oberwolfach]] and from 1952 to 1954 at the [[University of Munich]].  From 1954 to 1956 he worked at the [[Institute for Advanced Study]] in Princeton.  In 1954 he was Privatdozent at Munich, and from 1956 to 1959 he worked in the same position at Hamburg. In 1959 he became an associate professor at the [[University of Saarbrucken]] and in the same year at the [[University of Tübingen]]. From 1967 he was professor at the [[Ruprecht-Karls-University]] of Heidelberg, where he retired in 1996.

Roquette worked on number and function fields and especially local [[p-adic field]]s. He applied the methods of [[model theory]] ([[Nonstandard arithmetic]]) in number theory, joint with [[Abraham Robinson]], with whom he worked on [[Mahler's theorem]] (on the finiteness of integral points on a curve of genus g&gt; 0) using [[non-standard analysis|non-standard]] methods. He authored a number of works on the [[history of mathematics]], in particular on the schools of [[Helmut Hasse]] and [[Emmy Noether]]. In 1975 Roquette was co-editor of the collected essays by Helmut Hasse.

Since 1978 Roquette is member of the [[Heidelberg Academy of Sciences]] and since 1985, the [[German Academy of Sciences Leopoldina]].  He has an honorary doctorate from the [[University of Duisburg-Essen]] and is honorary member of the [[Mathematical Society of Hamburg]]. In 1958 he was an [[list of International Congresses of Mathematicians Plenary and Invited Speakers|invited speaker at the International Congress of Mathematicians]] in [[Edinburgh]] (on the topic of Some fundamental theorems on abelian function fields).

His doctoral students include [[Gerhard Frey]] and {{Interlanguage link multi|Volker Weispfenning|de}}.

==Selected publications==
* Analytic theory of elliptic functions over local fields.  Vandenhoeck and Ruprecht 1970.
* With Franz Lemmermeyer (Editor): The Correspondence of Helmut Hasse and Emmy Noether 1925-1935 Göttingen State and University Library, 2006..
* with Günther Frei (Editor): [https://www.springer.com/mathematics/numbers/book/978-3-0348-0714-2 Emil Artin and Helmut Hasse - correspondence 1923-1934], University of Göttingen Publisher 2008
* The Brauer-Hasse-Noether Theorem in Historical Perspective. Mathem. the-Naturwiss writings.  Class of the Heidelberg Academy of Sciences, Springer-Verlag, 2005.
* Anthony V. Geramita, Paulo Ribenboim (ed.): Collected Papers of Peter Roquette 3 volumes.  Queens Papers in Pure and Applied Mathematics Bd.118, Kingston, Ontario, Queen's University, 2002.
* With Alexander Prestel: Formally p-adic Fields. Lecture Notes in Mathematics, Springer-Verlag 1984.
* Robinson, A.; Roquette, P. On the finiteness theorem of Siegel and Mahler concerning Diophantine equations. J. Number Theory  7  (1975), 121–176.

==External links==

*[http://www.rzuser.uni-heidelberg.de/~ci3/ homepage]
*{{mathgenealogy|21608}}

{{Authority control}}

{{DEFAULTSORT:Roquette, Peter}}
[[Category:1927 births]]
[[Category:Living people]]
[[Category:20th-century German mathematicians]]
[[Category:21st-century German mathematicians]]
[[Category:University of Hamburg alumni]]
[[Category:Ludwig Maximilian University of Munich faculty]]
[[Category:Saarland University faculty]]
[[Category:University of Tübingen faculty]]
[[Category:Heidelberg University faculty]]
[[Category:Number theorists]]
[[Category:Model theorists]]
[[Category:Historians of mathematics]]</text>
      <sha1>gagavpex7ctnpu6rofhotk9mwsslig3</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial transformation</title>
    <ns>0</ns>
    <id>3881088</id>
    <revision>
      <id>832796989</id>
      <parentid>728015696</parentid>
      <timestamp>2018-03-28T01:47:50Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6737">{{no footnotes|date=May 2014}}

In [[mathematics]], a '''polynomial transformation''' consists of computing the polynomial whose [[root of a polynomial|roots]] are a given function of the roots of polynomial. Polynomial transformations such as [[Tschirnhaus transformation]]s are often used to simplify the solution of [[algebraic equation]]s.

==Simple examples==

===Translating the roots===
Let 
:&lt;math&gt; P(x) = a_0x^n + a_1 x^{n-1} + \cdots + a_{n} &lt;/math&gt;
be a polynomial, and 
:&lt;math&gt;\alpha_1, \ldots, \alpha_n&lt;/math&gt; 
be its complex roots (not necessarily distinct).

For any constant {{math|''c''}}, the polynomial whose roots are 
:&lt;math&gt;\alpha_1+c, \ldots, \alpha_n+c&lt;/math&gt; 
is 
:&lt;math&gt;Q(y) = P(y-c)= a_0(y-c)^n + a_1 (y-c)^{n-1} + \cdots + a_{n}. &lt;/math&gt;

If the coefficients of {{math|''P''}} are [[integer]]s and the constant &lt;math&gt;c=\frac{p}{q}&lt;/math&gt; is a [[rational number]], the coefficients of {{math|''Q''}} may be not integer, but the polynomial {{math|''c''&lt;sup&gt;''n''&lt;/sup&gt; ''Q''}} has integers coefficients and has the same roots as {{math|''Q''}}.

A special case is when &lt;math&gt;c=\frac{a_1}{a_0}.&lt;/math&gt; The resulting polynomial {{math|''Q''}} does not have any term in {{math|''y''&lt;sup&gt;''n'' &amp;minus; 1&lt;/sup&gt;}}.

===Reciprocals of the roots===
Let 
:&lt;math&gt; P(x) = a_0x^n + a_1 x^{n-1} + \cdots + a_{n} &lt;/math&gt;
be a polynomial. The polynomial whose roots are the [[Multiplicative inverse|reciprocals]] of the roots of {{math|''P''}} as roots is its [[reciprocal polynomial]]
:&lt;math&gt; Q(y)= y^nP\left(\frac{1}{y}\right)= a_ny^n + a_{n-1} y^{n-1} + \cdots + a_{0}.&lt;/math&gt;

===Scaling the roots===

Let 
:&lt;math&gt; P(x) = a_0x^n + a_1 x^{n-1} + \cdots + a_{n} &lt;/math&gt;
be a polynomial, and {{math|''c''}} be a non-zero constant. A polynomial whose roots are the product by {{math|''c''}} of the roots of {{math|''P''}} is 
:&lt;math&gt;Q(y)=c^nP\left(\frac{y}{c} \right) = a_0y^n + a_1 cy^{n-1} + \cdots + a_{n}c^n. &lt;/math&gt;
The factor {{math|''c''&lt;sup&gt;''n''&lt;/sup&gt;}} appears here because, if {{math|''c''}} and the coefficients of {{math|''P''}} are integers or belong to some [[integral domain]], the same is true for the coefficients of {{math|''Q''}}.

In the special case where &lt;math&gt;c=a_0&lt;/math&gt;, all coefficients of {{math|''Q''}} are multiple of {{math|''c''}}, and &lt;math&gt; \frac{Q}{c}&lt;/math&gt; is a [[monic polynomial]], whose coefficients belong to any integral domain containing {{math|''c''}} and the coefficients of {{math|''P''}}. This polynomial transformation is often used to reduce questions on [[algebraic number]]s to questions on [[algebraic integer]]s.

Combining this with a [[#Translating the roots|translation of the roots]] by &lt;math&gt;\frac{a_1}{a_0}&lt;/math&gt;, allows to reduce any question on the roots of a polynomial, such as [[root-finding]], to a similar question on a simpler polynomial, which is monic and does not have a term of degree {{math|''n'' &amp;minus; 1}}. For examples of this, see [[cubic function#Reduction to a depressed cubic|Cubic function § Reduction to a depressed cubic]] or [[Quartic function#Converting to a depressed quartic|Quartic function § Converting to a depressed quartic]].

==Transformation by a rational function==
All preceding examples are polynomial transformations by a [[rational function]], also called [[Tschirnhaus transformation]]s. Let 
:&lt;math&gt;f(x)=\frac{g(x)}{h(x)}&lt;/math&gt;
be a rational function, where {{math|''g''}} and {{math|''h''}} are [[coprime]] polynomials. The polynomial transformation of a polynomial {{math|''P''}} by {{math|''f''}} is the polynomial {{math|''Q''}} (defined [[up to]] the product by a non-zero constant) whose roots are the images by {{math|''f''}} of the roots of {{math|''P''}}.

Such a polynomial transformation may be computed as a [[resultant]]. In fact, the roots of the desired polynomial {{math|''Q''}} are exactly the [[complex number]]s {{math|''y''}} such that there is a complex number {{math|''x''}} such one has simultaneously (if the coefficients of {{math|''P'', ''g''}} and {{math|''h''}} are not real or complex numbers, ''"complex number"'' has to be replaced by ''"element of an [[algebraically closed field]] containing the coefficients of the input polynomials"'')
:&lt;math&gt;\begin{align}
P(x)&amp;=0\\
y\,h(x)-g(x)&amp;=0\,.
\end{align}
&lt;/math&gt;
This is exactly the defining property of the resultant
:&lt;math&gt;\operatorname{Res}_x(y\,h(x)-g(x),P(x))&lt;/math&gt;

This is generally difficult to compute this through a hand-written computation. However, as most [[computer algebra system]]s have a built-in function to compute resultants, it is straightforward to compute it with a [[computer]].

===Properties===
If the polynomial {{math|''P''}} is [[irreducible polynomial|irreducible]], then either the resulting polynomial {{math|''Q''}} is irreducible, or it is a power of an irreducible polynomial. Let &lt;math&gt;\alpha&lt;/math&gt; be a root of {{math|''P''}} and consider {{math|''L''}}, the [[field extension]] generated by &lt;math&gt;\alpha&lt;/math&gt;. The former case means that &lt;math&gt;f(\alpha)&lt;/math&gt; is a [[simple extension|primitive element]] of {{math|''L''}}, which has {{math|''Q''}} as [[minimal polynomial (field theory)|minimal polynomial]]. In the latter case, &lt;math&gt;f(\alpha)&lt;/math&gt; belongs to a subfield of {{math|''L''}} and its minimal polynomial is the irreducible polynomial that has {{math|''Q''}} as power.

==Transformation for equation-solving==

Polynomial transformations have been applied to the simplification of polynomial equations for solution, where possible, by radicals.  Descartes introduced the transformation of a polynomial of degree ''d'' which eliminates the term of degree ''d''−1 by a translation of the roots.  Such a polynomial is termed '''depressed'''. this already suffices to solve the quadratic by square roots.   In the case of the cubic, Tschirnhaus transformations replace the variable by a quadratic function, thereby making it possible to eliminate two terms, and so can be used to eliminate the linear term in a depressed cubic to achieve the solution of the cubic by a combination of square and cube roots.  The Bring–Jerrard transformation, which is quartic in the variable, brings a quintic into "principal" or [[Bring-Jerrard normal form]] with terms of degree 5,1 and zero.

==References==
* {{cite journal | last1=Adamchik | first1=Victor S. | last2=Jeffrey | first2=David J. | title=Polynomial transformations of Tschirnhaus, Bring and Jerrard | zbl=1055.65063 | journal=SIGSAM Bull. | volume=37 | number=3 | pages=90–94 | year=2003 | url=http://www.sigsam.org/bulletin/articles/145/Adamchik.pdf | deadurl=yes | archiveurl=https://web.archive.org/web/20090226035637/http://www.sigsam.org/bulletin/articles/145/Adamchik.pdf | archivedate=2009-02-26 | df= }}

[[Category:Algebra]]</text>
      <sha1>eyemhlvfcapm3rjd5hf7o9rjyskiajh</sha1>
    </revision>
  </page>
  <page>
    <title>Rational reconstruction (mathematics)</title>
    <ns>0</ns>
    <id>37066906</id>
    <revision>
      <id>774929086</id>
      <parentid>723947946</parentid>
      <timestamp>2017-04-11T15:30:49Z</timestamp>
      <contributor>
        <username>WikiMasterGhibif</username>
        <id>29277190</id>
      </contributor>
      <minor/>
      <comment>Added wikilink</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1544">{{Underlinked|date=June 2016}}

In mathematics, '''rational reconstruction''' is a method that allows one to recover a [[rational number]] from its value modulo an integer. If a problem with a rational solution &lt;math&gt;\frac{r}{s}&lt;/math&gt; is considered modulo a number ''m'', one will obtain the number &lt;math&gt;n = r\times s^{-1}\pmod{m}&lt;/math&gt;. If |''r''| &lt; ''N'' and 0 &lt; ''s'' &lt; ''D'' then ''r'' and ''s'' can be uniquely determined from ''n'' if ''m'' &gt; 2''ND'' using the [[Euclidean algorithm]], as follows.&lt;ref&gt;P. S. Wang, ''a p-adic algorithm for univariate partial fractions'', Proceedings of SYMSAC ´81, ACM Press, 212 (1981); P. S. Wang, M. J. T. Guy, and J. H. Davenport, ''p-adic reconstruction of rational numbers'', SIGSAM Bulletin '''16''' (1982).&lt;/ref&gt;

One puts &lt;math&gt;v = (m,0)&lt;/math&gt; and &lt;math&gt;w = (n,1)&lt;/math&gt;. One then repeats the following steps until the first component of ''w'' becomes &lt;math&gt;\leq N&lt;/math&gt;. Put &lt;math&gt;q = \left\lfloor{\frac{v_{1}}{w_{1}}}\right\rfloor&lt;/math&gt;, put ''z'' = ''v''&amp;nbsp;&amp;minus;&amp;nbsp;''qw''. The new ''v'' and ''w'' are then obtained by putting ''v'' = ''w'' and ''w'' = ''z''.

Then with ''w'' such that &lt;math&gt;w_{1}\leq N&lt;/math&gt;, one makes the second component positive by putting ''w'' = &amp;minus;''w'' if &lt;math&gt;w_{2}&lt;0&lt;/math&gt;. If &lt;math&gt;w_2&lt;D&lt;/math&gt; and &lt;math&gt;\gcd(w_1,w_2)=1&lt;/math&gt;, then the fraction &lt;math&gt;\frac{r}{s}&lt;/math&gt; exists and &lt;math&gt;r = w_{1}&lt;/math&gt; and &lt;math&gt;s = w_{2}&lt;/math&gt;, else no such fraction exists.

==References==
&lt;references/&gt;

[[Category:Number theory]]


{{numtheory-stub}}</text>
      <sha1>dcuecakj50rexhuxoku6q38t3pgwt62</sha1>
    </revision>
  </page>
  <page>
    <title>Realizability</title>
    <ns>0</ns>
    <id>11009758</id>
    <revision>
      <id>835337883</id>
      <parentid>736983945</parentid>
      <timestamp>2018-04-08T02:25:32Z</timestamp>
      <contributor>
        <ip>97.126.77.28</ip>
      </contributor>
      <comment>/* Later developments */  spelling "premiss" -&gt; "premise"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7070">In [[mathematical logic]], '''realizability''' is a collection of methods in [[proof theory]] used to study [[constructive proof]]s and extract additional information from them.&lt;ref&gt;van Oosten 2000&lt;/ref&gt; Formulas from a formal theory are "realized" by objects, known as "realizers", in a way that knowledge of the realizer gives knowledge about the truth of the formula. There are many variations of realizability; exactly which class of formulas is studied and which objects are realizers differ from one variation to another.

Realizability can be seen as a formalization of the [[BHK interpretation]] of intuitionistic logic; in realizability the notion of "proof" (which is left undefined in the BHK interpretation) is replaced with a formal notion of "realizer". Most variants of realizability begin with a theorem that any statement that is provable in the formal system being studied is realizable. The realizer, however, usually gives more information about the formula than a formal proof would directly provide.

Beyond giving insight into intuitionistic provability, realizability can be applied to prove the [[disjunction and existence properties]] for intuitionistic theories and to extract programs from proofs, as in [[proof mining]]. It is also related to [[topos theory]] via the [[realizability topos]].

== Example: realizability by numbers ==

Kleene's original version of realizability uses natural numbers as realizers for formulas in [[Heyting arithmetic]]. The following clauses are used to define a relation "''n'' realizes ''A''" between natural numbers ''n'' and formulas ''A'' in the language of Heyting arithmetic. A few pieces of notation are required: first, an ordered pair (''n'',''m'') is treated as a single number using a fixed effective [[pairing function]]; second, for each natural number ''n'', &amp;phi;&lt;sub&gt;''n''&lt;/sub&gt; is the [[computable function]] with index ''n''. 
* A number ''n'' realizes an atomic formula ''s''=''t'' if and only if ''s''=''t'' is true. Thus every number realizes a true equation, and no number realizes a false equation.
* A pair (''n'',''m'') realizes a formula ''A''&amp;and;''B'' if and only if ''n'' realizes ''A'' and ''m'' realizes ''B''. Thus a realizer for a conjunction is a pair of realizers for the conjuncts. 
* A pair (''n'',''m'') realizes a formula ''A''&amp;or;''B'' if and only if the following hold: ''n'' is 0 or 1; and if ''n'' is 0 then ''m'' realizes ''A''; and if ''n'' is 1 then ''m'' realizes ''B''.  Thus a realizer for a disjunction explicitly picks one of the disjuncts (with ''n'') and provides a realizer for it (with ''m'').
* A number ''n'' realizes a formula ''A''&amp;rarr;''B'' if and only if, for every ''m'' that realizes ''A'', &amp;phi;&lt;sub&gt;''n''&lt;/sub&gt;(''m'') realizes ''B''. Thus a realizer for an implication is a computable function that takes a realizer for the hypothesis and produces a realizer for the conclusion. 
* A pair (''n'',''m'') realizes a formula (&amp;exist; ''x'')''A''(''x'') if and only if ''m'' is a realizer for ''A''(''n''). Thus a realizer for an existential formula produces an explicit witness for the quantifier along with a realizer for the formula instantiated with that witness.
* A number ''n'' realizes a formula (&amp;forall; ''x'')''A''(''x'') if and only if, for all ''m'', &amp;phi;&lt;sub&gt;''n''&lt;/sub&gt;(''m'') is defined and realizes ''A''(''m''). Thus a realizer for a universal statement is a computable function that produces, for each ''m'', a witness for the formula instantiated with ''m''.

With this definition, the following theorem is obtained:&lt;ref&gt;van Oosten 2000, p.&amp;nbsp;7&lt;/ref&gt;
:Let ''A'' be a sentence of Heyting arithmetic (HA). If HA proves ''A'' then there is an ''n'' such that ''n'' realizes ''A''. 
On the other hand, there are formulas that are realized but which are not provable in HA, a fact first established by Rose.&lt;ref&gt;Rose 1953&lt;/ref&gt;

Further analysis of the method can be used to prove that HA has the "[[disjunction and existence properties]]":&lt;ref&gt;van Oosten 2000, p.&amp;nbsp;6&lt;/ref&gt;
* If HA proves a sentence (&amp;exist; ''x'')''A''(''x''), then there is an ''n'' such that HA proves ''A''(''n'')
* If HA proves  a sentence ''A''&amp;or;''B'', then HA proves ''A'' or HA proves ''B''.

==Later developments==

Kreisel introduced '''modified realizability''', which uses [[typed lambda calculus]] as the language of realizers. Modified realizability is one way to show that [[Markov's principle]] is not derivable in intuitionistic logic. On the contrary, it allows to constructively justify the principle of independence of premise: 
:&lt;math&gt;(A \rightarrow \exists x\;P(x)) \rightarrow \exists x\;(A \rightarrow P(x))&lt;/math&gt;.

Relative realizability&lt;ref&gt;Birkedal 2000&lt;/ref&gt; is an intuitionist analysis of recursive or recursively enumerable elements of data structures that are not necessarily computable, such as computable operations on all real numbers when reals can be only approximated on digital computer systems.

==Applications ==

Realizability is one of the methods used in [[proof mining]] to extract concrete "programs" from seemingly nonconstructive mathematical proof. Program extraction using realizability is implemented in some [[proof assistant]]s such as [[Coq]].

== See also ==

* [[Curry–Howard correspondence]]
* [[Dialectica interpretation]]
* [[Harrop formula]]

==Notes==
&lt;references/&gt;

==References==

* {{cite book | last = Birkedal | first = Lars |author2=Jaap van Oosten  | year = 2000 | title = Relative and modified relative realizability | url = https://www.staff.science.uu.nl/~ooste110/realizability/birkoost.ps.gz }}
* Kreisel G. (1959). "Interpretation of Analysis by Means of Constructive Functionals of Finite Types", in: Constructivity in Mathematics, edited by A. Heyting, North-Holland, pp.&amp;nbsp;101–128.
* {{cite journal | last = Kleene | first = S. C. | year = 1945 | title = On the interpretation of intuitionistic number theory | jstor = 2269016 | journal = Journal of Symbolic Logic | volume = 10 | issue = 4 | pages = 109–124 | doi = 10.2307/2269016}}
* Kleene, S. C. (1973). "Realizability: a retrospective survey" from {{cite book | last = Mathias | first = A. R. D. |author2=Hartley Rogers  | title = Cambridge Summer School in Mathematical Logic : held in Cambridge/England, August 1–21, 1971 | year = 1973 | location = Berlin | publisher = Springer | isbn = 3-540-05569-X}}, pp.&amp;nbsp;95–112.
* {{cite book | last = van Oosten | first = Jaap | year = 2000 | title = Realizability: An Historical Essay | url = http://www.math.uu.nl/people/jvoosten/realizability/history.ps.gz }}
* {{cite journal | last = Rose | first = G. F. | year = 1953 | title = Propositional calculus and realizability | jstor = 1990776 | journal = Transactions of the American Mathematical Society | volume = 75 | issue = 1 | pages = 1–19 | doi = 10.2307/1990776}}

== External links ==
*[http://www.math.uu.nl/people/jvoosten/realizability.html Realizability] Collection of links to recent papers on realizability and related topics.

[[Category:Proof theory]]
[[Category:Constructivism (mathematics)]]</text>
      <sha1>jwuh70m4hus5ziksq5i4x05y1c215dh</sha1>
    </revision>
  </page>
  <page>
    <title>Schuette–Nesbitt formula</title>
    <ns>0</ns>
    <id>14182874</id>
    <revision>
      <id>850558510</id>
      <parentid>753867334</parentid>
      <timestamp>2018-07-16T16:04:35Z</timestamp>
      <contributor>
        <username>Tholme</username>
        <id>14312321</id>
      </contributor>
      <comment>lintfix: unicode star</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23730">In [[mathematics]], the '''Schuette–Nesbitt formula''' is a generalization of the [[inclusion–exclusion principle]]. It is named after [[Donald R. Schuette]] and [[Cecil J. Nesbitt]].

The [[probability theory|probabilistic]] version of the Schuette–Nesbitt [[formula]] has practical applications in [[actuarial science]], where it is used to calculate the [[net premium valuation|net single premium]] for [[life annuity|life annuities]] and [[life insurance]]s based on the general symmetric status.

==Combinatorial versions==

Consider a [[set (mathematics)|set]] {{math|Ω}} and [[subsets]] {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;m&lt;/sub&gt;''}}. Let

{{NumBlk|:|&lt;math&gt; N(\omega)=\sum_{n=1}^m 1_{A_n}(\omega),\qquad \omega\in\Omega,&lt;/math&gt;|{{EquationRef|1}}}}

denote the number of subsets to which {{math|''ω'' ∈ Ω}} belongs, where we use the [[indicator function]]s of the sets {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;m&lt;/sub&gt;''}}. Furthermore, for each {{math|''k'' ∈ {{mset|0, 1, ..., ''m''}}}}, let

{{NumBlk|:|&lt;math&gt;N_k(\omega)=\sum_{\scriptstyle J\subset\{1,\ldots,m\}\atop\scriptstyle|J|=k} 1_{\cap_{j\in J}A_j}(\omega),\qquad\omega\in\Omega,&lt;/math&gt;|{{EquationRef|2}}}}

denote the number of [[intersection (set theory)|intersections]] of exactly {{mvar|k}} sets out of {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;m&lt;/sub&gt;''}}, to which {{mvar|ω}} belongs, where the intersection over the [[empty set|empty index set]] is defined as {{math|Ω}}, hence {{math|''N''&lt;sub&gt;0&lt;/sub&gt; {{=}} 1&lt;sub&gt;Ω&lt;/sub&gt;}}. Let {{mvar|V}} denote a [[vector space]] over a [[field (mathematics)|field]] {{mvar|R}} such as the [[real number|real]] or [[complex number]]s (or more generally a [[module (mathematics)|module]] over a [[ring (mathematics)|ring]] {{mvar|R}} with [[multiplicative identity]]). Then, for every choice of {{math|''c''&lt;sub&gt;0&lt;/sub&gt;, ..., ''c&lt;sub&gt;m&lt;/sub&gt;'' ∈ ''V''}},

{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m 1_{\{N=n\}}c_n = \sum_{k=0}^m N_k\sum_{l=0}^k (-1)^{k-l}\binom klc_l,&lt;/math&gt;|{{EquationRef|3}}}}

where {{math|1&lt;sub&gt;{{mset|''N''{{=}}''n''}}&lt;/sub&gt;}} denotes the indicator function of the set of all {{math|''ω'' ∈ Ω}} with {{math|''N''(''ω'') {{=}} ''n''}}, and &lt;math&gt;\textstyle\binom kl&lt;/math&gt; is a [[binomial coefficient]]. Equality ({{EquationNote|3}}) says that the two {{mvar|V}}-valued functions defined on {{math|Ω}} are the same.

&lt;div style="clear:both;width:95%;" class="NavFrame"&gt;
&lt;div class="NavHead" style="background-color:#FFFAF0; text-align:left; font-size:larger;"&gt;Proof of ({{EquationNote|3}})&lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;display:none;"&gt;
We prove that ({{EquationNote|3}}) holds pointwise. Take {{math|''ω'' ∈ Ω}} and define {{math|''n'' {{=}} ''N''(''ω'')}}.
Then the left-hand side of ({{EquationNote|3}}) equals {{math|''c&lt;sub&gt;n&lt;/sub&gt;''}}.
Let {{mvar|I}} denote the set of all those indices {{math|''i'' ∈ {{mset|1, ..., ''m''}}}} such that {{math|''ω'' ∈ ''A&lt;sub&gt;i&lt;/sub&gt;''}}, hence {{mvar|I}} contains exactly {{mvar|n}} indices.
Given {{math|''J'' ⊂ {{mset|1, ..., ''m''}}}} with {{mvar|k}} elements, then {{mvar|ω}} belongs to the intersection {{math|∩&lt;sub&gt;''j''∈''J''&lt;/sub&gt;''A&lt;sub&gt;j&lt;/sub&gt;''}} if and only if {{mvar|J}} is a subset of {{mvar|I}}.
By the combinatorial interpretation of the [[binomial coefficient]], there are {{math|''N&lt;sub&gt;k&lt;/sub&gt;'' {{=}}}} &lt;math&gt;\textstyle\binom nk&lt;/math&gt; such subsets (the binomial coefficient is zero for {{math|''k'' &gt; ''n''}}).
Therefore the right-hand side of ({{EquationNote|3}}) evaluated at {{mvar|ω}} equals

:&lt;math&gt;\sum_{k=0}^m \binom nk\sum_{l=0}^k (-1)^{k-l}\binom klc_l
=\sum_{l=0}^m\underbrace{\sum_{k=l}^n (-1)^{k-l}\binom nk \binom kl}_{=:\,(*)} c_l,&lt;/math&gt;

where we used that the first binomial coefficient is zero for {{math|''k'' &gt; ''n''}}.
Note that the sum (*) is empty and therefore defined as zero for {{math|''n'' &lt; ''l''}}.
Using the [[binomial coefficient#Factorial formula|factorial formula]] for the binomial coefficients, it follows that

:&lt;math&gt;
\begin{align}
(*)
&amp;=\sum_{k=l}^n (-1)^{k-l}\frac{n!}{k!\,(n-k)!}\,\frac{k!}{l!\,(k-l)!}\\
&amp;=\underbrace{\frac{n!}{l!\,(n-l)!}}_{=\binom nl}\underbrace{\sum_{k=l}^n (-1)^{k-l}\frac{(n-l)!}{(n-k)!\,(k-l)!}}_{=:\,(**)}\\
\end{align}
&lt;/math&gt;
Rewriting (**) with the summation index {{math|''j'' {{=}} ''k'' − ''l''}} und using the [[binomial formula]] for the third equality shows that
:&lt;math&gt;
\begin{align}
(**)
&amp;=\sum_{j=0}^{n-l} (-1)^{j}\frac{(n-l)!}{(n-l-j)!\,j!}\\
&amp;=\sum_{j=0}^{n-l} (-1)^{j}\binom{n-l}{j}
=(1-1)^{n-l}
=\delta_{ln},
\end{align}
&lt;/math&gt;
which is the [[Kronecker delta]]. Substituting this result into the above formula and noting that {{mvar|n}} choose {{mvar|l}} equals {{math|1}} for {{math|''l'' {{=}} ''n''}}, it follows that the right-hand side of ({{EquationNote|3}}) evaluated at {{mvar|ω}} also reduces to {{math|''c&lt;sub&gt;n&lt;/sub&gt;''}}.
&lt;/div&gt;
&lt;/div&gt;

===Representation in the polynomial ring===
As a special case, take for {{mvar|V}} the [[polynomial ring]] {{math|''R''[''x'']}} with the [[indeterminate (variable)|indeterminate]] {{mvar|x}}. Then ({{EquationNote|3}}) can be rewritten in a more compact way as

{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m 1_{\{N=n\}}x^n = \sum_{k=0}^m N_k(x-1)^k.&lt;/math&gt;|{{EquationRef|4}}}}

This is an identity for two [[polynomial]]s whose coefficients depend on {{mvar|ω}}, which is implicit in the notation.

&lt;div style="clear:both;width:95%;" class="NavFrame"&gt;
&lt;div class="NavHead" style="background-color:#FFFAF0; text-align:left; font-size:larger;"&gt;Proof of ({{EquationNote|4}}) using ({{EquationNote|3}}) &lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;display:none;"&gt;
Substituting {{math|''c&lt;sub&gt;n&lt;/sub&gt;'' {{=}} ''x&lt;sup&gt;n&lt;/sup&gt;''}} for {{math|''n''  ∈ {{mset|0, ..., ''m''}}}} into ({{EquationNote|3}}) and using the [[binomial formula]] shows that
:&lt;math&gt;
\sum_{n=0}^m 1_{\{N=n\}}x^n
=\sum_{k=0}^m N_k\underbrace{\sum_{l=0}^k \binom kl(-1)^{k-l}x^l}_{=\,(x-1)^k},
&lt;/math&gt;
which proves ({{EquationNote|4}}).
&lt;/div&gt;
&lt;/div&gt;

===Representation with shift and difference operators===
Consider the [[Linear map|linear]] [[shift operator]] {{mvar|E}} and the linear [[difference operator]] {{math|Δ}}, which we define here on the [[sequence space]] of {{mvar|V}} by

:&lt;math&gt;\begin{align}
E:V^{\mathbb{N}_0}&amp;\to V^{\mathbb{N}_0},\\
E(c_0,c_1,c_2,c_3,\ldots)&amp;\mapsto(c_1,c_2,c_3,\ldots),\\
\end{align}&lt;/math&gt;

and

:&lt;math&gt;\begin{align}
\Delta:V^{\mathbb{N}_0}&amp;\to V^{\mathbb{N}_0},\\
\Delta(c_0,c_1,c_2,c_3\ldots)&amp;\mapsto(c_1-c_0,c_2-c_1,c_3-c_2,\ldots).\\
\end{align}&lt;/math&gt;

Substituting {{math|''x'' {{=}} ''E''}} in ({{EquationNote|4}}) shows that

{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m 1_{\{N=n\}}E^n = \sum_{k=0}^m N_k\Delta^k,&lt;/math&gt;|{{EquationRef|5}}}}

where we used that {{math|Δ {{=}} ''E'' – ''I''}} with {{mvar|I}} denoting the [[identity operator]]. Note that {{math|''E''&lt;sup&gt;0&lt;/sup&gt;}} and {{math|Δ&lt;sup&gt;0&lt;/sup&gt;}} equal the identity operator&amp;nbsp;{{mvar|I}} on the sequence space, {{math|''E&lt;sup&gt;k&lt;/sup&gt;''}} and {{math|Δ&lt;sup&gt;''k''&lt;/sup&gt;}} denote the {{mvar|k}}-fold [[function composition|composition]].

&lt;div style="clear:both;width:95%;" class="NavFrame"&gt;
&lt;div class="NavHead" style="background-color:#FFFAF0; text-align:left; font-size:larger;"&gt;Direct proof of ({{EquationNote|5}}) by the operator method&lt;/div&gt;
&lt;div class="NavContent" style="text-align:left;display:none;"&gt;
To prove ({{EquationNote|5}}), we first want to verify the equation
{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m 1_{\{N=n\}}E^n=\prod_{j=1}^m(1_{A_j^{\mathrm c}}I+1_{A_j}E)&lt;/math&gt;|{{EquationRef|✳}}}}

involving [[indicator function]]s of the sets {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;m&lt;/sub&gt;''}} and their [[complement (set theory)|complements]] with respect to {{math|Ω}}. Suppose an {{mvar|ω}} from {{math|Ω}} belongs to exactly {{mvar|k}} sets out of {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;m&lt;/sub&gt;''}}, where {{math|''k'' ∈ {{mset|0, ..., ''m''}}}}, for simplicity of notation say that {{mvar|ω}} only belongs to {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;k&lt;/sub&gt;''}}. Then the left-hand side of ({{EquationNote|✳}}) is {{math|''E&lt;sup&gt;k&lt;/sup&gt;''}}. On the right-hand side of ({{EquationNote|✳}}), the first {{mvar|k}} factors equal {{mvar|E}}, the remaining ones equal {{mvar|I}}, their product is also {{math|''E&lt;sup&gt;k&lt;/sup&gt;''}}, hence the formula ({{EquationNote|✳}}) is true.

Note that

:&lt;math&gt;\begin{align}
1_{A_j^{\mathrm c}}I+1_{A_j}E
&amp;=I-1_{A_j}I+1_{A_j}E\\
&amp;=I+1_{A_j}(E-I)=I+1_{A_j}\Delta,\qquad j\in\{0,\ldots,m\}.
\end{align}&lt;/math&gt;

Inserting this result into equation ({{EquationNote|✳}}) and expanding the product gives

:&lt;math&gt;\sum_{n=0}^m 1_{\{N=n\}}E^n
=\sum_{k=0}^m\sum_{\scriptstyle J\subset\{1,\ldots,m\}\atop\scriptstyle|J|=k}
1_{\cap_{j\in J}A_j}\Delta^k,
&lt;/math&gt;

because the product of indicator functions is the indicator function of the intersection. Using the definition ({{EquationNote|2}}), the result ({{EquationNote|5}}) follows.
&lt;/div&gt;
&lt;/div&gt;

Let {{math|(Δ&lt;sup&gt;''k''&lt;/sup&gt;''c'')&lt;sub&gt;0&lt;/sub&gt;}} denote the 0th [[vector component|component]]  of the {{mvar|k}}-fold [[function composition|composition]] {{math|Δ&lt;sup&gt;''k''&lt;/sup&gt;}} applied to {{math|''c'' {{=}} (''c''&lt;sub&gt;0&lt;/sub&gt;, ''c''&lt;sub&gt;1&lt;/sub&gt;, ..., ''c&lt;sub&gt;m&lt;/sub&gt;'', ...)}}, where {{math|Δ&lt;sup&gt;0&lt;/sup&gt;}} denotes the identity. Then ({{EquationNote|3}}) can be rewritten in a more compact way as

{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m 1_{\{N=n\}}c_n = \sum_{k=0}^m N_k(\Delta^k c)_0.&lt;/math&gt;|{{EquationRef|6}}}}

==Probabilistic versions==

Consider arbitrary [[event (probability theory)|events]] {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;m&lt;/sub&gt;''}} in a [[probability space]] {{math|(Ω,&amp;thinsp;{{mathcal|F}},&amp;thinsp;ℙ)}} and let {{math|'''E'''}} denote the [[expected value|expectation operator]]. Then {{mvar|N}} from ({{EquationNote|1}}) is the [[random variable|random number]] of these events which occur simultaneously. Using {{math|''N&lt;sub&gt;k&lt;/sub&gt;''}} from ({{EquationNote|2}}), define

{{NumBlk|:|&lt;math&gt;S_k=\mathbb{E}[N_k]=\sum_{\scriptstyle J\subset\{1,\ldots,m\}\atop\scriptstyle|J|=k} \mathbb{P}\biggl(\bigcap_{j\in J}A_j\biggr),\qquad k\in\{0,\ldots,m\},&lt;/math&gt;|{{EquationRef|7}}}}

where the intersection over the empty index set is again defined as {{math|Ω}}, hence {{math|''S''&lt;sub&gt;0&lt;/sub&gt; {{=}} 1}}. If the ring {{mvar|R}} is also an [[unital algebra|algebra]] over the real or complex numbers, then taking the expectation of the coefficients in ({{EquationNote|4}}) and using the notation from ({{EquationNote|7}}),

{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m \mathbb{P}(N=n)x^n = \sum_{k=0}^m S_k(x-1)^k&lt;/math&gt;|{{EquationRef|4'}}}}

in {{math|''R''[''x'']}}. If {{mvar|R}} is the [[field (mathematics)|field]] of real numbers, then this is the [[probability-generating function]] of the [[probability distribution]] of {{mvar|N}}.

Similarly, ({{EquationNote|5}}) and ({{EquationNote|6}}) yield

{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m \mathbb{P}(N=n)E^n=\sum_{k=0}^m S_k\Delta^k&lt;/math&gt;|{{EquationRef|5'}}}}

and, for every sequence {{math|''c'' {{=}} (''c''&lt;sub&gt;0&lt;/sub&gt;, ''c''&lt;sub&gt;1&lt;/sub&gt;, ''c''&lt;sub&gt;2&lt;/sub&gt;, ''c''&lt;sub&gt;3&lt;/sub&gt;, ..., ''c&lt;sub&gt;m&lt;/sub&gt;'', ...)}},

{{NumBlk|:|&lt;math&gt;\sum_{n=0}^m \mathbb{P}(N=n)\,c_n=\sum_{k=0}^m S_k\,(\Delta^kc)_0.&lt;/math&gt;|{{EquationRef|6'}}}}

The quantity on the left-hand side of ({{EquationNote|6'}}) is the expected value of&amp;nbsp;{{math|''c''&lt;sub&gt;''N''&lt;/sub&gt;}}.

==Remarks==
#In [[actuarial science]], the name ''Schuette–Nesbitt formula'' refers to equation ({{EquationNote|6'}}), where {{mvar|V}} denotes the set of real numbers.
#The left-hand side of equation ({{EquationNote|5'}}) is a [[convex combination]] of the [[power (mathematics)|powers]] of the shift operator {{mvar|E}}, it can be seen as the [[expected value]] of random operator {{math|''E&lt;sup&gt;N&lt;/sup&gt;''}}. Accordingly, the left-hand side of equation ({{EquationNote|6'}}) is the expected value of random component {{math|''c&lt;sub&gt;N&lt;/sub&gt;''}}. Note that both have a [[discrete probability distribution]] with finite [[support (measure theory)|support]], hence expectations are just the well-defined finite sums.
#The probabilistic version of the [[inclusion–exclusion principle]] can be derived from equation ({{EquationNote|6'}}) by choosing the sequence {{math|''c'' {{=}} (0, 1, 1, ...)}}: the left-hand side reduces to the probability of the event {{math|{{mset|''N'' ≥ 1}}}}, which is the union of {{math|''A''&lt;sub&gt;1&lt;/sub&gt;, ..., ''A&lt;sub&gt;m&lt;/sub&gt;''}}, and the right-hand side is {{math|''S''&lt;sub&gt;1&lt;/sub&gt; – ''S''&lt;sub&gt;2&lt;/sub&gt; + ''S''&lt;sub&gt;3&lt;/sub&gt; – ... – (–1)&lt;sup&gt;''m''&lt;/sup&gt;''S&lt;sub&gt;m&lt;/sub&gt;''}}, because {{math|(Δ&lt;sup&gt;0&lt;/sup&gt;''c'')&lt;sub&gt;0&lt;/sub&gt; {{=}} 0}} and {{math|(Δ&lt;sup&gt;''k''&lt;/sup&gt;''c'')&lt;sub&gt;0&lt;/sub&gt; {{=}} –(–1)&lt;sup&gt;''k''&lt;/sup&gt;}} for {{math|''k'' ∈ {{mset|1, ..., ''m''}}}}.
#Equations ({{EquationNote|5}}), ({{EquationNote|5'}}), ({{EquationNote|6}}) and ({{EquationNote|6'}}) are also true when the shift operator and the difference operator are considered on a subspace like the [[Lp space#.E2.84.93p spaces|{{math|''ℓ&lt;sup&gt;&amp;nbsp;p&lt;/sup&gt;''}}&amp;nbsp;spaces]].
#If desired, the formulae ({{EquationNote|5}}), ({{EquationNote|5'}}), ({{EquationNote|6}}) and ({{EquationNote|6'}}) can be considered in finite dimensions, because only the first {{math|''m'' + 1}} components of the sequences matter. Hence, represent the linear shift operator {{mvar|E}} and the linear difference operator {{math|Δ}} as mappings of the {{math|(''m'' + 1)}}-dimensional [[Euclidean space]] into itself, given by the {{math|(''m'' + 1) × (''m'' + 1)}}-[[matrix (mathematics)|matrices]]

:::&lt;math&gt;E=\begin{pmatrix}
0&amp;1&amp;0&amp;\cdots&amp;0\\
0&amp;0&amp;1&amp;\ddots&amp;\vdots\\
\vdots&amp;\ddots&amp;\ddots&amp;\ddots&amp;0\\
0&amp;\cdots&amp;0&amp;0&amp;1\\
0&amp;\cdots&amp;0&amp;0&amp;0
\end{pmatrix},
\qquad
\Delta=\begin{pmatrix}
-1&amp;1&amp;0&amp;\cdots&amp;0\\
0&amp;-1&amp;1&amp;\ddots&amp;\vdots\\
\vdots&amp;\ddots&amp;\ddots&amp;\ddots&amp;0\\
0&amp;\cdots&amp;0&amp;-1&amp;1\\
0&amp;\cdots&amp;0&amp;0&amp;-1
\end{pmatrix},
&lt;/math&gt;

::and let {{mvar|I}} denote the {{math|(''m'' + 1)}}-dimensional [[identity matrix]]. Then ({{EquationNote|6}}) and ({{EquationNote|6'}}) hold for every [[vector space|vector]] {{math|''c'' {{=}} (''c''&lt;sub&gt;0&lt;/sub&gt;, ''c''&lt;sub&gt;1&lt;/sub&gt;, ..., ''c&lt;sub&gt;m&lt;/sub&gt;'')&lt;sup&gt;T&lt;/sup&gt;}} in {{math|(''m'' + 1)}}-dimensional Euclidean space, where the exponent {{math|T}} in the definition of {{mvar|c}} denotes the [[transpose]].
#Equations ({{EquationNote|5}}) and ({{EquationNote|5'}}) hold for an arbitrary linear operator {{mvar|E}} as long as {{math|Δ}} is the difference of {{mvar|E}} and the identity operator {{mvar|I}}.
#The probabilistic versions ({{EquationNote|4'}}), ({{EquationNote|5'}}) and ({{EquationNote|6'}}) can be generalized to every [[finite measure|finite measure space]].

For textbook presentations of the probabilistic Schuette–Nesbitt formula ({{EquationNote|6'}}) and their applications to actuarial science, cf. {{harvtxt|Gerber|1997}}. Chapter 8, or {{harvtxt|Bowers|Gerber|Hickman|Jones|1997}}, Chapter 18 and the Appendix, pp.&amp;nbsp;577–578.

==History==

For [[statistical independence|independent]] events, the formula ({{EquationNote|6'}}) appeared in a discussion of Robert P. White and T.N.E. Greville's paper by Donald R. Schuette and [[Cecil J. Nesbitt]], see {{harvtxt|Schuette|Nesbitt|1959}}. In the two-page note {{harvtxt|Gerber|1979}}, Hans U. Gerber, called it Schuette–Nesbitt formula and generalized it to arbitrary events. Christian Buchta, see {{harvtxt|Buchta|1994}}, noticed the combinatorial nature of the formula and published the elementary [[combinatorial proof]] of&amp;nbsp;({{EquationNote|3}}).

Cecil J. Nesbitt, [[PhD]], [[Society of Actuaries#FSA designation|F.S.A.]], M.A.A.A., received his [[mathematical education]] at the [[University of Toronto]] and the [[Institute for Advanced Study]] in [[Princeton, New Jersey|Princeton]]. He taught [[actuarial mathematics]] at the [[University of Michigan]] from 1938 to 1980. He served the [[Society of Actuaries]] from 1985 to 1987 as Vice-President for Research and Studies. Professor Nesbitt died in 2001. (Short [[curriculum vitae|CV]] taken from {{harvtxt|Bowers|Gerber|Hickman|Jones|1997}}, page&amp;nbsp;xv.)

Donald Richard Schuette was a PhD student of C.&amp;nbsp;Nesbitt, he later became professor at the [[University of Wisconsin–Madison]].

The probabilistic version of the Schuette–Nesbitt formula ({{EquationNote|6'}}) generalizes much older formulae of [[Edward Waring|Waring]], which express the probability of the events {{math|{{mset|''N'' {{=}} ''n''}}}} and {{math|{{mset|''N'' ≥ ''n''}}}} in terms of  {{math|''S''&lt;sub&gt;1&lt;/sub&gt;}}, {{math|''S''&lt;sub&gt;2&lt;/sub&gt;}}, ..., {{math|''S&lt;sub&gt;m&lt;/sub&gt;''}}. More precisely, with &lt;math&gt;\textstyle\binom kn&lt;/math&gt; denoting the [[binomial coefficient]],

{{NumBlk|:|&lt;math&gt;\mathbb{P}(N=n)=\sum_{k=n}^m(-1)^{k-n}\binom kn S_k, \qquad n\in\{0,\ldots,m\},&lt;/math&gt;|{{EquationRef|8}}}}

and

{{NumBlk|:|&lt;math&gt;\mathbb{P}(N\ge n)=\sum_{k=n}^m(-1)^{k-n}\binom{k-1}{n-1}S_k,\qquad n\in\{1,\ldots,m\},&lt;/math&gt;|{{EquationRef|9}}}}

see {{harvtxt|Feller|1968}}, Sections IV.3 and IV.5, respectively.

To see that these formulae are special cases of the probabilistic version of the Schuette–Nesbitt formula, note that by the [[binomial theorem]]

:&lt;math&gt;\Delta^k=(E-I)^k=\sum_{j=0}^k\binom kj (-1)^{k-j}E^j,\qquad k\in\mathbb{N}_0.&lt;/math&gt;

Applying this operator identity to the sequence {{math|''c'' {{=}} (0, ..., 0, 1, 0, 0, ...)}} with {{mvar|n}} leading zeros and noting that {{math|(''E&lt;sup&gt;&amp;nbsp;j&lt;/sup&gt;c'')&lt;sub&gt;0&lt;/sub&gt; {{=}} 1}} if {{math|''j'' {{=}} ''n''}} and {{math|(''E&lt;sup&gt;&amp;nbsp;j&lt;/sup&gt;c'')&lt;sub&gt;0&lt;/sub&gt; {{=}} 0}} otherwise, the formula ({{EquationNote|8}}) for {{math|{{mset|''N'' {{=}} ''n''}}}} follows from ({{EquationNote|6'}}).

Applying the identity to {{math|''c'' {{=}} (0, ..., 0, 1, 1, 1, ...)}} with {{mvar|n}} leading zeros and noting that {{math|(''E&lt;sup&gt;&amp;nbsp;j&lt;/sup&gt;c'')&lt;sub&gt;0&lt;/sub&gt; {{=}} 1}} if {{math|''j'' ≥ ''n''}} and {{math|(''E&lt;sup&gt;&amp;nbsp;j&lt;/sup&gt;c'')&lt;sub&gt;0&lt;/sub&gt; {{=}} 0}} otherwise, equation ({{EquationNote|6'}}) implies that

:&lt;math&gt;\mathbb{P}(N\ge n)=\sum_{k=n}^m S_k\sum_{j=n}^k\binom kj(-1)^{k-j}.&lt;/math&gt;

Expanding {{math|(1 – 1)&lt;sup&gt;''k''&lt;/sup&gt;}} using the binomial theorem and using [[Binomial coefficient#Formulas involving binomial coefficients|equation (11) of the formulas involving binomial coefficients]], we obtain

:&lt;math&gt;\sum_{j=n}^k\binom kj(-1)^{k-j}
=-\sum_{j=0}^{n-1}\binom kj(-1)^{k-j}
=(-1)^{k-n}\binom{k-1}{n-1}.&lt;/math&gt;

Hence, we have the formula ({{EquationNote|9}}) for {{math|{{mset|''N'' ≥ ''n''}}}}.

==An application in actuarial science==

'''Problem:''' Suppose there are {{mvar|m}} persons aged {{math|''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x&lt;sub&gt;m&lt;/sub&gt;''}} with remaining random (but independent) lifetimes {{math|''T''&lt;sub&gt;1&lt;/sub&gt;, ..., ''T&lt;sub&gt;m&lt;/sub&gt;''}}. Suppose the group signs a life insurance contract which pays them after {{mvar|t}} years the amount {{math|''c&lt;sub&gt;n&lt;/sub&gt;''}} if exactly {{mvar|n}} persons out of {{mvar|m}} are still alive after {{mvar|t}} years. How high is the expected payout of this insurance contract in {{mvar|t}} years?

'''Solution:''' Let {{math|''A&lt;sub&gt;j&lt;/sub&gt;''}} denote the event that person {{mvar|j}} survives {{mvar|t}} years, which means that {{math|''A&lt;sub&gt;j&lt;/sub&gt;'' {{=}} {{mset|''T&lt;sub&gt;j&lt;/sub&gt;'' &gt; ''t''}}}}. In [[actuarial notation]] the probability of this event is denoted by {{math|''&lt;sub&gt;t&lt;/sub&gt;&amp;thinsp;p&lt;sub&gt;x&lt;sub&gt;j&lt;/sub&gt;&lt;/sub&gt;''}} and can be taken from a [[life table]]. Use independence to calculate the probability of intersections. Calculate {{math|''S''&lt;sub&gt;1&lt;/sub&gt;, ..., ''S&lt;sub&gt;m&lt;/sub&gt;''}} and use the probabilistic version of the Schuette–Nesbitt formula ({{EquationNote|6'}}) to calculate the expected value of {{math|''c&lt;sub&gt;N&lt;/sub&gt;''}}.

==An application in probability theory==

Let {{mvar|σ}} be a [[random permutation]] of the set {{math|{{mset|1, ..., ''m''}}}} and let {{math|''A&lt;sub&gt;j&lt;/sub&gt;''}} denote the event that {{mvar|''j''}} is a [[Fixed point (mathematics)|fixed point]] of {{mvar|σ}}, meaning that {{math|''A&lt;sub&gt;j&lt;/sub&gt;'' {{=}} {{mset|''σ''(''j'') {{=}} ''j''}}}}. When the numbers in {{mvar|J}}, which is a subset of {{math|{{mset|1, ..., ''m''}}}}, are fixed points, then there are {{math|(''m'' – {{abs|''J''}})!}} ways to permute the remaining {{math|''m'' – {{abs|''J''}}}} numbers, hence

:&lt;math&gt;\mathbb{P}\biggl(\bigcap_{j\in J}A_j\biggr)=\frac{(m-|J|)!}{m!}.&lt;/math&gt;

By the combinatorical interpretation of the [[binomial coefficient]], there are &lt;math&gt;\textstyle\binom mk&lt;/math&gt; different choices of a subset {{mvar|J}} of {{math|{{mset|1, ..., ''m''}}}} with {{mvar|k}} elements, hence ({{EquationNote|7}}) simplifies to

:&lt;math&gt;S_k=\binom mk \frac{(m-k)!}{m!}=\frac1{k!}.&lt;/math&gt;

Therefore, using ({{EquationNote|4'}}), the [[probability-generating function]] of the number {{mvar|N}} of fixed points is given by

:&lt;math&gt;\mathbb{E}[x^N]=\sum_{k=0}^m\frac{(x-1)^k}{k!},\qquad x\in\mathbb{R}.&lt;/math&gt;

This is the [[partial sum]] of the infinite series giving the [[exponential function]] at {{math|''x'' – 1}}, which in turn is the [[Probability-generating function#Examples|probability-generating function]] of the [[Poisson distribution]] with parameter {{math|1}}. Therefore, as {{mvar|m}} tends to [[infinity]], the distribution of {{mvar|N}} [[Convergence in distribution|converges]] to the Poisson distribution with parameter {{math|1}}.

==See also==
*[[Rencontres numbers]]

==References==
* {{Citation
  | last = Bowers
  | first = Newton L.
  | last2 = Gerber
  | first2 = Hans U.
  | last3 = Hickman
  | first3 = James C.
  | last4 = Jones
  | first4 = Donald A.
  | last5 = Nesbitt
  | first5 = Cecil J.
  | title = Actuarial Mathematics
  | edition = 2nd
  | publisher = The Society of Actuaries
  | year = 1997
  | isbn = 0-938959-46-8
  | zbl = 0634.62107}}
* {{Citation
  | last1 = Buchta
  | first1 = Christian
  | title = An elementary proof of the Schuette–Nesbitt formula
  | journal = Mitteilungen der Schweiz. Vereinigung der Versicherungsmathematiker
  | volume = 1994
  | issue = 2
  | pages = 219–220
  | year = 1994
  | zbl = 0825.62745}}
* {{Citation
 | last = Feller
 | first = William
 | author-link = William Feller
 | title = An Introduction to Probability Theory and Its Applications
 | place = New York, London, Sydney
 | publisher = John Wiley and Sons
 | series = Wiley Series in Probability and Mathematical Statistics
 | volume = I
 | year = 1968
 | origyear = 1950
 | edition = revised printing, 3rd
 | isbn = 0-471-25708-7
 | zbl = 0155.23101}}
* {{Citation
 | last = Gerber
 | first = Hans U.
 | title = A proof of the Schuette–Nesbitt formula for dependent events
 | journal = Actuarial Research Clearing House
 | volume = 1
 | pages = 9–10
 | year = 1979
 | url = http://www.soa.org/library/research/actuarial-research-clearing-house/1978-89/1979/arch-1/arch79v16.pdf}}
* {{Citation
 | last = Gerber
 | first = Hans U.
 | title = Life Insurance Mathematics
 | place = Berlin
 | publisher = Springer-Verlag
 | origyear = 1986
 | year = 1997
 | edition = 3rd
 | isbn = 3-540-62242-X
 | zbl = 0869.62072}}
* {{Citation
 | last = Schuette
 | first = Donald R.
 | last2 = Nesbitt
 | first2 = Cecil J.
 | author2-link = Cecil J. Nesbitt
 | title = Discussion of the preceding paper by Robert P. White and T.N.E. Greville
 | journal = Transactions of Society of Actuaries
 | volume = 11
 | issue = 29AB
 | pages = 97–99
 | year = 1959
 | url = http://www.soa.org/library/research/transactions-of-society-of-actuaries/1959/january/tsa59v11n29ab7.pdf}}

==External links==
*{{Mathgenealogy|name = Cecil J. Nesbitt|id = 7749}}
*{{Mathgenealogy|name = Donald R. Schuette|id = 5022}}

{{DEFAULTSORT:Schuette-Nesbitt formula}}
[[Category:Enumerative combinatorics]]
[[Category:Probability theorems]]
[[Category:Statistical theorems]]
[[Category:Articles containing proofs]]</text>
      <sha1>eru4y2vw00bc6cv2eu1njmhq1242ahz</sha1>
    </revision>
  </page>
  <page>
    <title>Self-adjoint</title>
    <ns>0</ns>
    <id>302202</id>
    <revision>
      <id>793295655</id>
      <parentid>682021455</parentid>
      <timestamp>2017-07-31T21:33:49Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>/* top */ A* → A{{sup|∗}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2009">In [[mathematics]], an element ''x'' of a [[*-algebra]] is '''self-adjoint''' if  &lt;math&gt;x^*=x&lt;/math&gt;.

A collection ''C'' of elements of a star-algebra is '''self-adjoint''' if it is closed under the [[Involution (mathematics)|involution]] operation. For example, if &lt;math&gt;x^*=y&lt;/math&gt; then since &lt;math&gt;y^*=x^{**}=x&lt;/math&gt; in a star-algebra, the set {''x'',''y''} is a self-adjoint set even though ''x'' and ''y'' need not be self-adjoint elements.

In [[functional analysis]], a [[linear operator]] ''A'' on a [[Hilbert space]] is called '''self-adjoint''' if it is equal to its own [[adjoint operator|adjoint]] ''A''{{sup|∗}} and that the domain of ''A'' is the same as that of ''A''{{sup|∗}}. See [[self-adjoint operator]] for a detailed discussion. If the Hilbert space is finite-dimensional and an [[orthonormal basis]] has been chosen, then the operator ''A'' is self-adjoint if and only if the [[matrix (mathematics)|matrix]] describing ''A'' with respect to this basis is [[Hermitian matrix|Hermitian]], i.e. if it is equal to its own [[conjugate transpose]]. Hermitian matrices are also called '''self-adjoint'''.

In a [[dagger category]], a [[morphism]] &lt;math&gt; f&lt;/math&gt; is called '''self-adjoint''' if &lt;math&gt; f=f^\dagger&lt;/math&gt;; this is possible only for an [[endomorphism]] &lt;math&gt;f\colon A \to A&lt;/math&gt;.

==See also==
*[[Symmetric matrix]]
*[[Self-adjoint operator]]
*[[Hermitian matrix]]

==References==
*{{cite book |authorlink=Michael C. Reed |first=M. |last=Reed |authorlink2=Barry Simon |first2=B. |last2=Simon |title=Methods of Mathematical Physics |others=Vol 2 |publisher=Academic Press |year=1972 |isbn= }}
*{{cite book |authorlink=Gerald Teschl |first=G. |last=Teschl |title=Mathematical Methods in Quantum Mechanics; With Applications to Schrödinger Operators |publisher=American Mathematical Society |location=Providence |year=2009 |url=http://www.mat.univie.ac.at/~gerald/ftp/book-schroe/ }}

{{DEFAULTSORT:Self-Adjoint}}
[[Category:Abstract algebra]]
[[Category:Linear algebra]]</text>
      <sha1>e42xwbf64j305c2conhk3eyx56ars3p</sha1>
    </revision>
  </page>
  <page>
    <title>Self-organization in cybernetics</title>
    <ns>0</ns>
    <id>52563216</id>
    <revision>
      <id>846856895</id>
      <parentid>846717456</parentid>
      <timestamp>2018-06-21T09:01:59Z</timestamp>
      <contributor>
        <username>Mauro Lanari</username>
        <id>7652703</id>
      </contributor>
      <comment>+ source ({{cite book}})</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11191">[[Self-organization]], a process where some form of overall [[order and disorder|order]] arises out of the local interactions between parts of an initially disordered system, was discovered in [[cybernetics]] by [[William Ross Ashby]] in 1947.&lt;ref name=ashby1947&gt;{{Cite journal | doi=10.1080/00221309.1947.9918144| pmid=20270223| title=Principles of the Self-Organizing Dynamic System| journal=The Journal of General Psychology| volume=37| issue=2| pages=125–8| year=1947| last1=Ashby | first1=W. R.}}&lt;/ref&gt;&lt;ref&gt;Ashby, W. R. (1962). [http://csis.pace.edu/~marchese/CS396x/Computing/Ashby.pdf "Principles of the self-organizing system"], pp. 255–278 in ''Principles of Self-Organization''. [[Heinz von Foerster]] and George W. Zopf, Jr. (eds.) U.S. Office of Naval Research.&lt;/ref&gt; It states that any deterministic [[dynamic system]] automatically evolves towards a state of equilibrium that can be described in terms of an [[attractor]] in a [[Attractor|basin]] of surrounding states. Once there, the further evolution of the system is constrained to remain in the attractor. This constraint implies a form of mutual dependency or coordination between its constituent components or subsystems. In Ashby's terms, each subsystem has adapted to the environment formed by all other subsystems.&lt;ref name=ashby1947/&gt;

The cybernetician [[Heinz von Foerster]] formulated the principle of "order from [[noise (signal processing)|noise]]" in 1960.&lt;ref&gt;Von Foerster, H. (1960). [http://e1020.pbworks.com/f/fulltext.pdf "On self-organizing systems and their environments"], pp. 31–50 in ''Self-organizing systems''. M.C. Yovits and S. Cameron (eds.), Pergamon Press, London&lt;/ref&gt; It notes that self-organization is facilitated by random perturbations ("noise") that let the system explore a variety of states in its state space. This increases the chance that the system will arrive into the basin of a "strong" or "deep" attractor, from which it then quickly enters the attractor itself. The biophysicist [[Henri Atlan]] developed such a concept by proposing the principle of "[[complexity]] from noise"&lt;ref&gt;See [https://www.google.com/search?&amp;tbm=bks&amp;q=inauthor:%22Henri+Atlan%22%22complexity+from+noise%22 occurrences] on [[Google Books]].&lt;/ref&gt;&lt;ref&gt;{{cite book |editor-last=François |editor-first=Charles |editor-link=Charles François (systems scientist) |title=[[International Encyclopedia of Systems and Cybernetics]] |year=2011 |origyear=[https://books.google.com/books?id=SZxnQgAACAAJ 1997] |edition=2nd |publisher=[[Walter de Gruyter]] |location=[[Berlin]] |page=[https://books.google.com/?id=XCn2mn98uEAC&amp;pg=PA107&amp;dq=%22complexity+from+noise+principle%22+Atlan+1972 107] |isbn=3-1109-6801-0 |id={{ISBN|978-3-110-96801-9}}}}&lt;/ref&gt; ({{lang-fr|le principe de complexité par le bruit}})&lt;ref&gt;See [https://www.google.com/search?&amp;tbm=bks&amp;q=inauthor:%22Henri+Atlan%22%22complexité+par+le+bruit%22 occurrences] on Google Books.&lt;/ref&gt; first in the 1972 book ''L'organisation biologique et la théorie de l'information''&lt;ref&gt;[https://www.google.com/search?&amp;q=%22complexité+par+le+bruit%22%22L'Organisation+biologique+et+la+théorie+de+l'information%22+1972].&lt;/ref&gt; and then in the 1979 book ''Entre le cristal et la fumée''.&lt;ref&gt;[https://www.google.com/search?&amp;q=%22complexité+par+le+bruit%22%22Entre+le+cristal+et+la+fumée%22+1979].&lt;/ref&gt; The thermodynamicist [[Ilya Prigogine]] formulated a similar principle as "order through fluctuations"&lt;ref&gt;Nicolis, G. and Prigogine, I. (1977). ''Self-organization in nonequilibrium systems: From dissipative structures to order through fluctuations''. Wiley, New York.&lt;/ref&gt; or "order out of chaos".&lt;ref&gt;Prigogine, I. and Stengers, I. (1984). ''Order out of chaos: Man's new dialogue with nature''. Bantam Books.&lt;/ref&gt; It is applied in the method of [[simulated annealing]] for [[problem solving]] and [[machine learning]].&lt;ref&gt;{{cite journal|last1=Ahmed|first1=Furqan|last2=Tirkkonen |first2=Olav|title=Applied Soft Computing |journal=Applied Soft Computing |date=January 2016 |volume=38|pages=762–770 |doi=10.1016/j.asoc.2015.10.028 |url=http://www.sciencedirect.com/science/article/pii/S1568494615006687}}&lt;/ref&gt;

[[Norbert Wiener|Wiener]] regarded the automatic serial [[System identification|identification]] of a [[black box]] and its subsequent reproduction (copying) as sufficient to meet the condition of self-organization.&lt;ref&gt;Wiener, Norbert (1962) "The mathematics of self-organising systems". ''Recent developments in information and decision processes'', Macmillan, N. Y. and Chapter X in ''Cybernetics, or control and communication in the animal and the machine'', The MIT Press.&lt;/ref&gt; The importance of [[phase locking]] or the "attraction of frequencies", as he called it, is discussed in the 2nd edition of his "[[Cybernetics]]".&lt;ref&gt;''Cybernetics, or control and communication in the animal and the machine'', The MIT Press, Cambridge, Massachusetts and Wiley, NY, 1948. 2nd Edition 1962 "Chapter X "Brain Waves and Self-Organizing Systems"pp 201–202.&lt;/ref&gt; [[K. Eric Drexler|Drexler]] sees [[Molecular assembler|self-replication]] (copying) as a key step in nano and [[Universal assembler|universal assembly]].&lt;ref&gt;Eric K. Drexler "Engines of Creation" 1986&lt;/ref&gt; In later work he seeks to lessen this constraint.&lt;ref&gt;Engines of Creation 2 http://www1.appstate.edu/dept/physics/nanotech/EnginesofCreation2_8803267.pdf&lt;/ref&gt;

By contrast, the four concurrently connected galvanometers of W. Ross Ashby's [[Homeostat]] [[Hunting oscillation|hunt]], when perturbed, to converge on one of many possible stable states.&lt;ref&gt;[[William Ross Ashby|Ashby, William Ross]] (1952) ''Design for a Brain'', Chapter 5 Chapman &amp; Hall&lt;/ref&gt; Ashby used his state counting measure of [[variety (cybernetics)|variety]]&lt;ref&gt;Ashby, William Ross (1956) [http://pespmc1.vub.ac.be/books/introcyb.pdf ''An Introduction to Cybernetics''], Part Two Chapman &amp; Hall&lt;/ref&gt; to describe stable states and produced the "[[Good Regulator]]"&lt;ref&gt;{{cite journal|title=Every good regulator of a system must be a model of that system  |author=Conant, R. C.|author2=Ashby, W. R. |journal=Int. J. Systems Sci.|volume=1|issue=2|pages=89–97|year=1970|url=http://pcp.vub.ac.be/Books/Conant_Ashby.pdf|doi=10.1080/00207727008920220}}&lt;/ref&gt; theorem which requires internal models for self-organized [[Endurantism|endurance]] and stability (e.g. [[Nyquist stability criterion]]).

[[Warren McCulloch]] proposed "Redundancy of Potential Command"&lt;ref&gt;''Embodiments of Mind'' MIT Press (1965)"&lt;/ref&gt; as characteristic of the organization of the brain and human nervous system and the necessary condition for self-organization.

[[Heinz von Foerster]] proposed Redundancy, ''R'' = 1&amp;nbsp;−&amp;nbsp;''H''/''H''&lt;sub&gt;max&lt;/sub&gt;, where ''H'' is [[entropy]].&lt;ref&gt;{{cite journal|author=von Foerster, Heinz |author2= Pask, Gordon |title=A Predictive Model for Self-Organizing Systems, Part I|journal=Cybernetica|volume= 3|pages= 258–300|year=1961}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=von Foerster, Heinz |author2= Pask, Gordon |title=A Predictive Model for Self-Organizing Systems, Part II|journal=Cybernetica|volume= 4 |pages=20–55|year= 1961}}&lt;/ref&gt; In essence this states that unused potential communication bandwidth is a measure of self-organization.

In the 1970s [[Stafford Beer]] considered this condition as necessary for [[autonomy]] which identifies self-organization in persisting and living systems. He applied his [[viable system model]] to management. It consists of five parts: the monitoring of performance of the survival processes (1), their management by recursive application of regulation (2), [[Homeostasis|homeostatic]] operational control (3) and development (4) which produce maintenance of identity (5) under environmental perturbation. Focus is prioritized by an alerting "algedonic loop" feedback: a sensitivity to both pain and pleasure produced from under-performance or over-performance relative to a standard capability.&lt;ref&gt;"Brain of the Firm" Alan Lane (1972) see also "Beyond Dispute," Wiley, Stafford Beer 1994 "Redundancy of Potential Command" pp. 157–158.&lt;/ref&gt;{{Full citation needed|date=April 2018}}

In the 1990s [[Gordon Pask]] pointed out von Foerster's H and Hmax were not independent and interacted via [[Countable set|countably infinite]] recursive concurrent [[spin (physics)|spin]] processes&lt;ref name=p1996/&gt; (he favoured the [[Bohm interpretation]]) which he called concepts (liberally defined in ''any'' medium, "productive and, incidentally reproductive"). His strict definition of concept "a procedure to bring about a relation"&lt;ref name=p1973&gt;Pask, G. (1973). ''Conversation, Cognition and Learning. A Cybernetic Theory and Methodology''. Elsevier&lt;/ref&gt; permitted his theorem "Like concepts repel, unlike concepts attract"&lt;ref&gt;{{Cite journal | doi = 10.1108/03684920110391913| title = On Gordon Pask| journal = Kybernetes| volume = 30| issue = 5/6| pages = 673| year = 2001| last1 = Green | first1 = N. }}&lt;/ref&gt; to state a general spin based ''principle of self-organization''. His edict, an exclusion principle, "There are [[Gordon Pask#No Doppelgangers|No Doppelgangers]]"&lt;ref&gt;Pask, Gordon (1993) [http://www.cybsoc.org/PasksIAT.PDF ''Interactions of Actors (IA), Theory and Some Applications''].&lt;/ref&gt;&lt;ref name=p1996&gt;{{cite journal|author=Pask, Gordon |year=1996|url=http://www.cybsoc.org/GPprog.PDF |title=Heinz von Foerster's Self-Organisation, the Progenitor of Conversation and Interaction Theories|journal= Systems Research |volume=13|issue= 3|pages=349–362 |doi=10.1002/(sici)1099-1735(199609)13:3&lt;349::aid-sres103&gt;3.3.co;2-7}}&lt;/ref&gt; means no two concepts can be the same (all interactions occur with different perspectives making time incommensurable for [[Gordon Pask#Interactions of Actors Theory|actors]]). This means, after sufficient duration as differences assert, all concepts will attract and coalesce as [[pink noise]] and [[entropy]] increases (and see [[Big Crunch]], [[self-organized criticality]]). The theory is applicable to all organizationally [[Closure (topology)|closed]] or homeostatic processes that produce [[Endurantism|enduring]] and [[Coherence (physics)|coherent]] products (where spins have a fixed average phase relationship and also in the sense of [[Nicholas Rescher]]'s coherence theory of truth with the proviso that the sets and their members exert repulsive forces at their boundaries) through interactions: [[Evolution|evolving]], [[learning]] and [[adaptation|adapting]].

Pask's [[Gordon Pask#Interactions of Actors Theory|Interactions of Actors]] "hard carapace" model is reflected in some of the ideas of [[emergence]] and [[Coherence (physics)|coherence]]. It requires a [[knot theory|knot]] [[Emergence#Mathematics|emergence topology]] that produces radiation during interaction with a [[unit cell]] that has a prismatic [[tensegrity]] structure. [[Robert B. Laughlin|Laughlin]]'s  [[Emergence#CITEREFLaughlin2005|contribution]] to emergence reflects some of these constraints.&lt;ref&gt;R. B. Laughlin and David Pines "The Theory of Everything" http://www.pnas.org/content/97/1/28.full&lt;/ref&gt;

==References==
{{reflist|30em}}

[[Category:Cybernetics]]
[[Category:Self-organization]]</text>
      <sha1>2bwm6wm4rvcaewbcnhkhgrowjmx07x8</sha1>
    </revision>
  </page>
  <page>
    <title>Skew-symmetric graph</title>
    <ns>0</ns>
    <id>17283742</id>
    <revision>
      <id>842553752</id>
      <parentid>841535352</parentid>
      <timestamp>2018-05-23T05:41:07Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add arxiv identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17338">{{Graph families defined by their automorphisms}}
In [[graph theory]], a branch of mathematics, a '''skew-symmetric graph''' is a [[directed graph]] that is [[graph isomorphism|isomorphic]] to its own [[transpose graph]], the graph formed by reversing all of its edges, under an isomorphism that is an [[involution (mathematics)|involution]] without any [[Fixed point (mathematics)|fixed points]].  Skew-symmetric graphs are identical to the [[Bipartite double cover|double covering graphs]] of [[bidirected graph]]s.

Skew-symmetric graphs were first introduced under the name of ''antisymmetrical digraphs'' by {{harvtxt|Tutte|1967}}, later as the double covering graphs of polar graphs by {{harvtxt|Zelinka|1976b}}, and still later as the double covering graphs of bidirected graphs by {{harvtxt|Zaslavsky|1991}}. They arise in modeling the search for alternating paths and alternating cycles in algorithms for finding [[Matching (graph theory)|matchings]] in graphs, in testing whether a [[still life (cellular automaton)|still life]] pattern in [[Conway's Game of Life]] may be partitioned into simpler components, in [[graph drawing]], and in the [[implication graph]]s used to efficiently solve the [[2-satisfiability]] problem.

==Definition==
As defined, e.g., by {{harvtxt|Goldberg|Karzanov|1996}}, a skew-symmetric graph ''G'' is a directed graph, together with a function σ mapping vertices of ''G'' to other vertices of ''G'', satisfying the following properties:
# For every vertex ''v'', σ(''v'') ≠ ''v'',
# For every vertex ''v'', σ(σ(''v'')) = ''v'',
# For every edge (''u'',''v''), (σ(''v''),σ(''u'')) must also be an edge.
One may use the third property to extend σ to an orientation-reversing function on the edges of ''G''.

The [[transpose graph]] of ''G'' is the graph formed by reversing every edge of ''G'', and σ defines a [[graph isomorphism]] from ''G'' to its transpose. However, in a skew-symmetric graph, it is additionally required that the isomorphism pair each vertex with a different vertex, rather than allowing a vertex to be mapped to itself by the isomorphism or to group more than two vertices in a cycle of isomorphism.

A path or cycle in a skew-symmetric graph is said to be ''regular'' if, for each vertex ''v'' of the path or cycle, the corresponding vertex σ(''v'') is not part of the path or cycle.

==Examples==
Every directed [[path graph]] with an even number of vertices is skew-symmetric, via a symmetry that swaps the two ends of the path. However, path graphs with an odd number of vertices are not skew-symmetric, because the orientation-reversing symmetry of these graphs maps the center vertex of the path to itself, something that is not allowed for skew-symmetric graphs.

Similarly, a directed [[cycle graph]] is skew-symmetric if and only if it has an even number of vertices. In this case, the number of different mappings σ that realize the skew symmetry of the graph equals half the length of the cycle.

==Polar/switch graphs, double covering graphs, and bidirected graphs==
A skew-symmetric graph may equivalently be defined as the double covering graph of a ''polar graph'' (introduced by {{harvtxt|Zelinka|1974}}, {{harvtxt|Zelinka|1976}}, called a ''switch graph'' by {{harvtxt|Cook|2003}}), which is an undirected graph in which the edges incident to each vertex are partitioned into two subsets. Each vertex of the polar graph corresponds to two vertices of the skew-symmetric graph, and each edge of the polar graph corresponds to two edges of the skew-symmetric graph. This equivalence is the one used by {{harvtxt|Goldberg|Karzanov|1996}} to model problems of matching in terms of skew-symmetric graphs; in that application, the two subsets of edges at each vertex are the unmatched edges and the matched edges. Zelinka (following F. Zitek) and Cook visualize the vertices of a polar graph as points where multiple tracks of a [[train track (mathematics)|train track]] come together: if a train enters a switch via a track that comes in from one direction, it must exit via a track in the other direction.  The problem of finding non-self-intersecting smooth curves between given points in a train track comes up in testing whether certain kinds of [[graph drawing]]s are valid {{harv|Hui|Schaefer|Štefankovič|2004}} and may be modeled as the search for a regular path in a skew-symmetric graph.

A closely related concept is the [[bidirected graph]] of {{harvtxt|Edmonds|Johnson|1970}} ("polarized graph" in the terminology of {{harvtxt|Zelinka|1974}}, {{harvtxt|Zelinka|1976}}), a graph in which each of the two ends of each edge may be either a head or a tail, independently of the other end. A bidirected graph may be interpreted as a polar graph by letting the partition of edges at each vertex be determined by the partition of endpoints at that vertex into heads and tails; however, swapping the roles of heads and tails at a single vertex ("switching" the vertex, in the terminology of {{harvtxt|Zaslavsky|1991}}) produces a different bidirected graph but the same polar graph. 

For the correspondence between bidirected graphs and skew-symmetric graphs (i.e., their double covering graphs) see {{harvtxt|Zaslavsky|1991}}, Section 5, or {{harvtxt|Babenko|2006}}. 

To form the double covering graph (i.e., the corresponding skew-symmetric graph) from a polar graph ''G'', create for each vertex ''v'' of ''G'' two vertices ''v''&lt;sub&gt;0&lt;/sub&gt; and ''v''&lt;sub&gt;1&lt;/sub&gt;, and let σ(''v''&lt;sub&gt;''i''&lt;/sub&gt;)&amp;nbsp;=&amp;nbsp;''v''&lt;sub&gt;1&amp;nbsp;&amp;minus;&amp;nbsp;''i''&lt;/sub&gt;. For each edge ''e''&amp;nbsp;=&amp;nbsp;(''u'',''v'') of ''G'', create two directed edges in the covering graph, one oriented from ''u'' to ''v'' and one oriented from ''v'' to ''u''. If ''e'' is in the first subset of edges at ''v'', these two edges are from ''u''&lt;sub&gt;0&lt;/sub&gt; into ''v''&lt;sub&gt;0&lt;/sub&gt; and from ''v''&lt;sub&gt;1&lt;/sub&gt; into ''u''&lt;sub&gt;1&lt;/sub&gt;, while if ''e'' is in the second subset, the edges are from ''u''&lt;sub&gt;0&lt;/sub&gt; into ''v''&lt;sub&gt;1&lt;/sub&gt; and from ''v''&lt;sub&gt;0&lt;/sub&gt; into ''u''&lt;sub&gt;1&lt;/sub&gt;.
In the other direction, given a skew-symmetric graph ''G'', one may form a polar graph that has one vertex for every corresponding pair of vertices in ''G'' and one undirected edge for every corresponding pair of edges in ''G''. The undirected edges at each vertex of the polar graph may be partitioned into two subsets according to which vertex of the polar graph they go out of and come into.

A regular path or cycle of a skew-symmetric graph corresponds to a path or cycle in the polar graph that uses at most one edge from each subset of edges at each of its vertices.

==Matching==
In constructing [[Matching (graph theory)|matchings]] in undirected graphs, it is important to find ''alternating paths'', paths of vertices that start and end at unmatched vertices, in which the edges at odd positions in the path are not part of a given partial matching and in which the edges at even positions in the path are part of the matching. By removing the matched edges of such a path from a matching, and adding the unmatched edges, one can increase the size of the matching. Similarly, cycles that alternate between matched and unmatched edges are of importance in weighted matching problems.
As {{harvtxt|Goldberg|Karzanov|1996}} showed, an alternating path or cycle in an undirected graph may be modeled as a regular path or cycle in a skew-symmetric directed graph. To create a skew-symmetric graph from an undirected graph ''G'' with a specified matching ''M'', view ''G'' as a switch graph in which the edges at each vertex are partitioned into matched and unmatched edges; an alternating path in ''G'' is then a regular path in this switch graph and an alternating cycle in ''G'' is a regular cycle in the switch graph.

{{harvtxt|Goldberg|Karzanov|1996}} generalized alternating path algorithms to show that the existence of a regular path between any two vertices of a skew-symmetric graph may be tested in linear time. Given additionally a non-negative length function on the edges of the graph that assigns the same length to any edge ''e'' and to σ(''e''), the shortest regular path connecting a given pair of nodes in a skew-symmetric graph with ''m'' edges and ''n'' vertices may be tested in time O(''m''&amp;nbsp;log&amp;nbsp;''n''). If the length function is allowed to have negative lengths, the existence of a negative regular cycle may be tested in polynomial time.

Along with the path problems arising in matchings, skew-symmetric generalizations of the [[max-flow min-cut theorem]] have also been studied ({{harvnb|Goldberg|Karzanov|2004}}; {{harvnb|Tutte|1967}}).

==Still life theory==
{{harvtxt|Cook|2003}} shows that a [[still life (cellular automaton)|still life pattern]] in [[Conway's Game of Life]] may be partitioned into two smaller still lifes if and only if an associated switch graph contains a regular cycle. As he shows, for switch graphs with at most three edges per vertex, this may be tested in polynomial time by repeatedly removing [[Bridge (graph theory)|bridges]] (edges the removal of which disconnects the graph) and vertices at which all edges belong to a single partition until no more such simplifications may be performed. If the result is an [[empty graph]], there is no regular cycle; otherwise, a regular cycle may be found in any remaining bridgeless component. The repeated search for bridges in this algorithm may be performed efficiently using a dynamic graph algorithm of {{harvtxt|Thorup|2000}}.

Similar bridge-removal techniques in the context of matching were previously considered by {{harvtxt|Gabow|Kaplan|Tarjan|1999}}.

==Satisfiability==
[[File:Implication graph.svg|thumb|240px|An [[implication graph]]. Its skew symmetry can be realized by rotating the graph through a 180 degree angle and reversing all edges.]]
An instance of the [[2-satisfiability]] problem, that is, a Boolean expression in [[conjunctive normal form]] with two variables or negations of variables per clause, may be transformed into an [[implication graph]] by replacing each clause &lt;math&gt;\scriptstyle u\lor v&lt;/math&gt; by the two implications
&lt;math&gt;\scriptstyle(\lnot u)\Rightarrow v&lt;/math&gt; and &lt;math&gt;\scriptstyle(\lnot v)\Rightarrow u&lt;/math&gt;. This graph has a vertex for each variable or negated variable, and a directed edge for each implication; it is, by construction, skew-symmetric, with a correspondence σ that maps each variable to its negation.
As {{harvtxt|Aspvall|Plass|Tarjan|1979}} showed, a satisfying assignment to the 2-satisfiability instance is equivalent to a partition of this implication graph into two subsets of vertices, ''S'' and σ(''S''), such that no edge starts in ''S'' and ends in σ(''S''). If such a partition exists, a satisfying assignment may be formed by assigning a true value to every variable in ''S'' and a false value to every variable in σ(''S''). This may be done if and only if no [[strongly connected component]] of the graph contains both some vertex ''v'' and its complementary vertex σ(''v''). If two vertices belong to the same strongly connected component, the corresponding variables or negated variables are constrained to equal each other in any satisfying assignment of the 2-satisfiability instance. The total time for testing strong connectivity and finding a partition of the implication graph is linear in the size of the given 2-CNF expression.

==Recognition==
It is [[NP-complete]] to determine whether a given directed graph is skew-symmetric, by a result of {{harvtxt|Lalonde|1981}} that it is NP-complete to find a color-reversing involution in a [[bipartite graph]]. Such an involution exists if and only if the directed graph given by [[Orientation (graph theory)|orienting]] each edge from one color class to the other is skew-symmetric, so testing skew-symmetry of this directed graph is hard. This complexity does not affect path-finding algorithms for skew-symmetric graphs, because these algorithms assume that the skew-symmetric structure is given as part of the input to the algorithm rather than requiring it to be inferred from the graph alone.

==References==
*{{citation
 | last1 = Aspvall | first1 = Bengt
 | last2 = Plass | first2 = Michael F.
 | authorlink3 = Robert Tarjan | last3 = Tarjan | first3 = Robert E.
 | title = A linear-time algorithm for testing the truth of certain quantified boolean formulas
 | journal = Information Processing Letters
 | volume = 8 | issue = 3 | pages = 121–123 | year = 1979
 | doi = 10.1016/0020-0190(79)90002-4}}.
*{{citation
 | last = Babenko | first = Maxim A.
 | contribution = Acyclic bidirected and skew-symmetric graphs: algorithms and structure
 | title = Computer Science – Theory and Applications
 | publisher = Springer-Verlag | series = Lecture Notes in Computer Science | year = 2006 | volume = 3967
 | pages = 23–34 | doi = 10.1007/11753728_6
 | isbn = 978-3-540-34166-6| arxiv = math/0607547}}.
*{{citation
 | last = Biggs | first = Norman | authorlink = Norman L. Biggs 
 | title = Algebraic Graph Theory 
 | publisher = Cambridge University Press | place = London | year = 1974 }}.
*{{citation
 | authorlink = Matthew Cook
 | last = Cook | first = Matthew
 | contribution = Still life theory
 | year = 2003
 | title = New Constructions in Cellular Automata
 | publisher = Santa Fe Institute Studies in the Sciences of Complexity, Oxford University Press
 | pages = 93–118}}.
*{{citation
 | last1 = Edmonds | first1 = Jack | authorlink1 = Jack Edmonds
 | last2 = Johnson | first2 = Ellis L.
 | contribution = Matching: a well-solved class of linear programs
 | title = Combinatorial Structures and their Applications: Proceedings of the Calgary Symposium, June 1969
 | publisher = Gordon and Breach | location = New York | year = 1970 
}}. Reprinted in ''Combinatorial Optimization — Eureka, You Shrink!'', Springer-Verlag, Lecture Notes in Computer Science 2570, 2003, pp.&amp;nbsp;27–30, {{doi|10.1007/3-540-36478-1_3}}.
*{{citation
 | last1 = Gabow | first1 = Harold N.
 | last2 = Kaplan | first2 = Haim
 | last3 = Tarjan | first3 = Robert E. | authorlink3 = Robert Tarjan
 | contribution = Unique maximum matching algorithms
 | title = Proc. 31st ACM Symp. Theory of Computing (STOC)
 | year = 1999 | pages = 70–78
 | doi = 10.1145/301250.301273
 | isbn = 1-58113-067-8}}.
*{{citation
 | last1 = Goldberg | first1 = Andrew V. | author1-link = Andrew V. Goldberg
 | last2 = Karzanov | first2 = Alexander V.
 | title = Path problems in skew-symmetric graphs
 | journal = Combinatorica
 | volume = 16 | issue = 3 | year = 1996 | pages = 353–382
 | doi = 10.1007/BF01261321}}.
*{{citation
 | last1 = Goldberg | first1 = Andrew V. | author1-link = Andrew V. Goldberg
 | last2 = Karzanov | first2 = Alexander V.
 | title = Maximum skew-symmetric flows and matchings
 | journal = Mathematical programming
 | volume = 100 | issue = 3 | year = 2004 | pages = 537–568
 | doi = 10.1007/s10107-004-0505-z| arxiv = math/0304290}}.
*{{citation
 | last1 = Hui | first1 = Peter
 | last2 = Schaefer | first2 = Marcus
 | last3 = Štefankovič | first3 = Daniel
 | contribution = Train tracks and confluent drawings
 | title = [[International Symposium on Graph Drawing|Proc. 12th Int. Symp. Graph Drawing]]
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | volume = 3383 | year = 2004 | pages = 318–328}}.
*{{citation
 | last = Lalonde | first = François
 | doi = 10.1016/0012-365X(81)90271-5
 | issue = 3
 | journal = Discrete Mathematics
 | mr = 602044
 | pages = 271–280
 | title = Le problème d'étoiles pour graphes est NP-complet
 | volume = 33
 | year = 1981}}.
*{{citation|first=Mikkel|last=Thorup|authorlink=Mikkel Thorup|year=2000|pages=343–350|doi=10.1145/335305.335345|contribution=Near-optimal {{Sic|hide=y|fully|-}}dynamic graph connectivity|title=[[Symposium on Theory of Computing|Proc. 32nd ACM Symposium on Theory of Computing]]|isbn=1-58113-184-4}}.
*{{citation
 | last = Tutte | first = W. T. | authorlink = W. T. Tutte
 | title = Antisymmetrical digraphs
 | journal = Canadian Journal of Mathematics
 | volume = 19 | pages = 1101–1117 | year = 1967
 | doi = 10.4153/CJM-1967-101-8}}.
*{{citation
 | last = Zaslavsky | first = Thomas | authorlink = Thomas Zaslavsky
 | title = Signed graphs
 | journal = Discrete Applied Mathematics 
 | volume = 4 | pages = 47–74  | year = 1982 | doi=10.1016/0166-218X(82)90033-6}}.
*{{citation
 | last = Zaslavsky | first = Thomas | authorlink = Thomas Zaslavsky
 | title = Orientation of signed graphs 
 | journal = European Journal of Combinatorics
 | volume = 12 | pages = 361–375  | year = 1991 | doi=10.1016/s0195-6698(13)80118-7}}.
*{{citation
 | last = Zelinka | first = Bohdan 
 | title = Polar graphs and railway traffic 
 | journal = Aplikace Matematiky 
 | volume = 19 | pages = 169–176  | year = 1974 }}.
*{{citation
 | last = Zelinka | first = Bohdan 
 | title = Isomorphisms of polar and polarized graphs 
 | journal = Czechoslovak Mathematical Journal 
 | volume = 26 | pages = 339–351  | year = 1976a }}.
*{{citation
 | last = Zelinka | first = Bohdan 
 | title = Analoga of Menger's theorem for polar and polarized graphs 
 | journal = Czechoslovak Mathematical Journal 
 | volume = 26 | pages = 352–360  | year = 1976b }}.

[[Category:Graph families]]
[[Category:Directed graphs]]
[[Category:Matching]]</text>
      <sha1>bve6esacuqyzphxfnyg1ly0wp48a7ei</sha1>
    </revision>
  </page>
  <page>
    <title>The Compendious Book on Calculation by Completion and Balancing</title>
    <ns>0</ns>
    <id>1406909</id>
    <revision>
      <id>864935286</id>
      <parentid>863541851</parentid>
      <timestamp>2018-10-20T15:27:42Z</timestamp>
      <contributor>
        <ip>2605:E000:2358:C100:D483:9715:EEFB:840D</ip>
      </contributor>
      <comment>/* Other topics */ changed the word "are" to "and", which fits the sentence better.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12360">{{italic title}}
[[File:Image-Al-Kitāb al-muḫtaṣar fī ḥisāb al-ğabr wa-l-muqābala.jpg|thumb|A page from the book]]
'''''The Compendious Book on Calculation by Completion and Balancing''''' ({{lang-ar|الكتاب المختصر في حساب الجبر والمقابلة}}, ''Al-kitāb al-mukhtaṣar fī ḥisāb al-ğabr wa’l-muqābala'';{{refn|The Arabic title is sometimes condensed to ''Hisab al-jabr w’al-muqabala'' or ''Kitab al-Jabr wa-l-Muqabala'' or given under other [[romanization of Arabic|transliterations]].}} {{lang-la|Liber Algebræ et Almucabola}}) is an Arabic treatise on [[mathematics]] written by Persian polymath [[Muḥammad ibn Mūsā al-Khwārizmī]] around 820&amp;nbsp;CE while he was in the [[Abbasid Caliphate|Abbasid]] capital of [[Baghdad]]. Translated into Latin by [[Robert of Chester]] in 1145, it was used until the sixteenth century as the ''principal mathematical text-book'' of European universities.&lt;ref&gt;{{Cite book|url=https://books.google.co.in/books?id=lQbcCwAAQBAJ&amp;printsec=frontcover&amp;source=gbs_ge_summary_r&amp;cad=0#v=onepage&amp;q&amp;f=false|title=History of the Arabs|last=[[Philip Khuri Hitti]]|first=|publisher=|year=2002|isbn=|location=|pages=379}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.co.in/books?id=9S0XAQAAIAAJ|title=A History of the Islamic World|last=Fred James Hill, Nicholas Awde|first=|publisher=|year=2003|isbn=|location=|pages=55|quote="The Compendious Book on Calculation by Completion and Balancing" (Hisab al-Jabr wa H-Muqabala) on the development of the subject cannot be underestimated. Translated into Latin during the twelfth century, it remained the principal mathematics textbook in European universities until the sixteenth century''}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.ms.uky.edu/~carl/ma330/project2/al-khwa21.html|title=Al-Khwarizmi|last=Shawn Overbay, Jimmy Schorer, and Heather Conger|first=[[University of Kentucky]]|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.sjsu.edu/people/patricia.backer/history/islam.htm|title=Islam Spain and the history of technology|website=www.sjsu.edu|access-date=2018-01-24}}&lt;/ref&gt;It also introduced the term "[[algebra]]" ({{lang|ar|الجبر}}, ''al-jabr'') to European languages. The ''Compendious Book'' provided an exhaustive account of solving for the positive [[root of a function|roots]] of [[polynomial equations]] up to the second degree.&lt;ref&gt;{{cite book|first=Carl B.|last=Boyer|authorlink=Carl Benjamin Boyer|title=A History of Mathematics|edition=Second|publisher=John Wiley &amp; Sons, Inc.|year=1991|chapter=The Arabic Hegemony|isbn=0-471-54397-7|page=228}}
{{quote|"The Arabs in general loved a good clear argument from premise to conclusion, as well as systematic organization – respects in which neither Diophantus nor the Hindus excelled."}}&lt;/ref&gt;

Several authors have also published texts under this name, including [[Al-Dinawari|Abū Ḥanīfa al-Dīnawarī]], [[Abū Kāmil Shujā ibn Aslam]],&lt;ref&gt;''Rasāla fi l-ğabr wa-l-muqābala''&lt;/ref&gt; Abū Muḥammad al-ʿAdlī, Abū Yūsuf al-Miṣṣīṣī, [['Abd al-Hamīd ibn Turk]], Sind ibn ʿAlī, Sahl ibn Bišr,&lt;ref&gt;Possibly.&lt;/ref&gt; and [[Sharaf al-Dīn al-Tūsī|Šarafaddīn al-Ṭūsī]].

==Legacy==
R. Rashed and Angela Armstrong write:
{{quote|Al-Khwarizmi's text can be seen to be distinct not only from the [[Babymathematics|Babylonian tablets]], but also from the [[Diophantus]]' ''[[Arithmetica]]''. It no longer concerns a series of [[problem]]s to be resolved, but an [[Expository writing|exposition]] which starts with primitive terms in which the combinations must give all possible prototypes for equations, which henceforward explicitly constitute the true object of study. On the other hand, the idea of an equation for its own sake appears from the beginning and, one could say, in a generic manner, insofar as it does not simply emerge in the course of solving a problem, but is specifically called on to define an infinite class of problems.&lt;ref&gt;{{Cite book | last1=Rashed | first1=R. | last2=Armstrong | first2=Angela | year=1994 | title=The Development of Arabic Mathematics | publisher=[[Springer Science+Business Media|Springer]] | isbn=0-7923-2565-6 | oclc=29181926 | pages=11–2 | ref=harv | postscript=&lt;!--None--&gt;}}&lt;/ref&gt;}}

J. J. O'Connor and E. F. Robertson wrote in the ''[[MacTutor History of Mathematics archive]]'':
{{quote|Perhaps one of the most significant advances made by Arabic mathematics began at this time with the work of al-Khwarizmi, namely the beginnings of algebra. It is important to understand just how significant this new idea was. It was a revolutionary move away from the Greek concept of mathematics which was essentially geometry. Algebra was a unifying theory which allowed [[rational numbers]], [[irrational number]]s, geometrical magnitudes, etc., to all be treated as "algebraic objects". It gave mathematics a whole new development path so much broader in concept to that which had existed before, and provided a vehicle for future development of the subject. Another important aspect of the introduction of algebraic ideas was that it allowed mathematics to be applied to itself in a way which had not happened before.&lt;ref&gt;{{MacTutor|class=HistTopics|id=Arabic_mathematics|title=Arabic mathematics: forgotten brilliance?|year=1999}}&lt;/ref&gt;}}

==The book==
The book was a compilation and extension of known rules for solving [[quadratic equation]]s and for some other problems, and considered to be the foundation of algebra, establishing it as an independent discipline. The word ''algebra'' is derived from the name of one of the basic operations with equations described in this book, following its Latin translation by [[Robert of Chester]].&lt;ref name=Algebra&gt;{{cite book | last = Robert of Chester  | first =  | authorlink = | coauthors = | title = Algebra of al-Khowarizmi  | url = http://library.albany.edu/preservation/brittle_bks/khuwarizmi_robertofchester/ | publisher = Macmillan | year = 1915| location = | pages = | doi =  | isbn =  }}&lt;/ref&gt;

Since the book does not give any citations to previous authors, it is not clearly known what earlier works were used by al-Khwarizmi, and modern mathematical historians put forth opinions based on the textual analysis of the book and the overall body of knowledge of the contemporary Muslim world. There are indications of connections with [[Indian mathematics]], as he had written a book entitled ''The Book of Bringing Together and Separating According to the Hindu Calculation'' (''Kitāb al-Jamʿ wa-l-tafrīq bi-ḥisāb al-Hind''), discussing the [[Hindu-Arabic numeral system]].

== Quadratic equations ==
[[File:Bodleian MS. Huntington 214 roll332 frame36.jpg|thumbnail|right|Pages from a 14th-century Arabic copy of the book, showing geometric solutions to two quadratic equations]]
The book classifies quadratic equations to one of the six basic types and provides algebraic and geometric methods to solve the basic ones. Historian Carl Boyer notes the following regarding the lack of modern abstract notations in the book:&lt;ref&gt;Carl B. Boyer, A History of Mathematics, Second Edition (Wiley, 1991), page 228&lt;/ref&gt;
{{quote|... the algebra of al-Khwarizmi is thoroughly rhetorical, with none of the syncopation (see [[History of algebra]]) found in the Greek ''[[Arithmetica]]'' or in [[Brahmagupta]]'s work. Even the numbers were written out in words rather than symbols! | Carl B. Boyer | A History of Mathematics}}

Thus the equations are verbally described in terms of "squares" (what would today be "''x''&lt;sup&gt;2&lt;/sup&gt;"), "roots" (what would today be "''x''") and "numbers" ("constants": ordinary spelled out numbers, like 'forty-two'). The six types, with modern notations, are:
# squares equal roots (''ax''&lt;sup&gt;2&lt;/sup&gt; = ''bx'')
# squares equal number (''ax''&lt;sup&gt;2&lt;/sup&gt; = ''c'')
# roots equal number (''bx'' = ''c'')
# squares and roots equal number (''ax''&lt;sup&gt;2&lt;/sup&gt; + ''bx'' = ''c'')
# squares and number equal roots (''ax''&lt;sup&gt;2&lt;/sup&gt; + ''c'' = ''bx'')
# roots and number equal squares (''bx'' + ''c'' = ''ax''&lt;sup&gt;2&lt;/sup&gt;)

Islamic mathematicians, unlike the Hindus, did not deal with negative numbers at all; hence an equation like ''bx'' + ''c'' = 0 does not appear in the classification, because it has no positive solutions if all the coefficients are positive. Similarly equation types 4, 5 and 6, which look equivalent to the modern eye, were distinguished because the coefficients must all be positive.&lt;ref&gt;Katz&lt;/ref&gt;

The ''al-ğabr'' ("forcing", "restoring") operation is moving a deficient quantity from one side of the equation to the other side. In an al-Khwarizmi's example (in modern notation), "''x''&lt;sup&gt;2&lt;/sup&gt; = 40''x''&amp;nbsp;−&amp;nbsp;4''x''&lt;sup&gt;2&lt;/sup&gt;" is transformed by ''al-ğabr'' into "5''x''&lt;sup&gt;2&lt;/sup&gt; = 40''x''". Repeated application of this rule eliminates negative quantities from calculations.

''Al-Muqabala'' ({{lang|ar|المقابله}}, "balancing" or "corresponding") means subtraction of the same positive quantity from both sides:  "''x''&lt;sup&gt;2&lt;/sup&gt; + 5 = 40''x'' + 4''x''&lt;sup&gt;2&lt;/sup&gt;" is turned into "5 = 40''x'' + 3''x''&lt;sup&gt;2&lt;/sup&gt;". Repeated application of this rule makes quantities of each type ("square"/"root"/"number") appear in the equation at most once, which helps to see that there are only 6 basic solvable types of the problem, when restricted to positive coefficients and solutions. &lt;!-- see talk --&gt;

Subsequent parts of the book do not rely on solving quadratic equations.

== Area and volume ==
The second chapter of the book catalogues methods of finding [[area]] and [[volume]]. These include approximations of [[pi]] (π), given three ways, as 3 1/7, √10, and 62832/20000. This latter approximation, equalling 3.1416, earlier appeared in the Indian ''[[Āryabhaṭīya]]'' (499 CE).&lt;ref name=BLvdW&gt;B.L. van der Waerden, ''A History of Algebra: From al-Khwārizmī to Emmy Noether''; Berlin: Springer-Verlag, 1985. {{ISBN|3-540-13610-X}}&lt;/ref&gt;

== Other topics ==
[[Al-Khwārizmī]] explicates the [[Jewish calendar]] and the [[Metonic cycle|19-year cycle]] described by the convergence of lunar months and solar years.&lt;ref name=BLvdW /&gt;

About half of the book deals with [[Islamic inheritance jurisprudence|Islamic rules of inheritance]], which are complex and require skill in first-order algebraic equations.&lt;ref&gt;{{cite encyclopedia|encyclopedia=Companion Encyclopedia of the History and Philosophy of the Mathematical Sciences|volume=1|editor=I. Grattan-Guinness
|publisher=JHU Press|year=2003|title=Mathematics applied to aspects of religious ritual in Islam|author=David A. King|url=https://books.google.com/books?id=2hDvzITtfdAC&amp;pg=PA83|page=83}}&lt;/ref&gt;

== References ==
{{reflist|2}}

== Further reading ==
* Barnabas B. Hughes, ed., ''[[Robert of Chester]]'s Latin Translation of Al-Khwarizmi's Al-Jabr: A New Critical Edition'', (in [[Latin language]]) Wiesbaden: F. Steiner Verlag, 1989. {{ISBN|3-515-04589-9}}
*{{cite book|first=Carl B.|last=Boyer|authorlink=Carl Benjamin Boyer|title=[[A History of Mathematics]]|edition=Second|publisher=John Wiley &amp; Sons, Inc.|year=1991|chapter=The Arabic Hegemony|isbn=0-471-54397-7}}
* R. Rashed, ''The development of Arabic mathematics: between arithmetic and algebra'', London, 1994.

==External links==
*[https://archive.org/details/algebraofmohamme00khuwrich 19th Century English Translation]
*[http://www-history.mcs.st-andrews.ac.uk/Mathematicians/Al-Khwarizmi.html Al-Khwarizmi]
*[http://www.uni-due.de/imperia/md/content/didmath/ag_jahnke/musa.pdf Annotated excerpt from a translation of the Compendious Book]. [[University of Duisburg-Essen]].
*[http://www.wilbourhall.org/index.html#algebra The Compendious Book on Calculation by Completion and Balancing] In the Arabic original with an English translation (PDF)
*{{cite web|url=http://www.muslimheritage.com/topics/default.cfm?ArticleID=637 |title=The Science of Restoring and Balancing – The Science of Algebra |first=Mahbub |last=Ghani |date=5 January 2007 |work=Muslim Heritage}}
{{Use dmy dates|date=March 2011}}

{{Islamic mathematics}}

{{Authority control}}

{{DEFAULTSORT:Compendious Book On Calculation By Completion And Balancing}}
[[Category:History of algebra]]
[[Category:Mathematical works of medieval Islam]]
[[Category:9th-century Arabic books]]
[[Category:Abbasid literature]]</text>
      <sha1>6esl852bgqymamrhyhdzz0wunwukff7</sha1>
    </revision>
  </page>
  <page>
    <title>Thomson's lamp</title>
    <ns>0</ns>
    <id>1240997</id>
    <revision>
      <id>855792259</id>
      <parentid>848413717</parentid>
      <timestamp>2018-08-20T21:27:35Z</timestamp>
      <contributor>
        <username>Eli355</username>
        <id>33551130</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6040">{{Primary|date=April 2018}}
'''Thomson's lamp''' is a philosophical [[puzzle]] based on infinites.  It was devised in 1954 by British philosopher [[James F. Thomson (philosopher)|James F. Thomson]], who used it to analyze the possibility of a [[supertask]], which is the completion of an infinite number of tasks.

{| border="0"  cellspacing="5" cellpadding="5" align="right" style="border: 1px solid darkgray; margin: 2em"
|-
! Time
! State
|-
| align="center"|0.000 || align="center"|On
|-
| align="center"|1.000 || align="center"|Off
|-
| align="center"|1.500 || align="center"|On
|-
| align="center"|1.750 || align="center"|Off
|-
| align="center"|1.875 || align="center"|On
|-
| align="center"| ... || align="center"|...
|-
| align="center"|2.000 || align="center"|?
|-
|}

Consider a lamp with a [[toggle switch]].  Flicking the switch once turns the lamp on.  Another flick will turn the lamp off.  Now suppose that there is a being able to perform the following task:  starting a timer, he turns the lamp on.  At the end of one minute, he turns it off.  At the end of another half minute, he turns it on again.  At the end of another quarter of a minute, he turns it off.  At the next eighth of a minute, he turns it on again, and he continues thus, flicking the switch each time after waiting exactly one-half the time he waited before flicking it previously.{{sfn|Thomson|1954|p=5}}  The sum of this [[Series (mathematics)|infinite series]] of time intervals is exactly two minutes.{{sfn|Thomson|1954|p=9}}

The following question is then considered: Is the lamp on or off at two minutes?{{sfn|Thomson|1954|p=5}} Thomson reasoned that this supertask creates a contradiction:

:It seems impossible to answer this question. It cannot be on, because I did not ever turn it on without at once turning it off. It cannot be off, because I did in the first place turn it on, and thereafter I never turned it off without at once turning it on. But the lamp must be either on or off. This is a contradiction.{{sfn|Thomson|1954|p=5}}

==Mathematical series analogy==

The question is related to the behavior of [[Grandi's series]], ''i.e.'' the divergent infinite series

:''S'' = 1 − 1 + 1 − 1 + 1 − 1 + · · ·

For even values of ''n'', the above finite series sums to 1; for odd values, it sums to 0. In other words, as ''n'' takes the values of each of the non-negative [[integer]]s 0, 1, 2, 3, ... in turn, the series generates the [[sequence]] {1, 0, 1, 0, ...}, representing the changing state of the lamp.{{sfn|Thomson|1954|p=6}} The sequence does not [[Limit of a sequence|converge]] as ''n'' tends to infinity, so neither does the infinite series.

Another way of illustrating this problem is to rearrange the series:

:''S'' = 1 − (1 − 1 + 1 − 1 + 1 − 1 + · · ·)

The unending series in the brackets is exactly the same as the original series ''S''. This means ''S'' = 1 − ''S'' which implies ''S'' = &lt;sup&gt;1&lt;/sup&gt;⁄&lt;sub&gt;2&lt;/sub&gt;. In fact, this manipulation can be rigorously justified: there are [[Cesàro summation|generalized definitions for the sums of series]] that do assign Grandi's series the value &lt;sup&gt;1&lt;/sup&gt;⁄&lt;sub&gt;2&lt;/sub&gt;.

One of Thomson's objectives in his original 1954 paper is to differentiate supertasks from their series analogies. He writes of the lamp and Grandi's series,
:"Then the question whether the lamp is on or off… is the question: What is the sum of the infinite divergent sequence
::+1, −1, +1, …?
:"Now mathematicians do say that this sequence has a sum; they say that its sum is &lt;sup&gt;1&lt;/sup&gt;⁄&lt;sub&gt;2&lt;/sub&gt;. And this answer does not help us, since we attach no sense here to saying that the lamp is half-on. I take this to mean that there is no established method for deciding ''what'' is done when a super-task is done. … We cannot be expected to ''pick up'' this idea, just because we have the idea of a task or tasks having been performed and because we are acquainted with transfinite numbers."&lt;ref&gt;Thomson p.6. For the mathematics and its history he cites Hardy and Waismann's books, for which see ''[[History of Grandi's series]]''.&lt;/ref&gt;
Later, he claims that even the divergence of a series does not provide information about its supertask: "The impossibility of a super-task does not depend at all on whether some vaguely-felt-to-be-associated arithmetical sequence is convergent or divergent."{{sfn|Thomson|1954|p=7}}

== See also ==
* [[List of paradoxes]]
* [[Ross–Littlewood paradox]]
* [[Supertask]]
* [[Zeno's paradoxes]]
* [[Zeno machine]]

==Notes==
{{reflist}}

==References==
*{{cite book|title=Zeno, Aristotle, the Racetrack and the Achilles: A Historical and Philosophical Investigation|first=Benjamin William|last=Allen|publisher=Rutgers, The State University of New Jersey |location=New Brunswick, NJ|year=2008|isbn=9781109058437|pages=209–210|url=https://books.google.com/books?id=LQEnRFmeOu4C&amp;pg=PA209}}
*{{cite journal|title=Tasks, Super-Tasks, and the Modern Eleatics|first=Paul|last=Benacerraf|journal=The Journal of Philosophy|volume=59|issue=24|year=1962|pages=765–784|jstor=2023500}}
*{{cite book|title=Everywhere and Everywhen : Adventures in Physics and Philosophy: Adventures in Physics and Philosophy|first=Nick|last=Huggett|publisher=Oxford University Press|year=2010|isbn=9780199702114|pages=22–23|url=https://books.google.com/books?id=PV98odlvq4kC&amp;pg=PA22}}
*{{cite journal |ref=harv|last=Thomson |first=James F. |authorlink=James F. Thomson  (philosopher) |title=Tasks and Super-Tasks |journal=Analysis |volume=15 |issue=1 |date=October 1954 |pages=1–13 |doi=10.2307/3326643 |publisher=Analysis, Vol. 15, No. 1 |jstor=3326643}}
*Earman, John and Norton, John (1996) [http://pitt.edu/~jearman/EarmanNorton1996a.pdf Infinite Pains: The Trouble with Supertasks. In Benacerraf and his Critics], Adam Morton and Stephen P. Stich (Eds.), p.&amp;nbsp;231-261.

{{Grandi's series}}
{{DEFAULTSORT:ThomSon'S Lamp}}
[[Category:Supertasks]]
[[Category:Paradoxes of infinity]]
[[Category:Fictional lamps]]
[[Category:Grandi's series]]</text>
      <sha1>p6jnkk4brxldnpvlvapea047c4u0y0d</sha1>
    </revision>
  </page>
  <page>
    <title>Traffic flow</title>
    <ns>0</ns>
    <id>2831127</id>
    <revision>
      <id>859981604</id>
      <parentid>858424278</parentid>
      <timestamp>2018-09-17T15:34:40Z</timestamp>
      <contributor>
        <ip>132.248.177.6</ip>
      </contributor>
      <comment>/* Speed */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="81340">{{dablink|For traffic flow in a computer network see [[traffic flow (computer networking)]]}}
{{dablink|For traffic equations in a queueing network see [[traffic equations]]}}

In [[mathematics]] and [[civil engineering]], '''traffic flow''' is the study of interactions between travellers (including pedestrians, cyclists, drivers, and their vehicles) and infrastructure (including highways, signage, and traffic control devices), with the aim of understanding and developing an optimal transport network with efficient movement of [[traffic]] and minimal [[traffic congestion]] problems.

==History==
Attempts to produce a mathematical theory of traffic flow date back to the 1920s, when [[Frank Knight]] first produced an analysis of traffic equilibrium, which was refined into [[John Glen Wardrop|Wardrop's first and second principles]] of equilibrium in 1952.

Nonetheless, even with the advent of significant computer processing power, to date there has been no satisfactory general theory that can be consistently applied to real flow conditions. Current [[traffic model]]s use a mixture of [[empirical]] and [[Deductive reasoning|theoretical]] techniques. These models are then developed into [[Transportation forecasting|traffic forecasts]], to take account of proposed local or major changes, such as increased vehicle use, changes in [[land use]] or changes in [[mode of transport]] (with people moving from bus to train or car, for example), and to identify areas of [[Traffic congestion|congestion]] where the network needs to be adjusted.

==Overview==
Traffic behaves in a complex and nonlinear way, depending on the interactions of a large number of [[vehicle]]s. Due to the individual reactions of human drivers, vehicles do not interact simply following the laws of mechanics, but rather display cluster [[structure formation|formation]] and [[shock wave]] propagation,{{Citation needed|date=December 2008}} both forward and backward, depending on vehicle [[density]]. Some mathematical models of traffic flow use a [[vertical queue]] assumption, in which the vehicles along a congested link do not spill back along the length of the link.

In a free-flowing network, ''traffic flow theory'' refers to the traffic stream variables of speed, flow, and concentration. These relationships are mainly concerned with uninterrupted traffic flow, primarily found on freeways or expressways.&lt;ref&gt;{{cite journal|url=http://www.fhwa.dot.gov/publications/research/operations/tft/index.cfm|title=Traffic-Flow Theory|author=Henry Lieu|publisher=US Dept of Transportation|journal=Public Roads|issue=Vol. 62· No. 4|date=January–February 1999}}&lt;/ref&gt; 
Flow conditions are considered "free" when less than 12 vehicles per mile are on a road. "Stable" is sometimes described as 12–30 vehicles per mile per lane. As the density reaches the maximum [[mass flow rate]] (or [[flux]]) and exceeds the optimum density (above 30 vehicles per mile), traffic flow becomes unstable, and even a minor incident can result in persistent [[Traffic wave|stop-and-go]] driving conditions. A "breakdown" condition occurs when traffic becomes unstable and exceeds 67 vehicles per mile.&lt;ref&gt;{{cite web|last1=Rijn|first1=John|title=Road Capacities|url=http://www.indevelopment.nl/PDFfiles/CapacityOfRroads.pdf|website=Indevelopment|accessdate=22 July 2014}}&lt;/ref&gt; "Jam density" refers to extreme traffic density when traffic flow stops completely, usually in the range of 185–250 vehicles per mile per lane.&lt;ref&gt;{{cite journal|url=http://www.tandfonline.com/doi/full/10.1080/21680566.2016.1256239|title=Automatic fitting procedure for the fundamental diagram|author=V.L. Knoop and W. Daamen|publisher=Taylor and Francis|journal=Transportmetrica B: Transport Dynamics|issue=Vol. 5 No 2|date=2017|doi=10.1080/21680566.2016.1256239|volume=5|pages=133–148}}&lt;/ref&gt;

However, calculations about congested networks are more complex and rely more on empirical studies and extrapolations from actual road counts. Because these are often urban or suburban in nature, other factors (such as road-user safety and environmental considerations) also influence the optimum conditions.

There are [[Traffic congestion: Reconstruction with Kerner’s three-phase theory|common spatiotemporal empirical features of traffic congestion]] that are qualitatively the same for different highways in different countries, measured during years of traffic observations. Some of these common features of traffic congestion define synchronized flow and wide moving jam traffic phases of congested traffic in [[Boris Kerner|Kerner]]’s [[three-phase traffic theory]] of traffic flow.

==Traffic stream properties==
{{Expert needed|Mathematics|documentation|talk="Traffic Stream Properties" Section Needs Improvement|date=June 2011}}
Traffic flow is generally constrained along a one-dimensional pathway (e.g. a travel lane). A time-space diagram shows graphically the flow of vehicles along a pathway over time. Time is displayed along the horizontal axis, and distance is shown along the vertical axis. Traffic flow in a time-space diagram is represented by the individual trajectory lines of individual vehicles. Vehicles following each other along a given travel lane will have parallel trajectories, and trajectories will cross when one vehicle passes another. Time-space diagrams are useful tools for displaying and analyzing the traffic flow characteristics of a given roadway segment over time (e.g. analyzing traffic flow congestion).

There are three main variables to visualize a traffic stream: speed (v), density (indicated k; the number of vehicles per unit of space), and flow{{clarify|date=December 2016}} (indicated q; the number of vehicles per unit of time).
[[Image:Time Space Diag Figure 1.JPG|thumb|right|350px|Figure 1. Time Space diagram]]

===Speed===
Speed is the distance covered per unit time. One cannot track the speed of every vehicle; so, in practice, average speed is measured by sampling vehicles in a given area over a period of time. Two definitions of average speed are identified: "time mean speed" and "space mean speed".

* "Time mean speed" is measured at a reference point on the roadway over a period of time. In practice, it is measured by the use of loop detectors. Loop detectors, when spread over a reference area, can identify each vehicle and can track its speed. However, average speed measurements obtained from this method are not accurate because instantaneous speeds averaged over several vehicles do not account for the difference in travel time for the vehicles that are traveling at different speeds over the same distance.{{clarify|date=December 2016}}

{{in5}}{{in5}}&lt;math&gt; v_t = (1/m) \sum_{i=1}^m v_i&lt;/math&gt;

where ''m'' represents the number of vehicles passing the fixed point and ''v&lt;sub&gt;i&lt;/sub&gt;'' is the speed of the ''i''th vehicle.

* "Space mean speed" is measured over the whole roadway segment. Consecutive pictures or video of a roadway segment track the speed of individual vehicles, and then the average speed is calculated. It is considered more accurate than the time mean speed. The data for space calculating space mean speed may be taken from satellite pictures, a camera, or both.

{{in5}}{{in5}}&lt;math&gt; v_s = \left((1/n)\sum_{i=1}^n (1/v_i)\right)^{-1}&lt;/math&gt;

where ''n'' represents the number of vehicles passing the roadway segment.

The "space mean speed" is thus the [[harmonic mean]] of the speeds.

The time mean speed is never less than space mean speed:

{{in5}}{{in5}}&lt;math&gt; v_t = v_s + \frac{\sigma_s^2}{v_s}&lt;/math&gt;

where &lt;math&gt;\sigma_s^2&lt;/math&gt; is the variance of the space mean speed&lt;ref&gt;Lint, J. W. C. V., "Reliable travel time prediction for freeways", Phd thesis, Netherlands TRAIL Research School, 2004&lt;/ref&gt;
[[Image:mean space and time speed.png|thumb|right|350px|Figure 2. Space Mean- and Time Mean speeds]]

In a time-space diagram, the instantaneous velocity, v = dx/dt, of a vehicle is equal to the slope along the vehicle’s trajectory. The average velocity of a vehicle is equal to the slope of the line connecting the trajectory endpoints where a vehicle enters and leaves the roadway segment. The vertical separation (distance) between parallel trajectories is the vehicle spacing (s) between a leading and following vehicle. Similarly, the horizontal separation (time) represents the vehicle headway (h). A time-space diagram is useful for relating headway and spacing to traffic flow and density, respectively.

===Density===
Density (k) is defined as the number of vehicles per unit length of the roadway. In traffic flow, the two most important densities are the critical density (''k''&lt;sub&gt;''c''&lt;/sub&gt;) and jam density (''k''&lt;sub&gt;''j''&lt;/sub&gt;). The maximum density achievable under free flow is ''k''&lt;sub&gt;''c''&lt;/sub&gt;, while ''k''&lt;sub&gt;''j''&lt;/sub&gt; is the maximum density achieved under congestion. In general, jam density is seven times the critical density. Inverse of density is spacing (s), which is the center-to-center distance between two vehicles.

{{in5}}&lt;math&gt;k = \frac 1 s &lt;/math&gt;

[[Image:Flow Density Relationship.png|thumb|right|350px|Figure 3. Flow Density relationship]]
[[Image:Relationship between q k and v.png|thumb|right|350px|Figure 4. Relationship between flow (''q''), density (''k''), and speed (''v'')]]

The density (''k'') within a length of roadway (''L'') at a given time (''t''&lt;sub&gt;1&lt;/sub&gt;) is equal to the inverse of the average spacing of the ''n'' vehicles.

{{in5}}&lt;math&gt;K(L,t_1) = \frac{n}{L} = \frac{1} {\bar{s}(t_1)}&lt;/math&gt;

In a time-space diagram, the density may be evaluated in the region A.

{{in5}}&lt;math&gt;k(A) = \frac{n}{L} = \frac{n \, dt}{L \, dt} = \frac{tt}{\left | A \right \vert}&lt;/math&gt;

where ''tt'' is the total travel time in ''A''.
[[File:Time Space Diag Figure 2.JPG|thumb|right|350px|Figure 5.]]

===Flow===
Flow (''q'') is the number of vehicles passing a reference point per unit of time, vehicles per hour. The inverse of flow is headway (''h''), which is the time that elapses between the ''i''th vehicle passing a reference point in space and the (''i''&amp;nbsp;+&amp;nbsp;1)th vehicle. In congestion, ''h'' remains constant. As a traffic jam forms, ''h'' approaches infinity.

{{in5}}&lt;math&gt;q=kv \, &lt;/math&gt;

{{in5}}&lt;math&gt;q=1/h \, &lt;/math&gt;

The flow (''q'') passing a fixed point (''x''&lt;sub&gt;1&lt;/sub&gt;) during an interval (''T'') is equal to the inverse of the average headway of the ''m'' vehicles.

{{in5}}&lt;math&gt;q(T,x_1) = \frac{m}{T} = \frac{1} {\bar{h}(x_1)}&lt;/math&gt;

In a time-space diagram, the flow may be evaluated in the region ''B''.

{{in5}}&lt;math&gt;q(B) = \frac{m}{T} = \frac{m\,dx}{T\,dx} = \frac{td}{\left | B \right \vert}&lt;/math&gt;

where ''td'' is the total distance traveled in ''B''.
[[File:Time Space Diag Figure 3.JPG|thumb|right|350px|Figure 6.]]

===Generalized density and flow in time-space diagram===
A more general definition of the flow and density in a time-space diagram is illustrated by region C:

{{in5}}&lt;math&gt;q(C) = \frac{td}{\left | C \right \vert}&lt;/math&gt;

{{in5}}&lt;math&gt;k(C) = \frac{tt}{\left | C \right \vert}&lt;/math&gt;

where:

{{in5}}&lt;math&gt;td = \sum_{i=1}^m \, dx_i&lt;/math&gt;

{{in5}}&lt;math&gt;tt = \sum_{i=1}^n \, dt_i&lt;/math&gt;

===Congestion shockwave===
In addition to providing information on the speed, flow, and density of traffic streams, time-space diagrams may illustrate the propagation of congestion upstream from a traffic bottleneck (shockwave). Congestion shockwaves will vary in propagation length, depending upon the upstream traffic flow and density. However, shockwaves will generally travel upstream at a rate of approximately 20&amp;nbsp;km/h.
[[File:Time Space Diag Figure 4.JPG|thumb|right|350px|Figure 7.]]

===Stationary traffic===
Traffic on a stretch of road is said to be stationary if an observer does not detect movement in an arbitrary area of the time-space diagram. Traffic is stationary if all the vehicle trajectories are parallel and equidistant. It is also stationary if it is a superposition of families of trajectories with these properties (e.g. fast and slow drivers). By using a very small hole in the template one could sometimes view an empty region of the diagram and other times not, so that even in these cases, one could say that traffic was not stationary. Clearly, for such fine level of observation, stationary traffic does not exist. A microscopic level of observation must be excluded from the definition if traffic appears to be similar through larger windows. In fact, we relax the definition even further by only requiring that the quantities '''t(A)''' and '''d(A)''' be approximately the same, regardless of where the "large" window '''(A)''' is placed.

==Methods of analysis==
Analysts approach the problem in three main ways, corresponding to the three main scales of observation in physics:

* Microscopic scale: At the most basic level, every vehicle is considered as an individual. An equation can be written for each, usually an [[ordinary differential equation]] (ODE). Cellular automation models can also be used, where the road is divided into cells, each of which contains a moving car, or is empty. The [[Nagel–Schreckenberg model]] is a simple example of such a model. As the cars interact it can model collective phenomena such as [[traffic jam]]s.
* Macroscopic scale: Similar to models of [[fluid dynamics]], it is considered useful to employ a system of [[partial differential equations]], which balance laws for some gross quantities of interest; e.g., the density of vehicles or their mean velocity.
* Mesoscopic (kinetic) scale: A third, intermediate possibility, is to define a function &lt;math&gt;f(t,x,V)&lt;/math&gt; which expresses the probability of having a vehicle at time &lt;math&gt;t&lt;/math&gt; in position &lt;math&gt;x&lt;/math&gt; which runs with velocity &lt;math&gt;V&lt;/math&gt;. This function, following methods of [[statistical mechanics]], can be computed using an integro-differential equation such as the [[Boltzmann equation]].

The engineering approach to analysis of highway traffic flow problems is primarily based on [[empirical analysis]] (i.e., observation and mathematical curve fitting). One major reference used by American planners is the ''Highway Capacity Manual'',&lt;ref&gt;[http://www.trb.org/news/blurb_detail.asp?id=1166 Highway Capacity Manual 2000]&lt;/ref&gt; published by the [[Transportation Research Board]], which is part of the [[United States National Academy of Sciences]]. This recommends modelling traffic flows using the whole travel time across a link using a delay/flow function, including the effects of queuing. This technique is used in many US traffic models and in the SATURN model in Europe.&lt;ref&gt;[http://www.saturnsoftware.co.uk SATURN ITS Transport Software Site]&lt;/ref&gt;

In many parts of Europe, a hybrid empirical approach to traffic design is used, combining macro-, micro-, and mesoscopic features. Rather than simulating a [[steady state]] of flow for a journey, transient "demand peaks" of congestion are simulated. These are modeled by using small "time slices" across the network throughout the working day or weekend. Typically, the origins and destinations for trips are first estimated and a traffic model is generated before being calibrated by comparing the mathematical model with observed counts of actual traffic flows, classified by type of vehicle. "Matrix estimation" is then applied to the model to achieve a better match to observed link counts before any changes, and the revised model is used to generate a more realistic traffic forecast for any proposed scheme. The model would be run several times (including a current baseline, an "average day" forecast based on a range of economic parameters and supported by sensitivity analysis) in order to understand the implications of temporary blockages or incidents around the network. From the models, it is possible to total the time taken for all drivers of different types of vehicle on the network and thus deduce average fuel consumption and emissions.

Much of UK, Scandinavian, and Dutch authority practice is to use the modelling program CONTRAM for large schemes, which has been developed over several decades under the auspices of the UK's [[Transport Research Laboratory]], and more recently with the support of the [[Swedish Road Administration]].&lt;ref&gt;[http://www.contram.com/about/introduction.shtml Introduction to Contram]&lt;/ref&gt; By modelling forecasts of the road network for several decades into the future, the economic benefits of changes to the road network can be calculated, using estimates for value of time and other parameters. The output of these models can then be fed into a cost-benefit analysis program.&lt;ref&gt;[http://www.webtag.org.uk/overview/modelling.htm UK [[Department for Transport]]'s WebTag guidance on the conduct of transport studies]&lt;/ref&gt;

==Cumulative vehicle count curves (''N''-curves)==
A cumulative vehicle count curve, the ''N''-curve, shows the cumulative number of vehicles that pass a certain location ''x'' by time ''t'', measured from the passage of some reference vehicle.&lt;ref&gt;{{cite journal | last1 = Cassidy | first1 = M.J. | last2 = Bertini | first2 = R.L. | year = 1999 | title = Some Traffic Features at Freeway Bottlenecks | url = | journal = Transportation Research Part B: Methodological | volume = 33 | issue = 1| pages = 25–42 }}&lt;/ref&gt; This curve can be plotted if the arrival times are known for individual vehicles approaching a location ''x'', and the departure times are also known as they leave location ''x''.  Obtaining these arrival and departure times could involve data collection: for example, one could set two point sensors at locations ''X''&lt;sub&gt;1&lt;/sub&gt; and ''X''&lt;sub&gt;2&lt;/sub&gt;, and count the number of vehicles that pass this segment while also recording the time each vehicle arrives at ''X''&lt;sub&gt;1&lt;/sub&gt; and departs from ''X''&lt;sub&gt;2&lt;/sub&gt;. The resulting plot is a pair of cumulative curves where the vertical axis (''N'') represents the cumulative number of vehicles that pass the two points: ''X''&lt;sub&gt;1&lt;/sub&gt; and ''X''&lt;sub&gt;2&lt;/sub&gt;, and the horizontal axis (''t'') represents the elapsed time from ''X''&lt;sub&gt;1&lt;/sub&gt; and ''X''&lt;sub&gt;2&lt;/sub&gt;.
[[File:Simple cumulative curve two.png|thumb|350px|Figure 8. Simple cumulative curves]]
[[File:Arrival, Virtual Arrival, and Departure Curves.png|thumb|350px|Figure 9. Arrival, virtual arrival, and departure curves]]

If vehicles experience no delay as they travel from ''X''&lt;sub&gt;1&lt;/sub&gt; to ''X''&lt;sub&gt;2&lt;/sub&gt;, then the arrivals of vehicles at location ''X''&lt;sub&gt;1&lt;/sub&gt; is represented by curve ''N''&lt;sub&gt;1&lt;/sub&gt; and the arrivals of the vehicles at location ''X''&lt;sub&gt;2&lt;/sub&gt; is represented by ''N''&lt;sub&gt;2&lt;/sub&gt; in figure 8. More commonly, curve ''N''&lt;sub&gt;1&lt;/sub&gt; is known as the ''arrival curve'' of vehicles at location ''X''&lt;sub&gt;1&lt;/sub&gt; and curve ''N''&lt;sub&gt;2&lt;/sub&gt; is known as the ''arrival curve'' of vehicles at location ''X''&lt;sub&gt;2&lt;/sub&gt;. Using a one-lane signalized approach to an intersection as an example, where ''X''&lt;sub&gt;1&lt;/sub&gt; is the location of the stop bar at the approach and ''X''&lt;sub&gt;2&lt;/sub&gt; is an arbitrary line on the receiving lane just across of the intersection, when the traffic signal is green, vehicles can travel through both points with no delay and the time it takes to travel that distance is equal to the free-flow travel time. Graphically, this is shown as the two separate curves in figure 8.

However, when the traffic signal is red, vehicles arrive at the stop bar (''X''&lt;sub&gt;1&lt;/sub&gt;) and are delayed by the red light before crossing ''X''&lt;sub&gt;2&lt;/sub&gt; some time after the signal turns green. As a result, a queue builds at the stop bar as more vehicles are arriving at the intersection while the traffic signal is still red. Therefore, for as long as vehicles arriving at the intersection are still hindered by the queue, the curve ''N''&lt;sub&gt;2&lt;/sub&gt; no longer represents the vehicles’ arrival at location ''X''&lt;sub&gt;2&lt;/sub&gt;; it now represents the vehicles’ ''virtual arrival'' at location ''X''&lt;sub&gt;2&lt;/sub&gt;, or in other words, it represents the vehicles' arrival at ''X''&lt;sub&gt;2&lt;/sub&gt; if they did not experience any delay. The vehicles' arrival at location ''X''&lt;sub&gt;2&lt;/sub&gt;, taking into account the delay from the traffic signal, is now represented by the curve ''N′''&lt;sub&gt;2&lt;/sub&gt; in figure 9.

However, the concept of the ''virtual arrival curve'' is flawed. This curve does not correctly show the queue length resulting from the interruption in traffic (i.e. red signal). It assumes that all vehicles are still reaching the stop bar before being delayed by the red light. In other words, the ''virtual arrival curve'' portrays the stacking of vehicles vertically at the stop bar. When the traffic signal turns green, these vehicles are served in a first-in-first-out (FIFO) order. For a multi-lane approach, however, the service order is not necessarily FIFO. Nonetheless, the interpretation is still useful because of the concern with average total delay instead of total delays for individual vehicles.&lt;ref name="Pitstick"&gt;Pitstick, Mark E.  "Measuring Delay and Simulating Performance at Isolated Signalized Intersections Using Cumulative Curves." ''Transportation Research Record 1287'' (1990)&lt;/ref&gt;

===Step function vs. smooth function===
[[File:Step function.png|thumb|350px|Figure 10. Step function]]
The traffic light example depicts ''N''-curves as smooth functions. Theoretically, however, plotting ''N''-curves from collected data should result in a step-function (figure 10). Each step represents the arrival or departure of one vehicle at that point in time.&lt;ref name="Pitstick" /&gt; When the ''N''-curve is drawn on larger scale reflecting a period of time that covers several cycles, then the steps for individual vehicles can be ignored, and the curve will then look like a smooth function (figure 8).

===''N''-curve: traffic flow characteristics===
The ''N''-curve can be used in a number of different traffic analyses, including freeway bottlenecks and dynamic traffic assignment. This is due to the fact that a number of traffic flow characteristics can be derived from the plot of cumulative vehicle count curves. Illustrated in figure 11 are the different traffic flow characteristics that can be derived from the ''N''-curves.  
[[File:Showing traffic char.png|thumb|350px|Figure 11. Traffic flow characteristics from two ''N''-curves]]

These are the different traffic flow characteristics from figure 11:

{| class="wikitable"
|-
! Symbol !! Definition
|-
| ''N''&lt;sub&gt;1&lt;/sub&gt; || the cumulative number of vehicles arriving at location ''X''&lt;sub&gt;1&lt;/sub&gt;
|-
| ''N''&lt;sub&gt;2&lt;/sub&gt; || the virtual cumulative number of vehicles arriving at location ''X''&lt;sub&gt;2&lt;/sub&gt;, or the cumulative number of vehicles that would have liked to cross ''X''&lt;sub&gt;2&lt;/sub&gt; by time ''t''
|-
| ''N′''&lt;sub&gt;2&lt;/sub&gt; || the actual cumulative number of vehicles arriving at location ''X''&lt;sub&gt;2&lt;/sub&gt;
|-
| ''TT''&lt;sub&gt;FF&lt;/sub&gt; || the time it takes to travel from location ''X''&lt;sub&gt;1&lt;/sub&gt; to location ''X''&lt;sub&gt;2&lt;/sub&gt; at free-flow conditions
|-
| ''w''(''i'') || the delay experienced by vehicle ''i'' as it travels from ''X''&lt;sub&gt;1&lt;/sub&gt; to ''X''&lt;sub&gt;2&lt;/sub&gt;
|-
| ''TT''(''i'') || the total time it takes to travel from ''X''&lt;sub&gt;1&lt;/sub&gt; to ''X''&lt;sub&gt;2&lt;/sub&gt; including delays (''TT''&lt;sub&gt;FF&lt;/sub&gt; + ''w''(''i''))
|-
| ''Q''(''t'') || the queue at any time ''t'', or the number of vehicles being delayed at time ''t''
|-
| ''n'' || total number of vehicles in the system
|-
| ''m'' || total number of delayed vehicles
|-
| ''TD'' || total delay experienced by ''m'' vehicles (area between ''N''&lt;sub&gt;2&lt;/sub&gt; and ''N′''&lt;sub&gt;2&lt;/sub&gt;)
|-
| ''t''&lt;sub&gt;1&lt;/sub&gt; || time at which congestion begins
|-
| ''t''&lt;sub&gt;2&lt;/sub&gt; || time at which congestion ends
|}

From these variables, the average delay experienced by each vehicle and the average queue length at any time ''t'' can be calculated, using the following formulas:

{{in5}}&lt;math&gt;\text{average delay (}w_\text{avg}\text{)} = \frac{\text{total delay experienced by }m\text{ vehicles}} {\text{total number of delayed vehicles}} = \frac{TD} {m}&lt;/math&gt;

{{in5}}&lt;math&gt;\text{average queue (}Q_\text{avg}\text{)} = \frac{\text{total delay experienced by }m\text{ vehicles}} {\text{duration of congestion}} = \frac{TD} {(t_2-t_1)}&lt;/math&gt;

===Hamilton Jacobi PDE===
In traffic flow area, an alternative way to solve the kinematic wave model is to treat it like a [[Hamilton–Jacobi equation]], which is particularly useful in identifying conserved quantities for mechanical systems.

Suppose we are interested in finding the cumulative curve as a function of time and space, ''N(t,x)''. Based the definition of cumulative curve,&lt;math&gt; \frac{\partial N(t,x)}{\partial t} = \rho(x,t) &lt;/math&gt; refers to the flow and &lt;math&gt; \frac{\partial N(t,x)}{\partial x} = -k(x,t) &lt;/math&gt; refers to the density. Note that the sign convention should be consistent. Then the fundamental flow-density (&lt;math&gt; q-k &lt;/math&gt;) equation: &lt;math&gt; q = F(k) &lt;/math&gt; can be expressed in cumulative count form as: &lt;br /&gt;&lt;math&gt;\frac{\partial N(t,x)}{\partial t} - F(-\frac{\partial N(t,x)}{\partial x})=0&lt;/math&gt; &lt;br /&gt;&lt;math&gt;s.t. N(B)=G(B)&lt;/math&gt;, where &lt;math&gt;B&lt;/math&gt; is a known boundary.

Now, for a generic random point &lt;math&gt;P(x,t)&lt;/math&gt; in the time-space diagram, the solution to the above partial derivative equation is equivalent to solve the following optimization problem, which minimizes the vehicles pass-by:&lt;math&gt;N(P)=\min{{G(x_b)+(t-t_b)R(\frac{x-x_b}{t-t_b})}}&lt;/math&gt;, where &lt;math&gt;b&lt;/math&gt; is a random point on the boundary &lt;math&gt;B&lt;/math&gt;.

The function &lt;math&gt;R&lt;/math&gt; is defined as the maximum passing rate along the observers. In the case of triangular fundamental diagram, we have &lt;math&gt;R(v)=Q-K_c*v&lt;/math&gt;. The observer speed &lt;math&gt;v\isin[-w,u]&lt;/math&gt;.Here, notation &lt;math&gt;Q&lt;/math&gt; corresponds to the capacity, &lt;math&gt;k_c&lt;/math&gt; corresponds to the critical density, &lt;math&gt;u&lt;/math&gt; and &lt;math&gt;w&lt;/math&gt; are free flow speed and wave speed respectively.

With that being said, the minimization function above simplifies into: &lt;math&gt;N(P)=\min{G(x_b)+(t-t_b)Q-(x-x_b)K_c}&lt;/math&gt;, where &lt;math&gt;b&lt;/math&gt; is a random point on the boundary &lt;math&gt;B&lt;/math&gt;. Here, we limit the solution discussion over initial value problems (IVP) and boundary value problems (BVP).

====Initial value problem====
Initial value problem occurs when boundary condition is given at a fixed time, e.g. at &lt;math&gt;t=0&lt;/math&gt; and boundary &lt;math&gt;B:=N(0,x)&lt;/math&gt;. As the observer speed is bounded by &lt;math&gt;v\isin[-w,u]&lt;/math&gt;, the potential solution is delimited by two lines &lt;math&gt;x=x_U+ut&lt;/math&gt; and &lt;math&gt;x=x_D-wt&lt;/math&gt;.

Thus, the IVP is defined as follow:
&lt;br /&gt;&lt;math&gt;N(P)=\min{f(x_b)\equiv G(x_b)+(t-t_b)Q-(x-x_b)K_c}&lt;/math&gt;
&lt;br /&gt;&lt;math&gt;s.t. N(0,x)=G(x)&lt;/math&gt;
&lt;br /&gt;&lt;math&gt;x_U&lt;x_b&lt;x_D&lt;/math&gt;

The local minimum point occurs when the first order derivative is 0 and the second order derivative is greater than 0. Or, the minimum happens at boundaries. So, the set of potential solutions goes as follow: 
&lt;br /&gt;1.&lt;math&gt;\forall x_b &lt;/math&gt; that &lt;math&gt;f'(x_b)=G'(x_b)+K_c=-k(0,x_b)+K_c=0&lt;/math&gt; and &lt;math&gt;f''(x_b)=G''(x_b)=-k_x(0,x_b)&gt;0&lt;/math&gt;
&lt;br /&gt;2.&lt;math&gt;x_U&lt;/math&gt; and &lt;math&gt;x_D&lt;/math&gt;.
&lt;br /&gt;The solution will be the minimum corresponding &lt;math&gt;N(P)&lt;/math&gt; of all candidate points. &lt;math&gt;N(P)=\min(f(x_U),f(x_D),&lt;/math&gt; and all &lt;math&gt;f(x_b)&lt;/math&gt; from condition 1).

Specifically, if the initial condition &lt;math&gt;G(x)&lt;/math&gt;is a linear function, &lt;math&gt;N(P)=\min(f(x_U),f(x_D))&lt;/math&gt;

====Boundary value problem====
Similarly, the boundary value problem indicates the boundary condition is given at a fix location, e.g. &lt;math&gt;B:=N(x_0,0)&lt;/math&gt;. Still, the observer speed is bounded by &lt;math&gt;v\isin[-w,u]&lt;/math&gt;. For a random point &lt;math&gt;P(x,t)&lt;/math&gt;, the upper bound for solution candidates: if &lt;math&gt;x&gt;x_0&lt;/math&gt;, &lt;math&gt;t_U=t-\frac{x-x_0}{u}&lt;/math&gt;; else, &lt;math&gt;t_D=t-\frac{x_0-x}{w}&lt;/math&gt;.

The BVP is defined as follow:
&lt;br /&gt;&lt;math&gt;N(P)=\min{f(t_b)\equiv G(t_b)+(t-t_b)Q-(x-x_b)K_c}&lt;/math&gt;
&lt;br /&gt;&lt;math&gt;s.t. N(t,x_0)=G(t)&lt;/math&gt;
&lt;br /&gt;&lt;math&gt;\begin{cases}
t&lt;t_U, &amp; \text{if }x&gt;x_0 \\
t&lt;t_D, &amp; \text{if }x&lt;x_0
\end{cases}&lt;/math&gt;

The first order derivative:&lt;math&gt;f'(t_b)=G'(t_b)-Q=q(t_b,0)-Q&lt;/math&gt; is always smaller than 0 because flows won't exceed the capacity. Thus, the minimum happens at the upper bound of the time axis.
&lt;br /&gt;&lt;math&gt;N(P)=\begin{cases}
f(t_U), &amp; \text{if }x&gt;x_0 \\
f(t_D), &amp; \text{if }x&lt;x_0
\end{cases}&lt;/math&gt;

In practice, people use this method to estimate the traffic states at &lt;math&gt;P(t,x)&lt;/math&gt; between two loop detectors, which can be viewed as a combination of two boundary value problems (one at upstream and one at down stream). Denote the upstream loop detector location as &lt;math&gt;x_U&lt;/math&gt; and the downstream loop detector location as &lt;math&gt;x_D&lt;/math&gt;. Based on the conclusion above, the minimum value occurs at the upper bound along the time axis.
&lt;br /&gt;&lt;math&gt;N(P)=\min(f(t_U),f(t_D))&lt;/math&gt;, with &lt;math&gt;\begin{cases}
t_U = t-\frac{x-x_U}{u}\\
t_D = t-\frac{x_D-x}{w}
\end{cases}&lt;/math&gt;

===Applications===

====The bottleneck model====
[[File:Roadway section with bottleneck.png|thumb|350px|Figure 12. Roadway section experiencing a bottleneck]]
[[File:Max queue delay.png|thumb|350px|Figure 13. Maximum queue length and delay]]
One application of the ''N''-curve is the bottleneck model, where the cumulative vehicle count is known at a point ''before'' the bottleneck (i.e. this is location ''X''&lt;sub&gt;1&lt;/sub&gt;). However, the cumulative vehicle count is not known at a point ''after'' the bottleneck (i.e. this is location ''X''&lt;sub&gt;2&lt;/sub&gt;), but rather only the capacity of the bottleneck, or the discharge rate, ''μ'', is known. The bottleneck model can be applied to real-world bottleneck situations such as those resulting from a roadway design problem or a traffic incident.
	
Take a roadway section where a bottleneck exists such as in figure 12. At some location ''X''&lt;sub&gt;1&lt;/sub&gt; before the bottleneck, the arrivals of vehicles follow a regular ''N''-curve. If the bottleneck is absent, the departure rate of vehicles at location ''X''&lt;sub&gt;2&lt;/sub&gt; is essentially the same as the arrival rate at ''X''&lt;sub&gt;1&lt;/sub&gt; at some later time (i.e. at time ''TT''&lt;sub&gt;FF&lt;/sub&gt; – free-flow travel time). However, due to the bottleneck, the system at location ''X''&lt;sub&gt;2&lt;/sub&gt; is now only able to have a departure rate of ''μ''. When graphing this scenario, essentially we have the same situation as in figure 9, where the arrival curve of vehicles is ''N''&lt;sub&gt;1&lt;/sub&gt;, the departure curve of vehicles absent the bottleneck is ''N''&lt;sub&gt;2&lt;/sub&gt;, and the limited departure curve of vehicles given the bottleneck is ''N′''&lt;sub&gt;2&lt;/sub&gt;. The discharge rate ''μ'' is the slope of curve ''N′''&lt;sub&gt;2&lt;/sub&gt;, and all the same traffic flow characteristics as in figure 11 can be determined from this diagram. The maximum delay and maximum queue length can be found at a point ''M'' in figure 13 where the slope of ''N''&lt;sub&gt;2&lt;/sub&gt; is the same as the slope of ''N′''&lt;sub&gt;2&lt;/sub&gt;; i.e. when the virtual arrival rate is equal to the discharge / departure rate ''μ''.  
	
The ''N''-curve in the bottleneck model may also be used to calculate the benefits in removing the bottleneck, whether in terms of a capacity improvement or removing an incident to the side of the roadway.

==== Tandem queues ====
[[File:Qidi's_Tandem_Queue.png|thumb|329x329px|Figure 14. Tandem Queues]]
[[File:N-curve_with_two_BNs.png|thumb|329x329px|Figure 15. N-Curve of Tandem Queues with Two BNs]]
[[File:N-curve_with_n_BNs.png|thumb|329x329px|Figure 16. N-Curve of Tandem Queues with n BNs]]
As introduced in the section above, the N-curve is an applicable model to estimate traffic delay during time by setting arrival and departure cumulative counting curve. Since the curve can represent various traffic characteristics and roadway conditions, the delay and queue situations under these conditions will be able to be recognized and modeled using N-curves. Tandem queues occur when multiple bottlenecks exist between the arrival and departure locations. Figure 14 shows a qualitative layout of a tandem-queue roadway segment with a certain initial arrival. The bottlenecks along the stream have their own capacity,  '&lt;nowiki/&gt;''μ''&lt;sub&gt;i&lt;/sub&gt; [veh/time], and the departure is defined at the downstream end of the entire segment.

To determine the ultimate departure, ''D''(''t''), it can be an available method to research on the individual departures, ''D''&lt;sub&gt;''i''&lt;/sub&gt;(''t''). As shown in the Figure 15, if the free-flow travel-time is neglected, the departure of BN&lt;sub&gt;''i''−1&lt;/sub&gt; will be the virtual arrival of BN&lt;sub&gt;''i''&lt;/sub&gt;, which can also be presented as ''D''&lt;sub&gt;''i''−1&lt;/sub&gt;(''t'') = ''A''&lt;sub&gt;''i''&lt;/sub&gt;(''t''). Thus, the N-curve of a roadway with two bottlenecks (minimum number of BNs along a tandem-queue roadway) can be developed as Figure 15 with ''μ''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;''μ''&lt;sub&gt;2&lt;/sub&gt;. In this case, D&lt;sub&gt;2&lt;/sub&gt;(t) will be the ultimate departure of this 2-BN tandem-queue roadway.

Regarding of a tandem-queue roadway having 3 BNs with ''μ''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;''μ''&lt;sub&gt;2&lt;/sub&gt;, if ''μ''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;''μ''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;''μ''&lt;sub&gt;3&lt;/sub&gt;, similarly as the 2-BN case, D&lt;sub&gt;3&lt;/sub&gt;(t) will be the ultimate departure of this 3-BN tandem-queue roadway. If, however, ''μ''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;''μ''&lt;sub&gt;3&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;''μ''&lt;sub&gt;2&lt;/sub&gt;, D&lt;sub&gt;2&lt;/sub&gt;(t) will then still be the ultimate departure of the 3-BN tandem-queue roadway. Thus, it can be summarized that, the departure of the bottleneck with the minimum capacity will be the ultimate departure of the entire system, regardless of the other capacities and the number of bottlenecks. Figure 16 shows a general case with n BNs.

The N-curve model describing above represents a significant characteristic of the tandem-queue systems, which is that the ultimate departure only depends on the bottleneck with the minimum capacity. In a practical perspective, when the resources (economy, effort, etc.) of the investment on tandem-queue systems are limited, the investment can mainly focus on the bottleneck with the worst condition.

==== Traffic light ====
[[File:Departure Curve for a Signal with Releasing Capacity of mius.png|thumb|Figure 17. Departure curve for a signal with a releasing capacity    |332x332px]][[File:Sat case of traffic light.png|thumb|Figure 18. Saturated case at a traffic light    |332x332px]][[File:Unsat case of traffic light.png|thumb|Figure 19. Unsaturated case at a traffic light with a downstream bottleneck|330x330px]]
A signalized intersection will have special departure behaviors. With simplified speaking, a constant releasing free-flow capacity, ''μ''&lt;sub&gt;s&lt;/sub&gt;, exists during the green phases. On the contrary, the releasing capacity during the red phases should be zero. Thus, the departure N-curve regardless of arrival will look like as Figure 17 below: counts increase with the slope of ''μ''&lt;sub&gt;s&lt;/sub&gt; during green, and remain the same during red..

Saturated case of a traffic light occurs when the releasing capacity is fully used. This case usually exists when the arriving demand is relatively large. The N-curve representation of the saturated case is shown in the Figure 18.

Unsaturated case of a traffic light occurs when releasing capacity is not fully used. This case usually exists when the arriving demand is relatively small. The N-curve representation of the unsaturated case is shown in the Figure 19. If there is a bottleneck with a capacity of ''μ''&lt;sub&gt;b&lt;/sub&gt;(&lt;''μ''&lt;sub&gt;s&lt;/sub&gt;) downstream of the light, the ultimate departure of the light-bottleneck system will be that of the downstream bottleneck.

====Dynamic traffic assignment====
Dynamic traffic assignment can also be solved using the ''N''-curve. There are two main approaches to tackle this problem: system optimum, and user equilibrium. This application will be discussed further in the following section.

==Kerner’s three-phase traffic theory==
[[Three-phase traffic theory|Kerner’s three-phase traffic theory]] is an alternative theory of traffic flow. Probably the most important result of the three-phase theory is that at any time instance there is a range of highway capacities of free flow at a bottleneck. The capacity range is between some maximum and minimum capacities.  The range of highway capacities of free flow at the bottleneck in three-phase traffic theory contradicts fundamentally classical traffic theories as well as methods for traffic management and traffic control which at any time instant assume the existence of a ''particular'' deterministic or stochastic highway capacity of free flow at the bottleneck.

==Traffic assignment==
[[File:4 step model for traffic assignment.png|thumb|350px|Figure 14. The Four Step Travel Demand Model for Traffic Assignment]]
The aim of traffic flow analysis is to create and implement a model which would enable vehicles to reach their destination in the shortest possible time using the maximum roadway capacity. This is a four-step process:

* Generation – the program estimates how many trips would be generated. For this, the program needs the statistical data of residence areas by population, location of workplaces etc.;
* Distribution – after generation it makes the different Origin-Destination (OD) pairs between the location found in step 1;
* Modal Split/Mode Choice – the system has to decide how much percentage of the population would be split between the difference modes of available transport, e.g. cars, buses, rails, etc.;
* Route Assignment – finally, routes are assigned to the vehicles based on minimum criterion rules.
This cycle is repeated until the solution converges.

There are two main approaches to tackle this problem with the end objectives:

* [[Wardrop's Principle|System optimum]]
* [[Wardrop's Principle|User equilibrium]]

===System optimum===
System Optimum is based on the assumption that routes of all vehicles would be controlled by the system, and that rerouting would be based on maximum utilization of resources and minimum total system cost. (Cost can be interpreted as travel time.) Hence, in a System Optimum routing algorithm, all routes between a given OD pair have the same marginal cost.
In traditional transportation economics, System Optimum is determined by equilibrium of demand function and marginal cost function. In this approach, marginal cost is roughly depicted as increasing function in traffic congestion. In traffic flow approach, the marginal cost of the trip can be expressed as sum of the cost(delay time, w)  experienced by the driver and the externality(e) that a driver imposes on the rest of the users.&lt;ref&gt;Juan Carlos Muñoz and Jorge A. Laval. “System optimum dynamic traffic assignment graphical solution method for a congested freeway and one destination”. Transportation Research Part B : Methodological (2006)&lt;/ref&gt; 
Suppose there is a freeway(0) and an alternative route(1), which users can be diverted onto off-ramp. Operator knows total arrival rate(A(t)), the capacity of the freeway(μ_0), and the capacity of the alternative route(μ_1). From the time 't_0', when freeway is congested, some of the users start moving to alternative route. However, when 't_1', alternative route is also full of capacity. Now operator decides the number of vehicles(N), which use alternative route. The optimal number of vehicles(N) can be obtained by calculus of variation, to make marginal cost of each route equal.  Thus, optimal condition is T_0=T_1+∆_1. In this graph, we can see that the queue on the alternative route should clear ∆_1 time units before it clears from the freeway. This solution does not define how we should allocates vehicles arriving between t_1  and T_1, we just can conclude that the optimal solution is not unique. If operator wants freeway not to be congested, operator can impose the congestion toll, e_0-e_1, which is the difference between the externality of freeway and alternative route. In this situation, freeway will maintain free flow speed, however alternative route will be extremely congested.

===User equilibrium===
The user optimum equilibrium assumes that all users choose their own route towards their destination based on the travel time that will be consumed in different route options. The users will choose the route which requires the least travel time. The user optimum model is often used in simulating the impact on traffic assignment by highway bottlenecks. When the congestion occurs on highway, it will extend the delay time in travelling through the highway and create a longer travel time. Under the user optimum assumption, the users would choose to wait until the travel time using a certain freeway is equal to the travel time using city streets, and hence equilibrium is reached. This equilibrium is called User Equilibrium, Wardrop Equilibrium or Nash Equilibrium.
[[File:User equilibrium traffic model.jpg|thumb|400px|Figure 15. User equilibrium traffic model]]

The core principle of User Equilibrium is that all used routes between a given OD pair have the same travel time. An alternative route option is enabled to use when the actual travel time in the system has reached the free-flow travel time on that route.

For a highway user optimum model considering one alternative route, a typical process of traffic assignment is shown in figure 15. When the traffic demand stays below the highway capacity, the delay time on highway stays zero. When the traffic demand exceeds the capacity, the queue of vehicle will appear on the highway and the delay time will increase. Some of users will turn to the city streets when the delay time reaches the difference between the free-flow travel time on highway and the free-flow travel time on city streets. It indicates that the users staying on the highway will spend as much travel time as the ones who turn to the city streets. At this stage, the travel time on both the highway and the alternative route stays the same. This situation may be ended when the demand falls below the road capacity, that is the travel time on highway begins to decrease and all the users will stay on the highway. The total of part area 1 and 3 represents the benefits by providing an alternative route. The total of area 4 and area 2 shows the total delay cost in the system, in which area 4 is the total delay occurs on the highway and area 2 is the extra delay by shifting traffic to city streets.

===Time delay===
Both User Optimum and System Optimum can be subdivided into two categories on the basis of the approach of time delay taken for their solution:

* Predictive Time Delay
* Reactive Time Delay

Predictive time delay is based on the concept that the system or the user knows when the congestion point is reached or when the delay of the freeway would be equal to the delay on city streets, and the decision for route assignment is taken in time. On the other hand, reactive time delay is when the system or user waits to experience the point where the delay is observed and the diversion of routes is in reaction to that experience. Predictive delay gives significantly better results than the reactive delay method.

===Kerner’s network breakdown minimization (BM) principle===
[[Boris Kerner|Kerner]] introduced an alternative approach to traffic assignment based on his network [[Kerner’s breakdown minimization principle|breakdown minimization (BM) principle]]. Rather than an explicit minimization of travel time that is the objective of [[Wardrop's Principle|System Optimum]] and [[Wardrop's Principle|User Equilibrium]], the BM principle minimizes the probability of the occurrence of congestion in a traffic network.&lt;ref&gt;[http://iopscience.iop.org/1751-8121/labtalk-article/45319 ''Minimizing the probability of the occurrence of traffic congestion in a traffic network'']&lt;/ref&gt; Under sufficient traffic demand, the application of the BM principle should lead to implicit minimization of travel time in the network.

==Variable speed limit assignment==
This is an upcoming approach of eliminating shockwave and increasing safety for the vehicles. The concept is based on the fact that the risk of accident on a roadway increases with speed differential between the upstream and downstream vehicles. The two types of crash risk which can be reduced from VSL implementation are the rear-end crash and the lane-change crash. Variable speed limits seek to homogenize speed, leading to a more constant flow.&lt;ref&gt;{{cite journal|last1=Xu|first1=Wang|title=Implementation of Variable Speed Limits: Preliminary Test on Whitemud Drive, Edmonton, Canada|journal=Journal Of Transportation Engineering|date=2016|volume=142|issue=12|doi=10.1061/(ASCE)TE.1943-5436.0000895}}&lt;/ref&gt; Different approaches have been implemented by researchers to build a suitable VSL algorithm.

==Road junctions==
A major consideration in road capacity relates to the design of junctions. By allowing long "weaving sections" on gently curving roads at graded intersections, vehicles can often move across lanes without causing significant interference to the flow. However, this is expensive and takes up a large amount of land, so other patterns are often used, particularly in urban or very rural areas. Most large models use crude simulations for intersections, but computer simulations are available to model specific sets of traffic lights, roundabouts, and other scenarios where flow is interrupted or shared with other types of road users or pedestrians. A well-designed junction can enable significantly more traffic flow at a range of traffic densities during the day. By matching such a model to an "Intelligent Transport System", traffic can be sent in uninterrupted "packets" of vehicles at predetermined speeds through a series of phased traffic lights.
The UK's [[Transport Research Laboratory|TRL]] has developed junction modelling programs for small-scale local schemes that can take account of detailed geometry and sight lines; [[ARCADY]] for roundabouts, [[Junctions#PICADY|PICADY]] for priority intersections, and OSCADY and TRANSYT for signals. Many other junction analysis software packages&lt;ref&gt;{{cite journal|last1=Mahmud|first1=Khizir|last2=Town|first2=Graham E.|title=A review of computer tools for modeling electric vehicle energy requirements and their impact on power distribution networks|journal=Applied Energy|date=June 2016|volume=172|pages=337–359|doi=10.1016/j.apenergy.2016.03.100}}&lt;/ref&gt; exist such as [[Sidra Intersection|Sidra]] and [[LINSIG|LinSig]] and [[Synchro Software|Synchro]].

==Kinematic wave model==
The [[kinematic wave]] model was first applied to traffic flow by Lighthill and Whitham in 1955. Their two-part paper first developed the theory of kinematic waves using the motion of water as an example. In the second half, they extended the theory to traffic on “crowded arterial roads.” This paper was primarily concerned with developing the idea of traffic “humps” (increases in flow) and their effects on speed, especially through bottlenecks.&lt;ref name=lighthill_whitham_1955&gt;{{cite journal |last=Lighthill |first=M.J.|last2=Whitham |first2=G.B.  |year= 1955 |title=On kinematic waves. I: Flood movement in long rivers. II: A theory of traffic flow on long crowded roads
 |journal=[[Proceedings of the Royal Society]]
 |volume=229A |issue=4 |pages=281–345
}}
&lt;/ref&gt;

The authors began by discussing previous approaches to traffic flow theory. They note that at the time there had been some experimental work, but that “theoretical approaches to the subject [were] in their infancy.” One researcher in particular, John Glen Wardrop, was primarily concerned with statistical methods of examination, such as space mean speed, time mean speed, and “the effect of increase of flow on overtaking” and the resulting decrease in speed it would cause. Other previous research had focused on two separate models: one related traffic speed to traffic flow and another related speed to the headway between vehicles.&lt;ref name="lighthill_whitham_1955"/&gt;

The goal of Lighthill and Whitham, on the other hand, was to propose a new method of study “suggested by theories of the flow about supersonic projectiles and of flood movement in rivers.” The resulting model would capture both of the aforementioned relationships, speed-flow and speed-headway, into a single curve, which would “[sum] up all the properties of a stretch of road which are relevant to its ability to handle the flow of congested traffic.” The model they presented related traffic flow to concentration (now typically known as density). They wrote, “The fundamental hypothesis of the theory is that at any point of the road the flow q (vehicles per hour) is a function of the concentration k (vehicles per mile).” According to this model, traffic flow resembled the flow of water in that “Slight changes in flow are propagated back through the stream of vehicles along ‘kinematic waves,’ whose velocity relative to the road is the slope of the graph of flow against concentration.” The authors included an example of such a graph; this flow-versus-concentration (density) plot is still used today (see figure 3 above).&lt;ref name="lighthill_whitham_1955"/&gt;

The authors used this flow-concentration model to illustrate the concept of shock waves, which slow down vehicles which enter them, and the conditions that surround them. They also discussed bottlenecks and intersections, relating both to their new model. For each of these topics, flow-concentration and time-space diagrams were included. Finally, the authors noted that no agreed-upon definition for capacity existed, and argued that it should be defined as the “maximum flow of which the road is capable.” Lighthill and Whitham also recognized that their model had a significant limitation: it was only appropriate for use on long, crowded roadways, as the “continuous flow” approach only works with a large number of vehicles.&lt;ref name="lighthill_whitham_1955"/&gt;

===Components of the kinematic wave model of traffic flow theory===
The kinematic wave model of traffic flow theory is the simplest dynamic traffic flow model that reproduces the propagation of traffic waves. It is made up of three components: the fundamental diagram, the conservation equation, and initial conditions. The law of conservation is the fundamental law governing the kinematic wave model:

{{in5}}&lt;math&gt;\frac{\partial k}{\partial t} + \frac{\partial q}{\partial x} =0,&lt;/math&gt;

The fundamental diagram of the kinematic wave model relates traffic flow with density, as seen in figure 3 above. It can be written as:

{{in5}}&lt;math&gt;{q}={F(k)}&lt;/math&gt;

Finally, initial conditions must be defined to solve a problem using the model. A boundary is defined to be &lt;math&gt;{k(t,x)}&lt;/math&gt;, representing density as a function of time and position.  These boundaries typically take two different forms, resulting in initial value problems (IVPs) and boundary value problems (BVPs). Initial value problems give the traffic density at time &lt;math&gt;{t}={0}&lt;/math&gt;, such that &lt;math&gt;{k(0,x)}={g(x)}&lt;/math&gt;, where &lt;math&gt;{g(x)}&lt;/math&gt; is the given density function. Boundary value problems give some function &lt;math&gt;{g(t)}&lt;/math&gt; that represents the density at the &lt;math&gt;{x=0}&lt;/math&gt; position, such that  &lt;math&gt;{k(t,0)}={g(t)}&lt;/math&gt;.
The model has many uses in traffic flow. One of the primary uses is in modeling traffic bottlenecks, as described in the following section.

==Newell-Daganzo Merge Models==
[[File:Diagram for Newell daganzo merge model.png|thumb|300px|border|right|text-top|The diagram of Newell-Daganzo merge model and its variables]]

In the condition of traffic flows leaving two branch roadways and merging into a single flow through a single roadway, determining the flows that pass through the merging process and the state of each branch of roadways becomes an important task for traffic engineers. the Newell-Daganzo merge model is a good approach to solve these problems. This simple model is the output of the result of both Gordon Newell's description of the merging process&lt;ref&gt;{{cite book |last1= Newell |first1= Gordon |title= Applications of Queueing Theory |edition= 2nd|year= 1982 |publisher= Chapman and Hall|location= London }}&lt;/ref&gt; and the Daganzo's [[Cell Transmission Model|cell transmission model]].&lt;ref&gt;{{cite journal |url=http://escholarship.org/uc/item/9pz309w7;jsessionid=916E06317A6CD10953CA769F0E2C8D23 |title=The Cell Transmission Model, part II: Network Traffic|author=Daganzo, Carlos |journal=Transportation Research Part B: Methodological|volume= 28|issue=2 |pages=279–293 |year=1994}}&lt;/ref&gt; In order to apply the model to determine the flows which exiting two branch of roadways and the stat of each branch of roadways, one needs to know the capacities of the two input branches of roadways, the exiting capacity, the demands for each branch of roadways, and the number of lanes of the single roadway. The merge ratio will be calculated in order to determine the proportion of the two input flows when both of branches of roadway are operating in congested conditions.

As can be seen in a simplified model of the process of merging,&lt;ref&gt;{{cite journal |url=http://www.uctc.net/research/papers/722.pdf |title=Driver Turn-Taking Behavior in Congested Freeway Merges|author1=Cassidy, Michael J.  |author2=Ahn, Soyoung  |journal=Transportation Research Record: Journal of the Transportation Research Board|volume= 1934 |pages=140–147 |year=2005 |doi=10.3141/1934-15}}&lt;/ref&gt; the exiting capacity of the system is defined to be μ, the capacities of the two input branches of roadways are defined as μ&lt;sub&gt;1&lt;/sub&gt; and μ&lt;sub&gt;2&lt;/sub&gt;, and the demands for each branch of roadways are defined as q&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;D&lt;/sup&gt; and q&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;D&lt;/sup&gt;. The q&lt;sub&gt;1&lt;/sub&gt; and q&lt;sub&gt;2&lt;/sub&gt; are the output of the model which are the flows that pass through the merging process. The process of the model is based on the assumption that the sum of capacities of the two input branches of roadways is less than the exiting capacity of the system, μ&lt;sub&gt;1&lt;/sub&gt;+μ&lt;sub&gt;2&lt;/sub&gt; ≤ μ.

===Solution for Newell-Daganzo Merge Model===
[[File:Graphical solution of newell model.png|thumb|300px|border|right|text-top|Graphical solution of Newell–Daganzo merge model.]]

The flows that pass through the merging process, q&lt;sub&gt;1&lt;/sub&gt; and q&lt;sub&gt;2&lt;/sub&gt;, are determined by split priority or, merge ratio. The state of each branch of roadways is determined by graphically with the input of the demands for each branch of roadways, q&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;D&lt;/sup&gt; and q&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;D&lt;/sup&gt;. There are four possible states for the merge system, both inlets in free flow, one of the inlets in congestion, and both inlets in congestion.

A common approach to calculate the merge ratio p is called "zipper rule" which p is calculated based on the number of lanes of the single roadway when both inlets are in congestion. If there are n lanes of the single roadway, then under the zipper rule, p=1/(2n-1). This merge ratio is also the ratio of minimum capacities of the inlets μ&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt; and μ&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;. μ&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt; + μ&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt; = μ. As a result, q&lt;sub&gt;1=(μ&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;/μ)*μ and q&lt;sub&gt;2=(μ&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;/μ)*μ.

The state of each branch of roadways is determined by the graphical solution which is shown in the right. The x-axis is the possible value of ''q''&lt;sub&gt;1&lt;/sub&gt; and the y-axis is the possible value of ''q''&lt;sub&gt;2&lt;/sub&gt;.The feasible region of demands is the defined by the maximum possible values for q&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;D&lt;/sup&gt; and q&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;D&lt;/sup&gt; which are μ&lt;sub&gt;1&lt;/sub&gt; and μ&lt;sub&gt;2&lt;/sub&gt;. The [[feasible region]] for ''q''&lt;sub&gt;1&lt;/sub&gt; and ''q''&lt;sub&gt;2&lt;/sub&gt; is defined as the intersection between the line of ''q''&lt;sub&gt;1&lt;/sub&gt; + ''q''&lt;sub&gt;2&lt;/sub&gt; = ''μ'' and the feasible region of demands. The merge ration, p, is plotted from the origin to the line of ''q''&lt;sub&gt;1&lt;/sub&gt; + ''q''&lt;sub&gt;2&lt;/sub&gt; = ''μ''.

The four possible states of the merge system are shown in the graph by the regions noted by A1, A2, A3, and A4. A specific states of a merge system is determined by the region where the input data fall into. The region A1 represents the state when both inlet 1 and inlet 2 are in free flow. The region A2 represents the state when inlet 1 is in free flow and inlet 2 is in congestion. The region A3 represents the state when inlet 1 is in congestion and inlet 2 is in free flow. The region A4 represents the state when both inlet 1 and inlet 2 are in congestion.

==Traffic bottleneck==
Traffic bottlenecks are disruptions of traffic on a roadway caused either due to road design, traffic lights, or accidents. There are two general types of bottlenecks, stationary and moving bottlenecks. Stationary bottlenecks are those that arise due to a disturbance that occurs due to a stationary situation like narrowing of a roadway, an accident. Moving bottlenecks on the other hand are those vehicles or vehicle behavior that causes the disruption in the vehicles which are upstream of the vehicle. Generally, moving bottlenecks are caused by heavy trucks as they are slow moving vehicles with less acceleration and also may make lane changes.

[[File:Percentage split of causes of Traffic Congestion.png|thumb|350px|Figure 16.]]

Bottlenecks are important considerations because they impact the flow in traffic, the average speeds of the vehicles. The main consequence of a bottleneck is an immediate reduction in capacity of the roadway. The Federal Highway Authority has stated that 40% of all congestion is from bottlenecks figure 16 shows the pie-chart for various causes of congestion. Figure 17&lt;ref name=missing&gt;figure missing&lt;/ref&gt; shows the common causes of congestion or bottlenecks.

===Stationary bottleneck===
The general cause of stationary bottlenecks are lane drops which occurs when the a multilane roadway loses one or more its lane. This causes the vehicular traffic in the ending lanes to merge onto the other lanes.

[[Image:Wikipedia TrafficBottlenecks regular.svg|thumb|350px|Figure 18.]]
Consider a stretch of highway with two lanes in one direction.  Suppose that the [[fundamental diagram]] is modeled as shown here. The highway has a peak capacity of Q vehicles per hour, corresponding to a density of k&lt;sub&gt;c&lt;/sub&gt; vehicles per mile. The highway normally becomes jammed at k&lt;sub&gt;j&lt;/sub&gt; vehicles per mile.

Before capacity is reached, traffic may flow at A vehicles per hour, or a higher B vehicles per hour. In either case, the speed of vehicles is v&lt;sub&gt;f&lt;/sub&gt;, or "free flow," because the roadway is under capacity.

Now, suppose that at a certain location x&lt;sub&gt;0&lt;/sub&gt;, the highway narrows to one lane. The maximum capacity is now limited to D', or half of Q, since only one lane of the two is available. D shares the same flowrate as state D', but its vehicular density is higher.
[[Image:Wikipedia TrafficBottlenecks regular tsd.svg|thumb|350px|Figure 19.]]

Using a time-space diagram, we may model the bottleneck event. Suppose that at time 0, traffic begins to flow at rate B and speed v&lt;sub&gt;f&lt;/sub&gt;. After time t1, vehicles arrive at the lower flowrate A.

Before the first vehicles reach location x&lt;sub&gt;0&lt;/sub&gt;, the traffic flow is unimpeded. However, downstream of x&lt;sub&gt;0&lt;/sub&gt;, the roadway narrows, reducing the capacity by half &amp;ndash; and to below that of state B. Due to this, vehicles will begin queuing upstream of x&lt;sub&gt;0&lt;/sub&gt;. This is represented by high-density state D. The vehicle speed in this state is the slower v&lt;sub&gt;d&lt;/sub&gt;, as taken from the fundamental diagram. Downstream of the bottleneck, vehicles transition to state D', where they again travel at free-flow speed v&lt;sub&gt;f&lt;/sub&gt;.

Once vehicles arrive at rate A starting at t1, the queue will begin to clear and eventually dissipate. State A has a flowrate below the one-lane capacity of states D and D'.

On the time-space diagram, a sample vehicle trajectory is represented with a dotted arrow line. The diagram can readily represent vehicular delay and queue length. It is a simple matter of taking horizontal and vertical measurements within the region of state D.

===Moving bottleneck===
As explained above, moving bottlenecks are caused due to slow moving vehicles that cause disruption in traffic. Moving bottlenecks can be active or inactive bottlenecks. If the reduced capacity(q&lt;sub&gt;u&lt;/sub&gt;) caused due to a moving bottleneck is greater than the actual capacity(μ) downstream of the vehicle, then this bottleneck is said to be an active bottleneck. Figure 20 shows the case of a truck moving with velocity 'v' approaching an downstream location with capacity 'μ'. If the reduced capacity of the truck (q&lt;sub&gt;u&lt;/sub&gt;) is less than the downstream capacity, then the truck becomes an inactive bottleneck.
[[File:Active Inactive Moving Bottleneck1.PNG|thumb|350px|Moving Bottleneck|Figure 20.]]

Laval 2009, presents a framework for estimating analytical expressions for the capacity reductions caused by a subset of vehicles forced to slow down at horizontal/vertical curves on multilane freeway. In each of the lane the underperforming stream is described in terms of its desired speed distribution and is modeled as per Newell’s kinematic wave theory for moving bottlenecks. Lane changing in the presence of trucks can lead to a positive or negative impact on capacity. If the target lane is empty then the lane-changing increases capacity

[[Image:Tractor-OnTheRoad01.jpg|thumb|Figure 21. A slow tractor creates a moving bottleneck.]]
For this example, consider three lanes of traffic in one direction. Assume that a truck starts traveling at speed v, slower than the free flow speed v&lt;sub&gt;f&lt;/sub&gt;. As shown on the [[fundamental diagram]] below, q&lt;sub&gt;u&lt;/sub&gt; represents the reduced capacity (2/3 of Q, or 2 of 3 lanes available) around the truck.

State A represents normal approaching traffic flow, again at speed v&lt;sub&gt;f&lt;/sub&gt;. State U, with  flowrate q&lt;sub&gt;u&lt;/sub&gt;, corresponds to the queuing upstream of the truck. On the fundamental diagram, vehicle speed v&lt;sub&gt;u&lt;/sub&gt; is slower than v&lt;sub&gt;f&lt;/sub&gt;. But once drivers have navigated around the truck, they can again speed up and transition to downstream state D. While this state travels at free flow, the vehicle density is less because fewer vehicles get around the bottleneck.
[[Image:Wikipedia TrafficBottlenecks moving1.svg|thumb|none|350px|Figure 22.]]

Suppose that, at time t, the truck slows from free-flow to v. A queue builds behind the truck, represented by state U. Within the region of state U, vehicles drive slower as indicated by the sample trajectory. Because state U limits to a smaller flow than state A, the queue will back up behind the truck and eventually crowd out the entire highway (slope s is negative). If state U had the higher flow, there would still be a growing queue. However, it would not back up because the slope s would be positive.
[[Image:Wikipedia TrafficBottlenecks moving1 tsd.svg|thumb|none|350px|Figure 23.]]

===Riemann's problem===
Imagine a scenario in which a two lane road is reduced to one lane at point ''x''&lt;sub&gt;o&lt;/sub&gt; from here on the road’s capacity is reduced to half its original (½µ), Case I. Later along the road at point ''x''&lt;sub&gt;1&lt;/sub&gt; the 2nd lane is opened and the capacity is restored to its original (µ), Case II.

;Case I:
There is a bottleneck limiting the flow of traffic which causes an increase in the density of cars (k) at location (''x''&lt;sub&gt;o&lt;/sub&gt;). This causes a deceleration for all oncoming cars traveling at speed u to slow to speed ''v''&lt;sub&gt;d&lt;/sub&gt;. This shockwave will travel at the speed of the slope of line U-D on the fundamental diagram. The wave speed can be calculated as v&lt;sub&gt;shock&lt;/sub&gt; = (''q''&lt;sub&gt;D&lt;/sub&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''q''&lt;sub&gt;U&lt;/sub&gt;)/(''k''&lt;sub&gt;D&lt;/sub&gt;&amp;minus;''k''&lt;sub&gt;U&lt;/sub&gt;).  This line delineates the congestion traffic from oncoming free-flow traffic. If the slope of U-D on the fundamental diagram is positive congestion will continue downstream of the highway. If it has a negative slope the congestion will continue upstream (see figure a&lt;ref name=missing/&gt;). This deceleration is the case I of Riemann’s problem (see figure b and c).

;Case II:
In case II of Riemann’s problem traffic goes from congestion to free-flow and the cars accelerate as the density drops. Again the slope of these shock waves can be calculated using the same formula v&lt;sub&gt;shock&lt;/sub&gt; = (''q''&lt;sub&gt;D&lt;/sub&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''q''&lt;sub&gt;U&lt;/sub&gt;)/(''k''&lt;sub&gt;D&lt;/sub&gt;&amp;minus;''k''&lt;sub&gt;U&lt;/sub&gt;). The difference this time is that traffic flow travels along the fundamental diagram not in a straight line across but many slopes between various points on the curved fundamental diagram (see figure d). This causes many lines emanating from point ''x''&lt;sub&gt;1&lt;/sub&gt; all in a fan shape, called rarefaction (see figure e). This model implies that the users later on in time will take longer to accelerate as they meet each of the lines. Instead a better approximation is a triangular diagram where the traffic increases abruptly as it would when a driver sees an opening in front of them (see figures f and g).

[[File:A and B Fundamental Diagram.png|thumb|A and B|350px|Figure 24.]]

[[File:C Fundamental Diagram.png|thumb|C|350px|Figure 25.]]

[[File:D and E Fundamental Diagram.png|thumb|350px|Figure 26.]]

[[File:F and G Fundamental Diagram.png|thumb|350px|Figure 27.]]

==Criticism==
In a critical review,&lt;ref name="KernerReview"&gt;{{cite journal|url = http://www.sciencedirect.com/science/article/pii/S0378437113004986 | doi=10.1016/j.physa.2013.06.004 | volume=392 | title=Criticism of generally accepted fundamentals and methodologies of traffic and transportation theory: A brief review | year=2013 | journal=Physica A: Statistical Mechanics and its Applications | pages=5261–5282 | last1 = Kerner | first1 = Boris S.| bibcode=2013PhyA..392.5261K }}&lt;/ref&gt; Kerner explained that generally accepted classical fundamentals and methodologies of traffic and transportation theory are inconsistent with the set of fundamental empirical features of traffic breakdown at a highway bottleneck.

===Set of fundamental empirical features of traffic breakdown at highway bottlenecks===
The set of fundamental empirical features of traffic breakdown at a highway bottleneck is as follows:

# Traffic breakdown at a highway bottleneck is a local phase transition from free flow (''F'') to congested traffic whose downstream front is usually fixed at the bottleneck location. Such congested traffic is called synchronized flow (''S'').  Within the downstream front of synchronized flow, vehicles accelerate from synchronized flow upstream of the bottleneck to free flow downstream of the bottleneck.

# At the same bottleneck, traffic breakdown can be either spontaneous or induced.
# The probability of traffic breakdown is an increasing flow rate function.
# There is a well-known hysteresis phenomenon associated with traffic breakdown: When the breakdown has occurred at some flow rates with resulting congested pattern formation upstream of the bottleneck, then a return transition to free flow at the bottleneck is usually observed at considerably smaller flow rates.

A spontaneous traffic breakdown occurs, where there are free flows both upstream and downstream of the bottleneck before the breakdown has occurred. In contrast, an induced traffic breakdown is caused by a propagation of a congested pattern that has earlier emerged for example at another downstream bottleneck.

Empirical data that illustrates the set of fundamental empirical features of traffic breakdown at highway bottlenecks as well as explanations of the empirical data can be found in Wikipedia article [[Kerner’s breakdown minimization principle]] and in review.&lt;ref name=KernerReview/&gt;

===Classical traffic flow theories===
The generally accepted classical fundamentals and methodologies of traffic and transportation theory are as follows:

(i) The Lighthill-Whitham-Richards (LWR) model introduced in 1955&amp;ndash;56.&lt;ref name=lighthill_whitham_1955/&gt;&lt;ref name="RichardsLWR"&gt;[http://pubsonline.informs.org/doi/abs/10.1287/opre.4.1.42 P.I. Richards, "Shockwaves on the highway". Oper. Res., 4, 42-51 (1956)]&lt;/ref&gt; Daganzo introduced a cell-transmission model (CTM) that is consistent with the LWR model.&lt;ref name=" Daganzo CTM"&gt;{{cite journal|url = http://www.sciencedirect.com/science/article/pii/0191261594900027 | doi=10.1016/0191-2615(94)90002-7 | volume=28 | title=The cell transmission model: A dynamic representation of highway traffic consistent with the hydrodynamic theory | year=1994 | journal=Transportation Research Part B: Methodological | pages=269–287 | last1 = Daganzo | first1 = Carlos F.}}&lt;/ref&gt;

(ii) A traffic flow instability that causes a growing wave of a local reduction of the vehicle speed. This classical traffic flow instability was introduced in 1959&amp;ndash;61 in the General Motors (GM) car-following model by Herman, Gazis,  Montroll, Potts, and Rothery.&lt;ref name="GM1"&gt;[http://pubsonline.informs.org/doi/abs/10.1287/opre.7.1.86 R. Herman, E.W. Montroll, R.B. Potts, and  R.W. Rothery, "Traffic dynamics: analysis of stability in car following". Oper. Res. , 7,  86-106 (1959)]&lt;/ref&gt;&lt;ref name=" GM2"&gt;[http://pubsonline.informs.org/doi/abs/10.1287/opre.9.4.545  D.C. Gazis, R. Herman, and R.W. Rothery. "Nonlinear follow-the-leader models of traffic flow". Oper. Res., 9,  545-567 (1961)]&lt;/ref&gt;   The classical traffic flow instability of the GM model has been incorporated in a huge number of traffic flow models like Gipps's model, Payne's model, Newell's optimal velocity (OV) model, Wiedemann's model, Whitham's model, the Nagel-Schreckenberg (NaSch) cellular automaton (CA) model, Bando et al. OV model, Treiber's IDM, Krauß model, the Aw-Rascle model and many other well-known microscopic and macroscopic traffic-flow models, which are the basis of [[traffic simulation]] tools widely used by traffic engineers and researchers (see, e.g., references in review&lt;ref name=KernerReview/&gt;).

(iii) The understanding of highway capacity as a ''particular'' value. This understanding of road capacity was probably introduced in 1920&amp;ndash;35 (see &lt;ref name=" Greenshields"&gt;[http://pubsonline.informs.org/doi/abs/10.1287/opre.7.1.86  Greenshields, B.D. "A study of traffic capacity". Highway Research Board Proceedings,  14,  448–477 (1935) )]&lt;/ref&gt;). Currently, it is assumed that highway capacity of free flow at a highway bottleneck is a stochastic value. However, in accordance with the classical understanding of highway capacity, it is assumed that at a given time instant there can be only one particular value of this stochastic highway capacity  (see references in the book&lt;ref name=" Elefteriadou"&gt;[https://link.springer.com/book/10.1007/978-1-4614-8435-6 Elefteriadou, L. "An Introduction to Traffic Flow Theory". Springer Optimization and Its Applications, Vol. 84 (Springer, Berlin 2014) ]&lt;/ref&gt;).

(iv) Wardrop's user equilibrium (UE) and system optimum (SO) principles for traffic and transportation network optimization and control.&lt;ref name="Wardrop"&gt;[http://www.icevirtuallibrary.com/content/article/10.1680/ipeds.1952.11259  J.G. Wardrop, "Some theoretical aspects of road traffic research", in Proc. of Inst. of Civil Eng. II., 1, 325—362 (1952)]&lt;/ref&gt;
–

===Failure of classical traffic flow theories===
Kerner explains the failure of the generally accepted classical traffic flow theories as follows:&lt;ref name=KernerReview/&gt;

1. The LWR-theory fails because this theory cannot show empirical induced traffic breakdown observed in real traffic. Correspondingly, all applications of LWR-theory to the description of traffic breakdown at highway bottlenecks (like related applications of Daganzo’s  cell-transmission model, cumulative vehicle count curves (''N''-curves), bottleneck model, highway capacity models as well as associated applications of kinematic wave theory) are also inconsistent with the set of fundamental empirical features of traffic breakdown.

2. Two-phase traffic flow models of the GM model class (see references in&lt;ref name=KernerReview/&gt;) fail because traffic breakdown in the models of the GM class is a phase transition from free flow (''F'') to a moving jam (''J'') (called F → J transition): In a traffic flow model belonging to the GM model class due to traffic breakdown, a moving jam(s) appears spontaneously in an initially free flow at a highway bottleneck. In contrast with this model result, real traffic breakdown is a phase transition from free flow (''F'') to synchronized flow (''S'') (called F → S transition): Rather than a moving jam(s), due to traffic breakdown in real traffic, synchronized flow occurs whose downstream front is fixed at the bottleneck.

3. The understanding of highway capacity as a particular value (see references in the book &lt;ref name= Elefteriadou /&gt;) fails because this assumption about the nature of highway capacity contradicts the empirical evidence that traffic breakdown can be induced at a highway bottleneck.

4. Dynamic traffic assignment or/and any kind of traffic optimization and control based on Wardrop's SO or UE principles fail because of possible random transitions between the free flow and synchronized flow at highway bottlenecks. Due to such random transitions, the minimization of travel cost in a traffic network is not possible.

According to Kerner,&lt;ref name=KernerReview/&gt; the inconsistence the generally accepted classical fundamentals and methodologies of traffic and transportation theory with the set of fundamental empirical features of traffic breakdown at a highway bottleneck can explain why network optimization and control approaches based on these fundamentals and methodologies have failed by their applications in the real world. Even several decades of a very intensive effort to improve and validate network optimization    models have no success. Indeed, there can be found no examples where on-line implementations of the network optimization models based on these fundamentals and methodologies could reduce congestion in real traffic and transportation networks.

This is due to the fact that the fundamental empirical features of traffic breakdown at highway bottlenecks have been understood only during last 20 years. In contrast, the generally accepted fundamentals and methodologies of traffic and transportation theory have been introduced in the 50s-60s. Thus the scientists whose ideas led to these classical fundamentals and methodologies of traffic and transportation theory could not know the set of empirical features of real traffic breakdown.

===Incommensurability of Kerner’s three-phase traffic theory and classical traffic-flow theories===
The explanation of traffic breakdown at a highway bottleneck by a F → S transition in a metastable free flow at the bottleneck is the basic assumption of Kerner’s [[three-phase traffic theory]].&lt;ref name=KernerReview /&gt; The three-phase traffic theory is consistent with the set of fundamental empirical features of traffic breakdown.
''None'' of earlier traffic-flow theories incorporates a F→S transition in a metastable free flow at the bottleneck. Therefore, as above mentioned none of the classical traffic flow theories is consistent with the set of empirical features of real traffic breakdown at a highway bottleneck. 
The F→S phase transition in metastable free flow at highway bottleneck does explain the empirical evidence of the induced transition from free flow to synchronized flow together with the flow-rate dependence of the breakdown probability. In accordance with the classical book by Kuhn,&lt;ref name=KuhnBook&gt;[http://press.uchicago.edu/ucp/books/book/chicago/S/bo13179781.html  T.S. Kuhn, "The structure of scientific revolutions". Fourth edition. (The University of Chicago Press, Chicago, London 2012)]&lt;/ref&gt; this shows ''the incommensurability'' of three-phase theory and the classical traffic-flow theories (for more details, see &lt;ref name="incommensurability "&gt;{{cite journal | last1 = Kerner | first1 = Boris S. | last2 = Klenov | first2 = Sergey L. | last3 = Schreckenberg | first3 = Michael | year = 2014 | title = Probabilistic physical characteristics of phase transitions at highway bottlenecks: Incommensurability of three-phase and two-phase traffic-flow theories | url = | journal = Phys. Rev. E | volume = 89 | issue = | page = 052807 | doi = 10.1103/PhysRevE.89.052807 | bibcode = 2014PhRvE..89e2807K }}&lt;/ref&gt;):

{{Quote|The minimum highway capacity &lt;math&gt;C_{min}&lt;/math&gt;,  at which the F→S phase transition can still be induced at a highway bottleneck as stated in Kerner’s theory, has ''no'' sense for other traffic flow theories and models.}}

The term [[commensurability (philosophy of science)|"incommensurability"]] has been introduced by Kuhn in his classical book&lt;ref name=KuhnBook /&gt; to explain a [[paradigm shift]] in a scientific field. It must also be noted that the existence of these two traffic phases, free flow (''F'') and synchronized flow (''S'') at the same flow rate does not result from the stochastic nature of traffic: Even if there were no stochastic processes in vehicular traffic, the states ''F'' and ''S'' do exist at the same flow rate. However, classical stochastic approaches to traffic control do not assume a possibility of an F→S phase transition in metastable free flow.  For this reason, these stochastic approaches cannot resolve the problem of the inconsistence of classical theories with the set of empirical features of real traffic breakdown.

==See also==
* [[Braess' paradox]]
* [[Data flow]]
* [[Dijkstra's algorithm]]
* [[Epidemiology of motor vehicle collisions]]
* [[Floating car data]]
* [[Flow (computer networking)]]
* [[Fundamental diagram of traffic flow]]
* [[Infrared traffic logger]]
* ''[[Journal of Transport and Land Use]]''
* [[John Nestor|Nestoring]]
* [[Newell's car-following model]]
* [[Newell–Daganzo merge model]]
* [[Truck Lane Restriction]]
* [[Road traffic control]]
* [[Road traffic safety#Statistics]]
* [[Rule 184]]
* [[Three-phase traffic theory]]
* [[Kerner’s breakdown minimization principle]]
* [[Three-detector problem and Newell's method]]
* [[Traffic bottleneck]]
* [[Traffic model]]
* [[Traffic simulation]]
** [[Microscopic traffic flow model]]
** [[Macroscopic traffic flow model]]
* [[Traffic wave]]
* [[Traffic counter]]
* [[Traffic congestion: Reconstruction with Kerner’s three-phase theory]]
* [[Traffic engineering (transportation)|Traffic engineering]]
* [[Turning movement counters]]

==References==
{{reflist|2}}

==Further reading==
A survey about the state of art in traffic flow modelling:

*N. Bellomo, V. Coscia, M. Delitala, On the Mathematical Theory of Vehicular Traffic Flow I. Fluid Dynamic and Kinetic Modelling, ''Math. Mod. Meth. App. Sc.'', Vol. 12, No. 12 (2002) 1801–1843
*S. Maerivoet, ''[https://lirias.kuleuven.be/bitstream/1979/348/2/dissertation-svenmaerivoet.pdf Modelling Traffic on Motorways: State-of-the-Art, Numerical Data Analysis, and Dynamic Traffic Assignment]'', Katholieke Universiteit Leuven, 2006
*M. Garavello and  B. Piccoli, Traffic Flow on Networks, American Institute of Mathematical Sciences (AIMS), Springfield, MO, 2006. pp.&amp;nbsp;xvi+243 {{ISBN|978-1-60133-000-0}}
*Carlos F.Daganzo, "Fundamentals of Transportation and Traffic Operations.", Pergamon-Elsevier, Oxford, U.K. (1997)
*[https://www.springer.com/engineering/mechanical+eng/book/978-3-642-02604-1 B.S. Kerner, ''Introduction to Modern Traffic Flow Theory and Control: The Long Road to Three-Phase Traffic Theory'', Springer, Berlin, New York 2009]
*Cassidy, M.J. and R.L. Bertini.  "Observations at a Freeway Bottleneck."  ''Transportation and Traffic Theory'' (1999).
*Daganzo, Carlos F.  "A Simple Traffic Analysis Procedure."  ''Networks and Spatial Economics'' 1.i (2001): 77–101.
*Lindgren, Roger V.F.  "Analysis of Flow Features in Queued Traffic on a German Freeway."  ''Portland State University'' (2005).
*Ni, B. and J.D. Leonard.  "Direct Methods of Determining Traffic Stream Characteristics by Definition."  ''Transportation Research Record'' (2006).

Useful books from the physical point of view:

*[https://www.springer.com/physics/complexity/book/978-3-642-32459-8 M. Treiber and A. Kesting, "Traffic Flow Dynamics", Springer, 2013]
*[https://www.springer.com/physics/complexity/book/978-3-540-20716-0 B.S. Kerner, ''The Physics of Traffic'', Springer, Berlin, New York 2004]
*[http://xstructure.inr.ac.ru/x-bin/theme2.py?arxiv=cond-mat&amp;level=2&amp;index1=28 Traffic flow on arxiv.org]
*May, Adolf. ''Traffic Flow Fundamentals''. Prentice Hall, Englewood Cliffs, NJ, 1990.
*Taylor, Nicholas. ''[http://www.contram.com/download/NETS_CONTRAM_DTA.pdf The Contram dynamic traffic assignment model]'' [[Transport Research Laboratory|TRL]] 2003

==External links==
*[http://hcm.trb.org/ The Transportation Research Board's (TRB) fifth edition of the Highway Capacity Manual (HCM 2010)]

{{Portal bar|Mathematics|Roads|Transport}}

{{DEFAULTSORT:Traffic Flow}}
[[Category:Road transport]]
[[Category:Mathematical physics]]
[[Category:Conservation equations]]
[[Category:Road traffic management]]
[[Category:Traffic flow]]</text>
      <sha1>8e5s22frv6xopg47kmpcs0j0t3k30kj</sha1>
    </revision>
  </page>
  <page>
    <title>Value at risk</title>
    <ns>0</ns>
    <id>148633</id>
    <revision>
      <id>871787467</id>
      <parentid>871787427</parentid>
      <timestamp>2018-12-03T12:35:19Z</timestamp>
      <contributor>
        <ip>169.202.235.2</ip>
      </contributor>
      <comment>/* Backtesting */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41941">{{Distinguish|Valuation risk}}
[[File:VaR diagram.JPG|thumb|300px|The 5% Value at Risk of a hypothetical profit-and-loss probability density function]]

'''Value at risk''' ('''VaR''') is a measure of the risk of loss for investments. It estimates how much a set of investments might lose (with a given probability), given normal market conditions, in a set time period such as a day. VaR is typically used by firms and regulators in the financial industry to gauge the amount of assets needed to cover possible losses.

For a given portfolio, time horizon, and [[probability]] ''p'', the ''p'' VaR can be defined informally as the maximum possible loss during the time if we exclude worse outcomes whose probability is less than ''p''. This assumes [[Mark to market accounting|mark-to-market]] pricing, and no trading in the portfolio.&lt;ref name="Jorion"&gt;{{cite book|last=Jorion|first=Philippe|title=Value at Risk: The New Benchmark for Managing Financial Risk|edition=3rd|publisher=McGraw-Hill|year=2006|isbn=978-0-07-146495-6}}&lt;/ref&gt;

For example, if a portfolio of stocks has a one-day 5% VaR of $1 million, that means that there is a 0.05 probability that the portfolio will fall in value by more than $1 million over a one-day period if there is no trading. Informally, a loss of $1 million or more on this portfolio is expected on 1 day out of 20 days (because of 5% probability). A loss which exceeds the VaR threshold is termed a "VaR breach".&lt;ref name="Holton"&gt;Holton, Glyn A. (2014). ''[http://value-at-risk.net Value-at-Risk: Theory and Practice]'' second edition, e-book.&lt;/ref&gt;

More formally, ''p'' VaR is defined such that the probability of a loss greater than VaR is less than or equal to ''p'' while the probability of a loss less than VaR is less than or equal to 1−''p''. For instance, assume someone makes a bet that flipping a coin seven times will not give seven heads. The terms are that he gains $100 if it doesn't happen (with probability 127/128) but loses $12,700 if it does (with probability 1/128). The 1% VaR is then -100, because the probability that he loses more than that is less than 1% while the probability that he loses less than zero (which is impossible) is less than 99%.&lt;ref name="Einhorn II"/&gt;

VaR has four main uses in [[finance]]: [[risk management]], financial [[Comptroller|control]], [[Financial statements|financial reporting]] and computing [[capital requirement|regulatory capital]]. VaR is sometimes used in non-financial applications as well.&lt;ref name="McNeil"&gt;{{cite book|first1=Alexander|last1=McNeil|first2=Rüdiger|last2=Frey|first3=Paul|last3=Embrechts|title=Quantitative Risk Management: Concepts Techniques and Tools|publisher=Princeton University Press|year=2005|isbn=978-0-691-12255-7}}&lt;/ref&gt;

Important related ideas are [[economic capital]], [[backtesting]], [[stress test (financial)|stress testing]], [[expected shortfall]], and [[tail conditional expectation]].&lt;ref name="Dowd"&gt;{{cite book|last=Dowd|first=Kevin|title=Measuring Market Risk|year=2005|publisher=John Wiley &amp; Sons|isbn=978-0-470-01303-8}}&lt;/ref&gt;

== Details ==

Common parameters for VaR are 1% and 5% probabilities and one day and two week horizons, although other combinations are in use.&lt;ref name="Pearson"&gt;{{cite book|first=Neil|last=Pearson|title=Risk Budgeting: Portfolio Problem Solving with Value-at-Risk|publisher=John Wiley &amp; Sons|year=2002|isbn=978-0-471-40556-6}}&lt;/ref&gt;

The reason for assuming normal markets and no trading, and to restricting loss to things measured in [[financial statements|daily accounts]], is to make the loss [[Observability|observable]]. In some extreme financial events it can be impossible to determine losses, either because market prices are unavailable or because the loss-bearing institution breaks up. Some longer-term consequences of disasters, such as lawsuits, loss of market confidence and employee morale and impairment of brand names can take a long time to play out, and may be hard to allocate among specific prior decisions. VaR marks the boundary between normal days and extreme events. Institutions can lose far more than the VaR amount; all that can be said is that they will not do so very often.&lt;ref name="Unbearable" /&gt;

The probability level is about equally often specified as one minus the probability of a VaR break, so that the VaR in the example above would be called a one-day 95% VaR instead of one-day 5% VaR. This generally does not lead to confusion because the probability of VaR breaks is almost always small, certainly less than 50%.&lt;ref name="Jorion" /&gt;

Although it virtually always represents a loss, VaR is conventionally reported as a positive number. A negative VaR would imply the portfolio has a high probability of making a profit, for example a one-day 5% VaR of negative $1 million implies the portfolio has a 95% chance of making more than $1 million over the next day.&lt;ref name="Crouhy"&gt;{{cite book|first1=Michel|last1=Crouhy|first2=Dan|last2=Galai|first3=Robert|last3=Mark|title=The Essentials of Risk Management|publisher=McGraw-Hill|year=2001|isbn=978-0-07-142966-5}}&lt;/ref&gt;

Another inconsistency is that VaR is sometimes taken to refer to profit-and-loss at the end of the period, and sometimes as the maximum loss at any point during the period. The original definition was the latter, but in the early 1990s when VaR was aggregated across trading desks and time zones, end-of-day valuation was the only reliable number so the former became the ''de facto'' definition. As people began using multiday VaRs in the second half of the 1990s, they almost always estimated the distribution at the end of the period only. It is also easier theoretically to deal with a point-in-time estimate versus a maximum over an interval. Therefore, the end-of-period definition is the most common both in theory and practice today.&lt;ref name="Lopez"&gt;{{cite journal|author=Jose A. Lopez|title=Regulatory Evaluation of Value-at-Risk Models|publisher=Wharton Financial Institutions Center Working Paper 96-51|date=September 1996}}&lt;/ref&gt;

== Varieties ==

The definition of VaR is [[Constructive proof|nonconstructive]]; it specifies a [[Property (philosophy)|property]] VaR must have, but not how to compute VaR. Moreover, there is wide scope for interpretation in the definition.&lt;ref name="Roundtable I"&gt;{{cite conference|first1=Joe|last1=Kolman|first2=Michael|last2=Onak|first3=Philippe|last3=Jorion|first4=Nassim|last4=Taleb|first5=Emanuel|last5=Derman|first6=Blu|last6=Putnam|first7=Richard|last7=Sandor|first8=Stan|last8=Jonas|first9=Ron|last9=Dembo|first10=George|last10=Holt|first11=Richard|last11=Tanenbaum|first12=William|last12=Margrabe|first13=Dan|last13=Mudge|first14=James|last14=Lam|first15=Jim|last15=Rozsypal|title=Roundtable: The Limits of VaR|publisher=Derivatives Strategy|date=April 1998}}&lt;/ref&gt; This has led to two broad types of VaR, one used primarily in [[risk management]] and the other primarily for risk measurement. The distinction is not sharp, however, and hybrid versions are typically used in financial [[Comptroller|control]], [[Financial statements|financial reporting]] and computing [[capital requirement|regulatory capital]].&lt;ref name="Brown"&gt;{{Citation|author=[[Aaron Brown (financial author)|Aaron Brown]]|title=The Next Ten VaR Disasters|publisher=Derivatives Strategy|date=March 1997}}&lt;/ref&gt;

To a risk manager, VaR is a system, not a number. The system is run periodically (usually daily) and the published number is compared to the computed price movement in opening positions over the time horizon. There is never any subsequent adjustment to the published VaR, and there is no distinction between VaR breaks caused by input errors (including [[Information Technology]] breakdowns, [[fraud]] and [[rogue trader|rogue trading]]), computation errors (including failure to produce a VaR on time) and market movements.&lt;ref name="Wilmott"&gt;{{cite book|first1=Paul|last1=Wilmott|author1-link=Paul Wilmott|title=Paul Wilmott Introduces Quantitative Finance|publisher=Wiley|year=2007|isbn=978-0-470-31958-1}}&lt;/ref&gt;

A [[Frequency probability|frequentist]] claim is made, that the long-term frequency of VaR breaks will equal the specified probability, within the limits of sampling error, and that the VaR breaks will be [[Statistical independence|independent]] in time and [[Statistical independence|independent]] of the level of VaR. This claim is validated by a [[backtesting|backtest]], a comparison of published VaRs to actual price movements. In this interpretation, many different systems could produce VaRs with equally good [[backtesting|backtests]], but wide disagreements on daily VaR values.&lt;ref name="Jorion" /&gt;

For risk measurement a number is needed, not a system. A [[Bayesian probability]] claim is made, that given the information and beliefs at the time, the [[Bayesian probability|subjective probability]] of a VaR break was the specified level. VaR is adjusted after the fact to correct errors in inputs and computation, but not to incorporate information unavailable at the time of computation.&lt;ref name="Crouhy" /&gt; In this context, "[[backtesting|backtest]]" has a different meaning. Rather than comparing published VaRs to actual market movements over the period of time the system has been in operation, VaR is retroactively computed on scrubbed data over as long a period as data are available and deemed relevant. The same position data and pricing models are used for computing the VaR as determining the price movements.&lt;ref name="Holton" /&gt;

Although some of the sources listed here treat only one kind of VaR as legitimate, most of the recent ones seem to agree that risk management VaR is superior for making short-term and tactical decisions today, while risk measurement VaR should be used for understanding the past, and making medium term and strategic decisions for the future. When VaR is used for [[Comptroller|financial control]] or [[Financial statements|financial reporting]] it should incorporate elements of both. For example, if a [[trader (finance)|trading desk]] is held to a VaR limit, that is both a risk-management rule for deciding what risks to allow today, and an input into the risk measurement computation of the [[trader (finance)|desk's]] risk-adjusted [[Return (finance)|return]] at the end of the reporting period.&lt;ref name="Dowd" /&gt;

=== In governance ===
VaR can also be applied to [[financial governance|governance]] of endowments, trusts, and pension plans. Essentially trustees adopt portfolio Values-at-Risk metrics for the entire pooled account and the diversified parts individually managed. Instead of probability estimates they simply define maximum levels of acceptable loss for each. Doing so provides an easy metric for oversight and adds accountability as managers are then directed to manage, but with the additional constraint to avoid losses within a defined risk parameter. VaR utilized in this manner adds relevance as well as an easy way to monitor risk measurement control far more intuitive than Standard Deviation of Return. Use of VaR in this context, as well as a worthwhile critique on board governance practices as it relates to investment management oversight in general can be found in ''Best Practices in Governance.''&lt;ref&gt;{{Citation|title=Best Practices in Governance|author=Lawrence York|year=2009}}&lt;/ref&gt;

== Mathematical definition ==

The VaR of &lt;math&gt;X&lt;/math&gt; at the confidence level &lt;math&gt;\alpha\in(0,1)&lt;/math&gt; is the smallest number &lt;math&gt;y&lt;/math&gt; such that the probability that &lt;math&gt;Y:=-X&lt;/math&gt; does not exceed &lt;math&gt;y&lt;/math&gt; is at least &lt;math&gt;1-\alpha&lt;/math&gt;. Mathematically, &lt;math&gt;\operatorname{VaR}_{\alpha}(X)&lt;/math&gt; is the &lt;math&gt;(1-\alpha)&lt;/math&gt;-[[quantile]] of &lt;math&gt;Y&lt;/math&gt;, i.e.,

:&lt;math&gt;\operatorname{VaR}_\alpha(X)=\inf\big\{x\in\mathbb{R}:F_X(x)&gt;\alpha\big\} = F^{-1}_Y(1-\alpha).&lt;/math&gt;&lt;ref&gt;{{cite journal|last=Artzner|first=Philippe|last2=Delbaen|first2=Freddy|last3=Eber|first3=Jean-Marc|last4=Heath|first4=David|year=1999|title=Coherent Measures of Risk|journal=Mathematical Finance|volume=9|issue=3|pages=203–228|url=http://www.math.ethz.ch/~delbaen/ftp/preprints/CoherentMF.pdf|format=pdf|accessdate=February 3, 2011|doi=10.1111/1467-9965.00068}}&lt;/ref&gt;&lt;ref&gt;{{cite book|first1=Hans|last1=Foellmer|first2=Alexander|last2=Schied|title=Stochastic Finance|publisher=[[Walter de Gruyter]]|year=2004|isbn=311-0183463|series=de Gruyter Series in Mathematics|volume=27|location=Berlin|pages=177–182|mr=2169807}}&lt;/ref&gt;

This is the most general definition of VaR and the two identities are equivalent (indeed, for any random variable &lt;math&gt;X&lt;/math&gt; its [[cumulative distribution function]] &lt;math&gt;F_X&lt;/math&gt; is well defined). 
However this formula cannot be used directly for calculations unless we assume that &lt;math&gt;X&lt;/math&gt; has some parametric distribution.

Risk managers typically assume that some fraction of the bad events will have undefined losses, either because markets are closed or illiquid, or because the entity bearing the loss breaks apart or loses the ability to compute accounts. Therefore, they do not accept results based on the assumption of a well-defined probability distribution.&lt;ref name="Unbearable"&gt;{{Citation|author=[[Aaron Brown (financial author)|Aaron Brown]]|title=The Unbearable Lightness of Cross-Market Risk|publisher=Wilmott Magazine|date=March 2004}}&lt;/ref&gt; [[Nassim Taleb]] has labeled this assumption, "charlatanism".&lt;ref name="Taleb II"&gt;{{Citation|author=Nassim Taleb|title=The World According to Nassim Taleb|publisher=Derivatives Strategy|date=December 1996 – January 1997|url=http://www.derivativesstrategy.com/magazine/archive/1997/1296qa.asp}}&lt;/ref&gt; On the other hand, many academics prefer to assume a well-defined distribution, albeit usually one with [[Kurtosis|fat tails]].&lt;ref name="Jorion" /&gt; This point has probably caused more contention among VaR theorists than any other.&lt;ref name="Roundtable I" /&gt;

Value of Risks can also be written as a [[distortion risk measure]] given by the [[distortion function]] &lt;math&gt;g(x) = \begin{cases}0 &amp; \text{if }0 \leq x &lt; 1-\alpha\\ 1 &amp; \text{if }1-\alpha \leq x \leq 1\end{cases}.&lt;/math&gt;&lt;ref name="Wirch"&gt;{{cite web|title=Distortion Risk Measures: Coherence and Stochastic Dominance|author=Julia L. Wirch|author2=Mary R. Hardy|url=http://pascal.iseg.utl.pt/~cemapre/ime2002/main_page/papers/JuliaWirch.pdf|format=pdf|accessdate=March 10, 2012}}&lt;/ref&gt;&lt;ref name="PropertiesDRM"&gt;{{Cite journal | last1 = Balbás | first1 = A. | last2 = Garrido | first2 = J. | last3 = Mayoral | first3 = S. | doi = 10.1007/s11009-008-9089-z | title = Properties of Distortion Risk Measures | journal = Methodology and Computing in Applied Probability | volume = 11 | issue = 3 | pages = 385 | year = 2008 | pmid =  | pmc = }}&lt;/ref&gt;

== Risk measure and risk metric ==

The term "VaR" is used both for a [[risk measure]] and a [[risk metric]]. This sometimes leads to confusion. Sources earlier than 1995 usually emphasize the risk measure, later sources are more likely to emphasize the metric.

The VaR risk measure defines risk as [[Mark to market accounting|mark-to-market]] loss on a fixed portfolio over a fixed time horizon. There are many alternative risk measures in finance. Given the inability to use mark-to-market (which uses market prices to define loss) for future performance, loss is often defined (as a substitute) as change in [[Intrinsic value (finance)|fundamental value]]. For example, if an institution holds a [[loan]] that declines in market price because [[interest]] rates go up, but has no change in cash flows or credit quality, some systems do not recognize a loss. Also some try to incorporate the [[Economics|economic]] cost of harm not measured in daily [[financial statements]], such as loss of market confidence or employee morale, impairment of brand names or lawsuits.&lt;ref name="Dowd" /&gt;

Rather than assuming a static portfolio over a fixed time horizon, some risk measures incorporate the dynamic effect of expected trading (such as a [[Order (exchange)|stop loss order]]) and consider the expected holding period of positions.&lt;ref name="Dowd" /&gt;

The VaR risk metric summarizes the [[Probability distribution|distribution]] of possible losses by a [[Quantile function|quantile]], a point with a specified probability of greater losses. A common alternative metrics is [[expected shortfall]].&lt;ref name="Jorion" /&gt;

== VaR risk management ==

Supporters of VaR-based risk management claim the first and possibly greatest benefit of VaR is the improvement in [[systems]] and modeling it forces on an institution. In 1997, [[Philippe Jorion]] [http://www.derivativesstrategy.com/magazine/archive/1997/0497fea2.asp wrote]:&lt;ref name="Jorion I"&gt;{{cite conference|first1=Philippe|last1=Jorion|title=The Jorion-Taleb Debate|publisher=Derivatives Strategy|date=April 1997}}&lt;/ref&gt;&lt;blockquote&gt;[T]he greatest benefit of VAR lies in the imposition of a structured methodology for critically thinking about risk. Institutions that go through the process of computing their VAR are forced to confront their exposure to financial risks and to set up a proper risk management function. Thus the process of getting to VAR may be as important as the number itself.&lt;/blockquote&gt;

Publishing a daily number, on-time and with specified [[Statistics|statistical]] properties holds every part of a trading organization to a high objective standard. Robust backup systems and default assumptions must be implemented. Positions that are reported, modeled or priced incorrectly stand out, as do data feeds that are inaccurate or late and systems that are too-frequently down. Anything that affects profit and loss that is left out of other reports will show up either in inflated VaR or excessive VaR breaks. "A risk-taking institution that ''does not'' compute VaR might escape disaster, but an institution that ''cannot'' compute VaR will not."&lt;ref name="Einhorn I"&gt;{{cite journal|author=[[Aaron Brown (financial author)|Aaron Brown]]|title=Private Profits and Socialized Risk|journal=GARP Risk Review|date=June–July 2008}}&lt;/ref&gt;

The second claimed benefit of VaR is that it separates risk into two [[regime]]s. Inside the VaR limit, conventional [[statistical]] methods are reliable. Relatively short-term and specific data can be used for analysis. Probability estimates are meaningful, because there are enough data to test them. In a sense, there is no true risk because you have a sum of many [[Statistical independence|independent]] observations with a left bound on the outcome. A casino doesn't worry about whether red or black will come up on the next roulette spin. Risk managers encourage productive risk-taking in this regime, because there is little true cost. People tend to worry too much about these risks, because they happen frequently, and not enough about what might happen on the worst days.&lt;ref name="Haug" /&gt;

Outside the VaR limit, all bets are off. Risk should be analyzed with [[stress testing]] based on long-term and broad market data.&lt;ref name="Zask"&gt;{{Citation|author=Ezra Zask|title=Taking the Stress Out of Stress Testing|publisher=Derivative Strategy|date=February 1999}}&lt;/ref&gt;  Probability statements are no longer meaningful.&lt;ref name="Roundtable II"&gt;{{cite journal|first1=Joe|last1=Kolman|first2=Michael|last2=Onak|first3=Philippe|last3=Jorion|first4=Nassim|last4=Taleb|first5=Emanuel|last5=Derman|first6=Blu|last6=Putnam|first7=Richard|last7=Sandor|first8=Stan|last8=Jonas|first9=Ron|last9=Dembo|first10=George|last10=Holt|first11=Richard|last11=Tanenbaum|first12=William|last12=Margrabe|first13=Dan|last13=Mudge|first14=James|last14=Lam|first15=Jim|last15=Rozsypal|title=Roundtable: The Limits of Models|journal=Derivatives Strategy|date=April 1998}}&lt;/ref&gt;  Knowing the distribution of losses beyond the VaR point is both impossible and useless. The risk manager should concentrate instead on making sure good plans are in place to limit the loss if possible, and to survive the loss if not.&lt;ref name="Jorion" /&gt;

One specific system uses three regimes.&lt;ref name="Size"&gt;{{cite journal|author=[[Aaron Brown (financial author)|Aaron Brown]]|title=On Stressing the Right Size|journal=GARP Risk Review|date=December 2007}}&lt;/ref&gt;

# One to three times VaR are normal occurrences. You expect periodic VaR breaks. The loss distribution typically has [[Kurtosis|fat tails]], and you might get more than one break in a short period of time. Moreover, markets may be abnormal and trading may exacerbate losses, and you may take losses not measured in daily [[financial statements|marks]] such as lawsuits, loss of employee morale and market confidence and impairment of brand names. So an institution that can't deal with three times VaR losses as routine events probably won't survive long enough to put a VaR system in place.
# Three to ten times VaR is the range for [[stress testing]]. Institutions should be confident they have examined all the foreseeable events that will cause losses in this range, and are prepared to survive them. These events are too rare to estimate probabilities reliably, so risk/return calculations are useless.
# Foreseeable events should not cause losses beyond ten times VaR. If they do they should be [[Hedge (finance)|hedged]] or insured, or the business plan should be changed to avoid them, or VaR should be increased. It's hard to run a business if foreseeable losses are orders of magnitude larger than very large everyday losses. It's hard to plan for these events, because they are out of scale with daily experience. Of course there will be unforeseeable losses more than ten times VaR, but it's pointless to anticipate them, you can't know much about them and it results in needless worrying. Better to hope that the discipline of preparing for all foreseeable three-to-ten times VaR losses will improve chances for surviving the unforeseen and larger losses that inevitably occur.

"A risk manager has two jobs: make people take more risk the 99% of the time it is safe to do so, and survive the other 1% of the time. VaR is the border."&lt;ref name="Einhorn I" /&gt;

Another reason VaR is useful as a metric is due to its ability to compress the riskiness of a portfolio to a single number, making it comparable across different portfolios (of different assets). Within any portfolio it is also possible to isolate specific position that might better hedge the portfolio to reduce, and minimise, the VaR. An example of market-maker employed strategies for trading linear interest rate derivatives and interest rate swaps portfolios is cited.&lt;ref name=PHIRS&gt;[http://www.tradinginterestrates.com The Pricing and Hedging of Interest Rate Derivatives: A Practical Guide to Swaps], J H M Darbyshire, 2016, {{ISBN|978-0995455511}}&lt;/ref&gt;

== Computation methods ==

VaR can be estimated either parametrically (for example, [[variance]]-[[covariance]] VaR or [[Greeks (finance)#Delta|delta]]-[[Greeks (finance)#Gamma|gamma]] VaR) or nonparametrically (for examples, historical [[simulation]] VaR or [[Resampling (statistics)|resampled]] VaR).&lt;ref name="Dowd" /&gt;&lt;ref name="Unbearable" /&gt; Nonparametric methods of VaR estimation are discussed in Markovich &lt;ref name="Markovich"&gt;{{Citation|last=Markovich|first=N.|title=Nonparametric analysis of univariate heavy-tailed data|publisher=Wiley|year=2007}}&lt;/ref&gt; and Novak.&lt;ref name="Novak"&gt;{{cite book|last=Novak|first=S.Y.|title=Extreme value methods with applications to finance|publisher=Chapman &amp; Hall/CRC Press|year=2011|isbn=978-1-4398-3574-6}}&lt;/ref&gt; A comparison of a number of strategies for VaR prediction is given in Kuester et al.&lt;ref&gt;{{cite journal|last=Kuester|first=Keith|last2=Mittnik|first2=Stefan|last3=Paolella|first3=Marc |author2-link=Stefan Mittnik |title=Value-at-Risk Prediction: A Comparison of Alternative Strategies |journal=Journal of Financial Econometrics |year=2006 |volume=4 |pages=53–89 |doi=10.1093/jjfinec/nbj002}}&lt;/ref&gt;

A McKinsey report&lt;ref name="McKinsey"&gt;{{cite web|title=McKinsey Working Papers on Risk, Number 32|author=McKinsey &amp; Company|url=http://www.mckinsey.com/~/media/McKinsey/dotcom/client_service/Risk/Working%20papers/Working_Papers_on_Risk_32.ashx|format=pdf}}&lt;/ref&gt; published in May 2012 estimated that 85% of large banks were using [[historical simulation (finance)|historical simulation]]. The other 15% used [[Monte Carlo methods in finance|Monte Carlo methods]].

== Backtesting ==
A key advantage to VaR over most other measures of risk such as [[expected shortfall]] is the availability several backtesting procedures for validating a set of VaR forecasts. Early examples of backtests can be found in Christoffersen (1998),&lt;ref&gt;{{Cite journal|last=Christoffersen|first=Peter|date=1998|title=Evaluating interval forecasts|url=|journal=International Economic Review|volume=39|pages=841–62|via=}}&lt;/ref&gt; later generalized by Pajhede (2017),&lt;ref name="Pajhede 2017 597–613"&gt;{{Cite journal|last=Pajhede|first=Thor|date=2017|title=Backtesting Value-at-Risk: A Generalized Markov Framework|url=https://poseidon01.ssrn.com/delivery.php?ID=743026093126097113080092123125124066037017048084024017014107075023102020031076102024041053042031049004119124091109095066083031111041044041067010097001066114108022002006052110086104075075017104068112081094116072094091102090000094072124002013089021065&amp;EXT=pdf|journal=Journal of Forecasting|volume= 36|pages=597–613|via=}}&lt;/ref&gt; which models a "hit-sequence" of losses greater than the VaR and proceed to tests for these "hit's" to be independent from one another and with a correct probability of occurring. E.g. a 5% probability of a loss greater than VaR should be observed over time when using a 95% VaR, these hits should occur independently.

A number of other backtests are available which model the time between hits in the hit-sequence, see Christoffersen (2014),&lt;ref&gt;{{Cite journal|last=Christoffersen|first=Peter|date=2014|title=Backtesting Value-at-Risk: A Duration-Based Approach|url=|journal=Journal of Financial Econometrics|volume=|pages=|via=}}&lt;/ref&gt; Haas (2016),&lt;ref&gt;{{Cite journal|last=Haas|first=M.|date=2006|title=Improved duration-based backtesting of value-at-risk|url=|journal=Journal of Risk|volume=8|pages=|via=}}&lt;/ref&gt; Tokpavi et al. (2014).&lt;ref&gt;{{Cite journal|last=Tokpavi|first=S.|date=|title=Backtesting Value-at-Risk: A GMM Duration-Based Test|url=|journal=Journal of Financial Econometrics|volume=|pages=|via=}}&lt;/ref&gt; and Pajhede (2017)&lt;ref name="Pajhede 2017 597–613"/&gt; As pointed out in several of the papers, the asymptotic distribution is often poor when considering high levels of coverage, e.g. a 99% VaR, therefore the parametric bootstrap method of Dufour (2006)&lt;ref&gt;{{Cite journal|last=Dufour|first=J-M|date=2006|title=Monte carlo tests with nuisance parameters: A general approach to finite-sample inference and nonstandard asymptotics|url=|journal=Journal of Econometrics|volume=|pages=|via=}}&lt;/ref&gt; is often used to obtain correct size properties for the tests. Backtest toolboxes are available in Matlab [http://www.econ.ku.dk/pajhede/BackTestToolbox%20v1.0.zip], or [https://cran.r-project.org/web/packages/backtest/backtest.pdf R]—though only the first implements the parametric bootstrap method.

== History ==

The problem of risk measurement is an old one in [[statistics]], [[economics]] and [[finance]]. Financial risk management has been a concern of regulators and financial executives for a long time as well. Retrospective analysis has found some VaR-like concepts in this history. But VaR did not emerge as a distinct concept until the late 1980s. The triggering event was the stock market [[Black Monday (1987)|crash of 1987]]. This was the first major financial crisis in which a lot of academically-trained [[Quantitative analyst|quants]] were in high enough positions to worry about firm-wide survival.&lt;ref name="Jorion" /&gt;

The crash was so unlikely given standard [[statistical]] models, that it called the entire basis of [[Quantitative analyst|quant]] finance into question. A reconsideration of history led some quants to decide there were recurring crises, about one or two per decade, that overwhelmed the statistical assumptions embedded in models used for [[Trader (finance)|trading]], [[investment management]] and [[Derivative (finance)|derivative]] pricing. These affected many markets at once, including ones that were usually not [[Financial correlation|correlated]], and seldom had discernible economic cause or warning (although after-the-fact explanations were plentiful).&lt;ref name="Roundtable II" /&gt; Much later, they were named "[[Black Swan theory|Black Swans]]" by [[Nassim Nicholas Taleb|Nassim Taleb]] and the concept extended far beyond [[finance]].&lt;ref name="Black Swan"&gt;{{cite book | author=Taleb, Nassim Nicholas | title=[[The Black Swan: The Impact of the Highly Improbable]] | publisher=[[Random House]] | location=New York | year=2007 | isbn=978-1-4000-6351-2}}&lt;/ref&gt;

If these events were included in [[quantitative analysis (finance)|quantitative analysis]] they dominated results and led to strategies that did not work day to day. If these events were excluded, the profits made in between "Black Swans" could be much smaller than the losses suffered in the crisis. Institutions could fail as a result.&lt;ref name="Einhorn I" /&gt;&lt;ref name="Roundtable II" /&gt;&lt;ref name="Black Swan" /&gt;

VaR was developed as a systematic way to segregate extreme events, which are studied qualitatively over long-term history and broad market events, from everyday price movements, which are studied quantitatively using short-term data in specific markets. It was hoped that "Black Swans" would be preceded by increases in estimated VaR or increased frequency of VaR breaks, in at least some markets. The extent to which this has proven to be true is controversial.&lt;ref name="Roundtable II" /&gt;

Abnormal markets and trading were excluded from the VaR estimate in order to make it observable.&lt;ref name="Haug"&gt;{{cite book|author=Espen Haug|title=Derivative Models on Models|publisher=John Wiley &amp; Sons|year=2007|isbn=978-0-470-01322-9}}&lt;/ref&gt; It is not always possible to define loss if, for example, markets are closed as after [[September 11 attacks|9/11]], or severely illiquid, as happened several times in 2008.&lt;ref name="Einhorn I" /&gt; Losses can also be hard to define if the risk-bearing institution fails or breaks up.&lt;ref name="Haug" /&gt; A measure that depends on traders taking certain actions, and avoiding other actions, can lead to [[self reference]].&lt;ref name="Jorion" /&gt;

This is risk management VaR. It was well established in [[Quantitative analyst|quantitative trading]] groups at several financial institutions, notably [[Bankers Trust]], before 1990, although neither the name nor the definition had been standardized. There was no effort to aggregate VaRs across trading desks.&lt;ref name="Roundtable II" /&gt;

The financial events of the early 1990s found many firms in trouble because the same underlying bet had been made at many places in the firm, in non-obvious ways. Since many trading desks already computed risk management VaR, and it was the only common risk measure that could be both defined for all businesses and aggregated without strong assumptions, it was the natural choice for reporting firmwide risk. [[JPMorgan Chase|J. P. Morgan]] CEO [[Dennis Weatherstone]] famously called for a "4:15 report" that combined all firm [[risk]] on one page, available within 15 minutes of the market close.&lt;ref name="Roundtable I" /&gt;

Risk measurement VaR was developed for this purpose. Development was most extensive at [[JPMorgan Chase|J. P. Morgan]], which published the methodology and gave free access to estimates of the necessary underlying parameters in 1994. This was the first time VaR had been exposed beyond a relatively small group of [[Quantitative analyst|quants]]. Two years later, the methodology was spun off into an independent for-profit business now part of RiskMetrics Group (now part of [[MSCI]]).&lt;ref name="Roundtable I" /&gt;

In 1997, the [[U.S. Securities and Exchange Commission]] ruled that public corporations must disclose quantitative information about their [[Derivative (finance)|derivatives]] activity. Major [[bank]]s and dealers chose to implement the rule by including VaR information in the notes to their [[financial statements]].&lt;ref name="Jorion" /&gt;

Worldwide adoption of the [[Basel II Accord]], beginning in 1999 and nearing completion today, gave further impetus to the use of VaR. VaR is the preferred [[Measure (mathematics)|measure]] of [[market risk]], and concepts similar to VaR are used in other parts of the accord.&lt;ref name="Jorion" /&gt;

== Criticism ==

VaR has been controversial since it moved from trading desks into the public eye in 1994. A famous 1997 [http://www.derivativesstrategy.com/magazine/archive/1997/0497fea2.asp debate] between [[Nassim Nicholas Taleb|Nassim Taleb]] and Philippe Jorion set out some of the major points of contention. Taleb claimed VaR:&lt;ref name="Taleb Criticism"&gt;{{Citation|author=Nassim Taleb|title=The Jorion-Taleb Debate|publisher=Derivatives Strategy|date=April 1997}}&lt;/ref&gt;

# Ignored 2,500 years of experience in favor of untested models built by non-traders
# Was charlatanism because it claimed to estimate the risks of rare events, which is impossible
# Gave false confidence
# Would be exploited by traders

In 2008 [[David Einhorn (hedge fund manager)|David Einhorn]] and [[Aaron Brown (financial author)|Aaron Brown]] debated VaR in [https://web.archive.org/web/20110226150454/http://www.garpdigitallibrary.org/download/GRR/2012.pdf Global Association of Risk Professionals Review]&lt;ref name="Einhorn I" /&gt;&lt;ref name="Einhorn II"&gt;{{Citation|author=David Einhorn|url=https://www.tilsonfunds.com/Einhorn-4-08.pdf|archiveurl=https://web.archive.org/web/20160426114310/http://www.tilsonfunds.com/Einhorn-4-08.pdf|archivedate=April 26, 2016|deadurl=no|title=Private Profits and Socialized Risk|publisher=GARP Risk Review|date=June–July 2008}}&lt;/ref&gt; Einhorn compared VaR to "an airbag that works all the time, except when you have a car accident". He further charged that VaR:

# Led to excessive risk-taking and leverage at financial institutions
# Focused on the manageable risks near the center of the distribution and ignored the tails
# Created an incentive to take "excessive but remote risks"
# Was "potentially catastrophic when its use creates a false sense of security among senior executives and watchdogs."

[[The New York Times|New York Times]] reporter [[Joseph Nocera|Joe Nocera]] wrote an extensive piece [https://www.nytimes.com/2009/01/04/magazine/04risk-t.html?pagewanted=1&amp;_r=1 Risk Mismanagement]&lt;ref name="Nocera"&gt;{{Citation|author=[[Joe Nocera]]|title=Risk Mismanagement|publisher=[[The New York Times]] Magazine|date=January 4, 2009}}&lt;/ref&gt; on January 4, 2009 discussing the role VaR played in the [[Financial crisis of 2007-2008]]. After interviewing risk managers (including several of the ones cited above) the article suggests that VaR was very useful to risk experts, but nevertheless exacerbated the crisis by giving false security to bank executives and regulators. A powerful tool for professional risk managers, VaR is portrayed as both easy to misunderstand, and dangerous when misunderstood.

Taleb in 2009 testified in Congress asking for the banning of VaR for a number of reasons. One was that tail risks are non-measurable. Another was that for [[anchoring]] reasons VaR leads to higher risk taking.&lt;ref&gt;{{cite web|last1=Nassim Taleb|title=Report on The Risks of Financia l Modeling, VaR and the Economic Breakdown|url=http://gop.science.house.gov/Media/hearings/oversight09/sept10/taleb.pdf|publisher=U.S. House of Representatives|archiveurl=https://web.archive.org/web/20091104013038/http://gop.science.house.gov/Media/hearings/oversight09/sept10/taleb.pdf|archivedate=November 4, 2009|date=Sep 10, 2009}}&lt;/ref&gt;

VaR is not [[Subadditivity|subadditive]]:&lt;ref name="Dowd" /&gt; VaR of a combined portfolio can be larger than the sum of the VaRs of its components.

For example, the average bank branch in the United States is robbed about once every ten years. A single-branch bank has about 0.0004% chance of being robbed on a specific day, so the risk of robbery would not figure into one-day 1% VaR. It would not even be within an order of magnitude of that, so it is in the range where the institution should not worry about it, it should insure against it and take advice from insurers on precautions. The whole point of insurance is to aggregate risks that are beyond individual VaR limits, and bring them into a large enough portfolio to get statistical predictability. It does not pay for a one-branch bank to have a security expert on staff.

As institutions get more branches, the risk of a robbery on a specific day rises to within an order of magnitude of VaR. At that point it makes sense for the institution to run internal stress tests and analyze the risk itself. It will spend less on insurance and more on in-house expertise. For a very large banking institution, robberies are a routine daily occurrence. Losses are part of the daily VaR calculation, and tracked statistically rather than case-by-case. A sizable in-house security department is in charge of prevention and control, the general risk manager just tracks the loss like any other cost of doing business.
As portfolios or institutions get larger, specific risks change from low-probability/low-predictability/high-impact to statistically predictable losses of low individual impact. That means they move from the range of far outside VaR, to be insured, to near outside VaR, to be analyzed case-by-case, to inside VaR, to be treated statistically.&lt;ref name="Einhorn I" /&gt;

VaR is a static measure of risk. By definition, VaR is a particular characteristic of the probability distribution of the underlying (namely, VaR is essentially a quantile). For a dynamic measure of risk, see Novak,&lt;ref name="Novak"/&gt; ch. 10.

There are common abuses of VaR:&lt;ref name="Unbearable" /&gt;&lt;ref name="Roundtable I" /&gt;

# Assuming that plausible losses will be less than some multiple (often three) of VaR. Losses can be extremely large. 
# Reporting a VaR that has not passed a [[backtesting|backtest]]. Regardless of how VaR is computed, it should have produced the correct number of breaks (within [[sampling error]]) in the past. A common violation of common sense is to estimate a VaR based on the unverified assumption that everything follows a [[multivariate normal distribution]].

===VaR, CVaR and EVaR===

The VaR is not a [[coherent risk measure]] since it violates the sub-additivity property, which is

&lt;math&gt;\mathrm{If}\; X,Y \in \mathbf{L} ,\; \mathrm{then}\; \rho(X + Y) \leq \rho(X) + \rho(Y).&lt;/math&gt;

However, it can be bounded by coherent risk measures like [[Conditional Value-at-Risk]] (CVaR) or [[entropic value at risk]] (EVaR). In fact, for &lt;math&gt; X\in \mathbf{L}_{M^+} &lt;/math&gt; (with &lt;math&gt;\mathbf{L}_{M^+} &lt;/math&gt; the set of all [[Borel measure|Borel]] [[measurable function]]s whose [[moment-generating function]] exists for all positive real values) we have

&lt;math&gt;\text{VaR}_{1-\alpha}(X)\leq\text{CVaR}_{1-\alpha}(X)\leq\text{EVaR}_{1-\alpha}(X),&lt;/math&gt;

where

&lt;math&gt;
\begin{align}
&amp;\text{VaR}_{1-\alpha}(X):=\inf_{t\in\mathbf{R}}\{t:\text{Pr}(X\leq t)\geq 1-\alpha\},\\
&amp;\text{CVaR}_{1-\alpha}(X) := \frac{1}{\alpha}\int_0^{\alpha} \text{VaR}_{1-\gamma}(X)d\gamma,\\
&amp;\text{EVaR}_{1-\alpha}(X):=\inf_{z&gt;0}\{z^{-1}\ln(M_X(z)/\alpha)\},
\end{align}
&lt;/math&gt;

in which &lt;math&gt; M_X(z) &lt;/math&gt; is the moment-generating function of &lt;math&gt; X &lt;/math&gt; at &lt;math&gt; z &lt;/math&gt;.  In the above equations the variable &lt;math&gt;X&lt;/math&gt; denotes the financial loss, rather than wealth as is typically the case.

== See also ==
* [[Capital Adequacy Directive]]
* [[Conditional value-at-risk]]
* [[Cyber risk quantification|Cyber risk quantification based on cyber value-at-risk or CyVaR]]
* [[Extended Mathematical Programming (EMP)#EMP for stochastic programming|EMP for stochastic programming]]— solution technology for optimization problems involving VaR and CVaR
* [[Entropic value at risk]]
* [[Profit at risk]]
* [[Margin at risk]]
* [[Liquidity at risk]]
* [[Risk return ratio]]
* [[Valuation risk]]

== References ==
&lt;!--This section uses the Cite.php citation mechanism. If you would like more information on how to add references to this article, please see http://meta.wikimedia.org/wiki/Cite/Cite.php --&gt;
{{reflist|30em}}

== External links ==
;Discussion
* [http://spauldinggrp.com/value-risk/ "Value At Risk"], [[Ben Sopranzetti]], Ph.D., CPA
* [http://www.wilmott.com/blogs/satyajitdas/enclosures/perfectstorms%28may2007%291.pdf "Perfect Storms" – Beautiful &amp; True Lies In Risk Management], [[Satyajit Das]]
* [https://web.archive.org/web/20080914192413/http://www.gloriamundi.org/ "Gloria Mundi" – All About Value at Risk], Barry Schachter
* [https://www.nytimes.com/2009/01/04/magazine/04risk-t.html?dlbk=&amp;pagewanted=all Risk Mismanagement], [[Joe Nocera]] [[NY Times]] article.
* [http://www.savvysoft.com/registerpagevarnothard.htm "VaR Doesn't Have To Be Hard"], Rich Tanenbaum
;Tools
* [http://tradinginterestrates.com "The Pricing and Trading of Interest Rate Derivatives"], [[J H M Darbyshire]], MSc.
* [https://web.archive.org/web/20071015050012/http://cba.ua.edu/~rpascala/VaR/VaRForm.php Online real-time VaR calculator], Razvan Pascalau, [[University of Alabama]]
* [http://simonbenninga.com/wiener/MiER74.pdf Value-at-Risk (VaR)], Simon Benninga and Zvi Wiener. (Mathematica in Education and Research Vol. 7 No. 4 1998.)
* [http://www.derivativesstrategy.com/magazine/archive/1998/0298fea2.asp Derivatives Strategy Magazine. "Inside D. E. Shaw"] Trading and Risk Management 1998

{{Financial risk}}
{{Portal bar|Business and economics}}

[[Category:Actuarial science]]
[[Category:Financial risk modeling]]
[[Category:Market risk]]
[[Category:Monte Carlo methods in finance]]</text>
      <sha1>e7kevbb5hdqkw1pokthgce6r2moppqs</sha1>
    </revision>
  </page>
  <page>
    <title>Wald's martingale</title>
    <ns>0</ns>
    <id>38246823</id>
    <revision>
      <id>753388890</id>
      <parentid>746860531</parentid>
      <timestamp>2016-12-06T21:39:20Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Stochastic processes]]; added [[Category:Martingale theory]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1552">{{technical|date=March 2013}}
In [[probability theory]] '''Wald's martingale''', named after [[Abraham Wald]] and more commonly
known as the [[geometric Brownian motion]], is a [[stochastic process]] of the form

:: &lt;math&gt;\left\{\exp\left(\lambda W_t-\frac{1}{2}\lambda^2t\right),t\geq 0\right\}&lt;/math&gt;

for any [[real number|real value]] ''λ'' where ''W''&lt;sub&gt;''t''&lt;/sub&gt; is a [[Wiener process]].&lt;ref name="james"&gt;{{Cite book | first1 = P. J. | last1 = Hunt | first2 = J. E. | last2 = Kennedy| doi = 10.1002/0470863617.ch3 | chapter = Martingales | title = Financial Derivatives in Theory and Practice | series = Wiley Series in Probability and Statistics | pages = 31 | year = 2005 | isbn = 9780470863619 | pmid =  | pmc = }}&lt;/ref&gt;{{rp|32}}&lt;ref&gt;{{Cite book | last1 = Chang | first1 = F. R. | chapter = Boundaries and Absorbing Barriers | doi = 10.1017/CBO9780511616747.008 | title = Stochastic Optimization in Continuous Time | pages = 225 | year = 2004 | isbn = 9780511616747 | pmid =  | pmc = }}&lt;/ref&gt;{{rp|261}}&lt;ref&gt;{{Cite journal | doi = 10.1239/aap/1013540169 | last1 = Asmussen | first1 = S. R.| last2 = Kella | first2 = O. | title = A multi-dimensional martingale for Markov additive processes and its applications| journal = Adv. Appl. Probab.| volume = 32| issue = 2| year = 2000| pages = 376–393| jstor = 1428194| pmid =  | pmc = }}&lt;/ref&gt; The process is a [[martingale (probability theory)|martingale]].&lt;ref name="james" /&gt;

==See also==

*[[Wald's equation]]

==Notes==

{{Reflist}}

[[Category:Martingale theory]]


{{probability-stub}}</text>
      <sha1>hd8mw0v85vbgv33j1l1r2qt2rn7vje6</sha1>
    </revision>
  </page>
  <page>
    <title>Whitehead problem</title>
    <ns>0</ns>
    <id>212619</id>
    <revision>
      <id>837256056</id>
      <parentid>736965278</parentid>
      <timestamp>2018-04-19T17:43:42Z</timestamp>
      <contributor>
        <ip>176.139.89.213</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4908">{{Distinguish|Whitehead theorem}}

In [[group theory]], a branch of [[abstract algebra]], the '''Whitehead problem''' is the following question:

:Is every [[abelian group]] ''A'' with [[Ext functor|Ext]]&lt;sup&gt;1&lt;/sup&gt;(''A'', '''Z''') = 0 a [[free abelian group]]?

Shelah (1974) proved that Whitehead's problem is [[Independence (mathematical logic)|undecidable]] within standard [[ZFC]] set theory.

==Refinement==
The condition Ext&lt;sup&gt;1&lt;/sup&gt;(''A'', '''Z''') = 0 can be equivalently formulated as follows: whenever ''B'' is an abelian group and ''f'' : ''B'' → ''A'' is a [[surjective]] [[group homomorphism]] whose [[kernel (algebra)|kernel]] is [[isomorphic]] to the group of [[integer]]s '''Z''', then there exists a group [[homomorphism]] ''g'' : ''A'' → ''B'' with ''fg'' = [[identity function|id&lt;sub&gt;''A''&lt;/sub&gt;]]. Abelian groups ''A'' satisfying this condition are sometimes called '''Whitehead groups''', so Whitehead's problem asks: is every Whitehead group free?

''Caution'': The converse of Whitehead's problem, namely that every free abelian group is Whitehead, is a well known group-theoretical fact. Some authors call ''Whitehead group'' only a ''non-free'' group ''A'' satisfying Ext&lt;sup&gt;1&lt;/sup&gt;(''A'', '''Z''') = 0. Whitehead's problem then asks: do Whitehead groups exist?

==Shelah's proof==
{{harvs|txt=yes|authorlink=Saharon Shelah|first=Saharon|last=Shelah|year=1974}} showed that,  given the canonical [[ZFC]] axiom system, the problem is [[Independence (mathematical logic)|independent of the usual axioms of set theory]]. More precisely, he showed that:
* If every set is [[Axiom of constructibility|constructible]], then every Whitehead group is free;
* If [[Martin's axiom]] and the negation of the [[continuum hypothesis]] both hold, then there is a non-free Whitehead group.
Since the [[consistency]] of ZFC implies the consistency of both of the following:
*The [[axiom of constructibility]] (which asserts that all sets are constructible);
*[[Martin's axiom]] plus the negation of the [[continuum hypothesis]],
Whitehead's problem cannot be resolved in ZFC.

==Discussion==
[[J. H. C. Whitehead]], motivated by the [[second Cousin problem]], first posed the problem in the 1950s. {{harvtxt|Stein|1951}} answered the question in the affirmative for [[countable]] groups. Progress for larger groups was slow, and the problem was considered an important one in [[abstract algebra|algebra]] for some years.

Shelah's result was completely unexpected. While the existence of undecidable statements had been known since [[Gödel's incompleteness theorem]] of 1931, previous examples of undecidable statements (such as the [[continuum hypothesis]]) had all been in pure [[set theory]]. The Whitehead problem was the first purely algebraic problem to be proved undecidable.

{{harvs|txt=yes|authorlink=Saharon Shelah|last=Shelah|year1=1977|year2=1980}} later showed that the Whitehead problem remains undecidable even if one assumes the Continuum hypothesis. The Whitehead conjecture is true if all sets are [[constructible universe|constructible]]. That this and other statements about uncountable abelian groups are provably independent of [[ZFC]] shows that the theory of such groups is very sensitive to the assumed underlying [[set theory]].

==See also==
*[[Free abelian group]]
*[[Whitehead torsion]]
*[[List of statements undecidable in ZFC]]
*[[Statements true in L|Statements true if all sets are constructible]]

== References ==
*{{citation|first= Paul C. |last=Eklof|title=Whitehead's Problem is Undecidable|journal=The American Mathematical Monthly|volume= 83|issue= 10|year=1976|pages= 775–788
|doi= 10.2307/2318684|publisher= The American Mathematical Monthly, Vol. 83, No. 10|jstor=2318684}} An expository account of Shelah's proof.
*{{springer|id=W/w110030|title=Whitehead problem|author=Eklof, P.C.}}
*{{citation| first=S.|last=Shelah|title=Infinite Abelian groups, Whitehead problem and some constructions
|journal=Israel Journal of Mathematics |volume=18 |year=1974|pages=243–256|doi=10.1007/BF02757281| mr=0357114| issue=3}}
*{{citation|first=S.|last=Shelah|title=Whitehead groups may not be free, even assuming CH. I
|journal=Israel Journal of Mathematics |volume=28 |year=1977|pages=193–203|doi=10.1007/BF02759809|mr=0469757|issue=3}}
*{{citation|first=S.|last=Shelah|title=Whitehead groups may not be free, even assuming CH. II
|journal=Israel Journal of Mathematics |volume=35 |year=1980|pages=257–285|doi=10.1007/BF02760652|mr=0594332|issue=4}}
*{{citation
|last=Stein|first= Karl
|title=Analytische Funktionen mehrerer komplexer Veränderlichen zu vorgegebenen Periodizitätsmoduln und das zweite Cousinsche Problem|journal= Math. Ann.  |volume=123|year=1951|pages= 201–222
|doi=10.1007/BF02054949
|mr=0043219}}

{{DEFAULTSORT:Whitehead Problem}}
[[Category:Independence results]]
[[Category:Group theory]]
[[Category:Mathematical problems]]</text>
      <sha1>fb4mypzxzavt8t5za332dmlxblq291w</sha1>
    </revision>
  </page>
</mediawiki>
