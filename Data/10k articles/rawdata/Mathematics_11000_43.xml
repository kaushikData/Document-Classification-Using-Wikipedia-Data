<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Alain Chenciner</title>
    <ns>0</ns>
    <id>48254929</id>
    <revision>
      <id>857358121</id>
      <parentid>846298302</parentid>
      <timestamp>2018-08-31T05:15:12Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Removing from [[Category:French mathematicians]] using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4663">'''Alain Chenciner''' (23 October 1943, [[Villeneuve-sur-Lot]]) is a French mathematician, specializing in [[dynamical system]]s with applications to [[celestial mechanics]].

[[File:Chenciner alain.jpg|thumb|Alain Chenciner, Oberwolfach 2011]]
Chenciner studied from 1963 to 1965 at the [[École polytechnique]] and did research from 1966 for [[CNRS]] (Attachée de Recherche) at the École Polytechnique (at the Centre de Mathématiques founded by [[Laurent Schwartz]]). In 1971 he received his Ph.D. from the [[University of Paris XI]] under Jean Cerf with thesis ''Sur la géométrie des strates de petites codimensions de l'espace des fonctions différentiables réelles sur une variété''&lt;ref&gt;{{worldcat|oclc=489608553|name=Sur la géométrie des strates de petites codimensions de l'espace des fonctions différentiables réelles sur une variété}}&lt;/ref&gt; (Chenciner's thesis defense involved [[Henri Cartan]], Laurent Schwartz and [[René Thom]]). Chenciner became a ''[[maître de conférences]]'' at the University of Paris XI, then in 1973 at the [[University of Paris VII]], and in 1975 at the [[University of Nice]]. He returned in 1978 as ''maître de conférences'' to the University of Paris VII, where in 1981 he became professor extraordinarius (''professeur de première classe'') and in 1991 professor ordinarius (''professeur en classe exceptionelle''). In 2012 he became professor emeritus.

At the beginning of his career Chenciner worked on differential topology and its applications to dynamical systems, following the pioneering efforts of [[Stephen Smale]], and also worked on [[singularity theory]]. Later in his career he worked on mathematical problems of celestial mechanics (specifically, the [[three-body problem]]&lt;ref&gt;{{cite journal|author=Chenciner, Alain|author2=Montgomery, Richard|title=A remarkable periodic solution of the three-body problem in the case of equal masses|journal=Annals of Mathematics |series=Second Series|volume=152|issue=3|year=2000|pages=881–902|doi=10.2307/2661357|arxiv=math/0011268}}&lt;/ref&gt; and the [[n-body problem]]) and studied bifurcations at elliptical fixed points of dynamical systems.

Chenciner, with [[Jacques Laskar]], founded in 1992 the research group ''astronomie et systèmes dynamiques'' at the [[Observatory of Paris]]. In 2002 he was an [[invited speaker at the International Congress of Mathematicians]] in Beijing and gave a talk ''Action minimizing solutions of the Newtonian n-body problem: from homology to symmetry''. He became in 2012 a fellow of the [[American Mathematical Society]]. He gave a eulogy on 9 July 2012 at [[cimetière du Montparnasse]] to mark the centenary of the death of [[Henri Poincaré]].&lt;ref&gt;
{{cite web
 |url=http://www.poincare.fr/itineraire-d-un-savant-universel/sa-vie/88-eloge-de-poincare 
 |title=Éloge de Poincaré 
 |website=le site de l'[[Institut Henri-Poincaré]] 
 |deadurl=yes 
 |archiveurl=https://web.archive.org/web/20140112035652/http://www.poincare.fr/itineraire-d-un-savant-universel/sa-vie/88-eloge-de-poincare 
 |archivedate=2014-01-12 
 |df= 
}}&lt;/ref&gt;&lt;ref&gt;
{{cite web
 |url=http://www.atlantico.fr/decryptage/centenaire-mort-dhenri-poincare-lhomme-qui-tentait-delucider-chaos-jean-paul-truc-426437.html 
 |title=Henri Poincaré, ce mathématicien multicarte de génie dont la vision et les intuitions guident encore la recherche d’aujourd’hui
 |date=22 July 2012
 |website=le site [[Atlantico]]
}}&lt;/ref&gt;

Chenciner's doctoral students include [[Daniel Bennequin]].&lt;ref&gt;{{MathGenealogy|id=123961}}&lt;/ref&gt;

==Selected publications==
*as editor with Richard Cushman, Clark Robinson, and Zhihong Jeff Xia: Celestial Mechanics, dedicated to [[Donald Saari]] for his 60th birthday, Contemporary Mathematics, American Mathematical Society 2002&lt;ref&gt;{{cite web|url=http://www.ams.org/bookstore-getitem/item=CONM-292|title=Celestial Mechanics: Dedicated to Donald Saari for his 60th Birthday|website=American Mathematical Society}}&lt;/ref&gt;
*Courbes Algébriques Planes, Springer Verlag 2007
*[http://www.scholarpedia.org/article/Three_body_problem Three Body Problem, Scholarpedia]

==References==
{{reflist}}

==External links==
*[http://www.imcce.fr/Equipes/ASD/person/chenciner/ Alain Chenciner's Homepage]

{{Authority control}}

{{DEFAULTSORT:Chenciner, Alain}}
[[Category:1943 births]]
[[Category:Living people]]
[[Category:20th-century French mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:University of Paris alumni]]
[[Category:University of Paris faculty]]
[[Category:École Normale Supérieure alumni]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:People from Villeneuve-sur-Lot]]</text>
      <sha1>jmaq7ifl8h434843i6e1o7ck85m5hzv</sha1>
    </revision>
  </page>
  <page>
    <title>Altenberg Workshops in Theoretical Biology</title>
    <ns>0</ns>
    <id>21796451</id>
    <revision>
      <id>788692430</id>
      <parentid>715070943</parentid>
      <timestamp>2017-07-02T22:53:46Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4797">The '''Altenberg Workshops in Theoretical Biology''' are expert meetings focused on a key issue of [[biological theory]], hosted by the [[Konrad Lorenz Institute for Evolution and Cognition Research]] (KLI) since 1996. The workshops are organized by leading experts in their field, who invite a group of international top level [[scientists]] as participants for a 3-day working meeting in the [[Konrad Lorenz|Lorenz]] Mansion at Altenberg near [[Vienna]], [[Austria]]. By this procedure the KLI intends to generate new conceptual advances and research initiatives in the biosciences, which, due to their explicit interdisciplinary nature, are attractive to a wide variety of scientists from practically all fields of biology and the neighboring disciplines.

==Workshops and their topics==
*Cultural Niche Construction. Organized by Kevin Laland and Mike O´Brien. September 2011
*Strategic Interaction in Humans and Other Animals. Organized by Simon Huttegger and Brain Skyrms. September 2011
*The Meaning of "Theory" in Biology. Organized by Massimo Pigliucci, Kim Sterelny, and Werner Callebaut. June 2011
*Biological and Physical Constraints on the Evolution of Form in Plants and Animals. Organized by Jeffrey H. Schwartz and Bruno Maresca. September 2010
*Scaffolding in Evolution, Culture, and Cognition. Organized by Linnda Caporael, James Griesemer, and William Wimsatt. July 2010
*Models of Man for Evolutionary Economics. Organized by Werner Callebaut, Christophe Heintz, and Luigi Marengo. September 2009
*Human EvoDevo: The Role of Development in Human Evolution. Organized by Philipp Gunz and Philipp Mitteroecker. September 2009
*Origins of EvoDevo - A tribute to Pere Alberch. Organized by [[Gerd Müller (theoretical biologist)|Gerd B. Müller]] and Diego Rasskin-Gutman. September 2008
*Measuring Biology - Quantitative Methods: Past and Future. Organized by Fred L. Bookstein and Katrin Schäfer. September 2008
*Toward an Extended Evolutionary Synthesis Organized by [[Massimo Pigliucci]] and [[Gerd Müller (theoretical biologist)|Gerd B. Müller]]. July 2008
*Innovation in Cultural Systems - Contributions from Evolutionary Anthropology. Organized by Michael J. O´Brien and Stephen J. Shennan. September 2007
*The Major Transitions Revisited. Organized by Brett Calcott and [[Kim Sterelny]]. July 2007
*Comparative Philosophy of Technical Artifacts and Biological Organisms. Organized by Ulrich Krohs and Peter Kroes. September 2006
*The New Cognitive Sciences - Bringing Evolution and Development to Bear on Mind and Brain. Organized by Lynn Nadel, Mary Peterson, and Luca Tommasi. June 2006
*Arriving at a Theoretical Biology - The Waddington Centennial. Organized by Manfred Laubichler and Brian K. Hall. September 2005
*The Evolution of Communicative Creativity - From Fixed Signals to Contextual Flexibility. Organized by D. Kimbrough Oller and Ulrike Griebel. July 2005
*Analog Communication - Evolution, Brain Mechanisms, Dynamics, Simulation. Organized by Karl Grammer and Astrid Juette. September 2004
*Modeling Biology - Structures, Behavior, Evolution. Organized by Luciano da Fontoura Costa and [[Gerd Müller (theoretical biologist)|Gerd B. Müller]]. July 2004
*Viennese Roots of Theoretical Biology - The Vivarium Centenary. Organized by Manfred Laubichler, [[Gerd Müller (theoretical biologist)|Gerd B. Müller]], and Werner Callebaut. September 2002
*Biological Information Beyond Metaphor. Organized by Werner Callebaut. July 2002
*Evolution of Communication Systems. Organized by D. Kimbrough Oller and Ulrike Griebel. October 2001
*Environment, Development, and Evolution. Organized by Brian Hall, Roy Pearson, and [[Gerd Müller (theoretical biologist)|Gerd B. Müller]]. July 2001
*Modularity - Understanding the Development and Evolution of Complex Natural Systems. Organized by Werner Callebaut and Diego Rasskin-Guttman. October 2000
*Origins of Organismal Form - Beyond the Gene Paradigm Organized by [[Gerd Müller (theoretical biologist)|Gerd B. Müller]] and [[Stuart Newman]]. October 1999
*Evolution of Cognition. Organized by Cecilia Heyes, Ludwig Huber, and Adolf Heschl. August 1998
*Evolutionary Naturalism - Bioepistemology and the Challenge of Development and Sociality. Organized by Werner Callebaut and Karola Stotz. June 1997
*The Emergence and Evolution of Organization.  Organized by Walter Fontana, [[Gerd Müller (theoretical biologist)|Gerd B. Müller]] and [[Günter Wagner]]. September 1996

==External links==
*[http://kli.ac.at/events/altenberg-workshops Altenberg Workshops in Theoretical Biology]
*[https://web.archive.org/web/20100805213316/http://mitpress.mit.edu/catalog/browse/browse.asp?btype=6&amp;serid=102 Vienna Series in Theoretical Biology]

[[Category:Meetings]]
[[Category:Mathematical and theoretical biology]]</text>
      <sha1>35as8y82lhjj9d8hxwkgs8roqncee37</sha1>
    </revision>
  </page>
  <page>
    <title>Approximations of π</title>
    <ns>0</ns>
    <id>4416073</id>
    <revision>
      <id>871787541</id>
      <parentid>869377885</parentid>
      <timestamp>2018-12-03T12:36:36Z</timestamp>
      <contributor>
        <username>Narky Blert</username>
        <id>22041646</id>
      </contributor>
      <comment>Link to DAB page repaired</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="65524">{{hatnote|This page is about the history of approximations of {{pi}}; see also [[chronology of computation of π|chronology of computation of {{pi}}]] for a tabular summary. See also the [[History of pi|history of {{pi}}]] for other aspects of the evolution of our knowledge about mathematical properties of {{pi}}.}}
{{Use dmy dates|date=June 2014}}
{{DISPLAYTITLE:Approximations of {{pi}}}}
[[File:Record pi approximations.svg|380px|thumb|Graph showing the historical evolution of the record precision of numerical approximations to pi, measured in decimal places (depicted on a logarithmic scale; time before 1400 is not shown to scale).]]
{{Pi box}}
[[Approximation#Mathematics|Approximations]] for the [[mathematical constant]] [[pi]] ({{pi}}) in the [[history of mathematics]] reached an accuracy within 0.04% of the true value before the beginning of the [[Common Era]] ([[Archimedes]]). In [[Chinese mathematics]], this was improved to approximations correct to what corresponds to about seven decimal digits by the 5th century.

Further progress was not made until the 15th century ([[Jamshīd al-Kāshī]]). Early modern mathematicians reached an accuracy of 35 digits by the beginning of the 17th century ([[Ludolph van Ceulen]]), and 126 digits by the 19th century ([[Jurij Vega]]), surpassing the accuracy required for any conceivable application outside of pure mathematics.&lt;!--see point on planck scale vs. size of observable universe in article body--&gt;

The record of manual approximation of {{pi}} is held by [[William Shanks]], who calculated 527 digits correctly in the years preceding 1873. Since the middle of the 20th century, the approximation of {{pi}} has been the task of electronic digital computers; {{as of|November 2016|lc=y}}, the record is 22.4{{nbsp}}trillion digits.&lt;ref name="Yee2016"&gt;{{cite web|url=http://www.numberworld.org/y-cruncher/|title=y-cruncher: A Multi-Threaded Pi Program|first=Alexander J.|last=Yee|date=2016|access-date=28 March 2017}}&lt;/ref&gt; (For a comprehensive account, see [[chronology of computation of π|Chronology of computation of {{pi}}]].)

==Early history==
The best known approximations to {{pi}} dating to [[1st millennium BC|before the Common Era]] were accurate to two decimal places; this was improved upon in [[Chinese mathematics]] in particular by the mid-first millennium, to an accuracy of seven decimal places. After this, no further progress was made until the late medieval period.

Some Egyptologists&lt;ref&gt;{{cite book
 |author-last= Petrie |author-first= W.M.F. |title= Wisdom of the Egyptians |year=1940}}
&lt;/ref&gt;
have claimed that the [[ancient Egypt]]ians used an approximation of {{pi}} as {{frac|22|7}} from as early as the [[Old Kingdom]].&lt;ref&gt;{{cite book
 |author-first= Miroslav |author-last= Verner |author-link=Miroslav Verner
 |title= The Pyramids: The Mystery, Culture, and Science of Egypt's Great Monuments
 |year= 2001 |orig-year= 1997 |publisher= [[Grove Press]] |isbn= 0-8021-3935-3
 |quote= Based on the [[Great Pyramid of Giza]], supposedly built so that the circle whose radius is equal to the height of the pyramid has a circumference equal to the perimeter of the base (it is 1760 [[cubits]] around and 280 cubits in height).}}&lt;/ref&gt;
This claim has met with skepticism.&lt;ref name=Rossi&gt;{{cite book
 |author-first=  |author-last= Rossi
 |title= Corinna Architecture and Mathematics in Ancient Egypt
 |year= 2007 |orig-year= |publisher= [[Cambridge University Press]] |isbn= 978-0-521-69053-9
 |quote= }}&lt;/ref&gt;&lt;ref&gt;{{cite book
 |author-first= J. A. R. |author-last= Legon
 |title= On Pyramid Dimensions and Proportions
 |series= Discussions in Egyptology |volume= 20 |pages=25–34
 |year= 1991 |orig-year= |publisher=  |isbn= |url= http://www.legon.demon.co.uk/pyrprop/propde.htm }}&lt;/ref&gt;

[[Babylonian mathematics]] usually approximated {{pi}} to 3, sufficient for the architectural projects of the time (notably also reflected in the description of [[Solomon's Temple]] in the [[First Book of Kings|Hebrew Bible]]).&lt;ref&gt;See [[#Imputed biblical value]]. {{cite book
 |author-first= Petr  |author-last= Beckmann |author-link= Petr Beckmann
 |title= [[A History of Pi]]
 |series=  |volume=  |page= 
 |year= 1971 |orig-year= |publisher= [[St. Martin's Press|St. Martin's]] |isbn= |url=
 |quote= There has been concern over the apparent biblical statement of {{pi}}&amp;nbsp;≈&amp;nbsp;3 from the early times of [[rabbinical Judaism]], addressed by [[Rabbi Nehemiah]] in the 2nd century. }}{{page needed|date=April 2015}}&lt;/ref&gt;
The Babylonians were aware that this was an approximation, and one Old Babylonian mathematical tablet excavated near [[Susa]] in 1936 (dated to between the 19th and 17th centuries BCE) gives a better approximation of {{pi}} as {{math|1=25/8=3.125}}, about 0.5 percent below the exact value.&lt;ref&gt;{{cite book
 |author-first= David Gilman |author-last= Romano |author-link=  David Gilman Romano
 |title= Athletics and Mathematics in Archaic Corinth: The Origins of the Greek Stadion
 |series=  |volume=  |page= 78
 |year= 1993 |orig-year= |publisher= [[American Philosophical Society]] |isbn=
 |url= https://books.google.com/books?id=q0gyy5JOZzIC&amp;pg=PA78&amp;lpg=PA78
 |quote= A group of mathematical clay tablets from the Old Babylonian Period, excavated at Susa in 1936, and published by E.M. Bruins in 1950, provide the information that the Babylonian approximation of {{pi}} was 3 1/8 or 3.125. }}&lt;/ref&gt;&lt;ref&gt;{{cite web
 |author-first= E. M. |author-last= Bruins |author-link=
 |title= Quelques textes mathématiques de la Mission de Suse
 |year= 1950 |orig-year= |publisher= [[]] |isbn= |url= http://www.dwc.knaw.nl/DL/publications/PU00018846.pdf }}&lt;/ref&gt;&lt;ref&gt;{{cite book
 |author-first= E. M. |author-last= Bruins |author-link=
 |author2-first= M.  |author2-last= Rutten |author2-link=
 |title= Textes mathématiques de Suse
 |series= Mémoires de la Mission archéologique en Iran |volume= XXXIV |page= |pages=–
 |year= 1961 |orig-year= |publisher= [[]] |isbn= |url=
 |quote= }}&lt;/ref&gt;&lt;ref&gt;See also {{harvnb|Beckmann|1971|pages=12, 21–22}} "in 1936, a tablet was excavated some 200 miles from Babylon.&amp;nbsp;... The mentioned tablet, whose translation was partially published only in 1950,&amp;nbsp;... states that the ratio of the perimeter of a regular hexagon to the circumference of the circumscribed circle equals a number which in modern notation is given by 57/60+36/(60)&lt;sup&gt;2&lt;/sup&gt; [i.e. {{pi}} = 3/0.96 = 25/8]".&lt;/ref&gt;

At about the same time, the Egyptian [[Rhind Mathematical Papyrus]] (dated to the [[Second Intermediate Period]], c. 1600&amp;nbsp;BCE, although stated to be a copy of an older, [[Middle Kingdom of Egypt|Middle Kingdom]] text) implies an approximation of {{pi}} as {{frac|256|81}} ≈ 3.16 (accurate to 0.6 percent) by calculating the area of a circle by approximating the circle by an octagon.&lt;ref name=Rossi/&gt;&lt;ref&gt;{{cite book
 |editor-last= Katz |editor-first=Victor J.
 |author-last= Imhausen |author-first= Annette |author-link= Annette Imhausen
 |title= The Mathematics of Egypt, Mesopotamia, China, India, and Islam: A Sourcebook
 |publisher= [[Princeton University Press]] |year= 2007 |isbn= 978-0-691-11485-9}}&lt;/ref&gt;

Astronomical calculations in the ''[[Shatapatha Brahmana]]'' (c. 6th century BCE) use a fractional approximation of {{math|1= 339/108 ≈ 3.139}}.&lt;ref&gt;Chaitanya, Krishna. [https://books.google.com/books?ei=9h35T9PdIoHQrQeO4ZXhBg&amp;id=hDc8AAAAMAAJ&amp;dq=Satapatha+Brahmana+value+of+pi&amp;q=pi#search_anchor A profile of Indian culture.] Indian Book Company (1975). P. 133.&lt;/ref&gt;

In the 3rd century BCE, [[Archimedes]] proved the sharp inequalities {{frac|223|71}}&amp;nbsp;&lt;&amp;nbsp;{{pi}}&amp;nbsp;&lt;&amp;nbsp;{{frac|22|7}}, by means of regular [[Polygon|96-gons]] (accuracies of 2·10&lt;sup&gt;−4&lt;/sup&gt; and 4·10&lt;sup&gt;−4&lt;/sup&gt;, respectively).

In the 2nd century CE, [[Ptolemy]], used the value {{frac|377|120}}, the first known approximation accurate to three decimal places (accuracy 2·10&lt;sup&gt;−5&lt;/sup&gt;).&lt;ref&gt;http://uzweb.uz.ac.zw/science/maths/zimaths/pi.htm{{dead link|date=July 2017 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;

The [[Chinese mathematics|Chinese mathematician]] [[Liu Hui]] in 263&amp;nbsp;CE computed {{pi}} to between {{val|3.141024}} and {{val|3.142708}} by inscribing a 96-gon and 192-gon; the average of these two values is {{val|3.141866}} (accuracy 9·10&lt;sup&gt;−5&lt;/sup&gt;).
He also suggested that 3.14 was a good enough approximation for practical purposes. He has also frequently been credited with a later and more accurate result {{math|1=π ≈ 3927/1250 = 3.1416}} (accuracy 2·10&lt;sup&gt;−6&lt;/sup&gt;), although some scholars instead believe that this is due to the later (5th-century) Chinese mathematician [[Zu Chongzhi]].&lt;ref&gt;{{citation
 | last1 = Lam | first1 = Lay Yong
 | last2 = Ang | first2 = Tian Se
 | doi = 10.1016/0315-0860(86)90055-8
 | issue = 4
 | journal = Historia Mathematica
 | mr = 875525
 | pages = 325–340
 | title = Circle measurements in ancient China
 | volume = 13
 | year = 1986}}. Reprinted in {{cite book
 |title=Pi: A Source Book
 |editor1-first=J. L.|editor1-last=Berggren
 |editor2-first=Jonathan M.|editor2-last=Borwein
 |editor3-first=Peter|editor3-last=Borwein
 |publisher=Springer
 |year= 2004 |isbn= 9780387205717 |pages= 20–35
 |url=https://books.google.com/books?id=QlbzjN_5pDoC&amp;pg=PA20}}. See in particular pp. 333–334 (pp. 28–29 of the reprint).&lt;/ref&gt;
Zu Chongzhi is known to have computed {{pi}} between 3.1415926 and 3.1415927, which was correct to seven decimal places. He gave [[Milü|two other approximations of {{pi}}]]: {{math|1=π ≈ 22/7}} and {{math|1=π ≈ 355/113}}. The latter fraction is the best possible rational approximation of {{pi}} using fewer than five decimal digits in the numerator and denominator. Zu Chongzhi's result surpasses the accuracy reached in Hellenistic mathematics, and would remain without improvement for close to a millennium.{{citation needed|date=March 2018}}

In [[Gupta-era India]] (6th century), mathematician [[Aryabhata]] in his astronomical treatise [[Āryabhaṭīya]] calculated the value of {{pi}} to five significant figures ({{math|1=π ≈ 62832/20000 = 3.1416}}).&lt;ref name="aryabhattapi"&gt;[http://www.livemint.com/Sundayapp/8wRiLexg1N2IOXjeK2BKcL/How-Aryabhata-got-the-earths-circumference-right-millenia-a.html How Aryabhata got the earth's circumference right] {{webarchive|url=https://web.archive.org/web/20170115063654/http://www.livemint.com/Sundayapp/8wRiLexg1N2IOXjeK2BKcL/How-Aryabhata-got-the-earths-circumference-right-millenia-a.html |date=15 January 2017 }}&lt;/ref&gt;&lt;ref&gt;Āryabhaṭīya ({{IAST|gaṇitapāda&amp;nbsp;10}}):
:{{IAST|chaturadhikam śatamaṣṭaguṇam dvāśaṣṭistathā sahasrāṇām ayutadvayaviṣkambhasyāsanno vr̥ttapariṇahaḥ}}.
:"Add four to one hundred, multiply by eight and then add sixty-two thousand. The result is approximately the circumference of a circle of diameter twenty thousand. By this rule the relation of the circumference to diameter is given."
In other words, (4&amp;nbsp;+&amp;nbsp;100)&amp;nbsp;×&amp;nbsp;8&amp;nbsp;+&amp;nbsp;62000 is the circumference of a circle with diameter 20000. This provides a value of {{math|1=π ≈ 62832/20000 = 3.1416}},
{{cite book
 |title= Geometry: Seeing, Doing, Understanding (Third Edition)
 |last= Jacobs |first= Harold R.
 |year= 2003 |publisher= [[W.H. Freeman and Company]]
 |location= New York|isbn= |page= 70}}&lt;/ref&gt; using it to calculate an approximation of the [[Earth]]'s circumference.&lt;ref&gt;{{cite web|url=http://www-history.mcs.st-and.ac.uk/Biographies/Aryabhata_I.html|title=Aryabhata the Elder|publisher=''[[University of St Andrews]], School of Mathematics and Statistics''|accessdate=20 July 2011}}&lt;/ref&gt; Aryabhata stated that his result "approximately" (''{{IAST|āsanna}}'' "approaching") gave the circumference of a circle. His 15th-century commentator [[Nilakantha Somayaji]] ([[Kerala school of astronomy and mathematics]]) has argued that the word means not only that this is an approximation, but that the value is [[irrational number|incommensurable (irrational)]].&lt;ref&gt;{{cite book
 | author = S. Balachandra Rao
 | title = Indian Mathematics and Astronomy: Some Landmarks
 | publisher = Jnana Deep Publications
 | year = 1998
 | place = Bangalore
 | isbn = 81-7371-205-0
}}&lt;/ref&gt;

==Middle Ages==
By the 5th century CE, {{pi}} was known to about seven digits in Chinese mathematics, and to about five in Indian mathematics. Further progress was not made for nearly a millennium, until the 14th century, when Indian mathematician and astronomer [[Madhava of Sangamagrama]], founder of the [[Kerala school of astronomy and mathematics]], discovered the [[Series (mathematics)|infinite series]] for {{pi}}, now known as the [[Leibniz formula for pi|Madhava–Leibniz series]],&lt;ref&gt;{{Cite book|title=Special Functions|author1=George E. Andrews |author2=Richard Askey |first=Ranjan Roy|publisher=[[Cambridge University Press]]|year=1999|isbn=0-521-78988-5|page=58|postscript=&lt;!--None--&gt;}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|first=R. C.|last=Gupta|title=On the remainder term in the Madhava–Leibniz's series|journal=Ganita Bharati|volume=14|issue=1–4|year=1992|pages=68–71|postscript=&lt;!--None--&gt;}}&lt;/ref&gt; and gave two methods for computing the value of {{pi}}. One of these methods is to obtain a rapidly converging series by transforming the original [[series (mathematics)|infinite series]] of {{pi}}. By doing so, he obtained the infinite series

: &lt;math&gt;\pi = \sqrt{12}\sum^\infty_{k=0} \frac{(-3)^{-k}}{2k+1} = \sqrt{12}\sum^\infty_{k=0} \frac{(-\frac{1}{3})^k}{2k+1} = \sqrt{12}\left(1-{1\over 3\cdot3}+{1\over5\cdot 3^2}-{1\over7\cdot 3^3}+\cdots\right)&lt;/math&gt;

{{comparison_pi_infinite_series.svg|300px|two Madhava series (the one with {{radic|12}} in dark blue) and}}

and used the first 21 terms to compute an approximation of {{pi}} correct to 11 decimal places as {{val|3.14159265359}}.

The other method he used was to add a remainder term to the original series of {{pi}}. He used the remainder term

: &lt;math&gt;\frac{n^2 + 1}{4n^3 + 5n}&lt;/math&gt;

in the infinite series expansion of {{frac|{{pi}}|4}} to improve the approximation of {{pi}} to 13 decimal places of accuracy when&amp;nbsp;{{math|n}}&amp;nbsp;=&amp;nbsp;75.

[[Jamshīd al-Kāshī]] (Kāshānī), a [[Islamic astronomy|Persian astronomer]] and [[Islamic mathematics|mathematician]], correctly computed 2{{pi}} to 9 [[sexagesimal]] digits in 1424.&lt;ref&gt;{{cite book |author1=Boris A. Rosenfeld |last-author-amp=yes |author2=Adolf P. Youschkevitch |chapter=Ghiyath al-din Jamshid Masud al-Kashi (or al-Kashani) |title=Dictionary of Scientiﬁc Biography |volume=Vol. 7 |date=1981 |page=256}}&lt;/ref&gt; This figure is equivalent to 17 decimal digits as

: &lt;math&gt; 2\pi \approx 6.28318530717958648, &lt;/math&gt;

which equates to

: &lt;math&gt; \pi \approx 3.14159265358979324. &lt;/math&gt;

He achieved this level of accuracy by calculating the perimeter of a [[regular polygon]] with 3 × 2&lt;sup&gt;28&lt;/sup&gt; sides.&lt;ref&gt;{{cite journal| first1=Mohammad K. | last1=Azarian | title=al-Risāla al-muhītīyya: A Summary | journal=Missouri Journal of Mathematical Sciences | volume=22 | issue=2 | year=2010 | pages=64–85 | url=http://projecteuclid.org/euclid.mjms/1312233136}}&lt;/ref&gt;

==16th to 19th centuries==
In the second half of the 16th century, the French mathematician [[François Viète]] discovered an infinite product that converged on {{pi}} known as [[Viète's formula]].

The German-Dutch mathematician [[Ludolph van Ceulen]] (''circa'' 1600) computed the first 35 decimal places of {{pi}} with a 2&lt;sup&gt;62&lt;/sup&gt;-gon. He was so proud of this accomplishment that he had them inscribed on his [[tomb stone|tombstone]].&lt;ref&gt;[http://www.ams.org/samplings/math-history/hap-6-pi.pdf Capra, B. Digits of Pi] Retrieved 13th January 2018&lt;/ref&gt;

In ''Cyclometricus'' (1621), [[Willebrord Snellius]] demonstrated that the perimeter of the inscribed polygon converges on the circumference twice as fast as does the perimeter of the corresponding circumscribed polygon. This was proved by [[Christiaan Huygens]] in 1654. Snellius was able to obtain seven digits of {{pi}} from a [[enneacontahexagon|96-sided polygon]].&lt;ref&gt;[https://docs.google.com/viewer?a=v&amp;q=cache:NTSdP7wNFA8J:www.ijpam.eu/contents/2003-7-2/4/4.pdf+&amp;hl=en&amp;gl=uk&amp;pid=bl&amp;srcid=ADGEESjTAd8gQzDqGaN7fo99joDgBNmLm4PCsT69_vWR13A0nR6yT0T-RZFFSpqN-djir-w4lBOV2Juacul9apQNCW2KMOxf0csRinFDa-1DOSRpxTk83Cg4i8qAxvylfWoLRM04qjE8&amp;sig=AHIEtbSw0AiTGzbt4uLFRLrbOXiXNknJCg Google Docs]&lt;/ref&gt;

In 1789, the Slovene mathematician [[Jurij Vega]] calculated the first 140 decimal places for {{pi}}, of which the first 126 were correct&lt;ref name="Sandifer2007"&gt;{{cite book |first=Edward |last=Sandifer |year=2007 |title=Jurij baron Vega in njegov čas: Zbornik ob 250-letnici rojstva |page=17 |chapter=Why 140 Digits of Pi Matter |chapter-url=https://web.archive.org/web/20160303184631/http://people.wcsu.edu/sandifere/History/Preprints/Talks/Jurij%20Vega/Vega%20math%20script.pdf#page=17 |trans-title=Baron Jurij Vega and His Times: Celebrating 250 Years |publisher=DMFA |location=Ljubljana |isbn=978-961-6137-98-0 |lccn=2008467244 |oclc=448882242 |quote=We should note that Vega's value contains an error in the 127th digit. Vega gives a 4 where there should be an {{bracket|6}}, and all digits after that are incorrect.}}&lt;/ref&gt; and held the world record for 52 years until 1841, when [[William Rutherford (mathematician)|William Rutherford]] calculated 208 decimal places, of which the first 152 were correct. Vega improved [[John Machin]]'s formula from 1706 and his method is still mentioned today.{{Citation needed|date=December 2017}}

The magnitude of such precision (152 decimal places) can be put into context by the fact that the circumference of the largest known object, the observable universe, can be calculated from its diameter (93{{nbsp}}billion [[light-year]]s) to a precision of less than one [[Planck length]] (at {{val|1.6162|e=-35|u=[[meter]]s}}, the shortest unit of length that has real meaning) using {{pi}} expressed to just 62 decimal places.

The English amateur mathematician [[William Shanks]], a man of independent means, spent over 20 years calculating {{pi}} to 707 decimal places. This was accomplished in 1873, with the first 527 places correct. He would calculate new digits all morning and would then spend all afternoon checking his morning's work. This was the longest expansion of {{pi}} until the advent of the electronic digital computer three-quarters of a century later.{{Citation needed|date=December 2017}}

==20th and 21st centuries==
{{main|Chronology of computation of π#The age of electronic computers (from 1949 onwards)}}
In 1910, the Indian mathematician [[Srinivasa Ramanujan]] found several rapidly converging infinite series of {{pi}}, including

:&lt;math&gt; \frac{1}{\pi} = \frac{2\sqrt{2}}{9801} \sum^\infty_{k=0} \frac{(4k)!(1103+26390k)}{(k!)^4 396^{4k}} &lt;/math&gt;

which computes a further eight decimal places of {{pi}} with each term in the series. His series are now the basis for the fastest algorithms currently used to calculate {{pi}}. See also [[Ramanujan–Sato series]].

From the mid-20th century onwards, all calculations of {{pi}} have been done with the help of [[calculators]] or [[computers]].

In 1944, D. F. Ferguson, with the aid of a [[Mechanical calculator|mechanical desk calculator]], found that William Shanks had made a mistake in the 528th decimal place, and that all succeeding digits were incorrect.

In the early years of the computer, an expansion of {{pi}} to {{val|100000}} decimal places&lt;ref name="Shanks &amp; Wrench"/&gt;{{Rp|78}} was computed by Maryland mathematician [[Daniel Shanks]] (no relation to the above-mentioned William Shanks) and his team at the [[United States Naval Research Laboratory]] in Washington, D.C. In 1961, Shanks and his team used two different power series for calculating the digits of {{pi}}. For one, it was known that any error would produce a value slightly high, and for the other, it was known that any error would produce a value slightly low. And hence, as long as the two series produced the same digits, there was a very high confidence that they were correct. The first 100,265 digits of {{pi}} were published in 1962.&lt;ref name="Shanks &amp; Wrench"&gt;{{Cite journal|first1=D.|last1=Shanks|author1-link=Daniel Shanks|first2=J. W.|last2=Wrench, Jr.|author2-link=John Wrench|title=Calculation of {{pi}} to 100,000 decimals|journal=Mathematics of Computation|volume=16|year=1962|pages=76–99|doi=10.2307/2003813|jstor=2003813|issue=77|publisher=American Mathematical Society}}&lt;/ref&gt;{{Rp|80–99}} The authors outlined what would be needed to calculate {{pi}} to 1 million decimal places and concluded that the task was beyond that day's technology, but would be possible in five to seven years.&lt;ref name="Shanks &amp; Wrench"/&gt;{{Rp|78}}

In 1989, the [[Chudnovsky brothers]] computed {{pi}} to over 1 billion decimal places on the [[supercomputer]] [[IBM 3090]] using the following variation of Ramanujan's infinite series of {{pi}}:

:&lt;math&gt; \frac{1}{\pi} = 12 \sum^\infty_{k=0} \frac{(-1)^k (6k)! (13591409 + 545140134k)}{(3k)!(k!)^3 640320^{3k + 3/2}}.&lt;/math&gt;

In 1999, [[Yasumasa Kanada]] and his team at the [[University of Tokyo]] computed {{pi}} to over 200 billion decimal places on the supercomputer [[HITACHI SR8000/MPP]] (128 nodes) using another variation of Ramanujan's infinite series of {{pi}}. In October 2005, they claimed to have calculated it to 1.24 trillion places.&lt;ref&gt;{{cite web|url=http://www.super-computing.org/pi_current.html|title=Announcement at the Kanada lab web site.|website=Super-computing.org|access-date=11 December 2017}}&lt;/ref&gt;

Records since then have all been accomplished on personal computers using the [[Chudnovsky algorithm]]. In 2009, [[Fabrice Bellard]] computed just under 2.7 trillion digits, and from 2010 onward, all records have been set using Alexander Yee's [[y-cruncher]] software.  {{As of|2016|November}}, the record stands at 22,459,157,718,361 ({{pi}}&lt;sup&gt;''e''&lt;/sup&gt;&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;12&lt;/sup&gt;) digits.&lt;ref&gt;{{Cite arxiv |title=Digit Statistics of the First 22.4 Trillion Decimal Digits of Pi |eprint=1612.00489 |class=math.NT |date=30 November 2016 |first=Peter |last=Treub}}&lt;/ref&gt; The limitation on further expansion is primarily storage space for the computation.&lt;ref&gt;{{cite web |title=12.1 Trillion Digits of Pi, And we're out of disk space... |first1=Alexander J. |last1=Yee |first2=Shigeru |last2=Kondo |url=http://www.numberworld.org/misc_runs/pi-12t/ |date=December 2013}}&lt;/ref&gt;

In November 2002, [[Yasumasa Kanada]] and a team of 9 others used the [[Hitachi SR8000]], a 64-node supercomputer with 1 terabyte of main memory, to calculate {{pi}} to roughly 1.24 trillion digits in around 600 hours.

In August 2009, a Japanese supercomputer called the [[T2K Open Supercomputer]] more than doubled the previous record by calculating {{pi}} to roughly 2.6 trillion digits in approximately 73 hours and 36 minutes.

In December 2009, [[Fabrice Bellard]] used a home computer to compute 2.7 trillion decimal digits of {{pi}}. Calculations were performed in base 2 (binary), then the result was converted to base 10 (decimal). The calculation, conversion, and verification steps took a total of 131 days.&lt;ref&gt;{{cite web|url=http://bellard.org/pi/pi2700e9/|title=Pi Computation Record|publisher=}}&lt;/ref&gt;

In August 2010, Shigeru Kondo used Alexander Yee's y-cruncher to calculate 5 trillion digits of {{pi}}. This was the world record for any type of calculation, but significantly it was performed on a home computer built by Kondo.&lt;ref&gt;[http://www.mccormick.northwestern.edu/news/articles/article_743.html McCormick Grad Sets New Pi Record] {{webarchive |url=https://web.archive.org/web/20110928084418/http://www.mccormick.northwestern.edu/news/articles/article_743.html |date=28 September 2011 }}&lt;/ref&gt; The calculation was done between 4 May and 3 August, with the primary and secondary verifications taking 64 and 66 hours respectively.&lt;ref&gt;{{cite web|url=http://www.numberworld.org/misc_runs/pi-5t/announce_en.html|title=Pi - 5 Trillion Digits|publisher=}}&lt;/ref&gt;

In October 2011, Shigeru Kondo broke his own record by computing ten trillion (10&lt;sup&gt;13&lt;/sup&gt;) and fifty digits using the same method but with better hardware.&lt;ref&gt;{{cite web|author=By Glenn |url=https://www.newscientist.com/blogs/shortsharpscience/2011/10/pi-10-trillion.html |title=Short Sharp Science: Epic pi quest sets 10 trillion digit record |publisher=Newscientist.com |date=2011-10-19 |accessdate=2016-04-18}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.numberworld.org/misc_runs/pi-10t/details.html |title=Round 2... 10 Trillion Digits of Pi |author=Alexander J. Yee |author2=Shigeru Kondo |date=22 October 2011}}&lt;/ref&gt;

In December 2013, Kondo broke his own record for a second time when he computed 12.1 trillion digits of {{pi}}.&lt;ref&gt;{{cite web |url=http://www.numberworld.org/misc_runs/pi-12t/ |title=12.1 Trillion Digits of Pi |author=Alexander J. Yee |author2=Shigeru Kondo |date=28 December 2013}}&lt;/ref&gt;

{{anchor|21st century – current claimed world record|Current world record|World record|Current record|Current claimed world record}}
&lt;!-- Keep only the most recent record below this line, when it the record is broken, place it above the previous {{anchor}} line --&gt;
In October 2014, Sandon Van Ness, going by the pseudonym "houkouonchi" used y-cruncher to calculate 13.3 trillion digits of {{pi}}.&lt;ref name="Yee2018"&gt;{{cite web|url=http://www.numberworld.org/y-cruncher/|title=y-cruncher: A Multi-Threaded Pi Program|first=Alexander J.|last=Yee|date=2018|access-date=14 March 2018}}&lt;/ref&gt;

In November 2016, Peter Trueb and his sponsors computed on y-cruncher and fully verified 22.4 trillion digits of {{pi}}. The computation took (with three interruptions) 105 days to complete.&lt;ref&gt;{{Cite web|url=http://www.numberworld.org/y-cruncher/|title=y-cruncher - A Multi-Threaded Pi Program|website=www.numberworld.org|access-date=2016-11-29}}&lt;/ref&gt;

==Practical approximations==
Depending on the purpose of a calculation, {{pi}} can be approximated by using fractions for ease of calculation. The most notable such approximations are {{frac|22|7}} ([[relative error]] of about 4·10&lt;sup&gt;−4&lt;/sup&gt;) and {{frac|355|113}} (relative error of about 8·10&lt;sup&gt;−8&lt;/sup&gt;).

== Non-mathematical "definitions" of {{pi}} ==
Of some notability are legal or historical texts purportedly "defining {{pi}}" to have some rational value, such as the "[[Indiana Pi Bill]]" of 1897, which stated "the ratio of the diameter and circumference is as five-fourths to four" (which would imply "{{math|1=''π'' = 3.2}}") and a passage in the [[Hebrew Bible]] that implies that {{math|1=''&amp;pi;'' = 3}}.

===Indiana bill===
The so-called "[[Indiana Pi Bill]]" of 1897 has often been characterized as an attempt to "legislate the value of Pi". Rather, the bill dealt with a purported solution to the problem of geometrically "[[squaring the circle]]".&lt;ref&gt;"Indiana's squared circle" by Arthur E. Hallerberg (''Mathematics Magazine'', vol. 50 (1977), pp.&amp;nbsp;136–140)&lt;/ref&gt;

The bill was nearly passed by the [[Indiana General Assembly]] in the U.S., and has been claimed to imply a number of different values for {{pi}}, although the closest it comes to explicitly asserting one is the wording "the ratio of the diameter and circumference is as five-fourths to four", which would make {{math|1=''π'' = 16/5 = 3.2}}, a discrepancy of nearly 2 percent. A mathematics professor who happened to be present the day the bill was brought up for consideration in the Senate, after it had passed in the House, helped to stop the passage of the bill on its second reading, after which the assembly thoroughly ridiculed it before tabling it indefinitely.

===Imputed biblical value===
{{see also|Molten Sea}}&lt;!-- This section is linked from [[History of π]] --&gt;

It is sometimes claimed that the [[Hebrew Bible]] implies that "{{pi}} equals three", based on a passage in {{bibleverse|1 Kings|7:23|NKJV|}} and {{bibleverse|2 Chronicles|4:2|NKJV|}} giving measurements for the [[Molten Sea|round basin]] located in front of the [[Temple in Jerusalem]] as having a diameter of 10 [[cubit]]s and a circumference of 30 cubits.

The issue is discussed in the [[Talmud]] and in [[Rabbinic literature]].&lt;ref&gt;{{Cite journal|first1=Boaz|last1=Tsaban|first2=David|last2=Garber|date=February 1998|title=On the rabbinical approximation of {{pi}}|journal=Historia Mathematica|volume=25|issue=1|pages=75–84|issn=0315-0860|doi=10.1006/hmat.1997.2185|url=http://u.cs.biu.ac.il/~tsaban/Pdf/latexpi.pdf|accessdate=14 July 2009}}&lt;/ref&gt; Among the many explanations and comments are these:
*[[Rabbi Nehemiah]] explained this in his ''Mishnat ha-Middot'' (the earliest known [[Hebrew]] text on [[geometry]], ca. 150 CE) by saying that the diameter was measured from the ''outside'' rim while the circumference was measured along the ''inner'' rim. This interpretation implies a brim about 0.225 cubit (or, assuming an 18-inch "cubit", some 4&amp;nbsp;inches), or one and a third "[[handbreadth]]s," thick (cf. {{bibleverse|1|Kings|7:24||NKJV|}} and {{bibleverse|2|Chronicles|4:3||NKJV}}).
* [[Maimonides]] states (ca. 1168 CE) that {{pi}} can only be known approximately, so the value 3 was given as accurate enough for religious purposes. This is taken by some&lt;ref&gt;[[Wilbur Knorr|Wilbur Richard Knorr]], The Ancient Tradition of Geometric Problems, New York: Dover Publications, 1993.&lt;/ref&gt; as the earliest assertion that {{pi}} is irrational.
* Another rabbinical explanation{{by whom|date=April 2015}}{{year needed|date=April 2015}} invokes [[gematria]]: In {{bibleverse|1|Kings|7:23||NKJV}} the word translated 'measuring line' appears in the Hebrew text spelled QWH קַוה, but elsewhere the word is most usually spelled QW קַו. The ratio of the numerical values of these Hebrew spellings is {{frac|111|106}}. If the putative value of 3 is multiplied by this ratio, one obtains {{frac|333|106}} = 3.141509433...&amp;nbsp;– giving 5 correct digits, which is within 1/10,000 of the true value of {{pi}}. For this to work, it must be assumed that the measuring line is different for the diameter and circumference.

There is still some debate on this passage in biblical scholarship.{{failed verification|date=April 2015}}&lt;ref&gt;{{cite web
|first=H. Peter
|last=Aleff
|url=http://www.recoveredscience.com/const303solomonpi.htm|title=Ancient Creation Stories told by the Numbers: Solomon's Pi
|publisher=recoveredscience.com
|accessdate=30 October 2007| archiveurl= https://web.archive.org/web/20071014201334/http://recoveredscience.com/const303solomonpi.htm| archivedate= 14 October 2007 &lt;!--DASHBot--&gt;| deadurl= no}}&lt;/ref&gt;&lt;ref name="ahop"&gt;
{{cite web
|first=J J
|last=O'Connor
|author2=E F Robertson
|url=http://www-groups.dcs.st-and.ac.uk/~history/HistTopics/Pi_through_the_ages.html
|title=A history of Pi
|date=August 2001
|accessdate=30 October 2007| archiveurl= https://web.archive.org/web/20071030063811/http://www-groups.dcs.st-and.ac.uk/~history/HistTopics/Pi_through_the_ages.html| archivedate= 30 October 2007 &lt;!--DASHBot--&gt;| deadurl= no}}&lt;/ref&gt; Many reconstructions of the basin show a wider brim (or flared lip) extending outward from the bowl itself by several inches to match the description given in {{bibleverse|1|Kings|7:26||NKJV}}&lt;ref&gt;[http://mathforum.org/library/drmath/view/52573.html Math Forum&amp;nbsp;– Ask Dr. Math&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; In the succeeding verses, the rim is described as "a handbreadth thick; and the brim thereof was wrought like the brim of a cup, like the flower of a lily: it received and held three thousand baths" {{bibleverse|2|Chronicles|4:5||NKJV}}, which suggests a shape that can be encompassed with a string shorter than the total length of the brim, e.g., a [[Lilium]] flower or a [[Teacup]].

==Development of efficient formulae==
{{Main article|List of formulae involving π}}

===Polygon approximation to a circle===
Archimedes, in his ''Measurement of a Circle'', created the first algorithm for the calculation of {{pi}} based on the idea that the perimeter of any (convex) polygon inscribed in a circle is less than the circumference of the circle, which, in turn, is less than the perimeter of any circumscribed polygon. He started with inscribed and circumscribed regular hexagons, whose perimeters are readily determined. He then shows how to calculate the perimeters of regular polygons of twice as many sides that are inscribed and circumscribed about the same circle. This is a recursive procedure which would be described today as follows: Let {{math|''p''&lt;sub&gt;''k''&lt;/sub&gt;}} and {{math|''P''&lt;sub&gt;''k''&lt;/sub&gt;}} denote the perimeters of regular polygons of {{math|''k''}} sides that are inscribed and circumscribed about the same circle, respectively. Then,
:&lt;math&gt;P_{2n} = \frac{2p_nP_n}{p_n + P_n}, \quad \quad p_{2n} = \sqrt{p_n P_{2n}}.&lt;/math&gt;
Archimedes uses this to successively compute {{math|''P''&lt;sub&gt;12&lt;/sub&gt;, ''p''&lt;sub&gt;12&lt;/sub&gt;, ''P''&lt;sub&gt;24&lt;/sub&gt;, ''p''&lt;sub&gt;24&lt;/sub&gt;, ''P''&lt;sub&gt;48&lt;/sub&gt;, ''p''&lt;sub&gt;48&lt;/sub&gt;, ''P''&lt;sub&gt;96&lt;/sub&gt;}} and {{math|''p''&lt;sub&gt;96&lt;/sub&gt;}}.&lt;ref&gt;{{harvnb|Eves|1992|page=131}}&lt;/ref&gt; Using these last values he obtains
:&lt;math&gt;3 \frac{10}{71} &lt; \pi &lt; 3 \frac{1}{7}.&lt;/math&gt;
It is not known why Archimedes stopped at a 96-sided polygon; it only takes patience to extend the computations. [[Hero of Alexandria|Heron]] reports in his ''Metrica'' (about 60 CE) that Archimedes continued the computation in a now lost book, but then attributes an incorrect value to him.&lt;ref&gt;{{harvnb|Beckmann|1971|page=66}}&lt;/ref&gt;

Archimedes uses no trigonometry in this computation and the difficulty in applying the method lies in obtaining good approximations for the square roots that are involved. Trigonometry, in the form of a table of chord lengths in a circle, was probably used by [[Claudius Ptolemaeus|Claudius Ptolemy of Alexandria]] to obtain the value of {{pi}} given in the ''Almagest'' (circa 150 CE).&lt;ref&gt;{{harvnb|Eves|1992|page=118}}&lt;/ref&gt;

Advances in the approximation of {{pi}} (when the methods are known) were made by increasing the number of sides of the polygons used in the computation. A trigonometric improvement by [[Willebrord Snellius|Willebrord Snell]] (1621) obtains better bounds from a pair of bounds gotten from the polygon method. Thus, more accurate results were obtained from polygons with fewer sides.&lt;ref name=EvesSnell&gt;{{harvnb|Eves|1992|page=119}}&lt;/ref&gt; [[Viète's formula]], published by [[François Viète]] in 1593, was derived by Viète using a closely related polygonal method, but with areas rather than perimeters of polygons whose numbers of sides are powers of two.&lt;ref&gt;{{harvnb|Beckmann|1971|pages=94–95}}&lt;/ref&gt;

The last major attempt to compute {{pi}} by this method was carried out by Grienberger in 1630 who calculated 39 decimal places of {{pi}} using Snell's refinement.&lt;ref name=EvesSnell/&gt;

===Machin-like formula===
{{main|Machin-like formula}}
For fast calculations, one may use formulae such as [[John Machin|Machin's]]:
: &lt;math&gt;\frac{\pi}{4} = 4 \arctan\frac{1}{5} - \arctan\frac{1}{239} &lt;/math&gt;
together with the [[Taylor series]] expansion of the function [[arctan]](''x''). This formula is most easily verified using [[polar coordinates]] of [[complex number]]s, producing:

&lt;math&gt;(5+i)^4\cdot(239-i)=2^2 \cdot 13^4(1+i).&lt;/math&gt;

(Note also that {&lt;nowiki/&gt;{{mvar|x}},{{mvar|y}}&lt;nowiki/&gt;} = {239, 13&lt;sup&gt;2&lt;/sup&gt;} is a solution to the [[Pell equation]] {{mvar|x}}&lt;sup&gt;2&lt;/sup&gt;−2{{mvar|y}}&lt;sup&gt;2&lt;/sup&gt; = −1.)

Formulae of this kind are known as ''[[Machin-like formula]]e''. &lt;nowiki/&gt;&lt;nowiki/&gt;Machin's particular formula was used well into the computer era for calculating record numbers of digits of {{pi}},&lt;ref name="Shanks &amp; Wrench" /&gt; but more recently other similar formulae have been used as well.

For instance, [[Daniel Shanks|Shanks]] and his team used the following Machin-like formula in 1961 to compute the first 100,000 digits of {{pi}}:&lt;ref name="Shanks &amp; Wrench" /&gt;

&lt;math&gt;\frac{\pi}{4} = 6 \arctan\frac{1}{8} + 2 \arctan\frac{1}{57} + \arctan\frac{1}{239} &lt;/math&gt;

and they used another Machin-like formula,

&lt;math&gt;\frac{\pi}{4} = 12 \arctan\frac{1}{18} + 8 \arctan\frac{1}{57} - 5 \arctan\frac{1}{239}&lt;/math&gt;

as a check.

The record as of December 2002 by Yasumasa Kanada of Tokyo University stood at 1,241,100,000,000 digits. The following Machin-like formulae were used for this:
: &lt;math&gt;\frac{\pi}{4} = 12 \arctan\frac{1}{49} + 32 \arctan\frac{1}{57} - 5 \arctan\frac{1}{239} + 12 \arctan\frac{1}{110443}&lt;/math&gt;
K. Takano (1982).
: &lt;math&gt;\frac{\pi}{4} = 44 \arctan\frac{1}{57} + 7 \arctan\frac{1}{239} - 12 \arctan\frac{1}{682} + 24 \arctan\frac{1}{12943}&lt;/math&gt;
F. C. W. Störmer (1896).

===Other classical formulae===
Other formulae that have been used to compute estimates of {{pi}} include:

[[Liu Hui's π algorithm|Liu Hui]] (see also [[Viète's formula]]):
: &lt;math&gt;
\begin{align}
\pi &amp;\approx 768 \sqrt{2 - \sqrt{2 + \sqrt{2 + \sqrt{2 + \sqrt{2 + \sqrt{2 + \sqrt{2 + \sqrt{2 + \sqrt{2+1}}}}}}}}}\\
&amp;\approx 3.141590463236763.
\end{align}
&lt;/math&gt;

[[Madhava of Sangamagrama|Madhava]]:
:&lt;math&gt;\pi = \sqrt{12}\sum^\infty_{k=0} \frac{(-3)^{-k}}{2k+1} = \sqrt{12}\sum^\infty_{k=0} \frac{(-\frac{1}{3})^k}{2k+1} = \sqrt{12}\left({1\over 1\cdot3^0}-{1\over 3\cdot3^1}+{1\over5\cdot 3^2}-{1\over7\cdot 3^3}+\cdots\right)&lt;/math&gt;

[[Euler]]:
:&lt;math&gt;{\pi} = 20 \arctan\frac{1}{7} + 8 \arctan\frac{3}{79} &lt;/math&gt;

[[Isaac Newton|Newton]] / Euler Convergence Transformation:&lt;ref&gt;{{cite web|url=http://mathworld.wolfram.com/PiFormulas.html |title=Pi Formulas - from Wolfram MathWorld |publisher=Mathworld.wolfram.com |date=2016-04-13 |accessdate=2016-04-18}}&lt;/ref&gt;
:&lt;math&gt;
\frac{\pi}{2}= 
\sum_{k=0}^\infty\frac{k!}{(2k+1)!!}= \sum_{k=0}^{\infty} \cfrac {2^k k!^2}{(2k + 1)!} =
1+\frac{1}{3}\left(1+\frac{2}{5}\left(1+\frac{3}{7}\left(1+\cdots\right)\right)\right)
&lt;/math&gt;
where (2k+1)!! denotes the product of the odd integers up to 2k+1.

[[Ramanujan]]:
:&lt;math&gt; \frac{1}{\pi} = \frac{2\sqrt{2}}{9801} \sum^\infty_{k=0} \frac{(4k)!(1103+26390k)}{(k!)^4 396^{4k}} &lt;/math&gt;

[[David Chudnovsky (mathematician)|David Chudnovsky]] and [[Gregory Chudnovsky]]:
:&lt;math&gt; \frac{1}{\pi} = 12 \sum^\infty_{k=0} \frac{(-1)^k (6k)! (13591409 + 545140134k)}{(3k)!(k!)^3 640320^{3k + 3/2}} &lt;/math&gt;

Ramanujan's work is the basis for the [[Chudnovsky algorithm]], the fastest algorithms used, as of the turn of the millennium, to calculate {{pi}}.

===Modern algorithms===
Extremely long decimal expansions of {{pi}} are typically computed with iterative formulae like the [[Gauss–Legendre algorithm]] and [[Borwein's algorithm]]. The latter, found in 1985 by [[Jonathan Borwein|Jonathan]] and [[Peter Borwein]], converges extremely quickly:

For &lt;math&gt;y_0=\sqrt2-1,\ a_0=6-4\sqrt2&lt;/math&gt; and
:&lt;math&gt;y_{k+1}=(1-f(y_k))/(1+f(y_k)) ~,~ a_{k+1} = a_k(1+y_{k+1})^4 - 2^{2k+3} y_{k+1}(1+y_{k+1}+y_{k+1}^2) &lt;/math&gt;
where &lt;math&gt;f(y)=(1-y^4)^{1/4}&lt;/math&gt;, the sequence &lt;math&gt;1/a_k&lt;/math&gt; [[rate of convergence|converges quartically]] to {{pi}}, giving about 100 digits in three steps and over a trillion digits after 20 steps. However, it is known that using an algorithm such as the Chudnovsky algorithm (which converges linearly) is faster than these iterative formulae.

The first one million digits of {{pi}} and {{frac|1|{{pi}}}} are available from [[Project Gutenberg]] (see external links below). A former calculation record (December 2002) by [[Yasumasa Kanada]] of [[Tokyo University]] stood at 1.24 trillion digits, which were computed in September 2002 on a 64-node [[Hitachi, Ltd.|Hitachi]] [[supercomputer]] with 1 terabyte of main memory, which carries out 2 trillion operations per second, nearly twice as many as the computer used for the previous record (206 billion digits). The following Machin-like formulæ were used for this:

:&lt;math&gt; \frac{\pi}{4} = 12 \arctan\frac{1}{49} + 32 \arctan\frac{1}{57} - 5 \arctan\frac{1}{239} + 12 \arctan\frac{1}{110443}&lt;/math&gt;
:K. Takano (1982).

: &lt;math&gt; \frac{\pi}{4} = 44 \arctan\frac{1}{57} + 7 \arctan\frac{1}{239} - 12 \arctan\frac{1}{682} + 24 \arctan\frac{1}{12943}&lt;/math&gt; ([[Carl Størmer|F. C. W. Störmer]] (1896)).

These approximations have so many digits that they are no longer of any practical use, except for testing new supercomputers.&lt;ref&gt;{{cite web|url=http://www.extremetech.com/extreme/122159-what-can-you-do-with-a-supercomputer|title=What can you do with a supercomputer? - ExtremeTech|publisher=}}&lt;/ref&gt; Properties like the potential [[normal number|normality]] of [[pi|{{pi}}]] will always depend on the infinite string of digits on the end, not on any finite computation.

===Miscellaneous approximations===
Historically, [[radix|base]] 60 was used for calculations. In this base, {{pi}} can be approximated to eight (decimal) significant figures with the number 3:8:29:44{{sub|60}}, which is

:&lt;math&gt; 3 + \frac{8}{60} + \frac{29}{60^2} + \frac{44}{60^3} = 3.14159\ 259^+&lt;/math&gt;

(The next [[sexagesimal]] digit is 0, causing truncation here to yield a relatively good approximation.)

In addition, the following expressions can be used to estimate {{pi}}:
* accurate to three digits:
::&lt;math&gt;\frac{22}{7} = 3.143^+&lt;/math&gt;
* accurate to three digits:
:: &lt;math&gt;\sqrt{2} + \sqrt{3} = 3.146^+&lt;/math&gt;
: [[Karl Popper]] conjectured that [[Plato]] knew this expression, that he believed it to be exactly {{pi}}, and that this is responsible for some of Plato's confidence in the [[omnicompetence]] of mathematical geometry—and Plato's repeated discussion of special [[right triangle]]s that are either [[isosceles]] or halves of [[equilateral]] triangles.
:: &lt;math&gt;\sqrt{15} - \sqrt {3} + 1 = 3.140^+&lt;/math&gt;
* accurate to four digits:
::&lt;math&gt;\sqrt[3]{31} = 3.1413^+&lt;/math&gt;&lt;ref&gt;{{Cite journal|first=Martin|last=Gardner|authorlink=Martin Gardner|title=New Mathematical Diversions|publisher=Mathematical Association of America|year=1995|page=92}}&lt;/ref&gt;
* accurate to four digits (or five significant figures):
::&lt;math&gt;\sqrt{7+\sqrt{6+\sqrt{5}}} = 3.1416^+&lt;/math&gt;&lt;ref&gt;[http://www.mschneider.cc/papers/pi.pdf A nested radical approximation for {{pi}}] {{webarchive |url=https://web.archive.org/web/20110706215615/http://www.mschneider.cc/papers/pi.pdf |date=6 July 2011 }}&lt;/ref&gt;
* an approximation by [[Ramanujan]], accurate to 4 digits (or five significant figures):
::&lt;math&gt;\frac{9}{5}+\sqrt{\frac{9}{5}} = 3.1416^+&lt;/math&gt;
* accurate to five digits:
::&lt;math&gt;\frac{7^7}{4^9} = 3.14156^+&lt;/math&gt;
* accurate to seven digits:
::&lt;math&gt;\frac{355}{113} = 3.14159\ 29^+&lt;/math&gt;
*accurate to nine digits:
:: &lt;math&gt; \sqrt[4]{3^4+2^4+\frac{1}{2+(\frac{2}{3})^2}} =\sqrt[4]{\frac{2143}{22}} = 3.14159\ 2652^+&lt;/math&gt;
: This is from [[Ramanujan]], who claimed the [[Namagiri Thayar|Goddess of Namagiri]] appeared to him in a dream and told him the true value of {{pi}}.&lt;ref&gt;"Lost notebook page 16" ,Ramanujan&lt;/ref&gt;
* accurate to ten digits:
::&lt;math&gt;\frac{63}{25} \times \frac{17 + 15\sqrt{5}}{7 + 15\sqrt{5}} = 3.14159\ 26538^+&lt;/math&gt;
* accurate to ten digits (or eleven significant figures):
::&lt;math&gt;\sqrt[193]{\frac{10^{100}}{11222.11122}} = 3.14159\ 26536^+&lt;/math&gt;
:This curious approximation follows the observation that the 193rd power of 1/{{pi}} yields the sequence 1122211125... Replacing 5 by 2 completes the symmetry without reducing the correct digits of {{pi}}, while inserting a central decimal point remarkably fixes the accompanying magnitude at 10&lt;sup&gt;100&lt;/sup&gt;.&lt;ref&gt;Hoffman, D.W. ''College Mathematics Journal'', '''40''' (2009) 399&lt;/ref&gt;
* accurate to 18 digits:
::&lt;math&gt;\frac{80\sqrt{15}(5^4+53\sqrt{89})^\frac{3}{2}}{3308(5^4+53\sqrt{89})-3\sqrt{89}}&lt;/math&gt;&lt;ref name="CetinHakimoglu–Brown"&gt;{{cite web|url=http://iamned.com/math|title=Mathematics|publisher=}}&lt;/ref&gt;
:This is based on the [[fundamental discriminant]] {{math|d}} = 3(89) = 267 which has [[Binary quadratic form|class number]] {{math|h}}(-{{math|d}}) = 2 explaining the [[algebraic numbers]] of degree 2. Note that the core radical &lt;math&gt; \scriptstyle 5^4+53\sqrt{89}&lt;/math&gt; is 5&lt;sup&gt;3&lt;/sup&gt; more than the [[Fundamental unit (number theory)|fundamental unit]] &lt;math&gt; \scriptstyle U_{89} = 500+53\sqrt{89}&lt;/math&gt; which gives the smallest solution { {{math|''x''}}, {{math|''y''}}} = {500, 53} to the [[Pell equation]] {{math|''x''}}&lt;sup&gt;2&lt;/sup&gt;-89{{math|''y''}}&lt;sup&gt;2&lt;/sup&gt; = -1.
* accurate to 30 decimal places:
::&lt;math&gt;\frac{\ln(640320^3+744)}{\sqrt{163}} = 3.14159\ 26535\ 89793\ 23846\ 26433\ 83279^+&lt;/math&gt;
: Derived from the closeness of [[Ramanujan's constant|Ramanujan constant]] to the integer 640320³+744. This does not admit obvious generalizations in the integers, because there are only finitely many [[Heegner number]]s and negative [[discriminant]]s ''d'' with [[Binary quadratic form|class number]] ''h''(−''d'') = 1, and d = 163 is the largest one in [[absolute value]].
* accurate to 52 decimal places:
::&lt;math&gt;\frac{\ln(5280^3(236674+30303\sqrt{61})^3+744)}{\sqrt{427}}&lt;/math&gt;
:Like the one above, a consequence of the [[j-invariant]]. Among negative discriminants with class number 2, this ''d'' the largest in absolute value.
* accurate to 161 decimal places:
::&lt;math&gt;\frac{\ln\big((2u)^6+24\big)}{\sqrt{3502}}&lt;/math&gt;
:where ''u'' is a product of four simple quartic units,
:&lt;math&gt;u = (a+\sqrt{a^2-1})^2(b+\sqrt{b^2-1})^2(c+\sqrt{c^2-1})(d+\sqrt{d^2-1})&lt;/math&gt;
:and,
:&lt;math&gt;\begin{align}
a &amp;= \tfrac{1}{2}(23+4\sqrt{34})\\
b &amp;= \tfrac{1}{2}(19\sqrt{2}+7\sqrt{17})\\
c &amp;= (429+304\sqrt{2})\\
d &amp;= \tfrac{1}{2}(627+442\sqrt{2})
\end{align}&lt;/math&gt;
:Based on one found by [[Daniel Shanks]]. Similar to the previous two, but this time is a quotient of a [[modular form]], namely the [[Dedekind eta function]], and where the argument involves &lt;math&gt;\tau = \sqrt{-3502}&lt;/math&gt;. The discriminant ''d'' = 3502 has ''h''(−''d'') = 16.
* The [[continued fraction]] representation of {{pi}} can be used to generate successive [[best rational approximation]]s. These approximations are the best possible rational approximations of {{pi}} relative to the size of their denominators. Here is a list of the first thirteen of these:&lt;ref&gt;{{Cite OEIS|sequencenumber=A002485 |name=Numerators of convergents to Pi}}&lt;/ref&gt;&lt;ref&gt;{{Cite OEIS|sequencenumber=A002486 |name=Denominators of convergents to Pi}}&lt;/ref&gt;
:&lt;math&gt;\frac{3}{1}, \frac{22}{7}, \frac{333}{106}, \frac{355}{113}, \frac{103993}{33102}, \frac{104348}{33215}, \frac{208341}{66317}, \frac{312689}{99532}, \frac{833719}{265381}, \frac{1146408}{364913}, \frac{4272943}{1360120}, \frac{5419351}{1725033}&lt;/math&gt;
:Of all of these, &lt;math&gt;\frac{355}{113}&lt;/math&gt; is the only fraction in this sequence that gives more exact digits of {{pi}} (i.e. 7) than the number of digits needed to approximate it (i.e. 6). The accuracy can be improved by using other fractions with larger numerators and denominators, but, for most such fractions, more digits are required in the approximation than correct significant figures achieved in the result.&lt;ref&gt;{{cite web|url=http://qin.laya.com/tech_projects_approxpi.html|title=Fractional Approximations of Pi|publisher=}}&lt;/ref&gt;

===Summing a circle's area===
[[File:Pi 30K.gif|thumb|right|Numerical approximation of {{pi}}: as points are randomly scattered inside the unit square, some fall within the unit circle. The fraction of points inside the circle approaches {{math|π/4}} as points are added.]]

Pi can be obtained from a circle if its radius and area are known using the relationship:
:&lt;math&gt; A = \pi r^2.&lt;/math&gt;

If a circle with radius ''{{math|r}}'' is drawn with its center at the point (0,&amp;nbsp;0), any point whose distance from the origin is less than ''{{math|r}}'' will fall inside the circle. The [[Pythagorean theorem]] gives the distance from any point ({{math|''x''}},&amp;nbsp;{{math|''y''}}) to the center:
:&lt;math&gt;d=\sqrt{x^2+y^2}.&lt;/math&gt;

Mathematical "graph paper" is formed by imagining a 1×1 square centered around each cell ({{math|''x''}},&amp;nbsp;{{math|''y''}}), where {{math|''x''}} and {{math|''y''}} are [[integer]]s between −{{math|r}} and {{math|r}}. Squares whose center resides inside or exactly on the border of the circle can then be counted by testing whether, for each cell ({{math|''x''}},&amp;nbsp;{{math|''y''}}),
:&lt;math&gt;\sqrt{x^2+y^2} \le r.&lt;/math&gt;

The total number of cells satisfying that condition thus approximates the area of the circle, which then can be used to calculate an approximation of {{pi}}. Closer approximations can be produced by using larger values of {{math|r}}.

Mathematically, this formula can be written:
:&lt;math&gt;\pi = \lim_{r \to \infty} \frac{1}{r^2} \sum_{x=-r}^{r} \; \sum_{y=-r}^{r} \begin{cases}
1 &amp; \text{if } \sqrt{x^2+y^2} \le r \\
0 &amp; \text{if } \sqrt{x^2+y^2} &gt; r. \end{cases}
&lt;/math&gt;

In other words, begin by choosing a value for {{math|r}}. Consider all cells ({{math|''x''}},&amp;nbsp;{{math|''y''}}) in which both {{math|''x''}} and {{math|''y''}} are integers between −{{math|r}} and {{math|r}}. Starting at 0, add 1 for each cell whose distance to the origin (0,0) is less than or equal to ''{{math|r}}''. When finished, divide the sum, representing the area of a circle of radius {{math|r}}, by {{math|r}}&lt;sup&gt;2&lt;/sup&gt; to find the approximation of {{pi}}.
For example, if {{math|r}} is 5, then the cells considered are:
:{| style="font-size:75%;text-align:center;color:blue;height:1em" cellspacing="15"
|- style="color:black"
| (−5,5) || (−4,5) || (−3,5) || (−2,5) || (−1,5) || style="color:#bc1e47" | (0,5) || (1,5) || (2,5) || (3,5) || (4,5) || (5,5)
|-
| style="color:black" | (−5,4) || style="color:black" | (−4,4) || style="color:#bc1e47" | (−3,4) || (−2,4) || (−1,4) || (0,4) || (1,4) || (2,4) || style="color:#bc1e47" | (3,4) || style="color:black" | (4,4) || style="color:black" | (5,4)
|-
| style="color:black" | (−5,3) || style="color:#bc1e47" | (−4,3) || (−3,3) || (−2,3) || (−1,3) || (0,3) || (1,3) || (2,3) || (3,3) || style="color:#bc1e47" | (4,3) || style="color:black" | (5,3)
|-
| style="color:black" | (−5,2) || (−4,2) || (−3,2) || (−2,2) || (−1,2) || (0,2) || (1,2) || (2,2) || (3,2) || (4,2) || style="color:black" | (5,2)
|-
| style="color:black" | (−5,1) || (−4,1) || (−3,1) || (−2,1) || (−1,1) || (0,1) || (1,1) || (2,1) || (3,1) || (4,1) || style="color:black" | (5,1)
|-
| style="color:#bc1e47" | (−5,0) || (−4,0) || (−3,0) || (−2,0) || (−1,0) || (0,0) || (1,0) || (2,0) || (3,0) || (4,0) || style="color:#bc1e47" | (5,0)
|-
| style="color:black" | (−5,−1) || (−4,−1) || (−3,−1) || (−2,−1) || (−1,−1) || (0,−1) || (1,−1) || (2,−1) || (3,−1) || (4,−1) || style="color:black" | (5,−1)
|-
| style="color:black" | (−5,−2) || (−4,−2) || (−3,−2) || (−2,−2) || (−1,−2) || (0,−2) || (1,−2) || (2,−2) || (3,−2) || (4,−2) || style="color:black" | (5,−2)
|-
| style="color:black" | (−5,−3) || style="color:#bc1e47" | (−4,−3) || (−3,−3) || (−2,−3) || (−1,−3) || (0,−3) || (1,−3) || (2,−3) || (3,−3) || style="color:#bc1e47" | (4,−3) || style="color:black" | (5,−3)
|-
| style="color:black" | (−5,−4) || style="color:black" | (−4,−4) || style="color:#bc1e47" | (−3,−4) || (−2,−4) || (−1,−4) || (0,−4) || (1,−4) || (2,−4) || style="color:#bc1e47" | (3,−4) || style="color:black" | (4,−4) || style="color:black" | (5,−4)
|- style="color:black"
| (−5,−5) || (−4,−5) || (−3,−5) || (−2,−5) || (−1,−5) || style="color:#bc1e47" | (0,−5) || (1,−5) || (2,−5) || (3,−5) || (4,−5) || (5,−5)
|}

[[File:Kreuz-5.svg|right|250px|thumb|This circle as it would be drawn on a [[Cartesian coordinate]] graph. The cells (±3, ±4) and (±4, ±3) are labeled.]]
The 12 cells (0, ±5), (±5, 0), (±3, ±4), (±4, ±3) are ''exactly on'' the circle, and 69 cells are ''completely inside'', so the approximate area is 81, and {{pi}} is calculated to be approximately 3.24 because 81 / 5&lt;sup&gt;2&lt;/sup&gt; = 3.24. Results for some values of {{math|r}} are shown in the table below:
&lt;center&gt;
{| class="wikitable" style="text-align:center"
|-
! r !! area !! approximation of {{pi}}
|-
| 2 || 13 || 3.25
|-
| 3 || 29 || 3.22222
|-
| 4 || 49 || 3.0625
|-
| 5 || 81 || 3.24
|-
| 10 || 317 || 3.17
|-
| 20 || 1257 || 3.1425
|-
| 100 || 31417 || 3.1417
|-
| 1000 || 3141549 || 3.141549
|}
&lt;/center&gt;

For related results see [https://oeis.org/A057655 The circle problem: number of points (x,y) in square lattice with x^2 + y^2 &lt;= n].

Similarly, the more complex approximations of {{pi}} given below involve repeated calculations of some sort, yielding closer and closer approximations with increasing numbers of calculations.

===Continued fractions===
Besides its simple [[continued fraction]] representation [3; 7, 15, 1, 292, 1, 1,{{nbsp}}...], which displays no discernible pattern, {{pi}} has many [[generalized continued fraction]] representations generated by a simple rule, including these two.
:&lt;math&gt;
\pi= {3 + \cfrac{1^2}{6 + \cfrac{3^2}{6 + \cfrac{5^2}{6 + \ddots\,}}}}
&lt;/math&gt;
:&lt;math&gt;
\pi = \cfrac{4}{1 + \cfrac{1^2}{3 + \cfrac{2^2}{5 + \cfrac{3^2}{7 + \ddots}}}}
&lt;/math&gt;

(Other representations are available at [http://functions.wolfram.com/Constants/Pi/10/ The Wolfram Functions Site].)

===Trigonometry===

====Gregory–Leibniz series====
The [[Leibniz formula for pi|Gregory–Leibniz series]]
: &lt;math&gt;\pi = 4\sum_{n=0}^{\infty} \cfrac {(-1)^n}{2n+1} = 4\left( \frac{1}{1} - \frac{1}{3} + \frac{1}{5} - \frac{1}{7} +- \cdots\right) \! = \cfrac{4}{1 + \cfrac{1^2}{2 + \cfrac{3^2}{2 + \cfrac{5^2}{2 + \ddots}}}}&lt;/math&gt;
is the power series for [[arctan]](x) specialized to {{math|''x''}}&amp;nbsp;=&amp;nbsp;1. It converges too slowly to be of practical interest. However, the power series converges much faster for smaller values of &lt;math&gt;x&lt;/math&gt;, which leads to formulae where &lt;math&gt;\pi&lt;/math&gt; arises as the sum of small angles with rational tangents, known as [[Machin-like formula]]e.

====Arctangent====
{{further information|Double factorial}}
Knowing that 4 arctan 1 = {{pi}}, the formula can be simplified to get:
: &lt;math&gt;\begin{align}
\pi &amp;= 2\left( 1 + \cfrac{1}{3} + \cfrac{1\cdot2}{3\cdot5}
+ \cfrac{1\cdot2\cdot3}{3\cdot5\cdot7} + \cfrac{1\cdot2\cdot3\cdot4}{3\cdot5\cdot7\cdot9}
+ \cfrac{1\cdot2\cdot3\cdot4\cdot5}{3\cdot5\cdot7\cdot9\cdot11} + \cdots\right) \\
&amp;= 2\sum_{n=0}^{\infty} \cfrac {n!}{(2n + 1)!!}
= \sum_{n=0}^{\infty} \cfrac {2^{n+1} n!^2} {(2n + 1)!}
= \sum_{n=0}^{\infty} \cfrac {2^{n+1}} {\binom {2n} n (2n + 1)} \\
&amp;= 2 + \frac{2}{3} + \frac{4}{15} + \frac{4}{35} + \frac{16}{315} + \frac{16}{693}
+ \frac{32}{3003} + \frac{32}{6435} + \frac{256}{109395} + \frac{256}{230945} + \cdots
\end{align}&lt;/math&gt;

with a convergence such that each additional 10 terms yields at least three more digits.

====Arcsine====
Observing an equilateral triangle and noting that
: &lt;math&gt;\sin\left (\frac{\pi}{6}\right )=\frac{1}{2}&lt;/math&gt;
yields
: &lt;math&gt;\begin{align}
\pi &amp;= 6 \sin^{-1} \left( \frac{1}{2} \right)
= 6 \left( \frac{1}{2} + \frac{1}{2\cdot 3\cdot 2^3} + \frac{1\cdot 3}{2\cdot 4\cdot 5\cdot 2^5}
 + \frac{1\cdot 3\cdot 5}{2\cdot 4\cdot 6\cdot 7\cdot 2^7} + \cdots\! \right) \\
&amp;= \frac {3} {16^0 \cdot 1} + \frac {6} {16^1 \cdot 3} + \frac {18} {16^2 \cdot 5} + \frac {60} {16^3 \cdot 7} + \cdots\!
= \sum_{n=0}^\infty \frac {3 \cdot \binom {2n} n} {16^n (2n+1)} \\
&amp;= 3 + \frac{1}{8} + \frac{9}{640} + \frac{15}{7168} + \frac{35}{98304}
+ \frac{189}{2883584} + \cfrac{693}{54525952} + \frac{429}{167772160} + \cdots
\end{align}&lt;/math&gt;
with a convergence such that each additional five terms yields at least three more digits.

===The Salamin–Brent algorithm===
The [[Gauss–Legendre algorithm]] or Salamin–Brent algorithm was discovered independently by [[Richard Brent (scientist)|Richard Brent]] and [[Eugene Salamin (mathematician)|Eugene Salamin]] in 1975. This can compute &lt;math&gt;\pi&lt;/math&gt; to &lt;math&gt;N&lt;/math&gt; digits in time proportional to &lt;math&gt;N\,\log(N)\,\log(\log(N))&lt;/math&gt;, much faster than the trigonometric formulae.

==Digit extraction methods==
The [[Bailey–Borwein–Plouffe formula]] (BBP) for calculating {{pi}} was discovered in 1995 by Simon Plouffe. Using [[Hexadecimal|{{nowrap|base 16}}]] math, the formula can compute any particular digit of {{pi}}—returning the hexadecimal value of the digit—without having to compute the intervening digits (digit extraction).&lt;ref&gt;MathWorld: BBP Formula [http://mathworld.wolfram.com/BBPFormula.html Wolfram.com]&lt;/ref&gt;
: &lt;math&gt;\pi=\sum_{n=0}^\infty \left(\frac{4}{8n+1}-\frac{2}{8n+4}-\frac{1}{8n+5}-\frac{1}{8n+6}\right)\left(\frac{1}{16}\right)^n&lt;/math&gt;
In 1996, Simon Plouffe derived an algorithm to extract the {{math|n}}th decimal digit of {{pi}} (using base{{nbsp}}10 math to extract a base{{nbsp}}10 digit), and which can do so with an improved speed of {{math|''O''(''n''&lt;sup&gt;3&lt;/sup&gt;(log ''n'')&lt;sup&gt;3&lt;/sup&gt;)}} time. The algorithm requires virtually no memory for the storage of an array or matrix so the one-millionth digit of {{pi}} can be computed using a pocket calculator.&lt;ref&gt;{{cite arXiv|eprint=0912.0303v1 |last1=Plouffe |first1=Simon |title=On the computation of the n^th decimal digit of various transcendental numbers |class=math.NT |year=2009 }}&lt;/ref&gt; However, it would be quite tedious and impractical to do so.
: &lt;math&gt;\pi+3=\sum_{n=1}^\infty \frac{n2^nn!^2}{(2n)!}&lt;/math&gt;
The calculation speed of Plouffe's formula was improved to {{math|''O''(''n''&lt;sup&gt;2&lt;/sup&gt;)}} by [[Fabrice Bellard]], who derived an alternative formula (albeit only in base{{nbsp}}2 math) for computing {{pi}}.&lt;ref&gt;Bellard's Website: [http://bellard.org/pi/pi_n2/pi_n2.html Bellard.org]&lt;/ref&gt;
: &lt;math&gt;\pi=\frac{1}{2^6}\sum_{n=0}^\infty \frac{(-1)^n}{2^{10n}} \left (-\frac{2^5}{4n+1}-\frac{1}{4n+3}+\frac{2^8}{10n+1}-\frac{2^6}{10n+3}-\frac{2^2}{10n+5}-\frac{2^2}{10n+7}+\frac{1}{10n+9}\right )&lt;/math&gt;

==Efficient methods==
Many other expressions for {{pi}} were developed and published by Indian mathematician [[Srinivasa Ramanujan]]. He worked with mathematician [[Godfrey Harold Hardy]] in England for a number of years.

Extremely long decimal expansions of {{pi}} are typically computed with the [[Gauss–Legendre algorithm]] and [[Borwein's algorithm]]; the [[Salamin–Brent algorithm]], which was invented in 1976, has also been used.

In 1997, [[David H. Bailey]], [[Peter Borwein]] and [[Simon Plouffe]] published a paper (Bailey, 1997) on [[Bailey–Borwein–Plouffe formula|a new formula]] for {{pi}} as an [[infinite series]]:
: &lt;math&gt;\pi = \sum_{k = 0}^\infty \frac{1}{16^k}
\left( \frac{4}{8k + 1} - \frac{2}{8k + 4} - \frac{1}{8k + 5} - \frac{1}{8k + 6}\right).&lt;/math&gt;

This formula permits one to fairly readily compute the ''k''th [[Binary numeral system|binary]] or [[hexadecimal]] digit of {{pi}}, without having to compute the preceding ''k''&amp;nbsp;−&amp;nbsp;1 digits. Bailey's website&lt;ref&gt;{{cite web|url=http://crd.lbl.gov/~dhbailey/|title=David H Bailey|website=crd.LBL.gov|access-date=11 December 2017}}&lt;/ref&gt; contains the derivation as well as implementations in various [[programming language]]s. The [[PiHex]] project computed 64&amp;nbsp;bits around the [[Names of large numbers|quadrillion]]th bit of {{pi}} (which turns out to be 0).

[[Fabrice Bellard]] further improved on BBP with [[Bellard's formula|his formula]]:&lt;ref&gt;{{cite web|url=http://www.pi314.net/eng/bellard.php |title=The world of Pi - Bellard |publisher=Pi314.net |date=2013-04-13 |accessdate=2016-04-18}}&lt;/ref&gt;
:&lt;math&gt;\pi = \frac{1}{2^6} \sum_{n=0}^{\infty} \frac{{(-1)}^n}{2^{10n}} \left( - \frac{2^5}{4n+1} - \frac{1}{4n+3} + \frac{2^8}{10n+1} - \frac{2^6}{10n+3} - \frac{2^2}{10n+5} - \frac{2^2}{10n+7} + \frac{1}{10n+9} \right)&lt;/math&gt;

Other formulae that have been used to compute estimates of {{pi}} include:
:&lt;math&gt;
\frac{\pi}{2}=\sum_{k=0}^\infty\frac{k!}{(2k+1)!!}=\sum_{k=0}^{\infty}\frac{2^k k!^2}{(2k+1)!} =1+\frac{1}{3}\left(1+\frac{2}{5}\left(1+\frac{3}{7}\left(1+\cdots\right)\right)\right)&lt;/math&gt;
:[[Isaac Newton|Newton]].
:&lt;math&gt; \frac{1}{\pi} = \frac{2\sqrt{2}}{9801} \sum^\infty_{k=0} \frac{(4k)!(1103+26390k)}{(k!)^4 396^{4k}}&lt;/math&gt;
:[[Srinivasa Ramanujan]].
This converges extraordinarily rapidly. Ramanujan's work is the basis for the fastest algorithms used, as of the turn of the millennium, to calculate {{pi}}.
:&lt;math&gt; \frac{1}{\pi} = 12 \sum^\infty_{k=0} \frac{(-1)^k (6k)! (13591409 + 545140134k)}{(3k)!(k!)^3 640320^{3k + 3/2}}&lt;/math&gt;
:[[David Chudnovsky (mathematician)|David Chudnovsky]] and [[Gregory Chudnovsky]].

==Projects==

===Pi Hex===
[[PiHex|Pi Hex]] was a project to compute three specific binary digits of {{pi}} using a distributed network of several hundred computers. In 2000, after two years, the project finished computing the five trillionth (5*10&lt;sup&gt;12&lt;/sup&gt;), the forty trillionth, and the quadrillionth (10&lt;sup&gt;15&lt;/sup&gt;) bits. All three of them turned out to be 0.{{cn|date=January 2017}}

==Software for calculating {{pi}}==
Over the years, several programs have been written for calculating {{pi}} to [[arbitrary-precision arithmetic|many digits]] on [[personal computer]]s.

===General purpose===
Most [[computer algebra system]]s can calculate {{pi}} and other common [[mathematical constant]]s to any desired precision.

Functions for calculating {{pi}} are also included in many general [[Library (computing)|libraries]] for [[arbitrary-precision arithmetic]], for instance [[Class Library for Numbers]] and [[MPFR]].

===Special purpose===
Programs designed for calculating {{pi}} may have better performance than general-purpose mathematical software. They typically implement [[checkpointing]] and efficient [[paging|disk swapping]] to facilitate extremely long-running and memory-expensive computations.
* '''{{math|''y''}}-cruncher''' by Alexander Yee&lt;ref name="Yee2016"/&gt; is the program which Shigeru Kondo used to compute the current [[#21st century – current claimed world record|world record number of digits]]. {{math|''y''}}-cruncher can also be used to calculate other constants and holds world records for several of them.
* '''PiFast''' by Xavier Gourdon was the fastest program for [[Microsoft Windows]] in 2003. According to its author, it can compute one million digits in 3.5 seconds on a 2.4&amp;nbsp;GHz [[Pentium 4]].&lt;ref&gt;"[http://numbers.computation.free.fr/Constants/PiProgram/timings.html PiFast timings]"&lt;/ref&gt; PiFast can also compute other irrational numbers like ''[[e (mathematical constant)|{{math|''e''}}]]'' and [[square root of 2|{{math|{{radic|2}}}}]]. It can also work at lesser efficiency with very little memory (down to a few tens of megabytes to compute well over a billion (10&lt;sup&gt;9&lt;/sup&gt;) digits). This tool is a popular benchmark in the [[overclocking]] community. PiFast 4.4 is available from [http://members.shaw.ca/francislyster/pi/pi.html Stu's Pi page]. PiFast 4.3 is available from Gourdon's page.
* '''QuickPi''' by Steve Pagliarulo for Windows is faster than PiFast for runs of under 400 million digits. Version 4.5 is available on Stu's Pi Page below. Like PiFast, QuickPi can also compute other irrational numbers like {{math|''e''}}, {{math|{{radic|2}}}}, and [[square root of 3|{{math|{{radic|3}}}}]]. The software may be obtained from the Pi-Hacks Yahoo! forum, or from [http://members.shaw.ca/francislyster/pi/pi.html Stu's Pi page].
* '''[[Super PI]]''' by Kanada Laboratory&lt;ref&gt;{{cite web|url=http://pi2.cc.u-tokyo.ac.jp/index.html |title=Kanada Laboratory home page |date=10 August 2010 |author1=Takahashi, Daisuke |author2=Kanada, Yasumasa |publisher=University of Tokyo |accessdate=1 May 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20110824110203/http://pi2.cc.u-tokyo.ac.jp/index.html |archivedate=24 August 2011 |df=dmy }}&lt;/ref&gt; in the University of Tokyo is the program for Microsoft Windows for runs from 16,000 to 33,550,000 digits. It can compute one million digits in 40 minutes, two million digits in 90 minutes and four million digits in 220 minutes on a Pentium 90&amp;nbsp;MHz. Super PI version 1.1 is available from [https://web.archive.org/web/20111210155704/http://filecluster.com/Home-Education/E-books-Literature/Download-Super-PI.html Super PI 1.1 page].

==Notes==
{{Reflist|30em}}

==References==
* {{Cite journal
 | author1 = [[David H. Bailey|Bailey, David H.]] |author2 = [[Peter Borwein|Borwein, Peter B.]] |author3 = [[Simon Plouffe|Plouffe, Simon]] |last-author-amp=yes
 |date=April 1997
 | title = On the Rapid Computation of Various Polylogarithmic Constants
 | journal = Mathematics of Computation
 | volume = 66 | issue = 218 | pages = 903–913
 | url = http://crd.lbl.gov/~dhbailey/dhbpapers/digits.pdf
 | doi = 10.1090/S0025-5718-97-00856-9
 }}
* {{citation|first=Petr|last=Beckmann|title=[[A History of π|A History of {{pi}}]] |year=1971|publisher=St. Martin's Press|place=New York|isbn=978-0-88029-418-8|mr=0449960}}
* {{citation|first=Howard|last=Eves|title=An Introduction to the History of Mathematics|year=1992|edition=6th|publisher=Saunders College Publishing|isbn=0-03-029558-0}}
* {{Cite book
 | author = Joseph, George G.
 | year =2000
 | title = The Crest of the Peacock: Non-European Roots of Mathematics
 | edition=New ed., London : Penguin
 | isbn=0-14-027778-1
 | publisher = Penguin
 | location = London
 }}
* {{Cite book
 |author1=Jackson, K  |author2=Stamp, J.
 | year =2002
 | title = Pyramid: Beyond Imagination. Inside the Great Pyramid of Giza
 | publisher = BBC
 | location = London
 }}

{{DEFAULTSORT:Approximations of Pi}}
[[Category:Approximations]]
[[Category:History of mathematics]]
[[Category:Pi]]
[[Category:Real transcendental numbers]]</text>
      <sha1>pu008q8i0knj4w6lg4dq48nwfw4tu6f</sha1>
    </revision>
  </page>
  <page>
    <title>Band sum</title>
    <ns>0</ns>
    <id>1367647</id>
    <revision>
      <id>746817753</id>
      <parentid>608151863</parentid>
      <timestamp>2016-10-29T19:15:16Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1284">In [[geometric topology]], a '''band sum''' of two ''n''-dimensional knots ''K''&lt;sub&gt;1&lt;/sub&gt; and ''K''&lt;sub&gt;2&lt;/sub&gt; along an (''n''&amp;nbsp;+&amp;nbsp;1)-dimensional 1-handle ''h'' called a ''band''  is an ''n''-dimensional knot ''K'' such that:

* There is an (''n''&amp;nbsp;+&amp;nbsp;1)-dimensional 1-handle ''h'' connected to (''K''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''K''&lt;sub&gt;2&lt;/sub&gt;) embedded in ''S''&lt;sup&gt;''n''+2&lt;/sup&gt;.
* There are points &lt;math&gt;p_1\in K_1&lt;/math&gt; and &lt;math&gt;p_2\in K_2&lt;/math&gt; such that &lt;math&gt;h&lt;/math&gt; is attached to &lt;math&gt;K_1\sqcup K_2&lt;/math&gt; along &lt;math&gt;p_1\sqcup p_2&lt;/math&gt;.

''K'' is the ''n''-dimensional knot obtained by this surgery.

A band sum is thus a generalization of the usual [[connected sum]] of knots.

==See also==
*[[Manifold decomposition]]

==References==
*{{citation|title=Knots and Links|first=Peter R.|last=Cromwell|publisher=Cambridge University Press|year=2004|isbn=9780521548311|page=90|url=https://books.google.com/books?id=djvbTNR2dCwC&amp;pg=PA90}}.
*{{citation|title=Survey on Knot Theory|first=Akio|last=Kawauchi|publisher=Springer|year=1996|isbn=9783764351243|page=31|url=https://books.google.com/books?id=gWbyJn7c5G0C&amp;pg=PA31}}.

[[Category:Topology]]
[[Category:Differential topology]]
[[Category:Knot theory]]
[[Category:Binary operations]]


{{knottheory-stub}}</text>
      <sha1>2mmpc4isqvo2qn3uep3aatm7jivjo8k</sha1>
    </revision>
  </page>
  <page>
    <title>Blake canonical form</title>
    <ns>0</ns>
    <id>39986184</id>
    <revision>
      <id>800983455</id>
      <parentid>797759780</parentid>
      <timestamp>2017-09-16T23:29:12Z</timestamp>
      <contributor>
        <username>Shaded0</username>
        <id>5264861</id>
      </contributor>
      <minor/>
      <comment>clean up and formatting using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3542">In [[Boolean logic]], a [[Formula (mathematical logic)|formula]] for a Boolean function  ''f'' is in '''Blake canonical form''' ('''BCF'''),&lt;ref name="Brown_2012"/&gt; also called the '''complete sum of prime implicants''',&lt;ref&gt;{{cite book |author-first=Tsutomu |author-last=Sasao |chapter=Ternary Decision Diagrams and their Applications |editor-first1=Tsutomu |editor-last1=Sasao |editor-first2=Masahira |editor-last2=Fujita |title=Representations of Discrete Functions |isbn=0792397207 |date=1996 |page=278|url=https://link.springer.com/chapter/10.1007/978-1-4613-1385-4_12}}&lt;/ref&gt; the '''complete sum''',&lt;ref name="kandel"&gt;{{cite book |author-first=Abraham |author-last=Kandel |title=Foundations of Digital Logic Design |page=177|url=https://books.google.com/books?id=4sX9fTGRo7QC&amp;printsec=frontcover#v=onepage&amp;q=%22complete%20sum%22&amp;f=false}}&lt;/ref&gt; or the '''disjunctive prime form''',&lt;ref&gt;[[Donald E. Knuth]], ''[[The Art of Computer Programming]]'' '''4A''': ''Combinatorial Algorithms, Part 1'', 2011, p. 54&lt;/ref&gt; when it is a [[logical disjunction|disjunction]] of all the [[prime implicant]]s of ''f''.&lt;ref name="Brown_2012"/&gt; The Blake canonical form is a [[disjunctive normal form]].

The Blake canonical form is not necessarily [[Boolean minimization|minimal]], however all the terms of a minimal sum are contained in the Blake canonical form.&lt;ref name="kandel"/&gt;

It was introduced in 1937 by Archie Blake, who called it the "simplified canonical form";&lt;ref name="Blake_1937"/&gt;&lt;ref name="Kinsey_1938"/&gt; it was named in honor of Blake by Frank Markham Brown in 1990.&lt;ref name="Brown_2012"/&gt;

Blake discussed three methods for calculating the canonical form: exhaustion of implicants, iterated [[consensus (boolean algebra)|consensus]], and multiplication. The iterated consensus method was rediscovered by Samson and Mills, [[Willard van Orman Quine|Quine]], and Bing.&lt;ref name="Brown_2012"/&gt;

==See also==
* [[Horn clause]]
* [[Consensus theorem]]

==References==
{{reflist|refs=
&lt;ref name="Brown_2012"&gt;{{cite book |title=Boolean Reasoning - The Logic of Boolean Equations |chapter=Chapter 4: The Blake Canonical Form |author-first=Frank Markham |author-last=Brown |edition=&lt;!-- 2012 --&gt;reissue of 2nd |publisher=[[Dover Publications, Inc.]] |location=Mineola, New York |date=2012 |orig-year=2003, 1990 |isbn=978-0-486-42785-0 |id={{ISBN|0-486-42785-4}} |pages=77ff.}} [&lt;!-- 1st edition --&gt;http://www2.fiit.stuba.sk/~kvasnicka/Free%20books/Brown_Boolean%20Reasoning.pdf&lt;!-- https://web.archive.org/web/20170416231752/http://www2.fiit.stuba.sk/~kvasnicka/Free%20books/Brown_Boolean%20Reasoning.pdf --&gt;]&lt;/ref&gt;
&lt;ref name="Blake_1937"&gt;{{cite book |title=Canonical expressions in Boolean algebra |author-first=Archie |author-last=Blake |type=Dissertation |publisher=[[University of Chicago Libraries]] |location=Department of Mathematics, [[University of Chicago]] |date=1937}}&lt;/ref&gt;
&lt;ref name="Kinsey_1938"&gt;{{cite journal |title=Blake, Archie. Canonical expressions in Boolean algebra, Department of Mathematics, University of Chicago, 1937 |type=Review |editor-first=J. C. C. |editor-last=McKinsey |editor-link=John Charles Chenoweth McKinsey |journal=[[The Journal of Symbolic Logic]] |volume=3 |number=2:93 |date=June 1938 |doi=10.2307/2267634 |jstor=2267634 |url=https://www.researchgate.net/publication/275744873_Blake_Archie_Canonical_expressions_in_Boolean_algebra_Dissertation_Chicago_1937_Lithographed_The_University_of_Chicago_Libraries_Chicago_1938_ii_60_pp}}&lt;/ref&gt;
}}

[[Category:Normal forms (logic)]]


{{mathlogic-stub}}</text>
      <sha1>1dx3zh20cwsnxf9sj0ma3gqt4yf6kev</sha1>
    </revision>
  </page>
  <page>
    <title>Brewer sum</title>
    <ns>0</ns>
    <id>37184509</id>
    <revision>
      <id>795770350</id>
      <parentid>748800032</parentid>
      <timestamp>2017-08-16T10:28:02Z</timestamp>
      <contributor>
        <username>Quinton Feldberg</username>
        <id>29380370</id>
      </contributor>
      <minor/>
      <comment>fix citations</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1855">In [[mathematics]], '''Brewer sums''' are finite [[character sum]] introduced by {{harvs|txt|last=Brewer|year1=1961|year2=1966}} related to [[Jacobsthal sum]]s.

==Definition==

The Brewer sum is given by
:&lt;math&gt;\Lambda_n(a) = \sum_{x\bmod p}\binom{D_{n+1}(x,a)}{p}&lt;/math&gt;
where ''D''&lt;sub&gt;''n''&lt;/sub&gt; is the [[Dickson polynomial]] (or "Brewer polynomial") given by 
:&lt;math&gt; D_{0}(x,a)=2,\quad D_1(x,a)=x,  \quad D_{n+1}(x,a)=xD_n(x,a)-aD_{n-1}(x,a)&lt;/math&gt;
and () is the [[Legendre symbol]].

The Brewer sum is zero when ''n'' is [[coprime]] to ''q''&lt;sup&gt;2&lt;/sup&gt;−1.

==References==
{{reflist}}
*{{Citation | last1=Brewer | first1=B. W. | title=On certain character sums | jstor=1993392 | mr=0120202 | zbl=0103.03205  | year=1961 | journal=[[Transactions of the American Mathematical Society]] | issn=0002-9947 | volume=99 | issue=2 | pages=241–245 | doi=10.2307/1993392}}
*{{Citation | last1=Brewer | first1=B. W. | title=On primes of the form u²+5v² | jstor=2035200 | mr=0188171 | zbl=0147.29801  | year=1966 | journal=[[Proceedings of the American Mathematical Society]] | issn=0002-9939 | volume=17 | issue=2 | pages=502–509 | doi=10.2307/2035200}}
*{{Citation | last1=Berndt | first1=Bruce C. | last2=Evans | first2=Ronald J. | title=Sums of Gauss, Eisenstein, Jacobi, Jacobsthal, and Brewer | url=http://projecteuclid.org/getRecord?id=euclid.ijm/1256048104 | mr=537798 | zbl=0393.12029 | year=1979 | journal=Illinois Journal of Mathematics | issn=0019-2082 | volume=23 | issue=3 | pages=374–437}}
*{{citation | zbl=0866.11069 | last1=Lidl | first1=Rudolf | last2=Niederreiter | first2=Harald | author2-link = Harald Niederreiter | title=Finite fields | edition=2nd | series=Encyclopedia of Mathematics and Its Applications | volume=20 | publisher=[[Cambridge University Press]] | year=1997 | isbn=0-521-39231-4 }}

[[Category:Number theory]]</text>
      <sha1>g3atrepqtlnhjvtib84405omwseam22</sha1>
    </revision>
  </page>
  <page>
    <title>Cobordism ring</title>
    <ns>0</ns>
    <id>44846510</id>
    <revision>
      <id>641740726</id>
      <parentid>641253524</parentid>
      <timestamp>2015-01-09T15:28:35Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1846">In mathematics, the '''oriented cobordism ring''' is a [[ring (mathematics)|ring]] where elements are oriented [[cobordism class]]es&lt;ref&gt;Two compact oriented manifolds ''M'', ''N'' are [[oriented cobordant]] if there is a compact manifold with boundary such that the boundary is diffeomorphic to the disjoint union of ''M'' with the given orientation and ''N'' with the reversed orientation.&lt;/ref&gt; of manifolds, the multiplication is given by the Cartesian product of manifolds and the addition is given as the disjoint union of manifolds. The ring is [[graded ring|graded]] by dimensions of manifolds and is denoted by
:&lt;math&gt;\Omega^{SO}_* = \oplus_0^\infty \Omega^{SO}_n&lt;/math&gt;
where &lt;math&gt;\Omega^{SO}_n&lt;/math&gt; consists of oriented cobordism classes of manifolds of dimension ''n''. One can also define an '''unoriented cobordism ring''', denoted by &lt;math&gt;\Omega^O_*&lt;/math&gt;. If ''O'' is replaced ''U'', then one gets the [[complex cobordism ring]], oriented or unoriented.

In general, one writes &lt;math&gt;\Omega^B_*&lt;/math&gt; for the cobordism ring of manifolds with structure ''B''.

A theorem of Thom&lt;ref&gt;http://math.northwestern.edu/~jnkf/classes/mflds/3thom.pdf&lt;/ref&gt; says:
:&lt;math&gt;\Omega^O_n = \pi_{n}(MO)&lt;/math&gt;
where ''MO'' is the [[Thom spectrum]].

== Notes ==
{{reflist}}

== References ==
* {{Citation | last1=Milnor | first1=John Willard | author1-link=John Milnor | last2=Stasheff | first2=James D. |author2-link=Jim Stasheff| title=Characteristic classes | publisher=Princeton University Press; University of Tokyo Press | series=Annals of Mathematics Studies | isbn=978-0-691-08122-9 | year=1974 | volume=76}}

== External links ==
*http://ncatlab.org:8080/nlab/show/cobordism+ring
*https://amathew.wordpress.com/2012/05/23/the-unoriented-cobordism-ring/, a blog post by Akhil Mathew

{{topology-stub}}

[[Category:Algebraic topology]]</text>
      <sha1>25y3o7r3hzq362n94j0iyt1gro97y2j</sha1>
    </revision>
  </page>
  <page>
    <title>Combinatory logic</title>
    <ns>0</ns>
    <id>149848</id>
    <revision>
      <id>868042847</id>
      <parentid>861772838</parentid>
      <timestamp>2018-11-09T16:46:48Z</timestamp>
      <contributor>
        <username>Fivlasz</username>
        <id>20569363</id>
      </contributor>
      <comment>Changed the worst-case size of a translated term using the translation ''T''[&amp;nbsp;] and added appropriate citation.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41789">{{distinguish|text=[[combinational logic]], a topic in digital electronics}}

'''Combinatory logic''' is a notation to eliminate the need for [[Quantifier (logic)|quantified]] variables in [[mathematical logic]]. It was introduced by [[Moses Schönfinkel]]&lt;ref&gt;{{cite journal |first=Moses |last=Schönfinkel |authorlink=Moses Schönfinkel |year=1924 |url=http://www.cip.ifi.lmu.de/~langeh/test/1924%20-%20Schoenfinkel%20-%20Ueber%20die%20Bausteine%20der%20mathematischen%20Logik.pdf |title=Über die Bausteine der mathematischen Logik |journal=Mathematische Annalen |volume=92 |pages=305–316 |doi=10.1007/bf01448013}} Translated by Stefan Bauer-Mengelberg as "On the building blocks of mathematical logic" in [[Jean van Heijenoort]], 1967. ''A Source Book in Mathematical Logic, 1879&amp;ndash;1931''. Harvard Univ. Press: 355&amp;ndash;66.&lt;/ref&gt; and [[Haskell Curry]],&lt;ref&gt;{{cite journal|last=Curry|first=Haskell Brooks|title=Grundlagen der Kombinatorischen Logik|journal=American Journal of Mathematics|year=1930|volume=52|issue=3|pages=509–536|authorlink=Haskell Curry|trans-title=Foundations of combinatorial logic|publisher=The Johns Hopkins University Press|language=German|doi=10.2307/2370619|jstor=2370619}}&lt;/ref&gt; and has more recently been used in [[computer science]] as a theoretical model of [[computation]] and also as a basis for the design of [[functional programming languages]]. It is based on '''combinators''' which were introduced by [[Moses Schönfinkel|Schönfinkel]] in 1920 with the idea of providing an analogous way to build up functions - and to remove any mention of variables - particularly in predicate logic.&lt;ref&gt;{{cite book|last=Wolfram|first=Stephen|title=A New Kind of Science|publisher=Wolfram Media, Inc.|year=2002|page=1121|isbn=1-57955-008-8}}&lt;/ref&gt;  A combinator is a [[higher-order function]] that uses only function application and earlier defined combinators to define a result from its arguments.

==In mathematics==
Combinatory logic was originally intended as a 'pre-logic' that would clarify the role of [[quantifier (logic)|quantified variables]] in logic, essentially by eliminating them. Another way of eliminating quantified variables is [[Willard Van Orman Quine|Quine's]] [[predicate functor logic]]. While the [[expressive power (computer science)|expressive power]] of combinatory logic typically exceeds that of [[first-order logic]], the expressive power of [[predicate functor logic]] is identical to that of first order logic ([[#Quine 1960 1966|Quine 1960, 1966, 1976]]).

The original inventor of combinatory logic, [[Moses Schönfinkel]], published nothing on combinatory logic after his original 1924 paper. [[Haskell Curry]] rediscovered the combinators while working as an instructor at [[Princeton University]] in late 1927.&lt;ref name="Seldin 2006"&gt;{{cite journal|last=Seldin|first=Jonathan|title=The Logic of Curry and Church|year=2008|url=http://people.uleth.ca/%7Ejonathan.seldin/CCL.pdf}}&lt;/ref&gt; In the latter 1930s, [[Alonzo Church]] and his students at Princeton invented a rival formalism for functional abstraction, the [[lambda calculus]], which proved more popular than combinatory logic. The upshot of these historical contingencies was that until theoretical computer science began taking an interest in combinatory logic in the 1960s and 1970s, nearly all work on the subject was by [[Haskell Curry]] and his students, or by [[Robert Feys]] in [[Belgium]]. Curry and Feys (1958), and Curry ''et al.'' (1972) survey the early history of combinatory logic. For a more modern treatment of combinatory logic and the lambda calculus together, see the book by [[Henk Barendregt|Barendregt]],{{sfn|Barendregt|1984}} which reviews the [[model theory|models]] [[Dana Scott]] devised for combinatory logic in the 1960s and 1970s.
&lt;!-- This section needs a LOT of filling in!!! --&gt;

==In computing==
In [[computer science]], combinatory logic is used as a simplified model of [[computation]], used in [[computability theory]] and [[proof theory]]. Despite its simplicity, combinatory logic captures many essential features of computation.

Combinatory logic can be viewed as a variant of the [[lambda calculus]], in which lambda expressions (representing functional abstraction) are replaced by a limited set of ''combinators'', primitive functions from which [[bound variable]]s are absent. It is easy to transform lambda expressions into combinator expressions, and combinator reduction is much simpler than lambda reduction. Hence combinatory logic has been used to model some [[non-strict programming language|non-strict]] [[functional programming]] languages and [[graph reduction machine|hardware]]. The purest form of this view is the programming language [[Unlambda]], whose sole primitives are the S and K combinators augmented with character input/output. Although not a practical programming language, Unlambda is of some theoretical interest.

Combinatory logic can be given a variety of interpretations. Many early papers by Curry showed how to translate axiom sets for conventional logic into combinatory logic equations (Hindley and Meredith 1990). [[Dana Scott]] in the 1960s and 1970s showed how to marry [[model theory]] and combinatory logic.

== Summary of lambda calculus ==
{{main|Lambda calculus}}

Lambda calculus is concerned with objects called ''lambda-terms'', which can be represented by
the following three forms of strings:

*       {{mvar|v}}
*       {{tmath|\lambda v.E_1}}
*       {{tmath|(E_1 E_2)}}

where ''v'' is a variable name drawn from a predefined infinite set of
variable names, and {{tmath|E_1}} and {{tmath|E_2}} are lambda-terms.

Terms of the form {{tmath|\lambda v.E_1}} are called ''abstractions''. The variable ''v'' is
called the [[formal parameter]] of the abstraction, and {{tmath|E_1}} is the ''body''
of the abstraction.  The term {{tmath|\lambda v.E_1}} represents the function which, applied
to an argument, binds the formal parameter ''v'' to the argument and then
computes the resulting value of {{tmath|E_1}}&amp;mdash; that is, it returns {{tmath|E_1}}, with
every occurrence of ''v'' replaced by the argument.

Terms of the form {{tmath|(E_1 E_2)}} are called ''applications''. Applications model
function invocation or execution: the function represented by {{tmath|E_1}} is to be
invoked, with {{tmath|E_2}} as its argument, and the result is computed. If {{tmath|E_1}}
(sometimes called the ''applicand'') is an abstraction, the term may be
''reduced'': {{tmath|E_2}}, the argument, may be substituted into the body of {{tmath|E_1}}
in place of the formal parameter of {{tmath|E_1}}, and the result is a new lambda
term which is ''equivalent'' to the old one. If a lambda term contains no
subterms of the form {{tmath|((\lambda v.E_1) E_2)}} then it cannot be reduced, and is said to
be in [[Beta normal form|normal form]].

The expression {{tmath|E[v :{{=}} a]}}  represents the result of taking the term {{mvar|E}} and replacing all free occurrences of {{mvar|v}} in it with {{mvar|a}}.  Thus we write

:{{tmath|((\lambda v.E) a) \Rightarrow E[v :{{=}} a]}}

By convention, we take {{tmath|(a b c d ... z)}} as shorthand for {{tmath|(...(((a b) c) d) ... z)}} (i.e., application is [[Associative#Non-associativity|left associative]]).

The motivation for this definition of reduction is that it captures
the essential behavior of all mathematical functions. For example,
consider the function that computes the square of a number. We might
write

:The square of ''x'' is {{tmath|x*x}}

(Using "{{tmath|*}}" to indicate multiplication.)  ''x'' here is the [[formal parameter]] of the function. To evaluate the square for a particular
argument, say 3, we insert it into the definition in place of the
formal parameter:

:The square of 3 is {{tmath|3*3}}

To evaluate the resulting expression {{tmath|3*3}}, we would have to resort to
our knowledge of multiplication and the number 3. Since any
computation is simply a composition of the evaluation of suitable
functions on suitable primitive arguments, this simple substitution
principle suffices to capture the essential mechanism of computation.
Moreover, in lambda calculus, notions such as '3' and '{{tmath|*}}' can be
represented without any need for externally defined primitive
operators or constants. It is possible to identify terms in lambda calculus, which, when suitably interpreted, behave like the
number 3 and like the multiplication operator, q.v. [[Church encoding]].

Lambda calculus is known to be computationally equivalent in power to
many other plausible models for computation (including [[Turing machine]]s); that is, any calculation that can be accomplished in any
of these other models can be expressed in lambda calculus, and
vice versa. According to the [[Church-Turing thesis]], both models
can express any possible computation.

It is perhaps surprising that lambda-calculus can represent any
conceivable computation using only the simple notions of function
abstraction and application based on simple textual substitution of
terms for variables. But even more remarkable is that abstraction is
not even required. ''Combinatory logic'' is a model of computation
equivalent to lambda calculus, but without abstraction.  The advantage
of this is that evaluating expressions in lambda calculus is quite complicated
because the semantics of substitution must be specified with great care to
avoid variable capture problems.  In contrast, evaluating expressions in
combinatory logic is much simpler, because there is no notion of substitution.

== Combinatory calculi ==

Since abstraction is the only way to manufacture functions in the
lambda calculus, something must replace it in the combinatory
calculus.  Instead of abstraction, combinatory calculus provides a
limited set of primitive functions out of which other functions may be
built.

=== Combinatory terms ===

A combinatory term has one of the following forms:
*{{mvar|x}}
*{{mvar|P}}
*{{tmath|(E_1 E_2)}}
where {{mvar|x}} is a variable, {{mvar|P}} is one of the primitive functions, and {{tmath|(E_1 E_2)}} is the application of combinatory terms {{tmath|E_1}} and {{tmath|E_2}}.  The primitive functions themselves are ''combinators'', or functions that, when seen as lambda terms, contain no [[free variable]]s.
To shorten the notations, a general convention is that {{tmath|(E_1 E_2 E_3 ... E_n)}}, or even {{tmath|E_1 E_2 E_3... E_n}}, denotes the term {{tmath|(...((E_1 E_2) E_3)... E_n)}}. This is the same general convention (left-associativity) as for multiple application in lambda calculus.

=== Reduction in combinatory logic ===

In combinatory logic, each primitive combinator comes with a reduction rule of the form

:{{math|1=(''P'' ''x''&lt;sub&gt;1&lt;/sub&gt; ... ''x&lt;sub&gt;n&lt;/sub&gt;'') = ''E''}}

where ''E'' is a term mentioning only variables from the set {{math|{{mset|''x''&lt;sub&gt;1&lt;/sub&gt; ... ''x&lt;sub&gt;n&lt;/sub&gt;''}}}}. It is in this way that primitive combinators behave as functions.

=== Examples of combinators ===

The simplest example of a combinator is '''I''', the identity
combinator, defined by

:('''I''' ''x'') = ''x''

for all terms ''x''.  Another simple combinator is '''K''', which
manufactures constant functions:  ('''K''' ''x'') is the function which,
for any argument, returns ''x'', so we say

:(('''K''' ''x'') ''y'') = ''x''

for all terms ''x'' and ''y''.  Or, following the convention for
multiple application,

:('''K''' ''x'' ''y'') = ''x''

A third combinator is '''S''', which is a generalized version of
application:

:('''S''' ''x y z'') = (''x z'' (''y z''))

'''S''' applies ''x'' to ''y'' after first substituting ''z'' into
each of them. Or put another way, ''x'' is applied to ''y'' inside the
environment ''z''.

Given '''S''' and '''K''', '''I''' itself is unnecessary, since it can
be built from the other two:

:(('''S K K''') ''x'')
::  =  ('''S K K''' ''x'')
::  =  ('''K''' ''x'' ('''K''' ''x''))
::  =  ''x''

for any term ''x''.  Note that although (('''S K K''')
''x'') = ('''I''' ''x'') for any ''x'', ('''S K K''')
itself is not equal to '''I'''.  We say the terms are [[extensional equality|extensionally equal]].  Extensional equality captures the
mathematical notion of the equality of functions: that two functions
are ''equal'' if they always produce the same results for the same
arguments.  In contrast, the terms themselves, together with the
reduction of primitive combinators, capture the notion of
''intensional equality'' of functions: that two functions are ''equal''
only if they have identical implementations up to the expansion of primitive
combinators when these ones are applied to enough arguments.  There are many ways to
implement an identity function; ('''S K K''') and '''I'''
are among these ways.  ('''S K S''') is yet another.  We
will use the word ''equivalent'' to indicate extensional equality,
reserving ''equal'' for identical combinatorial terms.

A more interesting combinator is the [[fixed point combinator]] or '''Y''' combinator, which can be used to implement [[recursion]].

=== Completeness of the S-K basis ===

'''S''' and '''K''' can be composed to produce combinators that are extensionally equal to ''any'' lambda term, and therefore, by Church's thesis, to any computable function whatsoever.  The proof is to present a transformation, ''T''[&amp;nbsp;], which converts an arbitrary lambda term into an equivalent combinator.

''T''[&amp;nbsp;] may be defined as follows:

#       ''T''[''x'']          =&gt; ''x''
#       ''T''[(''E''₁ ''E''₂)]    =&gt; (''T''[''E''₁] ''T''[''E''₂])
#       ''T''[''λx''.''E'']       =&gt; ('''K''' ''T''[''E''])         (if ''x'' does not occur free in ''E'')
#       ''T''[''λx''.''x'']       =&gt; '''I'''
#       ''T''[''λx''.''λy''.''E'']    =&gt; ''T''{{!(}}''λx''.''T''{{!(}}''λy''.''E''{{))!}} (if ''x'' occurs free in ''E'')
#       ''T''[''λx''.(''E''₁ ''E''₂)] =&gt; ('''S''' ''T''[''λx''.''E''₁] ''T''[''λx''.''E₂'']) (if ''x'' occurs free in ''E''₁ or ''E''₂)
This process is also known as ''abstraction elimination''. This definition is exhaustive: any lambda expression will be subject to exactly one of these rules (see [[Combinatory logic#Summary of lambda calculus|Summary of lambda calculus]] above).

It is related to the process of ''bracket abstraction'', which takes an expression ''E'' built from variables and application and produces a combinator expression [x]E in which the variable x is not free, such that [''x'']''E x'' = ''E'' holds.
A very simple algorithm for bracket abstraction is defined by induction on the structure of expressions as follows:&lt;ref name="Turner 1979"&gt;{{cite journal|last=Turner|first=David A.|authorlink=David Turner (computer scientist)|title=Another Algorithm for Bracket Abstraction|journal=The Journal of Symbolic Logic|volume=44|pages=267–270|year=1979|doi=10.2307/2273733|jstor=2273733}}&lt;/ref&gt;
# [''x'']''y'' := '''K''' ''y''
# [''x'']''x'' := '''I'''
# [''x''](''E₁'' ''E₂'') := '''S'''([''x'']''E₁'')([''x'']''E₂'')
Bracket abstraction induces a translation from lambda terms to combinator expressions, by interpreting lambda-abstractions using the bracket abstraction algorithm.

==== Conversion of a lambda term to an equivalent combinatorial term ====

For example, we will convert the lambda term ''λx''.''λy''.(''y'' ''x'') to a
combinatorial term:

:''T''[''λx''.''λy''.(''y'' ''x'')]
::        = ''T''{{!(}}''λx''.''T''{{!(}}''λy''.(''y'' ''x''){{))!}} (by 5)
::        = ''T''[''λx''.('''S''' ''T''[''λy''.''y''] ''T''[''λy''.''x''])] (by 6)
::        = ''T''[''λx''.('''S I'''       ''T''[''λy''.''x''])] (by 4)
::        = ''T''[''λx''.('''S I'''       ('''K''' ''T''[''x'']))] (by 3)
::        = ''T''[''λx''.('''S I'''       ('''K''' ''x''))] (by 1)
::        = ('''S''' ''T''[''λx''.('''S I''')] ''T''[''λx''.('''K''' ''x'')]) (by 6)
::        = ('''S''' ('''K''' ('''S I'''))   ''T''[''λx''.('''K''' ''x'')]) (by 3)
::        = ('''S''' ('''K''' ('''S I'''))   ('''S''' ''T''[''λx''.'''K'''] ''T''[''λx''.''x''])) (by 6)
::        = ('''S''' ('''K''' ('''S I'''))   ('''S''' ('''K K''') ''T''[''λx''.''x''])) (by 3)
::        = ('''S''' ('''K''' ('''S I'''))   ('''S''' ('''K K''') '''I''')) (by 4)

If we apply this combinatorial term to any two terms ''x'' and ''y'', it
reduces as follows:

:          ('''S''' ('''K''' ('''S''' '''I''')) ('''S''' ('''K''' '''K''') '''I''') x y)
::        = ('''K''' ('''S''' '''I''') x  ('''S''' ('''K''' '''K''')   '''I''' x) y)
::        = ('''S''' '''I''' ('''S''' ('''K''' '''K''')   '''I''' x) y)
::        = ('''I''' y ('''S''' ('''K''' '''K''')   '''I''' x y))
::        = (y ('''S''' ('''K''' '''K''')   '''I''' x y))
::        = (y ('''K''' '''K''' x ('''I''' x) y))
::        = (y ('''K''' ('''I''' x) y))
::        = (y ('''I''' x))
::        = (y x)

The combinatory representation, ('''S''' ('''K''' ('''S I''')) ('''S''' ('''K K''') '''I''')) is much
longer than the representation as a lambda term, ''λx''.''λy''.(y x).  This is typical.  In general, the ''T''[&amp;nbsp;] construction may expand a lambda
term of length ''n'' to a combinatorial term of length
[[Big O notation|Θ]](''n''&lt;sup&gt;3&lt;/sup&gt;) &lt;ref&gt;{{cite journal |last1=Lachowski |first1=Łukasz |title=On the Complexity of the Standard Translation of Lambda Calculus into Combinatory Logic |journal=Reports on Mathematical Logic |date=2018 |issue=53 |pages=19-42 |doi=10.4467/20842589RM.18.002.8835 |url=http://www.ejournals.eu/rml/2018/Number-53/art/12285 |accessdate=9 September 2018}}&lt;/ref&gt;.

==== Explanation of the ''T''[&amp;nbsp;] transformation ====

The ''T''[&amp;nbsp;] transformation is motivated by a desire to eliminate
abstraction.  Two special cases, rules 3 and 4, are trivial: ''λx''.''x'' is
clearly equivalent to '''I''', and ''λx''.''E'' is clearly equivalent to
('''K''' ''T''[''E'']) if ''x'' does not appear free in ''E''.

The first two rules are also simple: Variables convert to themselves,
and applications, which are allowed in combinatory terms, are
converted to combinators simply by converting the applicand and the
argument to combinators.

It is rules 5 and 6 that are of interest.  Rule 5 simply says that to convert a complex abstraction to a combinator, we must first convert its body to a combinator, and then eliminate the abstraction.  Rule 6 actually eliminates the abstraction.

''λx''.(''E''₁ ''E''₂) is a function which takes an argument, say ''a'', and
substitutes it into the lambda term (''E''₁ ''E''₂) in place of ''x'',
yielding (''E''₁ ''E''₂)[''x'' : = ''a''].  But substituting ''a'' into (''E''₁ ''E''₂) in place of ''x'' is just the same as substituting it into both ''E''₁ and ''E''₂, so

:        (''E''₁ ''E''₂)[''x'' := ''a''] = (''E''₁[''x'' := ''a''] ''E''₂[''x'' := ''a''])

:        (''λx''.(''E''₁ ''E''₂) ''a'') = ((''λx''.''E''₁ ''a'') (''λx''.''E''₂ ''a''))
:::::                       = ('''S''' ''λx''.''E''₁ ''λx''.''E''₂ ''a'')
:::::                       = (('''S''' ''λx''.''E₁'' ''λx''.''E''₂) ''a'')

By extensional equality,

:        ''λx''.(''E''₁ ''E''₂)     = ('''S''' ''λx''.''E''₁ ''λx''.''E''₂)

Therefore, to  find  a combinator equivalent to ''λx''.(''E''₁ ''E''₂), it is
sufficient to find a combinator equivalent to ('''S''' ''λx''.''E''₁ ''λx''.''E''₂), and

:        ('''S''' ''T''[''λx''.''E''₁] ''T''[''λx''.''E''₂])

evidently fits the bill.  ''E''₁ and ''E''₂ each contain strictly fewer
applications than (''E''₁ ''E''₂), so the recursion must terminate in a lambda
term with no applications at all—either a variable, or a term of the
form ''λx''.''E''.

=== Simplifications of the transformation ===

==== η-reduction ====

The combinators generated by the ''T''[&amp;nbsp;] transformation can be made
smaller if we take into account the ''η-reduction'' rule:

:        ''T''[''λx''.(''E'' ''x'')] = ''T''[''E'']   (if ''x'' is not free in ''E'')

''λx''.(''E'' x) is the function which takes an argument, ''x'', and
applies the function ''E'' to it; this is extensionally equal to the
function ''E'' itself.  It is therefore sufficient to convert ''E'' to
combinatorial form.

Taking this simplification into account, the example above becomes:

:&amp;nbsp;          ''T''[''λx''.''λy''.(''y'' ''x'')]
:        = ...
:        = ('''S''' ('''K''' ('''S I'''))   ''T''[''λx''.('''K''' ''x'')])
:        = ('''S''' ('''K''' ('''S I'''))   '''K''')                 (by η-reduction)

This combinator is equivalent to the earlier, longer one:

:&amp;nbsp;          ('''S''' ('''K''' ('''S I'''))   '''K''' ''x y'')
:        = ('''K''' ('''S I''') ''x'' ('''K''' ''x'') ''y'')
:        = ('''S I''' ('''K''' ''x'') ''y'')
:        = ('''I''' ''y'' ('''K''' ''x y''))
:        = (''y'' ('''K''' ''x y''))
:        = (''y x'')

Similarly, the original version of the ''T''[&amp;nbsp;] transformation
transformed the identity function ''λf''.''λx''.(''f'' ''x'') into ('''S''' ('''S''' ('''K S''') ('''S''' ('''K K''') '''I''')) ('''K I''')).  With the η-reduction rule, ''λf''.''λx''.(''f'' ''x'') is
transformed into '''I'''.

==== One-point basis ====

There are one-point bases from which every combinator can be composed extensionally equal to ''any'' lambda term. The simplest example of such a basis is {'''X'''} where:

:        '''X''' ≡ ''λx''.((x'''S''')'''K''')

It is not difficult to verify that:
:        '''X''' ('''X''' ('''X''' '''X''')) =&lt;sup&gt;ηβ&lt;/sup&gt; '''K''' and
:        '''X''' ('''X''' ('''X''' ('''X''' '''X'''))) =&lt;sup&gt;ηβ&lt;/sup&gt; '''S'''.

Since {'''K''', '''S'''} is a basis, it follows that {'''X'''} is a basis too. The [[Iota and Jot|Iota]] programming language uses '''X''' as its sole combinator.

Another simple example of a one-point basis is:

:        '''X'''' ≡ ''λx''.(x '''K''' '''S''' '''K''') with
:        ('''X'''' '''X'''') '''X'''' =&lt;sup&gt;β&lt;/sup&gt; '''K''' and
:        '''X'''' ('''X'''' '''X'''') =&lt;sup&gt;β&lt;/sup&gt; '''S'''

'''X' ''' does not need η contraction in order to produce '''K''' and '''S'''. In fact, there exist infinitely many such bases.&lt;ref&gt;{{cite journal | first=Mayer | last=Goldberg | url = http://www.sciencedirect.com/science/article/pii/S0020019003005416 | doi=10.1016/j.ipl.2003.12.005 | volume=89 | year=2004 | title=A construction of one-point bases in extended lambda calculi | journal=Information Processing Letters | pages=281–286}}&lt;/ref&gt;

==== Combinators B, C ====

In addition to '''S''' and '''K''', [[Moses Schönfinkel|Schönfinkel]]'s paper included two combinators which are now called '''B''' and '''C''', with the following reductions:

:        ('''C''' ''f'' ''g'' ''x'') = ((''f'' ''x'') ''g'')
:        ('''B''' ''f'' ''g'' ''x'') = (''f'' (''g'' ''x''))

He also explains how they in turn can be expressed using only '''S''' and '''K''':

: '''B''' = ('''S''' ('''K S''') '''K''') 
: '''C''' = ('''S''' ('''S''' ('''K''' ('''S''' ('''K S''') '''K''')) '''S''') ('''K K'''))

These combinators are extremely useful when translating predicate logic or lambda calculus into combinator expressions. They were also used by [[Haskell Curry|Curry]], and much later by [[David Turner (computer scientist)|David Turner]], whose name has been associated with their computational use. Using them, we can extend the rules for the transformation as follows:

#       ''T''[''x'']          &amp;rArr; ''x''
#       ''T''[(''E₁'' ''E₂'')]    &amp;rArr; (''T''[''E₁''] ''T''[''E₂''])
#       ''T''[''λx''.''E'']       &amp;rArr; ('''K''' ''T''[''E''])         (if ''x'' is not free in ''E'')
#       ''T''[''λx''.''x'']       &amp;rArr; '''I'''
#       ''T''[''λx''.''λy''.''E'']    &amp;rArr; ''T''{{!(}}''λx''.''T''{{!(}}''λy''.''E''{{))!}} (if ''x'' is free in ''E'')
#       ''T''[''λx''.(''E₁'' ''E₂'')] &amp;rArr; ('''S''' ''T''[''λx''.''E₁''] ''T''[''λx''.''E₂'']) (if ''x'' is free in both ''E₁'' and ''E₂'')
#       ''T''[''λx''.(''E₁'' ''E₂'')] &amp;rArr; ('''C''' ''T''[''λx''.''E₁''] ''T''[''E₂'']) (if ''x'' is free in ''E₁'' but not ''E₂'')
#       ''T''[''λx''.(''E₁'' ''E₂'')] &amp;rArr; ('''B''' ''T''[''E₁''] ''T''[''λx''.''E₂'']) (if ''x'' is free in ''E₂'' but not ''E₁'')

Using '''B''' and '''C''' combinators, the transformation of
''λx''.''λy''.(''y'' ''x'') looks like this:

:&amp;nbsp;&amp;nbsp;          ''T''[''λx''.''λy''.(''y'' ''x'')]
:        = ''T''{{!(}}''λx''.''T''{{!(}}''λy''.(''y'' ''x''){{))!}}
:        = ''T''[''λx''.('''C''' ''T''[''λy''.''y''] ''x'')]     (by rule 7)
:        = ''T''[''λx''.('''C''' '''I''' ''x'')]
:        = ('''C''' '''I''')                   (η-reduction)
:        = &lt;math&gt;\mathbf{C}_{*}&lt;/math&gt; (traditional canonical notation : &lt;math&gt;\mathbf{X}_{*} = \mathbf{X I}&lt;/math&gt;)
:        = &lt;math&gt;\mathbf{I}'&lt;/math&gt; (traditional canonical notation: &lt;math&gt;\mathbf{X}' = \mathbf{C X}&lt;/math&gt;)

And indeed, ('''C''' '''I''' ''x'' ''y'') does reduce to (''y'' ''x''):

:&amp;nbsp;&amp;nbsp;          ('''C''' '''I''' ''x'' ''y'')
:        = ('''I''' ''y'' ''x'')
:        = (''y'' ''x'')

The motivation here is that '''B''' and '''C''' are limited versions of '''S'''.
Whereas '''S''' takes a value and substitutes it into both the applicand and
its argument before performing the application, '''C''' performs the
substitution only in the applicand, and '''B''' only in the argument.

The modern names for the combinators come from [[Haskell Curry]]'s doctoral thesis of 1930 (see [[B, C, K, W System]]). In [[Moses Schönfinkel|Schönfinkel]]'s original paper, what we now call  '''S''', '''K''', '''I''', '''B''' and '''C''' were called '''S''', '''C''', '''I''', '''Z''', and '''T''' respectively.

The reduction in combinator size that results from the new transformation rules
can also be achieved without introducing '''B''' and '''C''', as demonstrated in Section 3.2 of.
&lt;ref&gt;{{cite book |first=John |last=Tromp |chapter=Binary Lambda Calculus and Combinatory Logic |title=Randomness And Complexity, from Leibniz To Chaitin |editor-first=Cristian S. |editor-last=Calude |publisher=World Scientific Publishing Company |year=2008 |chapter-url=https://web.archive.org/web/20160304083208/http://tromp.github.io/cl/LC.pdf}}&lt;/ref&gt;

===== CL&lt;sub&gt;K&lt;/sub&gt; versus CL&lt;sub&gt;I&lt;/sub&gt; calculus =====
A distinction must be made between the '''CL'''&lt;sub&gt;K&lt;/sub&gt; as described in this article and the '''CL'''&lt;sub&gt;I&lt;/sub&gt; calculus. The distinction corresponds to that between the λ&lt;sub&gt;K&lt;/sub&gt; and the λ&lt;sub&gt;I&lt;/sub&gt; calculus. Unlike the λ&lt;sub&gt;K&lt;/sub&gt; calculus, the λ&lt;sub&gt;I&lt;/sub&gt; calculus restricts abstractions to:
::''λx''.''E'' where ''x'' has at least one free occurrence in ''E''.
As a consequence, combinator '''K''' is not present in the λ&lt;sub&gt;I&lt;/sub&gt; calculus nor in the '''CL'''&lt;sub&gt;I&lt;/sub&gt; calculus. The constants of '''CL'''&lt;sub&gt;I&lt;/sub&gt; are: '''I''', '''B''', '''C''' and '''S''', which form a basis from which all '''CL'''&lt;sub&gt;I&lt;/sub&gt; terms can be composed (modulo equality). Every λ&lt;sub&gt;I&lt;/sub&gt; term can be converted into an equal '''CL'''&lt;sub&gt;I&lt;/sub&gt; combinator according to rules similar to those presented above for the conversion of λ&lt;sub&gt;K&lt;/sub&gt; terms into '''CL'''&lt;sub&gt;K&lt;/sub&gt; combinators. See chapter 9 in Barendregt (1984).

=== Reverse conversion ===

The conversion ''L''[&amp;nbsp;] from combinatorial terms to lambda terms is
trivial:

: ''L''['''I''']       = ''λx''.''x''
: ''L''['''K''']       = ''λx''.''λy''.''x''
: ''L''['''C''']       = ''λx''.''λy''.''λz''.(''x'' ''z'' ''y'')
: ''L''['''B''']       = ''λx''.''λy''.''λz''.(''x'' (''y'' ''z''))
: ''L''['''S''']       = ''λx''.''λy''.''λz''.(''x'' ''z'' (''y'' ''z''))
: ''L''[(''E₁'' ''E₂'')] = (''L''[''E₁''] ''L''[''E₂''])

Note, however, that this transformation is not the inverse
transformation of any of the versions of ''T''[&amp;nbsp;] that we have seen.

== Undecidability of combinatorial calculus ==

A [[normal form (abstract rewriting)|normal form]] is any combinatory term in which the primitive combinators that occur, if any, are not applied to enough arguments to be simplified. It is undecidable whether a general combinatory term has a normal form; whether two combinatory terms are equivalent, etc.  This is equivalent to the undecidability of the corresponding problems for lambda terms.  However, a direct proof is as follows:

First, observe that the term

:        '''Ω''' = ('''S''' '''I''' '''I''' ('''S''' '''I''' '''I'''))

has no normal form, because it reduces to itself after three steps, as
follows:

:{{spaces|2}}  ('''S''' '''I''' '''I''' ('''S''' '''I''' '''I'''))
: = ('''I''' ('''S''' '''I''' '''I''') ('''I''' ('''S''' '''I''' '''I''')))
: = ('''S''' '''I''' '''I''' ('''I''' ('''S''' '''I''' '''I''')))
: = ('''S''' '''I''' '''I''' ('''S''' '''I''' '''I'''))
and clearly no other reduction order can make the expression shorter.

Now, suppose '''N''' were a combinator for detecting normal forms,
such that

:&lt;math&gt;(\mathbf{N} \  x) = \begin{cases} \mathbf{T}, \text{ if } x \text{ has a normal form} \\
\mathbf{F}, \text{ otherwise.} \end{cases}&lt;/math&gt;
:(Where {{math|'''T'''}} and {{math|'''F'''}} represent the conventional [[Church encoding]]s of true and false, ''λx''.''λy''.''x'' and ''λx''.''λy''.''y'', transformed into combinatory logic. The combinatory versions have {{math|1='''T''' = '''K'''}} and {{math|1='''F''' = ('''K''' '''I''')}}.)

Now let

:        ''Z'' = ('''C''' ('''C''' ('''B''' '''N''' ('''S''' '''I''' '''I''')) '''Ω''') '''I''')

now consider the term  ('''S''' '''I''' '''I''' ''Z'').  Does ('''S''' '''I''' '''I''' ''Z'') have a normal
form?  It does if and only if the following do also:

:{{spaces|2}} ('''S''' '''I''' '''I''' ''Z'')
: = ('''I''' ''Z'' ('''I''' ''Z''))
: = (''Z'' ('''I''' ''Z''))
: = (''Z'' ''Z'')
: = ('''C''' ('''C''' ('''B''' '''N''' ('''S''' '''I''' '''I''')) '''Ω''') '''I''' ''Z'')           (definition of ''Z'')
: = ('''C''' ('''B''' '''N''' ('''S''' '''I''' '''I''')) '''Ω''' ''Z'' '''I''')
: = ('''B''' '''N''' ('''S''' '''I''' '''I''') ''Z'' '''Ω''' '''I''')
: = ('''N''' ('''S''' '''I''' '''I''' ''Z'') '''Ω''' '''I''')
Now we need to apply '''N''' to ('''S''' '''I''' '''I''' ''Z'').
Either ('''S''' '''I''' '''I''' ''Z'') has a normal form, or it does not.  If it ''does''
have a normal form, then the foregoing reduces as follows:

:{{spaces|2}} ('''N''' ('''S''' '''I''' '''I''' ''Z'') '''Ω''' '''I''')
: = ('''K''' '''Ω''' '''I''')                               (definition of '''N''')
: = '''Ω'''
but '''Ω''' does ''not'' have a normal form, so we have a contradiction.  But
if ('''S''' '''I''' '''I''' ''Z'') does ''not'' have a normal form, the foregoing reduces as
follows:

:{{spaces|2}} ('''N''' ('''S''' '''I''' '''I''' ''Z'') '''Ω''' '''I''')
: = ('''K''' '''I''' '''Ω''' '''I''')                             (definition of '''N''')
: = ('''I''' '''I''')
: = '''I'''
which means that the normal form of ('''S''' '''I''' '''I''' ''Z'') is simply '''I''', another
contradiction.  Therefore, the hypothetical normal-form combinator '''N'''
cannot exist.

The combinatory logic analogue of [[Rice's theorem]] says that there is no complete nontrivial predicate.  A ''predicate'' is a combinator that, when applied,  returns either '''T''' or '''F'''.   A predicate '''N''' is ''nontrivial'' if there are two arguments ''A'' and ''B'' such that '''N''' ''A'' = '''T''' and '''N''' ''B'' = '''F'''. A combinator '''N''' is ''complete'' if and only if '''N'''''M'' has a normal form for every argument ''M''.  The analogue of Rice's theorem then says that every complete predicate is trivial. The proof of this theorem is rather simple.
&lt;blockquote&gt;
'''Proof:''' By reductio ad absurdum. Suppose there is a complete non trivial predicate, say '''N'''. Because '''N''' is supposed to be non trivial there are combinators ''A'' and ''B'' such that
:('''N''' ''A'') = '''T''' and
:('''N''' ''B'') = '''F'''.

:Define NEGATION ≡ ''λx''.(if ('''N''' ''x'') then ''B'' else ''A'') ≡ ''λx''.(('''N''' ''x'') ''B'' ''A'')
:Define ABSURDUM ≡ ('''Y''' NEGATION)

Fixed point theorem gives: ABSURDUM = (NEGATION ABSURDUM), for
:ABSURDUM ≡ ('''Y''' NEGATION) = (NEGATION ('''Y''' NEGATION)) ≡ (NEGATION ABSURDUM).

Because '''N''' is supposed to be complete either:
# ('''N''' ABSURDUM) = '''F''' or
# ('''N''' ABSURDUM) = '''T'''

* Case 1: '''F''' = ('''N''' ABSURDUM) = '''N''' (NEGATION ABSURDUM) = ('''N''' ''A'') = '''T''', a contradiction.
* Case 2: '''T''' = ('''N''' ABSURDUM) = '''N''' (NEGATION ABSURDUM) = ('''N''' ''B'') = '''F''', again a contradiction.

Hence ('''N''' ABSURDUM) is neither '''T''' nor '''F''', which contradicts the presupposition that '''N''' would be a complete non trivial predicate. '''[[Q.E.D.]]'''
&lt;/blockquote&gt;
From this undecidability theorem it immediately follows that there is no complete predicate that can discriminate between terms that have a normal form and terms that do not have a normal form. It also follows that there is '''no''' complete predicate, say EQUAL, such that:
:(EQUAL ''A B'') = '''T''' if ''A'' = ''B'' and
:(EQUAL ''A B'') = '''F''' if ''A'' ≠ ''B''.
If EQUAL would exist, then for all ''A'', ''λx.''(EQUAL ''x A'') would have to be a complete non trivial predicate.

== Applications ==

=== Compilation of functional languages ===

David Turner used his combinators to implement the [[SASL programming language]].

[[Kenneth E. Iverson]] used primitives based on Curry's combinators in his [[J programming language]], a successor to [[APL (programming language)|APL]]. This enabled what Iverson called [[tacit programming]], that is, programming in functional expressions containing no variables, along with powerful tools for working with such programs. It turns out that tacit programming is possible in any APL-like language with user-defined operators.&lt;ref&gt;{{cite journal |title=Pure Functions in APL and J |journal=Proceedings of the international conference on APL '91 |first=Edward |last=Cherlin |pages=88–93 |year=1991 |doi=10.1145/114054.114065}}&lt;/ref&gt;
&lt;!--
(Discuss strict vs. [[lazy evaluation]] semantics.  Note implications of
graph reduction implementation for lazy evaluation.  Point out
efficiency problem in lazy semantics: Repeated evaluation of the same
expression, in, e.g. (square COMPLICATED) =&gt; (* COMPLICATED
COMPLICATED), normally avoided by eager evaluation and call-by-value.
Discuss benefit of graph reduction in this case: when (square
COMPLICATED) is evaluated, the representation of COMPLICATED can be
shared by both branches of the resulting graph for (* COMPLICATED
COMPLICATED), and evaluated only once.)
--&gt;
&lt;!-- Work in [[combinator library]] somehow. --&gt;

=== Logic ===
The [[Curry–Howard isomorphism]] implies a connection between logic and programming: every proof of a theorem of [[intuitionistic logic]] corresponds to a reduction of a typed lambda term, and conversely. Moreover, theorems can be identified with function type signatures. Specifically, a typed combinatory logic corresponds to a [[Hilbert-style deduction system|Hilbert system]] in [[proof theory]].

The '''K''' and '''S''' combinators correspond to the axioms
:'''AK''': ''A'' → (''B'' → ''A''),
:'''AS''': (''A'' → (''B'' → ''C'')) → ((''A'' → ''B'') → (''A'' → ''C'')),
and function application corresponds to the detachment (modus ponens) rule
:'''MP''': from ''A'' and ''A'' → ''B'' infer ''B''.
The calculus consisting of '''AK''', '''AS''', and '''MP''' is complete for the implicational fragment of the intuitionistic logic, which can be seen as follows. Consider the set ''W'' of all deductively closed sets of formulas, ordered by [[inclusion (set theory)|inclusion]]. Then &lt;math&gt;\langle W,\subseteq\rangle&lt;/math&gt; is an intuitionistic [[Kripke semantics|Kripke frame]], and we define a model &lt;math&gt;\Vdash&lt;/math&gt; in this frame by
:&lt;math&gt;X\Vdash A\iff A\in X.&lt;/math&gt;
This definition obeys the conditions on satisfaction of →: on one hand, if &lt;math&gt;X\Vdash A\to B&lt;/math&gt;, and &lt;math&gt;Y\in W&lt;/math&gt; is such that &lt;math&gt;Y\supseteq X&lt;/math&gt; and &lt;math&gt;Y\Vdash A&lt;/math&gt;, then &lt;math&gt;Y\Vdash B&lt;/math&gt; by modus ponens. On the other hand, if &lt;math&gt;X\not\Vdash A\to B&lt;/math&gt;, then &lt;math&gt;X,A\not\vdash B&lt;/math&gt; by the [[deduction theorem]], thus the deductive closure of &lt;math&gt;X\cup\{A\}&lt;/math&gt; is an element &lt;math&gt;Y\in W&lt;/math&gt; such that &lt;math&gt;Y\supseteq X&lt;/math&gt;, &lt;math&gt;Y\Vdash A&lt;/math&gt;, and &lt;math&gt;Y\not\Vdash B&lt;/math&gt;.

Let ''A'' be any formula which is not provable in the calculus. Then ''A'' does not belong to the deductive closure ''X'' of the empty set, thus &lt;math&gt;X\not\Vdash A&lt;/math&gt;, and ''A'' is not intuitionistically valid.

==See also==
* [[Applicative computing systems]]
* [[B, C, K, W system]]
* [[Categorical abstract machine]]
* [[Combinatory categorial grammar]]
* [[Explicit substitution]]
* [[Fixed point combinator]]
* [[Graph reduction machine]]
* [[Lambda calculus]] and [[Cylindric algebra]], other approaches to modelling quantification and eliminating variables
* [[SKI combinator calculus]]
* [[Supercombinator]]
* ''[[To Mock a Mockingbird]]''

== References ==
{{reflist}}

==Further reading==
*{{cite book|last=Barendregt|first=Hendrik Pieter|authorlink=Henk Barendregt|year=1984|title=The Lambda Calculus, Its Syntax and Semantics. Studies in Logic and the Foundations of Mathematics|volume=Volume 103|publisher=North Holland|isbn=0-444-87508-5|ref=harv}}
*{{cite book|last1=Curry|first1=Haskell B.|authorlink1=Haskell Curry|last2=Feys|first2=Robert|authorlink2=Robert Feys|title=Combinatory Logic|volume=Vol. I|year=1958|publisher=North Holland|location=Amsterdam|isbn=0-7204-2208-6}}
*{{cite book|last1=Curry|first1=Haskell B.|authorlink1=Haskell Curry|first2=J. Roger|last2=Hindley|authorlink2=J. Roger Hindley|first3=Jonathan P.|last3=Seldin|title=Combinatory Logic|volume=Vol. II|year=1972|publisher=North Holland|location=Amsterdam|isbn=0-7204-2208-6}}
*{{cite book |last1=Field |first1=Anthony J. |first2=Peter G. |last2=Harrison |authorlink2=Peter G. Harrison |year=1998 |title=Functional Programming |publisher=Addison-Wesley |isbn=0-201-19249-7}}
*{{citation|last1=Hindley|first1=J. Roger|authorlink1=J. Roger Hindley|last2=Meredith|first2=David|title=Principal type-schemes and condensed detachment|url=http://projecteuclid.org/euclid.jsl/1183743187|MR=1043546|journal=[[Journal of Symbolic Logic]]|volume = 55|issue=1|pp=90–105|year=1990|doi=10.2307/2274956|jstor=2274956}}
*{{cite book |last1=Hindley |first1=J. R. |authorlink1=J. Roger Hindley |last2=Seldin |first2=J. P. |year=2008 |url=http://www.cambridge.org/catalogue/catalogue.asp?isbn=9780521898850 |title=λ-calculus and Combinators: An Introduction |publisher=Cambridge University Press}}
*{{cite book |last=Paulson |first=Lawrence C. |authorlink=Lawrence Paulson |year=1995 |url=http://www.cl.cam.ac.uk/Teaching/Lectures/founds-fp/Founds-FP.ps.gz |title=Foundations of Functional Programming |publisher=University of Cambridge}}
*&lt;span id="Quine 1960"&gt;{{cite journal |authorlink=Willard Van Orman Quine |last=Quine |first=W. V. |year=1960 |title=Variables explained away |journal=Proceedings of the American Philosophical Society |volume=104 |issue=3 |pages=343–347 |jstor=985250}} Reprinted as Chapter 23 of Quine's ''Selected Logic Papers'' (1966), pp.&amp;nbsp;227–235&lt;/span&gt;
* [[Moses Schönfinkel|Schönfinkel, Moses]], 1924, "[http://www.cip.ifi.lmu.de/~langeh/test/1924%20-%20Schoenfinkel%20-%20Ueber%20die%20Bausteine%20der%20mathematischen%20Logik.pdf Über die Bausteine der mathematischen Logik]," translated as "On the Building Blocks of Mathematical Logic" in ''From Frege to Gödel: a source book in mathematical logic, 1879–1931'', [[Jean van Heijenoort]], ed. Harvard University Press, 1967. {{ISBN|0-674-32449-8}}. The article that founded combinatory logic.
* [[Raymond Smullyan|Smullyan, Raymond]], 1985. ''[[To Mock a Mockingbird]]''. Knopf. {{ISBN|0-394-53491-3}}. A gentle introduction to combinatory logic, presented as a series of recreational puzzles using bird watching metaphors.
*--------, 1994. ''Diagonalization and Self-Reference''. Oxford Univ. Press. Chapters 17–20 are a more formal introduction to combinatory logic, with a special emphasis on fixed point results.
*Sørensen, Morten Heine B. and Paweł Urzyczyn, 1999. ''[https://web.archive.org/web/20051016213140/http://folli.loria.fr/cds/1999/library/pdf/curry-howard.pdf Lectures on the Curry–Howard Isomorphism.]'' University of Copenhagen and University of Warsaw, 1999.
* {{cite book |last=Wolfengagen |first=V. E. |url=https://archive.org/details/CLP-2003_780 |title=Combinatory logic in programming: Computations with objects through examples and exercises |edition=2nd |location=Moscow |publisher="Center JurInfoR" Ltd. |year=2003 |isbn=5-89158-101-9}}.

==External links==
*[[Stanford Encyclopedia of Philosophy]]: "[http://plato.stanford.edu/entries/logic-combinatory/ Combinatory Logic]" by Katalin Bimbó.
*[https://web.archive.org/web/20070209093802/http://www.sadl.uleth.ca/gsdl/cgi-bin/library?a=p&amp;p=about&amp;c=curry 1920–1931 Curry's block notes.]
*Keenan, David C. (2001) "[http://dkeenan.com/Lambda/index.htm To Dissect a Mockingbird: A Graphical Notation for the Lambda Calculus with Animated Reduction.]"
*Rathman, Chris, "[http://www.angelfire.com/tx4/cus/combinator/birds.html Combinator Birds.]" A table distilling much of the essence of Smullyan (1985).
*[https://web.archive.org/web/20081029051502/http://cstein.kings.cam.ac.uk/~chris/combinators.html Drag 'n' Drop Combinators.] (Java Applet)
*[https://web.archive.org/web/20160304083208/http://tromp.github.io/cl/LC.pdf Binary Lambda Calculus and Combinatory Logic.]
*[http://code.google.com/p/clache Combinatory logic reduction web server]
{{authority control}}
[[Category:Lambda calculus]]
[[Category:Logic in computer science]]
[[Category:Combinatory logic| ]]</text>
      <sha1>p9qh5j7dr92k915xdds4wjyyjt6n442</sha1>
    </revision>
  </page>
  <page>
    <title>Communications in Algebra</title>
    <ns>0</ns>
    <id>48037177</id>
    <revision>
      <id>840767231</id>
      <parentid>684340060</parentid>
      <timestamp>2018-05-12T01:21:31Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <comment>| abbreviation = Commun. Algebra | mathscinet = Comm. Algebra</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1976">{{Infobox journal
| title = Communications in Algebra
| cover =
| discipline = [[Algebra]]
| abbreviation = Commun. Algebra
| mathscinet = Comm. Algebra
| publisher = [[Taylor &amp; Francis]]
| country =
| history = 1974–present
| frequency = Monthly
| impact = 0.388
| impact-year = 2014
| ISSN = 0092-7872
| eISSN = 1532-4125
| website = http://www.tandfonline.com/action/journalInformation?show=aimsScope&amp;journalCode=lagb20
}}
'''''Communications in Algebra''''' is a monthly [[peer-reviewed]] [[scientific journal]] covering [[algebra]], including [[commutative algebra]], [[ring theory]], [[Module (mathematics)|module theory]], [[non-associative algebra]] (including [[Lie algebra]]s and [[Jordan algebra]]s), [[group theory]], and [[algebraic geometry]]. It was established in 1974 and is published by [[Taylor &amp; Francis]]. The [[editor-in-chief]] is Lance W. Small ([[University of California, San Diego]]). Earl J. Taft ([[Rutgers University]]) was the founding editor.

== Abstracting and indexing ==
The journal is abstracted and indexed in [[CompuMath Citation Index]], [[Current Contents]]/Chemical, Earth, and Physical Sciences, [[Mathematical Reviews]], [[MathSciNet]], [[Science Citation Index Expanded]] (SCIE), and [[Zentralblatt MATH]]. According to the ''[[Journal Citation Reports]]'', the journal has a 2014 [[impact factor]] of 0.388, ranking it 253th out of 310 journals in the category "Mathematics".&lt;ref name=WoS&gt;{{cite book |year=2015 |chapter=Journals Ranked by Impact: Mathematics |title=2014 [[Journal Citation Reports]] |publisher=[[Thomson Reuters]] |edition=Science |series=[[Web of Science]]}}&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* {{Official website|1=http://www.tandfonline.com/action/journalInformation?show=aimsScope&amp;journalCode=lagb20}}

[[Category:Publications established in 1974]]
[[Category:Mathematics journals]]
[[Category:English-language journals]]
[[Category:Monthly journals]]


{{mathematics-journal-stub}}</text>
      <sha1>s03pxqno45ygii91hs04wki8xrbidov</sha1>
    </revision>
  </page>
  <page>
    <title>Competitive regret</title>
    <ns>0</ns>
    <id>46903016</id>
    <revision>
      <id>846516400</id>
      <parentid>708146918</parentid>
      <timestamp>2018-06-19T07:25:04Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3208">{{
Multiple issues|
{{More footnotes|date=June 2015}}
{{Orphan|date=June 2015}}
}}
In [[decision theory]], '''competitive regret''' is the relative [[Regret (decision theory)|regret]] compared to an oracle with limited or unlimited power in the process of distribution estimation.

==Competitive regret to the oracle with full power==

Consider estimating a discrete [[probability distribution]] &lt;math&gt;p&lt;/math&gt; on a discrete set &lt;math&gt; \mathcal{X}&lt;/math&gt; based on data &lt;math&gt;X&lt;/math&gt;, the regret of an estimator&lt;ref name="alon2014"&gt;{{citation
| last1 = Orlitsky|first1=Alon|last2=Suresh|first2=Ananda Theertha.
| title = Competitive Distribution Estimation
| journal =  |arxiv=1503.07940
| year = 2015
|bibcode=2015arXiv150307940O}}&lt;/ref&gt; &lt;math&gt;q&lt;/math&gt; is defined as

:&lt;math&gt; \max_{p\in \mathcal{P}} r_n (q,p). &lt;/math&gt;

where &lt;math&gt;\mathcal{P}&lt;/math&gt; is the set of all possible probability distribution, and

:&lt;math&gt; r_n(q,p) = \mathbb{E} (D(p || q(X))).&lt;/math&gt;

where &lt;math&gt;D(p || q)&lt;/math&gt; is the [[Kullback–Leibler divergence]] between &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;q&lt;/math&gt;.

==Competitive regret to the oracle with limited power==

===Oracle with partial information===

The oracle is restricted to have access to partial information of the true distribution &lt;math&gt;p&lt;/math&gt; by knowing the location of &lt;math&gt;p&lt;/math&gt; in the parameter space up to a partition.&lt;ref name="alon2014"/&gt; Given a partition &lt;math&gt;\mathbb{P}&lt;/math&gt; of the parameter space, and suppose the oracle knows the subset &lt;math&gt;P&lt;/math&gt; where the true &lt;math&gt;p \in P&lt;/math&gt;. The oracle will have regret as

:&lt;math&gt; r_n(P) = \min_q \max_{p\in P} r_n (q,p). &lt;/math&gt;

The competitive regret to the oracle will be

:&lt;math&gt;r_n^\mathbb{P}(q, \mathcal{P}) = \max_{P \in \mathbb{P}} (r_n(q,P) - r_n(P)). &lt;/math&gt;

===Oracle with partial information===

The oracle knows exactly &lt;math&gt;p&lt;/math&gt;, but can only choose the estimator among natural estimators.A natural estimator assigns equal probability to the symbols which appear the same number of time in the sample.&lt;ref name="alon2014"/&gt; The regret of the oracle is

:&lt;math&gt;r_n^{nat} (p)= \min_{q\in \mathcal{Q}_{nat}} r_n(q,p),&lt;/math&gt;

and the competitive regret is

:&lt;math&gt;\max_{p \in \mathcal{P}} (r_n(q,p) - r_n^{nat} (p)).&lt;/math&gt;

==Example==

For the estimator &lt;math&gt;q&lt;/math&gt; proposed in Acharya et al.(2013),&lt;ref name="alon2013"&gt;{{citation
| last1 = Acharya|first1=Jayadev|last2 = Jafarpour|first2=Ashkan|last3 = Orlitsky|first3=Alon|last4 = Suresh|first4=Ananda Theertha 
| title = Optimal probability estimation with applications to prediction and classification
| journal = Proceedings of the 26th Annual Conference on Learning Theory (COLT) 
| year = 2013
}}&lt;/ref&gt;

:&lt;math&gt; r_n^{\mathbb{P}_\sigma} (q, \Delta_k) \leq r^{nat}_n(q, \Delta_k) \leq \tilde{\mathcal{O}} (\min (\frac{1}{\sqrt{n}}, \frac{k}{n})). &lt;/math&gt;

Here &lt;math&gt;\Delta_k&lt;/math&gt; denotes the k-dimensional unit simplex surface. The partition &lt;math&gt;\mathbb{P}_\sigma&lt;/math&gt; denotes the permutation class on &lt;math&gt;\Delta_k&lt;/math&gt;, where &lt;math&gt;p&lt;/math&gt; and &lt;math&gt;p'&lt;/math&gt; are partitioned into the same subset if and only if &lt;math&gt;p'&lt;/math&gt; is a permutation of &lt;math&gt;p&lt;/math&gt;.

==References==
{{reflist}}

[[Category:Game theory]]</text>
      <sha1>n7bxwc2hkiku75g9h9vf5n146jm8fgt</sha1>
    </revision>
  </page>
  <page>
    <title>Complex system</title>
    <ns>0</ns>
    <id>37438</id>
    <revision>
      <id>864572339</id>
      <parentid>863260137</parentid>
      <timestamp>2018-10-18T03:04:12Z</timestamp>
      <contributor>
        <username>Fabrickator</username>
        <id>8660314</id>
      </contributor>
      <minor/>
      <comment>/* General form of complexity computation */ correct "overtime" to "over time"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="47916">{{Redirect|Complex systems|the journal|Complex Systems (journal)}}
{{Complex systems}}
A '''complex system''' is a [[system]] composed of many components which may interact with each other. Examples of complex systems are Earth's global [[climate]], [[organisms]], the [[human brain]], infrastructure such as power grid, transportation or communication systems, social and economic organizations (like [[cities]]), an [[ecosystem]], a living [[Cell (biology)|cell]], and ultimately the entire [[universe]].

Complex systems are [[system]]s whose behavior is intrinsically difficult to model due to the dependencies, competitions, relationships, or other types of interactions between their parts or between a given system and its environment. Systems that are "[[Complexity|complex]]" have distinct properties that arise from these relationships, such as [[Nonlinear system|nonlinearity]], [[emergence]], [[spontaneous order]], [[Complex adaptive system|adaptation]], and [[Feedback|feedback loops]], among others. Because such systems appear in a wide variety of fields, the commonalities among them have become the topic of their own independent area of research. In many cases it is useful to represent such a system as a network where the nodes represent the components and the links their interactions.

== Overview ==
The term ''complex systems'' often refers to the study of complex systems, which is an approach to science that investigates how relationships between a system's parts give rise to its collective behaviors and how the system interacts and forms relationships with its environment.&lt;ref&gt;{{cite journal|last=Bar-Yam|first=Yaneer|date=2002|title=General Features of Complex Systems|url=http://www.eolss.net/sample-chapters/c15/E1-29-01-00.pdf|journal=Encyclopedia of Life Support Systems|publisher=[[Encyclopedia of Life Support Systems|EOLSS]] [[UNESCO]] Publishers, Oxford, UK|doi=|pmid=|accessdate=16 September 2014}}&lt;/ref&gt; The study of complex systems regards collective, or system-wide, behaviors as the fundamental object of study; for this reason, complex systems can be understood as an alternative paradigm to [[reductionism]], which attempts to explain systems in terms of their constituent parts and the individual interactions between them.

As an interdisciplinary domain, complex systems draws contributions from many different fields, such as the study of [[self-organization]] from physics, that of [[spontaneous order]] from the social sciences, [[Chaos theory|chaos]] from mathematics, [[Complex adaptive system|adaptation]] from biology, and many others. ''Complex systems'' is therefore often used as a broad term encompassing a research approach to problems in many diverse disciplines, including [[statistical physics]], [[information theory]], [[Nonlinear system|nonlinear dynamics]], [[anthropology]], [[computer science]], [[meteorology]], [[sociology]], [[economics]], [[psychology]], and [[biology]].

== Key concepts ==

=== Systems ===
[[File:OpenSystemRepresentation.svg|thumb|252px|''Open systems'' have input and output flows, representing exchanges of matter, energy or information with their surroundings.]]
Complex systems is chiefly concerned with the behaviors and properties of ''[[system]]s''. A system, broadly defined, is a set of entities that, through their interactions, relationships, or dependencies, form a unified whole. It is always defined in terms of its ''boundary'', which determines the entities that are or are not part of the system. Entities lying outside the system then become part of the system's ''environment''.

A system can exhibit ''properties'' that produce ''behaviors'' which are distinct from the properties and behaviors of its parts; these system-wide or ''global'' properties and behaviors are characteristics of how the system interacts with or appears to its environment, or of how its parts behave (say, in response to external stimuli) by virtue of being within the system. The notion of ''behavior'' implies that the study of systems is also concerned with processes that take place over time (or, in [[mathematics]], some other [[phase space]] [[Parametrization|parameterization]]). Because of their broad, interdisciplinary applicability, systems concepts play a central role in complex systems.

As a field of study, complex systems is a subset of [[systems theory]]. General systems theory focuses similarly on the collective behaviors of interacting entities, but it studies a much broader class of systems, including non-complex systems where traditional reductionist approaches may remain viable. Indeed, systems theory seeks to explore and describe ''all'' classes of systems, and the invention of categories that are useful to researchers across widely varying fields is one of systems theory's main objectives.

As it relates to complex systems, systems theory contributes an emphasis on the way relationships and dependencies between a system's parts can determine system-wide properties. It also contributes the interdisciplinary perspective of the study of complex systems: the notion that shared properties link systems across disciplines, justifying the pursuit of modeling approaches applicable to complex systems wherever they appear. Specific concepts important to complex systems, such as emergence, feedback loops, and adaptation, also originate in systems theory.

=== Complexity ===
Systems exhibit complexity means that their behaviors cannot be easily implied from the very properties that make them difficult to model, and the complex behaviors are governed entirely, or almost entirely, by the behaviors those properties produce. Any modeling approach that ignores such difficulties or characterizes them as noise, then, will necessarily produce models that are neither accurate nor useful. As yet no fully general theory of complex systems has emerged for addressing these problems, so researchers must solve them in domain-specific contexts. Researchers in complex systems address these problems by viewing the chief task of modeling to be capturing, rather than reducing, the complexity of their respective systems of interest.

While no generally accepted exact definition of complexity exists yet, there are many archetypal examples of complexity. Systems can be complex if, for instance, they have [[Chaos theory|chaotic]] behavior (behavior that exhibits extreme sensitivity to initial conditions), or if they have [[Emergence|emergent]] properties (properties that are not apparent from their components in isolation but which result from the relationships and dependencies they form when placed together in a system), or if they are computationally intractable to model (if they depend on a number of parameters that grows too rapidly with respect to the size of the system).

=== Networks ===
The interacting components of a complex system form a [[Network theory|network]], which is a collection of discrete objects and relationships between them, usually depicted as a [[Graph (discrete mathematics)|graph]] of vertices connected by edges. Networks can describe the relationships between individuals within an organization, between [[logic gate]]s in a [[Circuit (computer science)|circuit]], between [[gene]]s in [[gene regulatory network]]s, or between any other set of related entities.

Networks often describe the sources of complexity in complex systems. Studying complex systems as networks therefore enables many useful applications of [[graph theory]] and [[network science]]. Some complex systems, for example, are also [[complex network]]s, which have properties such as phase transitions and power-law degree distributions that readily lend themselves to emergent or chaotic behavior. The fact that the number of edges in a [[complete graph]] grows [[Quadratic growth|quadratically]] in the number of vertices sheds additional light on the source of complexity in large networks: as a network grows, the number of relationships between entities quickly dwarfs the number of entities in the network.

=== Nonlinearity ===
[[File:A Trajectory Through Phase Space in a Lorenz Attractor.gif|frame|border|right|A sample solution in the Lorenz attractor when ρ = 28, σ = 10, and β = 8/3]]
Complex systems often have nonlinear behavior, meaning they may respond in different ways to the same input depending on their state or context. In [[mathematics]] and [[physics]], nonlinearity describes systems in which a change in the size of the input does not produce a proportional change in the size of the output. For a given change in input, such systems may yield significantly greater than or less than proportional changes in output, or even no output at all, depending on the current state of the system or its parameter values.

Of particular interest to complex systems are [[nonlinear dynamical systems]], which are systems of [[differential equation]]s that have one or more nonlinear terms. Some nonlinear dynamical systems, such as the [[Lorenz system]], can produce a mathematical phenomenon known as [[Chaos theory|chaos]]. Chaos as it applies to complex systems refers to the sensitive dependence on initial conditions, or "[[butterfly effect]]," that a complex system can exhibit. In such a system, small changes to initial conditions can lead to dramatically different outcomes. Chaotic behavior can therefore be extremely hard to model numerically, because small rounding errors at an intermediate stage of computation can cause the model to generate completely inaccurate output. Furthermore, if a complex system returns to a state similar to one it held previously, it may behave completely differently in response to exactly the same stimuli, so chaos also poses challenges for extrapolating from past experience.

=== Emergence ===
[[File:Gospers glider gun.gif|frame|right|[[Bill Gosper|Gosper's]] [[Gun (cellular automaton)|Glider Gun]] creating "[[Glider (Conway's Life)|gliders]]" in the cellular automaton [[Conway's Game of Life]]&lt;ref&gt;[[Daniel Dennett]] (1995), ''[[Darwin's Dangerous Idea]]'', Penguin Books, London, {{ISBN|978-0-14-016734-4}}, {{ISBN|0-14-016734-X}}&lt;/ref&gt;]]
Another common feature of complex systems is the presence of emergent behaviors and properties: these are traits of a system which are not apparent from its components in isolation but which result from the interactions, dependencies, or relationships they form when placed together in a system. [[Emergence]] broadly describes the appearance of such behaviors and properties, and has applications to systems studied in both the social and physical sciences. While emergence is often used to refer only to the appearance of unplanned organized behavior in a complex system, emergence can also refer to the breakdown of organization; it describes any phenomena which are difficult or even impossible to predict from the smaller entities that make up the system.

One example of complex system whose emergent properties have been studied extensively is [[Cellular automaton|cellular automata]]. In a cellular automaton, a grid of cells, each having one of finitely many states, evolves over time according to a simple set of rules. These rules guide the "interactions" of each cell with its neighbors. Although the rules are only defined locally, they have been shown capable of producing globally interesting behavior, for example in [[Conway's Game of Life]].

==== Spontaneous order and self-organization ====
When emergence describes the appearance of unplanned order, it is [[spontaneous order]] (in the social sciences) or [[self-organization]] (in physical sciences). Spontaneous order can be seen in [[herd behavior]], whereby a group of individuals coordinates their actions without centralized planning. Self-organization can be seen in the global symmetry of certain [[crystal]]s, for instance the apparent radial [[symmetry]] of [[snowflake]]s, which arises from purely local [[Intermolecular force|attractive and repulsive forces]] both between water molecules and between water molecules and their surrounding environment.

=== Adaptation ===
[[Complex adaptive system]]s are special cases of complex systems that are [[adaptive]] in that they have the capacity to change and learn from experience. Examples of complex adaptive systems include the [[stock market]], social insect and [[ant]] colonies, the [[biosphere]] and the [[ecosystem]], the [[Human brain|brain]] and the [[immune system]], the [[Cell (biology)|cell]] and the developing [[embryo]], the cities, [[Manufacturing|manufacturing businesses]] and any human social group-based endeavor in a cultural and [[social system]] such as [[Political party|political parties]] or [[Community|communities]].&lt;ref&gt;[http://journals.sagepub.com/doi/abs/10.1177/1473095218780515 On the ‘complexity turn’ in planning: An adaptive rationale to navigate spaces and times of uncertainty]&lt;/ref&gt;

==Features==
Complex systems may have the following features:&lt;ref&gt;{{cite book|title=Risk and Precaution
|author=Alan Randall
|author-link=Alan Randall
|isbn=9781139494793
|url=https://books.google.de/books?id=IlHj3fvJzMsC&amp;printsec=frontcover&amp;dq=inauthor:%22Alan+Randall%22&amp;hl=de&amp;sa=X&amp;ved=0ahUKEwjA_u_a2pXLAhVIOpoKHZRLAacQ6AEIODAE#v=onepage&amp;q&amp;f=false
|publisher=Cambridge University Press|year=2011}}&lt;/ref&gt;

;[[Cascading failure]]s
:Due to the strong coupling between components in complex systems, a failure in one or more components can lead to cascading failures which may have catastrophic consequences on the functioning of the system.&lt;ref&gt;{{cite journal|author=S. V. Buldyrev|author2=R. Parshani|author3=G. Paul|author4=H. E. Stanley|author5=S. Havlin|author5-link=Shlomo Havlin|title=Catastrophic cascade of failures in interdependent networks|journal=Nature|year=2010|volume=464|pages=08932|url=http://havlin.biu.ac.il/Publications.php?keyword=Catastrophic+cascade+of+failures+in+interdependent+networks&amp;year=*&amp;match=all | doi = 10.1038/nature08932|pmid=20393559|issue=7291|arxiv = 0907.1182 |bibcode = 2010Natur.464.1025B }}&lt;/ref&gt; Localized attack may lead to cascading failures and abrupt collapse in spatial networks.&lt;ref name="BerezinBashan2015"&gt;{{cite journal|last1=Berezin|first1=Yehiel|last2=Bashan|first2=Amir|last3=Danziger|first3=Michael M.|last4=Li|first4=Daqing|last5=Havlin|first5=Shlomo|title=Localized attacks on spatially embedded networks with dependencies|journal=Scientific Reports|volume=5|issue=1|year=2015|issn=2045-2322|doi=10.1038/srep08934|bibcode=2015NatSR...5E8934B}}&lt;/ref&gt;

;Complex systems may be open
:Complex systems are usually [[Open system (systems theory)|open systems]] — that is, they exist in a [[thermodynamic]] gradient and dissipate energy. In other words, complex systems are frequently far from energetic [[thermodynamic equilibrium|equilibrium]]: but despite this flux, there may be [[pattern stability]], see [[synergetics (Haken)|synergetics]].

;Complex systems may have a memory
:The history of a complex system may be important. Because complex systems are [[dynamical systems]] they change over time, and prior states may have an influence on present states. More formally, complex systems often exhibit spontaneous failures and recovery as well as [[hysteresis]].&lt;ref name="MajdandzicPodobnik2013"&gt;{{cite journal|last1=Majdandzic|first1=Antonio|last2=Podobnik|first2=Boris|last3=Buldyrev|first3=Sergey V.|last4=Kenett|first4=Dror Y.|last5=Havlin|first5=Shlomo|last6=Eugene Stanley|first6=H.|title=Spontaneous recovery in dynamical networks|journal=Nature Physics|volume=10|issue=1|year=2013|pages=34–38|issn=1745-2473|doi=10.1038/nphys2819|bibcode=2014NatPh..10...34M}}&lt;/ref&gt; Interacting systems may have complex hysteresis of many transitions.&lt;ref name="MajdandzicBraunstein2016"&gt;{{cite journal|last1=Majdandzic|first1=Antonio|last2=Braunstein|first2=Lidia A.|last3=Curme|first3=Chester|last4=Vodenska|first4=Irena|last5=Levy-Carciente|first5=Sary|last6=Eugene Stanley|first6=H.|last7=Havlin|first7=Shlomo|title=Multiple tipping points and optimal repairing in interacting networks|journal=Nature Communications|volume=7|year=2016|pages=10850|issn=2041-1723|doi=10.1038/ncomms10850|arxiv=1502.00244|bibcode=2016NatCo...710850M}}&lt;/ref&gt;

;Complex systems may be [[Hierarchy#Nested hierarchy|nested]]
:The components of a complex system may themselves be complex systems. For example, an [[Economics|economy]] is made up of [[organisation]]s, which are made up of [[person|people]], which are made up of [[cell (biology)|cells]] - all of which are complex systems.

;Dynamic network of multiplicity
:As well as [[coupling]] rules, the dynamic [[Biological network|network]] of a complex system is important. [[Small-world network|Small-world]] or [[Scale-free network|scale-free]] networks&lt;ref&gt;{{cite journal|last=A. L. Barab´asi|first=R. Albert|title=Statistical mechanics of complex networks|journal=Reviews of Modern Physics |year=2002|volume=74|pages=47–94|url=http://rmp.aps.org/abstract/RMP/v74/i1/p47_1 | doi = 10.1103/RevModPhys.74.47|bibcode=2002RvMP...74...47A|arxiv = cond-mat/0106096 }}&lt;/ref&gt;&lt;ref&gt;{{cite book|title= Networks: An Introduction|author= M. Newman|year=2010|publisher=Oxford University Press|isbn=978-0-19-920665-0}}&lt;/ref&gt;&lt;ref name=":0"&gt;{{cite book|title=[[Complex Networks]]: Structure, Robustness and Function|last=Reuven Cohen|first=Shlomo Havlin|author-link=Shlomo Havlin|year=2010|publisher=Cambridge University Press|isbn=978-0-521-84156-6}}&lt;/ref&gt; which have many local interactions and a smaller number of inter-area connections are often employed. Natural complex systems often exhibit such topologies. In the human [[Cerebral cortex|cortex]] for example, we see dense local connectivity and a few very long [[axonal|axon]] projections between regions inside the cortex and to other brain regions.

;May produce emergent phenomena
:Complex systems may exhibit behaviors that are [[emergence|emergent]], which is to say that while the results may be sufficiently determined by the activity of the systems' basic constituents, they may have properties that can only be studied at a higher level.  For example, the [[termites]] in a mound have physiology, biochemistry and biological development that are at one level of analysis, but their [[social behavior]] and mound building is a property that emerges from the collection of termites and needs to be analysed at a different level.

;Relationships are non-linear
:In practical terms, this means a small perturbation may cause a large effect (see [[butterfly effect]]), a proportional effect, or even no effect at all. In linear systems, effect is ''always'' directly proportional to cause. See [[nonlinearity]].

;Relationships contain feedback loops
:Both negative ([[damping]]) and positive (amplifying) [[feedback]] are always found in complex systems. The effects of an element's behaviour are fed back to in such a way that the element itself is altered.

== History ==
[[File:2018 Map of the Complexity Sciences.jpg|thumb|360px|A perspective on the development of complexity science: http://www.art-sciencefactory.com/complexity-map_feb09.html|alt= http://www.art-sciencefactory.com/complexity-map_feb09.html]]

Although it is arguable that humans have been studying complex systems for thousands of years, the modern scientific study of complex systems is relatively young in comparison to established fields of science such as [[physics]] and [[chemistry]]. The history of the scientific study of these systems follows several different research trends.

In the area of [[mathematics]], arguably the largest contribution to the study of complex systems was the discovery of [[chaos theory|chaos]] in [[deterministic]] systems, a feature of certain [[dynamical systems]] that is strongly related to [[nonlinearity]].&lt;ref&gt;[http://www.irit.fr/COSI/training/complexity-tutorial/history-of-complex-systems.htm History of Complex Systems&lt;!-- Bot generated title --&gt;] {{webarchive|url=https://web.archive.org/web/20071123171158/http://www.irit.fr/COSI/training/complexity-tutorial/history-of-complex-systems.htm |date=2007-11-23 }}&lt;/ref&gt;  The study of [[neural networks]] was also integral in advancing the mathematics needed to study complex systems.

The notion of [[self-organizing]] systems is tied with work in [[nonequilibrium thermodynamics]], including that pioneered by [[chemist]] and [[Nobel laureate]] [[Ilya Prigogine]] in his study of [[dissipative structures]]. Even older is the work by [[Hartree-Fock]] c.s. on the [[quantum-chemistry]] equations and later calculations of the structure of molecules which can be regarded as one of the earliest examples of emergence and emergent wholes in science.

One complex system containing humans is the classical political economy of the [[Scottish Enlightenment]], later developed by the [[Austrian school of economics]], which argues that order in market systems is spontaneous (or [[Emergence|emergent]]) in that it is the result of human action, but not the execution of any human design.&lt;ref&gt;{{cite book |last=Ferguson |first=Adam |authorlink=Adam Ferguson |coauthors= |title=An Essay on the History of Civil Society |publisher=T. Cadell |year=1767 |location=London |pages=Part the Third, Section II, p. 205 |url=http://oll.libertyfund.org/index.php?option=com_staticxt&amp;staticfile=show.php%3Ftitle=1428&amp;Itemid=28 |doi= |id= |isbn= |nopp=true}}&lt;/ref&gt;&lt;ref&gt;Friedrich Hayek, "The Results of Human Action but Not of Human Design" in ''New Studies in Philosophy, Politics, Economics'', Chicago: University of Chicago Press, 1978, pp. 96–105.&lt;/ref&gt;

Upon this the Austrian school developed from the 19th to the early 20th century the [[economic calculation problem]], along with the concept of [[dispersed knowledge]], which were to fuel debates against the then-dominant [[Keynesian economics]]. This debate would notably lead economists, politicians and other parties to explore the question of [[Economic calculation problem#Computational complexity|computational complexity]].{{Citation needed|date=November 2016}}

A pioneer in the field, and inspired by [[Karl Popper]]'s and [[Warren Weaver]]'s works, Nobel prize economist and philosopher [[Friedrich Hayek]] dedicated much of his work, from early to the late 20th century, to the study of complex phenomena,&lt;ref&gt;Bruce J. Caldwell, Popper and Hayek: [http://www.unites.uqam.ca/philo/pdf/Caldwell_2003-01.pdf Who influenced whom?], Karl Popper 2002 Centenary Congress, 2002.&lt;/ref&gt; not constraining his work to human economies but venturing into other fields such as [[psychology]],&lt;ref&gt;Friedrich von Hayek, ''The Sensory Order: An Inquiry into the Foundations of Theoretical Psychology'', The University of Chicago Press, 1952.&lt;/ref&gt; [[biology]] and [[cybernetics]].  [[Gregory Bateson]] played a key role in establishing the connection between anthropology and systems theory; he recognized that the interactive parts of cultures function much like ecosystems.

While the explicit study of complex systems dates at least to the 1970s,&lt;ref&gt;{{cite book |last=Vemuri |first=V. |date=1978 |title=Modeling of Complex Systems: An Introduction |location=New York |publisher=Academic Press|isbn=0127165509}}&lt;/ref&gt; the first research institute focused on complex systems, the [[Santa Fe Institute]], was founded in 1984.&lt;ref&gt;{{cite journal | last1 = Ledford | first1 = H | year = 2015 | title = How to solve the world's biggest problems | url = http://www.nature.com/news/how-to-solve-the-world-s-biggest-problems-1.18367 | journal = Nature | volume = 525 | issue = 7569| pages = 308–311 | doi=10.1038/525308a| bibcode = 2015Natur.525..308L }}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.santafe.edu/about/history|title=History {{!}} Santa Fe Institute|website=www.santafe.edu|language=en|access-date=2018-05-17}}&lt;/ref&gt; Early Santa Fe Institute participants included physics Nobel laureates [[Murray Gell-Mann]] and [[Philip Warren Anderson|Philip Anderson]], economics Nobel laureate [[Kenneth Arrow]], and Manhattan Project scientists [[George Cowan]] and [[Herbert L. Anderson|Herb Anderson]].&lt;ref&gt;Waldrop, M. M. (1993). [https://books.google.com/books/about/Complexity.html?id=JTRJxYK_tZsC Complexity: The emerging science at the edge of order and chaos.] Simon and Schuster.&lt;/ref&gt; Today, there are over 50 [[#Institutes_and_research_centers|institutes and research centers]] focusing on complex systems. A scientific society called [https://cssociety.org/home Complex Systems Society] organizes every year a general conference on these topics.

== Applications ==

===Complexity in practice===
The traditional approach to dealing with complexity is to reduce or constrain it. Typically, this involves compartmentalisation: dividing a large system into separate parts. Organizations, for instance, divide their work into departments that each deal with separate issues. Engineering systems are often designed using modular components. However, modular designs become susceptible to failure when issues arise that bridge the divisions.

===Complexity management===
As projects and [[acquisitions]] become increasingly complex, companies and governments are challenged to find effective ways to manage mega-acquisitions such as the Army [[Future Combat Systems]].  Acquisitions such as the [[Future Combat Systems|FCS]] rely on a web of interrelated parts which interact unpredictably.  As acquisitions become more network-centric and complex, businesses will be forced to find ways to manage complexity while governments will be challenged to provide effective governance to ensure flexibility and resiliency.&lt;ref&gt;[http://csis.org/files/publication/090410_Organizing_for_a_Complex_World_The_Way_Ahead_0.pdf CSIS paper: "Organizing for a Complex World: The Way Ahead]&lt;/ref&gt;

===Complexity economics===
Over the last decades, within the emerging field of [[complexity economics]] new predictive tools have been developed to explain economic growth. Such is the case with the models built by the [[Santa Fe Institute]] in 1989 and the more recent [[economic complexity index]] (ECI), introduced by the [[MIT]] physicist [[Cesar A. Hidalgo]] and the [[Harvard]] economist [[Ricardo Hausmann]]. Based on the ECI, Hausmann, Hidalgo and their team of [[The Observatory of Economic Complexity]] have [[List of countries by future GDP (based on ECI) estimates|produced GDP forecasts for the year 2020]].{{Citation needed|date=February 2016}}

=== Complexity and education ===
Focusing on issues of student persistence with their studies, Forsman, Moll and Linder explore the "viability of using complexity science as a frame to extend methodological applications for physics education research", finding that "framing a social network analysis within a complexity science perspective offers a new and powerful applicability across a broad range of PER topics".&lt;ref&gt;{{Cite journal|last=Forsman|first=Jonas|last2=Moll|first2=Rachel|last3=Linder|first3=Cedric|date=2014|title=Extending the theoretical framing for physics education research: An illustrative application of complexity science|url=http://link.aps.org/doi/10.1103/PhysRevSTPER.10.020122|journal=Physical Review Special Topics: Physics Education Research|volume=10|issue=2|doi=10.1103/PhysRevSTPER.10.020122|id=http://hdl.handle.net/10613/2583|bibcode=2014PRPER..10b0122F}}&lt;/ref&gt;

===Complexity and modeling===
One of Friedrich Hayek's main contributions to early complexity theory is his distinction between the human capacity to predict the behaviour of simple systems and its capacity to predict the behaviour of complex systems through [[Scientific modelling|modeling]]. He believed that economics and the sciences of complex phenomena in general, which in his view included biology, psychology, and so on, could not be modeled after the sciences that deal with essentially simple phenomena like physics.&lt;ref&gt;[http://www.reason.com/news/show/33304.html Reason Magazine - The Road from Serfdom&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; Hayek would notably explain that complex phenomena, through modeling, can only allow pattern predictions, compared with the precise predictions that can be made out of non-complex phenomena.&lt;ref&gt;[http://nobelprize.org/nobel_prizes/economics/laureates/1974/hayek-lecture.html Friedrich August von Hayek - Prize Lecture&lt;!-- Bot generated title --&gt;]&lt;/ref&gt;

===Complexity and chaos theory===
Complexity theory is rooted in [[chaos theory]], which in turn has its origins more than a century ago in the work of the French mathematician [[Henri Poincaré]]. Chaos is sometimes viewed as extremely complicated information, rather than as an absence of order.&lt;ref&gt;Hayles, N. K. (1991). ''Chaos Bound: Orderly Disorder in Contemporary Literature and Science''. Cornell University Press, Ithaca, NY.&lt;/ref&gt; Chaotic systems remain deterministic, though their long-term behavior can be difficult to predict with any accuracy. With perfect knowledge of the initial conditions and of the relevant equations describing the chaotic system's behavior, one can theoretically make perfectly accurate predictions about the future of the system, though in practice this is impossible to do with arbitrary accuracy. [[Ilya Prigogine]] argued&lt;ref&gt;Prigogine, I. (1997). ''The End of Certainty'', The Free Press, New York.&lt;/ref&gt; that complexity is non-deterministic, and gives no way whatsoever to precisely predict the future.&lt;ref&gt;See also {{cite journal |author=D. Carfì |year=2008 |title=Superpositions in Prigogine approach to irreversibility |journal=AAPP: Physical, Mathematical, and Natural Sciences |volume=86 |issue=1 |pages=1–13 |url=http://cab.unime.it/journals/index.php/AAPP/article/view/384/0 |format= |accessdate=}}.&lt;/ref&gt;

The emergence of complexity theory shows a domain between deterministic order and randomness which is complex.&lt;ref name="PC98"&gt;[[Paul Cilliers|Cilliers, P.]] (1998). ''Complexity and Postmodernism: Understanding Complex Systems'', Routledge, London.&lt;/ref&gt; This is referred as the "[[edge of chaos]]".&lt;ref&gt;[[Per Bak]] (1996). ''How Nature Works: The Science of Self-Organized Criticality'', Copernicus, New York, U.S.&lt;/ref&gt;

[[File:Lorenz attractor yb.svg|thumb|left|200px|A plot of the [[Lorenz attractor]].]]

When one analyzes complex systems, sensitivity to initial conditions, for example, is not an issue as important as it is within chaos theory, in which it prevails. As stated by Colander,&lt;ref&gt;Colander, D. (2000). ''The Complexity Vision and the Teaching of Economics'', E. Elgar, Northampton, Massachusetts.&lt;/ref&gt; the study of complexity is the opposite of the study of chaos. Complexity is about how a huge number of extremely complicated and dynamic sets of relationships can generate some simple behavioral patterns, whereas chaotic behavior, in the sense of deterministic chaos, is the result of a relatively small number of non-linear interactions.&lt;ref name="PC98"/&gt;

Therefore, the main difference between chaotic systems and complex systems is their history.&lt;ref&gt;Buchanan, M. (2000). ''Ubiquity : Why catastrophes happen'', three river press, New-York.&lt;/ref&gt; Chaotic systems do not rely on their history as complex ones do. Chaotic behaviour pushes a system in equilibrium into chaotic order, which means, in other words, out of what we traditionally define as 'order'.{{clarify|date=September 2011}} On the other hand, complex systems evolve far from equilibrium at the edge of chaos. They evolve at a critical state built up by a history of irreversible and unexpected events, which physicist [[Murray Gell-Mann]] called "an accumulation of frozen accidents".&lt;ref&gt;Gell-Mann, M. (1995). What is Complexity?  Complexity 1/1, 16-19&lt;/ref&gt; In a sense chaotic systems can be regarded as a subset of complex systems distinguished precisely by this absence of historical dependence. Many real complex systems are, in practice and over long but finite time periods, robust. However, they do possess the potential for radical qualitative change of kind whilst retaining systemic integrity. Metamorphosis serves as perhaps more than a metaphor for such transformations.

{{clear left}}

===Complexity and network science===
A complex system is usually composed of many components and their interactions. Such a system can be represented by a network where nodes represent the components and links represent their interactions.&lt;ref name=":0" /&gt;&lt;ref name="DorogovtsevMendes2003"&gt;{{cite journal|last1=Dorogovtsev|first1=S.N.|last2=Mendes|first2=J.F.F.|year=2003|doi=10.1093/acprof:oso/9780198515906.001.0001|title=Evolution of Networks|arxiv=cond-mat/0106144}}&lt;/ref&gt;
&lt;ref name="Fortunato2011"&gt;{{cite journal|last1=Fortunato|first1=Santo|title=Reuven Cohen and Shlomo Havlin: Complex Networks|journal=Journal of Statistical Physics|volume=142|issue=3|year=2011|pages=640–641|issn=0022-4715|doi=10.1007/s10955-011-0129-7|bibcode=2011JSP...142..640F}}&lt;/ref&gt;&lt;ref name="Newman2010"&gt;{{cite journal|last1=Newman|first1=Mark|year=2010|doi=10.1093/acprof:oso/9780199206650.001.0001|title=Networks}}&lt;/ref&gt; for example, the INTERNET can be represented as a network composed of nodes (computers) and links (direct connections between computers). Its resilience to failures was studied using percolation theory.&lt;ref name="CohenErez2001"&gt;{{cite journal|last1=Cohen|first1=Reuven|last2=Erez|first2=Keren|last3=ben-Avraham|first3=Daniel|last4=Havlin|first4=Shlomo|title=Cohen, Erez, ben-Avraham, and Havlin Reply:|journal=Physical Review Letters|volume=87|issue=21|year=2001|issn=0031-9007|doi=10.1103/PhysRevLett.87.219802|bibcode=2001PhRvL..87u9802C}}&lt;/ref&gt;
Other examples are social networks, airline networks,&lt;ref name="BarratBarthelemy2004"&gt;{{cite journal|last1=Barrat|first1=A.|last2=Barthelemy|first2=M.|last3=Pastor-Satorras|first3=R.|last4=Vespignani|first4=A.|title=The architecture of complex weighted networks|journal=Proceedings of the National Academy of Sciences|volume=101|issue=11|year=2004|pages=3747–3752|issn=0027-8424|doi=10.1073/pnas.0400087101|pmid=15007165|pmc=374315|arxiv=cond-mat/0311416|bibcode=2004PNAS..101.3747B}}&lt;/ref&gt; biological networks and climate networks.&lt;ref name="YamasakiGozolchiani2008"&gt;{{cite journal|last1=Yamasaki|first1=K.|last2=Gozolchiani|first2=A.|last3=Havlin|first3=S.|title=Climate Networks around the Globe are Significantly Affected by El Niño|journal=Physical Review Letters|volume=100|issue=22|year=2008|issn=0031-9007|doi=10.1103/PhysRevLett.100.228501|pmid=18643467|page=228501|bibcode=2008PhRvL.100v8501Y}}&lt;/ref&gt;
Networks can also fail and recover spontaneously. For modeling this phenomenon see Majdandzik et al.&lt;ref name="MajdandzicPodobnik2013"/&gt;
Interacting complex systems can be modeled as networks of networks. For their breakdown and recovery properties see Gao et al.&lt;ref name="GaoBuldyrev2011"&gt;{{cite journal|last1=Gao|first1=Jianxi|last2=Buldyrev|first2=Sergey V.|last3=Stanley|first3=H. Eugene|last4=Havlin|first4=Shlomo|title=Networks formed from interdependent networks|journal=Nature Physics|volume=8|issue=1|year=2011|pages=40–48|issn=1745-2473|doi=10.1038/nphys2180|bibcode=2012NatPh...8...40G|url=http://cps-www.bu.edu/hes/articles/gbsh12.pdf}}&lt;/ref&gt;
&lt;ref name="MajdandzicBraunstein2016"/&gt; Traffic in a city can be represented as a network. The weighted links represent  the velocity between two junctions (nodes). This approach was found useful to characterize the global traffic efficiency in  a city.&lt;ref&gt;{{Cite journal|last=Li|first=Daqing|last2=Fu|first2=Bowen|last3=Wang|first3=Yunpeng|last4=Lu|first4=Guangquan|last5=Berezin|first5=Yehiel|last6=Stanley|first6=H. Eugene|last7=Havlin|first7=Shlomo|date=2015-01-20|title=Percolation transition in dynamical traffic network with evolving critical bottlenecks|url=http://www.pnas.org/content/112/3/669|journal=Proceedings of the National Academy of Sciences|language=en|volume=112|issue=3|pages=669–672|doi=10.1073/pnas.1419185112|issn=0027-8424|pmid=25552558|bibcode=2015PNAS..112..669L|pmc=4311803}}&lt;/ref&gt; The complex pattern of exposures between financial institutions has been shown to trigger financial instability. &lt;ref&gt;{{Cite journal|last=Battiston|first= Stefano|last2=Caldarelli|first2=Guido|last3=May|first3=Robert M.|last4=Roukny|first4=tarik|last5=Stiglitz|first5=Joseph E.|date=2016-09-06|title=The price of complexity in financial networks|url=http://www.pnas.org/content/113/36/10031|journal=Proceedings of the National Academy of Sciences|language=en|volume=113|issue=36|pages=10031–10036|doi=10.1073/pnas.1521573113|bibcode=2016PNAS..11310031B|pmc=5018742}}&lt;/ref&gt;

===General form of complexity computation===

The computational law of reachable optimality&lt;ref&gt;Wenliang Wang (2015). Pooling Game Theory and Public Pension Plan. {{ISBN|978-1507658246}}. Chapter 4.&lt;/ref&gt; is established as a general form of computation for ordered systems and it reveals complexity computation is a compound computation of optimal choice and optimality driven reaching pattern over time underlying a specific and any experience path of ordered system within the general limitation of system integrity.

The computational law of reachable optimality has four key components as described below.

1. '''Reachability of Optimality''': Any intended optimality shall be reachable. Unreachable optimality has no meaning for a member in the ordered system and even for the ordered system itself.

2. '''Prevailing and Consistency''': Maximizing reachability to explore best available optimality is the prevailing computation logic for all members in the ordered system and is accommodated by the ordered system.

3. '''Conditionality''': Realizable tradeoff between reachability and optimality depends primarily upon the initial bet capacity and how the bet capacity evolves along with the payoff table update path triggered by bet behavior and empowered by the underlying law of reward and punishment. Precisely, it is a sequence of conditional events where the next event happens upon reached status quo from experience path.

4. '''Robustness''': The more challenge a reachable optimality can accommodate, the more robust it is in term of path integrity.

There are also four computation features in the law of reachable optimality.

1. '''Optimal Choice''': Computation in realizing Optimal Choice can be very simple or very complex. A simple rule in Optimal Choice is to accept whatever is reached, Reward As You Go (RAYG). A Reachable Optimality computation reduces into optimizing reachability when RAYG is adopted. The Optimal Choice computation can be more complex when multiple NE strategies present in a reached game.

2. '''Initial Status''': Computation is assumed to start at an interested beginning even the absolute beginning of an ordered system in nature may not and need not present. An assumed neutral Initial Status facilitates an artificial or a simulating computation and is not expected to change the prevalence of any findings.

3. '''Territory''': An ordered system shall have a territory where the universal computation sponsored by the system will produce an optimal solution still within the territory.

4. '''Reaching Pattern''': The forms of Reaching Pattern in the computation space, or the Optimality Driven Reaching Pattern in the computation space, primarily depend upon the nature and dimensions of measure space underlying a computation space and the law of punishment and reward underlying the realized experience path of reaching. There are five basic forms of experience path we are interested in, persistently positive reinforcement experience path, persistently [[negative reinforcement]] experience path, mixed persistent pattern experience path, decaying scale experience path and selection experience path.

The compound computation in selection experience path includes current and lagging interaction, dynamic topological transformation and implies  both invariance and variance characteristics in an ordered system's experience path.

In addition, the computation law of reachable optimality gives out the boundary between complexity model, chaotic model and determination model. When RAYG is the Optimal Choice computation, and the reaching pattern is a persistently positive experience path, persistently negative experience path, or mixed persistent pattern experience path, the underlying computation shall be a simple system computation adopting determination rules. If the reaching pattern has no persistent pattern experienced in RAYG regime, the underlying computation hints there is a chaotic system. When the optimal choice computation involves non-RAYG computation, it's a complexity computation driving the compound effect.

== Notable figures ==
* [[Robert McCormick Adams Jr.|Robert McCormick Adams]]
* [[Christopher Alexander]]
* [[Philip Warren Anderson|Philip Anderson]]
* [[Kenneth Arrow]]
* [[Robert Axelrod]]
* [[W. Brian Arthur]]
* [[Yaneer Bar-Yam]]
*&lt;nowiki/&gt;[[Albert-László Barabási|Albert-Laszlo Barabasi]]
* [[Gregory Bateson]]
* [[Ludwig von Bertalanffy|Lu]]&lt;nowiki/&gt;[[Ludwig von Bertalanffy|dwig von Bertalanffy]]
* [[Samuel Bowles (economist)|Samuel Bowles]]
* [[Paul Cilliers]]
* [[Walter Clemens, Jr.]]
* [[Brian J. Enquist|Brian Enquist]]
* [[Joshua M. Epstein|Joshua Epstein]]
* [[J. Doyne Farmer|Doyne Farmer]]
* [[Jay Forrester]]
* [[Murray Gell-Mann]]
* [[Nigel Goldenfeld]]
* [[James Hartle]]
* [[John Henry Holland|John Holland]]
* [[Alfred Hübler|Alfred Hubler]]
* [[Arthur Iberall]]
* [[Stuart Kauffman]]
* [[David Krakauer (scientist)|David Krakauer]]
* [[Ellen Levy]]
* [[Robert May, Baron May of Oxford|Robert May]]
* [[Melanie Mitchell]]
* [[Cris Moore]]
* [[Edgar Morin]]
* [[Harold J. Morowitz|Harold Morowitz]]
* [[David Pines]]
* [[Sidney Redner]]
* [[Jerry Sabloff]]
* [[Cosma Shalizi]]
* [[Dave Snowden]]
* [[Sergei Starostin]]
* [[Steven Strogatz]]
* [[Andreas Wagner]]
* [[Duncan J. Watts|Duncan Watts]]
* [[Geoffrey West]]
* [[Stephen Wolfram]]
* [[David Wolpert]]

== See also ==
{{Portal|Systems science}}
{|
|- style="vertical-align:top"
|style="padding-right:2em"|
* [[Biological organisation]]
* [[Chaos theory]]
* [[Cybernetics]]
* [[Cognitive model#Dynamical systems|Cognitive modeling]]
* [[Cognitive Science]]
* [[Complex (disambiguation)]]
* [[Complexity (disambiguation)]]
* [[Complex adaptive system]]
* [[Complex networks]]
* [[Complexity]]
* [[Complexity economics]]
* [[Decision engineering]]
* [[Dissipative system]]
* [[Dual-phase evolution]]
* [[Dynamical system]]
* [[Dynamical systems theory]]
|style="padding-right:2em"|
* [[Emergence]]
* [[Enterprise systems engineering]]
* [[Fractal]]
* [[Generative sciences]]
* [[Homeokinetics]]
* [[Interdependent networks]]
* [[Invisible hand]]
* [[Mixed reality]]
* [[Multi-agent system]]
* [[Network science]]
* [[Nonlinearity]]
* [[Pattern-oriented modeling]]
* [[Percolation]]
* [[Percolation theory]]
* [[Process architecture]]
* [[System equivalence]]
* [[System Dynamics]]
|
* [[Systems theory]]
** [[Systems theory in anthropology|in anthropology]]
* [[Self-organization]]
* [[Sociology and complexity science]]
* {{longitem|style=line-height:1.35em|[[Volatility, uncertainty, complexity and ambiguity|Volatility, uncertainty, complexity&lt;br/&gt;and ambiguity]]}}
|}

== References ==
{{Reflist}}

== Further reading ==
* Bazin, A. (2014). [https://www.academia.edu/attachments/34737324/download_file?st=MTQxNzA5MzgyNywxMDguMjYuMTIzLjE2MSwxMzMzMjk5MA%3D%3D&amp;s=swp-toolbar&amp;ct=MTQxNzA5MzgyNyw2OTU5MCwxMzMzMjk5MA==] Small Wars Journal.
* Syed M. Mehmud (2011), [https://web.archive.org/web/20120426052819/http://predictivemodeler.com/sitecontent/book/Ch06_Applications/Actuarial/HEC_Model/Healthcare%20Exchange%20Complexity%20Model%20-%20Report%20-%20Aug2011.pdf ''A Healthcare Exchange Complexity Model'']
* {{cite journal | last1 = Chu | first1 = D. | last2 = Strand | first2 = R. | last3 = Fjelland | first3 = R. | year = 2003 | title = Theories of complexity | url = | journal = Complexity | volume = 8 | issue = 3 | pages = 19–30 | doi = 10.1002/cplx.10059 | bibcode = 2003Cmplx...8c..19C }}
* [[Luis Amaral|L.A.N. Amaral]] and J.M. Ottino, [http://amaral-lab.org/media/publication_pdfs/Amaral-2004-Eur.Phys.J.B-38-147.pdf ''Complex networks — augmenting the framework for the study of complex system''], 2004.
* {{cite journal | last1 = Gell-Mann | first1 = Murray | year = 1995 | title = Let's Call It Plectics | url = http://www.santafe.edu/~mgm/Site/Publications_files/MGM%20118.pdf | format = PDF | journal = Complexity | volume = 1 | issue = 5 | doi = 10.1002/cplx.6130010502 | pages=3–5| bibcode = 1996Cmplx...1e...3G }}
* [[Nigel Goldenfeld]] and Leo P. Kadanoff, [http://guava.physics.uiuc.edu/~nigel/articles/complexity.html ''Simple Lessons from Complexity''], 1999
* A. Gogolin, A. Nersesyan and A. Tsvelik, [https://web.archive.org/web/20070715195144/http://www.cmth.bnl.gov/~tsvelik/theory.html ''Theory of strongly correlated systems ''], Cambridge University Press, 1999.
* Kelly, K. (1995). [http://www.kk.org/outofcontrol/contents.php ''Out of Control''], Perseus Books Group.
* {{cite journal | last1 = Donald Snooks | first1 = Graeme | year = 2008 | title = A general theory of complex living systems: Exploring the demand side of dynamics | url = | journal = Complexity | volume = 13 | issue = 6 | doi=10.1002/cplx.20225 | pages=12–20| bibcode = 2008Cmplx..13f..12S }}
* [https://sfi-edu.s3.amazonaws.com/sfi-edu/production/uploads/publication/2016/10/31/Bulletin_Fall_2014_FINAL.pdf SFI @30, Foundations &amp; Frontiers] (2014).
* [https://web.archive.org/web/20110220054920/http://www.oeaw.ac.at/byzanz/repository/Preiser_WorkingPapers_Calculating_I.pdf Preiser-Kapeller, Johannes, "Calculating Byzantium. Social Network Analysis and Complexity Sciences as tools for the exploration of medieval social dynamics". August 2010]
* [[Walter Clemens, Jr.]], [https://web.archive.org/web/20150219221633/http://www.sunypress.edu/p-5782-complexity-science-and-world-af.aspx ''Complexity Science and World Affairs''], SUNY Press, 2013.

== External links ==
{{Commons category|Complex systems}}
{{Wiktionary|complex systems}}
* {{cite web|url=http://www.openabm.org |title=The Open Agent-Based Modeling Consortium}}
* {{cite web|url=http://www.complexity.ecs.soton.ac.uk/ |title=Complexity Science Focus}}
* {{cite web|url=http://www.santafe.edu/ |title=Santa Fe Institute}}
* {{cite web|url=http://www.lsa.umich.edu/cscs/ |title=The Center for the Study of Complex Systems, Univ. of Michigan Ann Arbor}}
* {{cite web|url=http://indecs.eu/ |title=INDECS}} (Interdisciplinary Description of Complex Systems)
* {{cite web|url=http://www.complexityexplorer.org/courses/89-introduction-to-complexity |title=Introduction to Complexity - Free online course by Melanie Mitchell}}
* {{cite web|url=http://www.eoearth.org/view/article/51cbed507896bb431f69154d/?topic=51cbfc79f702fc2ba8129ed7 |title=Complex Systems|date=October 24, 2013|author=Jessie Henshaw|publisher=[[Encyclopedia of Earth]]}}
* [http://havlin.biu.ac.il/course1.php Introduction to complex systems-short course by Shlomo Havlin]
* [http://www.scholarpedia.org/article/Complex_Systems Complex systems] in scholarpedia.
* [http://cssociety.org Complex Systems Society]
* [http://www.complexsystems.net.au/ (Australian) Complex systems research network.]
* [http://informatics.indiana.edu/rocha/complex/csm.html Complex Systems Modeling] based on [[Luis M. Rocha]], 1999.
* [https://web.archive.org/web/20110722075059/http://www.crm.cat/ComplexSystems_Lines/defaultsistemescomplexos.htm CRM Complex systems research group]
* [https://web.archive.org/web/20110430200327/http://www.ccsr.uiuc.edu/ The Center for Complex Systems Research, Univ. of Illinois at Urbana-Champaign]
* [http://www.futurict.eu FuturICT - Exploring and Managing our Future]

{{Complex systems topics}}
{{Systems science}}

[[Category:Complex dynamics]]
[[Category:Complex systems theory| ]]
[[Category:Cybernetics]]
[[Category:Emergence]]
[[Category:Systems]]
[[Category:Systems science]]
[[Category:Mathematical modeling]]</text>
      <sha1>eizh7kkqmlefacooy9q6v3ic1ig5vie</sha1>
    </revision>
  </page>
  <page>
    <title>Computability logic</title>
    <ns>0</ns>
    <id>616985</id>
    <revision>
      <id>853654231</id>
      <parentid>828536883</parentid>
      <timestamp>2018-08-06T04:35:45Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 3 sources and tagging 0 as dead. #IABot (v2.0beta5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="28895">{{distinguish|computational logic}}
'''Computability logic''' ('''CoL''') is a research program and mathematical framework for redeveloping logic as a systematic formal theory of computability, as opposed to [[classical logic]] which is a formal theory of truth. It was introduced and so named by [[Giorgi Japaridze]] in 2003.&lt;ref&gt; G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S016800720300023X    Introduction to computability logic]''. Annals of Pure and Applied Logic 123 (2003), pages 1–99.&lt;/ref&gt; 

Comparing CoL with classical logic, while formulas in the latter represent true/false statements, in CoL they represent [[computational problem]]s. In classical logic, validity of a formula is understood as being always true, i.e., true regardless of the interpretation of its non-logical primitives (atoms), based solely on form rather than meaning. Similarly, in CoL validity means being always computable. More generally, classical logic tells us when the truth of a given statement always follows from the truth of a given set of other statements. Similarly, CoL tells us when the computability of a given problem  ''A'' always follows from the computability of other given problems ''B&lt;sub&gt;1&lt;/sub&gt;,…,B&lt;sub&gt;n&lt;/sub&gt;''. Moreover, it provides a uniform way to actually construct a solution ([[algorithm]]) for such an ''A'' from any known solutions of ''B&lt;sub&gt;1&lt;/sub&gt;,…,B&lt;sub&gt;n&lt;/sub&gt;''.

CoL understands computational problems in their most general – [[Interactive computation|interactive]] sense. They are formalized as games played by a machine against its environment, and computability means existence of a machine that wins the game against any possible behavior by the environment. Defining what such game-playing machines mean, CoL provides a generalization of the [[Church-Turing thesis]] to the interactive level. The classical concept of truth turns out to be a special, zero-interactivity-degree case of computability. This makes classical logic a special fragment of CoL. Being a [[conservative extension]] of the former, computability logic is, at the same time, by an order of magnitude more expressive, constructive and computationally meaningful. Besides classical logic, [[independence-friendly logic|independence-friendly (IF) logic]]  and certain proper extensions of [[linear logic]] and [[intuitionistic logic]] also turn out to be natural fragments of CoL.&lt;ref&gt;G. Japaridze, ''[http://www.springerlink.com/content/m02201161744867/?p=a62bebfc0dec4164a3a3ba90fefb86aa&amp;pi=10 In the beginning was game semantics]''.   Games: Unifying Logic, Language and Philosophy. O. Majer, A.-V. Pietarinen and T. Tulenheimo, eds. Springer 2009, pp.&amp;nbsp;249–350. [https://arxiv.org/pdf/cs/0507045v3.pdf Prepublication]&lt;/ref&gt;&lt;ref&gt;G. Japaridze, ''[https://www.sciencedirect.com/science/article/pii/S0168007207000346 The intuitionistic fragment of computability logic at the propositional level]''. Annals of Pure and Applied Logic 147 (2007), pages 187–227.&lt;/ref&gt; Hence meaningful concepts of "intuitionistic truth", "linear-logic truth" and "IF-logic truth" can be derived from the semantics of CoL.

Providing a systematic answer to the fundamental question of what can be computed and how, CoL claims a wide range of potential application areas. Those include constructive applied theories, knowledge base systems, systems for planning and action. Out of these, only applications in constructive applied theories have been extensively explored so far: a series of CoL-based number theories, termed "clarithmetics", have been constructed&lt;ref&gt;G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S0890540111001076 Introduction to clarithmetic I]''. Information and Computation 209 (2011),  pp.&amp;nbsp;1312–1354. [https://arxiv.org/pdf/1003.4719v6.pdf Prepublication]&lt;/ref&gt;&lt;ref&gt;G. Japaridze, ''[https://lmcs.episciences.org/2020/pdf Build your own clarithmetic I: Setup and completeness]''. Logical Methods is Computer Science 12 (2016), Issue 3, paper 8, pp.&amp;nbsp;1–59.&lt;/ref&gt; as computationally and complexity-theoretically meaningful alternatives to the classical-logic-based [[Peano axioms|Peano arithmetic]] and its variations such as systems of [[bounded arithmetic]].

The traditional proof systems such as [[natural deduction]] or [[sequent calculus]] turn out to be insufficient for axiomatizing any more or less nontrivial fragments of CoL. This has necessitated developing alternative, more general and flexible methods of proof, such as [[cirquent calculus]].&lt;ref&gt;G. Japaridze, ''[http://logcom.oxfordjournals.org/cgi/content/abstract/16/4/489  Introduction to cirquent calculus and abstract resource semantics]''. Journal of Logic and Computation 16 (2006),  pages 489–532. [https://arxiv.org/pdf/math/0506553v3.pdf Prepublication]&lt;/ref&gt;&lt;ref&gt;G. Japaridze, ''[https://link.springer.com/article/10.1007/s00153-012-0313-8 The taming of recurrences in computability logic through cirquent calculus, Part I]''. Archive for Mathematical Logic 52 (2013), pp.&amp;nbsp;173–212. [https://arxiv.org/abs/1105.3853 Prepublication]&lt;/ref&gt;

==Language== 
[[File:Operators_of_computability_logic.png|thumb|Operators of computability logic: names, symbols and readings]] The full language of CoL is an extension of the language of classical first-order logic. Its logical vocabulary has several sorts of conjunctions, disjunctions, quantifiers, implications, negations and so called recurrence operators. This collection includes  all connectives and quantifiers of classical logic. The language also has two sorts of nonlogical atoms: ''elementary'' and ''general''. Elementary atoms, which are nothing but the atoms of classical logic, represent ''elementary problems'', i.e., games with no moves that are automatically won by the machine when true and lost when false. General atoms, on the other hand, can be interpreted as any games, elementary or non-elementary. Both semantically and syntactically, classical logic is nothing but the fragment of CoL obtained by forbidding general atoms in its language, and forbidding all operators other than &amp;not;, &amp;and;, &amp;or;, &amp;rarr;, &amp;forall;, &amp;exist;.

Japaridze has repeatedly pointed out that the language of CoL is open-ended, and may undergo further extensions. Due to the expressiveness of this language, advances in CoL, such as constructing axiomatizations or building CoL-based applied theories, have usually been limited to one or another proper fragment of the language.

==Semantics== 
The games underlying the semantics of CoL are called "''static games''". Such games impose no regulations on which player can or should move in a given situation, and it is generally up to the player to decide whether to move or wait for moves by its adversary. It is always a possibility that the adversary moves while a given player is "thinking" on its next step. However, static games are defined in such a way that it never hurts a player to delay its own moves, so such games never become contests of speed. All elementary games are automatically static, and so are the games allowed to be interpretations of general atoms.  There are two players in static games: the ''machine'' and the ''environment''. The machine can only follow algorithmic strategies, while there are no restrictions on the behavior of the environment. Each run (play) is won by one of these players and lost by the other.

The logical operators of CoL are understood as operations on games. Here we informally survey some of those operations. For simplicity we assume that the domain of discourse is always {0,1,2,…}. 

The operation &amp;not; of ''negation'' ("not") switches the roles of the two players, turning moves and wins by the machine into those by the environment, and vice versa. For instance, if ''Chess'' is the game of chess (but with ties ruled out) from the white player’s perspective, then &amp;not;''Chess'' is the same game from the black player’s perspective. 

The ''parallel conjunction'' &amp;and; ("pand")  and ''parallel disjunction'' &amp;or; ("por") combine games in a parallel fashion. A run of ''A''&amp;and;''B'' or ''A''&amp;or;''B'' is a simultaneous play in the two conjuncts. The machine wins ''A''&amp;and;''B'' (resp. ''A''&amp;or;''B'') if it wins both (resp. at least one) of those. So, for instance, ''Chess''&amp;or;&amp;not;''Chess'' is a game on two boards, one played white and one black, and where the task of the machine is to win on at least one board. Such a game can be easily won regardless who the adversary is, by copying his moves from one board to the other. The ''parallel implication'' operator &amp;rarr; ("pimplication") is defined by ''A''&amp;rarr;''B'' = &amp;not;''A''&amp;or;''B''. The intuitive meaning of this operation is ''reducing'' ''B'' to ''A'', i.e., solving ''A'' as long as the adversary solves ''B''. The ''parallel quantifiers'' &lt;big&gt;&lt;big&gt;&amp;and;&lt;/big&gt;&lt;/big&gt; ("pall") and &lt;big&gt;&lt;big&gt;&amp;or;&lt;/big&gt;&lt;/big&gt; ("pexists") can be defined by &lt;big&gt;&lt;big&gt;&amp;and;&lt;/big&gt;&lt;/big&gt;''xA''(''x'') = ''A''(0)&amp;and;''A''(1)&amp;and;''A''(2)&amp;and;...  and  &lt;big&gt;&lt;big&gt;&amp;or;&lt;/big&gt;&lt;/big&gt;''xA''(''x'') = ''A''(0)&amp;or;''A''(1)&amp;or;''A''(2)&amp;or;.... These are thus simultaneous plays of ''A''(0),''A''(1),''A''(2),…, each on a separate board. The machine wins &lt;big&gt;&lt;big&gt;&amp;and;&lt;/big&gt;&lt;/big&gt;''xA''(''x'') (resp. &lt;big&gt;&lt;big&gt;&amp;or;&lt;/big&gt;&lt;/big&gt;''xA''(''x'')) if it wins all (resp. some) of these games. The ''blind quantifiers'' &amp;forall; ("blall") and &amp;exist; ("blexists"), on the other hand, generate single-board games. A run of &amp;forall;''xA''(''x'') or &amp;exist;''xA''(''x'') is a single run of ''A''. The machine wins &amp;forall;''xA''(''x'') (resp. &amp;exist;''xA''(''x'')) if such a run is a won run of ''A''(''x'') for all (resp. at least one) possible values of ''x''. 

All of the operators characterized so far behave exactly like their classical counterparts when they are applied to elementary (moveless) games, and validate the same principles. This is why CoL uses the same symbols for those operators as classical logic does. When such operators are applied to non-elementary games, however, their behavior is no longer classical. So, for instance, if ''p'' is an elementary atom and ''P'' a general atom, ''p''&amp;rarr;''p''&amp;and;''p'' is valid while ''P''&amp;rarr;''P''&amp;and;''P'' is not. The principle of the excluded middle ''P''&amp;or;&amp;not;''P'', however, remains valid. The same principle is invalid with all three other sorts (choice, sequential and toggling) of disjunction.  The ''choice disjunction''  &amp;#8852; ("chor") of games ''A'' and ''B'', written ''A''&amp;#8852;''B'', is a game where, in order to win, the machine has to choose one of the two disjuncts and then win in the chosen component. The ''sequential disjunction'' ("sor") ''A''&lt;small&gt;&amp;#5121;&lt;/small&gt;''B'' starts as ''A''; it also ends as ''A'' unless the machine makes a "switch" move, in which case ''A'' is abandoned and the game restarts and continues as ''B''. In the ''toggling disjunction'' ("tor") ''A''&amp;#10843;''B'', the machine may switch between ''A'' and ''B'' any finite number of times. Each disjunction operator has its dual conjunction, obtained by interchanging the roles of the two players. The corresponding quantifiers can further be defined as infinite conjunctions or disjunctions in the same way as in the case of the parallel quantifiers. Each sort disjunction also induces a corresponding implication operation the same way as this was the case with the parallel implication &amp;rarr;. For instance, the ''choice implication'' ("chimplication") ''A''&amp;#8848;''B'' is defined as &amp;not;''A''&amp;#8852;''B''. 

Then comes the ''recurrence'' group of operators. The ''parallel recurrence'' ("precurrence") of ''A'' can be defined as the infinite parallel conjunction ''A''&amp;and;A&amp;and;A&amp;and;... The sequential ("srecurrence") and toggling ("trecurrence") sorts of recurrences can be defined similarly. The corresponding ''corecurrence'' operators, on the other hand, can be defined as infinite disjunctions instead. ''Branching recurrence'' ("brecurrence") &lt;big&gt;&amp;#10992;&lt;/big&gt;, which is the strongest sort of recurrence, does not have a corresponding conjunction. &lt;big&gt;&amp;#10992;&lt;/big&gt;''A'' is a game that starts and proceeds as ''A''. At any time, however, the environment is allowed to make a "replicative" move, which creates two copies of the then-current position of ''A'', thus splitting the play into two parallel threads with a common past but possibly different future developments. In the same fashion, the environment can further replicate any of positions of any thread, thus creating more and more threads of ''A''. Those threads are played in parallel, and the machine needs to win ''A'' in all threads to be the winner in &lt;big&gt;&amp;#10992;&lt;/big&gt;''A''. ''Branching corecurrence'' ("cobrecurrence") &lt;big&gt;&amp;#10991;&lt;/big&gt; is defined symmetrically by interchanging "machine" and "environment". 

Each sort of recurrence further induces a corresponding weak version of implication and weak version of negation. The former is said to be a ''rimplication'', and the latter a ''refutation''. The ''branching rimplication'' ("brimplication") ''A''&lt;big&gt;&amp;#10204;&lt;/big&gt;''B'' is nothing but &lt;big&gt;&amp;#10992;&lt;/big&gt;''A''&amp;rarr;''B'', and the ''branching refutation'' ("brefutation") of ''A'' is ''A''&lt;big&gt;&amp;#10204;&lt;/big&gt;&amp;#8869;, where &amp;#8869; is the always-lost elementary game. Similarly for all other sorts of rimplication and refutation.

==As a problem specification tool== 
The language of CoL offers a systematic way to specify an infinite variety of computational problems, with or without names established in the literature. Below are some examples. 

Let ''f'' be a unary function. The problem of computing ''f'' will be written as &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;x&lt;big&gt;&lt;big&gt;&amp;#8852;&lt;/big&gt;&lt;/big&gt;y(''y''=''f''(''x'')). According to the semantics of CoL, this is a game where the first move ("input") is by the environment, which should choose a value ''m'' for ''x''. Intuitively, this amounts to asking the machine to tell the value of ''f''(''m''). The game continues as &lt;big&gt;&lt;big&gt;&amp;#8852;&lt;/big&gt;&lt;/big&gt;y(''y''=''f''(''m'')). Now the machine is expected to make a move ("output"), which should be choosing a value ''n'' for ''y''. This amounts to saying that ''n'' is the value of ''f''(m). The game is now brought down to the elementary ''n''=''f''(''m''), which is won by the machine if and only if ''n'' is indeed the value of ''f''(''m''). 

Let ''p'' be a unary predicate. Then &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''p''(''x'')&amp;#8852;&amp;not;''p''(''x'')) expresses the problem of [[Decidability (logic)|deciding]] ''p'', &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''p''(''x'')&amp;&lt;small&gt;&amp;#5121;&lt;/small&gt;&amp;not;''p''(''x'')) expresses the problem of [[Recursively enumerable set|semidieciding]] ''p'', and &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''p''(''x'')&amp;#10843;&amp;not;''p''(''x'')) the problem of [[Computation in the limit|recursively approximating]] ''p''. 

Let ''p'' and ''q'' be two unary predicates. Then  &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''p''(''x'')&amp;#8852;&amp;not;''p''(''x''))&lt;big&gt;&amp;#10204;&lt;/big&gt;&lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''q''(''x'')&amp;#8852;&amp;not;''q''(''x'')) expresses the problem of [[Turing reduction|Turing-reducing]] ''q'' to ''p'' (in the sense that ''q'' is Turing reducible to ''p'' if and only if the interactive problem  &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''p''(''x'')&amp;#8852;&amp;not;''p''(''x''))&lt;big&gt;&amp;#10204;&lt;/big&gt;&lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''q''(''x'')&amp;#8852;&amp;not;''q''(''x'')) is computable).   &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''p''(''x'')&amp;#8852;&amp;not;''p''(''x''))&lt;big&gt;&amp;rarr;&lt;/big&gt;&lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''(''q''(''x'')&amp;#8852;&amp;not;''q''(''x'')) does the same but for the stronger version of Turing reduction where the oracle for ''p'' can be queried only once. &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;x&lt;big&gt;&lt;big&gt;&amp;#8852;&lt;/big&gt;&lt;/big&gt;''y''(''q''(''x'')&amp;#8596;''p''(''y'')) does the same for the problem of [[Many-one reduction|many-one reducing]] ''q'' to ''p''. With more complex expressions one can capture all kinds of nameless yet potentially meaningful relations and operations on computational problems, such as, for instance, "Turing-reducing the problem of semideciding ''r'' to the problem of many-one reducing ''q'' to ''p''". Imposing time or space restrictions on the work of the machine, one further gets complexity-theoretic counterparts of such relations and operations.

==As a problem solving tool== 
The known deductive systems for various fragments of CoL share the property that a solution (algorithm) can be automatically extracted from a proof of a problem in the system. This property is further inherited by all applied theories based on those systems.  So, in order to find a solution for a given problem, it is sufficient to express it in the language of CoL and then find a proof of that expression. Another way to look at this phenomenon is to think of a formula ''G'' of CoL as program specification (goal). Then a proof of ''G'' is – more precisely, translates into – a program meeting that specification. There is no need to verify that the specification is met, because the proof itself is, in fact, such a verification. 

Examples of CoL-based applied theories are the so-called ''clarithmetics''. These are number theories based on CoL in the same sense as Peano arithmetic PA is based on classical logic. Such a system is usually a conservative extension of PA. It typically includes all [[Peano axioms]], and adds to them one or two extra-Peano axioms such as &lt;big&gt;&lt;big&gt;&amp;#8851;&lt;/big&gt;&lt;/big&gt;''x''&lt;big&gt;&lt;big&gt;&amp;#8852;&lt;/big&gt;&lt;/big&gt;''y''(''y''=''x''') expressing the computability of the successor function. Typically it also has one or two non-logical rules of inference, such as constructive versions of induction or comprehension. Through routine variations in such rules one can obtain sound and complete systems characterizing one or another interactive computational complexity class ''C''. This is in the sense that a problem belongs to ''C'' if and only if it has a proof in the theory. So, such a theory can be used for finding not merely algorithmic solutions, but also efficient ones on demand, such as solutions that run in polynomial time or logarithmic space. It should be pointed out that all claritmetical theories share the same logical postulates, and only their non-logical postulates vary depending on the target complexity class. Their notable distinguishing feature from other approaches with similar aspirations (such as [[bounded arithmetic]]) is that they extend rather than weaken PA, preserving the full deductive power and convenience of the latter.

==Literature==
*M. Bauer, ''[http://dl.acm.org/citation.cfm?id=2559949 A PSPACE-complete first order fragment of computability logic]''.  ACM Transactions on Computational Logic 15 (2014), No 1, Article 1, 12 pages.
*M. Bauer, ''[https://arxiv.org/pdf/1401.1849.pdf The computational complexity of propositional cirquent calculus]''.  Logical Methods is Computer Science 11 (2015), Issue 1, Paper 12, pages 1–16.
*G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S016800720300023X    Introduction to computability logic]''. Annals of Pure and Applied Logic 123 (2003), pages 1–99.
*G. Japaridze, ''[http://portal.acm.org/citation.cfm?id=1131313.1131318&amp;coll=portal&amp;dl=ACM&amp;idx=1131313&amp;part=periodical&amp;WantType=periodical&amp;title=ACM%20Transactions%20on%20Computational%20Logic%20%28TOCL%29&amp;CFID=71203179&amp;CFTOKEN=21225900  Propositional computability logic I]''. ACM Transactions on Computational Logic 7 (2006),  pages 302–330.
*G. Japaridze, ''[http://portal.acm.org/citation.cfm?id=1131313.1131319&amp;coll=portal&amp;dl=ACM&amp;idx=1131313&amp;part=periodical&amp;WantType=periodical&amp;title=ACM%20Transactions%20on%20Computational%20Logic%20%28TOCL%29&amp;CFID=71203179&amp;CFTOKEN=21225900 Propositional computability logic II]''. ACM Transactions on Computational Logic 7 (2006),  pages 331–362. 
*G. Japaridze, ''[http://logcom.oxfordjournals.org/cgi/content/abstract/16/4/489  Introduction to cirquent calculus and abstract resource semantics]''. Journal of Logic and Computation 16 (2006),  pages 489–532. [https://arxiv.org/pdf/math/0506553v3.pdf Prepublication]
*G. Japaridze, ''[http://www.springerlink.com/content/l10m555830730182/   Computability logic: a formal theory of interaction]''. Interactive Computation: The New Paradigm. D.Goldin, S.Smolka and P.Wegner, eds. Springer Verlag, Berlin 2006, pages 183–223.  [https://arxiv.org/pdf/cs/0404024v3.pdf Prepublication]
*G. Japaridze, ''[https://www.sciencedirect.com/science/article/pii/S0304397506002660 From truth to computability I]''. Theoretical Computer Science 357 (2006), pages 100–135.
*G. Japaridze, ''[https://www.sciencedirect.com/science/article/pii/S0304397507000199 From truth to computability II]''. Theoretical Computer Science 379 (2007), pages 20–52.
*G. Japaridze, ''[http://www.inf.u-szeged.hu/actacybernetica/edb/vol18n1/Japaridze_2007_ActaCybernetica.xml Intuitionistic computability logic]''. Acta Cybernetica 18 (2007), pages 77–113.
*G. Japaridze, ''[https://web.archive.org/web/20150628201840/http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.jsl%2F1174668394 The logic of interactive Turing reduction]''. Journal of Symbolic Logic 72 (2007),  pages 243–276.  [https://arxiv.org/pdf/cs/0512100v4.pdf Prepublication]
*G. Japaridze, ''[https://www.sciencedirect.com/science/article/pii/S0168007207000346 The intuitionistic fragment of computability logic at the propositional level]''. Annals of Pure and Applied Logic 147 (2007), pages 187–227.
*G. Japaridze, ''[https://archive.is/20130415174625/http://logcom.oxfordjournals.org/cgi/content/abstract/exn019 Cirquent calculus deepened]''. Journal of Logic and Computation 18 (2008), No.6, pp.&amp;nbsp;983–1028.
*G. Japaridze, ''[http://clx.doi.org/10.1016/j.ic.2008.10.001  Sequential operators in computability logic]{{dead link|date=August 2017 |bot=InternetArchiveBot |fix-attempted=yes }}''. Information and Computation 206 (2008), No.12, pp.&amp;nbsp;1443–1475. [https://arxiv.org/pdf/0712.1345v2.pdf Prepublication]
*G. Japaridze, ''[http://www.springerlink.com/content/04t6780731373n13/ Many concepts and two logics of algorithmic reduction]''. Studia Logica 91 (2009), No.1,  pp.&amp;nbsp;1–24.  [https://arxiv.org/pdf/0706.0103v4.pdf Prepublication]
*G. Japaridze, ''[http://www.springerlink.com/content/m022011617448676/?p=a62bebfc0dec4164a3a3ba90fefb86aa&amp;pi=10 In the beginning was game semantics]''.   Games: Unifying Logic, Language and Philosophy. O. Majer, A.-V. Pietarinen and T. Tulenheimo, eds. Springer 2009, pp.&amp;nbsp;249–350. [https://arxiv.org/pdf/cs/0507045v3.pdf Prepublication]
*G. Japaridze, ''[https://web.archive.org/web/20150629001449/http://projecteuclid.org/DPubS?verb=Display&amp;version=1.0&amp;service=UI&amp;handle=euclid.jsl%2F1268917495&amp;page=record Towards applied theories based on computability logic]''.  Journal of Symbolic Logic 75 (2010), pp.&amp;nbsp;565–601.
*G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S0304397510006754 Toggling operators in computability logic]''. Theoretical Computer Science 412 (2011), pp.&amp;nbsp; 971–1004. [https://arxiv.org/pdf/0904.3469v2.pdf Prepublication]
*G. Japaridze, ''[https://arxiv.org/pdf/0906.2154.pdf From formulas to cirquents in computability logic]''. Logical Methods in Computer Science 7 (2011), Issue 2 , Paper 1, pp.&amp;nbsp;1–55.
*G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S0890540111001076 Introduction to clarithmetic I]''. Information and Computation 209 (2011),  pp.&amp;nbsp;1312–1354. [https://arxiv.org/pdf/1003.4719v6.pdf Prepublication]
*G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S0168007211001734 Separating the basic logics of the basic recurrences]''. Annals of Pure and Applied Logic 163 (2012), pp.&amp;nbsp;377–389. [https://arxiv.org/pdf/1007.1324v3.pdf Prepublication]
*G. Japaridze, ''[http://logcom.oxfordjournals.org/content/22/3/605.full.pdf+html A logical basis for constructive systems]''. Journal of Logic and Computation 22 (2012), pp.&amp;nbsp;605–642. 
*G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S0893965911005763 A new face of the branching recurrence of computability logic]''. Applied Mathematics Letters 25 (2012), &amp;nbsp;1585–1589. [https://arxiv.org/pdf/1102.1054v2.pdf Prepublication]
*G. Japaridze, ''[https://link.springer.com/article/10.1007/s00153-012-0313-8 The taming of recurrences in computability logic through cirquent calculus, Part I]''. Archive for Mathematical Logic 52 (2013), pp.&amp;nbsp;173–212. [https://arxiv.org/abs/1105.3853 Prepublication]
*G. Japaridze, ''[https://link.springer.com/article/10.1007/s00153-012-0314-7 The taming of recurrences in computability logic through cirquent calculus, Part II]''. Archive for Mathematical Logic   52 (2013),  pp.&amp;nbsp;213–259. [https://arxiv.org/abs/1106.3705 Prepublication]
*G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S0168007213001115 Introduction to clarithmetic III]''. Annals of Pure and Applied Logic 165 (2014), &amp;nbsp;241–252. [https://arxiv.org/pdf/1008.0770v2.pdf Prepublication]
*G. Japaridze, ''[https://arxiv.org/pdf/1203.0103.pdf On the system CL12 of computability logic ]''. Logical Methods is Computer Science 11 (2015), Issue 3, paper 1, pp.&amp;nbsp;1–71.  
*G. Japaridze, ''[http://www.sciencedirect.com/science/article/pii/S0890540116000092 Introduction to clarithmetic II]''.  Information and Computation 247 (2016), pp.&amp;nbsp;290–312.
*G. Japaridze, ''[https://lmcs.episciences.org/2020/pdf Build your own clarithmetic I: Setup and completeness]''. Logical Methods is Computer Science 12 (2016), Issue 3, paper 8, pp.&amp;nbsp;1–59.  
*G. Japaridze, ''[https://lmcs.episciences.org/2042/pdf Build your own clarithmetic II: Soundness]''. Logical Methods is Computer Science 12 (2016), Issue 3, paper 12,  pp.&amp;nbsp;1–62.  
*K. Kwon, ''[http://search.ieice.org/bin/summary.php?id=e97-a_6_1385&amp;category=A&amp;year=2014&amp;lang=E&amp;abst= Expressing algorithms as concise as possible via computability logic]''. IEICE Transactions on Fundamentals of Electronics, Communications and Computer Sciences, v. E97-A (2014), pp.&amp;nbsp;1385–1387. 
*X. Li and J. Liu, ''[http://www.doc88.com/p-9035333690863.html Research on decidability of CoL2 in computability logic]''. Computer Science 42 (2015), No 7, pp.&amp;nbsp;44–46.
*I. Mezhirov and N. Vereshchagin, ''[http://portal.acm.org/citation.cfm?id=1808347.1808575 On abstract resource semantics and computability logic]''. Journal of Computer and System Sciences 76 (2010), pp.&amp;nbsp;356–372.
*M. Qu, J. Luan, D. Zhu and M. Du, ''[https://link.springer.com/article/10.1007%2Fs11390-013-1329-1 On the toggling-branching recurrence of computability logic]''. Journal of Computer Science and Technology 28 (2013), pp.&amp;nbsp;278–284.
*N. Vereshchagin, ''[http://lpcs.math.msu.su/~ver/papers/japaridze.ps   Japaridze's computability logic and intuitionistic propositional calculus]''. Moscow State University, 2006.
*W. Xu and S. Liu, ''[http://www.sciencedirect.com/science/article/pii/S157086831200047X  The countable versus uncountable branching recurrences in computability logic]''. Journal of Applied Logic 10 (2012), pp.&amp;nbsp;431–446.
*W. Xu and S. Liu, ''[http://jigpal.oxfordjournals.org/content/20/1/317.abstract Soundness and completeness of the cirquent calculus system CL6 for computability logic]''.  Logic Journal of the IGPL 20 (2012), pp.&amp;nbsp;317–330.
*W. Xu and S. Liu, ''[https://web.archive.org/web/20170116174906/http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.ndjfl%2F1355494523 The parallel versus branching recurrences in computability logic]''.  Notre Dame Journal of Formal Logic 54 (2013), pp.&amp;nbsp;61–78.
*W. Xu, ''[http://jigpal.oxfordjournals.org/content/22/6/982  A propositional system induced by Japaridze’s approach to IF logic]''. Logic Journal of the IGPL 22 (2014), pp.&amp;nbsp;982–991
*W. Xu, ''[http://www.sciencedirect.com/science/article/pii/S1570868316300131 A cirquent calculus system with clustering and ranking]''. Journal of Applied Logic 16 (2016), pp.&amp;nbsp;37–49.

==See also==
*[[Game semantics]]
*[[Interactive computation]]
*[[Logic]]
*[[Logics for computability]]

==References==
{{Reflist}}

==External links==
*[http://www.csc.villanova.edu/~japaridz/CL/ Computability Logic Homepage] Comprehensive survey of the subject.
*[http://www.csc.villanova.edu/~japaridz/ Giorgi Japaridze] 
*[http://www.csc.villanova.edu/~japaridz/CL/gsoll.html Game Semantics or Linear Logic?]
*[http://www.csc.villanova.edu/~japaridz/CL/clx.html Lecture Course on Computability Logic]
* [http://www.mathnet.ru/php/presentation.phtml?option_lang=eng&amp;presentid=4373 On abstract resource semantics and computabilty logic] Video lecture by N.Vereshchagin.

{{Logic}}

[[Category:Computability theory]]
[[Category:Logic in computer science]]
[[Category:Non-classical logic]]</text>
      <sha1>o72vwip0p09bmje8ktrnop1v8obx7ya</sha1>
    </revision>
  </page>
  <page>
    <title>Cora Barbara Hennel</title>
    <ns>0</ns>
    <id>55589991</id>
    <revision>
      <id>832763064</id>
      <parentid>827175479</parentid>
      <timestamp>2018-03-27T21:28:52Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Removed invisible unicode characters + other fixes ([[User:Yobot/55|Task 55]]), replaced: → using [[Project:AWB|AWB]] (12151)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5042">'''Cora Barbara Hennel''' (January 21, 1886 – June 26, 1947) was an Indiana mathematician active in the first half of the 20th century.

== Early life and education ==
Hennel was born in [[Evansville, Indiana]] to Joseph H. and Anna Marie Thuman Hennel.&lt;ref name=":0"&gt;{{Cite web|url=http://purl.dlib.indiana.edu/iudl/findingaids/archives/InU-Ar-VAC9620|title=Cecilia Hennel Hendricks family papers, 1843-1971, bulk 1896-1970|website=purl.dlib.indiana.edu|access-date=2017-10-21}}&lt;/ref&gt; After high school graduation Cora and her older sister [[Cecilia Hennel Hendricks|Cecilia]] taught in country grade schools to save money for college. In 1903, both Hennels entered [[Indiana University]] and shortly thereafter, convinced their parents to move with their younger sister, Edith, to [[Bloomington, Indiana|Bloomington]]. All three sisters attended and graduated from Indiana University.&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=IRbOAwAAQBAJ&amp;pg=PA199&amp;lpg=PA199&amp;dq=Cora+B.+Hennel&amp;source=bl&amp;ots=RDcuIdHKPK&amp;sig=nGuRuG1qr6jwTTv-QdfwmGmJNFM&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjtgNjYhYLXAhUSyYMKHduyA04Q6AEIWjAM#v=onepage&amp;q=Cora%20B.%20Hennel&amp;f=false|title=Pioneering Women in American Mathematics: The Pre-1940 PhD's| first1 = Judy | last1 = Green | author1-link = Judy Green (mathematician) | first2 = Jeanne | last2 = LaDuke | author2-link = Jeanne LaDuke|date=2009|publisher=American Mathematical Soc.|isbn=9780821843765|language=en}} Biography on p.261-263 of the [https://www.ams.org/bookpages/hmath-34-PioneeringWomen.pdf Supplementary Material] at [https://www.ams.org/publications/authors/books/postpub/hmath-34 AMS]&lt;/ref&gt; Hennel earned her earned her A.B. in Mathematics in 1907, her Masters in 1908, and in 1912, became the first person to earn a Ph.D. in Mathematics from Indiana University.&lt;ref name=":0" /&gt;&lt;ref&gt;{{Cite web|url=https://hdl.handle.net/2027/uc1.b2872360?urlappend=;seq=99|title=Indiana University Alumni Quarterly v. 1 1914.|website=HathiTrust|language=en|access-date=2017-12-29}}&lt;/ref&gt; As an undergraduate, Cora was the class poet and active in student affairs; in graduate school, she was a founding member and Secretary of the Euclidean Circle,&lt;ref&gt;{{cite web|url=http://webapp1.dlib.indiana.edu/findingaids/view?doc.view=entire_text&amp;docId=InU-Ar-VAA2782|title=Euclidean Circle (Indiana University) records, 1907-1942|work=Archives online|publisher=Indiana University|accessdate=2017-10-22}}&lt;/ref&gt; a mathematics club for faculty and students.

== Career ==
As she worked toward her doctorate, Cora served as Instructor in the Department of Mathematics. She continued in this role after receipt of her degree and in 1916, she was appointed Assistant Professor of Mathematics. She was promoted to Associate Professor in 1923 and became a full Professor in 1936. Hennel spent the entirety of her academic career at Indiana University and was still teaching at the time of her death in 1947.&lt;ref&gt;{{Cite web|url=http://webapp1.dlib.indiana.edu/iubot/|title=Indiana University Board of Trustees Minutes - Home|website=webapp1.dlib.indiana.edu|access-date=2017-10-21}}&lt;/ref&gt;

Hennel was an active member of the Indiana University faculty, serving as president of the Bloomington chapter of the [[American Association of University Professors]], the [[American Association of University Women]] and served as chair of the Indiana Section of the [[Mathematical Association of America]]. Professionally, she was a member of [[Phi Beta Kappa]], [[Sigma Xi]], [[Pi Lambda Theta]], [[Mortar Board]], and the Indiana Academy of Sciences.&lt;ref name=":1"&gt;{{Cite web|url=https://www.agnesscott.edu/lriddle/women/hennel.htm|title=Cora Barbara Hennel|website=www.agnesscott.edu|access-date=2017-10-21}}&lt;/ref&gt;

== Honors and tributes ==
In 1958, Cecilia Hennel established the Cora B. Hennel Memorial Scholarship to honor her sister. The Hennel Scholarships are awarded to students who have demonstrated high ability in mathematics.&lt;ref&gt;{{Cite web|url=https://math.indiana.edu/undergraduate/Aid.html|title=Aid:                                   Undergraduate:                                     Department of Mathematics: Indiana University|website=Department of Mathematics|language=en-US|access-date=2017-10-21}}&lt;/ref&gt; The department continues to remember Hennel and in 1995, named the faculty/student lounge in the renovated Rawles Hall the Cora B. Hennel Room.&lt;ref name=":1" /&gt;

== Selected published works ==
* "Transformations and Invariants Connected with Linear Homogeneous Difference Equations and other Functional Equations" in ''[[American Journal of Mathematics]]'' 35, no. 4 (1913): 431-52
* ''[https://hdl.handle.net/2027/uc1.$b423549 A Course in General Mathematics]'' (1925), co-authored with Harold T. Davis

== References ==
&lt;references /&gt;

{{DEFAULTSORT:Hennel, Cora Barbara}}
[[Category:Women in mathematics]]
[[Category:1886 births]]
[[Category:1947 deaths]]
[[Category:Indiana University alumni]]
[[Category:People from Evansville, Indiana]]
[[Category:Indiana University faculty]]
[[Category:Women mathematicians]]</text>
      <sha1>avitm6gvfbew3xjss91d8l9wowsi5a2</sha1>
    </revision>
  </page>
  <page>
    <title>Cryptology ePrint Archive</title>
    <ns>0</ns>
    <id>87047</id>
    <revision>
      <id>865106824</id>
      <parentid>732160635</parentid>
      <timestamp>2018-10-21T19:41:52Z</timestamp>
      <contributor>
        <username>BenKuykendall</username>
        <id>12604315</id>
      </contributor>
      <comment>add IACR template</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="831">{{no footnotes|date=January 2013}}
The '''Cryptology ePrint Archive''' is an electronic archive ([[eprint]]) of new results in the field of [[cryptography]], maintained by the [[International Association for Cryptologic Research]]. It contains articles covering many of the most recent advances in cryptography, that did not (yet) undergo any [[peer review|refereeing process]].

==See also==
* [[arXiv]]
* [[Electronic Colloquium on Computational Complexity]]

==External links==
* [http://eprint.iacr.org/ ePrint Archive]

[[Category:Cryptography journals]]
[[Category:Publications with year of establishment missing]]
[[Category:Discipline-oriented digital libraries]]
[[Category:Eprint archives]]
[[Category:Open-access archives]]


{{crypto-stub}}
{{compu-journal-stub}}

{{International Association for Cryptologic Research}}</text>
      <sha1>su7tquulp75y3p9ruviml27dvlbsjh8</sha1>
    </revision>
  </page>
  <page>
    <title>Cyclohedron</title>
    <ns>0</ns>
    <id>31649951</id>
    <revision>
      <id>796727220</id>
      <parentid>687078240</parentid>
      <timestamp>2017-08-22T18:21:39Z</timestamp>
      <contributor>
        <username>Natg 19</username>
        <id>3492060</id>
      </contributor>
      <minor/>
      <comment>Disambiguating links to [[Configuration space]] (link changed to [[Configuration space (mathematics)]]) using [[User:Qwertyytrewqqwerty/DisamAssist|DisamAssist]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2271">[[File:Cyclohedron W3.svg|thumb|300px|Cyclohedron W&lt;sub&gt;3&lt;/sub&gt;]]
In [[geometry]], the '''cyclohedron''' or '''Bott–Taubes polytope''' is a certain (''n''&amp;nbsp;&amp;minus;&amp;nbsp;1)-dimensional [[polytope]] that is useful in studying [[knot invariant]]s.{{sfn|Stasheff|1997|p=58}}

The [[Configuration space (mathematics)|configuration space]] of ''n'' distinct points on the circle ''S''&lt;sup&gt;1&lt;/sup&gt; is an ''n''-dimensional [[manifold]], which can be [[Fulton–MacPherson compactification|compactified]] into a [[manifold with corners]] by allowing the points to approach each other.  This [[Compactification (mathematics)|compactification]] can be factored as &lt;math&gt;S^1 \times W_n&lt;/math&gt;, where ''W&lt;sub&gt;n&lt;/sub&gt;'' is the '''cyclohedron'''.

==See also==
*[[Associahedron]]
*[[Permutohedron]]

==Notes==
{{Reflist}}

==References==
{{Refbegin}}
*{{Citation |last=Stasheff |first=Jim|authorlink=Jim Stasheff |year=1997 |chapter=From operads to 'physically' inspired theories |editor-last=Loday |editor-first=Jean-Louis |editor2-last=Stasheff |editor2-first=James D. |editor3-last=Voronov |editor3-first=Alexander A. |title=Operads: Proceedings of Renaissance Conferences |series=Contemporary Mathematics |volume=202 |pages=53–82 |publisher=AMS Bookstore |isbn=978-0-8218-0513-8 |url=http://www.math.unc.edu/Faculty/jds/operadchik.ps |accessdate=1 May 2011}}
{{Refend}}

==Further reading==
{{Refbegin}}
*{{Citation |last=Forcey |first=Stefan |last2=Springfield |first2=Derriell |date=December 2010 |title=Geometric combinatorial algebras: cyclohedron and simplex |journal=[[Journal of Algebraic Combinatorics]] |volume=32 |issue=4 |pages=597–627 |doi=10.1007/s10801-010-0229-5 |arxiv=0908.3111}}
*{{Citation |last=Morton |first=James |last2=Pachter |first2=Lior|author2-link= Lior Pachter |last3=Shiu |first3=Anne |last4=Sturmfels |first4=Bernd|author4-link=Bernd Sturmfels |date=January 2007 |title=The Cyclohedron Test for Finding Periodic Genes in Time Course Expression Studies |journal=[[Statistical Applications in Genetics and Molecular Biology]] |volume=6 |issue=1 |doi=10.2202/1544-6115.1286 |arxiv=q-bio/0702049}}
{{Refend}}

==External links==
*{{mathworld|title=Cyclohedron|urlname=Cyclohedron|author=Bryan Jacobs}}

[[Category:Polytopes]]


{{Geometry-stub}}</text>
      <sha1>8044y8mropvq3gvpdeafk1dj6d1ss4s</sha1>
    </revision>
  </page>
  <page>
    <title>David Hilbert</title>
    <ns>0</ns>
    <id>8302</id>
    <revision>
      <id>869190182</id>
      <parentid>867836518</parentid>
      <timestamp>2018-11-17T00:05:53Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Anne Bosworth]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="49908">{{short description|German mathematician}}
{{Redirect|Hilbert}}
{{Infobox scientist
| name = David Hilbert
| image = Hilbert.jpg
| image_size = 220px
| caption = David Hilbert (1912)
| birth_date = {{birth date|1862|1|23|df=y}}
| birth_place = [[Königsberg]] or [[Wehlau]], [[Province of Prussia]] in the [[Kingdom of Prussia]] (today [[Kaliningrad]] or [[Znamensk, Kaliningrad Oblast]] in [[Russia]])
| death_date = {{death date and age|1943|2|14|1862|1|23|df=y}}
| death_place = [[Göttingen]], [[Nazi Germany]]
| nationality = [[Germany|German]]
| field = [[Mathematics]], [[Physics]] and [[Philosophy]]
| work_institutions = [[University of Königsberg]]&lt;br /&gt;[[Göttingen University]]
| alma_mater = [[University of Königsberg]] ([[PhD]])
| thesis_title = On Invariant Properties of Special Binary Forms, Especially of Spherical Functions
| thesis_year = 1885
| doctoral_advisor = [[Ferdinand von Lindemann]]&lt;ref name="Lindemann"&gt;{{MathGenealogy|id=7298}}&lt;/ref&gt;
| doctoral_students = [[Wilhelm Ackermann]]&lt;br /&gt;[[Heinrich Behmann]]&lt;br /&gt;[[Otto Blumenthal]]&lt;br /&gt;[[Anne Bosworth]]&lt;br /&gt;[[Werner Boy]]&lt;br /&gt;[[Richard Courant]]&lt;br /&gt;[[Haskell Curry]]&lt;br /&gt;[[Max Dehn]]&lt;br /&gt;[[Rudolf Fueter]]&lt;br /&gt;[[Paul Funk]]&lt;br /&gt;[[Kurt Grelling]]&lt;br /&gt;[[Alfréd Haar]]&lt;br /&gt;[[Erich Hecke]]&lt;br /&gt;[[Earle Raymond Hedrick|Earle Hedrick]]&lt;br&gt;[[Ernst Hellinger]]&lt;br /&gt;[[Wallie Abraham Hurwitz|Wallie Hurwitz]]&lt;br /&gt;[[Margarete Kahn]]&lt;br /&gt;[[Oliver Dimon Kellogg|Oliver Kellogg]]&lt;br /&gt;[[Hellmuth Kneser]]&lt;br /&gt;[[Robert König]]&lt;br /&gt;[[Emanuel Lasker]]&lt;br /&gt;[[Klara Löbenstein]]&lt;br /&gt;[[Max Mason|Charles Max Mason]]&lt;br /&gt;[[Erhard Schmidt]]&lt;br /&gt;[[Kurt Schütte]]&lt;br /&gt;[[Andreas Speiser]]&lt;br /&gt;[[Hugo Steinhaus]]&lt;br /&gt;[[Gabriel Sudan]]&lt;br /&gt;[[Teiji Takagi]]&lt;br /&gt;[[Hermann Weyl]]&lt;br /&gt;[[Ernst Zermelo]]&lt;br /&gt;[[Edward Kasner]]
| notable_students = [[John von Neumann]]
| influences = [[Immanuel Kant]]&lt;ref&gt;Richard Zach, [http://plato.stanford.edu/entries/hilbert-program/ "Hilbert's Program"], The Stanford Encyclopedia of Philosophy.&lt;/ref&gt;
| known_for = [[Hilbert's basis theorem]]&lt;br /&gt;[[Hilbert's axioms]]&lt;br /&gt;[[Hilbert's problems]]&lt;br /&gt;[[Hilbert's program]]&lt;br /&gt;[[Einstein–Hilbert action]]&lt;br /&gt;[[Hilbert space]]&lt;br /&gt;[[Epsilon calculus]]
| prizes = [[Lobachevsky Prize]] &lt;small&gt;(1903)&lt;/small&gt;{{Citation needed lead|date=September 2016}}&lt;br&gt;[[Bolyai Prize]] &lt;small&gt;(1910)&lt;/small&gt;{{Citation needed lead|date=September 2016}}&lt;br&gt;[[Foreign Member of the Royal Society|ForMemRS]]&lt;ref name="frs"&gt;{{Cite journal | last1 = Weyl | first1 = H. | authorlink = Hermann Weyl| title = David Hilbert. 1862-1943 | doi = 10.1098/rsbm.1944.0006 | journal = [[Obituary Notices of Fellows of the Royal Society]] | volume = 4 | issue = 13 | pages = 547–553| year = 1944 | pmid =  | pmc = }}&lt;/ref&gt;
| spouse = Käthe Jerosch
| children = Franz (b. 1893)
}}

'''David Hilbert'''  ({{IPAc-en|ˈ|h|ɪ|l|b|ər|t}};&lt;ref&gt;[http://www.dictionary.com/browse/hilbert "Hilbert"]. ''[[Random House Webster's Unabridged Dictionary]]''.&lt;/ref&gt; {{IPA-de|ˈdaːvɪt ˈhɪlbɐt|lang}}; 23 January 1862 – 14 February 1943) was a German [[mathematician]]. He is recognized as one of the most influential and universal mathematicians of the 19th and early 20th centuries. Hilbert discovered and developed a broad range of fundamental ideas in many areas, including [[invariant theory]], calculus of variations, commutative algebra, algebraic number theory, the [[Hilbert's axioms|foundations of geometry]], spectral theory of operators and its application to integral equations, mathematical physics, and foundations of mathematics (particularly proof theory).

Hilbert adopted and warmly defended [[Georg Cantor]]'s set theory and [[transfinite number]]s. A famous example of his leadership in [[mathematics]] is his 1900 presentation of a [[Hilbert's problems|collection of problems]] that set the course for much of the mathematical research of the 20th century.

Hilbert and his students contributed significantly to establishing rigor and developed important tools used in modern mathematical physics. Hilbert is known as one of the founders of [[proof theory]] and [[mathematical logic]], as well as for being among the first to distinguish between mathematics and [[metamathematics]].&lt;ref&gt;{{cite web
|url=http://plato.stanford.edu/entries/hilbert-program/
|title=Hilbert's Program
|work=Stanford Encyclopedia of Philosophy
|author=Zach, Richard
|author-link=Richard Zach
|date=2003-07-31
|accessdate=2009-03-23
}}&lt;/ref&gt;

==Life==

===Early life and education===
Hilbert, the first of two children of Otto and Maria Therese (Erdtmann) Hilbert, was born in the [[Province of Prussia]], [[Kingdom of Prussia]], either in [[Königsberg]] (according to Hilbert's own statement) or in Wehlau (known since 1946 as [[Znamensk, Kaliningrad Oblast|Znamensk]]) near Königsberg where his father worked at the time of his birth.&lt;ref&gt;Reid 1996, pp. 1–2; also on p.&amp;nbsp;8, Reid notes that there is some ambiguity as to exactly where Hilbert was born. Hilbert himself stated that he was born in Königsberg.&lt;/ref&gt;

In late 1872, Hilbert entered the Friedrichskolleg [[Gymnasium (school)|Gymnasium]] (''Collegium fridericianum'', the same school that [[Immanuel Kant]] had attended 140 years before); but, after an unhappy period, he transferred to (late 1879) and graduated from (early 1880) the more science-oriented Wilhelm Gymnasium.&lt;ref&gt;Reid 1996, pp. 4–7.&lt;/ref&gt; Upon graduation, in autumn 1880, Hilbert enrolled at the [[University of Königsberg]], the "Albertina". In early 1882, [[Hermann Minkowski]] (two years younger than Hilbert and also a native of Königsberg but had gone to Berlin for three semesters),&lt;ref&gt;Reid 1996, p.&amp;nbsp;11.&lt;/ref&gt; returned to Königsberg and entered the university. Hilbert developed a lifelong friendship with the shy, gifted Minkowski.&lt;ref&gt;Reid 1996, p.&amp;nbsp;12.&lt;/ref&gt;&lt;ref&gt;{{citation|first=Hermann|last=Weyl|title=Levels of Infinity/Selected writings on Mathematics and Philosophy|chapter=David Hilbert and his Mathematical Work|page=94|year=2012|publisher=Dover|editor= Peter Pesic|isbn=978-0-486-48903-2}}&lt;/ref&gt;

===Career===
In 1884, [[Adolf Hurwitz]] arrived from Göttingen as an [[Professor|Extraordinarius]] (i.e., an associate professor)&lt;!--at the Albertina in 1884--&gt;. An intense and fruitful scientific exchange among the three began, and Minkowski and Hilbert especially would exercise a reciprocal influence over each other at various times in their scientific careers. Hilbert obtained his doctorate in 1885, with a dissertation, written under [[Ferdinand von Lindemann]],&lt;ref name="Lindemann"/&gt; titled ''Über invariante Eigenschaften spezieller binärer Formen, insbesondere der Kugelfunktionen'' ("On the invariant properties of special [[binary quantic|binary forms]], in particular the spherical harmonic functions").

Hilbert remained at the [[University of Königsberg]] as a ''Privatdozent'' (senior lecturer) from 1886 to 1895.  In 1895, as a result of intervention on his behalf by [[Felix Klein]], he obtained the position of Professor of Mathematics at the [[University of Göttingen]]. During the Klein and Hilbert years, Göttingen became the preeminent institution in the mathematical world.&lt;ref&gt;{{citation|first=Jeff|last=Suzuki|title=Mathematics in Historical Context|year=2009|publisher=Mathematical Association of America|isbn=978-0883855706|page=342|url=https://books.google.com/?id=lew5IC5piCwC&amp;pg=PA342&amp;dq=gottingen+mathematics#v=onepage&amp;q=gottingen%20mathematics&amp;f=false}}&lt;/ref&gt; He remained there for the rest of his life.

[[File:Mathematik Göttingen.jpg|thumb|right|The Mathematical Institute in Göttingen. Its new building, constructed with funds from the [[Rockefeller Foundation]], was opened by Hilbert and Courant in 1930.]]

===Göttingen school===
[[File:David Hilbert.tif|thumb|left|Portrait of David Hilbert in the 1900s, artist Anna Gorban, the cover image of the theme issue [http://rsta.royalsocietypublishing.org/content/376/2118 ‘Hilbert's sixth problem], Phil. Trans. R. Soc. A 2018, 376 (2118).]]
Among Hilbert's students were [[Hermann Weyl]], chess champion [[Emanuel Lasker]], [[Ernst Zermelo]], and [[Carl Gustav Hempel]]. [[John von Neumann]] was his assistant. At the University of Göttingen, Hilbert was surrounded by a social circle of some of the most important mathematicians of the 20th century, such as [[Emmy Noether]] and [[Alonzo Church]].

Among his 69 Ph.D. students in Göttingen were many who later became famous mathematicians, including (with date of thesis): [[Otto Blumenthal]] (1898), [[Felix Bernstein (mathematician)|Felix Bernstein]] (1901), [[Hermann Weyl]] (1908), [[Richard Courant]] (1910), [[Erich Hecke]] (1910), [[Hugo Steinhaus]] (1911), and [[Wilhelm Ackermann]] (1925).&lt;ref&gt;{{cite web|url=http://genealogy.math.ndsu.nodak.edu/html/id.phtml?id=7298| title = The Mathematics Genealogy Project - David Hilbert | accessdate=2007-07-07}}&lt;/ref&gt; Between 1902 and 1939 Hilbert was editor of the ''[[Mathematische Annalen]]'', the leading mathematical journal of the time.

{{quote|"Good, he did not have enough imagination to become a mathematician".|Hilbert's response upon hearing that one of his students had dropped out to study poetry.&lt;ref&gt;{{cite book|url=https://books.google.com/?id=nnpChqstvg0C&amp;pg=PA151&amp;dq=%22He+did+not+have+enough+imagination+to+become+a+mathematician%22|title=The Universal Book of Mathematics|author=David J. Darling|page=151|publisher=[[John Wiley and Sons]] | isbn=978-0-471-27047-8|year=2004}}&lt;/ref&gt;}}

===Later years===

Around 1925, Hilbert developed [[pernicious anemia]], a then-untreatable vitamin deficiency whose primary symptom is exhaustion; his assistant [[Eugene Wigner]] described him as subject to "enormous fatigue" and how he "seemed quite old", and that even after eventually being diagnosed and treated, he "was hardly a scientist after 1925, and certainly not a Hilbert."&lt;ref&gt;1992 (as told to Andrew Szanton). ''The Recollections of Eugene P. Wigner''. Plenum. {{isbn|0-306-44326-0}}&lt;/ref&gt;

Hilbert lived to see the [[Law for the Restoration of the Professional Civil Service|Nazis purge]] many of the prominent faculty members at [[Georg August University of Göttingen|University of Göttingen]] in 1933.&lt;ref&gt;{{cite web|url=http://www.atomicheritage.org/index.php/component/content/167.html?task=view|title="Shame" at Göttingen}} (Hilbert's colleagues exiled)
&lt;/ref&gt; Those forced out included [[Hermann Weyl]] (who had taken Hilbert's chair when he retired in 1930), [[Emmy Noether]] and [[Edmund Landau]]. One who had to leave Germany, [[Paul Bernays]], had collaborated with Hilbert in [[mathematical logic]], and co-authored with him the important book ''[[Grundlagen der Mathematik]]'' (which eventually appeared in two volumes, in 1934 and 1939). This was a sequel to the Hilbert-[[Wilhelm Ackermann|Ackermann]] book ''[[Principles of Mathematical Logic]]'' from 1928. Hermann Weyl's successor was [[Helmut Hasse]].

About a year later, Hilbert attended a banquet and was seated next to the new Minister of Education, [[Bernhard Rust]]. Rust asked whether "the ''Mathematical Institute'' really suffered so much because of the departure of the Jews". Hilbert replied,
"Suffered? It doesn't exist any longer, does it!"&lt;ref&gt;Eckart Menzler-Trott: ''Gentzens Problem. Mathematische Logik im nationalsozialistischen Deutschland.'', Birkhäuser, 2001, {{isbn|3-764-36574-9}}, Birkhäuser; Auflage: 2001 p.&amp;nbsp;142.&lt;/ref&gt;&lt;ref&gt;Hajo G. Meyer: ''Tragisches Schicksal. Das deutsche Judentum und die Wirkung historischer Kräfte: Eine Übung in angewandter Geschichtsphilosophie'', Frank &amp; Timme, 2008, {{isbn|3-865-96174-6}}, p.&amp;nbsp;202.&lt;/ref&gt;

[[File:Göttingen Stadtfriedhof Grab David Hilbert.jpg|thumb|Hilbert's tomb:&lt;br /&gt;''Wir müssen wissen&lt;br /&gt;Wir werden wissen'']]
By the time Hilbert died in 1943, the Nazis had nearly completely restaffed the university, as many of the former faculty had either been Jewish or married to Jews. Hilbert's funeral was attended by fewer than a dozen people, only two of whom were fellow academics, among them [[Arnold Sommerfeld]], a theoretical physicist and also a native of Königsberg.&lt;ref&gt;Reid 1996, p.&amp;nbsp;213.&lt;/ref&gt; News of his death only became known to the wider world six months after he had died.

The epitaph on his tombstone in Göttingen consists of the famous lines he spoke at the conclusion of his retirement address to the Society of German Scientists and Physicians on 8 September 1930. The words were given in response to the Latin maxim: "[[Ignoramus et ignorabimus]]" or "We do not know, we shall not know":&lt;ref&gt;Reid 1996, p.&amp;nbsp;192&lt;/ref&gt;

:''Wir müssen wissen.''
:''Wir werden wissen.''

In English:
: We must know.
: We will know.

The day before Hilbert pronounced these phrases at the 1930 annual meeting of the Society of German Scientists and Physicians, [[Kurt Gödel]]—in a round table discussion during the Conference on Epistemology held jointly with the Society meetings—tentatively announced the first expression of his incompleteness theorem.&lt;ref&gt;
"The Conference on Epistemology of the Exact Sciences ran for three days, from 5 to 7 September" (Dawson 1997:68). "It ... was held in conjunction with and just before the ninety-first annual meeting of the Society of German Scientists and Physicians ... and the sixth Assembly of German Physicists and Mathematicians.... Gödel's contributed talk took place on Saturday, 6 September [1930], from 3 until 3:20 in the afternoon, and on Sunday the meeting concluded with a round table discussion of the first day's addresses. During the latter event, without warning and almost offhandedly, Gödel quietly announced that "one can even give examples of propositions (and in fact of those of the type of [[Christian Goldbach|Goldbach]] or [[Pierre de Fermat|Fermat]]) that, while contentually true, are unprovable in the formal system of classical mathematics [153]" (Dawson:69) "... As it happened, Hilbert himself was present at Königsberg, though apparently not at the Conference on Epistemology. The day after the roundtable discussion he delivered the opening address before the Society of German Scientists and Physicians -- his famous lecture ''Naturerkennen und Logik'' (Logic and the knowledge of nature), at the end of which he declared: 'For the mathematician there is no Ignorabimus, and, in my opinion, not at all for natural science either. ... The true reason why [no one] has succeeded in finding an unsolvable problem is, in my opinion, that there is ''no'' unsolvable problem. In contrast to the foolish Ignorabimus, our credo avers: We must know, We shall know [159]'"(Dawson:71). Gödel's paper was received on November 17, 1930 (cf Reid p.&amp;nbsp;197, van Heijenoort 1976:592) and published on 25 March 1931 (Dawson 1997:74). But Gödel had given a talk about it beforehand... "An abstract had been presented on October 1930 to the Vienna Academy of Sciences by [[Hans Hahn (mathematician)|Hans Hahn]]" (van Heijenoort:592); this abstract and the full paper both appear in van Heijenoort:583ff.
&lt;/ref&gt; [[Gödel's incompleteness theorems]] show that even [[elementary proof|elementary]] axiomatic systems such as [[Peano arithmetic]] are either self-contradicting or contain logical propositions that are impossible to prove or disprove.

===Personal life===
In 1892, Hilbert married Käthe Jerosch (1864–1945), "the daughter of a Königsberg merchant, an outspoken young lady with an independence of mind that matched his own".&lt;ref&gt;Reid 1996, p.&amp;nbsp;36.&lt;/ref&gt; While at Königsberg they had their one child, Franz Hilbert (1893–1969).

Hilbert's son Franz suffered throughout his life from an undiagnosed mental illness. His inferior intellect was a terrible disappointment to his father and this misfortune was a matter of distress to the mathematicians and students at Göttingen.&lt;ref&gt;Reid 1996, p.&amp;nbsp;139.&lt;/ref&gt;

Hilbert considered the mathematician [[Hermann Minkowski]] to be his "best and truest friend".&lt;ref&gt;Reid 1996, p.&amp;nbsp;121.&lt;/ref&gt;

Hilbert was baptized and raised a [[Calvinist]] in the [[Prussian Union of churches|Prussian Evangelical Church]].&lt;ref&gt;The Hilberts had by this time left the Reformed Protestant Church in which they had been baptized and married. - Reid 1996, p.91&lt;/ref&gt; He later on left the Church and became an [[agnostic]].&lt;ref name=hilbertagnostic&gt;{{Cite journal|
last1 = Shaposhnikov|
first1 = Vladislav|
doi = 10.1515/slgr-2016-0009|
title = Theological Underpinnings of the Modern Philosophy of Mathematics. Part II: The Quest for Autonomous Foundations |
journal = Studies in Logic, Grammar and Rhetoric|
volume = 44|
issue = 1|
pages = 147–168|
year = 2016|
url =https://www.degruyter.com/view/j/slgr.2016.44.issue-1/slgr-2016-0009/slgr-2016-0009.xml|
quote=David Hilbert seemed to be agnostic and had nothing to do with theology proper or even religion. Constance Reid tells a story on the subject:&lt;blockquote&gt;The Hilberts had by this time [around 1902] left the Reformed Protestant Church in which they had been baptized and married. It was told in Göttingen that when [David Hilbert's son] Franz had started to school he could not answer the question, ‘What religion are you?’ (1970, p.&amp;nbsp;91)&lt;/blockquote&gt; In the 1927 Hamburg address, Hilbert asserted: "mathematics is pre-suppositionless science (die Mathematik ist eine voraussetzungslose Wissenschaft)" and "to found it I do not need a good God ([z]u ihrer Begründung brauche ich weder den lieben Gott)" (1928, S. 85; van Heijenoort, 1967, p.&amp;nbsp;479). However, from Mathematische Probleme (1900) to Naturerkennen und Logik (1930) he placed his quasi-religious faith in the human spirit and in the power of pure thought with its beloved child– mathematics. He was deeply convinced that every mathematical problem could be solved by pure reason: in both mathematics and any part of natural science (through mathematics) there was "no ignorabimus" (Hilbert, 1900, S. 262; 1930, S. 963; Ewald, 1996, pp. 1102, 1165). That is why finding an inner absolute grounding for mathematics turned into Hilbert’s life-work. He never gave up this position, and it is symbolic that his words "wir müssen wissen, wir werden wissen" ("we must know, we shall know") from his 1930 Königsberg address were engraved on his tombstone. Here, we meet a ghost of departed theology (to modify George Berkeley’s words), for to absolutize human cognition means to identify it tacitly with a divine one.}}&lt;/ref&gt; He also argued that mathematical truth was independent of the existence of God or other ''[[A priori and a posteriori|a priori]]'' assumptions.&lt;ref&gt;"Mathematics is a presuppositionless science. To found it I do not need God, as does Kronecker, or the assumption of a special faculty of our understanding attuned to the principle of mathematical induction, as does Poincaré, or the primal intuition of Brouwer, or, finally, as do Russell and Whitehead, axioms of infinity, reducibility, or completeness, which in fact are actual, contentual assumptions that cannot be compensated for by consistency proofs." David Hilbert, ''Die Grundlagen der Mathematik'', [http://people.cs.uchicago.edu/~odonnell/OData/Courses/22C:096/Lecture_notes/Hilbert_program.html Hilbert's program, 22C:096, University of Iowa].&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Science, Worldviews and Education|year=2009|publisher=Springer|isbn=9789048127795|page=129|author=Michael R. Matthews|quote=As is well known, Hilbert rejected Leopold Kronecker's God for the solution of the problem of the foundations of mathematics.}}&lt;/ref&gt;

==Hilbert solves Gordan's Problem&lt;!-- predominantly capitalized in the literature; 'Gordan's problem' and 'Gordan's Problem' redirect here--&gt;==
Hilbert's first work on invariant functions led him to the demonstration in 1888 of his famous ''finiteness theorem''. Twenty years earlier, [[Paul Gordan]] had demonstrated the [[theorem]] of the finiteness of generators for binary forms using a complex computational approach. Attempts to generalize his method to functions with more than two variables failed because of the enormous difficulty of the calculations involved. In order to solve what had become known in some circles as ''Gordan's Problem'', Hilbert realized that it was necessary to take a completely different path. As a result, he demonstrated ''[[Hilbert's basis theorem]]'', showing the existence of a finite set of generators, for the invariants of [[algebraic form|quantics]] in any number of variables, but in an abstract form. That is, while demonstrating the existence of such a set, it was not a [[constructive proof]] — it did not display "an object" — but rather, it was an [[existence proof]]&lt;ref&gt;Constance Reid 1996, pp. 36–37.&lt;/ref&gt; and relied on use of the [[law of excluded middle]] in an infinite extension.

Hilbert sent his results to the ''[[Mathematische Annalen]]''. Gordan, the house expert on the theory of invariants for the ''Mathematische Annalen'', could not appreciate the revolutionary nature of Hilbert's theorem and rejected the article, criticizing the exposition because it was insufficiently comprehensive. His comment was:

:''Das ist nicht Mathematik. Das ist Theologie.''
::(''This is not Mathematics. This is Theology.'')&lt;ref&gt;Reid 1996, p.&amp;nbsp;34.&lt;/ref&gt;

[[Felix Klein|Klein]], on the other hand, recognized the importance of the work, and guaranteed that it would be published without any alterations. Encouraged by Klein, Hilbert extended his method in a second article, providing estimations on the maximum degree of the minimum set of generators, and he sent it once more to the ''Annalen''. After having read the manuscript, Klein wrote to him, saying:

:''Without doubt this is the most important work on general algebra that the ''Annalen'' has ever published.''&lt;ref&gt;Rowe, p.&amp;nbsp;195&lt;/ref&gt;

Later, after the usefulness of Hilbert's method was universally recognized, Gordan himself would say:

:''I have convinced myself that even theology has its merits.''&lt;ref name="Reid 1996, p.&amp;nbsp;37"&gt;Reid 1996, p.&amp;nbsp;37.&lt;/ref&gt;

For all his successes, the nature of his proof stirred up more trouble than Hilbert could have imagined at the time. Although [[Leopold Kronecker|Kronecker]] had conceded, Hilbert would later respond to others' similar criticisms that "many different constructions are subsumed under one fundamental idea" — in other words (to quote Reid): "Through a proof of existence, Hilbert had been able to obtain a construction"; "the proof" (i.e. the symbols on the page) ''was'' "the object".&lt;ref name="Reid 1996, p.&amp;nbsp;37"/&gt; Not all were convinced. While [[Leopold Kronecker|Kronecker]] would die soon afterwards, his [[Constructivism (mathematics)|constructivist]] philosophy would continue with the young [[Luitzen Egbertus Jan Brouwer|Brouwer]] and his developing [[intuitionist]] "school", much to Hilbert's torment in his later years.&lt;ref&gt;cf. Reid 1996, pp. 148–149.&lt;/ref&gt; Indeed, Hilbert would lose his "gifted pupil" [[Hermann Weyl|Weyl]] to intuitionism — "Hilbert was disturbed by his former student's fascination with the ideas of Brouwer, which aroused in Hilbert the memory of Kronecker".&lt;ref&gt;Reid 1996, p.&amp;nbsp;148.&lt;/ref&gt; Brouwer the intuitionist in particular opposed the use of the Law of Excluded Middle over infinite sets (as Hilbert had used it). Hilbert would respond:

:''Taking the Principle of the Excluded Middle from the mathematician ... is the same as ... prohibiting the boxer the use of his fists.''&lt;ref&gt;Reid 1996, p.&amp;nbsp;150.&lt;/ref&gt;

==Axiomatization of geometry==
{{Main|Hilbert's axioms}}

The text ''[[Grundlagen der Geometrie]]'' (tr.: ''Foundations of Geometry'') published by Hilbert in 1899 proposes a formal set, called Hilbert's axioms, substituting for the traditional [[Euclid's elements|axioms of Euclid]]. They avoid weaknesses identified in those of [[Euclid]], whose works at the time were still used textbook-fashion. It is difficult to specify the axioms used by Hilbert without referring to the publication history of the ''Grundlagen'' since Hilbert changed and modified them several times. The original monograph was quickly followed by a French translation, in which Hilbert added V.2, the Completeness Axiom. An English translation, authorized by Hilbert, was made by E.J. Townsend and copyrighted in 1902.&lt;ref&gt;{{harvnb|Hilbert|1950}}&lt;/ref&gt;&lt;ref&gt;[[G. B. Mathews]](1909) [http://www.nature.com/nature/journal/v80/n2066/pdf/080394a0.pdf The Foundations of Geometry] from [[Nature (journal)|Nature]] 80:394,5 (#2066)&lt;/ref&gt; This translation incorporated the changes made in the French translation and so is considered to be a translation of the 2nd edition. Hilbert continued to make changes in the text and several editions appeared in German. The 7th edition was the last to appear in Hilbert's lifetime. New editions followed the 7th, but the main text was essentially not revised.
&lt;!-- Independently and contemporaneously, a 19-year-old American student named [[Robert Lee Moore]] published an equivalent set of axioms. Some of the axioms coincide, while some of the axioms in Moore's system are theorems in Hilbert's and vice-versa. --&gt;

Hilbert's approach signaled the shift to the modern [[axiomatic method]].  In this, Hilbert was anticipated by [[Moritz Pasch]]'s work from 1882.  Axioms are not taken as self-evident truths. Geometry may treat ''things'', about which we have powerful intuitions, but it is not necessary to assign any explicit meaning to the undefined concepts. The elements, such as [[point (geometry)|point]], [[Line (geometry)|line]], [[plane (geometry)|plane]], and others, could be substituted, as Hilbert is reported to have said to [[Schoenflies]] and [[Ernst Kötter|Kötter]], by tables, chairs, glasses of beer and other such objects.&lt;ref&gt;{{cite book| author=[[Otto Blumenthal]]| title=Lebensgeschichte| year=1935| volume=3| pages=388–429| publisher=Julius Springer| editor=David Hilbert| series=Gesammelte Abhandlungen| url=http://gdz-lucene.tc.sub.uni-goettingen.de/gcs/gcs?action=pdf&amp;metsFile=PPN237834022&amp;divID=LOG_0001&amp;pagesize=original&amp;pdfTitlePage=http://gdz.sub.uni-goettingen.de/dms/load/pdftitle/?metsFile=PPN237834022%7C&amp;targetFileName=PPN237834022_LOG_0001.pdf&amp;| access-date=2018-09-06| archive-url=https://web.archive.org/web/20160304122623/http://gdz-lucene.tc.sub.uni-goettingen.de/gcs/gcs?action=pdf&amp;metsFile=PPN237834022&amp;divID=LOG_0001&amp;pagesize=original&amp;pdfTitlePage=http%3A%2F%2Fgdz.sub.uni-goettingen.de%2Fdms%2Fload%2Fpdftitle%2F%3FmetsFile%3DPPN237834022%7C&amp;targetFileName=PPN237834022_LOG_0001.pdf&amp;| archive-date=2016-03-04| dead-url=yes| df=}} Here: p.402-403&lt;/ref&gt; It is their defined relationships that are discussed.

Hilbert first enumerates the undefined concepts: point, line, plane, lying on (a relation between points and lines, points and planes, and lines and planes), betweenness, congruence of pairs of points ([[line segment]]s), and [[criteria of congruence of angles|congruence]] of [[angle]]s. The axioms unify both the [[Euclidean geometry|plane geometry]] and [[solid geometry]] of Euclid in a single system.

==The 23 problems==
{{Main|Hilbert's problems}}

Hilbert put forth a most influential list of 23 unsolved problems at the [[International Congress of Mathematicians]] in [[Paris]] in 1900. This is generally reckoned as the most successful and deeply considered compilation of open problems ever to be produced by an individual mathematician.

After re-working the foundations of classical geometry, Hilbert could have extrapolated to the rest of mathematics. His approach differed, however, from the later 'foundationalist' Russell-Whitehead or 'encyclopedist' [[Nicolas Bourbaki]], and from his contemporary [[Giuseppe Peano]]. The mathematical community as a whole could enlist in problems, which he had identified as crucial aspects of the areas of mathematics he took to be key.

The problem set was launched as a talk "The Problems of Mathematics" presented during the course of the Second International Congress of Mathematicians held in Paris. The introduction of the speech that Hilbert gave said:

:''Who among us would not be happy to lift the veil behind which is hidden the future; to gaze at the coming developments of our science and at the secrets of its development in the centuries to come? What will be the ends toward which the spirit of future generations of mathematicians will tend? What methods, what new facts will the new century reveal in the vast and rich field of mathematical thought?''&lt;ref&gt;{{cite web|url=http://www.seas.harvard.edu/courses/cs121/handouts/Hilbert.pdf |title=Archived copy |accessdate=2012-09-11 |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20090530182730/http://www.seas.harvard.edu/courses/cs121/handouts/Hilbert.pdf |archivedate=2009-05-30 |df= }}, archived from [www.seas.harvard.edu/courses/cs121/handouts/Hilbert.pdf]&lt;/ref&gt;

He presented fewer than half the problems at the Congress, which were published in the acts of the Congress. In a subsequent publication, he extended the panorama, and arrived at the formulation of the now-canonical 23 Problems of Hilbert. See also [[Hilbert's twenty-fourth problem]]. The full text is important, since the exegesis of the questions still can be a matter of inevitable debate, whenever it is asked how many have been solved.

Some of these were solved within a short time. Others have been discussed throughout the 20th century, with a few now taken to be unsuitably open-ended to come to closure. Some even continue to this day to remain a challenge for mathematicians.

==Formalism==
In an account that had become standard by the mid-century, Hilbert's problem set was also a kind of manifesto, that opened the way for the development of the [[formalism (mathematics)|formalist]] school, one of three major schools of mathematics of the 20th century. According to the formalist, mathematics is manipulation of symbols according to agreed upon formal rules. It is therefore an autonomous activity of thought.  There is, however, room to doubt whether Hilbert's own views were simplistically formalist in this sense.

===Hilbert's program===
{{Main|Hilbert's program}}
In 1920 he proposed explicitly a research project (in ''[[metamathematics]]'', as it was then termed) that became known as Hilbert's program. He wanted [[mathematics]] to be formulated on a solid and complete logical foundation. He believed that in principle this could be done, by showing that:

# all of mathematics follows from a correctly chosen finite system of [[axiom]]s; and
# that some such axiom system is provably consistent through some means such as the [[epsilon calculus]].

He seems to have had both technical and philosophical reasons for formulating this proposal. It affirmed his dislike of what had become known as the ''[[ignorabimus]]'', still an active issue in his time in German thought, and traced back in that formulation to [[Emil du Bois-Reymond]].

This program is still recognizable in the most popular [[philosophy of mathematics]], where it is usually called ''formalism''. For example, the [[Bourbaki group]] adopted a watered-down and selective version of it as adequate to the requirements of their twin projects of (a) writing encyclopedic foundational works, and (b) supporting the [[axiomatic method]] as a research tool. This approach has been successful and influential in relation with Hilbert's work in algebra and functional analysis, but has failed to engage in the same way with his interests in physics and logic.

Hilbert wrote in 1919:

:We are not speaking here of arbitrariness in any sense. Mathematics is not like a game whose tasks are determined by arbitrarily stipulated rules.  Rather, it is a conceptual system possessing internal necessity that can only be so and by no means otherwise.&lt;ref&gt;Hilbert, D. (1919-20), Natur und Mathematisches Erkennen: Vorlesungen, gehalten 1919-1920 in G\"ottingen. Nach der Ausarbeitung von Paul Bernays (Edited and with an English introduction by David E. Rowe), Basel, Birkh\"auser (1992).&lt;/ref&gt;

Hilbert published his views on the foundations of mathematics in the 2-volume work [[Grundlagen der Mathematik]].

===Gödel's work===
Hilbert and the mathematicians who worked with him in his enterprise were committed to the project. His attempt to support axiomatized mathematics with definitive principles, which could banish theoretical uncertainties, ended in failure.

[[Kurt Gödel|Gödel]] demonstrated that any non-contradictory formal system, which was comprehensive enough to include at least arithmetic, cannot demonstrate its completeness by way of its own axioms. In 1931 his [[Gödel's incompleteness theorem|incompleteness theorem]] showed that Hilbert's grand plan was impossible as stated. The second point cannot in any reasonable way be combined with the first point, as long as the axiom system is genuinely [[finitary]].

Nevertheless, the subsequent achievements of [[proof theory]] at the very least ''clarified'' consistency as it relates to theories of central concern to mathematicians. Hilbert's work had started logic on this course of clarification; the need to understand Gödel's work then led to the development of [[recursion theory]] and then [[mathematical logic]] as an autonomous discipline in the 1930s. The basis for later [[theoretical computer science]], in the work of [[Alonzo Church]] and [[Alan Turing]], also grew directly out of this 'debate'.

==Functional analysis==
Around 1909, Hilbert dedicated himself to the study of differential and [[integral equation]]s; his work had direct consequences for important parts of modern functional analysis. In order to carry out these studies, Hilbert introduced the concept of an infinite dimensional [[Euclidean space]], later called [[Hilbert space]]. His work in this part of analysis provided the basis for important contributions to the mathematics of physics in the next two decades, though from an unanticipated direction.
Later on, [[Stefan Banach]] amplified the concept, defining [[Banach spaces]]. Hilbert spaces are an important class of objects in the area of [[functional analysis]], particularly of the [[spectral theory]] of self-adjoint linear operators, that grew up around it during the 20th century.

==Physics==
Until 1912, Hilbert was almost exclusively a "pure" mathematician.  When planning a visit from Bonn, where he was immersed in studying physics, his fellow mathematician and friend [[Hermann Minkowski]] joked he had to spend 10 days in quarantine before being able to visit Hilbert.  In fact, Minkowski seems responsible for most of Hilbert's physics investigations prior to 1912, including their joint seminar in the subject in 1905.

In 1912, three years after his friend's death, Hilbert turned his focus to the subject almost exclusively.  He arranged to have a "physics tutor" for himself.&lt;ref&gt;Reid 1996, p.&amp;nbsp;129.&lt;/ref&gt;  He started studying [[Kinetic theory of gases|kinetic gas theory]] and moved on to elementary [[radiation]] theory and the molecular theory of matter.  Even after the war started in 1914, he continued seminars and classes where the works of [[Albert Einstein]] and others were followed closely.

By 1907 Einstein had framed the fundamentals of the theory of gravity, but then struggled for nearly 8 years with a confounding problem of putting the theory into final form.&lt;ref&gt;Isaacson 2007:218&lt;/ref&gt; By early summer 1915, Hilbert's interest in physics had focused on [[general relativity]], and he invited Einstein to Göttingen to deliver a week of lectures on the subject.&lt;ref&gt;Sauer 1999, Folsing 1998, Isaacson 2007:212&lt;/ref&gt; Einstein received an enthusiastic reception at Göttingen.&lt;ref&gt;Isaacson 2007:213&lt;/ref&gt; Over the summer Einstein learned that Hilbert was also working on the field equations and redoubled his own efforts. During November 1915 Einstein published several papers culminating in "The Field Equations of Gravitation" (see [[Einstein field equations]]).&lt;ref&gt;In time, associating the gravitational field equations with Hilbert's name became less and less common. A noticeable exception is P. Jordan (Schwerkraft und Weltall, Braunschweig, Vieweg, 1952), who called the equations of gravitation in the vacuum the Einstein–Hilbert equations. (Leo Corry, David Hilbert and the Axiomatization of Physics, p.&amp;nbsp;437)&lt;/ref&gt; Nearly simultaneously David Hilbert published "The Foundations of Physics", an axiomatic derivation of the field equations (see [[Einstein–Hilbert action]]). Hilbert fully credited Einstein as the originator of the theory, and no public priority dispute concerning the field equations ever arose between the two men during their lives.&lt;ref&gt;Since 1971 there have been some spirited and scholarly discussions about which of the two men first presented the now accepted form of the field equations. "Hilbert freely admitted, and frequently stated in lectures, that the great idea was Einstein's."Every boy in the streets of Gottingen understands more about four dimensional geometry than Einstein," he once remarked. "Yet, in spite of that, Einstein did the work and not the mathematicians" (Reid 1996, pp.&amp;nbsp;141–142, also Isaacson 2007:222 quoting Thorne p.&amp;nbsp;119).&lt;/ref&gt; See more at [[relativity priority dispute#General Relativity 3|priority]].

Additionally, Hilbert's work anticipated and assisted several advances in the [[mathematical formulation of quantum mechanics]]. His work was a key aspect of [[Hermann Weyl]] and [[John von Neumann]]'s work on the mathematical equivalence of [[Werner Heisenberg]]'s [[matrix mechanics]] and [[Erwin Schrödinger]]'s [[Schrödinger equation|wave equation]] and his namesake [[Hilbert space]] plays an important part in quantum theory.  In 1926 von Neumann showed that if atomic states were understood as vectors in Hilbert space, then they would correspond with both Schrödinger's wave function theory and Heisenberg's matrices.&lt;ref&gt;In 1926, the year after the matrix mechanics formulation of quantum theory by [[Max Born]] and [[Werner Heisenberg]], the mathematician [[John von Neumann]] became an assistant to David Hilbert at Göttingen.  When von Neumann left in 1932, von Neumann's book on the mathematical foundations of quantum mechanics, based on Hilbert's mathematics, was published under the title  ''Mathematische Grundlagen der Quantenmechanik''.  See: Norman Macrae, ''John von Neumann:  The Scientific Genius Who Pioneered the Modern Computer, Game Theory, Nuclear Deterrence, and Much More'' (Reprinted by the American Mathematical Society, 1999) and Reid 1996.&lt;/ref&gt;

Throughout this immersion in physics, Hilbert worked on putting rigor into the mathematics of physics.  While highly dependent on higher mathematics, physicists tended to be "sloppy" with it.  To a "pure" mathematician like Hilbert, this was both "ugly" and difficult to understand.  As he began to understand physics and how physicists were using mathematics, he developed a coherent mathematical theory for what he found, most importantly in the area of [[integral equations]].  When his colleague [[Richard Courant]] wrote the now classic ''[[Methoden der mathematischen Physik]]'' (Methods of Mathematical Physics) including some of Hilbert's ideas, he added Hilbert's name as author even though Hilbert had not directly contributed to the writing.  Hilbert said "Physics is too hard for physicists", implying that the necessary mathematics was generally beyond them; the Courant-Hilbert book made it easier for them.

==Number theory==
Hilbert unified the field of [[algebraic number theory]] with his 1897 treatise ''[[Zahlbericht]]'' (literally "report on numbers"). He also resolved a significant number-theory [[Waring's problem|problem formulated by Waring]] in 1770.  As with [[#The finiteness theorem|the finiteness theorem]], he used an existence proof that shows there must be solutions for the problem rather than providing a mechanism to produce the answers.&lt;ref&gt;Reid 1996, p.&amp;nbsp;114&lt;/ref&gt;  He then had little more to publish on the subject; but the emergence of [[Hilbert modular form]]s in the dissertation of a student means his name is further attached to a major area.

He made a series of conjectures on [[class field theory]]. The concepts were highly influential, and his own contribution lives on in the names of the [[Hilbert class field]] and of the [[Hilbert symbol]] of [[local class field theory]]. Results were mostly proved by 1930, after work by [[Teiji Takagi]].&lt;ref&gt;This work established Takagi as Japan's first mathematician of international stature.&lt;/ref&gt;

Hilbert did not work in the central areas of [[analytic number theory]], but his name has become known for the [[Hilbert–Pólya conjecture]], for reasons that are anecdotal.

==Works==
His collected works (''Gesammelte Abhandlungen'') have been published several times. The original versions of his papers contained "many technical errors of varying degree";&lt;ref&gt;Reid, chap.13&lt;/ref&gt; when the collection was first published, the errors were corrected and it was found that this could be done without major changes in the statements of the theorems, with one exception—a claimed proof of the [[continuum hypothesis]].&lt;ref name="Sieg13"&gt;Page 284f in: {{Cite book|title=Hilbert's Programs and Beyond|author=Wilfried Sieg|publisher=Oxford University Press| isbn=9780195372229|year=2013}}&lt;/ref&gt;&lt;ref name="Rota97"&gt;[[Gian-Carlo Rota|Rota G.-C.]] (1997), "[http://www.ams.org/notices/199701/comm-rota.pdf Ten lessons I wish I had been taught]", ''[[Notices of the AMS]], 44: 22-25.&lt;/ref&gt; The errors were nonetheless so numerous and significant that it took [[Olga Taussky-Todd]] three years to make the corrections.&lt;ref name="Rota97"/&gt;

==See also==
{{Portal|Biography|Logic}}
{{Div col|colwidth=15em}}
* [[List of things named after David Hilbert]]
* [[Brouwer–Hilbert controversy]]
* [[Foundations of geometry]]
* [[Geometry and the Imagination]]
* [[Hilbert–Burch theorem]]
* [[Hilbert C*-module]]
* [[Hilbert cube]]
* [[Hilbert curve]]
* [[Hilbert matrix]]
* [[Hilbert metric]]
* [[Hilbert–Mumford criterion]]
* [[Hilbert number]]
* [[Hilbert ring]]
* [[Hilbert–Poincaré series]]
* [[Hilbert series and Hilbert polynomial]]
* [[Hilbert spectrum]]
* [[Hilbert system]]
* [[Hilbert transform]]
* [[Hilbert's arithmetic of ends]]
* [[Hilbert's irreducibility theorem]]
* [[Hilbert's Nullstellensatz]]
* [[Hilbert's paradox of the Grand Hotel]]
* [[Hilbert's theorem (differential geometry)]]
* [[Hilbert's Theorem 90]]
* [[Hilbert's syzygy theorem]]
* [[Hilbert–Schmidt operator]]
* [[Hilbert–Smith conjecture]]
* [[Hilbert–Speiser theorem]]
* [[Relativity priority dispute]]
{{Div col end}}

==Notes==
{{Reflist|40em}}

==References==

===Primary literature in English translation===
* Ewald, William B., ed., 1996. ''From Kant to Hilbert: A Source Book in the Foundations of Mathematics'', 2 vols. Oxford Uni. Press.
** 1918. "Axiomatic thought," 1115–14.
** 1922. "The new grounding of mathematics: First report," 1115–33.
** 1923. "The logical foundations of mathematics," 1134–47.
** 1930. "Logic and the knowledge of nature," 1157–65.
** 1931. "The grounding of elementary number theory," 1148–56.
** 1904. "On the foundations of logic and arithmetic," 129–38.
** 1925. "On the infinite," 367–92.
** 1927. "The foundations of mathematics," with comment by [[Weyl]] and Appendix by [[Bernays]], 464–89.
* [[Jean van Heijenoort]], 1967. ''From Frege to Gödel: A Source Book in Mathematical Logic, 1879–1931''. Harvard Univ. Press.
* {{citation|last=Hilbert|first=David|authorlink=David Hilbert|title=The Foundations of Geometry [Grundlagen der Geometrie]|edition=2nd|publisher=Open Court Publishing|place=La Salle, IL|year=1950|origyear=first published 1902|others=English translation by E.J. Townsend|url=http://www.gutenberg.org/files/17384/17384-pdf.pdf}}
* {{citation|last=Hilbert|first=David|authorlink=David Hilbert|title=Foundations of Geometry [Grundlagen der Geometrie]|edition=2nd English|publisher=Open Court Publishing|place=La Salle, IL|year=1990|origyear=1971|others=translated by Leo Unger from the 10th German edition|isbn=978-0-87548-164-7}}
* {{citation| title = Geometry and Imagination | author = David Hilbert |author2=Stephan Cohn-Vossen|authorlink2=Stephan Cohn-Vossen| year = 1999 | publisher = American Mathematical Society | isbn = 978-0-8218-1998-2}} - an accessible set of lectures originally for the citizens of Göttingen.
* {{citation| title = David Hilbert's Lectures on the foundations of Mathematics and Physics, 1891–1933 | author = David Hilbert |editor= Michael Hallett and Ulrich Majer| year = 2004 | publisher = Springer-Verlag Berlin Heidelberg| isbn = 978-3-540-64373-9}}

===Secondary literature===
*{{Citation
| last = Bertrand
| first = Gabriel
| author-link = Gabriel Bertrand
| title = Allocution
| journal = [[Comptes rendus de l'Académie des sciences|Comptes rendus hebdomadaires des séances de l'Académie des sciences]]
| place = Paris
| volume = 217
| pages =625–640
| date = 20 December 1943b
| language = French
| url =http://gallica.bnf.fr/ark:/12148/bpt6k31698/f629.image
}}, available at [[Gallica]]. The "Address" of Gabriel Bertrand of December 20, 1943 at the French Academy: he gives biographical sketches of the lives of recently deceased members, including [[Pieter Zeeman]], David Hilbert and [[Georges Giraud]].
* Bottazzini Umberto, 2003. ''Il flauto di Hilbert. Storia della matematica''. [[UTET]], {{isbn|88-7750-852-3}}
* Corry, L., Renn, J., and Stachel, J., 1997, "Belated Decision in the Hilbert-Einstein Priority Dispute," ''Science 278'': nn-nn.
* Dawson, John W. Jr 1997. ''Logical Dilemmas: The Life and Work of Kurt Gödel''. Wellesley MA: A. K. Peters. {{isbn|1-56881-256-6}}.
* Folsing, Albrecht, 1998. ''Albert Einstein''. Penguin.
* [[Ivor Grattan-Guinness|Grattan-Guinness, Ivor]], 2000. ''The Search for Mathematical Roots 1870-1940''. Princeton Univ. Press.
* [[Jeremy Gray|Gray, Jeremy]], 2000. ''The Hilbert Challenge''. {{isbn|0-19-850651-1}}
* {{cite book | title = From Brouwer to Hilbert, The Debate on the Foundations of Mathematics in 1920s| first = Paolo |last= Mancosu| year = 1998 | publisher = Oxford Univ. Press| isbn = 978-0-19-509631-6}}
* [[Jagdish Mehra|Mehra, Jagdish]], 1974. ''Einstein, Hilbert, and the Theory of Gravitation''. Reidel.
* [[Piergiorgio Odifreddi]], 2003. ''Divertimento Geometrico - Da Euclide ad Hilbert''. Bollati Boringhieri, {{isbn|88-339-5714-4}}. A clear exposition of the "errors" of Euclid and of the solutions presented in the ''Grundlagen der Geometrie'', with reference to [[non-Euclidean geometry]].
* Reid, Constance, 1996. ''Hilbert'', [[Springer Science and Business Media|Springer]], {{isbn|0-387-94674-8}}. The definitive English-language biography of Hilbert.
* {{Cite journal | last1 = Rowe | first1 = D. E. | doi = 10.1086/368687 | title = Klein, Hilbert, and the Gottingen Mathematical Tradition | journal = Osiris | volume = 5 | pages = 186–213 | year = 1989 | pmid =  | pmc = }}
* {{cite journal | last1 = Sauer | first1 = Tilman | year = 1999 | title = The relativity of discovery: Hilbert's first note on the foundations of physics | journal = Arch. Hist. Exact Sci. | volume = 53 | issue = | pages = 529–75 | arxiv = physics/9811050 | bibcode = 1998physics..11050S }}
* Sieg, Wilfried, and Ravaglia, Mark, 2005, "Grundlagen der Mathematik" in [[Ivor Grattan-Guinness|Grattan-Guinness, I.]], ed., ''Landmark Writings in Western Mathematics''. [[Elsevier]]: 981-99. (in English)
* [[Kip Thorne|Thorne, Kip]], 1995. ''[[Black Holes and Time Warps|Black Holes and Time Warps: Einstein's Outrageous Legacy]]'',  W. W. Norton &amp; Company; Reprint edition. {{isbn|0-393-31276-3}}.

==External links==
{{wikisource author}}
{{commons}}
{{Wikiquote}}
* {{MathGenealogy|id=7298}}
* [https://web.archive.org/web/20110517092213/http://www.ags.uni-sb.de/~cp/p/hilbertbernays/goal.htm Hilbert Bernays Project]
* [http://aleph0.clarku.edu/~djoyce/hilbert/problems.html Hilbert's 23 Problems Address]
* [http://mathematics.conference-site.com// ICMM 2014 dedicated to the memory of D.Hilbert]
* {{Gutenberg author |id=Hilbert,+David | name=David Hilbert}}
* {{Internet Archive author |sname=David Hilbert}}
* {{Librivox author |id=3033}}
* [http://math.sfsu.edu/smith/Documents/HilbertRadio/HilbertRadio.mp3 Hilbert's radio speech recorded in Königsberg 1930 (in German)], with English [http://math.sfsu.edu/smith/Documents/HilbertRadio/HilbertRadio.pdf translation]
* [http://mathworld.wolfram.com/HilbertsConstants.html Wolfram MathWorld – Hilbert'Constant]
* {{MacTutor Biography|id=Hilbert}}
* [https://web.archive.org/web/20080514013255/http://www.gresham.ac.uk/event.asp?PageId=45&amp;EventId=628 'From Hilbert's Problems to the Future'], lecture by Professor Robin Wilson, [[Gresham College]], 27 February 2008 (available in text, audio and video formats).

{{Authority control}}

{{DEFAULTSORT:Hilbert, David}}
[[Category:1862 births]]
[[Category:1943 deaths]]
[[Category:19th-century mathematicians]]
[[Category:20th-century mathematicians]]
[[Category:Foreign Members of the Royal Society]]
[[Category:Members of the Bavarian Maximilian Order for Science and Art]]
[[Category:Recipients of the Pour le Mérite (civil class)]]
[[Category:Formalism (deductive)]]
[[Category:German agnostics]]
[[Category:Former Protestants]]
[[Category:German mathematicians]]
[[Category:Geometers]]
[[Category:Mathematical analysts]]
[[Category:Number theorists]]
[[Category:Operator theorists]]
[[Category:People from Königsberg]]
[[Category:People from the Province of Prussia]]
[[Category:Relativity theorists]]
[[Category:University of Göttingen faculty]]
[[Category:University of Königsberg alumni]]
[[Category:University of Königsberg faculty]]
[[Category:David Hilbert| ]]
[[Category:Mathematicians involved with Mathematische Annalen]]</text>
      <sha1>8wiq19r5q3vhpa4ocn7n6xp9jheo9kl</sha1>
    </revision>
  </page>
  <page>
    <title>Delone set</title>
    <ns>0</ns>
    <id>38607512</id>
    <revision>
      <id>867139084</id>
      <parentid>862708727</parentid>
      <timestamp>2018-11-03T22:56:30Z</timestamp>
      <contributor>
        <username>Zetifree</username>
        <id>9716452</id>
      </contributor>
      <comment>fix broken link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10080">[[File:Metric epsilon-net.svg|thumb|300px|The red points form part of an ε-net for the Euclidean plane, where ε is the radius of the large yellow disks. The blue disks of half the radius are disjoint, and the yellow disks together cover the whole plane, satisfying the two definitional requirements on an ε-net.]]
In the mathematical theory of [[metric space]]s, '''ε-nets''', '''ε-packings''', '''ε-coverings''', '''uniformly discrete sets''', '''relatively dense sets''', and '''Delone sets''' (named after [[Boris Delone]]) are several closely related definitions of well-spaced sets of points, and the '''packing radius''' and '''covering radius''' of these sets measure how well-spaced they are. These sets have applications in [[coding theory]], [[approximation algorithm]]s, and the theory of [[quasicrystal]]s.

==Definitions==
If (''M'',''d'') is a metric space, and ''X'' is a subset of ''M'', then the '''packing radius''' of ''X'' is half of the [[Infimum and supremum|infimum]] of distances between distinct members of ''X''. If the packing radius is ''r'', then open balls of radius ''r'' centered at the points of ''X'' will all be disjoint from each other, and each open ball centered at one of the points of ''X'' with radius ''2r'' will be disjoint from the rest of ''X''. The '''covering radius''' of ''X'' is the infimum of the numbers ''r'' such that every point of ''M'' is within distance ''r'' of at least one point in ''X''; that is, it is the smallest radius such that closed balls of that radius centered at the points of ''X'' have all of ''M'' as their union. An '''ε-packing''' is a set ''X'' of packing radius ≥&amp;nbsp;ε/2 (equivalently, minimum distance ≥&amp;nbsp;ε), an '''ε-covering''' is a set ''X'' of covering radius ≤&amp;nbsp;ε, and an '''ε-net''' is a set that is both an ε-packing and an ε-covering. A set is '''uniformly discrete''' if it has a nonzero packing radius, and '''relatively dense''' if it has a finite covering radius. A '''Delone set''' is a set that is both uniformly discrete and relatively dense; thus, every ε-net is Delone, but not vice versa.&lt;ref&gt;{{citation
 | last = Clarkson | first = Kenneth L.
 | contribution = Building triangulations using ε-nets
 | doi = 10.1145/1132516.1132564
 | location = New York
 | mr = 2277158
 | pages = 326–335
 | publisher = ACM
 | title = [[Symposium on Theory of Computing|STOC'06: Proceedings of the 38th Annual ACM Symposium on Theory of Computing]]
 | year = 2006| isbn = 1595931341
 }}.&lt;/ref&gt;&lt;ref&gt;Some sources use "ε-net" for what is here called an "ε-covering"; see, e.g. {{citation
 | last = Sutherland | first = W.A.
 | isbn = 0-19-853161-3
 | page = 110
 | publisher = Oxford University Press
 | title = Introduction to metric and topological spaces
 | year = 1975
 | zbl = 0304.54002}}.&lt;/ref&gt;

==Construction of ε-nets==
As the most restrictive of the definitions above, ε-nets are at least as difficult to construct as ε-packings, ε-coverings, and Delone sets. However, whenever the points of ''M'' have a [[well-ordering]], [[transfinite induction]] shows that it is possible to construct an ε-net ''N'', by including in ''N'' every point for which the infimum of distances to the set of earlier points in the ordering is at least&amp;nbsp;ε.  For finite sets of points in a Euclidean space of bounded dimension, each point may be tested in constant time by mapping it to a grid of cells of diameter ε, and using a [[hash table]] to test which nearby cells already contain points of ''N''; thus, in this case, an ε-net can be constructed in [[linear time]].&lt;ref&gt;{{citation
 | last = Har-Peled | first = S. | authorlink = Sariel Har-Peled
 | doi = 10.1007/s00454-004-2822-7
 | issue = 4
 | journal = [[Discrete and Computational Geometry]]
 | mr = 2053498
 | pages = 545–565
 | title = Clustering motion
 | volume = 31
 | year = 2004}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Har-Peled | first1 = S.
 | last2 = Raichel | first2 = B.
 | contribution = Net and prune: A linear time algorithm for Euclidean distance problems
 | pages = 605–614
 | title = [[Symposium on Theory of Computing|STOC'13: Proceedings of the 45th Annual ACM Symposium on Theory of Computing]]
 | contribution-url = https://arxiv.org/abs/1409.7425
 | year = 2013}}.&lt;/ref&gt;

For more general finite or [[compact space|compact]] metric spaces, an alternative algorithm of [[Teofilo F. Gonzalez|Teo Gonzalez]] based on the [[farthest-first traversal]] can be used to construct a finite ε-net. This algorithm initializes the net ''N'' to be empty, and then repeatedly adds to ''N'' the farthest point in ''M'' from ''N'', breaking ties arbitrarily and stopping when all points of&amp;nbsp;''M'' are within distance&amp;nbsp;ε of&amp;nbsp;''N''.&lt;ref&gt;{{citation
 | last = Gonzalez | first = T. F.
 | doi = 10.1016/0304-3975(85)90224-5
 | issue = 2–3
 | journal = [[Theoretical Computer Science (journal)|Theoretical Computer Science]]
 | mr = 807927
 | pages = 293–306
 | title = Clustering to minimize the maximum intercluster distance
 | volume = 38
 | year = 1985}}.&lt;/ref&gt; In [[doubling space|spaces of bounded doubling dimension]], Gonzalez' algorithm can be implemented in O(''n''&amp;nbsp;log&amp;nbsp;''n'') time for point sets with a polynomial ratio between their farthest and closest distances, and approximated in the same time bound for arbitrary point sets.&lt;ref name="HM06"&gt;{{citation
 | last1 = Har-Peled | first1 = S.
 | last2 = Mendel | first2 = M.
 | doi = 10.1137/S0097539704446281
 | issue = 5
 | journal = [[SIAM Journal on Computing]]
 | mr = 2217141
 | pages = 1148–1184
 | title = Fast construction of nets in low-dimensional metrics, and their applications
 | volume = 35
 | year = 2006| arxiv = cs/0409057
 }}.&lt;/ref&gt;

==Applications==
===Coding theory===
{{main|Hamming bound#Covering radius and packing radius}}

In the theory of [[error-correcting code]]s, the metric space containing a [[block code]] ''C'' consists of strings of a fixed length, say ''n'', taken over an alphabet of size ''q'' (can be thought of as [[Coordinate vector|vectors]]), with the [[Hamming metric]]. This space is denoted by &lt;math&gt;\scriptstyle \mathcal{A}_q^n&lt;/math&gt;. The covering radius and packing radius of this metric space are related to the code's ability to correct errors.

===Approximation algorithms===
{{harvtxt|Har-Peled|Raichel|2013}} describe an algorithmic paradigm that they call "net and prune" for designing [[approximation algorithm]]s for certain types of geometric optimization problems defined on sets of points in [[Euclidean space]]s. An algorithm of this type works by performing the following steps:
#Choose a random point ''p'' from the point set, find its nearest neighbor ''q'', and set ε to the distance between ''p'' and ''q''.
#Test whether ε is (approximately) bigger than or smaller than the optimal solution value (using a technique specific to the particular optimization problem being solved)
#*If it is bigger, remove from the input the points whose closest neighbor is farther than ε
#*If it is smaller, construct an ε-net ''N'', and remove from the input the points that are not in ''N''.
In both cases, the expected number of remaining points decreases by a constant factor, so the time is dominated by the testing step. As they show, this paradigm can be used to construct fast approximation algorithms for [[k-center]] clustering, finding a pair of points with median distance, and several related problems.

A hierarchical system of nets, called a ''net-tree'', may be used in [[doubling space|spaces of bounded doubling dimension]] to construct [[well-separated pair decomposition]]s, [[geometric spanner]]s, and approximate [[Nearest neighbor search|nearest neighbors]].&lt;ref name="HM06"/&gt;&lt;ref&gt;{{citation
 | last1 = Krauthgamer | first1 = Robert
 | last2 = Lee | first2 = James R.
 | contribution = Navigating nets: simple algorithms for proximity search
 | isbn = 0-89871-558-X
 | location = Philadelphia, PA, USA
 | pages = 798–807
 | publisher = Society for Industrial and Applied Mathematics
 | title = Proceedings of the 15th Annual ACM-SIAM Symposium on Discrete Algorithms (SODA '04)
 | url = http://dl.acm.org/citation.cfm?id=982792.982913
 | year = 2004}}.&lt;/ref&gt;

===Crystallography===
For points in [[Euclidean space]], a set ''X'' is a [[Meyer set]] if it is relatively dense and its [[Minkowski difference|difference set]] ''X''&amp;nbsp;&amp;minus;&amp;nbsp;''X'' is uniformly discrete. Equivalently, ''X'' is a Meyer set if both ''X'' and ''X''&amp;nbsp;&amp;minus;&amp;nbsp;''X'' are Delone. Meyer sets are named after [[Yves Meyer]], who introduced them (with a different but equivalent definition based on [[harmonic analysis]]) as a mathematical model for [[quasicrystal]]s. They include the point sets of [[lattice (group)|lattice]]s, [[Penrose tiling]]s, and the [[Minkowski sum]]s of these sets with finite sets.&lt;ref&gt;{{citation
 | last = Moody | first = Robert V. | authorlink = Robert Moody
 | contribution = Meyer sets and their duals
 | location = Dordrecht
 | mr = 1460032
 | pages = 403–441
 | publisher = Kluwer Academic Publishers
 | series = NATO Advanced Science Institutes Series C: Mathematical and Physical Sciences
 | title = The Mathematics of Long-Range Aperiodic Order (Waterloo, ON, 1995)
 | url = http://www.math.ualberta.ca/~rvmoody/psFiles/moody.ps
 | volume = 489
 | year = 1997}}.&lt;/ref&gt;

The [[Voronoi cell]]s of symmetric Delone sets form [[space-filling polyhedron|space-filling polyhedra]] called [[plesiohedron|plesiohedra]].&lt;ref&gt;{{citation
 | last1 = Grünbaum | first1 = Branko | author1-link = Branko Grünbaum
 | last2 = Shephard | first2 = G. C. | author2-link = Geoffrey Colin Shephard
 | doi = 10.1090/S0273-0979-1980-14827-2
 | issue = 3
 | journal = [[Bulletin of the American Mathematical Society]]
 | mr = 585178
 | pages = 951–973
 | series = New Series
 | title = Tilings with congruent tiles
 | volume = 3
 | year = 1980}}.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
* [http://tilings.math.uni-bielefeld.de/glossary/delone_set Delone set] – Tilings Encyclopedia

[[Category:Metric geometry]]</text>
      <sha1>fk3gbs4tuo7stsybtj3ykr8proqq5gg</sha1>
    </revision>
  </page>
  <page>
    <title>Denjoy–Wolff theorem</title>
    <ns>0</ns>
    <id>33962500</id>
    <revision>
      <id>807134115</id>
      <parentid>790701720</parentid>
      <timestamp>2017-10-26T03:20:28Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>[[User:JCW-CleanerBot#Logic|task]], replaced: C. R. Acad. Scie. → C. R. Acad. Sci. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6228">In [[mathematics]], the '''Denjoy–Wolff theorem''' is a theorem in [[complex analysis]] and [[dynamical systems]] concerning fixed points and iterations of [[holomorphic mapping]]s of the [[unit disc]] in the [[complex numbers]] into itself. The result was proved independently in 1926 by the French mathematician [[Arnaud Denjoy]] and the Dutch mathematician [[Julius Wolff (mathematician)|Julius Wolff]].

==Statement==
'''Theorem.''' Let ''D'' be the open unit disk in '''C''' and let ''f'' be a holomorphic function mapping ''D'' into ''D'' which is not an automorphism of ''D'' (i.e. a [[Möbius transformation]]). Then there is a unique point ''z'' in the closure of ''D'' such that the iterates of ''f'' tend to ''z'' uniformly on compact subsets of ''D''. If ''z'' lies in ''D'', it is the unique fixed point of ''f''. The mapping ''f'' leaves invariant [[Poincaré metric#Metric and volume element on the Poincaré disk|hyperbolic disks]] centered on ''z'', if ''z'' lies in ''D'', and disks tangent to the unit circle at ''z'', if ''z'' lies on the boundary of ''D''.

When the fixed point is at ''z''&amp;nbsp;=&amp;nbsp;0, the hyperbolic disks centred at ''z''  are just the Euclidean disks with centre 0. Otherwise ''f'' can be conjugated by a Möbius transformation so that the fixed point is zero. An elementary proof of the theorem is given below, taken from {{harvtxt|Shapiro|1993}} and {{harvtxt|Burckel|1981}}. Two other short proofs can be found in {{harvtxt|Carleson|Gamelin|1993}}.

==Proof of theorem==

===Fixed point in the disk===
If ''f'' has a fixed point ''z'' in ''D'' then, after conjugating by a Möbius transformation, it can be assumed that ''z'' = 0. Let ''M''(''r'') be the maximum modulus of ''f'' on ''|z|'' = ''r'' &lt; 1. By the [[Schwarz lemma]]&lt;ref&gt;{{harvnb|Shapiro|1992|p=79}}&lt;/ref&gt;

:&lt;math&gt; |f(z)|\le \delta(r) |z|,&lt;/math&gt;

for |''z''| ≤ ''r'', where

:&lt;math&gt;\delta(r)={M(r)\over r} &lt; 1.&lt;/math&gt;

It follows by iteration that

:&lt;math&gt;|f^n(z)|\le \delta(r)^n&lt;/math&gt;

for |''z''| ≤ ''r''. These two inequalities imply the result in this case.

===No fixed points===
When ''f'' acts in ''D'' without fixed points, Wolff showed that there is a point ''z'' on the boundary such that the iterates of ''f'' leave invariant each disk tangent to the boundary at that point.

Take a sequence &lt;math&gt;r_k&lt;/math&gt; increasing to 1 and set&lt;ref&gt;{{harvnb|Burckel|1981}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Steinmetz|1993|pp=43–44}}&lt;/ref&gt;

:&lt;math&gt;f_k(z)=r_kf(z).&lt;/math&gt;

By applying [[Rouché's theorem]] to &lt;math&gt;f_k(z) - z&lt;/math&gt; and &lt;math&gt;g(z)=z&lt;/math&gt;, &lt;math&gt;f_k &lt;/math&gt; has exactly one zero &lt;math&gt;z_k&lt;/math&gt; in ''D''. 
Passing to a subsequence if necessary, it can be assumed that &lt;math&gt;z_k\rightarrow z.&lt;/math&gt; The point ''z'' cannot lie in ''D'', because, 
by passing to the limit, ''z'' would have to be a fixed point. The result for the case of fixed points implies that the maps &lt;math&gt;f_k &lt;/math&gt; leave invariant all Euclidean disks whose hyperbolic center is located at &lt;math&gt;z_k&lt;/math&gt;. Explicit computations show that, as ''k'' increases, one can choose such disks so that they tend to any given disk tangent to the boundary at ''z''. By continuity, ''f'' leaves each such disk Δ invariant.

To see that &lt;math&gt;f^n&lt;/math&gt; converges uniformly on compacta to the constant ''z'', it is enough to show that the same is true for any subsequence &lt;math&gt;f^{n_k}&lt;/math&gt;, convergent in the same sense to ''g'', say. Such limits exist by Montel's theorem, and if
''g'' is non-constant, it can also be assumed that &lt;math&gt;f^{n_{k+1}-n_k}&lt;/math&gt; has a limit, ''h'' say. But then

:&lt;math&gt;h(g(w))=g(w), &lt;/math&gt;

for ''w'' in ''D''.

Since ''h'' is holomorphic and ''g''(''D'') open,

:&lt;math&gt;h(w) = w&lt;/math&gt;

for all ''w''.

Setting  &lt;math&gt; m_k= n_{k+1} - n_k&lt;/math&gt;, it can also be assumed that &lt;math&gt;f^{m_k-1}&lt;/math&gt; is convergent to ''F'' say.

But then ''f''(''F''(''w'')) = ''w'' = ''f''(''F''(''w'')), contradicting the fact that ''f'' is not an automorphism.

Hence every subsequence tends to some constant uniformly on compacta in ''D''.

The invariance of Δ implies each such constant lies in the closure of each disk Δ, and hence their intersection, the single point ''z''. By Montel's theorem, it follows that &lt;math&gt;f^n&lt;/math&gt; converges uniformly on compacta to the constant ''z''.

==Notes==
{{reflist}}

==References==
*{{citation|last=Beardon|first= A. F.|title=Iteration of contractions and analytic maps|journal=
J. London Math. Soc.|volume=41|year= 1990|pages= 141–150}}
*{{citation|last=Burckel|first=R. B.|title=Iterating analytic self-maps of discs|journal=Amer. Math. Monthly|volume= 88 |year=1981|pages= 396–407|doi=10.2307/2321822}}
*{{citation|last=Carleson|first=L.|last2= Gamelin|first2= T. D. W.|title=Complex dynamics|series=
Universitext: Tracts in Mathematics|publisher= Springer-Verlag|year=1993|isbn=0-387-97942-5}}
*{{citation|first=A.|last= Denjoy|title= Sur l’itération des fonctions analytiques|journal= C. R. Acad. Sci.|volume= 182|year=1926|pages= 255–257}}
*{{citation|last=Shapiro|first=J. H.|title=Composition operators and classical function theory|series=Universitext: Tracts in Mathematics|publisher= Springer-Verlag|year= 1993|isbn=0-387-94067-7}}
*{{citation|last=Shoikhet|first=D.|title=Semigroups in geometrical function theory|publisher= Kluwer Academic Publishers|year= 2001|isbn=0-7923-7111-9 }}
*{{citation|last=Steinmetz|first= Norbert|title=Rational iteration. Complex analytic dynamical systems|series =de Gruyter Studies in Mathematics|volume=16|publisher=Walter de Gruyter &amp; Co.|year=1993|isbn= 3-11-013765-8}}
*{{citation|first=J.|last= Wolff|title= Sur l’itération des fonctions holomorphes dans une région, et dont les valeurs appartiennent a cette région|journal= C. R. Acad. Sci.|volume= 182 |year=1926|pages= 42–43}}
*{{citation|first=J. |last=Wolff|title= Sur l’itération des fonctions bornées|journal= C. R. Acad. Sci. |volume=182 |year=1926|pages=200–201}}
*{{citation|first=J.|last= Wolff|title=Sur une généralisation d’un théorème de Schwarz|journal= C. R. Acad. Sci.|volume=
182 |year=1926|pages=918–920}}

{{DEFAULTSORT:Denjoy-Wolff theorem}}
[[Category:Theorems in dynamical systems]]
[[Category:Theorems in complex analysis]]</text>
      <sha1>cd1ofcck9arrhm0lntfnui0bigemvu4</sha1>
    </revision>
  </page>
  <page>
    <title>Direct Autonomous Authentication</title>
    <ns>0</ns>
    <id>58794547</id>
    <revision>
      <id>865255810</id>
      <parentid>864599874</parentid>
      <timestamp>2018-10-22T19:14:57Z</timestamp>
      <contributor>
        <username>Escape Orbit</username>
        <id>4788526</id>
      </contributor>
      <comment>removed section.  This article is not a [[WP:COATRACK|coatrack]] to offer a view on the history of cybersecurity</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7053">'''Direct Autonomous Authentication''' (DAA) is a [[cybersecurity]] platform developed by San Francisco-based&lt;ref&gt;{{Cite web|url=https://www.bloomberg.com/research/stocks/private/snapshot.asp?privcapId=535447543|title=Bloomberg Research|last=|first=|date=2017-11-29|website=Bloomberg.com|language=en|access-date=2018-10-16}}&lt;/ref&gt; technology company Averon.&lt;ref&gt;{{Cite web|url=http://fortune.com/2017/10/30/term-sheet-monday-october-30/|title=Term Sheet Monday|last=Marinova|first=Polina|date=2017-10-30|website=Fortune.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://techcrunch.com/2017/10/28/averon-closes-8-3m-funding-to-make-your-smartphone-the-key-to-id-online/|title=TechCrunch: The Key to ID Online|last=Butcher|first=Mike|date=2017-10-28|website=techcrunch.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;

The DAA platform enables secure authentication of a mobile user whilst simultaneously preserving privacy of the user.&lt;ref&gt;{{Cite web|url=https://451research.com/report-short?entityId=94202/|title=451 Research Analyst Report|last=Bekker|first=Garrett|date=2018-01-30|website=451 Research|language=en|access-date=2018-10-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://cdn2.hubspot.net/hubfs/3955296/ovum-report-averon.pdf?hsCtaTracking=21516a12-2112-4331-b738-9cc9ebbd4b19%7C77dd6935-548f-45ff-9b6a-8652e13c284c/|title=Ovum Report: On The Radar |last=Kellet|first=Andrew|date=2018-03-21|website=ovum.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;

The technology was developed in stealth from late 2015, first publicly introduced by Averon in 2018, and featured at the 2018 [[Consumer Electronics Show]] as a new technology that combats the increasing threats of cybercrime and consumer account hacking.&lt;ref&gt;{{Cite web|url=https://www.crn.com.au/news/10-coolest-smb-products-at-ces-2018-480892?utm_source=desktop&amp;utm_medium=twitter&amp;utm_campaign=share/|title=10 Coolest Products at CES 2018|last=Alspach|first=Kyle|date=2018-01-11|website=CRN|language=en|access-date=2018-10-16}}&lt;/ref&gt;


== Overview ==
In contrast to legacy methods of cybersecurity, the DAA platform bypasses end user actions, and rather than focusing on the authentication of a user's device, DAA instead provides autonomous authentication of a user's mobile phone number, since the mobile phone number continues to be associated with the user even when they lose, destroy or upgrade their mobile phone. &lt;ref&gt;{{Cite web|url=https://www.redherring.com/mobile/averon-ceo-wendell-brown-ux-now-crucial-element-cybersecurity/|title=UX Now Crucial Element in Cybersecurity|last=Williams|first=Sean|date=2017-11-02|website=redherring.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;

The DAA method uses a proprietary mix of technology developed by Averon that works inside the secure mobile network data pipelines together with encrypted technology already within every smartphone. The combination of these autonomous authentication methods has been described by research analysts as a faster, more secure, and stronger method of cybersecurity than traditional methods.&lt;ref&gt;{{Cite web|url=https://451research.com/report-short?entityId=94202/|title=Averon offers frictionless mobile authentication|last=Bekker|first=Garrett|date=2018-01-28|website=451 Research|language=en|access-date=2018-03-16}}&lt;/ref&gt;

== Blockchain and privacy properties ==
Blockchain technology incorporated into the DAA platform ensures the privacy of end users. No identifiable personal data is maintained on the platform, therefore public disclosure of one's authentic identity (such as for the purpose of verified social media interactions) is voluntary. DAA technology affords the end user full control over identity disclosure in any given online interaction, which can be controlled by the end user in varying degrees from fully anonymous to fully identified publicly. &lt;ref&gt;{{Cite web|url=https://martechseries.com/mobile/salesforce-ceo-marc-benioff-invests-in-mobile-identity-start-up-averon/|title=Salesforce CEO Marc Benioff Invests in Mobile Identity Startup Averon |last=|first=|date=2018-03-22|website=martechseries.com|language=en|access-date=2018-10-16}}&lt;/ref&gt; In cases involving the need for anonymity with regard to an end user's safety, such as in cases of whistleblowers or political activists, the DAA platform's blockchain technology provides a method for both complete anonymity with the option of voluntary verification of limited but often needed data (such as verifying an anonymous user's general location). Thus DAA technology alleviates the heretofore insurmountable challenge of protecting user privacy with the need for authentication.&lt;ref&gt;{{Cite web|url=https://451research.com/report-short?entityId=94202/|title=Averon offers frictionless mobile authentication|last=Bekker|first=Garrett|date=2018-01-28|website=451 Research|language=en|access-date=2018-03-16}}&lt;/ref&gt;

== Use cases ==
The DAA technology platform was designed to be seamlessly adopted for utilization in a wide variety of industries and use cases in which mobile authentication of users is required.&lt;ref&gt;{{Cite web|url=https://medium.com/ideo-colab/digital-identity-is-broken-but-we-can-fix-it-b15398180bdf/|title=Digital Identity Is Broken, But We Can Fix It|last=Elitzer|first=Dan|date=2017-04-11|website=Medium|language=en|access-date=2018-03-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://451research.com/report-short?entityId=94202/|title=Averon offers frictionless mobile authentication|last=Bekker|first=Garrett|date=2018-01-28|website=451 Research|language=en|access-date=2018-03-16}}&lt;/ref&gt;

== Recognition ==
Since its introduction to the market in 2018, the DAA platform has been recognized by a number of industry groups for its innovation, including winning the Gold prize at the 2018 [[Edison Awards]], a Cybersecurity Excellence Award, and a BIG Innovation 2018 Award.&lt;ref&gt;{{Cite web|url=http://www.edisonawards.com/winners2018.php  |title=Edison Awards 2018 Winners|last=|first=|date=2018-04-17|website=tmcnet.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.tmcnet.com/usubmit/2018/04/17/8737272.htm/|title=Gold Edison Award 2018|last=|first=|date=2018-04-17|website=tmcnet.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.bintelligence.com/blog/2018/2/7/55-chosen-as-winners-in-annual-big-innovation-awards|title=BIG Innovation Winners 2018|last=|first=|date=2018-02-07|website=bintelligence.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://cybersecurity-excellence-awards.com/candidates/averon|title=Cybersecurity Excellence Awards|last=|first=|date=2018-05-03|website=oneworldidentity.com|language=en|access-date=2018-10-16}}&lt;/ref&gt;


==See also==
* [[Cybersecurity]]
* [[Blockchain|Blockchain technology]]
* [[Cryptographic protocol]]
* [[Digital credential]]
* [[Privacy enhancing technologies]]

==References==
&lt;references/&gt;

[[Category:Proprietary software]]
[[Category:Computing platforms]]
[[Category:Cryptography]]
[[Category:Mobile Web]]
[[Category:Technology]]
[[Category:Information technology]]</text>
      <sha1>3nylpbvrn30xwai5ttpcphin1zaalzc</sha1>
    </revision>
  </page>
  <page>
    <title>Efficiency (network science)</title>
    <ns>0</ns>
    <id>44431245</id>
    <revision>
      <id>852133244</id>
      <parentid>809227676</parentid>
      <timestamp>2018-07-26T21:19:23Z</timestamp>
      <contributor>
        <ip>8.26.157.145</ip>
      </contributor>
      <comment>/* Definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6075">{{Network Science}}

In [[network science]], the '''efficiency''' of a [[complex network|network]] is a measure of how efficiently it exchanges information.
&lt;ref name="LatoraMarchiori2001"&gt;{{Cite journal
 | doi     = 10.1103/PhysRevLett.87.198701
 | authors = Latora, Vito; Marchiori, Massimo
 | title   = Efficient Behavior of Small-World Networks
 | journal = Phys. Rev. Lett.
 | volume  = 87
 | date    = 17 October 2001
 | arxiv   = cond-mat/0101396
 | bibcode=2001PhRvL..87s8701L}}
&lt;/ref&gt; The concept of efficiency can be applied to both local and global scales in a network. On a global scale, efficiency quantifies the exchange of information across the whole network where information is concurrently exchanged. The local efficiency quantifies a network's resistance to failure on a small scale. That is the local efficiency of a node &lt;math&gt;i&lt;/math&gt; characterizes how well information is exchanged by its neighbors when it is removed.

==Definition==
The '''average efficiency''' of a network &lt;math&gt;G&lt;/math&gt; is defined as:&lt;ref name="LatoraMarchiori2001"/&gt;

:&lt;math&gt;
E(G) = \frac{1}{n(n-1)} \sum_{i \neq j \in G} \frac{1}{d(i,j)} 
&lt;/math&gt;

where &lt;math&gt;n&lt;/math&gt; denotes the total nodes in a network and &lt;math&gt;d(i,j)&lt;/math&gt; denotes the length of the shortest path between a node &lt;math&gt;i&lt;/math&gt; and another node &lt;math&gt;j&lt;/math&gt;.

As an alternative to the [[average path length]] &lt;math&gt;L&lt;/math&gt; of a network, the '''global efficiency''' of a network is defined as:

:&lt;math&gt;
E_{glob}(G) = \frac{E(G)}{E(G^{ideal})} 
&lt;/math&gt;

where &lt;math&gt;G^{ideal}&lt;/math&gt; is the "ideal" graph on &lt;math&gt;n&lt;/math&gt; nodes wherein all possible edges are present.  The global efficiency of network is a measure comparable to &lt;math&gt;1/L&lt;/math&gt;, rather than just the average path length itself. The key distinction is that &lt;math&gt;1/L&lt;/math&gt; measures efficiency in a system where only one packet of information is being moved through the network and &lt;math&gt;E_{glob}(G)&lt;/math&gt; measures the efficiency where all the nodes are exchanging packets of information with each other.

As an alternative to the [[clustering coefficient]] of a network, the '''local efficiency''' of a network is defined as:

:&lt;math&gt;
E_{loc}(G) = \frac{1}{n} \sum_{i \in G} E(G_i) 
&lt;/math&gt;

where &lt;math&gt;G_i&lt;/math&gt; is the local [[Glossary of graph theory#Subgraphs|subgraph]] consisting only of a node &lt;math&gt;i&lt;/math&gt;'s immediate neighbors, but not the node &lt;math&gt;i&lt;/math&gt; itself.

==Applications==
Broadly speaking, the efficiency of a network can be used to quantify [[Small-world network|small world]] behavior in networks. Efficiency can also be used to determine cost-effective structures in [[Weighted network|weighted]] and unweighted networks. 
&lt;ref name="LatoraMarchiori2002"&gt;{{Cite journal
 | doi     =  10.1140/epjb/e2003-00095-5
 | authors = Latora, Vito; Marchiori, Massimo
 | title   = Economic small-world behavior in weighted networks 
 | journal = The European Physical Journal B
 | volume  = 32
 | issue   = 2
 | pages   = 249–263
 | date    = March 2003
 | arxiv   = cond-mat/0204089|bibcode = 2003EPJB...32..249L }}
&lt;/ref&gt; Comparing the two measures of efficiency in a network to a [[Random graph|random network]] of the same size to see how economically a network is constructed. Furthermore, global efficiency is easier to use numerically than its counterpart, path length.
&lt;ref name="BullmoreSporns2009"&gt;{{Cite journal
 | doi     = 10.1038/nrn2575
 | authors = Bullmore, Ed; Sporns, Olaf
 | title   = Complex brain networks graph theoretical analysis of structural and functional systems
 | journal = Nature Reviews Neuroscience
 | volume  = 10
 | pages   = 186–198
 | date    = March 2009
 | pmid=19190637}}
&lt;/ref&gt;

For these reasons the concept of efficiency has been used across the many diverse applications of network science.&lt;ref name="LatoraMarchiori2002"/&gt;
&lt;ref name="Bocaletti et al 2006"&gt;{{Cite journal
 | doi     = 10.1016/j.physrep.2005.10.009
 | authors = Bocaletti, S.; Latora, V.; Moreno, Y.; Chavez, M.; Hwang, D.-U.
 | title   = Complex networks: Structure and dynamics
 | journal = Physics Reports
 | volume  = 424
 | issue   = 4-5
 | pages   = 175–308
 | date    = February 2006 |bibcode = 2006PhR...424..175B }}
&lt;/ref&gt; Efficiency is useful in analysis of man-made networks such as transportation networks and communications networks. It is used to help determine how cost-efficient a particular network construction is, as well as how fault tolerant it is. Studies of such networks reveal that they tend to have high global efficiency, implying good use of resources, but low local efficiency. This is because, for example, a subway network is not closed, and passengers can be re-routed, by buses for example, even if a particular line in the network is down.&lt;ref name="LatoraMarchiori2001"/&gt;

Beyond human constructed networks, efficiency is a useful metric when talking about physical biological networks. In any facet of biology, the scarcity of resource plays a key role, and biological networks are no exception. Efficiency is used in neuroscience to discuss information transfer across [[Biological neural network|neural networks]], where the physical space and resource constraints are a major factor.&lt;ref name="BullmoreSporns2009"/&gt; Efficiency has also been used in the study of [[ant colony]] tunnel systems, which are usually composed of large rooms as well as many sprawling tunnels.&lt;ref name="Buhl et al 2004"&gt;{{Cite journal
 | doi     =  10.1140/epjb/e2004-00364-9
 | authors = Buhl, J.; Gautrais, J.; Solé, R.V.; Kuntz, P.; Valverde, S.; Deneubourg, J.L.; Theraulaz, G. 
 | title   = Efficiency and robustness in ant networks of galleries 
 | journal = The European Physical Journal B
 | volume  = 42
 | issue   = 1
 | pages   = 123–129
 | date    = November 2002|bibcode = 2004EPJB...42..123B }}
&lt;/ref&gt; This application to ant colonies is not too surprising because the large structure of a colony must serve as a transportation network for various resources, most namely food.&lt;ref name="Bocaletti et al 2006"/&gt;

==References==
{{Reflist}}

[[Category:Network theory]]</text>
      <sha1>9ssq3k4zj1q7zxwisxhit946kl68w0m</sha1>
    </revision>
  </page>
  <page>
    <title>Eilenberg's inequality</title>
    <ns>0</ns>
    <id>9718355</id>
    <revision>
      <id>812602641</id>
      <parentid>812602554</parentid>
      <timestamp>2017-11-28T20:08:11Z</timestamp>
      <contributor>
        <ip>2601:547:901:ACB0:FCF6:6824:74A0:8210</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1119">'''Eilenberg's inequality''' is a [[inequality (mathematics)|mathematical inequality]] for [[Lipschitz continuity|Lipschitz-continuous function]]s.

Let ''&amp;fnof;''&amp;nbsp;:&amp;nbsp;''X''&amp;nbsp;→&amp;nbsp;''Y'' be a Lipschitz-continuous function between [[separable space|separable]] [[metric space]]s whose Lipschitz constant is denoted by Lip&amp;nbsp;''&amp;fnof;''. Then, Eilenberg's inequality states that

:&lt;math&gt;\int_Y^* H_{m-n}(A\cap f^{-1}(y)) \, dH_n(y) \leq \frac{v_{m-n}v_n}{v_m}(\text{Lip }f)^n H_m(A), &lt;/math&gt;

for any ''A''&amp;nbsp;⊂&amp;nbsp;''X'' and all 0&amp;nbsp;≤&amp;nbsp;''n''&amp;nbsp;≤&amp;nbsp;''m'', where

* the asterisk denotes the upper&amp;nbsp;[[Lebesgue integral]],
* ''v''&lt;sub&gt;''n''&lt;/sub&gt; is the volume of the unit ball in&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;,
* ''H''&lt;sub&gt;''n''&lt;/sub&gt; is the ''n''-dimensional [[Hausdorff measure]].
The Eilenberg's Inequality is a key ingredient for the proof of the [[Coarea formula]].
==References==
* Yu. D. Burago and V. A. Zalgaller, ''Geometric inequalities''. Translated from the Russian by A. B. Sosinskiĭ. Springer-Verlag, Berlin, 1988. {{ISBN|3-540-13615-0}}.

[[Category:Inequalities]]</text>
      <sha1>6fwik1el5ndoj62rizennewvknu5g36</sha1>
    </revision>
  </page>
  <page>
    <title>Euclidean shortest path</title>
    <ns>0</ns>
    <id>10976022</id>
    <revision>
      <id>841574594</id>
      <parentid>805923514</parentid>
      <timestamp>2018-05-16T17:34:33Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6371">[[File:Euclidean Shortest Path KernelCAD Screenshot.jpg|thumb|right|Example of a shortest path in a three-dimensional Euclidean space]]
The '''Euclidean shortest path''' problem is a problem in [[computational geometry]]: given a set of [[Polyhedron|polyhedral]] obstacles in a [[Euclidean space]], and two points, find the shortest path between the points that does not intersect any of the obstacles.

In two dimensions, the problem can be solved in [[polynomial time]] in a model of computation allowing addition and comparisons of real numbers, despite theoretical difficulties involving the [[Precision (computer science)|numerical precision]] needed to perform such calculations. These algorithms are based on two different principles, either performing a shortest path algorithm such as [[Dijkstra's algorithm]] on a [[visibility graph]] derived from the obstacles or (in an approach called the ''continuous Dijkstra'' method) propagating a wavefront from one of the points until it meets the other.

In three (and higher) dimensions the problem is [[NP-hard]] in the general case,&lt;ref&gt;
J. Canny and J. H. Reif, "New lower bound techniques for robot motion planning
problems", Proc. 28th Annu. IEEE Sympos. Found. Comput. Sci., 1987, pp.
49-60.
&lt;/ref&gt; but there exist efficient approximation algorithms that run in polynomial time based on the idea of finding a suitable sample of points on the obstacle edges and performing a visibility graph calculation using these sample points.

There are many results on computing shortest paths which stays on a polyhedral surface. Given two points s and t, say on the surface
of a [[convex polyhedron]], the problem is to compute a shortest path that never leaves the surface and connects s with t. 
This is a generalization of the problem from 2-dimension but it is much easier than the 3-dimensional problem.

Also, there are variations of this problem, where the obstacles are ''weighted'', i.e., one can go through an obstacle, but it incurs
an extra cost to go through an obstacle. The standard problem is the special case where the obstacles have infinite weight.  This is
termed as the ''[[weighted region problem]]'' in the literature.

==See also==
*[[Shortest path problem]]

==Notes==
{{reflist}}

==References==
*{{citation
 | last1 = Aleksandrov | first1 = Lyudmil
 | last2 = Maheshwari | first2 = Anil
 | last3 = Sack    | first3= Joerg
 | title = Determining approximate shortest paths in weighted polyhedral surfaces
 | pages = 25–53
 | url = http://doi.acm.org/10.1145/1044731.1044733
 | year = 2005
 | doi = 10.1145/1044731.1044733
 | journal = [[Journal of the ACM]]
 | volume = 52}}.
*{{citation
 | last1 = Chiang | first1 = Yi-Jen
 | last2 = Mitchell | first2 = Joseph S. B.
 | contribution = Two-point Euclidean shortest path queries in the plane
 | pages = 215–224
 | title = Proc. 10th ACM-SIAM Symposium on Discrete Algorithms (SODA 1999)
 | url = http://portal.acm.org/citation.cfm?id=314500.314560
 | year = 1999}}.
*{{citation
 | last1 = Choi | first1 = Joonsoo
 | last2 = Sellen | first2 = Jürgen
 | last3 = Yap | first3 = Chee-Keng
 | contribution = Approximate Euclidean shortest path in 3-space
 | doi = 10.1145/177424.177501
 | pages = 41–48
 | title = [[Symposium on Computational Geometry|Proc. 10th ACM Symposium on Computational Geometry]]
 | year = 1994
 | isbn = 0-89791-648-4}}.
*{{citation
 | last1 = Hershberger | first1 = John
 | last2 = Suri | first2 = Subhash | author2-link = Subhash Suri
 | doi = 10.1137/S0097539795289604
 | issue = 6
 | journal = [[SIAM Journal on Computing]]
 | pages = 2215–2256
 | title = An optimal algorithm for Euclidean shortest paths in the plane
 | volume = 28
 | year = 1999| citeseerx = 10.1.1.47.2037}}.
*{{citation
 | last1 = Kapoor | first1 = S.
 | last2 = Maheshwari | first2 = S. N.
 | contribution = Efficient algorithms for Euclidean shortest path and visibility problems with polygonal obstacles
 | doi = 10.1145/73393.73411
 | pages = 172–182
 | title = [[Symposium on Computational Geometry|Proc. 4th ACM Symposium on Computational Geometry]]
 | year = 1988
 | isbn = 0-89791-270-5}}.
*{{citation
 | last1 = Kapoor | first1 = S.
 | last2 = Maheshwari | first2 = S. N.
 | last3 = Mitchell | first3 = Joseph S. B.
 | doi = 10.1007/PL00009323
 | issue = 4
 | journal = [[Discrete and Computational Geometry]]
 | pages = 377–383
 | title = An efficient algorithm for Euclidean shortest paths among polygonal obstacles in the plane
 | volume = 18
 | year = 1997}}.
*{{citation
 | last1 = Lanthier | first1 = Mark
 | last2 = Maheshwari | first2 = Anil
 | last3 = Sack    | first3= Joerg
 | contribution = Approximating shortest paths on weighted polyhedral surfaces
 | pages = 527–562
 | title = [[Algorithmica]]
 | contribution-url = http://link.springer.de/link/service/journals/00453/contents/01/0027/
 | year = 2001}}.
*{{citation
 | last1 = Lee | first1 = D. T. | author1-link = Der-Tsai Lee
 | last2 = Preparata | first2 = F. P. | author2-link = Franco P. Preparata
 | doi = 10.1002/net.3230140304
 | issue = 3
 | journal = Networks
 | pages = 393–410
 | title = Euclidean shortest paths in the presence of rectilinear barriers
 | volume = 14
 | year = 1984}}.
*{{citation
 | last1 = Li | first1 = Fajie
 | last2 = Klette | first2 = Reinhard
 | doi = 10.1007/978-1-4471-2256-2
 | isbn = 978-1-4471-2255-5
 | publisher = [[Springer-Verlag]]
 | title = Euclidean Shortest Paths: Exact or Approximate Algorithms
 | year = 2011}}.
*{{citation
 | last1 = Samuel | first1 = David
 | last2 = Toussaint | first2 = Godfried T. | author2-link = Godfried Toussaint
 | doi = 10.1007/BF02247961
 | issue = 1
 | journal = Computing
 | pages = 1–19
 | title = Computing the external geodesic diameter of a simple polygon
 | volume = 44
 | year = 1990}}.
*{{citation
 | last = Toussaint | first = Godfried T. | author-link = Godfried Toussaint
 | issue = 2
 | journal = Revue D'Intelligence Artificielle
 | pages = 9–42
 | title = Computing geodesic properties inside a simple polygon
 | url = http://cgm.cs.mcgill.ca/~godfried/publications/geodesic.pdf
 | volume = 3
 | year = 1989}}.

== External links ==
* [http://www.dynoinsight.com/ESP.htm Implementation] of Euclidean Shortest Path algorithm in [[KernelCAD]] software

[[Category:Geometric algorithms]]
[[Category:Computational geometry]]


{{combin-stub}}
{{geometry-stub}}</text>
      <sha1>iwwkh1yzh53kg9d4ze9hncsajdsqvf2</sha1>
    </revision>
  </page>
  <page>
    <title>Glossary of order theory</title>
    <ns>0</ns>
    <id>453204</id>
    <revision>
      <id>855502669</id>
      <parentid>847331548</parentid>
      <timestamp>2018-08-18T19:49:04Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <minor/>
      <comment>convert HTML entities</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27769">This is a glossary of some terms used in various branches of [[mathematics]] that are related to the fields of [[order theory|order]], [[lattice (order)|lattice]], and [[domain theory]]. Note that there is a structured [[list of order topics]] available as well. Other helpful resources might be the following overview articles:

* [[completeness (order theory)|completeness properties]] of partial orders
* [[distributivity (order theory)|distributivity laws]] of order theory
* [[limit preserving (order theory)|preservation properties]] of functions between posets.

In the following, partial orders will usually just be denoted by their carrier sets. As long as the intended meaning is clear from the context, ≤ will suffice to denote the corresponding relational symbol, even without prior introduction. Furthermore, &lt; will denote the [[strict order]] induced by ≤.

{{compact ToC|side=yes|top=yes|num=yes}}
__NOTOC__

== A ==
* '''Acyclic'''.  A [[binary relation]] is acyclic if it contains no "cycles": equivalently, its [[transitive closure]] is [[Antisymmetric relation|antisymmetric]].&lt;ref name=BosSuz/&gt;
* '''Adjoint'''. See ''Galois connection''.
* '''[[Alexandrov topology]]'''. For a preordered set ''P'', any upper set ''O'' is '''Alexandrov-open'''. Inversely, a topology is Alexandrov if any intersection of open sets is open.
* '''[[Algebraic poset]]'''. A poset is algebraic if it has a base of compact elements.
* '''[[Antichain]]'''. An antichain is a poset in which no two elements are comparable, i.e., there are no two distinct elements ''x'' and ''y'' such that ''x'' ≤ ''y''. In other words, the order relation of an antichain is just the identity relation.
* '''Approximates relation'''. See ''way-below relation''.
* A [[relation (mathematics)|relation]] ''R'' on a set ''X'' is '''[[antisymmetric relation|antisymmetric]]''', if ''x R y'' and ''y R x'' implies ''x = y'', for all elements ''x'', ''y'' in ''X''.
* An '''[[antitone]]''' function ''f'' between posets ''P'' and ''Q'' is a function for which, for all elements ''x'', ''y'' of ''P'', ''x'' ≤ ''y'' (in ''P'') implies ''f''(''y'') ≤ ''f''(''x'') (in ''Q''). Another name for this property is ''order-reversing''. In [[Mathematical analysis|analysis]], in the presence of [[total order]]s, such functions are often called '''monotonically decreasing''', but this is not a very convenient description when dealing with non-total orders. The dual notion is called ''monotone'' or ''order-preserving''.
* '''[[Asymmetric relation|Asymmetric]]'''. A [[Relation (mathematics)|relation]] ''R'' on a set ''X'' is asymmetric, if ''x R y'' implies ''not y R x'', for all elements ''x'', ''y'' in ''X''.
* An '''atom''' in a poset ''P'' with least element 0, is an element that is minimal among all elements that are unequal to 0.
* A '''atomic''' poset ''P'' with least element 0 is one in which, for  every non-zero element ''x'' of ''P'', there is an atom ''a'' of ''P'' with ''a'' ≤ ''x''.

== B ==

* '''Base'''. See ''continuous poset''.
* A '''[[Boolean algebra (structure)|Boolean algebra]]''' is a distributive lattice with least element 0 and greatest element 1, in which every element ''x'' has a complement ¬''x'', such that ''x'' &amp;and; ¬''x'' = 0 and ''x'' &amp;or; ¬''x'' = 1.
* A '''[[bounded poset|bounded]]''' poset is one that has a least element and a greatest element.
* A poset is '''[[bounded complete]]''' if every of its subsets with some upper bound also has a least such upper bound. The dual notion is not common.

== C ==

* '''[[Total order#Chains|Chain]]'''. A chain is a totally ordered set or a totally ordered subset of a poset. See also ''total order''.
* '''[[Chain complete]]'''.  A [[partially ordered set]] in which every [[Total order#Chains|chain]] has a [[least upper bound]].
* '''[[Closure operator]]'''. A closure operator on the poset ''P'' is a function ''C'' : ''P'' → ''P'' that is monotone, [[idempotent]], and satisfies ''C''(''x'') ≥ ''x'' for all ''x'' in ''P''.
* '''[[compact element|Compact]]'''. An element ''x'' of a poset is compact if it is ''[[way-below relation|way below]]'' itself, i.e. ''x''&lt;&lt;''x''. One also says that such an ''x'' is ''finite''.
* '''Comparable'''. Two elements ''x'' and ''y'' of a poset ''P'' are comparable if either ''x'' ≤ ''y'' or ''y'' ≤ ''x''.
* '''[[Comparability graph]]'''.  The comparability graph of a poset (''P'', ≤) is the [[Graph (discrete mathematics)|graph]] with vertex set ''P'' in which the edges are those pairs of distinct elements of ''P'' that are comparable under ≤ (and, in particular, under its reflexive reduction &lt;).
* '''[[Complete Boolean algebra]]'''.  A [[Boolean algebra (structure)|Boolean algebra]] that is a complete lattice.
* '''[[Complete Heyting algebra]]'''. A [[Heyting algebra]] that is a complete lattice is called a complete Heyting algebra. This notion coincides with the concepts ''frame'' and ''locale''.
* '''[[Complete lattice]]'''. A complete [[lattice (order)|lattice]] is a poset in which arbitrary (possibly infinite) joins (suprema) and meets (infima) exist.
* '''[[Complete partial order]]'''. A complete partial order, or '''cpo''', is a [[directed complete partial order]] (q.v.) with least element.
* '''Complete relation'''.  Synonym for ''[[Total relation]]''.
* '''Complete semilattice'''. The notion of a ''complete semilattice'' is defined in different ways. As explained in the article on [[completeness (order theory)]], any poset for which either all suprema or all infima exist is already a complete lattice. Hence the notion of a complete semilattice is sometimes used to coincide with the one of a complete lattice. In other cases, complete (meet-) semilattices are defined to be [[bounded complete]] [[complete partial order|cpos]], which is arguably the most complete class of posets that are not already complete lattices.
* '''[[Completely distributive lattice]]'''. A complete lattice is completely distributive if arbitrary joins distribute over arbitrary meets.
* '''Completion'''. A completion of a poset is an [[order-embedding]] of the poset in a complete lattice.
* '''[[Continuous poset]]'''. A poset is continuous if it has a '''base''', i.e. a subset ''B'' of ''P'' such that every element ''x'' of ''P'' is the supremum of a directed set contained in {''y'' in ''B'' | ''y''&lt;&lt;''x''}.
* '''Continuous function'''. See ''Scott-continuous''.
* '''Converse'''.  The converse &lt;° of an order &lt; is that in which x &lt;° y whenever y &lt; x.
* '''Cover'''. An element ''y'' of a poset ''P'' is said to cover an element ''x'' of ''P'' (and is called a cover of ''x'') if ''x'' &lt; ''y'' and there is no element ''z'' of ''P'' such that ''x'' &lt; ''z'' &lt; ''y''.
* '''[[Complete partial order|cpo]]'''. See ''complete partial order''.

== D ==

* '''dcpo'''. See ''[[directed complete partial order]]''.
* A '''[[dense order|dense]]''' poset ''P'' is one in which, for all elements ''x'' and ''y'' in ''P'' with ''x'' &lt; ''y'', there is an element ''z'' in ''P'', such that ''x'' &lt; ''z'' &lt; ''y''.  A subset ''Q'' of ''P'' is '''dense in''' ''P'' if for any elements ''x'' &lt; ''y'' in ''P'', there is an element ''z'' in ''Q'' such that ''x'' &lt; ''z'' &lt; ''y''.
* '''[[directed set|Directed]]'''. A [[non-empty]] subset ''X'' of a poset ''P'' is called directed, if, for all elements ''x'' and ''y'' of ''X'', there is an element ''z'' of ''X'' such that ''x'' ≤ ''z'' and ''y'' ≤ ''z''. The dual notion is called ''filtered''.
* '''[[Directed complete partial order]]'''. A poset ''D'' is said to be a directed complete poset, or '''dcpo''', if every directed subset of ''D'' has a supremum.
* '''[[distributivity (order theory)|Distributive]]'''. A lattice ''L'' is called distributive if, for all ''x'', ''y'', and ''z'' in ''L'', we find that ''x'' &amp;and; (''y'' &amp;or; ''z'') = (''x'' &amp;and; ''y'') &amp;or; (''x'' &amp;and; ''z''). This condition is known to be equivalent to its order dual. A meet-[[semilattice]] is distributive if for all elements ''a'', ''b'' and ''x'', ''a'' &amp;and; ''b'' ≤ ''x'' implies the existence of elements ''a' '' ≥ ''a'' and ''b' '' ≥ ''b'' such that ''a' '' &amp;and; ''b' '' = ''x''. See also ''completely distributive''.
* '''[[domain theory|Domain]]'''. Domain is a general term for objects like those that are studied in [[domain theory]]. If used, it requires further definition.
* '''Down-set'''. See ''lower set''.
* '''[[duality (order theory)|Dual]]'''. For a poset (''P'', ≤), the dual order ''P''&lt;sup&gt;''d''&lt;/sup&gt; = (''P'', ≥) is defined by setting ''x ≥ y'' [[if and only if]] ''y ≤ x''. The dual order of ''P'' is sometimes denoted by ''P''&lt;sup&gt;op&lt;/sup&gt;, and is also called ''opposite'' or ''converse'' order. Any order theoretic notion induces a dual notion, defined by applying the original statement to the order dual of a given set. This exchanges ≤ and ≥, meets and joins, zero and unit.

== E ==

* '''Extension'''.  For partial orders ≤ and ≤′ on a set ''X'', ≤′ is an extension of ≤ provided that for all elements ''x'' and ''y'' of ''X'', ''x'' ≤ ''y'' implies that ''x'' ≤′ ''y''.

== F ==

* '''[[filter (mathematics)|Filter]]'''. A subset ''X'' of a poset ''P'' is called a filter if it is a filtered upper set. The dual notion is called ''ideal''.
* '''Filtered'''. A [[non-empty]] subset ''X'' of a poset ''P'' is called filtered, if, for all elements ''x'' and ''y'' of ''X'', there is an element ''z'' of ''X'' such that ''z'' ≤ ''x'' and ''z'' ≤ ''y''. The dual notion is called ''directed''.
* '''Finite element'''. See ''compact''.
* '''[[complete Heyting algebra|Frame]]'''. A frame ''F'' is a complete lattice, in which, for every ''x'' in ''F'' and every subset ''Y'' of ''F'', the infinite distributive law ''x'' &amp;and; &lt;math&gt;\bigvee&lt;/math&gt;''Y'' = &lt;math&gt;\bigvee&lt;/math&gt;{''x'' &amp;and; ''y'' | ''y'' in ''Y''} holds. Frames are also known as ''locales'' and as complete [[Heyting algebra]]s.

== G ==

* '''[[Galois connection]]'''. Given two posets ''P'' and ''Q'', a pair of monotone functions ''F'':''P'' → ''Q'' and ''G'':''Q'' → ''P'' is called a Galois connection, if ''F''(''x'') ≤ ''y'' is equivalent to ''x'' ≤ ''G''(''y''), for all ''x'' in ''P'' and ''y'' in ''Q''. ''F'' is called the '''lower adjoint''' of ''G'' and ''G'' is called the '''upper adjoint''' of ''F''.
* '''[[Greatest element]]'''. For a subset ''X'' of a poset ''P'', an element ''a'' of ''X'' is called the greatest element of ''X'', if ''x'' ≤ ''a'' for every element ''x'' in ''X''. The dual notion is called ''least element''.
* '''Ground set'''. The ground set of a poset (''X'', ≤) is the set ''X'' on which the partial order ≤ is defined.

== H ==

* '''[[Heyting algebra]]'''. A Heyting algebra ''H'' is a bounded lattice in which the function ''f''&lt;sub&gt;''a''&lt;/sub&gt;: ''H'' → ''H'', given by ''f''&lt;sub&gt;''a''&lt;/sub&gt;(''x'') = ''a'' &amp;and; ''x'' is the lower adjoint of a [[Galois connection]], for every element ''a'' of ''H''. The upper adjoint of ''f''&lt;sub&gt;''a''&lt;/sub&gt; is then denoted by ''g''&lt;sub&gt;''a''&lt;/sub&gt;, with ''g''&lt;sub&gt;''a''&lt;/sub&gt;(''x'') = ''a'' ⇒; ''x''. Every [[Boolean algebra (structure)|Boolean algebra]] is a Heyting algebra.
* '''[[Hasse diagram]]'''. A Hasse diagram is a type of mathematical diagram used to represent a finite partially ordered set, in the form of a drawing of its [[transitive reduction]].

== I ==

* An '''[[ideal (order theory)|ideal]]''' is a subset ''X'' of a poset ''P'' that is a directed lower set. The dual notion is called ''filter''.
* The '''[[incidence algebra]]''' of a poset is the [[associative algebra]] of all scalar-valued functions on intervals, with addition and scalar multiplication defined pointwise, and multiplication defined as a certain convolution; see [[incidence algebra]] for the details.
* '''[[Infimum]]'''. For a poset ''P'' and a subset ''X'' of ''P'', the greatest element in the set of lower bounds of ''X'' (if it exists, which it may not) is called the '''infimum''', '''meet''', or '''greatest lower bound''' of ''X''. It is denoted by inf ''X'' or &lt;math&gt;\bigwedge&lt;/math&gt;''X''. The infimum of two elements may be written as inf{''x'',''y''} or ''x'' &amp;and; ''y''. If the set ''X'' is finite, one speaks of a '''finite infimum'''.  The dual notion is called ''supremum''.
* '''[[Interval (mathematics)|Interval]]'''. For two elements ''a'', ''b'' of a partially ordered set ''P'', the ''interval'' [''a'',''b''] is the subset {''x'' in ''P'' | ''a'' ≤ ''x'' ≤ ''b''} of ''P''. If ''a'' ≤ ''b'' does not hold the interval will be empty.
*&lt;span id="interval finite poset"&gt;&lt;/span&gt;'''Interval finite poset'''. A partially ordered set ''P'' is '''interval finite''' if every interval of the form {x in P | x ≤ a} is a finite set.&lt;ref&gt;{{harvnb|Deng|2008|loc=p. 22}}&lt;/ref&gt;
* '''Inverse'''.  See ''converse''.
* '''[[Irreflexive]]'''. A [[Relation (mathematics)|relation]] ''R'' on a set ''X'' is irreflexive, if there is no element ''x'' in ''X'' such that ''x R x''.
* '''Isotone'''.  See ''monotone''.

== J ==

* '''Join'''. See ''supremum''.

== L ==

* '''[[Lattice (order)|Lattice]]'''. A lattice is a poset in which all non-empty finite joins (suprema) and meets (infima) exist.
* '''[[Least element]]'''. For a subset ''X'' of a poset ''P'', an element ''a'' of ''X'' is called the least element of ''X'', if ''a'' ≤ ''x'' for every element ''x'' in ''X''. The dual notion is called ''greatest element''.
* The '''length''' of a chain is the number of elements less one.  A chain with 1 element has length 0, one with 2 elements has length 1, etc.
* '''Linear'''. See ''total order''.
* '''[[Linear extension]]'''. A linear extension of a partial order is an extension that is a linear order, or total order.
* '''[[complete Heyting algebra|Locale]]'''. A locale is a ''complete Heyting algebra''. Locales are also called ''frames'' and appear in [[Stone duality]] and [[pointless topology]].
* '''[[Locally finite poset]]'''. A partially ordered set ''P'' is ''locally finite'' if every interval [''a'', ''b''] = {''x'' in ''P'' | ''a'' ≤ ''x'' ≤ ''b''} is a finite set.
* '''[[Lower bound]]'''. A lower bound of a subset ''X'' of a poset ''P'' is an element ''b'' of ''P'', such that ''b'' ≤ ''x'', for all ''x'' in ''X''. The dual notion is called ''upper bound''.
* '''[[Lower set]]'''. A subset ''X'' of a poset ''P'' is called a lower set if, for all elements ''x'' in ''X'' and ''p'' in ''P'', ''p'' ≤ ''x'' implies that ''p'' is contained in ''X''. The dual notion is called ''upper set''.

== M ==

* '''Maximal chain'''. A [[Total order#Chains|chain]] in a poset to which no element can be added without losing the property of being totally ordered. This is stronger than being a saturated chain, as it also excludes the existence of elements either less than all elements of the chain or greater than all its elements. A finite saturated chain is maximal if and only if it contains both a minimal and a maximal element of the poset.
* '''[[Maximal element]]'''. A maximal element of a subset ''X'' of a poset ''P'' is an element ''m'' of ''X'', such that ''m'' ≤ ''x'' implies ''m'' = ''x'', for all ''x'' in ''X''. The dual notion is called ''minimal element''.
* '''[[greatest element|Maximum element]]'''. Synonym of greatest element. For a subset ''X'' of a poset ''P'', an element ''a'' of ''X'' is called the maximum element of ''X'' if ''x'' ≤ ''a'' for every element ''x'' in ''X''. A maxim''um'' element is necessarily maxim''al'', but the converse need not hold.
* '''Meet'''. See ''infimum''.
* '''[[Minimal element]]'''. A minimal element of a subset ''X'' of a poset ''P'' is an element ''m'' of ''X'', such that ''x'' ≤ ''m'' implies ''m'' = ''x'', for all ''x'' in ''X''. The dual notion is called ''maximal element''.
* '''[[least element|Minimum element]]'''. Synonym of least element. For a subset ''X'' of a poset ''P'', an element ''a'' of ''X'' is called the minimum element of ''X'' if ''x'' ≥ ''a'' for every element ''x'' in ''X''. A minim''um'' element is necessarily minim''al'', but the converse need not hold.
* '''[[monotone function|Monotone]]'''. A function ''f'' between posets ''P'' and ''Q'' is monotone if, for all elements ''x'', ''y'' of ''P'', ''x'' ≤ ''y'' (in ''P'') implies ''f''(''x'') ≤ ''f''(''y'') (in ''Q''). Other names for this property are ''isotone'' and ''order-preserving''. In [[Mathematical analysis|analysis]], in the presence of [[total order]]s, such functions are often called '''monotonically increasing''', but this is not a very convenient description when dealing with non-total orders. The dual notion is called ''antitone'' or ''order reversing''.

== O ==

* '''Order-dual'''.  The order dual of a partially ordered set is the same set with the partial order relation replaced by its converse.
* '''[[Order-embedding]]'''. A function ''f'' between posets ''P'' and ''Q'' is an order-embedding if, for all elements ''x'', ''y'' of ''P'', ''x'' ≤ ''y'' (in ''P'') is equivalent to ''f''(''x'') ≤ ''f''(''y'') (in ''Q'').
* '''[[Order isomorphism]]'''. A mapping ''f'': ''P'' → ''Q'' between two posets ''P'' and ''Q'' is called an order isomorphism, if it is [[bijective]] and both ''f'' and ''f''&lt;sup&gt;−1&lt;/sup&gt; are [[monotone function|monotone]]. Equivalently, an order isomorphism is a surjective ''order embedding''.
* '''[[Order-preserving]]'''. See ''monotone''.
* '''[[Order-reversing]]'''. See ''antitone''.

== P ==

* '''[[Partial order]]'''. A partial order is a [[binary relation]] that is [[reflexive relation|reflexive]], [[antisymmetric relation|antisymmetric]], and [[transitive relation|transitive]]. In a slight abuse of terminology, the term is sometimes also used to refer not to such a relation, but to its corresponding partially ordered set.
* [[Partially ordered set]]. A partially ordered set (''P'', ≤), or ''poset'' for short, is a set ''P'' together with a partial order ≤ on ''P''.
* '''Poset'''. A partially ordered set.
* '''[[Preorder]]'''. A preorder is a [[binary relation]] that is [[reflexive relation|reflexive]] and [[transitive relation|transitive]]. Such orders may also be called ''quasiorders''. The term ''preorder'' is also used to denote an [[#A|acyclic]] [[binary relation]] (also called an ''acyclic digraph'').
* '''[[limit-preserving function (order theory)|Preserving]]'''. A function ''f'' between posets ''P'' and ''Q'' is said to preserve suprema (joins), if, for all subsets ''X'' of ''P'' that have a supremum sup ''X'' in ''P'', we find that sup{''f''(''x''): ''x'' in ''X''} exists and is equal to ''f''(sup ''X''). Such a function is also called '''join-preserving'''. Analogously, one says that ''f'' preserves finite, non-empty, directed, or arbitrary joins (or meets). The converse property is called ''join-reflecting''.
* '''[[order ideal|Prime]]'''. An ''ideal'' ''I'' in a lattice ''L'' is said to be prime, if, for all elements ''x'' and ''y'' in ''L'', ''x'' &amp;and; ''y'' in ''I'' implies ''x'' in ''I'' or ''y'' in ''I''. The dual notion is called a ''prime filter''. Equivalently, a set is a prime filter [[if and only if]] its complement is a prime ideal.
* '''[[order ideal|Principal]]'''. A filter is called ''principal filter'' if it has a least element. Dually, a ''principal ideal'' is an ideal with a greatest element. The least or greatest elements may also be called ''principal elements'' in these situations.
* '''Projection (operator)'''. A self-map on a [[poset|partially ordered set]] that is [[monotonic function|monotone]] and [[idempotent]] under [[function composition]]. Projections play an important role in [[domain theory]].
* '''Pseudo-complement'''. In a [[Heyting algebra]], the element ''x'' ⇒; ''0'' is called the pseudo-complement of ''x''. It is also given by sup{''y'' :  ''y'' &amp;and; ''x'' = 0}, i.e. as the least upper bound of all elements ''y'' with ''y'' &amp;and; ''x'' = 0.

== Q ==

* '''Quasiorder'''. See ''preorder''.
* '''[[Quasitransitive relation|Quasitransitive]]'''.  A relation is quasitransitive if the relation on distinct elements is transitive.  Transitive implies quasitransitive and quasitransitive implies acyclic.&lt;ref name=BosSuz&gt;{{cite book | title=Consistency, choice and rationality | first1=Walter | last1=Bossert | first2=Kōtarō | last2=Suzumura | publisher=Harvard University Press | year=2010 | isbn=0674052994 }}&lt;/ref&gt;

== R ==

* '''[[limit preserving (order theory)|Reflecting]]'''. A function ''f'' between posets ''P'' and ''Q'' is said to reflect suprema (joins), if, for all subsets ''X'' of ''P'' for which the supremum sup{''f''(''x''): ''x'' in ''X''} exists and is of the form ''f''(''s'') for some ''s'' in ''P'', then we find that sup ''X'' exists and that sup ''X'' = ''s'' . Analogously, one says that ''f'' reflects finite, non-empty, directed, or arbitrary joins (or meets). The converse property is called ''join-preserving''.
* '''[[reflexive relation|Reflexive]]'''. A [[binary relation]] ''R'' on a set ''X'' is reflexive, if ''x R x'' holds for every element ''x'' in ''X''.
* '''Residual'''.  A dual map attached to a [[residuated mapping]].
* '''[[Residuated mapping]]'''.  A monotone map for which the preimage of a principal down-set is again principal.  Equivalently, one component of a Galois connection.

== S ==

* '''Saturated chain'''. A [[Total order#Chains|chain]] such that no element can be added ''between two of its elements'' without losing the property of being totally ordered. If the chain is finite, this means that in every pair of successive elements the larger one covers the smaller one. See also maximal chain.
* '''[[scattered order|Scattered]]'''. A total order is scattered if it has no densely ordered subset.
* '''[[Scott-continuous]]'''. A monotone function ''f'' : ''P'' → ''Q'' between posets ''P'' and ''Q'' is Scott-continuous if, for every directed set ''D'' that has a supremum sup ''D'' in ''P'', the set {''fx'' | ''x'' in ''D''} has the supremum ''f''(sup ''D'') in ''Q''. Stated differently, a Scott-continuous function is one that [[limit preserving function (order theory)|preserves]] all directed suprema. This is in fact equivalent to being [[continuity (topology)|continuous]] with respect to the [[Scott topology]] on the respective posets.
* '''[[Scott domain]]'''. A Scott domain is a partially ordered set which is a [[bounded complete]] [[algebraic poset|algebraic]] [[complete partial order|cpo]].
* '''Scott open'''. See ''Scott topology''.
* '''Scott topology'''. For a poset ''P'', a subset ''O'' is '''Scott-open''' if it is an [[upper set]] and all directed sets ''D'' that have a supremum in ''O'' have non-empty intersection with ''O''. The set of all Scott-open sets forms a [[topology]], the '''Scott topology'''.
* '''[[Semilattice]]'''. A semilattice is a poset in which either all finite non-empty joins (suprema) or all finite non-empty meets (infima) exist. Accordingly, one speaks of a '''join-semilattice''' or '''meet-semilattice'''.
* '''Smallest element'''. See ''least element''.
* [[Sperner property of a partially ordered set]]
* [[Sperner poset]]
* [[Strictly Sperner poset]]
* [[Strongly Sperner poset]]
* '''[[Strict order]]'''. A strict order is a [[binary relation]] that is [[antisymmetric relation|antisymmetric]], [[transitive relation|transitive]], and [[irreflexive]].
* '''[[Supremum]]'''. For a poset ''P'' and a subset ''X'' of ''P'', the [[least element]] in the set of [[upper bound]]s of ''X'' (if it exists, which it may not) is called the '''supremum''', '''join''', or '''least upper bound''' of ''X''. It is denoted by sup ''X'' or &lt;math&gt;\bigvee&lt;/math&gt;''X''. The supremum of two elements may be written as sup{''x'',''y''} or ''x'' &amp;or; ''y''. If the set ''X'' is finite, one speaks of a '''finite supremum'''. The dual notion is called ''infimum''.
* '''Suzumura consistency'''.  A binary relation R is Suzumura consistent if ''x'' R&lt;sup&gt;&amp;lowast;&lt;/sup&gt; ''y'' implies that ''x'' R ''y'' or not ''y'' R ''x''.&lt;ref name=BosSuz/&gt;
* '''[[Symmetric relation|Symmetric]]'''. A [[Relation (mathematics)|relation]] ''R'' on a set ''X'' is symmetric, if ''x R y'' implies ''y R x'', for all elements ''x'', ''y'' in ''X''.

== T ==

* '''Top'''. See ''unit''.
* '''[[Total order]]'''. A total order ''T'' is a partial order in which, for each ''x'' and ''y'' in ''T'', we have ''x'' ≤ ''y'' or ''y'' ≤ ''x''. Total orders are also called ''linear orders'' or ''chains''.
* '''[[Total relation]]'''.  A total or complete relation ''R'' on a set ''X'' has the property that for all elements ''x'', ''y'' of ''X'', at least one of ''x R y'' or ''y R x'' holds.
* '''[[transitive relation|Transitive]]'''. A [[Relation (mathematics)|relation]] ''R'' on a set ''X'' is transitive, if ''x R y'' and ''y R z'' imply ''x R z'', for all elements ''x'', ''y'', ''z'' in ''X''.
* '''[[Transitive closure]]'''.  The transitive closure R&lt;sup&gt;&amp;lowast;&lt;/sup&gt; of a relation R consists of all pairs ''x'',''y'' for which there cists a finite chain ''x'' R ''a'', ''a'' R ''b'', ..., ''z'' R ''y''.&lt;ref name=BosSuz/&gt;

== U ==

* '''Unit'''. The [[greatest element]] of a poset ''P'' can be called ''unit'' or just ''1'' (if it exists). Another common term for this element is '''top'''. It is the infimum of the empty set and the supremum of ''P''. The dual notion is called ''zero''.
* '''Up-set'''. See ''upper set''.
* '''[[Upper bound]]'''. An upper bound of a subset ''X'' of a poset ''P'' is an element ''b'' of ''P'', such that ''x'' ≤ ''b'', for all ''x'' in ''X''. The dual notion is called ''lower bound''.
* '''[[Upper set]]'''. A subset ''X'' of a poset ''P'' is called an upper set if, for all elements ''x'' in ''X'' and ''p'' in ''P'', ''x'' ≤ ''p'' implies that ''p'' is contained in ''X''. The dual notion is called ''lower set''.

== V ==

* '''Valuation'''.  Given a lattice &lt;math&gt;X&lt;/math&gt;, a valuation &lt;math&gt;\nu : X \to [0,1]&lt;/math&gt; is strict (i.e., &lt;math&gt;\nu(\emptyset)=0&lt;/math&gt;), monotone, modular (i.e., &lt;math&gt;\nu(U) + \nu(V) = \nu(U \cup V) + \nu(U \cap V)&lt;/math&gt;) and positive.  Continuous valuations are a generalization of measures.

== W ==

* '''[[Way-below relation]]'''. In a poset ''P'', some element ''x'' is ''way below'' ''y'', written ''x''&lt;&lt;''y'', if for all directed subsets ''D'' of ''P'' which have a supremum, ''y'' ≤ ''sup D'' implies ''x'' ≤ ''d'' for some ''d'' in ''D''. One also says that ''x'' '''approximates''' ''y''. See also [[domain theory]].
* '''[[Weak order]]'''.  A partial order ≤ on a set ''X'' is a weak order provided that the poset (X, ≤) is [[isomorphic]] to a countable collection of sets ordered by comparison of [[cardinality]].

== Z ==

* '''Zero'''. The [[least element]] of a poset ''P'' can be called ''zero'' or just ''0'' (if it exists). Another common term for this element is '''bottom'''. Zero is the supremum of the empty set and the infimum of ''P''. The dual notion is called ''unit''.

==Notes==
{{reflist}}

==References==

The definitions given here are consistent with those that can be found in the following standard reference books:

* B. A. Davey and H. A. Priestley, ''Introduction to Lattices and Order'', 2nd Edition, Cambridge University Press, 2002.
* G. Gierz, K. H. Hofmann, K. Keimel, J. D. Lawson, M. Mislove and D. S. Scott, ''Continuous Lattices and Domains'', In ''Encyclopedia of Mathematics and its Applications'', Vol. 93, Cambridge University Press, 2003.

Specific definitions:

*{{Citation
| last=Deng
| first=Bangming
| title=Finite dimensional algebras and quantum groups
| year=2008
| publisher=American Mathematical Society
| isbn=978-0-8218-4186-0
| series=Mathematical surveys and monographs
| volume=150
}}

[[Category:Glossaries of mathematics|Order theory]]
[[Category:Order theory| ]]</text>
      <sha1>dywnvwstnvg6nh6hfqhmx6fejfent3e</sha1>
    </revision>
  </page>
  <page>
    <title>Hardy–Littlewood inequality</title>
    <ns>0</ns>
    <id>36704617</id>
    <revision>
      <id>790709791</id>
      <parentid>644337875</parentid>
      <timestamp>2017-07-15T15:43:15Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Proof */LaTeX spacing clean up, replaced: \, &lt;/math&gt; → &lt;/math&gt; (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2653">In [[mathematical analysis]], the '''Hardy–Littlewood inequality''', named after [[G. H. Hardy]] and [[John Edensor Littlewood]], states that if ''f'' and ''g'' are nonnegative [[measurable function|measurable]] [[real functions]] vanishing at [[infinity]] that are defined on ''n''-[[dimension]]al [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt; then

:&lt;math&gt;\int_{\mathbb{R}^n} f(x)g(x) \, dx \leq \int_{\mathbb{R}^n} f^*(x)g^*(x) \, dx&lt;/math&gt;

where  ''f''&lt;sup&gt;*&lt;/sup&gt; and ''g''&lt;sup&gt;*&lt;/sup&gt; are the [[symmetric decreasing rearrangement]]s of ''f''(''x'') and ''g''(''x''), respectively.&lt;ref name=liebloss&gt;{{cite book|last1=Lieb|first1=Elliott|authorlink1=Elliott H. Lieb|last2=Loss|first2=Michael|author2-link=Michael Loss|title=Analysis|year=2001|edition=2nd|publisher=[[American Mathematical Society]]|series=Graduate Studies in Mathematics|volume=14|isbn=978-0821827833}}
&lt;/ref&gt;&lt;ref name=burchard&gt;{{cite book|title=A Short Course on Rearrangement Inequalities|first=Almut|last=Burchard|url=http://www.math.toronto.edu/almut/rearrange.pdf}}&lt;/ref&gt;

==Proof==
From [[layer cake representation]] we have:&lt;ref name=liebloss/&gt;&lt;ref name=burchard/&gt;
:&lt;math&gt;f(x)= \int_0^\infty \chi_{f(x)&gt;r} \, dr&lt;/math&gt;
:&lt;math&gt;g(x)= \int_0^\infty \chi_{g(x)&gt;s} \, ds&lt;/math&gt;

where &lt;math&gt;\chi_{f(x)&gt;r}&lt;/math&gt; denotes the [[indicator function]] of the subset ''E''&lt;sub&gt; ''f''&lt;/sub&gt; given by

:&lt;math&gt;E_f=\left\{x\in X: f(x)&gt;r\right\} &lt;/math&gt;

Analogously, &lt;math&gt;\chi_{g(x)&gt;s}&lt;/math&gt; denotes the indicator function of the subset ''E''&lt;sub&gt; ''g''&lt;/sub&gt; given by

:&lt;math&gt;E_g=\left\{x\in X: g(x)&gt;s\right\} &lt;/math&gt;

:&lt;math&gt;
\int_{\mathbb{R}^n} f(x)g(x) \, dx = \displaystyle\int_{\mathbb{R}^n}\int_0^\infty \int_0^\infty \chi_{f(x)&gt;r}\chi_{g(x)&gt;s} \, dr \, ds \, dx &lt;/math&gt;
:::&lt;math&gt;= \int_0^\infty \int_0^\infty \int_{\mathbb{R}^n}\chi_{f(x)&gt;r\cap g(x)&gt;s} \, dx \, dr \, ds &lt;/math&gt;
:::&lt;math&gt;= \int_0^\infty \int_0^\infty \mu\left(\left\{f(x)&gt;r\right\}\cap\left\{ g(x)&gt;s\right\}\right) \, dr \, ds&lt;/math&gt;
:::&lt;math&gt;\leq \int_0^\infty \int_0^\infty \min\left(\mu\left(f(x)&gt;r\right);\mu\left(g(x)&gt;s\right)\right) \, dr \, ds&lt;/math&gt;
:::&lt;math&gt;= \int_0^\infty \int_0^\infty \min\left(\mu\left(f^*(x)&gt;r\right);\mu\left(g^*(x)&gt;s\right)\right) \, dr \, ds&lt;/math&gt;
:::&lt;math&gt;= \int_0^\infty \int_0^\infty \mu\left(\left\{f^\ast(x)&gt;r\right\}\cap\left\{ g^\ast(x)&gt;s\right\}\right) \, dr \, ds&lt;/math&gt;
:::&lt;math&gt;= \int_{\mathbb{R}^n} f^*(x)g^*(x) \, dx &lt;/math&gt;

==See also==
* [[Rearrangement inequality]]
* [[Chebyshev's sum inequality]]
* [[Lorentz space]]

==References==
&lt;references/&gt;

{{DEFAULTSORT:Hardy-Littlewood inequality}}
[[Category:Inequalities]]
[[Category:Articles containing proofs]]</text>
      <sha1>9gmihlzh7c2rouwgv9rf7tgk5wgqh6l</sha1>
    </revision>
  </page>
  <page>
    <title>IEEE 854-1987</title>
    <ns>0</ns>
    <id>3253502</id>
    <revision>
      <id>854926316</id>
      <parentid>722454982</parentid>
      <timestamp>2018-08-14T19:00:19Z</timestamp>
      <contributor>
        <username>Filipović Zoran</username>
        <id>20294490</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1496">{{use dmy dates|date=March 2012}}
'''IEEE Std 854-1987''', the ''Standard for Radix-Independent Floating-Point Arithmetic'', was the first [[Institute of Electrical and Electronics Engineers]] (IEEE) [[international standard|standard]] for [[floating-point arithmetic]] with [[radix]] 2 or radix 10 (not more general than that, despite the title).

The standard was published in 1987, nearly immediately superseded by [[IEEE 754-1985]] but never terminated (the year of ratification appears after the dash).&lt;ref&gt;{{Cite book |title= 854-1987: IEEE Standard for Radix-Independent Floating-Point Arithmetic |year= 1987 |isbn= 0-7381-1167-8 |publisher= IEEE Standards Association |doi= 10.1109/IEEESTD.1987.81037 }}&lt;/ref&gt; IEEE 854 did not specify any formats, whereas IEEE 754-1985 did. IEEE 754 specifies floating-point arithmetic for both radix 2 ([[binary numeral system|binary]]) and radix 10 ([[decimal]]), including specifying two alternative formats for radix 10 floating-point values. IEEE 754-1985 was only superseded in 2008 by [[IEEE 754-2008]].&lt;ref&gt;{{Cite web |title= IEEE 754: Standard for Binary Floating-Point Arithmetic |work= Working group web site |url= http://grouper.ieee.org/groups/754/ |accessdate=21 September 2011 }}&lt;/ref&gt; IEEE 754-2008 also has many other updates to the IEEE floating point standardisation.

==References==
{{Reflist}}

{{IEEE standards}}

{{DEFAULTSORT:Ieee 854-1987}}
[[Category:Computer arithmetic]]
[[Category:IEEE standards]]
[[Category:Floating point]]</text>
      <sha1>k1bfeejexox5kjkdogctqvnsixjwvdd</sha1>
    </revision>
  </page>
  <page>
    <title>Invertible module</title>
    <ns>0</ns>
    <id>22352470</id>
    <revision>
      <id>788973454</id>
      <parentid>700440999</parentid>
      <timestamp>2017-07-04T15:35:43Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic_links|magic links]] with templates per [[Special:PermaLink/772743896#Future_of_magic_links|local RfC]] - [[User:PrimeBOT/13|BRFA]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1276">In [[mathematics]], particularly [[commutative algebra]], an '''invertible module''' is intuitively a [[module (mathematics)|module]] that has an [[inverse element|inverse]] with respect to the [[tensor product]]. Invertible modules form the foundation for the definition of [[invertible sheaf|invertible sheaves]] in [[algebraic geometry]].

Formally, a [[finitely generated module]] ''M'' over a ring ''R'' is said to be invertible if it is locally a [[free module]] of [[rank of a free module|rank]] 1. In other words, &lt;math&gt; M_P\cong R_P &lt;/math&gt; for all [[prime element|primes]] ''P'' of ''R''. Now, if ''M'' is an invertible ''R''-module, then its [[Duality (mathematics)#Dual objects|dual]] {{nowrap|''M''&lt;sup&gt;*&lt;/sup&gt; {{=}} Hom(''M'',''R'')}} is its inverse with respect to the tensor product, i.e. &lt;math&gt;M\otimes _R M^*\cong R&lt;/math&gt;.

The theory of invertible modules is closely related to the theory of [[codimension]] one [[algebraic variety|varieties]] including the theory of [[divisor (algebraic geometry)|divisor]]s.

==See also==
* [[Picard group]]

==References==
* [[David Eisenbud|Eisenbud, David]], ''Commutative Algebra with a View Toward Algebraic Geometry'', Springer, {{ISBN|978-0-387-94269-8}}

[[Category:Mathematical structures]]
[[Category:Algebra]]</text>
      <sha1>9w9tuhwndhdm50o6fhxe5bjbn3h4k96</sha1>
    </revision>
  </page>
  <page>
    <title>Karen Willcox</title>
    <ns>0</ns>
    <id>58573060</id>
    <revision>
      <id>871295011</id>
      <parentid>862521680</parentid>
      <timestamp>2018-11-30T03:09:44Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>add category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7397">{{Infobox scientist
| name = Karen Elizabeth Willcox
| birth_place = [[Auckland|Auckland, New Zealand]]
| nationality = [[New Zealand]]
| fields = [[Applied mathematics]], [[aerospace engineering]]
| workplaces = [[Massachusetts Institute of Technology]]
[[University of Texas at Austin]]
| alma_mater = [[University of Auckland]], New Zealand
[[Massachusetts Institute of Technology]], Massachusetts
| thesis_title = Reduced-Order Aerodynamic Models for Aeroelastic Control of Turbomachines
| thesis_year = 2000
| doctoral_advisor = [[Jaime Peraire]]
James Paduano
| known_for = [[Model order reduction|Reduced-order modeling]], [[Multifidelity simulation|multi-fidelity methods]]
}}
'''Karen Elizabeth Willcox''' {{post-nominals|country=NZL|MNZM}} is an [[applied mathematician]] best known for her work on [[Model order reduction|reduced-order modeling]] and the study of [[Multifidelity simulation|multi-fidelity methods]]. She is currently the director of the [[Institute for Computational Engineering and Sciences]] and professor of Aerospace Engineering and Engineering Mechanics at the [[University of Texas at Austin]], Texas.&lt;ref&gt;{{Cite news|url=https://www.ices.utexas.edu/people/1617/|title=Institute for Computational Engineering and Sciences {{!}} University of Texas at Austin|work=ICES|access-date=2018-09-25|language=en-us}}&lt;/ref&gt;

== Personal life and education ==
Willcox was born and raised in New Zealand where she earned a bachelor's degree in Engineering Science from the [[University of Auckland]] in the year 1994.&lt;ref name=":0"&gt;{{Cite web|url=http://kiwi.ices.utexas.edu/papers/Willcox-resume.pdf|title=Curriculum Vitate|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; She subsequently moved to [[Boston|Boston, Massachusetts]] to join the [[Massachusetts Institute of Technology]] (MIT) for graduate studies. At MIT, she received a master's degree in Aeronautics and Astronautics in 1996 and a PhD in the same subject in the year 2000.&lt;ref name=":0" /&gt; Her thesis, titled 'Reduced-Order Aerodynamic Models for Aeroelastic Control of Turbomachines', was completed under the supervision of [[Jaime Peraire]] and James Paduano.&lt;ref&gt;{{Cite web|url=https://acdl.mit.edu/Willcox_thesis.pdf|title=Thesis|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; While at MIT, Willcox played for the MIT Women's Rugby team.&lt;ref name=":1"&gt;{{Cite web|url=https://infinitehistory.mit.edu/video/karen-e-willcox-sm-96-phd-00|title=Karen E. Willcox SM '96, PhD '00 {{!}} MIT Infinite History|website=infinitehistory.mit.edu|language=en|access-date=2018-09-25}}&lt;/ref&gt; She is also an avid marathon-runner and an experienced mountain climber.&lt;ref&gt;{{Cite web|url=https://sirpeterblaketrust.org/posts/2018/3/23/karen-willcox-dt|title=Sir Peter Blake Trust|website=sirpeterblaketrust.org|language=en|access-date=2018-09-25}}&lt;/ref&gt;

Willcox had long wanted to be an astronaut.&lt;ref name=":1" /&gt; She made the shortlist of candidates for NASA's astronaut training program in 2009&lt;ref&gt;{{Cite web|url=https://www.stuff.co.nz/national/2539011/Kiwi-misses-out-on-Nasa-space-training|title=Kiwi misses out on Nasa space training|website=Stuff|language=en|access-date=2018-09-25}}&lt;/ref&gt; and 2013, but both attempts remained unsuccessful.

== Career ==
Following her doctoral studies, Willcox worked at [[Boeing Phantom Works]] in the Blended-Wing-Body aircraft design group for a year. In 2001, she joined the Department of Aeronautics and Astronautics at MIT as a professor. In 2008, She additionally became a founding co-director of the MIT Center for Computational Engineering. She stayed at MIT until July 2018. During this period, she also had short-term visiting appointments at [[Sandia National Laboratories]], the University of Auckland and [[Singapore University of Technology and Design]]. In August 2018, Willcox joined the University of Texas at Austin to succeed [[J. Tinsley Oden]] as the director of the Institute for Computational Engineering and Sciences.&lt;ref&gt;{{Cite news|url=https://news.utexas.edu/2018/04/10/new-director-of-no-1-ranked-computational-institute|title=UT Hires Next Director of No. 1 Ranked Computational Institute|date=2018-04-10|work=UT News {{!}} The University of Texas at Austin|access-date=2018-09-25|language=en}}&lt;/ref&gt;

Willcox has served on the editorial board of several journals; she is currently a Section editor for the [[SIAM Journal on Scientific Computing]]&lt;ref&gt;{{Cite web|url=https://www.siam.org/Publications/Journals/SIAM-journal-on-scientific-computing-sisc/editorial-board|title=SISC {{!}} Editorial Board {{!}} SIAM|website=www.siam.org|language=en-US|access-date=2018-09-25}}&lt;/ref&gt; and an Associate editor for the [[AIAA Journal]].&lt;ref&gt;{{Cite web|url=https://arc.aiaa.org/page/aiaaj/masthead|title=AIAA Journal|website=arc.aiaa.org|language=en-US|access-date=2018-09-25}}&lt;/ref&gt;

In addition to research, Willcox is involved in science education and policy as well. An advocate for innovation in teaching, she served as co-chair of the Online Education Policy Initiative at MIT.&lt;ref&gt;{{Cite news|url=http://news.mit.edu/2015/mit-creates-new-online-education-policy-initiative-0414|title=MIT creates new Online Education Policy Initiative|work=MIT News|access-date=2018-09-25}}&lt;/ref&gt; In 2015, she received a First in the World grant from the [[United States Department of Education|US Department of Education]].&lt;ref&gt;{{Cite web|url=https://www.ed.gov/news/press-releases/department-awards-60-million-first-world-grants-17-colleges-universities-and-organizations|title=Department Awards $60 Million in First in the World Grants to 18 Colleges, Universities and Organizations {{!}} U.S. Department of Education|website=www.ed.gov|language=en|access-date=2018-09-25}}&lt;/ref&gt;

==Recognition==
Willcox became a Member of the [[New Zealand Order of Merit]] in 2017.&lt;ref&gt;{{citation|url=https://www.dpmc.govt.nz/queens-birthday-honours-2017-citations-for-members-of-the-new-zealand-order-of-merit|title=Queen's Birthday Honours 2017 – Citations for members of the New Zealand Order of Merit|publisher=New Zealand Department of the Prime Minister and Cabinet|accessdate=2018-10-01}}&lt;/ref&gt;
She was elected as a fellow of the [[Society for Industrial and Applied Mathematics]] in 2018, "for contributions to model reduction and multifidelity methods, with applications in optimization, control, design, and uncertainty quantification of large-scale systems".&lt;ref&gt;{{citation|url=https://sinews.siam.org/Details-Page/siam-announces-class-of-2018-fellows|journal=SIAM News|date=March 29, 2018|title=SIAM Announces Class of 2018 Fellows|accessdate=2018-10-01}}&lt;/ref&gt;

== External links ==

# [http://kiwi.ices.utexas.edu/ Personal website]
# [https://scholar.google.com/citations?user=axvGyXoAAAAJ&amp;hl=en&amp;oi=ao Google Scholar profile]

== References ==
{{Reflist}}

{{DEFAULTSORT:Willcox, Karen}}
[[Category:Living people]]
[[Category:Applied mathematicians]]
[[Category:Women mathematicians]]
[[Category:Aerospace engineers]]
[[Category:Women engineers]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Massachusetts Institute of Technology faculty]]
[[Category:University of Texas at Austin faculty]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]
[[Category:Members of the New Zealand Order of Merit]]
[[Category:21st-century women engineers]]</text>
      <sha1>kbtb6nhcmvgcd2993zhxyjvr3j6lveh</sha1>
    </revision>
  </page>
  <page>
    <title>Kish grid</title>
    <ns>0</ns>
    <id>26066467</id>
    <revision>
      <id>677383956</id>
      <parentid>675534027</parentid>
      <timestamp>2015-08-22T22:16:42Z</timestamp>
      <contributor>
        <username>Hubon</username>
        <id>26039353</id>
      </contributor>
      <comment>that should be the term used by Kish himself, cf. e.g. Kish (1965), p. 399</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2400">{{More footnotes|date=January 2013}}
The '''Kish grid''' or '''Kish selection grid''' is a method for selecting members within a [[household]] to be [[interview]]ed.  It uses a pre-assigned table of random numbers to find the person to be interviewed.  It was developed by statistician [[Leslie Kish]] in 1949.&lt;ref&gt;{{Citation |last1=Laurie |first1=Heather |editor1-last=Lewis-Beck |editor1-first=Michael S. |editor2-last=Bryman |editor2-first=Alan |editor3-last=Futing Liao |editor3-first=Tim |title=Kish Grid |doi=10.4135/9781412950589 |work=Encyclopedia of Social Science Research Methods |year=2004 |isbn=978-0-7619-2363-3 |url=http://srmo.sagepub.com/view/the-sage-encyclopedia-of-social-science-research-methods/n464.xml}}&lt;/ref&gt;

It is a technique widely used in [[survey research]].&lt;ref&gt;{{cite encyclopedia |url=http://www.encyclopedia.com/doc/1O88-Kishgrid.html |last1=Marshall |first1=Gordan |title=Kish grid |encyclopedia=A Dictionary of Sociology |year=1998 |accessdate=March 26, 2013 |publisher=Encyclopedia.com}}&lt;/ref&gt; However, in telephone surveys, the [[next-birthday method]] is sometimes preferred to the Kish grid.

== References ==
===Notes===
{{reflist}}
===Sources===
*{{Citation
 | last = Kish
 | first = Leslie
 | title = A Procedure for Objective Respondent Selection within the Household
 | journal = Journal of the American Statistical Association
 | volume = 44
 | issue = 247
 | pages = 380–387
 |date=September 1949
 | jstor = 2280236
 | doi = 10.1080/01621459.1949.10483314
}}

*{{Citation
 | last = McBurney
 | first = Peter
 | title = On Transferring Statistical Techniques Across Cultures: The Kish Grid
 | journal = Current Anthropology
 | volume = 29
 | issue = 2
 | pages = 323–325
 |date=April 1988
 | jstor = 2743408
 | doi = 10.1086/203642
}}

*{{Citation
 |last1 = Salmon
 |first1 = Charles T.
 |last2 = Nichols
 |first2 = John Spicer
 |title = The Next-Birthday Method for Respondent Selection
 |journal = Public Opinion Quarterly
 |year = 1983
 |volume = 47
 |issue = 2
 |pages = 270–276
 |jstor = 2749026
 |doi = 10.1086/268785
}}

*{{Citation
 | last = Gaziano
 | first = Cecilie
 | title = Comparative Analysis of Within-Household Respondent Selection Techniques
 | journal = Public Opinion Quarterly
 | volume = 69
 | issue = 1
 | pages = 124–157
 | year = 2005
 | doi = 10.1093/poq/nfi006
}}

[[Category:Sampling techniques]]

{{statistics-stub}}</text>
      <sha1>mehl2us536tmjatjgb9em4nj4sczlbr</sha1>
    </revision>
  </page>
  <page>
    <title>List of long mathematical proofs</title>
    <ns>0</ns>
    <id>33074893</id>
    <revision>
      <id>865481885</id>
      <parentid>862218922</parentid>
      <timestamp>2018-10-24T06:54:47Z</timestamp>
      <contributor>
        <username>TheSpanishEdition</username>
        <id>34962990</id>
      </contributor>
      <comment>Mochizuki's papers on "IUT" is not a "proof" of a single notable result</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10605">This is a list of unusually long [[mathematical proof]]s.

{{as of|2011}}, the longest mathematical proof, measured by number of published journal pages, is the [[classification of finite simple groups]] with well over 10000 pages. There are several proofs that would be far longer than this if the details of the computer calculations they depend on were published in full.

==Long proofs==
The length of unusually long proofs has increased with time. As a rough rule of thumb, 100 pages in 1900, or 200 pages in 1950, or 500 pages in 2000 is unusually long for a proof.

*1799 The [[Abel–Ruffini theorem]] was nearly proved by [[Paolo Ruffini]], but his proof, spanning 500 pages, was mostly ignored and later, in 1824, [[Niels Henrik Abel]] published a proof that required just six pages
*1890 Killing's classification of simple complex Lie algebras, including his discovery of the [[exceptional Lie algebra]]s, took 180 pages in 4 papers.
*1894 The ruler-and-compass construction of a [[constructible polygon|polygon of 65537 sides]] by [[Johann Gustav Hermes]] took over 200 pages.
*1905 [[Emanuel Lasker]]'s original proof of the [[Lasker–Noether theorem]] took 98 pages, but has since been simplified: modern proofs are less than a page long.
*1963 [[Odd order theorem]] by Feit and Thompson was 255 pages long, which at the time was over 10 times as long as what had previously been considered a long paper in group theory.
*1964 [[Resolution of singularities]] Hironaka's original proof was 216 pages long; it has since been simplified considerably down to about 10 or 20 pages.
*1966 Abyhankar's proof of [[resolution of singularities]] for 3-folds in characteristic greater than 6 covered about 500 pages in several papers. (In 2009 Cutkosky simplified this to about 40 pages.)
*1966 [[Discrete series representation]]s of Lie groups. Harish-Chandra's construction of these involved a long series of papers totaling around 500 pages. His later work on the Plancherel theorem for semisimple groups added another 150 pages to these.
*1968 the [[Pyotr Novikov|Novikov]]-[[Sergei Adian|Adian]] proof solving [[Burnside's problem]] on finitely generated infinite groups with finite exponents negatively. The three-part original paper is more than 300 pages long. (Britton later published a 282 page paper attempting to solve the problem, but his paper contained a serious gap.)
*1960–1970 [[Fondements de la Géometrie Algébrique]], [[Éléments de géométrie algébrique]] and [[Séminaire de géométrie algébrique]]. Grothendieck's work on the foundations of algebraic geometry covers many thousands of pages. Although this is not a proof of a single theorem, there are several theorems in it whose proofs depend on hundreds of earlier pages.
*1974 [[N-group theorem]] Thompson's classification of N-groups used 6 papers totaling about 400 pages, but also used earlier results of his such as the [[odd order theorem]], which bring to total length up to more than 700 pages.
*1974 [[Ramanujan conjecture]] and the [[Weil conjectures]]. While Deligne's final paper proving these was "only" about 30 pages long, it depended on background results in algebraic geometry and [[étale cohomology]] that Deligne estimated to be about 2000 pages long.
*1974 [[4-color theorem]]. Appel and Haken's proof of this took 139 pages, and also depended on long computer calculations.
*1974 The [[Gorenstein–Harada theorem]] classifying finite groups of sectional 2-rank at most 4 was 464 pages long.
*1976 [[Eisenstein series]] Langlands's proof of the functional equation for Eisenstein series was 337 pages long.
*1983 [[Trichotomy theorem]] Gorenstein and Lyons's proof for the case of rank at least 4 was 731 pages long, and Aschbacher's proof of the rank 3 case adds another 159 pages, for a total of 890 pages.
*1983 [[Selberg trace formula]] Hejhal's proof of a general form of the Selberg trace formula consisted of 2 volumes with a total length of 1322 pages.
*[[Arthur–Selberg trace formula]]. Arthur's proofs of the various versions of this cover several hundred pages spread over many papers.
*2000 [[Almgren's regularity theorem]] Almgren's proof  was 955 pages long.
*2000 [[Lafforgue's theorem]] on the Langlands conjecture for the general linear group over function fields. [[Laurent Lafforgue]]'s proof of this  was about 600 pages long, not counting many pages of background results.
*2003 [[Poincaré conjecture]], [[Geometrization conjecture|Geometrization theorem]], [[Geometrization conjecture]]. Perelman's original proofs of the Poincaré conjecture and the Geometrization conjecture were not lengthy, but were rather sketchy. Several other mathematicians have published proofs with the details filled in, which come to several hundred pages.
*2004 [[Quasithin group]]s The classification of the simple quasithin groups by Aschbacher and Smith was 1221 pages long, one of the longest single papers ever written.
*2004 [[Classification of finite simple groups]]. The proof of this is spread out over hundreds of journal articles which makes it hard to estimate its total length, which is probably around 10000 to 20000 pages.
*2004 [[Robertson–Seymour theorem]]. The proof takes about 500 pages spread over about 20 papers.
*2005 [[Kepler conjecture]] [[Thomas Callister Hales|Hales]]'s proof of this involves several hundred pages of published arguments, together with several gigabytes of computer calculations.
*2006 the [[strong perfect graph theorem]], by [[Maria Chudnovsky]],  [[Neil Robertson (mathematician)|Neil Robertson]], [[Paul Seymour (mathematician)|Paul Seymour]], and Robin Thomas. 180 pages in the [[Annals of Mathematics]].

==Long computer calculations==

There are many mathematical theorems that have been checked by  long computer calculations. If these were written out as proofs many would be far longer than most of the proofs above. There is not really a clear distinction between computer calculations and proofs, as several of the proofs above, such as the 4-color theorem and the Kepler conjecture, use long computer calculations as well as many pages of mathematical argument. For the computer calculations in this section, the mathematical arguments are only a few pages long, and the length is due to long but routine calculations.  Some typical examples of such theorems include:

*Several proofs of the existence of [[sporadic simple groups]], such as the [[Lyons group]],  originally used computer calculations with large matrices or with permutations on billions of symbols. In most cases, such as the [[baby monster group]], the computer proofs were later replaced by shorter proofs avoiding computer calculations. Similarly the calculation of the maximal subgroups of the larger sporadic groups uses a lot of computer calculations.
*2004 Verification of the [[Riemann hypothesis]] for the first 10&lt;sup&gt;13&lt;/sup&gt; zeros of the [[Riemann zeta function]].
*2007 Verification that [[Checkers]] is a draw.
*2008 Proofs that various [[Mersenne numbers]] with around ten million digits are prime.
*Calculations of large numbers of digits of π.
*2010 Showing that [[Rubik's Cube]] [[Optimal solutions for Rubik's Cube|can be solved in 20 moves]].
*2012 Showing that  Sudoku needs [https://arxiv.org/abs/1201.0749 at least 17 clues] .
*2013 [[Ternary Goldbach conjecture]]: Every odd number greater than 5 can be expressed as the sum of three primes. 
*2014 Proof of [[Paul Erdős|Erdős]] [[±1-sequence|discrepancy conjecture]] for particular case C=2: every [[±1-sequence]] of the length 1161 has a discrepancy at least 3, original  proof generated by a SAT solver  had a size of  13 gigabytes, it has been reduced later to 850 megabytes.
*2016 Solving [[boolean Pythagorean triples problem]] required generation of 200 terabytes of proof.&lt;ref&gt;http://www.nature.com/news/two-hundred-terabyte-maths-proof-is-largest-ever-1.19990&lt;/ref&gt;
*2017 Heule, who coauthored solution to the boolean Pythagorean triples problem, announced 2 petabytes long proof that 5th [[Schur's theorem|Schur's number]] is 160.&lt;ref&gt;Heule, Marijn JH. "Schur Number Five." ''arXiv preprint arXiv:1711.08076'' (2017).&lt;/ref&gt;

==Long proofs in mathematical logic==
{{main|Gödel's speed-up theorem}}
[[Kurt Gödel]] showed how to find explicit examples of statements in formal systems that are provable in that system but whose shortest proof is absurdly long. For example, the statement:
:"This statement cannot be proved in Peano arithmetic in less than a googolplex symbols"
is provable in Peano arithmetic but the shortest proof has at least a googolplex symbols. It has a short proof in a more powerful system: in fact it is easily provable in Peano arithmetic together with the statement that Peano arithmetic is consistent (which cannot be proved in Peano arithmetic by [[Gödel's incompleteness theorem]]).

In this argument, Peano arithmetic can be replaced by any more powerful consistent system, and a googolplex can be replaced by any number that can be described concisely in the system.

[[Harvey Friedman]] found some explicit natural examples of this phenomenon, giving some explicit statements in Peano arithmetic and other formal systems  whose shortest proofs  are ridiculously long {{harv|Smoryński|1982}}. For example, the statement
:"there is an integer ''n'' such that if there is a sequence of rooted trees ''T''&lt;sub&gt;1&lt;/sub&gt;, ''T''&lt;sub&gt;2&lt;/sub&gt;, ..., ''T''&lt;sub&gt;''n''&lt;/sub&gt; such that ''T''&lt;sub&gt;''k''&lt;/sub&gt; has at most ''k''+10 vertices, then some tree can be homeomorphically [[Graph embedding|embedded]] in a later one"
is provable in Peano arithmetic, but the shortest proof has length at least ''A''(1000), where ''A''(0)=1 and ''A''(''n''+1)=2&lt;sup&gt;''A''(''n'')&lt;/sup&gt;. The statement is a special case of [[Kruskal's theorem]] and has a short proof in [[second order arithmetic]].

==See also==

*[[List of incomplete proofs]]
*[[Proof by intimidation]]

==References==
{{Reflist}}

*{{Citation | last1=Krantz | first1=Steven G.|authorlink= Steven G. Krantz | title=The proof is in the pudding. The changing nature of mathematical proof | url=http://www.math.wustl.edu/~sk/books/proof.pdf | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=978-0-387-48908-7 |mr=2789493 | year=2011 | doi=10.1007/978-0-387-48744-1}}
*{{citation|mr=0685558|last=Smoryński|first= C.
|title=The varieties of arboreal experience 
|journal=Math. Intelligencer |volume=4 |year=1982|issue= 4|pages= 182–189|doi=10.1007/bf03023553}}

[[Category:Mathematics-related lists|Published Incomplete Proofs]]
[[Category:Theorems]]
[[Category:Mathematical proofs]]</text>
      <sha1>kur6dlbusm7ghzrvamtq9ex3082l5ke</sha1>
    </revision>
  </page>
  <page>
    <title>Logical matrix</title>
    <ns>0</ns>
    <id>4109196</id>
    <revision>
      <id>863791403</id>
      <parentid>863783507</parentid>
      <timestamp>2018-10-13T01:58:17Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <minor/>
      <comment>/* Example */ finish sentence</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8675">A '''logical matrix''', '''binary matrix''', '''relation matrix''', '''Boolean matrix''', or '''(0,1) matrix''' is a [[matrix (mathematics)|matrix]] with entries from the [[Boolean domain]] {{nowrap|1='''B''' = {0, 1}.}}  Such a matrix can be used to represent a [[binary relation]] between a pair of [[finite set]]s.

==Matrix representation of a relation==
If ''R'' is a [[binary relation]] between the finite [[indexed set]]s ''X'' and ''Y'' (so {{nowrap| ''R'' ⊆ ''X''×''Y''}}), then ''R'' can be represented by the logical matrix ''M'' whose row and column indices index the elements of ''X'' and ''Y'', respectively, such that the entries of ''M'' are defined by:

:&lt;math&gt;M_{i,j} =
 \begin{cases}
   1 &amp; (x_i, y_j) \in R \\
   0 &amp; (x_i, y_j) \not\in R 
 \end{cases}
 &lt;/math&gt;

In order to designate the row and column numbers of the matrix, the sets ''X'' and ''Y'' are indexed with positive integers: ''i'' ranges from 1 to the [[cardinality]] (size) of ''X'' and ''j'' ranges from 1 to the cardinality of ''Y''. See the entry on [[indexed set]]s for more detail.

===Example===
The binary relation ''R'' on the set {{nowrap|{1, 2, 3, 4}{{null}}}} is defined so that ''aRb'' holds if and only if ''a'' divides ''b'' evenly, with no remainder.  For example, 2''R''4 holds because 2 divides 4 without leaving a remainder, but 3''R''4 does not hold because when 3 divides 4 there is a remainder of 1. The following set is the set of pairs for which the relation ''R'' holds. 
:{(1, 1), (1, 2), (1, 3), (1, 4), (2, 2), (2, 4), (3, 3), (4, 4)}.
The corresponding representation as a logical matrix is:

:&lt;math&gt;\begin{pmatrix}
   1 &amp; 1 &amp; 1 &amp; 1 \\
   0 &amp; 1 &amp; 0 &amp; 1 \\
   0 &amp; 0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; 0 &amp; 1
 \end{pmatrix}&lt;/math&gt; which includes a diagonal of ones since each number divides itself.

==Other examples==

* A [[permutation matrix]] is a (0,1)-matrix, all of whose columns and rows each have exactly one nonzero element. 
** A [[Costas array]] is a special case of a permutation matrix
* An [[incidence matrix]] in [[combinatorics]] and [[finite geometry]] has ones to indicate incidence between points (or vertices) and lines of a geometry, blocks of a [[block design]], or edges of a [[graph (discrete mathematics)]]
* A [[design matrix]] in [[analysis of variance]] is a (0,1)-matrix with constant row sums.
* A logical matrix may represent an [[adjacency matrix]] in [[graph theory]]: non-symmetric matrices correspond to [[directed graph]]s, symmetric matrices to ordinary [[graph (discrete mathematics)|graph]]s, and a 1 on the diagonal corresponds to a [[loop (graph theory)|loop]] at the corresponding vertex.
* The [[biadjacency matrix]] of a simple, undirected [[bipartite graph]] is a (0,1)-matrix, and any (0,1)-matrix arises in this way.
* The prime factors of a list of ''m'' [[square-free integer|square-free]], [[smooth number|''n''-smooth]] numbers can be described as a ''m''&amp;times;π(''n'') (0,1)-matrix, where π is the [[prime-counting function]] and ''a''&lt;sub&gt;''ij''&lt;/sub&gt; is 1 if and only if the ''j''th prime divides the ''i''th number. This representation is useful in the [[quadratic sieve]] factoring algorithm.
*A [[Raster graphics|bitmap image]] containing [[pixel]]s in only two colors can be represented as a (0,1)-matrix in which the 0's represent pixels of one color and the 1's represent pixels of the other color.
* A binary matrix can be used to check the game rules in the game of [[Go (game)|Go]] &lt;ref&gt;{{cite web|url=http://senseis.xmp.net/?BinMatrix|title=Binmatrix|date=February 8, 2013|access-date=August 11, 2017|first=Kjeld|last=Petersen}}&lt;/ref&gt;

==Some properties==
The matrix representation of the [[Equality (mathematics)|equality relation]] on a finite set is the [[identity matrix]] I, that is, the matrix whose entries on the diagonal are all 1, while the others are all 0. More generally, if relation ''R'' satisfies I ⊂ ''R'', then R is a [[reflexive relation]].

If the Boolean domain is viewed as a [[semiring]], where addition corresponds to [[logical OR]] and multiplication to [[logical AND]], the matrix representation of the [[composition of relations|composition]] of two relations is equal to the [[matrix product]] of the matrix representations of these relation.
This product can be computed in [[Expected value|expected]] time O(''n''&lt;sup&gt;2&lt;/sup&gt;).&lt;ref&gt;{{cite journal| author=Patrick E. O'Neil, Elizabeth J. O'Neil| title=A Fast Expected Time Algorithm for Boolean Matrix Multiplication and Transitive Closure| journal=Information and Control| year=1973| volume=22| issue=2 |pages=132–138| url=http://www.sciencedirect.com/science/article/pii/S0019995873902283/pdf?md5=37b2d0aafda0b0639e48370c73d5e82a&amp;pid=1-s2.0-S0019995873902283-main.pdf| doi=10.1016/s0019-9958(73)90228-3}} &amp;mdash; The algorithm relies on addition being [[idempotent]], cf. p.134 (bottom).&lt;/ref&gt;

Frequently operations on binary matrices are defined in terms of [[modular arithmetic]] mod 2&amp;mdash;that is, the elements are treated as elements of the [[Galois field]] {{nowrap|1='''GF'''(2) = ℤ&lt;sub&gt;2&lt;/sub&gt;}}. They arise in a variety of representations and have a number of more restricted special forms. They are applied e.g. in [[XOR-satisfiability]].&lt;!---more links to applications should go here---&gt;

The number of distinct ''m''-by-''n'' binary matrices is equal to 2&lt;sup&gt;''mn''&lt;/sup&gt;, and is thus finite.

==Lattice==
Let ''n'' and ''m'' be given and let ''U'' denote the set of all logical ''m'' × ''n'' matrices. Then ''U'' has a [[partial order]] given by
:&lt;math&gt;m \subset n \quad \text{when} \quad \forall i,j \quad m_{ij} = 1 \implies n_{ij} = 1 .&lt;/math&gt;

In fact, ''U'' forms a [[Boolean algebra]] with the operations [[and (logic)|and]] and [[or (logic)|or]] between two matrices applied component-wise. The complement of a logical matrix is obtained by swapping all zeros and ones for their opposite.

Every logical matrix a = ( a &lt;sub&gt;i j &lt;/sub&gt; ) has an '''transpose''' a&lt;sup&gt;T&lt;/sup&gt; = ( a &lt;sub&gt;j i&lt;/sub&gt; ). Suppose ''a'' is a logical matrix with no columns or rows identically zero. Then the matrix product, using Boolean arithmetic, a&lt;sup&gt;T&lt;/sup&gt; a is the ''m'' × ''m'' [[identity matrix]], and the product a a&lt;sup&gt;T&lt;/sup&gt; is the ''n'' × ''n'' identity.

As a mathematical structure, the Boolean algebra ''U'' forms a [[lattice (order)|lattice]] ordered by [[inclusion (logic)|inclusion]]; additionally it is a '''multiplicative lattice''' due to matrix multiplication. 

Every logical matrix in ''U'' corresponds to a binary relation. These listed operations on ''U'', and ordering, correspond to a [[algebraic logic#Calculus of relations|calculus of relations]], where the matrix multiplication represents [[composition of relations]].&lt;ref&gt;[[Irving Copilowish]] (December 1948) "Matrix development of the calculus of relations", [[Journal of Symbolic Logic]] 13(4): 193–203 [https://www.jstor.org/stable/2267134?seq=1#page_scan_tab_contents Jstor link]&lt;/ref&gt;

==Logical vectors==
If ''m'' or ''n'' equals one, then the ''m'' × ''n'' logical matrix (M&lt;sub&gt;i j&lt;/sub&gt;) is a logical vector. If ''m'' = 1 the vector is a row vector, and if ''n'' = 1 it is a column vector. In either case the index equaling one is dropped from denotation of the vector.

Suppose &lt;math&gt;(P_i), \quad i = 1, 2,... m \ \ \text{and}\ \ (Q_j), \quad j = 1,2,... n&lt;/math&gt; are two logical vectors. The [[outer product]] of ''P'' and ''Q'' results in an ''m'' × ''n'' [[rectangular relation]]:
:&lt;math&gt;M_{i j} = P_i \and Q_j .&lt;/math&gt; A re-ordering of the rows and columns of such a matrix can assemble all the ones into a rectangular part of the matrix. &lt;ref&gt;{{cite book | doi=10.1017/CBO9780511778810 | isbn=9780511778810 | author=[[Gunther Schmidt]] | page=95 | title=Relational Mathematics | location= | publisher=Cambridge University Press | series= | volume= | edition= | month= | year=2013 }}&lt;/ref&gt;

In [[concept analysis]] a relation is studied by determining the maximal rectangular relations contained in it.

==See also==
{{Commons category|Binary matrix}}
* [[List of matrices]]
* [[De Bruijn torus|Binatorix]] (a binary De Bruijn torus)
* [[Redheffer matrix]]

==Notes==
{{reflist}}

==References==
* {{Citation | last1=Hogben | first1=Leslie | title=Handbook of Linear Algebra (Discrete Mathematics and Its Applications) | publisher=Chapman &amp; Hall/CRC | location=Boca Raton | isbn=978-1-58488-510-8 | year=2006}}, section 31.3, Binary Matrices
* {{Citation | last1=Kim | first1=Ki Hang | title=Boolean Matrix Theory and Applications |year=1982| isbn=0-8247-1788-0}}

==External links==
* {{springer|title=Logical matrix|id=p/l060740}}

{{DEFAULTSORT:Logical Matrix}}
[[Category:Boolean algebra]]
[[Category:Matrices]]</text>
      <sha1>lrov86ja7b32k5h4difwlkq630ycm16</sha1>
    </revision>
  </page>
  <page>
    <title>Metric signature</title>
    <ns>0</ns>
    <id>463225</id>
    <revision>
      <id>870957783</id>
      <parentid>870749096</parentid>
      <timestamp>2018-11-28T01:26:17Z</timestamp>
      <contributor>
        <username>Verdana Bold</username>
        <id>21078279</id>
      </contributor>
      <comment>/* top */ see wolfram article on lt. This edit comes directly from there.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9628">The '''signature''' {{nowrap|(''v'', ''p'', ''r'')}} of a [[metric tensor]] ''g'' (or equivalently, a real [[quadratic form]] thought of as a real [[symmetric bilinear form]] on a finite-dimensional vector space) is the number (counted with multiplicity) of positive, zero, and negative [[eigenvalue]]s of the real [[symmetric matrix]] {{nowrap|''g''&lt;sub&gt;''ab''&lt;/sub&gt;}}  of the metric tensor with respect to a [[Basis (linear algebra)|basis]]. In physics, the ''v'' represents for the time or virtual dimension, and the ''p'' for the space and physical dimension. Alternatively, it can be defined as the dimensions of a maximal positive and null subspace. By [[Sylvester's law of inertia]] these numbers do not depend on the choice of basis. The signature thus classifies the metric up to a choice of basis. The signature is often denoted by a pair of integers {{nowrap|(''v'', ''p'')}} implying ''r'' = 0 or as an explicit list of signs of eigenvalues such as {{nowrap|(+, −, −, −)}} or {{nowrap|(−, +, +, +)}} for the signature {{nowrap|(1, 3, 0)}}, respectively.&lt;ref&gt;Rowland, Todd. "Matrix Signature." From MathWorld--A Wolfram Web Resource, created by Eric W. Weisstein. http://mathworld.wolfram.com/MatrixSignature.html&lt;/ref&gt;

The signature is said to be '''indefinite''' or '''mixed''' if both ''v'' and ''p'' are nonzero, and degenerate if ''r'' is nonzero. A [[Riemannian metric]] is a metric with a [[definite bilinear form|positive definite]] signature {{nowrap|(''v'', p)}}. The [[Lorentz metric|Lorentzian metric]] is a metric signature {{nowrap|(''v'', ''p'')}} with two eigenvalues.

There is another notion of '''signature''' of a nondegenerate metric tensor given by a single number ''s'' defined as {{nowrap|(''v''−''p'')}}, where ''v'' and ''p'' are as above, which is equivalent to the above definition when the dimension ''n'' = ''v'' + ''p'' is given or implicit.  For example, ''s'' = 1 − 3 = −2 for {{nowrap|(+, −, −, −)}} and its mirroring ''s' '' = −''s'' = +2 for {{nowrap|(−, +, +, +)}}.

== Definition ==
The signature of a metric tensor is defined as the signature of the corresponding [[quadratic form]].&lt;ref&gt;{{cite book|ref=harv|last1=Landau|first1=L.D.|authorlink1=Lev Landau|last2=Lifshitz|first2=E.M.|authorlink2=Evgeny Lifshitz|title=The Classical Theory of Fields|series=Course of Theoretical Physics|volume=2|edition=4th|publisher=[[Butterworth&amp;ndash;Heinemann]]|isbn=0 7506 2768 9|year=2002|orig-year=1939|pages=245&amp;ndash;246}}&lt;/ref&gt; It is the number {{nowrap|(''v'', ''p'', ''r'')}} of positive and zero [[eigenvalues]] of any matrix (i.e. in any basis for the underlying vector space) representing the form, counted with their [[algebraic multiplicity]]. Usually, {{nowrap|''r'' {{=}} 0}} is required, which is the same as saying a metric tensor must be nondegenerate, i.e. no nonzero vector is orthogonal to all vectors.

By Sylvester's law of inertia, the numbers {{nowrap|(''v'', ''p'', ''r'')}} are basis independent.

== Properties ==

=== Signature and dimension ===
By the [[spectral theorem]] a symmetric ''n'' × ''n'' matrix over the reals is always [[diagonalizable]], and has therefore exactly ''n'' real eigenvalues (counted with [[algebraic multiplicity]]). Thus {{nowrap|1=''v'' + ''p'' = ''n'' = dim(''V'')}}.

=== Sylvester's law of inertia: independence of basis choice and existence of orthonormal basis ===
According to [[Sylvester's law of inertia]], the signature of the scalar product  (a.k.a. real symmetric bilinear form), ''g'' does not depend on the choice of basis. Moreover, for every metric ''g'' of signature {{nowrap|(''v'', ''p'', ''r'')}} there exists a basis such that 
{{nowrap|1=''g''&lt;sub&gt;''ab''&lt;/sub&gt; = +1}} for {{nowrap|1=''a'' = ''b'' = 1, ..., ''v''}}, {{nowrap|1=''g''&lt;sub&gt;''ab''&lt;/sub&gt; = −1}} for {{nowrap|1=''a'' = ''b'' = ''v'' + 1, ..., ''v'' + ''p''}} and {{nowrap|1=''g''&lt;sub&gt;''ab''&lt;/sub&gt; = 0}} otherwise. It follows that there exists an [[isometry]] {{nowrap|(''V''&lt;sub&gt;1&lt;/sub&gt;, ''g''&lt;sub&gt;1&lt;/sub&gt;) → (''V''&lt;sub&gt;2&lt;/sub&gt;, ''g''&lt;sub&gt;2&lt;/sub&gt;)}} if and only if the signatures of ''g''&lt;sub&gt;1&lt;/sub&gt; and ''g''&lt;sub&gt;2&lt;/sub&gt; are equal.  Likewise the signature is equal for two [[congruent matrices]] and classifies a matrix up to congruency. Equivalently, the signature is constant on the orbits of the general linear group GL(''V'') on the space of symmetric rank 2 contravariant tensors ''S''&lt;sup&gt;2&lt;/sup&gt;''V''&lt;sup&gt;∗&lt;/sup&gt; and classifies each orbit.

===Geometrical interpretation of the indices ===
The number ''v'' (resp.  ''p'') is the maximal dimension of a vector subspace on which the scalar product ''g'' is positive-definite (resp. negative-definite), and ''r'' is the dimension of the [[Symmetric bilinear form#Orthogonality and singularity|radical]] of the scalar product ''g'' or the [[null space|null subspace]] of [[symmetric matrix]] {{nowrap|''g''&lt;sub&gt;''ab''&lt;/sub&gt;}} of the [[scalar product]]. Thus a nondegenerate scalar product has signature {{nowrap|(''v'', ''p'', 0)}}, with {{nowrap|1=''v'' + ''p'' = ''n''}}. A duality of the special cases {{nowrap|(''v'', ''p'', 0)}} correspond to two scalar eigenvalues which can be transformed into each other by the mirroring reciprocally.

== Examples ==

=== Matrices ===
The signature of the {{nowrap|''n'' × ''n''}} [[identity matrix]] is {{nowrap|(''v'', ''p'', 0)}} where {{nowrap|1=''n'' = ''v'' + ''p''}}. The [[diagonal matrix]] of a signature is the number of positive, negative and zero numbers on its [[main diagonal]].

The following matrices have both the same signature {{nowrap|(1, 1, 0)}}, therefore they are congruent because of [[Sylvester's law of inertia]]:
:&lt;math&gt;\begin{pmatrix} 1 &amp; 0  \\ 0 &amp; -1 \end{pmatrix}, \quad \begin{pmatrix} 0 &amp; 1  \\ 1 &amp; 0 \end{pmatrix}. &lt;/math&gt;

=== Scalar products ===
The standard [[scalar product]] defined on &lt;math&gt; \mathbb{R}^n &lt;/math&gt; has the n-dimensional signatures {{nowrap|(''v'', ''p'', ''r'')}}, where {{nowrap|1=''v'' + ''p'' = ''n''}} and rank {{nowrap|1=''r ''=''0''}}.

In physics, the [[Minkowski space]] is a spacetime manifold &lt;math&gt;\R^4&lt;/math&gt; with ''v=1'' and ''p=3'' bases, and has a scalar product defined by either the &lt;math&gt;\check g&lt;/math&gt; matrix:
:&lt;math&gt;\check g=\begin{pmatrix} -1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix} &lt;/math&gt;
which has signature &lt;math&gt;(1, 3, 0)^-&lt;/math&gt; and known as space-supremacy or space-like; Or the mirroring signature &lt;math&gt;(1,3, 0)^+&lt;/math&gt;, known virtual-supremacy or time-like with the &lt;math&gt;\hat g&lt;/math&gt; matrix. 
:&lt;math&gt;\hat g=\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; -1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; -1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; -1 \end{pmatrix}=-\check g&lt;/math&gt;

== How to compute the signature ==
There are some methods for computing the signature of a matrix.
* For any [[nondegenerate]] [[symmetric matrix]] of {{nowrap|''n'' × ''n''}}, [[Matrix diagonalization|diagonalize]] it (or find all of [[eigenvalue]]s of it) and count the number of positive and negative signs.
* For a symmetric matrix, the characteristic polynomial will have all real roots whose signs may in some cases be completely determined by [[Descartes' rule of signs]].
* Lagrange algorithm gives a way to compute an [[orthogonal basis]], and thus compute a diagonal matrix congruent (thus, with the same signature) to the other one: the signature of a diagonal matrix is the number of positive, negative and zero elements on its diagonal.
* According to Jacobi's criterion, a symmetric matrix is positive-definite if and only if all the determinants of its main minors are positive.

== Signature in physics ==
In mathematics, the usual convention for any [[Riemannian manifold]] is to use a positive-definite [[metric tensor]] (meaning that after diagonalization, elements on the diagonal are all positive).

In [[theoretical physics]], [[spacetime]] is modeled by a [[pseudo-Riemannian manifold]].  The signature counts how many time-like or space-like characters are in the spacetime, in the sense defined by [[special relativity]]: as used in [[particle physics]], the metric has an eigenvalue on the time-like subspace, and its mirroring eigenvalue on the space-like subspace.
In the specific case of the [[Minkowski space|Minkowski metric]],
: &lt;math&gt; ds^2 = c^2 dt^2 - dx^2 - dy^2 - dz^2 &lt;/math&gt; ,
the metric signature is &lt;math&gt;(1, 3, 0)^+&lt;/math&gt; or (+, −, −, −) if its eigenvalue is defined in the time direction, or &lt;math&gt;(1, 3, 0)^-&lt;/math&gt; or (−, +, +, +) if the eigenvalue is defined in the three spatial directions ''x'', ''y'' and ''z''. 
(Sometimes the opposite [[Sign (mathematics)|sign]] convention is used, but with the one given here ''s'' directly measures [[proper time]].)

==Signature change==
If a metric is regular everywhere then the signature of the metric is constant. However if one allows for metrics that are degenerate or discontinuous on some hypersurfaces, then signature of the metric may change at these surfaces.&lt;ref&gt;{{cite journal
|last1=Dray    |first1=Tevian
|last2=Ellis   |first2=George
|last3=Hellaby |first3=Charles
|last4=Manogue |first4=Corinne A.
|title          =Gravity and signature change
|journal        =General Relativity and Gravitation
|volume         =29
|pages          =591–597
|doi            =10.1023/A:1018895302693
|year           =1997
|arxiv          =gr-qc/9610063
|bibcode = 1997GReGr..29..591D }}&lt;/ref&gt; Such signature changing metrics may possibly have applications in [[physical cosmology|cosmology]] and [[quantum gravity]].

==See also==
*[[pseudo-Riemannian manifold]]
*[[Sign convention]]

==Notes==
{{reflist}}

[[Category:Differential geometry]]
[[Category:Metric tensors|*2]]</text>
      <sha1>euyhhh3xmjhng4r3hd6dy9yftnin6s9</sha1>
    </revision>
  </page>
  <page>
    <title>Mixed volume</title>
    <ns>0</ns>
    <id>32953045</id>
    <revision>
      <id>777316130</id>
      <parentid>745656329</parentid>
      <timestamp>2017-04-26T13:22:54Z</timestamp>
      <contributor>
        <username>Xnn</username>
        <id>10877435</id>
      </contributor>
      <comment>/* top */ shape seems more important than size</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4570">In [[mathematics]], more specifically, in [[convex geometry]], the '''mixed volume''' is a way to associate a non-negative number to an &lt;math&gt;n&lt;/math&gt;-tuple of [[convex body|convex bodies]] in the &lt;math&gt;n&lt;/math&gt;-dimensional space. This number depends on the size and shape of the bodies and on their relative orientation to each other.

==Definition==

Let &lt;math&gt;K_1, K_2, \dots, K_r&lt;/math&gt; be convex bodies in &lt;math&gt;\mathbb{R}^n&lt;/math&gt; and consider the function

:&lt;math&gt; f(\lambda_1, \ldots, \lambda_r) 
= \mathrm{Vol}_n (\lambda_1 K_1 + \cdots + \lambda_r K_r), \qquad \lambda_i \geq 0, &lt;/math&gt;

where &lt;math&gt;\text{Vol}_n&lt;/math&gt; stands for the &lt;math&gt;n&lt;/math&gt;-dimensional volume and its argument is the [[Minkowski sum]] of the scaled convex bodies &lt;math&gt;K_i&lt;/math&gt;. One can show that &lt;math&gt;f&lt;/math&gt; is a [[homogeneous polynomial]] of degree &lt;math&gt;n&lt;/math&gt;, therefore it can be written as

:&lt;math&gt; f(\lambda_1, \ldots, \lambda_r)
 = \sum_{j_1, \ldots, j_n = 1}^r V(K_{j_1}, \ldots, K_{j_n}) 
   \lambda_{j_1} \cdots \lambda_{j_n},  &lt;/math&gt;

where the functions &lt;math&gt;V&lt;/math&gt; are symmetric. Then &lt;math&gt;V(K_1, \dots, K_n)&lt;/math&gt; is called the mixed volume of &lt;math&gt;K_1, \dots, K_n&lt;/math&gt;.

Equivalently,

:&lt;math&gt;
V(K_1, \ldots, K_n) 
= \frac{1}{n!} \left. \frac{\partial^n}{\partial \lambda_1 \cdots \partial \lambda_n}\right|_{\lambda_1 = \cdots = \lambda_n = +0} 
  \mathrm{Vol}_n(\lambda_1 K_1 + \cdots + \lambda_n K_n).&lt;/math&gt;

==Properties==

* The mixed volume is uniquely determined by the following three properties:
# &lt;math&gt;
V(K, \dots, K) = \text{Vol}_n (K)&lt;/math&gt;;
# &lt;math&gt;V&lt;/math&gt; is symmetric in its arguments;
# &lt;math&gt;V&lt;/math&gt; is multilinear: &lt;math&gt;
V(\lambda K + \lambda' K', K_2, \dots, K_n) = \lambda V(K, K_2, \dots, K_n)
+ \lambda' V(K', K_2, \dots, K_n)&lt;/math&gt; for &lt;math&gt;
\lambda,\lambda' \geq 0&lt;/math&gt;.

* The mixed volume is non-negative and monotonically increasing in each variable: &lt;math&gt;
V(K_1, K_2, \ldots, K_n) \leq V(K_1', K_2, \ldots, K_n)&lt;/math&gt; for &lt;math&gt;
K_1 \subseteq K_1'&lt;/math&gt;.
* The Alexandrov&amp;ndash;Fenchel inequality, discovered by [[Aleksandr Danilovich Aleksandrov]] and [[Werner Fenchel]]:

::&lt;math&gt; V(K_1, K_2, K_3, \ldots, K_n) \geq \sqrt{V(K_1, K_1, K_3, \ldots, K_n) V(K_2,K_2, K_3,\ldots,K_n)}.&lt;/math&gt;

:Numerous geometric inequalities, such as the [[Brunn&amp;ndash;Minkowski inequality]] for convex bodies and [[Minkowski's first inequality for convex bodies|Minkowski's first inequality]], are special cases of the Alexandrov&amp;ndash;Fenchel inequality.

==Quermassintegrals==

Let &lt;math&gt;K \subset \mathbb{R}^n&lt;/math&gt; be a convex body and let &lt;math&gt;B = B_n \subset \mathbb{R}^n&lt;/math&gt; be the [[Unit ball#Unit spheres and balls in Euclidean space|Euclidean ball]] of unit radius. The mixed volume

:&lt;math&gt; W_j(K) = V(\overset{n-j \text{ times}}{\overbrace{K,K, \ldots,K}}, \overset{j \text{ times}}{\overbrace{B,B,\ldots,B}})&lt;/math&gt;

is called the ''j''-th '''quermassintegral''' of &lt;math&gt;K&lt;/math&gt;.&lt;ref&gt;{{cite journal|mr=1089383|last=McMullen|first=P.|authorlink=Peter McMullen|title=Inequalities between intrinsic volumes|journal=Monatsh. Math.|volume=111|year=1991|issue=1|pages=47&amp;ndash;53|doi=10.1007/bf01299276}}&lt;/ref&gt;

The definition of mixed volume yields the '''Steiner formula''' (named after [[Jakob Steiner]]):

:&lt;math&gt; \mathrm{Vol}_n(K + tB)
 = \sum_{j=0}^n \binom{n}{j} W_j(K) t^j.&lt;/math&gt;

===Intrinsic volumes===

The ''j''-th '''intrinsic volume''' of &lt;math&gt;K&lt;/math&gt; is a different normalization of the quermassintegral, defined by

:&lt;math&gt; V_j(K) = \binom{n}{j} \frac{W_{n-j}(K)}{\kappa_{n-j}},&lt;/math&gt; or in other words &lt;math&gt; \mathrm{Vol}_n(K + tB) = \sum_{j=0}^n V_j(K)\, \mathrm{Vol}_{n-j}(tB_{n-j}).&lt;/math&gt;

where &lt;math&gt;\kappa_{n-j} = \text{Vol}_{n-j} (B_{n-j})&lt;/math&gt; is the volume of the &lt;math&gt;(n-j)&lt;/math&gt;-dimensional unit ball.

===Hadwiger's characterization theorem===
{{main|Hadwiger's theorem}}

Hadwiger's theorem asserts that every [[valuation (measure theory)|valuation]] on convex bodies in &lt;math&gt;\mathbb{R}^n&lt;/math&gt; that is continuous and invariant under rigid motions of &lt;math&gt;\mathbb{R}^n&lt;/math&gt; is a linear combination of the quermassintegrals (or, equivalently, of the intrinsic volumes).&lt;ref&gt;{{cite journal|mr=1376731|last=Klain|first=D.A.|title=A short proof of Hadwiger's characterization theorem|journal=Mathematika|volume=42|year=1995|issue=2|pages=329&amp;ndash;339|doi=10.1112/s0025579300014625}}&lt;/ref&gt;

==Notes==
{{Reflist}}

==External links==
{{eom|id=Mixed-volume_theory|title=Mixed volume theory|first=Yu.D.|last=Burago}}

[[Category:Convex geometry]]
[[Category:Integral geometry]]</text>
      <sha1>r791xywq2cs5qn2bdbid5hnutb4se1t</sha1>
    </revision>
  </page>
  <page>
    <title>Otto Frostman</title>
    <ns>0</ns>
    <id>34049712</id>
    <revision>
      <id>843238877</id>
      <parentid>835128419</parentid>
      <timestamp>2018-05-27T20:48:17Z</timestamp>
      <contributor>
        <username>Halibut Memorial</username>
        <id>30919881</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2176">{{Infobox scientist
| name              = Otto A. Frostman
| image             = &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size        = 
| image_upright     = 
| alt               = 
| caption           = 
| birth_date        = {{birth date |1907|1|3|df=y}}
| birth_place       = [[Höör]], [[Sweden]]
| death_date        = {{death date and age |1977|12|29 |1907|1|3|df=y}}
| death_place       = [[Djursholm]], Sweden
| nationality       = [[Sweden|Swedish]]
| fields            = [[Mathematics]]
| workplaces        = 
| alma_mater        = 
| thesis_title      = &lt;!--(or  | thesis1_title =  and  | thesis2_title = )--&gt;
| thesis_url        = &lt;!--(or  | thesis1_url  =   and  | thesis2_url  =  )--&gt;
| thesis_year       = &lt;!--(or  | thesis1_year =   and  | thesis2_year =  )--&gt;
| doctoral_advisor  = [[Marcel Riesz]]
| doctoral_students = 
| known_for         = [[Frostman lemma]]
| awards            = 
}}

'''Otto Albin Frostman''' (3 January 1907 &amp;ndash; 29 December 1977) was a Swedish [[mathematician]], known for his work in [[potential theory]] and [[complex analysis]].

Frostman earned his Ph.D. in 1935 at [[Lund University]] under the Hungarian-born mathematician [[Marcel Riesz]], the younger brother of [[F. Riesz]]. In potential theory, [[Frostman's lemma]] is named after him.&lt;ref&gt;{{cite journal|author=Kjell-Ove Widman|title=Household names in Swedish mathematics|journal=[[Newsletter of the European Mathematical Society|EMS Newsletter]]|volume=52|year=2004}}&lt;/ref&gt; He supervised the 1971 Stockholm University Ph.D. thesis of Bernt Lindström, which initiated the "Stockholm School" of [[topological combinatorics]] (combining [[simplicial homology]] and [[enumerative combinatorics]]).

==Notes==
{{Reflist}}

==External links==
* {{MathGenealogy|id=34954}}
* [http://www.icmihistory.unito.it/portrait/frostman.php ICMI webpage]

{{Authority control}}
{{DEFAULTSORT:Frostman, Otto}}
[[Category:Mathematical analysts]]
[[Category:Swedish mathematicians]]
[[Category:Directors of the Mittag-Leffler Institute]]
[[Category:1977 deaths]]
[[Category:1907 births]]
[[Category:20th-century Swedish mathematicians]]


{{Sweden-mathematician-stub}}</text>
      <sha1>mblo9bppeuqt19988cfwy4dd9bt1hfa</sha1>
    </revision>
  </page>
  <page>
    <title>Paul Erdős Award</title>
    <ns>0</ns>
    <id>28001680</id>
    <revision>
      <id>850896934</id>
      <parentid>848519344</parentid>
      <timestamp>2018-07-18T18:03:53Z</timestamp>
      <contributor>
        <username>Alistair1978</username>
        <id>86816</id>
      </contributor>
      <minor/>
      <comment>typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2009">The '''Paul Erdős Award''', named after [[Paul Erdős]], is given by the
[[World Federation of National Mathematics Competitions]] for those who "have played a significant role in the development of mathematical challenges at the national or international level and which have been a stimulus for the enrichment of mathematics learning". The awards have been given in two-year periods since 1996.

==Awardees==
* 1992:
** [[Luis Davidson San Juan|Luis Davidson]], Cuba
** [[Nikolay Konstantinov]], Russia
** John Webb, South Africa
* 1994:
** Ronald Dunkley, Canada
** Walter Mientka, USA
** Urgengtserengiin Sanjmyatav, Mongolia
** Jordan Tabov, Bulgaria
** Peter Taylor, Australia
** Qiu Zonghu, People's Republic of China
* 1996:
** George Berzsenyi, USA
** [[Tony Gardiner]], United Kingdom
** Derek Holton, New Zealand
*1998:
** Agnis Andzans, Latvia
** Wolfgang Engel, Germany
** Mark Saul, USA
*2000:
** Francisco Bellot Rosado, Spain
** István Reiman, Hungary
** János Surányi, Hungary
*2002:
** Bogoljub Marinkovic, Yugoslavia
** Harold Braun Reiter, United States of America
** Wen-Hsien Sun, China(Taiwan)
*2004:
** Warren Atkins, Australia
** André Deledicq, France
** Patricia Fauring, Argentina
*2006:
** Simon Chua, Philippines
** Ali Rejali, Iran
** [[Alexander Soifer]], USA
*2008:
** Hans-Dietrich (Dieter) Gronau, Germany
** Bruce Henry, Australia
** Leou Shian, China(Taiwan)
*2010:
**Rafael Sanchez-Lamoneda, Venezuela
**Yahya Tabesh, Iran
*2012:
**[[Cecil C. Rousseau]], USA
**Paul Vaderlind, Sweden
*2014:
**Petar Kenderov, Bulgaria
**József Pelikán, Hungary
**[[Richard Rusczyk]], USA
*2016:
**Luis Caceres, Puerto Rico
**David Christopher Hunt, Australia
**Kar-Ping Shum, Hong Kong, China
*2018:
**Bin Xiong, China
**David Monk, United Kingdom
**[[Carlos Gustavo Moreira|Carlos Gustavo Tamm de Araujo Moreira]], Brazil

==Sources==
* [http://www.wfnmc.org/awards.html Homepage] of the award.

{{DEFAULTSORT:Erdos Award}}
[[Category:Paul Erdős]]
[[Category:Mathematics awards]]</text>
      <sha1>jb5640u1m4qt6h9g99p8n10xjlv4m9n</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial matrix</title>
    <ns>0</ns>
    <id>7852591</id>
    <revision>
      <id>851070756</id>
      <parentid>851060504</parentid>
      <timestamp>2018-07-19T21:16:37Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/96.40.48.159|96.40.48.159]]: Distinguishing with moomial matrices is necessary because a monomial matrix is not a matrix of polynomials such that all entries are monomials. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2435">{{distinguish|matrix polynomial}}
In [[mathematics]], a '''polynomial matrix''' or '''matrix of polynomials''' is a [[matrix (mathematics)|matrix]] whose elements are univariate or multivariate [[polynomial]]s. Equivalently, a polynomial matrix is a polynomial whose coefficients are matrices. 

A univariate polynomial matrix ''P'' of degree ''p'' is defined as:

:&lt;math&gt;P = \sum_{n=0}^p A(n)x^n = A(0)+A(1)x+A(2)x^2+ \cdots +A(p)x^p&lt;/math&gt;

where &lt;math&gt;A(i)&lt;/math&gt; denotes a matrix of constant coefficients, and &lt;math&gt;A(p)&lt;/math&gt; is non-zero. 
An example 3×3 polynomial matrix, degree 2:

:&lt;math&gt;
P=\begin{pmatrix}
1 &amp; x^2 &amp; x \\
0 &amp; 2x &amp; 2 \\
3x+2 &amp; x^2-1 &amp; 0
\end{pmatrix}
=\begin{pmatrix}
1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 \\
2 &amp; -1 &amp; 0
\end{pmatrix}

+\begin{pmatrix}
0 &amp; 0 &amp; 1 \\
0 &amp; 2 &amp; 0 \\
3 &amp; 0 &amp; 0
\end{pmatrix}x+\begin{pmatrix}
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0
\end{pmatrix}x^2.
&lt;/math&gt;

We can express this by saying that for a [[ring (mathematics)|ring]] ''R'', the rings &lt;math&gt;M_n(R[X])&lt;/math&gt; and
&lt;math&gt;(M_n(R))[X]&lt;/math&gt; are [[Ring homomorphism|isomorphic]].

==Properties==
*A polynomial matrix over a [[field (mathematics)|field]] with [[determinant]] equal to a non-zero element of that field is called [[unimodular matrix|unimodular]], and has an [[matrix inverse|inverse]] that is also a polynomial matrix. Note that the only scalar unimodular polynomials are polynomials of degree 0 – nonzero constants, because an inverse of an arbitrary polynomial of higher degree is a rational function.
*The roots of a polynomial matrix over the [[complex numbers]] are the points in the [[complex plane]] where the matrix loses [[rank (linear algebra)|rank]].

Note that polynomial matrices are ''not'' to be confused with [[monomial matrix|monomial matrices]], which are simply matrices with exactly one non-zero entry in each row and column.

If by λ we denote any element of the [[field (mathematics)|field]] over which we constructed the matrix, by ''I'' the identity matrix, and we let ''A'' be a polynomial matrix, then the matrix λ''I''&amp;nbsp;&amp;minus;&amp;nbsp;''A'' is the '''characteristic matrix''' of the matrix ''A''. Its determinant, |λ''I''&amp;nbsp;&amp;minus;&amp;nbsp;''A''| is the [[characteristic polynomial]] of the matrix&amp;nbsp;''A''.

== References ==

* E.V.Krishnamurthy, Error-free Polynomial Matrix computations, Springer Verlag, New York, 1985

[[Category:Matrices]]
[[Category:Polynomials]]

{{Linear-algebra-stub}}</text>
      <sha1>kplbm3izld0ecbzpdkxgi2lz9i4ar80</sha1>
    </revision>
  </page>
  <page>
    <title>Radical axis</title>
    <ns>0</ns>
    <id>2093844</id>
    <revision>
      <id>868508227</id>
      <parentid>847409055</parentid>
      <timestamp>2018-11-12T17:21:43Z</timestamp>
      <contributor>
        <username>Sp.mandal</username>
        <id>5496087</id>
      </contributor>
      <comment>Provide a image matching with the descriptive text.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11967">{{About|the radical axis used in geometry|the animation studio|Radical Axis (studio)}}

[[File:Radical axis orthogonal circles.svg|thumb|300px|right|Figure 1.  Illustration of the radical axis (red line) of two given circles (solid black).  For any point '''P''' (blue) on the radical axis, a unique circle (dashed) can be drawn that is centered on that point and intersects both given circles at right angles, i.e., orthogonally, at the points where the tangents from P touch the circles.  The point '''P''' has an equal [[power of a point|power]] with respect to both given circles, because the tangents from '''P''' (blue lines) are radii of the orthogonal circle and thus have equal length.]]

The '''radical axis''' (or '''power line''') of two [[circles]] is the [[locus (mathematics)|locus]] of points at which tangents drawn to both circles have the same length.  The radical axis is always a straight line and always [[perpendicular]] to the line connecting the centers of the circles, albeit closer to the circumference of the larger circle.  If the circles intersect, the radical axis is the line passing through the intersection points; similarly, if the circles are [[tangent]], the radical axis is simply the common tangent.  

For any point '''P''' on the radical axis, there is a unique circle centered on '''P''' that intersects both circles at right angles (orthogonally); conversely, the center of any circle that cuts both circles orthogonally must lie on the radical axis.  In technical language, each point '''P''' on the radical axis has the same [[power of a point|power]] with respect to both circles&lt;ref&gt;Johnson (1960), pp. 31&amp;ndash;32.&lt;/ref&gt;

:&lt;math&gt;
R^{2} = d_{1}^{2} - r_{1}^{2} = d_{2}^{2} - r_{2}^{2}
&lt;/math&gt;

where ''r''&lt;sub&gt;1&lt;/sub&gt; and ''r''&lt;sub&gt;2&lt;/sub&gt; are the radii of the two circles, ''d''&lt;sub&gt;1&lt;/sub&gt; and ''d''&lt;sub&gt;2&lt;/sub&gt; are distances from '''P''' to the centers of the two circles, and ''R'' is the radius of the unique orthogonal circle centered on '''P'''.

In general, two disjoint, non-concentric circles can be aligned with the circles of [[bipolar coordinates]]; in that case, the radical axis is simply the ''y''-axis; every circle on that axis that passes through the two foci intersect the two circles orthogonally.  Thus, two radii of such a circle are tangent to both circles, satisfying the definition of the radical axis. The collection of all circles with the same radical axis and with centers on the same line is known as a [[pencil (mathematics)|pencil]] of [[coaxal circles]].

==Definition and general properties==

[[File:Radical axis intersecting circles.svg|thumb|left|200px|If the two circles intersect, the radical axis is the [[secant line]] corresponding to their common [[chord (geometry)|chord]].]]

[[File:Radical center.svg|thumb|right|300px|Figure 2: The radical center (orange point) is the center of the unique circle (also orange) that intersects three given circles at right angles.]]

==Radical center of three circles==

Consider three circles '''A''', '''B''' and '''C''', no two of which are concentric.  The '''radical axis theorem''' states that the three radical axes (for each pair of circles) intersect in one point called the [[power center (geometry)|radical center]], or are parallel.&lt;ref&gt;Johnson (1960), pp. 32&amp;ndash;33.&lt;/ref&gt;  In technical language, the three radical axes are ''concurrent'' (share a common point); if they are parallel, they concur at a point of infinity.

A simple proof is as follows.&lt;ref&gt;Johnson (1960), p. 32.&lt;/ref&gt;  The radical axis of circles '''A''' and '''B''' is defined as the line along which the tangents to those circles are equal in length ''a''=''b''.  Similarly, the tangents to circles '''B''' and '''C''' must be equal in length on their radical axis.  By the [[transitive relation|transitivity]] of [[equality (mathematics)|equality]], all three tangents are equal ''a''=''b''=''c'' at the intersection point '''r''' of those two radical axes.  Hence, the radical axis for circles '''A''' and '''C''' must pass through the same point '''r''', since ''a''=''c'' there.  This common intersection point '''r''' is the '''radical center'''.

There is a unique circle with its center at the radical center that is orthogonal to all three circles.  This follows, also by transitivity, because each radical axis, being the locus of centers of circles that cut each pair of given circles orthogonally, requires all three circles to have equal radius at the intersection of all three axes.

==Geometric construction==
[[File:Radical-Axis-Construction.png|alt=|left|thumb|216x216px|Radical Axis Construction]]
The radical axis of two circles '''A''' and '''B''' can be constructed by drawing a line through any two of its points.  Such a point can be found by drawing a circle '''C''' that intersects both circles '''A''' and '''B''' in two points.  The two lines passing through each pair of intersection points are the radical axes of '''A''' and '''C''' and of '''B''' and '''C'''.  These two lines intersect in a point '''J''' that is the radical center of all three circles, as described [[#Radical center of three circles|above]]; therefore, this point also lies on the radical axis of '''A''' and '''B'''.  Repeating this process with another such circle '''D''' provides a second point '''K'''.  The radical axis is the line passing through both '''J''' and '''K'''.

[[File:Two circles antihomothetic points.svg|thumb|right|300px|Figure 3: Lines through corresponding antihomologous points intersect on the radical axis of the two given circles (green and blue, centered on points '''C''' and '''D''', respectively).  The points '''P''' and '''Q''' are antihomologous, as are '''S''' and '''T'''.  These four points lie on a circle that intersects the two given circles.]]

A special case of this approach, seen in Figure 3, is carried out with [[Homothetic_center#Homologous_and_antihomologous_points|antihomologous]] points from an internal or external center of similarity.  Consider two rays emanating from an external homothetic center '''E'''. Let the antihomologous pairs of intersection points of these rays with the two given circles be denoted as '''P''' and '''Q''', and '''S''' and '''T''', respectively.  These four points lie on a common circle that intersects the two given circles in two points each.&lt;ref&gt;Johnson (1960), pp. 20&amp;ndash;21.&lt;/ref&gt;  Hence, the two lines joining '''P''' and '''S''', and '''Q''' and '''T''' intersect at the radical center of the three circles, which lies on the radical axis of the given circles.&lt;ref name="Johnson 1960, p. 41"&gt;Johnson (1960), p. 41.&lt;/ref&gt;  Similarly, the line joining two antihomologous points on separate circles and their tangents form an isosceles triangle, with both tangents being of equal length.&lt;ref&gt;Johnson (1960), p. 21.&lt;/ref&gt;  Therefore, such tangents meet on the radical axis.&lt;ref name="Johnson 1960, p. 41"/&gt;

==Algebraic construction==

[[File:Radical axis algebraic.svg|thumb|right|300px|Figure 4: Finding the radical axis algebraically.  ''L'' is the distance from '''J''' to '''K''', whereas ''x''&lt;sub&gt;1&lt;/sub&gt; and ''x''&lt;sub&gt;2&lt;/sub&gt; are the distances from '''K''' to '''B''' and from '''K''' to '''V''', respectively.  The variables ''d''&lt;sub&gt;1&lt;/sub&gt; and ''d''&lt;sub&gt;2&lt;/sub&gt; represent the distances from '''J''' to '''B''' and from '''J''' to '''V''', respectively.]]

Referring to Figure 4, the radical axis (red) is perpendicular to the blue line segment joining the centers '''B''' and '''V''' of the two given circles, intersecting that line segment at a point '''K''' between the two circles.  Therefore, it suffices to find the distance ''x''&lt;sub&gt;1&lt;/sub&gt; or ''x''&lt;sub&gt;2&lt;/sub&gt; from '''K''' to '''B''' or '''V''', respectively, where ''x''&lt;sub&gt;1&lt;/sub&gt;+''x''&lt;sub&gt;2&lt;/sub&gt; equals ''D'', the distance between '''B''' and '''V'''.

Consider a point '''J''' on the radical axis, and let its distances to '''B''' and '''V''' be denoted as ''d''&lt;sub&gt;1&lt;/sub&gt; and ''d''&lt;sub&gt;2&lt;/sub&gt;, respectively.  Since '''J''' must have the same [[power of a point|power]] with respect to both circles, it follows that

:&lt;math&gt;
d_{1}^{2} - r_{1}^{2} = d_{2}^{2} - r_{2}^{2} 
&lt;/math&gt;

where ''r''&lt;sub&gt;1&lt;/sub&gt; and ''r''&lt;sub&gt;2&lt;/sub&gt; are the radii of the two given circles.  By the [[Pythagorean theorem]], the distances ''d''&lt;sub&gt;1&lt;/sub&gt; and ''d''&lt;sub&gt;2&lt;/sub&gt; can be expressed in terms of ''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt; and ''L'', the distance from '''J''' to '''K'''

:&lt;math&gt;
L^{2} + x_{1}^{2}  - r_{1}^{2} = L^{2} + x_{2}^{2}  - r_{2}^{2} 
&lt;/math&gt;

By cancelling ''L''&lt;sup&gt;2&lt;/sup&gt; on both sides of the equation, the equation can be written 

:&lt;math&gt;
x_{1}^{2}  - x_{2}^{2} = r_{1}^{2}  - r_{2}^{2}
&lt;/math&gt;

Dividing both sides by ''D''&amp;nbsp;=&amp;nbsp;''x''&lt;sub&gt;1&lt;/sub&gt;+''x''&lt;sub&gt;2&lt;/sub&gt; yields the equation

:&lt;math&gt;
x_{1}  - x_{2} = \frac{r_{1}^{2}  - r_{2}^{2}}{D} 
&lt;/math&gt;

Adding this equation to ''x''&lt;sub&gt;1&lt;/sub&gt;+''x''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''D'' yields a formula for ''x''&lt;sub&gt;1&lt;/sub&gt;

:&lt;math&gt;
2x_{1} = D + \frac{r_{1}^{2}  - r_{2}^{2}}{D}
&lt;/math&gt;

Subtracting the same equation yields the corresponding formula for ''x''&lt;sub&gt;2&lt;/sub&gt;

:&lt;math&gt;
2x_{2} = D - \frac{r_{1}^{2}  - r_{2}^{2}}{D}
&lt;/math&gt;

==Determinant calculation==

If the circles are represented in [[trilinear coordinates]] in the usual way, then their radical center is conveniently given as a certain determinant.  Specifically, let ''X'' = ''x''&amp;nbsp;:&amp;nbsp;''y''&amp;nbsp;:&amp;nbsp;''z'' denote a variable point in the plane of a triangle ''ABC'' with sidelengths ''a'' = |''BC''|, ''b'' = |''CA''|, ''c'' = |''AB''|, and represent the circles as follows:

:(''dx + ey + fz'')(''ax + by + cz'') + ''g''(''ayz + bzx + cxy'') = 0

:(''hx + iy + jz'')(''ax + by + cz'') + ''k''(''ayz + bzx + cxy'') = 0

:(''lx + my + nz'')(''ax + by + cz'') + ''p''(''ayz + bzx + cxy'') = 0

Then the radical center is the point

:&lt;math&gt; \det \begin{bmatrix}g&amp;k&amp;p\\
e&amp;i&amp;m\\f&amp;j&amp;n\end{bmatrix} : \det \begin{bmatrix}g&amp;k&amp;p\\
f&amp;j&amp;n\\d&amp;h&amp;l\end{bmatrix} : \det \begin{bmatrix}g&amp;k&amp;p\\
d&amp;h&amp;l\\e&amp;i&amp;m\end{bmatrix}.&lt;/math&gt;

==Radical plane and hyperplane==

The '''radical plane''' of two nonconcentric spheres in three dimensions is defined similarly: it is the locus of points from which tangents to the two spheres have the same length.&lt;ref&gt;See [https://www.merriam-webster.com/dictionary/radical%20plane Merriam–Webster online dictionary].&lt;/ref&gt;  The fact that this locus is a plane follows by rotation in the third dimension from the fact that the radical axis is a straight line.  

The same definition can be applied to [[hypersphere]]s in [[Euclidean space]] of any dimension, giving the '''radical hyperplane''' of two nonconcentric hyperspheres.

==Notes==
{{reflist|1}}

==References==

*{{cite book | author = R. A. Johnson | year = 1960 | title = Advanced Euclidean Geometry: An Elementary Treatise on the Geometry of the Triangle and the Circle | edition = reprint of 1929 edition by Houghton Miflin | publisher = Dover Publications | location = New York | isbn = 978-0-486-46237-0 | pages = 31&amp;ndash;43 }}

==Further reading==
* {{Cite book | author = [[C. Stanley Ogilvy]] | year = 1990 | title = Excursions in Geometry | publisher = Dover | isbn = 0-486-26530-7 | pages = 17&amp;ndash;23}}
*{{cite book | title = Geometry Revisited | author = [[Harold Scott MacDonald Coxeter|H. S. M. Coxeter]], [[S. L. Greitzer]]| year = 1967 | publisher = [[Mathematical Association of America]] | location = [[Washington, D.C.]] | isbn = 978-0-88385-619-2 | pages = 31&amp;ndash;36, 160&amp;ndash;161}}
* Clark Kimberling, "Triangle Centers and Central Triangles," ''Congressus Numerantium'' 129 (1998) i–xxv, 1–295.

==External links==

{{commons cat|Radical axes}}

* {{mathworld|RadicalLine|Radical line}}
* {{mathworld|ChordalTheorem|Chordal theorem}}
* [http://www.cut-the-knot.org/Curriculum/Geometry/IncircleInSegment1.shtml Animation] at [[Cut-the-knot]]

[[Category:Circles]]
[[Category:Elementary geometry]]
[[Category:Analytic geometry]]</text>
      <sha1>tvp2g5c39b3kf21d54negit0ofrsfm6</sha1>
    </revision>
  </page>
  <page>
    <title>Ran space</title>
    <ns>0</ns>
    <id>42455846</id>
    <revision>
      <id>866537346</id>
      <parentid>866522156</parentid>
      <timestamp>2018-10-30T23:12:24Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Citation needed}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4691">In mathematics, the '''Ran space''' (or '''Ran's space''') of a [[topological space]] ''X'' is a topological space &lt;math&gt;\operatorname{Ran}(X)&lt;/math&gt; whose underlying set is the set of all nonempty finite subsets of ''X'': for a metric space ''X'' the topology is induced by the [[Hausdorff distance]].  The notion is named after [[Ziv Ran]].  It seems the notion was first introduced and popularized by [[Alexander Beilinson]] and [[Vladimir Drinfeld]] in the context of [[Chiral algebra]]s.{{Citation needed|date=October 2018}}


==Definition==
In general, the topology of the Ran space is generated by sets

: &lt;math&gt;\{ S \in \operatorname{Ran}(U_1 \cup \dots \cup U_m) \mid S \cap U_1 \ne \emptyset, \dots, S \cap U_m \ne \emptyset \}&lt;/math&gt;

for any disjoint open subsets &lt;math&gt;U_i \subset X, 1 \le i \le m&lt;/math&gt;.

There is an analog of a Ran space for a [[Scheme (mathematics)|scheme]]:&lt;ref&gt;http://www.math.harvard.edu/~lurie/282ynotes/LectureVII-Stacks.pdf&lt;/ref&gt; the '''Ran prestack''' of a [[quasi-projective scheme]] ''X'' over a field ''k'', denoted by &lt;math&gt;\operatorname{Ran}(X)&lt;/math&gt;, is the category where the objects are triples &lt;math&gt;(R, S, \mu)&lt;/math&gt; consisting of a finitely generated ''k''-algebra ''R'', a nonempty set ''S'' and a map of sets &lt;math&gt;\mu: S \to X(R)&lt;/math&gt; and where a morphism &lt;math&gt;(R, S, \mu) \to (R', S', \mu')&lt;/math&gt;  consists of a ''k''-algebra homomorphism &lt;math&gt;R \to R'&lt;/math&gt;, a surjective map &lt;math&gt;S \to S'&lt;/math&gt; that commutes with &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\mu'&lt;/math&gt;. Roughly, an ''R''-point of &lt;math&gt;\operatorname{Ran}(X)&lt;/math&gt; is a nonempty finite set of ''R''-rational points of ''X'' "with labels" given by &lt;math&gt;\mu&lt;/math&gt;. A theorem of Beilinson and Drinfeld continues to hold: &lt;math&gt;\operatorname{Ran}(X)&lt;/math&gt; is [[acyclic complex|acyclic]] if ''X'' is connected.

==Properties==
A theorem of Beilinson and Drinfeld states that the Ran space of a [[Connected space|connected]] [[manifold]] is [[weakly contractible]].&lt;ref&gt;{{cite book|last1=Beilinson|first1=Alexander|authorlink1=Alexander Beilinson|last2=Drinfeld|first2=Vladimir|authorlink2=Vladimir Drinfeld | title=Chiral algebras|date=2004|publisher=American Mathematical Society|isbn=0-8218-3528-9|page=173}}&lt;/ref&gt;

== Topological chiral homology ==
If ''F'' is a [[cosheaf]] on the Ran space &lt;math&gt;\operatorname{Ran}(M)&lt;/math&gt;, then its space of global sections is called the '''topological chiral homology''' of ''M'' with coefficients in ''F''. If ''A'' is, roughly, a family of commutative algebras parametrized by points in ''M'', then there is a [[factorizable sheaf]] associated to ''A''. Via this construction, one also obtains the topological chiral homology with coefficients in ''A''. The construction is a generalization of  [[Hochschild homology]].&lt;ref&gt;{{harvnb|Lurie|2016|loc=Theorem 5.5.3.11}}&lt;/ref&gt;
&lt;!--
== &lt;math&gt;\operatorname{Ran}_G(X)&lt;/math&gt; and nonabelian Poincaré duality ==

If ''G'' is trivial, &lt;math&gt;\operatorname{Ran}_G(X) = \operatorname{Ran}(X)&lt;/math&gt;

The basic idea is that one expects the forgetful functor &lt;math&gt;\operatorname{Ran}_G(X) \to \operatorname{Bun}_G(X)&lt;/math&gt; to be a "homotopy equivalence"&lt;ref&gt;http://cgp.ibs.re.kr/~gabriel/notes/spr11/lurie_may_23.pdf&lt;/ref&gt;. Instead of making this precise, one can show it is a universal homological equivalence; i.e., induces homological equivalence after the base change. For characteristic zero, this was proved in Gaitsgory's paper.

The basic question to keep in mind is what is the [[homotopy type]] of &lt;math&gt;\operatorname{Bun}_G(X)&lt;/math&gt;? The above thus gives an answer to this question. Since one thinks &lt;math&gt;\operatorname{Bun}_G(X)&lt;/math&gt; is something global, while &lt;math&gt;\operatorname{Ran}_G(X)&lt;/math&gt; is something local, this establishes the [[local-to-global principle]].

The idea may be also understood in terms of an analogy to "nonabelian Poincaré duality",&lt;ref&gt;{{harvnb|Lurie|2016|loc=Theorem 5.5.6.6.}}&lt;/ref&gt; which says, in one formulation, the space of compactly supported sections of a "bundle" ''E'' on a manifold ''M'' is the [[topological chiral homology]] of ''E''.

== D-modules on Ran space ==
{{expand-section}}

== Atiyah–Bott formula ==
{{expand-section}}
--&gt;

== See also ==
*[[Chiral homology]]

== Notes ==
{{reflist}}

== References ==
*[[Dennis Gaitsgory]], [https://arxiv.org/pdf/1108.1741.pdf Contractibility of the space of rational maps], 2012
*http://www.math.harvard.edu/~lurie/282ynotes/LectureVIII-Poincare.pdf
*Jacob Lurie, [http://www.math.harvard.edu/~lurie/papers/HA.pdf Higher Algebra], last updated March 2016.
*http://pantodon.shinshu-u.ac.jp/topology/literature/ja/exponential_space.html

{{geometry-stub}}

[[Category:Topological spaces]]</text>
      <sha1>fg68hifp6tse3r05afazp41f84i9zkx</sha1>
    </revision>
  </page>
  <page>
    <title>Romanovski polynomials</title>
    <ns>0</ns>
    <id>48536047</id>
    <revision>
      <id>858574535</id>
      <parentid>858573481</parentid>
      <timestamp>2018-09-08T04:36:41Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: pages. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19180">In [[mathematics]], '''Romanovski polynomials''' is an informal term for one of three finite subsets of real orthogonal polynomials discovered by [[Vsevolod Romanovsky]]&lt;ref&gt;{{cite journal|first=V. |last=Romanovski |title=Sur quelques classes nouvelles de polynomes orthogonaux |journal=C. R. Acad. Sci. Paris |volume=188 |date=1929 |page=1023 |language=French}}&lt;/ref&gt; (Romanovski in French transcription) within the context of probability distribution functions in statistics. They form an orthogonal subset of a more general family of little-known '''Routh polynomials''' introduced by [[Edward Routh|Edward John Routh]]&lt;ref&gt;{{cite journal|first=E. J. |last=Routh |title=On some properties of certain solutions of a differential equation of second order |journal=Proc. London Math. Soc. |volume=16 |date=1884 |page=245 |doi=10.1112/plms/s1-16.1.245}}&lt;/ref&gt; in 1884. The term '''Romanovski polynomials''' was put forward by Raposo,&lt;ref name="RAP"&gt;{{cite journal|first1=A. P. |last1=Raposo |first2=H. J. |last2=Weber |first3=D. E. |last3=Álvarez Castillo |first4=M. |last4=Kirchbach |title=Romanovski polynomials in selected physics problems |journal=Centr. Eur. J. Phys. |volume=5 |issue=3 |pages=253–284 |year=2007 |doi=10.2478/s11534-007-0018-5|arxiv=0706.3897 |bibcode=2007CEJPh...5..253R }}&lt;/ref&gt; with reference to the so-called 'pseudo-Jacobi polynomials in Lesky's classification scheme.&lt;ref&gt;{{cite journal|first=P. A. |last=Lesky |title=Endliche und unendliche Systeme von kontinuierlichen klassischen Orthogonalpolynomen |language=German |journal=Z. Angew. Math. Mech. |volume=76 |issue=3 |date=1996 |page=181 |doi=10.1002/zamm.19960760317|bibcode=1996ZaMM...76..181L }}&lt;/ref&gt; It seems more consistent to refer to them as '''Romanovski–Routh polynomials''', by analogy with the terms '''Romanovski–Bessel''' and '''Romanovski–Jacobi''' used by Lesky for two other sets of orthogonal polynomials.

In some contrast to the standard classical orthogonal polynomials, the polynomials under consideration differ, in so far as for arbitrary parameters only ''a finite number of them are orthogonal'', as discussed in more detail below.

==The differential equation for the Romanovski polynomials==

The Romanovski polynomials solve the following version of the [[hypergeometric differential equation]]

{{NumBlk|:|&lt;math&gt;
\begin{align}
&amp;\left(1+x^2\right) {R^{(\alpha,\beta)}_n}''(x) + t^{(\alpha,\beta)}_1(x) {R^{(\alpha,\beta)}_n}'(x) + \lambda_n R^{(\alpha,\beta) }_n(x) = 0,\\[4pt]
&amp; \qquad x\in (-\infty, +\infty ), \quad t^{(\alpha,\beta)}_1(x)=2\beta x +\alpha, \quad
\lambda_n -n(2\beta +n-1).
\end{align}
&lt;/math&gt;|{{EquationRef|1}}}}

Curiously, they have been omitted from the standard textbooks on [[special functions]] in mathematical physics&lt;ref name=Abramowitz&gt;{{cite book|first1=M.|last1=Abramowitz|authorlink1=Milton Abramowitz|first2=I.|last2=Stegun|authorlink2=Irene Stegun|year=1972|title=Handbook of Mathematical Functions with Formulas, Graphs and Mathematical Tables|publisher=Dover |edition=2nd |location=New York, NY|isbn=978-0-486-61272-0}}&lt;/ref&gt;&lt;ref&gt;{{cite book|first1=A. F. |last1=Nikiforov |first2=V. B. |last2=Uvarov |title=Special Functions of Mathematical Physics |publisher=Birkhäuser Verlag |location=Basel |date=1988}}&lt;/ref&gt; and in mathematics&lt;ref&gt;{{cite book|first=G. |last=Szego |title=Orthogonal Polynomials |publisher=American Mathematical Society |volume=23 |location=Providence, RI |date=1939}}&lt;/ref&gt;&lt;ref&gt;{{cite book|first=M. E. H. |last=Ismail |title=Classical and Quantum Orthogonal Polynomials in One Variable |publisher=Cambridge University Press |date=2005}}&lt;/ref&gt; and have only a relatively scarce presence elsewhere in the mathematical literature.&lt;ref&gt;{{cite journal|first=R. |last=Askey |title=An integral of Ramanujan and orthogonal polynomials |journal=J. Indian Math. Soc. |volume=51 |date=1987 |page=27}}&lt;/ref&gt;&lt;ref&gt;{{cite book|first=R. |last=Askey |contribution=Beta integrals and the associated orthogonal polynomials |title=Number Theory |date=1987 |volume=1395 |series=Lecture Notes in Math |publisher=Springer |location=Madras/Berlin |page=84}}&lt;/ref&gt;&lt;ref&gt;{{cite thesis|first=A. |last=Zarzo Altarejos |title=Differential Equations of the Hypergeometric Type |language=Spanish |type=PhD |publisher=Faculty of Science, University of Granada |date=1995}}&lt;/ref&gt;

The [[Sturm–Liouville theory|weight functions]] are 
{{NumBlk|:|&lt;math&gt;
w^{(\alpha,\beta)}(x) =\left(1+x^2\right)^{\beta-1} \exp\left(-\alpha \arccot x\right);
&lt;/math&gt;|{{EquationRef|2}}}}
they solve Pearson's differential equation 
{{NumBlk|:|&lt;math&gt;
[s(x) w(x)]' = t(x) w(x), \quad s(x)=1+x^2,
&lt;/math&gt;|{{EquationRef|3}}}}
that assures the [[Self adjoint operator|self-adjointness]] of the differential operator of the hypergeometric 
[[ordinary differential equation]].

For {{math|''α'' {{=}} 0}} and {{math|''β'' &lt; 0}}, the weight function of the Romanovski polynomials takes the shape of the [[Lorentz distribution|Cauchy distribution]], whence the associated polynomials are also denoted as Cauchy polynomials&lt;ref&gt;{{cite journal|first1=N. S. |last1=Witte |first2=P. J. |last2=Forrester |title=Gap probabilities in finite and scaled Cauchy random matrix ensembles |journal=Nonlinearity |volume=13 |issue=6 |pages=13–1986 |year=1965 |doi=10.1088/0951-7715/13/6/305|arxiv=math-ph/0009022 |bibcode=2000Nonli..13.1965W }}&lt;/ref&gt; in their applications in random matrix theory.&lt;ref&gt;{{cite book|first=P. J. |last=Forrester |title=Log-Gases and Random Matrices |series=London Mathematical Society Monographs |publisher=Princeton University Press |date=2010}}&lt;/ref&gt;

The Rodrigues formula specifies the polynomial {{math|''R''{{su|b=''n''|p=(''α'',''β'')}}(''x'')}} as
{{NumBlk|:|&lt;math&gt;
 R^{(\alpha,\beta)}_n(x)=N_n \frac{1}{w^{(\alpha,\beta )}(x)} \frac{\mathrm{d}^n}{\mathrm{d}x^n} \left(w^{(\alpha,\beta) }(x)s(x)^n \right), \quad
 0\leq n,
&lt;/math&gt;|{{EquationRef|4}}}}
where {{math|''N&lt;sub&gt;n&lt;/sub&gt;''}} is a normalization constant. This constant is related to the coefficient {{mvar|c&lt;sub&gt;n&lt;/sub&gt;}} of the term of degree {{mvar|n}} in the polynomial {{math|''R''{{su|b=''n''|p=(''α'',''β'')}}(''x'')}} by the expression
{{NumBlk|:|&lt;math&gt;
N_{n}= \frac{(-1)^{n} n! \, c_n}{\prod_{k=0}^{n-1} \lambda_n^{(k)}},\quad \lambda_n=-n\left({t^{(\alpha,\beta)}_n}' +
\tfrac{1}{2}(n-1)s''(x)\right),
&lt;/math&gt;|{{EquationRef|5}}}}
which holds for {{math|''n'' ≥ 1}}.

==Relationship between the polynomials of Romanovski and Jacobi==

As shown by Askey this finite sequence of real orthogonal polynomials can be expressed in terms of Jacobi polynomials of imaginary argument and thereby is frequently referred to as complexified Jacobi polynomials.&lt;ref&gt;{{cite journal|first=N. |last=Cotfas |title=Systems of orthogonal polynomials defined by hypergeometric type equations with application to quantum mechanics |journal=Centr. Eur. J. Phys. |volume=2 |issue=3 |pages=456–466 |date=2004 |doi=10.2478/bf02476425|arxiv=math-ph/0602037 |bibcode=2004CEJPh...2..456C }}&lt;/ref&gt; Namely, the Romanovski equation ({{EquationNote|1}}) can be formally obtained from the Jacobi equation,&lt;ref&gt;{{MathWorld|id=JacobiDifferentialEquation|title=Jacobi Differential Equation}}&lt;/ref&gt;
{{NumBlk|:|&lt;math&gt;
\begin{align}
&amp;\left(1-x^2\right) {P_n^{(\gamma,\delta)}}''(x) + t^{(\gamma,\delta)}_1(x) {P_n^{(\gamma,\delta )}}'(x) + \lambda_n P^{(\gamma, \delta)}_n(x) = 0, \\[4pt]
&amp;\qquad t^{(\gamma, \delta)}_1(x)=\delta -\gamma -(\gamma +\delta +2)x, \quad
\lambda_n= n(n+\gamma +\delta +1),\quad x\in \left[-1,1 \right],
\end{align}
&lt;/math&gt;|{{EquationRef|6}}}}
via the replacements, for real {{mvar|x}}, 
{{NumBlk|:|&lt;math&gt;
x\to ix, \quad \frac{\mathrm d}{{\mathrm d}x}\to -i\frac{\mathrm d}{{\mathrm d}x}, 
\quad \gamma=\delta^\ast =\beta -1 -\frac{\alpha i}{2},
&lt;/math&gt;|{{EquationRef|7}}}}
in which case one finds
{{NumBlk|:|&lt;math&gt;
R^{(\alpha,\beta)}_n(x) = i^n P^{\left(\beta - 1 - \frac{i}{2}\alpha,\beta -1 + \frac{i}{2}\alpha\right)}_n(ix),
&lt;/math&gt;|{{EquationRef|8}}}}
(with suitably chosen normalization constants for the Jacobi polynomials). However, this alternative expression is not useful when considering the orthogonality properties. The issue is that the orthogonality integrals of the complex Jacobi polynomials depend on the integration contour. In Kuijlaars ''et al.'' (2003)&lt;ref&gt;{{cite journal|first1=A. B. J. |last1=Kuijlaars |first2=A. |last2=Martinez-Finkelshtein |first3=R. |last3=Orive |title=Orthogonality of Jacobi polynomials with general parameters |journal=[[Electronic Transactions on Numerical Analysis|Electron. Trans. Num. Anal.]] |volume=19 |date=2003 |page=1}}&lt;/ref&gt; an orthogonality relation for Jacobi polynomials along the imaginary axis has been given, as required by the replacements in ({{EquationNote|7}}), but only for a limited case of real, not integer, parameters.

Notice the invertibility of ({{EquationNote|8}}) according to
{{NumBlk|:|&lt;math&gt;
P^{(\alpha,\beta)}_n(x) = (-i)^n R^{\left(i(\alpha-\beta), 
\frac{1}{2}(\alpha+\beta)+1)\right)}_n(-ix),
&lt;/math&gt;|{{EquationRef|9}}}}
where, now, {{math|''P''{{su|b=''n''|p=(''α'',''β'')}}(''x'')}} is a real Jacobi polynomial and
:&lt;math&gt;R^{\left(i(\alpha-\beta), \frac{1}{2}(\alpha+\beta)+1)\right)}_n(-ix)&lt;/math&gt; 
would be a complex Romanovski polynomial.

==Properties of Romanovski polynomials==

===Explicit construction===
For real {{math|''α'', ''β''}} and {{math|''n'' {{=}} 0, 1, 2, ...}}, a function {{math|''R''{{su|b=''n''|p=(''α'',''β'')}}(''x'')}} can be defined
by the Rodrigues formula in Equation ({{EquationNote|4}}) as
{{NumBlk|:|&lt;math&gt;
R_n^{(\alpha,\beta)}(x) \equiv \frac{1}{w^{(\alpha,\beta)}(x)} \frac{{\rm d}^n}{{\rm d}x^n}\left( w^{(\alpha,\beta)}(x) s(x)^n \right),
&lt;/math&gt;|{{EquationRef|10}}}}
where {{math|''w''&lt;sup&gt;(''α'',''β'')&lt;/sup&gt;}} is the same weight function as in ({{EquationNote|2}}), and {{math|''s''(''x'') {{=}} 1 + ''x''&lt;sup&gt;2&lt;/sup&gt;}} is the coefficient of the second derivative of the [[hypergeometric differential equation]] as in ({{EquationNote|1}}).

Note that we have chosen the normalization constants {{math|''N&lt;sub&gt;n&lt;/sub&gt;'' {{=}} 1}}, which is equivalent to making a choice of the coefficient of highest degree in the polynomial, as given by equation ({{EquationNote|5}}). It takes the form
{{NumBlk|:|&lt;math&gt;
 c_n = \frac{1}{n!} \prod_{k=0}^{n-1} \bigl ( 2 \beta (n-k) + n(n-1) - k(k-1)\bigr ),
\quad n\geq 1.
&lt;/math&gt;|{{EquationRef|11}}}}

Also note that the coefficient {{mvar|c&lt;sub&gt;n&lt;/sub&gt;}} does not depend on the parameter {{mvar|α}}, but only on {{mvar|β}} and, for particular values of {{mvar|β}}, {{mvar|c&lt;sub&gt;n&lt;/sub&gt;}} vanishes (i.e., for all the values 
:&lt;math&gt;\beta=\frac{k(k-1) - n(n-1)}{2(n-k)}&lt;/math&gt; 
where {{math|''k'' {{=}} 0, ..., ''n'' − 1}}). This observation poses a problem addressed below.

For later reference, we write explicitly the polynomials of degree 0, 1, and 2,
:&lt;math&gt; 
\begin{align}
R_0^{(\alpha,\beta)}(x) &amp; = 1, \\[6pt]
R^{(\alpha ,\beta )}_1(x) &amp; = \frac{1}{w^{(\alpha,\beta)}(x)}
\left(w'^{(\alpha,\beta)}(x)s(x)+s'(x)w^{(\alpha,\beta)}(x)\right)\\[6pt]
&amp; = t^{(\alpha,\beta)}(x)=2\beta x+\alpha,\\[6pt]
R^{(\alpha ,\beta )}_2(x) &amp; = \frac{1}{w^{(\alpha,\beta)}(x)}\frac{\mathrm d}{{\mathrm d}x}
\left(s^2(x) w'^{(\alpha,\beta)}(x)+2s(x)s'(x)w^{(\alpha,\beta)}(x)\right)\\
&amp; = \frac{1}{w^{(\alpha,\beta)}(x)}\frac{\mathrm d}{{\mathrm d}x}\left(s(x)w^{(\alpha,\beta)}(x)
\left(t^{(\alpha,\beta)}(x)+s'(x)\right)\right)\\[6pt]
&amp; = \left(2x+t^{(\alpha,\beta)}(x)\right)
t^{(\alpha,\beta)}(x)+\left(2+t'^{(\alpha,\beta)}(x)\right)s(x)\\[6pt]
&amp; = (2\beta+1)(2\beta+2) x^2 + 2(2\beta+1)\alpha x + \left(2\beta + \alpha^2 +2\right),
\end{align}
&lt;/math&gt;

which derive from the Rodrigues formula ({{EquationNote|10}}) in conjunction with Pearson's ODE ({{EquationNote|3}}).

===Orthogonality===
The two polynomials, {{math|''R''{{su|b=''m''|p=(''α'',''β'')}}(''x'')}} and {{math|''R''{{su|b=''n''|p=(''α'',''β'')}}(''x'')}} with {{math|''m'' ≠ ''n''}}, are orthogonal,&lt;ref name="RAP" /&gt;
{{NumBlk|:|&lt;math&gt;
\int_{-\infty}^{+\infty} w^{(\alpha, \beta )}(x)R_m^{(\alpha,\beta )}(x)R_n^{(\alpha,\beta )}(x)=0
&lt;/math&gt;|{{EquationRef|12}}}}

if and only if, 
{{NumBlk|:|&lt;math&gt;
m+n&lt; 1-2\beta.
&lt;/math&gt;|{{EquationRef|13}}}}

In other words, for arbitrary parameters, only a finite number of Romanovski polynomials are orthogonal. This property is referred to as ``finite orthogonality''. However, for some special cases in which the parameters depend in a particular way on the polynomial degree infinite orthogonality can be achieved.

This is the case of a version of equation ({{EquationNote|1}}) that has been independently encountered anew within the context of the exact solubility of the quantum mechanical problem of the trigonometric Rosen–Morse potential and reported in Compean &amp; Kirchbach (2006).&lt;ref name="CK"&gt;{{cite journal|first1=C. B. |last1=Compean |first2=M. |last2=Kirchbach |title=The trigonometric Rosen–Morse potential in supersymmetric quantum mechanics and its exact solutions |journal=J. Phys. A: Math. Gen. |volume=39 |issue=3 |pages=547–558 |date=2006 |doi=10.1088/0305-4470/39/3/007|arxiv=quant-ph/0509055 |bibcode=2006JPhA...39..547C }}&lt;/ref&gt; There, the polynomial parameters {{mvar|α}} and {{math|β}} are no longer arbitrary but are expressed in terms of the potential parameters, {{mvar|a}} and {{mvar|b}}, and the degree {{mvar|n}} of the polynomial according to the relations,

{{NumBlk|:|&lt;math&gt;
\begin{align}
\alpha\to \alpha_n=\frac{2b}{n+1+a}, \quad \beta \to \beta_n= -(a+n+1) +1, \quad n=0,1,2,\ldots, \infty.
\end{align}
&lt;/math&gt;|{{EquationRef|14}}}}

Correspondingly, {{mvar|λ&lt;sub&gt;n&lt;/sub&gt;}} emerges as {{math|''λ&lt;sub&gt;n&lt;/sub&gt;'' {{=}} −''n''(2''a'' + ''n'' − 1)}}, while the weight function takes the shape
:&lt;math&gt;\left(1+x^2\right)^{-(a+n+1) }\exp\left(-\frac{2b}{n+a+1} \arccot x\right).&lt;/math&gt;
Finally, the one-dimensional variable, {{mvar|x}}, in Compean &amp; Kirchbach (2006)&lt;ref name="CK" /&gt; has been taken as
:&lt;math&gt;x=\cot\left( \frac{r}{d}\right),&lt;/math&gt;
where {{mvar|r}} is the radial distance, while &lt;math&gt;d&lt;/math&gt; is an appropriate length parameter. In Compean &amp; Kirchbach&lt;ref name="CK" /&gt; it has been shown that the family of Romanovski polynomials corresponding to the infinite sequence of parameter pairs, 
{{NumBlk|:|&lt;math&gt;
\left(\alpha_1,\beta_1\right),\left(\alpha_2\beta_2\right),\ldots, \left(\alpha_n\beta_n\right),\ldots, \quad n \longrightarrow \infty , 
&lt;/math&gt;|{{EquationRef|15}}}}
is orthogonal.

===Generating function===
In Weber (2007)&lt;ref name="HJW"&gt;{{cite journal|first=H. J. |last=Weber |title=Connection between Romanovski polynomials and other polynomials |journal=Centr. Eur. J. Math. |volume=5 |issue=3 |date=2007 |page=581 |doi=10.2478/s11533-007-0014-4|arxiv=0706.3153 }}&lt;/ref&gt; polynomials {{math|''Q''{{su|b=''ν''|p=(''α&lt;sub&gt;n&lt;/sub&gt;'', ''β&lt;sub&gt;n&lt;/sub&gt;'' + ''n'')}}(''x'')}}, with {{math|''β&lt;sub&gt;n&lt;/sub&gt;'' + ''n'' {{=}} −''a''}}, and complementary to {{math|''R''{{su|p=(''α&lt;sub&gt;n&lt;/sub&gt;'', ''β&lt;sub&gt;n&lt;/sub&gt;'')|b=''n''}}(''x'')}} have been studied, generated in the following way:

{{NumBlk|:|&lt;math&gt;
Q_\nu^{\left(\alpha_n, \beta_n+n\right)}(x)=
\frac{1}{w^{\left(\alpha_n,\beta_n +n-\nu \right)}}
\frac{{\mathrm d}^\nu}{{\mathrm d}x^\nu}
w^{\left(\alpha_n,\beta_n\right)}(x)\left(1+x^2\right)^n.
&lt;/math&gt;|{{EquationRef|16}}}}

In taking into account the relation,

{{NumBlk|:|&lt;math&gt;
w^{\left(\alpha_n,\beta_n\right)}(x)\left(1+x^2\right)^\delta =w^{\left(\alpha_n,\beta_n+\delta \right) }(x),
&lt;/math&gt;|{{EquationRef|17}}}}

Equation ({{EquationNote|16}}) becomes equivalent to

{{NumBlk|:|&lt;math&gt;\begin{align} 
Q_\nu^{\left(\alpha_n, \beta_n+n\right)}(x)&amp; =
\frac{1}{w^{\left(\alpha_n,\beta_n +n-\nu\right)}}
\frac{{\mathrm d}^\nu}{{\mathrm d}x^\nu}
w^{\left(\alpha_n,\beta_n +n-\nu\right)}(x)\left(1+x^2\right)^\nu\\[4pt]
&amp;=R_\nu^{\left(\alpha_n,\beta_n+n-\nu\right)}(x),
\end{align} &lt;/math&gt;|{{EquationRef|18}}}}

and thus links the complementary to the principal Romanovski polynomials.

The main attraction of the complementary polynomials is that their [[generating function]] can be calculated in closed form.&lt;ref&gt;{{cite journal|first=H. J. |last=Weber |title=Connections between real polynomial solutions of hypergeometric-type differential equations with Rodrigues formula |journal=Centr. Eur. J. Math. |volume=5 |issue=2 |pages=415–427 |date=2007 |doi=10.2478/s11533-007-0004-6|arxiv=0706.3003 }}&lt;/ref&gt; Such a [[generating function]], written for the Romanovski polynomials based on Equation ({{EquationNote|18}}) with the parameters in ({{EquationNote|14}}) and therefore referring to infinite orthogonality, has been introduced as
{{NumBlk|:|&lt;math&gt;
G^{\left(\alpha_n, \beta_n\right)}(x,y) =\sum_{\nu=0}^{\infty}R_\nu^{\left(\alpha_n,\beta_{n}+n-\nu \right)}(x)\frac{y^\nu}{\nu !}.
&lt;/math&gt;|{{EquationRef|19}}}}

The notational differences between Weber&lt;ref name="HJW" /&gt; and those used here are summarized as follows:
*{{math|''G''&lt;sup&gt;(''α&lt;sub&gt;n&lt;/sub&gt;'', ''β&lt;sub&gt;n&lt;/sub&gt;'')&lt;/sup&gt;(''x'',''y'')}} here versus {{math|''Q''(''x'',''y'';''α'',−''a'')}} there, {{mvar|α}} there in place of {{mvar|α&lt;sub&gt;n&lt;/sub&gt;}} here,
*{{math|''a'' {{=}} −''β&lt;sub&gt;n&lt;/sub&gt;'' − ''n''}}, and
*{{math|''Q''{{su|p=(''α'',−''a'')|b=''ν''}}(''x'')}} in Equation (15) in Weber&lt;ref name="HJW" /&gt; corresponding to {{math|''R''{{su|b=''ν''|p=(''α&lt;sub&gt;n&lt;/sub&gt;'', ''β&lt;sub&gt;n&lt;/sub&gt;'' + ''n'' − ''ν'')}}(''x'')}} here. 
The generating function under discussion obtained in Weber&lt;ref name="HJW" /&gt; now reads:

{{NumBlk|:|&lt;math&gt;
G^{(\alpha_n, \beta_n)}(x,y)=
\left(1+x^2\right)^{-\beta_n -n +1}\exp\left(\alpha_n\arccot x\right)
\left( 1+\left(x+y\left(1+x^2\right)\right)^2\right)^{-\left(-\beta_{n}-n +1\right)}\exp\left(-\alpha_n\arccot \left(x+y\left(1+x^2\right)\right)\right.
&lt;/math&gt;|{{EquationRef|20}}}}

==Recurrence relations==

[[Recurrence relations]] between the infinite orthogonal series of Romanovski polynomials with the parameters in the above equations ({{EquationNote|14}}) follow from the [[generating function]],&lt;ref name="HJW" /&gt;

{{NumBlk|:|&lt;math&gt;
\nu\bigl(\nu+1-2(\beta_n+n)\bigr)R_{\nu-1}^{\left(\alpha_n, \beta_{n}+n-\nu+1\right)}(x)+\frac{\mathrm d}{{\mathrm d}x}R_\nu^{\left(\alpha_n,\beta_{n}+n-\nu\right)}(x)=0,
&lt;/math&gt;|{{EquationRef|21}}}}
and
{{NumBlk|:|&lt;math&gt;
R^{\left(\alpha_n,\beta_{n}+n-\nu -1\right)}_{\nu+ 1}(x) = 
\bigl(\alpha_n -2x(-\beta_n-n+\nu +1) \bigr) R_\nu^{\left(\alpha_n, \beta_{n}+n-\nu\right)}
 -\nu \left(1+x^2\right)\bigl(2(-\beta_n -n) +\nu +1\bigr) R_{\nu -1} ^{\left(\alpha_n,\beta_{n}+n -\nu +1\right)},
&lt;/math&gt;|{{EquationRef|22}}}}

as Equations (10) and (23) of Weber (2007)&lt;ref name="HJW" /&gt; respectively.

==See also==
{{div col|colwidth=20em}}
* [[Associated Legendre function]]s
* [[Gaussian quadrature]]
* [[Gegenbauer polynomials]]
* [[Legendre rational functions]]
* [[Turán's inequalities]]
* [[Legendre wavelet]]
* [[Jacobi polynomials]]
* [[Legendre polynomials]]
* [[Spherical harmonics]]
{{div col end}}

==References==
{{lacking ISBN|date=December 2017}}&lt;!--- and DOIs ---&gt;
{{reflist|30em}}
{{Authority control}}

{{DEFAULTSORT:Romanovski Polynomials}}
[[Category:Special hypergeometric functions]]
[[Category:Orthogonal polynomials]]
[[Category:Polynomials]]</text>
      <sha1>sioqwzb9ucrt679m378i04ge81ep9nh</sha1>
    </revision>
  </page>
  <page>
    <title>Samuel Vince</title>
    <ns>0</ns>
    <id>3386222</id>
    <revision>
      <id>847759551</id>
      <parentid>823047609</parentid>
      <timestamp>2018-06-27T15:47:00Z</timestamp>
      <contributor>
        <username>CitationCleanerBot</username>
        <id>15270283</id>
      </contributor>
      <minor/>
      <comment>/* Works */cleanup</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4590">[[Image:Samuel-Vince.jpg|thumb|right|Samuel Vince]]
[[File:Astronomy; Samuel Vince reading in his rooms at Sidney Susse Wellcome V0024858.jpg|thumb|
Vince at Cambridge
|alt=Old man sits, reading by lamplight]]
'''Samuel Vince''' (6 April 1749 – 28 November 1821) was an [[England|English]] clergyman, mathematician and astronomer at the [[University of Cambridge]].

==Life==
He was born in [[Fressingfield]]. The son of a plasterer, Vince was admitted as a [[sizar]] to [[Caius College, Cambridge]] in 1771.&lt;ref name=Venn&gt;{{acad|VN771S|Samuel Vince}}&lt;/ref&gt; In 1775 he was [[Senior Wrangler]], and Winner of the [[Smith Prize]] at Cambridge. Migrating to [[Sidney Sussex College, Cambridge|Sidney Sussex College]] in 1777, he gained his M.A. in 1778 and was ordained a clergyman in 1779.&lt;ref name=Venn /&gt;

He was awarded the [[Copley Medal]] in 1780 and was [[Plumian Professor of Astronomy and Experimental Philosophy]] at Cambridge from 1796 until his death. He became [[Archdeacon of Bedford]] in 1809, and died in [[Ramsgate]].&lt;ref name=Venn/&gt;

==Works==
As a mathematician, Vince wrote on many aspects of his expertise, including [[logarithms]] and  [[imaginary numbers]]. His ''Observations on the Theory of the Motion and Resistance of Fluids''&lt;ref&gt;{{Cite journal|last=Vince|first=Samuel|date=1795|title=The Bakerian Lecture. Observations on the Theory of the Motion and Resistance of Fluids; With a Description of the Construction of Experiments, in Order to Obtain Some Fundamental Principles. By the Rev. Samuel Vince, A. M. F. R. S.|jstor=106943|journal=Philosophical Transactions of the Royal Society of London|volume=85|pages=24–45}}&lt;/ref&gt; and ''Experiments upon the Resistance of Bodies Moving in Fluids''&lt;ref&gt;{{Cite journal|last=Vince|first=Samuel|date=1798|title=The Bakerian Lecture. Experiments upon the Resistance of Bodies Moving in Fluids. By the Rev. Samuel Vince, A. M. F. R. S. Plumian Professor of Astronomy and Experimental Philosophy in the University of Cambridge|jstor=106967|journal=Philosophical Transactions of the Royal Society of London|volume=88|pages=1–14}}&lt;/ref&gt; had later importance to [[History of aviation|aviation history]]. He was also author of the influential ''A Complete System of Astronomy'' (3 vols. 1797-1808).

Vince also published the pamphlet ''The Credibility of Christianity Vindicated, In Answer to Mr. Hume's Objections; In Two Discourses Preached Before the University of Cambridge by the Rev. S. Vince''. In this work, Vince made an apology of the Christian religion and, like [[Charles Babbage]], sought to present rational arguments in favor of the belief in [[miracles]], against [[David Hume]]'s criticism. A review of this work with direct quotations can be found in ''[[The British Critic]]'', Volume 12, 1798.&lt;ref&gt;[https://books.google.com/books?id=52tAAQAAMAAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false The British Critic, Volume 12] (1798). F. and C. Rivington. pp. 258-263.&lt;/ref&gt;

==References==
{{reflist}}

==External links==
{{Wikiquote}}
*[https://archive.org/stream/ondivisionsamong00vinciala#page/n7/mode/2up On the divisions among Christians: A charge, delivered to the clergy of the archdeaconry of Bedford] (1810)
*{{cite web|url=http://www.nasm.si.edu/wrightbrothers/fly/1900/designing.cfm|title=The Wright Brothers: Designing the 1900 Wright Glider|work=[[National Air and Space Museum]]|publisher=[[Smithsonian Institution]]|deadurl=yes|archiveurl=https://web.archive.org/web/20110927002349/http://www.nasm.si.edu/wrightbrothers/fly/1900/designing.cfm|archivedate=2011-09-27|df=}}
*[http://www.royalsoc.ac.uk/page.asp?id=1794 Royal Society]
*[http://janus.lib.cam.ac.uk/db/node.xsp?id=CV%2FPers%2FVince%2C%20Samuel%20(1749-1821)%20mathematician%20and%20astronomer Janus (Cambridge library)]
*{{DNB Cite|wstitle=Vince, Samuel|volume=58}}

{{Copley Medallists 1751-1800}}

{{Authority control}}

{{DEFAULTSORT:Vince, Samuel}}
[[Category:1749 births]]
[[Category:1821 deaths]]
[[Category:18th-century English mathematicians]]
[[Category:19th-century English mathematicians]]
[[Category:Archdeacons of Bedford]]
[[Category:Academics of the University of Cambridge]]
[[Category:Recipients of the Copley Medal]]
[[Category:Fellows of the Royal Society]]
[[Category:Alumni of Gonville and Caius College, Cambridge]]
[[Category:Alumni of Sidney Sussex College, Cambridge]]
[[Category:Senior Wranglers]]
[[Category:Place of birth unknown]]
[[Category:Date of death unknown]]
[[Category:18th-century English Anglican priests]]
[[Category:19th-century English Anglican priests]]
[[Category:People from Fressingfield]]</text>
      <sha1>tp6gdqqrkqyilg2vxo3m9rqsixnm0pq</sha1>
    </revision>
  </page>
  <page>
    <title>Sanov's theorem</title>
    <ns>0</ns>
    <id>31587409</id>
    <revision>
      <id>847608517</id>
      <parentid>750089350</parentid>
      <timestamp>2018-06-26T15:29:01Z</timestamp>
      <contributor>
        <username>Dwmalone</username>
        <id>954299</id>
      </contributor>
      <comment>Add issue number. Include reference to original Russian version.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2299">{{multiple issues|
{{context|date=February 2012}}
{{no footnotes|date=February 2012}}
}}

In [[information theory]], '''Sanov's theorem''' gives a bound on the probability of observing an [[Typical set|atypical]] sequence of samples from a given [[probability distribution]].

Let ''A'' be a set of probability distributions over an alphabet ''X'', and let ''q'' be an arbitrary distribution over ''X'' (where ''q'' may or may not be in ''A'').  Suppose we draw ''n'' [[Independent and identically distributed random variables|i.i.d.]] samples from ''q'', represented by the vector &lt;math&gt;x^n = x_1, x_2, \ldots, x_n&lt;/math&gt;.  Further, let us ask that the [[Empirical distribution function|empirical distribution]], &lt;math&gt;\hat{p}_{x^n}&lt;/math&gt;, of the samples falls within the set ''A''—formally, we write &lt;math&gt;\{x^n : \hat{p}_{x^n} \in A\}&lt;/math&gt;. Then,

:&lt;math&gt;q^n(x^n) \le (n+1)^{|X|} 2^{-nD_{\mathrm{KL}}(p^*||q)}&lt;/math&gt;,

where
* &lt;math&gt;q^n(x^n)&lt;/math&gt; is shorthand for &lt;math&gt;q(x_1)q(x_2) \cdots q(x_n)&lt;/math&gt;, and
* &lt;math&gt;p^*&lt;/math&gt; is the [[information projection]] of ''q'' onto ''A''.

In words, the probability of drawing an atypical distribution is proportional to the [[Kullback–Leibler divergence|KL distance]] from the true distribution to the atypical one; in the case that we consider a set of possible atypical distributions, there is a dominant atypical distribution, given by the information projection.

Furthermore, if ''A'' is the [[Closure (topology)|closure]] of its [[Interior (topology)|interior]],

:&lt;math&gt;\lim_{n\to\infty}\frac{1}{n}\log q^n(x^n) = -D_{\mathrm{KL}}(p^*||q).&lt;/math&gt;

==References==

*{{Cite book
  | last1 = Cover  | first1 = Thomas M.
  | last2 = Thomas | first2 = Joy A.
  | title = Elements of Information Theory
  | publisher = Wiley Interscience
  | edition = 2
  | date = 2006
  | location = Hoboken, New Jersey
  | pages = 362}}

*Sanov, I. N. (1957) "On the probability of large deviations of random variables". ''Mat. Sbornik'' 42(84), No. 1, 11–44.
*Санов, И. Н. (1957) "О вероятности больших отклонений случайных величин". ''МАТЕМАТИЧЕСКИЙ СБОРНИК' 42(84), No. 1, 11–44.

[[Category:Information theory]]
[[Category:Probabilistic inequalities]]


{{probability-stub}}</text>
      <sha1>amruiukfozqewhlzsn7iypsuzp37iro</sha1>
    </revision>
  </page>
  <page>
    <title>Social software (social procedure)</title>
    <ns>0</ns>
    <id>1186980</id>
    <revision>
      <id>845068872</id>
      <parentid>788343450</parentid>
      <timestamp>2018-06-09T03:58:42Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>adding links to references using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7471">{{About|the field of research|computer software used for social interaction|Social software}}

In philosophy and the social sciences, '''social software''' is an interdisciplinary research program that borrows
mathematical tools and techniques from game theory and computer science in order to analyze and design [[social procedure]]s. The goals of research in this field are modeling social situations, developing theories of correctness, and designing social procedures.&lt;ref name=Pacuit10&gt;Pacuit (2005), p.10&lt;/ref&gt;

Work under the term social software has been going on since about 1996, and conferences in Copenhagen, London, Utrecht and New York, have been partly or wholly devoted to it. Much of the work is carried out at the [[City University of New York]] under the leadership of [[Rohit Jivanlal Parikh]], who was influential in the development of the field.

== Goals and tools ==
Current research in the area of social software include the analysis of social procedures and examination of them for fairness, appropriateness, correctness and efficiency.  For example, an election procedure could be a simple majority vote, [[Borda count]], a Single Transferable vote (STV), or Approval voting.  All of these procedures can be examined for various properties like monotonicity.  Monotonicity has the property that voting for a candidate should not harm that candidate.  This may seem obvious, true
under any system, but it is something which can happen in STV.{{Citation needed|date=March 2009}} Another question would be the ability to elect a Condorcet winner in case there is one. 

Other principles which are considered by researchers in social software include the concept that a procedure for fair division should be Pareto optimal, equitable and envy free.  A procedure for auctions should be one which would encourage bidders to bid their actual valuation – a property which holds with the Vickrey auction.

What is new in social software compared to older fields is the use of tools from computer science like program logic, [[analysis of algorithms]] and epistemic logic. Like programs, social procedures dovetail into each other. For instance an airport provides runways for planes to land, but it also provides security checks, and it must provide for ways in which buses and taxis can take arriving passengers to their local destinations. The entire mechanism can be analyzed in the way in which a complex computer program can be analyzed. The Banach-Knaster procedure for dividing a cake fairly, or the [[Steven Brams|Brams]] and Taylor procedure for fair division have been analyzed in this way. To point to the need for epistemic logic, a building not only needs restrooms, for obvious reasons, it also needs signs indicating where they are.  Thus epistemic considerations enter in addition to structural ones. For a more urgent example, in addition to medicines, physicians also need tests to indicate what a patient’s problem is.

== See also==
* [[Dynamic logic (modal logic)|Dynamic logic]]
* [[Epistemic logic]]
* [[Fair division]]
* [[Game theory]]
* [[Mechanism design]]
* [[No-trade theorem]]
* [[Social procedure]]
* [[Social technology]]

==Notes==
{{Reflist}}

== Further reading ==
* [[John Searle]], ''The Construction of Social Reality'' (1995)  New York : Free Press, c1995.
* [[Rohit Jivanlal Parikh|Rohit Parikh]], “Social Software,” ''Synthese'', 132, Sep 2002, 187-211.
* Eric Pacuit and [[Rohit Jivanlal Parikh|Rohit Parikh]],  "Social Interaction, Knowledge, and Social Software", in  ''Interactive Computation: The New Paradigm'', ed.  Dina Goldin, Sott Smolka, Peter Wegner, Springer 2007, 441-461.
* [[Ludwig Wittgenstein]], ''Philosophical Investigations,'' Macmillan, 1953.
* [[Jaakko Hintikka]], ''Knowledge and Belief: an introduction to the logic of the two notions'', Cornell University press, 1962, {{ISBN|9781904987086}}
* D. Lewis, ''Convention, a Philosophical Study'', Harvard U. Press, 1969.
* R. Aumann, Agreeing to disagree, ''Annals of Statistics'', 4 (1976) 1236-1239.
* {{cite journal|author=[[Paul Milgrom]] and [[Nancy Stokey]]|title=Information, trade and common knowledge|journal=Journal of Economic Theory|volume=26|issue=1|pages=17–27|year=1982|url=http://www.kellogg.northwestern.edu/research/math/papers/377.pdf|doi=10.1016/0022-0531(82)90046-1}}
* J. Geanakoplos and H. Polemarchakis, We Can't Disagree Forever, ''J. Economic Theory'', 28 (1982), 192-200.
* [[Rohit Jivanlal Parikh|R. Parikh]] and P. Krasucki, Communication, Consensus and Knowledge, ''J. Economic Theory'' 52 (1990) pp.&amp;nbsp;178–189.
* [[W. Brian Arthur]]. [https://ocw.tudelft.nl/wp-content/uploads/ElFarolArtur1994.pdf Inductive reasoning and bounded rationality]. ''Complexity in Economic Theory'', 84(2):406-411, 1994.
* [[Ronald Fagin]], [[Joseph Halpern]], [[Yoram Moses]] and [[Moshe Vardi]], ''Reasoning about Knowledge'', MIT Press 1995.
* Steven Brams and Alan Taylor, ''The Win-Win Solution: guaranteeing fair shares to everybody,'' Norton 1999.
* [[David Harel]], [[Dexter Kozen]] and [[Jerzy Tiuryn]], ''Dynamic Logic'', MIT Press, 2000.
* Michael Chwe, ''Rational ritual : culture, coordination, and common knowledge'',  Princeton University Press, 2001.
* Marc Pauly, ''Logic for Social Software'', Ph.D. Thesis, University of Amsterdam. ILLC Dissertation Series 2001-10, {{ISBN|90-6196-510-1}}.
* [[Rohit Jivanlal Parikh|Rohit Parikh]], Language as social software, in  ''Future Pasts: the Analytic Tradition in Twentieth Century Philosophy'', Ed. J. Floyd and S. Shieh, Oxford U. Press, 2001, 339-350.
* [[Rohit Jivanlal Parikh|Parikh, R.]] and Ramanujam, R., A knowledge based semantics of messages, in ''J. Logic, Language, and Information'', 12, pp.&amp;nbsp;453 – 467, 2003.
* Eric Pacuit, [http://ai.stanford.edu/~epacuit/thesis.html'' Topics in Social Software: Information in Strategic Situations''], Doctoral dissertation, City University of New York (2005).
* Eric Pacuit, [[Rohit Jivanlal Parikh|Rohit Parikh]] and Eva Cogan, The Logic of Knowledge Based Obligation, ''Knowledge, Rationality and Action'', a subjournal of ''Synthese'', 149(2), 311 – 341, 2006.
* Eric Pacuit and [[Rohit Jivanlal Parikh|Rohit Parikh]], Reasoning about Communication Graphs, in Interactive Logic, Edited by Johan van Benthem, Dov Gabbay and [[Benedikt Lowe]] (2007).
* Mike Wooldridge, Thomas Ågotnes, Paul E. Dunne, and Wiebe van der Hoek. Logic for Automated Mechanism Design - A Progress Report. In ''Proceedings of the Twenty-Second Conference on Artificial Intelligence (AAAI-07''), Vancouver, Canada, July 2007.

== External links ==
*[http://web.cs.gc.cuny.edu/~kgb/ Knowledge, Games and Beliefs Group]. City University of New York, Graduate Center.
*[http://www.philog.ruc.dk/phiconf4.html Social Software conference]. Carlsberg Academy, Copenhagen. May 27–29, 2004. Retrieved on 2009-06-26.
*[http://www.illc.uva.nl/ADMW05/ Interactive Logic: Games and Social Software workshop]. King's College, London. November 4–7, 2005. Retrieved on 2009-06-26.
* [http://www.lorentzcenter.nl/lc/web/2006/235/info.php3?wsid=235 Games, action and social software workshop]. Lorentz Center, Leiden University, Netherlands. 30 Oct 2006&amp;ndash;3 Nov 2006. Retrieved on 2009-06-26.
* [http://web.cs.gc.cuny.edu/~kgb/socsoft/ Social Software Mini-conference]. Knowledge, Games and Beliefs Group, City University of New York. May 18–19, 2007. Retrieved on 2009-06-26.

[[Category:Game theory]]
[[Category:Logic]]</text>
      <sha1>2lo7d8xa76xw5oyvaz9didqlbmq52xj</sha1>
    </revision>
  </page>
  <page>
    <title>Statistical interference</title>
    <ns>0</ns>
    <id>10988372</id>
    <revision>
      <id>827545063</id>
      <parentid>800624578</parentid>
      <timestamp>2018-02-25T09:43:21Z</timestamp>
      <contributor>
        <username>Rathfelder</username>
        <id>398607</id>
      </contributor>
      <comment>-[[Category:Engineering]]; -[[Category:Quality]]; -[[Category:Standards]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4214">{{Distinguish|Statistical inference}}

When two [[probability distribution]]s overlap, '''statistical interference''' exists.  Knowledge of the distributions can be used to determine the likelihood that one parameter exceeds another, and by how much.

This technique can be used for dimensioning of mechanical parts, determining when an applied load exceeds the strength of a structure, and in many other situations.   This type of analysis can also be used to estimate the ''probability of failure'' or the ''frequency of failure''.

==Dimensional interference==
[[File:Interference.jpg|right|thumb|300px|Interference of measurement distributions to determine fit of parts]]

Mechanical parts are usually designed to fit precisely together. For example, if a shaft is designed to have a "sliding fit" in a hole, the shaft must be a little smaller than the hole. (Traditional [[tolerance (engineering)|tolerances]] may suggest that all dimensions fall within those intended tolerances.  A [[process capability]] study of actual production, however, may reveal [[normal distribution]]s with long tails.) Both the shaft and hole sizes will usually form normal distributions with some average ([[arithmetic mean]]) and [[standard deviation]].

With two such normal distributions, a distribution of interference can be calculated.  The derived distribution will also be normal, and its average will be equal to the difference between the means of the two base distributions.  The [[variance]] of the derived distribution will be the sum of the variances of the two base distributions.

This derived distribution can be used to determine how often the difference in dimensions will be less than zero (i.e., the shaft cannot fit in the hole), how often the difference will be less than the required sliding gap (the shaft fits, but too tightly), and how often the difference will be greater than the maximum acceptable gap (the shaft fits, but not tightly enough).

==Physical property interference==
[[File:Interference Forces.jpg|right|thumb|300px|Interference of distributions of applied load and strength]]

Physical properties and the conditions of use are also inherently variable.  For example, the applied load (stress) on a mechanical part may vary.  The measured strength of that part (tensile strength, etc.) may also be variable.  The part will break when the stress exceeds the strength.&lt;ref&gt;{{Citation
  | last = Sundarth
  | first = S
  | last2 = Woeste, Frank E.; Galligan, William
  | first2 = 
  | title = Differential reliability : probabilistic engineering applied to wood members in bending-tension
  | publisher = US Forest Products Laboratory
  | series = 
  | volume = Res. Pap. FPL-RP-302. 
  | origyear =
  | year = 1978
  | url = http://www.fpl.fs.fed.us/documnts/fplrp/fplrp302.pdf
| accessdate =21 January 2015}}&lt;/ref&gt;
&lt;ref&gt;{{Citation
  | last = Long
  | first = M W
  | last2 = Narcico
  | first2 = J D
  | title = Probabilistic Design Methodology for Composite Aircraft Structures, DOT/FAA/AR-99/2
  | publisher = FAA
  | series = 
  |date=June 1999
  
| url = http://oai.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA365683
| accessdate =24 January 2015}}&lt;/ref&gt;

With two normal distributions, the statistical interference may be calculated as above. (This problem is also workable for transformed units such as the [[log-normal distribution]]).  With other distributions, or combinations of different distributions, a [[Monte Carlo method]] or simulation is often the most practical way to quantify the effects of statistical interference.

==See also==
*[[Interference fit]]
*[[Joint probability distribution]]
*[[Probabilistic design]]
*[[Process capability]]
*[[Reliability engineering]]
*[[Specification]]
*[[Tolerance (engineering)]]

==References==

{{reflist}}

*Paul H. Garthwaite, Byron Jones, Ian T. Jolliffe (2002) ''Statistical Inference''.  {{ISBN|0-19-857226-3}}
*Haugen, (1980) ''Probabilistic mechanical design'',  Wiley. {{ISBN|0-471-05847-5}}

{{DEFAULTSORT:Statistical Interference}}
[[Category:Statistical theory]]
[[Category:Survival analysis]]
[[Category:Reliability engineering]]
[[Category:Probability theory]]
[[Category:Applied probability]]</text>
      <sha1>luae288hewgo3dsxn06n698j4u701mj</sha1>
    </revision>
  </page>
  <page>
    <title>Strong Law of Small Numbers</title>
    <ns>0</ns>
    <id>18093481</id>
    <revision>
      <id>787351126</id>
      <parentid>787008443</parentid>
      <timestamp>2017-06-24T22:10:57Z</timestamp>
      <contributor>
        <username>Bellerophon5685</username>
        <id>1258165</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3854">{{Other uses|Law of small numbers (disambiguation)}}

In [[mathematics]], the "'''Strong Law of Small Numbers'''" is the humorous title of a popular paper by mathematician [[Richard K. Guy]] and also the so-called [[Law (principle)|law]] that proclaims: 
{{quote|''"There aren't enough small numbers to meet the many demands made of them."''&lt;ref&gt;{{Cite journal
|last=Guy
|first=Richard K.
|authorlink=Richard K. Guy
|year=1988
|title=The Strong Law of Small Numbers
|journal=[[American Mathematical Monthly]]
|volume=95
|issue=8
|pages=697–712
|issn=0002-9890
|pmid=
|pmc=
|doi=10.2307/2322249
|bibcode=
|oclc=
|id=
|url=http://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/Guy697-712.pdf
|accessdate=2009-08-30
|jstor=2322249
}}
&lt;/ref&gt;}}
In other words, any given small number appears in far more contexts than may seem reasonable, leading to many apparently surprising coincidences in mathematics, simply because small numbers appear so often and yet are so few. Guy's paper gives 35 examples in support of this thesis. This can lead inexperienced mathematicians to conclude that these concepts are related, when in fact they are not.

Guy's observation has since become part of [[mathematical folklore]], and is commonly referenced by other authors.&lt;ref&gt;{{Cite book| first = David| last = Wells | year = 2005 | title = Prime Numbers: The Most Mysterious Figures in Math | publisher = John Wiley &amp; Sons | location = Hoboken | page = 31}}&lt;/ref&gt;&lt;ref&gt;{{Cite book| first = Underwood| last = Dudley | year = 1998 | title = Numerology: Or, What Pythagoras Wrought | publisher = The Mathematical Association of America | page = 87}}&lt;/ref&gt;

== Second Strong Law of Small Numbers ==

The original strong law of small numbers was quickly followed by the '''second strong law of small numbers''':
{{quote|''"When two numbers look equal, it ain't necessarily so!"''&lt;ref&gt;{{Cite journal
|last=Guy
|first=Richard K.
|authorlink=Richard K. Guy
|year=1990
|title=The Second Strong Law of Small Numbers
|journal=[[Mathematics Magazine]]
|volume=63
|issue=1
|pages=3–20
|doi=10.2307/2691503
|jstor=2691503
}}
&lt;/ref&gt;}}
The second strong law of small numbers emphasizes the fact that two [[arithmetic function]]s taking equal values at small arguments do not necessarily coincide.

==See also==
* [[Insensitivity to sample size]]
* [[Law of large numbers]] (unrelated, but the origin of the name)
* [[Mathematical coincidence]]
* [[Pigeonhole principle]]
* [[Representativeness heuristic]]

==Notes==
{{Reflist}}

==External links==
* {{Cite web
|first=Chris
|last=Caldwell
|title=Law of small numbers
|url=http://primes.utm.edu/glossary/page.php?sort=LawOfSmall
|work=The Prime Glossary
}}
* {{MathWorld|urlname=StrongLawofSmallNumbers|title=Strong Law of Small Numbers}}
* {{Cite web
|title=Small finite sets
|work=Secret Blogging Seminar
|date=2007-10-27
|first=Scott
|last=Carnahan
|url=http://sbseminar.wordpress.com/2007/10/27/small-finite-sets/
|postscript=, notes on a talk by [[Jean-Pierre Serre]] on properties of small finite sets.
}}
* {{cite journal |title=Belief in the law of small numbers. |author1=[[Amos Tversky]] |author2=[[Daniel Kahneman]] |journal=Psychological Bulletin |volume=76 |number=2 |pages=105–110.|date=August 1971 |doi=10.1037/h0031322 |url=http://psycnet.apa.org/?&amp;fa=main.doiLanding&amp;doi=10.1037/h0031322 |quote=people have erroneous intuitions about the laws of chance. In particular, they regard a sample randomly drawn from a population as highly representative, I.e., similar to the population in all essential characteristics.}}

[[Category:Mathematics papers]]
[[Category:Mathematical humor]]
[[Category:1988 documents]]
[[Category:1988 in science]]
[[Category:Works originally published in American magazines]]
[[Category:Works originally published in science and technology magazines]]


{{mathematics-lit-stub}}</text>
      <sha1>l269ie2qbpxitvhzh1idsjbod52gshq</sha1>
    </revision>
  </page>
  <page>
    <title>Structural complexity (applied mathematics)</title>
    <ns>0</ns>
    <id>40354723</id>
    <revision>
      <id>800713253</id>
      <parentid>788504512</parentid>
      <timestamp>2017-09-15T06:32:47Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2628">:''This page is about structural complexity in applied mathematics. For structural complexity theory in [[computational complexity theory]] of [[computer science]] see [[structural complexity theory]].''

'''Structural complexity''' is a science of [[applied mathematics]], that aims at relating fundamental physical or biological aspects of a [[complex system]] with the mathematical description of the morphological complexity that the system exhibits, by establishing rigorous relations between mathematical and physical properties of such system (Ricca 2005). 

Structural complexity emerges from all systems that display morphological organization (Nicolis &amp; Prigogine 1989). Filamentary structures, for instance, are an example of [[Lagrangian_coherent_structures |coherent structures]] that emerge, interact and evolve in many physical and biological systems, such as mass distribution in the [[Shape of the universe|Universe]], [[Vortex |vortex filaments]] in turbulent flows, [[neural networks]] in our brain and genetic material (such as [[DNA]]) in a cell. In general information on the degree of morphological [[Order_and_disorder_(physics) |disorder]] present in the system tells us something important about fundamental physical or biological processes.

Structural complexity methods are based on applications of [[differential geometry]] and [[topology]] (and in particular [[knot theory]]) to interpret physical properties of [[dynamical systems]] (Abraham &amp; Shaw 1992; Ricca 2009), such as relations between [[kinetic energy]] and tangles of vortex filaments in a turbulent flow or [[magnetic energy]] and braiding of magnetic fields in the solar corona, including aspects of [[topological fluid dynamics]].

==References==

*[[Ralph Abraham (mathematician)|Abraham, R.H.]] &amp; [[Robert_Shaw_(Physicist)#Illustrations |Shaw, C.D.]] (1992) ''Dynamics - the Geometry of Behavior''. Addison-Wesley. {{ISBN|978-0201567175}}
*Nicolis, G. &amp; [[Ilya_Prigogine |Prigogine, I.]] (1989) ''Exploring Complexity''. W.H. Freeman &amp; Co., New York. {{ISBN|9780716718598}}
*[[Renzo_L._Ricca |Ricca, R.L.]] (2005) Structural complexity, in ''Encyclopedia of Nonlinear Science'' (ed. A. Scott), pp. 885-887. Routledge, New York and London. {{ISBN|9781579583859}}
*[[Renzo_L._Ricca |Ricca, R.L.]] (2009) Detecting structural complexity: from visiometrics to genomics and brain research, in [https://www.springer.com/mathematics/applications/book/978-88-470-1121-2 ''Mathknow''], (ed. M. Emmer &amp; A. Quarteroni), pp. 167-181. Springer-Verlag. {{ISBN|9788847011212}}

[[Category:Applied mathematics]]
[[Category:Complex systems theory]]</text>
      <sha1>rgp73ngpjtmonjvwufkj9x37n2q8wgu</sha1>
    </revision>
  </page>
  <page>
    <title>Substructural type system</title>
    <ns>0</ns>
    <id>14554100</id>
    <revision>
      <id>859202944</id>
      <parentid>859202734</parentid>
      <timestamp>2018-09-12T12:40:37Z</timestamp>
      <contributor>
        <username>Arjayay</username>
        <id>5718152</id>
      </contributor>
      <minor/>
      <comment>Sp</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6630">{{One source|date=February 2018}}
{{Type systems}}

'''Substructural type systems''' are a family of [[type system]]s analogous to [[substructural logic]]s where one or more of the [[structural rule]]s are absent or only allowed under controlled circumstances. Such systems are useful for constraining access to [[system resource]]s such as [[Computer file|files]], [[Lock (computer science)|locks]] and [[Computer memory|memory]] by keeping track of changes of state that occur and preventing invalid states.{{sfn|Walker|2002|p=X}}{{sfn|Walker|2002|p=4}}

== Different substructural type systems ==
Several type systems have emerged by discarding some of the [[structural rule|structural rules]] of exchange, weakening, and contraction:
{| class="wikitable"
|+
!
!exchange
!weakening
!contraction
!use
|-
!linear
|allowed
|—
|—
|exactly once
|-
!affine
|allowed
|allowed
|—
|at most once
|-
!relevant
|allowed
|—
|allowed
|at least once
|-
!ordered
|—
|—
|—
|exactly once in order
|}

* '''Linear type systems''' (allow exchange, but neither weakening nor contraction): Every variable is used exactly once.
* '''Affine type systems''' (allow exchange and weakening, but not contraction): Every variable is used at most once.
* '''Relevant type systems''' (allow exchange and contraction, but not weakening): Every variable is used at least once.
* '''Ordered type systems''' (discard exchange, contraction, and weakening): Every variable is used exactly once in the order it was introduced.

The explanation for affine type systems is best understood if rephrased as “every ''occurrence'' of a variable is used at most once”.

=== Linear type systems ===
'''Linear types''' corresponds to [[linear logic]] and ensures that objects are used exactly once, allowing the system to safely [[Memory management|deallocate]] an object after its use.{{sfn|Walker|2002|p=6}}

The [[Clean (programming language)|Clean programming language]] makes use of [[uniqueness type]]s (a variant of linear types) to help support concurrency, [[input/output]], and in-place update of arrays.{{sfn|Walker|2002|p=43}}

Linear type systems allow [[Reference (computer science)|reference]]s but not [[Aliasing (computing)|alias]]es. To enforce this, a reference goes out of [[scope (programming)|scope]] after appearing on the right-hand side of an [[assignment (computer science)|assignment]], thus ensuring that only one reference to any object exists at once. Note that passing a reference as an [[parameter (computer science)|argument]] to a [[function (computer science)|function]] is a form of assignment, as the function parameter will be assigned the value inside the function, and therefore such use of a reference also causes it to go out of scope.

A linear type system is similar to [[C++]]'s [[unique_ptr]] [[class (computer science)|class]], which behaves like a pointer but can only be moved (i.e. not copied) in an assignment. Although the linearity constraint is checked at [[compile time]], dereferencing an invalidated unique_ptr causes undefined behavior at [[Run time (program lifecycle phase)|run-time]].&lt;ref&gt;[http://en.cppreference.com/w/cpp/memory/unique_ptr std::unique_ptr reference]&lt;/ref&gt;

The single-reference property makes linear type systems suitable as programming languages for [[quantum computation]], as it reflects the [[no-cloning theorem]] of quantum states.  From the [[category theory]] point of view, no-cloning is a statement that there is no [[diagonal functor]] which could duplicate states; similarly, from the [[combinator]] point of view, there is no K-combinator which can destroy states.  From the [[simply typed lambda calculus|lambda calculus]] point of view, a variable ''x'' can appear exactly once in a term.&lt;ref&gt;John c. Baez and Mike Stay, "[http://math.ucr.edu/home/baez/rosetta/rose3.pdf Physics, Topology, Logic and Computation: A Rosetta Stone]", (2009) [https://arxiv.org/abs/0903.0340/ ArXiv 0903.0340] in ''New Structures for Physics'', ed. Bob Coecke, ''Lecture Notes in Physics'' vol. '''813''', Springer, Berlin, 2011, pp. 95-174.&lt;/ref&gt;

Linear type systems are the [[internal language]] of [[closed monoidal category|closed symmetric monoidal categories]], much in the same way that [[simply typed lambda calculus]] is the language of [[Cartesian closed categories]].  More precisely, one may construct [[functor]]s between the category of linear type systems and the category of closed symmetric monoidal categories.&lt;ref&gt;S. Ambler, "[http://www.lfcs.inf.ed.ac.uk/reports/92/ECS-LFCS-92-194/  First order logic in symmetric monoidal closed categories]", Ph.D. thesis, U. of Edinburgh, 1991.&lt;/ref&gt;

=== Affine type systems ===
'''Affine types''' are a version of linear types allowing to ''discard'' (i.e. ''not use'') a resource, corresponding to [[affine logic]]. An affine resource ''can'' only be used once, while a linear one ''must'' be used once.

=== Relevant type system ===
'''Relevant types''' correspond to [[relevant logic]] which allows exchange and contraction, but not weakening, which translates to every variable being used at least once.

=== Ordered type system ===
'''Ordered types''' correspond to [[noncommutative logic]] where exchange, contraction and weakening are discarded. This can be used to model [[stack-based memory allocation]] (contrast with linear types which can be used to model heap-based memory allocation).{{sfn|Walker|2002|pp=30–31}} Without the exchange property, an object may only be used when at the top of the modelled stack, after which it is popped off resulting in every variable being used exactly once in the order it was introduced.

== Programming languages ==
The following programming languages support linear or affine types:

* [[ATS (programming language)|ATS]]
* [[Clean (programming language)|Clean]]
* [[Idris (programming language)|Idris]]
* [[Mercury (programming language)|Mercury]]
* [[Rust (programming language)|Rust]]
* [[F* (programming language)|F*]]
* [https://github.com/pikatchu/LinearML LinearML]
* [http://users.eecs.northwestern.edu/~jesse/pubs/alms/ Alms]
* [https://arxiv.org/abs/1710.09756 Linear Haskell]

==See also==
* [[Effect system]]
* [[Linear logic]]
* [[Affine logic]]

== Notes ==
{{Reflist|2}}

== References ==
* {{cite book|first=David|last=Walker|authorlink=David Walker (computer scientist)|editor1-first=Benjamin C.|editor1-last=Pierce|editor1-link=Benjamin C. Pierce|year=2002|title=Advanced Topics in Types and Programming Languages|publisher=MIT Press|isbn=0-262-16228-8 | ref = harv | chapter = Substructural Type Systems | pages = 3&amp;ndash;43}}

[[Category:Type theory]]</text>
      <sha1>1k6eo94mrtafatxraz5eaogou23howu</sha1>
    </revision>
  </page>
  <page>
    <title>Surface (mathematics)</title>
    <ns>0</ns>
    <id>4342970</id>
    <revision>
      <id>865818751</id>
      <parentid>858051385</parentid>
      <timestamp>2018-10-26T11:01:30Z</timestamp>
      <contributor>
        <username>Citizen Canine</username>
        <id>33426808</id>
      </contributor>
      <minor/>
      <comment>/* Parametric surface */ "an Euclidean" → "a Euclidean"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20850">{{refimprove|date=May 2016}}

In [[mathematics]], a '''surface''' is a generalization of a [[plane (geometry)|plane]] which needs not be flat – that is, the [[surface curvature|curvature]] is not necessarily zero. This is analogous to a [[curve]] generalizing a [[straight line]].
There are several more precise definitions, depending on the context and the mathematical tools that are used for the study.

The mathematical concept of surface is an idealization of what is meant by ''surface'' in common language, [[science]], and [[computer graphics]].

[[Image:Sphere and Ball.png|right|thumb|A [[sphere]] is the surface of a solid [[ball (mathematics)|ball]], here having [[radius]] ''r''.]]

==Definitions==
Often, a surface is defined by [[equation]]s that are satisfied by the [[coordinate]]s of its points. This is the case of the [[graph of a function|graph]] of a [[continuous function]] of two variables.  The set of the [[zero of a function|zeros of a function]] of three variables is a surface, which is called an [[implicit surface]].&lt;ref&gt;Here implicit does not refer to a property of the surface, which may be defined by other means, but it refers to how it is defined. Thus this term is an abbreviation of "surface defined by an [[implicit equation]]".&lt;/ref&gt; If the defining three-variate function is a [[polynomial]], the surface is an [[algebraic surface]]. For example, the [[unit sphere]] is an algebraic surface, as it may be defined by the [[implicit equation]]
:&lt;math&gt;x^2+y^2+z^2 -1= 0.&lt;/math&gt;

A surface may also be defined as the [[Image (mathematics)|image]], in some space of [[dimension]] at least 3, of a [[continuous function]] of two variables (some further conditions are required to insure that the image is not a [[curve]]). In this case, one says that one has a [[parametric surface]], which is ''parametrized'' by these two variables, called ''parameters''. For example, the unit sphere may be parametrized by the [[Euler angles]], also called [[longitude]] {{mvar|u}} and [[latitude]] {{mvar|v}} by 
:&lt;math&gt;\begin{align}
x&amp;= \cos(u)\cos(v)\\
y&amp;=\sin(u)\cos(v)\\
z&amp;=\sin(v)\,.
\end{align}&lt;/math&gt;

Parametric equations of surfaces are often irregular at some points. For example, all but two points of the unit sphere, are the image, by the above parametrization, of exactly one pair of Euler angles ([[modulo operation|modulo]] {{math|2{{pi}}}}). For the remaining two points (the [[North Pole|north]] and [[South Pole|south poles]]), one has {{math|1=cos ''v'' = 0}}, and the longitude {{math|''u''}} may take any values. Also, there are surfaces for which there cannot exist a single parametrization that covers the whole surface. Therefore, one often considers surfaces which are parametrized by several parametric equations, whose images cover the surface. This is formalized by the concept of [[manifold]]: in the context of manifolds, typically in [[topology]] and [[differential geometry]], a surface is a manifold of dimension two; this means that a surface is a [[topological space]] such that every point has a [[neighborhood]] which is [[homeomorphism|homeomorphic]] to an [[open subset]] of the [[Euclidean plane]] (see [[Surface (topology)]] and [[Surface (differential geometry)]]). This allows defining surfaces in spaces of dimension higher than three, and even ''abstract surfaces'', which are not contained in any other space. On the other hand, this excludes surfaces that have [[singularity theory|singularities]], such as the vertex of a [[conical surface]] or points where a surface crosses itself.

In [[classical geometry]], a surface is generally defined as a [[locus (mathematics)|locus]] of a point or a line. For example, a [[sphere]] is the locus of a point which is at a given distance of a fixed point, called the center; a [[conical surface]] is the locus of a line passing through a fixed point and crossing a [[curve]]; a [[surface of revolution]] is the locus of a curve rotating around a line. A [[ruled surface]] is the locus of a moving line satisfying some constraints; in modern terminology, a ruled surface is a surface, which is a [[union (set theory)|union]] of lines.

==Terminology==
In this article, several kinds of surfaces are considered and compared. An unambiguous terminology is thus necessary to distinguish them. Therefore, we call [[#Topological surface|topological surfaces]] the surfaces that are [[manifold]]s of dimension two (the surfaces considered in [[Surface (topology)]]). We call [[#Differential surface|differential surfaces]] the surfaces that are [[differentiable manifold]]s (the surfaces considered in [[Surface (differential geometry)]]). Every differential surface is a topological surface, but the converse is false.

For simplicity, unless otherwise stated, "surface" will mean a surface in the [[Euclidean space]] of dimension 3 or in {{math|'''R'''&lt;sup&gt;3&lt;/sup&gt;}}. A surface that is not supposed to be included in another space is called an '''abstract surface'''.

== Examples ==
* The [[graph of a function|graph]] of a [[continuous function]] of two variables, defined over a [[connected space|connected]] [[open subset]] of {{math|'''R'''&lt;sup&gt;2&lt;/sup&gt;}} is a ''topological surface''. If the function is [[differentiable function|differentiable]], the graph is a ''differential surface''.
* A [[plane (geometry)|plane]] is both an [[algebraic surface]] and a differentiable surface. It is also a [[ruled surface]] and a [[surface of revolution]].
* A [[circular cylinder]] (that is, the [[locus (mathematics)|locus]] of a line crossing a circle and parallel to a given direction) is an algebraic surface and a differential surface.
* A [[conical surface|circular cone]] (locus of a line crossing a circle, and passing through a fixed point, the ''apex'', which is outside the plane of the circle) is an algebraic surface which is not a differential surface. If one removes the apex, the remainder of the cone is the union of two differential surfaces. 
* The surface of a [[polyhedron]] is a topological surface, which is neither a differential surface nor an algebraic surface.
* An [[hyperbolic paraboloid]] (the graph of the function {{math|1=''z'' = ''xy''}}) is a differential surface and an algebraic surface. It is also a ruled surface, and, for this reason, is often used in [[architecture]].
* A [[two-sheet hyperboloid]] is an algebraic surface and the union of two non-intersecting differential surfaces.

==Parametric surface==
{{main|Parametric surface}}

A '''parametric surface''' is the image of an open subset of the [[Euclidean plane]] (typically &lt;math&gt;\Bbb R^2&lt;/math&gt;) by a [[continuous function]], in a [[topological space]], generally a [[Euclidean space]] of dimension at least three. Usually the function is supposed to be [[continuously differentiable]], and this will be always the case in this article.

Specifically, a parametric surface in &lt;math&gt;\Bbb R^3&lt;/math&gt; is given by three functions of two variables {{mvar|u}} and {{mvar|v}}, called ''parameters''
:&lt;math&gt;\begin{align}
x&amp;=f_1(u,v)\\
y&amp;=f_2(u,v)\\
z&amp;=f_3(u,v)\,.
\end{align}&lt;/math&gt;

As the image of such a function may be a [[curve]] (for example if the three functions are constant with respect to {{mvar|v}}), a further condition is required, generally that, for [[almost all]] values of the parameters, the [[Jacobian matrix]] 
:&lt;math&gt;
\begin{bmatrix}
\dfrac{\partial f_1}{\partial u} &amp; \dfrac{\partial f_1}{\partial v}\\
\dfrac{\partial f_2}{\partial u} &amp; \dfrac{\partial f_2}{\partial v}\\
\dfrac{\partial f_3}{\partial u} &amp; \dfrac{\partial f_3}{\partial v}\\
\end{bmatrix}
&lt;/math&gt;
has [[rank of a matrix|rank]] two. Here "almost all" means that the values of the parameters where the rank is two contain a [[dense subset|dense]] [[open subset]] of the range of the parametrization. For surfaces in a space of higher dimension, the condition is the same, except for the number of columns of the Jacobian matrix.

===Tangent plane and normal vector===
A point {{mvar|p}} where the above Jacobian matrix has rank two is called ''regular'', or, more properly, the parametrization is called ''regular'' at {{mvar|p}}.

The '''tangent plane''' at a regular point {{mvar|p}} is the unique plane passing through {{mvar|p}} and having a direction parallel to the two [[row vector]]s of the Jacobian matrix. The tangent plane is an [[affine property|affine concept]], because its definition is independent of the choice of a [[metric (mathematics)|metric]]. In other words, any [[affine transformation]] maps the tangent plane to the surface at a point to the tangent plane to the image of the surface at the image of the point.

The '''[[normal vector|normal line]]''', or simply '''normal''' at a point of a surface is the unique line passing through the point and perpendicular to the tangent plane. A [[normal vector]] is a vector which is parallel to the normal.

For other [[differential invariant]]s of surfaces, in the neighborhood of a point, see [[Differential geometry of surfaces]].

===Irregular point and singular point===
A point of a parametric surface which is not regular is '''irregular'''. There are several kinds of irregular points.

It may occur that an irregular point becomes regular, if one changes the parametrization. This is the case of the poles in the parametrization of the [[unit sphere]] by [[Euler angles]]: it suffices to permute the role of the different [[coordinate axes]] for changing the poles.

On the other hand, let us consider the [[circular cone]] of parametric equation
:&lt;math&gt;\begin{align}
x&amp;= t\cos(u)\\
y&amp;=t\sin(u)\\
z&amp;=t\,.
\end{align}&lt;/math&gt;
The apex of the cone is the origin {{math|(0, 0, 0)}}, and is obtained for {{math|1=''t'' = 0}}. It is an irregular point that remains irregular, whichever parametrization is chosen (otherwise, there would exist a unique tangent plane). Such an irregular point, where the tangent plane is undefined, is said '''singular'''.

There is another kind of singular points. There are the '''self-crossing points''', that is the points where the surface crosses itself. In other words, these are the points which are obtained for (at least) two different values of the parameters.

===Graph of a bivariate function===

Let {{math|1=''z'' = ''f''(''x'', ''y'')}} be a function of two real variables. This is a parametric surface, parametrized as 
:&lt;math&gt;\begin{align}
x&amp;= t\\
y&amp;=u\\
z&amp;=f(t,u)\,.
\end{align}&lt;/math&gt;
Every point of this surface is regular, as the two first columns of the Jacobian matrix form the [[identity matrix]] of rank two.

===Rational surface===
{{main|Rational surface}}
A '''rational surface''' is a surface that may be parametrized by [[rational functions]] of two variables. That is, if {{math|''f&lt;sub&gt;i&lt;/sub&gt;''(''t'', ''u'')}} are, for {{math|1=''i'' = 0, 1, 2, 3}}, [[polynomial]]s in two indeterminates, then the parametric surface, defined by 
:&lt;math&gt;\begin{align}
x&amp;= \frac{f_1(t,u)}{f_0(t,u)}\\
y&amp;=\frac{f_2(t,u)}{f_0(t,u)}\\
z&amp;=\frac{f_3(t,u)}{f_0(t,u)}\,, 
\end{align}&lt;/math&gt;
is a rational surface.

A rational surface is an [[algebraic surface]], but most algebraic surfaces are not rational.

==Implicit surface==
{{main|Implicit surface}}

An implicit surface in a [[Euclidean space]] (or, more generally, in an [[affine space]]) of dimension 3 is the set of the common zeros of a [[differentiable function]] of three variables
:&lt;math&gt;f(x, y, z)=0.&lt;/math&gt;

Implicit means that the equation defines implicitly one of the variables as a function of the other variables. This is made more exact by the [[implicit function theorem]]: if {{math|1=''f''(''x''&lt;sub&gt;0&lt;/sub&gt;, ''y''&lt;sub&gt;0&lt;/sub&gt;, ''z''&lt;sub&gt;0&lt;/sub&gt;) = 0}}, and the partial derivative in {{mvar|z}} of {{mvar|f}} is not zero at {{math|(''x''&lt;sub&gt;0&lt;/sub&gt;, ''y''&lt;sub&gt;0&lt;/sub&gt;, ''z''&lt;sub&gt;0&lt;/sub&gt;)}}, then there exists a differentiable function {{math|''φ''(''x'', ''y'')}} such that
:&lt;math&gt;f(x,y,\varphi(x,y))=0&lt;/math&gt;
in a [[neighbourhood (mathematics)|neighbourhood]] of {{math|(''x''&lt;sub&gt;0&lt;/sub&gt;, ''y''&lt;sub&gt;0&lt;/sub&gt;, ''z''&lt;sub&gt;0&lt;/sub&gt;)}}. In other words, the implicit surface is the [[graph of a function]] near a point of the surface where the partial derivative in {{mvar|z}} is nonzero. An implicit surface has thus, locally, a parametric representation, except at the points of the surface where the three partial derivatives are zero.

===Regular points and tangent plane===
A point of the surface where at least one partial derivative of {{mvar|f}} is nonzero is called '''regular'''. At such a point &lt;math&gt;(x_0, y_0, z_0)&lt;/math&gt;, the tangent plane and the direction of the normal are well defined, and may be deduced, with the implicit function theorem from the definition given above, in {{slink||Tangent plane and normal vector}}. The direction of the normal is the [[gradient]], that is the vector
:&lt;math&gt;\left[\frac{\partial f}{\partial x}(x_0, y_0, z_0), \frac{\partial f}{\partial y}(x_0, y_0, z_0), \frac{\partial f}{\partial z}(x_0, y_0, z_0)\right].&lt;/math&gt;
The tangent plane is defined by its implicit equation
:&lt;math&gt;\frac{\partial f}{\partial x}(x_0, y_0, z_0)(x-x_0) + \frac{\partial f}{\partial y}(x_0, y_0, z_0) (y-y_0)+ \frac{\partial f}{\partial z}(x_0, y_0, z_0)(z-z_0) = 0.&lt;/math&gt;

===Singular point===

A '''singular point''' of an implicit surface (in &lt;math&gt;\Bbb R^3&lt;/math&gt;) is a point of the surface where the implicit equation holds and the three partial derivatives of its defining function are all zero. Therefore, the singular points are the solutions of a [[simultaneous equations|system]] of four equations in three indeterminates. As most such systems have no solution, many surfaces do not have any singular point. A surface with no singular point is called ''regular'' or ''non-singular''.

The study of surfaces near their singular points and the classification of the singular points is [[singularity theory]]. A singular point is [[isolated singularity|isolated]] if there is no other singular point in a neighborhood of it. Otherwise, the singular points may form a curve. This is in particular the case for self-crossing surfaces.

==Algebraic surface==
{{main|Algebraic surface}}
Originally, an algebraic surface was a surface which may be defined by an implicit equation
:&lt;math&gt;f(x,y,z)=0,&lt;/math&gt;
where {{math|''f''}} is a polynomial in three [[indeterminate (variable)|indeterminate]]s, with real coefficients.

The concept has been extended in several directions, by defining surfaces over arbitrary [[field (mathematics)|field]]s, and by considering surfaces in spaces of arbitrary dimension or in [[projective space]]s. Abstract algebraic surfaces, which are not explicitly embedded in another space, are also considered.

===Surfaces over arbitrary fields===

Polynomials with coefficients in any [[field (mathematics)|field]] are accepted for defining an algebraic surface. 
However, the field of coefficients of a polynomial is not well defined, as, for example, a polynomial with [[rational number|rational]] coefficients may also be considered as a polynomial with [[real number|real]] or [[complex number|complex]] coefficients. Therefore, the concept of ''point'' of the surface has been generalized in the following way:&lt;ref&gt;{{Citation | last1=Weil | first1=André | author1-link=André Weil | title=Foundations of Algebraic Geometry | url=https://books.google.com/books?id=ML7u26rkEkIC | publisher=[[American Mathematical Society]] | location=Providence, R.I. | series=American Mathematical Society Colloquium Publications |volume=29  |mr=0023093 | year=1946}}&lt;/ref&gt;

Given a polynomial {{math|''f''(''x'', ''y'', ''z'')}}, let {{math|''k''}} be the smallest field containing the coefficients, and {{math|''K''}} be an [[algebraically closed extension]] of  {{math|''k''}}, of infinite [[transcendence degree]].&lt;ref&gt;The infinite degree of transcendence is a technical condition, which allows an accurate definition of the concept of [[generic point]].&lt;/ref&gt; Then a ''point'' of the surface is an element of {{math|''K''&lt;sup&gt;3&lt;/sup&gt;}} which is a solution of the equation
:&lt;math&gt;f(x,y,z)=0.&lt;/math&gt;
If the polynomial has real coefficients, the field {{math|''K''}} is the [[complex field]], and a point of the surface that belongs to &lt;math&gt;\Bbb{R}^3&lt;/math&gt; (a usual point) is called a ''real point''. A point that belongs to {{math|''k''&lt;sup&gt;3&lt;/sup&gt;}} is called ''rational over {{math|k}}'', or simply a ''rational point'', if {{math|''k''}} is the field of [[rational number]]s.

===Projective surface===

A '''projective surface''' in a [[projective space]] of dimension three is the set of points whose [[homogeneous coordinates]] are zeros of a single [[homogeneous polynomial]] in three variables. More generally, a projective surface is a subset of a projective space, which is a [[projective variety]] of [[dimension of an algebraic variety|dimension]] two.

Projective surfaces are strongly related to affine surfaces (that is, ordinary algebraic surfaces). One passes from a projective surface to the corresponding affine surface by setting to one some coordinate or indeterminate of the defining polynomials (usually the last one). Conversely, one passes from an affine surface to its associated projective surface (called ''projective completion'') by [[Homogeneous polynomial#Homogenization|homogenizing]] the defining polynomial (in case of surfaces in a space of dimension three), or by homogenizing all polynomials of the defining ideal (for surfaces in a space of higher dimension).

===In higher dimensional spaces===

One cannot define the concept of algebraic surface in a space of dimension higher than three without a general definition of an [[algebraic variety]] and of the [[dimension of an algebraic variety]]. In fact, an algebraic surface is an ''algebraic variety of dimension two''.

More precisely, an algebraic surface in a space of dimension {{mvar|n}} is the set of the common zeros of at least {{math|''n'' – 2}} polynomials, but these polynomials must satisfy further conditions that may be not immediate to verify. Firstly, the polynomials must not define a variety or an [[algebraic set]] of higher dimension, which is typically the case if one of the polynomials is in the [[ideal (ring theory)|ideal]] generated by the others. Generally, {{math|''n'' – 2}} polynomials define an algebraic set of dimension two or higher. If the dimension is two, the algebraic set may have several [[irreducible component]]s. If there is only one component the {{math|''n'' – 2}} polynomials define a surface, which is a [[complete intersection]]. If there are several components, then one needs further polynomials for selecting a specific component.

Most authors consider as an algebraic surface only algebraic varieties of dimension two, but some also consider as surfaces algebraic sets all of whose irreducible components have the dimension two.

In the case of surfaces in a space of dimension three, every surface is a complete intersection, and a surface is defined by a single polynomial, which is [[irreducible polynomial|irreducible]] or not, depending on whether non-irreducible algebraic sets of dimension two are considered as surfaces or not.

===Abstract algebraic surface===
{{expand section|date=May 2016}}

===Rational surfaces are algebraic surfaces===
{{expand section|date=May 2016}}

==Topological surface==
{{main|Surface (topology)}}

In [[topology]], a surface is generally defined as a [[manifold]] of dimension two. This means that a topological surface is a [[topological space]] such that every point has a [[neighborhood (mathematics)|neighborhood]] that is [[homeomorphism|homeomorphic]] to an [[open subset]] of a [[Euclidean plane]].

Every topological surface is homeomorphic to a [[polyhedral surface]] such that all [[facet (geometry)|facets]] are [[triangle]]s. The [[combinatorics|combinatorial]] study of such arrangements of triangles (or, more generally, of higher-dimensional [[simplex]]es) is the starting object of [[algebraic topology]]. This allows the characterization of the properties of surfaces in terms of purely algebraic [[invariant (mathematics)|invariants]], such as the [[genus (mathematics)|genus]] and [[homology group]]s.

The homeomorphism classes of surfaces have been completely described (see [[Surface (topology)]]).

==Differential surface==
{{main|Surface (differential geometry)}}

==Fractal surface==
{{main|Fractal surface}}
{{expand section|date=April 2016}}

==In computer graphics==
{{main|Surface (computer graphics)}}
{{expand section|date=April 2016}}

==See also==
* [[Area element]], the area of a differential element of a surface
* [[Coordinate surfaces]]
* [[Perimeter]], two-dimensional equivalent.
* [[Polyhedral surface]]
* [[Shape]]
* [[Signed distance function]]
* [[Surface area]]
* [[Surface integral]]

==Notes==
{{reflist}}

[[Category:Geometry]]
[[Category:Surfaces]]
[[Category:Broad-concept articles]]</text>
      <sha1>nkipir1kaoija4tqgfrl1d4wthjb8an</sha1>
    </revision>
  </page>
  <page>
    <title>Table of mathematical symbols by introduction date</title>
    <ns>0</ns>
    <id>8434205</id>
    <revision>
      <id>844346167</id>
      <parentid>844340660</parentid>
      <timestamp>2018-06-04T09:31:02Z</timestamp>
      <contributor>
        <username>ArnoldReinhold</username>
        <id>84951</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/112.209.217.145|112.209.217.145]] ([[User talk:112.209.217.145|talk]]) to last version by Jim1138</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22748">{{Use dmy dates|date=September 2010}}
{{ SpecialChars
| special    = [[Unicode]] [[mathematical symbols]]
| fix        = Help:Special_characters
| characters = [[mathematical symbols]]
}}
The following table lists many specialized [[symbols]] commonly used in [[mathematics]], ordered by their introduction date. 
&lt;br /&gt;{{clear}}
{| class="wikitable sortable" border="1"
|- bgcolor=#a0e0a0
! &lt;div style="font-size:130%;"&gt;Symbol&lt;/div&gt;
! Name
! Date of earliest use
! First author to use
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;+&lt;/div&gt;
| [[plus and minus signs|plus sign]]
| ca. 1360 (abbreviation for Latin ''et'' resembling the plus sign)
| [[Nicole Oresme]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;−&lt;/div&gt;
| [[plus and minus signs|minus sign]]
| 1489 (first appearance of minus sign, and also first appearance of plus sign in print)
| [[Johannes Widmann]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;√&lt;/div&gt; 
| radical symbol (for [[square root]])
| 1525 (without the [[vinculum (symbol)|vinculum]] above the [[radicand]])
| [[Christoff Rudolff]]
|-
| rowspan=2 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;(…)&lt;/div&gt;
| rowspan=2| [[Bracket#Parentheses ( )|parentheses]] (for precedence grouping)
| 1544 (in handwritten notes)
| [[Michael Stifel]]
|-
| 1556
| [[Niccolò Fontana Tartaglia|Niccolò Tartaglia]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;=&lt;/div&gt; 
| [[equals sign]]
| 1557
| [[Robert Recorde]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;&amp;times;&lt;/div&gt; 
| [[multiplication sign]]
| 1618
| rowspan=3| [[William Oughtred]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;±&lt;/div&gt; 
| [[plus-minus sign]]
| rowspan=2| 1628
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∷&lt;/div&gt; 
| [[proportion sign]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;&lt;sup&gt;''n''&lt;/sup&gt;√&lt;br /&gt;&amp;nbsp;&lt;/div&gt; 
| radical symbol (for [[nth root|''n''th root]])
| 1629
| [[Albert Girard]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;&lt;&lt;br /&gt;&gt;&lt;/div&gt;
| [[strict inequality]] signs (''less-than sign'' and ''greater-than sign'')
| 1631
| [[Thomas Harriot]]
|-
| rowspan=2 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;''x&lt;sup&gt;y&lt;/sup&gt;''&lt;br /&gt;&amp;nbsp;&lt;/div&gt; 
| rowspan=2| [[superscript]] notation (for [[exponentiation]])
| 1636 (using [[Roman numerals]] as superscripts)
| [[James Hume (mathematician)|James Hume]]
|-
| style=border-bottom:none| 1637 (in the modern form)
| [[René Descartes]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;√ ̅  &lt;/div&gt; 
| radical symbol (for [[square root]])
| style=border-bottom:none| 1637 (with the [[vinculum (symbol)|vinculum]] above the [[radicand]])
| [[René Descartes]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;%&lt;/div&gt; 
| [[percent sign]]
| ca. 1650
| unknown
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;÷&lt;/div&gt; 
| ''division sign'' (a.k.a. [[obelus]])
| 1659
| [[Johann Rahn]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∞&lt;/div&gt; 
| [[infinity]] sign
| 1655
| rowspan=2| [[John Wallis]]
|-
| rowspan=2 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;≤&lt;br /&gt;&lt;br /&gt;≥&lt;/div&gt; 
| rowspan=2| [[inequality (mathematics)|unstrict inequality signs]] (''less-than or equals to sign'' and ''greater-than or equals to sign'')
| 1670 (with the horizontal bar over the inequality sign, rather than below it)
|-
| 1734 (with double horizontal bar below the inequality sign)
| [[Pierre Bouguer]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;d&lt;/div&gt; 
| [[differential (calculus)|differential]] sign
| rowspan=2| 1675
| rowspan=4| [[Gottfried Leibniz]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∫&lt;/div&gt; 
| [[integral sign]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;:&lt;/div&gt; 
| [[colon (punctuation)|colon]] (for [[division (mathematics)|division]])
| 1684 (deriving from use of colon to denote fractions, dating back to 1633)
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;·&lt;/div&gt; 
| [[middle dot]] (for [[multiplication]])
| 1698 (perhaps deriving from a much earlier use of middle dot to separate juxtaposed numbers)
|-
| bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;⁄&lt;/div&gt; 
| [[slash (punctuation)|division slash]] (a.k.a. ''solidus'')
| 1718 (deriving from horizontal fraction bar, invented by Arabs in the 12th century)
| [[Thomas Twining (merchant)|Thomas Twining]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;≠&lt;/div&gt; 
| [[inequality (mathematics)|inequality]] sign (''not equal to'')
| unknown
| rowspan=2| [[Leonhard Euler]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∑&lt;/div&gt; 
| [[summation]] symbol
| 1755
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∝&lt;/div&gt; 
| [[proportionality (mathematics)|proportionality]] sign
| 1768
| [[William Emerson (mathematician)|William Emerson]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∂&lt;/div&gt; 
| [[partial differential]] sign (a.k.a. ''curly d'' or ''[[Carl Gustav Jacob Jacobi|Jacobi]]'s delta'')
| rowspan=2| 1770
| [[Marquis de Condorcet]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;''x''&amp;prime;&lt;/div&gt;  
| [[prime symbol]] (for [[derivative]])
| [[Joseph Louis Lagrange]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;≡&lt;/div&gt; 
| [[Identity (mathematics)|identity]] sign (for [[congruence relation]])
| 1801 (first appearance in print; used previously in personal writings of Gauss)
| rowspan=3| [[Carl Friedrich Gauss]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;[''x'']&lt;/div&gt; 
| ''integral part'' (a.k.a. [[floor and ceiling functions|floor]])
| 1808
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∏&lt;/div&gt; 
| [[multiplication|product]] symbol
| 1812
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;!&lt;/div&gt; 
| [[factorial]]
| 1808
| [[Christian Kramp]]
|-
| rowspan=2 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;⊂&lt;br /&gt;⊃&lt;/div&gt;
| rowspan=2| [[set inclusion]] signs (''subset of'', ''superset of'')
| 1817
| [[Joseph Gergonne]]
|-
| 1890
| [[Ernst Schröder]]
|-
| rowspan=2 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;|…|&lt;/div&gt; 
| [[absolute value]] notation
| rowspan=2| 1841
| [[Karl Weierstrass]]
|-
| [[determinant]] of a matrix
| rowspan=2| [[Arthur Cayley]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%; white-space:nowrap;"&gt;‖…‖&lt;/div&gt; 
| [[matrix (mathematics)|matrix]] notation
| 1843&lt;ref name="matrix"&gt;{{cite web|title=Earliest Uses of Symbols for Matrices and Vectors|url=http://jeff560.tripod.com/matrices.html|website=jeff560.tripod.com|accessdate=18 December 2016}}&lt;/ref&gt;
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∇&lt;/div&gt; 
| [[nabla symbol]] (for [[vector differential]])
| 1846 (previously used by Hamilton as a general-purpose operator sign)
| [[William Rowan Hamilton]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∩&lt;br /&gt;∪&lt;/div&gt; 
| [[intersection (set theory)|intersection]] &lt;br /&gt;&lt;br /&gt; [[union (set theory)|union]] 
| 1888
| rowspan=3| [[Giuseppe Peano]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∈&lt;/div&gt; 
| [[membership sign]] (''is [[element (mathematics)|an element]] of'')
| 1894
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∃&lt;/div&gt; 
| [[existential quantifier]] (''there exists'')
| 1897
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;" class="Unicode"&gt;ℵ&lt;/div&gt; 
| [[aleph number|aleph]] symbol (for [[transfinite cardinal number]]s)
| 1893
| rowspan=2| [[Georg Cantor]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;{…}&lt;/div&gt;
| braces, a.k.a. [[curly bracket]]s (for [[Set (mathematics)|set]] notation)
| rowspan=2| 1895
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"  class="Unicode"&gt;ℕ&lt;/div&gt; 
| [[Blackboard bold]] capital N (for [[natural number]]s set)
| [[Giuseppe Peano]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;·&lt;/div&gt; 
| [[middle dot]] (for [[dot product]])
| rowspan=2| 1902
| rowspan=2| [[J. Willard Gibbs]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;&amp;times;&lt;/div&gt; 
| [[multiplication sign]] (for [[cross product]])
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∨&lt;/div&gt;
| [[logical disjunction]] (a.k.a. ''OR'')
| 1906
| [[Bertrand Russell]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;(…)&lt;/div&gt; 
| rowspan=2| [[matrix (mathematics)|matrix]] notation
| 1909&lt;ref name="matrix" /&gt;
| [[Maxime Bôcher]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;[…]&lt;br /&gt;&amp;nbsp;&lt;/div&gt; 
| 1909&lt;ref name="matrix" /&gt;
| [[Gerhard Kowalewski]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∮&lt;/div&gt;
| [[line integral|contour integral]] sign
| 1917
| [[Arnold Sommerfeld]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"  class="Unicode"&gt;ℤ&lt;/div&gt; 
| [[Blackboard bold]] capital Z (for [[integer]] numbers set)
| 1930
| [[Edmund Landau]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"  class="Unicode"&gt;ℚ&lt;/div&gt; 
| [[Blackboard bold]] capital Q (for [[rational number]]s set)
| 1895
| [[Giuseppe Peano]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;∀&lt;/div&gt; 
| [[universal quantifier]] (''for all'')
| 1935
| [[Gerhard Gentzen]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;" class="Unicode"&gt;∅&lt;/div&gt;
| [[empty set]] sign
| 1939
| [[André Weil]] / [[Nicolas Bourbaki]]&lt;ref&gt;{{citation|title=The Apprenticeship of a Mathematician|first=André|last=Weil|authorlink=André Weil|publisher=Springer|year=1992|isbn=9783764326500|page=114|url=https://books.google.com/books?id=73REHmJ9JNUC&amp;pg=PA114}}.&lt;/ref&gt;
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"  class="Unicode"&gt;ℂ&lt;/div&gt; 
| [[Blackboard bold]] capital C (for [[complex number]]s set)
| 1939
| [[Nathan Jacobson]]
|-
| rowspan=2 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;→&lt;/div&gt;
| rowspan=2| [[arrow]] (for [[function (mathematics)|function]] notation)
| 1936 (to denote images of specific elements)
| [[Øystein Ore]]
|-
| 1940 (in the present form of f: X → Y)
| [[Witold Hurewicz]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;" class="Unicode"&gt;∎&lt;/div&gt;
| [[end of proof]] sign (a.k.a. [[tombstone (typography)|tombstone]])
| 1950&lt;ref&gt;{{Cite book
 | last = Halmos
 | first = Paul
 | authorlink = 
 | year = 1950
 | title = Measure Theory
 | publisher = Van Nostrand
 | location = New York
 | quote = The symbol ∎ is used throughout the entire book in place of such phrases as "Q.E.D." or "This completes the proof of the theorem" to signal the end of a proof.
 | pages = vi
}}&lt;/ref&gt;
| [[Paul Halmos]]
|-
| bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;" class="Unicode"&gt;⌊''x''⌋&lt;br /&gt;⌈''x''⌉&lt;/div&gt; 
| ''greatest integer &amp;le; x'' (a.k.a. [[floor and ceiling functions|floor]]) &lt;br /&gt; &lt;br /&gt; ''smallest integer &amp;ge; x'' (a.k.a. [[floor and ceiling functions|ceiling]])
| 1962&lt;ref&gt;{{citation|author=[[Kenneth E. Iverson]]|title=A Programming Language|date=1962|publisher=Wiley|url=http://www.jsoftware.com/papers/APL.htm|accessdate=20 April 2016}}&lt;/ref&gt;
| [[Kenneth E. Iverson]]

&lt;!--
|-
| rowspan=6 bgcolor=#d0f0d0 align=center|&lt;br /&gt;&lt;div style="font-size:200%;"&gt;⊕&lt;/div&gt; &lt;br&gt;&lt;br&gt;&lt;div style="font-size:200%;"&gt;⊻&lt;/div&gt; ||[[exclusive or]] 
| rowspan=3| The statement ''A'' ⊕ ''B'' is true when either A or B, but not both, are true. ''A'' ⊻ ''B'' means the same.
| rowspan=3| (¬''A'') ⊕ ''A'' is always true, ''A'' ⊕ ''A'' is always false.
|-
|align=center|xor
|-
|align=right|[[propositional logic]], [[Boolean algebra]]
|-
||[[Direct_sum_of_modules|direct sum]]
|rowspan=3|The direct sum is a special way of combining several one modules into one general module (the symbol ⊕ is used, ⊻ is only for logic).&lt;br&gt;&lt;br&gt;
|rowspan=3|Most commonly, for vector spaces ''U'', ''V'', and ''W'', the following consequence is used:&lt;br&gt; ''U'' = ''V'' ⊕ ''W'' ⇔ (''U'' = ''V'' + ''W'') ∧ (''V'' ∩ ''W'' = {{0/}})
|-
|align=center|direct sum of
|-
|align=right|[[Abstract_algebra|Abstract algebra]]
|-
| rowspan=3  bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;&amp;exist;!&lt;/div&gt; 
||[[uniqueness quantification]]
| rowspan=3|&amp;exist;!&amp;nbsp;''x'': ''P''(''x'') means there is exactly one ''x'' such that ''P''(''x'') is true.
| rowspan=3|&amp;exist;!&amp;nbsp;''n''&amp;nbsp;∈ ℕ: ''n''&amp;nbsp;+ 5&amp;nbsp;= 2''n''.
|-
|align=center|there exists exactly one
|-
|align=right|[[predicate logic]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;:=&lt;br&gt;&lt;br&gt; ≡&lt;br&gt;&lt;br&gt;:⇔&lt;/div&gt; 
||[[definition]]
| rowspan=3|''x''&amp;nbsp;:= ''y'' or ''x''&amp;nbsp;≡ ''y'' means ''x'' is defined to be another name for ''y''&lt;br&gt;&lt;br&gt;(''Some writers use'' ≡ ''to mean [[congruence]]'').&lt;br&gt;&lt;br&gt; ''P''&amp;nbsp;:⇔ ''Q'' means ''P'' is defined to be logically equivalent to ''Q''.
| rowspan=3|cosh&amp;nbsp;''x''&amp;nbsp;:= (1/2)(exp&amp;nbsp;''x''&amp;nbsp;+  exp&amp;nbsp;(&amp;minus;''x''))&lt;br&gt;&lt;br&gt; ''A''&amp;nbsp;'''xor'''&amp;nbsp;''B'' :⇔ (''A''&amp;nbsp;∨&amp;nbsp;''B'')&amp;nbsp;∧&amp;nbsp;¬(''A''&amp;nbsp;∧&amp;nbsp;''B'')
|-
|align=center|is defined as
|-
|align=right|everywhere
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;{&amp;nbsp;,&amp;nbsp;}&lt;/div&gt; 
||[[Set (mathematics)|set]] brackets
| rowspan=3|{''a'',''b'',''c''} means the set consisting of ''a'', ''b'', and ''c''.
| rowspan=3|ℕ&amp;nbsp;= {&amp;nbsp;1, 2, 3, …}
|-
|align=center|the set of …
|-
|align=right|[[naive set theory|set theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt; &lt;math&gt;\Delta&lt;/math&gt; &lt;/div&gt; 
||[[symmetric difference]]
| rowspan=3|&lt;math&gt; A\Delta B&lt;/math&gt; means the set of elements in exactly one of ''A'' or ''B''.
| rowspan=3|{1,5,6,8} &lt;math&gt;\Delta&lt;/math&gt; {2,5,8} = {1,2,6}
|-
|align=center|symmetric difference
|-
|align=right|[[naive set theory|set theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;∖&lt;/div&gt; 
||[[complement (set theory)|set-theoretic complement]]
| rowspan=3|''A''&amp;nbsp;∖ ''B'' means the set that contains all those elements of ''A'' that are not in ''B''.
| rowspan=3|{1,2,3,4} ∖ {3,4,5,6} = {1,2}
|-
|align=center|minus; without
|-
|align=right|[[naive set theory|set theory]]
|-
| rowspan=6 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;( )&lt;/div&gt; 
||[[function (mathematics)|function]] application
| rowspan=3|''f''(''x'') means the value of the function ''f'' at the element ''x''.
| rowspan=3|If ''f''(''x'')&amp;nbsp;:= ''x''&lt;sup&gt;2&lt;/sup&gt;, then ''f''(3)&amp;nbsp;= 3&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;= 9.
|-
|align=center|of
|-
|align=right|[[naive set theory|set theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;&lt;small&gt;o&lt;/small&gt;&lt;/div&gt; 
||[[function composition]]
| rowspan=3|''f''&lt;small&gt;o&lt;/small&gt;''g'' is the function, such that (''f''&lt;small&gt;o&lt;/small&gt;''g'')(''x'') = ''f''(''g''(''x'')).
| rowspan=3|if ''f''(''x'') := 2''x'', and ''g''(''x'') := ''x'' + 3, then  (''f''&lt;small&gt;o&lt;/small&gt;''g'')(''x'') = 2(''x'' + 3).
|-
|align=center|composed with
|-
|align=right|[[naive set theory|set theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt; '''''π'''''&lt;/div&gt;||pi
| rowspan=3|'''''π''''' is the ratio of a [[circle]]'s circumference to its diameter. Its value is 3.14159265...&amp;nbsp;.
| rowspan=3|''A''&amp;nbsp;= '''''π'''''&amp;nbsp;''r''² is the area of a circle with radius ''r''&lt;br&gt;&lt;br&gt; '''''π'''''&amp;nbsp;[[radian]]s = [[degree (angle)|180°]]&lt;br&gt;&lt;br&gt; '''''π'''''&amp;nbsp;≈ 22&amp;nbsp;/&amp;nbsp;7
|-
|align=center|pi
|-
|align=right|[[Euclidean geometry]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;&lt;nowiki&gt;||&lt;/nowiki&gt;…&lt;nowiki&gt;||&lt;/nowiki&gt;&lt;/div&gt; 
||[[normed vector space|norm]]
| rowspan=3| &lt;nowiki&gt;||&lt;/nowiki&gt;&amp;nbsp;''x''&amp;nbsp;&lt;nowiki&gt;||&lt;/nowiki&gt; is the [[norm (mathematics)|norm]] of the element ''x'' of a [[normed vector space]].
| rowspan=3| &lt;nowiki&gt;||&lt;/nowiki&gt;&amp;nbsp;''x''&amp;nbsp; + ''y''&amp;nbsp;&lt;nowiki&gt;||&lt;/nowiki&gt; ≤&amp;nbsp; &lt;nowiki&gt;||&lt;/nowiki&gt;&amp;nbsp;''x''&amp;nbsp;&lt;nowiki&gt;||&lt;/nowiki&gt;&amp;nbsp; +&amp;nbsp;  &lt;nowiki&gt;||&lt;/nowiki&gt;&amp;nbsp;''y''&amp;nbsp;&lt;nowiki&gt;||&lt;/nowiki&gt;
|-
|align=center|norm of&lt;br&gt;&lt;br&gt; length of
|-
|align=right| [[linear algebra]]
|-
||[[Cartesian product]]
| rowspan=3|
&lt;math&gt;\prod_{i=0}^{n}{Y_i}&lt;/math&gt; means the set of all [[n-tuple|(n+1)-tuples]]
::(''y''&lt;sub&gt;0&lt;/sub&gt;, …, ''y''&lt;sub&gt;''n''&lt;/sub&gt;).
| rowspan=3|
&lt;math&gt;\prod_{n=1}^{3}{\mathbb{R}} = \mathbb{R}\times\mathbb{R}\times\mathbb{R} = \mathbb{R}^3&lt;/math&gt;
|-
|align=center|the Cartesian product of; the direct product of
|-
|align=right|[[naive set theory|set theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;∐&lt;/div&gt; 
||[[coproduct]]
| rowspan=3|
| rowspan=3|
|-
|align=center|coproduct over … from … to … of
|-
|align=right|[[category theory]]
|-
|[[Boundary (topology)|boundary]]
| rowspan=3| ∂''M'' means the boundary of ''M''
| rowspan=3| ∂{x : &lt;nowiki&gt;||&lt;/nowiki&gt;x&lt;nowiki&gt;||&lt;/nowiki&gt; ≤ 2} = {x : &lt;nowiki&gt;||&lt;/nowiki&gt;x&lt;nowiki&gt;||&lt;/nowiki&gt; = 2}
|-
|align=center|boundary of
|-
|align=right|[[topology]]
|-
| rowspan=6 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;&amp;perp;&lt;/div&gt; 
||[[perpendicular]]
| rowspan=3|''x'' &amp;perp; ''y'' means ''x'' is perpendicular to ''y''; or more generally ''x'' is orthogonal to ''y''.
| rowspan=3|If ''l'' &amp;perp; ''m'' and ''m'' &amp;perp; ''n'' then ''l'' &lt;nowiki&gt;||&lt;/nowiki&gt; ''n''.
|-
|align=center|is perpendicular to
|-
|align=right|[[geometry]]
|-
||[[bottom element]]
| rowspan=3|''x'' = &amp;perp; means ''x'' is the smallest element. 
| rowspan=3|&amp;forall;''x'' : ''x'' ∧ &amp;perp; = &amp;perp;
|-
|align=center|the bottom element
|-
|align=right|[[Lattice (order)|lattice theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;&lt;nowiki&gt;||&lt;/nowiki&gt;&lt;/div&gt; 
||[[parallel (geometry)|parallel]]
| rowspan=3|''x'' &lt;nowiki&gt;||&lt;/nowiki&gt; ''y'' means ''x'' is parallel to ''y''.
| rowspan=3|If ''l'' &lt;nowiki&gt;||&lt;/nowiki&gt; ''m'' and ''m'' &amp;perp; ''n'' then ''l'' &amp;perp; ''n''.
|-
|align=center|is parallel to
|-
|align=right|[[geometry]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;⊧&lt;/div&gt; 
||[[entailment]]
| rowspan=3| ''A'' ⊧ ''B'' means the sentence ''A'' entails the sentence ''B'', that is every model in which ''A'' is true, ''B'' is also true.
| rowspan=3| ''A'' ⊧ ''A'' ∨ ¬''A''
|-
|align=center|entails
|-
|align=right| [[model theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt;⊢&lt;/div&gt; 
||[[inference]]
| rowspan=3|''x'' ⊢ ''y'' means ''y'' is derived from ''x''.
| rowspan=3| ''A'' → ''B'' ⊢ ¬''B'' → ¬''A''
|-
|align=center|infers or is derived from
|-
|align=right|[[propositional logic]], [[predicate logic]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center| &lt;div style="font-size:200%;"&gt; ◅ &lt;/div&gt;
||[[normal subgroup]]
| rowspan=3| ''N'' ◅ ''G'' means that ''N'' is a normal subgroup of group ''G''.
| rowspan=3| ''Z''(''G'') ◅ ''G'' 
|-
|align=center|is a normal subgroup of
|-
|align=right|[[group theory]]
|-
| rowspan=6 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt; / &lt;/div&gt;
||[[quotient group]]
| rowspan=3| ''G''/''H'' means the quotient of group ''G'' [[modulo]] its subgroup ''H''.
| rowspan=3| {0, ''a'', 2''a'', ''b'', ''b''+''a'', ''b''+2''a''} / {0, ''b''} = {{0, ''b''}, {''a'', ''b''+''a''}, {2''a'', ''b''+2''a''}}
|-
|align=center| mod
|-
|align=right| [[group theory]]
|-
|quotient set
| rowspan=3| ''A''/~ means the set of all ~ [[equivalence class]]es in ''A''.
|-
|align=center|
|-
|align=right| [[set theory]]
|-
| rowspan=6 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt; ≈ &lt;/div&gt;
||[[isomorphism]]
| rowspan=3| ''G'' ≈ ''H'' means that group ''G'' is isomorphic to group ''H''
| rowspan=3| ''Q'' / {1, &amp;minus;1} ≈ ''V'', &lt;br /&gt;where ''Q'' is the [[quaternion group]] and ''V'' is the [[Klein four-group]].
|-
|align=center | is isomorphic to
|-
|align=right| [[group theory]]
|-
|approximately equal
| rowspan=3|''x'' ≈ ''y'' means ''x'' is approximately equal to ''y'' 
| rowspan=3|π ≈ 3.14159
|-
|align=center|is approximately equal to
|-
|align=right|everywhere
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;~&lt;/div&gt; 
||same [[order of magnitude]]
| rowspan=3| ''m''&amp;nbsp;~ ''n'', means the quantities ''m'' and ''n'' have the [[order of magnitude|general size]]. &lt;br&gt;&lt;br&gt;(''Note that'' ~ ''is used for an approximation that is poor, otherwise use '' ≈&amp;nbsp;.)
| rowspan=3|2 ~ 5&lt;br&gt;&lt;br&gt; 8&amp;nbsp;×&amp;nbsp;9&amp;nbsp;~ 100&lt;br&gt;&lt;br&gt; but π&lt;sup&gt;2&lt;/sup&gt; ≈ 10
|-
|align=right|roughly similar&lt;br&gt;&lt;br&gt; [[approximation|poorly approximates]]
|-
|align=right|[[Approximation theory]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt;〈,〉&lt;br/&gt;&lt;br/&gt;( | )&lt;br/&gt;&lt;br/&gt;·&lt;br/&gt;&lt;br/&gt;:&lt;/div&gt; 
||[[Inner_product_space|inner product]]
| rowspan=3|〈''x'',''y''〉 means the inner product of ''x'' and ''y'' as defined in an [[Inner_product_space|inner product space]]. &lt;br/&gt;
For spatial vectors, the [[dot product]] notation, ''x''·''y'' is common. &lt;br/&gt;
For matricies, the colon notation may be used.
| rowspan=3|The [[Dot product|standard inner product]] between two vectors ''x'' = (2, 3) and ''y'' = (−1, 5) is:&lt;br /&gt;〈x, y〉 = 2×−1 + 3×5 = 13&lt;br/&gt;
&lt;math&gt;A:B = \sum_{i,j} A_{ij}B_{ij}&lt;/math&gt;
|-
|align=center|inner product of
|-
|align=right|[[Vector_algebra|vector algebra ]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt; ⊗ &lt;/div&gt;
||[[tensor product]]
| rowspan=3| ''V'' ⊗ ''U'' means the tensor product of ''V'' and ''U''.
| rowspan=3| {1, 2, 3, 4} ⊗ {1,1,2} = &lt;br /&gt; {{1, 2, 3, 4}, {1, 2, 3, 4}, {2, 4, 6, 8}}
|-
|align=center| tensor product of
|-
|align=right| [[linear algebra]]
|-
| rowspan=3 bgcolor=#d0f0d0 align=center|&lt;div style="font-size:200%;"&gt; * &lt;/div&gt;
||[[convolution]]
| rowspan=3| ''f'' * ''g'' means the convolution of ''f'' and ''g''.
| rowspan=3| &lt;math&gt;(f  * g )(t) = \int f(\tau) g(t - \tau)\, d\tau&lt;/math&gt;
|-
|align=center| convolution
|-
|align=right| 
--&gt;
|}

==See also==
* [[History of mathematical notation]]
* [[History of the Hindu–Arabic numeral system]]
* [[Table of mathematical symbols]]

==Sources==
{{reflist}}

* [http://jeff560.tripod.com/mathsym.html Jeff Miller: ''Earliest Uses of Various Mathematical Symbols'']

[[Category:Mathematical notation|*]]
[[Category:Mathematics-related lists|Symbols by introduction date]]
[[Category:Mathematical symbols| ]]
[[Category:Mathematics timelines]]</text>
      <sha1>l3cg3xp6kz2kp3kaimhxbsjsta0y1ed</sha1>
    </revision>
  </page>
  <page>
    <title>Transylvania lottery</title>
    <ns>0</ns>
    <id>3504251</id>
    <revision>
      <id>865474205</id>
      <parentid>854929996</parentid>
      <timestamp>2018-10-24T05:24:27Z</timestamp>
      <contributor>
        <ip>2600:8800:2982:7F00:3918:8F15:5E7E:3EE7</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2743">[[File:Fano plane.svg|thumb|The Fano plane]]
In mathematical combinatorics, the '''Transylvanian lottery''' is a [[lottery]] where three numbers between 1 and 14 are picked by the player for any given ticket, and three numbers are chosen randomly. The player wins if two of their numbers, on a given ticket, are among the random ones. The problem of how many tickets the player must buy in order to be certain of winning can be solved by the use of the [[Fano plane]].
{{harv|Mazur|2010|loc=p.280 problem 15}}
{{harvs | last1=Martínez | first1=Javier | last2=Gutiérrez | first2=Gloria | last3=Cordero | first3=Pablo | last4=Rodríguez | first4=Francisco J. | last5=Merino | first5=Salvador | editor1-last=Moore | editor1-first=Kenneth B. | title=Discrete mathematics research progress | url=https://books.google.com/books?id=_uCQVCAXOJAC&amp;pg=PA85 | publisher=Nova Sci. Publ. | location=Hauppauge, NY | isbn=978-1-60456-123-4 |mr=2446219 | year=2008 | chapter=Algebraic topics on discrete mathematics | pages=41–90|loc=p.85}}

The solution is to buy a total of 14 tickets, in two sets of seven.  One set of seven is every line of a Fano plane with the numbers 1-7, the other with 8-14, i.e.:

1-2-5,    1-3-6,    1-4-7,    2-3-7,    2-4-6,    3-4-5,    5-6-7,    8-9-12,    8-10-13,    8-11-14,    9-10-14,    9-11-13,    10-11-12,    12-13-14.

Because at least two of the winning numbers must be either high (8-14) or low (1-7), and every high and low pair is represented by exactly one ticket, you would be guaranteed at least two correct numbers on one ticket with these 14 purchases.  21/26 of the time you will have one ticket with two numbers matched.  If all three winning numbers are either high or low you would either have one ticket with all three numbers (1/26 chance of this occurring), or three different tickets that each matched two (4/26 chance).

==See also==
* [[Combinatorial design]]
* [[Lottery Wheeling]]

==References==

*{{Citation | last1=Martínez | first1=Javier | last2=Gutiérrez | first2=Gloria | last3=Cordero | first3=Pablo | last4=Rodríguez | first4=Francisco J. | last5=Merino | first5=Salvador | editor1-last=Moore | editor1-first=Kenneth B. | title=Discrete mathematics research progress | url=https://books.google.com/books?id=_uCQVCAXOJAC&amp;pg=PA85 | publisher=Nova Sci. Publ. | location=Hauppauge, NY | isbn=978-1-60456-123-4 |mr=2446219 | year=2008 | chapter=Algebraic topics on discrete mathematics | pages=41–90}}
*{{Citation | last1=Mazur | first1=David R. | title=Combinatorics | url=https://books.google.com/books?id=yI4Jx5Obr08C&amp;pg=PA280 | publisher=[[Mathematical Association of America]] | series=MAA Textbooks | isbn=978-0-88385-762-5 |mr=2572113 | year=2010}}


[[Category:Combinatorics]]</text>
      <sha1>i1jmb6x1xo6nrw71ppnwlbv84hf48yf</sha1>
    </revision>
  </page>
  <page>
    <title>Warsaw School (mathematics)</title>
    <ns>0</ns>
    <id>1028194</id>
    <revision>
      <id>847510803</id>
      <parentid>771506769</parentid>
      <timestamp>2018-06-25T21:40:59Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <minor/>
      <comment>lk Helena Rasiowa</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1817">{{unreferenced|date=August 2012}}
'''Warsaw School of Mathematics''' is the name given to a group of [[mathematician]]s who worked at [[Warsaw]], [[Poland]], in the two decades between the World Wars, especially in the fields of [[logic]], [[set theory]], [[point-set topology]] and [[real analysis]]. They published in the journal ''[[Fundamenta Mathematicae]]'', founded in 1920—one of the world's first specialist [[mathematics journal|pure-mathematics journals]]. It was in this journal, in 1933, that [[Alfred Tarski]]—whose illustrious career would a few years later take him to the [[University of California, Berkeley]]—published his celebrated theorem on the [[undefinability of the notion of truth]].

Notable members of the Warsaw School of Mathematics have included:
* [[Wacław Sierpiński]]
* [[Kazimierz Kuratowski]]
* [[Edward Marczewski]]
* [[Bronisław Knaster]]
* [[Zygmunt Janiszewski]]
* [[Stefan Mazurkiewicz]]
* [[Stanisław Saks]]
* [[Karol Borsuk]]
* [[Roman Sikorski]]
* [[Nachman Aronszajn]]
* [[Samuel Eilenberg]]

Additionally, notable logicians of the [[Lwów-Warsaw School of Logic]], working at [[Warsaw]], have included:
* [[Stanisław Leśniewski]]
* [[Adolf Lindenbaum]]
* [[Alfred Tarski]]
* [[Jan Łukasiewicz]]
* [[Andrzej Mostowski]]
* [[Helena Rasiowa]]

Fourier analysis has been advanced at [[Warsaw]] by:
* [[Aleksander Rajchman]]
* [[Antoni Zygmund]]
* [[Józef Marcinkiewicz]]
* [[Otton M. Nikodym]]
* [[Jerzy Spława-Neyman]]

==See also==
* [[Polish School of Mathematics]]
* [[Kraków School of Mathematics]]
* [[Lwów School of Mathematics]]

{{warsaw-stub}}
{{math-stub}}

[[Category:Polish mathematics]]
[[Category:History of education in Poland]]
[[Category:History of mathematics]]
[[Category:History of Warsaw]]
[[Category:Science and technology in Poland]]</text>
      <sha1>0b8bkvcmr33alw498d6b33b25u233eu</sha1>
    </revision>
  </page>
  <page>
    <title>Étienne Ghys</title>
    <ns>0</ns>
    <id>7561937</id>
    <revision>
      <id>866820194</id>
      <parentid>738488447</parentid>
      <timestamp>2018-11-01T19:30:39Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>added statement about doctoral students</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2278">{{Use dmy dates|date=May 2013}}
'''Étienne Ghys''' (born 29 December 1954) is a French mathematician. His research focuses mainly on [[geometry]] and [[dynamical system]]s, though his mathematical interests are broad. He also expresses much interest in the historical development of mathematical ideas, especially the contributions of [[Henri Poincaré]].

[[File:Étienne Ghys.jpeg|thumb|Étienne Ghys, 2007.]]

He co-authored the [[computer graphics]] mathematical movie ''[[Dimensions (animation)|Dimensions: A walk through mathematics!]]''

Alumnus of the [[École normale supérieure de Saint-Cloud]], he is currently a [[CNRS]] "directeur de recherche" at the [[École Normale Supérieure de Lyon|École normale supérieure]] in [[Lyon]]. He is also editor-in-chief of the [[Publications Mathématiques de l'IHÉS]] and a member of the [[French Academy of Sciences]].

He was an invited speaker at the [[International Congress of Mathematicians|ICM]] of Kyoto in 1990, and a plenary speaker at the ICM of Madrid in 2006.&lt;ref&gt;http://www.mathunion.org/db/ICM/Speakers/SortedByLastname.php&lt;/ref&gt;

In 2015, he was awarded the inaugural [[Clay Mathematics Institute|Clay Award for Dissemination of Mathematical Knowledge]].&lt;ref&gt;http://www.claymath.org/events/news/clay-award-dissemination&lt;/ref&gt;

His doctoral students include [[Serge Cantat]].

==External links==
* [http://genealogy.math.ndsu.nodak.edu/id.php?id=104570 Étienne Ghys at the Mathematics Genealogy Project]
* [http://www.umpa.ens-lyon.fr/~ghys/ Homepage at the UMPA]
* [http://www.academie-sciences.fr/academie/membre/Ghys_notice_2001.pdf « Notice sur les travaux scientifiques d'Étienne Ghys »], an overview of his mathematical interests and results, written for his entry at the [[French Academy of Sciences]].
* [http://www.dimensions-math.org/Dim_E.htm Homepage of the movie ''Dimensions'']

== References ==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Ghys, Etienne}}
[[Category:1954 births]]
[[Category:Living people]]
[[Category:20th-century mathematicians]]
[[Category:French mathematicians]]
[[Category:Geometers]]
[[Category:Members of the French Academy of Sciences]]
[[Category:ENS Fontenay-Saint-Cloud-Lyon alumni]]
[[Category:Dynamical systems theorists]]


{{France-mathematician-stub}}</text>
      <sha1>dfdfeo77wh7q3jmi5psg9mn3m31rueh</sha1>
    </revision>
  </page>
</mediawiki>
