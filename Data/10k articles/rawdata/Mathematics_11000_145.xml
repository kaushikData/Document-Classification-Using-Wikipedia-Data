<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Accuracy paradox</title>
    <ns>0</ns>
    <id>59146042</id>
    <revision>
      <id>870948341</id>
      <parentid>870562307</parentid>
      <timestamp>2018-11-28T00:01:00Z</timestamp>
      <contributor>
        <username>JzG</username>
        <id>760284</id>
      </contributor>
      <comment>rm. academic [[vanity press]] IGI Global</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1329">The '''accuracy paradox''' is the [[paradox|paradoxical]] finding that [[accuracy]] is not a good metric for [[predictive model]]s when [[binary classification|classifying]] in [[predictive analytics]].  This is because a simple model may have a high level of accuracy but be too crude to be useful.  For example, if the incidence of category A is dominant, being found in 99% of cases, then predicting that &lt;u&gt;every&lt;/u&gt; case is category A will have an accuracy of 99%.  [[Precision and recall]] are better measures in such cases.&lt;ref name=Abma/&gt;&lt;ref name=PNEM/&gt;

==References==
{{reflist |refs=
&lt;ref name=Abma&gt;{{citation |last=Abma |first=B. J. M. |date=10 September 2009 |title=Evaluation of requirements management tools with support for traceability-based change impact analysis |publisher=University of Twente |pages=86–87 |url=https://www.utwente.nl/en/eemcs/trese/graduation_projects/2009/Abma.pdf}}&lt;/ref&gt;
&lt;ref name=PNEM&gt;{{citation |work=Information Access Evaluation. Multilinguality, Multimodality, and Visualization |year=2013 |publisher=Springer |isbn=9783642408021 |last1=Valverde-Albacete |last2=Carillo-de-Albornoz |last3=Peláez-Moreno |title=A Proposal for New Evaluation Metrics and Result Vizualization Technique for Sentiment Analysis Tasks}}&lt;/ref&gt;
}}

[[Category:Statistical paradoxes]]

{{statistics-stub}}</text>
      <sha1>lxbi15vwqnlukur6egcow0e8ss1evn4</sha1>
    </revision>
  </page>
  <page>
    <title>Boolean prime ideal theorem</title>
    <ns>0</ns>
    <id>314919</id>
    <revision>
      <id>867145101</id>
      <parentid>858405697</parentid>
      <timestamp>2018-11-03T23:48:06Z</timestamp>
      <contributor>
        <ip>2600:1702:E30:7870:18DA:E44C:9984:E90A</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14656">In [[mathematics]], the '''Boolean prime ideal theorem''' states that [[ideal (order theory)|ideals]] in a [[Boolean algebra (structure)|Boolean algebra]] can be extended to [[Ideal (order theory)#Prime ideals | prime ideal]]s.  A variation of this statement for [[filter (mathematics)|filters]] on sets is known as the [[#The ultrafilter lemma|ultrafilter lemma]].  Other theorems are obtained by considering different mathematical structures with appropriate notions of ideals, for example, [[ring (mathematics)|rings]] and prime ideals (of ring theory), or [[distributive lattice]]s and ''maximal'' ideals (of [[order theory]]).  This article focuses on prime ideal theorems from order theory.

Although the various prime ideal theorems may appear simple and intuitive, they cannot be deduced in general from the axioms of [[Zermelo–Fraenkel set theory]] without the axiom of choice  (abbreviated ZF). Instead, some of the statements turn out to be equivalent to the [[axiom of choice]] (AC), while others—the Boolean prime ideal theorem, for instance—represent a property that is strictly weaker than AC. It is due to this intermediate status between ZF and ZF&amp;nbsp;+&amp;nbsp;AC (ZFC) that the Boolean prime ideal theorem is often taken as an axiom of set theory. The abbreviations BPI or PIT (for Boolean algebras) are sometimes used to refer to this additional axiom.

==Prime ideal theorems==
An [[ideal (order theory)|order ideal]] is a (non-empty) [[directed set|directed]] [[lower set]]. If the considered [[partially ordered set]] (poset) has binary [[supremum|suprema]] (a.k.a. [[join and meet|joins]]), as do the posets within this article, then this is equivalently characterized as a non-empty lower set ''I'' that is closed for binary suprema (i.e. ''x'', ''y'' in ''I'' imply ''x''&lt;math&gt;\vee&lt;/math&gt;''y'' in ''I''). An ideal ''I'' is prime if its set-theoretic complement in the poset is a [[Filter (mathematics)|filter]]. Ideals are proper if they are not equal to the whole poset.

Historically, the first statement relating to later prime ideal theorems was in fact referring to filters—subsets that are ideals with respect to the [[duality (order theory)|dual]] order. The ultrafilter lemma states that every filter on a set is contained within some maximal (proper) filter—an ''ultrafilter''. Recall that filters on sets are proper filters of the Boolean algebra of its [[powerset]]. In this special case, maximal filters (i.e. filters that are not strict subsets of any proper filter) and prime filters (i.e. filters that with each union of subsets ''X''  and ''Y'' contain also ''X'' or ''Y'') coincide. The dual of this statement thus assures that every ideal of a powerset is contained in a prime ideal.

The above statement led to various generalized prime ideal theorems, each of which exists in a weak and in a strong form. ''Weak prime ideal theorems'' state that every ''non-trivial'' algebra of a certain class has at least one prime ideal. In contrast, ''strong prime ideal theorems'' require that every ideal that is disjoint from a given filter can be extended to a prime ideal that is still disjoint from that filter. In the case of algebras that are not posets, one uses different substructures instead of filters. Many forms of these theorems are actually known to be equivalent, so that the assertion that "PIT" holds is usually taken as the assertion that the corresponding statement for Boolean algebras (BPI) is valid.

Another variation of similar theorems is obtained by replacing each occurrence of ''prime ideal'' by ''maximal ideal''. The corresponding maximal ideal theorems (MIT) are often—though not always—stronger than their PIT equivalents.

== Boolean prime ideal theorem ==
The Boolean prime ideal theorem is the strong prime ideal theorem for Boolean algebras. Thus the formal statement is:

: Let ''B'' be a Boolean algebra, let ''I'' be an ideal and let ''F'' be a filter of ''B'', such that ''I'' and ''F'' are [[disjoint set|disjoint]]. Then ''I'' is contained in some prime ideal of ''B'' that is disjoint from ''F''.

The weak prime ideal theorem for Boolean algebras simply states:

: Every Boolean algebra contains a prime ideal.

We refer to these statements as the weak and strong ''BPI''.  The two are equivalent, as the strong BPI clearly implies the weak BPI, and the reverse implication can be achieved by using the weak BPI to find prime ideals in the appropriate quotient algebra.

The BPI can be expressed in various ways. For this purpose, recall the following theorem:

For any ideal ''I'' of a Boolean algebra ''B'', the following are equivalent:
* ''I'' is a prime ideal.
* ''I'' is a maximal ideal, i.e. for any proper ideal ''J'', if ''I'' is contained in ''J'' then ''I'' = ''J''.
* For every element ''a'' of ''B'', ''I'' contains exactly one of {''a'', ¬''a''}.
This theorem is a well-known fact for Boolean algebras. Its dual establishes the equivalence of prime filters and ultrafilters. Note that the last property is in fact self-dual—only the prior assumption that ''I'' is an ideal gives the full characterization. All of the implications within this theorem can be proven in ZF.

Thus the following (strong) maximal ideal theorem (MIT) for Boolean algebras is equivalent to BPI:

:Let ''B'' be a Boolean algebra, let ''I'' be an ideal and let ''F'' be a filter of ''B'', such that ''I'' and ''F'' are disjoint. Then ''I'' is contained in some maximal ideal of ''B'' that is disjoint from ''F''.

Note that one requires "global" maximality, not just maximality with respect to being disjoint from ''F''. Yet, this variation yields another equivalent characterization of BPI:

:Let ''B'' be a Boolean algebra, let ''I'' be an ideal and let ''F'' be a filter of ''B'', such that ''I'' and ''F'' are disjoint. Then ''I'' is contained in some ideal of ''B'' that is maximal among all ideals disjoint from ''F''.

The fact that this statement is equivalent to BPI is easily established by noting the following theorem: For any [[distributive lattice]] ''L'', if an ideal ''I'' is maximal among all ideals of ''L'' that are disjoint to a given filter ''F'', then ''I'' is a prime ideal. The proof for this statement (which can again be carried out in ZF set theory) is included in the article on ideals. Since any Boolean algebra is a distributive lattice, this shows the desired implication.

All of the above statements are now easily seen to be equivalent. Going even further, one can exploit the fact the dual orders of Boolean algebras are exactly the Boolean algebras themselves. Hence, when taking the equivalent duals of all former statements, one ends up with a number of theorems that equally apply to Boolean algebras, but where every occurrence of ''ideal'' is replaced by ''filter''. It is worth noting that for the special case where the Boolean algebra under consideration is a [[powerset]] with the [[subset]] ordering, the "maximal filter theorem" is called the ultrafilter lemma.

Summing up, for Boolean algebras, the weak and strong MIT, the weak and strong PIT, and these statements with filters in place of ideals are all equivalent. It is known that all of these statements are consequences of the [[Axiom of Choice]], ''AC'', (the easy proof makes use of [[Zorn's lemma]]), but cannot be proven in [[Zermelo–Fraenkel set theory|ZF]] (Zermelo-Fraenkel set theory without ''AC''), if ZF is [[consistent]]. Yet, the BPI is strictly weaker than the axiom of choice, though the proof of this statement, due to  J. D. Halpern and [[Azriel Lévy]] is rather non-trivial.

== Further prime ideal theorems ==
The prototypical properties that were discussed for Boolean algebras in the above section can easily be modified to include more general [[lattice (order)|lattices]], such as [[distributive lattice]]s or [[Heyting algebra]]s. However, in these cases maximal ideals are different from prime ideals, and the relation between PITs and MITs is not obvious.

Indeed, it turns out that the MITs for distributive lattices and even for Heyting algebras are equivalent to the axiom of choice. On the other hand, it is known that the strong PIT for distributive lattices is equivalent to BPI (i.e. to the MIT and PIT for Boolean algebras). Hence this statement is strictly weaker than the axiom of choice. Furthermore, observe that Heyting algebras are not self dual, and thus using filters in place of ideals yields different theorems in this setting. Maybe surprisingly, the MIT for the duals of Heyting algebras is not stronger than BPI, which is in sharp contrast to the abovementioned MIT for Heyting algebras.

Finally, prime ideal theorems do also exist for other (not order-theoretical) abstract algebras. For example, the MIT for rings implies the axiom of choice. This situation requires to replace the order-theoretic term "filter" by other concepts—for rings a "multiplicatively closed subset" is appropriate.

== The ultrafilter lemma ==
A filter on a set ''X'' is a nonempty collection of nonempty subsets of ''X'' that is closed under finite intersection and under superset.  An ultrafilter is a maximal filter.   The ultrafilter lemma states that every filter  on a set ''X'' is a subset of some [[ultrafilter]] on ''X''.&lt;ref&gt;{{citation
 | last = Halpern | first = James D.
 | issue = 3
 | journal = Proceedings of the American Mathematical Society
 | pages = 670–673
 | title = Bases in Vector Spaces and the Axiom of Choice
 | jstor = 2035388
 | volume = 17
 | year = 1966
 | publisher = American Mathematical Society
 | doi = 10.1090/S0002-9939-1966-0194340-1}}.&lt;/ref&gt;  This lemma is most often used in the study of [[topology]].  An ultrafilter that does not contain finite sets is called "non-principal".The ultrafilter lemma, and in particular the existence of non-principal ultrafilters (consider the filter of all sets with finite complements), follows easily from [[Zorn's lemma]].

The ultrafilter lemma is equivalent to the Boolean prime ideal theorem, with the equivalence provable in ZF set theory without the axiom of choice.  The idea behind the proof is that the subsets of any set form a Boolean algebra partially ordered by inclusion, and any Boolean algebra is representable as an algebra of sets by [[Stone's representation theorem]].

== Applications ==
Intuitively, the Boolean prime ideal theorem states that there are "enough" prime ideals in a Boolean algebra in the sense that we can extend ''every'' ideal to a maximal one. This is of practical importance for proving [[Stone's representation theorem for Boolean algebras]], a special case of [[Stone duality]], in which one equips the set of all prime ideals with a certain topology and can indeed regain the original Boolean algebra ([[up to]] [[isomorphism]]) from this data. Furthermore, it turns out that in applications one can freely choose either to work with prime ideals or with prime filters, because every ideal uniquely determines a filter: the set of all Boolean complements of its elements. Both approaches are found in the literature.

Many other theorems of general topology that are often said to rely on the axiom of choice are in fact equivalent to BPI. For example, the theorem that a product of compact [[Hausdorff spaces]] is compact is equivalent to it. If we leave out "Hausdorff" we get a [[Tychonoff's theorem|theorem]] equivalent to the full axiom of choice.

In [[graph theory]], the [[De Bruijn–Erdős theorem (graph theory)|de Bruijn–Erdős theorem]] is another equivalent to BPI. It states that, if a given infinite graph requires at least some finite number {{mvar|k}} in any [[graph coloring]], then it has a finite subgraph that also requires {{mvar|k|colors}}.&lt;ref&gt;{{citation
 | last = Läuchli | first = H.
 | doi = 10.1007/BF02771458
 | journal = Israel Journal of Mathematics
 | mr = 0288051
 | pages = 422–429
 | title = Coloring infinite graphs and the Boolean prime ideal theorem
 | volume = 9
 | year = 1971}}.&lt;/ref&gt;

A not too well known application of the Boolean prime ideal theorem is the existence of a [[non-measurable set]]&lt;ref&gt;{{citation
 | last = Sierpiński | first = Wacław | author-link = Wacław Sierpiński
 | journal = [[Fundamenta Mathematicae]]
 | pages = 96–99
 | title = Fonctions additives non complètement additives et fonctions non mesurables
 | volume = 30
 | year = 1938}}&lt;/ref&gt; (the example usually given is the [[Vitali set]], which requires the axiom of choice).  From this and the fact that the BPI is strictly weaker than the axiom of choice, it follows that the existence of non-measurable sets is strictly weaker than the axiom of choice.

In linear algebra, the Boolean prime ideal theorem can be used to prove that any two [[Basis (linear algebra)|bases]] of a given [[vector space]] have the same [[cardinality]].

==See also==
* [[List of Boolean algebra topics]]

==Notes==
{{reflist}}

==References==

*{{citation
 | last1 = Davey | first1 = B. A.
 | last2 = Priestley | first2 = H. A. | author2-link = Hilary Priestley
 | edition = 2nd
 | isbn = 978-0-521-78451-1
 | publisher = Cambridge University Press
 | title = Introduction to Lattices and Order
 | year = 2002}}.
: ''An easy to read introduction, showing the equivalence of PIT for Boolean algebras and distributive lattices.''

*{{citation
 | last = Johnstone | first = Peter | author-link = Peter Johnstone (mathematician)
 | isbn = 978-0-521-33779-3
 | publisher = Cambridge University Press
 | series = Cambridge studies in advanced mathematics
 | title = Stone Spaces
 | volume = 3
 | year = 1982}}.
: ''The theory in this book often requires choice principles. The notes on various chapters discuss the general relation of the theorems to PIT and MIT for various structures (though mostly lattices) and give pointers to further literature.''

*{{citation
 | last = Banaschewski | first = B.
 | doi = 10.1112/jlms/s2-27.2.193
 | issue = 2
 | journal = [[Journal of the London Mathematical Society]] |series=Second Series

| pages = 193–202

 | title = The power of the ultrafilter theorem
 | volume = 27
 | year = 1983}}.
: ''Discusses the status of the ultrafilter lemma.''

*{{citation
 | last = Erné | first = M.
 | journal = Applied Categorical Structures
 | pages = 115–144
 | title = Prime ideal theory for general algebras
 | volume = 8
 | year = 2000
 | doi = 10.1023/A:1008611926427}}.
: ''Gives many equivalent statements for the BPI, including prime ideal theorems for other algebraic structures. PITs are considered as special instances of separation lemmas.''

[[Category:Theorems in algebra]]
[[Category:Boolean algebra]]
[[Category:Order theory]]
[[Category:Axiom of choice]]</text>
      <sha1>rr0g5htn0whdysmq7ytdj7qdpklsuug</sha1>
    </revision>
  </page>
  <page>
    <title>Bose–Einstein condensation (network theory)</title>
    <ns>0</ns>
    <id>8337948</id>
    <revision>
      <id>854922602</id>
      <parentid>833308141</parentid>
      <timestamp>2018-08-14T18:29:47Z</timestamp>
      <contributor>
        <ip>2620:106:6000:20:F0:0:0:50</ip>
      </contributor>
      <comment>beta = 1 / T, not beta = 1 ... see the cited paper Bianconi and Barabasi just after equation 2 is introduced</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17191">{{Multiple issues|
{{MOS|date=February 2011}}
{{refimprove|date=February 2011}}
{{cleanup|date=February 2011}}
{{review|date=February 2011}}
}}
[[Image:Bec5555.jpg|thumb|350px|right|Bose–Einstein condensation at 400, 200, and 50 nanokelvins (left to right).  As the temperature falls, more and more atoms "condense" to the same energy level, producing more prominent "peaks".]]

'''Bose–Einstein condensation in networks''' is a [[phase transition]] observed in [[complex network]]s that can be described with the same [[mathematical model]] as that explaining [[Bose–Einstein condensation]] in physics.

==Background==
In [[physics]], a [[Bose–Einstein condensate]] is a state of matter that occurs in certain gases at very low temperatures. Any elementary particle, atom, or molecule, can be classified as one of two types: a [[boson]] or a [[fermion]]. For example, an electron is a fermion, while a photon or a [[helium]] atom is a boson.  In [[quantum mechanics]], the energy of a (bound) particle is limited to a set of discrete values, called energy levels. An important characteristic of a fermion is that it obeys the [[Pauli exclusion principle]], which states that no two fermions may occupy the same state. Bosons, on the other hand, do not obey the exclusion principle, and any number can exist in the same state. As a result, at very low energies (or temperatures), a great majority of the bosons in a [[Bose gas]] can be crowded into the lowest energy state, creating a Bose–Einstein condensate.

A Bose–Einstein condensate is therefore a quantum phenomenon characteristic of boson particles. Nevertheless, a similar type of condensation transition can occur also in off-equilibrium classical systems and in particular, complex networks. In this context, a condensation phenomenon occurs when a distribution of a large number of elements in a large number of element classes becomes degenerate, i.e. instead of having an even distribution of elements in the classes, one class (or a few classes) become occupied by a finite fraction of all the elements of the system.

Condensation transitions occur in traffic jams, where long queues of cars are found,&lt;ref name="Evans"&gt;M. R. Evans T. Hanney J. Phy. A: Math. Gen 38 (2005) R195-R239&lt;/ref&gt; in wealth distribution models&lt;ref name="Bouchaud"&gt;J. P. Bouchaud and M. Mezard Wealth Condensation in a simple model of economy, Physica A statistical Mechanics and its Applications 282 (2000) 536&lt;/ref&gt; where a few people might have a finite fraction of all the wealth, or in Ising [[spin glass]] models.&lt;ref name=Mezard&gt;M. Mezard and A. Montanari, Information Physics and computation, Oxford Graduate Texts 2009&lt;/ref&gt; However, the condensation transition in these models cannot in general be mapped to a Bose–Einstein condensation.

A network is characterized by a set of nodes or vertices and a set of links between these nodes. In mathematics, [[graph theory]] describes networks in general. The theory of [[random graphs]] deals in particular with stochastic networks (networks in which each link is present with a given probability ''p''). A large class of networks that describe real complex systems like the Internet, the [[world wide web]], airport networks or the biological networks of molecular interactions, are described by random networks. [[Network theory]] is a recent field of research  which investigates methods of characterizing and modeling real complex networks. In particular it has been found that many complex networks have universal features like the [[Small-world network|small world]] property and a scale-free degree distribution. The scale-free degree distribution of networks can be caused by the "[[preferential attachment]]" mechanism.&lt;ref name="ALB"&gt;{{cite book |title=Linked |last=Barabási |first=Albert-László |authorlink=Albert-László Barabási  |year=2002 |publisher=Perseus Publishing |location=Cambridge, MA |isbn=0-7382-0667-9}}&lt;/ref&gt;

==History==
In the late 1990s, Ginestra Bianconi was a graduate student, working with Prof. [[Albert-László Barabási]], a noted network theorist.&lt;ref name="ALB" /&gt; At his request, she began investigating the [[fitness model (network theory)|fitness model]], a model in which the network evolves with the "preferential attachment" mechanism but in addition, each node has an intrinsic quality or fitness that describe its ability to acquire new links. For example, in the world wide web each web page has a different content, in [[social network]]s different people might have different social skills, in airport networks each airport is connected to cities with unevenly distributed economic activity, etc. It was found that under certain conditions, a single node could acquire most, if not all of the links in the network, resulting in the network analog of a [[Bose–Einstein condensate]]. In particular, a perfect analogy&lt;ref name=bia&gt;Bianconi, G.;  Barabási, A.-L. (2001). "[http://prola.aps.org/abstract/PRL/v86/i24/p5632_1 Bose–Einstein Condensation in Complex Networks.]" ''[[Physical Review Letters|Phys. Rev. Lett.]]'' '''86''': 5632–35.&lt;/ref&gt; could be drawn between the mathematics of the network and the mathematics of a Bose gas if  each node in the network were thought of as an energy level, and each link as a particle. These results have implications for any real situation involving random graphs, including the world wide web, social networks, and financial markets.

==The concept==
The result of the efforts of Bose and Einstein is the concept of a [[Bose gas]], governed by the [[Bose–Einstein statistics]], which describes the statistical distribution of identical particles with integer spin, now known as bosons (such as the photon and helium-4). In Bose–Einstein statistics, any number of identical bosons can be in the same state. In particular, given an energy state {{mvar|ε}}, the number of non-interacting bosons in thermal equilibrium at temperature {{math|''T'' {{=}} {{sfrac|1|''β''}}}} is given by the Bose occupation number

: &lt;math&gt;n(\varepsilon)=\frac{1}{e^{\beta(\varepsilon-\mu)}-1}&lt;/math&gt;

where the constant {{mvar|μ}} is determined by an equation describing the conservation of the number of particles

:&lt;math&gt;N=\int d\varepsilon \, g(\varepsilon) \, n(\varepsilon)&lt;/math&gt;

with {{math|''g''(''ε'')}} being the density of states of the system.

This last equation may lack a solution at low enough temperatures when {{math|''g''(''ε'') → 0}} for {{math|''ε'' → 0}}. In this case a critical temperature {{math|''T&lt;sub&gt;c&lt;/sub&gt;''}} is found such that for {{math|''T'' &lt; ''T&lt;sub&gt;c&lt;/sub&gt;''}} the system is in a Bose-Einstein condensed phase and a finite fraction of the bosons are in the ground state.

The density of states {{math|''g''(''ε'')}} depends on the dimensionality of the space.  In particular &lt;math&gt;g(\varepsilon)\sim \varepsilon^{\frac{d-2}{2}}&lt;/math&gt; therefore {{math|''g''(''ε'') → 0}} for {{math|''ε'' → 0}} only in dimensions {{math|''d'' &gt; 2}}. Therefore, a Bose-Einstein condensation of an ideal Bose gas can only occur for dimensions {{math|''d'' &gt; 2}}.

For a uniform three-dimensional Bose gas consisting of non-interacting particles with no apparent internal degrees of freedom, the critical temperature is given by:

:&lt;math&gt;T_c=\left(\frac{n}{\zeta \left (\tfrac{3}{2} \right)}\right)^{\tfrac{2}{3}}\frac{h^2}{2\pi m k_B}&lt;/math&gt;

where:

* {{mvar|n}} is the particle density;
* {{mvar|m}} is the mass per boson;
* {{mvar|h}} is [[Planck's constant]];
* {{math|''k&lt;sub&gt;B&lt;/sub&gt;''}} is the [[Boltzmann constant]]; 
* {{mvar|ζ}} is the [[Riemann zeta function]]; and
* {{math|''ζ''({{sfrac|3|2}}) ≈ 2.6124}}.

==Connection with network theory==
The evolution of many complex systems, including the World Wide Web, business, and citation networks, is encoded in the dynamic web describing the interactions between the system’s constituents. Despite their irreversible and nonequilibrium nature these networks follow Bose statistics and can undergo Bose–Einstein condensation. Addressing the dynamical properties of these nonequilibrium systems within the framework of equilibrium quantum gases predicts that the “first-mover-advantage,” “fit-get-rich ('''FGR'''),” and “winner-takes-all” phenomena observed in competitive systems are thermodynamically distinct phases of the underlying evolving networks.&lt;ref name="bia"/&gt;

[[File:Schematic illustration of mapping between network model and Bose-Einstein Condensate.jpg|thumb|450px|left|Schematic illustration of the mapping between the network model and the Bose gas.&lt;ref name=bia/&gt;]]

Starting from the [[fitness model (network theory)|fitness model]], the mapping of a Bose gas to a network can be done by assigning an energy {{math|''ε&lt;sub&gt;i&lt;/sub&gt;''}} to each node, determined by its fitness through the relation&lt;ref name=bara&gt;Albert, R.; Barabási, A.-L. (2002). "[http://prola.aps.org/abstract/RMP/v74/i1/p47_1 Statistical mechanics of complex networks.]" ''[[Reviews of Modern Physics|Rev. Mod. Phys.]]'' '''74''': 47–97.&lt;/ref&gt;

: &lt;math&gt;\varepsilon_i=-\frac{1}{\beta}\ln{\eta_i}&lt;/math&gt;

where {{math|''β'' {{=}} 1 / T}} &lt;!-- plays the role of inverse temperature --&gt;. In particular when {{math|''β'' {{=}} 0}} all the nodes have equal fitness, when instead {{math|''β'' ≫ 1}} nodes with different "energy" have very different fitness. We assume that the network evolves through a modified [[preferential attachment]] mechanism. At each time a new node {{mvar|i}} with energy {{math|''ε&lt;sub&gt;i&lt;/sub&gt;''}} drawn from a probability distribution {{math|''p''(''ε'')}} enters in the network and attach a new link to a node {{mvar|j}} chosen with probability:

: &lt;math&gt;\Pi_j=\frac{e^{-\beta\varepsilon_j}k_j}{\sum_r e^{-\beta\varepsilon_r}k_r}.&lt;/math&gt;

In the mapping to a Bose gas, we assign to every new link linked by preferential attachment to node {{mvar|j}} a particle in the energy state {{math|''ε&lt;sub&gt;j&lt;/sub&gt;''}}.

The continuum theory predicts that the rate at which links accumulate on node {{mvar|i}} with "energy " {{math|''ε&lt;sub&gt;i&lt;/sub&gt;''}} is given by

: &lt;math&gt;\frac{\partial k_i(\varepsilon_i,t,t_i)}{\partial t}=m\frac{e^{-\beta\varepsilon_i}k_i(\varepsilon_i,t,t_i)}{Z_t}&lt;/math&gt;

where &lt;math&gt;k_i(\varepsilon_i,t, t_i)&lt;/math&gt; indicating the number of links attached to node {{mvar|i}} that was added to the network at the time step &lt;math&gt;t_i&lt;/math&gt;. &lt;math&gt;Z_t&lt;/math&gt; is the [[Partition function (statistical mechanics)|partition function]], defined as:

: &lt;math&gt;Z_t=\sum_i  e^{-\beta\varepsilon_i}k_i(\varepsilon_i,t,t_i).&lt;/math&gt;

The solution of this differential equation is:

: &lt;math&gt;k_i(\varepsilon_i,t,t_i)=m\left(\frac{t}{t_i}\right)^{f(\varepsilon_i)}&lt;/math&gt;

where the dynamic exponent &lt;math&gt;f(\varepsilon)&lt;/math&gt; satisfies &lt;math&gt;f(\varepsilon)=e^{-\beta(\varepsilon-\mu)}&lt;/math&gt;, {{mvar|μ}} plays the role of the chemical potential, satisfying the equation

: &lt;math&gt;\int d\varepsilon \, p(\varepsilon) \frac{1}{e^{\beta(\varepsilon-\mu)}-1}=1&lt;/math&gt;

where {{math|''p''(''ε'')}} is the probability that a node has "energy" {{mvar|ε}} and "fitness" {{math|''η'' {{=}} ''e&lt;sup&gt;−βε&lt;/sup&gt;''}}. In the limit, {{math|''t'' → ∞}}, the occupation number, giving the number of links linked to nodes with "energy" {{mvar|ε}}, follows the familiar Bose statistics

: &lt;math&gt;n(\varepsilon)=\frac{1}{e^{\beta(\varepsilon -\mu)}-1}.&lt;/math&gt;

The definition of the constant {{mvar|μ}} in the network models is surprisingly similar to the definition of the chemical potential in a Bose gas. In particular for probabilities {{math|''p''(''ε'')}} such that {{math|''p''(''ε'') → 0}} for {{math|''ε'' → 0}} at high enough value of {{mvar|β}} we have a condensation phase transition in the network model. When this occurs, one node, the one with higher fitness acquires a finite fraction of all the links. The Bose–Einstein condensation in complex networks is therefore a [[network topology|topological]] phase transition after which the network has a star-like dominant structure.

==Bose–Einstein phase transition in complex networks==
[[Image:Bec2222.jpg|thumb|350px|right|Numerical evidence for Bose–Einstein condensation in a network model.&lt;ref name=bia/&gt;]]
The mapping of a Bose gas predicts the existence of two distinct phases as a function of the energy distribution. In the fit-get-rich phase, describing the case of uniform fitness, the fitter nodes acquire edges at a higher rate than older but less fit nodes. In the end the fittest node will have the most edges, but the richest node is not the absolute winner, since its share of the edges (i.e. the ratio of its edges to the total number of edges in the system) reduces to zero in the limit of large system sizes (Fig.2(b)). The unexpected outcome of this mapping is the possibility of Bose–Einstein condensation for {{math|''T'' &lt; ''T&lt;sub&gt;BE&lt;/sub&gt;''}}, when the fittest node acquires a finite fraction of the edges and maintains this share of edges over time (Fig.2(c)).

A representative [[Fitness model (network theory)|fitness distribution]] {{math|''ρ''(''η'')}} that leads to a condensations

:&lt;math&gt;\rho(\eta)=(1-\eta)^{\lambda} &lt;/math&gt;

with {{math|''λ'' {{=}} 1}}.

However, the existence of the Bose–Einstein condensation or the fit-get-rich phase does not depend on the temperature or {{mvar|β}} of the system but depends only on the functional form of the fitness distribution {{math|''ρ''(''ν'')}} of the system. In the end, {{mvar|β}} falls out of all topologically important quantities. In fact it can be shown that Bose–Einstein condensation exists in the fitness model even without mapping to a Bose gas.&lt;ref name=dor&gt;Dorogovtsev, S. N.; Mendes, J. F. F. (2001). "[http://prola.aps.org/abstract/PRE/v63/i5/e056125 Scaling properties of scale-free evolving networks: &amp;ensp;Continuous approach.] ''[[Physical Review|Phys. Rev. E]]'' '''63''': 056125.&lt;/ref&gt; A similar gelation can be seen in models with [[generalized scale-free model|superlinear preferential attachment]],&lt;ref name=kra&gt;Krapivsky, P. L.; Redner, S.; Leyvraz, F. (2000). "[http://prola.aps.org/abstract/PRL/v85/i21/p4629_1 Connectivity of Growing Random Networks.]" ''[[Physical Review Letters|Phys. Rev.
Lett.]]'' '''85''': 4629–32.&lt;/ref&gt; however, it is not clear whether this is an accident or a deeper connection lies between this and the fitness model.

{{-}}

== Bose–Einstein condensation in evolutionary models and ecological systems ==
In evolutionary models each species reproduces proportionally to its fitness. In the infinite alleles model, each mutation generates a new species with a random fitness. This model was studied by the statistician [[John Kingman|J. F. C. Kingman]] and is known as the "house of cards" models.&lt;ref name="Kingman"&gt;J. F C Kingman, A simple model for the balance between selection and mutation J. Appl. Prob. 15 (1978)1&lt;/ref&gt; Depending on the fitness distribution, the model shows a condensation phase transition. Kingman did not realize that this phase transition could be mapped to a Bose–Einstein condensation. Recently the mapping of this model to a Bose–Einstein condensation was made in the context of a stochastic model for non-[[Unified neutral theory of biodiversity|neutral]] ecologies.&lt;ref name="Ecologies"&gt;G. Bianconi L Ferretti and S. Franz, Non-neutral theory of biodiversity Europhys. Lett. 87 (2009) P07028&lt;/ref&gt; When the condensation phenomenon in an ecological system occurs, one species becomes dominant and strongly reduces the biodiversity of the system. This phase transition describes a basic stylized mechanism which is responsible for the large impact of invasive species in many ecological systems.

==Memory understood as an equilibrium Bose gas==
[[Herbert Fröhlich]] is the source of the idea that quantum coherent waves could be generated in the [[biological neural network]]. His studies claimed to show that with an oscillating charge in a thermal bath, large numbers of quanta may condense into a single state known as a Bose condensate.&lt;ref name=fro&gt;Frohlich, H. (1968). ''Long range coherence and energy storage in biological systems''. International Journal of Quantum Chemistry, 2, 641-649 [http://www.springerlink.com/content/u3r5637k10185774]&lt;/ref&gt; Already in 1970 Pascual-Leone had shown that memory experiments can be modelled by the Bose–Einstein occupancy model.&lt;ref name=pas&gt;Pascual-Leone, J. (1970). ''A mathematical model for the transition rule in Piaget's developmental stages''. Acta Psychologica, 32, 301-345&lt;/ref&gt; From this and a large body of other empirical findings (based on studies of [[EEG]] and [[psychometrics]]) Weiss and Weiss draw the generalized conclusion that [[memory span]] can be understood as the quantum number of a harmonic oscillator, where memory is to be mapped into an equilibrium Bose gas.&lt;ref name=wei&gt;Weiss V., Weiss H. (2003). ''The golden mean as clock cycle of brain waves''. Chaos, Solitons and Fractals, 18, 643-652. [http://www.v-weiss.de/chaos.html  Full text]&lt;/ref&gt;

==References==
&lt;references/&gt;

{{DEFAULTSORT:Bose-Einstein condensation: a network theory approach}}
[[Category:Applied and interdisciplinary physics]]
[[Category:Network theory]]</text>
      <sha1>1xosgw5cv7g4ed44ak9g7txtyasrd1p</sha1>
    </revision>
  </page>
  <page>
    <title>Change-making problem</title>
    <ns>0</ns>
    <id>20913204</id>
    <revision>
      <id>859970660</id>
      <parentid>853433977</parentid>
      <timestamp>2018-09-17T14:02:53Z</timestamp>
      <contributor>
        <username>Kranix</username>
        <id>12719072</id>
      </contributor>
      <comment>/* Greedy method */ Fixed grammar</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11104">The '''change-making problem''' addresses the question of finding the minimum number of coins (of certain denominations) that add up to a given amount of money. It is a special case of the integer [[knapsack problem|knapsack problem]], and has applications wider than just currency.

It is also the most common variation of the ''coin change problem'', a general case of [[partition problem|partition]] in which, given the available denominations of an infinite set of coins, the objective is to find out the number of possible ways of making a change for a specific amount of money, without considering the order of the coins.

It is [[Weak NP-completeness|weakly NP-hard]], but may be solved optimally in [[pseudo-polynomial time]] by [[dynamic programming]].&lt;ref&gt;{{cite book
 | last1 = Cormen | first1 = Thomas H.
 | last2 = Leiserson | first2 = Charles E.
 | last3 = Rivest | first3 = Ronald L.
 | last4 = Stein | first4 = Clifford
 | at = Problem 16-1, p. 446
 | publisher = MIT Press
 | title = [[Introduction to Algorithms]]
 | year = 2009}}&lt;/ref&gt;&lt;ref&gt;{{cite book
 | last1 = Goodrich | first1 = Michael T.
 | last2 = Tamassia | first2 = Roberto
 | at = Exercise A-12.1, p. 349
 | publisher = Wiley
 | title = Algorithm Design and Applications
 | year = 2015}}&lt;/ref&gt;

==Mathematical definition==
Coin values can be modeled by a set of {{mvar|n}} distinct positive [[integer]] values (whole numbers), arranged in increasing order as {{math|''w''&lt;sub&gt;1&lt;/sub&gt; {{=}} 1}} through {{math|''w''&lt;sub&gt;''n''&lt;/sub&gt;}}. The problem is: given an amount {{mvar|W}}, also a positive integer, to find a set of non-negative (positive or zero) integers {{math|{''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;}}}, with each {{math|''x''&lt;sub&gt;''j''&lt;/sub&gt;}} representing how often the coin with value {{math|''w''&lt;sub&gt;''j''&lt;/sub&gt;}} is used, which minimize the total number of coins {{math|''f''(''W'')}}

: &lt;math&gt;f(W)=\sum_{j=1}^n x_j&lt;/math&gt;

subject to

: &lt;math&gt;\sum_{j=1}^n w_j x_j = W.&lt;/math&gt;

==Non-currency examples==
An application of change-making problem can be found in computing the ways one can make a [[nine dart finish]] in a game of darts.

Another application is computing the possible atomic (or isotopic) composition of a given mass/charge peak in mass spectrometry.

==Methods of solving==

===Simple dynamic programming===
A classic [[dynamic programming]] strategy works upward by finding the combinations of all smaller values that would sum to the current threshold.&lt;ref&gt;* {{cite journal |author=J.W.Wright |title=The Change-Making Problem |journal=Journal of the Association for Computing Machinery |volume=22 |issue=1 |year=1975 |pages=125-128 |doi=10.1145/321864.321874 }}&lt;/ref&gt; Thus, at each threshold, all previous thresholds are potentially considered to work upward to the goal amount ''W''. For this reason, this dynamic programming approach may require a number of steps that is at least quadratic in the goal amount ''W''.

==== Optimal substructure ====

Since the problem exhibits [[optimal substructure]], dynamic programming strategy can be applied to reach a solution as follows:

Firstly, given that &lt;math&gt;S&lt;/math&gt; is the optimal solution that contains exactly &lt;math&gt;n&lt;/math&gt; coins, hence &lt;math&gt;S' = S - c&lt;/math&gt;. It may seem as if &lt;math&gt;c \in S&lt;/math&gt;, is the optimal solution for the sub-problem that contains exactly &lt;math&gt;n - c&lt;/math&gt; coins.

However, &lt;math&gt;S'&lt;/math&gt; does not contain &lt;math&gt;n - c&lt;/math&gt; coins, and is not optimal, therefore the solution is known as &lt;math&gt;X \neq S'&lt;/math&gt;, hence &lt;math&gt;X&lt;/math&gt; becomes the optimal solution, since it must contain fewer coins than &lt;math&gt;S'&lt;/math&gt;.

Finally, combining &lt;math&gt;X&lt;/math&gt; with &lt;math&gt;c&lt;/math&gt; achieves the optimal solution that contains exactly &lt;math&gt;n&lt;/math&gt; coins, while contradicting any assumptions that &lt;math&gt;S&lt;/math&gt; is the optimal solution for the original problem.

==== Implementation ====

The following is a dynamic programming implementation (with Python 3) which uses a matrix to keep track of the optimal solutions to sub-problems, and returns the minimum number of coins. A second matrix may be used to obtain the set of coins for the optimal solution.

&lt;source lang="python" line="1"&gt;
def _get_change_making_matrix(set_of_coins, r):
    m = [[0 for _ in range(r + 1)] for _ in range(len(set_of_coins) + 1)]
    for i in range(r + 1):
        m[0][i] = i
    return m

def change_making(coins, n):
    """This function assumes that all coins are available infinitely.
    n is the number to obtain with the fewest coins.
    coins is a list or tuple with the available denominations."""
    m = _get_change_making_matrix(coins, n)
    for c in range(1, len(coins) + 1):
        for r in range(1, n + 1):
            # Just use the coin coins[c - 1].
            if coins[c - 1] == r:
                m[c][r] = 1
            # coins[c - 1] cannot be included.
            # Use the previous solution for making r,
            # excluding coins[c - 1].
            elif coins[c - 1] &gt; r:
                m[c][r] = m[c - 1][r]
            # coins[c - 1] can be used.
            # Decide which one of the following solutions is the best:
            # 1. Using the previous solution for making r (without using coins[c - 1]).
            # 2. Using the previous solution for making r - coins[c - 1] (without
            #      using coins[c - 1]) plus this 1 extra coin.
            else:
                m[c][r] = min(m[c - 1][r], 1 + m[c][r - coins[c - 1]])
    return m[-1][-1]
&lt;/source&gt;

===Dynamic programming with the probabilistic convolution tree===
The probabilistic convolution tree&lt;ref name="Serang" &gt;{{cite journal|last=Serang|first=O.|title=The Probabilistic Convolution Tree: Efficient Exact Bayesian Inference for Faster LC-MS/MS Protein Inference
|journal=PLOS ONE|volume=9|year=2012|doi=10.1371/journal.pone.0091507|ref=harv|issue=3|pages=e91507|pmid=24626234|pmc=3953406|bibcode=2014PLoSO...991507S}}&lt;/ref&gt; can also be used as a more efficient dynamic programming approach. The probabilistic convolution tree merges pairs of coins to produce all amounts which can be created by that pair of coins (with neither coin present, only the first coin present, only the second coin present, and both coins present), and then subsequently merging pairs of these merged outcomes in the same manner. This process is repeated until the final two collections of outcomes are merged into one, leading to a balanced binary tree with ''W log(W)'' such merge operations. Furthermore, by discretizing the coin values, each of these merge operations can be performed via convolution, which can often be performed more efficiently with the [[fast Fourier transform]] (FFT). In this manner, the probabilistic convolution tree may be used to achieve a solution in sub-quadratic number of steps: each convolution can be performed in ''n log(n)'', and the initial (more numerous) merge operations use a smaller ''n'', while the later (less numerous) operations require ''n'' on the order of ''W''.

The probabilistic convolution tree-based dynamic programming method also efficiently solves the probabilistic generalization of the change-making problem, where uncertainty or fuzziness in the goal amount ''W'' makes it a discrete distribution rather than a fixed quantity, where the value of each coin is likewise permitted to be fuzzy (for instance, when an exchange rate is considered), and where different coins may be used with particular frequencies.

===Greedy method===
For the so-called canonical coin systems, like those used in the US and many other countries, a [[greedy algorithm]] of picking the largest denomination of coin which is not greater than the remaining amount to be made will produce the optimal result.&lt;ref&gt;
{{cite journal |author=Xuan Cai |title=Canonical Coin Systems for CHANGE-MAKING Problems |journal=Proceedings of the Ninth International Conference on Hybrid Intelligent Systems |volume=1 |pages=499–504 |year=2009 |doi=10.1109/HIS.2009.103 |arxiv=0809.0400 }}
&lt;/ref&gt; This is not the case for arbitrary coin systems, though: if the coin denominations were 1, 3 and 4, then to make 6, the greedy algorithm would choose three coins (4,1,1) whereas the optimal solution is two coins (3,3).

However, there is a modified version of greedy algorithm to solve this question. In our case, we have 
:&lt;math&gt;W=x_1+3x_2+4x_3&lt;/math&gt;
where &lt;math&gt;0 \leq x_1 \leq 2&lt;/math&gt; and &lt;math&gt;0 \leq x_2 \leq 2&lt;/math&gt; 
since &lt;math&gt;3w_1=w_2&lt;/math&gt; and &lt;math&gt;3w_2=w_1+2w_3&lt;/math&gt;.

Now let &lt;math&gt;y=x_1+3x_2&lt;/math&gt;. We can write
:&lt;math&gt;W=y+4x_3&lt;/math&gt; 
where &lt;math&gt;0 \leq y \leq 8&lt;/math&gt;.

For example, given &lt;math&gt;W=2018&lt;/math&gt;, we have &lt;math&gt;2018=6+4 \times 503&lt;/math&gt;.
Hence &lt;math&gt;f(2018)=f(6)+503=505&lt;/math&gt;.

Therefore 
:&lt;math&gt;f(W)=[W/4]-1+f(4+W\%4)&lt;/math&gt;
where &lt;math&gt;[W/4]&lt;/math&gt; denotes the largest integer less than or equal to &lt;math&gt;W/4&lt;/math&gt;
and &lt;math&gt;W\%4&lt;/math&gt; denotes the remainder of &lt;math&gt;W&lt;/math&gt; divided by 4.

== Related problems ==
The "optimal [[denomination (currency)|denomination]] problem"&lt;ref&gt;
{{cite journal |author=J. Shallit |title=What this country needs is an 18c piece |journal=[[Mathematical Intelligencer]] |volume=25 |issue=2| year=2003 |pages=20–23 |doi=10.1007/BF02984830 |url=http://www.cs.uwaterloo.ca/~shallit/Papers/change2.pdf}}
&lt;/ref&gt; is a problem for people who design entirely new currencies. It asks what denominations should be chosen for the coins in order to minimize the average cost of making change, that is, the average number of coins needed to make change? The version of this problem assumed that the people making change will use the minimum number of coins (from the denominations available). One variation of this problem assumes that the people making change will use the "greedy algorithm" for making change, even when that requires more than the minimum number of coins. Most current currencies use a [[1-2-5 series]], but some other set of denominations would require fewer denominations of coins or a smaller average number of coins to make change or both.

==See also==
* [[List of knapsack problems]]
* [[Coin problem]]
* [[package-merge algorithm#The coin collector's problem|The coin collector's problem]]

==References==
{{reflist}}

== Further reading ==
* {{cite journal |author=X. Cai |title=Canonical Coin Systems for Change-Making Problems |journal=Proceedings of the Ninth International Conference on Hybrid Intelligent Systems |year=2009 |pages=499–504 |doi=10.1109/HIS.2009.103 |arxiv=0809.0400|ref=Cai}}
* {{cite journal |author=M. Adamaszek, A. Niewiarowska |title=Combinatorics of the change-making problem |journal=European Journal of Combinatorics |volume=31 |issue=1 |year=2010 |pages=47–63 |doi=10.1016/j.ejc.2009.05.002 |arxiv=0801.0120}}
* {{cite journal |author=J.W.Wright |title=The Change-Making Problem |journal=Journal of the Association for Computing Machinery |volume=22 |issue=1 |year=1975 |pages=125-128 |doi=10.1145/321864.321874 }}

[[Category:Number theory]]
[[Category:Recreational mathematics]]
[[Category:Combinatorial optimization]]
[[Category:Articles with example Python code]]</text>
      <sha1>cjq6ndyhle9hpu8q49u71guj7s2xjlq</sha1>
    </revision>
  </page>
  <page>
    <title>Chen Chung Chang</title>
    <ns>0</ns>
    <id>25413983</id>
    <revision>
      <id>862475072</id>
      <parentid>862475043</parentid>
      <timestamp>2018-10-04T16:28:09Z</timestamp>
      <contributor>
        <ip>219.143.155.24</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2710">{{Infobox scientist
| name = C. C. Chang
| image = C C Chang.jpg
| image_size = 
| alt = 
| birth_date = [[#{{harvid|Chang|Keisler|1990}}|{{Birth year and age|1927}}]]
| birth_place = 
| death_date = 
| death_place = 
| fields = [[Mathematics]]
| workplaces = [[University of California, Los Angeles]]
| alma_mater = 
| doctoral_advisor = [[Alfred Tarski]]
| doctoral_students = 
| known_for = [[Chang's conjecture]]
| influences = 
| influenced = 
| awards = 
| signature = &lt;!--(filename only)--&gt;
| signature_alt = 
| footnotes = 
}}
'''Chen Chung Chang''' (Chinese: 张晨钟) is a [[mathematician]] who works in [[model theory]]. He obtained  his PhD from [[UC Berkeley|Berkeley]] in 1955 on "Cardinal and Ordinal Factorization of Relation Types" under [[Alfred Tarski]]. He wrote the standard text {{harvtxt|Chang|Keisler|1990}} on model theory. [[Chang's conjecture]] and [[Chang's model]] are named after him. He also proved the ordinal partition theorem (expressed in the [[Arrow notation (Ramsey theory)|arrow notation]] for [[Ramsey theory]]) ω&lt;sup&gt;ω&lt;/sup&gt;→(ω&lt;sup&gt;ω&lt;/sup&gt;,3)&lt;sup&gt;2&lt;/sup&gt;, originally a problem of [[Paul Erdős|Erdős]] and [[András Hajnal|Hajnal]]. He also introduced [[MV-algebra]]s as models for [[Łukasiewicz logic]]. Chang is emeritus professor at the mathematics department of the [[University of California, Los Angeles]].

== Selected publications ==
*{{Citation |last1=Chang | first1=Chen Chung | last2=Keisler | first2=H. Jerome | author2-link=Howard Jerome Keisler | title=Continuous Model Theory | series=Annals of Mathematical Studies | volume=58 |publisher=Princeton University Press | year=1966 | postscript=; xii+165 pp. | url=https://books.google.com/books/about/Continuous_Model_Theory.html?id=uTGdPSI5rI4C}}
*{{Citation | last1=Chang | first1=Chen Chung | last2=Keisler | first2=H. Jerome | author2-link=Howard Jerome Keisler | title=Model Theory | publisher=[[Elsevier]] | edition=3rd | series=Studies in Logic and the Foundations of Mathematics | isbn=978-0-444-88054-3 | year=1990 | url=https://books.google.com/books/about/Model_Theory.html?id=uiHq0EmaFp0C}}
* C. C. Chang. Algebraic analysis of many-valued logics. Transactions of the American Mathematical Society, 88, 467–490, 1958, {{doi|10.1090/S0002-9947-1958-0094302-9}}

==External links==
*{{MathGenealogy|id=13228}}

{{Authority control}}

{{DEFAULTSORT:Chang, Chen Chung}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Living people]]
[[Category:Model theorists]]
[[Category:University of California, Berkeley alumni]]
[[Category:University of California, Los Angeles faculty]]
[[Category:1927 births]]


{{mathematician-stub}}</text>
      <sha1>7nddo0wlhsw332ys0zsxjef6sfa55rk</sha1>
    </revision>
  </page>
  <page>
    <title>Chowla–Selberg formula</title>
    <ns>0</ns>
    <id>596179</id>
    <revision>
      <id>862708557</id>
      <parentid>852441876</parentid>
      <timestamp>2018-10-06T05:13:55Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3460">In [[mathematics]], the '''Chowla–Selberg formula''' is the evaluation of a certain product of values of the [[Gamma function]] at rational values in terms of values of the [[Dedekind eta function]] at imaginary quadratic irrational numbers. The result was essentially found by {{harvs|txt|author-link=Mathias Lerch|last=Lerch|year=1897}} and rediscovered by {{harvs|txt|last=Chowla|author1-link=Sarvadaman Chowla|Chowla|author2-link=Atle Selberg|last2=Selberg|year1=1949|year2=1967}}.

==Statement==

In logarithmic form, the Chowla–Selberg formula states that in certain cases the sum

: &lt;math&gt; \frac{w}{4}\sum_r \chi(r)\log \Gamma\left( \frac{r}{D} \right) = \frac{h}{2}\log(4\pi\sqrt{|D|})
+\sum_\tau\log\left(\sqrt{\Im(\tau)}|\eta(\tau)|^2\right)
&lt;/math&gt;

can be evaluated using the [[Kronecker limit formula]]. Here χ is the [[quadratic residue symbol]] modulo ''D'', where ''−D'' is the [[discriminant]] of an imaginary [[quadratic field]]. The sum is taken over 0 &lt; ''r'' &lt; ''D'', with the usual convention χ(''r'') = 0 if ''r'' and ''D'' have a common factor. The function η is the [[Dedekind eta function]], and ''h'' is the class number, and ''w'' is the number of roots of unity.

==Origin and applications==
The origin of such formulae is now seen to be in the theory of [[complex multiplication]], and in particular in the theory of periods of an [[abelian variety of CM-type]]. This has led to much research and generalization. In particular there is an analog  of the Chowla–Selberg formula for [[p-adic number]]s, involving a [[p-adic gamma function]], called the [[Gross–Koblitz formula]].

The Chowla–Selberg formula gives a formula for  a finite product of values of the eta functions. By combining this with the theory of [[complex multiplication]], one can give a formula for the individual absolute values of the eta function as
:&lt;math&gt;\Im(\tau)|\eta(\tau)|^4 = \frac{\alpha}{4\pi\sqrt{|D|}} \prod_r\Gamma(r/|D|)^{\chi(r)\frac{w}{2h}}&lt;/math&gt;
for some algebraic number α.

==Examples==

Using the reflection formula for the gamma function gives:

*&lt;math&gt;\eta(i) = 2^{-1}\pi^{-3/4}\Gamma(\tfrac{1}{4})&lt;/math&gt;

==See also==
* [[Multiplication theorem]]

{{Reflist}}

==References==

*{{Citation | last1=Chowla | first1=S. | last2=Selberg | first2=Atle | title=On Epstein's zeta function. I | jstor=88112 | mr=0030997  | year=1949 | journal=[[Proceedings of the National Academy of Sciences|Proceedings of the National Academy of Sciences of the United States of America]] | issn=0027-8424 | volume=35 | pages=371–374 | doi=10.1073/pnas.35.7.371| pmc=1063041 }}
*{{Citation
| title=On Epstein's Zeta-function
| first2=Atle
| last2=Selberg
| author2-link=Atle Selberg
| first=Sarvadaman
| last=Chowla
| journal=[[Journal für die reine und angewandte Mathematik]]
| year=1967
| volume=227
| pages=86–110
| doi=10.1515/crll.1967.227.86
| mr=0215797
| issue=227
}}
*{{Citation
| last=Lerch
| first=Mathias
| author-link=Mathias Lerch
| title=Sur quelques formules relatives au nombre des classes
| journal=[[Bulletin des Sciences Mathématiques]]
| volume=21
| year=1897
| pages=290–304
}}
*{{Citation
| last=Schappacher
| first=Norbert
| title=Periods of Hecke characters
| series=Lecture Notes in Mathematics
| year=1988
| publisher=[[Springer-Verlag]]
| location=Berlin
| volume=1301
| mr=0935127
}}

{{DEFAULTSORT:Chowla-Selberg formula}}
[[Category:Theorems in number theory]]
[[Category:Gamma and related functions]]</text>
      <sha1>7tnbf2u8s1r420ly3mtgtvbl721tw1y</sha1>
    </revision>
  </page>
  <page>
    <title>David A. Cox</title>
    <ns>0</ns>
    <id>41248158</id>
    <revision>
      <id>832140087</id>
      <parentid>827583321</parentid>
      <timestamp>2018-03-24T01:58:40Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>/* Writings */ add a journal article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4094">{{infobox person
|birth_name = David Archibald Cox
|birth_date = {{birth date and age|1948|9|23}}
|birth_place = Washington, D.C.
|image = Cox david a.jpg
|caption = David A. Cox, Oberwolfach 2007
|alma_mater = [[Rice University]]&lt;br&gt;[[Princeton University]]
|occupation = Mathematician, professor
}}
'''David Archibald Cox''' (born September 23, 1948 in Washington, D.C.)&lt;ref&gt;''American Men and Women of Science'', Thomson Gale 2004&lt;/ref&gt; is an American mathematician, working in [[algebraic geometry]].

Cox graduated from [[Rice University]] with a bachelor's degree in 1970 and his Ph.D. in 1975 at [[Princeton University]], under the supervision of [[Eric Friedlander]] (''Tubular Neighborhoods in the Etale Topology'').&lt;ref&gt;[http://www.genealogy.math.ndsu.nodak.edu/id.php?id=30418 Mathematics Genealogy Project]&lt;/ref&gt; From 1974 to 1975, he was assistant professor at [[Haverford College]] and at [[Rutgers University]] from 1975 to 1979. In 1979, he became assistant professor and in 1988 professor at [[Amherst College]].

He studies, among other things, [[étale homotopy theory]], [[elliptic surface]]s, computer-based algebraic geometry (such as [[Gröbner basis]]), [[Torelli set]]s and [[toric variety|toric varieties]], and [[history of mathematics]]. He is also known for several textbooks. He is a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-12-02.&lt;/ref&gt;

From 1987 to 1988 he was a guest professor at [[Oklahoma State University]]. In 2012, he received the [[Lester Randolph Ford Award]] for ''Why [[Gotthold Eisenstein|Eisenstein]] Proved the [[Eisenstein Criterion]] and Why [[Theodor Schönemann|Schönemann]] Discovered It First''.&lt;ref&gt;{{cite journal|author=David A. Cox|title=Why Eisenstein Proved the Eisenstein Criterion and Why Schönemann Discovered It First|journal=American Mathematical Monthly|volume=118|issue=1|year=2011|pages=3–21|url=http://www.maa.org/programs/maa-awards/writing-awards/why-eisenstein-proved-the-eisenstein-criterion-and-why-sch-nemann-discovered-it-first|doi=10.4169/amer.math.monthly.118.01.003}}&lt;/ref&gt;

== Writings ==
* With John Little, [[Donal O'Shea]]: ''Ideals, varieties, and algorithms: an introduction to computational algebraic geometry and commutative algebra'', 3rd. edition, Springer Verlag 2007
*  David A. Cox, John Little, and [[Donal O'Shea]]: ''Using algebraic geometry'',  2nd. edition, Graduate Texts in Mathematics, vol. 185, Springer-Verlag, 2005. 
* With [[Sheldon Katz]]: ''Mirror Symmetry and Algebraic Geometry'', [[American Mathematical Society]] 1999
* ''Galois Theory'', Wiley/Interscience 2004
* With [[Bernd Sturmfels]], Dinesh Manocha (eds.) ''Applications of computational algebraic geometry'', American Mathematical Society 1998
* Primes of the form &lt;math&gt;x^2 + n \cdot y^2&lt;/math&gt;: Fermat, class field theory, and complex multiplication, Wiley 1989
* With John Little, Henry Schenck: ''Toric Varieties'', American Mathematical Society 2011
* Contributions to [[Ernst Kunz]] ''Residues and duality for projective algebraic varieties'', American Mathematical Society 2008
* {{citation |last1=Cox|first1=David A.|last2=Zucker |first2=Steven | authorlink2=Steven Zucker| title=Intersection numbers of sections of elliptic surfaces| journal=[[Inventiones Mathematicae]]| volume= 53 |year=1979|issue=1|
pages= 1–44|doi=10.1007/BF01403189|mr=0538682}}

==See also==
*[[Cox–Zucker machine]]
*[[Cox ring]]

== References ==
{{reflist}}

== External links ==
* [http://www3.amherst.edu/~dacox/ Homepage]
* {{MathGenealogy|30418}}

{{Authority control}}

{{DEFAULTSORT:Cox, David Archibald}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:1948 births]]
[[Category:Living people]]
[[Category:People from Washington, D.C.]]
[[Category:Rice University alumni]]
[[Category:Princeton University alumni]]
[[Category:Amherst College faculty]]
[[Category:Algebraic geometers]]</text>
      <sha1>2c6el3gqp0ajnp0q248onziyk1kawfg</sha1>
    </revision>
  </page>
  <page>
    <title>David E. Rowe</title>
    <ns>0</ns>
    <id>2906918</id>
    <revision>
      <id>868304106</id>
      <parentid>820331369</parentid>
      <timestamp>2018-11-11T09:57:11Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */recategorize</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3222">{{Use mdy dates|date=October 2015}}
[[File:David Rowe.jpg|thumb|David Rowe, Oberwolfach 2005]]

'''David E. Rowe''' (born August 11, 1950) is an American mathematician and historian.&lt;ref&gt;{{Cite web |url=https://scholar.google.com/scholar?hl=en&amp;q=David+E.+Rowe&amp;btnG=&amp;as_sdt=1%2C44&amp;as_sdtp= |title=David E. Rowe |publisher=scholar.google.com |accessdate=August 11, 2017}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=https://www.genealogy.math.ndsu.nodak.edu/id.php?id=36124 |title=David Rowe |publisher=ndsu.edu |accessdate=August 11, 2017}}&lt;/ref&gt; He studied [[mathematics]] and the [[history of science]] at the [[University of Oklahoma]], and took a second doctorate in history at the [[CUNY Graduate Center|Graduate Center of the City University of New York]]. He served as book review editor, managing editor, and editor of the journal ''[[Historia Mathematica]]''. In 1992, Rowe was appointed Professor of History of Mathematics and Natural Sciences at the [[Johannes Gutenberg University of Mainz|Johannes Gutenberg University]] in [[Mainz]] where he presently teaches. His research has mainly focused on mathematics in Germany, but in recent years he has been concerned with [[Einstein]]'s [[general theory of relativity]] and the broader cultural and political impact of Einstein's ideas. As part of this effort, he and {{ill|Robert Schulmann|de}} have co-edited a source book entitled ''Einstein on Politics: His Private Thoughts and Public Stands on Nationalism, Zionism, War, Peace, and the Bomb'', published by [[Princeton University Press]] in 2007.&lt;ref&gt;{{cite book |title=Einstein on Politics: His Private Thoughts and Public Stands on Nationalism, Zionism, War, Peace, and the Bomb |editor=Rowe, David. &amp; Robert Schulmann |publisher=Princeton University Press |date=April 16, 2007 |isbn=0-691-12094-3}}&lt;/ref&gt;

==Publications==
* Editor with Robert J. Schulmann: ''Einstein on Politics – his private thoughts and public stands on nationalism, zionism, war, peace and the bomb'', Princeton University Press, 2007.
* with [[Karen Parshall]]: ''The Emergence of the American Mathematical Research Community, 1876–1900. J.J. Sylvester, Felix Klein, and E.H. Moore'', AMS/LMS History of Mathematics Series, Vol. 8, Providence: American Mathematical Society, 1994.
* Editor with John McCleary: ''The History of Modern Mathematics: Ideas and their Reception'', Academic Press, Vol.1, 1989 (in vol. 1 by Rowe: ''Klein, Lie, and the Geometric Background of the Erlangen Program''), Vol. 2, 1990
* ''Klein, Hilbert, and the Göttingen Mathematical Tradition'', Osiris, Vol. 5, 1989, pp.&amp;nbsp;186–213.

==References==
{{Reflist}}

==External links==
* [http://www.daviderowe.net Personal Homepage: www.DavidERowe.net]
* [https://web.archive.org/web/20120315030446/http://www.mathematik.uni-mainz.de/arbeitsgruppen/geschichte/rowe Homepage at the Universität Mainz]

{{Authority control}}

{{DEFAULTSORT:Rowe, David E.}}
[[Category:University of Mainz faculty]]
[[Category:Historians of mathematics]]
[[Category:Graduate Center, CUNY alumni]]
[[Category:University of Oklahoma alumni]]
[[Category:Living people]]
[[Category:21st-century American historians]]
[[Category:1950 births]]


{{US-mathematician-stub}}
{{US-historian-stub}}</text>
      <sha1>9b5zlbymk7hj19zx3di1xh477y8o84u</sha1>
    </revision>
  </page>
  <page>
    <title>Donatella Danielli</title>
    <ns>0</ns>
    <id>53761797</id>
    <revision>
      <id>857349550</id>
      <parentid>811285801</parentid>
      <timestamp>2018-08-31T04:09:47Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6127">{{Use dmy dates|date=November 2013}}
{{Infobox scientist
| name              = Donatella Danielli
| image             = 
| image_size        = 
| caption           = 
| birth_date        = 
| birth_place       = [[Italy]]
| death_date        = 
| death_place       = 
| nationality       = 
| fields            = [[Mathematics]]
| workplaces        = [[Purdue University]]
| alma_mater        = [[University of Bologna]]
| doctoral_advisor  = [[Carlos Kenig]]
| doctoral_students =
| known_for         = 
| awards            = [[National Science Foundation CAREER Awards]] (2003) [[Fellow]] of the [[American Mathematical Society]] (2017)
}}
'''Donatella Danielli''' is a professor of mathematics at [[Purdue University]]{{r|pfac}} and is known for her contributions to [[partial differential equations]], [[calculus of variations]] and [[geometric measure theory]], with specific emphasis on [[free boundary problem]]s.  She received a [[Laurea]] [[cum Laude]] in Mathematics from the [[University of Bologna]], Italy in 1989. {{r|cv}} She completed her doctorate in 1999 at Purdue, under the supervision of [[Carlos Kenig]].{{r|cv}} Before joining the Purdue University faculty in 2001, she held positions at The [[Johns Hopkins University]] and at the [[Institut Mittag-Leffler]] in Sweden. She was also a visiting fellow at the [[Isaac Newton Institute for Mathematical Sciences]] in 2014.

She is the creator and organizer of the Symposia on Analysis and PDEs and of the Women in Mathematics Days, both at Purdue University. Her [[mathematics genealogy]] ID is 52294 {{r|mgp}}.

== Selected awards ==
She has been the recipient of a [[National Science Foundation CAREER Awards|National Science Foundation CAREER Award]] in 2003, a [[Purdue University]] Teaching for Tomorrow Award in 2004, a Ruth and [[Joel Spira]] Award for Graduate Teaching in 2011, and a Butler Leadership in Action Award in 2013. She was awarded a Simons Fellow in Mathematics in 2014. {{r|simons}} In 2017, she became a [[Fellow]] of the [[American Mathematical Society]] "for contributions to partial differential equations and geometric measure theory, and for service to the mathematical community".{{r|fams}}

== Selected publications ==
===Books===
* Capogna, Luca, et al. An introduction to the Heisenberg group and the sub-Riemannian isoperimetric problem. Vol. 259. Springer Science &amp; Business Media, 2007.{{r|hajlasz}}

===Papers===

* Danielli, Donatella Regularity at the boundary for solutions of nonlinear subelliptic equations. Indiana Univ. Math. J. 44 (1995), no. 1, 269–286.
* Capogna, Luca; Danielli, Donatella; Garofalo, Nicola Capacitary estimates and the local behavior of solutions of nonlinear subelliptic equations. Amer. J. Math. 118 (1996), no. 6, 1153–1196. (Reviewer: Chu Li Fu) 35H05 (35B45 35B65)
* Danielli, Donatella Regularity at the boundary for solutions of nonlinear subelliptic equations. Indiana Univ. Math. J. 44 (1995), no. 1, 269–286.Danielli, Donatella; Petrosyan, Arshak A minimum problem with free boundary for a degenerate quasilinear operator. Calc. Var. Partial Differential Equations 23 (2005), no. 1, 97–124.
* Danielli, Donatella; Garofalo, Nicola; Nhieu, Duy-Minh Non-doubling Ahlfors measures, perimeter measures, and the characterization of the trace spaces of Sobolev functions in Carnot-Carathéodory spaces. Mem. Amer. Math. Soc. 182 (2006), no. 857, x+119 pp. 
* Recent developments in nonlinear partial differential equations. Proceedings of the 2nd Symposium on Analysis and PDEs held at Purdue University, West Lafayette, IN, June 7–10, 2004. Edited by Donatella Danielli. Contemporary Mathematics, 439. American Mathematical Society, Providence, RI, 2007. 
* Capogna, Luca; Danielli, Donatella; Pauls, Scott D.; Tyson, Jeremy T. An introduction to the Heisenberg group and the sub-Riemannian isoperimetric problem. Progress in Mathematics, 259. Birkhäuser Verlag, Basel, 2007. 
* Danielli, Donatella; Garofalo, Nicola; Petrosyan, Arshak The sub-elliptic obstacle problem: C1,α regularity of the free boundary in Carnot groups of step two. Adv. Math. 211 (2007), no. 2, 485–516. 
* Danielli, D.; Garofalo, N.; Nhieu, D. M. Sub-Riemannian calculus on hypersurfaces in Carnot groups. Adv. Math. 215 (2007), no. 1, 292–378.
* Danielli, D.; Garofalo, N.; Nhieu, D. M.; Pauls, S. D. Instability of graphical strips and a positive answer to the Bernstein problem in the Heisenberg group H1. J. Differential Geom. 81 (2009), no. 2, 251–295.

== Personal life ==
She and her husband, Nicola Garofalo (also a mathematician), have four children.

==References==
{{reflist|refs=

&lt;ref name=pfac&gt;[http://www.math.purdue.edu/people/faculty.php Faculty Directory at Purdue ], retrieved 2017-04-12&lt;/ref&gt;

&lt;ref name=cv&gt;[http://www.math.purdue.edu/~danielli/CV.htm Curriculum vitae], retrieved 2017-04-12&lt;/ref&gt;

&lt;ref name=simons&gt;[https://www.simonsfoundation.org/funding/funding-opportunities/mathematics-physical-sciences/simons-fellow-program/simons-fellows-awardees-mathematics/2014-simons-fellows-awardees-mathematics/ 2014 Simons Fellows in Mathematics], retrieved 2017-04-15&lt;/ref&gt;

&lt;ref name=fams&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2017-04-15&lt;/ref&gt;

&lt;ref name=hajlasz&gt;Hajłasz, Piotr (2009), Review of ''An introduction to the Heisenberg group'', {{MR|2312336}}&lt;/ref&gt;

&lt;ref name=mgp&gt;{{mathgenealogy|id=52294}}&lt;/ref&gt;

}}

==External links==
* [http://www.math.purdue.edu/~danielli/ Personal home page].
* [https://mathinstitutes.org/videos/videos/5133 IMA Presentation on Regularity Results for a Class of Permeability Problems]

{{authority control}}

{{DEFAULTSORT:Danielli, Donatella}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:21st-century American mathematicians]]
[[Category:Italian mathematicians]]
[[Category:Women mathematicians]]
[[Category:University of Bologna alumni]]
[[Category:Purdue University alumni]]
[[Category:Johns Hopkins University faculty]]
[[Category:Purdue University faculty]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>ihpz6p6qffbcrykk9zjrg38jgd1bn8b</sha1>
    </revision>
  </page>
  <page>
    <title>Dora Musielak</title>
    <ns>0</ns>
    <id>59096855</id>
    <revision>
      <id>871294030</id>
      <parentid>869477363</parentid>
      <timestamp>2018-11-30T03:01:56Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add category</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4826">'''Dora Elia Musielak''' is a Mexican-American [[Aerospace engineering|aerospace engineer]], [[history of mathematics|historian of mathematics]], and book author. She is an expert on high-speed [[airbreathing jet engine]]s,{{r|chron}} and an adjunct professor of mechanical and aerospace engineering at the [[University of Texas at Arlington]].{{r|uta}}

==Education and career==
Musielak earned a bachelor's degree in aeronautical engineering from the [[Instituto Politécnico Nacional]] in Mexico in 1978,{{r|uta}} the first woman to earn a degree in this field there.{{r|uta|repub}} She continued with a master's degree at the [[University of Tennessee]] in 1980, and a Ph.D. at the [[University of Alabama in Huntsville]] in 1994.{{r|uta}}

Her employers have included [[Northrop Grumman]], MSE Technology Applications, and ATK Allied Techsystems.{{r|uta}} She chaired the High Speed Air Breathing Propulsion Technical Committee of the [[American Institute of Aeronautics and Astronautics]] from 2014 to 2016.{{r|hsabp}}

==Books==
Musielak's 2004 self-published [[Historical fiction|historical novel]] ''Sophie's Diary: A Mathematical Novel'', based on the life of mathematician [[Sophie Germain]], was republished in a second edition in 2012 by the [[Mathematical Association of America]].{{r|repub}}{{r|sd}}

Musielak also wrote a biography of Germain, ''Prime Mystery: The Life and Mathematics of Sophie Germain'' (2015).{{r|pm}}
Her other books include
''Kuxan Suum: Path to the Center of the Universe'' (2010) and
''Euler Celestial Analysis: Introduction to Spacecraft Orbit Mechanics'' (2018).
These remain self-published, through [[AuthorHouse]].

==References==
{{reflist|refs=

&lt;ref name=chron&gt;{{citation|url=https://www.houstonchronicle.com/news/nation-world/article/Aircraft-s-target-Mach-6-for-5-minutes-3788430.php|newspaper=Houston Chronicle|title=Aircraft's target: Mach 6 for 5 minutes|date=August 14, 2012|quote=Dora Musielak, an adjunct professor of physics at the University of Texas at Arlington whose research focuses on high-speed propulsion}}&lt;/ref&gt;

&lt;ref name=hsabp&gt;{{citation|journal=HighSpeed Times: Newsletter of the AIAA High Speed Air Breathing Propulsion Technical Committee|first=Dora|last=Musielak|title=Message from the chair|volume=5|issue=2|date=July 2014|page=1}}&lt;/ref&gt;

&lt;ref name=pm&gt;Review of ''Prime Mystery'':
*{{citation|title=Review|journal=MAA Reviews|date=April 2015|first=David|last=Pengelley|url=https://www.maa.org/press/maa-reviews/prime-mystery-the-life-and-mathematics-of-sophie-germain}}
&lt;/ref&gt;

&lt;ref name=repub&gt;{{citation|url=https://www.uta.edu/news/releases/2012/05/sophiesdiary-release.php|title=A mathematical novel from UT Arlington professor|work=UTA News Center|publisher=[[University of Texas at Arlington]]|date=May 9, 2012}}&lt;/ref&gt;

&lt;ref name=sd&gt;Reviews of ''Sophie's Diary'':
*{{citation|title=Review|journal=MAA Reviews|date=September 2006|first=Judy|last=Holdener|url=https://www.maa.org/press/maa-reviews/sophies-diary-a-historical-fiction-0}}
*{{citation|title=Review|journal=MAA Reviews|date=July 2012|first=Michele|last=Intermont|url=https://www.maa.org/press/maa-reviews/sophies-diary-a-mathematical-novel}}
*{{citation|title=Texas &amp; Southwest books roundup|first=Si|last=Dunn|date=August 2012|newspaper=Dallas Morning News|url=https://www.dallasnews.com/arts/books/2012/08/03/texas-southwest-books-roundup-a-little-history-a-little-music-a-memoir-and-some-fiction}}
*{{citation|title=none|first=Norman R.|last=Draper|journal=International Statistical Review|volume=80|issue=3|date=December 2012|pages=481–482|jstor=41819871|doi=10.1111/j.1751-5823.2012.00196_13.x}}
*{{citation|title=none|first=Christing|last=Hebert|journal=The Mathematics Teacher|volume=107|issue=3|date=October 2013|page=239|doi=10.5951/mathteacher.107.3.0238}}
*{{citation|title=Review|last=Rauff|first=James V.|journal=Mathematics and Computer Education|volume=49|issue=1|date=Winter 2015|page=71|url=https://search.proquest.com/openview/626006bfaf2187af48e3550028ca5bd9/1}}
*{{citation|title=none|journal=Mathematical Reviews|first=John J.|last=Watkins|mr=2918718}}
&lt;/ref&gt;

&lt;ref name=uta&gt;{{citation|url=https://mentis.uta.edu/explore/profile/dora-musielak|title=Dr. Dora Elia Musielak|publisher=[[University of Texas at Arlington]]|accessdate=2018-11-18}}&lt;/ref&gt;

}}

{{Authority control}}

{{DEFAULTSORT:Musielak, Dora}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:Aerospace engineers]]
[[Category:Mexican engineers]]
[[Category:Women engineers]]
[[Category:Historians of mathematics]]
[[Category:Instituto Politécnico Nacional alumni]]
[[Category:University of Tennessee alumni]]
[[Category:University of Alabama in Huntsville alumni]]
[[Category:University of Texas at Arlington faculty]]
[[Category:21st-century women engineers]]</text>
      <sha1>pong9hghih3jbfm7zaktclga3404oke</sha1>
    </revision>
  </page>
  <page>
    <title>Enterprise value</title>
    <ns>0</ns>
    <id>964342</id>
    <revision>
      <id>851936845</id>
      <parentid>851936559</parentid>
      <timestamp>2018-07-25T14:50:39Z</timestamp>
      <contributor>
        <username>Mike1843</username>
        <id>34278172</id>
      </contributor>
      <minor/>
      <comment>Minor mistake</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9045">'''Enterprise value''' ('''EV'''), '''total enterprise value''' ('''TEV'''), or '''firm value''' ('''FV''') is an economic measure reflecting the market value of a business. It is a sum of claims by all claimants: creditors (secured and unsecured) and shareholders (preferred and common). Enterprise value is one of the fundamental metrics used in [[business valuation]], [[financial modeling]], [[accounting]], [[Portfolio (finance)|portfolio]] analysis, and [[risk analysis]].

Enterprise value is more comprehensive than [[market capitalization]], which only reflects common equity.&lt;ref&gt;[http://www.investopedia.com/terms/e/enterprisevalue.asp Definition of 'Enterprise Value - EV']&lt;/ref&gt; Importantly, EV reflects the opportunistic nature of business and may change substantially over time because of both external and internal conditions. Therefore, financial analysts often use a comfortable range of EV in their calculations.



==EV equation==

For detailed information on the valuation process see [[Valuation (finance)]].

: Enterprise value = 
:: common equity at [[market value]] (this line item is also known as "market cap")
:: + [[debt]] at market value (here debt refers to interest-bearing liabilities, both long-term and short-term)
:: + [[minority interest]] at market value, if any
:: + [[preferred equity]] at market value
:: + [[Pension#Funding|unfunded pension liabilities]] and other debt-deemed provisions
:: – value of associate companies
:: – cash and cash equivalents.

==Understanding==
A simplified way to understand the EV concept is to envision purchasing an entire business. If you settle with all the security holders, you pay EV. Counter-intuitively, increases or decreases in enterprise value do not necessarily correspond to "value creation" or value destruction". Any acquisition of assets (whether paid for in cash or through share issues) will increase EV, whether or not those assets are productive. Similarly, reductions in capital intensity (for example by reducing working capital) will reduce EV.

EV can be negative if the company, for example, holds abnormally high amounts of cash that is not reflected in the market value of the stock and total capitalization.&lt;ref&gt;[https://www.bloomberg.com/apps/news?pid=newsarchive&amp;sid=ahiVT6vmGNEA&amp;refer=home Cheapest Stocks Since 1995 Show Cash Exceeds Market (Update5)]&lt;/ref&gt;

All the components relevant in liquidation analysis, since using [[absolute priority]] in a bankruptcy all securities senior to the equity have par claims. Generally, also, debt is less liquid than equity so that the "market price" may be significantly different from the price at which an entire debt issue could be purchased. In valuing equities, this approach is more conservative.

Cash is subtracted because it reduces the net cost to a potential purchaser. The effect applies whether the cash is used to issue dividends or to pay down debt.

Value of minority interest is added because it reflects the claim on assets consolidated into the firm in question.

Value of associate companies is subtracted because it reflects the claim on assets consolidated into other firms.

EV should also include such special components as unfunded pension liabilities, [[employee stock option]]s, environmental provisions, abandonment provisions, and so on, since they also reflect claims on the company.

It can be demonstrated that enterprise value depends on the probability of default (the rating) and works as a "negative growth rate" in the future.&lt;ref&gt;{{cite journal |last1=Gleißner |first1=Werner |title=Kapitalmarktorientierte Unternehmensbewertung: Erkenntnisse der empirischen Kapitalmarktforschung und alternative Bewertungsmethoden |journal=Corporate Finance |page=158}}&lt;/ref&gt;

Enterprise value is only a useful measure of success or a useful measure of performance, when, apart from the rating, the earnings risks of the company are accounted for (for example by using the discount interest rate).&lt;ref&gt;{{cite book |last1=Gleißner |first1=Werner |title=Grundlagen des Risikomanagements: mit fundierten Informationen zu besseren Entscheidungen |date=2017 |location=Munich |isbn=978-3-8006-4953-2 |page=47}}&lt;/ref&gt;

==Usage==
*Because EV is a [[capital structure]]-neutral metric, it is useful when comparing companies with diverse capital structures. Price/earnings ratios, for example, will be significantly more volatile in companies that are highly leveraged.
*'''Stock market investors''' use  [[EV/EBITDA]] to compare returns between equivalent companies on a risk-adjusted basis.  They can then superimpose their own choice of debt levels.  In practice, equity investors may have difficulty accurately assessing EV if they do not have access to the market quotations of the company debt.  It is not sufficient to substitute the book value of the debt because a) the market interest rates may have changed, and b) the market's perception of the risk of the loan may have changed since the debt was issued.  Remember, the point of EV is to neutralize the different risks, and costs of different capital structures.
*'''Buyers of controlling interests''' in a business use EV to compare returns between businesses, as above. They also use the EV valuation (or a debt free cash free valuation) to determine how much to pay for the whole entity ('''not''' just the equity) since the change of control may require debt repayment. They may also want to change the [[capital structure]] once in control.

==Technical considerations==

===Data availability===
Unlike market capitalization, where both the market price and the outstanding number of shares in issue are readily available and easy to find, it is virtually impossible to calculate an EV without making a number of adjustments to published data, including often subjective estimations of value:
* The vast majority of corporate debt is not publicly traded. Most corporate debt is in the form of bank financing, finance leases and other forms of debt for which there is no market price.
* Associates and minority interests are stated at historical book values in the accounts, which may be very different from their market values.
* Unfunded pension liabilities rely on a variety of actuarial assumptions and represent an estimate of the outstanding liability, not a true “market” value.
* Public data for certain key inputs of EV, such as cash balances, debt levels and provisions are only published infrequently (often only once a year in the annual report &amp; accounts of the company).
* Published accounts are only disclosed weeks or months after the year-end date, meaning that the information disclosed is already out of date.

In practice, EV calculations rely on reasonable estimates of the market value of these components. For example, in many professional valuations:
* Unfunded pension liabilities are valued at face value as set out in notes to the latest available accounts.
* Debt that is not publicly traded is usually taken at face value, unless the company is highly geared (in which case a more sophisticated analysis is required).
* Associates &amp; minority interests are usually valued either at book value or as a multiple of their earnings.

===Avoiding temporal mismatches===
When using valuation multiples such as EV/EBITDA and EV/EBIT, the numerator should correspond to the denominator. The EV should, therefore, correspond to the market value of the assets that were used to generate the profits in question, excluding assets acquired (and including assets disposed) during a different financial reporting period. This requires restating EV for any mergers and acquisitions (whether paid in cash or equity), significant capital investments or significant changes in [[working capital]] occurring after or during the reporting period being examined. Ideally, multiples should be calculated using the market value of the weighted average capital employed of the company during the comparable financial period.

When calculating multiples over different time periods (e.g. historic multiples vs forward multiples), EV should be adjusted to reflect the weighted average invested capital of the company in each period.&lt;ref group="note"&gt;This is analogous to the way earnings per share (net income / weighted average number of shares) is influenced by changes in the number of shares over different financial years.&lt;/ref&gt;

==See also==
*[[Discounted cash flow|DCF]], discounted cash flow method of valuation
*[[Capital structure]]
*[[Weighted average cost of capital|WACC]], weighted average cost of capital
*[[Social accounting]]
*[[Residual Income Valuation]]

==Notes==
{{Reflist|group=note}}

==References==
{{Reflist}}

==External links==
*[https://www.youtube.com/watch?v=c8HdwcRlWZk Investopedia Video: Introduction To Enterprise Value]
*[http://aswathdamodaran.blogspot.ru/2008/12/entperise-value-is-negative-is-that.html Enterprise value is negative... Is that possible?]

{{corporate finance and investment banking}}

[[Category:Mathematical finance]]
[[Category:Fundamental analysis]]</text>
      <sha1>5zsyxxc8hqbo8cy2wvwqtbr4ae8jvav</sha1>
    </revision>
  </page>
  <page>
    <title>Enumerative geometry</title>
    <ns>0</ns>
    <id>3069092</id>
    <revision>
      <id>849094272</id>
      <parentid>841692700</parentid>
      <timestamp>2018-07-06T13:47:13Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <comment>/* External links */ 10.1080/00029890.2008.11920584</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8274">{{see also|Intersection theory}}
{{more footnotes|date=September 2012}}
In [[mathematics]], '''enumerative geometry''' is the branch of [[algebraic geometry]] concerned with counting numbers of solutions to geometric questions, mainly by means of [[intersection theory]].

==History==
[[File:Apollonius8ColorMultiplyV2.svg|thumb|right|[[Problem of Apollonius|Circles of Apollonius]]]]
The [[problem of Apollonius]] is one of the earliest examples of enumerative geometry.  This problem asks for the number and construction of circles that are tangent to three given circles, points or lines.  In general, the problem for three given circles has eight solutions, which can be seen as 2&lt;sup&gt;3&lt;/sup&gt;, each tangency condition imposing a quadratic condition on the space of circles.  However, for special arrangements of the given circles, the number of solutions may also be any integer from 0 (no solutions) to six; there is no arrangement for which there are seven solutions to Apollonius' problem.

==Key tools==
A number of tools, ranging from the elementary to the more advanced, include:
* [[Dimension counting]]
* [[Bézout's theorem]]
* [[Schubert calculus]], and more generally [[characteristic class]]es in [[cohomology]]
* The connection of counting intersections with cohomology is [[Poincaré duality]]
* The study of [[moduli spaces]] of curves, maps and other geometric objects, sometimes via the theory of [[quantum cohomology]]. The study of [[quantum cohomology]], [[Gromov–Witten invariant]]s and [[mirror symmetry (string theory)|mirror symmetry]] gave a significant progress in [[Clemens conjecture]].

Enumerative geometry is very closely tied to [[intersection theory]].

==Schubert calculus==
Enumerative geometry saw spectacular development towards the end of the nineteenth century, at the hands of [[Hermann Schubert]].&lt;ref&gt;{{Cite book|first=H. |last=Schubert|title=Kalkül der abzählenden Geometrie| origyear =1879|year =1979}}&lt;/ref&gt; He introduced for the purpose the [[Schubert calculus]], which has proved of fundamental geometrical and [[topological]] value in broader areas. The specific needs of enumerative geometry were not addressed until some further attention was paid to them in the 1960s and 1970s (as pointed out for example by [[Steven Kleiman]]). [[Intersection number]]s had been rigorously defined (by [[André Weil]] as part of his foundational programme 1942&amp;ndash;6, and again subsequently), but this did not exhaust the proper domain of enumerative questions.

==Fudge factors and Hilbert's fifteenth problem==
Naïve application of dimension counting and Bézout's theorem yields incorrect results, as the following example shows. In response to these problems, algebraic geometers introduced vague "fudge factors", which were only rigorously justified decades later.

As an example, count the [[conic section]]s tangent to five given lines in the [[projective plane]].&lt;ref&gt;{{cite book|first=William|last= Fulton|authorlink=William Fulton (mathematician)| title=Intersection Theory|year=1984|chapter= 10.4|isbn=0-387-12176-5}}&lt;/ref&gt; The conics constitute a [[projective space]] of dimension 5, taking their six coefficients as [[homogeneous coordinates]], and [[five points determine a conic]], if the points are in [[general linear position]], as passing through a given point imposes a linear condition. Similarly, tangency to a given line ''L'' (tangency is intersection with multiplicity two) is one quadratic condition, so determined a [[quadric]] in ''P''&lt;sup&gt;5&lt;/sup&gt;. However the [[linear system of divisors]] consisting of all such quadrics is not without a [[base locus]]. In fact each such quadric contains the [[Veronese surface]], which parametrizes the conics

:(''aX'' + ''bY'' + ''cZ'')&lt;sup&gt;2&lt;/sup&gt; = 0

called 'double lines'. This is because a double line intersects every line in the plane, since lines in the projective plane intersect, with multiplicity two because it is doubled, and thus satisfies the same intersection condition (intersection of multiplicity two) as a nondegenerate conic that is ''tangent'' to the line.

The general [[Bézout theorem]] says 5 general quadrics in 5-space will intersect in 32 = 2&lt;sup&gt;5&lt;/sup&gt; points. But the relevant quadrics here are not in [[general position]]. From 32, 31 must be subtracted and attributed to the Veronese, to leave the correct answer (from the point of view of geometry), namely 1. This process of attributing intersections to 'degenerate' cases is a typical geometric introduction of a '[[Wiktionary:fudge factor|fudge factor]]'.

[[Hilbert's fifteenth problem]] was to overcome the apparently arbitrary nature of these interventions; this aspect goes beyond the foundational question of the Schubert calculus itself.

==Clemens conjecture==

In 1984 [[Herbert Clemens|H. Clemens]] studied the counting of the number of [[rational curve]]s on a [[quintic threefold]] &lt;math&gt;X\subset P^4&lt;/math&gt; and reached the following conjecture.
: Let &lt;math&gt;X \subset P^4&lt;/math&gt; be a general quintic threefold, &lt;math&gt;d&lt;/math&gt; a positive integer, then there are only a finite number of rational curves with degree &lt;math&gt;d&lt;/math&gt; on &lt;math&gt;X&lt;/math&gt;.

This conjecture has been resolved in the case &lt;math&gt;d \le 9&lt;/math&gt;, but is still open for higher &lt;math&gt;d&lt;/math&gt;.

In 1991 the paper&lt;ref&gt;* {{cite journal |last=Candelas |first=Philip |authorlink=Philip Candelas |last2=de la Ossa |first2=Xenia |last3=Green |first3=Paul |last4=Parks |first4=Linda |date=1991 |title=A pair of Calabi-Yau manifolds as an exactly soluble superconformal field theory |journal=Nuclear Physics B |volume=359 |issue=1 |pages=21–74|doi=10.1016/0550-3213(91)90292-6 }}&lt;/ref&gt; about mirror symmetry on the quintic threefold in &lt;math&gt;P^4&lt;/math&gt; from the string theoretical viewpoint gives numbers of degree d rational curves on &lt;math&gt;X&lt;/math&gt; for all &lt;math&gt;d &gt; 0&lt;/math&gt;. Prior to this, algebraic geometers could calculate these numbers only for &lt;math&gt;d \le 5&lt;/math&gt;.

==Examples==

Some of the historically important examples of enumerations in algebraic geometry include: 

*2  The number of lines meeting 4 general lines in space
*8   The number of circles tangent to 3 general circles (the [[problem of Apollonius]]).
*27   The number of lines on a smooth [[cubic surface]] ([[George Salmon|Salmon]] and [[Arthur Cayley|Cayley]])
*2875  The number of lines on a general [[quintic threefold]]
*3264  The number of [[Steiner's conic problem|conics tangent to 5 plane conics]] in general position ([[Michel Chasles|Chasles]])
*609250   The number of conics on a general [[quintic threefold]]
*4407296 The number of conics tangent to 8 general quadric surfaces {{harvtxt|Fulton|1984|loc=p. 193}}
*666841088  The number of quadric surfaces tangent to 9 given quadric surfaces in general position in 3-space {{harv|Schubert|1879|loc=p.106}} {{harv|Fulton|1984|loc=p. 193}}
*5819539783680 The number of twisted cubic curves tangent to 12  given quadric surfaces in general position in 3-space {{harv|Schubert|1879|loc=p.184}}  {{harvs|last=Kleiman|first=S.|last2= Strømme|first2= S. A.|last3= Xambó|first3= S.|year= 1987}}

==References==
{{reflist}}
*{{citation|mr=0908713  |last=Kleiman|first=S.|last2= Strømme|first2= S. A.|last3= Xambó|first3= S.|chapter= Sketch of a verification of Schubert's number 5819539783680 of twisted cubics|title= Space curves (Rocca di Papa, 1985)|pages= 156–180|series= Lecture Notes in Math., |volume=1266|publisher= Springer|place= Berlin|year= 1987|doi=10.1007/BFb0078183}}
*{{citation|mr=0555576 
|last=Schubert|first= Hermann
|title=Kalkül der abzählenden Geometrie|language=German
|series=Reprint of the 1879 original|editor-first=Steven L. |editor-last=Kleiman|publisher= Springer-Verlag|place= Berlin-New York|year= 1979|isbn= 3-540-09233-1 |origyear=1879|url=https://archive.org/details/kalklderabzh00schuuoft}}

==External links==
*{{cite journal|author=Bashelor, Andrew|author2=Ksir, Amy|author3=Traves, Will|title=Enumerative Algebraic Geometry of Conics|journal=Amer. Math. Monthly|volume=115|issue=8|year=2008|pages=701–7|url=http://www.maa.org/programs/maa-awards/writing-awards/enumerative-algebraic-geometry-of-conics| jstor=27642583|doi=10.1080/00029890.2008.11920584}}

[[Category:Intersection theory]]
[[Category:Algebraic geometry]]</text>
      <sha1>e2ud31l2zxqje71zfdo65qilwrzwrg5</sha1>
    </revision>
  </page>
  <page>
    <title>Eugene M. Luks</title>
    <ns>0</ns>
    <id>38404291</id>
    <revision>
      <id>859754439</id>
      <parentid>848602930</parentid>
      <timestamp>2018-09-16T02:58:41Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3934">'''Eugene Michael Luks''' (born circa 1940)&lt;ref name="rg"/&gt; is an American [[mathematician]] and [[computer scientist]], a professor emeritus of [[University of Oregon Department of Computer and Information Science|computer and information science]] at the [[University of Oregon]]. He is known for his research on the [[graph isomorphism problem]] and on algorithms for computational [[group theory]].

==Professional career==
Luks did his undergraduate studies at the [[City College of New York]], earning a bachelor's degree in 1960,&lt;ref&gt;[http://ix.cs.uoregon.edu/~luks/ Home page at U. of Oregon], retrieved 2013-02-02.&lt;/ref&gt; and went on to graduate studies at the [[Massachusetts Institute of Technology]], earning a doctorate in mathematics in 1966 under the supervision of [[Kenkichi Iwasawa]].&lt;ref&gt;{{mathgenealogy|id=41898}}&lt;/ref&gt; He taught at [[Tufts University]] from 1966 to 1968, and at [[Bucknell University]] from then until 1983, when he joined the University of Oregon faculty as chair of the computer and information science department.&lt;ref name="rg"/&gt; He retired in 2006,&lt;ref&gt;[http://gov.oregonlive.com/pers/browse/1/ Top beneficiaries], [[Oregon Public Employees Retirement System]], accessed 2011-02-03.&lt;/ref&gt; but was recalled in 2012–2013 to serve as interim chair.&lt;ref name="uo-ams"&gt;[http://www.cs.uoregon.edu/news/20121101-Luks.php Prof. Eugene Luks Named to Prestigious AMS Fellows Group], U. Oregon CIS News, accessed 2013-02-03.&lt;/ref&gt;

==Awards and honors==
In 1985, Luks won the [[Fulkerson Prize]] for his work showing that [[graph isomorphism]] could be tested in [[polynomial time]] for graphs with bounded [[degree (graph theory)|maximum degree]].&lt;ref name="rg"&gt;{{citation|url=https://news.google.com/newspapers?id=w_hVAAAAIBAJ&amp;sjid=huEDAAAAIBAJ&amp;pg=6539,2351404&amp;dq=fulkerson-prize&amp;hl=en|newspaper=[[The Register-Guard|Eugene Register-Guard]]|title=U of O Computer Chief Gets Top Award|date=August 10, 1985}}.&lt;/ref&gt; In 2012 he became a fellow of the [[American Mathematical Society]].&lt;ref name="uo-ams"/&gt;&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-02-02.&lt;/ref&gt;

==Selected publications==
*{{citation
 | last1 = Furst | first1 = Merrick
 | last2 = Hopcroft | first2 = John | author2-link = John Hopcroft
 | last3 = Luks | first3 = Eugene M.
 | contribution = Polynomial-time algorithms for permutation groups
 | doi = 10.1109/SFCS.1980.34
 | pages = 36–41
 | title = Proceedings of the 21st IEEE [[Symposium on Foundations of Computer Science]] (FOCS'80)
 | year = 1980| contribution-url = http://www.dtic.mil/get-tr-doc/pdf?AD=ADA097825}}.
*{{citation
 | last = Luks | first = Eugene M.
 | issue = 1
 | journal = Journal of Computer and System Sciences
 | pages = 42–65
 | title = Isomorphism of graphs of bounded valence can be tested in polynomial time
 | volume = 25
 | year = 1982
 | doi=10.1016/0022-0000(82)90009-5}}.
*{{citation
 | last1 = Babai | first1 = László | author1-link = László Babai
 | last2 = Luks | first2 = Eugene M.
 | contribution = Canonical labeling of graphs
 | doi = 10.1145/800061.808746
 | pages = 171–183
 | title = Proceedings of the 15th ACM [[Symposium on Theory of Computing]] (STOC '83)
 | year = 1983}}.

==References==
{{reflist}}

{{authority control}}

{{DEFAULTSORT:Luks, Eugene M.}}
[[Category:Year of birth missing (living people)]]
[[Category:Living people]]
[[Category:American computer scientists]]
[[Category:American mathematicians]]
[[Category:Theoretical computer scientists]]
[[Category:Graph theorists]]
[[Category:Group theorists]]
[[Category:City College of New York alumni]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Tufts University faculty]]
[[Category:Bucknell University faculty]]
[[Category:University of Oregon faculty]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Place of birth missing (living people)]]</text>
      <sha1>0zp9hqobvui06ijkuvkpc7aqgg07y68</sha1>
    </revision>
  </page>
  <page>
    <title>Fractional chromatic number</title>
    <ns>0</ns>
    <id>745755</id>
    <redirect title="Fractional coloring" />
    <revision>
      <id>784248067</id>
      <parentid>313403106</parentid>
      <timestamp>2017-06-07T08:02:06Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Redirect category shell|Redirect category shell]]}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="122">#REDIRECT [[Fractional coloring]]

{{Redirect category shell|1=
{{R with possibilities}}
}}

[[Category:Graph invariants]]</text>
      <sha1>0lxpggdo0wbfa1evcdxr605fx3pr8xd</sha1>
    </revision>
  </page>
  <page>
    <title>GIT quotient</title>
    <ns>0</ns>
    <id>41139312</id>
    <revision>
      <id>846596554</id>
      <parentid>827281210</parentid>
      <timestamp>2018-06-19T19:03:12Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6927">In [[algebraic geometry]], an affine '''GIT quotient''', or affine '''[[geometric invariant theory]] quotient''', of an affine scheme &lt;math&gt;\operatorname{Spec} A&lt;/math&gt; with an [[Group-scheme action|action]] by a [[group scheme]] ''G'' is the affine scheme &lt;math&gt;\operatorname{Spec}(A^G)&lt;/math&gt;, the [[prime spectrum]] of the [[ring of invariants]] of ''A'', and is denoted by &lt;math&gt;X /\!/ G&lt;/math&gt;. A GIT quotient is a [[categorical quotient]]: any invariant morphism uniquely factors through it.

Taking [[Proj construction|Proj]] (of a [[graded ring]]) instead of &lt;math&gt;\operatorname{Spec}&lt;/math&gt;, one obtains a projective GIT quotient (which is a quotient of the set of [[semistable point]]s.)

A GIT quotient is a categorical quotient of the locus of semistable points; i.e., "the" quotient of the semistable locus. Since the categorical quotient is unique, if there is a [[geometric quotient]], then the two notions coincide: for example, one has &lt;math&gt;G / H = G /\!/ H = \operatorname{Spec}k[G]^H&lt;/math&gt; for an [[algebraic group]] ''G'' over a field ''k'' and closed subgroup ''H''.

If ''X'' is a complex [[smooth variety|smooth]] [[projective variety]] and if ''G'' is a reductive [[complex Lie group]], then the GIT quotient of ''X'' by ''G'' is homeomorphic to the [[symplectic quotient]] of ''X'' by a [[maximal compact subgroup]] of ''G'' ([[Kempf–Ness theorem]]).

== Construction of a GIT quotient ==
Let ''G'' be a [[reductive group]] acting on a quasi-projective scheme ''X'' over a field and ''L'' a [[linearized line bundle|linearlized ample line bundle]] on ''X''. Let &lt;math&gt;R = \bigoplus_{n \ge 0} \Gamma(X, L^{\otimes n})&lt;/math&gt; be the section ring. By definition, the semistable locus &lt;math&gt;X^{ss}&lt;/math&gt; is the complement of the zero set &lt;math&gt;V(R_+^G)&lt;/math&gt; in ''X''; in other words, it is the union of all open subsets &lt;math&gt;U_s = \{ s \ne 0 \}&lt;/math&gt; for global sections ''s'' of &lt;math&gt;(L^{\otimes n})^G&lt;/math&gt;, ''n'' large. By ampleness, each &lt;math&gt;U_s&lt;/math&gt; is affine; say &lt;math&gt;U_s = \operatorname{Spec}(A_s)&lt;/math&gt; and so we can form the affine GIT quotient
:&lt;math&gt;\pi_s: U_s \to U_s /\!/ G = \operatorname{Spec}(A_s^G)&lt;/math&gt;.
Note that &lt;math&gt;U_s /\!/ G&lt;/math&gt; is of finite type by [[Hilbert's theorem on the ring of invariants]]. By universal property of [[categorical quotient]]s, these affine quotients glue and result in
:&lt;math&gt;\pi: X^{ss} \to X /\!/_L G&lt;/math&gt;,
which is the GIT quotient of ''X'' with respect to ''L''. Note that if ''X'' is projective; i.e., it is the Proj of ''R'', then the quotient &lt;math&gt;X /\!/_L G&lt;/math&gt; is given simply as the Proj of the [[ring of invariants]] &lt;math&gt;R^G&lt;/math&gt;.

The most interesting case is when the stable locus&lt;ref&gt;NB: In {{harv|MFK}}, it was called the set of properly stable points&lt;/ref&gt; &lt;math&gt;X^s&lt;/math&gt; is nonempty; &lt;math&gt;X^s&lt;/math&gt; is the open set of semistable points that have finite stabilizers and orbits that are closed in &lt;math&gt;X^{ss}&lt;/math&gt;. In such a case, the GIT quotient restricts to
:&lt;math&gt;\pi^s: X^s \to X^s/\!/G&lt;/math&gt;,
which has the property: every fiber is an orbit. That is to say, &lt;math&gt;\pi^s&lt;/math&gt; is a genuine quotient (i.e., [[geometric quotient]]) and one writes &lt;math&gt;X^s/G = X^s/\!/G&lt;/math&gt;. Because of this, when &lt;math&gt;X^s&lt;/math&gt; is nonempty, the GIT quotient &lt;math&gt;\pi&lt;/math&gt; is often referred to as a "compactification" of a geometric quotient of an open subset of ''X''.

A difficult and seemingly open question is: which geometric quotient arises in the above GIT fashion? The question is of a great interest since the GIT approach produces an ''explicit'' quotient, as opposed to an abstract quotient, which is hard to compute. One known partial answer to this question is the following:&lt;ref&gt;{{harvnb|MFK|loc=Converse 1.13. NB: even though the result is stated for a smooth variety, the proof there is valid for a locally factorial one.}}&lt;/ref&gt; let &lt;math&gt;X&lt;/math&gt; be a [[locally factorial scheme|locally factorial]] algebraic variety (for example, a smooth variety) with an action of &lt;math&gt;G&lt;/math&gt;. Suppose there are an open subset &lt;math&gt;U \subset X&lt;/math&gt; as well as a geometric quotient &lt;math&gt;\pi: U \to U/G&lt;/math&gt; such that (1) &lt;math&gt;\pi&lt;/math&gt; is an [[affine morphism]] and (2) &lt;math&gt;U/G&lt;/math&gt; is quasi-projective. Then &lt;math&gt;U \subset X^s(L)&lt;/math&gt; for some linearlized line bundle ''L'' on ''X''.

== Examples ==
A simple example of a GIT quotient is given by the &lt;math&gt;\mathbb{Z}/2&lt;/math&gt;-action on &lt;math&gt;\mathbb{C}[x,y]&lt;/math&gt; sending
:&lt;math&gt;
\begin{align}
x \mapsto -x &amp;&amp; y \mapsto -y
\end{align}
&lt;/math&gt;
Notice that the monomials &lt;math&gt;x^2,xy,y^2&lt;/math&gt; generate the ring &lt;math&gt;\mathbb{C}[x,y]^{\mathbb{Z}/2}&lt;/math&gt;. Hence we can write the ring of invariants as
:&lt;math&gt;\mathbb{C}[x,y]^{\mathbb{Z}/2} = \mathbb{C}[x^2,xy,y^2] = \frac{\mathbb{C}[a,b,c]}{(ac - b^2)}&lt;/math&gt;
Scheme theoretically, we get the morphism
:&lt;math&gt;\mathbb{A}^2 \to \text{Spec}\left(\frac{\mathbb{C}[a,b,c]}{(ac - b^2)}\right) = \mathbb{A}^2/(\mathbb{Z}/2)&lt;/math&gt;

== See also ==
*[[quotient stack]]
*[[character variety]]
*[[Chow quotient]]

== Notes ==
{{reflist}}

== References ==
=== Pedagogical ===
*{{cite book
| last        = Mukai
| first       = S.
| year        = 2002
| title       = An introduction to invariants and moduli
| series      = Cambridge Studies in Advanced Mathematics
| volume      = 81
| isbn        = 978-0-521-80906-1
| url         = http://www.cambridge.org/catalogue/catalogue.asp?isbn=0521809061
}}
*M. Brion, "Introduction to actions of algebraic groups" [http://www-fourier.ujf-grenoble.fr/~mbrion/notes_luminy.pdf]
*{{Cite journal|last=Thomas |first=R. P. |arxiv=math/0512411 |title=Notes on GIT and symplectic reduction for bundles and varieties |journal=Surveys in Differential Geometry,  (): A Tribute to Professor S.-S. Chern |volume=10 |issue=2006 |year=2006 |version=v3 |bibcode=2005math.....12411T }}


=== Reference ===

*{{Cite arxiv|last=Alper|first=Jarod|date=2008-04-14|title=Good moduli spaces for Artin stacks|eprint=0804.2242|class=math.AG}}
*{{cite arXiv |first=Brent  |last=Doran |first2=Frances |last2=Kirwan |eprint=math/0703131v1 |year=2007 |title=Towards non-reductive geometric invariant theory }}
*Victoria Hoskins, [https://www.math.uzh.ch/index.php?file&amp;key1=22003 Quotients in algebraic and symplectic geometry]
*F. C. Kirwan, Cohomology of Quotients in Complex and Algebraic Geometry, Mathematical Notes 31, Princeton University Press, Princeton N. J., 1984.
*{{Cite book| last1=Mumford | first1=David | author1-link=David Mumford | last2=Fogarty | first2=J. | last3=Kirwan | first3=F. | author3-link=Frances Kirwan | title=Geometric invariant theory | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=3rd | series=Ergebnisse der Mathematik und ihrer Grenzgebiete (2) [Results in Mathematics and Related Areas (2)] | isbn=978-3-540-56963-3 |mr=1304906 | year=1994 | volume=34}}


[[Category:Algebraic geometry]]


{{algebraic-geometry-stub}}</text>
      <sha1>8io2jyi2j2beddvmtvrkw9u4nbl8czu</sha1>
    </revision>
  </page>
  <page>
    <title>Grand Riemann hypothesis</title>
    <ns>0</ns>
    <id>669864</id>
    <revision>
      <id>849413178</id>
      <parentid>744402365</parentid>
      <timestamp>2018-07-08T20:44:07Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1317">In [[mathematics]], the '''grand Riemann hypothesis''' is a generalisation of the [[Riemann hypothesis]] and [[generalized Riemann hypothesis]]. It states that the nontrivial zeros of all [[automorphic function|automorphic]] [[L-function|''L''-functions]] lie on the critical line &lt;math&gt;\frac{1}{2} + it&lt;/math&gt; with &lt;math&gt;t&lt;/math&gt; a real number variable and &lt;math&gt;i&lt;/math&gt; the [[imaginary unit]].

The '''modified grand Riemann hypothesis''' is the assertion that the nontrivial zeros of all automorphic ''L''-functions lie on the critical line or the [[real line]].

== Notes ==

* It is widely believed that all global ''L''-functions are automorphic ''L''-functions.{{Citation needed|date=November 2012}}
* The [[Siegel zero]], conjectured not to exist{{Citation needed|date=November 2012}}, is a possible real zero of a [[Dirichlet L-series]], rather near ''s'' = 1.
* L-functions of Maass cusp forms can have trivial zeros which are off the real line.

==References==
* {{citation |title=The Riemann hypothesis: a resource for the aficionado and virtuoso alike |volume=27 |series=CMS books in mathematics |first=Peter B. |last=Borwein |publisher=[[Springer-Verlag]] | year=2008 |isbn=0-387-72125-8 }}

{{mathanalysis-stub}}
[[Category:Zeta and L-functions]]
[[Category:Conjectures]]
[[Category:Bernhard Riemann]]</text>
      <sha1>9t4wcmulac5jhx2qhq88516gczieerx</sha1>
    </revision>
  </page>
  <page>
    <title>Géza Grünwald</title>
    <ns>0</ns>
    <id>35261957</id>
    <revision>
      <id>866392160</id>
      <parentid>865419597</parentid>
      <timestamp>2018-10-30T01:47:13Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Mathematicians who died in the Holocaust per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 October 12]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="666">'''Géza Grünwald''' (October 18, 1910, Budapest – September 7, 1943)  was a [[Jewish-Hungarian]]&lt;ref&gt;{{cite web |url=http://www.math.technion.ac.il/hat/people/obits/grunwald.html |title=The life and mathematics of Géza Grünwald |publisher=Technion-Israel Institute of Technology |accessdate=May 9, 2013}}&lt;/ref&gt; mathematician who worked on [[Analysis (mathematics)|analysis]].

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Grunwald, Geza}}
[[Category:Hungarian mathematicians]]
[[Category:1910 births]]
[[Category:1943 deaths]]
[[Category:Hungarian Jewish people who died in the Holocaust]]

{{Hungary-scientist-stub}}
{{mathematician-stub}}</text>
      <sha1>0enysch0uqk5oeln637ivog5s32fs1a</sha1>
    </revision>
  </page>
  <page>
    <title>Hamiltonian path</title>
    <ns>0</ns>
    <id>244437</id>
    <revision>
      <id>861727640</id>
      <parentid>852369767</parentid>
      <timestamp>2018-09-29T15:48:23Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>clean up, replaced: Trans. American Math. Soc. → Trans. Amer. Math. Soc.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15206">{{about|the nature of Hamiltonian paths|the question of the existence of a Hamiltonian path or cycle in a given graph|Hamiltonian path problem}}
{{Hamiltonian path dodecahedron}}
[[Image:Herschel graph.svg|thumb|The [[Herschel graph]] is the smallest possible [[polyhedral graph]] that does not have a Hamiltonian cycle.]]

In the [[mathematics|mathematical]] field of [[graph theory]], a '''Hamiltonian path''' (or '''traceable path''') is a [[path (graph theory)|path]] in an undirected or directed graph that visits each [[vertex (graph theory)|vertex]] exactly once. A '''Hamiltonian cycle''' (or '''Hamiltonian circuit''') is a Hamiltonian path that is a [[cycle (graph theory)|cycle]]. Determining whether such paths and cycles exist in graphs is the [[Hamiltonian path problem]], which is [[NP-complete problem|NP-complete]].

Hamiltonian paths  and cycles are named after [[William Rowan Hamilton]] who invented the [[icosian game]], now also known as ''Hamilton's puzzle'', which involves finding a Hamiltonian cycle in the edge graph of the [[dodecahedron]].  Hamilton solved this problem using the [[icosian calculus]], an [[algebraic structure]] based on [[root of unity|roots of unity]] with many similarities to the [[quaternion]]s (also invented by Hamilton).  This solution does not generalize to arbitrary graphs.

Despite being named after Hamilton, Hamiltonian cycles in polyhedra had also been studied a year earlier by [[Thomas Kirkman]], who, in particular, gave an example of a polyhedron without Hamiltonian cycles.&lt;ref&gt;{{citation
 | last = Biggs | first = N. L.
 | doi = 10.1112/blms/13.2.97
 | issue = 2
 | journal = The Bulletin of the London Mathematical Society
 | mr = 608093
 | pages = 97–120
 | title = T. P. Kirkman, mathematician
 | volume = 13
 | year = 1981}}.&lt;/ref&gt; Even earlier, Hamiltonian cycles and paths in the [[knight's graph]] of the [[chessboard]], the [[knight's tour]], had been studied in the 9th century in [[Indian mathematics]] by [[Rudrata]], and around the same time in [[Mathematics in medieval Islam|Islamic mathematics]] by {{ill|al-Adli ar-Rumi|fr|Al-Adli}}. In 18th century Europe, knight's tours were published by [[Abraham de Moivre]] and [[Leonhard Euler]].&lt;ref&gt;{{citation|title=Across the Board: The Mathematics of Chessboard Problems|first=John J.|last=Watkins|publisher=Princeton University Press|year=2004|pages=25–38|chapter=Chapter 2: Knight's Tours|isbn=978-0-691-15498-5}}.&lt;/ref&gt;

==Definitions==
A ''Hamiltonian path'' or ''traceable path'' is a [[path (graph theory)|path]] that visits each vertex of the graph exactly once. A graph that contains a Hamiltonian path is called a '''traceable graph'''. A graph is '''Hamiltonian-connected''' if for every pair of vertices there is a Hamiltonian path between the two vertices.

A ''Hamiltonian cycle'', ''Hamiltonian circuit'', ''vertex tour'' or ''graph cycle'' is a [[cycle (graph theory)|cycle]] that visits each vertex exactly once
(except for the vertex that is both the start and end, which is visited twice). A graph that contains a Hamiltonian cycle is called a '''Hamiltonian graph'''.

Similar notions may be defined for ''[[directed graph]]s'', where each edge (arc) of a path or cycle can only be traced in a single direction (i.e., the vertices are connected with arrows and the edges traced "tail-to-head").

A [[Hamiltonian decomposition]] is an edge decomposition of a graph into Hamiltonian circuits.

A ''Hamilton maze'' is a type of logic puzzle in which the goal is to find the unique Hamiltonian cycle in a given graph.&lt;ref&gt;{{cite book |last=de Ruiter |first=Johan |date=2017 |title=Hamilton Mazes - The Beginner's Guide}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www2.stetson.edu/~efriedma/puzzle/ham/ |title=Hamiltonian Mazes |last=Friedman |first=Erich |date=2009 |website=Erich's Puzzle Palace |access-date=27 May 2017 |deadurl=no |archiveurl=https://web.archive.org/web/20160416235225/http://www2.stetson.edu/~efriedma/puzzle/ham/ |archivedate=16 April 2016 |df= }}&lt;/ref&gt;

==Examples==
*a [[complete graph]] with more than two vertices is Hamiltonian
*every [[cycle graph]] is Hamiltonian
*every [[tournament (graph theory)|tournament]] has an odd number of Hamiltonian paths ([[László Rédei|Rédei]] 1934)
*every [[platonic solid]], considered as a graph, is Hamiltonian&lt;ref&gt;[http://www.scientificamerican.com/magazine/sa/1957/05-01/ Gardner, M. "Mathematical Games: About the Remarkable Similarity between the Icosian Game and the Towers of Hanoi." Sci. Amer. 196, 150–156, May 1957]
&lt;/ref&gt;
*the [[Cayley graph]] of a finite [[Coxeter group]] is Hamiltonian  (For more information on Hamiltonian paths in Cayley graphs, see the [[Lovász conjecture]])

==Properties==
Any Hamiltonian cycle can be converted to a Hamiltonian path by removing one of its edges, but a Hamiltonian path can be extended to Hamiltonian cycle only if its endpoints are adjacent.

All Hamiltonian graphs are [[Biconnected graph|biconnected]], but a biconnected graph need not be Hamiltonian (see, for example, the [[Petersen graph]]).&lt;ref&gt;{{cite web|url=http://mathworld.wolfram.com/BiconnectedGraph.html|title=Biconnected Graph|author=Eric Weinstein|publisher=Wolfram MathWorld}}&lt;/ref&gt;

An [[Eulerian graph]] ''G'' (a [[connected graph]] in which every vertex has even degree) necessarily has an Euler tour, a closed walk passing through each edge of ''G'' exactly once.
This tour corresponds to a Hamiltonian cycle in the [[line graph]] ''L''(''G''), so the line graph of every Eulerian graph is Hamiltonian. Line graphs may have other Hamiltonian cycles that do not correspond to Euler tours, and in particular the line graph ''L''(''G'') of every Hamiltonian graph ''G'' is itself Hamiltonian, regardless of whether the graph ''G'' is Eulerian.&lt;ref&gt;{{citation|title=A Textbook of Graph Theory|first1=R.|last1=Balakrishnan|first2=K.|last2=Ranganathan|publisher=Springer|year=2012|isbn=9781461445296|contribution=Corollary 6.5.5|page=134|url=https://books.google.com/books?id=mpgu6wgnZgYC&amp;pg=PA134}}.&lt;/ref&gt;

A [[Tournament (graph theory)|tournament]] (with more than two vertices) is Hamiltonian if and only if it is [[Strongly connected component|strongly connected]].

The number of different Hamiltonian cycles in a complete undirected graph on ''n'' vertices is {{nowrap|(''n'' &amp;minus; 1)! / 2}} and in a complete directed graph on ''n'' vertices is {{nowrap|(''n'' &amp;minus; 1)!}}.  These counts assume that cycles that are the same apart from their starting point are not counted separately.

== Bondy–Chvátal theorem ==

The best vertex [[degree (graph theory)|degree]] characterization of Hamiltonian graphs was provided in 1972 by the [[J. A. Bondy|Bondy]]–[[Václav Chvátal|Chvátal]] theorem, which generalizes earlier results by [[Gabriel Andrew Dirac|G. A. Dirac]] (1952) and [[Øystein Ore]]. Both Dirac's and Ore's theorems can also be derived from [[Lajos Pósa (mathematician)|Pósa]]'s theorem (1962). Hamiltonicity has been widely studied with relation to various parameters such as graph [[Dense graph|density]], [[Graph toughness|toughness]], [[Forbidden subgraph problem|forbidden subgraphs]] and [[Distance (graph theory)|distance]] among other parameters.&lt;ref&gt;{{Cite web|url = http://www.mathcs.emory.edu/~rg/advances.pdf|title = Advances on the Hamiltonian Problem - A Survey|date = July 8, 2002|accessdate = 2012-12-10|publisher = Emory University|last = Gould|first = Ronald J.}}&lt;/ref&gt; Dirac and Ore's theorems basically state that a graph is Hamiltonian if it has ''enough edges''.

Bondy–Chvátal theorem operates on the '''closure''' cl(''G'') of a graph ''G'' with ''n'' vertices, obtained by repeatedly adding a new edge ''uv'' connecting a [[nonadjacent]] pair of vertices ''u'' and ''v'' with {{nowrap|degree(''v'') + degree(''u'') ≥ ''n''}} until no more pairs with this property can be found.

'''Bondy–Chvátal theorem'''
:A graph is Hamiltonian if and only if its closure is Hamiltonian.

As complete graphs are Hamiltonian, all graphs whose closure is complete are Hamiltonian, which is the content of the following earlier theorems by Dirac and Ore.

'''Dirac''' (1952)
:A [[simple graph]] with ''n'' vertices ({{nowrap|''n'' ≥ 3}}) is Hamiltonian if every vertex has degree {{nowrap|''n'' / 2}} or greater.

'''Ore''' (1960)
:A graph with ''n'' vertices (''n'' ≥ 3) is Hamiltonian if, for every pair of non-adjacent vertices, the sum of their degrees is ''n'' or greater (see [[Ore's theorem]]).

The following theorems can be regarded as directed versions:

'''Ghouila-Houiri''' (1960)
:A [[strongly connected graph|strongly connected]] [[simple graph|simple]] [[directed graph]] with ''n'' vertices is Hamiltonian if every vertex has a full degree greater than or equal to&amp;nbsp;''n''.

'''Meyniel''' (1973)
:A [[strongly connected graph|strongly connected]] [[simple graph|simple]] [[directed graph]] with ''n'' vertices is Hamiltonian if the sum of full degrees of every pair of distinct non-adjacent vertices is greater than or equal to {{nowrap|2''n'' − 1}}.

The number of vertices must be doubled because each undirected edge corresponds to two directed arcs and thus the degree of a vertex in the directed graph is twice the degree in the undirected graph.

'''Rahman-Kaykobad''' (2005)
:A [[simple graph]] with ''n'' vertices has a Hamiltonian path if, for every non-adjacent vertex pairs the sum of their degrees and their shortest path length is greater than ''n''.&lt;ref&gt;{{Cite journal|url = |title = On Hamiltonian cycles and Hamiltonian paths|last = Rahman|first = M. S.|date = April 2005|journal = Information Processing Letters|doi = 10.1016/j.ipl.2004.12.002|pmid = |access-date = |last2 = Kaykobad|first2 = M.|volume = 94|pages = 37–41}}&lt;/ref&gt;

The above theorem can only recognize the existence of a Hamiltonian path in a graph and not a Hamiltonian Cycle.

Many of these results have analogues for balanced [[bipartite graph]]s, in which the vertex degrees are compared to the number of vertices on a single side of the bipartition rather than the number of vertices in the whole graph.&lt;ref&gt;{{citation
 | last1 = Moon | first1 = J.
 | last2 = Moser | first2 = L. | author2-link = Leo Moser
 | doi = 10.1007/BF02759704
 | journal = [[Israel Journal of Mathematics]]
 | mr = 0161332
 | pages = 163–165
 | title = On Hamiltonian bipartite graphs
 | volume = 1
 | year = 1963}}&lt;/ref&gt;

== Existence of Hamiltonian cycles in planar graphs ==

; Theorem (Whitney, 1931)
:A 4-connected planar triangulation has a Hamiltonian cycle.

; Theorem (Tutte, 1956)
:A 4-connected planar graph has a Hamiltonian cycle.

==See also==
{{refbegin|colwidth=40em}}
* [[Barnette's conjecture]], an open problem on Hamiltonicity of cubic [[bipartite graph|bipartite]] [[polyhedral graph]]s
* [[Eulerian path]], a path through all edges in a graph
* [[Fleischner's theorem]], on Hamiltonian [[power of graph|squares of graphs]]
* [[Grinberg's theorem]] giving a necessary condition for [[planar graph]]s to have a Hamiltonian cycle
* [[Hamiltonian path problem]], the computational problem of finding Hamiltonian paths
* [[Hypohamiltonian graph]], a non-Hamiltonian graph in which every vertex-deleted subgraph is Hamiltonian
* [[Knight's tour]], a Hamiltonian cycle in the [[knight's graph]]
* [[LCF notation]] for Hamiltonian [[cubic graph]]s.
* [[Lovász conjecture]] that [[vertex-transitive graph]]s are Hamiltonian
* [[Pancyclic graph]], graphs with cycles of all lengths including a Hamiltonian cycle
* [[Shortness exponent]], a numerical measure of how far from Hamiltonian the graphs in a family can be
* [[Snake-in-the-box]], the longest [[induced path]] in a hypercube
* [[Steinhaus–Johnson–Trotter algorithm]] for finding a Hamiltonian path in a [[permutohedron]]
* [[Subhamiltonian graph]], a subgraph of a [[planar graph|planar]] Hamiltonian graph
* [[Tait's conjecture]] (now known false) that 3-regular [[polyhedral graph]]s are Hamiltonian
* [[Travelling salesman problem]]
* [[Gray code]]
{{refend}}

==Notes==
{{reflist}}

== References ==
* {{citation
 | last1 = Berge | first1 = Claude | author1-link = Claude Berge
 | last2 = Ghouila-Houiri | first2 = A.
 | location = New York
 | publisher = Sons, Inc.
 | title = Programming, games and transportation networks
 | year = 1962}}
*{{citation
 | last = DeLeon | first = Melissa
 | issue = 1
 | journal = Rose-Hulman Undergraduate Math Journal
 | title = A study of sufficient conditions for Hamiltonian cycles
 | url = http://www.rose-hulman.edu/mathjournal/archives/2000/vol1-n1/paper4/v1n1-4pd.PDF
 | volume = 1
 | year = 2000}}.
*{{citation
 | last = Dirac | first = G. A. | authorlink = Gabriel Andrew Dirac
 | doi = 10.1112/plms/s3-2.1.69
 | mr = 0047308
 | journal = Proceedings of the London Mathematical Society | series = 3rd Ser.
 | pages = 69–81
 | title = Some theorems on abstract graphs
 | volume = 2
 | year = 1952}}.
*{{citation
 | last = Hamilton | first = William Rowan | author-link = William Rowan Hamilton
 | journal = [[Philosophical Magazine]]
 | page = 446
 | title = Memorandum respecting a new system of roots of unity
 | volume = 12
 | year = 1856}}.
*{{citation
 | last = Hamilton | first = William Rowan | author-link = William Rowan Hamilton
 | journal = [[Proceedings of the Royal Irish Academy]]
 | pages = 415–416
 | title = Account of the Icosian Calculus
 | volume = 6
 | year = 1858}}.
*{{citation
 | last = Meyniel | first = M.
 | doi = 10.1016/0095-8956(73)90057-9
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 0317997
 | pages = 137–147
 | series = Series B
 | title = Une condition suffisante d'existence d'un circuit hamiltonien dans un graphe orienté
 | volume = 14
 | year = 1973}}.
*{{citation
 | last = Ore | first = Øystein | authorlink = Øystein Ore
 | journal = The American Mathematical Monthly
 | jstor = 2308928
 | mr = 0118683
 | doi = 10.2307/2308928
 | page = 55
 | title = Note on Hamilton circuits
 | volume = 67
 | year = 1960}}.
*{{citation
 | last = Pósa | first = L. | authorlink = Lajos Pósa (mathematician)
 | journal = Magyar Tud. Akad. Mat. Kutató Int. Közl.
 | mr = 0184876
 | pages = 225–226
 | title = A theorem concerning Hamilton lines
 | volume = 7
 | year = 1962}}.
*{{citation
 | last = Whitney | first = Hassler | authorlink = Hassler Whitney
 | doi = 10.2307/1968197
 | issue = 2
 | journal = Annals of Mathematics
 | mr = 1503003
 | pages = 378–390
 | series = Second Series
 | title = A theorem on graphs
 | volume = 32
 | year = 1931}}.
*{{citation
 | last = Tutte | first = W. T. | authorlink = W._T._Tutte
 | doi = 10.1090/s0002-9947-1956-0081471-8
 | issue = 
 | journal = Trans. Amer. Math. Soc.
 | mr = 
 | pages = 99–116
 | series = 
 | title = A theorem on planar graphs
 | volume = 82
 | year = 1956}}.

==External links==
* {{MathWorld|title=Hamiltonian Cycle|urlname=HamiltonianCycle}}
* [https://web.archive.org/web/20120309190309/http://www.graph-theory.net/euler-tour-and-hamilton-cycles/ Euler tour and Hamilton cycles]

[[Category:Computational problems in graph theory]]
[[Category:NP-complete problems]]
[[Category:Graph theory objects]]
[[Category:Hamiltonian paths and cycles| ]]
[[Category:William Rowan Hamilton]]</text>
      <sha1>t5nyig63fytxvkhlfdvvg7xu3lne1g0</sha1>
    </revision>
  </page>
  <page>
    <title>Hesse normal form</title>
    <ns>0</ns>
    <id>20665580</id>
    <revision>
      <id>838586935</id>
      <parentid>837846734</parentid>
      <timestamp>2018-04-28T00:07:00Z</timestamp>
      <contributor>
        <username>Nikolaiho</username>
        <id>20623822</id>
      </contributor>
      <comment>Added {{[[:Template:one source|one source]]}} tag to article ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3202">{{one source|date=April 2018}}
[[Image:Hesse normal form.png|thumb|Drawing of the normal (in red) and the distance from the origin to the line (in green) calculated with the Hesse normal form]]
The '''Hesse normal form''' named after [[Otto Hesse]], is an equation used in [[analytic geometry]], and describes a [[line (geometry)|line]] in &lt;math&gt;\mathbb{R}^2&lt;/math&gt; or a [[plane (geometry)|plane]] in [[Euclidean space]] &lt;math&gt;\mathbb{R}^3&lt;/math&gt; or a hyperplane in higher dimensions.&lt;ref&gt;{{citation|title=Plane Analytic Geometry: With Introductory Chapters on the Differential Calculus|first=Maxime|last=Bôcher|publisher=H. Holt|year=1915|authorlink=Maxime Bôcher|page=44|url=https://books.google.com/books?id=bYkLAAAAYAAJ&amp;pg=PA44}}.&lt;/ref&gt; It is primarily used for calculating distances (see [[point-plane distance]] and [[point-line distance]]). 

It is written in vector notation as

:&lt;math&gt;\vec r \cdot \vec n_0 - d = 0.\,&lt;/math&gt;

The dot &lt;math&gt;\cdot&lt;/math&gt; indicates the [[scalar product]] or [[dot product]].
The vector &lt;math&gt;\vec n_0&lt;/math&gt; represents the [[unit vector|unit]] [[normal vector]] of ''E'' or ''g'', that points from the origin of the coordinate system to the plane (or line, in 2D). The distance &lt;math&gt;d \ge 0&lt;/math&gt; is the distance from the origin to the plane (or line).

This equation is satisfied by all points ''P'', lying precisely in the plane ''E'' (or in 2D, on the line ''g''), described by the location vector &lt;math&gt;\vec r&lt;/math&gt; that points from the origin of the coordinate system to ''P''.

== Derivation/Calculation from the normal form ==

Note: For simplicity, the following derivation discusses the 3D case. However, it is also applicable in 2D.

In the normal form,

:&lt;math&gt;(\vec r -\vec a)\cdot \vec n = 0\,&lt;/math&gt;

a plane is given by a normal vector &lt;math&gt;\vec n&lt;/math&gt; as well as an arbitrary position vector &lt;math&gt;\vec a&lt;/math&gt; of a point &lt;math&gt;A \in E&lt;/math&gt;. The direction of &lt;math&gt;\vec n&lt;/math&gt; is chosen to satisfy the following inequality 

:&lt;math&gt;\vec a\cdot \vec n \geq 0\,&lt;/math&gt;

By dividing the normal vector &lt;math&gt;\vec n&lt;/math&gt; by its [[Euclidean_vector#Length_of_a_vector|magnitude]] &lt;math&gt;| \vec n |&lt;/math&gt;, we obtain the unit (or normalized) normal vector

:&lt;math&gt;\vec n_0 = {{\vec n} \over {| \vec n |}}\,&lt;/math&gt;

and the above equation can be rewritten as

:&lt;math&gt;(\vec r -\vec a)\cdot \vec n_0 = 0.\,&lt;/math&gt;

Substituting

:&lt;math&gt;d = \vec a\cdot \vec n_0 \geq 0\,&lt;/math&gt;

we obtain the Hesse normal form

:&lt;math&gt;\vec r \cdot \vec n_0 - d = 0.\,&lt;/math&gt;

&lt;center&gt;[[File:Ebene Hessesche Normalform.PNG]]&lt;/center&gt;

In this diagram, ''d'' is the distance from the origin. Because &lt;math&gt;\vec r \cdot \vec n_0 = d&lt;/math&gt; holds for every point in the plane, it is also true at point ''Q'' (the point where the vector from the origin meets the plane E), with &lt;math&gt;\vec r = \vec r_s&lt;/math&gt;, per the definition of the [[Scalar product]]

:&lt;math&gt;d = \vec r_s \cdot \vec n_0 = |\vec r_s| \cdot |\vec n_0| \cdot \cos(0^\circ) = |\vec r_s| \cdot 1 = |\vec r_s|.\,&lt;/math&gt;

The magnitude &lt;math&gt;|\vec r_s|&lt;/math&gt; of &lt;math&gt;{\vec r_s}&lt;/math&gt; is the shortest distance from the origin to the plane.

==References==
{{reflist}}

[[Category:Analytic geometry]]</text>
      <sha1>i55cgd6sj5kv57juaa9u53wwv8z9gpt</sha1>
    </revision>
  </page>
  <page>
    <title>ICTP Ramanujan Prize</title>
    <ns>0</ns>
    <id>13595525</id>
    <revision>
      <id>868220533</id>
      <parentid>850450750</parentid>
      <timestamp>2018-11-10T20:10:12Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: title. Converted bare reference to cite template. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]]; [[Category:Pages with citations having bare URLs]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5307">The '''ICTP Ramanujan Prize for Young Mathematicians from Developing Countries''' is a [[mathematics]] [[prize]] awarded annually by the [[International Centre for Theoretical Physics]] and named after the mathematician [[Srinivasa Ramanujan]]. It was founded in 2004,&lt;ref&gt;[https://www.ictp.it/media/612528/ictp_full_technical_report_2012.pdf The Abdus Salam International Centre for Theoretical Physics Full Technical Report 2012, p. 182]&lt;/ref&gt; and was first awarded in 2005.

The prize is awarded to a researcher from a developing country less than 45 years of age who has conducted outstanding research in a developing country.&lt;ref&gt;{{citation|title=Ramanujan's Place in the World of Mathematics: Essays Providing a Comparative Study|first=Krishnaswami|last=Alladi|authorlink= Krishnaswami Alladi |publisher=Springer|year=2012|isbn=9788132207672|contribution=Niels Henrik Abel: Norwegian Mathematical Genius|pages=81–88|doi=10.1007/978-81-322-0767-2_13}}. See in particular [https://books.google.com/books?id=XLNJDylP53QC&amp;pg=PA87 p.&amp;nbsp;87]. Reprint of an article originally published in ''[[The Hindu]]'', December 2004.&lt;/ref&gt;  The prize is supported by the [[Ministry of Science and Technology (India)]] and [[Norwegian Academy of Science and Letters]] through the [[Abel Prize|Abel Fund]], with the cooperation of the [[International Mathematical Union]].

== Winners ==

Source: [http://www.mathunion.org/general/prizes/ramanujan-prize/prize-winners/winners/ International Mathematical Union]

* 2005 [[Marcelo Viana]], Brazil&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200601/people.pdf|department=Mathematics People|title=Viana Awarded ICTP/IMU Ramanujan Prize|journal=[[Notices of the AMS]]|page=51|date=January 2006|volume=53|issue=1}}.&lt;/ref&gt;
* 2006 [[Ramdorai Sujatha]], India&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200702/people.pdf|department=Mathematics People|title=Sujatha Awarded ICTP/IMU Ramanujan Prize|journal=[[Notices of the AMS]]|page=268|date=February 2007|volume=54|issue=2}}.&lt;/ref&gt;
* 2007 [[Jorge Lauret]], Argentina&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200802/tx080200264p.pdf|department=Mathematics People|title=Lauret Awarded ICTP/IMU Ramanujan Prize|journal=[[Notices of the AMS]]|page=265|first=Allyn|last=Jackson|date=February 2008|volume=55|issue=2}}.&lt;/ref&gt;
* 2008 [[Enrique Pujals]], Argentina/Brazil&lt;ref&gt;{{citation|url=http://www.ams.org/notices/200902/rtx090200268p.pdf|department=Mathematics People|title=Pujals Awarded ICTP/IMU Ramanujan Prize|journal=[[Notices of the AMS]]|page=268|date=February 2009|volume=56|issue=2}}.&lt;/ref&gt;
* 2009 [[Ernesto Lupercio]], Mexico&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201004/rtx100400532p.pdf|department=Mathematics People|title=Lupercio Awarded ICTP/IMU Ramanujan Prize|journal=[[Notices of the AMS]]|page=533|date=April 2010|volume=57|issue=4}}.&lt;/ref&gt;
* 2010 [[Shi Yuguang]], China&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201108/rtx110801131p.pdf|department=Mathematics People|title=Shi Awarded ICTP Ramanujan Prize|journal=[[Notices of the AMS]]|page=1132|date=September 2011|volume=58|issue=8}}.&lt;/ref&gt;
* 2011 [[Philibert Nang]], Gabon&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201204/rtx120400578p.pdf|department=Mathematics People|title=Nang Awarded Ramanujan Prize for Young Mathematicians from Developing Countries|journal=[[Notices of the AMS]]|page=578|date=April 2012|volume=59|issue=4}}.&lt;/ref&gt;
* 2012 [[Fernando Codá Marques]], Brazil&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201302/rnoti-p245.pdf|department=Mathematics People|title=Codá Marques Awarded Ramanujan and TWAS Prizes|journal=[[Notices of the AMS]]|page=245|date=February 2013|volume=60|issue=2|first=Elaine|last=Kehoe}}.&lt;/ref&gt;
* 2013 [[Tian Ye (mathematician)|Tian Ye]], China&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201402/rnoti-p195.pdf|department=Mathematics People|title=Ye Tian Awarded 2013 ICTP/IMU Ramanujan Prize|journal=[[Notices of the AMS]]|page=195|date=February 2014|volume=61|issue=2}}.&lt;/ref&gt;
* 2014 [[Miguel Walsh]], Argentina&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201410/rnoti-p1253.pdf|department=Mathematics People|title=Walsh Awarded ICTP-IMU Ramanujan Prize|journal=[[Notices of the AMS]]|page=1253|date=November 2014|volume=61|issue=10|first=Elaine|last=Kehoe}}.&lt;/ref&gt;
* 2015 [[Amalendu Krishna]], India&lt;ref&gt;[https://www.ictp.it/about-ictp/prizes-awards/the-ramanujan-prize/the-ramanujan-prize-winners/ramanujan-prize-winner-2015.aspx Award citation], retrieved 2015-08-03.&lt;/ref&gt;
* 2016 [[Chenyang Xu]], China
* 2017 [[Eduardo Teixeira]], Brazil &lt;ref&gt;{{citation|url=https://www.ictp.it/about-ictp/media-centre/news/2017/6/ramanujan-2017-announce.aspx|title=ICTP - Ramanujan Prize Winner Announced}}.&lt;/ref&gt;
* 2018 [[Ritabrata Munshi]], India &lt;ref&gt;{{cite web | url=https://www.ictp.it/about-ictp/prizes-awards/the-ramanujan-prize/the-ramanujan-prize-winners/ramanujan-prize-winner-2018.aspx | title=ICTP - Ramanujan Prize Winner 2018}}&lt;/ref&gt;

==See also==
* [[SASTRA Ramanujan Prize]]

==References==
{{reflist}}

==External links==
* [http://www.ictp.it/about-ictp/prizes-awards/the-ramanujan-prize.aspx Official web site]

[[Category:Mathematics awards]]
[[Category:Awards established in 2004]]
[[Category:Srinivasa Ramanujan]]
[[Category:International awards]]

{{math-stub}}</text>
      <sha1>q3k0yk8r4igtksxqhji6d7war8konoq</sha1>
    </revision>
  </page>
  <page>
    <title>Impartial game</title>
    <ns>0</ns>
    <id>79378</id>
    <revision>
      <id>845153525</id>
      <parentid>845153335</parentid>
      <timestamp>2018-06-09T19:46:31Z</timestamp>
      <contributor>
        <username>Tea2min</username>
        <id>36029</id>
      </contributor>
      <comment>/* top */ Move examples up. I think this helps the reader understand the definition.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4312">In [[combinatorial game theory]], an '''impartial game''' is a [[Mathematical game|game]] in which the allowable moves depend only on the position and not on which of the two players is currently moving, and where the payoffs are symmetric. In other words, the only difference between player 1 and player 2 is that player 1 goes first. The game is played until a terminal position is reached. A terminal position is one from which no moves are possible. Then one of the players is declared the winner and the other the loser. Furthermore, impartial games are played with perfect information and no chance moves, meaning all information about the game and operations for both players are visible to both players.

Impartial games include [[Nim]], [[Sprouts (game)|Sprouts]], [[Kayles]], [[Quarto (board game)|Quarto]], [[Cram (game)|Cram]], [[Chomp]], [[Subtract a square]], [[Notakto]], and [[poset game]]s. [[Go (board game)|Go]] and [[chess]] are not impartial, as each player can only place or move pieces of their own color. Games such as [[poker]], [[dice]] or [[Dominoes|dominos]] are not impartial games as they rely on chance.

Impartial games can be analyzed using the [[Sprague–Grundy theorem]], stating that every impartial game under the [[normal play convention]] is equivalent to a [[nimber]]. The representation of this nimber can change from game to game, but every possible state of any variation of an impartial game board should be able to have some nimber value. For example, several nim heaps in the game nim can be calculated, then summed using nimber addition, to give a nimber value for the game.

A game that is not impartial can be a [[partisan game]] though some partisan games can still be evaluated using nimbers such as [[Domineering]].&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/933627646|title=Advances in computer games : 14th International Conference, ACG 2015, Leiden, the Netherlands, July 1-3, 2015, Revised selected papers|others=Herik, Jaap van den,, Plaat, Aske,, Kosters, Walter,|isbn=3319279920|location=Cham|oclc=933627646}}&lt;/ref&gt; Domineering would not be classified as an impartial game as players use differently acting pieces, one player with vertical dominoes, one with horizontal ones, thereby breaking the rule that each player must be able to act using the same operations.

== Requirements ==
All impartial games must meet the following conditions:
* Two players must alternate turns until a final state is reached.
* A winner is chosen when one player may no longer change position or make any operation.
* There must be a finite number of operations and positions for both player. For example, in Nim, players must take away a subset of a stack that is currently in play. As there is a finite number of coins in any stack, a player may only remove a finite number of coins.
* All operations must be able to be done by both sides. In all Impartial games, the players are making actions to some game board whether in the form of stacks for Nim or rows and columns Cram. Both players are acting on the board till the board can no longer change in some way.
* No action in the game may be reliant on chance. Any inclusion of chance would mean there is not perfect information about the game, furthermore actions could not be minmaxed ruling out any form inductive strategy.&lt;ref&gt;{{Cite web|url=https://www.cs.cmu.edu/afs/cs/academic/class/15859-f01/www/notes/comb.pdf|title=Game Theory|last=Ferguson|first=Thomas S.|date=Fall 2000|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;

== References ==
{{reflist}}

==Further reading==
*{{cite book |author1=E. Berlekamp |author2=J. H. Conway |author3=R. Guy | title=[[Winning Ways for your Mathematical Plays]] | publisher=Academic Press | year=1982 | volume=2 vols.}}; {{cite book|title=vol. 1|isbn=0-12-091101-9}}; {{cite book|title=vol. 2|isbn=0-12-091102-7}}
*{{cite book |author1=E. Berlekamp |author2=J. H. Conway |author3=R. Guy | title=Winning Ways for your Mathematical Plays | edition=2nd | publisher=A K Peters Ltd | year=2001–2004 | volume=4 vols.}}; {{cite book|title=vol. 1|isbn=1-56881-130-6}}; {{cite book|title=vol. 2|isbn=1-56881-142-X}}; {{cite book|title=vol. 3|isbn=1-56881-143-8}}; {{cite book|title=vol. 4|isbn=1-56881-144-6}}

[[Category:Combinatorial game theory]]</text>
      <sha1>0cf10j5b8j8ng7j2qv54rwr6zl4do8k</sha1>
    </revision>
  </page>
  <page>
    <title>Index of accounting articles</title>
    <ns>0</ns>
    <id>192123</id>
    <revision>
      <id>837456770</id>
      <parentid>828556197</parentid>
      <timestamp>2018-04-20T23:07:54Z</timestamp>
      <contributor>
        <username>Allforrous</username>
        <id>12120664</id>
      </contributor>
      <comment>new key for [[Category:Accounting]]: "*" using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4680">This page is an '''index of accounting topics'''.

{{main|Accounting}}
{{AlphanumericTOC|
 align=center|
 nobreak=|
 numbers=|
 references=|
 externallinks=|
 top=|}}

==A==
[[Accounting ethics]] - [[Accounting information system]] - [[Accounting research]] - [[Activity-based costing|Activity-Based Costing]] - [[Assets]]

==B==
[[Balance sheet]]
- [[Big Four auditors]]
- [[Bond (finance)|Bond]]
- [[Bookkeeping]]
- [[Book value]]

==C==
[[Cash-basis accounting]]
- [[Cash-basis versus accrual-basis accounting]]
- [[Cash flow statement]]
- [[Certified General Accountant]]
- [[Certified Management Accountant]]s
- [[Certified Public Accountant]]
- [[Chartered accountant]]
- [[Chart of accounts]]
- [[Common stock]]
- [[Comprehensive income]]
- [[Construction accounting]]
- [[Convention of conservatism]]
- [[Convention of disclosure]]
- [[Cost accounting]]
- [[Cost of capital]]
- [[Cost of goods sold]]
- [[Creative accounting]]
- [[credit (finance)|Credit]]
- [[Credit note]]
- [[Current asset]]
- [[Current liability]]

==D==
[[Debit]]capital reserve
- [[Debit note]]
- [[Debt]]
- [[Deficit (disambiguation)]]
- [[Depreciation]]
- [[Diluted EPS|Diluted earnings per share]]
- [[Dividend]]
- [[Double-entry bookkeeping system]]
- [[Dual aspect]]

==E==
[[E-accounting]]
- [[Earnings before interest and taxes|EBIT]]
- [[EBITDA]]
- [[Earnings per share]]
- [[Engagement Letter]]
- [[Entity concept]]
- [[Environmental accounting]]
- [[Expense]]
- [[Ownership equity|Equity]]
- [[Equivalent Annual Cost]]

==F==
[[Financial Accounting Standards Board]]
- [[Financial accountancy]]
- [[Financial audit]]
- [[Financial reports]]
- [[Financial statements]]
- [[Fixed assets]]
- [[Fixed assets management]]
- [[Forensic accounting]]
- [[Fraud deterrence]]
- [[Free cash flow]]
- [[Fund accounting]]

==G==
[[Gain (accounting)|Gain]]
- [[General ledger]]
- [[Generally Accepted Accounting Principles]]
- [[Going concern]]
- [[Goodwill (accounting)|Goodwill]]
- [[Governmental Accounting Standards Board]]

==H==
[[Historical cost]] - [[History of accounting]]

==I==
[[Income]]
- [[Income statement]]
- [[Institute of Chartered Accountants in England and Wales]]
- [[Institute of Chartered Accountants of Scotland]]
- [[Institute of Management Accountants]]
- [[Intangible asset]]
- [[Interest]]
- [[Internal audit]]
- [[International Accounting Standards Board]]
- [[International Accounting Standards Committee]]
- [[International Accounting Standards]]
- [[International Federation of Accountants]]
- [[International Financial Reporting Standards]]
- [[Inventory]]
- [[Investment]]
- [[Invoice]]s
- [[Indian Accounting Standards]]

==J==
[[Job costing]]
- [[Journal (accounting)|Journal]]

==L==
[[Lean accounting]]
- [[Ledger]]
- [[Liability (accounting)|Liability]]
- [[Long-term asset]]
- [[Long-term liabilities]]
- [[Loss on sale of residential property]]

==M==
[[Maker-checker]]
- [[Management accounting]]
- [[Management Assertions]]
- [[Mark-to-market accounting]]
- [[Matching principle]]
- [[Materiality (auditing)|Materiality]]
- [[Money measurement concept]]
- [[Mortgage loan]]

==N==
[[Negative assurance]]
- [[Net income]]
- [[Notes to the Financial Statements]]

==O==
[[OBERAC]]
- [[Online Accounting]]
- [[Operating expense]]
- [[Ownership equity]]

==P==
[[Payroll]]
- [[Petty cash]]
- [[Philosophy of Accounting]]
- [[Preferred stock]]
- [[P/E ratio]]
- [[Positive accounting]]
- [[Positive assurance]]
- [[PricewaterhouseCoopers]]
- [[Profit and loss account]]
- [[Pro-forma amount]]
- [[Production accounting]]
- [[Project accounting]]

==R==
[[Retained earnings]]
- [[Revenue]]
- [[Revenue recognition]]

==S==
[[security (finance)|Security]]
- [[Sales journal]]
- [[Social accounting]]
- [[Spreadsheet]]
- [[Statement of changes in equity]]
- [[Statutory accounting principles]]
- [[Stock option]]
- [[Stock split]]
- [[Stock]]
- [[Shareholder]]
- [[Shareholders' equity]]
- [[South African Institute of Chartered Accountants]]
- [[Sunk cost]]
- [[Society of Accounting Education]]

==T==
[[Throughput accounting]]
- [[Trade credit]]
- [[Treasury stock]]
- [[Trial balance]]

==U==
[[UK generally accepted accounting principles]]
- [[Unified Ledger Accounting]]
- [[U.S. Securities and Exchange Commission]]
- [[US generally accepted accounting principles]]
- [[Work sheet]]
- [[Write off]]

==See also==
* [[Outline of finance]]
* [[Outline of marketing]]
* [[Outline of economics]]
* [[Outline of production]]
* [[Outline of business]]
* [[Index of auditing articles]]

[[Category:Accounting|*]]
[[Category:Business-related lists|Accounting topics]]
[[Category:Indexes of business topics|Accounting]]
[[Category:Mathematics-related lists|Accounting]]</text>
      <sha1>q7b3bhxymgf5pvw9no2wa8qtim2udq7</sha1>
    </revision>
  </page>
  <page>
    <title>Informating</title>
    <ns>0</ns>
    <id>9732458</id>
    <revision>
      <id>750732598</id>
      <parentid>750732594</parentid>
      <timestamp>2016-11-21T14:40:04Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/155.245.35.6|155.245.35.6]] to version by Jodosma. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (2844156) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4458">'''Informating''' is a term coined by [[Shoshana Zuboff]] in her book ''In the Age of the Smart Machine'' (1988).&lt;ref&gt;[[Shoshana Zuboff |Zuboff, Shoshana]]. ''In the Age of the Smart Machine: The Future of Work and Power''; 1988&lt;/ref&gt; It is the process that translates descriptions and measurements of activities, events and objects into [[information]]. By doing so, these activities become visible to the organization.

Informating has both an empowering and oppressing influence. On the one hand, as information processes become more powerful, the access to information is pushed to ever lower levels of the [[organization]]. Conversely, information processes can be used to monitor what Zuboff calls human agency.  

==Zuboff Description== 
From ''In the Age of the Smart Machine'', Informating is described as:

&lt;blockquote&gt;
''What is it, then, that distinguishes information technology from earlier generations of machine [[technology]]? As information technology is used to reproduce, extend, and improve upon the process of substituting machines for human agency, it simultaneously accomplishes something quite different. The devices that automate by translating information into action also register data about those automated activities, thus generating new streams of information. For example, computer-based, numerically controlled machine tools or microprocessor-based sensing devices not only apply programmed instructions to equipment but also convert the current state of equipment, product, or process into data. Scanner devices in supermarkets automate the checkout process and simultaneously generate data that can be used for inventory control, warehousing, scheduling of deliveries, and market analysis. The same systems that make it possible to automate office transactions also create a vast overview of an organization's operations, with many levels of data coordinated and accessible for a variety of analytical efforts." (Zuboff, 1988; p. 9)''
&lt;/blockquote&gt;

==Concept==
As per the Zuboff's definition, and examples stated in her book surrounding the concept, confers the basic idea as, any activity, such as two friends who using Facebook communicate to other whats on their mind. Which could also be said they are informating, where using a technological tool such as Facebook, the two friends are converting their activity of thinking or per se something specific to their mutual context, into information. Thereby making their activity visible to friend or friends. 

With advent of parallelism also the concept of informating is achieving further value. Because any activity done is able to produce multiple streams of information, which may be independent, yet held together by the context, in which they are embedded.  

==Usage of Word==
Recently a Limited Liability Partnership was successfully registered with Ministry of Corporate Affairs, India with the use of the word ''Informating'' in the Company title.&lt;ref&gt;"CHIASMA Informating Communities", as per [https://docs.google.com/open?id=0B-k_qEFnjEm6YVk1TVRxbEpZT3c Certificate of Incorporation],  by Ministry of Corporate Affairs, INDIA. Dated 18 September 2012.&lt;/ref&gt;

''Informating'' as a concept, is being applied to several contexts. 
:Such as Education. Example, Alan November, in his 2010 work, ''Empowering Students With Technology'',&lt;ref&gt; November, Alan. ''Empowering Students With Technology''; 2010.&lt;/ref&gt; builds on Zuboff's definition: 
&lt;blockquote&gt;
It is a powerful learning tool because it shifts the power and control to students by giving access to new sources of information and relationships. November states, "Students have access to content information that was previously only available in the teacher's edition of the textbook."
&lt;/blockquote&gt;

:Such as [[Communities of Practice]]. Example from corporate world, a recent India based start-up [[CHIASMA Informating Communities]] has embarked on creating communication architecture, using this principle as reflected in their Activity Statement.
&lt;blockquote&gt;
We consult communities on optimization of their knowledge management and informational activities. We are also involved in designing communication architecture for communities. We analyze Information Flow and Group Dynamics of our adopted communities. Our chief role is in the area of facilitating knowledge exchange and network building activities internationally. 
&lt;/blockquote&gt;

==References==
{{Reflist}}

[[Category:Information theory]]</text>
      <sha1>of1qd5yq3t2lh50gxahb9lj099es3zn</sha1>
    </revision>
  </page>
  <page>
    <title>Integration by parts operator</title>
    <ns>0</ns>
    <id>13653437</id>
    <revision>
      <id>753384014</id>
      <parentid>635067143</parentid>
      <timestamp>2016-12-06T21:06:46Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed [[Category:Stochastic processes]]; added [[Category:Stochastic calculus]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4446">{{no footnotes|date=November 2014}}
In [[mathematics]], an '''integration by parts operator''' is a [[linear operator]] used to formulate [[integration by parts]] formulae; the most interesting examples of integration by parts operators occur in infinite-dimensional settings and find uses in [[stochastic analysis]] and its applications.

==Definition==

Let ''E'' be a [[Banach space]] such that both ''E'' and its [[continuous dual space]] ''E''&lt;sup&gt;∗&lt;/sup&gt; are [[separable space]]s; let ''&amp;mu;'' be a [[Borel measure]] on ''E''.  Let ''S'' be any (fixed) [[subset]] of the class of functions defined on ''E''.  A linear operator ''A''&amp;nbsp;:&amp;nbsp;''S''&amp;nbsp;→&amp;nbsp;''L''&lt;sup&gt;2&lt;/sup&gt;(''E'',&amp;nbsp;''&amp;mu;'';&amp;nbsp;'''R''') is said to be an '''integration by parts operator''' for ''&amp;mu;'' if

:&lt;math&gt;\int_{E} \mathrm{D} \varphi(x) h(x) \, \mathrm{d} \mu(x) = \int_{E} \varphi(x) (A h)(x) \, \mathrm{d} \mu(x)&lt;/math&gt;

for every [[smooth function|''C''&lt;sup&gt;1&lt;/sup&gt; function]] ''&amp;phi;''&amp;nbsp;:&amp;nbsp;''E''&amp;nbsp;→&amp;nbsp;'''R''' and all ''h''&amp;nbsp;∈&amp;nbsp;''S'' for which either side of the above equality makes sense.  In the above, D''&amp;phi;''(''x'') denotes the [[Fréchet derivative]] of ''&amp;phi;'' at ''x''.

==Examples==

* Consider an [[abstract Wiener space]] ''i''&amp;nbsp;:&amp;nbsp;''H''&amp;nbsp;→&amp;nbsp;''E'' with abstract Wiener measure ''&amp;gamma;''.  Take ''S'' to be the set of all ''C''&lt;sup&gt;1&lt;/sup&gt; functions from ''E'' into ''E''&lt;sup&gt;∗&lt;/sup&gt;; ''E''&lt;sup&gt;∗&lt;/sup&gt; can be thought of as a subspace of ''E'' in view of the inclusions

::&lt;math&gt;E^{*} \xrightarrow{i^{*}} H^{*} \cong H \xrightarrow{i} E.&lt;/math&gt;

:For ''h''&amp;nbsp;&amp;isin;&amp;nbsp;''S'', define ''Ah'' by

::&lt;math&gt;(A h)(x) = h(x) x - \mathrm{trace}_{H} \mathrm{D} h(x).&lt;/math&gt;

:This operator ''A'' is an integration by parts operator, also known as the [[divergence]] operator; a proof can be found in Elworthy (1974).

* The [[classical Wiener space]] ''C''&lt;sub&gt;0&lt;/sub&gt; of [[continuous function|continuous paths]] in '''R'''&lt;sup&gt;''n''&lt;/sup&gt; starting at zero and defined on the [[interval (mathematics)|unit interval]] [0,&amp;nbsp;1] has another integration by parts operator.  Let ''S'' be the collection

::&lt;math&gt;S = \left\{ \left. h \colon C_{0} \to L_{0}^{2, 1} \right| h \mbox{ is bounded and non-anticipating} \right\},&lt;/math&gt;

:i.e., all [[bounded function|bounded]], [[adapted process|adapted]] processes with [[absolutely continuous]] sample paths.  Let ''&amp;phi;''&amp;nbsp;:&amp;nbsp;''C''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;&amp;rarr;&amp;nbsp;'''R''' be any ''C''&lt;sup&gt;1&lt;/sup&gt; function such that both ''&amp;phi;'' and D''&amp;phi;'' are bounded.  For ''h''&amp;nbsp;&amp;isin;&amp;nbsp;''S'' and ''&amp;lambda;''&amp;nbsp;&amp;isin;&amp;nbsp;'''R''', the [[Girsanov theorem]] implies that

::&lt;math&gt;\int_{C_{0}} \varphi (x + \lambda h(x)) \, \mathrm{d} \gamma(x) = \int_{C_{0}} \varphi(x) \exp \left( \lambda \int_{0}^{1} \dot{h}_{s} \cdot \mathrm{d} x_{s} - \frac{\lambda^{2}}{2} \int_{0}^{1} | \dot{h}_{s} |^{2} \, \mathrm{d} s \right) \, \mathrm{d} \gamma(x).&lt;/math&gt;

:Differentiating with respect to ''&amp;lambda;'' and setting ''&amp;lambda;''&amp;nbsp;=&amp;nbsp;0 gives

::&lt;math&gt;\int_{C_{0}} \mathrm{D} \varphi(x) h(x) \, \mathrm{d} \gamma(x) = \int_{C_{0}} \varphi(x) (A h) (x) \, \mathrm{d} \gamma(x),&lt;/math&gt;

:where (''Ah'')(''x'') is the [[Itō integral]]

::&lt;math&gt;\int_{0}^{1} \dot{h}_{s} \cdot \mathrm{d} x_{s}.&lt;/math&gt;

:The same relation holds for more general ''&amp;phi;'' by an approximation argument; thus, the Itō integral is an integration by parts operator and can be seen as an infinite-dimensional divergence operator.  This is the same result as the [[Clark-Ocone theorem#Integration by parts on Wiener space|integration by parts formula derived from the Clark-Ocone theorem]].

==References==

* {{cite book
| last = Bell
| first = Denis R.
| title = The Malliavin calculus
| publisher = Dover Publications Inc.
| location = Mineola, NY
| year = 2006
| pages = x+113
| isbn = 0-486-44994-7
}} {{MathSciNet|id=2250060}} (See section 5.3)
* {{cite book
| last = Elworthy
| first =  K. David
| chapter = Gaussian measures on Banach spaces and manifolds
| title = Global analysis and its applications (Lectures, Internat. Sem. Course, Internat. Centre Theoret. Phys., Trieste, 1972), Vol. II
| pages = 151&amp;ndash;166
| publisher = Internat. Atomic Energy Agency
| location = Vienna
| year = 1974
}} {{MathSciNet|id=0464297}}

[[Category:Integral calculus]]
[[Category:Measure theory]]
[[Category:Operator theory]]
[[Category:Stochastic calculus]]</text>
      <sha1>92v7di5n6qn34x017c3ln8rahaub54f</sha1>
    </revision>
  </page>
  <page>
    <title>Kolmogorov's zero–one law</title>
    <ns>0</ns>
    <id>191797</id>
    <revision>
      <id>831699958</id>
      <parentid>814984192</parentid>
      <timestamp>2018-03-21T20:51:28Z</timestamp>
      <contributor>
        <username>Wgxli</username>
        <id>29981670</id>
      </contributor>
      <comment>Intuitive explanation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4548">{{Redirect|Tail event|"tail events" meaning "rare events"|fat tail}}

In [[probability theory]], '''Kolmogorov's zero–one law''', named in honor of [[Andrey Nikolaevich Kolmogorov]], specifies that a certain type of [[Event (probability theory)|event]], called a ''tail event'', will either [[almost surely]] happen or almost surely not happen; that is, the [[probability]] of such an event occurring is zero or one.

Tail events are defined in terms of infinite [[sequence]]s of [[random variable]]s. Suppose

:&lt;math&gt;X_1,X_2,X_3,\dots&lt;/math&gt;

is an infinite sequence of [[statistical independence|independent]] random variables (not necessarily identically distributed). Let &lt;math&gt;\mathcal{F}&lt;/math&gt; be the [[sigma-algebra|&amp;sigma;-algebra]] generated by the &lt;math&gt;X_i&lt;/math&gt;. Then, a '''tail event''' &lt;math&gt;F \in \mathcal{F}&lt;/math&gt; is an event which is [[statistical independence|probabilistically independent]] of each finite subset of these random variables. (Note: &lt;math&gt;F&lt;/math&gt; belonging to &lt;math&gt;\mathcal{F}&lt;/math&gt; implies that membership in &lt;math&gt;F&lt;/math&gt; is uniquely determined by the values of the &lt;math&gt;X_i&lt;/math&gt; but the latter condition is strictly weaker and does not suffice to prove the zero-one law.) For example, the event that the sequence converges, and the event that its sum converges are both tail events.  In an infinite sequence of coin-tosses, a sequence of 100 consecutive heads occurring infinitely many times is a tail event.

Intuitively, tail events are precisely those events whose occurrence can still be determined if an arbitrarily large but finite initial segment of the &lt;math&gt;X_i&lt;/math&gt; are removed.

In many situations, it can be easy to apply Kolmogorov's zero–one law to show that some event has probability 0 or 1, but surprisingly hard to determine ''which'' of these two extreme values is the correct one.

== Formulation ==
A more general statement of Kolmogorov's zero–one law holds for sequences of independent &amp;sigma;-algebras. Let (&amp;Omega;,''F'',''P'') be a [[probability space]] and let ''F''&lt;sub&gt;''n''&lt;/sub&gt; be a sequence of mutually independent &amp;sigma;-algebras contained in ''F''. Let
:&lt;math&gt;G_n=\sigma\bigg(\bigcup_{k=n}^\infty F_k\bigg)&lt;/math&gt;
be the smallest &amp;sigma;-algebra containing ''F''&lt;sub&gt;''n''&lt;/sub&gt;, ''F''&lt;sub&gt;''n''+1&lt;/sub&gt;, &amp;hellip;. Then Kolmogorov's zero–one law asserts that for any event
:&lt;math&gt;F\in \bigcap_{n=1}^\infty G_n&lt;/math&gt;
one has either ''P''(''F'') = 0 or 1.

The statement of the law in terms of random variables is obtained from the latter by taking each ''F''&lt;sub&gt;''n''&lt;/sub&gt; to be the &amp;sigma;-algebra generated by the random variable ''X''&lt;sub&gt;''n''&lt;/sub&gt;. A tail event is then by definition an event which is measurable with respect to the &amp;sigma;-algebra generated by all ''X''&lt;sub&gt;''n''&lt;/sub&gt;, but which is independent of any finite number of ''X''&lt;sub&gt;''n''&lt;/sub&gt;. That is, a tail event is precisely an element of the intersection &lt;math&gt;\textstyle{\bigcap_{n=1}^\infty G_n}&lt;/math&gt;.

==Examples==
An [[invertible]] [[measure-preserving transformation]] on a [[standard probability space]] that obeys the 0-1 law is called a [[Kolmogorov automorphism]].{{what|reason=This makes little sense. See talk.|date=December 2015}} All [[Bernoulli automorphism]]s are Kolmogorov automorphisms but not ''vice versa''.

==See also==
* [[Borel–Cantelli lemma]]
* [[Hewitt–Savage zero–one law]]
* [[Lévy's zero–one law]]
* [[Long tail]]
* [[Tail risk]]

==References==
*{{Cite book | last1=Stroock | first1=Daniel | title=Probability theory: An analytic view | publisher=[[Cambridge University Press]] | edition=revised | isbn=978-0-521-66349-6 | year=1999}}.
*{{Cite book | first1 = Zdzislaw | last1 = Brzezniak | first2 = Thomasz | last2 = Zastawniak | year = 2000 | title = Basic Stochastic Processes | publisher = [[Springer Science+Business Media|Springer]] | isbn = 3-540-76175-6}}
*{{Cite book | last1=Rosenthal | first1=Jeffrey S. | title=A first look at rigorous probability theory | publisher=World Scientific Publishing Co. Pte. Ltd. | location=Hackensack, NJ | isbn=978-981-270-371-2 | year=2006 | page=37}}

==External links==
* [https://web.archive.org/web/20050115091525/http://kolmogorov.com/ The Legacy of Andrei Nikolaevich Kolmogorov] Curriculum Vitae and Biography. Kolmogorov School. Ph.D. students and descendants of A. N. Kolmogorov. A. N. Kolmogorov works, books, papers, articles. Photographs and Portraits of A. N. Kolmogorov.

{{DEFAULTSORT:Kolmogorov's zero-one law}}
[[Category:Probability theorems]]
[[Category:Covering lemmas]]</text>
      <sha1>22as6skjtpjceogift004jc8aojxlcr</sha1>
    </revision>
  </page>
  <page>
    <title>Linear system</title>
    <ns>0</ns>
    <id>722503</id>
    <revision>
      <id>860331158</id>
      <parentid>860331152</parentid>
      <timestamp>2018-09-19T22:53:03Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/Peytiepal26|Peytiepal26]] to version by D.Lazard. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3479695) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6662">{{About|linear systems of systems theory|linear systems of equations|System of linear equations|the concept in algebraic geometry|Linear system of divisors|the system of infantry tactics|Line (formation)}}
{{Unreferenced|date=December 2009}}
A '''linear system''' is a [[mathematical model]] of a [[system]] based on the use of a [[linear operator]].
Linear systems typically exhibit features and properties that are much simpler than the [[nonlinear]] case.
As a mathematical abstraction or idealization, linear systems find important applications in [[automatic control]] theory, [[signal processing]], and [[telecommunications]]. For example, the propagation medium for wireless communication systems can often be
modeled by linear systems.

==Definition==
A general [[deterministic system (mathematics)|deterministic system]] can be described by an operator, &lt;math&gt;H&lt;/math&gt;, that maps an input, &lt;math&gt;x(t)&lt;/math&gt;, as a function of &lt;math&gt;t&lt;/math&gt; to an output, &lt;math&gt;y(t)&lt;/math&gt;, a type of [[Black box (systems)|black box]] description.  Linear systems satisfy the property of [[Superposition principle|superposition]]. Given two valid inputs 
:&lt;math&gt;x_1(t) \,&lt;/math&gt;
:&lt;math&gt;x_2(t) \,&lt;/math&gt;
as well as their respective outputs
:&lt;math&gt;y_1(t) = H \left \{ x_1(t) \right \} &lt;/math&gt;
:&lt;math&gt;y_2(t) = H \left \{ x_2(t) \right \} &lt;/math&gt;
then a linear system must satisfy
:&lt;math&gt;\alpha y_1(t) + \beta y_2(t) = H \left \{ \alpha x_1(t) + \beta x_2(t) \right \} &lt;/math&gt;
for any [[scalar (mathematics)|scalar]] values &lt;math&gt;\alpha \,&lt;/math&gt; and &lt;math&gt;\beta \,&lt;/math&gt;.
&lt;!-- Insert picture depicting the superposition and scaling properties --&gt;

The system is then defined by the equation &lt;math&gt;H(x(t)) = y(t)&lt;/math&gt;, where &lt;math&gt;y(t)&lt;/math&gt; is some arbitrary function of time, and &lt;math&gt;x(t)&lt;/math&gt; is the system state.  Given &lt;math&gt;y(t)&lt;/math&gt; and &lt;math&gt;H&lt;/math&gt;, &lt;math&gt;x(t)&lt;/math&gt; can be solved for.  For example, a simple harmonic oscillator obeys the differential equation:
:&lt;math&gt;m \frac{d^2(x)}{dt^2} = -kx&lt;/math&gt;.

If
:&lt;math&gt;H(x(t)) = m \frac{d^2(x(t))}{dt^2} + kx(t)&lt;/math&gt;,
then &lt;math&gt;H&lt;/math&gt; is a linear operator.  Letting &lt;math&gt;y(t) = 0&lt;/math&gt;, we can rewrite the differential equation as &lt;math&gt;H(x(t)) = y(t)&lt;/math&gt;, which shows that a simple harmonic oscillator is a linear system.

The behavior of the resulting system subjected to a complex input can be described as a sum of responses to simpler inputs.  In nonlinear systems, there is no such relation.  
This mathematical property makes the solution of modelling equations simpler than many nonlinear systems.
For [[time-invariant system|time-invariant]] systems this is the basis of the [[impulse response]] or the [[frequency response]] methods (see [[LTI system theory]]), which describe a general input function &lt;math&gt;x(t)&lt;/math&gt; in terms of unit [[Dirac's delta function|impulses]] or [[frequency components]].  

Typical [[differential equation]]s of linear [[time-invariant system|time-invariant]] systems are well adapted to analysis using the [[Laplace transform]] in the [[continuous function|continuous]] case, and the [[Z-transform]] in the [[discrete mathematics|discrete]] case (especially in computer implementations).

Another perspective is that solutions to linear systems comprise a system of [[function (mathematics)|function]]s which act like [[vector (geometric)|vector]]s in the geometric sense.

A common use of linear models is to describe a nonlinear system by [[linearization]].  This is usually done for mathematical convenience.

==Time-varying impulse response==
The '''time-varying impulse response''' ''h''(''t''&lt;sub&gt;2&lt;/sub&gt;,''t''&lt;sub&gt;1&lt;/sub&gt;) of a linear system is defined as the response of the system at time ''t'' = ''t''&lt;sub&gt;2&lt;/sub&gt; to a single [[impulse function|impulse]] applied at time ''t'' = ''t''&lt;sub&gt;1&lt;/sub&gt;.  In other words, if the input ''x''(''t'') to a linear system is 

:&lt;math&gt;x(t) = \delta(t-t_1) \,&lt;/math&gt;

where δ(''t'') represents the [[Dirac delta function]], and the corresponding response ''y''(''t'') of the system is

:&lt;math&gt;y(t) |_{t=t_2} = h(t_2,t_1) \,&lt;/math&gt;

then the function  ''h''(''t''&lt;sub&gt;2&lt;/sub&gt;,''t''&lt;sub&gt;1&lt;/sub&gt;) is the time-varying impulse response of the system. Since the system cannot respond before the input is applied the following '''causality condition''' must be satisfied:

:&lt;math&gt; h(t_2,t_1)=0, t_2&lt;t_1 &lt;/math&gt;

==The convolution integral==

The output of any general continuous-time linear system is related to the input by an integral which may be written over a doubly infinite range because of the causality condition:

:&lt;math&gt; y(t) = \int_{-\infty}^{t}  h(t,t') x(t')dt' = \int_{-\infty}^{\infty}  h(t,t') x(t') dt' &lt;/math&gt;

If the properties of the system do not depend on the time at which it is operated then it is said to be '''time-invariant''' and h() is a function only of the time difference τ = t-t' which is zero for τ&lt;0 (namely t&lt;t'). By redefinition of h() it is then possible to write the input-output relation equivalently in any of the ways,

:&lt;math&gt; y(t) = \int_{-\infty}^{t}  h(t-t') x(t') dt' = \int_{-\infty}^{\infty}  h(t-t') x(t') dt' = \int_{-\infty}^{\infty}  h(\tau) x(t-\tau) d \tau  = \int_{0}^{\infty}  h(\tau) x(t-\tau) d \tau &lt;/math&gt;

Linear time-invariant systems are most commonly characterized by the Laplace transform of the impulse response function called  the ''transfer function'' which is:

:&lt;math&gt;H(s) =\int_0^\infty  h(t) e^{-st}\, dt.&lt;/math&gt;

In applications this is usually a rational algebraic function of s. Because h(t) is zero for negative t, the integral may  equally be written over the doubly infinite range and putting s = iω follows the formula for the ''frequency response function'':

:&lt;math&gt; H(i\omega) = \int_{-\infty}^{\infty}  h(t) e^{-i\omega t} dt &lt;/math&gt;

==Discrete time systems==
The output of any discrete time linear system is related to the input by the time-varying convolution sum:

:&lt;math&gt; y[n] = \sum_{m =-\infty}^{n} { h[n,m] x[m] }  = \sum_{m =-\infty}^{\infty} { h[n,m] x[m] }&lt;/math&gt;

or equivalently for a time-invariant system on redefining h(),

:&lt;math&gt; y[n] = \sum_{k =0}^{\infty} { h[k] x[n-k] } = \sum_{k =-\infty}^{\infty} { h[k] x[n-k] }&lt;/math&gt;

where

:&lt;math&gt; k = n-m \, &lt;/math&gt;

represents the lag time between the stimulus at time ''m'' and the response at time ''n''.

==See also==
*[[Linear system of divisors]] in [[algebraic geometry]]
*[[Shift invariant system]]
*[[LTI system theory]]
*[[Nonlinear system]]
*[[System analysis]]
*[[System of linear equations]]

{{DEFAULTSORT:Linear System}}
[[Category:Systems theory]]
[[Category:Dynamical systems]]
[[Category:Mathematical modeling]]
[[Category:Concepts in physics]]</text>
      <sha1>t3h8jr7oe7ny12cao9ik0d5t5r5gwmg</sha1>
    </revision>
  </page>
  <page>
    <title>Loop braid group</title>
    <ns>0</ns>
    <id>4543610</id>
    <revision>
      <id>866423231</id>
      <parentid>825576603</parentid>
      <timestamp>2018-10-30T06:49:30Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Alissa Crans]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2645">The '''loop braid group''' is a mathematical [[group (mathematics)|group structure]] that is used in some models of [[theoretical physics]] to model the exchange of [[Elementary particle|particle]]s with loop-like topologies  within three dimensions of space and time.

The basic operations which generate a loop braid group for ''n'' loops are exchanges of two adjacent loops, and passing one adjacent loop through another.  The topology forces these generators to satisfy some relations, which determine the group.

To be precise, the loop braid group on ''n'' loops is defined as the motion group of n disjoint circles embedded in a compact three-dimensional "box" diffeomorphic to the three-dimensional disk.  A motion is a loop in the configuration space, which consists of all possible ways of embedding ''n'' circles into the 3-disk.  This becomes a group in the same way as loops in any space can be made into a group; first, we define equivalence classes of loops by letting paths g and h be equivalent iff they are related by a (smooth) homotopy, and then we define a group operation on the equivalence classes by concatenation of paths.  In his 1962 [[Ph.D.]] thesis, David M. Dahm was able to show that there is an injective homomorphism from this group into the automorphism group of the free group on n generators, so it is natural to identify the group with this subgroup of the automorphism group.&lt;ref&gt;{{citation
 | last = Goldsmith | first = Deborah L.
 | issue = 1
 | journal = The Michigan Mathematical Journal
 | mr = 600411
 | pages = 3–17
 | title = The theory of motion groups
 | url = http://projecteuclid.org/euclid.mmj/1029002454
 | volume = 28
 | year = 1981
 | doi=10.1307/mmj/1029002454}}.&lt;/ref&gt;  One may also show that the loop braid group is isomorphic to the welded braid group, as is done for example in a paper by [[John C. Baez]], Derek Wise, and [[Alissa Crans]], which also gives some presentations of the loop braid group using the work of Xiao-Song Lin.&lt;ref&gt;{{citation
 | last1 = Baez | first1 = John C. | author1-link = John C. Baez
 | last2 = Wise | first2 = Derek K.
 | last3 = Crans | first3 = Alissa S. | author3-link = Alissa Crans
 | arxiv = gr-qc/0603085
 | issue = 5
 | journal = Advances in Theoretical and Mathematical Physics
 | mr = 2362007
 | pages = 707–749
 | title = Exotic statistics for strings in 4D ''BF'' theory
 | url = http://projecteuclid.org/euclid.atmp/1197555591
 | volume = 11
 | year = 2007|bibcode = 2006gr.qc.....3085B | doi=10.4310/atmp.2007.v11.n5.a1}}.&lt;/ref&gt;

== See also ==
* [[Braid group]]

==References==
{{reflist}}

[[Category:Braid groups]]


{{topology-stub}}</text>
      <sha1>ttd2uq03j8msccbxsqp58bmkxi8xgur</sha1>
    </revision>
  </page>
  <page>
    <title>Magic graph</title>
    <ns>0</ns>
    <id>4351071</id>
    <revision>
      <id>870184325</id>
      <parentid>870180961</parentid>
      <timestamp>2018-11-23T01:04:39Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* Magic squares */ better explanation not just that they are different but how</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2760">A '''magic graph''' is a [[Graph (discrete mathematics)|graph]] whose edges are labelled by positive integers, so that the sum over the edges incident with any vertex is the same, independent of the choice of vertex; or it is a graph that has such a labelling.  If the integers are the first ''q'' positive integers, where ''q'' is the number of edges, the graph and the labelling are called '''supermagic'''.

A graph is '''vertex-magic''' if its vertices can be labelled so that the sum on any edge is the same.  It is '''total magic''' if its edges and vertices can be labelled so that the vertex label plus the sum of labels on edges incident with that vertex is a constant.

There are a great many variations on the concept of magic labelling of a graph.  There is much variation in terminology as well.  The definitions here are perhaps the most common.

Comprehensive references for magic labellings and magic graphs are Gallian (1998), Wallis (2001), and Marr and Wallis (2013).

==Magic squares==
[[File:4x4_magic_square_hierarchy.svg|thumb|upright|[[Euler diagram]] of requirements of some types of 4&amp;times;4 magic squares. Cells of the same colour sum to the magic constant.
* In 4&amp;times;4 most-perfect magic squares, any 2 cells that are 2 cells diagonally apart (including wraparound) sum to half the magic constant, hence any 2 such pairs also sum to the magic constant.]]
A '''semimagic square''' is an ''n'' &amp;times; ''n'' square with the numbers 1 to ''n''&lt;sup&gt;2&lt;/sup&gt; in its cells, in which the sum of each row and column is the same.  A semimagic square is equivalent to a magic labelling of the complete bipartite graph ''K&lt;sub&gt;n,n&lt;/sub&gt;''.  The two vertex sets of ''K&lt;sub&gt;n,n&lt;/sub&gt;'' correspond to the rows and the columns of the square, respectively, and the label on an edge ''r&lt;sub&gt;i&lt;/sub&gt;s&lt;sub&gt;j&lt;/sub&gt;'' is the value in row ''i'', column ''j'' of the semimagic square.  

The definition of semimagic squares differs from the definition of [[magic square]]s in the treatment of the diagonals of the square. Magic squares are required to have diagonals with the same sum as the row and column sums, but for semimagic squares this is not required. Thus, every magic square is semimagic, but not vice versa.

==References==

* W. D. Wallis (2001), ''Magic Graphs''. Birkhäuser Boston, Boston, Mass.  {{isbn|0-8176-4252-8}}
* [[Alison Marr|Alison M. Marr]] and W. D. Wallis (2013), ''Magic Graphs''. Second edition. Birkhäuser/Springer, New York.  {{isbn|978-0-8176-8390-0}}; 978-0-8176-8391-7
* Joseph A. Gallian (1998), A dynamic survey of graph labeling. ''Electronic Journal of Combinatorics'', vol. 5, Dynamic Survey 6.  Updated several times.

[[Category:Graph theory]]
[[Category:Magic squares]]


{{Magic polygons
}}{{combin-stub}}</text>
      <sha1>57mgcr5pbc8c7t0y8c9n0jb0ydfw2w1</sha1>
    </revision>
  </page>
  <page>
    <title>Martin Hairer</title>
    <ns>0</ns>
    <id>26920158</id>
    <revision>
      <id>866206513</id>
      <parentid>864851836</parentid>
      <timestamp>2018-10-28T23:36:34Z</timestamp>
      <contributor>
        <username>Aegiscake70a</username>
        <id>31266238</id>
      </contributor>
      <comment>/* Education */ Corrected month he earned his BSc in Mathematics  and Msc in Physics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16886">{{Use dmy dates|date=August 2014}}
{{Infobox scientist
| name = Martin Hairer
| honorific_suffix = {{post-nominals|country=GBR|KBE|FRS|size=100%}}
| image = Professor Martin Hairer FRS.jpg
| caption = Martin Hairer at the [[Royal Society]] admissions day in London, July 2014
| birth_date = {{Birth date and age|df=yes|1975|11|14}}
| birth_place = [[Geneva]], [[Switzerland]]
| residence = [[London]]
| citizenship = [[Austrians|Austrian]]
| alma_mater = [[University of Geneva]]
| thesis_title = Comportement Asymptotique d'Équations à Dérivées Partielles Stochastiques
| thesis_url = http://www.hairer.org/papers/these.pdf
| thesis_year = 2001
| doctoral_advisor = [[Jean-Pierre Eckmann]]&lt;ref name="mathgene"&gt;{{MathGenealogy|56119}}&lt;/ref&gt;
| doctoral_students = 
| known_for = 
| website = {{URL|hairer.org}}
| spouse = {{marriage|Xue-Mei Li|2003}}&lt;ref name=whoswho/&gt;&lt;ref name=spouse/&gt;
| field = {{Plainlist|
* [[Probability theory]]&lt;ref name="googlescholar"/&gt;
* [[Analysis]]&lt;ref name="googlescholar"&gt;{{Google scholar id}}&lt;/ref&gt;}}
| work_institution = [[Imperial College London]]&lt;br&gt;[[University of Warwick]]&lt;br&gt;[[New York University]]&lt;ref name=whoswho/&gt;
| prizes = {{Plainlist|
* [[Whitehead Prize]] (2008)
* [[Philip Leverhulme Prize]] (2008)
* [[Royal Society Wolfson Research Merit Award|Wolfson Research Merit Award]] (2009)
* [[Fermat Prize]] (2013)
* [[Fröhlich Prize]] (2014)
* [[Fields Medal]] (2014)}}
| education = College Claparede, Geneva{{fact|date=September 2018}}
}}

'''Martin Hairer''' {{post-nominals|country=GBR|KBE|FRS}} (born 14 November 1975 in [[Geneva]], [[Switzerland]])&lt;ref name=whoswho&gt;{{Who's Who | surname = Hairer| othernames = Prof. Martin | id = U282027 | year = 2016 |author=Anon|doi=10.1093/ww/9780199540884.013.U282027| edition = online [[Oxford University Press]]|location=Oxford}} {{subscription required}}&lt;/ref&gt; is an Austrian mathematician working in the field of [[stochastic analysis]], in particular [[stochastic partial differential equation]]s. He  is Professor of Mathematics at [[Imperial College London]], having previously held appointments at the [[University of Warwick]] and the [[Courant Institute]] of [[New York University]].&lt;ref name=wmi/&gt;&lt;ref&gt;{{Cite journal | doi = 10.1007/s002200100424| title = Uniqueness of the Invariant Measure¶for a Stochastic PDE Driven by Degenerate Noise| journal = Communications in Mathematical Physics| volume = 219| issue = 3| pages = 523| year = 2001| last1 = Eckmann | first1 = J. -P. | last2 = Hairer | first2 = M.| arxiv = nlin/0009028| bibcode = 2001CMaPh.219..523E}}&lt;/ref&gt;&lt;ref name="scopus"&gt;{{Scopus|id=6602190457}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | doi = 10.4007/annals.2006.164.993| title = Ergodicity of the 2D Navier–Stokes equations with degenerate stochastic forcing| journal = Annals of Mathematics| volume = 164| issue = 3| pages = 993| year = 2006| last1 = Hairer | first1 = M. | last2 = Mattingly | first2 = J. | arxiv = math/0406087}}&lt;/ref&gt; In 2014 he was awarded the [[Fields Medal]]&lt;ref name=imu&gt;{{cite web|url=http://www.mathunion.org/general/prizes/2014/|title=IMU Prizes 2014|date=12 August 2014|accessdate=12 August 2014}}&lt;/ref&gt;, one of the highest honours a mathematician can achieve.&lt;ref&gt;[http://www.snf.ch/SiteCollectionDocuments/horizonte/Horizonte_gesamt/Horizonte_103_E.pdf Daniel Saraga: ''The equation Tamer''], in: ''Horizons'', [[Swiss National Science Foundation]] No. 103, p.&amp;nbsp;26–7&lt;/ref&gt;

==Education==
Hairer attended the College Claparede Geneva where he received his high school diploma in 1994 , followed by the [[University of Geneva]], where he obtained his [[Bachelor of Science]] degree in Mathematics in July 1998, [[Master of Science]] in Physics in October 1998 and PhD in Physics under the supervision of [[Jean-Pierre Eckmann]] in November 2001.&lt;ref name="mathgene"/&gt;&lt;ref&gt;{{cite web |title=Martin Hairer CV |url=http://www.hairer.org/cv.pdf}}&lt;/ref&gt;

==Research and career==
Hairer is one of the world's foremost leaders in the field of [[stochastic partial differential equation]]s in particular, and in stochastic analysis and stochastic dynamics in general.&lt;ref name="royal"/&gt;  By bringing new ideas to the subject he made fundamental advances in many important directions such as the study of variants of [[Hörmander's condition|Hörmander's theorem]], systematisation of the construction of [[Lyapunov functions]] for stochastic systems, development of a general theory of [[ergodicity]] for non-[[Markov process|Markovian systems]], [[Multiple-scale analysis|multiscale analysis techniques]], [[Asymptotic homogenization|theory of homogenisation]], [[Transition path sampling|theory of path sampling]] and, most recently, theory of [[rough path]]s and the newly introduced theory of [[regularity structure]]s.&lt;ref name="royal"/&gt; 

Under the name HairerSoft, he develops [[Macintosh]] software.&lt;ref&gt;{{cite web|url=http://www.hairersoft.com/|title=Audio editor / sound and voice recorder for Mac OS X|publisher=HairerSoft|accessdate=13 March 2014}}&lt;/ref&gt;

===Affiliations===
[[File:Four_Fields_medallists_plus_epsilon.jpg|thumb|Four Fields medallists left to right ([[:en:Artur Avila|Artur Avila]], Martin Hairer (at back), [[:en:Maryam Mirzakhani|Maryam Mirzakhani]], with Maryam's daughter Anahita) and [[Manjul Bhargava]] at the ICM 2014 in Seoul]]
{{div col|colwidth=35em}}
*[[Regius Professor of Mathematics]], [[University of Warwick]] (2014)&lt;ref name="wmi"&gt;{{cite web|author=Warwick Mathematics Institute|title=Professor Martin Hairer, FRS|url=http://www2.warwick.ac.uk/fac/sci/maths/people/staff/martin_hairer/|accessdate=6 May 2014}}&lt;/ref&gt;
*Member of the scientific steering committee of ETHZ-ITS (since 2013)&lt;ref&gt;{{cite web|url=http://www.eth-its.ethz.ch/about-us/organisation.html |title=Organisation of the Institute for Theoretical Studies – Institute for Theoretical Studies &amp;#124; ETH Zurich |publisher=Eth-its.ethz.ch |date= |accessdate=2014-08-14}}&lt;/ref&gt;
*[[Institut Henri Poincaré]], member of scientific steering committee (since 2012)&lt;ref&gt;{{cite web|author=Institut Henri Poincaré|title=Members' directory|url=http://www.ihp.fr/en/directory/program|accessdate=6 May 2014}}&lt;/ref&gt;
*[[Mathematical Research Institute of Oberwolfach]], member of steering committee (since 2013)&lt;ref&gt;{{cite web|author=Mathematisches Forschungsinstitut Oberwolfach|title=Scientific Committee|url=http://www.mfo.de/about-the-institute/structure/scientific-committee|accessdate=6 May 2014}}&lt;/ref&gt;
*Editor, ''[[Probability Theory and Related Fields]]''&lt;ref&gt;{{cite web|last=Springer|title=Probability Theory and Related Fields Probability Theory and Related Fields – Editorial Board|url=https://www.springer.com/mathematics/probability/journal/440?detailsPage=editorialBoard|accessdate=6 May 2014}}&lt;/ref&gt;
*Editor, ''Nonlinear Differential Equations and Applications''&lt;ref&gt;{{cite web|last=Springer|title=Nonlinear Differential Equations and Applications – Editorial Board|url=https://www.springer.com/birkhauser/mathematics/journal/30?detailsPage=editorialBoard|accessdate=6 May 2014}}&lt;/ref&gt;
*Editor, ''[[Annales Henri Poincaré]]'' Ser. B&lt;ref&gt;{{cite web|author=Institute of Mathematical Statistics|title=Annales de l'Institut Henri Poincaré|url=http://imstat.org/aihp/|accessdate=6 May 2014}}&lt;/ref&gt;
*Editor, ''Electronic Journal of Probability''&lt;ref&gt;{{cite web|author=Electronic Journal of Probability|title=Editorial Team|url=http://ejp.ejpecp.org/about/editorialTeam|accessdate=6 May 2014}}&lt;/ref&gt;
*Editor, ''Stochastic Partial Differential Equations: Analysis and Computations''&lt;ref&gt;{{cite web|last=Springer|title=Stochastic Partial Differential Equations: Analysis and Computations – Editorial Board|url=https://www.springer.com/mathematics/probability/journal/40072?detailsPage=editorialBoard|accessdate=6 May 2014}}&lt;/ref&gt;
*Visiting Professor, [[Paul Sabatier University|Université Paul Sabatier]], Toulouse (December 2006 and February 2014)&lt;ref name="cv"&gt;{{cite web|last=Hairer|first=Martin|title=Curriculum Vitae|url=http://www.hairer.org/cv.pdf|accessdate=6 May 2014}}&lt;/ref&gt;
*Visiting Professor, [[Technical University of Berlin]] (July 2009)&lt;ref name="cv" /&gt;
*Visiting Professor, [[École Normale Supérieure]], Paris (April 2013)&lt;ref name="cv" /&gt;
*Member, [[Institute for Advanced Study]], [[Princeton University|Princeton]] (March – April 2014)&lt;ref name="cv" /&gt;
*Lipschitz Lectures, [[Hausdorff Center for Mathematics]], [[University of Bonn]] (July 2013)&lt;ref&gt;{{cite web|author=Hausdorff Center for Mathematics, University of Bonn|title=Lipschitz Lectures|url=http://www.hcm.uni-bonn.de/lipschitz-hairer/|accessdate=6 May 2014}}&lt;/ref&gt;
*Minerva Lectures, [[Columbia University]] (February 2014)&lt;ref&gt;{{cite web|author=Columbia University|title=Minerva Lectures|url=http://www.math.columbia.edu/department/probability/seminar/minerva.html|accessdate=6 May 2014}}&lt;/ref&gt;
*Euler Lecture, [[Zuse Institute Berlin]] (May 2014)&lt;ref&gt;{{cite web|author=Zuse Institute, Berlin|title=Euler-Vorlesung 2014|url=http://www.zib.de/Euler/2014/index.de.html|accessdate=6 May 2014}}&lt;/ref&gt;
*Medallion Lecture, [[Institute of Mathematical Statistics]] (July 2014)&lt;ref&gt;{{cite web|author=Institute of Mathematical Statistics|title=Awards – Special Lectures Winners|url=http://imstat.org/awards/lectures_winners.htm|accessdate=6 May 2014}}&lt;/ref&gt;
*Lévy Lecture, Conference on Stochastic Processes and their Applications (July 2014)&lt;ref&gt;{{cite web|author=University of Buenos Aires|title=37th Conference on Stochastic Processes and their Applications|url=http://mate.dm.uba.ar/~probab/spa2014/|accessdate=6 May 2014}}&lt;/ref&gt;
*Fields Medal lecture, [[International Congress of Mathematicians]], [[Seoul]] (August 2014)&lt;ref&gt;{{cite web|author=Warwick Mathematics Institute|title=Five Warwick mathematicians to speak at ICM 2014|url=http://www2.warwick.ac.uk/fac/sci/maths/general/news/2013/#icm2014|accessdate=6 May 2014|date=21 October 2013}}&lt;/ref&gt;
*Collingwood Lecture, [[Durham University]] (February 2015)&lt;ref name="hairer.org"&gt;http://hairer.org/cv.pdf&lt;/ref&gt;
*Bernoulli Lecture, [[École polytechnique fédérale de Lausanne]] (May 2015) &lt;ref name="hairer.org"/&gt;
*Leonardo da Vinci Lecture, [[University of Milan]] (October 2015) &lt;ref name="hairer.org"/&gt;
*Kai-Lai Chung Lecture, [[Stanford University]] (November 2015)&lt;ref name="hairer.org"/&gt;
*Michalik Lecture, [[University of Pittsburgh]] (December 2015)&lt;ref name="hairer.org"/&gt;
{{div col end}}

===Awards and honours===
*Advanced [[Research Fellow]]ship, [[Engineering and Physical Sciences Research Council]] (EPSRC) 2006–2011&lt;ref&gt;{{cite web|author=Warwick Mathematics Institute|title=EPSRC Advanced Research Fellowship awarded to Martin Hairer|url=http://www.maths.warwick.ac.uk/general/news/2006.html#hairer|accessdate=6 May 2014|date=29 May 2006}}&lt;/ref&gt;
*Editors' Choice Award, [[Macworld]] (2007)&lt;ref&gt;{{cite web|last=Macworld|title=The 23rd Annual Editors' Choice Awards|url=http://www.macworld.com/article/1131153/eddyawards2007.html?page=3|accessdate=6 May 2014|date=19 December 2007}}&lt;/ref&gt;
*[[Whitehead Prize]], [[London Mathematical Society]] (2008)&lt;ref&gt;{{cite web|author=London Mathematical Society|title=List of LMS prize winners: Whitehead Prize|url=http://www.lms.ac.uk/prizes/list-lms-prize-winners#Whitehead_Prize|accessdate=6 May 2014}}&lt;/ref&gt;&lt;ref&gt;{{cite web|author=London Mathematical Society|url=http://www.lms.ac.uk/news/2008/PR083Prizes_2008.pdf|title=London Mathematical Society Prizes 2008|date=4 July 2008|accessdate=14 April 2010}}&lt;/ref&gt;&lt;ref&gt;{{cite web|author=Warwick Mathematics Institute|title=Martin Hairer receives LMS Whitehead Prize|url=http://www2.warwick.ac.uk/fac/sci/maths/general/news/2008/#hairerwhitehead|accessdate=6 May 2014|date=6 July 2008}}&lt;/ref&gt;
*[[Philip Leverhulme Prize]], [[Leverhulme Trust]] (2008)&lt;ref&gt;{{cite web|author=Warwick Mathematics Institute|title=Martin Hairer wins Philip Leverhulme Prize|url=http://www2.warwick.ac.uk/fac/sci/maths/general/news/2008/#hairerplp|accessdate=6 May 2014|date=6 November 2008}}&lt;/ref&gt;&lt;ref&gt;{{cite web |url=http://www.leverhulme.ac.uk/files/seealsodocs/231/LEVERHULME%20REPORT%202008.PDF |title=Report of the Leverhulme Trustees 2008 |format=PDF |date= |accessdate=2014-08-14 |deadurl=yes |archiveurl=https://web.archive.org/web/20140421064526/http://www.leverhulme.ac.uk/files/seealsodocs/231/LEVERHULME%20REPORT%202008.PDF |archivedate=21 April 2014 |df=dmy-all }}&lt;/ref&gt;
*[[Royal Society Wolfson Research Merit Award]] (2009){{citation needed|date=April 2017}}
*Leverhulme Research Leadership Award, Leverhulme Trust (2012)&lt;ref&gt;{{cite web|author=Warwick Mathematics Institute|title=Martin Hairer wins Leverhulme Research Leadership Award|url=http://www2.warwick.ac.uk/fac/sci/maths/general/news/2012/|accessdate=6 May 2014|date=27 November 2012}}&lt;/ref&gt;
*[[Fermat Prize]], [[Institut de Mathématiques de Toulouse]] (2013)&lt;ref&gt;{{cite web|author=Institut de Mathématiques de Toulouse|title=Prix Fermat 2013|url=http://www.math.univ-toulouse.fr/spip.php?article489&amp;lang=en|accessdate=6 May 2014|date=6 November 2013}}&lt;/ref&gt;&lt;ref&gt;{{cite web|author=Warwick Mathematics Institute|title=Martin Hairer awarded 2013 Fermat Prize|url=http://www2.warwick.ac.uk/fac/sci/maths/general/news/2013/#hairer-fermat|accessdate=6 May 2014|date=10 November 2013}}&lt;/ref&gt;
*Consolidator grant, [[European Research Council]] (2014)&lt;ref&gt;{{cite web|author=Warwick Mathematics Institute|title=Martin Hairer &amp; José Luis Rodrigo win ERC Consolidator grants|url=http://www2.warwick.ac.uk/fac/sci/maths/general/news/2014/#erc-consolidate|accessdate=6 May 2014|date=4 February 2014}}&lt;/ref&gt;
*Elected [[List of Fellows of the Royal Society elected in 2014|Fellow of the Royal Society (FRS) in 2014]]&lt;ref name="royal"&gt;{{cite web|location=London|url=https://royalsociety.org/people/martin-hairer-11561/|author=Anon|publisher=[[Royal Society]]|year=2014|title=Professor Martin Hairer FRS}} One or more of the preceding sentences incorporates text from the royalsociety.org website where: {{quote|“All text published under the heading 'Biography' on Fellow profile pages is available under [[Creative Commons license|Creative Commons Attribution 4.0 International License]].” --{{Webarchive|url=http://web.archive.org/web/20161111170346/https://royalsociety.org/about-us/terms-conditions-policies/|title=Royal Society Terms, conditions and policies|date=2016-11-11}}}}&lt;/ref&gt;
*[[Fröhlich Prize]], London Mathematical Society (2014)&lt;ref&gt;{{cite web|author=London Mathematical Society|title=List of LMS prize winners: Fröhlich Prize|url=http://www.lms.ac.uk/prizes/list-lms-prize-winners#FRÖHLICH_prize|accessdate=7 July 2014}}&lt;/ref&gt;
*[[Fields Medal]] (2014)&lt;ref name="imu" /&gt;
*Fellow of the [[American Mathematical Society]] (2015)&lt;ref&gt;{{citation|url=http://www.ams.org/profession/ams-fellows/new-fellows|title=2016 Class of the Fellows of the AMS|publisher=[[American Mathematical Society]]|accessdate=2015-11-16}}.&lt;/ref&gt;
*Member of the [[Austrian Academy of Sciences]] (2015)&lt;ref&gt;http://www.oeaw.ac.at/oesterreichische-akademie-der-wissenschaften/die-oeaw/article/oeaw-waehlte-40-neue-mitglieder/&lt;/ref&gt;
*Member of the [[Academy of Sciences Leopoldina]] (2015)&lt;ref&gt;https://idw-online.de/de/news?print=1&amp;id=647829&lt;/ref&gt;
*Honorary [[Knight Commander of the Order of the British Empire]] (2016)&lt;ref&gt;[https://www.gov.uk/government/uploads/system/uploads/attachment_data/file/581724/2016_Honorary_awards_V4.pdf Honorary awards]&lt;/ref&gt;

==Personal life==
Hairer is an Austrian citizen and speaks [[French language|French]], [[German language|German]] and [[English language|English]]; he married the mathematician Li Xue-mei in 2003.&lt;ref name=whoswho/&gt;&lt;ref name=spouse&gt;{{cite web|url=http://www.xuemei.org|website=xuemei.org|first=Li|last=Xue-mei|year=2017|title=Xue-Mei Li: About me}}&lt;/ref&gt; His father is [[Ernst Hairer]], a mathematician at the [[University of Geneva]].

==References==
{{Reflist|30em}}

{{Commons category-inline}}

{{FRS 2014}}

{{Fields medalists}}
{{Authority control}}
{{Portal bar|Mathematics|Biography}}
{{CC-notice|cc=by4|url=https://royalsociety.org/people/martin-hairer-11561}}
{{DEFAULTSORT:Hairer, Martin}}
[[Category:1975 births]]
[[Category:Living people]]
[[Category:20th-century British mathematicians]]
[[Category:21st-century British mathematicians]]
[[Category:Academics of the University of Warwick]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Royal Society]]
[[Category:Royal Society Wolfson Research Merit Award holders]]
[[Category:Honorary Knights Commander of the Order of the British Empire]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Fields Medalists]]
[[Category:Courant Institute of Mathematical Sciences faculty]]
[[Category:Probability theorists]]
[[Category:University of Geneva alumni]]
[[Category:Whitehead Prize winners]]
[[Category:Members of the Austrian Academy of Sciences]]
[[Category:Austrian emigrants to England]]</text>
      <sha1>fbocui8nyheylri9cep35drq0mo6uw8</sha1>
    </revision>
  </page>
  <page>
    <title>Master theorem (analysis of algorithms)</title>
    <ns>0</ns>
    <id>561585</id>
    <revision>
      <id>861403108</id>
      <parentid>861198383</parentid>
      <timestamp>2018-09-27T04:39:25Z</timestamp>
      <contributor>
        <ip>14.139.234.181</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15403">{{for|the result in enumerative combinatorics|MacMahon Master theorem}}
{{for|the result about Mellin transforms|Ramanujan's master theorem}}
In the [[analysis of algorithms]], the '''master theorem for divide-and-conquer recurrences''' provides an [[asymptotic analysis]] (using [[Big O notation]]) for [[recurrence relation]]s of types that occur in the [[Analysis of algorithms|analysis]] of many [[divide and conquer algorithm]]s. The approach was first presented by [[Jon Bentley (computer scientist)|Jon Bentley]], [[Dorothea Haken]], and [[James B. Saxe]] in 1980, where it was described as a "unifying method" for solving such recurrences.&lt;ref&gt;{{citation | last1 = Bentley | first1 = Jon Louis | author1-link = Jon Bentley (computer scientist) | last2 = Haken | first2 = Dorothea | author2-link = Dorothea Blostein | last3 = Saxe | first3 = James B. | author3-link = James B. Saxe | date = September 1980 | doi = 10.1145/1008861.1008865 | issue = 3 | journal = [[ACM SIGACT News]] | pages = 36–44 | title = A general method for solving divide-and-conquer recurrences | volume = 12| url = http://www.dtic.mil/get-tr-doc/pdf?AD=ADA064294 }}&lt;/ref&gt; The name "master theorem" was popularized by the widely used algorithms textbook ''[[Introduction to Algorithms]]'' by [[Thomas H. Cormen|Cormen]], [[Charles E. Leiserson|Leiserson]], [[Ron Rivest|Rivest]], and [[Clifford Stein|Stein]]. 

Not all recurrence relations can be solved with the use of this theorem; its generalizations include the [[Akra–Bazzi method]].

== Introduction ==
Consider a problem that can be solved using a [[recursive algorithm]] such as the following:

  '''procedure''' p( input ''x'' of size ''n'' ):
    '''if''' ''n'' &lt; some constant ''k'':
      Solve ''x'' directly without recursion
    '''else''':
      Create ''a'' subproblems of ''x'', each having size ''n''/''b''
      Call procedure p recursively on each subproblem
      Combine the results from the subproblems

The above algorithm divides the problem into a number of subproblems recursively, each subproblem being of size {{math|''n''/''b''}}. Its [[call tree]] has a node for each recursive call, with the children of that node being the other calls made from that call. The leaves of the tree are the base cases of the recursion, the subproblems (of size less than ''k'') that do not recurse. The above example would have {{mvar|a}} child nodes at each non-leaf node. Each node does an amount of work that corresponds to the size of the sub problem {{mvar|n}} passed to that instance of the recursive call and given by &lt;math&gt;f(n)&lt;/math&gt;. The total amount of work done by the entire algorithm is the sum of the work performed by all the nodes in the tree. 

The runtime of an algorithm such as the 'p' above on an input of size 'n', usually denoted &lt;math&gt;T(n)&lt;/math&gt;, can be expressed by the [[recurrence relation]]
:&lt;math&gt;T(n) = a \; T\left(\frac{n}{b}\right) + f(n),&lt;/math&gt;
where &lt;math&gt; f(n)&lt;/math&gt; is the time to create the subproblems and combine their results in the above procedure. This equation can be successively substituted into itself and expanded to obtain an expression for the total amount of work done.&lt;ref&gt;
    Duke University,
    "Big-Oh for Recursive Functions: Recurrence Relations",
    http://www.cs.duke.edu/~ola/ap/recurrence.html
&lt;/ref&gt;
The master theorem allows many recurrence relations of this form to be converted to [[Big O notation|Θ-notation]] directly, without doing an expansion of the recursive relation.

== Generic form ==

The master theorem often yields asymptotically tight bounds to some recurrences from [[divide and conquer algorithm]]s that partition an input into smaller subproblems of equal sizes, solve the subproblems recursively, and then combine the subproblem solutions to give a solution to the original problem. The time for such an algorithm can be expressed by adding the work that they perform at the top level of their recursion (to divide the problems into subproblems and then combine the subproblem solutions) together with the time made in the recursive calls of the algorithm. If &lt;math&gt;T(n)&lt;/math&gt; denotes the total time for the algorithm on an input of size &lt;math&gt;n&lt;/math&gt;, and &lt;math&gt;f(n)&lt;/math&gt; denotes the amount of time taken at the top level of the recurrence then the time can be expressed by a [[recurrence relation]] that takes the form:
:&lt;math&gt;T(n) = a \; T\!\left(\frac{n}{b}\right) + f(n)&lt;/math&gt;
Here &lt;math&gt;n&lt;/math&gt; is the size of an input problem, &lt;math&gt;a&lt;/math&gt; is the number of subproblems in the recursion, and &lt;math&gt;b&lt;/math&gt; is the factor by which the subproblem size is reduced in each recursive call.
The theorem below also assumes that, as a base case for the recurrence, &lt;math&gt;T(n)=\Theta(1)&lt;/math&gt; when &lt;math&gt;n&lt;/math&gt; is less than some bound &lt;math&gt;\kappa &gt; 0&lt;/math&gt;, the smallest input size that will lead to a recursive call.

Recurrences of this form often satisfy one of the three following regimes, based on how the work to split/recombine the problem &lt;math&gt;f(n)&lt;/math&gt; relates to the ''critical exponent'' &lt;math&gt;c_{\operatorname{crit}}=\log_b a&lt;/math&gt;.
(The table below uses standard [[big O notation]].)

:&lt;math&gt;c_{\operatorname{crit}} = \log_b a = \log(\#\text{subproblems})/\log(\text{relative subproblem size})&lt;/math&gt;

{| class="wikitable"
|-
! width=10|Case
! Description
! Condition on &lt;math&gt;f(n)&lt;/math&gt; in relation to &lt;math&gt;c_{\operatorname{crit}}&lt;/math&gt;, i.e. &lt;math&gt;\log_b a&lt;/math&gt;
! Master Theorem bound
! width=400|Notational examples
|-


! 1
| Work to split/recombine a problem is dwarfed by subproblems. 

i.e. the recursion tree is leaf-heavy
| When &lt;math&gt;f(n) = O(n^{c})&lt;/math&gt; where &lt;math&gt;c&lt;c_{\operatorname{crit}}&lt;/math&gt; 

(upper-bounded by a lesser exponent polynomial)

| ... then &lt;math&gt;T(n)= \Theta\left( n^{c_{\operatorname{crit}}} \right)&lt;/math&gt;

(The splitting term does not appear; the recursive tree structure dominates.)

| If &lt;math&gt;b=a^2&lt;/math&gt; and &lt;math&gt;f(n) = O(n^{1/2-\epsilon})&lt;/math&gt;, then &lt;math&gt;T(n) = \Theta(n^{1/2})&lt;/math&gt;.

|-


! 2
| Work to split/recombine a problem is comparable to subproblems.
| When &lt;math&gt;f(n) = \Theta(n^{c_{\operatorname{crit}}}\log^{k} n)&lt;/math&gt; for any &lt;math&gt;k \ge 0&lt;/math&gt;

(rangebound by the critical-exponent polynomial, times zero or more optional &lt;math&gt;\log&lt;/math&gt;s)

| ... then &lt;math&gt;T(n)= \Theta\left( n^{c_{\operatorname{crit}}} \log^{k+1} n \right)&lt;/math&gt;

(The bound is the splitting term, where the log is augmented by a single power.)

| If &lt;math&gt;b=a^2&lt;/math&gt; and &lt;math&gt;f(n) = \Theta(n^{1/2})&lt;/math&gt;, then &lt;math&gt;T(n) = \Theta(n^{1/2} \log n)&lt;/math&gt;.

If &lt;math&gt;b=a^2&lt;/math&gt; and &lt;math&gt;f(n) = \Theta(n^{1/2} \log n)&lt;/math&gt;, then &lt;math&gt;T(n) = \Theta(n^{1/2} \log^{2} n)&lt;/math&gt;.

|-


! 3
| Work to split/recombine a problem dominates subproblems. 

i.e. the recursion tree is root-heavy.
| When &lt;math&gt;f(n) = \Omega(n^{c})&lt;/math&gt;where &lt;math&gt;c&gt;c_{\operatorname{crit}}&lt;/math&gt; 

(lower-bounded by a greater-exponent polynomial)

| ... this doesn't necessarily yield anything. If it is furthermore known that

:&lt;math&gt;a f\left( \frac{n}{b} \right) \le k f(n)&lt;/math&gt; for some constant &lt;math&gt;k &lt; 1&lt;/math&gt; and sufficiently large &lt;math&gt;n&lt;/math&gt; (often called the ''regularity condition'')

then the total is dominated by the splitting term &lt;math&gt;f(n)&lt;/math&gt;:

:&lt;math&gt;T\left(n \right) = \Theta\left(f(n) \right)&lt;/math&gt;

| If &lt;math&gt;b=a^2&lt;/math&gt; and &lt;math&gt;f(n) = \Omega(n^{1/2+\epsilon})&lt;/math&gt; and the regularity condition holds, then &lt;math&gt;T(n) = \Theta(f(n))&lt;/math&gt;.

|}

A useful extension of Case 2 handles all values of &lt;math&gt;k&lt;/math&gt;:&lt;ref name="Yap"&gt;
Chee Yap, A real elementary approach to the master recurrence and generalizations, Proceedings of the 8th annual conference on Theory and applications of models of computation (TAMC'11), pages 14–26, 2011. [https://pdfs.semanticscholar.org/5273/51a915d7f34f8965c74ecf422e70cd410b52.pdf Online copy.]
&lt;/ref&gt;

{| class="wikitable"
|-
! width=10|Case
! Condition on &lt;math&gt;f(n)&lt;/math&gt; in relation to &lt;math&gt;c_{\operatorname{crit}}&lt;/math&gt;, i.e. &lt;math&gt;\log_b a&lt;/math&gt;
! Master Theorem bound
! width=400|Notational examples

|-

! 2a
| When &lt;math&gt;f(n) = \Theta(n^{c_{\operatorname{crit}}}\log^{k} n)&lt;/math&gt; for any &lt;math&gt;k &gt; -1&lt;/math&gt;

| ... then &lt;math&gt;T(n)= \Theta\left( n^{c_{\operatorname{crit}}} \log^{k+1} n \right)&lt;/math&gt;

(The bound is the splitting term, where the log is augmented by a single power.)

| If &lt;math&gt;b=a^2&lt;/math&gt; and &lt;math&gt;f(n) = \Theta(n^{1/2}/\log^{1/2} n)&lt;/math&gt;, then &lt;math&gt;T(n) = \Theta(n^{1/2} \log^{1/2} n)&lt;/math&gt;.

|-

! 2b
| When &lt;math&gt;f(n) = \Theta(n^{c_{\operatorname{crit}}}\log^{k} n)&lt;/math&gt; for &lt;math&gt;k = -1&lt;/math&gt;

| ... then &lt;math&gt;T(n)= \Theta\left( n^{c_{\operatorname{crit}}} \log \log n \right)&lt;/math&gt;

(The bound is the splitting term, where the log reciprocal is replaced by an iterated log.)

| If &lt;math&gt;b=a^2&lt;/math&gt; and &lt;math&gt;f(n) = \Theta(n^{1/2}/\log n)&lt;/math&gt;, then &lt;math&gt;T(n) = \Theta(n^{1/2} \log \log n)&lt;/math&gt;.

|-

! 2c
| When &lt;math&gt;f(n) = \Theta(n^{c_{\operatorname{crit}}}\log^{k} n)&lt;/math&gt; for any &lt;math&gt;k &lt; -1&lt;/math&gt;

| ... then &lt;math&gt;T(n)= \Theta\left( n^{c_{\operatorname{crit}}} \right)&lt;/math&gt;

(The bound is the splitting term, where the log disappears.)

| If &lt;math&gt;b=a^2&lt;/math&gt; and &lt;math&gt;f(n) = \Theta(n^{1/2}/\log^2 n)&lt;/math&gt;, then &lt;math&gt;T(n) = \Theta(n^{1/2})&lt;/math&gt;.

|}


=== Examples ===

==== Case 1 example ====
:&lt;math&gt;T(n) = 8 T\left(\frac{n}{2}\right) + 1000n^2&lt;/math&gt;

As one can see from the formula above:

:&lt;math&gt;a = 8, \, b = 2, \, f(n) = 1000n^2&lt;/math&gt;, so
:&lt;math&gt;f(n) = O\left(n^c\right)&lt;/math&gt;, where &lt;math&gt;c = 2&lt;/math&gt;

Next, we see if we satisfy the case 1 condition:
:&lt;math&gt;\log_b a = \log_2 8 = 3&gt;c&lt;/math&gt;.

It follows from the first case of the master theorem that

:&lt;math&gt;T(n) = \Theta\left( n^{\log_b a} \right) = \Theta\left( n^{3} \right)&lt;/math&gt;

(This result is confirmed by the exact solution of the recurrence relation, which is &lt;math&gt;T(n) = 1001 n^3 - 1000 n^2&lt;/math&gt;, assuming &lt;math&gt;T(1) = 1&lt;/math&gt;).

==== Case 2 example ====
&lt;math&gt;T(n) = 2 T\left(\frac{n}{2}\right) + 10n&lt;/math&gt;

As we can see in the formula above the variables get the following values:

:&lt;math&gt;a = 2, \, b = 2, \, c = 1, \, f(n) = 10n&lt;/math&gt;
:&lt;math&gt;f(n) = \Theta\left(n^{c} \log^{k} n\right)&lt;/math&gt; where &lt;math&gt;c = 1, k = 0&lt;/math&gt;
Next, we see if we satisfy the case 2 condition:
:&lt;math&gt;\log_b a = \log_2 2 = 1&lt;/math&gt;, and therefore, &lt;math&gt;c = \log_b a&lt;/math&gt;

So it follows from the second case of the master theorem:

:&lt;math&gt;T(n) = \Theta\left( n^{\log_b a} \log^{k+1} n\right) = \Theta\left( n^{1} \log^{1} n\right) = \Theta\left(n \log n\right)&lt;/math&gt; 

Thus the given recurrence relation ''T''(''n'') was in Θ(''n'' log ''n'').

(This result is confirmed by the exact solution of the recurrence relation, which is &lt;math&gt;T(n) = n + 10 n\log_2 n&lt;/math&gt;, assuming &lt;math&gt;T(1) = 1&lt;/math&gt;.)

==== Case 3 example ====
:&lt;math&gt;T(n) = 2 T\left(\frac{n}{2}\right) + n^2&lt;/math&gt;

As we can see in the formula above the variables get the following values:

:&lt;math&gt;a = 2, \, b = 2, \, f(n) = n^2&lt;/math&gt;
:&lt;math&gt;f(n) = \Omega\left(n^c\right)&lt;/math&gt;, where &lt;math&gt;c = 2&lt;/math&gt;

Next, we see if we satisfy the case 3 condition:
:&lt;math&gt;\log_b a = \log_2 2 = 1&lt;/math&gt;, and therefore, yes, &lt;math&gt;c &gt; \log_b a&lt;/math&gt;

The regularity condition also holds:

:&lt;math&gt; 2 \left(\frac{n^2}{4}\right) \le k n^2 &lt;/math&gt;, choosing &lt;math&gt; k = 1/2 &lt;/math&gt;

So it follows from the third case of the master theorem:

:&lt;math&gt;T \left(n \right) = \Theta\left(f(n)\right) = \Theta \left(n^2 \right).&lt;/math&gt;

Thus the given recurrence relation ''T''(''n'') was in Θ(''n''&lt;sup&gt;2&lt;/sup&gt;), that complies with the ''f'' (''n'') of the original formula.

(This result is confirmed by the exact solution of the recurrence relation, which is &lt;math&gt;T(n) = 2 n^2 - n&lt;/math&gt;, assuming &lt;math&gt;T(1) = 1&lt;/math&gt;.)

== Inadmissible equations==
The following equations cannot be solved using the master theorem:&lt;ref&gt;
    Massachusetts Institute of Technology (MIT),
    "Master Theorem: Practice Problems and Solutions",
    http://www.csail.mit.edu/~thies/6.046-web/master.pdf
&lt;/ref&gt;

*&lt;math&gt;T(n) = 2^nT\left (\frac{n}{2}\right )+n^n&lt;/math&gt;
*:''a'' is not a constant; the number of subproblems should be fixed
*&lt;math&gt;T(n) = 2T\left (\frac{n}{2}\right )+\frac{n}{\log n}&lt;/math&gt;
*:non-polynomial difference between f(n) and &lt;math&gt;n^{\log_b a}&lt;/math&gt; (see below; extended version applies)
*&lt;math&gt;T(n) = 0.5T\left (\frac{n}{2}\right )+n&lt;/math&gt;
*:&lt;math&gt; a&lt;1 &lt;/math&gt; cannot have less than one sub problem
*&lt;math&gt;T(n) = 64T\left (\frac{n}{8}\right )-n^2\log n&lt;/math&gt;
*:f(n), which is the combination time, is not positive
*&lt;math&gt;T(n) = T\left (\frac{n}{2}\right )+n(2-\cos n)&lt;/math&gt;
*:case 3 but regularity violation.

In the second inadmissible example above, the difference between &lt;math&gt;f(n)&lt;/math&gt; and &lt;math&gt;n^{\log_b a}&lt;/math&gt; can be expressed with the ratio &lt;math&gt;\frac{f(n)}{n^{\log_b a}} = \frac{n / \log n}{n^{\log_2 2}} = \frac{n}{n \log n} = \frac{1}{\log n}&lt;/math&gt;.  It is clear that &lt;math&gt;\frac{1}{\log n} &lt; n^\epsilon&lt;/math&gt; for any constant &lt;math&gt;\epsilon &gt; 0&lt;/math&gt;.  Therefore, the difference is not polynomial and the basic form of the Master Theorem does not apply. The extended form (case 2b) does apply, giving the solution &lt;math&gt;T(n) = \Theta(n\log\log n)&lt;/math&gt;.

== Application to common algorithms ==
{| class="wikitable"
|-
! Algorithm
! Recurrence relationship
! Run time
! Comment
|-
| [[Binary search]]
| &lt;math&gt;T(n) = T\left(\frac{n}{2}\right) + O(1)&lt;/math&gt;
| &lt;math&gt;O(\log n)&lt;/math&gt;
| Apply Master theorem case &lt;math&gt;c = \log_b a&lt;/math&gt;, where &lt;math&gt;a = 1, b = 2, c = 0, k = 0&lt;/math&gt;&lt;ref name="dartmouth"&gt;
    Dartmouth College,
    http://www.math.dartmouth.edu/archive/m19w03/public_html/Section5-2.pdf
&lt;/ref&gt;
|-
| Binary tree traversal
| &lt;math&gt;T(n) = 2 T\left(\frac{n}{2}\right) + O(1)&lt;/math&gt;
| &lt;math&gt;O(n)&lt;/math&gt;
| Apply Master theorem case &lt;math&gt;c &lt; \log_b a&lt;/math&gt; where &lt;math&gt;a = 2, b = 2, c = 0&lt;/math&gt;&lt;ref name="dartmouth" /&gt;
|-
| Optimal sorted matrix search
| &lt;math&gt;T(n) = 2 T\left(\frac{n}{2}\right) + O(\log n)&lt;/math&gt;
| &lt;math&gt;O(n)&lt;/math&gt;
| Apply the [[Akra–Bazzi theorem]] for &lt;math&gt;p=1&lt;/math&gt; and &lt;math&gt;g(u)=\log(u)&lt;/math&gt; to get &lt;math&gt;\Theta(2n - \log n)&lt;/math&gt; 
|-
| [[Merge sort]]
| &lt;math&gt;T(n) = 2 T\left(\frac{n}{2}\right) + O(n)&lt;/math&gt;
| &lt;math&gt;O(n \log n)&lt;/math&gt;
| Apply Master theorem case &lt;math&gt;c = \log_b a&lt;/math&gt;, where &lt;math&gt;a = 2, b = 2, c = 1, k = 0&lt;/math&gt;
|}

==See also==

* [[Akra–Bazzi method]]
* [[Asymptotic complexity]] 

== Notes ==
{{reflist}}

== References ==
* [[Thomas H. Cormen]], [[Charles E. Leiserson]], [[Ronald L. Rivest]], and [[Clifford Stein]]. ''[[Introduction to Algorithms]]'', Second Edition. MIT Press and McGraw–Hill, 2001. {{ISBN|0-262-03293-7}}. Sections 4.3 (The master method) and 4.4 (Proof of the master theorem), pp.&amp;nbsp;73&amp;ndash;90.
* [[Michael T. Goodrich]] and [[Roberto Tamassia]]. ''Algorithm Design: Foundation, Analysis, and Internet Examples''. Wiley, 2002. {{ISBN|0-471-38365-1}}. The master theorem (including the version of Case 2 included here, which is stronger than the one from CLRS) is on pp.&amp;nbsp;268–270.

== External Links ==
* [https://www.blogcyberini.com/2017/11/teorema-mestre.html Teorema Mestre e Exemplos Resolvidos] {{pt icon}}

{{DEFAULTSORT:Master Theorem}}
[[Category:Asymptotic analysis]]
[[Category:Theorems in computational complexity theory]]
[[Category:Recurrence relations]]
[[Category:Analysis of algorithms]]</text>
      <sha1>5kpamwzpt7roiacvmvxkcvqtn40qbml</sha1>
    </revision>
  </page>
  <page>
    <title>Motion planning</title>
    <ns>0</ns>
    <id>4562875</id>
    <revision>
      <id>857191000</id>
      <parentid>855706126</parentid>
      <timestamp>2018-08-30T04:04:27Z</timestamp>
      <contributor>
        <username>Olawlor</username>
        <id>10916192</id>
      </contributor>
      <comment>Rephrase awkward last sentence.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20136">{{Refimprove|date=June 2013}}

'''Motion planning''' (also known as the '''navigation problem''' or the '''piano mover's problem''') is a term used in [[robotics]] for the process of breaking down a desired movement task into discrete motions that satisfy movement constraints and possibly optimize some aspect of the movement.

For example, consider navigating a [[mobile robot]] inside a building to a distant waypoint.  It should execute this task while avoiding walls and not falling down stairs.  A motion planning algorithm would take a description of these tasks as input, and produce the speed and turning commands sent to the robot's wheels.  Motion planning algorithms might address robots with a larger number of joints (e.g., industrial manipulators), more complex tasks (e.g. manipulation of objects), different constraints (e.g., a car that can only drive forward), and uncertainty (e.g. imperfect models of the environment or robot).

Motion planning has several robotics applications, such as [[Autonomous robot|autonomy]], [[automation]], and robot design in [[CAD software]], as well as applications in other fields, such as animating [[digital character]]s, [[video game]], [[artificial intelligence]], [[architectural design]], [[robotic surgery]], and the study of [[biological molecule]]s.

==Concepts==
[[Image:Motion planning workspace 1.svg|thumb|Example of a workspace.]]
[[Image:Motion planning workspace 1 configuration space 1.svg|thumb|Configuration space of a point-sized robot. White = ''C&lt;sub&gt;free&lt;/sub&gt;'', gray = ''C&lt;sub&gt;obs&lt;/sub&gt;''.]]
[[Image:Motion planning workspace 1 configuration space 2.svg|thumb|Configuration space for a rectangular translating robot (pictured red). White = ''C&lt;sub&gt;free&lt;/sub&gt;'', gray = ''C&lt;sub&gt;obs&lt;/sub&gt;'', where dark gray = the objects, light gray = configurations where the robot would touch an object or leave the workspace.]]
[[Image:Motion planning configuration space curved valid path.svg|thumb|Example of a valid path.]]
[[Image:Motion planning configuration space curved invalid path.svg|thumb|Example of an invalid path.]]
[[Image:Motion planning configuration space road map path.svg|thumb|Example of a road map.]]

A basic motion planning problem is to produce a continuous motion that connects a start configuration S and a goal configuration G, while avoiding collision with known obstacles.  The robot and obstacle geometry is described in a 2D or 3D ''workspace'', while the motion is represented as a path in (possibly higher-dimensional) [[Configuration space (physics)|configuration space]].

===Configuration space===
A configuration describes the pose of the robot, and the [[Configuration space (physics)|configuration space]] C is the set of all possible configurations.  For example:
* If the robot is a single point (zero-sized) translating in a 2-dimensional plane (the workspace), C is a plane, and a configuration can be represented using two parameters (x, y).
* If the robot is a 2D shape that can translate and rotate, the workspace is still 2-dimensional.   However, C is the special Euclidean group '''SE'''(2) = '''R'''&lt;sup&gt;2&lt;/sup&gt; &lt;math&gt;\times&lt;/math&gt; '''SO'''(2) (where '''SO'''(2) is the [[special orthogonal group]] of 2D rotations), and a configuration can be represented using 3 parameters (x, y, θ).
* If the robot is a solid 3D shape that can translate and rotate, the workspace is 3-dimensional, but C is the special Euclidean group '''SE(3)''' = '''R'''&lt;sup&gt;3&lt;/sup&gt; &lt;math&gt;\times&lt;/math&gt; '''SO'''(3), and a configuration requires 6 parameters: (x, y, z) for translation, and [[Euler angles]] (α, β, γ).
* If the robot is a fixed-base manipulator with N revolute joints (and no closed-loops), C is N-dimensional.

===Free space===
The set of configurations that avoids collision with obstacles is called the free space C&lt;sub&gt;free&lt;/sub&gt;.  The complement of C&lt;sub&gt;free&lt;/sub&gt; in C is called the obstacle or forbidden region.

Often, it is prohibitively difficult to explicitly compute the shape of C&lt;sub&gt;free&lt;/sub&gt;.  However, testing whether a given configuration is in C&lt;sub&gt;free&lt;/sub&gt; is efficient.  First, [[forward kinematics]] determine the position of the robot's geometry, and [[collision detection]] tests if the robot's geometry collides with the environment's geometry.

===Target space===
Target space is a [[linear subspace]] of free space which denotes where we want the robot to move to. In global motion planning, target space is observable by the robot's sensors. However, in local motion planning, the robot cannot observe the target space in some states. To solve this problem, the robot goes through several virtual target spaces, each of which is located within the observable area (around the robot). A virtual target space is called a sub-goal.

==Algorithms==
Low-dimensional problems can be solved with grid-based algorithms that overlay a grid on top of configuration space, or geometric algorithms that compute the shape and connectivity of C&lt;sub&gt;free&lt;/sub&gt;.

Exact motion planning for high-dimensional systems under complex constraints is computationally [[Computational complexity theory#Intractability|intractable]].  Potential-field algorithms are efficient, but fall prey to local minima (an exception is the harmonic potential fields).  Sampling-based algorithms avoid the problem of local minima, and solve many problems quite quickly.
They are unable to determine that no path exists, but they have a probability of failure that decreases to zero as more time is spent.

Sampling-based algorithms are currently considered state-of-the-art for motion planning in high-dimensional spaces, and have been applied to problems which have dozens or even hundreds of dimensions (robotic manipulators, biological molecules, animated digital characters, and legged robots).

===Grid-based search===
Grid-based approaches overlay a grid on configuration space, and assume each configuration is identified with a grid point.  At each grid point, the robot is allowed to move to adjacent grid points as long as the line between them is completely contained within C&lt;sub&gt;free&lt;/sub&gt; (this is tested with collision detection).  This discretizes the set of actions, and [[search algorithms]] (like [[A* search algorithm|A*]]) are used to find a path from the start to the goal.

These approaches require setting a grid resolution.  Search is faster with coarser grids, but the algorithm will fail to find paths through narrow portions of C&lt;sub&gt;free&lt;/sub&gt;.  Furthermore, the number of points on the grid grows exponentially in the configuration space dimension, which make them inappropriate for high-dimensional problems.

Traditional grid-based approaches produce paths whose heading changes are constrained to multiples of a given base angle, often resulting in suboptimal paths. [[Any-angle path planning]] approaches find shorter paths by propagating information along grid edges (to search fast) without constraining their paths to grid edges (to find short paths).

Grid-based approaches often need to search repeatedly, for example, when the knowledge of the robot about the configuration space changes or the configuration space itself changes during path following. [[Incremental heuristic search]] algorithms replan fast by using experience with the previous similar path-planning problems to speed up their search for the current one.

===Interval-based search===
These approaches are similar to grid-based search approaches except that they generate a paving covering entirely the configuration space instead of a grid.&lt;ref&gt;{{cite journal|last=Jaulin|first=L.|title=Path planning using intervals and graphs|journal=Reliable Computing|year=2001|volume=7|issue=1|url=http://www.ensta-bretagne.fr/jaulin/paper_cameleon.pdf}}&lt;/ref&gt; The paving is decomposed into two [[subpaving]]s X&lt;sup&gt;−&lt;/sup&gt;,X&lt;sup&gt;+&lt;/sup&gt; made with boxes such that X&lt;sup&gt;−&lt;/sup&gt; ⊂ C&lt;sub&gt;free&lt;/sub&gt; ⊂ X&lt;sup&gt;+&lt;/sup&gt;. Characterizing C&lt;sub&gt;free&lt;/sub&gt; amounts to solve a [[set inversion|set inversion problem]]. [[Interval arithmetic|Interval analysis]] could thus be used when C&lt;sub&gt;free&lt;/sub&gt; cannot be described by linear inequalities in order to have a guaranteed enclosure.

The robot is thus allowed to move freely in X&lt;sup&gt;−&lt;/sup&gt;, and cannot go outside X&lt;sup&gt;+&lt;/sup&gt;. To both subpavings, a neighbor graph is built and paths can be found using algorithms such as [[Dijkstra's algorithm|Dijkstra]] or [[A* search algorithm|A*]]. When a path is feasible in X&lt;sup&gt;−&lt;/sup&gt;, it is also feasible in C&lt;sub&gt;free&lt;/sub&gt;. When no path exists in X&lt;sup&gt;+&lt;/sup&gt; from one initial configuration to the goal, we have the guarantee that no feasible path exists in C&lt;sub&gt;free&lt;/sub&gt;. As for the grid-based approach, the interval approach is inappropriate for high-dimensional problems, due to the fact that the number of boxes to be generated grows exponentially with respect to the dimension of configuration space.

An illustration is provided by the three figures on the right where a hook with two degrees of freedom has to move from the left to the right, avoiding two horizontal small segments. [[File:Graph2displaycolor.jpg|thumb|Motion from the initial configuration (blue) to the final configuration of the hook, avoiding the two obstacles (red segments). The left-bottom corner of the hook has to stay on the horizontal line, which makes the hook two degrees of freedom.]] 
[[File:Graph1sivia.jpg|thumb|Decomposition with boxes covering the configuration space: The subpaving X&lt;sup&gt;−&lt;/sup&gt; is the union all red boxes and the subpaving X&lt;sup&gt;+&lt;/sup&gt; is the union of red and green boxes. The path corresponds to the motion represented above.]]
[[File:Graph3cameleon.jpg|thumb|This figure corresponds to the same path as above but obtained with many fewer boxes.The algorithm avoids bisecting boxes in parts of the configuration space that do not influence the final result.]]
The decomposition with subpavings using interval analysis also makes it possible to characterize the topology of C&lt;sub&gt;free&lt;/sub&gt; such as counting its number of connected components.&lt;ref&gt;{{cite journal|last1=Delanoue|first1=N.|last2=Jaulin|first2=L.|last3=Cottenceau|first3=B.|title=Counting the Number of Connected Components of a Set and Its Application to Robotics|journal=Applied Parallel Computing, Lecture Notes in Computer Science|year=2006|volume=3732|issue=1|url=http://www.ensta-bretagne.fr/jaulin/delanoueCounting.pdf}}&lt;/ref&gt;

===Geometric algorithms===
Point robots among polygonal obstacles
* [[Visibility graph]]
* [[Boustrophedon cell decomposition|Cell decomposition]]

Translating objects among obstacles
* [[Minkowski sum]]

===Reward-based algorithms===
Reward-based algorithms assume that the robot in each state (position and internal state, including direction) can choose between different actions (motion). However, the result of each action is not definite. In other words, outcomes (displacement) are partly random and partly under the control of the robot. The robot gets positive reward when it reaches the target and gets negative reward if it collides with an obstacle. These algorithms try to find a path which maximizes cumulative future rewards. The [[Markov decision process]] (MDP) is a popular mathematical framework that is used in many reward-based algorithms. The advantage of MDPs over other reward-based algorithms is that they generate the optimal path. The disadvantage of MDPs is that they limit the robot to choose from a finite set of actions. Therefore, the path is not smooth (similar to grid-based approaches).

===Artificial potential fields===
One approach is to treat the robot's configuration as a point in a potential field that combines attraction to the goal, and repulsion from obstacles.  The resulting trajectory is output as the path.  This approach has advantages in that the trajectory is produced with little computation.  However, they can become trapped in [[local minima]] of the potential field and fail to find a path, or can find a non-optimal path. The artificial potential fields can be treated as continuum equations similar to electrostatic potential fields (treating the robot like a point charge), or motion through the field can be discretized using a set of linguistic rules.

===Sampling-based algorithms===
Sampling-based algorithms represent the configuration space with a roadmap of sampled configurations.
A basic algorithm samples N configurations in C, and retains those in C&lt;sub&gt;free&lt;/sub&gt; to use as ''milestones''.  A roadmap is then constructed that connects two milestones P and Q if the line segment PQ is completely in C&lt;sub&gt;free&lt;/sub&gt;.  Again, collision detection is used to test inclusion in C&lt;sub&gt;free&lt;/sub&gt;.  To find a path that connects S and G, they are added to the roadmap.  If a path in the roadmap links S and G, the planner succeeds, and returns that path.  If not, the reason is not definitive: either there is no path in C&lt;sub&gt;free&lt;/sub&gt;, or the planner did not sample enough milestones.

These algorithms work well for high-dimensional configuration spaces, because unlike combinatorial algorithms, their running time is not (explicitly) exponentially dependent on the dimension of C.  They are also (generally) substantially easier to implement.  They are probabilistically complete, meaning the probability that they will produce a solution approaches 1 as more time is spent.  However, they cannot determine if no solution exists.

Given basic ''visibility'' conditions on C&lt;sub&gt;free&lt;/sub&gt;, it has been proven that as the number of configurations N grows higher, the probability that the above algorithm finds a solution approaches 1 exponentially.&lt;ref&gt;{{Cite journal
  | last1 = Hsu | first1 = D.
  | last2 = [[Jean-Claude Latombe|J.C. Latombe]] | first2 =J.C.
  | last3 = Motwani | first3 = R.
  | title = Path Planning in Expansive Configuration Spaces
  | journal = Proc. IEEE Int. Conf. on Robotics and Automation
  | year = 1997
  | postscript = &lt;!--None--&gt;
}}&lt;/ref&gt;  Visibility is not explicitly dependent on the dimension of C; it is possible to have a high-dimensional space with "good" visibility or a low-dimensional space with "poor" visibility.  The experimental success of sample-based methods suggests that most commonly seen spaces have good visibility.

There are many variants of this basic scheme:
* It is typically much faster to only test segments between nearby pairs of milestones, rather than all pairs.
* Nonuniform sampling distributions attempt to place more milestones in areas that improve the connectivity of the roadmap.
* [[Quasirandom]] samples typically produce a better covering of configuration space than [[pseudorandom]] ones, though some recent work argues that the effect of the source of randomness is minimal compared to the effect of the sampling distribution.
* It is possible to substantially reduce the number of milestones needed to solve a given problem by allowing curved eye sights (for example by crawling on the obstacles that block the way between two milestones &lt;ref&gt;{{Cite journal
  | last1 = Shvalb | first1 = N.
  | last2 = Ben Moshe | first2 =B.
  | last3 = Medina | first3 = O.
  | title = A real-time motion planning algorithm for a hyper-redundant set of mechanisms.
  | journal = Robotica
  | year = 2013
  | volume=31
  | issue=8
  | doi=10.1017/S0263574713000489 | pages=1327–1335}}&lt;/ref&gt;). 
* If only one or a few planning queries are needed, it is not always necessary to construct a roadmap of the entire space.  Tree-growing variants are typically faster for this case (single-query planning).  Roadmaps are still useful if many queries are to be made on the same space (multi-query planning)

===List of notable algorithms===
*[[A*]]
*[[D*]]
*[[Rapidly-exploring random tree]]
*[[Probabilistic roadmap]]

==Completeness and performance==
A motion planner is said to be complete if the planner in finite time either produces a solution or correctly reports that there is none. Most complete algorithms are geometry-based. The performance of a complete planner is assessed by its [[Computational complexity theory|computational complexity]].

''Resolution completeness'' is the property that the planner is guaranteed to find a path if the resolution of an underlying grid is fine enough.  Most resolution complete planners are grid-based or interval-based.  The computational complexity of resolution complete planners is dependent on the number of points in the underlying grid, which is O(1/h&lt;sup&gt;d&lt;/sup&gt;), where h is the resolution (the length of one side of a grid cell) and d is the configuration space dimension.

''Probabilistic completeness'' is the property that as more “work” is performed, the probability that the planner fails to find a path, if one exists, asymptotically approaches zero.  Several sample-based methods are probabilistically complete.  The performance of a probabilistically complete planner is measured by the rate of convergence.

''Incomplete'' planners do not always produce a feasible path when one exists.  Sometimes incomplete planners do work well in practice.

==Problem variants==
Many algorithms have been developed to handle variants of this basic problem.

===Differential constraints===
[[Degrees of freedom (engineering)|Holonomic]]
* Manipulator arms (with dynamics)

[[Nonholonomic]]
* Cars
* Unicycles
* Planes
* Acceleration bounded systems
* Moving obstacles (time cannot go backward)
* Bevel-tip steerable needle
* Differential Drive Robots

===Optimality constraints===

===Hybrid systems===

[[Hybrid systems]] are those that mix discrete and continuous behavior.  Examples of such systems are:
* [[Robotics|Robotic manipulation]]
* [[Design for Assembly|Mechanical assembly]]
* Legged robot locomotion
* [[Self-Reconfiguring Modular Robotics|Reconfigurable robots]]

===Uncertainty===
* Motion uncertainty
* Missing information
* Active sensing
* Sensorless planning

==Applications==
* [[Robot navigation]]
* [[Automation]]
* The [[driverless car]]
* [[Robotic surgery]]
* [[Computer animation|Digital character animation]]
* [[Protein folding]]
* Safety and accessibility in [[computer-aided architectural design]]

==See also==
{{Portal|Robotics|Computer science}}
* [[Gimbal lock]] – similar traditional issue in mechanical engineering
* [[Pebble motion problems]] – multi-robot motion planning
* [[Kinodynamic planning]]
* [[Mountain climbing problem]]
* [[Velocity obstacle]]
* [[OMPL]] - The Open Motion Planning Library
* [[Shortest path problem]]
* [[Pathfinding]]

==References==
{{Reflist}}

==Further reading==
*''Robot Motion Planning'', Jean-Claude Latombe, 1991, Kluwer Academic Publishers
*''[http://planning.cs.uiuc.edu/ Planning Algorithms]'', Steven M. LaValle, 2006, Cambridge University Press, {{ISBN|0-521-86205-1}}.
* ''Principles of Robot Motion: Theory, Algorithms, and Implementation'', H. Choset,  W. Burgard, S. Hutchinson, G. Kantor, [[Lydia Kavraki|L. E. Kavraki]], K. Lynch, and S. Thrun, MIT Press, April 2005.
* {{Cite book|author = Mark de Berg|author2 = Marc van Kreveld|author3 = Mark Overmars|author3-link = Mark Overmars|author4 = Otfried Schwarzkopf|last-author-amp = yes | year = 2000 | title = Computational Geometry | publisher = [[Springer-Verlag]] | edition = 2nd revised | isbn = 3-540-65620-0}} Chapter 13: Robot Motion Planning: pp.&amp;nbsp;267&amp;ndash;290.

==External links==
{{Commons category|Motion planning}}
*"Open Robotics Automation Virtual Environment", http://openrave.org/
* [https://web.archive.org/web/20070929091715/http://www.researchchannel.org/prog/displayevent.aspx?rID=2132&amp;fID=567 Jean-Claude Latombe talks about his work with robots and motion planning, 5 April 2000]
*"Open Motion Planning Library ([[OMPL]])", http://ompl.kavrakilab.org
*"Motion Strategy Library", http://msl.cs.uiuc.edu/msl/
*"Motion Planning Kit", http://ai.stanford.edu/~mitul/mpk
*"Simox", http://simox.sourceforge.net
*"Robot Motion Planning and Control", http://www.laas.fr/%7Ejpl/book.html

{{Use dmy dates|date=September 2010}}

{{DEFAULTSORT:Motion Planning}}
[[Category:Robot kinematics]]
[[Category:Theoretical computer science]]
[[Category:Automated planning and scheduling]]</text>
      <sha1>j0llh4aq7gamkeb46cna2nh7iwidk3a</sha1>
    </revision>
  </page>
  <page>
    <title>Numerical model of the Solar System</title>
    <ns>0</ns>
    <id>1355025</id>
    <revision>
      <id>858298263</id>
      <parentid>788073304</parentid>
      <timestamp>2018-09-06T05:55:32Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: isbn. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[User:AquaDTRS|AquaDTRS]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10924">{{No footnotes|article|date=April 2009}}A '''numerical model of the [[Solar System]]''' is a set of mathematical equations, which, when solved, give the approximate positions of the planets as a function of time. Attempts to create such a model established the more general field of [[celestial mechanics]]. The results of this simulation can be compared with past measurements to check for accuracy and then be used to predict future positions. Its main use therefore is in preparation of almanacs.

==Older efforts==
The simulations can be done in either [[Cartesian coordinate system|Cartesian]] or in [[Spherical coordinate system|spherical]] coordinates. The former are easier, but extremely calculation intensive, and only practical on an electronic computer. As such only the latter was used in former times. Strictly speaking not much less calculation intensive, but it was possible to start with some simple approximations and then to add [[Perturbation (astronomy)|perturbations]], as much as needed to reach the wanted accuracy.

In essence this mathematical simulation of the Solar System is a form of the ''[[N-body problem]]''. The symbol '''''N''''' represents the number of bodies, which can grow quite large if one includes 1 sun, 8 planets, dozens of moons and countless planetoids, comets and so forth. However the influence of the sun on any other body is so large, and the influence of all the other bodies on each other so small that the problem can be reduced to the analytically solvable 2-body problem. The result for each planet is an orbit, a simple description of its position as function of time. Once this is solved the influences moons and planets have on each other are added as small corrections. These are small compared to a full planetary orbit. Some corrections might be still several degrees large, while measurements can be made to an accuracy of better than 1″.

Although this method is no longer used for simulations, it is still useful to find an approximate ephemeris as one can take the relatively simple main solution, perhaps add a few of the largest perturbations, and arrive without too much effort at the wanted planetary position. The disadvantage is that perturbation theory is very advanced mathematics.

==Modern method==
The modern method consists of numerical integration in 3-dimensional space. One starts with a high accuracy value for the position (''x'', ''y'', ''z'') and the velocity (''v&lt;sub&gt;x&lt;/sub&gt;'', ''v&lt;sub&gt;y&lt;/sub&gt;'', ''v&lt;sub&gt;z&lt;/sub&gt;'') for each of the bodies involved. When also the mass of each body is known, the acceleration (''a&lt;sub&gt;x&lt;/sub&gt;'', ''a&lt;sub&gt;y&lt;/sub&gt;'', ''a&lt;sub&gt;z&lt;/sub&gt;'') can be calculated from [[Newton's Law of Gravitation]]. Each body attracts each other body, the total acceleration being the sum of all these attractions. Next one chooses a small time-step Δ''t'' and applies [[Newton's Second Law of Motion]]. The acceleration multiplied with Δ''t'' gives a correction to the velocity. The velocity multiplied with Δ''t'' gives a correction to the position. This procedure is repeated for all other bodies.

The result is a new value for position and velocity for all bodies. Then, using these new values one starts over the whole calculation for the next time-step Δ''t''. Repeating this procedure often enough, and one ends up with a description of the positions of all bodies over time.

The advantage of this method is that for a computer it is a very easy job to do, and it yields highly accurate results for all bodies at the same time, doing away with the complex and difficult procedures for determining perturbations. The disadvantage is that one must start with highly accurate figures in the first place, or the results will drift away from the reality in time; that one gets ''x'', ''y'', ''z'' positions which are often first to be transformed into more practical ecliptical or equatorial coordinates before they can be used; and that it is an all or nothing approach. If one wants to know the position of one planet on one particular time, then all other planets and all intermediate time-steps are to be calculated too.

==Integration==
In the previous section it was assumed that acceleration remains constant over a small timestep Δt so that the calculation reduces to simply the addition of V × Δt to R and so forth. In reality this is not the case, except when one takes Δt so small that the number of steps to be taken would be prohibitively high. Because while at any time the position is changed by the acceleration, the value of the acceleration is determined by the instantaneous position. Evidently a full integration is needed.

Several methods are available. First notice the needed equations:

&lt;math&gt;\vec{a}_j = \sum_{i \neq j}^n G \frac{M_i}{|\vec{r}_i - \vec{r}_j|^3} (\vec{r}_i - \vec{r}_j)&lt;/math&gt;

This equation describes the acceleration all bodies '''i''' running from 1 to N exercise on a particular body '''j'''. It is a vector equation, so it is to be split in 3 equations for each of the X, Y, Z components, yielding:

&lt;math&gt;(a_j)_x = \sum_{i \neq j}^n G \frac{M_i}{( (x_i - x_j)^2 + (y_i - y_j)^2 + (z_i - z_j)^2 )^{3/2}} (x_i - x_j)&lt;/math&gt;

with the additional relationships

&lt;math&gt;a_{x} = \frac{dv_{x}}{dt}&lt;/math&gt;, &lt;math&gt;v_{x} = \frac{dx}{dt}&lt;/math&gt;

likewise for Y and Z.

The former equation (gravitation) may look foreboding, but its calculation is no problem. The latter equations (motion laws) seems simpler, but yet it cannot be calculated. Computers cannot integrate, they cannot work with infinitesimal values, so instead of dt we use Δt and bringing the resulting variable to the left:

&lt;math&gt;\Delta v_x = a_{x} \Delta t &lt;/math&gt;, and: &lt;math&gt;\Delta x = v_{x} \Delta t &lt;/math&gt;

Remember that '''a''' is still a function of time. The simplest way to solve these is just the [[Euler]] algorithm, which in essence is the linear addition described above. Limiting ourselves to 1 dimension only in some general computer language:
 a.old = gravitationfunction(x.old)
 x.new = x.old + v.old * dt
 v.new = v.old + a.old * dt

As in essence the acceleration used for the whole duration of the timestep, is the one as it was in the beginning of the timestep, this simple method has no high accuracy. Much better results are achieved by taking a mean acceleration, the average between the beginning value and the expected (unperturbed) end value:

 a.old = gravitationfunction(x.old)
 x.expect = x.old + v.old * dt
 a.expect = gravitationfunction(x.expect)
 v.new = v.old + (a.old + a.expect) * 0.5 * dt
 x.new = x.old + (v.new + v.old) * 0.5 * dt

Of course still better results can be expected by taking intermediate values. This is what happens when using the [[Runge-Kutta]] method, especially the one of grade 4 or 5 are most useful.

A completely different method is the use of [[Taylor series]]. In that case we write: &lt;math&gt;r = r_0 + r'_0 t + r''_0 \frac{t^2}{2!} + ... &lt;/math&gt;

but rather than developing up to some higher derivative in r only, one can develop in r and v (that is r') by writing &lt;math&gt;r = f r_0 + g r'_0&lt;/math&gt;and then write out the factors ''f'' and ''g'' in a series.

==Approximations==
To calculate the accelerations the gravitational attraction of each body on each other body is to be taken into account. As a consequence the amount of calculation in the simulation goes up with the square of the number of bodies: Doubling the number of bodies increases the work with a factor four. To increase the accuracy of the simulation not only more decimals are to be taken but also smaller timesteps, again quickly increasing the amount of work. Evidently tricks are to be applied to reduce the amount of work. Some of these tricks are given here.

By far the most important trick is the use of a proper integration method, as already outlined above.

The choice of units is important. Rather than to work in [[SI units]], which would make some values extremely small and some extremely large, all units are to be scaled such that they are in the neighbourhood of 1. For example for distances in the Solar System the [[astronomical unit]] is most straightforward. If this is not done one is almost certain to see a simulation aborted in the middle of a calculation on a [[floating point]] [[arithmetic overflow|overflow]] or [[arithmetic underflow|underflow]], and if not that bad, still accuracy is likely to get lost due to [[truncation]] errors.

If N is large (not so much in Solar System simulations, but more in galaxy simulations) it is customary to create dynamic groups of bodies. All bodies in a particular direction and on large distance from the reference body, which is being calculated at that moment, are taken together and their gravitational attraction is averaged over the whole group.

The total amount of [[energy]] and [[angular momentum]] of a closed system are conserved quantities. By calculating these amounts after every time step the simulation can be programmed to increase the stepsize Δt if they do not change significantly, and to reduce it if they start to do so. Combining the bodies in groups as in the previous and apply larger and thus less timesteps on the faraway bodies than on the closer ones, is also possible.

To allow for an excessively rapid change of the acceleration when a particular body is close to the reference body, it is customary to introduce a small softness parameter ''e'' so that
&lt;math&gt;a = \frac{G M}{r^2 + e}&lt;/math&gt;

==Complications==
If the highest possible accuracy is needed, the calculations become much more complex. In the case of comets, nongravitational forces, such as radiation pressure and gas drag, must be taken into account. In the case of Mercury, and other planets for long term calculations, relativistic effects cannot be ignored. Then also the total energy is no longer a constant (because the four vector energy with linear momentum is). The finite speed of light also makes it important to allow for light-time effects, both classical and relativistic. Planets can no longer be considered as particles, but their shape and density must also be considered. For example, the flattening of the Earth causes precession, which causes the axial tilt to change, which affects the long-term movements of all planets.
Long term models, going beyond a few tens of millions of years, are not possible due to the lack of [[stability of the Solar System]].

==See also==
*[[Ephemeris]]
*[[Astronomical algorithm]]
*[[VSOP (planets)]]

==References==
*{{Cite book|first=Dan L. |last=Boulet |title=Methods of orbit determination for the microcomputer |publisher=Willmann-Bell, Inc |location=[[Richmond, Virginia]] |year=1991 |pages= |isbn=978-0-943396-34-7 |oclc=23287041}}{{Page needed|date=September 2010}}

{{DEFAULTSORT:Numerical Model Of Solar System}}
[[Category:Numerical analysis]]
[[Category:Computational physics]]
[[Category:Dynamical systems]]
[[Category:Dynamics of the Solar System]]</text>
      <sha1>b9kchq5kneogsgesljvrz8bhrkk41vz</sha1>
    </revision>
  </page>
  <page>
    <title>Password Authenticated Key Exchange by Juggling</title>
    <ns>0</ns>
    <id>20893911</id>
    <revision>
      <id>819503404</id>
      <parentid>810708686</parentid>
      <timestamp>2018-01-09T18:49:35Z</timestamp>
      <contributor>
        <username>Fh240</username>
        <id>6944248</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8730">The '''Password Authenticated Key Exchange by Juggling''' (or J-PAKE) is a [[password-authenticated key agreement]] protocol, proposed by Feng Hao and Peter Ryan.&lt;ref&gt;F. Hao, P. Ryan. [http://grouper.ieee.org/groups/1363/Research/contributions/hao-ryan-2008.pdf Password Authenticated Key Exchange by Juggling]. ''Proceedings of the 16th International Workshop on Security Protocols, 2008.''&lt;/ref&gt; This protocol allows two parties to establish private and authenticated communication solely based on their shared (low-entropy) password without requiring a [[Public Key Infrastructure]]. It provides [[mutual authentication]] to the key exchange, a feature that is lacking in the [[Diffie–Hellman key exchange]] protocol.

==Description==

Two parties, Alice and Bob, agree on a group &lt;math&gt;G&lt;/math&gt; with generator &lt;math&gt;g&lt;/math&gt; of prime order &lt;math&gt;q&lt;/math&gt; in which the discrete log problem is hard. Typically a [[Schnorr group]] is used. In general, J-PAKE can use any prime order group that is suitable for public key cryptography, including [[Elliptic curve cryptography]]. Let &lt;math&gt;s&lt;/math&gt; be their shared (low-entropy) secret, which can be a password or a hash of a password (&lt;math&gt;s \neq 0&lt;/math&gt;). The protocol executes in two rounds.

;Round 1: Alice selects &lt;math&gt;x_1 \in_R [0, q-1]&lt;/math&gt;, &lt;math&gt;x_2 \in_R [1, q-1]&lt;/math&gt; and sends out &lt;math&gt;g^{x_1}&lt;/math&gt;, &lt;math&gt;g^{x_2}&lt;/math&gt; together with the [[Zero-knowledge proofs]] (using for example Schnorr non-interactive zero-knowledge proof as specified in RFC 8235) for the proof of the exponents &lt;math&gt;x_1&lt;/math&gt; and &lt;math&gt;x_2&lt;/math&gt;. Similarly, Bob selects &lt;math&gt;x_3 \in_R [0, q-1]&lt;/math&gt;, &lt;math&gt;x_4 \in_R [1, q-1]&lt;/math&gt; and sends out &lt;math&gt;g^{x_3}&lt;/math&gt;, &lt;math&gt;g^{x_4}&lt;/math&gt; together with the [[Zero-knowledge proofs]] for the proof of the exponents &lt;math&gt;x_3&lt;/math&gt; and &lt;math&gt;x_4&lt;/math&gt;. The above communication can be completed in one round as neither party depends on the other. When it finishes, Alice and Bob verify the received [[Zero-knowledge proofs]] and also check &lt;math&gt;g^{x_2}, g^{x_4} \neq 1&lt;/math&gt;.

;Round 2: Alice sends out &lt;math&gt;A = g^{(x_1 + x_3 + x_4) x_2 s}&lt;/math&gt; and a [[Zero-knowledge proof]] for the proof of the exponent &lt;math&gt;x_2 s&lt;/math&gt;. (Note Alice actually derives a new public key using &lt;math&gt;g^{x_1 + x_3 + x_4}&lt;/math&gt; as the generator). Similarly, Bob sends out &lt;math&gt;B = g^{(x_1 + x_2 + x_3) x_4 s}&lt;/math&gt; and a [[Zero-knowledge proof]] for the proof of the exponent &lt;math&gt;x_4 s&lt;/math&gt;.

After Round 2, Alice computes &lt;math&gt;K = (B/g^{x_2 x_4 s})^{x_2} = g^{(x_1 + x_3) x_2 x_4 s}&lt;/math&gt;. Similarly, Bob computes &lt;math&gt;K = (A/g^{x_2 x_4 s})^ {x_4} = g^{(x_1 + x_3) x_2 x_4 s}&lt;/math&gt;. With the same keying material &lt;math&gt;K&lt;/math&gt;, Alice and Bob can derive a session key using a [[Cryptographic hash function]]: &lt;math&gt;\kappa = H(K)&lt;/math&gt;.

The two-round J-PAKE protocol is completely symmetric. This helps significantly simplify the security analysis. For example, the proof that one party does not leak any password information in the data exchange must hold true for the other party based on the symmetry. This reduces the number of the needed security proofs by half.

In practice, it is more likely to implement J-PAKE in three flows since one party shall normally take the initiative. This can be done trivially without loss of security. Suppose Alice initiates the communication by sending to Bob: &lt;math&gt;g^{x_1}, g^{x_2}&lt;/math&gt; and Zero-knowledge proofs. Then Bob replies with: &lt;math&gt;g^{x_3}, g^{x_4}, B = g^{(x_1 + x_2 + x_3) x_4 s}&lt;/math&gt; and Zero-knowledge proofs. Finally, Alice sends to Bob: &lt;math&gt;A = g^{(x_1 + x_3 + x_4) x_2 s}&lt;/math&gt; and a Zero-knowledge proof. Both parties can now derive the same session key.

Depending on the application requirement, Alice and Bob may perform an optional key confirmation step. There are several ways to do it. A simple method described in [[SPEKE (cryptography)|SPEKE]] works as follows: Alice sends to Bob &lt;math&gt;H(H(\kappa))&lt;/math&gt;, and then Bob replies with &lt;math&gt;H(\kappa)&lt;/math&gt;.&lt;ref&gt;{{cite journal | first = David | last = Jablon | title = Strong Password-Only Authenticated Key Exchange | journal = Computer Communication Review | publisher = ACM SIGCOMM | volume = 26 | issue = 5 | pages = 5–26 |date=October 1996 | url =  http://www.jablon.org/passwordlinks.html#Jab96 | doi = 10.1145/242896.242897}}&lt;/ref&gt; Alternatively,  Alice and Bob can realize explicit key confirmation by using the newly constructed session key to encrypt a known value (or a random challenge). [[Encrypted key exchange|EKE]], [[Kerberos (protocol)|Kerberos]] and [[Needham-Schroeder]] all attempt to provide explicit key confirmation by exactly this method.

==Security properties==

Given that the underlying Schnorr non-interactive [[zero-knowledge proof]] is secure, the J-PAKE protocol is proved to satisfy the following properties:&lt;ref&gt;F. Hao, P. Ryan. [http://eprint.iacr.org/2010/190.pdf J-PAKE: Authenticated Key Exchange Without PKI]. ''Springer Transactions on Computational Science XI, Special Issue on Security in Computing, Part II, Vol. 6480, pp. 192-206, 2010.&lt;/ref&gt;

# Off-line dictionary attack resistance - It does not leak any password verification information to a passive/active attacker.
# [[Forward secrecy]] - It produces session keys that remain secure even when the password is later disclosed.
# Known-key security - It prevents a disclosed session key from affecting the security of other sessions.
# On-line dictionary attack resistance - It limits an active attacker to test only one password per protocol execution.

In 2015, Abdalla, Benhamouda and MacKenzie conducted an independent formal analysis of J-PAKE to prove its security in a random oracle model assuming algebraic adversaries.&lt;ref&gt;M. Abdalla, F. Benhamouda, P. MacKenzie [http://www.normalesup.org/~fbenhamo/files/publications/SP_AbdBenMac15.pdf Security of the J-PAKE Password-Authenticated Key Exchange Protocol].&lt;/ref&gt;

==The protocol design==

The J-PAKE protocol is designed by combining random public keys in such a structured way to achieve a vanishing effect if both parties supplied exactly the same passwords. This is somehow similar to the [[Anonymous veto network]] protocol design. The essence of the idea, however, can be traced back to [[David Chaum]]'s original [[dining cryptographers problem|Dining Cryptographers]] network protocol,&lt;ref&gt;David Chaum. [https://dx.doi.org/10.1007/BF00206326  The Dining Cryptographers Problem: Unconditional Sender and Recipient Untraceability] Journal of Cryptology, vol. 1, No, 1, pp. 65-75,  1988&lt;/ref&gt; where binary bits are combined in a structured way to achieve a vanishing effect.

==The implementation==

J-PAKE has been implemented in [[OpenSSL]] and [[OpenSSH]] as an experimental authentication protocol. It was removed from the OpenSSH source code at the end of January 2014.&lt;ref&gt;[http://cvsweb.openbsd.org/cgi-bin/cvsweb/src/usr.bin/ssh/Attic/jpake.c OpenBSD CVS log for src/usr.bin/ssh/Attic/jpake.c]&lt;/ref&gt; It has also been implemented in [[Network Security Services|NSS]] and was used by [[Firefox Sync]] version 1.1 but discontinued in 1.5 which uses a different key exchange and storage method.&lt;ref&gt;https://blog.mozilla.org/services/2014/04/30/firefox-syncs-new-security-model/&lt;/ref&gt; Mozilla's J-PAKE server was shut down along with the Sync 1.1 storage servers on 30 September 2015.&lt;ref&gt;https://blog.mozilla.org/services/2015/07/31/shutting-down-the-legacy-sync-service/&lt;/ref&gt; [[Pale Moon (web browser)|Pale Moon]] continues to use J-PAKE as part of its Sync service.&lt;ref&gt;https://forum.palemoon.org/viewtopic.php?f=1&amp;t=9854&lt;/ref&gt; Since February 2013, J-PAKE has been added to the lightweight API in [[Bouncycastle]] (1.48 and onwards). J-PAKE is also used in the [[Thread (network protocol)]]&lt;ref&gt;http://threadgroup.org/Portals/0/documents/whitepapers/Thread%20Commissioning%20white%20paper_v2_public.pdf&lt;/ref&gt;

==Standardization==

J-PAKE has been included in ISO/IEC 11770-4 (2017) as an international standard.&lt;ref&gt;https://www.iso.org/obp/ui/#iso:std:67933:en&lt;/ref&gt; It is also published in RFC 8236.

==References==
{{reflist}}

==External links==
* [https://tools.ietf.org/html/draft-hao-jpake-01 J-PAKE  draft]
* [http://www.links.org/?p=393 A prototype demo of J-PAKE in C]
* [http://haofeng66.googlepages.com/JPAKEDemo.java A prototype demo of J-PAKE in Java]
* [http://homepages.cs.ncl.ac.uk/feng.hao/files/EllipticCurveJPAKEDemo.java An example of implementing J-PAKE using Elliptic Curve]
* [http://www.lightbluetouchpaper.org/2008/05/29/j-pake J-PAKE: From Dining Cryptographers to Jugglers]

{{DEFAULTSORT:Password Authenticated Key Exchange By Juggling}}
[[Category:Cryptography]]
[[Category:Cryptographic protocols]]</text>
      <sha1>06r76jp04bwb3sg5ybzqzhkgrog0x3s</sha1>
    </revision>
  </page>
  <page>
    <title>Permutation model</title>
    <ns>0</ns>
    <id>43782287</id>
    <revision>
      <id>829169711</id>
      <parentid>769410818</parentid>
      <timestamp>2018-03-07T01:48:20Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* References */[[User:JCW-CleanerBot#Logic|task]], replaced: Comptes rendus des séances de la Société des Sciences et des Lettres de Varsovie → Comptes Rendus des Séances de la Société des Sciences et des Lettres d using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2563">In mathematical [[set theory]], a '''permutation model''' is a [[model (mathematical logic)|model]] of set theory with [[Atom (set theory)|atoms]] (ZFA) constructed using a [[permutation group|group]] of [[permutation]]s of the atoms. A '''symmetric model''' is similar except that it is a model of ZF (without atoms) and is constructed using a group of permutations of a forcing [[poset]]. One application is to show the independence of the [[axiom of choice]] from the other axioms of ZFA or ZF.
Permutation models were introduced by {{harvs|txt|last=Fraenkel|year=1922}} and developed further by {{harvs|txt|last=Mostowski|year=1938}}. 
Symmetric models were introduced by [[Paul Cohen (mathematician)|Paul Cohen]].

==Construction of permutation models==

Suppose that ''A'' is a set of atoms, and ''G'' is a group of permutations of ''A''. A '''normal filter''' of ''G'' is a collection ''F'' of subgroups of ''G'' such that 
*''G'' is in ''F''
*The intersection of two elements of ''F'' is in ''F''
*Any subgroup containing an element of ''F'' is in ''F''
*Any conjugate of an element of ''F'' is in ''F''
*The subgroup fixing any element of ''A'' is in ''F''.

If ''V'' is a model of ZFA with ''A'' the set of atoms, then an element of ''V'' is called symmetric if the subgroup fixing it is in ''F'', and is called hereditarily symmetric if it and all elements of its transitive closure are symmetric. The '''permutation model''' consists of all hereditarily symmetric elements, and is a model of ZFA.

==Construction of filters on a group==

A filter on a group can be constructed from an invariant ideal on of the Boolean algebra of subsets of ''A'' containing all elements of ''A''. Here an ideal is a collection ''I'' of subsets of ''A'' closed under taking unions and subsets, and is called invariant if it is invariant under the action of the group ''G''. For each element ''S'' of the ideal one can take the subgroup of ''G'' consisting of all elements fixing every element ''S''. These subgroups generate a normal filter of ''G''.

==References==

*{{citation|last=Fraenkel|first= A.
|title=Der Begriff "definit" und die Unabhängigkeit des Auswahlaxioms| JFM =48.0199.02
|journal=Sitzungsberichte der Königlich Preussischen Akademie der Wissenschaften|year= 1922|pages= 253–257 }}
*{{citation|first= Andrzej |last=Mostowski|title= Über den Begriff einer Endlichen Menge|year=1938|journal= Comptes Rendus des Séances de la Société des Sciences et des Lettres de Varsovie, Classe III|volume=31|issue=8|pages=13–20}}

[[Category:Set theory]]</text>
      <sha1>teth8zxrhysam5nfdj7uknhbkebwnuo</sha1>
    </revision>
  </page>
  <page>
    <title>Pinsker's inequality</title>
    <ns>0</ns>
    <id>20064401</id>
    <revision>
      <id>864545314</id>
      <parentid>864530596</parentid>
      <timestamp>2018-10-17T22:28:37Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Citation needed}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4328">In [[information theory]], '''Pinsker's inequality''', named after its inventor [[Mark Semenovich Pinsker]], is an [[inequality (mathematics)|inequality]] that bounds the [[total variation distance]] (or statistical distance) in terms of the [[Kullback–Leibler divergence]].
The inequality is tight up to constant factors.&lt;ref&gt;{{cite book|title=Information Theory: Coding Theorems for Discrete Memoryless Systems|first1=Imre|last1=Csiszár|first2=János|last2=Körner|publisher=Cambridge University Press|year=2011|isbn=9781139499989|page=44|url=https://books.google.com/books?id=2gsLkQlb8JAC&amp;pg=PA44}}&lt;/ref&gt;

==Formal statement==
Pinsker's inequality states that, if &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; are two [[probability distribution]]s on a [[measurable space]] &lt;math&gt;(X, \Sigma)&lt;/math&gt;, then

:&lt;math&gt;\delta(P,Q) \le \sqrt{\frac{1}{2} D_{\mathrm{KL}}(P\|Q)},&lt;/math&gt;

where

:&lt;math&gt;\delta(P,Q)=\sup \bigl\{ |P(A) - Q(A)| \big| A \in \Sigma \text{ is a measurable event} \bigr\}&lt;/math&gt;

is the [[Total variation distance of probability measures|total variation distance]] (or statistical distance) between &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; and

:&lt;math&gt;D_{\mathrm{KL}}(P\|Q) = \operatorname{E}_P \left( \log \frac{\mathrm{d} P}{\mathrm{d} Q} \right) = \int_X \left( \log \frac{\mathrm{d} P}{\mathrm{d} Q} \right) \, \mathrm{d} P&lt;/math&gt;

is the [[Kullback–Leibler divergence]] in [[Nat (unit)|nats]].  When the sample space &lt;math&gt;X&lt;/math&gt; is a finite set, the Kullback–Leibler divergence is given by

: &lt;math&gt;D_{\mathrm{KL}}(P\|Q) = \sum_{i \in X} \left( \log \frac{P(i)}{Q(i)}\right) P(i)\!&lt;/math&gt;

Note that in terms of the [[Total_variation#Total_variation_of_a_measure|total variation norm]] &lt;math&gt;\| P - Q \|&lt;/math&gt; of the [[signed measure]] &lt;math&gt;P - Q&lt;/math&gt;, Pinsker's inequality differs from the one given above by a factor of two:
:&lt;math&gt;\| P - Q \| \le \sqrt{2 D_{\mathrm{KL}}(P\|Q)}.&lt;/math&gt;

A proof of Pinsker's inequality uses the [[partition inequality]] for [[f-divergence|''f''-divergences]].

==History==
Pinsker first proved the inequality with a worse constant. The inequality in the above form was proved independently by [[Solomon Kullback|Kullback]], [[Imre Csiszár|Csiszár]], and [[Johannes Kemperman|Kemperman]].&lt;ref&gt;{{cite book|last=Tsybakov|first=Alexandre|title=Introduction to Nonparametric Estimation|year=2009|publisher=Springer|isbn=9780387790527|page=132}}&lt;/ref&gt;

==Inverse problem==
A precise inverse of the inequality cannot hold:  for every &lt;math&gt;\varepsilon &gt; 0&lt;/math&gt;, there are distributions &lt;math&gt;P_\varepsilon, Q&lt;/math&gt; with &lt;math&gt;\delta(P_\varepsilon,Q)\le\varepsilon&lt;/math&gt; but &lt;math&gt;D_{\mathrm{KL}}(P_\varepsilon\|Q) = \infty&lt;/math&gt;. An easy example is given by the two-point space &lt;math&gt;\{0,1\}&lt;/math&gt; with &lt;math&gt;Q(0) = 0, Q(1) = 1&lt;/math&gt; and &lt;math&gt;P_\varepsilon(0) = \varepsilon, P_\varepsilon(1) = 1-\varepsilon&lt;/math&gt;. &lt;ref&gt;The divergence becomes infinite whenever one of the two distributions assigns probability zero to an event while the other assigns it a nonzero probability (no matter how small); see e.g. {{cite book|title=Data Complexity in Pattern Recognition|first1=Mitra|last1=Basu|first2=Tin Kam|last2=Ho|publisher=Springer|year=2006|isbn=9781846281723|page=161|url=https://books.google.com/books?id=GflBKbzym9oC&amp;pg=PA161}}.&lt;/ref&gt;

However, an inverse inequality holds{{Citation needed|date=October 2018}} on finite spaces &lt;math&gt;X&lt;/math&gt; with a constant depending on &lt;math&gt;Q&lt;/math&gt;. More specifically, it can be shown that with the definition &lt;math&gt;\alpha_Q := \min_{x \in X: Q(x) &gt; 0} Q(x)&lt;/math&gt; we have for any measure &lt;math&gt;P&lt;/math&gt; which is absolutely continuous to &lt;math&gt;Q&lt;/math&gt;

: &lt;math&gt;\frac{1}{2} D_{\mathrm{KL}}(P\|Q) \le \frac{1}{\alpha_Q} \delta(P,Q)^2. &lt;/math&gt;

As a consequence, if &lt;math&gt;Q&lt;/math&gt; has full [[Support_(measure_theory)|support]] (i.e. &lt;math&gt;Q(x) &gt; 0&lt;/math&gt; for all &lt;math&gt;x \in X&lt;/math&gt;), then

: &lt;math&gt; \delta(P,Q)^2 \le \frac{1}{2} D(P\|Q) \le \frac{1}{\alpha_Q} \delta(P,Q)^2. &lt;/math&gt;

==References==
{{Reflist}}

==Further reading==
* Thomas M. Cover and Joy A. Thomas: ''Elements of Information Theory'', 2nd edition, Willey-Interscience, 2006
* Nicolo Cesa-Bianchi and Gábor Lugosi: ''Prediction, Learning, and Games'', Cambridge University Press, 2006

[[Category:Information theory]]
[[Category:Probabilistic inequalities]]</text>
      <sha1>2t0152qlot910cevko2brnpl09hmxx3</sha1>
    </revision>
  </page>
  <page>
    <title>Polish Mathematical Society</title>
    <ns>0</ns>
    <id>2121791</id>
    <revision>
      <id>850437664</id>
      <parentid>832962228</parentid>
      <timestamp>2018-07-15T21:32:18Z</timestamp>
      <contributor>
        <username>Rathfelder</username>
        <id>398607</id>
      </contributor>
      <comment>removed [[Category:Learned societies of Poland]]; added [[Category:Polish scientific societies]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4273">{{Infobox Organization
| name         = Polish Mathematical Society
| image        = logo-PTM.jpg
| image_border = 
| size         = 150x150
| caption      = 
| formation    = April 2, 1919
| type         = 
| headquarters = [[Warsaw, Poland|ul. Śniadeckich 8, 00-956 Warszawa, Poland]]
| location     = [[Poland]]
| membership   =  
| language     = Polish, English
| leader_title = President
| leader_name  = [[Wacław Marzantowicz]]
| key_people   = [[Sławomir Kołodziej]], [[Krzysztof Szajowski]], [[Małgorzata Migda]], [[Adrian Łydka]], [[Jacek Miękisz]], [[Ewa Swoboda (mathematician)|Ewa Swoboda]], [[Aleksy Tralle]], [[Robert Wolak]]
| num_staff    = 
| budget       = 
| website      = http://www.ptm.org.pl/
}}
The '''Polish Mathematical Society''' ({{lang-pl|Polskie Towarzystwo Matematyczne}}) began in [[Kraków]], [[Poland]] in 1917. It was originally simply called the Mathematical Society. It was officially constituted on April 2, 1919.  [[Hugo Steinhaus]], [[Stefan Banach]] and [[Otto Nikodym]] were among the founders.&lt;ref name=mac&gt;{{cite web |url=http://www-history.mcs.st-and.ac.uk/history/Biographies/Steinhaus.html |title=Hugo Dyonizy Steinhaus |author=J.J. O'Connor |author2=E. F. Robertson |date=February 2000 |work=The MacTutor History of Mathematics archive |publisher=School of Mathematics and Statistics, University of St Andrews, Scotland |accessdate=16 August 2011}}&lt;/ref&gt;

Ever since its foundation, the Society's main activity was to bring mathematicians together by means of organizing conferences and lectures. The second main activity is the publication of its annals "Annales Societatis Mathematicae Polonae", consisting of 
* Series 1: [https://web.archive.org/web/20100807105055/http://www.ptm.org.pl/wydawnictwa/2/ Commentationes Mathematicae] 
* Series 2: [https://web.archive.org/web/20100807105050/http://www.ptm.org.pl/wydawnictwa/1/ Wiadomości Matematyczne] ("Mathematical News"), in Polish
* Series 3: [https://web.archive.org/web/20100807035825/http://www.ptm.org.pl/wydawnictwa/4/ Matematyka Stosowana] ("Applied Mathematics"), in Polish
* Series 4: [[Fundamenta Informaticae]]
* Series 5: [https://web.archive.org/web/20100807105110/http://www.ptm.org.pl/wydawnictwa/3/ Didactica Mathematicae], in Polish
* Series 6: [https://web.archive.org/web/20101202094937/http://www.ptm.org.pl/wydawnictwa/5/ Antiquitates Mathematicae], in Polish
* Series 7: [https://web.archive.org/web/20100807040140/http://www.ptm.org.pl/wydawnictwa/7/ Delta], in Polish

The annals are also known under the Polish name "Roczniki Polskiego Towarzystwa Matematycznego" and under the English name "Polish Mathematical Society Annals".

== International Stefan Banach Prize ==
The International Stefan Banach Prize (Polish: ''Międzynarodowa Nagroda im. Stefana Banacha'') is an annual award presented by the Mathematical Society to mathematicians for best doctoral dissertations in the [[mathematical sciences]]. Its aim is to "promote and financially support the most promising young researchers" in the field of [[mathematics]]. It was founded in 2009 and is named in honour of a renowned Polish mathematician [[Stefan Banach]] (1892-1945). The laureates of the award also receive a cash prize of [[Polish złoty|PLN]] 20,000 (c.$5,000).

== References ==
{{reflist}}
* {{cite journal | title=Polish Mathematical Society (PTM)|author=Janusz Kowalski | journal= EMS|date=December 2004| url=http://www.emis.de/newsletter/54/page24.pdf | accessdate=April 10, 2006|format=PDF}}
* [http://wiadmat.wmid.amu.edu.pl/English Website of the journal Wiadomości Matematyczne], edited by the Polish Mathematical Society. Retrieved on January 9, 2009.

==External links==
* [http://www.ptm.org.pl Polish Mathematical Society website] (in Polish)
* {{cite web | title=Polish Mathematical Society | work=Mathematical Societies, Medals, Prizes and other honours | url=http://www.gap-system.org/~history/Societies/Polish.html | accessdate=June 26, 2005 | deadurl=yes | archiveurl=https://web.archive.org/web/20051214221824/http://www.gap-system.org/~history/Societies/Polish.html | archivedate=December 14, 2005 | df= }}

[[Category:Polish scientific societies]]
[[Category:Mathematical societies]]
[[Category:1917 establishments in Poland]]


{{math-stub}}</text>
      <sha1>aue5ge2nmdy5uf07rdda8k1kyiudtta</sha1>
    </revision>
  </page>
  <page>
    <title>Principle of least action</title>
    <ns>0</ns>
    <id>249438</id>
    <revision>
      <id>870636546</id>
      <parentid>870455679</parentid>
      <timestamp>2018-11-26T02:49:50Z</timestamp>
      <contributor>
        <username>JRSpriggs</username>
        <id>1026643</id>
      </contributor>
      <comment>/* General statement */ still better</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22504">{{classical mechanics}}

:''This article discusses the history of the principle of least action. For the application, please refer to [[action (physics)]].''
The '''principle of least action''' – or, more accurately, the '''principle of stationary action''' – is a [[variational principle]] that, when applied to the [[action (physics)|action]] of a [[mechanics|mechanical]] system, can be used to obtain the [[equations of motion]] for that system. In relativity, a different action must be minimized or maximized. The principle can be used to derive [[Newtonian mechanics|Newtonian]], [[Lagrangian mechanics|Lagrangian]] and [[Hamiltonian mechanics|Hamiltonian]] [[equations of motion]], and even [[general relativity]] (see [[Einstein–Hilbert action]]). The physicist Paul Dirac&lt;ref&gt;P.A.M. Dirac, Physikalische Zeitschrift der Sowjetunion, Band 3, Heft 1, 64
(1933). A translated version can be found in; Julian S. Schwinger, Selected Papers on Electrodynamics, Dover Publications Inc.(1958), pp. 312.{{ISBN|9780883076484}}&lt;/ref&gt;, and after him Julian Schwinger and Richard Feynman, demonstrated how this principle can also be used in quantum calculations.&lt;ref&gt;R. Feynman, Quantum Mechanics, And Path Integrals, McGraw-Hill Companies (1965), {{ISBN|0070206503}}&lt;/ref&gt;&lt;ref&gt;R. J. S. Schwinger, Quantum Kinematics and Dynamics, W. A. Benjamin Publishers (1970), {{ISBN|0738203033}}&lt;/ref&gt;
It was historically called "least" because its solution requires finding the path that has the least value.&lt;ref name=":0"&gt;Chapter 19 of Volume II,  [[Richard Feynman|Feynman R]], [[Robert B. Leighton|Leighton R]], and [[Matthew Sands|Sands M.]] ''The Feynman Lectures on Physics ''. 3 volumes 1964, 1966. Library of Congress Catalog Card No. 63-20717. {{ISBN|0-201-02115-3}} (1970 paperback three-volume set); {{ISBN|0-201-50064-7}} (1989 commemorative hardcover three-volume set); {{ISBN|0-8053-9045-6}} (2006 the definitive edition (2nd printing); hardcover)&lt;/ref&gt; Its classical mechanics and electromagnetic expressions are a consequence of quantum mechanics, but the stationary action method helped in the development of quantum mechanics.&lt;ref&gt;[[Richard Feynman]], ''[[The Character of Physical Law]]''.&lt;/ref&gt;

The principle remains central in [[modern physics]] and [[mathematics]], being applied in [[thermodynamics]],&lt;ref&gt;{{cite journal |doi=10.1016/j.aop.2008.04.007 |title=Thermodynamics based on the principle of least abbreviated action: Entropy production in a network of coupled oscillators |journal=Annals of Physics |volume=323 |issue=8 |pages=1844–58 |year=2008 |last1=García-Morales |first1=Vladimir |last2=Pellicer |first2=Julio |last3=Manzanares |first3=José A. |bibcode=2008AnPhy.323.1844G |arxiv=cond-mat/0602186 }}&lt;/ref&gt; [[fluid mechanics]],&lt;ref&gt;http://www.scholarpedia.org/article/Principle_of_least_action&lt;/ref&gt; the [[theory of relativity]], [[quantum mechanics]],&lt;ref&gt;{{cite journal |bibcode=1942PhDT.........5F |title=The Principle of Least Action in Quantum Mechanics |author1=Feynman |first1=Richard Phillips |year=1942 }}&lt;/ref&gt; [[particle physics]], and [[string theory]]&lt;ref&gt;[http://www.damtp.cam.ac.uk/user/db275/LeastAction.pdf Principle of Least Action - damtp]&lt;/ref&gt; and is a focus of modern mathematical investigation in [[Morse theory]]. [[Maupertuis' principle]] and [[Hamilton's principle]] exemplify the principle of stationary action.

The action principle is preceded by earlier ideas in [[optics]]. In [[ancient Greece]], [[Euclid]] wrote in his ''Catoptrica'' that, for the path of light reflecting from a mirror, the [[angle of incidence (optics)|angle of incidence]] equals the [[angle of reflection]].{{Citation needed|date=January 2015}} [[Hero of Alexandria]] later showed that this path was the shortest length and least time.&lt;ref&gt;{{cite book
|last=Kline|first=Morris
|title=Mathematical Thought from Ancient to Modern Times
|publisher=Oxford University Press|location=New York
|date=1972|pages= 167–68|isbn=0-19-501496-0}}&lt;/ref&gt;

Scholars often credit [[Pierre Louis Maupertuis]] for formulating the principle of least action because he wrote about it in 1744&lt;ref name="mau44"&gt;P.L.M. de Maupertuis, ''[[s:fr:Accord de différentes loix de la nature qui avoient jusqu’ici paru incompatibles|Accord de différentes lois de la nature qui avaient jusqu'ici paru incompatibles.]]'' (1744) Mém. As. Sc. Paris p. 417. ([[s:Accord between different laws of Nature that seemed incompatible|English translation]])&lt;/ref&gt; and 1746.&lt;ref name="mau46"&gt;P.L.M. de Maupertuis, ''[[s:fr:Les loix du mouvement et du repos déduites d'un principe metaphysique|Le lois de mouvement et du repos, déduites d'un principe de métaphysique.]]'' (1746) Mém. Ac. Berlin, p. 267.([[s:Derivation of the laws of motion and equilibrium from a metaphysical principle|English translation]])&lt;/ref&gt; However, [[Leonhard Euler]] discussed the principle in 1744,&lt;ref name="eul44"&gt;Leonhard Euler, ''Methodus Inveniendi Lineas Curvas Maximi Minive Proprietate Gaudentes.'' (1744) Bousquet, Lausanne &amp;amp; Geneva. 320 pages. Reprinted in ''Leonhardi Euleri Opera Omnia: Series I vol 24.'' (1952) C. Cartheodory (ed.) Orell Fuessli, Zurich. [http://math.dartmouth.edu/~euler/pages/E065.html Scanned copy of complete text] at ''[http://math.dartmouth.edu/~euler/ The Euler Archive]'', Dartmouth.&lt;/ref&gt; and evidence shows that [[Gottfried Leibniz]] preceded both by 39 years.&lt;ref name="oco03"&gt;J J O'Connor and E F Robertson, "[http://www-history.mcs.st-andrews.ac.uk/history/HistTopics/Forgery_2.html The Berlin Academy and forgery]", (2003), at ''[http://www-history.mcs.st-andrews.ac.uk/history/ The MacTutor History of Mathematics archive]''.&lt;/ref&gt;&lt;ref name="ger98"&gt;Gerhardt CI. (1898) "Über die vier Briefe von Leibniz, die Samuel König in dem Appel au public, Leide MDCCLIII, veröffentlicht hat", ''Sitzungsberichte der Königlich Preussischen Akademie der Wissenschaften'', '''I''', 419-427.&lt;/ref&gt;&lt;ref name="kab13"&gt;Kabitz W. (1913) "Über eine in Gotha aufgefundene Abschrift des von S. König in  seinem Streite mit Maupertuis und der Akademie veröffentlichten, seinerzeit für unecht erklärten Leibnizbriefes", ''Sitzungsberichte der Königlich Preussischen Akademie der Wissenschaften'', '''II''', 632-638.&lt;/ref&gt;

In 1933, [[Paul Dirac]] discerned the [[Path integral formulation#Quantum action principle|quantum mechanical underpinning]] of the principle in the [[Interference (wave propagation)#Quantum interference|quantum interference]] of amplitudes.&lt;ref&gt;{{cite journal |last=Dirac |first=Paul A. M. |authorlink=Paul Dirac |year=1933 |title=The Lagrangian in Quantum Mechanics |journal=Physikalische Zeitschrift der Sowjetunion |volume=3 |pages=64–72 |url=http://www.hep.anl.gov/czachos/soysoy/Dirac33.pdf}}&lt;/ref&gt;

==General statement==
[[File:Least action principle.svg|250px|thumb|As the system evolves, '''q''' traces a path through [[configuration space (physics)|configuration space]] (only some are shown). The path taken by the system (red) has a stationary action (''δS'' = 0) under small changes in the configuration of the system (''δ'''''q''').&lt;ref name=penrose&gt;{{cite book |author=R. Penrose| title=[[The Road to Reality]]| publisher= Vintage books| year=2007 | page = 474|isbn=0-679-77631-1}}&lt;/ref&gt;]]

The starting point is the ''[[action (physics)|action]]'', denoted &lt;math&gt; \mathcal{S} &lt;/math&gt; (calligraphic S), of a physical system. It is defined as the [[integral (mathematics)|integral]] of the [[Lagrangian mechanics|Lagrangian]] ''L'' between two instants of [[time in physics|time]] ''t''&lt;sub&gt;1&lt;/sub&gt; and ''t''&lt;sub&gt;2&lt;/sub&gt; - technically a [[functional (mathematics)|functional]] of the ''N'' [[generalized coordinates]] '''q''' = (''q''&lt;sub&gt;1&lt;/sub&gt;, ''q''&lt;sub&gt;2&lt;/sub&gt;, ... , ''q&lt;sub&gt;N&lt;/sub&gt;'') which define the [[Configuration space (physics)|configuration]] of the system:

:&lt;math&gt; \mathbf{q} : \mathbf{R} \to \mathbf{R}^N &lt;/math&gt;
:&lt;math&gt; \mathcal{S}[\mathbf{q}, t_1, t_2] 
= \int_{t_1}^{t_2} L(\mathbf{q}(t),\mathbf{\dot{q}}(t), t) dt &lt;/math&gt;

where the dot denotes the [[time derivative]], and ''t'' is time.

Mathematically the principle is&lt;ref&gt;Encyclopaedia of Physics (2nd Edition), R.G. Lerner, G.L. Trigg, VHC publishers, 1991, ISBN (Verlagsgesellschaft) 3-527-26954-1, ISBN (VHC Inc.) 0-89573-752-3&lt;/ref&gt;&lt;ref&gt;McGraw Hill Encyclopaedia of Physics (2nd Edition), C.B. Parker, 1994, {{ISBN|0-07-051400-3}}&lt;/ref&gt;&lt;ref name="Analytical Mechanics 2008"&gt;Analytical Mechanics, L.N. Hand, J.D. Finch, Cambridge University Press, 2008, {{ISBN|978-0-521-57572-0}}&lt;/ref&gt;

:&lt;math&gt; \delta \mathcal{S} = 0 ,&lt;/math&gt;

where ''δ'' (lowercase Greek [[Delta (letter)|delta]]) means a ''small'' change. In words this reads:&lt;ref name=penrose/&gt;

:''The path taken by the system between times t&lt;sub&gt;1&lt;/sub&gt; and t&lt;sub&gt;2&lt;/sub&gt; and configurations q&lt;sub&gt;1&lt;/sub&gt; and q&lt;sub&gt;2&lt;/sub&gt; is the one for which the '''action''' is '''stationary (no change)''' to '''first order'''.''

In applications the statement and definition of action are taken together:&lt;ref&gt;Classical Mechanics, T.W.B. Kibble, European Physics Series, McGraw-Hill (UK), 1973, {{ISBN|0-07-084018-0}}&lt;/ref&gt;

:&lt;math&gt; \delta \int_{t_1}^{t_2} L(\mathbf{q}, \mathbf{\dot{q}},t) dt = 0 .&lt;/math&gt;

The action and Lagrangian both contain the dynamics of the system for all times. The term "path" simply refers to a curve traced out by the system in terms of the coordinates in the [[Configuration space (physics)|configuration space]], i.e. the curve '''q'''(''t''), parameterized by time (see also [[parametric equation]] for this concept).

==Origins, statements, and controversy==

===Fermat===
{{main article|Fermat's principle}}
In the 1600s, [[Pierre de Fermat]] postulated that "''light travels between two given points along the path of shortest time''," which is known as the '''principle of least time''' or '''[[Fermat's principle]]'''.&lt;ref name="Analytical Mechanics 2008"/&gt;

===Maupertuis===
{{main article|Maupertuis principle}}
Credit for the formulation of the '''principle of least action''' is commonly given to [[Pierre Louis Maupertuis]], who felt that "Nature is thrifty in all its actions", and applied the principle broadly:

{{quote|The laws of movement and of rest deduced from this principle being precisely the same as those observed in nature, we can admire the application of it to all phenomena. The movement of animals, the vegetative growth of plants ... are only its consequences; and the spectacle of the universe becomes so much the grander, so much more beautiful, the worthier of its Author, when one knows that a small number of laws, most wisely established, suffice for all movements.|Pierre Louis Maupertuis&lt;ref&gt;Chris Davis. [http://www.idlex.freeserve.co.uk/idle/evolution/ref/leastact.html ''Idle theory''] {{webarchive|url=https://web.archive.org/web/20060615043538/http://www.idlex.freeserve.co.uk/idle/evolution/ref/leastact.html |date=2006-06-15 }} (1998)&lt;/ref&gt;}}

This notion of Maupertuis, although somewhat deterministic today, does capture much of the essence of mechanics.

In application to physics, Maupertuis suggested that the quantity to be minimized was the product of the duration (time) of movement within a system by the "[[vis viva]]",

{{Equation box 1
|indent =:
|title='''Maupertuis' principle'''
|equation = &lt;math&gt;\delta \int 2T(t)  dt=0&lt;/math&gt;
|border=2
|border colour = #0073CF
|background colour=#F5FFFA}}

which is the integral of twice what we now call the [[kinetic energy]] ''T'' of the system.

===Euler===

[[Leonhard Euler]] gave a formulation of the action principle in 1744, in very recognizable terms, in the ''Additamentum 2'' to his ''Methodus Inveniendi Lineas Curvas Maximi Minive Proprietate Gaudentes''. Beginning with the second paragraph:

{{cquote|Let the mass of the projectile be ''M'', and let its speed be ''v'' while being moved over an infinitesimal distance ''ds''.   The body will have a momentum ''Mv'' that, when multiplied by the distance ''ds'', will give {{nowrap|''Mv'' ''ds''}}, the momentum of the body integrated over the distance ''ds''.  Now I assert that the curve thus described by the body to be the curve (from among all other curves connecting the same endpoints) that minimizes
:&lt;math&gt;\int Mv\,ds&lt;/math&gt;
or, provided that ''M'' is constant along the path,
:&lt;math&gt;M\int v\,ds&lt;/math&gt;.|20px|20px|Leonhard Euler&lt;ref name="eul44" /&gt;&lt;ref&gt;Euler, [[s:la:Methodus inveniendi/Additamentum II|Additamentum II]] ([http://math.dartmouth.edu/~euler/docs/originals/E065h external link]), ibid. ([[https://en.wikisource.org/w/index.php?title=Translation:Methodus_inveniendi/Additamentum_II&amp;oldid=6399338| English translation]])&lt;/ref&gt;}}

As Euler states, ∫''Mv''d''s'' is the integral of the momentum over distance travelled, which, in modern notation, equals the abbreviated or [[reduced action]]

{{Equation box 1
|indent =:
|title='''Euler's principle'''
|equation = &lt;math&gt;\delta\int p\,dq=0&lt;/math&gt;
|border=2
|border colour = #0073CF
|background colour=#F5FFFA}}

Thus, Euler made an equivalent and (apparently) independent statement of the variational principle in the same year as Maupertuis, albeit slightly later. Curiously, Euler did not claim any priority, as the following episode shows.

===Disputed priority===

Maupertuis' priority was disputed in 1751 by the mathematician [[Samuel König]], who claimed that it had been invented by [[Gottfried Leibniz]] in 1707. Although similar to many of Leibniz's arguments, the principle itself has not been documented in Leibniz's works. König himself showed a ''copy'' of a 1707 letter from Leibniz to [[Jacob Hermann (mathematician)|Jacob Hermann]] with the principle, but the ''original'' letter has been lost. In contentious proceedings, König was accused of forgery,&lt;ref name="oco03" /&gt; and even the [[Frederick the Great|King of Prussia]] entered the debate, defending Maupertuis (the head of his Academy), while [[Voltaire]] defended König.{{Citation needed|date=July 2017}}

Euler, rather than claiming priority, was a staunch defender of Maupertuis, and Euler himself prosecuted König for forgery before the Berlin Academy on 13 April 1752.&lt;ref name="oco03" /&gt; The claims of forgery were re-examined 150 years later, and archival work by [[C.I. Gerhardt]] in 1898&lt;ref name="ger98" /&gt; and [[W. Kabitz]] in 1913&lt;ref name="kab13" /&gt; uncovered other copies of the letter, and three others cited by König, in the [[Bernoulli family|Bernoulli]] archives.

==Further development==

Euler continued to write on the topic; in his ''Reflexions sur quelques loix generales de la nature'' (1748), he called the quantity "effort". His expression corresponds to what we would now call [[potential energy]], so that his statement of least action in statics is equivalent to the principle that a system of bodies at rest will adopt a configuration that minimizes total potential energy.

===Lagrange and Hamilton===
{{main article|Hamilton's principle}}
Much of the calculus of variations was stated by [[Joseph-Louis Lagrange]] in 1760&lt;ref&gt;{{cite book|editor=D. J. Struik|title=A Source Book in Mathematics, 1200-1800|publisher=MIT Press|location=Cambridge, Mass|year=1969}} pp. 406-413&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Kline|first=Morris|title=Mathematical Thought from Ancient to Modern Times|publisher=Oxford University Press|location=New York|year=1972|isbn=0-19-501496-0}} pp. 582-589&lt;/ref&gt; and he proceeded to apply this to problems in dynamics. In ''Méchanique Analytique'' (1788) Lagrange derived the general [[Lagrangian equations of motion|equations of motion]] of a mechanical body.&lt;ref&gt;{{cite book|last=Lagrange|first=Joseph-Louis|title=Mécanique Analytique|year=1788}} p. 226&lt;/ref&gt;  [[William Rowan Hamilton]] in 1834 and 1835&lt;ref&gt;W. R. Hamilton, "On a General Method in Dynamics", ''Philosophical Transactions of the Royal Society'' [http://www.emis.de/classics/Hamilton/GenMeth.pdf Part I (1834) p.247-308]; [http://www.emis.de/classics/Hamilton/SecEssay.pdf Part II (1835) p. 95-144]. (''From the collection [http://www.emis.de/classics/Hamilton/ Sir William Rowan Hamilton (1805-1865): Mathematical Papers] edited by David R. Wilkins, School of Mathematics, Trinity College, Dublin 2, Ireland. (2000); also reviewed as [http://www.maths.tcd.ie/pub/HistMath/People/Hamilton/Dynamics/ On a General Method in Dynamics]'')&lt;/ref&gt; applied the variational principle to the classical [[Lagrangian mechanics|Lagrangian]] [[function (mathematics)|function]]

:&lt;math&gt;L=T-V&lt;/math&gt;

to obtain the [[Euler–Lagrange equations]] in their present form.

===Jacobi and Morse===
In 1842, [[Carl Gustav Jacobi]] tackled the problem of whether the variational principle always found minima as opposed to other [[stationary points]] (maxima or stationary [[saddle points]]); most of his work focused on [[geodesics]] on two-dimensional surfaces.&lt;ref&gt;G.C.J. Jacobi, ''Vorlesungen über Dynamik, gehalten an der Universität Königsberg im Wintersemester 1842-1843''. A. Clebsch (ed.) (1866); Reimer; Berlin. 290 pages, available online [http://math-doc.ujf-grenoble.fr/cgi-bin/oeitem?id=OE_JACOBI__8_1_0  Œuvres complètes volume '''8'''] at [http://math-doc.ujf-grenoble.fr/OEUVRES/ Gallica-Math] from the [http://gallica.bnf.fr/ Gallica Bibliothèque nationale de France].&lt;/ref&gt; The first clear general statements were given by [[Marston Morse]] in the 1920s and 1930s,&lt;ref&gt;Marston Morse (1934). "The Calculus of Variations in the Large", ''American Mathematical Society Colloquium Publication'' '''18'''; New York.&lt;/ref&gt; leading to what is now known as [[Morse theory]]. For example, Morse showed that the number of [[conjugate points]] in a trajectory equalled the number of negative eigenvalues in the second variation of the Lagrangian.

===Gauss and Hertz===
Other extremal principles of [[classical mechanics]] have been formulated, such as [[Gauss's principle of least constraint]] and its corollary, [[Hertz's principle of least curvature]].

==Disputes about possible teleological aspects==

The  mathematical equivalence of the [[differential equation|differential]] [[equations of motion]] and their [[integral equation|integral]]
counterpart has important philosophical implications.  The differential equations are statements about quantities localized to a single point in space or single moment of time.  For example, [[Newton's laws of motion|Newton's second law]]

:&lt;math&gt;\mathbf{F}=m\mathbf{a}&lt;/math&gt;

states that the ''instantaneous'' force '''F''' applied to a mass ''m'' produces an acceleration '''a''' at the same ''instant''.  By  contrast, the action principle is not localized to a point; rather, it involves integrals over an interval of time and (for fields) an extended region of space.  Moreover, in the usual formulation of [[classical physics|classical]] action principles, the initial and final states of the system are fixed, e.g.,

:''Given that the particle begins at position x&lt;sub&gt;1&lt;/sub&gt; at time t&lt;sub&gt;1&lt;/sub&gt; and ends at position x&lt;sub&gt;2&lt;/sub&gt; at time t&lt;sub&gt;2&lt;/sub&gt;, the physical trajectory that connects these two endpoints is an [[extremum]] of the action integral.''

In particular, the fixing of the ''final'' state has been interpreted as giving the action principle a [[teleology|teleological character]] which has been controversial historically. However, according to W. Yourgrau and S. Mandelstam, ''the teleological approach... presupposes that the variational principles themselves have mathematical characteristics which they ''de facto'' do not possess''&lt;ref name="Stöltzner1994"&gt;{{cite book|last=Stöltzner|first=Michael|title=Inside Versus Outside: Action Principles and Teleology|year=1994|publisher=Springer|isbn=978-3-642-48649-4|pages=33–62 |doi=10.1007/978-3-642-48647-0_3}}&lt;/ref&gt; In addition, some critics maintain this apparent [[teleology]] occurs because of the way in which the question was asked. By specifying some but not all aspects of both the initial and final conditions (the positions but not the velocities) we are making some inferences about the initial conditions from the final conditions, and it is this "backward" inference that can be seen as a teleological explanation. Teleology can also be overcome if we consider the classical description as a limiting case of the [[Quantum mechanics|quantum]] formalism of [[Path integral formulation|path integration]], in which stationary paths are obtained as a result of interference of amplitudes along all possible paths.&lt;ref name=":0" /&gt;

The short story ''[[Story of Your Life]]'' by the speculative fiction writer [[Ted Chiang]] contains visual depictions of [[Fermat's Principle]] along with a discussion of its teleological dimension. [[Keith Devlin]]'s ''The Math Instinct'' contains a chapter, "Elvis the Welsh Corgi Who Can Do Calculus" that discusses the calculus "embedded" in some animals as they solve the "least time" problem in actual situations.

==See also==
{{Div col|colwidth=}}
* [[Action (physics)]]
* [[Path integral formulation]]
* [[Schwinger's quantum action principle]]
* [[Path of least resistance]]
* [[Analytical mechanics]]
* [[Calculus of variations]]
* [[Hamiltonian mechanics]]
* [[Lagrangian mechanics]]
* [[Occam's razor]]
{{Div col end}}

==Notes and references==
{{reflist|30em}}

==External links==
{{wikiquote}}
* [http://www.eftaylor.com/software/ActionApplets/LeastAction.html Interactive explanation of the principle of least action]
* [http://www.eftaylor.com/software/ActionClockTicks/ Interactive applet to construct trajectories using principle of least action]
*{{cite book |doi=10.1007/978-3-642-28583-7_9 |chapter=A Quantitative Measure, Mechanism and Attractor for Self-Organization in Networked Complex Systems |title=Self-Organizing Systems |volume=7166 |pages=90–5 |series=Lecture Notes in Computer Science |year=2012 |last1=Georgiev |first1=Georgi Yordanov |isbn=978-3-642-28582-0 }}
* {{Cite journal|title=The Least Action and the Metric of an Organized System |journal=Open Systems and Information Dynamics |volume=9 |issue=4 |pages=371–380 |arxiv=1004.3518 |author1=Georgiev |first1=Georgi |last2=Georgiev |first2=Iskren |year=2002 |doi=10.1023/a:1021858318296}}
* {{cite arxiv |eprint=1511.03429|last1=Terekhovich|first1=Vladislav|title=Metaphysics of the Principle of Least Action|class=physics.hist-ph|year=2015}}

{{DEFAULTSORT:Principle Of Least Action}}
[[Category:Concepts in physics]]
[[Category:Calculus of variations]]
[[Category:History of physics]]
[[Category:Principles]]
[[Category:Scientific laws]]

[[de:Prinzip der kleinsten Wirkung]]
[[sq:Principi i Hamiltonit]]</text>
      <sha1>renk0m7te80orxvunzsyfj7qjnz9qp5</sha1>
    </revision>
  </page>
  <page>
    <title>Quasiidentity</title>
    <ns>0</ns>
    <id>12748025</id>
    <revision>
      <id>786788654</id>
      <parentid>618191838</parentid>
      <timestamp>2017-06-21T16:18:56Z</timestamp>
      <contributor>
        <ip>2600:8802:2203:3B00:290E:B436:704E:91A3</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1102">In [[universal algebra]], a '''quasi-identity''' is an implication of the form 

:''s''&lt;sub&gt;1&lt;/sub&gt; = ''t''&lt;sub&gt;1&lt;/sub&gt; ∧ … ∧ ''s''&lt;sub&gt;''n''&lt;/sub&gt; = ''t''&lt;sub&gt;''n''&lt;/sub&gt; → ''s'' = ''t'' 

where ''s&lt;sub&gt;1&lt;/sub&gt;, ..., s&lt;sub&gt;n&lt;/sub&gt;, s'' and ''t&lt;sub&gt;1&lt;/sub&gt;, ..., t&lt;sub&gt;n&lt;/sub&gt;,t'' are terms built up from variables using the operation symbols of the specified [[signature (logic)|signature]].

Quasi-identities amount to conditional equations for which the conditions themselves are equations.  A quasi-identity for which ''n'' = 0 is an ordinary [[Identity (mathematics)|identity]] or equation, whence quasi-identities are a generalization of identities. Quasi-identities are special type of [[Horn clause]]s.

== See also ==

[[Quasivariety]]

== References ==

* {{ cite book | last=Burris | first =Stanley N. |author2=H.P. Sankappanavar  | publisher=[[Springer Science+Business Media|Springer]] | title=A Course in Universal Algebra | year=1981 | isbn=3-540-90578-2 }} [http://www.thoralf.uwaterloo.ca/htdocs/ualg.html Free online edition].

[[Category:Universal algebra]]

{{algebra-stub}}</text>
      <sha1>kyj3138kykqjdfowthfwntrljr3t8e8</sha1>
    </revision>
  </page>
  <page>
    <title>Radial function</title>
    <ns>0</ns>
    <id>25242779</id>
    <revision>
      <id>733808653</id>
      <parentid>671638888</parentid>
      <timestamp>2016-08-10T07:12:41Z</timestamp>
      <contributor>
        <username>Jmcgnh</username>
        <id>28223823</id>
      </contributor>
      <comment>Disambiguated: [[spherical function]] → [[spherical harmonics]]  ([[WP:BPL|you can help]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2954">In [[mathematics]], a '''radial function''' is a [[function (mathematics)|function]] defined on a [[Euclidean space]] '''R'''&lt;sup&gt;''n''&lt;/sup&gt; whose value at each point depends only on the distance between that point and the origin.  For example, a radial function Φ in two dimensions has the form
:&lt;math&gt;\Phi(x,y) = \varphi(r), \quad r = \sqrt{x^2+y^2}&lt;/math&gt;
where φ is a function of a single non-negative real variable.  Radial functions are contrasted with [[spherical harmonics|spherical functions]], and any decent function (e.g., [[continuous function|continuous]] and [[rapidly decreasing]]) on Euclidean space can be decomposed into a series consisting of radial and spherical parts: the [[solid spherical harmonic]] expansion.

A function is radial [[if and only if]] it is invariant under all [[rotation]]s leaving the origin fixed.  That is, ''ƒ'' is radial if and only if
:&lt;math&gt;f\circ \rho = f\,&lt;/math&gt;
for all {{nowrap|&amp;rho; &amp;isin; SO(''n'')}}, the [[special orthogonal group]] in ''n'' dimensions.  This characterization of radial functions makes it possible also to define radial [[distribution (mathematics)|distributions]].  These are distributions ''S'' on '''R'''&lt;sup&gt;''n''&lt;/sup&gt; such that
:&lt;math&gt;S[\phi] = S[\varphi\circ\rho]&lt;/math&gt;
for every test function φ and rotation ρ.

Given any (locally integrable) function ''ƒ'', its radial part is given by averaging over spheres centered at the origin.  To wit,
:&lt;math&gt;\phi(x) = \frac{1}{\omega_{n-1}}\int_{S^{n-1}} f(rx')\,dx'&lt;/math&gt;
where ω&lt;sub&gt;''n''&amp;minus;1&lt;/sub&gt; is the surface area of the [[N sphere|(''n''&amp;minus;1)-sphere]] ''S''&lt;sup&gt;''n''&amp;minus;1&lt;/sup&gt;, and {{nowrap|1=''r'' = {{abs|''x''}}}}, {{nowrap|1=''x''&amp;prime; = ''x''/r}}.  It follows essentially by [[Fubini's theorem]] that a locally integrable function has a well-defined radial part at [[almost every]] ''r''.

The [[Fourier transform]] of a radial function is also radial, and so radial functions play a vital role in [[Fourier analysis]].  Furthermore, the Fourier transform of a radial function typically has stronger decay behavior at infinity than non-radial functions: for radial functions bounded in a neighborhood of the origin, the Fourier transform decays faster than ''R''&lt;sup&gt;&amp;minus;(''n''&amp;minus;1)/2&lt;/sup&gt;.  The [[Bessel functions]] are a special class of radial function that arise naturally in Fourier analysis as the radial [[eigenfunction]]s of the [[Laplacian]]; as such they appear naturally as the radial portion of the Fourier transform.

==See also==
* [[Radial basis function]]

==References==
*{{citation|last1=Stein|first1=Elias|authorlink1=Elias Stein|first2=Guido|last2=Weiss|authorlink2=Guido Weiss|title=Introduction to Fourier Analysis on Euclidean Spaces|publisher=Princeton University Press|year=1971|isbn=978-0-691-08078-9|location=Princeton, N.J.}}.

{{DEFAULTSORT:Radial Function}}
[[Category:Harmonic analysis]]
[[Category:Rotational symmetry]]
[[Category:Types of functions]]</text>
      <sha1>kzswgfsveufhnqbimb4knttbiqogf6h</sha1>
    </revision>
  </page>
  <page>
    <title>Regularization by spectral filtering</title>
    <ns>0</ns>
    <id>41323011</id>
    <revision>
      <id>790774602</id>
      <parentid>681164507</parentid>
      <timestamp>2017-07-16T00:13:02Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Filter function for Landweber iteration */LaTeX spacing clean up, replaced: \, &lt;/math&gt; → &lt;/math&gt; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11813">'''Spectral regularization''' is any of a class of [[Regularization (mathematics)|regularization]] techniques used in [[machine learning]] to control the impact of noise and prevent [[overfitting]]. Spectral regularization can be used in a broad range of applications, from deblurring images to classifying emails into a spam folder and a non-spam folder. For instance, in the email classification example, spectral regularization can be used to reduce the impact of noise and prevent overfitting when a machine learning system is being trained on a labeled set of emails to learn how to tell a spam and a non-spam email apart.

Spectral regularization algorithms rely on methods that were originally defined and studied in the theory of [[Ill-posed problem|ill-posed]] [[inverse problem]]s (for instance, see&lt;ref&gt;[[Heinz Engl|H. W. Engl]], M. Hanke, and A. Neubauer. ''Regularization of inverse problems''. Kluwer, 1996.&lt;/ref&gt;) focusing on the inversion of a linear operator (or a matrix) that possibly has a bad [[condition number]] or an unbounded inverse. In this context, regularization amounts to substituting the original operator by a bounded operator called the "regularization operator" that has a condition number controlled by a regularization parameter,&lt;ref name="rosasco"&gt;L. Lo Gerfo, L. Rosasco, F. Odone, E. De Vito, and A. Verri. Spectral Algorithms for Supervised Learning, ''Neural Computation'', 20(7), 2008.&lt;/ref&gt; a classical example being [[Tikhonov regularization]]. To ensure stability, this regularization parameter is tuned based on the level of noise.&lt;ref name="rosasco" /&gt; The main idea behind spectral regularization is that each regularization operator can be described using spectral calculus as an appropriate filter on the eigenvalues of the operator that defines the problem, and the role of the filter is to "suppress the oscillatory behavior corresponding to small eigenvalues".&lt;ref name="rosasco" /&gt; Therefore, each algorithm in the class of spectral regularization algorithms is defined by a suitable filter function (which needs to be derived for that particular algorithm). Three of the most commonly used regularization algorithms for which spectral filtering is well-studied are Tikhonov regularization, [[Landweber iteration]], and [[Singular value decomposition#Reduced SVDs|truncated singular value decomposition]] (TSVD). As for choosing the regularization parameter, examples of candidate methods to compute this parameter include the discrepancy principle, generalized [[Cross-validation (statistics)|cross validation]], and the L-curve criterion.&lt;ref&gt;P. C. Hansen, J. G. Nagy, and D. P. O'Leary. ''Deblurring Images: Matrices, Spectra, and Filtering'', Fundamentals of Algorithms 3, SIAM, Philadelphia, 2006.&lt;/ref&gt;

It is of note that the notion of spectral filtering studied in the context of machine learning is closely connected to the literature on [[function approximation]] (in signal processing).

== Notation ==
The training set is defined as &lt;math&gt;S = \{(x_1, y_1), \dots , (x_n, y_n)\}&lt;/math&gt;, where &lt;math&gt;X&lt;/math&gt; is the &lt;math&gt;n \times d&lt;/math&gt; input matrix and &lt;math&gt;Y = (y_1,\dots,y_n)&lt;/math&gt; is the output vector. Where applicable, the kernel function is denoted by &lt;math&gt;k&lt;/math&gt;, and the &lt;math&gt;n \times n&lt;/math&gt; kernel matrix is denoted by &lt;math&gt;K&lt;/math&gt; which has entries &lt;math&gt;K_{ij} = k(x_i,x_j)&lt;/math&gt; and &lt;math&gt;\mathcal{H}&lt;/math&gt; denotes the [[RKHS|Reproducing Kernel Hilbert Space]] (RKHS) with kernel &lt;math&gt;k&lt;/math&gt;. The regularization parameter is denoted by &lt;math&gt;\lambda&lt;/math&gt;.

''(Note: For &lt;math&gt;g \in G&lt;/math&gt; and &lt;math&gt;f \in F&lt;/math&gt;, with &lt;math&gt;G&lt;/math&gt; and &lt;math&gt;F&lt;/math&gt; being Hilbert spaces, given a linear, continuous operator &lt;math&gt;L&lt;/math&gt;, assume that &lt;math&gt;g = Lf&lt;/math&gt; holds. In this setting, the direct problem would be to solve for &lt;math&gt;g&lt;/math&gt; given &lt;math&gt;f&lt;/math&gt; and the inverse problem would be to solve for &lt;math&gt;f&lt;/math&gt; given &lt;math&gt;g&lt;/math&gt;. If the solution exists, is unique and stable, the inverse problem (i.e. the problem of solving for &lt;math&gt;f&lt;/math&gt;) is well-posed; otherwise, it is ill-posed.) ''

== Relation to the theory of ill-posed inverse problems ==
The connection between the regularized least squares (RLS) estimation problem (Tikhonov regularization setting) and the theory of ill-posed inverse problems is an example of how spectral regularization algorithms are related to the theory of ill-posed inverse problems.

The RLS estimator solves

: &lt;math&gt; \min_{f\in\mathcal{H}} \frac{1}{n}\sum_{i=1}^{n}(y_i-f(x_i))^2+\lambda \|f\|^2_\mathcal{H}&lt;/math&gt;

and the RKHS allows for expressing this RLS estimator as &lt;math&gt;f_S^\lambda (X)=\sum_{i=1}^n c_i k(x,x_i)&lt;/math&gt; where &lt;math&gt;(K+n\lambda I)c=Y&lt;/math&gt; with &lt;math&gt;c=(c_1,\dots,c_n)&lt;/math&gt;.&lt;ref name="BB"&gt;L. Rosasco. Lecture 6 of the Lecture Notes for 9.520: Statistical Learning Theory and Applications. Massachusetts Institute of Technology, Fall 2013. Available at http://www.mit.edu/~9.520/fall13/slides/class06/class06_RLSSVM.pdf&lt;/ref&gt; The penalization term is used for controlling smoothness and preventing overfitting. Since the solution of empirical risk minimization &lt;math&gt; \min_{f\in\mathcal{H}} \frac{1}{n}\sum_{i=1}^{n}(y_i-f(x_i))^2&lt;/math&gt; can be written as &lt;math&gt;f_S^{\lambda}(X)=\sum_{i=1}^n c_i k(x,x_i)&lt;/math&gt; such that &lt;math&gt;Kc=Y&lt;/math&gt;, adding the penalty function amounts to the following change in the system that needs to be solved:&lt;ref name="AA"&gt;L. Rosasco. Lecture 7 of the Lecture Notes for 9.520: Statistical Learning Theory and Applications. Massachusetts Institute of Technology, Fall 2013. Available at http://www.mit.edu/~9.520/fall13/slides/class07/class07_spectral.pdf&lt;/ref&gt;

: &lt;math&gt;\bigg\{ \min_{f\in\mathcal{H}} \frac{1}{n}\sum_{i=1}^n (y_i-f(x_i))^2\rightarrow \min_{f\in\mathcal{H}} \frac{1}{n}\sum_{i=1}^n (y_i-f(x_i))^2+\lambda \|f\|^2_\mathcal{H}\bigg\}\equiv \bigg\{Kc=Y\rightarrow (K+n\lambda I)c=Y\bigg\}.&lt;/math&gt;

In this learning setting, the kernel matrix can be decomposed as &lt;math&gt;K = Q\Sigma Q^T&lt;/math&gt;, with

: &lt;math&gt;\sigma = \operatorname{diag}(\sigma_1,\dots,\sigma_n),~\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_n \geq 0&lt;/math&gt;

and &lt;math&gt;q_1,\dots,q_n&lt;/math&gt; are the corresponding eigenvectors. Therefore, in the initial learning setting, the following holds:

: &lt;math&gt;c=K^{-1}Y=Q\Sigma^{-1}Q^TY=\sum_{i=1}^n \frac{1}{\sigma_i} \langle q_i,Y \rangle q_i.&lt;/math&gt;

Thus, for small eigenvalues, even small perturbations in the data can lead to considerable changes in the solution. Hence, the problem is ill-conditioned, and solving this RLS problem amounts to stabilizing a possibly ill-conditioned matrix inversion problem, which is studied in the theory of ill-posed inverse problems; in both problems, a main concern is to deal with the issue of numerical stability.

== Implementation of algorithms ==
Each algorithm in the class of spectral regularization algorithms is defined by a suitable filter function, denoted here by &lt;math&gt;G_{\lambda}(\cdot)&lt;/math&gt;. If the Kernel matrix is denoted by &lt;math&gt;K&lt;/math&gt;, then &lt;math&gt;\lambda&lt;/math&gt; should control the magnitude of the smaller eigenvalues of &lt;math&gt;G_{\lambda}(K)&lt;/math&gt;. In a filtering setup, the goal is to find estimators &lt;math&gt;f_S^{\lambda}(X):=\sum_{i=1}^n c_i k(x,x_i)&lt;/math&gt; where &lt;math&gt;c=G_{\lambda}(K)Y&lt;/math&gt;. To do so, a scalar filter function &lt;math&gt;G_\lambda(\sigma)&lt;/math&gt; is defined using the eigen-decomposition of the kernel matrix:

: &lt;math&gt;G_\lambda(K)=QG_{\lambda}(\Sigma)Q^T,&lt;/math&gt;

which yields

: &lt;math&gt;G_{\lambda}(K)Y~=~\sum_{i=1}^{n}G_{\lambda}(\sigma_i) \langle q_i,Y\rangle q_i.&lt;/math&gt;

Typically, an appropriate filter function should have the following properties:&lt;ref name="AA" /&gt;

1. As &lt;math&gt;\lambda&lt;/math&gt; goes to zero, &lt;math&gt;G_\lambda (\sigma)~\rightarrow ~1/\sigma&lt;/math&gt;.

2. The magnitude of the (smaller) eigenvalues of &lt;math&gt;G_{\lambda}&lt;/math&gt; is controlled by &lt;math&gt;\lambda&lt;/math&gt;.

While the above items give a rough characterization of the general properties of filter functions for all spectral regularization algorithms, the derivation of the filter function (and hence its exact form) varies depending on the specific regularization method that spectral filtering is applied to.

=== Filter function for Tikhonov regularization ===
In the Tikhonov regularization setting, the filter function for RLS is described below. As shown in,&lt;ref name="BB" /&gt; in this setting, &lt;math&gt;c=(K+n\lambda I)^{-1}Y&lt;/math&gt;. Thus,

: &lt;math&gt;c=(K+n\lambda I)^{-1}Y=Q(\Sigma+n\lambda I)^{-1}Q^T Y=\sum_{i=1}^n \frac{1}{\sigma_i+n\lambda}&lt;q_i,Y&gt;q_i.&lt;/math&gt;

The undesired components are filtered out using regularization:
* If &lt;math&gt;\sigma \gg \lambda n&lt;/math&gt;, then &lt;math&gt; \frac{1}{\sigma_i+n\lambda} \sim  \frac{1}{\sigma_i}&lt;/math&gt;.
* If &lt;math&gt;\sigma \ll \lambda n&lt;/math&gt;, then &lt;math&gt; \frac{1}{\sigma_i+n\lambda} \sim \frac{1}{\lambda n}&lt;/math&gt;.
The filter function for Tikhonov regularization is therefore defined as:&lt;ref name="AA" /&gt;

&lt;math&gt;G_\lambda (\sigma)=\frac{1}{\sigma+n\lambda }.&lt;/math&gt;

=== Filter function for Landweber iteration ===
The idea behind the Landweber iteration is [[gradient descent]]:&lt;ref name="AA" /&gt;

: &lt;math&gt;c^0 =0 &lt;/math&gt;

: &lt;math&gt;\text{for } i=1,\dots,t-1 &lt;/math&gt;

: &lt;math&gt;~~~~~          c^i=c^{i-1}+\eta(Y-Kc^{i-1})&lt;/math&gt;

: &lt;math&gt; \mathrm{end} &lt;/math&gt;

In this setting, if &lt;math&gt;n&lt;/math&gt; is larger than &lt;math&gt;K&lt;/math&gt;'s largest eigenvalue, the above iteration converges by choosing &lt;math&gt;\eta = 2/n&lt;/math&gt; as the step-size:.&lt;ref name="AA" /&gt; The above iteration is equivalent to minimizing &lt;math&gt;\frac{1}{n}||Y-Kc||_2^2&lt;/math&gt; (i.e. the empirical risk) via gradient descent; using induction, it can be proved that at the &lt;math&gt;t&lt;/math&gt;-th iteration, the solution is given by  &lt;ref name="AA" /&gt;

: &lt;math&gt;c=\eta\sum_{i=0}^{t-1}(I-\eta K)^iY.&lt;/math&gt;

Thus, the appropriate filter function is defined by:

&lt;math&gt;G_\lambda(\sigma)=\eta\sum_{i=0}^{t-1}(I-\eta\sigma)^i. &lt;/math&gt;

It can be shown that this filter function corresponds to a truncated power expansion of &lt;math&gt;K^{-1}&lt;/math&gt;;&lt;ref name="AA" /&gt; to see this, note that the relation &lt;math&gt;\sum_{i\geq0} x^i = 1/(1 - x)&lt;/math&gt;, would still hold if &lt;math&gt;x&lt;/math&gt; is replaced by a matrix; thus, if &lt;math&gt;K&lt;/math&gt; (the kernel matrix), or rather &lt;math&gt;I - \eta K&lt;/math&gt;, is considered, the following holds:

: &lt;math&gt;K^{-1}=\eta\sum_{i=0}^\infty (I-\eta K)^i \sim \eta\sum_{i=0}^{t-1}(I-\eta K)^i.&lt;/math&gt;

In this setting, the number of iterations gives the regularization parameter; roughly speaking, &lt;math&gt;t \sim 1/\lambda&lt;/math&gt;.&lt;ref name="AA" /&gt; If &lt;math&gt;t&lt;/math&gt; is large, overfitting may be a concern. If &lt;math&gt;t&lt;/math&gt; is small, oversmoothing may be a concern. Thus, choosing an appropriate time for early stopping of the iterations provides a regularization effect.

=== Filter function for TSVD ===
In the TSVD setting, given the eigen-decomposition &lt;math&gt;K = Q\Sigma Q^T&lt;/math&gt; and using a prescribed threshold &lt;math&gt;\lambda n&lt;/math&gt;, a regularized inverse can be formed for the kernel matrix by discarding all the eigenvalues that are smaller than this threshold.&lt;ref name="AA" /&gt;
Thus, the filter function for TSVD can be defined as

: &lt;math&gt;G_\lambda(\sigma) =\left\{\begin{array}[c]{lcll}1/\sigma &amp; ,&amp; \text{if }\sigma\geq\lambda n\\[0.05in]0&amp;,&amp; \text{otherwise}\\[0.05in]\end{array}\right..&lt;/math&gt;

It can be shown that TSVD is equivalent to the (unsupervised) projection of the data using (kernel) [[Principal component analysis|Principal Component Analysis]] (PCA), and that it is also equivalent to minimizing the empirical risk on the projected data (without regularization).&lt;ref name="AA" /&gt; Note that the number of components kept for the projection is the only free parameter here.

== References ==
{{reflist}}

[[Category:Mathematical analysis]]
[[Category:Inverse problems]]
[[Category:Computer engineering]]</text>
      <sha1>8p52sr0yw0zpx8ibpke32ll09js017v</sha1>
    </revision>
  </page>
  <page>
    <title>Rolle's theorem</title>
    <ns>0</ns>
    <id>200305</id>
    <revision>
      <id>871519343</id>
      <parentid>871519216</parentid>
      <timestamp>2018-12-01T17:10:51Z</timestamp>
      <contributor>
        <username>Joel B. Lewis</username>
        <id>13974845</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/2405:204:1093:561C:5417:6A4:F19D:C173|2405:204:1093:561C:5417:6A4:F19D:C173]] ([[User talk:2405:204:1093:561C:5417:6A4:F19D:C173|talk]]) to last revision by Joel B. Lewis. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14513">{{Calculus}}
[[File:RTCalc.svg|thumb|300 px|right|If a [[real number|real]]-valued function {{mvar|f}} is [[continuous function|continuous]] on a [[closed interval]] {{math|[''a'', ''b'']}}, [[derivative|differentiable]] on the [[open interval]] {{math|(''a'', ''b'')}}, and {{math|''f&amp;thinsp;''(''a'') {{=}} ''f&amp;thinsp;''(''b'')}}, then there exists a {{mvar|c}} in the open interval {{math|(''a'', ''b'')}} such that {{math|''f&amp;thinsp;''′(''c'') {{=}} 0}}.]]

In [[calculus]], '''Rolle's theorem''' or '''Rolle's lemma''' essentially states that any real-valued [[differentiable function]] that attains equal values at two distinct points must have at least one [[stationary point]] somewhere between them—that is, a point where the first derivative (the slope of the tangent line to the graph of the function) is zero.

== Standard version of the theorem ==

If  a [[real number|real]]-valued function {{mvar|f}} is [[continuous function|continuous]] on a proper [[closed interval]] {{math|[''a'',&amp;nbsp;''b'']}}, [[Differentiable function|differentiable]] on the [[open interval]] {{math|(''a'', ''b'')}}, and {{math|''f&amp;thinsp;''(''a'') {{=}} ''f&amp;thinsp;''(''b'')}}, then there exists at least one {{mvar|c}} in the open interval {{math|(''a'', ''b'')}} such that

:&lt;math&gt;f'(c) = 0&lt;/math&gt;.

This version of Rolle's theorem is used to prove the [[mean value theorem]], of which Rolle's theorem is indeed a special case. It is also the basis for the proof of [[Taylor's theorem]].

== History ==
Indian mathematician [[Bhāskara II]] (1114–1185) is credited with knowledge of Rolle's theorem.&lt;ref&gt;{{cite book |first=R. C. |last=Gupta |title=Encyclopaedia of the History of Science, Technology, and Medicine in Non-Western Cultures |page=156 |url=https://books.google.com/books?id=raKRY3KQspsC&amp;pg=PA156 }}&lt;/ref&gt; Although the theorem is named after [[Michel Rolle]], Rolle's 1691 proof covered only the case of polynomial functions. His proof did not use the methods of differential calculus, which at that point in his life he considered to be fallacious. The theorem was first proved by [[Augustin-Louis Cauchy|Cauchy]] in 1823 as a corollary of a proof of the [[mean value theorem]].&lt;ref&gt;{{cite web |first=A. |last=Besenyei |title=A brief history of the mean value theorem |work= |date=September 17, 2012 |url=https://abesenyei.web.elte.hu/publications/meanvalue.pdf }}&lt;/ref&gt; The name "Rolle's theorem" was first used by [[Moritz Wilhelm Drobisch]] of Germany in 1834 and by [[Giusto Bellavitis]] of Italy in 1846.&lt;ref&gt;See {{cite book |first=Florian |last=Cajori |authorlink=Florian Cajori |title=A History of Mathematics |page=224 |url=https://books.google.com/books?id=mGJRjIC9fZgC&amp;pg=RA1-PA119-IA5 }}&lt;/ref&gt;

== Examples ==

===First example===
[[File:semicircle.svg|thumb|300px|A '''semicircle''' of radius {{mvar|r}}.]]
For a radius {{math|''r'' &gt; 0}}, consider the function

:&lt;math&gt;f(x)=\sqrt{r^2-x^2},\quad x\in[-r,r].&lt;/math&gt;

Its [[graph of a function|graph]] is the upper [[semicircle]] centered at the origin. This function is continuous on the closed interval {{math|[−''r'', ''r'']}} and differentiable in the open interval {{math|(−''r'', ''r'')}}, but not differentiable at the endpoints {{math|−''r''}} and {{mvar|r}}. Since {{math|''f&amp;thinsp;''(−''r'') {{=}} ''f&amp;thinsp;''(''r'')}}, Rolle's theorem applies, and indeed, there is a point where the derivative of {{mvar|f}} is zero. Note that the theorem applies even when the function cannot be differentiated at the endpoints because it only requires the function to be differentiable in the open interval.

{{clear}}&lt;!--This break ensures that the text of the next section is clear of the image in the current section--&gt;

===Second example===
[[File:Absolute value.svg|thumb|300px|The graph of the absolute value function.]]
If differentiability fails at an interior point of the interval, the conclusion of Rolle's theorem may not hold. Consider the [[absolute value]] function

:&lt;math&gt;f(x) = |x|,\qquad x\in[-1,1].&lt;/math&gt;

Then {{math|''f&amp;thinsp;''(−1) {{=}} ''f&amp;thinsp;''(1)}}, but there is no {{mvar|c}} between −1 and 1 for which the {{math|''f&amp;thinsp;''′(''c'')}} is zero. This is because that function, although continuous, is not differentiable at {{math|''x'' {{=}} 0}}. Note that the derivative of {{mvar|f}} changes its sign at {{math|''x'' {{=}} 0}}, but without attaining the value 0. The theorem cannot be applied to this function because it does not satisfy the condition that the function must be differentiable for every {{mvar|x}} in the open interval. However, when the differentiability requirement is dropped from Rolle's theorem, {{mvar|f}} will still have a [[critical number]] in the open interval {{math|(''a'', ''b'')}}, but it may not yield a horizontal tangent (as in the case of the absolute value represented in the graph).

{{clear}}&lt;!--This break ensures that the text of the next section is clear of the image in the current section--&gt;

== Generalization ==

The second example illustrates the following generalization of Rolle's theorem:

Consider a real-valued, continuous function {{mvar|f}} on a closed interval {{math|[''a'', ''b'']}} with {{math|''f&amp;thinsp;''(''a'') {{=}} ''f&amp;thinsp;''(''b'')}}. If for every {{mvar|x}} in the open interval {{math|(''a'', ''b'')}} the [[One-sided limit|right-hand limit]]

:&lt;math&gt;f'(x^+):=\lim_{h \to 0^+}\frac{f(x+h)-f(x)}{h}&lt;/math&gt;

and the left-hand limit

:&lt;math&gt;f'(x^-):=\lim_{h \to 0^-}\frac{f(x+h)-f(x)}{h}&lt;/math&gt;

exist in the [[extended real line]] {{math|[−∞, ∞]}}, then there is some number {{mvar|c}} in the open interval {{math|(''a'', ''b'')}} such that one of the two limits

:&lt;math&gt;f'(c^+)\quad\text{and}\quad f'(c^-)&lt;/math&gt;

is ≥&amp;nbsp;0 and the other one is ≤&amp;nbsp;0 (in the extended real line). If the right- and left-hand limits agree for every {{mvar|x}}, then they agree in particular for {{mvar|c}}, hence the derivative of {{mvar|f}} exists at {{mvar|c}} and is equal to zero.

===Remarks===
*If {{mvar|f}} is convex or concave, then the right- and left-hand derivatives exist at every inner point, hence the above limits exist and are real numbers.
*This generalized version of the theorem is sufficient to prove [[Convex function|convexity]] when the one-sided derivatives are [[monotonically increasing]]:&lt;ref&gt;{{citation |last=Artin |first=Emil |authorlink=Emil Artin |translator-first= Michael |translator-last= Butler |title=The Gamma Function |origyear=1931 |year=1964 |publisher=[[Henry Holt and Company|Holt, Rinehart and Winston]] |pages=3–4}}&lt;/ref&gt;

::&lt;math&gt;f'(x^-) \le f'(x^+) \le f'(y^-),\qquad x &lt; y.&lt;/math&gt;

== Proof of the generalized version ==

Since the proof for the standard version of Rolle's theorem and the generalization are very similar, we prove the generalization.

The idea of the proof is to argue that if {{math|''f&amp;thinsp;''(''a'') {{=}} ''f&amp;thinsp;''(''b'')}}, then {{mvar|f}} must attain either [[maxima and minima|a maximum or a minimum]] somewhere between {{mvar|a}} and {{mvar|b}}, say at {{mvar|c}}, and the function must change from increasing to decreasing (or the other way around) at {{mvar|c}}. In particular, if the derivative exists, it must be zero at {{mvar|c}}.

By assumption, {{mvar|f}} is continuous on {{math|[''a'', ''b'']}}, and by the [[extreme value theorem]] attains both its maximum and its minimum in {{math|[''a'', ''b'']}}. If these are both attained at the endpoints of {{math|[''a'', ''b'']}}, then {{mvar|f}} is [[constant function|constant]] on {{math|[''a'', ''b'']}} and so the derivative of {{mvar|f}} is zero at every point in {{math|(''a'', ''b'')}}.

Suppose then that the maximum is obtained at an [[interior point]] {{mvar|c}} of {{math|(''a'', ''b'')}} (the argument for the minimum is very similar, just consider {{math|−''f&amp;thinsp;''}}). We shall examine the above right- and left-hand limits separately.

For a real {{mvar|h}} such that {{math|''c'' + ''h''}} is in {{math|[''a'', ''b'']}}, the value {{math|''f&amp;thinsp;''(''c'' + ''h'')}} is smaller or equal to {{math|''f&amp;thinsp;''(''c'')}} because {{mvar|f}} attains its maximum at {{mvar|c}}. Therefore, for every {{math|''h'' &gt; 0}},

:&lt;math&gt;\frac{f(c+h)-f(c)}{h}\le0,&lt;/math&gt;

hence

:&lt;math&gt;f'(c^+):=\lim_{h \to 0^+}\frac{f(c+h)-f(c)}{h}\le0,&lt;/math&gt;

where the limit exists by assumption, it may be minus infinity.
 
Similarly, for every {{math|''h'' &lt; 0}}, the inequality turns around because the denominator is now negative and we get

:&lt;math&gt;\frac{f(c+h)-f(c)}{h}\ge0,&lt;/math&gt;

hence

:&lt;math&gt;f'(c^-):=\lim_{h \to 0^-}\frac{f(c+h)-f(c)}{h}\ge0,&lt;/math&gt;

where the limit might be plus infinity.

Finally, when the above right- and left-hand limits agree (in particular when {{mvar|f}} is differentiable), then the derivative of {{mvar|f}} at {{mvar|c}} must be zero.

(Alternatively, we can apply [[Fermat's theorem (stationary points)|Fermat's stationary point theorem]] directly.)

== Generalization to higher derivatives ==

We can also generalize Rolle's theorem by requiring that {{mvar|f}} has more points with equal values and greater regularity.  Specifically, suppose that
* the function {{mvar|f}} is {{math|''n'' − 1}} times [[Smoothness#Differentiability_classes|continuously differentiable]] on the closed interval {{math|[''a'', ''b'']}} and the {{mvar|n}}th derivative exists on the open interval {{math|(''a'', ''b'')}}, and
* there are {{mvar|n}} intervals given by {{math|''a''&lt;sub&gt;1&lt;/sub&gt; &lt; ''b''&lt;sub&gt;1&lt;/sub&gt; ≤ ''a''&lt;sub&gt;2&lt;/sub&gt; &lt; ''b''&lt;sub&gt;2&lt;/sub&gt; ≤ … ≤ ''a&lt;sub&gt;n&lt;/sub&gt;'' &lt; ''b&lt;sub&gt;n&lt;/sub&gt;''}} in {{math|[''a'', ''b'']}} such that {{math|''f&amp;thinsp;''(''a&lt;sub&gt;k&lt;/sub&gt;'') {{=}} ''f&amp;thinsp;''(''b&lt;sub&gt;k&lt;/sub&gt;'')}} for every {{mvar|k}} from 1 to {{mvar|n}}. Then there is a number {{mvar|c}} in {{math|(''a'', ''b'')}} such that the {{mvar|n}}th derivative of {{mvar|f}} at {{mvar|c}} is zero.
[[File:Rolle Generale.svg|thumb|290x290px|The red curve is the graph of function with 3 roots in the interval {{math|[−3, 2]}}. Thus its second derivative (graphed in green) also has a root in the same interval.]]

The requirements concerning the {{mvar|n}}th derivative of {{mvar|f}} can be weakened as in the generalization above, giving the corresponding (possibly weaker) assertions for the right- and left-hand limits defined above with {{math|''f&amp;thinsp;''{{isup|(''n'' − 1)}}}} in place of {{mvar|f}}.

Particularly, this version of the theorem asserts that if a function differentiable enough times has {{mvar|n}} roots (so they have the same value, that is 0), then there is an internal point where {{math|''f&amp;thinsp;''{{isup|(''n'' − 1)}}}} vanishes.

===Proof===
The proof uses [[mathematical induction]]. The case {{math|''n'' {{=}} 1}} is simply the standard version of Rolle's theorem. As the induction hypothesis, assume the generalization is true for {{math|''n'' − 1}}. We want to prove it for {{math|''n'' &gt; 1}}. By the standard version of Rolle's theorem, for every integer {{mvar|k}} from 1 to {{mvar|n}}, there exists a {{mvar|c&lt;sub&gt;k&lt;/sub&gt;}} in the open interval {{math|(''a&lt;sub&gt;k&lt;/sub&gt;'', ''b&lt;sub&gt;k&lt;/sub&gt;'')}} such that {{math|''f&amp;thinsp;''′(''c&lt;sub&gt;k&lt;/sub&gt;'') {{=}} 0}}. Hence, the first derivative satisfies the assumptions on the {{math|''n'' − 1}} closed intervals {{math|[''c''&lt;sub&gt;1&lt;/sub&gt;, ''c''&lt;sub&gt;2&lt;/sub&gt;], …, [''c''&lt;sub&gt;''n'' − 1&lt;/sub&gt;, ''c&lt;sub&gt;n&lt;/sub&gt;'']}}. By the induction hypothesis, there is a {{mvar|c}} such that the {{math|(''n'' − 1)}}st derivative of {{math|''f&amp;thinsp;''′}} at {{mvar|c}} is zero.

== Generalizations to other fields ==
Rolle's theorem is a property of differentiable functions over the real numbers, which are an [[ordered field]]. As such, it does not generalize to other [[field (mathematics)|fields]], but the following corollary does: if a real polynomial factors (has all of its roots) over the real numbers, then its derivative does as well. One may call this property of a field '''Rolle's property'''.{{citation needed|date=September 2018}} More general fields do not always have differentiable functions, but they do always have polynomials, which can be symbolically differentiated. Similarly, more general fields may not have an order, but one has a notion of a root of a polynomial lying in a field.

Thus Rolle's theorem shows that the real numbers have Rolle's property.  Any algebraically closed field such as the [[complex numbers]] has Rolle's property. However, the rational numbers do not – for example, {{math|''x''&lt;sup&gt;3&lt;/sup&gt; − ''x'' {{=}} ''x''(''x'' − 1)(''x'' + 1)}} factors over the [[rational numbers|rationals]], but its derivative,
:&lt;math&gt;3x^2-1 = 3 \left (x-\tfrac{1}{\sqrt 3} \right ) \left (x+\tfrac{1}{\sqrt 3} \right ) ,&lt;/math&gt;
does not. The question of which fields satisfy Rolle's property was raised in {{Harv|Kaplansky|1972}}. For [[finite field]]s, the answer is that only {{math|'''F'''&lt;sup&gt;2&lt;/sup&gt;}} and {{math|'''F'''&lt;sup&gt;4&lt;/sup&gt;}} have Rolle's property; this was first proven via technical means in {{Harv|Craven|Csordas|1977}}, and a simple proof is given in {{Harv|Ballantine|Roberts|2002}}.

For a complex version, see [[Voorhoeve index]].

== See also ==
*[[Mean value theorem]]
*[[Intermediate value theorem]]
*[[Linear interpolation]]
*[[Gauss–Lucas theorem]]

== Notes ==
{{reflist}}

== References ==
{{refbegin}}
* {{ Citation | first = Irving | last = Kaplansky | authorlink = Irving Kaplansky | title = Fields and Rings | year = 1972 }}
* {{ Citation | title = Multiplier sequences for fields | first1 = Thomas | last1 = Craven | first2 = George | last2 = Csordas | journal = Illinois J. Math. | volume = 21 | year = 1977 | pages = 801–817 | url = http://projecteuclid.org/euclid.ijm/1256048929 | issue = 4 }}
* {{ Citation | title = A Simple Proof of Rolle's Theorem for Finite Fields | first1 = C. | last1 = Ballantine | first2 = J. | last2 = Roberts | journal = [[The American Mathematical Monthly]] | volume = 109 |date=January 2002 | pages = 72–74 | issue = 1 | doi = 10.2307/2695770 | jstor = 2695770 | publisher = Mathematical Association of America }}
{{refend}}

== External links ==
* {{springer|title=Rolle theorem|id=p/r082550}}
* [http://www.cut-the-knot.org/Curriculum/Calculus/MVT.shtml Rolle's and Mean Value Theorems] at [[cut-the-knot]].
* [[Mizar system]] proof: http://mizar.org/version/current/html/rolle.html#T2

{{Commons category|Rolle's theorem}}

{{DEFAULTSORT:Rolle's Theorem}}
[[Category:Theorems in real analysis]]
[[Category:Articles containing proofs]]
[[Category:Theorems in calculus]]</text>
      <sha1>huqohp8nm5ak4tcpsgdxk0ah6z52kf5</sha1>
    </revision>
  </page>
  <page>
    <title>Space group</title>
    <ns>0</ns>
    <id>463721</id>
    <revision>
      <id>865903962</id>
      <parentid>865903872</parentid>
      <timestamp>2018-10-26T23:12:17Z</timestamp>
      <contributor>
        <username>HickoryOughtShirt?4</username>
        <id>32314202</id>
      </contributor>
      <comment>Reverted to revision 865849499 by [[Special:Contributions/GGG33|GGG33]] ([[User talk:GGG33|talk]]): This doesnt seem constructive . ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="45654">[[File:Ice Ih Space Group.jpg|thumb|500px|The space group of hexagonal H{{sub|2}}O ice is P6{{sub|3}}/''mmc''. The first ''m'' indicates the mirror plane perpendicular to the c-axis (a), the second ''m'' indicates the mirror planes parallel to the c-axis (b), and the ''c'' indicates the glide planes (b) and (c). The black boxes outline the unit cell.]]

In [[mathematics]], [[physics]] and [[chemistry]], a '''space group''' is the [[symmetry group]] of a configuration in space, usually in [[three dimensions]].&lt;ref&gt;{{cite journal|author=Hiller, Howard|title=Crystallography and cohomology of groups|journal=Amer. Math. Monthly|volume=93|issue=10|year=1986|pages=765–779|url=http://www.maa.org/programs/maa-awards/writing-awards/crystallography-and-cohomology-of-groups|doi=10.2307/2322930|jstor=2322930}}&lt;/ref&gt; In three dimensions, there are 219 distinct types, or 230 if [[Chirality (mathematics)|chiral]] copies are considered distinct. Space groups are also studied in dimensions other than 3 where they are sometimes called '''[[Ludwig Bieberbach|Bieberbach]] groups''', and are discrete [[Cocompact group action|cocompact]]  [[group (mathematics)|group]]s of isometries of an oriented Euclidean space.

In [[crystallography]], space groups are also called the '''crystallographic''' or '''[[Evgraf Fedorov|Fedorov]] groups''', and represent a description of the [[symmetry]] of the crystal. A definitive source regarding 3-dimensional space groups is the ''International Tables for Crystallography'' ({{harvtxt|Hahn|2002}}).

==History==
Space groups in 2 dimensions are the 17 [[wallpaper group]]s which have been known for several centuries, though the proof that the list was complete was only given in 1891, after the much harder case of space groups had been done.

In 1879 [[Leonhard Sohncke]] listed the 65 space groups (called Sohncke groups) whose elements preserve the orientation. More accurately, he listed 66 groups, but Fedorov and Schönflies both noticed that two of them were really the same. The space groups in 3 dimensions were first enumerated by {{harvs|txt|authorlink=Evgraf Fedorov|last=Fedorov|year=1891}} (whose list had 2 omissions (I{{overline|4}}3d and Fdd2) and one duplication (Fmm2)), and shortly afterwards were independently enumerated by {{harvs|txt|authorlink=Arthur Moritz Schönflies|last=Schönflies|year=1891}} (whose list had 4 omissions (I{{overline|4}}3d, Pc, Cc, ?) and one duplication (P{{overline|4}}2&lt;sub&gt;1&lt;/sub&gt;m)). The correct list of 230 space groups was found by 1892 during correspondence between Fedorov and Schönflies. {{harvs|txt|authorlink=William Barlow (geologist)|last=Barlow|year=1894}} later enumerated the groups with a different method, but omitted four groups (Fdd2, I{{overline|4}}2d, P{{overline|4}}2&lt;sub&gt;1&lt;/sub&gt;d, and P{{overline|4}}2&lt;sub&gt;1&lt;/sub&gt;c) even though he already had the correct list of 230 groups from Fedorov and Schönflies; the common claim that Barlow was unaware of their work is a myth.{{citation needed|date=January 2017}}
{{harvtxt|Burckhardt|1967}} describes the history of the discovery of the space groups in detail.

==Elements==
The space groups in three dimensions are made from combinations of the 32 [[crystallographic point group]]s with the 14 [[Bravais lattice]]s, each of the latter belonging to one of 7 [[lattice system]]s.  This results in a space group being some combination of the translational symmetry of a [[unit cell]] including lattice centering, the point group symmetry operations of [[Reflection (mathematics)|reflection]], [[rotation]] and [[improper rotation]] (also called rotoinversion), and the [[screw axis]] and [[glide plane]] symmetry operations.  The combination of all these symmetry operations results in a total of 230 different space groups describing all possible crystal symmetries.

===Elements fixing a point===
The elements of the space group fixing a point of space are the identity element, reflections, rotations and [[improper rotation]]s.

===Translations===
The translations form a normal abelian subgroup of rank 3, called the Bravais lattice. There are 14 possible types of Bravais lattice. The [[Quotient (group theory)|quotient]] of the space group by the Bravais lattice is a finite group which is one of the 32 possible [[point group]]s. Translation is defined as the face moves from one point to another point.

===Glide planes===
A [[glide plane]] is a reflection in a plane, followed by a translation parallel with that plane. This is noted by ''a'', ''b'' or ''c'', depending on which axis the glide is along.  There is also the ''n'' glide, which is a glide along the half of a diagonal of a face, and the ''d'' glide, which is a fourth of the way along either a face or space diagonal of the unit cell. The latter is called the diamond glide plane as it features in the [[diamond]] structure. In 17 space groups, due to the centering of the cell, the glides occur in two perpendicular directions simultaneously, ''i.e.'' the same glide plane can be called ''b'' or ''c'', ''a'' or ''b'', ''a'' or ''c''. For example, group Abm2 could be also called Acm2, group Ccca could be called Cccb. In 1992, it was suggested to use symbol ''e'' for such planes. The symbols for five space groups have been modified:
{| class="wikitable"
! Space group No. !! 39 !! 41 !! 64 !! 67 !! 68
|-
! New symbol
| Aem2 || Aea2|| Cmce|| Cmme|| Ccce
|-
! Old Symbol
| Abm2|| Aba2|| Cmca|| Cmma|| Ccca
|}

===Screw axes===
A [[screw axis]] is a rotation about an axis, followed by a translation along the direction of the axis.  These are noted by a number, ''n'', to describe the degree of rotation, where the number is how many operations must be applied to complete a full rotation (e.g., 3 would mean a rotation one third of the way around the axis each time).  The degree of translation is then added as a subscript showing how far along the axis the translation is, as a portion of the parallel lattice vector.  So, 2&lt;sub&gt;1&lt;/sub&gt; is a twofold rotation followed by a translation of 1/2 of the lattice vector.

=== General formula ===
The general formula for the action of an element of a space group is

''y'' = ''M''.''x'' + ''D''

where ''M'' is its matrix, ''D'' is its vector, and where the element transforms point ''x'' into point ''y''. In general, ''D'' = ''D''([[lattice (group)|lattice]]) + ''D''(''M''), where ''D''(''M'') is a unique function of ''M'' that is zero for ''M'' being the identity. The matrices ''M'' form a [[point group]] that is a basis of the space group; the lattice must be symmetric under that point group.

The lattice dimension can be less than the overall dimension, resulting in a "subperiodic" space group. For (overall dimension, lattice dimension):
* (1,1): One-dimensional [[line group]]s
* (2,1): Two-dimensional [[line group]]s: [[frieze group]]s
* (2,2): [[Wallpaper group]]s
* (3,1): Three-dimensional [[line group]]s; with the 3D crystallographic point groups, the [[rod group]]s
* (3,2): [[Layer group]]s
* (3,3): The space groups discussed in this article

==Notation==
{{further|List of space groups}}
There are at least ten methods of naming space groups.  Some of these methods can assign several different names to the same space group, so altogether there are many thousands of different names.

*'''Number'''. The International Union of Crystallography publishes tables of all space group types, and assigns each a unique number from 1 to 230.  The numbering is arbitrary, except that groups with the same crystal system or point group are given consecutive numbers.
*'''International symbol''' or '''[[Hermann–Mauguin notation]]'''. The Hermann–Mauguin (or international) notation describes the lattice and some generators for the group. It has a shortened form called the '''international short symbol''', which is the one most commonly used in crystallography, and usually consists of a set of four symbols.  The first describes the centering of the Bravais lattice (''P'', ''A'', ''B'', ''C'', ''I'', ''R'' or ''F'').  The next three describe the most prominent symmetry operation visible when projected along one of the high symmetry directions of the crystal. These symbols are the same as used in [[point group]]s, with the addition of glide planes and screw axis, described above.  By way of example, the space group of [[quartz]] is P3&lt;sub&gt;1&lt;/sub&gt;21, showing that it exhibits primitive centering of the motif (i.e., once per unit cell), with a threefold screw axis and a twofold rotation axis.  Note that it does not explicitly contain the [[crystal system]], although this is unique to each space group (in the case of ''P''3&lt;sub&gt;1&lt;/sub&gt;21, it is trigonal).

:In the international short symbol the first symbol (3&lt;sub&gt;1&lt;/sub&gt; in this example) denotes the symmetry along the major axis (c-axis in trigonal cases), the second (2 in this case) along axes of secondary importance (a and b) and the third symbol the symmetry in another direction. In the trigonal case there also exists a space group P3&lt;sub&gt;1&lt;/sub&gt;12. In this space group the twofold axes are not along the a and b-axes but in a direction rotated by 30°.

:The international symbols and international short symbols for some of the space groups were changed slightly between 1935 and 2002, so several space groups have 4 different international symbols in use.

*'''Hall notation'''[http://cci.lbl.gov/sginfo/hall_symbols.html]. Space group notation with an explicit origin. Rotation, translation and axis-direction symbols are clearly separated and inversion centers are explicitly defined. The construction and format of the notation make it particularly suited to computer generation of symmetry information. For example, group number 3 has three Hall symbols: P 2y (P 1 2 1), P 2 (P 1 1 2), P 2x (P 2 1 1).
*'''[[Schönflies notation#Space groups|Schönflies notation]]'''. The space groups with given point group are numbered  by 1, 2, 3, ...  (in the same order as their international number) and this number is added as a superscript to the Schönflies symbol for the point group. For example, groups numbers 3 to 5 whose point group is ''C''&lt;sub&gt;2&lt;/sub&gt; have Schönflies symbols ''C''{{sup sub|1|2}}, ''C''{{sup sub|2|2}}, ''C''{{sup sub|3|2}}.
*'''[[Evgraf Fedorov|Fedorov]] notation'''
*'''Shubnikov symbol'''
*'''Strukturbericht designation''' is related notation for crystal structures given a letter and index: '''A''' Elements (monatomic), '''B''' for AB compounds, '''C''' for AB&lt;sub&gt;2&lt;/sub&gt; compounds, '''D''' for A&lt;sub&gt;m &lt;/sub&gt;B&lt;sub&gt;n&lt;/sub&gt; compounds, ('''E''', '''F''', …, '''K''' More complex compounds), '''L''' Alloys, '''O''' Organic compounds, '''S''' Silicates. Some structure designation share the same space groups. For example, space group 225 is A&lt;sub&gt;1&lt;/sub&gt;, B&lt;sub&gt;1&lt;/sub&gt;, and C&lt;sub&gt;1&lt;/sub&gt;. Space group 221 is A&lt;sub&gt;h&lt;/sub&gt;, and B&lt;sub&gt;2&lt;/sub&gt;.&lt;ref&gt;{{cite web|url=http://commons.wikimedia.org/wiki/Strukturbericht|title=Strukturbericht - Wikimedia Commons|website=commons.wikimedia.org}}&lt;/ref&gt;  However, crystallographers would not use Strukturbericht notation to describe the space group, rather it would be used to describe a specific crystal structure (e.g. space group + atomic arrangement (motif)).
* 2D:'''[[Orbifold notation]]''' and 3D:[[Fibrifold notation]]. As the name suggests, the orbifold notation describes the orbifold, given by the quotient of Euclidean space by the space group, rather than generators of the space group. It was introduced by [[John Horton Conway|Conway]] and [[William Thurston|Thurston]], and is not used much outside mathematics. Some of the space groups have several different fibrifolds associated to them, so have several different fibrifold symbols.
*'''[[Coxeter notation]]''' – Spatial and point symmetry groups, represented as modications of the pure reflectional [[Coxeter group]]s.
* [[Geometric notation]]&lt;ref&gt;[[PDF]] [http://geocalc.clas.asu.edu/pdf/CrystalGA.pdf The Crystallographic Space Groups in Geometric Algebra], David Hestenes and Jeremy Holt&lt;/ref&gt; is a [[Geometric algebra]] notation.

==Classification systems==
There are (at least) 10 different ways to classify space groups into classes. The relations between  some of  these are described in the following table. Each classification system is a refinement of the ones below it.

{|class=wikitable
|colspan=2|'''(Crystallographic) space group types''' (230 in three dimensions). Two space groups, considered as subgroups of the group of affine transformations of space, have the same space group type if they are conjugate by an  orientation-preserving affine transformation. In three dimensions, for 11 of the [[affine space]] groups, there is no orientation-preserving map from the group to its mirror image, so if one distinguishes groups from their mirror images these each split into two cases. So there are 54&amp;nbsp;+&amp;nbsp;11&amp;nbsp;=&amp;nbsp;65 space group types that preserve orientation.
|-
|colspan=2|'''Affine space group types''' (219 in three dimensions). Two space groups, considered as subgroups of the group of affine transformations of space, have the same affine space group type if they are conjugate under an affine transformation. The affine space group type is determined by the underlying abstract group of the space group. In three dimensions there are 54 affine space group types that preserve orientation.
|-
|colspan=2|'''Arithmetic crystal classes''' (73 in three dimensions). Sometimes called Z-classes. These are determined by the point group together with the action of the point group on the subgroup of translations.  In other words, the arithmetic crystal classes correspond to conjugacy classes of finite subgroup of the general linear group GL&lt;sub&gt;n&lt;/sub&gt;('''Z''') over the integers.  A space group is called '''symmorphic''' (or '''split''')  if there is a point such that all symmetries are the product of a symmetry fixing this point and a translation. Equivalently, a space group is symmorphic if it is a [[semidirect product]] of its point group with its translation subgroup. There are 73 symmorphic space groups, with exactly one in each arithmetic crystal class. There are also 157 nonsymmorphic space group types with varying numbers in the arithmetic crystal classes.

Arithmetic crystal classes may be interpreted as different orientations of the point groups in the lattice, with the group elements' matrix components being constrained to have integer coefficients in lattice space. This is rather easy to picture in the two-dimensional, [[wallpaper group]] case. Some of the point groups have reflections, and the reflection lines can be along the lattice directions, halfway in between them, or both.
* None: C&lt;sub&gt;1&lt;/sub&gt;: p1; C&lt;sub&gt;2&lt;/sub&gt;: p2; C&lt;sub&gt;3&lt;/sub&gt;: p3; C&lt;sub&gt;4&lt;/sub&gt;: p4; C&lt;sub&gt;6&lt;/sub&gt;: p6
* Along: D&lt;sub&gt;1&lt;/sub&gt;: pm, pg; D&lt;sub&gt;2&lt;/sub&gt;: pmm, pmg, pgg; D&lt;sub&gt;3&lt;/sub&gt;: p31m
* Between: D&lt;sub&gt;1&lt;/sub&gt;: cm; D&lt;sub&gt;2&lt;/sub&gt;: cmm; D&lt;sub&gt;3&lt;/sub&gt;: p3m1
* Both: D&lt;sub&gt;4&lt;/sub&gt;: p4m, p4g; D&lt;sub&gt;6&lt;/sub&gt;: p6m
|-
|'''(geometric) [[Crystal classes]]''' (32 in three dimensions). Sometimes called Q-classes. The crystal class of a space group is determined by its point group: the quotient by the subgroup of translations, acting on the lattice. Two space groups are in the same crystal class if and only if their point groups, which are subgroups of GL&lt;sub&gt;n&lt;/sub&gt;('''Z'''), are conjugate in the larger group GL&lt;sub&gt;n&lt;/sub&gt;('''Q''').
|'''Bravais flocks''' (14 in three dimensions). These are determined by the underlying Bravais lattice type. 
These correspond to conjugacy classes of  lattice point groups in GL&lt;sub&gt;n&lt;/sub&gt;('''Z'''), where the lattice point group is the group of symmetries of the underlying lattice that fix a point of the lattice, and contains the point group.
|-
|'''[[Crystal systems]]'''. (7 in three dimensions) Crystal systems are an ad hoc modification of the lattice systems to make them compatible with the classification according to point groups. They differ from crystal families in that the hexagonal crystal family is split into two subsets, called the trigonal and hexagonal crystal systems. The trigonal crystal system is larger than the rhombohedral lattice system, the hexagonal crystal system is smaller than the hexagonal lattice system, and the remaining crystal systems and lattice systems are the same. 
|'''[[Lattice system]]s''' (7 in three dimensions). The lattice system of a space group is determined by the conjugacy class of the lattice point group (a subgroup of GL&lt;sub&gt;n&lt;/sub&gt;('''Z''')) in the larger group GL&lt;sub&gt;n&lt;/sub&gt;('''Q'''). In three dimensions the lattice point group can have one of the 7 different orders 2, 4, 8, 12, 16, 24, or 48. The hexagonal crystal family is split into two subsets, called the rhombohedral and hexagonal lattice systems. 
|-
|colspan=2|'''[[Crystal families]]''' (6 in three dimensions). The point group of a space group does not quite determine its lattice system, because occasionally two space groups with the same point group may be in different lattice systems. Crystal families are formed from lattice systems by merging the two lattice systems whenever this happens, so that the crystal family of a space group is determined by either its lattice system or its point group. In 3 dimensions the only two lattice families that get merged in this way are the hexagonal and rhombohedral lattice systems, which are combined into the hexagonal crystal family.  The 6 crystal families in 3 dimensions are called triclinic, monoclinic, orthorhombic, tetragonal, hexagonal, and cubic. Crystal families  are commonly used in popular books on crystals, where they are sometimes called crystal systems.
|}

{{harvs|txt | last1=Conway  | author1-link=John Horton Conway | last2=Delgado Friedrichs | last3=Huson |  last4=Thurston |  author4-link=William Thurston | title=On three-dimensional space groups | url=http://www.emis.de/journals/BAG/vol.42/no.2/17.html |mr=1865535 | year=2001 | journal=Beiträge zur Algebra und Geometrie. Contributions to Algebra and Geometry | issn=0138-4821 | volume=42 | issue=2 | pages=475–507}} gave another classification of the space groups, called a [[fibrifold notation]], according to the [[fibrifold]] structures on the corresponding [[orbifold]]. They divided the 219 affine space groups into reducible and irreducible groups. The reducible groups fall into 17 classes corresponding to the 17 [[wallpaper group]]s, and the remaining 35 irreducible groups are the same as the [[cubic crystal system#Cubic space groups|cubic groups]] and are classified separately.

==In other  dimensions==

===Bieberbach's theorems===
In ''n'' dimensions, an affine space group, or Bieberbach group, is a discrete subgroup of isometries of ''n''-dimensional Euclidean space with a compact fundamental domain. {{harvs|txt|last=Bieberbach|year1=1911|year2=1912}} proved that the subgroup of translations of any such group contains ''n'' linearly independent translations, and is a free [[Abelian group|abelian]] subgroup of finite index, and is also the unique maximal normal abelian subgroup. He also showed that in any dimension ''n'' there are  only a finite number of possibilities for the isomorphism class of the underlying group of a space group, and moreover the action of the group on Euclidean space is unique up to conjugation by affine transformations. This answers part of [[Hilbert's eighteenth problem]]. {{harvtxt|Zassenhaus|1948}} showed that conversely any group that is the extension of '''Z'''&lt;sup&gt;''n''&lt;/sup&gt; by a finite group acting faithfully is an [[Affine space|affine]] space group. Combining these results shows that classifying space groups in ''n'' dimensions up to conjugation by affine transformations is essentially the same as classifying isomorphism classes for groups that are extensions of '''Z'''&lt;sup&gt;''n''&lt;/sup&gt; by a finite group acting faithfully.

It is essential in Bieberbach's theorems to assume that the group acts as isometries; the theorems do not generalize to discrete cocompact groups of affine transformations of Euclidean space. A counter-example is given by the 3-dimensional Heisenberg group of the integers acting by translations on the Heisenberg group of the reals, identified with 3-dimensional Euclidean space. This is a discrete cocompact group of affine transformations of space, but does not contain a subgroup '''Z'''&lt;sup&gt;3&lt;/sup&gt;.

===Classification in small dimensions===
This table gives the number of space group types in small dimensions, including the numbers of various classes of space group. The numbers of enantiomorphic pairs are given in parentheses.
{| class="wikitable" cellpadding=0 style="margin: 1em auto; text-align: center;"
|-
!Dimensions
!Crystal families {{OEIS|id=A004032}}
!Crystal systems {{OEIS|id=A004031}}
!Bravais lattices {{OEIS|id=A004030}}
!Abstract crystallographic point groups {{OEIS|id=A006226}}
!Geometric crystal classes, Q-classes, crystallographic point groups {{OEIS|id=A004028}}
!Arithmetic crystal classes, Z-classes {{OEIS|id=A004027}}
!Affine space group types {{OEIS|id=A004029}}
!Crystallographic space group types {{OEIS|id=A006227}}
|-
|0&lt;sup&gt;a&lt;/sup&gt;
|1
|1
|1
|1
|1
|1
|1
|1
|-
|1&lt;sup&gt;b&lt;/sup&gt;
|1
|1
|1
|2
|2
|2
|2
|2
|-
|2&lt;sup&gt;c&lt;/sup&gt;
|4
|4
|5
|9
|10
|13
|17
|17
|-
|3&lt;sup&gt;d&lt;/sup&gt;
|6
|7
|14
|18
|32
|73
|219 (+11)
|230
|-
|4&lt;sup&gt;e&lt;/sup&gt;
|23 (+6)
|33 (+7)
|64 (+10)
|118
|227 (+44)
|710 (+70)
|4783 (+111)
|4894
|-
|5&lt;sup&gt;f&lt;/sup&gt;
|32
|59
|189
|239
|955
|6079
|222018 (+79)
|222097
|-
|6&lt;sup&gt;g&lt;/sup&gt;
|91
|251
|841
|1594
|7103
|85308 (+?)
|28927915 (+?)
|?
|}

a - Trivial group &lt;BR&gt;
b - One is the group of integers and the other is the [[infinite dihedral group]]; see [[symmetry groups in one dimension]] &lt;BR&gt;
c - these '''2D space groups''' are also called '''[[wallpaper group]]s''' or '''plane groups'''. &lt;BR&gt;
d - In 3D there are 230 crystallographic space group types, which reduces to 219 affine space group types because of some types being different from their mirror image; these are said to differ by "[[Chirality (mathematics)|enantiomorphous]] character" (e.g.  P3&lt;sub&gt;1&lt;/sub&gt;12 and  P3&lt;sub&gt;2&lt;/sub&gt;12). Usually "space group" refers to 3D. They were enumerated independently by {{harvtxt|Barlow|1894}},  {{harvtxt|Fedorov|1891}} and {{harvtxt|Schönflies|1891}}. &lt;BR&gt;
e - The 4895 4-dimensional groups were enumerated by {{harvs | txt|last1=Brown | first1=Harold | last2=Bülow | first2=Rolf | last3=Neubüser | first3=Joachim | last4=Wondratschek | first4=Hans | last5=Zassenhaus | first5=Hans | author5-link=Hans Zassenhaus | title=Crystallographic groups of four-dimensional space | publisher=Wiley-Interscience [John Wiley &amp; Sons] | location=New York | isbn=978-0-471-03095-9 |mr=0484179 | year=1978}}. {{harvtxt|Neubüser|Souvignier|Wondratschek|2002}} corrected the number of enantiomorphic groups from 112 to 111, so total number of groups is 4783+111=4894. There are 44 enantiomorphic point groups in 4-dimensional space. If we consider enantiomorphic groups as different, the total number of point groups is 227+44=271. &lt;BR&gt;
f - {{harvtxt|Plesken|Schulz|2000}} enumerated the ones of dimension 5. {{harvtxt|Souvignier|2003}} counted the enantiomorphs. &lt;BR&gt;
g - {{harvtxt|Plesken|Schulz|2000}} enumerated the ones of dimension 6, later the corrected figures were found.&lt;ref&gt;{{cite web|title=The CARAT Homepage|url=http://wwwb.math.rwth-aachen.de/carat/|accessdate=11 May 2015}}&lt;/ref&gt; Initially published number of 826 Lattice types in {{harvtxt|Plesken|Hanrath|1984}} was corrected to 841 in {{harvtxt|Opgenorth|Plesken|Schulz|1998}}. See also {{harvtxt|Janssen|Birman|Koptsik|Verger-Gaugry|2002}}. {{harvtxt|Souvignier|2003}} counted the enantiomorphs, but that paper relied on old erroneous CARAT data for dimension 6.

===Magnetic groups and time reversal===

In addition to crystallographic space groups there are also magnetic space groups (also called two-color (black and white) crystallographic groups or Shubnikov groups). These symmetries contain an element known as time reversal. They treat time as an additional dimension, and the group elements can include time reversal as reflection in it. They are of importance in [[magnetic structure]]s that contain ordered unpaired spins, i.e. [[ferromagnetism|ferro-]], [[ferrimagnetism|ferri-]] or [[antiferromagnetism|antiferromagnetic]] structures as studied by [[neutron diffraction]]. The time reversal element flips a magnetic spin while leaving all other structure the same and it can be combined with a number of other symmetry elements. Including time reversal there are 1651 magnetic space groups in 3D {{harv|Kim|1999|loc=p.428}}. It has also been possible to construct magnetic versions for other overall and lattice dimensions ([https://web.archive.org/web/20111119065722/http://www.bk.psu.edu/faculty/litvin/Download.html Daniel Litvin's papers], {{harv|Litvin|2008}}, {{harv|Litvin|2005}}). Frieze groups are magnetic 1D line groups and layer groups are magnetic wallpaper groups, and the axial 3D point groups are magnetic 2D point groups. Number of original and magnetic groups by (overall, lattice) dimension:
* (0,0): 1, 2
* (1,0): 2, 5
* (1,1): 2, 7
* (2,0): 10, 31
* (2,1): 7, 31
* (2,2): 17, 80
* (3,0): 32, 122
* (3,1): 75, 394 (rod groups, not 3D line groups in general)
* (3,2): 80, 528
* (3,3): 230, 1651  
* (4,0): 271, 1202
* (4,1): 343, {{harv|Palistrant|2012}}
* (4,2): 1091, {{harv|Palistrant|2012}}
* (4,3): 1594, {{harv|Palistrant|2012}}
* (4,4): 4894, 62227 {{harv|Souvignier|2006}}

==Table of space groups in 2 dimensions (wallpaper groups)==

Table of the [[wallpaper group]]s using the classification of the 3-dimensional space groups:
{| class="wikitable"
|-
! rowspan=2|[[Crystal system]]&lt;BR&gt;(Bravais lattice)
! colspan=4|Geometric class &lt;br&gt; [[Point group]]
! rowspan=2|Arithmetic&lt;BR&gt;class
! rowspan=2 colspan=4|Wallpaper groups&lt;BR&gt;(cell diagram)
|- align=center
![[Schönflies notation|Schön.]]||[[Orbifold notation]] ||[[Coxeter notation|Cox.]]||[[group order|Ord.]]
|- align=center
|rowspan=2| Oblique&lt;BR&gt;[[File:Reseaux 2D mp.png|80px]]
| C&lt;sub&gt;1&lt;/sub&gt;||(1)||[&amp;nbsp;]&lt;sup&gt;+&lt;/sup&gt;||1
| None
| p1&lt;BR&gt;(1)||[[File:Wallpaper group diagram p1.svg|60px]]
|colspan=2|&amp;nbsp;
|- align=center
| C&lt;sub&gt;2&lt;/sub&gt;||(22)||[2]&lt;sup&gt;+&lt;/sup&gt;||2
| None
| p2&lt;BR&gt;(2222)||[[File:Wallpaper group diagram p2.svg|60px]]
|colspan=2|&amp;nbsp;
|- align=center
|rowspan=2| Rectangular&lt;BR&gt;(Centered rhombic)&lt;BR&gt;[[File:Reseaux 2D op.png|80px]]
| D&lt;sub&gt;1&lt;/sub&gt;||(*)||[&amp;nbsp;]||2
| Along
| pm&lt;BR&gt;(**)||[[File:Wallpaper group diagram pm.svg|60px]]
| pg&lt;BR&gt;(××)||[[File:Wallpaper group diagram pg.svg|60px]]
|- align=center
| D&lt;sub&gt;2&lt;/sub&gt;||(*22)||[2]||4
| Along
| pmm&lt;BR&gt;(*2222)||[[File:Wallpaper group diagram pmm.svg|60px]]
| pmg&lt;BR&gt;(22*)||[[File:Wallpaper group diagram pmg.svg|60px]]
|- align=center
|rowspan=2| Rhombic&lt;BR&gt;(Centered rectangular)&lt;BR&gt;[[File:Reseaux 2D oc.png|80px]]
| D&lt;sub&gt;1&lt;/sub&gt;||(*)||[ ]||2
| Between
| cm&lt;BR&gt;(*×)||[[File:Wallpaper group diagram cm.svg|60px]]
|colspan=2|&amp;nbsp;
|- align=center
| D&lt;sub&gt;2&lt;/sub&gt;||(*22)||[2]||4
| Between
| cmm&lt;BR&gt;(2*22)||[[File:Wallpaper group diagram cmm.svg|60px]]
| pgg&lt;BR&gt;(22×)||[[File:Wallpaper group diagram pgg.svg|60px]]
|- align=center
|rowspan=2| Square&lt;BR&gt;[[File:Reseaux 2D tp.png|80px]]
| C&lt;sub&gt;4&lt;/sub&gt;||(44)||[4]&lt;sup&gt;+&lt;/sup&gt;||4
| None
| p4&lt;BR&gt;(442)||[[File:Wallpaper group diagram p4 square.svg|50px]]
|colspan=2|&amp;nbsp;
|- align=center
| D&lt;sub&gt;4&lt;/sub&gt;||(*44)||[4]||8
| Both
| p4m&lt;BR&gt;(*442)||[[File:Wallpaper group diagram p4m square.svg|50px]]
| p4g&lt;BR&gt;(4*2)||[[File:Wallpaper group diagram p4g square.svg|50px]]
|- align=center
|rowspan=4| Hexagonal&lt;BR&gt;[[File:Reseaux 2D hp.png|80px]]
| C&lt;sub&gt;3&lt;/sub&gt;||(33)||[3]&lt;sup&gt;+&lt;/sup&gt;||3
| None
| p3&lt;BR&gt;(333)||[[File:Wallpaper group diagram p3.svg|60px]]
|colspan=2|&amp;nbsp;
|- align=center
| D&lt;sub&gt;3&lt;/sub&gt;||(*33)||[3]||6
| Between
| p3m1&lt;BR&gt;(*333)||[[File:Wallpaper group diagram p3m1.svg|60px]]
| p31m&lt;BR&gt;(3*3)||[[File:Wallpaper group diagram p31m.svg|60px]]
|- align=center
| C&lt;sub&gt;6&lt;/sub&gt;||(66)||[6]&lt;sup&gt;+&lt;/sup&gt;||6
| None
| p6&lt;BR&gt;(632)||[[File:Wallpaper group diagram p6.svg|60px]]
|colspan=2|&amp;nbsp;
|- align=center
| D&lt;sub&gt;6&lt;/sub&gt;||(*66)||[6]||12
| Both
| p6m&lt;BR&gt;(*632)||[[File:Wallpaper group diagram p6m.svg|60px]]
|colspan=2|&amp;nbsp;
|}
For each geometric class, the possible arithmetic classes are
* None: no reflection lines
* Along: reflection lines along lattice directions
* Between: reflection lines halfway in between lattice directions
* Both: reflection lines both along and between lattice directions

==Table of space groups in 3 dimensions==
{{further|List of space groups}}

{| class="wikitable"
|- 
!rowspan=2 width=60|#
!rowspan=2 width=100|[[Crystal system]]&lt;BR&gt;(count)&lt;BR&gt;Bravais lattice
!rowspan=1 colspan=5|[[Crystallographic point group|Point group]]
!rowspan=2 | '''Space groups''' (international short symbol)
|- 
![[Hermann–Mauguin notation|Intl]] || [[Schönflies notation|Schön.]]||[[Orbifold notation]] ||[[Coxeter notation|Cox.]]||[[group order|Ord.]]
|- bgcolor=#ffffff align=center
! 1
|rowspan=2|[[Triclinic]]&lt;BR&gt;(2)&lt;BR&gt;[[File:Triclinic.svg|50px]]
| 1|| C&lt;sub&gt;1&lt;/sub&gt;||11||[&amp;nbsp;]&lt;sup&gt;+&lt;/sup&gt;||1
|align=left|P1
|- bgcolor=#ffffff align=center
! 2
| {{overline|1}}|| C&lt;sub&gt;i&lt;/sub&gt;||1×||[2&lt;sup&gt;+&lt;/sup&gt;,2&lt;sup&gt;+&lt;/sup&gt;]||2
|align=left|P{{overline|1}} 
|-  align=center
! 3–5
|rowspan=3|[[Monoclinic]]&lt;BR&gt;(13)&lt;BR&gt;[[File:Monoclinic.svg|40px]][[File:Monoclinic-base-centered.svg|40px]]
| 2|| C&lt;sub&gt;2&lt;/sub&gt; || 22|| [2]&lt;sup&gt;+&lt;/sup&gt;||2
|align=left|P2, P2&lt;sub&gt;1&lt;/sub&gt;&lt;BR&gt;C2
|-  align=center
! 6–9
| m|| C&lt;sub&gt;s&lt;/sub&gt;|| *11|| [&amp;nbsp;]||2
|align=left|Pm, Pc&lt;BR&gt;Cm, Cc 
|-  align=center
! 10–15
| 2/m|| C&lt;sub&gt;2h&lt;/sub&gt;|| 2*|| [2,2&lt;sup&gt;+&lt;/sup&gt;]||4
|align=left|P2/m, P2&lt;sub&gt;1&lt;/sub&gt;/m&lt;BR&gt;C2/m,  P2/c, P2&lt;sub&gt;1&lt;/sub&gt;/c&lt;BR&gt;C2/c 
|- bgcolor=#ffffff align=center
! 16–24
|rowspan=3|[[Orthorhombic]]&lt;BR&gt;(59)&lt;BR&gt;[[File:Orthorhombic.svg|40px]][[File:Orthorhombic-body-centered.svg|40px]]&lt;BR&gt;[[File:Orthorhombic-base-centered.svg|40px]][[File:Orthorhombic-face-centered.svg|40px]]
|  222||  D&lt;sub&gt;2&lt;/sub&gt;|| 222|| [2,2]&lt;sup&gt;+&lt;/sup&gt;||4
|align=left|P222, P222&lt;sub&gt;1&lt;/sub&gt;, P2&lt;sub&gt;1&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt;2, P2&lt;sub&gt;1&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt;, C222&lt;sub&gt;1&lt;/sub&gt;, C222, F222, I222, I2&lt;sub&gt;1&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt; 
|- bgcolor=#ffffff align=center
!  25–46
| mm2||  C&lt;sub&gt;2v&lt;/sub&gt;|| *22|| [2]||4
|align=left|Pmm2, Pmc&lt;!-- not a PMCID--&gt;2&lt;sub&gt;1&lt;/sub&gt;, Pcc2, Pma2, Pca2&lt;sub&gt;1&lt;/sub&gt;, Pnc2, Pmn2&lt;sub&gt;1&lt;/sub&gt;, Pba2, Pna2&lt;sub&gt;1&lt;/sub&gt;, Pnn2&lt;BR&gt;Cmm2, Cmc2&lt;sub&gt;1&lt;/sub&gt;, Ccc2, Amm2, Aem2, Ama2, Aea2&lt;BR&gt;Fmm2, Fdd2&lt;BR&gt;Imm2, Iba2, Ima2 
|- bgcolor=#ffffff align=center
!  47–74
| mmm||  D&lt;sub&gt;2h&lt;/sub&gt;|| *222|| [2,2]||8
|align=left|Pmmm, Pnnn, Pccm, Pban, Pmma, Pnna, Pmna, Pcca, Pbam, Pccn, Pbcm, Pnnm, Pmmn, Pbcn, Pbca, Pnma&lt;BR&gt;Cmcm, Cmce, Cmmm, Cccm, Cmme, Ccce&lt;BR&gt;Fmmm, Fddd&lt;BR&gt;Immm, Ibam, Ibca, Imma 
|- align=center
! 75–80
|rowspan=7| [[Tetragonal]]&lt;BR&gt;(68)&lt;BR&gt;[[File:Tetragonal.svg|45px]]&lt;BR&gt;[[File:Tetragonal-body-centered.svg|45px]]
| 4|| C&lt;sub&gt;4&lt;/sub&gt;||44||[4]&lt;sup&gt;+&lt;/sup&gt;||4
|align=left|P4,  P4&lt;sub&gt;1&lt;/sub&gt;, P4&lt;sub&gt;2&lt;/sub&gt;, P4&lt;sub&gt;3&lt;/sub&gt;, I4, I4&lt;sub&gt;1&lt;/sub&gt; 
|-  align=center
! 81–82
| {{overline|4}}|| S&lt;sub&gt;4&lt;/sub&gt;||2×||[2&lt;sup&gt;+&lt;/sup&gt;,4&lt;sup&gt;+&lt;/sup&gt;]||4
|align=left|P{{overline|4}}, I{{overline|4}} 
|-  align=center
! 83–88
| 4/m|| C&lt;sub&gt;4h&lt;/sub&gt;||4*||[2,4&lt;sup&gt;+&lt;/sup&gt;]||8
|align=left|P4/m, P4&lt;sub&gt;2&lt;/sub&gt;/m, P4/n, P4&lt;sub&gt;2&lt;/sub&gt;/n&lt;BR&gt;I4/m, I4&lt;sub&gt;1&lt;/sub&gt;/a 
|-  align=center
! 89–98
|  422 ||  D&lt;sub&gt;4&lt;/sub&gt;||224||[2,4]&lt;sup&gt;+&lt;/sup&gt;||8
|align=left|P422, P42&lt;sub&gt;1&lt;/sub&gt;2, P4&lt;sub&gt;1&lt;/sub&gt;22, P4&lt;sub&gt;1&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt;2, P4&lt;sub&gt;2&lt;/sub&gt;22, P4&lt;sub&gt;2&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt;2, P4&lt;sub&gt;3&lt;/sub&gt;22, P4&lt;sub&gt;3&lt;/sub&gt;2&lt;sub&gt;1&lt;/sub&gt;2&lt;BR&gt;I422, I4&lt;sub&gt;1&lt;/sub&gt;22 
|-  align=center
!  99–110
|  4mm||  C&lt;sub&gt;4v&lt;/sub&gt;||*44||[4]||8
|align=left|P4mm, P4bm, P4&lt;sub&gt;2&lt;/sub&gt;cm, P4&lt;sub&gt;2&lt;/sub&gt;nm, P4cc, P4nc, P4&lt;sub&gt;2&lt;/sub&gt;mc, P4&lt;sub&gt;2&lt;/sub&gt;bc&lt;BR&gt;I4mm, I4cm, I4&lt;sub&gt;1&lt;/sub&gt;md, I4&lt;sub&gt;1&lt;/sub&gt;cd 
|-  align=center
! 111–122
|  {{overline|4}}2m||  D&lt;sub&gt;2d&lt;/sub&gt;||2*2||[2&lt;sup&gt;+&lt;/sup&gt;,4]||8
|align=left|P{{overline|4}}2m, P{{overline|4}}2c, P{{overline|4}}2&lt;sub&gt;1&lt;/sub&gt;m, P{{overline|4}}2&lt;sub&gt;1&lt;/sub&gt;c, P{{overline|4}}m2, P{{overline|4}}c2, P{{overline|4}}b2, P{{overline|4}}n2&lt;BR&gt;I{{overline|4}}m2, I{{overline|4}}c2, I{{overline|4}}2m, I{{overline|4}}2d 
|- align=center
!  123–142
|  4/mmm||  D&lt;sub&gt;4h&lt;/sub&gt;||*224||[2,4]||16
|align=left|P4/mmm, P4/mcc, P4/nbm, P4/nnc, P4/mbm, P4/mnc, P4/nmm, P4/ncc, P4&lt;sub&gt;2&lt;/sub&gt;/mmc, P4&lt;sub&gt;2&lt;/sub&gt;/mcm, P4&lt;sub&gt;2&lt;/sub&gt;/nbc, P4&lt;sub&gt;2&lt;/sub&gt;/nnm, P4&lt;sub&gt;2&lt;/sub&gt;/mbc, P4&lt;sub&gt;2&lt;/sub&gt;/mnm, P4&lt;sub&gt;2&lt;/sub&gt;/nmc, P4&lt;sub&gt;2&lt;/sub&gt;/ncm&lt;BR&gt;I4/mmm, I4/mcm, I4&lt;sub&gt;1&lt;/sub&gt;/amd, I4&lt;sub&gt;1&lt;/sub&gt;/acd
|- bgcolor=#ffffff align=center
! 143–146
| rowspan=5|[[Trigonal]]&lt;BR&gt;(25)&lt;BR&gt;[[File:Hexagonal latticeR.svg|60px]][[File:Hexagonal latticeFRONT.svg|60px]]
| 3|| C&lt;sub&gt;3&lt;/sub&gt;||33||[3]&lt;sup&gt;+&lt;/sup&gt;||3
|align=left|P3, P3&lt;sub&gt;1&lt;/sub&gt;, P3&lt;sub&gt;2&lt;/sub&gt;&lt;BR&gt;R3 
|-  bgcolor=#ffffff align=center
! 147–148
| {{overline|3}}|| S&lt;sub&gt;6&lt;/sub&gt;||3×||[2&lt;sup&gt;+&lt;/sup&gt;,6&lt;sup&gt;+&lt;/sup&gt;]||6
|align=left|P{{overline|3}}, R{{overline|3}} 
|-  bgcolor=#ffffff align=center
! 149–155
| 32|| D&lt;sub&gt;3&lt;/sub&gt;||223||[2,3]&lt;sup&gt;+&lt;/sup&gt;||6
|align=left|P312, P321, P3&lt;sub&gt;1&lt;/sub&gt;12, P3&lt;sub&gt;1&lt;/sub&gt;21, P3&lt;sub&gt;2&lt;/sub&gt;12, P3&lt;sub&gt;2&lt;/sub&gt;21&lt;BR&gt;R32 
|- bgcolor=#ffffff align=center
! 156–161
| 3m|| C&lt;sub&gt;3v&lt;/sub&gt;||*33||[3]||6
|align=left|P3m1, P31m, P3c1, P31c&lt;BR&gt;R3m, R3c 
|-  bgcolor=#ffffff align=center
! 162–167
| {{overline|3}}m|| D&lt;sub&gt;3d&lt;/sub&gt;||2*3||[2&lt;sup&gt;+&lt;/sup&gt;,6]||12
|align=left|P{{overline|3}}1m, P{{overline|3}}1c, P{{overline|3}}m1, P{{overline|3}}c1&lt;BR&gt;R{{overline|3}}m, R{{overline|3}}c
|- align=center
! 168–173
|rowspan=7| [[Hexagonal crystal system|Hexagonal]]&lt;BR&gt;(27)&lt;BR&gt;[[File:Hexagonal latticeFRONT.svg|60px]]
| 6|| C&lt;sub&gt;6&lt;/sub&gt;||66||[6]&lt;sup&gt;+&lt;/sup&gt;||6
|align=left|P6, P6&lt;sub&gt;1&lt;/sub&gt;, P6&lt;sub&gt;5&lt;/sub&gt;, P6&lt;sub&gt;2&lt;/sub&gt;, P6&lt;sub&gt;4&lt;/sub&gt;, P6&lt;sub&gt;3&lt;/sub&gt; 
|-  align=center
! 174
| {{overline|6}}|| C&lt;sub&gt;3h&lt;/sub&gt;||3*||[2,3&lt;sup&gt;+&lt;/sup&gt;]||6
|align=left|P{{overline|6}}
|-   align=center
! 175–176
| 6/m|| C&lt;sub&gt;6h&lt;/sub&gt;||6*||[2,6&lt;sup&gt;+&lt;/sup&gt;]||12
|align=left|P6/m, P6&lt;sub&gt;3&lt;/sub&gt;/m 
|-  align=center
! 177–182
| 622|| D&lt;sub&gt;6&lt;/sub&gt;||226||[2,6]&lt;sup&gt;+&lt;/sup&gt;||12
|align=left|P622, P6&lt;sub&gt;1&lt;/sub&gt;22, P6&lt;sub&gt;5&lt;/sub&gt;22, P6&lt;sub&gt;2&lt;/sub&gt;22, P6&lt;sub&gt;4&lt;/sub&gt;22, P6&lt;sub&gt;3&lt;/sub&gt;22 
|-  align=center
! 183–186
| 6mm|| C&lt;sub&gt;6v&lt;/sub&gt;||*66||[6]||12
|align=left|P6mm, P6cc, P6&lt;sub&gt;3&lt;/sub&gt;cm, P6&lt;sub&gt;3&lt;/sub&gt;mc 
|-  align=center
! 187–190
| {{overline|6}}m2|| D&lt;sub&gt;3h&lt;/sub&gt;||*223||[2,3]||12
|align=left|P{{overline|6}}m2, P{{overline|6}}c2, P{{overline|6}}2m, P{{overline|6}}2c 
|-  align=center
! 191–194
| 6/mmm|| D&lt;sub&gt;6h&lt;/sub&gt;||*226||[2,6]||24
|align=left|P6/mmm, P6/mcc, P6&lt;sub&gt;3&lt;/sub&gt;/mcm, P6&lt;sub&gt;3&lt;/sub&gt;/mmc 
|- bgcolor=#ffffff align=center
! 195–199
| rowspan=5|[[Cubic crystal system|Cubic]]&lt;BR&gt;(36)&lt;BR&gt;[[Image:Cubic.svg|60px]]&lt;BR&gt;[[Image:Cubic-body-centered.svg|60px]]&lt;BR&gt;[[Image:Cubic-face-centered.svg|60px]]

| 23|| T||332||[3,3]&lt;sup&gt;+&lt;/sup&gt;||12
|align=left|P23, F23, I23&lt;BR&gt;P2&lt;sub&gt;1&lt;/sub&gt;3, I2&lt;sub&gt;1&lt;/sub&gt;3
|- bgcolor=#ffffff align=center
! 200–206
| m{{overline|3}}|| T&lt;sub&gt;h&lt;/sub&gt;|| 3*2||[3&lt;sup&gt;+&lt;/sup&gt;,4]||24
|align=left|Pm{{overline|3}}, Pn{{overline|3}}, Fm{{overline|3}}, Fd{{overline|3}}, Im{{overline|3}}, Pa{{overline|3}}, Ia{{overline|3}}
|- bgcolor=#ffffff align=center
! 207–214
| 432|| O||432||[3,4]&lt;sup&gt;+&lt;/sup&gt;||24
|align=left|P432, P4&lt;sub&gt;2&lt;/sub&gt;32&lt;BR&gt;F432, F4&lt;sub&gt;1&lt;/sub&gt;32&lt;BR&gt;I432&lt;BR&gt;P4&lt;sub&gt;3&lt;/sub&gt;32, P4&lt;sub&gt;1&lt;/sub&gt;32, I4&lt;sub&gt;1&lt;/sub&gt;32
|- bgcolor=#ffffff align=center
! 215–220
| {{overline|4}}3m|| T&lt;sub&gt;d&lt;/sub&gt;|| *332||[3,3]||24
|align=left|P{{overline|4}}3m, F{{overline|4}}3m, I{{overline|4}}3m&lt;BR&gt;P{{overline|4}}3n, F{{overline|4}}3c, I{{overline|4}}3d 
|- bgcolor=#ffffff align=center
! 221–230
| m{{overline|3}}m|| O&lt;sub&gt;h&lt;/sub&gt;|| *432||[3,4]||48
|align=left|Pm{{overline|3}}m, Pn{{overline|3}}n, Pm{{overline|3}}n, Pn{{overline|3}}m&lt;BR&gt;Fm{{overline|3}}m, Fm{{overline|3}}c, Fd{{overline|3}}m, Fd{{overline|3}}c&lt;BR&gt;Im{{overline|3}}m, Ia{{overline|3}}d
|}

'''Note'''. An ''e'' plane is a double glide plane, one having glides in two different directions. They are found in seven orthorhombic, five tetragonal and five cubic space groups, all with centered lattice. The use of the symbol ''e'' became official with {{harvtxt|Hahn|2002}}.

The lattice system can be found as follows. If the crystal system is not trigonal then the lattice system is of the same type. If the crystal system is trigonal, then the lattice system is hexagonal unless the space group is one of the seven in the [[rhombohedral lattice system]] consisting of the 7 trigonal space groups in the table above whose name begins with R. (The term rhombohedral system is also sometimes used as an alternative name for the whole trigonal system.) The [[hexagonal lattice system]] is larger than the hexagonal crystal system, and consists of the hexagonal crystal system together with the 18 groups of the trigonal crystal system other than the seven whose names begin with R.

The [[Bravais lattice]] of the space group is determined by the lattice system together with the initial letter of its name, which for the non-rhombohedral groups is P, I, F, or C, standing for the principal, body centered, face centered, or C-face centered lattices.

==References==

{{Reflist}}

*{{Citation | last1=Barlow | first1=W | title=Über die geometrischen Eigenschaften starrer Strukturen und ihre Anwendung auf Kristalle | year=1894 | journal=Z. Kristallogr. | volume=23 | pages=1–63 | doi=10.1524/zkri.1894.23.1.1}}
*{{Citation | last1=Bieberbach | first1=Ludwig | title=Über die Bewegungsgruppen der Euklidischen Räume  | doi=10.1007/BF01564500 | year=1911 | journal=[[Mathematische Annalen]] | issn=0025-5831 | volume=70 | issue=3 | pages=297–336}}
*{{Citation | last1=Bieberbach | first1=Ludwig | title=Über die Bewegungsgruppen der Euklidischen Räume (Zweite Abhandlung.) Die Gruppen mit einem endlichen Fundamentalbereich  | doi=10.1007/BF01456724 | year=1912 | journal=[[Mathematische Annalen]] | issn=0025-5831 | volume=72 | issue=3 | pages=400–412}}
*{{Citation | last1=Brown | first1=Harold | last2=Bülow | first2=Rolf | last3=Neubüser | first3=Joachim | last4=Wondratschek | first4=Hans | last5=Zassenhaus | first5=Hans | author5-link=Hans Zassenhaus | title=Crystallographic groups of four-dimensional space | publisher=Wiley-Interscience [John Wiley &amp; Sons] | location=New York | isbn=978-0-471-03095-9 |mr=0484179 | year=1978}}
*{{Citation | last1=Burckhardt | first1=Johann Jakob | title=Die Bewegungsgruppen der Kristallographie | publisher=Verlag Birkhäuser, Basel | series=Lehrbücher und Monographien aus dem Gebiete der exakten Wissenschaften |mr=0020553 | year=1947 | volume=13}}
*{{Citation | last1=Burckhardt | first1=Johann Jakob | title=Zur Geschichte der Entdeckung der 230 Raumgruppen | doi=10.1007/BF00412962 |mr=0220837 | year=1967 | journal=[[Archive for History of Exact Sciences]] | issn=0003-9519 | volume=4 | issue=3 | pages=235–246}}
*{{Citation | last1=Conway | first1=John Horton | author1-link=John Horton Conway | last2=Delgado Friedrichs | first2=Olaf | last3=Huson | first3=Daniel H. | last4=Thurston | first4=William P. | author4-link=William Thurston | title=On three-dimensional space groups | url=http://www.emis.de/journals/BAG/vol.42/no.2/17.html |mr=1865535 | year=2001 | journal=Beiträge zur Algebra und Geometrie. Contributions to Algebra and Geometry | issn=0138-4821 | volume=42 | issue=2 | pages=475–507}}
*{{Citation | last1=Fedorov | first1=E. S. | title=Symmetry of Regular Systems of Figures | year=1891 | journal=Zap. Mineral. Obch. | volume=28 | issue=2 | pages=1–146}}
*{{Citation | last1=Fedorov | first1=E. S. | title=Symmetry of crystals | publisher=American Crystallographic Association | series=ACA Monograph  | year=1971 | volume=7}}
*{{Citation | editor1-last=Hahn | editor1-first=Theo | title=International Tables for Crystallography, Volume A: Space Group Symmetry | url=http://it.iucr.org/A/ | publisher=[[Springer-Verlag]] | location=Berlin, New York | edition=5th | isbn=978-0-7923-6590-7 | doi=10.1107/97809553602060000100 | year=2002 | last1=Hahn | first1=Th. | volume=A| series=International Tables for Crystallography }}
*{{Citation | last1=Hall | first1=S.R. | title=Space-Group Notation with an Explicit Origin | journal=Acta Crystallogr. A |volume=37 | issue=4 | pages=517–525 | year=1981|doi=10.1107/s0567739481001228 |bibcode = 1981AcCrA..37..517H }}
*{{citation |last1=Janssen|first1=T. |last2=Birman| first2=J.L. |last3=Dénoyer|first3=F.|last4=Koptsik|first4=V.A. |last5=Verger-Gaugry| first5=J.L. |last6=Weigel|first6=D.|last7=Yamamoto|first7=A. |last8=Abrahams| first8=S.C. |last9=Kopsky|first9=V.|title=Report of a Subcommittee on the Nomenclature of ''n''-Dimensional Crystallography. II. Symbols for arithmetic crystal classes, Bravais classes and space groups |journal=Acta Crystallogr. A |volume=58 |issue=Pt 6 |pages=605–621 |year=2002 |doi=10.1107/S010876730201379X }}
*{{Citation | last1=Kim | first1=Shoon K. | title=Group theoretical methods and applications to molecules and crystals | publisher=[[Cambridge University Press]] | isbn=978-0-521-64062-6 |mr=1713786 | year=1999 | doi=10.1017/CBO9780511534867}}
*{{citation |last=Litvin |first=D.B. |title=Tables of crystallographic properties of magnetic space groups |journal=Acta Crystallogr. A |volume=64 |issue=Pt 3 |pages=419–24 |date=May 2008 |pmid=18421131 |doi=10.1107/S010876730800768X |bibcode = 2008AcCrA..64..419L }}
*{{citation |last=Litvin |first=D.B. |title=Tables of properties of magnetic subperiodic groups |journal=Acta Crystallogr. A |volume=61 |issue=Pt 3 |pages=382–5 |date=May 2005 |pmid=15846043 |doi=10.1107/S010876730500406X |bibcode = 2005AcCrA..61..382L }}
*{{citation |last1=Neubüser |first1=J. |last2=Souvignier| first2=B. |last3=Wondratschek|first3=H.|title=Corrections to Crystallographic Groups of Four-Dimensional Space by Brown et al. (1978) [New York: Wiley and Sons] |journal=Acta Crystallogr. A |volume=58 |issue=Pt 3 |pages=301 |year=2002 |doi=10.1107/S0108767302001368|pmid=11961294 }}
*{{Citation | last1=Opgenorth| first1=J| last2=Plesken | first2=W| last3=Schulz | first3=T|title=Crystallographic Algorithms and Tables | year=1998 | journal=Acta Crystallogr. A| volume=54 | issue=Pt 5 | pages=517–531|doi=10.1107/S010876739701547X}}
*{{Citation | last1=Palistrant| first1=A. F. | title= Complete Scheme of Four-Dimensional Crystallographic Symmetry Groups | year=2012| journal=Crystallography Reports | volume=57 | issue=4 | pages=471–477 | doi=10.1134/S1063774512040104| bibcode=2012CryRp..57..471P}}
*{{Citation | last1=Plesken | first1=Wilhelm | last2=Hanrath | first2=W| title=The lattices of six-dimensional space | year=1984 | journal=Math. Comp. | volume=43 | issue=168 | pages=573–587 | doi=10.1090/s0025-5718-1984-0758205-5}}
*{{Citation | last1=Plesken | first1=Wilhelm | last2=Schulz | first2=Tilman | title=Counting crystallographic groups in low dimensions | url=http://projecteuclid.org/euclid.em/1045604675 |mr=1795312 | year=2000 | journal=Experimental Mathematics | issn=1058-6458 | volume=9 | issue=3 | pages=407–411 | doi=10.1080/10586458.2000.10504417}}
*{{Citation | last1=Schönflies | first1=Arthur Moritz | title=Theorie der Kristallstruktur | year=1891 | journal=Gebr. Bornträger, Berlin.}}
*{{Citation | last1=Souvignier| first1=Bernd| title=The four-dimensional magnetic point and space groups | year=2006 | journal=Z. Kristallogr.| volume=221 | pages=77–82 | doi=10.1524/zkri.2006.221.1.77|bibcode = 2006ZK....221...77S }}
*{{eom|id=C/c027190|title=Crystallographic group|last=Vinberg|first=E.}}
*{{Citation | doi=10.1007/BF02568029 | last1=Zassenhaus | first1=Hans | author1-link=Hans Zassenhaus | title=Über einen Algorithmus zur Bestimmung der Raumgruppen | url=http://www.digizeitschriften.de/index.php?id=166&amp;ID=380406 |mr=0024424 | year=1948 | journal=Commentarii Mathematici Helvetici | issn=0010-2571 | volume=21 | pages=117–141}}
*{{Citation | last1=Souvignier| first1=Bernd| title=Enantiomorphism of crystallographic groups in higher dimensions with results in dimensions up to 6 | year=2003 | journal=Acta Crystallogr. A| volume=59 | issue=3| pages=210–220 | doi=10.1107/S0108767303004161}}

==External links==
{{commons category|Space groups}}
* [http://www.iucr.org International Union of Crystallography]
* [http://neon.mems.cmu.edu/degraef/pointgroups/ Point Groups and Bravais Lattices]
* [http://www.cryst.ehu.es/] [[Bilbao Crystallographic Server]]
* [http://cci.lbl.gov/sginfo/ Space Group Info (old) ]
* [http://cci.lbl.gov/cctbx/explore_symmetry.html Space Group Info (new) ]
* [https://web.archive.org/web/20080324193801/http://cst-www.nrl.navy.mil/lattice/spcgrp/ Crystal Lattice Structures: Index by Space Group]
* [http://img.chem.ucl.ac.uk/sgp/mainmenu.htm Full list of 230 crystallographic space groups]
* [http://www.spacegroup.info/html/space_groups.html Interactive 3D visualization of all 230 crystallographic space groups]
* {{citation|url=http://www-ab.informatik.uni-tuebingen.de/talks/pdfs/Fibrifolds-Princeton%201999.pdf |title=The Fibrifold Notation and Classification for 3D Space Groups|first= Daniel H. |last=Huson|year=1999}}
* [http://www.geom.uiuc.edu/docs/reference/CRC-formulas/node9.html The Geometry Center: 2.1 Formulas for Symmetries in Cartesian Coordinates (two dimensions)]
* [http://www.geom.uiuc.edu/docs/reference/CRC-formulas/node45.html The Geometry Center: 10.1 Formulas for Symmetries in Cartesian Coordinates (three dimensions)]

{{Authority control}}

[[Category:Symmetry]]
[[Category:Crystallography]]
[[Category:Finite groups]]
[[Category:Discrete groups]]</text>
      <sha1>oe82j8wldnvtc8r005q7qdf9nroq2wz</sha1>
    </revision>
  </page>
  <page>
    <title>Sparse network</title>
    <ns>0</ns>
    <id>46864821</id>
    <revision>
      <id>869336453</id>
      <parentid>863766493</parentid>
      <timestamp>2018-11-17T23:44:26Z</timestamp>
      <contributor>
        <username>JJMC89</username>
        <id>24812038</id>
      </contributor>
      <minor/>
      <comment>removed orphan tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4717">In the context of [[network science]], a '''sparse network''' is a network with fewer links than the maximum possible number of links within the same network. The opposite of the sparse network is '''dense''' or '''complete network'''. The study of sparse networks is a relatively new area primarily stimulated by the study of real networks, such as social and computer networks.&lt;ref&gt;{{cite book|last1=Barabási|first1=Albert-László|title=Network Science|date=2015|publisher=Cambridge University Press|url=http://barabasi.com/networksciencebook/|accessdate=25 May 2015}}&lt;/ref&gt;

== Description ==
The number of links vary from network to network. The number of links in the network can be higher than the number of nodes in network, if each node is linked to every node in the network, such networks are called '''dense''':
L = links; N = nodes

&lt;math&gt;L=N^2&lt;/math&gt;

If each node is linked to all other nodes, except itself, which means that network does not contain loops, than this type of network is referred as '''complete'''. If the number of links is smaller than the maximum number of links, then it is a '''sparse network'''. Sparse connectivity can be identified in networks in which nodes are difficult to be linked:

&lt;math&gt;L&lt;L_{max}&lt;/math&gt;        &lt;big&gt;for&lt;/big&gt;        &lt;math&gt;L_{max} = N(N-1)/2&lt;/math&gt;

Most of the real networks are sparse, however they can still be efficiently analyzed. Typically, sparse networks have a [[Scale-free network|scale-free]] (power-law) node-degree distribution, meaning that there are few extremely linked nodes and many sparsely linked nodes within the same network.&lt;ref&gt;{{cite web|last1=Scholz|first1=Matthias|title=Getting connected - The highly connected society|url=http://www.network-science.org/highly-connected-society-dense-social-complex-networks.html|website=Network-Science|accessdate=25 May 2015}}&lt;/ref&gt;

== Node degree distribution ==
The node degree distribution changes with the increasing connectivity. Different link densities in the complex networks have different node-degree distribution, as Flickr Network Analysis suggests.&lt;ref&gt;http://jdmdh.episciences.org/77/pdf&lt;/ref&gt; The sparsely connected networks have a scale free, power law distribution. With increasing connectivity, the networks show increasing divergence from power law. One of the main factors, influencing on the network connectivity is the [[Node (networking)|node similarity]]. For instance, in [[social networks]], people are likely to be linked to each other if they share common social background, interests, tastes, beliefs, etc. In context of biological networks, proteins or other molecules are linked if they have exact or complementary fit of their complex surfaces.&lt;ref&gt;{{cite journal|last1=Scholz|first1=Matthias|title=Node similarity as a basic principle behind connectivity in complex networks|journal=Journal of Data Mining and Digital Humanities|date=7 January 2015|issue=77|url=http://jdmdh.episciences.org/77/pdf|accessdate=25 May 2015}}&lt;/ref&gt;

== Common terminology ==
If the nodes in the networks are not weighted, the structural components of the network can be shown through [[adjacency matrix]]. If the most elements in the matrix are zero, such matrix is referred as [[sparse matrix]]. In contrast, if most of the elements are nonzero, then the matrix is [[Dense matrix|dense]]. The sparsity or density of the matrix is identified by the fraction of the zero element to the total number of the elements in the matrix. Similarly, in the context of [[graph theory]], if the number of links is close to its maximum, then the graph would be known as [[dense graph]]. If the number of links is lower than the maximum number of links, this type of graphs are referred as [[sparse graph]].&lt;ref&gt;{{cite web|last1=Nykamp|first1=Duane Q.|title=An introduction to networks|url=http://mathinsight.org/network_introduction|website=Math Insight|accessdate=25 May 2015}}&lt;/ref&gt;

== Applications ==
Sparse Network can be found in [[Social network|social]], [[Computer network|computer]] and [[biological network]]s, as well as, its applications can be found in [[transport network|transportation]], power-line, citation networks, etc.  Since most real networks are large and sparse, there were several models developed to understand and analyze them.&lt;ref&gt;{{cite web|last1=Gribonval|first1=Rémi|title=Sparse Models, Algorithms and Learning for Large-scale data|url=http://www.small-project.eu/|website=SMALL|accessdate=25 May 2015}}&lt;/ref&gt; These networks have inspired sparse [[Network on a chip|network-on-chip]] design in multiprocessor embedded [[computer engineering]].

==References==
{{reflist|2}}

[[Category:Networks]]
[[Category:Network theory]]
[[Category:Network topology]]</text>
      <sha1>4vasl9uig3wljppzgejaaaux2rbu4hg</sha1>
    </revision>
  </page>
  <page>
    <title>Stabilizer code</title>
    <ns>0</ns>
    <id>5045759</id>
    <revision>
      <id>847023816</id>
      <parentid>842445191</parentid>
      <timestamp>2018-06-22T11:22:54Z</timestamp>
      <contributor>
        <ip>2001:630:E4:4220:CCA1:B3FC:DBCA:2CA2</ip>
      </contributor>
      <comment>/* Example of a stabilizer code */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15758">{{Cleanup|date=March 2010}}
The theory of [[quantum error correction]] plays a prominent role in the practical realization and engineering of
[[quantum computing]] and [[quantum communication]] devices. The first quantum
error-correcting codes  are strikingly similar to [[error correction|classical block codes]]  in their
operation and performance. Quantum error-correcting codes restore a noisy,
[[decoherence|decohered]] [[quantum state]] to a pure quantum state. A
[[Group action#Orbits and stabilizers|stabilizer]] quantum error-correcting code appends [[Ancilla (quantum computing)|ancilla qubits]]
to qubits that we want to protect. A unitary encoding circuit rotates the
global state into a subspace of a larger [[Hilbert space]]. This highly [[Quantum entanglement|entangled]],
encoded state corrects for local noisy errors. A quantum error-correcting code makes [[quantum computation]]
and [[quantum communication]] practical by providing a way for a sender and
receiver to simulate a noiseless qubit channel given a [[noisy qubit channel]]
whose noise conforms to a particular error model.

The stabilizer theory of [[quantum error correction]] allows one to import some
classical binary or quaternary codes for use as a quantum code. However, when importing the
classical code, it must satisfy the [[dual code|dual-containing]] (or self-orthogonality)
constraint. Researchers have found many examples of classical codes satisfying
this constraint, but most classical codes do not. Nevertheless, it is still useful to import classical codes in this way (though, see how the [[entanglement-assisted stabilizer formalism]] overcomes this difficulty).

== Mathematical background ==

The Stabilizer formalism exploits elements of
the [[Pauli group]] &lt;math&gt;\Pi&lt;/math&gt; in formulating quantum error-correcting codes. The set
&lt;math&gt;\Pi=\left\{  I,X,Y,Z\right\}  &lt;/math&gt; consists of the [[Pauli operators]]:
:&lt;math&gt;
I\equiv
\begin{bmatrix}
1 &amp; 0\\
0 &amp; 1
\end{bmatrix}
,\ X\equiv
\begin{bmatrix}
0 &amp; 1\\
1 &amp; 0
\end{bmatrix}
,\ Y\equiv
\begin{bmatrix}
0 &amp; -i\\
i &amp; 0
\end{bmatrix}
,\ Z\equiv
\begin{bmatrix}
1 &amp; 0\\
0 &amp; -1
\end{bmatrix}
.
&lt;/math&gt;
The above operators act on a single [[qubit]]---a state represented by a vector in a two-dimensional
[[Hilbert space]]. Operators in &lt;math&gt;\Pi&lt;/math&gt; have [[eigenvalues]] &lt;math&gt;\pm1&lt;/math&gt; and either [[Commutative property|commute]]
or [[anti-commute]]. The set &lt;math&gt;\Pi^{n}&lt;/math&gt; consists of &lt;math&gt;n&lt;/math&gt;-fold [[tensor product]]s of
[[Pauli operator]]s:
:&lt;math&gt;
\Pi^{n}=\left\{
\begin{array}
[c]{c}
e^{i\phi}A_{1}\otimes\cdots\otimes A_{n}:\forall j\in\left\{  1,\ldots
,n\right\}  A_{j}\in\Pi,\ \ \phi\in\left\{  0,\pi/2,\pi,3\pi/2\right\}
\end{array}
\right\}  .
&lt;/math&gt;
Elements of &lt;math&gt;\Pi^{n}&lt;/math&gt; act on a quantum register of &lt;math&gt;n&lt;/math&gt; qubits. We
occasionally omit [[tensor product]] symbols in what follows so that
:&lt;math&gt;A_{1}\cdots A_{n}\equiv A_{1}\otimes\cdots\otimes A_{n}.&lt;/math&gt;
The &lt;math&gt;n&lt;/math&gt;-fold [[Pauli group]]
&lt;math&gt;\Pi^{n}&lt;/math&gt; plays an important role for both the encoding circuit and the
error-correction procedure of a quantum stabilizer code over &lt;math&gt;n&lt;/math&gt; qubits.

== Definition ==

Let us define an &lt;math&gt;\left[  n,k\right]  &lt;/math&gt; stabilizer quantum error-correcting
code to encode &lt;math&gt;k&lt;/math&gt; logical qubits into &lt;math&gt;n&lt;/math&gt; physical qubits. The rate of such a
code is &lt;math&gt;k/n&lt;/math&gt;. Its stabilizer &lt;math&gt;\mathcal{S}&lt;/math&gt; is an [[abelian group|abelian]] [[subgroup]] of the
&lt;math&gt;n&lt;/math&gt;-fold Pauli group &lt;math&gt;\Pi^{n}&lt;/math&gt;: &lt;math&gt;\mathcal{S}\subset\Pi^{n}&lt;/math&gt;. &lt;math&gt;\mathcal{S}&lt;/math&gt;
does not contain the operator &lt;math&gt;-I^{\otimes n}&lt;/math&gt;. The simultaneous
&lt;math&gt;+1&lt;/math&gt;-[[eigenspace]] of the operators constitutes the ''codespace''. The
codespace has dimension &lt;math&gt;2^{k}&lt;/math&gt; so that we can encode &lt;math&gt;k&lt;/math&gt; qubits into it. The
stabilizer &lt;math&gt;\mathcal{S}&lt;/math&gt; has a minimal [[Representation (mathematics)|representation]] in terms of &lt;math&gt;n-k&lt;/math&gt;
independent generators
:&lt;math&gt;\left\{  g_{1},\ldots,g_{n-k}\ |\ \forall i\in\left\{
1,\ldots,n-k\right\}  ,\ g_{i}\in\mathcal{S}\right\} .&lt;/math&gt;

The generators are
independent in the sense that none of them is a product of any other two (up
to a [[Quantum state|global phase]]). The operators &lt;math&gt;g_{1},\ldots,g_{n-k}&lt;/math&gt; function in the same
way as a [[parity check matrix]] does for a classical [[linear block code]].

== Stabilizer error-correction conditions ==

One of the fundamental notions in quantum error correction theory is that it
suffices to correct a [[Discrete set|discrete]] error set with [[Support (mathematics)|support]] in the [[Pauli group]]
&lt;math&gt;\Pi^{n}&lt;/math&gt;. Suppose that the errors affecting an
encoded quantum state are a subset &lt;math&gt;\mathcal{E}&lt;/math&gt; of the [[Pauli group]] &lt;math&gt;\Pi^{n}&lt;/math&gt;:
:&lt;math&gt;\mathcal{E}\subset\Pi^{n}.&lt;/math&gt;

Because &lt;math&gt;\mathcal{E}&lt;/math&gt; and &lt;math&gt;\mathcal{S}&lt;/math&gt; are both subsets of  &lt;math&gt;\Pi^{n}&lt;/math&gt;, an error &lt;math&gt;E\in\mathcal{E}&lt;/math&gt; that affects an
encoded quantum state either [[Commutative property|commute]]s or [[anticommute]]s with any particular
element &lt;math&gt;g&lt;/math&gt; in &lt;math&gt;\mathcal{S}&lt;/math&gt;. The error &lt;math&gt;E&lt;/math&gt; is correctable if it
anticommutes with an element &lt;math&gt;g&lt;/math&gt; in &lt;math&gt;\mathcal{S}&lt;/math&gt;. An anticommuting error
&lt;math&gt;E&lt;/math&gt; is detectable by [[quantum measurement|measuring]] each element &lt;math&gt;g&lt;/math&gt; in &lt;math&gt;\mathcal{S}&lt;/math&gt; and
computing a [[syndrome]] &lt;math&gt;\mathbf{r}&lt;/math&gt; identifying &lt;math&gt;E&lt;/math&gt;. The syndrome is a binary
vector &lt;math&gt;\mathbf{r}&lt;/math&gt; with length &lt;math&gt;n-k&lt;/math&gt; whose elements identify whether the
error &lt;math&gt;E&lt;/math&gt; commutes or anticommutes with each &lt;math&gt;g\in\mathcal{S}&lt;/math&gt;. An error
&lt;math&gt;E&lt;/math&gt; that commutes with every element &lt;math&gt;g&lt;/math&gt; in &lt;math&gt;\mathcal{S}&lt;/math&gt; is correctable if
and only if it is in &lt;math&gt;\mathcal{S}&lt;/math&gt;. It corrupts the encoded state if it
commutes with every element of &lt;math&gt;\mathcal{S}&lt;/math&gt; but does not lie in &lt;math&gt;\mathcal{S}
&lt;/math&gt;. So we compactly summarize the stabilizer error-correcting conditions: a
stabilizer code can correct any errors &lt;math&gt;E_{1},E_{2}&lt;/math&gt; in &lt;math&gt;\mathcal{E}&lt;/math&gt; if
:&lt;math&gt;E_{1}^{\dagger}E_{2}\notin\mathcal{Z}\left(  \mathcal{S}\right)  &lt;/math&gt;

or

:&lt;math&gt;E_{1}^{\dagger}E_{2}\in\mathcal{S}&lt;/math&gt;

where &lt;math&gt;\mathcal{Z}\left(  \mathcal{S}
\right)  &lt;/math&gt; is the [[centralizer]] of &lt;math&gt;\mathcal{S}&lt;/math&gt; (i.e., the subgroup of elements that commute with all members of &lt;math&gt;\mathcal{S}&lt;/math&gt;, also known as the commutant).

== Relation between [[Pauli group]] and binary vectors ==

A simple but useful mapping exists between elements of &lt;math&gt;\Pi&lt;/math&gt; and the binary
[[vector space]] &lt;math&gt;\left(  \mathbb{Z}_{2}\right)  ^{2}&lt;/math&gt;. This mapping gives a
simplification of quantum error correction theory. It represents quantum codes
with [[bit vector|binary vector]]s and [[binary operation]]s rather than with [[Pauli operator]]s and
[[matrix operation]]s respectively.

We first give the mapping for the one-qubit case. Suppose &lt;math&gt;\left[  A\right]  &lt;/math&gt;
is a set of [[equivalence class]]es of an [[Operator (physics)|operator]] &lt;math&gt;A&lt;/math&gt; that have the same [[phase (waves)|phase]]:
:&lt;math&gt;
\left[  A\right]  =\left\{  \beta A\ |\ \beta\in\mathbb{C},\ \left\vert
\beta\right\vert =1\right\}  . 
&lt;/math&gt;

Let &lt;math&gt;\left[  \Pi\right]  &lt;/math&gt; be the set of phase-free Pauli operators where
&lt;math&gt;\left[  \Pi\right]  =\left\{  \left[  A\right]  \ |\ A\in\Pi\right\}  &lt;/math&gt;.
Define the map &lt;math&gt;N:\left(  \mathbb{Z}_{2}\right)  ^{2}\rightarrow\Pi&lt;/math&gt; as
:&lt;math&gt;
00 \to I, \,\,
01 \to X, \,\,
11 \to Y, \,\,
10 \to Z
&lt;/math&gt;

Suppose &lt;math&gt;u,v\in\left(  \mathbb{Z}_{2}\right)  ^{2}&lt;/math&gt;. Let us employ the
shorthand &lt;math&gt;u=\left(  z|x\right)  &lt;/math&gt; and &lt;math&gt;v=\left(  z^{\prime}|x^{\prime
}\right)  &lt;/math&gt; where &lt;math&gt;z&lt;/math&gt;, &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;z^{\prime}&lt;/math&gt;, &lt;math&gt;x^{\prime}\in\mathbb{Z}_{2}&lt;/math&gt;. For
example, suppose &lt;math&gt;u=\left(  0|1\right)  &lt;/math&gt;. Then &lt;math&gt;N\left(  u\right)  =X&lt;/math&gt;. The
map &lt;math&gt;N&lt;/math&gt; induces an [[isomorphism]] &lt;math&gt;\left[  N\right]  :\left(  \mathbb{Z}
_{2}\right)  ^{2}\rightarrow\left[  \Pi\right]  &lt;/math&gt; because addition of vectors
in &lt;math&gt;\left(  \mathbb{Z}_{2}\right)  ^{2}&lt;/math&gt; is equivalent to multiplication of
Pauli operators up to a global phase:
:&lt;math&gt;
\left[  N\left(  u+v\right)  \right]  =\left[  N\left(  u\right)  \right]
\left[  N\left(  v\right)  \right]  .
&lt;/math&gt;

Let &lt;math&gt;\odot&lt;/math&gt; denote the [[symplectic product]] between two elements &lt;math&gt;u,v\in\left(
\mathbb{Z}_{2}\right)  ^{2}&lt;/math&gt;:
:&lt;math&gt;
u\odot v\equiv zx^{\prime}-xz^{\prime}.
&lt;/math&gt;
The symplectic product &lt;math&gt;\odot&lt;/math&gt; gives the [[Commutative property|commutation]] relations of elements of
&lt;math&gt;\Pi&lt;/math&gt;:
:&lt;math&gt;
N\left(  u\right)  N\left(  v\right)  =\left(  -1\right)  ^{\left(  u\odot
v\right)  }N\left(  v\right)  N\left(  u\right)  .
&lt;/math&gt;

The symplectic product and the mapping &lt;math&gt;N&lt;/math&gt; thus give a useful way to phrase
Pauli relations in terms of [[Boolean algebra (logic)|binary algebra]].
The extension of the above definitions and mapping &lt;math&gt;N&lt;/math&gt; to multiple qubits is
straightforward. Let &lt;math&gt;\mathbf{A}=A_{1}\otimes\cdots\otimes A_{n}&lt;/math&gt; denote an
arbitrary element of &lt;math&gt;\Pi^{n}&lt;/math&gt;. We can similarly define the phase-free
&lt;math&gt;n&lt;/math&gt;-qubit Pauli group &lt;math&gt;\left[  \Pi^{n}\right]  =\left\{  \left[
\mathbf{A}\right]  \ |\ \mathbf{A}\in\Pi^{n}\right\}  &lt;/math&gt; where
:&lt;math&gt;
\left[  \mathbf{A}\right]  =\left\{  \beta\mathbf{A}\ |\ \beta\in
\mathbb{C},\ \left\vert \beta\right\vert =1\right\}  .
&lt;/math&gt;

The [[group operation]] &lt;math&gt;\ast&lt;/math&gt; for the above equivalence class is as follows:
:&lt;math&gt; \left[  \mathbf{A}\right]  \ast\left[  \mathbf{B}\right]    \equiv\left[
A_{1}\right]  \ast\left[  B_{1}\right]  \otimes\cdots\otimes\left[
A_{n}\right]  \ast\left[  B_{n}\right]  =\left[  A_{1}B_{1}\right]  \otimes\cdots\otimes\left[  A_{n}B_{n}\right]
=\left[  \mathbf{AB}\right]  .
&lt;/math&gt;
The equivalence class &lt;math&gt;\left[  \Pi^{n}\right]  &lt;/math&gt; forms a [[commutative group]]
under operation &lt;math&gt;\ast&lt;/math&gt;. Consider the &lt;math&gt;2n&lt;/math&gt;-dimensional [[vector space]]
:&lt;math&gt;
\left(  \mathbb{Z}_{2}\right)  ^{2n}=\left\{  \left(  \mathbf{z,x}\right)
:\mathbf{z},\mathbf{x}\in\left(  \mathbb{Z}_{2}\right)  ^{n}\right\}  .
&lt;/math&gt;
It forms the commutative group &lt;math&gt;(\left(  \mathbb{Z}_{2}\right)  ^{2n},+)&lt;/math&gt; with
operation &lt;math&gt;+&lt;/math&gt; defined as binary vector addition. We employ the notation
&lt;math&gt;\mathbf{u}=\left(  \mathbf{z}|\mathbf{x}\right)  ,\mathbf{v}=\left(
\mathbf{z}^{\prime}|\mathbf{x}^{\prime}\right)  &lt;/math&gt; to represent any vectors
&lt;math&gt;\mathbf{u,v}\in\left(  \mathbb{Z}_{2}\right)  ^{2n}&lt;/math&gt; respectively. Each
vector &lt;math&gt;\mathbf{z}&lt;/math&gt; and &lt;math&gt;\mathbf{x}&lt;/math&gt; has elements &lt;math&gt;\left(  z_{1},\ldots
,z_{n}\right)  &lt;/math&gt; and &lt;math&gt;\left(  x_{1},\ldots,x_{n}\right)  &lt;/math&gt; respectively with
similar representations for &lt;math&gt;\mathbf{z}^{\prime}&lt;/math&gt; and &lt;math&gt;\mathbf{x}^{\prime}&lt;/math&gt;.
The ''symplectic product'' &lt;math&gt;\odot&lt;/math&gt; of &lt;math&gt;\mathbf{u}&lt;/math&gt; and &lt;math&gt;\mathbf{v}&lt;/math&gt; is
:&lt;math&gt;
\mathbf{u}\odot\mathbf{v\equiv}\sum_{i=1}^{n}z_{i}x_{i}^{\prime}-x_{i}
z_{i}^{\prime},
&lt;/math&gt;
or
:&lt;math&gt;
\mathbf{u}\odot\mathbf{v\equiv}\sum_{i=1}^{n}u_{i}\odot v_{i},
&lt;/math&gt;
where &lt;math&gt;u_{i}=\left(  z_{i}|x_{i}\right)  &lt;/math&gt; and &lt;math&gt;v_{i}=\left(  z_{i}^{\prime
}|x_{i}^{\prime}\right)  &lt;/math&gt;. Let us define a map &lt;math&gt;\mathbf{N}:\left(
\mathbb{Z}_{2}\right)  ^{2n}\rightarrow\Pi^{n}&lt;/math&gt; as follows:
:&lt;math&gt;
\mathbf{N}\left(  \mathbf{u}\right)  \equiv N\left(  u_{1}\right)
\otimes\cdots\otimes N\left(  u_{n}\right)  .
&lt;/math&gt;
Let
:&lt;math&gt;
\mathbf{X}\left(  \mathbf{x}\right)   \equiv X^{x_{1}}\otimes\cdots\otimes
X^{x_{n}}, \,\,\,\,\,\,\,
\mathbf{Z}\left(  \mathbf{z}\right)     \equiv Z^{z_{1}}\otimes\cdots\otimes
Z^{z_{n}},
&lt;/math&gt;
so that &lt;math&gt;\mathbf{N}\left(  \mathbf{u}\right)  &lt;/math&gt; and &lt;math&gt;\mathbf{Z}\left(
\mathbf{z}\right)  \mathbf{X}\left(  \mathbf{x}\right)  &lt;/math&gt; belong to the same
[[equivalence class]]:
:&lt;math&gt;
\left[  \mathbf{N}\left(  \mathbf{u}\right)  \right]  =\left[  \mathbf{Z}
\left(  \mathbf{z}\right)  \mathbf{X}\left(  \mathbf{x}\right)  \right]  .
&lt;/math&gt;
The map &lt;math&gt;\left[  \mathbf{N}\right]  :\left(  \mathbb{Z}_{2}\right)
^{2n}\rightarrow\left[  \Pi^{n}\right]  &lt;/math&gt; is an [[isomorphism]] for the same
reason given as in the previous case:
:&lt;math&gt;
\left[  \mathbf{N}\left(  \mathbf{u+v}\right)  \right]  =\left[
\mathbf{N}\left(  \mathbf{u}\right)  \right]  \left[  \mathbf{N}\left(
\mathbf{v}\right)  \right]  ,
&lt;/math&gt;
where &lt;math&gt;\mathbf{u,v}\in\left(  \mathbb{Z}_{2}\right)  ^{2n}&lt;/math&gt;. The [[symplectic product]]
captures the commutation relations of any operators &lt;math&gt;\mathbf{N}\left(
\mathbf{u}\right)  &lt;/math&gt; and &lt;math&gt;\mathbf{N}\left(  \mathbf{v}\right)  &lt;/math&gt;:
:&lt;math&gt;
\mathbf{N\left(  \mathbf{u}\right)  N}\left(  \mathbf{v}\right)  =\left(
-1\right)  ^{\left(  \mathbf{u}\odot\mathbf{v}\right)  }\mathbf{N}\left(
\mathbf{v}\right)  \mathbf{N}\left(  \mathbf{u}\right)  .
&lt;/math&gt;
The above binary representation and [[symplectic algebra]] are useful in making
the relation between classical linear [[error correction]] and [[quantum error correction]] more explicit.

By comparing quantum error correcting codes in this language to [[symplectic vector space]]s, we can see the following. A [[Symplectic vector space#Subspaces|symplectic]] subspace corresponds to a [[direct sum]] of Pauli algebras (i.e., encoded qubits), while an [[Symplectic vector space#Subspaces|isotropic]] subspace corresponds to a set of stabilizers.

==Example of a stabilizer code==

An example of a stabilizer code is the five qubit
&lt;math&gt;\left[[  5,1,3\right]]  &lt;/math&gt; stabilizer code. It encodes &lt;math&gt;k=1&lt;/math&gt; logical qubit
into &lt;math&gt;n=5&lt;/math&gt; physical qubits and protects against an arbitrary single-qubit
error. It has code distance &lt;math&gt;d=3&lt;/math&gt;. Its stabilizer consists of &lt;math&gt;n-k=4&lt;/math&gt; Pauli operators:
:&lt;math&gt;
\begin{array}
[c]{ccccccc}
g_{1} &amp; = &amp; X &amp; Z &amp; Z &amp; X &amp; I\\
g_{2} &amp; = &amp; I &amp; X &amp; Z &amp; Z &amp; X\\
g_{3} &amp; = &amp; X &amp; I &amp; X &amp; Z &amp; Z\\
g_{4} &amp; = &amp; Z &amp; X &amp; I &amp; X &amp; Z
\end{array}
&lt;/math&gt;
The above operators commute. Therefore, the codespace is the simultaneous
+1-eigenspace of the above operators. Suppose a single-qubit error occurs on
the encoded quantum register. A single-qubit error is in the set &lt;math&gt;\left\{
X_{i},Y_{i},Z_{i}\right\}&lt;/math&gt; where &lt;math&gt;A_{i}&lt;/math&gt; denotes a Pauli error on qubit &lt;math&gt;i&lt;/math&gt;.
It is straightforward to verify that any arbitrary single-qubit error has a
unique syndrome. The receiver corrects any single-qubit error by identifying
the syndrome and applying a corrective operation.

==References==

* D. Gottesman, "Stabilizer codes and quantum error correction," quant-ph/9705052, Caltech Ph.D. thesis. https://arxiv.org/abs/quant-ph/9705052
* P. W. Shor, “Scheme for reducing decoherence in quantum computer memory,” Phys. Rev. A, vol. 52, no. 4, pp. R2493–R2496, Oct 1995.
* A. R. Calderbank and P. W. Shor, “Good quantum error-correcting codes exist,” Phys. Rev. A, vol. 54, no. 2, pp.&amp;nbsp;1098–1105, Aug 1996. Available at https://arxiv.org/abs/quant-ph/9512032
* A. M. Steane, “Error correcting codes in quantum theory,” Phys. Rev. Lett., vol. 77, no. 5, pp.&amp;nbsp;793–797, Jul 1996.
* A. Calderbank, E. Rains, P. Shor, and N. Sloane, “Quantum error correction via codes over GF(4),” IEEE Trans. Inf. Theory, vol. 44, pp.&amp;nbsp;1369–1387, 1998. Available at https://arxiv.org/abs/quant-ph/9608006

{{Quantum computing}}

[[Category:Linear algebra]]
[[Category:Quantum computing]]</text>
      <sha1>2ujne8o3ximhvy3trrn4e69cmtzwuwl</sha1>
    </revision>
  </page>
  <page>
    <title>Stationary phase approximation</title>
    <ns>0</ns>
    <id>1459010</id>
    <revision>
      <id>868575161</id>
      <parentid>854597787</parentid>
      <timestamp>2018-11-13T02:14:29Z</timestamp>
      <contributor>
        <ip>128.115.190.44</ip>
      </contributor>
      <comment>/* Formula */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9143">In [[mathematics]], the '''stationary phase approximation''' is a basic principle of [[asymptotic analysis]], applying to '''oscillatory integrals'''

:&lt;math&gt;I(k) = \int g(x) e^{i k f(x)} \, dx&lt;/math&gt;

taken over ''n''-dimensional space ℝ&lt;sup&gt;''n''&lt;/sup&gt; where ''i'' is the [[imaginary unit]]. Here ''f'' and ''g'' are real-valued [[smooth function]]s. The role of ''g'' is to ensure convergence; that is, ''g'' is a [[test function]]. The large real parameter ''k'' is considered in the limit as &lt;math&gt;k \to \infty &lt;/math&gt;.

This method originates from the 19th century, and is due to [[George Gabriel Stokes]] and [[Lord Kelvin]].&lt;ref&gt;{{Citation
| last1 = Courant
| first1 = Richard
| author1-link = Richard Courant
| last2 = Hilbert
| first2 = David
| author2-link = David Hilbert
| title = [[Methoden der mathematischen Physik|Methods of mathematical physics]]
| volume = 1
| page = 474
| year = 1953
| edition = 2nd revised
| publisher = Interscience Publishers
| location = New York
| oclc = 505700
}}&lt;/ref&gt;

==Basics==

The main idea of stationary phase methods relies on the cancellation of sinusoids with rapidly varying phase. If many sinusoids have the same phase and they are added together, they will add constructively. If, however, these same sinusoids have phases which change rapidly as the frequency changes, they will add incoherently, varying between constructive and destructive addition at different times.

== Formula ==
Letting &lt;math&gt;\Sigma&lt;/math&gt; denote the set of [[Critical point (mathematics)|critical points]] of the function &lt;math&gt;f&lt;/math&gt; (i.e. points where &lt;math&gt;\nabla f =0&lt;/math&gt;), under the assumption that &lt;math&gt;g&lt;/math&gt; is either compactly supported or has exponential decay, and that all critical points are nondegenerate (i.e. &lt;math&gt;\det(\mathrm{Hess}(f(x_0))\neq 0&lt;/math&gt; for &lt;math&gt;x_0 \in \Sigma&lt;/math&gt;) we have the following asymptotic formula, as &lt;math&gt;k\to \infty&lt;/math&gt;:

&lt;math&gt;\int_{\mathbb{R}^n}g(x)e^{ikf(x)}=\sum_{x_0\in \Sigma} e^{ik f(x_0)}|\det(\mathrm{Hess}(f))|^{-1/2}e^{\pi i/4 \mathrm{sign}(\mathrm{Hess(f)})}(2\pi/k)^{n/2}g(x_0)+o(k^{-n/2})&lt;/math&gt;

Here &lt;math&gt;\mathrm{Hess}(f)&lt;/math&gt; denotes the [[Hessian matrix|Hessian]] of &lt;math&gt;f&lt;/math&gt;.

For &lt;math&gt;n=1&lt;/math&gt;, this reduces to:

&lt;math&gt;\int_\mathbb{R}g(x)e^{ikf(x)}dx=\sum_{x_0\in \Sigma} g(x_0)e^{ik f(x_0)+\mathrm{sign}(f''(x_0))i\pi/4}\left(\frac{2\pi}{k |f''(x_0)|}\right)^{1/2}+o(k^{-1/2})&lt;/math&gt;

In this case the assumptions on &lt;math&gt;f&lt;/math&gt; reduce to all the critical points being non-degenerate.

This is just the [[Wick rotation|Wick rotated]] version of the formula for the [[method of steepest descent]].

==An example==

Consider a function

:&lt;math&gt;f(x,t) = \frac{1}{2\pi} \int_{\mathbb R} F(\omega) e^{i [k(\omega) x - \omega t]} \, d\omega&lt;/math&gt;.

The phase term in this function, {{nowrap|''ϕ'' {{=}} ''k''(''ω'') ''x'' − ''ω'' ''t''}}, is stationary when

:&lt;math&gt;\frac{d}{d\omega}\mathopen{}\left(k(\omega) x - \omega t\right)\mathclose{} = 0&lt;/math&gt;

or equivalently,

:&lt;math&gt;\frac{d k}{d\omega} = \frac{t}{x}&lt;/math&gt;.

Solutions to this equation yield dominant frequencies ''ω''&lt;sub&gt;0&lt;/sub&gt; for some ''x'' and ''t''. If we expand ''ϕ'' as a [[Taylor series]] about ''ω''&lt;sub&gt;0&lt;/sub&gt; and neglect terms of order higher than {{nowrap|(''ω'' − ''ω''&lt;sub&gt;0&lt;/sub&gt;)&lt;sup&gt;2&lt;/sup&gt;}},

:&lt;math&gt;\phi = \left[k(\omega_0) x - \omega_0 t\right] + \frac{1}{2} x k''(\omega_0) (\omega - \omega_0)^2 + \cdots&lt;/math&gt;

where ''k''″ denotes the second derivative of ''k''.  When ''x'' is relatively large, even a small difference {{nowrap|(''ω'' − ''ω''&lt;sub&gt;0&lt;/sub&gt;)}} will generate rapid oscillations within the integral, leading to cancellation. Therefore we can extend the limits of integration beyond the limit for a Taylor expansion. If we double the real contribution from the positive frequencies of the transform to account for the negative frequencies,

:&lt;math&gt;f(x, t) \approx \frac{1}{2\pi} \cdot 2 \operatorname{Re} \left\{ e^{i \left[k(\omega_0) x - \omega_0 t\right]} \left|F(\omega_0)\right| \int_{\mathbb R} e^{\frac{1}{2} i x k''(\omega_0) (\omega - \omega_0)^2} \, d\omega \right\}&lt;/math&gt;.

This integrates to

:&lt;math&gt;f(x, t) \approx \frac{\left|F(\omega_0)\right|}{\pi} \sqrt{\frac{2\pi}{x \left|k''(\omega_0)\right|}} \cos\left[k(\omega_0) x - \omega_0 t \pm \frac{\pi}{4}\right]&lt;/math&gt;.

==Reduction steps==

The first major general statement of the principle involved is that the asymptotic behaviour of ''I''(''k'') depends only on the [[critical point (mathematics)|critical point]]s of ''f''.  If by choice of ''g'' the integral is localised to a region of space where ''f'' has no critical point, the resulting integral tends to 0 as the frequency of oscillations is taken to infinity. See for example [[Riemann-Lebesgue lemma]].

The second statement is that when ''f'' is a [[Morse function]], so that the singular points of ''f'' are [[non-degenerate critical point|non-degenerate]] and isolated, then the question can be reduced to the case ''n'' = 1. In fact, then, a choice of ''g'' can be made to split the integral into cases with just one critical point ''P'' in each. At that point, because the [[Hessian determinant]] at ''P'' is by assumption not 0, the [[Morse lemma]] applies. By a change of co-ordinates ''f'' may be replaced by

:&lt;math&gt;(x_1^2 + x_2^2 + \cdots + x_j^2) - (x_{j + 1}^2 + x_{j + 2}^2 + \cdots + x_n^2)&lt;/math&gt;.

The value of ''j'' is given by the [[signature of a quadratic form|signature]] of the [[Hessian matrix]] of ''f'' at ''P''. As for ''g'', the essential case is that ''g'' is a product of [[bump function]]s of ''x''&lt;sub&gt;''i''&lt;/sub&gt;. Assuming now without loss of generality that ''P'' is the origin,  take a smooth bump function ''h'' with value 1 on the interval {{nowrap|[−1, 1]}} and quickly tending to 0 outside it. Take

:&lt;math&gt;g(x) = \prod_i h(x_i)&lt;/math&gt;,

then [[Fubini's theorem]] reduces ''I''(''k'') to a product of integrals over the real line like

:&lt;math&gt;J(k) = \int h(x) e^{i k f(x)} \, dx&lt;/math&gt;

with ''f''(''x'') = ±''x''&lt;sup&gt;2&lt;/sup&gt;. The case with the minus sign is the [[complex conjugate]] of the case with the plus sign, so there is essentially one required asymptotic estimate.

In this way asymptotics can be found for oscillatory integrals for Morse functions. The degenerate case requires further techniques (see for example [[Airy function]]).

==One-dimensional case==

The essential statement is this one:

:&lt;math&gt;\int_{-1}^1 e^{i k x^2} \, dx = \sqrt{\frac{\pi}{k}} e^{i \pi / 4} + \mathcal O \mathopen{}\left(\frac{1}{k}\right)\mathclose{}&lt;/math&gt;.

In fact by [[contour integration]] it can be shown that the main term on the right hand side of the equation is the value of the integral on the left hand side, extended over the range {{nowrap|[−∞, ∞]}} (for a proof see [[Fresnel integral]]). Therefore it is the question of estimating away the integral over, say, {{nowrap|[1, ∞]}}.&lt;ref&gt;See for example [[Jean Dieudonné]], ''Infinitesimal Calculus'', p. 119 or [[Jean Dieudonné]], ''Calcul Infinitésimal'', p.135.&lt;/ref&gt;

This is the model for all one-dimensional integrals ''I''(''k'') with ''f'' having a single non-degenerate critical point at which ''f'' has [[second derivative]] &gt; 0. In fact the model case has second derivative 2 at 0. In order to scale using ''k'', observe that replacing ''k'' by {{nowrap|''c'' ''k''}}
where ''c'' is constant is the same as scaling ''x'' by √''c''. It follows that for general values of {{nowrap|''f''″(0) &gt; 0}}, the factor {{nowrap|√(''π'' / ''k'')}} becomes

:&lt;math&gt;\sqrt{\frac{2 \pi}{k f''(0)}}&lt;/math&gt;.

For {{nowrap|''f''″(0) &lt; 0}} one uses the complex conjugate formula, as mentioned before.

== Lower Order Terms ==
As can be seen from the formula, stationary phase provides the first-order approximation of the asymptotic behavior of the integral. The lower order terms can be understood as a sum of over [[Feynman diagram|Feynman diagrams]] with various weighting factors, for well behaved &lt;math&gt;f&lt;/math&gt;.

==See also==

* [[Common integrals in quantum field theory]]

==Notes==
{{Reflist}}

==References==
* Bleistein, N. and Handelsman, R. (1975), ''Asymptotic Expansions of Integrals'',  Dover, New York.
* [[Victor Guillemin]] and Shlomo Sternberg (1990), [http://www.ams.org/online_bks/surv14/ ''Geometric Asymptotics''], (see Chapter 1).
* {{citation|first=L.|last=Hörmander|authorlink=Lars Hörmander|title=Linear Partial Differential Operators, Volume 1|publisher=Springer-Verlag|year=1976|isbn=978-3-540-00662-6}}.
* Aki, Keiiti; &amp; Richards, Paul G. (2002). "Quantitative Seismology" (2nd ed.), pp 255–256. University Science Books, {{isbn|0-935702-96-2}}
*Wong, R. (2001), ''Asymptotic Approximations of Integrals'',  Classics in Applied Mathematics, Vol. 34. Corrected reprint of the 1989 original. Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA. xviii+543 pages, {{isbn|0-89871-497-4}}.
*Dieudonné, J. (1980), ''Calcul Infinitésimal'', Hermann, Paris

==External links==
*{{Springer|id=S/s087270|title=Stationary phase, method of the}}

[[Category:Mathematical analysis]]
[[Category:Perturbation theory]]</text>
      <sha1>gb84682163gh8jmd16k47q2n91vcvjq</sha1>
    </revision>
  </page>
  <page>
    <title>Tarka-Sangraha</title>
    <ns>0</ns>
    <id>52318693</id>
    <revision>
      <id>865274393</id>
      <parentid>865274374</parentid>
      <timestamp>2018-10-22T21:34:01Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>added [[Category:17th-century works]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5650">'''Tarka-Sangraha''' is a treatise in [[Sanskrit]] giving a foundational exposition of the ancient Indian system of logic and reasoning.  The work is authored by Annambhatta and the author himself has given a detailed commentary, called Tarka-Sangraha Deepika,  for the text.&lt;ref&gt;{{cite book|last1=James Robert Ballantyne|title=Lectures on the Nyaya Philosophy Embracing the Text of Tarka Sangraha|date=1849|publisher=Printed for the use of Benares College|location=Allahabad|url=https://books.google.co.in/books?hl=en&amp;lr=&amp;id=VZ_a-UYzrcIC&amp;oi=fnd&amp;pg=PA1&amp;dq=tarka+sangraha&amp;ots=sDB0eSvK5s&amp;sig=Obeo4QEYXvDFr2V4WIaG_HrU1Io#v=onepage&amp;q=tarka%20sangraha&amp;f=false|accessdate=16 November 2016}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Annambhaṭṭa, James Robert Ballantyne|title=The Tarka-sangraha, with a translation and notes in Hindí and English|date=1851|publisher=Presbyterian Mission Press|url=https://archive.org/details/tarkasangrahawi00ballgoog|accessdate=17 November 2016}}&lt;/ref&gt; Annambhatta composed  the text as well as the commentary in the second half of 17th century CE. &lt;ref&gt;{{cite book|last1=Edited by Yashawant Vasudev Athalye|title=Tarka Sangraha Of Annambhatta (Bombay Sanskrit Series)|date=1918|publisher=The Department of Public Insruction|location=Bombay|url=https://archive.org/stream/TarkaSangrahaOfAnnambhatta1918BombaySanskritSeries/Tarka%20Sangraha%20of%20Annambhatta%201918%20-%20Bombay%20Sanskrit%20Series#page/n1/mode/2up|accessdate=17 November 2016}}&lt;/ref&gt; The text of Tarka-sangraha is a small book with about 15 pages only&lt;ref&gt;{{cite web|title=Tarka-Sangraha of Annambhatta|url=http://sanskritdocuments.org/doc_z_misc_major_works/tarka2.pdf|website=Sanskrit Documents|accessdate=18 November 2016}}&lt;/ref&gt; and it was composed to help boys and girls learn easily the basic principles of Nyaya. Of all the works of Annambhatta, only Tarka-Sangraha and its commentary attained wide acceptance. They have been used as basic text for beginners for several generations. 

In  Indian philosophical writings, the traditional structure of presenting a system consisted of three things: ''uddesa'' (listing of items to be discussed), ''laksana'' (defining each item in the list) and ''pariksa'' (critically examining whether the definitions apply properly to the items defined). The Tarka-Sangraha follows this model except for the third item of ''pariksa''. The text presents the [[ontology]], logic and [[epistemology]] of the [[Nyaya]]-[[Vaiseshika]] system.&lt;ref name=Jha/&gt; 

==Annambhatta, author of Tarka-Sangraha==

Practically only very little is known about Annambhatta the author of Tarka-Sangraha. From the scanty references to other works and writers contained in his works, it has been estimated that Annambhatta must be a comparatively modern author and he must have flourished during the seventeenth century CE. His father's name was Advaitavidyacarya Tirumala. He was Tailanga Brahmin of [[North Arcot]] District of erstwhile state of [[Andhra Pradesh]] who had settled down in [[Benares]]. &lt;ref name=Jha&gt;{{cite book|last1=V. N. Jha|title=Tarkasangraha Of Annambhatta (English Translation with Notes)|date=January 2010|publisher=Chinmaya International Foundation|location=Ernakulam, Kerala|page=ix|url=https://archive.org/details/TarkasangrahaOfAnnambhattaVNJha|accessdate=17 November 2016}}&lt;/ref&gt; Tirumala was a Rigvedi Smarta Brahmana well versed in [[Vedanta]] philosophy. Annambhatta was a learned man in several areas of traditional scholarship, namely, Nyaya, [[Vyakarana]], Vedanta and [[Purva-Mimamsa]]. Though not as well-known as Tarka-Sangraha, many  of Annambhatta's works on other disciplines have survived. Besides, Tarka-Sangraha and its Commentary Dipika, the following works have been attributed to Annambhatta:&lt;ref name=author/&gt;
*Mitakshara
*Tattva-Bodhini-Tika
*Nyaya-Parisishta-Prakasa
*Subodhini-Sudhasara
*Katyayana-Pratisakhya-Vyakhyana
*Mahabhashya-Vivarnodyatana
*Tattvacinthamnyaloka-Siddhanjana
*Brahmasutra-Vritti

==Commentaries on Tarka-Sangraha==
Because of its wide popularity, several scholars have written commentaries on Tarks-Sangraha. Annambhatta, the author of the treatise, himself has written a commentary named Tarka-Samgraha-Dipika. Researchers have located as many as 90 different commentaries on Tarka-Sangraha including the one by Annambhatta.&lt;ref name=Jha/&gt;

==Notes==
*For a detailed discussion on the date of Annambhatta, author of Tarka-Sangraha, see  ''Tarka Sangraha of Annambhatta (Bombay Sanskrit Series)''.&lt;ref name=author&gt;{{cite book|last1=Edited by Yashawant Vasudev Athalye|title=Tarka Sangraha Of Annambhatta (Bombay Sanskrit Series)|date=1918|publisher=The Department of Public Insruction|location=Bombay|url=https://archive.org/stream/TarkaSangrahaOfAnnambhatta1918BombaySanskritSeries/Tarka%20Sangraha%20of%20Annambhatta%201918%20-%20Bombay%20Sanskrit%20Series#page/n1/mode/2up|accessdate=17 November 2016}} (Annambhatta and his works pp.LX - LXX)&lt;/ref&gt;
*The text of Tarka-Sangraha without any commentary has been reproduced in the [[Devanagari]] script itself in the website of Sanskrit Documents.org.&lt;ref name=doc&gt;{{cite web|title=Tarka-Sangraha of Annambhatta|url=http://sanskritdocuments.org/doc_z_misc_major_works/tarka2.html?lang=sa|website=Sanskrit Documents|accessdate=18 November 2016}}&lt;/ref&gt;

==See also==
*{{Portal-inline|Epistemology}}
*{{Portal-inline|Logic}}
*{{Portal-inline|Philosophy}}

==References==
{{reflist}}

{{Hindudharma}}
{{Indian Philosophy}}
{{Philosophy topics}}
{{Logic|state=collapsed}}

[[Category:Philosophical traditions]]
[[Category:Indian philosophy]]
[[Category:History of logic]]
[[Category:Nyaya|!]]
[[Category:17th-century works]]</text>
      <sha1>lnt5j1ednicyqp5fdqb00wu4tqa2vdb</sha1>
    </revision>
  </page>
  <page>
    <title>Theory of Lie groups</title>
    <ns>0</ns>
    <id>37262638</id>
    <revision>
      <id>727545534</id>
      <parentid>687448427</parentid>
      <timestamp>2016-06-29T17:56:20Z</timestamp>
      <contributor>
        <username>Randy Kryn</username>
        <id>4796325</id>
      </contributor>
      <comment>italicize title</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2434">{{italic title}}
In mathematics, '''''Theory of Lie groups''''' is a series of books on [[Lie group]]s by {{harvs|txt|authorlink=Claude Chevalley|first=Claude|last=Chevalley|year1=1946|year2=1951|year3=1955}}. The first in the series was one of the earliest books on Lie groups to treat them from the global point of view, and for many years was the standard text on Lie groups. The second and third volumes, on [[algebraic group]]s and [[Lie algebra]]s, were written in French, and later reprinted bound together as one volume. Apparently further volumes were planned but not published, though his lectures {{harv|Chevalley|2005}} on the classification of [[semisimple algebraic group]]s could be considered as a continuation of the series.

==References==

*{{Citation | last1=Chevalley | first1=Claude | title=Theory of Lie Groups. I | url=http://press.princeton.edu/titles/284.html | publisher=[[Princeton University Press]] | series=Princeton Mathematical Series | isbn=978-0-691-04990-8 |mr=0015396 | year=1946 | volume=8}}
*{{Citation | last1=Chevalley | first1=Claude | title=Théorie des groupes de Lie. Tome II. Groupes algébriques | publisher=Hermann &amp; Cie., Paris | series=Actualités Sci. Ind. |mr=0051242 | year=1951 | volume=1152}}
*{{Citation | last1=Chevalley | first1=Claude | title=Théorie des groupes de Lie. Tome III. Théorèmes généraux sur les algèbres de Lie | publisher=Hermann &amp; Cie, Paris | series=Actualités Sci. Ind. |mr=0068552 | year=1955 | volume=1226}}
*{{Citation | last1=Chevalley | first1=Claude | title= Théorie des groupes de Lie : Groupes algébriques, théorèmes généraux sur les algèbres de Lie | publisher=Hermann | location=Paris | language=French | id=Reprint of volumes II and III bound as one volume | year=1968 | volume=8}}
*{{Citation | last1=Chevalley | first1=Claude | editor1-last=Cartier | editor1-first=P. | title=Classification des groupes algébriques semi-simples | origyear=1958 | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Collected works. | isbn=978-3-540-23031-1 |mr=0106966 | year=2005 | volume=3}}
*{{Citation | last1=Smith | first1=P. A. | title=Review: Claude Chevalley, The theory of Lie groups, I | url=http://projecteuclid.org/euclid.bams/1183511055 | year=1947 | journal= Bull. Amer. Math. Soc. | volume=53 | issue=9 | pages=884–887 | doi=10.1090/s0002-9904-1947-08876-5}}

[[Category:Mathematics books]]
[[Category:Lie groups]]</text>
      <sha1>8q7obmjb3i32qz4eswhdsaqbe4n4vcq</sha1>
    </revision>
  </page>
  <page>
    <title>Uniform field theory</title>
    <ns>0</ns>
    <id>29749902</id>
    <revision>
      <id>591889738</id>
      <parentid>562620620</parentid>
      <timestamp>2014-01-22T16:53:25Z</timestamp>
      <contributor>
        <username>Dthomsen8</username>
        <id>6277327</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="783">{{For|the uniform field theory of physics|Unified field theory}}

'''Uniform field theory''' is a formula for determining the effective [[electrical resistance]] of a parallel wire system. By calculating the mean square field acting throughout a section of coil, formulae are obtained for the effective resistances of single- and multi-layer solenoidal coils of either solid or stranded wire.&lt;ref&gt;E. F. Armstrong and T. P. Hilditch, [http://www.nature.com/nature/journal/v107/n2696/abs/107573b0.html A study of catalytic actions at solid surfaces], ''Nature,''  107, pages 573-575 (30 June 1921).&lt;/ref&gt;

==See also==
*[[Mathematical methods in electronics]]

==References==
{{Reflist}}

[[Category:Applied mathematics]]
[[Category:Electronic engineering]]


{{Electromagnetism-stub}}</text>
      <sha1>q36tfsquvpv8hwjgk1n8be96xo7e3xx</sha1>
    </revision>
  </page>
  <page>
    <title>Vafa–Witten theorem</title>
    <ns>0</ns>
    <id>3036126</id>
    <revision>
      <id>794085965</id>
      <parentid>790524229</parentid>
      <timestamp>2017-08-05T18:58:18Z</timestamp>
      <contributor>
        <username>Headbomb</username>
        <id>1461430</id>
      </contributor>
      <minor/>
      <comment>/* top */cleanup using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1393">{{expert needed|date=August 2017}}
In [[theoretical physics]], the '''Vafa–Witten theorem''', named after [[Cumrun Vafa]] and [[Edward Witten]], is a [[theorem]] that shows that vector-like [[global symmetry|global symmetries]] (those that transform as expected under reflections) such as [[isospin]] and [[baryon number]] in vector-like gauge theories like [[Quantum chromodynamics|QCD]] cannot be [[spontaneous symmetry breaking|spontanteously broken]] as long as the [[theta angle]] is zero. This theorem can be proved by showing the exponential fall off of the propagator of fermions.

==See also==
*[[F-theory]]

==References==
*{{Cite journal
  | author1-link = Cumrun Vafa | last1 = Vafa | first1 = Cumrun
  | author2-link = Edward Witten | last2 = Witten | first2 = Edward
  | title = Restrictions on symmetry breaking in vector-like gauge theories
  | date = 1984}}
*{{Cite journal
  | doi = 10.1103/PhysRevLett.53.535
  | author1-link = Cumrun Vafa | last1 = Vafa | first1 = Cumrun
  | author2-link = Edward Witten | last2 = Witten | first2 = Edward
  | title = Parity Conservation in Quantum Chromodynamics
  | journal = Phys. Rev. Lett.
  | volume = 53
  | issue = 6
  | pages = 535–536
  | date = August 1984 | bibcode=1984PhRvL..53..535V}}

{{DEFAULTSORT:Vafa-Witten theorem}}
[[Category:Quantum field theory]]
[[Category:Theorems in mathematical physics]]


{{quantum-stub}}</text>
      <sha1>nihr77f09022hoj53ftswcggwcocnlf</sha1>
    </revision>
  </page>
  <page>
    <title>Valentin Afraimovich</title>
    <ns>0</ns>
    <id>27479533</id>
    <revision>
      <id>845033263</id>
      <parentid>840186428</parentid>
      <timestamp>2018-06-08T21:25:15Z</timestamp>
      <contributor>
        <username>Paintspot</username>
        <id>18915484</id>
      </contributor>
      <comment>removed [[Category:Living people]] using [[WP:HC|HotCat]] (Uhhh, removed Living People category...)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11715">{{BLP sources|date=May 2010}}
'''Valentin Afraimovich''' ({{lang-ru|Валентин Сендерович Афраймович}}, 2 April 1945, [[Kirov, Kirov Oblast]], [[USSR]] – 21 February 2018, [[Nizhny Novgorod]], [[Russia]]&lt;ref&gt;Leonid Bunimovich,   Anatoly Neishtadt, and   Jürgen Kurths, [https://doi.org/10.1063/1.5034461 Editorial: In memoriam—Valentin S. (Valya) Afraimovich (2 April 1945–21 February 2018)] // Chaos 28, 040401 (2018)&lt;/ref&gt;) was a [[USSR|Soviet]], [[Russia]]n and [[Mexico|Mexican]] [[mathematician]]. He made contributions to [[dynamical systems theory]], qualitative theory of [[ordinary differential equations]], [[bifurcation theory]], concept of [[attractor]],&lt;ref&gt;{{cite web|url=http://www.ams.org/journals/tran/1996-348-12/S0002-9947-96-01578-4/home.html |title=Transactions of the American Mathematical Society |doi=10.1090/S0002-9947-96-01578-4 |publisher=Ams.org |date= |accessdate=2015-03-02}}&lt;/ref&gt; [[strange attractors]], [[space-time]] [[Chaos theory|chaos]], [[mathematical models]] of nonequilibrium media and [[biological systems]], traveling [[wave]]s in lattices, [[complexity]] of [[orbits]] and dimension-like characteristics in [[dynamical systems]].&lt;ref&gt;{{cite web|url=https://www.springer.com/mathematics/analysis/book/978-3-540-18173-6?changeHeader|title=Dynamical Systems V|work=Springer.com|accessdate=2015-03-02}}&lt;/ref&gt;

==Biography==
He got his Ph.D. ([[Kandidat]]) degree in 1974 at the [[Nizhny Novgorod State University]] under the advice of L. P. Shil’nikov. Also in 1990 he received his [[Doctor of Science]] degree in Mathematics and Physics, at [[Saratov State University]] in Russia.
After then, he held several academic positions, including:
* 1992-1995 Visiting Principal Research Scientist, [[Georgia Institute of Technology]], [[Atlanta]].
* 1995-1996 Visiting Professor, [[Northwestern University]], [[Evanston, IL]].
* 1996-1998 Visiting Professor, [[National Tsing Hua University]], [[Hsinchu]], [[Taiwan]].
* 1998–present Professor–researcher, IICO, [[Universidad Autónoma de San Luis Potosí]], S.L.P., [[México]].
Afraimovich's students include Mark Shereshevsky, Nizhny Novgorod 1990; Todd Ray Young, Atlanta, Georgia, 1995; Antonio Morante, San Luis Potosí (SLP) México, 2002; Salomé Murgia, SLP México, 2003; [[Alberto Cordonet]], SLP Mexico, 2002; Francisco Ordaz, SLP Mexico, 2004; Leticia Ramirez, SLP Mexico, 2005; Irma Tristan-Lopez, SLP Mexico, 2010; Rosendo Vazquez-Bañuelos, 2013.

==Selected scientific papers==
* VS Afraimovich, G Moses, TR Young. Two dimensional heteroclinic attractor in the generalized Lotka-Volterra system. Nonlinearity 29 (2016). 1645-1667. doi:10.1088/0951-7715/29/5/1645.
* V. Afraimovich, X. Gong, M. Rabinovich. Sequential memory: Binding dynamics. Chaos, 5(10):103118, 2015.
* V. Afraimovich. M. Courbage, L. Glebsky. Directional Complexity and entropy for Lift Mappings. Discrete and Continuous Dynamical Systems. Series B. Mathematical Modelling, Analysis and Computations. Volume 20, Number 10. December 2015.
* Valentin S. Afraimovich, Todd R. Young, Mikhail I. Rabinovich. Hierarchical Heteroclinics in Dynamical Model of Cognitive Processes: Chunking. International Journal of Bifurcation and Chaos Vol. 24, No. 10, 1450132 (2014)
* V. S. Afraimovich, L. P. Shilnikov. Symbolic Dynamics in Multidimensional Annulus and Chimera States. International Journal of Bifurcation and Chaos. Vol: 24, N: 08 (August 2014) DOI: 10.1142/S0218127414400021, 1440002
* V. S. Afraimovich, T. Young, M.K. Muezzinglu, M. Rabinovich. Nonlinear Dynamics Of Emotion-Cognition Interaction: When Emotion Does Not Destroy Cognition? Bull Math Biol (2011) 73:266-284. DOI 10.1007/s11538-010-9572-x
* V. S. Afraimovich, L.A. Bunimovich, S.V. Moreno, Dynamical Networks: Continuous Time and General Discrete Time Models, Regular and Chaotic Dynamics, Vol. 15, 129-147, 2010. 
* V. Afraimovich, L. Glebsky, Measures Related To ''e,n''-Complexity Functions, Discrete And Continuous Dynamical Systems, Vol. 22, N 12. 2008.
* V. S. Afraimovich, M. Rabinovich, R. Huerta, P. Varona, Transient Cognitive Dynamics, Metastability, and Decision Making, PLOS Computational Biology 04, 05: 1&amp;ndash;9. 2008.
* V. Afraimovich. Some topological properties of lattice dynamical systems, in Dynamics of Coupled Map Lattices and of Related Spatially Extended Systems, eds. J.-R. Chazottes and B. Fernandez, Lecture Notes in Physics, Springer 2005, p 153-180.
* V. Afraimovich, V. Zhigulin and M. Rabinovich, On the origin of reproducible sequential activity in neural circuits, Chaos 14 (2004), 1123&amp;ndash;1129.
* V. Afraimovich, L. Bunimovich and J. Hale, Sistemi dinamici, Storia della Scienza IX, Enciclopedia Italiana 841&amp;ndash;850. (2003)&lt;ref&gt;{{cite web|url=http://www.treccani.it/portale/opencms/Portale/homePage.html |accessdate=25 May 2010 |deadurl=yes |archiveurl=https://web.archive.org/web/20100209031906/http://www.treccani.it/portale/opencms/Portale/homePage.html |archivedate=9 February 2010 }}&lt;/ref&gt;
* V. Afraimovich, G.M. Zaslavsky, Space time complexity in Hamiltonian dynamics, Chaos, 13, 2, (2003), pp.&amp;nbsp;519&amp;ndash;532.
* V. Afraimovich, J. R. Chazottes and A. Cordonet, Synchronization in directionally coupled systems, Discrete Contin. Dyn. Syst., Ser. B, vol. 1 (2001), 421&amp;ndash;442.
* V. Afraimovich, J.-R. Chazottes and B. Saussol, Local dimensions for Poincare recurrences, Electron.Res.Announc.Amer.Math.Soc., vol.6 (2000), 64&amp;ndash;74 &lt;ref&gt;{{cite web|url=http://www.aimsciences.org/journals/pdfs.jsp?paperID=2397&amp;mode=full |title=Local Dimensions for Poincare Recurrences |publisher=Aimsciences.org |accessdate=2015-03-02}}&lt;/ref&gt;&lt;ref&gt;{{cite web|author=Nancy Imelda Schafer|url=http://esi-topics.com/nhp/2004/may-04-ValentinAfraimovich.html |title=New Hot Paper Comment by Valentin Afraimovich |publisher=Esi-topics.com |date= |accessdate=2015-03-02}}&lt;/ref&gt;
* V. Afraimovich and T. Young, Relative density of irrational rotation numbers in families of circle di eomorphisms. Ergodic theory and dynamical systems, 18 (1998), 1&amp;ndash;16.
* V. Afraimovich and S-N. Chow, Topological spatial chaos and homoclinic points of Z-d actions in lattice dynamical systems, Japan J. Indust.Appl. Math. 12 1995, 1&amp;ndash;17.
* V. Afraimovich, S.-N. Chow and W. Liu, Lorenz type attractors from codimensional-one bifurcation, Journal of Dynamics and Differential Equations, 7 (2), 1995, 375&amp;ndash;407.
* V. Afraimovich and V.I. Nekorkin, Chaos of traveling waves in a discrete chain of di usively coupled maps, International Journal of Bifurcation and Chaos, 4 (3) (1994).
* V. Afraimovich and Ya. Pesin, Hyperbolicity of infinite-dimensional drift systems, Nonlinearity, 3 (1990), 1&amp;ndash;19.
* V. Afraimovich, N.N. Verichev and M.I. Rabinovich, Stochastic synchronization of oscillations in dissipative systems, Radio zika, 29 (9), 1050&amp;ndash;1060 (1986) (in Russian).
* V. Afraimovich, V.V. Bykov and L.P. Shil'nikov, On attracting nonstructurally stable limiting sets of the type of Lorenz attractor, Trans. of Moscow Math. Soc., 44 (1982).
* V. Afraimovich and L.P. Shil'nikov, On critical sets of Morse&amp;ndash;Smale systems, Trans. Moscow Math. Soc., 28 (1973).

==Selected bibliography==
* {{Cite book | last=Afraimovich | first=V.S. | author2=[[Vladimir Arnold|V.I. Arnold]] | title=Bifurcation Theory And Catastrophe Theory | publisher=Springer | year=1999 |isbn=3-540-65379-1 |display-authors=etal}}
* {{Cite book | last=Afraimovich | first=V.S. |author2=I. S. Aranson |author3=M. I. Rabinovich  | title=Multidimensional Strange Attractors and Turbulence | publisher=Harwood Academic | isbn=3-7186-4868-7 }}
*  {{Cite book | last=Afraimovich | first=V.S. |author2=Sze-Bi Hsu | title=Lectures On Chaotic Dynamical Systems | publisher=Ams/Ip Studies In Advanced Mathematics | isbn=0-8218-3168-2 }}
* {{Cite book | last=Afrajmovich | first=V.S. | author2=[[Vladimir Arnold|V.I. Arnold]] |author3=Yu S. Il'yashenko |author4=L. P. Shil'nikov | title=Dynamical Systems V | publisher=Springer | isbn=3-540-18173-3 }}
* {{Cite book | last=Afraimovich | first=V.S. |author2=V. I. Nekorkin |author3=G. V. Osipov |author4=V. D. Shalfeev  | title=Stability, structures and chaos in nonlinear synchronization networks | isbn=978-981-279-871-8 }}
* {{Cite book | last=Afraimovich | first=V.S. | author2=E. Ugalde |author3=J. Urías | title=Fractal Dimensions for Poincaré Recurrences (Monograph Series on Nonlinear Sciences and Complexity Volume 2) | publisher=Elsevier | year=2006 |isbn=0-444-52189-5 }}
* {{Cite book | last=Афраймович | first=В.С. |author2=Э. Угальде |author3=Х. Уриас  | title=Фрактальные Размерности для Времен Возвращения Пуанкаре | publisher=R&amp;C Dynamics, Russia |year=2011 | isbn=978-5-93972-903-1 }}
* {{Cite book | editor-last=Luo | editor-first=A. | editor2=Afraimovich V.S. | title=Hamiltonian Chaos Beyond the KAM Theory | publisher=Springer | year=2010 |isbn=978-3-642-12717-5 }}
* {{Cite book | editor-last=Luo | editor-first=A. | editor2=Afraimovich V.S. | title=Long-range Interactions, Stochasticity and Fractional Dynamics | publisher=Springer | year=2010 |isbn=978-3-642-12342-9 }}
* {{Cite book | editor-last=Luo | editor-first=A. | editor2=Afraimovich V.S. | title=Continuous Dynamical Systems | publisher=Higher Education Press Limited Company and L&amp;H Scientific Publishing | year=2012 | isbn=978-1-62155-000-6 }}
* {{Cite book | editor-last=Luo | editor-first=A. | editor2=Afraimovich V.S. | title=Discrete and Switching Dynamical Systems | publisher=Higher Education Press Limited Company and L&amp;H Scientific Publishing | year=2012 | isbn=978-1-62155-002-0 }}
* {{Cite book |  last=Afraimovich | first=V. | author2=Luo A. | author3=Fu X. | title=Nonlinear Dynamics and Complexity (Nonlinear Systems and Complexity) | publisher=Springer-Verlag Gmbh | year=2014 | isbn=3319023527 }}
* {{Cite book | last=Afraimovich | first=V. | author2=Machado J.A.T. | author3=Zhang J. | title=Complex Motions and Chaos in Nonlinear Systems  (Nonlinear Systems and Complexity) | publisher=Springer-Verlag Gmbh | year=2016 | isbn=978-3-319-28764-5 }}

==See also==
{{Portal|Mathematics}}
*[[Dynamical systems]]
*[[Homoclinic orbit]]
*[[Topology]]
*[[Chaos theory]]
*[[Attractor]]
*[[Bifurcation theory]]
*[[Catastrophe theory]]
*[[Torus]]

==References==
{{Reflist}}

==External links==
* [http://www.iico.uaslp.mx/investigadores/afraimovich.htm Personal web page]
* [http://www.iico.uaslp.mx/valefest/ Conference celebrating Afraimovich's 65th anniversary]
* {{DBLP|name=Valentin S. Afraimovich}}
* [http://www.aimsciences.org/journals/processSearch3.jsp American Institute of Mathematical Sciences]
* [http://www.foroconsultivo.org.mx/comisiones_sni_2010/cv/a1_valentin_afraimovich.pdf A super short curriculum vitae]
* {{MathGenealogy|name=Valentin S. Afraimovich}}
* [http://www.scholarpedia.org/article/Torus_breakdown Torus breakdown article at Scholarpedia]
* [http://conf.uni-obuda.hu/nsc2012 Lagrange Award 2012]
* [https://www.springer.com/gp/book/9783319580616#aboutBook Book dedicated to V. Afraimovich]
* [https://www.springer.com/cda/content/document/cda_downloaddocument/9783319580616-p1.pdf?SGWID=0-0-45-1609817-p180836606 preface]

{{Authority control}}

{{Use dmy dates|date=June 2013}}

{{DEFAULTSORT:Afraimovich, Valentin}}
[[Category:1945 births]]
[[Category:2018 deaths]]
[[Category:20th-century Russian mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Russian mathematicians]]
[[Category:Soviet mathematicians]]
[[Category:Mathematical analysts]]
[[Category:Moscow State University faculty]]
[[Category:Dynamical systems]]
[[Category:People from Kirov, Kirov Oblast]]</text>
      <sha1>n5v161ye05waux06ilpqfkwtjw8zkmh</sha1>
    </revision>
  </page>
</mediawiki>
