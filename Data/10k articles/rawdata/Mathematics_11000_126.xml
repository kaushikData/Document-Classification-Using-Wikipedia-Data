<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>3x + 1 semigroup</title>
    <ns>0</ns>
    <id>49840293</id>
    <revision>
      <id>815557840</id>
      <parentid>811548998</parentid>
      <timestamp>2017-12-15T15:45:44Z</timestamp>
      <contributor>
        <username>Jnestorius</username>
        <id>89336</id>
      </contributor>
      <minor/>
      <comment>/* Definition */ wl " [[generator (mathematics)|generated]] by the set"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4073">{{DISPLAYTITLE:3''x'' + 1 semigroup}}
In [[algebra]], the '''3''x'' + 1 semigroup''' is a special [[subsemigroup]] of the multiplicative [[semigroup]] of all positive [[rational number]]s.&lt;ref name="Applegate"&gt;{{cite journal | last1 = Applegate | first1 = David | author1-link = David Applegate | last2 = Lagarias | first2 = Jeffrey C. | author2-link = Jeffrey Lagarias | doi = 10.1016/j.jnt.2005.06.010 | issue = 1 | journal = Journal of Number Theory | mr = 2204740 | pages = 146–159 | title = The {{math|3''x'' + 1}} semigroup | volume = 117 | year = 2006}}&lt;/ref&gt; The elements of a generating set of this semigroup are related to the sequence of numbers involved in  the yet to be proved conjecture known as the [[Collatz conjecture]] or the "3''x'' + 1 problem". The 3''x'' + 1 semigroup has been used to prove a weaker form of the Collatz conjecture. In fact, it was in such context the concept of the 3''x'' + 1 semigroup was introduced by H. Farkas in 2005.&lt;ref&gt;{{cite book|last1=H. Farkas|title="Variants  of  the 3 N + 1 problem  and  multiplicative  semigroups", Geometry, Spectral Theory, Groups and Dynamics: Proceedings in Memor y of Robert Brooks|date=2005|publisher=Springer}}&lt;/ref&gt; Various generalizations of the 3''x'' + 1 semigroup have been constructed and their properties have been investigated.&lt;ref name="Ana"&gt;{{cite web|last1=Ana Caraiani|title=Multiplicative Semigroups Related to the 3x+1 Problem|url=https://web.math.princeton.edu/~caraiani/papers/semigroups.pdf|publisher=Princeton University|accessdate=17 March 2016}}&lt;/ref&gt;

==Definition==
The 3''x'' + 1 semigroup is the multiplicative semigroup of positive rational numbers [[generator (mathematics)|generated]] by the set
:&lt;math&gt;\{2\}\cup \left\{\frac{2k+1}{3k+2} : k\geq 0\right\}=\left\{ 2, \frac{1}{2}, \frac{3}{5}, \frac{5}{8}, \frac{7}{11},\ldots \right\}.&lt;/math&gt;

The function ''T'' : ''Z'' → ''Z'', where ''Z'' is the set of all integers, as defined below is used in the "shortcut" definition of the [[Collatz conjecture#As a parity sequence|Collatz conjecture]]:
:&lt;math&gt;T(n)=\begin{cases} n/2 &amp; \text{if } n \text{ is even}\\ (3n+1)/2 &amp; \text{if } n \text{ is odd}\end{cases}&lt;/math&gt;
The Collatz conjecture asserts that for each positive integer ''n'', there is some iterate of ''T'' with itself which maps ''n'' to 1, that is, there is some integer ''k'' such that ''T''&lt;sup&gt;(''k'')&lt;/sup&gt;(''n'') = 1.  For example if  ''n'' = 7 then the values of ''T''&lt;sup&gt;(''k'')&lt;/sup&gt;(''n'') for ''k'' = 1, 2, 3, . . . are 11, 17, 26, 13, 20, 10, 5, 8, 4, 2, 1 and ''T''&lt;sup&gt;(11)&lt;/sup&gt;(7) = 1.

The relation between the 3''x'' + 1 semigroup and the Collatz conjecture is that the 3''x''&amp;nbsp;+&amp;nbsp;1 semigroup is also generated by the set &lt;math&gt; \left\{ \dfrac{n}{T(n)} : n&gt;0 \right\}&lt;/math&gt;.

==The weak Collatz conjecture==

The weak Collatz conjecture asserts the following: "The 3''x'' + 1 semigroup contains every positive integer." This was formulated by Farkas and it has been proved to be true as a consequence of the following property of the 3''x'' + 1 semigroup.&lt;ref name=Applegate/&gt;
"The 3''x'' + 1 semigroup ''S'' equals the set of all positive rationals ''a''/''b'' in lowest terms having the property that ''b'' ≠ 0 (mod 3). In particular, ''S'' contains every positive integer."

==The wild semigroup==
The semigroup generated by the set &lt;math&gt;\left\{\frac{1}{2}\right\}\cup \left\{\frac{3k+2}{2k+1}:k\geq 0\right\}&lt;/math&gt;,
which is also generated by the set &lt;math&gt;\left\{\frac{T(n)}{n}: n&gt;0\right\}&lt;/math&gt;, is called the wild semigroup. The integers in the wild semigroup consists of all integers ''m'' such that ''m'' ≠ 0 (mod 3).&lt;ref&gt;{{cite journal|last1=J.C. Lagarias|title=Wild and Wooley numbers|journal=American Mathematical Monthly|date=2006|volume=113|doi=10.2307/27641862|url=https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/lagarias97.pdf|accessdate=18 March 2016}}&lt;/ref&gt;

==See also==
*[[Wild number]]

==References==
{{reflist}}

[[Category:Semigroup theory]]
[[Category:Arithmetic]]
[[Category:Integer sequences]]
[[Category:Number theory]]</text>
      <sha1>nrxi487w9s1n667yddhnhzoya0msxak</sha1>
    </revision>
  </page>
  <page>
    <title>Approximate tangent space</title>
    <ns>0</ns>
    <id>41452559</id>
    <revision>
      <id>718339142</id>
      <parentid>590442260</parentid>
      <timestamp>2016-05-02T22:56:42Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>[[Template:CSdoc|Ref]] [[Template:CSdoc#date|cleanup]], [[WP:AWB/T|typo(s) fixed]]: On the other hand → On the other hand, (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5275">In [[geometric measure theory]] an '''approximate tangent space''' is a [[measure theory|measure theoretic]] generalization of the concept of a [[tangent space]] for a [[differentiable manifold]].

== Definition ==

In [[differential geometry]] the defining characteristic of a [[tangent space]] is that it approximates the smooth [[manifold]] to first order near the point of tangency. Equivalently, if we zoom in more and more at the point of tangency the manifold appears to become more and more straight, asymptotically tending to approach the tangent space. This turns out to be the correct point of view in geometric measure theory.

=== Definition for sets ===

'''Definition'''. Let &lt;math&gt;M \subset \mathbb{R}^n&lt;/math&gt; be a set that is [[measurable]] with respect to ''m''-dimensional [[Hausdorff measure]] &lt;math&gt;\mathcal{H}^m&lt;/math&gt;, and such that the restriction measure &lt;math&gt;\mathcal{H}^m \llcorner M&lt;/math&gt; is a [[Radon measure]]. We say that an ''m''-dimensional subspace &lt;math&gt;P \subset \mathbb{R}^n&lt;/math&gt; is the '''approximate tangent space''' to &lt;math&gt;M&lt;/math&gt; at a certain point &lt;math&gt;x&lt;/math&gt;, denoted &lt;math&gt;T_x M = P&lt;/math&gt;, if

:&lt;math&gt; \left( \mathcal{H}^m \llcorner M \right)_{x,\lambda} \rightharpoonup \mathcal{H}^m \llcorner P&lt;/math&gt; as &lt;math&gt;\lambda \downarrow 0&lt;/math&gt;

in the sense of [[Radon measure]]s. Here for any measure &lt;math&gt;\mu&lt;/math&gt; we denote by &lt;math&gt;\mu_{x,\lambda}&lt;/math&gt; the rescaled and translated measure:

:&lt;math&gt;\mu_{x,\lambda}(A) := \lambda^{-n} \mu(x + \lambda A), \qquad A \subset \mathbb{R}^n&lt;/math&gt;

Certainly any classical tangent space to a smooth submanifold is an approximate tangent space, but the converse is not necessarily true.

=== Multiplicities ===

The parabola

:&lt;math&gt;M_1 := \{ (x, x^2) : x \in \mathbb{R} \} \subset \mathbb{R}^2&lt;/math&gt;

is a smooth 1-dimensional submanifold. Its tangent space at the origin &lt;math&gt;(0,0) \in M_1&lt;/math&gt; is the horizontal line &lt;math&gt;T_{(0,0)} M_1 = \mathbb{R} \times \{0\}&lt;/math&gt;. On the other hand, if we incorporate the reflection along the ''x''-axis:

:&lt;math&gt;M_2 := \{ (x, x^2) : x \in \mathbb{R} \} \cup \{ (x, -x^2) : x \in \mathbb{R} \} \subset \mathbb{R}^2  \subset \mathbb{R}^2 &lt;/math&gt;

then &lt;math&gt;M_2&lt;/math&gt; is no longer a smooth 1-dimensional submanifold, and there is no classical tangent space at the origin. On the other hand, by zooming in at the origin the set &lt;math&gt;M_2&lt;/math&gt; is approximately equal to two straight lines that overlap in the limit. It would be reasonable to say it has an approximate tangent space &lt;math&gt;\mathbb{R} \times \{0\}&lt;/math&gt; with multiplicity two.

=== Definition for measures ===

One can generalize the previous definition and proceed to define approximate tangent spaces for certain [[Radon measure]]s, allowing for multiplicities as explained in the section above.

'''Definition'''. Let &lt;math&gt;\mu&lt;/math&gt; be a Radon measure on &lt;math&gt;\mathbb{R}^n&lt;/math&gt;. We say that an ''m''-dimensional subspace &lt;math&gt;P \subset \mathbb{R}^n&lt;/math&gt; is the approximate tangent space to &lt;math&gt;\mu&lt;/math&gt; at a point &lt;math&gt;x&lt;/math&gt; with multiplicity &lt;math&gt;\theta(x) \in (0,\infty)&lt;/math&gt;, denoted &lt;math&gt;T_x \mu = P&lt;/math&gt; with multiplicity &lt;math&gt;\theta(x)&lt;/math&gt;, if

:&lt;math&gt;\mu_{x,\lambda} \rightharpoonup \theta \; \mathcal{H}^m \llcorner P&lt;/math&gt; as &lt;math&gt;\lambda \downarrow 0&lt;/math&gt;

in the sense of Radon measures. The right-hand side is a constant multiple of ''m''-dimensional [[Hausdorff measure]] restricted to &lt;math&gt;P&lt;/math&gt;.

This definition generalizes the one for sets as one can see by taking &lt;math&gt;\mu := \mathcal{H}^n \llcorner M&lt;/math&gt; for any &lt;math&gt;M&lt;/math&gt; as in that section. It also accounts for the reflected paraboloid example above because for &lt;math&gt;\mu := \mathcal{H}^1 \llcorner M_2&lt;/math&gt; we have &lt;math&gt;T_{(0,0)} \mu = \mathbb{R} \times \{0\}&lt;/math&gt; with multiplicity two.

== Relation to rectifiable sets ==

The notion of approximate tangent spaces is very closely related to that of [[rectifiable set]]s. Loosely speaking, rectifiable sets are precisely those for which approximate tangent spaces exist almost everywhere. The following lemma encapsulates this relationship:

'''Lemma'''. Let &lt;math&gt;M \subset \mathbb{R}^n&lt;/math&gt; be [[measurable]] with respect to ''m''-dimensional [[Hausdorff measure]]. Then &lt;math&gt;M&lt;/math&gt; is m-[[rectifiable set|rectifiable]] if and only if there exists a positive locally &lt;math&gt;\mathcal{H}^m&lt;/math&gt;-integrable function &lt;math&gt;\theta : M \to (0,\infty)&lt;/math&gt; such that the [[Radon measure]]

:&lt;math&gt;\mu(A) = \int_A \theta(x) \, d\mathcal{H}^m(x) &lt;/math&gt;

has approximate tangent spaces &lt;math&gt;T_x \mu&lt;/math&gt; for &lt;math&gt;\mathcal{H}^m&lt;/math&gt;-almost every &lt;math&gt;x \in M&lt;/math&gt;.

==References==
*{{citation
| last=Simon
| first=Leon
| authorlink = Leon Simon
| title=Lectures on Geometric Measure Theory
| publisher=Australian National University
| series=Proceedings of the Centre for Mathematical Analysis
| date=1983
| volume=3
}}, particularly Chapter 3, Section 11 "'Basic Notions, Tangent Properties.''"
&lt;!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. ---&gt;
*
*
*
*

[[Category:Geometry]]
[[Category:Measure theory]]</text>
      <sha1>s2luxflyqeybmar6ztfgy60uss6m4u0</sha1>
    </revision>
  </page>
  <page>
    <title>Bates distribution</title>
    <ns>0</ns>
    <id>31100511</id>
    <revision>
      <id>857967368</id>
      <parentid>836901143</parentid>
      <timestamp>2018-09-04T05:26:33Z</timestamp>
      <contributor>
        <username>Smasongarrison</username>
        <id>16185737</id>
      </contributor>
      <minor/>
      <comment>/* References */copy editing, applying [[Wikipedia:AutoWikiBrowser/General_fixes|General fixes]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4448">{{more footnotes|date=June 2011}}
{{Probability distribution
  |name       = Bates
  |type       = density
  |pdf_image  = [[Image:batesPDF.svg|325px]]
  |cdf_image  = [[Image:batesCDF.svg|325px]]
  |parameters = &lt;math&gt;-\infty &lt; a &lt; b &lt; \infty &lt;/math&gt; &lt;br&gt; &lt;math&gt; n \geq 1 &lt;/math&gt; integer
  |support    = &lt;math&gt;x \in [a,b]&lt;/math&gt;
  |pdf        = see below
  |cdf        = 
  |mean       = &lt;math&gt;\tfrac{1}{2}(a+b)&lt;/math&gt;
  |median     = 
  |mode       = 
  |variance   = &lt;math&gt;\tfrac{1}{12n}(b-a)^2&lt;/math&gt;
  |skewness   = 0
  |kurtosis   = &lt;math&gt;-\tfrac{6}{5n}&lt;/math&gt;
  |entropy    = 
  |mgf        = 
  |char       = &lt;math&gt;\left(-\frac{in (e^{\tfrac{ibt}{n}}-e^{\tfrac{iat}{n}}) }{(b-a)t}\right)^n&lt;/math&gt; 
}}

In [[probability]] and [[statistics]], the '''Bates distribution''', named after [[Grace Bates]], is a [[probability distribution]] of the [[mean]] of a number of [[statistically independent]]  [[continuous uniform distribution|uniformly distributed]] random variables on the [[unit interval]].&lt;ref&gt;Jonhson, N. L.; Kotz, S.; Balakrishnan (1995) ''Continuous Univariate Distributions'', Volume 2, 2nd Edition, Wiley {{ISBN|0-471-58494-0}}(Section 26.9)&lt;/ref&gt; This distribution is sometimes confused&lt;ref&gt;{{Cite web|url=https://github.com/d3/d3/issues/1647|title=The thing named "Irwin-Hall distribution" in d3.random is actually a Bates distribution · Issue #1647 · d3/d3|website=GitHub|language=en|access-date=2018-04-17}}&lt;/ref&gt; with the [[Irwin–Hall distribution]], which is the distribution of the '''sum''' (not the '''mean''') of ''n'' independent random variables uniformly distributed from 0 to&amp;nbsp;1.

==Definition==
The Bates distribution is the continuous [[probability distribution]] of the [[mean]], ''X'', of ''n'' [[independence (probability theory)|independent]] [[continuous uniform distribution|uniformly distributed]] random variables on the [[unit interval]], ''U&lt;sub&gt;i&lt;/sub&gt;'':

:&lt;math&gt;
X = \frac{1}{n}\sum_{k=1}^n U_k.
&lt;/math&gt;

The equation defining the probability density function of a Bates distribution random variable ''X'' is

: &lt;math&gt;
f_X(x;n)=\frac n {2(n-1)!} \sum_{k=0}^n (-1)^k {n \choose k} (nx-k)^{n-1} \sgn(nx-k)
&lt;/math&gt;

for ''x'' in the interval (0,1), and zero elsewhere. Here sgn(''nx'' &amp;minus; ''k'') denotes the [[sign function]]:

:&lt;math&gt; \sgn(nx-k) = \begin{cases} 
-1 &amp;  nx &lt; k \\
0 &amp;  nx = k \\
1 &amp;  nx &gt; k. \end{cases}
&lt;/math&gt;

More generally, the mean of ''n'' [[independence (probability theory)|independent]] [[continuous uniform distribution|uniformly distributed]] random variables on the interval [''a'',''b'']

:&lt;math&gt;
X_{(a,b)} = \frac{1}{n}\sum_{k=1}^n U_k(a,b).
&lt;/math&gt;

would have the probability density function (PDF) of

:&lt;math&gt; g(x;n,a,b) = f_X\left(\frac{x-a}{b-a};n\right) \text{ for } a \leq x \leq b &lt;/math&gt;

Therefore, the PDF of the distribution is
: &lt;math&gt; f(x) = \begin{cases}
                       \sum_{k=0}^n (-1)^k \binom{n}{k} \left( \frac{x-a}{b-a}-k/n \right)^{n-1} \sgn\left( \frac{x-a}{b-a}-k/n \right) &amp; \text{if } x\in[a,b]\\
                       0 &amp; \text{otherwise}
                  \end{cases}&lt;/math&gt;

==Extensions to the Bates distribution==
Instead of dividing by ''n'' we can also use {{radic|''n''}} to create a similar distribution with a constant variance (like unity). By subtracting the mean we can set the resulting mean to zero. This way the parameter ''n'' would become a purely shape-adjusting parameter, and we obtain a distribution which covers the uniform, the triangular and, in the limit, also the normal Gaussian distribution. By allowing also non-integer ''n'' a highly flexible distribution can be created (e.g. ''U''(0,1)&amp;nbsp;+&amp;nbsp;0.5''U''(0,1) gives a trapezodial distribution). Actually the Student-t distribution provides a natural extension of the normal Gaussian distribution for modeling of long tail data. And such generalized Bates distribution is doing so for short tail data (kurtosis&amp;nbsp;&lt;&amp;nbsp;3).

== See also ==
* [[Irwin–Hall distribution]]
* [[Normal distribution]]
* [[Central limit theorem]]
* [[Uniform distribution (continuous)]]
* [[Triangular distribution]]

==Notes==
{{reflist}}

==References==
*Bates,G.E. (1955) "Joint distributions of time intervals for the occurrence of successive accidents in a generalized Polya urn scheme", ''[[Annals of Mathematical Statistics]]'', 26, 705&amp;ndash;720
 
{{ProbDistributions|continuous-bounded}}

[[Category:Continuous distributions]]


{{probability-stub}}</text>
      <sha1>mmuf7s1kyfvh0vgie8sywn6iv5nt3xw</sha1>
    </revision>
  </page>
  <page>
    <title>Bidirectional recurrent neural networks</title>
    <ns>0</ns>
    <id>49686608</id>
    <revision>
      <id>867577477</id>
      <parentid>863229528</parentid>
      <timestamp>2018-11-06T16:45:57Z</timestamp>
      <contributor>
        <ip>2601:602:9900:E0:5956:8BB9:1A40:5498</ip>
      </contributor>
      <comment>Increased size of image so text would be legible.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5305">{{Orphan|date=March 2016}}

'''Bidirectional Recurrent Neural Networks''' ('''BRNN''') connects two hidden layers of opposite directions to the same output. With this form of [[Generative model|generative deep learning]], the output layer can get information from past (backwards) and future (forward) states simultaneously.&lt;ref&gt;{{Cite web|url=https://deepai.org/machine-learning-glossary-and-terms/bidirectional-recurrent-neural-networks|title=What are Bidirectional Recurrent Neural Networks?|last=|first=|date=|website=deepai.org|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt; Invented in 1997 by Schuster and Paliwal,&lt;ref name="Schuster"&gt;Schuster, Mike, and Kuldip K. Paliwal. "Bidirectional recurrent neural networks." Signal Processing, IEEE Transactions on 45.11 (1997): 2673-2681.2. Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan&lt;/ref&gt; BRNNs were introduced to increase the amount of input information available to the network. For example, [[multilayer perceptron]] (MLPs) and [[time delay neural network]] (TDNNs) have limitations on the input data flexibility, as they require their input data to be fixed. Standard [[recurrent neural network]] (RNNs) also have restrictions as the future input information cannot be reached from the current state. On the contrary, BRNNs do not require their input data to be fixed. Moreover, their future input information is reachable from the current state. &lt;ref&gt;{{Cite web|url=https://arxiv.org/pdf/1801.01078.pdf|title=Recent Advances in Recurrent Neural Networks|last=|first=|date=|website=|archive-url=|archive-date=|dead-url=|access-date=}}&lt;/ref&gt;

BRNN are especially useful when the context of the input is needed. For example, in handwriting recognition, the performance can be enhanced by knowledge of the letters located before and after the current letter.

==Architecture==
[[File:RNN BRNN.png|thumbnail|Structure of RNN and BRNN&lt;ref name="Schuster" /&gt;|alt=|350x350px]]

The principle of BRNN is to split the neurons of a regular RNN into two directions, one for positive time direction (forward states), and another for negative time direction (backward states). Those two states’ output are not connected to inputs of the opposite direction states. The general structure of RNN and BRNN can be depicted in the right diagram. By using two time directions, input information from the past and future of the current time frame can be used unlike standard RNN which requires the delays for including future information.&lt;ref name="Schuster" /&gt;

==Training==

BRNNs can be trained using similar algorithms to RNNs, because the two directional neurons do not have any interactions. However, when back-propagation is applied, additional processes are needed because updating input and output layers cannot be done at once. General procedures for training are as follows: For forward pass, forward states and backward states are passed first, then output neurons are passed. For backward pass, output neurons are passed first, then forward states and backward states are passed next. After forward and backward passes are done, the weights are updated.&lt;ref name="Schuster" /&gt;

==Applications==

Applications of BRNN include :

*Speech Recognition (Combined with [[Long short-term memory]])&lt;ref&gt;Graves, Alex, Santiago Fernández, and Jürgen Schmidhuber. "Bidirectional LSTM networks for improved phoneme classification and recognition." Artificial Neural Networks: Formal Models and Their Applications–ICANN 2005. Springer Berlin Heidelberg, 2005. 799-804.
&lt;/ref&gt;&lt;ref&gt;Graves, Alan, Navdeep Jaitly, and Abdel-rahman Mohamed. "Hybrid speech recognition with deep bidirectional LSTM." Automatic Speech Recognition and Understanding (ASRU), 2013 IEEE Workshop on. IEEE, 2013.&lt;/ref&gt;

*Translation&lt;ref&gt;Sundermeyer, Martin, et al. "Translation modeling with bidirectional recurrent neural networks." Proceedings of the Conference on Empirical Methods on Natural Language Processing, October. 2014.&lt;/ref&gt;
*Handwritten Recognition&lt;ref&gt;Liwicki, Marcus, et al. "A novel approach to on-line handwriting recognition based on bidirectional long short-term memory networks." Proc. 9th Int. Conf. on Document Analysis and Recognition. Vol. 1. 2007.&lt;/ref&gt;
*Protein Structure Prediction&lt;ref&gt;Baldi, Pierre, et al. "Exploiting the past and the future in protein secondary structure prediction." Bioinformatics 15.11 (1999): 937-946.&lt;/ref&gt;&lt;ref&gt;Pollastri, Gianluca, and Aoife Mclysaght. "Porter: a new, accurate server for protein secondary structure prediction." Bioinformatics 21.8 (2005): 1719-1720.&lt;/ref&gt;
*Part-of-speech tagging
*Dependency Parsing&lt;ref&gt;Grella and Cangialosi "Non-Projective Dependency Parsing via Latent Heads Representation" (2018).&lt;/ref&gt;
*Entity Extraction&lt;ref&gt;{{Cite arxiv|last=Dernoncourt|first=Franck|last2=Lee|first2=Ji Young|last3=Szolovits|first3=Peter|date=2017-05-15|title=NeuroNER: an easy-to-use program for named-entity recognition based on neural networks|eprint=1705.05487|class=cs.CL}}&lt;/ref&gt;

==See also==

* [[Artificial neural network]]
* [[Recurrent neural networks]]
* [[Long short-term memory]]

==References==
{{reflist}}

==External links==
*[https://github.com/hycis/bidirectional_RNN] Implementation of BRNN/LSTM in Python with Theano

[[Category:Artificial neural networks]]</text>
      <sha1>dc3qk2co4lrcdowg37oai26k0ebiu26</sha1>
    </revision>
  </page>
  <page>
    <title>Boolean satisfiability algorithm heuristics</title>
    <ns>0</ns>
    <id>48777793</id>
    <revision>
      <id>869890449</id>
      <parentid>765344495</parentid>
      <timestamp>2018-11-21T01:31:57Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <comment>Rephrasing is needed to avoid using 'we'.  Wikipedia is an encyclopedia, not a math textbook.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13496">{{Orphan|date=February 2016}}
Given a Boolean expression &lt;Math&gt;B&lt;/Math&gt; with &lt;Math&gt;V = \{v_0, \ldots , v_n\}&lt;/Math&gt; variables, finding an assignment &lt;Math&gt;V^*&lt;/Math&gt; of the variables such that &lt;Math&gt;B(V^*)&lt;/Math&gt; is true is called the [[Boolean satisfiability problem]], frequently abbreviated SAT, and is seen as the canonical [[NP-complete]] problem.

Although no known algorithm is known to solve SAT in polynomial time, there are classes of SAT problems which do have efficient algorithms that solve them. These classes of problems arise from many practical problems in [[AI planning]], [[Circuit satisfiability problem|circuit testing]], and software verification.&lt;ref&gt;Aloul, Fadi A., "On Solving Optimization Problems Using Boolean Satisfiability", American University of Sharjah (2005), http://www.aloul.net/Papers/faloul_icmsao05.pdf&lt;/ref&gt;&lt;ref name = "princeton"&gt;Zhang, Lintao. Malik, Sharad. "The Quest for Efficient Boolean Satisfiability Solvers", Department of Electrical Engineering, Princeton University. https://www.princeton.edu/~chaff/publication/cade_cav_2002.pdf&lt;/ref&gt; Research on constructing efficient SAT solvers has been based on various principles such as resolution, search, local search and random walk, binary decisions, and Stalmarck's algorithm.&lt;ref name = "princeton"/&gt;

Some of these algorithms are [[Deterministic algorithm|deterministic]], while others may be [[Randomized algorithm|stochastic]].

As there exist polynomial-time algorithms to convert any Boolean expression to conjunctive normal form such as [[Tseytin transformation|Tseitin's algorithm]], posing SAT problems in CNF does not change their computational difficulty. SAT problems are canonically expressed in CNF because CNF has certain properties that can help prune the search space and speed up the search process.&lt;ref name = "princeton"/&gt;

== Branching heuristics in conflict-driven algorithms &lt;ref name = "princeton"/&gt; ==

One of the cornerstone [[Conflict-Driven Clause Learning]] SAT solver algorithms is the [[DPLL algorithm]]. The algorithm works by iteratively assigning free variables, and when the algorithm encounters a bad assignment, then it backtracks to a previous iteration and chooses a different assignment of variables. It relies on a Branching Heuristic to pick the next free variable assignment; the branching algorithm effectively makes choosing the variable assignment into a decision tree. Different implementations of this heuristic produce markedly different decision trees, and thus have significant effect on the efficiency of the solver.

Early branching Heuristics (Bohm's Heuristic, Maximum Occurrences on Minimum sized clauses heuristic, and Jeroslow-Wang heuristic) can be regarded as [[greedy algorithms]]. Their basic premise is to choose a free variable assignment that will satisfy the most already unsatisfied clauses in the Boolean expression. However, as Boolean expressions get larger, more complicated, or more structured, these heuristics fail to capture useful information about these problems that could improve efficiency; they often get stuck in local maxima or do not consider the distribution of variables. Additionally, larger problems require more processing, as the operation of counting free variables in unsatisfied clauses dominates the run-time.

Another heuristic called Variable State Independent Decaying Sum (VSIDS) attempts to score each variable. VSIDS starts by looking at small portions of the Boolean expression and assigning each phase of a variable (a variable and its negated complement) a score proportional to the number of clauses that variable phase is in. As VSIDS progresses and searches more parts of the Boolean expression, periodically, all scores are divided by a constant. This discounts the effect of the presence of variables in earlier-found clauses in favor of variables with a greater presence in more recent clauses. VSIDS will select the variable phase with the highest score to determine where to branch.

VSIDS is quite effective because the scores of variable phases is independent of the current variable assignment, so backtracking is much easier. Further, VSIDS guarantees that each variable assignment satisfies the greatest number of recently searched segments of the Boolean expression.

== Stochastic solvers &lt;ref&gt;Sung, Phil. "Maximum Satisfiability" (2006) http://math.mit.edu/~goemans/18434S06/max-sat-phil.pdf&lt;/ref&gt; ==

[[MAX-SAT]] (the version of SAT in which the number of satisfied clauses is maximized) solvers can also be solved using probabilistic algorithms. If we{{who?|date=November 2018}} are given a Boolean expression &lt;Math&gt;B&lt;/Math&gt;, with &lt;Math&gt;V = \{v_0, \ldots , v_n\}&lt;/Math&gt; variables and we{{who?|date=November 2018}} set each variable randomly, then each clause &lt;Math&gt;c&lt;/Math&gt;, with &lt;Math&gt;|c|&lt;/Math&gt; variables, has a chance of being satisfied by a particular variable assignment Pr(&lt;Math&gt;c&lt;/Math&gt; is satisfied) = &lt;Math&gt;1-2^{-|c|}&lt;/Math&gt;. This is because each variable in &lt;Math&gt;c&lt;/Math&gt; has &lt;Math&gt;\frac{1}{2}&lt;/Math&gt; probability of being satisfied, and we{{who?|date=November 2018}} only need one variable in &lt;Math&gt;c&lt;/Math&gt; to be satisfied. This works &lt;Math&gt;\forall ~|c| \geq 1&lt;/Math&gt;, so Pr(&lt;Math&gt;c&lt;/Math&gt; is satisfied) = &lt;Math&gt;1-2^{-|c|} \geq \frac{1}{2}&lt;/Math&gt;.

Now we{{who?|date=November 2018}} show that randomly assigning variable values is a &lt;Math&gt;\frac{1}{2}&lt;/Math&gt;-approximation algorithm, which means that is an optimal approximation algorithm unless P = NP. Suppose we{{who?|date=November 2018}} are given a Boolean expression &lt;Math&gt;B = \{c_i\}_{i=1}^n&lt;/Math&gt; and

: &lt;math&gt;\delta_{ij} = \begin{cases}
0 &amp;\text{if } c_i \text{ is satisfied},   \\
1 &amp;\text{if } c_i \text{ is not satisfied}. \end{cases}&lt;/math&gt;

: &lt;Math&gt;
\begin{align}
E[\text{Num Clauses Satsified}] &amp; = \sum_i E[\delta_i] = \sum_{i} 1-2^{-|c_i|} \\
&amp; \geq \sum_i \frac{1}{2} = \frac{1}{2}|i| = \frac{1}{2} OPT
\end{align}
&lt;/Math&gt;

This algorithm cannot be further optimized by the [[PCP theorem]] unless P = NP.

Other Stochastic SAT solvers, such as [[WalkSAT]] and [[GSAT]] are an improvement to the above procedure. They start by randomly assigning values to each variable and then traverse the given Boolean expression to identify which variables to flip to minimize the number of unsatisfied clauses. They may randomly select a variable to flip or select a new random variable assignment to escape local maxima, much like a [[simulated annealing]] algorithm.

== 2-SAT heuristics ==

Unlike general SAT problems, [[2-SAT]] problems are [[Tractable problem|tractable]]. There exist algorithms that can compute the satisfiability of a 2-SAT problem in polynomial time. This is a result of the constraint that each clause has only two variables, so when an algorithm sets a variable &lt;Math&gt;v_i&lt;/Math&gt;, the satisfaction of clauses, which contain &lt;Math&gt;v_i&lt;/Math&gt; but are not satisfied by that variable assignment, depend on the satisfaction of the second variable in those clauses, which leaves only one possible assignment for those variables.

=== Backtracking ===

Suppose we{{who?|date=November 2018}} are given a Boolean expressions:

: &lt;Math&gt;B_1 = (v_3 \lor \neg v_2) \wedge (\neg v_1 \lor \neg v_3)&lt;/Math&gt;

: &lt;Math&gt;B_2 = (v_3 \lor \neg v_2) \wedge (\neg v_1 \lor \neg v_3) \wedge (\neg v_1 \lor v_2). &lt;/Math&gt;

With &lt;Math&gt;B_1&lt;/Math&gt;, the algorithm can select &lt;Math&gt;v_1 = \text{true}&lt;/Math&gt;, so to satisfy the second clause, the algorithm will need to set &lt;Math&gt;v_3 = \text{false}&lt;/Math&gt;, and resultantly to satisfy the first clause, the algorithm will set &lt;Math&gt;v_2 = \text{false}&lt;/Math&gt;.

If the algorithm tries to satisfy &lt;Math&gt;B_2&lt;/Math&gt; in the same way it tried to solve &lt;Math&gt;B_1&lt;/Math&gt;, then the third clause will remain unsatisfied. This will cause the algorithm to backtrack and set &lt;Math&gt;v_1 = \text{false}&lt;/Math&gt; and continue assigning variables further.

=== Graph reduction &lt;ref&gt;Griffith, Richard. "Strongly Connected Components and the 2-SAT Problem in Dart". http://www.greatandlittle.com/studios/index.php?post/2013/03/26/Strongly-Connected-Components-and-the-2-SAT-Problem-in-Dart&lt;/ref&gt; ===

2-SAT problems can also be reduced to running a [[depth-first search]] on a [[strongly connected components]] of a graph. Each variable phase (a variable and its negated complement) is connected to other variable phases based on implications. In the same way when the algorithm above tried to solve

: &lt;Math&gt;B_1, v_1 = \text{true} \implies v_3 = \text{false} \implies v_2 = \text{false} \implies v_1 = \text{true}.&lt;/Math&gt;

However, when the algorithm tried solve

: &lt;Math&gt;
\begin{align}
B_2, v_1 = \text{true} &amp; \implies v_3 = \text{false} \implies v_2 = \text{false} \\ &amp; \implies v_1 = \text{false} \implies \cdots \implies v_1 = \text{true},
\end{align}
&lt;/Math&gt;

which is a contradiction.

Once a 2-SAT problem is reduced to a graph, then if a depth first search finds a strongly connected component with both phases of a variable, then the 2-SAT problem is not satisfiable. Likewise, if the depth first search does not find a strongly connected component with both phases of a variable, then the 2-SAT problem is satisfiable.

== Weighted SAT problems ==
Numerous weighted SAT problems exist as the [[Optimization problem|optimization versions]] of the general SAT problem. In this class of problems, each clause in a CNF Boolean expression is given a weight. The objective is the maximize or minimize the total sum of the weights of the satisfied clauses given a Boolean expression. weighted Max-SAT is the maximization version of this problem, and [[Maximum satisfiability problem|Max-SAT]] is an instance of weighted MAX-SAT problem where the weights of each clause are the same. The partial Max-SAT problem is the problem where some clauses necessarily must be satisfied (hard clauses) and the sum total of weights of the rest of the clauses (soft clauses) are to be maximized or minimized, depending on the problem. Partial Max-SAT represents an intermediary between Max-SAT (all clauses are soft) and SAT (all clauses are hard).

Note that the stochastic probabilistic solvers can also be used to find optimal approximations for Max-SAT.

=== Variable splitting&lt;ref&gt;Pipatsrisawat, Knot. Palyan, Akop. et. al. "Solving Weighted Max-SAT Problems in a Reduced Search Space: A Performance Analysis". University of California Computer Science Department http://reasoning.cs.ucla.edu/fetch.php?id=86&amp;type=pdf&lt;/ref&gt; ===
Variable splitting is a tool to find upper and lower bounds on a Max-SAT problem. It involves splitting a variable &lt;Math&gt;a&lt;/Math&gt; into new variables for all but once occurrence of &lt;Math&gt;a&lt;/Math&gt; in the original Boolean expression. For example, given the Boolean expression:
&lt;Math&gt;B = (a \lor b \lor c) \wedge (\neg a \lor e \lor \neg b) \wedge (a \lor \neg c \lor f)&lt;/Math&gt;
will become:
&lt;Math&gt;B^* = (a \lor b \lor c) \wedge (\neg a_1 \lor e \lor \neg b) \wedge (a_2 \lor \neg c \lor f)&lt;/Math&gt;,
with &lt;Math&gt;a,a_1,a_2,\ldots,a_n&lt;/Math&gt; being all distinct variables.

This relaxes the problem by introducing new variables into the Boolean expression, which has the effect of removing many of the constraints in the expression. Because any assignment of variables in &lt;Math&gt;B&lt;/Math&gt; can be represented by an assignment of variables in &lt;Math&gt;B^*&lt;/Math&gt;, the minimization and maximization of the weights of &lt;Math&gt;B^*&lt;/Math&gt; represent lower and upper bounds on the minimization and maximization of the weights of &lt;Math&gt;B&lt;/Math&gt;.

=== Partial Max-SAT ===
Partial Max-SAT can be solved by first considering all of the hard clauses and solving them as an instance of SAT. The total maximum (or minimum) weight of the soft clauses can be evaluated given the variable assignment necessary to satisfy the hard clauses and trying to optimize the free variables (the variables that the satisfaction of the hard clauses does not depend on). The latter step is an implementation of Max-SAT given some pre-defined variables. Of course, different variable assignments that satisfy the hard clauses might have different optimal free variable assignments, so it is necessary to check different hard clause satisfaction variable assignments.

== Data structures for storing clauses &lt;ref name = "princeton"/&gt; ==

As SAT solvers and practical SAT problems (e.g. circuit verification) get more advanced, the Boolean expressions of interest may exceed millions of variables with several million clauses; therefore, efficient data structures to store and evaluate the clauses must be used.

Expressions can be stored as a list of clauses, where each clause is a list of variables, much like an [[adjacency list]]. Though these data structures are convenient for manipulation (adding elements, deleting elements, etc.), they rely on many pointers, which increases their memory overhead, decreases [[cache locality]], and increases [[cache misses]], which renders them impractical for problems with large clause counts and large clause sizes.

When clause sizes are large, more efficient analogous implementations include storing expressions as a list of clauses, where each clause is represented as a matrix that represents the clauses and the variables present in that clause, much like an [[adjacency matrix]]. The elimination of pointers and the contiguous memory occupation of arrays serve to decrease memory usage and increase cache locality and cache hits, which offers a run-time speed up compared to the aforesaid implementation.

== References ==
{{reflist}}

[[Category:Boolean algebra]]</text>
      <sha1>sxiesn2pl4wtce712n9j79fsttzdry1</sha1>
    </revision>
  </page>
  <page>
    <title>Brouwer fixed-point theorem</title>
    <ns>0</ns>
    <id>4101</id>
    <revision>
      <id>868601314</id>
      <parentid>863259721</parentid>
      <timestamp>2018-11-13T07:17:03Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="52583">&lt;!-- The French version of this article is a featured article. Large portions have been translated and inserted here in 2009. --&gt;
'''Brouwer's fixed-point theorem''' is a [[fixed-point theorem]] in [[topology]], named after [[Luitzen Egbertus Jan Brouwer|L. E. J. (Bertus) Brouwer]]. It states that for any [[continuous function]] &lt;math&gt;f&lt;/math&gt; mapping a [[compactness|compact]] [[convex set]] to itself there is a point &lt;math&gt;x_0&lt;/math&gt; such that &lt;math&gt;f(x_0)=x_0&lt;/math&gt;. The simplest forms of Brouwer's theorem are for continuous functions &lt;math&gt;f&lt;/math&gt; from a closed interval &lt;math&gt;I&lt;/math&gt; in the real numbers to itself or from a closed [[Disk (mathematics)|disk]] &lt;math&gt;D&lt;/math&gt; to itself. A more general form than the latter is for continuous functions from a convex compact subset &lt;math&gt;K
&lt;/math&gt; of [[Euclidean space]] to itself.

Among hundreds of [[fixed-point theorem]]s,&lt;ref&gt;E.g. F &amp; V Bayart ''[http://www.bibmath.net/dico/index.php3?action=affiche&amp;quoi=./p/pointfixe.html Théorèmes du point fixe]'' on Bibm@th.net  {{webarchive|url=https://web.archive.org/web/20081226200755/http://www.bibmath.net/dico/index.php3?action=affiche&amp;quoi=.%2Fp%2Fpointfixe.html |date=December 26, 2008 }}&lt;/ref&gt; Brouwer's is particularly well known, due in part to its use across numerous fields of mathematics.
In its original field, this result is one of the key theorems characterizing the topology of Euclidean spaces, along with the [[Jordan curve theorem]], the [[hairy ball theorem]] and the [[Borsuk–Ulam theorem]].&lt;ref&gt;See page 15 of: D. Leborgne ''Calcul différentiel et géométrie'' Puf (1982) {{ISBN|2-13-037495-6}}&lt;/ref&gt;
This gives it a place among the fundamental theorems of topology.&lt;ref&gt;More exactly, according to Encyclopédie Universalis: ''Il en a démontré l'un des plus beaux théorèmes, le théorème du point fixe, dont les applications et généralisations, de la théorie des jeux aux équations différentielles, se sont révélées fondamentales.'' [http://www.universalis.fr/encyclopedie/T705705/BROUWER_L.htm Luizen Brouwer] by G. Sabbagh&lt;/ref&gt; The theorem is also used for proving deep results about [[differential equation]]s and is covered in most introductory courses on [[differential geometry]].
It appears in unlikely fields such as [[game theory]]. In economics, Brouwer's fixed-point theorem and its extension, the [[Kakutani fixed-point theorem]], play a central role in the [[Arrow–Debreu model|proof of existence]] of [[general equilibrium]] in market economies as developed in the 1950s by economics Nobel prize winners [[Kenneth Arrow]] and [[Gérard Debreu]].

The theorem was first studied in view of work on differential equations by the French mathematicians around [[Henri Poincaré]] and [[Charles Émile Picard]]. Proving results such as the [[Poincaré–Bendixson theorem]] requires the use of topological methods. This work at the end of the 19th century opened into several successive versions of the theorem. The general case was first proved in 1910 by [[Jacques Hadamard]]&lt;ref name="hadamard-1910"&gt;[[Jacques Hadamard]]: ''[https://archive.org/stream/introductionla02tannuoft#page/436/mode/2up Note sur quelques applications de l’indice de Kronecker]'' in [[Jules Tannery]]: ''Introduction à la théorie des fonctions d’une variable'' (Volume 2), 2nd edition, A. Hermann &amp; Fils, Paris 1910, pp. 437–477 (French)&lt;/ref&gt; and by [[Luitzen Egbertus Jan Brouwer]].&lt;ref name="brouwer-1910"&gt;[[Luitzen Egbertus Jan Brouwer|L. E. J. Brouwer]] ''[http://resolver.sub.uni-goettingen.de/purl?GDZPPN002264021 Über Abbildungen von Mannigfaltigkeiten]'' [[Mathematische Annalen]] 71, pp. 97–115, {{doi|10.1007/BF01456931}} (German; published 25 July 1911, written July 1910)&lt;/ref&gt;

==Statement==
The theorem has several formulations, depending on the context in which it is used and its degree of generalization. The simplest is sometimes given as follows:

:;In the plane: Every [[continuous function (topology)|continuous function]] from a [[Closed set|closed]] [[Disk (mathematics)|disk]] to itself has at least one fixed point.&lt;ref&gt;D. Violette ''[http://newton.mat.ulaval.ca/amq/bulletins/dec06/sperner.pdf Applications du lemme de Sperner pour les triangles]'' Bulletin AMQ, V. XLVI N° 4, (2006) p 17. {{webarchive |url=https://web.archive.org/web/20110608214059/http://newton.mat.ulaval.ca/amq/bulletins/dec06/sperner.pdf |date=June 8, 2011 }}&lt;/ref&gt;

This can be generalized to an arbitrary finite dimension:

:;In Euclidean space:Every continuous function from a [[closed ball]] of a [[Euclidean space]] into itself has a fixed point.&lt;ref&gt;Page 15 of: D. Leborgne ''Calcul différentiel et géométrie'' Puf (1982) {{ISBN|2-13-037495-6}}.&lt;/ref&gt;

A slightly more general version is as follows:&lt;ref&gt;This version follows directly from the previous one because every convex compact subset of a Euclidean space is homeomorphic to a closed ball of the same dimension as the subset; see {{cite book|title=General Equilibrium Analysis: Existence and Optimality Properties of Equilibria|first=Monique|last=Florenzano|publisher=Springer|year=2003|isbn=9781402075124|page=7|url=https://books.google.com/books?id=cNBMfxPQlvEC&amp;pg=PA7|accessdate=2016-03-08}}&lt;/ref&gt;

:;Convex compact set:Every continuous function from a [[Convex set|convex]] [[Compact space|compact]] subset ''K'' of a Euclidean space to ''K'' itself has a fixed point.&lt;ref&gt;V. &amp; F. Bayart ''[http://www.bibmath.net/dico/index.php3?action=affiche&amp;quoi=./p/pointfixe.html Point fixe, et théorèmes du point fixe ]'' on Bibmath.net.  {{webarchive|url=https://web.archive.org/web/20081226200755/http://www.bibmath.net/dico/index.php3?action=affiche&amp;quoi=.%2Fp%2Fpointfixe.html |date=December 26, 2008 }}&lt;/ref&gt;

An even more general form is better known under a different name:

:;[[Schauder fixed point theorem]]:Every continuous function from a convex compact subset ''K'' of a [[Banach space]] to ''K'' itself has a fixed point.&lt;ref&gt;C. Minazzo K. Rider ''[http://math1.unice.fr/~eaubry/Enseignement/M1/memoire.pdf Théorèmes du Point Fixe et Applications aux Equations Différentielles]'' Université de Nice-Sophia Antipolis.&lt;/ref&gt;

==Importance of the pre-conditions==
The theorem holds only for sets that are ''compact'' (thus, in particular, bounded and closed) and ''convex'' (or homeomorphic to convex). The following examples show why the pre-conditions are important.

===Boundedness===
Consider the function
:&lt;math&gt;f(x) = x+1&lt;/math&gt;
which is a continuous function from &lt;math&gt;\mathbb{R}&lt;/math&gt; to itself. As it shifts every point to the right, it cannot have a fixed point. Note that &lt;math&gt;\mathbb{R}&lt;/math&gt; is convex and closed, but not bounded.

===Closedness===
Consider the function
:&lt;math&gt;f(x) = \frac{x+1}2&lt;/math&gt;
which is a continuous function from the open interval (−1,1) to itself. In this interval, it shifts every point to the right, so it cannot have a fixed point. Note that (−1,1) is convex and bounded, but not closed. The function ''f''  ''does'' have a fixed point for the closed interval [−1,1], namely ''f''(1) = 1.

===Convexity===
Note that convexity is not strictly necessary for BFPT. Because the properties involved (continuity, being a fixed point) are invariant under [[homeomorphism]]s, BFPT is equivalent to forms in which the domain is required to be a closed unit ball &lt;math&gt;D^n&lt;/math&gt;. For the same reason it holds for every set that is homeomorphic to a closed ball (and therefore also [[closed set|closed]], bounded, [[connected space|connected]], [[simply connected|without holes]], etc.).

The following example shows that BFPT doesn't work for domains with holes. Consider the following function, defined in polar coordinates:
:&lt;math&gt;f(r,\theta)=(r,\theta+\pi/4)&lt;/math&gt;
which is a continuous function from the unit circle to itself. It rotates every point on the unit circle 45 degrees counterclockwise, so it cannot have a fixed point. Note that the unit circle is closed and bounded, but it has a hole (and so it is not convex). The function ''f''  ''does'' have a fixed point for the unit disc, since it takes the origin to itself.

A formal generalization of BFPT for "hole-free" domains can be derived from the [[Lefschetz fixed-point theorem]].&lt;ref&gt;{{cite web | url=http://math.stackexchange.com/questions/323841/why-is-convexity-a-requirement-for-brouwer-fixed-points-shouldnt-no-holes-be | title=Why is convexity a requirement for Brouwer fixed points? | publisher=Math StackExchange | accessdate=22 May 2015 | author=Belk, Jim}}&lt;/ref&gt;

===Notes===
The continuous function in this theorem is not required to be [[bijective]] or even [[surjective]].

==Illustrations==
The theorem has several "real world" illustrations. Here are some examples.

1. Take two sheets of graph paper of equal size with coordinate systems on them, lay one flat on the table and crumple up (without ripping or tearing) the other one and place it, in any fashion, on top of the first so that the crumpled paper does not reach outside the flat one. There will then be at least one point of the crumpled sheet that lies directly above its corresponding point (i.e. the point with the same coordinates) of the flat sheet. This is a consequence of the ''n'' = 2 case of Brouwer's theorem applied to the continuous map that assigns to the coordinates of every point of the crumpled sheet the coordinates of the point of the flat sheet immediately beneath it.

2. Take an ordinary map of a country, and suppose that that map is laid out on a table inside that country.  There will always be a "You are Here" point on the map which represents that same point in the country.

3. In three dimensions a consequence of the Brouwer fixed-point theorem is that, no matter how much you stir a cocktail in a glass (or think about milk shake), when the liquid has come to rest, some point in the liquid will end up in exactly the same place in the glass as before you took any action, assuming that the final position of each point is a continuous function of its original position, that the liquid after stirring is contained within the space originally taken up by it, and that the glass (and stirred surface shape) maintain a convex volume.  Ordering a cocktail [[shaken, not stirred]] defeats the convexity condition ("shaking" being defined as a dynamic series of non-convex inertial containment states in the vacant headspace under a lid).  In that case, the theorem would not apply, and thus all points of the liquid disposition are potentially displaced from the original state. {{Citation needed|date=September 2018}}

==Intuitive approach==

===Explanations attributed to Brouwer===
The theorem is supposed to have originated from Brouwer's observation of a cup of coffee.&lt;ref&gt;The interest of this anecdote rests in its intuitive and didactic character, but its accuracy is dubious. As the history section shows, the origin of the theorem is not Brouwer's work. More than 20 years earlier [[Henri Poincaré]] had proved an equivalent result, and 5 years before Brouwer P.&amp;nbsp;Bohl had proved the three-dimensional case.&lt;/ref&gt;
If one stirs to dissolve a lump of sugar, it appears there is always a point without motion.
He drew the conclusion that at any moment, there is a point on the surface that is not moving.&lt;ref name=Arte&gt;This citation comes originally from a television broadcast: ''[https://archive.is/20130113210953/http://archives.arte.tv/hebdo/archimed/19990921/ftext/sujet5.html Archimède]'', [[Arte]], 21 septembre 1999&lt;/ref&gt;
The fixed point is not necessarily the point that seems to be motionless, since the centre of the turbulence moves a little bit.
The result is not intuitive, since the original fixed point may become mobile when another fixed point appears.

Brouwer is said to have added: "I can formulate this splendid result different, I take a horizontal sheet, and another identical one which I crumple, flatten and place on the other. Then a point of the crumpled sheet is in the same place as on the other sheet."&lt;ref name=Arte /&gt;
Brouwer "flattens" his sheet as with a flat iron, without removing the folds and wrinkles. This example is better than the coffee cup one as it shows that uniqueness of the fixed point may fail. This distinguishes Brouwer's result from other fixed-point theorems, such as [[Stefan Banach]]'s, that guarantee uniqueness.

===One-dimensional case===
[[File:Théorème-de-Brouwer-dim-1.svg|200px|right]]
In one dimension, the result is intuitive and easy to prove.  The continuous function ''f'' is defined on a closed interval [''a'',&amp;nbsp;''b''] and takes values in the same interval.  Saying that this function has a fixed point amounts to saying that its graph (dark green in the figure on the right) intersects that of the function defined on the same interval [''a'',&amp;nbsp;''b''] which maps ''x'' to ''x'' (light green).

Intuitively, any continuous line from the left edge of the square to the right edge must necessarily intersect the green diagonal.  To prove this, consider the function ''g'' which maps ''x'' to ''f''(''x'')&amp;nbsp;-&amp;nbsp;''x''. It is ≥&amp;nbsp;0 on ''a'' and ≤&amp;nbsp;0 on&amp;nbsp;''b''.  By the [[intermediate value theorem]], ''g'' has a [[Root of a function|zero]] in [''a'',&amp;nbsp;''b'']; this zero is a fixed point.

Brouwer is said to have expressed this as follows: "Instead of examining a surface, we will prove the theorem about a piece of string. Let us begin with the string in an unfolded state, then refold it. Let us flatten the refolded string. Again a point of the string has not changed its position with respect to its original position on the unfolded string."&lt;ref name=Arte /&gt;

==History==
The Brouwer fixed point theorem was one of the early achievements of [[algebraic topology]], and is the basis of more general [[fixed point theorem]]s which are important in [[functional analysis]]. The case ''n'' = 3 first was proved by [[Piers Bohl]] in 1904 (published in ''[[Journal für die reine und angewandte Mathematik]]'').&lt;ref name=Bohl1904&gt;{{cite journal |first=P. |last=Bohl |title=  Über die Bewegung eines mechanischen Systems in der Nähe einer Gleichgewichtslage |journal=J. Reine Angew. Math. |volume=127 |issue=3/4 |pages=179–276 |year=1904 }}&lt;/ref&gt; It was later proved by [[Luitzen Egbertus Jan Brouwer|L. E. J. Brouwer]] in 1909. [[Jacques Hadamard]] proved the general case in 1910,&lt;ref name="hadamard-1910" /&gt; and Brouwer found a different proof in the same year.&lt;ref name="brouwer-1910" /&gt;  Since these early proofs were all [[Constructive proof|non-constructive]] [[indirect proof]]s, they ran contrary to Brouwer's [[intuitionist]] ideals. Although the existence of a fixed point is not constructive in the sense of [[Constructivism (mathematics)|constructivism in mathematics]], methods to [[Approximation theory|approximate]] fixed points guaranteed by Brouwer's theorem are now known.&lt;ref name=Karamardian1977&gt;{{cite book|last1=Karamardian|first1=Stephan|title=Fixed points: algorithms and applications|date=1977|publisher=Academic Press|location=New York|isbn=978-0-12-398050-2}}&lt;/ref&gt;&lt;ref name=Istratescu1981&gt;{{cite book|last1=Istrăţescu|first1=Vasile|title=Fixed point theory|date=1981|publisher=D. Reidel Publishing Co.|location=Dordrecht-Boston, Mass.|isbn=978-90-277-1224-0}}&lt;/ref&gt;

===Prehistory===
[[File:Théorème-de-Brouwer-(cond-1).jpg|thumb|right|For flows in an unbounded area, or in an area with a "hole", the theorem is not applicable.]]
[[File:Théorème-de-Brouwer-(cond-2).jpg|thumb|left|The theorem applies to any disk-shaped area, where it guarantees the existence of a fixed point.]]
To understand the prehistory of Brouwer's fixed point theorem one needs to pass through [[differential equation]]s. At the end of the 19th century, the old problem&lt;ref&gt;See F. Brechenmacher ''[https://arxiv.org/abs/0704.2931 L'identité algébrique d'une pratique portée par la discussion sur l'équation à l'aide de laquelle on détermine les inégalités séculaires des planètes]'' CNRS Fédération de Recherche Mathématique du Nord-Pas-de-Calais&lt;/ref&gt; of the [[stability of the solar system]] returned into the focus of the mathematical community.&lt;ref&gt;[[Henri Poincaré]] won the [[Oscar II, King of Sweden|King of Sweden]]'s mathematical competition in 1889 for his work on the related [[three-body problem]]: [[Jacques Tits]] ''[http://www.culture.gouv.fr/culture/actualites/celebrations2004/poincare.htm Célébrations nationales 2004]'' Site du Ministère Culture et Communication&lt;/ref&gt;
Its solution required new methods. As noted by [[Henri Poincaré]], who worked on the [[three-body problem]], there is no hope to find an exact solution: "Nothing is more proper to give us an idea of the hardness of the three-body problem, and generally of all problems of Dynamics where there is no uniform integral and the Bohlin series diverge."&lt;ref name=methodes&gt;[[Henri Poincaré]] ''Les méthodes nouvelles de la mécanique céleste'' T Gauthier-Villars, Vol 3 p 389 (1892) new edition Paris: Blanchard, 1987.&lt;/ref&gt;
He also noted that the search for an approximate solution is no more efficient: "the more we seek to obtain precise approximations, the more the result will diverge towards an increasing imprecision".&lt;ref&gt;Quotation from [[Henri Poincaré]] taken from: P. A. Miquel ''[http://www.arches.ro/revue/no03/no3art03.htm La catégorie de désordre] {{Webarchive|url=https://web.archive.org/web/20160303205947/http://www.arches.ro/revue/no03/no3art03.htm# |date=2016-03-03 }}'', on the website of l'Association roumaine des chercheurs francophones en sciences humaines&lt;/ref&gt;

He studied a question analogous to that of the surface movement in a cup of coffee. What can we say, in general, about the trajectories on a surface animated by a constant [[flow (mathematics)|flow]]?&lt;ref&gt;This question was studied in: {{cite journal |first=H. |last=Poincaré |title=Sur les courbes définies par les équations différentielles |journal=[[Journal de Mathématiques Pures et Appliquées|J. de Math.]] |volume=2 |issue=4 |pages=167–244 |year=1886 }}&lt;/ref&gt; Poincaré discovered that the answer can be found in what we now call the [[topology|topological]] properties in the area containing the trajectory. If this area is [[compact space|compact]], i.e. both [[closed set|closed]] and [[bounded set|bounded]], then the trajectory either becomes stationary, or it approaches a [[limit cycle]].&lt;ref&gt;This follows from the [[Poincaré–Bendixson theorem]].&lt;/ref&gt; Poincaré went further; if the area is of the same kind as a disk, as is the case for the cup of coffee, there must necessarily be a fixed point. This fixed point is invariant under all functions which associate to each point of the original surface its position after a short time interval&amp;nbsp;''t''. If the area is a circular band, or if it is not closed,&lt;ref&gt;Multiplication by {{sfrac|1|2}} on ]0,&amp;nbsp;1[&lt;sup&gt;2&lt;/sup&gt; has no fixed point.&lt;/ref&gt; then this is not necessarily the case.

To understand differential equations better, a new branch of mathematics was born. Poincaré called it ''analysis situs''. The French [[Encyclopædia Universalis]] defines it as the branch which "treats the properties of an object that are invariant if it is deformed in any continuous way, without tearing".&lt;ref&gt;"concerne les propriétés invariantes d'une figure lorsqu’on la déforme de manière continue quelconque, sans déchirure (par exemple, dans le cas de la déformation de la sphère, les propriétés corrélatives des objets tracés sur sa surface". From C. Houzel M. Paty ''[http://www.scientiaestudia.org.br/associac/paty/pdf/Paty,M_1997g-PoincareEU.pdf Poincaré, Henri (1854–1912)] {{webarchive|url=https://web.archive.org/web/20101008232932/http://www.scientiaestudia.org.br/associac/paty/pdf/Paty%2CM_1997g-PoincareEU.pdf |date=2010-10-08 }}'' Encyclopædia Universalis Albin Michel, Paris, 1999, p.&amp;nbsp;696–706&lt;/ref&gt; In 1886, Poincaré proved a result that is equivalent to Brouwer's fixed-point theorem,&lt;ref&gt;Poincaré's theorem is stated in: V. I. Istratescu ''Fixed Point Theory an Introduction'' Kluwer Academic Publishers (réédition de 2001) p 113 {{isbn|1-4020-0301-3}}&lt;/ref&gt; although the connection with the subject of this article was not yet apparent.&lt;ref&gt;M.I. Voitsekhovskii ''[http://eom.springer.de/b/b017670.htm Brouwer theorem]'' Encyclopaedia of Mathematics {{isbn|1-4020-0609-8}}&lt;/ref&gt; A little later, he developed one of the fundamental tools for better understanding the analysis situs, now known as the [[fundamental group]] or sometimes the Poincaré group.&lt;ref&gt;{{cite book |first=Jean |last=Dieudonné |authorlink= Jean Dieudonné| title=A History of Algebraic and Differential Topology, 1900–1960 |location=Boston |publisher=Birkhäuser |year=1989 |isbn=978-0-8176-3388-2 |pages=17–24 }}&lt;/ref&gt; This method can be used for a very compact proof of the theorem under discussion.&lt;!-- fr.wikipedia has it in its article on the fundamental group, we don't --&gt;

Poincaré's method was analogous to that of [[Charles Émile Picard|Émile Picard]], a contemporary mathematician who generalized the [[Cauchy–Lipschitz theorem]].&lt;ref&gt;See for example: [[Charles Émile Picard|Émile Picard]] ''[http://portail.mathdoc.fr/JMPA/PDF/JMPA_1893_4_9_A4_0.pdf Sur l'application des méthodes d'approximations successives à l'étude de certaines équations différentielles ordinaires] {{Webarchive|url=https://web.archive.org/web/20110716055143/http://portail.mathdoc.fr/JMPA/PDF/JMPA_1893_4_9_A4_0.pdf# |date=2011-07-16 }}'' Journal de Mathématiques p 217 (1893)&lt;/ref&gt; Picard's approach is based on a result that would later be formalised by [[Banach fixed-point theorem|another fixed-point theorem]], named after [[Stefan Banach|Banach]]. Instead of the topological properties of the domain, this theorem uses the fact that the function in question is a [[contraction mapping|contraction]].

===First proofs===
[[Image:Hadamard2.jpg|thumb|right|[[Jacques Hadamard]] helped Brouwer to formalize his ideas.]]
At the dawn of the 20th century, the interest in analysis situs did not stay unnoticed. However, the necessity of a theorem equivalent to the one discussed in this article was not yet evident. [[Piers Bohl]], a [[Latvia]]n mathematician, applied topological methods to the study of differential equations.&lt;ref&gt;J. J. O'Connor E. F. Robertson ''[http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Bohl.html Piers Bohl]''&lt;/ref&gt; In 1904 he proved the three-dimensional case of our theorem,&lt;ref name="Bohl1904" /&gt; but his publication was not noticed.&lt;ref&gt;{{cite journal |first=A. D. |last=Myskis |first2=I. M. |last2=Rabinovic |title=Первое доказательство теоремы о неподвижной точке при непрерывном отображении шара в себя, данное латышским математиком П.Г.Болем |trans-title=The first proof of a fixed-point theorem for a continuous mapping of a sphere into itself, given by the Latvian mathematician P. G. Bohl |language=Russian |journal=Успехи математических наук |volume=10 |issue=3 |year=1955 |pages=188–192 |url=http://mi.mathnet.ru/eng/umn/v10/i3/p179 }}&lt;/ref&gt;

It was Brouwer, finally, who gave the theorem its first patent of nobility. His goals were different from those of Poincaré. This mathematician was inspired by the foundations of mathematics, especially [[mathematical logic]] and [[topology]]. His initial interest lay in an attempt to solve [[Hilbert's fifth problem]].&lt;ref&gt;J. J. O'Connor E. F. Robertson ''[http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Brouwer.html Luitzen Egbertus Jan Brouwer]''&lt;/ref&gt; In 1909, during a voyage to Paris, he met [[Henri Poincaré]], [[Jacques Hadamard]], and [[Émile Borel]]. The ensuing discussions convinced Brouwer of the importance of a better understanding of Euclidean spaces, and were the origin of a fruitful exchange of letters with Hadamard. For the next four years, he concentrated on the proof of certain great theorems on this question. In 1912 he proved the [[hairy ball theorem]] for the two-dimensional sphere, as well as the fact that every continuous map from the two-dimensional ball to itself has a fixed point.&lt;ref&gt;{{cite journal |first=Hans  |last=Freudenthal |authorlink=Hans Freudenthal | title=The cradle of modern topology, according to Brouwer's inedita |journal=[[Historia Mathematica]] |volume=2 |issue=4 |pages=495–502 [p. 495] |year=1975 |doi=10.1016/0315-0860(75)90111-1 }}&lt;/ref&gt; These two results in themselves were not really new. As Hadamard observed, Poincaré had shown a theorem equivalent to the hairy ball theorem.&lt;ref&gt;{{cite journal |first=Hans |last=Freudenthal |authorlink=Hans Freudenthal | title=The cradle of modern topology, according to Brouwer's inedita |journal=[[Historia Mathematica]] |volume=2 |issue=4 |pages=495–502 [p. 495] |year=1975 |doi=10.1016/0315-0860(75)90111-1 |quote=... cette dernière propriété, bien que sous des hypothèses plus grossières, ait été démontré par H. Poincaré }}&lt;/ref&gt; The revolutionary aspect of Brouwer's approach was his systematic use of recently developed tools such as [[homotopy]], the underlying concept of the Poincaré group. In the following year, Hadamard generalised the theorem under discussion to an arbitrary finite dimension, but he employed different methods. [[Hans Freudenthal]] comments on the respective roles as follows: &lt;!-- NON-LITERAL QUOTATION! translated back from French --&gt;"Compared to Brouwer's revolutionary methods, those of Hadamard were very traditional, but Hadamard's participation in the birth of Brouwer's ideas resembles that of a midwife more than that of a mere spectator."&lt;ref&gt;{{cite journal |first=Hans |last=Freudenthal |authorlink=Hans Freudenthal | title=The cradle of modern topology, according to Brouwer's inedita |journal=[[Historia Mathematica]] |volume=2 |issue=4 |pages=495–502 [p. 501] |year=1975 |doi=10.1016/0315-0860(75)90111-1 }}&lt;/ref&gt;

Brouwer's approach yielded its fruits, and in 1910 he also found a proof that was valid for any finite dimension,&lt;ref name="brouwer-1910" /&gt; as well as other key theorems such as the invariance of dimension.&lt;ref&gt;If an open subset of a [[manifold]] is [[homeomorphism|homeomorphic]] to an open subset of a Euclidean space of dimension ''n'', and if ''p'' is a positive integer other than ''n'', then the open set is never homeomorphic to an open subset of a Euclidean space of dimension ''p''.&lt;/ref&gt; In the context of this work, Brouwer also generalized the [[Jordan curve theorem]] to arbitrary dimension and established the properties connected with the [[degree of a continuous mapping]].&lt;ref&gt;J. J. O'Connor E. F. Robertson ''[http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Brouwer.html Luitzen Egbertus Jan Brouwer]''.&lt;/ref&gt; This branch of mathematics, originally envisioned by Poincaré and developed by Brouwer, changed its name. In the 1930s, analysis situs became [[algebraic topology]].&lt;ref&gt;The term ''algebraic topology'' first appeared 1931 under the pen of David van Dantzig: J. Miller ''[http://jeff560.tripod.com/t.html Topological algebra]'' on the site Earliest Known Uses of Some of the Words of Mathematics (2007)&lt;/ref&gt;

===Reception===
[[Image:John f nash 20061102 2.jpg|thumb|220px|left|[[John Forbes Nash|John Nash]] used the theorem in [[game theory]] to prove the existence of an equilibrium strategy profile.]]
The theorem proved its worth in more than one way. During the 20th century numerous fixed-point theorems were developed, and even a branch of mathematics called [[fixed-point theory]].&lt;ref&gt;V. I. Istratescu ''Fixed Point Theory. An Introduction'' Kluwer Academic Publishers (new edition 2001) {{isbn|1-4020-0301-3}}.&lt;/ref&gt;
Brouwer's theorem is probably the most important.&lt;ref&gt;"... Brouwer's fixed point theorem, perhaps the most important fixed point theorem." p xiii V. I. Istratescu ''Fixed Point Theory an Introduction'' Kluwer Academic Publishers (new edition 2001) {{isbn|1-4020-0301-3}}.&lt;/ref&gt; It is also among the foundational theorems on the topology of [[topological manifold]]s and is often used to prove other important results such as the [[Jordan curve theorem]].&lt;ref&gt;E.g.: S. Greenwood J. Cao'' [http://www.math.auckland.ac.nz/class750/section5.pdf Brouwer’s Fixed Point Theorem and the Jordan Curve Theorem]'' University of Auckland, New Zealand.&lt;/ref&gt;

Besides the fixed-point theorems for more or less [[contraction mapping|contracting]] functions, there are many that have emerged directly or indirectly from the result under discussion. A continuous map from a closed ball of Euclidean space to its boundary cannot be the identity on the boundary. Similarly, the [[Borsuk–Ulam theorem]] says that a continuous map from the ''n''-dimensional sphere to '''R'''&lt;sup&gt;n&lt;/sup&gt; has a pair of antipodal points that are mapped to the same point. In the finite-dimensional case, the [[Lefschetz fixed-point theorem]] provided from 1926 a method for counting fixed points. In 1930, Brouwer's fixed-point theorem was generalized to [[Banach space]]s.&lt;ref&gt;{{cite journal |first=J. |last=Schauder |title=Der Fixpunktsatz in Funktionsräumen |journal=[[Studia Mathematica|Studia. Math.]] |volume=2 |year=1930 |issue= |pages=171–180 |doi= }}&lt;/ref&gt; This generalization is known as [[Fixed-point theorems in infinite-dimensional spaces|Schauder's fixed-point theorem]], a result generalized further by S. Kakutani to [[multivalued function]]s.&lt;ref&gt;{{cite journal |first=S. |last=Kakutani |title=A generalization of Brouwer's Fixed Point Theorem |journal=Duke Math. J. |volume=8 |year=1941 |issue=3 |pages=457–459 |doi=10.1215/S0012-7094-41-00838-4 }}&lt;/ref&gt; One also meets the theorem and its variants outside topology. It can be used to prove the [[Hartman-Grobman theorem]], which describes the qualitative behaviour of certain differential equations near certain equilibria. Similarly, Brouwer's theorem is used for the proof of the [[Central Limit Theorem]]. The theorem can also be found in existence proofs for the solutions of certain [[partial differential equation]]s.&lt;ref&gt;These examples are taken from: F. Boyer ''[http://www.cmi.univ-mrs.fr/~fboyer/ter_fboyer2.pdf Théorèmes de point fixe et applications]'' CMI Université Paul Cézanne (2008–2009) [https://www.webcitation.org/5refXIDvI?url=http://www.cmi.univ-mrs.fr/%7Efboyer/ter_fboyer2.pdf Archived copy] at [[WebCite]] (August 1, 2010).&lt;/ref&gt;

Other areas are also touched. In [[game theory]], [[John Forbes Nash|John Nash]] used the theorem to prove that in the game of [[Hex (board game)|Hex]] there is a winning strategy for white.&lt;ref&gt;For context and references see the article [[Hex (board game)]].&lt;/ref&gt; In economics, P. Bich explains that certain generalizations of the theorem show that its use is helpful for certain classical problems in game theory and generally for equilibria ([[Hotelling's law]]), financial equilibria and incomplete markets.&lt;ref&gt;P. Bich ''[http://www.ann.jussieu.fr/~plc/code2007/bich.pdf Une extension discontinue du théorème du point fixe de Schauder, et quelques applications en économie] {{webarchive |url=https://web.archive.org/web/20110611140634/http://www.ann.jussieu.fr/~plc/code2007/bich.pdf |date=June 11, 2011 }}'' Institut Henri Poincaré, Paris (2007)&lt;/ref&gt;

Brouwer's celebrity is not exclusively due to his topological work. The proofs of his great topological theorems are [[constructive proof|not constructive]],&lt;ref&gt;For a long explanation, see: {{cite journal |first=J. P. |last=Dubucs |url=http://www.persee.fr/web/revues/home/prescript/article/rhs_0151-4105_1988_num_41_2_4094 |title=L. J. E. Brouwer : Topologie et constructivisme |journal=Revue d'Histoire des Sciences |volume=41 |issue=2 |pages=133–155 |year=1988 }}&lt;/ref&gt; and Brouwer's dissatisfaction with this is partly what led him to articulate the idea of [[constructivism (mathematics)|constructivity]]. He became the originator and zealous defender of a way of formalising mathematics that is known as [[intuitionistic logic|intuitionism]], which at the time made a stand against [[set theory]].&lt;ref&gt;Later it would be shown that the formalism that was combatted by Brouwer can also serve to formalise intuitionism, with some modifications. For further details see [[constructive set theory]].&lt;/ref&gt; Brouwer disavowed his original proof of the fixed-point theorem. The first algorithm to approximate a fixed point was proposed by [[Herbert Scarf]].&lt;ref&gt;H. Scarf found the first algorithmic proof: M.I. Voitsekhovskii ''[http://eom.springer.de/b/b017670.htm Brouwer theorem]'' Encyclopaedia of Mathematics {{isbn|1-4020-0609-8}}.&lt;/ref&gt; It is important to here note a confusing subtlety — Scarf's algorithm finds a point that is ''almost fixed'' by a function ''f'', but in general cannot find a point that is close to an actual fixed point. In mathematical language, if ε is chosen to be very small, Scarf's algorithm can be used to find a point ''x'' such that ''f(x)'' is very close to ''x'', i.e., &lt;math&gt;d(f(x),x) &lt; \varepsilon&lt;/math&gt;. But Scarf's algorithm cannot be used to find a point ''x'' such that ''x'' is very close to a fixed point: we cannot guarantee &lt;math&gt;d(x,y) &lt; \varepsilon&lt;/math&gt;, where &lt;math&gt;f(y)=y&lt;/math&gt;. Often this latter condition is what is meant by the informal phrase "approximating a fixed point."

==Proof outlines==

===A proof using degree===
Brouwer's original 1911 proof relied on the notion of the [[degree of a continuous mapping]].  Modern accounts of the proof can also be found in the literature.&lt;ref&gt;{{citation | last = Teschl| first = Gerald| authorlink = Gerald Teschl| title = Topics in Real and Functional Analysis| url = http://www.mat.univie.ac.at/~gerald/ftp/book-fa/index.html|chapter=14.4: The Brouwer fixed point theorem|year=2005|accessdate=2016-03-08}}&lt;/ref&gt;

Let &lt;math&gt;K=\overline{B(0)}&lt;/math&gt; denote the closed unit ball in &lt;math&gt;\mathbb R^n&lt;/math&gt; centered at the origin.  Suppose for simplicitly that &lt;math&gt;f:K\to K&lt;/math&gt; is continuously differentiable.  A [[regular value]] of &lt;math&gt;f&lt;/math&gt; is a point &lt;math&gt;p\in B(0)&lt;/math&gt; such that the [[Jacobian matrix and determinant|Jacobian]] of &lt;math&gt;f&lt;/math&gt; is non-singular at every point of the preimage of &lt;math&gt;p&lt;/math&gt;.  In particular, by the [[inverse function theorem]], every point of the preimage of &lt;math&gt;f&lt;/math&gt; lies in &lt;math&gt;B(0)&lt;/math&gt; (the interior of &lt;math&gt;K&lt;/math&gt;).  The degree of &lt;math&gt;f&lt;/math&gt; at a regular value &lt;math&gt;p\in B(0)&lt;/math&gt; is defined as the sum of the signs of the [[Jacobian determinant]] of &lt;math&gt;f&lt;/math&gt; over the preimages of &lt;math&gt;p&lt;/math&gt; under &lt;math&gt;f&lt;/math&gt;:

:&lt;math&gt;\operatorname{deg}_p(f) = \sum_{x\in f^{-1}(p)} \operatorname{sign}\left(\det(Df(x))\right).&lt;/math&gt;

The degree is, roughly speaking, the number of "sheets" of the preimage ''f'' lying over a small open set around ''p'', with sheets counted oppositely if they are oppositely oriented.  This is thus a generalization of [[winding number]] to higher dimensions.

The degree satisfies the property of ''homotopy invariance'': let &lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt; be two continuously differentiable functions, and &lt;math&gt;H_t(x)=tf+(1-t)g&lt;/math&gt; for &lt;math&gt;0\le t\le 1&lt;/math&gt;.  Suppose that the point &lt;math&gt;p&lt;/math&gt; is a regular value of &lt;math&gt;H_t&lt;/math&gt; for all ''t''.  Then &lt;math&gt;\deg_p f = \deg_p g&lt;/math&gt;.

If there is no fixed point of the boundary of &lt;math&gt;K&lt;/math&gt;, then the function 
:&lt;math&gt;g(x)=\frac{x-f(x)}{\sup_{x\in K}\left|x-f(x)\right|}&lt;/math&gt;

is well-defined, and 

&lt;math&gt;H(t,x) = \frac{x-tf(x)}{\sup_{x\in K}\left|x-tf(x)\right|}&lt;/math&gt;

defines a homotopy from the identity function to it.  The identity function has degree one at every point.  In particular, the identity function has degree one at the origin, so &lt;math&gt;g&lt;/math&gt; also has degree one at the origin.  As a consequence, the preimage &lt;math&gt;g^{-1}(0)&lt;/math&gt; is not empty.  The elements of &lt;math&gt;g^{-1}(0)&lt;/math&gt; are precisely the fixed points of the original function ''f''.

This requires some work to make fully general.  The definition of degree must be extended to singular values of ''f'', and then to continuous functions.  The more modern advent of [[homology theory]] simplifies the construction of the degree, and so has become a standard proof in the literature.

===A proof using homology===
The proof uses the observation that the [[boundary (topology)|boundary]] of ''D''&lt;sup&gt; ''n''&lt;/sup&gt; is ''S''&lt;sup&gt; ''n'' − 1&lt;/sup&gt;, the (''n'' − 1)-[[sphere]].

[[Image:Brouwer fixed point theorem retraction.svg|thumb|right|Illustration of the retraction ''F'']]
The argument proceeds by contradiction, supposing that a continuous function ''f''&amp;nbsp;:&amp;nbsp;''D''&lt;sup&gt; ''n''&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;''D''&lt;sup&gt; ''n''&lt;/sup&gt; has ''no'' fixed point, and then attempting to derive an inconsistency, which proves that the function must in fact have a fixed point. For each ''x'' in ''D''&lt;sup&gt; ''n''&lt;/sup&gt;, there is only one straight line that passes through ''f''(''x'') and ''x'', because it must be the case that ''f''(''x'') and ''x'' are distinct by hypothesis (recall that ''f'' having no fixed points means that ''f''(''x'') ≠ ''x''). Following this line from ''f''(''x'') through ''x'' leads to a point on ''S''&lt;sup&gt; ''n'' − 1&lt;/sup&gt;, denoted by ''F''(''x''). This defines a continuous function ''F''&amp;nbsp;:&amp;nbsp;''D''&lt;sup&gt; ''n''&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;''S''&lt;sup&gt; ''n'' − 1&lt;/sup&gt;, which is a special type of continuous function known as a [[retract]]ion: every point of the [[codomain]] (in this case ''S''&lt;sup&gt; ''n'' − 1&lt;/sup&gt;) is a fixed point of the function.

Intuitively it seems unlikely that there could be a retraction of ''D''&lt;sup&gt; ''n''&lt;/sup&gt; onto ''S''&lt;sup&gt; ''n'' − 1&lt;/sup&gt;, and in the case ''n'' = 1 it is obviously impossible because ''S''&lt;sup&gt; 0&lt;/sup&gt; (i.e., the endpoints of the closed interval ''D''&lt;sup&gt; 1&lt;/sup&gt;) is not even connected. The case ''n'' = 2 is less obvious, but can be proven by using basic arguments involving the [[fundamental group]]s of the respective spaces: the retraction would induce an injective [[group homomorphism]] from the fundamental group of ''S''&lt;sup&gt; 1&lt;/sup&gt; to that of ''D''&lt;sup&gt; 2&lt;/sup&gt;, but the first group is isomorphic to '''Z''' while the latter group is trivial, so this is impossible. The case ''n'' = 2 can also be proven by contradiction based on a theorem about non-vanishing [[vector field]]s.

For ''n'' &gt; 2, however, proving the impossibility of the retraction is more difficult. One way is to make use of [[Homology (mathematics)|homology groups]]:  the homology ''H''&lt;sub&gt;''n'' − 1&lt;/sub&gt;(''D''&lt;sup&gt; ''n''&lt;/sup&gt;) is trivial, while ''H''&lt;sub&gt;''n'' − 1&lt;/sub&gt;(''S''&lt;sup&gt;&amp;nbsp;''n'' − 1&lt;/sup&gt;) is infinite [[cyclic group|cyclic]]. This shows that the retraction is impossible, because again the retraction would induce an injective group homomorphism from the latter to the former group.

===A proof using Stokes's theorem===
To prove that a map has fixed points, one can assume that it is smooth, because if a map has no fixed points then convolving it with a smooth function of sufficiently small support and integral equal to one produces a smooth function with no fixed points. As in the proof using homology, one is reduced to proving that there is no smooth retraction ''F'' from the ball ''B'' onto its boundary ''∂B''. If ω is a volume form on the boundary then by [[Stokes Theorem]],
:&lt;math&gt;0&lt;\int_{\partial B}\omega = \int_{\partial B}F^*(\omega) = \int_BdF^*(\omega)= \int_BF^*(d\omega)=\int_BF^*(0) = 0&lt;/math&gt;
giving a contradiction.

More generally, this shows that there is no smooth retraction from any non-empty smooth orientable compact manifold onto its boundary. The proof using Stokes's theorem is closely related to the proof using homology (or rather cohomology), because the form ω generates the de Rham cohomology group ''H''&lt;sup&gt;''n''−1&lt;/sup&gt;(''∂B'') used in the cohomology proof.

===A combinatorial proof===
The BFPT can be proved using [[Sperner's lemma]]. We now give an outline of the proof for the special case in which ''f'' is a function from the standard ''n''-[[simplex]], &lt;math&gt;\Delta^n,&lt;/math&gt; to itself, where

:&lt;math&gt;\Delta^n = \left\{P\in\mathbb{R}^{n+1}\mid\sum_{i = 0}^{n}{P_i} = 1 \text{ and } P_i \ge 0 \text{ for all } i\right\}.&lt;/math&gt;

For every point &lt;math&gt;P\in \Delta^n,&lt;/math&gt; also &lt;math&gt;f(P)\in \Delta^n.&lt;/math&gt; Hence the sum of their coordinates is equal:

:&lt;math&gt;\sum_{i = 0}^{n}{P_i} = 1 = \sum_{i = 0}^{n}{f(P)_i}&lt;/math&gt;

Hence, by the pigeonhole principle, for every &lt;math&gt;P\in \Delta^n,&lt;/math&gt; there must be an index &lt;math&gt;j \in \{0, \ldots, n\}&lt;/math&gt; such that the &lt;math&gt;j&lt;/math&gt;th coordinate of &lt;math&gt;P&lt;/math&gt; is greater than or equal to the &lt;math&gt;j&lt;/math&gt;th coordinate of its image under ''f'':

:&lt;math&gt;P_j \geq f(P)_j.&lt;/math&gt;

Moreover, if &lt;math&gt;P&lt;/math&gt; lies on a ''k''-dimensional sub-face of &lt;math&gt;\Delta^n,&lt;/math&gt; then by the same argument, the index &lt;math&gt;j&lt;/math&gt; can be selected from among the {{nowrap|''k'' + 1}} coordinates which are not zero on this sub-face.

We now use this fact to construct a Sperner coloring.  For every triangulation of &lt;math&gt;\Delta^n,&lt;/math&gt; the color of every vertex &lt;math&gt;P&lt;/math&gt; is an index &lt;math&gt;j&lt;/math&gt; such that &lt;math&gt;f(P)_j \leq P_j.&lt;/math&gt;

By construction, this is a Sperner coloring. Hence, by Sperner's lemma, there is an ''n''-dimensional simplex whose vertices are colored with the entire set of {{nowrap|''n'' + 1}} available colors.

Because ''f'' is continuous, this simplex can be made arbitrarily small by choosing an arbitrarily fine triangulation. Hence, there must be a point &lt;math&gt;P&lt;/math&gt; which satisfies the labeling condition in all coordinates: &lt;math&gt;f(P)_j \leq P_j&lt;/math&gt; for all &lt;math&gt;j.&lt;/math&gt;

Because the sum of the coordinates of &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;f(P)&lt;/math&gt; must be equal, all these inequalities must actually be equalities. But this means that:

:&lt;math&gt;f(P) = P.&lt;/math&gt;

That is, &lt;math&gt;P&lt;/math&gt; is a fixed point of &lt;math&gt;f.&lt;/math&gt;

===A proof by Hirsch===
There is also a quick proof, by [[Morris Hirsch]], based on the impossibility of a differentiable retraction.  The [[indirect proof]] starts by noting that the map ''f'' can be approximated by a smooth map retaining the property of not fixing a point; this can be done by using the [[Weierstrass approximation theorem]], for example.  One then defines a retraction as above which must now be differentiable.  Such a retraction must have a non-singular value, by [[Sard's theorem]], which is also non-singular for the restriction to the boundary (which is just the identity).  Thus the inverse image would be a 1-manifold with boundary. The boundary would have to contain at least two end points, both of which would have to lie on the boundary of the original ball—which is impossible in a retraction.

{{harv|Kellogg|Li|Yorke|1976}} turned Hirsch's proof into a [[Computability|computable]] proof by observing that the retract is in fact defined everywhere except at the fixed points. For almost any point, ''q'', on the boundary, (assuming it is not a fixed point) the one manifold with boundary mentioned above does exist and the only possibility is that it leads from ''q'' to a fixed point. It is an easy numerical task to follow such a path from ''q'' to the fixed point so the method is essentially computable. {{harv|Chow|Mallet-Paret|Yorke|1978}} gave a conceptually similar path-following version of the homotopy proof which extends to a wide variety of related problems.

===A proof using the ''oriented area''===
A variation of the preceding proof does not employ the Sard's theorem, and goes as follows. If &lt;math&gt;r\colon B\to \partial B&lt;/math&gt; is a smooth retraction, one considers the smooth deformation &lt;math&gt;g^t(x):=t\, r(x)+(1-t)x&lt;/math&gt;, and the smooth function
:&lt;math&gt;\varphi(t):=\int_B \operatorname{det} D g^t(x) dx&lt;/math&gt;
Differentiating under the sign of integral it is not difficult to check that ''φ′(t)=0'' for all ''t'', so ''φ'' is a constant function, which is a contradiction because ''φ(0)'' is the ''n''-dimensional volume of the ball, while ''φ(1)'' is zero.  The geometric idea is that ''φ(t)'' is the oriented area of ''g&lt;sup&gt;t&lt;/sup&gt;(B)'' (that is, the Lebesgue measure of the image of the ball via ''g&lt;sup&gt;t&lt;/sup&gt;'', taking into account multiplicity and orientation), and should remain constant (as it is very clear in the one-dimensional case). On the other hand, as the parameter ''t'' passes form ''0'' to ''1'' the map ''g&lt;sup&gt;t&lt;/sup&gt;'' transforms continuously from the identity map of the ball, to the retraction ''r'', which is a contradiction since the oriented area of the identity coincides with the volume of the ball, while the oriented area of ''r'' is necessarily ''0'', as its image is the boundary of the ball, a set of null measure.

===A proof using the game hex===
A quite different proof given by [[David Gale]] is based on the game of [[Hex (board game)|Hex]].  The basic theorem about Hex is that no game can end in a draw.  This is equivalent to the Brouwer fixed-point theorem for dimension 2.  By considering ''n''-dimensional versions of Hex, one can prove in general that Brouwer's theorem is equivalent to the [[determinacy]] theorem for Hex.&lt;ref&gt;{{cite journal|author=David Gale |year=1979|title=The Game of Hex and Brouwer Fixed-Point Theorem | journal=The American Mathematical Monthly | volume=86 | pages=818–827|doi=10.2307/2320146|jstor=2320146|issue=10}}&lt;/ref&gt;

===A proof using the Lefschetz fixed-point theorem===
The Lefschetz fixed-point theorem says that if a continuous map ''f'' from a finite simplicial complex ''B'' to itself has only isolated fixed points, then the number of fixed points counted with multiplicities (which may be negative) is equal to the Lefschetz number
:&lt;math&gt;\displaystyle \sum_n(-1)^n\operatorname{Tr}(f|H_n(B))&lt;/math&gt;
and in particular if the Lefschetz number is nonzero then ''f'' must have a fixed point. If ''B'' is a ball (or more generally is contractible) then the Lefschetz number is one because the only non-zero homology group is :&lt;math&gt;H_0(B)&lt;/math&gt; and ''f'' acts as the identity on this group, so ''f'' has a fixed point.

===A proof in a weak logical system===
In [[reverse mathematics]], Brouwer's theorem can be proved in the system [[Weak König's lemma|WKL&lt;sub&gt;0&lt;/sub&gt;]], and conversely over the base system [[reverse mathematics|RCA&lt;sub&gt;0&lt;/sub&gt;]] Brouwer's theorem for a square implies the [[weak König's lemma]], so this gives a precise description of the strength of Brouwer's theorem.

==Generalizations==
The Brouwer fixed-point theorem forms the starting point of a number of more general [[fixed-point theorem]]s.

The straightforward generalization to infinite dimensions, i.e. using the unit ball of an arbitrary [[Hilbert space]] instead of Euclidean space, is not true. The main problem here is that the unit balls of infinite-dimensional Hilbert spaces are not [[compact space|compact]]. For example, in the Hilbert space [[Lp space|ℓ&lt;sup&gt;2&lt;/sup&gt;]] of square-summable real (or complex) sequences, consider the map ''f'' : ℓ&lt;sup&gt;2&lt;/sup&gt; → ℓ&lt;sup&gt;2&lt;/sup&gt; which sends a sequence (''x''&lt;sub&gt;''n''&lt;/sub&gt;) from the closed unit ball of ℓ&lt;sup&gt;2&lt;/sup&gt; to the sequence (''y''&lt;sub&gt;''n''&lt;/sub&gt;) defined by
:&lt;math&gt;y_0=\sqrt{1-\|x\|_2^2}\qquad\text{ and }\qquad y_n=x_{n-1}\quad\text{ for }\quad n\geq 1.&lt;/math&gt;
It is not difficult to check that this map is continuous, has its image in the unit sphere of ℓ&lt;sup&gt; 2&lt;/sup&gt;, but does not have a fixed point.

The generalizations of the Brouwer fixed-point theorem to infinite dimensional spaces therefore all include a compactness assumption of some sort, and in addition also often an assumption of [[Convex set|convexity]]. See [[fixed-point theorems in infinite-dimensional spaces]] for a discussion of these theorems.

There is also finite-dimensional generalization to a larger class of spaces: If &lt;math&gt;X&lt;/math&gt; is a product of finitely many chainable continua, then every continuous function &lt;math&gt;f:X\rightarrow X&lt;/math&gt; has a fixed point,&lt;ref&gt;{{cite journal|author=Eldon Dyer |year=1956|title=A fixed point theorem | journal=Proceedings of the American Mathematical Society| volume=7 | pages=662–672|doi=10.1090/S0002-9939-1956-0078693-4|url=http://www.ams.org/journals/proc/1956-007-04/S0002-9939-1956-0078693-4/home.html|issue=4}}&lt;/ref&gt; where a chainable continuum is a (usually but in this case not necessarily [[Metric space|metric]]) [[Compact space|compact]] [[Hausdorff space]] of which every [[open cover]] has a finite open refinement &lt;math&gt;\{U_1,\ldots,U_m\}&lt;/math&gt;, such that &lt;math&gt;U_i \cap U_j \neq \emptyset&lt;/math&gt; if and only if &lt;math&gt;|i-j| \leq 1&lt;/math&gt;. Examples of chainable continua include compact connected linearly ordered spaces and in particular closed intervals of real numbers.

The [[Kakutani fixed point theorem]] generalizes the Brouwer fixed-point theorem in a different direction: it stays in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, but considers upper [[hemi-continuous]] [[correspondence (mathematics)|correspondences]] (functions that assign to each point of the set a subset of the set). It also requires compactness and convexity of the set.

The [[Lefschetz fixed-point theorem]] applies to (almost) arbitrary compact topological spaces, and gives a condition in terms of [[singular homology]] that guarantees the existence of fixed points; this condition is trivially satisfied for any map in the case of ''D''&lt;sup&gt; ''n''&lt;/sup&gt;.

== Equivalent results ==
{{Analogous fixed-point theorems}}

==See also==
* [[Banach fixed-point theorem]]
* [[Infinite compositions of analytic functions]]
* [[Nash equilibrium#Alternate proof using the Brouwer fixed-point theorem|Nash equilibrium]]
* [[Poincaré–Miranda theorem]] – equivalent to the Brouwer fixed-point theorem
* [[Topological combinatorics]]

==Notes==
{{reflist|35em}}

==References==
*{{cite journal |first=Shui Nee |last=Chow |first2=John |last2=Mallet-Paret |first3=James A. |last3=Yorke |author3-link=James A. Yorke | title=Finding zeroes of maps: Homotopy methods that are constructive with probability one |journal=[[Mathematics of Computation]] |volume=32 |year=1978 |issue= 143|pages=887–899 |doi=10.1090/S0025-5718-1978-0492046-9|mr=0492046 }}
*{{cite journal|author=Gale, D. |year=1979|title=The Game of Hex and Brouwer Fixed-Point Theorem | journal=The American Mathematical Monthly | volume=86 | pages=818–827|doi=10.2307/2320146|jstor=2320146|issue=10}}
*{{cite book |first=Morris W. |last=Hirsch | authorlink=Morris Hirsch| title=Differential Topology |location=New York |publisher=Springer |year=1988 |isbn=978-0-387-90148-0 }} (see p.&amp;nbsp;72–73 for Hirsch's proof utilizing non-existence of a differentiable retraction)
*{{cite book |first=Vasile I. |last=Istrăţescu |title=Fixed Point Theory |series=Mathematics and its Applications|volume= 7 |publisher=D. Reidel|location=Dordrecht–Boston, MA |year=1981 |isbn=978-90-277-1224-0|mr=0620639 }}
*{{cite book |editor-first=S. |editor-last=Karamardian |title=Fixed Points: Algorithms and Applications |location= |publisher=Academic Press |year=1977 |isbn=978-0-12-398050-2 }}
*{{cite journal |first=R. Bruce |last=Kellogg |first2=Tien-Yien |last2=Li |first3=James A. |last3=Yorke |author3-link=James A. Yorke| title=A constructive proof of the Brouwer fixed point theorem and computational results |journal=[[SIAM Journal on Numerical Analysis]] |volume=13 |year=1976 |issue=4 |pages=473–483 |doi=10.1137/0713041|mr=0416010 }}
*Leoni, Giovanni (2017). ''[http://bookstore.ams.org/gsm-181/ A First Course in Sobolev Spaces: Second Edition]''. [[Graduate Studies in Mathematics]]. '''181'''. American Mathematical Society. pp.&amp;nbsp;734. {{ISBN|978-1-4704-2921-8}}
*{{springer | title=Brouwer theorem | id=B/b017670 | last=Sobolev | first=Vladimir I. | author-link=&lt;!--Vladimir Ivanovich Sobolev--&gt;}}

==External links==
* [http://www.cut-the-knot.org/do_you_know/poincare.shtml#brouwertheorem Brouwer's Fixed Point Theorem for Triangles] at [[cut-the-knot]]
* [http://planetmath.org/encyclopedia/BrouwerFixedPointTheorem.html Brouwer theorem], from [[PlanetMath]] with attached proof.
* [http://www.mathpages.com/home/kmath262/kmath262.htm Reconstructing Brouwer] at MathPages
* [http://mathforum.org/mathimages/index.php/Brouwer_Fixed_Point_Theorem Brouwer Fixed Point Theorem] at Math Images.

{{DEFAULTSORT:Brouwer Fixed Point Theorem}}
[[Category:Fixed-point theorems]]
[[Category:Continuous mappings]]
[[Category:Theorems in topology]]
[[Category:Theorems in convex geometry]]</text>
      <sha1>7fjrcal1167c6ie1ogdfoimko3zcu00</sha1>
    </revision>
  </page>
  <page>
    <title>Cantor's first set theory article</title>
    <ns>0</ns>
    <id>49411787</id>
    <redirect title="Georg Cantor&#039;s first set theory article" />
    <revision>
      <id>830925763</id>
      <parentid>704711857</parentid>
      <timestamp>2018-03-17T18:45:15Z</timestamp>
      <contributor>
        <username>RJGray</username>
        <id>8268674</id>
      </contributor>
      <comment>Added categories</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="183">#REDIRECT [[Georg Cantor's first set theory article]]
{{R from move}}

[[Category:History of mathematics]]
[[Category:Set theory]]
[[Category:Real analysis]]
[[Category:Georg Cantor]]</text>
      <sha1>b121rz748dhklluk4dvjtljtmqxdwyq</sha1>
    </revision>
  </page>
  <page>
    <title>Chain rule for Kolmogorov complexity</title>
    <ns>0</ns>
    <id>8566056</id>
    <revision>
      <id>826008476</id>
      <parentid>790697155</parentid>
      <timestamp>2018-02-16T17:55:00Z</timestamp>
      <contributor>
        <ip>68.144.152.113</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4521">{{inline|date=July 2014}}
The chain rule{{cn|date=July 2014}} for [[Kolmogorov complexity]] is an analogue of the chain rule for [[information entropy]], which states:

:&lt;math&gt;
H(X,Y) = H(X) + H(Y|X)
&lt;/math&gt;

That is, the combined [[randomness]] of two sequences ''X'' and ''Y'' is the sum of the randomness of ''X'' plus whatever randomness is left in ''Y'' once we know ''X''.
This follows immediately from the definitions of [[conditional entropy|conditional]] and [[joint entropy]], and the fact from [[probability theory]] that the [[joint probability]] is the product of the [[marginal probability|marginal]] and [[conditional probability]]:

:&lt;math&gt;
P(X,Y) = P(X) P(Y|X)
&lt;/math&gt;
:&lt;math&gt;
\Rightarrow \log P(X,Y) = \log P(X) + \log P(Y|X)
&lt;/math&gt;

The equivalent statement for Kolmogorov complexity does not hold exactly; it is true only up to a [[logarithm]]ic term:

:&lt;math&gt;
K(x,y) = K(x) + K(y|x) + O(\log(K(x,y)))
&lt;/math&gt;

(An exact version, ''KP''(''x'',&amp;nbsp;''y'')&amp;nbsp;=&amp;nbsp;''KP''(''x'')&amp;nbsp;+&amp;nbsp;''KP''(''y''|''x''*)&amp;nbsp;+&amp;nbsp;O(1),
holds for the prefix complexity ''KP'', where  ''x*'' is a shortest program for ''x''.)

It states that the shortest program printing ''X'' and ''Y'' is obtained by concatenating a shortest program printing ''X'' with a program printing ''Y'' given ''X'', plus [[Big-O notation|at most]] a logarithmic factor. The results implies that  [[Mutual information#Absolute mutual information|algorithmic mutual information]], an analogue of mutual information for Kolmogorov complexity is symmetric: ''I(x:y) = I(y:x) + O(log K(x,y))'' for all ''x,y''.

==Proof==

The ≤ direction is obvious: we can write a program to produce ''x'' and ''y'' by concatenating a program to produce ''x'', a program to produce ''y'' given
access to ''x'', and (whence the log term) the length of one of the programs, so
that we know where to separate the two programs for ''x'' and ''y''|''x'' (log(''K''(''x'',&amp;nbsp;''y'')) upper-bounds this length).

For the ≥ direction, it suffices to show that for all k,l such that k+l = K(x,y) we have that either

      ''K(x|k,l) ≤ k + O(1)''   or   ''K(y|x,k,l) ≤ l + O(1)''.

Consider the list ''(a&lt;sub&gt;1&lt;/sub&gt;,b&lt;sub&gt;1&lt;/sub&gt;), (a&lt;sub&gt;2&lt;/sub&gt;,b&lt;sub&gt;2&lt;/sub&gt;), ..., (a&lt;sub&gt;e&lt;/sub&gt;,b&lt;sub&gt;e&lt;/sub&gt;)'' of all pairs ''(a,b)'' produced by programs of length exactly ''K(x,y)'' [hence K(a,b) ≤ K(x,y)]. Note that this list
* contains the pair ''(x,y)'',
* can be [[recursively enumerable|enumerated]] given ''k'' and ''l'' (by running all programs of length ''K(x,y)'' in parallel),
* has at most ''2&lt;sup&gt;K(x,y)&lt;/sup&gt;'' elements (because there are at most 2&lt;sup&gt;n&lt;/sup&gt; programs of length n).

First, suppose that ''x'' appears less than ''2&lt;sup&gt;l&lt;/sup&gt;'' times as first element. We can specify ''y'' given ''x,k,l'' by enumerating ''(a&lt;sub&gt;1&lt;/sub&gt;,b&lt;sub&gt;1&lt;/sub&gt;), (a&lt;sub&gt;2&lt;/sub&gt;,b&lt;sub&gt;2&lt;/sub&gt;), ...'' and then selecting ''(x,y)'' in the sub-list of pairs ''(x,b)''. By assumption, the index of ''(x,y)'' in this sub-list is less than ''2&lt;sup&gt;l&lt;/sup&gt;'' and hence, there is a program for ''y'' given ''x,k,l'' of length ''l + O(1)''.
Now, suppose that ''x'' appears at least ''2&lt;sup&gt;l&lt;/sup&gt;'' times as first element. This can happen for at most ''2&lt;sup&gt;K(x,y)-l&lt;/sup&gt; = 2&lt;sup&gt;k&lt;/sup&gt;'' different strings. These strings can be enumerated given ''k,l'' and hence ''x'' can be specified by its index in this enumeration. The corresponding program for ''x'' has size ''k + O(1)''. Theorem proved.

==References==
* {{cite book
  | last = Li
  | first = Ming
  | author2 = Vitányi, Paul
  | title = An introduction to Kolmogorov complexity and its applications
  | location = New York
  | publisher = [[Springer-Verlag]]
  |date=February 1997
  | isbn = 0-387-94868-6 }}

* {{cite news
  | last = Kolmogorov
  | first = A.N.
  | title = Logical basis for information theory and probability theory
  | journal = IEEE Transactions on Information Theory 
  | number = 5
  | volume = 14 
  | pages = 662–664 
  | year = 1968 }}

* {{cite news
  | first = A. 
  | last = Zvonkin 
  |author2=L. Levin  
  | title = The complexity of finite objects and the development of the concepts of information and randomness by means of the theory of algorithms. 
  | journal = Russian Mathematical Surveys 
  | volume = 25
  | number = 6
  | pages = 83–124 
  | year = 1970}}

[[Category:Algorithmic information theory|*]]
[[Category:Information theory|*]]
[[Category:Computability theory]]
[[Category:Theory of computation]]
[[Category:Articles containing proofs]]</text>
      <sha1>iikeioi5nwgvat3gkziin8tk585377r</sha1>
    </revision>
  </page>
  <page>
    <title>Coarse structure</title>
    <ns>0</ns>
    <id>4960605</id>
    <revision>
      <id>860063388</id>
      <parentid>860063142</parentid>
      <timestamp>2018-09-18T02:38:32Z</timestamp>
      <contributor>
        <username>Cymru.lass</username>
        <id>12407053</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/2405:204:E48A:6FA9:F84C:8E4:F26F:F890|2405:204:E48A:6FA9:F84C:8E4:F26F:F890]] ([[User talk:2405:204:E48A:6FA9:F84C:8E4:F26F:F890|talk]]) to last version by User-duck</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6235">:''"Coarse space" redirects here. For the use of "coarse space" in numerical analysis, see [[coarse problem]].''

In the [[mathematical]] fields of [[geometry]] and [[topology]], a '''coarse structure''' on a [[Set (mathematics)|set]] ''X'' is a collection of [[subset]]s of the [[cartesian product]] ''X'' × ''X'' with certain properties which allow the ''large-scale structure'' of [[metric space]]s and [[topological space]]s to be defined.

The concern of traditional geometry and topology is with the small-scale structure of the space: properties such as the [[continuous function|continuity]] of a [[function (mathematics)|function]] depend on whether the [[image (mathematics)|inverse image]]s of small [[open set]]s, or [[neighbourhood (mathematics)|neighborhoods]], are themselves open. Large-scale properties of a space&amp;mdash;such as [[bounded set|boundedness]], or the [[degrees of freedom (statistics)|degrees of freedom]] of the space&amp;mdash;do not depend on such features. ''Coarse geometry'' and ''coarse topology'' provide tools for measuring the large-scale properties of a space, and just as a [[metric (mathematics)|metric]] or a [[topology]] contains information on the small-scale structure of a space, a coarse structure contains information on its large-scale properties.

Properly, a coarse structure is not the large-scale analog of a topological structure, but of a [[Uniform space|uniform structure]].

==Definition==

A '''coarse structure''' on a [[Set (mathematics)|set]] ''X'' is a collection '''E''' of [[subset]]s of ''X'' × ''X'' (therefore falling under the more general categorization of [[binary relation]]s on ''X'') called ''controlled sets'', and so that '''E''' possesses the [[identity relation]], is closed under taking subsets, inverses, and finite unions, and is closed under [[composition of relations]]. Explicitly:

;1. Identity/diagonal: The [[diagonal]] Δ = {(''x'', ''x'') : ''x'' in ''X''} is a member of '''E'''&amp;mdash;the identity relation.
;2. Closed under taking subsets: If ''E'' is a member of '''E''' and ''F'' is a subset of ''E'', then ''F'' is a member of '''E'''.
;3. Closed under taking inverses: If ''E'' is a member of '''E''' then the '''inverse''' (or '''transpose''') ''E'' &lt;sup&gt;&amp;minus;1&lt;/sup&gt; = {(''y'', ''x'') : (''x'', ''y'') in ''E''} is a member of '''E'''&amp;mdash;the inverse relation.
;4. Closed under taking unions: If ''E'' and ''F'' are members of '''E''' then the '''[[union (set theory)|union]]''' of ''E'' and ''F'' is a member of '''E'''.
;5. Closed under composition: If ''E'' and ''F'' are members of '''E''' then the '''product''' ''E'' &lt;/small&gt;o&lt;/small&gt; ''F'' = {(''x'', ''y'') : there is a ''z'' in ''X'' such that (''x'', ''z'') is in ''E'', (''z'', ''y'') is in ''F''} is a member of '''E'''&amp;mdash;the composition of relations.

A set ''X'' endowed with a coarse structure '''E''' is a ''coarse space''.

The set ''E''[''K''] is defined as {''x'' in ''X'' : there is a ''y'' in ''K'' such that (''x'', ''y'') is in ''E''}. We define the ''section'' of ''E'' by ''x'' to be the set ''E''[{''x''}], also denoted ''E'' &lt;sub&gt;''x''&lt;/sub&gt;. The symbol ''E''&lt;sup&gt;''y''&lt;/sup&gt; denotes the set ''E'' &lt;sup&gt;&amp;minus;1&lt;/sup&gt;[{''y''}]. These are forms of [[Projection (relational algebra)|projections]].

== Intuition ==
The controlled sets are "small" sets, or "[[negligible set]]s": a set ''A'' such that ''A'' &amp;times; ''A'' is controlled is negligible, while a function ''f'' : ''X'' → ''X'' such that its graph is controlled is "close" to the identity. In the bounded coarse structure, these sets are the bounded sets, and the functions are the ones that are a finite distance from the identity in the [[uniform metric]].

==Examples==

* The ''bounded coarse structure'' on a [[metric space]] (''X'', ''d'') is the collection '''E''' of all [[subsets]] ''E'' of ''X'' × ''X'' such that sup{''d''(''x'', ''y'') : (''x'', ''y'') is in ''E''} is [[finite set|finite]].
*:With this structure, the [[integer lattice]] '''Z'''&lt;sup&gt;''n''&lt;/sup&gt; is coarsely equivalent to ''n''-dimensional [[Euclidean space]].
* A space ''X'' where ''X'' &amp;times; ''X'' is controlled is called a '''bounded space.''' Such a space is coarsely equivalent to a point. A metric space with the bounded coarse structure is bounded (as a coarse space) if and only if it is bounded (as a metric space).
* The trivial coarse structure only consists of the diagonal and its subsets.
*:In this structure, a map is a coarse equivalence if and only if it is a bijection (of sets).
* The ''C''&lt;sub&gt;0&lt;/sub&gt; ''coarse structure'' on a metric space ''X'' is the collection of all subsets ''E'' of ''X'' × ''X'' such that for all ε &gt; 0 there is a [[compact space|compact]] set ''K'' of ''X'' such that ''d''(''x'', ''y'') &lt; ε for all (''x'', ''y'') in ''E'' &amp;minus; ''K'' × ''K''. Alternatively, the collection of all subsets ''E'' of ''X'' × ''X'' such that {(''x'', ''y'') in ''E'' : ''d''(''x'', ''y'') ≥ ε} is compact.
* The ''discrete coarse structure'' on a set ''X'' consists of the [[diagonal]] together with subsets ''E'' of ''X'' × ''X'' which contain only a finite number of points (''x'', ''y'') off the diagonal.
* If ''X'' is a [[topological space]] then the ''indiscrete coarse structure'' on ''X'' consists of all ''proper'' subsets of ''X'' × ''X'', meaning all subsets ''E'' such that ''E'' [''K''] and ''E'' &lt;sup&gt;&amp;minus;1&lt;/sup&gt;[''K''] are [[relatively compact subspace|relatively compact]] whenever ''K'' is relatively compact.

==See also==

* [[uniform space]]
* [[quasi-isometry]]

==References==

* John Roe, &lt;cite&gt;Lectures in Coarse Geometry&lt;/cite&gt;, University Lecture Series Vol. 31, American Mathematical Society: Providence, Rhode Island, 2003. &lt;small&gt;[http://www.personal.psu.edu/jxr57/writings/correction.pdf Corrections to ''Lectures in Coarse Geometry'']&lt;/small&gt;
* {{ cite journal
   | last = Roe
   | first = John
   | title = What is...a Coarse Space?
   | journal = [[Notices of the American Mathematical Society]]
   |date=June–July 2006
   | volume = 53
   | issue = 6
   | pages = 669
   | url = http://www.ams.org/notices/200606/whatis-roe.pdf
   | format = [[PDF]]
   | accessdate = 2008-01-16 }}

[[Category:Metric geometry]]
[[Category:Topology]]</text>
      <sha1>ntxm8kx5r76awgm16l33x928r2zkknz</sha1>
    </revision>
  </page>
  <page>
    <title>Combinatorial species</title>
    <ns>0</ns>
    <id>160076</id>
    <revision>
      <id>868057219</id>
      <parentid>868056885</parentid>
      <timestamp>2018-11-09T18:29:58Z</timestamp>
      <contributor>
        <username>Staszek Lem</username>
        <id>12536756</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6446">{{morefootnotes|date=June 2018}}
{{expert-subject|mathematics|date=June 2018}}
In [[combinatorics|combinatorial]] [[mathematics]], the theory of '''combinatorial species''' is an abstract, systematic method for analysing discrete structures in terms of [[generating function]]s. Examples of discrete structures are ([[wiktionary:finite|finite]]) [[Graph (discrete mathematics)|graphs]], [[permutation]]s, [[Tree (graph theory)|trees]], and so on; each of these has an associated generating function which counts how many structures there are of a certain size. One goal of species theory is to be able to analyse complicated structures by describing them in terms of transformations and combinations of simpler structures. These operations correspond to equivalent manipulations of generating functions, so producing such functions for complicated structures is much easier than with other methods. The theory was introduced, carefully elaborated and applied by the Canadian group of people around [[André Joyal]].

==Definition of species==
{{unreferenced section|date=June 2018}}
[[File:Combinatorial species generic structure.svg|thumb|Schematic illustration of a combinatorial species structure on five elements by using a Labelle diagram]]

Any structure &amp;mdash; an instance of a particular species &amp;mdash; is associated with some [[Set (mathematics)|set]], and there are often many possible structures for the same set. For example, it is possible to construct several different graphs whose node labels are drawn from the same given set. At the same time, any set could be used to build the structures. The difference between one species and another is that they build a different set of structures out of the same base set.

This leads to the formal definition of a ''combinatorial species''. Let &lt;math&gt;\mathcal{B}&lt;/math&gt; be the [[category (mathematics)|category]] of [[finite set]]s, with the [[morphism]]s of the category being the [[bijection]]s between these sets. A species is a [[functor]]

:&lt;math&gt;F\colon \mathcal{B} \to \mathcal{B} \ &lt;/math&gt;

For a set ''A'' the set ''F''[''A''] is called the set of ''F''-structures on ''A'', or the set of structures of species ''F'' on ''A''. Further, by the definition of a functor, if φ is a bijection between sets ''A'' and ''B'', then ''F''[φ] is a bijection between the sets of ''F''-structures ''F''[''A''] and ''F''[''B''], called ''transport of F-structures along φ''.&lt;ref name=lasa-invi&gt;Federico G. Lastaria, [http://math.math.unipa.it/~grim/ELastaria221-230.PDF An invitation to Combinatorial Species]. (2002)&lt;/ref&gt;

For example, the "species of permutations" maps each finite set ''A'' to the set of all permutations of ''A'', and each bijection from ''A'' to another set ''B'' naturally induces a bijection from the set of all permutations of ''A'' to the set of all permutations of ''B''. Similarly, the "species of partitions" can be defined by assigning to each finite set the set of all its [[partition of a set|partition]]s, and the "power set species" assigns to each finite set its [[power set]].

There is a standard way of illustrating an instance of any structure, regardless of its nature. The adjacent diagram shows a structure on a set of five elements: arcs connect the structure (red) to the elements (blue) from which it is built.

The choice of &lt;math&gt;\mathcal{B}&lt;/math&gt; as the category on which species operate is important. Because a bijection can only exist between two sets when they have the same size, the number of elements in ''F''[''A''] depends only on the size of ''A''. (This follows from the formal definition of a functor.{{cn|date=November 2018}}) Restriction to finite sets means that |''F''[''A'']| is always finite, so it is possible to do arithmetic with such quantities. In particular, the ''exponential generating series'' ''F''(''x'') of a species ''F'' can be defined:
:&lt;math&gt;F(x) = \sum_{n \ge 0} f_n \frac{x^n}{n!}&lt;/math&gt;
where &lt;math&gt;f_n&lt;/math&gt; is the size of ''F''[''A''] for any set ''A'' having ''n'' elements.

Some examples:
* The species of sets (traditionally called ''E'', from the French "''ensemble''", meaning "set") is the functor which maps ''A'' to {''A''}. Then &lt;math&gt;f_n = 1&lt;/math&gt;, so &lt;math&gt;E(x) = e^x&lt;/math&gt;.
* The species ''S'' of permutations, described above, has &lt;math&gt;f_n = n!&lt;/math&gt;. &lt;math&gt;S(x) = 1/(1 - x)&lt;/math&gt;.
* The species ''T''&lt;sub&gt;2&lt;/sub&gt; of pairs (2-[[tuple]]s) is the functor taking a set ''A'' to ''A''&lt;sup&gt;2&lt;/sup&gt;. Then &lt;math&gt;f_n = n^2&lt;/math&gt; and &lt;math&gt;T_2(x) = x (x+1) e^x&lt;/math&gt;.

==Software==
Operations with species are supported by [[SageMath]]&lt;ref&gt;Sage documentation on [http://doc.sagemath.org/html/en/reference/combinat/sage/combinat/species/species.html combinatorial species].&lt;/ref&gt; and, using a special package, also by [[Haskell (programming language)|Haskell]].&lt;ref&gt;Haskell package [http://hackage.haskell.org/package/species species].&lt;/ref&gt;&lt;ref&gt;{{Cite journal | first = Yorgey | last = Brent A. | title = Species and functors and types, oh my! | booktitle = Haskell '10: Proceedings of the third ACM Haskell symposium on Haskell | publisher = ACM | year = 2010 | isbn = 978-1-4503-0252-4 | pages = 147–158 | doi = 10.1145/1863523.1863542}}&lt;/ref&gt;

==See also==
* [[Container (type theory)]]

==Notes==
{{Reflist}}

==References==
* André Joyal, ''Une théorie combinatoire des séries formelles'', Advances in Mathematics 42:1–82 (1981).
* Labelle, Jacques. ''Quelques espèces sur les ensembles de petite cardinalité.'', Ann. Sc. Math. Québec 9.1 (1985): 31-58.
* J. Labelle and Y.N. Yeh, ''The Relation Between Burnside Rings and Combinatorial Species'', Journal of Combinatorial Theory Series A 50, (1989) 269–284
* Yves Chiricota, ''Classification des espèces moléculaires de degré 6 et 7'',  Ann. Sci. Math. Québec 17 (1993), no. 1, 1 l–37.
* François Bergeron, Gilbert Labelle, Pierre Leroux, ''Théorie des espèces et combinatoire des structures arborescentes'', LaCIM, Montréal (1994). English version: [http://bergeron.math.uqam.ca/Species/especes.html ''Combinatorial Species and Tree-like Structures''], Cambridge University Press (1998).
* Kerber, Adalbert (1999), Applied finite group actions, Algorithms and Combinatorics, 19 (2nd ed.), Berlin, New York: Springer-Verlag, {{ISBN|978-3-540-65941-9}}, MR 1716962, OCLC 247593131

==External links==
* {{MathWorld|Species|Species}}

[[Category:Enumerative combinatorics]]
[[Category:Algebraic combinatorics]]</text>
      <sha1>lfku2cbrlylyfm6okdzv2nxua703p2v</sha1>
    </revision>
  </page>
  <page>
    <title>Cubane</title>
    <ns>0</ns>
    <id>417665</id>
    <revision>
      <id>816101002</id>
      <parentid>800169643</parentid>
      <timestamp>2017-12-19T08:03:31Z</timestamp>
      <contributor>
        <username>Rjghermsen</username>
        <id>21785112</id>
      </contributor>
      <minor/>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11025">{{chembox
| Watchedfields = changed
| verifiedrevid = 443545029
| Name = '''Cubane'''
| ImageFileL1 = Cuban.svg
| ImageNameL1 = Structural formula of cubane
| ImageFileR1 = Cubane molecule ball.png
| ImageNameR1 = Ball-and-stick model of cubane
| PIN = Cubane&lt;ref name=iupac2013&gt;{{cite book | title =  Nomenclature of Organic Chemistry : IUPAC Recommendations and Preferred Names 2013 (Blue Book) | publisher = [[Royal Society of Chemistry|The Royal Society of Chemistry]] | date = 2014 | location = Cambridge | page = 169 | doi = 10.1039/9781849733069-FP001 | isbn = 978-0-85404-182-4 | quote = The retained names adamantane and cubane are used in general nomenclature and as preferred IUPAC names.}}&lt;/ref&gt;
| SystematicName = Pentacyclo[4.2.0.0&lt;sup&gt;2,5&lt;/sup&gt;.0&lt;sup&gt;3,8&lt;/sup&gt;.0&lt;sup&gt;4,7&lt;/sup&gt;]octane
| OtherNames = 
|Section1={{Chembox Identifiers
| ChemSpiderID_Ref = {{chemspidercite|correct|chemspider}}
| ChemSpiderID = 119867
| PubChem = 136090
| InChIKey = TXWRERCHRDBNLG-UHFFFAOYAL
| StdInChI_Ref = {{stdinchicite|correct|chemspider}}
| StdInChI = 1S/C8H8/c1-2-5-3(1)7-4(1)6(2)8(5)7/h1-8H
| StdInChIKey_Ref = {{stdinchicite|correct|chemspider}}
| StdInChIKey = TXWRERCHRDBNLG-UHFFFAOYSA-N
| CASNo_Ref = {{cascite|correct|??}}
| CASNo = 277-10-1
| ChEBI_Ref = {{ebicite|correct|EBI}}
| ChEBI = 33014
| SMILES = C12C3C4C1C5C2C3C45
| InChI = 1/C8H8/c1-2-5-3(1)7-4(1)6(2)8(5)7/h1-8H
  }}
|Section2={{Chembox Properties
| Formula = C&lt;sub&gt;8&lt;/sub&gt;H&lt;sub&gt;8&lt;/sub&gt;
| MolarMass = 104.15 g/mol
| Density = 1.29 g/cm&lt;sup&gt;3&lt;/sup&gt;
| MeltingPtC = 133.5 
| MeltingPt_ref = &lt;ref name = Biegasiewicz /&gt;
| BoilingPtC = 161.6
| BoilingPt_ref = &lt;ref name= Biegasiewicz /&gt;
  }}
|Section8={{Chembox Related
| OtherFunction = [[Cuneane]]&lt;br /&gt;[[Dodecahedrane]]&lt;br /&gt;[[Tetrahedrane]]&lt;br /&gt;[[Prismane]]&lt;br /&gt;[[Prismane C8]]
| OtherFunction_label = [[hydrocarbon]]s
| OtherCompounds = [[Heptanitrocubane]]&lt;br /&gt;[[Octanitrocubane]]&lt;br /&gt;[[Octaazacubane]]
  }}
}}
'''Cubane''' (C&lt;sub&gt;8&lt;/sub&gt;H&lt;sub&gt;8&lt;/sub&gt;) is a synthetic [[hydrocarbon]] [[molecule]] that consists of eight [[carbon]] [[atom]]s arranged at the corners of a [[Cube (geometry)|cube]], with one [[hydrogen]] atom attached to each carbon atom. A solid [[crystal]]line substance, cubane is one of the [[Platonic hydrocarbon]]s and a member of the [[prismanes]]. It was first synthesized in 1964 by [[Philip Eaton]] and Thomas Cole.&lt;ref name="eaton-1964" /&gt; Before this work, researchers believed that cubic carbon-based molecules would be too unstable to exist. The cubic shape requires the carbon atoms to adopt an unusually sharp 90° bonding angle, which would be highly [[strain (chemistry)|strained]] as compared to the 109.45° angle of a [[tetrahedral geometry|tetrahedral]] carbon. Once formed, cubane is quite [[kinetic stability|kinetically stable]], due to a lack of readily available decomposition paths. It is the simplest hydrocarbon with [[octahedral symmetry]].

Having high energy but kinetic stability makes cubane and its derivative compounds useful for controlled energy storage. For example, [[octanitrocubane]] and [[heptanitrocubane]] have been studied as high-performance explosives.

These compounds also typically have a very high [[density]] for hydrocarbon molecules. The resulting high [[energy density]] means a large amount of energy can be stored in a comparably small amount of space, an important consideration for applications in fuel storage and energy transport.

==Synthesis==
The classic 1964 synthesis starts with the conversion of [[2-cyclopentenone]] to 2-bromo[[cyclopentadienone]]:&lt;ref name="eaton-1964"/&gt;&lt;ref name=eaton1964 /&gt;

:[[File:Cyclopentenone to 2-bromocyclopentadienone.png|500px]]

[[Allylic]] [[bromination]] with [[N-Bromosuccinimide|''N''-bromosuccinimide]] in [[carbon tetrachloride]] followed by addition of molecular bromine to the [[alkene]] gives a 2,3,4-tribromocyclopentanone. Treating this compound with [[diethylamine]] in [[diethyl ether]] causes [[elimination reaction|elimination]] of two equivalents of [[hydrogen bromide]] to give the diene product.

:[[Image:CubaneSynthesis.png|thumb|left|500px|Eaton's 1964 synthesis of cubane]]{{clear left}}

The construction of the eight-carbon cubane framework begins when 2-bromocyclopentadienone undergoes a spontaneous [[Diels-Alder reaction|Diels-Alder dimerization]], analogous to the dimerization of [[cyclopentadiene]] to [[dicyclopentadiene]]—two molecules of '''1''' react to form '''2'''. For the subsequent steps to succeed, only the [[Endo-exo isomerism|''endo'' isomer]] is useful, and this is the predominant isomer formed in this reaction. This is the most likely product as a result of minimized [[steric]] interactions between the bromine of each molecule with the bromine and [[carbonyl]] of the other when the reactants approach each other and minimized like-dipole interactions in the [[transition state]] of the reaction itself. Both carbonyl groups are [[protecting group|protected]] as [[acetal]]s with [[ethylene glycol]] and [[P-Toluenesulfonic acid|''p''-toluenesulfonic acid]] in [[benzene]]; one acetal is then selectively deprotected with aqueous [[hydrochloric acid]] to '''3'''.

In the next step, the ''endo'' isomer '''3''' (with both [[alkene]] groups in close proximity) forms the cage-like isomer '''4''' in  a [[photochemical]] [2+2] [[cycloaddition]]. The [[haloketone|bromoketone]] group is converted to ring-contracted [[carboxylic acid]] '''5''' in a [[Favorskii rearrangement]] with [[potassium hydroxide]]. Next, the thermal [[decarboxylation]] takes place through the [[acid chloride]] (with [[thionyl chloride]]) and the [[tert-butyl|''tert''-butyl]] [[perester]] '''6''' (with [[Tert-Butyl hydroperoxide|''tert''-butyl hydroperoxide]] and [[pyridine]]) to '''7'''; afterward, the acetal is once more removed in '''8'''. A second Favorskii rearrangement gives '''9''', and finally another decarboxylation gives, via '''10''', cubane ('''11''').

==Derivatives==
{{see also|Cubane-type cluster}}
The synthesis of the octaphenyl [[derivative (chemistry)|derivative]] from tetraphenylcyclobutadiene nickel bromide by Freedman in 1962 pre-dates that of the parent compound. It is a sparingly soluble colourless compound that melts at 425–427&amp;nbsp;°C.&lt;ref name= Biegasiewicz /&gt;&lt;ref name=freedman1961 /&gt;&lt;ref name=freedman1962 /&gt;&lt;ref name=freedman1965 /&gt;  A [[hypercubane]], with a [[hypercube]]-like structure,  was predicted to exist in a 2014 publication.&lt;ref&gt;{{cite journal|last=Pichierri|first=F.|journal=Chem. Phys. Lett.|date=2014|volume=612|pages=198–202|doi=10.1016/j.cplett.2014.08.032|title= Hypercubane: DFT-based prediction of an ''O&lt;sub&gt;h&lt;/sub&gt;''-symmetric double-shell hydrocarbon}}&lt;/ref&gt;&lt;ref&gt;http://www.compchemhighlights.org/2014/12/hypercubane-dft-based-prediction-of-oh.html&lt;/ref&gt; Two different isomers of [[cubene]] have been synthesized, and a third analyzed [[computational chemistry|computationally]]. The alkene in ''ortho''-cubene is exceptionally reactive due to its [[pyramidalization|pyramidalized geometry]]. At the time of its synthesis, this was the most pyramidalized alkene to have been successfully made.&lt;ref&gt;{{cite journal |title= Cubene (1,2-dehydrocubane) |first1= Philip E. |last1= Eaton |first2= Michele |last2= Maggini |journal= J. Am. Chem. Soc. |year= 1988 |volume= 110 |issue= 21 |pages= 7230–7232 |doi= 10.1021/ja00229a057 }}&lt;/ref&gt; The ''meta''-cubene isomer is even less stable, and the ''para''-cubene isomer probably only exists as a [[diradical]] rather than an actual diagonal bond.&lt;ref&gt;{{cite book |title= Strained Hydrocarbons |editor-first= Helena |editor-last= Dodziuk |chapter= 2.3 A Theoretical Approach to the Study and Design of Prismane Systems |first1= Ruslan M. |last1= Minyaev |first2= Vladimir I. |last2= Minkin |first3= Tatyana N. |last3= Gribanova |publisher= Wiley |year= 2009 |isbn= 9783527627141 |page= 55 }}&lt;/ref&gt;&lt;!-- not sure how to format this; want to reference the section/page of relevance, but it's in a collected work that already consumes the book's overall ed/title and chapter's author/title --&gt;

==Reactions==
[[Cuneane]] may be produced from cubane by a [[metal-ion-catalyzed σ-bond rearrangement]].&lt;ref name=March /&gt;&lt;ref name=kindler /&gt;

==See also==
*[[Basketane]]
*[[Hypercubane]]
*[[Octanitrocubane]]
*[[Heptanitrocubane]]

==References==
{{reflist|colwidth=30em
 |refs=
&lt;ref name= Biegasiewicz &gt;{{cite journal| last1 = Biegasiewicz | first1 = Kyle | last2 = Griffiths | first2 = Justin | last3 = Savage | first3 = G. Paul | last4 = Tsanakstidis | first4 = John | last5 = Priefer | first5 = Ronny | year = 2015 | title = Cubane: 50 years later | journal = Chemical Reviews| volume = 115 | pages = 6719–6745 | doi=10.1021/cr500523x | pmid=26102302}}&lt;/ref&gt; 
&lt;ref name="eaton-1964"&gt;{{cite journal|title=Cubane|first1=Philip E.|last1=Eaton|first2=Thomas W.|last2=Cole|journal=[[J. Am. Chem. Soc.]]|date=1964|volume=86|issue=15|pages=3157–3158|DOI=10.1021/ja01069a041}}&lt;/ref&gt;
&lt;ref name=eaton1964 &gt;{{cite journal|title=The Cubane System|first1=Philip E.|last1=Eaton|first2=Thomas W.|last2=Cole|journal=[[J. Am. Chem. Soc.]]|date=1964|volume=86|issue=5|pages=962–964|DOI=10.1021/ja01059a072}}&lt;/ref&gt;
&lt;ref name=March&gt;{{cite book|first1=Michael B.|last1=Smith|first2=Jerry|last2=March|title=March’s Advanced Organic Chemistry|edition=5th|publisher=John Wiley &amp; Sons|date=2001|page=1459|ISBN=0-471-58589-0}}&lt;/ref&gt;
&lt;ref name=kindler&gt;{{cite journal|title=Studien über den Mechanismus chemischer Reaktionen, XXIII. Hydrierungen von Nitrilen unter Verwendung von Terpenen als Wasserstoffdonatoren|first1=K.|last1=Kindler|first2=K.|last2=Lührs|journal=[[Chem. Ber.]]|volume=99|date=1966|pages=227–232|DOI=10.1002/cber.19660990135}}&lt;/ref&gt;
&lt;ref name=freedman1961&gt;{{cite journal|title=Tetraphenylcyclobutadiene Derivatives. II.1 Chemical Evidence for the Triplet State|first=H. H.|last=Freedman|journal=[[J. Am. Chem. Soc.]]|date=1961|volume=83|issue=9|pages=2195–2196|DOI=10.1021/ja01470a037}}&lt;/ref&gt;
&lt;ref name=freedman1962&gt;{{cite journal|title=Tetraphenylcyclobutadiene Derivatives. IV.1 "Octaphenylcubane"; A Dimer of Tetraphenylcyclobutadiene|first=H. H.|last=Freedman|first2=D. R.|last2=Petersen|journal=[[J. Am. Chem. Soc.]]|date=1962|volume=84|issue=14|pages=2837–2838|DOI=10.1021/ja00873a046}}&lt;/ref&gt;
&lt;ref name=freedman1965&gt;{{cite journal|title=Structure of the Dimer of tetraphenylcyclobutadiene|first1=G. S.|last1=Pawley|first2=W. N.|last2=Lipscomb|first3=H. H.|last3=Freedman|journal=[[J. Am. Chem. Soc.]]|date=1964|volume=86|issue=21|pages=4725–4726|DOI=10.1021/ja01075a042}}&lt;/ref&gt;
}}

==External links==
* [http://www.synarchive.com/syn/14 Eaton's cubane synthesis at SynArchive.com]
* [http://www.synarchive.com/syn/189 Tsanaktsidis's cubane synthesis at SynArchive.com]
* [http://www.ch.ic.ac.uk/local/projects/b_muir/Cubane/Cubanepro/Start.html Cubane chemistry at Imperial College London]

[[Category:Polycyclic nonaromatic hydrocarbons]]
[[Category:Molecular geometry]]
[[Category:Theoretical chemistry]]
[[Category:Cyclobutanes]]</text>
      <sha1>dgrw0quhgm2jyubdqb29qawc7uq0nfc</sha1>
    </revision>
  </page>
  <page>
    <title>DPLL algorithm</title>
    <ns>0</ns>
    <id>2745094</id>
    <revision>
      <id>836763597</id>
      <parentid>834359365</parentid>
      <timestamp>2018-04-16T18:18:42Z</timestamp>
      <contributor>
        <username>MaxEnt</username>
        <id>1190064</id>
      </contributor>
      <comment>satisfy specific Putnam; Wikipedia prefers straight quotes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12789">In [[computer science]], the '''Davis–Putnam–Logemann–Loveland''' ('''DPLL''') '''algorithm''' is a complete, [[backtracking]]-based [[search algorithm]] for [[Boolean satisfiability problem|deciding the satisfiability]] of [[propositional logic|propositional logic formulae]] in [[conjunctive normal form]], i.e. for solving the [[Boolean satisfiability problem|CNF-SAT]] problem.

It was introduced in 1962 by [[Martin Davis]], [[George Logemann]] and [[Donald W. Loveland]] and is a refinement of the earlier [[Davis–Putnam algorithm]], which is a [[Resolution (logic)|resolution]]-based procedure developed by Davis and [[Hilary Putnam]] in 1960. Especially in older publications, the Davis–Logemann–Loveland algorithm is often referred to as the "Davis–Putnam method" or the "DP algorithm". Other common names that maintain the distinction are DLL and DPLL.

After more than 50 years the DPLL procedure still forms the basis for most efficient complete SAT solvers. It has recently been extended for [[automated theorem proving]] for fragments of [[first-order logic]].&lt;ref&gt;
{{Citation|contribution=Abstract DPLL and Abstract DPLL Modulo Theories
|first1=Robert
|last1=Nieuwenhuis
|first2=Albert
|last2=Oliveras
|first3=Cesar
|last3=Tinelli
|year=2004
|pages=36–50
|title=Proceedings Int. Conf. on [[Logic for Programming, Artificial Intelligence, and Reasoning]], LPAR 2004
|contributionurl=http://www.lsi.upc.edu/~roberto/papers/lpar04.pdf
}}&lt;/ref&gt;

{{Infobox algorithm
|name=DPLL
|image=[[File:Backtracking-no-backjumping.svg]]
|class=[[Boolean satisfiability problem]]
|data=
|time=&lt;math&gt;O(2^n)&lt;/math&gt;
|space=&lt;math&gt;O(n)&lt;/math&gt; (basic algorithm)
}}

== Implementations and applications ==
The [[Boolean satisfiability problem|SAT problem]] is important both from theoretical and practical points of view. In [[Computational complexity theory|complexity theory]] it was the first problem proved to be [[NP-complete]], and can appear in a broad variety of applications such as ''[[model checking]]'', [[automated planning and scheduling]], and [[diagnosis (artificial intelligence)|diagnosis in artificial intelligence]].

As such, it has been a hot topic in research for many years, and competitions between [[SAT solver]]s regularly take place.&lt;ref&gt;
{{Citation|url=http://www.satcompetition.org/|title=The international SAT Competitions web page|publisher=sat! live}}&lt;/ref&gt; DPLL's modern implementations like [[zChaff|Chaff and zChaff]],&lt;ref&gt;
{{Citation|url=http://www.princeton.edu/~chaff/zchaff.html|title=zChaff website}}&lt;/ref&gt;&lt;ref&gt;
{{Citation|url=http://www.princeton.edu/~chaff/|title=Chaff website}}
&lt;/ref&gt; [[GRASP (SAT solver)|GRASP]] or Minisat&lt;ref&gt;
{{Cite web|url=http://minisat.se/|title=Minisat website}}
&lt;/ref&gt; are in the first places of the competitions these last years.{{when|date=January 2017}}

Another application that often involves DPLL is [[automated theorem proving]] or [[satisfiability modulo theories]] (SMT), which is a SAT problem in which [[propositional variable]]s are replaced with formulas of another [[mathematical theory]].

==The algorithm==

The basic backtracking algorithm runs by choosing a literal, assigning a [[truth value]] to it, simplifying the formula and then recursively checking if the simplified formula is satisfiable; if this is the case, the original formula is satisfiable; otherwise, the same recursive check is done assuming the opposite truth value. This is known as the ''splitting rule'', as it splits the problem into two simpler sub-problems. The simplification step  essentially removes all clauses that become true under the assignment from the formula, and all literals that become false from the remaining clauses.

The DPLL algorithm enhances over the backtracking algorithm by the eager use of the following rules at each step:

; [[Unit propagation]] : If a clause is a ''unit clause'', i.e. it contains only a single unassigned literal, this clause can only be satisfied by assigning the necessary value to make this literal true. Thus, no choice is necessary. In practice, this often leads to deterministic cascades of units, thus avoiding a large part of the naive search space.

; Pure literal elimination : If a [[propositional variable]] occurs with only one polarity in the formula, it is called ''pure''. Pure literals can always be assigned in a way that makes all clauses containing them true. Thus, these clauses do not constrain the search anymore and can be deleted.

Unsatisfiability of a given partial assignment is  detected if one clause becomes empty, i.e. if all its variables have been assigned in a way that makes the corresponding literals false. Satisfiability of the formula is detected either when all variables are assigned without generating the empty clause, or, in modern implementations, if all clauses are satisfied. Unsatisfiability of the complete formula can only be detected after exhaustive search.

The DPLL algorithm can be summarized in the following pseudocode, where Φ is the [[Conjunctive_normal_form|CNF]] formula:

{{Algorithm-begin|name=DPLL}}
   Input: A set of clauses Φ.
   Output: A Truth Value.

 '''function''' DPLL(Φ)
    '''if''' Φ is a consistent set of literals
        '''then''' '''return''' true;
    '''if''' Φ contains an empty clause
        '''then''' '''return''' false;
    '''for every''' unit clause ''{l}'' '''in''' Φ
       Φ ← ''unit-propagate''(''l'', Φ);
    '''for every''' literal ''l'' that occurs pure '''in''' Φ
       Φ ← ''pure-literal-assign''(''l'', Φ);
    ''l'' ← ''choose-literal''(Φ);
    '''return''' ''DPLL''(Φ '''∧''' {l}) '''or''' ''DPLL''(Φ '''∧''' {not(l)});
{{Algorithm-end}}
In this pseudocode, &lt;code&gt;unit-propagate(l, Φ)&lt;/code&gt; and &lt;code&gt;pure-literal-assign(l, Φ)&lt;/code&gt; are functions that return the result of applying unit propagation and the pure literal rule, respectively, to the literal &lt;code&gt;l&lt;/code&gt; and the formula &lt;code&gt;Φ&lt;/code&gt;. In other words, they replace every occurrence of &lt;code&gt;l&lt;/code&gt; with "true" and every occurrence of &lt;code&gt;not l&lt;/code&gt; with "false" in the formula &lt;code&gt;Φ&lt;/code&gt;, and simplify the resulting formula. 
The &lt;code&gt;'''or'''&lt;/code&gt; in the &lt;code&gt;'''return'''&lt;/code&gt; statement is a [[short-circuiting operator]]. &lt;code&gt;Φ '''∧''' {l}&lt;/code&gt; denotes the simplified result of substituting "true" for &lt;code&gt;l&lt;/code&gt; in &lt;code&gt;Φ&lt;/code&gt;.

The pseudocode DPLL function only returns whether the final assignment satisfies the formula or not. In a real implementation, the partial satisfying assignment typically is also returned on success; this can be derived from the consistent set of literals of the first &lt;code&gt;if&lt;/code&gt; statement of the function.

The Davis–Logemann–Loveland algorithm depends on the choice of ''branching literal'', which is the literal considered in the backtracking step. As a result, this is not exactly an algorithm, but rather a family of algorithms, one for each possible way of choosing the branching literal. Efficiency is strongly affected by the choice of the branching literal: there exist instances for which the running time is constant or exponential depending on the choice of the branching literals. Such choice functions  are also called [[heuristic function]]s or branching heuristics.&lt;ref&gt;{{Cite book | last1 = Marques-Silva | first1 = João P.| chapter = The Impact of Branching Heuristics in Propositional Satisfiability Algorithms | doi = 10.1007/3-540-48159-1_5 | title = Progress in Artificial Intelligence: 9th Portuguese Conference on Artificial Intelligence, EPIA '99 Évora, Portugal, September 21–24, 1999 Proceedings | editor1-first = Pedro | editor1-last = Barahona | editor2-first = José J. | editor2-last = Alferes| series = [[Lecture Notes in Computer Science|LNCS]] | volume = 1695 | pages = 62–63 | year = 1999 | isbn = 978-3-540-66548-9 | pmid =  | pmc = }}&lt;/ref&gt;

===Visualization===

Davis, Logemann, Loveland (1962) had developed this algorithm.
Some properties of this original algorithm are:
::::* It is based on search.
::::* It is the basis for almost all modern SAT solvers.
::::* It DOES NOT use learning and non-chronological backtracking (introduced in 1996).
An example with visualization of a DPLL algorithm having chronological backtracking:
&lt;gallery&gt;
Image:Dpll1.png|All clauses making a CNF formula
Image:Dpll2.png|Pick a variable
Image:Dpll3.png|Make a decision, variable a = False (0), thus green clauses becomes True
Image:Dpll4.png|After making several decisions, we find an [[implication graph]] that leads to a conflict.
Image:Dpll5.png|Now backtrack to immediate level and by force assign opposite value to that variable
Image:Dpll6.png|But a forced decision still leads to another conflict
Image:Dpll7.png|Backtrack to previous level and make a forced decision
Image:Dpll8.png|Make a new decision, but it leads to a conflict
Image:Dpll9.png|Make a forced decision, but again it leads to a conflict
Image:Dpll10.png|Backtrack to previous level
Image:Dpll11.png|Continue in this way and the final implication graph
&lt;/gallery&gt;

==Current work==

In the 2010s years, work on improving the algorithm has been done on three directions: 
# Defining different policies for choosing the branching literals.
# Defining new data structures to make the algorithm faster, especially the part on '''unit propagation'''
# Defining variants of the basic backtracking algorithm. The latter direction include ''non-chronological backtracking'' (aka ''[[backjumping]]'') and ''[[Conflict-Driven Clause Learning|clause learning]]''. These refinements describe a method of backtracking after reaching a conflict clause which "learns" the root causes (assignments to variables) of the conflict in order to avoid reaching the same conflict again. The resulting [[Conflict-Driven Clause Learning]] SAT solvers are the state of the art in 2014.{{citation needed|date=December 2015}}

A newer algorithm from 1990 is [[Stålmarck's method]]. Also since 1986 (reduced ordered) [[binary decision diagram]]s have also been used for SAT solving.

== Relation to other notions ==
Runs of DPLL-based algorithms on unsatisfiable instances correspond to tree [[Resolution (logic)|resolution]] refutation proofs.&lt;ref name="RossiBeek2006"&gt;{{cite book|editor1-first=Francesca|editor1-last=Rossi|editor2-first=Peter|editor2-last=Van Beek|editor3-first=Toby|editor3-last=Walsh|title=Handbook of constraint programming|url=https://books.google.com/books?id=Kjap9ZWcKOoC&amp;pg=PA122|year=2006|publisher=Elsevier|isbn=978-0-444-52726-4|page=122|first=Peter|last=Van Beek|chapter=Backtracking search algorithms}}&lt;/ref&gt;

==See also==
*[[Davis–Putnam algorithm]]
*[[Chaff algorithm]]
*[[Proof complexity]]
*[[Herbrandization]]

==References==
{{commons category|Davis-Putnam-Logemann-Loveland algorithm}}
'''General'''
* {{cite journal
|last=Davis
|first=Martin
| authorlink= Martin Davis
|author2=Putnam, Hilary |authorlink2=Hilary Putnam 
| title=A Computing Procedure for Quantification Theory
| journal =[[Journal of the ACM]]
| volume = 7
| issue = 3
| pages = 201–215
| year = 1960
| url = http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=321034
| doi=10.1145/321033.321034}}
*{{cite journal
| last=Davis
| first=Martin |author2=Logemann, George |author3=Loveland, Donald
| title=A Machine Program for Theorem Proving
| journal =[[Communications of the ACM]]
| volume=5
| issue=7
| pages = 394–397
| year=1962
| url=https://archive.org/details/machineprogramfo00davi
| doi=10.1145/368273.368557}}
*{{cite journal
| first=Ming
| last=Ouyang
| title=How Good Are Branching Rules in DPLL?
| journal=Discrete Applied Mathematics
| volume=89
| issue=1–3
| pages=281–286
| year=1998
| doi=10.1016/S0166-218X(98)00045-6}}
* {{cite book|author=John Harrison|title=Handbook of practical logic and automated reasoning|year=2009|publisher=Cambridge University Press|isbn=978-0-521-89957-4|pages=79–90}}

'''Specific'''
{{reflist}}

== Further reading ==
* {{cite book|author1=Malay Ganai|author2=Aarti Gupta|author3=Dr. Aarti Gupta|title=SAT-based scalable formal verification solutions|year=2007|publisher=Springer|isbn=978-0-387-69166-4|pages=23–32}}
* {{cite book|editor1-first=Frank|editor1-last=Van Harmelen|editor2-first=Vladimir|editor2-last=Lifschitz|editor3-first=Bruce|editor3-last=Porter|title=Handbook of knowledge representation|year=2008|publisher=Elsevier|isbn=978-0-444-52211-5|pages=89–134|first1=Carla P.|last1=Gomes|first2=Henry|last2=Kautz|first3= Ashish|last3=Sabharwal|first4=Bart|last4=Selman|chapter=Satisfiability Solvers|doi=10.1016/S1574-6526(07)03002-7|series=Foundations of Artificial Intelligence|volume=3}}

[[Category:Constraint programming]]
[[Category:Automated theorem proving]]
[[Category:SAT solvers]]
[[Category:Articles with example pseudocode]]</text>
      <sha1>580u7e8a9rxv6mwj229t42whqz6107z</sha1>
    </revision>
  </page>
  <page>
    <title>Differential topology</title>
    <ns>0</ns>
    <id>8562</id>
    <revision>
      <id>859700106</id>
      <parentid>829449277</parentid>
      <timestamp>2018-09-15T18:37:34Z</timestamp>
      <contributor>
        <username>Adraria</username>
        <id>27430108</id>
      </contributor>
      <comment>/* Differential topology versus differential geometry */Made the sentence inclusive of potential nonbinary or robotic differential topologists.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7963">In [[mathematics]], '''differential topology''' is the field dealing with [[differentiable function]]s on [[differentiable manifold]]s. It is closely related to [[differential geometry]] and together they make up the geometric theory of differentiable [[manifolds]].

== Description ==

Differential topology considers the properties and structures that require only a [[smooth structure]] on a manifold to be defined.  Smooth manifolds are 'softer' than manifolds with extra geometric structures, which can act as obstructions to certain types of equivalences and [[Deformation theory|deformations]] that exist in differential topology. For instance, volume and [[Riemannian curvature]] are [[Invariant (mathematics)|invariants]] that can distinguish different geometric structures on the same smooth manifold&amp;mdash;that is, one can smoothly "flatten out" certain manifolds, but it might require distorting the space and affecting the curvature or volume.

On the other hand, smooth manifolds are more rigid than the [[topological manifold]]s. [[John Milnor]] discovered that some spheres have more than one smooth structure—see [[exotic sphere]] and [[Donaldson's theorem]].  [[Kervaire]] exhibited topological manifolds with no smooth structure at all.&lt;ref name="Kervaire"&gt;{{harvnb|Kervaire|1960}}&lt;/ref&gt; Some constructions of smooth manifold theory, such as the existence of tangent bundles,&lt;ref name="lashof"&gt;{{harvnb|Lashof|1972}}&lt;/ref&gt; can be done in the topological setting with much more work, and others cannot.

One of the main topics in differential topology is the study of special kinds of smooth mappings between manifolds, namely [[immersion (mathematics)|immersions]] and [[submersion (mathematics)|submersions]], and the intersections of submanifolds via [[transversality (mathematics)|transversality]]. More generally one is interested in properties and invariants of smooth manifolds which are carried over by [[diffeomorphisms]], another special kind of smooth mapping. [[Morse theory]] is another branch of differential topology, in which topological information about a manifold is deduced from changes in the [[rank (differential topology)|rank]] of the [[Jacobian matrix and determinant|Jacobian]] of a function.

For a list of differential topology topics, see the following reference: [[List of differential geometry topics]].

== Differential topology versus differential geometry ==
{{details|geometry and topology}}
Differential topology and differential geometry are first characterized by their ''similarity''.  They both study primarily the properties of differentiable manifolds, sometimes with a variety of structures imposed on them.

One major difference lies in the nature of the problems that each subject tries to address.  In one view,&lt;ref&gt;{{harvnb|Hirsch|1997}}&lt;/ref&gt; differential topology distinguishes itself from differential geometry by studying primarily those problems which are ''inherently global''.
Consider the example of a coffee cup and a donut (see &lt;span class="plainlinks"&gt;[http://upload.wikimedia.org/wikipedia/commons/2/26/Mug_and_Torus_morph.gif this example]&lt;/span&gt;).  From the point of view of differential topology, the donut and the coffee cup are ''the same'' (in a sense). This is an inherently global view, though, because there is no way for the differential topologist to tell whether the two objects are the same (in this sense) by looking at just a tiny (''local'') piece of either of them.  They must have access to each entire (''global'') object.

From the point of view of differential geometry, the coffee cup and the donut are ''different'' because it is impossible to rotate the coffee cup in such a way that its configuration matches that of the donut.  This is also a global way of thinking about the problem.  But an important distinction is that the geometer does not need the entire object to decide this.  By looking, for instance, at just a tiny piece of the handle, he can decide that the coffee cup is different from the donut because the handle is thinner (or more curved) than any piece of the donut.

To put it succinctly, differential topology studies structures on manifolds which, in a sense, have no interesting local structure.  Differential geometry studies structures on manifolds which do have an interesting local (or sometimes even infinitesimal) structure.

More mathematically, for example, the problem of constructing a [[diffeomorphism]] between two manifolds of the same dimension is inherently global since ''locally'' two such manifolds are always diffeomorphic.  Likewise, the problem of computing a quantity on a manifold which is invariant under differentiable mappings is inherently global, since any local invariant will be ''trivial'' in the sense that it is already exhibited in the topology of '''R'''&lt;sup&gt;n&lt;/sup&gt;.  Moreover, differential topology does not restrict itself necessarily to the study of diffeomorphism.  For example, [[symplectic topology]]—a subbranch of differential topology—studies global properties of [[symplectic manifold]]s.  Differential geometry concerns itself with problems—which may be local ''or'' global—that always have some non-trivial local properties.  Thus differential geometry may study differentiable manifolds equipped with a ''[[connection (mathematics)|connection]]'', a ''[[Metric (mathematics)|metric]]'' (which may be [[Riemannian metric|Riemannian]], [[pseudo-Riemannian metric|pseudo-Riemannian]], or [[Finsler metric|Finsler]]), a special sort of ''[[Frobenius integration theorem|distribution]]'' (such as a [[CR structure]]), and so on.

This distinction between differential geometry and differential topology is blurred, however, in questions specifically pertaining to local diffeomorphism invariants such as the [[tangent space]] at a point.  Differential topology also deals with questions like these, which specifically pertain to the properties of differentiable mappings on '''R'''&lt;sup&gt;n&lt;/sup&gt; (for example the [[tangent bundle]], [[jet (mathematics)|jet bundles]], the [[Whitney extension theorem]], and so forth).

The distinction is concise in abstract terms: 
*Differential topology is the study of the (infinitesimal, local, and global) properties of structures on manifolds that have ''only trivial'' [[Moduli space|local moduli]]
*Differential geometry is such a study of structures on manifolds that have one or more ''non-trivial'' local moduli.

== See also ==
* [[List of differential geometry topics]]
* [[Glossary of differential geometry and topology]]
* [[List of publications in mathematics#Differential geometry|Important publications in differential geometry]]
* [[List of publications in mathematics#Differential topology|Important publications in differential topology]]
* [[Basic introduction to the mathematics of curved spacetime]]

==Notes==
&lt;references/&gt;

== References ==
*{{cite book | ref=harv|title = A First Course in Geometric Topology and Differential Geometry|first = Ethan D.|last = Bloch | year = 1996 |location=Boston |publisher=Birkhäuser |isbn=0-8176-3840-7 }}
*{{cite book | ref=harv|title = Differential Topology|authorlink=Morris Hirsch|first = Morris|last = Hirsch|publisher=Springer-Verlag|year=1997|isbn = 0-387-90148-5}}
*{{cite journal|ref=harv|last=Lashof|first=Richard|authorlink=Richard Lashof|title=The Tangent Bundle of a Topological Manifold|journal=The American Mathematical Monthly|date=Dec 1972|volume=79|issue=10|pages=1090–1096|jstor=2317423|doi=10.2307/2317423}}
*{{cite journal|ref=harv|last=Kervaire|first=Michel A.|authorlink=Michel Kervaire|title=A manifold which does not admit any differentiable structure|journal=Commentarii Mathematici Helvetici|date=Dec 1960|volume=34|issue=1|pages=257–270|doi=10.1007/BF02565940|url=https://dx.doi.org/10.1007/BF02565940}}

== External links ==
* {{Springer |title=Differential topology |id=p/d032290}}

{{Topology}}

{{Authority control}}

[[Category:Differential topology| ]]</text>
      <sha1>fwn8wno0v1kw5g59ulck0cius5par5e</sha1>
    </revision>
  </page>
  <page>
    <title>Dirichlet space</title>
    <ns>0</ns>
    <id>34043560</id>
    <revision>
      <id>746159834</id>
      <parentid>673815008</parentid>
      <timestamp>2016-10-25T16:43:44Z</timestamp>
      <contributor>
        <username>Fixer88</username>
        <id>9945971</id>
      </contributor>
      <comment>Disambiguated: [[norm]] → [[norm (mathematics)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4017">In [[mathematics]], the '''Dirichlet space''' on the domain  &lt;math&gt;\Omega \subseteq \mathbb{C}, \, \mathcal{D}(\Omega)&lt;/math&gt; (named after [[Peter Gustav Lejeune Dirichlet]]), is the [[reproducing kernel Hilbert space]] of [[holomorphic function]]s, contained within the [[Hardy space]] &lt;math&gt;H^2(\Omega)&lt;/math&gt;,  for which the ''Dirichlet integral'', defined by

:&lt;math&gt; \mathcal{D}(f) := {1\over \pi} \iint_\Omega |f^\prime(z)|^2 \, dA = {1\over 4\pi}\iint_\Omega |\partial_x f|^2 + |\partial_y f|^2 \, dx \, dy &lt;/math&gt;

is finite (here ''dA'' denotes the area Lebesgue measure on the complex plane &lt;math&gt;\mathbb{C}&lt;/math&gt;). The latter is the integral occurring in [[Dirichlet's principle]] for [[harmonic functions]]. The Dirichlet integral defines a [[seminorm]] on &lt;math&gt;\mathcal{D}(\Omega)&lt;/math&gt;. It is not a [[norm (mathematics)|norm]] in general, since &lt;math&gt;\mathcal{D}(f) = 0&lt;/math&gt; whenever ''f'' is a [[constant function]].

For &lt;math&gt;f,\, g \in \mathcal{D}(\Omega)&lt;/math&gt;, we define

:&lt;math&gt;\mathcal{D}(f, \, g) : = {1\over \pi} \iint_\Omega f'(z) \overline{g'(z)} \, dA(z).&lt;/math&gt;

This is a semi-inner product, and clearly &lt;math&gt;\mathcal{D}(f, \, f) = \mathcal{D}(f)&lt;/math&gt;. We may equip &lt;math&gt;\mathcal{D}(\Omega)&lt;/math&gt; with an [[inner product]] given by

:&lt;math&gt; \langle f, g \rangle_{\mathcal{D}(\Omega)} := \langle f, \, g \rangle_{H^2 (\Omega)} + \mathcal{D}(f, \, g) \; \; \; \; \; (f, \, g \in \mathcal{D}(\Omega)),&lt;/math&gt;

where &lt;math&gt; \langle \cdot, \, \cdot \rangle_{H^2 (\Omega)}&lt;/math&gt; is the usual inner product on &lt;math&gt;H^2 (\Omega).&lt;/math&gt; The corresponding norm &lt;math&gt; \| \cdot \|_{\mathcal{D}(\Omega)} &lt;/math&gt; is given by

:&lt;math&gt; \|f\|^2_{\mathcal{D}(\Omega)} := \|f\|^2_{H^2 (\Omega)} + \mathcal{D}(f) \; \; \; \; \; (f \in \mathcal{D} (\Omega)).&lt;/math&gt;

Note that this definition is not unique, another common choice is to take &lt;math&gt; \|f\|^2 = |f(c)|^2 + \mathcal{D}(f)&lt;/math&gt;, for some fixed &lt;math&gt; c \in \Omega &lt;/math&gt;.

The Dirichlet space is not an [[Algebra over a field|algebra]], but the space &lt;math&gt;\mathcal{D}(\Omega) \cap H^\infty(\Omega)&lt;/math&gt; is a [[Banach algebra]], with respect to the norm

:&lt;math&gt; \|f\|_{\mathcal{D}(\Omega) \cap H^\infty(\Omega)} := \|f\|_{H^\infty(\Omega)} + \mathcal{D}(f)^{1/2} \; \; \; \; \; (f \in \mathcal{D}(\Omega) \cap H^\infty(\Omega)).&lt;/math&gt;


We usually have &lt;math&gt;\Omega = \mathbb{D}&lt;/math&gt; (the [[unit disk]] of the [[complex plane]] &lt;math&gt;\mathbb{C}&lt;/math&gt;), in that case &lt;math&gt;\mathcal{D}(\mathbb{D}):=\mathcal{D}&lt;/math&gt;, and if 

:&lt;math&gt; f(z) = \sum_{n \ge 0} a_n z^n \; \; \; \; \; (f \in \mathcal{D}), &lt;/math&gt;

then 

:&lt;math&gt; D(f) =\sum_{n\ge 1} n |a_n|^2,&lt;/math&gt;

and

:&lt;math&gt; \|f \|^2_\mathcal{D} = \sum_{n \ge 0} (n+1) |a_n|^2. &lt;/math&gt;

Clearly, &lt;math&gt;\mathcal{D}&lt;/math&gt; contains all the [[polynomial|polynomials]] and, more generally, all functions &lt;math&gt;f&lt;/math&gt;, holomorphic on &lt;math&gt;\mathbb{D}&lt;/math&gt; such that &lt;math&gt;f'&lt;/math&gt; is [[bounded function|bounded]] on &lt;math&gt;\mathbb{D}&lt;/math&gt;.

The [[reproducing kernel]] of &lt;math&gt;\mathcal{D}&lt;/math&gt; at &lt;math&gt;w \in \mathbb{C} \setminus \{ 0 \}&lt;/math&gt; is given by

:&lt;math&gt; k_w(z) = \frac{1}{z\overline{w}} \log \left( \frac{1}{1-z\overline{w}} \right) \; \; \; \; \; (z \in \mathbb{C} \setminus \{ 0 \}).&lt;/math&gt;

==See also==
*[[Banach space]]
*[[Bergman space]]
*[[Hardy space]]
*[[Hilbert space]]

==References==
*{{citation|journal=New York J. Math. |volume=17a |year=2011|pages= 45–86|title=
The Dirichlet space: a survey|first1=Nicola|last1= Arcozzi|first2= Richard|last2= Rochberg|first3= Eric T.|last3= Sawyer|first4=Brett D. |last4=Wick|
url=http://nyjm.albany.edu/j/2011/17a-4v.pdf}}
*{{cite book|first1=Omar|last1=El-Fallah|first2=Karim|last2=Kellay|first3=Javad|last3=Mashreghi|first4=Thomas|last4=Ransford|title=A primer on the Dirichlet space|date=2014|publisher=Cambridge University Press|location=Cambridge, UK|isbn=978-1-107-04752-5|url=http://cambridge.org/9781107047525}}
[[Category:Complex analysis]]
[[Category:Functional analysis]]
{{mathanalysis-stub}}</text>
      <sha1>852qq9ivb4bqcf312vc0y1y77xr5hms</sha1>
    </revision>
  </page>
  <page>
    <title>Discrepancy function</title>
    <ns>0</ns>
    <id>711668</id>
    <revision>
      <id>541448368</id>
      <parentid>401281037</parentid>
      <timestamp>2013-03-01T06:53:32Z</timestamp>
      <contributor>
        <username>Lotje</username>
        <id>10434788</id>
      </contributor>
      <minor/>
      <comment>See also section</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1833">A '''discrepancy function''' is a mathematical function which describes how closely a [[Structural equation modeling|structural model]] conforms to observed data. Larger values of the discrepancy function indicate a poor fit of the model to data. In general, the parameter estimates for a given model are chosen so as to make the discrepancy function for that model as small as possible.&lt;!-- &lt;ref name="multiple"&gt;{{cite web | url = http://spin.magnet.fsu.edu/local/stat-book/glosd.html | title = Department of Chemistry and Biochemistry at Florida State University  | accessdate=September 10, 2006 }}&lt;/ref&gt; --&gt; &lt;!-- Ref gone 404 --&gt;

There are several basic types of discrepancy functions, including [[maximum likelihood]] (ML), [[generalized least squares]] (GLS), and [[ordinary least squares]] (OLS), which are considered the "classical" discrepancy functions.&lt;ref&gt;{{cite web | title = Discrepancy Functions Used in SEM | url = http://www2.gsu.edu/~mkteer/discrep.html | accessdate=2008-08-18 }}&lt;/ref&gt;  Discrepancy functions all meet the following basic criteria:

*They are non-negative, i.e., always greater than or equal to zero. 
*They are zero only if the fit is perfect, i.e., if the model and parameter estimates perfectly reproduce the observed data. 
*The discrepancy function is a continuous function of the elements of '''S''', the sample covariance matrix, and '''Σ(θ)''', the "reproduced" estimate of '''S''' obtained by using the parameter estimates and the structural model.

In order for "maximum likelihood" to meet the first criterion, it is used in a revised form as the [[Deviance (statistics)|deviance]].

==See also==
*[[Constructions of low-discrepancy sequences]]
*[[Discrepancy theory]]
*[[Low-discrepancy sequence]]

==References==

&lt;references/&gt;

[[Category:Structural equation models]]

{{stat-stub}}</text>
      <sha1>nw3it4nt3bvy8yg1kmfhlquyzc96us4</sha1>
    </revision>
  </page>
  <page>
    <title>Equilibrium point</title>
    <ns>0</ns>
    <id>1441435</id>
    <revision>
      <id>865329303</id>
      <parentid>857029545</parentid>
      <timestamp>2018-10-23T07:11:04Z</timestamp>
      <contributor>
        <ip>117.136.95.53</ip>
      </contributor>
      <comment>/* Formal definition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2438">In [[mathematics]], specifically in [[differential equations]], an '''equilibrium point''' is a constant solution to a differential equation.

==Formal definition==
The points &lt;math&gt;\tilde{\mathbf{x}}\in \mathbb{R}^n&lt;/math&gt; is an '''equilibrium point''' for the [[differential equation]] 

:&lt;math&gt;\frac{d\mathbf{x}}{dt} = \mathbf{f}(t,\mathbf{x})&lt;/math&gt; 

if &lt;math&gt;\mathbf{f}(t,\tilde{\mathbf{x}})=\mathbf{0}&lt;/math&gt; for all &lt;math&gt;t&lt;/math&gt;.

Similarly, the point  &lt;math&gt;\tilde{\mathbf{x}}\in \mathbb{R}^n&lt;/math&gt; is an '''equilibrium point''' (or [[Fixed point (mathematics)|fixed point]]) for the [[difference equation]] 

:&lt;math&gt;\mathbf{x}_{k+1} = \mathbf{f}(k,\mathbf{x}_k)&lt;/math&gt; 

if &lt;math&gt;\mathbf{f}(k,\tilde{\mathbf{x}})= \tilde{\mathbf{x}} &lt;/math&gt; for &lt;math&gt;k=0,1,2,\ldots&lt;/math&gt;.

==Classification==
Equilibria can be classified by looking at the signs of the eigenvalues of the linearization of the equations about the equilibria. That is to say, by evaluating the [[Jacobian matrix]] at each of the equilibrium points of the system, and then finding the resulting eigenvalues, the equilibria can be categorized. Then the behavior of the system in the neighborhood of each equilibrium point can be qualitatively determined, (or even quantitatively determined, in some instances), by finding the eigenvector(s) associated with each eigenvalue. 

An equilibrium point is ''[[Hyperbolic equilibrium point|hyperbolic]]'' if none of the eigenvalues have zero real part. If all eigenvalues have negative real part, the equilibrium is a stable equation. If at least one has a positive real part, the equilibrium is an unstable node. If at least one eigenvalue has negative real part and at least one has positive real part, the equilibrium is a [[saddle point]].

==See also==
* [[Autonomous equation]]
* [[Critical point (mathematics)|Critical point]]
* [[Steady state]]

==References==
{{reflist}}
*{{cite book | last1=Boyce | first1=William E. | last2=DiPrima | first2=Richard C. | title = Elementary Differential Equations and Boundary Value Problems | year=2012 | publisher=Wiley | isbn=978-0-470-45831-0 | edition=10th}}
*{{cite book |last=Perko |first=Lawrence |title=Differential Equations and Dynamical Systems |location= |publisher=Springer |edition=3rd |year=2001 |pages=102–104 |isbn=1-4613-0003-7 |url=https://books.google.com/books?id=VFnSBwAAQBAJ&amp;pg=PA102 }}

[[Category:Stability theory]]
[[Category:Dynamical systems]]</text>
      <sha1>fvlgyqxa5blkozsweez0jqbw1ywtqnj</sha1>
    </revision>
  </page>
  <page>
    <title>Exterior space</title>
    <ns>0</ns>
    <id>34045124</id>
    <revision>
      <id>854903532</id>
      <parentid>854903316</parentid>
      <timestamp>2018-08-14T15:54:59Z</timestamp>
      <contributor>
        <username>RJFJR</username>
        <id>141808</id>
      </contributor>
      <comment>use named ref to combine refs</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9101">{{multiple issues|
{{cleanup|date=January 2012}}
{{orphan|date=January 2012}}
}}

In [[mathematics]], the notion of '''externology''' in a [[topological space]] ''X'' generalizes the basic properties of the family

: &lt;big&gt;''ε''&lt;sup&gt;''X''&lt;/sup&gt;&lt;sub&gt;cc&lt;/sub&gt; = {E ⊆ X : X\E is a closed compact subset of X}&lt;/big&gt;

of [[Complement (set theory)|complements]] of the [[Closed set|closed]] [[Compact space|compact]] [[topological subspace|subspaces]] of ''X'', which are used to construct its [[Alexandroff compactification]]. An externology permits to introduce a notion of end&lt;ref name=ncatlab&gt;{{cite web|url=http://ncatlab.org/nlab/show/proper+homotopy+theory|title=proper homotopy theory in nLab|website=ncatlab.org}}&lt;/ref&gt; point, to study the divergence of [[Net (mathematics)|nets]] in terms of convergence to end points and it is a useful tool for the study and classification of some families of non compact topological spaces. It can also be used to approach a topological space as the [[Limit (category theory)|limit]] of other topological spaces: the externologies are very useful when a compact [[metric space]] embedded in a [[Hilbert cube|Hilbert space]] is approached by its [[open neighbourhood]]s.

== Definition ==
Let &lt;big&gt;(X,τ)&lt;/big&gt; be a topological space. An '''externology''' on &lt;big&gt;(X,τ)&lt;/big&gt; is a non-empty collection &lt;big&gt;ε&lt;/big&gt; of [[open subsets]] satisfying:
* If &lt;big&gt;E&lt;sub&gt;1&lt;/sub&gt;, E&lt;sub&gt;2&lt;/sub&gt; ∈ ε&lt;/big&gt;, then &lt;big&gt;E&lt;sub&gt;1&lt;/sub&gt; ∩ E&lt;sub&gt;2&lt;/sub&gt; ∈ ε&lt;/big&gt;;
* if &lt;big&gt;E ∈ ε, U ∈ τ&lt;/big&gt; and &lt;big&gt;E ⊆ U&lt;/big&gt;, then &lt;big&gt;U ∈ ε&lt;/big&gt;.

An '''''exterior space''''' &lt;big&gt;(X,τ,ε)&lt;/big&gt; consists of a topological space &lt;big&gt;(X,τ)&lt;/big&gt; together with an externology &lt;big&gt;ε&lt;/big&gt;. An open &lt;big&gt;E&lt;/big&gt; which is in &lt;big&gt;ε&lt;/big&gt; is said to be an '''exterior-open subset'''. A map &lt;big&gt;f:(X,τ,ε) → (X',τ',ε')&lt;/big&gt; is said to be an '''exterior map''' if it is [[Continuous map|continuous]] and  &lt;big&gt;f&lt;sup&gt;−1&lt;/sup&gt;(E) ∈ ε&lt;/big&gt;, for all &lt;big&gt;E ∈ ε'&lt;/big&gt;.

The [[Category (mathematics)|category]] of exterior spaces and exterior maps will be denoted by '''E'''. It is remarkable that '''E''' is a [[Complete category|complete]] and [[Complete category|cocomplete]] category.

== Some examples of exterior spaces ==
* For a space &lt;big&gt;(X,τ)&lt;/big&gt; one can always consider the ''trivial externology'' &lt;big&gt;ε&lt;sub&gt;tr&lt;/sub&gt;={X}&lt;/big&gt;, and, on the other hand, the ''total externology'' &lt;big&gt;ε&lt;sub&gt;tot&lt;/sub&gt;=τ&lt;/big&gt;. Note that an externology &lt;big&gt;ε&lt;/big&gt; is a [[topological space|topology]] if and only if the empty set is a member of &lt;big&gt;ε&lt;/big&gt; if and only if &lt;big&gt;ε=τ&lt;/big&gt;.
* Given a space &lt;big&gt;(X,τ)&lt;/big&gt;, the externology &lt;big&gt;ε&lt;sup&gt;X&lt;/sup&gt;&lt;sub&gt;cc&lt;/sub&gt;&lt;/big&gt; of the complements of closed compact subsets of &lt;big&gt;X&lt;/big&gt; permits a connection with the theory of [[proper map]]s.
* Given a space &lt;big&gt;(X,τ)&lt;/big&gt; and a subset &lt;big&gt;A⊆X&lt;/big&gt; the family &lt;big&gt;ε(X,A)={U⊆X:A⊆U,U∈τ}&lt;/big&gt; is an externology in &lt;big&gt;X&lt;/big&gt;. Two particular cases with important applications on [[Shape theory (mathematics)|shape theory]] and on [[dynamical systems]], respectively, are the following:
* If &lt;big&gt;A&lt;/big&gt; is a closed subspace of the [[Hilbert cube]] &lt;big&gt;X=Q&lt;/big&gt; the externology &lt;big&gt;ε&lt;sup&gt;A&lt;/sup&gt;=ε(Q,A)&lt;/big&gt; is a resolution of &lt;big&gt;A&lt;/big&gt; in the sense of the shape theory.
* Let &lt;big&gt;X&lt;/big&gt; be a [[continuous dynamical system]] and &lt;big&gt;P&lt;/big&gt; the subset of [[periodic point]]s; we can consider the externology &lt;big&gt;ε(X,P)&lt;/big&gt;. More generally, if &lt;big&gt;A&lt;/big&gt; is an invariant subset the externology &lt;big&gt;ε(X,A)&lt;/big&gt; is useful to study the dynamical properties of the [[Dynamical system|flow]].

== Applications of exterior spaces ==
* ''Proper homotopy theory'':&lt;ref name=ncatlab/&gt; A continuous map &lt;big&gt;f:X→Y&lt;/big&gt; between topological spaces is said to be ''[[Proper map|proper]]'' if for every closed compact subset &lt;big&gt;K&lt;/big&gt; of &lt;big&gt;Y&lt;/big&gt;, &lt;big&gt;f&lt;sup&gt;−1&lt;/sup&gt;(K)&lt;/big&gt; is a compact subset of &lt;big&gt;X&lt;/big&gt;. The category of spaces and proper maps will be denoted by '''P'''. This category and the corresponding proper [[homotopy category]] are very useful for the study of non compact spaces. Nevertheless, one has the problem that this category does not have enough limits and colimits and then we can not develop the usual homotopy constructions like [[loop space|loops]], homotopy limits and colimits, etc. An answer to this problem is the category of exterior spaces '''E''' which admits [[Model category|Quillen model structures]] and contains as a [[full subcategory]] the category of spaces and proper maps; that is, there is [[Full functor|full]] and [[Faithful functor|faithful]] [[functor]] &lt;big&gt;'''P'''→'''E'''&lt;/big&gt; which carries a topological space &lt;big&gt;(X,τ)&lt;/big&gt; to the exterior space &lt;big&gt;(X,τ,ε&lt;sup&gt;X&lt;/sup&gt;&lt;sub&gt;cc&lt;/sub&gt;)&lt;/big&gt;.
* ''Proper [[Lusternik–Schnirelmann category|LS category]]'': The problem of finding Ganea and Whitehead characterizations of this proper invariant can not be faced within the proper category because of the lack of (co)limits. Nevertheless, an extension of this invariant to the category of exterior spaces permits to find a solution to such a problem. This numerical proper invariant has been applied to the study of open 3-[[manifolds]].
* ''[[Shape theory (mathematics)|Shape theory]]'': Many [[Shape theory (mathematics)|shape]] invariants (Borsuk groups, Quigley inward and approaching groups) of a compact [[metric space]] can be obtained as exterior homotopy groups of the exterior space determined by the open neighborhoods of a compact metric space embedded in the Hilbert cube.
* ''Discrete and continuous dynamical systems (semi-flows and flows)'': There are many constructions that associate an exterior space to a dynamical system, for example: Given a continuous (discrete) flow one can consider the exterior spaces induced by the open neighborhoods of the subset of [[periodic point]]s, Poisson periodic points, [[omega limit]]s, etc. The constructions and properties of these associated exterior spaces are used to study the dynamical properties of the (semi-flow) flow.

==References==
{{reflist}}
* M. Cárdenas, F.F. Lasheras and A. Quintero. '' [http://journals.cambridge.org/action//displayAbstract?fromPage=online&amp;aid=8466968&amp;fulltextType=RA&amp;fileId=S0305004111000417 Detecting cohomology classes for the proper LS category. The case of semi-stable 3-manifolds] '', Math. Proc. Camb. Philos. Soc. (2011).
* A. Del Río, L.J. Hernández and M.T. Rivas Rodríguez. ''[http://www.springerlink.com/content/n20774l864824343/ S-Types of global towers of spaces an exterior spaces]'', Appl. Categ. Struct., '''17''' no. 3, 287–301, (2009).
* L. Español, J. M. García-Calcines, M. C. Mínguez. ''[http://www.springerlink.com/content/lq2087wvp070254m/ On proper and exterior sequentiality]'',  Appl. Categ. Struct., '''18''', no. 6, 653–668, (2010).
* J.I. Extremiana, L.J. Hernández and M.T. Rivas. ''[http://www.sciencedirect.com/science/article/pii/S0166864104003505 Postnikov factorizations at infinity]'', Topol. Appl., '''153''', 370–393, (2005).
* J.I. Extremiana, L.J. Hernández and M.T. Rivas. ''[http://www.unirioja.es/servicios/sp/catalogo/monografias/vr77.shtml An approach to dynamical systems using exterior spaces]''. Scientific contributions in honor of Mirian Andrés Gómez, 307Đ318, Univ. La Rioja Serv. Publ., Logroño, 2010.
* J.M. García-Calcines, P. R. García-Díaz,  A. Murillo Mas. ''[http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=1025304 A Whitehead-Ganea approach for proper Lusternik–Schnirelmann category]''. Math. Proc. Camb. Philos. Soc. '''142''' (2007), no. 3, 439—457.
* J.M. García-Calcines, P. R. García-Díaz,  A. Murillo Mas, ''[http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=7791519 The Ganea conjecture in proper homotopy via exterior homotopy theory]''. Math. Proc. Camb. Philos. Soc. '''149''' (2010), no. 1, 75—91.
* J.M. García-Calcines, M. García Pinillos and L.J. Hernández. ''[http://journals.cambridge.org/action/displayAbstract?fromPage=online&amp;aid=4853844 A closed model category for proper homotopy and shape theories]'', Bull. Aust. Math. Soc. '''57''' no.2, 221—242, (1998).
* J.M. García-Calcines and L.J. Hernández. ''[http://www.sciencedirect.com/science/article/pii/S0166864100000353 Sequential homology]'', Topol. Appl. '''114''' /2, 201–225, (2001).
* J.M. García-Calcines, M. García Pinillos and  L.J. Hernández. ''[http://www.springerlink.com/content/t5p84t1261x03lv5/ Closed simplicial model structures for exterior and proper homotopy]'', Appl. Categ. Struct. '''12''', no.3, 225–243, (2004).
* M. García-Pinillos, L.J. Hernández Paricio and M.T. Rivas Rodríguez. ''[http://www.springerlink.com/content/311478q31q32p510/ Exact sequences and closed model categories]'', Appl. Categ. Struct., '''18''', no. 4, 343–375 (2010). DOI 10.1007/s10485-008-9176-x (2009).

&lt;!--- Categories ---&gt;
[[Category:Articles created via the Article Wizard]]
[[Category:Topology]]
[[Category:Homotopy theory]]</text>
      <sha1>c9ttfpjkm84xnscfu6zwocbknnrub5x</sha1>
    </revision>
  </page>
  <page>
    <title>Forking extension</title>
    <ns>0</ns>
    <id>15933750</id>
    <revision>
      <id>861647418</id>
      <parentid>592982011</parentid>
      <timestamp>2018-09-28T23:36:03Z</timestamp>
      <contributor>
        <username>Wbm1058</username>
        <id>14383484</id>
      </contributor>
      <minor/>
      <comment>Disambiguate [[Substructure]] to [[Substructure (mathematics)]] using [[:en:Wikipedia:Tools/Navigation_popups|popups]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2938">In [[model theory]], a forking extension is an [[Substructure (mathematics)|extension]] that is not {{clarify-span|free|date=August 2013}} whereas a '''non-forking extension''' is an extension that is as free as possible. This can be used to extend the notions of [[Linear independence|linear]] or [[algebraic independence]] to [[Stable theory|stable theories]]. These concepts were introduced by [[S. Shelah]].

==Definitions==
Suppose that ''A'' and ''B'' are models of some complete ω-stable theory ''T''. 
If ''p'' is a type of ''A'' and ''q'' is a type of ''B'' containing ''p'', then ''q'' is called a '''forking extension''' of ''p'' if its [[Morley rank]] is smaller, and a '''nonforking extension''' if it has the same Morley rank.

==Axioms==
Let ''T'' be a stable complete theory. The non-forking relation ≤ for types over ''T'' is the unique relation that satisfies the following axioms:
#If ''p''≤ ''q'' then  ''p''⊂''q''. If ''f'' is an elementary map then ''p''≤''q'' if and only if ''fp''≤''fq''
#If ''p''⊂''q''⊂''r'' then ''p''≤''r'' if and only if ''p''≤''q'' and ''q''≤ ''r''
#If ''p'' is a type of ''A'' and ''A''⊂''B'' then there is some type ''q'' of ''B'' with ''p''≤''q''.
#There is a cardinal κ such that if ''p'' is a type of ''A'' then there is a subset ''A''&lt;sub&gt;0&lt;/sub&gt; of ''A'' of cardinality less than κ so that (''p''|''A''&lt;sub&gt;0&lt;/sub&gt;) ≤ ''p'', where | stands for restriction.
#For any ''p'' there is a cardinal λ such that there are at most λ non-contradictory types ''q'' with ''p''≤''q''.

==References==
*{{citation|doi=10.1016/0168-0072(84)90005-8
|mr=0747686
|last=Harnik|first= Victor|last2= Harrington|first2=Leo
|title=Fundamentals of forking
|journal=Ann. Pure Appl. Logic |volume=26 |year=1984|issue= 3|pages= 245–286}} 
*{{citation|title=An Introduction to Forking
|first=        Daniel |last=Lascar|first2= Bruno|last2= Poizat 
|journal=        The Journal of Symbolic Logic|volume= 44|issue= 3|year=1979|pages= 330–350|doi=10.2307/2273127|jstor=2273127|publisher=Association for Symbolic Logic}} 
*{{citation|title=A survey of basic stability theory, with particular emphasis on orthogonality and regular types
|doi=10.1007/BF02760649
|journal	=Israel Journal of Mathematics
|volume= 49|year= 1984
|first=M.|issue=1-3|last= Makkai|pages=181–238}}
*{{Citation | last1=Marker | first1=David | title=Model Theory: An Introduction | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=[[Graduate Texts in Mathematics]] | isbn=978-0-387-98760-6 | year=2002}}
*{{springer|id=F/f110150|title=Forking|first=Siu-Ah|last= Ng}}
*{{Citation | last1=Shelah | first1=Saharon | author1-link=Saharon Shelah | title=Classification theory and the number of nonisomorphic models | origyear=1978 | publisher=Elsevier | edition=2nd | series=Studies in Logic and the Foundations of Mathematics | isbn=978-0-444-70260-9 | year=1990}}

[[Category:Model theory]]</text>
      <sha1>0azb0bbthknvb7lh6nzjb5ideco96ae</sha1>
    </revision>
  </page>
  <page>
    <title>Geometric probability</title>
    <ns>0</ns>
    <id>733613</id>
    <revision>
      <id>809398791</id>
      <parentid>808334703</parentid>
      <timestamp>2017-11-08T21:23:17Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>/* top */WL 1 first-publisher; [[WP:GenFixes]] on; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2290">{{For|the probability distribution|Geometric distribution}}

Problems of the following type, and their solution techniques, were first studied in the 18th century, and the general topic became known as '''geometric probability'''.

* ([[Buffon's needle]]) What is the chance that a needle dropped randomly onto a floor marked with equally spaced parallel lines will cross one of the lines?
* What is the mean length of a random chord of a unit circle? (cf. [[Bertrand's paradox (probability)|Bertrand's paradox]]).
* What is the chance that three random points in the plane form an acute (rather than obtuse) triangle?
* What is the mean area of the polygonal regions formed when randomly oriented lines are spread over the plane?

For mathematical development see the concise monograph by Solomon.&lt;ref&gt;
{{cite book 
|author=Herbert Solomon
|title=Geometric Probability
|year= 1978
|publisher=[[Society for Industrial and Applied Mathematics]]
|location=Philadelphia, PA}}
&lt;/ref&gt;

Since the late 20th century the topic has split into two topics with different emphases.  [[Integral geometry]] sprang from the principle that the mathematically natural probability models are those that are invariant under certain transformation groups.  This topic emphasises systematic development of formulas for calculating expected values associated with the geometric 
objects derived from random points, and can in part be viewed as a sophisticated branch of [[multivariate calculus]].  [[Stochastic geometry]] emphasises the random geometrical objects themselves.  For instance: different models for random lines or for random tessellations of the plane; random sets formed by making points of a [[Poisson process|spatial Poisson process]] be (say) centers of discs.

== See also ==

* [[Wendel's theorem]]

== References ==

&lt;references/&gt;

*Daniel A. Klain, Gian-Carlo Rota - Introduction to Geometric Probability.
*Maurice G. Kendall, Patrick A. P. Moran - Geometrical Probability.
*[https://www.jstor.org/stable/41134124 Eugene Seneta, Karen Hunger Parshall, François Jongmans - Nineteenth-Century Developments in Geometric Probability: J. J. Sylvester, M. W. Crofton, J.-É. Barbier, and J. Bertrand]

{{DEFAULTSORT:Geometric Probability}}
[[Category:Geometry|*]]
[[Category:Probability theory]]</text>
      <sha1>8zvrqzmi0llqxfjduvhe2bzji2drvpe</sha1>
    </revision>
  </page>
  <page>
    <title>Graph amalgamation</title>
    <ns>0</ns>
    <id>42677761</id>
    <revision>
      <id>819877418</id>
      <parentid>819866823</parentid>
      <timestamp>2018-01-11T19:37:35Z</timestamp>
      <contributor>
        <ip>37.171.102.179</ip>
      </contributor>
      <comment>/* Example */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4774">In [[graph theory]], a '''graph amalgamation''' is a relationship between two graphs (one graph is an amalgamation of another).  Similar relationships include [[Glossary of graph theory#Subgraphs|subgraphs]] and [[graph minor|minors]]. Amalgamations can provide a way to reduce a graph to a simpler graph while keeping certain structure intact. The amalgamation can then be used to study properties of the original graph in an easier to understand context. Applications include embeddings,&lt;ref name="gross"&gt;Gross, Tucker 1987&lt;/ref&gt; computing  genus distribution,&lt;ref name="jlg2"&gt;Gross 2011&lt;/ref&gt; and [[Hamiltonian decomposition]]s.

== Definition ==

Let &lt;math&gt;G&lt;/math&gt; and &lt;math&gt;H&lt;/math&gt; be two graphs with the same number of edges where &lt;math&gt;G&lt;/math&gt; has more vertices than &lt;math&gt;H&lt;/math&gt;.  Then we say that &lt;math&gt;H&lt;/math&gt; is an amalgamation of &lt;math&gt;G&lt;/math&gt; if there is a [[bijection]] &lt;math&gt;\phi: E(G) \to E(H)&lt;/math&gt; and a [[surjection]] &lt;math&gt;\psi: V(G) \to V(H)&lt;/math&gt; and the following hold:
* If &lt;math&gt;x&lt;/math&gt;, &lt;math&gt;y&lt;/math&gt; are two vertices in &lt;math&gt;G&lt;/math&gt; where &lt;math&gt;\psi(x) \neq \psi(y)&lt;/math&gt;, and both &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are adjacent by edge &lt;math&gt;e&lt;/math&gt; in &lt;math&gt;G&lt;/math&gt;, then &lt;math&gt;\psi(x)&lt;/math&gt; and &lt;math&gt;\psi(y)&lt;/math&gt; are adjacent by edge &lt;math&gt;\phi(e)&lt;/math&gt; in &lt;math&gt;H&lt;/math&gt;.
* If &lt;math&gt;e&lt;/math&gt; is a loop on a vertex &lt;math&gt;x \in V(G)&lt;/math&gt;, then &lt;math&gt; \phi(e)&lt;/math&gt; is a loop on &lt;math&gt;\psi(x) \in H&lt;/math&gt;.
* If &lt;math&gt;e&lt;/math&gt; joins &lt;math&gt;x,y \in V(G)&lt;/math&gt;, where &lt;math&gt;x \neq y&lt;/math&gt;, but &lt;math&gt;\psi(x) = \psi(y)&lt;/math&gt;, then &lt;math&gt;\phi(e)&lt;/math&gt; is a loop on &lt;math&gt;\psi(x)&lt;/math&gt;.&lt;ref name="hilton"&gt;Hilton 1984&lt;/ref&gt;

Note that while &lt;math&gt;G&lt;/math&gt; can be a graph or a [[pseudograph]], it will usually be the case that &lt;math&gt;H&lt;/math&gt; is a pseudograph.

=== Properties ===
[[Edge coloring]]s are invariant to amalgamation.  This is obvious, as all of the edges between the two graphs are in bijection with each other.   However, what may not be obvious, is that if &lt;math&gt;G&lt;/math&gt; is a [[complete graph]] of the form &lt;math&gt;K_{2n+1}&lt;/math&gt;, and we color the edges as to specify a Hamiltonian decomposition (a decomposition into [[Hamiltonian path]]s, then those edges also form a Hamiltonian Decomposition in &lt;math&gt;H&lt;/math&gt;.

== Example ==
[[File:Graph amalgamation of k5.png|thumb|FIgure 1: An amalgamation of the complete graph on five vertices.]]
Figure 1 illustrates an amalgamation of &lt;math&gt;K_5&lt;/math&gt;.  The invariance of edge coloring and Hamiltonian Decomposition can be seen clearly. The function &lt;math&gt;\phi&lt;/math&gt; is a bijection and is given as letters in the figure.  The function &lt;math&gt;\psi&lt;/math&gt; is given in the table below.

{| class="wikitable"
|-
! &lt;math&gt;v \in V(G)&lt;/math&gt; !! &lt;math&gt;\psi(v)&lt;/math&gt;
|-
| &lt;math&gt;v_1&lt;/math&gt; || &lt;math&gt;u_2&lt;/math&gt;
|-
| &lt;math&gt;v_2&lt;/math&gt; || &lt;math&gt;u_2&lt;/math&gt;
|-
| &lt;math&gt;v_3&lt;/math&gt; || &lt;math&gt;u_1&lt;/math&gt;
|-
| &lt;math&gt;v_4&lt;/math&gt; || &lt;math&gt;u_3&lt;/math&gt;
|-
| &lt;math&gt;v_5&lt;/math&gt; || &lt;math&gt;u_2&lt;/math&gt;
|}

=== Hamiltonian decompositions ===
One of the ways in which amalgamations can be used is to find Hamiltonian Decompositions of complete graphs with 2''n''&amp;nbsp;+&amp;nbsp;1 vertices.&lt;ref name="barg"&gt;Bahmanian, Amin; Rodger, Chris 2012&lt;/ref&gt; The idea is to take a graph and produce an amalgamation of it which is edge colored in &lt;math&gt;n&lt;/math&gt; colors and satisfies certain properties (called an outline Hamiltonian decomposition).  We can then 'reverse' the amalgamation  and we are left with &lt;math&gt;K_{2n+1}&lt;/math&gt; colored in a Hamiltonian Decomposition.

In &lt;ref name="hilton" /&gt; Hilton outlines a method for doing this, as well as a method for finding all Hamiltonian Decompositions without repetition. The methods rely on a theorem he provides which states (roughly) that if we have an outline Hamiltonian decomposition, we could have arrived at it by first starting with a Hamiltonian decomposition of the complete graph and then finding an amalgamation for it.

== Notes ==
 {{Reflist}}

== References ==
* Bahmanian, Amin; Rodger, Chris (2012), [http://www.auburn.edu/academic/cosam/departments/math/images/Bahmanian2012.pdf "What Are Graph Amalgamations?"], [[Auburn University]]
* [[Anthony Hilton|Hilton, A. J. W]] (1984), [https://www.sciencedirect.com/science/article/pii/0095895684900200 "Hamiltonian Decompositions of Complete Graphs], [[Journal of Combinatorial Theory]], Series B 36, 125–134
* Gross, Jonathan L.; Tucker, Thomas W.  (1987),   Topological Graph Theory, [[Dover Publications|Courier Dover Publications]], 151
* Gross, Jonathan L. (2011), [http://www.emis.ams.org/journals/JGAA/getPaper-86.html?id=227  "Genus Distributions of Cubic Outerplanar Graphs"],  [[Journal of Graph Algorithms and Applications]], Vol. 15, no. 2, pp.&amp;nbsp;295–316

[[Category:Graph theory]]</text>
      <sha1>iui47iyw28m0912ghzwn893dv473rgj</sha1>
    </revision>
  </page>
  <page>
    <title>Graph minor</title>
    <ns>0</ns>
    <id>353042</id>
    <revision>
      <id>871685159</id>
      <parentid>871634145</parentid>
      <timestamp>2018-12-02T20:02:11Z</timestamp>
      <contributor>
        <username>Sniffnoy</username>
        <id>1098639</id>
      </contributor>
      <comment>/* Definitions */ rewrite definition in definition style</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34733">In [[graph theory]], an [[undirected graph]] ''H'' is called a '''minor''' of the graph ''G'' if ''H'' can be formed from ''G'' by deleting edges and vertices and by [[edge contraction|contracting edges]].

The theory of graph minors began with [[Wagner's theorem]] that a graph is [[planar graph|planar]] if and only if its minors include neither the [[complete graph]] ''K''&lt;sub&gt;5&lt;/sub&gt; nor the [[complete bipartite graph]] ''K''&lt;sub&gt;3,3&lt;/sub&gt;.&lt;ref name="w"&gt;{{harvtxt|Lovász|2006}}, p.&amp;nbsp;77; {{harvtxt|Wagner|1937a}}.&lt;/ref&gt; The [[Robertson–Seymour theorem]] implies that an analogous [[forbidden minors|forbidden minor characterization]] exists for every property of graphs that is preserved by deletions and edge contractions.&lt;ref name="rst"&gt;{{harvtxt|Lovász|2006}}, theorem 4, p.&amp;nbsp;78; {{harvtxt|Robertson|Seymour|2004}}.&lt;/ref&gt;
For every fixed graph ''H'', it is possible to test whether ''H'' is a minor of an input graph ''G'' in [[polynomial time]];&lt;ref name="rs95"/&gt; together with the forbidden minor characterization this implies that every graph property preserved by deletions and contractions may be recognized in polynomial time.&lt;ref name="fl88"/&gt;

Other results and conjectures involving graph minors include the [[graph structure theorem]], according to which the graphs that do not have ''H'' as a minor may be formed by gluing together simpler pieces, and [[Hadwiger conjecture (graph theory)|Hadwiger's conjecture]] relating the inability to [[graph coloring|color a graph]] to the existence of a large [[complete graph]] as a minor of it. Important variants of graph minors include the topological minors and immersion minors.

==Definitions==
An edge contraction is an operation which removes an edge from a graph while simultaneously merging the two vertices it used to connect. An [[undirected graph]] ''H'' is a minor of another undirected graph ''G'' if a [[Graph isomorphism|graph isomorphic]] to ''H'' can be obtained from ''G'' by contracting some edges, deleting some edges, and deleting some isolated vertices.  The order in which a sequence of such contractions and deletions is performed on ''G'' does not affect the resulting graph ''H''.

Graph minors are often studied in the more general context of [[matroid minor]]s. In this context, it is common to assume that all graphs are connected, with [[loop (graph theory)|self-loops]] and [[multiple edge]]s allowed (that is, they are [[multigraph]]s rather than simple graphs); the contraction of a loop and the deletion of a [[cut-edge]] are forbidden operations. This point of view has the advantage that edge deletions leave the [[rank (graph theory)|rank]] of a graph unchanged, and edge contractions always reduce the rank by one.

In other contexts (such as with the study of [[pseudoforest]]s) it makes more sense to allow the deletion of a cut-edge, and to allow disconnected graphs, but to forbid multigraphs. In this variation of graph minor theory, a graph is always simplified after any edge contraction to eliminate its self-loops and multiple edges.&lt;ref&gt;{{harvtxt|Lovász|2006}} is inconsistent about whether to allow self-loops and multiple adjacencies: he writes on p.&amp;nbsp;76 that "parallel edges and loops are allowed" but on p.&amp;nbsp;77 he states that "a graph is a forest if and only if it does not contain the triangle ''K''&lt;sub&gt;3&lt;/sub&gt; as a minor", true only for simple graphs.&lt;/ref&gt;

A function ''f'' is referred to as "minor-monotone" if, whenever ''H'' is a minor of ''G'', one has f(H) ≤ f(G).

==Example==
In the following example, graph H is a minor of graph G:

H. [[Image:GraphMinorExampleA.png|100px|graph H]]

G. [[Image:GraphMinorExampleB.svg|200px|graph G]]

The following diagram illustrates this. First construct a subgraph of G by deleting the dashed edges (and the resulting isolated vertex), and then contract the gray edge (merging the two vertices it connects):

[[Image:GraphMinorExampleC.svg|190px|transformation from G to H]]

== Major results and conjectures ==
It is straightforward to verify that the graph minor [[binary relation|relation]] forms a [[partial order]] on the isomorphism classes of undirected graphs: it is [[Transitive relation|transitive]] (a minor of a minor of ''G'' is a minor of ''G'' itself), and ''G'' and ''H'' can only be minors of each other if they are isomorphic because any nontrivial minor operation removes edges or vertices. A [[deep result]] by [[Neil Robertson (mathematician)|Neil Robertson]] and [[Paul Seymour (mathematician)|Paul Seymour]] states that this partial order is actually a [[well-quasi-ordering]]:  if an infinite list ''G''&lt;sub&gt;1&lt;/sub&gt;, ''G''&lt;sub&gt;2&lt;/sub&gt;,... of finite graphs is given, then there always exist two indices ''i'' &lt; ''j'' such that ''G''&lt;sub&gt;''i''&lt;/sub&gt; is a minor of ''G''&lt;sub&gt;''j''&lt;/sub&gt;. Another equivalent way of stating this is that any set of graphs can have only a finite number of [[minimal element]]s under the minor ordering.&lt;ref&gt;{{harvtxt|Diestel|2005}}, Chapter 12: Minors, Trees, and WQO; {{harvtxt|Robertson|Seymour|2004}}.&lt;/ref&gt; This result proved a conjecture formerly known as Wagner's conjecture, after [[Klaus Wagner]]; Wagner had conjectured it long earlier, but only published it in 1970.&lt;ref&gt;{{harvtxt|Lovász|2006}}, p.&amp;nbsp;76.&lt;/ref&gt;

In the course of their proof, Seymour and Robertson also prove the [[graph structure theorem]] in which they determine, for any fixed graph ''H'', the rough structure of any graph which does not have ''H'' as a minor.  The statement of the theorem is itself long and involved, but in short it establishes that such a graph must have the structure of a [[clique-sum]] of smaller graphs that are modified in small ways from graphs [[graph embedding|embedded]] on surfaces of bounded [[Genus (mathematics)|genus]].
Thus, their theory establishes fundamental connections between graph minors and [[graph embedding|topological embeddings]] of graphs.&lt;ref&gt;{{harvtxt|Lovász|2006}}, pp. 80–82; {{harvtxt|Robertson|Seymour|2003}}.&lt;/ref&gt;
 
For any graph ''H'', the simple ''H''-minor-free graphs must be [[sparse graph|sparse]], which means that the number of edges is less than some constant multiple of the number of vertices.&lt;ref&gt;{{harvtxt|Mader|1967}}.&lt;/ref&gt; More specifically, if ''H'' has ''h'' vertices, then a simple ''n''-vertex simple ''H''-minor-free graph can have at most &lt;math&gt;\scriptstyle O(nh\sqrt{\log h})&lt;/math&gt; edges, and some ''K&lt;sub&gt;h&lt;/sub&gt;''-minor-free graphs have at least this many edges.&lt;ref&gt;{{harvtxt|Kostochka|1982}}; {{harvtxt|Kostochka|1984}}; {{harvtxt|Thomason|1984}}; {{harvtxt|Thomason|2001}}.&lt;/ref&gt; Thus, if ''H'' has ''h'' vertices, then ''H''-minor-free graphs have average degree &lt;math&gt;\scriptstyle O(h \sqrt{\log h})&lt;/math&gt; and furthermore [[Degeneracy (graph theory)|degeneracy]] &lt;math&gt;\scriptstyle O(h \sqrt{\log h})&lt;/math&gt;. Additionally, the ''H''-minor-free graphs have a separator theorem similar to the [[planar separator theorem]] for planar graphs: for any fixed ''H'', and any ''n''-vertex ''H''-minor-free graph ''G'', it is possible to find a subset of &lt;math&gt;\scriptstyle O(\sqrt{n})&lt;/math&gt; vertices whose removal splits ''G'' into two (possibly disconnected) subgraphs with at most 2''n''/3 vertices per subgraph.&lt;ref&gt;{{harvtxt|Alon|Seymour|Thomas|1990}}; {{harvtxt|Plotkin|Rao|Smith|1994}}; {{harvtxt|Reed|Wood|2009}}.&lt;/ref&gt; Even stronger, for any fixed ''H'', ''H''-minor-free graphs have [[treewidth]] &lt;math&gt;\scriptstyle O(\sqrt{n})&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Grohe|2003}}&lt;/ref&gt;

The [[Hadwiger conjecture (graph theory)|Hadwiger conjecture]] in graph theory proposes that if a graph ''G'' does not contain a minor isomorphic to the [[complete graph]] on ''k'' vertices, then ''G'' has a [[graph coloring|proper coloring]] with ''k''&amp;nbsp;&amp;minus;&amp;nbsp;1 colors.&lt;ref&gt;{{harvtxt|Hadwiger|1943}}.&lt;/ref&gt; The case ''k''&amp;nbsp;=&amp;nbsp;5 is a restatement of the [[four color theorem]]. The Hadwiger conjecture has been proven for ''k''&amp;nbsp;≤&amp;nbsp;6,&lt;ref&gt;{{harvtxt|Robertson|Seymour|Thomas|1993}}.&lt;/ref&gt; but is unknown in the general case. {{harvtxt|Bollobás|Catlin|Erdős|1980}} call it “one of the deepest unsolved problems in graph theory.” Another result relating the four-color theorem to graph minors is the [[snark theorem]] announced by Robertson, Sanders, Seymour, and Thomas, a strengthening of the four-color theorem conjectured by [[W. T. Tutte]] and stating that any [[Bridge (graph theory)|bridgeless]] [[cubic graph|3-regular graph]] that requires four colors in an [[edge coloring]] must have the [[Petersen graph]] as a minor.&lt;ref&gt;{{harvtxt|Thomas|1999}}; {{harvtxt|Pegg|2002}}.&lt;/ref&gt;

==Minor-closed graph families== &lt;!-- "Minor-closed graph family" redirects here --&gt;
{{details|topic=minor-closed graph families, including a list of some|Robertson–Seymour theorem}}

Many families of graphs have the property that every minor of a graph in ''F'' is also in ''F''; such a class is said to be ''minor-closed''. For instance, in any [[planar graph]], or any [[graph embedding|embedding]] of a graph on a fixed [[2-manifold|topological surface]], neither the removal of edges nor the contraction of edges can increase the [[genus (mathematics)|genus]] of the embedding; therefore, planar graphs and the graphs embeddable on any fixed surface form minor-closed families.

If ''F'' is a minor-closed family, then (because of the well-quasi-ordering property of minors) among the graphs that do not belong to ''F'' there is a finite set ''X'' of minor-minimal graphs. These graphs are [[Forbidden graph characterization|forbidden minors]] for ''F'': a graph belongs to ''F'' if and only if it does not contain as a minor any graph in ''X''. That is, every minor-closed family ''F'' can be characterized as the family of ''X''-minor-free graphs for some finite set ''X'' of forbidden minors.&lt;ref name="rst"/&gt;
The best-known example of a characterization of this type is [[Wagner's theorem]] characterizing the planar graphs as the graphs having neither K&lt;sub&gt;5&lt;/sub&gt; nor K&lt;sub&gt;3,3&lt;/sub&gt; as minors.&lt;ref name="w"/&gt;

In some cases, the properties of the graphs in a minor-closed family may be closely connected to the properties of their excluded minors. For example a minor-closed graph family ''F'' has bounded [[pathwidth]] if and only if its forbidden minors include a [[tree (graph theory)|forest]],&lt;ref&gt;{{harvtxt|Robertson|Seymour|1983}}.&lt;/ref&gt; ''F'' has bounded [[tree-depth]] if and only if its forbidden minors include a disjoint union of [[path graph]]s, ''F'' has bounded [[treewidth]] if and only if its forbidden minors include a [[planar graph]],&lt;ref&gt;{{harvtxt|Lovász|2006}}, Theorem 9, p.&amp;nbsp;81; {{harvtxt|Robertson|Seymour|1986}}.&lt;/ref&gt; and ''F'' has bounded local treewidth (a functional relationship between [[diameter (graph theory)|diameter]] and treewidth) if and only if its forbidden minors include an [[apex graph]] (a graph that can be made planar by the removal of a single vertex).&lt;ref&gt;{{harvtxt|Eppstein|2000}}; {{harvtxt|Demaine|Hajiaghayi|2004}}.&lt;/ref&gt; If ''H'' can be drawn in the plane with only a single crossing (that is, it has [[crossing number (graph theory)|crossing number]] one) then the ''H''-minor-free graphs have a simplified structure theorem in which they are formed as clique-sums of planar graphs and graphs of bounded treewidth.&lt;ref&gt;{{harvtxt|Robertson|Seymour|1993}}; {{harvtxt|Demaine|Hajiaghayi|Thilikos|2002}}.&lt;/ref&gt; For instance, both ''K''&lt;sub&gt;5&lt;/sub&gt; and ''K''&lt;sub&gt;3,3&lt;/sub&gt; have crossing number one, and as Wagner showed the  ''K''&lt;sub&gt;5&lt;/sub&gt;-free graphs are exactly the 3-clique-sums of planar graphs and the eight-vertex [[Wagner graph]], while the ''K''&lt;sub&gt;3,3&lt;/sub&gt;-free graphs are exactly the 2-clique-sums of planar graphs and&amp;nbsp;''K''&lt;sub&gt;5&lt;/sub&gt;.&lt;ref&gt;{{harvtxt|Wagner|1937a}}; {{harvtxt|Wagner|1937b}}; {{harvtxt|Hall|1943}}.&lt;/ref&gt;

==Variations==
===Topological minors=== &lt;!--Topological minor redirects here--&gt;
A graph ''H'' is called a '''topological minor''' of a graph ''G'' if a [[Subdivision (graph theory)|subdivision]] of ''H'' is [[Graph isomorphism|isomorphic]] to a [[Glossary of graph theory#subgraph|subgraph]] of ''G''.&lt;ref&gt;{{Harvnb|Diestel|2005|p=20}}&lt;/ref&gt; It is easy to see that every topological minor is also a minor. The converse however is not true in general (for instance the [[complete graph]] ''K''&lt;sub&gt;5&lt;/sub&gt; in the [[Petersen graph]] is a minor but not a topological one), but holds for graph with maximum degree not greater than three.&lt;ref&gt;{{Harvnb|Diestel|2005|p=22}}&lt;/ref&gt;

The topological minor relation is not a well-quasi-ordering on the set of finite graphs{{sfnp|Ding|1996}} and hence the result of Robertson and Seymour does not apply to topological minors. However it is straightforward to construct finite forbidden topological minor characterizations from finite forbidden minor characterizations by replacing every branch set with ''k'' outgoing edges by every tree on ''k'' leaves that has down degree at least two.

===Induced minors===
A graph ''H'' is called an '''induced minor''' of a graph ''G'' if it can be obtained from an induced subgraph of ''G'' by contracting edges. Otherwise, ''G'' is said to be ''H''-induced minor-free.&lt;ref&gt;{{harvtxt|Błasiok|Kamiński|Raymond|Trunck}}&lt;/ref&gt;

===Immersion minor===
A graph operation called ''lifting'' is central in a concept called ''immersions''.  The ''lifting'' is an operation on adjacent edges.  Given three vertices ''v'', ''u'', and ''w'', where ''(v,u)'' and ''(u,w)'' are edges in the graph, the lifting of ''vuw'', or equivalent of ''(v,u), (u,w)'' is the operation that deletes the two edges ''(v,u)'' and ''(u,w)'' and adds the edge ''(v,w)''.  In the case where ''(v,w)'' already was present, ''v'' and ''w'' will now be connected by more than one edge, and hence this operation is intrinsically a multi-graph operation.

In the case where a graph ''H'' can be obtained from a graph ''G'' by a sequence of lifting operations (on ''G'') and then finding an isomorphic subgraph, we say that ''H'' is an immersion minor of ''G''.
There is yet another way of defining immersion minors, which is equivalent to the lifting operation.  We say that ''H'' is an immersion minor of ''G'' if there exists an injective mapping from vertices in ''H'' to vertices in ''G'' where the images of adjacent elements of ''H'' are connected in ''G'' by edge-disjoint paths.

The immersion minor relation is a well-quasi-ordering on the set of finite graphs and hence the result of Robertson and Seymour applies to immersion minors.  This furthermore means that every immersion minor-closed family is characterized by a finite family of forbidden immersion minors.

In [[graph drawing]], immersion minors arise as the [[planarization]]s of [[planar graph|non-planar graphs]]: from a drawing of a graph in the plane, with crossings, one can form an immersion minor by replacing each crossing point by a new vertex, and in the process also subdividing each crossed edge into a path. This allows drawing methods for planar graphs to be extended to non-planar graphs.{{sfnp|Buchheim|Chimani|Gutwenger|Jünger|2014}}

===Shallow minors===
A [[shallow minor]] of a graph ''G'' is a minor in which the edges of ''G'' that were contracted to form the minor form a collection of disjoint subgraphs with low [[distance (graph theory)|diameter]]. Shallow minors interpolate between the theories of graph minors and subgraphs, in that shallow minors with high depth coincide with the usual type of graph minor, while the shallow minors with depth zero are exactly the subgraphs.&lt;ref&gt;{{harvtxt|Nešetřil|Ossona de Mendez|2012}}.&lt;/ref&gt; They also allow the theory of graph minors to be extended to classes of graphs such as the [[1-planar graph]]s that are not closed under taking minors.&lt;ref&gt;{{harvtxt|Nešetřil|Ossona de Mendez|2012}}, pp. 319–321.&lt;/ref&gt;

===Parity conditions===
An alternative and equivalent definition of a graph minor is that ''H'' is a minor of ''G'' whenever the vertices of ''H'' can be represented by a collection of vertex-disjoint subtrees of ''G'', such that if two vertices are adjacent in ''H'', there exists an edge with its endpoints in the corresponding two trees in ''G''.
An [[odd minor]] restricts this definition by adding parity conditions to these subtrees. If ''H'' is represented by a collection of subtrees of ''G'' as above, then ''H'' is an odd minor of ''G'' whenever it is possible to assign two colors to the vertices of ''G'' in such a way that each edge of ''G'' within a subtree is properly colored (its endpoints have different colors) and each edge of ''G'' that represents an adjacency between two subtrees is monochromatic (both its endpoints are the same color). Unlike for the usual kind of graph minors, graphs with forbidden odd minors are not necessarily sparse.&lt;ref&gt;{{citation
 | last1 = Kawarabayashi | first1 = Ken-ichi | author1-link = Ken-ichi Kawarabayashi
 | last2 = Reed | first2 = Bruce | author2-link = Bruce Reed (mathematician)
 | last3 = Wollan | first3 = Paul
 | contribution = The graph minor algorithm with parity conditions
 | doi = 10.1109/focs.2011.52
 | pages = 27–36
 | publisher = Institute of Electrical and Electronics Engineers
 | title = 52nd Annual IEEE Symposium on Foundations of Computer Science
 | year = 2011}}.&lt;/ref&gt; The [[Hadwiger conjecture (graph theory)|Hadwiger conjecture]], that ''k''-chromatic graphs necessarily contain ''k''-vertex [[complete graph]]s as minors, has also been studied from the point of view of odd minors.&lt;ref&gt;{{citation
 | last1 = Geelen | first1 = Jim | author1-link = Jim Geelen
 | last2 = Gerards | first2 = Bert
 | last3 = Reed | first3 = Bruce | author3-link = Bruce Reed (mathematician)
 | last4 = Seymour | first4 = Paul | author4-link = Paul Seymour (mathematician)
 | last5 = Vetta | first5 = Adrian
 | doi = 10.1016/j.jctb.2008.03.006
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 2467815
 | pages = 20–29
 | series = Series B
 | title = On the odd-minor variant of Hadwiger's conjecture
 | volume = 99
 | year = 2009}}.&lt;/ref&gt;

A different parity-based extension of the notion of graph minors is the concept of a [[bipartite minor]], which produces a [[bipartite graph]] whenever the starting graph is bipartite. A graph ''H'' is a bipartite minor of another graph ''G'' whenever ''H'' can be obtained from ''G'' by deleting vertices, deleting edges, and collapsing pairs of vertices that are at distance two from each other along a [[peripheral cycle]] of the graph. A form of [[Wagner's theorem]] applies for bipartite minors: A bipartite graph ''G'' is a [[planar graph]] if and only if it does not have the [[utility graph]] ''K''&lt;sub&gt;3,3&lt;/sub&gt; as a bipartite minor.&lt;ref&gt;{{citation
 | last1 = Chudnovsky | first1 = Maria | author1-link = Maria Chudnovsky
 | last2 = Kalai | first2 = Gil | author2-link = Gil Kalai
 | last3 = Nevo | first3 = Eran
 | last4 = Novik | first4 = Isabella | author4-link = Isabella Novik
 | last5 = Seymour | first5 = Paul | author5-link = Paul Seymour (mathematician)
 | arxiv = 1312.0210
 | doi = 10.1016/j.jctb.2015.08.001
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 3425242
 | pages = 219–228
 | series = Series B
 | title = Bipartite minors
 | volume = 116
 | year = 2016}}.&lt;/ref&gt;

==Algorithms==
The problem of [[decision problem|deciding]] whether a graph ''G'' contains ''H'' as a minor is NP-complete in general; for instance, if ''H'' is a [[cycle graph]] with the same number of vertices as ''G'', then ''H'' is a minor of ''G'' if and only if ''G'' contains a [[Hamiltonian cycle]]. However, when ''G'' is part of the input but ''H'' is fixed, it can be solved in polynomial time. More specifically, the running time for testing whether ''H'' is a minor of ''G'' in this case is ''O''(''n''&lt;sup&gt;3&lt;/sup&gt;), where ''n'' is the number of vertices in ''G'' and the [[big O notation]] hides a constant that depends superexponentially on ''H'';&lt;ref name="rs95"&gt;{{harvtxt|Robertson|Seymour|1995}}.&lt;/ref&gt; since the original Graph Minors result, this algorithm has been improved to ''O''(''n''&lt;sup&gt;2&lt;/sup&gt;) time.&lt;ref name="kkr12"&gt;{{harvtxt|Kawarabayashi|Kobayashi|Reed|2012}}.&lt;/ref&gt; Thus, by applying the polynomial time algorithm for testing whether a given graph contains any of the forbidden minors, it is possible to recognize the members of any minor-closed family in [[polynomial time]]. However, in order to apply this result constructively, it is necessary to know what the forbidden minors of the graph family are.&lt;ref name="fl88"&gt;{{harvtxt|Fellows|Langston|1988}}.&lt;/ref&gt; In some cases, the forbidden minors are known, or can be computed.&lt;ref&gt;{{Cite journal|last=Bodlaender|first=Hans L.|date=1993|title=A Tourist Guide through Treewidth|url=https://dspace.library.uu.nl/bitstream/handle/1874/2301/1992-12.pdf?sequence=1|journal=Acta Cybernetica|volume=11|pages=1–21|via=}} See end of Section 5.&lt;/ref&gt;

In the case where ''H'' is a fixed [[planar graph]], then we can test in linear time in an input graph ''G'' whether ''H'' is a minor of ''G''.&lt;ref&gt;{{Cite journal|last=Bodlaender|first=Hans L.|date=1993|title=A Tourist Guide through Treewidth|url=https://dspace.library.uu.nl/bitstream/handle/1874/2301/1992-12.pdf?sequence=1|journal=Acta Cybernetica|volume=11|pages=1–21|via=}} First paragraph after Theorem 5.3&lt;/ref&gt; In cases where ''H'' is not fixed, faster algorithms are known in the case where ''G'' is planar.&lt;ref&gt;{{Cite journal|last=Adler|first=Isolde|last2=Dorn|first2=Frederic|last3=Fomin|first3=Fedor V.|last4=Sau|first4=Ignasi|last5=Thilikos|first5=Dimitrios M.|date=2012-09-01|title=Fast Minor Testing in Planar Graphs|url=http://www.lirmm.fr/~sau/Pubs/Minor-planar.pdf|journal=Algorithmica|language=en|volume=64|issue=1|pages=69–84|doi=10.1007/s00453-011-9563-9|issn=0178-4617}}&lt;/ref&gt;

==Notes==
{{reflist|2}}

==References==
{{refbegin|2}}
*{{citation
 | last1 = Alon | first1 = Noga | author1-link = Noga Alon
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | last3 = Thomas | first3 = Robin | author3-link = Robin Thomas (mathematician)
 | doi = 10.2307/1990903
 | mr = 1065053
 | journal = [[Journal of the American Mathematical Society]]
 | pages = 801–808
 | title = A separator theorem for nonplanar graphs
 | issue = 4
 | url = http://www.ams.org/journals/jams/1990-03-04/S0894-0347-1990-1065053-0/home.html
 | volume = 3
 | year = 1990
 | jstor = 1990903}}.
*{{citation
 | last1 = Błasiok | first1 = Jarosław
 | last2 = Kamiński | first2 = Marcin
 | last3 = Raymond | first3 = Jean-Florent
 | last4 = Trunck | first4 = Théophile
 | title = Induced minors and well-quasi-ordering
 | arxiv=1510.07135| bibcode = 2015arXiv151007135B}}.
*{{citation
 |last1        = Bollobás
 |first1       = B.
 |author1-link = Béla Bollobás
 |last2        = Catlin
 |first2       = P. A.
 |last3        = Erdős
 |first3       = Paul
 |author3-link = Paul Erdős
 |journal      = [[European Journal of Combinatorics]]
 |pages        = 195–199
 |title        = Hadwiger's conjecture is true for almost every graph
 |url          = http://www2.renyi.hu/~p_erdos/1980-10.pdf
 |volume       = 1
 |year         = 1980
 |doi          = 10.1016/s0195-6698(80)80001-1
 |deadurl      = yes
 |archiveurl   = https://web.archive.org/web/20090318165333/http://www2.renyi.hu/~p_erdos/1980-10.pdf
 |archivedate  = 2009-03-18
 |df           = 
}}.
*{{citation
 | last1 = Buchheim | first1 = Christoph
 | last2 = Chimani | first2 = Markus
 | last3 = Gutwenger | first3 = Carsten
 | last4 = Jünger | first4 = Michael
 | last5 = Mutzel | first5 = Petra | author5-link = Petra Mutzel
 | editor-last = Tamassia | editor-first = Roberto | editor-link = Roberto Tamassia
 | contribution = Crossings and planarization
 | publisher = CRC Press, Boca Raton, FL
 | series = Discrete Mathematics and its Applications (Boca Raton)
 | title = Handbook of Graph Drawing and Visualization
 | year = 2014}}.
*{{citation
 | last1 = Demaine | first1 = Erik D. | author1-link = Erik Demaine
 | last2 = Hajiaghayi | first2 = MohammadTaghi
 | doi = 10.1007/s00453-004-1106-1
 | issue = 3
 | journal = Algorithmica
 | pages = 211–215
 | title = Diameter and treewidth in minor-closed graph families, revisited
 | url = http://erikdemaine.org/papers/DiameterTreewidth_Algorithmica/
 | volume = 40
 | year = 2004}}.
*{{citation
 | last1 = Demaine | first1 = Erik D. | author1-link = Erik Demaine
 | last2 = Hajiaghayi | first2 = MohammadTaghi
 | last3 = Thilikos | first3 = Dimitrios M.
 | contribution = 1.5-Approximation for treewidth of graphs excluding a graph with one crossing as a minor
 | doi = 10.1007/3-540-45753-4_8
 | pages = 67–80
 | publisher = Springer-Verlag
 | series = Lecture Notes in Computer Science
 | title = Proc. 5th International Workshop on Approximation Algorithms for Combinatorial Optimization (APPROX 2002)
 | volume = 2462
 | year = 2002}}
*{{citation
 | last = Diestel | first = Reinhard
 | edition = 3rd
 | isbn = 978-3-540-26183-4
 | location = Berlin, New York
 | publisher = Springer-Verlag
 | title = Graph Theory
 | url = http://www.math.uni-hamburg.de/home/diestel/books/graph.theory/
 | year = 2005}}.
*{{citation
 | last = Ding | first = Guoli
 | doi = 10.1006/jctb.1996.0002
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]]
 | mr = 1368512
 | pages = 11–23
 | series = Series B
 | title = Excluding a long double path minor
 | volume = 66
 | year = 1996}}.
*{{citation
 | last = Eppstein | first = David | authorlink = David Eppstein
 | doi = 10.1007/s004530010020
 | arxiv=math.CO/9907126
 | mr = 1759751
| journal = Algorithmica
 | pages = 275–291
 | title = Diameter and treewidth in minor-closed graph families
 | volume = 27
 | year = 2000}}.
*{{citation
 | last1 = Fellows | first1 = Michael R. | author1-link = Michael Fellows
 | last2 = Langston | first2 = Michael A. | author2-link = Michael Langston
 | doi = 10.1145/44483.44491
 | issue = 3
 | journal = [[Journal of the ACM]]
 | pages = 727–739
 | title = Nonconstructive tools for proving polynomial-time decidability
 | volume = 35
 | year = 1988}}.
*{{citation
 | last = Grohe | first = Martin
 | title = Local tree-width, excluded minors, and approximation algorithms
 | journal = [[Combinatorica]]
 | doi = 10.1007/s00493-003-0037-9
 | volume = 23
 | issue = 4
 | pages = 613–632
 | year = 2003
 | arxiv = math/0001128
 }}.
*{{citation
 | last = Hadwiger | first = Hugo | author-link = Hugo Hadwiger
 | journal = Vierteljschr. Naturforsch. Ges. Zürich
 | pages = 133–143
 | title = Über eine Klassifikation der Streckenkomplexe
 | volume = 88
 | year = 1943}}.
*{{citation
 | last = Hall | first = Dick Wick
 | doi = 10.1090/S0002-9904-1943-08065-2
 | issue = 12
 | journal = [[Bulletin of the American Mathematical Society]]
 | pages = 935–936
 | title = A note on primitive skew curves
 | volume = 49
 | year = 1943}}.
*{{citation
 | last1 = Kawarabayashi | first1 = Ken-ichi | author1-link = Ken-ichi Kawarabayashi
 | last2 = Kobayashi | first2 = Yusuke
 | last3 = Reed | first3 = Bruce | author3-link = Bruce Reed (mathematician)
 | title = The disjoint paths problem in quadratic time
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | volume = 102
 | issue = 2
 |date=March 2012
 | pages = 424–435
 | doi = 10.1016/j.jctb.2011.07.004}}
*{{citation
 | last = Kostochka | first = Alexandr V.
 | journal = Metody Diskret. Analiz.
 | language = Russian
 | pages = 37–58
 | title = The minimum Hadwiger number for graphs with a given mean degree of vertices
 | volume = 38
 | year = 1982}}.
*{{citation
 | last = Kostochka | first = Alexandr V.
 | doi = 10.1007/BF02579141
 | journal = Combinatorica
 | pages = 307–316
 | title = Lower bound of the Hadwiger number of graphs by their average degree
 | volume = 4
 | year = 1984}}.
*{{citation
 | last = Lovász | first = László | author-link = László Lovász
 | doi = 10.1090/S0273-0979-05-01088-8
 | issue = 1
 | journal = [[Bulletin of the American Mathematical Society]]
 | pages = 75–86
 | title = Graph minor theory
 | volume = 43
 | year = 2006}}.
*{{citation
 | last = Mader | first = Wolfgang
 | doi = 10.1007/BF01364272
 | issue = 4
 | journal = Mathematische Annalen
 | pages = 265–268
 | title = Homomorphieeigenschaften und mittlere Kantendichte von Graphen
 | volume = 174
 | year = 1967}}.
*{{citation
 | last1 = Nešetřil | first1 = Jaroslav | author1-link = Jaroslav Nešetřil
 | last2 = Ossona de Mendez | first2 = Patrice | author2-link = Patrice Ossona de Mendez
 | doi = 10.1007/978-3-642-27875-4
 | isbn = 978-3-642-27874-7
 | mr = 2920058
 | pages = 62–65
 | publisher = Springer
 | series = Algorithms and Combinatorics
 | title = Sparsity: Graphs, Structures, and Algorithms
 | volume = 28
 | year = 2012}}.
*{{citation|last=Pegg|first=Ed, Jr.|authorlink=Ed Pegg, Jr.|title=Book Review: The Colossal Book of Mathematics|journal=Notices of the American Mathematical Society|volume=49|issue=9|year=2002|pages=1084–1086|url=http://www.ams.org/notices/200209/rev-pegg.pdf | doi = 10.1109/TED.2002.1003756|bibcode=2002ITED...49.1084A}}.
*{{citation
 | last1 = Plotkin | first1 = Serge
 | last2 = Rao | first2 = Satish
 | last3 = Smith | first3 = Warren D.
 | contribution = Shallow excluded minors and improved graph decompositions
 | pages = 462–470
 | title = Proc. 5th ACM–SIAM Symp. on Discrete Algorithms (SODA 1994)
 | url = http://www.stanford.edu/~plotkin/lminors.ps
 | year = 1994}}.
*{{citation
 | last1 = Reed | first1 = Bruce | authorlink = Bruce Reed (mathematician)
 | last2 = Wood | first2 = David R.
 | doi = 10.1145/1597036.1597043
 | issue = 4
 | journal = ACM Transactions on Algorithms
 | pages = Article 39
 | title = A linear-time algorithm to find a separator in a graph excluding a minor
 | volume = 5
 | year = 2009}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/0095-8956(83)90079-5
 | issue = 1
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 39–61
 | title = Graph minors. I. Excluding a forest
 | volume = 35
 | year = 1983}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul D. | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/0095-8956(86)90030-4
 | issue = 1
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 92–114
 | title = Graph minors. V. Excluding a planar graph
 | volume = 41
 | year = 1986}}
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul D. | author2-link = Paul Seymour (mathematician)
 | contribution = Excluding a graph with one crossing
 | editor1-last = Robertson | editor1-first = Neil
 | editor2-last = Seymour | editor2-first = Paul
 | pages = 669–675
 | publisher = [[American Mathematical Society]]
 | series = Contemporary Mathematics
 | title = Graph Structure Theory: Proc. AMS–IMS–SIAM Joint Summer Research Conference on Graph Minors
 | volume = 147
 | year = 1993}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul D. | author2-link = Paul Seymour (mathematician)
 | doi = 10.1006/jctb.1995.1006
 | issue = 1
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 65–110
 | title = Graph Minors. XIII. The disjoint paths problem
 | volume = 63
 | year = 1995}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul D. | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/S0095-8956(03)00042-X
 | issue = 1
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 43–76
 | title = Graph Minors. XVI. Excluding a non-planar graph
 | volume = 89
 | year = 2003}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul D. | author2-link = Paul Seymour (mathematician)
 | doi = 10.1016/j.jctb.2004.08.001
 | issue = 2
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 325–357
 | title = Graph Minors. XX. Wagner's conjecture
 | volume = 92
 | year = 2004}}.
*{{citation
 | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician)
 | last2 = Seymour | first2 = Paul | author2-link = Paul Seymour (mathematician)
 | last3 = Thomas | first3 = Robin | author3-link = Robin Thomas (mathematician)
 | doi = 10.1007/BF01202354
 | journal = [[Combinatorica]]
 | pages = 279–361
 | title = Hadwiger's conjecture for ''K''&lt;sub&gt;6&lt;/sub&gt;-free graphs
 | url = http://www.math.gatech.edu/~thomas/PAP/hadwiger.pdf
 | volume = 13
 | year = 1993}}.
*{{citation
 | last = Thomas | first = Robin | authorlink = Robin Thomas (mathematician)
 | contribution = Recent excluded minor theorems for graphs
 | location = Cambridge
 | mr = 1725004
 | pages = 201–222
 | publisher = Cambridge Univ. Press
 | series = London Math. Soc. Lecture Note Ser.
 | title = Surveys in combinatorics, 1999 (Canterbury)
 | url=http://people.math.gatech.edu/~thomas/PAP/bcc.pdf
 | volume = 267
 | year = 1999}}.
*{{citation
 | last = Thomason | first = Andrew
 | doi = 10.1017/S0305004100061521
 | issue = 2
 | journal = [[Mathematical Proceedings of the Cambridge Philosophical Society]]
 | pages = 261–265
 | title = An extremal function for contractions of graphs
 | volume = 95
 | year = 1984| bibcode = 1983MPCPS..95..261T
 }}.
*{{citation
 | last = Thomason | first = Andrew
 | doi = 10.1006/jctb.2000.2013
 | issue = 2
 | journal = [[Journal of Combinatorial Theory|Journal of Combinatorial Theory, Series B]]
 | pages = 318–338
 | title = The extremal function for complete minors
 | volume = 81
 | year = 2001}}.
*{{citation
 | last = Wagner | first = Klaus | author-link = Klaus Wagner
 | doi = 10.1007/BF01594196
 | journal = Math. Ann.
 | pages = 570–590
 | title = Über eine Eigenschaft der ebenen Komplexe
 | volume = 114
 | year = 1937a}}.
*{{citation
 | last = Wagner | first = Klaus | author-link = Klaus Wagner
 | journal = Deutsche Mathematik
 | pages = 280–285
 | title = Über eine Erweiterung des Satzes von Kuratowski
 | volume = 2
 | year = 1937b}}.
{{refend}}

==External links==
*{{mathworld|urlname=GraphMinor|title=Graph Minor}}

{{DEFAULTSORT:Minor (Graph Theory)}}
[[Category:Graph minor theory| ]]
[[Category:Graph theory objects]]</text>
      <sha1>ovzxtav66ycwlcau8z59u76fpu9supp</sha1>
    </revision>
  </page>
  <page>
    <title>Hamming(7,4)</title>
    <ns>0</ns>
    <id>8712675</id>
    <revision>
      <id>871476262</id>
      <parentid>845700012</parentid>
      <timestamp>2018-12-01T09:35:29Z</timestamp>
      <contributor>
        <username>Kiwileaks</username>
        <id>27231030</id>
      </contributor>
      <minor/>
      <comment>Adding a small line about the use of hamming (7,4) in the steane code</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25615">{{infobox code
 | name           = Hamming(7,4)-Code
 | image          = [[File:Hamming(7,4).svg|160px]]
 | image_caption  =
 | namesake       = [[Richard W. Hamming]]
 | type           = [[Linear block code]]
 | block_length   = 7
 | message_length = 4
 | rate           = 4/7 ~ 0.571
 | distance       = 3
 | alphabet_size  = 2
 | notation       = [7,4,3]&lt;sub&gt;2&lt;/sub&gt;-code
 | decoding       =
 | properties     = [[perfect code]]
}}
[[Image:Hamming(7,4).svg|thumb|300px|Graphical depiction of the 4 data bits ''d''&lt;sub&gt;1&lt;/sub&gt; to ''d''&lt;sub&gt;4&lt;/sub&gt; and 3 parity bits ''p''&lt;sub&gt;1&lt;/sub&gt; to ''p''&lt;sub&gt;3&lt;/sub&gt; and which parity bits apply to which data bits]]
In [[coding theory]], '''Hamming(7,4)''' is a [[linear code|linear error-correcting code]] that encodes four [[bit]]s of data into seven bits by adding three [[parity bit]]s. It is a member of a larger family of  [[Hamming code]]s, but the term ''Hamming code'' often refers to this specific code that [[Richard W. Hamming]] introduced in 1950. At the time, Hamming worked at [[Bell Telephone Laboratories]] and was frustrated with the error-prone [[punched card]] reader, which is why he started working on error-correcting codes.&lt;ref&gt;{{cite web | url = http://biobio.loc.edu/chu/web/Courses/Cosi460/hamming_codes.htm | title = History of Hamming Codes | accessdate = 2008-04-03}}&lt;/ref&gt;

The Hamming code adds three additional check bits to every four data bits of the message. Hamming's (7,4) [[algorithm]] can correct any single-bit error, or detect all single-bit and two-bit errors. In other words, the minimal [[Hamming distance]] between any two correct codewords is 3, and received words can be correctly decoded if they are at a distance of at most one from the codeword that was transmitted by the sender. This means that for transmission medium situations where [[error burst|burst errors]] do not occur, Hamming's (7,4) code is effective (as the medium would have to be extremely noisy for two out of seven bits to be flipped).

In [[quantum information]], the Hamming (7,4) is used as the base for the [[Steane code]], a type of [[CSS code]] used for [[quantum error correction]]. 

== Goal ==
The goal of the Hamming codes is to create a set of [[parity bit]]s that overlap such that a single-bit error (the bit is logically flipped in value) in a data bit ''or'' a parity bit can be detected ''and'' corrected. While multiple overlaps can be created, the general method is presented in [[Hamming code#Hamming codes|Hamming codes]].

:{| class="wikitable"
|-
!Bit #  !! 1 !! 2 !! 3 !! 4 !! 5 !! 6 !! 7
|-
!Transmitted bit  !! &lt;math&gt;p_1&lt;/math&gt; !! &lt;math&gt;p_2&lt;/math&gt; !! &lt;math&gt;d_1&lt;/math&gt; !! &lt;math&gt;p_3&lt;/math&gt; !! &lt;math&gt;d_2&lt;/math&gt; !! &lt;math&gt;d_3&lt;/math&gt; !! &lt;math&gt;d_4&lt;/math&gt;
|-
| &lt;math&gt;p_1&lt;/math&gt;
| {{yes}}
| {{No}}
| {{Yes}}
| {{No}}
| {{Yes}}
| {{No}}
| {{Yes}}
|-
| &lt;math&gt;p_2&lt;/math&gt;
| {{No}}
| {{Yes}}
| {{Yes}}
| {{No}}
| {{No}}
| {{Yes}}
| {{Yes}}
|-
| &lt;math&gt;p_3&lt;/math&gt;
| {{No}}
| {{No}}
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|}

This table describes which parity bits cover which transmitted bits in the encoded word. For example, ''p''&lt;sub&gt;2&lt;/sub&gt; provides an even parity for bits 2, 3, 6, and 7. It also details which transmitted bit is covered by which parity bit by reading the column. For example, ''d''&lt;sub&gt;1&lt;/sub&gt; is covered by ''p''&lt;sub&gt;1&lt;/sub&gt; and ''p''&lt;sub&gt;2&lt;/sub&gt; but not ''p''&lt;sub&gt;3&lt;/sub&gt; This table will have a striking resemblance to the parity-check matrix ('''H''') in the next section.

Furthermore, if the parity columns in the above table were removed
:{| class="wikitable"
|-
! !! &lt;math&gt;d_1&lt;/math&gt; !! &lt;math&gt;d_2&lt;/math&gt; !! &lt;math&gt;d_3&lt;/math&gt; !! &lt;math&gt;d_4&lt;/math&gt;
|-
| &lt;math&gt;p_1&lt;/math&gt;
| {{Yes}}
| {{Yes}}
| {{No}}
| {{Yes}}
|-
| &lt;math&gt;p_2&lt;/math&gt;
| {{Yes}}
| {{No}}
| {{Yes}}
| {{Yes}}
|-
| &lt;math&gt;p_3&lt;/math&gt;
| {{No}}
| {{Yes}}
| {{Yes}}
| {{Yes}}
|}
then resemblance to rows 1, 2, and 4 of the code generator matrix ('''G''') below will also be evident.

So, by picking the parity bit coverage correctly, all errors with a Hamming distance of 1 can be detected and corrected, which is the point of using a Hamming code.

== Hamming matrices ==
Hamming codes can be computed in [[linear algebra]] terms through [[matrix (mathematics)|matrices]] because Hamming codes are [[linear code]]s. For the purposes of Hamming codes, two '''Hamming matrices''' can be defined: the '''code [[generator matrix]]''' '''G''' and the '''[[parity-check matrix]]''' '''H''':

:&lt;math&gt;\mathbf{G} := \begin{pmatrix}
 1 &amp; 1 &amp; 0 &amp; 1 \\
 1 &amp; 0 &amp; 1 &amp; 1 \\
 1 &amp; 0 &amp; 0 &amp; 0 \\
 0 &amp; 1 &amp; 1 &amp; 1 \\
 0 &amp; 1 &amp; 0 &amp; 0 \\
 0 &amp; 0 &amp; 1 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}, \qquad \mathbf{H} := \begin{pmatrix}
 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\
 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\
 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
\end{pmatrix}.&lt;/math&gt;

[[Image:Hamming(7,4) as bits.svg|thumb|300px|Bit position of the data and parity bits]]
As mentioned above, rows 1, 2, and 4 of '''G''' should look familiar as they map the data bits to their parity bits:
* ''p''&lt;sub&gt;1&lt;/sub&gt; covers ''d''&lt;sub&gt;1&lt;/sub&gt;, ''d''&lt;sub&gt;2&lt;/sub&gt;, ''d''&lt;sub&gt;4&lt;/sub&gt;
* ''p''&lt;sub&gt;2&lt;/sub&gt; covers ''d''&lt;sub&gt;1&lt;/sub&gt;, ''d''&lt;sub&gt;3&lt;/sub&gt;, ''d''&lt;sub&gt;4&lt;/sub&gt;
* ''p''&lt;sub&gt;3&lt;/sub&gt; covers ''d''&lt;sub&gt;2&lt;/sub&gt;, ''d''&lt;sub&gt;3&lt;/sub&gt;, ''d''&lt;sub&gt;4&lt;/sub&gt;
The remaining rows (3, 5, 6, 7) map the data to their position in encoded form and there is only 1 in that row so it is an identical copy. In fact, these four rows are [[linearly independent]] and form the [[identity matrix]] (by design, not coincidence).

Also as mentioned above, the three rows of '''H''' should be familiar. These rows are used to compute the '''syndrome vector''' at the receiving end and if the syndrome vector is the [[null vector (vector space)|null vector]] (all zeros) then the received word is error-free; if non-zero then the value indicates which bit has been flipped.

The four data bits &amp;mdash; assembled as a vector '''p''' &amp;mdash; is pre-multiplied by '''G''' (i.e., '''Gp''') and taken [[Modulo operation|modulo]] 2 to yield the encoded value that is transmitted. The original 4 data bits are converted to seven bits (hence the name "Hamming(7,4)") with three parity bits added to ensure even parity using the above data bit coverages. The first table above shows the mapping between each data and parity bit into its final bit position (1 through 7) but this can also be presented in a [[Venn diagram]]. The first diagram in this article shows three circles (one for each parity bit) and encloses data bits that each parity bit covers. The second diagram (shown to the right) is identical but, instead, the bit positions are marked.

For the remainder of this section, the following 4 bits (shown as a column vector) will be used as a running example:
: &lt;math&gt;\mathbf{p} = \begin{pmatrix} d_1 \\ d_2 \\ d_3 \\ d_4 \\ \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 1 \\ 1 \end{pmatrix}&lt;/math&gt;

== Channel coding ==
[[Image:Hamming(7,4) example 1011.svg|thumb|300px|Mapping in the example '''x'''. The parity of the red, green, and blue circles are even.]]

Suppose we want to transmit this data (&lt;code&gt;1011&lt;/code&gt;) over a [[signal noise|noisy]] [[channel (communications)|communications channel]]. Specifically, a [[binary symmetric channel]] meaning that error corruption does not favor either zero or one (it is symmetric in causing errors). Furthermore, all source vectors are assumed to be equiprobable. We take the product of '''G''' and '''p''', with entries modulo 2, to determine the transmitted codeword '''x''':

: &lt;math&gt;\mathbf{x} = \mathbf{G} \mathbf{p} =
\begin{pmatrix}
 1 &amp; 1 &amp; 0 &amp; 1 \\
 1 &amp; 0 &amp; 1 &amp; 1 \\
 1 &amp; 0 &amp; 0 &amp; 0 \\
 0 &amp; 1 &amp; 1 &amp; 1 \\
 0 &amp; 1 &amp; 0 &amp; 0 \\
 0 &amp; 0 &amp; 1 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}
\begin{pmatrix} 1 \\ 0 \\ 1 \\ 1 \end{pmatrix} =
\begin{pmatrix} 2 \\ 3 \\ 1 \\ 2 \\ 0 \\ 1 \\ 1 \end{pmatrix} =
\begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \\ 1 \end{pmatrix} &lt;/math&gt;

This means that &lt;code&gt;0110011&lt;/code&gt; would be transmitted instead of transmitting &lt;code&gt;1011&lt;/code&gt;.

Programmers concerned about multiplication should observe that each row of the result is the least significant bit of the [[Hamming weight|Population Count]] of set bits resulting from the row and column being [[Bitwise AND]]ed together rather than multiplied.

In the adjacent diagram, the seven bits of the encoded word are inserted into their respective locations; from inspection it is clear that the parity of the red, green, and blue circles are even:
* red circle has two 1's
* green circle has two 1's
* blue circle has four 1's

What will be shown shortly is that if, during transmission, a bit is flipped then the parity of two or all three circles will be incorrect and the errored bit can be determined (even if one of the parity bits) by knowing that the parity of all three of these circles should be even.

== Parity check ==
If no error occurs during transmission, then the received codeword '''r''' is identical to the transmitted codeword '''x''':

:&lt;math&gt;\mathbf{r} = \mathbf{x}&lt;/math&gt;

The receiver multiplies '''H''' and '''r''' to obtain the '''syndrome''' vector '''z''', which indicates whether an error has occurred, and if so, for which codeword bit.  Performing this multiplication (again, entries modulo 2):

: &lt;math&gt;\mathbf{z} = \mathbf{H}\mathbf{r} = 
\begin{pmatrix}
 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\
 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\
 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\
\end{pmatrix}
\begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \\ 1 \end{pmatrix} =
\begin{pmatrix} 2 \\ 4 \\ 2 \end{pmatrix} = 
\begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} &lt;/math&gt;

Since the syndrome '''z''' is the [[null vector (vector space)|null vector]], the receiver can conclude that no error has occurred.  This conclusion is based on the observation that when the data vector is multiplied by '''G''', a change of basis occurs into a vector subspace that is the [[kernel (matrix)|kernel]] of '''H'''.  As long as nothing happens during transmission, '''r''' will remain in the kernel of '''H''' and the multiplication will yield the null vector.

== Error correction ==
Otherwise, suppose a ''single'' bit error has occurred.  Mathematically, we can write

:&lt;math&gt;\mathbf{r}  = \mathbf{x} +\mathbf{e}_i&lt;/math&gt;

modulo 2, where '''e'''&lt;sub&gt;''i''&lt;/sub&gt; is the &lt;math&gt;i_{th}&lt;/math&gt; [[unit vector]], that is, a zero vector with a 1 in the &lt;math&gt;i^{th}&lt;/math&gt;, counting from 1.

: &lt;math&gt;\mathbf{e}_2 = \begin{pmatrix} 0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{pmatrix}&lt;/math&gt;

Thus the above expression signifies a single bit error in the &lt;math&gt;i^{th}&lt;/math&gt; place.

Now, if we multiply this vector by '''H''':

:&lt;math&gt;\mathbf{Hr} = \mathbf{H} \left( \mathbf{x}+\mathbf{e}_i \right) = \mathbf{Hx} + \mathbf{He}_i&lt;/math&gt;

Since '''x''' is the transmitted data, it is without error, and as a result, the product of '''H''' and '''x''' is zero. Thus

: &lt;math&gt; \mathbf{Hx} + \mathbf{He}_i = \mathbf{0} + \mathbf{He}_i = \mathbf{He}_i&lt;/math&gt;

Now, the product of '''H''' with the &lt;math&gt;i^{th}&lt;/math&gt; standard basis vector picks out that column of '''H''', we know the error occurs in the place where this column of  '''H''' occurs.

For example, suppose we have introduced a bit error on bit #5

: &lt;math&gt;\mathbf{r} = \mathbf{x}+\mathbf{e}_5 = \begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \\ 1 \end{pmatrix} + \begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 1 \\ 0 \\ 0 \end{pmatrix} = \begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 1 \\ 1 \\ 1 \end{pmatrix}&lt;/math&gt;

[[Image:Hamming(7,4) example 1011 bit 5 error.svg|thumb|300px|A bit error on bit 5 causes bad parity in the red and green circles]]
The diagram to the right shows the bit error (shown in blue text) and the bad parity created (shown in red text) in the red and green circles. The bit error can be detected by computing the parity of the red, green, and blue circles. If a bad parity is detected then the data bit that overlaps ''only'' the bad parity circles is the bit with the error. In the above example, the red and green circles have bad parity so the bit corresponding to the intersection of red and green but not blue indicates the errored bit.

Now,

: &lt;math&gt;\mathbf{z} = \mathbf{Hr} = \begin{pmatrix} 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \\ \end{pmatrix} 
\begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 1 \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 3 \\ 4 \\ 3 \end{pmatrix} =  \begin{pmatrix} 1 \\ 0 \\ 1 \end{pmatrix} &lt;/math&gt;

which corresponds to the fifth column of '''H'''. Furthermore, the general algorithm used (''see [[Hamming code#General algorithm]]'') was intentional in its construction so that the syndrome of 101 corresponds to the binary value of 5, which indicates the fifth bit was corrupted. Thus, an error has been detected in bit 5, and can be corrected (simply flip or negate its value):

:&lt;math&gt; \mathbf{r}_{\text{corrected}} =  \begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ \overline{1} \\ 1 \\ 1 \end{pmatrix} = \begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \\ 1 \end{pmatrix} &lt;/math&gt;

This corrected received value indeed, now, matches the transmitted value '''x''' from above.

== Decoding ==
Once the received vector has been determined to be error-free or corrected if an error occurred (assuming only zero or one bit errors are possible) then the received data needs to be decoded back into the original four bits.

First, define a matrix '''R''':

:&lt;math&gt;\mathbf{R} = \begin{pmatrix}
 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix} &lt;/math&gt;

Then the received value, '''p&lt;sub&gt;r&lt;/sub&gt;''', is equal to '''Rr'''. Using the running example from above

:&lt;math&gt;\mathbf{p_r} = \begin{pmatrix}
 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
\end{pmatrix}
\begin{pmatrix} 0 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \\ 1  \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \\ 1 \\ 1 \end{pmatrix} &lt;/math&gt;

== Multiple bit errors ==
[[Image:Hamming(7,4) example 1011 bits 4 &amp; 5 error.svg|thumb|300px|A bit error on bit 4 &amp; 5 are introduced (shown in blue text) with a bad parity only in the green circle (shown in red text)]]

It is not difficult to show that only single bit errors can be corrected using this scheme. Alternatively, Hamming codes can be used to detect single and double bit errors, by merely noting that the product of '''H''' is nonzero whenever errors have occurred. In the adjacent diagram, bits 4 and 5 were flipped. This yields only one circle (green) with an invalid parity but the errors are not recoverable.

However, the Hamming (7,4) and similar Hamming codes cannot distinguish between single-bit errors and two-bit errors. That is, two-bit errors appear the same as one-bit errors. If error correction is performed on a two-bit error the result will be incorrect.

Similarly, Hamming codes cannot detect or recover from an arbitrary three-bit error; Consider the diagram: if the bit in the green circle (colored red) were 1, the parity checking would return the null vector, indicating that there is no error in the codeword.

{{clear}}

== All codewords ==
Since the source is only 4 bits then there are only 16 possible transmitted words. Included is the eight-bit value if an extra parity bit is used (''see [[Hamming code#.5B7.2C4.5D Hamming code with an additional parity bit|Hamming(7,4) code with an additional parity bit]]''). (The data bits are shown in blue; the parity bits are shown in red; and the extra parity bit shown in green.)

{| class="wikitable"
|-
!rowspan="2"| Data&lt;BR&gt;&lt;math&gt;({\color{blue}d_1}, {\color{blue}d_2}, {\color{blue}d_3}, {\color{blue}d_4})&lt;/math&gt;
!colspan="2"| Hamming(7,4)
!colspan="2"| Hamming(7,4) with extra parity bit (Hamming(8,4))
|-
! Transmitted&lt;BR&gt;&lt;math&gt;({\color{red}p_1}, {\color{red}p_2}, {\color{blue}d_1}, {\color{red}p_3}, {\color{blue}d_2}, {\color{blue}d_3}, {\color{blue}d_4})&lt;/math&gt;
! Diagram
! Transmitted&lt;BR&gt;&lt;math&gt;({\color{red}p_1}, {\color{red}p_2}, {\color{blue}d_1}, {\color{red}p_3}, {\color{blue}d_2}, {\color{blue}d_3}, {\color{blue}d_4}, {\color{green}p_4})&lt;/math&gt;
! Diagram
|-
| &lt;span style="color:blue;"&gt;0000&lt;/span&gt;
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;000&lt;/span&gt;
| [[Image:Hamming(7,4) example 0000.svg|150px|Hamming code for 0000 becomes 0000000]]
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;000&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 0000 with extra parity.svg|150px|Hamming code for 0000 becomes 0000000 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;1000&lt;/span&gt;
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;000&lt;/span&gt;
| [[Image:Hamming(7,4) example 1000.svg|150px|Hamming code for 1000 becomes 1000011]]
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;000&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 1000 with extra parity.svg|150px|Hamming code for 1000 becomes 1000011 with extra parity bit 1]]
|-
| &lt;span style="color:blue;"&gt;0100&lt;/span&gt;
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;100&lt;/span&gt;
| [[Image:Hamming(7,4) example 0100.svg|150px|Hamming code for 0100 becomes 0100101]]
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;100&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 0100 with extra parity.svg|150px|Hamming code for 0100 becomes 0100101 with extra parity bit 1]]
|-
| &lt;span style="color:blue;"&gt;1100&lt;/span&gt;
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;100&lt;/span&gt;
| [[Image:Hamming(7,4) example 1100.svg|150px|Hamming code for 1100 becomes 1100110]]
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;100&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 1100 with extra parity.svg|150px|Hamming code for 1100 becomes 1100110 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;0010&lt;/span&gt;
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;010&lt;/span&gt;
| [[Image:Hamming(7,4) example 0010.svg|150px|Hamming code for 0010 becomes 0010110]]
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;010&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 0010 with extra parity.svg|150px|Hamming code for 0010 becomes 0010110 with extra parity bit 1]]
|-
| &lt;span style="color:blue;"&gt;1010&lt;/span&gt;
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;010&lt;/span&gt;
| [[Image:Hamming(7,4) example 1010.svg|150px|Hamming code for 1010 becomes 1010101]]
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;010&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 1010 with extra parity.svg|150px|Hamming code for 1010 becomes 1010101 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;0110&lt;/span&gt;
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;110&lt;/span&gt;
| [[Image:Hamming(7,4) example 0110.svg|150px|Hamming code for 0110 becomes 0110011]]
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;110&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 0110 with extra parity.svg|150px|Hamming code for 0110 becomes 0110011 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;1110&lt;/span&gt;
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;110&lt;/span&gt;
| [[Image:Hamming(7,4) example 1110.svg|150px|Hamming code for 1110 becomes 1110000]]
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;110&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 1110 with extra parity.svg|150px|Hamming code for 1110 becomes 1110000 with extra parity bit 1]]
|-
| &lt;span style="color:blue;"&gt;0001&lt;/span&gt;
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;001&lt;/span&gt;
| [[Image:Hamming(7,4) example 0001.svg|150px|Hamming code for 0001 becomes 0001111]]
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;001&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 0001 with extra parity.svg|150px|Hamming code for 0001 becomes 0001111 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;1001&lt;/span&gt;
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;001&lt;/span&gt;
| [[Image:Hamming(7,4) example 1001.svg|150px|Hamming code for 1001 becomes 1001100]]
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;001&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 1001 with extra parity.svg|150px|Hamming code for 1001 becomes 1001100 with extra parity bit 1]]
|-
| &lt;span style="color:blue;"&gt;0101&lt;/span&gt;
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;101&lt;/span&gt;
| [[Image:Hamming(7,4) example 0101.svg|150px|Hamming code for 0101 becomes 0101010]]
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;101&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 0101 with extra parity.svg|150px|Hamming code for 0101 becomes 0101010 with extra parity bit 1]]
|-
| &lt;span style="color:blue;"&gt;1101&lt;/span&gt;
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;101&lt;/span&gt;
| [[Image:Hamming(7,4) example 1101.svg|150px|Hamming code for 1101 becomes 1101001]]
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;101&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 1101 with extra parity.svg|150px|Hamming code for 1101 becomes 1101001 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;0011&lt;/span&gt;
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;011&lt;/span&gt;
| [[Image:Hamming(7,4) example 0011.svg|150px|Hamming code for 0011 becomes 0011001]]
| &lt;span style="color:red;"&gt;10&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;011&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 0011 with extra parity.svg|150px|Hamming code for 0011 becomes 0011001 with extra parity bit 1]]
|-
| &lt;span style="color:blue;"&gt;1011&lt;/span&gt;
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;011&lt;/span&gt;
| [[Image:Hamming(7,4) example 1011.svg|150px|Hamming code for 1011 becomes 1011010]]
| &lt;span style="color:red;"&gt;01&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;0&lt;/span&gt;&lt;span style="color:blue;"&gt;011&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 1011 with extra parity.svg|150px|Hamming code for 1011 becomes 1011010 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;0111&lt;/span&gt;
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;111&lt;/span&gt;
| [[Image:Hamming(7,4) example 0111.svg|150px|Hamming code for 0111 becomes 0111100]]
| &lt;span style="color:red;"&gt;00&lt;/span&gt;&lt;span style="color:blue;"&gt;0&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;111&lt;/span&gt;&lt;span style="color:green;"&gt;0&lt;/span&gt;
| [[Image:Hamming(7,4) example 0111 with extra parity.svg|150px|Hamming code for 0111 becomes 0111100 with extra parity bit 0]]
|-
| &lt;span style="color:blue;"&gt;1111&lt;/span&gt;
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;111&lt;/span&gt;
| [[Image:Hamming(7,4) example 1111.svg|150px|Hamming code for 1111 becomes 1111111]]
| &lt;span style="color:red;"&gt;11&lt;/span&gt;&lt;span style="color:blue;"&gt;1&lt;/span&gt;&lt;span style="color:red;"&gt;1&lt;/span&gt;&lt;span style="color:blue;"&gt;111&lt;/span&gt;&lt;span style="color:green;"&gt;1&lt;/span&gt;
| [[Image:Hamming(7,4) example 1111 with extra parity.svg|150px|Hamming code for 1111 becomes 1111111 with extra parity bit 1]]
|}

== References ==
{{reflist}}

== External links ==
* [http://acm.timus.ru/problem.aspx?space=1&amp;num=1792 A programming problem about the Hamming Code(7,4)]
* [http://toolmenow.com/34/Hamming(7,4)-Code-Calculator Hamming (7,4) Code Calculator]
* [http://www.toolmenow.com/31/Hamming(7,4)-Code-Checker Hamming (7,4) Code Checker]
[[Category:Coding theory]]
[[Category:Error detection and correction]]
[[Category:Computer arithmetic]]</text>
      <sha1>mpcqw49cd7lsvslmhjrd1kwps19wfod</sha1>
    </revision>
  </page>
  <page>
    <title>Homogeneous coordinates</title>
    <ns>0</ns>
    <id>243316</id>
    <revision>
      <id>863094372</id>
      <parentid>863094301</parentid>
      <timestamp>2018-10-08T17:44:00Z</timestamp>
      <contributor>
        <username>Shellwood</username>
        <id>2366721</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/49.128.173.202|49.128.173.202]] ([[User talk:49.128.173.202|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26643">[[File:RationalBezier2D.svg|thumb|Rational Bézier curve &amp;ndash; polynomial curve defined in homogeneous coordinates (blue) and its projection on plane &amp;ndash; rational curve (red)]]
In [[mathematics]], '''homogeneous coordinates''' or '''projective coordinates''', introduced by [[August Ferdinand Möbius]] in his 1827 work ''Der barycentrische Calcül'',&lt;ref&gt;{{MacTutor|class=Biographies|id=Mobius|title=August Ferdinand Möbius}}&lt;/ref&gt;&lt;ref&gt;
{{cite book |title=History of Modern Mathematics|first=David Eugene|last=Smith
|publisher=J. Wiley &amp; Sons|year=1906|isbn=|page=53
|url=https://books.google.com/books?id=6DpBAAAAYAAJ&amp;pg=PA53#v=onepage}}&lt;/ref&gt; are a system of coordinates used in [[projective geometry]], as [[Cartesian coordinate system|Cartesian coordinates]] are used in [[Euclidean geometry]]. They have the advantage that the coordinates of points, including points at infinity, can be represented using finite coordinates. Formulas involving homogeneous coordinates are often simpler and more symmetric than their Cartesian counterparts. Homogeneous coordinates have a range of applications, including [[computer graphics]] and 3D [[computer vision]], where they allow [[affine transformation]]s and, in general, [[projective transformation]]s to be easily represented by a matrix.

If the homogeneous coordinates of a point are multiplied by a non-zero scalar then the resulting coordinates represent the same point. Since homogeneous coordinates are also given to [[point at infinity|points at infinity]], the number of coordinates required to allow this extension is one more than the dimension of the [[projective space]] being considered. For example, two homogeneous coordinates are required to specify a point on the projective line and three homogeneous coordinates are required to specify a point in the projective plane.
&lt;!--
This to too mathy for the lead section, try to merge with later section:
Therefore this system of coordinates can be explained as follows: if the projective space is constructed from a vector space ''V'' of dimension ''n''&amp;nbsp;+&amp;nbsp;1, introduce coordinates in ''V'' by choosing a basis, and use these in ''P''(''V''), the equivalence classes of proportional non-zero vectors in ''V''. --&gt;

==Introduction==
The [[projective plane#Extended Euclidean plane|real projective plane]] can be thought of as the [[Euclidean geometry|Euclidean plane]] with additional points added, which are called [[point at infinity|points at infinity]], and are considered to lie on a new line, the [[line at infinity]]. There is a point at infinity corresponding to each direction (numerically given by the slope of a line), informally defined as the limit of a point that moves in that direction away from the origin. Parallel lines in the Euclidean plane are said to intersect at a point at infinity corresponding to their common direction. Given a point {{nowrap|(''x'', ''y'')}} on the Euclidean plane, for any non-zero real number ''Z'', the triple {{nowrap|(''xZ'', ''yZ'', ''Z'')}} is called a ''set of homogeneous coordinates'' for the point. By this definition, multiplying the three homogeneous coordinates by a common, non-zero factor gives a new set of homogeneous coordinates for the same point. In particular, {{nowrap|(''x'', ''y'', 1)}} is such a system of homogeneous coordinates for the point {{nowrap|(''x'', ''y'')}}.
For example, the Cartesian point {{nowrap|(1, 2)}} can be represented in homogeneous coordinates as {{nowrap|(1, 2, 1)}} or {{nowrap|(2, 4, 2)}}. The original Cartesian coordinates are recovered by dividing the first two positions by the third. Thus unlike Cartesian coordinates, a single point can be represented by infinitely many homogeneous coordinates.

The equation of a line through the origin {{nowrap|(0, 0)}} may be written {{nowrap|1=''nx'' + ''my'' = 0}} where ''n'' and ''m'' are not both 0. In [[Parametric equation|parametric]] form this can be written {{nowrap|1 = ''x'' = ''mt'', ''y'' = −''nt''}}. Let ''Z'' = 1/''t'', so the coordinates of a point on the line may be written {{nowrap|1=(''m''/''Z'',  −''n''/''Z'') }}. In homogeneous coordinates this becomes {{nowrap|(''m'',  −''n'', ''Z'')}}. In the limit, as ''t'' approaches infinity, in other words, as the point moves away from the origin, ''Z'' approaches 0 and the homogeneous coordinates of the point become {{nowrap|(''m'', −''n'', 0)}}. Thus we define {{nowrap|(''m'', −''n'', 0)}} as the homogeneous coordinates of the point at infinity corresponding to the direction of the line {{nowrap|1=''nx'' + ''my'' = 0}}. As any line of the Euclidean plane is parallel to a line passing through the origin, and since parallel lines have the same point at infinity, the infinite point on every line of the Euclidean plane has been given homogeneous coordinates.

To summarize:
*Any point in the projective plane is represented by a triple {{nowrap|(''X'', ''Y'', ''Z'')}}, called the '''homogeneous coordinates''' or '''projective coordinates''' of the point, where ''X'', ''Y'' and ''Z'' are not all 0. 
*The point represented by a given set of homogeneous coordinates is unchanged if the coordinates are multiplied by a common factor.
*Conversely, two sets of homogeneous coordinates represent the same point if and only if one is obtained from the other by multiplying all the coordinates by the same non-zero constant.
*When ''Z'' is not 0 the point represented is the point {{nowrap|(''X/Z'', ''Y/Z'')}} in the Euclidean plane.
*When ''Z'' is 0 the point represented is a point at infinity.
Note that the triple {{nowrap|(0, 0, 0)}} is omitted and does not represent any point. The origin is represented by {{nowrap|(0, 0, 1)}}.&lt;ref&gt;For the section: {{harvnb|Jones|1912| pages= 120&amp;ndash;122}}&lt;/ref&gt;

===Notation===
Some authors use different notations for homogeneous coordinates which help distinguish them from Cartesian coordinates. The use of colons instead of commas, for example (''x'':''y'':''z'') instead of {{nowrap|(''x'', ''y'', ''z'')}}, emphasizes that the coordinates are to be considered ratios.&lt;ref&gt;{{harvnb|Woods|1922}}&lt;/ref&gt; Square brackets, as in {{nowrap|[''x'', ''y'', ''z'']}} emphasize that multiple sets of coordinates are associated with a single point.&lt;ref&gt;{{harvnb|Garner|1981}}&lt;/ref&gt; Some authors use a combination of colons and square brackets, as in [''x'':''y'':''z''].&lt;ref&gt;{{harvnb|Miranda|1995}}&lt;/ref&gt;

==Other dimensions==
The discussion in the preceding section applies analogously to projective spaces other than the plane. So the points on the [[projective line]] may be represented by pairs of coordinates {{nowrap|(''x'', ''y'')}}, not both zero. In this case, the point at infinity is {{nowrap|(1, 0)}}. Similarly the points in projective ''n''-space are represented by (''n''&amp;nbsp;+&amp;nbsp;1)-tuples.&lt;ref&gt;{{harvnb|Bôcher|1907|pp= 13&amp;ndash;14}}&lt;/ref&gt;

==Other projective spaces==
The use of [[real number]]s gives the homogeneous coordinates of points in the classical case of the real projective spaces, however any [[field (mathematics)|field]] may be used, in particular, the [[complex number]]s may be used for [[complex projective space]]. For example, the [[complex projective line]] uses two homogeneous complex coordinates and is known as the [[Riemann sphere]]. Other fields, including [[finite field]]s, can be used.

Homogeneous coordinates for projective spaces can also be created with elements from a [[division ring]] (skewfield). However, in this case, care must be taken to account for the fact that multiplication may not be [[Commutative property|commutative]].&lt;ref&gt;{{harvnb|Garner|1981|pp=32&amp;ndash;33}}&lt;/ref&gt;

==Alternative definition==
Another definition of the real projective plane can be given in terms of [[equivalence class]]es. For non-zero elements of '''R'''&lt;sup&gt;3&lt;/sup&gt;, define {{nowrap|(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, ''z''&lt;sub&gt;1&lt;/sub&gt;) ~ (''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;, ''z''&lt;sub&gt;2&lt;/sub&gt;)}} to mean there is a non-zero ''λ'' so that {{nowrap|1=(''x''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, ''z''&lt;sub&gt;1&lt;/sub&gt;) = (''λx''&lt;sub&gt;2&lt;/sub&gt;, ''λy''&lt;sub&gt;2&lt;/sub&gt;, ''λz''&lt;sub&gt;2&lt;/sub&gt;)}}. Then ~ is an [[equivalence relation]] and the projective plane can be defined as the equivalence classes of {{nowrap|'''R'''&lt;sup&gt;3&lt;/sup&gt; ∖ {0}.}} If {{nowrap|(''x'', ''y'', ''z'')}} is one of the elements of the equivalence class ''p'' then these are taken to be homogeneous coordinates of ''p''.

Lines in this space are defined to be sets of solutions of equations of the form {{nowrap|1=''ax'' + ''by'' + ''cz'' = 0}} where not all of ''a'', ''b'' and ''c'' are zero. The condition {{nowrap|1=''ax'' + ''by'' + ''cz'' = 0}} depends only on the equivalence class of {{nowrap|(''x'', ''y'', ''z'')}} so the equation defines a set of points in the projective plane. The mapping {{nowrap|(''x'', ''y'') → (''x'', ''y'', 1)}} defines an inclusion from the Euclidean plane to the projective plane and the complement of the image is the set of points with {{nowrap|1=''z'' = 0}}. This is the equation of a line according to the definition and the complement is called the ''line at infinity''.

The equivalence classes, ''p'', are the lines through the origin with the origin removed. The origin does not really play an essential part in the previous discussion so it can be added back in without changing the properties of the projective plane. This produces a variation on the definition, namely the projective plane is defined as the set of lines in '''R'''&lt;sup&gt;3&lt;/sup&gt; that pass through the origin and the coordinates of a non-zero element {{nowrap|(''x'', ''y'', ''z'')}} of a line are taken to be homogeneous coordinates of the line. These lines are now interpreted as points in the projective plane.

Again, this discussion applies analogously to other dimensions. So the projective space of dimension ''n'' can be defined as the set of lines through the origin in '''R'''&lt;sup&gt;''n''+1&lt;/sup&gt;.&lt;ref&gt;For the section: {{harvnb|Cox|Little|O'Shea|2007|pp=360&amp;ndash;362}}&lt;/ref&gt;

==Homogeneity==
Homogeneous coordinates are not uniquely determined by a point, so a function defined on the coordinates, say {{nowrap|''f''(''x'', ''y'', ''z'')}}, does not determine a function defined on points as with Cartesian coordinates. But a condition {{nowrap|1=''f''(''x'', ''y'', ''z'') = 0}} defined on the coordinates, as might be used to describe a curve, determines a condition on points if the function is [[Homogeneous function|homogeneous]]. Specifically, suppose there is a ''k'' such that

:&lt;math&gt;f(\lambda x, \lambda y, \lambda z) = \lambda^k f(x,y,z).\,&lt;/math&gt;

If a set of coordinates represent the same point as {{nowrap|(''x'', ''y'', ''z'')}} then it can be written {{nowrap|(λ''x'', λ''y'', λ''z'')}} for some non-zero value of λ. Then

:&lt;math&gt; f(x,y,z)=0 \iff f(\lambda x, \lambda y, \lambda z) = \lambda^k f(x,y,z)=0.&lt;/math&gt;

A [[polynomial]] {{nowrap|''g''(''x'', ''y'')}} of degree ''k'' can be turned into a [[homogeneous polynomial]] by replacing ''x'' with ''x''/''z'', ''y'' with ''y''/''z'' and multiplying by ''z&lt;sup&gt;k&lt;/sup&gt;'', in other words by defining

:&lt;math&gt;f(x, y, z)=z^k g(x/z, y/z).\,&lt;/math&gt;

The resulting function ''f'' is a polynomial so it makes sense to extend its domain to triples where {{nowrap|1=''z'' = 0}}. The process can be reversed by setting {{nowrap|1=''z'' = 1}}, or

:&lt;math&gt;g(x, y)=f(x, y, 1).\,&lt;/math&gt;

The equation {{nowrap|1=''f''(''x'', ''y'', ''z'') = 0}} can then be thought of as the homogeneous form of {{nowrap|1=''g''(''x'', ''y'') = 0}} and it defines the same curve when restricted to the Euclidean plane. For example, the homogeneous form of the equation of the line {{nowrap|1=''ax'' + ''by'' + ''c'' = 0}} is {{nowrap|1=''ax'' + ''by'' + ''cz'' = 0.}}&lt;ref&gt;For the section: {{harvnb|Miranda|1995|p= 14}} and {{harvnb|Jones|1912|p= 120}}&lt;/ref&gt;

==Line coordinates and duality==
{{Main|Duality (projective geometry)}}
The equation of a line in the projective plane may be given as {{nowrap|1=''sx'' + ''ty'' + ''uz'' = 0}} where ''s'', ''t'' and ''u'' are constants. Each triple {{nowrap|(''s'', ''t'', ''u'')}} determines a line, the line determined is unchanged if it is multiplied by a non-zero scalar, and at least one of ''s'', ''t'' and ''u'' must be non-zero. So the triple {{nowrap|(''s'', ''t'', ''u'')}} may be taken to be homogeneous coordinates of a line in the projective plane, that is [[line coordinates]] as opposed to point coordinates. If in ''sx''&amp;nbsp;+&amp;nbsp;''ty''&amp;nbsp;+&amp;nbsp;''uz''&amp;nbsp;=&amp;nbsp;0 the letters ''s'', ''t'' and ''u'' are taken as variables and ''x'', ''y'' and ''z'' are taken as constants then the equation becomes an equation of a set of lines in the space of all lines in the plane. Geometrically it represents the set of lines that pass through the point {{nowrap|(''x'', ''y'', ''z'')}} and may be interpreted as the equation of the point in line-coordinates. In the same way, planes in 3-space may be given sets of four homogeneous coordinates, and so on for higher dimensions.&lt;ref&gt;{{harvnb|Bôcher|1907|pp= 107&amp;ndash;108}} (adapted to the plane according to the footnote on p. 108)&lt;/ref&gt;

The same relation, {{nowrap|1=''sx'' + ''ty'' + ''uz'' = 0}}, may be regarded as either the equation of a line or the equation of a point. In general, there is no difference either algebraically or logically between the homogeneous coordinates of points and lines. So plane geometry with points as the fundamental elements and plane geometry with lines as the fundamental elements are equivalent except for interpretation. This leads to the concept of ''duality'' in projective geometry, the principle that the roles of points and lines can be interchanged in a theorem in projective geometry and the result will also be a theorem. Analogously, the theory of points in projective 3-space is dual to the theory of planes in projective 3-space, and so on for higher dimensions.&lt;ref&gt;{{harvnb|Woods|1922|pp= 2, 40}}&lt;/ref&gt;

==Plücker coordinates==
{{Main|Plücker coordinates}}
Assigning coordinates to lines in projective 3-space is more complicated since it would seem that a total of 8 coordinates, either the coordinates of two points which lie on the line or two planes whose intersection is the line, are required. A useful method, due to [[Julius Plücker]], creates a set of six coordinates as the determinants {{nowrap|1=''x''&lt;sub&gt;''i''&lt;/sub&gt;''y''&lt;sub&gt;''j''&lt;/sub&gt; − ''x''&lt;sub&gt;''j''&lt;/sub&gt;''y''&lt;sub&gt;''i''&lt;/sub&gt; (1 ≤ ''i'' &lt; ''j'' ≤ 4)}} from the homogeneous coordinates of two points {{nowrap|(''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ''x''&lt;sub&gt;3&lt;/sub&gt;, ''x''&lt;sub&gt;4&lt;/sub&gt;)}} and {{nowrap|(''y''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;3&lt;/sub&gt;, ''y''&lt;sub&gt;4&lt;/sub&gt;)}} on the line. The [[Plücker embedding]] is the generalization of this to create homogeneous coordinates of elements of any dimension ''m'' in a projective space of dimension ''n''.&lt;ref&gt;{{harvnb|Wilczynski|1906|p=50}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Bôcher|1907|p= 110}}&lt;/ref&gt;

==Application to Bézout's theorem==
[[Bézout's theorem]] predicts that the number of points of intersection of two curves is equal to the product of their degrees (assuming an algebraically closed field and with certain conventions followed for counting intersection multiplicities). Bézout's theorem predicts there is one point of intersection of two lines and in general this is true, but when the lines are parallel the point of intersection is infinite. Homogeneous coordinates are used to locate the point of intersection in this case. Similarly, Bézout's theorem predicts that a line will intersect a conic at two points, but in some cases one or both of the points is infinite and homogeneous coordinates must be used to locate them. For example, {{nowrap|1=''y'' = ''x''&lt;sup&gt;2&lt;/sup&gt;}} and {{nowrap|1=''x'' = 0}} have only one point of intersection in the finite (affine) plane. To find the other point of intersection, convert the equations into homogeneous form, {{nowrap|1=''yz'' = ''x''&lt;sup&gt;2&lt;/sup&gt;}} and {{nowrap|1=''x'' = 0}}. This produces {{nowrap|1=''x'' = ''yz'' = 0}} and, assuming not all of ''x'', ''y'' and ''z'' are 0, the solutions are {{nowrap|1=''x'' = ''y'' = 0, ''z'' ≠ 0}} and {{nowrap|1=''x'' = ''z'' = 0, ''y'' ≠ 0}}. This first solution is the point {{nowrap|(0, 0)}} in Cartesian coordinates, the finite point of intersection. The second solution gives the homogeneous coordinates {{nowrap|(0, 1, 0)}} which corresponds to the direction of the ''y''-axis. For the equations {{nowrap|1=''xy'' = 1}} and {{nowrap|1=''x'' = 0}} there are no finite points of intersection. Converting the equations into homogeneous form gives {{nowrap|1=''xy'' = ''z''&lt;sup&gt;2&lt;/sup&gt;}} and {{nowrap|1=''x'' = 0}}. Solving produces the equation {{nowrap|1=''z''&lt;sup&gt;2&lt;/sup&gt; = 0}} which has a double root at {{nowrap|1=''z'' = 0}}. From the original equation, {{nowrap|1=''x'' = 0}}, so {{nowrap|1=''y'' ≠ 0}} since at least one coordinate must be non-zero. Therefore, {{nowrap|(0, 1, 0)}} is the point of intersection counted with multiplicity 2 in agreement with the theorem.&lt;ref&gt;{{harvnb|Jones|1912|pp= 117&amp;ndash;118, 122}} with simplified examples.&lt;/ref&gt;

==Circular points==
{{Main|Circular points at infinity}}
The homogeneous form for the equation of a circle in the real or complex projective plane is {{nowrap|1=''x''&lt;sup&gt;2&lt;/sup&gt; + ''y''&lt;sup&gt;2&lt;/sup&gt; + 2''axz'' + 2''byz'' + c''z''&lt;sup&gt;2&lt;/sup&gt; = 0}}. The intersection of this curve with the line at infinity can be found by setting {{nowrap|1=''z'' = 0}}. This produces the equation {{nowrap|1=''x''&lt;sup&gt;2&lt;/sup&gt; + ''y''&lt;sup&gt;2&lt;/sup&gt; = 0}} which has two solutions over the complex numbers, giving rise to the points with homogeneous coordinates {{nowrap|(1, ''i'', 0)}} and {{nowrap|(1, −''i'', 0)}} in the complex projective plane. These points are called the [[circular points at infinity]] and can be regarded as the common points of intersection of all circles. This can be generalized to curves of higher order as [[circular algebraic curve]]s.&lt;ref&gt;{{harvnb|Jones|1912|p= 204}}&lt;/ref&gt;

==Change of coordinate systems==
Just as the selection of axes in the Cartesian coordinate system is somewhat arbitrary, the selection of a single system of homogeneous coordinates out of all possible systems is somewhat arbitrary. Therefore, it is useful to know how the different systems are related to each other.

Let {{nowrap|(''x'', ''y'', ''z'')}} be the homogeneous coordinates of a point in the projective plane. A fixed matrix
:&lt;math&gt;A=\begin{pmatrix}a&amp;b&amp;c\\d&amp;e&amp;f\\g&amp;h&amp;i\end{pmatrix},&lt;/math&gt;
with nonzero [[determinant]], defines a new system of coordinates {{nowrap|(''X'', ''Y'', ''Z'')}} by the equation
:&lt;math&gt;\begin{pmatrix}X\\Y\\ Z\end{pmatrix}=A\begin{pmatrix}x\\y\\z\end{pmatrix}.&lt;/math&gt;
Multiplication of {{nowrap|(''x'', ''y'', ''z'')}} by a scalar results in the multiplication of {{nowrap|(''X'', ''Y'', ''Z'')}} by the same scalar, and ''X'', ''Y'' and ''Z'' cannot be all 0 unless ''x'', ''y'' and ''z'' are all zero since ''A'' is nonsingular. So {{nowrap|(''X'', ''Y'', ''Z'')}} are a new system of homogeneous coordinates for the same point of the projective plane.

==Barycentric coordinates==
{{Main|Barycentric coordinates (mathematics)}}
Möbius' original formulation of homogeneous coordinates specified the position of a point as the [[center of mass]] (or barycenter) of a system of three point masses placed at the vertices of a fixed triangle. Points within the triangle are represented by positive masses and points outside the triangle are represented by allowing negative masses. Multiplying the masses in the system by a scalar does not affect the center of mass, so this is a special case of a system of homogeneous coordinates.

==Trilinear coordinates==
{{Main|Trilinear coordinates}}
Let ''l'', ''m'', ''n'' be three lines in the plane and define a set of coordinates ''X'', ''Y'' and ''Z'' of a point ''p'' as the signed distances from ''p'' to these three lines. These are called the ''trilinear coordinates'' of ''p'' with respect to the triangle whose vertices are the pairwise intersections of the lines. Strictly speaking these are not homogeneous, since the values of ''X'', ''Y'' and ''Z'' are determined exactly, not just up to proportionality. There is a linear relationship between them however, so these coordinates can be made homogeneous by allowing multiples of {{nowrap|(''X'', ''Y'', ''Z'')}} to represent the same point. More generally, ''X'', ''Y'' and ''Z'' can be defined as constants ''p'', ''r'' and ''q'' times the distances to ''l'', ''m'' and ''n'', resulting in a different system of homogeneous coordinates with the same triangle of reference. This is, in fact, the most general type of system of homogeneous coordinates for points in the plane if none of the lines is the line at infinity.&lt;ref&gt;{{harvnb|Jones|1912|pp= 452 ff}}&lt;/ref&gt;

==Use in computer graphics and computer vision==
{{See also|Transformation matrix}}

Homogeneous coordinates are ubiquitous in computer graphics because they allow common vector operations such as [[Translation (geometry)|translation]], [[Rotation (mathematics)|rotation]], [[Scaling (geometry)|scaling]] and [[perspective projection]] to be represented as a matrix by which the vector is multiplied. By the chain rule, any sequence of such operations can be multiplied out into a single matrix, allowing simple and efficient processing. By contrast, using Cartesian coordinates, translations and perspective projection cannot be expressed as matrix multiplications, though other operations can. Modern [[OpenGL]] and [[Microsoft Direct3D|Direct3D]] [[graphics card]]s take advantage of homogeneous coordinates to implement a [[vertex shader]] efficiently using [[vector processor]]s with 4-element registers.&lt;ref&gt;{{cite web|url=http://msdn.microsoft.com/en-us/library/bb206341(VS.85).aspx|title=Viewports and Clipping (Direct3D 9) (Windows)|author=|date=|website=msdn.microsoft.com|accessdate=10 April 2018}}&lt;/ref&gt;&lt;ref&gt;Shreiner, Dave; Woo, Mason; Neider, Jackie; Davis, Tom; "OpenGL Programming Guide", 4th Edition, {{isbn|978-0-321-17348-5}}, published December 2004.  Page 38 and Appendix F (pp. 697-702) Discuss how [[OpenGL]] uses homogeneous coordinates in its rendering pipeline.  Page 2 indicates that OpenGL is a software interface to [[graphics card|graphics hardware]].&lt;/ref&gt;

For example, in perspective projection, a position in space is associated with the line from it to a fixed point called the ''center of projection''. The point is then mapped to a plane by finding the point of intersection of that plane and the line. This produces an accurate representation of how a three-dimensional object appears to the eye. In the simplest situation, the center of projection is the origin and points are mapped to the plane {{nowrap|1=''z'' = 1}}, working for the moment in Cartesian coordinates. For a given point in space, {{nowrap|(''x'', ''y'', ''z'')}}, the point where the line and the plane intersect is {{nowrap|(''x''/''z'', ''y''/''z'', 1)}}. Dropping the now superfluous ''z'' coordinate, this becomes {{nowrap|(''x''/''z'', ''y''/''z'')}}. In homogeneous coordinates, the point {{nowrap|(''x'', ''y'', ''z'')}} is represented by {{nowrap|(''xw'', ''yw'', ''zw'', ''w'')}} and the point it maps to on the plane is represented by  {{nowrap|(''xw'', ''yw'', ''zw'')}}, so projection can be represented in matrix form as{{clarify|reason=Confusing; it must be explicit how this matrix acts on coordinates vectors. Apparently, contrarily to the common convention, the vector is on the left and the matrix on the right in the multiplication matrix vector|date=November 2014}}
:&lt;math&gt;\begin{pmatrix}1&amp;0&amp;0&amp;0\\0&amp;1&amp;0&amp;0\\0&amp;0&amp;1&amp;0\end{pmatrix}&lt;/math&gt;
Matrices representing other geometric transformations can be combined with this and each other by matrix multiplication. As a result, any perspective projection of space can be represented as a single matrix.&lt;ref&gt;
{{cite book |title=Mathematics for Computer Graphics Applications|first=Michael E.|last=Mortenson
|publisher=Industrial Press Inc.|year=1999|isbn=0-8311-3111-X|page=318}}&lt;/ref&gt;&lt;ref&gt;
{{cite book |title=Computer Graphics: Theory into Practice|first=Jeffrey J.|last=McConnell
|publisher=Jones &amp; Bartlett Learning|year=2006|isbn=0-7637-2250-2|page=120}}&lt;/ref&gt;

==Notes==
{{Reflist}}

==References==
*{{cite book |title=Introduction to Higher Algebra|first=Maxime|last=Bôcher
|publisher=Macmillan|year=1907|pages=11ff
|url=https://books.google.com/books?id=j0gNAAAAYAAJ&amp;pg=PA11}}
*{{cite book |title=Elements of Analytical Geometry of Two Dimensions
|first1=Charles|last1=Briot|first2=Jean Claude|last2=Bouquet|others=trans. J.H. Boyd
|publisher=Werner school book company|year=1896|page=380
|url=https://books.google.com/books?id=zaULAAAAYAAJ&amp;pg=PA380#v=onepage}}
*{{cite book |title=Ideals, Varieties, and Algorithms
|first1=David A.|last1=Cox|first2=John B.|last2=Little|first3=Donal|last3=O'Shea
|publisher=Springer|year=2007|isbn=0-387-35650-9|page=357
|url=https://books.google.com/books?id=yCsDO425PC0C&amp;pg=PA357}}
*{{citation|first=Lynn E.|last=Garner|title=An Outline of Projective Geometry|year=1981|publisher=North Holland|isbn=0-444-00423-8}}
*{{cite book |title=An Introduction to Algebraical Geometry|first=Alfred Clement|last=Jones
|publisher=Clarendon|year=1912
|url=https://books.google.com/books?id=JoJsAAAAMAAJ&amp;pg=PA120#v=onepage}}
*{{cite book |title=Algebraic Curves and Riemann Surfaces|first=Rick|last=Miranda
|publisher=AMS Bookstore|year=1995|isbn=0-8218-0268-2|page=13
|url=https://books.google.com/books?id=qjg6GOQaHNEC&amp;pg=PA13}}
*{{cite book |title=Projective Differential Geometry of Curves and Ruled Surfaces
|first=Ernest Julius|last=Wilczynski|publisher=B.G. Teubner|year=1906
|url=https://books.google.com/books?id=LEpLAAAAMAAJ&amp;pg=PR1#v=onepage}}
*{{cite book |title=Higher Geometry|first=Frederick S.|last=Woods
|publisher=Ginn and Co.|year=1922|pages=27ff
|url=https://books.google.com/books?id=3ZULAAAAYAAJ&amp;pg=PA27#v=onepage&amp;q&amp;f=false}}

==Further reading==
*{{cite book |title=Mathematics and its History|first=John|last=Stillwell
|publisher=Springer|year=2002|isbn=0-387-95336-1|pages=134ff
|url=https://books.google.com/books?id=WNjRrqTm62QC&amp;pg=PA134}}

==External links==
{{commonscat|Projective geometry}}
* Jules Bloomenthal and Jon Rokne, Homogeneous coordinates [http://www.unchainedgeometry.com/jbloom/pdf/homog-coords.pdf]
* Ching-Kuang Shene, Homogeneous coordinates [http://www.cs.mtu.edu/~shene/COURSES/cs3621/NOTES/geometry/homo-coor.html]
* [http://mathworld.wolfram.com/HomogeneousCoordinates.html Wolfram MathWorld]

[[Category:Linear algebra]]
[[Category:Projective geometry]]
[[Category:1827 in science]]</text>
      <sha1>gtgg7rupe1ot17b6ye4hca4n42k6g4p</sha1>
    </revision>
  </page>
  <page>
    <title>JLO cocycle</title>
    <ns>0</ns>
    <id>13580667</id>
    <revision>
      <id>866931825</id>
      <parentid>866931765</parentid>
      <timestamp>2018-11-02T14:18:56Z</timestamp>
      <contributor>
        <username>Runawayangel</username>
        <id>7340759</id>
      </contributor>
      <comment>added template</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3550">{{no footnotes|date=November 2018}}
In [[noncommutative geometry]], the '''JLO cocycle''' is a [[Group cohomology|cocycle]] (and thus defines a [[cohomology class]]) in entire [[cyclic cohomology]]. It is a non-commutative version of the classic [[Chern character]] of the conventional [[differential geometry]]. In noncommutative geometry, the concept of a manifold is replaced by a noncommutative algebra &lt;math&gt;\mathcal{A}&lt;/math&gt; of "functions" on the putative noncommutative space. The cyclic cohomology of the algebra &lt;math&gt;\mathcal{A}&lt;/math&gt; contains the information about the topology of that noncommutative space, very much as the [[de Rham cohomology]] contains the information about the topology of a conventional manifold.

The JLO cocycle is associated with a metric structure of non-commutative differential geometry known as a &lt;math&gt;\theta&lt;/math&gt;-summable [[spectral triple]] (also known as a &lt;math&gt;\theta&lt;/math&gt;-summable Fredholm module).

== &lt;math&gt;\theta&lt;/math&gt;-summable spectral triples ==

A &lt;math&gt;\theta&lt;/math&gt;-summable spectral triple consists of the following data:

(a) A [[Hilbert space]] &lt;math&gt;\mathcal{H}&lt;/math&gt; such that &lt;math&gt;\mathcal{A}&lt;/math&gt; acts on it as an algebra of bounded operators.

(b) A &lt;math&gt;\mathbb{Z}_2&lt;/math&gt;-grading &lt;math&gt;\gamma&lt;/math&gt; on &lt;math&gt;\mathcal{H}&lt;/math&gt;, &lt;math&gt;\mathcal{H}=\mathcal{H}_0\oplus\mathcal{H}_1&lt;/math&gt;. We assume that the algebra &lt;math&gt;\mathcal{A}&lt;/math&gt; is even under the &lt;math&gt;\mathbb{Z}_2&lt;/math&gt;-grading, i.e. &lt;math&gt;a\gamma=\gamma a&lt;/math&gt;, for all &lt;math&gt;a\in\mathcal{A}&lt;/math&gt;.

(c) A self-adjoint (unbounded) operator &lt;math&gt;D&lt;/math&gt;, called the ''Dirac operator'' such that

:(i) &lt;math&gt;D&lt;/math&gt; is odd under &lt;math&gt;\gamma&lt;/math&gt;, i.e. &lt;math&gt;D\gamma=-\gamma D&lt;/math&gt;.

:(ii) Each &lt;math&gt;a\in\mathcal{A}&lt;/math&gt; maps the domain of &lt;math&gt;D&lt;/math&gt;, &lt;math&gt;\mathrm{Dom}\left(D\right)&lt;/math&gt; into itself, and the operator &lt;math&gt;\left[D,a\right]:\mathrm{Dom}\left(D\right)\to\mathcal{H}&lt;/math&gt; is bounded.

:(iii) &lt;math&gt;\mathrm{tr}\left(e^{-tD^2}\right)&lt;\infty&lt;/math&gt;, for all &lt;math&gt;t&gt;0&lt;/math&gt;.

A classic example of a &lt;math&gt;\theta&lt;/math&gt;-summable spectral triple arises as follows. Let &lt;math&gt;M&lt;/math&gt; be a compact [[spin manifold]], &lt;math&gt;\mathcal{A}=C^\infty\left(M\right)&lt;/math&gt;, the algebra of smooth functions on &lt;math&gt;M&lt;/math&gt;, &lt;math&gt;\mathcal{H}&lt;/math&gt; the Hilbert space of square integrable forms on &lt;math&gt;M&lt;/math&gt;, and &lt;math&gt;D&lt;/math&gt; the standard Dirac operator.

== The cocycle ==

The JLO cocycle &lt;math&gt;\Phi_t\left(D\right)&lt;/math&gt; is a sequence

:&lt;math&gt;\Phi_t\left(D\right)=\left(\Phi_t^0\left(D\right),\Phi_t^2\left(D\right),\Phi_t^4\left(D\right),\ldots\right)&lt;/math&gt;

of functionals on the algebra &lt;math&gt;\mathcal{A}&lt;/math&gt;, where

:&lt;math&gt;\Phi_t^0\left(D\right)\left(a_0\right)=\mathrm{tr}\left(\gamma a_0 e^{-tD^2}\right),&lt;/math&gt;
:&lt;math&gt;\Phi_t^n\left(D\right)\left(a_0,a_1,\ldots,a_n\right)=\int_{0\leq s_1\leq\ldots s_n\leq t}\mathrm{tr}\left(\gamma a_0 e^{-s_1 D^2}\left[D,a_1\right]e^{-\left(s_2-s_1\right)D^2}\ldots\left[D,a_n\right]e^{-\left(t-s_n\right)D^2}\right)ds_1\ldots ds_n,&lt;/math&gt;

for &lt;math&gt;n=2,4,\dots&lt;/math&gt;. The cohomology class defined by &lt;math&gt;\Phi_t\left(D\right)&lt;/math&gt; is independent of the value of &lt;math&gt;t&lt;/math&gt;.

==External links==
* [http://projecteuclid.org/DPubS/Repository/1.0/Disseminate?view=body&amp;id=pdf_1&amp;handle=euclid.cmp/1104161905] - The original paper introducing the JLO cocycle.
* [https://web.archive.org/web/20100624222022/http://www.math.psu.edu/higson/Slides/trieste4.pdf] - A nice set of lectures.

[[Category:Noncommutative geometry]]</text>
      <sha1>3cmotsjb6n53ny8rhcj9ur9tmsgvafh</sha1>
    </revision>
  </page>
  <page>
    <title>Jordan's lemma</title>
    <ns>0</ns>
    <id>4743700</id>
    <revision>
      <id>804409783</id>
      <parentid>804395636</parentid>
      <timestamp>2017-10-08T20:48:32Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Clarify}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6560">In [[complex analysis]], '''Jordan's lemma''' is a result frequently used in conjunction with the [[residue theorem]] to evaluate [[contour integral]]s and [[improper integral]]s. It is named after the French mathematician [[Camille Jordan]].

== Statement ==

Consider a [[complex number|complex]]-valued, [[continuous function]] {{math|''f''}}, defined on a semicircular contour

:&lt;math&gt;C_R = \{R e^{i \theta} \mid \theta \in [0, \pi]\}&lt;/math&gt;

of positive radius {{math|''R''}} lying in the [[upper half-plane]], centred at the origin. If the function {{math|''f''}} is of the form

:&lt;math&gt;f(z) = e^{i a z} g(z) , \quad z \in C_R ,&lt;/math&gt;

with a positive parameter {{math|''a''}}, then Jordan's lemma states the following upper bound for the contour integral:

:&lt;math&gt;\left| \int_{C_R} f(z) \, dz \right| \le \frac{\pi}{a} M_R \quad \text{where} \quad M_R := \max_{\theta \in [0,\pi]} \left| g \left(R e^{i \theta}\right) \right| .&lt;/math&gt;

where equal sign is when {{math|''g''}} vanishes everywhere{{clarify|date=October 2017}}. An analogous statement for a semicircular contour in the lower half-plane holds when {{math|''a'' &lt; 0}}.

=== Remarks ===

* If {{math|''f''}} is continuous on the semicircular contour {{math|''C&lt;sub&gt;R&lt;/sub&gt;''}} for all large {{math|''R''}} and
 
{{NumBlk|::|&lt;math&gt;\lim_{R \to \infty} M_R = 0&lt;/math&gt;|{{EquationRef|&lt;nowiki&gt;*&lt;/nowiki&gt;}}}}

:then by Jordan's lemma
 
::&lt;math&gt;\lim_{R \to \infty} \int_{C_R} f(z)\, dz = 0.&lt;/math&gt;
 
* For the case {{math|''a'' {{=}} 0}}, see the [[estimation lemma]].
* Compared to the estimation lemma, the upper bound in Jordan's lemma does not explicitly depend on the length of the contour {{math|''C&lt;sub&gt;R&lt;/sub&gt;''}}.

== Application of Jordan's lemma ==

[[Image:Jordan's Lemma.svg|right|thumb|300px|The path {{math|''C''}} is the concatenation of the paths {{math|''C''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''C''&lt;sub&gt;2&lt;/sub&gt;}}.]]

Jordan's lemma yields a simple way to calculate the integral along the real axis of functions {{math|''f''(''z'') {{=}} ''e&lt;sup&gt;i a z&lt;/sup&gt; g''(''z'')}} [[Holomorphic function|holomorphic]] on the upper half-plane and continuous on the closed upper half-plane, except possibly at a finite number of non-real points {{math|''z''&lt;sub&gt;1&lt;/sub&gt;}}, {{math|''z''&lt;sub&gt;2&lt;/sub&gt;}}, …, {{math|''z&lt;sub&gt;n&lt;/sub&gt;''}}. Consider the closed contour {{math|''C''}}, which is the concatenation of the paths {{math|''C''&lt;sub&gt;1&lt;/sub&gt;}} and {{math|''C''&lt;sub&gt;2&lt;/sub&gt;}} shown in the picture. By definition,

:&lt;math&gt;\oint_C f(z) \, dz = \int_{C_1}f(z)\,dz + \int_{C_2} f(z)\,dz\,.&lt;/math&gt;

Since on {{math|''C''&lt;sub&gt;2&lt;/sub&gt;}} the variable {{math|''z''}} is real, the second integral is real:

:&lt;math&gt;\int_{C_2} f(z) \, dz = \int_{-R}^{R} f(x)\,dx\,.&lt;/math&gt;

The left-hand side may be computed using the [[residue theorem]] to get, for all {{math|''R''}} larger than the maximum of {{math|{{!}}''z''&lt;sub&gt;1&lt;/sub&gt;{{!}}}}, {{math|{{!}}''z''&lt;sub&gt;2&lt;/sub&gt;{{!}}}}, …, {{math|{{!}}''z&lt;sub&gt;n&lt;/sub&gt;''{{!}}}},

:&lt;math&gt;\oint_{C} f(z)\, dz = 2\pi i \sum_{k=1}^n \operatorname{Res}(f, z_k)\,,&lt;/math&gt;

where {{math|Res(''f'', ''z&lt;sub&gt;k&lt;/sub&gt;'')}} denotes the [[Residue (complex analysis)|residue]] of {{math|''f''}} at the singularity {{math|''z&lt;sub&gt;k&lt;/sub&gt;''}}. Hence, if {{math|''f''}} satisfies condition ({{EquationNote|*}}), then taking the limit as {{math|''R''}} tends to infinity, the contour integral over {{math|''C''&lt;sub&gt;1&lt;/sub&gt;}} vanishes by Jordan's lemma and we get the value of the improper integral

:&lt;math&gt;\int_{-\infty}^{\infty} f(x)\,dx = 2\pi i \sum_{k=1}^n \operatorname{Res}(f, z_k)\,.&lt;/math&gt;

== Example ==

The function

:&lt;math&gt;f(z)=\frac{e^{iz}}{1+z^2},\qquad z\in{\mathbb C}\setminus\{i,-i\},&lt;/math&gt;

satisfies the condition of Jordan's lemma with {{math|''a'' {{=}} 1}} for all {{math|''R'' &gt; 0}} with {{math|''R'' ≠ 1}}. Note that, for {{math|''R'' &gt; 1}},

:&lt;math&gt;M_R=\max_{\theta\in[0,\pi]}\frac1{|1+R^2e^{2i\theta}|}=\frac1{R^2-1}\,,&lt;/math&gt;

hence ({{EquationNote|*}}) holds. Since the only singularity of {{math|''f''}} in the upper half plane is at {{math|''z'' {{=}} ''i''}}, the above application yields

:&lt;math&gt;\int_{-\infty}^\infty \frac{e^{ix}}{1+x^2}\,dx=2\pi i\,\operatorname{Res}(f,i)\,.&lt;/math&gt;

Since {{math|''z'' {{=}} ''i''}} is a [[simple pole]] of {{math|''f''}} and {{math|1 + ''z''&lt;sup&gt;2&lt;/sup&gt; {{=}} (''z'' + ''i'')(''z'' − ''i'')}}, we obtain
:&lt;math&gt;\operatorname{Res}(f,i)=\lim_{z\to i}(z-i)f(z)
=\lim_{z\to i}\frac{e^{iz}}{z+i}=\frac{e^{-1}}{2i}&lt;/math&gt;

so that

:&lt;math&gt;\int_{-\infty}^\infty \frac{\cos x}{1+x^2}\,dx=\operatorname{Re}\int_{-\infty}^\infty \frac{e^{ix}}{1+x^2}\,dx=\frac{\pi}{e}\,.&lt;/math&gt;

This result exemplifies the way some integrals difficult to compute with classical methods are easily evaluated with the help of complex analysis.

== Proof of Jordan's lemma ==

By definition of the [[Line integral#Complex line integral|complex line integral]],

:&lt;math&gt; \int_{C_R} f(z)\, dz
=\int_0^\pi g(Re^{i\theta})\,e^{iaR(\cos\theta+i \sin\theta)}\,i Re^{i\theta}\,d\theta
=R\int_0^\pi g(Re^{i\theta})\,e^{aR(i\cos\theta-\sin\theta)}\,ie^{i\theta}\,d\theta\,.
&lt;/math&gt;

Now the inequality

:&lt;math&gt; \biggl|\int_a^b f(x)\,dx\biggr|\le\int_a^b \left|f(x)\right|\,dx&lt;/math&gt;

yields

:&lt;math&gt; I_R:=\biggl|\int_{C_R} f(z)\, dz\biggr|
\le R\int_0^\pi\bigl|g(Re^{i\theta})\,e^{aR(i\cos\theta-\sin\theta)}\,ie^{i\theta} \bigr|\,d\theta
=R\int_0^\pi \bigl|g(Re^{i\theta})\bigr|\,e^{-aR\sin\theta}\,d\theta\,.
&lt;/math&gt;

Using {{math|''M&lt;sub&gt;R&lt;/sub&gt;''}} as defined in ({{EquationNote|*}}) and the symmetry {{math|sin ''θ'' {{=}} sin(''π'' – ''θ'')}}, we obtain

:&lt;math&gt; I_R \le RM_R\int_0^\pi e^{-aR\sin\theta}\,d\theta = 2RM_R\int_0^{\pi/2} e^{-aR\sin\theta}\,d\theta\,.&lt;/math&gt;

Since the graph of {{math|sin ''θ''}} is [[concave function|concave]] on the interval {{math|''θ'' ∈ [0, ''π'' ⁄ 2]}}, the graph of {{math|sin ''θ''}} lies above the straight line connecting its endpoints, hence

:&lt;math&gt;\sin\theta\ge \frac{2\theta}{\pi}\quad&lt;/math&gt;

for all {{math|''θ'' ∈ [0, ''π'' ⁄ 2]}}, which further implies

:&lt;math&gt;I_R
\le 2RM_R \int_0^{\pi/2} e^{-2aR\theta/\pi}\,d\theta
=\frac{\pi}{a} (1-e^{-a R}) M_R\le\frac\pi{a}M_R\,.&lt;/math&gt;

==See also==
*[[Estimation lemma]]

==References==
* {{Cite book| last1=Brown| first1=James W.| last2=Churchill| first2=Ruel V.| date=2004| title=Complex Variables and Applications| edition=7th|place=New York | publisher=McGraw Hill| pages=262–265| isbn = 0-07-287252-7}}

{{DEFAULTSORT:Jordan's Lemma}}
[[Category:Theorems in complex analysis]]
[[Category:Articles containing proofs]]
[[Category:Lemmas]]</text>
      <sha1>fh6yjxz7ipvd4iu7rpa0k21bchbunfm</sha1>
    </revision>
  </page>
  <page>
    <title>Joseph Larmor</title>
    <ns>0</ns>
    <id>665108</id>
    <revision>
      <id>836330870</id>
      <parentid>835580173</parentid>
      <timestamp>2018-04-14T03:11:07Z</timestamp>
      <contributor>
        <username>EdmundT</username>
        <id>285130</id>
      </contributor>
      <minor/>
      <comment>/* Biography */ Spelling</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17141">{{redirect|Larmor}}
{{EngvarB|date=October 2013}}
{{Use dmy dates|date=October 2013}}
{{Infobox scientist
|name              = Joseph Larmor
|image             =
|image_size        =
|caption           =
|birth_date        = {{Birth date|1857|7|11|df=y}}
|birth_place       = Magheragall, [[County Antrim]], Ireland, [[United Kingdom of Great Britain and Ireland]]
|death_date        = {{death date and age|1942|5|19|1857|7|11|df=y}}
|death_place       = [[Holywood]], [[County Down]], [[Northern Ireland]]&lt;ref&gt;{{MacTutor Biography|id=Larmor}}&lt;/ref&gt;
|residence         =
|citizenship       =
|ethnicity         =
|field             = [[Physics]]
|work_institutions = [[St John's College, Cambridge]]&lt;br/&gt;[[National University of Ireland, Galway|Queen's College, Galway]]
|alma_mater        = [[Royal Belfast Academical Institution]]&lt;br/&gt;[[Queen's University Belfast]]&lt;br/&gt;[[St John's College, Cambridge]]
|doctoral_advisor  = [[Edward Routh]]
|academic_advisors =
|doctoral_students = [[Kwan-ichi Terazawa]]
|notable_students  =
|awards            = [[Smith's Prize]] (1880)&lt;br/&gt;[[Senior Wrangler]] (1880)&lt;br/&gt; [[Fellow of the Royal Society]] (1892)&lt;br/&gt; [[Adams Prize]] (1898)&lt;br/&gt; {{nowrap|[[Lucasian Professor of Mathematics]] (1903)}}&lt;br/&gt; [[De Morgan Medal]] (1914)&lt;br/&gt; [[Royal Medal]] (1915)&lt;br/&gt; [[Copley Medal]] (1921)
|known_for         = [[Larmor precession]]&lt;br/&gt;[[Larmor radius]]&lt;br/&gt;[[Larmor's theorem]]&lt;br/&gt;[[Larmor formula]]&lt;br/&gt;[[Relativity of simultaneity]]
|influences        =
|influenced        =
|prizes            =
|religion          =
|footnotes         =
|signature         =
}}

'''Sir Joseph Larmor''' [[Royal Society of London|FRS]] [[FRSE]] DCL LLD&lt;ref name="frs"&gt;{{Cite journal | last1 = Eddington | first1 = A. S. | authorlink = Arthur Eddington| title = Joseph Larmor. 1857-1942 | doi = 10.1098/rsbm.1942.0016 | journal = [[Obituary Notices of Fellows of the Royal Society]] | volume = 4 | issue = 11 | pages = 197–207 | year = 1942 | pmid =  | pmc = }}&lt;/ref&gt; (11 July 1857 – 19 May 1942) was an Irish&lt;ref&gt;https://www.britannica.com/biography/Joseph-Larmor&lt;/ref&gt; [[physicist]] and mathematician who made innovations in the understanding of electricity, [[dynamics (mechanics)|dynamics]], [[thermodynamics]], and the electron theory of matter. His most influential work was ''Aether and Matter'', a theoretical physics book published in 1900.

==Biography==
He was born in [[Magheragall]] in [[County Antrim]] the son of Hugh Larmor, a [[Belfast]] shopkeeper and his wife, Anna Wright.&lt;ref&gt;{{cite book|title=Biographical Index of Former Fellows of the Royal Society of Edinburgh 1783–2002|date=July 2006|publisher=[[The Royal Society of Edinburgh]]|isbn=0 902 198 84 X|url=https://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp2.pdf}}&lt;/ref&gt; The family moved to Belfast around 1860, and he was educated at the [[Royal Belfast Academical Institution]], and then studied mathematics and experimental science at science at [[Queen's College, Belfast]] (BA 1874, MA  1875),&lt;ref&gt;[http://lisburn.com/history/digger/Digger-2011/digger-06-05-2011.html From Ballycarrickmaddy to the moon] Lisburn.com, 06/05/2011&lt;/ref&gt;where one of his teachers was [[John Purser (mathematician)|John Purser]].  He subsequently studied at [[St John's College, Cambridge]] where in 1880 he was [[Senior Wrangler]] ([[J. J. Thomson]] was second wrangler that year) and Smith's Prizeman, getting his MA in 1883.&lt;ref&gt;{{acad|id=LRMR876J|name=Larmor, Joseph}}&lt;/ref&gt; After teaching physics for a few years at [[Queen's College, Galway]], he accepted a lectureship in mathematics at Cambridge in 1885. In 1892 he was elected a Fellow of the [[Royal Society of London]] and was made an Honorary Fellow of the [[Royal Society of Edinburgh]] in 1910.&lt;ref&gt;{{cite book|title=Biographical Index of Former Fellows of the Royal Society of Edinburgh 1783–2002|date=July 2006|publisher=The Royal Society of Edinburgh|isbn=0 902 198 84 X|url=https://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp2.pdf}}&lt;/ref&gt;

In 1903 he was appointed [[Lucasian Professor of Mathematics]] at Cambridge, a post he retained until his retirement in 1932. He never married. He was knighted by King [[Edward VII]] in 1909.

Motivated by his strong opposition to [[Devolution|Home Rule for Ireland]], in February 1911 Larmor ran for and was elected as Member of Parliament for [[Cambridge University (UK Parliament constituency)]] with the [[Liberal Unionist]] party. He remained in parliament until the [[United Kingdom general election, 1922|1922 general election]], at which point the Irish question had been settled. Upon his retirement from Cambridge in 1932 Larmor moved back to [[County Down]] in Northern Ireland.

He received the honorary [[Legum Doctor|Doctor of Laws]] (LL.D) from the [[University of Glasgow]] in June 1901.&lt;ref&gt;{{Cite newspaper The Times |articlename=Glasgow University jubilee |day_of_week=Friday |date=14 June 1901 |page_number=10 |issue=36481}}&lt;/ref&gt; He was awarded the [[Poncelet Prize]] for 1918 by the [[French Academy of Sciences]].&lt;ref&gt;{{cite journal|url=http://www.nature.com/nature/journal/v102/n2565/abs/102334b0.html|title=Prize Awards of the Paris Academy of Sciences for 1918|journal=Nature|volume=102|issue=2565|pages=334–335|date=26 December 1918|doi=10.1038/102334b0|bibcode = 1918Natur.102R.334. }}&lt;/ref&gt; Larmor was a Plenary Speaker in 1920 at the [[International Congress of Mathematicians|ICM]] at Strasbourg&lt;ref&gt;{{cite book|chapter-url=http://www.mathunion.org/ICM/ICM1920/Main/icm1920.0003.0040.ocr.pdf|pages=3–40|year=1921|title=Compte rendu du Congrès international des mathématiciens tenu à Strasbourg du 22 au 30 Septembre 1920|chapter=''Questions in physical indetermination'' by Joseph Larmor|deadurl=yes|archiveurl=https://web.archive.org/web/20131227061941/http://www.mathunion.org/ICM/ICM1920/Main/icm1920.0003.0040.ocr.pdf|archivedate=27 December 2013|df=dmy-all}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|title=The International Congress of Mathematicians|journal=Nature|date=7 October 1920|volume=106|issue=2658|pages=196–197|url=https://books.google.com/books?id=YBJLAQAAMAAJ&amp;pg=PA196|bibcode=1920Natur.106..196H|doi=10.1038/106196a0}} In his plenary address, Larmor advocated the aether theory as opposed to Einstein's general theory of relativity.&lt;/ref&gt; and an Invited Speaker at the ICM in 1924 in Toronto and at the ICM in 1928 in Bologna.

He died in [[Holywood, County Down]] on 19 May 1942.&lt;ref&gt;{{cite book|title=Biographical Index of Former Fellows of the Royal Society of Edinburgh 1783–2002|date=July 2006|publisher=The Royal Society of Edinburgh|isbn=0 902 198 84 X|url=https://www.royalsoced.org.uk/cms/files/fellows/biographical_index/fells_indexp2.pdf}}&lt;/ref&gt;

==Work==
Larmor proposed that the [[Luminiferous aether|aether]] could be represented as a [[Homogeneous (chemistry)|homogeneous]] [[fluid]] medium which was perfectly [[incompressible]] and [[Elasticity (physics)|elastic]]. Larmor believed the aether was separate from matter. He united [[William Thomson, 1st Baron Kelvin|Lord Kelvin]]'s model of spinning [[gyrostat]]s (see [[Vortex theory of the atom]]) with this [[theory]]. Larmor held that [[matter]] consisted of [[Elementary particle|particles]] moving in the aether. Larmor believed the source of [[electric charge]] was a "''particle''" (which as early as 1894 he was referring to as the [[electron]]). Larmor held that the flow of charged particles constitutes the [[Current (electricity)|current]] of [[conductor (material)|conduction]] (but was not part of the [[atom]]). Larmor calculated the rate of energy [[radiation]] from an [[acceleration|accelerating]] electron. Larmor explained the splitting of the [[spectral line]]s in a [[magnetic field]] by the [[oscillation]] of electrons.

In 1919, Larmor proposed [[sunspot]]s are [[Regenerative circuit|self-regenerative]] [[dynamo]] action on the [[Sun]]'s surface.

==Discovery of Lorentz transformation==
{{Main|History of Lorentz transformations#Larmor|History of special relativity}}
Parallel to the development of [[Lorentz ether theory]], Larmor published an approximation to the [[Lorentz transformation]]s in the ''[[Philosophical Transactions of the Royal Society]]'' in 1897,&lt;ref&gt;{{Citation |author=Larmor, Joseph |year=1897 |title=[[s:Dynamical Theory of the Electric and Luminiferous Medium III|On a Dynamical Theory of the Electric and Luminiferous Medium, Part 3, Relations with material media]] |journal=Philosophical Transactions of the Royal Society |volume=190 |pages=205–300 |doi=10.1098/rsta.1897.0020|bibcode = 1897RSPTA.190..205L }}&lt;/ref&gt;
namely &lt;math&gt;x_{1}  =x\epsilon^{\frac{1}{2}}&lt;/math&gt; for the spatial part and &lt;math&gt;dt_{1}  =dt^{\prime}\epsilon^{-\frac{1}{2}}&lt;/math&gt; for the temporal part, where &lt;math&gt;\epsilon =\left(1-v^{2}/c^{2}\right)^{-1}&lt;/math&gt; and the local time &lt;math&gt;t^{\prime} =t-vx/c^{2}&lt;/math&gt;. He obtained the full Lorentz transformation in 1900 by inserting &lt;math&gt;\epsilon&lt;/math&gt; into his expression of local time such that &lt;math&gt;t^{\prime\prime} =t^{\prime}-\epsilon vx^{\prime}/c^{2}&lt;/math&gt;, and as before &lt;math&gt;x_{1} =\epsilon^{\frac{1}{2}}x^{\prime}&lt;/math&gt; and &lt;math&gt;dt_{1} =\epsilon^{-\frac{1}{2}}dt^{\prime\prime}&lt;/math&gt;.&lt;ref&gt;{{Citation |author=Larmor, Joseph |year=1900 |title=[[s:Aether and Matter|Aether and Matter]] |publisher=Cambridge University Press}}&lt;/ref&gt; This was done around the same time as [[Hendrik Lorentz]] (1899, 1904) and five years before [[Albert Einstein]] (1905). 

Larmor however did not possess the correct velocity transformations, which include the addition of velocities law, which were later discovered by [[Henri Poincaré]]. Larmor predicted the [[phenomenon]] of [[time dilation]], at least for orbiting electrons, by writing  (Larmor 1897): "... individual electrons describe corresponding parts of their orbits in times shorter for the [rest] system in the ratio&amp;nbsp;(1&amp;nbsp;–&amp;nbsp;''v''&lt;sup&gt;2&lt;/sup&gt;/''c''&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;1/2&lt;/sup&gt;". He also verified that the [[FitzGerald–Lorentz contraction]] ([[length contraction]]) should occur for bodies whose atoms were held together by electromagnetic forces. In his book ''Aether and Matter'' (1900), he again presented the Lorentz transformations, time dilation and length contraction (treating these as dynamic rather than [[kinematic]] effects). Larmor was opposed to the [[spacetime]] interpretation of the Lorentz transformation in [[special relativity]] because he continued to believe in an absolute aether. He was also critical of the [[space-time|curvature of space]] of [[general relativity]], to the extent that he claimed that an absolute time was essential to astronomy (Larmor 1924, 1927).

==Publications==
* 1884, "Least action as the fundamental formulation in dynamics and physics", ''Proceedings of the London Mathematical Society''.
* 1887, "On the direct applications of first principles in the theory of partial differential equations", ''[[Proceedings of the Royal Society]]''.
* 1891, "On the theory of electrodynamics", ''Proceedings of the Royal Society''.
* 1892, "On the theory of electrodynamics, as affected by the nature of the mechanical stresses in excited dielectrics", ''Proceedings of the Royal Society''.
* 1893–97, "Dynamical Theory of the Electric and Luminiferous Medium", ''Proceedings of the Royal Society; Philosophical Transactions of the Royal Society''. Series of 3 papers containing Larmor's physical theory of the universe.
* 1896, "The influence of a magnetic field on radiation frequency", ''Proceedings of the Royal Society''.
* 1896, "On the absolute minimum of optical deviation by a prism", ''Proceedings of the Cambridge Philosophical Society''.
*{{Cite journal | last1 = Larmor | first1 = J. | doi = 10.1098/rsta.1897.0020 | title = A Dynamical Theory of the Electric and Luminiferous Medium. Part III. Relations with Material Media | journal = Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences | volume = 190 | pages = 205 | year = 1897 | pmid =  | pmc = |bibcode = 1897RSPTA.190..205L }}
* 1898, "Note on the complete scheme of electrodynamic equations of a moving material medium, and electrostriction", ''Proceedings of the Royal Society''.
* 1898, "On the origin of magneto-optic rotation", ''Proceedings of the Cambridge Philosophical Society''.
* {{Citation | author=Larmor, J. | year=1900 | title=[[s:Aether and Matter|Aether and Matter]] | publisher=Cambridge University Press}}; Containing the [[Lorentz transformation]]s on p.&amp;nbsp;174.
* 1903, "On the electrodynamic and thermal relations of energy of magnetisation", ''Proceedings of the Royal Society''.
* 1907, "Aether" in ''[[Encyclopædia Britannica]]'', 11th ed.  London.
* 1908, "William Thomson, Baron Kelvin of Largs. 1824–1907" (Obituary). ''Proceedings of the Royal Society''.
* 1924, "On Editing Newton", ''Nature''.
* 1927, "Newtonian time essential to astronomy", ''Nature''.
* 1929, ''Mathematical and Physical Papers''. Cambridge Univ. Press.&lt;ref&gt;{{cite journal|author=Gronwall, T. H.|authorlink=Thomas Hakon Grönwall|title=Review: ''Mathematical and Physical Papers'', by Sir Joseph Larmor|journal=Bull. Amer. Math. Soc.|year=1930|volume=36|issue=7|pages=470–471|url=http://www.ams.org/journals/bull/1930-36-07/S0002-9904-1930-04975-7/S0002-9904-1930-04975-7.pdf|doi=10.1090/s0002-9904-1930-04975-7}}&lt;/ref&gt;
* 1937, (as editor), ''Origins of Clerk Maxwell's Electric Ideas as Described in Familiar Letters to William Thomson''. Cambridge University Press.&lt;ref&gt;{{cite journal|author=Page, Leigh|authorlink=Leigh Page|title=Review: ''Origins of Clerk Maxwell's Electric Ideas as Described in Familiar Letters to William Thomson'', by Sir Joseph Larmor|journal=Bull. Amer. Math. Soc.|year=1938|volume=44|issue=5|pages=320|url=http://www.ams.org/journals/bull/1938-44-05/S0002-9904-1938-06738-9/S0002-9904-1938-06738-9.pdf|doi=10.1090/s0002-9904-1938-06738-9}}&lt;/ref&gt;
Larmor edited the collected works of [[Sir George Stokes, 1st Baronet|George Stokes]], [[James Thomson (engineer)|James Thomson]] and [[William Thomson, 1st Baron Kelvin|William Thomson]].

==See also==
{{wikisource author}}
*[[History of Lorentz transformations]]
*[[Larmor precession]]
*[[Larmor (crater)]]

==References==
{{reflist|colwidth=30em}}

==Further reading==
* Bruce J. Hunt (1991) [[The Maxwellians]], [[Cornell University Press]]
* Macrossan, M. N. "[https://web.archive.org/web/20161013173619/http://photontheory.com/larmor.pdf A note on relativity before Einstein]", ''British Journal for the Philosophy of Science'', '''37''' (1986): 232–234.
* Warwick, Andrew, "''On the Role of the FitzGerald–Lorentz Contraction Hypothesis in the Development of Joseph Larmor's Electronic Theory of Matter''". Archive for History of Exact Sciences 43 (1991): 29–91.
* {{Citation|author=Darrigol, O. |title=The Electron Theories of Larmor and Lorentz: A Comparative Study |year=1994 |journal=Historical Studies in the Physical and Biological Sciences |volume=24|issue=2 |pages=265–336 |doi=10.2307/27757725|jstor=27757725 }}
* "''[https://web.archive.org/web/20061004061956/http://www.universityscience.ie/pages/scientists/sci_josephlarmor.php A very short biography of Joseph Larmor]''"
* "''[http://www.victorianweb.org/science/ether.htm Ether and field theories in the late 19th century]''" At ''VictorianWeb:'' History of science in the Victorian era
* "''[http://janus.lib.cam.ac.uk/db/node.xsp?id=EAD%2FGBR%2F0275%2FLarmor;recurse=1 Papers of Sir Joseph Larmor]''". Janus, University of Cambridge.

{{S-start}}
{{s-par|uk}}
{{Succession box
 | title  = Member of Parliament for [[Cambridge University (UK Parliament constituency)|Cambridge University]]
 | years  = [[Cambridge University by-election, 1911|1911]] – [[United Kingdom general election, 1922|1922]]
 | with   = [[John Rawlinson (footballer and MP)|John Rawlinson]]
 | before = [[Samuel Butcher (classicist)|Samuel Butcher]]&lt;br /&gt;[[John Rawlinson (footballer and MP)|John Rawlinson]]
 | after  = [[J. R. M. Butler]]&lt;br /&gt;[[John Rawlinson (footballer and MP)|John Rawlinson]]
}}
{{S-end}}
{{Copley Medallists 1901-1950}}
{{Lucasian Professors of Mathematics}}

{{Authority control}}

{{DEFAULTSORT:Larmor, Joseph}}
[[Category:1857 births]]
[[Category:1942 deaths]]
[[Category:Alumni of St John's College, Cambridge]]
[[Category:19th-century British mathematicians]]
[[Category:20th-century British mathematicians]]
[[Category:Fellows of the Royal Society]]
[[Category:Liberal Unionist Party MPs for English constituencies]]
[[Category:Lucasian Professors of Mathematics]]
[[Category:Members of the Parliament of the United Kingdom for the University of Cambridge]]
[[Category:People educated at the Royal Belfast Academical Institution]]
[[Category:People from Belfast]]
[[Category:Physicists from Northern Ireland]]
[[Category:Relativity theorists]]
[[Category:UK MPs 1910–18]]
[[Category:UK MPs 1918–22]]
[[Category:Recipients of the Copley Medal]]
[[Category:Royal Medal winners]]
[[Category:Senior Wranglers]]
[[Category:De Morgan Medallists]]
[[Category:Mathematicians from Northern Ireland]]</text>
      <sha1>742bzsd3ijo8oakezw48qfzu4bzzxf0</sha1>
    </revision>
  </page>
  <page>
    <title>Kernel operator</title>
    <ns>0</ns>
    <id>23875401</id>
    <redirect title="Closure operator" />
    <revision>
      <id>309540268</id>
      <parentid>306223759</parentid>
      <timestamp>2009-08-23T03:44:42Z</timestamp>
      <contributor>
        <username>Pcap</username>
        <id>7417813</id>
      </contributor>
      <minor/>
      <comment>Quick-adding category [[:Category:Order theory|Order theory]] (using [[WP:HOTCAT|HotCat]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="101">#REDIRECT [[closure operator#Closure operators on partially ordered sets]]

[[Category:Order theory]]</text>
      <sha1>dwvhpo7y1nxo1etw5kxkqdrdfgubeck</sha1>
    </revision>
  </page>
  <page>
    <title>Linear extension</title>
    <ns>0</ns>
    <id>11726298</id>
    <revision>
      <id>841573394</id>
      <parentid>828833779</parentid>
      <timestamp>2018-05-16T17:27:15Z</timestamp>
      <contributor>
        <username>Nemo bis</username>
        <id>2584239</id>
      </contributor>
      <comment>Added free to read link in citations with [[WP:OABOT|OAbot]] #oabot</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8749">In [[order theory]], a branch of mathematics, a '''linear extension''' of a [[partial order]] is a [[total order]] (or linear order) that is compatible with the partial order. As a classic example, the [[lexicographic order]] of totally ordered sets is a linear extension of their [[product order]].

==Definitions==
Given any partial orders ≤ and ≤&lt;sup&gt;*&lt;/sup&gt; on a set ''X'', ≤&lt;sup&gt;*&lt;/sup&gt; is a linear extension of ≤ exactly when (1) ≤&lt;sup&gt;*&lt;/sup&gt; is a [[total order]] and (2) for every ''x'' and ''y'' in ''X'', if {{nowrap|''x'' ≤ ''y''}}, then {{nowrap|''x'' ≤&lt;sup&gt;*&lt;/sup&gt; ''y''}}. It is that second property that leads mathematicians to describe ≤&lt;sup&gt;*&lt;/sup&gt; as '''extending''' ≤.

Alternatively, a linear extension may be viewed as an [[order-preserving]] [[bijection]] from a partially ordered set ''P'' to a [[Total_order#Chains|chain]] ''C'' on the same ground set.

== Order-extension principle ==
{{further|Szpilrajn extension theorem}}
The statement that every partial order can be extended to a total order is known as the '''order-extension principle'''. A proof using the [[axiom of choice]] was first published by [[Edward Marczewski]] in 1930. Marczewski writes that the theorem had previously been proven by [[Stefan Banach]], [[Kazimierz Kuratowski]], and [[Alfred Tarski]], again using the axiom of choice, but that the proofs had not been published.&lt;ref&gt;{{citation
 | last = Marczewski | first = Edward | authorlink = Edward Marczewski
 | journal = Fundamenta Mathematicae
 | language = French
 | pages = 386–389
 | title = Sur l'extension de l'ordre partiel
 | url = http://matwbn.icm.edu.pl/ksiazki/fm/fm16/fm16125.pdf
 | volume = 16
 | year = 1930}}.&lt;/ref&gt;

In modern [[axiomatic set theory]] the order-extension principle is itself taken as an axiom, of comparable ontological status to the axiom of choice. The order-extension principle is implied by the [[Boolean prime ideal theorem]] or the equivalent [[compactness theorem]],&lt;ref&gt;{{citation
 | last = Jech | first = Thomas | author-link = Thomas Jech
 | isbn = 0-486-46624-8
 | origyear=originally published in 1973
 | publisher = [[Dover Publications]]
 | title = The Axiom of Choice
 | year = 2008}}.&lt;/ref&gt; but the reverse implication doesn't hold.&lt;ref&gt;{{citation
 | last1 = Felgner | first1 = U.
 | last2 = Truss | first2 = J. K.
 | date = March 1999
 | doi = 10.2307/2586759
 | issue = 1
 | journal = The Journal of Symbolic Logic
 | pages = 199–215
 | publisher = Association for Symbolic Logic
 | title = The Independence of the Prime Ideal Theorem from the Order-Extension Principle
 | volume = 64
 | jstor = 2586759| citeseerx = 10.1.1.54.8336
 }}.&lt;/ref&gt;

Applying the order-extension principle to a partial order in which every two elements are incomparable shows that (under this principle) every set can be linearly ordered. This assertion that every set can be linearly ordered is known as the '''ordering principle''', OP, and is a weakening of the [[well-ordering theorem]]. However, there are [[model theory|models of set theory]] in which the ordering principle holds while the order-extension principle does not.&lt;ref&gt;{{citation
 | last = Mathias | first = A. R. D.
 | contribution = The order extension principle
 | editor1-last = Scott | editor1-first = Dana S.
 | editor2-last = Jech | editor2-first = Thomas J.
 | pages = 179–183
 | publisher = American Mathematical Society
 | series = Proceedings of Symposia in Pure Mathematics
 | title = Axiomatic Set Theory (University of California, Los Angeles, Calif., July 10 – August 5, 1967)
 | volume = 13
 | year = 1971}}.&lt;/ref&gt;

==Related results==
The order extension principle is [[constructive proof|constructively provable]] for ''finite'' sets using [[topological sorting]] algorithms, where the partial order is represented by a [[directed acyclic graph]] with the set's elements as its [[vertex (graph theory)|vertices]]. Several algorithms can find an extension in [[linear time]].&lt;ref&gt;{{citation
 | last1 = Cormen | first1 = Thomas H. | author1-link = Thomas H. Cormen
 | last2 = Leiserson | first2 = Charles E. | author2-link = Charles E. Leiserson
 | last3 = Rivest | first3 = Ronald L. | author3-link = Ronald L. Rivest
 | last4 = Stein | first4 = Clifford | author4-link = Clifford Stein
 | contribution = Section 22.4: Topological sort
 | edition = 2nd
 | isbn = 0-262-03293-7
 | pages = 549–552
 | publisher = MIT Press
 | title = [[Introduction to Algorithms]]
 | year = 2001}}.&lt;/ref&gt; Despite the ease of finding a single linear extension, the problem of counting all linear extensions of a finite partial order is [[Sharp-P-complete|#P-complete]]; however, it may be estimated by a [[fully polynomial-time randomized approximation scheme]].&lt;ref&gt;{{citation
 | last1 = Brightwell | first1 = Graham R.
 | last2 = Winkler | first2 = Peter | author2-link = Peter Winkler
 | doi = 10.1007/BF00383444
 | issue = 3
 | journal = [[Order (journal)|Order]]
 | pages = 225–242
 | title = Counting linear extensions
 | volume = 8
 | year = 1991}}&lt;/ref&gt;&lt;ref&gt;
{{citation
 | last1 = Bubley | first1 = Russ
 | last2 = Dyer | first2 = Martin | author2-link = Martin Dyer
 | doi = 10.1016/S0012-365X(98)00333-1
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages =81-88
 | title = Faster random generation of linear extensions
 | volume = 201
 | year = 1999}}.&lt;/ref&gt; Among all partial orders with a fixed number of elements and a fixed number of comparable pairs, the partial orders that have the largest number of linear extensions are [[semiorder]]s.&lt;ref&gt;{{citation
 | last1 = Fishburn | first1 = Peter C. | author1-link = Peter C. Fishburn
 | last2 = Trotter | first2 = W. T.
 | doi = 10.1016/0012-365X(92)90036-F
 | mr = 1171114
 | issue = 1
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 25–40
 | title = Linear extensions of semiorders: a maximization problem
 | volume = 103
 | year = 1992}}.&lt;/ref&gt;

The [[order dimension]] of a partial order is the minimum cardinality of a set of linear extensions whose intersection is the given partial order; equivalently, it is the minimum number of linear extensions needed to ensure that each [[Critical pair (order theory)|critical pair]] of the partial order is reversed in at least one of the extensions.

[[Antimatroid]]s may be viewed as generalizing partial orders; in this view, the structures corresponding to the linear extensions of a partial order are the basic words of the antimatroid.&lt;ref&gt;{{citation
 | last1 = Björner | first1 = Anders
 | last2 = Ziegler | first2 = Günter M. | author2-link = Günter M. Ziegler
 | contribution = Introduction to Greedoids
 | editor-last = White | editor-first = Neil
 | isbn = 978-0-521-38165-9
 | pages = 284–357
 | publisher = Cambridge University Press
 | series = Encyclopedia of Mathematics and its Applications
 | title = Matroid Applications
 | volume = 40
 | year = 1992}}. See especially item (1) on {{nowrap|p. 294.}}&lt;/ref&gt;

This area also includes one of order theory's most famous open problems, the [[1/3–2/3 conjecture]], which states that in any finite partially ordered set ''P'' that is not [[total order|totally ordered]] there exists a pair (''x'',''y'') of elements of ''P'' for which the linear extensions of ''P'' in which {{nowrap|''x'' &lt; ''y''}} number between 1/3 and 2/3 of the total number of linear extensions of ''P''.&lt;ref&gt;{{citation|author=Kislitsyn, S. S.|year=1968|title=Finite partially ordered sets and their associated sets of permutations|journal=Matematicheskiye Zametki|volume=4|pages=511–518}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Brightwell | first = Graham R.
 | doi = 10.1016/S0012-365X(98)00311-2
 | issue = 1-3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 25–52
 | title = Balanced pairs in partial orders
 | volume = 201
 | year = 1999}}.&lt;/ref&gt; An equivalent way of stating the conjecture is that, if one chooses a linear extension of ''P'' uniformly at random, there is a pair (''x'',''y'') which has probability between 1/3 and 2/3 of being ordered as {{nowrap|''x'' &lt; ''y''}}. However, for certain infinite partially ordered sets, with a canonical probability defined on its linear extensions as a limit of the probabilities for finite partial orders that cover the infinite partial order, the 1/3–2/3 conjecture does not hold.&lt;ref&gt;{{citation
 | last1 = Brightwell | first1 = G. R.
 | last2 = Felsner | first2 = S.
 | last3 = Trotter | first3 = W. T.
 | doi = 10.1007/BF01110378
 | mr = 1368815
 | issue = 4
 | journal = [[Order (journal)|Order]]
 | pages = 327–349
 | title = Balancing pairs and the cross product conjecture
 | volume = 12
 | year = 1995}}.&lt;/ref&gt;

== References ==
{{reflist}}

[[Category:Order theory]]</text>
      <sha1>c23yoibox38nddgktsufot54o84n6e8</sha1>
    </revision>
  </page>
  <page>
    <title>List of numbers</title>
    <ns>0</ns>
    <id>209103</id>
    <revision>
      <id>871671392</id>
      <parentid>871188257</parentid>
      <timestamp>2018-12-02T18:14:16Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>con</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="63996">This is a list of articles about [[number]]s (''not'' about [[Numeral (linguistics)|numerals]]).

== Rational numbers ==
{{main|Rational number}}
A rational number is any number that can be expressed as the [[quotient]] or [[fraction (mathematics)|fraction]] {{math|''p''/''q''}} of two [[integer]]s, a [[numerator]] {{math|''p''}} and a non-zero [[denominator]] {{math|''q''}}.&lt;ref name="Rosen"&gt;{{cite book |last = Rosen |first=Kenneth |year=2007 |title=Discrete Mathematics and its Applications |edition=6th |publisher=McGraw-Hill |location=New York, NY |isbn=978-0-07-288008-3 |pages=105, 158–160}}&lt;/ref&gt; Since {{math|''q''}} may be equal to&amp;nbsp;1, every integer is a rational number. The [[set (mathematics)|set]] of all rational numbers, often referred to as "the rationals",  the field of rationals or the field of rational numbers is usually denoted by a boldface {{math|'''Q'''}} (or [[blackboard bold]] &lt;math&gt;\mathbb{Q}&lt;/math&gt;, Unicode &amp;#x211A;);&lt;ref&gt;{{cite web|last1=Rouse|first1=Margaret|title=Mathematical Symbols|url=http://searchdatacenter.techtarget.com/definition/Mathematical-Symbols|accessdate=1 April 2015}}&lt;/ref&gt; it was thus denoted in 1895 by [[Giuseppe Peano]] after ''[[wikt:quoziente|quoziente]]'', Italian for "[[quotient]]".

=== Natural numbers ===
{{main|Natural number}}
Natural numbers are those used for [[counting]] (as in "there are ''six'' (6) coins on the table") and [[total order|ordering]] (as in "this is the ''third'' (3rd) largest city in the country").  In common language, words used for counting are "[[cardinal number (linguistics)|cardinal numbers]]" and words used for ordering are "[[ordinal number (linguistics)|ordinal numbers]]". There are infinitely many natural numbers.

&lt;!-- Per consensus established so long ago I can't find it, this section only includes ''articles'', not ''redirects'', and is intended to include articles at least pointing to all the articles on "small" (less than 10^10) numbers.  If someone has a different idea of consensus for what should be in this section, please discuss. --&gt;

{| class="wikitable sortable mw-collapsible mw-collapsed" style="text-align: center" rowpadding="3"
|+
|-
| [[0]]
| [[1]]
| [[2]]
| [[3]]
| [[4]]
| [[5]]
| [[6]]
| [[7]]
| [[8]]
| [[9]]
|-
| [[10]]
| [[11 (number)|11]]
| [[12 (number)|12]]
| [[13 (number)|13]]
| [[14 (number)|14]]
| [[15 (number)|15]]
| [[16 (number)|16]]
| [[17 (number)|17]]
| [[18 (number)|18]]
| [[19 (number)|19]]
|-
| [[20 (number)|20]]
| [[21 (number)|21]]
| [[22 (number)|22]]
| [[23 (number)|23]]
| [[24 (number)|24]]
| [[25 (number)|25]]
| [[26 (number)|26]]
| [[27 (number)|27]]
| [[28 (number)|28]]
| [[29 (number)|29]]
|-
| [[30 (number)|30]]
| [[31 (number)|31]]
| [[32 (number)|32]]
| [[33 (number)|33]]
| [[34 (number)|34]]
| [[35 (number)|35]]
| [[36 (number)|36]]
| [[37 (number)|37]]
| [[38 (number)|38]]
| [[39 (number)|39]]
|-
| [[40 (number)|40]]
| [[41 (number)|41]]
| [[42 (number)|42]]
| [[43 (number)|43]]
| [[44 (number)|44]]
| [[45 (number)|45]]
| [[46 (number)|46]]
| [[47 (number)|47]]
| [[48 (number)|48]]
| [[49 (number)|49]]
|-
| [[50 (number)|50]]
| [[51 (number)|51]]
| [[52 (number)|52]]
| [[53 (number)|53]]
| [[54 (number)|54]]
| [[55 (number)|55]]
| [[56 (number)|56]]
| [[57 (number)|57]]
| [[58 (number)|58]]
| [[59 (number)|59]]
|-
| [[60 (number)|60]]
| [[61 (number)|61]]
| [[62 (number)|62]]
| [[63 (number)|63]]
| [[64 (number)|64]]
| [[65 (number)|65]]
| [[66 (number)|66]]
| [[67 (number)|67]]
| [[68 (number)|68]]
| [[69 (number)|69]]
|-
| [[70 (number)|70]]
| [[71 (number)|71]]
| [[72 (number)|72]]
| [[73 (number)|73]]
| [[74 (number)|74]]
| [[75 (number)|75]]
| [[76 (number)|76]]
| [[77 (number)|77]]
| [[78 (number)|78]]
| [[79 (number)|79]]
|-
| [[80 (number)|80]]
| [[81 (number)|81]]
| [[82 (number)|82]]
| [[83 (number)|83]]
| [[84 (number)|84]]
| [[85 (number)|85]]
| [[86 (number)|86]]
| [[87 (number)|87]]
| [[88 (number)|88]]
| [[89 (number)|89]]
|-
| [[90 (number)|90]]
| [[91 (number)|91]]
| [[92 (number)|92]]
| [[93 (number)|93]]
| [[94 (number)|94]]
| [[95 (number)|95]]
| [[96 (number)|96]]
| [[97 (number)|97]]
| [[98 (number)|98]]
| [[99 (number)|99]]
|-
| [[100 (number)|100]]
| [[101 (number)|101]]
| [[102 (number)|102]]
| [[103 (number)|103]]
| [[104 (number)|104]]
| [[105 (number)|105]]
| [[106 (number)|106]]
| [[107 (number)|107]]
| [[108 (number)|108]]
| [[109 (number)|109]]
|-
| [[110 (number)|110]]
| [[111 (number)|111]]
| [[112 (number)|112]]
| [[113 (number)|113]]
| [[114 (number)|114]]
| [[115 (number)|115]]
| [[116 (number)|116]]
| [[117 (number)|117]]
| [[118 (number)|118]]
| [[119 (number)|119]]
|-
| [[120 (number)|120]]
| [[121 (number)|121]]
| [[122 (number)|122]]
| [[123 (number)|123]]
| [[124 (number)|124]]
| [[125 (number)|125]]
| [[126 (number)|126]]
| [[127 (number)|127]]
| [[128 (number)|128]]
| [[129 (number)|129]]
|-
| [[130 (number)|130]]
| [[131 (number)|131]]
| [[132 (number)|132]]
| [[133 (number)|133]]
| [[134 (number)|134]]
| [[135 (number)|135]]
| [[136 (number)|136]]
| [[137 (number)|137]]
| [[138 (number)|138]]
| [[139 (number)|139]]
|-
| [[140 (number)|140]]
| [[141 (number)|141]]
| [[142 (number)|142]]
| [[143 (number)|143]]
| [[144 (number)|144]]
| [[145 (number)|145]]
| [[146 (number)|146]]
| [[147 (number)|147]]
| [[148 (number)|148]]
| [[149 (number)|149]]
|-
| [[150 (number)|150]]
| [[151 (number)|151]]
| [[152 (number)|152]]
| [[153 (number)|153]]
| [[154 (number)|154]]
| [[155 (number)|155]]
| [[156 (number)|156]]
| [[157 (number)|157]]
| [[158 (number)|158]]
| [[159 (number)|159]]
|-
| [[160 (number)|160]]
| [[161 (number)|161]]
| [[162 (number)|162]]
| [[163 (number)|163]]
| [[164 (number)|164]]
| [[165 (number)|165]]
| [[166 (number)|166]]
| [[167 (number)|167]]
| [[168 (number)|168]]
| [[169 (number)|169]]
|-
| [[170 (number)|170]]
| [[171 (number)|171]]
| [[172 (number)|172]]
| [[173 (number)|173]]
| [[174 (number)|174]]
| [[175 (number)|175]]
| [[176 (number)|176]]
| [[177 (number)|177]]
| [[178 (number)|178]]
| [[179 (number)|179]]
|-
| [[180 (number)|180]]
| [[181 (number)|181]]
| [[182 (number)|182]]
| [[183 (number)|183]]
| [[184 (number)|184]]
| [[185 (number)|185]]
| [[186 (number)|186]]
| [[187 (number)|187]]
| [[188 (number)|188]]
| [[189 (number)|189]]
|-
| [[190 (number)|190]]
| [[191 (number)|191]]
| [[192 (number)|192]]
| [[193 (number)|193]]
| [[194 (number)|194]]
| [[195 (number)|195]]
| [[196 (number)|196]]
| [[197 (number)|197]]
| [[198 (number)|198]]
| [[199 (number)|199]]
|-
| [[200 (number)|200]]
| [[201 (number)|201]]
| [[202 (number)|202]]
| [[203 (number)|203]]
| [[204 (number)|204]]
| [[205 (number)|205]]
| [[206 (number)|206]]
| [[207 (number)|207]]
| [[208 (number)|208]]
| [[209 (number)|209]]
|-
| [[210 (number)|210]]
| [[211 (number)|211]]
| [[212 (number)|212]]
| [[213 (number)|213]]
| [[214 (number)|214]]
| [[215 (number)|215]]
| [[216 (number)|216]]
| [[217 (number)|217]]
| [[218 (number)|218]]
| [[219 (number)|219]]
|-
| [[220 (number)|220]]
| [[221 (number)|221]]
| [[222 (number)|222]]
| [[223 (number)|223]]
| [[224 (number)|224]]
| [[225 (number)|225]]
| [[226 (number)|226]]
| [[227 (number)|227]]
| [[228 (number)|228]]
| [[229 (number)|229]]
|-
| [[230 (number)|230]]
| [[231 (number)|231]]
| [[232 (number)|232]]
| [[233 (number)|233]]
| [[234 (number)|234]]
| [[235 (number)|235]]
| [[236 (number)|236]]
| [[237 (number)|237]]
| [[238 (number)|238]]
| [[239 (number)|239]]
|-
| [[240 (number)|240]]
| [[241 (number)|241]]
| [[242 (number)|242]]
| [[243 (number)|243]]
| [[244 (number)|244]]
| [[245 (number)|245]]
| [[246 (number)|246]]
| [[247 (number)|247]]
| [[248 (number)|248]]
| [[249 (number)|249]]
|-
| [[250 (number)|250]]
| [[251 (number)|251]]
| [[252 (number)|252]]
| [[253 (number)|253]]
| [[254 (number)|254]]
| [[255 (number)|255]]
| [[256 (number)|256]]
| [[257 (number)|257]]
| [[258 (number)|258]]
| [[259 (number)|259]]
|-
|
|
|
|
|
|
| [[260 (number)|260]]
| [[270 (number)|270]]
| [[280 (number)|280]]
| [[290 (number)|290]]
|-
|
|
|
| [[300 (number)|300]]
| [[400 (number)|400]]
| [[500 (number)|500]]
| [[600 (number)|600]]
| [[700 (number)|700]]
| [[800 (number)|800]]
| [[900 (number)|900]]
|-
|
| [[1000 (number)|1000]]
| [[2000 (number)|2000]]
| [[3000 (number)|3000]]
| [[4000 (number)|4000]]
| [[5000 (number)|5000]]
| [[6000 (number)|6000]]
| [[7000 (number)|7000]]
| [[8000 (number)|8000]]
| [[9000 (number)|9000]]
|-
|
| [[10000 (number)|10000]]
| [[20000 (number)|20000]]
| [[30000 (number)|30000]]
| [[40000 (number)|40000]]
| [[50000 (number)|50000]]
| [[60000 (number)|60000]]
| [[70000 (number)|70000]]
| [[80000 (number)|80000]]
| [[90000 (number)|90000]]
|-
|
|
|
|
|
| [[100000 (number)|10&lt;sup&gt;5&lt;/sup&gt;]]
| [[1000000 (number)|10&lt;sup&gt;6&lt;/sup&gt;]]
| [[10000000 (number)|10&lt;sup&gt;7&lt;/sup&gt;]]
| [[100000000 (number)|10&lt;sup&gt;8&lt;/sup&gt;]]
| [[1000000000 (number)|10&lt;sup&gt;9&lt;/sup&gt;]]
|-
|
|
|
|
| [[10000000000 (number)|10&lt;sup&gt;10&lt;/sup&gt;]]
| [[Googol|10&lt;sup&gt;100&lt;/sup&gt;]]
| [[Googolplex|10&lt;sup&gt;10&lt;sup&gt;100&lt;/sup&gt;&lt;/sup&gt;]]
| colspan=3 |[[Orders of magnitude (numbers)|Larger numbers]]
|}
(Note that the status of 0 is ambiguous. In [[set theory]] and [[computer science]], 0 is considered a natural number. In [[number theory]], it usually is not.)

=== Powers of ten (scientific notation) ===
{{Main|Orders of magnitude (numbers)}}
A [[power of ten|power of ten 18]] is a number 10&lt;sup&gt;''k''&lt;/sup&gt;, where ''k'' is an integer. For instance, with ''k''&amp;nbsp;=&amp;nbsp;0, 1, 2, 3, ..., the appropriate powers of ten are 1, 10, 100, 1000, ... Powers of ten can also be fractional: for instance, ''k''&amp;nbsp;=&amp;nbsp;-3 gives 1/1000, or 0.001.

In [[scientific notation]], real numbers are written in the form ''m''&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;''n''&lt;/sup&gt;. The number 394,000 is written in this form as 3.94&amp;nbsp;×&amp;nbsp;10&lt;sup&gt;5&lt;/sup&gt;.

=== Integers ===
{{main|Integer}}

==== Notable integers ====
Integers that are notable for their mathematical properties or cultural meanings include:
* [[−40 (number)|−40]], the equal point in the [[Fahrenheit]] and [[Celsius]] scales.
* [[−1 (number)|−1]], the additive inverse of unity.
* [[0 (number)|0]], the [[additive identity]].
* [[1 (number)|1]], the multiplicative identity. Also the only natural number (not including 0) that isn't prime or composite.
* [[2 (number)|2]], the base of the [[binary number]] system, used in almost all modern computers and information systems. Also notable as the only even [[prime number]].
* [[3 (number)|3]], significant in [[Christianity]] as the [[Trinity]]. Also considered significant in [[Hinduism]] ([[Trimurti]], [[Tridevi]]). Holds significance in a number of ancient mythologies. 
* [[4 (number)|4]], the first [[composite number]], also considered an "unlucky number" in modern China due to its audible similarity to the word "Death."
* [[6 (number)|6]], the first of the series of [[perfect number]]s, whose proper factors sum to the number itself.
* [[7 (number)|7]], considered a [[numerology|"lucky" number]] in Western cultures.
* [[8 (number)|8]], considered a [[numerology|"lucky" number]] in Chinese culture.
* [[9 (number)|9]], the first [[Parity (mathematics)|odd]] number that is [[Composite number|composite]].
* [[10 (number)|10]], the [[decimal|number base]] for most modern counting systems.
* [[12 (number)|12]], the [[duodecimal|number base]] for some ancient counting systems and the basis for some modern measuring systems. Known as a [[dozen]].
* [[13 (number)|13]], considered an [[numerology|"unlucky" number]] in Western superstition. Also known as a "Baker's Dozen".
* [[20 (number)|20]], known as a [[20 (number)|score]].
* [[28 (number)|28]], the second [[perfect number]].
* [[42 (number)|42]], the "answer to the ultimate question of life, the universe, and everything" in the popular science fiction work ''[[The Hitchhiker's Guide to the Galaxy]]''.
* [[60 (number)|60]], the [[sexagesimal|number base]] for some ancient counting systems, such as the [[Babylonian numerals|Babylonians']], and the basis for many modern measuring systems.
* [[69 (number)|69]], used as slang to refer to a sexual act.
* [[86 (number)|86]], a slang term that is used in the American popular culture as a transitive verb to mean throw out or get rid of.&lt;ref name="mw"&gt;{{cite web|url=http://www.merriam-webster.com/dictionary/86|title=Eighty-six – Definition of eighty-six by Merriam-Webster|work=merriam-webster.com|deadurl=no|archiveurl=https://web.archive.org/web/20130408004615/http://www.merriam-webster.com/dictionary/86|archivedate=2013-04-08|df=}}&lt;/ref&gt;
* [[108 (number)|108]], considered sacred by the [[Dharmic Religions]]. Approximately equal to the ratio of the distance from Earth to Sun and diameter of the Sun.
* [[144 (number)|144]], a [[dozen]] times dozen, known as a [[gross (unit)|gross]].
* [[255 (number)|255]], 2&lt;sup&gt;8&lt;/sup&gt; − 1, a [[Mersenne number]] and the smallest [[perfect totient number]] that is neither a power of three nor thrice a prime; it is also the largest number that can be represented using an [[8-bit]] unsigned [[Integer (computer science)|integer]].
* [[420 (number)|420]], a code-term that refers to the consumption of [[420 (cannabis culture)|cannabis]].
* [[496 (number)|496]], the third [[perfect number]].
* [[666 (number)|666]], the [[Number of the Beast]] from the Book of Revelation.
* [[786 (number)|786]], regarded as sacred in the Muslim [[Abjad numerals|Abjad numerology]].
* [[1729 (number)|1729]], the [[Hardy–Ramanujan number]], also known as the second [[taxicab number]]; that is, the smallest positive integer that can be written as the sum of two positive cubes in two different ways.&lt;ref&gt;{{cite web|url=http://mathworld.wolfram.com/Hardy-RamanujanNumber.html|title=Hardy–Ramanujan Number|first=Eric W.|last=Weisstein|publisher=|deadurl=no|archiveurl=https://web.archive.org/web/20040408221409/http://mathworld.wolfram.com/Hardy-RamanujanNumber.html|archivedate=2004-04-08|df=}}&lt;/ref&gt;
* [[5040 (number)|5040]], mentioned by [[Plato]] in the ''[[Laws (dialogue)|Laws]]'' as one of the most important numbers for the city. It is also the largest [[factorial]] (7! = 5040) that is also a [[highly composite number]].
* [[8128 (number)|8128]], the fourth perfect number.
* [[65535 (number)|65535]], 2&lt;sup&gt;16&lt;/sup&gt; − 1, the maximum value of a [[16-bit]] unsigned integer.
* [[65537 (number)|65537]], 2&lt;sup&gt;16&lt;/sup&gt; + 1, the most popular RSA public key prime exponent in most SSL/TLS certificates on the Web/Internet.
* [[142857 (number)|142857]], the smallest [[base 10]] [[cyclic number]].
* [[2147483647]], 2&lt;sup&gt;31&lt;/sup&gt; − 1, the maximum value of a [[32-bit]] [[Integer (computer science)|signed integer]] using [[two's complement]] representation.
* [[9814072356 (number)|9814072356]], the largest [[perfect power]] that contains no repeated digits in base ten.
* [[9223372036854775807]], 2&lt;sup&gt;63&lt;/sup&gt; − 1, the maximum value of a [[64-bit]] [[Integer (computer science)|signed integer]] using [[two's complement]] representation.

==== Named numbers ====

* [[Googol]] (10&lt;sup&gt;100&lt;/sup&gt;) and [[googolplex]] (10&lt;sup&gt;(10&lt;sup&gt;100&lt;/sup&gt;)&lt;/sup&gt;) and [[googolplexian]] (10&lt;sup&gt;(10&lt;sup&gt;(10&lt;sup&gt;100&lt;/sup&gt;)&lt;/sup&gt;)&lt;/sup&gt;) or 1 followed by a googolplex of zeros.
* [[Graham's number]]
* [[Moser's number]]
* [[Shannon number]]
* [[Hardy–Ramanujan number]] (1729)
* [[Skewes' number]]
* [[Avogadro's number]]
* [[6174 (number)|Kaprekar's constant]] (6174)

=== Prime numbers ===
{{Main|Prime number}}
A prime number is a positive integer which has exactly two [[divisor]]s: 1 and itself.

The first 100 prime numbers are:

{| class="wikitable sortable mw-collapsible mw-collapsed" style="text-align: center" rowpadding="3"
|+
|-
 |&amp;nbsp;&amp;nbsp;[[2 (number)|2]] ||&amp;nbsp;&amp;nbsp;[[3 (number)|3]] ||&amp;nbsp;&amp;nbsp;[[5 (number)|5]] ||&amp;nbsp;&amp;nbsp;[[7 (number)|7]] ||&amp;nbsp;[[11 (number)|11]] ||&amp;nbsp;[[13 (number)|13]] ||&amp;nbsp;[[17 (number)|17]] ||&amp;nbsp;[[19 (number)|19]] ||&amp;nbsp;[[23 (number)|23]] ||&amp;nbsp;[[29 (number)|29]]
 |-
 |&amp;nbsp;[[31 (number)|31]] ||&amp;nbsp;[[37 (number)|37]] ||&amp;nbsp;[[41 (number)|41]] ||&amp;nbsp;[[43 (number)|43]] ||&amp;nbsp;[[47 (number)|47]] ||&amp;nbsp;[[53 (number)|53]] ||&amp;nbsp;[[59 (number)|59]] ||&amp;nbsp;[[61 (number)|61]] ||&amp;nbsp;[[67 (number)|67]] ||&amp;nbsp;[[71 (number)|71]]
 |-
 |&amp;nbsp;[[73 (number)|73]] ||&amp;nbsp;[[79 (number)|79]] ||&amp;nbsp;[[83 (number)|83]] ||&amp;nbsp;[[89 (number)|89]] ||&amp;nbsp;[[97 (number)|97]] ||[[101 (number)|101]] ||[[103 (number)|103]] ||[[107 (number)|107]] ||[[109 (number)|109]] ||[[113 (number)|113]]
 |-
 |[[127 (number)|127]] ||[[131 (number)|131]] ||[[137 (number)|137]] ||[[139 (number)|139]] ||[[149 (number)|149]] ||[[151 (number)|151]] ||[[157 (number)|157]] ||[[163 (number)|163]] ||[[167 (number)|167]]||[[173 (number)|173]]
 |-
 |[[179 (number)|179]]||[[181 (number)|181]] ||[[191 (number)|191]]||[[193 (number)|193]] ||[[197 (number)|197]] ||[[199 (number)|199]] ||[[211 (number)|211]] ||[[223 (number)|223]] ||[[227 (number)|227]]||[[229 (number)|229]]
 |-
 |[[233 (number)|233]] ||[[239 (number)|239]] ||[[241 (number)|241]] ||[[251 (number)|251]] ||[[257 (number)|257]] ||[[263 (number)|263]] ||[[269 (number)|269]] ||[[271 (number)|271]] ||[[277 (number)|277]] ||[[281 (number)|281]]
 |-
 |[[283 (number)|283]] ||[[293 (number)|293]] ||[[307 (number)|307]] ||[[311 (number)|311]] ||[[313 (number)|313]] ||[[317 (number)|317]] ||[[331 (number)|331]] ||[[337 (number)|337]] ||[[347 (number)|347]] ||[[349 (number)|349]]
 |-
 |[[353 (number)|353]] ||[[359 (number)|359]] ||[[367 (number)|367]] ||[[373 (number)|373]] ||[[379 (number)|379]] ||[[383 (number)|383]] ||[[389 (number)|389]] ||[[397 (number)|397]] ||[[401 (number)|401]] ||[[409 (number)|409]]
 |-
 |[[419 (number)|419]] ||[[421 (number)|421]] ||[[431 (number)|431]] ||[[433 (number)|433]] ||[[439 (number)|439]] ||[[443 (number)|443]] ||[[449 (number)|449]] ||[[457 (number)|457]] ||[[461 (number)|461]] ||[[463 (number)|463]]
 |-
 |[[467 (number)|467]] ||[[479 (number)|479]] ||[[487 (number)|487]] ||[[491 (number)|491]] ||[[499 (number)|499]] ||[[503 (number)|503]] ||[[509 (number)|509]] ||[[521 (number)|521]] ||[[523 (number)|523]] ||[[541 (number)|541]]
 |}

=== Highly composite numbers ===
{{main|Highly composite number}}

A highly composite number (HCN) is a positive integer with more divisors than any smaller positive integer. They are often used in [[geometry]], grouping and time measurement.

The first 20 highly composite numbers are:

[[1 (number)|1]], [[2 (number)|2]], [[4 (number)|4]], [[6 (number)|6]], [[12 (number)|12]], [[24 (number)|24]], [[36 (number)|36]], [[48 (number)|48]], [[60 (number)|60]], [[120 (number)|120]], [[180 (number)|180]], [[240 (number)|240]], [[360 (number)|360]], [[720 (number)|720]], [[840 (number)|840]], [[1260 (number)|1260]], [[1680 (number)|1680]], [[2520 (number)|2520]], [[5040 (number)|5040]], [[7560 (number)|7560]].

=== Perfect numbers ===
{{main|Perfect number}}

A perfect number is an integer that is the sum of its positive proper divisors (all divisors except itself).

The first 10 perfect numbers:

{| class="wikitable" style="text-align:right"
|-
! 1
|[[6 (number)|6]]
|-
! 2
|[[28 (number)|28]]
|-
! 3
|[[496 (number)|496]]
|-
! 4
|[[8128 (number)|8 128]]
|-
! 5
|33 550 336
|-
! 6
|8 589 869 056
|-
! 7
|137 438 691 328
|-
! 8
|2 305 843 008 139 952 128
|-
! 9
|2 658 455 991 569 831 744 654 692 615 953 842 176
|-
! 10
|191 561 942 608 236 107 294 793 378 084 303 638 130 997 321 548 169 216
|}

=== Cardinal numbers ===
{{main|cardinal number}}

In the following tables, [and] indicates that the word ''and'' is used in some [[dialect]]s (such as [[British English]]), and omitted in other dialects (such as [[American English]]).

==== Small numbers ====
This table demonstrates the standard English construction of small cardinal numbers up to one hundred million—names for which all variants of English agree.
{| class="wikitable sortable"
|-
! Value !! Name !! Alternate names, and names for sets of the given size
|-
| align="right" | 0 || [[Names for the number 0|Zero]] || aught, cipher, cypher, donut, dot, duck, goose egg, [[Tennis score#Scoring a game|love]], nada, naught, nil, none, nought, nowt, null, ought, oh, squat, zed, zilch, zip, zippo, Sunya ([[Sanskrit]])
|-
| align="right" | 1 || One || ace, individual, single, singleton, unary, unit, unity, Pratham([[Sanskrit]])
|-
| align="right" | 2 || Two || binary, [[brace (grouping)|brace]], couple, couplet, distich, deuce, double, doubleton, duad, duality, duet, duo, dyad, pair, span, twain, twin, twosome, yoke
|-
| align="right" | 3 || Three || deuce-ace, leash, set, tercet, ternary, ternion, terzetto, threesome, tierce, trey, triad, trine, trinity, trio, triplet, troika, hat-trick
|-
| align="right" | 4 || Four || foursome, quadruplet, quatern, quaternary, quaternity, quartet, tetrad
|-
| align="right" | 5 || Five || cinque, fin, fivesome, pentad, quint, quintet, quintuplet
|-
| align="right" | 6 || Six || half dozen, hexad, sestet, sextet, sextuplet, sise
|-
| align="right" | 7 || Seven || heptad, septet, septuple, [[List of playing-card nicknames#Single cards|walking stick]]
|-
| align="right" | 8 || Eight || octad, octave, octet, octonary, octuplet, ogdoad
|-
| align="right" | 9 || Nine || ennead
|-
| align="right" | 10 || Ten || deca, decade, das ([[India]])
|-
| align="right" | 11 || Eleven || onze, ounze, ounce, [[wikt:banker's dozen|banker's dozen]]
|-
| align="right" | 12 || Twelve || dozen
|-
| align="right" | 13 || Thirteen || [[baker's dozen]], long dozen&lt;ref name="ShipAssistant"&gt;{{cite web|url=https://books.google.com/books?id=cDkSAAAAYAAJ&amp;pg=PA417&amp;lpg=PA417&amp;dq=%22long%20score%22%2021&amp;source=bl&amp;ots=uU-HfR9K0J&amp;sig=YhXx-SlxYVF38x27a_X9Ia7ncR8&amp;hl=en&amp;ei=9vjSTbPvM8ezrAeys6jECQ&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=1&amp;ved=0CBgQ6AEwAA#v=onepage&amp;q&amp;f=false|title=The Shipmaster's Assistant, and Commercial Digest: Containing Information Useful to Merchants, Owners, and Masters of Ships |first=Joseph|last=Blunt|date=1 January 1837|publisher=E. &amp; G.W. Blunt|via=Google Books}}&lt;/ref&gt;
|-
| align="right" | 14 || Fourteen || rowspan=6 |
|-
| align="right" | 15 || Fifteen
|-
| align="right" | 16 || Sixteen
|-
| align="right" | 17 || Seventeen
|-
| align="right" | 18 || Eighteen
|-
| align="right" | 19 || Nineteen
|-
| align="right" | 20 || Twenty || score, 
|-
| align="right" | 21 || Twenty-one || long score&lt;ref name="ShipAssistant" /&gt;
|-
| align="right" | 22 || Twenty-two || Deuce-deuce
|-
| align="right" | 23 || Twenty-three ||
|-
| align="right" | 24 || Twenty-four || two dozen
|-
| align="right" | 25 || Twenty-five || rowspan=8 |
|-
| align="right" | 26 || Twenty-six
|-
| align="right" | 27 || Twenty-seven
|-
| align="right" | 28 || Twenty-eight
|-
| align="right" | 29 || Twenty-nine
|-
| align="right" | 30 || Thirty
|-
| align="right" | 31 || Thirty-one
|-
| align="right" | 32 || Thirty-two
|-
| align="right" | 40 || Forty || two-score
|-
| align="right" | 50 || Fifty || half-century
|-
| align="right" | 60 || Sixty || three-score
|-
| align="right" | 70 || Seventy || three-score and ten
|-
| align="right" | 80 || Eighty || four-score
|-
| align="right" | 87 || Eighty-seven || [[Gettysburg Address|four-score and seven]]
|-
| align="right" | 90 || Ninety || four-score and ten
|-
| align="right" | 100 || One hundred || centred, century, ton, short hundred
|-
| align="right" | 101 || One hundred [and] one
|-
| align="right" | 110 || One hundred [and] ten
|-
| align="right" | 111 || One hundred [and] eleven || eleventy-one&lt;ref&gt;{{cite news |last=Ezard |first=John |date=2 Jan 2003 |title=
Tolkien catches up with his hobbit |url=https://www.theguardian.com/uk/2003/jan/02/jrrtolkien.books |work=The Guardian |access-date=6 Apr 2018 }}&lt;/ref&gt;
|-
| align="right" | 120 || One hundred [and] twenty || long hundred,&lt;ref name="ShipAssistant" /&gt; great hundred, ''(obsolete)'' hundred
|-
| align="right" | 121 || One hundred [and] twenty-one
|-
| align="right" | 144 || One hundred [and] forty-four || [[Gross (unit)|gross]], dozen dozen, small gross
|-
| align="right" | 200 || Two hundred || rowspan= 10|
|-
| align="right" | 300 || Three hundred
|-
| align="right" | 400 || Four hundred
|-
| align="right" | 500 || Five hundred
|-
| align="right" | 600 || Six hundred
|-
| align="right" | 666 || Six hundred [and] sixty-six
|-
| align="right" | 700 || Seven hundred
|-
| align="right" | 777 || Seven hundred [and] seventy-seven
|-
| align="right" | 800 || Eight hundred
|-
| align="right" | 900 || Nine hundred
|-
| align="right" | {{gaps|1|000}} || One thousand || chiliad, grand, G, thou, yard, kilo, k, [[millennium]], Hajaar ([[India]])
|-
| align="right" | {{gaps|1|001}} || One thousand [and] one || rowspan=3 |
|-
| align="right" | {{gaps|1|010}} || One thousand [and] ten
|-
| align="right" | {{gaps|1|011}} || One thousand [and] eleven
|-
| align="right" | {{gaps|1|024}} || One thousand [and] twenty-four || kibi or kilo in [[computing]], see [[binary prefix]] (kilo is shortened to K, Kibi to Ki)
|-
| align="right" | {{gaps|1|100}} || One thousand one hundred || Eleven hundred
|-
| align="right" | {{gaps|1|101}} || One thousand one hundred [and] one ||
|-
| align="right" | {{gaps|1|728}} || One thousand seven hundred [and] twenty-eight || great gross, long gross, dozen gross
|-
| align="right" | {{gaps|2|000}} || Two thousand || rowspan=2 |
|-
| align="right" | {{gaps|3|000}} || Three thousand
|-
| align="right" | {{gaps|10|000}} || Ten thousand || [[myriad]], [[Myriad#Sinosphere|wan]] (China)
|-
| align="right" | {{gaps|100|000}} || One hundred thousand || [[lakh]]
|-
| align="right" | {{gaps|500|000}} || Five hundred thousand || [[crore]] (Iranian)
|-
| align="right" | {{gaps|1|000|000}} || One million || Mega, meg, mil, (often shortened to M)
|-
| align="right" | {{gaps|1|048|576}} || One million forty-eight thousand five hundred [and] seventy-six || Mibi or Mega in [[computing]], see [[binary prefix]] (Mega is shortened to M, Mibi to Mi)
|-
| align="right" | {{gaps|10|000|000}} || Ten million || [[crore]] (Indian)(Pakistan)
|-
| align="right" | {{gaps|100|000|000}} || One hundred million || [[Myriad#Sinosphere|yi]] (China)
|-
|}

==== English names for powers of 10 ====
This table compares the English names of cardinal numbers according to various American, British, and Continental European conventions. See [[English numerals]] or [[names of large numbers]] for more information on naming numbers.
{| class="wikitable"
|- style="text-align: center"
! !! [[long and short scales|Short scale]] !! colspan="2" | [[long and short scales|Long scale]] !! colspan="2" | Power
|- style="background: #eeeeff; text-align: center"
! Value !! American!! British&lt;br&gt; ([[Nicolas Chuquet]]) !! Continental European &lt;br&gt; ([[Jacques Peletier du Mans]]) !! of a thousand !! of a million
|-
| 10&lt;sup&gt;0&lt;/sup&gt; || colspan=3 align="center"| One || 1000&lt;sup&gt;−1+1&lt;/sup&gt; || 1000000&lt;sup&gt;0&lt;/sup&gt;
|-
| 10&lt;sup&gt;1&lt;/sup&gt; || colspan=3 align="center"| Ten || ||
|-
| 10&lt;sup&gt;2&lt;/sup&gt; || colspan=3 align="center"| Hundred || ||
|-
| 10&lt;sup&gt;3&lt;/sup&gt; || colspan=3 align="center"| Thousand || 1000&lt;sup&gt;0+1&lt;/sup&gt; || 1000000&lt;sup&gt;0.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;6&lt;/sup&gt; || colspan=3 align="center"| Million || 1000&lt;sup&gt;1+1&lt;/sup&gt; || 1000000&lt;sup&gt;1&lt;/sup&gt;
|-
| 10&lt;sup&gt;9&lt;/sup&gt; || Billion || Thousand million || Milliard || 1000&lt;sup&gt;2+1&lt;/sup&gt; || 1000000&lt;sup&gt;1.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;12&lt;/sup&gt; || Trillion || colspan=2 align="center"| Billion || 1000&lt;sup&gt;3+1&lt;/sup&gt; || 1000000&lt;sup&gt;2&lt;/sup&gt;
|-
| 10&lt;sup&gt;15&lt;/sup&gt; || Quadrillion || Thousand billion || Billiard || 1000&lt;sup&gt;4+1&lt;/sup&gt; || 1000000&lt;sup&gt;2.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;18&lt;/sup&gt; || Quintillion || colspan=2 align="center"| Trillion || 1000&lt;sup&gt;5+1&lt;/sup&gt; || 1000000&lt;sup&gt;3&lt;/sup&gt;
|-
| 10&lt;sup&gt;21&lt;/sup&gt; || Sextillion || Thousand trillion || Trilliard || 1000&lt;sup&gt;6+1&lt;/sup&gt; || 1000000&lt;sup&gt;3.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;24&lt;/sup&gt; || Septillion || colspan=2 align="center"| Quadrillion || 1000&lt;sup&gt;7+1&lt;/sup&gt; || 1000000&lt;sup&gt;4&lt;/sup&gt;
|-
| 10&lt;sup&gt;27&lt;/sup&gt; || Octillion || Thousand quadrillion || Quadrilliard || 1000&lt;sup&gt;8+1&lt;/sup&gt; || 1000000&lt;sup&gt;4.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;30&lt;/sup&gt; || Nonillion || colspan=2 align="center"| Quintillion || 1000&lt;sup&gt;9+1&lt;/sup&gt; || 1000000&lt;sup&gt;5&lt;/sup&gt;
|-
| 10&lt;sup&gt;33&lt;/sup&gt; || Decillion || Thousand quintillion || Quintilliard || 1000&lt;sup&gt;10+1&lt;/sup&gt; || 1000000&lt;sup&gt;5.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;36&lt;/sup&gt; || Undecillion || colspan=2 align="center"| Sextillion || 1000&lt;sup&gt;11+1&lt;/sup&gt; || 1000000&lt;sup&gt;6&lt;/sup&gt;
|-
| 10&lt;sup&gt;39&lt;/sup&gt; || Duodecillion || Thousand sextillion || Sextilliard || 1000&lt;sup&gt;12+1&lt;/sup&gt; || 1000000&lt;sup&gt;6.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;42&lt;/sup&gt; || Tredecillion || colspan=2 align="center"| Septillion || 1000&lt;sup&gt;13+1&lt;/sup&gt; || 1000000&lt;sup&gt;7&lt;/sup&gt;
|-
| 10&lt;sup&gt;45&lt;/sup&gt; || Quattuordecillion || Thousand septillion || Septilliard || 1000&lt;sup&gt;14+1&lt;/sup&gt; || 1000000&lt;sup&gt;7.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;48&lt;/sup&gt; || Quindecillion || colspan=2 align="center"| Octillion || 1000&lt;sup&gt;15+1&lt;/sup&gt; || 1000000&lt;sup&gt;8&lt;/sup&gt;
|-
| 10&lt;sup&gt;51&lt;/sup&gt; || Sexdecillion || Thousand octillion || Octilliard || 1000&lt;sup&gt;16+1&lt;/sup&gt; || 1000000&lt;sup&gt;8.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;54&lt;/sup&gt; || Septendecillion || colspan=2 align="center"| Nonillion || 1000&lt;sup&gt;17+1&lt;/sup&gt; || 1000000&lt;sup&gt;9&lt;/sup&gt;
|-
| 10&lt;sup&gt;57&lt;/sup&gt; || Octodecillion || Thousand nonillion || Nonilliard || 1000&lt;sup&gt;18+1&lt;/sup&gt; || 1000000&lt;sup&gt;9.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;60&lt;/sup&gt; || Novemdecillion || colspan=2 align="center"| Decillion || 1000&lt;sup&gt;19+1&lt;/sup&gt; || 1000000&lt;sup&gt;10&lt;/sup&gt;
|-
| 10&lt;sup&gt;63&lt;/sup&gt; || Vigintillion || Thousand decillion || Decilliard || 1000&lt;sup&gt;20+1&lt;/sup&gt; || 1000000&lt;sup&gt;10.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;66&lt;/sup&gt; || Unvigintillion || colspan=2 align="center"| Undecillion || 1000&lt;sup&gt;21+1&lt;/sup&gt; || 1000000&lt;sup&gt;11&lt;/sup&gt;
|-
| 10&lt;sup&gt;69&lt;/sup&gt; || Duovigintillion || Thousand undecillion || Undecilliard || 1000&lt;sup&gt;22+1&lt;/sup&gt; || 1000000&lt;sup&gt;11.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;72&lt;/sup&gt; || Trevigintillion || colspan=2 align="center"| Duodecillion || 1000&lt;sup&gt;23+1&lt;/sup&gt; || 1000000&lt;sup&gt;12&lt;/sup&gt;
|-
| 10&lt;sup&gt;75&lt;/sup&gt; || Quattuorvigintillion || Thousand duodecillion || Duodecilliard || 1000&lt;sup&gt;24+1&lt;/sup&gt; || 1000000&lt;sup&gt;12.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;78&lt;/sup&gt; || Quinvigintillion || colspan=2 align="center"| Tredecillion || 1000&lt;sup&gt;25+1&lt;/sup&gt; || 1000000&lt;sup&gt;13&lt;/sup&gt;
|-
| 10&lt;sup&gt;81&lt;/sup&gt; || Sexvigintillion || Thousand tredecillion || Tredecilliard || 1000&lt;sup&gt;26+1&lt;/sup&gt; || 1000000&lt;sup&gt;13.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;84&lt;/sup&gt; || Septenvigintillion || colspan=2 align="center"| Quattuordecillion || 1000&lt;sup&gt;27+1&lt;/sup&gt; || 1000000&lt;sup&gt;14&lt;/sup&gt;
|-
| 10&lt;sup&gt;87&lt;/sup&gt; || Octovigintillion || Thousand quattuordecillion || Quattuordecilliard || 1000&lt;sup&gt;28+1&lt;/sup&gt; || 1000000&lt;sup&gt;14.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;90&lt;/sup&gt; || Novemvigintillion || colspan=2 align="center"| Quindecillion || 1000&lt;sup&gt;29+1&lt;/sup&gt; || 1000000&lt;sup&gt;15&lt;/sup&gt;
|-
| 10&lt;sup&gt;93&lt;/sup&gt; || Trigintillion || Thousand quindecillion || Quindecilliard || 1000&lt;sup&gt;30+1&lt;/sup&gt; || 1000000&lt;sup&gt;15.5&lt;/sup&gt;
|-
| 10&lt;sup&gt;96&lt;/sup&gt; || Untrigintillion || colspan=2 align="center" | Sexdecillion || 1000&lt;sup&gt;31+1&lt;/sup&gt; || 1000000&lt;sup&gt;16&lt;/sup&gt;
|-
| 10&lt;sup&gt;99&lt;/sup&gt; || Duotrigintillion || Thousand sexdecillion || Sexdecilliard || 1000&lt;sup&gt;32+1&lt;/sup&gt; || 1000000&lt;sup&gt;16.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;120&lt;/sup&gt; || Novemtrigintillion || colspan=2 align="center"| Vigintillion || 1000&lt;sup&gt;39+1&lt;/sup&gt; || 1000000&lt;sup&gt;20&lt;/sup&gt;
|-
| 10&lt;sup&gt;123&lt;/sup&gt; || Quadragintillion || Thousand vigintillion || Vigintilliard || 1000&lt;sup&gt;40+1&lt;/sup&gt; || 1000000&lt;sup&gt;20.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;153&lt;/sup&gt; || Quinquagintillion || Thousand quinvigintillion || Quinvigintilliard || 1000&lt;sup&gt;50+1&lt;/sup&gt; || 1000000&lt;sup&gt;25.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;180&lt;/sup&gt; || Novemquinquagintillion || colspan=2 align="center"| Trigintillion || 1000&lt;sup&gt;59+1&lt;/sup&gt; || 1000000&lt;sup&gt;30&lt;/sup&gt;
|-
| 10&lt;sup&gt;183&lt;/sup&gt; || Sexagintillion || Thousand trigintillion || Trigintilliard || 1000&lt;sup&gt;60+1&lt;/sup&gt; || 1000000&lt;sup&gt;30.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;213&lt;/sup&gt; || Septuagintillion || Thousand quintrigintillion || Quintrigintilliard || 1000&lt;sup&gt;70+1&lt;/sup&gt; || 1000000&lt;sup&gt;35.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;240&lt;/sup&gt; || Novemseptuagintillion || colspan=2 align="center"| Quadragintillion || 1000&lt;sup&gt;79+1&lt;/sup&gt; || 1000000&lt;sup&gt;40&lt;/sup&gt;
|-
| 10&lt;sup&gt;243&lt;/sup&gt; || Octogintillion || Thousand quadragintillion || Quadragintilliard || 1000&lt;sup&gt;80+1&lt;/sup&gt; || 1000000&lt;sup&gt;40.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;273&lt;/sup&gt; || Nonagintillion || Thousand quinquadragintillion || Quinquadragintilliard || 1000&lt;sup&gt;90+1&lt;/sup&gt; || 1000000&lt;sup&gt;45.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;300&lt;/sup&gt; || Novemnonagintillion || colspan=2 align="center"| Quinquagintillion || 1000&lt;sup&gt;99+1&lt;/sup&gt; || 1000000&lt;sup&gt;50&lt;/sup&gt;
|-
| 10&lt;sup&gt;303&lt;/sup&gt; || [[Centillion]] || Thousand quinquagintillion || Quinquagintilliard || 1000&lt;sup&gt;100+1&lt;/sup&gt; || 1000000&lt;sup&gt;50.5&lt;/sup&gt;
|-
| ... || ... || colspan=2 align="center"| ... || ... || ...
|-
| 10&lt;sup&gt;360&lt;/sup&gt; || Cennovemdecillion || colspan=2 align="center"| Sexagintillion || 1000&lt;sup&gt;119+1&lt;/sup&gt; || 1000000&lt;sup&gt;60&lt;/sup&gt;
|-
| 10&lt;sup&gt;420&lt;/sup&gt; || Cennovemtrigintillion || colspan=2 align="center"| Septuagintillion || 1000&lt;sup&gt;139+1&lt;/sup&gt; || 1000000&lt;sup&gt;70&lt;/sup&gt;
|-
| 10&lt;sup&gt;480&lt;/sup&gt; || Cennovemquinquagintillion || colspan=2 align="center"| Octogintillion || 1000&lt;sup&gt;159+1&lt;/sup&gt; || 1000000&lt;sup&gt;80&lt;/sup&gt;
|-
| 10&lt;sup&gt;540&lt;/sup&gt; || Cennovemseptuagintillion || colspan=2 align="center"| Nonagintillion || 1000&lt;sup&gt;179+1&lt;/sup&gt; || 1000000&lt;sup&gt;90&lt;/sup&gt;
|-
| 10&lt;sup&gt;600&lt;/sup&gt; || Cennovemnonagintillion || colspan=2 align="center"| [[Centillion]] || 1000&lt;sup&gt;199+1&lt;/sup&gt; || 1000000&lt;sup&gt;100&lt;/sup&gt;
|-
| 10&lt;sup&gt;603&lt;/sup&gt; || Ducentillion || Thousand centillion || [[Centilliard]] || 1000&lt;sup&gt;200+1&lt;/sup&gt; || 1000000&lt;sup&gt;100.5&lt;/sup&gt;
|}

There is no consistent and widely accepted way to extend cardinals beyond [[centillion]] ([[centilliard]]).

==== SI prefixes for powers of 10 ====

{| class="wikitable"
|-
! Value !! 1000&lt;sup&gt;''m''&lt;/sup&gt; !! [[SI prefix]] !! Name !! [[Binary prefix]] !! 1024&lt;sup&gt;''m''&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;2&lt;sup&gt;10''m''&lt;/sup&gt; !!  Value
|-
| align="right" | {{gaps|1|000}} || 1000&lt;sup&gt;1&lt;/sup&gt; || k || [[Kilo-|Kilo]] || Ki || 1024&lt;sup&gt;1&lt;/sup&gt; || align="right" | 1 024
|-
| align="right" | {{gaps|1|000|000}} || 1000&lt;sup&gt;2&lt;/sup&gt; || M || [[Mega-|Mega]] || Mi || 1024&lt;sup&gt;2&lt;/sup&gt; || align="right" | 1 048 576
|-
| align="right" | {{gaps|1|000|000|000}} || 1000&lt;sup&gt;3&lt;/sup&gt; || G || [[Giga]] || Gi || 1024&lt;sup&gt;3&lt;/sup&gt; || align="right" | 1 073 741 824
|-
| align="right" | {{gaps|1|000|000|000|000}} || 1000&lt;sup&gt;4&lt;/sup&gt; || T || [[Tera-|Tera]] || Ti || 1024&lt;sup&gt;4&lt;/sup&gt; || align="right" | 1 099 511 627 776
|-
| align="right" | {{gaps|1|000|000|000|000|000}} || 1000&lt;sup&gt;5&lt;/sup&gt; || P || [[Peta-|Peta]] || Pi || 1024&lt;sup&gt;5&lt;/sup&gt; || align="right" | 1 125 899 906 842 624
|-
| align="right" | {{gaps|1|000|000|000|000|000|000}} || 1000&lt;sup&gt;6&lt;/sup&gt; || E || [[Exa]] || Ei || 1024&lt;sup&gt;6&lt;/sup&gt; || align="right" | 1 152 921 504 606 846 976
|-
| align="right" | {{gaps|1|000|000|000|000|000|000|000}} || 1000&lt;sup&gt;7&lt;/sup&gt; || Z || [[Zetta]] || Zi || 1024&lt;sup&gt;7&lt;/sup&gt; || align="right" | 1 180 591 620 717 411 303 424
|-
| align="right" | {{gaps|1|000|000|000|000|000|000|000|000}} || 1000&lt;sup&gt;8&lt;/sup&gt; || Y || [[Yotta]] || Yi || 1024&lt;sup&gt;8&lt;/sup&gt; || align="right" | 1 208 925 819 614 629 174 706 176
|-
|}

=== {{anchor|Fractional numbers}} Fractional numbers ===
&lt;!-- This Anchor tag serves to provide a permanent target for incoming section links. Please do not modify it, even if you modify the section title. --&gt;
{{See also|Fraction (mathematics)#Vocabulary|English numerals#Fractions and decimals}}
This is a table of English names for non-negative [[rational number]]s less than or equal to 1. It also lists alternative names, but there is no widespread convention for the names of extremely small positive numbers.

Keep in mind that rational numbers like 0.12 can be represented in [[Infinity|infinitely]] many ways, e.g. ''zero-point-one-two'' (0.12), ''twelve [[percent]]'' (12%), ''three twenty-fifths'' ({{sfrac|3|25}}), ''nine seventy-fifths'' ({{sfrac|9|75}}), ''six fiftieths'' ({{sfrac|6|50}}), ''twelve hundredths'' ({{sfrac|12|100}}), ''twenty-four two-hundredths'' ({{sfrac|24|200}}), etc.
{| class="wikitable"
|-
! Value !! Fraction !! Common names !! Alternative names
|-
| 1
| align="center" | {{sfrac|1|1}}
| One
| [[0.999...]], Unity
|-
| 0.9
| align="center" | {{sfrac|9|10}}
| Nine tenths, [zero] point nine
|-
| 0.8
| align="center" | {{sfrac|4|5}}
| Four fifths, eight tenths, [zero] point eight
|-
| 0.7
| align="center" | {{sfrac|7|10}}
| Seven tenths, [zero] point seven
|-
| 0.6
| align="center" | {{sfrac|3|5}}
| Three fifths, six tenths, [zero] point six
|-
| 0.5
| align="center" | {{sfrac|1|2}}
| [[One half]], five tenths, [zero] point five
|-
| 0.4
| align="center" | {{sfrac|2|5}}
| Two fifths, four tenths, [zero] point four
|-
| {{gaps|0.333|333...}}
| align="center" | {{sfrac|1|3}}
| One third
|-
| 0.3
| align="center" | {{sfrac|3|10}}
| Three tenths, [zero] point three
|-
| 0.25
| align="center" | {{sfrac|1|4}}
| One quarter, one fourth, twenty-five hundredths, [zero] point two five
|-
| 0.2
| align="center" | {{sfrac|1|5}}
| One fifth, two tenths, [zero] point two
|-
| {{gaps|0.166|666...}}
| align="center" | {{sfrac|1|6}}
| One sixth
|-
| {{gaps|0.142|857|142|857...}}
| align="center" | {{sfrac|1|7}}
| One seventh
|-
| 0.125
| align="center" | {{sfrac|1|8}}
| One eighth, one-hundred-[and-]twenty-five thousandths, [zero] point one two five
|-
| {{gaps|0.111|111...}}
| align="center" | {{sfrac|1|9}}
| One ninth
|-
| 0.1
| align="center" | {{sfrac|1|10}}
| One tenth, [zero] point one
| One perdecime, one perdime
|-
| {{gaps|0.090|909...}}
| align="center" | {{sfrac|1|11}}
| One eleventh
|-
| 0.09
| align="center" | {{sfrac|9|100}}
| Nine hundredths, [zero] point zero nine
|-
| {{gaps|0.083|333...}}
| align="center" | {{sfrac|1|12}}
| One twelfth
|-
| 0.08
| align="center" | {{sfrac|2|25}}
| Two twenty-fifths, eight hundredths, [zero] point zero eight
|-
| 0.0625
| align="center" | {{sfrac|1|16}}
| One sixteenth, six-hundred-[and-]twenty-five ten-thousandths, [zero] point zero six two five
|-
| 0.05
| align="center" | {{sfrac|1|20}}
| One twentieth, [zero] point zero five
|-
| {{gaps|0.047|619|047|619...}}
| align="center" | {{sfrac|1|21}}
| One twenty-first
|-
| {{gaps|0.045|454|545...}}
| align="center" | {{sfrac|1|22}}
| One twenty-second
|-
| {{gaps|0.043|478|260|869|565|217|391|304|347...}}
| align="center" | {{sfrac|1|23}}
| One twenty-third
|-
| {{gaps|0.041|666...}}
| align="center" | {{sfrac|1|24}}
| One twenty-fourth
|-
| {{gaps|0.033|333...}}
| align="center" | {{sfrac|1|30}}
| One thirtieth
|-
| 0.03125
| align="center" | {{sfrac|1|32}}
| One thirty-second, thirty one-hundred [and] twenty five hundred-thousandths, [zero] point zero three one two five
|-
| {{gaps|0.016|666...}}
| align="center" | {{sfrac|1|60}}
| One sixtieth
|-
| 0.015625
| align="center" | {{sfrac|1|64}}
| One sixty-fourth, ten thousand fifty six-hundred [and] twenty-five millionths, [zero] point zero one five six two five  
|-
| {{gaps|0.012|345|679|012|345|679...}}
| align="center" | {{sfrac|1|81}}
| One eighty-first
|-
| 0.01
| align="center" | {{sfrac|1|100}}
| One hundredth, [zero] point zero one
| One [[percent]]
|-
| 0.001
| align="center" | {{sfrac|1|1000}}
| One thousandth, [zero] point zero zero one
| One [[permille]]
|-
| {{gaps|0.000|277|777...}}
| align="center" | {{sfrac|1|3600}}
| One thirty-six hundredth
|-
| 0.0001
| align="center" | {{sfrac|1|{{gaps|10|000}}}}
| One ten-thousandth, [zero] point zero zero zero one
| One myriadth, one permyria, one permyriad, one [[basis point]]
|-
| {{gaps|0.000|01}}
| align="center" | {{sfrac|1|{{gaps|100|000}}}}
| One hundred-thousandth
| One lakhth, one perlakh
|-
| {{gaps|0.000|001}}
| align="center" | {{sfrac|1|{{gaps|1|000|000}}}}
| One millionth
| One [[Parts per million|ppm]]
|-
| {{gaps|0.000|000|1}}
| align="center" | {{sfrac|1|{{gaps|10|000|000}}}}
| One ten-millionth
| One crorth, one percrore
|-
| {{gaps|0.000|000|01}}
| align="center" | {{sfrac|1|{{gaps|100|000|000}}}}
| One hundred-millionth
|-
| {{gaps|0.000|000|001}}
| align="center" | {{sfrac|1|{{gaps|1|000|000|000}}}}
| One billionth (in some dialects)
| One [[Parts per billion|ppb]]
|-
| 0
| align="center" | {{sfrac|0|1}}
| [[Names for the number 0 in English|Zero]]
| Nil
|-
|}

== Irrational and suspected irrational numbers ==
{{main|Irrational number}}

=== Algebraic numbers ===
{{main|Algebraic number}}
{| class="wikitable"
|-
! Expression !! Approximate value !! Notes
|-
| align="center" | {{sfrac|{{sqrt|3}}|4}}
| {{val|0.433012701892219323381861585376}}
| Area of an [[equilateral triangle]] with side length 1.
|-
| align="center" | {{sfrac|{{sqrt|5}} − 1|2}}
| {{val|0.618033988749894848204586834366}}
| [[Golden ratio#Golden ratio conjugate|Golden ratio conjugate]] Φ, [[Multiplicative inverse|reciprocal]] of and one less than the [[golden ratio]].
|-
| align="center" | {{sfrac|{{sqrt|3}}|2}}
| {{val|0.866025403784438646763723170753}}
| Height of an [[equilateral triangle]] with side length 1.
|-
| align="center" | {{radic|2|12}}
| {{val|1.059463094359295264561825294946}}
| [[Twelfth root of two]]. &lt;br&gt; Proportion between the frequencies of adjacent [[semitone]]s in the [[equal temperament]] scale.
|-
| align="center" | {{sfrac|3{{sqrt|2}}|4}}
| {{val|1.060660171779821286601266543157}}
| The size of the cube that satisfies [[Prince Rupert's cube]].
|-
| align="center" | {{radic|2|3}}
| {{val|1.259921049894873164767210607278}}
| [[Cube root]] of two. &lt;br&gt; Length of the edge of a [[cube]] with volume two. See [[doubling the cube]] for the significance of this number.
|-
| align="center" | —
| {{val|1.303577269034296391257099112153}}
| [[Conway constant#Basic properties|Conway's constant]], defined as the unique positive real root of a certain polynomial of degree 71.
|-
| align="center" | &lt;math&gt;\sqrt[3]{\frac{1}{2}+\frac{1}{6}\sqrt{\frac{23}{3}}}+\sqrt[3]{\frac{1}{2}-\frac{1}{6}\sqrt{\frac{23}{3}}}&lt;/math&gt;
| {{val|1.324717957244746025960908854478}}
| [[Plastic number]], the unique real root of the cubic equation ''x''{{sup|3}} = ''x'' + 1.
|-
| align="center" | {{sqrt|2}}
| {{val|1.414213562373095048801688724210}}
| {{sqrt|2}} = 2 sin 45° = 2 cos 45° &lt;br&gt; [[Square root of two]] a.k.a. [[Pythagoras' constant]]. &lt;br&gt; Ratio of [[diagonal]] to side length in a [[Square (geometry)|square]]. &lt;br&gt; Proportion between the sides of [[paper size]]s in the [[ISO 216]] series (originally [[DIN]] 476 series).
|-
| align="center" | &lt;math&gt;\frac{1}{3}+\frac{2}{3\sqrt[3]{116+12\sqrt{93}}}+\frac{1}{6}\sqrt[3]{116+12\sqrt{93}}&lt;/math&gt;
| {{val|1.465571231876768026656731225220}}
| The limit to the ratio between subsequent numbers in the binary [[Look-and-say sequence]].
|-
| align="center" | &lt;math&gt;\frac{\sqrt{5+2\sqrt{5}}}{2}&lt;/math&gt;
| {{val|1.538841768587626701285145288018}}
| Altitude of a [[pentagon|regular pentagon]] with side length 1.
|-
| align="center" | {{sfrac|{{sqrt|17}} − 1|2}}
| {{val|1.561552812808830274910704927987}}
| The [[Triangular number#Triangular roots and tests for triangular numbers|Triangular root]] of 2.
|-
| align="center" | {{sfrac|{{sqrt|5}} + 1|2}}
| {{val|1.618033988749894848204586834366}}
| [[Golden ratio]] (φ), the larger of the two real roots of ''x''{{sup|2}} = ''x'' + 1.
|-
| align="center" | &lt;math&gt;\frac{5}{4\sqrt{5-2\sqrt{5}}}&lt;/math&gt;
| {{val|1.720477400588966922759011977389}}
| Area of a [[pentagon|regular pentagon]] with side length 1.
|-
| align="center" | {{sqrt|3}}
| {{val|1.732050807568877293527446341506}}
| {{sqrt|3}} = 2 sin 60° = 2 cos 30° &lt;br&gt; [[Square root of three]] a.k.a. ''[[vesica piscis|the measure of the fish]]''. &lt;br&gt; Length of the [[space diagonal]] of a [[cube]] with edge length 1. &lt;br&gt; Length of the diagonal of a 1 × {{sqrt|2}} [[rectangle]]. &lt;br&gt; [[Altitude (triangle)|Altitude]] of an [[equilateral triangle]] with side length 2. &lt;br&gt; Altitude of a [[hexagon|regular hexagon]] with side length 1 and diagonal length 2.
|-
| align="center" | &lt;math&gt;\frac{1+\sqrt[3]{19+3\sqrt{33}}+\sqrt[3]{19-3\sqrt{33}}}{3}&lt;/math&gt;
| {{val|1.839286755214161132551852564653}}
| The [[Generalizations of Fibonacci numbers#Tribonacci numbers|Tribonacci constant]]. &lt;br&gt; Appears in the volume and coordinates of the [[snub cube]] and some related polyhedra. &lt;br&gt; It satisfies the equation ''x'' + ''x''&lt;sup&gt;−3&lt;/sup&gt; = 2.
|-
| align="center" | {{sqrt|5}}
| {{val|2.236067977499789696409173668731}}
| [[Square root of five]]. &lt;br&gt; Length of the [[diagonal]] of a 1 × 2 [[rectangle]]. &lt;br&gt; Length of the diagonal of a {{sqrt|2}} × {{sqrt|3}} rectangle. &lt;br&gt; Length of the space diagonal of a 1 × {{sqrt|2}} × {{sqrt|2}} [[cuboid|rectangular box]].
|-
| align="center" | {{sqrt|2}} + 1
| {{val|2.414213562373095048801688724210}}
| [[Silver ratio]] (δ{{sub|S}}), the larger of the two real roots of ''x''{{sup|2}} = 2''x'' + 1.&lt;br&gt; Altitude of a [[octagon|regular octagon]] with side length 1.
|-
| align="center" | {{sqrt|6}}
| {{val|2.449489742783178098197284074706}}
| {{sqrt|2}} · {{sqrt|3}} = [[area]] of a {{sqrt|2}} × {{sqrt|3}} rectangle. &lt;br&gt; Length of the [[space diagonal]] of a 1 × 1 × 2 [[cuboid|rectangular box]]. &lt;br&gt; Length of the diagonal of a 1 × {{sqrt|5}} [[rectangle]]. &lt;br&gt; Length of the diagonal of a 2 × {{sqrt|2}} rectangle. &lt;br&gt; Length of the [[diagonal]] of a [[Square (geometry)|square]] with side length {{sqrt|3}}.
|-
| align="center" | {{sfrac|3{{sqrt|3}}|2}}
| {{val|2.598076113533159402911695122588}}
| Area of a [[hexagon|regular hexagon]] with side length 1.
|-
| align="center" | {{sqrt|7}}
| {{val|2.645751311064590590501615753639}}
| Length of the [[space diagonal]] of a 1 × 2 × {{sqrt|2}} [[cuboid|rectangular box]]. &lt;br&gt; Length of the diagonal of a 1 × {{sqrt|6}} [[rectangle]]. &lt;br&gt; Length of the diagonal of a 2 × {{sqrt|3}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|2}} × {{sqrt|5}} rectangle.
|-
| align="center" | {{sqrt|8}}
| {{val|2.828427124746190097603377448419}}
| 2{{sqrt|2}} &lt;br&gt; [[Volume]] of a [[cube]] with edge length {{sqrt|2}}. &lt;br&gt; Length of the [[diagonal]] of a [[Square (geometry)|square]] with side length 2. &lt;br&gt; Length of the diagonal of a 1 × {{sqrt|7}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|2}} × {{sqrt|6}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|3}} × {{sqrt|5}} rectangle.
|-
| align="center" | {{sqrt|10}}
| {{val|3.162277660168379331998893544433}}
| {{sqrt|2}} · {{sqrt|5}} = [[area]] of a {{sqrt|2}} × {{sqrt|5}} rectangle. &lt;br&gt; Length of the [[diagonal]] of a 1 × 3 [[rectangle]]. &lt;br&gt; Length of the diagonal of a 2 × {{sqrt|6}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|3}} × {{sqrt|7}} rectangle. &lt;br&gt; Length of the [[diagonal]] of a [[Square (geometry)|square]] with side length {{sqrt|5}}.
|-
| align="center" | {{sqrt|11}}
| {{val|3.316624790355399849114932736671}}
| Length of the [[space diagonal]] of a 1 × 1 × 3 [[cuboid|rectangular box]]. &lt;br&gt; Length of the diagonal of a 1 × {{sqrt|10}} [[rectangle]]. &lt;br&gt; Length of the diagonal of a 2 × {{sqrt|7}} rectangle. &lt;br&gt; Length of the diagonal of a 3 × {{sqrt|2}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|3}} × {{sqrt|8}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|5}} × {{sqrt|6}} rectangle.
|-
| align="center" | {{sqrt|12}}
| {{val|3.464101615137754587054892683012}}
| 2{{sqrt|3}} &lt;br&gt; Length of the [[space diagonal]] of a [[cube]] with edge length 2. &lt;br&gt; Length of the diagonal of a 1 × {{sqrt|11}} [[rectangle]]. &lt;br&gt; Length of the diagonal of a 2 × {{sqrt|8}} rectangle. &lt;br&gt; Length of the diagonal of a 3 × {{sqrt|3}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|2}} × {{sqrt|10}} rectangle. &lt;br&gt; Length of the diagonal of a {{sqrt|5}} × {{sqrt|7}} rectangle. &lt;br&gt; Length of the [[diagonal]] of a [[Square (geometry)|square]] with side length {{sqrt|6}}.
|}

=== Transcendental numbers ===
{{main|Transcendental number}}
* (−1)&lt;sup&gt;[[Imaginary unit|i]]&lt;/sup&gt; = e&lt;sup&gt;−{{pi}}&lt;/sup&gt; = {{val|0.0432139183}}...
* [[Liouville number#Liouville constant|Liouville constant]]: c = {{val|0.110001000000000000000001000}}...
* [[Champernowne constant]]: C&lt;sub&gt;10&lt;/sub&gt; = {{val|0.12345678910111213141516}}...
* [[Imaginary unit#i raised to the i power|i&lt;sup&gt;i&lt;/sup&gt;]] = {{sqrt|e{{sup|−{{pi}}}}}} = {{val|0.207879576}}...
* {{sfrac|1|[[pi|{{pi}}]]}} = {{val|0.318309886183790671537767526745028724068919291480}}...&lt;ref name="David Wells page 27"&gt;"The Penguin Dictionary of Curious and Interesting Numbers" by David Wells, page 27.&lt;/ref&gt;
* {{sfrac|1|[[e (number)|e]]}} = {{val|0.367879441171442321595523770161460867445811131031}}...&lt;ref name="David Wells page 27"/&gt;
* [[Prouhet–Thue–Morse constant]]: {{mvar|&amp;tau;}} = {{val|0.412454033640}}...
* [[Logarithm|log]]&lt;sub&gt;[[base 10|10]]&lt;/sub&gt; [[e (number)|e]] = {{val|0.434294481903251827651128918916605082294397005803}}...&lt;ref name="David Wells page 27"/&gt;
* [[Omega constant]]: Ω = {{val|0.5671432904097838729999686622}}...
* [[Cahen's constant]]: c = {{val|0.64341054629}}...
* [[Natural logarithm of 2|ln 2]]: {{val|0.693147180559945309417232121458}}...
* {{sfrac|{{pi}}|{{sqrt|18}}}} = 0.7404... the maximum density of sphere packing in three dimensional Euclidean space according to the [[Kepler conjecture]]&lt;ref name="David Wells page 29"&gt;"The Penguin Dictionary of Curious and Interesting Numbers" by David Wells, page 29.&lt;/ref&gt;
* [[Gauss's constant]]: G = {{val|0.8346268}}...
* {{sfrac|{{pi}}|{{sqrt|12}}}} = 0.9068..., the fraction of the plane covered by the densest possible [[circle packing#Packings in the plane|circle packing]]&lt;ref&gt;"The Penguin Dictionary of Curious and Interesting Numbers" by David Wells, page 30.&lt;/ref&gt;
* [[Euler number|e&lt;sup&gt;i&lt;/sup&gt; + e&lt;sup&gt;−i&lt;/sup&gt;]] = [[Cosine similarity|2 cos 1]] = {{val|1.08060461}}...
* {{sfrac|{{pi}}{{sup|4}}|90}} = [[Riemann zeta function|ζ]](4) = {{val|1.082323}}...&lt;ref&gt;"The Penguin Dictionary of Curious and Interesting Numbers" by David Wells, page 33.&lt;/ref&gt;
* [[Super-root#Square root|{{sqrt|2}}{{sub|''s''}}]]: {{val|1.559610469}}...&lt;ref&gt;{{cite web|url=http://www.qbyte.org/puzzles/p029s.html|title=Nick's Mathematical Puzzles: Solution 29|publisher=|deadurl=no|archiveurl=https://web.archive.org/web/20111018184029/http://www.qbyte.org/puzzles/p029s.html|archivedate=2011-10-18|df=}}&lt;/ref&gt;
* [[Irrational number#Logarithms|log&lt;sub&gt;2&lt;/sub&gt; 3]]: {{val|1.584962501}}... (the logarithm of any positive integer to any integer base greater than 1 is either rational or transcendental)
* [[Gaussian integral]]: {{sqrt|{{pi}}}} = {{val|1.772453850905516}}...
* [[Komornik–Loreti constant]]: q = {{val|1.787231650}}...
* [[Universal parabolic constant]]: P&lt;sub&gt;2&lt;/sub&gt; = {{val|2.29558714939}}...
* [[Gelfond–Schneider constant]]: 2{{sup|{{sqrt|2}}}} = {{val|2.665144143}}...
* [[Euler's number|e]] = {{val|2.718281828459045235360287471353}}...
* [[Pi|{{pi}}]] = {{val|3.141592653589793238462643383279}}...
* [[Imaginary unit|{{radic|i|i}}]] = {{sqrt|e{{sup|{{pi}}}}}} = {{val|4.810477381}}...
* [[Tau (mathematical constant)|Tau]], or 2{{pi}}: {{mvar|&amp;tau;}} = {{val|6.283185307179586}}..., The ratio of the [[circumference]] to a [[radius]], and the number of [[radian]]s in a complete circle&lt;ref&gt;"The Penguin Dictionary of Curious and Interesting Numbers" by David Wells, page 69&lt;/ref&gt;&lt;ref&gt;Sequence {{OEIS2C|A019692}}.&lt;/ref&gt;
* [[Gelfond's constant]]: {{val|23.14069263277925}}...
* [[Heegner number#Almost integers and Ramanujan's constant|Ramanujan's constant]]: e{{sup|{{pi}}{{sqrt|163}}}} = {{val|262537412640768743.99999999999925}}...

==== Suspected transcendentals ====

These are [[irrational number]]s that are thought to be, but have not yet been proved to be, transcendental.
* [[Riemann–Siegel formula|Z(1)]]: {{val|-0.736305462867317734677899828925614672}}...
* [[Heath-Brown–Moroz constant]]: C = {{val|0.001317641}}...
* [[Kepler–Bouwkamp constant]]: {{val|0.1149420448}}...
* [[MRB constant]]: {{val|0.187859}}...
* [[Meissel–Mertens constant]]: M = {{val|0.2614972128476427837554268386086958590516}}...
* [[Bernstein's constant]]: β = {{val|0.2801694990}}...
* [[Strongly carefree constant]]: {{val|0.286747}}...&lt;ref&gt;{{OEIS2C|A065473}}&lt;/ref&gt;
* [[Gauss–Kuzmin–Wirsing constant]]: λ&lt;sub&gt;1&lt;/sub&gt; = {{val|0.3036630029}}...&lt;ref&gt;{{mathworld|urlname=Gauss-Kuzmin-WirsingConstant|title=Gauss–Kuzmin–Wirsing Constant}}&lt;/ref&gt;
* [[Hafner–Sarnak–McCurley constant]]: {{val|0.3532363719}}...
* [[Artin's conjecture on primitive roots|Artin's constant]]: {{val|0.3739558136}}...
* [[Prime constant]]: ρ = {{val|0.414682509851111660248109622}}...
* [[Carefree constant]]: {{val|0.428249}}...&lt;ref&gt;{{OEIS2C|A065464}}&lt;/ref&gt;
* [[Fresnel integral|S(1)]]: {{val|0.438259147390354766076756696625152}}...
* [[Dawson integral|F(1)]]: {{val|0.538079506912768419136387420407556}}...
* [[Stephens' constant]]: {{val|0.575959}}...&lt;ref&gt;{{OEIS2C|A065478}}&lt;/ref&gt;
* [[Euler–Mascheroni constant]]: γ = {{val|0.577215664901532860606512090082}}...
* [[Golomb–Dickman constant]]: λ = {{val|0.62432998854355087099293638310083724}}...
* [[Twin prime conjecture#First Hardy.E2.80.93Littlewood conjecture|Twin prime constant]]: C&lt;sub&gt;2&lt;/sub&gt; = {{val|0.660161815846869573927812110014}}...
* [[Copeland–Erdős constant]]: {{val|0.235711131719232931374143}}...
* [[Feller–Tornier constant]]: {{val|0.661317}}...&lt;ref&gt;{{OEIS2C|A065493}}&lt;/ref&gt;
* [[Laplace limit]]: ε = {{val|0.6627434193}}...[http://mathworld.wolfram.com/LaplaceLimit.html]
* [[Taniguchi's constant]]: {{val|0.678234}}...&lt;ref&gt;{{OEIS2C|A175639}}&lt;/ref&gt;
* [[Continued Fraction Constant]]: C = {{val|0.697774657964007982006790592551}}...&lt;ref&gt;{{cite web|url=http://mathworld.wolfram.com/ContinuedFractionConstants.html|title=Continued Fraction Constant|first=Eric W.|last=Weisstein|publisher=Wolfram Research, Inc.|deadurl=no|archiveurl=https://web.archive.org/web/20111024094057/http://mathworld.wolfram.com/ContinuedFractionConstant.html|archivedate=2011-10-24|df=}}&lt;/ref&gt;
* [[Embree–Trefethen constant]]: β* = {{val|0.70258}}...
* [[Sarnak's constant]]: {{val|0.723648}}...&lt;ref&gt;{{OEIS2C|A065476}}&lt;/ref&gt;
* [[Landau–Ramanujan constant]]: {{val|0.76422365358922066299069873125}}...
* [[Fresnel integral|C(1)]]: {{val|0.77989340037682282947420641365}}...
* {{sfrac|1|[[Riemann zeta function|ζ]](3)}} = {{val|0.831907}}..., the probability that three random numbers have no [[common factor]] greater than 1.&lt;ref name="David Wells page 29"/&gt;
* [[Brun's constant|Brun's constant for prime quadruplets]]: B&lt;sub&gt;2&lt;/sub&gt; = {{val|0.8705883800}}...
* [[Quadratic class number constant]]: {{val|0.881513}}...&lt;ref&gt;{{OEIS2C|A065465}}&lt;/ref&gt;
* [[Catalan's constant]]: G = {{val|0.915965594177219015054603514932384110774}}...
* [[Random Fibonacci sequence|Viswanath's constant]]: σ(1) = {{val|1.1319882487943}}...
* [[Khinchin–Lévy constant]]: {{val|1.1865691104}}...[http://mathworld.wolfram.com/LevyConstant.html]
* [[Riemann zeta function|ζ]](3) = {{val|1.202056903159594285399738161511449990764986292}}..., also known as [[Apéry's constant]], known to be irrational, but not known whether or not it is [[Transcendental function|transcendental]].&lt;ref&gt;"The Penguin Dictionary of Curious and Interesting Numbers" by David Wells, page 33&lt;/ref&gt;
* [[Double exponential function#Doubly exponential sequences|Vardi's constant]]: E = {{val|1.264084735305}}...
* [[Glaisher–Kinkelin constant]]: A = {{val|1.28242712}}...
* [[Mills' constant]]: A = {{val|1.30637788386308069046}}...
* [[Totient summatory constant]]: {{val|1.339784}}...&lt;ref&gt;{{OEIS2C|A065483}}&lt;/ref&gt;
* [[Ramanujan–Soldner constant]]: μ = {{val|1.451369234883381050283968485892027449493}}...
* [[Backhouse's constant]]: {{val|1.456074948}}...
* [[Favard constant]]: K&lt;sub&gt;1&lt;/sub&gt; = {{val|1.57079633}}...
* [[Erdős–Borwein constant]]: E = {{val|1.606695152415291763}}...
* [[Somos' quadratic recurrence constant]]: σ = {{val|1.661687949633594121296}}...
* [[Niven's constant]]: c = {{val|1.705211}}...
* [[Brun's constant]]: B&lt;sub&gt;2&lt;/sub&gt; = {{val|1.902160583104}}...
* [[Landau's totient constant]]: {{val|1.943596}}...&lt;ref&gt;{{OEIS2C|A082695}}&lt;/ref&gt;
* [[Lambert W function|exp(−W{{sub|0}}(−ln({{radic|3|3}})))]] = {{val|2.47805268028830}}..., the smaller solution to 3{{sup|''x''}} = ''x''{{sup|3}} and what, when put to the root of itself, is equal to 3 put to the root of itself.&lt;ref&gt;{{OEIS2C|A166928}}&lt;/ref&gt;
* Second [[Feigenbaum constant]]: α = 2.5029...
* [[Sierpiński's constant]]: K = {{val|2.5849817595792532170658936}}...
* [[Barban's constant]]: {{val|2.596536}}...&lt;ref&gt;{{OEIS2C|A175640}}&lt;/ref&gt;
* [[Khinchin's constant]]: K&lt;sub&gt;0&lt;/sub&gt; = {{val|2.685452001}}...[http://mathworld.wolfram.com/KhinchinsConstant.html]
* [[Fransén–Robinson constant]]: F = {{val|2.8077702420}}...
* [[Murata's constant]]: {{val|2.826419}}...&lt;ref&gt;{{OEIS2C|A065485}}&lt;/ref&gt;
* [[Lévy's constant]]: γ = {{val|3.275822918721811159787681882}}...
* [[Reciprocal Fibonacci constant]]: ψ = {{val|3.359885666243177553172011302918927179688905133731}}...
* [[Van der Pauw's constant]]: {{sfrac|{{pi}}|ln 2}} = {{val|4.53236014182719380962}}...&lt;ref&gt;{{OEIS2C|A163973}}&lt;/ref&gt;
* First [[Feigenbaum constant]]: δ = 4.6692...

=== Numbers not known with high precision ===

* The constant in the [[Berry–Esseen theorem|Berry–Esseen Theorem]]: 0.4097 &lt; ''C'' &lt; 0.4748
* [[Landau's constants|2nd Landau's constant]]: 0.4330 &lt; ''B'' &lt; 0.472
* [[Bloch's theorem (complex variables)#Bloch's constant|Bloch's constant]]: 0.4332 &lt; ''B'' &lt; 0.4719
* [[Landau's constants|1st Landau's constant]]: 0.5 &lt; ''L'' &lt; 0.5433
* [[Landau's constants|3rd Landau's constant]]: 0.5 &lt; ''A'' ≤ 0.7853
* [[Grothendieck constant]]: 1.57 &lt; ''k'' &lt; 1.79

== Hypercomplex numbers ==
{{main|Hypercomplex number}}
[[Hypercomplex number]] is a traditional term for an [[element (mathematics)|element]] of a unital [[algebra over a field|algebra]] over the [[field (mathematics)|field]] of [[real number]]s.

=== Algebraic complex numbers ===

* [[Imaginary unit]]: i = {{sqrt|−1}}
* ''n''th [[roots of unity]]: (ξ{{sub|''n''}}){{sup|''k''}} = cos (2{{pi}} {{sfrac|''k''|''n''}}) + i sin (2{{pi}} {{sfrac|''k''|''n''}}), while 0 ≤ ''k'' ≤ ''n''−1, [[greatest common divisor|GCD]](''k'', ''n'') = 1

===Other hypercomplex numbers===

* The [[quaternion]]s
* The [[octonion]]s
* The [[sedenion]]s
* The [[dual number]]s (with an [[infinitesimal]])

== Transfinite numbers ==
{{main|Transfinite number}}
[[Transfinite numbers]] are numbers that are "[[Infinity|infinite]]" in the sense that they are larger than all [[finite set|finite]] numbers, yet not necessarily [[absolutely infinite]].
* [[Aleph-null]]: ℵ{{sub|0}}: the smallest infinite cardinal, and the cardinality of ℕ, the set of [[natural number]]s
* [[Aleph-one]]: ℵ{{sub|1}}: the cardinality of ω&lt;sub&gt;1&lt;/sub&gt;, the set of all countable ordinal numbers
* [[Beth-one]]: ℶ{{sub|1}} the [[cardinality of the continuum]] 2{{sup|ℵ{{sub|0}}}}
* ℭ or &lt;math&gt;\mathfrak c&lt;/math&gt;: the [[cardinality of the continuum]] 2{{sup|ℵ{{sub|0}}}}
* [[First infinite ordinal|omega]]: ω, the smallest [[infinite ordinal]]

== Numbers representing measured quantities ==
Various terms have arisen to describe commonly used measured quantities.
* [[2 (number)|Pair]]: 2 (the base of the [[binary numeral system]])
* [[Dozen]]: 12 (the base of the [[duodecimal]] numeral system)
* [[Baker's dozen]]: 13
* [[20 (number)|Score]]: 20 (the base of the [[vigesimal]] numeral system)
* [[Gross (unit)|Gross]]: 144 (= 12&lt;sup&gt;2&lt;/sup&gt;)
* [[Great gross]]: 1728 (= 12&lt;sup&gt;3&lt;/sup&gt;)

== Numbers representing physical quantities ==
Physical quantities that appear in the universe are often described using [[physical constant]]s.
* [[Avogadro constant]]: ''N''{{sub|A}} = {{val|6.0221417930e23}} mol&lt;sup&gt;−1&lt;/sup&gt;
* [[Coulomb's constant]]: ''k''{{sub|e}} = {{val|8.987551787368e9}} [[newton (unit)|N]]&amp;middot;[[metre|m]]&lt;sup&gt;2&lt;/sup&gt;/[[coulomb|C]]&lt;sup&gt;2&lt;/sup&gt; (m/[[farad|F]])
* [[Electronvolt]]: eV = {{val|1.60217648740e-19}} J
* [[Electron#Fundamental properties|Electron relative atomic mass]]: ''A''{{sub|r}}(e) = {{val|0.0005485799094323}}...
* [[Fine structure constant]]: ''α'' = {{val|0.007297352537650}}...
* [[Gravitational constant]]: ''G'' = {{val|6.67384e−11}}&amp;nbsp;N·(m/kg)&lt;sup&gt;2&lt;/sup&gt;
* [[Molar mass constant]]: ''M''{{sub|u}} = 0.001&amp;nbsp;kg/mol
* [[Planck constant]]: ''h'' = {{val|6.6260689633e-34}} J · s
* [[Rydberg constant]]: ''R''{{sub|∞}} = {{val|10973731.56852773}} m&lt;sup&gt;−1&lt;/sup&gt;
* [[Speed of light|Speed of light in vacuum]]: ''c'' = {{val|299792458}} m/s
* [[Stefan–Boltzmann constant]]: σ = {{val|5.670400e-8}} W · m&lt;sup&gt;−2&lt;/sup&gt; · K&lt;sup&gt;−4&lt;/sup&gt;

== Numbers without specific values ==
{{Main|Indefinite and fictitious numbers}}
Many languages have words expressing [[indefinite and fictitious numbers]]—inexact terms of indefinite size, used forever  comic effect, for exaggeration, as [[placeholder name]]s, or when precision is unnecessary or undesirable. One technical term for such words is "non-numerical vague quantifier".&lt;ref&gt;[http://versita.metapress.com/content/t98071387u726916/?p=1ad6a085630c432c94528c5548f5c2c4&amp;pi=1 "Bags of Talent, a Touch of Panic, and a Bit of Luck: The Case of Non-Numerical Vague Quantifiers" from Linguista Pragensia, Nov. 2, 2010] {{webarchive|url=https://archive.is/20120731092211/http://versita.metapress.com/content/t98071387u726916/?p=1ad6a085630c432c94528c5548f5c2c4&amp;pi=1 |date=2012-07-31 }}&lt;/ref&gt; Such words designed to indicate large quantities can be called "indefinite hyperbolic numerals".&lt;ref&gt;[https://www.bostonglobe.com/ideas/2016/07/13/the-surprising-history-indefinite-hyperbolic-numerals/qYTKpkP9lyWVfItLXuTHdM/story.html  Boston Globe, July 13, 2016: "The surprising history of indefinite hyperbolic numerals"]&lt;/ref&gt;

==See also==
{{col-begin}}
{{col-break|width=33%}}
*[[English-language numerals]]
*[[Floating point]]
*[[Fraction (mathematics)]]
*[[Integer sequence]]
*[[Interesting number paradox]]
*[[Large numbers]]
*[[List of numbers in various languages]]
*[[List of prime numbers]]
*[[List of types of numbers]]
*[[Mathematical constant]]
*[[Names of large numbers]]
*[[Names of small numbers]]
{{col-break}}
*[[Negative number]]
*[[Number prefix]]
*[[Numeral (linguistics)]]
*[[Orders of magnitude (numbers)]]
*[[Ordinal number]]
*''[[The Penguin Dictionary of Curious and Interesting Numbers]]''
*[[Power of two]]
*[[Powers of 10]]
*[[SI prefix]]
*[[Small number]]
*[[Surreal number]]
*[[Table of prime factors]]
{{col-end}}

==Notes==
{{Reflist}}

== Further reading ==
* ''Kingdom of Infinite Number: A Field Guide'' by Bryan Bunch, W.H. Freeman &amp; Company, 2001. {{isbn|0-7167-4447-3}}

== External links ==
* [http://www.virtuescience.com/number.html The Database of Number Correlations: 1 to 2000+]
* [http://www.archimedes-lab.org/numbers/Num1_69.html What's Special About This Number? A Zoology of Numbers: from 0 to 500]
* [http://www.isthe.com/chongo/tech/math/number/number.html Name of a Number]
* [http://www.mathcats.com/explore/reallybignumbers.html See how to write big numbers]
* {{webarchive |url=http://webarchive.loc.gov/all/20011125134506/http://pages.prodigy.net/jhonig/bignum/indx.html |title=About big numbers |date=2001-11-25}}
* [http://www.mrob.com/pub/math/largenum.html Robert P. Munafo's Large Numbers page]
* [http://www-users.cs.york.ac.uk/~susan/cyc/b/big.htm Different notations for big numbers – by Susan Stepney]
* [http://www.unc.edu/~rowlett/units/large.html Names for Large Numbers], in ''How Many? A Dictionary of Units of Measurement'' by Russ Rowlett
* [http://www.stetson.edu/~efriedma/numbers.html What's Special About This Number?] (from 0 to 9999)

{{DEFAULTSORT:List Of Numbers}}
[[Category:Number-related lists]]
[[Category:Mathematical tables|Numbers]]
[[Category:Numeral systems]]</text>
      <sha1>96d7uypivdytfgetvwsmopshfze0pof</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after Pierre-Simon Laplace</title>
    <ns>0</ns>
    <id>40279847</id>
    <revision>
      <id>757544028</id>
      <parentid>716393475</parentid>
      <timestamp>2016-12-31T07:37:21Z</timestamp>
      <contributor>
        <username>Zingvin</username>
        <id>29985174</id>
      </contributor>
      <comment>added [[Category:Pierre-Simon Laplace]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2746">{{refimprove|date=August 2013}}

This is a list of things named after [[Pierre-Simon Laplace]]

==Probability theory==

*[[de Moivre-Laplace theorem]] that approximates binomial distribution with a normal distribution
*[[Laplace–Bayes estimator]]
*[[Laplace distribution]]

==Mathematical analysis==

*[[Laplace principle (large deviations theory)]]
* [[Laplace series]]
* [[Laplace transform]]
**[[Two-sided Laplace transform]]
** [[Laplace–Stieltjes transform]] 
** [[Inverse Laplace transform]]
* [[Laplace's method]] for approximating integrals
* [[Laplace limit]], concerning series solutions to [[Kepler's equation]]

===Differential equations===

* [[Laplace's equation]]
** [[Laplace operator]]
*** [[Laplace–Beltrami operator]]
* [[Laplacian]], see Laplace operator
** [[p-Laplacian]]
* [[Young–Laplace equation]]
* [[Laplace invariant]]

===Spherical harmonics===

* [[Laplace series]] (Fourier–Laplace series)
* [[Laplace expansion (potential)]]
* Laplace coefficient: see Laplace expansion (potential)

==Algebra==

*[[Laplace expansion]] of determinants of matrices
==Discrete mathematics==

*[[Laplace matrix|Laplace matrices]] in graph theory

==Physics==

*[[Laplace's demon]]
* [[Laplace-Runge-Lenz vector]]
* [[Laplace resonance]]

==Others==
* The asteroid [[4628 Laplace]] is named for Laplace.&lt;ref&gt;{{cite book | author=Schmadel, L. D. | title=Dictionary of Minor Planet Names | edition=5th rev. | location=Berlin | publisher=Springer-Verlag | year=2003 | isbn=3-540-00238-3}}&lt;/ref&gt;
* A spur of the [[Montes Jura]] on the moon is known as [[Promontorium Laplace]].
* The tentative working name of the [[European Space Agency]] [[Europa Jupiter System Mission]] is the "Laplace" [[space probe]].
* [[LaplacesDemon]] is Bayesian software

===In popular culture===
*[[Laplace no Ma]], a video game about Laplace's demon
*In [[Kamen Rider Fourze]] the Libra Horoscopes develops an ability called "The eye of Laplace"
*In [[Mega Man Star Force 3]] Solo gains a wizard named Laplace.
*The idea of the Laplace Demon has been cited several times in Japanese pop culture:
**In the [[Super Robot Wars]] serial, Elemental Lord of the Wind [[Cybuster]] is said to be equipped with the Laplace Demon which can alter the Laws of Probabilities.
**In [[Gundam UC]], the titular machine, the Gundam Unicorn, has the La+ (Laplus; Laplace) operative system, which is the key to obtain the Box of Laplace—a repository of secret information whose possession could change the course of the world.

==See also==
*{{Intitle|Laplace}}
*{{Intitle|Laplacian}}

==References==
{{reflist}}

[[Category:Lists of things named after mathematicians|Laplace]]
[[Category:Lists of things named after astronomers|L]]
[[Category:Pierre-Simon Laplace]]</text>
      <sha1>as3cab2hei5794fkhuxmeblvjs5zdaf</sha1>
    </revision>
  </page>
  <page>
    <title>Location arithmetic</title>
    <ns>0</ns>
    <id>1207129</id>
    <revision>
      <id>855829545</id>
      <parentid>854570376</parentid>
      <timestamp>2018-08-21T03:50:02Z</timestamp>
      <contributor>
        <username>Shenme</username>
        <id>101696</id>
      </contributor>
      <minor/>
      <comment>tagged with not a typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="70713">{{Rabdology}}

'''Location arithmetic''' (Latin ''arithmeticæ localis'') is the additive (non-positional) [[binary arithmetic|binary]] [[numeral systems]], which [[John Napier]] explored as a computation technique in his treatise ''[[Rabdology]]'' (1617), both symbolically and on a [[chessboard]]-like grid.

Napier's terminology, derived from using the positions of counters on the board to represent numbers, is potentially misleading in current vocabulary because the numbering system is non-positional.

During Napier's time, most of the computations were made on boards with tally-marks or [[jeton]]s. So, unlike how it may be seen by the modern reader, his goal was not to use moves of counters on a board to multiply, divide and find square roots, but rather to find a way to compute symbolically.

However, when reproduced on the board, this new technique did not require mental trial-and-error computations nor complex carry memorization (unlike base 10 computations). He was so pleased by his discovery that he said in his preface

: ... ''it might be well described as more of a lark than a labor, for it carries out addition, subtraction, multiplication, division and the extraction of square roots purely by moving counters from place to place.'' {{ref|Napier}}

== Location Numerals ==

[[Binary notation]] had not yet been standardized, so Napier used what he called '''location numerals''' to represent binary numbers. Napier's system uses [[sign-value notation]] to represent numbers; it uses successive letters from the Latin alphabet to represent successive powers of two: '''a''' = 2&lt;sup&gt;0&lt;/sup&gt; = 1, '''b''' = 2&lt;sup&gt;1&lt;/sup&gt; = 2, '''c''' = 2&lt;sup&gt;2&lt;/sup&gt; = 4, '''d''' = 2&lt;sup&gt;3&lt;/sup&gt; = 8, '''e''' = 2&lt;sup&gt;4&lt;/sup&gt; = 16 and so on.

To represent a given number as a location numeral, that number is expressed as a sum of powers of two and then each power of two is replaced by its corresponding digit (letter). For example, when converting from a decimal numeral:

: 87 = 1 + 2 + 4 + 16 + 64 = 2&lt;sup&gt;0&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt; + 2&lt;sup&gt;2&lt;/sup&gt; + 2&lt;sup&gt;4&lt;/sup&gt; + 2&lt;sup&gt;6&lt;/sup&gt; = '''abceg'''

Using the reverse process, a location numeral can be converted to another numeral system. For example, when converting to a decimal numeral:

: '''abdgkl''' = 2&lt;sup&gt;0&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt; + 2&lt;sup&gt;3&lt;/sup&gt; + 2&lt;sup&gt;6&lt;/sup&gt; + 2&lt;sup&gt;10&lt;/sup&gt; + 2&lt;sup&gt;11&lt;/sup&gt; = 1 + 2 + 8 + 64 + 1024 + 2048 = 3147

Napier showed multiple methods of converting numbers in and out of his numeral system. These methods are similar to modern methods of converting numbers in and out of the [[binary numeral system]], so they are not shown here. Napier also showed how to add, subtract, multiply, divide, and extract square roots.

=== Abbreviated and Extended Form ===

As in any numeral system using [[sign-value notation]] (but ''not'' those using [[positional notation]]), digits (letters) can be repeated such that multiple numerals can represent a single number. For example:

: '''abbc''' = '''acc''' = '''ad''' = 9

Additionally, the order of digits does not matter. For example:

: '''abbc''' = '''bbca''' = '''bcba''' = ... = 9

Because each digit in a location numeral represents twice the value of its next-lower digit, replacing any two occurrences of the same digit with one of the next-higher digit does not change the numeral's numeric value. Thus, repeatedly applying the rules of replacement '''aa''' → '''b''', '''bb''' → '''c''', '''cc''' → '''d''', etc. to a location numeral removes all repeated digits from that numeral.

Napier called this process '''abbreviation''' and the resulting location numeral the '''abbreviated form''' of that numeral; he called location numerals containing repeated digits '''extended forms'''. Each number can be represented by a unique abbreviated form, not considering the order of its digits (e.g., '''abc''', '''bca''', '''cba''', etc. all represent the number 7).

=== Arithmetic ===

==== Addition ====

Location numerals allow for a simple and intuitive algorithm for addition:

# join the numerals end-to-end
# when necessary, rearrange this conjoined numeral's digits so they are in ascending order
# abbreviate this rearranged and conjoined numeral

For example, to add 157 = '''acdeh''' and 230 = '''bcfgh''', join the numerals end-to-end:

: '''acdeh''' + '''bcfgh''' → '''acdehbcfgh'''

rearrange the digits of the previous result (because the digits of '''acdehbcfgh''' are not in ascending order):

: '''acdehbcfgh''' → '''abccdefghh'''

and abbreviate the previous result:

: '''abccdefghh''' → '''abddefghh''' → '''abeefghh''' → '''abffghh''' → '''abgghh''' → '''abhhh''' → '''abhi'''

The final result, '''abhi''', equals 387 ('''abhi''' = 2&lt;sup&gt;0&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt; + 2&lt;sup&gt;7&lt;/sup&gt; + 2&lt;sup&gt;8&lt;/sup&gt; = 1 + 2 + 128 + 256 = 387); this is the same result achieved by adding 157 and 230 in decimal notation.

==== Subtraction ====

Subtraction is also intuitive, but may require expanding abbreviated forms to extended forms to perform [[Carry (arithmetic)|borrows]].

Write the [[Subtraction|minuend]] (the largest number you want to diminish) and remove from it all the digits appearing in the [[Subtraction|subtrahend]] (the smallest number). In case the digit to be removed does not appear in the minuend, then ''borrow'' it by expanding the unit just larger. Repeat until all the digit of the subtrahend have been removed.

A few examples show it is simpler than it sounds :

* Subtract 5 = '''ac''' from 77 = '''acdg''' :
: '''acdg''' - '''ac''' = '''&lt;s&gt;ac&lt;/s&gt;dg''' = '''dg''' = 8+64 = 72. 
 
* Subtract 3 = '''ab''' from 77 = '''acdg''' :
: '''acdg''' - '''ab''' = '''abbdg''' - '''ab''' = '''&lt;s&gt;ab&lt;/s&gt;bdg''' = '''bdg''' = 2+8+64 = 74.

* Subtract 7 = '''abc''' from 77 = '''acdg''' :
: '''acdg''' - '''abc''' = '''abbccg''' - '''abc''' = '''&lt;s&gt;ab&lt;/s&gt;b&lt;s&gt;c&lt;/s&gt;cg''' = '''bcg''' = 2+4+64 = 70.

==== Doubling, halving, odd and even ====

Napier proceeded to the rest of arithmetic, that is multiplication, division and square root, on an abacus, as it was common in his times. However, since the development of micro-processor computer, a lot of applicable algorithms have been developed or revived based on doubling and halving.

Doubling is done by adding a numeral to itself, which mean doubling each of its digit. This gives an extend form, which has to be abbreviated if needed.

This operation can also be done in one go by changing all the digit of a numeral by the next digit. For example, the double of '''a''' is '''b''', the double of '''b''' is '''c''', the double of '''ab''' is '''bc''', the double of '''acfg''' is '''bdgh''', etc...

Similarly, multiplying by a power of two, is just translating its digits. To multiply by '''c''' = 4, for example, is transforming the digits '''a''' → '''c''', '''b''' → '''d''', '''c''' → '''e''',... 
 
Halving is the reverse: change all the digit by the previous digit. For example, the half of '''bdgh''' is '''acfg'''.

One sees immediately that it is only feasible when the numeral to be halved does not contains an '''a''' (or, if the numeral is extended, an odd number of '''a'''s). In other words, an abbreviated numeral is odd if it contains an '''a''' and even if it does not.

With these basic operations (doubling and halving), we can adapt all the binary algorithms starting by, but not limited to, the [[Bisection method]] and [[Dichotomic search]].

==== Multiplication ====

Napier proceeded to multiplication and division on an abacus, as it was common in his times. However, the [[Egyptian multiplication and division|Egyptian multiplication]] gives an elegant way to carry multiplication without tables using only doubling, halving and adding.

Multiplying a single digit number by another single digit number is a simple process. Because all letters represent a power of 2, multiplying digits is the same as adding their exponents. This can also be thought of as finding the index of one digit in the alphabet ('''a''' = 0, '''b''' = 1, ...) and incrementing the other digit by that amount in terms of the alphabet ('''b''' + 2 =&gt; '''d''').

For example, multiply 4 = '''c''' by 16 = '''e'''

'''c''' * '''e''' = 2^2 * 2^4 = 2^6 = '''g'''

or... 

''AlphabetIndex''('''c''') = 2, so... '''e''' =&gt; '''f''' =&gt; '''g'''

To find the product of two multiple digit numbers, make a two column table. In the left column write the digits of the first number, one below the other. For each digit in the left column, multiply that digit and the second number and record it in the right column. Finally, add all the numbers of the right column together.

As an example, multiply 238 = '''bcdfgh''' by 13 = '''acd'''

:{|
|- 
| '''a''' || '''bcdfgh'''
|- 
| '''c''' ||  '''defhij''' 
|-
| '''d''' ||   '''efgijk''' 
|}

The result is the sum in the right column '''{{not a typo|bcdfgh defhij efgijk}}''' = '''{{not a typo|bcddeefffgghhiijjk}}''' = '''bcekl''' = 2+4+16+1024+2048 = 3094.

It is interesting to notice that the left column can also be obtained by successive halves of the first number, from which the even numbers are removed. In our example, '''acd''', '''&lt;s&gt;bc&lt;/s&gt;''' (even), '''ab''', '''a'''. Noticing that the right column contains successive doubles of the second number, shows why the [[Egyptian multiplication and division|peasant multiplication]] is exact.

==== Division, remainder ====

Division can be carried out by successive subtractions: the quotient is the number of time the divisor can be subtracted from the dividend, and the remainder is what is left rest after all the possible subtractions.

This process, which can be very long, may be made efficient if instead of the divisor we subtract multiple of the divisor, and computations are easier if we restrict to multiple by a power of 2.

In facts, this is what we do in the [[long division]] method.

==The grid==

Location arithmetic uses a square grid where each square on the grid represents a value. Two sides of the grid are marked with
increasing powers of two. Any inner square can be identified by two numbers on these two sides, one being vertically below the inner
square and the other to its far right. The value of the square is the product of these two numbers.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+'''Example grid'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 32
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 16
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 8
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;background-color: gray;"|'''32'''
| style="width:30px;background-color: gray;"|&amp;nbsp;
| style="width:30px;background-color: gray;"|&amp;nbsp;
| style="width:30px;background-color: gray;"|&amp;nbsp;
| style="background-color: white;" | '''4'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;background-color: gray;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 2
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;background-color:gray;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 1
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|32
| style="width:30px;"|16
| style="width:30px;"|'''8'''
| style="width:30px;"|4
| style="width:30px;"|2
| style="width:30px;"|1
|}
For instance, the square in this example grid represents 32, as it is the product of 4 on the right column and 8 from the bottom row. The grid itself can be any size, and larger grids simply permit us to handle larger numbers.

Notice that moving either one square to the left or one square up doubles the value. This property can be used to perform binary
addition using just a single row of the grid.

===Addition===
First, lay out a binary number on a row using counters to represent the 1s in the number. For example, 29 (= 11101 in binary) would be placed on the board like this:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+ '''11101 (= 29) on one row'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
|}
The number 29 is clearly the sum of the values of the squares on which there are counters. Now overlay the second number on this row.  Say we place 9 (= 1001 in binary) on it like this.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+ '''Overlay 1001 (= 9)'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|'''0'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
|}
The sum of these two numbers is just the total value represented by the counters on the board, but some of the squares have more than one counter.  Recall however, that moving to the left of a square doubles its value. So we replace two counters on a square with one counter to its left without changing the total value on the board. Note that this is the same idea used to abbreviate
location numerals. Let's start by replacing the rightmost pair of counters with a counter to its left, giving:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|←
|}
We still have another square with two counters on it, so we do it again:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|←
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|}
But replacing this pair created another square with two counters on it, so we replace a third time:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+ '''Result 100110 = 38'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|←
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
|}
Now each square has just one counter, and reading off the result in binary 100110 (= 38) gives the correct result.

===Subtraction===
Subtracting is not much more complicated than addition: instead of adding counters on the board we remove them. To "borrow" a value, we replace a counter on a square with two to its right.

Let's see how we might subtract 12 from 38. First place 38 (= 100110 in binary) on a row, and then place 12 (= 1100 in binary) under it:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white; color: black;"|'''38'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| '''12'''
|}
For every counter on the lower row that has a counter above it, remove both counters. We can remove one such pair on the board,
resulting in:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|↓
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|↓
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|}
Now we need to "borrow" counters to get rid of the remaining counter on the bottom. First replace the leftmost counter on the top row with two to its right:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|→
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|}
Now replace one of the two counters with two more to its right, giving:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|}
We can now take away one of the counters on the top row with the remaining counter on the bottom row:
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+ '''11010 = 26'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|↓
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|}
and read off 26, the final result.

===Some properties of the grid===

Unlike addition and subtraction, the entire grid is used to multiply, divide, and extract square roots. The grid has some useful properties utilized in these operations. First, all the squares on any diagonal going from the bottom left to the top right have the same value.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|256
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 32
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|256
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|16
| style="background-color: white;" | 16
|- style="height:30px; background-color: silver;"
| style="width:30px;"|256
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|16
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 8
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|16
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 4
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|16
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 2
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|16
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 1
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|32
| style="width:30px;"|16
| style="width:30px;"|8
| style="width:30px;"|4
| style="width:30px;"|2
| style="width:30px;"|1
|}
Since a diagonal move can be broken down into a move to the right (which halves the value) followed by a move
up (which doubles the value), the value of the square stays the same.

In conjunction with that diagonal property, there's a quick way to divide the numbers on the bottom and right edges of the grid.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+ '''32 ÷ 8'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal half.svg]]
| style="background-color: white;" | '''32'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 16
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 8
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;background-color: gray;"|&amp;nbsp;
| style="width:30px;"|→
| style="width:30px;"|→
| style="width:30px;"|→
| style="background-color: white;" | '''4'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 2
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical half.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | 1
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|32
| style="width:30px;"|16
| style="width:30px;"|'''8'''
| style="width:30px;"|4
| style="width:30px;"|2
| style="width:30px;"|1
|}
Locate the dividend 32 along the right side and the divisor 8 on the bottom edge of the grid. Extend a diagonal from the dividend and locate the square where it intersects a vertical line from the divisor.  The quotient lies at the right end of the grid from this square, which for our example is 4.

Why does this work? Moving along the diagonal doesn't change the value; the value of the square on the intersection
is still the dividend. But we also know it is the product of the squares along the bottom and right edge. Since the square on the bottom edge is the divisor, the square on the right edge is the quotient.

Napier extends this idea to divide two arbitrary numbers, as shown below.

==Multiplication==
To multiply a pair of binary numbers, first mark the two numbers
on the bottom and the right side of the grid. Say we want to
multiply 22 (= 10110) by 9 (= 1001).
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+'''10110 * 1001'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | &amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | &amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
|}
Now place counters at every "intersection" of vertical and
horizontal rows of the 1s in each number.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | &amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | &amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic horizontal.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic horizontal.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic horizontal.svg]]
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|[[Image:Location arithmetic vertical.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic horizontal.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic horizontal.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic horizontal.svg]]
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
|}
Notice that each row of counters on the grid is just
22 multiplied by some
power of two. In fact, the total value of the counters is the
sum of two rows
: 22*8 + 22*1 = 22*(8+1) = 22*9
So the counters on the board actually represent the product
of the two numbers, except it isn't possible to "read off" the
answer just yet.

Recall that moving counters diagonally doesn't change the value,
so move all the counters on inner squares diagonally until they
hit either the bottom row or the left column.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal half.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal half.svg]]
| style="width:30px;"|[[Image:Location arithmetic diagonal half.svg]]
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|}
Now we make the same moves we did for addition. Replace
two counters on a square with one to its left. If the square
is on the left column, replace two counters with one ''above''
it. Recall that the value of a square doubles if you move up,
so this doesn't change the value on the grid.

Let's first replace the two counters on the second square
at the bottom with one to its left which leaves two
counters at the corner.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|←
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|}
Finally, replace the two counters on the corner with one above it
and "read off" the binary number in an L-shaped fashion, starting from
the top left down to the bottom left corner, and then over to the
bottom right.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+ '''Result 11000110'''
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | &amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | &amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | &amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | '''1'''
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | '''1'''
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | &amp;nbsp;
| style="width:30px;"|↑
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|'''0'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
|}
Read the counters along the L but don't double count the corner square.
You will read the binary result 11000110 = 198 which is indeed 22*9.

Why can we read the binary number in this L-shaped fashion? The
bottom row is of course just the first six powers of two, but
notice that the leftmost column has the next five powers of
two. So we can directly read off an 11 digit binary number from
the L-shaped set of 11 squares that lie along the left and bottom
sides of the grid.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | 1024
| style="width:30px;"|↓
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | 512
| style="width:30px;"|↓
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | 256
| style="width:30px;"|↓
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | 128
| style="width:30px;"|↓
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | 64
| style="width:30px;"|↓
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|- style="height:30px; background-color: silver;"
| style="background-color: white;" | &amp;nbsp;
| style="width:30px;"|→
| style="width:30px;"|→
| style="width:30px;"|→
| style="width:30px;"|→
| style="width:30px;"|→
| style="width:30px;"|→
|- style="height:30px; background-color:white; color: black;"
| &amp;nbsp;
| style="width:30px;"|32
| style="width:30px;"|16
| style="width:30px;"|8
| style="width:30px;"|4
| style="width:30px;"|2
| style="width:30px;"|1
|}
Our small 6x6 grid can only multiply numbers each up to 63, and in
general an ''n''x''n'' grid can multiply two numbers each up to
2&lt;sup&gt;''n''&lt;/sup&gt;-1. This scales very fast, so board with 20 numbers per side, for
instance, can multiply numbers each up to a little over one million.

==Division==
[[Martin Gardner]] presented a slightly easier to understand
version {{ref|Gardner-86}} of Napier's division method, which is what is
shown here.

Division works pretty much the reverse of multiplication. Say we want
to divide 485 by 13. First place counters for 485 (= 111100101) along
the bottom edge and mark 13 (= 1101) along the right edge. To save
space, we'll just look at a rectangular portion of the board because
that's all we actually use.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|+'''485 ÷ 13'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|}
Starting from the left, the game is to move counters diagonally into
"columns of divisors" (that is, with one counter on each row marked
with a 1 from the divisor.) Let's demonstrate this with the leftmost
block of counters.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|[[Image:Location arithmetic bent.svg]]
| style="width:30px;"|[[Image:Location arithmetic bent.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|'''↑'''
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|}
Now the next block of counters we might try would begin with the
leftmost counter on the bottom, and we might attempt something like
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|'''?'''
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic bent.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|'''?'''
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|}
except that we don't have any counters that we can move diagonally
from the bottom edge into squares that would form the rest of the
"column of divisors."

In such cases, we instead "double down" the counter on the bottom
row and form a column one over to the right. As you will soon see, it
will always be possible to form a column this way. So first replace
the counter on the bottom with two to its right.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|→
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|}
and then move one diagonally to the top of the column, and move
another counter located on the edge of the board into its spot.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|'''?'''
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|↑
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|}
It looks like we still don't have a counter on the bottom edge to move
diagonally into the remaining square, but notice that we can instead
double down the leftmost counter again and then move it into the
desired square.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|'''?'''
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|→
| style="width:30px;"|[[Image:Location arithmetic two counters.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|}
and now move one counter diagonally to where we want it.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic bent.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|}
Let's proceed to build the next column. Once again, notice that moving
the leftmost counter to the top of the column doesn't leave enough
counters at the bottom to fill in the remaining squares.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|'''?'''
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic bent.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|'''?'''
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
|}
So we double down the counter and move one diagonally into the next
column over. Let's also move the rightmost counter into the column,
and here's how it looks after these steps.
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|'''?'''
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic bent.svg]]
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color:gray;"|[[Image:Location arithmetic one counter.svg]]
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|→
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|↑
|}
We still have a missing square, but we just double down again and move
the counter into this spot and end up with
{| border="0" cellpadding="0" cellspacing="1" style="text-align:center; background-color: white; color: black;"
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
| style="width:30px;"|'''0'''
| style="width:30px;"|'''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px; background-color: gray;"|[[Image:Location arithmetic one counter.svg]]
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic diagonal.svg]]
| style="width:30px;"|&amp;nbsp;
| style="background-color: white;" | '''0'''
|- style="height:30px; background-color: silver;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="background-color: white;" | '''1'''
|- style="height:30px; background-color:white; color: black;"
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|→
| style="width:30px;"|[[Image:Location arithmetic one counter.svg]]
| style="width:30px;"|&amp;nbsp;
| style="width:30px;"|&amp;nbsp;
|}
At this point, the counter on the bottom edge is so far to the right
that it cannot go diagonally to the top of any column, which signals
that we are done.

The result is "read" off the columns—each column with counters is
treated as a 1 and empty columns are 0. So the result is
100101 (= 37) and the remainder is the binary value of any counters
still left along the bottom edge. There is one counter on the third
column from the right, so we read it as 100 (= 4) and we get 485
÷ 13 = 37 with a remainder 4.

==Square roots==
===Napier's Method===
[[File:Napier's guide for forming the square.png|thumb|Napier's explanation of how to form the square in each subsequent step from Rabdology page 149]]
This process requires one to add counters to the abacus (board) to make square figures. The top of page 149 
shows diagrams that explain this process. Begin by placing a single counter on the board (it will actually go on 
one of the dotted squares). Adding three other counters adjacent (or with blank rows and columns between them 
and the first one placed) will result in another square figure on the abacus. Similarly adding another five counters 
to this (with or without the blank rows and columns shown) will result in an even bigger square.
Take the number to be considered and put counters along one margin that represent its value.
From the position of the largest counter in that value, follow the diagonal lines (bishop’s moves) across the 
board until you come to a square with a dot. Place a counter on that square. 
Subtract the value represented by this single counter from the original number in the margin.
Add three (five, seven, ... for subsequent steps) to create a square on the board and subtract the value of the 
added counters from the number in the margin until the number is either too large to be subtracted or there is no 
space left on the board. You should be left with a large square of counters (perhaps with blank rows and columns 
between them) on the board.
Move one of the counters in each row of the square to the margin and the positions of these marginal counters 
will yield the square root of the number.

[[File:Napier's method Square root of 1238.png|thumb|Example of finding the square root of 1238 using Napier's method for finding square roots provided in Rabdology on page 151]]
Napier provides an example of determining the square root of 1238.
The largest counter is in the 1024 position so the first counter is placed on the dot found by moving down the 1024 
diagonal (at the 32,32 position). Subtracting this value (1024) from the original number leaves counters at 128, 
64, 16, 4 and 2 (= 214). 
Placing three counters on the board to form a square with the first counter but whose value can still be subtracted 
from 214, results in counters at positions 32,2; 2,2; and 2,32 (whose values are 64, 4 and 64, which when subtracted 
from the remainder of 214 = 82.
The next square that can be constructed from five counters, yet the values of those five counters still being capable 
of being subtracted from 82 results in counters in positions 32,1; 2,1; 1,1; 1.2; and 1,32. The values of these five 
counters total 69 which when subtracted from 82 leave 13 as a remainder.
As there is no more room on the board we have to stop.
Move one counter from each row to the margin (rows 32, 2 and 1) and this value (35) is the square root required, 
or at least the integer part of it (the actual value is 35.1852....).

[[File:Napier's Method Square root of 2209.png|thumb|Example of finding the square root of 2209 using Napier's method for finding square roots provided in Rabdology on page 153]]
Napier provides a second example for calculating the square root of 2209 (= 47).
&lt;ref&gt;http://sliderulemuseum.com/Papers/Napier_John.Rabdologiae.1617.Edinburgh.pdf&lt;/ref&gt;

==See also==
*[[Jeton]]

==References==
#{{note|Napier}}John Napier; translated by William Frank Richardson; introduction by Robin E. Rider (1990). ''Rabdology''. MIT Press. {{isbn|0-262-14046-2}}.
#{{note|Gardner-86}}Martin Gardner (1986). ''Knotted doughnuts and other mathematical entertainments''. W. H. Freeman and Company. {{isbn|0-7167-1794-8}}.

;Specific
&lt;references /&gt;

==External links==
* [http://courses.cs.vt.edu/~cs1104/Napier/Chessboard.html Javascript simulation of Location arithmetic]

{{DEFAULTSORT:Location Arithmetic}}
[[Category:Mathematical tools]]
[[Category:Arithmetic]]</text>
      <sha1>tv55sll4zfu27vbdot099yu4gy04ga2</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematical notation</title>
    <ns>0</ns>
    <id>277184</id>
    <revision>
      <id>871074546</id>
      <parentid>871074366</parentid>
      <timestamp>2018-11-28T19:32:39Z</timestamp>
      <contributor>
        <username>Info-Screen</username>
        <id>17995228</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/78.149.124.6|78.149.124.6]] ([[User talk:78.149.124.6|talk]]) to last revision by Jan Spousta. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10671">{{for|information on rendering mathematical formulae|Help:Formula|Help:Displaying a formula|Wikipedia:Manual of Style/Mathematics}}
{{See Also|List of mathematical symbols}}

'''Mathematical notation''' is a system of [[symbol]]ic representations of mathematical objects and ideas. Mathematical notations are used in [[mathematics]], the [[physical sciences]], [[engineering]], and [[economics]]. Mathematical notations include relatively simple symbolic representations, such as the numbers 0, 1 and 2; [[function (mathematics)|function]] symbols such as [[sine|sin]]; operator symbols such as "[[Plus and minus signs#Plus sign|+]]"; conceptual symbols such as [[limit (mathematics)|lim]] and [[derivative|''dy/dx'']]; [[equation]]s and [[Variable (mathematics)|variables]]; and complex diagrammatic notations such as [[Penrose graphical notation]] and [[Coxeter–Dynkin diagram]]s.

==Definition==
A mathematical notation is a [[writing system]] used for recording concepts in mathematics.
*The notation uses symbols or symbolic [[expression (mathematics)|expressions]] which are intended to have a precise semantic meaning.
*In the [[history of mathematics]], these symbols have denoted numbers, shapes, patterns, and change. The notation can also include symbols for parts of the conventional discourse between mathematicians, when viewing [[mathematics as a language]].

The media used for writing are recounted below, but common materials currently include paper and pencil, board and chalk (or dry-erase marker), and electronic media. Systematic adherence to mathematical concepts is a fundamental concept of mathematical notation. (See also some related concepts: [[Logical argument]], [[Mathematical logic]], and [[Model theory]].)

==Expressions==
A [[Expression (mathematics)|mathematical expression]] is a ''sequence'' of symbols which can be evaluated.  For example, if the symbols represent numbers, the expressions are evaluated according to a conventional [[order of operations]] which provides for calculation, if possible, of any expressions within parentheses, followed by any exponents and roots, then multiplications and divisions and finally any additions or subtractions, all done from left to right. In a [[computer language]], these rules are implemented by the [[compiler]]s. For more on expression evaluation, see the [[computer science]] topics: [[eager evaluation]], [[lazy evaluation]], and [[evaluation operator]].

==Precise semantic meaning==
Modern mathematics needs to be precise, because [[ambiguous]] notations do not allow [[formal proof]]s. Suppose that we have [[Proposition (mathematics)|statement]]s, denoted by some formal [[sequence]] of symbols, about some objects (for example, numbers, shapes, patterns).  Until the statements can be shown to be valid, their meaning is not yet resolved.  While reasoning, we might let the symbols refer to those denoted objects, perhaps in a [[model (abstract)|model]]. The [[semantics]] of that object has a [[heuristic]] side and a [[deductive]] side. In either case, we might want to know the properties of that object, which we might then list in an [[intensional definition]].

Those properties might then be expressed by some well-known and agreed-upon symbols from a [[table of mathematical symbols]]. This mathematical notation might include annotation such as
*"All x", "No x", "There is an x" (or its equivalent, "Some x"), "A set", "A function"
*"A mapping from the real numbers to the complex numbers"

In different contexts, the same symbol or notation can be used to represent different concepts. Therefore, to fully understand a piece of mathematical writing, it is important to first check the definitions that an author gives for the notations that are being used. This may be problematic if the author assumes the reader is already familiar with the notation in use.

==History==
{{main article|History of mathematical notation}}

===Counting===
It is believed that a mathematical notation  to represent [[counting]] was first developed at least 50,000 years ago&lt;ref&gt;''An Introduction to the History of Mathematics'' (6th Edition) by [[Howard Eves]] (1990) p.9&lt;/ref&gt; — early mathematical ideas such as [[finger counting]]&lt;ref&gt;[[Georges Ifrah]] notes that humans learned to count on their hands. Ifrah shows, for example, a picture of [[Boethius]] (who lived 480–524 or 525) reckoning on his fingers in {{harvnb|Ifrah|2000|p=48}}.&lt;/ref&gt; have also been represented by collections of rocks, sticks, bone, clay, stone, wood carvings, and knotted ropes. The [[tally stick]] is a way of counting dating back to the Upper Paleolithic. Perhaps the oldest known mathematical texts are those of ancient [[Sumer]].  The [[census quipu|Census Quipu]] of the Andes and the [[Ishango Bone]] from Africa both used the [[tally mark]] method of accounting for numerical concepts.

The development of zero as a number is one of the most important developments in early mathematics. It was used as a placeholder by the [[Babylonian numerals|Babylonians]] and [[Greek numerals|Greek Egyptians]], and then as an integer by the [[Maya numerals|Mayans]], [[Indian numerals|Indians]] and [[Arabic numerals|Arabs]]. (See [[History of zero|The history of zero]] for more information.)

===Geometry becomes analytic===
The earliest mathematical viewpoints in [[geometry]] did not lend themselves well to counting. The [[natural number]]s, their relationship to [[fraction (mathematics)|fraction]]s, and the identification of [[Continuum (theory)|continuous]] quantities actually took millennia to take form, and even longer to allow for the development of notation. It was not until the invention of [[analytic geometry]] by [[René Descartes]] that geometry became more subject to a numerical notation.&lt;ref&gt;{{citation
 | last = Boyer | first = C. B.
 | journal = The American Mathematical Monthly
 | jstor = 2308751
 | mr = 0105335
 | quote = The great accomplishment of Descartes in mathematics invariably is described as the arithmetization of geometry.
 | pages = 390–393
 | title = Descartes and the geometrization of algebra
 | volume = 66
 | year = 1959
 | doi=10.2307/2308751}}&lt;/ref&gt; Some symbolic shortcuts for mathematical concepts came to be used in the publication of geometric proofs. Moreover, the power and authority of geometry's theorem and proof structure greatly influenced non-geometric treatises, [[Isaac Newton]]'s [[Philosophiae Naturalis Principia Mathematica|Principia Mathematica]], for example.

===Modern notation===
The 18th and 19th centuries saw the creation and standardization of mathematical notation as used today. [[Euler]] was responsible for many of the notations in use today: the use of ''a'', ''b'', ''c'' for constants and ''x'', ''y'', ''z'' for unknowns, ''e'' for the base of the natural logarithm, sigma (Σ) for [[summation]], ''i'' for the [[imaginary unit]], and the functional notation ''f''(''x''). He also popularized the use of π for [[Archimedes constant]] (due to [[William Jones (mathematician)|William Jones]]' proposal for the use of π in this way based on the earlier notation of [[William Oughtred]]). Many fields of mathematics bear the imprint of their creators for notation: the differential operator is due to [[Gottfried Wilhelm Leibniz|Leibniz]],&lt;ref&gt;{{cite web|url=http://www.maths.tcd.ie/pub/HistMath/People/Leibniz/RouseBall/RB_Leibnitz.html|title=Gottfried Wilhelm Leibnitz|publisher=|accessdate=5 October 2014}}&lt;/ref&gt; the [[cardinal number|cardinal]] infinities to [[Georg Cantor]] (in addition to the [[Infinity symbol|lemniscate]] (∞) of [[John Wallis]]), the congruence symbol (≡) to [[Carl Friedrich Gauss|Gauss]], and so forth.

===Computerized notation===
Mathematically oriented markup languages such as [[TeX]], [[LaTeX]] and, more recently, [[MathML]] are powerful enough to express a wide variety of mathematical notations.

Theorem-proving software naturally comes with its own notations for mathematics; the [http://www.omdoc.org/ OMDoc project] seeks to provide an open commons for such notations; and the [https://uniformal.github.io/doc/language/ MMT language] provides a basis for interoperability between other notations.

==Non-Latin-based mathematical notation==
[[Modern Arabic mathematical notation]] is based mostly on the [[Arabic alphabet]] and is used widely in the [[Arab world]], especially in pre-[[tertiary education]].  (Western notation uses [[Arabic numerals]], but the Arabic notation also replaces Latin letters and related symbols with Arabic script.)

Some mathematical notations are mostly diagrammatic, and so are almost entirely script independent. Examples are [[Penrose graphical notation]] and [[Coxeter–Dynkin diagram]]s.

Braille-based mathematical notations used by blind people include [[Nemeth Braille]] and [[GS8 Braille]].

==See also==
* [[Abuse of notation]]
* [[Begriffsschrift]]
* [[Bourbaki dangerous bend symbol]]
* [[History of mathematical notation]]
* [[ISO 31-11]]
* [[ISO 80000-2]]
* [[Knuth's up-arrow notation]]
* [[Mathematical Alphanumeric Symbols]]
* [[Notation in probability]]
* [[Language of mathematics]]
* [[Scientific notation]]
* [[Semasiography]]
* [[Table of mathematical symbols]]
* [[Typographical conventions in mathematical formulae]]
* [[Vector notation]]
* [[Modern Arabic mathematical notation]]

==Notes==
&lt;references/&gt;

==References==
* [[Florian Cajori]], [https://books.google.com/books?id=7juWmvQSTvwC&amp;printsec=frontcover ''A History of Mathematical Notations''] (1929), 2 volumes. {{isbn|0-486-67766-4}}
*{{Citation
  | last = Ifrah
  | first = Georges
  | author-link = Georges Ifrah
  | title = The Universal History of Numbers: From prehistory to the invention of the computer.
  | publisher = [[John Wiley and Sons]]
  | year= 2000
  | page = 48
  | isbn = 0-471-39340-1
}}. Translated from the French by David Bellos, E.F. Harding, Sophie Wood and Ian Monk. Ifrah supports his thesis by quoting idiomatic phrases from languages across the entire world.

==External links==
* [http://jeff560.tripod.com/mathsym.html Earliest Uses of Various Mathematical Symbols]
* [http://www.apronus.com/math/mrwmath.htm Mathematical ASCII Notation] how to type math notation in any text editor.
* [http://www.cut-the-knot.org/language/index.shtml Mathematics as a Language] at [[cut-the-knot]]
* [[Stephen Wolfram]]: [http://www.stephenwolfram.com/publications/mathematical-notation-past-future/ Mathematical Notation: Past and Future]. October 2000. Transcript of a keynote address presented at [[MathML]] and Math on the Web: MathML International Conference.

{{DEFAULTSORT:Mathematical Notation}}
[[Category:Mathematical notation| ]]</text>
      <sha1>k4bzycs3vvsimzekqo4kxo0koevc2rs</sha1>
    </revision>
  </page>
  <page>
    <title>Metabolic control analysis</title>
    <ns>0</ns>
    <id>5583296</id>
    <revision>
      <id>853882247</id>
      <parentid>851840621</parentid>
      <timestamp>2018-08-07T15:23:52Z</timestamp>
      <contributor>
        <username>Kontribuanto</username>
        <id>33515312</id>
      </contributor>
      <minor/>
      <comment>fixed broken (external) link to dbkgroup...</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16257">'''Metabolic control analysis''' ('''MCA''') is a mathematical framework for describing
[[Metabolic pathway|metabolic]], [[Cell signaling#Signaling pathways|signaling]], and [[genetic pathway]]s. MCA quantifies how variables,
such as [[flux]]es and [[Chemical species|species]] concentrations, depend on [[Network (mathematics)|network]] parameters.
In particular it is able to describe how network dependent properties,
called control [[coefficient]]s, depend on [[Local property|local properties]] called [[Elasticity of a function|elasticities]].&lt;ref&gt;Fell D., (1997) Understanding the Control of Metabolism, Portland Press.&lt;/ref&gt;&lt;ref&gt;Heinrich R. and Schuster S. (1996) The Regulation of Cellular Systems, Chapman and Hall.
&lt;/ref&gt;&lt;ref&gt;{{Cite journal 
| last1 = Salter | first1 = M. 
| last2 = Knowles | first2 = R. G. 
| last3 = Pogson | first3 = C. I. 
| title = Metabolic control 
| journal = Essays in biochemistry 
| volume = 28 
| pages = 1–12 
| year = 1994 
| pmid = 7925313
}}&lt;/ref&gt;

MCA was originally developed to describe the control in metabolic pathways
but was subsequently extended to describe signaling and [[Gene regulatory network|genetic networks]]. MCA has sometimes also been referred to as ''Metabolic Control Theory'' but this terminology was rather strongly opposed by [[Henrik Kacser]], one of the founders{{Citation needed|date=November 2010}}.

More recent work&lt;ref&gt;Ingalls, B. P. (2004) A Frequency Domain Approach to Sensitivity Analysis of Biochemical Systems , Journal of Physical Chemistry B, 108, 1143-1152.&lt;/ref&gt; has shown that MCA can be [[Isomorphism|mapped directly]] on to classical [[control theory]] and are as such equivalent.

[[Biochemical systems theory]]&lt;ref&gt;Savageau M.A (1976) Biochemical systems analysis: a study of function and design in molecular biology, Reading, MA, Addison–Wesley.&lt;/ref&gt; is a similar [[Formalism (mathematics)#Formalism|formalism]], though with a rather different objectives. Both are evolutions of an earlier theoretical analysis by Joseph Higgins.&lt;ref&gt;{{Cite journal 
| doi = 10.1111/j.1749-6632.1963.tb13382.x 
| last1 = Higgins | first1 = J. 
| title = Analysis of sequential reactions 
| journal = Annals of the New York Academy of Sciences 
| volume = 108 
| pages = 305–321 
| year = 1963 
| pmid = 13954410
}}&lt;/ref&gt;

== Control Coefficients ==

A control coefficient&lt;ref&gt;{{Cite journal 
| last1 = Kacser | first1 = H. 
| last2 = Burns | first2 = J. A. 
| title = The control of flux 
| journal = Symposia of the Society for Experimental Biology 
| volume = 27 
| pages = 65–104 
| year = 1973 
| pmid = 4148886
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal 
| doi = 10.1111/j.1432-1033.1974.tb03318.x 
| last1 = Heinrich | first1 = R. 
| last2 = Rapoport | first2 = T. A. 
| title = A linear steady-state treatment of enzymatic chains. General properties, control and effector strength 
| journal = European Journal of Biochemistry / FEBS 
| volume = 42 
| issue = 1 
| pages = 89–95 
| year = 1974 
| pmid = 4830198
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Burns | first1 = J.A. | last2 = Cornish-Bowden | first2 = A. | last3 = Groen | first3 = A.K. | last4 = Heinrich | first4 = R. | last5 = Kacser | first5 = H. | last6 = Porteous | first6 = J.W. | last7 = Rapoport | first7 = S.M. | last8 = Rapoport | first8 = T.A. | last9 = Stucki | first9 = J.W. | last10 = Tager | first10 = J.M. | last11 = Wanders | first11 = R.J.A. | last12 = Westerhoff | first12 = H.V. | year = 1985 | title = Control analysis of metabolic systems | url = | journal = Trends Biochem. Sci. | volume = 10 | issue = | page = 16 | doi=10.1016/0968-0004(85)90008-8}}&lt;/ref&gt; measures the relative [[steady state]] change in a system variable, e.g. pathway flux (J) or metabolite concentration (S), in response to a relative change in a [[parameter]], e.g. [[Enzyme kinetics|enzyme activity]] or the steady-state rate (&lt;math&gt; v_i &lt;/math&gt;) of step i. The two main control coefficients are the flux and concentration control coefficients. Flux control coefficients are defined by:

&lt;math&gt; C^J_{v_i} = \left( \frac{dJ}{dp} \frac{p}{J} \right) \bigg/ \left( \frac{\partial v_i}{\partial  p}\frac{p}{v_i} \right) = \frac{d\ln J}{d\ln v_i} &lt;/math&gt;

and concentration control coefficients by:

&lt;math&gt; C^S_{v_i}  = \left( \frac{dS}{dp} \frac{p}{S} \right)  \bigg/ \left( \frac{\partial v_i}{\partial p} \frac{p}{v_i} \right) = \frac{d\ln S}{d\ln v_i} &lt;/math&gt;

=== Summation Theorems ===
The flux control [[summation]] theorem was discovered independently by the Kacser/Burns group and the Heinrich/Rapoport group in the early 1970s and late 1960s. The flux control summation theorem [[Logical implication|implies]] that metabolic fluxes are systemic properties and that their control is shared by all [[Chemical reaction|reactions]] in the system. When a single reaction changes its control of the flux this is compensated by changes in the control of the same flux by all other reactions.

&lt;math&gt; \sum_i C^J_{v_i} = 1 &lt;/math&gt;

&lt;math&gt; \sum_i C^S_{v_i} = 0 &lt;/math&gt;

== Elasticity Coefficients ==

The elasticity coefficient measures the local response of an enzyme or other chemical reaction to changes in its environment. Such changes include factors such as substrates, products or effector concentrations. For further information please refer to the dedicated page at [[Elasticity Coefficient]]s.

=== Connectivity Theorems ===

The [[Connectivity (graph theory)|connectivity]] theorems are specific relationships between elasticities and control coefficients. They are useful because they highlight the close relationship between the [[Chemical kinetics|kinetic]] properties of individual reactions and the system properties of a pathway. Two basic sets of theorems exists, one for flux and another for concentrations. The concentration connectivity theorems are divided again depending on whether the system species &lt;math&gt; S_n &lt;/math&gt; is different from the local species &lt;math&gt; S_m &lt;/math&gt;.

&lt;math&gt; \sum_i C^J_i \varepsilon^i_S = 0 &lt;/math&gt;

&lt;math&gt; \sum_i C^{S_n}_i \varepsilon^i_{S_m} = 0 \quad n \neq m &lt;/math&gt;

&lt;math&gt; \sum_i C^{S_n}_i \varepsilon^i_{S_m} = -1 \quad n = m &lt;/math&gt;

== Control Equations ==

It is possible to combine the summation with the connectivity theorems to obtain [[Closed-form expression|closed expressions]] that relate the control coefficients to the elasticity coefficients. For example, consider the simplest [[Trivial (mathematics)|non-trivial]] pathway:

&lt;center&gt; &lt;math&gt; X_o \rightarrow S \rightarrow X_1 &lt;/math&gt; &lt;/center&gt;

We assume that &lt;math&gt; X_o &lt;/math&gt; and &lt;math&gt; X_1 &lt;/math&gt; are [[Boundary (thermodynamic)|fixed boundary]] species so that the pathway can reach a steady state. Let the first step have a rate &lt;math&gt; v_1 &lt;/math&gt; and the second step &lt;math&gt; v_2 &lt;/math&gt;. Focusing on the flux control coefficients, we can write one summation and one connectivity theorem for this simple pathway:

&lt;center&gt;
&lt;math&gt; C^J_{v_1} + C^J_{v_2} = 1 &lt;/math&gt;

&lt;math&gt; C^J_{v_1} \varepsilon^{v_1}_S + C^J_{v_2} \varepsilon^{v_2}_S = 0 &lt;/math&gt;
&lt;/center&gt;

Using these two equations we can solve for the flux control coefficients to yield:

&lt;center&gt;
&lt;math&gt; C^J_{v_1} = \frac{\varepsilon^{2}_S}{\varepsilon^{2}_S - \varepsilon^{1}_S} &lt;/math&gt;

&lt;math&gt; C^J_{v_2} = \frac{-\varepsilon^{1}_S}{\varepsilon^{2}_S - \varepsilon^{1}_S} &lt;/math&gt;
&lt;/center&gt;

Using these equations we can look at some simple extreme behaviors. For example, let us assume that the first step is completely insensitive to its product (i.e. not reacting with it), S, then &lt;math&gt; \varepsilon^{v_1}_S = 0 &lt;/math&gt;. In this case, the control coefficients reduce to:

&lt;center&gt;
&lt;math&gt; C^J_{v_1} = 1 &lt;/math&gt;

&lt;math&gt; C^J_{v_2} = 0 &lt;/math&gt;
&lt;/center&gt;

That is all the control (or sensitivity) is on the first step. This situation represents the classic [[Rate-determining step|rate-limiting step]] that is frequently mentioned in text books. The flux through the pathway is completely dependent on the first step. Under these conditions, no other step in the pathway can affect the flux. The effect is however dependent on the complete insensitivity of the first step to its product. Such a situation is likely to be rare in real pathways. In fact the classic rate limiting step has almost never been observed experimentally. Instead, a range of limitingness is observed, with some steps having more limitingness (control) than others.

We can also derive the concentration control coefficients for the simple two step pathway:

&lt;center&gt;
&lt;math&gt; C^S_{v_1} = \frac{1}{\varepsilon^{2}_S - \varepsilon^{1}_S} &lt;/math&gt;

&lt;math&gt; C^S_{v_2} = \frac{-1}{\varepsilon^{2}_S - \varepsilon^{1}_S} &lt;/math&gt;
&lt;/center&gt;

== Three Step Pathway ==

Consider the simple three step pathway:

&lt;center&gt; &lt;math&gt; X_o \rightarrow S_1 \rightarrow S_2 \rightarrow X_1 &lt;/math&gt; &lt;/center&gt;

where &lt;math&gt; X_o &lt;/math&gt; and &lt;math&gt; X_1 &lt;/math&gt; are fixed boundary species, the control equations for this pathway can be derived in a similar manner to the simple two step pathway although it is somewhat more tedious.

&lt;math&gt;
C^J_{e_1} = \varepsilon^{2}_1 \varepsilon^{3}_2 / D
&lt;/math&gt;

&lt;br&gt;
&lt;math&gt;
C^J_{e_2} = -\varepsilon^{1}_1 \varepsilon^{3}_2 / D
&lt;/math&gt;

&lt;br&gt;
&lt;math&gt;
C^J_{e_3} = \varepsilon^{1}_1 \varepsilon^{2}_2 / D
&lt;/math&gt;

&lt;br&gt;
where D the denominator is given by:

&lt;br&gt;
&lt;math&gt;
D = \varepsilon^{2}_1 \varepsilon^{3}_2 -\varepsilon^{1}_1 \varepsilon^{3}_2 + \varepsilon^{1}_1 \varepsilon^{2}_2
&lt;/math&gt;

Note that every term in the numerator appears in the denominator, this ensures that the flux control coefficient summation theorem is satisfied.

Likewise the concentration control coefficients can also be derived, for &lt;math&gt; S_1 &lt;/math&gt;

&lt;math&gt;
C^{S_1}_{e_1} = (\varepsilon^{3}_2 - \varepsilon^{2}_2) / D
&lt;/math&gt;

&lt;br&gt;
&lt;math&gt;
C^{S_1}_{e_2} = - \varepsilon^{3}_2 / D
&lt;/math&gt;

&lt;br&gt;
&lt;math&gt;
C^{S_1}_{e_3} = \varepsilon^{2}_2 / D
&lt;/math&gt;

&lt;br&gt;
And for &lt;math&gt; S_2 &lt;/math&gt;

&lt;br&gt;
&lt;math&gt;
C^{S_2}_{e_1} = \varepsilon^{2}_1 / D
&lt;/math&gt;

&lt;br&gt;
&lt;math&gt;
C^{S_2}_{e_2} = -\varepsilon^{1}_1 / D
&lt;/math&gt;

&lt;br&gt;
&lt;math&gt;
C^{S_2}_{e_3} = (\varepsilon^{1}_1 - \varepsilon^{2}_1) / D
&lt;/math&gt;

Note that the denominators remain the same as before and behave as a [[Normalizing constant|normalizing]] factor.

== Derivation using Perturbations ==

Control equations can also be derived by considering the effect of perturbations on the system. Consider that reaction rates &lt;math&gt;v_1&lt;/math&gt; and &lt;math&gt;v_2&lt;/math&gt; are determined by two enzymes &lt;math&gt;e_1&lt;/math&gt; and &lt;math&gt;e_2&lt;/math&gt; respectively. Changing either enzyme will result in a change to the steady state level of &lt;math&gt;x&lt;/math&gt; and the steady state reaction rates &lt;math&gt;v&lt;/math&gt;. Consider a small change in &lt;math&gt;e_1&lt;/math&gt; of magnitude &lt;math&gt;\delta e_1&lt;/math&gt;. This will have a number of effects, it will increase &lt;math&gt;v_1&lt;/math&gt; which in turn will increase &lt;math&gt;x&lt;/math&gt; which in turn will increase &lt;math&gt;v_2&lt;/math&gt;. Eventually the system will settle to a new steady state. We can describe these changes by focusing on the change in &lt;math&gt;v_1&lt;/math&gt; and &lt;math&gt;v_2&lt;/math&gt;. The change in &lt;math&gt;v_2&lt;/math&gt;, which we designate &lt;math&gt;\delta v_2&lt;/math&gt;, came about as a result of the change &lt;math&gt;\delta x&lt;/math&gt;. Because we are only considering small changes we can express the change &lt;math&gt;\delta v_2&lt;/math&gt; in terms of &lt;math&gt;\delta x&lt;/math&gt; using the relation:

&lt;math&gt;
\delta v_2 = \frac{\partial v_2}{\partial x} \delta x
&lt;/math&gt;

where the derivative &lt;math&gt;\partial v_2/\partial x&lt;/math&gt; measures how responsive &lt;math&gt;v_2&lt;/math&gt; is to changes in &lt;math&gt;x&lt;/math&gt;. The derivative can be computed if we know the rate law for &lt;math&gt;v_2&lt;/math&gt;. For example, if we assume that the rate law is &lt;math&gt;v_2 = k_2 x&lt;/math&gt; then the derivative is &lt;math&gt;k_2&lt;/math&gt;. We can also use a similar strategy to compute the change in &lt;math&gt;v_1&lt;/math&gt; as a result of the change &lt;math&gt;\delta e_1&lt;/math&gt;. This time the change in &lt;math&gt;v_1&lt;/math&gt; is a result of two changes, the change in &lt;math&gt;e_1&lt;/math&gt; itself and the change in &lt;math&gt;x&lt;/math&gt;. We can express these changes by summing the two individual contributions:

&lt;math&gt;
\delta v_1 = \frac{\partial v_1}{\partial e_1} \delta e_1 + \frac{\partial v_1}{\partial x} \delta x
&lt;/math&gt;

We have two equations, one describing the change in &lt;math&gt;v_1&lt;/math&gt; and the other in &lt;math&gt;v_2&lt;/math&gt;. Because we allowed the system to settle to a new steady state we can also state that the change in reaction rates must be the same (otherwise it wouldn't be at steady state). That is we can assert that &lt;math&gt;\delta v_1 = \delta v_2&lt;/math&gt;. With this in mind we equate the two equations and write:

&lt;math&gt; \frac{\partial v_2}{\partial x} \delta x = \frac{\partial v_1}{\partial e_1} \delta e_1 + \frac{\partial v_1}{\partial x} \delta x &lt;/math&gt;

Solving for the ratio &lt;math&gt;\delta x/\delta e_1&lt;/math&gt; we obtain:

&lt;math&gt; \frac{\delta x}{\delta e_1} = \dfrac{-\dfrac{\partial v_1}{\partial e_1}}{\dfrac{\partial v_2}{\partial x} - \dfrac{\partial v_1}{\partial x}} &lt;/math&gt;

In the limit, as we make the change &lt;math&gt;\delta e_1&lt;/math&gt; smaller and smaller, the left-hand side converges to the derivative &lt;math&gt;dx/de_1&lt;/math&gt;:

&lt;math&gt; \lim_{\delta e_1 \rightarrow 0} \frac{\delta x}{\delta e_1} = \frac{dx}{de_1} = \dfrac{-\dfrac{\partial v_1}{\partial e_1}}{\dfrac{\partial v_2}{\partial x} - \dfrac{\partial v_1}{\partial x}} &lt;/math&gt;

We can go one step further and scale the derivatives to eliminate units. Multiplying both sides by &lt;math&gt;e_1&lt;/math&gt; and dividing both sides by $x$ yields the scaled derivatives:

&lt;math&gt; \frac{dx}{de_1} \frac{e_1}{x}= \frac{-\dfrac{\partial v_1}{\partial e_1}\dfrac{e_1}{v_1}}
  {\dfrac{\partial v_2}{\partial x} \dfrac{x}{v_2} - \dfrac{\partial v_1}{\partial x} \dfrac{x}{v_1}} &lt;/math&gt;

The scaled derivatives on the right-hand side are the elasticities, &lt;math&gt;\varepsilon^v_x&lt;/math&gt; and the scaled left-hand term is the scaled sensitivity coefficient or concentration control coefficient, &lt;math&gt;C^x_{e}&lt;/math&gt;

&lt;math&gt; C^x_{e_1} = \frac{\varepsilon^1_{e_1}}{\varepsilon^2_x - \varepsilon^1_x} &lt;/math&gt;

We can simplify this expression further. The reaction rate &lt;math&gt;v_1&lt;/math&gt; is usually a linear function of &lt;math&gt;e_1&lt;/math&gt;. For example, in the Briggs-Haldane equation, the reaction rate is given by &lt;math&gt;v= e_1 k_{cat} x/(K_m + x)&lt;/math&gt;. Differentiating this rate law with respect to &lt;math&gt;e_1&lt;/math&gt; and scaling yields: &lt;math&gt;\varepsilon^{v_{1}}_{e_1} = 1&lt;/math&gt;.

Using this result gives:

&lt;math&gt;
C^x_{e_1} = \frac{1}{\varepsilon^2_x - \varepsilon^1_x}
&lt;/math&gt;

A similar analysis can be done where &lt;math&gt;e_2&lt;/math&gt; is perturbed. In this case we obtain the sensitivity of &lt;math&gt;x&lt;/math&gt; with respect to &lt;math&gt;e_2&lt;/math&gt;:

&lt;math&gt;
C^x_{e_2} = -\frac{1}{\varepsilon^2_x - \varepsilon^1_x}
&lt;/math&gt;

The above expressions measure how much enzymes &lt;math&gt;e_1&lt;/math&gt; and &lt;math&gt;e_2&lt;/math&gt; control the steady state concentration of intermediate &lt;math&gt;x&lt;/math&gt;. We can also consider how the steady state reaction rates &lt;math&gt;v_1&lt;/math&gt; and &lt;math&gt;v_2&lt;/math&gt; are affected by perturbations in &lt;math&gt;e_1&lt;/math&gt; and &lt;math&gt;e_2&lt;/math&gt;. This is often of importance to metabolic engineers who are interested in increasing rates of production. At steady state the reaction rates are often called the fluxes and abbreviated to &lt;math&gt;J_1&lt;/math&gt; and &lt;math&gt;J_2&lt;/math&gt;. For a linear pathway such this example, both fluxes are equal at steady state so that the flux through the pathway is simply referred to as &lt;math&gt;J&lt;/math&gt;. Expressing the change in flux as a result of a perturbations in &lt;math&gt;e_1&lt;/math&gt; and taking the limit as before we obtain:
&lt;math&gt;
C^J_{e_1} = \frac{\varepsilon^1_x}{\varepsilon^2_x - \varepsilon^1_x}, \quad C^J_{e_2} = \frac{-\varepsilon^1_x}{\varepsilon^2_x - \varepsilon^1_x}
&lt;/math&gt;

The above expressions tell us how much enzymes &lt;math&gt;e_1&lt;/math&gt; and &lt;math&gt;e_2&lt;/math&gt; control the steady state flux. The key point here is that changes in enzyme concentration, or equivalently the enzyme activity, must be brought about by an external action.

== References ==
&lt;references/&gt;

== External links ==
*[http://dbkgroup.org/metabolic-control-analysis/ The Metabolic Control Analysis Web]

{{DEFAULTSORT:Metabolic Control Analysis}}
[[Category:Biochemistry methods]]
[[Category:Metabolism]]
[[Category:Mathematical and theoretical biology]]
[[Category:Systems biology]]

{{portal bar|Metabolism}}</text>
      <sha1>19ezk0y45akbqf16431km401guwm7oy</sha1>
    </revision>
  </page>
  <page>
    <title>Method of lines</title>
    <ns>0</ns>
    <id>5744114</id>
    <revision>
      <id>855390257</id>
      <parentid>732399472</parentid>
      <timestamp>2018-08-17T23:15:49Z</timestamp>
      <contributor>
        <ip>150.135.165.8</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5627">[[File:Method of lines.gif|thumb|Method of lines - the example, which shows the origin of the name of method.]]
The '''method of lines''' (MOL, NMOL, NUMOL&lt;ref name=Schiesser1991&gt;{{cite book|last=Schiesser|first=W. E.|year=1991|title=The Numerical Method of Lines|publisher=Academic Press|isbn=0-12-624130-9}}&lt;/ref&gt;&lt;ref name=Hamdi2007&gt;{{citation|author1=Hamdi, S.|author2=W. E. Schiesser|author3=G. W. Griffiths|year=2007|url=http://www.scholarpedia.org/article/Method_of_Lines|title= Method of lines|work=Scholarpedia|volume=2|issue=7|page=2859|doi=10.4249/scholarpedia.2859}}&lt;/ref&gt;&lt;ref name=Schiesser2009&gt;{{cite book|last=Schiesser|first=W. E. |author2= G. W. Griffiths|year=2009|title=A Compendium of Partial Differential Equation Models:  Method of Lines Analysis with Matlab|publisher=Cambridge University Press|isbn=978-0-521-51986-1}}&lt;/ref&gt;) is a technique for solving [[partial differential equations]] (PDEs) in which all but one dimension is discretized.  MOL allows standard, general-purpose methods and software, developed for the numerical integration of ODEs and DAEs, to be used. A large number of integration routines have been developed over the years in many different programming languages, and some have been published as [[open source]] resources.&lt;ref name=Lee2004&gt;{{cite book|last=Lee|first=H. J.|author2=W. E. Schiesser|year=2004|title=Ordinary and Partial Differential Equation Routines in C, C++, Fortran, Java, Maple and Matlab|publisher=CRC Press|isbn=1-58488-423-1}}&lt;/ref&gt;

The method of lines most often refers to the construction or analysis of numerical methods for partial differential equations that proceeds by first discretizing the spatial derivatives only and leaving the time variable continuous.  This leads to a system of ordinary differential equations to which a numerical method for initial value ordinary equations can be applied.  The method of lines in this context dates back to at least the early 1960s.&lt;ref name=Sarmin1962&gt;{{citation|author1=E. N. Sarmin|author2=L. A. Chudov|year=1963|title=On the stability of the numerical integration of systems of ordinary differential equations arising in the use of the straight line method|work=USSR Computational Mathematics and Mathematical Physics|volume=3|issue=6|pages=1537–1543|doi=10.1016/0041-5553(63)90256-8}}&lt;/ref&gt;  Many papers discussing the  accuracy and stability of the method of lines for various types of partial differential equations have appeared since.&lt;ref name=Zafarullah1970&gt;{{citation|author1=A. Zafarullah|year=1970|title=Application of the Method of Lines to Parabolic Partial Differential Equations With Error Estimates|work=Journal of the Association for Computing Machinery|volume=17|issue=2|pages=294–302|doi=10.1145/321574.321583}}&lt;/ref&gt;&lt;ref name=Verwer1984&gt;{{citation|author1=J. G. Verwer|author2=J. M. Sanz-Serna|year=1984|title=Convergence of method of lines approximations to partial differential equations|work=Computing|volume=33|issue=3-4|pages=297–313|doi=10.1007/bf02242274}}&lt;/ref&gt;

== Application to elliptical equations ==
MOL requires that the PDE problem is well-posed as an initial value ([[cauchy problem|Cauchy]]) problem in at least one dimension, because ODE and DAE integrators are [[initial value problem]] (IVP) solvers. Thus it cannot be used directly on purely [[elliptic partial differential equations]], such as [[Laplace's equation]]. However, MOL has been used to solve Laplace's equation by using the ''method of false transients''.&lt;ref name=Schiesser1991 /&gt;&lt;ref name=Schiesser1994&gt;{{cite book|last=Schiesser|first=W. E.|year=1994|title=Computational mathematics in Engineering and Applied Science: ODEs, DAEs and PDEs|publisher=CRC Press|isbn=0-8493-7373-5}}&lt;/ref&gt; In this method, a time derivative of the dependent variable is added to Laplace’s equation. Finite differences are then used to approximate the spatial derivatives, and the resulting system of equations is solved by MOL. It is also possible to solve elliptical problems by a ''semi-analytical method of lines''.&lt;ref name=Subramanian2004&gt;{{citation|last=Subramanian|first=V.R.|author2=R.E. White|year=2004|title=Semianalytical method of lines for solving elliptic partial differential equations|work=Chemical Engineering Science|volume=59|pages=781–788|doi=10.1016/j.ces.2003.10.019}}&lt;/ref&gt; In this method, the discretization process results in a set of ODE's that are solved by exploiting  properties of the associated exponential matrix.

Recently, to overcome the stability issues associated with the method of false transients, a perturbation approach was proposed which was found to be more robust than standard method of false transients for a wide range of elliptic PDEs.&lt;ref&gt;{{citation|author1=P. W. C. Northrop|author2=P. A. Ramachandran|author3=W. E. Schiesser|author4=V. R. Subramanian|year=2013|title=A Robust False Transient Method of Lines for Elliptic Partial Differential Equations|work=Chem. Eng. Sci.|volume= 90|pages= 32–39|doi=10.1016/j.ces.2012.11.033}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://www.maple.eece.wustl.edu/falsetransient.html False Transient Method of Lines - sample code]
*[https://reference.wolfram.com/mathematica/tutorial/NDSolvePDE.html The Numerical Method of Lines]
&lt;!-- * {{cite book|last=Vande Wouwer | first=Alain|year=2001|title=Adaptive Method of Lines|publisher=Chapman &amp; Hall/CRC|isbn=1-58488-231-X}} --&gt;

{{wikibooks|Partial Differential Equations|Method of Lines}}

{{Numerical PDE}}

{{DEFAULTSORT:Method Of Lines}}
[[Category:Numerical differential equations]]
[[Category:Partial differential equations]]

{{applied-math-stub}}</text>
      <sha1>53xm70ow6rrrv7sfwh57llmef36culp</sha1>
    </revision>
  </page>
  <page>
    <title>Mid-range</title>
    <ns>0</ns>
    <id>2814021</id>
    <revision>
      <id>740663786</id>
      <parentid>732724677</parentid>
      <timestamp>2016-09-22T13:49:23Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* Small samples */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7589">{{For|loudspeakers|mid-range speaker}}
In [[statistics]], the '''mid-range''' or '''mid-extreme''' of a set of statistical data values is the [[arithmetic mean]] of the maximum and minimum values in a [[data set]], defined as:{{sfn|Dodge|2003}}

:&lt;math&gt;M=\frac{\max x + \min x}{2}.&lt;/math&gt;

The mid-range is the midpoint of the [[Range (statistics)|range]]; as such, it is a measure of [[central tendency]].

The mid-range is rarely used in practical statistical analysis, as it lacks [[#Efficiency|efficiency]] as an estimator for most distributions of interest,  because it ignores all intermediate points, and lacks [[#Robustness|robustness]], as outliers change it significantly. Indeed, it is one of the least efficient and least robust statistics. However, it finds some use in special cases: it is the maximally efficient estimator for the center of a uniform distribution, trimmed mid-ranges address robustness, and as an [[L-estimator]], it is simple to understand and compute.



==Robustness==

The midrange is highly sensitive to outliers and ignores all but two data points. It is therefore a very non-[[robust statistic]], having a [[breakdown point]] of 0, meaning that a single observation can change it arbitrarily. Further, it is highly influenced by outliers: increasing the sample maximum or decreasing the sample minimum by ''x'' changes the mid-range by &lt;math&gt;x/2,&lt;/math&gt; while it changes the sample mean, which also has breakdown point of 0, by only &lt;math&gt;x/n.&lt;/math&gt; It is thus of little use in practical statistics, unless outliers are already handled.

A [[trimmed estimator|trimmed]] midrange is known as a '''{{visible anchor|midsummary}}''' – the ''n''% trimmed midrange is the average of the ''n''% and (100&amp;minus;''n'')% percentiles, and is more robust, having a [[breakdown point]] of ''n''%. In the middle of these is the [[midhinge]], which is the 25% midsummary. The [[median]] can be interpreted as the fully trimmed (50%) mid-range; this accords with the convention that the median of an even number of points is the mean of the two middle points.

These trimmed midranges are also of interest as [[descriptive statistics]] or as [[L-estimator]]s of central location or [[skewness]]: differences of midsummaries, such as midhinge minus the median, give measures of skewness at different points in the tail.{{sfn|Velleman|Hoaglin|1981}}

==Efficiency==

Despite its drawbacks, in some cases it is useful: the midrange is a highly [[Efficiency (statistics)|efficient]] [[estimator]] of μ, given a small sample of a sufficiently [[platykurtic]] distribution, but it is inefficient for [[mesokurtic]] distributions, such as the normal.

For example, for a [[continuous uniform distribution]] with unknown maximum and minimum, the mid-range is the [[UMVU]] estimator for the mean. The [[sample maximum]] and sample minimum, together with sample size, are a sufficient statistic for the population maximum and minimum – the distribution of other samples, conditional on a given maximum and minimum, is just the uniform distribution between the maximum and minimum and thus add no information. See [[German tank problem]] for further discussion. Thus the mid-range, which is an unbiased and sufficient estimator of the population mean, is in fact the UMVU: using the sample mean just adds noise based on the uninformative distribution of points within this range.

Conversely, for the normal distribution, the sample mean is the UMVU estimator of the mean. Thus for platykurtic distributions, which can often be thought of as between a uniform distribution and a normal distribution, the informativeness of the middle sample points versus the extrema values varies from "equal" for normal to "uninformative" for uniform, and for different distributions, one or the other (or some combination thereof) may be most efficient. A robust analog is the [[trimean]], which averages the midhinge (25% trimmed mid-range) and median.

===Small samples===

For small sample sizes (''n'' from 4 to 20) drawn from a sufficiently platykurtic distribution (negative [[excess kurtosis]], defined as γ&lt;sub&gt;2&lt;/sub&gt; = (μ&lt;sub&gt;4&lt;/sub&gt;/(μ&lt;sub&gt;2&lt;/sub&gt;)²)&amp;nbsp;&amp;minus;&amp;nbsp;3), the mid-range is an efficient estimator of the mean ''μ''. The following table summarizes empirical data comparing three estimators of the mean for distributions of varied kurtosis; the [[modified mean]] is the [[truncated mean]], where the maximum and minimum are eliminated.&lt;ref&gt;{{Cite thesis |type=Master's |title=An Investigation of Measures of Central Tendency Used in Quality Control |url=https://books.google.com/books/about/An_Investigation_of_Measures_of_Central.html?id=GNtiNwAACAAJ |author= |last=Vinson |first=William Daniel |year=1951 |publisher= University of North Carolina at Chapel Hill |at=Table (4.1), pp. 32–34}}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Statistical methods in quality control |first=Dudley Johnstone |last=Cowden |publisher=Prentice-Hall |year=1957 |pages=[https://books.google.com/books?ei=DXFqUf7hFIiiige4lICIAg&amp;id=b-BTAAAAMAAJ&amp;dq=William+D.+Vinson+statistics&amp;q=William+D.+Vinson#search_anchor 67–68]}}&lt;/ref&gt;

{| class="wikitable"
! Excess kurtosis (γ&lt;sub&gt;2&lt;/sub&gt;) !! Most efficient estimator of ''μ''
|-
| &amp;minus;1.2 to &amp;minus;0.8 || Midrange                     
|-
| &amp;minus;0.8 to  2.0 || Mean
|-
|  2.0 to  6.0 || Modified mean
|}

For ''n'' = 1 or 2, the midrange and the mean are equal (and coincide with the median), and are most efficient for all distributions. For ''n'' = 3, the modified mean is the median, and instead the mean is the most efficient measure of central tendency for values of ''γ''&lt;sub&gt;2&lt;/sub&gt; from 2.0 to 6.0 as well as from &amp;minus;0.8 to 2.0.

==Sampling properties==

For a sample of size ''n'' from the [[standard normal distribution]], the mid-range ''M'' is unbiased, and has a variance given by:{{sfn|Kendall|Stuart|1969|loc=Example 14.4}}
:&lt;math&gt;\operatorname{var}(M)=\frac{\pi^2}{24 \ln(n)}.&lt;/math&gt;

For a sample of size ''n'' from the standard [[Laplace distribution]], the mid-range ''M'' is unbiased, and has a variance given by:{{sfn|Kendall|Stuart|1969|loc=Example 14.5}}
:&lt;math&gt;\operatorname{var}(M)=\frac{\pi^2}{12}&lt;/math&gt;
and, in particular, the variance does not decrease to zero as the sample size grows.

For a sample of size ''n'' from a zero-centred [[Uniform distribution (continuous)|uniform distribution]], the mid-range ''M'' is unbiased, ''nM'' has an [[asymptotic distribution]] which is a [[Laplace distribution]].{{sfn|Kendall|Stuart|1969|loc=Example 14.12}}

==Deviation==
While the mean of a set of values minimizes the sum of squares of [[Deviation (statistics)|deviations]] and the [[median]] minimizes the [[average absolute deviation]], the midrange minimizes the [[maximum deviation]] (defined as &lt;math&gt;\max\left|x_i-m\right|&lt;/math&gt;): it is a solution to a variational problem.

==See also==
* [[Range (statistics)]]
* [[Midhinge]]

==References==
{{reflist|2}}
{{refbegin}}
* {{cite book |title=The Oxford dictionary of Statistical Terms |last= Dodge |first=Y. |year=2003 |publisher=Oxford University Press |isbn=0-19-920613-9 |ref=harv }}
* {{cite book |title=The Advanced Theory of Statistics, Volume 1 |last1=Kendall |first1=M.G. |last2=Stuart |first2=A. |year=1969 |publisher=Griffin |isbn=0-85264-141-9 |ref=harv }}
* {{cite book |title=Applications, Basics and Computing of Exploratory Data Analysis |last1=Velleman |first1=P. F. |last2=Hoaglin |first2=D. C. |year=1981 |isbn=0-87150-409-X |ref=harv }}
{{refend}}

{{DEFAULTSORT:Mid-Range}}
[[Category:Means]]
[[Category:Summary statistics]]</text>
      <sha1>mih070fenvgamjhquxu3uud52ozh1od</sha1>
    </revision>
  </page>
  <page>
    <title>Nitrogen-vacancy center</title>
    <ns>0</ns>
    <id>14461309</id>
    <revision>
      <id>865134148</id>
      <parentid>863677169</parentid>
      <timestamp>2018-10-21T23:57:42Z</timestamp>
      <contributor>
        <ip>69.243.144.66</ip>
      </contributor>
      <comment>/* Energy level structure and its manipulation by external fields */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="45721">The '''nitrogen-vacancy center''' ('''N-V center''') is one of numerous [[Crystallographic defects in diamond|point defect]]s in [[diamond]].  Its most explored and useful property is [[photoluminescence]], which can be easily detected from an individual N-V center, especially those in the negative charge state (N-V&lt;sup&gt;−&lt;/sup&gt;). Electron spins at N-V centers, localized at atomic scales, can be manipulated at room temperature by applying a [[magnetic field]], [[electric field]], [[microwave]] radiation or light, or a combination, resulting in sharp resonances in the intensity and wavelength of the photoluminescence. These resonances can be explained in terms of [[electron spin]] related phenomena such as [[quantum entanglement]], [[spin-orbit interaction]] and [[Rabi cycle|Rabi oscillations]],  and analysed using advanced [[quantum optics]] theory. An individual N-V center can be viewed as a basic unit of a [[quantum computer]], and it has potential applications in novel, more efficient fields of electronics and computational science including [[quantum cryptography]], [[spintronics]], steadystomics and [[maser]]s.

[[Image:Model of nitrogen-vacancy center in diamond.jpg|thumb|upright|Simplified atomic structure of the N-V&lt;sup&gt;−&lt;/sup&gt; center]]

==Structure==
The nitrogen-vacancy center is a [[Crystallographic defects in diamond|point defect]] in the [[Diamond cubic|diamond lattice]]. It consists of a nearest-neighbor pair of a nitrogen atom, which substitutes for a carbon atom, and a [[Vacancy defect|lattice vacancy]].

[[File:N-V charge control PL maps.jpg|upright=1.1|thumb|Bottom images are spatial photoluminescence (PL) maps before and after application of +20 V voltage to a planar [[Schottky diode]]. Top image outlines the experiment. The PL maps reveal conversion of individual N-V&lt;sup&gt;0&lt;/sup&gt; centers into N-V&lt;sup&gt;−&lt;/sup&gt; centers that appear as bright dots.&lt;ref name=schottky&gt;{{cite journal|doi=10.1038/srep12160|pmid=26177799|pmc=4503995|title=Active charge state control of single N-V centres in diamond by in-plane Al-Schottky junctions|journal=Scientific Reports|volume=5|pages=12160|year=2015|last1=Schreyvogel|first1=C.|last2=Polyakov|first2=V.|last3=Wunderlich|first3=R.|last4=Meijer|first4=J.|last5=Nebel|first5=C. E.|bibcode=2015NatSR...512160S}}&lt;/ref&gt;]]
Two charge states of this defect, neutral N-V&lt;sup&gt;0&lt;/sup&gt; and negative N-V&lt;sup&gt;−&lt;/sup&gt;, are known from [[spectroscopy|spectroscopic]] studies using [[optical absorption]],&lt;ref name="davies"&gt;
{{cite journal
 |last1=Davies |first1=G.
 |last2=Hamer |first2=M. F.
 |date=1976
 |title=Optical Studies of the 1.945 eV Vibronic Band in Diamond
 |journal=[[Proceedings of the Royal Society of London A]]
 |volume=348 |issue=1653 |pages=285
 |bibcode=1976RSPSA.348..285D
 |doi=10.1098/rspa.1976.0039
}}&lt;/ref&gt;&lt;ref&gt;
{{Cite journal | last1 = Mita | first1 = Y. | title = Change of absorption spectra in type-Ib diamond with heavy neutron irradiation | doi = 10.1103/PhysRevB.53.11360 | journal = Physical Review B | volume = 53 | issue = 17 | pages = 11360–11364 | year = 1996 | bibcode = 1996PhRvB..5311360M }}&lt;/ref&gt; [[photoluminescence]] (PL),&lt;ref name="photochromism"&gt;
{{cite journal
 |last1=Iakoubovskii |first1=K.
 |last2=Adriaenssens |first2=G. J.
 |last3=Nesladek |first3=M.
 |date=2000
 |title=Photochromism of vacancy-related centres in diamond
 |journal=[[Journal of Physics: Condensed Matter]]
 |volume=12  |issue=2 |pages=189
 |url=http://pubman.nims.go.jp/pubman/item/escidoc:1587366:1/component/escidoc:1587365/jpc189.pdf
 |doi=10.1088/0953-8984/12/2/308
|bibcode = 2000JPCM...12..189I }}&lt;/ref&gt; [[electron paramagnetic resonance]] (EPR)&lt;ref name="w15"&gt;
{{cite journal
 |last1=Loubser |first1=J. H. N.
 |last2=van Wyk |first2=J. A.
 |date=1977
 |title=Electron Spin Resonance in Annealed Type 1b Diamond
 |journal=Diamond Research
 |volume=11 |pages=4–7
 |issn=0070-4679&lt;!-- Hard to find journal--&gt;
}}&lt;/ref&gt;&lt;ref name="w15b"&gt;
{{cite journal
 |last1=Loubser |first1=J. H. N.
 |last2=van Wyk |first2=J. A.
 |date=1978
 |title=Electron spin resonance in the study of diamond
 |journal=[[Reports on Progress in Physics]]
 |volume=41 |issue=8  |pages=1201
 |bibcode=1978RPPh...41.1201L
 |doi=10.1088/0034-4885/41/8/002
}}&lt;/ref&gt;&lt;ref name="redman"&gt;
{{cite journal
 |last1=Redman|first1=D.
 |last2=Brown|first2=S.
 |last3=Sands|first3=R.
 |last4=Rand|first4=S.
 |date=1991
 |title=Spin dynamics and electronic states of N-V centers in diamond by EPR and four-wave-mixing spectroscopy
 |journal=[[Physical Review Letters]]
 |volume=67 |issue=24 |pages=3420–3423
 |bibcode=1991PhRvL..67.3420R
 |doi=10.1103/PhysRevLett.67.3420
 |pmid=10044729
}}&lt;/ref&gt; and optically detected magnetic resonance (ODMR),&lt;ref name="gruber"/&gt; which can be viewed as a hybrid of PL and EPR; most details of the structure originate from EPR. A nitrogen atom has five valence electrons. Three of them [[Covalent bond|covalently]] bond to the carbon atoms and two remain non-bonded and are called a [[lone pair]]. The vacancy has three unpaired electrons. Two of them make a quasi covalent bond and one remains unpaired. The overall symmetry, however, is axial (trigonal [[Molecular symmetry#Common point groups|C&lt;sub&gt;3V&lt;/sub&gt;]]); one can visualize this by imagining the three unpaired vacancy electrons continuously exchanging their roles.

The N-V&lt;sup&gt;0&lt;/sup&gt; thus has one unpaired electron and is paramagnetic. However, despite extensive efforts, [[electron paramagnetic resonance]] signals from N-V&lt;sup&gt;0&lt;/sup&gt; avoided detection for decades until 2008. Optical excitation is required to bring the N-V&lt;sup&gt;0&lt;/sup&gt; defect into the EPR-detectable excited state; the signals from the ground state are presumably too broad for EPR detection.&lt;ref&gt;
{{cite journal
 |last1=Felton |first1=S.
 |display-authors=etal
  |date=2008
 |title=Electron paramagnetic resonance studies of the neutral nitrogen vacancy in diamond
 |journal=[[Physical Review B]]
 |volume=77 |issue=8 |pages=081201
 |bibcode=2008PhRvB..77h1201F
 |doi=10.1103/PhysRevB.77.081201
|url=https://pure.qub.ac.uk/portal/en/publications/electron-paramagnetic-resonance-studies-of-the-neutral-nitrogen-vacancy-in-diamond(c2c09f0e-632f-4687-9fb9-e7085ef7f1c9).html
 }}&lt;/ref&gt;

The N-V&lt;sup&gt;0&lt;/sup&gt; centers can be converted into N-V&lt;sup&gt;−&lt;/sup&gt; by changing the [[Fermi level]] position. This can be achieved by applying external voltage to a [[p-n junction]] made from doped diamond, e.g., in a [[Schottky diode]].&lt;ref name=schottky/&gt;

In the negative charge state N-V&lt;sup&gt;−&lt;/sup&gt;, an extra electron is located at the vacancy site forming a spin S=1 pair with one of the vacancy electrons. As in N-V&lt;sup&gt;0&lt;/sup&gt;, the vacancy electrons are "exchanging roles" preserving the overall trigonal symmetry. This N-V&lt;sup&gt;−&lt;/sup&gt; state is what is commonly, and somewhat incorrectly, called "the nitrogen-vacancy center". The neutral state has not yet been explored for spin manipulations.

The N-V centers are randomly oriented within a diamond crystal. [[Ion implantation]] techniques can enable their artificial creation in predetermined positions.&lt;ref name="V2"&gt;
{{cite journal
 |last1=Awschalom |first1=D. D.
 |last2=Epstein |first2=R.
 |last3=Hanson |first3=R.
 |date=2007
 |title=Diamond Age of Spintronics
 |journal=[[Scientific American]]
 |volume=297 |issue=4 |pages=84
 |bibcode=2007SciAm.297d..84A
 |doi=10.1038/scientificamerican1007-84
}}&lt;/ref&gt;

==Production==
{{Main|Crystallographic defects in diamond}}
Nitrogen-vacancy centers are typically produced from single substitutional nitrogen centers (called C or P1 centers in diamond literature) by irradiation followed by annealing at temperatures above 700&amp;nbsp;°C.&lt;ref name="davies"/&gt; A wide range of high-energy particles are suitable for such irradiation, including electrons, protons, neutrons, ions, and gamma photons. Irradiation produces lattice vacancies, which are a part of N-V centers. Those vacancies are immobile at room temperature, and annealing is required to move them. Single substitutional nitrogen produces strain in the diamond lattice;&lt;ref&gt;
{{cite journal
 |last1=Lang |first1=A. R.
 |display-authors=etal
  |date=1991
 |title=On the Dilatation of Synthetic Type Ib Diamond by Substitutional Nitrogen Impurity
 |journal=[[Philosophical Transactions of the Royal Society A]]
 |volume=337 |issue=1648 |pages=497–520
 |bibcode=1991RSPTA.337..497L
 |doi=10.1098/rsta.1991.0135
 }}&lt;/ref&gt; it therefore efficiently captures moving vacancies,&lt;ref&gt;
{{cite journal | last1 = Iakoubovskii | first1 = K. | last2 = Adriaenssens | first2 = G. J. | year = 2001 | title = Trapping of vacancies by defects in diamond | journal = Journal of Physics: Condensed Matter | volume = 13 | issue = 26 | pages = 6015 | doi = 10.1088/0953-8984/13/26/316 |bibcode = 2001JPCM...13.6015I }}&lt;/ref&gt; producing the N-V centers.

During [[chemical vapor deposition]] of diamond, a small fraction of single substitutional nitrogen impurity (typically &lt;0.5%) traps vacancies generated as a result of the plasma synthesis. Such nitrogen-vacancy centers are preferentially aligned to the growth direction.&lt;ref&gt;{{Cite journal | last1 = Edmonds | first1 = A. | last2 = d’Haenens-Johansson | first2 = U. | last3 = Cruddace | first3 = R. | last4 = Newton | first4 = M. | last5 = Fu | first5 = K. -M. | last6 = Santori | first6 = C. | last7 = Beausoleil | first7 = R. | last8 = Twitchen | first8 = D. | last9 = Markham | first9 = M. | title = Production of oriented nitrogen-vacancy color centers in synthetic diamond | doi = 10.1103/PhysRevB.86.035201 | journal = Physical Review B | volume = 86 | issue = 3 | pages = 035201 | year = 2012 | arxiv = 1112.5757 |bibcode = 2012PhRvB..86c5201E }}&lt;/ref&gt;

Diamond is notorious for having a relatively large lattice strain. Strain splits and shifts optical transitions from individual centers resulting in broad lines in the ensembles of centers.&lt;ref name="davies"/&gt; Special care is taken to produce extremely sharp N-V lines (line width ~10&amp;nbsp;MHz)&lt;ref name="stark"&gt;
{{cite journal
 |last1=Tamarat |first1=Ph.
 |display-authors=etal
  |date=2006
 |title=Stark Shift Control of Single Optical Centers in Diamond
 |journal=[[Physical Review Letters]]
 |volume=97 |issue=8 |pages=083002
 |arxiv=quant-ph/0607170
 |bibcode=2006PhRvL..97h3002T
 |doi=10.1103/PhysRevLett.97.083002
 |pmid=17026299
}}&lt;/ref&gt; required for most experiments: high-quality, pure natural or better synthetic diamonds (type IIa) are selected. Many of them already have sufficient concentrations of grown-in N-V centers and are suitable for applications. If not, they are irradiated by high-energy particles and annealed. Selection of a certain irradiation dose allows tuning the concentration of produced N-V centers such that individual N-V centers are separated by micrometre-large distances. Then, individual N-V centers can be studied with standard [[optical microscope]]s or, better, [[near-field scanning optical microscope]]s having sub-micrometre resolution.&lt;ref name="gruber"/&gt;&lt;ref name="SNOM"/&gt;

==Basic optical properties==
[[Image:NVple.JPG|thumb|upright=1.1|Optical absorption and emission of the N-V&lt;sup&gt;−&lt;/sup&gt; center at room temperature]]
N-V&lt;sup&gt;−&lt;/sup&gt; centers emit bright red light which can be conveniently excited by visible light sources, such as [[Ion laser|argon or krypton lasers]], frequency doubled [[Nd:YAG laser]]s, [[dye laser]]s, or [[He-Ne laser]]s. Excitation can also be achieved at energies below that of zero phonon emission.&lt;ref&gt;{{cite journal
 |last1=De Weerdt |first1=F.
 |last2=Collins|first2=A. T.
 |last3=Zugik|first3=M.
 |last4=Connor|first4=A.
 |date=2005
 |title=Sub-threshold excitation of luminescene of defects in diamonds
 |journal=[[Journal of Physics: Condensed Matter]]
 |volume=50 |issue=17 |pages=8005
 |doi=10.1088/0953-8984/17/50/018
|bibcode = 2005JPCM...17.8005D }}&lt;/ref&gt;
Laser illumination, however, also converts some N-V&lt;sup&gt;−&lt;/sup&gt; into N-V&lt;sup&gt;0&lt;/sup&gt; centers.&lt;ref name="photochromism"/&gt; Emission is very quick (relaxation time ~10 [[nanoseconds|ns]]).&lt;ref&gt;
{{cite journal
 |last1=Collins |first1=A. T.
 |last2=Thomaz|first2=M. F.
 |last3=Jorge|first3=M. I. B.
 |date=1983
 |title=Luminescence decay time of the 1.945 eV centre in type Ib diamond
 |journal=[[Journal of Physics C]]
 |volume=16 |issue=11 |pages=2177
 |bibcode=1983JPhC...16.2177C
 |doi=10.1088/0022-3719/16/11/020
}}&lt;/ref&gt;&lt;ref&gt;
{{cite journal
 |last1=Hanzawa |first1=H.
 |last2=Nisida |first2=Y.
 |last3=Kato |first3=T.
 |date=1997
 |title=Measurement of decay time for the NV centre in Ib diamond with a picosecond laser pulse
 |journal=[[Diamond and Related Materials]]
 |volume=6 |issue=11 |pages=1595
 |bibcode=1997DRM.....6.1595H
 |doi=10.1016/S0925-9635(97)00037-X
}}&lt;/ref&gt; At room temperature, no sharp peaks are observed because of the thermal broadening. However, cooling the N-V&lt;sup&gt;−&lt;/sup&gt; centers with [[liquid nitrogen]] or [[liquid helium]] dramatically narrows the lines down to a width of a few megahertz.

An important property of the luminescence from individual N-V&lt;sup&gt;−&lt;/sup&gt; centers is its high temporal stability. Whereas many single-molecular emitters bleach after emission of 10&lt;sup&gt;6&lt;/sup&gt;–10&lt;sup&gt;8&lt;/sup&gt; photons, no bleaching is observed for the N-V centers at room temperature.&lt;ref name="gruber"/&gt;&lt;ref name="SNOM"&gt;
{{cite journal
 |last1=Kuhn |first1=S.
 |display-authors=etal
  |title=Diamond colour centres as a nanoscopic light source for scanning near-field optical microscopy
 |date=2001
 |journal=[[Journal of Microscopy]]
 |volume=202 |issue=1 |pages=2–6
 |doi=10.1046/j.1365-2818.2001.00829.x
 |pmid=11298860
}}&lt;/ref&gt;

Because of these properties, the ideal technique to address the N-V centers is [[confocal microscopy]], both at room temperature and at low temperature. In particular, low temperature operation is required to specifically address only the zero-phonon line (ZPL).

==Energy level structure and its manipulation by external fields==
[[Image:NVenergy.JPG|thumb|upright=1.1|Schematic energy level structure of the N-V&lt;sup&gt;−&lt;/sup&gt; center. Electron transitions between the ground &lt;sup&gt;3&lt;/sup&gt;A and excited &lt;sup&gt;3&lt;/sup&gt;E states, separated by 1.945 eV (637&amp;nbsp;nm), produce absorption and luminescence. The &lt;sup&gt;3&lt;/sup&gt;A state is split by 1027 gauss&lt;ref name="w15"/&gt;&lt;ref name="w15b"/&gt; (~12 µeV) and the &lt;sup&gt;3&lt;/sup&gt;E state by 508 gauss&lt;ref name="fuchs"&gt;
{{cite journal
 |last1=Fuchs|first1=G. D.
 |display-authors=etal
  |date=2008
 |title=Excited-State Spectroscopy Using Single Spin Manipulation in Diamond
 |journal=[[Physical Review Letters]]
 |volume=101 |issue=1 |pages=117601
 |arxiv=0806.1939
 |bibcode=2008PhRvL.101k7601F
 |doi=10.1103/PhysRevLett.101.117601
 |pmid=18851332
}}&lt;/ref&gt; (~5.9 µeV). Numbers 0, ±1 indicate spin value; splitting due to the orbital degeneracy is not shown.]]

The energy level structure of the N-V&lt;sup&gt;−&lt;/sup&gt; center was established by combining optical, electron paramagnetic resonance and theoretical results, as shown in the figure. In particular, several theoretical works have been done, using the Linear Combination of Atomic Orbitals (LCAO) approach, to build the electronic orbitals to describe the possible quantum states, looking at the N-V center as a molecule. Moreover, group theory results are used, to take into account the symmetry of the diamond crystal, and so the symmetry of the N-V itself. The energy levels are labeled according to the group theory, and in particular are labelled after the [[Molecular symmetry#Character tables|irreducible representations]] of the C&lt;sub&gt;3V&lt;/sub&gt; [[Point groups in three dimensions#Rotation groups|symmetry group]] of the defect center, ''A&lt;sub&gt;1&lt;/sub&gt;, A&lt;sub&gt;2&lt;/sub&gt;'' and ''E''.
The numbers 3 in &lt;sup&gt;3&lt;/sup&gt;A and 1 in &lt;sup&gt;1&lt;/sup&gt;A represent the number of allowable ''m''&lt;sub&gt;s&lt;/sub&gt; spin states, or the spin multiplicity, which range from –''S'' to ''S'' for a total of 2''S''+1 possible states. If ''S''&amp;nbsp;= 1,  ''m''&lt;sub&gt;s&lt;/sub&gt; can be −1, 0, or 1. The &lt;sup&gt;1&lt;/sup&gt;A level is predicted by theory but not directly observed in experiment{{Citation needed|date=January 2015}}, and it is believed to play an important role in the quenching of photoluminescence.

In the absence of an external magnetic field, the ground and excited states are split by the magnetic interaction between the two unpaired electrons at the N-V&lt;sup&gt;−&lt;/sup&gt; center (see microscopic model): when two electrons have parallel spins (m&lt;sub&gt;s&lt;/sub&gt;=±1), their energy is higher than when spins are antiparallel (m&lt;sub&gt;s&lt;/sub&gt;=0). The farther apart the electrons are, the weaker their interaction energy '''D''' (roughly ''D''&amp;nbsp;~1/''r''&lt;sup&gt;3&lt;/sup&gt;).&lt;ref name="w15b"/&gt; Thus the smaller splitting in the excited state can be viewed in terms of larger electron-electron separation in the excited state. When an external magnetic field is applied to the N-V&lt;sup&gt;−&lt;/sup&gt; center, it does not affect the ''m''&lt;sub&gt;s&lt;/sub&gt;=0 states nor the &lt;sup&gt;1&lt;/sup&gt;A state (because it has ''S''&amp;nbsp;= 0), but it splits the ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= ±1 levels. If a magnetic field is oriented along the defect axis and reaches about 1027 G (or 508 G) then the ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= –1 and ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= 0 states in the ground (or excited) state become equal in energy; they strongly interact resulting in so-called [[spin polarization]], which strongly affects the intensity of optical absorption and luminescence transitions involving those states.&lt;ref name="fuchs"/&gt;

This happens because transitions between electronic states are mediated by a [[photon]] which cannot change overall [[spin (physics)|spin]]. Thus optical transitions must preserve the total spin and occur between levels of the same total spin. For this reason, transitions &lt;sup&gt;3&lt;/sup&gt;E↔&lt;sup&gt;1&lt;/sup&gt;A and &lt;sup&gt;1&lt;/sup&gt;A ↔ &lt;sup&gt;3&lt;/sup&gt;A are non-radiative and quench the luminescence. Whereas ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= −1 (excited state) ↔ ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= 0 (ground state) transition was forbidden in the absence of an external magnetic field, it becomes allowed when a magnetic field mixes the ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= −1 and ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= 0 levels in the ground state. As a measurable outcome of this phenomenon, luminescence intensity can be strongly modulated by magnetic field.

An important property of the non-radiative transition between &lt;sup&gt;3&lt;/sup&gt;E and &lt;sup&gt;1&lt;/sup&gt;A is that it is stronger for m&lt;sub&gt;s&lt;/sub&gt; = ±1 and weaker for m&lt;sub&gt;s&lt;/sub&gt; = 0. This property results in a very useful manipulation of N-V center, which is called optical spin-polarization. First, consider an off-resonance excitation which has a higher frequency (typically 2.32 eV (532&amp;nbsp;nm)) than the frequencies of all transitions and thus lays in the vibronic bands for all transitions. By using a pulse of this wavelength, people can excite all spin states and create phonons as well. For a spin state with m&lt;sub&gt;s&lt;/sub&gt; = 0, due to conservation of spin in transition, it will be excited to the corresponding m&lt;sub&gt;s&lt;/sub&gt; = 0 state in &lt;sup&gt;3&lt;/sup&gt;E and then go back to original state. However, for a spin state with m&lt;sub&gt;s&lt;/sub&gt; = ±1 in &lt;sup&gt;3&lt;/sup&gt;A, after the excitation, it has a relatively high probability to jump to the intermediate state &lt;sup&gt;1&lt;/sup&gt;A by non-radiative transition and go to the ground state with m&lt;sub&gt;s&lt;/sub&gt; = 0. After sufficient cycles, the state of the N-V center can be regarded as in the m&lt;sub&gt;s&lt;/sub&gt; = 0 state. Such a process can be used in the initialization of quantum state in quantum information processing.

There is an additional level splitting in the excited &lt;sup&gt;3&lt;/sup&gt;E state due to the orbital degeneracy and [[spin-orbit interaction]]. Importantly, this splitting can be modulated by applying a static [[electric field]],&lt;ref name="stark"/&gt;&lt;ref name="stark2"&gt;
{{cite journal
 |last1=Tamarat |first1=Ph.
 |display-authors=etal
 |date=2008
 |title=Spin-flip and spin-conserving optical transitions of the nitrogen-vacancy centre in diamond
 |journal=[[New Journal of Physics]]
 |volume=10 |issue=4 |pages=045004
 |bibcode=2008NJPh...10d5004T
 |doi=10.1088/1367-2630/10/4/045004
}}&lt;/ref&gt; in a similar fashion to the magnetic field mechanism outlined above, though the physics of the splitting is somewhat more complex. Nevertheless, an important practical outcome is that the intensity and position of the luminescence lines can be modulated by applying electric or/and magnetic fields.

The energy difference between the ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= 0 and ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= ±1 states corresponds to the [[microwave]] region. Thus by irradiating the N-V centers with microwave radiation, one can change the relative population of those levels, thereby again modulating the luminescence intensity.

There is an additional splitting of the ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= ±1 energy levels, which originates from the "[[Hyperfine structure|hyperfine]]" interaction between the nuclear and electron spins. Thus finally, the optical absorption and luminescence from the N-V&lt;sup&gt;−&lt;/sup&gt; center consists of roughly a dozen sharp lines with a separation in the MHz-GHz range, and all those lines can be resolved, given proper sample preparation. The intensity and position of those lines can be modulated using the following tools:

# Amplitude and orientation of [[magnetic field]], which splits the ''m''&lt;sub&gt;s&lt;/sub&gt;&amp;nbsp;= ±1 levels in the ground and excited states.
# Amplitude and orientation of [[Deformation (mechanics)|elastic field]] (strain), which can be applied by, e.g., squeezing the diamond. Similar effects can be induced by applying [[electric field]],&lt;ref name="stark"/&gt;&lt;ref name="stark2"/&gt; and the electric field can be controlled with much higher precision.
# Continuous-wave [[microwave]] radiation, which changes the population of the sublevels within the ground and excited state.&lt;ref name="stark2"/&gt;
# [[Tunable laser]], which can selectively excite certain sublevels of the ground and excited state.&lt;ref name="stark2"/&gt;&lt;ref&gt;
{{cite journal
 |last1=Santori |first1=C.
 |display-authors=etal
 |date=2006
 |title=Coherent Population Trapping of Single Spins in Diamond under Optical Excitation
 |journal=[[Physical Review Letters]]
 |volume=97 |issue=24 |pages=247401
 |arxiv=quant-ph/0607147
 |bibcode=2006PhRvL..97x7401S
 |doi=10.1103/PhysRevLett.97.247401
 |pmid=17280321
 |hdl=2318/103560
 }}&lt;/ref&gt;
# In addition to those static perturbations, numerous dynamic effects ([[spin echo]], [[Rabi cycle|Rabi oscillations]], etc.) can be exploited by applying a carefully designed sequence of microwave pulses.&lt;ref&gt;
{{cite journal
 |last1=Hanson |first1=R.
 |last2=Gywat |first2=O.
 |last3=Awschalom |first3=D. D.
 |date=2006
 |title=Room-temperature manipulation and decoherence of a single spin in diamond
 |journal=[[Physical Review B]]
 |volume=74 |issue=16 |pages=161203
 |arxiv=quant-ph/0608233
 |bibcode=2006PhRvB..74p1203H
 |doi=10.1103/PhysRevB.74.161203
 }}&lt;/ref&gt;&lt;ref&gt;
{{cite journal
 |last1=Dutt |first1=M. V. G.
 |display-authors=etal
 |date=2007
 |url=http://www.its.caltech.edu/~ljiang/academic/papers/Quantum_Register_Exp__Science_2007.pdf
 |title=Quantum Register Based on Individual Electronic and Nuclear Spin Qubits in Diamond
 |journal=[[Science (journal)|Science]]
 |volume=316 |issue=5829 |pages=1312–6
 |bibcode=2007Sci...316.....D
 |doi=10.1126/science.1139831
 |pmid=17540898
}}&lt;/ref&gt;&lt;ref&gt;
{{cite journal
 |last1=Childress |first1=L.
 |display-authors=etal
 |date=2006
 |title=Coherent Dynamics of Coupled Electron and Nuclear Spin Qubits in Diamond
 |journal=[[Science (journal)|Science]]
 |volume=314  |issue=5797 |pages=281–5
 |pmid=16973839
 |bibcode=2006Sci...314..281C
 |doi=10.1126/science.1131871
}}&lt;/ref&gt;&lt;ref&gt;
{{cite journal
 |last1=Batalov |first1=A.
 |display-authors=etal
 |date=2008
 |url=https://www.physik.uni-stuttgart.de/TR21/common/show_file.php/publications/176/publication.pdf
 |title=Temporal Coherence of Photons Emitted by Single Nitrogen-Vacancy Defect Centers in Diamond Using Optical Rabi-Oscillations
 |journal=[[Physical Review Letters]]
 |volume=100  |issue=7 |pages=077401
 |bibcode=2008PhRvL.100g7401B
 |doi=10.1103/PhysRevLett.100.077401
 |pmid=18352594
|hdl=11858/00-001M-0000-0011-A088-E
 }}&lt;/ref&gt;&lt;ref&gt;
{{cite journal
 |last1=Jelezko |first1=F.
 |display-authors=etal
 |date=2004
 |title=Observation of Coherent Oscillations in a Single Electron Spin
 |journal=[[Physical Review Letters]]
 |volume=92 |issue=7 |pages=076401
 |url=http://capem.buffalo.edu/rashba/PRL76401.pdf
 |doi=10.1103/PhysRevLett.92.076401
 |pmid=14995873
 |bibcode = 2004PhRvL..92g6401J
}}&lt;/ref&gt; The first pulse coherently excites the electron spins, and this coherence is then manipulated and probed by the subsequent pulses. Those dynamic effects are rather important for practical realization of [[quantum computer]]s, which ought to work at high frequency.
It should be noted that the above-described energy structure is by no means exceptional for a defect in diamond or other semiconductor.&lt;ref&gt;
{{cite journal
 |last1=Aharonovich |first1=I.
 |display-authors=etal
 |date=2009
 |title=Enhanced single-photon emission in the near infrared from a diamond color center
 |journal=[[Physical Review B]]
 |volume=79 |pages=235316 |issue=23
 |bibcode=2009PhRvB..79w5316A
 |doi=10.1103/PhysRevB.79.235316
}}&lt;/ref&gt;  It was not this structure alone, but a combination of several favorable factors (previous knowledge, easy production and excitation, etc.) which suggested the use of the N-V&lt;sup&gt;−&lt;/sup&gt; center.

== Spin dynamics ==
[[File:Diagram for spin dynamics.png|thumb|left|Spin dynamics in the N-V&lt;sup&gt;–&lt;/sup&gt; center on diamond. The primary transition between triplet ground and excited states is predominantly spin conserving. Decay via the intermediate singlets gives rise to spin polarization by preferentially switching spin from m&lt;sub&gt;s&lt;/sub&gt; = ±1 to m&lt;sub&gt;s&lt;/sub&gt; = 0. Both absorption and emission wavelengths are indicated,&lt;ref&gt;{{Cite journal|last=Gordon|first=Luke|last2=Weber|first2=Justin R.|last3=Varley|first3=Joel B.|last4=Janotti|first4=Anderson|last5=Awschalom|first5=David D.|last6=Van de Walle|first6=Chris G.|date=2013-10-01|title=Quantum computing with defects|journal=MRS Bulletin|volume=38|issue=10|pages=802–807|doi=10.1557/mrs.2013.206|pmid=20404195|pmc=2889300}}&lt;/ref&gt; since they differ due to [[Stokes shift]].&lt;ref&gt;{{Cite journal|last=Rogers|first=L. J.|last2=Doherty|first2=M. W.|last3=Barson|first3=M. S. J.|last4=Onoda|first4=S.|last5=Ohshima|first5=T.|last6=Manson|first6=N. B.|date=2015-01-01|title=Singlet levels of the NV − centre in diamond|journal=New Journal of Physics|
volume=17|issue=1|pages=013048|doi=10.1088/1367-2630/17/1/013048|arxiv = 1407.6244 |bibcode = 2015NJPh...17a3048R }}&lt;/ref&gt; ('''Correction''': The wavelength of the 1E-1A transition should be 1042 nm. &lt;ref&gt;{{Cite journal|last=Rogers|first=L. J.|last2=Armstrong|first2=S.|last3=Sellars|first3=M. J.|last4=Manson|first4=N. B.|date=2008|title=Infrared emission of the NV centre in diamond: Zeeman and uniaxial stress studies|url=http://stacks.iop.org/1367-2630/10/i=10/a=103024|journal=New Journal of Physics|language=en|volume=10|issue=10|pages=103024|doi=10.1088/1367-2630/10/10/103024|issn=1367-2630}}&lt;/ref&gt;)]]
Thinking of the N-V&lt;sup&gt;−&lt;/sup&gt; center as a multielectronic system, we can draw the diagram in the figure at right, where the states are labeled according to their symmetry and with a left superscript that indicates with a 3 if it is a triplet (S=1) and with a 1 if it is a singlet (S=0). It is well accepted today that we have two triplet states and two intermediate singlet states.&lt;ref&gt;{{Cite journal|last=Doherty|first=Marcus W.|last2=Manson|first2=Neil B.|last3=Delaney|first3=Paul|last4=Jelezko|first4=Fedor|last5=Wrachtrup|first5=Jörg|last6=Hollenberg|first6=Lloyd C. L.|date=2013-07-01|title=The nitrogen-vacancy colour centre in diamond|journal=Physics Reports|series=The nitrogen-vacancy colour centre in diamond|volume=528|issue=1|pages=1–45|doi=10.1016/j.physrep.2013.02.001|arxiv = 1302.3288 |bibcode = 2013PhR...528....1D |citeseerx=10.1.1.743.9147}}&lt;/ref&gt;

The optical excitations conserve the spin state, but there is a high probability of the states &lt;math display="inline"&gt;\left|^3\text{E},\pm1\right\rangle&lt;/math&gt; decaying non-radiatively to the singlet state &lt;math display="inline"&gt;\left|^1\text{A}_1\right\rangle&lt;/math&gt;, a phenomenon called intersystem crossing (ISC). This happens at an appreciable rate because the energy curve in function of the position of the atoms for the &lt;math display="inline"&gt;\left|^3\text{E},\pm1\right\rangle&lt;/math&gt; state intersects the curve for the &lt;math display="inline"&gt;\left|^1\text{A}_1\right\rangle&lt;/math&gt; state. Therefore, for some instant during the vibrational relaxation that the ions undergo after the excitement, it is possible for the spin to flip with little or no energy required in the transition.&lt;ref&gt;{{Cite journal|last=Choi|first=SangKook|date=2012-01-01|title=Mechanism for optical initialization of spin in NV|journal=Physical Review B|volume=86|issue=4|pages=041202|doi=10.1103/PhysRevB.86.041202|bibcode = 2012PhRvB..86d1202C }}&lt;/ref&gt; It is important to note that this mechanism also leads to a transition from &lt;math display="inline"&gt;\left|^3\text{E},0\right\rangle&lt;/math&gt; to &lt;math display="inline"&gt;\left|^1\text{A}_1\right\rangle&lt;/math&gt;, but the rate of this ISC is much lower than the &lt;math display="inline"&gt;\left|^3\text{E},\pm1\right\rangle&lt;/math&gt; states rate, therefore this transition is indicated with a thin line. The diagram also shows the non-radiative and infrared competing decay paths between the two singlet states, and the fine splitting in the triplet states, whose differences in energy correspond to microwave frequencies.

Some authors explain the dynamics of the N-V&lt;sup&gt;−&lt;/sup&gt; center by admitting that the transition from &lt;math display="inline"&gt;\left|^1\text{E}\right\rangle&lt;/math&gt; to &lt;math display="inline"&gt;\left|^3\text{A}_2,\pm1\right\rangle&lt;/math&gt; is small, but as Robledo et al. shows,&lt;ref&gt;{{Cite journal|last=Robledo|first=Lucio|last2=Bernien|first2=Hannes|last3=Sar|first3=Toeno van der|last4=Hanson|first4=Ronald|date=2011-01-01|title=Spin dynamics in the optical cycle of single nitrogen-vacancy centres in diamond|journal=New Journal of Physics|volume=13|issue=2|pages=025013|doi=10.1088/1367-2630/13/2/025013|arxiv = 1010.1192 |bibcode = 2011NJPh...13b5013R }}&lt;/ref&gt; only the fact that the probability of decaying to &lt;math display="inline"&gt;\left|^1\text{A}_1\right\rangle&lt;/math&gt; is smaller for &lt;math display="inline"&gt;\left|^3\text{E},0\right\rangle&lt;/math&gt; than for &lt;math display="inline"&gt;\left|^3\text{E},\pm1\right\rangle&lt;/math&gt; is enough to polarize the spin to m&lt;sub&gt;s&lt;/sub&gt; = 0.

==Potential applications==
[[File:N-V center based thermal probe.jpg|thumb|upright=1.4|[[Scanning thermal microscopy]] using the N-V center.&lt;br&gt;(a) Schematics of experimental setup. An electric current is applied to the arms of an [[Atomic force microscope|AFM]] [[cantilever]] ([[phosphorus]]-doped Si, P:Si) and heats up the end section above the tip ([[Intrinsic semiconductor|intrinsic]] Si, ''i''-Si). The bottom lens excites a diamond nanocrystal with a green laser light and collects photoluminescence (PL). The crystal hosts an N-V center and is attached to the AFM tip. A wire on the sample surface serves as the microwave source (mw). The temperature of the cantilever T&lt;sub&gt;h&lt;/sub&gt; is determined from the applied current and voltage. &lt;br&gt;
(b) ODMR spectra of the N-V center at three temperatures. The line splitting originates from a ∼1 mT applied magnetic field. &lt;br&gt;
(c) [[Thermal conductivity]] image of a gold letter E on [[sapphire]]. White circles indicate features that do not correlate with the AFM topography.
(d) PL image of the AFM cantilever end and tip where the diamond nanocrystal appears as the bright spot. (e) Zoomed PL image of the N-V center in d.&lt;ref name=thc&gt;{{cite journal |doi=10.1038/ncomms9954 |pmid=26584676 |pmc=4673876 |title=Imaging thermal conductivity with nanoscale resolution using a scanning spin probe |journal=Nature Communications |volume=6 |issue=8954 |pages=8954 |year=2015 |last1=Laraoui |first1=Abdelghani |last2=Aycock-Rizzo |first2=Halley |last3=Gao |first3=Yang |last4=Lu |first4=Xi |last5=Riedo |first5=Elisa |last6=Meriles |first6=Carlos A. |arxiv=1511.06916 |bibcode=2015NatCo...6E8954L}}&lt;/ref&gt;]]
The spectral shape and intensity of the optical signals from the N-V&lt;sup&gt;−&lt;/sup&gt; centers are sensitive to external perturbation, such as temperature, strain, electric and magnetic field. However, the use of spectral shape for sensing those perturbation is impractical, as the diamond would have to be cooled to cryogenic temperatures to sharpen the N-V&lt;sup&gt;−&lt;/sup&gt; signals. A more realistic approach is to use luminescence intensity (rather than lineshape), which exhibits a sharp resonance when a microwave frequency is applied to diamond that matches the splitting of the ground state levels. The resulting optically detected magnetic resonance signals are sharp even at room temperature, and can be used in miniature sensors. Such sensors can detect magnetic fields of a few nanotesla&lt;ref&gt;{{Cite journal | last1=Maze | first1=J. R. | last2=Stanwix | first2=P. L. | last3=Hodges | first3=J. S. | last4=Hong | first4=S. | last5=Taylor | first5=J. M. | last6=Cappellaro | first6=P. | last7=Jiang | first7=L. | last8=Dutt | first8=M. V. G. | last9=Togan | first9=E. | doi=10.1038/nature07279 | last10=Zibrov | first10=A. S. | last11=Yacoby | first11=A. | last12=Walsworth | first12=R. L. | last13=Lukin | first13=M. D. | title=Nanoscale magnetic sensing with an individual electronic spin in diamond | journal=Nature | volume=455 | issue=7213 | pages=644–647 | year=2008 | pmid=18833275 | url=http://zumbuhllab.unibas.ch/pdf/talks/090821_Sarah_DiamondNV_BSensor.pdf |bibcode=2008Natur.455..644M }}&lt;/ref&gt; or electric fields of about 10 V/cm&lt;ref&gt;{{Cite journal | last1=Dolde | first1=F. | last2=Fedder | first2=H. | last3=Doherty | first3=M. W. | last4=Nöbauer | first4=T. | last5=Rempp | first5=F. | last6=Balasubramanian | first6=G. | last7=Wolf | first7=T. | last8=Reinhard | first8=F. | last9=Hollenberg | first9=L. C. L. | last10=Jelezko | doi=10.1038/nphys1969 | first10=F. | last11=Wrachtrup | first11=J. | title=Electric-field sensing using single diamond spins | journal=Nature Physics | volume=7 | issue=6 | pages=459 | year=2011 | arxiv=1103.3432 |bibcode=2011NatPh...7..459D | hdl=11858/00-001M-0000-0027-768E-1 }}&lt;/ref&gt; at kilohertz frequencies after 100 seconds of averaging. This sensitivity allows detecting a magnetic or electric field produced by a single electron located tens of nanometers away from an N-V&lt;sup&gt;−&lt;/sup&gt; center.

Using the same mechanism, the N-V&lt;sup&gt;−&lt;/sup&gt; centers were employed in [[scanning thermal microscopy]] to measure high-resolution spatial maps of temperature and [[thermal conductivity]] (see image).&lt;ref name=thc/&gt;

Another possible use the N-V&lt;sup&gt;−&lt;/sup&gt; centers is as a detector to measure the full mechanical stress tensor in the bulk of the crystal. For this application, the stress-induced splitting of the zero-phonon-line is exploited, and its polarization properties.&lt;ref&gt;{{Cite journal | doi=10.1063/1.4819834 | title=Measurement of the full stress tensor in a crystal using photoluminescence from point defects: The example of nitrogen vacancy centers in diamond | journal=Applied Physics Letters | volume=103 | issue=10 | pages=101905 | year=2013 | last1=Grazioso | first1=F. | last2=Patton | first2=B. R. | last3=Delaney | first3=P. | last4=Markham | first4=M. L. | last5=Twitchen | first5=D. J. | last6=Smith | first6=J. M. |bibcode=2013ApPhL.103j1905G |arxiv=1110.3658 | url=https://pure.qub.ac.uk/portal/en/publications/measurement-of-the-full-stress-tensor-in-a-crystal-using-photoluminescence-from-point-defects-the-example-of-nitrogen-vacancy-centers-in-diamond(2bf91e15-bb44-4c1f-8f8c-ec140c822d80).html}}&lt;/ref&gt; A robust frequency-modulated radio receiver using the electron-spin-dependent photoluminescence that operated up to 350&amp;nbsp;°C demonstrates the possibility for use in extreme conditions.&lt;ref&gt;{{cite journal |last1=Shao |first1=Linbo |last2=Zhang |first2=Mian |last3=Markham |first3=Matthew |last4=Edmonds |first4=Andrew |last5=Loncar |first5=Marko |title=Diamond Radio Receiver: Nitrogen-Vacancy Centers as Fluorescent Transducers of Microwave Signals |journal=Phys. Rev. Appl. |date=15 December 2016 |volume=6 |issue=6 |pages=064008 |doi=10.1103/PhysRevApplied.6.064008 |bibcode=2016PhRvP...6f4008S}}&lt;/ref&gt;

In addition to the quantum optical applications, luminescence from the N-V&lt;sup&gt;−&lt;/sup&gt; centers can be applied for imaging biological processes, such as fluid flow in living cells.&lt;ref&gt;
{{cite journal
 |last1=Chang |first1=Y.-R.
 |display-authors=etal
 |date=2008
 |url=http://aao.sinica.edu.tw/download/publication_list/en/149.pdf
 |title=Mass production and dynamic imaging of fluorescent nanodiamonds
 |journal=[[Nature Nanotechnology]]
 |volume=3 |issue=5 |pages=284–8
 |doi=10.1038/nnano.2008.99
 |pmid=18654525
}}&lt;/ref&gt; This application relies on good compatibility of diamond nano-particles with the living cells and on favorable properties of photoluminescence from the N-V&lt;sup&gt;−&lt;/sup&gt; centers (strong intensity, easy excitation and detection, temporal stability, etc.). Compared with large single-crystal diamonds, nanodiamonds are cheap (about 1 USD per gram) and available from various suppliers. N-V&lt;sup&gt;−&lt;/sup&gt; centers are produced in diamond powders with sub-micrometre particle size using the standard process of irradiation and annealing described above. Those nanodiamonds are introduced in a cell, and their luminescence is monitored using a standard [[fluorescence microscope]].&lt;ref&gt;{{Cite journal | last1=Aharonovich | first1=I. | last2=Greentree | first2=A. D. | last3=Prawer | first3=S. | doi=10.1038/nphoton.2011.54 | title=Diamond photonics | journal=Nature Photonics | volume=5 | issue=7 | pages=397 | year=2011 | bibcode=2011NaPho...5..397A }}&lt;/ref&gt;

Further N-V&lt;sup&gt;−&lt;/sup&gt; center has been hypothesized to be a potential bio-mimetic system for emulating radical pair spin dynamics of the [[Magnetoreception|avian compass]].&lt;ref name="cryptochrome"&gt;[http://www.ks.uiuc.edu/Research/cryptochrome/ Cryptochrome and Magnetic Sensing], University of Illinois at Urbana-Champaign&lt;/ref&gt;&lt;ref&gt;{{Cite journal |title=Quantum Control and Entanglement in a Chemical Compass |journal=Physical Review Letters |date=2010-06-04 |pages=220502 |volume=104 |issue=22 |doi=10.1103/PhysRevLett.104.220502 |pmid=20867156 |first=Jianming |last=Cai |first2=Gian Giacomo |last2=Guerreschi |first3=Hans J. |last3=Briegel |arxiv=0906.2383 |bibcode=2010PhRvL.104v0502C}}&lt;/ref&gt;

[[Stimulated emission]] from the N-V&lt;sup&gt;−&lt;/sup&gt; center has been demonstrated, though it could be achieved only from the phonon side-band (i.e. broadband light) and not from the ZPL. For this purpose the center has to be excited at wavelength longer than ~650&amp;nbsp;nm, as higher-energy excitation ionizes the center.&lt;ref&gt;{{cite journal |doi=10.1038/ncomms14000 |pmid=28128228 |pmc=5290152 |title=Stimulated emission from nitrogen-vacancy centres in diamond |journal=Nature Communications |volume=8 |pages=14000 |year=2017 |last1=Jeske |first1=Jan |last2=Lau |first2=Desmond W. M. |last3=Vidal |first3=Xavier |last4=McGuinness |first4=Liam P. |last5=Reineck |first5=Philipp |last6=Johnson |first6=Brett C. |last7=Doherty |first7=Marcus W. |last8=McCallum |first8=Jeffrey C. |last9=Onoda |first9=Shinobu |last10=Jelezko |first10=Fedor |last11=Ohshima |first11=Takeshi |last12=Volz |first12=Thomas |last13=Cole |first13=Jared H. |last14=Gibson |first14=Brant C. |last15=Greentree |first15=Andrew D. |arxiv=1602.07418 |bibcode=2017NatCo...814000J}}&lt;/ref&gt;

The first continuous-wave room-temperature maser has been demonstrated.&lt;ref&gt;{{Cite journal |last=Breeze |first=Jonathan D. |last2=Sathian |first2=Juna |last3=Salvadori |first3=Enrico |last4=Alford |first4=Neil McN |last5=Kay |first5=Christopher W. M. |date=2018-03-21 |title=Continuous-wave room-temperature diamond maser |arxiv=1710.07726 |journal=Nature |volume=555 |issue=7697 |pages=493–496 |doi=10.1038/nature25970 |issn=0028-0836 |pmid=29565362 |bibcode=2018Natur.555..493B}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last1=Liu |first1=Ren-Bao |title=A diamond age of masers |journal=Nature |date=22 March 2018 |volume=555 |issue=7697 |pages=447–449 |doi=10.1038/d41586-018-03215-3|pmid=29565370 }}&lt;/ref&gt; It used 532-nm pumped N-V&lt;sup&gt;−&lt;/sup&gt; centers held within a high [[Purcell effect|Purcell factor]] microwave cavity and an external magnetic field of 4300 G. Continuous maser oscillation generated a coherent signal at ~9.2&amp;nbsp;GHz.

The N-V center can have a very long spin [[coherence time]] approaching the second regime.&lt;ref name="maurer"&gt;{{cite journal |last1=Maurer |first1=P.C. |last2=Kucsko |first2=G. |last3=Latta |first3=C. |last4=Jiang |first4=L. |last5=Yao |first5=N.Y. |last6=Bennett |first6=S.D. |last7=Pastawski |first7=F. |last8=Hunger |first8=D. |last9=Chisholm |first9=N. |last10=Markham |first10=M. |last11=Twitchen |first11=D.J. |last12=Cirac |first12=J.I. |last13=Lukin |first13=M.D. |title=Room-temperature quantum bit memory exceeding one second |journal=Science |volume=336 |issue=6086 |pages=1283–1286 |doi=10.1126/science.1220513 |bibcode=2012Sci...336.1283M |pmid=22679092 |year=2012 |url=http://nrs.harvard.edu/urn-3:HUL.InstRepos:12132060 |format=Submitted manuscript}}&lt;/ref&gt;&lt;ref name="gill"&gt;{{cite journal |last1=Bar-Gill |first1=N. |last2=Pham |first2=L.M. |last3=Jarmola |first3=A. |last4=Budker |first4=D. |last5=Walsworth |first5=R.L. |title=Solid-state electronic spin coherence time approaching one second |journal=Nature Communications |volume=4 |pages=1743 |doi=10.1038/ncomms2771 |arxiv=1211.7094 |bibcode=2013NatCo...4E1743B |pmid=23612284 |year=2012}}&lt;/ref&gt; This is advantageous for applications in [[quantum sensing]]&lt;ref name="mamin"&gt;{{cite journal |last1=Mamin |first1=H. J. |last2=Kim |first2=M. |last3=Sherwood |first3=M. H. |last4=Rettner |first4=C. T. |last5=Ohno |first5=K. |last6=Awschalom |first6=D. D. |last7=Rugar |first7=D. |title=Nanoscale Nuclear Magnetic Resonance with a Nitrogen-Vacancy Spin Sensor |journal=Science |volume=339 |issue=6119 |pages=557–560 |doi=10.1126/science.1231540 |bibcode=2013Sci...339..557M |pmid=23372008 |year=2013}}&lt;/ref&gt; and [[quantum communication]].&lt;ref name="hanson"&gt;{{cite journal | last1=Hensen | first1=B. | last2=Bernien | first2=H. | last3=Dréau | first3=A.E. | last4=Reiserer | first4=A. | last5=Kalb | first5=N. | last6=Blok | first6=M.S. | last7=Ruitenberg | first7=J. | last8=Vermeulen | first8=R.F. | last9=Schouten | first9=R.N. | last10=Abellán | first10=C. | last11=Amaya | first11=W. | last12=Pruneri | first12=V. | last13=Mitchell | first13=M.W. | last14=Markham | first14=M. | last15=Twitchen | first15=D.J. | last16=Elkouss | first16=D. | last17=Wehner | first17=S. | last18=Taminiau | first18=T.H. | last19=Hanson | first19=R. |title=Loophole-free Bell inequality violation using electron spins separated by 1.3 kilometres |journal=Nature |volume=526 | issue=7575 |pages=682–686 |doi=10.1038/nature15759 |arxiv=1508.05949 |bibcode=2015Natur.526..682H |pmid=26503041 |year=2015}}&lt;/ref&gt; Disadvantageous for these applications is the long radiative lifetime (~12 ns{{Citation needed|date=July 2018}}) of the N-V center and the strong phonon sideband in its emission spectrum. Both issues can be addressed by putting the N-V center in an [[optical cavity]] {{Citation needed|date=July 2018}}.

==Historical remarks==
The microscopic model and most optical properties of ensembles of the N-V&lt;sup&gt;−&lt;/sup&gt; centers have been firmly established in the 1970s based on the optical measurements combined with uniaxial stress&lt;ref name="davies"/&gt; and on the electron paramagnetic resonance.&lt;ref name="w15"/&gt;&lt;ref name="w15b"/&gt; However, a minor error in EPR results (it was assumed that illumination is required to observe N-V&lt;sup&gt;−&lt;/sup&gt; EPR signals) resulted in the incorrect multiplicity assignments in the energy level structure. In 1991 it was shown that EPR can be observed without illumination,&lt;ref name="redman"/&gt; which established the energy level scheme shown above. The magnetic splitting in the excited state has been measured only recently.&lt;ref name="fuchs"/&gt;

The characterization of single N-V&lt;sup&gt;−&lt;/sup&gt; centers has become a very competitive field nowadays, with many dozens of papers published in the most prestigious scientific journals. One of the first results was reported back in 1997.&lt;ref name="gruber"&gt;
{{cite journal
 |last1=Gruber |first1=A.
 |display-authors=etal
  |date=1997|url=http://sites.fas.harvard.edu/~phys191r/References/d4/Gruber1997.pdf
 |title=Scanning Confocal Optical Microscopy and Magnetic Resonance on Single Defect Centers
 |journal=[[Science (journal)|Science]]
 |volume=276 |pages=2012–2014 |issue=5321
 |doi=10.1126/science.276.5321.2012
}}&lt;/ref&gt; In that paper, it was demonstrated that the fluorescence of single N-V&lt;sup&gt;−&lt;/sup&gt; centers can be detected by room-temperature fluorescence microscopy and that the defect shows perfect photostability. Also one of the outstanding properties of the N-V center was demonstrated, namely room-temperature optically detected magnetic resonance.

==See also==
{{Commons category|Nitrogen-vacancy center in diamond}}
*[[Crystallographic defects in diamond]]
*[[Crystallographic defect]]
*[[Material properties of diamond]]

==References==
{{Reflist|30em}}

{{Quantum computing}}

[[Category:Diamond]]
[[Category:Spintronics]]
[[Category:Spectroscopy]]
[[Category:Crystallographic defects]]
[[Category:Quantum information science]]
[[Category:Quantum computing]]</text>
      <sha1>52tqpzi775maiv7utjskp6wcet6nexw</sha1>
    </revision>
  </page>
  <page>
    <title>Prouhet–Tarry–Escott problem</title>
    <ns>0</ns>
    <id>16400356</id>
    <revision>
      <id>813836618</id>
      <parentid>740950539</parentid>
      <timestamp>2017-12-05T14:03:12Z</timestamp>
      <contributor>
        <username>Maxal</username>
        <id>237258</id>
      </contributor>
      <comment>/* Examples */ formatting</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6465">In [[mathematics]], the '''Prouhet–Tarry–Escott problem''' asks for two [[disjoint sets|disjoint]] [[multiset]]s ''A'' and ''B'' of ''n'' [[integer]]s each, whose first ''k'' [[power sum symmetric polynomial]]s are all equal.
That is, the two multisets should satisfy the equations
:&lt;math&gt;\sum_{a\in A} a^i = \sum_{b\in B} b^i&lt;/math&gt;
for each integer ''i'' from 1 to a given ''k''.  It has been shown that ''n'' must be strictly greater than ''k''.  Solutions with &lt;math&gt;k = n - 1&lt;/math&gt; are called ''ideal solutions''.  Ideal solutions are known for &lt;math&gt;3 \le n \le 10&lt;/math&gt; and for &lt;math&gt;n = 12&lt;/math&gt;.  No ideal solution is known for &lt;math&gt;n=11&lt;/math&gt; or for &lt;math&gt;n \ge 13&lt;/math&gt;.&lt;ref name="Borwein"&gt;{{harvnb|Borwein|p=85}}&lt;/ref&gt;

This problem was named after [[Eugène Prouhet]], who studied it in the early 1850s, and [[Gaston Tarry]] and Escott, who studied it in the early 1910s. The problem originates from letters of [[Christian Goldbach]] and [[Leonhard Euler]] (1750/1751).

== Examples ==

; Ideal solutions

An ideal solution for ''n''&amp;nbsp;=&amp;nbsp;6 is given by the two sets {&amp;nbsp;0,&amp;nbsp;5,&amp;nbsp;6,&amp;nbsp;16,&amp;nbsp;17,&amp;nbsp;22&amp;nbsp;}
and {&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;10,&amp;nbsp;12,&amp;nbsp;20,&amp;nbsp;21&amp;nbsp;}, because:

: 0&lt;sup&gt;1&lt;/sup&gt; + 5&lt;sup&gt;1&lt;/sup&gt; + 6&lt;sup&gt;1&lt;/sup&gt; + 16&lt;sup&gt;1&lt;/sup&gt; + 17&lt;sup&gt;1&lt;/sup&gt; + 22&lt;sup&gt;1&lt;/sup&gt; = 1&lt;sup&gt;1&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt; + 12&lt;sup&gt;1&lt;/sup&gt; + 20&lt;sup&gt;1&lt;/sup&gt; + 21&lt;sup&gt;1&lt;/sup&gt;

: 0&lt;sup&gt;2&lt;/sup&gt; + 5&lt;sup&gt;2&lt;/sup&gt; + 6&lt;sup&gt;2&lt;/sup&gt; + 16&lt;sup&gt;2&lt;/sup&gt; + 17&lt;sup&gt;2&lt;/sup&gt; + 22&lt;sup&gt;2&lt;/sup&gt; = 1&lt;sup&gt;2&lt;/sup&gt; + 2&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;2&lt;/sup&gt; + 12&lt;sup&gt;2&lt;/sup&gt; + 20&lt;sup&gt;2&lt;/sup&gt; + 21&lt;sup&gt;2&lt;/sup&gt;

: 0&lt;sup&gt;3&lt;/sup&gt; + 5&lt;sup&gt;3&lt;/sup&gt; + 6&lt;sup&gt;3&lt;/sup&gt; + 16&lt;sup&gt;3&lt;/sup&gt; + 17&lt;sup&gt;3&lt;/sup&gt; + 22&lt;sup&gt;3&lt;/sup&gt; = 1&lt;sup&gt;3&lt;/sup&gt; + 2&lt;sup&gt;3&lt;/sup&gt; + 10&lt;sup&gt;3&lt;/sup&gt; + 12&lt;sup&gt;3&lt;/sup&gt; + 20&lt;sup&gt;3&lt;/sup&gt; + 21&lt;sup&gt;3&lt;/sup&gt;

: 0&lt;sup&gt;4&lt;/sup&gt; + 5&lt;sup&gt;4&lt;/sup&gt; + 6&lt;sup&gt;4&lt;/sup&gt; + 16&lt;sup&gt;4&lt;/sup&gt; + 17&lt;sup&gt;4&lt;/sup&gt; + 22&lt;sup&gt;4&lt;/sup&gt; = 1&lt;sup&gt;4&lt;/sup&gt; + 2&lt;sup&gt;4&lt;/sup&gt; + 10&lt;sup&gt;4&lt;/sup&gt; + 12&lt;sup&gt;4&lt;/sup&gt; + 20&lt;sup&gt;4&lt;/sup&gt; + 21&lt;sup&gt;4&lt;/sup&gt;

: 0&lt;sup&gt;5&lt;/sup&gt; + 5&lt;sup&gt;5&lt;/sup&gt; + 6&lt;sup&gt;5&lt;/sup&gt; + 16&lt;sup&gt;5&lt;/sup&gt; + 17&lt;sup&gt;5&lt;/sup&gt; + 22&lt;sup&gt;5&lt;/sup&gt; = 1&lt;sup&gt;5&lt;/sup&gt; + 2&lt;sup&gt;5&lt;/sup&gt; + 10&lt;sup&gt;5&lt;/sup&gt; + 12&lt;sup&gt;5&lt;/sup&gt; + 20&lt;sup&gt;5&lt;/sup&gt; + 21&lt;sup&gt;5&lt;/sup&gt;.

For ''n''&amp;nbsp;=&amp;nbsp;12, an ideal solution is given by ''A'' = {±22,&amp;nbsp;±61,&amp;nbsp;±86,&amp;nbsp;±127,&amp;nbsp;±140,&amp;nbsp;±151} and ''B''&amp;nbsp;=&amp;nbsp;{±35,&amp;nbsp;±47,&amp;nbsp;±94,&amp;nbsp;±121,&amp;nbsp;±146,&amp;nbsp;±148}.&lt;ref&gt;[http://euler.free.fr/eslp/TarryPrb.htm#Ideal%20symmetric Solution found by Nuutti Kuosa, Jean-Charles Meyrignac and Chen Shuwen, in 1999].&lt;/ref&gt;

; Other solutions

Prouhet used the [[Thue–Morse sequence]] to construct a solution with &lt;math&gt;n=2^k&lt;/math&gt; for any &lt;math&gt;k&lt;/math&gt;. Namely, partition the numbers from 0 to &lt;math&gt;2^{k+1}-1&lt;/math&gt; into the [[evil number]]s and the [[odious number]]s; then the two sets of the partition give a solution to the problem.&lt;ref&gt;{{citation
 | last = Wright | first = E. M.
 | doi = 10.2307/2309513
 | journal = The American Mathematical Monthly
 | mr = 0104622
 | pages = 199–201
 | title = Prouhet's 1851 solution of the Tarry–Escott problem of 1910
 | volume = 66
 | year = 1959}}.&lt;/ref&gt; For instance, for &lt;math&gt;n=8&lt;/math&gt; and &lt;math&gt;k=3&lt;/math&gt;, Prouhet's solution is:
:0&lt;sup&gt;1&lt;/sup&gt; + 3&lt;sup&gt;1&lt;/sup&gt; + 5&lt;sup&gt;1&lt;/sup&gt; + 6&lt;sup&gt;1&lt;/sup&gt; + 9&lt;sup&gt;1&lt;/sup&gt; + 10&lt;sup&gt;1&lt;/sup&gt; + 12&lt;sup&gt;1&lt;/sup&gt; + 15&lt;sup&gt;1&lt;/sup&gt; = 1&lt;sup&gt;1&lt;/sup&gt; + 2&lt;sup&gt;1&lt;/sup&gt; + 4&lt;sup&gt;1&lt;/sup&gt; + 7&lt;sup&gt;1&lt;/sup&gt; +  8&lt;sup&gt;1&lt;/sup&gt; + 11&lt;sup&gt;1&lt;/sup&gt; + 13&lt;sup&gt;1&lt;/sup&gt; + 14&lt;sup&gt;1&lt;/sup&gt;
:0&lt;sup&gt;2&lt;/sup&gt; + 3&lt;sup&gt;2&lt;/sup&gt; + 5&lt;sup&gt;2&lt;/sup&gt; + 6&lt;sup&gt;2&lt;/sup&gt; + 9&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;2&lt;/sup&gt; + 12&lt;sup&gt;2&lt;/sup&gt; + 15&lt;sup&gt;2&lt;/sup&gt; = 1&lt;sup&gt;2&lt;/sup&gt; + 2&lt;sup&gt;2&lt;/sup&gt; + 4&lt;sup&gt;2&lt;/sup&gt; + 7&lt;sup&gt;2&lt;/sup&gt; +  8&lt;sup&gt;2&lt;/sup&gt; + 11&lt;sup&gt;2&lt;/sup&gt; + 13&lt;sup&gt;2&lt;/sup&gt; + 14&lt;sup&gt;2&lt;/sup&gt;
:0&lt;sup&gt;3&lt;/sup&gt; + 3&lt;sup&gt;3&lt;/sup&gt; + 5&lt;sup&gt;3&lt;/sup&gt; + 6&lt;sup&gt;3&lt;/sup&gt; + 9&lt;sup&gt;3&lt;/sup&gt; + 10&lt;sup&gt;3&lt;/sup&gt; + 12&lt;sup&gt;3&lt;/sup&gt; + 15&lt;sup&gt;3&lt;/sup&gt; = 1&lt;sup&gt;3&lt;/sup&gt; + 2&lt;sup&gt;3&lt;/sup&gt; + 4&lt;sup&gt;3&lt;/sup&gt; + 7&lt;sup&gt;3&lt;/sup&gt; +  8&lt;sup&gt;3&lt;/sup&gt; + 11&lt;sup&gt;3&lt;/sup&gt; + 13&lt;sup&gt;3&lt;/sup&gt; + 14&lt;sup&gt;3&lt;/sup&gt;.

== Generalizations ==
A higher dimensional version of the Prouhet–Tarry–Escott problem has been introduced and studied by [[Andreas Alpers]] and [[Robert Tijdeman]] in 2007: Given parameters &lt;math&gt;n,k \in \mathbb{N}&lt;/math&gt;, find two different multi-sets &lt;math&gt;\{(x_1,y_1),\dots,(x_n,y_n)\}&lt;/math&gt;, &lt;math&gt;\{(x_1',y_1'),\dots,(x_n',y_n') \}&lt;/math&gt; of points from &lt;math&gt;\mathbb{Z}^2&lt;/math&gt;  such that

:&lt;math&gt;\sum_{i=1}^nx_i^jy_i^{d-j}=\sum_{i=1}^n{x'}_i^j{y'}_i^{d-j} &lt;/math&gt;

for all &lt;math&gt;d,j \in \{0,\dots,k\}&lt;/math&gt; with &lt;math&gt;j \leq d.&lt;/math&gt; This problem is related to [[discrete tomography]] and also leads to special Prouhet-Tarry-Escott solutions over the [[Gaussian integers]] (though solutions to the Alpers-Tijdeman problem do not exhaust the Gaussian integer solutions to Prouhet-Tarry-Escott).

A solution for &lt;math&gt;n=6&lt;/math&gt; and &lt;math&gt;k=5&lt;/math&gt; is given, for instance, by:

:&lt;math&gt;\{(x_1,y_1),\dots,(x_6,y_6)\}=\{(2,1),(1,3),(3,6),(6,7),(7,5),(5,2)\}&lt;/math&gt; and

:&lt;math&gt;\{(x'_1,y'_1),\dots,(x'_6,y'_6)\}=\{(1,2),(2,5),(5,7),(7,6),(6,3),(3,1)\}&lt;/math&gt;.

No solutions for &lt;math&gt;n=k+1&lt;/math&gt; with &lt;math&gt;k\geq6&lt;/math&gt; are known.

==See also==
* [[Euler's sum of powers conjecture]]
* [[Beal's conjecture]]
* [[Jacobi–Madden equation]]
* [[Taxicab number]]
* [[Pythagorean quadruple]]
* [[Sums of powers]], a list of related conjectures and theorems
* [[Discrete tomography]]

==Notes==
{{reflist}}

==References==
*{{citation | last=Borwein | first=Peter B. | authorlink=Peter Borwein | title=Computational Excursions in Analysis and Number Theory | chapter=The Prouhet–Tarry–Escott problem | pages=85–96 | series=CMS Books in Mathematics | publisher=[[Springer-Verlag]] | year=2002 | isbn=0-387-95444-9 | url=https://books.google.com/books?id=A_ITwN13J6YC&amp;pg=85#PPA85,M1 | accessdate=2009-06-16}} Chap.11.
*{{citation | last=Alpers| first=Andreas| authorlink=Andreas Alpers| author2=Rob Tijdeman | title=The Two-Dimensional Prouhet-Tarry-Escott Problem | pages=403–412 | year=2007 | journal=Journal of Number Theory | volume=123 | issue=2 | url=http://www.math.leidenuniv.nl/~tijdeman/altijd.pdf | accessdate=2015-04-01 | doi=10.1016/j.jnt.2006.07.001}}.

==External links==
*{{mathworld | title = Prouhet-Tarry-Escott problem | urlname = Prouhet-Tarry-EscottProblem }}

{{DEFAULTSORT:Prouhet-Tarry-Escott problem}}
[[Category:Diophantine equations]]
[[Category:Mathematical problems]]</text>
      <sha1>n2abolmohwwzg29pqvwcp2ngfs9t99f</sha1>
    </revision>
  </page>
  <page>
    <title>Provable security</title>
    <ns>0</ns>
    <id>1182348</id>
    <revision>
      <id>867267165</id>
      <parentid>867115540</parentid>
      <timestamp>2018-11-04T18:28:02Z</timestamp>
      <contributor>
        <username>NealKoblitz</username>
        <id>33499382</id>
      </contributor>
      <comment>Undid revision 867115540 by [[Special:Contributions/Marcelju|Marcelju]] ([[User talk:Marcelju|talk]]) unsourced, editorializing, see WP:OR</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15620">{{no footnotes|section|date=September 2018}}
'''Provable security''' refers to any type or level of security that can be proved. It is used in different ways by different fields.

Usually, this refers to mathematical proofs, which are common in cryptography. In such a proof, the capabilities of the attacker are defined by an [[adversary (cryptography)|adversarial]] model (also referred to as attacker model): the aim of the proof is to show that the attacker must solve the underlying [[Computational complexity theory#Hard|hard problem]] in order to break the security of the modelled system. Such a proof generally does not consider [[side-channel attacks]] or other implementation-specific attacks, because they are usually impossible to model without implementing the system (and thus, the proof only applies to this implementation).

Outside of cryptography, the term is often used in conjunction with [[secure coding]] and [[security by design]], both of which can rely on proofs to show the security of a particular approach. As with the cryptographic setting, this involves an attacker model and a model of the system. For example, code can be verified to match the intended functionality, described by a model: this can be done through [[Static program analysis|static checking]]. These techniques are sometimes used for evaluating products (see [[Common Criteria]]): the security here depends not only on the correctness of the attacker model, but also on the model of the code.

Finally, the term provable security is sometimes used by sellers of [[security software]] that are attempting to sell security products like [[firewall (computing)|firewalls]], [[antivirus software]] and [[intrusion detection systems]]. As these products are typically not subject to scrutiny, many [[hacker (computer security)|security researchers]] consider this type of claim to be selling [[Snake oil (cryptography)|snakeoil]].

== In cryptography ==
In [[cryptography]], a system has '''provable security''' if its security requirements can be stated formally in an [[adversary (cryptography)|adversarial]] model, as opposed to heuristically, with clear assumptions that the adversary has access to the system  as well as enough computational resources.  The proof of security (called a "reduction") is that these security requirements are met provided the assumptions about the adversary's access to the system are satisfied and some clearly stated assumptions about the [[computational hardness assumption|hardness]] of certain computational tasks hold.  An early example of such requirements and proof was given by [[Shafi Goldwasser|Goldwasser]] and [[Silvio Micali|Micali]] for [[semantic security]] and the construction based on the [[quadratic residuosity problem]]. Some proofs of security are in given theoretical models such as the [[random oracle model]], where real cryptographic hash functions are represented by an idealization.

There are several lines of research in provable security. One is to establish the "correct" definition of security for a given, intuitively understood task. Another is to suggest constructions and proofs based on general assumptions as much as possible, for instance the existence of a [[one-way function]]. A major open problem is to establish such proofs based on P ≠ NP, since the existence of one-way functions is not known to follow from the P ≠ NP conjecture.

=== Controversies ===

Several researchers have found mathematical fallacies in proofs that had been used to make claims about the security of important protocols.  In the following partial list of such researchers, their names are followed by first a reference to the original paper with the purported proof and then a reference to the paper in which the researchers reported on flaws:
V. Shoup;&lt;ref&gt;{{citation|last1=Bellare|first1=Mihir|last2=Rogaway|first2=Phillip|title=Optimal asymmetric encryption|journal=Advances in Cryptology -- Eurocrypt '94|pages=92–111|doi=10.1007/BFb0053428}}&lt;/ref&gt;&lt;ref&gt;{{citation|last=Shoup|first=Victor|title=OAEP reconsidered|journal=Journal of Cryptology|volume=15|issue=4|year=2002|pages=223–249|doi=10.1007/s00145-002-0133-9}}&lt;/ref&gt;
A. J. Menezes;&lt;ref&gt;{{citation|last=Krawczyk|first=Hugo|title=HMQV: A high-performance secure Diffie-Hellman protocol|journal=Advances in Cryptology -- Crypto 2005|pages=546–566|doi=10.1007/11535218_33}}&lt;/ref&gt;&lt;ref&gt;{{citation|last=Menezes|first=Alfred J.|title=Another look at HMQV|journal=Journal of Mathematical Cryptology|volume=1|year=2007|pages=47–64|doi=10.1515/JMC.2007.004}}&lt;/ref&gt;
A. Jha and M. Nandi;&lt;ref&gt;{{citation|last1=Bellare|first1=Mihir|last2=Pietrzak|first2=Krzysztof|last3=Rogaway|first3=Phillip|title=Improved security analyses for CBC MACs|journal=Advances in Cryptology -- Crypto 2005|pages=527–545|doi=10.1007/11535218_32}}; and {{citation|last=Pietrzak|first=Krzysztof|title=A tight bound for EMAC|journal=Automata, Languages and Programming. Part II -- ICALP 2006|pages=168–179|doi=10.1007/11787006_15}}&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Jha|first1=Ashwin|last2=Nandi|first2=Mridul|title=Revisiting structure graphs: Applications to CBC-MAC and EMAC|journal=Journal of Mathematical Cryptology|volume=10|year=2016|pages=157–180|doi=10.1515/jmc-2016-0030}}&lt;/ref&gt;
D. Galindo;&lt;ref&gt;{{citation|last1=Boneh|first1=Dan|last2=Franklin|first2=Matthew|title=Identity-based encryption from the Weil pairing|journal=SIAM Journal on Computing|volume=32|issue=3|year=2003|pages=586–615|doi=10.1137/S0097539701398521}}&lt;/ref&gt;&lt;ref&gt;{{citation|last=Galindo|first=David|title=Boneh-Franklin identity based encryption revisited|journal=Automata, Languages and Programming -- ICALP 2005|pages=791–802|doi=10.1007/11523468_64}}&lt;/ref&gt;
T. Iwata, K. Ohashi, and K. Minematsu;&lt;ref&gt;{{citation|last1=McGrew|first1=David A.|last2=Viega|first2=John|title=The security and performance of the Galois/Counter Mode (GCM) of operation|journal=Progress in Cryptology -- Indocrypt 2004|pages=343–355|doi=10.1007/978-3-540-30556-9_27}}&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Iwata|first1=Tetsu|last2=Ohashi|first2=Keisuke|last3=Minematsu|first3=Kazuhiko|title=Breaking and repairing GCM security proofs|journal=Advances in Cryptology -- Crypto 2012|pages=31–49|doi=10.1007/978-3-642-32009-5_3}}&lt;/ref&gt;
M. Nandi;&lt;ref&gt;{{citation|last1=Ristenpart|first1=Thomas|last2=Rogaway|first2=Phillip|title=How to enrich the message space of a cipher|journal=Fast Software Encryption -- FSE 2007|pages=101–118|doi=10.1007/978-3-540-74619-5_7}}&lt;/ref&gt;&lt;ref&gt;{{citation|last=Nandi|first=Mridul|title=XLS is not a strong pseudorandom permutation|journal=Advances in Cryptology -- Asiacrypt 2014|pages=478–490|doi=10.1007/978-3-662-45611-8_25}}&lt;/ref&gt;
J.-S. Coron and D. Naccache;&lt;ref&gt;{{citation|last1=Bellare|first1=Mihir|last2=Garray|first2=Juan A.|last3=Rabin|first3=Tal|title=Fast batch verification for modular exponentiation and digital signatures|journal=Advances in Cryptology -- Eurocrypt '98|pages=236–250|doi=10.1007/BFb0054130}}&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Coron|first1=Jean-Sébastien|last2=Naccache|first2=David|title=On the security of RSA screening|journal=Public Key Cryptography -- PKC '99|pages=197–203|doi=10.1007/3-540-49162-7}}&lt;/ref&gt;
D. Chakraborty, V. Hernández-Jiménez, and P. Sarkar;&lt;ref&gt;{{citation|last1=McGrew|first1=David A.|last2=Fluhrer|first2=Scott R.|title=The security of the extended codebook (XCB) mode of operation|journal=Selected Areas in Cryptography -- SAC 2007|pages=311–327|doi=10.1007/978-3-540-77360-3_20}}&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Chakraborty|first1=Debrup|last2=Hernández-Jiménez|first2=Vicente|last3=Sarkar|first3=Palash|title=Another look at XCB|journal=Cryptography and Communications|volume=7|number=4|year=2015|pages=439–468|doi=10.1007/s12095-015-0127-8}}&lt;/ref&gt;
P. Gaži and U. Maurer;&lt;ref&gt;{{citation|last1=Bellare|first1=Mihir|last2=Rogaway|first2=Phillip|title=The security of triple encryption and a framework for code-based game-playing proofs|journal=Advances in Cryptology -- Eurocrypt 2006|pages=409–426|doi=10.1007/11761679_25}}&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Gaži|first1=Peter|last2=Maurer|first2=Ueli|title=Cascade encryption revisited|journal=Advances in Cryptology -- Asiacrypt 2009|pages=37–51|doi=10.1007/978-3-642-10366-7_3}}&lt;/ref&gt;
S. A. Kakvi and E. Kiltz;&lt;ref&gt;{{citation|last=Coron|first=Jean-Sébastien|title=Optimal security proofs for PSS and other signature schemes|journal=Advances in Cryptology -- Eurocrypt 2002|pages=272–287|doi=10.1007/3-540-46035-7_18}}&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Kakvi|first1=Saqib A.|last2=Kiltz|first2=Eike|title=Optimal security proofs for full domain hash, revisited|journal=Advances in Cryptology -- Eurocrypt 2012|pages=537–553|doi=10.1007/978-3-642-29011-4_32}}&lt;/ref&gt;
and T. Holenstein, R. Künzler, and S. Tessaro.&lt;ref&gt;{{citation|last1=Coron|first1=Jean-Sébastien|last2=Patarin|first2=Jacques|last3=Seurin|first3=Yannick|title=The random oracle model and the ideal cipher model are equivalent|journal=Advances in Cryptology -- Crypto 2008|pages=1–20|doi=10.1007/978-3-540-85174-5_1}}&lt;/ref&gt;&lt;ref&gt;{{citation|last1=Holenstein|first1=Thomas|last2=Künzler|first2=Robin|last3=Tessaro|first3=Stefano|title=The equivalence of the random oracle model and the ideal cipher model, revisited|journal=STOC '11 Proceedings of the 43rd Annual ACM Symposium on Theory of Computing|pages=89–98|doi= 10.1145/1993636.1993650|arxiv=1011.1264}}&lt;/ref&gt;

Koblitz and Menezes have claimed that provable security results for important cryptographic protocols frequently have fallacies in the proofs; are often interpreted in a misleading manner, giving false assurances; typically rely upon strong assumptions that may turn out to be false; are based on unrealistic models of security; and serve to distract researchers' attention from the need for "old-fashioned" (non-mathematical) testing and analysis.  Their series of papers supporting these claims&lt;ref&gt;These papers are all available at {{cite web|title=Another look at provable security|url=http://anotherlook.ca|access-date=12 April 2018}}&lt;/ref&gt; have been controversial in the community.  Among the researchers who have rejected the viewpoint of Koblitz-Menezes is Oded Goldreich, a leading theoretician and author of ''Foundations of Cryptography.''&lt;ref&gt;{{cite book|last=Goldreich|first=Oded|title=Foundations of Cryptography|publisher=Cambridge University Press|year=2003|isbn=9780521791724}}&lt;/ref&gt; He wrote a refutation of their first paper "Another look at `provable security'"&lt;ref&gt;{{citation|last1=Koblitz|first1=Neal|last2=Menezes|first2=Alfred J.|title=Another look at "provable security"|journal=Journal of Cryptology|volume=20|issue=1|year=2007|pages=3–37|doi=10.1007/s00145-005-0432-z}}&lt;/ref&gt; that he titled "On post-modern cryptography."  Goldreich wrote: "...we point out some of the fundamental philosophical flaws that underly the said article and some of its misconceptions regarding theoretical research in Cryptography in the last quarter of a century."&lt;ref name="pomo"&gt;{{cite web|title=On post-modern cryptography|url=https://eprint.iacr.org/2006/461|access-date=12 April 2018}}&lt;/ref&gt;{{rp|1}} In his essay Goldreich argued that the rigorous analysis methodology of provable security is the only one compatible with science, and that Koblitz and Menezes are "reactionary (i.e., they play to the hands of the opponents of progress)."&lt;ref name="pomo"/&gt;{{rp|2}}

In 2007, [[Neal Koblitz|Koblitz]] published "The Uneasy Relationship Between Mathematics and Cryptography,"&lt;ref&gt;{{citation|last=Koblitz|first=Neal|title=The uneasy relationship between mathematics and cryptography|journal=Notices Amer. Math. Soc.|volume=54|issue=8|year=2007|pages=972–979|url=https://www.ams.org/notices/200708/tx070800972p.pdf}}&lt;/ref&gt; which contained some controversial statements about provable security and other topics.  Researchers [[Oded Goldreich]], Boaz Barak, [[Jonathan Katz (computer scientist)|Jonathan Katz]], Hugo Krawczyk, and [[Avi Wigderson]] wrote letters responding to Koblitz's article, which were published in the November 2007 and January 2008 issues of the journal.&lt;ref name="ams1"&gt;{{citation|title=Letters to the Editor|journal=Notices Amer. Math. Soc.|volume=54|issue=12|year=2007|pages=1454–1455|url=http://www.ams.org/notices/200711/tx071101454p.pdf}}&lt;/ref&gt;&lt;ref name="ams2"&gt;{{citation|title=Letters to the Editor|journal=Notices Amer. Math. Soc.|volume=55|issue=1|year=2008|pages=6–7|url=http://www.ams.org/notices/200801/tx080100006p.pdf}}&lt;/ref&gt;  Katz, who is coauthor of a highly regarded cryptography textbook,&lt;ref&gt;{{cite book|last1=Katz|first1=Jonathan|last2=Lindell|first2=Yehuda|title=Introduction to Modern Cryptography|publisher=Chapman &amp; Hall/CRC|year=2008|isbn=9781584885511}}&lt;/ref&gt; called Koblitz's article "snobbery at its purest";&lt;ref name="ams1"/&gt;{{rp|1455}} and Wigderson, who is a permanent member of the [[Institute for Advanced Study]] in Princeton, accused Koblitz of "slander."&lt;ref name="ams2"/&gt;{{rp|7}}

[[Ivan Damgård]] later wrote [[position paper]] at ICALP 2007 on the technical issues,&lt;ref&gt;{{Cite journal | last1 = Damgård | first1 = I. | title = A "proof-reading" of Some Issues in Cryptography | doi = 10.1007/978-3-540-73420-8_2 | volume = 4596 | pages = 2–11 | year = 2007 | journal = Automata, Languages and Programming, 34th International Colloquium, ICALP 2007, Wroclaw, Poland, July 9–13, 2007. Proceedings | isbn = 978-3-540-73419-2| series = [[LNCS]]| pmid =  | pmc = | postscript= .&amp;nbsp;[http://www.daimi.au.dk/~ivan/positionpaper.pdf preprint]}}&lt;/ref&gt; and it was recommended by [[Scott Aaronson]] as a good in-depth analysis.&lt;ref&gt;{{cite web|url=http://www.scottaaronson.com/blog/?p=268|title=Shtetl-Optimized|work=scottaaronson.com}}&lt;/ref&gt;
[[Brian Snow]], former Technical Director of the Information Assurance Directorate of the U.S. [[National Security Agency]], recommended the Koblitz-Menezes paper "The brave new world of bodacious assumptions in cryptography"&lt;ref&gt;{{citation|last1=Koblitz|first1=Neal|last2=Menezes|first2=Alfred J.|title=The brave new world of bodacious assumptions in cryptography|journal=Notices Amer. Math. Soc.|volume=57|year=2010|pages=357–365|url=https://www.ams.org/notices/201003/rtx100300357p.pdf}}&lt;/ref&gt; to the audience at the RSA Conference 2010 Cryptographers Panel.&lt;ref&gt;{{cite web|title=RSA Conference 2010 USA: The Cryptographers Panel|url=https://www.youtube.com/watch?v=z7nOsqgIzew|access-date=9 April 2018}}&lt;/ref&gt;

=== Practice oriented provable security ===

Classical provable security primarily aimed at studying the relationship between asymptotically defined objects. Instead, practice-oriented provable security is concerned with concrete objects of cryptographic practice, such as hash functions, block ciphers, and protocols as they are deployed and used.&lt;ref&gt;{{Cite journal | last1 = Rogaway | first1 = Phillip  | title = Practice-Oriented Provable Security and the Social Construction of Cryptography | journal = Unpublished essay corresponding to an invited talk at EUROCRYPT 2009. May 6, 2009 | postscript=[http://web.cs.ucdavis.edu/~rogaway/papers/cc.pdf preprint]}}&lt;/ref&gt; Practice oriented provable security uses [[concrete security]] to analyse practical constructions with fixed key sizes. "Exact security" or "[[concrete security]]" is the name given to provable security reductions where one quantifies security by computing precise bounds on computational effort, rather than an asymptotic bound which is guaranteed to hold for "sufficiently large" values of the [[security parameter]].

== References ==
{{reflist}}

[[Category:Cryptography]]
[[Category:Theory of cryptography]]</text>
      <sha1>81206w10essueb4eut5izsbugya55mi</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum Byzantine agreement</title>
    <ns>0</ns>
    <id>15985233</id>
    <revision>
      <id>854755883</id>
      <parentid>822445709</parentid>
      <timestamp>2018-08-13T15:22:04Z</timestamp>
      <contributor>
        <username>Shmurak</username>
        <id>32263378</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12289">{{Original research|date=July 2016}}

[[Byzantine fault tolerance|Byzantine fault tolerant]] [[Protocol (computing)|protocols]] are algorithms that are robust to arbitrary types of failures in [[distributed algorithms]]. With the advent and popularity of the [[Internet]], there is a need to develop algorithms that do not require any centralized control that have some guarantee of always working correctly.{{OR|date=July 2016}} The Byzantine agreement protocol is an essential part of this task. In this article the quantum version of the Byzantine protocol,&lt;ref name="Ben-Or"&gt;Michael Ben-Or and Avinatan Hassidim,
Fast quantum byzantine agreement,STOC '05: Proceedings of the thirty-seventh annual ACM symposium on Theory of computing,
pg 481-485 [2005]&lt;/ref&gt; which works in constant time is described.

==Introduction==
The [[Byzantine fault tolerance|Byzantine Agreement]] [[Communications protocol|protocol]] is a protocol in [[distributed computing]].
It takes its name from a problem formulated by Lamport, Shostak and Pease in 1982,&lt;ref name="Lamport:1982"&gt;L. Lamport and R. Shostak and M. Pease, 
The [[Byzantine]] Generals Problem, ACM Trans. Program. Lang. Syst., volume 4, number 3, pg 382-401 [1982]&lt;/ref&gt; which itself is a reference to a historical problem.  The Byzantine army was divided into divisions with each division being led by a General with the following properties:

*Each General is either loyal or a traitor to the [[Byzantine|Byzantine state]].
*All Generals communicate by sending and receiving messages.
*There are only two commands: attack and retreat.
*All loyal Generals should agree on the same plan of action: attack or retreat.
*A small linear fraction of bad Generals should not cause the protocol to fail (less than a &lt;math&gt;\frac{1}{3}&lt;/math&gt; fraction).
(See &lt;ref name="Lynch"&gt;Michael J. Fisher, Nancy  A. Lynch,Michael S. Paterson,Impossibility of Distributed Consensus with One Faulty Process, Journal of the ACM volume 32, issue=2, pg 374-382 [http://portal.acm.org/citation.cfm?doid=3149.214121 Impossibility of Distributed Consensus with One Faulty Process][1985]&lt;/ref&gt; for the proof of the impossibility result). 
The problem usually is equivalently restated in the form of a commanding General and loyal Lieutenants with the General being either loyal or a traitor and the same for the Lieutenants with the following properties.

*All loyal Lieutenants carry out the same order.
*If the commanding General is loyal, all loyal Lieutenants obey the order that he sends.
*A strictly less than &lt;math&gt;\frac{1}{3}&lt;/math&gt; fraction including the commanding General are traitors.

==Byzantine Failure and Resilience==
Failures in an [[algorithm]] or [[Communications protocol|protocol]] can be categorized into three main types:
# A failure to take another execution step in the algorithm: This is usually referred to as a "fail stop" fault.
# A random failure to execute correctly: This is called a "random fault" or "random Byzantine" fault.
# An arbitrary failure where the algorithm fails to execute the steps correctly (usually in a clever way by some adversary to make the whole algorithm fail) which also encompasses the previous two types of faults; this is called a "Byzantine fault".

A Byzantine resilient or [[Byzantine fault tolerance|Byzantine fault tolerant]] protocol or algorithm is an algorithm that is robust to all the kinds of failures mentioned above. For example, given a space shuttle with multiple redundant processors and some of the processors give incorrect data, which processors or sets of processors should be believed? The solution can be formulated as a [[Byzantine fault tolerance|Byzantine fault tolerant]] protocol.

==Sketch of the Algorithm==
We will sketch here the asynchronous algorithm &lt;ref name="Ben-Or"/&gt;
The algorithm works in two phases:
*Phase 1 (Communication phase):
:All messages are sent and received in this round.
:A coin flipping protocol is a procedure that allows two parties A and B that do not trust each other to toss a coin to win a particular object.
There are two types of coin flipping protocols
** [[Quantum Coin Flipping|weak coin flipping]] protocols:&lt;ref name="wiki:tossing"&gt;[https://arxiv.org/abs/quant-ph/0206121v2  I. Kerenidis, A. Nayak, coin flipping with small bias, arxiv]&lt;/ref&gt; The two players A and B initially start with no inputs and they are to compute some value &lt;math&gt;c_{A},c_{B} \in [0,1]&lt;/math&gt; and be able to accuse anyone of cheating. The protocol is successful if A and B agree on the outcome. The outcome 0 is defined as A winning and 1 as B winning. The protocol has the following properties:
***If both players are honest (they follow the protocol), then they agree on the outcome of the protocol &lt;math&gt; c_{A} = c_{B}&lt;/math&gt; with &lt;math&gt; Pr(c_{A} = c_{B} = b) = \frac{1}{2}&lt;/math&gt; for &lt;math&gt; a,b \in \{0, 1\}&lt;/math&gt;.
***If one of the players is honest (i.e., the other player may deviate arbitrarily from the protocol in his or her local computation), then the other party wins with probability at most &lt;math&gt; \frac{1}{2} + \epsilon&lt;/math&gt;. In other words, if B is dishonest, then &lt;math&gt;Pr(c_{A} = c_{B} = 1) \leq \frac{1}{2} + \epsilon&lt;/math&gt;, and if A is dishonest, then &lt;math&gt;Pr(c_{A} = c_{B} = 0)\leq \frac{1}{2} + \epsilon &lt;/math&gt;.
** A [[Quantum Coin Flipping|strong coin flipping protocol]]: In a strong coin flipping protocol, the goal is instead to produce a random bit which is biased away from any particular value 0 or 1. Clearly, any strong coin flipping protocol with bias &lt;math&gt;\epsilon&lt;/math&gt; leads to weak coin flipping with the same bias.

===Verifiable secret sharing.===
* A [[verifiable secret sharing]] (VSS) protocol:&lt;ref name="wiki:VSS"&gt;Verifiable secret sharing [[verifiable secret sharing]]&lt;/ref&gt; A (n,k) [[secret sharing]] protocol allows a set of n players to share a secret, ''s'' such that only a quorum of k or more players can discover the secret. The player sharing (distributing the secret pieces) the secret is usually referred to as the dealer. A verifiable secret sharing protocol differs from a basic secret sharing protocol in that players can verify that their shares are consistent even in the presence of a malicious dealer.

===The Fail-stop protocol.===

====Protocol QuantumCoinFlip for player &lt;math&gt;P_i&lt;/math&gt;====
#Round 1 generate the state &lt;math&gt;|Coin_i\rangle =\frac{1}{\sqrt{2}}|0,0,\ldots,0\rangle + \frac{1}{\sqrt{2}}|1,1,\ldots,1\rangle&lt;/math&gt; on n [[qubits]] and send the kth [[qubit]] to the kth player keeping one part
# Generate the state &lt;math&gt;|Leader_i\rangle= \frac{1}{n^{3/2}}\sum _{a=1}^{n^3}|a,a,\ldots,a\rangle&lt;/math&gt; on ''n'' qubits, an equal superposition of the numbers between 1 and &lt;math&gt;n^3&lt;/math&gt;.Distribute the ''n'' [[qubits]] between all the players
# Receive the quantum messages from all players and wait for the next communication round, thus forcing the adversary to choose which messages were passed.
# Round 2: Measure (in the standard base) all &lt;math&gt;Leader_{j}&lt;/math&gt; [[qubits]] received in round I. Select the player with the highest leader value (ties broken arbitrarily) as the "leader" of the round. Measure the leader’s coin in the standard base.
# Set the output of the QuantumCoinFlip protocol: &lt;math&gt;v_{i}&lt;/math&gt; = measurement outcome of the leader’s coin.

===The Byzantine protocol.===
To generate a random coin assign an integer in the range [0,n-1] to each player and each player is not allowed to choose its own 
random ID as each player &lt;math&gt;P_k&lt;/math&gt; selects a random number &lt;math&gt;s{_{k}^{i}}&lt;/math&gt; for every other player &lt;math&gt;P_{i}&lt;/math&gt; and distributes  this using a verifiable secret sharing scheme.

At the end of this phase players agree on which secrets were properly shared, the secrets are then opened and each player &lt;math&gt;P_i&lt;/math&gt; is assigned the  value &lt;math&gt;s_i =\sum \, {s_{k}^{i}}{\text{for all secrets properly shared}}\mod n&lt;/math&gt;
This requires private information channels so we replace the random secrets by the superposition &lt;math&gt;|\phi\rangle =\frac{1}{\sqrt{n}}\sum_{a=0}^{n-1}|a\rangle&lt;/math&gt;. In which the state is encoded using a quantum verifiable secret sharing protocol (QVSS).&lt;ref name="wiki:QVSS"&gt;Claude Cr´epeau, Daniel Gottesman and Adam Smith, Secure Multi-party Quantum Computation, In 34th ACM Symposium on the Theory of Computing, STOC, pg. 643–652, [2002]&lt;/ref&gt; We cannot distribute the state &lt;math&gt;|\phi,\phi,\ldots \phi\rangle&lt;/math&gt; since the bad players can collapse the state. To prevent bad players from doing so we encode the state using the Quantum verifiable secret sharing (QVSS) and send each player their share of the secret. Here again the verification requires Byzantine Agreement, but replacing the agreement by the grade-cast protocol is enough.&lt;ref name="wiki:byzantine"&gt;Michael Ben-Or, Elan Pavlov, Vinod Vaikuntanathan, Byzantine Agreement in the Full-Information Model in O(log n) Rounds, STOC '06: Proceedings of the thirty-eighth annual ACM symposium on Theory of computing,
pg 179-186 [2006]&lt;/ref&gt;&lt;ref name="wiki:prob"&gt;Pesech Feldman and Silvio Micali. An optimal probabilistic protocol for synchronous byzantine agreement. SIAM J. Comput., pg 873–933, [1997]&lt;/ref&gt;

====Grade-cast protocol====
&lt;!-- Missing image removed: [[Image:Broadcast.PNG|thumb|right|broadcast from dealer to players]] --&gt;
A grade-cast protocol has the following properties using the definitions in &lt;ref name="wiki:byzantine"/&gt;
Informally, a graded [[Broadcasting (computing)|broadcast]] protocol is a protocol with a designated player called “dealer” (the one who broadcasts) such that:
# If the dealer is good, all the players get the same message.
# Even if the dealer is bad, if some good player accepts the message, all the good players get the same message (but they may or may not accept it).
A protocol P is said to be achieve graded [[Broadcasting (computing)|broadcast]] if, at the beginning of the protocol, a designated player D (called the dealer) holds a value v, and at the end of the protocol, every player &lt;math&gt;P_{i}&lt;/math&gt; outputs a pair &lt;math&gt;(value_{i}, confidence_{i})
&lt;/math&gt; such that the following properties hold: 
&lt;math&gt;(\forall i, confidence_{i} \in \{0, 1, 2\})&lt;/math&gt;
#If D is honest, then &lt;math&gt;value_{i}&lt;/math&gt; = v and &lt;math&gt;confidence_{i}&lt;/math&gt; = 2 for every honest player &lt;math&gt;P_i&lt;/math&gt;.
# For any two honest players &lt;math&gt;P_{i}&lt;/math&gt; and &lt;math&gt; P_{j},&lt;/math&gt; &lt;math&gt;\vert confidence_{i} - confidence_{j}\vert \leq 1 &lt;/math&gt;.
# (Consistency) For any two honest players &lt;math&gt;P_{i}&lt;/math&gt; and &lt;math&gt;P_{j}&lt;/math&gt;, if &lt;math&gt;confidence_{i}&gt; 0&lt;/math&gt; and &lt;math&gt; confidence_{j}&gt; 0 &lt;/math&gt;,then &lt;math&gt; value_{i}= value_{j}&lt;/math&gt;.

For &lt;math&gt;t &lt; \frac{n}{4}&lt;/math&gt; the verification stage of the QVSS protocol guarantees that for a good dealer the correct state will be encoded, and that for any, possibly faulty dealer, some particular state will be recovered during the recovery stage. We note that for the purpose of our Byzantine quantum coin flip protocol the recovery stage is much simpler. Each player measures his share of the QVSS and sends the classical value to all other players. The verification stage guarantees, with high probability, that in the presence of up to &lt;math&gt;t &lt; \frac{n}{4}&lt;/math&gt; faulty players all the good players will recover the same classical value (which is the same value that would result from a direct measurement of the encoded state).

== Remarks ==
In 2007, a quantum protocol for Byzantine Agreement was demonstrated experimentally &lt;ref name="wiki:byzexperiment"&gt;Sascha Gaertner, Mohamed Bourennane, Christian Kurtsiefer, Adán Cabello, Harald Weinfurter, Experimental Demonstration of a Quantum Protocol for Byzantine Agreement and Liar Detection, [https://arxiv.org/abs/0710.0290v2 arXiv:0710.0290v2], [2007], [http://link.aps.org/doi/10.1103/PhysRevLett.100.070504 Phys. Rev. Lett. 100 (2008) 070504].&lt;/ref&gt; using a four-photon polarization-entangled state. This shows that the quantum implementation of classical Byzantine Agreement protocols is indeed feasible.

== References ==
{{reflist|2}}

{{DEFAULTSORT:Quantum Byzantine Agreement}}
[[Category:Quantum mechanics]]
[[Category:Cryptography]]
[[Category:Distributed computing problems]]
[[Category:Fault tolerance]]
[[Category:Engineering failures]]
[[Category:Theory of computation]]</text>
      <sha1>l91k4kf0ek4kldld9fz5bvrn5jo8xm8</sha1>
    </revision>
  </page>
  <page>
    <title>Quantum Markov chain</title>
    <ns>0</ns>
    <id>7941780</id>
    <revision>
      <id>825410217</id>
      <parentid>792175062</parentid>
      <timestamp>2018-02-13T06:27:45Z</timestamp>
      <contributor>
        <username>Jarble</username>
        <id>7226930</id>
      </contributor>
      <comment>adding links to references using [[Google Scholar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1598">{{expert}}
In [[mathematics]], the '''quantum Markov chain''' is a reformulation of the ideas of a classical [[Markov chain]], replacing the classical definitions of probability with [[quantum probability]].

==Introduction==
Very roughly, the theory of a quantum Markov chain resembles that of a [[Quantum_finite_automaton#Measure-many_automata|measure-many automaton]], with some important substitutions: the initial state is to be replaced by a [[density matrix]], and the projection operators are to be replaced by [[POVM|positive operator valued measures]].

==Formal statement==
More precisely, a quantum Markov chain is a pair &lt;math&gt;(E,\rho)&lt;/math&gt; with &lt;math&gt;\rho&lt;/math&gt; a [[density matrix]] and &lt;math&gt;E&lt;/math&gt; a [[quantum channel]] such that

:&lt;math&gt;E:\mathcal{B}\otimes\mathcal{B}\to\mathcal{B}&lt;/math&gt;

is a [[completely positive trace-preserving]] map, and &lt;math&gt;\mathcal{B}&lt;/math&gt; a [[C-star algebra|C&lt;sup&gt;*&lt;/sup&gt;-algebra]] of bounded operators. The pair must obey the quantum Markov condition, that
 
:&lt;math&gt;\operatorname{Tr} \rho (b_1\otimes b_2) = \operatorname{Tr} \rho E(b_1, b_2)&lt;/math&gt;

for all &lt;math&gt;b_1,b_2\in \mathcal{B}&lt;/math&gt;.

==See also==
*[[Quantum walk]]

==References==
{{Reflist}}
*Gudder, Stanley. "[https://www.researchgate.net/profile/Stan_Gudder/publication/228697748_Quantum_Markov_chains/links/004635213c09cea606000000/Quantum-Markov-chains.pdf Quantum Markov chains]." Journal of Mathematical Physics 49.7 (2008): 072105.

{{DEFAULTSORT:Quantum Markov Chain}}
[[Category:Exotic probabilities]]
[[Category:Quantum information science]]
[[Category:Markov models]]</text>
      <sha1>r5syoxnbh9rwwgu7xdmutz5bk0qvvvt</sha1>
    </revision>
  </page>
  <page>
    <title>Sample exclusion dimension</title>
    <ns>0</ns>
    <id>3119343</id>
    <revision>
      <id>743036226</id>
      <parentid>742839919</parentid>
      <timestamp>2016-10-07T11:26:37Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>cite repair;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1496">In [[computational learning theory]], '''sample exclusion dimensions''' arise in the study of exact [[concept learning]] with queries.&lt;ref&gt;{{cite book |title=Algorithmic Learning Theory: 12th International Conference, ALT 2001, Washington, DC, USA, November 2001, Proceedings |editor=N. Abe |editor2=R. Khardon |editor3=T. Zeugmann |author=D. Angluin |chapter=Queries Revisited |year=2001 |publisher=Springer |pages=26–28 |isbn=3-540-42875-5}}&lt;/ref&gt;  

In [[algorithmic learning theory]], a '''concept''' over a domain ''X'' is a [[Boolean function]] over ''X''. Here we only consider finite domains. A '''partial approximation''' ''S'' of a concept ''c'' is a Boolean function over &lt;math&gt;Y\subseteq X&lt;/math&gt; such that ''c'' is an extension to ''S''.

Let ''C'' be a class of concepts and ''c'' be a concept (not necessarily in ''C''). Then a '''specifying set''' for c w.r.t. ''C'', denoted by ''S'' is a partial approximation ''S'' of ''c'' such that ''C'' contains at most one extension to ''S''. If we have observed a specifying set for some concept w.r.t. ''C'', then we have enough information to verify a concept in ''C'' with at most one more mind change.
 
The '''exclusion dimension''', denoted by ''XD''(''C''), of a concept class is the maximum of the size of the minimum specifying set of ''c''&lt;nowiki&gt;'&lt;/nowiki&gt; with respect to ''C'', where ''c''&lt;nowiki&gt;'&lt;/nowiki&gt; is a concept not in ''C''.

== References ==
{{reflist}}

[[Category:Computational learning theory]]

{{math-stub}}</text>
      <sha1>lm3y3vz7ueobfole5mjz8m6pqjdguza</sha1>
    </revision>
  </page>
  <page>
    <title>Scottish Café</title>
    <ns>0</ns>
    <id>362651</id>
    <revision>
      <id>862190317</id>
      <parentid>832692514</parentid>
      <timestamp>2018-10-02T18:58:01Z</timestamp>
      <contributor>
        <username>Rathfelder</username>
        <id>398607</id>
      </contributor>
      <comment>removed [[Category:Coffeehouses]]; added [[Category:Coffeehouses of Poland]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4370">[[Image:Lwow - Kawiarnia Szkocka.jpg|thumb|alt=Picture of the building that used to house the Scottish Café|The Scottish Café's building now houses the Szkotcka Restaurant &amp; Bar (named for the original Scottish Café) and the Atlas Deluxe hotel.]]
[[Image:KsiegaSzkocka1.JPG|thumb|Part of the Scottish Book with [[Stefan Banach|Banach's]] and [[Stanislaw Ulam|Ulam's]] notes.]]
The '''Scottish Café''' ({{lang-pl|Kawiarnia Szkocka}}) was the café in [[Lviv|Lwów]], [[Second Polish Republic|Poland]] (now Lviv, [[Ukraine]]) where, in the 1930s and 1940s, &lt;!-- [[Poland|Polish]] --&gt; [[Lwów School of Mathematics|mathematicians from the Lwów School]] collaboratively discussed [[mathematical problem|research problem]]s, particularly in [[functional analysis]] and [[general topology|topology]].

[[Stanislaw Ulam]] recounts that the tables of the café had [[marble]] tops, so they could write in pencil, directly on the table, during their discussions. To keep the results from being lost, and after becoming annoyed with their writing directly on the table tops, [[Stefan Banach]]'s wife provided the mathematicians with a large notebook, which was used for writing the problems and answers and eventually became known as the ''[[Scottish Book]]''. The book—a collection of solved, unsolved, and even probably unsolvable problems—could be borrowed by any of the guests of the café. Solving any of the problems was rewarded with prizes, with the most difficult and challenging problems having expensive prizes (during the [[Great Depression]] and on the eve of [[World War II]]), such as a bottle of fine brandy.&lt;ref&gt;Mauldin, ed.&lt;/ref&gt;

For problem 153, which was later recognized as being closely related to Stefan Banach's "[[approximation problem|basis problem]]", [[Stanisław Mazur]] offered the prize of a live goose. This problem was solved only in 1972 by [[Per Enflo]], who was presented with the live goose in a ceremony that was broadcast throughout Poland.&lt;ref&gt;Mauldin, ed.; Kaluza.&lt;/ref&gt;

The café building now houses the Szkotcka Restaurant &amp; Bar (named for the original Scottish Café) and the Atlas Deluxe hotel at the street address of 27 [[Taras Shevchenko]] Prospekt.

==See also==
The following mathematicians were associated with the [[Lwów School of Mathematics]] or contributed to ''The Scottish Book'':
* [[Stefan Banach]]
* [[Karol Borsuk]]
* [[Marek Kac]]
* [[Stefan Kaczmarz]]
* [[Bronisław Knaster]]
* [[Kazimierz Kuratowski]]
* [[Stanisław Saks]]
* [[Juliusz Schauder]]
* [[Hugo Steinhaus]]

==References==
&lt;references/&gt;

* {{Cite book | first=Roman | last=Kałuża | title=Through a reporter's eyes: The life of Stefan Banach | editor=Ann Kostant and Wojbor Woyczyński | publisher=Birkhäuser | year=1996 | isbn=0-8176-3772-9 | url = https://books.google.com/books?visbn=0-8176-3772-9&amp;id=i3ZrfMinChkC&amp;printsec=frontcover&amp;dq=Stefan+Banach#PPP1,M1|mr=1392949}}
* {{cite book|title=The Scottish Book: Mathematics from the Scottish Café (Including selected papers presented at the ''Scottish Book'' Conference held at North Texas State University, Denton, Tex., May 1979)|editor=R. Daniel Mauldin|publisher=Birkhäuser|location=Boston, Mass.|year=1981|pages=xiii+268 pp. (2 plates)|isbn=3-7643-3045-7|mr=666400}}

==External links==
* [http://www-groups.dcs.st-and.ac.uk/~history/HistTopics/Scottish_Book.html#s5 Scottish book]
* [http://banach.univ.gda.pl/e-scottish-book.html Scottish book Web page] at [http://banach.univ.gda.pl/e-index.html Home Page of Stefan Banach] at [[University of Gdańsk]] website
** [http://banach.univ.gda.pl/pdf/ks-szkocka/ks-szkocka1pol.pdf Manuscript of Scottish book (PDF)]
** [http://banach.univ.gda.pl/pdf/ks-szkocka/ks-szkocka3ang.pdf Typescript of English version of Scottish book (PDF)]
* [http://www-history.mcs.st-and.ac.uk/history/Miscellaneous/Scottish_Cafe.html Kawiarnia Szkocka at the MacTutor archive]
* [http://www.axler.net/Banach.html [[Sheldon Axler]]'s review of "The Life of Stefan Banach"]
{{coord|49|50|09|N|24|1|57|E|type:landmark_region:UA|display=title}}

{{Lviv}}

[[Category:History of Lviv]]
[[Category:History of mathematics]]
[[Category:History of education in Poland]]
[[Category:Coffeehouses of Poland]]
[[Category:Buildings and structures in Lviv]]
[[Category:Poland–Scotland relations]]

{{Poland-hist-stub}}
{{mathpublication-stub}}
{{Ukraine-struct-stub}}</text>
      <sha1>ev7uaw2rfzydhqf61bbn55e8hwknf9m</sha1>
    </revision>
  </page>
  <page>
    <title>Shapiro inequality</title>
    <ns>0</ns>
    <id>5558590</id>
    <revision>
      <id>841087236</id>
      <parentid>820178654</parentid>
      <timestamp>2018-05-14T00:36:44Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.6.5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3952">In [[mathematics]], the '''Shapiro inequality''' is an [[inequality (mathematics)|inequality]] proposed by H. Shapiro in 1954.

==Statement of the inequality==

Suppose &lt;math&gt;n&lt;/math&gt; is a [[natural number]] and &lt;math&gt;x_1, x_2, \dots, x_n&lt;/math&gt; are [[positive number]]s and:

* &lt;math&gt;n&lt;/math&gt; is even and less than or equal to &lt;math&gt;12&lt;/math&gt;, or
* &lt;math&gt;n&lt;/math&gt; is odd and less than or equal to &lt;math&gt;23&lt;/math&gt;.

Then the '''Shapiro inequality''' states that

:&lt;math&gt;\sum_{i=1}^{n} \frac{x_i}{x_{i+1}+x_{i+2}} \geq \frac{n}{2}&lt;/math&gt;

where &lt;math&gt;x_{n+1}=x_1, x_{n+2}=x_2&lt;/math&gt;.

For greater values of &lt;math&gt;n&lt;/math&gt; the inequality does not hold and the strict lower bound is &lt;math&gt;\gamma \frac{n}{2}&lt;/math&gt; with &lt;math&gt;\gamma \approx 0.9891\dots&lt;/math&gt;.

The initial proofs of the inequality in the pivotal cases &lt;math&gt;n=12&lt;/math&gt; (Godunova and Levin, 1976) and &lt;math&gt;n=23&lt;/math&gt; (Troesch, 1989) rely on numerical computations. In 2002, P.J. Bushell and J.B. McLeod published an analytical proof for&amp;nbsp;&lt;math&gt;n=12&lt;/math&gt;.

The value of &lt;math&gt;\gamma&lt;/math&gt; was determined in 1971 by [[Vladimir Drinfeld]], who won a [[Fields Medal]] in 1990.  Specifically, Drinfeld showed that the strict lower bound &lt;math&gt;\gamma&lt;/math&gt; is given by &lt;math&gt;\frac{1}{2} \psi(0)&lt;/math&gt;, where &lt;math&gt;\psi&lt;/math&gt; is the function convex hull of &lt;math&gt;f(x)=e^{-x}&lt;/math&gt;&lt;/sup&gt; and &lt;math&gt;g(x) = \frac{2}{e^x+e^{\frac{x}{2}}}&lt;/math&gt;. (That is, the region above the graph of &lt;math&gt;\psi&lt;/math&gt; is the [[convex hull]] of the union of the regions above the graphs of '&lt;math&gt;f&lt;/math&gt; and &lt;math&gt;g&lt;/math&gt;.)

Interior local mimima of the left-hand side are always&lt;math&gt;\ge\frac{n}2&lt;/math&gt; (Nowosad, 1968).

==Counter-examples for higher &lt;math&gt;n&lt;/math&gt;==

The first counter-example was found by Lighthill in 1956, for &lt;math&gt;n=20&lt;/math&gt;:
:&lt;math&gt;x_{20} = (1+5\epsilon,\ 6\epsilon,\ 1+4\epsilon,\ 5\epsilon,\ 1+3\epsilon,\ 4\epsilon,\ 1+2\epsilon,\ 3\epsilon,\ 1+\epsilon,\ 2\epsilon,\ 1+2\epsilon,\ \epsilon,\ 1+3\epsilon,\ 2\epsilon,\ 1+4\epsilon,\ 3\epsilon,\ 1+5\epsilon,\ 4\epsilon,\ 1+6\epsilon,\ 5\epsilon)&lt;/math&gt; where &lt;math&gt;\epsilon&lt;/math&gt; is close to&amp;nbsp;0.
Then the left-hand side is equal to &lt;math&gt;10 - \epsilon^2 + O(\epsilon^3)&lt;/math&gt;, thus lower than 10 when &lt;math&gt;\epsilon&lt;/math&gt; is small enough.

The following counter-example for &lt;math&gt;n=14&lt;/math&gt; is by Troesch (1985):
:&lt;math&gt;x_{14} = (0, 42, 2, 42, 4, 41, 5, 39, 4, 38, 2, 38, 0, 40)&lt;/math&gt; (Troesch, 1985)&lt;!--this example has been double-checked by user:FvdP, 2010/01/12--&gt;
&lt;!-- Next counter-example is cited in A M Fink 1998 as from Troesch 1985. Sadly, it seems wrong: I compute LHS = 0.50010878... there probably is a typo in it.
:&lt;math&gt;x_{25} = (25, 0, 29, 0, 34, 5, 35, 13, 30, 17, 24, 18, 18, 17, 13, 16, 9, 16, 5, 16, 2, 18, 0, 20, 0)&lt;/math&gt;
--&gt;

==References==
* {{cite book | zbl=0895.26001 | last=Fink | first=A.M. | chapter=Shapiro's inequality | editor=Gradimir V. Milovanović, G. V. | title=Recent progress in inequalities. Dedicated to Prof. Dragoslav S. Mitrinović | location=Dordrecht | publisher=Kluwer Academic Publishers. | series=Mathematics and its Applications (Dordrecht) | volume=430 | pages=241–248 | year=1998 | isbn=0-7923-4845-1 }}
* {{cite journal | zbl=1018.26010 | last1=Bushell | first1=P.J. | last2=McLeod | first2=J.B. | title=Shapiro's cyclic inequality for even n | journal=J. Inequal. Appl. | volume=7 | number=3 | pages=331–348 | year=2002 | issn=1029-242X |url=ftp://ftp.sam.math.ethz.ch/EMIS/journals/HOA/JIA/40a3.pdf}} They give an analytic proof of the formula for even &lt;math&gt;n\le12&lt;/math&gt;, from which the result for all &lt;math&gt;n\le12&lt;/math&gt; follows. They state &lt;math&gt;n=23&lt;/math&gt; as an open problem.

==External links==
* [https://web.archive.org/web/20100630173514/http://www.math.niu.edu/~rusin/known-math/99/shapiro Usenet discussion in 1999] (Dave Rusin's notes)
* [http://planetmath.org/encyclopedia/ShapiroInequality.html PlanetMath]

[[Category:Inequalities]]</text>
      <sha1>85ce2fge0pzcf9schh3xj1uqr99ef6q</sha1>
    </revision>
  </page>
  <page>
    <title>Sidon sequence</title>
    <ns>0</ns>
    <id>20823677</id>
    <revision>
      <id>859932044</id>
      <parentid>841539998</parentid>
      <timestamp>2018-09-17T07:04:30Z</timestamp>
      <contributor>
        <username>Mvinyals</username>
        <id>12354125</id>
      </contributor>
      <minor/>
      <comment>Update reference URL</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6491">In [[number theory]], a '''Sidon sequence''' (or '''Sidon set'''), named after the Hungarian mathematician [[Simon Sidon]], is a sequence ''A''&amp;nbsp;=&amp;nbsp;{''a''&lt;sub&gt;0&lt;/sub&gt;,&amp;nbsp;''a''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''a''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;...} of natural numbers in which all pairwise sums ''a''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;+&amp;nbsp;''a''&lt;sub&gt;''j''&lt;/sub&gt; (''i''&amp;nbsp;≤&amp;nbsp;''j'') are different.  Sidon introduced the concept in his investigations of [[Fourier series]].

The main problem in the study of Sidon sequences, posed by Sidon,&lt;ref&gt;{{citation|first1=P.|last1=Erdős|author1-link=Paul Erdős|first2=P.|last2=Turán|author2-link=Pál Turán|title=On a problem of Sidon in additive number theory and on some related problems|journal=J. London Math. Soc.|volume=16|year=1941|pages=212–215|doi=10.1112/jlms/s1-16.4.212|url=http://www.renyi.hu/~p_erdos/1941-01.pdf}}. [http://www.math-inst.hu/~p_erdos/1944-02.pdf Addendum], '''19''' (1944), 208.&lt;/ref&gt; is to find the largest number of elements a Sidon sequence ''A'' can have smaller than some given number ''x''.  Despite a large body of research,&lt;ref&gt;{{citation|first=K.|last=O'Bryant|url=http://www.emis.ams.org/journals/EJC/Surveys/ds11.pdf|title=A complete annotated bibliography of work related to Sidon sequences|journal=Electronic Journal of Combinatorics|volume=11|year=2004|page=39}}.&lt;/ref&gt; the question remained unsolved for almost 80 years. In 2010, it was finally settled&lt;ref&gt;{{citation|first1=J.|last1=Cilleruelo|author1-link=Javier Cilleruelo|first2=I.|last2= Ruzsa|author2-link=Imre Z. Ruzsa|first3=C.|last3=Vinuesa|author3-link=Carlos Vinuesa|title=Generalized Sidon sets|journal=Advances in Mathematics|volume=225|year=2010|pages=2786–2807|url=https://matematicas.uam.es/~franciscojavier.cilleruelo/Papers/generalizados.pdf|doi=10.1016/j.aim.2010.05.010}}&lt;/ref&gt; by J. Cilleruelo, [[Imre Z. Ruzsa|I. Ruzsa]] and C. Vinuesa.

==Early results==

[[Paul Erdős]] and [[Pál Turán]] proved that, for every ''x'' &gt; 0, the number of elements smaller than ''x'' in a Sidon sequence is at most &lt;math&gt;\sqrt{x}+O(\sqrt[4]{x})&lt;/math&gt;.  Using a construction of J. Singer, they showed that there exist Sidon sequences that contain &lt;math&gt;\sqrt{x}(1-o(1))&lt;/math&gt; terms less than ''x''.

==Infinite Sidon sequences==

Erdős also showed that if we consider any particular infinite Sidon sequence ''A'' and let ''A''(''x'') denote the number of its elements up to ''x'', then

: &lt;math&gt;\liminf_{x \to \infty} \frac{A(x)\sqrt{\log x}}{\sqrt{x}}\leq 1&lt;/math&gt;.

That is, infinite Sidon sequences are thinner than the densest finite Sidon sequences.

For the other direction, [[Sarvadaman Chowla|Chowla]] and Mian observed that the greedy algorithm gives an infinite Sidon sequence with  &lt;math&gt;A(x)&gt;c\sqrt[3]{x}&lt;/math&gt; for every ''x''.&lt;ref&gt;{{citation
 | last1 = Mian | first1 = Abdul Majid
 | last2 = Chowla | first2 = S. | author2-link = Sarvadaman Chowla
 | journal = Proc. Natl. Acad. Sci. India A
 | mr = 0014114
 | pages = 3–4
 | title = On the ''B''&lt;sub&gt;2&lt;/sub&gt; sequences of Sidon
 | volume = 14
 | year = 1944}}.&lt;/ref&gt; [[Miklós Ajtai|Ajtai]], [[János Komlós (mathematician)|Komlós]], and [[Endre Szemerédi|Szemerédi]] improved this with a construction&lt;ref&gt;{{citation|first1=M.|last1=Ajtai|author1-link=Miklós Ajtai|first2=J.|last2=Komlós|author2-link=János Komlós (mathematician)|first3=E.|last3=Szemerédi|author3-link=Endre Szemerédi|title=A dense infinite Sidon sequence|journal=European Journal of Combinatorics|volume=2|year=1981|pages=1–11|mr=0611925|issue=1|doi=10.1016/s0195-6698(81)80014-5}}.&lt;/ref&gt; of a Sidon sequence with

: &lt;math&gt;A(x)&gt;\sqrt[3]{x\log x}.&lt;/math&gt;

The best lower bound to date was given by [[Imre Z. Ruzsa]], who proved&lt;ref&gt;{{citation|first=I. Z.|last=Ruzsa|authorlink=Imre Z. Ruzsa|title=An infinite Sidon sequence|journal=Journal of Number Theory|volume=68|year=1998|pages=63–71|mr=1492889|doi=10.1006/jnth.1997.2192}}.&lt;/ref&gt; that a Sidon sequence with

: &lt;math&gt;A(x)&gt;x^{\sqrt{2}-1-o(1)}&lt;/math&gt;

exists. Erdős conjectured that an infinite Sidon set ''A'' exists for which &lt;math&gt;A(x)&gt;x^{1/2-o(1)}&lt;/math&gt; holds. He and [[Alfréd Rényi|Rényi]] showed&lt;ref&gt;{{citation|first1=P.|last1=Erdős|author1-link=Paul Erdős|first2=A.|last2=Rényi|author2-link=Alfréd Rényi|title=Additive properties of random sequences of positive integers|journal=Acta Arithmetica|volume=6|year=1960|pages=83–110|mr=0120213|url=http://www.renyi.hu/~p_erdos/1960-02.pdf|doi=10.4064/aa-6-1-83-110}}.&lt;/ref&gt; the existence of a sequence {''a''&lt;sub&gt;0&lt;/sub&gt;,''a''&lt;sub&gt;1&lt;/sub&gt;,...} with the conjectural density but satisfying only the weaker property that there is a constant ''k'' such that for every natural number ''n'' there are at most ''k'' solutions of the equation ''a''&lt;sub&gt;''i''&lt;/sub&gt; + ''a''&lt;sub&gt;''j''&lt;/sub&gt; = ''n''.  (To be a Sidon sequence would require that ''k'' = 1.)

Erdős further conjectured that there exists a nonconstant [[integer]]-[[coefficient]] [[polynomial]] whose values at the [[natural numbers]] form a Sidon sequence.  Specifically, he asked if the set of fifth powers is a Sidon set. Ruzsa came close to this by showing that there is a real number ''c'' with 0 &lt; ''c'' &lt; 1 such that the range of the function 
''f''(''x'') = ''x''&lt;sup&gt;5&lt;/sup&gt; + [''cx''&lt;sup&gt;4&lt;/sup&gt;] is a Sidon sequence, where [.] denotes [[integer part]]. As ''c'' is irrational, this function ''f''(''x'') is not a polynomial.  The statement that the set of fifth powers is a Sidon set is a special case of the later conjecture of [[Euler's sum of powers conjecture#Generalizations|Lander, Parkin and Selfridge]].

==Relationship to Golomb rulers==
All finite Sidon sets are [[Golomb ruler]]s, and vice versa.

To see this, suppose for a [[proof by contradiction|contradiction]] that ''S'' is a Sidon set and not a Golomb ruler. Since it is not a Golomb ruler, there must be four members such that &lt;math&gt;a_i-a_j=a_k-a_l&lt;/math&gt;. It follows that &lt;math&gt;a_i+a_l=a_k+a_j&lt;/math&gt;, which contradicts the proposition that ''S'' is a Sidon set. Therefore all Sidon sets must be Golomb rulers. By a similar argument, all Golomb rulers must be Sidon sets.

==See also==
*[[Moser–de Bruijn sequence]]
*[[Sumset]]

==References==
{{reflist|30em}}
* {{cite book |last=Guy |first=Richard K. |authorlink=Richard K. Guy |title=Unsolved problems in number theory |publisher=[[Springer-Verlag]] |edition=3rd |year=2004 |isbn=0-387-20860-7 |at=C9 |zbl=1058.11001}}

{{DEFAULTSORT:Sidon Sequence}}
[[Category:Number theory]]
[[Category:Combinatorics]]</text>
      <sha1>1420sf16x9vyh42221yi80l5iheg0r4</sha1>
    </revision>
  </page>
  <page>
    <title>Swung note</title>
    <ns>0</ns>
    <id>561459</id>
    <redirect title="Swing (jazz performance style)" />
    <revision>
      <id>619402466</id>
      <parentid>606420399</parentid>
      <timestamp>2014-08-01T09:44:40Z</timestamp>
      <contributor>
        <username>Hyacinth</username>
        <id>17171</id>
      </contributor>
      <comment>[[Category:Note values]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="523">#REDIRECT [[Swing_(jazz_performance_style)#Swing_note]]


{{DEFAULTSORT:Swung Note}}
[[Category:Note values]]
[[Category:Mathematics of music]]
[[Category:Swing music]]
[[Category:Jazz techniques]]
[[Category:Drum patterns]]


[[de:Swing (Rhythmus)]]
[[es:Shuffle]]
[[fa:سوینگ]]
[[fr:Shuffle (musique)]]
[[it:Swing (musica)]]
[[he:שמיניות סווינג]]
[[ja:シャッフル (音楽)]]
[[ru:Свинг (музыкальный термин)]]
[[uk:Свінг (музичний термін)]]
[[zh:摇摆音符]]</text>
      <sha1>b98tgtbnlxhen0tnxq73ggzpt8xu097</sha1>
    </revision>
  </page>
  <page>
    <title>Theory of pure equality</title>
    <ns>0</ns>
    <id>26413136</id>
    <revision>
      <id>596388457</id>
      <parentid>538619859</parentid>
      <timestamp>2014-02-20T20:31:17Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <minor/>
      <comment>Fixing [[Wikipedia:Disambiguation pages with links|links to disambiguation pages]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1001">In [[mathematical logic]] the '''theory of pure equality''' is a [[first-order logic|first-order theory]]. It has a [[signature (mathematical logic)|signature]] consisting of only the equality relation symbol, and includes no non-logical axioms at all (Monk 1976:240&amp;ndash;242). This theory is consistent, as any set with the usual equality relation provides an interpretation.

The theory of pure equality was proven to be [[Decidability (logic)|decidable]] by Löwenheim in 1915. If an additional axiom is added saying either that there are exactly ''m'' objects, for a fixed natural number ''m'', or an axiom scheme is added stating there are infinitely many objects, the resulting theory is [[complete theory|complete]].

== References ==
* {{Citation | last1=Monk | first1=J. Donald | title=Mathematical Logic | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Graduate Texts in Mathematics | isbn=978-0-387-90170-1 | year=1976}}

[[Category:Formal theories]]
{{mathlogic-stub}}</text>
      <sha1>a8h4l3mz5kdrh9df45f3h2pxfmwoprh</sha1>
    </revision>
  </page>
  <page>
    <title>Tukey median</title>
    <ns>0</ns>
    <id>17542585</id>
    <redirect title="Centerpoint (geometry)" />
    <revision>
      <id>213947209</id>
      <timestamp>2008-05-21T13:55:59Z</timestamp>
      <contributor>
        <username>Melcombe</username>
        <id>4682566</id>
      </contributor>
      <minor/>
      <comment>create as redirect to [[Centerpoint (geometry)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="56">#REDIRECT [[Centerpoint (geometry)]]

[[Category:Means]]</text>
      <sha1>5c48xf1s8kzgehd9ui2re5ksxkgnx0g</sha1>
    </revision>
  </page>
  <page>
    <title>U-rank</title>
    <ns>0</ns>
    <id>35758279</id>
    <revision>
      <id>743139250</id>
      <parentid>587856444</parentid>
      <timestamp>2016-10-08T02:22:16Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>/* References */  cat cleanup</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3622">In [[model theory]], a branch of mathematical logic, '''U-rank''' is one measure of the complexity of a (complete) type, in the context of [[stable theory|stable theories]].  As usual, higher U-rank indicates less restriction, and the existence of a U-rank for all types over all sets is equivalent to an important model-theoretic condition: in this case, [[Stable theory#Superstable theories|superstability]].

== Definition ==
U-rank is defined inductively, as follows, for any (complete) n-type p over any set A:

* ''U''(''p'') ≥ 0
* If ''δ'' is a limit ordinal, then ''U''(''p'')&amp;nbsp;≥&amp;nbsp;''δ'' precisely when ''U''(''p'')&amp;nbsp;≥&amp;nbsp;''α'' for all ''α'' less than ''δ''
* For any ''α''&amp;nbsp;=&amp;nbsp;''β''&amp;nbsp;+&amp;nbsp;1, ''U''(''p'')&amp;nbsp;≥&amp;nbsp;''α'' precisely when there is a forking extension ''q'' of ''p'' with ''U''(''q'')&amp;nbsp;≥&amp;nbsp;''β''

We say that ''U''(''p'')&amp;nbsp;=&amp;nbsp;''α'' when the ''U''(''p'')&amp;nbsp;≥&amp;nbsp;''α'' but not ''U''(''p'')&amp;nbsp;≥&amp;nbsp;''α''&amp;nbsp;+&amp;nbsp;1.

If ''U''(''p'')&amp;nbsp;≥&amp;nbsp;''α'' for all ordinals ''α'', we say the U-rank is unbounded, or ''U''(''p'')&amp;nbsp;=&amp;nbsp;∞.

Note: U-rank is formally denoted &lt;math&gt;U_n(p)&lt;/math&gt;, where p is really p(x), and x is a tuple of variables of length n.  This subscript is typically omitted when no confusion can result.

== Ranking theories ==

U-rank is '''[[Monotonic function#Monotonicity in order theory|monotone]]''' in its domain.  That is, suppose ''p'' is a complete type over ''A'' and ''B'' is a subset of&amp;nbsp;''A''.  Then for ''q'' the restriction of ''p'' to ''B'', ''U''(''q'')&amp;nbsp;≥&amp;nbsp;''U''(''p'').

If we take ''B'' (above) to be empty, then we get the following: if there is an ''n''-type ''p'', over some set of parameters, with rank at least ''α'', then there is a type over the empty set of rank at least&amp;nbsp;''α''.  Thus, we can define, for a complete (stable) theory ''T'', &lt;math&gt;U_n(T)=\sup \{ U_n(p) : p\in S(T) \}&lt;/math&gt;.

We then get a concise characterization of superstability; a stable theory ''T'' is superstable if and only if &lt;math&gt;U_n(T)&lt;\infty&lt;/math&gt; for every&amp;nbsp;''n''.

== Properties ==

* As noted above, U-rank is monotone in its domain.
* If ''p'' has U-rank ''α'', then for any ''β''&amp;nbsp;&lt;&amp;nbsp;''α'', there is a forking extension ''q'' of ''p'' with U-rank&amp;nbsp;''β''.
* If ''p'' is the type of ''b'' over ''A'', there is some set ''B'' extending ''A'', with ''q'' the type of ''b'' over ''B''.
* If ''p'' is unranked (that is, ''p'' has U-rank ∞), then there is a forking extension ''q'' of ''p'' which is also unranked.
* Even in the absence of superstability, there is an ordinal ''β'' which is the maximum rank of all ranked types, and for any ''α''&amp;nbsp;&lt;&amp;nbsp;''β'', there is a type ''p'' of rank ''α'', and if the rank of ''p'' is greater than ''β'', then it must be&amp;nbsp;∞.

== Examples ==

* ''U''(''p'')&amp;nbsp;&gt;&amp;nbsp;0 precisely when ''p'' is nonalgebraic.
* If ''T'' is the theory of [[algebraically closed field]]s (of any fixed characteristic) then &lt;math&gt;U_1(T)=1&lt;/math&gt;.  Further, if ''A'' is any set of parameters and ''K'' is the field generated by ''A'', then a 1-type ''p'' over ''A'' has rank 1 if (all realizations of) ''p'' are transcendental over ''K'', and 0 otherwise.  More generally, an ''n''-type ''p'' over ''A'' has U-rank ''k'', the transcendence degree (over ''K'') of any realization of it.

== References ==

{{cite book |last1=Pillay |first1=Anand |title=An Introduction to Stability Theory |year=2008 |origyear=1983 |publisher=Dover |isbn=978-0-486-46896-9 |page=57}}

{{reflist}}

[[Category:Model theory]]</text>
      <sha1>mltob3hy3mtuyjwiqwltg6em29mrd3y</sha1>
    </revision>
  </page>
  <page>
    <title>UCL Faculty of Mathematical and Physical Sciences</title>
    <ns>0</ns>
    <id>28832206</id>
    <revision>
      <id>865074986</id>
      <parentid>864377317</parentid>
      <timestamp>2018-10-21T15:29:23Z</timestamp>
      <contributor>
        <ip>85.147.164.76</ip>
      </contributor>
      <comment>Chalkdust is - See website http://chalkdustmagazine.com/ latest issue 18 oktober 2018</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9226">{{Infobox University
|name           = UCL Faculty of Mathematical and Physical Sciences
|image_name     =
|image_size     = 270px × 120px
|established    = 
|dean           = Professor [[Ivan Parkin]]&lt;ref name=annualrev&gt;{{cite web|url=https://www.ucl.ac.uk/mathematical-physical-sciences/about-faculty/about-dean-and-vice-deans|title=UCL Review 2009|accessdate=14 September 2010|publisher=University College London}}&lt;/ref&gt;
|city           = [[London]], [[United Kingdom]]
|students       = 1,833&lt;ref name=annualrev/&gt;&lt;br /&gt;&lt;small&gt;([[Undergraduate education|Undergraduate]] (2008/09))&lt;/small&gt;&lt;br /&gt;544&lt;ref name=annualrev/&gt;&lt;br /&gt;&lt;small&gt;([[Postgraduate education|Graduate]] (2008/09))&lt;/small&gt;
|undergraduate  = 
|graduate       = 
|staff          = 445&lt;ref name=annualrev/&gt;&lt;br /&gt;&lt;small&gt;(Academic and research staff (as at October 2009))&lt;/small&gt;
|building       = 
|website        = [http://www.ucl.ac.uk/maps-faculty/ UCL Faculty of Mathematical and Physical Sciences] 
|logo           = 
}}

The '''UCL Faculty of Mathematical and Physical Sciences''' is one of the [[University College London#Faculties and departments|11 constituent faculties]] of [[University College London]] (UCL).&lt;ref&gt;{{cite web|url=http://www.ucl.ac.uk/academic-services/academic-units/|title=The Academic Units of UCL|accessdate=14 September 2010|publisher=University College London}}&lt;/ref&gt; The Faculty, the [[UCL Faculty of Engineering Sciences]] and the [[The Bartlett|UCL Faculty of the Built Envirornment (The Bartlett)]] together form the UCL School of the Built Environment, Engineering and Mathematical and Physical Sciences.

==Departments==
The Faculty currently comprises the following departments:&lt;ref&gt;{{cite web|url=http://www.ucl.ac.uk/departments/academic-departments/|title=Academic Departments by Faculty|accessdate=14 September 2010|publisher=University College London}}&lt;/ref&gt;&lt;ref name=depsinscents&gt;{{cite web|url=http://www.ucl.ac.uk/maps-faculty/departments|title=Departments and Institutes|accessdate=15 September 2010|publisher=UCL Faculty of Mathematical and Physical Sciences}}&lt;/ref&gt;

*UCL Department of Chemistry
*UCL Department of Earth Sciences
*UCL Department of Mathematics
**''Chalkdust'' is an online mathematics interest magazine published by Department of Mathematics students starting in 2015&lt;ref&gt;{{Cite web|title = Stretching mathematical minds|url = http://brianclegg.blogspot.co.uk/2015/03/stretching-mathematical-minds.html|website = Brian Clegg - Science author|accessdate = 2015-07-03|department = Now Appearing|date = 26 March 2015|last = Clegg|first = Brian|authorlink = Brian Clegg (writer)|type = blog}}&lt;/ref&gt;
*UCL Department of Natural Sciences
*UCL Department of Physics &amp; Astronomy
*[[UCL Department of Science and Technology Studies]]
*[[Mullard Space Science Laboratory|UCL Department of Space &amp; Climate Physics (Mullard Space Science Laboratory)]]
*UCL Department of Statistical Science
*[[London Centre for Nanotechnology]] - a joint venture between UCL and [[Imperial College London]] established in 2003 following the award of a £13.65m higher education grant under the Science Research Infrastructure Fund.&lt;ref&gt;{{cite news|url=http://news.bbc.co.uk/1/hi/sci/tech/2698649.stm | title=London's little idea|accessdate=5 March 2014|publisher=BBC News| date=27 January 2003}}&lt;/ref&gt;&lt;ref&gt;{{cite news|url=http://news.bbc.co.uk/1/hi/technology/2981480.stm | title=Nanotech under the microscope|accessdate=5 March 2014| publisher=BBC News| date=12 June 2003}}&lt;/ref&gt;

==Research centres and institutes==
[[Image:UCL Portico Building.jpg|250px|right|thumb|[[University College London]]]]

The Faculty is closely involved with the following research centres and institutes:&lt;ref name=depsinscents/&gt;

*UCL Centre for Materials Research
*UCL Centre for Mathematics and Physics in the Life Sciences and Experimental Biology (CoMPLEX) - an [[inter-disciplinary]] virtual centre that seeks to bring together [[mathematics|mathematicians]], [[physics|physical scientists]], [[computer science|computer scientists]] and [[engineering|engineers]] upon the problems posed by [[complexity]] in [[biology]] and [[biomedicine]]. The centre works with 29 departments and Institutes across UCL. It has a MRes/PhD program that requires that its students also belong to at least one of these Departments/Institutes. The centre is based in the Physics Building on the UCL main campus.
*Centre for Planetary Science at UCL/Birkbeck
*UCL Institute of Origins
*UCL Institute for Risk and Disaster Reduction
*The [[Thomas Young Centre]]

==Rankings==
In the 2013 ''[[Academic Ranking of World Universities]]'', UCL is ranked joint 51st to 75th in the world (and joint 12th in Europe) for Natural Sciences and Mathematics.&lt;ref&gt;{{cite web|url=http://www.shanghairanking.com/FieldSCI2013.html|title=Academic Ranking of World Universities in Natural Sciences and Mathematics – 2013|accessdate=2 September 2013|publisher=Shanghai Ranking Consultancy}}&lt;/ref&gt;

In the 2013 ''[[QS World University Rankings]]'', UCL is ranked 38th in the world (and 12th in Europe) for Natural Sciences.&lt;ref&gt;{{cite web|url=http://www.topuniversities.com/university-rankings/faculty-rankings/natural-sciences/2013|title=QS World University Rankings by Faculty 2013 – Natural Science|accessdate=23 September 2013|publisher=QS Quacquarelli Symonds Limited}}&lt;/ref&gt; In the 2014 ''QS World University Rankings by Subject'', UCL is ranked joint 51st-100th in the world (and joint 12th in Europe) for Chemistry,&lt;ref&gt;{{cite web|url=http://www.topuniversities.com/university-rankings/university-subject-rankings/2014/chemistry#sorting=rank+region=+country=+faculty=+stars=false+search=|title=QS World University Rankings by Subject 2014 - Chemistry|accessdate=1 March 2014|publisher=QS Quacquarelli Symonds Limited}}&lt;/ref&gt; joint 27th in the world (and 8th in Europe) for Earth &amp; Marine Sciences,&lt;ref&gt;{{cite web|url=http://www.topuniversities.com/university-rankings/university-subject-rankings/2014/earth-marine-sciences#sorting=rank+region=+country=+faculty=+stars=false+search=|title=QS World University Rankings by Subject 2014 - Earth &amp; Marine Sciences|accessdate=1 March 2014|publisher=QS Quacquarelli Symonds Limited}}&lt;/ref&gt; joint 51st-100th in the world (and joint 13th in Europe) for Materials Science,&lt;ref&gt;{{cite web|url=http://www.topuniversities.com/university-rankings/university-subject-rankings/2014/materials-sciences#sorting=rank+region=+country=+faculty=+stars=false+search=|title=QS World University Rankings by Subject 2014 - Materials Science|accessdate=1 March 2014|publisher=QS Quacquarelli Symonds Limited}}&lt;/ref&gt; joint 36th in the world (and joint 10th in Europe) for Mathematics,&lt;ref&gt;{{cite web|url=http://www.topuniversities.com/university-rankings/university-subject-rankings/2014/mathematics#sorting=rank+region=+country=+faculty=+stars=false+search=|title=QS World University Rankings by Subject 2014 - Mathematics|accessdate=1 March 2014|publisher=QS Quacquarelli Symonds Limited}}&lt;/ref&gt; 35th in the world (and 13th in Europe) for Physics &amp; Astronomy,&lt;ref&gt;{{cite web|url=http://www.topuniversities.com/university-rankings/university-subject-rankings/2014/physics#sorting=rank+region=+country=+faculty=+stars=false+search=|title=QS World University Rankings by Subject 2014 - Physics &amp; Astronomy|accessdate=1 March 2014|publisher=QS Quacquarelli Symonds Limited}}&lt;/ref&gt; and 47th in the world (and 9th in Europe) for Statistics &amp; Operational Research.&lt;ref&gt;{{cite web|url=http://www.topuniversities.com/university-rankings/university-subject-rankings/2014/statistics-operational-research#sorting=rank+region=+country=+faculty=+stars=false+search=|title=QS World University Rankings by Subject 2014 - Politics and International Studies|accessdate=1 March 2014|publisher=QS Quacquarelli Symonds Limited}}&lt;/ref&gt;

In the 2013/14 ''[[Times Higher Education World University Rankings]]'', UCL is ranked 51st in the world (and 16th in Europe) for Physical Sciences.&lt;ref&gt;{{cite web|url=http://www.timeshighereducation.co.uk/world-university-rankings/2013-14/subject-ranking/subject/physical-sciences|title=Top 100 universities for Physical Sciences 2013–14|accessdate=6 October 2013|work=Times Higher Education}}&lt;/ref&gt;

==Notable people==
* [[Michael Abraham (chemist)|Michael Abraham]]
* [[William Ramsay]]
* [[Steven T. Bramwell]]
* [[M. J. Seaton]]
* [[Sigurd Zienau]]
* [[Andrew Fisher (physicist)|Andrew Fisher]]
* [[Paul Davies]]
* [[Edwin Power]]
* [[Peter Higgs]]
* [[Otto Hahn]]
* [[Charles K. Kao]]
* [[Andrea Sella]]
*[[Raman Prinja]]

==See also==
*[[Birkbeck, University of London]]
*[[Imperial College London]]

==References==
{{reflist}}

==External links==
*[http://www.ucl.ac.uk/maps-faculty/ UCL Faculty of Mathematical and Physical Sciences]
*[http://www.ucl.ac.uk/beams/ UCL School of the Built Environment, Engineering and Mathematical and Physical Sciences] 
*[http://www.ucl.ac.uk University College London]
*[http://www.ucl.ac.uk/complex/ CoMPLEX homepage]

{{University College London|academics}}

[[Category:Departments of University College London]]
[[Category:Research institutes in London]]
[[Category:Complex systems theory]]
[[Category:Mathematical institutes]]
[[Category:Multidisciplinary research institutes]]</text>
      <sha1>chb87tros2z6m7ozijljuz6q7qa2x1i</sha1>
    </revision>
  </page>
  <page>
    <title>Unit vector</title>
    <ns>0</ns>
    <id>167053</id>
    <revision>
      <id>863629034</id>
      <parentid>859428081</parentid>
      <timestamp>2018-10-12T00:19:57Z</timestamp>
      <contributor>
        <ip>205.175.119.181</ip>
      </contributor>
      <comment>/* Right versor */ corrected Euler's formula</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17404">In [[mathematics]], a '''unit vector''' in a [[normed vector space]] is a [[Vector space|vector]] (often a [[vector (geometry)|spatial vector]]) of [[Norm (mathematics)|length]] 1. A unit vector is often denoted by a lowercase letter with a [[circumflex]], or "hat": &lt;math alt= i-hat&gt;{\hat{\imath}}&lt;/math&gt; (pronounced "i-hat").   The term [[direction vector]] is used to describe a unit vector being used to represent spatial direction, and such quantities are commonly denoted as '''d'''.  Two 2D direction vectors, '''d1''' and '''d2''' are illustrated.   2D spatial directions represented this way are numerically equivalent to points on the [[unit circle]].

The same construct is used to specify spatial directions in 3D.  As illustrated, each unique direction is equivalent numerically to a point on the [[unit sphere]].

[[File:2D Direction Vectors.svg|thumb|Examples of two 2D direction vectors]]
[[File:3D Direction Vectors.tiff|thumb|Examples of two 3D direction vectors]]
The normalized vector or versor '''û''' of a non-zero vector '''u''' is the unit vector in the direction of '''u''', i.e.,

:&lt;math alt= "u-hat equals the vector u divided by its length"&gt;\mathbf{\hat{u}} = \frac{\mathbf{u}}{|\mathbf{u}|}&lt;/math&gt;
where |'''u'''| is the [[Norm (mathematics)|norm]] (or length) of '''u'''.  The term ''normalized vector'' is sometimes used as a synonym for ''unit vector''.

Unit vectors are often chosen to form the [[basis (linear algebra)|basis]] of a vector space. Every vector in the space may be written as a [[linear combination]] of unit vectors.

By definition, in a [[Euclidean space]] the [[dot product]] of two unit vectors is a scalar value amounting to the [[cosine]] of the smaller subtended angle. In three-dimensional Euclidean space, the [[cross product]] of two arbitrary unit vectors is a third vector orthogonal to both of them having length equal to the sine of the smaller subtended angle. The normalized cross product corrects for this varying length, and yields the mutually orthogonal unit vector to the two inputs, applying the [[right-hand rule]] to resolve one of two possible directions.

==Orthogonal coordinates==

===Cartesian coordinates===
{{Main|Standard basis|Versor (physics)}}

Unit vectors may be used to represent the axes of a [[Cartesian coordinate system]]. For instance, the unit vectors in the direction of the ''x'', ''y'', and ''z'' axes of a three dimensional Cartesian coordinate system are

:&lt;math alt= "i-hat equals the 3 by 1 matrix 1,0,0; j-hat equals the 3 by 1 matrix 0,1,0; k-hat equals the 3 by 1 matrix 0,0,1"&gt;\mathbf{\hat{i}} = \begin{bmatrix}1\\0\\0\end{bmatrix}, \,\, \mathbf{\hat{j}} = \begin{bmatrix}0\\1\\0\end{bmatrix}, \,\,  \mathbf{\hat{k}} = \begin{bmatrix}0\\0\\1\end{bmatrix}&lt;/math&gt;

They are sometimes referred to as the [[Versor (physics)|versors]] of the coordinate system, and they form a set of mutually [[orthogonal]] unit vectors, typically referred to as a [[standard basis]] in [[linear algebra]].

They are often denoted using normal vector notation (e.g., '''''i''''' or &lt;math alt= "vector i"&gt;\vec{\imath}&lt;/math&gt;) rather than standard unit vector notation (e.g., &lt;math alt= "unit vector i"&gt;\mathbf{\hat{\imath}}&lt;/math&gt;). In most contexts it can be assumed that '''i''', '''j''', and '''k''', (or &lt;math alt="vector i"&gt;\vec{\imath},&lt;/math&gt; &lt;math alt= "vector j"&gt;\vec{\jmath},&lt;/math&gt; and &lt;math alt= "vector k"&gt; \vec{k}&lt;/math&gt;) are versors of a 3-D Cartesian coordinate system. The notations &lt;math alt="x-hat, y-hat, z-hat"&gt;(\mathbf{\hat{x}}, \mathbf{\hat{y}}, \mathbf{\hat{z}})&lt;/math&gt;, &lt;math alt="x-hat sub 1, x-hat sub 2, x-hat sub 3"&gt;(\mathbf{\hat{x}}_1, \mathbf{\hat{x}}_2, \mathbf{\hat{x}}_3)&lt;/math&gt;, &lt;math alt="e-hat sub x, e-hat sub y, e-hat sub z"&gt;(\mathbf{\hat{e}}_x, \mathbf{\hat{e}}_y, \mathbf{\hat{e}}_z)&lt;/math&gt;, or &lt;math alt= "e-hat sub 1, e-hat sub 2, e-hat sub 3"&gt;(\mathbf{\hat{e}}_1, \mathbf{\hat{e}}_2, \mathbf{\hat{e}}_3)&lt;/math&gt;, with or without [[Circumflex#Mathematics|hat]], are also used, particularly in contexts where '''i''', '''j''', '''k''' might lead to confusion with another quantity (for instance with [[Indexed family|index]] symbols such as ''i'', ''j'', ''k'', used to identify an element of a set or array or sequence of variables).

When a unit vector in space is expressed, with [[Cartesian coordinate system#Representing a vector with Cartesian notation|Cartesian notation]], as a linear combination of '''i''', '''j''', '''k''', its three scalar components can be referred to as [[direction cosines]]. The value of each component is equal to the cosine of the angle formed by the unit vector with the respective basis vector. This is one of the methods used to describe the [[Orientation (mathematics)|orientation]] (angular position) of a straight line, segment of straight line, oriented axis, or segment of oriented axis ([[vector (geometry)|vector]]).

===Cylindrical coordinates===

The three [[orthogonal]] unit vectors appropriate to cylindrical symmetry are: 
* &lt;math alt="rho-hat"&gt;\mathbf{\hat{\rho}}&lt;/math&gt; (also designated &lt;math alt="r-hat"&gt;\mathbf{\hat{e}}&lt;/math&gt; or &lt;math alt="s-hat"&gt;\boldsymbol{\hat s}&lt;/math&gt;), representing the direction along which the distance of the point from the axis of symmetry is measured; 
* &lt;math alt="phi-hat"&gt;\boldsymbol{\hat \varphi}&lt;/math&gt;, representing the direction of the motion that would be observed if the point were rotating counterclockwise about the symmetry axis;
* &lt;math alt="z-hat"&gt;\mathbf{\hat{z}}&lt;/math&gt;, representing the direction of the symmetry axis; 
They are related to the Cartesian basis &lt;math alt="x-hat"&gt;\hat{x}&lt;/math&gt;, &lt;math alt="y-hat"&gt;\hat{y}&lt;/math&gt;, &lt;math alt="z-hat"&gt;\hat{z}&lt;/math&gt; by:

:&lt;math alt="rho-hat"&gt;\mathbf{\hat{\rho}}&lt;/math&gt; = &lt;math alt="cosine of phi in the x-hat direction plus sine of phi in the y-hat direction"&gt;\cos \varphi\mathbf{\hat{x}} + \sin \varphi\mathbf{\hat{y}}&lt;/math&gt;

:&lt;math alt="phi-hat"&gt;\boldsymbol{\hat \varphi}&lt;/math&gt; = &lt;math alt="minus the sine of phi in the x-hat direction plus the cosine of phi in the y-hat direction"&gt;-\sin \varphi\mathbf{\hat{x}} + \cos \varphi\mathbf{\hat{y}}&lt;/math&gt;

:&lt;math alt="z-hat equals z-hat"&gt;\mathbf{\hat{z}}=\mathbf{\hat{z}}.&lt;/math&gt;

It is important to note that &lt;math alt="rho-hat"&gt;\mathbf{\hat{\rho}}&lt;/math&gt; and &lt;math alt="phi-hat"&gt;\boldsymbol{\hat \varphi}&lt;/math&gt; are functions of &lt;math alt="coordinate phi"&gt;\varphi&lt;/math&gt;, and are ''not'' constant in direction. When differentiating or integrating in cylindrical coordinates, these unit vectors themselves must also be operated on. For a more complete description, see [[Jacobian matrix]]. The derivatives with respect to &lt;math&gt;\varphi&lt;/math&gt; are:

:&lt;math alt="partial derivative of rho-hat with respect to phi equals minus sine of phi in the x-hat direction plus cosine of phi in the y-hat direction equals phi-hat"&gt;\frac{\partial \mathbf{\hat{\rho}}} {\partial \varphi} = -\sin \varphi\mathbf{\hat{x}} + \cos \varphi\mathbf{\hat{y}} = \boldsymbol{\hat \varphi}&lt;/math&gt;

:&lt;math alt="partial derivative of phi-hat with respect to phi equals minus cosine of phi in the x-hat direction minus sine of phi in the y-hat direction equals minus rho-hat"&gt;\frac{\partial \boldsymbol{\hat \varphi}} {\partial \varphi} = -\cos \varphi\mathbf{\hat{x}} - \sin \varphi\mathbf{\hat{y}} = -\mathbf{\hat{\rho}}&lt;/math&gt;

:&lt;math alt="partial derivative of z-hat with respect to phi equals zero"&gt;\frac{\partial \mathbf{\hat{z}}} {\partial \varphi} = \mathbf{0}.&lt;/math&gt;

===Spherical coordinates===

The unit vectors appropriate to spherical symmetry are: &lt;math alt="r-hat"&gt;\mathbf{\hat{r}}&lt;/math&gt;, the direction in which the radial distance from the origin increases; &lt;math alt="phi-hat"&gt;\boldsymbol{\hat{\varphi}}&lt;/math&gt;, the direction in which the angle in the ''x''-''y'' plane counterclockwise from the positive ''x''-axis is increasing; and &lt;math alt="theta-hat"&gt;\boldsymbol{\hat \theta}&lt;/math&gt;, the direction in which the angle from the positive ''z'' axis is increasing. To minimize redundancy of representations, the polar angle &lt;math alt="theta"&gt;\theta&lt;/math&gt; is usually taken to lie between zero and 180 degrees. It is especially important to note the context of any ordered triplet written in [[spherical coordinates]], as the roles of &lt;math alt="phi-hat"&gt;\boldsymbol{\hat \varphi}&lt;/math&gt; and &lt;math alt="theta-hat"&gt;\boldsymbol{\hat \theta}&lt;/math&gt; are often reversed. Here, the American "physics" convention&lt;ref&gt;Tevian Dray and Corinne A. Manogue,Spherical Coordinates, College Math Journal 34, 168-169 (2003).&lt;/ref&gt; is used. This leaves the azimuthal angle &lt;math alt="phi"&gt;\varphi&lt;/math&gt; defined the same as in cylindrical coordinates. The [[Cartesian coordinate system|Cartesian]] relations are:

:&lt;math alt="r-hat equals sin of theta times cosine of phi in the x-hat direction plus sine of theta times sine of phi in the y-hat direction plus cosine of theta in the z-hat direction"&gt;\mathbf{\hat{r}} = \sin \theta \cos \varphi\mathbf{\hat{x}}  + \sin \theta \sin \varphi\mathbf{\hat{y}} + \cos \theta\mathbf{\hat{z}}&lt;/math&gt;

:&lt;math alt="theta-hat equals cosine of theta times cosine of phi in the x-hat direction plus cosine of theta times sine of phi in the y-hat direction minus sine of theta in the z-hat direction"&gt;\boldsymbol{\hat \theta} = \cos \theta \cos \varphi\mathbf{\hat{x}} + \cos \theta \sin \varphi\mathbf{\hat{y}} - \sin \theta\mathbf{\hat{z}}&lt;/math&gt;

:&lt;math alt="phi-hat equals minus sine of phi in the x-hat direction plus cosine of phi in the y-hat direction"&gt;\boldsymbol{\hat \varphi} = - \sin \varphi\mathbf{\hat{x}} + \cos \varphi\mathbf{\hat{y}}&lt;/math&gt;

The spherical unit vectors depend on both &lt;math alt="phi"&gt;\varphi&lt;/math&gt; and &lt;math alt="theta"&gt;\theta&lt;/math&gt;, and hence there are 5 possible non-zero derivatives. For a more complete description, see [[Jacobian matrix and determinant]]. The non-zero derivatives are:

:&lt;math alt="partial derivative of r-hat with respect to phi equals minus sine of theta times sine of phi in the x-hat direction plus sine of theta times cosine of phi in the y-hat direction equals sine of theta in the phi-hat direction"&gt;\frac{\partial \mathbf{\hat{r}}} {\partial \varphi} = -\sin \theta \sin \varphi\mathbf{\hat{x}} + \sin \theta \cos \varphi\mathbf{\hat{y}} = \sin \theta\boldsymbol{\hat \varphi}&lt;/math&gt;

:&lt;math alt="partial derivative of r-hat with respect to theta equals cosine of theta times cosine of phi in the x-hat direction plus cosine of theta times sine of phi in the y-hat direction minus sine of theta in the z-hat direction equals theta-hat"&gt;\frac{\partial \mathbf{\hat{r}}} {\partial \theta} =\cos \theta \cos \varphi\mathbf{\hat{x}} + \cos \theta \sin \varphi\mathbf{\hat{y}} - \sin \theta\mathbf{\hat{z}}= \boldsymbol{\hat \theta}&lt;/math&gt;

:&lt;math alt="partial derivative of theta-hat with respect to phi equals minus cosine of theta times sine of phi in the x-hat direction plus cosine of theta times cosine of phi in the y-hat direction equals cosine of theta in the phi-hat direction"&gt;\frac{\partial \boldsymbol{\hat{\theta}}} {\partial \varphi} =-\cos \theta \sin \varphi\mathbf{\hat{x}} + \cos \theta \cos \varphi\mathbf{\hat{y}} = \cos \theta\boldsymbol{\hat \varphi}&lt;/math&gt;

:&lt;math alt="partial derivative of theta-hat with respect to theta equals minus sine of theta times cosine of phi in the x-hat direction minus sine of theta times sine of phi in the y-hat direction minus cosine of theta in the z-hat direction equals minus r-hat"&gt;\frac{\partial \boldsymbol{\hat{\theta}}} {\partial \theta} = -\sin \theta \cos \varphi\mathbf{\hat{x}} - \sin \theta \sin \varphi\mathbf{\hat{y}} - \cos \theta\mathbf{\hat{z}} = -\mathbf{\hat{r}}&lt;/math&gt;

:&lt;math alt="partial derivative of phi-hat with respect to phi equals minus cosine of phi in the x-hat direction minus sine of phi in the y-hat direction equals minus sine of theta in the r-hat direction minus cosine of theta in the theta-hat direction"&gt;\frac{\partial \boldsymbol{\hat{\varphi}}} {\partial \varphi} = -\cos \varphi\mathbf{\hat{x}} - \sin \varphi\mathbf{\hat{y}} = -\sin \theta\mathbf{\hat{r}} -\cos \theta\boldsymbol{\hat{\theta}}&lt;/math&gt;

===General unit vectors===

{{main|Orthogonal coordinates}}

Common general themes of unit vectors occur throughout [[physics]] and [[geometry]]:&lt;ref&gt;{{cite book|title=Calculus (Schaum's Outlines Series)|edition=5th|publisher=Mc Graw Hill|author1=F. Ayres |author2=E. Mandelson |year=2009|isbn=978-0-07-150861-2}}&lt;/ref&gt;

{| class="wikitable"
|-

! scope="col" width="200" | Unit vector
! scope="col" width="150" | Nomenclature
! scope="col" width="410" | Diagram
|-
| Tangent vector to a curve/flux line || &lt;math&gt; \mathbf{\hat{t}}&lt;/math&gt; || rowspan="3" | [[File:Tangent normal binormal unit vectors.svg|200px|"200px"]] [[File:Polar coord unit vectors and normal.svg|200px|"200px"]]
A normal vector &lt;math&gt; \mathbf{\hat{n}} &lt;/math&gt; to the plane containing and defined by the radial position vector &lt;math&gt; r \mathbf{\hat{r}} &lt;/math&gt; and angular tangential direction of rotation &lt;math&gt; \theta \boldsymbol{\hat{\theta}} &lt;/math&gt; is necessary so that the vector equations of angular motion hold.
|-
|Normal to a surface tangent plane/plane containing radial position component and angular tangential component
|| &lt;math&gt; \mathbf{\hat{n}}&lt;/math&gt;

In terms of [[spherical coordinate system|polar coordinates]];
&lt;math&gt; \mathbf{\hat{n}} = \mathbf{\hat{r}} \times \boldsymbol{\hat{\theta}} &lt;/math&gt;
|-
| Binormal vector to tangent and normal
|| &lt;math&gt; \mathbf{\hat{b}} = \mathbf{\hat{t}} \times \mathbf{\hat{n}} &lt;/math&gt;&lt;ref&gt;{{cite book|title=Vector Analysis (Schaum's Outlines Series)|edition=2nd|publisher=Mc Graw Hill|author1=M. R. Spiegel |author2=S. Lipschutz |author3=D. Spellman |year=2009|isbn=978-0-07-161545-7}}&lt;/ref&gt;
|-
| Parallel to some axis/line || &lt;math&gt; \mathbf{\hat{e}}_{\parallel} &lt;/math&gt; || rowspan="2" | [[File:Perpendicular and parallel unit vectors.svg|200px|"200px"]]
One unit vector &lt;math&gt; \mathbf{\hat{e}}_{\parallel}&lt;/math&gt; aligned parallel to a principal direction (red line), and a perpendicular unit vector &lt;math&gt; \mathbf{\hat{e}}_{\bot}&lt;/math&gt; is in any radial direction relative to the principal line.
|-
| Perpendicular to some axis/line in some radial direction
|| &lt;math&gt; \mathbf{\hat{e}}_{\bot} &lt;/math&gt;
|-
| Possible angular deviation relative to some axis/line
|| &lt;math&gt; \mathbf{\hat{e}}_{\angle} &lt;/math&gt;
|| [[File:Angular unit vector.svg|200px|"200px"]]
Unit vector at acute deviation angle ''φ'' (including 0 or ''π''/2 rad) relative to a principal direction.
|-
|}

==Curvilinear coordinates==
In general, a coordinate system may be uniquely specified using a number of [[Linear independence|linearly independent]] unit vectors &lt;math alt="e-hat sub n"&gt;\mathbf{\hat{e}}_n&lt;/math&gt; equal to the degrees of freedom of the space. For ordinary 3-space, these vectors may be denoted &lt;math alt="e-hat sub 1, e-hat sub 2, e-hat sub 3"&gt;\mathbf{\hat{e}}_1, \mathbf{\hat{e}}_2, \mathbf{\hat{e}}_3&lt;/math&gt;. It is nearly always convenient to define the system to be orthonormal and [[Right-hand rule|right-handed]]:

:&lt;math alt="e-hat sub i dot e-hat sub j equals Kronecker delta of i and j"&gt;\mathbf{\hat{e}}_i \cdot \mathbf{\hat{e}}_j = \delta_{ij} &lt;/math&gt;
:&lt;math alt="e-hat sub i dot e-hat sub j cross e-hat sub k = epsilon sub ijk"&gt;\mathbf{\hat{e}}_i \cdot (\mathbf{\hat{e}}_j \times \mathbf{\hat{e}}_k) = \varepsilon_{ijk} &lt;/math&gt;

where δ&lt;sub&gt;''ij''&lt;/sub&gt; is the [[Kronecker delta]] (which is 1 for ''i'' = ''j'' and 0 otherwise) and  &lt;math alt="epsilon sub i,j,k"&gt; \varepsilon_{ijk} &lt;/math&gt; is the [[Levi-Civita symbol]] (which is 1 for permutations ordered as ''ijk'' and −1 for permutations ordered as ''kji'').

==Right versor==
A unit vector in ℝ&lt;sup&gt;3&lt;/sup&gt; was called a '''right versor''' by [[W. R. Hamilton]] as he developed his [[quaternion]]s ℍ ⊂ ℝ&lt;sup&gt;4&lt;/sup&gt;. In fact, he was the originator of the term ''vector'' as every quaternion &lt;math&gt;q = s + v&lt;/math&gt; has a scalar part ''s'' and a vector part ''v''. If ''v'' is a unit vector in ℝ&lt;sup&gt;3&lt;/sup&gt;, then the square of ''v'' in quaternions is –1. By [[Euler's formula]] then, &lt;math&gt;\exp (\theta v) = \cos \theta + v \sin \theta&lt;/math&gt; is a [[versor]] in the [[3-sphere]]. When &amp;theta; is a [[right angle]], the versor is a right versor: its scalar part is zero and its vector part ''v'' is a unit vector in ℝ&lt;sup&gt;3&lt;/sup&gt;.

==See also==
{{wiktionary|unit vector}}
*[[Cartesian coordinate system]]
*[[Coordinate system]]
*[[Curvilinear coordinates]]
*[[Four-velocity]]
*[[Jacobian matrix and determinant]]
*[[Polar coordinate system]]
*[[Unit interval]]
* Unit [[unit square|square]], [[unit cube|cube]], [[unit circle|circle]], [[unit sphere|sphere]], and [[unit hyperbola|hyperbola]]
*[[Vector of ones]]

==Notes==
{{Reflist}}

==References==
*{{cite book|author1=G. B. Arfken  |author2=H. J. Weber |lastauthoramp=yes |title=Mathematical Methods for Physicists|edition=5th|year=2000|publisher=Academic Press|isbn=0-12-059825-6}}
*{{cite book|first=Murray R.|last=Spiegel|title=Schaum's Outlines: Mathematical Handbook of Formulas and Tables|edition=2nd|year=1998|publisher=McGraw-Hill|isbn=0-07-038203-4}}
*{{cite book|first=David J.|last=Griffiths|title=Introduction to Electrodynamics|edition=3rd|year=1998|publisher=Prentice Hall|isbn=0-13-805326-X}}

{{DEFAULTSORT:Unit Vector}}
[[Category:Linear algebra]]
[[Category:Elementary mathematics]]
[[Category:1 (number)]]
[[Category:Vectors (mathematics and physics)]]</text>
      <sha1>tkjzbgudv54vk4i2hc9f88yqzmkmfg9</sha1>
    </revision>
  </page>
</mediawiki>
