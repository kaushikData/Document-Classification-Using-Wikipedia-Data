<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>A-paracompact space</title>
    <ns>0</ns>
    <id>5075473</id>
    <revision>
      <id>695750360</id>
      <parentid>532052977</parentid>
      <timestamp>2015-12-18T08:49:49Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>/* References */[[WP:CHECKWIKI]] error fixes using [[Project:AWB|AWB]] (11757)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="747">{{lowercase}}
In [[mathematics]], in the field of [[topology]], a [[topological space]] is said to be '''a-paracompact''' if every [[open cover]] of the space has a [[Locally finite collection|locally finite]] [[refinement of an open cover|refinement]]. In contrast to the definition of [[paracompact space|paracompactness]], the refinement is not required to be open.

Every paracompact space is a-paracompact, and in [[regular space]]s the two notions coincide.

==References==
*{{cite book | author=Willard, Stephen | title=General Topology | publisher=Dover Publications | year=2004 | isbn=0-486-43479-6}}

[[Category:Compactness (mathematics)]]
[[Category:Properties of topological spaces]]
[[Category:Topological spaces]]


{{topology-stub}}</text>
      <sha1>eme1yw4bmb8f4feimofftchrp4wgusz</sha1>
    </revision>
  </page>
  <page>
    <title>ABC (stream cipher)</title>
    <ns>0</ns>
    <id>6339424</id>
    <revision>
      <id>644312432</id>
      <parentid>627260671</parentid>
      <timestamp>2015-01-26T21:56:19Z</timestamp>
      <contributor>
        <username>DissidentAggressor</username>
        <id>21438188</id>
      </contributor>
      <comment>+ref</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="797">{{onesource|date=April 2010}}
In [[cryptography]], '''ABC''' is a [[stream cipher|stream cypher]] [[algorithm]] developed by [[Vladimir Anashin]], [[Andrei Bogdanov (cryptographer)|Andrey Bogdanov]], [[Ilya Kizhvatov]], and [[Sandeep Kumar (cryptographer)|Sandeep Kumar]].&lt;ref name=ABCspec&gt;{{cite journal|last1=Anashin|first1=Vladimir|last2=Bogdanov|first2=Andrey|last3=Andrey|first3=Ilya|title=ABC: A New Fast Flexible Stream Cipher|journal=[[ECRYPT|European Network of Excellence in Cryptology II ]]|url=http://www.ecrypt.eu.org/stream/ciphers/abc/abc.pdf|accessdate=26 January 2015}}&lt;/ref&gt; It has been submitted to the [[eSTREAM]] Project of the [[eCRYPT]] network. 
==References==
{{reflist}}


{{Cryptography navbox | stream}}

{{DEFAULTSORT:Abc}}
[[Category:Stream ciphers]]

{{crypto-stub}}</text>
      <sha1>b2spa35jrdfzp92sfjfbkmypjftrsgp</sha1>
    </revision>
  </page>
  <page>
    <title>Angle of parallelism</title>
    <ns>0</ns>
    <id>1341579</id>
    <revision>
      <id>826252329</id>
      <parentid>815599405</parentid>
      <timestamp>2018-02-18T02:53:40Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <minor/>
      <comment>/* Demonstration */ lk Logarithmic measure</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7351">[[File:Limiting Parallels.jpg|thumb|If angle B is right and Aa and Bb are [[limiting parallel]] then the angle between ''Aa'' and ''AB'' is the angle of parallelism.]]

In [[hyperbolic geometry]], the '''angle of parallelism ''' &lt;math&gt; \Pi(a) &lt;/math&gt;, is the [[angle]] at one vertex of a right [[hyperbolic triangle]] that has two [[limiting parallel|asymptotic parallel]] sides. The angle depends on the segment length ''a'' between the right angle and the vertex of the angle of parallelism. 

Given a point off of a line, if we drop a perpendicular to the line from the point, then ''a'' is the distance along this perpendicular segment, and ''&amp;phi;'' or &lt;math&gt; \Pi(a) &lt;/math&gt; is the least angle such that the line drawn through the point at that angle does not intersect the given line. Since two sides are asymptotic parallel,

: &lt;math&gt; \lim_{a\to 0} \Pi(a) = \tfrac{1}{2}\pi\quad\text{ and }\quad\lim_{a\to\infty} \Pi(a) =  0.  &lt;/math&gt;

There are five equivalent expressions that relate '' &lt;math&gt; \Pi(a)&lt;/math&gt;'' and ''a'':

&lt;!-- extra blank line between two lines of "displayed" [[TeX]] for legibility --&gt;
: &lt;math&gt; \sin\Pi(a) = \operatorname{sech} a  = \frac{1}{\cosh a} =\frac{2}{e^a + e^{-a}} \ , &lt;/math&gt;

&lt;!-- extra blank line between two lines of "displayed" [[TeX]] for legibility --&gt;
: &lt;math&gt; \cos\Pi(a) = \tanh a = \frac {e^a - e^{-a}} {e^a + e^{-a}}  \ , &lt;/math&gt;

&lt;!-- extra blank line between two lines of "displayed" [[TeX]] for legibility --&gt;
: &lt;math&gt; \tan\Pi(a) = \operatorname{csch} a = \frac{1}{\sinh a} = \frac {2}{e^a - e^{-a}} \  , &lt;/math&gt;

&lt;!-- extra blank line between two lines of "displayed" [[TeX]] for legibility --&gt;
: &lt;math&gt; \tan \left( \tfrac{1}{2}\Pi(a) \right) = e^{-a}, &lt;/math&gt;

&lt;!-- extra blank line between two lines of "displayed" [[TeX]] for legibility --&gt;
: &lt;math&gt; \Pi(a) = \tfrac{1}{2}\pi - \operatorname{gd}(a), &lt;/math&gt;

where sinh, cosh, tanh, sech and csch are [[hyperbolic function]]s and gd is the [[Gudermannian function]].

==Construction==
[[JÃ¡nos Bolyai]] discovered a construction which gives the asymptotic parallel ''s'' to a line ''r'' passing through a point ''A'' not on ''r''.&lt;ref&gt;"Non-Euclidean Geometry" by Roberto Bonola, page 104, Dover Publications.&lt;/ref&gt; Drop a perpendicular from ''A'' onto ''B'' on ''r''. Choose any point ''C'' on ''r'' different from ''B''. Erect a perpendicular ''t'' to ''r'' at ''C''. Drop a perpendicular from ''A'' onto ''D'' on ''t''. Then length ''DA'' is longer than ''CB'', but shorter than ''CA''. Draw a circle around ''C'' with radius equal to ''DA''. It will intersect the segment ''AB'' at a point ''E''. Then the angle ''BEC'' is independent of the length ''BC'', depending only on ''AB''; it is the angle of parallelism. Construct ''s'' through ''A'' at angle ''BEC'' from ''AB''.
:&lt;math&gt; \sin BEC = \frac{ \sinh {BC} }{ \sinh {CE} } = \frac{ \sinh {BC} }{ \sinh {DA} } = \frac{ \sinh {BC} }{ \sin {ACD} \sinh {CA} } = \frac{ \sinh {BC} }{ \cos {ACB} \sinh {CA} } = \frac{ \sinh {BC} \tanh {CA} }{ \tanh {CB} \sinh {CA} } = \frac{ \cosh {BC} }{ \cosh {CA} } = \frac{ \cosh {BC} }{ \cosh {CB} \cosh {AB} } = \frac{ 1 }{ \cosh {AB} } \,.&lt;/math&gt;

See [[Hyperbolic triangle#Trigonometry of right triangles|Trigonometry of right triangles]] for the formulas used here.

==History==
{{Anchor|Lobachevsky originator}} &lt;!-- Lobachevsky's formula links here --&gt;

The '''angle of parallelism''' was developed in 1840 in the German publication "Geometrische Untersuchungen zur Theory der Parallellinien"  by [[Nicolai Lobachevsky]].

This publication became widely known in English after the Texas professor [[G. B. Halsted]] produced a translation in 1891. (''Geometrical Researches on the Theory of Parallels'')

The following passages define this pivotal concept in hyperbolic geometry:
:''The angle HAD between the parallel HA and the perpendicular AD is called the parallel angle (angle of parallelism) which we will here designate by Î (p) for AD = p''.&lt;ref name=Lob&gt;Nicholaus Lobatschewsky (1840) G.B. Halsted translator (1891) [https://books.google.ca/books?id=GJBsAAAAMAAJ Geometrical Researches on the Theory of Parallels], link from [[Google Books]]&lt;/ref&gt;{{rp|13}}&lt;ref&gt;{{cite book|last1=Bonola|first1=Roberto|title=Non-Euclidean geometry : a critical and historical study of its developments|date=1955|publisher=Dover|location=New York, NY|isbn=0-486-60027-0|edition=Unabridged and unaltered republ. of the 1. English translation 1912.}}&lt;/ref&gt;

==Demonstration==

[[Image:Angle of parallelism half plane model.svg|thumb|400px|right|The angle of parallelism, '''&amp;phi;''', formulated as: (a) The angle between the x-axis and the line running from ''x'', the center of ''Q'', to ''y'', the y-intercept of Q, and (b) The angle from the tangent of ''Q'' at ''y'' to the y-axis.&lt;br&gt;This diagram, with yellow [[ideal triangle]], is similar to one found in a book by Smogorzhevsky.&lt;ref&gt;A.S. Smogorzhevsky (1982) ''Lobachevskian Geometry'', Â§12 Basic formulas of hyperbolic geometry, figure 37, page 60, [[Mir Publishers]], Moscow&lt;/ref&gt;]] 


In the [[PoincarÃ© half-plane model]] of the hyperbolic plane (see [[Hyperbolic motion]]s), one can establish the relation of ''&amp;phi;'' to ''a'' with [[Euclidean geometry]]. Let ''Q'' be the semicircle with diameter on the ''x''-axis that passes through the points (1,0) and (0,''y''), where ''y'' &gt; 1. Since ''Q'' is tangent to the unit semicircle centered at the origin, the two semicircles represent ''parallel hyperbolic lines''. The ''y''-axis crosses both semicircles, making a right angle with the unit semicircle and a variable angle ''&amp;phi;'' with ''Q''. The angle at the center of ''Q'' subtended by the radius to (0,&amp;nbsp;''y'') is also ''&amp;phi;'' because the two angles have sides that are perpendicular, left side to left side, and right side to right side.  The semicircle ''Q'' has its center at (''x'',&amp;nbsp;0), ''x'' &lt; 0, so its radius is 1&amp;nbsp;&amp;minus;&amp;nbsp;''x''. Thus, the radius squared of ''Q'' is

: &lt;math&gt; x^2 + y^2 = (1 - x)^2, &lt;/math&gt;

hence

: &lt;math&gt; x = \tfrac{1}{2}(1 - y^2). &lt;/math&gt;

The [[Metric (mathematics)|metric]] of the [[PoincarÃ© half-plane model]] of hyperbolic geometry parametrizes distance on the ray {(0,&amp;nbsp;''y'') : ''y'' &gt; 0 } with [[logarithmic measure]]. Let log&amp;nbsp;''y'' = ''a'', so ''y'' = e&lt;sup&gt;''a''&lt;/sup&gt; where [[e (mathematical constant)|e]] is the base of the [[natural logarithm]]. Then 
the relation between ''&amp;phi;'' and ''a'' can be deduced from the triangle {(''x'',&amp;nbsp;0),&amp;nbsp;(0,&amp;nbsp;0),&amp;nbsp;(0,&amp;nbsp;''y'')}, for example:

: &lt;math&gt; \tan\phi = \frac{y}{-x} = \frac{2y}{y^2 - 1} = \frac{2e^a}{e^{2a} - 1} = \frac{1}{\sinh a}. &lt;/math&gt;

==References==
{{Reflist}}

* [[Marvin J. Greenberg]] (1974) ''Euclidean and Non-Euclidean Geometries'', pp.&amp;nbsp;211&amp;ndash;3, [[W.H. Freeman &amp; Company]].
* [[Robin Hartshorne]] (1997) ''Companion to Euclid'' pp.&amp;nbsp;319,&amp;nbsp;325, [[American Mathematical Society]], {{ISBN|0821807978}}.
* [[Jeremy Gray]] (1989) ''Ideas of Space: Euclidean, Non-Euclidean, and Relativistic'', 2nd edition, [[Clarendon Press]], Oxford (See pages 113 to 118).
* [[BÃ©la KerÃ©kjÃ¡rtÃ³]] (1966) ''Les Fondements de la GÃ©omÃ©try'', Tome Deux, Â§97.6 Angle de parallÃ©lisme de la gÃ©omÃ©try hyperbolique, pp. 411,2, Akademiai Kiado, Budapest.


[[Category:Hyperbolic geometry]]
[[Category:Functions and mappings]]
[[Category:Angle]]</text>
      <sha1>e6wo6mjh3few528oyzl7f6wnm5xggqs</sha1>
    </revision>
  </page>
  <page>
    <title>Bred vector</title>
    <ns>0</ns>
    <id>2983356</id>
    <revision>
      <id>823962379</id>
      <parentid>812242366</parentid>
      <timestamp>2018-02-04T14:09:46Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2126">[[File:Bred vector growth rates in Lorenz system.png|thumb|250px|The growth rates of bred vectors in the [[Lorenz system]]. Red indicates the fastest-growing bred vectors while blue the slowest.]]

In [[applied mathematics]], '''bred vectors''' are [[perturbation theory|perturbations]], related to [[Lyapunov vector]]s, that capture fast-growing dynamical [[instability|instabilities]] of the solution of a [[computer simulation|numerical model]]. They are used, for example, as initial perturbations for [[ensemble forecasting]] in [[numerical weather prediction]]. They were introduced by Zoltan Toth and [[Eugenia Kalnay]].&lt;ref&gt;{{cite journal|last1=Toth|first1=Zoltan|last2=Kalnay|first2=Eugenia|title=Ensemble Forecasting at NMC: The Generation of Perturbations|journal=Bulletin of the American Meteorological Society|date=December 1993|volume=74|issue=12|pages=2317â2330|doi=10.1175/1520-0477(1993)074&lt;2317:EFANTG&gt;2.0.CO;2|bibcode=1993BAMS...74.2317T}}&lt;/ref&gt;

==Method==
Bred vectors are created by adding initially random perturbations to a [[nonlinear]] model. The control (unperturbed) and the perturbed models are [[integral|integrated]] in time, and periodically the control solution is subtracted from the perturbed solution. This difference is the bred vector. The vector is scaled to be the same size as the initial perturbation, and is then added back to the control to create the new perturbed initial condition. After a short transient period, this "breeding" process creates bred vectors dominated by the naturally fastest-growing instabilities of the evolving control solution.

==References==
{{reflist}}
*{{cite book |last=Kalnay |first=E. |year=2003 |title=Atmospheric Modeling, Data Assimilation and Predictability |location=Cambridge |publisher=Cambridge University Press |isbn=978-0-521-79629-3 |url= }}
*{{cite book |editor-last=Glickman |editor-first=T. S. |year=2000 |title=Glossary of Meteorology |edition=Second |location=Boston, Massachusetts |publisher=American Meteorological Society |isbn= |url= }}

[[Category:Functional analysis]]
[[Category:Mathematical physics]]


{{mathanalysis-stub}}</text>
      <sha1>qpyrrsuk1s6scm93xfgfewinh2q94gf</sha1>
    </revision>
  </page>
  <page>
    <title>Byzantine fault tolerance</title>
    <ns>0</ns>
    <id>970031</id>
    <revision>
      <id>869107483</id>
      <parentid>869107459</parentid>
      <timestamp>2018-11-16T13:26:38Z</timestamp>
      <contributor>
        <username>Shellwood</username>
        <id>2366721</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/111.68.111.198|111.68.111.198]] ([[User talk:111.68.111.198|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27593">{{Redirect|Byzantine generals|military generals of the Byzantine empire|Category:Byzantine generals}}
'''Byzantine fault tolerance''' ('''BFT''') is the dependability of a [[fault-tolerant computer system]], particularly [[distributed computing]] systems, where components may fail and there is imperfect information on whether a component has failed. In a "Byzantine failure", a component such as a [[Server (computing)|server]] can inconsistently appear both failed and functioning to failure-detection systems, presenting different symptoms to different observers. 

It is difficult for the other components to declare it failed and shut it out of the network, because they need to first reach a [[Consensus (computer science)|consensus]] regarding which component has failed in the first place. The term is derived from the [[#Byzantine Generals' Problem|Byzantine Generals' Problem]],&lt;ref&gt;{{Cite journal | last1 = Lamport | first1 = L. | authorlink1 = Leslie Lamport| last2 = Shostak | first2 = R. | last3 = Pease | first3 = M. | doi = 10.1145/357172.357176 | title = The Byzantine Generals Problem | journal = ACM Transactions on Programming Languages and Systems | volume = 4 | issue = 3 | pages = 382&amp;ndash;401 | year = 1982 | url = https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fbyz.pdf | dead-url = no | archiveurl = https://web.archive.org/web/20180613015025/https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Flamport%2Fpubs%2Fbyz.pdf | archivedate = 13 June 2018}}&lt;/ref&gt; where actors must agree on a concerted strategy to avoid catastrophic system failure, but some of the actors are unreliable. Byzantine fault tolerance has been also referred to with the phrases '''interactive consistency''' or '''source congruency''', '''error avalanche''', '''Byzantine agreement problem''', '''Byzantine generals problem''', and '''Byzantine failure'''.&lt;ref&gt;{{cite web |url=http://lamspeople.epfl.ch/kirrmann/Pubs/FaultTolerance/Fault_Tolerance_Tutorial_HK.pdf#page=94
|title=Fault Tolerant Computing in Industrial Automation| last1= Kirrmann| first1= Hubert| date=n.d.| publisher= ABB Research Center| location=Switzerland |page=94 |access-date=2015-03-02}}&lt;/ref&gt;

==Background==
A Byzantine fault is any fault presenting different symptoms to different observers.&lt;ref name="DriscollHall2004"&gt;{{cite journal| last1=Driscoll| first1=K.| last2=Hall| first2=B.| last3=Paulitsch| first3=M.| last4=Zumsteg| first4=P. |last5=Sivencrona| first5=H.| title=The Real Byzantine Generals| year=2004| pages=6.D.4â61-11| doi=10.1109/DASC.2004.1390734}}&lt;/ref&gt;  A Byzantine failure is the loss of a system service due to a Byzantine fault in systems that require [[Consensus (computer science)|consensus]].&lt;ref name="DriscollHall2003"&gt;{{cite journal| last1=Driscoll| first1=Kevin| last2=Hall| first2=Brendan| last3=Sivencrona| first3=HÃ¥kan| last4=Zumsteg| first4=Phil
| title=Byzantine Fault Tolerance, from Theory to Reality| volume=2788| year=2003| pages=235â248| issn=0302-9743| doi=10.1007/978-3-540-39878-3_19}}&lt;/ref&gt;

The objective of Byzantine fault tolerance is to be able to defend against failures of system components with or without symptoms that prevent other components of the system from reaching an agreement among themselves, where such an agreement is needed for the correct operation of the system.

Remaining correctly operational components of a Byzantine fault tolerant system will be able to continue providing the system's service as originally intended, assuming there are sufficiently many accurately operating components to maintain the service.

Byzantine failures are considered the most general and most difficult class of failures among the [[Failure cause|failure modes]]. The so-called fail-stop failure mode occupies the simplest end of the spectrum. Whereas fail-stop failure mode simply means that the only way to fail is a [[Node (computer science)|node]] crash, detected by other nodes, Byzantine failures imply no restrictions, which means that the failed node can generate arbitrary data, pretending to be a correct one. Thus, Byzantine failures can confuse failure detection systems, which makes fault tolerance difficult. Despite the analogy, a Byzantine failure is not necessarily a [[security]] problem involving hostile human interference: it can arise purely from electrical faults.

The terms fault and failure are used here according to the standard definitions&lt;ref name="AvizienisLaprie2004"&gt;{{cite journal| last1=Avizienis
| first1=A.| last2=Laprie| first2=J.-C.| last3=Randell| first3=Brian| author-link3=Brian Randell| last4=Landwehr| first4=C.| title=Basic concepts and taxonomy of dependable and secure computing| journal=IEEE Transactions on Dependable and Secure Computing| volume=1| issue=1| year=2004| pages=11â33| issn=1545-5971
| doi=10.1109/TDSC.2004.2}}&lt;/ref&gt; originally created by a joint committee on "Fundamental Concepts and Terminology" formed by the [[IEEE]] Computer Society's Technical Committee on Dependable Computing and Fault-Tolerance and [[IFIP]] Working Group 10.4 on Dependable Computing and Fault Tolerance.&lt;ref&gt;{{cite web
| title = Dependable Computing and Fault Tolerance| url = http://www.dependability.org| accessdate = 2015-03-02}}&lt;/ref&gt; A version of these definitions is also described in the [[Dependability]] Wikipedia page.

==Byzantine Generals' Problem==
''Byzantine'' refers to the Byzantine Generals' Problem, an agreement problem (described by [[Leslie Lamport]], Robert Shostak and Marshall Pease in their 1982 paper, "The Byzantine Generals Problem")&lt;ref name=BGP_Paper /&gt; in which a group of generals, each commanding a portion of the [[Byzantine army]], encircle a city.  These generals wish to formulate a plan for attacking the city.  In its simplest form, the generals must decide only whether to attack or retreat.  Some generals may prefer to attack, while others prefer to retreat.  The important thing is that every general agree on a common decision, for a halfhearted attack by a few generals would become a [[rout]], and would be worse than either a coordinated attack or a coordinated retreat.

The problem is complicated by the presence of treacherous generals who may not only cast a vote for a suboptimal strategy, they may do so selectively.  For instance, if nine generals are voting, four of whom support attacking while four others are in favor of retreat, the ninth general may send a vote of retreat to those generals in favor of retreat, and a vote of attack to the rest.  Those who received a retreat vote from the ninth general will retreat, while the rest will attack (which may not go well for the attackers).  The problem is complicated further by the generals being physically separated and having to send their votes via messengers who may fail to deliver votes or may forge false votes.

Byzantine fault tolerance can be achieved if the loyal (non-faulty) generals have a majority agreement on their strategy.  There can be a default vote value given to missing messages.  For example, missing messages can be given the value &amp;lt;Null&amp;gt;.  Further, if the agreement is that the &amp;lt;Null&amp;gt; votes are in the majority, a pre-assigned default strategy can be used (e.g., retreat).&lt;ref name=BGP_Paper&gt;{{Cite journal | last1 = Lamport | first1 = L. | authorlink1 = Leslie Lamport| last2 = Shostak | first2 = R. | last3 = Pease | first3 = M. | doi = 10.1145/357172.357176 | title = The Byzantine Generals Problem | journal = ACM Transactions on Programming Languages and Systems | volume = 4 | issue = 3 | pages = 387&amp;ndash;389 | year=1982 | archiveurl = https://web.archive.org/web/20170207104645/http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf | archivedate = 7 February 2017 | url = http://research.microsoft.com/en-us/um/people/lamport/pubs/byz.pdf}}&lt;/ref&gt;

The typical mapping of this story onto computer systems is that the computers are the generals and their digital communication system links are the messengers. Although the problem is formulated in the analogy as a decision-making and security problem, in electronics, it cannot be solved simply by [[cryptographic]] [[digital signature]]s, because failures such as incorrect voltages can propagate through the encryption process. Thus, a component may appear functioning to one component and faulty to another, which prevents forming a consensus whether the component is faulty or not.

==Examples of Byzantine failures==
Several examples of Byzantine failures that have occurred are given in two equivalent journal papers.&lt;ref name="DriscollHall2004" /&gt;&lt;ref name="DriscollHall2003" /&gt; These and other examples are described on the [[NASA]] DASHlink web pages.&lt;ref&gt;{{cite web
| url         = https://c3.nasa.gov/dashlink/resources/624/
| title       = Real System Failures
| last        = Driscoll
| first       = Kevin
| date        = 2012-12-11
| publisher   = [[NASA]]
| access-date = 2015-03-02
| website     = DASHlink
}}&lt;/ref&gt;  These web pages also describe some phenomenology that can cause Byzantine faults.

Byzantine errors were observed infrequently and at irregular points during endurance testing for the newly constructed [[Virginia-class submarine|''Virginia'' class submarines]], at least through 2005 (when the issues were publicly reported).&lt;ref name="WalterEllis2005"&gt;{{cite journal|last1=Walter|first1=C.|last2=Ellis|first2=P.|last3=LaValley|first3=B.|title=The Reliable Platform Service: A Property-Based Fault Tolerant Service Architecture|year=2005|pages=34â43|doi=10.1109/HASE.2005.23}}&lt;/ref&gt;

A similar problem faces honeybee swarms. They have to find a new home, and the many scouts and wider participants have to reach consensus about which of perhaps several candidate homes to fly to. And then they all have to fly there, with their queen.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/587249075|title=Honeybee democracy|last=D.|first=Seeley, Thomas|date=2010|publisher=Princeton University Press|isbn=9780691147215|location=Princeton, N.J.|oclc=587249075}}&lt;/ref&gt;

==Early solutions==
Several solutions were described by Lamport, Shostak, and Pease in 1982.&lt;ref name=BGP_Paper/&gt; They began by noting that the Generals' Problem can be reduced to solving a "Commander and Lieutenants" problem where loyal Lieutenants must all act in unison and that their action must correspond to what the Commander ordered in the case that the Commander is loyal.
* One solution considers scenarios in which messages may be forged, but which will be ''Byzantine-fault-tolerant'' as long as the number of traitorous generals does not equal or exceed one third of the generals. The impossibility of dealing with one-third or more traitors ultimately reduces to proving that the one Commander and two Lieutenants problem cannot be solved, if the Commander is traitorous. To see this, suppose we have a traitorous Commander A, and two Lieutenants, B and C:  when A tells B to attack and C to retreat, and B and C send messages to each other, forwarding A's message, neither B nor C can figure out who is the traitor, since it is not necessarily Aâanother Lieutenant could have forged the message purportedly from A. It can be shown that if ''n'' is the number of generals in total, and ''t'' is the number of traitors in that ''n'', then there are solutions to the problem only when ''n'' &amp;gt; 3''t'' and the communication is synchronous (bounded delay).&lt;ref&gt;{{cite journal
| first1 = P.
| last1 = Feldman
| first2 = S.
| last2 = Micali
| url = http://people.csail.mit.edu/silvio/Selected%20Scientific%20Papers/Distributed%20Computation/An%20Optimal%20Probabilistic%20Algorithm%20for%20Byzantine%20Agreement.pdf
| title = An optimal probabilistic protocol for synchronous Byzantine agreement
| journal = SIAM J. Comput.
| volume = 26
| issue = 4
| pages = 873â933
| date = 1997
| doi = 10.1137/s0097539790187084}}&lt;/ref&gt;
* A second solution requires unforgeable message signatures.  For [[Critical system#Security critical|security-critical systems]], [[digital signature]]s (in modern computer systems, this may be achieved in practice using [[public-key cryptography]]) can provide Byzantine fault tolerance in the presence of an arbitrary number of traitorous generals.  However, for [[safety-critical system]]s (where "security" addresses intelligent threats while "safety" addresses the inherent dangers of an activity or mission), simple error detecting codes, such as [[Cyclic redundancy check|CRCs]], provide weaker but often sufficient coverage at a much lower cost.  This is true for both Byzantine and non-Byzantine faults. Furthermore, sometimes security measures weaken safety and vice versa--Thus, cryptographic digital signature methods are not a good choice for safety-critical systems, unless there is also a specific security threat as well.&lt;ref name="PaulitschMorris2005"&gt;{{cite journal
| last1=Paulitsch
| first1=M.
| last2=Morris
| first2=J.
| last3=Hall
| first3=B.
| last4=Driscoll
| first4=K.
| last5=Latronico
| first5=E.
| last6=Koopman
| first6=P.
| title=Coverage and the Use of Cyclic Redundancy Codes in Ultra-Dependable Systems
| year=2005
| pages=346â355
| doi=10.1109/DSN.2005.31}}&lt;/ref&gt; While error detecting codes, such as CRCs, are better than cryptographic techniques, neither provide adequate coverage for active electronics in safety-critical systems.  This is illustrated by the ''SchrÃ¶dinger CRC'' scenario where a CRC-protected message with a single Byzantine faulty bit presents different data to different observers and each observer sees a valid CRC.&lt;ref name="DriscollHall2004" /&gt;&lt;ref name="DriscollHall2003" /&gt;
* Also presented is a variation on the first two solutions allowing Byzantine-fault-tolerant behavior in some situations where not all generals can communicate directly with each other.

Several system architectures were designed c. 1980 that implemented Byzantine fault tolerance.  These include: Draper's FTMP,&lt;ref name="HopkinsLala1987"&gt;
{{cite journal
| last1=Hopkins
| first1=Albert L.
| last2=Lala
| first2=Jaynarayan H.
| last3=Smith
| first3=T. Basil
| title=The Evolution of Fault Tolerant Computing at the Charles Stark Draper Laboratory, 1955â85
| volume=1
| year=1987
| pages=121â140
| issn=0932-5581
| doi=10.1007/978-3-7091-8871-2_6}}&lt;/ref&gt;
Honeywell's MMFCS,&lt;ref name="MMFCS"&gt;
{{citation
| last1 = Driscoll
| first1 = Kevin
| last2 = Papadopoulos
| first2 = Gregory
| last3 = Nelson
| first3 = Scott
| last4 = Hartmann
| first4 = Gary
| last5 = Ramohalli
| first5 = Gautham
| title = Multi-Microprocessor Flight Control System
| publisher = AFWAL/FIGL U.S. Air Force Systems Command
| date = 1984
| type = Technical Report
| location = Wright-Patterson Air Force Base, OH 45433, USA 
| id = AFWAL-TR-84-3076
}}&lt;/ref&gt;
and SRI's SIFT.&lt;ref&gt;{{cite journal
| title=SIFT: design and analysis of a fault-tolerant computer for aircraft control|journal=Microelectronics Reliability|volume=19|issue=3|year=1979|page=190|issn=0026-2714|doi=10.1016/0026-2714(79)90211-7}}&lt;/ref&gt;

==Practical Byzantine fault tolerance==
In 1999, Miguel Castro and [[Barbara Liskov]] introduced the "Practical Byzantine Fault Tolerance" (PBFT) algorithm,&lt;ref&gt;{{cite journal
| first1 = M.
| last1 = Castro
| first2 = B.
| last2 = Liskov
| citeseerx = 10.1.1.127.6130
| title = Practical Byzantine Fault Tolerance and Proactive Recovery
| publisher = [[Association for Computing Machinery]]
| journal = ACM Transactions on Computer Systems
| volume = 20
| issue = 4
| pages = 398â461
| date = 2002
| doi = 10.1145/571637.571640}}&lt;/ref&gt; which provides high-performance Byzantine state machine replication, processing thousands of requests per second with sub-millisecond increases in latency.

After PBFT, several BFT protocols were introduced to improve its robustness and performance. For instance, Q/U,&lt;ref&gt;{{cite journal
| first1 = M.
| last1 = Abd-El-Malek
| first2 = G.
| last2 = Ganger
| first3 = G.
| last3 = Goodson
| first4 = M.
| last4 = Reiter
| first5 = J.
| last5 = Wylie
| doi = 10.1145/1095809.1095817
| title = Fault-scalable Byzantine Fault-Tolerant Services
| publisher = [[Association for Computing Machinery]]
| conference = Symposium on Operating Systems Principles
| date = 2005 }}&lt;/ref&gt;
HQ,&lt;ref&gt;{{cite conference
| first1 = James
| last1 = Cowling
| first2 = Daniel
| last2 = Myers
| authorlink3 = Barbara Liskov
| first3 = Barbara
| last3 = Liskov
| first4 = Rodrigo
| last4 = Rodrigues
| first5 = Liuba
| last5 = Shrira
| url = http://portal.acm.org/citation.cfm?id=1298455.1298473
| title = HQ Replication: A Hybrid Quorum Protocol for Byzantine Fault Tolerance
| conference = Proceedings of the 7th [[USENIX]] Symposium on Operating Systems Design and Implementation
| date = 2006
| isbn = 1-931971-47-1
| pages = 177â190}}&lt;/ref&gt;
Zyzzyva,&lt;ref&gt;{{cite journal
| first1 = Ramakrishna
| last1 = Kotla
| first2 = Lorenzo
| last2 = Alvisi
| first3 = Mike
| last3 = Dahlin
| first4 = Allen
| last4 = Clement
| first5 = Edmund
| last5 = Wong
| doi = 10.1145/1658357.1658358
| title = Zyzzyva: Speculative Byzantine Fault Tolerance
| publisher = [[Association for Computing Machinery]]
| journal = ACM Transactions on Computer Systems
| volume = 27
| issue = 4
| date = December 2009 }}&lt;/ref&gt;
and ABsTRACTs&lt;ref&gt;{{cite conference
| first1 = Rachid
| last1 = Guerraoui
| first2 = Nikola
| last2 = KneÅ¾evic
| first3 = Marko
| last3 = Vukolic
| first4 = Vivien
| last4 = QuÃ©ma
| url = http://infoscience.epfl.ch/record/144158
| title = The Next 700 BFT Protocols
| conference = Proceedings of the 5th European conference on Computer systems
| publisher = EuroSys
| date = 2010 }}&lt;/ref&gt;
, etc., addressed the performance and cost issues; whereas other protocols, like Aardvark&lt;ref&gt;{{cite conference|first1=A.|last1=Clement|first2=E.|last2=Wong|first3=L.|last3=Alvisi|first4=M.|last4=Dahlin|first5=M.|last5=Marchetti|url=http://www.usenix.org/events/nsdi09/tech/full_papers/clement/clement.pdf|title=Making Byzantine Fault Tolerant Systems Tolerate Byzantine Faults|publisher=[[USENIX]]|conference=Symposium on Networked Systems Design and Implementation|date=April 22â24, 2009}}&lt;/ref&gt;
and RBFT&lt;ref&gt;{{cite conference|first1=P.-L.|last1=Aublin|first2=S.|last2=Ben Mokhtar|first3=V.|last3=QuÃ©ma|url=http://www.temple.edu/cis/icdcs2013/program.html|title=RBFT: Redundant Byzantine Fault Tolerance|publisher=[[International Conference on Distributed Computing Systems]]|conference=33rd IEEE International Conference on Distributed Computing Systems|date=July 8â11, 2013|deadurl=yes|archiveurl=https://web.archive.org/web/20130805115252/http://www.temple.edu/cis/icdcs2013/program.html|archivedate=August 5, 2013}}&lt;/ref&gt;
, addressed its robustness issues. Furthermore, Adapt&lt;ref&gt;{{Cite journal|last=Bahsoun|first=J. P.|last2=Guerraoui|first2=R.|last3=Shoker|first3=A.|date=2015-05-01|title=Making BFT Protocols Really Adaptive|url=http://ieeexplore.ieee.org/document/7161576/|journal=Parallel and Distributed Processing Symposium (IPDPS), 2015 IEEE International|pages=904â913|doi=10.1109/IPDPS.2015.21}}&lt;/ref&gt; tried to make use of existing BFT protocols, through switching between them in an adaptive way, to improve system robustness and performance as the underlying conditions change. Furthermore, BFT protocols were introduced that leverage trusted components to reduce the number of replicas, e.g., A2M-PBFT-EA&lt;ref&gt;{{Cite journal|last=Chun|first=Byung-Gon|last2=Maniatis|first2=Petros|last3=Shenker|first3=Scott|last4=Kubiatowicz|first4=John|date=2007-01-01|title=Attested Append-only Memory: Making Adversaries Stick to Their Word|url=http://doi.acm.org/10.1145/1294261.1294280|journal=Proceedings of Twenty-first ACM SIGOPS Symposium on Operating Systems Principles|series=SOSP '07|location=New York, NY, USA|publisher=ACM|pages=189â204|doi=10.1145/1294261.1294280|isbn=9781595935915}}&lt;/ref&gt; and MinBFT.&lt;ref&gt;{{Cite journal|last=Veronese|first=G. S.|last2=Correia|first2=M.|last3=Bessani|first3=A. N.|last4=Lung|first4=L. C.|last5=Verissimo|first5=P.|date=2013-01-01|title=Efficient Byzantine Fault-Tolerance|url=http://ieeexplore.ieee.org/document/6081855/|journal=IEEE Transactions on Computers|volume=62|issue=1|pages=16â30|doi=10.1109/TC.2011.221|issn=0018-9340}}&lt;/ref&gt;

==Software==
UpRight&lt;ref&gt;[https://code.google.com/p/upright/ UpRight]. Google Code repository for the UpRight replication library.&lt;/ref&gt; is an open source library for constructing services that tolerate both crashes ("up") and Byzantine behaviors ("right") that incorporates many of these protocols' innovations.

In addition to PBFT and UpRight, there is the BFT-SMaRt library,&lt;ref&gt;[https://bft-smart.github.io/library/ BFT-SMaRt]. Google Code
repository for the BFT-SMaRt replication library.&lt;/ref&gt; a high-performance Byzantine fault-tolerant state machine replication library developed in Java. This library implements a protocol very similar to PBFT's, plus complementary protocols which offer state transfer and on-the-fly reconfiguration of hosts. BFT-SMaRt is the most recent effort to implement state machine replication, still being actively maintained.

[[Archistar]]&lt;ref&gt;[https://github.com/Archistar/archistar-core Archistar]. github repository for the Archistar project.&lt;/ref&gt; utilizes a slim BFT layer&lt;ref&gt;[https://github.com/Archistar/archistar-bft Archistar-bft BFT state-machine]. github repository for the Archistar project.&lt;/ref&gt; for communication. It prototypes a secure multi-cloud storage system using Java licensed under LGPLv2. Focus lies on simplicity and readability, it aims to be the foundation for further research projects.

Askemos&lt;ref&gt;[http://ball.askemos.org/ Askemos/BALL] project home page&lt;/ref&gt;  is a concurrent, garbage-collected, persistent programming platform atop of replicated state machines which tolerates Byzantine faults. It prototypes an execution environment facilitating [[Smart contracts]].

Tendermint&lt;ref&gt;[https://github.com/tendermint/tendermint Tendermint] github repository for the Tendermint project&lt;/ref&gt; is general purpose software for BFT state machine replication. Using a socket protocol, it enables state machines to be written in any programming language, and provides
means for the state machine to influence elements of the consensus, such as the list of active processes. Tendermint is implemented in the style of a [[Blockchain (database)|blockchain]], which amortizes the overhead of BFT and allows for faster recovery from failure.

==Product implementations==
One example of BFT in use is [[bitcoin]], a peer-to-peer digital cash system{{Citation needed|reason=Is there a proof that blockchain is BFT? |date=August 2018}}. The [[bitcoin network]] works in parallel to generate a [[blockchain]] with [[proof-of-work]] allowing the system to overcome Byzantine failures and reach a coherent global view of the system's state.

Some aircraft systems, such as the [[Airplane_Information_Management_System|Boeing 777 Aircraft Information Management System]] (via its [[ARINC]] 659 [[SAFEbus]] network),&lt;ref name="Zurawski2015"&gt;{{cite book
| last1=M.
| first1=Paulitsch
| last2=Driscoll
| first2=K.
| editor-first=Richard
| editor-last=Zurawski
| title=Industrial Communication Technology Handbook, Second Edition
| url=https://books.google.com/books?id=ppzNBQAAQBAJ
| date=9 January 2015
| chapter=Chapter 48:SAFEbus
| pages=48-1â48-26
| publisher=CRC Press
| isbn=978-1-4822-0733-0}}&lt;/ref&gt;
&lt;ref name="HenzingerKirsch2001"&gt;{{cite book
| author1=Thomas A. Henzinger
| author2=Christoph M. Kirsch
| title=Embedded Software: First International Workshop, EMSOFT 2001, Tahoe City, CA, USA, October 8-10, 2001. Proceedings
| url=http://www.csl.sri.com/papers/emsoft01/emsoft01.pdf
| date=26 September 2001
| publisher=Springer Science &amp; Business Media
| isbn=978-3-540-42673-8
| pages=307â}}&lt;/ref&gt;
the Boeing 777 flight control system,&lt;ref name="Yeh2001"&gt;{{cite journal
| last1=Yeh
| first1=Y.C.
| title=Safety critical avionics for the 777 primary flight controls system
| volume=1
| year=2001
| pages=1C2/1â1C2/11
| doi=10.1109/DASC.2001.963311}}&lt;/ref&gt;
and the Boeing 787 flight control systems use Byzantine fault tolerance;  because these are real-time systems, their Byzantine fault tolerance solutions must have very low latency.  For example, SAFEbus can achieve Byzantine fault tolerance within the order of a microsecond of added latency.

Some spacecraft flight systems such as that of the [[SpaceX Dragon]]&lt;ref&gt;[https://lwn.net/Articles/540368/ ELC: SpaceX lessons learned [LWN.net&amp;#93;&lt;!-- Bot generated title --&gt;]&lt;/ref&gt; consider Byzantine fault tolerance in their design.

Byzantine fault tolerance mechanisms use components that repeat an incoming message (or just its signature) to other recipients of that incoming message.  All these mechanisms make the assumption that the act of repeating a message blocks the propagation of Byzantine symptoms.  For systems that have a high degree of safety or security criticality, these assumptions must be proven to be true to an acceptable level of [[fault coverage]].  When providing proof through testing, one difficulty is creating a sufficiently wide range of signals with Byzantine symptoms.&lt;ref name="NanyaGoosen1989"&gt;{{cite journal |last1=Nanya|first1=T.|last2=Goosen|first2=H.A.|title=The Byzantine hardware fault model|journal=IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems|volume=8|issue=11|year=1989|pages=1226â1231|issn=0278-0070|doi=10.1109/43.41508}}&lt;/ref&gt;  Such testing likely will require specialized fault injectors.&lt;ref name="MartinsGandhi2013"&gt;{{cite journal|last1=Martins|first1=Rolando|last2=Gandhi|first2=Rajeev|last3=Narasimhan|first3=Priya|last4=Pertet|first4=Soila|last5=Casimiro|first5=AntÃ³nio|last6=Kreutz|first6=Diego|last7=VerÃ­ssimo|first7=Paulo|title=Experiences with Fault-Injection in a Byzantine Fault-Tolerant Protocol|volume=8275|year=2013|pages=41â61|issn=0302-9743|doi=10.1007/978-3-642-45065-5_3}}&lt;/ref&gt;&lt;ref&gt;{{cite patent
 | country = US
 | number = 7475318
 | status = patent
 | title = Method for testing the sensitive input range of Byzantine filters
 | gdate = 2009-01-06
 | fdate = 2006-01-27
 | pridate = 2005-01-28
 | inventor = Kevin R. Driscoll
 | assign1 = Honeywell International Inc.
 | class = G01R31/28
}}&lt;/ref&gt;

==See also==
{{Portal|Information technology}}
{{columns-list|colwidth=30em|
* [[Atomic commit]]
* [[BrooksâIyengar algorithm]]
* [[List of mathematical concepts named after places]]
* [[List of terms relating to algorithms and data structures]]
* [[Paxos (computer science)#Byzantine Paxos|Byzantine Paxos]]
* [[Quantum Byzantine agreement]]
* [[Two Armies Problem]]
}}

==References==
{{Reflist|30em}}

==External links==
* [https://web.archive.org/web/20080828060019/http://www.rkbexplorer.com/explorer/#display=mechanism%2D{http://resex.rkbexplorer.com/id/resilience-mechanism-65b5cef4} Byzantine Fault Tolerance in the RKBExplorer]
* [https://code.google.com/p/upright UpRight] is an open source library for Crash-tolerant and Byzantine-tolerant state machine replication.
* [https://bft-smart.github.io/library/ Bft-SMaRt] is a high-performance Byzantine fault-tolerant state machine replication library developed in Java with simplicity and robustness as primary requirements.

{{DEFAULTSORT:Byzantine Fault Tolerance}}
[[Category:Public-key cryptography]]
[[Category:Distributed computing problems]]
[[Category:Fault-tolerant computer systems]]
[[Category:Theory of computation]]</text>
      <sha1>pp1qgfb209fl3r684fkoelq9kwn04h1</sha1>
    </revision>
  </page>
  <page>
    <title>CPT symmetry</title>
    <ns>0</ns>
    <id>151040</id>
    <revision>
      <id>868593860</id>
      <parentid>867150790</parentid>
      <timestamp>2018-11-13T05:30:11Z</timestamp>
      <contributor>
        <username>DanTrent</username>
        <id>13767476</id>
      </contributor>
      <minor/>
      <comment>/* Consequences and implications */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10363">{{Redirect|CPT theorem|the album by Greydon Square|The C.P.T. Theorem}}
{{refimprove|date=January 2012}}
'''Charge, parity, and time reversal symmetry''' is a fundamental [[symmetry in physics|symmetry]] of [[physical law]]s under the simultaneous [[transformation (mathematics)|transformation]]s of [[charge conjugation]] (C), [[parity transformation]] (P), and [[T-symmetry|time reversal]] (T). CPT is the only combination of C, P, and T that is observed to be an exact symmetry of nature at the fundamental level.&lt;ref name=kost&gt;
{{cite arXiv
 |last1=KosteleckÃ½ |first1=V. A.
 |year=1998
 |title=The Status of CPT
 |eprint=hep-ph/9810365
}}&lt;/ref&gt; The '''CPT theorem''' says that CPT symmetry holds for all physical phenomena, or more precisely, that any [[Lorentz invariant]] local [[quantum field theory]] with a [[Self-adjoint operator|Hermitian]] [[Hamiltonian (quantum mechanics)|Hamiltonian]] must have CPT symmetry.

==History==
The CPT theorem appeared for the first time, implicitly, in the work of [[Julian Schwinger]] in 1951 to prove the [[Spin-statistics theorem|connection between spin and statistics]].&lt;ref&gt;
{{Cite journal
 |last = Schwinger |first = Julian
 |date = 1951
 |title =The Theory of Quantized Fields I
 |journal=[[Physical Review]]
 |volume=82 |issue=6 |pages = 914â927
 |bibcode = 1951PhRv...82..914S
 |doi = 10.1103/PhysRev.82.914
}}&lt;/ref&gt; In 1954, [[Gerhart LÃ¼ders]] and [[Wolfgang Pauli]] derived more explicit proofs,&lt;ref name=luders&gt;
{{cite journal
 |last=LÃ¼ders |first=G.
 |year=1954
 |title=On the Equivalence of Invariance under Time Reversal and under Particle-Antiparticle Conjugation for Relativistic Field Theories
 |journal=[[Kongelige Danske Videnskabernes Selskab, Matematisk-Fysiske Meddelelser]]
 |volume=28 |issue=5 |pages=1â17
}}&lt;/ref&gt;&lt;ref name=one&gt;
{{cite book
 |editor1-last=Pauli |editor1-first=W.
 |editor2-last=Rosenfelf |editor2-first=L.
 |editor3-last=Weisskopf |editor3-first=V.
 |title=Niels Bohr and the Development of Physics
 |publisher=[[McGraw-Hill]]
 |year=1955
 |lccn=56040984
}}&lt;/ref&gt; so this theorem is sometimes known as the LÃ¼dersâPauli theorem. At about the same time, and independently, this theorem was also proved by [[John Stewart Bell]].&lt;ref&gt;{{cite book |last=Whitaker |first=Andrew |title=John Stuart Bell and Twentieth-Century Physics |year=2016 |isbn=978-0198742999 |publisher=[[Oxford University Press]] |url=https://books.google.com/?id=tDtRDAAAQBAJ&amp;pg=PT186&amp;lpg=PT186&amp;dq=bell+luders+pauli+theorem#v=onepage&amp;q=bell%20luders%20pauli%20theorem&amp;f=false }}&lt;/ref&gt; These proofs are based on the principle of [[Lorentz invariance]] and the [[principle of locality]] in the interaction of quantum fields. Subsequently, [[Res Jost]] gave a more general proof in the framework of [[axiomatic quantum field theory]].

Efforts during the late 1950s revealed the violation of [[P-symmetry#Quantum mechanics|P-symmetry]] by phenomena that involve the [[weak force]], and there were well-known violations of [[C-symmetry]] as well. For a short time, the [[CP-symmetry]] was believed to be preserved by all physical phenomena, but that was later found to be false too, which implied, by '''CPT invariance''', violations of [[T-symmetry]] as well.

==Derivation of the CPT theorem==

Consider a [[Lorentz boost]] in a fixed direction ''z''. This can be interpreted as a rotation of the time axis into the ''z'' axis, with an [[imaginary number|imaginary]] rotation parameter. If this rotation parameter were [[real number|real]], it would be possible for a 180Â° rotation to reverse the direction of time and of ''z''. Reversing the direction of one axis is a reflection of space in any number of dimensions. If space has 3 dimensions, it is equivalent to reflecting all the coordinates, because an additional rotation of 180Â° in the ''x-y'' plane could be included.

This defines a CPT transformation if we adopt the [[Antiparticle#Feynman.E2.80.93Stueckelberg interpretation|Feynman-Stueckelberg interpretation]] of antiparticles as the corresponding particles traveling backwards in time. This interpretation requires a slight [[analytic continuation]], which is well-defined only under the following assumptions:
#The theory is [[Lorentz invariant]];
#The vacuum is Lorentz invariant;
#The energy is bounded below.

When the above hold, [[quantum field theory|quantum theory]] can be extended to a Euclidean theory, defined by translating all the operators to imaginary time using the [[Hamiltonian (quantum mechanics)|Hamiltonian]]. The [[commutation relation]]s of the Hamiltonian, and the [[PoincarÃ© group|Lorentz generator]]s, guarantee that [[Lorentz invariance]] implies [[rotational invariance]], so that any state can be rotated by 180 degrees.

Since a sequence of two CPT reflections is equivalent to a 360-degree rotation, [[fermion]]s change by a sign under two CPT reflections, while [[boson]]s do not. This fact can be used to prove the [[spin-statistics theorem]].

==Consequences and implications==
The implication of CPT symmetry is that a "mirror-image" of our universe â with all objects having their positions reflected by an arbitrary plane (corresponding to a [[parity (physics)|parity]] inversion), all [[momentum|momenta]] reversed (corresponding to a [[T-symmetry|time inversion]]) and with all [[matter]] replaced by [[antimatter]] (corresponding to a [[electric charge|charge]] inversion)âwould evolve under exactly our physical laws. The CPT transformation turns our universe into its "mirror image" and vice versa. CPT symmetry is recognized to be a fundamental property of physical laws.

In order to preserve this symmetry, every violation of the combined symmetry of two of its components (such as CP) must have a corresponding violation in the third component (such as T); in fact, mathematically, these are the same thing. Thus violations in T symmetry are often referred to as [[CP violation]]s.

The CPT theorem can be generalized to take into account [[pin group]]s.

In 2002 [[Oscar Greenberg]] published an apparent proof that CPT violation implies the breaking of [[Lorentz symmetry]].&lt;ref name="Greenberg"&gt;
{{cite journal
 |last=Greenberg |first=O. W.
 |year=2002
 |title=CPT Violation Implies Violation of Lorentz Invariance
 |journal=[[Physical Review Letters]]
 |volume=89 |issue= 23|pages=231602
 |arxiv=hep-ph/0201258
 |bibcode=2002PhRvL..89w1602G
 |doi=10.1103/PhysRevLett.89.231602
 |pmid=12484997
}}&lt;/ref&gt; If correct, this would imply that any study of CPT violation also includes Lorentz violation. However, Chaichian ''et al'' later disputed the validity of Greenberg's result.&lt;ref name="Chaichian2011"&gt;
{{cite journal |last=Chaichian |first=M. |last2=Dolgov |first2=A. D. |last3=Novikov |first3=V. A. |last4=Tureanu |first4=A. |year=2011 |title=CPT Violation Does Not Lead to Violation of Lorentz Invariance and Vice Versa |arxiv=1103.0168 |doi=10.1016/j.physletb.2011.03.026 |journal=[[Physics Letters B]] |volume=699 |issue=3 |pages=177â180|bibcode = 2011PhLB..699..177C }}&lt;/ref&gt; Greenberg replied that the model used in their paper meant that their "proposed objection was not relevant to my result".&lt;ref&gt;{{Cite journal|author=Greenberg, O. W.|title=Remarks on a challenge to the relation between CPT and Lorentz violation|date=4 May 2011|arxiv=1105.0927|bibcode = 2011arXiv1105.0927G|quote=The objection &amp;#91;{{arXiv|1103.0168}}&amp;#93; to my theorem &amp;#91;{{arXiv|hep-ph/0201258}}&amp;#93; that violation of CPT symmetry implies violation of Lorentz covariance is based on a nonlocal model in which time-ordered products are not well defined. I used covariance of time-ordered products as the condition for Lorentz covariance; therefore the proposed objection is not relevant to my result.}}&lt;/ref&gt;

The overwhelming majority of [[Modern searches for Lorentz violation|experimental searches for Lorentz violation]] have yielded negative results. A detailed tabulation of these results was given in 2011 by Kostelecky and Russell.&lt;ref name="DataTables"&gt;
{{cite journal
 |last=KosteleckÃ½ |first=V. A.
 |last2=Russell |first2=N.
 |title=Data tables for Lorentz and ''CPT'' violation
 |year=2011
 |journal=[[Reviews of Modern Physics]]
 |volume=83 |issue=1 |pages=11â31
 |arxiv=0801.0287
 |bibcode=2011RvMP...83...11K
 |doi=10.1103/RevModPhys.83.11
 }}&lt;/ref&gt;

==See also==

*[[PoincarÃ© group|PoincarÃ© symmetry]] and [[Quantum field theory]]
*[[Parity (physics)]], [[Charge conjugation]] and [[T-symmetry]]
*[[CP violation]] and [[kaon]]
*[[Gravitational interaction of antimatter#CPT theorem]]

==References==
&lt;references/&gt;

==Sources==
*{{cite book|author=Sozzi, M.S.|title=Discrete symmetries and CP violation|publisher=Oxford University Press|year=2008|isbn=978-0-19-929666-8}}
*{{cite book |author=Griffiths, David J. |title=Introduction to Elementary Particles |publisher=Wiley, John &amp; Sons, Inc |year=1987 |isbn=978-0-471-60386-3}}
*{{cite book |author=[[R. F. Streater]] and [[A. S. Wightman]] |title=PCT, spin and statistics, and all that|publisher=Benjamin/Cummings |year=1964 |isbn=978-0-691-07062-9}}

==External links==
*[http://www.physics.indiana.edu/~kostelec/faq.html Background information on Lorentz and CPT violation] by [[Alan KosteleckÃ½]] at Theoretical Physics Indiana University
*[https://arxiv.org/abs/0801.0287 Data Tables for Lorentz and CPT Violation] at the [[arXiv]]
*[http://www.arxiv.org/abs/math-ph/0012006 The Pin Groups in Physics: C, P, and T] at the [[arXiv]]
*[http://www.lbl.gov/abc/wallchart/chapters/05/2.html Charge, Parity, and Time Reversal (CPT) Symmetry] at [[Lawrence Berkeley National Laboratory|LBL]]
*[http://pdg.lbl.gov/2006/reviews/cpt_s011254.pdf CPT Invariance Tests in Neutral Kaon Decay] at [[Lawrence Berkeley National Laboratory|LBL]]
*[https://arxiv.org/abs/hep-th/0010074 Space--Time Symmetry, CPT and Mirror Fermions] at the [[arXiv]] â 8-component theory for fermions in which ''T-parity'' &lt;!-- (''P-parity'' ?) --&gt; can be a complex number with unit radius. The CPT invariance is not a theorem but a ''better to have'' property in these class of theories.
*[https://www.youtube.com/watch?v=yArprk0q9eE This Particle Breaks Time Symmetry] â [[YouTube]] video by [[Veritasium]]

&lt;!-- footer templates --&gt;
{{C, P and T}}

{{DEFAULTSORT:Cpt Symmetry}}
&lt;!-- categories --&gt;
[[Category:Quantum field theory]]
[[Category:Symmetry]]
[[Category:Theorems in quantum physics]]</text>
      <sha1>dhgkurcpkcbecedw2y7s6lea6te3dxy</sha1>
    </revision>
  </page>
  <page>
    <title>Chisini mean</title>
    <ns>0</ns>
    <id>1081339</id>
    <revision>
      <id>815974699</id>
      <parentid>815974661</parentid>
      <timestamp>2017-12-18T12:20:26Z</timestamp>
      <contributor>
        <username>No identd</username>
        <id>32135107</id>
      </contributor>
      <minor/>
      <comment>/* See also */ Fix typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="958">{{Math-stub}}

In [[mathematics]], a function ''f'' of ''n'' variables 

:''x''&lt;sub&gt;1&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt; 

leads to a '''Chisini mean''' ''M'' if for every vector &amp;lt;x&lt;sub&gt;1&lt;/sub&gt; ... x&lt;sub&gt;n&lt;/sub&gt;&amp;gt;, there exists a unique ''M'' such that 

:''f''(''M'',''M'', ..., ''M'') = ''f''(''x''&lt;sub&gt;1&lt;/sub&gt;,''x''&lt;sub&gt;2&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;).

The [[arithmetic mean|arithmetic]], [[harmonic mean|harmonic]], [[geometric mean|geometric]], [[generalised mean|generalised]], [[Heronian mean|Heronian]] and [[quadratic mean|quadratic]] means are all Chisini means, as are their weighted variants.

They were introduced by [[Oscar Chisini]] in 1929.

== See also ==
* [[FrÃ©chet mean]]
* [[Generalized mean]]
* [[Jensen's inequality]]
* [[Quasi-arithmetic mean]]
* [[Stolarsky mean]]

==References==
*Chisini, O. "Sul concetto di media." Periodico di Matematiche 4, 106&amp;ndash;116, 1929.

[[Category:Mathematical analysis]]
[[Category:Means]]</text>
      <sha1>drf7ncfcj69tzeqpv82t7qmd4hob1d4</sha1>
    </revision>
  </page>
  <page>
    <title>Classifier (UML)</title>
    <ns>0</ns>
    <id>7585515</id>
    <revision>
      <id>835813048</id>
      <parentid>834027928</parentid>
      <timestamp>2018-04-10T22:38:32Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>rm obsolete tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2216">{{Refimprove|date=October 2006}}
A '''classifier''' is a category of [[Unified Modeling Language]] (UML) [[UML element|elements]] that have some common features, such as [[Attribute (computing)|attribute]]s or [[Method (computer science)|method]]s.&lt;ref&gt;{{Cite web|url=http://www.uml-diagrams.org/classifier.html|title=UML Classifier|accessdate=December 7, 2012}}&lt;/ref&gt;

==Overview==
A classifier is an [[Abstraction (computer science)|abstract]] [[metaclass]] classification concept that serves as a mechanism to show [[interface (computer science)|interfaces]], [[Class (computer science)|classes]], [[datatypes]] and [[component diagram|components]].

A classifier describes a [[set (computer science)|set]] of [[instantiation (computer science)|instances]] that have common behavioral and structural features ([[Instruction (computer science)|operations]] and [[attribute (computing)|attributes]], respectively).

A classifier is a [[namespace]] whose [[method (computer science)|members]] can specify a generalization hierarchy by referencing its general classifiers.

A classifier is a type and can own generalizations, thereby making it possible to define generalization relationships to other classifiers.

A classifier is a redefinable element, as it is possible to redefine nested classifiers.

All [[Object (computer science)|objects]] that can have instances are classifiers.

==Important aspects==
*A classifier defines a [[namespace]].
*A classifier contains a set of features.
*A classifier is [[Class Diagram#Generalization|generalizable]].

==Types of UML classifiers==
*[[Class (computer science)|Class]]
*[[Component diagram|Component]]
*[[Datatype]]
*[[Interface (computer science)|Interface]]
*[[Vertex (graph theory)|Node]]
*Signal
*[[Subsystem]]
*[[Use Case]]

==Predefined UML classifiers==
*[[Actor (UML)|Actor]]
*[[Association (object-oriented programming)|Association]]
*[[Class (computer science)|Class]]
*[[Component diagram|Component]]
*[[Datatype]]
*[[Interface (computer science)|Interface]]
*[[Vertex (graph theory)|Node]]
*Signal
*[[Subsystem]]
*[[Use Case]]

==References==
{{Reflist}}

{{UML}}

{{DEFAULTSORT:Classifier (Uml)}}
[[Category:Unified Modeling Language]]


{{uml-stub}}</text>
      <sha1>ffjh7j9ejnkwhgotufmymrre284ahgk</sha1>
    </revision>
  </page>
  <page>
    <title>Compound of tesseract and 16-cell</title>
    <ns>0</ns>
    <id>59133525</id>
    <revision>
      <id>871587245</id>
      <parentid>871486221</parentid>
      <timestamp>2018-12-02T03:16:49Z</timestamp>
      <contributor>
        <username>Tomruen</username>
        <id>63601</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3678">{| class=wikitable align="right" width="280"
!bgcolor=#e7dcc3 colspan=2|Tesseract 16-cell compound
|-
|bgcolor=#e7dcc3|Type||Compound
|-
|bgcolor=#e7dcc3|[[SchlÃ¤fli symbol]]||{4,3,3} âª {3,3,4}
|-
|bgcolor=#e7dcc3|[[Coxeter diagram]]||{{CDD|node_1|4|node|3|node|3|node}} âª {{CDD|node|4|node|3|node|3|node_1}}
|-
|bgcolor=#e7dcc3|Intersection||[[bitruncated tesseract]]
|-
|bgcolor=#e7dcc3|Convex hull||[[24-cell]]
|-
|bgcolor=#e7dcc3|Polychora||2:&lt;BR&gt;1 [[tesseract]]&lt;BR&gt;1 [[16-cell]]
|-
|bgcolor=#e7dcc3|Polyhedra||24:&lt;BR&gt;8 [[cube]]s&lt;BR&gt;16 [[tetrahedra]]
|-
|bgcolor=#e7dcc3|Faces||56:&lt;BR&gt;24 squares&lt;BR&gt;32 triangles
|-
|bgcolor=#e7dcc3|Edges||56
|-
|bgcolor=#e7dcc3|Vertices||24
|-
|bgcolor=#e7dcc3|[[Symmetry group]]||[[Hyperoctahedral symmetry]]&lt;BR&gt;[4,3,3], order 384
|}
In 4-dimensional [[geometry]], the '''tesseract 16-cell compound'''&lt;ref&gt;{{KlitzingPolytopes|../explain/compound.htm|Compound polytopes}}&lt;/ref&gt; is a [[polytope compound]] composed of a regular [[tesseract]] and dual regular [[16-cell]]. A ''compound polytope'' is a figure that is composed of several polytopes sharing a common center. The outer vertices of a compound can be connected to form a [[convex polytope]] called the [[convex hull]]. The compound is a [[facetting]] of the convex hull.

In 4-polytope compounds constructed as dual pairs, cells and vertices swap positions and faces and edges swap positions. Because of this the number of cells and vertices are equal, as are faces and edges. Mid-edges of the tesseract cross mid-face in the 16-cell, and vice versa.

It can be seen as the 4-dimensional analogue of a [[compound of cube and octahedron]].

==Construction==

The 24 [[Cartesian coordinate]]s of the vertices of the compound are.
:  8: (Â±2, 0, 0, 0), ( 0, Â±2, 0, 0), ( 0, 0, Â±2, 0), ( 0, 0, 0, Â±2)
: 16: ( Â±1, Â±1, Â±1, Â±1)

These are the first two vertex sets of the [[stellation]]s of a 16-cell.&lt;ref name=chilton&gt;[https://www.jstor.org/stable/2314564 The Stellated Forms of the Sixteen-Cell]  B. L. Chilton The American Mathematical Monthly Vol. 74, No. 4 (Apr., 1967), pp. 372â378&lt;/ref&gt;

== Faceting==
The [[convex hull]] is the self-dual regular [[24-cell]], which is also a ''rectified 16-cell''. This makes it a [[faceting]] of the 24-cell.

The intersection of the tesseract and 16-cell compound is the uniform [[bitruncated tesseract]]: {{CDD|branch_11|4a3b|nodes}} = {{CDD|branch|4a3b|nodes_10l}} â© {{CDD|branch|4a3b|nodes_01l}}.

{| class=wikitable
|+ Graphs in B4 [[Coxeter plane]]
!colspan=2|Elements||Compound||Convex hull||Intersection
|- align=center
|[[File:4-cube t0.svg|160px]]&lt;BR&gt;Tesseract
|[[File:4-cube t3.svg|160px]]&lt;BR&gt;16-cell
|[[File:Cubeorthoplex-4 B4.svg|160px]]&lt;BR&gt;Tesseract and 16-cell
|[[File:24-cell t0 B4.svg|160px]]&lt;BR&gt;Self dual 24-cell
|[[File:4-cube t12.svg|160px]]&lt;BR&gt;Bitruncated tesseract
|-
!{{CDD|node_1|4|node|3|node|3|node}}
!{{CDD|node|4|node|3|node|3|node_1}}
!{{CDD|node_1|4|node|3|node|3|node}} âª {{CDD|node|4|node|3|node|3|node_1}}
!{{CDD|node_1|3|node|4|node|3|node}} = {{CDD|node_f1|3|node|4|node|3|node}} = {{CDD|node|4|node|3|node_f1|3|node}}
!{{CDD|node|4|node_1|3|node_1|3|node}}
|}

== See also ==
* [[Compound of 5-cube and 5-orthoplex]]

== References==
{{reflist}}
* {{MathWorld|title=Tesseract|urlname=Tesseract}}
* {{mathworld|title=16-Cell|urlname=16-Cell}}

== External links==
*[https://robertlovespi.net/2013/04/18/compound-of-the-tesseract-and-its-dual-the-16-cell Compound of the Tesseract and Its Dual, the 16-Cell]
*[https://robertlovespi.net/2013/02/06/rotating-compound-of-the-tesseract-and-its-dual Rotating Compound of the Tesseract and Its Dual]
{{Geometry-stub}}
[[Category:Polyhedral compounds]]</text>
      <sha1>k6tzyc9jzdzyj6xdkcoq14pfgjiyzc0</sha1>
    </revision>
  </page>
  <page>
    <title>David E. Shaw</title>
    <ns>0</ns>
    <id>2361708</id>
    <revision>
      <id>869064906</id>
      <parentid>866319120</parentid>
      <timestamp>2018-11-16T04:51:52Z</timestamp>
      <contributor>
        <username>Timothymarcc</username>
        <id>11170655</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9257">{{Infobox person
| name = David Shaw
|birth_name        = David Elliot Shaw
| birth_date  = {{birth date and age|1951|3|29}}
| alma_mater  = [[University of California, San Diego]] &lt;br&gt;[[Stanford University]]
| occupation  = Investor, computer scientist, and [[Hedge fund|hedge fund manager]]
| known_for = Founding and managing [[D. E. Shaw &amp; Co.]]
| net_worth   = [[US$]] 6.2 billion (June 2018)&lt;ref name=ForbesBillionaires&gt;[https://www.forbes.com/profile/david-shaw/ Forbes: "The World's Billionaires - David Shaw"] June 2018&lt;/ref&gt;
| spouse      = [[Beth Kobliner]]
}}

'''David Elliot Shaw''' (born March 29, 1951) is an American investor, computer scientist, and [[Hedge fund|hedge fund manager]]. He founded [[D. E. Shaw &amp; Co.]], a hedge fund company which was once described by ''[[Fortune (magazine)|Fortune]]'' magazine as "the most intriguing and mysterious force on Wall Street".&lt;ref name="fortune"&gt;{{cite web|url=http://money.cnn.com/magazines/fortune/fortune_archive/1996/02/05/207353/index.htm| title=Wall Street's King Quant David Shaw's Secret Formulas Pile Up Money. Now He Wants a Piece of the Net.|date=5 Feb 1996|last=Aley|first=James|work=Fortune|accessdate=21 Aug 2009}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://investing.businessweek.com/businessweek/research/stocks/private/person.asp?personId=232164|title=EXECUTIVE PROFILE: David Elliot Shaw Ph.D.|publisher=BusinessWeek}}&lt;/ref&gt; A former faculty member in the computer science department at [[Columbia University]], Shaw made his fortune exploiting inefficiencies in financial markets with the help of state-of-the-art high speed computer networks. In 1996, ''[[Fortune (magazine)|Fortune]]'' magazine referred to him as "King Quant" because of his firm's pioneering role in high-speed [[quantitative trading]].&lt;ref name="fortune" /&gt; In 2001, Shaw turned to full-time scientific research in computational biochemistry, more specifically [[molecular dynamics]] simulations of proteins.&lt;ref name=Nature&gt;{{cite news|last=Borrell|first=Brendan|title=Chemistry: Power play|url=http://www.nature.com/news/2008/080116/full/451240a.html|accessdate=14 August 2012|newspaper=Nature|date=16 January 2008}}&lt;/ref&gt;

==Early life and education==
Shaw received a bachelor's degree ''[[Latin honors|summa cum laude]]'' from the [[University of California, San Diego]] and obtained his PhD from [[Stanford University]] in 1980, then became a faculty member of the Department of Computer Science at [[Columbia University]].&lt;ref&gt;{{cite web|url=https://www.forbes.com/lists/2009/54/rich-list-09_David-E-Shaw_201Q.html|title=David E. Shaw|publisher=Forbes|accessdate=18 March 2013}}&lt;/ref&gt; While at Columbia, Shaw conducted research in [[massively parallel computing]] with the NON-VON supercomputer. This supercomputer was composed of processing elements in a [[tree structure]] meant to be used for fast [[relational database]] searches. Earlier in his career, he founded Stanford Systems Corporation.

==Investment career==
In 1986, he joined [[Morgan Stanley]], as vice president for technology in Nunzio Tartaglia's automated [[proprietary trading]] group. In 1994, Shaw was appointed by President Clinton to the President's Council of Advisors on Science and Technology, where he was chairman of the Panel on Educational Technology. In 2000, he was elected to the board of directors of the [[American Association for the Advancement of Science]] served as its treasurer 2000-2010. In 2007, Shaw was elected as a fellow of the [[American Academy of Arts and Sciences]]. In 2009, he was appointed by President [[Barack Obama|Obama]] again to the President's Council of Advisors on Science and Technology.&lt;ref&gt;{{cite web|url=http://www.ostp.gov/cs/pcast|title=PCAST Home Page}}&lt;/ref&gt; In 2012, he was elected to the National Academy of Engineering and in 2014 was elected to the [[National Academy of Sciences]].

===D. E. Shaw===
In 1988 he started his own [[hedge fund]], "D. E. Shaw &amp; Co.", which employed proprietary algorithms for securities trading. In 2018, ''[[Forbes]]'' estimated his [[wealth]] at $6.2 billion. He is also a [http://systemsbiology.columbia.edu/center-for-computational-biology-and-bioinformatics-c2b2 Senior Research Fellow at the Center for Computational Biology and Bioinformatics] at [[Columbia University]] and an Adjunct Professor of Biomedical Informatics at Columbia's medical school. Shaw is Chief Scientist of [[D. E. Shaw Research]], which conducts interdisciplinary research in the field of computational biochemistry.

According to the Institutional Investorâs ''Alpha'' magazine's annual ranking for 2014,&lt;ref name="Alpha_2015"&gt;{{citation |title=The 2015 Rich List: The Highest Earning Hedge Fund Managers of the Past Year |date=5 May 2015 |accessdate=23 June 2015 |first=Stephen |last=Taub |url=http://www.institutionalinvestorsalpha.com/Article/3450284/The-2015-Rich-List-The-Highest-Earning-Hedge-Fund-Managers-of-the-Past-Year.html?Print=true |work=Alpha }}&lt;/ref&gt; D. E. Shaw, who made $530 million in 2014, and  [[James H. Simons]] of [[Renaissance Technologies]]&lt;ref name="Renaissance_Man"&gt;{{cite news|title=Renaissance's Man: James Simons Does The Math on Fund|last=Zuckerman|first=Gregory|date=2005-07-01|work=[[The Wall Street Journal]]}}&lt;/ref&gt; who made $1.2 billion were among the top 25 earners in the hedge fund industry. They are both "quantitative strategists who founded firms that build algorithms for trading."&lt;ref name="NYT_2015_05"&gt;{{citation |url=http://news.blogs.nytimes.com/2015/05/05/morning-agenda-big-paychecks-despite-tough-year/?_r=0 |title=Morning Agenda: Big Paychecks Despite Tough Year |work=New York Times blog |date=5 May 2015 |accessdate=23 June 2015 }}&lt;/ref&gt;

==Political and philanthropic donations==
Shaw has donated US$2.25 million to [[Priorities USA Action]], a [[super PAC]] supporting [[Democratic Party (United States)|Democratic]] presidential candidate [[Hillary Clinton presidential campaign, 2016|Hillary Clinton]].&lt;ref&gt;{{cite news |date=May 27, 2016 |title= The Top Donors Backing Hillary Clinton's Super PAC |url=https://www.forbes.com/sites/ivonaiacob/2016/05/27/top-donors-hillary-clinton-superpac/#259f3ea42740 |newspaper=Forbes }}&lt;/ref&gt;

Through the Shaw Family Endowment Fund, by 2014 he and his wife have donated $1 million to [[Organizing for Action]], $400,000 to the [[Stephen Wise Free Synagogue]], $400,000 to [[Memorial Sloan Kettering Cancer Center]], $1 million to [[Yale University]], $800,000 to the [[Horace Mann School]], $1 million to [[Stanford University]], and $1 million to [[Harvard University]].&lt;ref name=NPQ&gt;{{Cite web|last=Cohen |first=Rick  |authorlink= |title= Philanthropically Speaking, Who are the Donors to Organizing for Action?  |publisher=[[Nonprofit Quarterly]]|date= June 20, 2014|url=https://nonprofitquarterly.org/2014/06/20/the-philanthropic-identities-of-donors-to-organizing-for-action/  |accessdate=}}&lt;/ref&gt; Shaw is also on the board of the [[American Association for the Advancement of Science]].&lt;ref name=NPQ /&gt;

==Personal life==
Shaw is married to personal finance commentator and journalist [[Beth Kobliner]].&lt;ref&gt;[http://therealdeal.com/blog/2012/08/01/hedge-funder-spend-75m-on-westchester-manse/ The Real Deal: "Hedge funder spends $75M on Westchester manse"] August 01, 2012&lt;/ref&gt;&lt;ref name=NPQ /&gt; They are members of the [[Stephen Wise Free Synagogue]] in New York.&lt;ref&gt;{{cite web |url=http://www.swfs.org/tikkun-olam-center-for-values-and-community-service/ |title=Archived copy |accessdate=2013-04-29 |deadurl=yes |archiveurl=https://archive.is/20130415213049/http://www.swfs.org/tikkun-olam-center-for-values-and-community-service/ |archivedate=2013-04-15 |df= }}&lt;/ref&gt;

==See also==
*[[List of computer scientists]]
*[[Computational chemistry]]

==References==
{{Reflist}}

==External links==
*[http://www.deshawresearch.com/ D. E. Shaw Research]
*[https://www.youtube.com/watch?v=Ve5xdqoh1bs New Architectures for a New Biology - a 2006 lecture by David E. Shaw for the Stanford University Computer Systems Colloquium] 
*[https://web.archive.org/web/20100908162123/http://www.thedeal.com/newsweekly/2010/june-7-2010/vc-mecca-on-the-hudson.php The Deal Weekly News]
*[http://systemsbiology.columbia.edu/faculty/david-e-shaw David E. Shaw] at Columbia Systems Biology
*[http://www.deshawresearch.com/people_chiefscientist.html Bio and photo at D. E. Shaw Research website]

{{Authority control}}

{{DEFAULTSORT:Shaw, David E.}}
[[Category:1951 births]]
[[Category:American Jews]]
[[Category:American biochemists]]
[[Category:American billionaires]]
[[Category:American chief executives]]
[[Category:American computer scientists]]
[[Category:American hedge fund managers]]
[[Category:American investors]]
[[Category:American money managers]]
[[Category:American philanthropists]]
[[Category:American stock traders]]
[[Category:Columbia School of Engineering and Applied Science alumni]]
[[Category:Columbia University faculty]]
[[Category:Stanford University alumni]]
[[Category:University of California, San Diego alumni]]
[[Category:Members of the United States National Academy of Engineering]]
[[Category:Members of the United States National Academy of Sciences]]
[[Category:Mathematical finance]]
[[Category:Computational chemists]]
[[Category:Living people]]</text>
      <sha1>eqx5toq357hrcdtbrek13cukvynjqh1</sha1>
    </revision>
  </page>
  <page>
    <title>Dependability</title>
    <ns>0</ns>
    <id>661384</id>
    <revision>
      <id>856524804</id>
      <parentid>856524175</parentid>
      <timestamp>2018-08-25T21:02:45Z</timestamp>
      <contributor>
        <username>DrJFMeyer</username>
        <id>34497367</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14022">In [[systems engineering]], '''dependability''' is a measure of a system's '''availability''', '''reliability''', and its '''maintainability''', and '''maintenance support performance''', and, in some cases, other characteristics such as '''durability''', '''safety''' and '''security'''.&lt;ref&gt; IEC, ''Electropedia del 192 Dependability'', http://www.electropedia.org, select 192 Dependability, see 192-01-22 Dependability.&lt;/ref&gt;  In [[software engineering]], '''dependability''' is the ability to provide services that can defensibly be trusted within a time-period.&lt;ref&gt;R. Kumar, S. A. Khan and R. A. Khan, Revisiting Software Security: Durability Perspective, International Journal of Hybrid Information Technology (SERSC) Vol.8, No.2 pp.311-322, 2015.&lt;/ref&gt; This may also encompass mechanisms designed to increase and maintain the dependability of a system or software.&lt;ref name="A. Avizienis, J pp. 11-33"&gt;A. Avizienis, J.-C. Laprie, [[Brian Randell]], and C. Landwehr, "[http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?&amp;arnumber=1335465 Basic Concepts and Taxonomy of Dependable and Secure Computing]," IEEE Transactions on Dependable and Secure Computing, vol. 1, pp. 11-33, 2004.&lt;/ref&gt;

The [[International Electrotechnical Commission]] (IEC), via its Technical Committee [[International Electrotechnical Commission#External links|TC 56]] develops and maintains international standards that provide systematic methods and tools for dependability assessment and management of equipment, services, and systems throughout their life cycles.

Dependability can be broken down into three elements:
* '''Attributes''' - A way to assess the dependability of a system
* '''Threats''' - An understanding of the things that can affect the dependability of a system
* '''Means''' - Ways to increase a system's dependability 

== History ==
Some sources hold that word was coined in the nineteen-teens in Dodge Brothers automobile print advertising. But the word predates that period, with the [[Oxford English Dictionary]] finding its first use in 1901.

As interest in fault tolerance and system reliability increased in the 1960s and 1970s, dependability came to be a measure of [x] as measures of [[Reliability engineering|reliability]] came to encompass additional measures like safety and integrity.&lt;ref&gt;[[Brian Randell]], "Software Dependability: A Personal View", in the Proc of the 25th International Symposium on Fault-Tolerant Computing (FTCS-25), California, USA, pp 35-41, June 1995.&lt;/ref&gt;  In the early 1980s, Jean-Claude Laprie thus chose ''dependability'' as the term to encompass studies of fault tolerance and system reliability without the extension of meaning inherent in ''reliability''.&lt;ref name="ReferenceA"&gt;J.C. Laprie. "Dependable Computing and Fault Tolerance: Concepts and terminology," in Proc. 15th IEEE Int. Symp. on Fault-Tolerant Computing, 1985&lt;/ref&gt;

The field of dependability has evolved from these beginnings to be an internationally active field of research fostered by a number of prominent international conferences, notably the [[International Conference on Dependable Systems and Networks]], the [[SRDS|International Symposium on Reliable Distributed Systems]] and the [[ISSRE|International Symposium on Software Reliability Engineering]].

Traditionally, dependability for a system incorporates [[availability]], [[reliability engineering|reliability]], [[maintainability]] but since the 1980s, [[safety]] and [[security]] have been added to measures of dependability.&lt;ref&gt;A. Avizienis, J.-C. Laprie and [[Brian Randell]]: ''[http://www.cert.org/research/isw/isw2000/papers/56.pdf Fundamental Concepts of Dependability]''. Research Report No 1145, [[Laboratory_for_Analysis_and_Architecture_of_Systems|LAAS-CNRS]], April 2001&lt;/ref&gt;

== Elements of dependability ==
=== Attributes ===

[[Image:dep-1.svg|thumb|Taxonomy showing relationship between Dependability &amp; Security and Attributes, Threats and Means (after Laprie et al.)]]

Attributes are qualities of a system. These can be assessed to determine its overall dependability using [[qualitative data|Qualitative]] or [[quantitative property|Quantitative]] measures. Avizienis et al. define the following Dependability Attributes:

* [[Availability]] - readiness for correct service
* [[Reliability engineering|Reliability]] - continuity of correct service
* [[Safety]] - absence of catastrophic consequences on the user(s) and the environment
* [[Integrity]] -  absence of improper system alteration
* [[Maintainability]] -  ability for a process to undergo modifications and repairs

As these definitions suggested, only Availability and Reliability  are quantifiable by direct measurements whilst others are more subjective. For instance Safety cannot be measured directly via metrics but is a subjective assessment that requires judgmental information to be applied to give a level of confidence, whilst Reliability can be measured as failures over time.

[[Confidentiality]], i.e. ''the absence of unauthorized disclosure of information'' is also used when addressing security. Security is a composite of [[Confidentiality]], [[Integrity]], and [[Availability]]. Security is sometimes classed as an attribute &lt;ref&gt;I. Sommerville, Software Engineering: Addison-Wesley, 2004.&lt;/ref&gt; but the current view is to aggregate it together with dependability and treat Dependability as a composite term called Dependability and Security.&lt;ref name="A. Avizienis, J pp. 11-33" /&gt;

Practically, applying security measures to the appliances of a system generally improves the dependability by limiting the number of externally originated errors.

=== Threats ===

Threats are things that can affect a system and cause a drop in Dependability. There are three main terms that must be clearly understood: 

* Fault: A fault (which is usually referred to as a bug for historic reasons) is a defect in a system. The presence of a fault in a system may or may not lead to a failure. For instance, although a system may contain a fault, its input and state conditions may never cause this fault to be executed so that an error occurs; and thus that particular fault never exhibits as a failure.
* Error: An error is a discrepancy between the intended behaviour of a system and its actual behaviour inside the system boundary. Errors occur at runtime when some part of the system enters an unexpected state due to the activation of a fault. Since errors are generated from invalid states they are hard to observe without special mechanisms, such as debuggers or debug output to logs.
* Failure:  A failure is an instance in time when a system displays behaviour that is contrary to its specification. An error may not necessarily cause a failure, for instance an exception may be thrown by a system but this may be caught and handled using fault tolerance techniques so the overall operation of the system will conform to the specification.

It is important to note that Failures are recorded at the system boundary. They are basically Errors that have propagated to the system boundary and have become observable.
Faults, Errors and Failures operate according to a mechanism. This mechanism is sometimes known as a Fault-Error-Failure chain.&lt;ref&gt;A. Avizienis, V. Magnus U, J. C. Laprie, and [[Brian Randell]], "Fundamental Concepts of Dependability," presented at ISW-2000, Cambridge, MA, 2000.&lt;/ref&gt; As a general rule a fault, when activated, can lead to an error (which is an invalid state) and the invalid state generated by an error may lead to another error or a failure (which is an observable deviation from the specified behaviour at the system boundary).

Once a fault is activated an error is created. An error may act in the same way as a fault in that it can create further error conditions, therefore an error may propagate multiple times within a system boundary without causing an observable failure. If an error propagates outside the system boundary a failure is said to occur. A failure is basically the point at which it can be said that a service is failing to meet its specification. Since the output data from one service may be fed into another, a failure in one service may propagate into another service as a fault so a chain can be formed of the form: Fault leading to Error leading to Failure leading to Error, etc.

=== Means ===

Since the mechanism of a Fault-Error-Chain is understood it is possible to construct means to break these chains and thereby increase the dependability of a system.
Four means have been identified so far:
# Prevention
# Removal
# Forecasting
# Tolerance

Fault Prevention deals with preventing faults being incorporated into a system. This can be accomplished by use of development methodologies and good implementation techniques.

Fault Removal can be sub-divided into two sub-categories: Removal During Development and Removal During Use.&lt;br&gt;
Removal during development requires verification so that faults can be detected and removed before a system is put into production. Once systems have been put into production a system is needed to record failures and remove them via a maintenance cycle.

Fault Forecasting predicts likely faults so that they can be removed or their effects can be circumvented.

[[Fault Tolerance]] deals with putting mechanisms in place that will allow a system to still deliver the required service in the presence of faults, although that service may be at a degraded level.

Dependability means are intended to reduce the number of failures presented to the user of a system. Failures are traditionally recorded over time and it is useful to understand how their frequency is measured so that the effectiveness of means can be assessed.11

== Dependability of information systems and survivability ==

Recent works, such &lt;ref&gt;John C. Knight, Elisabeth A. Strunk, Kevin J. Sullivan: ''[http://www.cs.virginia.edu/papers/discex.2003.pdf Towards a Rigorous Definition of Information System Survivability] {{webarchive|url=https://web.archive.org/web/20061029012406/http://www.cs.virginia.edu/papers/discex.2003.pdf |date=2006-10-29 }}''&lt;/ref&gt; upon dependability take benefit of structured '''[[information system]]s''', e.g. with [[Service-oriented architecture|SOA]], to introduce a more efficient ability, the '''[[survivability]]''', thus taking into account the degraded services that an Information System sustains or resumes after a non-maskable failure.

The flexibility of current frameworks encourage system architects to enable reconfiguration mechanisms that refocus the available, safe resources to support the most critical services rather than over-provisioning to build failure-proof system.

With the generalisation of networked information systems, '''[[accessibility]]''' was introduced to give greater importance to users' experience.

To take into account the level of performance, the measurement of '''[[performability]]''' is defined as "quantifying how well the object system performs in the presence of faults over a specified period of time".&lt;ref&gt;John F. Meyer, William H. Sanders ''[http://web.eecs.umich.edu/people/jfm/PMCCS-2.pdf Specification and construction of performability models]''&lt;/ref&gt;

== See also ==
* [[Dependable Systems and Networks]]
* [[Fault injection]]
* [[Fault-tolerance]]
* [[Formal methods]]
* [[List of system quality attributes]]
* [[RAMS]]
* [[Reliability engineering]]
* [[Safety engineering]]

== Further reading ==
=== Papers ===
* Wilfredo Torres-Pomales: ''[http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.108.7270 Software Fault Tolerance: A Tutorial]'', 2002
* Stefano Porcarelli, Marco Castaldi, Felicita Di Giandomenico, Andrea Bondavalli, Paola Inverardi ''[http://www.cs.kent.ac.uk/events/conf/2003/wads/Proceedings/porcarelli.pdf An Approach to Manage Reconfiguration in Fault-Tolerant Distributed Systems]''

=== Journals ===
*[http://www.prognosticsjournal.com Prognostics Journal] is an open access journal that provides an international forum for the electronic publication of original research and industrial experience articles in all areas of systems dependability and prognostics.
* [http://www.inderscience.com/ijccbs International Journal of Critical Computer-Based Systems]
* [http://www.ft.unicamp.br/ladc2013 Latin-American Symposium on Dependeable Computing]

=== Books ===
* J.C. Laprie, ''Dependability: Basic Concepts and Terminology'' Springer-Verlag, 1992. {{ISBN|0-387-82296-8}}

=== Research projects ===
* [http://www.deserec.eu DESEREC], ''DEpendability and Security by Enhanced REConfigurability'', [[Sixth Framework Programme|FP6]]/IST integrated project 2006â2008
* [http://nodes.imm.dtu.dk:8080 NODES]{{dead link|date=December 2017 |bot=InternetArchiveBot |fix-attempted=yes }}, ''Network on DEpendable Systems''
* ESFORS, ''European security Forum for Web Services, Software, and Systems'', FP6/IST coordination action
* [https://web.archive.org/web/20070908131928/http://www.hidenets.aau.dk/ HIDENETS] ''HIghly DEpendable ip-based NETworks and Services'', FP6/IST targeted project 2006â2008
* [http://www.resist-noe.org RESIST] FP6/IST Network of Excellence 2006â2007
* [http://rodin.cs.ncl.ac.uk RODIN] Rigorous Open Development Environment for Complex Systems FP6/IST targeted project 2004â2007
* SERENITY ''System Engineering for Security and Dependability'', FP6/IST integrated project 2006â2008
* [https://web.archive.org/web/20071031232813/http://dependability.cs.virginia.edu/research/willow/ Willow Survivability Architecture], and [https://web.archive.org/web/20071118013735/http://dependability.cs.virginia.edu/info/STILT STILT], ''System for Terrorism Intervention and Large-scale Teamwork'' 2002â2004
* [http://www.aniketos.eu ANIKETOS] ''Dependable and Secure Service Composition'', FP7/IST integrated project 2010â2014

==References==
{{Reflist}}

{{Computer science}}
[[Category:Computing terminology]]
[[Category:Safety]]
[[Category:Safety engineering]]
[[Category:Security]]
[[Category:Formal methods]]
[[Category:Quality]]</text>
      <sha1>2yoaggiub3w9k2etoeno3s1xtub14rr</sha1>
    </revision>
  </page>
  <page>
    <title>Dispersion point</title>
    <ns>0</ns>
    <id>7588072</id>
    <revision>
      <id>568301870</id>
      <parentid>560418715</parentid>
      <timestamp>2013-08-13T02:57:36Z</timestamp>
      <contributor>
        <username>EmausBot</username>
        <id>11292982</id>
      </contributor>
      <minor/>
      <comment>Bot: Migrating 1 interwiki links, now provided by [[Wikipedia:Wikidata|Wikidata]] on [[d:Q5282582]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1745">In [[topology]], a '''dispersion point''' or '''explosion point''' is a point in a topological space the removal of which leaves the space highly disconnected.

More specifically, if ''X'' is a [[connected space|connected topological space]] containing the [[point (geometry)|point]] ''p'' and at least two other points, ''p'' is a dispersion point for ''X'' if and only if &lt;math&gt;X\setminus \{p\}&lt;/math&gt; is [[totally disconnected]] (every subspace is disconnected, or, equivalently, every connected component is a single point). If ''X'' is connected and &lt;math&gt;X\setminus \{p\}&lt;/math&gt; is [[totally separated]] (for each two points ''x'' and ''y'' there exists a clopen set containing ''x'' and not containing ''y'') then ''p'' is an explosion point.  A space can have at most one dispersion point or explosion point. Every totally separated space is totally disconnected, so every explosion point is a dispersion point.

The [[KnasterâKuratowski fan]] has a dispersion point; any space with the [[particular point topology]] has an explosion point.

If ''p'' is an explosion point for a space ''X'', then the totally separated space &lt;math&gt;X\setminus \{p\}&lt;/math&gt; is said to be ''pulverized''.

==References==
*{{citation|first1=Mohammad|last1=Abry|first2=Jan J.|last2=Dijkstra|first3=Jan|last3=van Mill|title=On one-point connectifications|journal=Topology and its Applications|volume=154|issue=3|year=2007|pages=725â733|doi=10.1016/j.topol.2006.09.004|url=http://www.math.vu.nl/~vanmill/papers/papers2007/abry.pdf}}. (Note that this source uses ''hereditarily disconnected'' and ''totally disconnected'' for the concepts referred to here respectively as totally disconnected and totally separated.)

[[Category:Topology]]

{{topology-stub}}</text>
      <sha1>kwf9l7d69raf5ebszg2o4gwoss80z2f</sha1>
    </revision>
  </page>
  <page>
    <title>Electro-olfactography</title>
    <ns>0</ns>
    <id>48030765</id>
    <revision>
      <id>854465110</id>
      <parentid>849652757</parentid>
      <timestamp>2018-08-11T15:25:13Z</timestamp>
      <contributor>
        <username>Ozzie10aaaa</username>
        <id>17794675</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3048">{{Hatnote|Not to be confused with [[electrooculography]], which "EOG" usually refers to.}}
{{infobox medical equipment
| name         = Electro-olfactography
| acronym      =
| synonym      =
| image        = 
| caption      = 
| alt          = 
| image_size   = 
| specialty    = &lt;!-- from Wikidata, can be overwritten --&gt;
| intervention = 
| MedlinePlus  = 
| eMedicine    = 
| inventor     = 
| invention date = 
| manufacturer = 
| related      = 
}}
'''Electro-olfactography''' or '''electroolfactography''' ('''EOG''') is a type of electrography ([[electrophysiology|electrophysiologic]] test) that aids the study of [[olfaction]] (the sense of smell). It measures and records the changing electrical potentials of the [[olfactory epithelium]],&lt;ref name="Glatz_2015"&gt;{{Citation |editor-last=Glatz |editor-first=Richard |year=2015 |title=Molecular Basis of Olfaction. Volume 130 of Progress in Molecular Biology and Translational Science |publisher=Academic Press|page=ix |url=https://books.google.com/books?id=LFOZBQAAQBAJ&amp;lpg=PR9&amp;pg=PR9#v=onepage&amp;f=false |isbn=978-0128029138 |postscript=.}}&lt;/ref&gt; in a way similar to how other forms of electrography (such as [[electrocardiography|ECG]], [[electroencephalography|EEG]], and [[electromyography|EMG]]) measure and record other [[bioelectromagnetics|bioelectric activity]].

Electro-olfactography has been used for decades to advance the [[basic science]] of smell,&lt;ref name="Glatz_2015"/&gt;&lt;ref name="PMID_12203693"&gt;{{Cite journal |last=Scott |first=JW |last2=Scott-Johnson |first2=PE |year=2002 |title=The electroolfactogram: a review of its history and uses |journal=Microsc Res Tech |volume=58 |issue=3 |pages=152â160 |pmid=12203693 |postscript=. |doi=10.1002/jemt.10133}}&lt;/ref&gt;&lt;ref name="PMID_6524723"&gt;{{Cite journal |last=Myers |first=LJ |last2=Nash |first2=R |last3=Elledge |first3=HS |title=Electro-olfactography: a technique with potential for diagnosis of anosmia in the dog |journal=Am J Vet Res |year=1984 |volume=45 |issue=11 |pages=2296â2298 |pmid=6524723 }}&lt;/ref&gt; although the advances in [[molecular biology]] in recent decades have expanded olfactory science beyond the knowledge that the electrical recordings of electro-olfactography alone could provide.&lt;ref name="Glatz_2015"/&gt; Electro-olfactography is closely related to [[electroantennography]], the electrography of insect antennae olfaction.&lt;ref name="Glatz_2015"/&gt;
Neuroscientist David Ottoson (1918-2001) discovered the electro-olfactogram (EOG) and analysed its properties in great detail.&lt;ref name="DÃ¸ving_2003"&gt;{{Citation |last=DÃ¸ving |first=Kjell |year=2003 |title=David Ottoson (1918â2001) |journal=Chemical Senses |volume=28 |issue=2 |pages=83â84 |url=https://academic.oup.com/chemse/article/28/2/83/318851 |doi=10.1093/chemse/28.2.83 |postscript=.}}&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
* [https://www.ncbi.nlm.nih.gov/pubmed/?term=electroolfactogram Search PubMed for "electroolfactogram"]

[[Category:Electrophysiology]]
[[Category:Mathematics in medicine]]


{{med-diagnostic-stub}}</text>
      <sha1>sti1j8bahrw1s0qips1zgp5ve2m1124</sha1>
    </revision>
  </page>
  <page>
    <title>Excess-976</title>
    <ns>0</ns>
    <id>57914836</id>
    <redirect title="Offset binary" />
    <revision>
      <id>850519244</id>
      <timestamp>2018-07-16T11:35:23Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>[[WP:AES|â]]Redirected page to [[Offset binary#Excess-976]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="180">#REDIRECT [[Offset binary#Excess-976]]

{{Redirect category shell|1=
{{R to related topic}}
{{R with possibilities}}
}}

[[Category:Binary arithmetic]]
[[Category:Numeral systems]]</text>
      <sha1>l6n9w2nx2uveurwyx7zebjzwa4ts6lw</sha1>
    </revision>
  </page>
  <page>
    <title>Fast-growing hierarchy</title>
    <ns>0</ns>
    <id>24947285</id>
    <revision>
      <id>869268432</id>
      <parentid>868343706</parentid>
      <timestamp>2018-11-17T14:43:47Z</timestamp>
      <contributor>
        <ip>111.14.128.144</ip>
      </contributor>
      <comment>/* Approximate growth rates in comparison to other googological notations */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18559">In [[computability theory]], [[computational complexity theory]] and [[proof theory]], a '''fast-growing hierarchy''' (also called an '''extended [[Grzegorczyk hierarchy]]''') is an ordinal-indexed family of rapidly increasing functions ''f''&lt;sub&gt;Î±&lt;/sub&gt;: '''N''' â '''N''' (where '''N''' is the set of [[natural numbers]] {0, 1, ...}, and Î± ranges up to some large countable ordinal). A primary example is the '''Wainer hierarchy''', or '''LÃ¶bâWainer hierarchy''', which is an extension to all Î± &lt; [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]].  Such hierarchies provide a natural way to classify [[computable function]]s according to rate-of-growth and [[Computational complexity theory|computational complexity]].

==Definition==
Let Î¼ be a [[large countable ordinal]] such that a [[fundamental sequence (ordinals)|fundamental sequence]] (a strictly increasing sequence of ordinals whose supremum is a [[limit ordinal]]) is assigned to every limit ordinal less than Î¼.  A '''fast-growing hierarchy''' of functions ''f''&lt;sub&gt;Î±&lt;/sub&gt;: '''N''' â '''N''', for Î± &lt; Î¼, is then defined as follows:

*&lt;math&gt; f_0(n) = n + 1,&lt;/math&gt;
*&lt;math&gt; f_{\alpha+1}(n) = f_\alpha^n(n),&lt;/math&gt;
*&lt;math&gt; f_\alpha(n) = f_{\alpha[n]}(n) &lt;/math&gt; if Î± is a limit ordinal.

Here ''f''&lt;sub&gt;Î±&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt;(''n'') =  ''f''&lt;sub&gt;Î±&lt;/sub&gt;(''f''&lt;sub&gt;Î±&lt;/sub&gt;(...(''f''&lt;sub&gt;Î±&lt;/sub&gt;(''n''))...)) denotes the ''n''&lt;sup&gt;th&lt;/sup&gt; iterate of  ''f''&lt;sub&gt;Î±&lt;/sub&gt; applied to ''n'', and Î±[''n''] denotes the ''n''&lt;sup&gt;th&lt;/sup&gt; element of the fundamental sequence assigned to the limit ordinal Î±.  (An alternative definition takes the number of iterations to be ''n''+1, rather than ''n'', in the second line above.)

The initial part of this hierarchy, comprising the functions ''f''&lt;sub&gt;Î±&lt;/sub&gt; with ''finite'' index (i.e., Î± &lt; Ï), is often called the '''Grzegorczyk hierarchy''' because of its close relationship to the [[Grzegorczyk hierarchy]]; note, however, that the former is here an indexed family of functions ''f''&lt;sub&gt;''n''&lt;/sub&gt;, whereas the latter is an indexed family of ''sets'' of functions &lt;math&gt;\mathcal{E}^n&lt;/math&gt;. (See Points of Interest below.)

Generalizing the above definition even further, a '''fast iteration hierarchy''' is obtained by taking ''f''&lt;sub&gt;0&lt;/sub&gt; to be any increasing function g: '''N''' â '''N'''.

For limit ordinals not greater than [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]], there is a straightforward natural definition of the fundamental sequences (see the '''Wainer hierarchy''' below), but beyond [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]] the definition is much more complicated.  However, this is possible well beyond the FefermanâSchÃ¼tte ordinal, [[FefermanâSchÃ¼tte ordinal|Î&lt;sub&gt;0&lt;/sub&gt;]], up to at least the [[BachmannâHoward ordinal]]. Using [[Buchholz psi function]]s one can extend this definition easily to the ordinal of transfinitely iterated &lt;math&gt;\Pi^1_1&lt;/math&gt;-comprehension (see [[Analytical hierarchy]]).

A fully specified extension beyond the [[recursive ordinal]]s is thought to be unlikely; e.g., PrÓ§mel ''et al.'' [1991](p.&amp;nbsp;348) note that in such an attempt "there would even arise problems in ordinal notation".

==The Wainer hierarchy==

The '''Wainer hierarchy''' is the particular fast-growing hierarchy of functions ''f''&lt;sub&gt;Î±&lt;/sub&gt; (Î± â¤ [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]]) obtained by defining the fundamental sequences as follows [Gallier 1991][PrÓ§mel, et al., 1991]:

For limit ordinals Î» &lt; [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]], written in [[Cantor normal form]],

* if Î» = Ï&lt;sup&gt;Î±&lt;sub&gt;1&lt;/sub&gt;&lt;/sup&gt; + ... + Ï&lt;sup&gt;Î±&lt;sub&gt;kâ1&lt;/sub&gt;&lt;/sup&gt; + Ï&lt;sup&gt;Î±&lt;sub&gt;k&lt;/sub&gt;&lt;/sup&gt; for Î±&lt;sub&gt;1&lt;/sub&gt; â¥ ... â¥ Î±&lt;sub&gt;kâ1&lt;/sub&gt; â¥ Î±&lt;sub&gt;k&lt;/sub&gt;, then Î»[''n''] = Ï&lt;sup&gt;Î±&lt;sub&gt;1&lt;/sub&gt;&lt;/sup&gt; + ... + Ï&lt;sup&gt;Î±&lt;sub&gt;kâ1&lt;/sub&gt;&lt;/sup&gt; + Ï&lt;sup&gt;Î±&lt;sub&gt;k&lt;/sub&gt;&lt;/sup&gt;[''n''],
* if Î» = Ï&lt;sup&gt;Î±+1&lt;/sup&gt;, then Î»[''n''] = Ï&lt;sup&gt;Î±&lt;/sup&gt;''n'',
* if Î» = Ï&lt;sup&gt;Î±&lt;/sup&gt; for a limit ordinal Î±, then Î»[''n''] = Ï&lt;sup&gt;Î±[''n'']&lt;/sup&gt;,

and

* if Î» = Îµ&lt;sub&gt;0&lt;/sub&gt;, take Î»[0] = 0 and Î»[''n'' + 1] = Ï&lt;sup&gt;Î»[''n'']&lt;/sup&gt; as in [Gallier 1991]; alternatively, take the same sequence except starting with Î»[0] = 1 as in [PrÓ§mel, et al., 1991]. &lt;br&gt;For ''n'' &gt; 0, the alternative version has one additional Ï in the resulting exponential tower, i.e. Î»[''n''] = Ï&lt;sup&gt;Ï&lt;sup&gt;.&lt;sup&gt;.&lt;sup&gt;.&lt;sup&gt;Ï&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; with ''n'' omegas.

Some authors use slightly different definitions (e.g., Ï&lt;sup&gt;Î±+1&lt;/sup&gt;[''n''] = Ï&lt;sup&gt;Î±&lt;/sup&gt;(''n+1''), instead of Ï&lt;sup&gt;Î±&lt;/sup&gt;''n''), and some define this hierarchy only for Î± &lt; Îµ&lt;sub&gt;0&lt;/sub&gt; (thus excluding ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; from the hierarchy).

To continue beyond Îµ&lt;sub&gt;0&lt;/sub&gt;, see the [[Veblen function#Fundamental sequences for the Veblen hierarchy|Fundamental sequences for the Veblen hierarchy]].

==Points of interest==

Following are some relevant points of interest about fast-growing hierarchies:

* Every ''f''&lt;sub&gt;Î±&lt;/sub&gt; is a [[total function]].  If the fundamental sequences are computable (e.g., as in the Wainer hierarchy), then every ''f''&lt;sub&gt;Î±&lt;/sub&gt; is a total [[computable function]].
* In the Wainer hierarchy, ''f''&lt;sub&gt;Î±&lt;/sub&gt; is dominated by ''f''&lt;sub&gt;Î²&lt;/sub&gt; if Î± &lt; Î². (For any two functions ''f'', ''g'': '''N''' â '''N''', ''f'' is said to '''dominate''' ''g'' if ''f''(''n'') &gt; ''g''(''n'') for all sufficiently large ''n''.)  The same property holds in any fast-growing hierarchy with fundamental sequences satisfying the so-called [[Bachmann property]]. (This property holds for most natural well orderings.){{Clarify|reason=what does this mean?|date=November 2009}}
* In the Grzegorczyk hierarchy, every [[primitive recursive function]] is dominated by some ''f''&lt;sub&gt;Î±&lt;/sub&gt; with Î± &lt; Ï.  Hence, in the Wainer hierarchy, every primitive recursive function is dominated by ''f''&lt;sub&gt;Ï&lt;/sub&gt;, which is a variant of the [[Ackermann function]].
* For ''n'' â¥ 3, the set &lt;math&gt;\mathcal{E}^n&lt;/math&gt; in the [[Grzegorczyk hierarchy]] is composed of just those total multi-argument functions which, for sufficiently large arguments, are computable within time bounded by some fixed iterate ''f''&lt;sub&gt;''n''-1&lt;/sub&gt;&lt;sup&gt;''k''&lt;/sup&gt; evaluated at the maximum argument.
* In the Wainer hierarchy, every ''f''&lt;sub&gt;Î±&lt;/sub&gt; with Î± &lt; [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]] is computable and provably total in [[Peano arithmetic]].
* Every computable function that's provably total in Peano arithmetic is dominated by some ''f''&lt;sub&gt;Î±&lt;/sub&gt; with Î± &lt; [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]] in the Wainer hierarchy.  Hence ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; in the Wainer hierarchy is not provably total in Peano arithmetic.
* The [[Goodstein's theorem#Sequence length as a function of the starting value|Goodstein function]] has approximately the same growth rate (''i.e.'' each is dominated by some fixed iterate of the other) as ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; in the Wainer hierarchy, dominating every ''f''&lt;sub&gt;Î±&lt;/sub&gt; for which Î± &lt; [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]], and hence is not provably total in Peano Arithmetic.
* In the Wainer hierarchy, if Î± &lt; Î² &lt; [[Epsilon zero|Îµ&lt;sub&gt;0&lt;/sub&gt;]], then ''f''&lt;sub&gt;Î²&lt;/sub&gt; dominates every computable function within time and space bounded by some fixed iterate ''f''&lt;sub&gt;Î±&lt;/sub&gt;&lt;sup&gt;''k''&lt;/sup&gt;.
* [[Kruskal's tree theorem#Friedman's finite form|Friedman's TREE]] function dominates ''f''&lt;sub&gt;[[FefermanâSchÃ¼tte ordinal|Î&lt;sub&gt;0&lt;/sub&gt;]]&lt;/sub&gt; in a fast-growing hierarchy described by Gallier (1991).
* The Wainer hierarchy of functions ''f''&lt;sub&gt;Î±&lt;/sub&gt; and the [[Hardy hierarchy]] of functions ''h''&lt;sub&gt;Î±&lt;/sub&gt; are related by ''f''&lt;sub&gt;Î±&lt;/sub&gt; = ''h''&lt;sub&gt;Ï&lt;sup&gt;Î±&lt;/sup&gt;&lt;/sub&gt; for all Î± &lt; Îµ&lt;sub&gt;0&lt;/sub&gt;.  The Hardy hierarchy "catches up" to the Wainer hierarchy at Î± = Îµ&lt;sub&gt;0&lt;/sub&gt;, such that ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; and ''h''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; have the same growth rate, in the sense that ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;(''n''-1) â¤ ''h''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;(''n'') â¤ ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;(''n''+1) for all ''n'' â¥ 1. (Gallier 1991)
* {{harvtxt|Girard|1981}} and Cichon &amp; Wainer (1983) showed that the ''[[slow-growing hierarchy]]'' of functions ''g''&lt;sub&gt;Î±&lt;/sub&gt; attains the same growth rate as the function ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt; in the Wainer hierarchy when Î± is the [[BachmannâHoward ordinal]]. Girard (1981) further showed that the slow-growing hierarchy ''g''&lt;sub&gt;Î±&lt;/sub&gt; attains the same growth rate  as ''f''&lt;sub&gt;Î±&lt;/sub&gt; (in a particular fast-growing hierarchy) when Î± is the ordinal of the theory ''ID''&lt;sub&gt;&lt;Ï&lt;/sub&gt; of arbitrary finite iterations of an inductive definition. (Wainer 1989)

==Functions in fast-growing hierarchies==

The functions at finite levels (Î± &lt; Ï) of any fast-growing hierarchy coincide with those of the Grzegorczyk hierarchy: (using [[hyperoperation]])

* ''f''&lt;sub&gt;0&lt;/sub&gt;(''n'') = ''n'' + 1 = 2 [1] ''n'' â 1
* ''f''&lt;sub&gt;1&lt;/sub&gt;(''n'') = ''f''&lt;sub&gt;0&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt;(''n'') = ''n'' + ''n'' = 2''n'' = 2 [2] ''n''
* ''f''&lt;sub&gt;2&lt;/sub&gt;(''n'') = ''f''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt;(''n'') = 2&lt;sup&gt;''n''&lt;/sup&gt; Â· ''n'' &gt; 2&lt;sup&gt;''n''&lt;/sup&gt; = 2 [3] ''n'' for ''n'' â¥ 2
* ''f''&lt;sub&gt;''k''+1&lt;/sub&gt;(''n'') = ''f''&lt;sub&gt;''k''&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt;(''n'') &gt; (2 [''k'' + 1])&lt;sup&gt;''n''&lt;/sup&gt; ''n'' â¥ 2 [''k'' + 2] ''n'' for ''n'' â¥ 2, ''k'' &lt; Ï.

Beyond the finite levels are the functions of the Wainer hierarchy (Ï â¤ Î± â¤ Îµ&lt;sub&gt;0&lt;/sub&gt;):

* ''f''&lt;sub&gt;Ï&lt;/sub&gt;(''n'') = ''f''&lt;sub&gt;''n''&lt;/sub&gt;(''n'') &gt; 2 [''n'' + 1] ''n'' &gt; 2 [''n''] (''n'' + 3) â 3 = ''A''(''n'', ''n'') for ''n'' â¥ 4, where ''A'' is the [[Ackermann function]] (of which ''f''&lt;sub&gt;Ï&lt;/sub&gt; is a unary version).
* ''f''&lt;sub&gt;Ï+1&lt;/sub&gt;(''n'') = ''f''&lt;sub&gt;Ï&lt;/sub&gt;&lt;sup&gt;''n''&lt;/sup&gt;(''n'') â¥ f&lt;sub&gt;''n'' [''n'' + 2] ''n''&lt;/sub&gt;(''n'') for all ''n'' &gt; 0, where ''n'' [''n'' + 2] ''n'' is the ''n''&lt;sup&gt;th&lt;/sup&gt; [[Ackermann function#Ackermann numbers|Ackermann number]].
* ''f''&lt;sub&gt;Ï+1&lt;/sub&gt;(64) &gt; ''f''&lt;sub&gt;Ï&lt;/sub&gt;&lt;sup&gt;64&lt;/sup&gt;(6) &gt; [[Graham's number#Definition|Graham's number]] (= ''g''&lt;sub&gt;64&lt;/sub&gt; in the sequence defined by ''g''&lt;sub&gt;0&lt;/sub&gt; = 4, ''g''&lt;sub&gt;''k''+1&lt;/sub&gt; = 3 [''g''&lt;sub&gt;''k''&lt;/sub&gt; + 2] 3).  This follows by noting ''f''&lt;sub&gt;Ï&lt;/sub&gt;(''n'') &gt; 2 [''n'' + 1] ''n'' &gt; 3 [''n''] 3 + 2, and hence ''f''&lt;sub&gt;Ï&lt;/sub&gt;(''g''&lt;sub&gt;''k''&lt;/sub&gt; + 2) &gt; ''g''&lt;sub&gt;''k''+1&lt;/sub&gt; + 2.
* ''f''&lt;sub&gt;Îµ&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;(''n'') is the first function in the Wainer hierarchy that dominates the [[Goodstein function]].

==Approximate growth rates in comparison to other googological notations==

*&lt;math&gt; f_0(n) = n + 1,&lt;/math&gt;
*&lt;math&gt; f_1(n) = 2n,&lt;/math&gt;
*&lt;math&gt; f_2(n) = 2^n,&lt;/math&gt;
*&lt;math&gt; f_3(n) &gt; 2{\uparrow\uparrow}n &lt;/math&gt; (see [[Knuth's up-arrow notation]])
*&lt;math&gt; f_4(n) &gt; 2{\uparrow\uparrow\uparrow}n &lt;/math&gt;
*&lt;math&gt; f_m(n) &gt; 2{\uparrow^{m-1}}n &lt;/math&gt;
*&lt;math&gt; f_\omega(n) &gt; 2{\uparrow^{n-1}}n = \{ n,n,n \}&lt;/math&gt; (see [[Bird's Array Notation]])
*&lt;math&gt; f_{\omega+1}(n) = \{ n,n,1,2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega+2}(n) = \{ n,n,2,2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega+m}(n) = \{ n,n,m,2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega2}(n) = \{ n,n,n,2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega2+1}(n) = \{ n,n,1,3 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega3}(n) = \{ n,n,n,3 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega{m}}(n) = \{ n,n,n,m \}&lt;/math&gt;
*&lt;math&gt; f_{\omega{m+k}}(n) = \{ n,n,k,m+1 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^2}(n) = \{ n,n,n,n \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^3}(n) = \{ n,n,n,n,n \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^m}(n) = \{ n,n,n,...,n \}&lt;/math&gt; (m entries)
*&lt;math&gt; f_{\omega^\omega}(n) = \{ n,n,n,...,n \}&lt;/math&gt; (n entries) &lt;math&gt;= \{ n,n [2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega+1}}(n) = \{ n,n [2] 1,2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega+2}}(n) = \{ n,n [2] 1,1,2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega2}}(n) = \{ n,n [2] 1 [2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega2+1}}(n) = \{ n,n [2] 1 [2] 1,2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega3}}(n) = \{ n,n [2] 1 [2] 1 [2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega^2}}(n) = \{ n,n [3] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega^3}}(n) = \{ n,n [4] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega^{\omega}}}(n) = \{ n,n [1,2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega^{\omega^2}}}(n) = \{ n,n [1,1,2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega^{\omega^{\omega}}}}(n) = \{ n,n [1[2]2]2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_0}(n) = \{ n,n [1{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\epsilon_0+1}}(n) = \{ n,n [1[1{\backslash}2]2{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\omega^{\omega^{\epsilon_0+1}}}(n) = \{ n,n [1[1[1{\backslash}2]2{\backslash}2]2{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_1}(n) = \{ n,n [1{\backslash}3] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_2}(n) = \{ n,n [1{\backslash}4] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_\omega}(n) = \{ n,n [1{\backslash}1,2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_{\omega^{\omega}}}(n) = \{ n,n [1{\backslash}1[2]2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_{\epsilon_0}}(n) = \{ n,n [1{\backslash}1[1{\backslash}2]2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_{\epsilon_{\epsilon_0}}}(n) = \{ n,n [1{\backslash}1[1{\backslash}1[1{\backslash}2]2]2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\zeta_0}(n) = \{ n,n [1{\backslash}1{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_{\zeta_0+1}}(n) = \{ n,n [1{\backslash}2{\backslash}2] 2 \}&lt;/math&gt;

*&lt;math&gt; f_{\epsilon_{\zeta_0+\omega}}(n) = \{ n,n [1{\backslash}1,2{\backslash}2] 2 \}&lt;/math&gt;

*&lt;math&gt; f_{\epsilon_{\zeta_0+\{\epsilon_0\}}}(n) = \{ n,n [1{\backslash}1 {[1{\backslash}2]} 2{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\zeta_1}(n) = \{ n,n [1{\backslash}1{\backslash}3] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\zeta_\omega}(n) = \{ n,n [1{\backslash}1{\backslash}1,2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\zeta_{\epsilon_0}}(n) = \{ n,n [1{\backslash}1{\backslash}1[1{\backslash}2]2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\zeta_{\zeta_0}}(n) = \{ n,n [1{\backslash}1{\backslash}1[1{\backslash}1{\backslash}2]2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\eta_0}(n)  = \{ n,n [1{\backslash}1{\backslash}1{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(5,0)}(n) = \{ n,n [1{\backslash}1{\backslash}1{\backslash}1{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(6,0)}(n) = \{ n,n [1{\backslash}1{\backslash}1{\backslash}1{\backslash}1{\backslash}2] 2 \}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,0)}(n) = \{ n,n [1 [2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\epsilon_{\varphi(\omega,0)+1}}(n) = \{ n,n [1{\backslash}2[2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\zeta_{\varphi(\omega,0)+1}}(n) = \{ n,n [1{\backslash}1{\backslash}2[2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\eta_{\varphi(\omega,0)+1}}(n) = \{ n,n [1{\backslash}1{\backslash}1{\backslash}2[2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(5,{\varphi(\omega,0)+1})}(n) = \{ n,n [1{\backslash}1{\backslash}1{\backslash}1{\backslash}2[2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,1)}(n) = \{ n,n [1 [2{\neg}2] 3] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,2)}(n) = \{ n,n [1 [2{\neg}2] 4] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,\omega)}(n) = \{ n,n [1 [2{\neg}2] 1,2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,\epsilon_0)}(n) = \{ n,n [1 [2{\neg}2] 1[1{\backslash}2]2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,\zeta_0)}(n) = \{ n,n [1 [2{\neg}2] 1[1{\backslash}1{\backslash}2]2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,\varphi(\omega,0))}(n) = \{ n,n [1 [2{\neg}2] 1[1[2{\neg}2]2]2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega,\varphi(\omega,\varphi(\omega,0)))}(n) = \{ n,n [1 [2{\neg}2] 1[1[2{\neg}2]1[1[2{\neg}2]2]2]2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega+1,0)}(n) = \{ n,n [1 [2{\neg}2] 1{\backslash}2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega+2,0)}(n) = \{ n,n [1 [2{\neg}2] 1{\backslash}1{\backslash}2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega2,0)}(n) = \{ n,n [1 [2{\neg}2] 1 [2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega^2,0)}(n) = \{ n,n [1 [3{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega^3,0)}(n) = \{ n,n [1 [4{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega^{\omega},0)}(n) = \{ n,n [1 [1,2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(\omega^{\omega^{\omega}},0)}(n) = \{ n,n [1 [1[2]2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi({\epsilon_0},0)}(n) = \{ n,n [1 [1[1{\backslash}2]2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\Gamma_0}(n) = \{ n,n [1 [1{\backslash}2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\varphi(1,0,0,0)}(n)&lt;/math&gt;
*&lt;math&gt; f_{\varphi(1,0,0,0,0)}(n)&lt;/math&gt;
*&lt;math&gt; f_{\vartheta(\Omega^\omega)}(n) = \{ n,n [1 [1{\backslash}1,2{\neg}2] 2] 2\}&lt;/math&gt;
*&lt;math&gt; f_{\vartheta(\Omega^\Omega)}(n) = \{ n,n [1 [1{\backslash}1{\backslash}2{\neg}2] 2] 2\}&lt;/math&gt;

==References==
* Buchholz, W.; Wainer, S.S (1987). "Provably Computable Functions and the Fast Growing Hierarchy". ''Logic and Combinatorics'', edited by S. Simpson, Contemporary Mathematics, Vol. 65, AMS, 179-198.
*{{Citation | last1=Cichon | first1=E. A. | last2=Wainer | first2=S. S. | title=The slow-growing and the Grzegorczyk hierarchies | doi=10.2307/2273557 | mr=704094 | year=1983 | journal=The Journal of Symbolic Logic | issn=0022-4812 | volume=48 | issue=2 | pages=399â408}}
*{{citation|mr=1129778|last= Gallier|first= Jean H.|authorlink= Jean Gallier |title= What's so special about Kruskal's theorem and the ordinal Î&lt;sub&gt;0&lt;/sub&gt;? A survey of some results in proof theory|journal=  Ann. Pure Appl. Logic|volume=  53  |year=1991|issue=  3|pages= 199â260|url=http://stinet.dtic.mil/oai/oai?verb=getRecord&amp;metadataPrefix=html&amp;identifier=ADA290387|doi=10.1016/0168-0072(91)90022-E}} PDF's: [ftp://ftp.cis.upenn.edu/pub/papers/gallier/kruskal1.pdf part 1] [ftp://ftp.cis.upenn.edu/pub/papers/gallier/kruskal2.pdf 2] [ftp://ftp.cis.upenn.edu/pub/papers/gallier/kruskal3.pdf 3]. (In particular part 3, Section 12, pp.&amp;nbsp;59â64, "A Glimpse at Hierarchies of Fast and Slow Growing Functions".)
*{{Citation | last1=Girard | first1=Jean-Yves | author1-link=Jean-Yves Girard | title=Î &lt;sup&gt;1&lt;/sup&gt;&lt;sub&gt;2&lt;/sub&gt;-logic. I. Dilators | doi=10.1016/0003-4843(81)90016-4 | mr=656793 | year=1981 | journal=Annals of Mathematical Logic | issn=0003-4843 | volume=21 | issue=2 | pages=75â219}}
* LÃ¶b, M.H.; Wainer, S.S. (1970), "Hierarchies of number theoretic functions", ''Arch. Math. Logik'', 13. Correction, ''Arch. Math. Logik'', 14, 1971. Part I {{doi|10.1007/BF01967649}}, Part 2 {{doi|10.1007/BF01973616}}, Corrections {{doi|10.1007/BF01991855}}.
* PrÃ¶mel, H. J.; Thumser, W.; Voigt, B. "Fast growing functions based on Ramsey theorems", ''Discrete Mathematics'', v.95 n.1-3, p.&amp;nbsp;341-358, December 1991  {{doi|10.1016/0012-365X(91)90346-4}}.
* {{cite journal | last1 = Wainer | first1 = S.S | year = 1989 | title = Slow Growing Versus Fast Growing | journal = [[Journal of Symbolic Logic]] | volume = 54 | issue = 2| pages = 608â614 | jstor=2274873}}

{{DEFAULTSORT:Fast-Growing Hierarchy}}
[[Category:Computability theory]]
[[Category:Proof theory]]
[[Category:Hierarchy of functions]]
[[Category:Large numbers]]</text>
      <sha1>9fo0o4uqfn6w7qyw989cb2kup4ijuy1</sha1>
    </revision>
  </page>
  <page>
    <title>Generalized GaussâNewton method</title>
    <ns>0</ns>
    <id>17324351</id>
    <revision>
      <id>862709172</id>
      <parentid>852415213</parentid>
      <timestamp>2018-10-06T05:19:00Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="754">{{Refimprove|date=January 2017}}
The '''generalized GaussâNewton method''' is a generalization of the least-squares method originally described by [[Carl Friedrich Gauss]] and of [[Newton's method]] due to [[Isaac Newton]] to the case of constrained nonlinear least-squares problems.&lt;ref&gt;{{citation
 | last1 = Golub | first1 = G. H.
 | last2 = Pereyra | first2 = V.
 | journal = SIAM Journal on Numerical Analysis
 | mr = 0336980
 | pages = 413â432
 | title = The differentiation of pseudo-inverses and nonlinear least squares problems whose variables separate
 | volume = 10
 | year = 1973}}.&lt;/ref&gt;

==References==
{{reflist}}

{{Isaac Newton}}

{{DEFAULTSORT:Generalized Gauss-Newton method}}
[[Category:Numerical analysis]]


{{applied-math-stub}}</text>
      <sha1>pgo6sefxw3jqtl6aln4vcz9o6uo6bg8</sha1>
    </revision>
  </page>
  <page>
    <title>Glossary of arithmetic and diophantine geometry</title>
    <ns>0</ns>
    <id>3141761</id>
    <revision>
      <id>866997811</id>
      <parentid>859024346</parentid>
      <timestamp>2018-11-02T23:14:16Z</timestamp>
      <contributor>
        <username>PJOS</username>
        <id>12837188</id>
      </contributor>
      <minor/>
      <comment>Corrected mistake in Bombieri-Lang Conjecture</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="37871">This is a glossary of '''arithmetic and diophantine geometry''' in [[mathematics]], areas growing out of the traditional study of [[Diophantine equation]]s to encompass large parts of [[number theory]] and [[algebraic geometry]]. Much of the theory is in the form of proposed [[conjecture]]s, which can be related at various levels of generality.

[[Diophantine geometry]] in general is the study of [[algebraic varieties]] ''V'' over fields ''K'' that are finitely generated over their [[prime field]]sâincluding as of special interest [[number field]]s and [[finite field]]sâand over [[local field]]s. Of those, only the [[complex number]]s are [[algebraically closed]]; over any other ''K'' the existence of points of ''V'' with coordinates in ''K'' is something to be proved and studied as an extra topic, even knowing the geometry of ''V''.

''Arithmetical'' or ''arithmetic'' (algebraic) geometry is a field with a less elementary definition. After the advent of [[scheme theory]] it could reasonably be defined as the study of [[Alexander Grothendieck]]'s schemes ''of finite type'' over the [[spectrum of a ring|spectrum]] of the [[ring of integers]] '''Z'''. This point of view has been very influential for around half a century; it has very widely been regarded as fulfilling [[Leopold Kronecker]]'s ambition to have number theory operate only with rings that are quotients of [[polynomial ring]]s over the integers (to use the current language of [[commutative algebra]]). In fact scheme theory uses all sorts of auxiliary constructions that do not appear at all 'finitistic', so that there is little connection with 'constructivist' ideas as such. That scheme theory may not be the last word appears from continuing interest in the 'infinite primes' (the real and complex local fields), which do not come from [[prime ideal]]s as the [[p-adic number]]s do.
__NOTOC__
{{compact ToC|side=yes|top=yes|num=yes}}

==A==

{{term|abc conjecture}}
{{defn|1=The [[abc conjecture]] of [[David Masser|Masser]] and [[Joseph OesterlÃ©|OesterlÃ©]] attempts to state as much as possible about repeated prime factors in an equation ''a'' + ''b'' = ''c''. For example 3 + 125 = 128 but the prime powers here are exceptional.}}

{{term|Arakelov class group}}
{{defn|1=The ''Arakelov class group'' is the analogue of the [[ideal class group]] or [[divisor class group]] for [[Arakelov divisor]]s.&lt;ref name=Sch08&gt;{{cite book | last=Schoof | first=RenÃ© | authorlink=RenÃ© Schoof | chapter=Computing Arakelov class groups | pages=447â495 | editor1-first=J.P. | editor1-last=Buhler | editor2-first=Stevenhagen | editor2-last=P. | title=Algorithmic Number Theory: Lattices, Number Fields, Curves and Cryptography | series=MSRI Publications | volume=44 | publisher=[[Cambridge University Press]] | year=2008 | isbn=978-0-521-20833-8 | zbl=1188.11076 | mr=2467554 | url=http://www.mat.uniroma2.it/~schoof/papers.html }}&lt;/ref&gt;}}

{{term|Arakelov divisor}}
{{defn|1=An ''Arakelov divisor'' (or ''replete divisor''&lt;ref name=Neukirch189/&gt;) on a global field is an extension of the concept of [[Divisor (algebraic geometry)|divisor]] or [[fractional ideal]]. It is a formal linear combination of [[Valuation (algebra)|places]] of the field with [[finite place]]s having integer coefficients and the [[infinite place]]s having real coefficients.&lt;ref name=Sch08/&gt;&lt;ref&gt;Lang (1988) pp.74â75&lt;/ref&gt;&lt;ref&gt;{{cite journal | journal=Selecta Mathematica, New Series | volume=6 | number=4 | year=2000 | pages=377â398 | doi=10.1007/PL00001393 | title=Effectivity of Arakelov divisors and the theta divisor of a number field | first1=G. | last1=van der Geer | first2=R. | last2=Schoof | arxiv=math/9802121 | zbl=1030.11063 }}&lt;/ref&gt;}}

{{term|Arakelov height}}
{{defn|1=The ''Arakelov height'' on a projective space over the field of algebraic numbers is a global [[height function]] with local contributions coming from [[FubiniâStudy metric]]s on the [[Archimedean field]]s and the usual metric on the [[non-Archimedean field]]s.&lt;ref&gt;Bombieri &amp; Gubler (2006) pp.66â67&lt;/ref&gt;&lt;ref&gt;Lang (1988) pp.156â157&lt;/ref&gt;}}

{{term|Arakelov theory}}
{{defn|1=[[Arakelov theory]] is an approach to arithmetic geometry that explicitly includes the 'infinite primes'.}}

{{term|Arithmetic of abelian varieties}}
{{defn|1=''See main article [[arithmetic of abelian varieties]]''}}

{{term|Artin L-functions}}
{{defn|1=[[Artin L-function]]s are defined for quite general [[Galois representation]]s. The introduction of [[Ã©tale cohomology]] in the 1960s meant that [[HasseâWeil L-function]]s could be regarded as Artin L-functions for the Galois representations on [[l-adic cohomology]] groups.}}

==B==
{{glossary}}
{{term|Bad reduction}}
{{defn|1=See ''good reduction''.}}

{{term|Birch and Swinnerton-Dyer conjecture}}
{{defn|1=The [[Birch and Swinnerton-Dyer conjecture]] on [[elliptic curves]] postulates a connection between the [[rank of an elliptic curve]] and the order of pole of its HasseâWeil L-function. It has been an important landmark in Diophantine geometry since the mid-1960s, with results such as the [[CoatesâWiles theorem]], [[GrossâZagier theorem]] and [[Kolyvagin's theorem]].&lt;ref&gt;Lang (1997) pp.91â96&lt;/ref&gt;}}

{{term|BombieriâLang conjecture}}
{{defn|1=[[Enrico Bombieri]], [[Serge Lang]] and [[Paul Vojta]] and Piotr Blass have conjectured that algebraic varieties of [[general type]] do not have [[Zariski dense]] subsets of ''K''-rational points, for ''K'' a finitely-generated field. This circle of ideas includes the understanding of ''analytic hyperbolicity'' and the Lang conjectures on that, and the Vojta conjectures. An ''analytically hyperbolic algebraic variety'' ''V'' over the complex numbers is one such that no [[holomorphic mapping]] from the whole [[complex plane]] to it exists, that is not constant. Examples include [[compact Riemann surface]]s of genus ''g'' &gt; 1. Lang conjectured that ''V'' is analytically hyperbolic if and only if all subvarieties are of general type.&lt;ref name=HS479/&gt;}}
{{glossary end}}

==C==

{{term|Canonical height}}
{{defn|1=The canonical height on an [[abelian variety]] is a height function that is a distinguished [[quadratic form]]. See [[NÃ©ronâTate height]].}}

{{term|Chabauty's method}}
{{defn|1='''Chabauty's method''', based on ''p''-adic analytic functions, is a special application but capable of proving cases of the [[Mordell conjecture]] for curves whose Jacobian's rank is less than its dimension. It developed ideas from [[Thoralf Skolem]]'s method for an [[algebraic torus]]. (Other older methods for Diophantine problems include [[Runge's method]].)}}

{{term|CoatesâWiles theorem}}
{{defn|1=The ''CoatesâWiles theorem'' states that an [[elliptic curve]] with [[complex multiplication]] by an [[imaginary quadratic field]] of [[Class numbers of imaginary quadratic fields|class number]] 1 and positive [[Rank of an abelian group|rank]] has [[L-function]] with a zero at ''s''=1. This is a special case of the [[Birch and Swinnerton-Dyer conjecture]].&lt;ref&gt;{{cite journal |last=Coates |first=J. |authorlink=John Coates (mathematician) |last2=Wiles |first2=A. | authorlink2=Andrew Wiles |title=On the conjecture of Birch and Swinnerton-Dyer |journal=[[Inventiones Mathematicae]] |volume=39 |year=1977 |issue=3 |pages=223â251 |doi=10.1007/BF01402975 | zbl=0359.14009 |bibcode=1977InMat..39..223C }}&lt;/ref&gt;}}

{{term|Crystalline cohomology}}
{{defn|1=[[Crystalline cohomology]] is a p-adic cohomology theory in [[characteristic p]], introduced by [[Alexander Grothendieck]] to fill the gap left by [[Ã©tale cohomology]] which is deficient in using mod ''p'' coefficients in this case. It is one of a number of theories deriving in some way from [[Dwork's method]], and has applications outside purely arithmetical questions.}}

==D==

{{term|Diagonal forms}}
{{defn|1=[[Diagonal form]]s are some of the simplest [[projective varieties]] to study from an arithmetic point of view (including the [[Fermat varieties]]). Their [[local zeta-function]]s are computed in terms of [[Jacobi sum]]s. [[Waring's problem]] is the most classical case.}}

{{term|Diophantine dimension}}
{{defn|1=The ''Diophantine dimension'' of a field is the smallest natural number ''k'', if it exists, such that the field of is class C&lt;sub&gt;''k''&lt;/sub&gt;: that is, such that any homogeneous polynomial of degree ''d'' in ''N'' variables has a non-trivial zero whenever ''N'' &amp;gt; ''d''&lt;sup&gt;''k''&lt;/sup&gt;. [[Algebraically closed field]]s are of Diophantine dimension 0; [[quasi-algebraically closed field]]s of dimension 1.&lt;ref name=NSW361&gt;{{cite book | title=Cohomology of Number Fields | volume=323 | series=Grundlehren der Mathematischen Wissenschaften | first1=JÃ¼rgen | last1=Neukirch | first2=Alexander | last2=Schmidt | first3=Kay | last3=Wingberg | edition=2nd | publisher=[[Springer-Verlag]] | year=2008 | isbn=3-540-37888-X | page=361}}&lt;/ref&gt;}}

{{term|Discriminant of a point}}
{{defn|1=The ''discriminant of a point'' refers to two related concepts relative to a point ''P'' on an algebraic variety ''V'' defined over a number field ''K'': the ''geometric (logarithmic) discriminant''&lt;ref name=L146&gt;Lang (1997) p.146&lt;/ref&gt; ''d''(''P'') and the ''arithmetic discriminant'', defined by Vojta.&lt;ref name=L171&gt;Lang (1997) p.171&lt;/ref&gt; The difference between the two may be compared to the difference between the [[arithmetic genus]] of a [[singular curve]] and the [[geometric genus]] of the [[desingularisation]].&lt;ref name=L171/&gt; The arithmetic genus is larger than the geometric genus, and the height of a point may be bounded in terms of the arithmetic genus. Obtaining similar bounds involving the geometric genus would have significant consequences.&lt;ref name=L171/&gt;}}

{{term|Dwork's method}}
{{defn|1=[[Bernard Dwork]] used distinctive methods of [[p-adic analysis]], p-adic [[algebraic differential equation]]s, [[Koszul complex]]es and other techniques that have not all been absorbed into general theories such as [[crystalline cohomology]]. He first proved the [[rational function|rationality]] of local zeta-functions, the initial advance in the direction of the [[Weil conjectures]].}}

==E==

{{term|Ãtale cohomology}}
{{defn|1=The search for a Weil cohomology (q.v.) was at least partially fulfilled in the [[Ã©tale cohomology]] theory of [[Alexander Grothendieck]] and [[Michael Artin]]. It provided a proof of the [[functional equation (L-function)|functional equation]] for the [[local zeta-function]]s, and was basic in the formulation of the Tate conjecture (q.v.) and numerous other theories.}}

==F==

{{term|Faltings height}}
{{defn|1=The ''[[Faltings height]]'' of an elliptic curve or abelian variety defined over a number field is a measure of its complexity introduced by [[Gerd Faltings|Faltings]] in his proof of the [[Mordell conjecture]].&lt;ref&gt;{{cite journal |last=Faltings |first=Gerd |authorlink=Gerd Faltings | year=1983 | title=EndlichkeitssÃ¤tze fÃ¼r abelsche VarietÃ¤ten Ã¼ber ZahlkÃ¶rpern | journal=[[Inventiones Mathematicae]] | volume=73 | issue=3 | pages=349â366 | doi=10.1007/BF01388432 |bibcode=1983InMat..73..349F }}&lt;/ref&gt;&lt;ref&gt;{{cite book |title=Arithmetic geometry |last=Cornell |first=Gary |authorlink= |author2=Silverman, Joseph H. |year=1986 |publisher=Springer |location= New York |isbn=0-387-96311-1 |pages= }} â Contains an English translation of Faltings (1983)&lt;/ref&gt;}}

{{term|Fermat's last theorem}}
{{defn|1=[[Fermat's last theorem]], the most celebrated conjecture of Diophantine geometry, was proved by [[Andrew Wiles]] and [[Richard Taylor (mathematician)|Richard Taylor]].}}

{{term|Flat cohomology}}
{{defn|1=[[Flat cohomology]] is, for the school of Grothendieck, one terminal point of development. It has the disadvantage of being quite hard to compute with. The reason that the [[flat topology]] has been considered the 'right' foundational [[topos]] for [[scheme theory]] goes back to the fact of [[faithfully-flat descent]], the discovery of Grothendieck that the [[representable functor]]s are sheaves for it (i.e. a very general [[gluing axiom]] holds).}}

{{term|Function field analogy}}
{{defn|1=It was realised in the nineteenth century that the [[ring of integers]] of a number field has analogies with the affine [[coordinate ring]] of an algebraic curve or compact Riemann surface, with a point or more removed corresponding to the 'infinite places' of a number field. This idea is more precisely encoded in the theory that [[global field]]s should all be treated on the same basis. The idea goes further. Thus [[elliptic surface]]s over the complex numbers, also, have some quite strict analogies with [[elliptic curve]]s over number fields.}}

==G==

{{term|[[Geometric class field theory]]}}
{{defn|1=The extension of [[class field theory]]-style results on [[abelian covering]]s to varieties of dimension at least two is often called ''geometric'' class field theory.}}

{{term|Good reduction}}
{{defn|1=Fundamental to [[local analysis]] in arithmetic problems is to ''reduce'' ''[[modular arithmetic|modulo]]'' all prime numbers ''p'' or, more generally, [[prime ideal]]s. In the typical situation this presents little difficulty for [[almost all]] ''p''; for example [[denominator]]s of fractions are tricky, in that reduction modulo a prime in the denominator looks like [[division by zero]], but that rules out only finitely many ''p'' per fraction. With a little extra sophistication, [[homogeneous coordinates]] allow clearing of denominators by multiplying by a common scalar. For a given, single point one can do this and not leave a common factor ''p''. However [[singularity theory]] enters: a [[non-singular]] point may become a [[Mathematical singularity|singular point]] on reduction modulo ''p'', because the [[Zariski tangent space]] can become larger when linear terms reduce to 0 (the geometric formulation shows it is not the fault of a single set of coordinates). ''Good reduction'' refers to the reduced variety having the same properties as the original, for example, an [[algebraic curve]] having the same [[genus of a curve|genus]], or a [[smooth variety]] remaining smooth. In general there will be a finite set ''S'' of primes for a given variety ''V'', assumed smooth, such that there is otherwise a smooth reduced ''V''&lt;sub&gt;''p''&lt;/sub&gt; over '''Z'''/''p'''''Z'''. For [[abelian varieties]], good reduction is connected with [[Ramification (mathematics)|ramification]] in the field of [[division point]]s by the [[NÃ©ronâOggâShafarevich criterion]]. The theory is subtle, in the sense that the freedom to change variables to try to improve matters is rather unobvious: see [[NÃ©ron model]], [[potential good reduction]], [[Tate curve]], [[semistable abelian variety]], [[semistable elliptic curve]], [[SerreâTate theorem]].&lt;ref&gt;{{cite journal | first1=Jean-Pierre | last1=Serre | authorlink1=Jean-Pierre Serre | first2=John | last2=Tate | authorlink2=John Tate | title=Good reduction of abelian varieties | journal=[[The Annals of Mathematics]] | series=Second | volume=88 | number=3 | date=November 1968 | pages=492â517 | zbl=0172.46101 | doi=10.2307/1970722 | jstor=1970722}}&lt;/ref&gt;}}

{{term|GrothendieckâKatz conjecture}}
{{defn|1=The [[GrothendieckâKatz p-curvature conjecture]] applies reduction modulo primes to [[algebraic differential equation]]s, to derive information on [[algebraic function]] solutions. It is an open problem {{As of|2016|lc=on}}. The initial result of this type was [[Eisenstein's theorem]].}}

==H==

{{term|Hasse principle}}
{{defn|1=The [[Hasse principle]] states that solubility for a [[global field]] is the same as solubility in all relevant [[local field]]s. One of the main objectives of Diophantine geometry is to classify cases where the Hasse principle holds. Generally that is for a large number of variables, when the degree of an equation is held fixed. The Hasse principle is often associated with the success of the [[HardyâLittlewood circle method]]. When the circle method works, it can provide extra, quantitative information such as asymptotic number of solutions. Reducing the number of variables makes the circle method harder; therefore failures of the Hasse principle, for example for [[cubic form]]s in small numbers of variables (and in particular for [[elliptic curve]]s as [[cubic curve]]s) are at a general level connected with the limitations of the analytic approach.}}

{{term|HasseâWeil L-function}}
{{defn|1=A [[HasseâWeil L-function]], sometimes called a ''global'' L-function, is an [[Euler product]] formed from local zeta-functions. The properties of such [[L-function]]s remain largely in the realm of conjecture, with the proof of the [[TaniyamaâShimura conjecture]] being a breakthrough. The [[Langlands philosophy]] is largely complementary to the theory of global L-functions.}}

{{term|Height function}}
{{defn|1=A height function in Diophantine geometry quantifies the size of solutions to Diophantine equations.&lt;ref&gt;Lang (1997) pp.43â67&lt;/ref&gt; Classical or [[naive height]] is defined in terms of ordinary absolute value on [[homogeneous coordinates]]: it is now usual to take a [[logarithmic scale]], that is, height is proportional to the "algebraic complexity" or number of bits needed to store a point.&lt;ref&gt;Bombieri &amp; Gubler (2006) pp.15â21&lt;/ref&gt; Heights were initially developed by [[AndrÃ© Weil]] and [[D. G. Northcott]]. Innovations around 1960 were the [[NÃ©ronâTate height]] and the realisation that heights were linked to projective representations in much the same way that [[ample line bundle]]s are in pure geometry.}}

{{term|Hilbertian fields}}
{{defn|1=A [[Hilbertian field]] ''K'' is one for which the [[projective space]]s over ''K'' are not [[thin set (Serre)|thin set]]s in the sense of [[Jean-Pierre Serre]]. This is a geometric take on [[Hilbert's irreducibility theorem]] which shows the rational numbers are Hilbertian. Results are applied to the [[inverse Galois problem]]. Thin sets (the French word is ''mince'') are in some sense analogous to the [[meagre set]]s (French ''maigre'') of the [[Baire category theorem]].}}

==I==

{{term|Igusa zeta-function}}
{{defn|1=An [[Igusa zeta-function]], named for [[Jun-ichi Igusa]], is a [[generating function]] counting numbers of points on an algebraic variety modulo high powers ''p''&lt;sup&gt;''n''&lt;/sup&gt; of a fixed prime number ''p''. General [[rational function|rationality theorems]] are now known, drawing on methods of [[mathematical logic]].&lt;ref&gt;{{cite journal |last=Igusa |first=Jun-Ichi |year=1974 |title=Complex powers and asymptotic expansions. I. Functions of certain types |journal=[[Crelle's Journal|Journal fÃ¼r die reine und angewandte Mathematik]] |volume=1974 |issue=268â269 |pages=110â130 |doi=10.1515/crll.1974.268-269.110 | zbl=0287.43007}}&lt;/ref&gt;}}

{{term|Infinite descent}}
{{defn|1=[[Infinite descent]] was [[Pierre de Fermat]]'s classical method for Diophantine equations. It became one half of the standard proof of the MordellâWeil theorem, with the other being an argument with height functions (q.v.). Descent is something like division by two in a group of [[principal homogeneous space]]s (often called 'descents', when written out by equations); in more modern terms in a [[Galois cohomology]] group which is to be proved finite. See [[Selmer group]].}}

{{term|Iwasawa theory}}
{{defn|1=[[Iwasawa theory]] builds up from the [[analytic number theory]] and [[Stickelberger's theorem]] as a theory of [[ideal class group]]s as [[Galois module]]s and [[p-adic L-function]]s (with roots in [[Kummer congruence]] on [[Bernoulli number]]s). In its early days in the late 1960s it was called ''[[Kenkichi Iwasawa|Iwasawa's]] analogue of the Jacobian''. The analogy was with the [[Jacobian variety]] ''J'' of a curve ''C'' over a finite field ''F'' (''qua'' Picard variety), where the finite field has [[roots of unity]] added to make finite field extensions ''F''&amp;prime; The local zeta-function (q.v.) of ''C'' can be recovered from the points ''J''(''F''&amp;prime;) as Galois module. In the same way, Iwasawa added ''p''&lt;sup&gt;''n''&lt;/sup&gt;-power roots of unity for fixed ''p'' and with ''n'' &amp;rarr; &amp;infin;, for his analogue, to a number field ''K'', and considered the [[inverse limit]] of class groups, finding a ''p''-adic L-function earlier introduced by Kubota and Leopoldt.}}

==K==

{{term|K-theory}}
{{defn|1=[[Algebraic K-theory]] is on one hand a quite general theory with an [[abstract algebra]] flavour, and, on the other hand, implicated in some formulations of arithmetic conjectures. See for example [[BirchâTate conjecture]], [[Lichtenbaum conjecture]].}}

==L==

{{term|Linear torus}}
{{defn|1=A ''linear torus'' is a geometrically irreducible Zariski-closed subgroup of an affine torus (product of multiplicative groups).&lt;ref&gt;Bombieri &amp; Gubler (2006) pp.82â93&lt;/ref&gt;}}

{{term|Local zeta-function}}
{{defn|1=A [[local zeta-function]] is a [[generating function]] for the number of points on an algebraic variety ''V'' over a [[finite field]] ''F'', over the finite [[field extension]]s of ''F''. According to the Weil conjectures (q.v.) these functions, for [[non-singular]] varieties, exhibit properties closely analogous to the [[Riemann zeta-function]], including the [[Riemann hypothesis]].}}

==M==

{{term|ManinâMumford conjecture}}
{{defn|1=The [[ManinâMumford conjecture]], now proved by [[Michel Raynaud]], states that a curve ''C'' in its [[Jacobian variety]] ''J'' can only contain a finite number of points that are of finite order in ''J'', unless ''C'' = ''J''.&lt;ref&gt;{{cite book | first=Michel | last=Raynaud | authorlink=Michel Raynaud | chapter=Sous-variÃ©tÃ©s d'une variÃ©tÃ© abÃ©lienne et points de torsion | language=French | editor1-last=Artin | editor1-first=Michael | editor1-link=Michael Artin | editor2-last=Tate | editor2-first=John | editor2-link=John Tate | title=Arithmetic and geometry. Papers dedicated to I. R. Shafarevich on the occasion of his sixtieth birthday. Vol. I: Arithmetic | series=Progress in Mathematics | volume=35 | publisher=Birkhauser-Boston | year=1983 | pages= 327â352 | zbl=0581.14031 }}&lt;/ref&gt;&lt;ref&gt;{{cite book | zbl=1098.14030 | last=Roessler | first=Damian | chapter=A note on the ManinâMumford conjecture | editor1-last=van der Geer | editor1-first=Gerard | editor2-last=Moonen | editor2-first=Ben | editor3-last=Schoof | editor3-first=RenÃ© | editor3-link=RenÃ© Schoof | title=Number fields and function fields â two parallel worlds | publisher=BirkhÃ¤user | series=Progress in Mathematics | volume=239 | pages=311â318 | year=2005 | isbn=0-8176-4397-4 }}&lt;/ref&gt;}}

{{term|Mordell conjecture}}
{{defn|1=The [[Mordell conjecture]] is now the [[Faltings theorem]], and states that a curve of genus at least two has only finitely many rational points. The [[Uniformity conjecture]] states that there should be a uniform bound on the number of such points, depending only on the genus and the field of definition.}}

{{term|MordellâLang conjecture}}
{{defn|1=The MordellâLang conjecture is a collection of conjectures of Serge Lang unifying the Mordell conjecture and [[ManinâMumford conjecture]] in an [[abelian variety]] or [[semi-abelian variety]].&lt;ref&gt;{{cite book | title=A Guide to Classical and Modern Model Theory | volume=19 | series=Trends in Logic | first1=Annalisa | last1=Marcja | first2=Carlo | last2=Toffalori | publisher=[[Springer-Verlag]] | year=2003 | isbn=1402013302 | pages=305â306 }}&lt;/ref&gt;&lt;ref&gt;[http://www.math.harvard.edu/~mazur/preprints/Lang.mem.pdf 2 page exposition of the MordellâLang conjecture by B. Mazur, 3 Nov. 2005]&lt;/ref&gt;}}

{{term|MordellâWeil theorem}}
{{defn|1=The [[MordellâWeil theorem]] is a foundational result stating that for an abelian variety ''A'' over a number field ''K'' the group ''A''(''K'') is a [[finitely-generated abelian group]]. This was proved initially for number fields ''K'', but extends to all finitely-generated fields.}}

{{term|Mordellic variety}}
{{defn|1=A [[Mordellic variety]] is an algebraic variety which has only finitely many points in any finitely generated field.&lt;ref&gt;Lang (1997) p.15&lt;/ref&gt;}}

==N==

{{term|Naive height}}

{{defn|1=The ''naive'' or ''classical height'' of a vector of rational numbers is the maximum absolute value of the vector of coprime integers obtained by multiplying through by a [[lowest common denominator]]. This may be used to define height on a point in projective space over '''Q''', or of a polynomial, regarded as a vector of coefficients, or of an algebraic number, from the height of its minimal polynomial.&lt;ref&gt;{{cite book | first1=Alan | last1=Baker | authorlink1=Alan Baker (mathematician)| first2=Gisbert | last2= WÃ¼stholz | authorlink2=Gisbert WÃ¼stholz | title=Logarithmic Forms and Diophantine Geometry | series=New Mathematical Monographs | volume=9 | publisher=[[Cambridge University Press]] | year=2007 | isbn=978-0-521-88268-2 | zbl=1145.11004 | page=3 }}&lt;/ref&gt;}}

{{term|NÃ©ron symbol}}
{{defn|1=The ''NÃ©ron symbol'' is a bimultiplicative pairing between divisors and [[algebraic cycles]] on an [[Abelian variety]] used in NÃ©ron's formulation of the [[NÃ©ronâTate height]] as a sum of local contributions.&lt;ref name=BG301&gt;Bombieri &amp; Gubler (2006) pp.301â314&lt;/ref&gt;&lt;ref&gt;Lang (1988) pp.66â69&lt;/ref&gt;&lt;ref name=L212&gt;Lang (1997) p.212&lt;/ref&gt; The global NÃ©ron symbol, which is the sum of the local symbols, is just the negative of the height pairing.&lt;ref name=L8877&gt;Lang (1988) p.77&lt;/ref&gt;}}

{{term|NÃ©ronâTate height}}

{{defn|1=The [[NÃ©ronâTate height]] (also often referred to as the [[canonical height]]) on an [[abelian variety]] ''A'' is a height function (q.v.) that is essentially intrinsic, and an exact [[quadratic form]], rather than approximately quadratic with respect to the addition on ''A'' as provided by the general theory of heights. It can be defined from a general height by a limiting process; there are also formulae, in the sense that it is a sum of local contributions.&lt;ref name=L8877/&gt;}}

{{term|Nevanlinna invariant}}
{{defn|1= The ''[[Nevanlinna invariant]]'' of an [[ample divisor]] ''D'' on a [[normal variety|normal]] [[projective variety]] ''X'' is a real number which describes the rate of growth of the number of rational points on the variety with respect to the embedding defined by the divisor.&lt;ref&gt;Hindry &amp; Silverman (2000) p.488&lt;/ref&gt; It has similar formal properties to the abscissa of convergence of the [[height zeta function]] and it is conjectured that they are essentially the same.&lt;ref&gt;{{cite journal | zbl=0679.14008 | last1=Batyrev | first1=V.V. | last2=Manin | first2=Yu.I. | author2-link=Yuri I. Manin | title=On the number of rational points of bounded height on algebraic varieties | journal=Math. Ann. | volume=286 | pages=27â43 | year=1990 | doi = 10.1007/bf01453564 }}&lt;/ref&gt;}}

==O==

{{term|Ordinary reduction}}
{{defn|1=An Abelian variety ''A'' of dimension ''d'' has ''ordinary reduction'' at a prime ''p'' if it has [[good reduction]] at ''p'' and in addition the ''p''-torsion has rank ''d''.&lt;ref&gt;Lang (1997) pp.161â162&lt;/ref&gt;}}

==Q==

{{term|Quasi-algebraic closure}}
{{defn|1=The topic of [[quasi-algebraic closure]], i.e. solubility guaranteed by a number of variables polynomial in the degree of an equation, grew out of studies of the [[Brauer group]] and the [[ChevalleyâWarning theorem]]. It stalled in the face of [[counterexample]]s; but see [[AxâKochen theorem]] from [[mathematical logic]].}}

==R==

{{term|Reduction ''modulo'' a prime number or ideal}}
{{defn|1=See ''good reduction''.}}

{{term|Replete ideal}}
{{defn|1=A ''replete ideal'' in a number field ''K'' is a formal product of a [[fractional ideal]] of ''K'' and a vector of positive real numbers with components indexed by the infinite places of ''K''.&lt;ref&gt;Neukirch (1999) p.185&lt;/ref&gt; A ''replete divisor'' is an [[Arakelov divisor]].&lt;ref name=Neukirch189&gt;Neukirch (1999) p.189&lt;/ref&gt;}}

==S==

{{term|SatoâTate conjecture}}
{{defn|1=The [[SatoâTate conjecture]] describes the distribution of [[Frobenius element]]s in the [[Tate module]]s of the [[elliptic curve]]s over [[finite field]]s obtained from reducing a given elliptic curve over the rationals. [[Mikio Sato]] and, independently, [[John Tate]]&lt;ref&gt;It is mentioned in J. Tate, ''Algebraic cycles and poles of zeta functions'' in the volume (O. F. G. Schilling, editor), ''Arithmetical Algebraic Geometry'', pages 93â110 (1965).&lt;/ref&gt; suggested it around 1960. It is a prototype for [[Galois representation]]s in general.}}

{{term|Skolem's method}}
{{defn|1=See ''Chabauty's method''.}}

{{term|Special set}}
{{defn|1=The ''special set'' in an algebraic variety is the subset in which one might expect to find many rational points. The precise definition varies according to context. One definition is the [[Zariski closure]] of the union of images of algebraic groups under non-trivial rational maps; alternatively one may take images of abelian varieties;&lt;ref&gt;Lang (1997) pp.17â23&lt;/ref&gt; another definition is the union of all subvarieties that are not of general type.&lt;ref name=HS479&gt;Hindry &amp; Silverman (2000) p.479&lt;/ref&gt; For abelian varieties the definition would be the union of all translates of proper abelian subvarieties.&lt;ref name=HS480&gt;Hindry &amp; Silverman (2000) p.480&lt;/ref&gt; For a complex variety, the ''holomorphic special set'' is the Zariski closure of the images of all non-constant holomorphic maps from '''C'''. Lang conjectured that the analytic and algebraic special sets are equal.&lt;ref&gt;Lang (1997) p.179&lt;/ref&gt;}}

{{term|Subspace theorem}}
{{defn|1=Schmidt's '''[[subspace theorem]]''' shows that points of small height in projective space lie in a finite number of hyperplanes. A quantitative form of the theorem, in which the number of subspaces containing all solutions, was also obtained by Schmidt, and the theorem was generalised by Schlickewei (1977) to allow more general [[absolute value (algebra)|absolute values]] on [[number field]]s. The theorem may be used to obtain results on [[Diophantine equation]]s such as [[Siegel's theorem on integral points]] and solution of the [[S-unit equation]].&lt;ref&gt;Bombieri &amp; Gubler (2006) pp.176â230&lt;/ref&gt;}}

==T==

{{term|Tamagawa numbers}}
{{defn|1=The direct [[Tamagawa number]] definition works well only for [[linear algebraic group]]s. There the [[Weil conjecture on Tamagawa numbers]] was eventually proved. For abelian varieties, and in particular the BirchâSwinnerton-Dyer conjecture (q.v.), the Tamagawa number approach to a [[localâglobal principle]] fails on a direct attempt, though it has had heuristic value over many years. Now a sophisticated [[equivariant Tamagawa number conjecture]] is a major research problem.}}

{{term|Tate conjecture}}
{{defn|1=The [[Tate conjecture]] ([[John Tate]], 1963) provided an analogue to the [[Hodge conjecture]], also on [[algebraic cycle]]s, but well within arithmetic geometry. It also gave, for [[elliptic surface]]s, an analogue of the BirchâSwinnerton-Dyer conjecture (q.v.), leading quickly to a clarification of the latter and a recognition of its importance.}}

{{term|Tate curve}}
{{defn|1=The [[Tate curve]] is a particular elliptic curve over the [[p-adic number]]s introduced by John Tate to study bad reduction (see ''good reduction'').}}

{{term|Tsen rank}}
{{defn|1=The [[Tsen rank]] of a field, named for [[C. C. Tsen]] who introduced their study in 1936,&lt;ref&gt;{{cite journal | first=C. | last=Tsen | authorlink=C. C. Tsen | title=Zur Stufentheorie der Quasi-algebraisch-Abgeschlossenheit kommutativer KÃ¶rper | journal=J. Chinese Math. Soc. | volume=171 | year=1936 | pages=81â92 | zbl=0015.38803 }}&lt;/ref&gt; is the smallest natural number ''i'', if it exists, such that the field is of class T&lt;sub&gt;''i''&lt;/sub&gt;: that is, such that any system of polynomials with no constant term of degree ''d&lt;sub&gt;j&lt;/sub&gt;'' in ''n'' variables has a non-trivial zero whenever ''n'' &amp;gt; â ''d''&lt;sub&gt;''j''&lt;/sub&gt;&lt;sup&gt;''i''&lt;/sup&gt;. Algebraically closed fields are of Tsen rank zero. The Tsen rank is greater or equal to the [[Diophantine dimension]] but it is not known if they are equal except in the case of rank zero.&lt;ref&gt;{{cite book | first=Falko | last=Lorenz | title=Algebra. Volume II: Fields with Structure, Algebras and Advanced Topics | year=2008 | publisher=Springer | isbn=978-0-387-72487-4 | pages=109â126 }}&lt;/ref&gt;}}

==U==

{{term|Uniformity conjecture}}
{{defn|1=The ''uniformity conjecture'' states that for any number field ''K'' and ''g'' &gt; 2, there is a uniform bound ''B''(''g'',''K'') on the number of ''K''-rational points on any curve of genus ''g''. The conjecture would follow from the [[BombieriâLang conjecture]].&lt;ref&gt;{{cite journal | zbl=0872.14017 | last1=Caporaso | first1=Lucia | author1-link = Lucia Caporaso | last2=Harris | first2=Joe | author2-link = Joe Harris (mathematician) | last3=Mazur | first3=Barry | author3-link = Barry Mazur | title=Uniformity of rational points | journal=[[Journal of the American Mathematical Society]] | volume=10 | number=1 | year=1997 | pages=1â35 | url=http://www.ams.org/journals/jams/1997-10-01/S0894-0347-97-00195-1/home.html | doi=10.2307/2152901 }}&lt;/ref&gt;}}

{{term|Unlikely intersection}}
{{defn|1=An ''unlikely intersection'' is an algebraic subgroup intersecting a subvariety of a torus or abelian variety in a set of unusually large dimension, such as is involved in the [[MordellâLang conjecture]].&lt;ref&gt;{{cite book | title=Some Problems of Unlikely Intersections in Arithmetic and Geometry | series=Annals of Mathematics Studies | volume=181 | first=Umberto | last=Zannier | isbn=978-0-691-15371-1 | publisher=[[Princeton University Press]] | year=2012 }}&lt;/ref&gt;}}

==V==

{{term|Vojta conjecture}}
{{defn|1=The [[Vojta conjecture]] is a complex of conjectures by [[Paul Vojta]], making analogies between [[Diophantine approximation]] and [[Nevanlinna theory]].}}

==W==

{{term|Weights}}
{{defn|1=The [[yoga of weights]] is a formulation by [[Alexander Grothendieck]] of analogies between [[Hodge theory]] and [[l-adic cohomology]].&lt;ref&gt;[[Pierre Deligne]], ''Poids dans la cohomologie des variÃ©tÃ©s algÃ©briques'', Actes ICM, Vancouver, 1974, 79â85.&lt;/ref&gt;}}

{{term|Weil cohomology}}
{{defn|1=The initial idea, later somewhat modified, for proving the Weil conjectures (q.v.), was to construct a [[cohomology theory]] applying to algebraic varieties over [[finite field]]s that would both be as good as [[singular homology]] at detecting topological structure, and have [[Frobenius mapping]]s acting in such a way that the [[Lefschetz fixed-point theorem]] could be applied to the counting in [[local zeta-function]]s. For later history see [[motive (algebraic geometry)]], [[motivic cohomology]].}}

{{term|Weil conjectures}}
{{defn|1=The [[Weil conjectures]] were three highly influential conjectures of [[AndrÃ© Weil]], made public around 1949, on local zeta-functions. The proof was completed in 1973. Those being proved, there remain extensions of the [[ChevalleyâWarning theorem]] congruence, which comes from an elementary method, and [[improvements of Weil bounds]], e.g. better estimates for curves of the number of points than come from Weil's basic theorem of 1940. The latter turn out to be of interest for [[Goppa code]]s.}}

{{term|Weil distributions on algebraic varieties}}
{{defn|1=AndrÃ© Weil proposed a theory in the 1920s and 1930s on [[prime ideal]] decomposition of algebraic numbers in coordinates of points on algebraic varieties. It has remained somewhat under-developed.}}

{{term|Weil function}}
{{defn|1=A ''Weil function'' on an algebraic variety is a real-valued function defined off some [[Cartier divisor]] which generalises the concept of [[Green's function]] in [[Arakelov theory]].&lt;ref&gt;Lang (1988) pp.1â9&lt;/ref&gt; They are used in the construction of the local components of the [[NÃ©ronâTate height]].&lt;ref name=L164&gt;Lang (1997) pp.164,212&lt;/ref&gt;}}

{{term|Weil height machine}}

{{defn|1=The ''Weil height machine'' is an effective procedure for assigning a height function to any divisor on smooth projective variety over a number field (or to [[Cartier divisor]]s on non-smooth varieties).&lt;ref&gt;Hindry &amp; Silverman (2000) 184â185&lt;/ref&gt;}}

{{compact ToC|side=yes|top=yes|num=yes}}

==See also==
*[[Arithmetic topology]]
*[[Arithmetic dynamics]]

==References==
{{reflist|30em}}
* {{cite book | first1=Enrico | last1=Bombieri | authorlink1=Enrico Bombieri | first2=Walter | last2=Gubler | title=Heights in Diophantine Geometry | series=New Mathematical Monographs | volume=4 | publisher=[[Cambridge University Press]] | year=2006 | isbn=978-0-521-71229-3 | zbl=1130.11034 | doi=10.2277/0521846153 }}
* {{cite book | first1=Marc | last1=Hindry | first2=Joseph H. | last2=Silverman | authorlink2=Joseph H. Silverman | title=Diophantine Geometry: An Introduction | series=[[Graduate Texts in Mathematics]] | volume=201 | year=2000 | isbn=0-387-98981-1 | zbl=0948.11023 }}
* {{cite book | first=Serge | last=Lang | authorlink=Serge Lang | title=Introduction to Arakelov theory | publisher=[[Springer-Verlag]] | place=New York | year=1988 | isbn=0-387-96793-1 | mr=0969124 | zbl=0667.14001 }}
* {{cite book | first=Serge | last=Lang | authorlink=Serge Lang | title=Survey of Diophantine Geometry | publisher=[[Springer-Verlag]] | year=1997 | isbn=3-540-61223-8 | zbl=0869.11051 }}
* {{cite book | first=JÃ¼rgen | last=Neukirch | authorlink=JÃ¼rgen Neukirch | title=Algebraic Number Theory | volume=322 | series=Grundlehren der Mathematischen Wissenschaften | publisher=[[Springer-Verlag]] | year=1999 | isbn=978-3-540-65399-8 | zbl=0956.11021 }}

==Further reading==
*Dino Lorenzini (1996), [https://books.google.com/books?id=c8vnGts4994C An invitation to arithmetic geometry], AMS Bookstore, {{ISBN|978-0-8218-0267-0}}

{{Number theory-footer}}

[[Category:Diophantine geometry]]
[[Category:Algebraic geometry]]
[[Category:Glossaries of mathematics|Geometry]]</text>
      <sha1>3sck5wknpbc0wquyv5uz7ywwyf8duuw</sha1>
    </revision>
  </page>
  <page>
    <title>Gosper's algorithm</title>
    <ns>0</ns>
    <id>19590493</id>
    <revision>
      <id>786599958</id>
      <parentid>649833160</parentid>
      <timestamp>2017-06-20T12:45:15Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3720">In [[mathematics]], '''Gosper's algorithm''' is a procedure for finding sums of [[Hypergeometric identities|hypergeometric terms]] that are themselves hypergeometric terms. That is: suppose we have ''a''(1)&amp;nbsp;+&amp;nbsp;...&amp;nbsp;+&amp;nbsp;''a''(''n'') = ''S''(''n'')&amp;nbsp;&amp;minus;&amp;nbsp;''S''(0), where ''S''(''n'') is a hypergeometric term (i.e., ''S''(''n''&amp;nbsp;+&amp;nbsp;1)/''S''(''n'') is a [[rational function]] of ''n''); then necessarily ''a''(''n'') is itself a hypergeometric term, and given the formula for ''a''(''n'') Gosper's algorithm finds that for ''S(''n'').

==Outline of the algorithm==

Step 1: Find a polynomial ''p'' such that, writing ''b''(''n'') = ''a''(''n'')/''p''(''n''), the ratio ''b''(''n'')/''b''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1) has the form ''q''(''n'')/''r''(''n'') where ''q'' and ''r'' are polynomials and no ''q''(''n'') has a nontrivial factor with ''r''(''n''&amp;nbsp;+&amp;nbsp;''j'') for ''j'' = 0,&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;...&amp;nbsp;. (This is always possible, whether or not the series is summable in closed form.)

Step 2: Find a polynomial ''Æ'' such that ''S''(''n'') = ''q''(''n''&amp;nbsp;+&amp;nbsp;1)/''p''(''n'') ''Æ''(''n'') ''a''(''n''). If the series is summable in closed form then clearly a rational function ''Æ'' with this property exists; in fact it must always be a polynomial, and an upper bound on its degree can be found. Determining ''Æ'' (or finding that there is no such ''Æ'') is then a matter of solving a system of linear equations.

==Relationship to Wilf&amp;ndash;Zeilberger pairs==

Gosper's algorithm can be used to discover [[Wilf&amp;ndash;Zeilberger pair]]s, where they exist. Suppose that ''F''(''n''&amp;nbsp;+&amp;nbsp;1,&amp;nbsp;''k'')&amp;nbsp;&amp;minus;&amp;nbsp;''F''(''n'',&amp;nbsp;''k'') = ''G''(''n'',&amp;nbsp;''k''&amp;nbsp;+&amp;nbsp;1)&amp;nbsp;&amp;minus;&amp;nbsp;''G''(''n'',&amp;nbsp;''k'') where ''F'' is known but ''G'' is not. Then feed ''a''(''k'') := ''F''(''n''&amp;nbsp;+&amp;nbsp;1,&amp;nbsp;''k'')&amp;nbsp;&amp;minus;&amp;nbsp;''F''(''n'',&amp;nbsp;''k'') into Gosper's algorithm. (Treat this as a function of k whose coefficients happen to be functions of n rather than numbers; everything in the algorithm works in this setting.) If it successfully finds ''S''(''k'') with ''S''(''k'')&amp;nbsp;&amp;minus;&amp;nbsp;''S''(''k''&amp;nbsp;&amp;minus;&amp;nbsp;1) = ''a''(''k''), then we are done: this is the required ''G''. If not, there is no such ''G''.

==Definite versus indefinite summation==

Gosper's algorithm finds (where possible) a hypergeometric closed form for the ''indefinite'' sum of hypergeometric terms. It can happen that there is no such closed form, but that the sum over ''all'' ''n'', or some particular set of values of n, has a closed form. This question is only meaningful when the coefficients are themselves functions of some other variable. So, suppose a(n,k) is a hypergeometric term in both ''n'' and ''k'': that is, ''a''(''n'',&amp;nbsp;''k'')/''a''(''n''&amp;nbsp;&amp;minus;&amp;nbsp;1,''k'') and ''a''(''n'',&amp;nbsp;''k'')/''a''(''n'',&amp;nbsp;''k''&amp;nbsp;&amp;minus;&amp;nbsp;1) are rational functions of ''n'' and ''k''. Then [[Zeilberger's algorithm]] and [[PetkovÅ¡ek's algorithm]] may be used to find closed forms for the sum over ''k'' of ''a''(''n'',&amp;nbsp;''k'').

==History==

[[Bill Gosper]] discovered this algorithm in the 1970s while working on the [[Macsyma]] computer algebra system at [[Stanford Artificial Intelligence Laboratory|SAIL]] and [[MIT]].

==Further reading==
*[[Marko PetkovÅ¡ek]], [[Herbert Wilf]] and [[Doron Zeilberger]], ''A&amp;nbsp;=&amp;nbsp;B'', AK Peters 1996, {{isbn|1-56881-063-6}}.  Full text online.[http://www.math.upenn.edu/~wilf/AeqB.html]
*[http://www.pnas.org/cgi/reprint/75/1/40.pdf Gosper's 1977 article in PNAS] reporting on the algorithm.

[[Category:Computer algebra]]
[[Category:Hypergeometric functions]]</text>
      <sha1>q5um644bx7jpbc0tcdnviv6ngzgzdff</sha1>
    </revision>
  </page>
  <page>
    <title>Grothendieck connection</title>
    <ns>0</ns>
    <id>5852751</id>
    <revision>
      <id>751312481</id>
      <parentid>740973147</parentid>
      <timestamp>2016-11-24T20:27:09Z</timestamp>
      <contributor>
        <username>Fixer88</username>
        <id>9945971</id>
      </contributor>
      <comment>Disambiguated: [[curvature tensor]] â [[Affine connection]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3425">In [[algebraic geometry]] and [[synthetic differential geometry]], a '''Grothendieck connection''' is a way of viewing [[connection (mathematics)|connections]] in terms of descent data from infinitesimal neighbourhoods of the diagonal.

==Introduction and motivation==
The Grothendieck connection is a generalization of the [[GaussâManin connection]] constructed in a manner analogous to that in which the [[Ehresmann connection]] generalizes the [[covariant derivative#Koszul connection|Koszul connection]].  The construction itself must satisfy a requirement of ''geometric invariance'', which may be regarded as the analog of [[covariance]] for a wider class of structures including the [[scheme (mathematics)|schemes]] of algebraic geometry.  Thus the connection in a certain sense must live in a natural [[sheaf (mathematics)|sheaf]] on a [[Grothendieck topology]].  In this section, we discuss how to describe an Ehresmann connection in sheaf-theoretic terms as a Grothendieck connection.

Let ''M'' be a [[manifold (mathematics)|manifold]] and Ï : ''E'' â ''M'' a [[surjective]] [[submersion (mathematics)|submersion]], so that ''E'' is a manifold fibred over ''M''.  Let J&lt;sup&gt;1&lt;/sup&gt;(''M'',''E'') be the first-order [[jet bundle]] of sections of ''E''.  This may be regarded as a bundle over ''M'' or a bundle over the total space of ''E''.  With the latter interpretation, an Ehresmann connection is a section of the bundle (over ''E'') J&lt;sup&gt;1&lt;/sup&gt;(''M'',''E'') â ''E''.  The problem is thus to obtain an intrinsic description of the sheaf of sections of this vector bundle.

Grothendieck's solution is to consider the diagonal embedding Î : ''M'' â ''M'' &amp;times; ''M''.  The sheaf ''I'' of ideals of Î in ''M'' &amp;times; ''M'' consists of functions on ''M'' &amp;times; ''M'' which vanish along the diagonal.  Much of the infinitesimal geometry of ''M'' can be realized in terms of ''I''.  For instance, Î&lt;sup&gt;*&lt;/sup&gt; (''I''/''I''&lt;sup&gt;2&lt;/sup&gt;) is the sheaf of sections of the [[cotangent bundle]].  One may define a ''first-order infinitesimal neighborhood'' ''M''&lt;sup&gt;(2)&lt;/sup&gt; of Î in ''M'' &amp;times; ''M'' to be the [[scheme (mathematics)|subscheme]] corresponding to the sheaf of ideals ''I''&lt;sup&gt;2&lt;/sup&gt;.  (See below for a coordinate description.)  

There are a pair of projections  ''p''&lt;sub&gt;1&lt;/sub&gt;, ''p''&lt;sub&gt;2&lt;/sub&gt; : ''M'' &amp;times; ''M'' â ''M'' given by projection the respective factors of the Cartesian product, which restrict to give projections ''p''&lt;sub&gt;1&lt;/sub&gt;, ''p''&lt;sub&gt;2&lt;/sub&gt; : ''M''&lt;sup&gt;(2)&lt;/sup&gt; â ''M''.  One may now form the [[pullback bundle|pullback]] of the fibre space ''E'' along one or the other of ''p''&lt;sub&gt;1&lt;/sub&gt; or ''p''&lt;sub&gt;2&lt;/sub&gt;.  In general, there is no canonical way to identify ''p''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;''E'' and ''p''&lt;sub&gt;2&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt;''E'' with each other.  A '''Grothendieck connection''' is a specified isomorphism between these two spaces. One may proceed to define [[Affine connection|curvature]] and [[p-curvature]] of a connection in the same language.

==References==
# Osserman, B., "Connections, curvature, and p-curvature", ''preprint''. &lt;!-- Definitely need to find a more authoritative reference --&gt;
# Katz, N., "Nilpotent connections and the monodromy theorem", ''IHES Publ. Math.'' '''39''' (1970) 175â232. &lt;!--Looks promising, but need to read it carefully.--&gt;

[[Category:Connection (mathematics)]]
[[Category:Algebraic geometry]]</text>
      <sha1>s847n5xterf1d41u07xnms8hmfovaxm</sha1>
    </revision>
  </page>
  <page>
    <title>Helene StÃ¤helin</title>
    <ns>0</ns>
    <id>54388740</id>
    <revision>
      <id>861375500</id>
      <parentid>837331907</parentid>
      <timestamp>2018-09-26T23:57:11Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4991">[[File:Rosenblatt Stahelin Tonolo Zullig Zurich1932.tif|thumb|''Left to right:'' {{ill|Alfred Rosenblatt|es}}, [[Helene StÃ¤helin (mathematician)|Helene StÃ¤helin]] (in background), {{ill|Angelo Tonolo|it}}, and J. ZÃ¼llig, at the [[International Congress of Mathematicians]], [[ZÃ¼rich]] 1932]]
'''Helene StÃ¤helin''' (18 July 1891 [[Wintersingen]] â 30 December 1970 [[Basel]]) was a Swiss mathematician, teacher, and peace activist.&lt;ref name="Nipp.2014"&gt;{{cite web|title=Personenlexikon des Kanton Basel-Landschaft &amp;mdash; Helene StÃ¤helin|author=Manuela Nipp|url=https://personenlexikon.bl.ch/Helene_St%C3%A4helin|accessdate=25 Jun 2017}}&lt;/ref&gt; 
Between 1948 and 1967, she was president of the Swiss section of the [[Women's International League for Peace and Freedom]] and its representant in the Swiss Peace Council.&lt;ref name="Ludi.1998"&gt;{{cite web|title=No 12 &amp;mdash; StÃ¤helin, Helene | author=Regula Ludi|url=http://www.hls-dhs-dss.ch/textes/d/D21110.php|accessdate=25 Jun 2017}}&lt;/ref&gt;&lt;ref name="Willi.0000"&gt;{{cite web|title=Geschichte der WILPFSchweiz &amp;mdash; Eine Bewegung entsteht|author=Irene Willi|url= http://www.wilpfschweiz.ch/index.php?option=com_content&amp;task=view&amp;id=34&amp;Itemid=45 |accessdate=25 Jun 2017}}&lt;/ref&gt;

==Early life and scientific work==
She was one of twelve childs of the parson Gustav StÃ¤helin (1858&amp;ndash;1934)&lt;ref&gt;{{cite web|title="Online Catalogue of the State Archives Basel-Stadt &amp;mdash; PA 182a B 55 Gustav StÃ¤helin-Lieb (1858-1934), Pfr. Â§ 113 bzw. 207 neu, s.d. (sine dato) (Serie)|url=https://query.staatsarchiv.bs.ch/query/detail.aspx?ID=421954|accessdate=25 Jun 2017}}&lt;/ref&gt; and his wife Luise, nÃ©e Lieb. In 1894, the family moved from Wintersingen to Allschwil.
Helene StÃ¤helin attended the ''TÃ¶chterschule'' Basel and the Universities [[Basel University|Basel]] and [[GÃ¶ttingen University|GÃ¶ttingen]].
In 1922, she became teacher of mathematics and natural sciences at the ''TÃ¶chterinstitut''&lt;sup&gt;([[:de:Ftan#Bildung|de]])&lt;/sup&gt; in [[Ftan]].&lt;ref name="Nipp.2014"/&gt;
In 1924, she obtained her ''Dr.phil.'' degree&lt;ref name="query.staatsarchiv.bs.ch"&gt;{{cite web|title=Online Catalogue of the State Archives Basel-Stadt &amp;mdash; PA 182a B 90 Helene Staehelin (1891-1971), Dr. phil. Â§ 207,4 neu, 1955 (Serie)|url=https://query.staatsarchiv.bs.ch/query/detail.aspx?ID=422294|accessdate=25 Jun 2017}}&lt;/ref&gt;
from Basel University for her dissertation ''Die charakteristischen Zahlen analytischer Kurven auf dem Kegel zweiter Ordnung und ihrer [[Eduard Study|Study]]schen Bildkurven'', advised by [[Hans Mohrmann]] and {{ill|Otto Spiess|de}}.&lt;ref name="Nipp.2014"/&gt;&lt;ref&gt;{{cite thesis | type=Ph.D. thesis | url= | author=Helene StÃ¤helin | title=Die charakteristischen Zahlen analytischer Kurven auf dem Kegel zweiter Ordnung und ihrer Studyschen Bildkurven | institution=Basel University | year=1924 }}
&lt;/ref&gt;&lt;ref&gt;{{cite journal | url=http://gdz.sub.uni-goettingen.de/download/PPN235181684_0093/PPN235181684_0093___LOG_0019.pdf | author=Helene StÃ¤helin | title=Die charakteristischen Zahlen analytischer Kurven auf dem Kegel zweiter Ordnung und ihrer Studyschen Bildkurven | journal=[[Mathematische Annalen]] | volume=93  | pages=217&amp;mdash;229 | year=1925 }}&lt;/ref&gt;
In 1926, she became a member of the [[Swiss Mathematical Society]].
Between 1934 and 1956, Helene StÃ¤helin worked as teacher at the Protestant secondary school in [[Zug]].
After her pensioning she returned to Basel, where she assisted for several years to Otto Spiess' editing the [[Bernoulli family]] letters.&lt;ref name="Nipp.2014"/&gt;&lt;ref&gt;S. Gehr, F. Nagel, B. v. Reibnitz (Ed.), [http://www.margini.unibas.ch/web/resource/CatalogoBasel.pdf ''Editionen in Basel''], 2010, p.22-23 (20-21)&lt;/ref&gt;

==Political activism==
Being a pacifist, Helene StÃ¤helin committed herself to the [[Women's International League for Peace and Freedom]] (''Internationale Frauenliga fÃ¼r Frieden und Freiheit'', IFFF) and its struggle against scientific warfare.
She was president of the IFFF's Swiss section in 1947&amp;ndash;1967, when the main issues were the [[United Nations]] Organization, [[nuclear weapons]], and the [[Vietnam War]].&lt;ref name="Nipp.2014"/&gt;
Due to her peace activism, she was watched by Swiss authorities in the mid 1950s,&lt;ref name="Nipp.2014"/&gt;
her file at the {{ill|Swiss Public Prosecutor General|de|Schweizerische Bundesanwaltschaft}} was kept secret until 1986.&lt;ref name="query.staatsarchiv.bs.ch"/&gt;
Helene StÃ¤helin also was active towards [[Women's suffrage in Switzerland]],&lt;ref name="Nipp.2014"/&gt;
which was, however, not gained during her lifetime.

==References==
{{reflist}}


{{authority control}}

[[Category:Swiss mathematicians]]
[[Category:1891 births]]
[[Category:1970 deaths]]
[[Category:People from Basel-Stadt]]
[[Category:Women mathematicians]]
[[Category:Swiss pacifists]]
[[Category:Antiânuclear weapons activists]]
[[Category:AntiâVietnam War activists]]
[[Category:Women's suffrage]]
[[Category:Women's rights in Switzerland]]


{{mathematician-stub}}</text>
      <sha1>40907do1oxiox1eaj1cuqialrzb0v0n</sha1>
    </revision>
  </page>
  <page>
    <title>Hodge star operator</title>
    <ns>0</ns>
    <id>310914</id>
    <revision>
      <id>862709411</id>
      <parentid>861501677</parentid>
      <timestamp>2018-10-06T05:20:51Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32349">In [[mathematics]], the '''Hodge star operator''' or '''Hodge star''' is a [[linear map]] introduced by [[W. V. D. Hodge]].  It is defined on the [[exterior algebra]] of a finite-dimensional [[orientation (mathematics)|oriented]] [[vector space]] endowed with a [[Degenerate bilinear form|nondegenerate]] [[symmetric bilinear form]].  The result when applied to an element of the algebra is called the element's '''Hodge dual'''.

For example, in 3-dimensional Euclidean space, every oriented plane has an unique [[normal vector]], and every vector can be used to define a plane perpendicular to that vector. The Hodge star can be thought of as generalizing this relationship: in general, for an {{mvar|n}}-dimensional vector space, the Hodge star maps {{mvar|k}}-vectors to {{nowrap|({{mvar|n}} â {{mvar|k}})}}-vectors and vice versa.

==Dimensions and algebra==
Suppose that {{mvar|n}} is the dimension of the oriented inner product space and {{mvar|k}} is an integer such that {{math|0 â¤ ''k'' â¤ ''n''}}, then the Hodge star operator establishes a one-to-one mapping from the space of [[p-vector|{{mvar|k}}-vectors]] to the space of {{math|(''n'' â ''k'')}}-vectors.  The image of a {{mvar|k}}-vector under this mapping is called its ''Hodge dual''. The former space, of {{mvar|k}}-vectors, has dimension &lt;math&gt;\tbinom{n}{k} &lt;/math&gt;, while the latter has dimension &lt;math&gt;\tbinom{n}{n - k}&lt;/math&gt;, which are equal by the symmetry of the [[binomial coefficient]]s. Equal-dimensional [[vector space]]s are always [[isomorphic]], but not necessarily in a natural or canonical way. In this case, however, Hodge duality exploits the nondegenerate symmetric bilinear form, hereafter referred to as the ''inner product'' (though it might not be positive definite), and a choice of orientation to single out a unique isomorphism, which parallels the combinatorial symmetry of binomial coefficients. This in turn induces an inner product on the space of {{mvar|k}}-vectors. The naturalness of this definition means the duality can play a role in differential geometry.

The first interesting case is on three-dimensional [[Euclidean space]] {{mvar|V}}. In this context the relevant row of [[Pascal's triangle]] reads

:{{math|1, 3, 3, 1}}

and the Hodge star sets up an isomorphism between the two three-dimensional spaces, which are {{mvar|V}} and the image space of the [[exterior product]] acting on pairs of vectors in {{mvar|V}}. See ''{{section link||Examples}}'' for details. In this case the Hodge star allows the definition of the [[cross product]] of traditional [[vector calculus]] in terms of the exterior product. While the properties of the cross product are special to three dimensions, the Hodge star applies to an arbitrary number of dimensions.

==Extensions==
Since the space of alternating linear forms in {{mvar|k}} arguments on a vector space is naturally isomorphic to the dual of the space of {{mvar|k}}-vectors over that vector space, the Hodge star can be defined for these spaces as well.  As with most constructions from linear algebra, the Hodge star can then be extended to a [[vector bundle]].  Thus a context in which the Hodge star is very often seen is the exterior algebra of the cotangent bundle, the space of differential forms on a manifold, where it can be used to construct the [[#Codifferential|codifferential]] from the [[exterior derivative]], and thus the [[Laplaceâde Rham operator]], which leads to the [[Hodge decomposition]] of [[differential forms]] in the case of [[Compact space|compact]] [[Riemannian manifold]]s.

==Formal definition for {{math|''k''}}-vectors==
The '''Hodge star operator''' on a [[vector space]] {{math|''V''}} with an inner product is a linear operator on the [[exterior algebra]] of {{math|''V''}}, mapping {{mvar|k}}-vectors to {{math|(''n'' â ''k'')}}-vectors where {{math|''n'' {{=}} dim ''V''}}, for {{math|0 â¤ ''k'' â¤ ''n''}}. It has the following property, which defines it completely: given two {{math|''k''}}-vectors {{math|''Î±'', ''Î²''}},

:&lt;math&gt;\alpha \wedge (\star \beta) = \langle \alpha,\beta \rangle \,\omega&lt;/math&gt;

where &lt;math&gt;\langle \cdot,\cdot \rangle&lt;/math&gt; denotes the [[Exterior algebra#Inner product|inner product on {{mvar|k}}-vectors]] and {{mvar|Ï}} is the preferred unit {{mvar|n}}-vector.

The inner product &lt;math&gt;\langle \cdot,\cdot \rangle&lt;/math&gt; on {{mvar|k}}-vectors is extended from that on {{mvar|V}} by requiring that for any decomposable {{mvar|k}}-vectors &lt;math&gt;\alpha = \alpha_1 \wedge \cdots \wedge \alpha_k&lt;/math&gt; and &lt;math&gt;\beta = \beta_1 \wedge \cdots \wedge \beta_k&lt;/math&gt; it equals the [[Gram determinant]]

:&lt;math&gt; \langle \alpha,\beta \rangle = \det \left[ \left\langle \alpha_i,\beta_j \right\rangle \right] .&lt;/math&gt;

The unit {{mvar|n}}-vector {{mvar|Ï}} is unique up to a sign. The preferred choice of {{mvar|Ï}} defines an [[orientation (vector space)|orientation]] on {{mvar|V}}.

==Explanation==
Let {{mvar|W}} be a vector space, with an inner product &lt;math&gt;\langle\cdot, \cdot\rangle_W&lt;/math&gt;. The [[Riesz representation theorem]] states that for every continuous (even in the infinite-dimensional case) [[linear functional]] &lt;math&gt;f \in W^*&lt;/math&gt; there exists a unique vector {{mvar|v}} in {{mvar|W}} such that &lt;math&gt;f(w) = \langle w, v \rangle_W&lt;/math&gt; for all {{mvar|w}} in {{mvar|W}}. The map &lt;math&gt;W^* \to W&lt;/math&gt; given by &lt;math&gt;f \mapsto v&lt;/math&gt; is an isomorphism. (If {{mvar|W}} is complex, the map is ''conjugate linear'' as opposed to complex linear.) This holds for ''all'' vector spaces with an inner product, and can be used to explain the Hodge star.

Let {{mvar|V}} be an {{mvar|n}}-dimensional vector space with basis &lt;math&gt;\{e_1,\ldots,e_n\}&lt;/math&gt;. For {{math|0 â¤ ''k'' â¤ ''n''}}, consider the exterior power spaces &lt;math&gt;{\textstyle\bigwedge}^k V&lt;/math&gt; and &lt;math&gt;{\textstyle\bigwedge}^{n-k} V&lt;/math&gt;. For

:&lt;math&gt;\lambda \in {\textstyle\bigwedge}^k V, \quad \theta \in {\textstyle\bigwedge}^{n-k} V,&lt;/math&gt;

we have

:&lt;math&gt;\lambda \wedge \theta \in {\textstyle\bigwedge}^n V.&lt;/math&gt;

There is, up to a scalar, only one {{mvar|n}}-vector (an {{mvar|n}}-form), namely &lt;math&gt;e_1\wedge\ldots\wedge e_n&lt;/math&gt;. In other words, &lt;math&gt;\lambda \wedge \theta&lt;/math&gt; must be a scalar multiple of &lt;math&gt;e_1\wedge\ldots\wedge e_n&lt;/math&gt; for all &lt;math&gt;\lambda \in {\textstyle\bigwedge}^k V&lt;/math&gt; and &lt;math&gt;\theta \in {\textstyle\bigwedge}^{n-k} V&lt;/math&gt;.

Consider a ''fixed'' &lt;math&gt;\lambda \in {\textstyle\bigwedge}^k V&lt;/math&gt;. There exists a unique linear function

:&lt;math&gt;f_{\lambda} \in \left({\textstyle\bigwedge}^{n-k} V\right)^{\! *}&lt;/math&gt;

such that

:&lt;math&gt;\forall \theta \in {\textstyle\bigwedge}^{n-k} V: \qquad \lambda \wedge \theta = f_{\lambda}(\theta) \, (e_1\wedge\ldots\wedge e_n).&lt;/math&gt;

This &lt;math&gt;f_{\lambda}(\theta)&lt;/math&gt; is the scalar multiple mentioned in the previous paragraph. If &lt;math&gt;\langle\cdot, \cdot\rangle&lt;/math&gt; denotes the [[Exterior algebra#Inner product|inner product on {{math|(''n'' â ''k'')}}-vectors]], then there exists a unique {{math|(''n'' â ''k'')}}-vector, say

:&lt;math&gt;\star \lambda \in {\textstyle\bigwedge}^{n-k} V,&lt;/math&gt;

such that

:&lt;math&gt;\forall \theta \in {\textstyle\bigwedge}^{n-k} V: \qquad f_{\lambda}(\theta) = \langle \theta, \star \lambda\rangle.&lt;/math&gt;

This {{math|(''n'' â ''k'')}}-vector {{math|â''Î»''}} is the Hodge dual of {{mvar|Î»}}, and is the image of the &lt;math&gt;f_{\lambda}&lt;/math&gt; under the isomorphism induced by the inner product,

:&lt;math&gt;\left({\textstyle\bigwedge}^{n-k} V\right)^{\! *} \cong {\textstyle\bigwedge}^{n-k} V.&lt;/math&gt;

Thus,

:&lt;math&gt; \star : {\textstyle\bigwedge}^{k} V \to {\textstyle\bigwedge}^{n-k} V.&lt;/math&gt;

==Computation of the Hodge star==
Given an orthonormal basis &lt;math&gt;(e_1,\cdots,e_n)&lt;/math&gt; ordered such that &lt;math&gt;\omega = e_1\wedge \cdots \wedge e_n&lt;/math&gt;, for a positive-definite metric, we see that

:&lt;math&gt;\star (e_{i_1} \wedge e_{i_2}\wedge \cdots \wedge e_{i_k})= e_{i_{k+1}} \wedge e_{i_{k+2}} \wedge \cdots \wedge e_{i_n},&lt;/math&gt;

where &lt;math&gt;(i_1, i_2, \cdots, i_n)&lt;/math&gt; is an even permutation of {{math|{1, 2, ..., ''n''}.}}

Of these &lt;math&gt;n! \over 2&lt;/math&gt; relations, only &lt;math&gt;n \choose k&lt;/math&gt; are independent. The first one in the usual [[lexicographical order]] reads

:&lt;math&gt;\star (e_1\wedge e_2\wedge \cdots \wedge e_k)= e_{k+1}\wedge e_{k+2}\wedge \cdots \wedge e_n.&lt;/math&gt;

==Expression in index notation==
Using [[tensor index notation]], the Hodge dual of an arbitrary wedge product of one-forms is given by the following:

:&lt;math&gt;
\star(dx^{i_1} \wedge \dots \wedge dx^{i_k}) = \frac{\sqrt{|\det g|}}{(n-k)!} g^{i_1 j_1} \dots g^{i_k j_k} \varepsilon_{j_1 \dots j_n} dx^{j_{k+1}} \wedge \dots \wedge dx^{j_n}.
&lt;/math&gt;

The symbol &lt;math&gt;\varepsilon_{j_1 \dots j_n}&lt;/math&gt; is the [[Levi-Civita symbol]] defined so that &lt;math&gt;\varepsilon_{1 \dots n} = 1&lt;/math&gt; and &lt;math&gt;g^{ij}&lt;/math&gt; is the inverse metric. Note that the factorial &lt;math&gt;(n-k)!&lt;/math&gt; had to be inserted to account for double counting, and cancels out if one orders the summation indices so that &lt;math&gt;j_{k+1} &lt; \dots &lt; j_n&lt;/math&gt;.  The absolute value of the determinant is necessary since it may be negative, e.g. for tangent spaces to [[Pseudo-Riemannian manifold#Lorentzian manifold|Lorentzian manifold]]s.

An arbitrary differential form can be expanded into its components as follows:

:&lt;math&gt;
\alpha = \frac{1}{k!}\alpha_{i_1, \dots, i_k} dx^{i_1}\wedge \dots \wedge dx^{i_k} = \sum_{i_1 &lt; \dots &lt; i_k} \alpha_{i_1, \dots, i_k} dx^{i_1}\wedge \dots \wedge dx^{i_k}
&lt;/math&gt;

The factorial &lt;math&gt;k!&lt;/math&gt; is again included to account for double counting. We would like to define the dual of the component &lt;math&gt;\alpha_{i_1, \dots, i_k}&lt;/math&gt; so that the Hodge dual of the form is given by 

:&lt;math&gt;
(\star\alpha) = \frac{1}{(n-k)!}(\star \alpha)_{i_{k+1}, \dots, i_n} dx^{i_{k+1}} \wedge \dots \wedge dx^{i_n}.
&lt;/math&gt;

Thus using the expression for the Hodge dual of &lt;math&gt;dx^{i_1} \wedge \dots \wedge dx^{i_k}&lt;/math&gt; given at the beginning of this section we find&lt;ref&gt;{{cite book |title=The Geometry of Physics |edition=3rd |first=T. |last=Frankel |publisher=Cambridge University Press |year=2012 |isbn=978-1-107-60260-1 }}&lt;/ref&gt;

:&lt;math&gt;
(\star \alpha)_{i_{k+1}, \dots, i_n} = \frac{\sqrt{|\det g|}}{k!} \alpha^{i_1, \dots, i_k}\, \,\varepsilon_{i_1, \dots, i_n}
&lt;/math&gt;

It is understood that [[raising and lowering indices|indices are raised and lowered]] using the same inner product &lt;math&gt;g&lt;/math&gt; as in the definition of the Levi-Civita tensor. Although one can apply this expression to any tensor &lt;math&gt;\alpha&lt;/math&gt;, the result is antisymmetric, since contraction with the completely anti-symmetric Levi-Civita symbol cancels all but the totally antisymmetric part of the tensor.  It is thus equivalent to antisymmetrization followed by applying the Hodge star.

==Examples==

===Two dimensions===
In two dimensions with the normalized Euclidean metric and orientation given by the ordering {{math|(''x'', ''y'')}}, the Hodge star on {{math|''k''}}-forms is given by

:&lt;math&gt; {\star} \, 1 = dx \wedge dy &lt;/math&gt;
:&lt;math&gt; {\star} \, dx = dy &lt;/math&gt;
:&lt;math&gt; {\star} \, dy = -dx &lt;/math&gt;
:&lt;math&gt; {\star} ( dx \wedge dy ) = 1 .&lt;/math&gt;

The complex plane has the remarkable property that it is invariant under [[holomorphic]] changes of coordinate.
If {{math|''z'' {{=}} ''x'' + ''iy''}} is a holomorphic function of {{math|''w'' {{=}} ''u'' + ''iv''}}, then by the [[CauchyâRiemann equations]] {{math|{{sfrac|â''x''|â''u''}} {{=}} {{sfrac|â''y''|â''v''}}}} and {{math|{{sfrac|â''y''|â''u''}} {{=}} â{{sfrac|â''x''|â''v''}}}}. In the new coordinates

:&lt;math&gt; \alpha = p \,dx + q \,dy = \left( p \frac{\partial x}{\partial u} + q \frac{\partial y}{\partial u} \right) \,du + \left( p \frac{\partial x}{\partial v} + q \frac{\partial y}{\partial v} \right) \,dv = p_1 du + q_1 \, dv ,&lt;/math&gt;

so that

: &lt;math&gt;
\begin{align}
  {\star}\alpha = -q_1 \,du + p_1 \,dv &amp;= - \left( p \frac{\partial x}{\partial v} + q \frac{\partial y}{\partial v} \right) du + \left(p \frac{\partial x}{\partial u} + q \frac{\partial y}{\partial u} \right) dv \\[4pt]
                       &amp;= -q \left( \frac{\partial x}{\partial u} du + \frac{\partial x}{\partial v} dv \right) + p \left( \frac{\partial y}{\partial u} du + \frac{\partial y}{\partial v} dv \right) \\[4pt]
&amp; = -q\,dx + p\, dy,
\end{align}
&lt;/math&gt;

proving the claimed invariance.

===Three dimensions===
A common example of the star operator is the case {{math|''n'' {{=}} 3}}, when it can be taken as the correspondence between the vectors and the [[skew-symmetric matrix|skew-symmetric matrices]] of that size. This is used implicitly in [[vector calculus]], for example to create the [[cross product]] vector from the [[Exterior_algebra|wedge product]]  of two vectors. Specifically, for [[Euclidean space|Euclidean]] '''R'''&lt;sup&gt;3&lt;/sup&gt;, one easily finds that

:&lt;math&gt;\begin{align}
  \star \,dx &amp;= dy \wedge dz \\
  \star \,dy &amp;= dz \wedge dx \\
  \star \,dz &amp;= dx \wedge dy
\end{align}&lt;/math&gt;

where {{math|''dx''}}, {{math|''dy''}} and {{math|''dz''}} are the standard orthonormal differential [[one-form]]s on '''R'''&lt;sup&gt;3&lt;/sup&gt;. The Hodge star in this case clearly relates the cross-product to the wedge product in three dimensions. A detailed presentation not restricted to differential geometry is provided next.

Applied to three dimensions, the Hodge star provides an [[isomorphism]] between [[axial vector]]s and [[bivector]]s, so each axial vector '''a''' is associated with a bivector {{math|'''A'''}} and vice versa, that is:&lt;ref name=Lounesto&gt;{{cite book |title=Clifford Algebras and Spinors, ''Volume 286 of London Mathematical Society Lecture Note Series'' |author=Pertti Lounesto |url=https://books.google.com/books?id=E_xvJuA4M7QC&amp;pg=PA39 |page=39 |chapter=Â§3.6 The Hodge dual |isbn=0-521-00551-5 |year=2001 |edition=2nd |publisher=Cambridge University Press}}&lt;/ref&gt;

: &lt;math&gt;\mathbf{A} = \star \mathbf{a}\qquad\mathbf{a} = \star \mathbf{A}&lt;/math&gt;

where {{math|â}} is the Hodge star. These dual relations can be implemented using multiplication by the [[Pseudoscalar (Clifford algebra)#Unit pseudoscalar|unit pseudoscalar]] in [[Clifford algebra#Examples: real and complex Clifford algebras|Cl&lt;sub&gt;3&lt;/sub&gt;('''R''')]],&lt;ref name=Datta&gt;{{cite book |title=Geometric algebra and applications to physics |chapter=The pseudoscalar and imaginary unit | url=https://books.google.com/books?id=AXTQXnws8E8C&amp;pg=PA53 |page=53 ''ff'' |author=Venzo De Sabbata, Bidyut Kumar Datta |isbn=1-58488-772-9 | publisher=CRC Press |year=2007}}&lt;/ref&gt; {{math|''i'' {{=}} '''e'''&lt;sub&gt;1&lt;/sub&gt;'''e'''&lt;sub&gt;2&lt;/sub&gt;'''e'''&lt;sub&gt;3&lt;/sub&gt;}} (the vectors {{math|{'''e'''&lt;sub&gt;â&lt;/sub&gt;} }} are an orthonormal basis in three dimensional Euclidean space) according to the relations:&lt;ref name=Baylis&gt;{{cite book |title=Lectures on Clifford (geometric) algebras and applications |editor=Rafal Ablamowicz, Garret Sobczyk |page=100 ''ff'' |chapter=Chapter 4: Applications of Clifford algebras in physics |author=William E Baylis  |isbn=0-8176-3257-3 |year=2004 | publisher=BirkhÃ¤user | url=https://books.google.com/books?id=oaoLbMS3ErwC&amp;pg=PA100}}&lt;/ref&gt;

: &lt;math&gt;\mathbf{A} = \mathbf{a}i\,,\quad\mathbf{a} = - \mathbf{A} i. &lt;/math&gt;

The dual of a vector is obtained by multiplication by {{mvar|i}}, as established using the properties of the [[Geometric product#The geometric product|geometric product]] of the algebra as follows:

:&lt;math&gt;\begin{align}
  \mathbf{a}i &amp;= \left(a_1 \mathbf{e}_1 + a_2 \mathbf{e}_2 + a_3 \mathbf{e}_3\right) \mathbf{e}_1 \mathbf{e}_2 \mathbf{e}_3 \\
              &amp;= a_1 \mathbf{e}_2 \mathbf{e}_3 (\mathbf{e}_1)^2 + a_2 \mathbf{e}_3 \mathbf{e}_1(\mathbf{e}_2)^2 + a_3  \mathbf{e}_1 \mathbf{e}_2(\mathbf{e}_3)^2 \\
              &amp;= a_1 \mathbf{e}_2 \mathbf{e}_3 + a_2 \mathbf{e}_3 \mathbf{e}_1 + a_3 \mathbf{e}_1 \mathbf{e}_2 \\
              &amp;= (\star \mathbf{a})
\end{align}&lt;/math&gt;

and also, in the dual space spanned by {{math|{'''e'''&lt;sub&gt;â&lt;/sub&gt;'''e'''&lt;sub&gt;''m''&lt;/sub&gt;}:}}

:&lt;math&gt;\begin{align}
  \mathbf{A} i &amp;= \left(A_1 \mathbf{e}_2\mathbf{e}_3 + A_2 \mathbf{e}_3\mathbf{e}_1 + A_3 \mathbf{e}_1\mathbf{e}_2\right) \mathbf{e}_1 \mathbf{e}_2 \mathbf{e}_3 \\
               &amp;= A_1 \mathbf{e}_1 (\mathbf{e}_2 \mathbf{e}_3)^2 + A_2 \mathbf{e}_2 (\mathbf{e}_3 \mathbf{e}_1)^2 + A_3 \mathbf{e}_3(\mathbf{e}_1 \mathbf{e}_2)^2 \\
               &amp;= -\left( A_1 \mathbf{e}_1 + A_2 \mathbf{e}_2 + A_3  \mathbf{e}_3 \right) \\
               &amp;= -(\star \mathbf{A})
\end{align}&lt;/math&gt;

In establishing these results, the identities are used:

:&lt;math&gt;(\mathbf{e}_1\mathbf{e}_2)^2 = \mathbf{e}_1\mathbf{e}_2\mathbf{e}_1\mathbf{e}_2= -\mathbf{e}_1\mathbf{e}_2\mathbf{e}_2\mathbf{e}_1 = -1&lt;/math&gt;

and:

:&lt;math&gt;\mathit{i}^2 = (\mathbf{e}_1\mathbf{e}_2\mathbf{e}_3)^2 = \mathbf{e}_1\mathbf{e}_2\mathbf{e}_3\mathbf{e}_1\mathbf{e}_2\mathbf{e}_3 = \mathbf{e}_1\mathbf{e}_2\mathbf{e}_3\mathbf{e}_3\mathbf{e}_1\mathbf{e}_2 = \mathbf{e}_1\mathbf{e}_2\mathbf{e}_1\mathbf{e}_2 = -1.&lt;/math&gt;

These relations between the dual {{math|â}} and {{mvar|i}} apply to any vectors. Here they are applied to relate the axial vector created as the [[cross product]] {{math|1='''a''' = '''u''' Ã '''v'''}} to the bivector-valued [[exterior product]] {{math|1='''A''' = '''u''' â§ '''v'''}} of two [[polar vectors|polar]] (that is, not axial) vectors {{math|'''u'''}} and {{math|'''v'''}}; the two products can be written as [[determinant]]s expressed in the same way:

: &lt;math&gt;\mathbf a = \mathbf{u} \times \mathbf{v} = \begin{vmatrix} \mathbf{e}_1 &amp; \mathbf{e}_2 &amp; \mathbf{e}_3\\u_1 &amp; u_2 &amp; u_3\\v_1 &amp; v_2 &amp; v_3 \end{vmatrix}\,,\quad\mathbf A =  \mathbf{u} \wedge \mathbf{v} = \begin{vmatrix} \mathbf{e}_{23} &amp; \mathbf{e}_{31} &amp; \mathbf{e}_{12}\\u_1 &amp; u_2 &amp; u_3\\v_1 &amp; v_2 &amp; v_3 \end{vmatrix},&lt;/math&gt;

using the notation {{math|'''e'''&lt;sub&gt;â''m''&lt;/sub&gt; {{=}} '''e'''&lt;sub&gt;â&lt;/sub&gt;'''e'''&lt;sub&gt;''m''&lt;/sub&gt;}}. These expressions show these two types of vector are Hodge duals:&lt;ref name=Lounesto/&gt;

:&lt;math&gt;\star (\mathbf{u} \wedge \mathbf{v}) = \mathbf{u \times v}\,,\quad\star (\mathbf{u} \times \mathbf {v}) = \mathbf{u} \wedge \mathbf{v},&lt;/math&gt;

as a result of the relations:

:&lt;math&gt;\star \mathbf{e}_\ell = \mathbf{e}_\ell \mathit{i} = \mathbf{e}_\ell \mathbf{e}_1\mathbf{e}_2\mathbf{e}_3 = \mathbf{e}_m \mathbf{e}_n \,, &lt;/math&gt;

with {{math|â, ''m'', ''n''}} cyclic,

and:

:&lt;math&gt;\star ( \mathbf{e}_\ell \mathbf{e}_m ) = -( \mathbf{e}_\ell \mathbf{e}_m ) \mathit{i} = -\left( \mathbf{e}_\ell \mathbf{e}_m \right)\mathbf{e}_1\mathbf{e}_2\mathbf{e}_3 = \mathbf{e}_n &lt;/math&gt;

also with {{math|''â'', ''m'', ''n''}} cyclic.

Using the implementation of {{math|â}} based upon {{mvar|i}}, the commonly used relations are:&lt;ref name=Hestenes&gt;{{cite book |title=New foundations for classical mechanics: Fundamental Theories of Physics  |isbn=0-7923-5302-1 |edition=2nd |year=1999 |publisher=Springer |chapter=The vector cross product |authorlink = David Hestenes|author=David Hestenes |url=https://books.google.com/books?id=AlvTCEzSI5wC&amp;pg=PA60 |page=60 }}&lt;/ref&gt;

:&lt;math&gt; \mathbf{u \times v} = -(\mathbf{u} \wedge \mathbf{v}) i  \,,\quad  \mathbf{u} \wedge \mathbf{v} = (\mathbf{u \times v} )  i \ . &lt;/math&gt;

===Four dimensions===
In case {{math|1=''n'' = 4}}, the Hodge star acts as an [[endomorphism]] of the second exterior power (i.e. it maps two-forms to two-forms, since {{math|1=4 â 2 = 2}}). It is an [[involution (mathematics)|involution]], {{Inconsistent|date=October 2017|reason=It's not the case in the example for 2 forms below}} so it splits it into ''self-dual'' and ''anti-self-dual'' subspaces, on which it acts respectively as {{math|+1}} and {{math|â1}}.

Another useful example is {{math|''n'' {{=}} 4}} Minkowski spacetime with metric signature {{math|(+ â â â)}} and coordinates {{math|(''t'', ''x'', ''y'', ''z'')}} where (using &lt;math&gt;\varepsilon_{0123} = 1&lt;/math&gt;)

:&lt;math&gt;\begin{align}
  \star dt &amp;=  dx \wedge dy \wedge dz \\
  \star dx &amp;=  dt \wedge dy \wedge dz \\
  \star dy &amp;= -dt \wedge dx \wedge dz \\
  \star dz &amp;=  dt \wedge dx \wedge dy
\end{align}&lt;/math&gt;

for [[one-form]]s while

:&lt;math&gt;\begin{align}
  \star (dt \wedge dx) &amp;= - dy \wedge dz \\
  \star (dt \wedge dy) &amp;=   dx \wedge dz \\
  \star (dt \wedge dz) &amp;= - dx \wedge dy \\
  \star (dx \wedge dy) &amp;=   dt \wedge dz \\
  \star (dx \wedge dz) &amp;= - dt \wedge dy \\
  \star (dy \wedge dz) &amp;=   dt \wedge dx
\end{align}&lt;/math&gt;

for [[two-form]]s. Because their determinants are the same in both {{math|(+ â â â)}} and {{math|(â + + +)}}, the signs of the Minkowski space two-form duals depend only on the chosen orientation.{{verify source|date=October 2017}}

An easy rule to remember for the above Hodge operations is that given a form &lt;math&gt;\alpha&lt;/math&gt;, its Hodge dual &lt;math&gt;{\star}\alpha&lt;/math&gt; may be obtained by writing the components not involved in &lt;math&gt;\alpha&lt;/math&gt; in an order such that &lt;math&gt;\alpha \wedge (\star \alpha) = dx \wedge dy \wedge dz \wedge dt&lt;/math&gt;.{{Inconsistent|date=October 2017|reason=This orientation choice appears to be non-canonical, and not to match the earlier choice}} An extra minus sign will enter only if &lt;math&gt;\alpha&lt;/math&gt; does not contain &lt;math&gt;dt&lt;/math&gt;. (The latter convention stems from the choice {{math|(+ â â â)}} for the metric signature. For {{math|(â + + +)}}, one puts a minus sign only if &lt;math&gt;\alpha&lt;/math&gt; involves &lt;math&gt;dt&lt;/math&gt;.)

==Inner product of {{math|''k''}}-vectors==
The Hodge star induces an inner product on the space of {{mvar|k}}-vectors, that is, on the [[exterior algebra]] of {{mvar|V}}.  Given two {{mvar|k}}-vectors {{mvar|Î·}} and {{mvar|Î¶}}, one has

:&lt;math&gt;\zeta\wedge \star \eta = \langle\zeta, \eta \rangle\,\omega ,&lt;/math&gt;

where {{mvar|Ï}} is the normalised {{mvar|n}}-form (i.e. {{math|''Ï'' â§ â''Ï'' {{=}} ''Ï''}}). In the calculus of exterior [[differential form]]s on a [[pseudo-Riemannian manifold]] of dimension {{mvar|n}}, the normalised {{mvar|n}}-form is called the [[volume form]] and can be written as

:&lt;math&gt;\omega = \sqrt{ \left| \det [g_{ij}] \right| }\;dx^1\wedge\cdots\wedge dx^n ,&lt;/math&gt;

where &lt;math&gt; \left[ g_{ij} \right] &lt;/math&gt; is the matrix of components of the [[metric tensor]] on the manifold in the [[coordinate basis]].

If an inner product is given on &lt;math&gt; {\textstyle\bigwedge}^k(V) &lt;/math&gt;, then this equation can be regarded as an alternative definition of the Hodge star.&lt;ref&gt;{{cite book | last = Darling| first = R. W. R. | title = Differential forms and connections| publisher = Cambridge University Press| year = 1994 }}&lt;/ref&gt;

The ordered wedge products of k distinct orthonormal basis vectors of {{mvar|V}} form an ''orthonormal'' basis on each subspace &lt;math&gt;{\textstyle\bigwedge}^k(V)&lt;/math&gt; of the exterior algebra of {{mvar|V}}.

==Duality==
Applying the Hodge star twice leaves a {{math|''k''}}-vector unchanged, up to sign. Given a {{mvar|k}}-vector {{math|''Î·''}} in {{math|â&lt;sup&gt;''k''&lt;/sup&gt;(''V'')}} in an {{mvar|n}}-dimensional space {{mvar|V}}, one has

:&lt;math&gt;{\star} {\star} \eta = (-1)^{k(n-k)} s \eta ,&lt;/math&gt;

where {{mvar|s}} is related to the [[metric signature|signature]] of the inner product on {{mvar|V}}.  Specifically, {{mvar|s}} is the sign of the [[determinant]] of the matrix representation of the inner product tensor with respect to any basis. Thus, for example, if {{math|''n'' {{=}} 4}} and the signature of the inner product is either {{math|(+ â â â)}} or {{math|(â + + +)}} then {{math|''s'' {{=}} â1}}. For Riemannian manifolds (including Euclidean spaces), the signature is always positive, and so {{math|''s'' {{=}} 1}}.

Note that the above identity implies that the inverse of {{math|â}} can be given as

:&lt;math&gt; \begin{align} {\star}^{-1}: ~&amp; \Lambda^k \to \Lambda^{n-k} \\ &amp; \eta \mapsto (-1)^{k(n-k)} s {\star} \eta \end{align}&lt;/math&gt;

Note that if {{mvar|n}} is odd then {{math|''k''(''n'' â ''k'')}} is even for any {{mvar|k}}, whereas if {{mvar|n}} is even then {{math|''k''(''n'' â ''k'')}} has the parity of {{mvar|k}}. Therefore:

:&lt;math&gt;{\star}^{-1} = \begin{cases} s {\star} &amp; n \text{ is odd} \\ (-1)^k s {\star} &amp; n \text{ is even} \end{cases}&lt;/math&gt;

where {{mvar|k}} is the degree of the element operated on.

==On manifolds==
Applying the construction above to each [[cotangent space]] of an {{mvar|n}}-dimensional oriented [[Riemannian manifold|Riemannian]] or [[pseudo-Riemannian manifold]], we can obtain an object known as the '''Hodge dual''' of a [[differential form|{{mvar|k}}-form]].  To be explicit â

For any {{math|''k''}}-form {{math|''Î¶''}} we define {{math|â''Î¶''}} as the unique {{math|(''n'' â ''k'')}}-form satisfying

:&lt;math&gt;\eta\wedge {\star} \zeta = \langle \eta, \zeta \rangle \; \omega &lt;/math&gt;

for every {{math|''k''}}-form {{mvar|Î·}} (here the inner product on forms and the volume form {{math|''Ï''}} are induced by the Riemannian metric tensor in the usual way; greater understanding of these objects can be found by learning about the [[Exterior algebra#Inner product|inner product on {{mvar|k}}-forms]] and the [[Volume form#Riemannian volume form|volume form]]).

The Hodge star is thus related to the {{math|''L''&lt;sup&gt;2&lt;/sup&gt;}} inner product on {{math|''k''}}-forms by the formula:

:&lt;math&gt;(\eta,\zeta)=\int_M \eta\wedge {\star} \zeta.&lt;/math&gt;

for {{math|''k''}}-forms  {{mvar|Î·}} and {{mvar|Î¶}}. (Note that we can also see this as an inner product on  [[fibre bundle|sections]]  of &lt;math&gt;{\textstyle\bigwedge}^k(\text{T}^*M)&lt;/math&gt;.  The set of sections is frequently denoted as &lt;math&gt;\Omega^k(M) = \Gamma\left({\textstyle\bigwedge}^k\left(\text{T}^*M\right)\right)&lt;/math&gt;.  Each element of &lt;math&gt;\Omega^k(M)&lt;/math&gt; is a {{math|''k''}}-form.)

More generally, in the non-oriented case, one can define the Hodge star of a {{mvar|k}}-form as a {{math|(''n'' â ''k'')}}-[[pseudotensor|pseudo differential form]]; that is, a differential form with values in the [[Canonical bundle|canonical line bundle]].

===Codifferential&lt;!-- This section is linked from [[Differential form]] --&gt;===
The most important application of the Hodge star on manifolds is to define the '''codifferential''' {{mvar|Î´}} on {{mvar|k}}-forms.  Let

:&lt;math&gt;\delta = (-1)^{n(k-1) + 1} s\ {\star} d {\star} = (-1)^{k}\, {\star}^{-1} d {\star} &lt;/math&gt;

where {{math|''d''}} is the [[exterior derivative]] or differential, and {{math|''s'' {{=}} 1}} for Riemannian manifolds.

:&lt;math&gt;d:\Omega^k(M)\to \Omega^{k+1}(M)&lt;/math&gt;

while

:&lt;math&gt;\delta:\Omega^k(M)\to \Omega^{k-1}(M).&lt;/math&gt;

The codifferential is not an [[antiderivation]] on the exterior algebra, in contrast to the exterior derivative.

The codifferential is the adjoint of the exterior derivative, in that

:&lt;math&gt; (\eta,\delta \zeta) = (d\eta,\zeta). &lt;/math&gt;

where {{mvar|Î¶}} is a {{math|(''k'' + 1)}}-form and {{mvar|Î·}} a {{mvar|k}}-form. This identity follows from Stokes' theorem for smooth forms, when

:&lt;math&gt;\int_M d (\eta \wedge {\star} \zeta) = 0 = \int_M (d \eta \wedge {\star} \zeta - \eta \wedge {\star} (-1)^{k+1}\,{\star}^{-1} d {\star} \zeta)
=(d\eta,\zeta) -(\eta,\delta\zeta)&lt;/math&gt;

i.e. when {{mvar|M}} has empty boundary or when {{mvar|Î·}} or {{math|â''Î¶''}} has zero boundary values (of course, true adjointness follows after continuous continuation to the appropriate topological vector spaces as closures of the spaces of smooth forms).

Notice that since the differential satisfies {{math|''d''{{i sup|2}} {{=}} 0}}, the codifferential has the corresponding property

:&lt;math&gt;\delta^2 = s^2 {\star} d {\star} {\star} d {\star} = (-1)^{k(n-k)} s^3 {\star} d^2 {\star} = 0 &lt;/math&gt;

The [[LaplaceâBeltrami operator|LaplaceâdeRham]] operator is given by

:&lt;math&gt;\Delta=(\delta+d)^2 = \delta d + d\delta&lt;/math&gt;

and lies at the heart of [[Hodge theory]]. It is symmetric:

:&lt;math&gt;(\Delta \zeta,\eta) = (\zeta,\Delta \eta)&lt;/math&gt;

and non-negative:

:&lt;math&gt;(\Delta\eta,\eta) \ge 0.&lt;/math&gt;

The Hodge star sends harmonic forms to harmonic forms. As a consequence of the [[Hodge theory]], the [[de Rham cohomology]] is naturally isomorphic to the space of harmonic {{mvar|k}}-forms, and so the Hodge star induces an isomorphism of cohomology groups

:&lt;math&gt;{\star} : H^k_\Delta (M) \to H^{n-k}_\Delta(M),&lt;/math&gt;

which in turn gives canonical identifications via [[PoincarÃ© duality]] of {{math|''H&lt;sup&gt;âk&lt;/sup&gt;''(''M'')}} with its [[dual space]].

==Derivatives in three dimensions==
The combination of the {{math|â}} operator and the [[exterior derivative]] {{math|''d''}} generates the classical operators [[gradient|{{math|grad}}]], [[Curl (mathematics)|{{math|curl}}]], and [[divergence|{{math|div}}]], in three-dimensional Euclidean space. This works out as follows: {{math|''d''}} can take a 0-form (function) to a 1-form, a 1-form to a 2-form, and a 2-form to a 3-form (applied to a 3-form it just gives zero). For a 0-form, &lt;math&gt;\omega=f(x,y,z)&lt;/math&gt;, the first case written out in components is identifiable as the grad operator:

:&lt;math&gt;d\omega=\frac{\partial f}{\partial x} \, dx+\frac{\partial f}{\partial y} \, dy + \frac{\partial f}{\partial z} \, dz.&lt;/math&gt;

The second case followed by {{math|â}} is an operator on 1-forms (&lt;math&gt;\eta=A\,dx+B\,dy+C\,dz&lt;/math&gt;) that in components is the curl operator:

:&lt;math&gt;d\eta=\left({\partial C \over \partial y} - {\partial B \over \partial z}\right)dy\wedge dz  + \left({\partial C \over \partial x} - {\partial A \over \partial z}\right)dx\wedge dz+\left({\partial B \over \partial x} - {\partial A \over \partial y}\right)dx\wedge dy.&lt;/math&gt;

Applying the Hodge star gives:

:&lt;math&gt;\star d\eta=\left({\partial C \over \partial y} - {\partial B \over \partial z} \right) \, dx  - \left({\partial C \over \partial x} - {\partial A \over \partial z} \right) \, dy+\left({\partial B \over \partial x} - {\partial A \over \partial y}\right) \, dz.&lt;/math&gt;

The final case prefaced and followed by {{math|â}}, takes a 1-form (&lt;math&gt;\eta=A\,dx+B\,dy+C\,dz&lt;/math&gt;) to a 0-form (function); written out in components it is the divergence operator:

:&lt;math&gt;\begin{align}
\star\eta &amp;= A\,dy\wedge dz-B\,dx\wedge dz+C\,dx\wedge dy \\
d{\star\eta} &amp;= \left(\frac{\partial A}{\partial x}+\frac{\partial B}{\partial y}+\frac{\partial C}{\partial z}\right)dx\wedge dy\wedge dz \\
\star d{\star\eta} &amp;= \frac{\partial A}{\partial x}+\frac{\partial B}{\partial y}+\frac{\partial C}{\partial z}.
\end{align}&lt;/math&gt;

One advantage of this expression is that the identity {{math|''d''{{i sup|2}} {{=}} 0}}, which is true in all cases, sums up two others, namely that {{math|curl grad ''f'' {{=}} 0}} and {{math|div curl '''F''' {{=}} 0}}. In particular, [[Maxwell's equations]] take on a particularly simple and elegant form, when expressed in terms of the exterior derivative and the Hodge star.

One can also obtain the [[Laplacian]]. Using the information above and the fact that {{math|Îâ''f''â{{=}} divâgradâ''f''}} then for a 0-form, &lt;math&gt;\omega=f(x,y,z)&lt;/math&gt;:

:&lt;math&gt; \Delta \omega =\star d{\star d\omega}= \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2} + \frac{\partial^2 f}{\partial z^2}&lt;/math&gt;

==Notes==
{{Reflist}}

==References==
* David Bleecker (1981) ''Gauge Theory and Variational Principles''. Addison-Wesley Publishing. {{isbn|0-201-10096-7}}. Chpt. 0 contains a condensed review of non-Riemannian differential geometry.
* Jurgen Jost (2002) ''Riemannian Geometry and Geometric Analysis''. Springer-Verlag. {{isbn|3-540-42627-2}}. A detailed exposition starting from basic principles; does not treat the pseudo-Riemannian case.
* [[Charles W. Misner]], [[Kip S. Thorne]], [[John Archibald Wheeler]] (1970) ''Gravitation''. W.H. Freeman. {{isbn|0-7167-0344-0}}. A basic review of [[differential geometry]] in the special case of four-dimensional [[spacetime]].
* Steven Rosenberg (1997) ''The Laplacian on a Riemannian manifold''. Cambridge University Press. {{isbn|0-521-46831-0}}. An introduction to the [[heat equation]] and the [[Atiyah-Singer theorem]].
* [http://people.oregonstate.edu/~drayt/Courses/MTH434/2007/dual.pdf Tevian Dray (1999) ''The Hodge Dual Operator'']. A thorough overview of the definition and properties of the Hodge star operator.

{{Tensors}}

{{DEFAULTSORT:Hodge Dual}}
[[Category:Differential forms]]
[[Category:Riemannian geometry]]
[[Category:Duality theories]]</text>
      <sha1>jnz6t7cpucoqfawp6uj7qbcmj19ozc1</sha1>
    </revision>
  </page>
  <page>
    <title>Holonomic basis</title>
    <ns>0</ns>
    <id>36234984</id>
    <revision>
      <id>850891091</id>
      <parentid>850863906</parentid>
      <timestamp>2018-07-18T17:12:48Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>/* top */ grammar</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3828">In [[mathematics]] and [[mathematical physics]], a '''coordinate basis''' or '''holonomic basis''' for a [[differentiable manifold]] {{math|''M''}} is a set of [[Basis (linear algebra)|basis]] [[vector field]]s {{math|{'''e'''{{sub|1}}, ..., '''e'''{{sub|''n''}}}{{null}}}} defined at every point {{math|''P''}} of a region of the manifold as
:&lt;math&gt;\mathbf{e}_{\alpha} = \lim_{\delta x^{\alpha} \to 0} \frac{\delta \mathbf{s}}{\delta x^{\alpha}} ,&lt;/math&gt;
where {{math|''Î´'''''s'''}} is the infinitesimal displacement vector between the point {{math|''P''}} and a nearby point
{{math|''Q''}} whose coordinate separation from {{math|''P''}} is {{math|''Î´x''{{sup|''Î±''}}}} along the coordinate curve {{math|''x''{{sup|''Î±''}}}} (i.e. the curve on the manifold through {{math|''P''}} for which the [[Local coordinate system|local coordinate]] {{math|''x''{{sup|''Î±''}}}} varies and all other coordinates are constant).{{refn|{{citation |author1=M. P. Hobson |author2=G. P. Efstathiou |author3=A. N. Lasenby |year=2006 |title=General Relativity: An Introduction for Physicists |publisher=[[Cambridge University Press]] |page=57 }}}}

It is possible to make an association between such a basis and directional derivative operators.  Given a parameterized curve {{math|''C''}} on the manifold defined by {{math|''x''{{sup|''Î±''}}(''Î»'')}} with the tangent vector {{math|1='''u''' = ''u''{{sup|''Î±''}}'''e'''{{sub|''Î±''}}}}, where {{math|1=''u''{{sup|''Î±''}} = {{sfrac|''dx''{{sup|''Î±''}}|''dÎ»''}}}}, and a function {{math|''f''(''x''{{sup|''Î±''}})}} defined in a neighbourhood of {{math|''C''}}, the variation of {{math|''f''}} along {{math|''C''}} can be written as
:&lt;math&gt;\frac{df}{d\lambda} = \frac{dx^{\alpha}}{d\lambda}\frac{\partial f}{\partial x^{\alpha}} = u^{\alpha} \frac{\partial f}{\partial x^{\alpha}} .&lt;/math&gt;
Since we have that {{math|1='''u''' = ''u''{{sup|''Î±''}}'''e'''{{sub|''Î±''}}}}, the identification is often made between a coordinate basis vector {{math|'''e'''{{sub|''Î±''}}}} and the partial derivative operator {{math|{{sfrac|â|â''x''{{sup|''Î±''}}}}}}, under the interpretation of all vector relations as equalities between operators acting on scalar quantities.{{refn|{{citation |author=T. Padmanabhan |year=2010 |title=Gravitation: Foundations and Frontiers |publisher=[[Cambridge University Press]] |page=25}}}}

A local condition for a basis {{math|{'''e'''{{sub|1}}, ..., '''e'''{{sub|''n''}}}{{null}}}} to be holonomic is that all mutual [[Lie derivative]]s vanish:{{refn|{{citation |author1=Roger Penrose|author2=Wolfgang Rindler |title=Spinors and SpaceâTime: Volume 1, Two-Spinor Calculus and Relativistic Fields |publisher=[[Cambridge University Press]] |pages=197â199 }}}}
:&lt;math&gt; \left[ \mathbf{e}_{\alpha} , \mathbf{e}_{\beta} \right] = {\mathcal{L}}_{\mathbf{e}_{\alpha}} \mathbf{e}_{\beta} = 0 .&lt;/math&gt;

A basis that is not holonomic is called a non-holonomic or non-coordinate basis.

Given a [[metric tensor]] {{math|''g''}} on a manifold {{math|''M''}}, it is in general not possible to find a coordinate basis that is orthonormal in any open region {{math|''U''}} of {{math|''M''}}.{{refn|{{citation |author=Bernard F. Schutz |year=1980 |title=Geometrical Methods of Mathematical Physics |publisher=[[Cambridge University Press]] |page=69 |isbn=9780521298872 }}}}  An obvious exception is when {{math|''M''}} is the [[Real number|real]] [[coordinate space]] {{math|'''R'''{{sup|''n''}}}} considered as a manifold with {{math|''g''}} being the Euclidean metric {{math|''Î´''{{sub|''ij''&amp;thinsp;}}'''e'''{{sup|''i''}} â '''e'''{{i sup|''j''}}}} at every point.

==References==
{{reflist}}

==See also==
*[[Jet bundle]]
*[[Tetrad formalism]]
*[[Ricci calculus]]

[[Category:Differential geometry]]
[[Category:Mathematical physics]]


{{differential-geometry-stub}}</text>
      <sha1>1gn0cbkw0nldlsou74dfxtqzqxz8w5r</sha1>
    </revision>
  </page>
  <page>
    <title>Isotropic manifold</title>
    <ns>0</ns>
    <id>1966001</id>
    <revision>
      <id>840560626</id>
      <parentid>722676681</parentid>
      <timestamp>2018-05-10T17:34:52Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:PrimeBOT/24|Task 24]] - replace template usage following [[Wikipedia:Templates for discussion/Log/2018 February 19|a TFD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2587">{{unreferenced|date=June 2014}}
{{distinguish|text=[[isotropic subspace]], a quadratic space containing a non-zero vector ''v'' for which ''q''(''v'') is 0}}
In [[mathematics]], an '''isotropic manifold''' is a [[manifold]] in which the [[geometry]] does not depend on directions. Formally, we say that a Riemannian manifold &lt;math&gt;(M,g)&lt;/math&gt; is isotropic if for any point &lt;math&gt;p\in M&lt;/math&gt; and unit vectors &lt;math&gt;v,w\in T_pM&lt;/math&gt;, there is an isometry &lt;math&gt;\varphi&lt;/math&gt; of &lt;math&gt;M&lt;/math&gt; with &lt;math&gt;\varphi(p)=p&lt;/math&gt; and &lt;math&gt;\varphi_\ast(v)=w&lt;/math&gt;. Every complete isotropic manifold is [[homogeneous]], i.e. for any &lt;math&gt;p,q\in M&lt;/math&gt; there is an isometry &lt;math&gt;\varphi&lt;/math&gt; of &lt;math&gt;M&lt;/math&gt; with &lt;math&gt;\varphi(p)=q.&lt;/math&gt; This can be seen by considering a geodesic &lt;math&gt;\gamma:[0,2]\to M&lt;/math&gt; from &lt;math&gt;p&lt;/math&gt; to &lt;math&gt;q&lt;/math&gt; and taking the isometry which fixes &lt;math&gt;\gamma(1)&lt;/math&gt; and maps &lt;math&gt;\gamma'(1)&lt;/math&gt; to &lt;math&gt;-\gamma'(1).&lt;/math&gt;
==Examples==
The simply-connected space forms (the [[n-sphere]], [[hyperbolic space]], and &lt;math&gt;\mathbb{R}^n&lt;/math&gt;) are isotropic. It is not true in general that any constant curvature manifold is isotropic; for example, the flat torus &lt;math&gt;T=\mathbb{R}^2/\mathbb{Z}^2&lt;/math&gt; is not isotropic. This can be seen by noting that any isometry of &lt;math&gt;T&lt;/math&gt; which fixes a point &lt;math&gt;p\in T&lt;/math&gt; must lift to an isometry of &lt;math&gt;\mathbb{R}^2&lt;/math&gt; which fixes a point and preserves &lt;math&gt;\mathbb{Z}^2&lt;/math&gt;; thus the group of isometries of &lt;math&gt;T&lt;/math&gt; which fix &lt;math&gt;p&lt;/math&gt; is discrete. Moreover, it can be seen that no oriented surface with constant curvature and negative Euler characteristic is isotropic.

Moreover, there are isotropic manifolds which do not have constant curvature, such as the complex projective space &lt;math&gt;\mathbb{CP}^n&lt;/math&gt; (&lt;math&gt;n&gt;1&lt;/math&gt;) equipped with the Fubini-Study metric.

Further examples of isotropic manifolds are given by the rank one symmetric spaces, including the projective spaces &lt;math&gt;\mathbb{RP}^n&lt;/math&gt;, &lt;math&gt;\mathbb{CP}^n&lt;/math&gt;, &lt;math&gt;\mathbb{HP}^n&lt;/math&gt;, and &lt;math&gt;\mathbb{OP}^2&lt;/math&gt;, as well as their noncompact hyperbolic analogues.

A manifold can be homogeneous but not isotropic, such as the flat torus &lt;math&gt;T&lt;/math&gt; or &lt;math&gt;\mathbb{R}\times S^2&lt;/math&gt; with the product metric.

==See also==
* [[Cosmological principle]]
* [http://math.stackexchange.com/questions/448315/isotropic-manifolds Isotropic Manifold on Math.StackExchange (July 2013)]

[[Category:Differential geometry]]


{{differential-geometry-stub}}
{{topology-stub}}</text>
      <sha1>2dyp1argqf7174r3u7zm6sustbg3qq8</sha1>
    </revision>
  </page>
  <page>
    <title>Kengo Hirachi</title>
    <ns>0</ns>
    <id>50501311</id>
    <revision>
      <id>752442146</id>
      <parentid>726910153</parentid>
      <timestamp>2016-12-01T07:37:51Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* External links */clean up; http&amp;rarr;https for [[YouTube]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2930">'''Kengo Hirachi''' (å¹³å° å¥å¾ ''Hirachi Kengo'', born 30 November 1964) is a Japanese mathematician, specializing in [[CR manifold|CR geometry]] and mathematical analysis.

Hirachi received from [[Osaka University]] his B.S. in 1987, his M.S. in 1989, and his Dr.Sci., advised by Gen Komatsu, in 1994 with dissertation ''The second variation of the Bergman kernel for ellipsoids''.&lt;ref&gt;{{MathGenealogy|id=77773}}&lt;/ref&gt; He was a research assistant from 1989 to 1996 and a lecturer from 1996 to 2000 at Osaka University. He was an associate professor from 2000 to 2010 and a full professor from 2010 to the present at the [[University of Tokyo]]. He was a visiting professor at the Mathematical Sciences Research Institute from October 1995 to September 1996, at the Erwin SchrÃ¶dinger Institute for Mathematical Physics from March 2004 to April 2004, at Princeton University from October 2004 to July 2005, and at the Institute for Advanced Study from January 2009 to April 2009.&lt;ref&gt;[http://www.ms.u-tokyo.ac.jp/~hirachi/cv.html Curriculum Vitae, Kengo Hirachi, 2004]&lt;/ref&gt;

{{blockquote|Hirachiâs work employs a wide range of tools in geometry and analysis, including several complex variables, the complex Monge-AmpÃ¨re equation, microlocal analysis, parabolic invariant theory, explicit computations, and computer algebra packages. In a paper in the ''Annals of Mathematics'' (2000) Hirachi constructed CR invariants of strongly pseudoconvex boundaries via a deep study of the logarithmic singularity of the Bergman kernel. He has proved various results linking the Bergman and SzegÅ kernels, and he has made significant progress to a program in which the Bergman kernel function plays a role analogous to the heat kernel of Riemannian geometry.&lt;ref name=BergmanPrize&gt;{{cite journal|title=Hirachi Receives Bergman Prize|journal=Notices of the AMS|date=March 2006|volume=53|issue=3|pages=358â359|url=http://www.ams.org/notices/200603/people.pdf}}&lt;/ref&gt;}}

==Awards and honors==
*Takebe Senior Prize (1999) of the Mathematical Society of Japan
*[[Geometry prize|Geometry Prize]] (2003) of the Mathematical Society of Japan
*Stefan Bergman Prize (2006)&lt;ref name=BergmanPrize/&gt;
*Inoue Prize for Science (2012) 
*Invited lecture at ICM, Seoul 2014

==References==
{{reflist}}

==External links==
*[http://www.ms.u-tokyo.ac.jp/~hirachi/papers.html Kengo Hirachi -- Bibliography, U. of Tokyo website]
*[https://www.youtube.com/watch?v=qSyp-dwqHCc ICM2014 VideoSeries IL8.3 : Kengo Hirachi on Aug14Thu - YouTube]

{{Authority control}}
{{DEFAULTSORT:Hirachi, Kengo}}
[[Category:1964 births]]
[[Category:Living people]]
[[Category:20th-century Japanese mathematicians]]
[[Category:21st-century Japanese mathematicians]]
[[Category:Japanese mathematicians]]
[[Category:Osaka University alumni]]
[[Category:University of Tokyo faculty]]
[[Category:Complex analysts]]
[[Category:Mathematical analysts]]
[[Category:PDE theorists]]</text>
      <sha1>8pwshejkraqnvwd2zbr16w7xhbotco7</sha1>
    </revision>
  </page>
  <page>
    <title>Lancelot Stephen Bosanquet</title>
    <ns>0</ns>
    <id>35221526</id>
    <revision>
      <id>859563174</id>
      <parentid>857362293</parentid>
      <timestamp>2018-09-14T20:55:34Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>Removing from [[Category:English mathematicians]] (parent category) using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="592">'''Lancelot Stephen Bosanquet''' (26 December 1903  St. Stephen's-by-Saltash, Cornwall, England â 10 January 1984 Cambridge) was a British mathematician who worked in [[analysis (mathematics)|analysis]], especially [[Fourier series]].

==References==

*{{MathGenealogy|id=18532}}
*{{MacTutor|id=Bosanquet}}


{{authority control}}

{{DEFAULTSORT:Bosanquet, Lancelot Stephen}}
[[Category:People from Saltash]]
[[Category:1903 births]]
[[Category:1984 deaths]]
[[Category:20th-century English mathematicians]]
[[Category:Cornish scientists]]


{{UK-mathematician-stub}}
{{mathematician-stub}}</text>
      <sha1>jdjzd48g5axdhhylewx4k5nwulloou6</sha1>
    </revision>
  </page>
  <page>
    <title>Limit and colimit of presheaves</title>
    <ns>0</ns>
    <id>54494563</id>
    <revision>
      <id>798338547</id>
      <parentid>794180045</parentid>
      <timestamp>2017-09-01T09:29:31Z</timestamp>
      <contributor>
        <username>Alvin Seville</username>
        <id>8629244</id>
      </contributor>
      <comment>removing and categorizing</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2051">In [[category theory]], a branch of mathematics, a '''limit''' or a '''colimit''' of [[presheaf (category theory)|presheaves]] on a category ''C'' is a limit or colimit in the functor category &lt;math&gt;\widehat{C} = \mathbf{Fct}(C^{\text{op}}, \mathbf{Set})&lt;/math&gt;.&lt;ref&gt;'''Notes on the foundation''': the notation '''Set''' implicitly assumes that there is the notion of a small set; i.e., one has made a choice of a [[Grothendieck universe]].&lt;/ref&gt;

The category &lt;math&gt;\widehat{C}&lt;/math&gt; admits small [[limit (category theory)|limit]]s and small [[colimit (category theory)|colimit]]s.&lt;ref&gt;{{harvnb|KashiwaraâSchapira|loc=Corollary 2.4.3.}}&lt;/ref&gt; Explicitly, if &lt;math&gt;f: I \to \widehat{C}&lt;/math&gt; is a functor from a small category ''I'' and ''U'' is an object in ''C'', then &lt;math&gt;\varinjlim_{i \in I} f(i)&lt;/math&gt; is computed pointwise:

:&lt;math&gt;(\varinjlim f(i))(U) = \varinjlim f(i)(U).&lt;/math&gt;

The same is true for small limits. Concretely this means that, for example, a fiber product exists and is computed pointwise.

When ''C'' is small, by the Yoneda lemma, one can view ''C'' as the full subcategory of &lt;math&gt;\widehat{C}&lt;/math&gt;. If &lt;math&gt;\eta: C \to D&lt;/math&gt; is a functor, if &lt;math&gt;f: I \to C&lt;/math&gt; is a functor from a small category ''I'' and if the colimit &lt;math&gt;\varinjlim f&lt;/math&gt; in &lt;math&gt;\widehat{C}&lt;/math&gt; is representable; i.e., isomorphic to an object in ''C'', then,&lt;ref&gt;{{harvnb|KashiwaraâSchapira|loc=Proposition 2.6.4.}}&lt;/ref&gt; in ''D'',

: &lt;math&gt;\eta(\varinjlim f) \simeq \varinjlim \eta \circ f,&lt;/math&gt;

(in particular the colimit on the right exists in ''D''.)

The [[Density theorem (category theory)|density theorem]] states that every presheaf is a colimit of representable presheaves.

== Notes ==
{{reflist}}

== References ==
*{{Cite book
| last=Kashiwara
| first=Masaki
| last2=Schapira
| first2=Pierre
| title=Categories and sheaves
| year=2006
| ref=harv
|author-link = Masaki Kashiwara|author-link2 = Pierre Schapira (mathematician)}}

[[Category:Category theory]]
[[Category:Sheaf theory]]

{{categorytheory-stub}}</text>
      <sha1>dw5p0qx0x18uvo0osd3vamkg9hs4a9u</sha1>
    </revision>
  </page>
  <page>
    <title>Longest increasing subsequence</title>
    <ns>0</ns>
    <id>4587078</id>
    <revision>
      <id>852476627</id>
      <parentid>852474142</parentid>
      <timestamp>2018-07-29T07:16:12Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Last clean version</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14144">In [[computer science]], the '''longest increasing subsequence''' problem is to find a subsequence of a given [[sequence]] in which the subsequence's elements are in sorted order, lowest to highest, and in which the subsequence is as long as possible. This subsequence is not necessarily contiguous, or unique.
Longest increasing subsequences are studied in the context of various disciplines related to [[mathematics]], including [[algorithmics]], [[random matrix theory]], [[representation theory]], and [[physics]].&lt;ref&gt;{{citation
 | last1 = Aldous | first1 = David | author1-link = David Aldous
 | last2 = Diaconis | first2 = Persi | author2-link = Persi Diaconis
 | doi = 10.1090/S0273-0979-99-00796-X
 | journal = Bulletin of the American Mathematical Society
 | pages = 413â432
 | issue = 04
 | title = Longest increasing subsequences: from patience sorting to the BaikâDeiftâJohansson theorem
 | volume = 36
 | year = 1999}}.&lt;/ref&gt; The longest increasing subsequence problem is solvable in time O(''n'' log ''n''), where ''n'' denotes the length of the input sequence.&lt;ref name="schensted"/&gt;

==Example==
In the first 16 terms of the binary [[Van der Corput sequence]]
:0, 8, 4, 12, 2, 10, 6, 14, 1, 9, 5, 13, 3, 11, 7, 15
a longest increasing subsequence is
:0, 2, 6, 9, 11, 15.
This subsequence has length six; the input sequence has no seven-member increasing subsequences. The longest increasing subsequence in this example is not unique: for instance,
:0, 4, 6, 9, 11, 15 or  
:0, 2, 6, 9, 13, 15 or
:0, 4, 6, 9, 13, 15
are other increasing subsequences of equal length in the same input sequence.

== Relations to other algorithmic problems ==
The longest increasing subsequence problem is closely related to the [[longest common subsequence problem]], which has a quadratic time [[dynamic programming]] solution: the longest increasing subsequence of a sequence ''S'' is the longest common subsequence of ''S'' and ''T'', where ''T'' is the result of [[sorting]] ''S''. However, for the special case in which the input is a permutation of the integers 1, 2, ..., ''n'', this approach can be made much more efficient, leading to time bounds of the form O(''n'' log log ''n'').&lt;ref&gt;{{Citation |author1=Hunt, J. |author2=Szymanski, T. | title = A fast algorithm for computing longest common subsequences | journal = Communications of the ACM | year = 1977 | pages = 350â353 | doi = 10.1145/359581.359603 | issue = 5 | volume = 20 | postscript = .}}&lt;/ref&gt;

The largest [[clique (graph theory)|clique]] in a [[permutation graph]] is defined by the longest decreasing subsequence of the permutation that defines the graph; the longest decreasing subsequence is equivalent in computational complexity, by negation of all numbers, to the longest increasing subsequence. Therefore, longest increasing subsequence algorithms can be used to solve the [[clique problem]] efficiently in permutation graphs.&lt;ref&gt;{{citation|first=M. C.|last=Golumbic|authorlink=Martin Charles Golumbic|title=Algorithmic Graph Theory and Perfect Graphs|series=Computer Science and Applied Mathematics|publisher=Academic Press|year=1980|page=159}}.&lt;/ref&gt;

In the [[RobinsonâSchensted correspondence]] between [[permutation]]s and [[Young tableau]]x, the length of the first row of the tableau corresponding to a permutation equals the length of the longest increasing subsequence of the permutation, and the length of the first column equals the length of the longest decreasing subsequence.&lt;ref name="schensted"&gt;{{Citation | doi=10.4153/CJM-1961-015-3 | authorlink=Craige Schensted | last1=Schensted | first1=C. | title=Longest increasing and decreasing subsequences | mr = 0121305 | year=1961 | journal=[[Canadian Journal of Mathematics]] | volume=13 | pages=179â191}}.&lt;/ref&gt;

== Efficient algorithms ==
The algorithm outlined below solves the longest increasing subsequence problem efficiently with arrays and [[binary search]]ing. 
It processes the sequence elements in order, maintaining the longest increasing subsequence found so far. Denote the sequence values as X[0], X[1], etc. Then, after processing X[''i''], the algorithm will have stored values in two arrays:
:M[''j''] â stores the index ''k'' of the smallest value X[''k''] such that there is an increasing subsequence of length ''j'' ending at X[''k''] on the range ''k'' â¤ ''i''. Note that ''j'' â¤ ''(i+1)'', because ''j'' â¥ 1 represents the length of the increasing subsequence, and ''k'' â¥ 0 represents the index of its termination.
:P[''k''] â stores the index of the predecessor of X[''k''] in the longest increasing subsequence ending at X[''k''].
In addition the algorithm stores a variable L representing the length of the longest increasing subsequence found so far. Because the algorithm below uses [[zero-based numbering]], for clarity M is padded with M[0], which goes unused so that M[''j''] corresponds to a subsequence of length ''j''. A real implementation can skip M[0] and adjust the indices accordingly.

Note that, at any point in the algorithm, the sequence
:&lt;nowiki&gt;X[M[1]], X[M[2]], ..., X[M[L]]&lt;/nowiki&gt;
is increasing.  For, if there is an increasing subsequence of length ''j'' â¥ 2 ending at X[M[''j'']], then there is also a subsequence of length ''j''-1 ending at a smaller value: namely the one ending at X[P[M[''j'']]]. Thus, we may do binary searches in this sequence in logarithmic time.

The algorithm, then, proceeds as follows:
[[File:LISDemo.gif|400px|thumb|A demo of the code.]]
 
  P = array of length N
  M = array of length N + 1
 
  L = 0
  '''for''' i '''in range''' 0 '''to''' N-1:
    // Binary search for the largest positive j â¤ L
    // such that X[M[j]] &lt; X[i]
    lo = 1
    hi = L
    '''while''' lo â¤ hi:
      mid = ceil((lo+hi)/2)
      '''if''' X[M[mid]] &lt; X[i]:
        lo = mid+1
      '''else''':
        hi = mid-1
 
    // After searching, lo is 1 greater than the
    // length of the longest prefix of X[i]
    newL = lo
 
    // The predecessor of X[i] is the last index of 
    // the subsequence of length newL-1
    P[i] = M[newL-1]
    M[newL] = i
 
    '''if''' newL &gt; L:
      // If we found a subsequence longer than any we've
      // found yet, update L
      L = newL
 
  // Reconstruct the longest increasing subsequence
  S = array of length L
  k = M[L]
  '''for''' i '''in range''' L-1 '''to''' 0:
    S[i] = X[k]
    k = P[k]
 
  '''return''' S

Because the algorithm performs a single binary search per sequence element, its total time can be expressed using [[Big O notation]] as O(''n''&amp;nbsp;log&amp;nbsp;''n''). {{harvtxt|Fredman|1975}} discusses a variant of this algorithm, which he credits to [[Donald Knuth]]; in the variant that he studies, the algorithm tests whether each value X[''i''] can be used to extend the current longest increasing sequence, in constant time, prior to doing the binary search. With this modification, the algorithm uses at most {{nowrap|''n'' log&lt;sub&gt;2&lt;/sub&gt; ''n'' &amp;minus; ''n'' log&lt;sub&gt;2&lt;/sub&gt;log&lt;sub&gt;2&lt;/sub&gt; ''n'' + O(''n'')}} comparisons in the worst case, which is optimal for a comparison-based algorithm up to the constant factor in the O(''n'') term.&lt;ref&gt;{{citation
 | last = Fredman | first = Michael L. | authorlink = Michael Fredman
 | doi = 10.1016/0012-365X(75)90103-X
 | issue = 1
 | journal = Discrete Mathematics
 | pages = 29â35
 | title = On computing the length of longest increasing subsequences
 | volume = 11
 | year = 1975}}.&lt;/ref&gt;

==Length bounds==
According to the [[ErdÅsâSzekeres theorem]], any sequence of ''n''&lt;sup&gt;2&lt;/sup&gt;+1 distinct integers has an increasing or a decreasing subsequence of length  {{nowrap|''n'' + 1.&lt;ref&gt;{{Citation
  | author = [[Paul ErdÅs|ErdÅs, Paul]]; [[George Szekeres|Szekeres, George]]
  | title = A combinatorial problem in geometry
  | journal = Compositio Mathematica
  | volume = 2
  | pages = 463â470
  | year = 1935
  | url = http://www.numdam.org/item?id=CM_1935__2__463_0}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Steele | first = J. Michael | authorlink = J. Michael Steele
 | contribution = Variations on the monotone subsequence theme of ErdÅs and Szekeres
 | editor1-last = Aldous | editor1-first = David | editor1-link = David Aldous
 | editor2-last = Diaconis | editor2-first = Persi | editor2-link = Persi Diaconis
 | editor3-last = Spencer | editor3-first = Joel | editor3-link = Joel Spencer
 |display-editors = 3 | editor4-last = Steele | editor4-first = J. Michael | editor4-link = J. Michael Steele
 | pages = 111â131
 | publisher = Springer-Verlag
 | series = IMA Volumes in Mathematics and its Applications
 | title = Discrete Probability and Algorithms
 | url = http://www-stat.wharton.upenn.edu/~steele/Publications/PDF/VOTMSTOEAS.pdf
 | volume = 72
 | year = 1995}}.&lt;/ref&gt;}} For inputs in which each permutation of the input is equally likely, the expected length of the longest increasing subsequence is approximately 2{{radic|''n''}}.
&lt;ref name="vk"&gt;{{citation
 | last1 = Vershik | first1 = A. M. | author1-link = A._M._Vershik
 | last2 = Kerov | first2 = C. V. 
 | journal = Dokl. Akad. Nauk SSSR
 | pages = 1024â1027
 | title = Asymptotics of the Plancheral measure of the symmetric group and a limiting form for Young tableaux
 | volume = 233
 | year = 1977}}.&lt;/ref&gt; 
In the limit as ''n'' approaches infinity, the length of the longest increasing subsequence of a randomly permuted sequence of ''n'' items has a distribution approaching the [[TracyâWidom distribution]], the distribution of the largest eigenvalue of a random matrix in the [[Gaussian unitary ensemble]].&lt;ref&gt;{{citation|title=On the distribution of the length of the longest increasing subsequence of random permutations|first1=Jinho|last1=Baik|first2=Percy|last2=Deift|first3=Kurt|last3=Johansson|journal=Journal of the American Mathematical Society|volume=12|year=1999|issue=4|pages=1119â1178|doi=10.1090/S0894-0347-99-00307-0|arxiv=math/9810105}}.&lt;/ref&gt;

==Online algorithms==
The longest increasing subsequence has also been studied in the setting of [[online algorithm]]s, in which the elements of a sequence of independent random variables with continuous distribution ''F'' â or alternatively the elements of a [[random permutation]] â are presented one at a time to an algorithm that must decide whether to include or exclude each element, without knowledge of the later elements. In this variant of the problem, which allows for interesting applications in several contexts, it is possible to devise an optimal selection procedure that, given a random sample of size ''n'' as input, will generate an increasing sequence with maximal expected length of size approximately {{sqrt|''2n''}}.
&lt;ref
name="ss81"&gt;{{citation
 | doi = 10.1214/aop/1176994265
 | last1 = Samuels | first1 = Stephen. M.
 | last2 = Steele | first2 = J. Michael | author2-link = J._Michael_Steele
 | journal = Annals of Probability
 | pages = 937â947
 | title = Optimal Sequential Selection of a Monotone Sequence From a Random Sample
 | volume = 9
 | issue = 6
 | year = 1981}}&lt;/ref&gt;
The length of the increasing subsequence selected by this optimal procedure has variance approximately equal to {{sqrt|''2n''}}''/3'', and its limiting distribution is asymptotically [[normal distribution|normal]] after the usual centering and scaling.&lt;ref name="ans2015"&gt;{{citation
 | doi = 10.1016/j.spa.2015.03.009
 | last1 = Arlotto | first1 = Alessandro
 | last2 = Nguyen | first2 = Vinh V.
 | last3 = Steele | first3 = J. Michael | author3-link = J._Michael_Steele
 | journal = Stochastic Processes and their Applications
 | pages = 3596â3622
 | title = Optimal online selection of a monotone subsequence: a central limit theorem
 | volume = 125 
 | issue = 9
 | year = 2015| arxiv = 1408.6750}}&lt;/ref&gt;
The same asymptotic  results hold with more precise bounds for the corresponding problem in the setting of a Poisson arrival process.&lt;ref&gt;{{citation
 | last1 = Bruss | first1 = F. Thomas | author1-link = F._Thomas_Bruss
 | last2 = Delbaen | first2 = Freddy
 | doi =
 | issue = 2
 | journal = Stochastic Processes and their Applications
 | pages = 313â342
 | title = Optimal rules for the sequential selection of monotone subsequences of maximum expected length
 | volume = 96
 | year = 2001}}.&lt;/ref&gt;
A further refinement in the Poisson process setting is given through the proof of a [[central limit theorem]] for the optimal selection process
which holds, with a suitable normalization, in a more complete sense than one would expect. The proof yields not only the "correct" functional limit theorem
but also the (singular) [[covariance matrix]] of the three-dimensional process summarizing all interacting processes.
&lt;ref&gt;{{citation
 | last1 = Bruss | first1 = F. Thomas | author1-link = F._Thomas_Bruss
 | last2 = Delbaen | first2 = Freddy
 | doi = 10.1016/j.spa.2004.09.002
 | issue = 2
 | journal = Stochastic Processes and their Applications
 | pages = 287â311
 | title = A central limit theorem for the optimal selection process for monotone subsequences of maximum expected length
 | volume = 114
 | year = 2004}}.&lt;/ref&gt;

== See also ==
*[[Patience sorting]], an efficient technique for finding the length of the longest increasing subsequence
*[[Plactic monoid]], an algebraic system defined by transformations that preserve the length of the longest increasing subsequence
*[[Anatoly Vershik]], a Russian mathematician who studied applications of group theory to longest increasing subsequences
*[[Longest common subsequence]]
*[[Longest alternating subsequence]]

==References==
{{reflist}}

==External links==
*[http://www.algorithmist.com/index.php/Longest_Increasing_Subsequence Algorithmist's Longest Increasing Subsequence]
*[https://kuuatt.blogspot.com/2017/06/longest-increasing-sub-sequence-longest.html Simplified Longest Increasing Subsequence]
*[https://stackoverflow.com/questions/22923646/number-of-all-longest-increasing-subsequences/22945390#22945390 Finding count of longest increased subsequences]
*[https://cms.di.unipi.it/#/task/poldo/statement Poldo's diet]

[[Category:Problems on strings]]
[[Category:Combinatorics]]
[[Category:Formal languages]]
[[Category:Dynamic programming]]</text>
      <sha1>oql1z7grihwdff5959rxe2lxfw9grah</sha1>
    </revision>
  </page>
  <page>
    <title>Loop theorem</title>
    <ns>0</ns>
    <id>4350138</id>
    <revision>
      <id>790733594</id>
      <parentid>700997894</parentid>
      <timestamp>2017-07-15T19:05:44Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* top */LaTeX spacing clean up, replaced: \, &lt;/math&gt; â &lt;/math&gt; (7) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3048">In mathematics, in the [[topology]] of [[3-manifold]]s, the '''loop theorem''' is a generalization of [[Dehn's lemma]].  The loop theorem was first proven by [[Christos Papakyriakopoulos]] in 1956, along with Dehn's lemma and the [[Sphere theorem (3-manifolds)|Sphere theorem]].

A simple and useful version of the loop theorem states that if there is a map

:&lt;math&gt;f\colon (D^2,\partial D^2)\to (M,\partial M) &lt;/math&gt;

with &lt;math&gt;f|\partial D^2&lt;/math&gt; not nullhomotopic in &lt;math&gt;\partial M&lt;/math&gt;, then there is an embedding with the same property.

The following version of the loop theorem, due to [[John Stallings]], is given in the standard 3-manifold treatises (such as Hempel or Jaco):

Let &lt;math&gt;M&lt;/math&gt; be a [[3-manifold]] and let &lt;math&gt;S&lt;/math&gt;
be a connected surface in &lt;math&gt;\partial M &lt;/math&gt;. Let &lt;math&gt;N\subset 
\pi_1(S)&lt;/math&gt; be a [[normal subgroup]] such that &lt;math&gt;\mathop{\mathrm{ker}}(\pi_1(S) \to \pi_1(M)) - N \neq \emptyset&lt;/math&gt;.
Let

:&lt;math&gt;f \colon D^2\to M &lt;/math&gt;

be a '''continuous map''' such that

:&lt;math&gt;f(\partial D^2)\subset S &lt;/math&gt;

and

:&lt;math&gt;[f|\partial D^2]\notin N. &lt;/math&gt;

Then there exists an '''embedding'''

:&lt;math&gt;g\colon D^2\to M &lt;/math&gt;

such that

:&lt;math&gt;g(\partial D^2)\subset S &lt;/math&gt;

and

:&lt;math&gt;[g|\partial D^2]\notin N. &lt;/math&gt;

Furthermore if one starts with a map ''f'' in general position, then for any neighborhood U of the singularity set of ''f'', we can find such a ''g'' with image lying inside the union of image of ''f'' and U.

Stalling's proof utilizes an adaptation, due to Whitehead and Shapiro, of Papakyriakopoulos' "tower construction".  The "tower" refers to a special sequence of coverings designed to simplify lifts of the given map.  The same tower construction was used by Papakyriakopoulos to prove the [[sphere theorem (3-manifolds)]], which states that a nontrivial map of a sphere into a 3-manifold implies the existence of a nontrivial ''embedding'' of a sphere.  There is also a version of Dehn's lemma for minimal discs due to Meeks and S.-T. Yau, which also crucially relies on the tower construction.

A proof not utilizing the tower construction exists of the first version of the loop theorem.  This was essentially done 30 years ago by [[Friedhelm Waldhausen]] as part of his solution to the word problem for [[Haken manifold]]s; although he recognized this gave a proof of the loop theorem, he did not write up a detailed proof.  The essential ingredient of this proof is the concept of [[Haken hierarchy]].   Proofs were later written up, by [[Klaus Johannson]], [[Marc Lackenby]], and Iain Aitchison with [[Hyam Rubinstein]].

==References==
*W. Jaco, ''Lectures on 3-manifolds topology'', A.M.S. regional conference series in Math 43.
*J. Hempel, ''3-manifolds'', Princeton University Press 1976.
* Hatcher, ''Notes on basic 3-manifold topology'', [http://www.math.cornell.edu/~hatcher/3M/3Mdownloads.html available online]

[[Category:Geometric topology]]
[[Category:3-manifolds]]
[[Category:Continuous mappings]]
[[Category:Theorems in topology]]</text>
      <sha1>b0boprjx00gcrjucpukcyvudfzr21vg</sha1>
    </revision>
  </page>
  <page>
    <title>Luigi Guido Grandi</title>
    <ns>0</ns>
    <id>1464307</id>
    <revision>
      <id>855792213</id>
      <parentid>848414395</parentid>
      <timestamp>2018-08-20T21:27:13Z</timestamp>
      <contributor>
        <username>Eli355</username>
        <id>33551130</id>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7831">{{Redirect|Guido Grandi|the entomologist|Guido Grandi (entomologist)}}
[[image:Guidograndi.jpg|thumb|Guido Grandi]]
[[File:Grandi - De infinitis infinitorum, et infinite parvorum ordinibus disquisitio geometrica, 1710 - 1479870 F.jpeg|thumb|''De infinitis infinitorum'']]
'''[[Dom (title)|Dom]] Guido Grandi''', [[Camaldolese|O.S.B. Cam.]] (October 1, 1671 &amp;ndash; July 4, 1742) was an [[Italy|Italian]] [[monk]], [[priest]], [[philosopher]], [[theologian]], [[mathematician]], and [[engineer]].

==Life==
Grandi was born on Oct. 1, 1671 in [[Cremona]], [[Italy]] and [[baptised|christened]] Luigi Francesco Lodovico. When he was of age, he was educated at the [[Jesuit]] college there. After he completed his studies there in 1687, he entered the [[novitiate]] of the [[Camaldolese]] monks at [[Ferrara]] and took the name of Guido. In 1693 he was sent to the [[San Gregorio al Celio|Monastery of St. Gregory the Great]], the Camaldolese house in Rome, to complete his studies in [[philosophy]] and  [[theology]] in preparation for [[Holy Orders]]. A year later, Grandi was assigned as professor of both fields at the Camaldolese [[St. Mary of the Angels Monastery (Florence)|Monastery of St. Mary of the Angels]] in [[Florence]]. It appears that it was during this period of his life that he took an interest in [[mathematics]]. He did his research privately, however, as he was appointed professor of philosophy at St. Gregory Monastery in 1700, subsequently holding a post in the same field in [[Pisa]].

By 1707, however, Dom Grandi had developed such a reputation in the field of mathematics that he was named court mathematician to the [[Grand Duke of Tuscany]], [[Cosimo III de Medici]]. In that post, he also worked as an engineer, being appointed Superintendent of Water for the [[Duchy]], and in that capacity he was involved in the drainage of the [[List of wine-producing regions#Italy|Chiana Valley]].In 1709 he visited [[England]] where he clearly impressed his colleagues there, as he was elected a [[Fellow of the Royal Society]]. The [[University of Pisa]] named him Professor of Mathematics in 1714. It was there that he died on 4 July 1742.

==Mathematical studies==
In 1701 Grandi published a study of the [[cone (geometry)|conical]] [[loxodrome]], followed by a study in 1703 of the curve which he named ''versiera'', from the {{lang-la|vertere}} (to turn). This curve was later studied by one of the few women scientists to achieve a degree, [[Maria Gaetana Agnesi]]. Through a mistranslation by the translator of her work into English who mistook the term "witch" ({{lang-it|avversiera}}) for Grandi's term, this curve became known in English as the [[witch of Agnesi]].&lt;ref&gt;[http://press.princeton.edu/books/maor/sidebar_f.pdf  "Maria Agnesi and her Witch"] {{webarchive|url=https://web.archive.org/web/20111009082225/http://press.princeton.edu/books/maor/sidebar_f.pdf |date=2011-10-09 }}&lt;/ref&gt; It was through his studies on this curve that Grandi helped introduce [[Gottfried Leibniz|Leibniz]]' ideas on [[calculus]] to Italy.

In mathematics Grandi is best known for his work ''Flores geometrici'' (1728), studying the [[Rose (mathematics)|rose curve]], a curve which has the shape of a petalled flower, and for [[Grandi's series]]. He named the rose curve ''rhodonea''. He also contributed to the ''Note on the Treatise of Galileo Concerning Natural Motion'' in the first Florentine edition of [[Galileo Galilei]]'s works.

==List of works==
*{{cite book
|title = Geometrica demonstratio Vivianeorum problematum
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1483529&amp;custom_att_2=simple_viewer&amp;search_terms=DTL6&amp;pds_handle=
|publisher = ex Typographia Iacobi de Guiduccis propÃ¨ Conductam
|location = Florentiae
|year = 1699
}}
*{{cite book
|title = De infinitis infinitorum, et infinite parvorum ordinibus disquisitio geometrica
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1479870&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|publisher = ex Typographia Francisci Bindi impress. archiepisch.
|location = Pisis
|year = 1710
}}
*{{cite book
|title = Epistola mathematica de momento gravium in planis inclinatis
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1460266&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|publisher = typis Peregrini Frediani
|location = Lucae
|year = 1711
}}
*{{cite book
|title = Dialoghi circa la controversia eccitatagli contro dal sig. Alessandro Marchetti
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=124483&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|publisher = ad istanza di Francesco Maria Gaddi librajo in Pisa
|location = In Lucca
|year = 1712
}}
*{{cite book
|title = Prostasis ad exceptiones clari Varignonii libro De infinitis infinitorum ordinibus oppositas circa magnitudinum plusquam-infinitarum Vallisii defensionem et anguli contactus
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1460668&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|publisher = ex Typographia Francisci Bindi impress. archiepisch.
|location = Pisis
|year = 1713
}}
*{{cite book
|title = Del movimento dell'acque trattato geometrico
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=124156&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|location = Firenze
}}
*{{cite book
|title = Relazione delle operazioni fatte circa il padule di Fucecchio
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=2045932&amp;custom_att_2=simple_viewer&amp;search_terms=DTL3&amp;pds_handle=
|publisher = per Leonardo Venturini
|location = In Lucca
|year = 1718
}}
*{{cite book
|title = Trattato delle resistenze
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1498211&amp;custom_att_2=simple_viewer&amp;search_terms=DTL5&amp;pds_handle=
|publisher = per Tartini e Franchi
|location = Firenze
|year = 1718
}}
*{{cite book
|title = Compendio delle Sezioni coniche d'Apollonio con aggiunta di nuove proprietÃ  delle medesime sezioni
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1291272&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|publisher = nella Stamperia di S.A.R. per gli Tartini e Franchi
|location = In Firenze
|year = 1722
}}
*{{cite book
|title = Instituzioni meccaniche
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1495227&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|publisher = nella Stamperia di S.A.R. per Gio: Gaetano Tartini e Santi Franchi
|location = In Firenze
|year = 1739
}}
*{{cite book
|title = Istituzioni di aritmetica pratica
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1460393&amp;custom_att_2=simple_viewer&amp;search_terms=DTL4&amp;pds_handle=
|publisher = nella Stamperia di S.A.R. per Gio: Gaetano Tartini e Santi Franchi
|location = In Firenze
|year = 1740
}}
*{{cite book
|title = Sectionum conicarum synopsis
|url = http://gutenberg.beic.it/webclient/DeliveryManager?pid=1495610&amp;custom_att_2=simple_viewer&amp;search_terms=DTL6&amp;pds_handle=
|publisher = ex typographio Ioannis Paulli Giovannelli
|location = Florentiae
|year = 1750
}}

==References==
{{reflist}}

==External links==
*{{MacTutor Biography|id=Grandi}}
*[http://galileo.rice.edu/Catalog/NewFiles/grandi.html Galileo Project:] Guido Grandi

{{Grandi's series}}
{{Authority control}}

{{DEFAULTSORT:Grandi, Guido}}
[[Category:Italian engineers]]
[[Category:Italian philosophers]]
[[Category:17th-century Italian mathematicians]]
[[Category:18th-century Italian mathematicians]]
[[Category:Camaldolese Order]]
[[Category:Fellows of the Royal Society]]
[[Category:Catholic clergy scientists]]
[[Category:1671 births]]
[[Category:1742 deaths]]
[[Category:Italian Benedictines]]
[[Category:Benedictine scholars]]
[[Category:People from Cremona]]
[[Category:Benedictine writers]]
[[Category:Grandi's series]]</text>
      <sha1>fwcat80rc6l8g1qn7xni9ca9lfdmi2s</sha1>
    </revision>
  </page>
  <page>
    <title>Magnitude (mathematics)</title>
    <ns>0</ns>
    <id>577301</id>
    <revision>
      <id>856252656</id>
      <parentid>856252507</parentid>
      <timestamp>2018-08-23T22:47:02Z</timestamp>
      <contributor>
        <username>Shellwood</username>
        <id>2366721</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/177.142.89.137|177.142.89.137]] ([[User talk:177.142.89.137|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6805">{{Other uses|Magnitude (disambiguation)}}

In mathematics, '''magnitude''' is the size of a [[mathematical object]], a property which determines whether the object is larger or smaller than other objects of the same kind. More formally, an object's magnitude is the displayed result of an [[order theory|ordering]] (or ranking) of the [[class (mathematics)|class]] of objects to which it belongs.

==History==
The Greeks distinguished between several types of magnitude,&lt;ref&gt;{{cite book
 | last = Heath
 | first = Thomas Smd.
 | authorlink = T. L. Heath
 | title = The Thirteen Books of Euclid's Elements
 | edition = 2nd ed. [Facsimile. Original publication: Cambridge University Press, 1925]
 | year = 1956
 | publisher = Dover Publications
 | location = New York
 }}&lt;/ref&gt; including:
*Positive [[fractions]]
*[[Line segment]]s (ordered by [[length]])
*[[Geometric shape|Plane figures]] (ordered by [[area]])
*[[Polyhedron|Solids]] (ordered by [[volume]])
*[[Angle|Angles]] (ordered by angular magnitude)

They proved that the first two could not be the same, or even [[isomorphic]] systems of magnitude.&lt;ref&gt;{{citation|title=The Real Numbers and Real Analysis|first=Ethan D.|last=Bloch|publisher=Springer|year=2011|isbn=9780387721774|page=52|url=https://books.google.com/books?id=vXw_AAAAQBAJ&amp;pg=PA52|quote=The idea of incommensurable pairs of lengths of line segments was discovered in ancient Greece}}.&lt;/ref&gt; They did not consider negative magnitudes to be meaningful, and ''magnitude'' is still chiefly used in contexts in which zero is either the smallest size or less than all possible sizes.

==Numbers==
{{Main|Absolute value}}

The magnitude of any [[number]]  is usually called its "[[absolute value]]" or "modulus", denoted by |''x''|.

===Real numbers===
The absolute value of a [[real number]] ''r'' is defined by:&lt;ref&gt;{{cite book|last=Mendelson|first=Elliott|title=Schaum's Outline of Beginning Calculus|publisher=McGraw-Hill Professional|date=2008|isbn=978-0-07-148754-2|page=2}}&lt;/ref&gt;

:&lt;math&gt; \left| r \right| = r, \text{ if } r \text{ â¥ } 0 &lt;/math&gt;
:&lt;math&gt; \left| r \right| = -r, \text{ if } r &lt; 0 .&lt;/math&gt;

Absolute value may be thought of as the number's [[distance]] from [[zero]] on the real [[number line]]. For example, the absolute value of both 70 and â70 is 70.

===Complex numbers===
A [[complex number]] ''z'' may be viewed as the position of a point ''P'' in a [[Euclidean space|2-dimensional space]], called the [[complex plane]]. The absolute value or modulus of ''z'' may be thought of as the distance of ''P'' from the origin of that space. The formula for the absolute value of {{nowrap|1=''z'' = ''a'' + ''bi''}} is similar to that for the [[Euclidean norm]] of a vector in a 2-dimensional Euclidean space:&lt;ref&gt;{{cite book|last=Ahlfors|first=Lars V.|title=Complex Analysis|publisher=McGraw Hill Kogakusha|location=Tokyo|date=1953}}&lt;/ref&gt;

:&lt;math&gt; \left| z \right| = \sqrt{a^2 + b^2 }&lt;/math&gt;

where the real numbers ''a'' and ''b'' are the [[real part]] and the [[imaginary part]] of ''z'', respectively. For instance, the modulus of {{nowrap|â3 + 4&lt;var&gt;''i''&lt;/var&gt;}} is &lt;math&gt;\sqrt{(-3)^2+4^2} = 5&lt;/math&gt;.  Alternatively, the magnitude of a complex number ''z'' may be defined as the square root of the product of itself and its [[complex conjugate]], ''z''&lt;sup&gt;â&lt;/sup&gt;, where for any complex number {{nowrap|1=''z'' = ''a'' + ''bi''}}, its complex conjugate is {{nowrap|1=''z''&lt;sup&gt;â&lt;/sup&gt; = ''a'' â ''bi''}}. 
:&lt;math&gt; \left| z \right| = \sqrt{zz^* } = \sqrt{(a+bi)(a-bi)} = \sqrt{a^2 -abi + abi - b^2i^2} = \sqrt{a^2 + b^2 }&lt;/math&gt;
&lt;big&gt;(&lt;/big&gt; recall &lt;math&gt;i^2 = -1&lt;/math&gt; &lt;big&gt;)&lt;/big&gt;

==Vector spaces==
===Euclidean vector space===
{{Main|Euclidean norm}}
A [[Euclidean vector]] represents the position of a point ''P'' in a [[Euclidean space]]. Geometrically, it can be described as an arrow from the origin of the space (vector tail) to that point (vector tip). Mathematically, a vector '''x''' in an ''n''-dimensional Euclidean space can be defined as an ordered list of ''n'' [[real number]]s (the [[Cartesian coordinate]]s of ''P''): ''x'' = [''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ..., ''x''&lt;sub&gt;''n''&lt;/sub&gt;]. Its '''magnitude''' or '''length''' is most commonly defined as its [[Norm (mathematics)#Euclidean norm|Euclidean norm]] (or Euclidean length):&lt;ref&gt; {{Citation|last=Anton|first=Howard|year=2005|title=Elementary Linear Algebra (Applications Version)|publisher=Wiley International|edition=9th}}&lt;/ref&gt;
:&lt;math&gt;\|\mathbf{x}\| := \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}.&lt;/math&gt;
For instance, in a 3-dimensional space, the magnitude of [3, 4, 12] is 13 because &lt;math&gt;\sqrt{3^2 + 4^2 + 12^2} = \sqrt{169} = 13.&lt;/math&gt;
This is equivalent to the [[square root]] of the [[dot product]] of the vector by itself:
:&lt;math&gt;\|\mathbf{x}\| :=  \sqrt{\mathbf{x} \cdot \mathbf{x}}.&lt;/math&gt;

The Euclidean norm of a vector is just a special case of [[Euclidean distance]]: the distance between its tail and its tip. Two similar notations are used for the Euclidean norm of a vector ''x'':
#&lt;math&gt;\left \| \mathbf{x} \right \|,&lt;/math&gt;
#&lt;math&gt;\left | \mathbf{x} \right |.&lt;/math&gt;
A disadvantage of the second notation is that it is also used to denote the [[absolute value]] of scalars and the [[determinant]]s of matrices and therefore can be ambiguous.

===Normed vector spaces===
{{Main|Normed vector space}}

By definition, all Euclidean vectors have a magnitude (see above). However, the notion of magnitude cannot be applied to all kinds of vectors.

A function that maps objects to their magnitudes is called a [[norm (mathematics)|norm]]. A [[vector space]] endowed with a norm, such as the Euclidean space, is called a [[normed vector space]].&lt;ref&gt;{{Citation|last=Golan|first=Johnathan S.|date=January 2007|title=The Linear Algebra a Beginning Graduate Student Ought to Know|publisher=Springer|edition=2nd|isbn=978-1-4020-5494-5}}&lt;/ref&gt; Not all vector spaces are normed.

===Pseudo-Euclidean space===
In a [[pseudo-Euclidean space]], the magnitude of a vector is the value of the [[quadratic form]] for that vector.

==Logarithmic magnitudes==
When comparing magnitudes, a [[logarithm]]ic scale is often used. Examples include the [[loudness]] of a [[sound]] (measured in [[decibel|decibels]]), the [[brightness]] of a [[star]], and the [[Richter magnitude scale|Richter scale]] of earthquake intensity. Logarithmic magnitudes can be negative. It is not meaningful to simply add or subtract them.

==Order of magnitude==
{{main|Order of magnitude}}

Orders of magnitude denote differences in numeric quantities, usually measurements, by a factor of 10âthat is, a difference of one digit in the location of the decimal point.

==See also==
*[[Number sense]]

==References==
{{reflist}}

[[Category:Elementary mathematics]]
[[Category:Unary operations]]</text>
      <sha1>nvenzj13gxvuikzki4kblk27zeeb4eh</sha1>
    </revision>
  </page>
  <page>
    <title>Mark J. Ablowitz</title>
    <ns>0</ns>
    <id>18578839</id>
    <revision>
      <id>858980724</id>
      <parentid>858831215</parentid>
      <timestamp>2018-09-10T22:27:48Z</timestamp>
      <contributor>
        <username>EdmundT</username>
        <id>285130</id>
      </contributor>
      <minor/>
      <comment>/* Education */ Spelling</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6282">{{Infobox scientist
| name              = Mark Ablowitz
| native_name       = 
| native_name_lang  = 
| image             = &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| image_size        = 
| image_upright     = 
| alt               = 
| caption           = 
| birth_name        = Mark Jay Ablowitz
| birth_date        = {{birth date |1945|06|05}}
| birth_place       = [[New York City]]
| death_date        = &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| death_place       = 
| death_cause       = 
| resting_place     = 
| resting_place_coordinates = &lt;!--{{coord|LAT|LONG|type:landmark|display=inline,title}}--&gt;
| other_names       = 
| pronounce         =
| residence         = 
| citizenship       = 
| nationality       = 
| fields            = 
| workplaces        = [[University of Colorado Boulder]]&lt;br&gt;[[Princeton University]]
| patrons           = 
| education         = 
| alma_mater        = [[University of Rochester]] (BS)&lt;br&gt;[[Massachusetts Institute of Technology]] (PhD)
| thesis_title      = Non-Linear Dispersive Waves and Multiphase Modes
| thesis_url        = http://library.mit.edu/item/000677877
| thesis_year       = 1971
| doctoral_advisor  = [[David Benney]]&lt;ref name=mathgene/&gt;
| academic_advisors = 
| doctoral_students = [[Rudy Horne]]&lt;ref name=mathgene&gt;{{MathGenealogy|60180}}&lt;/ref&gt;
| notable_students  = 
| known_for         = 
| influences        = 
| influenced        = 
| awards            = [[Sloan Research Fellowship]]{{when|date=September 2018}}
| spouse            = &lt;!--(or | spouses = )--&gt;
| partner           = &lt;!--(or | partners = )--&gt;
| children          = 
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| website           = {{URL|markablowitz.com}}
| footnotes         = 
}}
'''Mark Jay Ablowitz''' (born June 5, 1945, [[New York City|New York]])&lt;ref&gt;{{cite web|url=https://books.google.com/books?id=Ax3L08ks7IwC&amp;q=%E2%80%9CAblowitz,+Mark+Jay%E2%80%9D&amp;dq=%E2%80%9CAblowitz,+Mark+Jay%E2%80%9D&amp;hl=en&amp;ei=q1AbTv_aJMussAKh1rDCBw&amp;sa=X&amp;oi=book_result&amp;ct=result&amp;resnum=2&amp;ved=0CC0Q6AEwAQ|title=American men &amp; women of science: a biographical directory of today's leaders in physical, biological and related sciences|first=R. R. Bowker|last=Company|date=9 September 1992|publisher=Bowker|via=Google Books}}&lt;/ref&gt; is a [[professor]] in the department of [[Applied Mathematics]] at the [[University of Colorado at Boulder]], [[Colorado]]. He was born in [[New York City]].{{fact|date=September 2018}} 

== Education==
Ablowitz received his [[Bachelor of Science]] degree in [[Mechanical Engineering]] from [[University of Rochester]],{{when|date=September 2018}} and completed his [[Doctor of Philosophy|Ph.D.]] in [[Mathematics]] under the supervision of [[David Benney]] at [[Massachusetts Institute of Technology]] in 1971.&lt;ref name=mathgene/&gt;&lt;ref name="AblowitzBenney1970"&gt;{{cite journal|last1=Ablowitz|first1=M. J.|last2=Benney|first2=D. J.|title=The Evolution of Multi-Phase Modes for Nonlinear Dispersive Waves|journal=Studies in Applied Mathematics|volume=49|issue=3|year=1970|pages=225â238|issn=00222526|doi=10.1002/sapm1970493225}}&lt;/ref&gt;

==Career and research==
Ablowitz was an assistant professor of Mathematics at [[Clarkson University]] during 1971â1975 and an associate professor during 1975â1976. He visited the Program in Applied Mathematics founded by [[Ahmed Cemal Eringen]] at [[Princeton University]] during 1977â1978. He was a professor of Mathematics at [[Clarkson University|Clarkson]] during 1976-1985 where he became the Chairman of the Department of Mathematics and Computer Science in 1979. In July 1, 1985, he was appointed as the Dean of Science of Clarkson University and served there until he joined to the department of [[Applied Mathematics]] (APPM) at [[University of Colorado Boulder]] in June 30, 1989.&lt;ref&gt;{{cite web|url=https://sites.google.com/site/ablowitz/background|title=Background - Mark J. Ablowitz|website=sites.google.com}}&lt;/ref&gt;

===Awards and honors===
*[[Sloan Fellowship]], 1975â1977.
*[[Clarkson University|Clarkson]] Graham Research Award, 1976.
*[[John Simon Guggenheim Foundation]] Fellowship, 1984.
*[[Society for Industrial and Applied Mathematics|SIAM]] Fellow, 2011.
*[[National Academy of Sciences]] Symposium on Soliton Theory Kiev, USSR 1979.
*Fellow of the [[American Mathematical Society]], 2012.&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2012-11-03.&lt;/ref&gt;

===Publications===
*''[[Solitons]] and the [[Inverse scattering problem|Inverse Scattering]] Transform'', M.J. Ablowitz and H. Segur, (SIAM Studies in Applied Mathematics) 1981
*''Topics in Soliton Theory and Exactly Solvable Nonlinear Equations'', Eds. M.J. Ablowitz, B. Fuchssteiner and [[Martin D. Kruskal|M. D. Kruskal]], ([[World Scientific]]) 1987
*''Solitons, Nonlinear Evolution Equations and Inverse Scattering'', M.J. Ablowitz and P.A. Clarkson, ([[London Mathematical Society]] Lecture Notes Series, 516 pages, ([[Cambridge University Press]], Cambridge, UK, 1991)
*''Complex Variables: Introduction and Applications'', Mark J. Ablowitz and [[Athanassios S. Fokas|A. S. Fokas]], (Cambridge University Press, Cambridge, UK, 1997)
*''Nonlinear Physics: Theory and Experiment. II'', M.J. Ablowitz, M. Boiti, F. Pempinelli and B. Prinari, (World Scientific 2003)
*''Discrete and Continuous Nonlinear SchrÃ¶dinger Systems'', Mark J. Ablowitz, B. Prinari and D. Trubatch, 258 (Cambridge University Press, Cambridge, UK, 2004)
*''Nonlinear Dispersive Waves: Asymptotic Analysis and Solitons'', Mark J. Ablowitz, (Cambridge University Press, Cambridge, UK, 2011)

==References==
{{reflist}}

{{Authority control}}

{{DEFAULTSORT:Ablowitz, Mark J.}}
[[Category:Living people]]
[[Category:University of Rochester alumni]]
[[Category:Massachusetts Institute of Technology alumni]]
[[Category:Clarkson University faculty]]
[[Category:University of Colorado Boulder faculty]]
[[Category:ISI highly cited researchers]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:1945 births]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Society for Industrial and Applied Mathematics]]</text>
      <sha1>ixx5tldtlol8una3jvrqko6n6twx9tm</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematics and fiber arts</title>
    <ns>0</ns>
    <id>13410380</id>
    <revision>
      <id>833778351</id>
      <parentid>788835431</parentid>
      <timestamp>2018-04-02T11:38:52Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTPâHTTPS]] (v485)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9252">[[File:Moebiusstripscarf.jpg|right|thumb|200px|A [[MÃ¶bius strip]] scarf made from crochet.]]
Ideas from '''[[Mathematics]]''' have been used as inspiration for '''[[fiber art]]s''' including [[quilt]] [[quilting|making]], [[knitting]], [[cross-stitch]], [[crochet]], [[embroidery]] and [[weaving]]. A wide range of mathematical concepts have been used as inspiration including [[topology]], [[graph theory]], [[number theory]] and [[algebra]]. Some techniques such as [[counted-thread embroidery]] are naturally [[geometry|geometrical]]; other kinds of [[textile]] provide a ready means for the colorful [[mathematics and art|physical expression of mathematical concepts]].

==Quilting==
{{main|quilt}}

The [[IEEE Spectrum]] has organized a number of competitions on [[quilt block]] design, and several books have been published on the subject. Notable quiltmakers include Diana Venters and Elaine Ellison, who have written a book on the subject ''Mathematical Quilts: No Sewing Required''. Examples of mathematical ideas used in the book as the basis of a quilt include the [[golden rectangle]], [[conic section]]s, [[Leonardo da Vinci]]'s Claw, the [[Koch curve]], the [[Clifford torus]], [[San Gaku]], [[Lorenzo Mascheroni|Mascheroni]]'s [[cardioid]], [[Pythagorean triple]]s, [[spidron]]s, and the six [[trigonometric functions]].&lt;ref&gt;{{cite book | last1=Ellison | first1=Elaine | last2=Venters | first2=Diana | isbn=1-55953-317-X | publisher=Key Curriculum | title=Mathematical Quilts: No Sewing Required | year=1999}}.&lt;/ref&gt;

==Knitting and crochet==
[[Image:Cross stitch embroidery.jpg|thumb|[[Cross-stitch]] [[counted-thread embroidery]]]]

Knitted mathematical objects include the [[Platonic solid]]s, [[Klein bottle]]s and [[Boy's surface]].
The [[Lorenz attractor|Lorenz manifold]] and the [[Hyperbolic manifold|hyperbolic plane]] have been crafted using crochet.&lt;ref&gt;{{citation | last1 = Henderson | first1 = David | last2 = Taimina | first2 = Daina | author2-link = Daina Taimina | doi = 10.1007/BF03026623 | issue = 2 | journal = [[Mathematical Intelligencer]]
 | pages = 17â28 | title = Crocheting the hyperbolic plane | url = http://www.math.cornell.edu/%7Edwh/papers/crochet/crochet.PDF | volume = 23 | year = 2001}}}.&lt;/ref&gt;&lt;ref&gt;{{citation | last1 = Osinga | first1 = Hinke M. | author1-link = Hinke Osinga
 | last2 = Krauskopf | first2 = Bernd | doi = 10.1007/BF02985416 | issue = 4 | journal = Mathematical Intelligencer | pages = 25â37 | title = Crocheting the Lorenz manifold | url = http://www.enm.bris.ac.uk/anm/preprints/2004r03.html | volume = 26 | year = 2004}}.&lt;/ref&gt; Knitted and crocheted [[torus|tori]] have also been constructed depicting [[toroidal graph|toroidal embeddings]] of the [[complete graph]] ''K''&lt;sub&gt;7&lt;/sub&gt; and of the [[Heawood graph]].&lt;ref&gt;{{citation|first1=sarah-marie|last1=belcastro|first2=Carolyn|last2=Yackel|contribution=The seven-colored torus: mathematically interesting and nontrivial to construct|pages=25â32|title=Homage to a Pied Puzzler|editor1-first=Ed, Jr.|editor1-last=Pegg|editor1-link=Ed Pegg, Jr.|editor2-first=Alan H.|editor2-last=Schoen|editor3-first=Tom|editor3-last=Rodgers|publisher=AK Peters|year=2009}}.&lt;/ref&gt; The crocheting of hyperbolic planes has been popularized by the [[Institute For Figuring]]; a book by [[Daina Taimina]] on the subject, ''Crocheting Adventures with Hyperbolic Planes'', won the 2009 [[Bookseller/Diagram Prize for Oddest Title of the Year]].&lt;ref&gt;{{citation | last = Bloxham | first = Andy | date = March 26, 2010 | journal = [[The Daily Telegraph|The Telegraph]] | title = Crocheting Adventures with Hyperbolic Planes wins oddest book title award
 | url = https://www.telegraph.co.uk/culture/books/bookprizes/7520047/Crocheting-Adventures-with-Hyperbolic-Planes-wins-oddest-book-title-award.html}}.&lt;/ref&gt;

==Embroidery==

[[File:Florentin.png|thumb|upright|Two [[Bargello (needlework)|Bargello patterns]]]]

Embroidery techniques such as [[counted-thread embroidery]]&lt;ref&gt;Gillow, John, and Bryan Sentance. ''World Textiles'', Little, Brown, 1999.&lt;/ref&gt; including [[cross-stitch]] and some [[canvas work]] methods such as [[Bargello (needlework)]] make use of the natural [[pixel]]s of the weave, lending themselves to geometric designs.&lt;ref&gt;Snook, Barbara. ''Florentine Embroidery''. Scribner, Second edition 1967.&lt;/ref&gt;&lt;ref&gt;Williams, Elsa S. ''Bargello: Florentine Canvas Work''. Van Nostrand Reinhold, 1967.&lt;/ref&gt;

==Weaving==

[[Ada Dietz]] (1882 &amp;ndash; 1950) was an American [[weaving|weaver]] best known for her 1949 monograph ''Algebraic Expressions in Handwoven Textiles'', which defines weaving patterns based on the expansion of multivariate [[polynomial]]s.&lt;ref&gt;{{citation | last = Dietz | first = Ada K. | location = Louisville, Kentucky
 | publisher = The Little Loomhouse | title = Algebraic Expressions in Handwoven Textiles | url = http://www.cs.arizona.edu/patterns/weaving/monographs/dak_alge.pdf | year = 1949}}&lt;/ref&gt;

{{harvs|first=J. C. P.|last=Miller|authorlink=J. C. P. Miller|year=1970|txt}} used the [[Rule 90]] [[cellular automaton]] to design [[tapestry|tapestries]] depicting both trees and abstract patterns of triangles.&lt;ref&gt;{{citation|first=J. C. P.|last=Miller|authorlink=J. C. P. Miller|title=Periodic forests of stunted trees |journal=Philosophical Transactions of the Royal Society of London |series=Series A, Mathematical and Physical Sciences |volume=266| issue=1172| year=1970 |pages=63â111 |doi=10.1098/rsta.1970.0003 |bibcode=1970RSPTA.266...63M |jstor=73779}}&lt;/ref&gt;

==Spinning==

[[Margaret Greig]] was a mathematician who articulated the mathematics of [[worsted spinning]].&lt;ref&gt;{{citation |title=International Women in Science |author=Catharine M. C. Haines |publisher=ABC-CLIO |year=2001 |isbn=9781576070901 |page=118}}&lt;/ref&gt;

==Fashion design==

The silk scarves from DMCK Designs' 2013 collection are all based on Douglas McKenna's [[space-filling curve]] patterns.&lt;ref&gt;{{cite web|title=Space-Filling Curves|url=https://dmck.us/the-company/space-filling-curves/|publisher=DMCK|accessdate=15 May 2015}}&lt;/ref&gt; The designs are either generalized Peano curves, or based on a new space-filling construction technique.&lt;ref&gt;{{cite web | author=McKenna, Douglas |title=The 7 Curve, Carpets, Quilts, and Other Asymmetric, Square-Filling, Threaded Tile Designs |work=Bridges Donostia: Mathematics, Music, Art, Architecture, Culture |url=http://www.bridgesmathart.org/2007/2007-program.html |publisher=The Bridges Organization | date=24 July 2007 |accessdate=15 May 2015}}&lt;/ref&gt;&lt;ref&gt;{{cite web |last1=McKenna |first1=Douglas |title=Designing Symmetric Peano Curve Tiling Patterns with Escher-esque Foreground/Background Ambiguity |work=Bridges Leeuwarden: Mathematics, Music, Art, Architecture, Culture |url=http://www.bridgesmathart.org/2008/Schedule_V9-1.pdf |publisher=The Bridges Organization |accessdate=15 May 2015|date=28 July 2008}}&lt;/ref&gt;

The [[Issey Miyake]] Fall-Winter 2010â2011 ready-to-wear collection featured designs from a collaboration between fashion designer Dai Fujiwara and mathematician [[William Thurston]]. The designs were inspired by Thurston's [[geometrization conjecture]], the statement that every [[3-manifold]] can be decomposed into pieces with one of eight different uniform geometries, a proof of which had been sketched in 2003 by [[Grigori Perelman]] as part of his proof of the [[PoincarÃ© conjecture]].&lt;ref&gt;{{cite | last = Barchfield | first = Jenny | date = March 5, 2010 | publisher = [[ABC News]] | title = Fashion and Advanced Mathematics Meet at Miyake | url = http://abcnews.go.com/Entertainment/wireStory?id=10017982}}.&lt;/ref&gt;

==References==

{{reflist|28em}}

==Further reading==
*{{cite book |editor1=belcastro, sarah-marie&lt;!--intentionally not caps--&gt; |editor2=Carolyn, Yackel |title=Making Mathematics with Needlework: Ten Papers and Ten Projects |year=2007 |publisher=A K Peters |isbn=1-56881-331-7}}
*{{cite journal |doi=10.2307/2690105 |author1=GrÃ¼nbaum, Branko |authorlink1=Branko GrÃ¼nbaum |author2=Shephard, Geoffrey C. |title=Satins and Twills: An Introduction to the Geometry of Fabrics |date=May 1980 |journal=Mathematics Magazine |volume=53 |issue=3 |pages=139â161 |jstor=2690105}}
*{{cite book |author=Taimina, Daina |authorlink=Daina Taimina|title=Crocheting Adventures with Hyperbolic Planes |year=2009 |publisher=A K Peters |isbn=1-56881-452-6}}

==External links==
*[http://www.mathematicalquilts.com/ Mathematical quilts]
*[http://www.toroidalsnark.net/mathknit.html Mathematical knitting]
*[http://www.allfiberarts.com/cs/math.htm Mathematical weaving]
*[http://www.k2g2.org/links:math_craft_projects Mathematical craft projects]
*[http://www.woollythoughts.com/mathspuzzles.html Wooly Thoughts Creations: Maths Puzzles &amp; Toys]
*[http://dogfeathers.com/quilt/penrose.html Penrose tiling quilt]
*[http://www.cabinetmagazine.org/issues/16/crocheting.php Crocheting the Hyperbolic Plane: An Interview with David Henderson and Daina Taimina]
*[http://www.toroidalsnark.net/mkss.html  AMS Special Session on Mathematics and Mathematics Education in Fiber Arts] (2005)

{{Mathematical art}}
{{Textile arts}}

[[Category:Mathematics and culture]]
[[Category:Textile arts]]
[[Category:Recreational mathematics]]
[[Category:Mathematics and art]]</text>
      <sha1>7fh73rtvqa8w62e1gy1qo7qjggom2sf</sha1>
    </revision>
  </page>
  <page>
    <title>Median (geometry)</title>
    <ns>0</ns>
    <id>1072006</id>
    <revision>
      <id>871399125</id>
      <parentid>871360084</parentid>
      <timestamp>2018-11-30T20:05:41Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <minor/>
      <comment>Reverted 1 edit by [[Special:Contributions/2405:204:C691:BA8D:0:0:2942:20A4|2405:204:C691:BA8D:0:0:2942:20A4]] ([[User talk:2405:204:C691:BA8D:0:0:2942:20A4|talk]]) to last revision by CLCStudent. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8067">{{distinguish|Geometric median}}

[[Image:Triangle.Centroid.svg|right|thumb|The triangle medians and the [[centroid]].]]
In [[geometry]], a '''median''' of a [[triangle]] is a [[line segment]] joining a [[vertex (geometry)|vertex]] to the [[midpoint]] of the opposing side, bisecting it. Every triangle has exactly three medians, one from each vertex, and they all intersect each other at the triangle's [[triangle centroid|centroid]]. In the case of [[isosceles]] and [[equilateral]] triangles, a median [[angle bisector|bisects any angle]] at a vertex whose two adjacent sides are equal in length.

The concept of a median extends to [[tetrahedron|tetrahedra]].

==Relation to center of mass==
Each median of a triangle passes through the triangle's [[centroid]], which is the [[center of mass]] of an infinitely thin object of uniform density coinciding with the triangle.&lt;ref&gt;{{cite book|last=Weisstein|first=Eric W.|title=CRC Concise Encyclopedia of Mathematics, Second Edition|year=2010|publisher=CRC Press|isbn=9781420035223|pages=375â377}}&lt;/ref&gt; Thus the object would balance on the intersection point of the medians. The centroid is twice as close along any median to the side that the median intersects as it is to the vertex it emanates from.

==Equal-area division==
[[Image:Triangle.Centroid.Median.png|thumb|right|300px|]]
Each median divides the area of the triangle in half; hence the name, and hence a triangular object of uniform density would balance on any median. (Any other lines which divide the area of the triangle into two equal parts do not pass through the centroid.)&lt;ref name=Bottomley2002&gt;{{cite web|last=Bottomley|first=Henry|title=Medians and Area Bisectors of a Triangle|url=http://www.se16.info/js/halfarea.htm|accessdate=27 September 2013}}&lt;/ref&gt;&lt;ref name=Dunn&gt;Dunn, J. A., and Pretty, J. E., "Halving a triangle," ''[[Mathematical Gazette]]'' 56, May 1972, 105-108.&lt;/ref&gt; The three medians divide the triangle into six smaller triangles of equal [[area]]. 

===Proof of equal-area property===
Consider a triangle ''ABC''. Let ''D'' be the midpoint of &lt;math&gt;\overline{AB}&lt;/math&gt;, ''E'' be the midpoint of &lt;math&gt;\overline{BC}&lt;/math&gt;, ''F'' be the midpoint of &lt;math&gt;\overline{AC}&lt;/math&gt;, and ''O'' be the centroid (most commonly denoted ''G'').

By definition, &lt;math&gt;AD=DB, AF=FC, BE=EC &lt;/math&gt;. Thus &lt;math&gt;[ADO]=[BDO], [AFO]=[CFO], [BEO]=[CEO],&lt;/math&gt; and &lt;math&gt;[ABE]=[ACE] &lt;/math&gt;, where &lt;math&gt;[ABC]&lt;/math&gt; represents the [[area]] of triangle &lt;math&gt;\triangle ABC&lt;/math&gt; ; these hold because in each case the two triangles have bases of equal length and share a common altitude from the (extended) base, and a triangle's area equals one-half its base times its height.

We have:
:&lt;math&gt;[ABO]=[ABE]-[BEO] &lt;/math&gt;

:&lt;math&gt;[ACO]=[ACE]-[CEO] &lt;/math&gt;

Thus, &lt;math&gt;[ABO]=[ACO] &lt;/math&gt; and &lt;math&gt;[ADO]=[DBO], [ADO]=\frac{1}{2}[ABO]&lt;/math&gt;

Since &lt;math&gt;[AFO]=[FCO], [AFO]= \frac{1}{2}[ACO]=\frac{1}{2}[ABO]=[ADO]&lt;/math&gt;, therefore, &lt;math&gt;[AFO]=[FCO]=[DBO]=[ADO]&lt;/math&gt;.
Using the same method, one can show that &lt;math&gt;[AFO]=[FCO]=[DBO]=[ADO]=[BEO]=[CEO] &lt;/math&gt;.

===Three congruent triangles===
In 2014 [[Lee Sallows]] discovered the following theorem:&lt;ref&gt;Sallows, Lee, "[https://www.jstor.org/stable/10.4169/math.mag.87.5.381 A Triangle Theorem]" ''[[Mathematics Magazine]]'', Vol. 87, No. 5 (December 2014), p.&amp;nbsp;381&lt;/ref&gt;
:The medians of any triangle dissect it into six equal area smaller triangles as in the figure above where three adjacent pairs of triangles meet at the midpoints D, E and F. If the two triangles in each such pair are rotated about their common midpoint until they meet so as to share a common side, then the three new triangles formed by the union of each pair are congruent.

==Formulas involving the medians' lengths==
The lengths of the medians can be obtained from [[Apollonius' theorem]] as:

:&lt;math&gt;m_a = \sqrt {\frac{2 b^2 + 2 c^2 - a^2}{4} }, &lt;/math&gt;

:&lt;math&gt;m_b = \sqrt {\frac{2 a^2 + 2 c^2 - b^2}{4} }, &lt;/math&gt;

:&lt;math&gt;m_c = \sqrt {\frac{2 a^2 + 2 b^2 - c^2}{4} }, &lt;/math&gt;

where ''a'', ''b'' and ''c'' are the sides of the triangle with respective medians ''m''&lt;sub&gt;''a''&lt;/sub&gt;, ''m''&lt;sub&gt;''b''&lt;/sub&gt;, and ''m''&lt;sub&gt;''c''&lt;/sub&gt; from their midpoints.

Thus we have the relationships:&lt;ref&gt;{{cite book |last=DÃ©planche |first=Y. |title=Diccio fÃ³rmulas  |language= |others=Medianas de un triÃ¡ngulo |year=1996 |publisher=Edunsa |isbn=978-84-7747-119-6 |page=22 |url=https://books.google.com/books?id=1HVHOwAACAAJ |accessdate=2011-04-24 }}&lt;/ref&gt;

:&lt;math&gt;a = \frac{2}{3} \sqrt{-m_a^2 + 2m_b^2 + 2m_c^2} = \sqrt{2(b^2+c^2)-4m_a^2} = \sqrt{\frac{b^2}{2} - c^2 + 2m_b^2} = \sqrt{\frac{c^2}{2} - b^2 + 2m_c^2},&lt;/math&gt;

:&lt;math&gt;b = \frac{2}{3} \sqrt{-m_b^2 + 2m_a^2 + 2m_c^2} = \sqrt{2(a^2+c^2)-4m_b^2} = \sqrt{\frac{a^2}{2} - c^2 + 2m_a^2} = \sqrt{\frac{c^2}{2} - a^2 + 2m_c^2},&lt;/math&gt;

:&lt;math&gt;c = \frac{2}{3} \sqrt{-m_c^2 + 2m_b^2 + 2m_a^2} = \sqrt{2(b^2+a^2)-4m_c^2} = \sqrt{\frac{b^2}{2} - a^2 + 2m_b^2} = \sqrt{\frac{a^2}{2} - b^2 + 2m_a^2}.&lt;/math&gt;

==Other properties==

The centroid divides each median into parts in the ratio 2:1, with the centroid being twice as close to the midpoint of a side as it is to the opposite vertex.

For any triangle with sides &lt;math&gt;a, b, c&lt;/math&gt; and medians &lt;math&gt;m_a, m_b, m_c,&lt;/math&gt;&lt;ref name=P&amp;S&gt;Posamentier, Alfred S., and Salkind, Charles T., ''Challenging Problems in Geometry'', Dover, 1996: pp. 86â87.&lt;/ref&gt;  

:&lt;math&gt;\tfrac{3}{4}(a+b+c) &lt; m_a+m_b+m_c &lt; a+b+c&lt;/math&gt;

and

:&lt;math&gt;\tfrac{3}{4}(a^2+b^2+c^2)=m_a^2+m_b^2+m_c^2.&lt;/math&gt;

The medians from sides of lengths ''a'' and ''b'' are [[perpendicular]] if and only if &lt;math&gt;a^2 + b^2 = 5c^2.&lt;/math&gt;&lt;ref&gt;Boskoff, Homentcovschi, and Suceava (2009), ''Mathematical Gazette'', Note 93.15.&lt;/ref&gt;

The medians of a [[right triangle]] with hypotenuse ''c'' satisfy &lt;math&gt;m_a^2+m_b^2=5m_c^2.&lt;/math&gt;

Any triangle's area ''T'' can be expressed in terms of its medians &lt;math&gt;m_a, m_b&lt;/math&gt;, and &lt;math&gt;m_c&lt;/math&gt; as follows. Denoting their semi-sum {{nowrap|(''m&lt;sub&gt;a&lt;/sub&gt;'' + ''m&lt;sub&gt;b&lt;/sub&gt;'' + ''m&lt;sub&gt;c&lt;/sub&gt;'')/2}} as Ï, we have&lt;ref&gt;Benyi, Arpad, "A Heron-type formula for the triangle", ''Mathematical Gazette'' 87, July 2003, 324â326.&lt;/ref&gt;
:&lt;math&gt;T = \frac{4}{3} \sqrt{\sigma (\sigma - m_a)(\sigma - m_b)(\sigma - m_c)}.&lt;/math&gt;

==Tetrahedron==
[[File:Tetrahedron centroid gimp.png|thumb|upright=1.25|{{center|medians of a tetrahedron}}&lt;br/&gt;&lt;math&gt;\begin{align}&amp;\frac{|AS|}{|SS_{BCD}|}=\frac{|BS|}{|SS_{ACD}|}=\frac{|CS|}{|SS_{ABD}|}\\=&amp;\frac{|DS|}{|SS_{BBC}|}=\frac{3}{1} \end{align}&lt;/math&gt;]]
A [[tetrahedron]] is a [[three-dimensional space|three-dimensional]] object having four triangular [[face (geometry)|faces]]. A line segment joining a vertex of a tetrahedron with the [[centroid]] of the opposite face is called a ''median'' of the tetrahedron. There are four medians, and they are all [[Concurrent lines|concurrent]] at the ''centroid'' of the tetrahedron.&lt;ref&gt;Leung, Kam-tim; and Suen, Suk-nam; "Vectors, matrices and geometry", Hong Kong University Press, 1994, pp. 53â54&lt;/ref&gt; As in the two-dimensional case, the centroid of the tetrahedron is the [[center of mass]]. However contrary to the two-dimensional case the centroid divides the medians not in a 2:1 ratio but in a 3:1 ratio ([[Commandino's theorem]]).

==See also==
*[[Angle bisector]]
*[[Altitude (triangle)]]
*[[Automedian triangle]]

==References==

{{reflist}}

==External links==
{{Commons cat|Median (geometry)}}
* [http://www.cut-the-knot.org/triangle/medians.shtml The Medians] at [[cut-the-knot]]
* [http://www.cut-the-knot.org/Curriculum/Geometry/MedianTriangle.shtml Area of Median Triangle] at [[cut-the-knot]]
* [http://www.mathopenref.com/trianglemedians.html Medians of a triangle] With interactive animation
* [http://www.mathopenref.com/constmedian.html Constructing a median of a triangle with compass and straightedge] animated demonstration
* {{MathWorld |title=Triangle Median |urlname=TriangleMedian}}

[[Category:Elementary geometry]]
[[Category:Triangle geometry]]
[[Category:Articles containing proofs]]</text>
      <sha1>nnqv6w5kj520dj3e46d8sag5xmmsjq5</sha1>
    </revision>
  </page>
  <page>
    <title>Michael J. Fischer</title>
    <ns>0</ns>
    <id>23504223</id>
    <revision>
      <id>847192352</id>
      <parentid>829938876</parentid>
      <timestamp>2018-06-23T15:26:43Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* Publications */ cite repair;</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10841">'''Michael John Fischer''' (born 1942) is a [[computer scientist]] who works in the fields of [[distributed computing]], [[parallel computing]], [[cryptography]], [[algorithm]]s and [[data structure]]s, and [[Computational complexity theory|computational complexity]].

==Career==
Fischer was born in 1942 in [[Ann Arbor]], [[Michigan]], USA. He received his [[BSc]] degree in [[mathematics]] from the [[University of Michigan]] in 1963. Fischer did his [[Master of Arts|MA]] and [[PhD]] studies in [[applied mathematics]] at [[Harvard University]]; he received his MA degree in 1965 and PhD in 1968. Fischer's PhD supervisor at Harvard was [[Sheila Greibach]].

After receiving his PhD, Fischer was an assistant professor of computer science at [[Carnegie-Mellon University]] in 1968â1969, an assistant professor of mathematics at [[Massachusetts Institute of Technology]] (MIT) in 1969â1973, and an associate professor of [[electrical engineering]] at MIT in 1973â1975. At MIT he supervised doctoral students who became prominent computer scientists, including [[David S. Johnson]], [[Frances Yao]], and [[Michael Martin Hammer|Michael Hammer]].

In 1975, Fischer was nominated as a professor of [[computer science]] at the [[University of Washington]]. Since 1981, he has been a professor of computer science at [[Yale University]]. Fischer served as the editor-in-chief of the [[Journal of the ACM]] in 1982â1986.&lt;ref&gt;{{cite web
| url=http://portal.acm.org/citation.cfm?id=322358
| title=Journal of the ACM (JACM), Volume 30, Issue 1 (January 1983)
| work=ACM Portal
| accessdate=2009-07-06
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
| url=http://portal.acm.org/citation.cfm?id=5925
| title=Journal of the ACM (JACM), Volume 33, Issue 3 (July 1986)
| work=ACM Portal
| accessdate=2009-07-06
}}&lt;/ref&gt; He was inducted as a Fellow of the [[Association for Computing Machinery]] (ACM) in 1996.&lt;ref&gt;{{cite web
 |url         = http://fellows.acm.org/homepage.cfm?alpha=M&amp;srt=alpha
 |title       = ACM Fellows
 |work        = ACM
 |accessdate  = 2009-07-06
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20090101062504/http://fellows.acm.org/homepage.cfm?alpha=M&amp;srt=alpha
 |archivedate = 2009-01-01
 |df          = 
}}
{{cite web
 |url        = http://fellows.acm.org/fellow_citation.cfm?id=1027952&amp;srt=alpha
 |title      = ACM: Fellows Award / Michael J Fischer
 |work       = ACM
 |accessdate = 2009-07-06
}} "For outstanding technical contributions to theoretical computer science, and for dedicated service to the computer science community."&lt;/ref&gt;

==Work==

===Distributed computing===

Fischer is famous for his contributions in the field of distributed computing. His 1985 work with [[Nancy A. Lynch]] and [[Michael S. Paterson]]&lt;ref&gt;{{harvtxt|Fischer|Lynch|Paterson|1985}}&lt;/ref&gt; on [[consensus (computer science)|consensus problems]] received the [[PODC Influential-Paper Award]] in 2001.&lt;ref name="podc-award"&gt;{{cite web
| url=http://www.podc.org/influential/2001.html
| title=PODC Influential Paper Award: 2001
| accessdate=2009-07-06
}}&lt;/ref&gt; Their work showed that in an asynchronous distributed system, consensus is impossible if there is one processor that crashes. [[Jennifer Welch]] writes that âThis result has had a monumental impact in distributed computing, both theory and practice. Systems designers were motivated to clarify their claims concerning under what circumstances the systems work.â&lt;ref name="podc-award"/&gt;

Fischer was the program chairman of the first [[Symposium on Principles of Distributed Computing]] (PODC) in 1982;&lt;ref&gt;{{cite web
| url=http://www.sigops.org/history.html
| title=A chronological history of SIGOPS
| work=ACM SIGOPS
| accessdate=2009-07-06
}}&lt;/ref&gt; nowadays, PODC is the leading conference in the field. In 2003, the distributed computing community honoured Fischer's 60th birthday by organising a lecture series during the 22nd PODC,&lt;ref&gt;{{cite web
| url=http://www.podc.org/podc2003/
| title=Twenty-Second ACM Symposium on Principles of Distributed Computing (PODC 2003), July 13-16, 2003, Boston, Massachusetts
| accessdate=2009-07-06
}}&lt;/ref&gt; with [[Leslie Lamport]], Nancy Lynch, [[Albert R. Meyer]], and Rebecca Wright as speakers.

===Parallel computing===
In 1980, Fischer and [[Richard E. Ladner]]&lt;ref&gt;{{harvtxt|Ladner|Fischer|1980}}.&lt;/ref&gt; presented a [[parallel algorithm]] for computing [[prefix sum]]s efficiently. They show how to construct a circuit that computes the prefix sums; in the circuit, each node performs an addition of two numbers. With their construction, one can choose a trade-off between the circuit depth and the number of nodes.&lt;ref&gt;{{cite web
| url=http://www.cs.mu.oz.au/498/notes/node25.html
| title=Ladner and Fischer's parallel prefix algorithm
| work=Networks and Parallel Processing Complexity â Notes
| last=Harwood | first=Aaron
| year=2003
| accessdate=2009-07-07
}}.&lt;/ref&gt; However, the same circuit designs were already studied much earlier in [[Soviet Union|Soviet]] mathematics.&lt;ref name="offman"&gt;{{Cite journal|first=Y. P.|last=Offman|title=On the Algorithmic Complexity of Discrete Functions|journal=Dokl. Sov. Acad. Sci.|volume=145|issue=1|year=1962|pages=48â51|language=Russian|ref=harv|postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}}}. English translation in ''Sov. Phys. Dokl.'' '''7''' (7): 589â591 1963.&lt;/ref&gt;&lt;ref name="krapchenko"&gt;{{Cite journal|first=A. N.|last=Krapchenko|title=Asymptotic Estimation of Addition Time of a Parallel Adder|journal=Syst. Theory Res.|volume=19|year=1970|pages=105â122|ref=harv|postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}}}.&lt;/ref&gt;

===Algorithms and computational complexity===
Fischer has done multifaceted work in theoretical computer science in general. Fischer's early work, including his PhD thesis, focused on [[parsing]] and [[formal grammar]]s.&lt;ref name="meyer03"&gt;{{cite web
| url=http://people.csail.mit.edu/meyer/fischer-fest.pdf
| last=Meyer | first=Albert R.
| title=M.J. Fischer, et al., the first decade: mid-60's to 70's
| date=12 July 2003
| accessdate=2009-07-06
}} Slides from PODC 2003.&lt;/ref&gt; One of Fischer's most-cited works deals with [[string matching]].&lt;ref&gt;{{harvtxt|Wagner|Fischer|1974}}.&lt;/ref&gt; Already during his years at Michigan, Fischer studied [[Disjoint-set data structure#Disjoint-set forests|disjoint-set data structures]] together with [[Bernard Galler]].&lt;ref&gt;{{harvtxt|Galler|Fischer|1964}}&lt;/ref&gt;

===Cryptography===
Fischer is one of the pioneers in [[electronic voting]]. In 1985, Fischer and his student Josh Cohen Benaloh&lt;ref&gt;{{harvtxt|Cohen|Fischer|1985}}&lt;/ref&gt; presented one of the first electronic voting schemes.&lt;ref name="wright03"&gt;{{Cite conference
| last=Wright | first=Rebecca N.
| contribution=Fischer's cryptographic protocols
| title=Proc. PODC 2003
| pages=20â22
| year=2003
| doi=10.1145/872035.872039
| ref=harv
| postscript=&lt;!--None--&gt;
}}.&lt;/ref&gt;

Other contributions related to cryptography include the study of [[key exchange]] problems and a protocol for [[oblivious transfer]].&lt;ref name="wright03"/&gt; In 1984, Fischer, [[Silvio Micali]], and [[Charles Rackoff]]&lt;ref&gt;{{harvtxt|Fischer|Micali|Rackoff|1996}}, originally presented in 1984.&lt;/ref&gt; presented an improved version of [[Michael O. Rabin]]'s protocol for oblivious transfer.

==Publications==
* {{Cite journal
| last1=Galler | first1=Bernard A. | authorlink1=Bernard Galler
| last2=Fischer | first2=Michael J.
| title=An improved equivalence algorithm
| journal=[[Communications of the ACM]]
| volume=7
| issue=5
| year=1964
| pages=301â303
| doi=10.1145/364099.364331
| ref=harv
| postscript=&lt;!--None--&gt;
}}.&lt;ref name="meyer03"/&gt;
* {{Cite journal
| last1=Wagner | first1=Robert A.
| last2=Fischer | first2=Michael J.
| title=The string-to-string correction problem
| journal=[[Journal of the ACM]]
| volume=21
| issue=1
| year=1974
| pages=168â173
| doi=10.1145/321796.321811
| ref=harv
| postscript=&lt;!--None--&gt;
}}.&lt;ref&gt;{{cite web
| url=https://scholar.google.com/scholar?cites=1168026360880314540
| title=1592 citations
| work=Google Scholar
| accessdate=2009-07-06
}}&lt;/ref&gt;
* {{Cite journal
| last1=Ladner | first1=Richard E.
| last2=Fischer | first2=Michael J.
| title=Parallel prefix computation
| journal=Journal of the ACM
| volume=27
| issue=4
| year=1980
| pages=831â838
| doi=10.1145/322217.322232
| ref=harv
| postscript=&lt;!--None--&gt;
}}.&lt;ref name="meyer03"/&gt;&lt;ref&gt;{{cite web
| url=https://scholar.google.com/scholar?cites=17348117272132242802
| title=726 citations
| work=Google Scholar
| accessdate=2009-07-07
}}&lt;/ref&gt;
* {{Cite journal
| last1=Fischer | first1=Michael J.
| last2=Lynch | first2=Nancy A. | authorlink2=Nancy A. Lynch
| last3=Paterson | first3=Michael S. | authorlink3=Michael S. Paterson
| title=Impossibility of distributed consensus with one faulty process
| journal=Journal of the ACM
| volume=32
| issue=2
| pages=374â382
| year=1985
| doi=10.1145/3149.214121
| ref=harv
| postscript=&lt;!--None--&gt;
}}.&lt;ref&gt;[[PODC Influential-Paper Award]] in 2001.&lt;/ref&gt;&lt;ref&gt;{{cite web
| url=https://scholar.google.com/scholar?cites=11993555002424078114
| title=2431 citations
| work=Google Scholar
| accessdate=2009-07-06
}}&lt;/ref&gt;
* {{Cite conference
| last1=Cohen | first1=Josh D.
| last2=Fischer | first2=Michael J.
|title=A robust and verifiable cryptographically secure election scheme
|book-title=26th Annual Symposium on Foundations of Computer Science (sfcs 1985)
| year=1985
| pages=372â382
| doi=10.1109/SFCS.1985.2
| ref=harv
}}.&lt;ref name="wright03"/&gt;
* {{Cite journal
| title=A secure protocol for the oblivious transfer (extended abstract)
| last1=Fischer | first1=M. J.
| last2=Micali | first2=S. | authorlink2=Silvio Micali
| last3=Rackoff | first3=C. | authorlink3=Charles Rackoff
| journal=[[Journal of Cryptology]]
| volume=9
| issue=3
| year=1996
| doi=10.1007/BF00208002
| pages=191â195
| ref=harv
| postscript=&lt;!--None--&gt;
}}.&lt;ref name="wright03"/&gt;

==Notes==
{{Reflist|30em}}

==External links==
*{{Official website}}
*{{MathGenealogy |name=Michael John Fischer}}
*{{DBLP |name=Michael J. Fischer}}
*{{ZbMATH |name=Fischer, Michael J.}}
*[http://www.ams.org/mathscinet/MRAuthorID/67165 Fischer, Michael J.] at [[MathSciNet]]

{{Authority control}}

{{DEFAULTSORT:Fischer, Michael J.}}
[[Category:1942 births]]
[[Category:Living people]]
[[Category:Researchers in distributed computing]]
[[Category:Theoretical computer scientists]]
[[Category:University of Michigan alumni]]
[[Category:Harvard University alumni]]
[[Category:Yale University faculty]]
[[Category:Fellows of the Association for Computing Machinery]]
[[Category:People from Ann Arbor, Michigan]]
[[Category:Dijkstra Prize laureates]]</text>
      <sha1>gmf7idg9zs45z312q0qibn9tpl8r3fj</sha1>
    </revision>
  </page>
  <page>
    <title>Monodomain model</title>
    <ns>0</ns>
    <id>37793177</id>
    <revision>
      <id>784111878</id>
      <parentid>697290943</parentid>
      <timestamp>2017-06-06T14:34:17Z</timestamp>
      <contributor>
        <username>Blueclaw</username>
        <id>4338671</id>
      </contributor>
      <comment>added [[Category:Biological theorems]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2431">{{Refimprove|date=April 2014}}
The '''monodomain model''' is a reduction of the [[bidomain model]] of the electrical propagation in myocardial tissue.
The reduction comes from assuming that the intra- and extracellular domains have equal anisotropy ratios.
Although not as physiologically accurate as the [[Bidomain|bidomain model]], it is still adequate in some cases, and has reduced complexity.

==Formulation==
The monodomain model can be formulated as follows&lt;ref name=KeenerSneyd&gt;{{cite book
 | author = Keener J, Sneyd J
 | year = 2009
 | edition = 2nd
 | title =  Mathematical Physiology II: Systems Physiology
 | publisher = Springer
 | isbn = 978-0-387-79387-0
 }}
&lt;/ref&gt;
: &lt;math&gt;
\frac{\lambda}{1+\lambda} \nabla \cdot \left(\mathbf\Sigma_i \nabla v \right) = \chi \left( C_m \frac{\partial v}{\partial t} + I_\text{ion} \right)
,&lt;/math&gt;

where &lt;math&gt;\mathbf\Sigma_i&lt;/math&gt; is the intracellular conductivity tensor, &lt;math&gt;v&lt;/math&gt; is the transmembrane potential, &lt;math&gt;I_\text{ion}&lt;/math&gt; is the transmembrane ionic current per unit area, &lt;math&gt;C_m&lt;/math&gt; is the membrane conductivity per unit area, &lt;math&gt;\lambda&lt;/math&gt; is the intra- to extracellular conductivity ratio, and &lt;math&gt;\chi&lt;/math&gt; is the membrane surface area per unit volume (of tissue).

==Derivation==
The [[Bidomain|bidomain model]] can be written as
: &lt;math&gt;
\begin{align}
\nabla \cdot \left(\mathbf\Sigma_i \nabla v \right) + \nabla \cdot \left(\mathbf\Sigma_i \nabla v_e \right) &amp; = \chi \left( C_m \frac{\partial v}{\partial t} + I_\text{ion} \right) \\
\nabla \cdot \left( \mathbf\Sigma_i \nabla v \right) + \nabla \cdot \left( \left( \mathbf\Sigma_i + \mathbf\Sigma_e \right) \nabla v_e \right) &amp; = 0
\end{align}
&lt;/math&gt;

Assuming equal anisotropy ratios, i.e. &lt;math&gt;\mathbf\Sigma_e = \lambda\mathbf\Sigma_i&lt;/math&gt;, the second equation can be written
: &lt;math&gt;
\nabla \cdot \left(\mathbf\Sigma_i\nabla v_e\right) = -\frac{1}{1+\lambda}\nabla\cdot\left(\mathbf\Sigma_i\nabla v\right) 
.&lt;/math&gt;

Inserting this into the first bidomain equation gives
: &lt;math&gt;
\frac{\lambda}{1+\lambda} \nabla \cdot \left(\mathbf\Sigma_i \nabla v \right) = \chi \left( C_m \frac{\partial v}{\partial t} + I_\text{ion} \right)
.&lt;/math&gt;

==References==
{{reflist}}

[[Category:Cardiac electrophysiology]]
[[Category:Differential equations]]
[[Category:Electrophysiology]]
[[Category:Partial differential equations]]
[[Category:Biological theorems]]
{{Applied-math-stub}}</text>
      <sha1>ko8mi9tj7hr6mmd3fdx7g01238fvpfc</sha1>
    </revision>
  </page>
  <page>
    <title>Mutual information</title>
    <ns>0</ns>
    <id>427282</id>
    <revision>
      <id>869990194</id>
      <parentid>869603207</parentid>
      <timestamp>2018-11-21T18:04:37Z</timestamp>
      <contributor>
        <ip>128.135.96.227</ip>
      </contributor>
      <comment>/* Independence Assumptions */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="41385">[[File:Entropy-mutual-information-relative-entropy-relation-diagram.svg|thumb|256px|right|[[Venn diagram]] showing additive and subtractive relationships various information measures associated with correlated variables X and Y. The area contained by both circles is the [[joint entropy]] &lt;math&gt;H(X,Y)&lt;/math&gt;. The circle on the left (red and violet) is the [[Entropy (information theory)|individual entropy]] &lt;math&gt;H(X)&lt;/math&gt;, with the red being the [[conditional entropy]] &lt;math&gt;H(X|Y)&lt;/math&gt;. The circle on the right (blue and violet) is &lt;math&gt;H(Y)&lt;/math&gt;, with the blue being &lt;math&gt;H(Y|X)&lt;/math&gt;. The violet is the [[mutual information]] &lt;math&gt;I(X;Y)&lt;/math&gt;.]]

In [[probability theory]] and [[information theory]], the '''mutual information''' ('''MI''') of two [[random variable]]s is a measure of the mutual [[Statistical dependence|dependence]] between the two variables. More specifically, it quantifies the "amount of information" (in [[unit of measurement|unit]]s such as [[shannon (unit)|shannon]]s, commonly called bits) obtained about one random variable through observing the other random variable.  The concept of mutual information is intricately linked to that of [[Entropy (information theory)|entropy]] of a random variable, a fundamental notion in information theory that quantifies the expected "[[Information content|amount of information]]" held in a random variable.

Not limited to real-valued random variables like the [[correlation coefficient]], MI is more general and determines how similar the [[joint distribution]] &lt;math&gt;p(x,y)&lt;/math&gt; is to the products of factored marginal distribution &lt;math&gt;p(x) \cdot p(y)&lt;/math&gt;. MI is the [[expected value]] of the [[pointwise mutual information]] (PMI).

== Definition ==
Formally, the mutual information of two discrete random variables &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; can be defined as:&lt;ref name=cover1991&gt;{{cite book|last1=Cover|first1=T.M.|last2=Thomas|first2=J.A.|title=Elements of Information Theory|date=1991|isbn=978-0-471-24195-9|edition=Wiley}}&lt;/ref&gt;{{rp|20}}

:&lt;math&gt; \operatorname{I}(X;Y) = \sum_{y \in \mathcal Y} \sum_{x \in \mathcal X}
    { p(x,y) \log{ \left(\frac{p(x,y)}{p(x)\,p(y)} \right) }},
&lt;/math&gt;

where &lt;math&gt;p(x,y)&lt;/math&gt; is the [[joint distribution|joint probability function]] of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt;, and &lt;math&gt;p(x)&lt;/math&gt; and &lt;math&gt;p(y)&lt;/math&gt; are the [[marginal probability]] distribution functions of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; respectively.

In the case of [[continuous function|continuous random variables]], the summation is replaced by a definite [[double integral]]:&lt;ref name=cover1991 /&gt;{{rp|251}}

:&lt;math&gt; \operatorname{I}(X;Y) = 
\int_{\mathcal Y} \int_{\mathcal X}
    {p(x,y) \log{ \left(\frac{p(x,y)}{p(x)\,p(y)} \right) }
} \; dx \,dy,
&lt;/math&gt;

where &lt;math&gt;p(x,y)&lt;/math&gt; is now the joint probability ''density'' function of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt;, and &lt;math&gt;p(x)&lt;/math&gt; and &lt;math&gt;p(y)&lt;/math&gt; are the marginal probability density functions of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; respectively.

If the [[Logarithm|log base]] 2 is used, the units of mutual information are [[bit|bits]].

== Motivation ==
Intuitively, mutual information measures the information that &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; share: It measures how much knowing one of these variables reduces uncertainty about the other. For example, if &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are independent, then knowing &lt;math&gt;X&lt;/math&gt; does not give any information about &lt;math&gt;Y&lt;/math&gt; and vice versa, so their mutual information is zero.  At the other extreme, if &lt;math&gt;X&lt;/math&gt; is a deterministic function of &lt;math&gt;Y&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; is a deterministic function of &lt;math&gt;X&lt;/math&gt; then all information conveyed by &lt;math&gt;X&lt;/math&gt; is shared with &lt;math&gt;Y&lt;/math&gt;: knowing &lt;math&gt;X&lt;/math&gt; determines the value of &lt;math&gt;Y&lt;/math&gt; and vice versa. As a result, in this case the mutual information is the same as the uncertainty contained in &lt;math&gt;Y&lt;/math&gt; (or &lt;math&gt;X&lt;/math&gt;) alone, namely the [[information entropy|entropy]] of &lt;math&gt;Y&lt;/math&gt; (or &lt;math&gt;X&lt;/math&gt;). Moreover, this mutual information is the same as the entropy of &lt;math&gt;X&lt;/math&gt; and as the entropy of &lt;math&gt;Y&lt;/math&gt;. (A very special case of this is when &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are the same random variable.)

Mutual information is a measure of the inherent dependence expressed in the [[joint distribution]] of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; relative to the joint distribution of &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; under the assumption of independence. Mutual information therefore measures dependence in the following sense: &lt;math&gt;I(X;Y)=0&lt;/math&gt; [[if and only if]] &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are independent random variables.  This is easy to see in one direction: if &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; are independent, then &lt;math&gt;p(x,y)=p(x) \cdot p(y)&lt;/math&gt;, and therefore:

:&lt;math&gt; \log{ \left( \frac{p(x,y)}{p(x)\,p(y)} \right) } = \log 1 = 0 .&lt;/math&gt;

Moreover, mutual information is nonnegative (i.e. &lt;math&gt;\operatorname{I}(X;Y) \ge 0&lt;/math&gt; see below) and [[Symmetric function|symmetric]] (i.e. &lt;math&gt;\operatorname{I}(X;Y) = \operatorname{I}(Y;X)&lt;/math&gt; see below).

== Relation to other quantities ==
=== Nonnegativity ===
Using [[Jensen's inequality]] on the definition of mutual information we can show that &lt;math&gt;I(X;Y)&lt;/math&gt; is non-negative, i.e.&lt;ref name=cover1991 /&gt;{{rp|28}}
:&lt;math&gt;\operatorname{I}(X;Y) \ge 0&lt;/math&gt;

=== Symmetry===
:&lt;math&gt;\operatorname{I}(X;Y) = \operatorname{I}(Y;X)&lt;/math&gt;

=== Relation to conditional and joint entropy ===
Mutual information can be equivalently expressed as

:&lt;math&gt;\begin{align}
  \operatorname{I}(X;Y) &amp;{} \equiv \Eta(X) - \Eta(X|Y) \\
         &amp;{} \equiv \Eta(Y) - \Eta(Y|X) \\
         &amp;{} \equiv \Eta(X) + \Eta(Y) - \Eta(X, Y) \\
         &amp;{} \equiv \Eta(X, Y) - \Eta(X|Y) - \Eta(Y|X)
\end{align}&lt;/math&gt;

where &lt;math&gt;\Eta(X)&lt;/math&gt; and &lt;math&gt;\Eta(Y)&lt;/math&gt; are the marginal [[information entropy|entropies]], Î(''X''|''Y'') and Î(''Y''|''X'') are the [[conditional entropy|conditional entropies]], and Î(''X'',''Y'') is the [[joint entropy]] of ''X'' and ''Y''. Note the analogy to the union, difference, and intersection of two sets, as illustrated in the Venn diagram. In terms of a communication channel in which the output &lt;math&gt;Y&lt;/math&gt; is a noisy version of the input &lt;math&gt;X&lt;/math&gt;, these relations are summarised in the figure below.

[[File:Figchannel2017ab.svg|thumb| The relationships between information theoretic quantities]]
 
Because &lt;math&gt;\operatorname{I}(X;Y)&lt;/math&gt; is non-negative, consequently, &lt;math&gt;\Eta(X) \ge \Eta(X|Y)&lt;/math&gt;. Here we give the detailed deduction of &lt;math&gt;I(X;Y)=H(Y)-H(Y|X)&lt;/math&gt;:

:&lt;math&gt;
\begin{align}
\operatorname{I}(X;Y) &amp; {} = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}\\
&amp; {} = \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)} - \sum_{x,y} p(x,y) \log p(y)  \\

&amp; {} = \sum_{x,y} p(x)p(y|x) \log p(y|x) - \sum_{x,y} p(x,y) \log p(y) \\
&amp; {} = \sum_x p(x) \left(\sum_y p(y|x) \log p(y|x)\right) - \sum_y \left(\sum_x p(x,y)\right) \log p(y) \\
&amp; {} = -\sum_x p(x) \Eta(Y|X=x) - \sum_y p(y) \log p(y) \\
&amp; {} = -\Eta(Y|X) + \Eta(Y)  \\
&amp; {} = \Eta(Y) - \Eta(Y|X).  \\
\end{align}
&lt;/math&gt;
The proofs of the other identities above are similar.

Intuitively, if entropy Î(''Y'') is regarded as a measure of uncertainty about a random variable, then Î(''Y''|''X'') is a measure of what ''X'' does ''not'' say about ''Y''. This is "the amount of uncertainty remaining about ''Y'' after ''X'' is known", and thus the right side of the second of these equalities can be read as "the amount of uncertainty in ''Y'', minus the amount of uncertainty in ''Y'' which remains after ''X'' is known", which is equivalent to "the amount of uncertainty in ''Y'' which is removed by knowing ''X''". This corroborates the intuitive meaning of mutual information as the amount of information (that is, reduction in uncertainty) that knowing either variable provides about the other.

Note that in the discrete case &lt;math&gt;\Eta(X|X) = 0&lt;/math&gt; and therefore &lt;math&gt;\Eta(X) = \operatorname{I}(X;X)&lt;/math&gt;. Thus &lt;math&gt;\operatorname{I}(X; X) \ge \operatorname{I}(X; Y)&lt;/math&gt;, and one can formulate the basic principle that a variable contains at least as much information about itself as any other variable can provide. This parallels a similar result about .

=== Relation to KullbackâLeibler divergence ===
Mutual information can also be expressed as a [[KullbackâLeibler divergence]] of the product of the [[marginal distribution]]s, &lt;math&gt;p(x) \cdot p(y)&lt;/math&gt;, of the two random variables &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt;, from the random variables' [[joint distribution]], &lt;math&gt;p(x,y)&lt;/math&gt;:

:&lt;math&gt; \operatorname{I}(X; Y) 
= D_\text{KL}\left(p(x, y) \parallel p(x)p(y)\right). &lt;/math&gt;

Furthermore, let ''p''(''x''|''y'') = ''p''(''x'', ''y'') / ''p''(''y'').  Then

:&lt;math&gt;\begin{align}
  \operatorname{I}(X;Y) &amp;= \sum_y p(y) \sum_x p(x|y) \log_2 \frac{p(x|y)}{p(x)} \\
    &amp;= \sum_y p(y) \; D_\text{KL}\!\left(p(x|y) \parallel p(x)\right) \\
    &amp;= \mathbb{E}_Y\left[D_\text{KL}\!\left(p(x|y) \parallel p(x)\right)\right].
\end{align}&lt;/math&gt;

Note that here the KullbackâLeibler divergence involves integration with respect to the random variable &lt;math&gt;X&lt;/math&gt; only and the expression &lt;math&gt;D_\text{KL}(p(x|y) \parallel p(x))&lt;/math&gt; is now a random variable in &lt;math&gt;Y&lt;/math&gt;. Thus mutual information can also be understood as the [[expected value|expectation]] of the KullbackâLeibler divergence of the [[univariate distribution]] &lt;math&gt;p(x)&lt;/math&gt; of &lt;math&gt;X&lt;/math&gt; from the [[conditional distribution]] &lt;math&gt;p(x|y)&lt;/math&gt; of &lt;math&gt;X&lt;/math&gt; given &lt;math&gt;Y&lt;/math&gt;: the more different the distributions &lt;math&gt;p(x|y)&lt;/math&gt; and &lt;math&gt;p(x)&lt;/math&gt; are on average, the greater the [[KullbackâLeibler divergence|information gain]].

=== Bayesian estimation of mutual information ===

It is well-understood how to do Bayesian estimation of the mutual information
of a joint distribution based on samples of that distribution. The
first work to do this, which also showed how to do Bayesian estimation of many
other information-theoretic besides mutual information, was &lt;ref&gt;{{cite journal | last1 = Wolpert | first1 = D.H. | last2 = Wolf | first2 = D.R. | year = 1995 | title = Estimating functions of probability distributions from a finite set of samples | journal = Physical Review E }}&lt;/ref&gt;. Subsequent researchers have rederived &lt;ref&gt;{{cite journal | last1 = Hutter | first1 = M. | year = 2001 | title = Distribution of Mutual Information | journal = Advances in Neural Information Processing Systems 2001 }}&lt;/ref&gt;
and extended &lt;ref&gt;{{cite journal | last1 = Archer | first1 = E. | last2 = Park | first2 = I.M. | last3 = Pillow | first3 = J. | year = 2013 | title = Bayesian and Quasi-Bayesian Estimators for Mutual Information from Discrete Data | journal = Entropy}}&lt;/ref&gt;
this analysis. See &lt;ref&gt;{{cite journal | last1 = Wolpert | first1 = D.H | last2 = DeDeo | first2 = S. | year = 2013 | title = Estimating Functions of Distributions Defined over Spaces of Unknown Size | journal = Entropy }}&lt;/ref&gt;
for a recent paper based on a prior specifically tailored to estimation of mutual
information per se.

=== Independence Assumptions ===
The Kullbeck-Leibler divergence formulation of the mutual information is predicated on that one is interested in comparing ''p(x,y)'' to the fully factorized [[outer product]] ''p(x)p(y)''. In many problems, such as [[non-negative matrix factorization]], one is interested in less extreme factorizations; specifically, one wishes to compare ''p(x,y)'' to a low-rank matrix approximation in some unknown variable ''w''; that is, to what degree one might have
:&lt;math&gt;p(x,y)\approx \sum_w p^\prime (x,w) p^{\prime\prime}(w,y)&lt;/math&gt;
Alternately, one might be interested in knowing how much more information ''p(x,y)'' carries over its factorization. In such a case, the excess information that the full distribution ''p(x,y)'' carries over the matrix factorization is given by the Kullbeck-Leibler divergence
:&lt;math&gt;\operatorname{I}_{LRMA} = \sum_{y \in \mathcal{Y}} \sum_{x \in \mathcal{X}}
    {p(x,y) \log{ \left(\frac{p(x,y)}{\sum_w p^\prime (x,w) p^{\prime\prime}(w,y)}
      \right) }},
&lt;/math&gt;
The conventional definition of the mutual information is recovered in the extreme case that the process ''W'' has only one value for ''w''.

== Variations ==
Several variations on mutual information have been proposed to suit various needs.  Among these are normalized variants and generalizations to more than two variables.

=== Metric ===
Many applications require a [[metric (mathematics)|metric]], that is, a distance measure between pairs of points. The quantity

:&lt;math&gt;
\begin{align}
d(X,Y) &amp;= \Eta(X,Y) - \operatorname{I}(X;Y) \\
       &amp;= \Eta(X) + \Eta(Y) - 2I(X;Y) \\
       &amp;= \Eta(X|Y) + \Eta(Y|X)
\end{align}
&lt;/math&gt;

satisfies the properties of a metric ([[triangle inequality]], [[non-negative|non-negativity]], [[identity of indiscernibles|indiscernability]] and symmetry). This distance metric is also known as the [[variation of information]].

If &lt;math&gt;X, Y&lt;/math&gt; are discrete random variables then all the entropy terms are non-negative, so &lt;math&gt;0 \le d(X,Y) \le \Eta(X,Y)&lt;/math&gt; and one can define a normalized distance

:&lt;math&gt;D(X,Y) = \frac{d(X, Y)}{\Eta(X, Y)} \le 1.&lt;/math&gt;

The metric ''D'' is a universal metric, in that if any other distance measure places ''X'' and ''Y'' close-by, then the ''D'' will also judge them close.&lt;ref&gt;{{cite arXiv|eprint=q-bio/0311039|last1=Kraskov|first1=Alexander|title=Hierarchical Clustering Based on Mutual Information|last2=StÃ¶gbauer|first2=Harald|last3= Andrzejak|first3=Ralph G.|last4=Grassberger|first4=Peter|year=2003}}&lt;/ref&gt;{{dubious|see talk page|date=November 2014}}

Plugging in the definitions shows that

:&lt;math&gt;D(X,Y) = 1 - \frac{I(X; Y)}{\Eta(X, Y)}.&lt;/math&gt;

In a set-theoretic interpretation of information (see the figure for [[Conditional entropy]]), this is effectively the [[Jaccard index|Jaccard distance]] between ''X'' and ''Y''.

Finally,

:&lt;math&gt;D^\prime(X, Y) = 1 - \frac{\operatorname{I}(X; Y)}{\max\left\{\Eta(X), \Eta(Y)\right\}}&lt;/math&gt;

is also a metric.

=== Conditional mutual information ===
{{Main|Conditional mutual information}}
Sometimes it is useful to express the mutual information of two random variables conditioned on a third.
:&lt;math&gt;
\begin{align}
&amp; {} \operatorname{I}(X;Y|Z) = \mathbb {E}_Z \big(\operatorname{I}(X;Y)|Z\big)
    = \\
&amp; {} \sum_{z\in Z} \sum_{y\in Y} \sum_{x\in X}
    {p_Z(z)\, p_{X,Y|Z}(x,y|z) 
        \log\left[\frac{p_{X,Y|Z}(x,y|z)}{p_{X|Z}\,(x|z)p_{Y|Z}(y|z)}\right]},
\end{align}
&lt;/math&gt;

which can be simplified as
:&lt;math&gt;
\begin{align}
&amp; {} I(X;Y|Z) = \\
&amp; {} \sum_{z\in Z} \sum_{y\in Y} \sum_{x\in X}
      p_{X,Y,Z}(x,y,z) \log \frac{p_{X,Y,Z}(x,y,z)p_{Z}(z)}{p_{X,Z}(x,z)p_{Y,Z}(y,z)}.
\end{align}
&lt;/math&gt;
Conditioning on a third random variable may either increase or decrease the mutual information, but it is always true that
:&lt;math&gt;\operatorname{I}(X;Y|Z) \ge 0&lt;/math&gt;
for discrete, jointly distributed random variables ''X'', ''Y'', ''Z''.  This result has been used as a basic building block for proving other [[inequalities in information theory]].

=== Multivariate mutual information ===
{{Main|Multivariate mutual information}}
Several generalizations of mutual information to more than two random variables have been proposed, such as [[total correlation]] and [[interaction information]].  If Shannon entropy is viewed as a [[signed measure]] in the context of [[information diagram]]s, as explained in the article ''[[Information theory and measure theory]]'', then the only definition of multivariate mutual information that makes sense{{Citation needed|date=January 2009}} is as follows:
:&lt;math&gt;\operatorname{I}(X_1;X_1) = \Eta(X_1)&lt;/math&gt;

and for &lt;math&gt;n &gt; 1,&lt;/math&gt;
:&lt;math&gt;\operatorname{I}(X_1;\,...\,;X_n)
 = \operatorname{I}(X_1;\,...\,;X_{n-1}) 
    - \operatorname{I}(X_1;\,...\,;X_{n-1}|X_n),&lt;/math&gt;

where (as above) we define
:&lt;math&gt;\operatorname{I}(X_1;\,...\,;X_{n-1}|X_n) 
 = \mathbb{E}_{X_n} \bigl[\operatorname{I}(X_1;\,...\,;X_{n-1})|X_n\bigr].&lt;/math&gt;

(This definition of multivariate mutual information is identical to that of [[interaction information]] except for a change in sign when the number of random variables is odd.)

==== Applications ====
Applying information diagrams blindly to derive the above definition{{Citation needed|date=July 2009}} has been criticised{{who|date=January 2016}}, and indeed it has found rather limited practical application since it is difficult to visualize or grasp the significance of this quantity for a large number of random variables.  It can be zero, positive, or negative for any odd number of variables &lt;math&gt;n \ge 3.&lt;/math&gt;

One high-dimensional generalization scheme which maximizes the mutual information between the joint distribution and other target variables is found to be useful in [[feature selection]].&lt;ref&gt;{{cite book
  |author1=Christopher D. Manning |author2=Prabhakar Raghavan |author3=Hinrich SchÃ¼tze | title = An Introduction to Information Retrieval
  | publisher = [[Cambridge University Press]]
  | year = 2008
  | isbn = 0-521-86571-9 }}&lt;/ref&gt;

Mutual information is also used in the area of signal processing as a [[Similarity measure|measure of similarity]] between two signals. For example, FMI metric&lt;ref&gt;{{cite journal | last1 = Haghighat | first1 = M. B. A. | last2 = Aghagolzadeh | first2 = A. | last3 = Seyedarabi | first3 = H. | year = 2011 | title = A non-reference image fusion metric based on mutual information of image features | doi = 10.1016/j.compeleceng.2011.07.012 | journal = Computers &amp; Electrical Engineering | volume = 37 | issue = 5| pages = 744â756 }}&lt;/ref&gt; is an image fusion performance measure that makes use of mutual information in order to measure the amount of information that the fused image contains about the source images. The [[Matlab]] code for this metric can be found at.&lt;ref&gt;{{cite web|url=http://www.mathworks.com/matlabcentral/fileexchange/45926-feature-mutual-information-fmi-image-fusion-metric|title=Feature Mutual Information (FMI) metric for non-reference image fusion - File Exchange - MATLAB Central|author=|date=|website=www.mathworks.com|accessdate=4 April 2018}}&lt;/ref&gt;

=== Directed information ===
[[Directed information]], &lt;math&gt;\operatorname{I}\left(X^n \to Y^n\right)&lt;/math&gt;,  measures the amount of information that flows from the process  &lt;math&gt;X^n&lt;/math&gt; to &lt;math&gt;Y^n&lt;/math&gt;, where &lt;math&gt;X^n&lt;/math&gt; denotes the vector &lt;math&gt;X_1, X_2, ..., X_n&lt;/math&gt; and &lt;math&gt;Y^n&lt;/math&gt; denotes &lt;math&gt;Y_1, Y_2, ..., Y_n&lt;/math&gt;. The term ''directed information'' was coined by [[James Massey]] and is defined as
:&lt;math&gt;\operatorname{I}\left(X^n \to Y^n\right)
= \sum_{i=1}^n \operatorname{I}\left(X^i; Y_i|Y^{i-1}\right)&lt;/math&gt;.

Note that if ''n'' = 1, the directed information becomes the mutual information. Directed information has many applications in problems where causality plays an important role, such as capacity of channel with feedback.&lt;ref&gt;{{cite journal|last1=Massey|first1=James|title=Causality, Feedback And Directed Informatio|date=1990|issue=ISITA|url=http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.5688&amp;rep=rep1&amp;type=pdf}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Permuter|first1=Haim Henry|last2=Weissman|first2=Tsachy|last3=Goldsmith|first3=Andrea J.|title=Finite State Channels With Time-Invariant Deterministic Feedback|journal=IEEE Transactions on Information Theory|date=February 2009|volume=55|issue=2|pages=644â662|doi=10.1109/TIT.2008.2009849|arxiv=cs/0608070}}&lt;/ref&gt;

=== Normalized variants ===
Normalized variants of the mutual information are provided by the ''coefficients of constraint'',{{sfn|Coombs|Dawes|Tversky|1970}} [[uncertainty coefficient]]&lt;ref name=pressflannery&gt;{{Cite book | last1=Press | first1=WH | last2=Teukolsky | first2=SA | last3=Vetterling | first3=WT | last4=Flannery | first4=BP | year=2007 | title=Numerical Recipes: The Art of Scientific Computing | edition=3rd | publisher=Cambridge University Press |  publication-place=New York | isbn=978-0-521-88068-8 | chapter=Section 14.7.3. Conditional Entropy and Mutual Information | chapter-url=http://apps.nrbook.com/empanel/index.html#pg=758 | ref=harv | postscript=&lt;!-- Bot inserted parameter. Either remove it; or change its value to "." for the cite to end in a ".", as necessary. --&gt;{{inconsistent citations}}}}&lt;/ref&gt; or proficiency:&lt;ref name=JimWhite&gt;{{Cite journal
 | last1= White |first1= Jim | last2= Steingold | first2=Sam | last3= Fournelle | first3=Connie
 | title = Performance Metrics for Group-Detection Algorithms
 | conference = Interface 2004
 | url = http://www.interfacesymposia.org/I04/I2004Proceedings/WhiteJim/WhiteJim.paper.pdf
}}&lt;/ref&gt;
:&lt;math&gt;
C_{XY} = \frac{\operatorname{I}(X;Y)}{\Eta(Y)}
~~~~\mbox{and}~~~~ 
C_{YX} = \frac{\operatorname{I}(X;Y)}{\Eta(X)}.
&lt;/math&gt;

The two coefficients are not necessarily equal. In some cases a symmetric measure may be desired, such as the following ''[[Redundancy (information theory)|redundancy]]''{{Citation needed|date=July 2008}} measure:
:&lt;math&gt;R = \frac{\operatorname{I}(X;Y)}{\Eta(X) + \Eta(Y)}&lt;/math&gt;

which attains a minimum of zero when the variables are independent and a maximum value of
:&lt;math&gt;R_\max = \frac{\min\left\{\Eta(X), \Eta(Y)\right\}}{\Eta(X) + \Eta(Y)}&lt;/math&gt;

when one variable becomes completely redundant with the knowledge of the other.  See also ''[[Redundancy (information theory)]]''. Another symmetrical measure is the ''symmetric uncertainty'' {{harv|Witten|Frank|2005}}, given by
:&lt;math&gt;U(X, Y) = 2R = 2\frac{\operatorname{I}(X;Y)}{\Eta(X) + \Eta(Y)}&lt;/math&gt;

which represents the [[harmonic mean]] of the two uncertainty coefficients &lt;math&gt;C_{XY}, C_{YX}&lt;/math&gt;.&lt;ref name=pressflannery /&gt;

If we consider mutual information as a special case of the [[total correlation]] or [[dual total correlation]], the normalized version are respectively,
:&lt;math&gt;\frac{\operatorname{I}(X;Y)}{\min\left[ \Eta(X),\Eta(Y)\right]}&lt;/math&gt; and &lt;math&gt;\frac{\operatorname{I}(X;Y)}{\Eta(X,Y)} \; .&lt;/math&gt;

This normalized version also known as '''Information Quality Ratio (IQR)''' which quantifies the amount of information of a variable based on another variable against total uncertainty:&lt;ref name=DRWijaya&gt;{{Cite journal
 | last1= Wijaya |first1= Dedy Rahman | last2= Sarno| first2=Riyanarto| last3= Zulaika | first3=Enny
 | title = Information Quality Ratio as a novel metric for mother wavelet selection
 | journal = Chemometrics and Intelligent Laboratory Systems
 | volume = 160
 | pages = 59â71
 | url = http://www.sciencedirect.com/science/article/pii/S0169743916304907
 | doi = 10.1016/j.chemolab.2016.11.012
}}&lt;/ref&gt;
:&lt;math&gt;IQR(X, Y) = \operatorname{E}[\operatorname{I}(X;Y)] 
= \frac{\operatorname{I}(X;Y)}{\Eta(X, Y)} 
= \frac{\sum_{x \in X} \sum_{y \in Y} p(x, y) \log {p(x)p(y)}}{\sum_{x \in X} \sum_{y \in Y} p(x, y) \log {p(x, y)}} - 1&lt;/math&gt;

There's a normalization&lt;ref name="strehl-jmlr02"&gt;{{Citation
 | title = Cluster Ensembles â A Knowledge Reuse Framework for Combining Multiple Partitions
 | journal = The Journal of Machine Learning Research
 | pages = 583â617 | volume = 3 | issue = Dec | year = 2002
 | last1 = Strehl | first1 = Alexander | last2 = Ghosh | first2 = Joydeep
 | url=http://www.jmlr.org/papers/volume3/strehl02a/strehl02a.pdf}}&lt;/ref&gt; which derives from first thinking of mutual information as an analogue to [[covariance]] (thus [[Entropy (information theory)|Shannon entropy]] is analogous to [[variance]]).  Then the normalized mutual information is calculated akin to the [[Pearson product-moment correlation coefficient|Pearson correlation coefficient]],

:&lt;math&gt;
\frac{\operatorname{I}(X;Y)}{\sqrt{\Eta(X)\Eta(Y)}}\; .
&lt;/math&gt;

=== Weighted variants ===
In the traditional formulation of the mutual information,

:&lt;math&gt; \operatorname{I}(X;Y) 
 = \sum_{y \in Y} \sum_{x \in X} p(x, y) \log \frac{p(x, y)}{p(x)\,p(y)}, &lt;/math&gt;

each ''event'' or ''object''  specified by &lt;math&gt;(x, y)&lt;/math&gt; is weighted by the corresponding  probability &lt;math&gt;p(x, y)&lt;/math&gt;.  This assumes that all objects or events are equivalent ''apart from'' their probability of occurrence.  However, in some applications it may be the case that certain objects or events are more ''significant'' than others, or that certain patterns of association are more semantically important than others.

For example, the deterministic mapping &lt;math&gt;\{(1,1),(2,2),(3,3)\}&lt;/math&gt; may be viewed as stronger than the deterministic mapping &lt;math&gt;\{(1,3),(2,1),(3,2)\}&lt;/math&gt;, although these relationships would yield the same mutual information.  This is because the mutual information is not sensitive at all to any inherent ordering in the variable values ({{harvnb|Cronbach|1954}}, {{harvnb|Coombs|Dawes|Tversky|1970}}, {{harvnb|Lockhead|1970}}), and is therefore not sensitive at all to the '''form''' of the relational mapping between the associated variables.  If it is desired that the former relationâshowing agreement on all variable valuesâbe judged stronger than the later relation, then it is possible to use the following ''weighted mutual information'' {{harv|Guiasu|1977}}.
:&lt;math&gt; \operatorname{I}(X;Y) 
= \sum_{y \in Y} \sum_{x \in X} w(x,y) p(x,y) \log \frac{p(x,y)}{p(x)\,p(y)}, &lt;/math&gt;

which places a weight &lt;math&gt;w(x,y)&lt;/math&gt; on the probability of each variable value co-occurrence, &lt;math&gt;p(x,y)&lt;/math&gt;. This allows that certain probabilities may carry more or less significance than others, thereby allowing the quantification of relevant ''holistic'' or ''[[PrÃ¤gnanz]]'' factors.  In the above example, using larger relative weights for &lt;math&gt;w(1,1)&lt;/math&gt;, &lt;math&gt;w(2,2)&lt;/math&gt;, and &lt;math&gt;w(3,3)&lt;/math&gt; would have the effect of assessing greater ''informativeness'' for the relation  &lt;math&gt;\{(1,1),(2,2),(3,3)\}&lt;/math&gt; than for the relation &lt;math&gt;\{(1,3),(2,1),(3,2)\}&lt;/math&gt;, which may be desirable in some cases of pattern recognition, and the like.  This weighted mutual information is a form of weighted KL-Divergence, which is known to take negative values for some inputs,&lt;ref name="weighted-kl"&gt;{{cite journal | last1 = KvÃ¥lseth | first1 = T. O. | year = 1991 | title = The relative useful information measure: some comments | url = | journal = Information sciences | volume = 56 | issue = 1| pages = 35â38 | doi=10.1016/0020-0255(91)90022-m}}&lt;/ref&gt; and there are examples where the weighted mutual information also takes negative values.&lt;ref&gt;{{cite dissertation
  |title=Feature Selection Via Joint Likelihood
  |first=A. |last=Pocock
  |year=2012
  |url=http://www.cs.man.ac.uk/~gbrown/publications/pocockPhDthesis.pdf
}}&lt;/ref&gt;

=== Adjusted mutual information ===
{{Main|adjusted mutual information}}

A probability distribution can be viewed as a [[partition of a set]].  One may then ask: if a set were partitioned randomly, what would the distribution of probabilities be?  What would the expectation value of the mutual information be? The [[adjusted mutual information]] or AMI subtracts the expectation value of the MI, so that the AMI is zero when two different distributions are random, and one when two distributions are identical.  The AMI is defined in analogy to the [[adjusted Rand index]] of two different partitions of a set.

=== Absolute mutual information ===&lt;!-- This section is linked from [[Kolmogorov complexity]] --&gt;
Using the ideas of [[Kolmogorov complexity]], one can consider the mutual information of two sequences independent of any probability distribution:

:&lt;math&gt;
\operatorname{I}_K(X;Y) = K(X) - K(X|Y).
&lt;/math&gt;

To establish that this quantity is symmetric up to a logarithmic factor (&lt;math&gt;\operatorname{I}_K(X;Y) \approx \operatorname{I}_K(Y;X)&lt;/math&gt;) requires the [[chain rule for Kolmogorov complexity]] {{Harvard citation|Li|VitÃ¡nyi|1997}}. Approximations of this quantity via [[Data compression|compression]] can be used to define a [[Metric (mathematics)|distance measure]] to perform a [[hierarchical clustering]] of sequences without having any [[domain knowledge]] of the sequences {{Harvard citation|Cilibrasi|VitÃ¡nyi|2005}}.

=== Linear correlation ===

Unlike correlation coefficients, such as the [[product moment correlation coefficient]], mutual information contains information about all dependenceâlinear and nonlinearâand not just linear dependence as the correlation coefficient measures. However, in the narrow case that the joint distribution for ''X'' and ''Y'' is a [[bivariate normal distribution]] (implying in particular that both marginal distributions are normally distributed), there is an exact relationship between ''I'' and the correlation coefficient &lt;math&gt;\rho&lt;/math&gt; {{harv|Gel'fand|Yaglom|1957}}.
:&lt;math&gt;\operatorname{I} = -\frac{1}{2} \log\left(1 - \rho^2\right)&lt;/math&gt;

The equation above can be derived as follows for a bivariate Gaussian:
:&lt;math&gt;\begin{align}
  \begin{pmatrix}
    X_1 \\
    X_2
  \end{pmatrix}  &amp;\sim \mathcal{N} \left( \begin{pmatrix}
    \mu_1 \\
    \mu_2
  \end{pmatrix}, \Sigma \right),\qquad
  \Sigma = \begin{pmatrix}
    \sigma^2_1           &amp; \rho\sigma_1\sigma_2 \\
    \rho\sigma_1\sigma_2 &amp; \sigma^2_2
  \end{pmatrix} \\
       \Eta(X_i) &amp;= \frac{1}{2}\log\left(2\pi e \sigma_i^2\right) = \frac{1}{2} + \frac{1}{2}\log(2\pi) + \log\left(\sigma_i\right), \quad i\in\{1, 2\} \\
  \Eta(X_1, X_2) &amp;= \frac{1}{2}\log\left[(2\pi e)^2|\Sigma|\right] = 1 + \log(2\pi) + \log\left(\sigma_1 \sigma_2\right) + \frac{1}{2}\log\left(1 - \rho^2\right) \\
\end{align}&lt;/math&gt;

Therefore, 
:&lt;math&gt; 
  \operatorname{I}\left(X_1; X_2\right) 
= \Eta\left(X_1\right) + \Eta\left(X_2\right) - \Eta\left(X_1, X_2\right) 
= -\frac{1}{2}\log\left(1 - \rho^2\right)
&lt;/math&gt;

=== For discrete data ===

When ''X'' and ''Y''  are limited to be in a discrete number of states, observation data is summarized in a [[contingency table]], with row variable ''X'' (or ''i'') and column variable ''Y'' (or ''j'').  Mutual information is one of the measures of [[association (statistics)|association]] or [[correlation and dependence|correlation]] between the row and column variables.  Other measures of association include [[Pearson's chi-squared test]] statistics, [[G-test]] statistics, etc. In fact, mutual information is equal to [[G-test]] statistics divided by 2''N'', where ''N'' is the sample size.

== Applications ==
In many applications, one wants to maximize mutual information (thus increasing dependencies), which is often equivalent to minimizing [[conditional entropy]].  Examples include:
* In [[search engine technology]], mutual information between phrases and contexts is used as a feature for [[k-means clustering]] to discover semantic clusters (concepts).&lt;ref name=magerman&gt;[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.78.4178&amp;rep=rep1&amp;type=pdf Parsing a Natural Language Using Mutual Information Statistics] by David M. Magerman and Mitchell P. Marcus&lt;/ref&gt;
* In [[telecommunications]], the [[channel capacity]] is equal to the mutual information, maximized over all input distributions.
* [[Discriminative model|Discriminative training]] procedures for [[hidden Markov model]]s have been proposed based on the [[maximum mutual information]] (MMI) criterion.
* [[Nucleic acid secondary structure|RNA secondary structure]] prediction from a [[multiple sequence alignment]].
* [[Phylogenetic profiling]] prediction from pairwise present and disappearance of functionally link [[gene]]s.
* Mutual information has been used as a criterion for [[feature selection]] and feature transformations in [[machine learning]]. It can be used to characterize both the relevance and redundancy of variables, such as the [[minimum redundancy feature selection]].
* Mutual information is used in determining the similarity of two different [[cluster analysis|clusterings]] of a dataset.  As such, it provides some advantages over the traditional [[Rand index]].
* Mutual information of words is often used as a significance function for the computation of [[collocation]]s in [[corpus linguistics]]. This has the added complexity that no word-instance is an instance to two different words; rather, one counts instances where 2 words occur adjacent or in close proximity; this slightly complicates the calculation, since the expected probability of one word occurring within ''N'' words of another, goes up with ''N''.
* Mutual information is used in [[medical imaging]] for [[image registration]]. Given a reference image (for example, a brain scan), and a second image which needs to be put into the same [[coordinate system]] as the reference image, this image is deformed until the mutual information between it and the reference image is maximized.
* Detection of [[phase synchronization]] in [[time series]] analysis
* In the [[infomax]] method for neural-net and other machine learning, including the infomax-based [[Independent component analysis]] algorithm
* Average mutual information in [[delay embedding theorem]] is used for determining the ''embedding delay'' parameter.
* Mutual information between [[genes]] in [[microarray|expression microarray]] data is used by the [[ARACNE]] algorithm for reconstruction of [[gene regulatory network|gene networks]].
* In [[statistical mechanics]], [[Loschmidt's paradox]] may be expressed in terms of mutual information.&lt;ref name=everett56&gt;[[Hugh Everett]] [https://www.pbs.org/wgbh/nova/manyworlds/pdf/dissertation.pdf Theory of the Universal Wavefunction], Thesis, Princeton University, (1956, 1973), pp 1â140 (page 30)&lt;/ref&gt;&lt;ref name=everett57&gt;{{cite journal | last1 = Everett | first1 = Hugh | authorlink = Hugh Everett | year = 1957 | title = Relative State Formulation of Quantum Mechanics | url = http://www.univer.omsk.su/omsk/Sci/Everett/paper1957.html | journal = Reviews of Modern Physics | volume = 29 | issue = | pages = 454â462 | doi=10.1103/revmodphys.29.454| bibcode = 1957RvMP...29..454E }}&lt;/ref&gt; Loschmidt noted that it must be impossible to determine a physical law which lacks [[time reversal symmetry]] (e.g. the [[second law of thermodynamics]]) only from physical laws which have this symmetry. He pointed out that the [[H-theorem]] of [[Boltzmann]] made the assumption that the velocities of particles in a gas  were permanently uncorrelated, which removed the time symmetry inherent in the H-theorem. It can be shown that if a system is described by a probability density in [[phase space]], then [[Liouville's theorem (Hamiltonian)|Liouville's theorem]] implies that the joint information (negative of the joint entropy) of the distribution remains constant in time. The joint information is equal to the mutual information plus the sum of all the marginal information (negative of the marginal entropies) for each particle coordinate. Boltzmann's assumption amounts to ignoring the mutual information in the calculation of entropy, which yields the thermodynamic entropy (divided by Boltzmann's constant).
* The mutual information is used to learn the structure of [[Bayesian network]]s/[[dynamic Bayesian network]]s, which is thought to explain the causal relationship between random variables, as exemplified by the GlobalMIT toolkit [http://code.google.com/p/globalmit/]: learning the globally optimal dynamic Bayesian network with the Mutual Information Test criterion.
* Popular cost function in [[decision tree learning]].
* The mutual information is used in Cosmology to test the influence of large-scale environments on galaxy properties in the [[Galaxy Zoo]].
* The mutual information was used in [[Solar Physics]]  to derive the solar differential profile, a travel-time deviation map for sunspots, and a timeâdistance diagram from quiet-Sun measurements&lt;ref&gt;{{cite journal|last1=Keys|first1=Dustin|last2=Kholikov|first2=Shukur|last3=Pevtsov|first3=Alexei A.|title=Application of Mutual Information Methods in Time Distance Helioseismology|journal=Solar Physics|date=February 2015|volume=290|issue=3|pages=659â671|doi=10.1007/s11207-015-0650-y|arxiv=1501.05597|bibcode=2015SoPh..290..659K}}&lt;/ref&gt;

== See also ==
* [[Pointwise mutual information]]
* [[Quantum mutual information]]

== Notes ==
&lt;references /&gt;

== References ==
* {{cite journal
  | last1 = Cilibrasi
  | first1 = R.
  | first2 = Paul
  | last2 = VitÃ¡nyi
  | title = Clustering by compression
  | journal = IEEE Transactions on Information Theory
  | volume = 51
  | issue = 4
  | pages = 1523â1545
  | year = 2005
  | url = http://www.cwi.nl/~paulv/papers/cluster.pdf
  | format = [[PDF]]
  | doi = 10.1109/TIT.2005.844059
  | ref = harv
}}
* {{Cite book|last1=Cronbach|first1=L. J.|year=1954|chapter=On the non-rational application of information measures in psychology|editor1-first=Henry|editor1-last=Quastler|editor1-link=Henry Quastler|title=Information Theory in Psychology: Problems and Methods|publisher=Free Press|place=Glencoe, Illinois|pages=14â30|ref=harv}}
* {{cite book|last1=Coombs|first1=C. H.|last2=Dawes|first2=R. M.|last3=Tversky|first3=A.|year=1970|title=Mathematical Psychology: An Elementary Introduction|publisher=Prentice-Hall|location=Englewood Cliffs, New Jersey|ref=harv}}
* {{cite journal|first1=Kenneth Ward|last1=Church|first2=Patrick|last2=Hanks|title=Word association norms, mutual information, and lexicography|journal=Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics|year=1989|url=http://dl.acm.org/citation.cfm?id=89095}}
* {{cite journal|first1=I.M.|last1=Gel'fand|first2=A.M.|last2=Yaglom|year=1957|title=Calculation of amount of information about a random function contained in another such function|journal= American Mathematical Society Translations: Series 2 |volume = 12 | pages = 199â246 |ref=harv}} English translation of original in ''Uspekhi Matematicheskikh Nauk'' '''12'''&amp;nbsp;(1):&amp;nbsp;3-52.
* {{cite book|last=Guiasu|first=Silviu|year=1977|title=Information Theory with Applications|publisher=McGraw-Hill, New York|isbn=978-0-07-025109-0|ref=harv}}
* {{cite book
  | last1 = Li
  | first1 = Ming
  | first2 = Paul
  | last2 = VitÃ¡nyi
  | title = An introduction to Kolmogorov complexity and its applications
  | location = New York
  | publisher = [[Springer-Verlag]]
  |date=February 1997
  | isbn = 0-387-94868-6
  | ref=harv }}
* {{cite journal | last1 = Lockhead | first1 = G. R. | year = 1970 | title = Identification and the form of multidimensional discrimination space | url = | journal = Journal of Experimental Psychology | volume = 85 | issue = 1| pages = 1â10 | doi=10.1037/h0029508| pmid = 5458322 | ref = harv}}
* David J. C. MacKay. ''[http://www.inference.phy.cam.ac.uk/mackay/itila/book.html Information Theory, Inference, and Learning Algorithms]'' Cambridge: Cambridge University Press, 2003. {{isbn|0-521-64298-1}} (available free online)
* {{cite journal | last1 = Haghighat | first1 = M. B. A. | last2 = Aghagolzadeh | first2 = A. | last3 = Seyedarabi | first3 = H. | year = 2011 | title = A non-reference image fusion metric based on mutual information of image features | url = | journal = Computers &amp; Electrical Engineering | volume = 37 | issue = 5| pages = 744â756 | doi=10.1016/j.compeleceng.2011.07.012}}
* [[Athanasios Papoulis]]. ''Probability, Random Variables, and Stochastic Processes'', second edition. New York: McGraw-Hill, 1984. ''(See Chapter 15.)''
* {{cite book|last1=Witten|first1=Ian H.|last2=Frank|first2=Eibe |lastauthoramp=yes |year=2005|title=Data Mining: Practical Machine Learning Tools and Techniques|publisher=Morgan Kaufmann, Amsterdam|isbn=978-0-12-374856-0|url=http://www.cs.waikato.ac.nz/~ml/weka/book.html|ref=harv}}
* {{cite journal|author=Peng, H.C., Long, F., and Ding, C.|title=Feature selection based on mutual information: criteria of max-dependency, max-relevance, and min-redundancy|journal=IEEE Transactions on Pattern Analysis and Machine Intelligence|volume=27|issue=8|pages=1226â1238|year=2005|url=http://research.janelia.org/peng/proj/mRMR/index.htm|doi=10.1109/tpami.2005.159|pmid=16119262}}
* {{cite journal|author1=Andre S. Ribeiro |author2=Stuart A. Kauffman |author3=Jason Lloyd-Price |author4=Bjorn Samuelsson |author5=Joshua Socolar  |last-author-amp=yes |year=2008|title=Mutual Information in Random Boolean models of regulatory networks|journal=Physical Review E|volume=77|issue=1|arxiv=0707.3642|doi=10.1103/physreve.77.011901 |bibcode=2008PhRvE..77a1901R}}
* {{cite journal
  | last1 = Wells
  | first1 = W.M. III
  | last2 = Viola
  | first2 = P.
  | last3 = Atsumi
  | first3 = H.
  | last4 = Nakajima
  | first4 = S.
  | last5 = Kikinis
  | first5 = R.
  | title = Multi-modal volume registration by maximization of mutual information
  | journal = Medical Image Analysis
  | volume = 1
  | issue = 1
  | pages = 35â51
  | year = 1996
  | pmid = 9873920
  | doi = 10.1016/S1361-8415(01)80004-9
  | url = http://www.ai.mit.edu/people/sw/papers/mia.pdf
  | format = [[PDF]]
  | ref = harv
}}
* {{cite journal | last1 = Pandey | first1 = Biswajit | last2 = Sarkar | first2 = Suman | year = 2017 | title = How much a galaxy knows about its large-scale environment?: An information theoretic perspective | url = | journal = Monthly Notices of the Royal Astronomical Society Letters| volume = 467 | issue = | page = L6 | doi=10.1093/mnrasl/slw250| arxiv = 1611.00283| bibcode = 2017MNRAS.467L...6P}}
[[Category:Information theory]]
[[Category:Entropy and information]]</text>
      <sha1>2rwmil7t94ja1mbr98qv7ykvac8iu5o</sha1>
    </revision>
  </page>
  <page>
    <title>Nicolaas Govert de Bruijn</title>
    <ns>0</ns>
    <id>3166399</id>
    <revision>
      <id>867430615</id>
      <parentid>867424541</parentid>
      <timestamp>2018-11-05T17:45:10Z</timestamp>
      <contributor>
        <username>Yahya Abdal-Aziz</username>
        <id>313039</id>
      </contributor>
      <comment>/* Work */ - clarify the two De BruijnâErdÅs theorems</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6570">{{Infobox scientist
| name              = Nicolaas Govert de Bruijn
| image             = Nicolaas_de_Bruijn.jpg&lt;!--(filename only)--&gt;
| image_size        =  
| caption           = 
| birth_date        = {{Birth date|1918|07|09|df=y}}
| birth_place       = [[The Hague]]
| death_date        = {{death date and age|2012|02|17|1918|07|09|df=yes}}
| death_place       = [[Nuenen]]
| nationality       = [[Netherlands|Dutch]]
| fields            = [[Mathematics]]
| workplaces        = [[Eindhoven University of Technology]]
| alma_mater        = [[Vrije Universiteit]] Amsterdam
| doctoral_advisor  = [[Jurjen Ferdinand Koksma]]
| doctoral_students = [[Johannes Runnenburg]]&lt;br /&gt;[[Stan Ackermans]]
| known_for         = [[De Bruijn sequence]]&lt;br/&gt;[[De Bruijn index]]&lt;br/&gt;[[Automath]]
| awards            = 
}}
'''Nicolaas Govert''' ('''Dick''') '''de Bruijn''' ({{IPA-nl|nikoËËlaËs ËxoËvÉrt dÉ ËbrÅyn|lang}};&lt;ref&gt;In isolation, ''Govert'' is pronounced {{IPA-nl|ËÉ£oËvÉrt|}}.&lt;/ref&gt; 9 July 1918 &amp;ndash; 17 February 2012) was a Dutch [[mathematician]], noted for his many contributions in the fields of [[mathematical analysis|analysis]], [[number theory]], [[combinatorics]] and [[logic]].&lt;ref name="UVA 2012"&gt;[http://www.science.uva.nl/math/NewsandEvents/Archives/index.php?year=2012#item1329781416 Nicolaas Govert de Bruijn's obituary] {{webarchive|url=https://web.archive.org/web/20130425103134/http://www.science.uva.nl/math/NewsandEvents/Archives/index.php?year=2012 |date=2013-04-25 }} 2012&lt;/ref&gt;

== Biography ==
Born in [[The Hague]], De Bruijn received his MA in Mathematics at the [[Leiden University]] in 1941. He received his PhD in 1943 from [[Vrije Universiteit Amsterdam]] with a thesis entitled "Over modulaire vormen van meer veranderlijken" advised by [[Jurjen Ferdinand Koksma]].&lt;ref name="MG"&gt;{{MathGenealogy|id=49968}}&lt;/ref&gt;

De Bruijn started his academic career at the [[University of Amsterdam]], where he was Professor of Mathematics from 1952 to 1960. In 1960 he moved to the [[Technical University Eindhoven]] where he was Professor of Mathematics until his retirement in 1984.&lt;ref name="UVA 2012"/&gt; Among his graduate students were [[Johannes Runnenburg]] (1960), [[Antonius Levelt]] (1961), S. Ackermans (1964), Jozef Beenakker (1966), W. van der Meiden (1967), [[Matheus Hautus]] (1970), Robert Nederpelt Lazarom (1973), Lambert van Benthem Jutting (1977), A. Janssen (1979), Diederik van Daalen (1980), and Harmannus Balsters (1986).&lt;ref name="MG"/&gt;

In 1957 he was appointed member of the [[Royal Netherlands Academy of Arts and Sciences]].&lt;ref&gt;{{cite web|author= |url=http://www.dwc.knaw.nl/biografie/pmknaw/?pagetype=authorDetail&amp;aId=PE00005777 |title=Nicolaas Govert de Bruijn (1918 - 2012) |language=Dutch |publisher=Royal Netherlands Academy of Arts and Sciences |date= |accessdate=17 July 2015}}&lt;/ref&gt; He was Knighted with the [[Order of the Netherlands Lion]].

== Work ==


De Bruijn covered many areas of mathematics. He is especially noted for:
* the discovery of the [[De Bruijn sequence]], 
* discovering an algebraic theory of the [[Penrose tiling]] and, more generally, discovering the "projection" and "multigrid" methods for constructing quasi-periodic tilings,&lt;ref&gt;{{cite journal|url = http://www.sciencedirect.com/science/article/pii/1385725881900160 | doi=10.1016/1385-7258(81)90016-0 | volume=84 | title=Algebraic theory of Penrose's non-periodic tilings of the plane. I | year=1981 | journal=Indagationes Mathematicae (Proceedings) | pages=39â52 | last1 = de Bruijn | first1 = N.G.}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|url = http://www.sciencedirect.com/science/article/pii/1385725881900172 | doi=10.1016/1385-7258(81)90017-2 | volume=84 | title=Algebraic theory of Penrose's non-periodic tilings of the plane. II | year=1981 | journal=Indagationes Mathematicae (Proceedings) | pages=53â66 | last1 = de Bruijn | first1 = N.G.}}&lt;/ref&gt;
* the [[De BruijnâNewman constant]],
* the ''De BruijnâErdÅs theorem'', in [[De BruijnâErdÅs theorem (graph theory)|graph theory]],
* a different theorem of the same name: the ''De BruijnâErdÅs theorem'', in [[De BruijnâErdÅs theorem (incidence geometry)|incidence geometry]],
* the [[BEST theorem]] in graph theory, and 
* [[De Bruijn index|De Bruijn indices]].

He wrote one of the standard books in advanced [[asymptotic analysis]] (De Bruijn, 1958).

In the late sixties, he designed the [[Automath]] language for representing mathematical proofs, so that they could be verified automatically (see [[automated theorem checking]]). Shortly before his death, he had been working on models for the [[human brain]].

== Publications ==
Books, a selection:
* 1943. ''Over modulaire vormen van meer veranderlijken''
* 1958. ''Asymptotic Methods in Analysis,'' North-Holland, Amsterdam.

Articles, a selection:
* de Bruijn, Nicolaas Govert. "A combinatorial problem", 1946.  In Proceedings of the Section of Sciences, Vol. 49, No. 7, pp.&amp;nbsp;758â764. Koninklijke Nederlandse Akademie v. Wetenschappen.
* de Bruijn, Nicolaas Govert. "[http://alexandria.tue.nl/repository/freearticles/597618.pdf The mathematical language AUTOMATH, its usage, and some of its extensions]." Symposium on automatic demonstration. Springer Berlin Heidelberg, 1970.
* de Bruijn, Nicolaas Govert. "[http://www.sciencedirect.com/science/article/pii/1385725872900340 Lambda calculus notation with nameless dummies, a tool for automatic formula manipulation, with application to the Church-Rosser theorem]." Indagationes Mathematicae (Proceedings). Vol. 75. No. 5. North-Holland, 1972.

==See also==
*[[Moserâde Bruijn sequence]]

== References ==
{{reflist}}

== External links ==
{{commons category|Nicolaas Govert de Bruijn (mathematician)}}
* [https://web.archive.org/web/20130425103134/http://www.science.uva.nl/math/NewsandEvents/Archives/index.php?year=2012#item1329781416 Nicolaas Govert de Bruijn's obituary]
* [http://www.win.tue.nl/lotgevallen/em/KleineTUEEncyclopedie19562006_NGdeBruijn.pdf Bruijn N.G. de] at win.tue.nl (in Dutch)

{{Authority control}}

{{DEFAULTSORT:Bruijn, Nicolaas Govert de}}
[[Category:1918 births]]
[[Category:2012 deaths]]
[[Category:20th-century Dutch mathematicians]]
[[Category:Graph theorists]]
[[Category:Leiden University alumni]]
[[Category:Vrije Universiteit Amsterdam alumni]]
[[Category:University of Amsterdam faculty]]
[[Category:Eindhoven University of Technology faculty]]
[[Category:People from The Hague]]
[[Category:Knights of the Order of the Netherlands Lion]]
[[Category:Members of the Royal Netherlands Academy of Arts and Sciences]]</text>
      <sha1>87yj58cxr0w6xokar63yz84ghbgwmla</sha1>
    </revision>
  </page>
  <page>
    <title>Octahedral pyramid</title>
    <ns>0</ns>
    <id>41727746</id>
    <revision>
      <id>771102940</id>
      <parentid>753289342</parentid>
      <timestamp>2017-03-19T15:28:38Z</timestamp>
      <contributor>
        <username>Joancharmant</username>
        <id>11986877</id>
      </contributor>
      <minor/>
      <comment>Added missing word in intro sentence.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5277">{| class="wikitable" align="right" style="margin-left:10px" width="250"
|-
!bgcolor=#e7dcc3 colspan=3|Octahedral pyramid
|-
|align=center colspan=3|[[Image:Octahedral pyramid.png|220px]]&lt;BR&gt;[[Schlegel diagram]]
|-
|bgcolor=#e7dcc3|Type
|colspan=2|[[Polyhedral pyramid]]
|-
|bgcolor=#e7dcc3|[[SchlÃ¤fli symbol]]
|colspan=2|( ) â¨ {3,4}&lt;BR&gt;( ) â¨ r{3,3}&lt;BR&gt;( ) â¨ s{2,6}&lt;BR&gt;( ) â¨ [{4} + { }]&lt;BR&gt;( ) â¨ [{ } + { } + { }]
|-
|bgcolor=#e7dcc3|Cells
|9
|1 [[octahedron|{3,4}]] [[Image:octahedron.png|30px]]&lt;BR&gt;8 [[tetrahedron|( ) â¨ {3}]] [[Image:Tetrahedron.png|30px]]
|-
|bgcolor=#e7dcc3|Faces
|colspan=2|20 [[triangle|{3}]]
|-
|bgcolor=#e7dcc3|Edges
|colspan=2|18
|-
|bgcolor=#e7dcc3|Vertices
|colspan=2|7
|-
|bgcolor=#e7dcc3|Dual
|colspan=2|[[Cubic pyramid]]
|-
|bgcolor=#e7dcc3|[[Coxeter group|Symmetry group]]
|colspan=2|B&lt;sub&gt;3&lt;/sub&gt;, [4,3,1], order 48&lt;BR&gt;[3,3,1], order 24&lt;BR&gt;[2&lt;sup&gt;+&lt;/sup&gt;,6,1], order 12&lt;BR&gt;[4,2,1], order 16&lt;BR&gt;[2,2,1], order 8
|-
|bgcolor=#e7dcc3|Properties
|colspan=2|[[Convex polytope|convex]], regular-faced
|}
In 4-dimensional [[geometry]], the '''octahedral pyramid''' is bounded by one [[octahedron]] on the base and 8 [[triangular pyramid]] [[cell (mathematics)|cells]] which meet at the apex. Since an octahedron has a circumradius divided by edge length less than one,&lt;ref&gt;{{KlitzingPolytopes|polyhedra.htm|3D convex uniform polyhedra|x3o4o - oct}} 1/sqrt(2) = 0.707107&lt;/ref&gt; the triangular pyramids can be made with regular faces (as regular [[tetrahedron]]s) by computing the appropriate height.

== Occurrences of the octahedral pyramid==
The regular [[16-cell]] has ''octahedral pyramids'' around every vertex, with the [[octahedron]] passing through the center of the 16-cell.

The octahedral pyramid is the [[vertex figure]] for a [[truncated 5-orthoplex]], {{CDD|node_1|3|node_1|3|node|3|node|4|node}}.
:[[File:Truncated pentacross.png|160px]]

The graph of the octahedral pyramid is the only possible minimal counterexample to [[Negami's conjecture]], that the connected graphs with [[planar cover]]s are themselves projective-planar.&lt;ref&gt;{{citation
 | last = HlinÄnÃ½ | first = Petr
 | doi = 10.1007/s00373-010-0934-9
 | issue = 4
 | journal = [[Graphs and Combinatorics]]
 | mr = 2669457
 | pages = 525â536
 | title = 20 years of Negami's planar cover conjecture
 | url = http://www.fi.muni.cz/~hlineny/papers/plcover20-gc.pdf
 | volume = 26
 | year = 2010}}&lt;/ref&gt;

== Other polytopes ==

The dual to the octahedral pyramid is a [[cubic pyramid]], seen as an cubic base, and 6 [[square pyramid]]s meeting at an [[apex (geometry)|apex]].
:[[File:Cubic pyramid.png|160px]]

{{-}}
=== Square-pyramidal pyramid ===
{| class="wikitable" align="right" style="margin-left:10px" width="330"
|-
!bgcolor=#e7dcc3 colspan=3|Square-pyramidal pyramid
|-
|align=center colspan=3|[[File:Square pyramid pyramid.png|150px]][[File:Square pyramid pyramid edgecenter.png|150px]]&lt;BR&gt;[[Schlegel diagram]]s
|-
|bgcolor=#e7dcc3|Type
|colspan=2|[[Polyhedral pyramid]]
|-
|bgcolor=#e7dcc3|[[SchlÃ¤fli symbol]]
|colspan=2|( ) â¨ [( ) â¨ {4}]&lt;BR&gt;[( )â¨( )] â¨ {4} = { } â¨ {4}&lt;BR&gt;{ } â¨ [{ } Ã { }]&lt;BR&gt;{ } â¨ [{ } + { }]
|-
|bgcolor=#e7dcc3|Cells
|6
|2 [[square pyramid|{ } â¨ {4}]] [[Image:square pyramid.png|30px]]&lt;BR&gt;4 [[tetrahedron|{ } â¨ {3}]] [[Image:Tetrahedron.png|30px]]
|-
|bgcolor=#e7dcc3|Faces
|colspan=2|12 [[triangle|{3}]]&lt;BR&gt;1 [[square|{4}]]
|-
|bgcolor=#e7dcc3|Edges
|colspan=2|13
|-
|bgcolor=#e7dcc3|Vertices
|colspan=2|6
|-
|bgcolor=#e7dcc3|Dual
|colspan=2|Self-dual
|-
|bgcolor=#e7dcc3|[[Coxeter group|Symmetry group]]
|colspan=2|[4,1,1], order 8&lt;BR&gt;[4,2,1], order 16&lt;BR&gt;[2,2,1], order 8
|-
|bgcolor=#e7dcc3|Properties
|colspan=2|[[Convex polytope|convex]], regular-faced
|}
The '''square-pyramidal pyramid''', ( ) â¨ [( ) â¨ {4}], is a bisected octahedral pyramid. It has a [[square pyramid]] base, and 4 [[tetrahedron]]s along with another one more square pyramid meeting at the apex. It can also be seen in an edge-centered projection as a [[square bipyramid]] with four tetrahedra wrapped around the common edge. If the height of the two apexes are the same, it can be given a higher symmetry name [( ) â¨ ( )] â¨ {4} = { } â¨ {4}, joining an edge to a perpendicular square.&lt;ref&gt; {{KlitzingPolytopes|..//incmats/squasc.htm|Segmentotope|squasc, K-4.4}}&lt;/ref&gt;

The ''square-pyramidal pyramid'' can be distorted into a ''rectangular-pyramidal pyramid'', { } â¨ [{ } Ã { }] or a ''rhombic-pyramidal pyramid'', { } â¨ [{ } + { }], or other lower symmetry forms.

The ''square-pyramidal pyramid'' exists as a vertex figure in uniform polytopes of the form {{CDD|node|p|node_1|q|node_1|r|node|4|node}}, including the [[bitruncated 5-orthoplex]] and [[bitruncated tesseractic honeycomb]].
:[[File:Bitruncated pentacross verf.png|120px]][[File:Bitruncated tesseractic honeycomb verf.png|120px]]

== References==
{{reflist}}

==External links==
*{{GlossaryForHyperspace |anchor=Pyramid |title=Pyramid}}
* {{KlitzingPolytopes|../explain/segmentochora.htm|4D|Segmentotopes}} 
** {{KlitzingPolytopes|..//incmats/octpy.htm|Segmentotope|octpy, K-4.3}}
* Richard Klitzing, [http://bendwavy.org/klitzing/pdf/edge-facetings_color.pdf Axial-Symmetrical Edge Facetings of Uniform Polyhedra]

[[Category:Polychora]]

{{geometry-stub}}</text>
      <sha1>0owbpwkysokhqwrspyg9tgkcu0d3k48</sha1>
    </revision>
  </page>
  <page>
    <title>OlimpÃ­ada de MatemÃ¡tica do Grande ABC</title>
    <ns>0</ns>
    <id>51088824</id>
    <revision>
      <id>862256887</id>
      <parentid>817548893</parentid>
      <timestamp>2018-10-03T05:31:55Z</timestamp>
      <contributor>
        <username>Graeme Bartlett</username>
        <id>38427</id>
      </contributor>
      <minor/>
      <comment>[[WP:AWB/T|Typo fixing]], replaced: researchs â researches, [[WP:AWB/T|typo(s) fixed]]: Subsequently â Subsequently,</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="22279">The '''OlimpÃ­ada de MatemÃ¡tica do Grande ABC''' (English:''Grande ABC Mathematical Olympiad''), or '''OMABC''' is a mathematical competition for pre-[[college|collegiate]] Brazilian students of [[Grande ABC]] region, composed by the following cities:&lt;ref name="ApresentaÃ§Ã£o da OlimpÃ­ada"&gt;{{cite web |url=https://portal.metodista.br/omabc/2015/apresentacao/apresentacao | title=ApresentaÃ§Ã£o da OMABC - Universidade Metodista de SÃ£o Paulo |publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt; 
&lt;ref&gt;[http://www.obm.org.br/opencms/competicoes/regionais/ COMPETIÃÃES REGIONAIS], acesso em 09 de junho de 2014&lt;/ref&gt; 
:&lt;ref&gt;[http://portal.metodista.br/ev/omabc/ Metodista: Eventos], acesso em 05 de dezembro de 2015&lt;/ref&gt;

* [[File:BandeiraSantoAndre.svg|border|20px]] [[Santo AndrÃ© (SÃ£o Paulo)|Santo AndrÃ©]]
* [[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] [[SÃ£o Caetano do Sul]] 
* [[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] [[SÃ£o Bernardo do Campo]]
* [[File:Bandeira_de_Diadema-SP,_Brasil.png|border|20px]] [[Diadema, SÃ£o Paulo|Diadema]]
* [[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|20px]] [[MauÃ¡]]
* [[File:Bandeira-ribeiraopires.jpg|border|20px]] [[RibeirÃ£o Pires]]
* [[File:Bandeira-riograndedaserra.png|border|20px]] [[Rio Grande da Serra]]

The Faculdade de CiÃªncias Exatas e TecnolÃ³gicas da [[Universidade Metodista de SÃ£o Paulo]] is the main organizator of this event, who create the tests and correct then. The main purpose of this olympiad is improve the mathematical knowledge, encouraging the study and research in [[science|scientific areas]].,&lt;ref&gt;{{cite web |url=http://noticias.universia.com.br/tempo-livre/noticia/2005/07/22/469878/alunos-do-abc-podem-participar-da-2-olimpiada-matematica-da-regio.html | title=Alunos do ABC podem participar da 2Â¦ OlimpÃ­ada de MatemÃ¡tica da regiÃ£o |publisher=Site Universia |access-date=5 December 2015}}&lt;/ref&gt; and contributing to participate in national mathematical competitions, like [[OlimpÃ­ada Brasileira de MatemÃ¡tica das Escolas PÃºblicas]] and [[OlimpÃ­ada Brasileira de MatemÃ¡tica]]. The first edition was held in 2004.

== Awards ==

=== Students ===

The participants are ranked based on their individual scores. Medals are awarded to the highest ranked participants, such that slightly less than half of them receive a medal. Subsequently, the cutoffs (minimum scores required to receive a gold, silver or bronze medal respectively) are chosen such that the ratio of gold to silver to bronze medals awarded approximates 1 : 2 : 3.&lt;ref name="ColÃ©gio NÃ³bilis"&gt;{{cite web |url=http://www.colegionobilis.com.br/omabc-agatha/ | title=Agatha Von Randow, medalhista na XII OMABC |publisher=ColÃ©gio Nobilis |access-date=5 December 2015}}&lt;/ref&gt;

* [[File:Gold medal.svg|20px]] '''[[Gold medal]]'''
* [[File:Silver medal.svg|20px]] '''[[Silver medal]]'''
* [[File:Bronze medal.svg|20px]] '''[[Bronze medal]]'''

=== Schools ===

Special prizes are awarded for the schools:&lt;ref name="PrÃªmios"&gt;{{cite web |url=https://portal.metodista.br/omabc/2015/premios | title=PrÃªmios da OMABC - Universidade Metodista de SÃ£o Paulo |publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;

* [[File:Trophy.jpg|30px]] '''[[Trophy]]''': For the schools whose students received at least a  golden medal.
*  '''[[Honorable Mention]]''': For the schools at least one student received an award.

== Champions of OMABC ==
&lt;ref&gt;{{Cite book|last=Bezerra|first=DÃ©bora de Jesus |author2=MÃ³dolo, Marcelo |author3=Pucetti, Silvana |author4=ThomÃ¡z, Valter EspÃ­ndola |title=Problemas e soluÃ§Ãµes: 10 anos de OlimpÃ­ada de MatemÃ¡tica do Grande ABC|publisher=Universidade Metodista de SÃ£o Paulo|language=pt|year=2013|isbn=978-85-7814-266-7|location=SÃ£o Bernardo do Campo|edition=1 |notasediÃ§Ã£o=}}&lt;/ref&gt;
&lt;ref name="OlimpÃ­ada de MatemÃ¡tica 2015 premia 57 jovens no Grande ABC"&gt;{{cite web |url=https://portal.metodista.br/matematica/noticias/olimpiada-de-matematica-2015-premia-46-jovens-no-grande-abc| title=OlimpÃ­ada de MatemÃ¡tica 2015 premia 57 jovens no Grande ABC |publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;  
&lt;ref name="Premiados 2004"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2004/premiados | title=Premiados 2004|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2005"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2005/premiados | title=Premiados 2005|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2006"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2006/premiados | title=Premiados 2006|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2007"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2007/premiados | title=Premiados 2007|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2008"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2008/premiados | title=Premiados 2008|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2009"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2009/premiados | title=Premiados 2009|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2012"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2011/premiados | title=Premiados 2012|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2014"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2014/premiados | title=Premiados 2014|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2015"&gt;{{cite web |url=http://portal.metodista.br/omabc/edicoes-anteriores/2015/premiados | title=Premiados 2015|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=5 December 2015}}&lt;/ref&gt;
&lt;ref name="Premiados 2016"&gt;{{cite web |url=http://portal.metodista.br/omabc/2016/resultado/resultado | title=Premiados 2016|publisher=[[Universidade Metodista de SÃ£o Paulo]] |access-date=16 December 2016}}&lt;/ref&gt;

{| class="toccolours" border="1" cellpadding="2" style="border-collapse: collapse; text-align: center; width: 100%; margin: 0 auto;"
|- style="background: #C1D8FF;"
!rowspan="2" width="1%"|Edition
!rowspan="2" width="1%"|Year
!colspan="4" !rowspan="2" |Champion
|- style="background: #C1D8FF;"
!width="19%"|Level 1
!width="19%"|Level 2
!width="19%"|Level 3
!width="19%"|Level 4

|-
| '''1'''
|'''2004'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2004|Details]]''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Paula Baranauskas Dutra Silva'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Gustavo Martella Achkar'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''NatÃ¡lia Mitiko Aono''' 
|
|- style="background: #C1D8FF;"
| '''2'''
|'''2005'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2005|Details]]''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''Thiago Tobal Furtado'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Gabriel Moreira Francisco'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Alexandre Soares Cavalcante''' 
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Sara Amaral Taira'''
|-
| '''3'''
|'''2006'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2006|Details]]''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Danilo Seixas de Souza'''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''CauÃª Felipe Brighenti Pan'''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''Abel Medina LourenÃ§o''' 
|[[File:Bandeira_da_cidade_de_S%C3%A3o_Paulo.svg|border|40px]] &lt;br /&gt;  '''Leandro de Araujo Carvalho'''
|- style="background: #C1D8FF;"
| '''4'''
|'''2007'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2007|Details]]''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Ana Beatrice Bonganha Zanon'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Guilherme da Rocha Dahrug'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Tayran MilÃ¡ Mendes OlegÃ¡rio''' 
|[[File:Bandeira_da_cidade_de_S%C3%A3o_Paulo.svg|border|40px]] &lt;br /&gt;  '''Abel Medina LourenÃ§o'''
|-
| '''5'''
|'''2008'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2008|Details]]''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Bruno Soiti Kamimura Marino'''
|[[File:Bandeira_de_Diadema-SP,_Brasil.png|border|40px]] &lt;br /&gt;  '''AndrÃ© Amaral de Sousa'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Guilherme da Rocha Dahrug'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''AndrÃ© Daher de Moura'''
|- style="background: #C1D8FF;"
| '''6'''
|'''2009'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2009|Details]]''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''JoÃ£o Ãlvaro Nogueira Nunes'''
|[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|45px]] &lt;br /&gt;  '''Bruna Favoretto'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Guilherme da Rocha Dahrug'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''JoÃ£o Fernando Doriguello Diniz'''
|- 
| '''7'''
|'''2010'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2010|Details]]''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''Amanda Tamkevicius Fernandes'''
|[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|45px]] &lt;br /&gt;  '''Nicolas Seoane Miquelin'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Danilo Moreira SimÃµes'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Guilherme da Rocha Dahrug'''
|- style="background: #C1D8FF;"
| '''8'''
|'''2011'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2011|Details]]''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''HÃ©lcio Prado de Lima'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Gabriella de Souza Costa'''
|[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|45px]] &lt;br /&gt;  '''Nicolas Seoane Miquelin'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Rafael Ferreira Antonioli'''
|- 
| '''9'''
|'''2012'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2012|Details]]''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''HÃ©lcio Prado de Lima'''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''[[Douglas de Araujo Smigly]]'''
|[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|45px]] &lt;br /&gt;  '''Nicolas Seoane Miquelin'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Ana Beatrice Bonganha Zanon'''
|- style="background: #C1D8FF;"
| '''10'''
|'''2013'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2013|Details]]''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''Leonardo FabrÃ­cio Gerlach'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Beatriz Marques de Brito'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Lucas VinÃ­cius Terani'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Gustavo Hideki Yamada'''
|-
| '''11'''
|'''2014'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2014|Details]]''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''VitÃ³ria Torres Nunes'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''JÃºlio CÃ©sar TibÃ©rio de AraÃºjo'''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''Douglas de Araujo Smigly'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Iago Martinelli Lopes'''
|- style="background: #C1D8FF;"
| '''12'''
|'''2015'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2015|Details]]''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Beatriz Maciel Ballarin'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Thiago Mendes Pinheiro'''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Gabriel MagalhÃ£es Cervi'''
|[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|40px]] &lt;br /&gt;  '''Douglas de Araujo Smigly'''  
|- 
| '''13'''
|'''2016'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2016|Details]]''
|[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|45px]] &lt;br /&gt;  '''Pedro Pinheiro Mezadre'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Alessandro da Cunha Menegon'''
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Jonathan Pereira Maria'''  
|[[File:BandeiraSantoAndre.svg|border|40px]] &lt;br /&gt;  '''Julian Drumov GonÃ§alves Simioni'''
|- style="background: #C1D8FF;"
| '''14'''
|'''2017'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2017|Details]]''
|
|  
|  
|
|}

=== Schools awarded with trophies ===

&lt;ref&gt;{{Cite book|last=Bezerra|first=DÃ©bora de Jesus |author2=MÃ³dolo, Marcelo |author3=Pucetti, Silvana |author4=ThomÃ¡z, Valter EspÃ­ndola |title=Problemas e soluÃ§Ãµes: 10 anos de OlimpÃ­ada de MatemÃ¡tica do Grande ABC|publisher=Universidade Metodista de SÃ£o Paulo|language=pt|year=2013|isbn=978-85-7814-266-7|location=SÃ£o Bernardo do Campo|edition=1 |notasediÃ§Ã£o=}}&lt;/ref&gt;

{| class="toccolours" border="1" cellpadding="2" style="border-collapse: collapse; text-align: center; width: 75%; margin: 0 auto;"
|- style="background: #C1D8FF;"
!width="1%"|Edition
!width="1%"|Year
|'''Schools awarded with trophies'''

|-
| '''1'''
|'''2004'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2004|Details]]''
|align="left"|{{col-begin}}
{{col-2}}
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Ãbaco'''&lt;br /&gt;[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Gradual''' &lt;br /&gt;[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Eduardo Gomes''' &lt;br /&gt;
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;ref&gt;{{cite web|url=http://www.agenciach.com.br/wp-content/uploads/2013/08/CNEF-Estadios-de-Futebol-no-Brasil-2013.pdf|title=Unidade Jardim - Nova marca|publisher=liceujardim.com.br|language=pt |access-date=}}&lt;/ref&gt;&lt;ref group="nota"&gt;The ColÃ©gio Unidade Jardim changes his name to ColÃ©gio Liceu Jardim in 2015.&lt;/ref&gt; &lt;br /&gt;[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''EE Wallace Cockrane Simonsen'''&lt;br /&gt;[[File:BandeiraSantoAndre.svg|border|20px]] '''EducandÃ¡rio Santo AntÃ´nio'''
|}
|- style="background: #C1D8FF;"
| '''2'''
|'''2005'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2005|Details]]''
|align="left"|{{col-begin}}
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''EducandÃ¡rio Santo AntÃ´nio'''&lt;br /&gt;[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Harmonia'''&lt;br /&gt;[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Ãbaco'''&lt;br /&gt;[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Eduardo Gomes''' &lt;br /&gt;[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;
{{col-2}}
[[File:Bandeira_de_Diadema-SP,_Brasil.png|border|20px]] '''ColÃ©gio BrasÃ­lia''' &lt;br /&gt;[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Metodista''' &lt;br /&gt;[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Termomecanica''' &lt;br /&gt;[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''Centro Educacional Objetivo''' &lt;ref&gt;{{cite web|url=http://www.objetivo-abc.com.br/index.php/cursos/ensino-medio|title=ColÃ©gio Objetivo ABC - unidades|publisher=ColÃ©gio Objetivo ABC|language=pt|access-date=}}&lt;/ref&gt;&lt;ref group="nota"&gt;O Centro Educacional Objetivo possui vÃ¡rias unidades na regiÃ£o do Grande ABC.&lt;/ref&gt;
|}
|-
| '''3'''
|'''2006'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2006|Details]]''
|align="left"|{{col-begin}}
{{col-2}}
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Harmonia'''&lt;br /&gt;[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|20px]] '''Centro Educacional Objetivo'''&lt;br /&gt; [[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Arbos'''&lt;br /&gt;
{{col-2}}
[[File:Bandeira_de_Diadema-SP,_Brasil.png|border|20px]] '''ColÃ©gio BrasÃ­lia''' &lt;br /&gt;[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ETE Jorge Street'''&lt;br /&gt;[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''Centro Educacional Objetivo'''
|}
|- style="background: #C1D8FF;"
| '''4'''
|'''2007'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2007|Details]]''
|align="left"|{{col-begin}}
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;[[File:BandeiraSantoAndre.svg|border|20px]] '''Centro Educacional InteraÃ§Ã£o'''&lt;br /&gt;
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''Centro Educacional Objetivo'''&lt;br /&gt;[[File:Bandeira_da_cidade_de_S%C3%A3o_Paulo.svg|border|20px]] '''ColÃ©gio Etapa'''
|}
|-
| '''5'''
|'''2008'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2008|Details]]''
|align="left"|{{col-begin}}
{{col-2}}
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''Centro Educacional Objetivo'''&lt;br /&gt;[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''Externato Santo AntÃ´nio'''&lt;br /&gt;[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|20px]] '''ColÃ©gio BarÃ£o de MauÃ¡'''&lt;br /&gt;
{{col-2}}
[[File:Bandeira_de_Diadema-SP,_Brasil.png|border|20px]] '''EE Augusto de Oliveira JordÃ£o''' &lt;br /&gt;[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim''' 
|}
|- style="background: #C1D8FF;"
| '''6'''
|'''2009'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2009|Details]]''
|align="left"| 
{{col-begin}}
{{col-2}}
[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|20px]] '''ColÃ©gio BarÃ£o de MauÃ¡'''&lt;br /&gt;
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim''' 
|}
|- 
| '''7'''
|'''2010'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2010|Details]]''
|align="left"| 
{{col-begin}}
{{col-2}}
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''Centro Educacional Objetivo'''&lt;br /&gt;
[[File:Bandeira_Maua_SaoPaulo_Brasil.svg|border|20px]] '''ColÃ©gio BarÃ£o de MauÃ¡'''&lt;br /&gt;
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Eduardo Gomes''' &lt;br /&gt;
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio PetrÃ³polis'''&lt;br /&gt;
[[File:BandeiraSantoAndre.svg|border|20px]] '''ETE JÃºlio de Mesquita''' 
|}
|- style="background: #C1D8FF;"
| '''8'''
|'''2011'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2011|Details]]''
|align="left"| 
{{col-begin}}
{{col-2}}
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Eduardo Gomes''' &lt;br /&gt;
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Singular'''&lt;br /&gt; 
|}
|- 
| '''9'''
|'''2012'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2012|Details]]''
|align="left"| 
{{col-begin}}
{{col-2}}
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''EMEF Leandro Klein''' &lt;br /&gt;
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Eduardo Gomes''' &lt;br /&gt;
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;
{{col-2}}
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Singular'''&lt;br /&gt; 
[[File:BandeiraSantoAndre.svg|border|20px]] '''EMEF CecÃ­lia Meireles'''&lt;br /&gt; 
|}
|- style="background: #C1D8FF;"
| '''10'''
|'''2013'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2013|Details]]''
|align="left"| 
{{col-begin}}
{{col-2}}
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''EMEF Professor Rosalvito Cobra''' &lt;br /&gt;
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Eduardo Gomes''' &lt;br /&gt;
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Metodista'''&lt;br /&gt;
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;
{{col-2}}
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Ãbaco'''&lt;br /&gt;
[[File:BandeiraSantoAndre.svg|border|20px]] '''Externato Santo AntÃ´nio'''&lt;br /&gt; 
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''Centro Educacional Objetivo - Unidade Frei Gaspar'''&lt;br /&gt;
|}
|- 
| '''11'''
|'''2014'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2014|Details]]''
|align="left"| 
{{col-begin}}
{{col-2}}
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''EMEF Professor Rosalvito Cobra''' &lt;br /&gt;
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;
{{col-2}}
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Termomecanica'''&lt;br /&gt;
|}
|- style="background: #C1D8FF;"
| '''12'''
|'''2015'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2015|Details]]''
|align="left"| 
{{col-begin}}
{{col-2}}
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio Termomecanica'''&lt;br /&gt;
[[File:BandeiraSantoAndre.svg|border|20px]] '''ColÃ©gio Liceu Jardim'''&lt;br /&gt;
{{col-2}}
[[File:Bandeira de SÃ£o Caetano do Sul.svg|border|20px]] '''ColÃ©gio Eduardo Gomes''' &lt;br /&gt;
[[File:Bandeira_de_S%C3%A3o_Bernardo_do_Campo.jpg|border|20px]] '''ColÃ©gio PetrÃ³polis'''&lt;br /&gt;
|}
|- 
| '''13'''
|'''2016'''&lt;br /&gt;''[[OlimpÃ­ada de MatemÃ¡tica do Grande ABC de 2016|Details]]''
|align="left"|
|}

{{reflist|group="nota"}}

== References ==
{{Reflist}}

== External links ==
* [http://portal.metodista.br/matematica/omabc/olimpiada-de-matematica-do-grande-abc OMABC - OlimpÃ­ada de MatemÃ¡tica do Grande ABC]
* [http://portal.metodista.br/ UMESP - Universidade Metodista de SÃ£o Paulo]
* [http://www.impa.br IMPA - Instituto de MatemÃ¡tica Pura e Aplicada]

{{DEFAULTSORT:Olimpiada de Matematica do Grande ABC}}
[[Category:Mathematics competitions]]</text>
      <sha1>46qfz6d2gblc5clr7nyl4kke6xnj616</sha1>
    </revision>
  </page>
  <page>
    <title>Phenotypic disease network (PDN)</title>
    <ns>0</ns>
    <id>46886526</id>
    <revision>
      <id>699800291</id>
      <parentid>698252844</parentid>
      <timestamp>2016-01-14T15:20:11Z</timestamp>
      <contributor>
        <username>Rjwilmsi</username>
        <id>203434</id>
      </contributor>
      <minor/>
      <comment>Journal cites, added 1 PMID, added 1 PMC using [[Project:AWB|AWB]] (11793)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6708">{{Orphan|date=July 2015}}
The first '''phenotypic disease network''' was constructed by Hidalgo et al. (2009)&lt;ref&gt;{{cite journal|last1=Hidalgo|first1=Cesar A.|last2=Blumm|first2=NIcholas|last3=BarabÃ¡si|first3=Albert-LÃ¡szlÃ³|last4=Christakis|first4=Nicholas A.|title=A Dynamic Network Approach for the Study of Human Phenotypes|journal=PLoS Computational Biology|date=2009|volume=5|issue=4|doi=10.1371/journal.pcbi.1000353|pages=e1000353|pmid=19360091|pmc=2661364}}&lt;/ref&gt; to help understand the origins of many diseases and the links between them. Hidalgo et al. (2009) defined [[disease]]s as specific sets of [[phenotype]]s that affect one or several physiological systems, and compiled data on pairwise [[comorbidity]] correlations for more than 10,000 diseases reconstructed from over 30 million medical records. Hidalgo et al. (2009) presented their data in the form of a [[network theory|network]] with diseases as the nodes and comorbidity correlations as the links. Intuitively, the phenotypic disease network (PDN) can be seen as a map of the phenotypic space whose structure can contribute to the understanding of disease progression.

==History==
During the last decade, several papers were published that aim at understanding the origins and interrelatedness of diseases using the analytical tools of [[network science]]. Interactions between disease-associated genes,&lt;ref&gt;{{cite journal|last1=Goh|first1=Kwang-Il|last2=Cusick|first2=Michael E.|last3=Valle|first3=David|last4=Childs|first4=Barton|last5=Vidal|first5=Marc|last6=BarabÃ¡si|first6=Albert-LÃ¡szlÃ³|title=The human disease network|journal=Proceedings of the National Academy of Sciences of the United States of America|date=2007|volume=104|issue=21|pages=8685â8690|doi=10.1073/pnas.0701361104|pmid=17502601|pmc=1885563}}&lt;/ref&gt; proteins,&lt;ref&gt;{{cite journal|last1=Rual|first1=Jean-FranÃ§ois|last2=Venkatesan|first2=Kavitha|last3=Kavitha|first3=Tong|last4=Hirozane-Kishikawa|first4=Tomoko|title=Towards a proteome-scale map of the human proteinâprotein interaction network|journal=Nature|date=2005|volume=437|pages=1173â1178|doi=10.1038/nature04209|display-authors=etal|pmid=16189514}}&lt;/ref&gt; and gene expressions&lt;ref&gt;{{cite journal|last1=Calvano|first1=Steve E.|last2=Xiao|first2=Wenzhong|last3=Richards|first3=Daniel R.|title=A network-based analysis of systemic inflammation in humans|journal=Nature|date=2005|volume=437|pages=1032â1037|doi=10.1038/nature03985|display-authors=etal}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Pujana|first1=MA|last2=Han|first2=JD|last3=Starita|first3=LM|title=Network modeling links breast cancer susceptibility and centrosome dysfunction|journal=Nature Genetics|date=2007|volume=39|issue=11|pages=1338â49|display-authors=etal|doi=10.1038/ng.2007.2|pmid=17922014}}&lt;/ref&gt; have been explored.
However, phenotypic information was essentially overlooked, despite the fact that there exist extensive, high-quality data on it in the form of clinical histories, until the seminal paper of Hidalgo et al. (2009) introducing the human phenotypic disease network.

==Data and Methodology==

===Source data===
Hidalgo et al. (2009) used [[Medicare (United States)|Medicare]] hospital claims based on the MedPAR records on hospitalizations for the period 1990-1993. For the 32 million elderly Americans aged 65 or older enrolled
in Medicare and alive for the entire study period, there were approximately 32,000,000 inpatient claims, belonging to about 13,000 individuals. The dataset consisted of mainly white patients over 65 years old living in an industrialized country which imposed some limitations on the study; for example, many infectious diseases or pregnancy related conditions did not appear in the data at all.

===Comorbidity correlation measures===
Comorbidity measures are used to measure the "distance" between two diseases. The relative risk (RR) of observing disease ''i'' and ''j'' affecting the same patient is given by
&lt;math&gt;
RR_{ij}=\frac{C_{ij}N}{P_iP_j}
&lt;/math&gt;
where &lt;math&gt;C_{ij}&lt;/math&gt; denotes the number of patients affected by both diseases, ''N'' is the total number of patients in the population, and &lt;math&gt;P_i&lt;/math&gt; and &lt;math&gt;P_j&lt;/math&gt; are the prevalences of diseases ''i'' and ''j'', respectively. 
The &lt;math&gt;\phi&lt;/math&gt;-correlation (Pearson correlation for binary measures) can be expressed as 
&lt;math&gt;
\phi_{ij}=\frac{C_{ij}N-P_iP_j}{\sqrt{P_i P_j(N-P_i)(N-P_j)}}.
&lt;/math&gt;
Both measures have inherent biases: RR overestimates relationships involving rare diseases and underestimates the comorbidity between highly prevalent diseases, while the &lt;math&gt;\phi&lt;/math&gt;-correlation is accurate in describing comorbidity between diseases with similar prevalence but underestimates the comorbidity between rare and common diseases. In the PDN, nodes are disease phenotypes and links connect those phenotypes that have significant comorbidity correlation according to the RR and &lt;math&gt;\phi&lt;/math&gt;-correlation.
Considering the complementary biases of these two measures, Hidalgo et al. (2009) constructed a separate PDN for each.

==Disease network dynamics==

===Disease progression===
Comparing the average correlation between illnesses diagnosed in the first two visits and those diagnosed later (during the third and fourth visits for patients with a total of four visits) to the average correlation in a randomized control case, inter-visit correlations were found to be significantly larger than those that would occur by chance alone, pointing to the fact that patients develop diseases that are close in the PDN to those they alread have.

===Connectedness and mortality===
Hidalgo et al. (2009) also established a connection between that the mortality associated with a given disease and its connectivity in the PDN. Diseases that are preceded by others are usually more connected than those that precede others, and they tend to be more lethal.
That is to say, patients that have a disease that is more connected in the network face higher mortality rates that those patients who have less connected conditions.

===Demographic differences===
In the Hidalgo et al. (2009) study, disease progression was found to be different across genders and ethnicities. For example, hypertension, diabetes, and renal disorders tend to be more comorbid in white males, while heart disease, infactions, pulmonary complications and hypercholesterolemia are more comorbid in white males.

==See also==
*[[Network science]]
*[[Human disease network]]
*[[Network medicine]]
*[[Biological network]]
*[[Nicholas A. Christakis]]
*[[Albert-LÃ¡szlÃ³ BarabÃ¡si]]

==References==
{{reflist}}

==External links==
*[http://www.barabasilab.com/ Center for Complex Network Research]

[[Category:Network theory]]</text>
      <sha1>b0vrft1rz7iuwhimzilsds5xmlejove</sha1>
    </revision>
  </page>
  <page>
    <title>Power law of cache misses</title>
    <ns>0</ns>
    <id>52031076</id>
    <revision>
      <id>835359581</id>
      <parentid>785947336</parentid>
      <timestamp>2018-04-08T06:38:08Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Richard Mattson]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3834">{{Underlinked|date=October 2016}}

A '''power law''' is a mathematical relationship between two quantities in which one is directly proportional to some power of the other. The '''power law for cache misses''' was first established by C. K. Chow in his 1974 paper,&lt;ref&gt;{{cite journal|date=May 1974|title=On Optimization of Storage Hierarchies|journal=IBM Journal of Research and Development|volume=18|issue=3|pages=194â203|doi=10.1147/rd.183.0194|last1=Chow|first1=C. K.}}&lt;/ref&gt; supported by experimental data on hit ratios for stack processing by [[Richard Mattson]] in 1971.&lt;ref&gt;{{cite journal|date=December 1971|title=Evaluation of multilevel memories|journal=IEEE Transactions on Magnetics|volume=7|issue=4|pages=814â819|doi=10.1109/TMAG.1971.1067237|last1=Mattson|first1=R.}}&lt;/ref&gt; The power law of cache misses can be used to narrow down the cache sizes to practical ranges, given a tolerable miss rate, as one of the early steps while designing the [[cache hierarchy]] for a uniprocessor system.&lt;ref name=":0"&gt;{{cite book|title=Fundamentals of Parallel Multicore Architecture|publisher=Chapman &amp; Hall|isbn=978-1482211184|last1=Solihin|first1=Yan}}&lt;/ref&gt;

The power law for cache misses can be stated as

: &lt;math&gt;M = M_0 C^{-\alpha}&lt;/math&gt;

where ''M'' is the miss rate for a cache of size ''C'' and ''M''&lt;sub&gt;0&lt;/sub&gt; is the miss rate of a baseline cache. The exponent ''Î±'' is workload-specific and typically ranges from 0.3 to 0.7.&lt;ref name=":1"&gt;{{Cite journal|last=Hartstein|first=A.|last2=Srinivasan|first2=V.|last3=Puzak|first3=T. R.|last4=Emma|first4=P. G.|date=2006-01-01|title=Cache Miss Behavior: Is It â2?|url=http://doi.acm.org/10.1145/1128022.1128064|journal=Proceedings of the 3rd Conference on Computing Frontiers|series=CF '06|location=New York, NY, USA|publisher=ACM|pages=313â320|doi=10.1145/1128022.1128064|isbn=1595933026}}&lt;/ref&gt;

== Caveats ==
The power law can only give an estimate of the miss rate only up to a certain value of cache size. A large enough cache eliminates capacity misses and increasing the cache size further will not reduce the miss rate any further, contrary to the power law's prediction.&lt;ref name=":0" /&gt;

The validity of the power law of cache misses also depends on the size of working memory set in a given process and also on the temporal re-reference pattern of cache blocks in a process. If a process has a small working memory set relative to the cache size, capacity misses are unlikely and the power law does not hold.

Although conflict misses reduce as associativity increases, Hartstein et al.&lt;ref name=":1" /&gt; showed that the power law holds irrespective of set associativity.

Hartstein et al. plotted the number of cache block re-accesses versus their re-reference times for a large number of workloads and found that most also follow an exponential relationship.&lt;ref name=":1" /&gt;

: &lt;math&gt;R(t) = R_0 t^{-\beta}&lt;/math&gt;

where ''R''(''t'') is the rate of re-referencing. It was found that the exponent ''Î²'' ranged between 1.7 and 1.3. Theoretically, it was proved that the power laws of cache re-reference and cache miss rate are related by the equation &lt;math&gt;\alpha = 1-\beta&lt;/math&gt;. This means that for workloads that do not follow the re-reference power law, the power law of cache misses does not hold true.

== Multilevel cache hierarchy ==
In a multilevel cache hierarchy, the miss pattern of the higher level cache becomes the re-reference pattern of the immediate lower level cache. Hartstein et al.&lt;ref name=":1" /&gt; found that whereas the cache misses for lower levels do not follow a strict power law, as long as the lower level cache is considerably larger than the higher level cache, the miss rate function can be approximated to the power law.

== See also ==
* [[Cache hierarchy]]

==References==
{{Reflist}}

[[Category:Mathematical concepts]]</text>
      <sha1>lnsawzghjadgpq2k2ia51wq18a52dwf</sha1>
    </revision>
  </page>
  <page>
    <title>Proofs of convergence of random variables</title>
    <ns>0</ns>
    <id>24334988</id>
    <revision>
      <id>845904955</id>
      <parentid>845904829</parentid>
      <timestamp>2018-06-14T22:50:18Z</timestamp>
      <contributor>
        <ip>2601:4A:8200:D335:B121:A67A:4A67:6B8</ip>
      </contributor>
      <comment>/* {{anchor|propB1}} Convergence in distribution to a constant implies convergence in probability */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13359">{{merge from|Uniform convergence in probability|discuss=Talk:Uniform convergence in probability#Merge to Convergence of random variables and Proofs of convergence of random variables|date=October 2017}}
{{No footnotes|date=November 2010}}

This article is supplemental for â[[Convergence of random variables]]â and provides proofs for selected results.

Several results will be established using the '''[[portmanteau lemma]]''': A sequence {''X&lt;sub&gt;n&lt;/sub&gt;''} converges in distribution to ''X'' if and only if any of the following conditions are met:
&lt;ol type=A&gt;
  &lt;li&gt; E[''f''(''X&lt;sub&gt;n&lt;/sub&gt;'')] â E[''f''(''X'')] for all [[Bounded function|bounded]], [[continuous function]]s ''f'';
  &lt;li&gt; E[''f''(''X&lt;sub&gt;n&lt;/sub&gt;'')] â E[''f''(''X'')] for all bounded, [[Lipschitz function]]s ''f'';
  &lt;li&gt; limsup{Pr(''X&lt;sub&gt;n&lt;/sub&gt;'' â ''C'')} â¤ Pr(''X'' â ''C'') for all [[closed set]]s ''C'';
&lt;/ol&gt;

=={{anchor|propA1}} Convergence almost surely implies convergence in probability==
: &lt;math&gt;X_n\ \xrightarrow{as}\ X  \quad\Rightarrow\quad  X_n\ \xrightarrow{p}\ X&lt;/math&gt;
'''Proof:''' If {''X&lt;sub&gt;n&lt;/sub&gt;''} converges to ''X'' almost surely, it means that the set of points {Ï: lim ''X&lt;sub&gt;n&lt;/sub&gt;''(Ï) â  ''X''(Ï)} has measure zero; denote this set ''O''. Now fix Îµ &gt; 0 and consider a sequence of sets
: &lt;math&gt;A_n = \bigcup_{m\geq n} \left \{ \left |X_m-X \right |&gt;\varepsilon \right\}&lt;/math&gt;

This sequence of sets is decreasing: ''A''&lt;sub&gt;''n''&lt;/sub&gt; â ''A''&lt;sub&gt;''n''+1&lt;/sub&gt; â ..., and it decreases towards the set

:&lt;math&gt;A_{\infty} = \bigcap_{n \geq 1} A_n.&lt;/math&gt;

For this decreasing sequence of events, their probabilities are also a decreasing sequence, and it decreases towards the Pr(''A''&lt;sub&gt;â&lt;/sub&gt;); we shall show now that this number is equal to zero. Now any point Ï in the complement of ''O'' is such that lim ''X&lt;sub&gt;n&lt;/sub&gt;''(Ï) = ''X''(Ï), which implies that |''X&lt;sub&gt;n&lt;/sub&gt;''(Ï) â ''X''(Ï)| &lt; Îµ for all ''n'' greater than a certain number ''N''. Therefore, for all ''n'' â¥ ''N'' the point Ï will not belong to the set ''A&lt;sub&gt;n&lt;/sub&gt;'', and consequently it will not belong to ''A''&lt;sub&gt;â&lt;/sub&gt;. This means that ''A''&lt;sub&gt;â&lt;/sub&gt; is disjoint with &lt;span style="text-decoration:overline"&gt;''O''&lt;/span&gt;, or equivalently, ''A''&lt;sub&gt;â&lt;/sub&gt; is a subset of ''O'' and therefore Pr(''A''&lt;sub&gt;â&lt;/sub&gt;) = 0.

Finally, consider
: &lt;math&gt;\operatorname{Pr}\left(|X_n-X|&gt;\varepsilon\right) \leq \operatorname{Pr}(A_n) \ \underset{n\to\infty}{\rightarrow} 0,&lt;/math&gt;
which by definition means that ''X&lt;sub&gt;n&lt;/sub&gt;'' converges in probability to ''X''.

=={{anchor|propA1i}} Convergence in probability does not imply almost sure convergence in the discrete case==
If ''X&lt;sub&gt;n&lt;/sub&gt;'' are independent random variables assuming value one with probability 1/''n'' and zero otherwise, then ''X&lt;sub&gt;n&lt;/sub&gt;'' converges to zero in probability but not almost surely. This can be verified using the [[BorelâCantelli lemma]]s.

=={{anchor|propA2}} Convergence in probability implies convergence in distribution==
: &lt;math&gt;    X_n\ \xrightarrow{p}\ X \quad\Rightarrow\quad X_n\ \xrightarrow{d}\ X,&lt;/math&gt;

===Proof for the case of scalar random variables===
'''Lemma.''' Let ''X'', ''Y'' be random variables, let ''a'' be a real number and Îµ &gt; 0. Then
: &lt;math&gt;    \operatorname{Pr}(Y \leq a) \leq \operatorname{Pr}(X\leq a+\varepsilon) + \operatorname{Pr}(|Y - X| &gt; \varepsilon).&lt;/math&gt;

'''Proof of lemma:'''
: &lt;math&gt;\begin{align}
\operatorname{Pr}(Y\leq a) &amp;= \operatorname{Pr}(Y\leq a,\ X\leq a+\varepsilon) + \operatorname{Pr}(Y\leq a,\ X&gt;a+\varepsilon) \\
      &amp;\leq \operatorname{Pr}(X\leq a+\varepsilon) + \operatorname{Pr}(Y-X\leq a-X,\ a-X&lt;-\varepsilon) \\
      &amp;\leq \operatorname{Pr}(X\leq a+\varepsilon) + \operatorname{Pr}(Y-X&lt;-\varepsilon) \\
      &amp;\leq \operatorname{Pr}(X\leq a+\varepsilon) + \operatorname{Pr}(Y-X&lt;-\varepsilon) + \operatorname{Pr}(Y-X&gt;\varepsilon)\\
      &amp;= \operatorname{Pr}(X\leq a+\varepsilon) + \operatorname{Pr}(|Y-X|&gt;\varepsilon)
  \end{align}&lt;/math&gt;

'''Proof of the theorem:''' Recall that in order to prove convergence in distribution, one must show that the sequence of cumulative distribution functions converges to the ''F&lt;sub&gt;X&lt;/sub&gt;'' at every point where ''F&lt;sub&gt;X&lt;/sub&gt;'' is continuous.  Let ''a'' be such a point. For every Îµ &gt; 0, due to the preceding lemma, we have:
: &lt;math&gt;\begin{align}
\operatorname{Pr}(X_n\leq a) &amp;\leq \operatorname{Pr}(X\leq a+\varepsilon) + \operatorname{Pr}(|X_n-X|&gt;\varepsilon) \\
\operatorname{Pr}(X\leq a-\varepsilon)&amp;\leq \operatorname{Pr}(X_n\leq a) + \operatorname{Pr}(|X_n-X|&gt;\varepsilon)
\end{align}&lt;/math&gt;

So, we have
: &lt;math&gt; \operatorname{Pr}(X\leq a-\varepsilon) - \operatorname{Pr} \left (\left |X_n-X \right |&gt;\varepsilon \right ) \leq \operatorname{Pr}(X_n\leq a) \leq \operatorname{Pr}(X\leq a+\varepsilon) + \operatorname{Pr} \left (\left |X_n-X \right |&gt;\varepsilon \right ).  &lt;/math&gt;

Taking the limit as ''n'' â â, we obtain:
: &lt;math&gt;    F_X(a-\varepsilon) \leq \lim_{n\to\infty} \operatorname{Pr}(X_n\leq a) \leq F_X(a+\varepsilon),&lt;/math&gt;
where ''F&lt;sub&gt;X&lt;/sub&gt;''(''a'') = Pr(''X'' â¤ ''a'') is the [[cumulative distribution function]] of ''X''. This function is continuous at ''a'' by assumption, and therefore both ''F&lt;sub&gt;X&lt;/sub&gt;''(''a''âÎµ) and ''F&lt;sub&gt;X&lt;/sub&gt;''(''a''+Îµ) converge to ''F&lt;sub&gt;X&lt;/sub&gt;''(''a'') as Îµ â 0&lt;sup&gt;+&lt;/sup&gt;. Taking this limit, we obtain
: &lt;math&gt;    \lim_{n\to\infty} \operatorname{Pr}(X_n \leq a) = \operatorname{Pr}(X \leq a),&lt;/math&gt;
which means that {''X&lt;sub&gt;n&lt;/sub&gt;''} converges to ''X'' in distribution.

===Proof for the generic case===
The implication follows for when ''X&lt;sub&gt;n&lt;/sub&gt;'' is a random vector by using [[#propB2|this property proved later on this page]] and by taking ''Y&lt;sub&gt;n&lt;/sub&gt; = X''.

=={{anchor|propB1}} Convergence in distribution to a constant implies convergence in probability==
: &lt;math&gt;    X_n\ \xrightarrow{d}\ c \quad\Rightarrow\quad X_n\ \xrightarrow{p}\ c,&lt;/math&gt; &lt;span style="position:relative;top:.4em;left:2em;"&gt;provided ''c'' is a constant.&lt;/span&gt;

'''Proof:''' Fix Îµ &gt; 0. Let ''B''&lt;sub&gt;Îµ&lt;/sub&gt;(''c'') be the open ball of radius Îµ around point ''c'', and ''B''&lt;sub&gt;Îµ&lt;/sub&gt;(''c'')&lt;sup&gt;''c''&lt;/sup&gt; its complement. Then
: &lt;math&gt;\operatorname{Pr}\left(|X_n-c|\geq\varepsilon\right) = \operatorname{Pr}\left(X_n\in B_\varepsilon(c)^c\right).&lt;/math&gt;
By the portmanteau lemma (part C), if ''X&lt;sub&gt;n&lt;/sub&gt;'' converges in distribution to ''c'', then the [[limsup]] of the latter probability must be less than or equal to Pr(''c'' â ''B''&lt;sub&gt;Îµ&lt;/sub&gt;(''c'')&lt;sup&gt;''c''&lt;/sup&gt;), which is obviously equal to zero. Therefore,

: &lt;math&gt;\begin{align}
\lim_{n\to\infty}\operatorname{Pr}\left( \left |X_n-c \right |\geq\varepsilon\right) &amp;\leq \limsup_{n\to\infty}\operatorname{Pr}\left( \left |X_n-c \right | \geq \varepsilon \right) \\
&amp;= \limsup_{n\to\infty}\operatorname{Pr}\left(X_n\in B_\varepsilon(c)^c\right) \\
&amp;\leq \operatorname{Pr}\left(c\in B_\varepsilon(c)^c\right) = 0
\end{align}&lt;/math&gt;

which by definition means that ''X&lt;sub&gt;n&lt;/sub&gt;'' converges to ''c'' in probability.

=={{anchor|propB2}} Convergence in probability to a sequence converging in distribution implies convergence to the same distribution==
: &lt;math&gt;    |Y_n-X_n|\ \xrightarrow{p}\ 0,\ \ X_n\ \xrightarrow{d}\ X\  \quad\Rightarrow\quad  Y_n\ \xrightarrow{d}\ X&lt;/math&gt;

'''Proof:''' We will prove this theorem using the portmanteau lemma, part B. As required in that lemma, consider any bounded function ''f'' (i.e. |''f''(''x'')| â¤ ''M'') which is also Lipschitz:

: &lt;math&gt;\exists K &gt;0, \forall x,y: \quad |f(x)-f(y)|\leq K|x-y|.&lt;/math&gt;

Take some Îµ &gt; 0 and majorize the expression |E[''f''(''Y&lt;sub&gt;n&lt;/sub&gt;'')] â E[''f''(''X&lt;sub&gt;n&lt;/sub&gt;'')]| as

: &lt;math&gt;\begin{align}
\left|\operatorname{E}\left[f(Y_n)\right] - \operatorname{E}\left [f(X_n) \right] \right| &amp;\leq \operatorname{E} \left [\left |f(Y_n) - f(X_n) \right | \right ]\\
&amp;= \operatorname{E}\left[ \left |f(Y_n) - f(X_n) \right |\mathbf{1}_{\left \{|Y_n-X_n|&lt;\varepsilon \right \}} \right] + \operatorname{E}\left[ \left |f(Y_n) - f(X_n) \right |\mathbf{1}_{\left \{|Y_n-X_n|\geq\varepsilon \right \}} \right] \\
&amp;\leq \operatorname{E}\left[K \left |Y_n - X_n \right |\mathbf{1}_{\left \{|Y_n-X_n|&lt;\varepsilon \right \}}\right] + \operatorname{E}\left[2M\mathbf{1}_{\left \{|Y_n-X_n|\geq\varepsilon \right \}}\right] \\
&amp;\leq K \varepsilon \operatorname{Pr} \left (\left |Y_n-X_n \right |&lt;\varepsilon\right) + 2M \operatorname{Pr} \left( \left |Y_n-X_n \right |\geq\varepsilon\right )\\
&amp;\leq K \varepsilon + 2M \operatorname{Pr} \left (\left |Y_n-X_n \right |\geq\varepsilon \right )
\end{align}&lt;/math&gt;

(here '''1'''&lt;sub&gt;{...}&lt;/sub&gt; denotes the [[indicator function]]; the expectation of the indicator function is equal to the probability of corresponding event). Therefore,
: &lt;math&gt;\begin{align}
\left |\operatorname{E}\left [f(Y_n)\right ] - \operatorname{E}\left [f(X) \right ]\right | &amp;\leq \left|\operatorname{E}\left[ f(Y_n) \right ]-\operatorname{E} \left [f(X_n) \right ] \right| + \left|\operatorname{E}\left [f(X_n) \right ]-\operatorname{E}\left [f(X) \right] \right| \\
    &amp;\leq K\varepsilon + 2M \operatorname{Pr}\left (|Y_n-X_n|\geq\varepsilon\right )+ \left |\operatorname{E}\left[ f(X_n) \right]-\operatorname{E} \left [f(X) \right ]\right|.
  \end{align}&lt;/math&gt;
If we take the limit in this expression as ''n''ââââ, the second term will go to zero since {''Y&lt;sub&gt;n&lt;/sub&gt;âX&lt;sub&gt;n&lt;/sub&gt;''} converges to zero in probability; and the third term will also converge to zero, by the portmanteau lemma and the fact that ''X&lt;sub&gt;n&lt;/sub&gt;'' converges to ''X'' in distribution. Thus
: &lt;math&gt;    \lim_{n\to\infty} \left|\operatorname{E}\left [f(Y_n) \right] - \operatorname{E}\left [f(X) \right ] \right| \leq K\varepsilon.&lt;/math&gt;
Since Îµ was arbitrary, we conclude that the limit must in fact be equal to zero, and therefore E[''f''(''Y&lt;sub&gt;n&lt;/sub&gt;'')] â E[''f''(''X'')], which again by the portmanteau lemma implies that {''Y&lt;sub&gt;n&lt;/sub&gt;''} converges to ''X'' in distribution. QED.

=={{anchor|propB3}} Convergence of one sequence in distribution and another to a constant implies joint convergence in distribution==
: &lt;math&gt;    X_n\ \xrightarrow{d}\ X,\ \ Y_n\ \xrightarrow{p}\ c\ \quad\Rightarrow\quad (X_n,Y_n)\ \xrightarrow{d}\ (X,c)
  &lt;/math&gt; &lt;span style="position:relative;top:.4em;left:2em;"&gt;provided ''c'' is a constant.&lt;/span&gt;

'''Proof:''' We will prove this statement using the portmanteau lemma, part A.

First we want to show that (''X&lt;sub&gt;n&lt;/sub&gt;'', ''c'') converges in distribution to (''X'', ''c''). By the portmanteau lemma this will be true if we can show that E[''f''(''X&lt;sub&gt;n&lt;/sub&gt;'', ''c'')] â E[''f''(''X'', ''c'')] for any bounded continuous function ''f''(''x'', ''y''). So let ''f'' be such arbitrary bounded continuous function. Now consider the function of a single variable ''g''(''x'') := ''f''(''x'', ''c''). This will obviously be also bounded and continuous, and therefore by the portmanteau lemma for sequence {''X&lt;sub&gt;n&lt;/sub&gt;''} converging in distribution to ''X'', we will have that E[''g''(''X&lt;sub&gt;n&lt;/sub&gt;'')] â E[''g''(''X'')]. However the latter expression is equivalent to âE[''f''(''X&lt;sub&gt;n&lt;/sub&gt;'', ''c'')] â E[''f''(''X'', ''c'')]â, and therefore we now know that (''X&lt;sub&gt;n&lt;/sub&gt;'', ''c'') converges in distribution to (''X'', ''c'').

Secondly, consider |(''X&lt;sub&gt;n&lt;/sub&gt;'', ''Y&lt;sub&gt;n&lt;/sub&gt;'') â (''X&lt;sub&gt;n&lt;/sub&gt;'', ''c'')| = |''Y&lt;sub&gt;n&lt;/sub&gt;'' â ''c''|. This expression converges in probability to zero because ''Y&lt;sub&gt;n&lt;/sub&gt;'' converges in probability to ''c''. Thus we have demonstrated two facts:
: &lt;math&gt;\begin{cases}
    \left| (X_n, Y_n) - (X_n,c) \right|\ \xrightarrow{p}\ 0, \\
    (X_n,c)\ \xrightarrow{d}\ (X,c).
  \end{cases}&lt;/math&gt;
By the property [[#propB2|proved earlier]], these two facts imply that (''X&lt;sub&gt;n&lt;/sub&gt;'', ''Y&lt;sub&gt;n&lt;/sub&gt;'') converge in distribution to (''X'', ''c'').

=={{anchor|propB4}} Convergence of two sequences in probability implies joint convergence in probability==
: &lt;math&gt;X_n\ \xrightarrow{p}\ X,\ \ Y_n\ \xrightarrow{p}\ Y\ \quad\Rightarrow\quad (X_n,Y_n)\ \xrightarrow{p}\ (X,Y)&lt;/math&gt;

'''Proof:'''
: &lt;math&gt;\begin{align}
\operatorname{Pr}\left(\left|(X_n,Y_n)-(X,Y)\right|\geq\varepsilon\right) &amp;\leq \operatorname{Pr}\left(|X_n-X| + |Y_n-Y|\geq\varepsilon\right) \\
&amp;\leq\operatorname{Pr}\left(|X_n-X|\geq\varepsilon/2\right) + \operatorname{Pr}\left(|Y_n-Y|\geq\varepsilon/2\right)
\end{align}&lt;/math&gt;
Each of the probabilities on the right-hand side converge to zero as ''n'' â â by definition of the convergence of {''X&lt;sub&gt;n&lt;/sub&gt;''} and {''Y&lt;sub&gt;n&lt;/sub&gt;''} in probability to ''X'' and ''Y'' respectively. Taking the limit we conclude that the left-hand side also converges to zero, and therefore the sequence {(''X&lt;sub&gt;n&lt;/sub&gt;'', ''Y&lt;sub&gt;n&lt;/sub&gt;'')} converges in probability to {(''X'', ''Y'')}.

==See also==
* [[Convergence of random variables]]

==References==
{{refbegin}}
* {{cite book
  | last = van der Vaart
  | first = Aad W.
  | author-link= Aad van der Vaart
  | title = Asymptotic statistics
  | year = 1998
  | publisher = Garrick Ardis
  | location = New York
  | isbn = 978-0-521-49603-2
  | ref = CITEREFvan_der_Vaart1998
  }}
{{refend}}

{{DEFAULTSORT:Proofs Of Convergence Of Random Variables}}
[[Category:Article proofs]]
[[Category:Statistical randomness]]</text>
      <sha1>i47i2ysu95tw9b807854y4js53vglsu</sha1>
    </revision>
  </page>
  <page>
    <title>Rational pricing</title>
    <ns>0</ns>
    <id>716969</id>
    <revision>
      <id>870083266</id>
      <parentid>870083164</parentid>
      <timestamp>2018-11-22T07:31:22Z</timestamp>
      <contributor>
        <ip>169.202.235.2</ip>
      </contributor>
      <comment>/* Pricing derivatives */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25625">{{Other uses|Rational (disambiguation){{!}}Rational}}
{{Original research|date=June 2014}}

'''Rational pricing''' is the assumption in [[financial economics]] that asset prices (and hence [[asset pricing model]]s) will reflect the [[arbitrage-free]] price of the asset as any deviation from this price will be "arbitraged away". This assumption is useful in pricing fixed income securities, particularly bonds, and is fundamental to the pricing of derivative instruments.

==Arbitrage mechanics==&lt;!-- This section is linked from [[Arbitrage]] --&gt;
[[Arbitrage]] is the practice of taking advantage of a state of imbalance between two (or possibly more) markets. Where this mismatch can be exploited (i.e. after transaction costs, storage costs, transport costs, dividends etc.) the arbitrageur can "lock in" a risk-free profit by purchasing and selling simultaneously in both markets.

In general, arbitrage ensures that "the [[law of one price]]" will hold; arbitrage also equalises the prices of assets with identical cash flows, and sets the price of assets with known future cash flows.

===The law of one price===
The same asset must trade at the same price on all markets ("the [[law of one price]]").
Where this is not true, the arbitrageur will:
# buy the asset on the market where it has the lower price, and simultaneously sell it ([[short selling|short]]) on the second market at the higher price
# deliver the asset to the buyer and receive that higher price
# pay the seller on the cheaper market with the proceeds and pocket the difference.

===Assets with identical cash flows===
Two assets with identical cash flows must trade at the same price.
Where this is not true, the arbitrageur will:
# sell the asset with the higher price ([[short selling|short sell]]) and simultaneously buy the asset with the lower price
# fund his purchase of the cheaper asset with the proceeds from the sale of the expensive asset and pocket the difference
# deliver on his obligations to the buyer of the expensive asset, using the cash flows from the cheaper asset.

===An asset with a known future-price===
An asset with a known price in the future must today trade at that price [[discounting|discount]]ed at the [[Risk-free interest rate|risk free rate]].

Note that this condition can be viewed as an application of the above, where the two assets in question are the asset to be delivered and the risk free asset.

(a) where the discounted future price is ''higher'' than today's price:
# The arbitrageur agrees to deliver the asset on the future date (i.e. [[Forward contract|sells forward]]) and simultaneously buys it today with borrowed money.
# On the delivery date, the arbitrageur hands over the underlying, and receives the agreed price.
# He then repays the lender the borrowed amount plus interest.
# The difference between the agreed price and the amount repaid (i.e. owed) is the arbitrage profit.

(b) where the discounted future price is ''lower'' than today's price:
# The arbitrageur agrees to pay for the asset on the future date (i.e. [[Forward contract|buys forward]]) and simultaneously sells ([[Short selling|short]]) the underlying today; he invests (or banks) the proceeds.
# On the delivery date, he cashes in the matured investment, which has appreciated at the risk free rate.
# He then takes delivery of the underlying and pays the agreed price using the matured investment.
# The difference between the maturity value and the agreed price is the arbitrage profit.

It will be noted that (b) is only possible for those holding the asset but not needing it until the future date.  There may be few such parties if short-term demand exceeds supply, leading to [[backwardation]].

==Fixed income securities==
Rational pricing is one approach used in pricing [[fixed rate bond]]s. Here, each cash flow can be matched by trading in (a) some multiple of a [[zero-coupon bond]] corresponding to the coupon date, and of equivalent [[credit worthiness]] (if possible, from the same issuer as the bond being valued) with the corresponding maturity, or (b) in a corresponding [[Zero-coupon bond#Strip bonds|strip]] and ZCB.

Given that the cash flows can be replicated, the price of the bond must today equal the sum of each of its cash flows discounted at the same rate as each ZCB, [[Rational pricing#Assets with identical cash flows|as above]]. Were this not the case, arbitrage would be possible and would bring the price back into line with the price based on ZCBs; see [[Bond valuation#Arbitrage-free pricing approach]]

The pricing formula is as below, where each cash flow &lt;math&gt;C_t\,&lt;/math&gt; is discounted at the rate  &lt;math&gt;r_t\,&lt;/math&gt; that matches the coupon date:
:Price =  &lt;math&gt; P_0 = \sum_{t=1}^T\frac{C_t}{(1+r_t)^t}&lt;/math&gt;

Often, the formula is expressed as &lt;math&gt; P_0 = \sum_{t=1}^ T C(t) \times P(t)&lt;/math&gt;, using prices instead of rates, as prices are more readily available.

''See also [[Fixed income arbitrage]]; [[Bond credit rating]].''

==Pricing derivatives==
A [[derivative (finance)|derivative]] is an instrument that allows for buying and selling of the same asset on two markets&amp;nbsp;â the [[spot price|spot market]] and the [[derivatives market]]. [[Mathematical finance]] assumes that any imbalance between the two markets will be arbitraged away. Thus, in a correctly priced derivative contract, the derivative price, the [[strike price]] (or [[reference rate]]), and the [[spot price]] will be related such that  arbitrage is not possible. See [[Fundamental theorem of arbitrage-free pricing]].

===Futures===&lt;!-- This section is linked from [[Contango]] --&gt;
In a [[futures contract]], for no arbitrage to be possible, the price paid on delivery (the [[forward price]]) must be the same as the cost (including interest) of buying and storing the asset. In other words, the rational forward price represents the expected [[future value]] of the [[underlying]] discounted at the risk free rate (the "[[Rational pricing#An asset with a known future-price|asset with a known future-price]]", as above); see [[Spotâfuture parity]]. Thus, for a simple, non-dividend paying asset, the value of the future/forward, &lt;math&gt;F(t)\,&lt;/math&gt;, will be found by accumulating the present value &lt;math&gt;S(t)\,&lt;/math&gt; at time &lt;math&gt;t\,&lt;/math&gt; to maturity &lt;math&gt;T\,&lt;/math&gt; by the rate of risk-free return &lt;math&gt;r\,&lt;/math&gt;.

:&lt;math&gt;F(t) = S(t)\times (1+r)^{(T-t)}\,&lt;/math&gt;

This relationship may be modified for storage costs, dividends, dividend yields, and convenience yields; see [[Futures contract#Pricing|futures contract pricing]].

Any deviation from this equality allows for arbitrage as follows.

*In the case where the forward price is ''higher'':
# The arbitrageur sells the futures contract and buys the underlying today (on the spot market) with borrowed money.
# On the delivery date, the arbitrageur hands over the underlying, and receives the agreed forward price.
# He then repays the lender the borrowed amount plus interest.
# The difference between the two amounts is the arbitrage profit.

*In the case where the forward price is ''lower'':
# The arbitrageur buys the futures contract and sells the underlying today (on the spot market); he invests the proceeds.
# On the delivery date, he cashes in the matured investment, which has appreciated at the risk free rate.
# He then receives the underlying and pays the agreed forward price using the matured investment. [If he was [[short selling|short]] the underlying, he returns it now.]
# The difference between the two amounts is the arbitrage profit.

===Options===
As above, where the value of an asset in the future is known (or expected), this value can be used to determine the asset's rational price today. In an [[option (finance)|option]] contract, however, exercise is dependent on the price of the underlying, and hence payment is uncertain. Option pricing models therefore include logic that either "locks in" or "infers" this future value; both approaches deliver identical results. Methods that lock-in future cash flows assume ''arbitrage free pricing'', and those that infer expected value assume ''[[Rational pricing#Risk neutral valuation|risk neutral valuation]]''.

To do this, (in their simplest, though widely used form) both approaches assume a "binomial model" for the behavior of the [[underlying instrument]], which allows for only two states&amp;nbsp;â up or down. If S is the current price, then in the next period the price will either be ''S up'' or ''S down''. Here, the value of the share in the up-state is S Ã u, and in the down-state is S Ã d (where u and d are multipliers with d &lt; 1 &lt; u and assuming d &lt; 1+r &lt; u; see the [[binomial options model]]). Then, given these two states, the "arbitrage free" approach creates a position that has an identical value in either state&amp;nbsp;â the cash flow in one period is therefore known, and arbitrage pricing is applicable. The risk neutral approach infers expected option value from the [[Option time value#Intrinsic value|intrinsic value]]s at the later two nodes.

Although this logic appears far removed from the [[BlackâScholes]] formula and the lattice approach in the [[Binomial options model]], it in fact underlies both models; see [[BlackâScholes equation|The BlackâScholes PDE]]. The assumption of binomial behaviour in the underlying price is defensible as the number of time steps between today (valuation) and exercise increases, and the period per time-step is correspondingly short. The Binomial options model allows for a high number of very short time-steps (if [[Source code|coded]] correctly), while BlackâScholes, in fact, models a [[Continuous-time Markov process|continuous process]].

The examples below have shares as the underlying, but may be generalised to other instruments. The value of a [[put option]] can be derived as below, or may be found from the value of the call using [[put-call parity]].

====Arbitrage free pricing====
Here, the future payoff is "locked in" using either "delta hedging" or the "[[replicating portfolio]]" approach. As above, this payoff is then discounted, and the result is used in the valuation of the option today.

=====Delta hedging=====&lt;!-- This section is linked from [[BlackâScholes]] --&gt;
It is possible to create a position consisting of '''Î''' shares and 1 [[call option|call]] sold, such that the position's value will be identical in the ''S up'' and ''S down'' states, and hence known with certainty (see [[Delta hedging]]).  This certain value corresponds to the forward price above ([[Rational pricing#An asset with a known future-price|"An asset with a known future price"]]), and as above, for no arbitrage to be possible, the present value of the position must be its expected future value discounted at the risk free rate, '''r'''. The value of a call is then found by equating the two.

# Solve for Î such that:
#: value of position in one period = Î Ã ''S up'' - [[Option time value#Intrinsic value|&lt;math&gt;max&lt;/math&gt;]] (''S up''&amp;nbsp;â strike price, 0 )  =  Î Ã ''S down'' - [[Option time value#Intrinsic value|&lt;math&gt;max&lt;/math&gt;]] (''S down''&amp;nbsp;â strike price, 0)
# Solve for the value of the call, using Î, where:
#: value of position today = value of position in one period Ã· (1 + r) =  Î Ã ''S current''&amp;nbsp;â value of  call

=====The replicating portfolio=====
{{main|Replicating portfolio}}
It is possible to create a position consisting of '''Î''' shares and $'''B''' borrowed at the risk free rate, which will produce identical cash flows to one option on the underlying share. The position created is known as a "replicating portfolio" since its cash flows replicate those of the option. As shown above ([[Rational pricing#Assets with identical cash flows|"Assets with identical cash flows"]]), in the absence of arbitrage opportunities, since the cash flows produced are identical, the price of the option today must be the same as the value of the position today.

# Solve simultaneously for Î and B such that:
#* Î Ã ''S up'' - B Ã (1 + r) =  [[Option time value#Intrinsic value|&lt;math&gt;\max&lt;/math&gt;]] ( 0, ''S up''&amp;nbsp;â strike price )
#* Î Ã ''S down'' - B Ã (1 + r) =  [[Option time value#Intrinsic value|&lt;math&gt;\max&lt;/math&gt;]] ( 0, ''S down''&amp;nbsp;â strike price )
# Solve for the value of the call, using Î and B, where:
#* call = Î Ã ''S current'' - B

Note that there is no discounting here &amp;nbsp;â the interest rate appears only as part of the construction. This approach is therefore used in preference to others where it is not clear whether the risk free rate may be applied as the [[discount window|discount rate]] at each decision point, or whether, instead, a [[Capital asset pricing model#Asset-specific required return|premium over risk free]], differing by state, would be required. The best example of this would be under [[Real options analysis]]&lt;ref name="Reilly &amp; Brown"&gt;See Ch. 23, Sec. 5, in: Frank Reilly, Keith Brown (2011). "Investment Analysis and Portfolio Management." (10th Edition). South-Western College Pub. {{ISBN|0538482389}}&lt;/ref&gt; where managements' actions actually change the risk characteristics of the project in question, and hence the [[Required rate of return]] could differ in the up- and down-states. Here, in the above formulae, we then have: "Î Ã ''S up'' - B Ã (1 + r '''''up''''')..." and "Î Ã ''S down'' - B Ã (1 + r '''''down''''')..." . See [[Real options valuation#Technical considerations]]. (Another case where the modelling assumptions may depart from rational pricing is the [[Employee stock option#Valuation|valuation of employee stock options]].)

====Risk neutral valuation====&lt;!-- This section is linked from [[BlackâScholes]] --&gt;
Here the value of the option is calculated using the [[Risk-neutral measure|risk neutrality]] assumption. Under this assumption, the "[[expected value]]" (as opposed to "locked in" value) is [[discounted]]. The expected value is calculated using the [[Option time value#Intrinsic value|intrinsic values]] from the later two nodes: "Option up" and "Option down", with '''u''' and '''d''' as price multipliers as above.  These are then weighted by their respective probabilities: "probability" '''p''' of an up move in the underlying, and "probability" '''(1-p)''' of a down move. The expected value is then discounted at '''r''', the [[Risk-free interest rate|risk-free rate]].

# Solve for p
#: under risk-neutrality, for no arbitrage to be possible in the share, today's price must represent its expected value discounted at the risk free rate (i.e., the share price is a [[Martingale (probability theory)|Martingale]]):
#:&lt;math&gt;
\begin{align}
S &amp;= \frac{p \times S_u + (1-p)\times S_d}{1 + r} \\
&amp;= \frac{p\times u\times S + (1-p)\times d\times S}{1 + r} \\
\Rightarrow p &amp;= \frac{(1+r) - d}{u-d}\\
\end{align}
&lt;/math&gt;
# Solve for call value, using p
#: for no arbitrage to be possible in the call, today's price must represent its expected value discounted at the risk free rate:
#:&lt;math&gt;
\begin{align}
C &amp;= \frac{p\times C_u + (1-p) \times C_d}{1+r} \\
&amp;= \frac{p\times \max(S_u - k, 0)  + (1-p) \times\max(S_d -k, 0)}{1+r} \\
\end{align}
&lt;/math&gt;

=====The risk neutrality assumption=====
Note that above, the risk neutral formula does not refer to the expected or forecast return of the underlying, nor its [[Volatility (finance)|volatility]] &amp;nbsp;â p as solved, relates to the [[risk-neutral measure]] as opposed to the actual [[probability distribution]] of prices. Nevertheless, both arbitrage free pricing and risk neutral valuation deliver identical results. In fact, it can be shown that "delta hedging" and "risk-neutral valuation" use identical formulae expressed differently. Given this equivalence, it is valid to assume "risk neutrality" when pricing derivatives. See [[fundamental theorem of arbitrage-free pricing]].

===Swaps===
Rational pricing underpins the logic of [[Swap (finance)|swap]] valuation. Here, two [[Counterparty|counterparties]] "swap" obligations, effectively exchanging [[cash flow]] streams calculated against a notional [[:wikt:principal|principal]] amount, and the value of the swap is the [[present value]] (PV) of both sets of future cash flows "netted off" against each other.

Note that since the [[2007â2012 global financial crisis]], pricing is under a "multi-curve" framework, whereas previously it was off a single, "self discounting", curve; see [[Financial economics#Derivative pricing]] for context. Of course, under both approaches, pricing must be arbitrage free, and the logic below therefore holds under either, although see [[Interest rate swap#Valuation and pricing]] for formulae.

====Valuation at initiation====
To be arbitrage free, the terms of a swap contract are such that, initially, the [[Net present value|''Net'' present value]] of these future cash flows is equal to zero; see [[Swap (finance)#Valuation|swap valuation]]. For example, consider [[Interest rate swap#Valuation and pricing|the valuation]] of a fixed-to-floating [[Interest rate swap]] where Party A pays a fixed rate, and Party B pays a floating rate. Here, the ''fixed rate'' would be such that the present value of future fixed rate payments by Party A is equal to the present value of the ''expected'' future floating rate payments (i.e. the NPV is zero). Were this not the case, an arbitrageur, C, could:
# Assume the position with the ''lower'' present value of payments, and borrow funds equal to this present value
# Meet the cash flow obligations on the position by using the borrowed funds, and receive the corresponding paymentsâwhich have a higher present value
# Use the received payments to repay the debt on the borrowed funds
# Pocket the difference&amp;nbsp;â where the difference between the present value of the loan and the present value of the inflows is the arbitrage profit

====Subsequent valuation====
Once traded, swaps can also be priced using rational pricing. For example, the Floating leg of an interest rate swap can be "decomposed" into a series of [[forward rate agreement]]s. Here, since the swap has identical payments to the FRA,  arbitrage free pricing must apply as above&amp;nbsp;â i.e. the value of this leg is equal to the value of the corresponding FRAs. Similarly, the "receive-fixed" leg of a swap can be valued by comparison to a [[Bond (finance)|bond]] with the same schedule of payments. (Relatedly, given that their [[underlying]]s have the same cash flows, [[bond option]]s and [[swaption]]s are equatable.)  See [[Swap (finance)#Using bond prices]].

==Pricing shares==
The [[arbitrage pricing theory]] (APT), a general theory of asset pricing, has become influential in the pricing of [[stock|shares]].  APT holds that the [[expected return]] of a financial asset can be modelled as a [[linear function]] of various [[macroeconomics|macro-economic]] factors, where sensitivity to changes in each factor is represented by a factor specific [[beta coefficient]]:

:&lt;math&gt;E\left(r_j\right) = r_f + b_{j1}F_1 + b_{j2}F_2 + ... + b_{jn}F_n + \epsilon_j&lt;/math&gt;

:where
:* &lt;math&gt;E(r_j)&lt;/math&gt; is the risky asset's expected return,
:* &lt;math&gt;r_f&lt;/math&gt; is the [[risk free rate]],
:* &lt;math&gt;F_k&lt;/math&gt; is the macroeconomic factor,
:* &lt;math&gt;b_{jk}&lt;/math&gt; is the sensitivity of the asset to factor &lt;math&gt;k&lt;/math&gt;,
:* and &lt;math&gt;\epsilon_j&lt;/math&gt; is the risky asset's idiosyncratic random shock with mean zero.

The model derived rate of return will then be used to price the asset correctly&amp;nbsp;â the asset price should equal the expected end of period price [[discounting|discount]]ed at the rate implied by model. If the price diverges, arbitrage should bring it back into line. Here, to perform the arbitrage, the investor "creates" a correctly priced asset (a ''synthetic'' asset), a ''portfolio'' with the same net-exposure to each of the macroeconomic factors as the mispriced asset but a different expected return. See the [[Arbitrage pricing theory#Arbitrage mechanics|arbitrage pricing theory]] article for detail on the construction of the portfolio.  The arbitrageur is then in a position to make a risk free profit as follows:

*Where the asset price is too low, the ''portfolio'' should have appreciated at the rate implied by the APT, whereas the mispriced asset would have appreciated at ''more'' than this rate. The arbitrageur could therefore:
#Today: [[short selling|short sell]] the ''portfolio'' and buy the mispriced-asset with the proceeds.
#At the end of the period: sell the mispriced asset, use the proceeds to buy back the ''portfolio'', and pocket the difference.

*Where the asset price is too high, the ''portfolio'' should have appreciated at the rate implied by the APT, whereas the mispriced asset would have appreciated at ''less'' than this rate. The arbitrageur could therefore:
#Today: [[short selling|short sell]]  the mispriced-asset and buy the ''portfolio'' with the proceeds.
#At the end of the period: sell the ''portfolio'', use the proceeds to buy back the mispriced-asset, and pocket the difference.

Note that under "true arbitrage", the investor locks-in a ''guaranteed'' payoff, whereas under APT arbitrage, the investor locks-in a positive ''expected'' payoff. The APT thus assumes "arbitrage in expectations"&amp;nbsp;â i.e. that arbitrage by investors will bring asset prices back into line with the returns expected by the model.

The [[capital asset pricing model]] (CAPM) is an earlier, (more) influential theory on asset pricing. Although based on different assumptions, the CAPM can, in some ways, be considered a "special case" of the APT; specifically, the CAPM's [[security market line]] represents a single-factor model of the asset price, where beta is exposure to changes in the [[Market portfolio|"value of the market"]] as a whole.

==No-arbitrage pricing under systemic risk==

Classical valuation methods like the Black-Scholes model or the Merton model cannot account for systemic counterparty risk which is present in systems with financial interconnectedness.&lt;ref name="Fischer (2014a)"&gt;{{cite journal|last=Fischer|first=Tom|title=NO-ARBITRAGE PRICING UNDER SYSTEMIC RISK: ACCOUNTING FOR CROSS-OWNERSHIP|journal=Mathematical Finance|year=2014|volume=24|issue=1|pages=97â124 (Published online: 19 Jun 2012)|doi=10.1111/j.1467-9965.2012.00526.x|url=https://dx.doi.org/10.1111/j.1467-9965.2012.00526.x}}&lt;/ref&gt;
More details regarding risk-neutral, arbitrage-free asset and derivative valuation can be found in Wikipedia's [[systemic risk]]
article (see also [[Systemic risk#Valuation of assets and derivatives under systemic risk|valuation under systemic risk]]).

==See also==
*[[Contingent claim analysis]]
*[[Efficient-market hypothesis]]
*[[Fair value]]
*[[Fundamental theorem of arbitrage-free pricing]]
*[[Homo economicus]]
*[[List of finance topics#Valuation|List of valuation topics]]
*[[No free lunch with vanishing risk]]
*[[Rational choice theory]]
*[[Rationality]]
*[[Risk-neutral measure]]
*[[Volatility arbitrage]]
*[[Systemic risk]]

==References==
{{reflist}}

==External links==

'''Arbitrage free pricing'''
*[https://web.archive.org/web/20160304041839/http://www.newschool.edu/nssr/het/essays/sequence/arbitpricing.htm Pricing by Arbitrage], The History of Economic Thought Website
*[http://www.quantnotes.com/fundamentals/basics/arbitragepricing.htm The Idea Behind Arbitrage Pricing], Samy Mohammed, Quantnotes
* [https://web.archive.org/web/20070628225647/http://www.in-the-money.com/artandpap/IV%20Fundamental%20Theorem%20-%20Part%20I.doc "The Fundamental Theorem" of Finance]; [https://web.archive.org/web/20070628225647/http://www.in-the-money.com/artandpap/IV%20Fundamental%20Theorem%20-%20Part%20II.doc part II]. Prof. [[Mark Rubinstein]], [[Haas School of Business]]
*[http://www.hss.caltech.edu/~kcb/Notes/Arbitrage.pdf Elementary Asset Pricing Theory], Prof. K. C. Border [[California Institute of Technology]]
*[http://www.fam.tuwien.ac.at/~wschach/pubs/preprnts/prpr0118a.pdf The Notion of Arbitrage and Free Lunch in Mathematical Finance], Prof. Walter Schachermayer
*[http://www-personal.umich.edu/~shumway/courses.dir/f872.dir/noarb.pdf No Arbitrage in Continuous Time], Prof. Tyler Shumway

'''Risk neutrality and arbitrage free pricing'''
*[http://www.bus.lsu.edu/academics/finance/faculty/dchance/Instructional/TN96-02.pdf Risk Neutral Pricing in Discrete Time] ([[portable document format|PDF]]), Prof. Don M. Chance
*[http://ssrn.com/abstract=1395390 Risk-Neutral Probabilities Explained]. Nicolas Gisiger
*[http://papers.ssrn.com/sol3/papers.cfm?abstract_id=290044 Risk-neutral Valuation: A Gentle Introduction], [http://papers.ssrn.com/sol3/papers.cfm?abstract_id=292724 Part II]. Joseph Tham [[Duke University]]

'''Application to derivatives'''
*[https://web.archive.org/web/20050212030415/http://www.rpi.edu/~olivaa2/binomial.pdf Option Valuation in the Binomial Model] ([[Internet Archive|archived]]), Prof. Ernst Maug, [[Rensselaer Polytechnic Institute]]
*[http://www.quantnotes.com/fundamentals/futures/futureforwardpricing.htm Pricing Futures and Forwards by Arbitrage Argument], Quantnotes
*[https://web.archive.org/web/20080208063017/http://www.iassa.co.za/images/file/indexmain.htm The relationship between futures and spot prices], [[Investment Analysts Society of Southern Africa]]
*[http://www.ederman.com/new/docs/qf-Illusions-dynamic.pdf The illusions of dynamic replication], [[Emanuel Derman]] and [[Nassim Taleb]]
*[http://papers.ssrn.com/sol3/papers.cfm?abstract_id=291988 Swaptions and Options], Prof. Don M. Chance

[[Category:Pricing]]
[[Category:Finance theories]]
[[Category:Mathematical finance]]</text>
      <sha1>c0mscm7o1vz9a2z8rdv1viwd25dl6bp</sha1>
    </revision>
  </page>
  <page>
    <title>Sphere</title>
    <ns>0</ns>
    <id>27859</id>
    <revision>
      <id>868742092</id>
      <parentid>868742058</parentid>
      <timestamp>2018-11-14T04:16:37Z</timestamp>
      <contributor>
        <username>Theinstantmatrix</username>
        <id>31567860</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/175.137.90.2|175.137.90.2]] ([[User talk:175.137.90.2|talk]]) to last version by TheRedBox</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33220">{{About|the concept in three-dimensional geometry}}
{{Redirect|Globose|the neuroanatomic structure|Globose nucleus}}
{{pp-move-indef}}
[[Image:Sphere wireframe 10deg 6r.svg|right|thumb|A two-dimensional [[3D projection#Perspective projection|perspective projection]] of a sphere]]
A '''sphere''' (from [[Greek language|Greek]] [[wikt:ÏÏÎ±á¿ÏÎ±|ÏÏÎ±á¿ÏÎ±]] â ''sphaira'', "globe, ball"&lt;ref&gt;[http://www.perseus.tufts.edu/hopper/text?doc=Perseus%3Atext%3A1999.04.0057%3Aentry%3Dsfai%3Dra^ ÏÏÎ±á¿ÏÎ±], Henry George Liddell, Robert Scott, ''A Greek-English Lexicon'', on Perseus&lt;/ref&gt;) is a perfectly round [[Geometry|geometrical]] object in [[solid geometry|three-dimensional space]] that is the surface of a completely round [[Ball (mathematics)|ball]] (viz., analogous to the circular objects in two dimensions, where a "[[circle]]" circumscribes its [[Disk (mathematics)|"disk"]]).

Like a circle in a two-dimensional space, a sphere is defined mathematically as the [[Locus (mathematics)|set of points]] that are all at the same distance {{math|''r''}} from a given point, but in a three-dimensional space.&lt;ref name=Albert54&gt;{{harvnb|Albert|2016|loc=p. 54}}&lt;/ref&gt; This distance {{math|''r''}} is the [[radius]] of the ball, which is made up from all points with a distance less than {{math|''r''}} from the given point, which is the [[centre (geometry)|center]] of the mathematical ball. These are also referred to as the radius and center of the sphere, respectively. The longest straight line through the ball, connecting two points of the sphere, passes through the center and its length is thus twice the radius; it is a [[diameter]] of both the sphere and its ball.

While outside mathematics the terms "sphere" and "ball" are sometimes used interchangeably, in [[mathematics]] the above distinction is made between a ''sphere'', which is a two-dimensional [[closed surface]], [[embedding|embedded]] in a three-dimensional [[Euclidean space]], and a ''ball'', which is a three-dimensional shape that includes the sphere and everything ''inside'' the sphere (a ''closed ball''), or, more often, just the points ''inside'', but ''not on'' the sphere (an ''open ball''). This distinction has not always been maintained and especially older mathematical references talk about a sphere as a solid. This is analogous to the situation in the [[Plane (geometry)|plane]], where the terms "circle" and "disk" can also be confounded.

==Equations in three-dimensional space==
[[Image:Sphere and Ball.png|right|thumb|two orthogonal radii of a sphere]]
{{see also|trigonometric function|spherical coordinates}}

In [[analytic geometry]], a sphere with center {{math|(''x''&lt;sub&gt;0&lt;/sub&gt;, ''y''&lt;sub&gt;0&lt;/sub&gt;, ''z''&lt;sub&gt;0&lt;/sub&gt;)}} and radius {{mvar|r}} is the [[Locus (mathematics)|locus]] of all points {{math|(''x'', ''y'', ''z'')}} such that
:&lt;math&gt; (x - x_0 )^2 + (y - y_0 )^2 + ( z - z_0 )^2 = r^2.&lt;/math&gt;

Let {{mvar|a, b, c, d, e}} be real numbers with {{math|''a'' â  0}} and put
:&lt;math&gt;x_0 = \frac{-b}{a}, \quad y_0 = \frac{-c}{a}, \quad z_0 = \frac{-d}{a}, \quad \rho = \frac{b^2 +c^2+d^2 - ae}{a^2}. &lt;/math&gt;
Then the equation
:&lt;math&gt;f(x,y,z) = a(x^2 + y^2 +z^2) + 2(bx + cy + dz) + e = 0&lt;/math&gt;
has no real points as solutions if &lt;math&gt;\rho &lt; 0&lt;/math&gt; and is called the equation of an '''imaginary sphere'''. If &lt;math&gt;\rho = 0&lt;/math&gt; the only solution of &lt;math&gt;f(x,y,z) = 0&lt;/math&gt; is the point &lt;math&gt;P_0 = (x_0,y_0,z_0)&lt;/math&gt; and the equation is said to be the equation of a '''point sphere'''. Finally, in the case &lt;math&gt;\rho &gt; 0&lt;/math&gt;, &lt;math&gt;f(x,y,z) = 0&lt;/math&gt; is an equation of a sphere whose center is &lt;math&gt;P_0&lt;/math&gt; and whose radius is &lt;math&gt;\sqrt \rho&lt;/math&gt;.&lt;ref name=Albert54 /&gt;

If {{mvar|a}} in the above equation is zero then {{math|1=''f''(''x'', ''y'', ''z'') = 0}} is the equation of a plane. Thus, a plane may be thought of as a sphere of infinite radius whose center is a [[point at infinity]].&lt;ref name=Woods266&gt;{{harvnb|Woods|1961|loc=p. 266}}&lt;/ref&gt;

The points on the sphere with radius &lt;math&gt;r &gt; 0&lt;/math&gt; and center &lt;math&gt;(x_0,y_0,z_0)&lt;/math&gt; can be parameterized via
:&lt;math&gt;\begin{align} x &amp;= x_0 + r \sin \varphi \; \cos \theta \\
y &amp;= y_0 + r \sin \varphi \; \sin \theta \qquad (0 \leq \varphi \leq \pi,\;  0 \leq \theta &lt; 2\pi ) \\
z &amp;= z_0 + r \cos \varphi \,\end{align}&lt;/math&gt;&lt;ref&gt;{{harvtxt|Kreyszig|1972|p=342}}&lt;/ref&gt;

A sphere of any radius centered at zero is an integral surface of the following [[differential form]]:
:&lt;math&gt; x \, dx + y \, dy + z \, dz = 0.&lt;/math&gt;

This equation reflects that position and velocity vectors of a point, {{math|(''x'', ''y'', ''z'')}} and {{math|(''dx'', ''dy'', ''dz'')}}, traveling on the sphere are always [[Orthogonality|orthogonal]] to each other.

A sphere can also be constructed as the surface formed by rotating a [[circle]] about any of its [[diameter]]s. Since a circle is a special type of [[ellipse]], a sphere is a special type of [[ellipsoid of revolution]]. Replacing the circle with an ellipse rotated about its [[major axis]], the shape becomes a prolate [[spheroid]]; rotated about the minor axis, an oblate spheroid.&lt;ref&gt;{{harvnb|Albert|2016|loc=p. 60}}&lt;/ref&gt;

== Enclosed volume{{anchor|Volume}} ==
[[File:Esfera ArquÃ­medes0.svg|thumb|Sphere and circumscribed cylinder]]

In three dimensions, the [[volume]] inside a sphere (that is, the volume of a [[ball (mathematics)|ball]], but classically referred to as the volume of a sphere) is 
: &lt;math&gt;V = \frac{4}{3}\pi r^3,&lt;/math&gt;
where {{mvar|r}} is the radius of the sphere. [[Archimedes]] first derived this formula, by showing that the volume inside a sphere is twice the volume between the sphere and the [[circumscribe]]d [[cylinder (geometry)|cylinder]] of that sphere (having the height and diameter equal to the diameter of the sphere).&lt;ref&gt;{{harvnb|Steinhaus|1969|loc=p. 223}}&lt;/ref&gt; This assertion can be obtained from [[Cavalieri's principle]]. This formula can also be derived using [[integral calculus]], i.e. [[disk integration]] to sum the volumes of an [[infinite number]] of [[Circle#Properties|circular]] disks of infinitesimally small thickness stacked side by side and centered along the {{mvar|x}}-axis from {{math|1=''x'' = â''r''}}  to {{math|1=''x'' = ''r''}}, assuming the sphere of radius {{mvar|r}} is centered at the origin. 

At any given {{mvar|x}}, the incremental volume ({{mvar|Î´V}}) equals the product of the cross-sectional [[area of a disk#Onion proof|area of the disk]] at {{mvar|x}} and its thickness ({{mvar|Î´x}}):
: &lt;math&gt;\delta V \approx \pi y^2 \cdot \delta x.&lt;/math&gt;

The total volume is the summation of all incremental volumes:
: &lt;math&gt;V \approx \sum \pi y^2 \cdot \delta x.&lt;/math&gt;

In the limit as {{mvar|Î´x}} approaches zero&lt;ref name="delta"/&gt; this equation becomes:
: &lt;math&gt;V = \int_{-r}^{r} \pi y^2 dx.&lt;/math&gt;

At any given {{mvar|x}}, a right-angled triangle connects {{mvar|x}}, {{mvar|y}} and {{mvar|r}} to the origin; hence, applying the [[Pythagorean theorem]] yields:
: &lt;math&gt;y^2 = r^2 - x^2.&lt;/math&gt;

Using this substitution gives
: &lt;math&gt;V = \int_{-r}^{r} \pi (r^2 - x^2)dx,&lt;/math&gt;

that can be evaluated to give the result
: &lt;math&gt;V = \pi \left[r^2x - \frac{x^3}{3} \right]_{-r}^{r} = \pi \left(r^3 - \frac{r^3}{3} \right) - \pi \left(-r^3 + \frac{r^3}{3} \right) = \frac43\pi r^3.&lt;/math&gt;

Alternatively, this formula is found using [[spherical coordinates]], with volume element
: &lt;math&gt; dV=r^2\sin\theta\, dr\, d\theta\, d\varphi&lt;/math&gt;
so
: &lt;math&gt;V=\int_0^{2\pi} \int_{0}^{\pi} \int_0^r r'^2\sin\theta\, dr'\, d\theta\, d\varphi  
= 2\pi \int_{0}^{\pi} \int_0^r r'^2\sin\theta\, dr'\, d\theta 
= 4\pi \int_0^r r'^2\, dr'\ 
=\frac43\pi r^3.&lt;/math&gt;
For most practical purposes, the volume inside a sphere [[Inscribed figure|inscribed]] in a cube can be approximated as 52.4% of the volume of the cube, since {{math|1=''V'' = {{sfrac|{{pi}}|6}} ''d''&lt;sup&gt;3&lt;/sup&gt;}}, where {{mvar|d}} is the diameter of the sphere and also the length of a side of the cube and {{sfrac|{{pi}}|6}}&amp;nbsp;â&amp;nbsp;0.5236. For example, a sphere with diameter 1 meter has 52.4% the volume of a cube with edge length 1 meter, or about 0.524&amp;nbsp;m&lt;sup&gt;3&lt;/sup&gt;.

==Surface area{{anchor|Area}}==
&lt;!-- [[Surface area of a sphere]] is a redirect that points to this section --&gt;

The [[surface area]] of a sphere of radius {{mvar|r}} is:
:&lt;math&gt;A = 4\pi r^2.&lt;/math&gt;

[[Archimedes]] first derived this formula&lt;ref name=MathWorld_Sphere&gt;{{MathWorld |title=Sphere |id=Sphere}}&lt;/ref&gt; from the fact that the projection to the lateral surface of a [[circumscribe]]d cylinder is area-preserving.&lt;ref&gt;{{harvnb|Steinhaus|1969|loc=p. 221}}&lt;/ref&gt; Another approach to obtaining the formula comes from the fact that it equals the [[derivative]] of the formula for the volume with respect to {{mvar|r}} because the total volume inside a sphere of radius {{mvar|r}} can be thought of as the summation of the surface area of an infinite number of spherical shells of infinitesimal thickness concentrically stacked inside one another from radius 0 to radius {{mvar|r}}. At infinitesimal thickness the discrepancy between the inner and outer surface area of any given shell is infinitesimal, and the elemental volume at radius {{mvar|r}} is simply the product of the surface area at radius {{mvar|r}} and the infinitesimal thickness.

At any given radius {{mvar|r}},&lt;ref&gt;{{mvar|r}} is being considered as a variable in this computation&lt;/ref&gt; the incremental volume ({{mvar|Î´V}}) equals the product of the surface area at radius {{mvar|r}} ({{math|''A''(''r'')}}) and the thickness of a shell ({{mvar|Î´r}}):
:&lt;math&gt;\delta V \approx A(r) \cdot \delta r. &lt;/math&gt;

The total volume is the summation of all shell volumes:
:&lt;math&gt;V \approx \sum A(r) \cdot \delta r.&lt;/math&gt;

In the limit as {{mvar|Î´r}} approaches zero&lt;ref name="delta"&gt;Pages 141, 149. {{cite book
|author1=E. J. Borowski |author2=J. M. Borwein |title=Collins Dictionary of Mathematics
|isbn=0-00-434347-6}}&lt;/ref&gt; this equation becomes:
:&lt;math&gt;V = \int_0^r A(r) \, dr.&lt;/math&gt;

Substitute {{mvar|V}}:
:&lt;math&gt;\frac43\pi r^3 = \int_0^r A(r) \, dr.&lt;/math&gt;

Differentiating both sides of this equation with respect to {{mvar|r}} yields {{mvar|A}} as a function of {{mvar|r}}:
:&lt;math&gt;4\pi r^2 = A(r).&lt;/math&gt;

This is generally abbreviated as:
:&lt;math&gt;A = 4\pi r^2,&lt;/math&gt;
where {{mvar|r}} is now considered to be the fixed radius of the sphere.

Alternatively, the [[area element]] on the sphere is given in [[spherical coordinates]] by {{math|1=''dA'' = ''r''&lt;sup&gt;2&lt;/sup&gt; sin ''Î¸ dÎ¸ dÏ''}}. In [[Cartesian coordinates]], the area element is
: &lt;math&gt;dS=\frac{r}{\sqrt{r^{2}-{\displaystyle \sum_{i\ne k}x_{i}^{2}}}}\prod_{i\ne k}dx_{i},\;\forall k.&lt;/math&gt; 
For more generality, see [[Volume element|area element]].

The total area can thus be obtained by [[Integral|integration]]:
:&lt;math&gt;A = \int_0^{2\pi} \int_0^\pi r^2 \sin\theta \, d\theta \, d\varphi = 4\pi r^2.&lt;/math&gt;

The sphere has the smallest surface area of all surfaces that enclose a given volume, and it encloses the largest volume among all closed surfaces with a given surface area. The sphere therefore appears in nature: for example, bubbles and small water drops are roughly spherical because the [[surface tension]] locally minimizes surface area.

The surface area relative to the mass of a ball is called the [[specific surface area]] and can be expressed from the above stated equations as
:&lt;math&gt;\mathrm{SSA} = \frac{A}{V\rho} = \frac{3}{r\rho},&lt;/math&gt;
where {{mvar|Ï}} is the [[density]] (the ratio of mass to volume).

==Geometric properties==
A sphere is uniquely determined by four points that are not [[coplanar]]. More generally, a sphere is uniquely determined by four conditions such as passing through a point, being tangent to a plane, etc.&lt;ref&gt;{{harvnb|Albert|2016|loc=p. 55}}&lt;/ref&gt; This property is analogous to the property that three [[collinear|non-collinear]] points determine a unique circle in a plane.

Consequently, a sphere is uniquely determined by (that is, passes through) a circle and a point not in the plane of that circle.

By examining the [[Circle of a sphere#Sphere-sphere intersection|common solutions of the equations of two spheres]], it can be seen that two spheres intersect in a circle and the plane containing that circle is called the '''radical plane''' of the intersecting spheres.&lt;ref&gt;{{harvnb|Albert|2016|loc=p. 57}}&lt;/ref&gt; Although the radical plane is a real plane, the circle may be imaginary (the spheres have no real point in common) or consist of a single point (the spheres are tangent at that point).&lt;ref name=Woods267&gt;{{harvnb|Woods|1961|loc=p. 267}}&lt;/ref&gt;

The angle between two spheres at a real point of intersection is the [[dihedral angle]] determined by the tangent planes to the spheres at that point. Two spheres intersect at the same angle at all points of their circle of intersection.&lt;ref&gt;{{harvnb|Albert|2016|loc=p. 58}}&lt;/ref&gt; They intersect at right angles (are [[Orthogonality|orthogonal]]) if and only if the squares of the distance between their centers is equal to the sum of the squares of their radii.&lt;ref name=Woods266 /&gt;

===Pencil of spheres===
If {{math|1=''f''(''x'', ''y'', ''z'') = 0}} and {{math|1=''g''(''x'', ''y'', ''z'') = 0}} are the equations of two distinct spheres then 
:&lt;math&gt;s f(x,y,z) + t g(x,y,z) = 0&lt;/math&gt;
is also the equation of a sphere for arbitrary values of the parameters {{mvar|s}} and {{mvar|t}}. The set of all spheres satisfying this equation is called a '''pencil of spheres''' determined by the original two spheres. In this definition a sphere is allowed to be a plane (infinite radius, center at infinity) and if both the original spheres are planes then all the spheres of the pencil are planes, otherwise there is only one plane (the radical plane) in the pencil.&lt;ref name=Woods266 /&gt;

If the pencil of spheres does not consist of all planes, then there are three types of pencils:&lt;ref name=Woods267 /&gt;
*If the spheres intersect in a real circle {{mvar|C}}, then the pencil consists of all the spheres containing {{mvar|C}}, including the radical plane. The centers of all the ordinary spheres in the pencil lie on a line passing through the center of {{mvar|C}} and perpendicular to the radical plane.
*If the spheres intersect in an imaginary circle, all the spheres of the pencil also pass through this imaginary circle but as ordinary spheres they are disjoint (have no real points in common). The line of centers is perpendicular to the radical plane, which is a real plane in the pencil containing the imaginary circle.
*If the spheres intersect in a point {{mvar|A}}, all the spheres in the pencil are tangent at {{mvar|A}} and the radical plane is the common tangent plane of all these spheres. The line of centers is perpendicular to the radical plane at {{mvar|A}}.

All the tangent lines from a fixed point of the radical plane to the spheres of a pencil have the same length.&lt;ref name=Woods267 /&gt;

The radical plane is the locus of the centers of all the spheres that are orthogonal to all the spheres in a pencil. Moreover, a sphere orthogonal to any two spheres of a pencil of spheres is orthogonal to all of them and its center lies in the radical plane of the pencil.&lt;ref name=Woods267 /&gt;

==Terminology==
Pairs of points on a sphere that lie on a straight line through the sphere's center are called [[antipodal point]]s. A [[great circle]] is a circle on the sphere that has the same center and radius as the sphere and, consequently, divides it into two equal parts. The [[plane section]]s of a sphere are called ''spheric sections''. They are all circles and those that are not great circles are called [[Circle of a sphere|''small circles'']].&lt;ref&gt;{{MathWorld |id=SphericSection |title=Spheric section}}&lt;/ref&gt; 

The shortest distance along the surface between two distinct non-antipodal points on the sphere is the length of the smaller of the two arcs on the unique great circle that includes the two points. Equipped with this "[[great-circle distance]]", a great circle becomes the [[Riemannian circle]].

If a particular point on a sphere is (arbitrarily) designated as its ''north pole'', then the corresponding antipodal point is called the ''south pole'', and the [[equator]] is the great circle that is equidistant to them. Great circles through the two poles are called lines (or [[meridian (geography)|meridians]]) of [[longitude]], and the line connecting the two poles is called the [[axis of rotation]]. Circles on the sphere that are parallel to the equator are lines of [[latitude]]. This terminology is also used for such approximately [[spheroid]]al [[astronomical bodies]] as the planet [[Earth]] (see [[geoid]]).

==Hemisphere==
{{anchor|hemisphere}}

Any plane that includes the center of a sphere divides it into two equal '''hemispheres'''. Any two intersecting planes that include the center of a sphere subdivide the sphere into four [[spherical lune|lunes]] or biangles, the vertices of which all coincide with the [[antipodal point]]s lying on the line of intersection of the planes.

The antipodal quotient of the sphere is the surface called the [[real projective plane]], which can also be thought of as the [[northern hemisphere]] with antipodal points of the equator identified.

The hemisphere is [[filling area conjecture|conjectured]] to be the optimal (least area) isometric filling of the [[Riemannian circle]].

==Generalizations==
===Dimensionality===
{{Main|n-sphere}}
Spheres can be generalized to spaces of any number of [[dimension]]s. For any [[natural number]] {{mvar|n}}, an "{{mvar|n}}-sphere," often written as {{math|''S''&lt;sup&gt;''n''&lt;/sup&gt;}}, is the set of points in ({{math|''n'' + 1}})-dimensional Euclidean space that are at a fixed distance {{mvar|r}} from a central point of that space, where {{mvar|r}} is, as before, a positive real number. In particular:
*{{math|''S''&lt;sup&gt;0&lt;/sup&gt;}}: a 0-sphere is a pair of endpoints of an interval {{math|[â''r'', ''r'']}} of the real line
*{{math|''S''&lt;sup&gt;1&lt;/sup&gt;}}: a 1-sphere is a [[circle]] of radius ''r''
*{{math|''S''&lt;sup&gt;2&lt;/sup&gt;}}: a 2-sphere is an ordinary sphere
*{{math|''S''&lt;sup&gt;3&lt;/sup&gt;}}: a [[3-sphere]] is a sphere in 4-dimensional Euclidean space.

Spheres for {{math|''n'' &gt; 2}} are sometimes called [[hypersphere]]s.

The {{mvar|n}}-sphere of unit radius centered at the origin is denoted {{math|''S''&lt;sup&gt;''n''&lt;/sup&gt;}} and is often referred to as "the" {{mvar|n}}-sphere. Note that the ordinary sphere is a 2-sphere, because it is a 2-dimensional surface (which is embedded in 3-dimensional space).

The surface area of the unit ({{math|''n''-1}})-sphere is
:&lt;math&gt;\frac{2 \pi^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)}&lt;/math&gt;

where {{math|Î(''z'')}} is Euler's [[gamma function]].

Another expression for the surface area is
:&lt;math&gt; \begin{cases}
 \displaystyle \frac{(2\pi)^{n/2}\,r^{n-1}}{2 \cdot 4 \cdots (n-2)}, &amp; \text{if } n \text{ is even}; \\ \\
 \displaystyle \frac{2(2\pi)^{(n-1)/2}\,r^{n-1}}{1 \cdot 3 \cdots (n-2)}, &amp; \text{if } n \text{ is odd}.
 \end{cases}&lt;/math&gt;

and the volume is the surface area times {{math|{{sfrac|''r''|''n''}}}} or
:&lt;math&gt; \begin{cases}
 \displaystyle \frac{(2\pi)^{n/2}\,r^n}{2 \cdot 4 \cdots n}, &amp; \text{if } n \text{ is even}; \\ \\
 \displaystyle \frac{2(2\pi)^{(n-1)/2}\,r^n}{1 \cdot 3 \cdots n}, &amp; \text{if } n \text{ is odd}.
 \end{cases}&lt;/math&gt;

General recursive formulas also exist for the [[volume of an n-ball|volume of an {{mvar|n}}-ball]].

===Metric spaces===
More generally, in a [[metric space]] {{math|(''E'',''d'')}}, the sphere of center {{mvar|x}} and radius {{math|''r'' &gt; 0}} is the set of points {{mvar|y}} such that {{math|1=''d''(''x'',''y'') = ''r''}}.

If the center is a distinguished point that is considered to be the origin of {{mvar|E}}, as in a [[norm (mathematics)|normed]] space, it is not mentioned in the definition and notation. The same applies for the radius if it is taken to equal one, as in the case of a [[unit sphere]].

Unlike a [[ball (mathematics)|ball]], even a large sphere may be an empty set. For example, in {{math|'''Z'''&lt;sup&gt;''n''&lt;/sup&gt;}} with [[Euclidean metric]], a sphere of radius {{math|''r''}} is nonempty only if {{math|''r''&lt;sup&gt;2&lt;/sup&gt;}} can be written as sum of {{math|''n''}} squares of [[integer]]s.

==Topology==
In [[topology]], an {{mvar|n}}-sphere is defined as a space [[homeomorphic]] to the boundary of an [[ball (mathematics)#Topological balls|{{math|(''n'' + 1)}}-ball]]; thus, it is [[homeomorphic]] to the Euclidean {{mvar|n}}-sphere, but perhaps lacking its [[Metric space|metric]].
*A 0-sphere is a pair of points with the [[discrete topology]].
*A 1-sphere is a circle ([[up to]] [[homeomorphism]]); thus, for example, (the image of) any [[Knot (mathematics)|knot]] is a 1-sphere.
*A 2-sphere is an ordinary sphere ([[up to]] [[homeomorphism]]); thus, for example, any [[spheroid]] is a 2-sphere.

The {{mvar|n}}-sphere is denoted {{math|''S&lt;sup&gt;n&lt;/sup&gt;''}}. It is an example of a [[compact space|compact]] [[topological manifold]] without [[Boundary (topology)|boundary]]. A sphere need not be [[Manifold#Differentiable manifolds|smooth]]; if it is smooth, it need not be [[diffeomorphic]] to the Euclidean sphere.

The [[HeineâBorel theorem]] implies that a Euclidean {{mvar|n}}-sphere is compact. The sphere is the inverse image of a one-point set under the continuous function {{math|{{norm|''x''}}}}. Therefore, the sphere is closed. {{math|''S&lt;sup&gt;n&lt;/sup&gt;''}} is also bounded; therefore it is compact.

Remarkably, it is possible to turn an ordinary sphere inside out in a [[three-dimensional space]] with possible self-intersections but without creating any crease, in a process called [[sphere eversion]].

==Spherical geometry==
[[Image:Sphere halve.png|thumb|right|[[Great circle]] on a sphere]]
{{Main|Spherical geometry}}
The basic elements of [[Euclidean plane geometry]] are [[Point (geometry)|points]] and [[line (mathematics)|lines]]. On the sphere, points are defined in the usual sense. The analogue of the "line" is the [[geodesic]], which is a [[great circle]]; the defining characteristic of a great circle is that the plane containing all its points also passes through the center of the sphere. Measuring by [[arc length]] shows that the shortest path between two points lying on the sphere is the shorter segment of the [[great circle]] that includes the points.

Many theorems from [[classical geometry]] hold true for spherical geometry as well, but not all do because the sphere fails to satisfy some of classical geometry's [[postulate]]s, including the [[parallel postulate]]. In [[spherical trigonometry]], [[angle]]s are defined between great circles. Spherical trigonometry differs from ordinary [[trigonometry]] in many respects. For example, the sum of the interior angles of a [[spherical triangle]] always exceeds 180&amp;nbsp;degrees. Also, any two [[similar triangles|similar]] spherical triangles are congruent.

==Eleven properties of the sphere==
[[Image:Sphere section.png|thumb|A normal vector to a sphere, a normal plane and its normal section. The curvature of the curve of intersection is the sectional curvature. For the sphere each normal section through a given point will be a circle of the same radius: the radius of the sphere. This means that every point on the sphere will be an umbilical point.]]

In their book ''Geometry and the Imagination''&lt;ref&gt;{{cite book
|author=[[David Hilbert|Hilbert, David]]; Cohn-Vossen, Stephan
|title=Geometry and the Imagination
|edition=2nd
|year=1952
|publisher=Chelsea
|isbn=0-8284-1087-9}}&lt;/ref&gt; [[David Hilbert]] and [[Stephan Cohn-Vossen]] describe eleven properties of the sphere and discuss whether these properties uniquely determine the sphere. Several properties hold for the [[plane (mathematics)|plane]], which can be thought of as a sphere with infinite radius. These properties are:
#''The points on the sphere are all the same distance from a fixed point. Also, the ratio of the distance of its points from two fixed points is constant.''
#:The first part is the usual definition of the sphere and determines it uniquely. The second part can be easily deduced and follows a similar [[Circle#Circle of Apollonius|result]] of [[Apollonius of Perga]] for the [[circle]]. This second part also holds for the [[plane (mathematics)|plane]].
#''The contours and plane sections of the sphere are circles.''
#:This property defines the sphere uniquely.
#''The sphere has constant width and constant girth.''
#:The width of a surface is the distance between pairs of parallel tangent planes. Numerous other closed convex surfaces have constant width, for example the [[Meissner body]]. The girth of a surface is the [[circumference]] of the boundary of its orthogonal projection on to a plane. Each of these properties implies the other.
#''All points of a sphere are [[umbilic]]s.''
#:At any point on a surface a [[Normal (geometry)|normal direction]] is at right angles to the surface because the sphere these are the lines radiating out from the center of the sphere. The intersection of a plane that contains the normal with the surface will form a curve that is called a ''normal section,'' and the curvature of this curve is the ''normal curvature''. For most points on most surfaces, different sections will have different curvatures; the maximum and minimum values of these are called the [[principal curvature]]s. Any closed surface will have at least four points called ''[[umbilical point]]s''. At an umbilic all the sectional curvatures are equal; in particular the [[principal curvature]]s are equal. Umbilical points can be thought of as the points where the surface is closely approximated by a sphere.
#:For the sphere the curvatures of all normal sections are equal, so every point is an umbilic. The sphere and plane are the only surfaces with this property.
#''The sphere does not have a surface of centers.''
#:For a given normal section exists a circle of curvature that equals the sectional curvature, is tangent to the surface, and the center lines of which lie along on the normal line. For example, the two centers corresponding to the maximum and minimum sectional curvatures are called the ''focal points'', and the set of all such centers forms the [[focal surface]].
#:For most surfaces the focal surface forms two sheets that are each a surface and meet at umbilical points. Several cases are special:
#:* For [[channel surface]]s one sheet forms a curve and the other sheet is a surface
#:* For [[Cone (geometry)|cones]], cylinders, [[torus|tori]] and [[Dupin cyclide|cyclides]] both sheets form curves.
#:* For the sphere the center of every osculating circle is at the center of the sphere and the focal surface forms a single point. This property is unique to the sphere.
#''All geodesics of the sphere are closed curves.''
#:[[Geodesics]] are curves on a surface that give the shortest distance between two points. They are a generalization of the concept of a straight line in the plane. For the sphere the geodesics are great circles. Many other surfaces share this property.
#''Of all the solids having a given volume, the sphere is the one with the smallest surface area; of all solids having a given surface area, the sphere is the one having the greatest volume.''
#:It follows from [[isoperimetric inequality]]. These properties define the sphere uniquely and can be seen in [[soap bubble]]s: a soap bubble will enclose a fixed volume, and [[surface tension]] minimizes its surface area for that volume. A freely floating soap bubble therefore approximates a sphere (though such external forces as gravity will slightly distort the bubble's shape).
#''The sphere has the smallest total mean curvature among all convex solids with a given surface area.''
#:The [[mean curvature]] is the average of the two principal curvatures, which is constant because the two principal curvatures are constant at all points of the sphere.
#''The sphere has constant mean curvature.''
#:The sphere is the only imbedded surface that lacks boundary or singularities with constant positive mean curvature. Other such immersed surfaces as [[minimal surface]]s have constant mean curvature.
#''The sphere has constant positive Gaussian curvature.''
#:[[Gaussian curvature]] is the product of the two principal curvatures. It is an intrinsic property that can be determined by measuring length and angles and is independent of how the surface is [[embedding|embedded]] in space. Hence, bending a surface will not alter the Gaussian curvature, and other surfaces with constant positive Gaussian curvature can be obtained by cutting a small slit in the sphere and bending it. All these other surfaces would have boundaries, and the sphere is the only surface that lacks a boundary with constant, positive Gaussian curvature. The [[pseudosphere]] is an example of a surface with constant negative Gaussian curvature.
#''The sphere is transformed into itself by a three-parameter family of rigid motions.''
#:Rotating around any axis a unit sphere at the origin will map the sphere onto itself. Any rotation about a line through the origin can be expressed as a combination of rotations around the three-coordinate axis (see [[Euler angles]]). Therefore, a three-parameter family of rotations exists such that each rotation transforms the sphere onto itself; this family is the [[rotation group SO(3)]]. The plane is the only other surface with a three-parameter family of transformations (translations along the {{mvar|x}}- and {{mvar|y}}-axes and rotations around the origin). Circular cylinders are the only surfaces with two-parameter families of rigid motions and the [[Surface of revolution|surfaces of revolution]] and [[helicoid]]s are the only surfaces with a one-parameter family.

== Gallery ==
&lt;gallery mode=packed heights="200px" style="text-align:left"&gt;
Image:Einstein gyro gravity probe b.jpg|An image of one of the most accurate human-made spheres, as it [[refraction|refracts]] the image of [[Albert Einstein|Einstein]] in the background. This sphere was a [[fused quartz]] [[gyroscope]] for the [[Gravity Probe B]] experiment, and differs in shape from a perfect sphere by no more than 40 atoms (less than 10 [[nanometers]]) of thickness. It was announced on 1 July 2008 that [[Australia]]n scientists had created even more nearly perfect spheres, accurate to 0.3&amp;nbsp;nanometers, as part of an international hunt to find a new global standard [[kilogram]].&lt;ref&gt;[https://www.newscientist.com/article/dn14229-roundest-objects-in-the-world-created.html New Scientist | Technology | Roundest objects in the world created]&lt;/ref&gt;
File:King of spades- spheres.jpg|Deck of playing cards illustrating engineering instruments, England, 1702. [[King of spades]]: Spheres
&lt;/gallery&gt;

==See also==
{{div col||colwidth=20em}}
*[[3-sphere]]
*[[Affine sphere]]
*[[Alexander horned sphere]]
*[[Celestial spheres]]
*[[Cube]]
*[[Curvature]]
*[[Directional statistics]]
*[[Dome (mathematics)]]
*[[Dyson sphere]]
*[[Hand with Reflecting Sphere]], [[M.C. Escher]] self-portrait drawing illustrating reflection and the optical properties of a mirror sphere
*[[Hoberman sphere]]
*[[Homology sphere]]
*[[Homotopy groups of spheres]]
*[[Homotopy sphere]]
*[[Hypersphere]]
*[[Lenart Sphere]]
*[[Napkin ring problem]]
*[[Orb (optics)]]
*[[Pseudosphere]]
*[[Riemann sphere]]
*[[Solid angle]]
*[[Sphere packing]]
*[[Spherical cap]]
*[[Spherical coordinates]]
*[[Spherical Earth]]
*Spherical helix, [[tangent indicatrix]] of a curve of constant precession
*[[Spherical sector]]
*[[Spherical segment]]
*[[Spherical shell]]
*[[Spherical wedge]]
*[[Spherical zone]]
*[[Zoll surface|Zoll sphere]]
{{div col end}}

==Notes==
{{reflist}}

==References==
{{Wikisource1911Enc|Sphere}}
*{{citation|first=Abraham Adrian|last=Albert|title=Solid Analytic Geometry|year=2016|origyear=1949|publisher=Dover|isbn=978-0-486-81026-3}}
*{{cite book|first=William |last=Dunham |pages=28,&amp;nbsp;226 |title=The Mathematical Universe: An Alphabetical Journey Through the Great Proofs, Problems and Personalities |isbn=0-471-17661-3 }}
* {{ citation | first1 = Erwin | last1 = Kreyszig | year = 1972 | isbn = 0-471-50728-8 | title = Advanced Engineering Mathematics | edition = 3rd | publisher = [[John Wiley &amp; Sons|Wiley]] | location = New York }}
*{{citation|first=H.|last=Steinhaus|title=Mathematical Snapshots|year=1969|publisher=Oxford University Press|edition=Third American}}
*{{citation|first=Frederick S.|last=Woods|title=Higher Geometry / An Introduction to Advanced Methods in Analytic Geometry|year=1961|origyear=1922|publisher=Dover}}

==External links==
{{Sister project links}}
*[[planetmath:186|Sphere (PlanetMath.org website)]]
*{{MathWorld |id=Sphere |title=Sphere}}
*[[Wikibooks:Mathematica/Uniform Spherical Distribution|Mathematica/Uniform Spherical Distribution]]
*[http://mathschallenge.net/index.php?section=faq&amp;ref=geometry/surface_sphere Surface area of sphere proof.]
{{Use dmy dates|date=March 2011}}

{{Authority control}}

[[Category:Differential geometry]]
[[Category:Differential topology]]
[[Category:Elementary geometry]]
[[Category:Elementary shapes]]
[[Category:Homogeneous spaces]]
[[Category:Spheres| ]]
[[Category:Surfaces]]
[[Category:Topology]]</text>
      <sha1>8qtqanocnb3lfgwc3f3ujd8xjzqpdjk</sha1>
    </revision>
  </page>
  <page>
    <title>Ternary relation</title>
    <ns>0</ns>
    <id>3784565</id>
    <revision>
      <id>869195738</id>
      <parentid>866723147</parentid>
      <timestamp>2018-11-17T00:56:44Z</timestamp>
      <contributor>
        <username>StraussInTheHouse</username>
        <id>32545823</id>
      </contributor>
      <minor/>
      <comment>/* top */unreferenced to refimprove</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6230">{{refimprove|date=December 2009}}
In [[mathematics]], a '''ternary relation''' or '''triadic relation''' is a [[finitary relation]] in which the number of places in the relation is three.  Ternary relations may also be referred to as '''3-adic''', '''3-ary''', '''3-dimensional''', or '''3-place'''.

Just as a [[binary relation]] is formally defined as a set of ''pairs'', i.e. a subset of the [[Cartesian product]] {{Nowrap|''A'' Ã ''B''}} of some sets ''A'' and ''B'', so a ternary relation is a set of triples, forming a subset of the Cartesian product {{Nowrap|''A'' Ã ''B'' Ã ''C''}} of three sets ''A'', ''B'' and ''C''.

An example of a ternary relation in elementary geometry can be given on triples of points, where a triple is in the relation if the three points are [[Collinearity|collinear]]. Another geometric example can be obtained by considering triples consisting of two points and a line, where a triple is in the ternary relation if the two points determine (are [[Incidence (geometry)|incident]] with) the line.

==Examples==

===Binary functions===
{{further|Graph of a function|Binary function}}

A function {{Nowrap|''Æ'': ''A'' Ã ''B'' â ''C''}} in two variables, mapping two values from sets ''A'' and ''B'', respectively, to a value in ''C'' associates to every pair (''a'',''b'') in {{Nowrap|''A'' Ã ''B''}} an element ''Æ''(''a'',&amp;nbsp;''b'') in&amp;nbsp;''C''. Therefore, its graph consists of pairs of the form {{Nowrap|((''a'', ''b''), ''Æ''(''a'', ''b''))}}. Such pairs in which the first element is itself a pair are often identified with triples. This makes the graph of ''Æ'' a ternary relation between ''A'', ''B'' and ''C'', consisting of all triples {{Nowrap|(''a'', ''b'', ''Æ''(''a'', ''b''))}}, satisfying {{nowrap|''a'' in ''A''}}, {{nowrap|''b'' in ''B''}}, and {{nowrap|''Æ''(''a'', ''b'') in ''C''.}}

===Cyclic orders===
{{Main article|Cyclic order}}

Given any set ''A'' whose elements are arranged on a circle, one can define a ternary relation ''R'' on ''A'', i.e. a subset of ''A''&lt;sup&gt;3&lt;/sup&gt; = {{Nowrap|''A'' Ã ''A'' Ã ''A''}}, by stipulating that {{Nowrap|''R''(''a'', ''b'', ''c'')}} holds if and only if the elements ''a'', ''b'' and ''c'' are pairwise different and when going from ''a'' to ''c'' in a clockwise direction one passes through ''b''. For example, if ''A'' = { {{Nowrap|1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12}} } represents the hours on a [[clock face]], then {{Nowrap|''R''(8, 12, 4)}} holds and {{Nowrap|''R''(12, 8, 4)}} does not hold.

===Betweenness relations===
{{Main article|Betweenness relation}}
{{Expand section|date=May 2011}}

===Congruence relation===
{{Main article|Congruence modulo m}}

The ordinary congruence of arithmetics
:&lt;math&gt; a \equiv b \pmod{m}&lt;/math&gt;
which holds for three integers ''a'', ''b'', and ''m'' if and only if ''m'' divides ''a''&amp;nbsp;â&amp;nbsp;''b'', formally may be considered as a ternary relation.  However, usually, this instead is considered as a family of [[binary relation]]s between the ''a'' and the ''b'', indexed by the [[Modular arithmetic|modulus]] ''m''.  For each fixed ''m'', indeed this binary relation has some natural properties, like being an [[equivalence relation]]; while the combined ternary relation in general is not studied as one relation.

===Typing relation===
{{Main article|Simply typed lambda calculus#Typing rules}}

A ''typing relation'' &lt;math&gt;\Gamma\vdash e\!:\!\sigma&lt;/math&gt; indicates that &lt;math&gt;e&lt;/math&gt; is a term of type &lt;math&gt;\sigma&lt;/math&gt; in context &lt;math&gt;\Gamma&lt;/math&gt;, and is thus a ternary relation between contexts, terms and types.

===SchrÃ¶der rules===
A ternary relation &lt;math&gt;(A,\ B,\ C)&lt;/math&gt; can be defined in the [[category of relations|category of binary relations]] using [[composition of relations]] ''AB'' and [[inclusion (set theory)|inclusion]] ''AB'' â ''C''. Within the [[calculus of relations]] each relation ''A'' has a [[converse relation]] ''A''&lt;sup&gt;T&lt;/sup&gt; and a complement relation &lt;math&gt;\bar{A} .&lt;/math&gt; Using these [[involution (mathematics)|involution]]s, [[Augustus De Morgan]] and [[Ernst SchrÃ¶der]] showed that &lt;math&gt;(A,\ B,\ C)&lt;/math&gt;is equivalent to &lt;math&gt;(\bar{C}, B^T, \bar{A})&lt;/math&gt; and also equivalent to &lt;math&gt;(A^T,\  \bar{C},\  \bar{B}).&lt;/math&gt; The mutual equivalences of these forms, constructed from the ternary {{nowrap|relation (''A, B, C''),}} are called the [[composition of relations#SchrÃ¶der rules| SchrÃ¶der rules]].&lt;ref&gt;[[Gunther Schmidt]] &amp; Thomas StrÃ¶hlein (1993) ''Relations and Graphs'', pages 15â19, [[Springer books]]&lt;/ref&gt;

==References==
{{reflist}}

==Further reading==
{{Refbegin}}
*{{Citation |last=Myers |first=Dale |year=1997 |chapter=An interpretive isomorphism between binary and ternary relations |editor-first=Jan |editor-last=Mycielski |editor2-first=Grzegorz |editor2-last=Rozenberg |editor3-first=Arto |editor3-last=Salomaa |title=Structures in Logic and Computer Science |series=Lecture Notes in Computer Science |volume=1261 |publisher=Springer |isbn=3-540-63246-8 |pages=84â105 |doi=10.1007/3-540-63246-8_6}}
*{{Citation |last=NovÃ¡k |first=VÃ­tÄzslav |year=1996 |title=Ternary structures and partial semigroups |journal=Czechoslovak Mathematical Journal |volume=46 |issue=1 |pages=111â120 |hdl=10338.dmlcz/127275}}
*{{Citation |last=NovÃ¡k |first=VÃ­tÄzslav |last2=NovotnÃ½ |first2=Miroslav |year=1989 |title=Transitive ternary relations and quasiorderings |journal=Archivum Mathematicum |volume=25 |issue=1â2 |pages=5â12 |hdl=10338.dmlcz/107333}}
*{{Citation |last=NovÃ¡k |first=VÃ­tÄzslav |last2=NovotnÃ½ |first2=Miroslav |year=1992 |title=Binary and ternary relations |journal=Mathematica Bohemica |volume=117 |issue=3 |pages=283â292 |hdl=10338.dmlcz/126278}}
*{{Citation |last=NovotnÃ½ |first=Miroslav |year=1991 |title=Ternary structures and groupoids |journal=Czechoslovak Mathematical Journal |volume=41 |issue=1 |pages=90â98 |hdl=10338.dmlcz/102437}}
*{{Citation |last=Å lapal |first=Josef |year=1993 |title=Relations and topologies |journal=Czechoslovak Mathematical Journal |volume=43 |issue=1 |pages=141â150 |hdl=10338.dmlcz/128381}}
{{Refend}}

{{DEFAULTSORT:Ternary Relation}}
[[Category:Mathematical relations]]

[[ru:Ð¢ÐµÑÐ½Ð°ÑÐ½Ð¾Ðµ Ð¾ÑÐ½Ð¾ÑÐµÐ½Ð¸Ðµ]]</text>
      <sha1>tm61b3hn2nh5y6e83jrlj4jr4cka3nf</sha1>
    </revision>
  </page>
  <page>
    <title>Thomas W. Tucker</title>
    <ns>0</ns>
    <id>44249205</id>
    <revision>
      <id>659322449</id>
      <parentid>654056965</parentid>
      <timestamp>2015-04-26T17:43:26Z</timestamp>
      <contributor>
        <username>KasparBot</username>
        <id>24420788</id>
      </contributor>
      <comment>authority control moved to wikidata</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1633">'''Thomas William Tucker''' (born July 15, 1945) is an American mathematician, the Charles Hetherington Professor of Mathematics at [[Colgate University]],&lt;ref name="cv"&gt;[http://math.colgate.edu/faculty/tomtuck.html Faculty web page], retrieved 2014-10-29.&lt;/ref&gt; and an expert in the area of [[topological graph theory]].&lt;ref&gt;J. L. Gross and T. W. Tucker, Topological Graph Theory, Wiley Interscience, 1987&lt;/ref&gt;&lt;ref&gt;{{cite journal|author=Thomassen, Carsten|title=Review: ''Topological Graph Theory'', by Jonathan L. Gross and Thomas W. Tucker|journal=Bull. Amer. Math. Soc. (N.S.)|year=1988|volume=19|issue=2|pages=560â561|url=http://www.ams.org/journals/bull/1988-19-02/S0273-0979-1988-15742-4/S0273-0979-1988-15742-4.pdf|doi=10.1090/s0273-0979-1988-15742-4}}&lt;/ref&gt;

Tucker did his undergraduate studies at [[Harvard University]], graduating in 1967,&lt;ref name="cv"/&gt; and obtained his Ph.D. from [[Dartmouth College]] in 1971, under the supervision of Edward Martin Brown.&lt;ref&gt;{{mathgenealogy|name=Thomas William Tucker|id=38735}}&lt;/ref&gt; 

Tucker's father, [[Albert W. Tucker]], was also a professional mathematician, and his brother, [[Alan Tucker]], and son, [[Thomas J. Tucker]], are also professional mathematicians.

==References==
{{reflist}}

{{Authority control}}
{{DEFAULTSORT:Tucker, Thomas W.}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Harvard University alumni]]
[[Category:Dartmouth College alumni]]
[[Category:Colgate University faculty]]
[[Category:Graph theorists]]
[[Category:Living people]]
[[Category:1945 births]]


{{US-mathematician-stub}}</text>
      <sha1>4n6ujsf4upws1x1u16z70yb1tc2omzt</sha1>
    </revision>
  </page>
  <page>
    <title>Trillium theorem</title>
    <ns>0</ns>
    <id>49188683</id>
    <revision>
      <id>857619517</id>
      <parentid>857619448</parentid>
      <timestamp>2018-09-01T22:30:01Z</timestamp>
      <contributor>
        <username>Toploftical</username>
        <id>16162765</id>
      </contributor>
      <comment>/* Theorem */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7498">In [[Euclidean geometry]], the '''trillium theorem''' â (from {{lang-rus|Ð»ÐµÐ¼Ð¼Ð° Ð¾ ÑÑÐµÐ·ÑÐ±ÑÐµ}},&lt;ref name="rkarasev" /&gt;&lt;ref name="approaching-2014-10-29-inscribed-angles" /&gt; literally 'lemma about trident', {{lang-rus|ÑÐµÐ¾ÑÐµÐ¼Ð° ÑÑÐ¸Ð»Ð¸ÑÑÐ½Ð¸ÐºÐ°}},&lt;ref name="9pointcircle" /&gt; literally 'theorem of trillium' or 'theorem of trefoil') is a statement about properties of [[inscribed circle|inscribed]] and [[circumscribed circle]]s and their relations.

== Theorem ==
[[File:Trillium theorem.svg|thumb|upright=1.2|Trillium theorem]]
Let {{mvar|ABC}} be an arbitrary [[triangle]].  Let {{mvar|I}} be its [[incenter]] and let {{mvar|D}} be the point where line {{mvar|BI}} (the [[angle bisector]] of {{math|â ''ABC''}}) crosses the [[Circumscribed circle|circumcircle]] of {{mvar|ABC}}. Then, the theorem states that {{mvar|D}} is [[equidistant]] from {{mvar|A}}, {{mvar|C}}, and {{mvar|I}}.
Equivalently:
*The circle through {{mvar|A}}, {{mvar|C}}, and {{mvar|I}} has its center at {{mvar|D}}. In particular, this implies that the center of this circle lies on the circumcircle.&lt;ref&gt;{{citation
 | last = Morris | first = Richard
 | issue = 2
 | journal = [[The Mathematics Teacher]]
 | jstor = 27951001
 | pages = 63â71
 | title = Circles through notable points of the triangle
 | volume = 21
 | year = 1928}}. See in particular the discussion on p.&amp;nbsp;65 of circles {{mvar|BIC}}, {{mvar|CIA}}, {{mvar|AIB}}, and their centers.&lt;/ref&gt;&lt;ref&gt;{{citation|url=http://www.cut-the-knot.org/m/Geometry/OnePropertyOfCircleThroughIncenter.shtml|title=A Property of Circle Through the Incenter|work=Cut-the-Knot|author=[[Alexander Bogomolny|Bogomolny, Alexander]]|accessdate=2016-01-26}}.&lt;/ref&gt;
*The three triangles {{mvar|AID}}, {{mvar|CID}}, and {{mvar|ACD}} are [[isosceles triangle|isosceles]], with {{mvar|D}} as their apex.
A fourth point, the [[excenter]] of {{mvar|ABC}} relative to {{mvar|B}}, also lies at the same distance from {{mvar|D}}, diametrally opposite from {{mvar|I}}.&lt;ref name="approaching-2014-10-29-inscribed-angles" /&gt;&lt;ref&gt;{{citation|url=http://www.cut-the-knot.org/Curriculum/Geometry/InExCircum.shtml|title=Midpoints of the Lines Joining In- and Excenters|work=[[Cut-the-Knot]]|first=Alexander|last=Bogomolny|accessdate=2016-01-26}}.&lt;/ref&gt;

== Proof ==

By the [[Inscribed angle|inscribed angle theorem]],

: &lt;math&gt;|\angle ABI| = |\angle DCA|, \quad |\angle CBI| = |\angle DAC|. &lt;/math&gt;

Since &lt;math&gt;BI&lt;/math&gt; is angle bisector,

: &lt;math&gt;
\begin{align}
&amp; |\angle DCA| = |\angle DAC| \\[6pt]
\Rightarrow {} &amp; |AD| = |CD|, \text{ and }  |\angle DIA| = 180^\circ - |\angle AIB| \\[6pt]
= {} &amp; 180^\circ - (180^\circ - |\angle IAB| - |\angle IBA|) \\[6pt]
= {} &amp; |\angle IAB| + |\angle IBA|= |\angle IAC| + |\angle CAD| \\[6pt]
= {} &amp; |\angle IAD| \\[6pt]
\Rightarrow {} &amp; |AD| = |DI|.
\end{align}
&lt;/math&gt;

==Application to triangle reconstruction==
This theorem can be used to reconstruct a triangle starting from the locations only of one vertex, the incenter, and the circumcenter of the triangle.
For, let {{mvar|B}} be the given vertex, {{mvar|I}} be the incenter, and {{mvar|O}} be the circumcenter. This information allows the successive construction of:
*the circumcircle of the given triangle, as the circle with center {{mvar|O}} and radius {{mvar|OB}},
*point {{mvar|D}} as the intersection of the circumcircle with line {{mvar|BI}},
*the circle of the Ã² theorem, with center {{mvar|D}} and radius {{mvar|DI}}, and
*vertices {{mvar|A}} and {{mvar|C}} as the intersection points of the two circles.&lt;ref&gt;{{citation|title=Problems and Solutions in Euclidean Geometry|series=Dover Books on Mathematics|first1=M. N.|last1=Aref|first2=William|last2=Wernick|publisher=Dover Publications, Inc.|year=1968|isbn=9780486477206|at=3.3(i), p.&amp;nbsp;68|url=https://books.google.com/books?id=vAcU7jOFhG4C&amp;pg=PA68}}.&lt;/ref&gt;
However, for some triples of points {{mvar|B}}, {{mvar|I}}, and {{mvar|O}}, this construction may fail, either because line {{mvar|IB}} is tangent to the circumcircle or because the two circles do not have two crossing points. It may also produce a triangle for which the given point {{mvar|I}} is an excenter rather than the incenter. In these cases, there can be no triangle having {{mvar|B}} as vertex, {{mvar|I}} as incenter, and {{mvar|O}} as circumcenter.&lt;ref name="yiu"&gt;{{citation
 | last = Yiu | first = Paul
 | issue = 2
 | journal = Journal for Geometry and Graphics
 | mr = 3088369
 | pages = 171â183
 | title = Conic construction of a triangle from its incenter, nine-point center, and a vertex
 | url = http://math.fau.edu/Yiu/j16h2yiu.pdf
 | volume = 16
 | year = 2012}}&lt;/ref&gt;

Other triangle reconstruction problems, such as the reconstruction of a triangle from a vertex, incenter, and center of its [[nine-point circle]], can be solved by reducing the problem to the case of a vertex, incenter, and circumcenter.&lt;ref name="yiu"/&gt;

==Generalization==
Let {{mvar|I}} and {{mvar|J}} be any two of the four points given by the incenter and the three excenters of a triangle {{mvar|ABC}}. Then {{mvar|I}} and {{mvar|J}} are collinear with one of the three triangle vertices. The circle with {{mvar|IJ}} as diameter passes through the other two vertices and is centered on the circumcircle of {{mvar|ABC}}. When one of {{mvar|I}} or {{mvar|J}} is the incenter, this is the trillium theorem, with line {{mvar|IJ}} as the (internal) angle bisector of one of the triangle's angles. However, it is also true when {{mvar|I}} and {{mvar|J}} are both excenters; in this case, line {{mvar|IJ}} is the external angle bisector of one of the triangle's angles.&lt;ref&gt;{{citation|title=Machine Proofs in Geometry: Automated Production of Readable Proofs for Geometry Theorems|volume=6|series=Series on applied mathematics|first1=Shang-Ching|last1=Chou|first2=Xiao-Shan|last2=Gao|first3=Jingzhong|last3=Zhang|publisher=World Scientific|year=1994|isbn=9789810215842|at=Examples 6.145 and 6.146, pp.&amp;nbsp;328â329|url=https://books.google.com/books?id=rnI7H_7bLacC&amp;pg=PA328}}.&lt;/ref&gt;

== See also ==
* [[Angle bisector theorem]]

==References==
{{reflist|30em|refs =

&lt;ref name="rkarasev"&gt;{{cite book
 |title = ÐÐ°Ð´Ð°ÑÐ¸ Ð´Ð»Ñ ÑÐºÐ¾Ð»ÑÐ½Ð¾Ð³Ð¾ Ð¼Ð°ÑÐµÐ¼Ð°ÑÐ¸ÑÐµÑÐºÐ¾Ð³Ð¾ ÐºÑÑÐ¶ÐºÐ°
 |author1=Ð . Ð. ÐÐ°ÑÐ°ÑÑÐ² |author2=Ð. Ð. ÐÐ¾Ð»ÑÐ½Ð¸ÐºÐ¾Ð² |author3=Ð. Ð. ÐÐ¾Ð³Ð´Ð°Ð½Ð¾Ð² |author4=Ð. Ð. ÐÐºÐ¾Ð¿ÑÐ½ |pages = 4
 |location = Problem 1.2
 |url = http://www.rkarasev.ru/common/upload/taskprob.pdf
}}&lt;/ref&gt;&lt;!-- Triangle ABC is inscribed in circle S. I is the center of inscribed circle of the triangle ABC. The line AI intersects S second time in the point D. Prove that DB = DC = DI. --&gt;

&lt;ref name="approaching-2014-10-29-inscribed-angles"&gt;{{cite web
 |url = http://math.mosolymp.ru/upload/files/2015/aesc/approaching-2014-10-29-inscribed-angles.pdf
 |publisher = Ð¡Ð£ÐÐ¦ ÐÐÐ£ Ð¸Ð¼. Ð. Ð. ÐÐ¾Ð¼Ð¾Ð½Ð¾ÑÐ¾Ð²Ð° - ÑÐºÐ¾Ð»Ð° Ð¸Ð¼. Ð.Ð. ÐÐ¾Ð»Ð¼Ð¾Ð³Ð¾ÑÐ¾Ð²Ð°
 |title = 6. ÐÐµÐ¼Ð¼Ð° Ð¾ ÑÑÐµÐ·ÑÐ±ÑÐµ
 |date = 2014-10-29
}}&lt;/ref&gt;

&lt;ref name="9pointcircle"&gt;{{cite journal
 |url = http://www.geometry.ru/persons/kushnir/9pointcircle.pdf
 |title = Ð­ÑÐ¾ Ð¾ÑÐºÑÑÑÐ¸Ðµ - Ð·Ð¾Ð»Ð¾ÑÐ¾Ð¹ ÐºÐ»ÑÑ ÐÐµÐ¾Ð½Ð°ÑÐ´Ð° Ð­Ð¹Ð»ÐµÑÐ°
 |location = Ð¤7 (Ð¢ÐµÐ¾ÑÐµÐ¼Ð° ÑÑÐ¸Ð»Ð¸ÑÑÐ½Ð¸ÐºÐ°), page 34; proof on page 36
 |author = Ð. Ð. ÐÑÑÐ½Ð¸Ñ
}}&lt;/ref&gt;

}}

==External links==
*{{mathworld|id=Incenter-ExcenterCircle|title=Incenter-Excenter Circle}}

[[Category:Triangle geometry]]
[[Category:Mathematical theorems|trillium]]</text>
      <sha1>0rhnaahj5qo00t7peo8ya3ohizv32wg</sha1>
    </revision>
  </page>
  <page>
    <title>Versor (physics)</title>
    <ns>0</ns>
    <id>40256418</id>
    <revision>
      <id>802214437</id>
      <parentid>801856174</parentid>
      <timestamp>2017-09-24T18:45:56Z</timestamp>
      <contributor>
        <username>Ctafur</username>
        <id>31987295</id>
      </contributor>
      <comment>/* Versor of a non-zero vector */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4374">[[File:3D Vector.svg|right|thumb|300px|Versors '''i''', '''j''', '''k''' of the Cartesian axes ''x'', ''y'', ''z'' for a three-dimensional [[Euclidean space]]. Every vector '''a''' in that space is a [[linear combination]] of these versors.]]
{{about|a unit vector codirectional with an axis or with another vector|other uses of the term versor|Versor (disambiguation)}}
{{unreferenced|date=August 2013}}

In [[geometry]] and [[physics]], the '''versor''' of an axis or of a vector is a [[unit vector]] indicating its [[Direction (geometry)|direction]]. 

The versor of a [[Cartesian coordinate system|Cartesian axis]] is also known as a '''standard basis vector'''. The versor of a vector is also known as a '''normalized vector'''.

== Versors of a Cartesian coordinate system ==

The versors of the axes of a [[Cartesian coordinate system]] are the unit vectors codirectional with the axes of that system. 
Every [[Euclidean vector]] '''a''' in a ''n''-dimensional [[Euclidean space]] ({{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}}) can be represented as a [[linear combination]] of the ''n'' versors of the corresponding Cartesian coordinate system. For instance, in a three-dimensional space ({{math|'''R'''}}&lt;sup&gt;3&lt;/sup&gt;), there are three versors:
:&lt;math&gt;\mathbf{i} = (1,0,0),&lt;/math&gt;
:&lt;math&gt;\mathbf{j} = (0,1,0),&lt;/math&gt;
:&lt;math&gt;\mathbf{k} = (0,0,1).&lt;/math&gt;

They indicate the direction of the Cartesian axes ''x'', ''y'', and ''z'', respectively. In terms of these, any vector '''a''' can be represented as 

:&lt;math&gt;\mathbf{a} = \mathbf{a}_x + \mathbf{a}_y + \mathbf{a}_z = a_x \mathbf{i} + a_y \mathbf{j} + a_z \mathbf{k},&lt;/math&gt;

where '''a'''&lt;sub&gt;''x''&lt;/sub&gt;, '''a'''&lt;sub&gt;''y''&lt;/sub&gt;, '''a'''&lt;sub&gt;''z''&lt;/sub&gt; are called the [[vector component]]s (or vector projections) of '''a''' on the Cartesian axes ''x'', ''y'', and ''z'' (see figure), while ''a''&lt;sub&gt;''x''&lt;/sub&gt;, ''a''&lt;sub&gt;''y''&lt;/sub&gt;, ''a''&lt;sub&gt;''z''&lt;/sub&gt; are the respective [[scalar component]]s (or scalar projections).

In [[linear algebra]], the set formed by these ''n'' versors is typically referred to as the [[standard basis]] of the corresponding [[Euclidean space]], and each of them is commonly called a '''standard basis vector'''.

=== Notation ===
A [[Circumflex#Mathematics|hat]] above the symbol of a versor is sometimes used to emphasize its status as a [[unit vector]] (e.g., &lt;math alt= "unit vector i"&gt;\hat{\bold{\imath}}&lt;/math&gt;). 

In most contexts it can be assumed that '''i''', '''j''', and '''k''', (or &lt;math alt="vector i"&gt;\vec{\imath},&lt;/math&gt; &lt;math alt= "vector j"&gt;\vec{\jmath},&lt;/math&gt; and &lt;math alt= "vector k"&gt; \vec{k}&lt;/math&gt;) are versors of a 3-D Cartesian coordinate system. The notations &lt;math alt="x-hat, y-hat, z-hat"&gt;(\hat{\bold{x}}, \hat{\bold{y}}, \hat{\bold{z}})&lt;/math&gt;, &lt;math alt="x-hat sub 1, x-hat sub 2, x-hat sub 3"&gt;(\hat{\bold{x}}_1, \hat{\bold{x}}_2, \hat{\bold{x}}_3)&lt;/math&gt;, &lt;math alt="e-hat sub x, e-hat sub y, e-hat sub z"&gt;(\hat{\bold{e}}_x, \hat{\bold{e}}_y, \hat{\bold{e}}_z)&lt;/math&gt;, or &lt;math alt= "e-hat sub 1, e-hat sub 2, e-hat sub 3"&gt;(\hat{\bold{e}}_1, \hat{\bold{e}}_2, \hat{\bold{e}}_3)&lt;/math&gt;, with or without [[Circumflex#Mathematics|hat]], are also used, particularly in contexts where '''i''', '''j''', '''k''' might lead to confusion with another quantity. This is recommended, for instance, when [[Indexed family|index]] symbols such as ''i'', ''j'', ''k'' are used to identify an element of a set of variables.

== Versor of a non-zero vector ==
The versor (or '''normalized vector''') &lt;math&gt;\hat{\mathbf{u}}&lt;/math&gt; of a non-zero vector &lt;math&gt;\mathbf{u}&lt;/math&gt; is the unit vector codirectional with &lt;math&gt;\mathbf{u}&lt;/math&gt;:

:&lt;math&gt;\hat{\mathbf{u}} = \frac{\mathbf{u}}{\|\mathbf{u}\|}.&lt;/math&gt;

where &lt;math&gt;\|\mathbf{u}\|&lt;/math&gt; is the [[norm (mathematics)|norm]] (or length) of &lt;math&gt;\mathbf{u}&lt;/math&gt;. Notice that a versor lost the units of the original vector. For instance, if we have the vector &lt;math&gt;\vec{u} = (0, 5, 0)\, \mathrm{m} &lt;/math&gt;, then &lt;math&gt;|\vec{u}| = \sqrt{0^2 + 5^2 + 0^2}\, \mathrm{m} = 5\, \mathrm{m}&lt;/math&gt; and

&lt;math&gt;\hat{u} = \frac{\vec{u}}{|\vec{u}|} = \frac{(0, 5, 0)\, \mathrm{m}}{5\, \mathrm{m}} = (0, 1, 0)&lt;/math&gt;

You can notice that &lt;math&gt;\hat{u}&lt;/math&gt; is a [[dimensionless quantity]].

[[Category:Vectors (mathematics and physics)]]
[[Category:Concepts in physics]]
[[Category:Geometry]]
[[Category:Elementary mathematics]]</text>
      <sha1>7lvdtwkkske46lbfxnfc4u80894q7js</sha1>
    </revision>
  </page>
  <page>
    <title>Vladimir Drinfeld</title>
    <ns>0</ns>
    <id>1053747</id>
    <revision>
      <id>842799560</id>
      <parentid>842725273</parentid>
      <timestamp>2018-05-24T18:52:24Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <minor/>
      <comment>remove [[:Category:Jewish mathematicians]]. [[WP:G4]] per [[:WP:Categories for discussion/Log/2007 May 14#Category:Jewish_mathematicians]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7754">{{Infobox scientist
|name              = Vladimir Drinfeld
|image = 
|caption           = 
|birth_date        = {{Birth date and age|1954|2|14}}
|birth_place       = [[Kharkov]], [[Ukrainian Soviet Socialist Republic|Ukrainian SSR]], [[Soviet Union]]
|field             = [[Mathematics]]
|work_institutions = [[University of Chicago]]
|alma_mater        = [[Moscow State University]]
|doctoral_advisor  = [[Yuri I. Manin|Yuri Manin]]
|doctoral_students = 
|known_for         = [[Quantum group]]s&lt;br&gt;[[Geometric Langlands correspondence]]&lt;br&gt;[[DrinfeldâSokolovâWilson equation]]&lt;br&gt;[[ManinâDrinfeld theorem]]&lt;br&gt;[[Oper (mathematics)|Oper]]s&lt;br&gt;[[Lie-* algebra]]
|prizes            = [[Fields Medal]] (1990) &lt;br&gt; [[Wolf Prize]] (2018)
}}
'''Vladimir Gershonovich Drinfeld''' ({{lang-uk|ÐÐ¾Ð»Ð¾Ð´Ð¸ÌÐ¼Ð¸Ñ ÐÐµÌÑÑÐ¾Ð½Ð¾Ð²Ð¸Ñ ÐÑÑÐ½ÑÐµÐ»ÑÐ´}}; {{lang-ru|ÐÐ»Ð°Ð´Ð¸ÌÐ¼Ð¸Ñ ÐÐµÌÑÑÐ¾Ð½Ð¾Ð²Ð¸Ñ ÐÑÐ¸ÌÐ½ÑÐµÐ»ÑÐ´}}; born February 14, 1954), surname also romanized as '''Drinfel'd''', is a Ukrainian-American [[mathematician]], currently working at the [[University of Chicago]].

Drinfeld's work connected [[algebraic geometry]] over [[finite field]]s with [[number theory]], especially the theory of [[automorphic form]]s, through the notions of [[elliptic module]] and the theory of the [[geometric Langlands correspondence]]. Drinfeld introduced the notion of a [[quantum group]] (independently discovered by [[Michio Jimbo]] at the same time) and made important contributions to [[mathematical physics]], including the [[ADHM construction]] of [[instanton]]s, algebraic formalism of the [[quantum inverse scattering method]], and the DrinfeldâSokolov reduction in the theory of [[soliton]]s.

He was awarded the [[Fields Medal]] in 1990.&lt;ref&gt;{{cite web|last=O'Connor|first=J. J.|title=Vladimir Gershonovich Drinfeld|url=http://www-history.mcs.st-and.ac.uk/Biographies/Drinfeld.html|work=Biographies|publisher=School of Mathematics and Statistics University of St Andrews, Scotland|accessdate=21 May 2012|author2=Robertson, E. F }}&lt;/ref&gt;
In 2016, he was elected to the [[National Academy of Sciences]].&lt;ref&gt;{{citation|url=http://www.nasonline.org/news-and-multimedia/news/may-3-2016-NAS-Election.html|title=National Academy of Sciences Members and Foreign Associates Elected|department=News from the National Academy of Sciences|publisher=[[National Academy of Sciences]]|date=May 3, 2016|accessdate=2016-05-14}}.&lt;/ref&gt; In 2018 he received the [[Wolf Prize in Mathematics]].&lt;ref&gt;[http://www.jpost.com/Israel-News/Culture/Paul-McCartney-among-9-Wolf-Prize-recipients-542404 Jerusalem Post - Wolf Prizes 2018]&lt;/ref&gt;

== Biography ==
Drinfeld was born in [[Kharkiv]], [[Ukrainian Soviet Socialist Republic|Ukrainian SSR]], [[Soviet Union]] in 1954. In 1969, at the age of 15, Drinfeld represented the [[Soviet Union]] at the [[International Mathematics Olympiad]] in [[Bucharest]], [[Romania]], and won a gold medal with the full score of 40 points. He was, at the time, the [[List of International Mathematical Olympiad participants#Exceptionally young participants|youngest participant to achieve a perfect score]], and has since only been surpassed by [[Sergei Konyagin]] (1972) and [[Noam Elkies]] (1981). Drinfeld entered [[Moscow State University]] in the same year and graduated from it in 1974. Drinfeld was awarded the [[Candidate of Sciences]] degree in 1978 and the [[Doctor of Sciences]] degree from the [[Steklov Institute of Mathematics]] in 1988. He was awarded the [[Fields Medal]] in 1990. From 1981 till 1999 he worked at the [[Verkin Institute for Low Temperature Physics and Engineering]] (Department of Mathematical Physics). Drinfeld moved to the [[United States]] in 1999 and has been working at the [[University of Chicago]] since January 1999.

== Contributions to mathematics ==
In 1974, at the age of twenty, Drinfeld announced a proof of the [[Langlands conjectures]] for [[General linear group|GL&lt;sub&gt;2&lt;/sub&gt;]] over a [[global field]] of positive characteristic. In the course of proving the conjectures, Drinfeld introduced a new class of objects that he called "elliptic modules" (now known as [[Drinfeld module]]s). Later, in 1983, Drinfeld published a short article that expanded the scope of the Langlands conjectures. The Langlands conjectures, when published in 1967, could be seen as a sort of [[non-abelian class field theory]]. It postulated the existence of a natural one-to-one correspondence between [[Galois representations]] and some [[automorphic form]]s. The "naturalness" is guaranteed by the essential coincidence of [[L-functions]]. However, this condition is purely arithmetic and cannot be considered for a general one-dimensional function field  in a straightforward way. Drinfeld pointed out that instead of automorphic forms one can consider automorphic [[perverse sheaves]] or automorphic [[D-module]]s. "Automorphicity" of these modules and the Langlands correspondence could be then understood in terms of the action of [[Hecke operators]].

Drinfeld has also done much work in [[mathematical physics]]. In collaboration with his advisor [[Yuri I. Manin|Yuri Manin]], he constructed the [[moduli space]] of [[YangâMills theory|YangâMills]] [[instantons]], a result that was proved independently by [[Michael Atiyah]] and [[Nigel Hitchin]]. Drinfeld coined the term "[[quantum group]]" in reference to [[Hopf algebra]]s that are deformations of [[simple Lie algebra]]s, and connected them to the study of the [[YangâBaxter equation]], which is a necessary condition for the solvability of statistical mechanical models. He also generalized Hopf algebras to [[quasi-Hopf algebra]]s and introduced the study of [[Drinfeld twist]]s, which can be used to factorize the [[R-matrix]] corresponding to the solution of the YangâBaxter equation associated with a [[quasitriangular Hopf algebra]].

Drinfeld has also collaborated with [[Alexander Beilinson]] to rebuild the theory of [[vertex algebras]] in a coordinate-free form, which have become increasingly important to [[two-dimensional conformal field theory]], [[string theory]], and the  [[geometric Langlands program]].  Drinfeld and Beilinson published their work in 2004 in a book titled "[[Chiral Algebras]]."

== See also ==
*[[Drinfeld reciprocity]]
*[[Drinfeld upper half plane]]
*[[ManinâDrinfeld theorem]]
*[[Quantum group]]
*[[Chiral algebra]]
*[[Quasitriangular Hopf algebra]]
*[[Ruziewicz problem]]
*

== Notes ==
{{Reflist}}

== References ==
* {{MacTutor Biography|id=Drinfeld}}
* [[Victor Ginzburg]], Preface to the special volume of ''Transformation Groups'' (vol 10, 3â4, December 2005, BirkhÃ¤user) on occasion of Vladimir Drinfeld's 50th birthday, pp 277â278, {{doi|10.1007/s00031-005-0400-6}}
* [https://web.archive.org/web/20041127062730/http://www.icm2002.org.cn/general/prize/medal/1990/Drinfeld/ Report by Manin]

== External links ==
* {{MathGenealogy |id=20646}}
* {{IMO results |id=10169 }}
* [http://www.math.uchicago.edu/~mitya/langlands/ Langlands Seminar homepage]

{{Fields medalists}}

{{Authority control}}

{{DEFAULTSORT:Drinfeld, Vladimir}}
[[Category:1954 births]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Moscow State University alumni]]
[[Category:Fields Medalists]]
[[Category:Living people]]
[[Category:Algebraic geometers]]
[[Category:Number theorists]]
[[Category:Soviet mathematicians]]
[[Category:Ukrainian Jews]]
[[Category:People from Kharkiv]]
[[Category:Ukrainian mathematicians]]
[[Category:International Mathematical Olympiad participants]]
[[Category:University of Chicago faculty]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Members of the United States National Academy of Sciences]]</text>
      <sha1>mo66884mvrkne6d71408o30kou2cg0m</sha1>
    </revision>
  </page>
  <page>
    <title>Void type</title>
    <ns>0</ns>
    <id>2056815</id>
    <revision>
      <id>847014742</id>
      <parentid>844505912</parentid>
      <timestamp>2018-06-22T09:36:48Z</timestamp>
      <contributor>
        <ip>87.64.232.134</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4777">{{About|the void type in computer programming languages|types of astronomical voids|Void (astronomy)|other uses|Void (disambiguation)}}

The '''Void type''', in several [[Curly bracket programming language|programming languages derived from C and Algol68]], is the [[type theory|type]] for the result of a [[function (computer science)|function]] that returns normally, but does not provide a result value to its caller.  Usually such functions are called for their [[Side effect (computer science)|side effects]], such as performing some task or writing to their output parameters. The usage of the void type in such context is comparable to [[Procedure (computer science)|procedures]] in [[Pascal programming language|Pascal]] and syntactic constructs which define [[subroutines]] in [[Visual Basic]]. It is also similar to the [[unit type]] used in [[functional programming languages]] and type theory.  See [[Unit type#In programming languages]] for a comparison.

[[C (programming language)|C]] and [[C++]] also support the '''pointer to void type''' (specified as &lt;code&gt;void *&lt;/code&gt;), but this is an unrelated notion. Variables of this type are [[Pointer (computer programming)|pointer]]s to data of an ''unspecified'' type, so in this context (but not the others) &lt;code&gt;void *&lt;/code&gt; acts roughly like a universal or [[top type]]. A program can probably convert a pointer to any type of data (except a [[function pointer]]) to a pointer to void and back to the original type without losing information, which makes these pointers useful for [[polymorphism (computer science)|polymorphic]] functions. The C language standard does not guarantee that the different pointer types have the same size.

== In C and C++ ==

A function with void result type ends either by reaching the end of the function or by executing a [[return statement]] with no returned value. The void type may also appear as the sole [[Parameter (computer programming)|argument]] of a [[function prototype]] to indicate that the function takes no arguments. Note that despite the name, in all of these situations, the void type serves as a [[unit type]], not as a zero or [[bottom type]] (which 
is sometimes confusingly called the "void type"), even though unlike a real unit type which is a singleton, the void type lacks a way to represent its value and the language does not provide any way to declare an object or represent a value with type &lt;code&gt;void&lt;/code&gt;.

In the earliest versions of C, functions with no specific result defaulted to a return type of &lt;code&gt;int&lt;/code&gt; and functions with no arguments simply had empty argument lists. Pointers to untyped data were declared as integers or pointers to &lt;code&gt;char&lt;/code&gt;. Some early C [[compiler]]s had the feature, now seen as an annoyance, of generating a warning on any function call that did not use the function's returned value. Old code sometimes [[Type conversion|casts]] such function calls to void to suppress this warning.  By the time [[Bjarne Stroustrup]] began his work on [[C++]] in 1979â1980, void and void pointers were part of the C language dialect supported by AT&amp;T-derived compilers.&lt;ref&gt;http://cm.bell-labs.com/cm/cs/who/dmr/chist.html, "Standardisation."&lt;/ref&gt;

The explicit use of void vs. giving no arguments in a [[function prototype]] has different semantics in C and C++, as detailed in the following table:&lt;ref&gt;{{cite book | last = Stroustrup | first = Bjarne | title = Programming: Principles and Practice Using C++| publisher = Addison-Wesley | location = Boston | year = 2009 | isbn = 0-321-54372-6 | page=996}}&lt;/ref&gt;

{| class="wikitable" border="1"
|-
!  C
!  C++ equivalent
|-
|  &lt;code&gt;void f(void);&lt;/code&gt;
|  &lt;code&gt;void f();&lt;/code&gt; (''preferred'')&lt;br&gt; &lt;code&gt;void f(void);&lt;/code&gt;
|-
|  &lt;code&gt;void f();&lt;/code&gt; (''accepts a constant but unknown number of arguments'')
|  ''no equivalent''
|}

A C prototype taking no arguments, e.g. &lt;code&gt;void f()&lt;/code&gt; above, has been deprecated in [[C99]]&lt;ref&gt;Bjarne Stroustrup, ''[http://www.ddj.com/cpp/184401562 C and C++: Case Studies in Compatibility. Reconcilable differences? You decide]'', [[Dr. Dobb's]], September 01, 2002; [http://www.research.att.com/~bs/examples_short.pdf print version]&lt;/ref&gt;, however.

==In Haskell==

Quite contrary to C++, in the [[functional programming language]] [[Haskell (programming language)|Haskell]] the void type denotes the empty type, which has no inhabitants [http://hackage.haskell.org/package/void]. A function into the void type does not return results, and a side-effectful program with type signature  &lt;code&gt;IO Void&lt;/code&gt;  does not terminate, or crashes. In particular, there are no [[total functions]] into the void type.

==References==
{{Reflist|2}}

{{Data types}}

[[Category:Data types]]
[[Category:Type theory]]</text>
      <sha1>bjw22rtrc6m71xt5mu9cqdji7fv92r2</sha1>
    </revision>
  </page>
</mediawiki>
