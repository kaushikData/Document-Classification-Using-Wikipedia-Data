<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Abstract machine</title>
    <ns>0</ns>
    <id>60492</id>
    <revision>
      <id>820138845</id>
      <parentid>820137588</parentid>
      <timestamp>2018-01-13T07:32:18Z</timestamp>
      <contributor>
        <username>Shyam Has Your Anomaly Mitigated</username>
        <id>32639101</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3648">{{confused|Virtual machine}}
{{Refimprove|date=October 2009}}

An '''abstract machine''', also called an '''abstract computer''', is a theoretical model of a [[computer]] hardware or software system used in [[automata theory]]. Abstraction of computing processes is used in both the [[computer science]] and [[computer engineering]] disciplines and usually assumes a [[discrete time]] [[paradigm]].

==Information==
In the [[theory of computation]], abstract machines are often used in [[thought experiments]] regarding [[computability]] or to analyze the complexity of [[algorithm]]s (''see'' [[computational complexity theory]]). A typical abstract machine consists of a definition in terms of input, output, and the set of allowable operations used to turn the former into the latter. The best-known example is the [[Turing machine]].

[[Abstract data type]]s can be specified in terms of their [[operational semantics]] on an abstract machine. For example, a stack can be specified in terms of operations on an abstract machine with an array of memory. Through the use of abstract machines it is possible to compute the amount of resources (time, memory, etc.) necessary to perform a particular operation without having to construct a physical system.{{clarify|this analysis is also possible by hand without abstract machines|date=December 2016}}

More complex definitions create abstract machines with full [[instruction set]]s, [[processor register|register]]s and [[memory hierarchy|models of memory]]. One popular model more similar to real modern machines is the [[RAM model]], which allows [[random access]] to indexed memory locations. As the performance difference between different levels of [[cache memory]] grows, cache-sensitive models such as the external-memory model and [[Cache-oblivious algorithm#Idealized cache model|cache-oblivious model]] are growing in importance.

An abstract machine can also refer to a [[microprocessor]] design which has yet to be (or is not intended to be) implemented as hardware. An abstract machine implemented as a software simulation, or for which an [[Interpreter (computing)|interpreter]] exists, is called a [[virtual machine]].

==See also==
*[[Abstraction (computer science)]]
*[[Abstract interpretation]]
*[[Discrete time]]
*[[Finite automata]]
*[[Flynn's taxonomy]] 
*[[Computability#Formal models of computation|Formal models of computation]]
*[[Parallel random-access machine]], the de facto standard model.&lt;ref name="Skillicorn2005"&gt;{{cite book|author=D. B. Skillicorn|title=Foundations of Parallel Programming|url=https://books.google.com/books?id=rQwsL5xsZigC&amp;pg=PA18|year=2005|publisher=Cambridge University Press|isbn=978-0-521-01856-2|page=18}}&lt;/ref&gt;
*[[Bulk synchronous parallel]]
*[[State space]]

==References==
{{FOLDOC}}
{{reflist}}

==Further reading==
*Peter van Emde Boas, ''Machine Models and Simulations'' pp.&amp;nbsp;3–66, appearing in:
::[[Jan van Leeuwen]], ed. "Handbook of Theoretical Computer Science. Volume A: Algorithms and Complexity'', The MIT PRESS/Elsevier, 1990. {{ISBN|0-444-88071-2}} (volume A). QA 76.H279 1990.
* Stephan Diehl, Pieter Hartel and Peter Sestoft, [http://www.inf.ed.ac.uk/teaching/courses/lsi/diehl_abstract_machines.pdf ''Abstract Machines for Programming Language Implementation''], Future Generation Computer Systems, Vol. 16(7), Elsevier, 2000.
* {{cite book|author=Werner Kluge|title=Abstract Computing Machines: A Lambda Calculus Perspective|year=2006|publisher=Springer|isbn=978-3-540-27359-2}}

{{DEFAULTSORT:Abstract Machine}}
[[Category:Abstract machines| ]]
[[Category:Automata (computation)]]
[[Category:Models of computation]]</text>
      <sha1>ti9cpzywjvqtb371hwxqye3g7etwknq</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetic</title>
    <ns>0</ns>
    <id>3118</id>
    <revision>
      <id>868875540</id>
      <parentid>868875328</parentid>
      <timestamp>2018-11-15T00:34:51Z</timestamp>
      <contributor>
        <username>Power~enwiki</username>
        <id>21155</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/Sandeep jot|Sandeep jot]] ([[User talk:Sandeep jot|talk]]): Rv; unnecessary/bizarre wikilinks added. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36731">{{for|the song by Brooke Fraser|Arithmetic (song)}}
[[File:Tables generales aritmetique MG 2108.jpg|thumb|Arithmetic tables for children, Lausanne, 1835]]
'''Arithmetic''' (from the [[Ancient Greek|Greek]] [[wikt:en:ἀριθμός#Ancient Greek|ἀριθμός]] ''arithmos'', "[[number]]" and [[wikt:en:τική#Ancient Greek|τική]] [[wikt:en:τέχνη#Ancient Greek|[τέχνη]]], ''tiké [téchne]'', "[[art]]") is a branch of [[mathematics]] that consists of the study of [[number]]s, especially the properties of the traditional [[operation (mathematics)|operations]] on them—[[addition]], [[subtraction]], [[multiplication]] and [[division (mathematics)|division]]. Arithmetic is an elementary part of [[number theory]], and number theory is considered to be one of the top-level [[Areas of mathematics|divisions of modern mathematics]], along with [[algebra]], [[geometry]], and [[mathematical analysis|analysis]]. The terms ''arithmetic'' and ''higher arithmetic'' were used until the beginning of the 20th&amp;nbsp;century as synonyms for ''number theory'' and are sometimes still used to refer to a wider part of number theory.&lt;ref&gt;[[Harold Davenport|Davenport, Harold]], ''The Higher Arithmetic: An Introduction to the Theory of Numbers'' (7th ed.), Cambridge University Press, Cambridge, 1999, {{ISBN|0-521-63446-6}}.&lt;/ref&gt;

==History==
The prehistory of arithmetic is limited to a small number of artifacts which may indicate the conception of addition and subtraction, the best-known being the [[Ishango bone]] from [[Democratic Republic of the Congo|central Africa]], dating from somewhere between 20,000 and 18,000&amp;nbsp;BC, although its interpretation is disputed.&lt;ref&gt;{{cite book |last=Rudman |first=Peter Strom |title=How Mathematics Happened: The First 50,000 Years |year=2007 |publisher=Prometheus Books |isbn=978-1-59102-477-4 |page=64}}&lt;/ref&gt;

The earliest written records indicate the [[Egyptian mathematics|Egyptians]] and [[Babylonian mathematics|Babylonians]] used all the [[elementary arithmetic]] operations as early as 2000&amp;nbsp;BC. These artifacts do not always reveal the specific process used for solving problems, but the characteristics of the particular [[numeral system]] strongly influence the complexity of the methods. The hieroglyphic system for [[Egyptian numerals]], like the later [[Roman numerals]], descended from [[tally marks]] used for counting. In both cases, this origin resulted in values that used a [[decimal]] base but did not include [[positional notation]]. Complex calculations with Roman numerals required the assistance of a [[counting board]] or the [[Roman abacus]] to obtain the results.

Early number systems that included positional notation were not decimal, including the [[sexagesimal]] (base&amp;nbsp;60) system for [[Babylonian numerals]] and the [[vigesimal]] (base&amp;nbsp;20) system that defined [[Maya numerals]]. Because of this place-value concept, the ability to reuse the same digits for different values contributed to simpler and more efficient methods of calculation.

The continuous historical development of modern arithmetic starts with the [[Hellenistic civilization]] of ancient Greece, although it originated much later than the Babylonian and Egyptian examples. Prior to the works of [[Euclid]] around 300&amp;nbsp;BC, [[Greek mathematics|Greek studies in mathematics]] overlapped with philosophical and mystical beliefs. For example, [[Nicomachus]] summarized the viewpoint of the earlier [[Pythagoreanism|Pythagorean]] approach to numbers, and their relationships to each other, in his ''[[Introduction to Arithmetic]]''.

[[Greek numerals]] were used by [[Archimedes]], [[Diophantus]] and others in a [[positional notation]] not very different from ours. The ancient Greeks lacked a symbol for zero until the Hellenistic period, and they used three separate sets of symbols as [[numerical digit|digits]]: one set for the units place, one for the tens place, and one for the hundreds. For the thousands place they would reuse the symbols for the units place, and so on. Their addition algorithm was identical to ours, and their multiplication algorithm was only very slightly different. Their long division algorithm was the same, and the [[Methods of computing square roots#Digit-by-digit calculation|digit-by-digit square root algorithm]], popularly used as recently as the 20th century, was known to Archimedes, who may have invented it. He preferred it to [[Heron's method|Hero's method]] of successive approximation because, once computed, a digit doesn't change, and the square roots of perfect squares, such as 7485696, terminate immediately as 2736. For numbers with a fractional part, such as 546.934, they used negative powers of 60 instead of negative powers of 10 for the fractional part 0.934.&lt;ref&gt;''The Works of Archimedes'', Chapter IV, ''Arithmetic in Archimedes'', edited by T.L. Heath, Dover Publications Inc, New York, 2002.&lt;/ref&gt;

The ancient Chinese had advanced arithmetic studies dating from the Shang Dynasty and continuing through the Tang Dynasty, from basic numbers to advanced algebra. The ancient Chinese used a positional notation similar to that of the Greeks. Since they also lacked a symbol for zero, they had one set of symbols for the unit's place, and a second set for the ten's place. For the hundred's place they then reused the symbols for the unit's place, and so on. Their symbols were based on the ancient [[counting rods]]. It is a complicated question to determine exactly when the Chinese started calculating with positional representation, but it was definitely before 400&amp;nbsp;BC.&lt;ref&gt;Joseph Needham, ''Science and Civilization in China'', Vol. 3, p. 9, Cambridge University Press, 1959.&lt;/ref&gt; The ancient Chinese were the first to meaningfully discover, understand, and apply negative numbers as explained in the ''[[Nine Chapters on the Mathematical Art]]'' (''Jiuzhang Suanshu''), which was written by [[Liu Hui]].

The gradual development of the [[Hindu–Arabic numeral system]] independently devised the place-value concept and positional notation, which combined the simpler methods for computations with a decimal base and the use of a digit representing [[0 (number)|0]]. This allowed the system to consistently represent both large and small integers. This approach eventually replaced all other systems. In the early {{nowrap|6th century AD,}} the Indian mathematician [[Aryabhata]] incorporated an existing version of this system in his work, and experimented with different notations. In the 7th&amp;nbsp;century, [[Brahmagupta]] established the use of&amp;nbsp;0 as a separate number and determined the results for multiplication, division, addition and subtraction of zero and all other numbers, except for the result of [[division by 0]]. His contemporary, the [[Syriac Christianity|Syriac]] bishop [[Severus Sebokht]] (650&amp;nbsp;AD) said, "Indians possess a method of calculation that no word can praise enough. Their rational system of mathematics, or of their method of calculation. I mean the system using nine symbols."&lt;ref&gt;Reference: Revue de l'Orient Chretien by François Nau pp.327-338. (1929)&lt;/ref&gt; The Arabs also learned this new method and called it ''hesab''.

[[File:Leibniz Stepped Reckoner.png|thumb|200px|Leibniz's [[Stepped Reckoner]] was the first calculator that could perform all four arithmetic operations.]]
Although the [[Codex Vigilanus]] described an early form of Arabic numerals (omitting&amp;nbsp;0) by 976&amp;nbsp;AD, Leonardo of Pisa ([[Fibonacci]]) was primarily responsible for spreading their use throughout Europe after the publication of his book ''[[Liber Abaci]]'' in 1202. He wrote, "The method of the Indians (Latin ''Modus Indoram'') surpasses any known method to compute. It's a marvelous method. They do their computations using nine figures and symbol [[zero]]".&lt;ref&gt;Reference: Sigler, L., "Fibonacci's Liber Abaci", Springer, 2003.&lt;/ref&gt;

In the Middle Ages, arithmetic was one of the seven [[liberal arts]] taught in universities.

The flourishing of [[algebra]] in the [[medieval]] [[Islamic]] world and in [[Renaissance]] [[Europe]] was an outgrowth of the enormous simplification of [[computation]] through [[decimal]] notation.

Various types of tools have been invented and widely used to assist in numeric calculations. Before Renaissance, they were various types of [[abaci]]. More recent examples include [[slide rule]]s, [[nomogram]]s and [[mechanical calculator]]s, such as [[Pascal's calculator]]. At present, they have been supplanted by electronic [[calculator]]s and [[computer]]s.

==Arithmetic operations==
{{See also|Algebraic operation}}
The basic arithmetic operations are addition, subtraction, multiplication and division, although this subject also includes more advanced operations, such as manipulations of [[percentage]]s, [[square root]]s, [[exponentiation]], [[logarithmic function]]s, and even [[trigonometric function]]s, in the same vein as logarithms ([[Prosthaphaeresis]]). Arithmetic expressions must be evaluated according to the intended sequence of operations. There are several methods to specify this, either –most common, together with [[infix notation]]– explicitly using parentheses, and relying on [[Order of operations|precedence rules]], or using a [[Polish notation|pre–]] or [[Reverse Polish notation|postfix]] notation, which uniquely fix the order of execution by themselves. Any set of objects upon which all four arithmetic operations (except division by&amp;nbsp;0) can be performed, and where these four operations obey the usual laws (including distributivity), is called a [[field mathematics|field]].&lt;ref name=Oxford&gt;{{cite book
|title=The Oxford Mathematics Study Dictionary
|first1=Frank
|last1=Tapson
|publisher=[[Oxford University Press]]
|year=1996
|isbn=0 19 914551 2}}&lt;/ref&gt;

===Addition (+)===
{{main|Addition}}
Addition is the most basic operation of arithmetic. In its simple form, addition combines two numbers, the ''addends'' or ''[[term (mathematics)|terms]]'', into a single number, the ''sum'' of the numbers (Such as {{math|2 + 2 {{=}} 4}} or {{math|3 + 5 {{=}} 8}}).

Adding finitely many numbers can be viewed as repeated simple addition; this procedure is known as [[summation]], a term also used to denote the definition for "adding infinitely many numbers" in an [[series (mathematics)|infinite series]]. Repeated addition of the number&amp;nbsp;[[one|1]] is the most basic form of [[counting]], the result of adding {{math|1}} is usually called the [[successor function|successor]] of the original number.

Addition is [[commutative]] and [[associative]], so the order in which finitely many terms are added does not matter. The [[identity element]] for a [[binary operation]] is the number that, when combined with any number, yields the same number as result. According to the rules of addition, adding&amp;nbsp;{{math|0}} to any number yields that same number, so {{math|0}} is the [[additive identity]]. The ''[[inverse element|inverse]] of a number'' with respect to a [[binary operation]] is the number that, when combined with any number, yields the identity with respect to this operation. So the inverse of a number with respect to addition (its [[additive inverse]], or the opposite number), is the number, that yields the additive identity,&amp;nbsp;{{math|0}}, when added to the original number; it is immediate that this is the negative of the original number. For example, the additive inverse of {{math|7}} is {{math|−7}}, since {{math|7 + (−7) {{=}} 0}}.

Addition can be interpreted geometrically as in the following example:
:If we have two sticks of lengths ''2'' and ''5'', then, if we place the sticks one after the other, the length of the stick thus formed is {{math|2 + 5 {{=}} 7}}.

===Subtraction (−)===
{{Main|Subtraction}}
{{See also|Method of complements}}
Subtraction is the inverse operation to addition. Subtraction finds the ''difference'' between two numbers, the ''minuend''  minus the ''subtrahend'': {{math|''D'' {{=}} ''M'' - ''S''.}} Resorting to the previously established addition, this is to say that the difference is the number that, when added to the subtrahend, results in the minuend: {{math|''D'' + ''S'' {{=}} ''M''.}}

For positive arguments {{mvar|M}} and {{mvar|S}} holds:
:If the minuend is larger than the subtrahend, the difference {{mvar|D}} is positive.
:If the minuend is smaller than the subtrahend, the difference {{mvar|D}} is negative.
In any case, if minuend and subtrahend are equal, the difference {{math|''D'' {{=}} 0.}}

Subtraction is neither [[Commutative property|commutative]] nor [[Associative property|associative]]. For that reason, in modern algebra the construction of this inverse operation is often discarded in favor of introducing the concept of inverse elements, as sketched under [[#Addition (+)| Addition]], and to look at subtraction as adding the additive inverse of the subtrahend to the minuend, that is {{math|''a'' − ''b'' {{=}} ''a'' + (−''b'')}}. The immediate price of discarding the binary operation of subtraction is the introduction of the (trivial) [[unary operation]], delivering the additive inverse for any given number, and losing the immediate access to the notion of [[difference (mathematics)|difference]], which is potentially misleading, anyhow, when negative arguments are involved.

For any representation of numbers there are methods for calculating results, some of which are particularly advantageous in exploiting procedures, existing for one operation, by small alterations also for others. For example, digital computers can reuse existing adding-circuitry and save additional circuits for implementing a subtraction by employing the method of [[two's complement]] for representing the additive inverses, which is extremely easy to implement in hardware ([[Inverter (logic gate)|negation]]). The trade-off is the halving of the number range for a fixed word length.

A formerly wide spread method to achieve a correct change amount, knowing the due and given amounts, is the ''counting up method'', which does not explicitly generate the value of the difference. Suppose an amount ''P'' is given in order to pay the required amount ''Q'', with ''P'' greater than ''Q''. Rather than explicitly performing the subtraction ''P'' − ''Q'' = ''C'' and counting out that amount ''C'' in change, money is counted out starting with the successor of ''Q'', and continuing in the steps of the currency, until ''P'' is reached. Although the amount counted out must equal the result of the subtraction ''P'' − ''Q'', the subtraction was never really done and the value of ''P'' − ''Q'' is not supplied by this method.

===Multiplication (× or · or *)===
{{main|Multiplication}}
Multiplication is the second basic operation of arithmetic. Multiplication also combines two numbers into a single number, the ''product''. The two original numbers are called the ''multiplier'' and the ''multiplicand'', mostly both are simply called ''factors''.

Multiplication may be viewed as a scaling operation. If the numbers are imagined as lying in a line, multiplication by a number, say ''x'', greater than&amp;nbsp;1 is the same as stretching everything away from&amp;nbsp;0 uniformly, in such a way that the number&amp;nbsp;1 itself is stretched to where ''x'' was. Similarly, multiplying by a number less than&amp;nbsp;1 can be imagined as squeezing towards&amp;nbsp;0. (Again, in such a way that&amp;nbsp;1 goes to the multiplicand.)

Another view on multiplication of integer numbers, extendable to rationals, but not very accessible for real numbers, is by considering it as repeated addition. So {{math|3 × 4}} corresponds to either adding {{math|3}} times a {{math|4}}, or {{math|4}} times a {{math|3}}, giving the same result. There are different opinions on the advantageousness of these [[Multiplication and repeated addition|paradigmata]] in math education. 

Multiplication is commutative and associative; further it is [[distributivity|distributive]] over addition and subtraction. The [[multiplicative identity]] is&amp;nbsp;1, since multiplying any number by&amp;nbsp;1 yields that same number (no stretching or squeezing). The [[multiplicative inverse]] for any number except&amp;nbsp;{{math|0}} is the [[reciprocal (mathematics)|reciprocal]] of this number, because  multiplying the reciprocal of any number by the number itself yields the multiplicative identity {{math|1}}.  {{math|0}}&amp;nbsp;is the only number without a multiplicative inverse, and the result of multiplying any number and {{math|0}} is again {{math|0.}} One says, {{math|0}} is not contained in the multiplicative [[Group (mathematics)|group]] of the numbers.

The product of ''a'' and ''b'' is written as {{math|''a'' × ''b''}} or {{math|''a''·''b''}}. When ''a'' or ''b'' are expressions not written simply with digits, it is also written by simple juxtaposition:&amp;nbsp;''ab''. In computer programming languages and software packages in which one can only use characters normally found on a keyboard, it is often written with an asterisk:&amp;nbsp;{{math|''a'' * ''b''.}}

Algorithms implementing the operation of multiplication for various representations of numbers are by far more costly and laborious than those for addition. Those accessible for manual computation either rely on breaking down the factors to single place values and apply repeated addition, or employ [[Mathematical table|tables]] or [[slide rules]], thereby mapping the multiplication to addition and back. These methods are outdated and replaced by mobile devices. Computers utilize diverse sophisticated and highly optimized algorithms to implement multiplication and division for the various number formats supported in their system.

===Division (÷ or /)===
{{main|Division (mathematics)}}
Division is essentially the inverse operation to multiplication. Division finds the ''quotient'' of two numbers, the ''dividend'' divided by the ''divisor''. Any dividend [[division by 0|divided by&amp;nbsp;0]] is undefined. For distinct positive numbers, if the dividend is larger than the divisor, the quotient is greater than&amp;nbsp;1, otherwise it is less than&amp;nbsp;1 (a similar rule applies for negative numbers). The quotient multiplied by the divisor always yields the dividend.

Division is neither commutative nor associative. So as explained for [[#Subtraction_(%E2%88%92)|subtraction]], in modern algebra the construction of the division is discarded in favor of constructing the inverse elements with respect to multiplication, as introduced [[#Multiplication_(%C3%97_or_%C2%B7_or_*)|there]]. That is, division is a multiplication with the dividend and the [[multiplicative inverse|reciprocal]] of the divisor as factors, that is {{math|''a'' ÷ ''b'' {{=}} ''a'' × {{sfrac|1|''b''}}.}}

Within natural numbers there is also a different, but related notion, the [[Euclidean division]], giving two results of "dividing" a natural {{mvar|N}} (numerator) by a natural {{mvar|D}} (denominator), first, a natural {{mvar|Q}} (quotient) and second, a natural {{mvar|R}} (remainder), such that {{math|''N'' {{=}} ''D''×''Q'' + ''R''}} and {{math|''R'' &lt; ''Q''.}}

==Decimal arithmetic==
'''[[Decimal representation]]''' refers exclusively, in common use, to the written [[numeral system]] employing [[arabic numerals]] as the [[numerical digit|digits]] for a [[radix]] [[decimal|10&amp;nbsp;("decimal")]] [[positional notation]]; however, any [[numeral system]] based on powers of&amp;nbsp;10, e.g., [[Greek Numerals|Greek]], [[Cyrillic numerals|Cyrillic]], [[Roman numerals|Roman]], or [[Chinese numerals]] may conceptually be described as "decimal notation" or "decimal representation".

Modern methods for four fundamental operations (addition, subtraction, multiplication and division) were first devised by [[Brahmagupta]] of India. This was known during medieval Europe as "Modus Indoram" or Method of the Indians. Positional notation (also known as "place-value notation") refers to the representation or encoding of [[number]]s using the same symbol for the different [[orders of magnitude]] (e.g., the "ones place", "tens place", "hundreds place") and, with a [[radix point]], using those same symbols to represent [[arithmetic fraction|fractions]] (e.g., the "tenths place", "hundredths place"). For example, 507.36 denotes 5&amp;nbsp;hundreds (10&lt;sup&gt;2&lt;/sup&gt;), plus 0&amp;nbsp;tens (10&lt;sup&gt;1&lt;/sup&gt;), plus 7&amp;nbsp;units (10&lt;sup&gt;0&lt;/sup&gt;), plus 3&amp;nbsp;tenths (10&lt;sup&gt;−1&lt;/sup&gt;) plus 6&amp;nbsp;hundredths (10&lt;sup&gt;−2&lt;/sup&gt;).

The concept of [[Zero|0]] as a number comparable to the other basic digits is essential to this notation, as is the concept of&amp;nbsp;0's use as a placeholder, and as is the definition of multiplication and addition with&amp;nbsp;0. The use of&amp;nbsp;0 as a placeholder and, therefore, the use of a positional notation is first attested to in the [[Jainism|Jain]] text from [[India]] entitled the ''[[Lokavibhâga]]'', dated 458&amp;nbsp;AD and it was only in the early 13th&amp;nbsp;century that these concepts, transmitted via the [[Mathematics in medieval Islam|scholarship of the Arabic world]], were introduced into [[Europe]] by [[Fibonacci]]&lt;ref&gt;[http://www.britannica.com/eb/article-4153/Leonardo-Pisano Leonardo Pisano – p. 3: "Contributions to number theory"]. ''[[Encyclopædia Britannica]]'' Online, 2006. Retrieved 18 September 2006.&lt;/ref&gt; using the Hindu–Arabic numeral system.

[[Algorism]] comprises all of the rules for performing arithmetic computations using this type of written numeral. For example, addition produces the sum of two arbitrary numbers. The result is calculated by the repeated addition of single digits from each number that occupies the same position, proceeding from right to left. An addition table with ten rows and ten columns displays all possible values for each sum. If an individual sum exceeds the value&amp;nbsp;9, the result is represented with two digits. The rightmost digit is the value for the current position, and the result for the subsequent addition of the digits to the left increases by the value of the second (leftmost) digit, which is always one. This adjustment is termed a ''carry'' of the value&amp;nbsp;1.

The process for multiplying two arbitrary numbers is similar to the process for addition. A multiplication table with ten rows and ten columns lists the results for each pair of digits. If an individual product of a pair of digits exceeds&amp;nbsp;9, the ''carry'' adjustment increases the result of any subsequent multiplication from digits to the left by a value equal to the second (leftmost) digit, which is any value from {{nowrap|1 to 8}} ({{math|9 × 9 {{=}} 81}}). Additional steps define the final result.

Similar techniques exist for subtraction and division.

The creation of a correct process for multiplication relies on the relationship between values of adjacent digits. The value for any single digit in a numeral depends on its position. Also, each position to the left represents a value ten times larger than the position to the right. In mathematical terms, the [[exponentiation|exponent]] for the [[radix]] (base) of&amp;nbsp;10 increases by&amp;nbsp;1 (to the left) or decreases by&amp;nbsp;1 (to the right). Therefore, the value for any arbitrary digit is multiplied by a value of the form&amp;nbsp;10&lt;sup&gt;''n''&lt;/sup&gt; with [[integer]]&amp;nbsp;''n''. The list of values corresponding to all possible positions for a single digit is written {{nowrap|as {..., 10&lt;sup&gt;2&lt;/sup&gt;, 10, 1, 10&lt;sup&gt;−1&lt;/sup&gt;, 10&lt;sup&gt;−2&lt;/sup&gt;, ...}.}}

Repeated multiplication of any value in this list by&amp;nbsp;10 produces another value in the list. In mathematical terminology, this characteristic is defined as [[closure (mathematics)|closure]], and the previous list is described as '''closed under multiplication'''. It is the basis for correctly finding the results of multiplication using the previous technique. This outcome is one example of the uses of [[number theory]].

==Compound unit arithmetic{{anchor|Compound Unit Arithmetic}}==
Compound&lt;ref&gt;{{cite web
|url=http://www.lloffion.org.uk/docs/walkingames_arithmetic/walkingames_arithmetic.pdf
|title=The Tutor's Companion; or, Complete Practical Arithmetic
|first=Francis
|last=Walkingame
|pages=24–39
|publisher=Webb, Millington &amp; Co
|year=1860
|deadurl=yes
|archiveurl=https://web.archive.org/web/20150504004020/http://www.lloffion.org.uk/docs/walkingames_arithmetic/walkingames_arithmetic.pdf
|archivedate=2015-05-04
|df=
}}&lt;/ref&gt; unit arithmetic is the application of arithmetic operations to [[mixed radix]] quantities such as feet and inches, gallons and pints, pounds shillings and pence, and so on. Prior to the use of decimal-based systems of money and units of measure, the use of compound unit arithmetic formed a significant part of commerce and industry.

===Basic arithmetic operations===
The techniques used for compound unit arithmetic were developed over many centuries and are well-documented in many textbooks in many different languages.&lt;ref name=FR&gt;{{cite book
|url=https://books.google.com/?id=ahjPAAAAMAAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false
|title=Métrologie universelle, ancienne et moderne: ou rapport des poids et mesures des empires, royaumes, duchés et principautés des quatre parties du monde
|language=French
|trans-title=Universal, ancient and modern metrology: or report of weights and measurements of empires, kingdoms, duchies and principalities of all parts of the world
|first=JFG
|last=Palaiseau
|location=Bordeaux
|date=October 1816
|accessdate=October 30, 2011}}&lt;/ref&gt;&lt;ref name=NL2&gt;{{cite book
|url=https://books.google.com/books?id=XYVbAAAAQAAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false
|title=Allereerste Gronden der Cijferkunst
|author=Jacob de Gelder
|location='s-Gravenhage and Amsterdam
|language=Dutch
|year=1824
|pages=163–176
|publisher=de Gebroeders van Cleef
|trans-title=Introduction to Numeracy
|accessdate=March 2, 2011}}&lt;/ref&gt;&lt;ref name=DE1842&gt;{{cite book
|title=Theoretisch-Praktischer Unterricht im Rechnen für die niederen Classen der Regimentsschulen der Königl. Bayer. Infantrie und Cavalerie
|language=German
|trans-title=Theoretical and practical instruction in arithmetic for the lower classes of the Royal Bavarian Infantry and Cavalry School
|last=Malaisé
|first=Ferdinand
|year=1842
|location=Munich
|url=http://www.spasslernen.de/geschichte/buch/index.htm
|accessdate=20 March 2012}}&lt;/ref&gt;&lt;ref name="eb1772"&gt;{{Citation
|at=Arithmetick
|title=[[Encyclopædia Britannica]]
|volume=Vol I
|location=Edinburgh
|year=1772}}&lt;/ref&gt; In addition to the basic arithmetic functions encountered in decimal arithmetic, compound unit arithmetic employs three more functions:
* '''[[Reduction (mathematics)|Reduction]]''' where a compound quantity is reduced to a single quantity, for example conversion of a distance expressed in yards, feet and inches to one expressed in inches.&lt;ref&gt;{{cite web
|url=http://www.lloffion.org.uk/docs/walkingames_arithmetic/walkingames_arithmetic.pdf
|title=The Tutor's Companion; or, Complete Practical Arithmetic
|first=Francis
|last=Walkingame
|pages=43–50
|publisher=Webb, Millington &amp; Co
|year=1860
|deadurl=yes
|archiveurl=https://web.archive.org/web/20150504004020/http://www.lloffion.org.uk/docs/walkingames_arithmetic/walkingames_arithmetic.pdf
|archivedate=2015-05-04
|df=
}}&lt;/ref&gt;
* '''Expansion''', the [[inverse function]] to reduction, is the conversion of a quantity that is expressed as a single unit of measure to a compound unit, such as expanding 24&amp;nbsp;oz to {{nowrap|1 lb, 8 oz}}.
* '''Normalization''' is the conversion of a set of compound units to a standard form&amp;nbsp;– for example rewriting "{{nowrap|1 ft 13 in}}" as "{{nowrap|2 ft 1 in}}".

Knowledge of the relationship between the various units of measure, their multiples and their submultiples forms an essential part of compound unit arithmetic.

===Principles of compound unit arithmetic===
There are two basic approaches to compound unit arithmetic:
* '''Reduction–expansion method''' where all the compound unit variables are reduced to single unit variables, the calculation performed and the result expanded back to compound units. This approach is suited for automated calculations. A typical example is the handling of time by [[Microsoft Excel]] where all time intervals are processed internally as days and decimal fractions of a day.
* '''On-going normalization method''' in which each unit is treated separately and the problem is continuously normalized as the solution develops. This approach, which is widely described in classical texts, is best suited for manual calculations. An example of the ongoing normalization method as applied to addition is shown below.
{|class="infobox bordered" style="font-size: 95%;"
|-style="border-bottom-width=0; background:lightblue;"
!align="center"|UK pre-decimal currency
|-
|
{|class="wikitable"
|-
|4 farthings (f) = 1 penny
|-
|12 pennies (d) = 1 shilling
|-
|20 shillings (s) = 1 pound (£)
|}
|}

{|class="wikitable" ||style="border: 1px solid #FFFFFF;"
|-
[[File:MixedUnitAddition.svg|left|thumb]]
The addition operation is carried out from right to left; in this case, pence are processed first, then shillings followed by pounds. The numbers below the "answer line" are intermediate results.

The total in the pence column is 25. Since there are 12 pennies in a shilling, 25 is divided by&amp;nbsp;12 to give&amp;nbsp;2 with a remainder of&amp;nbsp;1. The value&amp;nbsp;"1" is then written to the answer row and the value&amp;nbsp;"2" carried forward to the shillings column. This operation is repeated using the values in the shillings column, with the additional step of adding the value that was carried forward from the pennies column. The intermediate total is divided by&amp;nbsp;20 as there are 20&amp;nbsp;shillings in a pound. The pound column is then processed, but as pounds are the largest unit that is being considered, no values are carried forward from the pounds column.

For the sake of simplicity, the example chosen did not have farthings.
|}

===Operations in practice===
[[File:Yarloop wkshop gnangarra 14.jpg|thumb|A scale calibrated in imperial units with an associated cost display.]]
During the 19th and 20th centuries various aids were developed to aid the manipulation of compound units, particularly in commercial applications. The most common aids were mechanical tills which were adapted in countries such as the United Kingdom to accommodate pounds, shillings, pennies and farthings and "Ready Reckoners"&amp;nbsp;– books aimed at traders that catalogued the results of various routine calculations such as the percentages or multiples of various sums of money. One typical booklet&lt;ref&gt;{{cite book
|url=https://archive.org/stream/cihm_94706#page/n5/mode/2up
|title=The Ready Reckoner in miniature containing accurate table from one to the thousand at the various prices from one farthing to one pound.
|first=J
|last=Thomson
|location=Montreal
|year=1824
|accessdate=25 March 2012}}&lt;/ref&gt; that ran to 150&amp;nbsp;pages tabulated multiples "from one to ten thousand at the various prices from one farthing to one pound".

The cumbersome nature of compound unit arithmetic has been recognized for many years&amp;nbsp;– in 1586, the Flemish mathematician [[Simon Stevin]] published a small pamphlet called ''[[De Thiende]]'' ("the tenth")&lt;ref&gt;{{MacTutor|id=Stevin|date=January 2004}}&lt;/ref&gt; in which he declared the universal introduction of decimal coinage, measures, and weights to be merely a question of time. In the modern era, many conversion programs, such as that included in the Microsoft Windows&amp;nbsp;7 operating system calculator, display compound units in a reduced decimal format rather than using an expanded format (i.e. "2.5&amp;nbsp;ft" is displayed rather than {{nowrap|"2 ft 6 in"}}).

==Number theory==
{{main|Number theory}}
Until the 19th century, ''number theory'' was a synonym of "arithmetic". The addressed problems were directly related to the basic operations and concerned [[prime number|primality]], [[divisibility]], and the [[Diophantine equation|solution of equations in integers]], such as [[Fermat's last theorem]]. It appeared that most of these problems, although very elementary to state, are very difficult and may not be solved without very deep mathematics involving concepts and methods from many other branches of mathematics. This led to new branches of number theory such as [[analytic number theory]], [[algebraic number theory]], [[Diophantine geometry]] and [[arithmetic algebraic geometry]]. [[Wiles' proof of Fermat's Last Theorem]] is a typical example of the necessity of sophisticated methods, which go far beyond the classical methods of arithmetic, for solving problems that can be stated in elementary arithmetic.

==Arithmetic in education==
[[Primary education]] in mathematics often places a strong focus on algorithms for the arithmetic of [[natural number]]s, [[integer]]s, [[arithmetic fraction|fractions]], and [[decimal]]s (using the decimal place-value system). This study is sometimes known as algorism.

The difficulty and unmotivated appearance of these algorithms has long led educators to question this curriculum, advocating the early teaching of more central and intuitive mathematical ideas. One notable movement in this direction was the [[New Math]] of the 1960s and 1970s, which attempted to teach arithmetic in the spirit of axiomatic development from set theory, an echo of the prevailing trend in higher mathematics.&lt;ref&gt;[https://web.archive.org/web/20000519063231/http://mathematicallycorrect.com/glossary.htm Mathematically Correct: Glossary of Terms&lt;!--Bot generated title--&gt;]&lt;/ref&gt;

Also, arithmetic was used by [[Ulama|Islamic Scholars]] in order to teach application of the rulings related to [[Zakat]] and [[Islamic inheritance jurisprudence|Irth]]. This was done in a book entitled ''The Best of Arithmetic'' by Abd-al-Fattah-al-Dumyati.&lt;ref&gt;{{cite web |last=al-Dumyati |first=Abd-al-Fattah Bin Abd-al-Rahman al-Banna |url={{wdl|3945}} |date=1887 |title=The Best of Arithmetic |work=[[World Digital Library]] |language=Arabic |accessdate=30 June 2013}}&lt;/ref&gt;

The book begins with the foundations of mathematics and proceeds to its application in the later chapters.

==See also==
* {{Portal inline|size=tiny|Arithmetic}}
* [[Lists of mathematics topics]]
* [[Outline of arithmetic]]
* [[Slide rule]]

===Related topics===
{{Div col|colwidth=30em}}
* [[Addition of natural numbers]]
* [[Additive inverse]]
* [[Arithmetic coding]]
* [[Arithmetic mean]]
* [[Arithmetic progression]]
* [[Arithmetic properties]]
* [[Associativity]]
* [[Commutativity]]
* [[Distributivity]]
* [[Elementary arithmetic]]
* [[Finite field arithmetic]]
* [[Geometric progression]]
* [[Integer]]
* [[List of important publications in mathematics]]
* [[Mental calculation]]
* [[Number line]]
{{colend}}

==Notes==
{{Reflist}}

==References==
{{refbegin|2}}
* Cunnington, Susan, ''The Story of Arithmetic: A Short History of Its Origin and Development'', Swan Sonnenschein, London, 1904
* [[Leonard Eugene Dickson|Dickson, Leonard Eugene]], ''[[History of the Theory of Numbers]]'' (3 volumes), reprints: Carnegie Institute of Washington, Washington, 1932; Chelsea, New York, 1952, 1966
* [[Leonhard Euler|Euler, Leonhard]], ''[https://web.archive.org/web/20110413234352/http://web.mat.bham.ac.uk/C.J.Sangwin/euler/ Elements of Algebra]'', Tarquin Press, 2007
* [[Henry Burchard Fine|Fine, Henry Burchard]] (1858–1928), ''The Number System of Algebra Treated Theoretically and Historically'', Leach, Shewell &amp; Sanborn, Boston, 1891
* [[Louis Charles Karpinski|Karpinski, Louis Charles]] (1878–1956), ''The History of Arithmetic'', Rand McNally, Chicago, 1925; reprint: Russell &amp; Russell, New York, 1965
* [[Øystein Ore|Ore, Øystein]], ''Number Theory and Its History'', McGraw–Hill, New York, 1948
* [[André Weil|Weil, André]], ''Number Theory: An Approach through History'', Birkhauser, Boston, 1984; reviewed: [[Mathematical Reviews]] 85c:01004
{{refend}}

==External links==
{{Wiktionary}}
{{Wikibooks}}
{{Commons category|Arithmetic}}
{{Wikiquote}}
* [http://mathworld.wolfram.com/Arithmetic.html MathWorld article about arithmetic]
* [[:s:The New Student's Reference Work/Arithmetic|The New Student's Reference Work/Arithmetic]] (historical)
* [http://mathdl.maa.org/convergence/1/?pa=content&amp;sa=viewDocument&amp;nodeId=1293&amp;bodyId=1422 The Great Calculation According to the Indians, of Maximus Planudes] – an early Western work on arithmetic at [https://web.archive.org/web/20070713083148/http://mathdl.maa.org/convergence/1/ Convergence]
* {{cite AmCyc |last=Weyde |first=P. H. Vander |wstitle=Arithmetic|short=x}}

{{Areas of mathematics | state=collapsed}}

{{Authority control}}

[[Category:Arithmetic| ]]
[[Category:Mathematics education]]</text>
      <sha1>1k7f0o2ew1acbt8bwfwmfpge3r8hnhv</sha1>
    </revision>
  </page>
  <page>
    <title>Cohomological descent</title>
    <ns>0</ns>
    <id>44456093</id>
    <revision>
      <id>647264205</id>
      <parentid>644871660</parentid>
      <timestamp>2015-02-15T17:00:37Z</timestamp>
      <contributor>
        <username>Ironholds</username>
        <id>6804626</id>
      </contributor>
      <comment>Added tags to the page using [[Wikipedia:Page Curation|Page Curation]] (citation style)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1311">{{citation style|date=February 2015}}

In algebraic geometry, a '''cohomological descent''' is, roughly, a "[[derived category|derived]]" version of a fully faithful descent in the classical [[descent theory]]. This point is made precise by the below: the following are equivalent:&lt;ref&gt;{{harvnb|Conrad|loc=Lemma 6.8.}}&lt;/ref&gt; in an appropriate setting, given a map ''a'' from a simplicial space ''X'' to a space ''S'', 
*&lt;math&gt;a^*: D^+(S) \to D^+(X)&lt;/math&gt; is fully faithful.
*The natural transformation &lt;math&gt;\operatorname{id}_{D^+(S)} \to Ra_* \circ a^*&lt;/math&gt; is an isomorphism.
The map ''a'' is then said to be a morphism of cohomological descent.&lt;ref&gt;{{harvnb|Conrad|loc=Definition 6.5.}}&lt;/ref&gt;

The treatment in SGA uses a lot of [[topos theory]]. Conrad's notes gives a more down-to-earth exposition.

== See also ==
*[[hypercovering]], of which a cohomological descent is a generalization

== References ==
{{reflist}}
*SGA4 V&lt;sup&gt;bis&lt;/sup&gt; [http://library.msri.org/books/sga/sga/pdf/sga4-2.pdf]
*Brian Conrad, Cohomological descent [http://math.stanford.edu/~conrad/papers/hypercover.pdf]
*P. Deligne, ''Théorie des Hodge III,'' Publ. Math. IHES 44 (1975), pp.&amp;nbsp;6–77.

== External links ==
*http://ncatlab.org/nlab/show/cohomological+descent


{{topology-stub}}



[[Category:Algebraic geometry]]</text>
      <sha1>parrd84c68wlwx0uzecg82qq8y3723e</sha1>
    </revision>
  </page>
  <page>
    <title>Convex subgraph</title>
    <ns>0</ns>
    <id>36279953</id>
    <revision>
      <id>507936182</id>
      <parentid>507935937</parentid>
      <timestamp>2012-08-18T04:08:09Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>stub sort</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1827">[[Image:6n-graf.svg|thumb|In this graph, triangle 1-2-5 is convex, but path 2-3-4 is not, because it does not include one of the two shortest paths from 2 to 4.]]
In metric [[graph theory]], a '''convex subgraph''' of an undirected graph ''G'' is a subgraph that includes every [[shortest path]] in ''G'' between two of its vertices. Thus, it is analogous to the definition of a [[convex set]] in geometry, a set that contains the line segment between every pair of its points.

Convex subgraphs play an important role in the theory of [[partial cube]]s and [[median graph]]s. In particular, in median graphs, the convex subgraphs have the [[Helly property]]: if a family of convex subgraphs has the property that all pairwise intersections are nonempty, then the whole family has a nonempty intersection.

==References==
*{{citation
 | last1 = Bandelt | first1 = H.-J.
 | last2 = Chepoi | first2 = V.
 | contribution = Metric graph theory and geometry: a survey
 | editor1-last = Goodman | editor1-first = J. E. | editor1-link = Jacob E. Goodman
 | editor2-last = Pach | editor2-first = J. | editor2-link = János Pach
 | editor3-last = Pollack | editor3-first = R.
 | location = Providence, RI
 | pages = 49–86
 | publisher = AMS
 | series = Contemporary Mathematics
 | title = Surveys on Discrete and Computational Geometry: Twenty Years Later
 | url = http://pageperso.lif.univ-mrs.fr/~victor.chepoi/survey_cm_bis.pdf
 | volume = 453
 | year = 2008}}.
*{{citation
 | last1 = Imrich | first1 = Wilfried | last2 = Klavžar | first2 = Sandi
 | title = A convexity lemma and expansion procedures for bipartite graphs
 | journal = [[European Journal of Combinatorics]]
 | volume = 19 | year = 1998
 | issue = 6 | pages = 677–686
 | mr = 1642702
 | doi = 10.1006/eujc.1998.0229}}.

[[Category:Graph theory]]


{{combin-stub}}</text>
      <sha1>scr2vdnh58h0ud7obfyinx03gcrv2df</sha1>
    </revision>
  </page>
  <page>
    <title>Coxeter–James Prize</title>
    <ns>0</ns>
    <id>18739444</id>
    <revision>
      <id>866488924</id>
      <parentid>858390101</parentid>
      <timestamp>2018-10-30T17:11:56Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>/* Recipients of the Coxeter–James Prize */ added wikipedia links for Hinson &amp; Spivakovsky</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2026">The '''Coxeter–James Prize''' is presented annually by the [[Canadian Mathematical Society]].  The award is presented to young mathematicians in recognition of outstanding contributions to mathematical research. The first award was presented in 1978. The prize was named in honor of the mathematicians [[Donald Coxeter]] and [[Ralph Duncan James|Ralph James]].&lt;ref&gt;[http://www.cms.math.ca/Prizes/info/cj.html Coxeter–James Prize]&lt;/ref&gt;

==Recipients of the Coxeter–James Prize==
Source: [http://cms.math.ca/Prizes/info/cj.html  Canadian Mathematical Society ]
{{columns-list|colwidth=30em|
* 2018: [[Maksym Radziwill]]
* 2017: [[Sabin Cautis]]
* 2016: [[Louigi Addario-Berry]]
* 2015: [[Dong Li]]
* 2014: [[Marco Gualtieri]]
* 2013: [[Balázs Szegedy]]
* 2012: Gregory Smith
* 2011: Iosif Polterovich
* 2010: [[Bálint Virág]]
* 2009: [[Patrick Brosnan]] 
* 2008: [[Ravi Vakil]]
* 2007: Vinayak Vatsal  	
* 2006: [[Jim Geelen]] 	
* 2005: Robert McCann 	
* 2004: [[Izabella Łaba]]
* 2003: Jingyi Chen 	
* 2002: [[Lisa Jeffrey]]	
* 2001: [[Kai Behrend]] 	
* 2000: Damien Roy 	
* 1999: [[Maciej Zworski]] 	
* 1998: [[Henri Darmon]] 	
* 1997: Michael Ward 
* 1996: [[Nigel Higson]] 	
* 1995: [[Gordon Douglas Slade|Gordon Slade]] 	
* 1994: [[Mark Spivakovsky]] 	
* 1993: [[Jacques Hurtubise (mathematician)|Jacques Hurtubise]]
* 1992: [[Rick Jardine|J.F. Jardine]] 	
* 1991: [[V. Kumar Murty]] 	
* 1990: [[Nassif Ghoussoub]]
* 1989: Alan Dow
* 1988: [[M. Ram Murty]]
* 1987: [[Jonathan Borwein]]
* 1986: [[Ed Perkins|Edwin A. Perkins]]
* 1985: Paul Selick
* 1984: [[Mark Goresky]]
* 1983: [[Man-Duen Choi]]
* 1982: John Mallet-Paret
* 1981: John James Millson
* 1980: Francis Clarke
* 1979: [[David William Boyd|David W. Boyd]]
* 1978: [[Robert Moody]]
}}

==References==
{{Reflist}}

==External links==
* [http://www.cms.math.ca/ Canadian Mathematical Society]

{{DEFAULTSORT:Coxeter-James Prize}}
[[Category:Mathematics awards]]
[[Category:Awards established in 1978]]
[[Category:Canadian science and technology awards]]</text>
      <sha1>mjtqo9a78g7kwy7av8cdvt3gg0kex11</sha1>
    </revision>
  </page>
  <page>
    <title>Discrete metric</title>
    <ns>0</ns>
    <id>4372105</id>
    <redirect title="Discrete space" />
    <revision>
      <id>669056767</id>
      <parentid>43502906</parentid>
      <timestamp>2015-06-28T15:45:47Z</timestamp>
      <contributor>
        <username>SoSivr</username>
        <id>23449906</id>
      </contributor>
      <comment>added [[Category:Metric geometry]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="58">#REDIRECT [[Discrete space]]

[[Category:Metric geometry]]</text>
      <sha1>3chh5rfridgaghgbik9t7dbzwwjglqu</sha1>
    </revision>
  </page>
  <page>
    <title>Dominating decision rule</title>
    <ns>0</ns>
    <id>4120077</id>
    <revision>
      <id>647061661</id>
      <parentid>544297092</parentid>
      <timestamp>2015-02-14T06:31:08Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>source</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1163">In [[decision theory]], a decision rule is said to '''dominate''' another if the performance of the former is sometimes better, and never worse, than that of the latter.

Formally, let &lt;math&gt;\delta_1&lt;/math&gt; and &lt;math&gt;\delta_2&lt;/math&gt; be two [[decision theory|decision rules]], and let &lt;math&gt;R(\theta, \delta)&lt;/math&gt; be the [[risk function|risk]] of rule &lt;math&gt;\delta&lt;/math&gt; for parameter &lt;math&gt;\theta&lt;/math&gt;. The decision rule &lt;math&gt;\delta_1&lt;/math&gt; is said to dominate the rule &lt;math&gt;\delta_2&lt;/math&gt; if &lt;math&gt;R(\theta,\delta_1)\le R(\theta,\delta_2)&lt;/math&gt; for all &lt;math&gt;\theta&lt;/math&gt;, and the inequality is strict for some &lt;math&gt;\theta&lt;/math&gt;.&lt;ref name="fusion"&gt;{{citation|title=Data Fusion in Robotics &amp; Machine Intelligence|first1=Mongi|last1=Abadi|last2=Gonzalez|first2=Rafael C.|publisher=Academic Press|year=1992|isbn=9780323138352|page=227|url=https://books.google.com/books?id=47kOwU1xvMMC&amp;pg=PA227}}.&lt;/ref&gt;

This defines a [[partial order]] on decision rules; the [[maximal element]]s with respect to this order are called ''[[admissible decision rule]]s.''&lt;ref name="fusion"/&gt;

==References==
{{reflist}}

{{statistics-stub}}
[[Category:Decision theory]]</text>
      <sha1>9pbsccpys3kc7i46660o3yx8eke4xhb</sha1>
    </revision>
  </page>
  <page>
    <title>Domineering</title>
    <ns>0</ns>
    <id>1190521</id>
    <revision>
      <id>862071609</id>
      <parentid>790054883</parentid>
      <timestamp>2018-10-02T00:09:37Z</timestamp>
      <contributor>
        <username>PJTraill</username>
        <id>522601</id>
      </contributor>
      <comment>/* See also */ (new section)  [[Blockbusting (game)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8222">{{about|the pen-and-paper-game|the concept of domination|Domination (disambiguation)}}
{{redirects|Stop-Gate|the waterway feature|floodgate}}
{{Infobox game
|title=domineering
|players=2
|set_up_time=5
|random_chance=none
|skills=[[strategy]]
|playing_time=less than 2 [[minutes]]
|genre=[[tile-based game]]
}}
'''Domineering''' (also called '''Stop-Gate''' or '''Crosscram''') is a [[mathematical game]] played on a sheet of [[graph paper]], with any set of designs traced out. For example, it can be played on a 6×6 square, a [[checkerboard]], an entirely irregular [[polygon]], or any combination thereof. Two players have a collection of [[domino]]es which they place on the grid in turn, covering up squares. One player, Left, plays tiles vertically, while the other, Right, plays horizontally. As in [[Normal play convention|most]] games in [[combinatorial game theory]], the first player who cannot move loses.

Domineering is a [[partisan game]], in that players use different pieces: the [[impartial game|impartial]] version of the game is [[Cram (game)|Cram]].

==Basic examples==

===Single box===
Other than the empty game, where there is no grid, the simplest game is a single box.

[[Image:20x20square.png]]

In this game, clearly, neither player can move. Since it is a second-player win, it is therefore a [[zero game]].

===Horizontal rows===
[[Image:20x20square.png]][[Image:20x20square.png]]

This game is a 2-by-1 grid.  There is a convention of assigning the game a [[positive number|positive]] number when Left is winning and a [[negative number|negative]] one when Right is winning. In this case, Left has no moves, while Right can play a domino to cover the entire board, leaving nothing, which is clearly a zero game. Thus in [[surreal number]] notation, this game is &lt;nowiki&gt;{|&lt;/nowiki&gt;0} = −1. This makes sense, as this grid is a 1-move advantage for Right.

[[Image:20x20square.png]][[Image:20x20square.png]][[Image:20x20square.png]]

This game is also &lt;nowiki&gt;{|&lt;/nowiki&gt;0} = −1, because a single box is unplayable.

[[Image:20x20square.png]][[Image:20x20square.png]][[Image:20x20square.png]][[Image:20x20square.png]]

This grid is the first case of a choice. Right ''could'' play the left two boxes, leaving −1. The rightmost boxes leave −1 as well. He could also play the middle two boxes, leaving two single boxes. This option leaves 0+0 = 0. Thus this game can be expressed as &lt;nowiki&gt;{|&lt;/nowiki&gt;0,−1}. This is −2. If this game is played in conjunction with other games, this is two free moves for Right.

====Vertical rows====
Vertical columns are evaluated in the same way. If there is a row of 2''n'' or 2''n''+1 boxes, it counts as −''n''. A column of such size counts as +''n''.

===More complex grids===
[[Image:20x20square.png]][[Image:20x20square.png]]&lt;br&gt;
[[Image:20x20square.png]][[Image:20x20square.png]]

This is a more complex game. If Left goes first, either move leaves a 1×2 grid, which is +1. Right, on the other hand, can move to −1. Thus the [[surreal number]] notation is {1|−1}.  However, this is not a surreal number because 1 &gt; −1. This is a Game but not a number. The notation for this is ±1, and it is a [[hot game]], because each player wants to move here.

[[Image:20x20square.png]][[Image:20x20square.png]][[Image:20x20square.png]]&lt;br&gt;
[[Image:20x20square.png]][[Image:20x20square.png]][[Image:20x20square.png]]

This is a 2×3 grid, which is even more complex, but, just like any Domineering game, it can be broken down by looking at what the various moves for Left and Right are. Left can take the left column (or, equivalently, the right column) and move to ±1, but it is clearly a better idea to split the middle, leaving two separate games, each worth +1. Thus Left's best move is to +2. Right has four "different" moves, but they all leave the following shape in some [[rotation]]:

[[Image:20x20square.png]][[Image:20x20square.png]][[Image:20x20square.png]]&lt;br&gt;
[[Image:20x20square.png]]

This game is not a hot game (also called a [[cold game]]), because each move hurts the player making it, as we can see by examining the moves. Left can move to −1, Right can move to 0 or +1. Thus this game is {−1|0,1} = {−1|0} = −½.

Our 2×3 grid, then, is {2|−½}, which can also be represented by the mean value, ¾, together with the bonus for moving (the "temperature"), 1¼, thus: &lt;math&gt;\textstyle\left\{2 \left| -\frac{1}{2}\right.\right\} = \frac{3}{4} \pm \frac{5}{4}&lt;/math&gt;

==High-level play==

The [[Mathematical Sciences Research Institute]] held a Domineering [[tournament]], with a $500 prize for the winner.  This game was played on an [[8×8 board]].  The winner was mathematician Dan Calistrate, who defeated David Wolfe in the final.  The tournament was detailed in Richard J. Nowakowski's ''Games of No Chance'' (p.&amp;nbsp;85).

==Winning strategy==

A problem about Domineering is to compute the winning strategy for large boards, and particularly square boards. In 2000, Dennis Breuker, Jos Uiterwijk and [[Jaap van den Herik]] computed and published the solution for the 8x8 board.&lt;ref&gt;{{Cite journal|title = Solving 8×8 Domineering|url = http://www.sciencedirect.com/science/article/pii/S0304397599000821|journal = Theoretical Computer Science|date = 2000-01-06|pages = 195-206|volume = 230|issue = 1–2|doi = 10.1016/S0304-3975(99)00082-1|first = D. M.|last = Breuker|first2 = J. W. H. M.|last2 = Uiterwijk|first3 = H. J.|last3 = van den Herik}}&lt;/ref&gt; The 9x9 board followed soon after some improvements of their program. Then, in 2002, Nathan Bullock solved the 10x10 board, as part of his thesis on Domineering.&lt;ref&gt;Nathan Bullock [http://webdocs.cs.ualberta.ca/~games/domineering/thesis.ps Domineering:Solving Large Combinatorial Search Spaces] M.Sc. thesis, 2002&lt;/ref&gt; The 11x11 board has been solved by Jos Uiterwijk in 2016.&lt;ref&gt;{{Cite conference|title = 11x11 Domineering Is Solved: The First Player Wins.|url = https://link.springer.com/chapter/10.1007%2F978-3-319-50935-8_12|conference = Computers and Games 2016|pages = 129-136|doi = 10.1007/978-3-319-50935-8_12|first = J. W. H.|last = Uiterwijk}}&lt;/ref&gt;

Domineering is a first-player win for the 6x6, 7x7, 8x8, 9x9, 10x10, and 11x11 square boards. The other known values for rectangular boards can be found on the site of Nathan Bullock.&lt;ref&gt;Nathan Bullock'site : [http://webdocs.cs.ualberta.ca/~games/domineering/updated.html Updated Game Theoretic Values for Domineering Boards]&lt;/ref&gt;

==Cram==
{{Further|Cram (game)}}
'''Cram''' is the [[impartial game|impartial]] version of Domineering.  The only difference in the rules is that each player may place their dominoes in either orientation. It seems only a small variation in the rules, but it results in a completely different game, that can be analyzed with the [[Sprague–Grundy theorem]].

== See also ==
* [[Blockbusting (game)]] A combinatorial game whose analysis has been applied to Domineering.

== References ==
&lt;references /&gt;
* {{cite book | first=Michael H. | last=Albert      | authorlink= Michael H. Albert
             | first2=Richard J. | last2=Nowakowski
             | first3=David      | last3=Wolfe      | author3-link=
  | title=Lessons in Play: An Introduction to Combinatorial Game Theory | publisher=A K Peters, Ltd.
  | year=2007 | isbn= 1-56881-277-9
  }}
* {{cite book | first=Elwyn R.   | last=Berlekamp | authorlink=Elwyn Berlekamp
             | first2=John H.    | last2=Conway   | author2-link=John Horton Conway
             | first3=Richard K. | last3=Guy      | author3-link=Richard K. Guy
  | title=[[Winning Ways for Your Mathematical Plays]] 
  | publisher=A K Peters, Ltd. | year=2003 | isbn=0-12-091150-7 
  }}
* {{cite journal | first=Martin | last=Gardner |authorlink=Martin Gardner | title=Mathematical Games: Cram, crosscram and quadraphage: new games having elusive winning strategies
  | journal=Scientific American | volume=230 | issue=2 | year=1974 | pages=106–108
  }}

== External links ==
* {{bgg|7450|Stop-gate}}
* [http://www.papg.com/show?1TX6 Playable version at Pencil and Paper Games]

[[Category:Abstract strategy games]]
[[Category:Mathematical games]]
[[Category:Combinatorial game theory]]
[[Category:Paper-and-pencil games]]</text>
      <sha1>7pheyspt03djhztp5xpw96ar6fk535x</sha1>
    </revision>
  </page>
  <page>
    <title>E∞-operad</title>
    <ns>0</ns>
    <id>15845985</id>
    <revision>
      <id>757157775</id>
      <parentid>714712848</parentid>
      <timestamp>2016-12-29T03:30:36Z</timestamp>
      <contributor>
        <username>AxelBoldt</username>
        <id>2</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3947">{{DISPLAYTITLE:E&lt;sub&gt;∞&lt;/sub&gt;-operad}}
In the theory of [[operads]] in [[algebra]] and [[algebraic topology]], an '''E&lt;sub&gt;∞&lt;/sub&gt;-operad''' is a parameter space for a multiplication map that is [[associative]] and [[commutative]] "up to all higher [[homotopy|homotopies]]". (An operad that describes a multiplication that is  associative but not necessarily commutative "up to homotopy" is called an [[A-infinity operad|A&lt;sub&gt;∞&lt;/sub&gt;-operad]].)

== Definition ==
For the definition, it is necessary to work in the category of operads with an action of the [[symmetric group]]. An operad ''A'' is said to be an E&lt;sub&gt;∞&lt;/sub&gt;-operad if all of its spaces ''E''(''n'') are contractible; some authors also require the action of the symmetric group ''S&lt;sub&gt;n&lt;/sub&gt;'' on ''E''(''n'') to be free. In other [[Category (mathematics)|categories]] than topological spaces, the notion of ''contractibility'' has to be replaced by suitable analogs, such as [[Acyclic complex|acyclic]]ity in the category of [[chain complexes]].

== ''E''&lt;sub&gt;''n''&lt;/sub&gt;-operads and ''n''-fold loop spaces==
The letter ''E'' in the terminology stands for "everything" (meaning associative and commutative), and the infinity symbols says that commutativity is required up to "all" higher homotopies. More generally, there is a weaker notion of '''''E''&lt;sub&gt;''n''&lt;/sub&gt;-operad''' (''n'' ∈ '''N'''), parametrizing multiplications that are commutative only up to a certain level of homotopies. In particular,

* ''E''&lt;sub&gt;1&lt;/sub&gt;-spaces are [[A-infinity operad|''A''&lt;sub&gt;∞&lt;/sub&gt;-spaces]];
* ''E''&lt;sub&gt;2&lt;/sub&gt;-spaces are homotopy commutative ''A''&lt;sub&gt;∞&lt;/sub&gt;-spaces.

The importance of ''E''&lt;sub&gt;''n''&lt;/sub&gt;- and ''E''&lt;sub&gt;∞&lt;/sub&gt;-operads in topology stems from the fact that iterated [[loop space]]s, that is, spaces of continuous maps from an ''n''-dimensional sphere to another space ''X'' starting and ending at a fixed base point, constitute algebras over an ''E''&lt;sub&gt;''n''&lt;/sub&gt;-operad. (One says they are '''''E''&lt;sub&gt;''n''&lt;/sub&gt;-spaces'''.)  Conversely, any connected ''E''&lt;sub&gt;''n''&lt;/sub&gt;-space ''X'' is an ''n''-fold loop space on some other space (called ''B&lt;sup&gt;n&lt;/sup&gt;X'', the ''n''-fold [[classifying space]] of X).

== Examples ==
The most obvious, if not particularly useful, example of an ''E''&lt;sub&gt;∞&lt;/sub&gt;-operad is the ''commutative operad'' ''c'' given by ''c''(''n'')&amp;nbsp;=&amp;nbsp;*, a point, for all ''n''. Note that according to some authors, this is not really an ''E''&lt;sub&gt;∞&lt;/sub&gt;-operad because the ''S&lt;sub&gt;n&lt;/sub&gt;''-action is not free. This operad describes strictly associative and commutative multiplications. By definition, any other ''E''&lt;sub&gt;∞&lt;/sub&gt;-operad has a map to ''c'' which is a homotopy equivalence.

The [[Operad theory#"Little something" operads|operad of '''little ''n''-cubes''' or '''little ''n''-disks''']] is an example of an ''E''&lt;sub&gt;''n''&lt;/sub&gt;-operad that acts naturally on ''n''-fold loop spaces.

== See also ==
* [[operad]]
* [[A-infinity operad]]
* [[loop space]]

== References ==
* {{ cite journal
   | last = Stasheff
   | first = Jim | authorlink = Jim Stasheff
   | title = What Is...an Operad?
   | journal = [[Notices of the American Mathematical Society]]
   |date=June–July 2004
   | volume = 51
   | issue = 6
   | pages = 630&amp;ndash;631
   | url = http://www.ams.org/notices/200406/what-is.pdf
   | format = [[PDF]]
   | accessdate = 2008-01-17 }}

*{{cite book
 | author = J. P. May
 | year = 1972
 | publisher = Springer-Verlag
 | title = The Geometry of Iterated Loop Spaces
 | url = http://www.math.uchicago.edu/~may/BOOKSMaster.html
}}

*{{cite book
 | author = Martin Markl, [[Steve Shnider]], [[Jim Stasheff]]
 | year = 2002
 | title = Operads in Algebra, Topology and Physics
 | publisher = American Mathematical Society
 | url = http://www.ams.org/bookstore?fn=20&amp;arg1=survseries&amp;item=SURV-96
}}

{{DEFAULTSORT:E-Operad}}
[[Category:Abstract algebra]]
[[Category:Algebraic topology]]</text>
      <sha1>bhhphm70byicyeb1vfsut1uzjty4n1b</sha1>
    </revision>
  </page>
  <page>
    <title>Fermat's theorem</title>
    <ns>0</ns>
    <id>239599</id>
    <revision>
      <id>716290121</id>
      <parentid>661071381</parentid>
      <timestamp>2016-04-20T22:31:58Z</timestamp>
      <contributor>
        <username>Widefox</username>
        <id>1588193</id>
      </contributor>
      <comment>[[WP:SIA]] not dab</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="835">The works of the 17th-century mathematician [[Pierre de Fermat]] engendered many [[theorem]]s. '''Fermat's theorem''' may refer to one of the following theorems:

* [[Fermat's Last Theorem]], about integer solutions to ''a''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''b''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''c''&lt;sup&gt;''n''&lt;/sup&gt;
* [[Fermat's little theorem]], a property of prime numbers
* [[Fermat's theorem on sums of two squares]], about primes expressible as a sum of squares
* [[Fermat's theorem (stationary points)]], about local maxima and minima of differentiable functions
* [[Fermat's principle]], about the path taken by a ray of light
* [[Fermat polygonal number theorem]], about expressing integers as a sum of polygonal numbers

==See also==
* [[List of things named after Pierre de Fermat]]

{{SIA}}

[[Category:Set indices on mathematics]]</text>
      <sha1>o8ii1qw659g252tmos85wq87nki5u7a</sha1>
    </revision>
  </page>
  <page>
    <title>Fernando Codá Marques</title>
    <ns>0</ns>
    <id>43480206</id>
    <revision>
      <id>846588881</id>
      <parentid>833514966</parentid>
      <timestamp>2018-06-19T18:06:58Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16038">{{Infobox scientist
| name              = Fernando Codá Marques
| image             = Coda-Marques.png
| image_size        =
| caption           = 
| birth_date        = {{Birth date and age|1979|10|8}}
| birth_place       = [[São Carlos]], Brazil
| death_date        = 
| death_place       =
| residence         =
| citizenship       =
| nationality       = Brazilian
| fields            = [[Mathematics]]: [[geometric analysis]], [[geometric topology]]
| workplaces        = [[Princeton University]]&lt;br /&gt;[[Instituto Nacional de Matemática Pura e Aplicada|IMPA]]
| alma_mater        = [[Cornell University]] (Ph.D.)&lt;br /&gt;[[Instituto Nacional de Matemática Pura e Aplicada|IMPA]] (M.S.)&lt;br /&gt;[[Federal University of Alagoas|UFAL]] (B.S.)
| thesis_title      = Existence and Compactness Theorems on Conformal Deformation of Metrics
| thesis_year       = 2003
| doctoral_advisor  = [[José F. Escobar]]
| academic_advisors =
| doctoral_students =
| notable_students  =
| known_for         = [[Willmore conjecture]]&lt;br /&gt;[[Freedman–He–Wang conjecture]]&lt;br /&gt;[[Min-Oo conjecture]]&lt;br /&gt;[[Yau's conjecture]]&lt;br /&gt;Contributions to [[Almgren–Pitts min-max theory]]&lt;br /&gt;[[Yamabe problem]]
| author_abbrev_bot =
| author_abbrev_zoo =
| influences        = [[Richard Schoen]]&lt;br /&gt;[[Frederick J. Almgren, Jr.|Frederick Almgren, Jr.]]&lt;br /&gt;[[Manfredo do Carmo|Manfredo P. do Carmo]]&lt;br /&gt;[[Elon Lages Lima]]
| influenced        =
| awards            = [[Oswald Veblen Prize in Geometry|Veblen Prize in Geometry]] (2016)&lt;br /&gt;[[ICTP Ramanujan Prize]] (2012)&lt;br&gt;[[TWAS Prize]] (2012)
| signature         = &lt;!--(filename only)--&gt;
| footnotes         =
| spouse            = Ana Maria Menezes
| ethnicity         =
| website           = https://www.math.princeton.edu/directory/fernando-coda-marques
}}

'''Fernando Codá dos Santos Cavalcanti Marques''' (born 8 October 1979) is a [[Brazil]]ian [[mathematician]] working mainly in [[geometry]], [[topology]], [[partial differential equation]]s and [[Morse theory]]. He is a professor at [[Princeton University]]. In 2012, together with [[André Neves]], he proved the [[Willmore conjecture]].

==Biography==

Fernando Codá Marques was born on 8 October 1979 in [[São Carlos]] and grew up in [[Maceió]]. His parents were both professors of [[engineering]].&lt;ref name="ABC"&gt;[https://web.archive.org/web/20141006082630/http://www.abc.org.br/~CODA Brazilian Academy of Sciences]&lt;/ref&gt;&lt;ref name="alagoas"&gt;[http://culturadigital.br/cinciaalagoas/2011/07/08/alagoano-e-destaque-no-brasil-e-no-exterior/ "Alagoano é destaque no Brasil e no exterior"]. ''culturadigital.br'' (in Portuguese). Retrieved on 11 May 2016.&lt;/ref&gt;

Codá Marques started as a student of [[civil engineering]] at the [[Federal University of Alagoas]] in 1996, but switched to mathematics after two years.&lt;ref&gt;[http://redeglobo.globo.com/globouniversidade/entrevistas/noticia/2013/09/fernando-coda-relata-os-desafios-da-rotina-de-trabalho-de-um-matematico.html "Rede Globo &gt; entrevistas - Fernando Codá relata os desafios da  rotina de trabalho de um matemático"]. ''redeglobo.globo.com'' (in Portuguese). Retrieved on 11 May 2016.&lt;/ref&gt;&lt;ref&gt;Revista Turismo e Negócios – "[http://www.revistaturismoenegocios.com/materia.php?c=408 Entrevista: Pesquisador alagoano é destaque internacional]" (2011, in Portuguese)&lt;/ref&gt;

He obtained a master's degree from the [[Instituto Nacional de Matemática Pura e Aplicada]] (IMPA) in 1999. Among his teachers at the IMPA were [[Manfredo do Carmo]] and [[Elon Lages Lima]].&lt;ref&gt;http://www.ufal.edu.br/noticias/2013/08/alagoas-vira-referencia-em-formacao-de-matematicos-no-pais&lt;/ref&gt;

Following the advice of Manfredo do Carmo, Codá Marques went to [[Cornell University]] to learn [[geometric analysis]] from [[José F. Escobar]], so that he could return and bring this area of research to Brazil. While still in Brazil, Codá Marques had been informed that Escobar was facing cancer and that he could maybe die before Codá Marques could complete his Ph.D with him. Despite this information, Codá Marques decided to keep the arrangement and became his student.&lt;ref name="Piaui"&gt;{{citation|url=http://revistapiaui.estadao.com.br/edicao-87/vultos-das-ciencias/senhor-dos-aneis |title=Senhor dos anéis: Um grande resultado matemático e as suas consequências |magazine=[[piauí (magazine)|Revista Piauí]] |date=December 2013 |author=[[João Moreira Salles]] |language=Portuguese |deadurl=yes |archiveurl=https://web.archive.org/web/20140908153307/http://revistapiaui.estadao.com.br/edicao-87/vultos-das-ciencias/senhor-dos-aneis |archivedate=2014-09-08 |df= }}&lt;/ref&gt;

In 2001, Codá Marques was awarded Cornell's Battig Prize for graduate students, for "excellence and promise in mathematics".&lt;ref&gt;[https://www.math.cornell.edu/m/Graduate/Funds/awards "Department Prizes and Awards for Graduate Students"]. ''cornell.edu''. Retrieved on 11 May 2016.&lt;/ref&gt; He obtained his Ph.D. from Cornell University in 2003, under the supervision of José F. Escobar (thesis: ''Existence and Compactness Theorems on Conformal Deformation of Metrics'').&lt;ref&gt;{{MathGenealogy|id=77942}}&lt;/ref&gt;

Despite the usual path being to go for a postdoctoral research, Codá Marques had in mind that his mission was to return to Brazil. The [[Instituto Nacional de Matemática Pura e Aplicada]] (IMPA) had already offered him a position of researcher, and he accepted it. But after six months in Brazil, Escobar, who was his main connection with researchers outside of Brazil, died. Codá Marques faced the difficulties of doing research in isolation, so he decided to accept an invitation to stay one year as a postdoc at [[Stanford University]]. There he was influenced by [[Richard Schoen]]'s school of thought in geometry and met [[André Neves]] (who would become his main collaborator), and many other of his contacts.&lt;ref name="Piaui" /&gt;

He worked at the IMPA from 2003 to 2014.&lt;ref name="AMSN1604"&gt;{{citation|url=http://www.ams.org/publications/journals/notices/201604/rnoti-p429.pdf|title=2016 Oswald Veblen Prize in Geometry|journal=[[Notices of the AMS]]|date=April 2016|volume=63|issue=4|pages=429–431}}&lt;/ref&gt;

On September 1, 2014, Codá Marques joined [[Princeton University]] as a full professor.&lt;ref&gt;[https://www.princeton.edu/main/news/archive/S38/60/80C61/index.xml?section=topstories "Princeton University - Board approves three faculty appointments"]. ''princeton.edu''. Retrieved on 11 May 2016.&lt;/ref&gt;

==Mathematical work==

{{expand section|date=February 2018}}

Some of his best known works are the following:&lt;ref name="AMSN1604" /&gt;&lt;ref&gt;[http://www.im.uj.edu.pl/en/lojasiewicz/2014/fernando-coda-marques Web-site of the Institute of Mathematics of the Jagiellonian University &gt; Research &gt; Łojasiewicz Lecture &gt; Past lectures &gt; 2014 Lecture &gt; Fernando Coda Marques] Retrieved on 20 May 2016.&lt;/ref&gt;

=== Yamabe problem ===

In 2009, together with [[Richard Schoen]] and Marcus Khuri he did important work on the [[Yamabe problem]].&lt;ref&gt;Khuri, M. A., Marques, F. C., &amp; Schoen, R. M. (2009). A compactness theorem for the Yamabe problem. ''Journal of Differential Geometry'', 81(1), 143–196.&lt;/ref&gt;&lt;ref&gt;Marques, F. C. (2005). A priori estimates for the Yamabe problem in the non-locally conformally flat case. ''[[Journal of Differential Geometry]]'', 71(2), 315–346.&lt;/ref&gt; He solved Schoen's conjecture on compactness in the Yamabe problem for [[spin manifold]]s.

=== Rigidity conjecture of Min-Oo ===

In April 2010, in cooperation with [[Simon Brendle]] and [[André Neves]],&lt;ref&gt;{{Cite journal|title = Deformations of the hemisphere that increase scalar curvature|url = https://link.springer.com/article/10.1007/s00222-010-0305-4|journal = [[Inventiones Mathematicae]]|date = 2010-12-08|issn = 0020-9910|pages = 175–197|volume = 185|issue = 1|doi = 10.1007/s00222-010-0305-4|language = en|first = Simon|last = Brendle|first2 = Fernando C.|last2 = Marques|first3 = Andre|last3 = Neves|arxiv=1004.3088|bibcode = 2011InMat.185..175B}}&lt;/ref&gt; Marques provided a [[counter-example]] to the rigidity conjecture of Min-Oo.

=== Willmore conjecture ===

Codá Marques and Neves "Min-max theory and the Willmore conjecture" was uploaded to [[arXiv]] on February 2012, in it they solved the [[Willmore conjecture]], using [[Almgren–Pitts min-max theory]], which was then "a relatively old tool and already somewhat out of favor". According to [[Harold Rosenberg (mathematician)|Harold Rosenberg]], using this tool was possible because the pair discovered a connection between objects that were apparently very different: "connecting the problem with questions about minimal surfaces on the sphere [...] a priori there would be no reason for these things to be connected. It's curious, very curious.",&lt;ref name="Piaui" /&gt;&lt;ref&gt;{{Cite journal|title = Min-Max theory and the Willmore conjecture|url = http://annals.math.princeton.edu/2014/179-2/p06|journal = [[Annals of Mathematics]]|date = 2014-01-01|volume = 179|issue = 2|doi = 10.4007/annals.2014.179.2.6|pages = 683–782|first = Fernando|last = Marques|first2 = André|last2 = Neves|arxiv=1202.6036}}&lt;/ref&gt; the solution to the [[Willmore conjecture]]&lt;ref name="ramanujan" /&gt; ([[Thomas Willmore|Willmore]], 1965)

=== Freedman–He–Wang conjecture ===

In May 2012, in cooperation with [[Ian Agol]] and André Neves,&lt;ref&gt;{{Cite journal|title = Min-max theory and the energy of links|url = http://www.ams.org/jams/0000-000-00/S0894-0347-2015-00835-9/|journal = [[Journal of the American Mathematical Society]]|date = 2015-01-01|volume = 29|issn = 0894-0347|doi = 10.1090/jams/835|pages = 561–578|first = Ian|last = Agol|first2 = Fernando|last2 = Marques|first3 = André|last3 = Neves|arxiv=1205.0825}}&lt;/ref&gt; Marques provided the solution to the [[Freedman–He–Wang conjecture]] ([[Michael Freedman|Freedman]]–He–Wang, 1994)

=== Yau's conjecture ===
In December 2017, in cooperation with Kei Irie and André Neves, he solved [[Yau's conjecture]] ([[Shing-Tung Yau|Yau]], 1982) in the [[Generic property|generic]] case.&lt;ref&gt;https://arxiv.org/abs/1710.10752&lt;/ref&gt;

=== Almgren–Pitts min-max theory ===

Codá Marques and André Neves are currently working to extend [[Almgren–Pitts min-max theory]].&lt;ref&gt;{{citation|url=http://www.ams.org/journals/notices/201602/rnoti-p142.pdf|title=Interview with Fernando Codá Marques|journal=[[Notices of the AMS]]|date=February 2016|volume=63|issue=2|pages=142–143}}.&lt;/ref&gt;

==Honours==

He was an [[list of International Congresses of Mathematicians Plenary and Invited Speakers|invited speaker at the International Congress of Mathematicians]] (ICM) of 2010 in [[Hyderabad]] (on "[[Scalar curvature]], [[conformal geometry]], and the [[Ricci flow with surgery]]"),&lt;ref&gt;International Mathematical Union (IMU) . [http://www.mathunion.org/db/ICM/Speakers/SortedByLastname.php "ICM Plenary and Invited Speakers since 1897"]. ''mathunion.org''. Retrieved on 16 May 2016.&lt;/ref&gt; and a plenary speaker at the ICM of 2014 in [[Seoul]] (on "[[Minimal surface]]s – [[Calculus of variations|variational theory]] and applications").&lt;ref&gt;[http://www.icm2014.org/en/program/scientific/plenary Seoul ICM 2014 – Schedule of Plenary Lectures.] {{webarchive|url=https://web.archive.org/web/20150716122702/http://www.icm2014.org/en/program/scientific/plenary |date=2015-07-16 }}&lt;/ref&gt;

He received the [[TWAS Prize]] in 2012.&lt;ref name="Prizes and Awards"&gt;{{Cite web |url=http://twas.org/article/2012-twas-prize-winners-announced |title=Prizes and Awards |date=2016 |publisher=The World Academy of Sciences}}&lt;/ref&gt;

He was awarded the [[ICTP Ramanujan Prize]] in 2012.&lt;ref name="ramanujan"&gt;[http://www.abelprize.no/nyheter/vis.html?tid=54872 "News: Brazilian mathematician named Ramanujan Prize winner"]. ''abelprize.no''. Retrieved on 11 May 2016.&lt;/ref&gt;&lt;ref&gt;{{citation|url=http://www.ams.org/notices/201302/rnoti-p245.pdf|department=Mathematics People|title=Codá Marques Awarded Ramanujan and TWAS Prizes|journal=[[Notices of the AMS]]|page=245|date=February 2013|volume=60|issue=2|first=Elaine|last=Kehoe}}.&lt;/ref&gt;

In 2014 he gave the [[Łojasiewicz Lecture]] (on "The min-max theory of minimal surfaces and applications") at the [[Jagiellonian University|Jagiellonian University in Kraków]].&lt;ref&gt;{{Cite web|url=http://www.im.uj.edu.pl/en/lojasiewicz/2014/fernando-coda-marques|title=Fernando Coda Marques - Institute of Mathematics of the Jagiellonian University|website=www.im.uj.edu.pl|access-date=2016-12-29}}&lt;/ref&gt;

He is a full member of the [[Brazilian Academy of Sciences]] since 2014.&lt;ref name="ABC" /&gt;

He shared the 2016 [[Oswald Veblen Prize in Geometry]] with [[André Neves]].&lt;ref name="AMSN1604" /&gt;&lt;ref&gt;[http://www.ams.org/news?news_id=2866 "News, Events and Announcements"]. ''American Mathematical Society''. Retrieved on 11 May 2016.&lt;/ref&gt;

He was elected to the 2018 class of [[fellow]]s of the [[American Mathematical Society]].&lt;ref&gt;{{citation|url=http://ams.org/profession/ams-fellows/new-fellows|title=2018 Class of the Fellows of the AMS|publisher=[[American Mathematical Society]]|accessdate=2017-11-03}}&lt;/ref&gt;

He is a Distinguished Visiting Professor of Mathematics at the [[Institute for Advanced Studies]].&lt;ref&gt;https://www.ias.edu/scholars/fernando-coda-marques&lt;/ref&gt;

==Personal life==

He is married to mathematician Ana Maria Menezes de Jesus. She was a student of [[Harold Rosenberg (mathematician)|Harold Rosenberg]] at IMPA, and is currently an instructor of mathematics at Princeton University.&lt;ref&gt;[http://educacao.uol.com.br/noticias/2013/09/10/filha-de-agricultores-sergipana-de-26-anos-fara-pos-doutorado-na-franca.htm Paulo Rolemberg (2013) – "Filha de agricultores, sergipana de 26 anos fará pós-doutorado na França"]. ''UOL Educação''. Retrieved on 11 May 2016.&lt;/ref&gt;&lt;ref&gt;[https://www.math.princeton.edu/directory/ana-menezes "Ana Menezes"]. ''princeton.edu''. Retrieved on 11 May 2016.&lt;/ref&gt; Codá Marques and Menezes have a son named Pedro.&lt;ref&gt;[http://www.ams.org/profession/prizes-awards/PrizeBooklet-2016.pdf Joint Mathematics Meeting, Seattle, AMS, MAA, "Prizes and Awards", 2016]&lt;/ref&gt;

==References==
{{Reflist|2}}

==External links==
* [http://www.revistaturismoenegocios.com/materia.php?c=408 Interview with Fernando Codá Marques, 2011]
* [https://web.archive.org/web/20141006082630/http://www.abc.org.br/~CODA Academia Brasileira de Ciências – Fernando Codá dos Santos Cavalcanti Marques] (in Portuguese)
* [http://www.alagoas24horas.com.br/conteudo/?vCod=158709 Interview to Alagoas 24 Horas] (in Portuguese)
* [http://redeglobo.globo.com/globouniversidade/entrevistas/noticia/2013/09/fernando-coda-relata-os-desafios-da-rotina-de-trabalho-de-um-matematico.html Interview to Rede Globo] (in Portuguese)
* [http://www.cnpq.br/web/guest/noticias-popularizacao/-/journal_content/56_INSTANCE_a6MO/10157/1297679 CNPq – Jovem matemático é destaque no Brasil e no exterior] (in Portuguese)
* [http://www.abc.org.br/article.php3?id_article=582 Academia Brasileira de Ciências – Especial: Membros Afiliados da ABC do Rio de Janeiro 2009] (in Portuguese)
* {{MathGenealogy|id=77942}}
* Fernando Codá Marques' lecture "[https://www.youtube.com/watch?v=eBfXE3B3Yxw Soap films in mathematics]" (video from 2014)

{{Authority control}}

{{Veblen Prize recipients}}

{{DEFAULTSORT:Coda Marques, Fernando}}
[[Category:21st-century Brazilian mathematicians]]
[[Category:1979 births]]
[[Category:Living people]]
[[Category:Cornell University alumni]]
[[Category:Princeton University faculty]]
[[Category:Differential geometers]]
[[Category:Members of the Brazilian Academy of Sciences]]
[[Category:People from São Carlos]]
[[Category:PDE theorists]]
[[Category:Topologists]]
[[Category:Instituto Nacional de Matemática Pura e Aplicada alumni]]
[[Category:Instituto Nacional de Matemática Pura e Aplicada researchers]]
[[Category:Brazilian expatriate academics in the United States]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:TWAS laureates]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>e1kngel6xjn5ovcwrz7040uqimgdmef</sha1>
    </revision>
  </page>
  <page>
    <title>Fluxion</title>
    <ns>0</ns>
    <id>52956308</id>
    <revision>
      <id>853091736</id>
      <parentid>841210411</parentid>
      <timestamp>2018-08-02T11:16:52Z</timestamp>
      <contributor>
        <username>Iffy</username>
        <id>769695</id>
      </contributor>
      <minor/>
      <comment>Disambiguated: [[rate of change]] → [[Instantaneous rate of change]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4758">{{about|the mathematical concept}}
{{Calculus}}
The '''fluxion''' of a "[[fluent (mathematics)|fluent]]" (a time-varying quantity, or [[function (mathematics)|function]]) is its instantaneous [[Instantaneous rate of change|rate of change]], or [[gradient]], at a given point.&lt;ref&gt;{{cite book|last1=Newton|first1=Sir Isaac|title=The Method of Fluxions and Infinite Series: With Its Application to the Geometry of Curve-lines|date=1736|publisher=Henry Woodfall; and sold by John Nourse|url=https://books.google.com/books?id=WyQOAAAAQAAJ|accessdate=6 March 2017|language=en}}&lt;/ref&gt; Fluxions were introduced by [[Isaac Newton]] to describe his form of a [[time derivative]] (a [[derivative]] with respect to time). Newton introduced the concept in 1665 and detailed them in his [[mathematics|mathematical]] treatise, ''[[Method of Fluxions]]''.&lt;ref&gt;{{MathWorld|Fluxion}}&lt;/ref&gt; Fluxions and fluents made up Newton's early [[calculus]].&lt;ref&gt;{{Britannica|fluxion}}&lt;/ref&gt;

==History==
Fluxions were central to the [[Leibniz–Newton calculus controversy]], when Newton sent a letter to [[Gottfried Wilhelm Leibniz]] explaining them, but concealing his words in code due to his suspicion. He wrote:&lt;ref&gt;{{cite book|last1=Turnbull|first1=Isaac Newton. Ed. by H.W.|title=The correspondence of Isaac Newton|date=2008|publisher=Univ. Press|location=Cambridge [u.a.]|isbn=9780521737821|edition=Digitally printed version, pbk. re-issue.}}&lt;/ref&gt;
{{quote|I cannot proceed with the explanations of the fluxions now, I have preferred to conceal it thus: 6accdæ13eff7i319n4o4qrr4s8t12vz}}
The gibberish string was in fact an [[cipher|enciphered]] [[Latin]] phrase, meaning: "Given an equation that consists of any number of flowing quantities, to find the fluxions: and vice versa".&lt;ref name="clegg"&gt;{{cite book|last1=Clegg|first1=Brian|title=A brief history of infinity: the quest to think the unthinkable|date=2003|publisher=Constable|location=London|isbn=9781841196503}}&lt;/ref&gt;

==Example==
If the fluent {{tmath|y}} is defined as &lt;math&gt;y=t^2&lt;/math&gt; (where {{tmath|t}} is time) the fluxion (derivative) at &lt;math&gt;t=2&lt;/math&gt; is:
:&lt;math&gt;\dot y = \frac{\Delta y}{\Delta t} = \frac{(2+o)^2-2^2}{(2+o)-2} = \frac{4+4o+o^2-4}{2+o-2} = 4+o&lt;/math&gt;
Here {{tmath|o}} is an [[infinitesimal|infinitely small]] amount of time&lt;ref&gt;{{cite web|last1=Buckmire|first1=Ron|title=History of Mathematics|url=https://sites.oxy.edu/ron/math/395/10/ws/23.pdf|accessdate=28 January 2017}}&lt;/ref&gt; and according to Newton, we can now ignore it because of its infinite smallness.&lt;ref&gt;{{cite web|title=Isaac Newton (1642-1727)|url=http://www.mhhe.com/math/calc/smithminton2e/cd/tools/timeline/newton.html|website=www.mhhe.com|accessdate=6 March 2017}}&lt;/ref&gt; He justified the use of {{tmath|o}} as a non-zero quantity by stating that fluxions were a consequence of movement by an object.

==Criticism==
Bishop [[George Berkeley]], a prominent [[philosopher]] of the time, slammed Newton's fluxions in his essay [[The Analyst]], published in 1734.&lt;ref&gt;{{cite wikisource |title=The Analyst: a Discourse addressed to an Infidel Mathematician|wslink=The Analyst: a Discourse addressed to an Infidel Mathematician#XVI|last=Berkeley |first=George |authorlink=George Berkeley |year=1734 |location=London |page=25}}&lt;/ref&gt; Berkeley refused to believe that they were accurate because of the use of the [[infinitesimal]] {{tmath|o}}. He did not believe it could be ignored and pointed out that if it was zero, the consequence would be [[division by zero]]. Berkeley referred to them as "ghosts of departed quantities", a statement which unnerved mathematicians of the time and led to the eventual disuse of infinitesimals in calculus.

Towards the end of his life Newton revised his interpretation of {{tmath|o}} as [[infinitesimal|infinitely small]], preferring to define it as approaching [[zero]], using a similar definition to the concept of [[limit (mathematics)|limit]].&lt;ref&gt;{{cite journal|last1=Kitcher|first1=Philip|title=Fluxions, Limits, and Infinite Littlenesse. A Study of Newton's Presentation of the Calculus|journal=Isis|date=March 1973|volume=64|issue=1|pages=33–49|doi=10.1086/351042}}&lt;/ref&gt; He believed this put fluxions back on safe ground. By this time, Leibniz's derivative (and his notation) had largely replaced Newton's fluxions and fluents and remain in use today.

==See also==
{{div col|colwidth=22em}}
*''[[Method of Fluxions]]
*[[History of calculus]]
*[[Leibniz–Newton calculus controversy]]
*[[Derivative]]
*[[Newton's notation]]
*[[Fluent (mathematics)]]
{{div col end}}
{{portal bar|Mathematics}}

==References==
{{reflist}}

{{Calculus topics}}
{{Isaac Newton|state=collapsed}}
[[Category:Mathematical analysis]]
[[Category:Differential calculus]]
[[Category:History of calculus]]</text>
      <sha1>9mrh5wicrq8lw8xav68apqaulqujnd7</sha1>
    </revision>
  </page>
  <page>
    <title>Gottlob Frege</title>
    <ns>0</ns>
    <id>48416</id>
    <revision>
      <id>871761575</id>
      <parentid>867508126</parentid>
      <timestamp>2018-12-03T07:18:49Z</timestamp>
      <contributor>
        <username>Jemma88085</username>
        <id>33154167</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="43213">{{Use dmy dates|date=October 2012}}
{{Infobox philosopher
| region = [[Western philosophy]]
| era = [[19th-century philosophy]]&lt;br /&gt;[[20th-century philosophy]]
| image = Young frege.jpg
| caption = Frege in c. 1879
| name = Gottlob Frege
| birth_date  = 8 November 1848
| birth_place = [[Wismar]], [[Grand Duchy of Mecklenburg-Schwerin|Mecklenburg-Schwerin]], [[German Confederation|Germany]]
| death_date  = {{Death date and age|df=yes|1925|7|26|1848|11|8}}
| death_place = [[Bad Kleinen]], [[Free State of Mecklenburg-Schwerin|Mecklenburg-Schwerin]], [[Weimar Republic|Germany]]
| education   = [[University of Göttingen]] ([[PhD]], 1873)&lt;br&gt;[[University of Jena]] ([[Dr. phil. hab.]], 1874)
| school_tradition = [[Analytic philosophy]]&lt;br&gt;[[Linguistic turn]]&lt;br&gt;[[Logical objectivism]]&lt;br&gt;[[Modern Platonism]]&lt;ref name=SEP-P&gt;[https://plato.stanford.edu/entries/platonism/ Platonism in Metaphysics (Stanford Encyclopedia of Philosophy)]&lt;/ref&gt;&lt;br&gt;[[Logicism]]&lt;br&gt;[[Transcendental idealism]]&lt;ref&gt;[[Hans Sluga]], "Frege's alleged realism," ''Inquiry'' 20 (1–4):227–242 (1977).&lt;/ref&gt;&lt;ref name="Resnik"&gt;[[Michael Resnik]], "II. Frege as Idealist and then Realist," ''Inquiry'' 22 (1–4):350–357 (1979).&lt;/ref&gt; (before 1891)&lt;br&gt;[[Metaphysical realism]]&lt;ref name="Resnik" /&gt; (after 1891)&lt;br&gt;[[Foundationalism]]&lt;ref&gt;[[Tom Rockmore]], ''On Foundationalism: A Strategy for Metaphysical Realism'', Rowman &amp; Littlefield, 2004, p. 111.&lt;/ref&gt;&lt;br&gt;[[Indirect realism]]&lt;ref&gt;Frege criticized [[direct realism]] in his "[[On Sense and Reference|Über Sinn und Bedeutung]]" (see Samuel Lebens, ''Bertrand Russell and the Nature of Propositions: A History and Defence of the Multiple Relation Theory of Judgement'', Routledge, 2017, p. 34).&lt;/ref&gt;&lt;br&gt;[[Redundancy theory of truth]]&lt;ref name=IEP-T/&gt;
| main_interests   = [[Philosophy of mathematics]], [[mathematical logic]], [[philosophy of language]]
| influences       = [[Immanuel Kant]], [[Kuno Fischer]], [[Bruno Bauch]],&lt;ref&gt;[[Hans Sluga]] (1980), ''Gottlob Frege'', Routledge, pp. 53ff.&lt;/ref&gt; [[Friedrich Adolf Trendelenburg]],&lt;ref name="Brandom"&gt;[[Robert Boyce Brandom]], "Frege's Technical Concepts", in [https://books.google.com/books?id=DwxUZZF21mQC&amp;hl=el&amp;source=gbs_navlinks_s ''Frege Synthesized: Essays on the Philosophical and Foundational Work of G. Frege''], L. Haaparanta and J. Hintikka, Synthese Library, D. Reidel, 1986, pp. 253–295&lt;/ref&gt; [[Hermann Lotze]],&lt;ref name="Brandom" /&gt; [[Otto Liebmann]],&lt;ref&gt;Gottfried Gabriel, "Frege, Lotze, and the Continental Roots of Early Analytic Philosophy," in: Erich H. Reck (ed.). ''From Frege to Wittgenstein: Perspectives on Early Analytic Philosophy'', Oxford University Press, 2002, pp. 39–51, esp. 44–48.&lt;/ref&gt; [[Benno Kerry]],&lt;ref&gt;Tom Ricketts, Michael Potter, ''The Cambridge Companion to Frege'', Cambridge University Press, 2010, p. 179.&lt;/ref&gt; [[Ernst Abbe]], [[David Hume]], [[Gottfried Wilhelm Leibniz|G. W. Leibniz]], [[Bernard Bolzano]]&lt;ref&gt;Sundholm, B. G., [https://openaccess.leidenuniv.nl/handle/1887/10421 "When, and why, did Frege read Bolzano?"], LOGICA Yearbook 1999, 164–174 (2000).&lt;/ref&gt;
| influenced = [[Giuseppe Peano]], [[Bertrand Russell]], [[Rudolf Carnap]], [[Ludwig Wittgenstein]], [[Michael Dummett]], [[Edmund Husserl]], [[Gershom Scholem]], [[Karl Popper]], and most of the [[Analytic philosophy|analytic tradition]] |[[Analytic Philosophy]], [[Ordinary language philosophy|Ordinary Language Philosophy]]
| notable_ideas    = [[Principle of compositionality]], [[context principle]], [[quantification theory]], [[predicate calculus]], [[logicism]],&lt;br&gt;[[sense and reference]], [[Frege's puzzles]], [[concept and object]], [[sortal]], [[Third Realm (Frege)|Third Realm]], [[mediated reference theory]] (Frege–Russell view), [[descriptivist theory of names]], [[redundancy theory of truth]],&lt;ref name=IEP-T&gt;[http://www.iep.utm.edu/truth/#SH7a Truth – Internet Encyclopedia of Philosophy]; [http://plato.stanford.edu/entries/truth-deflationary/#HisDef The Deflationary Theory of Truth (Stanford Encyclopedia of Philosophy)].&lt;/ref&gt; [[set-theoretic definition of natural numbers]], [[Hume's principle]], [[Basic Law V]], [[Frege's theorem]], [[Frege–Church ontology]], [[Frege–Geach problem]], [[law of trichotomy]], [[Currying|technique for binding arguments]]&lt;ref&gt;[[Willard Van Orman Quine]], introduction to "Bausteine der mathematischen Logik", pp.&amp;nbsp;305–316. Translated by Stefan Bauer-Mengelberg as "On the building blocks of mathematical logic" in [[Jean van Heijenoort]] (1967), ''A Source Book in Mathematical Logic, 1879–1931''. Harvard University Press, pp. 355–66.&lt;/ref&gt;
|notable_works = ''[[Begriffsschrift]]'' (1879)&lt;br /&gt;''[[The Foundations of Arithmetic]]'' (1884)
|thesis_title = Ueber&lt;!--[sic; see 'Talk:Gottlob Frege#Ueber']--&gt; eine geometrische Darstellung der imaginären Gebilde in der Ebene (On a Geometrical Representation of Imaginary Forms in a Plane)
|thesis_url   = http://reader.digitale-sammlungen.de/de/fs1/object/goToPage/bsb11160343.html?pageNo=2
|thesis_year  = 1873
|doctoral_advisor  = [[Ernst Christian Julius Schering]] (PhD adv.)
|academic_advisors = [[Alfred Clebsch|Rudolf Friedrich Alfred Clebsch]]
}}
'''Friedrich Ludwig Gottlob Frege''' ({{IPAc-en|ˈ|f|r|eɪ|g|ə}};&lt;ref&gt;[http://dictionary.reference.com/browse/frege "Frege"]. ''[[Random House Webster's Unabridged Dictionary]]''.&lt;/ref&gt; {{IPA-de|ˈɡɔtloːp ˈfreːɡə|lang}}; 8 November 1848 – 26 July 1925) was a German [[philosopher]], [[Mathematical logic|logician]], and [[mathematics|mathematician]].  He is understood by many to be the father of [[analytic philosophy]], concentrating on the philosophy of language and mathematics. Though largely ignored during his lifetime, [[Giuseppe Peano]] (1858–1932) and [[Bertrand Russell]] (1872–1970) introduced his work to later generations of logicians and philosophers.

His contributions include the development of modern logic in the ''[[Begriffsschrift]]'' and work in the [[foundations of mathematics]].  His book the ''[[Foundations of Arithmetic]]'' is the seminal text of the [[logicist]] project, and is cited by [[Michael Dummett]] as where to pinpoint the [[linguistic turn]].  His philosophical papers "[[On Sense and Reference]]" ("Über Sinn und Bedeutung") and "The Thought" ("Der Gedanke") are widely cited.

== Life ==

=== Childhood (1848–69) ===
Frege was born in 1848 in [[Wismar]], [[Grand Duchy of Mecklenburg-Schwerin|Mecklenburg-Schwerin]] (today part of [[Mecklenburg-Vorpommern]]). His father Carl (Karl) Alexander Frege (1809–1866) was the co-founder and headmaster of a girls' high school until his death. After Carl's death, the school was led by Frege's mother Auguste Wilhelmine Sophie Frege (née Bialloblotzky, 12 January 1815 – 14 October 1898); her mother was Auguste Amalia Maria Ballhorn, a descendant of [[Philipp Melanchthon]]&lt;ref&gt;Lothar Kreiser, ''Gottlob Frege: Leben - Werk - Zeit'', Felix Meiner Verlag, 2013, p. 11.&lt;/ref&gt; and her father was Johann Heinrich Siegfried Bialloblotzky, a descendant of a [[Poles|Polish]] noble family who left Poland in the 17th century.&lt;ref&gt;Arndt Richter, [http://www.genetalogie.de/gg/alfrege.pdf "Ahnenliste des Mathematikers Gottlob Frege, 1848-1925"]&lt;/ref&gt;

In childhood, Frege encountered philosophies that would guide his future scientific career. For example, his father wrote a [[textbook]] on the German language for children aged 9–13, entitled ''Hülfsbuch zum Unterrichte in der deutschen Sprache für Kinder von 9 bis 13 Jahren'' (2nd ed., Wismar 1850; 3rd ed., Wismar and Ludwigslust: Hinstorff, 1862), the first section of which dealt with the structure and [[logic]] of [[language]].

Frege studied at a [[gymnasium (school)|''gymnasium'']] in Wismar and graduated in 1869. His teacher Gustav Adolf Leo Sachse (5 November 1843 – 1 September 1909), who was a poet, played the most important role in determining Frege's future scientific career, encouraging him to continue his studies at the [[University of Jena]].

=== Studies at University: Jena and Göttingen (1869–74) ===
Frege matriculated at the University of Jena in the spring of 1869 as a citizen of the [[North German Confederation]]. In the four semesters of his studies he attended approximately twenty courses of lectures, most of them on mathematics and physics. His most important teacher was [[Ernst Karl Abbe]] (1840–1905; physicist, mathematician, and inventor). Abbe gave lectures on theory of gravity, galvanism and electrodynamics, complex analysis theory of functions of a complex variable, applications of physics, selected divisions of mechanics, and mechanics of solids. Abbe was more than a teacher to Frege: he was a trusted friend, and, as director of the optical manufacturer Carl Zeiss AG, he was in a position to advance Frege's career. After Frege's graduation, they came into closer correspondence.

His other notable university teachers were Christian Philipp Karl Snell (1806–86; subjects: use of infinitesimal analysis in geometry, analytical geometry of [[plane (geometry)|planes]], analytical mechanics, optics, physical foundations of mechanics); [[Hermann Schaeffer|Hermann Karl Julius Traugott Schaeffer]] (1824–1900; analytical geometry, applied physics, algebraic analysis, on the telegraph and other [[electronics|electronic machines]]); and the philosopher [[Kuno Fischer]] (1824–1907; Kantian and critical philosophy).

Starting in 1871, Frege continued his studies in Göttingen, the leading university in mathematics in German-speaking territories, where he attended the lectures of [[Alfred Clebsch|Rudolf Friedrich Alfred Clebsch]] (1833–72; analytical geometry), [[Ernst Christian Julius Schering]] (1824–97; function theory), [[Wilhelm Eduard Weber]] (1804–91; physical studies, applied physics), Eduard Riecke (1845–1915; theory of electricity), and [[Hermann Lotze]] (1817–81; philosophy of religion). Many of the philosophical doctrines of the mature Frege have parallels in Lotze; it has been the subject of scholarly debate whether or not there was a direct influence on Frege's views arising from his attending Lotze's lectures.

In 1873, Frege attained his doctorate under Ernst Christian Julius Schering, with a dissertation under the title of "Ueber&lt;!--[sic; see 'Talk:Gottlob Frege#Ueber']--&gt; eine geometrische Darstellung der imaginären Gebilde in der Ebene" ("On a Geometrical Representation of Imaginary Forms in a Plane"), in which he aimed to solve such fundamental problems in geometry as the mathematical interpretation of projective geometry's infinitely distant (imaginary) points.

Frege married Margarete Katharina Sophia Anna Lieseberg (15 February 1856 – 25 June 1904) on 14 March 1887.

== Work as a logician ==
{{Main|Begriffsschrift}}
Though his education and early mathematical work focused primarily on geometry, Frege's work soon turned to logic. His {{Citation | title = [[Begriffsschrift]], eine der arithmetischen nachgebildete Formelsprache des reinen Denkens | place = Halle a/S | publisher = Verlag von Louis Nebert | year = 1879 |trans-title=Concept-Script: A Formal Language for Pure Thought Modeled on that of Arithmetic}} marked a turning point in the history of logic. The ''Begriffsschrift'' broke new ground, including a rigorous treatment of the ideas of [[function (mathematics)|functions]] and [[Variable (mathematics)|variables]]. Frege's goal was to show that mathematics grows out of [[logic]], and in so doing, he devised techniques that took him far beyond the Aristotelian syllogistic and Stoic propositional logic that had come down to him in the logical tradition.

[[File:Begriffsschrift Titel.png|right|thumb|250px|Title page to ''Begriffsschrift'' (1879)]] In effect, Frege invented [[axiomatization|axiomatic]] [[predicate logic]], in large part thanks to his invention of [[Quantification (logic)|quantified variables]], which eventually became ubiquitous in [[mathematics]] and logic, and which solved the [[problem of multiple generality]]. Previous logic had dealt with the [[logical constant]]s ''and'', ''or'', ''if... then...'', ''not'', and ''some'' and ''all'', but iterations of these operations, especially "some" and "all", were little understood: even the distinction between a sentence like "every boy loves some girl" and "some girl is loved by every boy" could be represented only very artificially, whereas Frege's formalism had no difficulty expressing the different readings of "every boy loves some girl who loves some boy who loves some girl" and similar sentences, in complete parallel with his treatment of, say, "every boy is foolish".

A frequently noted example is that Aristotle's logic is unable to represent mathematical statements like [[Euclid's theorem]], a fundamental statement of number theory that there are an infinite number of [[prime number]]s. Frege's "conceptual notation" however can represent such inferences.&lt;ref&gt;Horsten, Leon and Pettigrew, Richard, "Introduction" in ''The Continuum Companion to Philosophical Logic'' (Continuum International Publishing Group, 2011), p. 7.&lt;/ref&gt;  The analysis of logical concepts and the machinery of formalization that is essential to ''[[Principia Mathematica]]'' (3 vols., 1910–13) (by [[Bertrand Russell]], 1872–1970, and [[Alfred North Whitehead]], 1861–1947), to Russell's [[theory of descriptions]], to [[Kurt Gödel]]'s (1906–78) [[Gödel's incompleteness theorem|incompleteness theorems]], and to [[Alfred Tarski]]'s (1901–83) theory of truth, is ultimately due to Frege.

One of Frege's stated purposes was to isolate genuinely logical principles of inference, so that in the proper representation of mathematical proof, one would at no point appeal to "intuition". If there was an intuitive element, it was to be isolated and represented separately as an axiom: from there on, the proof was to be purely logical and without gaps. Having exhibited this possibility, Frege's larger purpose was to defend the view that [[arithmetic]] is a branch of logic, a view known as [[logicism]]: unlike geometry, arithmetic was to be shown to have no basis in "intuition", and no need for non-logical axioms. Already in the 1879 ''Begriffsschrift'' important preliminary theorems, for example a generalized form of [[law of trichotomy]], were derived within what Frege understood to be pure logic.

This idea was formulated in non-symbolic terms in his ''[[The Foundations of Arithmetic]]'' (1884). Later, in his ''Basic Laws of Arithmetic'' (vol. 1, 1893; vol. 2, 1903; vol. 2 was published at his own expense), Frege attempted to derive, by use of his symbolism, all of the laws of arithmetic from axioms he asserted as logical. Most of these axioms were carried over from his ''[[Begriffsschrift]]'', though not without some significant changes. The one truly new principle was one he called the {{nowrap|[[Basic Law V]]}}: the "value-range" of the function ''f''(''x'') is the same as the "value-range" of the function ''g''(''x'') if and only if ∀''x''[''f''(''x'') = ''g''(''x'')].

The crucial case of the law may be formulated in modern notation as follows. Let {''x''|''Fx''} denote the [[extension (predicate logic)|extension]] of the [[Predicate (logic)|predicate]] ''Fx'', i.e., the set of all Fs, and similarly for ''Gx''. Then Basic Law V says that the predicates ''Fx'' and ''Gx'' have the same extension [[iff]] ∀x[''Fx'' ↔ ''Gx'']. The set of Fs is the same as the set of Gs just in case every F is a G and every G is an F. (The case is special because what is here being called the extension of a predicate, or a set, is only one type of "value-range" of a function.)

In a famous episode, Bertrand Russell wrote to Frege, just as Vol. 2 of the ''Grundgesetze'' was about to go to press in 1903, showing that [[Russell's paradox]] could be derived from Frege's Basic Law V. It is easy to define the relation of ''membership'' of a set or extension in Frege's system; Russell then drew attention to "the set of things ''x'' that are such that ''x'' is not a member of ''x''". The system of the ''Grundgesetze'' entails that the set thus characterised ''both'' is ''and'' is not a member of itself, and is thus inconsistent. Frege wrote a hasty, last-minute Appendix to Vol. 2, deriving the contradiction and proposing to eliminate it by modifying Basic Law V. Frege opened the Appendix with the exceptionally honest comment: "Hardly anything more unfortunate can befall a scientific writer than to have one of the foundations of his edifice shaken after the work is finished. This was the position I was placed in by a letter of Mr. Bertrand Russell, just when the printing of this volume was nearing its completion." (This letter and Frege's reply are translated in [[Jean van Heijenoort]] 1967.)

Frege's proposed remedy was subsequently shown to imply that there is but one object in the [[universe of discourse]], and hence is worthless (indeed, this would make for a contradiction in Frege's system if he had axiomatized the idea, fundamental to his discussion, that the True and the False are distinct objects; see, for example, [[Michael Dummett|Dummett]] 1973), but recent work has shown that much of the program of the ''Grundgesetze'' might be salvaged in other ways:
* Basic Law V can be weakened in other ways. The best-known way is due to philosopher and mathematical logician [[George Boolos]] (1940–1996), who was an expert on the work of Frege. A "concept" ''F'' is "small" if the objects falling under ''F'' cannot be put into one-to-one correspondence with the universe of discourse, that is, unless: ∃''R''[''R'' is 1-to-1 &amp; ∀''x''∃''y''(''xRy'' &amp; ''Fy'')]. Now weaken V to V*: a "concept" ''F'' and a "concept" ''G'' have the same "extension" if and only if neither ''F'' nor ''G'' is small or ∀''x''(''Fx'' ↔ ''Gx''). V* is consistent if [[second-order arithmetic]] is, and suffices to prove the axioms of second-order arithmetic.
* Basic Law V can simply be replaced with [[Hume's principle]], which says that the number of ''F''s is the same as the number of ''G''s if and only if the ''F''s can be put into a one-to-one correspondence with the ''G''s. This principle, too, is consistent if second-order arithmetic is, and suffices to prove the axioms of second-order arithmetic. This result is termed [[Frege's theorem]] because it was noticed that in developing arithmetic, Frege's use of Basic Law V is restricted to a proof of Hume's principle; it is from this, in turn, that arithmetical principles are derived. On Hume's principle and Frege's theorem, see "Frege's Logic, Theorem, and Foundations for Arithmetic".&lt;ref&gt;[http://plato.stanford.edu/entries/frege-logic/ Frege's Logic, Theorem, and Foundations for Arithmetic, ''Stanford Encyclopedia of Philosophy''] at plato.stanford.edu&lt;/ref&gt;
* Frege's logic, now known as [[second-order logic]], can be weakened to so-called [[Impredicativity|predicative]] second-order logic. Predicative second-order logic plus Basic Law V is provably consistent by [[finitism|finitistic]] or [[Mathematical constructivism|constructive]] methods, but it can interpret only very weak fragments of arithmetic.&lt;ref&gt;{{cite book|author=Burgess, John|title=Fixing Frege|year=2005|isbn=0-691-12231-8}}&lt;/ref&gt;

Frege's work in logic had little international attention until 1903 when Russell wrote an appendix to ''[[The Principles of Mathematics]]'' stating his differences with Frege. The diagrammatic notation
that Frege used had no antecedents (and has had no imitators since). Moreover, until Russell and Whitehead's ''[[Principia Mathematica]]'' (3 vols.) appeared in 1910–13, the dominant approach to [[mathematical logic]] was still that of [[George Boole]] (1815–64) and his intellectual descendants, especially [[Ernst Schröder]] (1841–1902). Frege's logical ideas nevertheless spread through the writings of his student [[Rudolf Carnap]] (1891–1970) and other admirers, particularly Bertrand Russell and [[Ludwig Wittgenstein]] (1889–1951).

== Philosopher ==
Frege is one of the founders of [[analytic philosophy]], whose work on logic and language gave rise to the [[linguistic turn]] in philosophy. His contributions to the [[philosophy of language]] include:
* [[Function (mathematics)|Function]]–argument analysis of the [[proposition]];
* Distinction between [[concept and object]] (''Begriff und Gegenstand'');
* Principle of [[compositionality]];
* [[Context principle]];
* Distinction between the [[sense and reference]] (''Sinn und Bedeutung'') of names and other expressions, sometimes said to involve a [[mediated reference theory]].

As a philosopher of mathematics, Frege attacked the [[psychologism|psychologistic]] appeal to mental explanations of the content of judgment of the meaning of sentences. His original purpose was very far from answering general questions about meaning; instead, he devised his logic to explore the foundations of arithmetic, undertaking to answer questions such as "What is a number?" or "What objects do number-words ("one", "two", etc.) refer to?" But in pursuing these matters, he eventually found himself analysing and explaining what meaning is, and thus came to several conclusions that proved highly consequential for the subsequent course of analytic philosophy and the philosophy of language.

It should be kept in mind that Frege was employed as a mathematician, not a philosopher, and he published his philosophical papers in scholarly journals that often were hard to access outside of the German-speaking world. He never published a philosophical monograph other than ''The Foundations of Arithmetic'', much of which was mathematical in content, and the first collections of his writings appeared only after World War II. A volume of English translations of Frege's philosophical essays first appeared in 1952, edited by students of Wittgenstein, [[Peter Geach]] (1916-2013) and [[Max Black]] (1909–88), with the bibliographic assistance of Wittgenstein (see Geach, ed. 1975, Introduction). Despite the generous praise of Russell and Wittgenstein, Frege was little known as a philosopher during his lifetime. His ideas spread chiefly through those he influenced, such as Russell, Wittgenstein, and Carnap, and through work on logic and semantics by Polish logicians.

== Sense and reference ==
{{Main|Sense and reference}}
Frege's 1892 paper, "On Sense and Reference" ("Über Sinn und Bedeutung"), introduced his influential distinction between ''sense'' ("Sinn") and ''reference'' ("Bedeutung", which has also been translated as "meaning", or "denotation"). While conventional accounts of meaning took expressions to have just one feature (reference), Frege introduced the view that expressions have two different aspects of significance: their sense and their reference.

''Reference'', (or, "Bedeutung") applied to [[proper names]], where a given expression (say the expression "Tom") simply refers to the entity bearing the name (the person named Tom). Frege also held that propositions had a referential relationship with their truth-value (in other words, a statement "refers" to the truth-value it takes). By contrast, the ''sense'' (or "Sinn") associated with a complete sentence is the thought it expresses. The sense of an expression is said to be the "mode of presentation" of the item referred to, and there can be multiple modes of representation for the same referent.

The distinction can be illustrated thus: In their ordinary uses, the name "Charles Philip Arthur George Mountbatten-Windsor", which for logical purposes is an unanalyzable whole, and the functional expression "the Prince of Wales", which contains the significant parts "the prince of ξ" and "Wales", have the same ''reference'', namely, the person best known as Prince Charles. But the ''sense'' of the word "Wales" is a part of the sense of the latter expression, but no part of the sense of the "full name" of Prince Charles.

These distinctions were disputed by Bertrand Russell, especially in his paper "[[On Denoting]]"; the controversy has continued into the present, fueled especially by [[Saul Kripke]]'s famous lectures "[[Naming and Necessity]]".

== 1924 diary ==
Frege's published philosophical writings were of a very technical nature and divorced from practical issues, so much so that Frege scholar [[Michael Dummett|Dummett]] expresses his "shock to discover, while reading Frege's diary, that his hero was an anti-Semite."&lt;ref&gt;Hersh, Reuben, ''What Is Mathematics, Really?'' (Oxford University Press, 1997), p. 241.&lt;/ref&gt;  After the [[German Revolution of 1918–19]] his political opinions became more radical. In the last year of his life, at the age of 76, his diary contains extreme [[right-wing]] political opinions, opposing the parliamentary system, democrats, liberals, Catholics, the French and Jews, who he thought ought to be deprived of political rights and, preferably, expelled from Germany.&lt;ref&gt;Michael Dummett: ''Frege: Philosophy of Language'', p. xii.&lt;/ref&gt;  Frege confided "that he had once thought of himself as a liberal and was an admirer of [[Otto von Bismarck|Bismarck]]", but then sympathized with General [[Erich Ludendorff|Ludendorff]] and [[Adolf Hitler]]. Some interpretations have been written about that time.&lt;ref&gt;[[Hans Sluga]]: ''Heidegger's Crisis: Philosophy and Politics in Nazi Germany'', pp. 99ff. Sluga's source was an article by Eckart Menzler-Trott: "Ich wünsch die Wahrheit und nichts als die Wahrheit: Das politische Testament des deutschen Mathematikers und Logikers Gottlob Frege". In: ''Forum'', vol. 36, no. 432, 20 December 1989, pp. 68–79.&lt;/ref&gt;  The diary contains a critique of [[universal suffrage]] and socialism. Frege had friendly relations with Jews in real life: among his students was [[Gershom Scholem]] who much valued his teacher;&lt;ref&gt;{{cite web|url=http://www-history.mcs.st-andrews.ac.uk/~history/Biographies/Frege.html|title=Frege biography|publisher=}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.iep.utm.edu/f/frege.htm|title=Frege, Gottlob – Internet Encyclopedia of Philosophy|publisher=}}&lt;/ref&gt; and he encouraged [[Ludwig Wittgenstein]] to leave for England.&lt;ref&gt;[http://www.bu.edu/philo/files/2011/01/Frege-WittCorrespondence.pdf Juliet Floyd, The Frege-Wittgenstein Correspondence: Interpretive Themes]&lt;/ref&gt; The 1924 diary was published posthumously in 1994.&lt;ref&gt;Gottfried Gabriel, Wolfgang Kienzler (editors): "Gottlob Freges politisches Tagebuch". In: ''Deutsche Zeitschrift für Philosophie'', vol. 42, 1994, pp. 1057–98. Introduction by the editors on pp. 1057–66. This article has been translated into English, in: ''Inquiry'', vol. 39, 1996, pp. 303–342.&lt;/ref&gt; Frege apparently never spoke in public about his political viewpoints.

== Personality ==
Frege was described by his students as a highly introverted person, seldom entering into dialogue, mostly facing the blackboard while lecturing though being witty and sometimes bitterly sarcastic.&lt;ref&gt;''Frege's Lectures on Logic'', ed. by Erich H. Reck and [[Steve Awodey]], Open Court Publishing, 2004, pp. 18–26.&lt;/ref&gt;

== Important dates ==
* Born 8 November 1848 in [[Wismar]], [[Grand Duchy of Mecklenburg-Schwerin|Mecklenburg-Schwerin]].
* 1869&amp;nbsp;— attends the [[University of Jena]].
* 1871&amp;nbsp;— attends the [[University of Göttingen]].
* 1873&amp;nbsp;— PhD, doctor in [[mathematics]] ([[geometry]]), attained at Göttingen.
* 1874&amp;nbsp;— [[Habilitation]] at Jena; [[Privatdozent|private teacher]].
* 1879&amp;nbsp;— Ausserordentlicher Professor at Jena.
* 1896&amp;nbsp;— Ordentlicher Honorarprofessor at Jena.
* 1917 or 1918&amp;nbsp;— retires.
* Died 26 July 1925 in [[Bad Kleinen]] (now part of [[Mecklenburg-Vorpommern]]).

== Important works ==

=== Logic, foundation of arithmetic ===
''[[Begriffsschrift|Begriffsschrift: eine der arithmetischen nachgebildete Formelsprache des reinen Denkens]]'' (1879), Halle a. S.
* In English: ''Begriffsschrift, a Formula Language, Modeled Upon That of Arithmetic, for Pure Thought'', in: [[Jean van Heijenoort|J. van Heijenoort]] (ed.), ''From Frege to Gödel: A Source Book in Mathematical Logic, 1879-1931'', Harvard, MA: Harvard University Press, 1967, pp.&amp;nbsp;5–82.
* In English (selected sections revised in modern formal notation): R. L. Mendelsohn, ''The Philosophy of Gottlob Frege'', Cambridge: Cambridge University Press, 2005: "Appendix A. Begriffsschrift in Modern Notation: (1) to (51)" and "Appendix B. Begriffsschrift in Modern Notation: (52) to (68)."
''[[The Foundations of Arithmetic|Die Grundlagen der Arithmetik: Eine logisch-mathematische Untersuchung über den Begriff der Zahl]]'' (1884), Breslau.
* In English: ''[[The Foundations of Arithmetic]]: A Logico-Mathematical Enquiry into the Concept of Number'', translated by [[J. L. Austin]], Oxford: Basil Blackwell, 1950.
''Grundgesetze der Arithmetik'', Band I (1893); Band II (1903), Jena: Verlag Hermann Pohle ([https://archive.org/download/diegrundlagende00freggoog/diegrundlagende00freggoog.pdf online version]).
* In English (translation of selected sections), "Translation of Part of Frege's ''Grundgesetze der Arithmetik''," translated and edited [[Peter Geach]] and [[Max Black]] in ''Translations from the Philosophical Writings of Gottlob Frege'', New York, NY: Philosophical Library, 1952, pp.&amp;nbsp;137–158.
* In German (revised in modern formal notation): ''Grundgesetze der Arithmetik'', Korpora ([[University of Duisburg-Essen]]), 2006: [https://korpora.zim.uni-duisburg-essen.de/Frege/PDF/gga1_o_corr.pdf Band I] and [https://korpora.zim.uni-duisburg-essen.de/Frege/PDF/gga2_o_corr.pdf Band II].
* In German (revised in modern formal notation): ''Grundgesetze der Arithmetik – Begriffsschriftlich abgeleitet. Band I und II: In moderne Formelnotation transkribiert und mit einem ausführlichen Sachregister versehen'', edited by T. Müller, B. Schröder, and R. Stuhlmann-Laeisz, Paderborn: mentis, 2009.
* In English: ''Basic Laws of Arithmetic'', translated and edited with an introduction by Philip A. Ebert and Marcus Rossberg. Oxford: Oxford University Press, 2013. {{ISBN|978-0-19-928174-9}}.

=== Philosophical studies ===
"Function and Concept" (1891)
* Original: "Funktion und Begriff"; in ''Jenaische Gesellschaft für Medizin und Naturwissenschaft'', Jena, 9 January 1891;
* In English: "[[Function and Concept]]''.
"On Sense and Reference" (1892)
* Original: "Über Sinn und Bedeutung", in ''[[Zeitschrift für Philosophie und philosophische Kritik]] C'' (1892): 25–50;
* In English: "[[On Sense and Reference]]", alternatively translated (in later edition) as "On Sense and Meaning".
"Concept and Object" (1892)
* Original: "Ueber&lt;!--[sic; see 'Talk:Gottlob Frege#Ueber']--&gt; Begriff und Gegenstand", in ''Vierteljahresschrift für wissenschaftliche Philosophie XVI'' (1892): 192–205;
* In English: "[[Concept and Object]]".
"What is a Function?" (1904)
* Original: "Was ist eine Funktion?", in ''Festschrift Ludwig Boltzmann gewidmet zum sechzigsten Geburtstage'', 20 February 1904, S. Meyer (ed.), Leipzig, 1904, pp.&amp;nbsp;656–666 (Internet Archive: [https://archive.org/details/festschriftludw00meyegoog], [https://archive.org/details/festschriftludw01meyegoog], [https://archive.org/details/festschriftludw02meyegoog]);
* In English: "What is a Function?".

''Logical Investigations'' (1918–1923).
Frege intended that the following three papers be published together in a book titled ''Logische Untersuchungen'' (''Logical Investigations''). Though the German book never appeared, the papers were published together in ''Logische Untersuchungen'', ed. G. Patzig, Vandenhoeck &amp; Ruprecht, 1966, and English translations appeared together in ''Logical Investigations'', ed. Peter Geach, Blackwell, 1975.
* 1918–19. "Der Gedanke: Eine logische Untersuchung" ("The Thought: A Logical Inquiry"), in ''Beiträge zur Philosophie des Deutschen Idealismus I'':&lt;ref name=DPG&gt;The journal ''Beiträge zur Philosophie des Deutschen Idealismus'' was the organ of {{Interlanguage link multi|Deutsche Philosophische Gesellschaft|de}}.&lt;/ref&gt; 58–77.
* 1918–19. "Die Verneinung" ("Negation") in ''Beiträge zur Philosophie des Deutschen Idealismus I'': 143–157.
* 1923. "Gedankengefüge" ("Compound Thought"), in ''Beiträge zur Philosophie des Deutschen Idealismus III'': 36–51.

=== Articles on geometry ===
* 1903: "Über die Grundlagen der Geometrie". II. ''Jahresbericht der deutschen Mathematiker-Vereinigung XII'' (1903), 368–375;
** In English: "On the Foundations of Geometry".
* 1967: ''Kleine Schriften''. (I. Angelelli, ed.). Darmstadt: Wissenschaftliche Buchgesellschaft, 1967 and Hildesheim, G. Olms, 1967. "Small Writings," a collection of most of his writings (e.g., the previous), [[posthumous work|posthumously]] published.

== See also ==
{{Portal|Philosophy|Logic}}
* [[Frege system]]
* [[List of pioneers in computer science]]
* [[Neo-Fregeanism]]
{{-}}

== References ==
{{Reflist}}

== Sources ==
=== Primary ===
* [http://plato.stanford.edu/entries/frege/catalog.html Online bibliography of Frege's works and their English translations (compiled by E. N. Zalta, ''Stanford Encyclopedia of Philosophy'').]
* 1879. ''[[Begriffsschrift]], eine der arithmetischen nachgebildete Formelsprache des reinen Denkens''. Halle a. S.: Louis Nebert. Translation: ''Concept Script, a formal language of pure thought modelled upon that of arithmetic'', by S. Bauer-Mengelberg in [[Jean Van Heijenoort]], ed., 1967. ''From Frege to Gödel: A Source Book in Mathematical Logic, 1879–1931''. Harvard University Press.
* 1884. ''Die Grundlagen der Arithmetik: Eine logisch-mathematische Untersuchung über den Begriff der Zahl''. Breslau: W. Koebner. Translation: [[J. L. Austin]], 1974. ''The Foundations of Arithmetic: A Logico-Mathematical Enquiry into the Concept of Number'', 2nd ed. Blackwell.
* 1891. "Funktion und Begriff." Translation: "Function and Concept" in Geach and Black (1980).
* 1892a. "Über Sinn und Bedeutung" in ''Zeitschrift für Philosophie und philosophische Kritik'' 100:25–50. Translation: "On Sense and Reference" in Geach and Black (1980).
* 1892b. "Ueber&lt;!--[sic; see 'Talk:Gottlob Frege#Ueber']--&gt; Begriff und Gegenstand" in ''Vierteljahresschrift für wissenschaftliche Philosophie'' 16:192–205. Translation: "Concept and Object" in Geach and Black (1980).
* 1893. ''Grundgesetze der Arithmetik, Band I''. Jena: Verlag Hermann Pohle. ''Band II'', 1903. [http://korpora.zim.uni-duisburg-essen.de/Frege Band I+II online]. Partial translation of volume 1: Montgomery Furth, 1964. ''The Basic Laws of Arithmetic''. Univ. of California Press. Translation of selected sections from volume 2 in Geach and Black (1980). Complete translation of both volumes: Philip A. Ebert and Marcus Rossberg, 2013, ''Basic Laws of Arithmetic''. Oxford University Press.
* 1904. "Was ist eine Funktion?" in Meyer, S., ed., 1904. ''Festschrift Ludwig Boltzmann gewidmet zum sechzigsten Geburtstage, 20. Februar 1904''. Leipzig: Barth: 656–666. Translation: "What is a Function?" in Geach and Black (1980).
* 1918–1923. Peter Geach (editor):  ''Logical Investigations'', Blackwell, 1975.
* 1924. Gottfried Gabriel, Wolfgang Kienzler (editors): ''Gottlob Freges politisches Tagebuch''. In: ''Deutsche Zeitschrift für Philosophie'', vol. 42, 1994, pp.&amp;nbsp;1057–98. Introduction by the editors on pp.&amp;nbsp;1057–66. This article has been translated into English, in: ''Inquiry'', vol. 39, 1996, pp.&amp;nbsp;303–342.
* [[Peter Geach]] and [[Max Black]], eds., and trans., 1980. ''Translations from the Philosophical Writings of Gottlob Frege'', 3rd ed. Blackwell (1st ed. 1952).

=== Secondary ===
;Philosophy
* [[Alain Badiou|Badiou, Alain]]. "On a Contemporary Usage of Frege", trans. [[Justin Clemens]] and [[Sam Gillespie]]. ''UMBR(a)'', no. 1, 2000, pp.&amp;nbsp;99–115.
* Baker, Gordon, and P.M.S. Hacker, 1984. ''Frege: Logical Excavations''. Oxford University Press.&amp;nbsp;— Vigorous, if controversial, criticism of both Frege's philosophy and influential contemporary interpretations such as Dummett's.''
* Currie, Gregory, 1982. ''Frege: An Introduction to His Philosophy''. Harvester Press.
* [[Michael Dummett|Dummett, Michael]], 1973. ''Frege: Philosophy of Language''. Harvard University Press.
* ------, 1981. ''The Interpretation of Frege's Philosophy''. Harvard University Press.
* Hill, Claire Ortiz, 1991. ''Word and Object in Husserl, Frege and Russell:  The Roots of Twentieth-Century Philosophy''. Athens OH: Ohio University Press.
* ------, and Rosado Haddock, G. E., 2000. ''Husserl or Frege: Meaning, Objectivity, and Mathematics''. Open Court.&amp;nbsp;— On the Frege-Husserl-Cantor triangle.
* [[Anthony Kenny|Kenny, Anthony]], 1995. ''Frege&amp;nbsp;— An introduction to the founder of modern analytic philosophy''. Penguin Books.&amp;nbsp;— Excellent non-technical introduction and overview of Frege's philosophy.
* Klemke, E.D., ed., 1968. ''Essays on Frege''. University of Illinois Press.&amp;nbsp;— 31 essays by philosophers, grouped under three headings: 1. [[Ontology]]; 2. [[Semantics]]; and 3. [[Logic]] and [[Philosophy of Mathematics]].
* Rosado Haddock, Guillermo E., 2006. ''A Critical Introduction to the Philosophy of Gottlob Frege''. Ashgate Publishing.
* Sisti, Nicola, 2005. ''Il Programma Logicista di Frege e il Tema delle Definizioni''. Franco Angeli.&amp;nbsp;— On Frege's theory of definitions.
* [[Hans Sluga|Sluga, Hans]], 1980. ''Gottlob Frege''. Routledge.
* Nicla Vassallo, 2014, ''Frege on Thinking and Its Epistemic Significance'' with Pieranna Garavaso, Lexington Books–Rowman &amp; Littlefield, Lanham, MD, Usa.
* Weiner, Joan, 1990. ''Frege in Perspective'', Cornell University Press.

;Logic and mathematics
* Anderson, D. J., and [[Edward Zalta]], 2004, "Frege, Boolos, and Logical Objects," ''Journal of Philosophical Logic 33'': 1–26.
* Blanchette, Patricia, 2012, ''Frege's Conception of Logic''. Oxford: Oxford University Press, 2012
* Burgess, John, 2005. ''Fixing Frege''. Princeton Univ. Press.&amp;nbsp;— A critical survey of the ongoing rehabilitation of Frege's logicism.
* [[George Boolos|Boolos, George]], 1998. ''Logic, Logic, and Logic''. MIT Press.&amp;nbsp;— 12 papers on [[Frege's theorem]] and the [[logicism|logicist]] approach to the foundation of [[arithmetic]].
* [[Michael Dummett|Dummett, Michael]], 1991. ''Frege: Philosophy of Mathematics''. Harvard University Press.
* Demopoulos, William, ed., 1995. ''Frege's Philosophy of Mathematics''. Harvard Univ. Press.&amp;nbsp;— Papers exploring [[Frege's theorem]] and Frege's mathematical and intellectual background.
* Ferreira, F. and [[Kai Wehmeier|Wehmeier, K.]], 2002, "On the consistency of the Delta-1-1-CA fragment of Frege's ''Grundgesetze''," ''Journal of Philosophic Logic 31'': 301–11.
* [[Ivor Grattan-Guinness|Grattan-Guinness, Ivor]], 2000. ''The Search for Mathematical Roots 1870–1940''. Princeton University Press.&amp;nbsp;— Fair to the mathematician, less so to the philosopher.
* [[Donald A. Gillies|Gillies, Donald A.]], 1982. ''Frege, Dedekind, and Peano on the foundations of arithmetic''. Methodology and Science Foundation, 2. Van Gorcum &amp; Co., Assen, 1982.
* Gillies, Donald: The Fregean revolution in logic. [[Revolutions in mathematics]], 265–305, Oxford Sci. Publ., Oxford Univ. Press, New York, 1992.
* [[Andrew David Irvine|Irvine, Andrew David]], 2010, "Frege on Number Properties," ''Studia Logica,'' 96(2): 239-60.
* [[Charles Parsons (philosopher)|Charles Parsons]], 1965, "Frege's Theory of Number." Reprinted with Postscript in Demopoulos (1965): 182–210. The starting point of the ongoing sympathetic reexamination of Frege's logicism.
* Gillies, Donald: The Fregean revolution in logic. [[Revolutions in mathematics]], 265–305, Oxford Sci. Publ., Oxford Univ. Press, New York, 1992.
* Heck, Richard G., Jr: ''Frege's Theorem''. Oxford: Oxford University Press, 2011
* Heck, Richard G., Jr: ''Reading Frege's Grundgesetze''. Oxford: Oxford University Press, 2013
* [[Crispin Wright|Wright, Crispin]], 1983. ''Frege's Conception of Numbers as Objects''. Aberdeen University Press.&amp;nbsp;— A systematic exposition and a scope-restricted defense of Frege's ''Grundlagen'' conception of numbers.

;Historical context
*{{Citation|last=Everdell|first=William R. |year=1997 |title=The First Moderns: Profiles in the Origins of Twentieth Century Thought |location= Chicago |publisher=University of Chicago Press}}

== External links ==
{{Sister project links|wikt=no|commons=Category:Gottlob Frege|b=no|n=no|q=Gottlob Frege|s=Author:Gottlob Frege|v=no|species=no }}
* {{Internet Archive author |sname=Gottlob Frege}}
* [http://www.genealogy.math.ndsu.nodak.edu/id.php?id=46166 Frege at Genealogy Project]
* [http://www.ocf.berkeley.edu/~brianwc/frege/ A comprehensive guide to Fregean material available on the web] by Brian Carver.
* [https://www.iep.utm.edu/frege/ Frege, Gottlob – Internet Encyclopedia of Philosophy]
* [[Stanford Encyclopedia of Philosophy]]:
** "[http://plato.stanford.edu/entries/frege/ Gottlob Frege]"&amp;nbsp;— by [[Edward Zalta]].
** "[http://plato.stanford.edu/entries/frege-logic/ Frege's Logic, Theorem, and Foundations for Arithmetic]"&amp;nbsp;— by [[Edward Zalta]].
* [[Internet Encyclopedia of Philosophy]]:
** [http://www.iep.utm.edu/f/frege.htm Gottlob Frege]&amp;nbsp;— by Kevin C. Klement.
** [http://www.utm.edu/research/iep/f/freg-lan.htm Frege and Language]&amp;nbsp;— by Dorothea Lotter.
* Metaphysics Research Lab: [http://mally.stanford.edu/frege.html Gottlob Frege.]
* [http://www.ontology.co/fregeg.htm Frege on Being, Existence and Truth.]
* {{MacTutor Biography|id=Frege}}
* [http://ctan.org/tex-archive/macros/latex/contrib/begriff/ Begriff], a [[LaTeX]] package for typesetting Frege's logic notation, earlier version
* [http://www.ctan.org/pkg/grundgesetze grundgesetze], a [[LaTeX]] package for typesetting Frege's logic notation, mature version
* [http://www.frege.info/ Frege's Basic Laws of Arithmetic], info website, incl. corrigenda and [[LaTeX]] typesetting tool&amp;nbsp;— by P.A. Ebert and M. Rossberg

{{analytic philosophy}}
{{philosophy of language}}
{{Authority control}}

{{DEFAULTSORT:Frege, Gottlob}}
[[Category:1848 births]]
[[Category:1925 deaths]]
[[Category:19th-century German male writers]]
[[Category:19th-century German mathematicians]]
[[Category:19th-century German philosophers]]
[[Category:19th-century German writers]]
[[Category:19th-century male writers]]
[[Category:19th-century philosophers]]
[[Category:20th-century German male writers]]
[[Category:20th-century German mathematicians]]
[[Category:20th-century German philosophers]]
[[Category:20th-century German writers]]
[[Category:20th-century male writers]]
[[Category:20th-century philosophers]]
[[Category:Analytic philosophers]]
[[Category:Epistemologists]]
[[Category:German logicians]]
[[Category:German philosophers]]
[[Category:Linguistic turn]]
[[Category:Metaphysicians]]
[[Category:Ontologists]]
[[Category:People from the Grand Duchy of Mecklenburg-Schwerin]]
[[Category:Philosophers of language]]
[[Category:Philosophers of mathematics]]
[[Category:Philosophers of mind]]
[[Category:Set theorists]]
[[Category:University of Jena alumni]]</text>
      <sha1>l1k2v4x0621ox0z72b773ihpgf3py3g</sha1>
    </revision>
  </page>
  <page>
    <title>Grinberg's theorem</title>
    <ns>0</ns>
    <id>22816079</id>
    <revision>
      <id>846613870</id>
      <parentid>778515543</parentid>
      <timestamp>2018-06-19T21:02:54Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 1 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7009">[[File:Grinberg 5CEC Nonhamiltonian graph.svg|thumb|A graph that can be proven non-Hamiltonian using Grinberg's theorem]]
In [[graph theory]], '''Grinberg's theorem''' is a necessary condition for a [[planar graph]] to contain a [[Hamiltonian cycle]], based on the lengths of its face cycles.  The result has been widely used to construct non-Hamiltonian planar graphs with further properties, such as to give new [[counterexample]]s to [[Tait's conjecture]] (originally disproved by [[W.T. Tutte]] in 1946).  This theorem was proved by [[Latvia]]n mathematician [[Emanuel Grinberg]] in 1968.

== Formulation ==
Let ''G'' be a finite planar graph with a Hamiltonian cycle ''C'', with a fixed planar embedding.
Denote by ''&amp;fnof;''&lt;sub&gt;''k''&lt;/sub&gt; and ''g''&lt;sub&gt;''k''&lt;/sub&gt; the number of ''k''-gonal faces of the embedding that are inside and outside of ''C'', respectively.  Then

: &lt;math&gt;\sum_{k \geq 3} (k-2) (f_k-g_k) = 0.&lt;/math&gt;

The proof is an easy consequence of [[Euler characteristic|Euler's formula]].

A corollary of this theorem is that if a planar graph can be embedded in such a way that all but one face has a number of sides that is 2 mod 3, and the remaining face has a number of sides that is not 2 mod 3, then the graph is not Hamiltonian. For instance, for the graph in the figure, all the bounded faces have 5 or 8 sides, but the unbounded face has 9 sides, so it satisfies this condition and is not Hamiltonian. For any planar graph, the faces whose number of sides is 2 mod 3 contribute 0 mod 3 to the sum in Grinberg's theorem, because of the factor of ''k''&amp;nbsp;&amp;minus;&amp;nbsp;2 in the sum. However, the other faces contribute a number that nonzero mod 3, regardless of whether they are inside or outside the Hamiltonian cycle. So, when there is only one face that contributes a nonzero amount, it is not possible for the total to be zero and the graph must be non-Hamiltonian.

==Applications==
Grinberg used his theorem to find non-Hamiltonian [[cubic graph|cubic]] [[polyhedral graph]]s with high cyclic edge connectivity. The cyclic edge connectivity of a graph is the smallest number of edges that may be deleted in such a way that the remaining graph has more than one cyclic component. The 46-vertex [[Tutte graph]], and the smaller cubic non-Hamiltonian polyhedral graphs derived from it, have cyclic edge connectivity three. Grinberg used his theorem to find a non-Hamiltonian cubic polyhedral graph with 44 vertices, 24 faces, and cyclic edge connectivity four, and another example (shown in the figure) with 46 vertices, 25 faces, and cyclic edge connectivity five, the maximum possible cyclic edge connectivity for a cubic planar graph other than ''K''&lt;sub&gt;4&lt;/sub&gt;. In the example shown, all of the bounded faces have either five or eight edges, both of which are numbers that are 2 mod 3, but the unbounded face has nine edges, unequal to 2 mod 3. Therefore, by the corollary to Grinberg's theorem, the graph cannot be Hamiltonian.

Grinberg's theorem has also been used to find planar [[hypohamiltonian graph]]s, again by making all but one face have a number of edges congruent to 2 mod 3 ({{harvnb|Thomassen|1976}}, {{harvnb|Wiener|Araya|2009}}). {{harvtxt|Thomassen|1981}} uses the theorem in a somewhat more complicated way to find a planar [[cubic graph|cubic]] hypohamiltonian graph: the graph he constructs includes a 4-edge face adjacent to four 7-edge faces, and all other faces have five or eight edges. In order to satisfy Grinberg's theorem, a Hamiltonian cycle would have to separate one of the 4- or 7-edge faces from the other four, which is not possible.

==Limitations==
There exist planar non-Hamiltonian graphs in which all faces have five or eight sides. For these graphs, Grinberg's formula taken modulo three is always satisfied by any partition of the faces into two subsets, preventing the application of his theorem to proving non-Hamiltonicity in this case {{harv|Zaks|1977}}.

It is not possible to use Grinberg's theorem to find counterexamples to [[Barnette's conjecture]], that every cubic [[bipartite graph|bipartite]] [[polyhedral graph]] is Hamiltonian. For, in such graphs, there always exists a partition of the faces into two subsets satisfying Grinberg's theorem, regardless of Hamiltonicity {{harv|Krooss|2004}}.

== References ==
*{{citation
 | last = Grinberg | first = È. Ja. | authorlink = Emanuels Grīnbergs
 | contribution = Plane homogeneous graphs of degree three without Hamiltonian circuits
 | language = Russian
 | location = Riga
 | mr = 0238732
 | pages = 51–58
 | publisher = Izdat. “Zinatne”
 | title = Latvian Math. Yearbook 4
 | year = 1968}}. English translation by Dainis Zeps, {{arxiv|0908.2563}}.
*{{citation
 | last = Krooss | first = André
 | journal = Analele Universităţii din Craiova. Seria Matematică-Informatică
 | language = German
 | mr = 2153849
 | pages = 59–65
 | title = Die Barnette'sche Vermutung und die Grinberg'sche Formel
 | volume = 31
 | year = 2004}}.
*{{citation
 | last = Malkevitch | first = Joseph
 | date = January 2005
 | publisher = [[American Mathematical Society]]
 | series = Feature Column
 | title = Euler's Polyhedral Formula: Part II
 | url = http://www.ams.org/featurecolumn/archive/eulers-formulaII.html}}.
*{{citation
 | last = Thomassen | first = Carsten | authorlink = Carsten Thomassen
 | title = Planar and infinite hypohamiltonian and hypotraceable graphs
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | volume = 14 | year = 1976 | pages = 377–389
 |mr=0422086
 | doi = 10.1016/0012-365X(76)90071-6
 | issue = 4}}.
*{{citation
 | last = Thomassen | first = Carsten | authorlink = Carsten Thomassen
 | doi = 10.1016/0095-8956(81)90089-7
 | issue = 1
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 609592
 | pages = 36–44
 | title = Planar cubic hypo-Hamiltonian and hypotraceable graphs
 | volume = 30
 | year = 1981}}.
*{{citation
 | last1 = Wiener | first1 = Gábor
 | last2 = Araya | first2 = Makoto
 | title = The ultimate question
 | year = 2009
 | arxiv = 0904.3012| bibcode = 2009arXiv0904.3012W}}.
*{{citation
 | last = Tutte | first = W. T. | authorlink = W. T. Tutte
 | contribution = Chapter 2: Knights Errant
 | isbn = 0-19-850251-6
 | location = New York
 | mr = 1635397
 | publisher = The Clarendon Press Oxford University Press
 | series = Oxford Lecture Series in Mathematics and its Applications
 | title = Graph theory as I have known it
 | volume = 11
 | year = 1998}}.
*{{citation
 | last = Zaks | first = Joseph
 | doi = 10.1016/0012-365X(77)90165-0
 | issue = 3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | mr = 0460189
 | pages = 317–321
 | title = Non-Hamiltonian non-Grinbergian graphs
 | volume = 17
 | year = 1977}}.

== External links ==
* [http://mathworld.wolfram.com/GrinbergGraphs.html Grinberg Graphs], from ''[[MathWorld]]''.

[[Category:Theorems in graph theory]]
[[Category:Planar graphs]]
[[Category:Hamiltonian paths and cycles]]</text>
      <sha1>bd4owxbo9d4abo8jrhyop2bnm5wookv</sha1>
    </revision>
  </page>
  <page>
    <title>Harish-Chandra class</title>
    <ns>0</ns>
    <id>11007822</id>
    <revision>
      <id>785380975</id>
      <parentid>730542165</parentid>
      <timestamp>2017-06-13T06:46:33Z</timestamp>
      <contributor>
        <username>Magic links bot</username>
        <id>30707369</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic links|magic links]] with templates per [[Special:Permalink/772743896#Future of magic links|local RfC]] and [[:mw:Requests for comment/Future of magic links|MediaWiki RfC]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1557">In mathematics, '''Harish-Chandra's class''' is a class of [[Lie group]]s used in [[representation theory]]. Harish-Chandra's class contains all [[Semisimple Lie group|semisimple]] connected [[linear group|linear]] Lie groups and is closed under natural operations, most importantly, the passage to [[Levi decomposition|Levi subgroup]]s. This closure property is crucial for many inductive arguments in representation theory of Lie groups, whereas the classes of semisimple or connected semisimple Lie groups are not closed in this sense.

==Definition==
A Lie group ''G'' with the [[Lie algebra]] ''g'' is said to be in Harish-Chandra's class if it satisfies the following conditions:
*''g'' is a [[Semisimple Lie algebra|reductive]] Lie algebra (the product of a semisimple and abelian Lie algebra).
*The Lie group ''G'' has only a finite number of [[connected space|connected component]]s. 
*The [[adjoint representation of a Lie group|adjoint action]] of any element of ''G'' on ''g'' is given by an action of an element of the connected component of the Lie group of Lie algebra automorphisms of the [[complexification]] ''g''⊗'''C'''.
*The subgroup ''G''&lt;sub&gt;ss&lt;/sub&gt; of ''G'' generated by the image of the semisimple part ''g''&lt;sub&gt;ss&lt;/sub&gt;=[''g'',''g''] of the Lie algebra ''g'' under the [[exponential map (Lie theory)|exponential map]] has finite [[center (group)|center]].

==References==
*A. W. Knapp, ''Structure theory of semisimple Lie groups'', in {{ISBN|0-8218-0609-2}}

[[Category:Representation theory of Lie groups]]


{{algebra-stub}}</text>
      <sha1>2439vrhxebsoi8avnra4nhp7439tsn2</sha1>
    </revision>
  </page>
  <page>
    <title>Incidence matrix</title>
    <ns>0</ns>
    <id>420919</id>
    <revision>
      <id>864848212</id>
      <parentid>846658107</parentid>
      <timestamp>2018-10-19T21:48:47Z</timestamp>
      <contributor>
        <ip>80.65.246.237</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8107">In [[mathematics]], an '''incidence matrix''' is a [[Matrix (mathematics)|matrix]] that shows the relationship between two classes of objects. If the first class is ''X'' and the second is ''Y'', the matrix has one row for each element of ''X'' and one column for each element of ''Y''. The entry in row ''x'' and column ''y'' is 1 if ''x'' and ''y'' are related (called ''incident'' in this context) and 0 if they are not. There are variations; see below.

==Graph theory==
Incidence matrices are frequently used in [[graph theory]].

===Undirected and directed graphs===
[[Image:Labeled undirected graph.svg|thumb|250px|An undirected graph.]]
In graph theory an [[undirected graph]] has two kinds of incidence matrices: unoriented and oriented. 

The ''unoriented incidence matrix'' (or simply ''incidence matrix'') of an undirected graph is a {{nowrap|''n'' × ''m''}} [[Matrix (math)|matrix]] ''B'', where ''n'' and ''m'' are the numbers of [[Vertex (graph theory)|vertices]] and [[Edge (graph theory)|edge]]s respectively, such that {{nowrap|1=''B''&lt;sub&gt;''i'',''j''&lt;/sub&gt; = 1}} if the vertex ''v''&lt;sub&gt;''i''&lt;/sub&gt; and edge ''e''&lt;sub&gt;''j''&lt;/sub&gt; are incident and 0 otherwise.

For example the incidence matrix of the undirected graph shown on the right is a matrix consisting of 4 rows (corresponding to the four vertices, 1–4) and 4 columns (corresponding to the four edges, e1–e4):
{|
|
{| align=left class=wikitable
|-
! !! e&lt;sub&gt;1&lt;/sub&gt; !! e&lt;sub&gt;2&lt;/sub&gt; !! e&lt;sub&gt;3&lt;/sub&gt; !! e&lt;sub&gt;4&lt;/sub&gt;
|-
!1
|1||1||1||0
|-
!2
|1||0||0||0 
|-
!3
|0||1||0||1 
|-
!4
|0||0||1||1
|}
| =
|
&lt;math&gt;
\begin{pmatrix}
 1 &amp; 1 &amp; 1 &amp; 0 \\
 1 &amp; 0 &amp; 0 &amp; 0 \\
 0 &amp; 1 &amp; 0 &amp; 1 \\
 0 &amp; 0 &amp; 1 &amp; 1 \\
\end{pmatrix}.
&lt;/math&gt;
|}

If we look at the incidence matrix, we see that the sum of each column is equal to 2. This is because each edge has a vertex connected to each end.

The ''incidence matrix'' of a [[directed graph]] is a {{nowrap|''n'' × ''m''}} matrix ''B'' where ''n'' and ''m'' are the number of vertices and edges respectively, such that {{nowrap|1=''B''&lt;sub&gt;''i'',''j''&lt;/sub&gt; = −1}} if the edge ''e''&lt;sub&gt;''j''&lt;/sub&gt; leaves vertex ''v''&lt;sub&gt;i&lt;/sub&gt;, 1 if it enters vertex ''v''&lt;sub&gt;''i''&lt;/sub&gt; and 0 otherwise (many authors use the opposite sign convention).

The ''oriented incidence matrix'' of an undirected graph is the incidence matrix, in the sense of directed graphs, of any [[Orientation (graph theory)|orientation]] of the graph. That is, in the column of edge ''e'', there is one 1 in the row corresponding to one vertex of ''e'' and one −1 in the row corresponding to the other vertex of ''e'', and all other rows have 0. The oriented incidence matrix is unique [[up to]] negation of any of the columns, since negating the entries of a column corresponds to reversing the orientation of an edge.

The unoriented incidence matrix of a graph ''G'' is related to the [[adjacency matrix]] of its [[line graph]] ''L''(''G'') by the following theorem:
: &lt;math&gt;A(L(G)) = B(G)^\textsf{T}B(G) - 2I_m.&lt;/math&gt;

where ''A''(''L''(''G'')) is the adjacency matrix of the line graph of ''G'', ''B''(''G'') is the incidence matrix, and I&lt;sub&gt;''m''&lt;/sub&gt; is the [[identity matrix]] of dimension ''m''.

The discrete [[Kirchhoff matrix|Laplacian]] (or Kirchhoff matrix) is obtained from the oriented incidence matrix ''B''(''G'') by the formula
: &lt;math&gt;B(G) B(G)^\textsf{T}.&lt;/math&gt;

The integral [[cycle space]] of a graph is equal to the [[null space]] of its oriented incidence matrix, viewed as a matrix over the [[integers]] or [[Real numbers|real]] or [[complex numbers]]. The binary cycle space is the null space of its oriented or unoriented incidence matrix, viewed as a matrix over the two-element [[Field (mathematics)|field]].

===Signed and bidirected graphs===
The incidence matrix of a [[signed graph]] is a generalization of the oriented incidence matrix. It is the incidence matrix of any [[bidirected graph]] that orients the given signed graph. The column of a positive edge has a 1 in the row corresponding to one endpoint and a −1 in the row corresponding to the other endpoint, just like an edge in an ordinary (unsigned) graph. The column of a negative edge has either a 1 or a −1 in both rows. The line graph and Kirchhoff matrix properties generalize to signed graphs.

===Multigraphs===
The definitions of incidence matrix apply to graphs with [[loop (graph theory)|loops]] and [[multiple edges]]. The column of an oriented incidence matrix that corresponds to a loop is all zero, unless the graph is signed and the loop is negative; then the column is all zero except for ±2 in the row of its incident vertex.

===Hypergraphs===
Because the edges of ordinary graphs can only have two vertices (one at each end), the column of an incidence matrix for graphs can only have two non-zero entries. By contrast, a [[hypergraph]] can have multiple vertices assigned to one edge; thus, a general matrix of non-negative integers describes a hypergraph.

==Incidence structures==
The ''incidence matrix'' of an [[incidence structure]] ''C'' is a {{nowrap|''p'' × ''q''}} matrix ''B'' (or its transpose), where ''p'' and ''q'' are the number of ''points'' and ''lines'' respectively, such that {{nowrap|1=''B''&lt;sub&gt;''i'',''j''&lt;/sub&gt; = 1}} if the point ''p''&lt;sub&gt;i&lt;/sub&gt; and line ''L''&lt;sub&gt;''j''&lt;/sub&gt; are incident and 0 otherwise. In this case, the incidence matrix is also a [[biadjacency matrix]] of the [[Levi graph]] of the structure. As there is a [[hypergraph]] for every Levi graph, and ''vice versa'', the incidence matrix of an incidence structure describes a hypergraph.

===Finite geometries===
An important example is a [[finite geometry]]. For instance, in a finite plane, ''X'' is the set of points and ''Y'' is the set of lines. In a finite geometry of higher dimension, ''X'' could be the set of points and ''Y'' could be the set of subspaces of dimension one less than the dimension of the entire space (hyperplanes); or, more generally, ''X'' could be the set of all subspaces of one dimension ''d'' and ''Y'' the set of all subspaces of another dimension ''e'', with incidence defined as containment.

===Polytopes===
In a similar manner, the relationship between cells whose dimensions differ by one in a polytope, can be represented by an incidence matrix.&lt;ref&gt;{{citation|first=H.S.M.|last=Coxeter|author-link=Coxeter|title=[[Regular Polytopes (book)|Regular Polytopes]]|year=1973|edition=3rd|origyear=1963|publisher=Dover|isbn=0-486-61480-8|pages=166-167}}&lt;/ref&gt;

===Block designs===
Another example is a [[block design]]. Here ''X'' is a finite set of "points" and ''Y'' is a class of subsets of ''X'', called "blocks", subject to rules that depend on the type of design. The incidence matrix is an important tool in the theory of block designs. For instance, it can be used to prove [[Fisher's inequality]], a fundamental theorem of balanced incomplete 2-designs (BIBDs), that the number of blocks is at least the number of points.&lt;ref&gt;{{citation|page=99|first=Herbert John|last=Ryser|title=Combinatorial Mathematics|series=The Carus Mathematical Monographs #14|publisher=The Mathematical Association of America|year=1963}}&lt;/ref&gt; Considering the blocks as a system of sets, the [[Permanent (mathematics)|permanent]] of the incidence matrix is the number of [[system of distinct representatives|systems of distinct representatives]] (SDRs).

==References==
{{reflist}}

==Further reading==

* {{citation | last=Diestel | first=Reinhard | title=Graph Theory | series=[[Graduate Texts in Mathematics]] | volume=173 | edition=3rd | date=2005 | publisher=Springer-Verlag | isbn=3-540-26183-4}}
* Jonathan L Gross, Jay Yellen, ''Graph Theory and its applications'', second edition, 2006 (p 97, Incidence Matrices for undirected graphs; p 98, incidence matrices for digraphs)


==External links==
{{Commons category|Incidence matrices of graphs}}
{{Wiktionary}}
* {{mathworld | urlname = IncidenceMatrix | title = Incidence matrix}}

{{Graph representations}}
[[Category:Algebraic graph theory]]
[[Category:Combinatorics]]
[[Category:Matrices]]
[[Category:Graph data structures]]</text>
      <sha1>o0uii9mtnl55ebr9s9zlm3qe7682jv0</sha1>
    </revision>
  </page>
  <page>
    <title>Incomplete Fermi–Dirac integral</title>
    <ns>0</ns>
    <id>406924</id>
    <revision>
      <id>731052529</id>
      <parentid>551045321</parentid>
      <timestamp>2016-07-22T16:40:55Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <comment>/* External links */clean up; http-&gt;https (see [[WP:VPR/Archive 127#RfC: Should we convert existing Google and Internet Archive links to HTTPS?|this RfC]]) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="573">In [[mathematics]], the '''incomplete [[Enrico Fermi|Fermi]]–[[Paul Dirac|Dirac]] integral''' for an index ''j'' is given by

:&lt;math&gt;F_j(x,b) = \frac{1}{\Gamma(j+1)} \int_b^\infty \frac{t^j}{\exp(t-x) + 1}\,dt.&lt;/math&gt;

This is an alternate definition of the [[incomplete polylogarithm]].

== See also ==
* [[Complete Fermi–Dirac integral]]

==External links==
* [https://www.gnu.org/software/gsl/manual/gsl-ref.html#SEC119 GNU Scientific Library - Reference Manual]

{{DEFAULTSORT:Incomplete Fermi-Dirac Integral}}
[[Category:Special functions]]


{{mathanalysis-stub}}</text>
      <sha1>qf4orbbbp7i0brx517a16t55gzw7rps</sha1>
    </revision>
  </page>
  <page>
    <title>Inverse dynamics</title>
    <ns>0</ns>
    <id>2129591</id>
    <revision>
      <id>756073554</id>
      <parentid>756053090</parentid>
      <timestamp>2016-12-21T21:03:16Z</timestamp>
      <contributor>
        <username>HCA</username>
        <id>86076</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/AccuracyRevealed1234|AccuracyRevealed1234]] ([[User talk:AccuracyRevealed1234|talk]]) to last version by Dcirovic</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7751">'''Inverse dynamics''' is an [[inverse problem]]. It commonly refers to either inverse rigid body dynamics or inverse [[structural dynamics]]. Inverse [[rigid-body dynamics]] is a method for computing forces and/or [[moment of force|moments of force]] (torques) based on the [[kinematics]] (motion) of a body and the body's inertial properties ([[mass]] and [[moment of inertia]]). Typically it uses link-segment models to represent the mechanical behaviour of interconnected segments, such as the [[Limb (anatomy)|limb]]s of humans,&lt;ref&gt;{{cite journal | author=Crowninshield, R. D., Johnston, R. C., Andrews, J. G., &amp; Brand, R. A. |  title=A biomechanical investigation of the human hip | journal=Journal of Biomechanics | year=1978| volume=11 | pages=75–85 | doi=10.1016/0021-9290(78)90045-3 | issue=1}}&lt;/ref&gt; animals or [[robot]]s, where given the kinematics of the various parts, inverse dynamics derives the minimum forces and moments responsible for the individual movements. In practice, inverse dynamics computes these internal moments and forces from measurements of the motion of limbs and external forces such as [[ground reaction force]]s, under a special set of assumptions.&lt;ref name=Robertson&gt;Robertson DGE, et al., Research Methods in Biomechanics, Champaign IL:Human Kinetics Pubs., 2004.&lt;/ref&gt;&lt;ref name=Winter&gt;{{cite book | author=Winter, D.A. | title=The biomechanics and motor control of human gait: normal, elderly and pathological | location=Waterloo, Ontario | publisher=University of Waterloo Press | year=1991 | id= }}&lt;/ref&gt;

==Applications==
The fields of [[robotics]] and [[biomechanics]] constitute the major application areas for inverse dynamics.{{Citation needed|date=July 2013}}

Within [[robotics]], inverse dynamics algorithms are used to calculate the [[torque]]s that a robot's motors must deliver to make the robot's end-point move in the way prescribed by its current task. The "inverse dynamics problem" in Robotics Engineering was solved by [[Eduardo Bayo]] in 1987. This solution calculates how each of the numerous electric motors that control a robot arm must move to produce a particular action. Humans can perform very complicated and precise movements, such as controlling the tip of a fishing rod well enough to cast the bait accurately. Before the arm moves, the brain calculates the necessary movement of each muscle involved and tells the muscles what to do as the arm swings. In the case of a robot arm, the "muscles" are the electric motors which must turn by a given amount at a given moment. Each motor must be supplied with just the right amount of electric current, at just the right time. Researchers can predict the motion of a robot arm if they know how the motors will move. This is known as the forward dynamics problem. Until this discovery, they had not been able to work backwards to calculate the movements of the motors required to generate a particular complicated motion.,&lt;ref&gt;"New Scientist Magazine".25, August, 1988. Pg. 34, "Robot Riddle Solved".&lt;/ref&gt; Bayo's work began with the application of frequency-domain methods to the inverse dynamics of single-link flexible robots. This approach yielded non-causal exact solutions due to the right-half plane zeros in the hub-torque-to-tip transfer functions. Extending this method to the nonlinear multi-flexible-link case was of particular importance to robotics. When combined with passive joint control in a collaborative effort with a control group, Bayo's inverse dynamics approach led to exponentially stable tip-tracking control for flexible multi-link robots.&lt;ref&gt;Bayo E., "A Finite Element Approach to Control the End-Point Motion of a Single Link Flexible Robot," "Journal of Robotic Systems", Vol. 4, No. 1, pp. 63–75. Feb. 1987.&lt;/ref&gt;

Similarly, inverse dynamics in biomechanics computes the net turning effect of all the anatomical structures across a joint, in particular the muscles and ligaments, necessary to produce the observed motions of the joint. These moments of force may then be used to compute the amount of [[mechanical work]] performed by that moment of force. Each moment of force can perform positive work to increase the speed and/or height of the body or perform negative work to decrease the speed and/or height of the body.&lt;ref name=Robertson/&gt;&lt;ref name=Winter/&gt; The equations of motion necessary for these computations are based on [[Newtonian mechanics]], specifically the [[Newton–Euler equations]] of:

: ''[[Force]] equal [[mass]] times [[linear]] [[acceleration]],'' and
: ''[[Moment (physics)|Moment]] equals [[moment of inertia|mass moment of inertia]] times [[angular acceleration]].

These equations mathematically model the behaviour of a limb in terms of a knowledge domain-independent, link-segment model, such as idealized [[solid of revolution|solids of revolution]] or a skeleton with fixed-length limbs and perfect pivot joints. From these equations, inverse dynamics derives the torque (moment) level at each joint based on the movement of the attached limb or limbs affected by the joint. This process used to derive the joint moments is known as inverse dynamics because it reverses the forward dynamics equations of motion, the set of differential equations which yield the position and angle trajectories of the idealized skeleton's limbs from the accelerations and forces applied.

From joint moments, a biomechanist could infer muscle forces that would lead to those moments based on a model of bone and muscle attachments, etc., thereby estimating muscle activation from kinematic motion.

Correctly computing force (or moment) values from inverse dynamics can be challenging because external forces (e.g., ground contact forces) affect motion but are not directly observable from the kinematic motion. In addition, co-activation of muscles can lead
to a family of solutions which are not distinguishable from the kinematic motion's characteristics. Furthermore, closed kinematic chains, such as swinging a bat or shooting a hockey puck, require the measurement of internal forces (in the bat or stick) be made before shoulder, elbow or wrist moments and forces can be derived.&lt;ref name=Robertson/&gt;

==See also==
* [[Kinematics]]
* [[Inverse kinematics]]: a problem similar to Inverse dynamics but with different goals and starting assumptions. While inverse dynamics asks for torques that produce a certain time-trajectory of positions and velocities, inverse kinematics only asks for a static set of joint angles such that a certain point (or a set of points) of the character (or robot) is positioned at a certain designated location. It is used in synthesizing the appearance of human motion, particularly in the field of video game design. Another use is in robotics, where joint angles of an arm must be calculated from the desired position of the end effector.
* [[Body segment parameter]]s

==References==
{{reflist}}
*{{cite journal |author1=Kirtley, C. |author2=Whittle, M.W |author3=Jefferson, RJ | title=Influence of Walking Speed on Gait Parameters | journal=Journal of Biomedical Engineering | year=1985 | volume=7 | pmid=4057987 | pages=282–8 | doi=10.1016/0141-5425(85)90055-X | issue=4}}
*{{cite journal | author=Jensen RK | title=Changes in segment inertia proportions between four and twenty years | journal=Journal of Biomechanics | year=1989 | volume=22 | pages=529–36 | pmid=2808438 | issue=6–7 | doi=10.1016/0021-9290(89)90004-3}}

==External links==
* [http://www.clinicalgaitanalysis.com/teach-in/inverse-dynamics.html Inverse dynamics] Chris Kirtley's research roundup and tutorials on biomechanical aspects of human gait.

[[Category:Robot control]]
[[Category:Motor control]]
[[Category:Inverse problems]]
[[Category:1987 in robotics]]</text>
      <sha1>dotzltqesw3qxw7q98d49q23tjsa8cu</sha1>
    </revision>
  </page>
  <page>
    <title>Kernighan–Lin algorithm</title>
    <ns>0</ns>
    <id>23174224</id>
    <revision>
      <id>792256369</id>
      <parentid>783356179</parentid>
      <timestamp>2017-07-25T13:14:03Z</timestamp>
      <contributor>
        <username>Flowi</username>
        <id>3142777</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4186">: ''This article is about the heuristic algorithm for the graph partitioning problem. For a heuristic for the traveling salesperson problem, see [[Lin–Kernighan heuristic]].''
The '''Kernighan–Lin algorithm''' is a [[Heuristic (computer science)|heuristic algorithm]] for [[graph partition|finding partitions of graphs]].
The algorithm has important applications in the layout of digital circuits and components in [[VLSI]].&lt;ref name="kl"/&gt;&lt;ref name="ravikumar"/&gt;

==Description==
The input to the algorithm is an [[undirected graph]] {{math|1=''G'' = (''V'',''E'')}} with vertex set {{mvar|V}}, edge set {{mvar|E}}, and (optionally) numerical weights on the edges in {{mvar|E}}. The goal of the algorithm is to partition {{mvar|V}} into two disjoint subsets {{mvar|A}} and {{mvar|B}} of equal (or nearly equal) size, in a way that minimizes the sum {{mvar|T}} of the weights of the subset of edges that cross from {{mvar|A}} to {{mvar|B}}. If the graph is unweighted, then instead the goal is to minimize the number of crossing edges; this is equivalent to assigning weight one to each edge. The algorithm maintains and improves a partition, in each pass using a [[greedy algorithm]] to pair up vertices of {{mvar|A}} with vertices of {{mvar|B}}, so that moving the paired vertices from one side of the partition to the other will improve the partition. After matching the vertices, it then performs a subset of the pairs chosen to have the best overall effect on the solution quality {{mvar|T}}.
Given a graph with {{mvar|n}} vertices, each pass of the algorithm runs in time {{math|''O''(''n''&lt;sup&gt;2&lt;/sup&gt; log ''n'')}}. 

In more detail, let &lt;math&gt;I_{a}&lt;/math&gt; be the ''internal cost'' of ''a'', that is, the sum of the costs of edges between ''a'' and other nodes in ''A'', and let &lt;math&gt;E_{a}&lt;/math&gt; be the ''external cost'' of ''a'', that is, the sum of the costs of edges between ''a'' and nodes in ''B''. Furthermore, let 
:&lt;math&gt;D_{a} = E_{a} - I_{a}&lt;/math&gt;
be the difference between the external and internal costs of ''a''. If ''a'' and ''b'' are interchanged, then the reduction in cost is
:&lt;math&gt;T_{old} - T_{new} = D_{a} + D_{b} - 2c_{a,b}&lt;/math&gt;
where &lt;math&gt;c_{a,b}&lt;/math&gt; is the cost of the possible edge between ''a'' and ''b''.

The algorithm attempts to find an optimal series of interchange operations between elements of &lt;math&gt;A&lt;/math&gt; and &lt;math&gt;B&lt;/math&gt; which maximizes &lt;math&gt;T_{old} - T_{new}&lt;/math&gt; and then executes the operations, producing a partition of the graph to ''A'' and ''B''.&lt;ref name="kl"&gt;{{cite journal|first1=B. W.|last1=Kernighan|authorlink1=Brian Kernighan|first2=Shen|last2=Lin| year = 1970 | title = An efficient heuristic procedure for partitioning graphs | journal = Bell System Technical Journal|volume=49|pages=291–307| doi=10.1002/j.1538-7305.1970.tb01770.x}}&lt;/ref&gt;

==Pseudocode==
See &lt;ref name="ravikumar"&gt;{{cite book |last=Ravikumar |first=C. P |title=Parallel methods for VLSI layout design|publisher=Greenwood Publishing Group|year=1995|pages=73|isbn=978-0-89391-828-6|url=https://books.google.com/books?id=VPXAxkTKxXIC}}&lt;/ref&gt;

&lt;code&gt;
  1  '''function''' Kernighan-Lin(''G(V,E)''):
  2      determine a balanced initial partition of the nodes into sets A and B
  3      
  4      '''do'''
  5         compute D values for all a in A and b in B
  6         let gv, av, and bv be empty lists
  7         '''for (n := 1 to |V|/2)'''
  8            find a from A and b from B, such that g = D[a] + D[b] - 2*c(a, b) is maximal
  9            remove a and b from further consideration in this pass
  10           add g to gv, a to av, and b to bv
  11           update D values for the elements of A = A \ a and B = B \ b
  12        '''end for'''
  13        find k which maximizes g_max, the sum of gv[1],...,gv[k]
  14        '''if (g_max &gt; 0)''' '''then'''
  15           Exchange av[1],av[2],...,av[k] with bv[1],bv[2],...,bv[k]
  16     '''until (g_max &lt;= 0)'''
  17  '''return G(V,E)'''
&lt;/code&gt;

==See also==
* [[Fiduccia-Mattheyses algorithm]]

==References==
{{reflist}}

{{DEFAULTSORT:Kernighan-Lin algorithm}}
[[Category:Combinatorial optimization]]
[[Category:Combinatorial algorithms]]
[[Category:Heuristic algorithms]]</text>
      <sha1>5dfacsj5onr6b99vxk8zql4gcdvnk59</sha1>
    </revision>
  </page>
  <page>
    <title>Laurent series</title>
    <ns>0</ns>
    <id>61213</id>
    <revision>
      <id>870260285</id>
      <parentid>870258756</parentid>
      <timestamp>2018-11-23T15:41:44Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>Undid revision 870258756 by [[Special:Contributions/2620:101:C040:860:EDDB:9272:6C19:F910|2620:101:C040:860:EDDB:9272:6C19:F910]] ([[User talk:2620:101:C040:860:EDDB:9272:6C19:F910|talk]]) not really helpful</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14863">{{about|doubly infinite power series|power series with finitely many negative exponents|Formal Laurent series}}

[[Image:Laurent series.svg|frame|right|A Laurent series is defined with respect
to a particular point ''c'' and a path of integration γ. The path of
integration must lie in an annulus, indicated here by the red color, inside which ''f''(''z'') is
[[holomorphic function|holomorphic]] (analytic).]]

In [[mathematics]], the '''Laurent series''' of a complex function ''f''(''z'') is a representation of that function as a [[power series]] which includes terms of negative degree. It may be used to express complex functions in cases where
a [[Taylor series]] expansion cannot be applied. The Laurent series was named
after and first published by [[Pierre Alphonse Laurent]] in 1843.
[[Karl Weierstrass]] may have discovered it first in a paper written in 1841, but it was not published until after his death.&lt;ref&gt;{{citation|title=Complex Analysis: In the Spirit of Lipman Bers|volume=245|series=Graduate Texts in Mathematics|first1=Rubi|last1=Rodriguez|first2=Irwin|last2=Kra|first3=Jane P.|last3=Gilman|author3-link=Jane Piore Gilman|publisher=Springer|year=2012|isbn=9781441973238|page=12|url=https://books.google.com/books?id=fZbf629lTy0C&amp;pg=PA12}}.&lt;/ref&gt;

The Laurent series for a complex function ''f''(''z'') about a point ''c'' is given by:

:&lt;math&gt;f(z)=\sum_{n=-\infty}^\infty a_n(z-c)^n&lt;/math&gt;

where the ''a&lt;sub&gt;n&lt;/sub&gt; and c'' are constants, defined by a [[line integral]]
which is a generalization of [[Cauchy's integral formula]]:

:&lt;math&gt;a_n=\frac{1}{2\pi i} \oint_\gamma \frac{f(z)\,\mathrm{d}z}{(z-c)^{n+1}}.\,&lt;/math&gt;

The path of integration &lt;math&gt;\gamma&lt;/math&gt; is counterclockwise around a [[Jordan curve]] enclosing
''c'' and lying in an [[annulus (mathematics)|annulus]] ''A'' in which &lt;math&gt;f(z)&lt;/math&gt; is
[[holomorphic function|holomorphic]] (analytic). The expansion for &lt;math&gt;f(z)&lt;/math&gt; will then be valid anywhere inside the annulus. The annulus is
shown in red in the figure on the right, along with an example of a suitable
path of integration labeled &lt;math&gt;\gamma&lt;/math&gt;.
If we take &lt;math&gt;\gamma&lt;/math&gt; to be a circle &lt;math&gt; |z-c| = \varrho&lt;/math&gt;, where &lt;math&gt;r &lt; \varrho &lt; R&lt;/math&gt;, this just amounts
to computing the complex [[Fourier coefficients]] of the restriction of &lt;math&gt;f&lt;/math&gt; to &lt;math&gt;\gamma&lt;/math&gt;. The fact that these
integrals are unchanged by a deformation of the contour &lt;math&gt;\gamma&lt;/math&gt; is an immediate consequence of [[Green's theorem]]. 

In practice, the above integral  formula may not offer the most practical method for computing the coefficients
&lt;math&gt;a_n&lt;/math&gt; for a given function &lt;math&gt;f(z)&lt;/math&gt;; instead, one often pieces together the Laurent
series by combining known Taylor expansions.
Because the Laurent expansion of a function is [[Unique (mathematics)|unique]] whenever
it exists, any  expression of this form that actually equals the given function 
&lt;math&gt;f(z)&lt;/math&gt; in some annulus must actually be the 
Laurent expansion of &lt;math&gt;f(z)&lt;/math&gt;.

== Convergent Laurent series ==

Laurent series with complex coefficients are an important tool in [[complex analysis]], especially to investigate the behavior of functions near [[mathematical singularity|singularities]].
[[Image:Expinvsqlau SVG.svg|right|thumb|''e''&lt;sup&gt;&amp;minus;(1/''x''&lt;sup&gt;2&lt;/sup&gt;)&lt;/sup&gt; and Laurent approximations: see text for key. As the negative degree of the Laurent series rises, it approaches the correct function.]]
[[Image:Expinvsqlau GIF.gif|right|thumb|''e''&lt;sup&gt;&amp;minus;(1/''x''&lt;sup&gt;2&lt;/sup&gt;)&lt;/sup&gt; and its Laurent approximations with the negative degree rising. The neighborhood around the zero singularity can never be approximated.]]

Consider for instance the function &lt;math&gt;f(x) = e^{-1/x^2}&lt;/math&gt; with &lt;math&gt;f(0) = 0&lt;/math&gt;. As a real function, it is infinitely differentiable everywhere; as a complex function however it is not differentiable at ''x'' = 0. By replacing ''x'' with &amp;minus;1/''x''&lt;sup&gt;2&lt;/sup&gt; in the [[power series]] for the [[exponential function]], we obtain its Laurent series which converges and is equal to ''ƒ''(''x'') for all complex numbers ''x'' except at the singularity ''x'' = 0. The graph opposite shows ''e''&lt;sup&gt;&amp;minus;1/''x''&lt;sup&gt;2&lt;/sup&gt;&lt;/sup&gt; in black and its Laurent approximations

:&lt;math&gt;\sum_{n=0}^N(-1)^n\,{x^{-2n}\over n!}&lt;/math&gt;

for ''N'' = &lt;span style="color:#b30000;"&gt;1&lt;/span&gt;, &lt;span style="color:#00b300;"&gt;2&lt;/span&gt;, &lt;span style="color:#0000b3;"&gt;3&lt;/span&gt;, &lt;span style="color:#b3b300;"&gt;4&lt;/span&gt;, &lt;span style="color:#00b3b3;"&gt;5&lt;/span&gt;, &lt;span style="color:#b300b3;"&gt;6&lt;/span&gt;, &lt;span style="color:#b3b3b3;"&gt;7&lt;/span&gt; and &lt;span style="color:#33b300;"&gt;50&lt;/span&gt;. As ''N'' → ∞, the approximation becomes exact for all (complex) numbers ''x'' except at the singularity ''x'' = 0.

More generally, Laurent series can be used to express [[holomorphic function]]s defined on an [[Annulus (mathematics)|annulus]], much as [[power series]] are used to express holomorphic functions defined on a [[Disk (mathematics)|disc]].

Suppose 

:&lt;math&gt;\sum_{n=-\infty}^\infty a_n ( z - c )^n&lt;/math&gt;

is a given Laurent series with complex coefficients ''a''&lt;sub&gt;''n''&lt;/sub&gt; and a complex center ''c''. Then there exists a [[unique (mathematics)|unique]] inner radius &lt;var&gt;r&lt;/var&gt; and outer radius ''R'' such that:
* The Laurent series converges on the open annulus ''A''&amp;nbsp;≡ {''z''&amp;nbsp;: ''r''&amp;nbsp;&lt;&amp;nbsp;|''z''&amp;nbsp;&amp;minus;&amp;nbsp;''c''|&amp;nbsp;&lt;&amp;nbsp;''R''}. To say that the Laurent series converges, we mean that both the positive degree power series and the negative degree power series converge. Furthermore, this convergence will be [[uniform convergence|uniform]] on [[compact set]]s. Finally, the convergent series defines a [[holomorphic function]] ''ƒ''(''z'') on the open annulus.
* Outside the annulus, the Laurent series diverges. That is, at each point of the [[exterior (topology)|exterior]] of ''A'', the positive degree power series or the negative degree power series diverges.
* On the [[boundary (topology)|boundary]] of the annulus, one cannot make a general statement, except to say that there is at least one point on the inner boundary and one point on the outer boundary such that ''ƒ''(''z'') cannot be holomorphically continued to those points.

It is possible that ''r'' may be zero or ''R'' may be infinite; at the other extreme, it's not necessarily true that ''r'' is less than ''R''.
These radii can be computed as follows:

:&lt;math&gt;\begin{align}
            r &amp;= \limsup_{n\rightarrow\infty} |a_{-n}|^\frac{1}{n} \\
  {1 \over R} &amp;= \limsup_{n\rightarrow\infty} |a_n|^\frac{1}{n}.
\end{align}&lt;/math&gt;

We take ''R'' to be infinite when this latter [[limit superior|lim sup]] is zero.

Conversely, if we start with an annulus of the form ''A''&amp;nbsp;≡ {''z''&amp;nbsp;: ''r''&amp;nbsp;&lt; |''z''&amp;nbsp;&amp;minus;&amp;nbsp;''c''|&amp;nbsp;&lt;&amp;nbsp;''R''} and a holomorphic function ''ƒ''(''z'') defined on ''A'', then there always exists a unique Laurent series with center ''c'' which converges (at least) on ''A'' and represents the function ''ƒ''(''z'').

As an example, consider the following rational function, along with its [[partial fraction]] expansion:

:&lt;math&gt;f(z) \ =\ \frac{1}{(z{-}1)(z{-}2i)} 
\ =\ \frac{1+2i}{5}\left(\frac{1}{z{-}1} - \frac{1}{z{-}2i}\right)
.&lt;/math&gt;

This function has singularities at ''z''&amp;nbsp;=&amp;nbsp;1 and ''z''&amp;nbsp;=&amp;nbsp;2''i'', where the denominator of the expression is zero and the expression is therefore undefined.
A [[Taylor series]] about ''z''&amp;nbsp;=&amp;nbsp;0 (which yields a power series) will only converge in a disc of [[radius]] 1, since it "hits" the singularity at 1.

However, there are three possible Laurent expansions about 0, depending on the radius of ''z'':
* One series is defined on the inner disc where |''z''|&amp;nbsp;&lt;&amp;nbsp;1; it is the same as the Taylor series,
:&lt;math&gt;f(z) = \frac{1 + 2i}{5} \sum_{n=0}^\infty \left(\frac{1}{(2i)^{n + 1}} - 1\right)z^n.&lt;/math&gt;
This follows from the partial fraction form of the function, along with the formula for the sum  of a [[geometric series]], &lt;math&gt;\textstyle \frac{1}{z-a} = - \frac{1}{a} \sum_{n=0}^\infty \left( \tfrac{z}{a} \right)^n &lt;/math&gt; for &lt;math&gt;|z| &lt; |a| &lt;/math&gt;.
* The second series is defined on the middle annulus where 1&amp;nbsp;&lt; |''z''|&amp;nbsp;&lt;&amp;nbsp;2, caught between the two singularities,
:&lt;math&gt;f(z) = \frac{1 + 2i}{5} \left(\sum_{n=1}^\infty z^{-n} + \sum_{n=0}^\infty \frac{1}{(2i)^{n + 1}}z^n\right).&lt;/math&gt;
Here, we use the alternative form of the geometric series summation, &lt;math&gt;\textstyle \frac{1}{z-a} = \frac{1}{z}\sum_{n=0}^\infty \left(\tfrac{a}{z}\right)^n &lt;/math&gt;  for &lt;math&gt;|a| &lt; |z| &lt;/math&gt;.
* The third series is defined on the infinite outer annulus where 2&amp;nbsp;&lt; |''z''|&amp;nbsp;&lt;&amp;nbsp;∞,
:&lt;math&gt;f(z) = \frac{1 + 2i}{5} \sum_{n=1}^\infty (1 - (2i)^{n - 1}) z^{-n}.&lt;/math&gt;
This series can be derived using geometric series as before, or by performing polynomial long division of 1 by (''x''&amp;minus;1)(''x''&amp;minus;2i), not stopping with a remainder but continuing into ''x''&lt;sup&gt;&amp;minus;''n''&lt;/sup&gt; terms; indeed, the "outer" Laurent series of a rational function is analogous to the decimal form of a fraction. (The "inner" Taylor series expansion can be obtained similarly, just reversing the [[monomial order|term order]] in the division algorithm.)

The case ''r''&amp;nbsp;=&amp;nbsp;0; i.e., a holomorphic function ''ƒ''(''z'') which may be undefined at a single point ''c'', is especially important.

The coefficient ''a''&lt;sub&gt;−1&lt;/sub&gt; of the Laurent expansion of such a function is called the [[residue (complex analysis)|residue]] of ''ƒ''(''z'') at the singularity ''c''; it plays a prominent role in the [[residue theorem]].

For an example of this, consider

:&lt;math&gt;f(z) = {e^z \over z} + e^\frac{1}{z}.&lt;/math&gt;

This function is holomorphic everywhere except at ''z''&amp;nbsp;=&amp;nbsp;0.
To determine the Laurent expansion about ''c''&amp;nbsp;=&amp;nbsp;0, we use our knowledge of the Taylor series of the [[exponential function]]:

:&lt;math&gt;f(z) = \cdots + \left( {1 \over 3!} \right) z^{-3} + \left( {1 \over 2!} \right) z^{-2} + 2z^{-1} + 2 + \left( {1 \over 2!} \right) z + \left( {1 \over 3!} \right) z^2 + \left( {1 \over 4!} \right) z^3 + \cdots&lt;/math&gt;

and we find that the residue is&amp;nbsp;2.

== Uniqueness ==

Suppose a function ƒ(''z'') holomorphic on the annulus  ''r'' &lt; |''z'' − ''c''| &lt; ''R'' has two Laurent series:

: &lt;math&gt;f(z)=\sum_{n=-\infty}^{\infty}a_{n}\left(z-c\right)^{n}=\sum_{n=-\infty}^{\infty}b_{n}\left(z-c\right)^{n}.&lt;/math&gt;

Multiply both sides with &lt;math&gt;\left(z-c\right)^{-k-1}&lt;/math&gt;, where k is an arbitrary integer, and integrate on a path γ inside the annulus,

: &lt;math&gt;\oint_{\gamma}\sum_{n=-\infty}^{\infty}a_{n}\left(z-c\right)^{n-k-1}\mathrm{d}z=\oint_{\gamma}\sum_{n=-\infty}^{\infty}b_{n}\left(z-c\right)^{n-k-1}\mathrm{d}z.&lt;/math&gt;

The series converges uniformly on &lt;math&gt;r+\epsilon\leq|z-c|\leq R-\epsilon&lt;/math&gt;, where ε is a positive number small enough for γ to be contained in the constricted closed annulus, so the integration and summation can be interchanged. Substituting the identity

: &lt;math&gt;\oint_{\gamma}(z-c)^{n-k-1}dz=2\pi i\delta_{nk}&lt;/math&gt;

into the summation yields

: &lt;math&gt;a_k=b_k&lt;/math&gt;

Hence the Laurent series is unique.

== Laurent polynomials ==
{{main|Laurent polynomial}}

A '''Laurent polynomial''' is a Laurent series in which only finitely many coefficients are non-zero. Laurent polynomials differ from ordinary [[polynomial]]s in that they may have terms of negative degree.

== Principal part ==
The '''principal part''' of a Laurent series is the series of terms with negative degree, that is
: &lt;math&gt;\sum_{k=-\infty}^{-1} a_k (z-c)^k.&lt;/math&gt;

If the principal part of ''f'' is a finite sum, then ''f'' has a [[pole (complex analysis)|pole]] at ''c'' of order equal to (negative) the degree of the highest term; on the other hand, if ''f'' has an [[essential singularity]] at ''c'', the principal part is an infinite sum (meaning it has infinitely many non-zero terms).

If the inner radius of convergence of the Laurent series for ''f'' is 0, then ''f'' has an essential singularity at ''c'' if and only if the principal part is an infinite sum, and has a pole otherwise.

If the inner radius of convergence is positive, ''f'' may have infinitely many negative terms but still be regular at ''c'', as in the example above, in which case it is represented by a ''different'' Laurent series in a disk about&amp;nbsp;''c''.

Laurent series with only finitely many negative terms are well-behaved—they are a power series divided by &lt;math&gt;z^k&lt;/math&gt;, and can be analyzed similarly—while Laurent series with infinitely many negative terms have complicated behavior on the inner circle of convergence.

=== Multiplication ===
Laurent series cannot in general be multiplied.
Algebraically, the expression for the terms of the product may involve infinite sums which need not converge (one cannot take the [[convolution]] of integer sequences).
Geometrically, the two Laurent series may have non-overlapping annuli of convergence.

Two Laurent series with only ''finitely'' many negative terms can be multiplied: algebraically, the sums are all finite; geometrically, these have poles at ''c'', and inner radius of convergence 0, so they both converge on an overlapping annulus.

Thus when defining [[Formal power series#Formal Laurent series|formal Laurent series]], one requires Laurent series with only finitely many negative terms.

Similarly, the sum of two convergent Laurent series need not converge, though it is always defined formally, but the sum of two bounded below Laurent series (or any Laurent series on a punctured disk) has a non-empty annulus of convergence.

== See also ==

* [[Puiseux series]]
* [[Mittag-Leffler's theorem]]
* [[Formal Laurent series]] &amp;mdash; Laurent series considered ''formally'', with coefficients from an arbitrary [[commutative ring]], without regard for convergence, and with only ''finitely'' many negative terms, so that multiplication is always defined.
* [[Z-transform]] &amp;mdash; the special case where the Laurent series is taken about zero has much use in time series analysis.
* [[Fourier series]] &amp;mdash; the substitution &lt;math&gt;z=e^{\pi i w}&lt;/math&gt; transforms a Laurent series into a Fourier series, or conversely. This is used in the ''q''-series expansion of the [[j-invariant|''j''-invariant]].
* [[Padé approximant]] &amp;mdash; Another technique used when a [[Taylor series]] is not viable

==References==
{{reflist}}

== External links ==
* {{springer|title=Laurent series|id=p/l057690}}
* {{MacTutor Biography|id=Laurent_Pierre}}
* {{MathWorld | urlname=LaurentSeries | title=Laurent Series }}
*[http://www.mrob.com/pub/muency/laurentseries.html Laurent Series and Mandelbrot set by Robert Munafo]

{{DEFAULTSORT:Laurent Series}}
[[Category:Complex analysis]]
[[Category:Series expansions]]</text>
      <sha1>2svo71zqfn5xlh1ydzusqcianarjhhw</sha1>
    </revision>
  </page>
  <page>
    <title>Limiting point (geometry)</title>
    <ns>0</ns>
    <id>41144612</id>
    <revision>
      <id>807594710</id>
      <parentid>807594601</parentid>
      <timestamp>2017-10-28T23:31:25Z</timestamp>
      <contributor>
        <username>Jimw338</username>
        <id>16217448</id>
      </contributor>
      <comment>Undid revision 807594601 by [[Special:Contributions/Jimw338|Jimw338]] ([[User talk:Jimw338|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2907">[[File:Apollonian circles.svg|thumb|240px|The two points where the red circles cross are the limiting points of each pair of blue circles]]
In geometry, the '''limiting points''' of two disjoint circles ''A'' and ''B'' in the [[Euclidean plane]] are points ''p'' that may be defined by any of the following equivalent properties:
*The [[pencil of circles]] defined by ''A'' and ''B'' contains a degenerate (radius zero) circle centered at&amp;nbsp;''p''.&lt;ref&gt;{{citation|title=A treatise on the circle and the sphere|year=1916|last=Coolidge|first=Julian Lowell|publisher=Oxford Clarendon Press|url=https://archive.org/details/treatiseoncircle00cooluoft|page=97}}.&lt;/ref&gt;
*Every circle or line that is [[perpendicular]] to both ''A'' and ''B'' passes through ''p''.&lt;ref&gt;This follows from the pencil definition, together with the fact that every pencil has a unique orthogonal pencil; see {{citation|title=Geometry of Complex Numbers|first=Hans|last=Schwerdtfeger|publisher=Dover|year=1979}}, Corollary, p.&amp;nbsp;31.&lt;/ref&gt;
*An [[Inversive geometry|inversion]] centered at ''p'' transforms ''A'' and ''B'' into [[concentric]] circles.&lt;ref&gt;{{harvtxt|Schwerdtfeger|1979}}, Example&amp;nbsp;2, p.&amp;nbsp;32.&lt;/ref&gt;

The midpoint of the two limiting points is the point where the [[radical axis]] of ''A'' and ''B'' crosses the line through their centers. This intersection point has equal [[power distance]] to all the circles in the pencil containing ''A'' and ''B''. The limiting points themselves can be found at this distance on either side of the intersection point, on the line through the two circle centers. From this fact it is straightforward to construct the limiting points algebraically or by [[compass and straightedge]].&lt;ref&gt;{{citation
 | last = Johnstone | first = John K.
 | doi = 10.1016/0167-8396(93)90049-9
 | issue = 1
 | journal = Computer Aided Geometric Design
 | mr = 1202965
 | pages = 1–24
 | title = A new intersection algorithm for cyclides and swept surfaces using circle decomposition
 | url = http://www.cis.uab.edu/info/faculty/jj/papers/implicit/intersectionSweptSurfCAGD.pdf
 | volume = 10
 | year = 1993}}.&lt;/ref&gt;
An explicit formula expressing the limiting points as the solution to a [[quadratic equation]] in the coordinates of the circle centers and their radii is given by Weisstein.&lt;ref&gt;{{mathworld|id=LimitingPoint|title=Limiting Point}}&lt;/ref&gt;

Inverting one of the two limiting points through ''A'' or ''B'' produces the other limiting point. An inversion centered at one limiting point maps the other limiting point to the common center of the concentric circles.&lt;ref&gt;{{citation|title=Modern Geometry |first1=C.|last1=Godfrey|first2=A. W.|last2=Siddons|year=1908|publisher=University Press|url=https://openlibrary.org/books/OL6525169M/Modern_geometry|page=109}}.&lt;/ref&gt;

==References==
{{reflist}}

[[Category:Circles]]
[[Category:Inversive geometry]]


{{elementary-geometry-stub}}</text>
      <sha1>45j660eq5npbpqzlcd1zlv59mxs1my5</sha1>
    </revision>
  </page>
  <page>
    <title>List of formulas in elementary geometry</title>
    <ns>0</ns>
    <id>33900798</id>
    <revision>
      <id>860607857</id>
      <parentid>817765399</parentid>
      <timestamp>2018-09-21T20:56:54Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <minor/>
      <comment>/* References */minor fixes</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2419">This is a short list of some common mathematical shapes and figures and the formulas that describe them.

== Two-dimensional shapes ==
{| class="wikitable"
|-
! Shape !! [[Area]] !! Perimeter/Circumference
|-
| [[Square]] (where &lt;math&gt;s&lt;/math&gt; is the length of a side)|| &lt;math&gt;A = s^2&lt;/math&gt; || &lt;math&gt;P = 4s&lt;/math&gt;
|-
| [[Rectangle]] ( &lt;math&gt;l&lt;/math&gt; is length, &lt;math&gt;w&lt;/math&gt; is width) || &lt;math&gt;A = lw&lt;/math&gt; || &lt;math&gt;P = 2l + 2w&lt;/math&gt;
|-
| [[Circle]] (where &lt;math&gt;r&lt;/math&gt; is the radius and &lt;math&gt;d&lt;/math&gt; is the diameter)|| &lt;math&gt;A = \pi r^2&lt;/math&gt; || &lt;math&gt;C = 2\pi r&lt;/math&gt; or &lt;math&gt;C = \pi d&lt;/math&gt;
|-im
| [[Ellipse]] (where &lt;math&gt;a&lt;/math&gt; is the semimajor axis and &lt;math&gt;b&lt;/math&gt; is the semiminor axis) || &lt;math&gt;A = \pi ab&lt;/math&gt; || 
|-
| [[Triangle]] (&lt;math&gt;b&lt;/math&gt; is base; &lt;math&gt;h&lt;/math&gt; is height; &lt;math&gt;a,b,c&lt;/math&gt; are sides) || &lt;math&gt;A = \frac{bh}{2}&lt;/math&gt; || &lt;math&gt;P = a + b + c&lt;/math&gt;
|-
| [[Parallelogram]] (&lt;math&gt;b&lt;/math&gt; is base, &lt;math&gt;h&lt;/math&gt; is height, &lt;math&gt;a&lt;/math&gt; is side) || &lt;math&gt;A = bh&lt;/math&gt; || &lt;math&gt;P = 2a + 2b&lt;/math&gt;
|-
| [[Trapezoid]] (where &lt;math&gt;a&lt;/math&gt; and &lt;math&gt;b&lt;/math&gt; are the bases) || &lt;math&gt;A = \frac{a + b}{2} h&lt;/math&gt; || 
|}
:Sources:&lt;ref&gt;{{cite web |url=http://www.austincc.edu/tutor/students/resources/Geometry.pdf |title=Archived copy |accessdate=2011-11-29 |deadurl=yes |archiveurl=https://web.archive.org/web/20120813015606/http://www.austincc.edu/tutor/students/resources/Geometry.pdf |archivedate=2012-08-13 |df= }}&lt;/ref&gt;&lt;ref&gt;http://www.math.com/tables/geometry/areas.htm&lt;/ref&gt;

== Three-dimensional shapes ==
{| class="wikitable"
|-
! Shape !! [[Volume]] !! Surface area
|-
| [[Cube]] (where &lt;math&gt;s&lt;/math&gt; is the length of a side) || &lt;math&gt;V=s^3&lt;/math&gt; || &lt;math&gt;6s^2&lt;/math&gt;
|-
| Rectangular [[Prism (geometry)|Prism]] (&lt;math&gt;l&lt;/math&gt; = length, &lt;math&gt;h&lt;/math&gt; = height, &lt;math&gt;w&lt;/math&gt; = width) || &lt;math&gt;V = lwh&lt;/math&gt; || &lt;math&gt;S = 2lw + 2lh + 2wh&lt;/math&gt;
|-
| [[Sphere]] (where &lt;math&gt;r&lt;/math&gt; is the radius) || &lt;math&gt;V = \frac{4\pi r^3}{3}&lt;/math&gt; || &lt;math&gt;S = 4\pi r^2&lt;/math&gt;
|-
| Right circular cylinder (where &lt;math&gt;r&lt;/math&gt; is the radius and &lt;math&gt;h&lt;/math&gt; is the height) || &lt;math&gt;V = \pi r^2h&lt;/math&gt; || &lt;math&gt;S = 2\pi rh + 2\pi r^2&lt;/math&gt;
|}
:Sources:&lt;ref&gt;http://www.math.com/tables/geometry/volumes.htm&lt;/ref&gt;

==References==
{{reflist}}

{{DEFAULTSORT:Formulas in elementary geometry}}
[[Category:Elementary geometry|*]]
[[Category:Mathematics-related lists]]</text>
      <sha1>904kqyenv6aumks2sys1v5blyftj4sz</sha1>
    </revision>
  </page>
  <page>
    <title>Logic optimization</title>
    <ns>0</ns>
    <id>7457346</id>
    <revision>
      <id>870853771</id>
      <parentid>846254744</parentid>
      <timestamp>2018-11-27T12:02:33Z</timestamp>
      <contributor>
        <username>Jakub Tětek</username>
        <id>28860976</id>
      </contributor>
      <comment>Fixing an ambiguous statement</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32007">{{other uses|Minimisation (disambiguation){{!}}Minimisation}}
'''Logic optimization''', a part of [[logic synthesis]] in [[electronics]], is the process of finding an equivalent representation of the specified [[logic circuit]] under one or more specified constraints. Generally the circuit is constrained to minimum chip area meeting a prespecified delay.

==Introduction==
With the advent of [[logic synthesis]], one of the biggest challenges faced by the [[electronic design automation]] (EDA) industry was to find the best [[netlist]] representation of the given design description. While [[two-level logic optimization]] had long existed in the form of the [[Quine–McCluskey algorithm]], later followed by the [[Espresso heuristic logic minimizer]], the rapidly improving chip densities, and the wide adoption of [[Hardware description language|HDLs]] for circuit description, formalized the logic optimization domain as it exists today.

Today, logic optimization is divided into various categories:

'''Based on circuit representation''' 
* Two-level logic optimization
* Multi-level logic optimization

'''Based on circuit characteristics'''
* Sequential logic optimization
* Combinational logic optimization

'''Based on type of execution'''
*Graphical optimization methods
*Tabular optimization methods
*Algebraic optimization methods

While a [[two-level circuit representation]] of circuits strictly refers to the flattened view of the circuit in terms of SOPs ([[Canonical form (Boolean algebra)|sum-of-products]]) &amp;mdash; which is more applicable to a [[Programmable logic array|PLA]] implementation of the design{{Clarify|date=February 2010}} &amp;mdash; a [[multi-level representation]] is a more generic view of the circuit in terms of arbitrarily connected SOPs, POSs ([[Canonical form (Boolean algebra)|product-of-sums]]), factored form etc. Logic optimization algorithms generally work either on the structural (SOPs, factored form) or functional ([[Binary decision diagram|BDDs]], ADDs) representation of the circuit.{{Clarify|date=February 2010}}

==Two-level versus multi-level representations==
If we have two functions ''F''&lt;sub&gt;1&lt;/sub&gt; and ''F''&lt;sub&gt;2&lt;/sub&gt;:

: &lt;math&gt;F_1 = AB + AC + AD,\,&lt;/math&gt;

: &lt;math&gt;F_2 = A'B + A'C + A'E.\,&lt;/math&gt;

The above 2-level representation takes six product terms and 24 transistors in CMOS Rep.{{Why|date=February 2010}}

A functionally equivalent representation in multilevel can be:

: ''P'' = ''B'' + ''C''.

: ''F''&lt;sub&gt;1&lt;/sub&gt; = ''AP'' + ''AD''.

: ''F''&lt;sub&gt;2&lt;/sub&gt; = ''A&lt;nowiki&gt;'&lt;/nowiki&gt;P'' + ''A&lt;nowiki&gt;'&lt;/nowiki&gt;E''.

While the number of levels here is 3, the total number of product terms and literals reduce {{Quantify|date=February 2010}} because of the sharing of the term B + C.

Similarly, we distinguish between [[Sequential logic|sequential]] and [[Combinational logic|combinational circuits]], whose behavior can be described in terms of [[finite-state machine]] state tables/diagrams or by Boolean functions and relations respectively.{{Clarify|date=February 2010}}

==Circuit minimization in Boolean algebra==
In [[Boolean algebra (logic)|Boolean algebra]], '''circuit minimization''' is the problem of obtaining the smallest [[logic circuit]] (Boolean formula) that represents a given [[Boolean function]] or [[truth table]].  For the case when the boolean function is specified by a circuit (that is, we want to find an equivalent circuit of minimum size possible), the unbounded circuit minimization problem was long-conjectured to be [[polynomial hierarchy|&lt;math&gt;\Sigma_2^P&lt;/math&gt;-complete]], a result finally proved in 2008,&lt;ref name="Buchfuhrer_2011"/&gt; but there are effective heuristics such as [[Karnaugh map]]s and the [[Quine–McCluskey algorithm]] that facilitate the process.

===Purpose===
The problem with having a complicated [[Electronic circuit|circuit]] (i.e. one with many elements, such as [[logic gate]]s) is that each element takes up physical space in its implementation and costs time and money to produce in itself. Circuit minimization may be one form of logic optimization used to reduce the area of complex logic in [[integrated circuit]]s.

===Example===
While there are many ways to minimize a circuit, this is an example that minimizes (or simplifies) a boolean function. Note that the boolean function carried out by the circuit is directly related to the algebraic expression from which the function is implemented.&lt;ref name="Mano_2014"/&gt;
Consider the circuit used to represent &lt;math&gt;(A \wedge \bar{B}) \vee (\bar{A} \wedge B)&lt;/math&gt;. It is evident that two negations, two conjunctions, and a disjunction are used in this statement. This means that to build the circuit one would need two [[Inverter (logic gate)|inverters]], two [[AND gate]]s, and an [[OR gate]].

We can simplify (minimize) the circuit by applying logical identities or using intuition. Since the example states that A is true when B is false or the other way around, we can conclude that this simply means &lt;math&gt;A \neq B&lt;/math&gt;. In terms of logical gates, [[inequality (mathematics)|inequality]] simply means an [[XOR gate]] (exclusive or). Therefore, &lt;math&gt;(A \wedge \bar{B}) \vee (\bar{A} \wedge B) \iff A \neq B&lt;/math&gt;. Then the two circuits shown below are equivalent:

[[File:Circuit-minimization.svg]]

You can additionally check the correctness of the result using a [[truth table]].

=={{anchor|Harvard|Svoboda|Händler|Kortum}}Graphical two-level logic minimization methods==
Graphical minimization methods for two-level logic include:
* ''[[Marquand diagram]]'' (1881) by [[Allan Marquand]] (1853–1924)&lt;ref name="Marquand_1881"/&gt;&lt;ref name="Brown_2012"/&gt;&lt;!-- a precursor to Karnaugh maps, needs to be covered explicitly inhere or in a separate article - until then parked here for completeness --&gt;
* ''[[Harvard minimizing chart]]'' (1951) by [[Howard H. Aiken]] and Martha L. Whitehouse of the [[Harvard Computation Laboratory]]&lt;ref name="Aiken_1952"/&gt;&lt;ref name="Karnaugh_1953"/&gt;&lt;ref name="Phister_1959"/&gt;&lt;ref name="Curtis_1962"/&gt;
* ''[[Veitch chart]]'' (1952) by [[Edward Veitch]] (1924–2013)&lt;ref name="Veitch_1952"/&gt;&lt;ref name="Brown_2012"/&gt;&lt;!-- a precursor to Karnaugh maps, needs to be covered explicitly inhere or in a separate article - until then parked here for completeness --&gt;
* ''[[Karnaugh map]]'' (1953) by [[Maurice Karnaugh]] (1924–)&lt;ref name="Karnaugh_1953"/&gt;&lt;ref name="Curtis_1962"/&gt;
* Svoboda's graphical aids (1956) and ''[[triadic map]]'' by [[Antonín Svoboda (computer scientist)|Antonín Svoboda]] (1907–1980)&lt;ref name="Svoboda_1956_1"/&gt;&lt;ref name="Svoboda_1956_2"/&gt;&lt;ref name="Steinbuch-Weber_1974"/&gt;&lt;ref name="Svoboda_1979"/&gt;
* ''[[Händler circle graph]]'' (aka &lt;!-- Händler-circle graph, Handler-circle graph, --&gt;{{lang|de|Händler'scher Kreisgraph}}, {{lang|de|Kreisgraph nach Händler}}, {{lang|de|Händler-Kreisgraph}}, {{lang|de|Händler-Diagramm}}, ''{{sic|{{lang|de|Minimisierungsgraph}}|expected={{lang|de|Minimierungsgraph}}}}'') (1958) by [[Wolfgang Händler]] (1920–1998)&lt;ref name="Händler_1958"/&gt;&lt;ref name="Colloquium_1960"/&gt;&lt;ref name="Steinbuch-Wagner_1967"/&gt;&lt;ref name="Steinbuch-Weber_1974"/&gt;&lt;ref name="Hotz_1974"/&gt;&lt;ref name="ISER_1"/&gt;&lt;ref name="ISER_2"/&gt;&lt;ref name="Broy_1990"/&gt;&lt;ref name="Bauer-Wirsing_1991"/&gt;
*Graph method (1965) by {{ill|Herbert Kortum|de}} (1907–1979)&lt;ref name="Kortum_1964_12"/&gt;&lt;ref name="Kortum_1965_1"/&gt;&lt;ref name="Kortum_1965_3"/&gt;&lt;ref name="Kortum_1965_5"/&gt;&lt;ref name="Kortum_1967_6"/&gt;&lt;ref name="Kortum_1966_12"/&gt;&lt;ref name="Tafel_1971"/&gt;

== See also ==
* [[Binary decision diagram]]
* [[Circuit minimization]]
* [[Espresso heuristic logic minimizer]]
* [[Karnaugh map]]
* [[Petrick's method]]
* [[Prime implicant]]
* [[Circuit complexity]]
* [[Function composition]]
* [[Function decomposition]]
* [[Circuit underutilization|Gate underutilization]]

== References ==
{{reflist|refs=
&lt;ref name="Buchfuhrer_2011"&gt;{{cite journal |doi=10.1016/j.jcss.2010.06.011 |title=The complexity of Boolean formula minimization |journal=[[Journal of Computer and System Sciences]] (JCSS) |volume=77 |issue=1 |pages=142–153 |date=January 2011 |location=Computer Science Department, [[California Institute of Technology]], Pasadena, CA, USA |author-last1=Buchfuhrer |author-first1=David |author-last2=Umans |author-first2=Christopher |author-link2=Christopher Umans |publisher=[[Elsevier Inc.]] |url=https://ac.els-cdn.com/S0022000010000954/1-s2.0-S0022000010000954-main.pdf?_tid=045f1450-f937-11e7-ae63-00000aab0f26&amp;acdnat=1515940215_dae38335610ea5f94fd299e5e7c95ffb}} This is an extended version of the conference paper: {{cite book |doi=10.1007/978-3-540-70575-8_3 |chapter=The Complexity of Boolean Formula Minimization |title=Proceedings of Automata, Languages and Programming |location=35th International Colloquium (ICALP) |volume=5125 |pages=24–35 |publisher=[[Springer-Verlag]] |publication-place=Berlin / Heidelberg, Germany |series=[[Lecture Notes in Computer Science]] (LNCS) |date=2008 |author-last1=Buchfuhrer |author-first1=David |author-last2=Umans |author-first2=Christopher |author-link2=Christopher Umans |isbn=978-3-540-70574-1 |url=http://users.cms.caltech.edu/~umans/papers/BU07.pdf |access-date=2018-01-14 |dead-url=no |archive-url=https://web.archive.org/web/20180114141842/http://users.cms.caltech.edu/~umans/papers/BU07.pdf |archive-date=2018-01-14}}&lt;/ref&gt;
&lt;ref name="Mano_2014"&gt;{{cite book |author-first1=M. Morris |author-last1=Mano |author-first2=Charles R. |author-last2=Kime |title=Logic and Computer Design Fundamentals |edition=4th new international |publisher=[[Pearson Education Limited]] |date=2014 |page=54 |isbn=978-1-292-02468-4}}&lt;/ref&gt;
&lt;ref name="Aiken_1952"&gt;{{cite book |title=Synthesis of electronic computing and control circuits |orig-year=January 1951 |date=1952 |edition=second printing, revised |chapter=Chapter V: Minimizing charts |pages=preface, 50–67 |author-first1=Howard H. |author-last1=Aiken |author-link1=Howard H. Aiken |author-first2=Gerrit |author-last2=Blaauw |author-link2=Gerrit Blaauw |author-first3=William |author-last3=Burkhart |author-first4=Robert J. |author-last4=Burns |author-first5=Lloyd |author-last5=Cali |author-first6=Michele |author-last6=Canepa |author-first7=Carmela M. |author-last7=Ciampa |author-first8=Charles A. |author-last8=Coolidge, Jr. |author-first9=Joseph R. |author-last9=Fucarile |author-first10=J. Orten |author-last10=Gadd, Jr. |author-first11=Frank F. |author-last11=Gucker |author-first12=John A. |author-last12=Harr |author-first13=Robert L. |author-last13=Hawkins |author-first14=Miles V. |author-last14=Hayes |author-first15=Richard |author-last15=Hofheimer |author-first16=William F. |author-last16=Hulme |author-first17=Betty L. |author-last17=Jennings |author-first18=Stanley A. |author-last18=Johnson |author-first19=Theodore |author-last19=Kalin |author-first20=Marshall |author-last20=Kincaid |author-first21=E. Edward |author-last21=Lucchini |author-first22=William |author-last22=Minty |author-first23=Benjamin L. |author-last23=Moore |author-first24=Joseph |author-last24=Remmes |author-first25=Robert J. |author-last25=Rinn |author-first26=John W. |author-last26=Roche |author-first27=Jacquelin |author-last27=Sanbord |author-first28=Warren L. |author-last28=Semon |author-first29=Theodore |author-last29=Singer |author-first30=Dexter |author-last30=Smith |author-first31=Leonard |author-last31=Smith |author-first32=Peter F. |author-last32=Strong |author-first33=Helene V. |author-last33=Thomas |author-first34=An |author-last34=Wang |author-link34=An Wang |author-first35=Martha L. |author-last35=Whitehouse |author-first36=Holly B. |author-last36=Wilkins |author-first37=Robert E. |author-last37=Wilkins |author-first38=Way Dong |author-last38=Woo |author-first39=Elbert P. |author-last39=Little |author-first40=M. Scudder |author-last40=McDowell |location=Write-Patterson Air Force Base |publisher=[[Harvard University Press]] (Cambridge, Massachusetts, USA) / Geoffrey Cumberlege Oxford University Press (London) |url=https://archive.org/stream/in.ernet.dli.2015.509288/2015.509288.Synthesis-Of#page/n6/mode/1up |access-date=2017-04-16 |quote=[…] Martha Whitehouse constructed the minimizing charts used so profusely throughout this book, and in addition prepared minimizing charts of seven and eight variables for experimental purposes. […] Hence, the present writer is obliged to record that the general algebraic approach, the switching function, the vacuum-tube operator, and the minimizing chart are his proposals, and that he is responsible for their inclusion herein. […]}} (NB. Work commenced in April 1948.)&lt;/ref&gt;
&lt;ref name="Phister_1959"&gt;{{cite book |title=Logical design of digital computers |author-first=Montgomery |author-last=Phister, Jr. |publisher=[[John Wiley &amp; Sons Inc.]] |date=1959 |orig-year=December 1958 |location=New York, USA |isbn=0471688053&lt;!-- |id={{ISBN|978-0471688051}}? --&gt; |pages=75–83 |url=https://archive.org/stream/in.ernet.dli.2015.74854/2015.74854.Logical-Design-Of-Digital-Computers#page/n0/mode/1up}}&lt;/ref&gt;
&lt;ref name="Curtis_1962"&gt;{{cite book |title=A new approach to the design of switching circuits |author-first=H. Allen |author-last=Curtis |publisher=[[D. van Nostrand Company, Inc.]] |date=1962 |location=Princeton, New Jersey, USA |series=The Bell Laboratories Series}}&lt;/ref&gt;
&lt;ref name="Karnaugh_1953"&gt;{{cite journal |author-last=Karnaugh |author-first=Maurice |author-link=Maurice Karnaugh |title=The Map Method for Synthesis of Combinational Logic Circuits |journal=[[Transactions of the American Institute of Electrical Engineers]] part I |volume=72 |issue=9 |pages=593–599 |date=November 1953 |orig-year=1953-04-23&lt;!-- available for printing --&gt;, 1953-03-17&lt;!-- sent in --&gt; |id=Paper 53-217 |doi=10.1109/TCE.1953.6371932 |url=http://philectrosophy.com/documents/The%20Map%20Method%20For%20Synthesis%20of.pdf |access-date=2017-04-16 |dead-url=no |archive-url=https://web.archive.org/web/20170416232229/http://philectrosophy.com/documents/The%20Map%20Method%20For%20Synthesis%20of.pdf |archive-date=2017-04-16}} (NB. Also contains a short review by [[Samuel H. Caldwell]].)&lt;/ref&gt;
&lt;ref name="Brown_2012"&gt;{{cite book |title=Boolean Reasoning - The Logic of Boolean Equations |author-first=Frank Markham |author-last=Brown |edition=&lt;!-- 2012 --&gt;reissue of 2nd |publisher=[[Dover Publications, Inc.]] |location=Mineola, New York |date=2012 |orig-year=2003, 1990 |isbn=978-0-486-42785-0 |id={{ISBN|0-486-42785-4}}}} [&lt;!-- 1st edition --&gt;http://www2.fiit.stuba.sk/~kvasnicka/Free%20books/Brown_Boolean%20Reasoning.pdf&lt;!-- https://web.archive.org/web/20170416231752/http://www2.fiit.stuba.sk/~kvasnicka/Free%20books/Brown_Boolean%20Reasoning.pdf --&gt;]&lt;/ref&gt;
&lt;ref name="Marquand_1881"&gt;{{cite journal |title=XXXIII: On Logical Diagrams for ''n'' terms |author-first=Allan |author-last=Marquand |author-link=Allan Marquand |journal=[[The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science]] |issue=75 |series=5 |date=1881 |volume=12 |doi=10.1080/14786448108627104 |pages=266–270 |url=http://www.tandfonline.com/doi/abs/10.1080/14786448108627104 |access-date=2017-05-15}} (NB. Quite many secondary sources erroneously cite this work as "A logical diagram for ''n'' terms" or "On a logical diagram for ''n'' terms".)&lt;/ref&gt;
&lt;ref name="Veitch_1952"&gt;{{cite journal |author-last=Veitch |author-first=Edward W. |author-link=Edward Veitch |title=A Chart Method for Simplifying Truth Functions |journal=ACM Annual Conference/Annual Meeting: Proceedings of the 1952 ACM Annual Meeting (Pittsburg) |publisher=[[Association for Computing Machinery|ACM]] |location=New York, USA |pages=127–133 |date=1952-05-03 |orig-year=1952-05-02 |doi=10.1145/609784.609801}}&lt;/ref&gt;
&lt;ref name="Svoboda_1956_1"&gt;{{cite book |title=Graficko-mechanické pomůcky užívané při analyse a synthese kontaktových obvodů |trans-title=Utilization of graphical-mechanical aids for the analysis and synthesis of contact circuits |journal=Stroje na zpracování informací [Symphosium IV on information processing machines] |author-first=Antonín |author-last=Svoboda |author-link=Antonín Svoboda (computer scientist) |location=Prague |publisher=Czechoslovak Academy of Sciences, Research Institute of Mathematical Machines |language=Czech |date=1956 |volume=IV |pages=9–21}}&lt;/ref&gt;
&lt;ref name="Svoboda_1956_2"&gt;{{cite book |title=Graphical Mechanical Aids for the Synthesis of Relay Circuits |journal=Nachrichtentechnische Fachberichte (NTF), Beihefte der Nachrichtentechnischen Zeitschrift (NTZ) |publisher=[[Vieweg-Verlag]] |location=Braunschweig, Germany |author-first=Antonín |author-last=Svoboda |author-link=Antonín Svoboda (computer scientist) |date=1956}}&lt;/ref&gt;
&lt;ref name="Svoboda_1979"&gt;{{cite book |title=Advanced Logical Circuit Design Techniques |author-first1=Antonín |author-last1=Svoboda |author-link1=Antonín Svoboda (computer scientist) |author-first2=Donnamaie E. |author-last2=White |date=2016 |orig-year=1979-08-01 |edition=retyped electronic reissue |publisher=[[Garland STPM Press]] (original issue) / WhitePubs (reissue) |isbn=0-8240-7014-3&lt;!-- 1990 1st issue --&gt; |id={{ISBN|978-0-8240-7014-4}}&lt;!-- 1990 1st issue --&gt; |url=http://www.donnamaie.com/Advanced_logic_ckt/Advanced_Logical_Circuit_Design_Techniques%20sm.pdf |access-date=2017-04-15 |dead-url=no |archive-url=https://web.archive.org/web/20160315001009/http://donnamaie.com/Advanced_logic_ckt/Advanced_Logical_Circuit_Design_Techniques%20sm.pdf |archive-date=2016-03-15}} [http://www.donnamaie.com/&lt;!-- https://web.archive.org/web/20170415220158/http://www.donnamaie.com/ --&gt;] [https://books.google.com/books?id=g3uzAAAAIAAJ]&lt;/ref&gt;
&lt;ref name="Händler_1958"&gt;{{cite book |title=Ein Minimisierungsverfahren zur Synthese von Schaltkreisen (Minimisierungsgraphen) |language=German |author-first=Wolfgang |author-last=Händler |author-link=Wolfgang Händler |publisher=[[Technische Hochschule Darmstadt]] |date=1958 |id=D&amp;nbsp;17 |type=Dissertation |url=https://books.google.com/books?id=D58TAQAAIAAJ}} [https://www.tib.eu/de/suchen/id/TIBKAT%3A044782241/Ein-Minimisierungsverfahren-zur-Synthese-von-Schaltkreisen/] (NB. Although written by a German, the title contains an [[anglicism]]; the correct German term would be "Minimierung" instead of "Minimisierung".)&lt;/ref&gt;
&lt;ref name="Hotz_1974"&gt;{{cite book |title=Schaltkreistheorie |language=German |trans-title=Switching circuit theory |author-first=Günter |author-last=Hotz |publisher=[[Walter de Gruyter &amp; Co.]] |series=DeGruyter Lehrbuch |date=1974 |isbn=3-11-00-2050-5 |page=117 |quote=[…] Der Kreisgraph von ''[[Wolfgang Händler|Händler]]'' ist für das Auffinden von [[prime implicant|Primimplikanten]] gut brauchbar. Er hat den Nachteil, daß er schwierig zu zeichnen ist. Diesen Nachteil kann man allerdings durch die Verwendung von Schablonen verringern. […] [The circle graph by ''Händler'' is well suited to find [[prime implicant]]s. A disadvantage is that it is difficult to draw. This can be remedied using stencils.]}}&lt;/ref&gt;
&lt;ref name="ISER_1"&gt;{{cite web |title=Informatik Sammlung Erlangen (ISER) |date=2012-03-13 |publisher=[[Friedrich-Alexander Universität]] |location=Erlangen, Germany |language=German |url=https://www.rrze.fau.de/wir-ueber-uns/kooperationen/iser.shtml |access-date=2017-04-12 |dead-url=yes |archive-url=https://web.archive.org/web/20170516154655/https://www.rrze.fau.de/wir-ueber-uns/kooperationen/iser.shtml |archive-date=2017-05-16}} (NB. Shows a picture of a {{lang|de|Kreisgraph}} by ''[[Wolfgang Händler|Händler]]''.)&lt;/ref&gt;
&lt;ref name="ISER_2"&gt;{{cite web |title=Informatik Sammlung Erlangen (ISER) - Impressum |date=2012-03-13 |publisher=[[Friedrich-Alexander Universität]] |location=Erlangen, Germany |language=German |url=http://www.iser.uni-erlangen.de:80/index.php?ort_id=327&amp;tree=0 |access-date=2017-04-15 |dead-url=no |archive-url=https://web.archive.org/web/20120226004316/http://www.iser.uni-erlangen.de/index.php?ort_id=327&amp;tree=0 |archive-date=2012-02-26}} (NB. Shows a picture of a {{lang|de|Kreisgraph}} by ''[[Wolfgang Händler|Händler]]''.)&lt;/ref&gt;
&lt;ref name="Broy_1990"&gt;{{cite book |title=Informatik und Mathematik |language=German |trans-title=Computer Sciences and Mathematics |chapter=Geschichte der Schaltalgebra |trans-chapter=History of circuit switching algebra |author-first=Heinz |author-last=Zemanek |author-link=Heinz Zemanek |editor-first=Manfred |editor-last=Broy |editor-link=Manfred Broy |orig-year=1990 |date=2013 |publisher=[[Springer-Verlag]] |isbn=9783642766770 |id={{ISBN|3642766773}} |pages=43–72 |url=https://books.google.com/books?id=y5GfBgAAQBAJ |quote=Einen Weg besonderer Art, der damals zu wenig beachtet wurde, wies [[Wolfgang Händler|W. Händler]] in seiner Dissertation […] mit einem Kreisdiagramm. […]}} [https://link.springer.com/chapter/10.1007%2F978-3-642-76677-0_3] (NB. Collection of papers at a colloquium held at the [[Bayerische Akademie der Wissenschaften]],
1989-06-12/14, in honor of [[Friedrich L. Bauer]].)&lt;/ref&gt;
&lt;ref name="Bauer-Wirsing_1991"&gt;{{cite book |author-first1=Friedrich Ludwig |author-last1=Bauer |author-link1=Friedrich Ludwig Bauer |author-first2=Martin |author-last2=Wirsing |author-link2=Martin Wirsing |title=Elementare Aussagenlogik |publisher=[[Springer-Verlag]] |language=German |location=Berlin / Heidelberg |date=March 1991 |isbn=3-540-52974-8 |id={{ISBN|978-3-540-52974-3}} |pages=54–56, 71, 112–113, 138–139 |url=https://books.google.com/books?id=Ff58BwAAQBAJ |quote=[…] handelt es sich um ein [[Wolfgang Händler|Händler]]-Diagramm […], mit den Würfelecken als Ecken eines 2&lt;sup&gt;m&lt;/sup&gt;-gons. […] Abb. […] zeigt auch Gegenstücke für andere Dimensionen. Durch waagerechte Linien sind dabei Tupel verbunden, die sich nur in der ersten Komponente unterscheiden; durch senkrechte Linien solche, die sich nur in der zweiten Komponente unterscheiden; durch 45°-Linien und 135°-Linien solche, die sich nur in der dritten Komponente unterscheiden usw. Als Nachteil der Händler-Diagramme wird angeführt, daß sie viel Platz beanspruchen. […]}}&lt;/ref&gt;
&lt;ref name="Colloquium_1960"&gt;{{cite book |editor-first1=Ernst Ferdinand |editor-last1=Peschl |editor-link1=Ernst Ferdinand Peschl |editor-first2=Heinz |editor-last2=Unger |editor-link2=:de:Heinz Unger (Mathematiker) |title=Colloquium über Schaltkreis- und Schaltwerk-Theorie - Vortragsauszüge vom 26. bis 28. Oktober 1960 in Bonn - Band 3 von Internationale Schriftenreihe zur Numerischen Mathematik [International Series of Numerical Mathematics] (ISNM) |language=German |volume=3 |chapter=Zum Gebrauch von Graphen in der Schaltkreis- und Schaltwerktheorie |author-first=Wolfgang |author-last=Händler |author-link=Wolfgang Händler |location=Institut für Angewandte Mathematik, [[Universität Saarbrücken]], Rheinisch-Westfälisches Institut für Instrumentelle Mathematik |publisher=[[Springer Basel AG]] / [[Birkhäuser Verlag Basel]] |date=2013 |orig-year=1961 |isbn=978-3-0348-5771-0 |id={{ISBN|3-0348-5771-3}} |doi=10.1007/978-3-0348-5770-3 |url=https://books.google.com/books?id=myTnoAEACAAJ |pages=169–198}} [https://link.springer.com/chapter/10.1007%2F978-3-0348-5770-3_10]&lt;/ref&gt;
&lt;ref name="Kortum_1964_12"&gt;{{cite journal |title=Minimierung von Kontaktschaltungen durch Kombination von Kürzungsverfahren und Graphenmethoden |trans-title=Minimization of contact circuits by combination of reduction procedures and graphical methods |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1965 |volume=8 |issue=12 |pages=421–425 |issn=0026-0347 |id={{CODEN|MSRGAN}} |url=https://www.tib.eu/en/search/id/ceaba%3ACEAB1966001170/MINIMIERUNG-VON-KONTAKTSCHALTUNGEN-DURCH-KOMBINATION/}} [https://www.tib.eu/en/search/id/ei-backfile%3Ac84_64eb63f914c231eeM6f1319817173212/Minimization-of-contact-circuits-by-combination/]&lt;/ref&gt;
&lt;ref name="Kortum_1965_1"&gt;{{cite journal |title=Konstruktion und Minimierung von Halbleiterschaltnetzwerken mittels Graphentransformation |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1966 |volume=9 |issue=1 |pages=9–12 |issn=0026-0347 |id={{CODEN|MSRGAN}} |url=https://www.tib.eu/en/search/id/ceaba%3ACEAB1966002519/KONSTRUKTION-UND-MINIMIERUNG-VON-HALBLEITER-SCHALTNETZWERKEN/}}&lt;/ref&gt;
&lt;ref name="Kortum_1965_3"&gt;{{cite journal |title=Weitere Bemerkungen zur Minimierung von Schaltnetzwerken mittels Graphenmethoden |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1966 |volume=9 |issue=3 |pages=96–102 |issn=0026-0347 |id={{CODEN|MSRGAN}} |url=https://www.tib.eu/en/search/id/ceaba%3ACEAB1966002896/WEITERE-BEMERKUNGEN-ZUR-MINIMIERUNG-VON-SCHALTNETZWERKEN/}}&lt;/ref&gt;
&lt;ref name="Kortum_1965_5"&gt;{{cite journal |title=Weitere Bemerkungen zur Behandlung von Schaltnetzwerken mittels Graphen. Konstruktion von vermaschten Netzwerken (Brückenschaltungen) |trans-title=Further remarks on treatment of switching networks by means of graphs |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1966 |volume=9 |issue=5 |pages=151–157 |issn=0026-0347 |id={{CODEN|MSRGAN}}}} {{cite journal |title=Weitere Bemerkungen zur Behandlung von Schaltnetzwerken mittels Graphen |trans-title=Further remarks on treatment of switching networks by means of graphs |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=Regelungstechnik |language=German |publisher= |date=1965 |volume=10 |issue=5 |pages=33–39 |location=10. Internationales Wissenschaftliches Kolloquium, Ilmenau. Technische Hochschule |url=https://www.tib.eu/en/search/id/ei-backfile%3Ac84_a3574af8cb8d6293M72eb19817173212/Further-remarks-on-treatment-of-switching-networks/}}&lt;/ref&gt;
&lt;ref name="Kortum_1966_12"&gt;{{cite journal |title=Zur Minimierung von Schaltsystemen |trans-title=Minimization of switching circuits |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=Wissenschaftliche Zeitschrift der TU Ilmenau |location=Jena |language=German |publisher=Technische Hochschule für Elektrotechnik Ilmenau / Forschungsstelle für Meßtechnik und Automatisierung der Deutschen Akademie der Wissenschaften |date=1966&lt;!-- one source states: 1965 --&gt; |volume=12 |issue=2&lt;!-- one sources states: 2, 3. --&gt; |pages=181–186 |url=https://www.tib.eu/en/search/id/ei-backfile%3Ac84_125e37df8f0a3cd4eM7a8919817173212/Minimization-of-switching-circuits/}}&lt;/ref&gt;
&lt;ref name="Kortum_1967_6"&gt;{{cite journal |title=Über zweckmäßige Anpassung der Graphenstruktur diskreter Systeme an vorgegebene Aufgabenstellungen |author-first=Herbert |author-last=Kortum |author-link=:de:Herbert Kortum |journal=messen-steuern-regeln (msr) |language=German |publisher={{ill|Verlag Technik|de}} |date=1967 |volume=10 |issue=6 |pages=208–211 |issn=0026-0347 |id={{CODEN|MSRGAN}}}}&lt;/ref&gt;
&lt;ref name="Tafel_1971"&gt;{{cite book |title=Einführung in die digitale Datenverarbeitung |language=German |trans-title=Introduction to digital information processing |chapter=4.3.5. Graphenmethode zur Vereinfachung von Schaltfunktionen |author-first=Hans Jörg |author-last=Tafel |publisher=[[Carl Hanser Verlag]] |date=1971 |location=[[RWTH]], Aachen, Germany |publication-place=Munich, Germany |isbn=3-446-10569-7 |pages=98–105, 107–113}}&lt;/ref&gt;
&lt;ref name="Steinbuch-Wagner_1967"&gt;{{cite book |title=Taschenbuch der Nachrichtenverarbeitung |language=German |editor-first1=Karl W. |editor-last1=Steinbuch |editor-link1=Karl W. Steinbuch |editor-first2=Siegfried W. |editor-last2=Wagner |author-first1=Erich R. |author-last1=Berger |author-first2=Wolfgang |author-last2=Händler |author-link2=Wolfgang Händler |date=1967 |orig-year=1962 |edition=2 |publisher=[[Springer-Verlag OHG]] |location=Berlin, Germany |id=Title No. 1036 |lccn=67-21079 |pages=64, 1034–1035, 1036, 1038 |quote=[…] Übersichtlich ist die Darstellung nach ''[[Wolfgang Händler|Händler]]'', die sämtliche Punkte, numeriert nach dem ''[[Gray-Code]]'' […], auf dem Umfeld eines Kreises anordnet. Sie erfordert allerdings sehr viel Platz. […] [''Händler's'' illustration, where all points, numbered according to the ''[[Gray code]]'', are arranged on the circumference of a circle, is easily comprehensible. It needs, however, a lot of space.]}}&lt;/ref&gt;
&lt;ref name="Steinbuch-Weber_1974"&gt;{{cite book |title=Taschenbuch der Informatik - Band II - Struktur und Programmierung von EDV-Systemen |language=German |editor-first1=Karl W. |editor-last1=Steinbuch |editor-link1=Karl W. Steinbuch |editor-first2=Wolfgang |editor-last2=Weber |editor-first3=Traute |editor-last3=Heinemann |date=1974 |orig-year=1967 |edition=3 |volume=2 |work=Taschenbuch der Nachrichtenverarbeitung |publisher=[[Springer-Verlag]] |location=Berlin, Germany |isbn=3-540-06241-6 |lccn=73-80607 |pages=25, 62, 96, 122–123, 238}}&lt;/ref&gt;
}}

== Further reading ==
* {{cite book |title=Synthesis and Optimization of Digital Circuits |author-first=Giovanni |author-last=De Micheli |author-link=Giovanni De Micheli |date=1994 |publisher=[[McGraw-Hill]] |isbn=0-07-016333-2}} (NB. Chapters 7-9 cover combinatorial two-level, combinatorial multi-level, and respectively sequential circuit optimization.)
* {{cite book |author-first1=Gary D. |author-last1=Hachtel |author-first2=Fabio |author-last2=Somenzi |title=Logic Synthesis and Verification Algorithms |date=2006 |orig-year=1996 |publisher=[[Springer Science &amp; Business Media]] |isbn=978-0-387-31005-3}}
* {{cite book |author-first1=Zvi |author-last1=Kohavi |author-first2=Niraj K. |author-last2=Jha |title=Switching and Finite Automata Theory |edition=3rd |publisher=[[Cambridge University Press]] |date=2009 |isbn=978-0-521-85748-2 |chapter=4–6}}
* {{cite book |title=The Art of Computer Programming |title-link=The Art of Computer Programming |date=2010 |author-last=Knuth |author-first=Donald Ervin |author-link=Donald Ervin Knuth |volume=4A |chapter=chapter 7.1.2: Boolean Evaluation |publisher=[[Addison-Wesley]] |pages=96–133 |isbn=0-201-03804-8}}
* {{cite book |author-first=Rob A. |author-last=Rutenbar |title=Multi-level minimization, Part I: Models &amp; Methods |type=lecture slides |publisher=[[Carnegie Mellon University]] (CMU) |id=Lecture 7 |url=https://www.ece.cmu.edu/~ee760/760docs/lec07.pdf |access-date=2018-01-15 |dead-url=no |archive-url=https://web.archive.org/web/20180115125725/https://www.ece.cmu.edu/~ee760/760docs/lec07.pdf |archive-date=2018-01-15}}; {{cite book |author-first=Rob A. |author-last=Rutenbar |title=Multi-level minimization, Part II: Cube/Cokernel Extract |type=lecture slides |publisher=[[Carnegie Mellon University]] (CMU) |id=Lecture 8 |url=https://www.ece.cmu.edu/~ee760/760docs/lec08.pdf |access-date=2018-01-15 |dead-url=no |archive-url=https://web.archive.org/web/20180115125733/https://www.ece.cmu.edu/~ee760/760docs/lec08.pdf |archive-date=2018-01-15}}
* {{cite journal |url=http://matwbn.icm.edu.pl/ksiazki/amc/amc13/amc13414.pdf |author-last1=Tomaszewski |author-first1=Sebastian P. |author-last2=Celik |author-first2=Ilgaz U. |author-last3=Antoniou |author-first3=George E. |title=WWW-based Boolean function minimization |journal=[[International Journal of Applied Mathematics and Computer Science]] |volume=13 |issue=part 4 |pages=577–584 |date=2003 |access-date=2018-01-15 |dead-url=no |archive-url=https://archive.is/20180115131301/http://matwbn.icm.edu.pl/ksiazki/amc/amc13/amc13414.pdf |archive-date=2018-01-15}}

{{digital electronics}}

[[Category:Electronic engineering]]
[[Category:Electronic design]]
[[Category:Digital electronics]]
[[Category:Electronic design automation]]
[[Category:Electronics optimization]]
[[Category:Boolean algebra]]
[[Category:Circuit complexity]]
[[Category:Logic in computer science]]</text>
      <sha1>r104p6nodz4jb9vk81x6wb1cykxzmzu</sha1>
    </revision>
  </page>
  <page>
    <title>MDS matrix</title>
    <ns>0</ns>
    <id>8288796</id>
    <revision>
      <id>805844804</id>
      <parentid>789271434</parentid>
      <timestamp>2017-10-18T00:25:14Z</timestamp>
      <contributor>
        <username>Cherkash</username>
        <id>10363</id>
      </contributor>
      <minor/>
      <comment>copyedit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3712">An '''MDS matrix''' ('''Maximum Distance Separable''') is a [[matrix (mathematics)|matrix]] representing a function with certain [[diffusion (cryptography)|diffusion]] properties that have useful applications in [[cryptography]]. Technically, an m&amp;times;n matrix A over a [[finite field]] K is an MDS matrix if it is the [[transformation matrix]] of a [[linear transformation]] f(x)=Ax from K&lt;sup&gt;n&lt;/sup&gt; to K&lt;sup&gt;m&lt;/sup&gt; such that no two different (m+n)-tuples of the form (x,f(x)) coincide in n or more components.
Equivalently, the set of all (m+n)-tuples (x,f(x)) is an [[Maximum distance separable code|MDS code]], i.e. a [[linear code]] that reaches the [[Singleton bound]].

Let &lt;math&gt;\tilde A = \left(\begin{array}{c}{\rm Id}_n\\  \hline{\rm A}\end{array}\right)&lt;/math&gt; be the matrix obtained by joining the [[identity matrix]] Id&lt;sub&gt;n&lt;/sub&gt; to A. Then a necessary and sufficient condition for a matrix A to be MDS is that every possible n&amp;times;n [[submatrix]] obtained by removing m rows from &lt;math&gt;\tilde A&lt;/math&gt; is [[non-singular matrix|non-singular]]. This is also equivalent to the following: all the sub-determinants of the matrix A are non-zero. Then a binary matrix A (namely over the field with two elements) is never MDS unless it has only one row or only one column with all components 1.

[[Reed–Solomon code]]s have the MDS property and are frequently used to obtain the MDS matrices used in cryptographic algorithms.

[[Serge Vaudenay]] suggested using MDS matrices in [[cryptographic primitive]]s to produce what he called ''multipermutations'', not-necessarily linear functions with this same property. These functions have what he called ''perfect diffusion'': changing t of the inputs changes at least m-t+1 of the outputs. He showed how to exploit imperfect diffusion to [[cryptanalysis|cryptanalyze]] functions that are not multipermutations.

MDS matrices are used for diffusion in such [[block cipher]]s as [[Advanced Encryption Standard|AES]], [[SHARK]], [[Square (cipher)|Square]], [[Twofish]], [[Anubis (cipher)|Anubis]], [[KHAZAD]], [[Manta (cipher)|Manta]], [[Hierocrypt]], [[Kalyna_(cipher)|Kalyna]] and [[Camellia (cipher)|Camellia]], and in the [[stream cipher]] [[MUGI]] and the [[cryptographic hash function]] [[Whirlpool (cryptography)|Whirlpool]].

== References ==
* {{ cite conference
     | authors = Serge Vaudenay
     | title = On the Need for Multipermutations: Cryptanalysis of MD4 and SAFER
     | conference = 2nd International Workshop on [[Fast Software Encryption]] (FSE '94)
     | pages = 286&amp;ndash;297
     | publisher = [[Springer-Verlag]]
     | date = November 16, 1994
     | location = [[Leuven]]
     | url = http://citeseer.ist.psu.edu/vaudenay94need.html
     | format = [[PDF]]/[[PostScript]]
     | accessdate = 2007-03-05 }}

* {{ cite conference
     | authors = [[Vincent Rijmen]], [[Joan Daemen]], [[Bart Preneel]], Anton Bosselaers, Erik De Win
     | title = The Cipher SHARK
     | conference = 3rd International Workshop on Fast Software Encryption (FSE '96)
     | pages = 99&amp;ndash;111
     | publisher = Springer-Verlag
     | date = February 1996
     | location = [[Cambridge]]
     | url = http://citeseer.ist.psu.edu/rijmen96cipher.html
     | format = PDF/PostScript
     | accessdate = 2007-03-06 }}

* {{ cite paper
     | authors = [[Bruce Schneier]], [[John Kelsey (cryptanalyst)|John Kelsey]], Doug Whiting, [[David A. Wagner|David Wagner]], Chris Hall, [[Niels Ferguson]]
     | title = The Twofish Encryption Algorithm
     | date = June 15, 1998
     | url = http://www.schneier.com/paper-twofish-paper.html
     | format = PDF/PostScript
     | accessdate = 2007-03-04 }}

{{crypto-stub}}

[[Category:Cryptography]]</text>
      <sha1>t7hhfkgpu60a2te2w5m36uvdmewnqkt</sha1>
    </revision>
  </page>
  <page>
    <title>Material derivative</title>
    <ns>0</ns>
    <id>668449</id>
    <revision>
      <id>865656620</id>
      <parentid>865656027</parentid>
      <timestamp>2018-10-25T09:54:20Z</timestamp>
      <contributor>
        <ip>144.48.37.78</ip>
      </contributor>
      <comment>(Sorry the edits I was referring to were not made by zedshort, they were made in 2014.)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12793">In [[continuum mechanics]], the '''material derivative'''&lt;ref name="BSLr2"/&gt;&lt;ref name=Batchelor&gt;{{cite book | first=G.K. | last=Batchelor | authorlink=George Batchelor | title=An Introduction to Fluid Dynamics | year=1967 | publisher=Cambridge University Press | isbn=0-521-66396-2 | pages=72–73}}&lt;/ref&gt; describes the time [[derivative|rate of change]] of some physical quantity (like [[heat]] or [[momentum]]) of a [[material element]] that is subjected to a space-and-time-dependent [[flow velocity|macroscopic velocity field]] variations of that physical quantity. The material derivative can serve as a link between [[Continuum mechanics#Eulerian description|Eulerian]] and [[Continuum mechanics#Lagrangian description|Lagrangian]] descriptions of continuum [[Deformation (mechanics)|deformation]].&lt;ref name=Trenberth&gt;{{cite book | first=K. E. | last=Trenberth | authorlink=Kevin_Trenberth | title=Climate System Modeling | year=1993 | publisher=Cambridge University Press | isbn=0-521-43231-6 | page=99 }}&lt;/ref&gt;

For example, in [[fluid dynamics]], the velocity field is the [[flow velocity]], and the quantity of interest might be the [[temperature]] of the fluid. In which case, the material derivative then describes the temperature change of a certain [[fluid parcel]] with time, as it flows along its [[Streamlines, streaklines, and pathlines|pathline]] (trajectory).
{{TOC right}}

==Names== &lt;!-- in bold, since the redirects lead to here --&gt;  

There are many other names for the material derivative, including:
*'''advective derivative'''&lt;ref&gt;{{cite book |title=Introduction to PDEs and Waves for the Atmosphere and Ocean | last=Majda |first=A. |author-link=Andrew Majda |isbn=0-8218-2954-8 |series=Courant Lecture Notes in Mathematics |volume=9 |year=2003 |publisher=American Mathematical Society |page=1 }}&lt;/ref&gt;
*'''convective derivative'''&lt;ref name=Ockendon&gt;{{cite book| first1=H. |last1=Ockendon |last2=Ockendon |first2=J.R. | title=Waves and Compressible Flow | publisher=Springer | year=2004 | isbn=0-387-40399-X | page=6 }}&lt;/ref&gt;
*'''derivative following the motion'''&lt;ref name="BSLr2"/&gt;
*'''hydrodynamic derivative'''&lt;ref name="BSLr2"/&gt;
*'''Lagrangian derivative'''&lt;ref name=Mellor&gt;{{cite book | first=G.L. | last=Mellor | title=Introduction to Physical Oceanography | publisher=Springer | year=1996 | isbn=1-56396-210-1 |page=19 }}&lt;/ref&gt;
*'''particle derivative'''&lt;ref&gt;{{cite book |title=Water Waves: The Mathematical Theory with Applications |last=Stoker |first=J.J. |author-link=James J. Stoker |isbn=0-471-57034-6 |page=5 |year=1992 |publisher=Wiley }}&lt;/ref&gt;
*'''substantial derivative'''&lt;ref name="BSLr2"&gt;{{cite book|last1=Bird |first1=R.B. |last2=Stewart |first2=W.E. | last3=Lightfoot |first3=E.N. |author3-link=Edwin N. Lightfoot |title=[[Transport Phenomena (book)|Transport Phenomena]] |edition=Revised Second |publisher=John Wiley &amp; Sons |year=2007 |isbn=978-0-470-11539-8 |page=83}}&lt;/ref&gt;
*'''substantive derivative'''&lt;ref name=Granger&gt;{{cite book| first=R.A. |last=Granger| title=Fluid Mechanics | publisher=Courier Dover Publications | year=1995 | isbn=0-486-68356-7 | page=30}}&lt;/ref&gt;
*'''Stokes derivative'''&lt;ref name=Granger/&gt;
*'''total derivative'''&lt;ref name="BSLr2"/&gt;&lt;ref&gt;{{Cite book | publisher = Butterworth-Heinemann | isbn = 0-7506-2767-0
| first1 = L.D. | last1 = Landau | author1-link = Lev Landau | first2 = E.M. | last2 = Lifshitz | author2-link = Evgeny Lifshitz | title = Fluid Mechanics | edition = 2nd | series = Course of Theoretical Physics | volume = 6 | year = 1987 | pages = 3–4 &amp; 227 }}&lt;/ref&gt;

==Definition==

The material derivative is defined for any [[tensor field]] ''y'' that is ''macroscopic'', with the sense that it depends only on position and time coordinates, {{nowrap|''y'' {{=}} ''y''('''x''', ''t'')}}:

:&lt;math&gt;\frac{\mathrm{D} y}{\mathrm{D}t} \equiv \frac{\partial y}{\partial t} + \mathbf{u}\cdot\nabla y,&lt;/math&gt;

where ∇''y'' is the [[covariant derivative]] of the tensor,  and '''u'''('''x''', ''t'') is the [[flow velocity]]. Generally the convective derivative of the field '''u'''·∇''y'', the one that contains the covariant derivative of the field, can be interpreted both as involving the streamline [[tensor derivative (continuum mechanics)|tensor derivative]] of the field '''u'''·(∇''y''), or as involving the streamline [[directional derivative]] of the field {{nowrap|('''u'''·∇) ''y''}}, leading to the same result.&lt;ref&gt;{{Cite book | last=Emanuel | first=G. | title=Analytical fluid dynamics | publisher=CRC Press | year=2001 | edition=second | isbn=0-8493-9114-8 |pages=6–7 }}&lt;/ref&gt; 
Only this spatial term containing the flow velocity describes the transport of the field in the flow, while the other describes the intrinsic variation of the field, independent by the presence of any flow.  Confusingly, sometimes the name "convective derivative" is used for the whole material derivative ''D/Dt'', instead for only the spatial term '''u'''·∇,&lt;ref name=Batchelor/&gt; which is also a redundant nomenclature. In the nonredundant nomenclature the material derivative only equals the convective derivative for absent flows. The effect of the time-independent terms in the definitions are for the scalar and tensor case respectively known as [[advection]] and convection.

===Scalar &amp; vector fields===
For example, for a macroscopic [[scalar field]] {{nowrap|''φ''('''x''', ''t'')}} and a macroscopic [[vector field]] {{nowrap|'''A'''('''x''', ''t'')}} the definition becomes:

:&lt;math&gt;\frac{\mathrm{D}\varphi}{\mathrm{D}t} \equiv \frac{\partial \varphi}{\partial t} + \mathbf{u}\cdot\nabla \varphi,&lt;/math&gt;

:&lt;math&gt;\frac{\mathrm{D}\mathbf{A}}{\mathrm{D}t} \equiv \frac{\partial \mathbf{A}}{\partial t} + \mathbf{u}\cdot\nabla \mathbf{A}.&lt;/math&gt;

In the scalar case ∇''φ'' is simply the [[gradient]] of a scalar, while ∇'''A''' is the [[covariant derivative]] of the macroscopic vector (which can also be thought of as the [[Jacobian matrix]] of '''A''' as a function of '''x''').  
In particular for a scalar field in a three-dimensional [[Cartesian coordinate system]] (''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ''x''&lt;sub&gt;3&lt;/sub&gt;), the components of the velocity '''u''' are ''u''&lt;sub&gt;1&lt;/sub&gt;,  ''u''&lt;sub&gt;2&lt;/sub&gt;, ''u''&lt;sub&gt;3&lt;/sub&gt;, the convective term is then: 

:&lt;math&gt; \mathbf{u}\cdot\nabla \varphi = u_1 \frac {\partial \varphi} {\partial x_1} + u_2 \frac {\partial \varphi} {\partial x_2} + u_3 \frac {\partial \varphi} {\partial x_3}.&lt;/math&gt;

==Development==
Consider a scalar quantity ''&amp;phi;'' = ''&amp;phi;''('''x''', ''t''), where ''t'' is time and '''x''' is position. Here ''&amp;phi;'' may be some physical variable such as temperature or chemical concentration. The physical quantity, whose scalar quantity is ''&amp;phi;'', exists in a continuum, and whose macroscopic velocity is represented by the vector field '''u'''('''x''', ''t'').

The (total) derivative with respect to time of ''&amp;phi;'' is expanded using the multivariate [[chain rule]]:

:&lt;math&gt;\frac{\mathrm{d}}{\mathrm{d} t}\varphi(\mathbf x, t) = \frac{\partial \varphi}{\partial t} + \dot \mathbf x \cdot \nabla \varphi.&lt;/math&gt;

It is apparent that this derivative is dependent on the vector

:&lt;math&gt;\dot \mathbf x \equiv \frac{\mathrm{d} \mathbf x}{\mathrm{d} t},&lt;/math&gt;

which describes a ''chosen'' path '''x'''(''t'') in space. For example, if &lt;math&gt; \dot \mathbf x= \mathbf 0&lt;/math&gt; is chosen, the time derivative becomes equal to the partial time derivative, which agrees with the definition of a [[partial derivative]]: a derivative taken with respect to some variable (time in this case) holding other variables constant (space in this case). This makes sense because if &lt;math&gt;\dot \mathbf x = 0&lt;/math&gt;, then the derivative is taken at some ''constant'' position. This static position derivative is called the Eulerian derivative.

An example of this case is a swimmer standing still and sensing temperature change in a lake early in the morning: the water gradually becomes warmer due to heating from the sun. In which case the term &lt;math&gt; \frac{\partial \varphi}{\partial t}&lt;/math&gt; is sufficient to describe the rate of change of temperature.

If the sun is not warming the water, but the path '''x'''(''t'') is not a standstill, the time derivative of ''&amp;phi;'' may change due to the path. For example, imagine the swimmer is in a motionless pool of water, indoors and unaffected by the sun. One end happens to be at a constant high temperature and the other end at a constant low temperature. By swimming from one end to the other the swimmer senses a change of temperature with respect to time, even though the temperature at any given (static) point is a constant. This is because the derivative is taken at the swimmer's changing location and the second term on the right &lt;math&gt; \dot \mathbf x \cdot \nabla \varphi &lt;/math&gt; is sufficient to describe the rate of change of temperature. A temperature sensor attached to the swimmer would show temperature varying with time, simply due to the temperature variation from one end of the pool  to the other.

The material derivative finally is obtained when the path '''x'''(''t'') is chosen to have a velocity equal to the fluid velocity

:&lt;math&gt;\dot \mathbf x = \mathbf u.&lt;/math&gt;

That is, the path follows the fluid current described by the fluid's velocity field '''u'''. So, the material derivative of the scalar ''&amp;phi;'' is

:&lt;math&gt;\frac{\mathrm{D} \varphi}{\mathrm{D} t} = \frac{\partial \varphi}{\partial t} + \mathbf u \cdot \nabla \varphi.&lt;/math&gt;

An example of this case is a lightweight, neutrally buoyant particle swept along a flowing river and experiencing  temperature changes as it does so. The temperature of the water locally may be increasing due to one portion of the river being sunny and the other in a shadow, or the water as a whole may be heating as the day progresses. The changes due to the particle's motion (itself caused by fluid motion) is called ''[[advection]]'' (or convection if a vector is being transported).

The definition above relied on the physical nature of a fluid current; however, no laws of physics were invoked (for example, it was assumed that a lightweight particle in a river will follow the velocity of the water), but it turns out that many physical concepts can be described concisely using the material derivative. The general case of advection, however, relies on conservation of mass of the fluid stream; the situation becomes slightly different if advection happens in a non-conservative medium.

Only a path was considered for the scalar above. For a vector, the gradient becomes a [[tensor derivative]]; for [[tensor]] fields we may want to take into account not only translation of the coordinate system due to the fluid movement but also its rotation and stretching. This is achieved by the [[upper convected time derivative]].

==Orthogonal coordinates==
It may be shown that, in [[orthogonal coordinates]], the ''j''-th component of the convection term of the material derivative is given by&lt;ref&gt;{{cite web
| url = http://mathworld.wolfram.com/ConvectiveOperator.html
| title = Convective Operator
| author = [[Eric W. Weisstein]]
| publisher = [[MathWorld]]
| accessdate = 2008-07-22
}}&lt;/ref&gt;

:&lt;math&gt;[\mathbf{u}\cdot\nabla \mathbf{A}]_j = 
\sum_i \frac{u_i}{h_i} \frac{\partial A_j}{\partial q^i} + \frac{A_i}{h_i h_j}\left(u_j \frac{\partial h_j}{\partial q^i} - u_i \frac{\partial h_i}{\partial q^j}\right),
&lt;/math&gt;

where the ''h''&lt;sub&gt;''i''&lt;/sub&gt; are related to the [[metric tensor]]s by

:&lt;math&gt;h_i = \sqrt{g_{ii}}.&lt;/math&gt;

In the special case of a three-dimensional [[Cartesian coordinate system]] (''x'', ''y'', ''z'') this is just

:&lt;math&gt;\mathbf{u}\cdot\nabla \mathbf{A} = 
\begin{pmatrix} 
  \displaystyle
  u_x \frac{\partial A_x}{\partial x} + u_y \frac{\partial A_x}{\partial y}+u_z \frac{\partial A_x}{\partial z}
  \\
  \displaystyle
  u_x \frac{\partial A_y}{\partial x} + u_y \frac{\partial A_y}{\partial y}+u_z \frac{\partial A_y}{\partial z} 
  \\
  \displaystyle
  u_x \frac{\partial A_z}{\partial x} + u_y \frac{\partial A_z}{\partial y}+u_z \frac{\partial A_z}{\partial z} 
\end{pmatrix}.
&lt;/math&gt;

==See also==
* [[Navier–Stokes equations]]
* [[Euler equations (fluid dynamics)]]
* [[Derivative (generalizations)]]
* [[Lie derivative]]
* [[Levi-Civita connection]]
* [[Spatial acceleration]]
* [[Spatial gradient]]

==References==
{{Reflist}}

==Further reading==
* {{cite book
|first1=Ira M.|last1=Cohen|first2=Pijush K|last2=Kundu
|title=Fluid Mechanics|isbn=978-0-12-373735-9|publisher=[[Academic Press]]|edition=4}}
* {{cite book|first1=Michael|last1=Lai|first2=Erhard|last2=Krempl|first3=David|last3=Ruben
|title=Introduction to Continuum Mechanics|isbn=978-0-7506-8560-3|publisher=Elsevier|edition=4}}

[[Category:Fluid dynamics]]
[[Category:Multivariable calculus]]</text>
      <sha1>kmx9np0xtme5uv0ykykjjnwj8zeykz3</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematics of radio engineering</title>
    <ns>0</ns>
    <id>31381761</id>
    <revision>
      <id>830502322</id>
      <parentid>830502317</parentid>
      <timestamp>2018-03-15T06:43:05Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/123.200.134.96|123.200.134.96]] to version by Jim.henderson. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3319589) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2200">[[File:Felder_um_Dipol.jpg|link=https://en.wikipedia.org/wiki/File:Felder_um_Dipol.jpg|thumb|260x260px|Diagram of the [[Electric field|electric fields]] ''&lt;span style="color:blue;"&gt;(blue)&lt;/span&gt;'' and [[Magnetic field|magnetic fields]] ''&lt;span style="color:red;"&gt;(red)&lt;/span&gt;'' radiated by a [[dipole antenna]] ''(black rods)'' during transmission.]]
The '''mathematics of radio engineering''' is the application of [[electrodynamics|electromagnetic theory]] to [[radio-frequency engineering]], using conceptual tools such as [[vector calculus]] and [[complex analysis]].&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=kIeKDQAAQBAJ|title=Introduction to Radio Engineering|last=Blaunstein|first=Nathan|last2=Christodoulou|first2=Christos|last3=Sergeev|first3=Mikhail|date=2016-10-14|publisher=[[CRC Press]]|year=|isbn=9781315350080|location=|pages=|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|url=https://books.google.com/books?id=m8Dgkvf84xoC|title=Radio Engineering for Wireless Communication and Sensor Applications|last=R&amp;auml;is&amp;auml;nen|first=Antti V.|last2=Lehto|first2=Arto|date=2003|publisher=[[Artech House]]|year=|isbn=9781580536691|location=|pages=|language=en}}&lt;/ref&gt; Topics studied in this area include [[Waveguide (electromagnetism)|waveguides]] and [[Transmission line|transmission lines]], the behavior of [[Antenna (radio)|radio antennas]], and the [[Radio propagation|propagation of radio waves]] through the Earth's atmosphere. Historically, the subject played a significant role in the development of [[nonlinear dynamics]].&lt;ref&gt;{{Cite book|url=https://sites.google.com/site/giorgioisrael/Art92.pdf|title=Technological Concepts and Mathematical Models in the Evolution of Modern Engineering Systems|last=Israel|first=Giorgio|date=2004|publisher=[[Birkhäuser]], Basel|year=|isbn=9783034896337|location=|pages=52–77|language=en|chapter=Technological Innovation and New Mathematics: van der Pol and the Birth of Nonlinear Dynamics|doi=10.1007/978-3-0348-7951-4_3}}&lt;/ref&gt;

==See also==
* [[Information theory]]
* [[Radio resource management]]

==References==
{{reflist|colwidth=}}{{Mathematics-stub}}{{Engineering-stub}}
[[Category:Radio electronics]]
[[Category:Signal processing]]</text>
      <sha1>pj0p625iyl28segj5iehw6mti7rbk3g</sha1>
    </revision>
  </page>
  <page>
    <title>Minimax</title>
    <ns>0</ns>
    <id>19589</id>
    <revision>
      <id>866945016</id>
      <parentid>864297555</parentid>
      <timestamp>2018-11-02T16:06:36Z</timestamp>
      <contributor>
        <username>Nbro</username>
        <id>23779285</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24589">{{about|the decision theory concept}}
'''Minimax''' (sometimes '''MinMax''' or '''MM'''&lt;ref&gt;[http://www.fraserinstitute.org/uploadedFiles/fraser-ca/Content/research-news/research/publications/provincial-healthcare-index-2013.pdf Provincial Healthcare Index 2013] (Bacchus Barua, Fraser Institute, January 2013 -see page 25-)&lt;/ref&gt;) is a decision rule used in [[artificial intelligence]], [[decision theory]], [[game theory]], [[statistics]] and [[philosophy]] for ''mini''mizing the possible [[loss function|loss]] for a worst case (''max''imum loss) scenario.  When dealing with gains, it is referred to as "maximin"—to maximize the minimum gain.  Originally formulated for two-player [[zero-sum]] [[game theory]], covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty.

==Game theory ==

=== In general games ===
The '''maximin value''' of a player is the highest value that the player can be sure to get without knowing the actions of the other players; equivalently, it is the lowest value the other players can force the player to receive when they know the player's action. Its formal definition is:&lt;ref name=ZMS2013&gt;{{cite book |title=Game Theory |authors=Michael Maschler, Eilon Solan &amp; Shmuel Zamir |publisher=[[Cambridge University Press]] |isbn=9781107005488 |year=2013 |pages=176–180}}&lt;/ref&gt;

:&lt;math&gt;\underline{v_i} = \max_{a_i} \min_{a_{-i}} {v_i(a_i,a_{-i})}&lt;/math&gt;

Where:
* {{mvar|i}} is the index of the player of interest.
* &lt;math&gt;-i&lt;/math&gt; denotes all other players except player {{mvar|i}}.
* &lt;math&gt;a_i&lt;/math&gt; is the action taken by player {{mvar|i}}.
* &lt;math&gt;a_{-i}&lt;/math&gt; denotes the actions taken by all other players.
* &lt;math&gt;v_i&lt;/math&gt; is the value function of player {{mvar|i}}.

Calculating the maximin value of a player is done in a worst-case approach: for each possible action of the player, we check all possible actions of the other players and determine the worst possible combination of actions—the one that gives player {{mvar|i}} the smallest value. Then, we determine which action player {{mvar|i}} can take in order to make sure that this smallest value is the highest possible.

For example, consider the following game for two players, where the first player ("row player") may choose any of three moves, labelled {{mvar|T}}, {{mvar|M}}, or {{mvar|B}}, and the second player ("column" player) may choose either of two moves, {{mvar|L}} or {{mvar|R}}. The result of the combination of both moves is expressed in a payoff table:

{| class="wikitable" style="text-align:center"
|-
!   !! {{mvar|L}} !! {{mvar|R}}
|-
| {{mvar|T}} || 3,1    || 2,-20
|-
| {{mvar|M}} || 5,0    || -10,1
|-
| {{mvar|B}} || -100,2 || 4,4
|}
(where the first number in each cell is the pay-out of the row player and the second number is the pay-out of the column player).

For the sake of example, we consider only pure strategies. Check each player in turn:
* The row player can play {{mvar|T}}, which guarantees them a payoff of at least {{mvar|2}} (playing {{mvar|B}} is risky since it can lead to payoff {{val|-100}}, and playing {{mvar|M}} can result in a payoff of {{val|-10}}). Hence: &lt;math&gt;\underline{v_{row}} = 2&lt;/math&gt;.
* The column player can play {{mvar|L}} and secure a payoff of at least {{val|0}} (playing {{mvar|R}} puts them in the risk of getting &lt;math&gt;-20&lt;/math&gt;). Hence: &lt;math&gt;\underline{v_{col}} = 0&lt;/math&gt;.

If both players play their respective maximin strategies &lt;math&gt;(T,L)&lt;/math&gt;, the payoff vector is &lt;math&gt;(3,1)&lt;/math&gt;.

The '''minimax value''' of a player is the smallest value that the other players can force the player to receive, without knowing the player's actions; equivalently, it is the largest value the player can be sure to get when they ''know'' the actions of the other players. Its formal definition is:&lt;ref name=ZMS2013/&gt;

:&lt;math&gt;\overline{v_i} = \min_{a_{-i}} \max_{a_i} {v_i(a_i,a_{-i})}&lt;/math&gt;

The definition is very similar to that of the maximin value—only the order of the maximum and minimum operators is inverse. In the above example:
* The row player can get a maximum value of {{mvar|4}} (if the other player plays {{mvar|R}}) or {{mvar|5}} (if the other player plays {{mvar|L}}), so: &lt;math&gt;\overline{v_{row}} = 4&lt;/math&gt;.
* The column player can get a maximum value of {{mvar|1}} (if the other player plays {{mvar|T}}), {{mvar|1}} (if {{mvar|M}}) or {{mvar|4}} (if {{mvar|B}}). Hence: &lt;math&gt;\overline{v_{col}} = 1&lt;/math&gt;.

For every player {{mvar|i}}, the maximin is at most the minimax:
:&lt;math&gt;\underline{v_i} \leq \overline{v_i}&lt;/math&gt;
Intuitively, in maximin the maximization comes before the minimization, so player {{mvar|i}} tries to maximize their value before knowing what the others will do; in minimax the maximization comes after the minimization, so player {{mvar|i}} is in a much better position—they maximize their value knowing what the others did.

Another way to understand the ''notation'' is by reading from right to left: when we write
:&lt;math&gt;\overline{v_i} = \min_{a_{-i}} \max_{a_i} {v_i(a_i,a_{-i})} = \min_{a_{-i}} \Big( \max_{a_i} {v_i(a_i,a_{-i})} \Big) &lt;/math&gt;
the initial set of outcomes &lt;math&gt;v_i(a_i,a_{-i})&lt;/math&gt; depends on both &lt;math&gt;{a_{i}}&lt;/math&gt; and &lt;math&gt;{a_{-i}}&lt;/math&gt;.  We first ''marginalize away'' &lt;math&gt;{a_{i}}&lt;/math&gt; from &lt;math&gt;v_i(a_i,a_{-i})&lt;/math&gt;, by maximizing over &lt;math&gt;{a_{i}}&lt;/math&gt; (for every possible value of &lt;math&gt;{a_{-i}}&lt;/math&gt;) to yield a set of marginal outcomes &lt;math&gt;v'_i(a_{-i})&lt;/math&gt;, which depends only on &lt;math&gt;{a_{-i}}&lt;/math&gt;.  We then minimize over &lt;math&gt;{a_{-i}}&lt;/math&gt; over these outcomes.  (Conversely for maximin.)

Although it is always the case that &lt;math&gt;\underline{v_{row}} \leq \overline{v_{row}}&lt;/math&gt; and &lt;math&gt;\underline{v_{col}} \leq \overline{v_{col}}&lt;/math&gt;, the payoff vector resulting from both players playing their minimax strategies, &lt;math&gt;(2,-20)&lt;/math&gt; in the case of &lt;math&gt;(T,R)&lt;/math&gt; or &lt;math&gt;(-10,1)&lt;/math&gt; in the case of &lt;math&gt;(M,R)&lt;/math&gt;, cannot similarly be ranked against the payoff vector &lt;math&gt;(3,1)&lt;/math&gt; resulting from both players playing their maximin strategy.

=== In zero-sum games ===
&lt;span id='Minimax theorem'&gt;&lt;/span&gt;&lt;!-- added label in order not to break incoming links --&gt;
In [[Zero-sum_game|zero-sum games]], the minimax solution is the same as the [[Nash equilibrium]].

In the context of zero-sum games, the [[minimax theorem]] is equivalent to:&lt;ref name=Osborne&gt;Osborne, Martin J., and [[Ariel Rubinstein]]. ''A Course in Game Theory''. Cambridge, MA: MIT, 1994. Print.&lt;/ref&gt;{{Failed verification|date=February 2015}}

&lt;blockquote&gt;For every two-person, [[zero-sum]] game with finitely many strategies, there exists a value V and a mixed strategy for each player, such that
:(a) Given player 2's strategy, the best payoff possible for player 1 is V, and
:(b) Given player 1's strategy, the best payoff possible for player 2 is −V.
&lt;/blockquote&gt;
Equivalently, Player 1's strategy guarantees them a payoff of V regardless of Player 2's strategy, and similarly Player 2 can guarantee themselves a payoff of −V.  The name minimax arises because each player minimizes the maximum payoff possible for the other—since the game is zero-sum, they also minimize their own maximum loss (i.e. maximize their minimum payoff).
See also [[example of a game without a value]].

===Example===
{| class="wikitable" style="text-align:center; float:right; margin-left:1em"
 ! 
 ! B chooses B1
 ! B chooses B2
 ! B chooses B3
 |-
 ! A chooses A1
 |  +3
 |  −2
 |  +2
 |-
 ! A chooses A2
 |  −1
 |  {{0|+}}0
 |  +4
 |-
 ! A chooses A3
 |  −4
 |  −3
 |  +1
|}
The following example of a zero-sum game, where '''A''' and '''B''' make simultaneous moves, illustrates ''minimax'' solutions. Suppose each player has three choices and consider the [[payoff matrix]] for '''A''' displayed on the right. Assume the payoff matrix for '''B''' is the same matrix with the signs reversed (i.e. if the choices are A1 and B1 then '''B''' pays 3 to '''A'''). Then, the minimax choice for '''A''' is A2 since the worst possible result is then having to pay 1, while the simple minimax choice for '''B''' is B2 since the worst possible result is then no payment.  However, this solution is not stable, since if '''B''' believes '''A''' will choose A2 then '''B''' will choose B1 to gain 1; then if '''A''' believes '''B''' will choose B1 then '''A''' will choose A1 to gain 3; and then '''B''' will choose B2; and eventually both players will realize the difficulty of making a choice. So a more stable strategy is needed.

Some choices are ''dominated'' by others and can be eliminated: '''A''' will not choose A3 since either A1 or A2 will produce a better result, no matter what '''B''' chooses; '''B''' will not choose B3 since some mixtures of B1 and B2 will produce a better result, no matter what '''A''' chooses.

'''A''' can avoid having to make an expected payment of more than 1∕3 by choosing A1 with probability 1∕6 and A2 with probability 5∕6: The expected payoff for '''A''' would be 3 × (1∕6) − 1 × (5∕6) = −1∕3 in case '''B''' chose B1 and −2 × (1∕6) + 0 × (5∕6) = −1/3 in case '''B''' chose B2.  Similarly, '''B''' can ensure an expected gain of at least 1/3, no matter what '''A''' chooses, by using a randomized strategy of choosing B1 with probability 1∕3 and B2 with probability 2∕3. These [[mixed strategy|mixed]] minimax strategies are now stable and cannot be improved.

===Maximin===
Frequently, in game theory, '''maximin''' is distinct from minimax. Minimax is used in zero-sum games to denote minimizing the opponent's maximum payoff. In a [[zero-sum game]], this is identical to minimizing one's own maximum loss, and to maximizing one's own minimum gain.

"Maximin" is a term commonly used for non-zero-sum games to describe the strategy which maximizes one's own minimum payoff. In non-zero-sum games, this is not generally the same as minimizing the opponent's maximum gain, nor the same as the [[Nash equilibrium]] strategy.

=== In repeated games ===
The minimax values are very important in the theory of [[repeated games]]. One of the central theorems in this theory, the [[folk theorem (game theory)|folk theorem]], relies on the minimax values.

==Combinatorial game theory==

In [[combinatorial game theory]], there is a minimax algorithm for game solutions.

A '''simple''' version of the minimax ''algorithm'', stated below, deals with games such as [[tic-tac-toe]], where each player can win, lose, or draw.
If player A ''can'' win in one move, their best move is that winning move.
If player B knows that one move will lead to the situation where player A ''can'' win in one move, while another move will lead to the situation where player A can, at best, draw, then player B's best move is the one leading to a draw.
Late in the game, it's easy to see what the "best" move is.
The Minimax algorithm helps find the best move, by working backwards from the end of the game. At each step it assumes that player A is trying to '''maximize''' the chances of A winning, while on the next turn player B is trying to '''minimize''' the chances of A winning (i.e., to maximize B's own chances of winning).

===Minimax algorithm with alternate moves===&lt;!-- This section is linked from [[Alpha-beta pruning]] --&gt;

A '''minimax algorithm'''&lt;ref&gt;{{Russell Norvig 2003|pages=163–171}}&lt;/ref&gt; is a recursive [[algorithm]] for choosing the next move in an n-player [[game theory|game]], usually a two-player game. A value is associated with each position or state of the game. This value is computed by means of a [[evaluation function|position evaluation function]] and it indicates how good it would be for a player to reach that position. The player then makes the move that maximizes the minimum value of the position resulting from the opponent's possible following moves. If it is '''A'''&lt;nowiki&gt;'s&lt;/nowiki&gt; turn to move, '''A''' gives a value to each of their legal moves.

A possible allocation method consists in assigning a certain win for '''A''' as +1 and for '''B''' as −1.  This leads to [[combinatorial game theory]] as developed by [[John Horton Conway]]. An alternative is using a rule that if the result of a move is an immediate win for '''A''' it is assigned positive infinity and, if it is an immediate win for '''B''', negative infinity. The value to '''A''' of any other move is the minimum of the values resulting from each of '''B'''&lt;nowiki&gt;'s&lt;/nowiki&gt; possible replies. For this reason, '''A''' is called the ''maximizing player'' and '''B''' is called the ''minimizing player'', hence the name ''minimax algorithm''. The above algorithm will assign a value of positive or negative infinity to any position since the value of every position will be the value of some final winning or losing position.  Often this is generally only possible at the very end of complicated games such as [[chess]] or [[Go (board game)|go]], since it is not computationally feasible to look ahead as far as the completion of the game, except towards the end, and instead positions are given finite values as estimates of the degree of belief that they will lead to a win for one player or another.

This can be extended if we can supply a [[heuristic]] evaluation function which gives values to non-final game states without considering all possible following complete sequences. We can then limit the minimax algorithm to look only at a certain number of moves ahead. This number is called the "look-ahead", measured in "[[Ply (chess)|plies]]". For example, the chess computer [[IBM Deep Blue|Deep Blue]] (the first one to beat a reigning world champion, [[Garry Kasparov]] at that time) looked ahead at least 12 plies, then applied a heuristic evaluation function.&lt;ref&gt;{{citation
 | last = Hsu | first = Feng-hsiung
 | doi = 10.1109/40.755469
 | issue = 2
 | journal = IEEE Micro
 | location = Los Alamitos, CA, USA
 | quote = During the 1997 match, the software search extended the search to about 40 plies along the forcing lines, even though the nonextended search reached only about 12 plies.
 | pages = 70–81
 | publisher = IEEE Computer Society
 | title = IBM's Deep Blue Chess Grandmaster Chips
 | volume = 19
 | year = 1999}}&lt;/ref&gt;

The algorithm can be thought of as exploring the [[node (computer science)|node]]s of a ''[[game tree]]''. The ''effective [[branching factor]]'' of the tree is the average number of [[child node|children]] of each node (i.e., the average number of legal moves in a position).  The number of nodes to be explored usually [[exponential growth|increases exponentially]] with the number of plies (it is less than exponential if evaluating [[forced move]]s or repeated positions). The number of nodes to be explored for the analysis of a game is therefore approximately the branching factor raised to the power of the number of plies. It is therefore [[Computational complexity theory#Intractability|impractical]] to completely analyze games such as chess using the minimax algorithm.

The performance of the naïve minimax algorithm may be improved dramatically, without affecting the result, by the use of [[alpha-beta pruning]].
Other heuristic pruning methods can also be used, but not all of them are  guaranteed to give the same result as the un-pruned search.

A naive minimax algorithm may be trivially modified to additionally return an entire [[Variation (game tree)#Principal variation|Principal Variation]] along with a minimax score.

=== Pseudocode ===

The [[pseudocode]] for the depth limited minimax algorithm is given below.

 '''function''' minimax(node, depth, maximizingPlayer) '''is'''
     '''if''' depth = 0 '''or''' node is a terminal node '''then'''
         '''return''' the heuristic value of node
     '''if''' maximizingPlayer '''then'''
         value := &amp;minus;∞
         '''for each''' child of node '''do'''
             value := max(value, minimax(child, depth &amp;minus; 1, FALSE))
         '''return''' value
     '''else''' ''(* minimizing player *)''
         value := +∞
         '''for each''' child of node '''do'''
             value := min(value, minimax(child, depth &amp;minus; 1, TRUE))
         '''return''' value

 ''(* Initial call *)''
 minimax(origin, depth, TRUE)

The minimax function returns a heuristic value for [[leaf nodes]] (terminal nodes and nodes at the maximum search depth).
Non leaf nodes inherit their value from a descendant leaf node.
The heuristic value is a score measuring the favorability of the node for the maximizing player.
Hence nodes resulting in a favorable outcome, such as a win, for the maximizing player have higher scores than nodes more favorable for the minimizing player.
The heuristic value for terminal (game ending) leaf nodes are scores corresponding to win, loss, or draw, for the maximizing player.
For non terminal leaf nodes at the maximum search depth, an evaluation function estimates a heuristic value for the node.
The quality of this estimate and the search depth determine the quality and accuracy of the final minimax result.

Minimax treats the two players (the maximizing player and the minimizing player) separately in its code. Based on the observation that &lt;math&gt;\max(a,b) = -\min(-a,-b)&lt;/math&gt;, minimax may often be simplified into the [[negamax]] algorithm.

=== Example ===

[[Image:Minimax.svg|right|300px]]
[[File:Plminmax.gif|thumb|400px|An animated pedagogical example that attempts to be human-friendly by substituting initial infinite (or arbitrarily large) values for emptiness and by avoiding using the [[negamax]] coding simplifications.]]

Suppose the game being played only has a maximum of two possible moves per player each turn. The algorithm generates the [[game tree|tree]] on the right, where the circles represent the moves of the player running the algorithm (''maximizing player''), and squares represent the moves of the opponent (''minimizing player''). Because of the limitation of computation resources, as explained above, the tree is limited to a ''look-ahead'' of 4 moves.

The algorithm evaluates each ''[[leaf node]]'' using a heuristic evaluation function, obtaining the values shown. The moves where the ''maximizing player'' wins are assigned with positive infinity, while the moves that lead to a win of the ''minimizing player'' are assigned with negative infinity. At level 3, the algorithm will choose, for each node, the '''smallest''' of the ''[[child node]]'' values, and assign it to that same node (e.g. the node on the left will choose the minimum between "10" and "+∞", therefore assigning the value "10" to itself). The next step, in level 2, consists of choosing for each node the '''largest''' of the ''child node'' values. Once again, the values are assigned to each ''[[parent node]]''. The algorithm continues evaluating the maximum and minimum values of the child nodes alternately until it reaches the ''[[root node]]'', where it chooses the move with the largest value (represented in the figure with a blue arrow). This is the move that the player should make in order to ''minimize'' the ''maximum'' possible [[loss function|loss]].

==Minimax for individual decisions==

===Minimax in the face of uncertainty===

Minimax theory has been extended to decisions where there is no other player, but where the consequences of decisions depend on unknown facts.  For example, deciding to prospect for minerals entails a cost which will be wasted if the minerals are not present, but will bring major rewards if they are.  One approach is to treat this as a game against ''nature'' (see [[move by nature]]), and using a similar mindset as [[Murphy's law]] or [[resistentialism]], take an approach which minimizes the maximum expected loss, using the same techniques as in the two-person zero-sum games.

In addition, [[expectiminimax tree]]s have been developed, for two-player games in which chance (for example, dice) is a factor.

===Minimax criterion in statistical decision theory===
{{main article|Minimax estimator}}
In classical statistical [[decision theory]], we have an [[estimator]] &lt;math&gt;\delta&lt;/math&gt; that is used to estimate a [[parameter]] &lt;math&gt;\theta \in \Theta&lt;/math&gt;. We also assume a [[risk function]] &lt;math&gt;R(\theta,\delta)&lt;/math&gt;, usually specified as the integral of a [[loss function]]. In this framework, &lt;math&gt;\tilde{\delta}&lt;/math&gt; is called '''minimax''' if it satisfies

: &lt;Math&gt;\sup_\theta R(\theta,\tilde{\delta}) = \inf_\delta \sup_\theta R(\theta,\delta).&lt;/math&gt;

An alternative criterion in the decision theoretic framework is the [[Bayes estimator]] in the presence of a [[prior distribution]] &lt;math&gt;\Pi&lt;/math&gt;. An estimator is Bayes if it minimizes the ''[[average]]'' risk

: &lt;Math&gt;\int_\Theta R(\theta,\delta)\,d\Pi(\theta).&lt;/math&gt;

=== Non-probabilistic decision theory ===
A key feature of minimax decision making is being non-probabilistic: in contrast to decisions using [[expected value]] or [[expected utility]], it makes no assumptions about the probabilities of various outcomes, just [[scenario analysis]] of what the possible outcomes are. It is thus [[:wikt:robust|robust]] to changes in the assumptions, as these other decision techniques are not. Various extensions of this non-probabilistic approach exist, notably [[minimax regret]] and [[Info-gap decision theory]].

Further, minimax only requires [[ordinal measurement]] (that outcomes be compared and ranked), not ''interval'' measurements (that outcomes include "how much better or worse"), and returns ordinal data, using only the modeled outcomes: the conclusion of a minimax analysis is: "this strategy is minimax, as the worst case is (outcome), which is less bad than any other strategy". Compare to expected value analysis, whose conclusion is of the form: "this strategy yields E(''X'')=''n.''" Minimax thus can be used on ordinal data, and can be more transparent.

== Maximin in philosophy ==

In philosophy, the term "maximin" is often used in the context of [[John Rawls]]'s ''[[A Theory of Justice]],'' where he refers to it (Rawls (1971, p.&amp;nbsp;152)) in the context of The [[Difference Principle]].
Rawls defined this principle as the rule which states that social and economic inequalities should be arranged so that "they are to be of the greatest benefit to the least-advantaged members of society".&lt;ref&gt;[[Kenneth Arrow|Arrow]], "Some Ordinalist-Utilitarian Notes on Rawls's Theory of Justice, Journal of Philosophy 70, 9 (May 1973), pp. 245-263.&lt;/ref&gt;&lt;ref&gt;[[John Harsanyi|Harsanyi]], "Can the Maximin Principle Serve as a Basis for Morality? a Critique of John Rawls's Theory, American Political Science Review 69, 2 (June 1975), pp. 594-606.&lt;/ref&gt;

== See also ==
{{div col|colwidth=20em}} 
* [[Alpha-beta pruning]]
* [[Expectiminimax]]
* [[Negamax]]
* [[Sion's minimax theorem]]
* [[Minimax Condorcet]]
* [[Claude Shannon]]
* [[Computer chess]]
* [[Horizon effect]]
* [[Monte Carlo tree search]]
* [[Regret (decision theory)|Minimax regret]]
* [[Negascout]]
* [[Tit for Tat]]
* [[Transposition table]]
* [[Wald's maximin model]]
{{div col end}}

==Notes==
{{reflist}}

== External links ==
{{Wiktionary}}
* {{springer|title=Minimax principle|id=p/m063950}}
* [http://www.cut-the-knot.org/Curriculum/Games/MixedStrategies.shtml A visualization applet]
* [http://www.swif.uniba.it/lei/foldop/foldoc.cgi?maximin+principle Maximin principle] at Dictionary of Philosophical Terms and Names
* [http://www.bewersdorff-online.de/quaak/rules.htm Play a betting-and-bluffing game against a mixed minimax strategy]
* [https://xlinux.nist.gov/dads/HTML/minimax.html Minimax] at [[Dictionary of Algorithms and Data Structures]]
* [http://ksquared.de/gamevisual/launch.php Minimax] (with or without alpha-beta pruning) algorithm visualization &amp;mdash; game tree solving (Java Applet), for balance or off-balance trees.
* [http://apmonitor.com/me575/index.php/Main/MiniMax Minimax Tutorial with a Numerical Solution Platform]
* [https://github.com/ykaragol/checkersmaster/blob/master/CheckersMaster/src/checkers/algorithm/MinimaxAlgorithm.java Java implementation used in a Checkers Game]

{{Game theory}}

[[Category:Detection theory]]
[[Category:Game artificial intelligence]]
[[Category:Graph algorithms]]
[[Category:Optimization algorithms and methods]]
[[Category:Search algorithms]]
[[Category:Game theory]]
[[Category:Theorems in discrete mathematics]]
[[Category:Decision theory]]
[[Category:Fixed points (mathematics)]]
[[Category:Articles with example pseudocode]]</text>
      <sha1>haoma613g64ou1cxzcnz5c2p3sran9f</sha1>
    </revision>
  </page>
  <page>
    <title>Miroslav Fiedler</title>
    <ns>0</ns>
    <id>5539109</id>
    <revision>
      <id>831589223</id>
      <parentid>831589163</parentid>
      <timestamp>2018-03-21T09:43:46Z</timestamp>
      <contributor>
        <ip>131.254.103.122</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2487">{{Infobox scientist
|name              = Miroslav Fiedler
|image             = 
|image_size        = 
|caption           = 
|birth_date        = 7 April 1926
|birth_place       = Prague, Czechoslovakia&lt;ref&gt;http://www-groups.dcs.st-and.ac.uk/~history/Biographies/Fiedler.html&lt;/ref&gt;
|death_date        ={{death date and age|2015|11|20|1926|4|7|df=y}}
|death_place       = 
|residence         = 
|citizenship       = 
|nationality       = 
|ethnicity         = 
|fields            =  [[linear algebra]]&lt;ref&gt;http://www.cs.cas.cz/fiedler/&lt;/ref&gt; &lt;br&gt;  [[graph theory]] &lt;br&gt;  [[Euclidean geometry]]
|workplaces        = Institute of Computer Science, The Czech Academy of Sciences
|alma_mater        = [[Charles University in Prague|Charles University, Prague]] 
|doctoral_advisor  = 
|academic_advisors = 
|doctoral_students = 
|notable_students  = 
|thesis_title = 
|thesis_year = 
|known_for         = 
|author_abbrev_bot = 
|author_abbrev_zoo = 
|influences        = 
|influenced        = 
|awards            = 
|religion          = 
|signature         = 
|website = {{URL|http://www.cs.cas.cz/fiedler/}}
|footnotes         = 
}}
'''Miroslav Fiedler''' (7 April 1926 – 20 November 2015) was a Czech [[mathematician]] known for his contributions to [[linear algebra]], [[graph theory]] and [[algebraic graph theory]].

His article, "Algebraic Connectivity of Graphs", published in the ''Czechoslovak Math Journal'' in 1973, established the use of the [[eigenvalue]]s of the [[Laplacian matrix]] of a graph to create tools for measuring [[algebraic connectivity]] in [[algebraic graph theory]].&lt;ref&gt;Algebraic connectivity of graphs. ''Czechoslovak Math. J.'' '''23'''(98):298 - 305 (1973).&lt;/ref&gt; Since then, this structure has become essential to large areas of research in [[Flocking (behavior)|flocking]], [[distributed control]], [[Cluster analysis|clustering]], [[multi-robot applications]] and [[image segmentation]].&lt;ref&gt;[http://www.ustavinformatiky.cz/docs/parte_Fiedler.pdf prof. RNDr. Miroslav Fiedler, DrSc.] {{cz icon}}&lt;/ref&gt;

==References==
{{reflist}}

==External links==
* [http://www.cs.cas.cz/~fiedler/  Home page] at the [[Academy of Sciences of the Czech Republic]].
* {{MacTutor Biography|id=Fiedler}}

{{Authority control}}

{{DEFAULTSORT:Fiedler, Miroslav}}
[[Category:1926 births]]
[[Category:2015 deaths]]
[[Category:Mathematicians from Prague]]
[[Category:Czech mathematicians]]
[[Category:Graph theorists]]
[[Category:Recipients of Medal of Merit (Czech Republic)]]</text>
      <sha1>7nvm3jd4mjhhq99ruyyfkjp6sp3my07</sha1>
    </revision>
  </page>
  <page>
    <title>NIST Handbook of Mathematical Functions</title>
    <ns>0</ns>
    <id>27353381</id>
    <redirect title="Digital Library of Mathematical Functions" />
    <revision>
      <id>840167475</id>
      <parentid>709914217</parentid>
      <timestamp>2018-05-08T04:40:06Z</timestamp>
      <contributor>
        <username>Bearcat</username>
        <id>24902</id>
      </contributor>
      <minor/>
      <comment>/* top */recat using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="357">#redirect[[Digital Library of Mathematical Functions#NIST Handbook of Mathematical Functions]]

{{R to section}}

[[Category:Cambridge University Press books]]
[[Category:2010 non-fiction books]]
[[Category:Handbooks and manuals]]
[[Category:Mathematics books]]
[[Category:Mathematical tables]]
[[Category:Numerical analysis]]
[[Category:Special functions]]</text>
      <sha1>8djrtun5v19i03eg21nuneuknuga1yd</sha1>
    </revision>
  </page>
  <page>
    <title>Neural cryptography</title>
    <ns>0</ns>
    <id>12589161</id>
    <revision>
      <id>855181420</id>
      <parentid>846696273</parentid>
      <timestamp>2018-08-16T13:53:10Z</timestamp>
      <contributor>
        <ip>5.148.88.9</ip>
      </contributor>
      <comment>/* Applications */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15426">'''Neural cryptography''' is a branch of [[cryptography]] dedicated to analyzing the application of [[stochastic]] algorithms, especially [[artificial neural network]] algorithms, for use in [[encryption]] and [[cryptanalysis]].

== Definition ==

[[Artificial neural network]]s are well known for their ability to selectively explore the solution space of a given problem.  This feature finds a natural niche of application in the field of [[cryptanalysis]]. At the same time, neural networks offer a new approach to attack ciphering algorithms based on the principle that any function could be reproduced by a neural network, which is a powerful proven computational tool that can be used to find the inverse-function of any cryptographic algorithm.

The ideas of mutual learning, self learning, and stochastic behavior of neural networks and similar algorithms can be used for different aspects of cryptography, like [[public-key cryptography]], solving the [[Key (cryptography)|key]] distribution problem using neural network mutual synchronization, [[Cryptographic hash function|hashing]] or generation of [[Cryptographically secure pseudo-random number generator|pseudo-random numbers]].

Another idea is the ability of a neural network to separate space in non-linear pieces using "bias". It gives different probabilities of activating the neural network or not. This is very useful in the case of Cryptanalysis.

Two names are used to design the same domain of research: Neuro-Cryptography and Neural Cryptography.

The first work that it is known on this topic can be traced back to 1995 in an IT Master Thesis.

== Applications ==

There are currently no practical applications due to the recent development of the field, but it could be used specifically where the keys are continually generated and the system (both pairs and the insecure media) is in a continuously evolving mode.&lt;br /&gt;
In 1995, Sebastien Dourlens applied neural networks to cryptanalyze [[Data Encryption Standard|DES]] by allowing the networks to learn how to invert the S-tables of the DES. The bias in DES studied through Differential Cryptanalysis by [[Adi Shamir]] is highlighted. The experiment shows about 50% of the key bits can be found, allowing the complete key to be found in a short time. Hardware application with multi micro-controllers have been proposed due to the easy implementation of multilayer neural networks in hardware.&lt;br /&gt;
One example of a public-key protocol is given by Khalil Shihab. He describes the decryption scheme and the public key creation that are based on a [[backpropagation]] neural network. The encryption scheme and the private key creation process are based on Boolean algebra. This technique has the advantage of small time and memory complexities. A disadvantage is the property of backpropagation algorithms: because of huge training sets, the learning phase of a neural network is very long. Therefore, the use of this protocol is only theoretical so far.

== Neural key exchange protocol ==

The most used protocol for key exchange between two parties A and B in the practice is [[Diffie-Hellman]] protocol. Neural key exchange, which is based on the synchronization of two tree parity machines, should be a secure replacement for this method.
Synchronizing these two machines is similar to synchronizing two chaotic oscillators in [[chaos communications]].
[[File:Tree Parity Machine.jpg|thumb|350x350px|Tree parity machine]]

=== Tree parity machine ===

The tree parity machine is a special type of multi-layer [[feedforward neural network]].

It consists of one output neuron, K hidden neurons and K*N input neurons. Inputs to the network take 3 values: 
:&lt;math&gt;x_{ij} \in \left\{ -1,0,+1 \right\}&lt;/math&gt;
The weights between input and hidden neurons take the values: 
:&lt;math&gt;w_{ij} \in \left\{-L,...,0,...,+L \right\}&lt;/math&gt;
Output value of each hidden neuron is calculated as a sum of all multiplications of input neurons and these weights: 
:&lt;math&gt;\sigma_i=\sgn(\sum_{j=1}^{N}w_{ij}x_{ij})&lt;/math&gt;
Signum is a simple function, which returns -1,0 or 1: &lt;br&gt;
:&lt;math&gt;\sgn (x) = \begin{cases}
-1 &amp; \text{if } x &lt; 0, \\
0 &amp; \text{if } x = 0, \\
1 &amp; \text{if } x &gt; 0. \end{cases}&lt;/math&gt;

If the scalar product is 0, the output of the hidden neuron is mapped to -1 in order to ensure a binary output value. The output of neural network is then computed as the multiplication of all values produced by hidden elements: &lt;br&gt;
:&lt;math&gt;\tau=\prod_{i=1}^{K}\sigma_i&lt;/math&gt;
Output of the tree parity machine is binary.

=== Protocol ===

Each party (A and B) uses its own tree parity machine. Synchronization of the tree parity machines is achieved in these steps
# Initialize random weight values
# Execute these steps until the full synchronization is achieved
## Generate random input vector X
## Compute the values of the hidden neurons
## Compute the value of the output neuron
## Compare the values of both tree parity machines
### Outputs are different: go to 2.1
### Outputs are same: one of the suitable learning rules is applied to the weights

After the full synchronization is achieved (the weights w&lt;sub&gt;ij&lt;/sub&gt; of both tree parity machines are same), A and B can use their weights as keys.&lt;br&gt;
This method is known as a bidirectional learning.&lt;br&gt; 
One of the following learning rules&lt;ref name="SinghAndNandal"&gt;{{cite journal |last1=Singh |first1=Ajit |last2=Nandal |first2=Aarti |date=May 2013 |title=Neural Cryptography for Secret Key Exchange and Encryption with AES |url=http://ijarcsse.com/Before_August_2017/docs/papers/Volume_3/5_May2013/V3I5-0187.pdf |journal=International Journal of Advanced Research in Computer Science and Software Engineering |volume=3 |issue=5 |pages=376–381 |issn=2277-128X}}&lt;/ref&gt; can be used for the synchronization:
* Hebbian learning rule:
:&lt;math&gt;w_i^+=g(w_i+\sigma_ix_i\Theta(\sigma_i\tau)\Theta(\tau^A\tau^B))&lt;/math&gt;
* Anti-Hebbian learning rule:
:&lt;math&gt;w_i^+=g(w_i-\sigma_ix_i\Theta(\sigma_i\tau)\Theta(\tau^A\tau^B))&lt;/math&gt;
* Random walk:
:&lt;math&gt;w_i^+=g(w_i+x_i\Theta(\sigma_i\tau)\Theta(\tau^A\tau^B))&lt;/math&gt;

Where:
:&lt;math&gt;\Theta(a,b)=0&lt;/math&gt; if &lt;math&gt;a \ne b&lt;/math&gt; otherwise &lt;math&gt;\Theta(a,b)=1&lt;/math&gt;
And:
:&lt;math&gt;g(x)&lt;/math&gt; is a [[Function_(mathematics)| function]] that keeps the &lt;math&gt;w_i&lt;/math&gt; in the range &lt;math&gt;\{-L, -L+1,...,0,...,L-1,L\}&lt;/math&gt;

=== Attacks and security of this protocol ===

In every attack it is considered, that the attacker E can eavesdrop messages between the parties A and B, but does not have an opportunity to change them.

==== Brute force ====
To provide a brute force attack, an attacker has to test all possible keys (all possible values of weights wij). By K hidden neurons, K*N input neurons and boundary of weights L, this gives (2L+1)&lt;sup&gt;KN&lt;/sup&gt; possibilities. For example, the configuration K = 3, L = 3 and N = 100 gives us 3*10&lt;sup&gt;253&lt;/sup&gt; key possibilities, making the attack impossible with today’s computer power.

==== Learning with own tree parity machine ====
One of the basic attacks can be provided by an attacker, who owns the same tree parity machine as the parties A and B. He wants to synchronize his tree parity machine with these two parties. In each step there are three situations possible:
# Output(A) ≠ Output(B): None of the parties updates its weights.
# Output(A) = Output(B) = Output(E): All the three parties update weights in their tree parity machines.
# Output(A) = Output(B) ≠ Output(E): Parties A and B update their tree parity machines, but the attacker can not do that. Because of this situation his learning is slower than the synchronization of parties A and B.
It has been proven, that the synchronization of two parties is faster than learning of an attacker. It can be improved by increasing of the synaptic depth L of the neural network. That gives this protocol enough security and an attacker can find out the key only with small probability.

==== Other attacks ====
For conventional cryptographic systems, we can improve the security of the protocol by increasing of the key length. In the case of neural cryptography, we improve it by increasing of the synaptic depth L of the neural networks. Changing this parameter increases the cost of a successful attack exponentially, while the effort for the users grows polynomially. Therefore, breaking the security of neural key exchange belongs to the complexity class NP.

Alexander Klimov, Anton Mityaguine, and Adi Shamir say that the original neural synchronization scheme can be broken by at least three different attacks—geometric, probabilistic analysis, and using genetic algorithms. Even though this particular implementation is insecure, the ideas behind chaotic synchronization could potentially lead to a secure implementation.&lt;ref name="Klimov"&gt;{{cite conference |last1=Klimov |first1=Alexander |last2=Mityagin |first2=Anton |last3=Shamir |first3=Adi |date=2002 |title=Analysis of Neural Cryptography |url=https://iacr.org/archive/asiacrypt2002/25010286/25010286.pdf |book-title=Advances in Cryptology |conference=ASIACRYPT 2002 |series=[[Lecture Notes in Computer Science|LNCS]] |volume=2501 |pages=288–298 |issn=0302-9743 |doi=10.1007/3-540-36178-2_18 |accessdate=2017-11-15}}&lt;/ref&gt;

=== Permutation parity machine ===

The permutation parity machine is a binary variant of the tree parity machine.&lt;ref name="Reyes"&gt;{{cite journal |last1=Reyes |first1=O. M. |last2=Kopitzke |first2=I. |last3=Zimmermann |first3=K.-H. |date=April 2009 |title=Permutation Parity Machines for Neural Synchronization |journal=Journal of Physics A: Mathematical and Theoretical |volume=42 |issue=19 |pages=195002 |issn=1751-8113 |doi=10.1088/1751-8113/42/19/195002|bibcode=2009JPhA...42s5002R }}&lt;/ref&gt;

It consists of one input layer, one hidden layer and one output layer. The number of neurons in the output layer depends on the number of hidden units K. Each hidden neuron has N binary input neurons: 
:&lt;math&gt;x_{ij} \in \left\{ 0,1 \right\}&lt;/math&gt;
The weights between input and hidden neurons are also binary: 
:&lt;math&gt;w_{ij} \in \left\{0,1 \right\}&lt;/math&gt;

Output value of each hidden neuron is calculated as a sum of all exclusive disjunctions (exclusive or) of input neurons and these weights:

:&lt;math&gt;\sigma_i=\theta_N(\sum_{j=1}^{N}w_{ij}\oplus x_{ij})&lt;/math&gt;

(⊕ means XOR).

The function &lt;math&gt;\theta_N(x)&lt;/math&gt; is a threshold function, which returns 0 or 1: &lt;br&gt;
:&lt;math&gt;\theta_N(x) = \begin{cases}
0 &amp; \text{if } x \leq N/2, \\
1 &amp; \text{if } x &gt; N/2. \end{cases}&lt;/math&gt;

The output of neural network with two or more hidden neurons can be computed as the exclusive or of the values produced by hidden elements: &lt;br&gt;
:&lt;math&gt;\tau=\bigoplus_{i=1}^{K}\sigma_i&lt;/math&gt;
Other configurations of the output layer for K&gt;2 are also possible.&lt;ref name="Reyes" /&gt;

This machine has proven to be robust enough against some attacks&lt;ref name="Reyes2"&gt;{{cite journal |last1=Reyes |first1=Oscar Mauricio |last2=Zimmermann |first2=Karl-Heinz |date=June 2010 |title=Permutation parity machines for neural cryptography |journal=Physical Review E |volume=81 |issue=6 |issn=1539-3755 |doi=10.1103/PhysRevE.81.066117|bibcode=2010PhRvE..81f6117R }}&lt;/ref&gt; so it could be used as a cryptographic mean, but it has been shown to be vulnerable to a probabilistic attack.&lt;ref name="Seoane"&gt;{{cite journal |last1=Seoane |first1=Luís F. |last2=Ruttor |first2=Andreas |date=February 2012 |title=Successful attack on permutation-parity-machine-based neural cryptography |journal=Physical Review E |volume=85 |issue=2 |issn=1539-3755 |doi=10.1103/PhysRevE.85.025101|arxiv=1111.5792 |bibcode=2012PhRvE..85b5101S }}&lt;/ref&gt;

=== Security against quantum computers ===
A [[quantum computer]] is a device that uses quantum mechanisms for computation. In this device the data are stored as qubits (quantum binary digits). That gives a quantum computer in comparison with a conventional computer the opportunity to solve complicated problems in a short time, e.g. discrete logarithm problem or factorization. Algorithms that are not based on any of these number theory problems are being searched because of this property.

Neural key exchange protocol is not based on any number theory.
It is based on the difference between unidirectional and bidirectional synchronization of neural networks.
Therefore, something like the neural key exchange protocol could give rise to potentially faster key exchange schemes.&lt;ref name="Klimov" /&gt;

== See also ==

* [[Neural network|Neural Network]]
* [[Stochastic neural network]]
* [[Shor%27s algorithm]]

== References ==
&lt;references /&gt;  
* [http://s.dourlens.free.fr/AppliedNeuroCryptography.pdf Neuro-Cryptography] 1995 - The first definition of the Neuro-Cryptography (AI Neural-Cryptography) applied to DES cryptanalysis by Sebastien Dourlens, France.
* [http://theorie.physik.uni-wuerzburg.de/~ruttor/neurocrypt.html Neural Cryptography] - Description of one kind of neural cryptography at the [[University of Würzburg]], Germany.
* {{cite conference |last1=Kinzel |first1=W. |last2=Kanter |first2=I. |date=2002 |title=Neural cryptography |book-title=Proceedings of the 9th International Conference on Neural Information Processing |conference=ICONIP '02 |pages=1351–1354 |doi=10.1109/ICONIP.2002.1202841|arxiv=cond-mat/0208453 }} - One of the leading papers that introduce the concept of using synchronized neural networks to achieve a public key authentication system.
* {{cite journal |last1=Li |first1=Li-Hua |last2=Lin |first2=Luon-Chang |last3=Hwang |first3=Min-Shiang |date=November 2001 |title=A remote password authentication scheme for multiserver architecture using neural networks |journal=IEEE Transactions on Neural Networks |volume=12 |issue=6 |pages=1498–1504 |issn=1045-9227 |doi=10.1109/72.963786}} - Possible practical application of Neural Cryptography.
* {{cite conference |last1=Klimov |first1=Alexander |last2=Mityagin |first2=Anton |last3=Shamir |first3=Adi |date=2002 |title=Analysis of Neural Cryptography |url=https://iacr.org/archive/asiacrypt2002/25010286/25010286.pdf |book-title=Advances in Cryptology |conference=ASIACRYPT 2002 |series=[[Lecture Notes in Computer Science|LNCS]] |volume=2501 |pages=288–298 |issn=0302-9743 |doi=10.1007/3-540-36178-2_18 |accessdate=2017-11-15}} - Analysis of neural cryptography in general and focusing on the weakness and possible attacks of using synchronized neural networks.
* [http://www.opus-bayern.de/uni-wuerzburg/volltexte/2007/2361/ Neural Synchronization and Cryptography] - Andreas Ruttor. PhD thesis, Bayerische Julius-Maximilians-Universität Würzburg, 2006.
* {{cite journal |last1=Ruttor |first1=Andreas |last2=Kinzel |first2=Wolfgang |last3=Naeh |first3=Rivka |last4=Kanter |first4=Ido |date=March 2006 |title=Genetic attack on neural cryptography |journal=Physical Review E |volume=73 |issue=3 |issn=1539-3755 |doi=10.1103/PhysRevE.73.036121|arxiv=cond-mat/0512022 |bibcode=2006PhRvE..73c6121R }}
* {{cite journal | author=Khalil Shihab | year=2006 | title=A backpropagation neural network for computer network security | journal=Journal of Computer Science 2 | pages=710&amp;ndash;715 | url=http://www.scipub.org/fulltext/jcs/jcs29710-715.pdf | deadurl=yes | archiveurl=https://web.archive.org/web/20070712012959/http://www.scipub.org/fulltext/jcs/jcs29710-715.pdf | archivedate=2007-07-12 | df= }}
{{Cryptography navbox}}

[[Category:Theory of cryptography]]
[[Category:Artificial neural networks]]</text>
      <sha1>3qbo99qeq50pv3b4wnufabr9tbiw69z</sha1>
    </revision>
  </page>
  <page>
    <title>New York State Mathematics League</title>
    <ns>0</ns>
    <id>2110951</id>
    <revision>
      <id>505880013</id>
      <parentid>167764914</parentid>
      <timestamp>2012-08-05T10:21:04Z</timestamp>
      <contributor>
        <username>Brasidas7</username>
        <id>16800507</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="420">The '''New York State Mathematics League''' (NYSML) competition was originally held in 1973 and has been held annually in a different location each year since. It was founded by [[Alfred Kalfus]]. The [[American Regions Math League]] competition is based on the format of the NYSML competition.

==External links==
*[http://www.nysml.com/ NYSML Homepage]

[[Category:Mathematics competitions]]

{{Math-competition-stub}}</text>
      <sha1>1kh1rd6a1bfe16actq9h580pf33u1u3</sha1>
    </revision>
  </page>
  <page>
    <title>Null set</title>
    <ns>0</ns>
    <id>21520</id>
    <revision>
      <id>868858851</id>
      <parentid>864608178</parentid>
      <timestamp>2018-11-14T22:22:04Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9207">{{For|the set with no elements|Empty set}}

In [[mathematical analysis]], a '''null set''' &lt;math&gt;N \subset \mathbb{R}&lt;/math&gt; is a set that can be [[Cover (topology)|covered]] by a countable union of [[interval (mathematics)|interval]]s of arbitrarily small total length. The notion of null set in set theory anticipates the development of [[Lebesgue measure]] since a null set necessarily has '''measure zero'''. More generally, on a given measure space &lt;math&gt;M = (X, \Sigma, \mu)&lt;/math&gt; a null set is a set &lt;math&gt;S \subset X&lt;/math&gt; such that &lt;math&gt;\mu(S) = 0&lt;/math&gt;.

== Definition ==
Suppose &lt;math&gt;A&lt;/math&gt; is a subset of the [[real line]] &lt;math&gt;\mathbb{R}&lt;/math&gt; such that 
:&lt;math&gt;\forall \varepsilon &gt; 0, \exists \left\{U_n\right\}\left(A \subset \bigcup_{n = 1}^\infty U_n \ \land\ \sum_{n = 1}^\infty \left|U_n\right| &lt; \varepsilon\right)&lt;/math&gt;

where the ''U''&lt;sub&gt;n&lt;/sub&gt; are [[interval (mathematics)|interval]]s and |''U''| is the length of ''U'', then ''A'' is a null set.&lt;ref&gt;{{cite book | first=John | last=Franks | date=2009 | title=A (Terse) Introduction to Lebesgue Integration | page=28 | publisher=[[American Mathematical Society]] | isbn=978-0-8218-4862-3 | doi=10.1090/stml/048}}&lt;/ref&gt; Also known as a set of zero-content. 

In terminology of [[mathematical analysis]], this definition requires that there be a [[sequence]] of [[open cover]]s of ''A'' for which the [[limit of a sequence|limit]] of the lengths of the covers is zero.

Null sets include all finite sets, all countable sets, and even some uncountable sets such as the [[Cantor set]].

== Properties ==
The [[empty set]] is always a null set. More generally, any [[countable]] [[union (set theory)|union]] of null sets is null. Any measurable subset of a null set is itself a null set. Together, these facts show that the ''m''-null sets of ''X'' form a [[sigma-ideal]] on ''X''. Similarly, the measurable ''m''-null sets form a sigma-ideal of the [[sigma-algebra]] of measurable sets. Thus, null sets may be interpreted as [[negligible set]]s, defining a notion of [[almost everywhere]].

== Lebesgue measure ==
The [[Lebesgue measure]] is the standard way of assigning a [[length]], [[area]] or [[volume]] to subsets of [[Euclidean space]].

A subset ''N'' of &lt;math&gt;\mathbb{R}&lt;/math&gt; has null Lebesgue measure and is considered to be a null set in &lt;math&gt;\mathbb{R}&lt;/math&gt; if and only if:
: [[Given any]] [[positive number]] ''ε'', [[Existential quantification|there is]] a [[sequence]] {''I''&lt;sub&gt;''n''&lt;/sub&gt;} of [[interval (mathematics)|intervals]] in &lt;math&gt;\mathbb{R}&lt;/math&gt; such that ''N'' is contained in the union of the {''I''&lt;sub&gt;''n''&lt;/sub&gt;} and the total length of the union is less than ''ε''.
This condition can be generalised to &lt;math&gt;\mathbb{R}^{n}&lt;/math&gt;, using ''n''-[[Cube (geometry)|cube]]s instead of intervals. In fact, the idea can be made to make sense on any [[Riemannian manifold]], even if there is no Lebesgue measure there.

For instance:
* With respect to &lt;math&gt;\mathbb{R}^n&lt;/math&gt;, all [[singleton (mathematics)|1-point set]]s are null, and therefore all [[countable set]]s are null. In particular, the set '''Q''' of [[rational number]]s is a null set, despite being [[dense (topology)|dense]] in &lt;math&gt;\mathbb{R}&lt;/math&gt;.
* The standard construction of the [[Cantor set]] is an example of a null [[uncountable set]] in &lt;math&gt;\mathbb{R}&lt;/math&gt;; however other constructions are possible which assign the Cantor set any measure whatsoever.
* All the subsets of &lt;math&gt;\mathbb{R}^n&lt;/math&gt; whose [[dimension]] is smaller than ''n'' have null Lebesgue measure in &lt;math&gt;\mathbb{R}^n&lt;/math&gt;. For instance straight lines or circles are null sets in &lt;math&gt;\mathbb{R}^2&lt;/math&gt;.
* [[Sard's lemma]]: the set of [[critical value]]s of a smooth function has measure zero.

If λ is Lebesgue measure for &lt;math&gt;\mathbb{R}&lt;/math&gt; and π is Lebesgue measure for &lt;math&gt;\mathbb{R}^{2}&lt;/math&gt;, then the [[product measure]] &lt;math&gt;\lambda \times \lambda = \pi&lt;/math&gt;. In terms of null sets, the following equivalence has been styled a [[Fubini's theorem]]:&lt;ref&gt;{{cite journal | first=Eric K. | last=van Douwen | date=1989 | title=Fubini’s theorem for null sets | journal=[[American Mathematical Monthly]] | volume=96 | issue=8 | pages=718–21 | mr=1019152 | jstor=2324722}}&lt;/ref&gt; 
* For &lt;math&gt;A \subset \mathbb{R}^{2}&lt;/math&gt; and &lt;math&gt;A_x = \{y : (x , y) \isin A \} ,&lt;/math&gt;
*: &lt;math&gt;(\pi(A) = 0) \equiv \lambda \left(\left\{ x : \lambda\left(A_x\right) &gt; 0 \right\}\right) = 0 .&lt;/math&gt;

== Uses ==
Null sets play a key role in the definition of the [[Lebesgue integration|Lebesgue integral]]: if functions ''f'' and ''g'' are equal except on a null set, then ''f'' is integrable if and only if ''g'' is, and their integrals are equal.

A measure in which all subsets of null sets are measurable is ''[[complete measure|complete]]''. Any non-complete measure can be completed to form a complete measure by asserting that subsets of null sets have measure zero. Lebesgue measure is an example of a complete measure; in some constructions, it is defined as the completion of a non-complete [[Borel measure]].

=== A subset of the Cantor set which is not Borel measurable ===
The Borel measure is not complete. One simple construction is to start with the standard [[Cantor set]] ''K'', which is closed hence Borel measurable, and which has measure zero, and to find a subset ''F'' of ''K'' which is not Borel measurable. (Since the Lebesgue measure is complete, this ''F'' is of course Lebesgue measurable.)

First, we have to know that every set of positive measure contains a nonmeasurable subset. Let ''f'' be the [[Cantor function]], a continuous function which is locally constant on ''K&lt;sup&gt;c&lt;/sup&gt;'', and monotonically increasing on [0, 1], with ''f''(0) = 0 and ''f''(1) = 1. Obviously, ''f''(''K&lt;sup&gt;c&lt;/sup&gt;'') is countable, since it contains one point per component of ''K&lt;sup&gt;c&lt;/sup&gt;''. Hence ''f''(''K&lt;sup&gt;c&lt;/sup&gt;'') has measure zero, so ''f''(''K'') has measure one. We need a strictly [[monotonic function]], so consider ''g''(''x'') = ''f''(''x'') + ''x''. Since ''g''(''x'') is strictly monotonic and continuous, it is a [[homeomorphism]]. Furthermore, ''g''(''K'')  has measure one. Let ''E'' ⊂ ''g''(''K'') be non-measurable, and let ''F'' = ''g''&lt;sup&gt;−1&lt;/sup&gt;(''E''). Because ''g'' is injective, we have that ''F'' ⊂ ''K'', and so ''F'' is a null set. However, if it were Borel measurable, then ''g''(''F'')  would also be Borel measurable (here we use the fact that the [[Image (mathematics)|preimage]] of a Borel set by a continuous function is measurable; ''g''(''F'') = (''g''&lt;sup&gt;−1&lt;/sup&gt;)&lt;sup&gt;−1&lt;/sup&gt;(''F'') is the preimage of ''F'' through the continuous function ''h'' = ''g''&lt;sup&gt;−1&lt;/sup&gt;.) Therefore, ''F'' is a null, but non-Borel measurable set.

==Haar null==
In a [[separable space|separable]] [[Banach space]] (''X'', +), the group operation moves any subset ''A'' ⊂ ''X'' to the translates ''A'' + ''x'' for any ''x'' ∈ ''X''. When there is a [[probability measure]] μ  on the σ-algebra of [[Borel subset]]s of ''X'', such that for all ''x'', μ(''A'' + ''x'') = 0, then ''A'' is a '''Haar null set'''.&lt;ref&gt;{{cite journal | first=Eva | last=Matouskova | date=1997 | url=http://www.ams.org/journals/proc/1997-125-06/S0002-9939-97-03776-3/S0002-9939-97-03776-3.pdf | title=Convexity and Haar Null Sets | journal=[[Proceedings of the American Mathematical Society]] | volume=125 | issue=6 | jstor=2162223}}&lt;/ref&gt;

The term refers to the null invariance of the measures of translates, associating it with the complete invariance found with [[Haar measure]].

Some algebraic properties of [[topological group]]s have been related to the size of subsets and Haar null sets.&lt;ref&gt;{{cite journal | first=S. | last=Solecki | date=2005 | title=Sizes of subsets of groups and Haar null sets | journal=Geometry and Functional Analysis | volume=15 | pages=246–73 | mr=2140632 | doi=10.1007/s00039-005-0505-z}}&lt;/ref&gt;
Haar null sets have been used to in [[Polish group]]s to show that when ''A'' is not a [[meagre set]] then ''A''&lt;sup&gt;–1&lt;/sup&gt;''A'' contains an open neighborhood of the [[identity element]].&lt;ref&gt;{{cite journal | first=Pandelis | last=Dodos | date=2009 | title=The Steinhaus property and Haar-null sets | journal=[[Bulletin of the London Mathematical Society]] | volume=41 | issue=2 | pages=377–44 | mr=4296513| bibcode=2010arXiv1006.2675D | arxiv=1006.2675 | doi=10.1112/blms/bdp014 }}&lt;/ref&gt; This property is named for [[Hugo Steinhaus]] since it is the conclusion of the [[Steinhaus theorem]].

== See also ==
* [[Cantor function]]
* [[Measure (mathematics)]]
* [[Empty set]]

==References==
{{Reflist}}
* {{cite book | first1=Marek | last1=Capinski | first2=Ekkehard | last2=Kopp | date=2005 | title=Measure, Integral and Probability | page=16 | publisher=Springer | isbn=1-85233-781-8}}
* {{cite book | first=Frank | last=Jones | date=1993 | title=Lebesgue Integration on Euclidean Spaces | page=107 | publisher=Jones &amp; Bartlett | isbn=0-86720-203-3}}
* {{cite book | first=John C. | last=Oxtoby | date=1971 | title=Measure and Category | page=3 | publisher=Springer-Verlag | isbn=0-387-05349-2}}


[[Category:Measure theory]]
[[Category:Set theory]]</text>
      <sha1>rncwtc5wj2m6xoj2xf8mhag7xx2i5mp</sha1>
    </revision>
  </page>
  <page>
    <title>Quadratics</title>
    <ns>0</ns>
    <id>9625798</id>
    <revision>
      <id>801309227</id>
      <parentid>777427720</parentid>
      <timestamp>2017-09-18T22:46:37Z</timestamp>
      <contributor>
        <ip>2602:306:36D5:8230:AD3E:6AF0:F00:8209</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2666">{{about|the TV series|the mathematical function|Quadratic function}}
{{Infobox television
| show_name          = Quadratics
| image              = 
| caption            = 
| genre              = [[Instructional television|Instructional]]
| director           = David Chamberlain
| writer             = Robert G. Dexter
| narrated           = [[Suzanne Grew Ellis]]
| country            = Canada
| language           = English
| num_episodes       = 6
| producer           = David Chamberlain
| runtime            = 10 minutes
| network            = [[TVOntario]]
| first_aired        = 1993
}}
'''''Quadratics''''' is a six-part Canadian [[instructional television]] series produced by [[TVOntario]] in 1993. The [[miniseries]] is part of the ''Concepts in Mathematics'' series. The program uses [[computer animation]] to demonstrate quadratic equations and their corresponding functions in the [[Cartesian coordinate system]].&lt;ref&gt;{{Cite document|url=http://www.tvontario.org/sales/crb/crb_catalog04.pdf|title=Curriculum Resource Bank - Catalog|year=2004|publisher=Ontario Educational Communications Authority|format=pdf|accessdate=2009-07-07}}&lt;/ref&gt;

==Synopsis==
Each program involves two [[robot]]s, Edie and Charon, who work on an assembly line in a high-tech factory. The robots discuss their desire to learn about [[quadratic equation]]s, and they are subsequently provided with lessons that further their education.&lt;ref&gt;{{cite manual|url=http://www.ket.org/education/guides/quad.pdf|title=Quadratics - Teacher's Guide|year=1993|publisher=Ontario Educational Communications Authority|format=pdf|accessdate=2009-07-07}}&lt;/ref&gt;

==Episodes==
{| class="wikitable plainrowheaders"
|-
! width="20"|# !! Title !! width="120"|Production code
{{Episode list
 |EpisodeNumber=1
 |Title=Zeroes and Roots ; a beginning
 |ProdCode=BPN 356101
}}
{{Episode list
 |EpisodeNumber=2
 |Title=Factoring Quadratics
 |ProdCode=BPN 356102
}}
{{Episode list
 |EpisodeNumber=3
 |Title=Completing the Square
 |ProdCode=BPN 356103
}}
{{Episode list
 |EpisodeNumber=4
 |Title=The Quadratic Formula
 |ProdCode=BPN 356104
}}
{{Episode list
 |EpisodeNumber=5
 |Title=Complex Roots
 |ProdCode=BPN 356105
}}
{{Episode list
 |EpisodeNumber=6
 |Title=Applications of Quadratics ; overview
 |ProdCode=BPN 356106
}}
|}

==References==
{{Reflist}}

==External links==
*{{tv.com show|quadratics}}

[[Category:1993 Canadian television series debuts]]
[[Category:1993 Canadian television series endings]]
[[Category:Canadian children's animated television series]]
[[Category:TVOntario shows]]
[[Category:Mathematics education television series]]
[[Category:1990s Canadian animated television series]]</text>
      <sha1>cla80mr7is4fduoc86oomumjda13r7t</sha1>
    </revision>
  </page>
  <page>
    <title>Richardson's theorem</title>
    <ns>0</ns>
    <id>13463844</id>
    <revision>
      <id>841829850</id>
      <parentid>836989115</parentid>
      <timestamp>2018-05-18T10:24:35Z</timestamp>
      <contributor>
        <username>Newagelink</username>
        <id>358839</id>
      </contributor>
      <minor/>
      <comment>removing link to nonexisting page</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5067">In mathematics, '''Richardson's theorem''' establishes a limit on the extent to which an [[algorithm]] can [[decision problem|decide]] whether certain mathematical expressions are equal. It states that for a certain fairly natural class of expressions, it is [[Undecidable problem|undecidable]] whether a particular expression ''E'' satisfies the equation ''E'' = 0, and similarly undecidable whether the functions defined by expressions ''E'' and ''F'' are everywhere equal (in fact ''E'' = ''F'' if and only if ''E'' - ''F'' = 0). It was proved in 1968 by computer scientist Daniel Richardson of the [[University of Bath]].

Specifically, the class of expressions for which the theorem holds is that generated by rational numbers, the number [[Pi|π]], the number [[natural logarithm|log 2]], the variable ''x'', the operations of addition, subtraction, multiplication, [[function composition|composition]], and the [[sine|sin]], [[exponential function|exp]], and [[absolute value|abs]] functions.

For some classes of expressions (generated by other primitives than in Richardson's theorem) there exist algorithms that can determine whether an expression is zero.&lt;ref&gt;
Dan Richardson and John Fitch, 1994, "[http://portal.acm.org/citation.cfm?id=190429 The identity problem for elementary functions and constants]", Proceedings of the international symposium on Symbolic and algebraic computation, pp. 85&amp;ndash;290.&lt;/ref&gt;

==Statement of the theorem==
Richardson's theorem can be stated as follows:&lt;ref&gt;[http://projecteuclid.org/euclid.jsl/1183736504 "Some Undecidable Problems Involving Elementary Functions of a Real Variable"], Daniel Richardson, ''J. Symbolic Logic'' '''33''', #4 (1968), pp. 514-520, {{JSTOR|2271358}}.&lt;/ref&gt;  
Let ''E'' be a set of expressions in the variable ''x'' which contains ''x'' and, as constant expressions, all rational numbers, and is such that if ''A(x)'' and ''B(x)'' are in ''E'', then ''A(x)'' + ''B(x)'', ''A(x)'' - ''B(x)'', ''A(x)B(x)'', and ''A(B(x))'' are also in ''E''.  Then:
* if x, log 2, π, ''e&lt;sup&gt;x&lt;/sup&gt;'', sin ''x'' ∈ E, then the problem of determining, for an expression ''A(x)'' in ''E'', whether ''A(x)'' &lt; 0 for some ''x'' is unsolvable;
* if also ''|x|'' ∈ ''E'' then the problem of determining whether ''A(x)'' = 0 for all ''x'' is also unsolvable;
* if furthermore there is a function ''B(x)'' ∈ ''E'' without an [[antiderivative]] in ''E'' then the integration problem is unsolvable. (Example: &lt;math&gt;e^{ax^2}&lt;/math&gt; has an antiderivative in the elementary functions if and only if {{math|1=''a'' = 0}}.)

==Extensions==
After [[Hilbert's Tenth Problem]] was solved in 1970, B. F. Caviness observed that the use of ''e&lt;sup&gt;x&lt;/sup&gt;'' and log 2 could be removed.&lt;ref&gt;On Canonical Forms and Simplification, B. F. Caviness, ''JACM'', '''17''', #2 (April 1970), pp. 385-396.&lt;/ref&gt;
P. S. Wang&lt;ref&gt;P. S. Wang, The undecidability of the existence of zeros of real elementary functions, ''Journal of the Association for Computing Machinery'' '''21''':4 (1974), pp. 586–589.&lt;/ref&gt; later noted that under the same assumptions under which the question of whether there was ''x'' with ''A(x)'' &lt; 0 was insoluble, the question of whether there was ''x'' with ''A(x)'' = 0 was also insoluble.  

[[Miklós Laczkovich]]&lt;ref&gt;[[Miklós Laczkovich]], The removal of π from some undecidable problems involving elementary functions, ''Proc. Amer. Math. Soc.'' '''131''':7 (2003), pp. 2235–2240.&lt;/ref&gt; removed also the need for π and reduced the use of composition.  In particular, given an expression ''A(x)'' in the ring generated by the integers, ''x'', sin ''x&lt;sup&gt;n&lt;/sup&gt;'', and sin(''x'' sin ''x&lt;sup&gt;n&lt;/sup&gt;''), both the question of whether ''A(x)'' &gt; 0 for some ''x'' and whether ''A(x)'' = 0 for some ''x'' are unsolvable.

By contrast, the [[Tarski–Seidenberg theorem]] says that the first-order theory of the real field is decidable, so it is not possible to remove the sine function entirely.

==See also==
*[[Constant problem]]

==References==
&lt;references /&gt;

==Further reading==
*{{cite book |last1=Petkovšek |first1=Marko |authorlink1=Marko Petkovšek |last2=Wilf |first2=Herbert S. |authorlink2=Herbert S. Wilf |last3=Zeilberger |first3=Doron |authorlink3=Doron Zeilberger |title=A&amp;nbsp;=&amp;nbsp;B |publisher=[[A. K. Peters]] |url=http://www.cis.upenn.edu/~wilf/AeqB.html |year=1996 |isbn=1-56881-063-6 |pages=212 |deadurl=yes |archiveurl=https://web.archive.org/web/20060129095451/http://www.cis.upenn.edu/~wilf/AeqB.html |archivedate=2006-01-29 |df= }}
*{{Cite news |last=Richardson |first=Daniel |year=1968 |title=Some undecidable problems involving elementary functions of a real variable|periodical=[[Journal of Symbolic Logic]] |volume=33 |issue=4 |pages=514–520 |url=https://www.jstor.org/pss/2271358 |doi=10.2307/2271358 |jstor=10.2307/2271358 |publisher=Association for Symbolic Logic}}

==External links==
*{{MathWorld|urlname=RichardsonsTheorem|title=Richardson's theorem}}

[[Category:Theorems in the foundations of mathematics]]
[[Category:Computability theory]]


{{mathlogic-stub}}</text>
      <sha1>e4ux083yequ3dud6b496vijhone3h8p</sha1>
    </revision>
  </page>
  <page>
    <title>Riemann–Hilbert problem</title>
    <ns>0</ns>
    <id>9710396</id>
    <revision>
      <id>865565137</id>
      <parentid>865498739</parentid>
      <timestamp>2018-10-24T18:12:08Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>/* References */ wikify some refs</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16215">{{For|the original problem of Hilbert concerning the existence of linear differential equations having a given monodromy group|Hilbert's twenty-first problem}}

In [[mathematics]], '''Riemann–Hilbert problems''', named after [[Bernhard Riemann]] and [[David Hilbert]], are a class of  problems  that arise in the study of [[differential equation]]s in the [[complex plane]]. Several [[existence theorem]]s for Riemann–Hilbert problems have been produced by [[Mark Krein]], [[Israel Gohberg]] and others (see the book by Clancey and Gohberg (1981)).

==The Riemann problem==
Suppose that &lt;math&gt;\Sigma&lt;/math&gt; is a closed simple contour in the complex plane dividing the plane into two parts denoted by &lt;math&gt;\Sigma_{+}&lt;/math&gt; (the inside) and &lt;math&gt;\Sigma_{-}&lt;/math&gt; (the outside), determined by the [[winding number|index]] of the contour with respect to a point.  The classical problem, considered in Riemann's PhD dissertation  (see {{harvtxt|Pandey|1996}}), was that of finding a function

:&lt;math&gt;M_+(z) = u(z) + i v(z)&lt;/math&gt;

analytic inside &lt;math&gt;\Sigma_{+}&lt;/math&gt; such that the boundary values of ''M''&lt;sub&gt;+&lt;/sub&gt; along &lt;math&gt;\Sigma&lt;/math&gt; satisfy the equation

:&lt;math&gt;a(z)u(z) - b(z)v(z) = c(z) &lt;/math&gt;

for all &lt;math&gt;z\in \Sigma&lt;/math&gt;, where ''a'', ''b'', and ''c'' are given real-valued functions {{harv|Bitsadze|2001}}.

By the [[Riemann mapping theorem]], it suffices to consider the case when &lt;math&gt;\Sigma&lt;/math&gt; is the unit circle {{harv|Pandey|1996|loc=§2.2}}.  In this case, one may seek ''M''&lt;sub&gt;+&lt;/sub&gt;(''z'') along with its [[Schwarz reflection principle|Schwarz reflection]]:

:&lt;math&gt;M_-(z) = \overline{M_+\left(\bar{z}^{-1}\right)}.&lt;/math&gt;

On the unit circle Σ, one has &lt;math&gt;z = 1/\bar{z}&lt;/math&gt;, and so

:&lt;math&gt;M_-(z) = \overline{M_+(z)},\quad z\in\Sigma.&lt;/math&gt;

Hence the problem reduces to finding a pair of functions ''M''&lt;sub&gt;+&lt;/sub&gt;(''z'') and ''M''&lt;sub&gt;&amp;minus;&lt;/sub&gt;(''z'') analytic, respectively, on the inside and the outside of the unit disc, so that on the unit circle

:&lt;math&gt;\frac{a(z)+ib(z)}{2}M_+(z) + \frac{a(z)-ib(z)}{2}M_-(z) = c(z),&lt;/math&gt;

and, moreover, so that the condition at infinity holds:

:&lt;math&gt;\lim_{z\to\infty}M_-(z) = \overline{{M}_+(0)}.&lt;/math&gt;

==The Hilbert problem==
Hilbert's generalization was to consider the problem of attempting to find ''M''&lt;sub&gt;+&lt;/sub&gt; and ''M''&lt;sub&gt;−&lt;/sub&gt; analytic, respectively, on the inside and outside of the curve Σ, such that on Σ one has

:&lt;math&gt;\alpha(z) M_+(z) + \beta(z) M_-(z) = c(z)&lt;/math&gt;

where α, β, and ''c'' are arbitrary given complex-valued functions (no longer just complex conjugates).

==Riemann–Hilbert problems==
In the Riemann problem as well as Hilbert's generalization, the contour Σ was simple.  A full Riemann–Hilbert problem allows that the contour may be composed of a union of several oriented smooth curves, with no intersections.  The + and &amp;minus; sides of the "contour" may then be determined according to the index of a point with respect to Σ.  The Riemann–Hilbert problem is to find a pair of functions, ''M''&lt;sub&gt;+&lt;/sub&gt; and ''M''&lt;sub&gt;−&lt;/sub&gt; analytic, respectively, on the + and &amp;minus; side of Σ, subject to the equation

:&lt;math&gt;\alpha(z) M_+(z) + \beta(z) M_-(z) = c(z)&lt;/math&gt;

for all ''z''∈Σ.

==Generalization: factorization problems==
Given an oriented "contour" Σ (technically: an oriented union of smooth curves without  points of infinite self-intersection in the complex plane). A '''[[Birkhoff factorization]] problem''' is the following.

Given a matrix function ''V'' defined on the contour Σ, to find a holomorphic matrix function M defined on the complement of Σ, such that two conditions be satisfied:
# If ''M''&lt;sub&gt;+&lt;/sub&gt; and ''M''&lt;sub&gt;&amp;minus;&lt;/sub&gt; denote the non-tangential limits of ''M'' as we approach Σ, then ''M''&lt;sub&gt;+&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''M''&lt;sub&gt;&amp;minus;&lt;/sub&gt;V, at all points of non-intersection in Σ.
#As ''z'' tends to infinity along any direction outside Σ, ''M'' tends to the [[identity matrix]].

In the simplest case ''V'' is smooth and integrable. In more complicated cases it could have singularities. The limits  ''M''&lt;sub&gt;+&lt;/sub&gt; and ''M''&lt;sub&gt;&amp;minus;&lt;/sub&gt; could be classical and continuous or they could be taken in the  [[square integrable|''L''&lt;sub&gt;2&lt;/sub&gt;]] sense.

==Applications to integrability theory ==

Riemann–Hilbert problems have applications to several related classes of problems.

A. [[Integrable model]]s. The [[inverse scattering]] or inverse spectral problem associated to the [[Cauchy problem]] for 1+1 dimensional [[partial differential equations]] on the line, periodic problems, or even initial-boundary value problems, can be stated as Riemann–Hilbert problems.

B. [[Orthogonal polynomials]], [[Random matrices]]. Given a weight on a contour, the corresponding orthogonal polynomials can be computed via the solution of a Riemann–Hilbert factorization problem. Furthermore, the distribution of eigenvalues of random matrices in several ensembles is reduced to computations involving orthogonal polynomials (see for example {{harvtxt|Deift|1999}}).

C. Combinatorial [[probability]]. The most celebrated example is the theorem of {{harvtxt|Baik|Deift|Johansson|1999}} on the  distribution of the length of the longest increasing subsequence of a  random permutation.

In particular, Riemann–Hilbert factorization problems are used to extract asymptotics for the three problems above (say, as time goes to infinity, or as the dispersion coefficient goes to zero, or as the polynomial degree goes to infinity, or as the size of the permutation goes to infinity). There exists a method for extracting the asymptotic behavior of solutions of Riemann–Hilbert problems, analogous to the [[method of stationary phase]] and the [[method of steepest descent]] applicable to exponential integrals.

By analogy with the classical asymptotic methods, one "deforms"  Riemann–Hilbert problems which are not explicitly solvable to problems that are. The so-called "nonlinear" method of stationary phase is due to {{harvtxt|Deift|Zhou|1993}}, expanding on a previous idea by {{harvtxt|Its|1982}} and {{harvtxt|Manakov|1979}}. A crucial ingredient of the Deift–Zhou analysis is the asymptotic analysis of singular integrals on contours.

An essential extension of the nonlinear method of stationary phase has been the introduction of the so-called finite gap g-function transformation by {{harvtxt|Deift|Venakides|Zhou|1997}}, which has been crucial in most applications. This was inspired by work of Lax, Levermore and Venakides, who reduced the analysis of the small dispersion limit of the [[KdV equation]] to the analysis of a maximization problem for a logarithmic potential under some external field: a variational problem of "electrostatic" type. The g-function is the logarithmic transform of the maximizing "equilibrium" measure. The analysis of the small dispersion limit of KdV has in fact provided the basis for the analysis of most of the work concerning "real" orthogonal polynomials (i.e. with the orthogonality condition defined on the real line)  and Hermitian random matrices.
 
Perhaps the most sophisticated extension of the theory so far is the one applied to the "non self-adjoint" case, i.e. when the underlying Lax operator (the first component of the [[Lax pair]]) is not [[self-adjoint]], by {{harvtxt|Kamvissis|McLaughlin|Miller|2003}}. In that case, actual "steepest descent contours" are defined and computed. The corresponding variational problem is a max-min problem: one looks for a contour that minimizes the "equilibrium" measure. The study of the variational problem and the proof of existence of a regular solution, under some conditions on the external field, was done in {{harvtxt|Kamvissis|Rakhmanov|2005}}; the contour arising is an "S-curve", as defined and studied in the 1980s by Herbert R. Stahl, Andrei A. Gonchar and Evguenii A Rakhmanov.

An alternative asymptotic analysis of Riemann–Hilbert factorization problems is provided in {{harvtxt|McLaughlin|Miller|2006}}, especially convenient when jump matrices do not have analytic extensions. Their method is based on the analysis of d-bar problems, rather than the asymptotic analysis of singular integrals on contours. An alternative way of dealing with jump matrices with no analytic extensions was introduced in {{harvtxt|Varzugin|1996}}.

Another extension of the theory appears in {{harvtxt|Kamvissis|Teschl|2012}} where the underlying space of the Riemann–Hilbert problem is a compact hyperelliptic Riemann surface. The right factorization problem is no more holomorphic, but rather [[Meromorphic function|meromorphic]], by reason of the [[Riemann–Roch theorem]].  The Riemann–Hilbert problem deformation theory is applied to the problem of stability of the infinite periodic [[Toda lattice]] under a "short range" perturbation (for example a perturbation of a finite number of particles).

Most Riemann–Hilbert factorization problems studied in the literature are 2-dimensional, i.e., the unknown matrices are of dimension 2. Higher-dimensional problems have been studied by [[Arno Kuijlaars]] and collaborators, see e.g. {{harvtxt|Kuijlaars|López|2015}}.

The numerical analysis of Riemann-Hilbert problems can also provide a most effective way for numerically solving integrable PDEs, see eg. Trogdon &amp; Olver (2016).

==Example: Scalar Riemann–Hilbert factorization problem==
Suppose ''V''&amp;nbsp;=&amp;nbsp;2, and Σ is a contour from ''z''&amp;nbsp;=&amp;nbsp;−1 to ''z''&amp;nbsp;=&amp;nbsp;1. What is the solution of&amp;nbsp;''M''?

To solve this, let's take the [[logarithm]] of equation &lt;math&gt;M_+=M_- V&lt;/math&gt;.
:&lt;math&gt; \log M_+(z)  = \log M_-(z) + \log 2. &lt;/math&gt; 
Since ''M'' tends to 1, log&amp;nbsp;''M'' tends to zero as ''z'' tends to infinity.

A standard fact about the [[Hilbert transform|Cauchy transform]] is that &lt;math&gt;C_+ -C_- = I &lt;/math&gt; 
where &lt;math&gt;C_+ , C_-&lt;/math&gt; are the limits of the Cauchy transform from above and below Σ; therefore, we get
:&lt;math&gt; \frac{1}{2\pi i}\int_{\Sigma_+} \frac{\log 2}{\zeta-z} \, d\zeta - \frac{1}{2\pi i} \int_{\Sigma_-} \frac{\log{2}}{\zeta-z} \, d\zeta = \log 2
\text{  when  } z\in\Sigma.
&lt;/math&gt;

Because the solution ''M'' of a Riemann–Hilbert factorization problem is unique
(an easy application of [[Liouville's theorem (complex analysis)]]), the [[Sokhotski–Plemelj theorem]]
gives the solution. We get 
:&lt;math&gt; \log M  = \frac{1}{2\pi i}\int_{\Sigma}\frac{\log{2}}{\zeta-z}d\zeta 
   = \frac{\log 2}{2\pi i}\int^{1-z}_{-1-z}\frac{1}{\zeta}d\zeta 
   = \frac{\log 2}{2\pi i} \log{\frac{z-1}{z+1}}, &lt;/math&gt;

i.e. &lt;math&gt; M(z)=\left( \frac{z-1}{z+1} \right)^{\frac{\log{2}}{2\pi i}}  &lt;/math&gt;
which has a branch cut at contour &lt;math&gt;\Sigma&lt;/math&gt;.

Check:
&lt;math&gt; M_+(0) =(e^{i\pi})^{\frac{\log 2}{2\pi i}} = e^{\frac{\log 2}{2}}, 
   M_-(0) =(e^{-i\pi})^{\frac{\log 2}{2\pi i}} = e^{-\frac{\log 2}{2}}; &lt;/math&gt;

therefore, &lt;math&gt;M_+(0)=M_-(0)e^{\log{2}}=M_-(0)2&lt;/math&gt;.

CAVEAT: If the problem is not scalar one cannot take logarithms. In general explicit solutions are very rare.

==References==

* {{citation|first1=J.|last1=Baik|first2=P.|last2=Deift|first3=K.|last3=Johansson|title=On the distribution of the length of the longest increasing subsequence of random permutations|journal=[[Journal of the American Mathematical Society]]|volume=12|year=1999|pages=1119–1178|url=http://www.ams.org/jams/1999-12-04/S0894-0347-99-00307-0/home.html}}.
* {{springer|id=b/b017400|last=Bitsadze|first=A.V.|title=Boundary value problems of analytic function theory|year=2001}}
* {{citation|first1=K.|last1=Clancey|first2=I.|last2=Gohberg|title=Factorization of matrix functions and singular integral operators|series=Oper. Theory: Advances and Appl.|volume=3|publisher=Birkhäuser Verlag|publication-place=Basel-Boston-Stuttgart|year=1981}}.
* {{citation|first=Percy A.|last=Deift|authorlink=Percy Deift|title=Orthogonal Polynomials and Random Matrices|publisher=[[American Mathematical Society]]|year=2000|isbn=978-0-8218-2695-9}}.
* {{citation|first1=Percy|last1=Deift|first2=S.|last2=Venakides|first3=X.|last3=Zhou|title=New Results in Small Dispersion  KdV  by an Extension of the Steepest Descent Method for Riemann–Hilbert Problems|series=International Mathematical Research Notices|year=1997|pages=286–299}}.
* {{citation|first1=Percy|last1=Deift|authorlink1=Percy Deift|first2=X.|last2=Zhou|title=A Steepest Descent Method for Oscillatory Riemann–Hilbert Problems; Asymptotics for the MKdV Equation|journal=[[Annals of Mathematics]] | series = Second Series|volume=137|year=1993|issue=2|pages=295&amp;ndash;368|doi=10.2307/2946540|arxiv=math/9201261}}.
* {{springer|first=G.|last=Khimshiashvili|title=Birkhoff factorization|id=b/b120240}}.
* {{citation|first=A.R.|last=Its|title=Asymptotics of Solutions of the Nonlinear Schrödinger Equation and Isomonodromic Deformations of Systems of Linear Differential Equations|journal=Soviet Mathematics - Doklady|volume=24|issue=3|year=1982|pages=14–18}}.
* {{citation|first=A.R.|last=Its|title=The Riemann–Hilbert Problem and Integrable Systems|journal=Notices of the AMS|volume=50|issue=11|year=2003|pages=1389–1400| url=http://www.ams.org/notices/200311/fea-its.pdf}}.
* {{citation|first1=S.|last1=Kamvissis|first2=K.|last2=McLaughlin|first3=P.|last3=Miller|title=Semiclassical Soliton Ensembles for the Focusing Nonlinear Schrödinger Equation|series=Annals of Mathematics|issue=Study 154|publisher=Princeton University Press|publication-place=Princeton|year=2003}}.
* {{citation|first1=S.|last1=Kamvissis|first2=E.A.|last2=Rakhmanov|title=Existence and Regularity for an Energy Maximization Problem in Two Dimensions|journal=[[Journal of Mathematical Physics]]|volume=46|issue=8|pages=083505|year=2005|doi=10.1063/1.1985069|bibcode = 2005JMP....46h3505K |arxiv=0907.5571}}.
* {{citation|first1=S.|last1=Kamvissis|first2=G.|last2=Teschl|authorlink2=Gerald Teschl|title=Long-time asymptotics of the periodic Toda lattice under short-range perturbations|journal=J. Math. Phys.|volume=53|issue=7|pages=073706|year=2012|doi=10.1063/1.4731768|arxiv = 0705.0346 |bibcode = 2012JMP....53g3706K }}.
* {{citation|first1=Arno|last1=Kuijlaars|first2=Abey|last2=López|title=A vector equilibrium problem for the normal matrix model, and multiple orthogonal polynomials on a star |journal=Nonlinearity|volume=28|year=2015|pages=347–406|arxiv=1401.2419|bibcode=2015Nonli..28..347K|doi=10.1088/0951-7715/28/2/347}}.
* {{citation|first1=Peter D.|last1=Lax|authorlink1=Peter D. Lax|first2=C.D.|last2=Levermore|title=The Zero Dispersion Limit for the KdV Equation I-III|journal=[[Communications on Pure and Applied Mathematics]]|volume=36|year=1983|pages=253–290, 571–593, 809–829}}.
* {{citation|first1=S.V.|last1=Manakov|title=Nonlinear Fraunnhofer diffraction|journal=Sov. Phys. JETP|volume=38|pages=693–696|year=1974|bibcode = 1974JETP...38..693M }}.
* {{citation|first1=K.|last1=McLaughlin|first2=P.|last2=Miller|title=The d-bar steepest descent method and the asymptotic behavior of polynomials orthogonal on the unit circle with fixed and exponentially varying nonanalytic weights|journal=IMRP|year=2006|pages=1–77}}.
*  {{citation|first=J.N.|last=Pandey|title=The Hilbert transform of Schwartz distributions and applications|publisher=Wiley-Interscience|year=1996}}.
* {{citation|first=G.G.|last=Varzugin|title=Asymptotics of oscillatory Riemann-Hilbert problems|journal= [[Journal of Mathematical Physics]] |volume=37|issue=11|year=1996}}.
* {{citation|first1=Thomas |last1=Trogdon |first2=Sheehan |last2=Olver|title= Riemann–Hilbert Problems, Their Numerical Solution, and the Computation of Nonlinear Special Functions|publisher= SIAM |year=2016}}.

== External links ==
*{{springer
 | title=Riemann–Hilbert problem
 | id= r/r081900
 | last= Gakhov
 | first= F.D.
 | author-link=Fyodor Gakhov
}}

{{DEFAULTSORT:Riemann-Hilbert problem}}
[[Category:Complex analysis]]
[[Category:Exactly solvable models]]
[[Category:Solitons]]
[[Category:Scattering theory]]
[[Category:Harmonic analysis]]
[[Category:Microlocal analysis]]
[[Category:Ordinary differential equations]]
[[Category:Partial differential equations]]
[[Category:Mathematical problems]]
[[Category:Bernhard Riemann]]</text>
      <sha1>eft9pdoqxx8wwv3t6b3980uxex5wx4i</sha1>
    </revision>
  </page>
  <page>
    <title>Risk cybernetics</title>
    <ns>0</ns>
    <id>38212767</id>
    <revision>
      <id>869354260</id>
      <parentid>821100386</parentid>
      <timestamp>2018-11-18T02:18:24Z</timestamp>
      <contributor>
        <username>Protocol99</username>
        <id>32766110</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1527">{{one source|date=January 2013}}

'''Risk cybernetics''' by Finamatrix.com (Author: Lanz Chan, Ph.D.) is a [[risk management]] blockchain project comprising risk specification and risk control techniques using advanced [[artificial intelligence]] and [[computing technology|computing technologies]] with [[feedback|circular-causal volatility-feedback]] in a [[genetic algorithm]] [[neural network]] (GANN) framework. More generally, risk cybernetics refers to risk management techniques which combine human and computer capabilities and functions in a circular-causal network/system. The objective of risk cybernetics is to achieve self-learning, self-enhancing and full-automation capabilities so as to reduce accidents, errors, etc. and obtain predictable and sustainable returns which can be applied to any industry including applications in [[Speculation#Volatility|market data]], [[Financial time series analysis|financial time series]], [[cyber security]] measures, robotics, etc.&lt;ref&gt;{{cite web | url=https://www.reuters.com/article/2011/02/01/idUS199803+01-Feb-2011+BW20110201 | title=Research and Markets: RISK CYBERNETICS: Training Manual Version 1.0 | publisher=Reuters | date=Feb 1, 2011 | accessdate=2013-05-17}}&lt;/ref&gt;&lt;ref&gt;{{cite web | ssrn=1687763 | title=Automated Trading with Genetic-Algorithm Neural-Network Risk Cybernetics: An Application on FX Markets | publisher=SSRN | date=Feb 20, 2012 | accessdate=2013-06-16}}&lt;/ref&gt; 

== References ==
{{reflist}}

[[Category:Risk management]]
[[Category:Cybernetics]]</text>
      <sha1>3vhkari2gvc1bdhoperk7oj7jiv5535</sha1>
    </revision>
  </page>
  <page>
    <title>Shear mapping</title>
    <ns>0</ns>
    <id>799405</id>
    <revision>
      <id>838489270</id>
      <parentid>829466741</parentid>
      <timestamp>2018-04-27T10:33:34Z</timestamp>
      <contributor>
        <username>Kmhkmh</username>
        <id>3586174</id>
      </contributor>
      <comment>/* Applications */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8001">[[Image:VerticalShear m=1.25.svg|thumb|175px|right|alt=Mesh Shear 5/4|A horizontal shearing of the plane with coefficient ''m'' = 1.25, illustrated by its effect (in green) on a rectangular grid and some figures (in blue). The black dot is the origin.]]
In [[plane geometry]], a '''shear mapping''' is a [[linear map]] that displaces each point in fixed direction, by an amount proportional to its [[signed distance function|signed distance]] from a [[straight line|line]] that is [[parallel (geometry)|parallel]] to that direction.&lt;ref&gt;Definition according to Weisstein, Eric W. [http://mathworld.wolfram.com/Shear.html Shear] From MathWorld − A Wolfram Web Resource&lt;/ref&gt;  This type of mapping is also called '''shear transformation''', '''transvection''', or just '''shearing'''.

An example is the mapping that takes any point with [[Cartesian coordinates|coordinates]] &lt;math&gt;(x,y)&lt;/math&gt; to the point &lt;math&gt;(x + 2y,y)&lt;/math&gt;.  In this case, the displacement is horizontal, the fixed line is the &lt;math&gt;x&lt;/math&gt;-axis, and the signed distance is the &lt;math&gt;y&lt;/math&gt; coordinate.  Note that points on opposite sides of the reference line are displaced in opposite directions.

Shear mappings must not be confused with [[rotation (geometry)|rotation]]s. Applying a shear map to a set of points of the plane will change all [[angle]]s between them (except [[straight angle]]s), and the length of any [[line segment]] that is not parallel to the direction of displacement. Therefore it will usually distort the shape of a geometric figure, for example turning squares into non-square [[parallelogram]]s, and [[circle]]s into [[ellipse]]s.  However a shearing does preserve the [[area]] of geometric figures and the alignment and relative distances of [[collinear]] points.  A shear mapping is the main difference between the upright and [[italic font|slanted (or italic)]] styles of [[Latin alphabet|letter]]s.

[[File:Laminar_shear.svg|thumb|200px|right|In [[fluid dynamics]] a shear mapping depicts fluid flow between parallel plates in relative motion.]]
The same definition is used in [[three-dimensional geometry]], except that the distance is measured from a fixed plane.  A three-dimensional shearing transformation preserves the volume of solid figures, but changes areas of plane figures (except those that are parallel to the displacement). 
This transformation is used to describe [[laminar flow]] of a fluid between plates, one moving in a plane above and parallel to the first.

In the general &lt;math&gt;n&lt;/math&gt;-dimensional [[Cartesian geometry|Cartesian space]] &lt;math&gt;\mathbb{R}^n&lt;/math&gt;, the distance is measured from a fixed [[hyperplane]] parallel to the direction of displacement.  This geometric transformation is a [[linear transformation]] of &lt;math&gt;\mathbb{R}^n&lt;/math&gt; that preserves the &lt;math&gt;n&lt;/math&gt;-dimensional [[measure (mathematics)|measure]] (hypervolume) of any set.

==Definition==

===Horizontal and vertical shear of the plane===
[[File:Academ Study about a periodic tiling by regular polygons.svg|thumb|upright=1.5|Through a '''shear mapping''' coded '''[[Scalable Vector Graphics|in&amp;nbsp;SVG]]''',&lt;br/&gt;a [[rectangle]] becomes a [[parallelogram]].]]
In the plane &lt;math&gt;\mathbb{R}^2 = \mathbb{R}\times\mathbb{R}&lt;/math&gt;, a '''horizontal shear''' (or '''shear parallel''' to the ''x'' axis) is a function that takes a generic point with coordinates &lt;math&gt;(x,y)&lt;/math&gt; to the point &lt;math&gt;(x + m y,y)&lt;/math&gt;; where &lt;math&gt;m&lt;/math&gt; is a fixed parameter, called the '''shear factor'''.

The effect of this mapping is to displace every point horizontally by an amount proportionally to its &lt;math&gt;y&lt;/math&gt; coordinate.  Any point above the &lt;math&gt;x&lt;/math&gt;-axis is displaced to the right (increasing &lt;math&gt;x&lt;/math&gt;) if &lt;math&gt;m &gt; 0&lt;/math&gt;, and to the left if &lt;math&gt;m &lt; 0&lt;/math&gt;. Points below the &lt;math&gt;x&lt;/math&gt;-axis move in the opposite direction, while points on the axis  stay fixed.

Straight lines parallel to the &lt;math&gt;x&lt;/math&gt;-axis remain where they are, while all other lines are turned, by various angles, about the point where they cross the &lt;math&gt;x&lt;/math&gt;-axis.  Vertical lines, in particular, become [[Angle#Types of angles|oblique]] lines with [[slope]] &lt;math&gt;1/m&lt;/math&gt;. Therefore the shear factor &lt;math&gt;m&lt;/math&gt; is the [[cotangent]] of the angle &lt;math&gt;\varphi&lt;/math&gt; by which the vertical lines tilt, called the '''shear angle'''.

If the coordinates of a point are written as a column vector (a 2×1 [[matrix (mathematics)|matrix]]), the shear mapping can be written as [[matrix product|multiplication]] by a [[2 × 2 real matrices|2×2 matrix]]:
: &lt;math&gt;
  \begin{pmatrix}x^\prime \\y^\prime \end{pmatrix}  =
  \begin{pmatrix}x + m y \\y \end{pmatrix} =
  \begin{pmatrix}1 &amp; m\\0 &amp; 1\end{pmatrix} 
    \begin{pmatrix}x \\y \end{pmatrix}.
&lt;/math&gt;

A '''vertical shear''' (or shear parallel to the &lt;math&gt;y&lt;/math&gt;-axis) of lines is similar, except that the roles of &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are swapped. It corresponds to multiplying the coordinate vector by the [[transpose of a matrix|transposed matrix]]:

:&lt;math&gt;
  \begin{pmatrix}x^\prime \\y^\prime \end{pmatrix}  = 
  \begin{pmatrix}x \\ m x + y \end{pmatrix} = 
  \begin{pmatrix}1 &amp; 0\\m &amp; 1\end{pmatrix} 
    \begin{pmatrix}x \\y \end{pmatrix}.
&lt;/math&gt;

The vertical shear displaces points to the right of the &lt;math&gt;y&lt;/math&gt;-axis up or down, depending on the sign of &lt;math&gt;m&lt;/math&gt;.  It leaves vertical lines invariant, but tilts all other lines about the point where they meet the &lt;math&gt;y&lt;/math&gt;-axis.  Horizontal lines, in particular, get tilted by the shear angle &lt;math&gt;\varphi&lt;/math&gt; to become lines with slope &lt;math&gt;m&lt;/math&gt;.

===General shear mappings===
For a [[vector space]] ''V'' and subspace ''W'', a shear fixing ''W'' translates all vectors parallel to ''W''.

To be more precise, if ''V'' is the [[direct sum of vector spaces|direct sum]] of ''W'' and ''W&amp;prime;'', and we write vectors as

:''v'' = ''w'' + ''w&amp;prime;''

correspondingly, the typical shear fixing ''W'' is ''L'' where

:''L''(''v'') = (''w'' + ''Mw&amp;prime;'') + ''w&amp;nbsp;&amp;prime;''

where ''M'' is a linear mapping from ''W&amp;prime;'' into ''W''. Therefore in [[block matrix]] terms ''L'' can be represented as

:&lt;math&gt;\begin{pmatrix} I &amp; M \\ 0 &amp; I \end{pmatrix} &lt;/math&gt;

==Applications==
The following applications of shear mapping were noted by [[William Kingdon Clifford]]:
:"A succession of shears will enable us to reduce any figure bounded by straight lines to a triangle of equal area."
:"... we may shear any triangle into a right-angled triangle, and this will not alter its area. Thus the area of any triangle is half the area of the rectangle on the same base and with height equal to the perpendicular on the base from the opposite angle."&lt;ref&gt;[[William Kingdon Clifford]] (1885) ''Common Sense and the Exact Sciences'', page 113&lt;/ref&gt;

The area-preserving property of a shear mapping can be used for results involving area. For instance, the [[Pythagorean theorem]] has been illustrated with shear mapping&lt;ref&gt;Hohenwarter, M [http://tube.geogebra.org/m/125392 Pythagorean theorem by shear mapping]; made using [[GeoGebra]]. Drag the sliders to observe the shears&lt;/ref&gt; as well as the related [[Geometric_mean_theorem#Based_on_shear_mappings|geometric mean theorem]].

An algorithm due to Alan W. Paeth uses a sequence of three shear mappings (horizontal, vertical, then horizontal again) to rotate a [[digital image]] by an arbitrary angle.  The algorithm is very simple to implement, and very efficient, since each step processes only one column or one row of [[pixel]]s at a time.&lt;ref&gt;Alan Paeth (1986), [http://www.cipprs.org/papers/VI/VI1986/pp077-081-Paeth-1986.pdf ''A Fast Algorithm for General Raster Rotation''.] Proceedings of Graphics Interface '86, pages 77–81.&lt;/ref&gt;

The [[oblique type]] can be thought of as normal text under a shear.

==See also==

* [[Shear matrix]]

==References==
{{commons category|Shear (geometry)}}
{{reflist}}

[[Category:Functions and mappings]]
[[Category:Linear algebra]]</text>
      <sha1>3t56lw573481r5o0pxiiszalirgh0xp</sha1>
    </revision>
  </page>
  <page>
    <title>Sir Henry Percy Gordon, 2nd Baronet</title>
    <ns>0</ns>
    <id>31077099</id>
    <revision>
      <id>860097613</id>
      <parentid>842651296</parentid>
      <timestamp>2018-09-18T09:43:36Z</timestamp>
      <contributor>
        <username>Deb</username>
        <id>1219</id>
      </contributor>
      <minor/>
      <comment>improve link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1809">'''Sir Henry Percy Gordon, 2nd Baronet''' [[Fellow of the Royal Society|FRS]] (21 October 1806 &amp;ndash; 29 July 1876).

He was the only son of [[Willoughby Gordon|Sir James Willoughby Gordon, 1st Baronet]], succeeding to his father's title in 1851.

He entered [[Peterhouse, Cambridge]] in 1823 and was [[senior wrangler]] and 2nd [[Smith's Prize|Smith's prizeman]] in 1827.  He received an [[Master of Arts (Oxbridge and Dublin)|M.A.]] in 1830.

He became a [[Fellow of the Royal Society]] in 1830.

He was admitted to [[Lincoln's Inn]] in 1828 and [[called to the bar]] in 1831. He was a [[Justice of the peace]] and [[deputy lieutenant]] for the [[Isle of Wight]].

In 1839 he married Lady Mary Agnes Blanche Ashburnham, daughter of [[George Ashburnham, 3rd Earl of Ashburnham]].

He had at least one daughter, Mary Charlotte Julia Gordon.  At his death, the baronetcy became extinct.
[[File:Memorial to Sir Henry Percy Gordon, 2nd Baronet, in St Peter's Church, Shorwell, Isle of Wight.jpg|thumb|Memorial to Sir Henry Percy Gordon, 2nd Baronet, in [[St Peter's Church, Shorwell]], Isle of Wight]]

==External links==
* {{cite book
 |last=Neale |first=Charles Montague |year=1907 
 |title= The senior wranglers of the University of Cambridge, from 1748 to 1907. With biographical, &amp; c., notes
 |page=31
 |url=https://archive.org/stream/senoirwranglerso00nealrich#page/30/mode/2up|accessdate=2011-03-04
 |publisher=Groom and Son
 |location=Bury St. Edmunds
}}
* {{acad|id=GRDN823HP|name=Gordon, Henry Percy}}
* [http://www.thepeerage.com/p2678.htm#i26779 Sir Henry Percy Gordon, 2nd Bt.] (thePeerage.com)

{{DEFAULTSORT:Gordon, Henry Percy}}
[[Category:1806 births]]
[[Category:1876 deaths]]
[[Category:Fellows of the Royal Society]]
[[Category:Alumni of Peterhouse, Cambridge]]
[[Category:Senior Wranglers]]</text>
      <sha1>0agre2yk8k404p0ews32lzom5jkv7ig</sha1>
    </revision>
  </page>
  <page>
    <title>Soma cube</title>
    <ns>0</ns>
    <id>36670</id>
    <revision>
      <id>862161694</id>
      <parentid>862161659</parentid>
      <timestamp>2018-10-02T15:26:04Z</timestamp>
      <contributor>
        <username>JC7V7DC5768</username>
        <id>34198373</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/82.26.206.146|82.26.206.146]] ([[User talk:82.26.206.146|talk]]): Rv joke/test. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8185">[[Image:Soma-cube-disassembled.jpg|thumb|The pieces of a Soma cube (with extra coloring)]]
[[Image:Soma-cube-assembled.jpg|thumb|The same puzzle, assembled into a cube]]
The '''Soma cube''' is a [[mechanical puzzle|solid dissection puzzle]] invented by [[Piet Hein (scientist)|Piet Hein]] in 1933&lt;ref&gt;{{cite web| url = http://www.fam-bundgaard.dk/SOMA/NEWS/N030310.HTM| title = The birth of SOMA| accessdate = 2010-12-04| author = Ole Poul Pedersen| editor = Thorleif Bundgaard|date=February 2010}}&lt;/ref&gt; during a lecture on [[quantum mechanics]] conducted by [[Werner Heisenberg]]. Its name is alleged to be derived from the fictitious drug ''soma'' consumed as a pastime by [[the establishment]] in [[Aldous Huxley]]'s [[Dystopia|dystopic]] novel ''[[Brave New World]]''.&lt;ref&gt;Cf. [[Martin Gardner]] (1961). ''The 2nd Scientific American Book of Mathematical Puzzles &amp; Diversions''. New York: Simon &amp; Schuster. Reprinted in 1987 by University of Chicago Press, {{ISBN|0-226-28253-8}}, p. 65 ([https://bobson.ludost.net/copycrime/mgardner/gardner02.pdf#page=64 online]).&lt;/ref&gt;

Seven pieces made out of unit cubes must be assembled into a 3×3×3 cube. The pieces can also be used to make a variety of other [[Three-dimensional space|3D]] shapes.

The pieces of the Soma cube consist of all possible combinations of three or four unit cubes, joined at their faces, such that at least one inside corner is formed. There is one combination of three cubes that satisfies this condition, and six combinations of four cubes that satisfy this condition, of which two are mirror images of each other (see [[Chirality (mathematics)|Chirality]]). Thus, 3 + (6 × 4) is 27, which is exactly the number of cells in a 3×3×3 cube.

The Soma cube was analyzed in detail by [[John Horton Conway]] on September 1958 in [[Mathematical Games column]] in ''[[Scientific American]]'', and the book ''[[Winning Ways for your Mathematical Plays]]'' also contains a detailed analysis of the Soma cube problem.

There are 240 distinct solutions of the Soma cube puzzle, excluding rotations and reflections: these are easily generated by a simple [[Recursion|recursive]] [[backtracking search]] computer program similar to that used for the [[eight queens puzzle]]. Current world record for the fastest time to solve a soma cube is 2.93 seconds and was set by [[Krishnam Raju Gadiraju]], [[India]].&lt;ref&gt;{{cite web|url=http://www.guinnessworldrecords.com/world-records/435864-fastest-time-to-complete-a-soma-cube/|title=Fastest time to complete a Soma cube|work=guinnessworldrecords.com}}&lt;/ref&gt;

==Pieces==
The seven Soma pieces are six [[polycube]]s of order four, and one of order three:
* [[Image:Soma-ra.svg|60x40px]] Piece 1, or "V".
* [[Image:Soma-l.svg|60x40px]] Piece 2, or "L": a row of three blocks with one added below the left side.
* [[Image:Soma-t.svg|60x40px]] Piece 3, or "T": a row of three blocks with one added below the center.
* [[Image:Soma-s.svg|60x40px]] Piece 4, or "Z": bent triomino with block placed on outside of clockwise side.
* [[Image:Soma-rscrew.svg|60x40px]] Piece 5, or "A": unit cube placed on top of clockwise side. Chiral in 3D.
* [[Image:Soma-lscrew.svg|60x40px]] Piece 6, or "B": unit cube placed on top of anticlockwise side. [[Chirality (mathematics)|Chiral]] in 3D.
* [[Image:Soma-branch.svg|60x40px]] Piece 7, or "P": unit cube placed on bend. Not chiral in 3D.&lt;ref&gt;{{cite web|last=Bundgaard|first=Thorleif|title=Why are the pieces labelled as they are|url=http://www.fam-bundgaard.dk/SOMA/NEWS/N111114.HTM|work=SOMA News|accessdate=10 August 2012}}&lt;/ref&gt;

==Production==
[[Piet Hein (Denmark)|Piet Hein]] authorized a finely crafted [[rosewood]] version of the Soma cube manufactured by Theodor Skjøde Knudsen's company Skjøde Skjern (of Denmark). Beginning in about 1967, it was marketed in the U.S. for several years by the game manufacturer [[Parker Brothers]]. Plastic Soma cube sets were also commercially produced by Parker Brothers in several colors (blue, red, and orange) during the 1970s. The package for the Parker Brothers version claimed there were 1,105,920 possible solutions. This figure includes rotations and reflections of each solution as well as rotations of the individual pieces. The puzzle is currently sold as a logic game by ThinkFun (formerly Binary Arts) under the name Block by Block.

==Solutions==
[[File:Soma cube solution.svg|thumb|One of the possible ways of assembling the Soma cube]]
Solving the Soma cube has been used as a task to measure individuals' performance and effort in a series of psychology experiments. In these experiments, test subjects are asked to solve a soma cube as many times as possible within a set period of time. For example, In 1969, [[Edward Deci]], a Carnegie Mellon University graduate assistant at the time,&lt;ref&gt;Pink, Daniel H. (2009). "Drive, The Surprising Truth About What Motivates Us". Riverhead Books.&lt;/ref&gt; asked his research subjects to solve a soma cube under conditions with varying incentives in his dissertation work on [[intrinsic motivation|intrinsic]] and [[extrinsic motivation|extrinsic]] motivation establishing the [[social psychological]] theory of [[Motivation crowding theory|crowding out]].

In each of the 240 solutions to the cube puzzle, there is only one place that the "T" piece can be placed. Each solved cube can be rotated such that the "T" piece is on the bottom with its long edge along the front and the "tongue" of the "T" in the bottom center cube (this is the normalized position of the large cube). This can be proven as follows: If you consider all the possible ways that the "T" piece can be placed in the large cube (without regard to any of the other pieces), it will be seen that it will always fill either two corners of the large cube or zero corners. There is no way to orient the "T" piece such that it fills only one corner of the large cube. The "L" piece can be oriented such that it fills two corners, or one corner, or zero corners. Each of the other five pieces have no orientation that fills two corners; they can fill either one corner or zero corners. Therefore, if you exclude the "T" piece, the maximum number of corners that can be filled by the remaining six pieces is seven (one corner each for five pieces, plus two corners for the "L" piece). A cube has eight corners. But the "T" piece cannot be oriented to fill just that one remaining corner, and orienting it such that it fills zero corners will obviously not make a cube. Therefore, the "T" must always fill two corners, and there is only one orientation (discounting rotations and reflections) in which it does that. It also follows from this that in all solutions, five of the remaining six pieces will fill their maximum number of corners and one piece will fill one fewer than its maximum (this is called the deficient piece).&lt;ref&gt;{{citation|url=http://www.fam-bundgaard.dk/SOMA/NEWS/N030518.HTM|title=The complete "SOMAP" is found|journal=SOMA News|first=William|last=Kustes|date=May 18, 2003|accessdate=April 25, 2014}}.&lt;/ref&gt;

==Similar puzzles==
Similar to Soma cube is the 3D [[pentomino]] puzzle, which can fill boxes of 2×3×10, 2×5×6 and 3×4×5 units.

The [[Bedlam cube]] is a 4×4×4 sided cube puzzle consisting of twelve [[pentacube]]s and one [[Polycube|tetracube]]. The [[Diabolical cube]] is a puzzle of six polycubes that can be assembled together to form a single 3×3×3 cube.

==See also==
* [[Tangram]]
* [[Tetromino]]
* [[Tromino]]
* [[Snake cube]]

==References==
{{Reflist}}

==External links==
{{commons|Soma cube|Soma cube}}
* [https://play.google.com/store/apps/details?id=com.egemen.egemen Soma Cube android game]
* [https://itunes.apple.com/us/app/soma-cubes-lite/id1030396427?mt=8 Soma Cube Lite iOS game]
* http://www.mathematik.uni-bielefeld.de/~sillke/POLYCUBE/SOMA/cube-secrets
* [http://mathworld.wolfram.com/SomaCube.html Soma Cube – from MathWorld]
* [http://www.fam-bundgaard.dk/SOMA/SOMA.HTM Thorleif's SOMA page]
* [https://www.youtube.com/watch?v=9ngzN2RQEtM SOMA CUBE ANIMATION by TwoDoorsOpen and Friends]


{{Polyforms}}

[[Category:Mechanical puzzle cubes]]
[[Category:Tiling puzzles]]
[[Category:Recreational mathematics]]</text>
      <sha1>hohcetr49opaubt7g5y7rfp4u69ewoh</sha1>
    </revision>
  </page>
  <page>
    <title>SpiNNaker</title>
    <ns>0</ns>
    <id>35891416</id>
    <revision>
      <id>869219310</id>
      <parentid>868939859</parentid>
      <timestamp>2018-11-17T04:55:47Z</timestamp>
      <contributor>
        <username>Cryptc</username>
        <id>19527221</id>
      </contributor>
      <comment>Fixed details of processor count vs core count.  Added RAM and power usage.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9199">{{Infobox project
| name = SpiNNaker: Spiking Neural Network Architecture
| logo = 
| website =  {{URL|http://apt.cs.manchester.ac.uk/projects/SpiNNaker/}} 
| commercial = 
| type = [[neuromorphic engineering|neuromorphic]]
| location = [[Manchester, UK]]
| owner = 
| founderimage = 
| founder = [[Steve Furber]] 
| date_of_establishment = &lt;!-- {{Start date|YYYY|MM|DD|df=y}} --&gt;
| date_of_disestablishment = &lt;!-- {{End date|YYYY|MM|DD|df=y}} --&gt;
}}'''SpiNNaker''' ('''Spiking Neural Network Architecture''') is a [[massively parallel (computing)|massively parallel]], [[manycore]] [[supercomputer architecture]] designed by the Advanced Processor Technologies Research Group (APT) at the [[School of Computer Science, University of Manchester]].&lt;ref&gt;[http://www.cs.manchester.ac.uk/our-research/groups/advanced-processor-technologies/ Advanced Processor Technologies Research Group]&lt;/ref&gt;  It is composed of 57,600 [[ARM9|ARM9 processors]] (specifically ARM968), each with 18 cores and 128MB of [[Mobile DDR|mobile DDR SDRAM]], totaling 1,036,800 cores and over 7TB of RAM.&lt;ref&gt;{{Cite web|url=http://apt.cs.manchester.ac.uk/projects/SpiNNaker/SpiNNchip/|title=SpiNNaker Project - The SpiNNaker Chip|last=|first=|date=|website=apt.cs.manchester.ac.uk|language=en|archive-url=|archive-date=|dead-url=|access-date=2018-11-17}}&lt;/ref&gt;  The computing platform is based on [[spiking neural networks]], useful in simulating the [[human brain]] (see [[Human Brain Project]]).&lt;ref name="UoM"&gt;{{citation |title=SpiNNaker Home Page |url=http://apt.cs.manchester.ac.uk/projects/SpiNNaker/ |publisher=University of Manchester |accessdate=11 June 2012}}&lt;/ref&gt;&lt;ref name="PIEEE"&gt;{{Cite journal | doi = 10.1109/JPROC.2014.2304638| title = The SpiNNaker Project| journal = Proceedings of the IEEE| pages = 1| year = 2014| last1 = Furber | first1 = S. B. | authorlink1 = Steve Furber| last2 = Galluppi | first2 = F. | last3 = Temple | first3 = S. | last4 = Plana | first4 = L. A. }}&lt;/ref&gt;&lt;ref name="IEEE"&gt;{{Cite book| last1 = Xin Jin| last2 = Furber | first2 = S. B.| authorlink2 = Steve Furber| last3 = Woods | first3 = J. V.| doi = 10.1109/IJCNN.2008.4634194| chapter = Efficient modelling of spiking neural networks on a scalable chip multiprocessor  |title = 2008 IEEE International Joint Conference on Neural Networks (IEEE World Congress on Computational Intelligence)| pages = 2812–2819| year = 2008| isbn = 978-1-4244-1820-6| pmid =  | pmc = | postscript = }}&lt;/ref&gt;&lt;ref&gt;[http://www.eetimes.com/electronics-news/4217840/Million-ARM-cores-brain-simulator A million ARM cores to host brain simulator] News article on the project in the [[EE Times]]&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Temple | first1 = S. | last2 = Furber | first2 = S. | authorlink2 = Steve Furber| doi = 10.1098/rsif.2006.0177 | title = Neural systems engineering | journal = Journal of the Royal Society Interface | volume = 4 | issue = 13 | pages = 193 | year = 2007 | pmid =  | pmc = 2359843}} A manifesto for the SpiNNaker project, surveying and reviewing the general level of understanding of brain function and approaches to building computer modelof the brain.&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Plana | first1 = L. A. | last2 = Furber | first2 = S. B. | authorlink2 = Steve Furber| last3 = Temple | first3 = S. | last4 = Khan | first4 = M. | last5 = Shi | first5 = Y. | last6 = Wu | first6 = J. | last7 = Yang | first7 = S. | doi = 10.1109/MDT.2007.149 | title = A GALS Infrastructure for a Massively Parallel Multiprocessor | journal = IEEE Design &amp; Test of Computers | volume = 24 | issue = 5 | pages = 454 | year = 2007 | pmid =  | pmc = }} A description of the Globally Asynchronous, Locally Synchronous (GALS) nature of SpiNNaker, with an overview of the asynchronous communications hardware designed to transmit neural 'spikes' between processors.&lt;/ref&gt;&lt;ref&gt;{{Cite book | doi = 10.1145/1542275.1542317| chapter = Understanding the interconnection network of SpiNNaker| title = Proceedings of the 23rd international conference on Conference on Supercomputing - ICS '09| pages = 286| year = 2009| last1 = Navaridas | first1 = J. | last2 = Luján | first2 = M. | last3 = Miguel-Alonso | first3 = J. | last4 = Plana | first4 = L. A. | last5 = Furber | first5 = S. | isbn = 9781605584980}} Modelling and analysis of the SpiNNaker interconnect in a million-core machine, showing the suitability of the packet-switched network for large-scale spiking neural network simulation.&lt;/ref&gt;&lt;ref&gt;{{Cite journal 
| last1 = Rast | first1 = A. 
| last2 = Galluppi | first2 = F. 
| last3 = Davies | first3 = S. 
| last4 = Plana | first4 = L. 
| last5 = Patterson | first5 = C. 
| last6 = Sharp | first6 = T. 
| last7 = Lester | first7 = D. 
| last8 = Furber | first8 = S. 
| authorlink8 = Steve Furber
| doi = 10.1016/j.neunet.2011.06.014 
| title = Concurrent heterogeneous neural model simulation on real-time neuromimetic hardware 
| journal = Neural Networks 
| volume = 24 
| issue = 9 
| pages = 961–978 
| year = 2011 
| pmid = 21778034 
| pmc = 
}} A demonstration of SpiNNaker's ability to simulate different neural models (simultaneously, if necessary) in contrast to other neuromorphic hardware.&lt;/ref&gt;&lt;ref&gt;{{Cite journal | last1 = Sharp | first1 = T. | last2 = Galluppi | first2 = F. | last3 = Rast | first3 = A. | last4 = Furber | first4 = S. | authorlink4 = Steve Furber| title = Power-efficient simulation of detailed cortical microcircuits on SpiNNaker | doi = 10.1016/j.jneumeth.2012.03.001 | journal = Journal of Neuroscience Methods | volume = 210 | issue = 1 | pages = 110–118 | year = 2012 | pmid = 22465805 | pmc = }} Four-chip, real-time simulation of a four-million-synapse cortical circuit, showing the extreme energy efficiency of the SpiNNaker architecture&lt;/ref&gt;

The completed design is housed in 10 [[19-inch rack]]s, with each rack holding over 100,000 cores.&lt;ref name="computerphile"&gt;[https://www.youtube.com/watch?v=2e06C-yUwlc Video interview by computerphile with Steve Furber]&lt;/ref&gt; The cards holding the chips are held in 5 [[Blade server#Blade enclosure|Blade enclosure]]s, and each core emulates 1000 [[Neuron]]s.&lt;ref name="computerphile"/&gt;  In total, the goal is to simulate the behavior of aggregates of up to a billion neurons in real time.&lt;ref&gt;{{Cite web|url=http://apt.cs.manchester.ac.uk/projects/SpiNNaker/architecture/|title=SpiNNaker Project - Architectural Overview|last=|first=|date=|website=apt.cs.manchester.ac.uk|language=en|archive-url=|archive-date=|dead-url=|access-date=2018-11-17}}&lt;/ref&gt;  This machine requires about 100kW from a 240V [[Power supply|supply]] and an air-conditioned environment.&lt;ref&gt;{{Cite web|url=http://apt.cs.manchester.ac.uk/projects/SpiNNaker/hardware/|title=SpiNNaker Project - Boards and Machines|last=|first=|date=|website=apt.cs.manchester.ac.uk|language=en|archive-url=|archive-date=|dead-url=|access-date=2018-11-17}}&lt;/ref&gt;

SpiNNaker is being used as one component of the [[neuromorphic engineering|neuromorphic computing]] platform for the [[Human Brain Project]].&lt;ref&gt;{{Cite journal
 | pmid = 24139655
| year = 2013
| author1 = Calimera
| first1 = A
| title = The Human Brain Project and neuromorphic computing
| journal = Functional neurology
| volume = 28
| issue = 3
| pages = 191–6
| last2 = Macii
| first2 = E
| last3 = Poncino
| first3 = M
| pmc = 3812737
}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal | doi = 10.1145/2601069| title = Neuromorphic computing gets ready for the (really) big time| journal = [[Communications of the ACM]]| volume = 57| issue = 6| year = 2014| last1 = Monroe | first1 = D. | pages = 13–15}}&lt;/ref&gt;

On October 14, 2018 the HBP announced that the million core milestone had been achieved.&lt;ref&gt;{{Cite news|url=https://www.datacenterdynamics.com/news/spinnaker-brain-simulation-project-hits-one-million-cores-single-machine/|title=SpiNNaker brain simulation project hits one million cores on a single machine|access-date=2018-10-19|language=en}}&lt;/ref&gt;&lt;ref&gt;{{Citation|last=Petrut Bogdan|title=SpiNNaker: 1 million core neuromorphic platform|date=2018-10-14|url=https://www.youtube.com/watch?v=V3MlOAru6Qk&amp;feature=youtu.be|access-date=2018-10-19}}&lt;/ref&gt;

==See also==
* [[TrueNorth]] – a processor architecture designed solely for spiking neural networks.

==References==
{{reflist|40em}}



{{Navboxes
|list=
{{John McCarthy navbox}}
{{philosophy of mind}}
{{philosophy of science}}
{{Evolutionary computation}}
{{Computable knowledge}}
{{Computer science}}
{{Emerging technologies}}
{{Robotics}}
}}



{{Philosophy of mind}}
{{Cybernetics}}
{{Computer science}}
{{Evolutionary computation}}
{{Emerging technologies}}
{{Authority control}}

{{DEFAULTSORT:Artificial Intelligence}}
[[Category:Artificial intelligence| ]]&lt;!--please leave the empty space as standard--&gt;
[[Category:Cybernetics]]
[[Category:Formal sciences]]
[[Category:Technology in society]]
[[Category:Computational neuroscience]]
[[Category:Emerging technologies]]
[[Category:Unsolved problems in computer science]]
[[Category:Computational fields of study]]

[[Category:AI accelerators]]
[[Category:Computer architecture]]
[[Category:School of Computer Science, University of Manchester]]
[[Category:Science and technology in Greater Manchester]]


{{comp-hardware-stub}}</text>
      <sha1>iiqnj2nuk4fbzz3zf8mikpsms884fec</sha1>
    </revision>
  </page>
  <page>
    <title>Symposium on Theory of Computing</title>
    <ns>0</ns>
    <id>21464146</id>
    <revision>
      <id>845171857</id>
      <parentid>811895204</parentid>
      <timestamp>2018-06-09T22:48:30Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8002">The '''Annual ACM Symposium on Theory of Computing''' ('''STOC''') is an [[academic conference]] in the field of [[theoretical computer science]]. STOC has been organized annually since 1969, typically in May or June; the conference is sponsored by the [[Association for Computing Machinery]] special interest group [[ACM SIGACT|SIGACT]]. Acceptance rate of STOC, averaged from 1970 to 2012, is 31%, with the rate of 29% in 2012.&lt;ref&gt;{{ cite web | url=http://dl.acm.org/citation.cfm?id=2213977&amp;coll=DL&amp;dl=GUIDE&amp;CFID=115128943&amp;CFTOKEN=16278130 | year=2012 | title=Proceedings of the 44th symposium on Theory of Computing | accessdate=2012-09-17 }}&lt;/ref&gt;

As {{harvtxt|Fich|1996}} writes, STOC and its annual [[IEEE]] counterpart FOCS (the [[Symposium on Foundations of Computer Science]]) are considered the two top conferences in theoretical computer science,&lt;ref&gt;{{cite web | url=http://www.conferenceranks.com/visualization/msar2014.html?field=Algorithms%20%26%20Theory | title=Conference Ranks | accessdate=2016-08-30 }}&lt;/ref&gt; considered broadly: they “are forums for some of the best work throughout theory of computing that promote breadth among theory of computing researchers and help to keep the community together.” {{harvtxt|Johnson|1984}} includes regular attendance at STOC and FOCS as one of several defining characteristics of theoretical computer scientists.

==Awards==
The [[Gödel Prize]] for outstanding papers in theoretical computer science is presented alternately at STOC and at the [[International Colloquium on Automata, Languages and Programming]] (ICALP); the [[Knuth Prize]] for outstanding contributions to the foundations of computer science is presented alternately at STOC and at [[FOCS]].

Since 2003, STOC has presented one or more Best Paper Awards &lt;ref&gt;{{cite web | url=http://jeffhuang.com/best_paper_awards.html#stoc | title=STOC Conference Best Paper Awards | accessdate=2012-04-07 }}&lt;/ref&gt; to recognize papers of the highest quality at the conference. In addition, the Danny Lewin Best Student Paper Award is awarded to the author(s) of the best student-authored paper in STOC&lt;ref&gt;{{cite web
 |url         = http://sigact.acm.org/prizes/student/
 |title       = Danny Lewin Best Student Paper Award
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20080620010241/http://sigact.acm.org/prizes/student/
 |archivedate = 2008-06-20
 |df          = 
}}&lt;/ref&gt;. The award is named in honor of [[Daniel M. Lewin]], an American-Israeli mathematician and entrepreneur who co-founded internet company [[Akamai Technologies]],  and was one of the first victims of the [[September 11 attacks]].&lt;ref&gt;{{cite web
 | url=http://www.egr.unlv.edu/~bein/SIGACT/lewin.html
 | first=Tom | last=Leighton
 | year=2002
 | title=Remarks made by Tom Leighton to commemorate the naming of the STOC Best Student Paper Award in honor of the late Daniel Lewin
}}&lt;/ref&gt;

==History==
STOC was first organised on 5–7 May 1969, in [[Marina del Rey]], [[California]], [[United States]]. The conference chairman was [[Patrick C. Fischer]], and the program committee consisted of [[Michael A. Harrison]], [[Robert W. Floyd]], [[Juris Hartmanis]], [[Richard M. Karp]], [[Albert R. Meyer]], and [[Jeffrey D. Ullman]].&lt;ref&gt;[http://portal.acm.org/toc.cfm?id=800169 Proc. STOC 1969].&lt;/ref&gt;

Early seminal papers in STOC include {{harvtxt|Cook|1971}}, which introduced the concept of [[NP-completeness]] (see also [[Cook–Levin theorem]]).

==Location==
STOC was organised in [[Canada]] in 1992, 1994, 2002, and 2008, and in [[Greece]] in 2001; all other meetings in 1969–2009 have been held in the [[United States]]. STOC was part of the [[Federated Computing Research Conference]] (FCRC) in 1993, 1996, 1999, 2003, 2007, and 2011.

==Invited speakers==
;[http://www.informatik.uni-trier.de/~ley/db/conf/stoc/stoc2004.html 2004]
:{{citation
 | doi=10.1145/1007352.1007356
 | author=[[Éva Tardos]]
 | contribution=Network games
 | title=Network games
 | year=2004
 | pages=341
}}
:{{citation
 | doi=10.1145/1007352.1007359
 | author=[[Avi Wigderson]]
 | contribution=Depth through breadth, or why should we attend talks in other areas?
 | title=Depth through breadth, or why should we attend talks in other areas?
 | year=2004
 | pages=579
}}

;[http://www.informatik.uni-trier.de/~ley/db/conf/stoc/stoc2005.html 2005]
:{{citation
 | doi=10.1145/1060590.1060609
 | author=[[Lance Fortnow]]
 | contribution=Beyond NP: the work and legacy of Larry Stockmeyer
 | title=Beyond NP
 | year=2005
 | pages=120
}}

;[http://www.informatik.uni-trier.de/~ley/db/conf/stoc/stoc2006.html 2006]
:{{citation
 | doi=10.1145/1132516.1132535
 | author=[[Prabhakar Raghavan]]
 | contribution=The changing face of web search: algorithms, auctions and advertising
 | title=The changing face of web search
 | year=2006
 | pages=129
}}
:{{citation
 | doi=10.1145/1132516.1132571
 | author=[[Russell Impagliazzo]]
 | contribution=Can every randomized algorithm be derandomized?
 | title=Can every randomized algorithm be derandomized?
 | year=2006
 | pages=373
}}

;[http://www.informatik.uni-trier.de/~ley/db/conf/stoc/stoc2007.html 2007]
:{{citation
 | doi=10.1145/1250790.1250826
 | author=[[Nancy Lynch]]
 | contribution=Distributed computing theory: algorithms, impossibility results, models, and proofs
 | title=Distributed computing theory
 | year=2007
 | pages=247
}}

;[http://www.informatik.uni-trier.de/~ley/db/conf/stoc/stoc2008.html 2008]
:{{citation
 | doi=10.1145/1374376.1374386
 | author=[[Jennifer Rexford]]
 | contribution=Rethinking internet routing
 | title=Rethinking internet routing
 | year=2008
 | pages=55
}}
:{{citation
 | doi=10.1145/1374376.1374468
 | author=[[David Haussler]]
 | contribution=Computing how we became human
 | title=Computing how we became human
 | year=2008
 | pages=639
}}
:{{citation
 | doi=10.1145/1374376.1374458
 | author=[[Ryan O'Donnell (mathematician)|Ryan O'Donnell]]
 | contribution=Some topics in analysis of boolean functions
 | title=Some topics in analysis of boolean functions
 | year=2008
 | pages=569
}}

;[http://www.informatik.uni-trier.de/~ley/db/conf/stoc/stoc2009.html 2009]
:{{citation
 | doi=10.1145/1536414.1536416
 | author=[[Shafi Goldwasser]]
 | contribution=Athena lecture: Controlling Access to Programs?
 | title=Athena lecture
 | year=2009
 | pages=167
}}

==See also==
*[[Theoretical computer science#Conferences|Conferences]] in theoretical computer science.
*The [[list of computer science conferences]] contains other academic conferences in computer science.

==Notes==
{{Reflist}}

==References==
*{{citation
 | last=Cook | first=Stephen | authorlink=Stephen Cook
 | year=1971
 | chapter=The complexity of theorem proving procedures
 | title=Proc. STOC 1971
 | pages=151–158
 | doi=10.1145/800157.805047}}.
*{{citation
 | last = Fich | first = Faith | authorlink = Faith Ellen
 | title = Infrastructure issues related to theory of computing research
 | journal = [[ACM Computing Surveys]]
 | volume = 28 | issue = 4es | doi = 10.1145/242224.242502
 | year = 1996
 | pages = 217}}.
*{{citation
 | last = Johnson | first = D. S. | authorlink = David S. Johnson
 | title = The genealogy of theoretical computer science: a preliminary report
 | journal = [[ACM SIGACT News]]
 | year = 1984 | volume = 16 | issue = 2 | pages = 36–49 | doi = 10.1145/1008959.1008960}}.

==External links==
*[http://sigact.acm.org/stoc.html STOC web page].
*[http://www.informatik.uni-trier.de/~ley/db/conf/stoc/ STOC proceedings information] in [[DBLP]].
*[http://portal.acm.org/toc.cfm?id=SERIES396 STOC proceedings] in the [[Association for Computing Machinery|ACM]] digital library.
*[http://www.cs.utah.edu/~suresh/citations/ Citation Statistics for FOCS/STOC/SODA], [[Piotr Indyk]] and [[Suresh Venkatasubramanian]], July 2007.

{{Association for Computing Machinery}}

[[Category:Theoretical computer science conferences]]
[[Category:Recurring events established in 1969]]
[[Category:Association for Computing Machinery conferences]]</text>
      <sha1>bk5c8f35p9t461bh9ibmaqqc9zakagg</sha1>
    </revision>
  </page>
  <page>
    <title>Ternary equivalence relation</title>
    <ns>0</ns>
    <id>47274958</id>
    <revision>
      <id>846978468</id>
      <parentid>756215679</parentid>
      <timestamp>2018-06-22T02:37:53Z</timestamp>
      <contributor>
        <username>Michael Kinyon</username>
        <id>842096</id>
      </contributor>
      <minor/>
      <comment>/* References */ fixed author name typos</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3228">In [[mathematics]], a '''ternary equivalence relation''' is a kind of [[ternary relation]] analogous to a [[binary relation|binary]] [[equivalence relation]]. A ternary equivalence relation is symmetric, reflexive, and transitive. The classic example is the relation of [[collinearity]] among three points in [[Euclidean space]]. In an abstract set, a ternary equivalence relation determines a collection of equivalence classes or ''[[pencil (mathematics)|pencils]]'' that form a [[linear space (geometry)|linear space]] in the sense of [[incidence geometry]]. In the same way,  a binary equivalence relation on a set determines a [[partition of a set|partition]].

==Definition==
A ternary equivalence relation on a set {{mvar|X}} is a relation {{math|''E'' ⊂ ''X''&lt;sup&gt;3&lt;/sup&gt;}}, written {{math|[''a'', ''b'', ''c'']}}, that satisfies the following axioms:
#Symmetry: If {{math|[''a'', ''b'', ''c'']}} then {{math|[''b'', ''c'', ''a'']}} and {{math|[''c'', ''b'', ''a'']}}. (Therefore also {{math|[''a'', ''c'', ''b'']}}, {{math|[''b'', ''a'', ''c'']}}, and {{math|[''c'', ''a'', ''b'']}}.)
#Reflexivity: {{math|[''a'', ''b'', ''b'']}}. Equivalently, if {{mvar|a}}, {{mvar|b}}, and {{mvar|c}} are not all distinct, then {{math|[''a'', ''b'', ''c'']}}.
#Transitivity:  If {{math|''a'' ≠ ''b''}} and {{math|[''a'', ''b'', ''c'']}} and {{math|[''a'', ''b'', ''d'']}} then {{math|[''b'', ''c'', ''d'']}}. (Therefore also {{math|[''a'', ''c'', ''d'']}}.)

==References==
*{{Citation |first=João |last=Araújo |first2=Janusz |last2=Konieczny |title=A method of finding automorphism groups of endomorphism monoids of relational systems |journal=Discrete Mathematics |volume=307 |year=2007 |pages=1609–1620 |doi=10.1016/j.disc.2006.09.029}}
*{{Citation |first=Friedrich |last=Bachmann |title=Aufbau der Geometrie aus dem Spiegelungsbegriff}}
*{{Citation |first=Helmut |last=Karzel |title=Loops related to geometric structures |journal=Quasigroups and Related Systems |volume=15 |year=2007 |pages=47–76}}
*{{Citation |first=Helmut |last=Karzel |first2=Silvia |last2=Pianta |title=Binary operations derived from symmetric permutation sets and applications to absolute geometry |journal=Discrete Mathematics |volume=308 |year=2008 |pages=415–421 |doi=10.1016/j.disc.2006.11.058}}
*{{Citation |first=Helmut |last=Karzel |first2=Mario |last2=Marchi |first3=Silvia |last3=Pianta |title=The defect in an invariant reflection structure |journal=Journal of Geometry |date=December 2010 |volume=99 |issue=1-2 |pages=67-87 |doi=10.1007/s00022-010-0058-7}}
*{{Citation |first=Rolf |last=Lingenberg |title=Metric planes and metric vector spaces |year=1979 |publisher=Wiley}}
*{{Citation |title=Ternary relations in geometry and algebra |first=G.Y. |last=Rainich |journal=Michigan Mathematical Journal |volume=1 |issue=2 |year=1952 |pages=97-111 |doi=10.1307/mmj/1028988890}}
*{{Citation |first=Wanda |last=Szmielew|authorlink=Wanda Szmielew |title=On ''n''-ary equivalence relations and their application to geometry |publisher=Instytut Matematyczny Polskiej Akademi Nauk |year=1981 |location=Warsaw |url=http://eudml.org/doc/268578}}

[[Category:Mathematical relations]]
[[Category:Incidence geometry]]
[[Category:Projective geometry]]</text>
      <sha1>2ndvfoml3g4zkmq0b5s2qv910gyxzcn</sha1>
    </revision>
  </page>
  <page>
    <title>Theory of computation</title>
    <ns>0</ns>
    <id>30402</id>
    <revision>
      <id>862102802</id>
      <parentid>860187069</parentid>
      <timestamp>2018-10-02T05:45:33Z</timestamp>
      <contributor>
        <username>Nowak Kowalski</username>
        <id>18891628</id>
      </contributor>
      <comment>better hatnote</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17771">{{Distinguish|computational theory of mind}}
{{For|the journal|Theory of Computing}}

[[Image:Maquina.png|thumb|250px|An artistic representation of a [[Turing machine]]. Turing machines are frequently used as theoretical models for computing.]]

In [[theoretical computer science]] and [[mathematics]], the '''theory of computation''' is the branch that deals with how efficiently problems can be solved on a [[model of computation]], using an [[algorithm]].  The field is divided into three major branches: [[automata theory]] and languages, [[computability theory]], and [[computational complexity theory]], which are linked by the question: ''"What are the fundamental capabilities and limitations of computers?".''&lt;ref name=Sipser-3rd&gt;{{cite book|author = [[Michael Sipser]] | year = 2013 | title = Introduction to the Theory of Computation 3rd |quote=central areas of the theory of computation: automata, computability, and complexity. (Page 1) |publisher =Cengage Learning |isbn=978-1-133-18779-0}}&lt;/ref&gt;

In order to perform a rigorous study of computation, computer scientists work with a mathematical abstraction of computers called a [[model of computation]].  There are several models in use, but the most commonly examined is the [[Turing machine]].&lt;ref name=Hodges-2012&gt;{{cite book| first=Andrew | last=Hodges | authorlink=Andrew Hodges | year = 2012 | title =[[Alan Turing: The Enigma]] (The Centenary Edition) | publisher=[[Princeton University Press]] |isbn=978-0-691-15564-7}}&lt;/ref&gt; Computer scientists study the Turing machine because it is simple to formulate, can be analyzed and used to prove results, and because it represents what many consider the most powerful possible "reasonable" model of computation (see [[Church–Turing thesis]]).&lt;ref&gt;{{cite video | last = Rabin | first = Michael O. | author-link = Michael O. Rabin | title = Turing, Church, Gödel, Computability, Complexity and Randomization: A Personal View | date = June 2012 | url = http://videolectures.net/turing100_rabin_turing_church_goedel/ }}&lt;/ref&gt; It might seem that the potentially infinite memory capacity is an unrealizable attribute, but any [[Decidability (logic)|decidable]] problem&lt;ref name=Monk1976&gt;{{cite book|author =Donald Monk | year = 1976| title =Mathematical Logic| publisher =Springer-Verlag |isbn=9780387901701}}&lt;/ref&gt; solved by a Turing machine will always require only a finite amount of memory. So in principle, any problem that can be solved (decided) by a Turing machine can be solved by a computer that has a finite amount of memory.

== History ==
The theory of computation can be considered the creation of models of all kinds in the field of computer science. Therefore, [[Mathematical logic|mathematics and logic]] are used. In the last century it became an independent academic discipline and was separated from mathematics.

Some pioneers of the theory of computation were [[Alonzo Church]], [[Kurt Gödel]], [[Alan Turing]], [[Stephen Kleene]], [[Rózsa Péter]], [[John von Neumann]] and [[Claude Shannon]].

== Branches ==

=== Automata theory ===
{{main|Automata theory}}
{| class="wikitable"
|-
! Grammar
! Languages
! Automaton
! Production rules (constraints)
|-
| Type-0
| [[recursively enumerable language|Recursively enumerable]]
| [[Turing machine]]
| &lt;math&gt;\alpha \rightarrow \beta&lt;/math&gt; (no restrictions)
|-
| Type-1
| [[context-sensitive grammar|Context-sensitive]]
| [[Linear bounded automaton|Linear-bounded non-deterministic Turing machine]]
| &lt;math&gt;\alpha A \beta \rightarrow \alpha \gamma \beta&lt;/math&gt;
|-
| Type-2
| [[context-free grammar|Context-free]]
| Non-deterministic [[pushdown automaton]]
| &lt;math&gt;A \rightarrow \gamma&lt;/math&gt;
|-
| Type-3
| [[regular grammar|Regular]]
| [[Finite state automaton]]
| &lt;math&gt;A \rightarrow a&lt;/math&gt;&lt;br /&gt; and&lt;br /&gt;&lt;math&gt;A \rightarrow aB&lt;/math&gt;
|}

Automata theory is the study of abstract machines (or more appropriately, abstract 'mathematical' machines or systems) and the computational problems that can be solved using these machines. These abstract machines are called automata. Automata comes from the Greek word (Αυτόματα) which means that something is doing something by itself.
Automata theory is also closely related to [[formal language]] theory,&lt;ref name=hopcroft-ullman&gt;{{cite book|author =[[John Hopcroft|Hopcroft, John E.]] and [[Jeffrey D. Ullman]]  | year = 2006| title =[[Introduction to Automata Theory, Languages, and Computation]]. 3rd ed| publisher =Reading, MA: Addison-Wesley. |isbn= 978-0-321-45536-9}}&lt;/ref&gt; as the automata are often classified by the class of formal languages they are able to recognize. An automaton can be a finite representation of a formal language that may be an infinite set. Automata are used as theoretical models for computing machines, and are used for proofs about computability.

==== Formal Language theory ====
{{main|Formal language}}
[[Image:Chomsky-hierarchy.svg|thumb|right|200px|alt=The Chomsky hierarchy|Set inclusions described by the Chomsky hierarchy]]
Language theory is a branch of mathematics concerned with describing languages as a set of operations over an [[alphabet]]. It is closely linked with automata theory, as automata are used to generate and recognize formal languages. There are several classes of formal languages, each allowing more complex language specification than the one before it, i.e. [[Chomsky hierarchy]],&lt;ref&gt;{{cite journal |last=[[Chomsky hierarchy]] |first= |last2= |first2= |date=1956 |title=Three models for the description of language |url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1056813&amp;tag=1 |journal=Information Theory, IRE Transactions on |publisher=IEEE |volume=2 |issue=3 |pages= 113–124|doi=10.1109/TIT.1956.1056813 |accessdate=6 January 2015}}&lt;/ref&gt; and each corresponding to a class of automata which recognizes it. Because automata are used as models for computation, formal languages are the preferred mode of specification for any problem that must be computed.

=== Computability theory ===
{{main|Computability theory}}
Computability theory deals primarily with the question of the extent to which a problem is solvable on a computer. The statement that the [[halting problem]] cannot be solved by a Turing machine&lt;ref&gt;{{cite journal |last=[[Alan Turing]] |first= |last2= |first2= |date=1937 |title=On computable numbers, with an application to the Entscheidungsproblem |url=http://www.turingarchive.org/browse.php/B/12 |journal= Proceedings of the [[London Mathematical Society]] |publisher=IEEE |volume=2 |issue=42 |pages=230–265 |doi=10.1112/plms/s2-42.1.230 |accessdate=6 January 2015}}&lt;/ref&gt; is one of the most important results in computability theory, as it is an example of a concrete problem that is both easy to formulate and impossible to solve using a Turing machine.  Much of computability theory builds on the halting problem result.

Another important step in computability theory was [[Rice's theorem]], which states that for all non-trivial properties of partial functions, it is [[Decidability (logic)|undecidable]] whether a Turing machine computes a partial function with that property.&lt;ref&gt;{{cite journal |last=Henry Gordon Rice |first= |last2= |first2= |date=1953 |title=Classes of Recursively Enumerable Sets and Their Decision Problems |journal= Transactions of the American Mathematical Society |publisher=American Mathematical Society|volume=74 |issue=2 |pages=358–366 |doi= 10.2307/1990888|jstor=1990888}}&lt;/ref&gt;

Computability theory is closely related to the branch of [[mathematical logic]] called [[recursion theory]], which removes the restriction of studying only models of computation which are reducible to the Turing model.&lt;ref name=davis&gt;{{cite book|author =[[Martin Davis]] |year = 2004 |title =The undecidable: Basic papers on undecidable propositions, unsolvable problems and computable functions (Dover Ed) |publisher =Dover Publications |isbn=978-0486432281}}&lt;/ref&gt;  Many mathematicians and computational theorists who study recursion theory will refer to it as computability theory.

=== Computational complexity theory ===
{{main|Computational complexity theory}}
[[Image:Complexity subsets pspace.svg|250px|thumb|right|A representation of the relation among complexity classes]]
[[Computational complexity theory|Complexity theory]] considers not only whether a problem can be solved at all on a computer, but also how efficiently the problem can be solved.  Two major aspects are considered: time complexity and space complexity, which are respectively how many steps does it take to perform a computation, and how much memory is required to perform that computation.

In order to analyze how much time and space a given [[algorithm]] requires, computer scientists express the time or space required to solve the problem as a function of the size of the input problem.  For example, finding a particular number in a long list of numbers becomes harder as the list of numbers grows larger.  If we say there are ''n'' numbers in the list, then if the list is not sorted or indexed in any way we may have to look at every number in order to find the number we're seeking.  We thus say that  in order to solve this problem, the computer needs to perform a number of steps that grows linearly in the size of the problem.

To simplify this problem, computer scientists have adopted [[Big O notation]], which allows functions to be compared in a way that ensures that particular aspects of a machine's construction do not need to be considered, but rather only the [[Asymptotic analysis|asymptotic behavior]] as problems become large.  So in our previous example we might say that the problem requires &lt;math&gt;O(n)&lt;/math&gt; steps to solve.

Perhaps the most important open problem in all of [[computer science]] is the question of whether a certain broad class of problems denoted [[NP (complexity)|NP]] can be solved efficiently. This is discussed further at [[P = NP problem|Complexity classes P and NP]], and [[P versus NP problem]] is one of the seven [[Millennium Prize Problems]] stated by the [[Clay Mathematics Institute]] in 2000. The [http://www.claymath.org/sites/default/files/pvsnp.pdf Official Problem Description] was given by [[Turing Award]] winner [[Stephen Cook]].

== Models of computation ==&lt;!-- This section is linked from [[Abstract machine]] --&gt;
{{main|Model of computation}}

Aside from a [[Turing machine]], other equivalent (See: [[Church–Turing thesis]]) models of computation are in use.

;[[Lambda calculus]]: A computation consists of an initial lambda expression (or two if you want to separate the function and its input) plus a finite sequence of lambda terms, each deduced from the preceding term by one application of [[Beta reduction]].
;[[Combinatory logic]]
:is a concept which has many similarities to &lt;math&gt;\lambda&lt;/math&gt;-calculus, but also important differences exist (e.g. fixed point combinator '''Y''' has normal form in combinatory logic but not in &lt;math&gt;\lambda&lt;/math&gt;-calculus). Combinatory logic was developed with great ambitions: understanding the nature of paradoxes, making foundations of mathematics more economic (conceptually), eliminating the notion of variables (thus clarifying their role in mathematics).

;[[μ-recursive function]]s: a computation consists of a mu-recursive function, ''i.e.'' its defining sequence, any input value(s) and a sequence of recursive functions appearing in the defining sequence with inputs and outputs.  Thus, if in the defining sequence of a recursive function &lt;math&gt;f(x)&lt;/math&gt; the functions &lt;math&gt;g(x)&lt;/math&gt; and &lt;math&gt;h(x,y)&lt;/math&gt; appear, then terms of the form 'g(5)=7' or 'h(3,2)=10' might appear.  Each entry in this sequence needs to be an application of a basic function or follow from the entries above by using [[Function composition (computer science)|composition]], [[primitive recursion]] or [[μ-recursive function|μ recursion]].  For instance if &lt;math&gt;f(x)=h(x,g(x))&lt;/math&gt;, then for 'f(5)=3' to appear, terms like 'g(5)=6' and 'h(5,6)=3' must occur above.  The computation terminates only if the final term gives the value of the recursive function applied to the inputs.

;[[Markov algorithm]]: a [[string rewriting system]] that uses [[grammar]]-like rules to operate on [[string (computer science)|strings]] of symbols.

;[[Register machine]]
:is a theoretically interesting idealization of a computer. There are several variants. In most of them, each register can hold a natural number (of unlimited size), and the instructions are simple (and few in number), e.g. only decrementation (combined with conditional jump) and incrementation exist (and halting). The lack of the infinite (or dynamically growing) external store (seen at Turing machines) can be understood by replacing its role with [[Gödel numbering]] techniques: the fact that each register holds a natural number allows the possibility of representing a complicated thing (e.g. a sequence, or a matrix etc.) by an appropriate huge natural number — unambiguity of both representation and interpretation can be established by [[number theory|number theoretical]]  foundations of these techniques.

In addition to the general computational models, some simpler computational models are useful for special, restricted applications.  [[Regular expressions]], for example,  specify string patterns in many contexts, from office productivity software to [[programming language]]s. Another formalism mathematically equivalent to regular expressions, [[finite state machines|Finite automata]] are used in circuit design and in some kinds of problem-solving. [[Context-free grammar]]s  specify programming language syntax.  Non-deterministic [[pushdown automaton|pushdown automata]] are another formalism equivalent to context-free grammars. [[Primitive recursive function]]s are a defined subclass of the recursive functions.

Different models of computation have the ability to do different tasks. One way to measure the power of a computational model is to study the class of [[formal language]]s that the model can generate; in such a way to the [[Chomsky hierarchy]] of languages is obtained.

== References ==
{{reflist}}

==Further reading==
;Textbooks aimed at computer scientists
(There are many textbooks in this area; this list is by necessity incomplete.)
* [[John Hopcroft|Hopcroft, John E.]], and [[Jeffrey D. Ullman]] (2006). ''[[Introduction to Automata Theory, Languages, and Computation]]. 3rd ed''  Reading, MA: Addison-Wesley. {{isbn|978-0-321-45536-9}} One of the standard references in the field.
*{{cite book|author=[[Linz P]]|title=An introduction to formal language and automata|publisher=Narosa Publishing|isbn=9788173197819}}
* {{cite book|author = [[Michael Sipser]] | year = 2013 | title = Introduction to the Theory of Computation|edition= 3rd |publisher =Cengage Learning |isbn=978-1-133-18779-0}}
* {{cite book | author = [[Eitan Gurari]] | year = 1989 | title = An Introduction to the Theory of Computation | url = http://www.cse.ohio-state.edu/~gurari/theory-bk/theory-bk.html | publisher = Computer Science Press | isbn = 0-7167-8182-4 | deadurl = yes | archiveurl = https://web.archive.org/web/20070107040625/http://www.cse.ohio-state.edu/~gurari/theory-bk/theory-bk.html | archivedate = 2007-01-07 | df =  }}
* Hein, James L. (1996) ''Theory of Computation.''  Sudbury, MA: Jones &amp; Bartlett.  {{isbn|978-0-86720-497-1}} A gentle introduction to the field, appropriate for second-year undergraduate computer science students.
* Taylor, R. Gregory (1998). ''Models of Computation and Formal Languages.''  New York: Oxford University Press.  {{isbn|978-0-19-510983-2}}  An unusually readable textbook, appropriate for upper-level undergraduates or beginning graduate students.
* Lewis, F. D. (2007). ''[http://cse.ucdenver.edu/~cscialtman/foundation/Essentials%20of%20Theoretical%20Computer%20Science.pdf Essentials of theoretical computer science]'' A textbook covering the topics of formal languages, automata and grammars. The emphasis appears to be on presenting an overview of the results and their applications rather than providing proofs of the results.
* [[Martin Davis]], Ron Sigal, Elaine J. Weyuker, ''Computability, complexity, and languages: fundamentals of theoretical computer science'', 2nd ed., Academic Press, 1994, {{isbn|0-12-206382-1}}. Covers a wider range of topics than most other introductory books, including [[program semantics]] and [[quantification theory]]. Aimed at graduate students.

;Books on computability theory from the (wider) mathematical perspective
* [[Hartley Rogers, Jr]] (1987). ''Theory of Recursive Functions and Effective Computability'', MIT Press. {{isbn|0-262-68052-1}}
* {{cite book|author = [[S. Barry Cooper]] | year = 2004 | title = Computability Theory | publisher = Chapman and Hall/CRC | isbn = 1-58488-237-9}}.
* [[Carl Herbert Smith|Carl H. Smith]], ''A recursive introduction to the theory of computation'', Springer, 1994, {{isbn|0-387-94332-3}}. A shorter textbook suitable for graduate students in Computer Science.

;Historical perspective
* {{cite book|author = [[Richard L. Epstein]] and [[Walter A. Carnielli]] | year = 2000 | title = Computability: Computable Functions, Logic, and the Foundations of Mathematics, with Computability: A Timeline (2nd ed.) | publisher = Wadsworth/Thomson Learning | isbn = 0-534-54644-7}}.

== External links ==
* [http://toc.csail.mit.edu/ Theory of Computation] at [[Massachusetts Institute of Technology|MIT]]
* [http://toc.seas.harvard.edu/ Theory of Computation] at [[Harvard]]
* [http://www.cis.upenn.edu/~giorgi/cl.html Computability Logic] - A theory of interactive computation. The main web source on this subject.

{{Areas of mathematics | state=collapsed}}

[[Category:Theory of computation| ]]</text>
      <sha1>ck6ve82s99zjvozv3g320e3oqqczhma</sha1>
    </revision>
  </page>
  <page>
    <title>Transformation (function)</title>
    <ns>0</ns>
    <id>1904373</id>
    <revision>
      <id>859370767</id>
      <parentid>852953009</parentid>
      <timestamp>2018-09-13T16:25:49Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10339">{{redirect|Transformation (mathematics)||Transformation (disambiguation){{!}}Transformation#In mathematics}}
{{Multiple issues|
{{refimprove|date=April 2012}}
{{cleanup|reason=remove material which is not about transformations in the narrow sense. Those belong to the article on function as examples. The same goes for examples of morphisms.|date=August 2014}}
}}
[[File:A code snippet for a rhombic repetitive pattern.svg|thumb|upright=1.5|A [[Function composition|composition]] of four [[Map (mathematics)|mappings]] coded [[Scalable Vector Graphics|in&amp;nbsp;SVG]],&lt;br/&gt;which '''transforms''' a [[Rectangle|rectangular]] repetitive [[pattern]]&lt;br/&gt;into a [[Rhombus|rhombic]] pattern. The four transformations are [[Linear map|linear]].]]
In [[mathematics]], particularly in [[semigroup]] theory, a '''transformation''' is a [[Function (mathematics)|function]] ''f'' that maps a [[set (mathematics)|set]] ''X'' to itself, i.e. {{nowrap|''f'' : ''X'' → ''X''}}.&lt;Ref&gt;{{cite book|author1=Olexandr Ganyushkin|author2=Volodymyr Mazorchuk|title=Classical Finite Transformation Semigroups: An Introduction|year=2008|publisher=Springer Science &amp; Business Media|isbn=978-1-84800-281-4|page=1}}&lt;/ref&gt;&lt;ref name="Grillet1995"&gt;{{cite book|author=Pierre A. Grillet|title=Semigroups: An Introduction to the Structure Theory|url=https://books.google.com/books?id=yM544W1N2UUC&amp;pg=PA2|year=1995|publisher=CRC Press|isbn=978-0-8247-9662-4|page=2}}&lt;/ref&gt;&lt;ref&gt;{{cite book|authors=Wilkinson, Leland &amp; Graham|title=The Grammar of Graphics|publisher=Springer|year=2005|isbn=978-0-387-24544-7|page=29|url=https://books.google.com/books?id=NRyGnjeNKJIC&amp;pg=PA29|edition=2nd}}&lt;/ref&gt; In other areas of mathematics, a transformation may simply be any function, regardless of domain and codomain.&lt;ref name="Halmos1960"&gt;{{cite book|author=P. R. Halmos|title=Naive Set Theory|url=https://books.google.com/books?id=x6cZBQ9qtgoC&amp;pg=PA30|year=1960|publisher=Springer Science &amp; Business Media|isbn=978-0-387-90092-6|pages=30–}}&lt;/ref&gt; This wider sense shall not be considered in this article; refer instead to the [[Function (mathematics)|article on function]] for that sense.

Examples include [[linear transformation]]s and [[affine transformation]]s, [[rotation]]s, [[reflection (mathematics)|reflections]] and [[translation (geometry)|translations]]. These can be carried out in [[Euclidean space]], particularly in {{math|'''R'''&lt;sup&gt;2&lt;/sup&gt;}} (two dimensions) and {{math|'''R'''&lt;sup&gt;3&lt;/sup&gt;}} (three dimensions). They are also operations that can be performed using [[linear algebra]], and described explicitly using [[matrix (mathematics)|matrices]].

==Translation==
{{Main|Translation (geometry)}}

A '''translation''', or '''translation operator''', is an [[affine transformation]] of [[Euclidean space]] which moves every point by a fixed distance in the same direction. It can also be interpreted as the addition of a constant [[vector space|vector]] to every point, or as shifting the [[Origin (mathematics)|origin]] of the [[coordinate system]]. In other words, if '''v''' is a fixed vector, then the translation ''T''&lt;sub&gt;'''v'''&lt;/sub&gt; will work as ''T''&lt;sub&gt;'''v'''&lt;/sub&gt;('''p''') = '''p''' + '''v'''.

The two interpretations of a translation lead to two related but different coordinate transformations. To illustrate this the examples will be restricted to the two dimensional case for simplicity, but the argument holds in any dimension.

Let ''P''(''x'',&amp;nbsp;''y'') be a point in the plane and apply the translation (''h'',&amp;nbsp;''k'') to obtain a new point ''P''' with coordinates (''X'',&amp;nbsp;''Y''). It follows from the definition that&lt;ref&gt;{{citation|page=61|first=James R.|last=Smart|title=Modern Geometries|edition=5th|year=1998|publisher=Brooks/Cole|isbn=0-534-35188-3}}&lt;/ref&gt;
:''X'' = ''x'' + ''h'' or ''x'' = ''X'' − ''h''
and
:''Y'' = ''y'' + ''k'' or ''y'' = ''Y'' − ''k''.

Now consider a point ''P''(''x'',&amp;nbsp;''y'') in the plane, whose coordinates are determined with respect to a given pair of [[Plot (graphics)|axes]]. Suppose the axes are shifted from their original position by (''h'',&amp;nbsp;''k'') and the shifted axes are taken as the new reference axes. The point ''P'' now has coordinates (''X'',&amp;nbsp;''Y'') with respect to the new reference axes. To obtain the coordinates of ''P'' with respect to the new reference axes from the coordinates of ''P'' with respect to the original reference axes, these ''formulas of translation'' are used ({{crossref|For more details see [[Translation of axes]]}}):

:''X'' = ''x'' − ''h'' or ''x'' = ''X'' + ''h''
and
:''Y'' = ''y'' − ''k'' or ''y'' = ''Y'' + ''k''.

Replacing the original coordinates, that is, ''x'' and ''y'', with these expressions in an equation of an object in the original coordinates, will produce the transformed equation for the same object with respect to the new reference axes.&lt;ref&gt;{{citation|pages=135-136|first1=W.A.|last1=Wilson|first2=J.I.|last2=Tracey|title=Analytic Geometry|year=1925|publisher=D.C. Heath and Co.|edition=revised}}&lt;/ref&gt;

The relationship that holds here is that each of the coordinate transformations is the [[inverse function]] of the other.

==Reflection==
{{Main|Reflection (mathematics)}}

A '''reflection''' is a [[function (mathematics)|map]] that transforms an object into its [[mirror image]] with respect to a "mirror", which is a hyperplane of fixed points in the geometry. For example, a reflection of the small Latin letter p with respect to a vertical line would look like a "q". In order to reflect a planar figure one needs the "mirror" to be a line (''axis of reflection'' or ''axis of symmetry''), while for reflections in the three-dimensional space one would use a [[plane (mathematics)|plane]] (the ''plane of reflection'' or ''symmetry'') for a mirror. Reflection may be considered as the limiting case of [[circle inversion|inversion]] as the radius of the reference circle increases without bound.

Reflection is considered to be an ''opposite'' motion since it changes the [[orientation (vector space)|orientation]] of the figures it reflects.

==Glide reflection==
[[File:Glide reflection.png|right|thumbnail|Example of a glide reflection]]
{{Main|Glide reflection}}
A '''glide reflection''' is a type of [[isometry]] of the [[Euclidean plane]]: the combination of a [[reflection (mathematics)|reflection]] in a line and a [[translation (geometry)|translation]] along that line. Reversing the order of combining gives the same result. Depending on context, we may consider a simple reflection (without translation) as a special case where the translation vector is the [[zero vector]].
{{Clr}}

==Rotation==
{{Main|Rotation (geometry)}}

A rotation is a transformation that is performed by "spinning" the object around a fixed point known as the center of rotation.  You can rotate the object at any degree measure, but 90° and 180° are two of the most common. Rotation by a positive angle rotates the object counterclockwise, whereas rotation by a negative angle rotates the object clockwise.

==Scaling==
{{Main|Scaling (geometry)}}

'''Uniform scaling''' is a [[linear transformation]] that enlarges or diminishes objects; the [[scale factor]] is the same in all directions; it is also called a [[Homothetic transformation|homothety]] or dilation. The result of uniform scaling is [[Similarity (geometry)|similar]] (in the geometric sense) to the original.

More general is '''scaling''' with a separate scale factor for each axis direction; a special case is '''directional scaling''' (in one direction). Shapes not aligned with the axes may be subject to shear (see below) as a side effect: although the angles between lines parallel to the axes are preserved, other angles are not.

==Shear==
{{Main|Shear mapping}}
'''Shear''' is a transform that effectively rotates one axis so that the axes are no longer perpendicular. Under shear, a [[rectangle]] becomes a [[parallelogram]], and a [[circle]] becomes an [[ellipse]]. Even if lines parallel to the axes stay the same length, others do not. As a mapping of the plane, it lies in the class of [[2 × 2 real matrices#Equi-areal mapping|equi-areal mappings]].

==More generally==

More generally, a '''transformation''' in mathematics means a [[function (mathematics)|mathematical function]] (synonyms: ''[[map (mathematics)|map]]'' and ''[[map (mathematics)|mapping]]''). A transformation can be an [[inverse function|invertible function]] from a set ''X'' to itself, or from ''X'' to another set ''Y''. The choice of the term ''transformation'' may simply flag that a function's more geometric aspects are being considered (for example, with attention paid to [[invariant (mathematics)|invariants]]).

{|
|+ A strong [[nonlinear transformation]] applied to a plane through the origin
|-
|[[File:Transformation (before).png|250px]]
|[[File:Transformation (after).png|250px]]
|-
|Before
|After
|}

===Partial transformations===
The notion of transformation generalized to [[partial functions]]. A '''partial transformation''' is a function ''f'': ''A'' → ''B'', where both ''A'' and ''B'' are [[subset]]s of some set ''X''.&lt;ref name="Hollings2014"&gt;{{cite book|author=Christopher Hollings|title=Mathematics across the Iron Curtain: A History of the Algebraic Theory of Semigroups|url=https://books.google.com/books?id=O9wJBAAAQBAJ&amp;pg=PA251|year=2014|publisher=American Mathematical Society|isbn=978-1-4704-1493-1|page=251}}&lt;/ref&gt;

==Algebraic structures==
The set of all transformations on a given base set together with [[function composition]] forms a [[regular semigroup]].

==Combinatorics==
For a finite set of [[cardinality]] ''n'', there are ''n''&lt;sup&gt;''n''&lt;/sup&gt; transformations and  (''n''+1)&lt;sup&gt;''n''&lt;/sup&gt; partial transformations.&lt;Ref&gt;{{cite book|author1=Olexandr Ganyushkin|author2=Volodymyr Mazorchuk|title=Classical Finite Transformation Semigroups: An Introduction|year=2008|publisher=Springer Science &amp; Business Media|isbn=978-1-84800-281-4|page=2}}&lt;/ref&gt;

==See also==
*[[Coordinate transformation]]
*[[Data transformation (statistics)]]
*[[Infinitesimal transformation]]
*[[Linear transformation]]
*[[Transformation geometry]]
*[[Transformation group]]
*[[Transformation matrix]]

==References==
{{reflist}}

{{DEFAULTSORT:Transformation (Geometry)}}
[[Category:Functions and mappings]]
[[Category:Transformation (function)| ]]</text>
      <sha1>9b7vp5qdlsqw4572qtnpouus97oz8lm</sha1>
    </revision>
  </page>
  <page>
    <title>Unifying theories in mathematics</title>
    <ns>0</ns>
    <id>186023</id>
    <revision>
      <id>841249588</id>
      <parentid>825965059</parentid>
      <timestamp>2018-05-14T19:28:05Z</timestamp>
      <contributor>
        <username>DeprecatedFixerBot</username>
        <id>33330201</id>
      </contributor>
      <minor/>
      <comment>Removed deprecated parameter(s) from [[Template:Columns-list]] using [[User:DeprecatedFixerBot| DeprecatedFixerBot]]. Questions? See [[Template:Div col#Usage of "cols" parameter]] or [[User talk:TheSandDoctor|msg TSD!]] (please mention that this is task #2!))</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11656">{{Unreferenced|date=January 2009}}
There have been several attempts in history to reach a '''unified theory of mathematics'''. Some of the greatest [[mathematician]]s have expressed views that the whole subject should be fitted into one theory.

==Historical perspective==

The process of unification might be seen as helping to define what constitutes mathematics as a discipline.

For example, [[mechanics]] and [[mathematical analysis]] were commonly combined into one subject during the 18th century, united by the [[differential equation]] concept; while [[algebra]] and [[geometry]] were considered largely distinct. Now we consider analysis, algebra, and geometry, but not mechanics, as parts of mathematics because they are primarily deductive [[formal science]]s, while mechanics like [[physics]] must proceed from observation. There is no major loss of content, with [[analytical mechanics]] in the old sense now expressed in terms of [[symplectic topology]], based on the newer theory of [[manifold]]s.

==Mathematical theories==

The term ''theory'' is used informally within mathematics to mean a self-consistent body of [[definition]]s, [[axiom]]s, [[theorem]]s, examples, and so on. (Examples include [[group theory]], [[Galois theory]], [[control theory]], and [[K-theory]].) In particular there is no connotation of ''hypothetical''. Thus the term ''unifying theory'' is more like a [[sociological]] term used to study the actions of mathematicians. It may assume nothing conjectural that would be analogous to an undiscovered scientific link. There is really no cognate within mathematics to such concepts as ''[[Proto-World language|Proto-World]]'' in [[linguistics]] or the [[Gaia hypothesis]].

Nonetheless there have been several episodes within the history of mathematics in which sets of individual theorems were found to be special cases of a single unifying result, or in which a single perspective about how to proceed when developing an area of mathematics could be applied fruitfully to multiple branches of the subject.

==Geometrical theories==

A well-known example was the development of [[analytic geometry]], which in the hands of mathematicians such as [[Descartes]] and [[Fermat]] showed that many theorems about [[curve]]s and [[Surface (topology)|surface]]s of special types could be stated in algebraic language (then new), each of which could then be proved using the same techniques. That is, the theorems were very similar algebraically, even if the geometrical interpretations were distinct.

In 1859 [[Arthur Cayley]] initiated a unification of [[metric geometry|metric geometries]] through use of the [[Cayley-Klein metric]]s. Later [[Felix Klein]] used such metrics to provide a foundation for [[non-Euclidean geometry]].

In 1872, Felix Klein noted that the many branches of geometry which had been developed during the 19th century ([[affine geometry]], [[projective geometry]], [[hyperbolic geometry]], etc.) could all be treated in a uniform way. He did this by considering the [[group theory|group]]s under which the geometric objects were invariant. This unification of geometry goes by the name of the [[Erlangen programme]].

==Through-axiomatisation==

Early in the 20th century, many parts of mathematics began to be treated by delineating useful sets of axioms and then studying their consequences. Thus, for example, the studies of "[[hypercomplex number]]s", such as considered by the [[Quaternion Society]], were put onto an axiomatic footing as branches of [[ring theory]] (in this case, with the specific meaning of [[associative algebra]]s over the field of complex numbers.) In this context, the [[quotient ring]] concept is one of the most powerful unifiers.

This was a general change of methodology, since the needs of applications had up until then meant that much of mathematics was taught by means of [[algorithm]]s (or processes close to being algorithmic). [[Arithmetic]] is still taught that way. It was a parallel to the development of [[mathematical logic]] as a stand-alone branch of mathematics. By the 1930s [[symbolic logic]] itself was adequately included within mathematics.

In most cases, mathematical objects under study can be defined (albeit non-canonically) as sets or, more informally, as sets with additional structure such as an addition operation. [[Set theory]] now serves as a ''[[lingua franca]]'' for the development of mathematical themes.

==Bourbaki==

The cause of axiomatic development was taken up in earnest by the [[Bourbaki group]] of mathematicians. Taken to its extreme, this attitude was thought to demand mathematics developed in its greatest generality. One started from the most general axioms, and then specialized, for example, by introducing [[module (mathematics)|modules]] over [[commutative ring]]s, and limiting to [[vector space]]s over the [[real number]]s only when absolutely necessary. The story proceeded in this fashion, even when the specializations were the theorems of primary interest.

In particular, this perspective placed little value on fields of mathematics (such as [[combinatorics]]) whose objects of study are very often special, or found in situations which can only superficially be related to more axiomatic branches of the subject.

==Category theory as a rival==

[[Category theory]] is a unifying theory of mathematics that was initially developed in the second half of the 20th century. In this respect it is an alternative and complement to set theory. A key theme from the "categorical" point of view is that mathematics requires not only certain kinds of objects ([[Lie group]]s, [[Banach space]]s, etc.) but also mappings between them that preserve their structure.

In particular, this clarifies exactly what it means for mathematical objects to be considered to be ''the same''. (For example, are all equilateral triangles ''the same'', or does size matter?) [[Saunders Mac Lane]] proposed that any concept with enough 'ubiquity' (occurring in various branches of mathematics) deserved isolating and studying in its own right. Category theory is arguably better adapted to that end than any other current approach. The disadvantages of relying on so-called ''[[abstract nonsense]]'' are a certain blandness and abstraction in the sense of breaking away from the roots in concrete problems. Nevertheless, the methods of category theory have steadily advanced in acceptance, in numerous areas (from [[D-module]]s to [[categorical logic]]).

==Uniting theories==

On a less grandiose scale, there are frequent instances in which it appears that sets of results in two different branches of mathematics are similar, and one might ask whether there is a unifying framework which clarifies the connections. We have already noted the example of analytic geometry, and more generally the field of [[algebraic geometry]] thoroughly develops the connections between geometric objects ([[algebraic varieties]], or more generally [[scheme (mathematics)|scheme]]s) and algebraic ones ([[ideal (ring theory)|ideal]]s); the touchstone result here is [[Hilbert's Nullstellensatz]] which roughly speaking shows that there is a natural one-to-one correspondence between the two types of objects.

One may view other theorems in the same light. For example, the [[fundamental theorem of Galois theory]] asserts that there is a one-to-one correspondence between extensions of a field and subgroups of the field's [[Galois group]]. The [[Taniyama–Shimura conjecture]] for elliptic curves (now proven) establishes a one-to-one correspondence between curves defined as [[modular forms]] and [[elliptic curve]]s defined over the [[rational number]]s. A research area sometimes nicknamed [[Monstrous Moonshine]] developed connections between modular forms and the finite simple group known as the [[Monster group|Monster]], starting solely with the surprise observation that in each of them  the rather unusual number 196884 would arise very naturally. Another field, known as the [[Langlands program]], likewise starts with apparently haphazard similarities (in this case, between number-theoretical results and representations of certain groups) and looks for constructions from which both sets of results would be corollaries.

==Reference list of major unifying concepts==

A short list of these theories might include:

{{columns-list|colwidth=30em|
*[[Cartesian geometry]]
*[[Calculus]]
*[[Complex analysis]]
*[[Galois theory]]
*[[Erlangen programme]]
*[[Lie group]]
*[[Set theory]]
*[[Hilbert space]]
*[[Computable function]]
*[[Characteristic class]]es
*[[Homological algebra]]
*[[Homotopy theory]]
*[[Scheme (mathematics)|Grothendieck's schemes]]
*[[Topos theory]]
*[[Langlands program]]
*[[Non-commutative geometry]]
}}

==Recent developments in relation with modular theory==

A well-known example is the [[Taniyama–Shimura conjecture]], now the [[modularity theorem]], which proposed that each [[elliptic curve]] over the rational numbers can be translated into a [[modular form]] (in such a way as to preserve the associated [[L-function]]). There are difficulties in identifying this with an isomorphism, in any strict sense of the word. Certain curves had been known to be both elliptic curves (of [[genus (mathematics)|genus]] 1) and [[modular curve]]s, before the conjecture was formulated (about 1955). The surprising part of the conjecture was the extension to factors of [[Jacobian variety|Jacobian]]s of modular curves of genus &gt; 1. It had probably not seemed plausible that there would be 'enough' such rational factors, before the conjecture was enunciated; and in fact the numerical evidence was slight until around 1970, when tables began to confirm it. The case of elliptic curves with [[complex multiplication]] was proved by Shimura in 1964. This conjecture stood for decades before being proved in generality.

In fact the [[Langlands program]] (or philosophy) is much more like a web of unifying conjectures; it really does postulate that the general theory of [[automorphic form]]s is regulated by the [[Langlands dual group|L-group]]s introduced by [[Robert Langlands]]. His ''principle of functoriality'' with respect to the L-group has a very large explanatory value with respect to known types of ''lifting'' of automorphic forms (now more broadly studied as [[automorphic representation]]s). While this theory is in one sense closely linked with the Taniyama–Shimura conjecture, it should be understood that the conjecture actually operates in the opposite direction. It requires the existence of an automorphic form, starting with an object that (very abstractly) lies in a category of [[motive (mathematics)|motives]].

Another significant related point is that the Langlands approach stands apart from the whole development triggered by [[monstrous moonshine]] (connections between [[elliptic modular function]]s as [[Fourier series]], and the [[group representation]]s of the [[Monster group]] and other [[sporadic group]]s). The Langlands philosophy neither foreshadowed nor was able to include this line of research.

==Isomorphism conjectures in K-theory==

Another case, which so far is less well-developed but covers a wide range of mathematics, is the conjectural basis of some parts of [[K-theory]]. The [[Baum–Connes conjecture]], now a long-standing problem, has been joined by others in a group known as the [[isomorphism conjectures in K-theory]]. These include the [[Farrell–Jones conjecture]] and [[Bost conjecture]].

==See also==

*[[Philosophy of mathematics]]
*[[Foundations of mathematics]]

[[Category:History of mathematics]]
[[Category:Theories of deduction]]</text>
      <sha1>7sxc284a4m3rvxdgfasotd20hccos5f</sha1>
    </revision>
  </page>
  <page>
    <title>Valentina Borok</title>
    <ns>0</ns>
    <id>1591416</id>
    <revision>
      <id>802511544</id>
      <parentid>802511477</parentid>
      <timestamp>2017-09-26T16:42:42Z</timestamp>
      <contributor>
        <username>Simulacrum</username>
        <id>24891374</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8199">{{Infobox person
| name         = Valentina Borok
| image        =
| caption      = 
| birth_name   = Valentina Mikhailovna Borok
| birth_date   = {{Birth date|1931|7|9|df=y}}
| birth_place  = [[Kharkiv]] in Ukraine
| death_date   = {{Death date and age|2004|2|4|1931|7|9|df=y}}
| death_place  = [[Haifa]], [[Israel]]
| occupation   = [[Mathematician]], [[professor]]
| years_active = 1949–1994
| spouse       = Yakov Zhitomirskii&lt;br&gt;&lt;/small&gt;
| children     = [[Svetlana Jitomirskaya]]}}

'''Valentina Mikhailovna Borok''' (9 July 1931, [[Kharkiv]], [[Ukraine]], [[USSR]] – 4 February
2004, [[Haifa]], [[Israel]]) was a [[USSR|Soviet]] [[Ukraine|Ukrainian]] [[mathematician]]. She is mainly known for her work on [[partial differential equations]].&lt;ref&gt;{{MacTutor|id=Borok|title=Valentina Mikhailovna Borok}}&lt;/ref&gt;

== Life ==
Borok was born in July 9, 1931 in [[Kharkiv]] in Ukraine (then USSR), into a Jewish family&lt;ref&gt;[http://www-history.mcs.st-and.ac.uk/Biographies/Borok.html Valentina Mikhailovna Borok]&lt;/ref&gt;. Her father, Michail Borok, was a [[chemist]], [[scientist]] and an expert in [[material science]]. Her mother, Bella Sigal, was a well-known economist. Because of her mothers' high position at the ministry of [[Economics]], Valentina Borok had a privileged early childhood. However, because of the political situation, her mother voluntarily resigned in 1937 and took a lower position, presumably because she knew she couldn't possibly have been spared the repressions of the late 1930s. This possibly helped the Borok family survive [[World War II]].

Valentina Borok had a talent for math even in her high school years. So in 1949, with the advice of her high school teachers Borok started to study Mathematics at [[Kiev State University]]. There she met Yakov Zhitomirskii, who would be her husband until her death. During her stay at [[Kiev State University]], Borok long with her future husband started her research in the field of mathematics under the supervision of the mathematics department supervisor, Georgii Shilov. Her undergraduate thesis on distribution theory and the applications to the theory of systems of linear partial differential equations was found to be extraordinary and was published in a top Russian journal. This thesis was later selected in 1957 to be part of the first volumes of American Mathematical Society translations.
In 1954, Borok graduated from [[Kiev State University]] and moved to [[Moscow State University]] in order to receive her graduate degree. In 1957, she received her [[PhD]] for her thesis ''On Systems of Linear Partial Differential Equations with Constant Coefficients''. The information about the system of Linear Partial Differential equations with constant coefficient was publicized in the annals of mathematics. She later published more papers from 1954 to 1959, which contained a range of inverse theorems that allowed partial differential equations to be characterized by certain properties of their solutions. “In the same period she obtained formula that made it possible to compute in simple algebraic terms the numerical parameters that determine classes of uniqueness and well-posed of the Cauchy problem for systems of linear partial differential equations with constant coefficients". In 1960, she moved to [[Kharkiv State University]], where she stayed until 1994. In 1970, Borok became a full professor and from 1983 to 1994, she was the Chair of the analysis department.

In the early 1960s Borok worked on the stability for partial differential equations well-posed. Her other works at this time were on the parabolic systems degnerating at infinity and on the dependence of classes of uniqueness on the transformations of the spatial argument. most of her works during this period of time were mostly joint works with her husband Yakov Zhitomirskii.

And during the period of the late 1960s, Borok began her series of papers that laid the foundations for the theory of local and non-local boundary value problems in infinite layers for systems of partial differential equations. The results of her studies included the construction of maximal classes of uniqueness and well-posedness, [[Phragmén–Lindelöf principle|Phragmen- Lindelöf type theorems]], and the study of asymptotic properties and stability of solutions of boundary-value problems in infinite layers.

Starting in the early 1970s, Borok opened a school for the study of the general theory of Partial Differential Equations in [[Kharkiv State University]]. Many of her papers helped the development of the theory of local and non-local boundary value problems in infinite layers for systems of Partial differential equations.  One of her earliest works includes results on the uniqueness and well-posedness of the solutions of the Cauchy problem. Most of her works were concentrated in the area of Partial differential equations along with functional-differential equations. even to this day many of her works are being cited.

During her years of being a professor at [[Kharkiv State University]], Borok was considered the teacher of rigorous analysis, which was a course in which many of the students got their first taste in research. Borok was known for her "creative problems" as well as her development of original lecture notes for many of the core and specialized courses in analysis and Partial differential Equations. She set the curriculum of the mathematics department in [[Kharkiv State University]] for more than 30 years, setting the tradition in the university.

In 1994, Borok became severely ill but because there was no necessary medical attention available in Ukraine, she had to move to [[Haifa]], [[Israel]]. She died at the age of 72 in 2004. Both of her children, Michail Zhitomirskii and [[Svetlana Jitomirskaya]], became research mathematicians.

==Works==
Borok is known for her research and contribution on the partial differentiation equation. During her lifetime she published 80 papers in top Russian and Ukrainian journals as well as supervised 16 PhDs along with many master theses.

Many of her thesis development included the studies of the Cauchy problem for the linear partial differential equations, which was published in the ''[[Annals of Mathematics]]''&lt;ref&gt;{{citation
 | last = Bochner | first = S. | authorlink = Salomon Bochner
 | journal = [[Annals of Mathematics]]
 | mr = 0015611
 | pages = 202–212
 | series = Second Series
 | title = Linear partial differential equations, with constant coefficients
 | volume = 47
 | year = 1946
 | doi=10.2307/1969243}}.&lt;/ref&gt; explaining the theory behind the linear partial differential equation.
In other works she has proved the theorem on uniqueness and well-posedness theorems for the initial
value problem as well as the Cauchy problem for system of linear partial differential equations.

In her studies, translated from Russian, in the Cauchy problem for systems of linear partial differential equations that are functional with respect to parameter, Her summary states that she proves that for the study in Cauchy problem for≠ system of equations of the form đu(x,y,z)/đt = P(đ/đx)u(x,t,ɖy), xɛRn, tɛ[0,T],y&gt;0,ɖ&gt;0, ɖ≠1, uɛCn, Where P(S) is an N x N Matrix with polynomial elements. We prove the existence of solutions of the homogeneous problem which exponentially converge to zero as |x|→∞ and for each y&gt;0. she established estimates for the solutions as |x|→∞, y→∞ or y→+0 which guarantee its uniqueness. and she found conditions for the correct solvability of the problem in the class of solutions which are polynomial with respect to y.

==References==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Borok, Valentina}}
[[Category:1931 births]]
[[Category:2004 deaths]]
[[Category:Moscow State University alumni]]
[[Category:Soviet academics]]
[[Category:Soviet mathematicians]]
[[Category:Taras Shevchenko National University of Kyiv alumni]]
[[Category:Ukrainian academics]]
[[Category:Ukrainian emigrants to Israel]]
[[Category:Ukrainian mathematicians]]
[[Category:Ukrainian Jews]]
[[Category:University of Kharkiv faculty]]
[[Category:Women mathematicians]]
[[Category:20th-century women scientists]]</text>
      <sha1>egpteaxkpk8gvwpy2krsbvr8dws3rkj</sha1>
    </revision>
  </page>
  <page>
    <title>Variable-length code</title>
    <ns>0</ns>
    <id>7280707</id>
    <revision>
      <id>852063539</id>
      <parentid>767092294</parentid>
      <timestamp>2018-07-26T11:31:16Z</timestamp>
      <contributor>
        <username>Puml</username>
        <id>31707693</id>
      </contributor>
      <minor/>
      <comment>/* Uniquely decodable codes */ Added minor spacing</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7934">{{Otheruses4|the transmission of data across noisy channels|the storage of text in computers|Variable-width encoding}}
In [[coding theory]] a '''variable-length code''' is a [[code]] which  maps source symbols to a ''variable'' number of bits. 

Variable-length codes can allow sources to be [[data compression|compressed]] and decompressed with ''zero'' error ([[lossless data compression]]) and still be read back symbol by symbol.  With the right coding strategy an [[independent and identically-distributed random variables|independent and identically-distributed source]] may be compressed almost arbitrarily close to its [[information entropy|entropy]]. This is in contrast to fixed length coding methods, for which data compression is only possible for large blocks of data, and any compression beyond the logarithm of the total number of possibilities comes with a finite (though perhaps arbitrarily small) probability of failure.  

Some examples of well-known variable-length coding strategies are [[Huffman coding]], [[Lempel–Ziv|Lempel–Ziv coding]] and [[arithmetic coding]].

== Codes and their extensions ==

The extension of a code is the mapping of finite length source sequences to finite length bit strings, that is obtained by concatenating for each symbol of the source sequence the corresponding codeword produced by the original code. 

Using terms from [[formal language theory]], the precise mathematical definition is as follows: Let &lt;math&gt;S&lt;/math&gt; and &lt;math&gt;T&lt;/math&gt; be two finite sets, called the source and target [[alphabet (computer science)|alphabets]], respectively. A '''code''' &lt;math&gt;C: S \to T^*&lt;/math&gt; is a [[total function]] mapping each symbol from &lt;math&gt;S&lt;/math&gt; to a [[Word (data type)|sequence of symbols]] over &lt;math&gt;T&lt;/math&gt;, and the extension of &lt;math&gt;C&lt;/math&gt; to a [[Homomorphism#Homomorphisms_and_e-free_homomorphisms_in_formal_language_theory|homomorphism]] of &lt;math&gt;S^*&lt;/math&gt; into &lt;math&gt;T^*&lt;/math&gt;, which naturally maps each sequence of source symbols to a sequence of target symbols, is referred to as its '''extension'''.

== Classes of variable-length codes ==

Variable-length codes can be strictly nested in order of decreasing generality as non-singular codes, uniquely decodable codes and prefix codes. Prefix codes are always uniquely decodable, and these in turn are always non-singular:

=== Non-singular codes ===

A code is '''non-singular''' if each source symbol is mapped to a different non-empty bit string, i.e. the mapping from source symbols to bit strings is [[injective]].
* For example the mapping &lt;math&gt;M_1 = \{\, a\mapsto 0, b\mapsto 0, c\mapsto 1\,\}&lt;/math&gt; is '''not''' non-singular because both "a" and "b" map to the same bit string "0" ; any extension of this mapping will generate a lossy (non-lossless) coding. Such singular coding may still be useful when some loss of information is acceptable (for example when such code is used in audio or video compression, where a lossy coding becomes equivalent to source [[Quantization (signal processing)|quantization]]).
* However, the mapping &lt;math&gt;M_2 = \{\, a \mapsto 1, b \mapsto 011, c\mapsto 01110, d\mapsto 1110, e\mapsto 10011, f\mapsto0\}&lt;/math&gt; is non-singular ; its extension will generate a lossless coding, which will be useful for general data transmission (but this feature is not always required). Note that it is not necessary for the non-singular code to be more compact than the source (and in many applications, a larger code is useful, for example as a way to detect and/or recover from encoding or transmission errors, or in security applications to protect a source from undetectable tampering).

=== Uniquely decodable codes ===

A code is '''uniquely decodable''' if its extension is non-singular (see above). Whether a given code is uniquely decodable can be decided with the [[Sardinas–Patterson algorithm]]. 
* The mapping &lt;math&gt;M_3 = \{\, a\mapsto 0, b\mapsto 01, c\mapsto 011\,\}&lt;/math&gt; is uniquely decodable (this can be demonstrated by looking at the ''follow-set'' after each target bit string in the map, because each bitstring is terminated as soon as we see a 0 bit which cannot follow any existing code to create a longer valid code in the map, but unambiguously starts a new code).
* Consider again the code  &lt;math&gt;M_2&lt;/math&gt; from the previous section. This code, which is based on an example found in,&lt;ref&gt;Berstel et al. (2009), Example 2.3.1, p. 63&lt;/ref&gt; is '''not''' uniquely decodable, since the string ''011101110011'' can be interpreted as the sequence of codewords ''01110 – 1110 – 011'', but also as the sequence of codewords ''011 – 1 – 011 – 10011''. Two possible decodings of this encoded string are thus given by ''cdb'' and ''babe''. However, such a code is useful when the set of all possible source symbols is completely known and finite, or when there are restrictions (for example a formal syntax) that determine if source elements of this extension are acceptable. Such restrictions permit the decoding of the original message by checking which of the possible source symbols mapped to the same symbol are valid under those restrictions.

=== Prefix codes ===
{{Main|Prefix code}}

A code is a '''prefix code''' if no target bit string in the mapping is a prefix of the target bit string of a different source symbol in the same mapping. This means that symbols can be decoded instantaneously after their entire codeword is received. Other commonly used names for this concept are '''prefix-free code''', '''instantaneous code''', or '''context-free code'''.
* The example mapping &lt;math&gt;M_3&lt;/math&gt; in the previous paragraph is '''not''' a prefix code because we don't know after reading the bit string "0" if it encodes an "a" source symbol, or if it is the prefix of the encodings of the "b" or "c" symbols.
* An example of a prefix code is shown below.
{| class="wikitable" style="text-align:center; position: relative; left: 1in;" |
|-
! Symbol !! Codeword
|-
| a || 0
|-
| b || 10
|-
| c || 110
|-
| d || 111
|}
:: Example of encoding and decoding:
::: aabacdab → 00100110111010 → |0|0|10|0|110|111|0|10| → aabacdab

A special case of prefix codes are [[block code]]s. Here all codewords must have the same length. The latter are not very useful in the context of [[data compression|source coding]], but often serve as [[forward error correction|error correcting codes]] in the context of [[channel coding]].

Another special case of prefix codes are [[variable-length quantity]] codes, which encode arbitrarily large integers as a sequence of octets -- i.e., every codeword is a multiple of 8 bits.

== Advantages ==

The advantage of a variable-length code is that unlikely source symbols can be assigned longer codewords and likely source symbols can be assigned shorter codewords, thus giving a low [[Expected_value|''expected'']] codeword length. For the above example, if the probabilities of (a, b, c, d) were &lt;math&gt;\textstyle\left(\frac{1}{2}, \frac{1}{4}, \frac{1}{8}, \frac{1}{8}\right)&lt;/math&gt;, the expected number of bits used to represent a source symbol using the code above would be:
:: &lt;math&gt;1\times\frac{1}{2}+2\times\frac{1}{4}+3\times\frac{1}{8}+3\times\frac{1}{8}=\frac{7}{4}&lt;/math&gt;.
As the entropy of this source is 1.7500 bits per symbol, this code compresses the source as much as possible so that the source can be recovered with ''zero'' error.

== Notes ==
&lt;references/&gt;
==References==
* {{cite book | last1=Berstel | first1=Jean | last2=Perrin | first2=Dominique | last3=Reutenauer | first3=Christophe | title=Codes and automata | series=Encyclopedia of Mathematics and its Applications | volume=129 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2010 | isbn=978-0-521-88831-8 | zbl=1187.94001 }}  [http://www-igm.univ-mlv.fr/~berstel/LivreCodes/Codes.html Draft available online]

{{Compression Methods}}

[[Category:Coding theory]]
[[Category:Lossless compression algorithms]]</text>
      <sha1>b76u80wtb3y9i2v3gd8s0h3oebffaqr</sha1>
    </revision>
  </page>
  <page>
    <title>Vieta's formulas</title>
    <ns>0</ns>
    <id>714050</id>
    <revision>
      <id>869127709</id>
      <parentid>869125989</parentid>
      <timestamp>2018-11-16T16:09:17Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* Example */ ce</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7239">{{For|a method for computing {{pi}}|Viète's formula}}
In [[mathematics]], '''Vieta's formulas''' are [[formula]]s that relate the [[coefficient]]s of a [[polynomial]] to sums and products of its [[Root of a function|roots]]. Named after [[François Viète]] (more commonly referred to by the Latinised form of his name, '''Franciscus Vieta'''), the formulas are used specifically in [[algebra]].

==Basic formulas==
Any general polynomial of degree ''n''
:&lt;math&gt;P(x)=a_nx^n  + a_{n-1}x^{n-1} +\cdots + a_1 x+ a_0 &lt;/math&gt;

(with the coefficients being real or complex numbers and ''a''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;≠&amp;nbsp;0) is known by the [[fundamental theorem of algebra]] to have ''n'' (not necessarily distinct) complex roots ''x''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''x''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;...,&amp;nbsp;''x''&lt;sub&gt;''n''&lt;/sub&gt;. Vieta's formulas relate the polynomial's coefficients {&amp;nbsp;''a''&lt;sub&gt;''k''&lt;/sub&gt;&amp;nbsp;} to signed sums and products of its roots {&amp;nbsp;''x''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;} as follows:

:&lt;math&gt;\begin{cases} x_1 + x_2 + \dots + x_{n-1} + x_n = -\dfrac{a_{n-1}}{a_{n}} \\ 
(x_1 x_2 + x_1 x_3+\cdots + x_1x_n) + (x_2x_3+x_2x_4+\cdots + x_2x_n)+\cdots + x_{n-1}x_n = \dfrac{a_{n-2}}{a_{n}} \\
{} \quad \vdots \\ x_1 x_2 \dots x_n = (-1)^n \dfrac{a_0}{a_n}. \end{cases}&lt;/math&gt;

Equivalently stated, the (''n''&amp;nbsp;&amp;minus;&amp;nbsp;''k'')th coefficient ''a''&lt;sub&gt;''n''&amp;minus;''k''&lt;/sub&gt; is related to a signed sum of all possible subproducts of roots, taken ''k''-at-a-time:

: &lt;math&gt;\sum_{1\le i_1 &lt; i_2 &lt; \cdots &lt; i_k\le n} x_{i_1}x_{i_2}\cdots x_{i_k}=(-1)^k\frac{a_{n-k}}{a_n}&lt;/math&gt;

for ''k''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;...,&amp;nbsp;''n'' (where we wrote the indices ''i''&lt;sub&gt;''k''&lt;/sub&gt; in increasing order to ensure each subproduct of roots is used exactly once).

The left hand sides of Vieta's formulas are the '''[[elementary symmetric polynomial|elementary symmetric function]]s''' of the roots.

==Generalization to rings==
Vieta's formulas are frequently used with polynomials with coefficients in any [[integral domain]] ''R''. Then, the quotients &lt;math&gt;a_i/a_n&lt;/math&gt; belong to the [[ring of fractions]] of ''R'' (or in ''R'' itself if &lt;math&gt;a_n&lt;/math&gt; is invertible in ''R'') and the roots &lt;math&gt;x_i&lt;/math&gt; are taken in an [[algebraically closed field|algebraically closed extension]]. Typically, ''R'' is the ring of the [[integer]]s, the field of fractions is the field of the [[rational number]]s and the algebraically closed field is the field of the [[complex numbers]].

Vieta's formulas are then useful because they provide relations between the roots without having to compute them.

For polynomials over a commutative ring which is not an integral domain, Vieta's formulas are only valid when &lt;math&gt;a_n&lt;/math&gt; is a non-zerodivisor and &lt;math&gt;P(x)&lt;/math&gt; factors as &lt;math&gt;a_n(x-x_1)(x-x_2)\dots(x-x_n)&lt;/math&gt;.  For example, in the ring of the integers [[Modular arithmetic|modulo]] 8, the polynomial &lt;math&gt;P(x)=x^2-1&lt;/math&gt; has four roots: 1, 3, 5, and 7. Vieta's formulas are not true if, say, &lt;math&gt;x_1=1&lt;/math&gt; and &lt;math&gt;x_2=3&lt;/math&gt;, because &lt;math&gt;P(x)\neq (x-1)(x-3)&lt;/math&gt;.  However, &lt;math&gt;P(x)&lt;/math&gt; does factor as &lt;math&gt; (x-1)(x-7)&lt;/math&gt; and as &lt;math&gt;(x-3)(x-5)&lt;/math&gt;, and Vieta's formulas hold if we set either &lt;math&gt;x_1=1&lt;/math&gt; and &lt;math&gt;x_2=7&lt;/math&gt; or &lt;math&gt;x_1=3&lt;/math&gt; and &lt;math&gt;x_2=5&lt;/math&gt;.

==Example==
Vieta's formulas applied to quadratic and cubic polynomial:

The roots &lt;math&gt;x_1, x_2&lt;/math&gt; of the [[quadratic polynomial]] &lt;math&gt;P(x) = ax^2 + bx + c&lt;/math&gt; satisfy
:&lt;math&gt; x_1 + x_2 = -\frac{b}{a}, \quad x_1 x_2 = \frac{c}{a}.&lt;/math&gt;

The first of these equations can be used to find the minimum (or maximum) of {{math|''P''}}; see {{slink|Quadratic equation|Vieta's formulas}}.

The roots &lt;math&gt;x_1, x_2, x_3&lt;/math&gt; of the [[cubic polynomial]] &lt;math&gt;P(x) = ax^3 + bx^2 + cx + d&lt;/math&gt; satisfy
:&lt;math&gt; x_1 + x_2 + x_3 = -\frac{b}{a}, \quad x_1 x_2 + x_1 x_3 + x_2 x_3 = \frac{c}{a}, \quad x_1 x_2 x_3 = -\frac{d}{a}.&lt;/math&gt;

==Proof==
Vieta's formulas can be proved by expanding the equality

: &lt;math&gt;a_nx^n  + a_{n-1}x^{n-1} +\cdots + a_1 x+ a_0 = a_n(x-x_1)(x-x_2)\cdots (x-x_n)&lt;/math&gt;

(which is true since &lt;math&gt;x_1, x_2, \dots, x_n&lt;/math&gt; are all the roots of this  polynomial), multiplying the factors on the right-hand side, and identifying the coefficients of each power of &lt;math&gt;x.&lt;/math&gt;

Formally, if one expands &lt;math&gt;(x-x_1)(x-x_2)\cdots(x-x_n),&lt;/math&gt; the terms are precisely &lt;math&gt;(-1)^{n-k}x_1^{b_1}\cdots x_n^{b_n} x^k,&lt;/math&gt; where &lt;math&gt;b_i&lt;/math&gt; is either 0 or 1, accordingly as whether &lt;math&gt;x_i&lt;/math&gt; is included in the product or not, and ''k'' is the number of &lt;math&gt;x_i&lt;/math&gt; that are excluded, so the total number of factors in the product is ''n'' (counting ''&lt;math&gt;x^k&lt;/math&gt;'' with multiplicity ''k'') – as there are ''n'' binary choices (include &lt;math&gt;x_i&lt;/math&gt; or ''x''), there are &lt;math&gt;2^n&lt;/math&gt; terms – geometrically, these can be understood as the vertices of a hypercube. Grouping these terms by degree yields the elementary symmetric polynomials in &lt;math&gt;x_i&lt;/math&gt; – for ''x&lt;sup&gt;k&lt;/sup&gt;,'' all distinct ''k''-fold products of &lt;math&gt;x_i.&lt;/math&gt;

== History ==
As reflected in the name, the formulas were discovered by the 16th century French mathematician [[François Viète]], for the case of positive roots.

In the opinion of the 18th century British mathematician [[Charles Hutton]], as quoted by Funkhouser,&lt;ref&gt;{{Harv|Funkhouser|1930}}&lt;/ref&gt; the general principle (not only for positive real roots) was first understood by the 17th century French mathematician [[Albert Girard]]: 
&lt;blockquote&gt;...[Girard was] the first person who understood the general doctrine of the formation of the coefficients of the powers from the sum of the roots and their products. He was the first who discovered the rules for summing the powers of the roots of any equation.&lt;/blockquote&gt;

==See also==

* [[Newton's identities]]
* [[Elementary symmetric polynomial]]
* [[Symmetric polynomial]]
* [[Content (algebra)]]
* [[Properties of polynomial roots]]
* [[Gauss–Lucas theorem]]
* [[Rational root theorem]]
* [[Vieta jumping]]

== References ==
{{reflist}}
* {{springer|title=Viète theorem|id=p/v096630}}
* {{Citation| first= H. Gray | last=Funkhouser | authorlink = Howard G. Funkhouser | title=A short account of the history of symmetric functions of roots of equations | journal=American Mathematical Monthly | year=1930 | volume= 37 | issue=7 | pages=357–365 | doi=10.2307/2299273| jstor= 2299273| publisher= Mathematical Association of America }}
*{{Citation
 | last       = Vinberg
 | first      = E. B.
 | authorlink= Ernest Vinberg
 | title      = A course in algebra
 | publisher  = American Mathematical Society, Providence, R.I
 | year       = 2003
 | pages      = 
 | isbn       = 0-8218-3413-4
}}

*{{Citation
 | last       = Djukić
 | first      = Dušan| title      = The IMO compendium: a collection of problems suggested for the International Mathematical Olympiads, 1959–2004
 | publisher  = Springer, New York, NY
 | year       = 2006
 | pages      = 
 | isbn       = 0-387-24299-6
|display-authors=etal}}

{{DEFAULTSORT:Viete's Formulas}}
[[Category:Articles containing proofs]]
[[Category:Polynomials]]
[[Category:Elementary algebra]]</text>
      <sha1>eaz69mvb5jzxv2cqb20ubveozicltww</sha1>
    </revision>
  </page>
  <page>
    <title>Volume-weighted average price</title>
    <ns>0</ns>
    <id>1869136</id>
    <revision>
      <id>863756870</id>
      <parentid>863756677</parentid>
      <timestamp>2018-10-12T20:19:30Z</timestamp>
      <contributor>
        <username>CLCStudent</username>
        <id>26398660</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/188.70.46.32|188.70.46.32]] ([[User talk:188.70.46.32|talk]]) to last version by Ontarioboy</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4002">{{Refimprove|date=June 2012}}
In finance, '''volume-weighted average price (VWAP)''' is the ratio of the value traded to total [[volume (finance)|volume]] traded over a particular time horizon (usually one day). It is a measure of the average price at which a [[stock]] is traded over the trading horizon.&lt;ref name=Berkowitz&gt;{{cite journal|last1=Berkowitz |first1=Stephen A. |last2=Logue |first2=Dennis E. |last3=Noser |first3=Eugene A. J. |date=March 1988 |title=The Total Cost of Transactions on the NYSE |journal=Journal of Finance |publisher=American Finance Association |volume=43 |issue=1 |pages=97–112 |doi=10.1111/j.1540-6261.1988.tb02591.x}}&lt;/ref&gt;

VWAP is often used as a trading [[Benchmarking|benchmark]] by investors who aim to be as passive as possible in their execution. Many [[pension fund]]s, and some [[mutual fund]]s, fall into this category. The aim of using a VWAP trading target is to ensure that the [[trader (finance)|trader]] executing the order does so in-line with volume on the market. It is sometimes argued that such execution reduces [[transaction costs]] by minimizing [[market impact cost]]s (the additional cost due to the [[market impact]], i.e. the adverse effect of a trader's activities on the price of a [[Security (finance)|security]]).

VWAP can be measured between any two points in time but is displayed as the one corresponding to elapsed time during the trading day by the information provider.

VWAP is often used in [[algorithmic trading]]. Indeed, a [[broker]] may guarantee execution of an order at the VWAP and have a computer program enter the orders into the market in order to earn the trader's [[Commission (remuneration)|commission]] and create [[P&amp;L]]. This is called a guaranteed VWAP execution. The broker can also trade in a best effort way and answer to the client the realized price. This is called a VWAP target execution; it incurs more dispersion in the answered price compared to the VWAP price for the client but a lower received/paid commission. Trading algorithms that use VWAP as a target belong to a class of algorithms known as ''volume participation algorithms''.

The first execution of the VWAP was in 1984 for the Ford Motor Company by James Elkins, then head trader at Abel Noser.{{cn|date=July 2016}}  

==Formula==
VWAP is calculated using the following formula:
:&lt;math&gt;P_{\mathrm{VWAP}} = \frac{\sum_{j}{P_j \cdot Q_j}}{\sum_j{Q_j}} \,&lt;/math&gt;

where:
:&lt;math&gt;P_{\mathrm{VWAP}}&lt;/math&gt; is Volume Weighted Average Price;
:&lt;math&gt;P_j&lt;/math&gt; is price of trade &lt;math&gt;j&lt;/math&gt;;
:&lt;math&gt;Q_j&lt;/math&gt; is quantity of trade &lt;math&gt;j&lt;/math&gt;;
:&lt;math&gt;j&lt;/math&gt; is each individual trade that takes place over the defined period of time, excluding cross trades and basket cross trades.&lt;ref name=investopedia&gt;{{cite web|title=Volume Weighted Average Price (VWAP) Definition|publisher=Investopedia|url=http://www.investopedia.com/terms/v/vwap.asp|accessdate=June 14, 2012}}&lt;/ref&gt;

==Using the VWAP==

The VWAP can be used similar to moving averages, where prices above the VWAP reflect a bullish sentiment and prices below the VWAP reflect a bearish sentiment. Traders may initiate short positions as a stock price moves below VWAP for a given time period or initiate long position as the price moves above VWAP&lt;ref&gt;{{cite web|title=Volume Weighted Average Price|url=https://www.investorsunderground.com/technical-indicators/vwap-volume-weighted-average-price/|website=Investors Underground|publisher=Investors Live LLC|accessdate=29 June 2016}}&lt;/ref&gt;

Institutional buyers and algorithms will often use VWAP to plan entries and initiate larger positions without disturbing the stock price.&lt;ref name="investopedia" /&gt;

==See also==
* [[Electronic trading]]
* [[Time-weighted average price]]

==External links==
* [http://asiaetrading.com/tools/vwap_performance_calculator.php Trade Performance Calculator used to compare VWAP against actual traded price]

== References ==
{{Reflist}}

[[Category:Mathematical finance]]
[[Category:Stock market]]</text>
      <sha1>39sty45il2kntrhe6efl9dfpp7pyqag</sha1>
    </revision>
  </page>
  <page>
    <title>Weapon target assignment problem</title>
    <ns>0</ns>
    <id>32044869</id>
    <revision>
      <id>862264723</id>
      <parentid>862257199</parentid>
      <timestamp>2018-10-03T07:21:57Z</timestamp>
      <contributor>
        <ip>97.88.54.210</ip>
      </contributor>
      <comment>/* Example */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5300">The '''weapon target assignment problem''' ('''WTA''') is a class of [[combinatorial optimization]] problems present in the fields of [[Optimization (mathematics)|optimization]] and [[operations research]].  It consists of finding an optimal assignment of a set of [[weapon]]s of various types to a set of targets in order to maximize the total expected damage done to the opponent.

The basic problem is as follows:

:There are a number of weapons and a number of targets. The weapons are of type &lt;math&gt; i = 1, \ldots, m &lt;/math&gt;. There are &lt;math&gt; W_{i} &lt;/math&gt; available weapons of type &lt;math&gt;i&lt;/math&gt;. Similarly, there are &lt;math&gt; j = 1, \ldots, n &lt;/math&gt; targets, each with a value of &lt;math&gt; V_{j} &lt;/math&gt;. Any of the weapons can be assigned to any target. Each weapon type has a certain probability of destroying each target, given by &lt;math&gt; p_{ij} &lt;/math&gt;.

Notice that as opposed to the classic [[assignment problem]] or the [[generalized assignment problem]], more than one agent (i.e., weapon) can be assigned to each ''task'' (i.e., target) and not all targets are required to have weapons assigned. Thus, we see that the WTA allows one to formulate optimal assignment problems wherein tasks require cooperation among agents.  Additionally, it provides the ability to model probabilistic completion of tasks in addition to costs.

Both static and dynamic versions of WTA can be considered.  In the static case, the weapons are assigned to targets once. The dynamic case involves many rounds of assignment where the state of the system after each exchange of fire (round) is considered in the next round. While the majority of work has been done on the static WTA problem, recently the dynamic WTA problem has received more attention.

In spite of the name, there are nonmilitary applications of the WTA. The main one is to search for a lost object or person by heterogeneous assets such as dogs, aircraft, walkers, etc. The problem is to assign the assets to a partition of the space in which the object is located to minimize the probability of not finding the object. The "value" of each element of the partition is the probability that the object is located there.

==Formal mathematical definition==

The '''weapon target assignment problem''' is often formulated as the following nonlinear [[integer programming]] problem:

:&lt;math&gt;\min \sum_{j = 1}^n \left ( V_{j}\prod_{i = 1}^m q_{ij}^{x_{ij}} \right )&lt;/math&gt;

subject to the constraints

:&lt;math&gt;\sum_{j = 1}^n x_{ij}\leq W_i \text{ for }i = 1, \ldots, m, \, &lt;/math&gt;
:&lt;math&gt;x_{ij}\ge 0\text{ and integer for }i = 1, \ldots, m \text{ and }j = 1, \ldots, n.&lt;/math&gt;

Where the variable &lt;math&gt;x_{ij}&lt;/math&gt; represents the assignment of as many weapons of type &lt;math&gt;i&lt;/math&gt; to target &lt;math&gt;j&lt;/math&gt; and &lt;math&gt;q_{ij}&lt;/math&gt; is the probability of survival (&lt;math&gt; 1 - p_{ij} &lt;/math&gt;). The first constraint requires that the number of weapons of each type assigned does not exceed the number available.  The second constraint is the integral constraint.

Notice that minimizing the expected survival value is the same as maximizing the expected damage.

== Algorithms and generalizations ==

An exact solution can be found using [[branch and bound]] techniques which utilize [[relaxation (approximation)]]. Many [[heuristic algorithm]]s have been proposed which provide near-optimal solutions in [[polynomial time]].&lt;ref&gt;Ahuja, R. et al. Exact and Heuristic Algorithms for the Weapon-Target Assignment Problem. Operations Research 55(6), pp. 1136–1146, 2007&lt;/ref&gt;

==Example==
A commander has 5 tanks, 2 aircraft, and 1 sea vessel and is told to engage 3 targets with values 5, 10, and 20.  Each weapon type has the following success probabilities against each target:
::{| class="wikitable"
|-
! Weapon Type !! &lt;math&gt; V_{1} = 5 &lt;/math&gt; !! &lt;math&gt; V_{2} = 10 &lt;/math&gt; !! &lt;math&gt; V_{3} = 20 &lt;/math&gt;
|-
| Tank || 0.3 || 0.2 || 0.05
|-
| Aircraft || 0.1 || 0.6 || 0.5
|-
| Sea Vessel || 0.4 || 0.5 || 0.4
|}
One feasible solution is to assign the sea vessel and one aircraft to the highest valued target (3). This results in an expected survival value of &lt;math&gt; 20(0.6)(0.5)= 6 &lt;/math&gt;.  One could then assign the remaining aircraft and 2 tanks to target #2, resulting in expected survival value of &lt;math&gt; 10 (0.4)(0.8)^2 = 2.56 &lt;/math&gt;.  Finally, the remaining 3 tanks are assigned to target #1 which has an expected survival value of &lt;math&gt; 5 (0.7)^3 = 1.715 &lt;/math&gt;.  Thus, we have a total expected survival value of &lt;math&gt; 6 + 2.56 + 1.715 = 10.275 &lt;/math&gt;. Note that a better solution can be achieved by assigning 3 tanks to target #1, 2 tanks and sea vessel to target #2 and 2 aircraft to target #3, giving an expected survival value of &lt;math&gt; 5(0.7)^3 +10(0.5)(0.8)^2 + 20(0.5)^2 = 9.915 &lt;/math&gt;.

==See also==
*[[Auction algorithm]]
*[[Closure problem]]
*[[Generalized assignment problem]]
*[[Linear bottleneck assignment problem]]
*[[Quadratic assignment problem]]
*[[Stable marriage problem]]

== References ==
{{Reflist}}

== Further reading ==
* {{cite book
 | authorlink = Ravindra K. Ahuja
 | first = Ravindra | last = Ahuja
 |author2=T. L. Magnanti |author3=J. B. Orlin
  | year = 1993
 | title = Network Flows
 | publisher = Prentice Hall
 | isbn = 0-13-617549-X
 }}

[[Category:Combinatorial optimization]]
[[Category:Matching]]</text>
      <sha1>e6h5i82f1dsplfibfltc4a086712l3s</sha1>
    </revision>
  </page>
</mediawiki>
