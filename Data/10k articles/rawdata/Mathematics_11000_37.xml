<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Architect (The Matrix)</title>
    <ns>0</ns>
    <id>805753</id>
    <revision>
      <id>858098024</id>
      <parentid>857679886</parentid>
      <timestamp>2018-09-05T01:39:57Z</timestamp>
      <contributor>
        <ip>98.16.177.226</ip>
      </contributor>
      <comment>/* The Matrix Reloaded */ Made qoute accurate</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14559">{{For|other uses of the term|Architect (disambiguation)}}
{{In-universe|date=February 2009}}
{{DISPLAYTITLE:Architect (''The Matrix'')}}
{{Infobox character
| colour      = #A1CAF1
| name        = Architect
| series      = [[The Matrix (franchise)|The Matrix]]
| image       = TheArchitectMatrix.jpg
| image_size  = 300px
| caption     = 
| first       = ''[[The Matrix Reloaded]]''
| last        = 
| cause       = 
| creator     = [[The Wachowskis]]
| portrayer   = [[Helmut Bakaitis]]
| episode     = 
| nickname    = 
| alias       = 
| species     = Computer program
| gender      = Appeared as male
| age         = 
| born        = 
| death       = 
| specialty   = 
| occupation  = 
| title       = Creator of [[the Matrix (fictional universe)|the Matrix]]
| family      = 
| spouse      = 
| children    = 
| relatives   = 
| residence   = 
| religion    = 
| nationality = 
}}

The '''Architect''' is a fictional character in the films ''[[The Matrix Reloaded]]'' and ''[[The Matrix Revolutions]]''. He is portrayed by [[Helmut Bakaitis]]. He also makes an appearance in the [[MMORPG]] ''[[The Matrix Online]]''.

==History==

===Constructing the First Matrixes===
The Architect created the first Matrix as a utopia for the humans whose minds inhabited it. However, the human minds rejected this first attempt as a perfect world and beta 1 of the Matrix crashed. A second attempt added the varying grotesqueries of human nature and a basic cause and effect, but this beta was also a failure.&lt;ref name=matrix&gt;{{cite web|title=The Matrix Reloaded: Meaning &amp; Interpretations|url=http://thematrix101.com/reloaded/meaning.php|publisher=the matrix101.com|accessdate=30 October 2013}}&lt;/ref&gt;&lt;ref name=lees&gt;{{cite web|title=Neo and The Architect|url=http://www.leesmovieinfo.net/special/MatrixReloadedSpeech1.php|publisher=leesmovieinfo.net|accessdate=30 October 2013}}&lt;/ref&gt;&lt;ref name=imdb&gt;{{cite web|title=The Architect|url=https://www.imdb.com/character/ch0000770/quotes|publisher=imdb.com|accessdate=30 October 2013}}&lt;/ref&gt;&lt;ref name=neo&gt;{{cite web|title=Neo and the Architect - Matrix deconstructed |url=http://www.matrix-deconstructed.com/Neo-and-the-Architect.25.0.html?&amp;L=1 |archive-url=https://web.archive.org/web/20111022030353/http://matrix-deconstructed.com/Neo-and-the-Architect.25.0.html?&amp;L=1 |dead-url=yes |archive-date=22 October 2011 |publisher=matrix-deconstructed.com |accessdate=30 October 2013 }}&lt;/ref&gt;&lt;ref name=revolutions&gt;{{cite web|title=Christian Symbolism in Matrix Revolutions|url=http://webpages.charter.net/mark_turner/matrix/revolutions.htm|publisher=webpages.charter.net|accessdate=30 October 2013}}&lt;/ref&gt;     
The Architect turned to a more intuitive program designed to understand human nature and psychology to augment the framework of the next Matrix. This time, the power of choice was added to the programming, where humans would be allowed the power to choose, even if the person was only aware of the choice on a vague, subconscious level.

This version of the Matrix worked, except for approximately 1 percent of human minds. These humans were apparently bodily ejected from the power plant. Some of these humans survived to join Zion.

The Architect noted that the Matrix was not as perfect as he initially envisioned; the addition of 'choice' to the Matrix's programming added an unpredictable element to the Architect's equations and would eventually cause the Matrix to suffer a destructive system crash.  This 'systemic anomaly' was personified within the Matrix by a semi-mythological figure that could 'break free' of the Matrix's control, and change it in whatever manner he desired.  The 'One', as this figure came to be known, was subconsciously compelled to travel to the Matrix's mainframe with critical source code for its eventual reboot.

===A New Matrix===
Together with the human intuitive program the Oracle (which could be considered the "mother" of the Matrix as the Architect could be considered the "father") for human minds to understand, the concept of the Prophecy was formed. The intuitive program (known to the humans as the [[The Oracle (The Matrix)|Oracle]]) would tell of this story to the small members of a human resistance that periodically infiltrated the Matrix, who would find the anomaly and help him to find the Architect's office, hidden deep within a fortified building. There, the Architect would use his measures of control to keep the Anomaly, and in turn both Zion and the Matrix, in check. In each of the first five cycles of the lire Matrix, the Anomaly, known to the humans as The One, manifested itself within the Matrix and eventually found the Architect's office.

The room has two exits, one leading to the Source and the other to the Matrix proper (constructeur as hell and heaven.) The Architect tells the One that Zion is about to be destroyed and that humanity's only chance of survival rests with the One. If the One fails to go to the Source, the system will eventually suffer a catastrophic failure that leads to the death of every human still connected to the Matrix; combined with the destruction of Zion, the entire human race will become extinct. In order to prevent this result, the One must travel to the Source, reloading the master program, and then select a small number of individuals to rebuild Zion. In each of these five cycles, the One enters the door to the Source, the Matrix is reloaded, and Zion is destroyed and subsequently reborn.

===The Sixth One===
On the sixth iteration, [[Neo (The Matrix)|Neo]], the sixth Anomaly, appears on schedule before the Architect. The Architect is surprised that this One, unlike his predecessors, is quicker of thought. This sixth Anomaly possesses the same dispensation for protecting humanity as the others, but unlike the other Ones has a deep attachment to one human: a Zion resistance member named [[Trinity (The Matrix)|Trinity]].

The Architect delivers the usual speech and threat, but he can already see that this One will not comply as his predecessors did. Neo leaves the Architect to save his love, and leaves the future of the Matrix in doubt.

The Oracle tells Neo more about the Architect at their final meeting. She says that the Architect's purpose is to balance the equation of the Matrix, while her purpose is to ''unbalance'' that equation. She also tells Neo that, as a program designed to be mathematically precise, the Architect doesn't understand the inherently unpredictable nature of choice. She tells Neo to head to the true location of the Source, the Machine City, to save not only humanity, but the Machine world as well.
 
After Neo sacrifices himself to stabilize the Matrix, the Machines gather Neo's body and successfully 'reboot' the Matrix.  The Architect then meets the Oracle and speaks of the "dangerous game" that she played, and agrees to honor the truce that Neo brokered for his part in rebooting the Matrix.

==Character==

Near the climax of ''[[The Matrix Reloaded]]'', [[Neo (The Matrix)|Neo]] meets the Architect face to face in a large oval-shaped room with two doors, whose walls are covered with television monitors. (A close-up of these monitors is briefly seen early in ''[[The Matrix]]'' when showing Neo sitting in the interrogation room, but is not identified as such at the time.) Taking the form of a cold, humorless, elderly white-haired man in a light gray suit, he is a computer program that created the [[Matrix (fictional universe)|Matrix]] and now oversees its functioning. His artificial nature is more readily apparent than that of other programs personified as humans. The Architect is extremely mechanical in his actions, in that he speaks in long logical chains of reasoning, utilizing several connectors (discourse markers) such as "ergo", "concordantly", and "thus", and has little variance in his tone of voice. He also has little facial expression beyond smirks and glares, but does exhibit emotion on limited occasions, such as regret, annoyance and arrogance.

The Architect's first attempt at a Matrix was a [[utopia]], but it failed miserably and many human lives were lost when the inhabitants refused to accept it. The Architect then redesigned the Matrix to reflect the darker side of human nature and history, but the dystopian version failed too. The solution to this problem was discovered by [[Oracle (The Matrix)|the Oracle]]: a version of the Matrix that gave humans the unconscious choice of accepting it. This version was accepted by ninety-nine percent of the Matrix' test subjects, and the Matrix was rewritten to allow for freedom of choice. The remaining one percent, that did not accept the Matrix, would eventually destabilize the system so badly that the Matrix might catastrophically crash, killing every human that was still connected.

In ''[[The Matrix Revolutions]]'', the Oracle explains to Neo that the true purpose of the Architect is to balance the mathematical equations that make up the programming of the Matrix, and he is unable to see the world as anything beyond a series of equations. It is also because of this that he is unable to comprehend choice and free will and cannot see the results of such choices as they are no more than variable factors in an equation to him.

==Function==
With the new Matrix in place, a system was enacted to control the inhabitants who refused to accept it. While the Oracle was able to guide the actions of the humans who left the Matrix through prophecy, it was the Architect who programmed ''The One'' that would fulfill these prophecies. ''The One'' was made carrying not only the [[source code]] of the Matrix "''Prime Program''", which gave him his outstanding powers over the Matrix, but also with a profound attachment to humanity that would later motivate him to fulfill the prophecies being spread by the Oracle. Every time the free humans had grown strong enough to start threatening machine hegemony, ''The One'' would be born into the Matrix.

As the prophecies were fulfilled by ''The One'', the machines would begin building an army to destroy [[Zion (The Matrix)|Zion]]. Under the guidance of the Oracle, ''The One'' would find his way to the machine mainframe, also called ''The Source'', convinced that his actions there would end the war on behalf of the humans. Because the Architect resides in a room that lies on the path to the Source, the One would invariably encounter him along the way. During this encounter, the Architect would reveal his influence over the preceding events and the reason the Matrix had been designed to allow a small percentage of its inhabitants to escape. He would then present ''The One'' with a choice, symbolized by the two doors in his office:

* He may return to the Source, at which point the Matrix source code would be reinserted into the program, allowing for the system to reboot. Zion is still destroyed and people are still trapped in the Matrix, but the One would be allowed to select seven males and sixteen females (making a total of [[23 (numerology)|twenty-three]] individuals) from the Matrix  to be freed so that they could found a new Zion. The One would then die, and a prophecy of his return would be spread, continuing the cycle.
* He may refuse to cooperate and return to the Matrix in an attempt to save Zion. This would lead to a massive system crash, killing all of the inhabitants of the Matrix. Combined with the inevitable destruction of Zion, this would ultimately mean the extinction of humanity.

The machinations of the Architect and the Oracle were successful in maintaining the [[status quo]] to the point that, until Neo, all incarnations of ''The One'' had chosen to cooperate with the Machines in order to preserve humanity.

==Character history==
===''The Matrix Reloaded''===
The Architect offered Neo the same choice he offered his five predecessors. Unlike previous Ones, Neo was experiencing his programmed attachment to humanity in a specific way: in his love for Trinity. At the same time Neo had met with the Architect, Trinity was in the Matrix being chased by an Agent in a reenactment of a [[nightmare]] Neo had that ended with her apparent death.&lt;ref name=youtube&gt;{{cite web|title=The architect. MATRIX RELOAD avi|url=https://www.youtube.com/watch?v=2wdKlWXyUkc|publisher=youtube.com|accessdate=30 October 2013}}&lt;/ref&gt;

During their conversation, Neo claims that the machines cannot allow humanity to be destroyed as they are using them for power and thus could not survive if they were killed. In response, the Architect, although his face remains unmoved, states in a grave voice, "''There are levels of survival we are prepared to accept''."

Presented with a choice between the destruction of humanity or losing Trinity, Neo sees no choice. Motivated by his love for Trinity and not wanting to play into The Architect's ultimatum like his predecessors, he defies The Architect and chooses to attempt to save Trinity. Even though the Architect had asserted that her death was certain and his attempt to save her would mean doom for all humanity, Neo returns to the Matrix in an attempt to save her and end the machines' control of humanity.

Before Neo departs he warns The Architect, "''If I were you, I would hope that we don't meet again''." The Architect simply replies, "''We won't''."

===''The Matrix Revolutions''===
In the final scene of the film, the Architect joins the Oracle, commenting that she "played a very dangerous game", referring to the Oracle's role in guiding Neo as he defied the Architect's system of control. He then promises her that the humans who desire release from the Matrix will gain it. When she asks if he will keep his word he replies, "''What do you think I am? Human?''"

==Parodies==
{{more citations needed|date=December 2013}}
*A parody version of the character was played by [[George Carlin]] in the comedy film ''[[Scary Movie 3]]''.
*Another parody was played by [[Will Ferrell]] in the intro to the ''[[2003 MTV Movie Awards]]''.
*Another parody appeared in the ''[[South Park]]'' episode "[[Something Wall-Mart This Way Comes]]", featuring a white-haired man who identifies himself as "Wall-Mart."

==See also==
* [[Sigmund Freud]]
* [[Simulated reality]]

== References ==
{{Reflist}}

== External links ==
{{wikiquote|The Matrix Reloaded}}

{{Matrix}}

[[Category:The Matrix (franchise) characters]]
[[Category:Fictional artificial intelligences]]
[[Category:Fictional hermits]]
[[Category:Fictional mathematicians]]
[[Category:Science fiction film characters]]
[[Category:Fictional characters introduced in 2003]]</text>
      <sha1>fly3so0aoiibdrxzy5ki2ndsitqwcoh</sha1>
    </revision>
  </page>
  <page>
    <title>Area chart</title>
    <ns>0</ns>
    <id>11731170</id>
    <revision>
      <id>867209955</id>
      <parentid>857986846</parentid>
      <timestamp>2018-11-04T10:50:43Z</timestamp>
      <contributor>
        <ip>96.92.72.153</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3031">[[Image:De wanderung.svg|thumb|200px|right|Area Chart]]
[[Image:US_and_USSR_nuclear_stockpiles.svg|thumb|200px|right|Layered Area Chart]]
An '''area chart''' or '''area graph''' displays graphically quantitative data. It is based on the [[line chart]]. The area between axis and line are commonly emphasized with colors, textures and hatchings. Commonly one compares two or more quantities with an area chart.

== History ==
[[William Playfair]] is usually credited with inventing the area charts as well as the [[Line chart|line]], [[Bar chart|bar]], and [[pie chart]]s. His book ''The Commercial and Political Atlas'', published in 1786, contained a number of [[time-series]] graphs, including ''Interest of the National Debt from the Revolution'' and ''Chart of all the Imports and Exports to and from England from the Year 1700 to 1782'' that are often described as the first area charts in history.&lt;ref&gt;{{cite book|title=Playfair's Commercial and Political Atlas and Statistical Breviary|last1=Playfair|first1=William|last2=Wainer|first2=Howard|last3=Spence|first3=Ian|publisher=Cambridge University Press|year=2005|ISBN=9780521855549|location=|pages=|author-link1=William Playfair|author-link2=Howard Wainer|author-link3=Ian Spence (psychologist)}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=The Visual Display of Quantitative Information|last=Tufte|first=Edward|publisher=Graphics Press|year=1983|ISBN=0961392142|location=Cheshire, Connecticut|page=13|pages=|author-link=Edward Tufte}}&lt;/ref&gt;
{{Gallery
|width=300
|align=center
|File:1786 Playfair - 25 Interest of the national Debt from the Revolution.jpg
|Interest of the National Debt from the Revolution (Playfair, 1786)
|File:1786 Playfair - 12 Exports and imports to and from Denmark &amp; Norway from 1700 to 1780.jpg
|Exports and imports to and from Denmark &amp; Norway from 1700 to 1780 (Playfair, 1786)
}}

== Common uses ==

Area charts are used to represent cumulated totals using numbers or percentages (stacked area charts in this case) over time.
Use the area chart for showing trends over time among related attributes. The area chart is like the plot chart except that the area below the plotted line is filled in with color to indicate volume.

When multiple attributes are included, the first attribute is plotted as a line with color fill followed by the second attribute, and so on.

== Variations ==

Area charts which use vertical and horizontal lines to connect the data points in a series forming a step-like progression are called ''step-area charts''.

Area charts in which data points are connected by smooth curves instead of straight lines are called ''spline-area charts''.&lt;ref&gt;{{cite web | title=Area, Spline-Area, Step-Area Charts | url=http://www.anychart.com/products/anychart/gallery/Area,_Spline-Area,_Step-Area_Charts/ | publisher=AnyChart | access-date=29 December 2015}}&lt;/ref&gt;

==See also==
*[[Streamgraph]]

==References==
&lt;references /&gt;

{{commonscat|Area charts }}

[[Category:Diagrams]]
[[Category:Statistical charts and diagrams]]


{{statistics-stub}}</text>
      <sha1>lxak7s8ckl5sqymfvnpchi9p1lsg1c0</sha1>
    </revision>
  </page>
  <page>
    <title>Autonomous convergence theorem</title>
    <ns>0</ns>
    <id>14469299</id>
    <revision>
      <id>822459066</id>
      <parentid>622454322</parentid>
      <timestamp>2018-01-26T14:08:03Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4569">In [[mathematics]], an '''autonomous convergence theorem''' is one of a family of related [[Theorem | theorems]] which specify conditions guaranteeing global [[asymptotic stability]] of a [[Continuous function | continuous]] [[Autonomous system (mathematics) | autonomous]] [[dynamical system]].

==History==
The [[Markus–Yamabe conjecture]] was formulated as an attempt to give conditions for global stability of continuous dynamical systems in two [[dimension]]s. However, the Markus–Yamabe conjecture does not hold for dimensions higher than two, a problem which autonomous convergence theorems attempt to address. The first autonomous convergence theorem was constructed by Russell Smith.&lt;ref&gt;Russell A. Smith, "Some applications of Hausdorff dimension inequalities for ordinary differential equations", ''Proceedings of the Royal Society of Edinburgh Section A'', '''104A''':235–259, 1986&lt;/ref&gt; This theorem was later refined by Michael Li and James Muldowney.&lt;ref&gt;Michael Y. Li and James S. Muldowney, "On R. A. Smith's autonomous convergence theorem", ''Rocky Mountain Journal of Mathematics'', '''25(1)''':365–379, 1995&lt;/ref&gt;

==An example autonomous convergence theorem==
A comparatively simple autonomous convergence theorem is as follows:

:Let &lt;math&gt;x&lt;/math&gt; be a [[Vector (mathematics and physics) | vector]] in some space &lt;math&gt;X \subseteq \mathbb{R}^n&lt;/math&gt;, evolving according to an [[Autonomous system (mathematics) | autonomous]] [[differential equation]] &lt;math&gt;\dot{x} = f(x)&lt;/math&gt;. Suppose that &lt;math&gt;X&lt;/math&gt; is [[Convex set | convex]] and forward [[Invariant (mathematics) | invariant]] under &lt;math&gt;f&lt;/math&gt;, and that there exists a [[Fixed point (mathematics) | fixed point]] &lt;math&gt;\hat{x} \in X&lt;/math&gt; such that &lt;math&gt;f(\hat{x}) = 0&lt;/math&gt;. If there exists a [[logarithmic norm]] &lt;math&gt;\mu&lt;/math&gt; such that the [[Jacobian matrix and determinant|Jacobian]] &lt;math&gt;J(x) = D_x f&lt;/math&gt; satisfies &lt;math&gt;\mu(J(x)) &lt; 0&lt;/math&gt; for all values of &lt;math&gt;x&lt;/math&gt;, then &lt;math&gt;\hat{x}&lt;/math&gt; is the only fixed point, and it is globally asymptotically stable.&lt;ref&gt;V. I. Verbitskii and [[Alexander Nikolaevich Gorban|A. N. Gorban]], [http://www.math.le.ac.uk/people/ag153/homepage/VerbitskiiGorban1992.pdf Jointly dissipative operators and their applications], ''Siberian Mathematical Journal'', '''33(1):19–23''', 1992 (see also A.N. Gorban, Yu.I. Shokin, V.I. Verbitskii, [https://arxiv.org/abs/physics/9702021 arXiv:physics/9702021v2] [physics.comp-ph])&lt;/ref&gt;&lt;ref&gt;Murad Banaji and Stephen Baigent, "Electron transfer networks", ''Journal of Mathematical Chemistry'', '''43(4)''':1355–1370, 2008&lt;/ref&gt;

This autonomous convergence theorem is very closely related to the [[Banach fixed-point theorem]].

==How autonomous convergence works==
Note: this is an intuitive description of how autonomous convergence theorems guarantee stability, not a strictly mathematical description.

The key point in the example theorem given above is the existence of a negative logarithmic norm, which is derived from a vector [[Norm (mathematics) | norm]]. The vector norm effectively measures the distance between points in the vector space on which the differential equation is defined, and the negative logarithmic norm means that distances between points, as measured by the corresponding vector norm, are decreasing with time under the action of &lt;math&gt;f&lt;/math&gt;. So long as the [[Trajectory | trajectories]] of all points in the [[phase space]] are [[Bounded set | bounded]], all trajectories must therefore eventually converge to the same point.

The autonomous convergence theorems by Russell Smith, Michael Li and James Muldowney work in a similar manner, but they rely on showing that the area of two-dimensional shapes in phase space decrease with time. This means that no [[Orbit (dynamics) | periodic orbits]] can exist, as all closed loops must shrink to a point. If the system is bounded, then according to [[Pugh's closing lemma]] there can be no [[Chaos theory | chaotic behaviour]] either, so all trajectories must eventually reach an equilibrium.

Michael Li has also developed an extended autonomous convergence theorem which is applicable to dynamical systems containing an [[Invariant (mathematics) | invariant]] [[manifold]].&lt;ref&gt;Michael Y. Li and James S. Muldowney, "Dynamics of differential equations on invariant manifolds", ''Journal of Differential Equations'', '''168''':295–320, 2000&lt;/ref&gt;

==Notes==
&lt;references /&gt;

[[Category:Stability theory]]
[[Category:Fixed points (mathematics)]]
[[Category:Theorems in dynamical systems]]</text>
      <sha1>fy22x61bo1fylzqut1hb0u1y1z57wrn</sha1>
    </revision>
  </page>
  <page>
    <title>Bochner–Riesz mean</title>
    <ns>0</ns>
    <id>20966805</id>
    <revision>
      <id>797304145</id>
      <parentid>581767526</parentid>
      <timestamp>2017-08-26T05:59:14Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: jstor. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4642">The '''Bochner–Riesz mean''' is a [[summability method]] often used in [[harmonic analysis]] when considering convergence of [[Fourier series]] and [[Fourier inversion theorem|Fourier integrals]]. It was introduced by [[Salomon Bochner]] as a modification of the [[Riesz mean]].

Define

:&lt;math&gt;(\xi)_+ = \begin{cases} \xi, &amp; \mbox{if }  \xi &gt; 0  \\ 0,  &amp; \mbox{otherwise}. \end{cases}&lt;/math&gt;

Let &lt;math&gt;f&lt;/math&gt; be a periodic function, thought of as being on the [[n-torus]], &lt;math&gt;\mathbb{T}^n&lt;/math&gt;, and having Fourier coefficients &lt;math&gt;\hat{f}(k)&lt;/math&gt; for &lt;math&gt;k \in \mathbb{Z}^n&lt;/math&gt;.  Then the Bochner–Riesz means of complex order &lt;math&gt;\delta&lt;/math&gt;, &lt;math&gt;B_R^\delta f&lt;/math&gt; of (where &lt;math&gt;R &gt; 0&lt;/math&gt; and &lt;math&gt;\mbox{Re}(\delta) &gt; 0&lt;/math&gt;) are defined as

:&lt;math&gt;B_R^\delta f(\theta) = \underset{|k| \leq R}{\sum_{k \in \mathbb{Z}^n}} \left( 1- \frac{|k|^2}{R^2} \right)_+^\delta \hat{f}(k) e^{2 \pi i k \cdot \theta}.&lt;/math&gt;

Analogously, for a function &lt;math&gt;f&lt;/math&gt; on &lt;math&gt;\mathbb{R}^n&lt;/math&gt; with Fourier transform &lt;math&gt;\hat{f}(\xi)&lt;/math&gt;, the Bochner–Riesz means of complex order &lt;math&gt;\delta&lt;/math&gt;, &lt;math&gt;S_R^\delta f&lt;/math&gt; (where &lt;math&gt;R &gt; 0&lt;/math&gt; and &lt;math&gt;\mbox{Re}(\delta) &gt; 0&lt;/math&gt;) are defined as

:&lt;math&gt;S_R^\delta f(x) = \int_{|\xi| \leq R} \left(1 - \frac{|\xi|^2}{R^2} \right)_+^\delta \hat{f}(\xi) e^{2 \pi i x \cdot \xi}\,d\xi.&lt;/math&gt;

For &lt;math&gt;\delta &gt; 0&lt;/math&gt; and &lt;math&gt;n=1&lt;/math&gt;, &lt;math&gt;S_R^\delta&lt;/math&gt; and &lt;math&gt;B_R^\delta&lt;/math&gt; may be written as [[convolution]] operators, where the convolution kernel is an [[mollifier|approximate identity]].  As such, in these cases, considering the [[almost everywhere convergence]] of Bochner–Riesz means for functions in &lt;math&gt;L^p&lt;/math&gt; spaces is much simpler than the problem of "regular" almost everywhere convergence of Fourier series/integrals (corresponding to &lt;math&gt;\delta = 0&lt;/math&gt;).  In higher dimensions, the convolution kernels become more "badly behaved" (specifically, for &lt;math&gt;\delta \leq \tfrac{n-1}{2}&lt;/math&gt;, the kernel is no longer integrable) and establishing almost everywhere convergence becomes correspondingly more difficult.

Another question is that of for which &lt;math&gt;\delta&lt;/math&gt; and which &lt;math&gt;p&lt;/math&gt; the Bochner–Riesz means of an &lt;math&gt;L^p&lt;/math&gt; function converge in norm.  This is of fundamental importance for &lt;math&gt;n \geq 2&lt;/math&gt;, since regular spherical norm convergence (again corresponding to &lt;math&gt;\delta = 0&lt;/math&gt;) fails in &lt;math&gt;L^p&lt;/math&gt; when &lt;math&gt;p \neq 2&lt;/math&gt;.  This was shown in a paper of 1971 by [[Charles Fefferman]].&lt;ref&gt;{{Cite journal |first=Charles |last=Fefferman |title=The multiplier problem for the ball |journal=[[Annals of Mathematics]] |volume=94 |issue=2 |year=1971 |pages=330–336 |doi=10.2307/1970864 |jstor=1970864 }}&lt;/ref&gt; By a transference result, the &lt;math&gt;\mathbb{R}^n&lt;/math&gt; and &lt;math&gt;\mathbb{T}^n&lt;/math&gt; problems are equivalent to one another, and as such, by an argument using the [[uniform boundedness principle]], for any particular &lt;math&gt;p \in (1, \infty)&lt;/math&gt;, &lt;math&gt;L^p&lt;/math&gt; norm convergence follows in both cases for exactly those &lt;math&gt;\delta&lt;/math&gt; where &lt;math&gt;(1-|\xi|^2)^{\delta}_+&lt;/math&gt; is the [[Fourier multiplier|symbol]] of an &lt;math&gt;L^p&lt;/math&gt; bounded [[Fourier multiplier]] operator.  For &lt;math&gt;n=2&lt;/math&gt;, this question has been completely resolved, but for &lt;math&gt;n \geq 3&lt;/math&gt;, it has only been partially answered.  The case of &lt;math&gt;n=1&lt;/math&gt; is not interesting here as convergence follows for &lt;math&gt;p \in (1, \infty)&lt;/math&gt; in the most difficult &lt;math&gt;\delta = 0&lt;/math&gt; case as a consequence of the &lt;math&gt;L^p&lt;/math&gt; boundedness of the [[Hilbert transform]] and an argument of [[Marcel Riesz]].

==References==
{{Reflist}}

==Further reading==
*{{Cite book |first=Shanzhen |last=Lu |year=2013 |title=Bochner-Riesz Means on Euclidean Spaces |edition=First |publisher=World Scientific |isbn=978-981-4458-76-4 }}
*{{Cite book |first=Loukas |last=Grafakos |year=2008 |title=Classical Fourier Analysis |edition=Second |location=Berlin |publisher=Springer |isbn=978-0-387-09431-1 }}
*{{Cite book |first=Loukas |last=Grafakos |year=2009 |title=Modern Fourier Analysis |edition=Second |location=Berlin |publisher=Springer |isbn=978-0-387-09433-5 }}
*{{Cite book |first=Elias M. |last=Stein |authorlink=Elias M. Stein |lastauthoramp=yes |first2=Timothy S. |last2=Murphy |year=1993 |title=Harmonic Analysis: Real-variable Methods, Orthogonality, and Oscillatory Integrals |location=Princeton |publisher=Princeton University Press |isbn=0-691-03216-5 }}

{{DEFAULTSORT:Bochner-Riesz Mean}}
[[Category:Means]]
[[Category:Summability methods]]</text>
      <sha1>brquwne8w6hb5jt9zjhv4qjh6nv3bhk</sha1>
    </revision>
  </page>
  <page>
    <title>Bramble–Hilbert lemma</title>
    <ns>0</ns>
    <id>13925681</id>
    <revision>
      <id>822482325</id>
      <parentid>783006381</parentid>
      <timestamp>2018-01-26T16:48:03Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11948">In [[mathematics]], particularly [[numerical analysis]], the '''Bramble–Hilbert [[lemma (mathematics)|lemma]]''', named after [[James H. Bramble]] and [[Stephen Hilbert]], bounds the [[approximation error|error]] of an [[approximation]] of a [[function (mathematics)|function]] &lt;math&gt;\textstyle u&lt;/math&gt; by a [[polynomial]] of order at most &lt;math&gt;\textstyle m-1&lt;/math&gt; in terms of [[derivative (mathematics)|derivatives]] of &lt;math&gt;\textstyle u&lt;/math&gt; of order &lt;math&gt;\textstyle m&lt;/math&gt;. Both the error of the approximation and the derivatives of &lt;math&gt;\textstyle u&lt;/math&gt; are measured by [[Lp space|&lt;math&gt;\textstyle L^{p}&lt;/math&gt; norms]] on a [[Bounded set|bounded]] [[Domain (mathematical analysis)|domain]] in &lt;math&gt;\textstyle \mathbb{R}^{n}&lt;/math&gt;. This is similar to classical numerical analysis, where, for example, the error of [[linear interpolation]] &lt;math&gt;\textstyle u&lt;/math&gt; can be bounded using the second derivative of &lt;math&gt;\textstyle u&lt;/math&gt;. However, the Bramble–Hilbert lemma applies in any number of dimensions, not just one dimension, and the approximation error and the derivatives of &lt;math&gt;\textstyle u&lt;/math&gt; are measured by more general norms involving averages, not just the [[maximum norm]].

Additional assumptions on the domain are needed for the Bramble–Hilbert lemma to hold. Essentially, the [[Boundary (topology)|boundary]] of the domain must be "reasonable". For example, domains that have a spike or a slit with zero angle at the tip are excluded. [[Lipschitz domain]]s are reasonable enough, which includes [[Convex set|convex]] domains and domains with [[continuously differentiable]] boundary. 

The main use of the Bramble–Hilbert lemma is to prove bounds on the error of interpolation of function &lt;math&gt;\textstyle u&lt;/math&gt; by an operator that preserves polynomials of order up to &lt;math&gt;\textstyle m-1&lt;/math&gt;, in terms of the derivatives of &lt;math&gt;\textstyle u&lt;/math&gt; of order &lt;math&gt;\textstyle m&lt;/math&gt;. This is an essential step in error estimates for the [[finite element method]]. The Bramble–Hilbert lemma is applied there on the domain consisting of one element (or, in some [[superconvergence]] results, a small number of elements).

==The one-dimensional case==

Before stating the lemma in full generality, it is useful to look at some simple special cases. In one dimension and for a function &lt;math&gt;\textstyle u&lt;/math&gt; that has &lt;math&gt;\textstyle m&lt;/math&gt; derivatives on interval &lt;math&gt;\textstyle \left(  a,b\right)  &lt;/math&gt;, the lemma reduces to

:&lt;math&gt; \inf_{v\in P_{m-1}}\bigl\Vert u^{\left(  k\right)  }-v^{\left(  k\right) }\bigr\Vert_{L^{p}\left(  a,b\right)  }\leq C\left(  m\right)  \left( b-a\right)  ^{m-k}\bigl\Vert u^{\left(  m\right)  }\bigr\Vert_{L^{p}\left( a,b\right)  }, &lt;/math&gt;

where &lt;math&gt;\textstyle P_{m-1}&lt;/math&gt; is the space of all polynomials of order at most &lt;math&gt;\textstyle m-1&lt;/math&gt;.

In the case when &lt;math&gt;\textstyle p=\infty&lt;/math&gt;, &lt;math&gt;\textstyle m=2&lt;/math&gt;, &lt;math&gt;\textstyle k=0&lt;/math&gt;, and &lt;math&gt;\textstyle u&lt;/math&gt; is twice differentiable, this means that there exists a polynomial &lt;math&gt;\textstyle v&lt;/math&gt; of degree one such that for all &lt;math&gt;\textstyle x\in\left(  a,b\right)  &lt;/math&gt;,

:&lt;math&gt; \left\vert u\left(  x\right)  -v\left(  x\right)  \right\vert \leq C\left( b-a\right)  ^{2}\sup_{\left(  a,b\right)  }\left\vert u^{\prime\prime }\right\vert. &lt;/math&gt;

This inequality also follows from the well-known error estimate for linear interpolation by choosing &lt;math&gt;\textstyle v&lt;/math&gt; as the linear interpolant of &lt;math&gt;\textstyle u&lt;/math&gt;.

==Statement of the lemma==
{{Dubious|Dependence of the constant|date=October 2011}}
Suppose &lt;math&gt;\textstyle \Omega&lt;/math&gt; is a bounded domain in &lt;math&gt;\textstyle \mathbb{R}^n&lt;/math&gt;, &lt;math&gt;\textstyle n\geq1&lt;/math&gt;, with boundary &lt;math&gt;\textstyle \partial\Omega&lt;/math&gt; and [[diameter]] &lt;math&gt;\textstyle d&lt;/math&gt;. &lt;math&gt;\textstyle W_p^k(\Omega)&lt;/math&gt; is the [[Sobolev space]] of all function &lt;math&gt;\textstyle u&lt;/math&gt; on &lt;math&gt;\textstyle \Omega&lt;/math&gt; with [[weak derivative]]s &lt;math&gt;\textstyle D^\alpha u&lt;/math&gt; of order &lt;math&gt;\textstyle \left\vert \alpha\right\vert &lt;/math&gt; up to &lt;math&gt;\textstyle k&lt;/math&gt; in &lt;math&gt;\textstyle L^p(\Omega)&lt;/math&gt;. Here, &lt;math&gt;\textstyle \alpha=\left(  \alpha_1,\alpha_2,\ldots,\alpha_n\right)  &lt;/math&gt; is a [[multiindex]], &lt;math&gt;\textstyle \left\vert \alpha\right\vert =&lt;/math&gt; &lt;math&gt;\textstyle \alpha_1+\alpha_2+\cdots+\alpha_n&lt;/math&gt; and &lt;math&gt;\textstyle D^\alpha&lt;/math&gt; denotes the derivative &lt;math&gt;\textstyle \alpha_1&lt;/math&gt; times with respect to &lt;math&gt;\textstyle x_1&lt;/math&gt;, &lt;math&gt;\textstyle \alpha_2&lt;/math&gt; times with respect to &lt;math&gt;\textstyle x_2&lt;/math&gt;, and so on. The Sobolev seminorm on &lt;math&gt;\textstyle W_p^m(\Omega)&lt;/math&gt; consists of the &lt;math&gt;\textstyle L^p&lt;/math&gt; norms of the highest order derivatives,

:&lt;math&gt; \left\vert u\right\vert _{W_p^m(\Omega)}=\left(  \sum_{\left\vert \alpha\right\vert =m}\left\Vert D^\alpha  u\right\Vert_{L^p(\Omega)}^p\right)  ^{1/p}\text{ if }1\leq p&lt;\infty &lt;/math&gt;

and

:&lt;math&gt; \left\vert u\right\vert _{W_\infty^{m}(\Omega)}=\max_{\left\vert \alpha\right\vert =m}\left\Vert D^{\alpha}u\right\Vert _{L^\infty(\Omega)}&lt;/math&gt;

&lt;math&gt;\textstyle P_k&lt;/math&gt; is the space of all polynomials of order up to &lt;math&gt;\textstyle k&lt;/math&gt; on &lt;math&gt;\textstyle \mathbb{R}^n&lt;/math&gt;. Note that &lt;math&gt;\textstyle D^{\alpha}v=0&lt;/math&gt; for all &lt;math&gt;\textstyle v\in P_{m-1}&lt;/math&gt; and &lt;math&gt;\textstyle \left\vert \alpha\right\vert =m&lt;/math&gt;, so &lt;math&gt;\textstyle \left\vert u+v\right\vert _{W_p^m(\Omega)}&lt;/math&gt; has the same value for any &lt;math&gt;\textstyle v\in P_{m-1}&lt;/math&gt;.

'''Lemma''' (Bramble and Hilbert) Under additional assumptions on the domain &lt;math&gt;\textstyle \Omega&lt;/math&gt;, specified below, there exists a constant &lt;math&gt;\textstyle C=C\left( m,\Omega\right)  &lt;/math&gt; independent of &lt;math&gt;\textstyle p&lt;/math&gt; and &lt;math&gt;\textstyle u&lt;/math&gt; such that for any &lt;math&gt;\textstyle u\in W_p^m(\Omega)&lt;/math&gt; there exists a polynomial &lt;math&gt;\textstyle v\in P_{m-1}&lt;/math&gt; such that for all &lt;math&gt;\textstyle k=0,\ldots,m,&lt;/math&gt;

:&lt;math&gt; \left\vert u-v\right\vert _{W_p^k(\Omega)}\leq Cd^{m-k}\left\vert u\right\vert _{W_p^m(\Omega)}. &lt;/math&gt;

==The original result==

The lemma was proved by Bramble and Hilbert &lt;ref name="Bramble-1970-ELF"&gt;J. H. Bramble and S. R. Hilbert. Estimation of linear functionals on Sobolev spaces with application to Fourier transforms and spline interpolation. ''SIAM J. Numer. Anal.'', 7:112–124, 1970.

&lt;/ref&gt; under the assumption that &lt;math&gt;\textstyle \Omega&lt;/math&gt; satisfies the [[strong cone property]]; that is, there exists a finite open covering &lt;math&gt;\textstyle \left\{  O_{i}\right\}  &lt;/math&gt; of &lt;math&gt;\textstyle \partial\Omega&lt;/math&gt; and corresponding cones &lt;math&gt;\textstyle \{C_{i}\}&lt;/math&gt; with vertices at the origin such that &lt;math&gt;\textstyle x+C_{i}&lt;/math&gt; is contained in &lt;math&gt;\textstyle \Omega&lt;/math&gt; for any &lt;math&gt;\textstyle x&lt;/math&gt; &lt;math&gt;\textstyle \in\Omega\cap O_{i}&lt;/math&gt;.

The statement of the lemma here is a simple rewriting of the right-hand inequality stated in Theorem 1 in.&lt;ref name="Bramble-1970-ELF"/&gt; The actual statement in &lt;ref name="Bramble-1970-ELF"/&gt; is that the norm of the factorspace &lt;math&gt;\textstyle W_{p}^{m}(\Omega)/P_{m-1}&lt;/math&gt; is equivalent to the &lt;math&gt;\textstyle W_{p}^{m}(\Omega)&lt;/math&gt; seminorm. The &lt;math&gt;\textstyle W_{p}^{m}(\Omega)&lt;/math&gt; norm is not the usual one but the terms are scaled with &lt;math&gt;\textstyle d&lt;/math&gt; so that the right-hand inequality in the equivalence of the seminorms comes out exactly as in the statement here.

In the original result, the choice of the polynomial is not specified, and the value of constant and its dependence on the domain &lt;math&gt;\textstyle \Omega&lt;/math&gt; cannot be determined from the proof.

==A constructive form==

An alternative result was given by Dupont and Scott &lt;ref name="Dupont-1980-PAF"&gt;Todd Dupont and Ridgway Scott. Polynomial approximation of functions in Sobolev spaces. ''Math. Comp.'', 34(150):441–463, 1980.&lt;/ref&gt; under the assumption that the domain &lt;math&gt;\textstyle \Omega&lt;/math&gt; is [[star-shaped]]; that is, there exists a ball &lt;math&gt;\textstyle B&lt;/math&gt; such that for any &lt;math&gt;\textstyle x\in\Omega&lt;/math&gt;, the closed [[convex hull]] of &lt;math&gt;\textstyle \left\{  x\right\}  \cup B&lt;/math&gt; is a subset of &lt;math&gt;\textstyle \Omega&lt;/math&gt;. Suppose that &lt;math&gt;\textstyle \rho _\max&lt;/math&gt; is the supremum of the diameters of such balls. The ratio &lt;math&gt;\textstyle \gamma=d/\rho_\max&lt;/math&gt; is called the chunkiness of &lt;math&gt;\textstyle \Omega&lt;/math&gt;.

Then the lemma holds with the constant &lt;math&gt;\textstyle C=C\left(  m,n,\gamma\right)  &lt;/math&gt;, that is, the constant depends on the domain &lt;math&gt;\textstyle \Omega&lt;/math&gt; only through its chunkiness &lt;math&gt;\textstyle \gamma&lt;/math&gt; and the dimension of the space &lt;math&gt;\textstyle n&lt;/math&gt;. In addition, &lt;math&gt;v&lt;/math&gt; can be chosen as &lt;math&gt;v=Q^m u&lt;/math&gt;, where &lt;math&gt;\textstyle Q^m u&lt;/math&gt; is the averaged [[Taylor polynomial]], defined as

:&lt;math&gt; Q^{m}u=\int_B T_y^mu\left(  x\right)  \psi\left(  y\right) \, dx, &lt;/math&gt;

where

:&lt;math&gt; T_y^m u\left(  x\right)  =\sum\limits_{k=0}^{m-1}\sum\limits_{\left\vert \alpha\right\vert =k}\frac{1}{\alpha!}D^\alpha u\left(  y\right)  \left( x-y\right)^\alpha&lt;/math&gt;

is the Taylor polynomial of degree at most &lt;math&gt;\textstyle m-1&lt;/math&gt; of &lt;math&gt;\textstyle u&lt;/math&gt; centered at &lt;math&gt;\textstyle y&lt;/math&gt; evaluated at &lt;math&gt;\textstyle x&lt;/math&gt;, and &lt;math&gt;\textstyle \psi\geq0&lt;/math&gt; is a function that has derivatives of all orders, equals to zero outside of &lt;math&gt;\textstyle B&lt;/math&gt;, and such that

:&lt;math&gt; \int_B\psi \, dx=1. &lt;/math&gt;

Such function &lt;math&gt;\textstyle \psi&lt;/math&gt; always exists.

For more details and a tutorial treatment, see the monograph by [[Susanne Brenner|Brenner]] and Scott.&lt;ref name="Brenner-2002-MTF"&gt;[[Susanne Brenner|Susanne C. Brenner]] and L. Ridgway Scott. ''The mathematical theory of finite element methods'', volume 15 of ''Texts in Applied Mathematics''. Springer-Verlag, New York, second edition, 2002. {{ISBN|0-387-95451-1}}

&lt;/ref&gt; The result can be extended to the case when the domain &lt;math&gt;\textstyle \Omega&lt;/math&gt; is the union of a finite number of star-shaped domains, which is slightly more general than the strong cone property, and other polynomial spaces than the space of all polynomials up to a given degree.&lt;ref name="Dupont-1980-PAF"/&gt;

==Bound on linear functionals==

This result follows immediately from the above lemma, and it is also called sometimes the Bramble–Hilbert lemma, for example by [[Philippe G. Ciarlet|Ciarlet]].&lt;ref name="Ciarlet-2002-FEM"&gt;[[Philippe G. Ciarlet]]. ''The finite element method for elliptic problems'', volume 40 of ''Classics in Applied Mathematics''. Society for Industrial and Applied Mathematics (SIAM), Philadelphia, PA, 2002. Reprint of the 1978 original [North-Holland, Amsterdam]. {{ISBN|0-89871-514-8}}

&lt;/ref&gt; It is essentially Theorem 2 from.&lt;ref name="Bramble-1970-ELF"/&gt;

'''Lemma''' Suppose that &lt;math&gt;\textstyle \ell&lt;/math&gt; is a [[continuous linear functional]] on &lt;math&gt;\textstyle W_{p}^{m}(\Omega)&lt;/math&gt; and &lt;math&gt;\textstyle \left\Vert \ell\right\Vert _{W_{p}^{m}(\Omega )^{^{\prime}}}&lt;/math&gt; its [[dual norm]]. Suppose that &lt;math&gt;\textstyle \ell\left(  v\right)  =0&lt;/math&gt; for all &lt;math&gt;\textstyle v\in P_{m-1}&lt;/math&gt;. Then there exists a constant &lt;math&gt;\textstyle C=C\left(  \Omega\right)  &lt;/math&gt; such that

:&lt;math&gt; \left\vert \ell\left(  u\right)  \right\vert \leq C\left\Vert \ell\right\Vert _{W_{p}^{m}(\Omega)^{^{\prime}}}\left\vert u\right\vert _{W_{p}^{m}(\Omega)}. &lt;/math&gt;

==References==
&lt;!-- this 'empty' section displays references defined elsewhere --&gt;
{{reflist}}

==External links==
* {{Springer|id=B/b130220|author=Raytcho D. Lazarov|title=Bramble–Hilbert lemma}}
* https://arxiv.org/abs/0710.5148 – Jan Mandel: The Bramble–Hilbert Lemma

{{DEFAULTSORT:Bramble-Hilbert Lemma}}
[[Category:Lemmas]]
[[Category:Approximation theory]]
[[Category:Finite element method]]</text>
      <sha1>icm00ufe5p59bpqhpmq61cuov9yinxy</sha1>
    </revision>
  </page>
  <page>
    <title>Brian Alspach</title>
    <ns>0</ns>
    <id>42451632</id>
    <revision>
      <id>857681216</id>
      <parentid>827934223</parentid>
      <timestamp>2018-09-02T09:17:01Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <minor/>
      <comment>Dating maintenance tags: {{Full}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6206">'''Brian Roger Alspach''' is a [[mathematician]] whose main research interest is in [[graph theory]]. Alspach has also studied the mathematics behind [[poker]], and writes for ''Poker Digest ''and ''Canadian Poker Player'' magazines.

==Biography==

Brian Alspach was born on May 29, 1938 in [[North Dakota]]. He attended the [[University of Washington]] from 1957 to 1961, receiving his B.A. in 1961. He taught at a junior high school for one year before beginning his graduate studies. In 1964 he received his master's degree and in 1966 he obtained his Ph.D. from the [[University of California, Santa Barbara]] under the supervision of [[Paul Kelly (mathematician)|Paul Kelly]].&lt;ref&gt;{{mathgenealogy|id=17147}}&lt;/ref&gt;  He taught at [[Simon Fraser University]] for 33 years. He retired from there in 1998. He currently works as an adjunct professor at the [[University of Regina]] and has been there since 1999.  He is responsible for creating an industrial mathematics degree at [[Simon Fraser University]].&lt;ref&gt;http://www.mathcentral.uregina.ca/humanface/career/profiles/brianalspach.pdf{{dead link|date=November 2016 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;

Brian Alspach believes that the growth and future of mathematics will depend on the business people in the industrial businesses.&lt;ref&gt;http://mathcentral.uregina.ca/humanface/careers/profiles/brianalspach.pdf{{full|date=September 2018}}&lt;/ref&gt;  His interests are in graph theory and its applications. One of his theories of coverings and decomposition has been applied to scheduling issues that can arise in the business world.  Alspach states that his biggest issue with this is trying to explain such complex math to people in the business world with only a basic understanding of math.  He has mentored a total of 13 Ph.D. students.  His wife is the vice president of academics at the University of Regina where he is currently an adjunct professor.&lt;ref&gt;{{cite journal |doi=10.1016/j.disc.2005.03.024 |title=Brian Alspach and his work |journal=Discrete Mathematics |volume=299 |issue=1–3 |pages=269–87 |year=2005 |last1=Morris |first1=Joy |last2=Šajna |first2=Mateja }}&lt;/ref&gt;

==Research==
One of his first publications was an article titled ''Cycles of each length in regular tournaments'', which was published in the [[Canadian Mathematical Bulletin]] (November, 1967).&lt;ref&gt;{{cite journal |doi=10.1016/0097-3165(89)90059-9 |title=The Oberwolfach problem and factors of uniform odd length cycles |journal=Journal of Combinatorial Theory, Series A |volume=52 |issue=1 |pages=20–43 |year=1989 |last1=Alspach |first1=Brian |last2=Schellenberg |first2=P.J |last3=Stinson |first3=D.R |last4=Wagner |first4=David }}&lt;/ref&gt;

Another influential piece of  Brian Alspach is  ''Point-symmetric graphs and digraphs of prime order and transitive permutation groups of prime degree'', which was published in the [[Journal of Combinatorial Theory]] (August, 1973).&lt;ref&gt;{{cite journal |doi=10.1016/0095-8956(73)90027-0 |title=Point-symmetric graphs and digraphs of prime order and transitive permutation groups of prime degree |journal=Journal of Combinatorial Theory, Series B |volume=15 |issue=1 |pages=12–7 |year=1973 |last1=Alspach |first1=Brian }}&lt;/ref&gt;

In his article titled ''Isomorphism of circulant graphs and digraphs'' which was published in [[Discrete Mathematics]] (February, 1979).&lt;ref&gt;{{cite journal |doi=10.1016/0012-365X(79)90011-6 |title=Isomorphism of circulant graphs and digraphs |journal=Discrete Mathematics |volume=25 |issue=2 |pages=97–108 |year=1979 |last1=Alspach |first1=Brian |last2=Parsons |first2=T.D. }}&lt;/ref&gt;
He discusses the [[graph isomorphism problem|isomorphism problem]] for a special class of graphs.

Brian Alspach coauthored an article with  [[Torrence Parsons|T.D. Parsons]]  titled ''A construction for vertex –transitive graph'' published in the [[Canadian Journal of Mathematics]] (April, 1982).&lt;ref&gt;{{cite journal|url=https://books.google.com/?id=mLY6nc-D10sC&amp;pg=PA307&amp;dq=brian+alspach#v=onepage&amp;q=brian%20alspach&amp;f=false|journal=Canadian Journal of Mathematics|title=A construction for vertex–transitive graphs|year=1982|volume=34|pages=307–318|doi=10.4153/cjm-1982-020-8}}&lt;/ref&gt;

[[Alspach's conjecture]], posed by Alspach in 1981, concerns the characterization of [[Edge cycle cover|disjoint cycle cover]]s of [[complete graph]]s with prescribed cycle lengths.
With Heather Gavlas Jordon, in 2001, Alspach proved a special case, on the decomposition of complete graphs into cycles that all have the same length.
This is possible if and only if the complete graph has an odd number of vertices (so its degree is even), the given cycle length is at most the number of vertices (so that cycles of that length exist), and the given length divides the number of edges of the graph.&lt;ref&gt;{{cite journal |doi=10.1006/jctb.2000.1996 |title=Cycle Decompositions of Kn and Kn−I |journal=Journal of Combinatorial Theory, Series B |volume=81 |pages=77–99 |year=2001 |last1=Alspach |first1=Brian |last2=Gavlas |first2=Heather }}&lt;/ref&gt; A proof of the full conjecture was published in 2014.&lt;ref&gt;{{cite journal | last1 = Bryant | first1 = Darryn | last2 = Horsley | first2 = Daniel | last3 = Pettersson | first3 = William | doi = 10.1112/plms/pdt051 | issue = 5 | journal = Proceedings of the London Mathematical Society | mr = 3214677 | pages = 1153–1192 | series = Third Series | title = Cycle decompositions V: Complete graphs into cycles of arbitrary lengths | volume = 108 | year = 2014}}&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
* [http://people.math.sfu.ca/~alspach/ Alspach's Mathematics &amp; Poker Page]
* [http://www.cs.uleth.ca/gtba/ Graph Theory of Brian Alspach: a conference in celebration of Alspach's 65th birthday]
* [https://www.sfu.ca/math/people/faculty/brian_alspach.html  Personal web page]
* [https://scholar.google.com/scholar?hl=en&amp;as_sdt=0,33&amp;q=brian+alspach Publications]

{{Authority control}}

{{DEFAULTSORT:Alspach, Brian}}
[[Category:Graph theorists]]
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:1938 births]]
[[Category:Mathematicians from North Dakota]]
[[Category:Living people]]</text>
      <sha1>kks6swoowwo8oskakjrpsga04q0pk64</sha1>
    </revision>
  </page>
  <page>
    <title>Cannon's algorithm</title>
    <ns>0</ns>
    <id>12022054</id>
    <revision>
      <id>833476773</id>
      <parentid>779174006</parentid>
      <timestamp>2018-03-31T19:58:50Z</timestamp>
      <contributor>
        <username>Dawars00</username>
        <id>33409464</id>
      </contributor>
      <comment>added runtime analysis, detailed pseudo code</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5713">In [[computer science]], '''Cannon's algorithm''' is a [[distributed algorithm|distributed]] [[algorithm for matrix multiplication]] for two-dimensional [[Mesh networking|meshes]] first described in 1969 by [[Lynn Elliot Cannon]].&lt;ref&gt;Lynn Elliot Cannon, ''[http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=905686 A cellular computer to implement the Kalman Filter Algorithm]'', Technical report, Ph.D. Thesis, Montana State University, 14 July 1969.&lt;/ref&gt;&lt;ref name="stanfordpaper"&gt;[http://dbpubs.stanford.edu:8090/pub/1994-25 Gupta, H.; Sadayappan, P.: Communication Efficient Matrix-Multiplication on Hypercubes], dbpubs.stanford.edu&lt;/ref&gt;

It is especially suitable for computers laid out in an ''N'' × ''N'' mesh.&lt;ref name="ornl.gov"&gt;[http://www.phy.ornl.gov/csep/la/node6.html 4.2 Matrix Multiplication on a Distributed Memory Machine], www.phy.ornl.gov&lt;/ref&gt;  While Cannon's algorithm works well in homogeneous 2D grids, extending it to heterogeneous 2D grids has been shown to be difficult.&lt;ref name="lyonfr"&gt;[https://web.archive.org/web/20090517034825/http://graal.ens-lyon.fr/~jfpineau/research.html Ph.D. Research], graal.ens-lyon.fr. The thesis itself is not available from the archived link. &lt;/ref&gt;

The main advantage of the algorithm is that its storage requirements remain constant and are independent of the number of processors.&lt;ref name="stanfordpaper"/&gt;

The Scalable Universal Matrix Multiplication Algorithm (SUMMA)&lt;ref&gt;Robert A. van de Geijn and Jerrell Watts, [http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1096-9128(199704)9:4%3C255::AID-CPE250%3E3.0.CO;2-2/abstract SUMMA: scalable universal matrix multiplication algorithm], Concurrency: Practice and Experience. Volume 9, Issue 4, pages 255–274, April 1997.&lt;/ref&gt;
is a more practical algorithm that requires less workspace and overcomes the need for a square 2D grid.  It is used by the [[ScaLAPACK]], [[PLAPACK]], and [http://code.google.com/p/elemental/ Elemental] libraries.

==Algorithm overview==

When multiplying two n×n matrices A and B, we need ''n''×n processing nodes p arranged in a 2d grid. Initially p&lt;sub&gt;i,j&lt;/sub&gt; is responsible for a&lt;sub&gt;i,j&lt;/sub&gt; and b&lt;sub&gt;i,j&lt;/sub&gt;.
 // PE(i , j)
 k := (i + j) mod N;
 &lt;nowiki&gt;a := a[i][k];&lt;/nowiki&gt;
 &lt;nowiki&gt;b := b[k][j];&lt;/nowiki&gt;
 c[i][j] := 0;
 for(l := 0; l &lt; N − 1; l++){
 &lt;nowiki&gt;    c[i][j] := c[i][j] + a * b;&lt;/nowiki&gt;
         concurrently{
             send a to PE(i, (j + N − 1) mod N);
             send b to PE((i + N − 1) mod N, j);
         } with {
             receive a' from PE(i, (j + 1) mod N);
             receive b' from PE((i + 1) mod N, j );
         }
     a := a';
     b := b';
 }
We need to select k in every iteration for every Processor Element (PE) so that processors don't access the same data for computing &lt;math&gt;a_{ik} * b_{kj}&lt;/math&gt;.

Therefore processors in the same row / column must begin summation with different indexes. If for example ''PE(0,0)''  calculates &lt;math&gt;a_{00} * b_{00}&lt;/math&gt; in the first step, ''PE(0,1) chooses'' &lt;math&gt;a_{01} * b_{11}&lt;/math&gt; first. The selection of ''k := (i + j) mod n'' for ''PE(i,j)'' satisfies this constraint for the first step.

In the first step we distribute the input matrices between the processors based on the previous rule.

In the next iterations we choose a new ''k' := (k + 1) mod n'' for every processor. This way every processor will continue accessing different values of the matrices. The needed data is then always at the neighbour processors. ''A PE(i,j)'' needs then the '''''&lt;math&gt;a&lt;/math&gt;''''' from ''PE(i,(j + 1) mod n)'' and the &lt;math&gt;b&lt;/math&gt; from ''PE((i + 1) mod n,j)'' for the next step. This means that &lt;math&gt;a&lt;/math&gt; has to be passed cyclically to the left and also &lt;math&gt;b&lt;/math&gt; cyclically upwards. The results of the multiplications are summed up as usual. After n steps, each processor has calculated all &lt;math&gt;a_{ik} * b_{kj}&lt;/math&gt; once and its sum is thus the searched &lt;math&gt;c_{ij}&lt;/math&gt;.

After the initial distribution of each processor, only the data for the next step has to be stored. These are the intermediate result of the previous sum, a &lt;math&gt;a_{ik}&lt;/math&gt; and a &lt;math&gt; b_{kj}&lt;/math&gt;. This means that all three matrices only need to be stored in memory once evenly distributed across the processors.

=== Generalisation ===
In practise we have much fewer processors than the matrix elements. We can replace the matrix elements with submatrices, so that every processor processes more values. The scalar multiplication and addition become sequential matrix multiplication and addition. The width and height of the submatrices will be &lt;math&gt;N=n/\sqrt {p}&lt;/math&gt;.

The runtime of the algorithm is  &lt;math&gt;T\mathcal{(n, p)} = T_{coll} (n/N, p) + N*T_{seq}(n/N) + 2(N - 1)(T_{start} + T_{byte}(n/ N)^2)
&lt;/math&gt; , where &lt;math&gt;T_{coll}&lt;/math&gt; is the time of the initial distribution of the matrices in the first step, &lt;math&gt;T_{seq}&lt;/math&gt; is the calculation of the intermediate results and &lt;math&gt;T_{start}&lt;/math&gt; and &lt;math&gt;T_{byte}&lt;/math&gt; stands for the time it takes to establish a connection and transmission of byte respectively.

A disadvantage of the algorithm is that there are many connection setups, with small message sizes. It would be better to be able to transmit more data in each message.

== See also ==
* [[Systolic array]]

== References ==
&lt;references/&gt;

== External links ==
* [http://www.cs.berkeley.edu/~demmel/cs267/lecture11/lecture11.html Lecture at Berkeley]
* [http://www.cs.mu.oz.au/498/notes/node30.html mu.oz.au]

{{Numerical linear algebra}}

{{DEFAULTSORT:Cannon's Algorithm}}
[[Category:Distributed algorithms]]
[[Category:Matrix multiplication algorithms]]
[[Category:Mesh networking]]


{{mathapplied-stub}}</text>
      <sha1>bvibfjy10h6tar9m78q1nqodmgois4v</sha1>
    </revision>
  </page>
  <page>
    <title>Canonical ring</title>
    <ns>0</ns>
    <id>1866872</id>
    <revision>
      <id>853113212</id>
      <parentid>846507542</parentid>
      <timestamp>2018-08-02T14:33:01Z</timestamp>
      <contributor>
        <username>John Baez</username>
        <id>233394</id>
      </contributor>
      <minor/>
      <comment>removed comma</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3570">In [[mathematics]], the '''pluricanonical ring''' of an [[algebraic variety]] ''V'' (which is [[non-singular]]), or of a [[complex manifold]], is the [[graded commutative ring|graded ring]] 
:&lt;math&gt;R(V,K)=R(V,K_V) \,&lt;/math&gt; 

of sections of powers of the [[canonical bundle]] ''K''. Its ''n''th graded component (for &lt;math&gt;n\geq 0&lt;/math&gt;) is:
:&lt;math&gt;R_n := H^0(V, K^n),\ &lt;/math&gt;

that is, the space of [[Section (fiber bundle)|sections]] of the ''n''-th [[tensor product]] ''K''&lt;sup&gt;''n''&lt;/sup&gt; of the canonical bundle ''K''.

The 0th graded component &lt;math&gt;R_0&lt;/math&gt; is sections of the trivial bundle, and is one-dimensional as ''V'' is projective. The projective variety defined by this graded ring is called the '''canonical model''' of ''V'', and the dimension of the canonical model is called the [[Kodaira dimension]] of ''V''. 

One can define an analogous ring for any [[line bundle]] ''L'' over ''V''; the analogous dimension is called the '''[[Iitaka dimension]]'''. A line bundle is called '''big''' if the Iitaka dimension equals the dimension of the variety.&lt;ref&gt;{{cite book|author=Hartshorne |title=Algebraic Geometry, Arcata 1974|year=1975|url={{Google books|plainurl=y|id=eICMfNiDdigC|page=7|text=line bundle}}|page=7}}&lt;/ref&gt;

==Properties==
===Birational invariance===
The canonical ring and therefore likewise the Kodaira dimension is a [[birational invariant]]: Any birational map between smooth compact complex manifolds induces an isomorphism between the respective canonical rings. As a consequence one can define the Kodaira dimension of a singular space as the Kodaira dimension of a [[desingularization]]. Due to the birational invariance this is well defined, i.e., independent of the choice of the desingularization.

===Fundamental conjecture of birational geometry===
A basic conjecture is that the pluricanonical ring is [[Finitely generated algebra|finitely generated]]. This is considered a major step in the [[Mori program]].
{{harvs|txt|first=Caucher |last=Birkar|first2= Paolo |last2=Cascini|first3= Christopher D. |last3=Hacon|first4= James|last4= McKernan|year=2010}}  proved this conjecture.

==The plurigenera==
The dimension

:&lt;math&gt;P_n = h^0(V, K^n) = \operatorname{dim}\ H^0(V, K^n)&lt;/math&gt;

is the classically defined ''n''-th '''''plurigenus''''' of ''V''. The pluricanonical divisor &lt;math&gt;K^n&lt;/math&gt;, via the corresponding [[linear system of divisors]], gives a map to projective space &lt;math&gt;\mathbf{P}(H^0(V, K^n)) = \mathbf{P}^{P_n - 1}&lt;/math&gt;, called the ''n''-canonical map.

The size of ''R'' is a basic invariant of ''V'', and is called the Kodaira dimension.

==Notes==
{{reflist}}

==References==
*{{Citation | last1=Birkar | first1=Caucher | authorlink1=Caucher Birkar | last2=Cascini | first2=Paolo | last3=Hacon | first3=Christopher D. | authorlink3=Christopher Hacon | last4=McKernan | first4=James | authorlink4=James McKernan | title=Existence of minimal models for varieties of log general type | arxiv=math.AG/0610203 | doi=10.1090/S0894-0347-09-00649-3 | mr=2601039 | year=2010 | journal=[[Journal of the American Mathematical Society]] | volume=23 | issue=2 | pages=405–468| bibcode=2010JAMS...23..405B }}
* {{Citation | first1=Phillip |last1=Griffiths | authorlink=Phillip Griffiths | first2=Joe |last2=Harris |author-link2=Joe Harris (mathematician) | title=Principles of Algebraic Geometry | series=Wiley Classics Library | publisher=Wiley Interscience | year=1994 | isbn=0-471-05059-8 | page=573 }}

[[Category:Algebraic geometry]]
[[Category:Birational geometry]]
[[Category:Structures on manifolds]]</text>
      <sha1>fu8k2t3ncwqz4pw51aew27y3kzsm4qw</sha1>
    </revision>
  </page>
  <page>
    <title>Capped octahedral molecular geometry</title>
    <ns>0</ns>
    <id>37191231</id>
    <revision>
      <id>869503436</id>
      <parentid>859620686</parentid>
      <timestamp>2018-11-19T01:12:47Z</timestamp>
      <contributor>
        <username>Officer781</username>
        <id>5336741</id>
      </contributor>
      <comment>add another reference for the common geometries</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2275">{{Infobox molecular geometry 
| Examples=MoF&lt;sub&gt;7&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt;
| Image_File=Face-capped octahedron.png
| Symmetry_group=C&lt;sub&gt;3v&lt;/sub&gt;
| Atom_direction=7
| Bond_angle=
| mu=
}}

In [[chemistry]], the '''capped octahedral molecular geometry''' describes the shape of compounds where seven atoms or groups of atoms or ligands are arranged around a central atom defining the vertices of a [[Gyroelongated pyramid|gyroelongated triangular pyramid]]. This shape has C&lt;sub&gt;3v&lt;/sub&gt; [[molecular symmetry|symmetry]] and is one of the three common shapes for heptacoordinate transition metal complexes, along with the [[pentagonal bipyramidal molecular geometry|pentagonal bipyramid]] and the [[capped trigonal prismatic molecular geometry|capped trigonal prism]].&lt;ref&gt;{{cite journal
| title   = Seven-coordination. A molecular orbital exploration of structure, stereochemistry, and reaction dynamics
| author1 = Roald. Hoffmann
| author2 = Barbara F. Beier
| author3 = Earl L. Muetterties
| author4 = Angelo R. Rossi
| journal = [[Inorganic Chemistry (journal)|Inorganic Chemistry]]
| year    = 1977
| volume  = 16
| issue   = 3
| pages   = 511–522
| doi     = 10.1021/ic50169a002
}}&lt;/ref&gt;&lt;ref&gt;Wells A.F. (1984) ''Structural Inorganic Chemistry'' 5th edition Oxford Science Publications {{ISBN|0-19-855370-6}}&lt;/ref&gt;

Examples of the capped octahedral molecular geometry are the heptafluoromolybdate (MoF&lt;sub&gt;7&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt;) and the heptafluorotungstate (WF&lt;sub&gt;7&lt;/sub&gt;&lt;sup&gt;−&lt;/sup&gt;) ions.&lt;ref&gt;{{cite journal
| title   = "Non-VSEPR" Structures and Bonding in d(0) Systems
| first   = Martin
| last    = Kaupp
| journal = Angew Chem Int Ed Engl
| year    = 2001
| volume  = 40
| issue   = 1
| pages   = 3534–3565
| doi     = 10.1002/1521-3773(20011001)40:19&lt;3534::AID-ANIE3534&gt;3.0.CO;2-#
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
| title   = Stereochemistry of Seven-Coordinate Main Group and d0 Transition Metal Molecules
| author1 = Zhenyang Lin
| author2 =  Ian Bytheway
| journal = [[Inorganic Chemistry (journal)|Inorganic Chemistry]]
| year    = 1996
| volume  = 35
| issue   = 3
| pages   = 594–603
| doi     = 10.1021/ic950271o
}}&lt;/ref&gt;

==References==
{{Reflist}}

{{MolecularGeometry}}

[[Category:Stereochemistry]]
[[Category:Molecular geometry]]

{{chemistry-stub}}</text>
      <sha1>hb8axvj3or8dlbr26wzo8xeoulmculc</sha1>
    </revision>
  </page>
  <page>
    <title>Category of manifolds</title>
    <ns>0</ns>
    <id>10059981</id>
    <revision>
      <id>778867462</id>
      <parentid>778182972</parentid>
      <timestamp>2017-05-05T17:09:31Z</timestamp>
      <contributor>
        <ip>96.127.219.71</ip>
      </contributor>
      <comment>/* Manp is a concrete category */ erased a misplaced fragment</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2393">In [[mathematics]], the '''category of manifolds''', often denoted '''Man'''&lt;sup&gt;''p''&lt;/sup&gt;, is the [[category (category theory)|category]] whose [[object (category theory)|object]]s are [[manifold]]s of [[smooth function|smoothness class]] ''C''&lt;sup&gt;''p''&lt;/sup&gt; and whose [[morphism]]s are ''p''-times continuously [[differentiable map]]s. This is a category because the [[function composition|composition]] of two ''C''&lt;sup&gt;''p''&lt;/sup&gt; maps is again continuous and of class ''C''&lt;sup&gt;''p''&lt;/sup&gt;.

One is often interested only in ''C''&lt;sup&gt;''p''&lt;/sup&gt;-manifolds modelled on spaces in a fixed category ''A'', and the category of such manifolds is denoted '''Man'''&lt;sup&gt;''p''&lt;/sup&gt;(''A''). Similarly, the category of ''C''&lt;sup&gt;''p''&lt;/sup&gt;-manifolds modelled on a fixed space ''E'' is denoted '''Man'''&lt;sup&gt;''p''&lt;/sup&gt;(''E'').

One may also speak of the category of [[differentiable manifold|smooth manifolds]], '''Man'''&lt;sup&gt;∞&lt;/sup&gt;, or the category of [[analytic manifold]]s,  '''Man'''&lt;sup&gt;''ω''&lt;/sup&gt;.

=='''Man'''&lt;sup&gt;''p''&lt;/sup&gt; is a concrete category==

Like many categories, the category '''Man'''&lt;sup&gt;''p''&lt;/sup&gt; is a [[concrete category]], meaning its objects are [[Set (mathematics)|sets]] with additional structure (i.e. a [[topology]] and an [[equivalence class]] of [[atlas (topology)|atlas]]es of [[atlas (topology)#Charts|charts]] defining a ''C''&lt;sup&gt;''p''&lt;/sup&gt;-differentiable structure) and its morphisms are [[function (mathematics)|function]]s preserving this structure. There is a natural [[forgetful functor]]
:''U'' : '''Man'''&lt;sup&gt;''p''&lt;/sup&gt; &amp;rarr; '''Top'''
to the [[category of topological spaces]] which assigns to each manifold the underlying topological space and to each ''p''-times continuously differentiable function the underlying continuous function of topological spaces. Similarly, there is a natural forgetful functor
:''U''&amp;prime; : '''Man'''&lt;sup&gt;''p''&lt;/sup&gt; &amp;rarr; '''Set'''
to the [[category of sets]] which assigns to each manifold the underlying set and to each ''p''-times continuously differentiable function the underlying function.

==References==

* {{cite book | last=Lang | first=Serge | title=Differential manifolds | publisher=Addison-Wesley Publishing Co., Inc. | location=Reading, Mass.&amp;ndash;London&amp;ndash;Don Mills, Ont. | year=1972 }}

[[Category:Categories in category theory|Manifolds]]
[[Category:Manifolds]]


{{cattheory-stub}}</text>
      <sha1>j9uedwp8d9cy4gvqtqty44mx6vpfgd0</sha1>
    </revision>
  </page>
  <page>
    <title>Chang's conjecture</title>
    <ns>0</ns>
    <id>25403351</id>
    <revision>
      <id>851515394</id>
      <parentid>764368271</parentid>
      <timestamp>2018-07-22T20:55:57Z</timestamp>
      <contributor>
        <username>Suslindisambiguator</username>
        <id>12329968</id>
      </contributor>
      <comment>added author link for R. L. Vaught</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1948">In [[model theory]], a branch of [[mathematical logic]], '''Chang's conjecture''', attributed to [[Chen Chung Chang]] by {{harvtxt|Vaught|1963|p=309}}, states that every model of type (ω&lt;sub&gt;2&lt;/sub&gt;,ω&lt;sub&gt;1&lt;/sub&gt;) for a countable language has an elementary submodel of type (ω&lt;sub&gt;1&lt;/sub&gt;, ω). A model is of type (α,β) if it is of cardinality α and a unary relation is represented by a subset of cardinality β. The usual notation is &lt;math&gt;(\omega_2,\omega_1)\twoheadrightarrow(\omega_1,\omega)&lt;/math&gt;.

The [[axiom of constructibility]] implies that Chang's conjecture fails. [[Jack Silver|Silver]] proved the consistency of Chang's conjecture from the consistency of an ω&lt;sub&gt;1&lt;/sub&gt;-[[Erdős cardinal]]. Hans-Dieter Donder showed the reverse implication: if CC holds, then ω&lt;sub&gt;2&lt;/sub&gt; is ω&lt;sub&gt;1&lt;/sub&gt;-Erdős in [[core model|K]].

More generally, Chang's conjecture for two pairs (α,β), (γ,δ) of cardinals is the claim
that every model of type (α,β) for a countable language has an elementary submodel of type (γ,δ). 
The consistency of &lt;math&gt;(\omega_3,\omega_2)\twoheadrightarrow(\omega_2,\omega_1)&lt;/math&gt; was shown by [[Richard Laver|Laver]] from the consistency of a [[huge cardinal]].

==References==
*{{Citation | last1=Chang | first1=Chen Chung | last2=Keisler | first2=H. Jerome | author2-link=Howard Jerome Keisler | title=Model Theory | publisher=[[Elsevier]] | edition=3rd | series=Studies in Logic and the Foundations of Mathematics | isbn=978-0-444-88054-3 | year=1990}}
*{{Citation | last1=Vaught | first1=R. L. | authorlink=Robert Lawson Vaught | title=Models of complete theories | doi=10.1090/S0002-9904-1963-10903-9 | mr=0147396 | year=1963 | journal=[[Bulletin of the American Mathematical Society]] | issn=0002-9904 | volume=69 | pages=299–313 |url=http://www.ams.org/bull/1963-69-03/S0002-9904-1963-10903-9/home.html}}

[[Category:Model theory|Model theory]]
[[Category:Set theory]]


{{mathlogic-stub}}</text>
      <sha1>3hno3zzh2gbccjhcvueagnwpszycux2</sha1>
    </revision>
  </page>
  <page>
    <title>Charlier polynomials</title>
    <ns>0</ns>
    <id>19585960</id>
    <revision>
      <id>828129135</id>
      <parentid>790697452</parentid>
      <timestamp>2018-02-28T18:51:58Z</timestamp>
      <contributor>
        <ip>188.105.141.38</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1236">In [[mathematics]], '''Charlier polynomials''' (also called '''Poisson–Charlier polynomials''') are a family of [[orthogonal polynomials]] introduced by [[Carl Charlier]].
They are given in terms of the [[generalized hypergeometric function]] by
:&lt;math&gt;C_n(x; \mu)= {}_2F_0(-n,-x,-1/\mu)=(-1)^n n! L_n^{(-1-x)}\left(-\frac 1 \mu \right),&lt;/math&gt;
where &lt;math&gt;L&lt;/math&gt; are [[Laguerre polynomials]]. They satisfy the [[orthogonality relation]]
:&lt;math&gt;\int_{x=0}^\infty \frac{\mu^x}{x!} C_n(x; \mu)C_m(x; \mu)=\mu^{-n} e^\mu n! \delta_{nm}, \quad \mu&gt;0.&lt;/math&gt;

== See also ==
* [[Wilson polynomials]], a generalization of Charlier polynomials.

== References ==
* C. V. L. Charlier (1905–1906) ''Über die Darstellung willkürlicher Funktionen'', Ark. Mat. Astr. och Fysic 2, 20.
* {{dlmf|id=18.19|title=Hahn Class: Definitions|first=Tom H. |last=Koornwinder|first2=Roderick S. C.|last2= Wong|first3=Roelof |last3=Koekoek||first4=René F. |last4=Swarttouw}}
* {{Citation | authorlink=Gábor Szegő | last1=Szegő | first1=Gabor | title=Orthogonal Polynomials | publisher=Colloquium Publications – American Mathematical Society | isbn=978-0-8218-1023-1 | mr=0372517 | year=1939}}

[[Category:Orthogonal polynomials]]


{{Algebra-stub}}</text>
      <sha1>qtt9ie2iqf9hlyay8a70y3nc1zsx370</sha1>
    </revision>
  </page>
  <page>
    <title>Clearance rate</title>
    <ns>0</ns>
    <id>169176</id>
    <revision>
      <id>866942320</id>
      <parentid>814477632</parentid>
      <timestamp>2018-11-02T15:47:41Z</timestamp>
      <contributor>
        <username>Arii C01</username>
        <id>35042251</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2073">[[Image:2004 UCR crime clearance.jpg|thumb|350 px|U.S. 2004 clearance rates separated by crime type]]

In [[criminal justice]], '''clearance rate''' is calculated by dividing the number of crimes that are "cleared" (a charge being laid) by the total number of crimes recorded. Clearance rates are used by various groups as a measure of [[crime]]s solved by the police. 

Clearance rates can be problematic for measuring the performance of police services and for comparing various police services. This is because a police force may employ a different way of measuring clearance rates. For example, each police force may have a different method of recording when a "crime" has occurred and different criteria for determining when a crime has been "cleared." One police force may appear to have a much better clearance rate because of its calculation methodology.&lt;ref&gt;The encyclopedia of police science, Volume 1 By Jack R. Greene, https://books.google.com/books?id=HIE_zF1Rv7MC&amp;lpg=PA907&amp;ots=fVuvhI2iZL&amp;dq=definition%20%22clearance%20rate%22%20police&amp;pg=PA907#v=onepage&amp;q=definition%20%22clearance%20rate%22%20police&amp;f=false&lt;/ref&gt;

In [[Conflict Model (criminal justice)|System Conflict Theory]], it is argued that clearance rates cause the police to focus on ''appearing ''to solve crimes (generating high clearance rate scores) rather than actually solving crimes. Further focus on clearance rates may result in effort being expended to attribute crimes (correctly or incorrectly) to a criminal, which may not result in retribution, compensation, rehabilitation or deterrence.

'''Definition: A measure of investigative effectiveness that compares the number of crimes reported or discovered to the number of crimes solved through arrest or other means (such as the death of the suspect).'''
==References==
'''Criminal Justice Today, An Introductory Text For The 21st Century. Fourteenth edition by Frank Schmalleger'''

[[Category:Criminology]]
[[Category:Law enforcement]]
[[Category:Crime statistics]]
[[Category:Ratios]]

{{criminology-stub}}
{{law-enforcement-stub}}</text>
      <sha1>fx5g410kc5de4nhlq5i2vvkyg1awyf6</sha1>
    </revision>
  </page>
  <page>
    <title>Commitment device</title>
    <ns>0</ns>
    <id>29847590</id>
    <revision>
      <id>855789804</id>
      <parentid>855788230</parentid>
      <timestamp>2018-08-20T21:05:27Z</timestamp>
      <contributor>
        <username>Rogerslab</username>
        <id>34196396</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7024">[[File:Hán Xìn.jpg|thumb|200px|Chinese military general [[Han Xin]] purportedly created a commitment device for his soldiers: he placed them with their backs to a river to make sure they would fight.]]
A '''commitment device''' is, according to journalist [[Stephen J. Dubner]] and economist [[Steven Levitt]], a way to lock yourself into following a plan of action that you might not want to do but you know is good for you.&lt;ref name=DubnerLevitt/&gt; In other words, a commitment device is a way to give yourself a reward or punishment to make an empty promise stronger and believable.&lt;ref name=ReevesD/&gt;

A commitment device is a technique where someone makes it easier for themselves to avoid [[akrasia]] (acting against one's better judgment), particularly [[procrastination]].

Commitment devices have two major features. They are voluntarily adopted for use and they tie consequences to follow-through failures.&lt;ref name="CD"/&gt; Consequences can be immutable (irreversible, such as a monetary consequence) or mutable (allows for the possibility of future reversal of the consequence).&lt;ref name="CD"/&gt;

==Overview==
[[File:Odysseus Sirens BM E440 n2.jpg|thumb|left|[[Odysseus]] lashed to the mast by his first mate. Depicted by the [[Siren Painter]].]]

The term "commitment device" is used in both economics and [[game theory]]. In particular, the concept is relevant to the fields of economics and especially the study of decision making (Brocas, ''et al.'').

A common example comes from mythology: Odysseus' plan to survive hearing the [[Siren (mythology)|siren]]s' song without jumping overboard. Economist Jodi Beggs writes "Commitment devices are a way to overcome the discrepancy between an individual's short-term and long-term preferences; in other words, they are a way for self-aware people to modify their incentives or set of possible choices in order to overcome impatience or other irrational behavior. You know the story of [[Ulysses (novel)|Ulysses]] tying himself to the mast so that he couldn't be lured in by the song of the Sirens? You can think of that as the quintessential commitment device" (Beggs 2009).

Behavioral economist Daniel Goldstein describes how commitment devices established in "cold states" help an protect themselves against impulsive decisions in later, emotional, stimulated, "hot states". Goldstein says that, despite their usefulness, commitment devices nevertheless have drawbacks. Namely, they still rely on some self-control.&lt;ref name=gold&gt;TED talk - Daniel Goldstein on the battle between your present and future self, http://www.ted.com/talks/daniel_goldstein_the_battle_between_your_present_and_future_self&lt;/ref&gt; 
Goldstein says that, for one, a commitment device can promote [[learned helplessness]] in the agent. If the agent enters a situation where the device does not incentivize commitment, the agent may not have enough will power or ability to control themselves. (Goldstein uses the example of a cake falling into the grey area of a diet, so it is eaten excessively.) Second, commitment devices can usually be reversed. (An unplugged distracting electronic can be plugged back in.)
&lt;ref name=gold/&gt;

Goldstein says "In effect you are like Odysseus and the first mate in one person. You're binding yourself, and then you're weaseling your way out of it, and then you're beating yourself up for it afterwards."&lt;ref name=gold/&gt;

==Methods==
* Create larger obstacles to temptations to increase the costs of temptations. 
* Make your commitment public, so your reputation may be affected. 
* Make a bet or monetary contract with someone to increase the benefit of keeping your promise.

==Challenges==
It can be challenging to promote uptake of commitment devices. In the field of health, for example, commitment devices have the potential to increase patient adherence to their health goals, but utilization of these techniques is low.&lt;ref name=WB /&gt;&lt;ref name="CD"/&gt; Health professionals can potentially increase patient uptake of commitment devices by increasing their accessibility, making policies opt-out, and leveraging patients’ social networks.&lt;ref name="CD"/&gt;

==Other examples==
[[File:Lawrence Joel.jpg|thumb|A soldier receives a Medal of Honor. Game theorists suggest that human cultural constructs like "Honor" might function as commitment devices.]]Examples of commitment devices abound. Dubner and Levitt give the example of [[Han Xin]], a general in Ancient China, who positioned his soldiers with their backs to a river, making it impossible for them to flee, thereby leaving them no choice but to attack the enemy head-on. They also present various commitment devices related to weight loss (2007). In addition, some game theorists have argued that human emotions and sense of honor are forms of commitment device (Arslan 2011 &amp; Ross and Dumouchel 2004). Other examples include announcing commitments publicly and [[mutually assured destruction]] (Straker 2011), as well as software programs that block internet access for a predetermined period of time.

==See also==
*[[Precommitment]]
*[[Positive psychology]]
*[[Hold-up problem]]

==References==
{{Reflist|2|refs=
&lt;ref name=DubnerLevitt&gt;[https://www.nytimes.com/2007/11/18/magazine/18wwln-freakonomics-t.html?_r=1 Dubner and Levitt, Stephen J. and Steven D. "The Stomach-Surgery Conundrum," New York Times, November 18, 2007.]&lt;/ref&gt;

&lt;ref name=WB&gt;[https://www.aeaweb.org/articles?id=10.1257/app.2.4.213 Put Your Money Where Your Butt Is: A Commitment Contract For Smoking Cessation. (2009). World Bank.] &lt;/ref&gt;

&lt;ref name=ReevesD&gt;[http://messymatters.com/2010/11/15/akrasia/ Reeves, Daniel. "How To Do What You Want: Akrasia and Self-Binding," Messy Matters, November 15, 2010.]&lt;/ref&gt;

&lt;ref name="CD"&gt;[https://scholar.harvard.edu/files/todd_rogers/files/commitment_devices_2.pdf Rogers, T., Milkman, K. L., &amp; Volpp, K. G. (2014). Commitment Devices: Using Initiatives to Change Behavior. JAMA , 311 (20), 2065-2066.]&lt;/ref&gt;
}}

==Further reading==
*Arslan, Ruben. "[https://web.archive.org/web/20120415041540/http://itb.biologie.hu-berlin.de/blogs/evoblog/contrib/evolution-of-cooperation-emotion-as-a-commitment-device-1 Evolution of cooperation: Emotion as a commitment device]," Evolutionary Theory across the Life Sciences, 2000-2011. 
*Beggs, Jodi. "[http://www.economistsdoitwithmodels.com/2009/06/17/be-careful-with-those-commitment-devices/ Be Careful With Those Commitment Devices…]," June 17, 2009.
*Brocas ''et al.'', Isabelle, Juan D. Carrillo, and Mathias Dewatripont. "[http://www-bcf.usc.edu/~juandc/PDFpapers/book2-ch04.pdf Commitment Devices under Self-Control Problems: An Overview],"
*Ross and Dumouchel, Don and Paul. "[http://rss.sagepub.com/content/16/3/251.abstract Emotions as Strategic Signals]," Rationality and Society August 2004 vol. 16 no. 3 251-286. 
*Straker, Dave. "[http://changingminds.org/techniques/general/more_methods/commitment_devices.htm Commitment Devices]," Changing Minds, 2002-2011.

[[Category:Behavioral economics]]
[[Category:Game theory]]</text>
      <sha1>ijy4rt52ccxm1hxo20fy24bffrbryku</sha1>
    </revision>
  </page>
  <page>
    <title>Continuous product</title>
    <ns>0</ns>
    <id>29354754</id>
    <redirect title="Product integral" />
    <revision>
      <id>392929812</id>
      <timestamp>2010-10-26T04:16:59Z</timestamp>
      <contributor>
        <username>Keilandreas</username>
        <id>11906412</id>
      </contributor>
      <comment>"continuous product" is a commonly used alternative name for "product integral"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="81">#REDIRECT [[product integral]]
[[Category:Integrals]]
[[Category:Multiplication]]</text>
      <sha1>ci30thga3k3gpol9f34zkzs20l5s9ka</sha1>
    </revision>
  </page>
  <page>
    <title>Director string</title>
    <ns>0</ns>
    <id>16820442</id>
    <revision>
      <id>750477774</id>
      <parentid>711064166</parentid>
      <timestamp>2016-11-20T00:09:21Z</timestamp>
      <contributor>
        <username>Dgpop</username>
        <id>96647</id>
      </contributor>
      <comment>/* See also */ Removed dead link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4141">In [[mathematics]], in the area of [[lambda calculus]] and [[computation]], '''directors''' or '''director strings''' are a mechanism for keeping track of the [[free variable]]s in a [[Expression (mathematics)|term]].  Loosely speaking, they can be understood as a kind of [[memoization]] for free variables; that is, as an [[program optimization|optimization]] technique for rapidly locating the free variables in a [[term algebra]] or in a lambda expression. Director strings were introduced by Kennaway and Sleep in 1982 and further developed by Sinot, Fernández and Mackie&lt;ref&gt;F.-R. Sinot, M. Fernández and I. Mackie. Efficient Reductions with Director Strings. In ''Proc. Rewriting Techniques and Applications''. Springer LNCS vol 2706, 2003&lt;/ref&gt; as a mechanism for understanding and controlling the [[Analysis of algorithms|computational complexity]] cost of [[beta reduction]].

==Motivation==
In beta reduction, one defines the value of the expression on the left to be that on the right:
:&lt;math&gt;(\lambda x.E)y \equiv E[x:= y]\,&lt;/math&gt; or &lt;math&gt;(\lambda x.E)y \equiv E[y/x]&lt;/math&gt;  (Replace all ''x'' in ''E''(body) by ''y'')

While this is a conceptually simple operation, the [[Analysis of algorithms|computational complexity]] of the step can be non-trivial: a naive algorithm would scan the expression ''E'' for all occurrences of the free variable ''x''. Such an algorithm is clearly ''O''(''n'') in the length of the expression ''E''. Thus, one is motivated to somehow track the occurrences of the free variables in the expression. One may attempt to track the position of ''every'' free variable, wherever it may occur in the expression, but this can clearly become very costly in terms of storage; furthermore, it provides a level of detail that is not really needed. Director strings suggest that the correct model is to track free variables in a hierarchical fashion, by tracking their use in component terms.

==Definition==
Consider, for simplicity, a [[term algebra]], that is, a collection of free variables, constants, and operators which may be freely combined. Assume that a term ''t'' takes the form 
:&lt;math&gt;t ::= f(t_1,t_2,\dots,t_n)&lt;/math&gt;

where ''f'' is a [[function (mathematics)|function]], of [[arity]] ''n'', with no [[free variable]]s, and the &lt;math&gt;t_i&lt;/math&gt; are terms that may or may not contain free variables. Let ''V'' denote the set of all free variables that may occur in the set of all terms.   The director is then the map

:&lt;math&gt;\sigma_t: V\to P(\lbrace 1,2,\dots,n\rbrace)&lt;/math&gt;

from the free variables to the [[power set]] &lt;math&gt;P(X)&lt;/math&gt; of the set &lt;math&gt;X=\lbrace 1,2,\dots,n\rbrace&lt;/math&gt;. The values taken by &lt;math&gt;\sigma_t&lt;/math&gt; are simply a list of the indices of the &lt;math&gt;t_i&lt;/math&gt; in which a given free variable occurs.  Thus, for example, if a free variable &lt;math&gt;x\in V&lt;/math&gt; occurs in &lt;math&gt;t_3&lt;/math&gt; and &lt;math&gt;t_5&lt;/math&gt; but in no other terms, then one has &lt;math&gt;\sigma_t(x) = \lbrace 3,5\rbrace&lt;/math&gt;.

Thus, for every term &lt;math&gt;t\in T&lt;/math&gt; in the set of all terms ''T'', one maintains a function &lt;math&gt;\sigma_t&lt;/math&gt;, and instead of working only with terms ''t'', one works with pairs &lt;math&gt;(t,\sigma_t)&lt;/math&gt;. Thus, the time complexity of finding the free variables in ''t'' is traded for the space complexity of maintaining a list of the terms in which a variable occurs.

== General case == 
Although the above definition is formulated in terms of a [[term algebra]], the general concept applies more generally, and can be defined both for [[combinatory algebra]]s and for [[lambda calculus]] proper, specifically, within the framework of [[explicit substitution]].

== See also==
* [[Term rewrite system]]
* [[Explicit substitution]]
* [[Memoization]]

==References==
&lt;references/&gt;
* F.-R. Sinot.  "[http://www.lsv.ens-cachan.fr/Publis/PAPERS/PDF/sinot-jlc05.pdf Director Strings Revisited: A Generic Approach to the Efficient Representation of Free Variables in Higher-order Rewriting.]"  ''Journal of Logic and Computation'' '''15'''(2), pages 201-218, 2005.

[[Category:Lambda calculus]]
[[Category:Rewriting systems]]
[[Category:Software optimization]]</text>
      <sha1>o3klu3cdkzhn1ri3gifdboqxrh9erp5</sha1>
    </revision>
  </page>
  <page>
    <title>ESC/Java</title>
    <ns>0</ns>
    <id>679218</id>
    <revision>
      <id>789893360</id>
      <parentid>786179469</parentid>
      <timestamp>2017-07-10T09:03:26Z</timestamp>
      <contributor>
        <ip>171.79.77.6</ip>
      </contributor>
      <comment>subcat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7525">{{More footnotes|date=March 2010}}
'''ESC/Java''' (and more recently '''ESC/Java2'''), the "Extended Static Checker for Java," is a [[programming tool]] that attempts to find common [[run-time error]]s in [[Java (programming language)|Java]] programs at [[compile time]].&lt;ref&gt;{{cite conference |last1=Flanagan |first1=C. |last2=Leino |first2=K.R.M. |last3=Lillibridge |first3=M. |last4=Nelson |first4=G. |last5=Saxe |first6=J. B. |author5-link=James B. Saxe|last6=Stata |first5=R. |title=Extended static checking for Java |work=Proceedings of the Conference on Programming Language Design and Implementation |pages=234–245 |year=2002 |isbn=1-58113-463-0 |doi=10.1145/512529.512558}}&lt;/ref&gt;  The underlying approach used in ESC/Java is referred to as [[extended static checking]], which is a collective name referring to a range of techniques for [[static code analysis|statically checking]] the correctness of various program constraints.  For example, that an integer variable is greater-than-zero, or lies between the [[bounds checking|bounds of an array]].  This technique was pioneered in ESC/Java (and its predecessor, ESC/Modula-3) and can be thought of as an extended form of [[type checking]].  Extended static checking usually involves the use of an [[automated theorem proving|automated theorem prover]] and, in ESC/Java, the Simplify theorem prover was used.

ESC/Java is neither [[soundness|sound]] nor [[completeness (logic)|complete]].  This was intentional and aims to reduce the number of errors and/or warnings reported to the programmer, in order to make the tool more useful in practice.  However, it does mean that: firstly, there are programs that ESC/Java will erroneously consider to be incorrect (known as ''false-positives''); secondly, there are incorrect programs it will consider to be correct (known as ''false-negatives'').  Examples in the latter category include errors arising from [[modular arithmetic]] and/or [[Thread (computer science)|multithreading]].

ESC/Java was originally developed at the [[DEC Systems Research Center|Compaq Systems Research Center]] (SRC).  SRC launched the project in 1997, after work on their original extended static checker, ESC/Modula-3, ended in 1996.  In 2002, SRC released the [[source code]] for ESC/Java and related tools.  Recent versions of ESC/Java are based around the [[Java Modeling Language]] (JML). Users can control the amount and kinds of checking by annotating their programs with specially formatted comments or ''[[Directive (programming)|pragmas]]''.

The [[Radboud University Nijmegen|University of Nijmegen]]'s ''Security of Systems'' group released alpha versions of ESC/Java2, an extended version of ESC/Java that processes the [[Java Modeling Language|JML]] specification language through 2004.  From 2004 to 2009, ESC/Java2 development was managed by the KindSoftware Research Group at [[University College Dublin]], which in 2009 moved to the [[IT University of Copenhagen]], and in 2012 to the [[Technical University of Denmark]].  Over the years, ESC/Java2 has gained many new features including the ability to reason with multiple [[Automated theorem prover|theorem prover]]s and integration with [[Eclipse (software)|Eclipse]].

[http://www.openjml.org/ OpenJML], the successor of ESC/Java2, is available for Java 1.8.&lt;ref&gt;http://jmlspecs.sourceforge.net/&lt;/ref&gt; The source is available at https://github.com/OpenJML

&lt;ref&gt;https://sourceforge.net/p/jmlspecs/code/HEAD/tree/OpenJML/trunk/OpenJML/&lt;/ref&gt;

== See also ==
*[[Java Modeling Language]] (JML)

== References ==
{{Reflist}}
;Notes
{{refbegin}}
*{{cite conference |last1=Flanagan |first1=C. |last2=Kiniry |first2=K. R. M. |title=Houdini, an Annotation Assistant for ESC/Java |work=FME 2001: Formal Methods for Increasing Software Productivity |pages=500–517 |year=2001 |isbn=3-540-41791-5 |doi=10.1007/3-540-45251-6_29}}
*{{cite conference |last1=Cataño |first1=N. |last2=Huisman |first2=M. |title=Formal Specification and Static Checking of Gemplus’ Electronic Purse Using ESC/Java |work=FME 2002:Formal Methods—Getting IT Right |pages=272–289 |year=2002 |isbn=3-540-43928-5 |doi=10.1007/3-540-45614-7_16}}
*{{cite conference |last1=Cok |first1=D. R. |last2=Kiniry |first2=J. R. |title=ESC/Java2: uniting ESC/Java and JML |work=Proceedings of the 2004 international conference on Construction and Analysis of Safe, Secure, and Interoperable Smart Devices |pages=108–128 |year=2005 |isbn=3-540-24287-2 |doi=10.1007/978-3-540-30569-9_6}}
*{{cite conference |last1=Chalin |first1=P. |last2=Kiniry |first2=J. R. |last3=Leavens |first3=G. T. |last4=Poll |first4=E. |title=Beyond Assertions: Advanced Specification and Verification with JML and ESC/Java2 |work=Formal Methods for Components and Objects |pages=342–363 |year=2006 |isbn=3-540-36749-7 |doi=10.1007/3-540-45614-7_16 |url=http://www.cs.ru.nl/~erikpoll/papers/fmco05.pdf}}
*{{cite conference |last1=Cok |first1=D. R. |title=Specifying java iterators with JML and Esc/Java2 |work=Proceedings of the 2006 conference on Specification and verification of component-based systems |pages=71–74 |year=2006 |isbn=1-59593-586-X |doi=10.1145/1181195.1181210}}
*{{cite conference |last1=Chalin |first1=P. |title=Early detection of JML specification errors using ESC/Java2 |work=Proceedings of the 2006 conference on Specification and verification of component-based systems |pages=25–32 |year=2006 |isbn=1-59593-586-X |doi=10.1145/1181195.1181201}}
*{{cite conference |last1=Ishikawa |first1=H. |title=An Approach for Refactoring using ESC/Java2: A Simple Case Study |work=Proceedings of the 2009 conference on New Trends in Software Methodologies, Tools and Techniques |pages=61–72 |year=2009 |isbn=978-1-60750-049-0}}
*{{cite conference |last1=Poll |first1=E. |title=Teaching Program Specification and Verification Using JML and ESC/Java2 |work=Proceedings of the 2nd International Conference on Teaching Formal Methods |pages=92–104 |year=2009 |isbn=978-3-642-04911-8 |doi=10.1007/978-3-642-04912-5_7 |url=http://www.cs.ru.nl/~erikpoll/papers/tfm2009.pdf}}
*{{cite conference |last1=James |first1=P. R. |last2=Chalin |first2=P. |title=ESC4: a modern caching ESC for Java |work=Proceedings of the 8th international workshop on Specification and verification of component-based systems |pages=19–26 |year=2009 |isbn=978-1-60558-680-9 |doi=10.1145/1596486.1596491}}
{{refend}}

== External links ==
* [http://www.hpl.hp.com/downloads/crl/jtk/ Java Programming Toolkit Source Release]
* {{webarchive |url=https://web.archive.org/web/20051208055447/http://research.compaq.com/SRC/esc/ |title=Extended Static Checking for Java |date=December 8, 2005}}
* [http://www.kindsoftware.com/products/opensource/ESCJava2/ ESC/Java2 at KindSoftware]
* [ftp://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-159.html SRC-RR-159 Extended Static Checking. - David L. Detlefs, K. Rustan M. Leino, Greg Nelson, James B. Saxe]
* {{webarchive |url=https://web.archive.org/web/20010228175138/http://research.compaq.com/SRC/esc/escm3/download.html |title=Extended Static Checking Modula-3 |date=February 28, 2001}}
* [http://www.researchchannel.org/prog/displayevent.aspx?rID=2761&amp;fID=345 Extended Static Checking] Computer Science &amp; Engineering Colloquia. University of Washington. 1999.

{{DEFAULTSORT:Esc Java}}
[[Category:2002 software]]
[[Category:Static program analysis tools]]
[[Category:Formal methods tools]]
[[Category:Formal specification languages]]
[[Category:Free computer programming tools]]</text>
      <sha1>eiqltjn6o2ug1xab9kjy0kqu3z0a215</sha1>
    </revision>
  </page>
  <page>
    <title>Frostman lemma</title>
    <ns>0</ns>
    <id>18104093</id>
    <revision>
      <id>637604188</id>
      <parentid>607155935</parentid>
      <timestamp>2014-12-11T09:58:36Z</timestamp>
      <contributor>
        <username>Novn</username>
        <id>23449227</id>
      </contributor>
      <minor/>
      <comment>Added link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1965">In [[mathematics]], and more specifically, in the [[fractal dimension|theory of fractal dimensions]], '''Frostman's lemma''' provides a convenient tool for estimating the [[Hausdorff dimension]] of sets.

'''Lemma:''' Let ''A'' be a [[Borel measurable|Borel]] subset of '''R'''&lt;sup&gt;''n''&lt;/sup&gt;, and let ''s''&amp;nbsp;&gt;&amp;nbsp;0. Then the following are equivalent:
*''H''&lt;sup&gt;''s''&lt;/sup&gt;(''A'')&amp;nbsp;&gt;&amp;nbsp;0, where ''H''&lt;sup&gt;''s''&lt;/sup&gt; denotes the ''s''-dimensional [[Hausdorff measure]].
*There is an (unsigned) [[Borel measure]] ''&amp;mu;'' satisfying ''&amp;mu;''(''A'')&amp;nbsp;&gt;&amp;nbsp;0, and such that 
::&lt;math&gt;\mu(B(x,r))\le r^s&lt;/math&gt; 
:holds for all ''x''&amp;nbsp;&amp;isin;&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt; and ''r''&gt;0.

[[Otto Frostman]] proved this lemma for closed sets ''A'' as part of his PhD dissertation at [[Lund University]] in 1935. The generalization to Borel sets is more involved, and requires the theory of [[Suslin set]]s.

A useful corollary of Frostman's lemma requires the notions of the ''s''-capacity of a Borel set ''A''&amp;nbsp;&amp;sub;&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;, which is defined by

:&lt;math&gt;C_s(A):=\sup\Bigl\{\Bigl(\int_{A\times A} \frac{d\mu(x)\,d\mu(y)}{|x-y|^{s}}\Bigr)^{-1}:\mu\text{ is a Borel measure and }\mu(A)=1\Bigr\}.&lt;/math&gt;

(Here, we take inf&amp;nbsp;&amp;empty;&amp;nbsp;=&amp;nbsp;&amp;infin; and {{Frac|1|&amp;infin;}}&amp;nbsp;=&amp;nbsp;0.  As before, the measure &lt;math&gt;\mu&lt;/math&gt; is unsigned.) It follows from Frostman's lemma that for Borel ''A''&amp;nbsp;&amp;sub;&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;

:&lt;math&gt;\mathrm{dim}_H(A)= \sup\{s\ge 0:C_s(A)&gt;0\}.&lt;/math&gt;

==References==
* {{Citation
 | last1=Mattila
 | first1=Pertti 
 | author1-link = Pertti Mattila
 | title=Geometry of sets and measures in Euclidean spaces | publisher=[[Cambridge University Press]]
 | isbn=978-0-521-65595-8 | year=1995
 | mr = 1333890 |series= Cambridge Studies in Advanced Mathematics | volume =  44}}

[[Category:Dimension theory]]
[[Category:Fractals]]
[[Category:Metric geometry]]


{{mathanalysis-stub}}</text>
      <sha1>192y8aa3f7z47ya22agksq6gqxt1vly</sha1>
    </revision>
  </page>
  <page>
    <title>Greedy coloring</title>
    <ns>0</ns>
    <id>21051195</id>
    <revision>
      <id>809913614</id>
      <parentid>809912391</parentid>
      <timestamp>2017-11-12T08:27:00Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 809912391 by [[Special:Contributions/138.16.102.178|138.16.102.178]] ([[User talk:138.16.102.178|talk]]) incorrect</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10496">[[Image:Greedy colourings.svg|thumb|right|Two greedy colorings of the same graph using different vertex orders. The right example generalises to 2-colorable graphs with {{mvar|n}} vertices, where the greedy algorithm expends {{math|''n''/2}} colors.]]
In the study of [[graph coloring]] problems in [[mathematics]] and [[computer science]], a '''greedy coloring''' is a coloring of the [[vertex (graph theory)|vertices]] of a [[undirected graph|graph]] formed by a [[greedy algorithm]] that considers the vertices of the graph in sequence and assigns each vertex its [[Mex (mathematics)|first available]] color. Greedy colorings do not in general use the minimum number of colors possible. However, they have been used in mathematics as a technique for proving other results about colorings and in computer science as a heuristic to find colorings with few colors.

==Greed is not always good==
A [[crown graph]] (a [[complete bipartite graph]] {{math|''K''&lt;sub&gt;''n'',''n''&lt;/sub&gt;}}, with the edges of a [[perfect matching]] removed) is a particularly bad case for greedy coloring: if the vertex ordering places two vertices consecutively whenever they belong to one of the pairs of the removed matching, then a greedy coloring will use {{mvar|n}} colors, while the optimal number of colors for this graph is two. There also exist graphs such that with high probability a randomly chosen vertex ordering leads to a number of colors much larger than the minimum.&lt;ref&gt;{{harvtxt|Kučera|1991}}.&lt;/ref&gt; Therefore, it is of some importance in greedy coloring to choose the vertex ordering carefully. The number of colors produced by the greedy coloring for the worst ordering of a given graph is called its [[Grundy number]].

It is NP-complete to determine, for a given graph {{mvar|G}} and number {{mvar|k}}, whether there exists an ordering of the vertices of {{mvar|G}} that forces the greedy algorithm to use {{mvar|k}} or more colors. In particular, this means that it is difficult to find the worst ordering for {{mvar|G}}.&lt;ref&gt;{{harvtxt|Zaker|2006}}.&lt;/ref&gt;

==Optimal ordering==
The vertices of any graph may always be ordered in such a way that the greedy algorithm produces an optimal coloring. For, given any optimal coloring in which the smallest color set is maximal, the second color set is maximal with respect to the first color set, etc., one may order the vertices by their colors. Then when one uses a greedy algorithm with this order, the resulting coloring is automatically optimal. More strongly, [[perfectly orderable graph]]s (which include [[chordal graph]]s, [[comparability graph]]s, and [[distance-hereditary graph]]s) have an ordering that is optimal both for the graph itself and for all of its [[induced subgraph]]s.&lt;ref&gt;{{harvtxt|Chvátal|1984}}.&lt;/ref&gt; However, finding an optimal ordering for an arbitrary graph is [[NP-hard]] (because it could be used to solve the [[NP-complete]] graph coloring problem), and recognizing perfectly orderable graphs is also NP-complete.&lt;ref&gt;{{harvtxt|Middendorf|Pfeiffer|1990}}.&lt;/ref&gt; For this reason, heuristics have been used that attempt to reduce the number of colors while not guaranteeing an optimal number of colors.

==Heuristic ordering strategies==
A commonly used ordering for greedy coloring is to choose a vertex {{mvar|v}} of minimum [[degree (graph theory)|degree]], order the remaining vertices [[recursion (computer science)|recursively]], and then place {{mvar|v}} last in the ordering. If every subgraph of a graph {{mvar|G}} contains a vertex of degree at most {{mvar|d}}, then the greedy coloring for this ordering will use at most {{math|''d''&amp;nbsp;+&amp;nbsp;1}} colors.&lt;ref&gt;{{harvtxt|Welsh|Powell|1967}}; {{harvtxt|Johnson|1979}}; {{harvtxt|Sysło|1989}}; {{harvtxt|Maffray|2003}}.&lt;/ref&gt; The smallest such {{mvar|d}} is commonly known as the [[Degeneracy (graph theory)|degeneracy]] of the graph.

For a graph of maximum degree {{math|Δ}}, any greedy coloring will use at most {{math|Δ&amp;nbsp;+&amp;nbsp;1}} colors. [[Brooks' theorem]] states that with two exceptions ([[complete graph|cliques]] and [[cycle graph|odd cycles]]) at most {{math|Δ}} colors are needed. One proof of Brooks' theorem involves finding a vertex ordering in which the first two vertices are adjacent to the final vertex but not adjacent to each other, and each subsequent vertex has at least one earlier neighbor. For an ordering with this property, the greedy coloring algorithm uses at most {{math|Δ}} colors.&lt;ref&gt;{{harvtxt|Lovász|1975}}.&lt;/ref&gt;

==Alternative color selection schemes==
It is possible to define a greedy coloring algorithm in which the vertices of the given graph are colored in a given sequence but in which the color chosen for each vertex is not necessarily the first available color; alternative color selection strategies have been studied within the framework of [[online algorithm]]s. In the online graph-coloring problem, vertices of a graph are presented one at a time in an arbitrary order to a coloring algorithm; the algorithm must choose a color for each vertex, based only on the colors of and adjacencies among already-processed vertices. In this context, one measures the quality of a color selection strategy by its [[Competitive analysis (online algorithm)|competitive ratio]], the ratio between the number of colors it uses and the optimal number of colors for the given graph.

If no additional restrictions on the graph are given, the optimal competitive ratio is only slightly sublinear.&lt;ref&gt;{{harvtxt|Lovász|Saks|Trotter|1989}}; {{harvtxt|Vishwanathan|1990}}.&lt;/ref&gt; However, for [[interval graph]]s, a constant competitive ratio is possible,&lt;ref&gt;{{harvtxt|Kierstead|Trotter|1981}}.&lt;/ref&gt; while for [[bipartite graph]]s and [[sparse graph]]s a logarithmic ratio can be achieved.&lt;ref name="irani"&gt;{{harvtxt|Irani|1994}}.&lt;/ref&gt; Indeed, for sparse graphs, the standard greedy coloring strategy of choosing the first available color achieves this competitive ratio, and it is possible to prove a matching lower bound on the competitive ratio of any online coloring algorithm.&lt;ref name="irani"/&gt;

==Notes==
{{reflist|2}}

==References==
*{{citation
 | last = Chvátal | first = Václav | author-link = Vašek Chvátal
 | contribution = Perfectly orderable graphs
 | editor1-last = Berge | editor1-first = Claude | editor1-link = Claude Berge
 | editor2-last = Chvátal | editor2-first = Václav | editor2-link = Vašek Chvátal
 | location = Amsterdam
 | pages = 63–68
 | publisher = North-Holland
 | series = Annals of Discrete Mathematics
 | title = Topics in Perfect Graphs
 | volume = 21
 | year = 1984}}. As cited by {{harvtxt|Maffray|2003}}.
*{{citation
 | last = Irani | first = Sandy
 | doi = 10.1007/BF01294263
 | issue = 1
 | journal = Algorithmica
 | pages = 53–72
 | title = Coloring inductive graphs on-line
 | volume = 11
 | year = 1994}}.
*{{citation
 | last1 = Kierstead | first1 = H. A.
 | last2 = Trotter | first2 = W. A.
 | journal = Congressus Numerantium
 | pages = 143–153
 | title = An extremal problem in recursive combinatorics
 | volume = 33
 | year = 1981}}. As cited by {{harvtxt|Irani|1994}}.
*{{citation
 | last = Kučera | first = Luděk
 | doi = 10.1016/0196-6774(91)90040-6
 | issue = 4
 | journal = Journal of Algorithms
 | pages = 674–684
 | title = The greedy coloring is a bad probabilistic algorithm
 | volume = 12
 | year = 1991}}.
*{{citation
 | last = Johnson | first = D. S. | author-link = David S. Johnson
 | contribution = Worst case behavior of graph coloring algorithms
 | location = Winnipeg
 | pages = 513–527
 | publisher = Utilitas Mathematica
 | title = Proc. 5th Southeastern Conf. Combinatorics, Graph Theory and Computation
 | year = 1979}}. As cited by {{harvtxt|Maffray|2003}}.
*{{citation
 | last = Lovász | first = L. | author-link = László Lovász
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | pages = 269–271
 | title = Three short proofs in graph theory
 | volume = 19
 | year = 1975
 | doi = 10.1016/0095-8956(75)90089-1
 | issue = 3}}.
*{{citation
 | last1 = Lovász | first1 = L. | author1-link = László Lovász
 | last2 = Saks | first2 = M. E.
 | last3 = Trotter | first3 = W. A.
 | doi = 10.1016/0012-365X(89)90096-4
 | issue = 1–3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 319–325
 | title = An on-line graph coloring algorithm with sublinear performance ratio
 | volume = 75
 | year = 1989}}.
*{{citation
 | last = Maffray | first = Frédéric
 | contribution = On the coloration of perfect graphs
 | doi = 10.1007/0-387-22444-0_3
 | editor1-last = Reed | editor1-first = Bruce A. | editor1-link = Bruce Reed (mathematician)
 | editor2-last = Sales | editor2-first = Cláudia L.
 | pages = 65–84
 | publisher = Springer-Verlag
 | series = CMS Books in Mathematics
 | title = Recent Advances in Algorithms and Combinatorics
 | volume = 11
 | year = 2003
 | isbn = 0-387-95434-1}}.
*{{citation
 | last1 = Middendorf | first1 = Matthias
 | last2 = Pfeiffer | first2 = Frank
 | doi = 10.1016/0012-365X(90)90251-C
 | issue = 3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 327–333
 | title = On the complexity of recognizing perfectly orderable graphs
 | volume = 80
 | year = 1990}}.
*{{citation
 | last = Sysło | first = Maciej M.
 | doi = 10.1016/0012-365X(89)90212-4
 | issue = 1–2
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 241–243
 | title = Sequential coloring versus Welsh-Powell bound
 | volume = 74
 | year = 1989}}.
*{{citation
 | last = Vishwanathan | first = S.
 | contribution = Randomized online graph coloring
 | doi = 10.1109/FSCS.1990.89567
 | pages = 464–469
 | title = Proceedings of the 31st IEEE [[Symposium on Foundations of Computer Science]] (FOCS '90)
 | volume = 2
 | year = 1990
 | isbn = 0-8186-2082-X}}.
*{{citation
 | last1 = Welsh | first1 = D. J. A.
 | last2 = Powell | first2 = M. B.
 | doi = 10.1093/comjnl/10.1.85
 | issue = 1
 | journal = [[The Computer Journal]]
 | pages = 85–86
 | title = An upper bound for the chromatic number of a graph and its application to timetabling problems
 | volume = 10
 | year = 1967}}.
*{{citation
 | last = Zaker | first = Manouchehr
 | doi = 10.1016/j.disc.2005.06.044
 | issue = 2–3
 | journal = [[Discrete Mathematics (journal)|Discrete Mathematics]]
 | pages = 3166–3173
 | title = Results on the Grundy chromatic number of graphs
 | volume = 306
 | year = 2006}}.

[[Category:Graph coloring]]</text>
      <sha1>d5rs9wn2yljnugin3c8re9f6jvdmhdy</sha1>
    </revision>
  </page>
  <page>
    <title>Grothendieck's Galois theory</title>
    <ns>0</ns>
    <id>372470</id>
    <revision>
      <id>842970641</id>
      <parentid>839576312</parentid>
      <timestamp>2018-05-25T23:07:07Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <minor/>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3913">In [[mathematics]], '''Grothendieck's Galois theory''' is an abstract approach to the [[Galois theory]] of fields, developed around 1960 to provide a way to study the [[fundamental group]] of [[algebraic topology]] in the setting of [[algebraic geometry]]. It provides, in the classical setting of [[field theory (mathematics)|field theory]], an alternative perspective to that of [[Emil Artin]] based on [[linear algebra]], which became standard from about the 1930s.

The approach of [[Alexander Grothendieck]] is concerned with the [[category theory|category-theoretic]] properties that characterise the categories of finite ''G''-sets for a fixed [[profinite group]] ''G''.  For example, ''G'' might be the group denoted &lt;math&gt;\hat{\Z}&lt;/math&gt;, which is the [[inverse limit]] of the cyclic additive groups '''Z'''/n'''Z''' &amp;mdash; or equivalently the completion of the [[infinite cyclic group]] '''Z''' for the topology of subgroups of finite [[Index of a subgroup|index]]. A finite ''G''-set is then a finite set ''X'' on which ''G'' acts through a quotient finite cyclic group, so that it is specified by giving some permutation of ''X''.

In the above example, a connection with classical [[Galois theory]] can be seen by regarding &lt;math&gt;\hat{\Z}&lt;/math&gt; as the profinite Galois group Gal(&lt;span style="text-decoration:overline"&gt;F&lt;/span&gt;/F) of the [[algebraic closure]] &lt;span style="text-decoration:overline"&gt;F&lt;/span&gt; of any [[finite field]] ''F'', over ''F''. That is, the automorphisms of &lt;span style="text-decoration:overline"&gt;F&lt;/span&gt; fixing ''F'' are described by the inverse limit, as we take larger and larger finite [[splitting field]]s over ''F''.  The connection with geometry can be seen when we look at [[covering space]]s of the [[unit disk]] in the [[complex plane]] with the origin removed: the finite covering realised by the ''z''&lt;sup&gt;''n''&lt;/sup&gt; map of the disk, thought of by means of a complex number variable ''z'', corresponds to the subgroup ''n''.'''Z''' of the fundamental group of the punctured disk.

The theory of Grothendieck, published in [[SGA1]], shows how to reconstruct the category of ''G''-sets from a ''fibre functor'' &amp;Phi;, which in the geometric setting takes the fibre of a covering above a fixed base point (as a set). In fact there is an isomorphism proved of the type

:''G'' &amp;cong; Aut(&amp;Phi;),

the latter being the group of automorphisms (self-[[natural equivalence]]s) of &amp;Phi;. An abstract classification of categories with a functor to the category of sets is given, by means of which one can recognise categories of ''G''-sets for ''G'' profinite.

To see how this applies to the case of fields, one has to study the [[tensor product of fields]].{{clarify|more details are needed.|date=November 2017}} Later developments in [[topos]] theory make this all part of a theory of ''[[atomic topos]]es''.

== See also ==
*[[Tannakian formalism]]

==References==
* {{cite book|
last=Grothendieck|
first=A.|
title=SGA1 ''Revêtements étales et groupe fondamental, 1960–1961'|
series=Lecture Notes in Mathematics 224|
year=1971|
publisher=SpringerSphiwe Verlag
|display-authors=etal}}
* {{cite book|
last=Joyal|
first=André|author2=Tierney, Myles|
title=An Extension of the Galois Theory of Grothendieck|
series=Memoirs of the American Mathematical Society|
year= 1984|
publisher=Proquest Info &amp; Learning|
isbn=0-8218-2312-4
}}

* Borceux, F. and Janelidze, G., Cambridge University Press  (2001). ''Galois theories'', {{ISBN|0-521-80309-8}} (This book introduces the reader to the Galois theory of [[Grothendieck]], and some generalisations, leading to Galois [[groupoids]].)
* Szamuely, T., Galois Groups and Fundamental Groups, Cambridge University Press, 2009.
* Dubuc, E. J and de la Vega, C. S., On the Galois theory of Grothendieck, https://arxiv.org/abs/math/0009145v1

[[Category:Field theory]]
[[Category:Algebraic geometry]]
[[Category:Category theory]]</text>
      <sha1>4hif4dv3ldy6zbzkmo1ur4v3605v0ba</sha1>
    </revision>
  </page>
  <page>
    <title>Haynsworth inertia additivity formula</title>
    <ns>0</ns>
    <id>31575765</id>
    <revision>
      <id>790709882</id>
      <parentid>717592683</parentid>
      <timestamp>2017-07-15T15:43:54Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* top */LaTeX spacing clean up, replaced: \, &lt;/math&gt; → &lt;/math&gt; (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1794">In mathematics, the '''Haynsworth inertia additivity formula''', discovered by Emilie Virginia Haynsworth&lt;ref&gt;Haynsworth, E. V., "Determination of the inertia of a partitioned Hermitian matrix", ''[[Linear Algebra and its Applications]]'', volume 1 (1968), pages 73–81&lt;/ref&gt; (1916–1985), concerns the number of positive, negative, and zero [[eigenvalue]]s of a [[Hermitian matrix]] and of [[block matrix|block matrices into which it is partitioned]].

The ''inertia'' of a Hermitian matrix ''H'' is defined as the ordered triple

: &lt;math&gt; \mathrm{In}(H) = \left( \pi(H), \nu(H), \delta(H) \right) &lt;/math&gt;

whose components are respectively the numbers of positive, negative, and zero eigenvalues of&amp;nbsp;''H''.  Haynsworth considered a partitioned Hermitian matrix

: &lt;math&gt; H = \begin{bmatrix} H_{11} &amp; H_{12} \\  H_{12}^\ast &amp; H_{22} \end{bmatrix} &lt;/math&gt;

where ''H''&lt;sub&gt;11&lt;/sub&gt; is [[nonsingular matrix|nonsingular]] and ''H''&lt;sub&gt;12&lt;/sub&gt;&lt;sup&gt;*&lt;/sup&gt; is the [[conjugate transpose]] of&amp;nbsp;''H''&lt;sub&gt;12&lt;/sub&gt;.  The formula states:&lt;ref&gt;{{cite book  |title=The Schur Complement and Its Applications |page=15|first=Fuzhen |last=Zhang |year=2005 |publisher=Springer| isbn=0-387-24271-6 }}&lt;/ref&gt;&lt;ref&gt;{{Google books |id=Wjd8_AwjiIIC |page=15 |title=The Schur Complement and Its Applications }}&lt;/ref&gt;

: &lt;math&gt; \mathrm{In} \begin{bmatrix} H_{11} &amp; H_{12} \\  H_{12}^\ast &amp; H_{22} \end{bmatrix} = \mathrm{In}(H_{11}) + \mathrm{In}(H/H_{11}) &lt;/math&gt;

where ''H''/''H''&lt;sub&gt;11&lt;/sub&gt; is the [[Schur complement]] of ''H''&lt;sub&gt;11&lt;/sub&gt; in&amp;nbsp;''H'':

: &lt;math&gt; H/H_{11} = H_{22} - H_{12}^\ast H_{11}^{-1}H_{12}. &lt;/math&gt;

== See also ==
* [[Block matrix pseudoinverse]]

== Notes and references ==
{{reflist}}

[[Category:Linear algebra]]
[[Category:Matrix theory]]
[[Category:Theorems in algebra]]</text>
      <sha1>9vam789v85sk4sut0azuft1vicn73m4</sha1>
    </revision>
  </page>
  <page>
    <title>How to Lie with Statistics</title>
    <ns>0</ns>
    <id>2099648</id>
    <revision>
      <id>859234606</id>
      <parentid>841567847</parentid>
      <timestamp>2018-09-12T17:39:51Z</timestamp>
      <contributor>
        <username>Bellerophon5685</username>
        <id>1258165</id>
      </contributor>
      <comment>/* See also */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3662">{{italic title}}
{{Infobox book
&lt;!-- |italic title = (see above) --&gt;
| name             = How to Lie with Statistics
| image            = How to Lie with Statistics.jpg
| caption          = First edition
| author           = [[Darrell Huff]]
| title_orig       = 
| translator       = 
| illustrator      = [[Irving Geis]]
| cover_artist     = 
| country          = 
| language         = 
| series           = 
| subject          = 
| genre            = 
| publisher        = [[W. W. Norton &amp; Company]]
| pub_date         = 1954
| english_pub_date = 
| media_type       = 
| pages            = 
| isbn =  
}}

'''''How to Lie with Statistics''''' is a book written by [[Darrell Huff]] in 1954 presenting an introduction to [[statistics]] for the general reader. Not a statistician, Huff was a journalist who wrote many "how to" articles as a freelancer.

==Subject==
The book is a brief illustrated volume outlining errors when it comes to the interpretation of statistics, and how these errors may create incorrect conclusions. 

In the 1960s and 1970s, it became a standard textbook introduction to the subject of statistics for many college students.  It has become one of the best-selling statistics books in history, with over one and a half million copies sold in the English-language edition.&lt;ref name="fiftyyears"&gt;"Over the last fifty years, How to Lie with Statistics has sold more copies than any other statistical text." J. M. Steele. "[http://www-stat.wharton.upenn.edu/~steele/Publications/PDF/TN148.pdf Darrell Huff and Fifty Years of ''How to Lie with Statistics'']. ''Statistical Science'', 20 (3), 2005, 205–209.&lt;/ref&gt; It has also been widely translated.

Themes of the book include "[[Correlation does not imply causation]]" and "Using [[random sampling]]". It also shows how statistical graphs can be used to distort reality, for example by truncating the bottom of a line or bar chart, so that differences seem larger than they are, or by representing one-dimensional quantities on a pictogram by two- or three-dimensional objects to compare their sizes, so that the reader forgets that the images do not scale the same way the quantities do.

The original edition contained illustrations by artist [[Irving Geis]]. In a UK edition, these were replaced with cartoons by [[Mel Calman]].

==See also==
*''[[Freakonomics]]''
*[[Lies, damned lies, and statistics]]
*[[Misuse of statistics]]
*''[[The Tiger That Isn't]]'', a book on taking numbers out of context

== Related books by Darrell Huff ==
* ''How to Take a Chance'' (1959)
* ''Score: The Strategy of Taking Tests'' (1961)
* ''Cycles in Your Life: The Rhythms of War, Wealth, Nature, and Human Behavior'' (1964)
* ''How to Figure the Odds on Everything'' (1972)
* ''The Complete How to Figure It: Using Math in Everyday Life'' (1996)

==Notes==
{{reflist}}

==Sources==
* Darrell Huff, (1954) ''How to Lie with Statistics'' (illust. I. Geis), Norton, New York, {{ISBN|0-393-31072-8}}
* Darrell Huff, (1991) ''How to Lie with Statistics''  Penguin; New Ed edition, {{ISBN|0-14-013629-0}}

==External links==
{{Wikiquote}}
*[http://www.mooreds.com/wordpress/archives/158 Book review] at www.mooreds.com
*[http://plus.maths.org/content/how-lie-statistics-0 Book review] at plus.maths.org
*[https://www.goodreads.com/book/show/51291.How_to_Lie_with_Statistics Book reviews] at goodreads.com
*Book readable online: [[iarchive:HowToLieWithStatistics|https://archive.org/details/HowToLieWithStatistics]]

{{Misuse of statistics}}

{{DEFAULTSORT:How To Lie With Statistics}}
[[Category:1954 books]]
[[Category:Statistics books]]
[[Category:Mathematics books]]
[[Category:Misuse of statistics]]</text>
      <sha1>l44rup11ukpltqbw31ur5srzbekdxwl</sha1>
    </revision>
  </page>
  <page>
    <title>Iterated limit</title>
    <ns>0</ns>
    <id>39305952</id>
    <revision>
      <id>861742854</id>
      <parentid>778130826</parentid>
      <timestamp>2018-09-29T17:59:54Z</timestamp>
      <contributor>
        <username>Thatsme314</username>
        <id>31364895</id>
      </contributor>
      <minor/>
      <comment>/* Sufficient condition */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3326">{{more footnotes|date=August 2013}}

In [[multivariable calculus]], an '''iterated limit''' is an expression of the form

: &lt;math&gt; \lim_{y \to q} \big( \lim_{x \to p} f(x, y) \big). \, &lt;/math&gt;

One has an expression whose value depends on at least two variables, one takes the limit as one of the two variables approaches some number, getting an expression whose value depends only on the other variable, and then one takes the limit as the other variable approaches some number.  This is not defined in the same way as the limit

: &lt;math&gt; \lim_{(x,y) \to (p, q)} f(x, y), \, &lt;/math&gt;

which is not an iterated limit.  To say that this latter [[Limit of a function#Limit of a function of more than one variable|limit of a function of more than one variable]] is equal to a particular number ''L'' means that ''&amp;fnof;''(''x'',&amp;nbsp;''y'') can be made as close to ''L'' as desired by making the point (''x'',&amp;nbsp;''y'') close enough to the point&amp;nbsp;(''p'',&amp;nbsp;''q'').  It does not involve first taking one limit and then another.

==Counterexamples==

It is not in all cases true that

{{NumBlk|:|&lt;math&gt; \lim_{(x,y) \to (p, q)} f(x, y) = \lim_{x \to p} \lim_{y \to q} f(x, y) = \lim_{y \to q} \lim_{x \to p} f(x, y). &lt;/math&gt;|{{EquationRef|1}}}} 

Among the standard counterexamples are those in which

: &lt;math&gt;
f(x,y) = \frac{x^2}{x^2+y^2}
&lt;/math&gt;

and

: &lt;math&gt; f(x,y) = \frac{xy}{x^2+y^2},&lt;/math&gt;&lt;ref&gt;{{cite book|chapter=Chapter 15.2 Limits and Continuity|pages=907–909|title=Multivariable Calculus|year=2008|last1=Stewart|first1=James|authorlink1=James_Stewart_(mathematician)|edition=6th|isbn=0495011630}}&lt;/ref&gt;

and (''p'',&amp;nbsp;''q'')&amp;nbsp;=&amp;nbsp;(0,&amp;nbsp;0).

In the first example, the values of the two iterated limits differ from each other:

: &lt;math&gt;
\lim_{y\to0} \left( \lim_{x\to0} \frac{x^2}{x^2+y^2} \right) = \lim_{y\to0} 0 = 0,
&lt;/math&gt;

and

: &lt;math&gt;
\lim_{x\to0} \left( \lim_{y\to0} \frac{x^2}{x^2+y^2} \right) = \lim_{x\to0} 1 = 1.
&lt;/math&gt;

In the second example, the two iterated limits are equal to each other despite the fact that the limit as (''x'',&amp;nbsp;''y'')&amp;nbsp;→&amp;nbsp;(0,&amp;nbsp;0) does not exist:

: &lt;math&gt;
\lim_{x\to0} \left( \lim_{y\to0} \frac{xy}{x^2+y^2} \right) = \lim_{x\to0} 0 = 0
&lt;/math&gt;

and

: &lt;math&gt;
\lim_{y\to0} \left( \lim_{x\to0} \frac{xy}{x^2+y^2} \right) = \lim_{y\to0} 0 = 0,
&lt;/math&gt;

but the limit as (''x'',&amp;nbsp;''y'')&amp;nbsp;→&amp;nbsp;(0,&amp;nbsp;0) along the line ''y''&amp;nbsp;=&amp;nbsp;''x'' is different:

: &lt;math&gt;
\lim_{\Big((x,y)\to(0,0)\,:\,y=x\Big)} \frac{xy}{x^2+y^2} = \lim_{x\to0} \frac{x^2}{x^2+x^2} = \frac12.
&lt;/math&gt;

It follows that

: &lt;math&gt; \lim_{(x,y)\to(0,0)} \frac{xy}{x^2+y^2} &lt;/math&gt;

does not exist.

==Sufficient condition==
A sufficient condition for ({{EquationNote|1}}) to hold is ''Moore-Osgood theorem'': If &lt;math&gt;\lim_{x \to p} f(x, y)&lt;/math&gt; exists pointwise for each ''y'' different from ''q'' and if &lt;math&gt;\lim_{y \to q} f(x, y)&lt;/math&gt; [[converges uniformly]] for ''x''≠''p'' then the double limit and the iterated limits exist and are equal.&lt;ref&gt;{{cite book|last1=Taylor|first1=Angus E.|title=General Theory of Functions and Integration|date=2012|publisher=Dover Books on Mathematics Series|isbn=9780486152141|page=140}}&lt;/ref&gt;

==See also==
* [[Interchange of limiting operations]]

==References==
&lt;references /&gt;

[[Category:Limits (mathematics)]]</text>
      <sha1>9weijt6cn4x70ui7jslk9lap3ylpb8v</sha1>
    </revision>
  </page>
  <page>
    <title>Jeu de taquin</title>
    <ns>0</ns>
    <id>17053866</id>
    <revision>
      <id>823459120</id>
      <parentid>745680878</parentid>
      <timestamp>2018-02-01T11:18:32Z</timestamp>
      <contributor>
        <username>Adavidb</username>
        <id>2413055</id>
      </contributor>
      <minor/>
      <comment>clean up using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11320">In the [[mathematics|mathematical]] field of [[combinatorics]], '''jeu de taquin'''  is a construction due to {{harvs|txt|authorlink=Marcel-Paul Schützenberger|first=Marcel-Paul|last=Schützenberger|year=1977}} which defines an [[equivalence relation]] on the set of [[Young tableau#Skew tableaux|skew standard Young tableaux]]. A '''jeu de taquin slide''' is a transformation where the numbers in a tableau are moved around in a way similar to how the pieces in the [[fifteen puzzle]] move.  Two tableaux are '''jeu de taquin equivalent''' if one can be transformed into the other via a sequence of such slides.

"Jeu de taquin" (literally "teasing game") is  the [[:fr:Taquin|French name for the fifteen puzzle]].

== Definition of a jeu de taquin slide ==
[[Image:Jeu de taquin.svg|thumb|right|200px|Example of a Jeu de taquin slide]]

Given a skew standard Young tableau ''T'' of skew shape &lt;math&gt;\lambda / \mu&lt;/math&gt;, pick an adjacent empty cell ''c'' that can be added to the skew diagram &lt;math&gt;\lambda\setminus\mu&lt;/math&gt;; what this means is that ''c'' must share at least one edge with some cell in ''T'', and &lt;math&gt;\{c\} \cup \lambda\setminus\mu&lt;/math&gt; must also be a skew diagram. There are two kinds of slide, depending on whether ''c'' lies to the upper left of ''T'' or to the lower right. Suppose to begin with that ''c'' lies to the upper left. Slide the number from its neighbouring cell into ''c''; if ''c'' has neighbours both to its right and below, then pick the smallest of these two numbers. (This rule is designed so that the tableau property of having increasing rows and columns will be preserved.) If the cell that just has been emptied has no neighbour to its right or below, then the slide is completed. Otherwise, slide a number into that cell according to the same rule as before, and continue in this way until the slide is completed. After this transformation, the resulting tableau (with the now-empty cell removed) is still a skew (or possibly straight) standard Young tableau.

The other kind of slide, when ''c'' lies to the lower right of ''T'', just goes in the opposite direction. In this case, one slides numbers into an empty cell from the neighbour to its left or above, picking the larger number whenever there is a choice. The two types of slides are mutual inverses – a slide of one kind can be undone using a slide of the other kind.

The two slides described above are referred to as '''slides into the cell ''c'''''. The first kind of slide (when ''c'' lies to the upper left of ''T'') is said to be an '''inward slide'''; the second kind is referred to as an '''outward slide'''.

The word "slide" is synonymous to the French word "glissement", which is occasionally also used in English literature.

=== Subtleties ===

Jeu-de-taquin slides change not only the relative order of the entries of a tableau, but also its shape. In the definition given above, the result of a jeu-de-taquin slide is given as a skew diagram along with a skew standard tableau having it as shape. Often, it is better to work with skew shapes rather than skew diagrams. (Recall that every skew shape &lt;math&gt;\lambda / \mu&lt;/math&gt; gives rise to a skew diagram &lt;math&gt;\lambda \setminus \mu&lt;/math&gt;, but this is not an injective correspondence because, e. g., the distinct skew shapes &lt;math&gt;(2,1)/(2)&lt;/math&gt; and &lt;math&gt;(1,1)/(1)&lt;/math&gt; yield the same skew diagram.) For this reason, it is useful to modify the above definition of a jeu-de-taquin slide in such a way that, when given a skew shape along with a skew standard tableau and an addable cell as an input, it yields a well-defined skew ''shape'' along with a skew standard tableau at its output. This is done as follows: An inward slide of a skew tableau ''T'' of skew shape &lt;math&gt;\lambda / \mu&lt;/math&gt; into a cell ''c'' is defined as above when ''c'' is a corner of &lt;math&gt;\mu&lt;/math&gt; (that is, when &lt;math&gt;\mu \setminus \left\{c\right\}&lt;/math&gt; is a Young diagram), and the resulting skew shape is set to be &lt;math&gt;(\lambda \setminus \left\{d\right\}) / (\mu \setminus \left\{c\right\})&lt;/math&gt; where ''d'' is the empty cell at the end of the sliding procedure. An outward slide of a skew tableau ''T'' of skew shape &lt;math&gt;\lambda / \mu&lt;/math&gt; into a cell ''c'' is defined as above when ''c'' is a cocorner of &lt;math&gt;\lambda &lt;/math&gt; (that is, when &lt;math&gt;\lambda \cup \left\{c\right\}&lt;/math&gt; is a Young diagram), and the resulting skew shape is set to be &lt;math&gt;(\lambda \cup \left\{c\right\}) / (\mu \cup \left\{d\right\})&lt;/math&gt; where ''d'' is the empty cell at the end of the sliding procedure.

=== Generalization to skew semistandard tableaux ===

Jeu de taquin slides generalize to skew semistandard (as opposed to skew standard) tableaux and retain most of their properties in that generality. The only change that has to be made to the definition of an inward slide, in order for it to generalize, is a rule on how to proceed when the (temporarily) empty cell has neighbours below and to its right, and these neighbours are filled with equal numbers. In this situation, the neighbour ''below'' (not the one to the right) has to be slid into the empty cell. A similar change is needed in the definition of an outward slide (where one has to choose the neighbor above). These changes may seem arbitrary, but they actually make the "only reasonable choices"—meaning the only choices that keep the columns of the tableau (disregarding the empty cell) strictly increasing (as opposed to just weakly increasing).

== Rectification ==

Given a skew standard or skew semistandard tableau ''T'', one can iteratively apply inward slides to ''T'' until the tableau becomes straight-shape (which means no more inward slides are possible). This can generally be done in many different ways (one can freely choose into which cell to slide first), but the resulting straight-shape tableau is known to be the same for all possible choices. This tableau is called the '''rectification''' of ''T''.

== Jeu-de-taquin equivalence ==

Two skew semistandard tableaux ''T'' and ''S'' are said to be '''jeu-de-taquin equivalent''' if one can transform one of them into the other using a sequence (possibly empty) of slides (both inward and outward slides being allowed). Equivalently, two skew semistandard tableaux ''T'' and ''S'' are jeu-de-taquin equivalent if and only if they have the same rectification.

== Reading words and Knuth equivalence ==

There are various ways to associate a word (in the sense of combinatorics, i. e., a finite sequence of elements of an alphabet—here the set of positive integers) to every Young tableau. We choose the one apparently most popular: We associate to every Young tableau ''T'' the word obtained by concatenating the rows of ''T'' from the bottom row to the top row. (Each row of ''T'' is seen as a word simply by reading its entries from left to right, and we draw Young tableaux in English notation so that the longest row of a straight-shape tableau appears at the top.) This word will be referred to as the '''reading word''', or briefly as the '''word''', of ''T''.

It can then be shown that two skew semistandard tableaux ''T'' and ''S'' are jeu-de-taquin equivalent if and only if the reading words of ''T'' and ''S'' are [[Knuth equivalence|Knuth equivalent]]. As a consequence, the rectification of a skew semistandard tableau ''T'' can also be obtained as the insertion tableau of the reading word of ''T'' under the [[Robinson-Schensted correspondence]].

== The Schützenberger involution ==

Jeu de taquin can be used to define an operation on standard [[Young tableau]]x of any given shape, which turns out to be an [[Involution (mathematics)|involution]], although this is not obvious from the definition. One starts by emptying the square in the top-left corner, turning the tableau into a skew tableau with one less square. Now apply a jeu de taquin slide to turn that skew tableau into a straight one, which will free one square on the outside border. Then fill this square with the negative of the value that was originally removed at the top-left corner; this negated value is considered part of a new tableau rather than of the original tableau, and its position will not change in the sequel. Now as long as the original tableau has some entries left, repeat the operation of removing the entry ''x'' of the top-left corner, performing a jeu de taquin slide on what is left of the original tableau, and placing the value −''x'' into the square so freed. When all entries of the original tableau have been handled, their negated values are arranged in such a way that rows and columns are increasing. Finally one can add an appropriate constant to all entries to obtain a Young tableau with positive entries.

== Applications ==

Jeu de taquin is closely connected to such topics as the [[Robinson–Schensted–Knuth correspondence]], the [[Littlewood–Richardson rule]], and [[Knuth equivalence]].

== References ==
*{{eom|id=J/j110030|first=J.|last= Désarménien}}
*{{Citation
 | last = Sagan
 | first = Bruce E.
 | author-link =Bruce Sagan
 | year = 2001
 | title = The Symmetric Group: Representations, Combinatorial Algorithms, and Symmetric Functions
 | edition = 2nd
 | volume =
 | series = Graduate Texts in Mathematics 203
 | place = New York
 | publisher = Springer
 | pages =
 | page =
 | id =
 | isbn = 0-387-95067-2
 | doi =
 | oclc =
 | url =
 | accessdate =
}}
*{{Citation
 | last = Fulton
 | first = William
 | author-link = William Fulton (mathematician)
 | year = 1997
 | title = Young Tableaux
 | edition = 1st
 | volume =
 | series = London Mathematical Society Student Texts 35
 | place = Melbourne
 | publisher = Cambridge University Press
 | pages =
 | page =
 | id =
 | isbn = 0-521-56144-2
 | doi =
 | oclc =
 | url =
 | accessdate =
}}
*{{Cite journal | last1 = Haiman | first1 = M. D. | doi = 10.1016/0012-365X(92)90368-P | title = Dual equivalence with applications, including a conjecture of Proctor | journal = Discrete Mathematics | volume = 99 | pages = 79–113 | year = 1992 | pmid =  | pmc = }}
*{{Citation
 | last = Schützenberger
 | first = Marcel-Paul
 | author-link = Marcel-Paul Schützenberger
 | year = 1977
 | contribution-url =
 | editor-last = Foata
 | editor-first = Dominique
 | editor-link =
 | editor2-last =
 | editor2-first =
 | editor2-link =
 | title = Combinatoire et représentation du groupe symétrique (Actes Table Ronde CNRS, Univ. Louis-Pasteur Strasbourg, Strasbourg, 1976)
 | edition =
 | series = Lecture Notes in Math. 
 | place = Berlin
 | publisher = Springer
 | volume =  579
 | pages = 59–113
 | id =
 | isbn =978-3-540-08143-2
 | doi =10.1007/BFb0090012
 | oclc =
 | url = http://www-igm.univ-mlv.fr/~berstel/Mps/Travaux/A/1977-4CorrespRobinsonStrasbourg.pdf
 | chapter = La correspondance de Robinson
}}

*{{Citation
 | last = Stanley
 | first = Richard P.
 | author-link = Richard P. Stanley
 | year = 1999
 | title = Enumerative Combinatorics
 | edition =
 | volume = 2
 | series = Cambridge Studies in Advanced Mathematics 62
 | publication-place =
 | place =
 | publisher = Cambridge University Press
 | pages =
 | page =
 | id =
 | isbn = 0-521-56069-1
 | doi =
 | oclc =
 | url = http://www-math.mit.edu/~rstan/ec/
 | accessdate =
}}

[[Category:Combinatorial algorithms]]
[[Category:Algebraic combinatorics]]</text>
      <sha1>sk1i1jxa4qljhuz5wmyzzxrw2287v3g</sha1>
    </revision>
  </page>
  <page>
    <title>Jónsson term</title>
    <ns>0</ns>
    <id>54457435</id>
    <revision>
      <id>788867786</id>
      <parentid>788867783</parentid>
      <timestamp>2017-07-03T23:52:09Z</timestamp>
      <contributor>
        <username>Joe Decker</username>
        <id>204282</id>
      </contributor>
      <comment>Cleaning up accepted [[Wikipedia:Articles for creation|Articles for creation]] submission ([[WP:AFCH|AFCH]] 0.9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="956">In [[universal algebra]], within [[mathematics]], a '''Jónsson term''' or '''majority term''' is a [[term (logic)|term]] ''t'' with exactly three [[free variable]]s that satisfies the [[equation]]s ''t''(''x'', ''x'', ''y'') = ''t''(''x'', ''y'', ''x'') = ''t''(''y'', ''x'', ''x'') = ''x''.&lt;ref&gt;R. Padmanabhan, Axioms for Lattices and Boolean Algebras,
  World Scientific Publishing Company (2008)&lt;/ref&gt;&lt;ref&gt;Clifford Bergman, Universal Algebra: Fundamentals and Selected Topics, Taylor &amp; Francis (2011)&lt;/ref&gt;

For example for [[lattice (order)|lattice]]s, the term (''x'' ∧ ''y'') ∨ (''y'' ∧ ''z'') ∨ (''z'' ∧ ''x'') is a Jónsson term.

Jónsson terms are named after the Icelandic [[logician]] [[Bjarni Jónsson]].

== References ==
&lt;!-- Inline citations added to your article will automatically display here. See https://en.wikipedia.org/wiki/WP:REFB for instructions on how to add citations. --&gt;
{{reflist}}

[[Category:Mathematical logic]]</text>
      <sha1>41u1q8pa8k790o867wu94whvphlvh9s</sha1>
    </revision>
  </page>
  <page>
    <title>Kappa calculus</title>
    <ns>0</ns>
    <id>33498023</id>
    <revision>
      <id>871742213</id>
      <parentid>871731449</parentid>
      <timestamp>2018-12-03T03:52:24Z</timestamp>
      <contributor>
        <username>Cedar101</username>
        <id>374440</id>
      </contributor>
      <minor/>
      <comment>/* Variants */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13145">In [[mathematical logic]], [[category theory]], and
[[computer science]], '''kappa calculus''' is a
[[formal system]] for defining [[First order functions|first-order]]
[[function (mathematics)|functions]].

Unlike [[lambda calculus]], kappa calculus has no
[[higher-order function]]s; its functions are
not [[First-class object|first class objects]].  Kappa-calculus can be
regarded as "a reformulation of the first-order fragment of typed
lambda calculus".&lt;ref name="Hasegawa"/&gt;

Because its functions are not first-class objects, evaluation of kappa
calculus expressions does not require
[[Closure (computer science)|closures]].

== Definition ==

''The definition below has been adapted from the diagrams on pages 205
and 207 of Hasegawa.''&lt;ref name="Hasegawa"/&gt;

=== Grammar ===

Kappa calculus consists of ''types'' and ''expressions,'' given by the
grammar below:

:&lt;math&gt;
\tau =
1 \mid
\tau\times\tau \mid
\ldots
&lt;/math&gt;

:&lt;math&gt;
e =
x                          \mid
id_\tau                    \mid
!_\tau                     \mid
\operatorname{lift}_\tau(e)               \mid
e \circ e                  \mid
\kappa x:1{\to}\tau . e
&lt;/math&gt;

In other words,

* 1 is a type
* If &lt;math&gt;\tau_1&lt;/math&gt; and &lt;math&gt;\tau_2&lt;/math&gt; are types then &lt;math&gt;\tau_1\times\tau_2&lt;/math&gt; is a type.
* Every variable is an expression
* If {{mvar|&amp;tau;}} is a type then &lt;math&gt;id_\tau&lt;/math&gt; is an expression
* If {{mvar|&amp;tau;}} is a type then &lt;math&gt;!_\tau&lt;/math&gt; is an expression
* If {{mvar|&amp;tau;}} is a type and e is an expression then &lt;math&gt;\operatorname{lift}_\tau(e)&lt;/math&gt; is an expression
* If &lt;math&gt;e_1&lt;/math&gt; and &lt;math&gt;e_2&lt;/math&gt; are expressions then &lt;math&gt;e_1\circ e_2&lt;/math&gt; is an expression
* If x is a variable, {{mvar|&amp;tau;}} is a type, and e is an expression, then &lt;math&gt;\kappa x{:}1{\to}\tau\;.\;e&lt;/math&gt; is an expression

The &lt;math&gt;:1{\to}\tau&lt;/math&gt; and the subscripts of {{math|id}}, {{math|!}}, and &lt;math&gt;\operatorname{lift}&lt;/math&gt; are
sometimes omitted when they can be unambiguously determined from the
context.

Juxtaposition is often used as an abbreviation for a combination of
&lt;math&gt;\operatorname{lift}&lt;/math&gt; and composition:

:&lt;math&gt;
e_1 e_2\ \overset\operatorname{def}{=}\ e_1 \circ \operatorname{lift}(e_2)
&lt;/math&gt;

=== Typing rules ===

''The presentation here uses sequents (&lt;math&gt;\Gamma\vdash e:\tau&lt;/math&gt;) rather than hypothetical judgments in order to ease comparison with the simply typed lambda calculus.  This requires the additional Var rule, which does not appear in Hasegawa''&lt;ref name="Hasegawa"/&gt;

In kappa calculus an expression has two types: the type of its ''source'' and the type of its ''target''.  The notation &lt;math&gt;e:\tau_1{\to}\tau_2&lt;/math&gt; is used to indicate that expression e has source type &lt;math&gt;{\tau_1}&lt;/math&gt; and target type &lt;math&gt;{\tau_2}&lt;/math&gt;.

Expressions in kappa calculus are assigned types according to the following rules:

:{| cellpadding="9" {{ts|ac}}
|&lt;math&gt;{x{:}1{\to}\tau\;\in\;\Gamma}\over{\Gamma \vdash x : 1{\to}\tau }&lt;/math&gt; || (Var)
|-
|&lt;math&gt;{}\over{\vdash id_\tau\;:\;\tau\to\tau }&lt;/math&gt; || (Id)
|-
|&lt;math&gt;{}\over{\vdash !_\tau\;:\;\tau\to 1 }&lt;/math&gt; || (Bang)
|-
|&lt;math&gt;{\Gamma \vdash e_1{:}\tau_1{\to}\tau_2
       \;\;\;\;\;\;
       \Gamma \vdash e_2{:}\tau_2{\to}\tau_3
      }\over{\Gamma \vdash e_2\circ e_1 : \tau_1{\to}\tau_3 }&lt;/math&gt; || (Comp)
|-
|&lt;math&gt;{\Gamma \vdash e{:}1{\to}\tau_1}
      \over
      {\Gamma \vdash \operatorname{lift}_{\tau_2}(e)\;:\;\tau_2\to(\tau_1\times\tau_2) }
&lt;/math&gt;
| (Lift)
|-
|&lt;math&gt;{\Gamma,\;x{:}1{\to}\tau_1\;\vdash\;e:\tau_2{\to}\tau_3}
      \over
      {\Gamma \vdash \kappa x{:}1{\to}\tau_1\,.\,e\;:\;\tau_1\times\tau_2\to\tau_3 }
&lt;/math&gt;
|(Kappa)
|}

In other words,

* '''Var:''' assuming &lt;math&gt;x:1{\to}\tau&lt;/math&gt; lets you conclude that &lt;math&gt;x:1{\to}\tau&lt;/math&gt;
* '''Id:''' for any type {{mvar|&amp;tau;}}, &lt;math&gt;id_\tau:\tau{\to}\tau&lt;/math&gt;
* '''Bang:''' for any type {{mvar|&amp;tau;}}, &lt;math&gt;!_\tau:\tau{\to}1&lt;/math&gt;
* '''Comp:''' if the target type of &lt;math&gt;e_1&lt;/math&gt; matches the source type of &lt;math&gt;e_2&lt;/math&gt; they may be composed to form an expression &lt;math&gt;e_2\circ e_1&lt;/math&gt; with the source type of &lt;math&gt;e_1&lt;/math&gt; and target type of &lt;math&gt;e_2&lt;/math&gt;
* '''Lift:''' if &lt;math&gt;e:1{\to}\tau_1&lt;/math&gt;, then &lt;math&gt;\operatorname{lift}_{\tau_2}(e):\tau_2{\to}(\tau_1\times\tau_2)&lt;/math&gt;
* '''Kappa:''' if we can conclude that &lt;math&gt;e:\tau_2\to\tau_3&lt;/math&gt; under the assumption that &lt;math&gt;x:1{\to}\tau_1&lt;/math&gt;, then we may conclude ''without that assumption'' that &lt;math&gt;\kappa x{:}1{\to}\tau_1\,.\,e\;:\;\tau_1\times\tau_2\to\tau_3&lt;/math&gt;

=== Equalities ===

Kappa calculus obeys the following equalities:

* '''Neutrality:''' If &lt;math&gt;f:\tau_1{\to}\tau_2&lt;/math&gt; then &lt;math&gt;f{\circ}id_{\tau_1}=f&lt;/math&gt; and &lt;math&gt;f=id_{\tau_2}{\circ}f&lt;/math&gt;
* '''Associativity:''' If &lt;math&gt;f:\tau_1{\to}\tau_2&lt;/math&gt;, &lt;math&gt;g:\tau_2{\to}\tau_3&lt;/math&gt;, and &lt;math&gt;h:\tau_3{\to}\tau_4&lt;/math&gt;, then &lt;math&gt;(h{\circ}g){\circ}f = h{\circ}(g{\circ}f)&lt;/math&gt;.
* '''Terminality:''' If &lt;math&gt;f{:}\tau{\to}1&lt;/math&gt; and &lt;math&gt;g{:}\tau{\to}1&lt;/math&gt; then &lt;math&gt;f=g&lt;/math&gt;
* '''Lift-Reduction:''' &lt;math&gt;(\kappa x.f)\circ \operatorname{lift}_\tau(c) = f[c/x]&lt;/math&gt;
* '''Kappa-Reduction:''' &lt;math&gt;\kappa x. (h\circ \operatorname{lift}_\tau(x)) = h&lt;/math&gt; if x is not free in h

The last two equalities are reduction rules for the calculus,
rewriting from left to right.

== Properties ==

The type {{val|1}} can be regarded as the [[unit type]].  Because of this, any two functions whose argument type is the same and whose result type is {{val|1}} should be equal – since there is only a single value of type {{val|1}} both functions must return that value for every argument ('''Terminality''').

Expressions with type &lt;math&gt;1{\to}\tau&lt;/math&gt; can be regarded as "constants" or values of "ground type"; this is because {{val|1}} is the unit type, and so a function from this type is necessarily a constant function.  Note that the kappa rule allows abstractions only when the variable being abstracted has the type &lt;math&gt;1{\to}\tau&lt;/math&gt; for some {{mvar|&amp;tau;}}.  This is the basic mechanism which ensures that all functions are first-order.

== Categorical semantics ==

Kappa calculus is intended to be the internal language of
''contextually complete'' categories.

== Examples ==

Expressions with multiple arguments have source types which are
"right-imbalanced" binary trees.  For example, a function f with three
arguments of types A, B, and C and result type D will have type

: &lt;math&gt;
  f : A\times (B\times (C\times 1)) \to D
&lt;/math&gt;

If we define left-associative juxtaposition &lt;math&gt;f\;c&lt;/math&gt; as an abbreviation
for &lt;math&gt;(f\circ \operatorname{lift}(c))&lt;/math&gt;, then – assuming that
&lt;math&gt;a:1{\to}A&lt;/math&gt;, &lt;math&gt;b:1{\to}B&lt;/math&gt;, and
&lt;math&gt;c:1{\to}C&lt;/math&gt; &amp;ndash; we can apply this function:

: &lt;math&gt;
  f\;a\;b\;c\;:\;1 \to D
&lt;/math&gt;

Since the expression &lt;math&gt;f\;a\;b\;c&lt;/math&gt; has source type {{val|1}}, it is a "ground value" and may be passed as an argument to another function. If &lt;math&gt;g:(D\times E){\to}F&lt;/math&gt;, then

: &lt;math&gt;
  g\;(f\;a\;b\;c)\;:\;E \to F
&lt;/math&gt;

Much like a curried function of type
&lt;math&gt;A{\to}(B{\to}(C{\to}D))&lt;/math&gt; in lambda calculus, partial
application is possible:

: &lt;math&gt;
  f\;a\;:\;B\times (C\times 1) \to D
&lt;/math&gt;

However no higher types (i.e. &lt;math&gt;(\tau{\to}\tau){\to}\tau&lt;/math&gt;) are involved.  Note that because the source type of {{mvar|f a}} is not {{val|1}}, the following expression cannot be well-typed under the assumptions mentioned so far:

: &lt;math&gt;
  h\;(f\;a)
&lt;/math&gt;

Because successive application is used for multiple
arguments it is not necessary to know the [[arity]] of a function in
order to determine its typing; for example, if we know that
&lt;math&gt;c:1{\to}C&lt;/math&gt; then the expression

: {{mvar
|  j c
}}

is well-typed as long as {{mvar|j}} has type
: &lt;math&gt;(C\times\alpha){\to}\beta&lt;/math&gt; for some {{mvar|&amp;alpha;}}
and {{mvar|&amp;beta;}}.  This property is important when calculating
the [[principal type]] of an expression, something
which can be difficult when attempting to exclude higher-order
functions from typed lambda calculi by restricting the grammar of types.

== History ==

Barendregt originally introduced&lt;ref name="Barendregt"/&gt; the term
"functional completeness" in the context of combinatory algebra.
Kappa calculus arose out of efforts by Lambek&lt;ref
name="Lambek"/&gt; to formulate an appropriate analogue of functional
completeness for arbitrary categories (see Hermida and Jacobs,&lt;ref
name=HermidaJacobs/&gt; section 1).  Hasegawa later developed kappa
calculus into a usable (though simple) programming language including
arithmetic over natural numbers and primitive recursion.&lt;ref
name="Hasegawa"/&gt;  Connections to [[Arrow (computer science)|arrows]]
were later investigated&lt;ref name="closed"/&gt; by Power, Thielecke, and others.

== Variants ==

It is possible to explore versions of kappa calculus with
[[Substructural logic|substructural types]] such as [[Linear type system|linear]], [[Affine logic|affine]],
and [[Noncommutative logic|ordered]] types.  These extensions require eliminating or
restricting the &lt;math&gt;!_\tau&lt;/math&gt; expression.  In such circumstances
the {{math|&amp;times;}} type operator is not a true cartesian product,
and is generally written {{math|&amp;otimes;}} to make this clear.

== References ==

&lt;references&gt;
&lt;ref name="Lambek"&gt;
{{cite journal
 | author-last = Lambek
 | author-first = Joachim
 | author-link = Joachim Lambek
 | date = August 1, 1973
 | title = Functional completeness of cartesian categories
 | url = http://www.sciencedirect.com/science/article/pii/0003484374900035
 | journal = Annals of Mathematical Logic
 | location = Amsterdam, North Holland
 | publisher = North-Holland Publishing Company
 | publication-date = March 1974
 | volume = 6
 | issue = 3-4
 | pages = 259–292
 | doi = 10.1016/0003-4843(74)90003-5
 | id =
 | issn = 0003-4843
 | layurl = http://mathoverflow.net/questions/37180
 | laysource = "Adam" answering "What are {{mvar|&amp;kappa;}}-categories?" on MathOverflow
 | laydate = August 31, 2010}}
&lt;/ref&gt;
&lt;ref name="HermidaJacobs"&gt;
{{cite journal
 | author1-last = Hermida
 | author1-first = Claudio
 | author2-last = Jacobs
 | author2-first = Bart
 | date = December 1995
 | title = Fibrations with indeterminates: contextual and functional completeness for polymorphic lambda calculi
 | url = http://journals.cambridge.org/article_S0960129500001213
 | journal = Mathematical Structures in Computer Science
 | location = Cambridge, England
 | publisher = Cambridge University Press
 | volume = 5
 | issue = 4
 | pages = 501–531
 | doi = 10.1017/S0960129500001213
 | id =
 | issn = 1469-8072}}
&lt;/ref&gt;
&lt;ref name="Barendregt"&gt;
{{cite journal
  | author-last =
  | author-first =
  | author-link =
  | date = October 1, 1984
  | editor-last = Barendregt
  | editor-first = Hendrik Pieter
  | title = The Lambda Calculus: Its Syntax and Semantics
  | url = https://www.elsevier.com/books/the-lambda-calculus/barendregt/978-0-444-87508-2
  | series = Studies in Logic and the Foundations of Mathematics
  | edition = Revised
  | location = Amsterdam, North Holland
  | publisher = Elsevier Science
  | volume = 103
  | doi =
  | id =
  | isbn = 0-444-87508-5}}
&lt;/ref&gt;
&lt;ref name="Hasegawa"&gt;
{{cite journal
 | author-last = Hasegawa
 | author-first = Masahito
 | year = 1995
 | editor1-last = Pitt
 | editor1-first = David
 | editor2-last = Rydeheard
 | editor2-first = David E.
 | editor3-last = Johnstone
 | editor3-first = Peter
 | editor3-link = Peter Johnstone (mathematician)
 | title = Decomposing typed lambda calculus into a couple of categorical programming languages
 | url = https://link.springer.com/chapter/10.1007%2F3-540-60164-3_28
 | journal = Category Theory and Computer Science: 6th International Conference, CTCS '95 Cambridge, United Kingdom, August 7–11, 1995 Proceedings
 | series = Lecture Notes in Computer Science
 | publisher = Springer-Verlag Berlin Heidelberg
 | volume = 953
 | pages = 200–219
 | doi = 10.1007/3-540-60164-3_28
 | id =
 | isbn = 978-3-540-60164-7
 | issn = 0302-9743
 | layurl = http://mathoverflow.net/questions/37180
 | laysource = "Adam" answering "What are {{mvar|&amp;kappa;}}-categories?" on MathOverflow
 | laydate = August 31, 2010}}
&lt;/ref&gt;
&lt;ref name="closed"&gt;
{{cite journal
 | author1-last = Power
 | author1-first = John
 | author2-last = Thielecke
 | author2-first = Hayo
 | year = 1999
 | editor1-last = Wiedermann
 | editor1-first = Jiří
 | editor2-last = van Emde Boas
 | editor2-first = Peter
 | editor2-link = Peter van Emde Boas
 | editor3-last = Nielsen
 | editor3-first = Mogens
 | title = Closed Freyd- and {{mvar|&amp;kappa;}}-Categories
 | url = https://link.springer.com/chapter/10.1007%2F3-540-48523-6_59
 | journal = Automata, Languages and Programming: 26th International Colloquium, ICALP’99 Prague, Czech Republic, July 11–15, 1999 Proceedings
 | series = Lecture Notes in Computer Science
 | publisher = Springer-Verlag Berlin Heidelberg
 | volume = 1644
 | pages = 625–634
 | doi = 10.1007/3-540-48523-6_59
 | id =
 | isbn = 978-3-540-66224-2
 | issn = 0302-9743}}
&lt;/ref&gt;
&lt;/references&gt;

[[Category:Logical calculi]]</text>
      <sha1>713yxmarohih7ys4eczuqgm8n81eyqc</sha1>
    </revision>
  </page>
  <page>
    <title>Klee–Minty cube</title>
    <ns>0</ns>
    <id>31302509</id>
    <revision>
      <id>824793720</id>
      <parentid>785204343</parentid>
      <timestamp>2018-02-09T14:57:06Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed grandparent category of [[Category:Linear programming]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14350">[[File:Unitcube.svg|thumb|right|alt=A three-dimensional cube|The '''Klee–Minty cube''' is a perturbation of the [[unit cube|cube]] shown here. Many linear optimization algorithms behave poorly on the Klee–Minty cube. On the three-dimensional version, the [[simplex method|simplex algorithm]] and the [[criss-cross algorithm]] visit all 8 corners in the worst case.]]
The '''Klee–Minty cube''' or '''Klee–Minty polytope''' (named after [[Victor Klee]] and {{ill|George J. Minty|de|George Minty}}) is a [[unit cube|unit]] [[hypercube]] of variable [[dimension]] whose corners have been perturbed. Klee and Minty demonstrated that [[George Dantzig]]'s [[simplex algorithm]] has poor worst-case performance when initialized at one corner of their "squashed cube".

In particular, many optimization [[algorithm]]s for [[linear programming|linear optimization]] exhibit poor performance when applied to the Klee–Minty cube. In 1973 Klee and Minty showed that Dantzig's [[simplex algorithm]] was not a [[polynomial-time algorithm]] when applied to their cube.&lt;ref name="KleeMinty"&gt;{{harvtxt|Klee|Minty|1972}}&lt;/ref&gt; Later, modifications of the Klee–Minty cube have shown poor behavior both for other [[matroid|basis]]-[[exchange algorithm|exchange]] pivoting algorithms and also for interior-point algorithms{{Citation needed|date=October 2015}}.

== Description of the cube ==

The Klee–Minty cube was originally specified with a parameterized system of linear inequalities, with the dimension as the parameter. When the dimension is two, the "cube" is a squashed square. When the dimension is three, the "cube" is a squashed cube. Illustrations of the "cube" have appeared besides algebraic descriptions.&lt;ref name="DNT08" /&gt;&lt;ref name="GZ94" /&gt;

The Klee–Minty polytope is given by&lt;ref&gt;Greenberg, Harvey J., ''Klee-Minty Polytope Shows Exponential Time Complexity of Simplex Method'' University of Colorado at Denver (1997) [http://glossary.computing.society.informs.org/notes/Klee-Minty.pdf PDF download]&lt;/ref&gt;

:&lt;math&gt;
\begin{align}
x_1\le 5\\
4x_1+x_2 \le 25\\
8x_1+4x_2+x_3 \le 125 \\
 \vdots\\
2^Dx_1+2^{D-1}x_2+ \dots +4x_{D-1}+x_D \le 5^D \\
x_1\ge0, \, \, \dots , \, \, x_D \ge0.
\end{align}
&lt;/math&gt;

This has ''D'' variables, ''D'' constraints other than the ''D'' non-negativity constraints, and 2&lt;sup&gt;''D''&lt;/sup&gt; vertices, just as a ''D''-dimensional [[hypercube]] does. If the objective function to be maximized is
:&lt;math&gt;2^{D-1}x_1+2^{D-2}x_2+ \dots + 2x_{D-1}+x_D,&lt;/math&gt;

and if the initial vertex for the simplex algorithm is the origin, then the algorithm as formulated by Dantzig visits all 2&lt;sup&gt;''D''&lt;/sup&gt; vertices, finally reaching the optimal vertex &lt;math&gt;(0, 0, \dots , 5^D).&lt;/math&gt;

== Computational complexity ==
The Klee–Minty cube has been used to analyze the performance of many algorithms, both in the worst case and on average. The [[time complexity]] of an [[algorithm]] counts the number of [[arithmetic operation]]s sufficient for the algorithm to solve the problem. For example, [[Gaussian elimination]] requires on the [[Big oh|order&amp;nbsp;of]]''&amp;nbsp;D''&lt;sup&gt;3&lt;/sup&gt; operations, and so it is said to have polynomial time-complexity, because its complexity is bounded by a [[cubic polynomial]]. There are examples of algorithms that do not have polynomial-time complexity. For example, a generalization of Gaussian elimination called [[Buchberger's algorithm]] has for its complexity an &lt;!--doubly --&gt; exponential function of the problem data (the [[degree of a polynomial|degree of the polynomials]] and the number of variables of the [[multivariate polynomial]]s). Because exponential functions eventually grow much faster than polynomial functions, an&lt;!-- attained rather than upper bound --&gt; exponential complexity implies that an algorithm has slow performance on large problems.

=== Worst case ===
[[File:Simplex description.png|thumb|240px|An illustration of a three-dimensional [[polytope]] which is the feasible region for a linear programming problem. The simplex algorithm traverses the edges between [[vertex (geometry)|vertices]] until it reaches an optimal vertex. In the case shown, the simplex algorithm takes five steps. However, the simplex algorithm visits every vertex in the worst case of a problem whose feasible region is the Klee–Minty cube, so the number of steps rises exponentially with the dimension of the problem.]]
In mathematical optimization, the Klee–Minty cube is an example that shows the [[worst-case complexity|worst-case]] [[Analysis of algorithms|computational]] [[time complexity|complexity]] of many [[algorithm]]s of [[linear optimization]]. It is a deformed [[unit cube|cube]] with exactly &amp;nbsp;2&lt;sup&gt;''D''&lt;/sup&gt;&amp;nbsp;corners in [[dimension (vector space)|dimension]]&amp;nbsp;''D''. Klee and Minty showed that [[George Dantzig|Dantzig's]] [[simplex algorithm]] visits all corners of a (perturbed) [[unit cube|cube]] in dimension&amp;nbsp;''D'' in the [[worst-case complexity|worst case]].&lt;ref name="KleeMinty" /&gt;&lt;ref name="MurtyComplexity"&gt;{{harvtxt|Murty|1983|loc=14.2 Worst-case computational complexity, pp. 434–437}}&lt;/ref&gt;&lt;ref name="TerlakyZhong"&gt;{{harvtxt|Terlaky|Zhang|1993}}&lt;/ref&gt;

Modifications of the Klee–Minty construction showed similar exponential [[time complexity]] for other pivoting rules of simplex type, which maintain primal feasibility, such as [[Bland's rule]].&lt;ref name="Bland"&gt;{{cite journal|title=New finite pivoting rules for the simplex method|first=Robert G.|last=Bland|journal=Mathematics of Operations Research|volume=2|number=2|date=May 1977|pages=103–107|doi=10.1287/moor.2.2.103|jstor=3689647|mr=459599|ref=harv}}&lt;/ref&gt;&lt;ref name="MurtyBland"&gt;{{harvtxt|Murty|1983|loc=Chapter&amp;nbsp;10.5, pp.&amp;nbsp;331–333; problem&amp;nbsp;14.8,  p.&amp;nbsp;439}} describes [[Bland's rule]].&lt;/ref&gt;&lt;ref name="MurtyBlandComplexity"&gt;{{harvtxt|Murty|1983|loc=Problem&amp;nbsp;14.3, p.&amp;nbsp;438; problem&amp;nbsp;14.8,  p.&amp;nbsp;439}} describes the worst-case complexity of Bland's rule.&lt;/ref&gt; Another modification showed that the [[criss-cross algorithm]], which does not maintain primal feasibility,  also visits all the corners of a modified Klee–Minty cube.&lt;ref name="TerlakyZhong" /&gt;&lt;ref name="Roos"&gt;{{harvtxt|Roos|1990}}&lt;/ref&gt;&lt;ref name="FukudaTerlaky"&gt;{{harvtxt|Fukuda|Terlaky|1997}}&lt;/ref&gt; Like the simplex algorithm, the criss-cross algorithm visits all&amp;nbsp;8 corners of the three-dimensional cube in the worst case.

==== Path-following algorithms ====
Further modifications of the Klee–Minty cube have shown poor performance of [[Central path|central-path]][[interior-point method|–following algorithms]] for linear optimization, in that the central path comes arbitrarily close to each of the corners of a cube. This "vertex-stalking" performance is surprising, because such path-following algorithms have polynomial-time complexity for linear optimization.&lt;ref name="DNT08"&gt;{{harvtxt|Deza|Nematollahi|Terlaky|2008}}&lt;/ref&gt;&lt;ref name="ShubMegiddo"&gt;{{harvtxt|Megiddo|Shub|1989}}&lt;/ref&gt;

=== Average case ===
The Klee–Minty cube has also inspired research on [[average-case complexity]]. When eligible pivots are made randomly (and not by the rule of steepest descent), Dantzig's simplex algorithm needs [[expected value|on average]] [[quadratic polynomial|quadratically]] many steps ([[Big Oh|on the order of]] O(''D''&lt;sup&gt;2&lt;/sup&gt;).&lt;ref name="GZ94"&gt;{{harvtxt|Gartner|Ziegler|1994}}&lt;/ref&gt;
Standard variants of the simplex algorithm takes on average&amp;nbsp;''D'' steps for a cube.&lt;ref&gt;More generally, for the simplex algorithm, the expected number of steps is  proportional to&amp;nbsp;''D'' for linear-programming problems that are randomly drawn from the [[Euclidean metric|Euclidean]] [[unit&amp;nbsp;sphere]], as proved by Borgwardt and by [[Stephen Smale|Smale]].&lt;p&gt;{{harvtxt|Borgwardt|1987}}: {{cite book|last=Borgwardt|first=Karl-Heinz|title=The simplex method: A probabilistic analysis|series=Algorithms and Combinatorics (Study and Research Texts)|volume=1|publisher=Springer-Verlag|location=Berlin|year=1987|pages=xii+268|isbn=3-540-17096-0|mr=868467|ref=harv}}&lt;/ref&gt; When it is initialized at a random corner of the cube, the criss-cross algorithm visits only&amp;nbsp;''D'' additional corners, however, according to a&amp;nbsp;1994 paper by Fukuda and Namiki.&lt;ref name="FukudaNamiki"&gt;{{harvtxt|Fukuda|Namiki|1994|p=367}}&lt;/ref&gt;&lt;ref name="FTNamiki"&gt;{{harvtxt|Fukuda|Terlaky|1997|p=385}}&lt;/ref&gt;  Both the simplex algorithm and the criss-cross algorithm visit exactly&amp;nbsp;3 additional corners of the three-dimensional cube on&amp;nbsp;average.

== See also ==
* [[Karmarkar's algorithm|Projective algorithm of Karmarkar]]
* [[Ellipsoidal method|Ellipsoidal algorithm of Khachiyan]]

== Notes ==
&lt;references /&gt;

== References ==
* {{cite journal|last1=Deza|first1=Antoine|last2=Nematollahi|first2=Eissa
|last3=Terlaky|first3=Tamás
|title=How good are interior point methods? Klee–Minty cubes tighten iteration-complexity bounds
|journal=Mathematical Programming|date=May 2008|pages=1–14|volume=113|number=1
|doi=10.1007/s10107-006-0044-x|mr=2367063|ref=harv}}
* {{cite journal|last1=Fukuda|first1=Komei|authorlink1=Komei Fukuda|last2=Namiki|first2=Makoto|title=On extremal behaviors of Murty's least index method|journal=Mathematical Programming|date=March 1994|pages=365–370|volume=64|number=1|doi=10.1007/BF01582581|ref=harv|mr=1286455}}
* {{cite journal|first1=Komei|last1=Fukuda|authorlink1=Komei Fukuda|first2=Tamás|last2=Terlaky|authorlink2=Tamás Terlaky|title=Criss-cross methods: A fresh view on pivot algorithms |doi=10.1007/BF02614325|journal=Mathematical Programming: Series&amp;nbsp;B |volume=79 |pages=369–395 |issue=Papers from the&amp;nbsp;16th International Symposium on Mathematical Programming held in Lausanne,&amp;nbsp;1997 |editors=Thomas&amp;nbsp;M. Liebling and Dominique de&amp;nbsp;Werra |publisher=North-Holland Publishing&amp;nbsp;Co., number 1—3 |location=Amsterdam|year=1997|mr=1464775|ref=harv|id=[http://www.cas.mcmaster.ca/~terlaky/files/crisscross.ps Postscript preprint]}}
* {{cite journal|first1=B.|last1=Gartner|first2=G. M.|last2=Ziegler|authorlink2=Günter M. Ziegler|title=Randomized simplex algorithms on Klee-Minty cubes|journal=Foundations of Computer Science, Annual IEEE Symposium on|pages=502–510|issue=35th Annual Symposium on Foundations of Computer Science (FOCS 1994)|year=1994|publisher=IEEE|url=http://doi.ieeecomputersociety.org/10.1109/SFCS.1994.365741|doi=10.1109/SFCS.1994.365741|ref=harv}}
* {{cite book|title=Inequalities&amp;nbsp;III (Proceedings of the Third Symposium on Inequalities held at the University of California, Los Angeles, Calif., September&amp;nbsp;1–9,&amp;nbsp;1969, dedicated to the memory of Theodore&amp;nbsp;S. Motzkin)|editor-first=Oved|editor-last=Shisha|publisher=Academic Press|location=New York-London|year=1972|mr=332165|last1=Klee|first1=Victor|authorlink1=Victor Klee|last2=Minty|first2= George&amp;nbsp;J.|authorlink2=George J. Minty|chapter=How good is the simplex algorithm?|pages=159–175|ref=harv}}
* {{cite journal|title=Boundary Behavior of Interior Point Algorithms in Linear Programming|first1=Nimrod|last1=Megiddo|authorlink1=Nimrod Megiddo|first2=Michael|last2=Shub|authorlink2=Michael Shub|journal=Mathematics of Operations Research|volume=14|number=1|date=February 1989|pages=97–146 |jstor=3689840|mr=984561|ref=harv|doi=10.1287/moor.14.1.97}}
* {{cite book|last=Murty|first=Katta&amp;nbsp;G.|authorlink=Katta G. Murty|title=Linear programming|publisher=John Wiley &amp; Sons|location=New York|year=1983|pages=xix+482|isbn=0-471-09725-X|mr=720547|ref=harv}}
* {{cite journal|last=Roos|first=C.|title=An exponential example for Terlaky's pivoting rule for the criss-cross simplex method|journal=Mathematical Programming|volume=46|year=1990|number=1|series=Series&amp;nbsp;A| pages= 79–84|doi=10.1007/BF01585729|mr=1045573|ref=harv}}
* {{cite journal|last1=Terlaky|first1=Tamás|last2=Zhang|first2=Shu&amp;nbsp;Zhong|title=Pivot rules for linear programming: A Survey on recent theoretical developments|issue=Degeneracy in optimization problems; number 1 |journal=Annals of Operations Research|volume=46–47|year=1993|pages=203–233|doi=10.1007/BF02096264|mr=1260019|citeseerx = 10.1.1.36.7658 |publisher=Springer Netherlands|issn=0254-5330|ref=harv}}

== External links ==

=== Algebraic description with illustration ===
The first two links have both an algebraic construction and a picture of a three-dimensional  Klee–Minty cube:
* {{cite journal|last1=Deza|first1=Antoine|last2=Nematollahi|first2=Eissa
|last3=Terlaky|first3=Tamás|title=How good are interior point methods? Klee–Minty cubes tighten iteration-complexity bounds|journal=Mathematical Programming|url=|date=May 2008|pages=1–14|volume=113|number=1|doi=10.1007/s10107-006-0044-x|mr=2367063|ref=harv|id={{subscription needed}}. [http://www.cas.mcmaster.ca/~deza/mp2008.pdf pdf version at Professor Deza's homepage]}}
* {{cite journal|first1=B.|last1=Gartner|first2=G. M.|last2=Ziegler|authorlink2=Günter M. Ziegler|title=Randomized simplex algorithms on Klee-Minty cubes|journal=Foundations of Computer Science, Annual IEEE Symposium on|pages=502–510|issue=35th Annual Symposium on Foundations of Computer Science (FOCS&amp;nbsp;1994)|year=1994|publisher=IEEE|url=http://doi.ieeecomputersociety.org/10.1109/SFCS.1994.365741|ref=harv|id=IEEE mis-spells the name "Gärnter" as "Gartner" (sic.).|doi=10.1109/SFCS.1994.365741}}

=== Pictures with no linear system ===
* [http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nematollahi:Eissa.html Articles of E. Nematollahi, which discuss the Klee-Minty cube with illustrations.]
* [https://translate.google.com/translate?sl=auto&amp;tl=en&amp;js=n&amp;prev=_t&amp;hl=en&amp;ie=UTF-8&amp;layout=2&amp;eotf=1&amp;u=http%3A%2F%2Fwww.mathematik.de%2Fger%2Finformation%2Fforschungsprojekte%2Fzieglergeometrie%2Fzieglergeometrie.html A picture of a Klee-Minty cube showing a simplex-algorithm path] (automatic translation of [http://www.mathematik.de/ger/information/forschungsprojekte/zieglergeometrie/zieglergeometrie.html German]) by [[Günter Ziegler]]. The picture in the second half of the page.

{{Mathematical programming|state=collapsed|COLLAPSED=yes}}
{{Optimization algorithms|state=collapsed|COLLAPSED=yes}}

{{DEFAULTSORT:Klee-Minty cube}}
[[Category:Linear programming]]
[[Category:Analysis of algorithms]]
[[Category:Computational complexity theory]]
[[Category:Convex geometry]]
[[Category:Cubes]]</text>
      <sha1>2zeldzkwftundnvx8a0d5soc5js0owp</sha1>
    </revision>
  </page>
  <page>
    <title>Klein geometry</title>
    <ns>0</ns>
    <id>2908224</id>
    <revision>
      <id>865203374</id>
      <parentid>674247367</parentid>
      <timestamp>2018-10-22T12:47:04Z</timestamp>
      <contributor>
        <ip>46.242.15.253</ip>
      </contributor>
      <comment>/* Examples */ Write stabilizer of point in elliptic geometry.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7614">In [[mathematics]], a '''Klein geometry''' is a type of [[geometry]] motivated by [[Felix Klein]] in his influential [[Erlangen program]]. More specifically, it is a [[homogeneous space]] ''X'' together with a [[group action|transitive action]] on ''X'' by a [[Lie group]] ''G'', which acts as the [[symmetry group]] of the geometry.

For background and motivation see the article on the [[Erlangen program]].

==Formal definition==
A '''Klein geometry''' is a pair {{nowrap|(''G'', ''H'')}} where ''G'' is a [[Lie group]] and ''H'' is a [[closed set|closed]] [[Lie subgroup]] of ''G'' such that the (left) [[coset space]] ''G''/''H'' is [[connected space|connected]]. The group ''G'' is called the '''principal group''' of the geometry and ''G''/''H'' is called the '''space''' of the geometry (or, by an abuse of terminology, simply the ''Klein geometry''). The space {{nowrap|1=''X'' = ''G''/''H''}} of a Klein geometry is a [[smooth manifold]] of dimension
:dim ''X'' = dim ''G'' − dim ''H''.

There is a natural smooth [[group action|left action]] of ''G'' on ''X'' given by
:&lt;math&gt;g.(aH) = (ga)H.&lt;/math&gt;
Clearly, this action is transitive (take {{nowrap|1=''a'' = 1}}), so that one may then regard ''X'' as a [[homogeneous space]] for the action of ''G''. The [[stabilizer (group theory)|stabilizer]] of the identity coset {{nowrap|''H'' ∈ ''X''}} is precisely the group ''H''.

Given any connected smooth manifold ''X'' and a smooth transitive action by a Lie group ''G'' on ''X'', we can construct an associated Klein geometry {{nowrap|(''G'', ''H'')}} by fixing a basepoint ''x''&lt;sub&gt;0&lt;/sub&gt; in ''X'' and letting ''H'' be the stabilizer subgroup of ''x''&lt;sub&gt;0&lt;/sub&gt; in ''G''. The group ''H'' is necessarily a closed subgroup of ''G'' and ''X'' is naturally [[diffeomorphic]] to ''G''/''H''.

Two Klein geometries {{nowrap|(''G''&lt;sub&gt;1&lt;/sub&gt;, ''H''&lt;sub&gt;1&lt;/sub&gt;)}} and {{nowrap|(''G''&lt;sub&gt;2&lt;/sub&gt;, ''H''&lt;sub&gt;2&lt;/sub&gt;)}} are '''geometrically isomorphic''' if there is a [[Lie group isomorphism]] {{nowrap|''φ'' : ''G''&lt;sub&gt;1&lt;/sub&gt; → ''G''&lt;sub&gt;2&lt;/sub&gt;}} so that {{nowrap|1=''φ''(''H''&lt;sub&gt;1&lt;/sub&gt;) = ''H''&lt;sub&gt;2&lt;/sub&gt;}}. In particular, if ''φ''  is [[conjugacy class|conjugation]] by an element {{nowrap|''g'' ∈ ''G''}}, we see that {{nowrap|(''G'', ''H'')}} and {{nowrap|(''G'', ''gHg''&lt;sup&gt;−1&lt;/sup&gt;)}} are isomorphic. The Klein geometry associated to a homogeneous space ''X'' is then unique up to isomorphism (i.e. it is independent of the chosen basepoint ''x''&lt;sub&gt;0&lt;/sub&gt;).

==Bundle description==
Given a Lie group ''G'' and closed subgroup ''H'', there is natural [[group action|right action]] of ''H'' on ''G'' given by right multiplication.  This action is both free and [[proper action|proper]]. The [[orbit (group theory)|orbits]] are simply the left [[coset]]s of ''H'' in ''G''. One concludes that ''G'' has the structure of a smooth [[principal bundle|principal ''H''-bundle]] over the left coset space ''G''/''H'':
:&lt;math&gt;H\to G\to G/H .&lt;/math&gt;

==Types of Klein geometries==

===Effective geometries===
The action of ''G'' on {{nowrap|1=''X'' = ''G''/''H''}} need not be effective. The '''kernel''' of a Klein geometry is defined to be the kernel of the action of ''G'' on ''X''. It is given by
:&lt;math&gt;K = \{k \in G : g^{-1}kg \in H\;\;\forall g \in G\}.&lt;/math&gt;
The kernel ''K'' may also be described as the [[core (group)|core]] of ''H'' in ''G'' (i.e. the largest subgroup of ''H'' that is [[normal subgroup|normal]] in ''G''). It is the group generated by all the normal subgroups of ''G'' that lie in ''H''.

A Klein geometry is said to be '''effective''' if {{nowrap|1=''K'' = 1}} and '''locally effective''' if ''K'' is [[discrete group|discrete]]. If {{nowrap|(''G'', ''H'')}} is a Klein geometry with kernel ''K'', then {{nowrap|(''G''/''K'', ''H''/''K'')}} is an effective Klein geometry canonically associated to {{nowrap|(''G'', ''H'')}}.

===Geometrically oriented geometries===
A Klein geometry {{nowrap|(''G'', ''H'')}} is '''geometrically oriented''' if ''G'' is [[connected space|connected]]. (This does ''not'' imply that ''G''/''H'' is an [[orientability|oriented manifold]]). If ''H'' is connected it follows that ''G'' is also connected (this is because ''G''/''H'' is assumed to be connected, and {{nowrap|''G'' → ''G''/''H''}} is a [[fibration]]).

Given any Klein geometry {{nowrap|(''G'', ''H'')}}, there is a geometrically oriented geometry canonically associated to {{nowrap|(''G'', ''H'')}} with the same base space ''G''/''H''. This is the geometry {{nowrap|(''G''&lt;sub&gt;0&lt;/sub&gt;, ''G''&lt;sub&gt;0&lt;/sub&gt; ∩ ''H'')}} where ''G''&lt;sub&gt;0&lt;/sub&gt; is the [[identity component]] of ''G''. Note that {{nowrap|1=''G'' = ''G''&lt;sub&gt;0&lt;/sub&gt; ''H''}}.

===Reductive geometries===
A Klein geometry {{nowrap|(''G'', ''H'')}} is said to be '''reductive''' and ''G''/''H'' a '''reductive homogeneous space''' if the [[Lie algebra]] &lt;math&gt;\mathfrak h&lt;/math&gt; of ''H'' has an ''H''-invariant complement in &lt;math&gt;\mathfrak g&lt;/math&gt;.

== Examples ==
In the following table, there is a description of the classical geometries, modeled as Klein geometries.

{| class="wikitable" border="1"; text-align:center; margin:.5em 0 .5em 1em;"
|-
| 
| '''Underlying space'''
| '''Transformation group ''G'''''
| '''Subgroup ''H'''''
| '''Invariants'''
|-
! ''[[Projective geometry]]''
| [[Real projective space]] &lt;math&gt;\mathbb{R}\mathrm{P}^n&lt;/math&gt; || [[Projective group]] &lt;math&gt;\mathrm{PGL}(n+1)&lt;/math&gt;|| A subgroup &lt;math&gt;P&lt;/math&gt; fixing a [[Flag (linear algebra)|flag]] &lt;math&gt;\{0\}\subset V_1\subset V_n&lt;/math&gt; || [[Projective line]]s, [[cross-ratio]] 
|-
! ''[[Conformal geometry]] on the sphere''
| [[Sphere]] &lt;math&gt;S^n&lt;/math&gt; || [[Lorentz group]] of an &lt;math&gt;(n+2)&lt;/math&gt;-dimensional space &lt;math&gt;\mathrm{O}(n+1,1)&lt;/math&gt; || A subgroup &lt;math&gt;P&lt;/math&gt; fixing a [[Line (geometry)|line]] in the [[null cone]] of the Minkowski metric || [[Generalized circle]]s, angles
|-
! ''[[Hyperbolic geometry]]''
| [[Hyperbolic space]] &lt;math&gt;H(n)&lt;/math&gt;, modelled e.g. as time-like lines in the [[Minkowski space]] &lt;math&gt;\R^{1,n}&lt;/math&gt; || [[Orthochronous Lorentz group]] &lt;math&gt;\mathrm{O}(1,n)/\mathrm{O}(1)&lt;/math&gt; || &lt;math&gt;\mathrm{O}(1)\times \mathrm{O}(n)&lt;/math&gt; || Lines, circles, distances, angles
|-
! ''[[Elliptic geometry]]''
| Elliptic space, modelled e.g. as the lines through the origin in [[Euclidean space]] &lt;math&gt;\mathbb{R}^{n+1}&lt;/math&gt; || &lt;math&gt;\mathrm{O}(n+1)/\mathrm{O}(1)&lt;/math&gt; || &lt;math&gt;\mathrm{O}(n)/\mathrm{O}(1)&lt;/math&gt; || Lines, circles, distances, angles
|-
! ''[[Spherical geometry]]''
| [[Sphere]] &lt;math&gt;S^n&lt;/math&gt; || Orthogonal group &lt;math&gt;\mathrm{O}(n+1)&lt;/math&gt; || Orthogonal group &lt;math&gt;\mathrm{O}(n)&lt;/math&gt; || Lines (great circles), circles, distances of points, angles
|-
! ''[[Affine geometry]]''
| [[Affine space]] &lt;math&gt;A(n)\simeq\R^n&lt;/math&gt; || [[Affine group]] &lt;math&gt;\mathrm{Aff}(n)\simeq \R^n \rtimes \mathrm{GL}(n)&lt;/math&gt; || [[General linear group]] &lt;math&gt;\mathrm{GL}(n)&lt;/math&gt; || Lines, quotient of surface areas of geometric shapes, [[center of mass]] of [[triangles]]
|-
! ''[[Euclidean geometry]]''
|  [[Euclidean space]] &lt;math&gt;E(n)&lt;/math&gt; || [[Euclidean group]] &lt;math&gt;\mathrm{Euc}(n)\simeq \R^n \rtimes \mathrm{O}(n)&lt;/math&gt; || [[Orthogonal group]] &lt;math&gt;\mathrm{O}(n)&lt;/math&gt; || Distances of [[Euclidean group|points]], [[angle]]s of [[Euclidean vector|vectors]], areas
|-
|}

==References==
*{{cite book | author=R. W. Sharpe | title=Differential Geometry: Cartan's Generalization of Klein's Erlangen Program | publisher=Springer-Verlag | year=1997 | isbn=0-387-94732-9}}

[[Category:Differential geometry]]
[[Category:Lie groups]]
[[Category:Homogeneous spaces]]</text>
      <sha1>c9tp84g9rqv1evmcy9w9pxfgustkq5w</sha1>
    </revision>
  </page>
  <page>
    <title>Kuranishi structure</title>
    <ns>0</ns>
    <id>48124047</id>
    <revision>
      <id>862709641</id>
      <parentid>859738717</parentid>
      <timestamp>2018-10-06T05:22:29Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Eponymous scientific concepts per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 September 22]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5349">In mathematics, especially in [[topology]], a '''Kuranishi structure''' is a smooth analogue of [[scheme (mathematics)|scheme]] structure. If a topological space is endowed with a Kuranishi structure, then locally it can be identified with the zero set of a smooth map &lt;math&gt; (f_1, \ldots, f_k): {\mathbb R}^{n+k} \to {\mathbb R}^k&lt;/math&gt;, or the quotient of such a zero set by a finite group. Kuranishi structure was introduced by Japanese mathematicians [[Kenji Fukaya]] and Kaoru Ono in the study of [[Gromov–Witten invariants]] in symplectic geometry and named after [[Masatake Kuranishi]].&lt;ref&gt;{{cite journal |last=Fukaya |first=K. |last2=Ono |first2=K. |title=Arnold Conjecture and Gromov–Witten Invariant |journal=[[Topology (journal)|Topology]] |volume=38 |year=1999 |issue=5 |pages=933–1048 |doi=10.1016/S0040-9383(98)00042-1 }}&lt;/ref&gt;

==Definition==

Let &lt;math&gt; X &lt;/math&gt; be a compact [[metrizable]] topological space. Let &lt;math&gt; p \in X &lt;/math&gt; be a point. A '''Kuranishi neighborhood''' of &lt;math&gt; p &lt;/math&gt; (of dimension &lt;math&gt; k &lt;/math&gt;) is a 5-tuple

:::&lt;math&gt; K_p = (U_p, E_p, S_p, \psi_p, F_p) &lt;/math&gt;

where

* &lt;math&gt; U_p &lt;/math&gt; is a smooth [[orbifold]];
* &lt;math&gt; E_p \to U_p &lt;/math&gt; is a smooth orbifold vector bundle;
* &lt;math&gt; S_p: U_p \to E_p &lt;/math&gt; is a smooth section;
* &lt;math&gt; \psi_p: S_p^{-1}(0) \to X &lt;/math&gt; is a continuous map and is homeomorphic onto its image &lt;math&gt; F_p \subset X &lt;/math&gt;.

They should satisfy that &lt;math&gt; \dim U_p - \operatorname{rank} E_p = k &lt;/math&gt;.

If &lt;math&gt; p, q \in X &lt;/math&gt; and &lt;math&gt; K_p = (U_p, E_p, S_p, \psi_p, F_p) &lt;/math&gt;, &lt;math&gt; K_q = (U_q, E_q, S_q, \psi_q, F_q) &lt;/math&gt; are their Kuranishi neighborhoods respectively, then a '''coordinate change''' from &lt;math&gt; K_q &lt;/math&gt; to &lt;math&gt; K_p &lt;/math&gt; is a triple

:::&lt;math&gt; T_{pq} = ( U_{pq}, \phi_{pq}, \hat\phi_{pq}) &lt;/math&gt;

where

* &lt;math&gt; U_{pq} \subset U_q &lt;/math&gt; is an open sub-orbifold;
* &lt;math&gt; \phi_{pq}: U_{pq} \to U_p &lt;/math&gt; is an orbifold embedding;
* &lt;math&gt; \hat\phi_{pq}: E_q|_{U_{pq}} \to E_p &lt;/math&gt; is an orbifold vector bundle embedding which covers &lt;math&gt; \phi_{pq} &lt;/math&gt;.

In addition, they must satisfy the compatibility condition:

* &lt;math&gt; S_p \circ \phi_{pq} = \hat\phi_{pq} \circ S_q|_{U_{pq}} &lt;/math&gt;;
* &lt;math&gt; \psi_p \circ \phi_{pq}|_{S_q^{-1}(0) \cap U_{pq}} = \psi_q|_{S_q^{-1}(0)\cap U_{pq}} &lt;/math&gt;.

A '''Kuranishi structure''' on &lt;math&gt; X &lt;/math&gt; of dimension &lt;math&gt; k &lt;/math&gt; is a collection

::: &lt;math&gt; \Big( \{ K_p = (U_p, E_p, S_p, \psi_p, F_p) \ |\ p \in X \},\ \{ T_{pq} = (U_{pq}, \phi_{pq}, \hat\phi_{pq} ) \ |\ p \in X,\ q \in F_p\} \Big)&lt;/math&gt;

where

* &lt;math&gt; K_p &lt;/math&gt; is a Kuranishi neighborhood of &lt;math&gt; p &lt;/math&gt; of dimension &lt;math&gt; k &lt;/math&gt;;
* &lt;math&gt; T_{pq} &lt;/math&gt; is a coordinate change from &lt;math&gt; K_q &lt;/math&gt; to &lt;math&gt; K_p &lt;/math&gt;.

In addition, the coordinate changes must satisfy the '''cocycle condition''', namely, whenever &lt;math&gt; q\in F_p,\ r \in F_q &lt;/math&gt;, we require that

::: &lt;math&gt; \phi_{pq} \circ \phi_{qr} = \phi_{pr},\ \hat\phi_{pq} \circ \hat\phi_{qr} = \hat\phi_{pr} &lt;/math&gt;

over the regions where both sides are defined.

==History==

In [[Gromov–Witten invariant|Gromov–Witten theory]], one needs to define integration over the moduli space of stable maps &lt;math&gt; \overline{\mathcal M}_{g, n} (X, A) &lt;/math&gt;.&lt;ref&gt;McDuff, D and Salamon, D. "J-holomorphic curves and symplectic topology", ''American Mathematical Society Colloquium Publications'', 52. American Mathematical Society, Providence, RI, 2004, {{isbn|0-8218-3485-1}}&lt;/ref&gt; They are maps &lt;math&gt; u &lt;/math&gt; from a nodal Riemann surface with genus &lt;math&gt; g &lt;/math&gt; and &lt;math&gt; n &lt;/math&gt; marked points into a [[symplectic manifold]] &lt;math&gt; X &lt;/math&gt;, such that each component satisfies the Cauchy–Riemann equation

::: &lt;math&gt; \overline\partial_J u  = 0 &lt;/math&gt;.

If the moduli space is a smooth, compact, oriented manifold or orbifold, then the integration (or a [[fundamental class]]) can be defined. When the symplectic manifold &lt;math&gt; X &lt;/math&gt; is '''semi-positive''', this is indeed the case (except for codimension 2 boundaries of the moduli space) if the [[almost complex structure]] &lt;math&gt; J &lt;/math&gt; is perturbed generically. However, when &lt;math&gt; X &lt;/math&gt; is not semi-positive, the moduli space may contain configurations for which one component is a multiple cover of a holomorphic sphere &lt;math&gt; u: S^2 \to X &lt;/math&gt; whose intersection with the first [[Chern class]] of &lt;math&gt; X &lt;/math&gt; is negative. Such configurations make the moduli space very singular so a fundamental class cannot be defined in the usual way.

The notion of Kuranishi structure was a way of defining a '''[[virtual fundamental cycle]]''', which plays the same role as a fundamental cycle when the moduli space is cut out transversely. It was first used by Fukaya and Ono in defining the Gromov–Witten invariants and Floer homology, and was further developed when Fukaya, Oh, Ohta, Ono studied the [[Floer homology|Lagrangian intersection Floer theory]].&lt;ref&gt;Fukaya, K., Oh, Y.-G., Ohta, H. and Ono, K., "Lagrangian intersection Floer theory: anomaly and obstruction, Part I and Part II", ''AMS/IP Studies in Advanced Mathematics'', 46, American Mathematical Society, Providence, RI; International Press, Somerville, MA, 2009. {{isbn|978-0-8218-4836-4}}&lt;/ref&gt;

==References==
{{Reflist}}

[[Category:Topology]]</text>
      <sha1>nszf9jqmqyhuttf8tiaspoc6s7hiufn</sha1>
    </revision>
  </page>
  <page>
    <title>M-Labs</title>
    <ns>0</ns>
    <id>31567389</id>
    <revision>
      <id>849108011</id>
      <parentid>819588657</parentid>
      <timestamp>2018-07-06T15:47:44Z</timestamp>
      <contributor>
        <username>X4t8Jmt6</username>
        <id>33891678</id>
      </contributor>
      <minor/>
      <comment>Add Genode citation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11432">{{advert|date=April 2017}}

'''M-Labs''' (formerly known as the '''Milkymist project''') is a company and community who develop, manufacture and sell advanced [[open hardware]] devices and solutions. It is best known for the Milkymist [[system-on-chip]] (SoC) which is among the first commercialized system-on-chip designs with [[Free software|free]] [[hardware description language|HDL]] source code.&lt;ref name="thereg"&gt;{{cite web|url=https://www.theregister.co.uk/2011/09/28/milkymist/|title=The Register: Open-source hardware group puts out vid system-on-a-chip|accessdate=2013-05-02}}&lt;/ref&gt;

M-Labs technologies have been reused in diverse applications. For example, [[NASA]]'s Communication Navigation and Networking Reconfigurable Testbed (CoNNeCT) experiment uses the [[memory controller]] that was originally developed for the Milkymist One&lt;ref name="jpl"&gt;{{cite web|url=http://m-labs.hk/jpl_letter.jpg|title=JPL acknowledgement letter|accessdate=2014-02-13}}&lt;/ref&gt;&lt;ref name="ttf"&gt;{{cite web|url=http://www.techthefuture.com/technology/open-source-hardware/|title=Tech the Future: Open source hardware|accessdate=2013-05-02}}&lt;/ref&gt;&lt;ref name="mmthesis" /&gt; and published under the terms of the [[GNU General Public License]] (GPL).

The project was presented at several open source and [[Hacker (computer security)|hacker]] conferences such as the [[Chaos Communication Congress]],&lt;ref name="26c3"&gt;{{cite web|url=https://events.ccc.de/congress/2009/Fahrplan/events/3350.en.html|title=26C3 schedule|accessdate=2011-04-22}}&lt;/ref&gt; [[FOSDEM]],&lt;ref name="fosdem"&gt;{{cite web|url=http://m.fosdem.org/event/milkymist|title=Milkymist : Pushing further the limits of electronics openness|accessdate=2011-04-22|deadurl=yes|archiveurl=https://web.archive.org/web/20110712080430/http://m.fosdem.org/event/milkymist|archivedate=2011-07-12|df=}}&lt;/ref&gt; [[Libre Software Meeting]],&lt;ref name="rmll"&gt;{{cite web|url=http://2010.rmll.info/Milkymist-a-free-System-on-Chip-for-real-time-video.html?lang=fr|title=Milkymist : a free System-on-Chip for real-time video|accessdate=2011-04-22}}&lt;/ref&gt; and [[Libre Graphics Meeting|Libre Graphics Meeting 2011]].&lt;ref&gt;{{cite web|url=http://en.qi-hardware.com/wiki/Press_Release:_Milkymist_One_video_synthesizer_shown_at_6th_Libre_Graphics_Meeting_in_Montreal|title=Milkymist One video synthesizer shown at 6th Libre Graphics Meeting in Montreal|accessdate=2011-05-14}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://fabricatorz.com/2011/05/milkymist-one-video-synthesizer-shown-at-6th-libre-graphics-meeting-in-montreal/ |title=Milkymist One Shown at Libre Graphics Meeting |accessdate=2011-05-14 |deadurl=yes |archiveurl=https://web.archive.org/web/20110519235131/http://fabricatorz.com/2011/05/milkymist-one-video-synthesizer-shown-at-6th-libre-graphics-meeting-in-montreal/ |archivedate=2011-05-19 |df= }}&lt;/ref&gt; It was also featured on the ''[[Make (magazine)|Make]]'' magazine blog&lt;ref name="makeblog"&gt;{{cite web|url=http://blog.makezine.com/archive/2010/08/milkymist-interactive-vj-station.html|title=Make: Online: Milkymist :: Interactive VJ Station|accessdate=2011-04-22}}&lt;/ref&gt; and the Milkymist One board was included in their "ultimate open source hardware gift guide 2010".&lt;ref name="makegg2010"&gt;{{cite web|url=http://blog.makezine.com/archive/2010/12/the-ultimate-open-source-hardware-g.html|title=Make: Online: The Ultimate Open Source Hardware Gift Guide 2010|accessdate=2011-04-22}}&lt;/ref&gt;

== Milkymist SoC ==
The Milkymist [[system-on-chip]] uses the [[LatticeMico32]] (LM32) core as a general purpose processor. It is a [[RISC]] 32-bit [[big endian]] [[CPU]] with a [[memory management unit]] (MMU) developed later by M-Labs contributors. It is supported by the [[GNU Compiler Collection|GCC]] compiler and can run [[RTEMS]] and [[μClinux]]. There is also an experimental back-end for [[LLVM]] targeting this microprocessor.

The LM32 microprocessor is assisted by a [[texture mapping unit]] and a programmable [[floating point]] [[Very long instruction word|VLIW]] coprocessor which are used by the [[#Milkymist_One_and_Flickernoise|Flickernoise]] video synthesis software. It is also surrounded by various peripheral cores to support every I/O device of the Milkymist One. The system-on-chip interconnect uses three bridged buses and mixes the [[Wishbone (computer bus)|Wishbone]] protocol with two custom protocols used for configuration registers and high performance [[Direct memory access|DMA]] with the [[SDRAM]].

The architecture of the Milkymist [[system-on-chip]] is largely documented in the project founder's Master thesis report.&lt;ref name="mmthesis"&gt;{{cite web|url=http://kth.diva-portal.org/smash/record.jsf?pid=diva2:370883|title=A performance-driven SoC architecture for video synthesis|last=Bourdeauducq|first=Sebastien|date=June 2010|accessdate=2011-04-22|publisher=KTH}}&lt;/ref&gt; Most components of the system-on-chip, except the [[LatticeMico32]] core, were custom developed and placed under the [[GNU GPL]] license.

The [[QEMU]] emulator can be used to run and debug Milkymist SoC binaries&lt;ref name="qemu"&gt;{{cite web|url=http://lists.nongnu.org/archive/html/qemu-devel/2011-04/msg00239.html|title=QEMU development mailing list|accessdate=2011-04-22}}&lt;/ref&gt; on another computer.

== Milkymist One and Flickernoise ==
{{Infobox information appliance
| name         = Milkymist One
| image        = [[File:Milkymist case acryl v6 1.jpg|250px]]
| caption      = 
| manufacturer = [[Qi Hardware]]
| type         = [[Video synthesizer]]
| releasedate  = {{Start date|2010|12|27}} (early developer kit), {{Start date|2011|09|28}} (final version)
| price        = 380 EUR (early developer kit), 499 USD (final version)
| lifespan     =
| media        = 
| os           = [[RTEMS]], [[Linux]]
| input        = [[USB]] keyboard and mouse
| camera       = External ([[CVBS]] digitizer)
| power        = 5 W
| cpu          = [[LatticeMico32]] in a [[Xilinx]] Spartan-6 FPGA
| storage      = 32 MB built-in NOR flash, [[memory card]]
| memory       = 128 MB [[DDR SDRAM]]
| display      = [[SVGA]] up to {{nowrap|140 MHz}} pixel clock (1280x1024)
| connectivity = [[DMX512]], [[MIDI]], [[OpenSoundControl]], [[AC97]] audio, [[Ethernet]], [[RC-5]] infrared, [[USB]], [[GPIO]]
| service      = 
| dimensions   = 172 × 145 × 45 mm
| weight       = 465 g
| touchpad     =
| predecessor  =
| successor    =
| related      = 
}}

The Milkymist One [[video synthesizer]] and [[Reconfigurable computing|reconfigurable computer]] is the main product released by the project. It was manufactured by [[Qi Hardware]], a start-up founded by former [[Openmoko]] employees.&lt;ref name="qihw"&gt;{{cite web|url=http://www.linux.com/news/embedded-mobile/mids/29263-openmoko-layoffs-lead-to-new-open-hardware-venture|title=OpenMoko Layoffs Lead to New Open Hardware Venture|accessdate=2011-04-22}}&lt;/ref&gt; It was first sold at the [[Chaos Communication Congress]] in 2010,&lt;ref name="hdccc"&gt;{{cite web|url=http://hackable-devices.org/news/post/john/2010/12/first-milkymist-one-early-developer-kits-are-c/|title=First Milkymist One Early Developer Kits are coming!|accessdate=2011-04-22}}&lt;/ref&gt; as an "early developer kit" for interested [[hacker (programmer subculture)|hacker]]s, [[open source]] activists and pioneers who could tolerate the remaining software and [[Field-programmable gate array|FPGA]] design shortcomings. A more refined version, including case and accessories, was later offered for sale.

The technical specifications of the Milkymist One&lt;ref name="mmone"&gt;{{cite web|url=http://m-labs.hk/m1.html|title=M-Labs official website: Milkymist One|accessdate=2013-05-02}}&lt;/ref&gt; are as follows:
* Multi-standard video input ([[PAL]]/[[SECAM]]/[[NTSC]])
* Two [[DMX512]] ([[RS485]]) ports
* [[MIDI]] IN and MIDI OUT ports
* [[SVGA]] output, 24 bpp, up to 140&amp;nbsp;MHz pixel clock (about 1280×1024)
* [[AC97]] audio
* Xilinx XC6SLX45 Spartan-6 [[Field-programmable gate array|FPGA]] supporting the open source Milkymist SoC
* 128&amp;nbsp;MB 32-bit DDR333 [[SDRAM]]
* 32&amp;nbsp;MB parallel flash
* 10/100 [[Ethernet]]
* [[Memory card]]
* Two [[USB]] host connectors
* [[RC-5]] compatible infrared receiver
* [[RS-232]] debug port

The design files of the [[printed circuit board]] and the [[Computer-aided design|CAD]] files of the case were released under the [[Creative Commons]] Attribution-Share Alike license.

{| style="margin: 1em auto 1em auto;"
| [[File:Flickernoise-darkblue.png|thumb|Screenshot of Flickernoise, showing the control panel, the patch editor etc.]]
| 
|}

Flickernoise is the video synthesis software that runs on the Milkymist One. It is heavily inspired by [[MilkDrop]] and uses a similar, and largely compatible, scripting language to define and program the visual effects. However, while MilkDrop is designed to run automatically in a music player, Flickernoise is focused on the interactivity of the visuals for use in live performances. The software supports the programming of visual effects that transform a live video stream coming from a camera connected to the Milkymist One, as well as input from [[OpenSoundControl]], [[DMX512]] and [[MIDI]] controllers.

Flickernoise runs on the [[RTEMS]] real-time operating system, and uses many [[POSIX]] software libraries that were ported to this operating system such as [[libpng]], [[libjpeg]], jbig2dec, [[OpenJPEG]], [[FreeType]], [[MuPDF]] and liblo for [[OpenSoundControl]] support. The streamlined hardware platform along with the use of a real-time operating system allows the system to have a lower response time than an equivalent PC-based setup. The user interface is based on a variant of the [[Genode]] FX toolkit&lt;ref&gt;{{cite web|url=https://www.genode-labs.com/products/fpga-graphics|title=Genode Labs: FPGA Graphics}}&lt;/ref&gt;

Flickernoise is also [[free software]], released under the terms of the [[GNU General Public License]].

== ARTIQ ==

[[File:ARTIQ_system_overview.pdf|thumb|right|ARTIQ system overview]]

In May 2014, M-Labs entered a partnership with [[NIST]] to develop a next-generation open source control system for [[quantum information]] experiments.&lt;ref name="nistpr"&gt;{{cite web|url=http://nist.gov/pml/div688/grp10/open-source-software-for-quantum-information.cfm|title=NIST: Open-Source Software for Quantum Information|accessdate=2015-01-25}}&lt;/ref&gt; &lt;ref name="mlabsartiq"&gt;{{cite web|url=https://m-labs.hk/artiq|title=M-Labs website: ARTIQ|accessdate=2017-02-14}}&lt;/ref&gt; The system, called ARTIQ (Advanced Real-Time Infrastructure for Quantum physics), is a combination of software and [[gateware]] that enables synchronized control of many devices with nanosecond-level timing resolution and sub-microsecond latency, while retaining features of high level programming languages.

Some of the ideas and code from Milkymist SoC have been reused in ARTIQ.

In 2016 M-Labs partnered with [https://www.arl.army.mil/www/default.cfm ARL] and [http://www.ise.pw.edu.pl/ ISE] to develop ARTIQ [https://github.com/m-labs/sinara Sinara], an open source hardware and software-defined radio platform.&lt;ref name="mlabsartiqmirror"&gt;{{cite web|url=https://ehsm.eu/m-labs.hk/artiq|title=M-Labs mirror: ARTIQ|accessdate=2017-02-14}}&lt;/ref&gt;

== References ==
{{Reflist}}

[[Category:Open hardware electronic devices]]
[[Category:Video art]]
[[Category:Video hardware]]
[[Category:Visual effects]]
[[Category:Open microprocessors]]
[[Category:Quantum information science]]
[[Category:Open hardware organizations and companies]]</text>
      <sha1>ny18n3wwswyet22vyq5beab79ljp20u</sha1>
    </revision>
  </page>
  <page>
    <title>Mirror symmetry (string theory)</title>
    <ns>0</ns>
    <id>644671</id>
    <revision>
      <id>842718557</id>
      <parentid>842718036</parentid>
      <timestamp>2018-05-24T06:45:15Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>/* References */ [[Clay Mathematics Monographs]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="42163">{{String theory}}
{{Other uses|Mirror symmetry (disambiguation){{!}}Mirror symmetry}}
In [[algebraic geometry]] and [[theoretical physics]], '''mirror symmetry''' is a relationship between [[geometry|geometric]] objects called [[Calabi–Yau manifold]]s. The term refers to a situation where two Calabi–Yau manifolds look very different geometrically but are nevertheless equivalent when employed as [[extra dimension]]s of [[string theory]].

Mirror symmetry was originally discovered by physicists. Mathematicians became interested in this relationship around 1990 when [[Philip Candelas]], Xenia de la Ossa, Paul Green, and Linda Parkes showed that it could be used as a tool in [[enumerative geometry]], a branch of mathematics concerned with counting the number of solutions to geometric questions. Candelas and his collaborators showed that mirror symmetry could be used to count [[rational curve]]s on a Calabi–Yau manifold, thus solving a longstanding problem. Although the original approach to mirror symmetry was based on physical ideas that were not understood in a mathematically precise way, some of its mathematical predictions have since been [[mathematical proof|proven rigorously]].

Today, mirror symmetry is a major research topic in [[pure mathematics]], and mathematicians are working to develop a mathematical understanding of the relationship based on physicists' intuition. Mirror symmetry is also a fundamental tool for doing calculations in string theory, and it has been used to understand aspects of [[quantum field theory]], the formalism that physicists use to describe [[elementary particle]]s. Major approaches to mirror symmetry include the [[homological mirror symmetry]] program of [[Maxim Kontsevich]] and the [[SYZ conjecture]] of [[Andrew Strominger]], [[Shing-Tung Yau]], and [[Eric Zaslow]].

==Overview==

===Strings and compactification===
{{main article|String theory|Compactification (physics)}}
[[Image:Open and closed strings.svg|right|thumb|alt=A wavy open segment and closed loop of string.|The fundamental objects of string theory are open and closed [[string (physics)|strings]]. ]]
In physics, [[string theory]] is a [[mathematical theory|theoretical framework]] in which the [[point particle|point-like particles]] of [[particle physics]] are replaced by [[one dimensional|one-dimensional]] objects called [[string (physics)|strings]]. These strings look like small segments or loops of ordinary string. String theory describes how strings propagate through space and interact with each other. On distance scales larger than the string scale, a string will look just like an ordinary particle, with its [[mass]], [[charge (physics)|charge]], and other properties determined by the vibrational state of the string. Splitting and recombination of strings correspond to particle emission and absorption, giving rise to the interactions between particles.&lt;ref&gt;For an accessible introduction to string theory, see Greene 2000.&lt;/ref&gt;

There are notable differences between the world described by string theory and the everyday world. In everyday life, there are three familiar dimensions of space (up/down, left/right, and forward/backward), and there is one dimension of time (later/earlier). Thus, in the language of modern physics, one says that [[spacetime]] is four-dimensional.&lt;ref&gt;Wald 1984, p. 4&lt;/ref&gt; One of the peculiar features of string theory is that it requires [[extra dimensions]] of spacetime for its mathematical consistency. In [[superstring theory]], the version of the theory that incorporates a theoretical idea called [[supersymmetry]], there are six extra dimensions of spacetime in addition to the four that are familiar from everyday experience.&lt;ref&gt;Zwiebach 2009, p. 8&lt;/ref&gt;

One of the goals of current research in string theory is to develop models in which the strings represent particles observed in high energy physics experiments. For such a model to be consistent with observations, its spacetime must be four-dimensional at the relevant distance scales, so one must look for ways to restrict the extra dimensions to smaller scales. In most realistic models of physics based on string theory, this is accomplished by a process called [[compactification (physics)|compactification]], in which the extra dimensions are assumed to "close up" on themselves to form circles.&lt;ref name=autogenerated1&gt;Yau and Nadis 2010, Ch. 6&lt;/ref&gt; In the limit where these curled up dimensions become very small, one obtains a theory in which spacetime has effectively a lower number of dimensions. A standard analogy for this is to consider a multidimensional object such as a garden hose. If the hose is viewed from a sufficient distance, it appears to have only one dimension, its length. However, as one approaches the hose, one discovers that it contains a second dimension, its circumference. Thus, an ant crawling on the surface of the hose would move in two dimensions.&lt;ref&gt;This analogy is used for example in Greene 2000, p. 186&lt;/ref&gt;

===Calabi–Yau manifolds===
{{main article|Calabi–Yau manifold}}
[[Image:Calabi yau.jpg|right|thumb|alt=Visualization of a complex mathematical surface with many convolutions and self intersections.|A cross section of a quintic [[Calabi–Yau manifold]] ]]
Compactification can be used to construct models in which spacetime is effectively four-dimensional. However, not every way of compactifying the extra dimensions produces a model with the right properties to describe nature. In a viable model of particle physics, the compact extra dimensions must be shaped like a [[Calabi–Yau manifold]].&lt;ref name=autogenerated1 /&gt; A Calabi–Yau manifold is a special [[topological space|space]] which is typically taken to be six-dimensional in applications to string theory. It is named after mathematicians [[Eugenio Calabi]] and [[Shing-Tung Yau]].&lt;ref&gt;Yau and Nadis 2010, p. ix&lt;/ref&gt;

After Calabi–Yau manifolds had entered physics as a way to compactify extra dimensions, many physicists began studying these manifolds. In the late 1980s, Lance Dixon, Wolfgang Lerche, [[Cumrun Vafa]], and Nick Warner noticed that given such a compactification of string theory, it is not possible to reconstruct uniquely a corresponding Calabi–Yau manifold.&lt;ref&gt;Dixon 1988; Lerche, Vafa, and Warner 1989&lt;/ref&gt; Instead, two different versions of string theory called [[type IIA string theory]] and [[type IIB]] can be compactified on completely different Calabi–Yau manifolds giving rise to the same physics.&lt;ref&gt;The shape of a Calabi–Yau manifold is described mathematically using an array of numbers called [[Hodge number]]s. The arrays corresponding to mirror Calabi–Yau manifolds are different in general, reflecting the different shapes of the manifolds, but they are related by a certain symmetry. For more information, see Yau and Nadis 2010, p. 160–3.&lt;/ref&gt; In this situation, the manifolds are called mirror manifolds, and the relationship between the two physical theories is called mirror symmetry.&lt;ref&gt;Aspinwall et al. 2009, p. 13&lt;/ref&gt;

The mirror symmetry relationship is a particular example of what physicists call a [[string duality|duality]]. In general, the term ''duality'' refers to a situation where two seemingly different physical theories turn out to be equivalent in a nontrivial way. If one theory can be transformed so it looks just like another theory, the two are said to be dual under that transformation. Put differently, the two theories are mathematically different descriptions of the same phenomena.&lt;ref&gt;Hori et al. 2003, p. xvi&lt;/ref&gt; Such dualities play an important role in modern physics, especially in string theory.&lt;ref&gt;Other dualities that arise in string theory are [[S-duality]], [[T-duality]], and the [[AdS/CFT correspondence]].&lt;/ref&gt;

Regardless of whether Calabi–Yau compactifications of string theory provide a correct description of nature, the existence of the mirror duality between different string theories has significant mathematical consequences.&lt;ref&gt;Zaslow 2008, p. 523&lt;/ref&gt; The Calabi–Yau manifolds used in string theory are of interest in [[pure mathematics]], and mirror symmetry allows mathematicians to solve problems in [[enumerative geometry|enumerative algebraic geometry]], a branch of mathematics concerned with counting the numbers of solutions to geometric questions. A classical problem of enumerative geometry is to enumerate the [[rational curve]]s on a Calabi–Yau manifold such as the one illustrated above. By applying mirror symmetry, mathematicians have translated this problem into an equivalent problem for the mirror Calabi–Yau, which turns out to be easier to solve.&lt;ref&gt;Yau and Nadis 2010, p. 168&lt;/ref&gt;

In physics, mirror symmetry is justified on physical grounds.&lt;ref name=autogenerated10&gt;Hori and Vafa 2000&lt;/ref&gt; However, mathematicians generally require [[mathematical rigor|rigorous proofs]] that do not require an appeal to physical intuition. From a mathematical point of view, the version of mirror symmetry described above is still only a conjecture, but there is another version of mirror symmetry in the context of [[topological string theory]], a simplified version of string theory introduced by [[Edward Witten]],&lt;ref name=autogenerated9&gt;Witten 1990&lt;/ref&gt; which has been rigorously proven by mathematicians.&lt;ref&gt;Givental 1996, 1998; Lian, Liu, Yau 1997, 1999, 2000&lt;/ref&gt; In the context of topological string theory, mirror symmetry states that two theories called the [[Topological A-model|A-model]] and [[Topological B-model|B-model]] are equivalent in the sense that there is a duality relating them.&lt;ref name=autogenerated5&gt;Zaslow 2008, p. 531&lt;/ref&gt; Today mirror symmetry is an active area of research in mathematics, and mathematicians are working to develop a more complete mathematical understanding of mirror symmetry based on physicists' intuition.&lt;ref name=developments&gt;Hori et al. 2003, p. xix&lt;/ref&gt;

==History==
The idea of mirror symmetry can be traced back to the mid-1980s when it was noticed that a string propagating on a circle of radius &lt;math&gt;R&lt;/math&gt; is physically equivalent to a string propagating on a circle of radius &lt;math&gt;1/R&lt;/math&gt; in appropriate [[units of measurements|units]].&lt;ref&gt;This was first observed in Kikkawa and Yamasaki 1984 and Sakai and Senda 1986.&lt;/ref&gt; This phenomenon is now known as [[T-duality]] and is understood to be closely related to mirror symmetry.&lt;ref name=autogenerated3&gt;Strominger, Yau, and Zaslow 1996&lt;/ref&gt; In a paper from 1985, [[Philip Candelas]], Gary Horowitz, [[Andrew Strominger]], and Edward Witten showed that by compactifying string theory on a Calabi–Yau manifold, one obtains a theory roughly similar to the [[standard model of particle physics]] that also consistently incorporates an idea called supersymmetry.&lt;ref&gt;Candelas et al. 1985&lt;/ref&gt; Following this development, many physicists began studying Calabi–Yau compactifications, hoping to construct realistic models of particle physics based on string theory. Cumrun Vafa and others noticed that given such a physical model, it is not possible to reconstruct uniquely a corresponding Calabi–Yau manifold. Instead, there are two Calabi–Yau manifolds that give rise to the same physics.&lt;ref&gt;This was observed in Dixon 1988 and Lerche, Vafa, and Warner 1989.&lt;/ref&gt;

By studying the relationship between Calabi–Yau manifolds and certain [[conformal field theory|conformal field theories]] called Gepner models, [[Brian Greene]] and Ronen Plesser found nontrivial examples of the mirror relationship.&lt;ref&gt;Green and Plesser 1990; Yau and Nadis 2010, p. 158&lt;/ref&gt; Further evidence for this relationship came from the work of Philip Candelas, Monika Lynker, and Rolf Schimmrigk, who surveyed a large number of Calabi–Yau manifolds by computer and found that they came in mirror pairs.&lt;ref&gt;Candelas, Lynker, and Schimmrigk 1990; Yau and Nadis 2010, p. 163&lt;/ref&gt;

Mathematicians became interested in mirror symmetry around 1990 when physicists Philip Candelas, Xenia de la Ossa, Paul Green, and Linda Parkes showed that mirror symmetry could be used to solve problems in enumerative geometry&lt;ref&gt;Candelas et al. 1991&lt;/ref&gt; that had resisted solution for decades or more.&lt;ref name=autogenerated7&gt;Yau and Nadis 2010, p. 165&lt;/ref&gt; These results were presented to mathematicians at a conference at the [[Mathematical Sciences Research Institute]] (MSRI) in [[Berkeley, California]] in May 1991. During this conference, it was noticed that one of the numbers Candelas had computed for the counting of rational curves disagreed with the number obtained by [[Norwegians|Norwegian]] mathematicians [[Geir Ellingsrud]] and Stein Arild Strømme using ostensibly more rigorous techniques.&lt;ref&gt;Yau and Nadis 2010, pp. 169–170&lt;/ref&gt; Many mathematicians at the conference assumed that Candelas's work contained a mistake since it was not based on rigorous mathematical arguments. However, after examining their solution, Ellingsrud and Strømme discovered an error in their computer code and, upon fixing the code, they got an answer that agreed with the one obtained by Candelas and his collaborators.&lt;ref&gt;Yau and Nadis 2010, p. 170&lt;/ref&gt;

In 1990, Edward Witten introduced topological string theory,&lt;ref name=autogenerated9 /&gt; a simplified version of string theory, and physicists showed that there is a version of mirror symmetry for topological string theory.&lt;ref&gt;Vafa 1992; Witten 1992&lt;/ref&gt; This statement about topological string theory is usually taken as the definition of mirror symmetry in the mathematical literature.&lt;ref&gt;Hori et al. 2003, p. xviii&lt;/ref&gt; In an address at the [[International Congress of Mathematicians]] in 1994, mathematician [[Maxim Kontsevich]] presented a new mathematical conjecture based on the physical idea of mirror symmetry in topological string theory. Known as [[homological mirror symmetry]], this conjecture formalizes mirror symmetry as an equivalence of two mathematical structures: the [[derived category]] of [[coherent sheaves]] on a Calabi–Yau manifold and the [[Fukaya category]] of its mirror.&lt;ref&gt;Kontsevich 1995a&lt;/ref&gt;

Also around 1995, Kontsevich analyzed the results of Candelas, which gave a general formula for the problem of counting rational curves on a [[quintic threefold]], and he reformulated these results as a precise mathematical conjecture.&lt;ref&gt;Kontsevich 1995b&lt;/ref&gt; In 1996, [[Alexander Givental]] posted a paper that claimed to prove this conjecture of Kontsevich.&lt;ref&gt;Givental 1996, 1998&lt;/ref&gt; Initially, many mathematicians found this paper hard to understand, so there were doubts about its correctness. Subsequently, Bong Lian, [[Kefeng Liu]], and Shing-Tung Yau published an independent proof in a series of papers.&lt;ref&gt;Lian, Liu, Yau 1997, 1999a, 1999b, 2000&lt;/ref&gt; Despite controversy over who had published the first proof, these papers are now collectively seen as providing a mathematical proof of the results originally obtained by physicists using mirror symmetry.&lt;ref name=autogenerated13&gt;Yau and Nadis 2010, p. 172&lt;/ref&gt; In 2000, Kentaro Hori and Cumrun Vafa gave another physical proof of mirror symmetry based on T-duality.&lt;ref name=autogenerated10 /&gt;

Work on mirror symmetry continues today with major developments in the context of strings on [[Riemann surface|surfaces]] with boundaries.&lt;ref name=developments /&gt; In addition, mirror symmetry has been related to many active areas of mathematics research, such as the [[McKay correspondence]], [[topological quantum field theory]], and the theory of [[wall-crossing|stability conditions]].&lt;ref&gt;Aspinwall et al. 2009, p. vii&lt;/ref&gt; At the same time, basic questions continue to vex. For example, mathematicians still lack an understanding of how to construct examples of mirror Calabi–Yau pairs though there has been progress in understanding this issue.&lt;ref&gt;Zaslow 2008, p. 537&lt;/ref&gt;

==Applications==

===Enumerative geometry===
{{main article|Enumerative geometry}}

[[File:Apollonius8ColorMultiplyV2.svg|thumb|right|alt=Three black circles in the plane and eight additional overlapping circles tangent to these three.|[[Problem of Apollonius|Circles of Apollonius]]: Eight colored circles are tangent to the three black circles. ]]

Many of the important mathematical applications of mirror symmetry belong to the branch of mathematics called enumerative geometry. In enumerative geometry, one is interested in counting the number of solutions to geometric questions, typically using the techniques of [[algebraic geometry]]. One of the earliest problems of enumerative geometry was posed around the year 200 [[BCE]] by the ancient Greek mathematician [[Apollonius of Perga|Apollonius]], who asked how many circles in the plane are tangent to three given circles. In general, the solution to the [[problem of Apollonius]] is that there are eight such circles.&lt;ref name=autogenerated8&gt;Yau and Nadis 2010, p. 166&lt;/ref&gt;

[[File:Clebsch Cublic.png|thumb|right|alt=A complex mathematical surface in three dimensions.|The [[Clebsch cubic]] ]]
Enumerative problems in mathematics often concern a class of geometric objects called [[algebraic varieties]] which are defined by the vanishing of [[polynomial]]s. For example, the [[Clebsch cubic]] (see the illustration) is defined using a certain polynomial of [[degree of a polynomial|degree]] three in four variables. A celebrated result of nineteenth-century mathematicians [[Arthur Cayley]] and [[George Salmon]] states that there are exactly 27 straight lines that lie entirely on such a surface.&lt;ref&gt;Yau and Nadis 2010, p. 167&lt;/ref&gt;

Generalizing this problem, one can ask how many lines can be drawn on a quintic Calabi–Yau manifold, such as the one illustrated above, which is defined by a polynomial of degree five. This problem was solved by the nineteenth-century German mathematician [[Hermann Schubert]], who found that there are exactly 2,875 such lines. In 1986, geometer Sheldon Katz proved that the number of curves, such as circles, that are defined by polynomials of degree two and lie entirely in the quintic is 609,250.&lt;ref name=autogenerated8 /&gt;

By the year 1991, most of the classical problems of enumerative geometry had been solved and interest in enumerative geometry had begun to diminish. According to mathematician Mark Gross, "As the old problems had been solved, people went back to check Schubert's numbers with modern techniques, but that was getting pretty stale."&lt;ref name=autogenerated6&gt;Yau and Nadis 2010, p. 169&lt;/ref&gt; The field was reinvigorated in May 1991 when physicists Philip Candelas, Xenia de la Ossa, Paul Green, and Linda Parkes showed that mirror symmetry could be used to count the number of degree three curves on a quintic Calabi–Yau. Candelas and his collaborators found that these six-dimensional Calabi–Yau manifolds can contain exactly 317,206,375 curves of degree three.&lt;ref name=autogenerated6 /&gt;

In addition to counting degree-three curves on a quintic three-fold, Candelas and his collaborators obtained a number of more general results for counting rational curves which went far beyond the results obtained by mathematicians.&lt;ref&gt;Yau and Nadis 2010, p. 171&lt;/ref&gt; Although the methods used in this work were based on physical intuition, mathematicians have gone on to [[mathematical proof|prove rigorously]] some of the predictions of mirror symmetry. In particular, the enumerative predictions of mirror symmetry have now been rigorously proven.&lt;ref name=autogenerated13 /&gt;

===Theoretical physics===
In addition to its applications in enumerative geometry, mirror symmetry is a fundamental tool for doing calculations in string theory. In the A-model of topological string theory, physically interesting quantities are expressed in terms of infinitely many numbers called [[Gromov–Witten invariant]]s, which are extremely difficult to compute. In the B-model, the calculations can be reduced to classical [[integral]]s and are much easier.&lt;ref&gt;Zaslow 2008, pp. 533–4&lt;/ref&gt; By applying mirror symmetry, theorists can translate difficult calculations in the A-model into equivalent but technically easier calculations in the B-model. These calculations are then used to determine the probabilities of various physical processes in string theory. Mirror symmetry can be combined with other dualities to translate calculations in one theory into equivalent calculations in a different theory. By outsourcing calculations to different theories in this way, theorists can calculate quantities that are impossible to calculate without the use of dualities.&lt;ref&gt;Zaslow 2008, sec. 10&lt;/ref&gt;

Outside of string theory, mirror symmetry is used to understand aspects of [[quantum field theory]], the formalism that physicists use to describe [[elementary particle]]s. For example, [[gauge theory|gauge theories]] are a class of highly symmetric physical theories appearing in the standard model of particle physics and other parts of theoretical physics. Some gauge theories which are not part of the standard model, but which are nevertheless important for theoretical reasons, arise from strings propagating on a nearly singular background. For such theories, mirror symmetry is a useful computational tool.&lt;ref&gt;Hori et al. 2003, p. 677&lt;/ref&gt; Indeed, mirror symmetry can be used to perform calculations in an important gauge theory in four spacetime dimensions that was studied by [[Nathan Seiberg]] and Edward Witten and is also familiar in mathematics in the context of [[Donaldson invariant]]s.&lt;ref&gt;Hori et al. 2003, p. 679&lt;/ref&gt; There is also a generalization of mirror symmetry called [[3D mirror symmetry]] which relates pairs of quantum field theories in three spacetime dimensions.&lt;ref&gt;Intriligator and Seiberg 1996&lt;/ref&gt;

==Approaches==

===Homological mirror symmetry===
{{main article|Homological mirror symmetry}}

[[File:D3-brane et D2-brane.PNG|thumb|right|alt=A pair of surfaces joined by wavy line segments.|Open strings attached to a pair of [[D-brane]]s]]

In string theory and related theories in physics, a ''[[brane]]'' is a physical object that generalizes the notion of a point particle to higher dimensions. For example, a point particle can be viewed as a brane of dimension zero, while a string can be viewed as a brane of dimension one. It is also possible to consider higher-dimensional branes. The word brane comes from the word "membrane" which refers to a two-dimensional brane.&lt;ref&gt;Moore 2005, p. 214&lt;/ref&gt;

In string theory, a string may be open (forming a segment with two endpoints) or closed (forming a closed loop). [[D-brane]]s are an important class of branes that arise when one considers open strings. As an open string propagates through spacetime, its endpoints are required to lie on a D-brane. The letter "D" in D-brane refers to a condition that it satisfies, the [[Dirichlet boundary condition]].&lt;ref&gt;Moore 2005, p. 215&lt;/ref&gt;

Mathematically, branes can be described using the notion of a [[category (mathematics)|category]].&lt;ref&gt;Aspinwall et al. 2009&lt;/ref&gt; This is a mathematical structure consisting of ''objects'', and for any pair of objects, a set of ''[[morphisms]]'' between them. In most examples, the objects are mathematical structures (such as [[set (mathematics)|sets]], [[vector spaces]], or [[topological spaces]]) and the morphisms are [[function (mathematics)|functions]] between these structures.&lt;ref&gt;A basic reference on category theory is Mac Lane 1998.&lt;/ref&gt; One can also consider categories where the objects are D-branes and the morphisms between two branes &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt; are [[wavefunction|states]] of open strings stretched between &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt;.&lt;ref name=autogenerated11&gt;Zaslow 2008, p. 536&lt;/ref&gt;

In the B-model of topological string theory, the D-branes are [[complex manifold|complex submanifold]]s of a Calabi–Yau together with additional data that arise physically from having charges at the endpoints of strings.&lt;ref name=autogenerated11 /&gt; Intuitively, one can think of a submanifold as a surface embedded inside the Calabi–Yau, although submanifolds can also exist in dimensions different from two.&lt;ref name=autogenerated7 /&gt; In mathematical language, the category having these branes as its objects is known as the derived category of coherent sheaves on the Calabi–Yau.&lt;ref name=autogenerated2&gt;Aspinwal et al. 2009, p. 575&lt;/ref&gt; In the A-model, the D-branes can again be viewed as submanifolds of a Calabi–Yau manifold. Roughly speaking, they are what mathematicians call [[special Lagrangian submanifold]]s.&lt;ref name=autogenerated2 /&gt; This means among other things that they have half the dimension of the space in which they sit, and they are length-, area-, or volume-minimizing.&lt;ref name=autogenerated12&gt;Yau and Nadis 2010, p. 175&lt;/ref&gt; The category having these branes as its objects is called the Fukaya category.&lt;ref name=autogenerated2 /&gt;

The derived category of coherent sheaves is constructed using tools from [[complex geometry]], a branch of mathematics that describes geometric curves in algebraic terms and solves geometric problems using [[algebraic equation]]s.&lt;ref&gt;Yau and Nadis 2010, pp. 180–1&lt;/ref&gt; On the other hand, the Fukaya category is constructed using [[symplectic geometry]], a branch of mathematics that arose from studies of [[classical physics]]. Symplectic geometry studies spaces equipped with a [[symplectic form]], a mathematical tool that can be used to compute [[area]] in two-dimensional examples.&lt;ref name=autogenerated5 /&gt;

The homological mirror symmetry conjecture of Maxim Kontsevich states that the derived category of coherent sheaves on one Calabi–Yau manifold is equivalent in a certain sense to the Fukaya category of its mirror.&lt;ref&gt;Aspinwall et al. 2009, p. 616&lt;/ref&gt; This equivalence provides a precise mathematical formulation of mirror symmetry in topological string theory. In addition, it provides an unexpected bridge between two branches of geometry, namely complex and symplectic geometry.&lt;ref&gt;Yau and Nadis 2010, p. 181&lt;/ref&gt;

===Strominger–Yau–Zaslow conjecture===
{{main article|SYZ conjecture}}
[[File:Torus cycles2.svg|thumb|right|alt=A donut shape with two circles drawn on its surface, one going around the hole and the other going through it.|A [[torus]] can be viewed as a [[union (set theory)|union]] of infinitely many circles such as the red one in the picture. There is one such circle for each point on the pink circle.]]
Another approach to understanding mirror symmetry was suggested by Andrew Strominger, Shing-Tung Yau, and [[Eric Zaslow]] in 1996.&lt;ref name=autogenerated3 /&gt; According to their conjecture, now known as the SYZ conjecture, mirror symmetry can be understood by dividing a Calabi–Yau manifold into simpler pieces and then transforming them to get the mirror Calabi–Yau.&lt;ref&gt;Yau and Nadis 2010, p. 174&lt;/ref&gt;

The simplest example of a Calabi–Yau manifold is a two-dimensional [[torus]] or donut shape.&lt;ref&gt;Zaslow 2008, p. 533&lt;/ref&gt; Consider a circle on this surface that goes once through the hole of the donut. An example is the red circle in the figure. There are infinitely many circles like it on a torus; in fact, the entire surface is a [[union (set theory)|union]] of such circles.&lt;ref&gt;Yau and Nadis 2010, p.&amp;nbsp;175–6&lt;/ref&gt;

One can choose an auxiliary circle &lt;math&gt;B&lt;/math&gt; (the pink circle in the figure) such that each of the infinitely many circles decomposing the torus passes through a point of &lt;math&gt;B&lt;/math&gt;. This auxiliary circle is said to ''parametrize'' the circles of the decomposition, meaning there is a correspondence between them and points of &lt;math&gt;B&lt;/math&gt;. The circle &lt;math&gt;B&lt;/math&gt; is more than just a list, however, because it also determines how these circles are arranged on the torus. This auxiliary space plays an important role in the SYZ conjecture.&lt;ref name=autogenerated12 /&gt;

The idea of dividing a torus into pieces parametrized by an auxiliary space can be generalized. Increasing the dimension from two to four real dimensions, the Calabi–Yau becomes a [[K3 surface]]. Just as the torus was decomposed into circles, a four-dimensional K3 surface can be decomposed into two-dimensional tori. In this case the space &lt;math&gt;B&lt;/math&gt; is an ordinary [[sphere]]. Each point on the sphere corresponds to one of the two-dimensional tori, except for twenty-four "bad" points corresponding to "pinched" or [[mathematical singularity|singular]] tori.&lt;ref name=autogenerated12 /&gt;

The Calabi–Yau manifolds of primary interest in string theory have six dimensions. One can divide such a manifold into [[3-torus|3-tori]] (three-dimensional objects that generalize the notion of a torus) parametrized by a [[3-sphere]] &lt;math&gt;B&lt;/math&gt; (a three-dimensional generalization of a sphere). Each point of &lt;math&gt;B&lt;/math&gt; corresponds to a 3-torus, except for infinitely many "bad" points which form a grid-like pattern of segments on the Calabi–Yau and correspond to singular tori.&lt;ref&gt;Yau and Nadis 2010, pp. 175–7.&lt;/ref&gt;

Once the Calabi–Yau manifold has been decomposed into simpler parts, mirror symmetry can be understood in an intuitive geometric way. As an example, consider the torus described above. Imagine that this torus represents the "spacetime" for a [[physical theory]]. The fundamental objects of this theory will be strings propagating through the spacetime according to the rules of [[quantum mechanics]]. One of the basic dualities of string theory is T-duality, which states that a string propagating around a circle of radius &lt;math&gt;R&lt;/math&gt; is equivalent to a string propagating around a circle of radius &lt;math&gt;1/R&lt;/math&gt; in the sense that all observable quantities in one description are identified with quantities in the dual description.&lt;ref name=autogenerated4&gt;Zaslow 2008, p. 532&lt;/ref&gt; For example, a string has [[momentum]] as it propagates around a circle, and it can also wind around the circle one or more times. The number of times the string winds around a circle is called the [[winding number]]. If a string has momentum &lt;math&gt;p&lt;/math&gt; and winding number &lt;math&gt;n&lt;/math&gt; in one description, it will have momentum &lt;math&gt;n&lt;/math&gt; and winding number &lt;math&gt;p&lt;/math&gt; in the dual description.&lt;ref name=autogenerated4 /&gt; By applying T-duality simultaneously to all of the circles that decompose the torus, the radii of these circles become inverted, and one is left with a new torus which is "fatter" or "skinnier" than the original. This torus is the mirror of the original Calabi–Yau.&lt;ref&gt;Yau and Nadis 2010, p. 178&lt;/ref&gt;

T-duality can be extended from circles to the two-dimensional tori appearing in the decomposition of a K3 surface or to the three-dimensional tori appearing in the decomposition of a six-dimensional Calabi–Yau manifold. In general, the SYZ conjecture states that mirror symmetry is equivalent to the simultaneous application of T-duality to these tori. In each case, the space &lt;math&gt;B&lt;/math&gt; provides a kind of blueprint that describes how these tori are assembled into a Calabi–Yau manifold.&lt;ref&gt;Yau and Nadis 2010, p. 178–9&lt;/ref&gt;

==See also==
* [[Donaldson–Thomas theory]]
* [[Wall-crossing]]

==Notes==
{{reflist|30em}}

==References==
{{refbegin|30em}}
* {{cite book |editor1-first=Paul |editor1-last=Aspinwall |editor2-first=Tom |editor2-last=Bridgeland |editor3-first=Alastair |editor3-last=Craw |editor4-first=Michael |editor4-last=Douglas |editor5-first=Mark |editor5-last=Gross |editor6-first=Anton |editor6-last=Kapustin |editor7-first=Gregory |editor7-last=Moore |editor8-first=Graeme |editor8-last=Segal |editor9-first=Balázs |editor9-last=Szendröi |editor10-first=P.M.H. |editor10-last=Wilson |title=Dirichlet Branes and Mirror Symmetry |year=2009 |publisher=American Mathematical Society | series = [[Clay Mathematics Monographs]] | volume = 4 | isbn=978-0-8218-3848-8}}
* {{cite journal |last=Candelas |first=Philip |last2=de la Ossa |first2=Xenia |last3=Green |first3=Paul |last4=Parkes |first4=Linda |year=1991 |title=A pair of Calabi–Yau manifolds as an exactly soluble superconformal field theory |journal=Nuclear Physics B |volume=359 |issue=1 |pages=21–74 |doi=10.1016/0550-3213(91)90292-6 |bibcode = 1991NuPhB.359...21C }}
* {{cite journal |last1=Candelas |first1=Philip |last2=Horowitz |first2=Gary |last3=Strominger |first3= Andrew |last4=Witten |first4=Edward |year=1985 |title=Vacuum configurations for superstrings |journal=Nuclear Physics B |volume=258 |issue= |pages=46–74|bibcode = 1985NuPhB.258...46C |doi=10.1016/0550-3213(85)90602-9 }}
* {{cite journal |last1=Candelas |first1=Philip |last2=Lynker |first2=Monika |last3=Schimmrigk |first3=Rolf |year=1990 |title=Calabi–Yau manifolds in weighted &lt;math&gt;\mathbb{P}_4&lt;/math&gt; |journal=Nuclear Physics B |volume=341 |issue=1 |pages=383–402 |doi=10.1016/0550-3213(90)90185-G|bibcode=1990NuPhB.341..383C }}
* {{cite journal |last1=Dixon |first1=Lance |year=1988 |title=Some world-sheet properties of superstring compactifications, on orbifolds and otherwise |journal=ICTP Ser. Theoret. Phys. |volume=4 |pages=67–126 |isbn=978-9971-5-0452-6}}
* {{cite journal |last1=Givental |first1=Alexander |year=1996 |title=Equivariant Gromov-Witten invariants |journal=International Mathematics Research Notices |volume=1996 |issue=13 |pages=613–663 |doi=10.1155/S1073792896000414}}
* {{cite journal |last1=Givental |first1=Alexander |year=1998 |title=A mirror theorem for toric complete intersections |journal=Topological field theory, primitive forms and related topics |pages=141–175 |doi=10.1007/978-1-4612-0705-4_5|isbn=978-1-4612-6874-1 |arxiv=alg-geom/9701016 }}
* {{cite book |last1=Greene |first1=Brian |title=[[The Elegant Universe: Superstrings, Hidden Dimensions, and the Quest for the Ultimate Theory]]|year=2000 |publisher=Random House |isbn=978-0-9650888-0-0}}
* {{cite journal |last=Greene |first=Brian |last2=Plesser |first2=Ronen |year=1990 |title=Duality in Calabi–Yau moduli space |journal=Nuclear Physics B |volume=338 |issue=1 |pages=15–37|bibcode=1990NuPhB.338...15G |doi=10.1016/0550-3213(90)90622-K }}
* {{cite book|editor1-first=Kentaro |editor1-last=Hori |editor2-first=Sheldon |editor2-last=Katz |editor3-first=Albrecht |editor3-last=Klemm |editor4-first=Rahul |editor4-last=Pandharipande |editor5-first=Richard |editor5-last=Thomas |editor6-first=Cumrun |editor6-last=Vafa |editor7-first=Ravi |editor7-last=Vakil |editor8-first=Eric |editor8-last=Zaslow |title=Mirror Symmetry |year=2003 |series=[[Clay Mathematics Monographs]]|volume=1|publisher=American Mathematical Society |url=http://math.stanford.edu/~vakil/files/mirrorfinal.pdf |isbn=0-8218-2955-6 |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20060919020706/http://math.stanford.edu/~vakil/files/mirrorfinal.pdf |archivedate=2006-09-19 |df= }}
* {{cite arXiv |last1=Hori |first1=Kentaro |last2=Vafa |first2=Cumrun |eprint=hep-th/0002222 |title=Mirror Symmetry |year=2000}}
* {{cite journal |last1=Intriligator |first1=Kenneth |last2=Seiberg |first2=Nathan |title=Mirror symmetry in three-dimensional gauge theories |journal=Physics Letters B |year=1996 |volume=387 |issue=3 |pages=513–519 |doi=10.1016/0370-2693(96)01088-X|bibcode=1996PhLB..387..513I |arxiv = hep-th/9607207 }}
* {{cite journal |last1=Kikkawa |first1=Keiji |last2=Yamasaki |first2=Masami |year=1984 |title=Casimir effects in superstring theories |journal=Physics Letters B |volume=149 |issue=4 |pages=357–360|bibcode = 1984PhLB..149..357K |doi = 10.1016/0370-2693(84)90423-4 }}
* {{Citation |last=Kontsevich |first=Maxim |date=1995a |publisher=Birkhäuser |doi=10.1007/978-1-4612-4264-2_12|contribution=Enumeration of Rational Curves Via Torus Actions |title=The Moduli Space of Curves |isbn=978-1-4612-8714-8 |page=335 |arxiv=hep-th/9405035 }}
* {{cite journal |last1=Kontsevich |first1=Maxim |year=1995b |title=Homological algebra of mirror symmetry |journal=Proceedings of the International Congress of Mathematicians |pages=120–139|bibcode=1994alg.geom.11018K |arxiv=alg-geom/9411018 }}
* {{cite journal |last1=Lerche |first1=Wolfgang |last2=Vafa |first2=Cumrun |last3=Warner |first3=Nicholas |year=1989 |title=Chiral rings in &lt;math&gt;\mathcal{N} = 2&lt;/math&gt; superconformal theories |journal=Nuclear Physics B |volume=324 |issue=2 |pages=427–474|bibcode = 1989NuPhB.324..427L |doi = 10.1016/0550-3213(89)90474-4 }}
* {{cite journal |last1=Lian |first1=Bong |last2=Liu |first2=Kefeng |last3=Yau |first3=Shing-Tung |year=1997 |title=Mirror principle, I |journal=Asian Journal of Mathematics |volume=1 |issue=4 |pages=729–763|bibcode=1997alg.geom.12011L |arxiv=alg-geom/9712011 |doi=10.4310/ajm.1997.v1.n4.a5}}
* {{cite journal |last1=Lian |first1=Bong |last2=Liu |first2=Kefeng |last3=Yau |first3=Shing-Tung |year=1999a |title=Mirror principle, II |journal=Asian Journal of Mathematics |volume=3 |pages=109–146|bibcode=1999math......5006L |arxiv=math/9905006 |doi=10.4310/ajm.1999.v3.n1.a6}}
* {{cite journal |last1=Lian |first1=Bong |last2=Liu |first2=Kefeng |last3=Yau |first3=Shing-Tung |year=1999b |title=Mirror principle, III |journal=Asian Journal of Mathematics |volume=3 |issue=4 |pages=771–800|bibcode=1999math.....12038L |arxiv=math/9912038 |doi=10.4310/ajm.1999.v3.n4.a4}}
* {{cite journal |last1=Lian |first1=Bong |last2=Liu |first2=Kefeng |last3=Yau |first3=Shing-Tung |year=2000 |title=Mirror principle, IV |journal=Surveys in Differential Geometry |pages=475–496|bibcode=2000math......7104L |arxiv=math/0007104 |doi=10.4310/sdg.2002.v7.n1.a15 |volume=7}}
* {{cite book |last1=Mac Lane |first1=Saunders |title=Categories for the Working Mathematician |year=1998 |isbn=978-0-387-98403-2}}
* {{cite journal| author=Moore, Gregory | title=What is&amp;nbsp;... a Brane?| journal=Notices of the AMS| year=2005 | url=http://www.ams.org/notices/200502/what-is.pdf |format=PDF| accessdate=6 August 2016 |page=214|  volume=52}}
* {{cite journal |last1=Sakai |first1=Norisuke |last2=Senda |first2=Ikuo |year=1986 |title=Vacuum energies of string compactified on torus |journal=Progress of Theoretical Physics |volume=75 |issue=3 |pages=692–705|bibcode = 1986PThPh..75..692S |doi = 10.1143/PTP.75.692 }}
* {{cite journal |last1=Strominger |first1=Andrew |last2=Yau |first2=Shing-Tung |last3=Zaslow |first3=Eric |year=1996 |title=Mirror symmetry is T-duality |journal=Nuclear Physics B |volume=479 |issue=1 |pages=243–259|arxiv = hep-th/9606040 |bibcode = 1996NuPhB.479..243S |doi = 10.1016/0550-3213(96)00434-8 }}
* {{cite journal |last1=Vafa |first1=Cumrun |year=1992 |title=Topological mirrors and quantum rings |journal=Essays on mirror manifolds |pages=96–119|bibcode=1991hep.th...11017V |isbn=978-962-7670-01-8 |arxiv=hep-th/9111017 }}
* {{cite book |last1=Wald |first1=Robert |title=General Relativity |year=1984 |publisher=University of Chicago Press |isbn=978-0-226-87033-5 }}
* {{cite journal |last1=Witten |first1=Edward |year=1990 |title=On the structure of the topological phase of two-dimensional gravity |journal=Nuclear Physics B |volume=340 |issue=2–3 |pages=281–332|bibcode = 1990NuPhB.340..281W |doi = 10.1016/0550-3213(90)90449-N }}
* {{cite journal |last1=Witten |first1=Edward |year=1992 |title=Mirror manifolds and topological field theory |journal=Essays on mirror manifolds |pages=121–160 |isbn=978-962-7670-01-8}}
* {{Cite book| first1 = Shing-Tung | last1 = Yau | first2 = Steve | last2 = Nadis | year = 2010 | title = The Shape of Inner Space: String Theory and the Geometry of the Universe's Hidden Dimensions | publisher = Basic Books | isbn = 978-0-465-02023-2 }}
* {{Cite book| last1=Zaslow | first1=Eric | contribution=Mirror Symmetry | year=2008 | title=[[The Princeton Companion to Mathematics]] | editor-last=Gowers | editor-first=Timothy | isbn=978-0-691-11880-2 }}
* {{cite book |last1=Zwiebach |first1=Barton |title=A First Course in String Theory |year=2009 |publisher=Cambridge University Press |isbn=978-0-521-88032-9}}

{{refend}}

==Further reading==

===Popularizations===
* {{Cite book| first1 = Shing-Tung | last1 = Yau | first2 = Steve | last2 = Nadis | year = 2010 | title = The Shape of Inner Space: String Theory and the Geometry of the Universe's Hidden Dimensions | publisher = Basic Books | isbn = 978-0-465-02023-2 }}
* {{cite arXiv |last=Zaslow |first=Eric |eprint=physics/0506153 |title=Physmatics |year=2005 }}
* {{Cite book| last1=Zaslow | first1=Eric | contribution=Mirror Symmetry | year=2008 | title=The Princeton Companion to Mathematics | editor-last=Gowers | editor-first=Timothy | isbn=978-0-691-11880-2 }}

===Textbooks===
* {{cite book |editor1-first=Paul |editor1-last=Aspinwall |editor2-first=Tom |editor2-last=Bridgeland |editor3-first=Alastair |editor3-last=Craw |editor4-first=Michael |editor4-last=Douglas |editor5-first=Mark |editor5-last=Gross |editor6-first=Anton |editor6-last=Kapustin |editor7-first=Gregory |editor7-last=Moore |editor8-first=Graeme |editor8-last=Segal |editor9-first=Balázs |editor9-last=Szendröi |editor10-first=P.M.H. |editor10-last=Wilson |title=Dirichlet Branes and Mirror Symmetry |year=2009 |publisher=American Mathematical Society | isbn=978-0-8218-3848-8}}
* {{cite book |last1=Cox |first1=David |last2=Katz |first2=Sheldon |title=Mirror symmetry and algebraic geometry |year=1999 |publisher=American Mathematical Society |isbn=978-0-8218-2127-5}}
* {{cite book|editor1-first=Kentaro |editor1-last=Hori |editor2-first=Sheldon |editor2-last=Katz |editor3-first=Albrecht |editor3-last=Klemm |editor4-first=Rahul |editor4-last=Pandharipande |editor5-first=Richard |editor5-last=Thomas |editor6-first=Cumrun |editor6-last=Vafa |editor7-first=Ravi |editor7-last=Vakil |editor8-first=Eric |editor8-last=Zaslow |title=Mirror Symmetry |year=2003 |publisher=American Mathematical Society |url=http://math.stanford.edu/~vakil/files/mirrorfinal.pdf |isbn=0-8218-2955-6 |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20060919020706/http://math.stanford.edu/~vakil/files/mirrorfinal.pdf |archivedate=2006-09-19 |df= }}

{{featured article}}
{{String theory topics |state=collapsed}}
{{DEFAULTSORT:Mirror Symmetry (String Theory)}}
[[Category:Algebraic geometry]]
[[Category:Symplectic geometry]]
[[Category:Mathematical physics]]
[[Category:String theory]]</text>
      <sha1>sgtfky197mkr9e8wuha4oa6zk936vf6</sha1>
    </revision>
  </page>
  <page>
    <title>Müntz–Szász theorem</title>
    <ns>0</ns>
    <id>3204608</id>
    <revision>
      <id>845384781</id>
      <parentid>726291261</parentid>
      <timestamp>2018-06-11T12:45:05Z</timestamp>
      <contributor>
        <ip>2003:F3:2BC0:6400:2C13:F9FB:C656:8FB2</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2121">The '''Müntz–Szász theorem''' is a basic result of [[approximation theory]], proved by [[Herman Müntz]] in 1914 and [[Otto Szász]] (1884–1952) in 1916. Roughly speaking, the theorem shows to what extent the [[Weierstrass theorem on polynomial approximation]] can have holes dug into it, by restricting certain coefficients in the polynomials to be zero. The form of the result had been conjectured by [[Sergei Bernstein]] before it was proved.

The theorem, in a special case, states that a necessary and sufficient condition for the [[monomial]]s

:&lt;math&gt;x^n,\quad n\in S\subset\mathbb N&lt;/math&gt;

to span a [[dense subset]] of the [[Banach space]] ''C''[''a'',''b''] of all [[continuous function]]s with [[complex number]] values on the [[closed interval]] [''a'',''b''] with ''a'' &gt; 0, with the [[uniform norm]], is that the sum

:&lt;math&gt;\sum_{n\in S}\frac{1}{n}\ &lt;/math&gt;

of the reciprocals, taken over ''S'', should [[divergent series|diverge]], i.e. ''S'' is a [[Large set (combinatorics)|large set]]. For an interval [0, ''b''], the [[constant function]]s are necessary: assuming therefore that 0 is in ''S'', the condition on the other exponents is as before.

More generally, one can take exponents from any [[strictly increasing]] sequence of positive real numbers, and the same result holds. Szász showed that for complex number exponents, the same condition applied to the sequence of [[real part]]s.

There are also versions for the [[Lp space|''L''&lt;sub&gt;''p''&lt;/sub&gt; spaces]].

==References==

*Müntz, Ch. H., ''Über den Approximationssatz von Weierstrass'', (1914) in H. A. Schwarz's Festschrift, Berlin, pp.&amp;nbsp;303–312. [http://quod.lib.umich.edu/u/umhistmath/aca0698.0001.001/316?view=image&amp;size=125 Scanned at University of Michigan]
*Szász, O.,'' Über die Approximation stetiger Funktionen durch lineare Aggregate von Potenzen'', Math. Ann., 77 (1916), pp.&amp;nbsp;482–496. [http://www.digizeitschriften.de/dms/resolveppn/?PPN=GDZPPN002266563 Scanned at digizeitschriften.de]

{{DEFAULTSORT:Muntz-Szasz Theorem}}
[[Category:Functional analysis]]
[[Category:Theorems in approximation theory]]</text>
      <sha1>cbuiu1h40jx8vpd20bzgt2iqdbu76fv</sha1>
    </revision>
  </page>
  <page>
    <title>Operator grammar</title>
    <ns>0</ns>
    <id>6370069</id>
    <revision>
      <id>838031276</id>
      <parentid>817977915</parentid>
      <timestamp>2018-04-24T14:22:40Z</timestamp>
      <contributor>
        <ip>67.198.37.16</ip>
      </contributor>
      <comment>/* Likelihood */ [[link grammar]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10048">{{About||the class of formal computer languages|operator-precedence grammar}}

'''Operator grammar''' is a [[mathematical]] theory of human language that explains how language carries [[information]]. This theory is the culmination of the life work of [[Zellig Harris]], with major [[#Bibliography|publications]] toward the end of the last century. Operator Grammar proposes that each human language is a [[self-organizing]] system in which both the [[syntax|syntactic]] and [[semantics|semantic]] properties of a word are established purely in relation to other words. Thus, no external system ([[metalanguage]]) is required to define the rules of a language. Instead, these rules are learned through exposure to usage and through participation, as is the case with most [[social construction|social behavior]]. The theory is consistent with the idea that [[origin of language|language evolved]] gradually, with each successive generation introducing new complexity and variation.

Operator Grammar posits three [[linguistic universal|universal]] constraints: [[#Dependency|dependency]] (certain words depend on the presence of other words to form an utterance), [[#Likelihood|likelihood]] (some combinations of words and their dependents are more likely than others) and [[#Reduction|reduction]] (words in high likelihood combinations can be reduced to shorter forms, and sometimes omitted completely). Together these provide a theory of [[#Information|language information]]: dependency builds a [[relation (mathematics)|predicate–argument structure]]; likelihood creates distinct meanings; reduction allows compact forms for communication.

==Dependency==

The fundamental mechanism of operator grammar is the dependency constraint: certain words ([[Operator (linguistics)|operators]]) require that one or more words (arguments) be present in an utterance. In the sentence ''John wears boots'', the operator ''wears'' requires the presence of two arguments, such as ''John'' and ''boots''. (This definition of dependency differs from other [[dependency grammar]]s in which the arguments are said to depend on the operators.)

In each language the dependency relation among words gives rise to [[part of speech|syntactic categories]] in which the allowable arguments of an operator are defined in terms of their dependency requirements. Class N contains words (e.g. ''John'', ''boots'') that do not require the presence of other words. Class O&lt;sub&gt;N&lt;/sub&gt; contains the words (e.g. ''sleeps'') that require exactly one word of type N. Class O&lt;sub&gt;NN&lt;/sub&gt; contains the words (e.g. ''wears'') that require two words of type N. Class O&lt;sub&gt;OO&lt;/sub&gt; contains the words (e.g. ''because'') that require two words of type O, as in ''John stumbles because John wears boots''. Other classes include O&lt;sub&gt;O&lt;/sub&gt; (''is possible''), O&lt;sub&gt;NNN&lt;/sub&gt; (''put''), O&lt;sub&gt;ON&lt;/sub&gt; (''with'', ''surprise''), O&lt;sub&gt;NO&lt;/sub&gt; (''know''), O&lt;sub&gt;NNO&lt;/sub&gt;  (''ask'') and O&lt;sub&gt;NOO&lt;/sub&gt;  (''attribute'').

The categories in operator grammar are [[linguistic universal|universal]] and are defined purely in terms of how words relate to other words, and do not rely on an external set of categories such as noun, verb, adjective, adverb, preposition, conjunction, etc. The dependency properties of each word are observable through usage and therefore learnable.

==Likelihood==

The dependency constraint creates a structure (syntax) in which any word of the appropriate class can be an argument for a given operator. The likelihood constraint places additional restrictions on this structure by making some operator/argument combinations more likely than others. Thus, ''John wears hats'' is more likely than ''John wears snow'' which in turn is more likely than ''John wears vacation''. The likelihood constraint creates meaning (semantics) by defining each word in terms of the words it can take as arguments, or of which it can be an argument.

Each word has a unique set of words with which it has been observed to occur called its [[selection (linguistics)|selection]]. The '''coherent selection''' of a word is the set of words for which the dependency relation has above average likelihood. Words that are similar in meaning have similar coherent selection.  This approach to meaning is self-organizing in that no external system is necessary to define what words mean. Instead, the meaning of the word is determined by its usage within a population of speakers. Patterns of frequent use are observable and therefore learnable. New words can be introduced at any time and defined through usage.

In this sense, [[link grammar]] could be viewed as a kind of operator grammar, in that the linkage of words is determined entirely by their context, and that each selection is assigned a log-likelihood.

==Reduction==

The reduction constraint acts on high likelihood combinations of operators and arguments and makes more compact forms. Certain reductions allow words to be omitted completely from an utterance. For example, ''I expect John to come'' is reducible to ''I expect John'', because ''to come'' is highly likely under ''expect''. The sentence ''John wears boots and John wears hats'' can be reduced to ''John wears boots and hats'' because repetition of the first argument ''John'' under the operator ''and'' is highly likely. ''John reads things'' can be reduced to ''John reads'', because the argument ''things'' has high likelihood of occurring under any operator.

Certain reductions reduce words to shorter forms, creating pronouns, suffixes and prefixes ([[morphology (linguistics)|morphology]]). ''John wears boots and John wears hats'' can be reduced to ''John wears boots and he wears hats'', where the pronoun ''he'' is a reduced form of ''John''. Suffixes and prefixes can be obtained by appending other freely occurring words, or variants of these. ''John is able to be liked'' can be reduced to ''John is likeable''. ''John is thoughtful'' is reduced from ''John is full of thought'', and ''John is anti-war'' from ''John is against war''.

Modifiers are the result of several of these kinds of reductions, which give rise to adjectives, adverbs, [[prepositional phrase]]s, [[subordinate clause]]s, etc.

# ''John wears boots; the boots are of leather'' (two sentences joined by [[semicolon]] operator) →
# ''John wears boots which are of leather'' (reduction of repeated noun to [[relative pronoun]]) →
# ''John wears boots of leather'' (omission of high likelihood phrase ''which are'') →
# ''John wears leather boots'' (omission of high likelihood operator ''of'', [[Transposition (mathematics)|transposition]] of short modifier to left of noun)

Each language has a unique set of reductions. For example, some languages have morphology and some don’t; some transpose short modifiers and some do not. Each word in a language participates only in certain kinds of reductions. However, in each case, the reduced material can be reconstructed from knowledge of what is likely in the given operator/argument combination. The reductions in which each word participates are observable and therefore learnable, just as one learns a word’s dependency and likelihood properties.

==Information==

The importance of reductions in operator grammar is that they separate sentences that contain reduced forms from those that don’t (base sentences). All reductions are [[paraphrase]]s, since they do not remove any information, just make sentences more compact. Thus, the base sentences contain all the information of the language and the reduced sentences are variants of these. Base sentences are made up of simple words without modifiers and largely without affixes, e.g. ''snow falls'', ''sheep eat grass'', ''John knows sheep eat grass'', ''that sheep eat snow surprises John''.

Each operator in a sentence makes a contribution in information according to its likelihood of occurrence with its arguments. Highly expected combinations have low information; rare combinations have high information. The precise contribution of an operator is determined by its selection, the set of words with which it occurs with high frequency. The arguments ''boots'', ''hats'', ''sheep'', ''grass'' and ''snow'' differ in meaning according to the operators for which they can appear with high likelihood in first or second argument position. For example, ''snow'' is expected as first argument of ''fall'' but not of ''eat'', while the reverse is true of ''sheep''. Similarly, the operators ''eat'', ''devour'', ''chew'' and ''swallow'' differ in meaning to the extent that the arguments they select and the operators that select them differ.

Operator grammar predicts that the information carried by a sentence is the accumulation of contributions of each argument and operator. The increment of information that a given word adds to a new sentence is determined by how it was used before. In turn, new usages stretch or even alter the information content associated with a word. Because this process is based on high frequency usage, the meanings of words are relatively stable over time, but can change in accordance with the needs of a linguistic community.

==Bibliography==
*{{Citation
 | last=[[Zellig Harris|Harris]]
 | first=Zellig
 | title=A Grammar of English on Mathematical Principles
 | publisher=New York: John Wiley and Sons
 | year=1982
 | ISBN=0-471-02958-0
 }}
*{{Citation
 | last=[[Zellig Harris|Harris]]
 | first=Zellig
 | title=Language and Information
 | publisher=New York: Columbia University Press
 | year=1988
 | ISBN=0-231-06662-7
 }}
*{{Citation
 | last=[[Zellig Harris|Harris]]
 | first=Zellig
 | title=The Form of Information in Science: Analysis of an immunology sublanguage
 | publisher=Springer
 | year=1989
 | ISBN=90-277-2516-0
 }}
*{{Citation
 | last=[[Zellig Harris|Harris]]
 | first=Zellig
 | title=A Theory of Language and Information: A Mathematical Approach
 | publisher=Oxford University Press, USA
 | year=1991
 | ISBN=0-19-824224-7
 }}

[[Category:Grammar frameworks]]
[[Category:Information theory]]</text>
      <sha1>bnsjues6qnd9hac2vkjflfm9wfzenjq</sha1>
    </revision>
  </page>
  <page>
    <title>Paraconsistent logic</title>
    <ns>0</ns>
    <id>421085</id>
    <revision>
      <id>868872477</id>
      <parentid>868859089</parentid>
      <timestamp>2018-11-15T00:04:35Z</timestamp>
      <contributor>
        <username>Trade</username>
        <id>30525710</id>
      </contributor>
      <comment>Rescuing 3 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36904">{{citations missing|date=April 2018}}
A '''paraconsistent logic''' is a [[logical system]] that attempts to deal with [[contradiction]]s in a discriminating way. Alternatively, paraconsistent logic is the subfield of [[logic]] that is concerned with studying and developing paraconsistent (or "inconsistency-tolerant") systems of logic.

Inconsistency-tolerant logics have been discussed since at least 1910 (and arguably much earlier, for example in the writings of [[Aristotle]]);&lt;ref&gt;{{cite web|url=http://plato.stanford.edu/entries/logic-paraconsistent/|title=Paraconsistent Logic|publisher=''[[Stanford Encyclopedia of Philosophy]]''|accessdate=1 December 2015|archive-url=https://web.archive.org/web/20151211014311/http://plato.stanford.edu/entries/logic-paraconsistent/#|archive-date=2015-12-11|dead-url=no|df=}}&lt;/ref&gt; however, the term ''paraconsistent'' ("beside the consistent") was not coined until 1976, by the [[Peru]]vian [[philosopher]] [[Francisco Miró Quesada]].&lt;ref&gt;Priest (2002), p. 288 and §3.3.&lt;/ref&gt;

==Definition==
In [[classical logic]] (as well as [[intuitionistic logic]] and most other logics), contradictions [[Entailment|entail]] everything. This curious feature, known as the [[principle of explosion]] or ''ex contradictione sequitur quodlibet'' ([[Latin]], "from a contradiction, anything follows")&lt;ref&gt;Carnielli, W. and Marcos, J. (2001) [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.107.70 "Ex contradictione non sequitur quodlibet"] {{Webarchive|url=https://web.archive.org/web/20121016215431/http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.107.70# |date=2012-10-16 }} ''Proc. 2nd Conf. on Reasoning and Logic'' (Bucharest, July 2000)&lt;/ref&gt; can be expressed formally as

{| class="wikitable" style="width:400px;"
|-
| 1
| align="center" | &lt;math&gt;P \land\neg P&lt;/math&gt;
| colspan="2" | Premise
|-
| 2
| align="center" | &lt;math&gt;P\,&lt;/math&gt;
| [[Simplification (logic)|Conjunctive elimination]]
| align="center" | from 1
|-
| 3
| align="center" | &lt;math&gt;P \lor A&lt;/math&gt;
| [[Addition (logic)|Disjunction introduction]]
| align="center" | from 2
|-
| 4
| align="center" | &lt;math&gt;\neg P\,&lt;/math&gt;
| Conjunctive elimination 
| align="center" | from 1
|-
| 5
| align="center" | &lt;math&gt;A\,&lt;/math&gt;
| [[Disjunctive syllogism]]
| align="center" | from 3 and 4
|}

Which means: if ''P'' and its negation ¬''P'' are both assumed to be true, then ''P'' is assumed to be true, from which it follows that at least one of the claims ''P'' and some other (arbitrary) claim ''A'' is true. However, if we know that either ''P'' or ''A'' is true, and also that ''P'' is not true (that ¬''P'' is true) we can conclude that ''A'', which could be anything, is true. Thus if a [[theory]] contains a single inconsistency, it is [[trivialism|trivial]]—that is, it has every sentence as a theorem.

The characteristic or defining feature of a paraconsistent logic is that it rejects the principle of explosion. As a result, paraconsistent logics, unlike classical and other logics, can be used to formalize inconsistent but non-trivial theories.

==Paraconsistent logics and classical logic==
Paraconsistent logics are [[propositional calculus|propositionally]] ''weaker'' than [[classical logic]]; that is, they deem ''fewer'' propositional inferences valid. The point is that a paraconsistent logic can never be a propositional extension of classical logic, that is, propositionally validate everything that classical logic does. In some sense, then, paraconsistent logic is more conservative or cautious than classical logic. It is due to such conservativeness that paraconsistent languages can be more ''expressive'' than their classical counterparts including the hierarchy of [[metalanguage]]s due to [[Alfred Tarski]] et al. According to [[Solomon Feferman]] [1984]: ''"…natural language abounds with directly or indirectly self-referential yet apparently harmless expressions—all of which are excluded from the Tarskian framework."'' This expressive limitation can be overcome in paraconsistent logic.

== Motivation ==
A primary motivation for paraconsistent logic is the conviction that it ought to be possible to reason with inconsistent [[information]] in a controlled and discriminating way. The principle of explosion precludes this, and so must be abandoned. In non-paraconsistent logics, there is only one inconsistent theory: the trivial theory that has every sentence as a theorem. Paraconsistent logic makes it possible to distinguish between inconsistent theories and to reason with them.

Research into paraconsistent logic has also led to the establishment of the philosophical school of [[dialetheism]] (most notably advocated by [[Graham Priest]]), which asserts that true contradictions exist in reality, for example groups of people holding opposing views on various moral issues.&lt;ref name="Fisher2007"&gt;{{cite book|author=Jennifer Fisher|title=On the Philosophy of Logic|url=https://books.google.com/books?id=k8L_YW-lEEQC&amp;pg=PT142|year=2007|publisher=Cengage Learning|isbn=978-0-495-00888-0|pages=132–134}}&lt;/ref&gt; Being a dialetheist rationally commits one to some form of paraconsistent logic, on pain of otherwise embracing [[trivialism]], i.e. accepting that all contradictions (and equivalently all statements) are true.&lt;ref name="GabbayWoods2007"&gt;{{cite book|editor1=Dov M. Gabbay|editor2=John Woods|title=The Many Valued and Nonmonotonic Turn in Logic|url=https://books.google.com/books?id=3TNj1ZkP3qEC&amp;pg=PA131|year=2007|publisher=Elsevier|isbn=978-0-444-51623-7|page=131|author=Graham Priest|chapter=Paraconsistency and Dialetheism}}&lt;/ref&gt; However, the study of paraconsistent logics does not necessarily entail a dialetheist viewpoint. For example, one need not commit to either the existence of true theories or true contradictions, but would rather prefer a weaker standard like [[empirical adequacy]], as proposed by [[Bas van Fraassen]].&lt;ref name="Allhoff2010"&gt;{{cite book|editor=Fritz Allhoff|title=Philosophies of the Sciences: A Guide|url=https://books.google.com/books?id=Vu6cVCLvPt0C&amp;pg=PA55|year=2010|publisher=John Wiley &amp; Sons|isbn=978-1-4051-9995-7|page=55|author=Otávio Bueno|chapter=Philosophy of Logic}}&lt;/ref&gt;

==Philosophy==
In classical logic Aristotle's three laws, namely, the excluded middle (''p'' or ¬''p''), non-contradiction ¬ (''p'' ∧ ¬''p'') and identity (''p'' iff ''p''), are regarded as the same, due to the inter-definition of the connectives. Moreover, traditionally contradictoriness (the presence of contradictions in a theory or in a body of knowledge) and triviality (the fact that such a theory entails all possible consequences) are assumed inseparable, granted that negation is available. These views may be philosophically challenged, precisely on the grounds that they fail to distinguish between contradictoriness and other forms of inconsistency.

On the other hand, it is possible to derive triviality from the 'conflict' between consistency and contradictions, once these notions have been properly distinguished. The very notions of consistency and inconsistency may be furthermore internalized at the object language level.

==Tradeoffs==
Paraconsistency involves tradeoffs. In particular, abandoning the principle of explosion requires one to abandon at least one of the following two principles:&lt;ref&gt;See the article on the [[principle of explosion]] for more on this.&lt;/ref&gt;
{| class="wikitable" style="margin: auto;"
![[Disjunction introduction]]
|&lt;math&gt;A \vdash A \lor B&lt;/math&gt;
|-
![[Disjunctive syllogism]]
|&lt;math&gt;A \lor B, \neg A \vdash B&lt;/math&gt;
|}

Both of these principles have been challenged.

One approach is to reject disjunction introduction but keep disjunctive syllogism and transitivity. In this approach, rules of [[natural deduction]] hold, except for [[disjunction introduction]] and [[excluded middle]]; moreover, inference A⊢B does not necessarily mean entailment A⇒B. Also, the following usual Boolean properties hold: [[double negation]] as well as [[associativity]], [[commutativity]], [[distributivity]], [[De Morgan's laws|De Morgan]], and [[idempotence]] inferences (for conjunction and disjunction).  Furthermore, inconsistency-robust proof by contradiction holds for entailment (A⇒(B∧¬B))⊢¬A.

Another approach is to reject disjunctive syllogism. From the perspective of [[dialetheism]], it makes perfect sense that disjunctive syllogism should fail. The idea behind this syllogism is that, if ''¬ A'', then ''A'' is excluded and ''B'' can be inferred from ''A ∨ B''. However, if ''A'' may hold as well as ''¬A'', then the argument for the inference is weakened.

Yet another approach is to do both simultaneously. In many systems of [[relevant logic]], as well as [[linear logic]], there are two separate disjunctive connectives. One allows disjunction introduction, and one allows disjunctive syllogism.  Of course, this has the disadvantages entailed by separate disjunctive connectives including confusion between them and complexity in relating them.

Furthermore, the rule of proof by contradiction (below) just by itself is inconsistency non-robust in the sense that the negation of every proposition can be proved from a contradiction.

{| class="wikitable" style="margin: auto;"
![[Proof by contradiction]]
|If &lt;math&gt; A \vdash B \land \neg B&lt;/math&gt;, then &lt;math&gt; \vdash \neg A&lt;/math&gt;
|}
Strictly speaking, having just the rule above is paraconsistent because it is not the case that ''every'' proposition can be proved from a contradiction. However, if the rule [[double negation elimination]] (&lt;math&gt;\neg \neg A \vdash A&lt;/math&gt;) is added as well, then every proposition can be proved from a contradiction. Double negation elimination does not hold for [[intuitionistic logic]].

== Example ==
One well-known system of paraconsistent logic is the simple system known as LP ("Logic of Paradox"), first proposed by the [[Argentina|Argentinian]] logician [[F. G. Asenjo]] in 1966 and later popularized by [[Graham Priest|Priest]] and others.&lt;ref&gt;Priest (2002), p. 306.&lt;/ref&gt;

One way of presenting the semantics for LP is to replace the usual [[function (mathematics)|functional]] valuation with a [[relation (mathematics)|relational]] one.&lt;ref&gt;LP is also commonly presented as a [[many-valued logic]] with three truth values (''true'', ''false'', and ''both'').&lt;/ref&gt;  The binary relation &lt;math&gt;V\,&lt;/math&gt; relates a [[Well-formed formula|formula]] to a [[truth value]]: &lt;math&gt;V(A,1)\,&lt;/math&gt; means that &lt;math&gt;A\,&lt;/math&gt; is true, and &lt;math&gt;V(A,0)\,&lt;/math&gt; means that &lt;math&gt;A\,&lt;/math&gt; is false. A formula must be assigned ''at least'' one truth value, but there is no requirement that it be assigned ''at most'' one truth value. The semantic clauses for [[negation]] and [[disjunction]] are given as follows:
* &lt;math&gt;V( \neg A,1) \Leftrightarrow V(A,0)&lt;/math&gt;
* &lt;math&gt;V( \neg A,0) \Leftrightarrow V(A,1)&lt;/math&gt;
* &lt;math&gt;V(A \lor B,1) \Leftrightarrow V(A,1) \text{ or } V(B,1)&lt;/math&gt;
* &lt;math&gt;V(A \lor B,0) \Leftrightarrow V(A,0) \text{ and } V(B,0)&lt;/math&gt;
(The other [[logical connective]]s are defined in terms of negation and disjunction as usual.)
Or to put the same point less symbolically:
* ''not A'' is true [[if and only if]] ''A'' is false
* ''not A'' is false if and only if ''A'' is true
* ''A or B'' is true if and only if ''A'' is true or ''B'' is true
* ''A or B'' is false if and only if ''A'' is false and ''B'' is false
(Semantic) [[logical consequence]] is then defined as truth-preservation:
:  &lt;math&gt;\Gamma\vDash A&lt;/math&gt; if and only if &lt;math&gt;A\,&lt;/math&gt; is true whenever every element of &lt;math&gt;\Gamma\,&lt;/math&gt; is true.
Now consider a valuation &lt;math&gt;V\,&lt;/math&gt; such that &lt;math&gt;V(A,1)\,&lt;/math&gt; and &lt;math&gt;V(A,0)\,&lt;/math&gt; but it is not the case that &lt;math&gt;V(B,1)\,&lt;/math&gt;. It is easy to check that this valuation constitutes a [[counterexample]] to both explosion and disjunctive syllogism. However, it is also a counterexample to [[modus ponens]] for the [[material conditional]] of LP. For this reason, proponents of LP usually advocate expanding the system to include a stronger conditional connective that is not definable in terms of negation and disjunction.&lt;ref&gt;See, for example, Priest (2002), §5.&lt;/ref&gt;

As one can verify, LP preserves most other inference patterns that one would expect to be valid, such as [[De Morgan's laws]] and the usual [[Natural deduction|introduction and elimination rules]] for negation, [[Logical conjunction|conjunction]], and disjunction. Surprisingly, the [[logical truth]]s (or [[Tautology (logic)|tautologies]]) of LP are precisely those of classical propositional logic.&lt;ref&gt;See Priest (2002), p. 310.&lt;/ref&gt;  (LP and classical logic differ only in the ''[[inference]]s'' they deem valid.)  Relaxing the requirement that every formula be either true or false yields the weaker paraconsistent logic commonly known as [[first-degree entailment]] (FDE). Unlike LP, FDE contains no logical truths.

It must be emphasized that LP is but one of ''many'' paraconsistent logics that have been proposed.&lt;ref&gt;Surveys of various approaches to paraconsistent logic can be found in Bremer (2005) and Priest (2002), and a large family of paraconsistent logics is developed in detail in Carnielli, Congilio and Marcos (2007).&lt;/ref&gt; It is presented here merely as an illustration of how a paraconsistent logic can work.

== Relation to other logics ==
One important type of paraconsistent logic is [[relevance logic]]. A logic is ''relevant'' [[iff]] it satisfies the following condition:

: if ''A'' → ''B'' is a theorem, then ''A'' and ''B'' share a [[logical constant|non-logical constant]].

It follows that a relevance logic cannot have (''p'' ∧ ¬''p'') → ''q'' as a theorem, and thus (on reasonable assumptions) cannot validate the inference from {''p'', ¬''p''} to ''q''.

Paraconsistent logic has significant overlap with [[many-valued logic]]; however, not all paraconsistent logics are many-valued (and, of course, not all many-valued logics are paraconsistent). [[Dialetheic logic]]s, which are also many-valued, are paraconsistent, but the converse does not hold.

[[Intuitionistic logic]] allows ''A'' ∨ ¬''A'' not to be equivalent to true, while paraconsistent logic allows ''A'' ∧ ¬''A'' not to be equivalent to false. Thus it seems natural to regard paraconsistent logic as the "[[duality (mathematics)|dual]]" of intuitionistic logic. However, intuitionistic logic is a specific logical system whereas paraconsistent logic encompasses a large class of systems. Accordingly, the dual notion to paraconsistency is called [[paracomplete logic|paracompleteness]], and the "dual" of intuitionistic logic (a specific paracomplete logic) is a specific paraconsistent system called ''anti-intuitionistic'' or ''dual-intuitionistic logic'' (sometimes referred to as ''Brazilian logic'', for historical reasons).&lt;ref&gt;See Aoyama (2004).&lt;/ref&gt;  The duality between the two systems is best seen within a [[sequent calculus]] framework. While in intuitionistic logic the sequent

: &lt;math&gt;\vdash A \lor \neg A&lt;/math&gt;

is not derivable, in dual-intuitionistic logic

: &lt;math&gt;A \land \neg A \vdash&lt;/math&gt;

is not derivable{{cn|reason=I think that's a typo. Not sure, though|date=April 2017}}. Similarly, in intuitionistic logic the sequent

: &lt;math&gt;\neg \neg A \vdash A&lt;/math&gt;

is not derivable, while in dual-intuitionistic logic

: &lt;math&gt;A \vdash \neg \neg A&lt;/math&gt;

is not derivable. Dual-intuitionistic logic contains a connective # known as ''pseudo-difference'' which is the dual of intuitionistic implication. Very loosely, {{nowrap|1=''A'' # ''B''}} can be read as "''A'' but not ''B''". However, # is not [[truth-functional]] as one might expect a 'but not' operator to be; similarly, the intuitionistic implication operator cannot be treated like "{{nowrap|1=¬ (''A'' ∧ ¬''B'')}}".  Dual-intuitionistic logic also features a basic connective ⊤ which is the dual of intuitionistic ⊥: negation may be defined as {{nowrap|1=¬''A'' = (⊤ # ''A'')}}

A full account of the duality between paraconsistent and intuitionistic logic, including an explanation on why dual-intuitionistic and paraconsistent logics do not coincide, can be found in Brunner and Carnielli (2005).

These other logics avoid explosion: [[implicational propositional calculus]], [[minimal logic]], [[positive propositional calculus]], and [[equivalential calculus]]. Minimal logic is both paraconsistent and paracomplete (a subsystem of intuitionistic logic). The other three simply do not allow one to express a contradiction to begin with since they lack the ability to form negations.

== An ideal three-valued paraconsistent logic ==
Here is an example of a [[three-valued logic]] which is paraconsistent and ''ideal'' as defined in "Ideal Paraconsistent Logics" by O. Arieli, A. Avron, and A. Zamansky, especially pages 22-23.&lt;ref&gt;{{Cite web |url=https://www.cs.tau.ac.il/~aa/articles/ideal.pdf# |title=Ideal Paraconsistent Logics |access-date=2018-08-21 |archive-url=https://web.archive.org/web/20170809143217/http://www.cs.tau.ac.il/~aa/articles/ideal.pdf# |archive-date=2017-08-09 |dead-url=no |df= }}&lt;/ref&gt; The three truth-values are: ''t'' (true only), ''b'' (both true and false), and ''f'' (false only).

{| style="border-spacing: 10px 0;" align="center"
|- valign="bottom"
|
{| class="wikitable" style="text-align:center;"
|+
! width="25" | P
! width="25" | ¬P
|-
! scope="row" {{yes|t}}
| {{no|f}}
|-
! scope="row" | b
| b
|-
! scope="row" {{no|f}}
| {{yes|t}}
|}
|
{| class="wikitable" style="text-align:center;"
|+ 
! rowspan="2" colspan="2" | P → Q
! colspan="3" | Q
|-
! width="25" {{yes|t}}
! width="25" | b
! width="25" {{no|f}}
|-
! scope="row" rowspan="3" width="25" | P
! scope="row" width="25" {{yes|t}}
| {{yes|t}}
| b
| {{no|f}}
|-
! scope="row" | b
| {{yes|t}}
| b
| {{no|f}}
|-
! scope="row" {{no|f}}
| {{yes|t}}
| {{yes|t}}
| {{yes|t}}
|}
|
{| class="wikitable" style="text-align:center;"
|+
! rowspan="2" colspan="2" | P ∨ Q
! colspan="3" | Q
|-
! width="25" {{yes|t}}
! width="25" | b
! width="25" {{no|f}}
|-
! scope="row" rowspan="3" width="25" | P
! scope="row" width="25" {{yes|t}}
| {{yes|t}}
| {{yes|t}}
| {{yes|t}}
|-
! scope="row" | b
| {{yes|t}}
| b
| b
|-
! scope="row" {{no|f}}
| {{yes|t}}
| b
| {{no|f}}
|}
|
{| class="wikitable" style="text-align:center;"
|+
! rowspan="2" colspan="2" | P ∧ Q
! colspan="3" | Q
|-
! width="25" {{yes|t}}
! width="25" | b
! width="25" {{no|f}}
|-
! scope="row" rowspan="3" width="25" | P
! scope="row" width="25" {{yes|t}}
| {{yes|t}}
| b
| {{no|f}}
|-
! scope="row" | b
| b
| b
| {{no|f}}
|-
! scope="row" {{no|f}}
| {{no|f}}
| {{no|f}}
| {{no|f}}
|}
|}

A formula is true if its truth-value is either ''t'' or ''b'' for the valuation being used. A formula is a tautology of paraconsistent logic if it is true in every valuation which maps atomic propositions to {''t'', ''b'', ''f''}. Every tautology of paraconsistent logic is also a tautology of classical logic. For a valuation, the set of true formulas is closed under [[modus ponens]] and the [[deduction theorem]]. Any tautology of classical logic which contains no negations is also a tautology of paraconsistent logic (by merging ''b'' into ''t''). This logic is sometimes referred to as "Pac" or "LFI1".

=== Included ===
Some tautologies of paraconsistent logic are:
* All axiom schemas for paraconsistent logic:
:&lt;math&gt;P \to (Q \to P)&lt;/math&gt; ** for deduction theorem and ?→{''t'',''b''} = {''t'',''b''}
:&lt;math&gt;(P \to (Q \to R)) \to ((P \to Q) \to (P \to R))&lt;/math&gt; ** for deduction theorem (note: {''t'',''b''}→{''f''} = {''f''} follows from the deduction theorem)
:&lt;math&gt;\lnot (P \to Q) \to P&lt;/math&gt; ** {''f''}→? = {''t''}
:&lt;math&gt;\lnot (P \to Q) \to \lnot Q&lt;/math&gt; ** ?→{''t''} = {''t''}
:&lt;math&gt;P \to (\lnot Q \to \lnot (P \to Q))&lt;/math&gt; ** {''t'',''b''}→{''b'',''f''} = {''b'',''f''}
:&lt;math&gt;\lnot \lnot P \to P&lt;/math&gt; ** ~{''f''} = {''t''}
:&lt;math&gt;P \to \lnot \lnot P&lt;/math&gt; ** ~{''t'',''b''} = {''b'',''f''} (note: ~{''t''} = {''f''} and ~{''b'',''f''} = {''t'',''b''} follow from the way the truth-values are encoded)
:&lt;math&gt;P \to (P \lor Q)&lt;/math&gt; ** {''t'',''b''}v? = {''t'',''b''}
:&lt;math&gt;Q \to (P \lor Q)&lt;/math&gt; ** ?v{''t'',''b''} = {''t'',''b''}
:&lt;math&gt;\lnot (P \lor Q) \to \lnot P&lt;/math&gt; ** {''t''}v? = {''t''}
:&lt;math&gt;\lnot (P \lor Q) \to \lnot Q&lt;/math&gt; ** ?v{''t''} = {''t''}
:&lt;math&gt;(P \to R) \to ((Q \to R) \to ((P \lor Q) \to R))&lt;/math&gt; ** {''f''}v{''f''} = {''f''}
:&lt;math&gt;\lnot P \to (\lnot Q \to \lnot (P \lor Q))&lt;/math&gt; ** {''b'',''f''}v{''b'',''f''} = {''b'',''f''}
:&lt;math&gt;(P \land Q) \to P&lt;/math&gt; ** {''f''}&amp;? = {''f''}
:&lt;math&gt;(P \land Q) \to Q&lt;/math&gt; ** ?&amp;{''f''} = {''f''}
:&lt;math&gt;\lnot P \to \lnot (P \land Q)&lt;/math&gt; ** {''b'',''f''}&amp;? = {''b''.''f''}
:&lt;math&gt;\lnot Q \to \lnot (P \land Q)&lt;/math&gt; ** ?&amp;{''b'',''f''} = {''b'',''f''}
:&lt;math&gt;(\lnot P \to R) \to ((\lnot Q \to R) \to (\lnot (P \land Q) \to R))&lt;/math&gt; ** {''t''}&amp;{''t''} = {''t''}
:&lt;math&gt;P \to (Q \to (P \land Q))&lt;/math&gt; ** {''t'',''b''}&amp;{''t'',''b''} = {''t'',''b''}
:&lt;math&gt;(P \to Q) \to ((\lnot P \to Q) \to Q)&lt;/math&gt; ** ? is the union of {''t'',''b''} with {''b'',''f''}
* Some other theorem schemas:
:&lt;math&gt;P \to P&lt;/math&gt;
:&lt;math&gt;(\lnot P \to P) \to P&lt;/math&gt;
:&lt;math&gt;((P \to Q) \to P) \to P&lt;/math&gt;
:&lt;math&gt;P \lor \lnot P&lt;/math&gt;
:&lt;math&gt;\lnot (P \land \lnot P)&lt;/math&gt;
:&lt;math&gt;(\lnot P \to Q) \to (P \lor Q)&lt;/math&gt;
:&lt;math&gt;((\lnot P \to Q) \to Q) \to (((P \land \lnot P) \to Q) \to (P \to Q))&lt;/math&gt; ** every truth-value is either ''t'', ''b'', or ''f''.
:&lt;math&gt;((P \to Q) \to R) \to (Q \to R)&lt;/math&gt;

=== Excluded ===
Some tautologies of classical logic which are ''not'' tautologies of paraconsistent logic are:
:&lt;math&gt;\lnot P \to (P \to Q)&lt;/math&gt; ** no explosion in paraconsistent logic
:&lt;math&gt;(\lnot P \to Q) \to ((\lnot P \to \lnot Q) \to P)&lt;/math&gt;
:&lt;math&gt;(P \to Q) \to ((P \to \lnot Q) \to \lnot P)&lt;/math&gt;
:&lt;math&gt;(P \lor Q) \to (\lnot P \to Q)&lt;/math&gt; ** disjunctive syllogism fails in paraconsistent logic
:&lt;math&gt;(P \to Q) \to (\lnot Q \to \lnot P)&lt;/math&gt; ** contrapositive fails in paraconsistent logic
:&lt;math&gt;(\lnot P \to \lnot Q) \to (Q \to P)&lt;/math&gt;
:&lt;math&gt;((\lnot P \to Q) \to Q) \to (P \to Q)&lt;/math&gt;
:&lt;math&gt;(P \land \lnot P) \to (Q \land \lnot Q)&lt;/math&gt; ** not all contradictions are equivalent in paraconsistent logic
:&lt;math&gt;(P \to Q) \to (\lnot Q \to (P \to R))&lt;/math&gt;
:&lt;math&gt;((P \to Q) \to R) \to (\lnot P \to R)&lt;/math&gt;
:&lt;math&gt;((\lnot P \to R) \to R) \to (((P \to Q) \to R) \to R)&lt;/math&gt; ** counter-factual for {''b'',''f''}→? = {''t'',''b''} (inconsistent with ''b''→''f'' = ''f'')

=== Strategy ===
Suppose we are faced with a contradictory set of premises &amp;Gamma; and wish to avoid being reduced to triviality. In classical logic, the only method one can use is to reject one or more of the premises in &amp;Gamma;. In paraconsistent logic, we may try to compartmentalize the contradiction. That is, weaken the logic so that &amp;Gamma;→''X'' is no longer a tautology provided the propositional variable ''X'' does not appear in &amp;Gamma;. However, we do not want to weaken the logic any more than is necessary for that purpose. So we wish to retain modus ponens and the deduction theorem as well as the axioms which are the introduction and elimination rules for the logical connectives (where possible).

To this end, we add a third truth-value ''b'' which will be employed within the compartment containing the contradiction. We make ''b'' a fixed point of all the logical connectives.
:&lt;math&gt; b = \lnot b = (b \to b) = (b \lor b) = (b \land b) &lt;/math&gt;

We must make ''b'' a kind of truth (in addition to ''t'') because otherwise there would be no tautologies at all.

To ensure that modus ponens works, we must have
:&lt;math&gt; (b \to f) = f ,&lt;/math&gt;
that is, to ensure that a true hypothesis and a true implication lead to a true conclusion, we must have that a not-true (''f'') conclusion and a true (''t'' or ''b'') hypothesis yield a not-true implication.

If all the propositional variables in &amp;Gamma; are assigned the value ''b'', then &amp;Gamma; itself will have the value ''b''. If we give ''X'' the value ''f'', then
:&lt;math&gt; (\Gamma \to X) = (b \to f) = f &lt;/math&gt;.
So &amp;Gamma;→''X'' will not be a tautology.

Limitations:
(1) There must not be constants for the truth values because that would defeat the purpose of paraconsistent logic. Having ''b'' would change the language from that of classical logic. Having ''t'' or ''f'' would allow the explosion again because
:&lt;math&gt; \lnot t \to X &lt;/math&gt; or &lt;math&gt; f \to X &lt;/math&gt;
would be tautologies. Note that ''b'' is not a fixed point of those constants since ''b'' ≠ ''t'' and ''b'' ≠ ''f''.

(2) This logic's ability to contain contradictions applies only to contradictions among particularized premises, not to contradictions among axiom schemas.

(3) The loss of disjunctive syllogism may result in insufficient commitment to developing the 'correct' alternative, possibly crippling mathematics.

(4) To establish that a formula &amp;Gamma; is equivalent to &amp;Delta; in the sense that either can be substituted for the other wherever they appear as a subformula, one must show
:&lt;math&gt;(\Gamma \to \Delta) \land (\Delta \to \Gamma) \land (\lnot \Gamma \to \lnot \Delta) \land (\lnot \Delta \to \lnot \Gamma)&lt;/math&gt;.
This is more difficult than in classical logic because the contrapositives do not necessarily follow.

== Applications ==
Paraconsistent logic has been applied as a means of managing inconsistency in numerous domains, including:&lt;ref name="See Bremer"&gt;Most of these are discussed in Bremer (2005) and Priest (2002).&lt;/ref&gt;
* [[Semantics]]. Paraconsistent logic has been proposed as means of providing a simple and intuitive formal account of [[truth]] that does not fall prey to paradoxes such as [[Liar paradox|the Liar]]. However, such systems must also avoid [[Curry's paradox]], which is much more difficult as it does not essentially involve negation.
* [[Set theory]] and the [[foundations of mathematics]].
* [[Epistemology]] and [[belief revision]]. Paraconsistent logic has been proposed as a means of reasoning with and revising inconsistent theories and belief systems.
* [[Knowledge management]] and [[artificial intelligence]]. Some [[computer scientist]]s have utilized paraconsistent logic as a means of coping gracefully with inconsistent information.&lt;ref&gt;See, for example, [[Truth maintenance systems]] or the articles in Bertossi et al. (2004).&lt;/ref&gt;
* [[Deontic logic]] and [[metaethics]]. Paraconsistent logic has been proposed as a means of dealing with ethical and other normative conflicts.
* [[Software engineering]]. Paraconsistent logic has been proposed as a means for dealing with the pervasive inconsistencies among the [[documentation]], [[use cases]], and [[Source code|code]] of large [[software systems]].&lt;ref name="Hewitt 2008b"&gt;Hewitt (2008b)&lt;/ref&gt;&lt;ref name="Hewitt 2008a"&gt;Hewitt (2008a)&lt;/ref&gt;&lt;ref&gt;Carl Hewitt. Formalizing common sense reasoning for scalable inconsistency-robust information coordination using Direct Logic Reasoning and the Actor Model. in Vol. 52 of Studies in Logic. College Publications. {{isbn|1848901593}}. 2015.&lt;/ref&gt;
* [[Electronics]] design routinely uses a [[four-valued logic]], with "hi-impedance (z)" and "don't care (x)" playing similar roles to "don't know" and "both true and false" respectively, in addition to True and False.  This logic was developed independently of Philosophical logics.
* [[Quantum physics]]
* [[Black hole|Black hole physics]]
* [[Hawking radiation]]
* [[Quantum computing]]
* [[Spintronics]]
* [[Quantum entanglement]]
* [[Quantum coupling]]
* [[Uncertainty principle]]

== Criticism ==
Some philosophers have argued against dialetheism on the grounds that the counterintuitiveness of giving up any of the three principles above outweighs any counterintuitiveness that the principle of explosion might have.

Others, such as [[David Lewis (philosopher)|David Lewis]], have objected to paraconsistent logic on the ground that it is simply impossible for a statement and its negation to be jointly true.&lt;ref&gt;See Lewis (1982).&lt;/ref&gt;  A related objection is that "negation" in paraconsistent logic is not really ''[[negation]]''; it is merely a [[Square of opposition|subcontrary]]-forming operator.&lt;ref&gt;See Slater (1995), Béziau (2000).&lt;/ref&gt;

== Alternatives ==
Approaches exist that allow for resolution of inconsistent beliefs without violating any of the intuitive logical principles. Most such systems use [[multi-valued logic]] with [[Bayesian inference]] and the [[Dempster-Shafer theory]], allowing that no non-tautological belief is completely (100%) irrefutable because it must be based upon incomplete, abstracted, interpreted, likely unconfirmed, potentially uninformed, and possibly incorrect knowledge (of course, this very assumption, if non-tautological, entails its own refutability, if by "refutable" we mean "not completely [100%] irrefutable"). These systems effectively give up several logical principles in practice without rejecting them in theory.

== Notable figures ==
Notable figures in the history and/or modern development of paraconsistent logic include:

* [[Alan Ross Anderson]] (United States, 1925–1973). One of the founders of [[relevance logic]], a kind of paraconsistent logic.
* [[F. G. Asenjo]] ([[Argentina]])
* [[Diderik Batens]] (Belgium)
* [[Nuel Belnap]] (United States, b. 1930). Worked with Anderson on relevance logic.
* [[Jean-Yves Béziau]] (France/Switzerland, b. 1965). Has written extensively on the general structural features and philosophical foundations of paraconsistent logics.
* [[Ross Brady]] (Australia)
* [[Bryson Brown]] (Canada)
* [[Walter Carnielli]] ([[Brazil]]). The developer of the  ''possible-translations semantics'',  a new semantics which makes paraconsistent logics applicable and philosophically understood.
* [[Newton da Costa]] ([[Brazil]], b. 1929). One of the first to develop formal systems of paraconsistent logic.
* [[Itala M. L. D'Ottaviano]] ([[Brazil]])
* [[J. Michael Dunn]] (United States). An important figure in relevance logic.
* [[Carl Hewitt]]
* [[Stanisław Jaśkowski]] ([[Poland]]). One of the first to develop formal systems of paraconsistent logic.
* [[R. E. Jennings]] (Canada)
* [[David Kellogg Lewis]] (USA, 1941–2001). Articulate critic of paraconsistent logic.
* [[Jan Łukasiewicz]] ([[Poland]], 1878–1956)
* [[Robert K. Meyer]] (United States/Australia)
* [[Chris Mortensen (philosopher)|Chris Mortensen]] (Australia). Has written extensively on paraconsistent mathematics.
* [[Lorenzo Peña]] (Spain, b. 1944). Has developed an original line of paraconsistent logic, gradualistic logic (also known as ''transitive logic'', TL), akin to [[fuzzy logic]].
* [[Val Plumwood]] [formerly Routley] (Australia, b. 1939). Frequent collaborator with Sylvan.
* [[Graham Priest]] (Australia). Perhaps the most prominent advocate of paraconsistent logic in the world today.
* [[Francisco Miró Quesada]] ([[Peru]]). Coined the term ''paraconsistent logic''.
* [[B. H. Slater]] (Australia). Another articulate critic of paraconsistent logic.
* [[Richard Sylvan]] [formerly Routley] (New Zealand/Australia, 1935–1996). Important figure in relevance logic and a frequent collaborator with Plumwood and Priest.
* [[Nicolai A. Vasiliev]] (Russia, 1880–1940). First to construct logic tolerant to contradiction (1910).

==See also==
{{Portal|Logic}}
*[[Deviant logic]]
*[[Formal logic]]
*[[Probability logic]]
*[[Intuitionistic logic]]
*[[Table of logic symbols]]

== Notes ==
{{Reflist|2}}

==Resources==
* {{cite book |title=Handbook of Paraconsistency |author=[[Jean-Yves Béziau]], [[Walter Carnielli]] and [[Dov Gabbay]], eds. |location=London |publisher=King's College |year=2007  |isbn=978-1-904987-73-4}}
* {{cite journal | author=Aoyama, Hiroshi | title= LK, LJ, Dual Intuitionistic Logic, and Quantum Logic | journal=Notre Dame Journal of Formal Logic | year=2004 | volume=45 | issue= 4 | pages= 193–213  | doi=10.1305/ndjfl/1099238445}}
* {{cite book | last=Bertossi | first=Leopoldo, eds. | title=Inconsistency Tolerance | year=2004 | publisher=Springer | location=Berlin  | isbn=3-540-24260-0  }}
* {{cite journal |author1=Brunner, Andreas  |author2=Carnielli, Walter  |lastauthoramp=yes | title=  Anti-intuitionism and paraconsistency | journal= [[Journal of Applied Logic]] | year=2005 | volume=3 | issue= 1 | pages= 161–184  | doi=10.1016/j.jal.2004.07.016}}
* {{cite book | last=Béziau | first=Jean-Yves | editor=In D. Batens et al. (eds.) | title=Frontiers of Paraconsistent Logic | year=2000 | publisher=Research Studies Press | location=Baldock | isbn=0-86380-253-2 | pages=95–111 | chapter=What is Paraconsistent Logic?}}
* {{cite book | last=Bremer | first=Manuel | title=An Introduction to Paraconsistent Logics | year=2005 | publisher=Peter Lang | location=Frankfurt | language= | isbn=3-631-53413-2}}
* {{cite book | last=Brown | first=Bryson | editor=In Dale Jacquette (ed.) | title=A Companion to Philosophical Logic | year=2002 | publisher=Blackwell Publishers | location=Malden, Massachusetts | isbn=0-631-21671-5 | pages=628–650 | chapter=On Paraconsistency}}
* {{cite book | last=Carnielli | first=Walter |author2=Coniglio, Marcelo E. |author3=Marcos,  J | editor=[[Dov Gabbay|D. Gabbay]] |editor2=F. Guenthner | title=Handbook of Philosophical Logic, Volume 14 | edition=2nd | year=2007 | publisher=[[Kluwer Academic Publishers]] | location=The Netherlands | isbn=1-4020-6323-7 | pages=1–93 | chapter=Logics of Formal Inconsistency}}
* {{cite journal|author=Feferman, Solomon | year=1984 | title=Toward Useful Type-Free Theories, I |doi=10.2307/2274093 |pages=75–111|volume=49|issue=1|journal=The Journal of Symbolic Logic}}
* {{cite conference | author=Hewitt, Carl |year=2008a | title=Large-scale Organizational Computing requires Unstratified Reflection and Strong Paraconsistency |booktitle=Coordination, Organizations, Institutions, and Norms in Agent Systems III |editor1=Jaime Sichman |editor2=Pablo Noriega |editor3=Julian Padget |editor4=Sascha Ossowski |series=Lecture Notes in Computer Science |volume=4780 |publisher=Springer-Verlag |doi=10.1007/978-3-540-79003-7}}
* {{cite arXiv | author=Hewitt, Carl |year=2008b | title=Common sense for concurrency and inconsistency tolerance using Direct Logic and the Actor model |eprint=0812.4852 | class=cs.LO}}
* {{cite book | last=Lewis | first=David | title=Papers in Philosophical Logic | origyear=1982 | year=1998 | publisher=Cambridge University Press | location=Cambridge | isbn=0-521-58788-3 | pages=97–110 | chapter=Logic for Equivocators}}
* {{cite journal | last=Peña | first=Lorenzo | authorlink=Lorenzo Peña | title=Graham Priest's 'Dialetheism': Is it altogether true? | origyear=1996 | url=http://lp.jurid.net/articles/logica/dialethe.htm | hdl=10261/9714 | accessdate=2009-05-03 | journal= Sorites | year=1996 | volume=7 | pages= 28–56 }}
* {{cite book | last=Priest | first=Graham | editor=In [[Dov Gabbay|D. Gabbay]] and F. Guenthner (eds.) | title=Handbook of Philosophical Logic, Volume 6 | edition=2nd | year=2002 | publisher=[[Kluwer Academic Publishers]] | location=The Netherlands  | isbn=1-4020-0583-0  | pages=287–393 | chapter=Paraconsistent Logic.}}
* {{cite web |author1=Priest, Graham  |author2=Tanaka, Koji  |lastauthoramp=yes | origyear=1996| year=2009 | title=Paraconsistent Logic | work=[[Stanford Encyclopedia of Philosophy]] | url=http://plato.stanford.edu/entries/logic-paraconsistent/ | accessdate= June 17, 2010}} (First published Tue Sep 24, 1996; substantive revision Fri Mar 20, 2009)
* {{cite journal | author=Slater, B. H. | title= Paraconsistent Logics? | journal=Journal of Philosophical Logic | year=1995 | volume=24 | pages= 451–454 | doi=10.1007/BF01048355 | issue=4}}
* {{cite book | last=Woods | first=John | title=Paradox and Paraconsistency: Conflict Resolution in the Abstract Sciences  | year=2003 | publisher=[[Cambridge University Press]] | location=Cambridge | isbn=0-521-00934-0}}

==External links==
*{{cite IEP |url-id=para-log |title=Paraconsistent Logic}}
* [http://plato.stanford.edu/entries/logic-paraconsistent/ Stanford Encyclopedia of Philosophy "Paraconsistent Logic"]
* [http://plato.stanford.edu/entries/mathematics-inconsistent/ Stanford Encyclopedia of Philosophy "Inconsistent Mathematics"]
* [http://www.paraconsistency.org "World Congress on Paraconsistency, Ghent 1997, Juquehy 2000, Toulouse, 2003, Melbourne 2008, Kolkata, 2014"]
* [https://arxiv.org/abs/0805.1481/ Paraconsistent First-Order Logic with infinite hierarchy levels of contradiction LP#. Axiomatical system HST#, as paraconsistent generalization of Hrbacek set theory HST]
* [https://www.cs.tau.ac.il/~aa/articles/ideal.pdf Ideal Paraconsistent Logics]

{{Non-classical logic}}

[[Category:Paraconsistent logic| ]]
[[Category:Belief revision]]
[[Category:Non-classical logic]]
[[Category:Philosophical logic]]
[[Category:Systems of formal logic]]</text>
      <sha1>hzsp7xlk0vc5vfnek53lgz91hw5seul</sha1>
    </revision>
  </page>
  <page>
    <title>Parity learning</title>
    <ns>0</ns>
    <id>23864280</id>
    <revision>
      <id>864636153</id>
      <parentid>864482873</parentid>
      <timestamp>2018-10-18T14:13:19Z</timestamp>
      <contributor>
        <username>Leschnei</username>
        <id>27335766</id>
      </contributor>
      <comment>/* {{Anchor|LPN}} Noisy version ("Learning Parity with Noise") */ added LPN</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1842">'''Parity learning''' is a problem in [[machine learning]]. An algorithm that solves this problem must find a function ''ƒ'', given some samples (''x'',&amp;nbsp;''ƒ''(''x'')) and the assurance that ''ƒ'' computes the [[Parity function|parity]] of bits at some fixed locations. The samples are generated using some distribution over the input. The problem is easy to solve using [[Gaussian elimination]] provided that a sufficient number of samples (from a distribution which is not too skewed) are provided to the algorithm.

== {{Anchor|LPN}} Noisy version ("Learning Parity with Noise") ==
In Learning Parity with Noise (LPN), the samples may contain some error. Instead of samples (''x'',&amp;nbsp;''ƒ''(''x'')), the algorithm is provided with (''x'',&amp;nbsp;''y''), where ''y''&amp;nbsp;=&amp;nbsp;1&amp;nbsp;&amp;minus;&amp;nbsp;''ƒ''(''x'') with some small probability. The noisy version of the parity learning problem is conjectured to be hard. {{citation needed|date=February  2017}}

== See also ==
* [[Learning with errors]]

== References ==
* Avrim Blum, Adam Kalai, and Hal Wasserman, “Noise-tolerant learning, the parity problem, and the statistical query model,” J. ACM 50, no. 4 (2003): 506&amp;ndash;519.
* Adam Tauman Kalai, Yishay Mansour, and Elad Verbin, “On agnostic boosting and parity learning,” in Proceedings of the 40th annual ACM symposium on Theory of computing (Victoria, British Columbia, Canada: ACM, 2008), 629&amp;ndash;638, http://portal.acm.org/citation.cfm?id=1374466.
* Oded Regev, “On lattices, learning with errors, random linear codes, and cryptography,” in Proceedings of the thirty-seventh annual ACM symposium on Theory of computing (Baltimore, MD, USA: ACM, 2005), 84&amp;ndash;93, http://portal.acm.org/citation.cfm?id=1060590.1060603.

{{DEFAULTSORT:Parity Learning}}
[[Category:Machine learning]]

{{Mathapplied-stub}}</text>
      <sha1>6ntlpp20uw24687ol8uq9txhg15j23a</sha1>
    </revision>
  </page>
  <page>
    <title>Pollard's kangaroo algorithm</title>
    <ns>0</ns>
    <id>12928899</id>
    <revision>
      <id>857329615</id>
      <parentid>768229147</parentid>
      <timestamp>2018-08-31T01:12:30Z</timestamp>
      <contributor>
        <username>Droplet739</username>
        <id>25212530</id>
      </contributor>
      <minor/>
      <comment>/* The algorithm */ Fixed link: it previously went to the wrong Pollard's rho</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5940">In [[computational number theory]] and [[computer algebra|computational algebra]], '''Pollard's kangaroo algorithm''' (also '''Pollard's lambda algorithm''', see [[#Naming|Naming]] below) is an [[algorithm]] for solving the [[discrete logarithm]] problem.  The algorithm was introduced in 1978 by the number theorist [[John Pollard (mathematician)|J. M. Pollard]], in the same paper &lt;ref&gt;J. Pollard, ''Monte Carlo methods for index computation mod p'', Mathematics of Computation, Volume 32, 1978&lt;/ref&gt; as his better-known [[Pollard's rho algorithm for logarithms|ρ algorithm]] for solving the same problem.  Although Pollard described the application of his algorithm to the discrete logarithm problem in the multiplicative group of units modulo a prime ''p'', it is in fact a generic discrete logarithm algorithm—it will work in any finite cyclic group.

==The algorithm==

Suppose &lt;math&gt;G&lt;/math&gt; is a finite cyclic group of order &lt;math&gt;n&lt;/math&gt; which is generated by the element &lt;math&gt;\alpha&lt;/math&gt;, and we seek to find the discrete logarithm &lt;math&gt;x&lt;/math&gt; of the element &lt;math&gt;\beta&lt;/math&gt; to the base &lt;math&gt;\alpha&lt;/math&gt;.  In other words, we seek &lt;math&gt;x \in Z_n&lt;/math&gt; such that &lt;math&gt;\alpha^x = \beta&lt;/math&gt;.  The lambda algorithm allows us to search for &lt;math&gt;x&lt;/math&gt; in some subset &lt;math&gt;\{a,\ldots,b\}\subset Z_n&lt;/math&gt;.  We may search the entire range of possible logarithms by setting &lt;math&gt;a=0&lt;/math&gt; and &lt;math&gt;b=n-1&lt;/math&gt;, although in this case [[Pollard's rho algorithm for logarithms]] is more efficient.  We proceed as follows:

1. Choose a set &lt;math&gt;S&lt;/math&gt; of integers and define a [[pseudorandom]] map &lt;math&gt;f: G \rightarrow S&lt;/math&gt;.

2. Choose an integer &lt;math&gt;N&lt;/math&gt; and compute a sequence of group elements &lt;math&gt;\{x_0,x_1,\ldots,x_N\}&lt;/math&gt; according to:
* &lt;math&gt;x_0 = \alpha^b\,&lt;/math&gt;
* &lt;math&gt;x_{i+1} = x_i\alpha^{f(x_i)}\mbox{ for }i=0,1,\ldots,N-1&lt;/math&gt;
3. Compute
:&lt;math&gt;d = \sum_{i=0}^{N-1}f(x_i)&lt;/math&gt;.
Observe that:
:&lt;math&gt;x_N = x_0\alpha^d = \alpha^{b+d}\, .&lt;/math&gt;
4. Begin computing a second sequence of group elements &lt;math&gt;\{y_0,y_1,\ldots\}&lt;/math&gt; according to:
* &lt;math&gt;y_0 = \beta\,&lt;/math&gt;
* &lt;math&gt;y_{i+1} = y_i\alpha^{f(y_i)}\mbox{ for }i=0,1,\ldots,N-1&lt;/math&gt;
and a corresponding sequence of integers &lt;math&gt;\{d_0,d_1,\ldots\}&lt;/math&gt; according to:
:&lt;math&gt;d_n = \sum_{i=0}^{n-1}f(y_i)&lt;/math&gt;.
Observe that:
:&lt;math&gt;y_i = y_0\alpha^{d_i} = \beta\alpha^{d_i}\mbox{ for }i=0,1,\ldots,N-1&lt;/math&gt;
5. Stop computing terms of &lt;math&gt;\{y_i\}&lt;/math&gt; and &lt;math&gt;\{d_i\}&lt;/math&gt; when either of the following conditions are met:

:A) &lt;math&gt;y_j = x_N&lt;/math&gt; for some &lt;math&gt;j&lt;/math&gt;.  If the sequences &lt;math&gt;\{x_i\}&lt;/math&gt; and &lt;math&gt;\{y_j\}&lt;/math&gt; "collide" in this manner, then we have:
::&lt;math&gt;x_N = y_j \Rightarrow \alpha^{b+d} = \beta\alpha^{d_j} \Rightarrow \beta = \alpha^{b+d-d_j} \Rightarrow 
x \equiv b+d-d_j \pmod{n}&lt;/math&gt;
:and so we are done.

:B) &lt;math&gt;d_i &gt; b-a+d&lt;/math&gt;.  If this occurs, then the algorithm has failed to find &lt;math&gt;x&lt;/math&gt;.  Subsequent attempts can be made by changing the choice of &lt;math&gt;S&lt;/math&gt; and/or &lt;math&gt;f&lt;/math&gt;.

==Complexity==

Pollard gives the time complexity of the algorithm as &lt;math&gt;{\scriptstyle O(\sqrt{b-a})}&lt;/math&gt;, based on a probabilistic argument which follows from the assumption that ''f'' acts pseudorandomly.  Note that when the size of the set {''a'',&amp;nbsp;…,&amp;nbsp;''b''} to be searched is measured in [[Binary digit|bits]], as is normal in [[Computational complexity theory|complexity theory]], the set  has size log(''b''&amp;thinsp;&amp;minus;&amp;thinsp;''a''), and so the algorithm's complexity is &lt;math&gt;{\scriptstyle O(\sqrt{b-a}) = O(2^{\frac{1}{2}\log(b-a)})}&lt;/math&gt;, which is exponential in the problem size.  For this reason, Pollard's lambda algorithm is considered an [[exponential time]] algorithm.  For an example of a [[subexponential time]] discrete logarithm algorithm, see the [[index calculus algorithm]].

==Naming==
The algorithm is well known by two names.

The first is "Pollard's kangaroo algorithm".  This name is a reference to an analogy used in the paper presenting the algorithm, where the algorithm is explained in terms of using a ''tame'' [[kangaroo]] to trap a ''wild'' kangaroo.  Pollard has explained&lt;ref&gt;J. M. Pollard, ''Kangaroos, Monopoly and Discrete Logarithms'', Journal of Cryptology, Volume 13, pp 437-447, 2000&lt;/ref&gt; that this analogy was inspired by a "fascinating" article published in the same issue of ''[[Scientific American]]'' as an exposition of the [[RSA (algorithm)|RSA]] [[public key cryptosystem]].  The article&lt;ref&gt;T. J. Dawson, ''Kangaroos'', Scientific American, August 1977, pp. 78-89&lt;/ref&gt; described an experiment in which a kangaroo's "energetic cost of locomotion, measured in terms of oxygen consumption at various speeds, was determined by placing kangaroos on a [[treadmill]]".

The second is "Pollard's lambda algorithm".  Much like the name of another of Pollard's discrete logarithm algorithms, [[Pollard's rho algorithm for logarithms|Pollard's rho algorithm]], this name refers to the similarity between a visualisation of the algorithm and the [[Greek letter]] [[lambda]] (&lt;math&gt;\lambda&lt;/math&gt;).  The shorter stroke of the letter lambda corresponds to the sequence &lt;math&gt;\{x_i\}&lt;/math&gt;, since it starts from the position b to the right of x.  Accordingly, the longer stroke corresponds to the sequence &lt;math&gt;\{y_i\}&lt;/math&gt;, which "collides with" the first sequence (just like the strokes of a lambda intersect) and then follows it subsequently.

Pollard has expressed a preference for the name "kangaroo algorithm",&lt;ref&gt;http://sites.google.com/site/jmptidcott2/&lt;/ref&gt; as this avoids confusion with some parallel versions of his rho algorithm, which have also been called "lambda algorithms".

==See also==
* [[Rainbow table]]

==References==
&lt;references/&gt;

{{Number-theoretic algorithms}}

[[Category:Number theoretic algorithms]]
[[Category:Computer algebra]]
[[Category:Logarithms]]</text>
      <sha1>39qwh6k00y6ss74o5rf1nivrur0epil</sha1>
    </revision>
  </page>
  <page>
    <title>Population ecology</title>
    <ns>0</ns>
    <id>1156819</id>
    <revision>
      <id>866722664</id>
      <parentid>863664626</parentid>
      <timestamp>2018-11-01T03:41:29Z</timestamp>
      <contributor>
        <ip>117.232.206.110</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="33177">{{short description|Study of the dynamics of species populations and how these populations interact with the environment}}
[[File:UN_DESA_continent_population_1950_to_2100.svg|300px|thumbnail|right|[[human population growth|The human population is growing]] at a logistic rate and has been affecting the populations of other species in return.  [[pollution|Chemical pollution]], [[deforestation]], and population is a very big problem.[[irrigation]] are examples of means by which humans may influence the population ecology of other species. As the human population increases, its effect on the populations of other species may also increase.]]
[[File:Phanerozoic Biodiversity.svg|300px|thumbnail|right|Populations cannot grow indefinitely. Population ecology involves studying factors that affect population growth and survival. [[Mass extinctions]] are examples of factors that have radically reduced populations' sizes and populations' [[survivability]]. The survivability of populations is critical to maintaining high levels of [[biodiversity]] on Earth. ]] '''Population ecology'''  is a sub-field of [[ecology]] that deals with the dynamics of [[species]] [[population]]s and how these populations interact with the [[natural environment|environment]].&lt;ref name="Odum1959"&gt;{{cite book | last =Odum | first =Eugene P. | authorlink =Eugene Odum | title =Fundamentals of Ecology | edition=Second| publisher =W. B. Saunders Co. | year =1959 | location =Philadelphia and London  | isbn = 9780721669410|oclc = 554879 | page =546 p}}&lt;/ref&gt; It is the study of how the [[population size]]s of species change over time and space. The term population ecology is often used interchangeably with [[population biology]] or [[population dynamics]]. 

The development of population ecology owes much to [[demography]] and [[actuary|actuarial]] [[life table]]s. Population ecology is important in [[conservation biology]], especially in the development of [[population viability analysis]] (PVA) which makes it possible to predict the long-term probability of a species persisting in a given habitat patch. Although population ecology is a subfield of [[biology]], it provides interesting problems for [[mathematics|mathematicians]] and [[statistics|statisticians]] who work in [[population dynamics]].

==Fundamentals==

{| class="wikitable"
|+ Terms used to describe natural groups of individuals in ecological studies&lt;ref name="Wells95"&gt;{{Cite journal|last=Wells |first=J. V. |last2=Richmond |first2=M. E. |title=Populations, metapopulations, and species populations: What are they and who should care? |journal=Wildlife Society Bulletin |volume=23 |issue=3 |pages=458–462 |year=1995 |url=http://www.uoguelph.ca/zoology/courses/BIOL3130/wells11.pdf |format= |deadurl=yes |archiveurl=https://web.archive.org/web/20051104081736/http://www.uoguelph.ca/zoology/courses/BIOL3130/wells11.pdf |archivedate=November 4, 2005 }}&lt;/ref&gt;
!width="120"|Term
!! !|Definition
|-valign="top"
|'''Species population''' || All individuals of a species.
|-valign="top"
|'''Metapopulation''' || A set of spatially disjunct populations, among which there is some immigration.
|-valign="top"
|'''Population''' || A group of conspecific individuals that is demographically, genetically, or spatially disjunct from other groups of individuals.
|-valign="top"
| '''Aggregation''' || A spatially clustered group of individuals.
|-valign="top"
| '''Deme''' || A group of individuals more genetically similar to each other than to other individuals, usually with some degree of spatial isolation as well.
|-valign="top"
| '''Local population''' || A group of individuals within an investigator-delimited area smaller than the geographic range of the species and often within a population (as defined above). A local population could be a disjunct population as well.
|-valign="top"
|'''Subpopulation''' || An arbitrary spatially delimited subset of individuals from within a population (as defined above).
|}

The most fundamental law of population ecology is [[Thomas Malthus]]' exponential law of population growth.&lt;ref name="Turchin01"&gt;{{Cite journal  | last = Turchin  | first = P.  | title = Does Population Ecology Have General Laws?  | journal = Oikos
  | volume = 94  | issue = 1  | pages = 17–26  | year = 2001  | doi = 10.1034/j.1600-0706.2001.11310.x  | postscript = &lt;!--None--&gt;}}&lt;/ref&gt;
&lt;blockquote&gt;
''A population will grow (or decline) exponentially as long as the environment experienced by all individuals in the population remains constant.''&lt;ref name="Turchin01" /&gt;{{rp|18}}
&lt;/blockquote&gt;

[[File:Thomas Robert Malthus Wellcome L0069037 -crop.jpg|thumbnail|left|[[Thomas Robert Malthus]]]]

This principle in population ecology provides the basis for formulating predictive theories and tests that follow:

Simplified population models usually start with four key variables (four '''demographic processes''') including death, birth, immigration, and emigration. Mathematical models used to calculate changes in population demographics and evolution hold the assumption (or [[null hypothesis]]) of no external influence. Models can be more mathematically complex where "...several competing hypotheses are simultaneously confronted with the data."&lt;ref name="Johnson04"&gt;{{Cite journal  | last = Johnson  | first = J. B.  | last2 = Omland  | first2 = K. S.  | title = Model selection in ecology and evolution.  | journal = Trends in Ecology and Evolution  | volume = 19  | issue = 2  | pages = 101–108  | year = 2004  | url = http://www.usm.maine.edu/bio/courses/bio621/model_selection.pdf  | doi = 10.1016/j.tree.2003.10.013  | pmid = 16701236  | postscript = &lt;!--None--&gt;}}&lt;/ref&gt; For example, in a closed system where immigration and emigration does not take place, the rate of change in the number of individuals in a population can be described as:

: &lt;math&gt;\frac{dN}{dT} = B - D = bN - dN = (b - d)N = rN,&lt;/math&gt;

where ''N'' is the total number of individuals in the population, ''B'' is the '''raw''' number of births, ''D'' is the '''raw''' number of deaths, ''b'' and ''d'' are the '''per capita''' rates of birth and death respectively, and ''r'' is the '''per capita''' average number of surviving offspring each individual has. This formula can be read as the rate of change in the population (''dN/dT'') is equal to births minus deaths (B - D).&lt;ref name="Turchin01" /&gt;&lt;ref name="Vandermeer03"&gt;{{Cite book  | last = Vandermeer  | first = J. H.  | last2 = Goldberg  | first2 = D. E.  | title = Population ecology: First principles  | place = Woodstock, Oxfordshire  | publisher = Princeton University Press  | year = 2003  | isbn =  0-691-11440-4  | postscript = &lt;!--None--&gt;}}&lt;/ref&gt;

Using these techniques, Malthus' population principle of growth was later transformed into a mathematical model known as the [[Logistic function#In ecology: modeling population growth|logistic equation]]:

: &lt;math&gt;\frac{dN}{dT} = aN \left( 1 - \frac{N}{K} \right),&lt;/math&gt;

where ''N'' is the biomass density, ''a'' is the maximum per-capita rate of change, and ''K'' is the [[carrying capacity]] of the population. The formula can be read as follows: the rate of change in the population (''dN/dT'') is equal to growth (''aN'') that is limited by carrying capacity ''(1-N/K)''. From these basic mathematical principles the discipline of population ecology expands into a field of investigation that queries the [[demographics]] of real populations and tests these results against the statistical models. The field of population ecology often uses data on life history and matrix algebra to develop projection matrices on fecundity and survivorship. This information is used for managing wildlife stocks and setting harvest quotas &lt;ref name="Vandermeer03" /&gt;&lt;ref name="Berryman92"&gt;{{Cite journal  | last = Berryman  | first = A. A.  | title = The Origins and Evolution of Predator-Prey Theory  | journal = Ecology  | volume = 73  | issue = 5  | pages = 1530–1535  | year = 1992  | doi = 10.2307/1940005  | publisher = Ecology, Vol. 73, No. 5  | jstor = 1940005}}&lt;/ref&gt;

{{clear}}

== Geometric populations ==

[[File:Operophtera.brumata.6961.jpg|thumbnail|left|''Operophtera brumata'' (Winter moth) populations are geometric.&lt;ref&gt;{{cite journal|last1=Hassell|first1=Michael P.|title=Foraging Strategies, Population Models and Biological Control: A Case Study|journal=The Journal of Animal Ecology|date=June 1980|volume=49|issue=2|pages=603|doi=10.2307/4267}}&lt;/ref&gt;]]
The population model below can be manipulated to mathematically infer certain properties of [[geometric]] populations. A population with a size that increases geometrically is a population where generations of reproduction do '''not''' overlap.&lt;ref name="afrc.uamont.edu"&gt;{{cite web|title=GEOMETRIC AND EXPONENTIAL POPULATION MODELS|url=http://www.afrc.uamont.edu/whited/Geometric%20and%20exponential%20population%20models.pdf}}&lt;/ref&gt; In each generation there is an [[effective population size]] denoted as &lt;big&gt;N&lt;sub&gt;e&lt;/sub&gt;&lt;/big&gt; which constitutes the number of individuals in the population that are able to reproduce ''and'' will reproduce in any reproductive generation in concern.&lt;ref&gt;{{cite web|last1=Holsinger|first1=Kent|title=Effective Population Size|url=http://darwin.eeb.uconn.edu/eeb348/lecture-notes/drift/node7.html|date=2008-08-26}}&lt;/ref&gt; In the population model below it is assumed that &lt;big&gt;N&lt;/big&gt; is the effective population size.&lt;ref name="afrc.uamont.edu"/&gt;

'''Assumption 01''': &lt;big&gt;N&lt;sub&gt;e&lt;/sub&gt;&lt;/big&gt; &lt;big&gt;=&lt;/big&gt; &lt;big&gt;N&lt;/big&gt;

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = N&lt;sub&gt;t&lt;/sub&gt; + B&lt;sub&gt;t&lt;/sub&gt; + I&lt;sub&gt;t&lt;/sub&gt; - D&lt;sub&gt;t&lt;/sub&gt;  - E&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''N&lt;sub&gt;t+1&lt;/sub&gt;''' || Population size in the generation after generation &lt;sub&gt;'''t'''&lt;/sub&gt;. This may be the current generation or the next (upcoming) generation depending on the situation in which the population model is used.
|-
| '''N&lt;sub&gt;t&lt;/sub&gt;''' || Population size in generation &lt;sub&gt;'''t'''&lt;/sub&gt;.
|-
| '''B&lt;sub&gt;t&lt;/sub&gt;''' || Sum (Σ) of births in the population between generations '''&lt;sub&gt;t&lt;/sub&gt;''' and '''&lt;sub&gt;t+1&lt;/sub&gt;'''. Also known as '''raw''' birth rate.
|-
| '''I&lt;sub&gt;t&lt;/sub&gt;''' || Sum (Σ) of [[immigrants]] moving into the population between generations '''&lt;sub&gt;t&lt;/sub&gt;''' and '''&lt;sub&gt;t+1&lt;/sub&gt;'''. Also known as '''raw''' [[immigration]] rate.
|-
| '''D&lt;sub&gt;t&lt;/sub&gt;''' || Sum (Σ) of deaths in the population between generations '''&lt;sub&gt;t&lt;/sub&gt;''' and '''&lt;sub&gt;t+1&lt;/sub&gt;'''. Also known as '''raw''' death rate.
|-
| '''E&lt;sub&gt;t&lt;/sub&gt;''' || Sum (Σ) of [[emigrants]] moving out of the population between generations '''&lt;sub&gt;t&lt;/sub&gt;''' and '''&lt;sub&gt;t+1&lt;/sub&gt;'''. Also known as '''raw''' [[emigration]] rate.
|-
|}

[[File:The general difference between populations that grow exponentially and geometrically.png|400px|thumb|'''The general difference between populations that grow exponentially and geometrically.'''
 Geometric populations grow in reproductive generations between intervals of [[abstinence]] from reproduction. Exponential populations grow without designated periods for reproduction. Reproduction is a [[continuity (mathematics)|continuous]] process and generations of reproduction overlap. This graph illustrates two hypothetical populations - one population growing periodically (and therefore geometrically) and the other population growing continuously (and therefore exponentially). The populations in the graph have a doubling time of 1 year. The populations in the graph are hypothetical. In reality, the doubling times differ between populations.]]

'''Assumption 02''': There is no migration to or from the population (&lt;big&gt;N&lt;/big&gt;)

&lt;big&gt;'''I&lt;sub&gt;t&lt;/sub&gt;  = E&lt;sub&gt;t&lt;/sub&gt; = 0'''&lt;/big&gt;

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = N&lt;sub&gt;t&lt;/sub&gt; + B&lt;sub&gt;t&lt;/sub&gt; - D&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

The '''raw''' birth and death rates are related to the '''per capita''' birth and death rates:

&lt;big&gt;'''B&lt;sub&gt;t&lt;/sub&gt; = b&lt;sub&gt;t&lt;/sub&gt; × N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

&lt;big&gt;'''D&lt;sub&gt;t&lt;/sub&gt; = d&lt;sub&gt;t&lt;/sub&gt; × N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

&lt;big&gt;'''b&lt;sub&gt;t&lt;/sub&gt; = B&lt;sub&gt;t&lt;/sub&gt; / N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

&lt;big&gt;'''d&lt;sub&gt;t&lt;/sub&gt; = D&lt;sub&gt;t&lt;/sub&gt; / N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''b&lt;sub&gt;t&lt;/sub&gt;''' || '''Per capita''' birth rate.
|-
| '''d&lt;sub&gt;t&lt;/sub&gt;''' || '''Per capita''' death rate.
|-
|}

Therefore:

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = N&lt;sub&gt;t&lt;/sub&gt; + (b&lt;sub&gt;t&lt;/sub&gt; × N&lt;sub&gt;t&lt;/sub&gt;) - (d&lt;sub&gt;t&lt;/sub&gt; × N&lt;sub&gt;t&lt;/sub&gt;)'''&lt;/big&gt;

'''Assumption 03''': '''b&lt;sub&gt;t&lt;/sub&gt;''' and '''d&lt;sub&gt;t&lt;/sub&gt;''' are constant (i.e. they don't change each generation).

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = N&lt;sub&gt;t&lt;/sub&gt; + (bN&lt;sub&gt;t&lt;/sub&gt;) - (dN&lt;sub&gt;t&lt;/sub&gt;)'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''b''' || Constant '''per capita''' birth rate.
|-
| '''d''' || Constant '''per capita''' death rate.
|-
|}

Take the term '''N&lt;sub&gt;t&lt;/sub&gt;''' out of the brackets.

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = N&lt;sub&gt;t&lt;/sub&gt; + (b - d)N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

&lt;big&gt;'''b - d = R'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''R''' || Geometric rate of increase.
|-

|}

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = N&lt;sub&gt;t&lt;/sub&gt; + RN&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = (N&lt;sub&gt;t&lt;/sub&gt; + RN&lt;sub&gt;t&lt;/sub&gt;)'''&lt;/big&gt;

Take the term '''N&lt;sub&gt;t&lt;/sub&gt;''' out of the brackets again.

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = (1 + R)N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

&lt;big&gt;'''1 + R = λ'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''λ''' || [[Infinity|Finite]] rate of increase.
|-

|}

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = λN&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

{| class="wikitable"
|-
| At &lt;sub&gt;'''t+1'''&lt;/sub&gt; || &lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = λN&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;
|-
| At &lt;sub&gt;'''t+2'''&lt;/sub&gt; || &lt;big&gt;'''N&lt;sub&gt;t+2&lt;/sub&gt; = λN&lt;sub&gt;t+1&lt;/sub&gt; = λλN&lt;sub&gt;t&lt;/sub&gt; = λ&lt;sup&gt;2&lt;/sup&gt;N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;
|-
| At &lt;sub&gt;'''t+3'''&lt;/sub&gt; || &lt;big&gt;'''N&lt;sub&gt;t+3&lt;/sub&gt; = λN&lt;sub&gt;t+2&lt;/sub&gt; = λλN&lt;sub&gt;t+1&lt;/sub&gt; = λλλN&lt;sub&gt;t&lt;/sub&gt; = λ&lt;sup&gt;3&lt;/sup&gt;N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;
|-
| At &lt;sub&gt;'''t+4'''&lt;/sub&gt; || &lt;big&gt;'''N&lt;sub&gt;t+4&lt;/sub&gt; = λN&lt;sub&gt;t+3&lt;/sub&gt; = λλN&lt;sub&gt;t+2&lt;/sub&gt; = λλλN&lt;sub&gt;t+1&lt;/sub&gt; = λλλλN&lt;sub&gt;t&lt;/sub&gt; = λ&lt;sup&gt;4&lt;/sup&gt;N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;
|-
| At &lt;sub&gt;'''t+5'''&lt;/sub&gt; || &lt;big&gt;'''N&lt;sub&gt;t+5&lt;/sub&gt; = λN&lt;sub&gt;t+4&lt;/sub&gt; = λλN&lt;sub&gt;t+3&lt;/sub&gt; = λλλN&lt;sub&gt;t+2&lt;/sub&gt; = λλλλN&lt;sub&gt;t+1&lt;/sub&gt; = λλλλλN&lt;sub&gt;t&lt;/sub&gt; = λ&lt;sup&gt;5&lt;/sup&gt;N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;
|}

Therefore:

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = λ&lt;sup&gt;t&lt;/sup&gt;N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''λ&lt;sup&gt;t&lt;/sup&gt;''' || [[Infinity|Finite]] rate of increase raised to the power of the number of generations (e.g. for '''&lt;sub&gt;t+2&lt;/sub&gt;''' [two generations] → '''λ&lt;sup&gt;2&lt;/sup&gt;''' , for '''&lt;sub&gt;t+1&lt;/sub&gt;''' [one generation] → '''λ&lt;sup&gt;1&lt;/sup&gt; = λ''', and for '''&lt;sub&gt;t&lt;/sub&gt;''' [before any generations - at time zero] → '''λ&lt;sup&gt;0&lt;/sup&gt; = 1'''
|-

|}

=== Doubling time of geometric populations ===

[[File:G. stearothermophilus has a shorter doubling time (td) than E. coli and N. meningitidis.png|400px|thumbnail|right|'''''G. stearothermophilus'' has a shorter doubling time (td) than ''E. coli'' and ''N. meningitidis''.''' Growth rates of 2 [[bacteria]]l species will differ by unexpected orders of magnitude if the doubling times of the 2 species differ by even as little as 10 minutes. In [[eukaryote]]s such as animals, fungi, plants, and protists, doubling times are much longer than in bacteria. This reduces the growth rates of eukaryotes in comparison to Bacteria. ''[[Bacillus stearothermophilus|G. stearothermophilus]]'', ''[[Escherichia coli|E. coli]]'', and ''[[Neisseria meningitidis|N. meningitidis]]'' have 20 minute,&lt;ref&gt;{{cite web|title=Bacillus stearothermophilus NEUF2011|url=https://microbewiki.kenyon.edu/index.php/Bacillus_stearothermophilus_NEUF2011|website=Microbe wiki}}&lt;/ref&gt; 30 minute,&lt;ref&gt;{{cite journal|last1=Chandler|first1=M.|last2=Bird|first2=R.E.|last3=Caro|first3=L.|title=The replication time of the Escherichia coli K12 chromosome as a function of cell doubling time|journal=Journal of Molecular Biology|date=May 1975|volume=94|issue=1|pages=127–132|doi=10.1016/0022-2836(75)90410-6}}&lt;/ref&gt; and 40 minute&lt;ref&gt;{{cite journal|last1=Tobiason|first1=D. M.|last2=Seifert|first2=H. S.|title=Genomic Content of Neisseria Species|journal=Journal of Bacteriology|date=19 February 2010|volume=192|issue=8|pages=2160–2168|doi=10.1128/JB.01593-09|pmc=2849444}}&lt;/ref&gt; doubling times under optimal conditions respectively. If bacterial populations could grow indefinitely (which they do not) then the number of bacteria in each species would approach infinity ('''∞'''). However, the percentage of ''G. stearothermophilus'' bacteria out of all the bacteria would approach '''100%''' whilst the percentage of ''E. coli'' and ''N. meningitidis'' combined out of all the bacteria would approach '''0%'''. This graph is a [[simulation]] of this hypothetical scenario. In reality, bacterial populations do not grow indefinitely in size and the 3 species require different optimal conditions to bring their doubling times to minima. 
{|
|-
! Time in minutes !! % that is ''G. stearothermophilus''
|-
| 30 || 44.4%
|-
| 60 || 53.3%
|-
| 90 || 64.9%
|-
| 120 || 72.7%
|-
| →∞ || 100%
|}

{|
|-
! Time in minutes !! % that is ''E. coli''
|-
| 30 || 29.6%
|-
| 60 || 26.7%
|-
| 90 || 21.6%
|-
| 120 || 18.2%
|-
| →∞ || 0.00%
|}

{|
|-
! Time in minutes !! % that is ''N. meningitidis''
|-
| 30 || 25.9%
|-
| 60 || 20.0%
|-
| 90 || 13.5%
|-
| 120 || 9.10%
|-
| →∞ || 0.00%
|}

&lt;small&gt;''Disclaimer: Bacterial populations are exponential (or, more correctly, [[logistic function|logistic]]) instead of geometric. Nevertheless, doubling times are applicable to both types of populations.''&lt;/small&gt;
]]

The [[doubling time]] of a population is the time required for the population to grow to twice its size.&lt;ref&gt;{{cite web|title=What is Doubling Time and How is it Calculated?|first=Lauren|last=Boucher|date=24 March 2015|website=Population Education|url=https://www.populationeducation.org/content/what-doubling-time-and-how-it-calculated}}&lt;/ref&gt; We can calculate the [[doubling time]] of a geometric population using the equation: &lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = λ&lt;sup&gt;t&lt;/sup&gt;N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt; by exploiting our knowledge of the fact that the population (&lt;big&gt;N&lt;/big&gt;) is twice its size (&lt;big&gt;2N&lt;/big&gt;) after the doubling time.&lt;ref name="afrc.uamont.edu"/&gt;

&lt;big&gt;'''2N&lt;sub&gt;t&lt;sub&gt;d&lt;/sub&gt;&lt;/sub&gt; = λ&lt;sup&gt;t&lt;sub&gt;d&lt;/sub&gt;&lt;/sup&gt; × N&lt;sub&gt;t&lt;/sub&gt;
'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''t&lt;sub&gt;d&lt;/sub&gt;''' || Doubling time.
|-

|}

&lt;big&gt;'''λ&lt;sup&gt;t&lt;sub&gt;d&lt;/sub&gt;&lt;/sup&gt; = 2N&lt;sub&gt;t&lt;sub&gt;d&lt;/sub&gt;&lt;/sub&gt; /  N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

'''&lt;big&gt;λ&lt;sup&gt;t&lt;sub&gt;d&lt;/sub&gt;&lt;/sup&gt; = 2&lt;/big&gt;'''

The doubling time can be found by taking logarithms. For instance:

&lt;big&gt;'''t&lt;sub&gt;d&lt;/sub&gt; × log&lt;sub&gt;2&lt;/sub&gt;(λ) = log&lt;sub&gt;2&lt;/sub&gt;(2)'''&lt;/big&gt;

&lt;big&gt;'''log&lt;sub&gt;2&lt;/sub&gt;(2) = 1'''&lt;/big&gt;

&lt;big&gt;'''t&lt;sub&gt;d&lt;/sub&gt; × log&lt;sub&gt;2&lt;/sub&gt;(λ) = 1'''&lt;/big&gt;

'''&lt;big&gt;t&lt;sub&gt;d&lt;/sub&gt; = 1 / log&lt;sub&gt;2&lt;/sub&gt;(λ)&lt;/big&gt;'''

Or:

&lt;big&gt;'''t&lt;sub&gt;d&lt;/sub&gt; × ln(λ) = ln(2)'''&lt;/big&gt;

'''&lt;big&gt;t&lt;sub&gt;d&lt;/sub&gt; = ln(2) / ln(λ)&lt;/big&gt;'''

'''&lt;big&gt;t&lt;sub&gt;d&lt;/sub&gt; = 0.693... / ln(λ)&lt;/big&gt;'''

Therefore:

'''&lt;big&gt;t&lt;sub&gt;d&lt;/sub&gt; = 1 / log&lt;sub&gt;2&lt;/sub&gt;(λ) = 0.693... / ln(λ) &lt;/big&gt;'''

=== Half-life of geometric populations ===

The [[half-life]] of a population is the time taken for the population to decline to half its size. We can calculate the half-life of a geometric population using the equation: &lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = λ&lt;sup&gt;t&lt;/sup&gt;N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt; by exploiting our knowledge of the fact that the population (&lt;big&gt;N&lt;/big&gt;) is half its size (&lt;big&gt;0.5N&lt;/big&gt;) after a half-life.&lt;ref name="afrc.uamont.edu"/&gt;

&lt;big&gt;'''0.5N&lt;sub&gt;t&lt;sub&gt;1/2&lt;/sub&gt;&lt;/sub&gt; = λ&lt;sup&gt;t&lt;sub&gt;1/2&lt;/sub&gt;&lt;/sup&gt; × N&lt;sub&gt;t&lt;/sub&gt;
'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''t&lt;sub&gt;1/2&lt;/sub&gt;''' || Half-life.
|-

|}

&lt;big&gt;'''λ&lt;sup&gt;t&lt;sub&gt;1/2&lt;/sub&gt;&lt;/sup&gt; = 0.5N&lt;sub&gt;t&lt;sub&gt;1/2&lt;/sub&gt;&lt;/sub&gt; /  N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

'''&lt;big&gt;λ&lt;sup&gt;t&lt;sub&gt;1/2&lt;/sub&gt;&lt;/sup&gt; = 0.5&lt;/big&gt;'''

The half-life can be calculated by taking logarithms (see above).

'''&lt;big&gt;t&lt;sub&gt;1/2&lt;/sub&gt; = 1 / log&lt;sub&gt;0.5&lt;/sub&gt;(λ) = ln(0.5) / ln(λ) &lt;/big&gt;'''

=== Geometric (R) and finite (λ) growth constants ===

==== Geometric (R) growth constant ====

'''&lt;big&gt;R = b - d&lt;/big&gt;'''

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = N&lt;sub&gt;t&lt;/sub&gt; + RN&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

'''&lt;big&gt;N&lt;sub&gt;t+1&lt;/sub&gt; - N&lt;sub&gt;t&lt;/sub&gt; = RN&lt;sub&gt;t&lt;/sub&gt;&lt;/big&gt;'''

'''&lt;big&gt;N&lt;sub&gt;t+1&lt;/sub&gt; - N&lt;sub&gt;t&lt;/sub&gt; = ΔN&lt;/big&gt;'''

{| class="wikitable"
|-
! Term !! Definition
|-
| '''ΔN''' || Change in population size between two generations (between generation '''&lt;sub&gt;t+1&lt;/sub&gt;''' and '''&lt;sub&gt;t&lt;/sub&gt;''').
|-

|}

'''&lt;big&gt;ΔN = RN&lt;sub&gt;t&lt;/sub&gt;&lt;/big&gt;'''

'''&lt;big&gt;ΔN/N&lt;sub&gt;t&lt;/sub&gt; = R&lt;/big&gt;'''

==== Finite (λ) growth constant ====

&lt;big&gt;'''1 + R = λ'''&lt;/big&gt;

&lt;big&gt;'''N&lt;sub&gt;t+1&lt;/sub&gt; = λN&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

&lt;big&gt;'''λ = N&lt;sub&gt;t+1&lt;/sub&gt; / N&lt;sub&gt;t&lt;/sub&gt;'''&lt;/big&gt;

===Mathematical relationship between geometric and exponential populations===

In geometric populations, &lt;big&gt;R&lt;/big&gt; and &lt;big&gt;λ&lt;/big&gt; represent growth constants (see [[Population ecology#Geometric populations|2]] and [[Population ecology#Geometric .28R.29 and finite .28.CE.BB.29 growth constants|2.3]]). In [[exponential growth|exponential]] populations however, the [[Population dynamics#Intrinsic rate of increase|intrinsic growth rate]], also known as [[Population dynamics#Intrinsic rate of increase|intrinsic rate of increase]] (&lt;big&gt;r&lt;/big&gt;) is the relevant growth constant. Since generations of reproduction in a geometric population do not overlap (e.g. reproduce once a year) but do in an exponential population, geometric and exponential populations are usually considered to be mutually exclusive.&lt;ref&gt;{{cite web|title=Population Growth|website=[[University of Alberta]]|url=http://www.biology.ualberta.ca/courses.hp/bio208/Lecture_Notes_files/Biol208_Lecture19_PopulationGrowth.pdf}}&lt;/ref&gt; However, geometric constants and exponential constants share the mathematical relationship below.&lt;ref name="afrc.uamont.edu"/&gt;

The growth equation for exponential populations is

&lt;big&gt;'''N&lt;sub&gt;t&lt;/sub&gt; = N&lt;sub&gt;0&lt;/sub&gt;e&lt;sup&gt;rt&lt;/sup&gt;'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''e''' || [[Euler's number]] - A [[universal constant]] often applicable in exponential equations.
|-
| '''r''' || [[Population dynamics#Intrinsic rate of increase|intrinsic growth rate]] - also known as [[Population dynamics#Intrinsic rate of increase|intrinsic rate of increase]].
|-
|}
[[File:Leonhard Euler 2.jpg|thumbnail|right|[[Leonhard Euler]] was the mathematician who established the universal constant 2.71828... also known as [[Euler's number]] or '''e'''.]]

'''Assumption:''' &lt;big&gt;N&lt;sub&gt;t&lt;/sub&gt;&lt;/big&gt; ''(of a geometric population)'' &lt;big&gt;=&lt;/big&gt; &lt;big&gt;N&lt;sub&gt;t&lt;/sub&gt;&lt;/big&gt; ''(of an exponential population)''.

Therefore:

'''&lt;big&gt;N&lt;sub&gt;0&lt;/sub&gt;e&lt;sup&gt;rt&lt;/sup&gt; = N&lt;sub&gt;0&lt;/sub&gt;λ&lt;sup&gt;t&lt;/sup&gt;&lt;/big&gt;'''

&lt;big&gt;'''N&lt;sub&gt;0&lt;/sub&gt;'''&lt;/big&gt; cancels on both sides.

'''&lt;big&gt;N&lt;sub&gt;0&lt;/sub&gt;e&lt;sup&gt;rt&lt;/sup&gt; / N&lt;sub&gt;0&lt;/sub&gt; = λ&lt;sup&gt;t&lt;/sup&gt;&lt;/big&gt;'''

'''&lt;big&gt;e&lt;sup&gt;rt&lt;/sup&gt; = λ&lt;sup&gt;t&lt;/sup&gt;&lt;/big&gt;'''

Take the [[natural logarithm]]s of the equation. Using natural logarithms instead of base 10 or base 2 logarithms simplifies the final equation as ln(e) = 1.
 
&lt;big&gt;'''rt × ln(e) = t × ln(λ)'''&lt;/big&gt;

{| class="wikitable"
|-
! Term !! Definition
|-
| '''ln''' || [[natural logarithm]] - in other words '''ln(y) = log&lt;sub&gt;e&lt;/sub&gt;(y)''' '''= x =''' the power ('''x''') that '''e''' needs to be raised to ('''e&lt;sup&gt;x&lt;/sup&gt;''') to give the answer '''y'''.
In this case, '''e&lt;sup&gt;1&lt;/sup&gt; = e therefore ln(e) = 1'''.
|-
|}

&lt;big&gt;'''rt × 1 = t × ln(λ)'''&lt;/big&gt;

&lt;big&gt;'''rt = t × ln(λ)'''&lt;/big&gt;

&lt;big&gt;'''t'''&lt;/big&gt; cancels on both sides.

&lt;big&gt;'''rt / t = ln(λ)'''&lt;/big&gt;

The results:

&lt;big&gt;'''r = ln(λ)'''&lt;/big&gt;

and

&lt;big&gt;'''e&lt;sup&gt;r&lt;/sup&gt; = λ'''&lt;/big&gt;

==r/K selection==
{{main|r/K selection}}
{{quote box
| quote = At its most elementary level, interspecific competition involves two species utilizing a similar [[Resource (biology)|resource]]. It rapidly gets more complicated, but stripping the phenomenon of all its complications, this is the basic principle: two consumers consuming the same resource.&lt;ref name="Vandermeer03" /&gt;{{rp|222}}
| width = 25%
| align = right}}

An important concept in population ecology is the [[r/K selection]] theory. The first variable is ''r'' (the intrinsic rate of natural increase in population size, density independent) and the second variable is ''K'' (the carrying capacity of a population, density dependent).&lt;ref name="Begon06"&gt;{{Cite book
| last = Begon
| first = M.
| last2 = Townsend
| first2 = C. R.
| last3 = Harper
| first3 = J. L.
| title = Ecology: From Individuals to Ecosystems
| place = Oxford, UK
| publisher = Blackwell Publishing
| year = 2006
| edition = 4th
| url = https://books.google.com/?id=Lsf1lkYKoHEC&amp;printsec=frontcover&amp;dq=ecology&amp;cd=1#v=onepage&amp;q=
| isbn = 978-1-4051-1117-1
| postscript = &lt;!--None--&gt;}}&lt;/ref&gt;
An ''r''-selected species (e.g., many kinds of insects, such as aphids&lt;ref name="Whitman78"&gt;{{Cite journal  | last = Whitham  | first = T. G.  | title = Habitat Selection by Pemphigus Aphids in Response to Response Limitation and Competition  | journal = Ecology  | volume = 59  | issue = 6  | pages = 1164–1176  | year = 1978  | doi = 10.2307/1938230  | publisher = Ecology, Vol. 59, No. 6  | jstor = 1938230}}&lt;/ref&gt;) is one that has high rates of fecundity, low levels of parental investment in the young, and high rates of mortality before individuals reach maturity. Evolution favors productivity in r-selected species. In contrast, a ''K''-selected species (such as humans) has low rates of fecundity, high levels of parental investment in the young, and low rates of mortality as individuals mature. Evolution in ''K''-selected species favors efficiency in the conversion of more [[Resource (biology)|resources]] into fewer offspring.&lt;ref name="MacArthur67"&gt;{{Cite journal  | last = MacArthur   | first = R.  | last2 = Wilson  | first2 = E. O.  | title = The Theory of Island Biogeography  | place = Princeton, NJ  | publisher = Princeton University Press  | year = 1967  | postscript = &lt;!--None--&gt;}}&lt;/ref&gt;&lt;ref name="Pianka72"&gt;{{Cite journal  | last = Pianka  | first = E. R.  | title = r and K Selection or b and d Selection?  | journal = The American Naturalist  | volume = 106  | issue = 951  | pages = 581–588  | year = 1972  | doi = 10.1086/282798}}&lt;/ref&gt;

==Metapopulation==
{{main|Metapopulation}}

Populations are also studied and conceptualized through the "[[metapopulation]]" concept. The metapopulation concept was introduced in 1969:&lt;ref name="Levins69"&gt;{{Cite journal  | last = Levins  | first = R.  | title = Some demographic and genetic consequences of environmental heterogeneity for biological control  | journal = Bulletin of the Entomological Society of America  | volume = 15  | pages = 237–240  | year = 1969  | url = https://books.google.com/?id=8jfmor8wVG4C&amp;pg=PA162&amp;q=  | publisher = Columbia University Press  | isbn = 978-0-231-12680-9}}&lt;/ref&gt;&lt;blockquote&gt; "as a population of populations which go extinct locally and recolonize."&lt;ref name="Levins70"&gt;{{Cite book  | last = Levins  | first = R.  | editor-last = Gerstenhaber  | editor-first = M.  | title = Extinction. In: Some Mathematical Questions in Biology  | year = 1970  | pages = 77–107  | url = https://books.google.com/?id=CfZHU1aZqJsC&amp;dq=Some+Mathematical+Questions+in+Biology&amp;printsec=frontcover&amp;q=  | publisher = AMS Bookstore  | isbn = 978-0-8218-1152-8}}&lt;/ref&gt;{{rp|105}}&lt;/blockquote&gt; Metapopulation ecology is a simplified model of the landscape into patches of varying levels of quality.&lt;ref name="Hanski98"&gt;{{Cite journal  | last = Hanski  | first = I.  | title = Metapopulation dynamics  | journal = Nature  | volume = 396  | pages = 41–49  | year = 1998  | url = http://www.helsinki.fi/~ihanski/Articles/Nature%201998%20Hanski.pdf  | doi = 10.1038/23876  | issue = 6706  | deadurl = yes  | archiveurl = https://web.archive.org/web/20101231165339/http://www.helsinki.fi/~ihanski/Articles/Nature%201998%20Hanski.pdf  | archivedate = 2010-12-31  | df =   }}&lt;/ref&gt; Patches are either occupied or they are not. Migrants moving among the patches are structured into metapopulations either as sources or sinks. Source patches are productive sites that generate a seasonal supply of migrants to other patch locations. Sink patches are unproductive sites that only receive migrants. In metapopulation terminology there are emigrants (individuals that leave a patch) and immigrants (individuals that move into a patch). Metapopulation models examine patch dynamics over time to answer questions about spatial and demographic ecology. An important concept in metapopulation ecology is the rescue effect, where small patches of lower quality (i.e., sinks) are maintained by a seasonal influx of new immigrants. Metapopulation structure evolves from year to year, where some patches are sinks, such as dry years, and become sources when conditions are more favorable. Ecologists utilize a mixture of computer models and field studies to explain metapopulation structure.&lt;ref name="Hanski04"&gt;{{Cite book  | editor-last = Hanski  | editor-first = I.  | editor2-last = Gaggiotti  | editor2-first = O. E.  | title = Ecology, genetics and evolution of metapopulations.  | publisher = Elsevier Academic Press | year = 2004  | location = Burlington, MA  | url = https://books.google.com/?id=EP8TAQAAIAAJ&amp;q=ecology,+genetics,+and+evolution+of+metapopulations&amp;dq=ecology,+genetics,+and+evolution+of+metapopulations&amp;cd=1  | isbn = 0-12-323448-4}}&lt;/ref&gt;

==History==
The older term, autecology (from Greek: αὐτο, ''auto'', "self"; οίκος, oikos, "household"; and λόγος, logos, "knowledge"), refers to roughly the same field of study as population ecology. It derives from the division of ecology into autecology—the study of individual species in relation to the environment—and [[Community ecology|synecology]]—the study of groups of organisms in relation to the environment—or community ecology. Odum (1959, p.&amp;nbsp;8) considered that synecology should be divided into population ecology, community ecology, and ecosystem ecology, defining autecology as essentially "species ecology."&lt;ref name="Odum1959"/&gt; However, for some time biologists have recognized that the more significant level of organization of a species is a population, because at this level the species gene pool is most coherent. In fact, Odum regarded "autecology" as no longer a "present tendency" in ecology (i.e., an archaic term), although included "species ecology"—studies emphasizing [[Biological life cycle|life history]] and behavior as adaptations to the environment of individual organisms or species—as one of four subdivisions of ecology.

==Journals==
The first journal publication of the Society of Population Ecology, titled ''Population Ecology'' (originally called ''Researches on Population Ecology'') was released in 1952.&lt;ref&gt;{{cite web|url=  http://www.springerlink.com/content/1438-3896?sortorder=asc&amp;p=93932389f9764a2aadcbe167b466fcef&amp;o=0|title= Population Ecology}}&lt;/ref&gt;

Scientific articles on population ecology can also be found in the ''[[Journal of Animal Ecology]]'', ''[[Oikos (journal)|Oikos]]'' and other journals.

==See also==
{{Refbegin|3}}
*[[Deep ecology]]
*[[Density-dependent inhibition]]
*[[Irruptive growth]]
*[[Lists of organisms by population]]
*[[Overpopulation (biology)|Overpopulation]]
*[[Overpopulation in companion animals]]
*[[Overshoot (population)]]
*[[Population density]]
*[[Population distribution]]
*[[Population dynamics]]
*[[Population dynamics of fisheries]]
*[[Population genetics]]
*[[Population growth]]
*[[Theoretical ecology]]
{{Refend}}

==References==
{{reflist|2}}

==Further reading==
* {{cite book | last = Kareiva | first = Peter | authorlink =  | editor = Roughgarden J., R.M. May and S. A. Levin | title = Perspectives in ecological theory | edition = | date = | year = 1989
 | month = | publisher = Princeton University Press| location = New Jersey | chapter = Renewing the Dialogue between Theory and Experiments in Population Ecology | page = 394 p}}
* {{cite book | last =Odum | first =Eugene P. | authorlink =Eugene Odum | title =Fundamentals of Ecology | edition=Second| publisher =W. B. Saunders Co. | year =1959 | location =Philadelphia and London  | isbn = 9780721669410|oclc = 554879 | page =546 p}}
*{{cite journal | last =Smith | first =Frederick E. | authorlink =| title =Experimental methods in population dynamics: a critique | journal =Ecology | volume =33 | issue = 4| pages =441–450
  | year =1952| doi = 10.2307/1931519| id = | publisher =Ecology, Vol. 33, No. 4 | jstor = 1931519  }}
*{{cite web|title=Geometric and Exponential Population Models|url=http://www.afrc.uamont.edu/whited/Geometric%20and%20exponential%20population%20models.pdf}}

==External links==
*[http://atlas.aaas.org/ AAAS Atlas of Population and Environment]

{{modelling ecosystems|expanded=other}}

{{DEFAULTSORT:Population Ecology}}
[[Category:Population ecology|*]]
[[Category:Applied statistics]]
[[Category:Population]]
[[Category:Subfields of ecology]]</text>
      <sha1>ezusl6yw8kw7hgos7lxetdjtdd6f8f4</sha1>
    </revision>
  </page>
  <page>
    <title>Pratibandhaka</title>
    <ns>0</ns>
    <id>44946754</id>
    <revision>
      <id>865273145</id>
      <parentid>755919943</parentid>
      <timestamp>2018-10-22T21:23:23Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed grandparent category of [[Category:Hindu philosophical concepts]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11084">{{Hinduism}}

'''Pratibandhaka''' ([[Sanskrit]]:प्रतिबन्धक)  variously means – 'opposition', 'resistance', 'investment', 'blockade', 'siege', 'invariable and inseparable  connection', 'cessation', 'disappointment'; &lt;ref&gt;{{cite book|title=The Practical Sanskrit-English dictionary|author=V.S.Apte|publisher=Digital Dictionaries of South Asia|page=176|url= http://dsalsrv02.uchicago.edu/cgi-bin/philologic/search3advanced?dbname=apte&amp;query=%E0%A4%AA%E0%A5%8D%E0%A4%B0%E0%A4%A4%E0%A4%BF%E0%A4%AC%E0%A4%A8%E0%A5%8D%E0%A4%A7%E0%A4%95&amp;matchtype=exact&amp;display=utf8 }}&lt;/ref&gt; it also means – 'impediment', 'obstacle', 'cognitive blocker', 'antidote' or 'preventive measure'. ''Pratibandhaka'' is a causal dependency &lt;ref&gt;{{cite book|title=Bhatihari and Wittgenstein|publisher=Sahitya Akademi|page=84|url= https://books.google.com/books?id=fS92npC8m5YC&amp;pg=PA84&amp;dq=pratibandhaka&amp;hl=en&amp;sa=X&amp;ei=nkCmVO35KMSUuATsxoGACg&amp;redir_esc=y#v=onepage&amp;q=pratibandhaka&amp;f=false }}&lt;/ref&gt; and refers to something that must perform the specific function of obstructing.&lt;ref&gt;{{cite book|title=A Critique of Causality|author=Sarbani Ganguli|publisher=Sanskrit Book Depot|page=|url= https://books.google.com/books?id=Zg_uAAAAIAAJ&amp;q=pratibandhaka&amp;dq=pratibandhaka&amp;hl=en&amp;sa=X&amp;ei=4j6mVNPaCJKeugTIj4DICQ&amp;redir_esc=y }}&lt;/ref&gt; 

==Jaina concept of causal power==

Prabhachandra, the disciple of Akalarika, endorses the Jaina argument that the causal complex has the causal power of producing effect owing to the existence of some extra-sensory power ('' [[shakti]] ''), that the hindrance in the origination of an effect is caused by counter-agents (''pratibandhaka'') is due to the special power.&lt;ref&gt;{{cite book|title=Encyclopaedia of Indian Philosophies Vol.XII.Part II|publisher=Motilal Banarsidass|page=21|url= http://www.orient.uw.edu.pl/balcerowicz/indology/prabhacandra-PKM.pdf }}&lt;/ref&gt; The followers of [[Jainism]] believe that the universe is full of karmic molecules whose mundane inflow towards the soul is caused by its own vibratory activities through mind, speech and body. [[Karma in Jainism|Karma]] is the invisible power that explains causality, and the matter that binds the soul as a result of actions. But the notion of some power connected with causation is rejected by the [[Nyaya|Nyaya school]] which school concludes that a cognitive state is perceptible only when all causal conditions are present, ''[[abhava]]'' is perceived only in constructive cognitive state. The [[Mīmāṃsā |Mimamsakas]] hold the view the power connected with causation can be destroyed by the presence of an antidote (''pratibandhaka'') and can be resuscitated by an antidote to the antidote. &lt;ref&gt;{{cite book|title=Logic, Language and Reality|author=Bimal Krishna Matilal|publisher=Motilal Banarsidass|page=289,212|url= https://books.google.com/books?id=V8SLH7ogB9oC&amp;pg=PA289&amp;dq=pratibandhaka&amp;hl=en&amp;sa=X&amp;ei=nkCmVO35KMSUuATsxoGACg&amp;redir_esc=y#v=onepage&amp;q=pratibandhaka&amp;f=false }}&lt;/ref&gt;

==Pervasion as ground for inference and Pratibandhaka==

Pervasion (''[[vyapti]]'') is the logical ground for inference which is a valid means of knowledge, and guarantees the truth of conclusion. &lt;ref&gt;{{cite book|title=Companion Encyclopaedia of Hindu philosophy|author= Subodh kapoor|publisher=Genesis Publishing (P) Ltd.|page=68|url=https://books.google.com/books?id=JZWdEymxyp4C&amp;pg=PA68&amp;dq=vyapti&amp;hl=en&amp;sa=X&amp;ei=akw9UbCIDoT_rAecs4GABw&amp;ved=0CEsQ6AEwBQ#v=onepage&amp;q=vyapti&amp;f=false}}&lt;/ref&gt; It is the unconditional and constant concomitant relationship between the pervaded and the pervade. Any person desiring emancipation (a ''mumuksu'') cannot gain liberation (''[[moksha]]'') without surmounting the obstacles (''pratibandhakas'') related to the connection with the body in the form of powerful and wicked actions or sinful deeds (''pāpa''). The physical body (''[[prakṛti]]''), by itself, is an obstacle to the union with the Supreme Being for it has within it imprisoned the self (''[[Atman (Hinduism)|ātman]]''). &lt;ref&gt;{{cite book|title=Self-surrender to God in Shrivaishnavism|author=Srilata Raman|publisher=Routledge|pages=84–85|url=  https://books.google.com/books?id=O1c6KjcHf5AC&amp;pg=PA84&amp;dq=Self-surrender+to+God+in+Shrivaishnavism+pratibandhaka&amp;hl=en&amp;sa=X&amp;ei=rUmmVNbiH5OIuATrqIHQCQ&amp;ved=0CB0Q6AEwAA#v=onepage&amp;q=Self-surrender%20to%20God%20in%20Shrivaishnavism%20pratibandhaka&amp;f=false }}&lt;/ref&gt;

==Gangesa’s theory of pervasion and role of Pratibandhaka==

[[Gangesha Upadhyaya|Gangesa]], the author of ''[[Tattvacintāmaṇi]]'' who had examined the possibility of dialectical reasoning as a way to grasp pervasion, in the ''anumāna-khanda'' of the same text states that pervasion is pursued so long as there is doubt because there is contradiction but does not require deviation; doubt is an invalid cognitive act and fallacious reasoning is the ground for contradiction, the nature of doubt and fallacious reasoning both being conceptual is not of determinate character . Thus, dialectical reasoning is blocking of the opposing view and continues so long as doubt persists. Gangesa agrees that since pervasion is a universal invariant concomitance, therefore, the possibility of a counter example cannot be ruled out, and concludes that contradiction as natural opposition cannot block an infinite regress, it is the doubter’s own behaviour proving the lie to the doubt that blocks it acting as the ''pratibandhaka''. Gangesa uses the term, ''pratibandhaka'', to refer to a natural opposition in cognitive logic, as a preventer.&lt;ref&gt;{{cite book|title=Classical Indian Metaphysics|author=Stephen H. Phillips|publisher=Motilal Banarsidass|pages=156–161, 245|url= https://books.google.com/books?id=yMA2RQ61OgoC&amp;pg=PA161&amp;lpg=PA161&amp;dq=pratibandhaka&amp;source=bl&amp;ots=0iGIR3W0NW&amp;sig=SxQxtsa_dZwB483-VrxeSb3g8pM&amp;hl=en&amp;sa=X&amp;ei=cTmmVJTiE4GXuASB_ICQAQ&amp;ved=0CDAQ6AEwBA#v=onepage&amp;q=pratibandhaka&amp;f=false }}&lt;/ref&gt; Pervasion by its absence is the cause of hindrance (''pratibandhaka'') to inferential knowledge which in turn is the cause of pervasion. Even though both grasp their objects directly, in ''[[savikalpa]]'' its contents become objects of reflective awareness which is not the case in ''[[nirvikalpa]]''.&lt;ref&gt;{{cite book|title=Gangesa’s Theory of truth|publisher=Motilal Banarsidass|pages=32,79|url= https://books.google.com/books?id=9d-ve7e2Vi0C&amp;pg=PA79&amp;dq=vyapti&amp;hl=en&amp;sa=X&amp;ei=akw9UbCIDoT_rAecs4GABw&amp;ved=0CEEQ6AEwAw#v=onepage&amp;q=vyapti&amp;f=false }}&lt;/ref&gt; Contradiction occurs only when one epistemic state is blocked by a pratibandhaka.&lt;ref&gt;{{cite book|title=The Development of Modern Logic|publisher=Oxford University Press|page=939|url= https://books.google.com/books?id=0jXavKsArnIC&amp;pg=PA939&amp;dq=pratibandhaka&amp;hl=en&amp;sa=X&amp;ei=pEGmVJrKPIuKuwSfLQ&amp;redir_esc=y#v=onepage&amp;q=pratibandhaka&amp;f=false }}&lt;/ref&gt;

Gangesa has defined inferential knowledge as the cognition generated by cognition of a property belonging to a locus and qualified by a pervasion.&lt;ref&gt;{{cite book|title=Encyclopaedia of Oriental Philosophy and Religion|publisher=Global Vision|page=265|url= https://books.google.com/books?id=Uec1E8DpiH8C&amp;pg=PA265&amp;lpg=PA265&amp;dq=gangesa+on+pervasion&amp;source=bl&amp;ots=1Uw_YEe8eb&amp;sig=gOyso2YbtK11XP4K54OQw8i7s9A&amp;hl=en&amp;sa=X&amp;ei=0FCnVPGMHNSKuAS7zYDYCQ&amp;ved=0CDIQ6AEwCQ#v=onepage&amp;q=gangesa%20on%20pervasion&amp;f=false }}&lt;/ref&gt; A seed remaining intact does not sprout, and the destruction of the seed is a condition for the sprout to arise, the former is the obstacle (''pratibandhaka'') to sprout, and the latter indicates the absence of such obstacle.&lt;ref&gt;{{cite book|title=The Encyclopedia of Indian Philosophies Vol.4|publisher=Princeton University Press|page=593|url= https://books.google.com/books?id=bqr_AwAAQBAJ&amp;pg=PA593&amp;lpg=PA593&amp;dq=pratibandhaka&amp;source=bl&amp;ots=82Apxw7z3H&amp;sig=QNOFSkOcY5N_2mx6rU8uU2BLffE&amp;hl=en&amp;sa=X&amp;ei=Aj2mVNGdJcm1uQSJsIDwCQ&amp;ved=0CCEQ6AEwAzgU#v=onepage&amp;q=pratibandhaka&amp;f=false }}&lt;/ref&gt;

==Vedic view of Pratibandhaka==

According to [[Advaita Vedanta]], obstruction (''pratibandhaka'') of superimposition (''[[adhyasa]]'') is true knowledge, the absence of which obstruction is lack of true knowledge or ignorance (''ajñāna'' or ''avidyā''). ''Pratibandhaka'' is that obstacle which prevents the production of an effect in causal conditions. &lt;ref&gt;{{cite web|title=Vivarna, the cause of adhyasa|publisher=advaita-l@lists.advaita-vedanta.org|url= http://permalink.gmane.org/gmane.culture.religion.advaita/579 }}&lt;/ref&gt; According to the [[Nyaya]] school an effect is the counter-entity of its own prior non-existence and a fresh beginning.&lt;ref&gt;{{cite web|title=The Theory of causation in Indian Vedic Philosophy|publisher=Indian philosophy.wordpress.com|url= https://indiaphilosophy.wordpress.com/tag/satkaryavad/ }}&lt;/ref&gt; Swami [[Vidyaranya]] lists four such obstacles or impediments, which are:-

:प्रतिबन्धो वर्तमानो विषयासक्त्तिलक्षणः | 
:प्रज्ञामान्द्यं कुतर्कश्च विपर्ययदुराग्रहः ||

a) binding attachment to the objects of the senses, b) dullness of the intellect, c) indulgence in improper and illogical arguments and d) the deep conviction that the Self is an agent and an enjoyer ([[Panchadasi]] IX.43). He explains:-

:शमाद्यैः श्रवणाद्यैश्च तत्र तत्रोचितैः क्षयम् |
:नीतेऽस्मिन्प्रतिबन्धेऽतः स्वस्य ब्रह्मत्वमश्नुते ||

that through the practice of inner control and other qualifications and through hearing the truth and so forth, suitable for counter-acting the impediments, the latter slowly perish, and one realizes his Self as [[Brahman]] ([[Panchadasi]] IX.44). The [[Yogi]] enters into the heaven of meritorious because of his practice of enquiry provided his enquiry is not impeded on account of the results of past evil deeds and his strong desire for [[Brahmaloka]] is not suppressed by him. &lt;ref&gt;{{cite book|title=Pancadasi of Sri Vidyaranya Swami with notes by Swami Swahananda|publisher=Sri Ramakrishna Math|pages=389–392|url= http://www.chennaimath.org/istore/product/pancadasi-of-sri-vidyaranya-swami/ }}&lt;/ref&gt;
  
In [[Ayurveda]], the word ''pratibandhaka'' as ''vyādhyutpāda pratibandhaka'' refers to the power of the body to resist disease which power (''vyādhi virodhaka'') when weakened can be restored by means of administering ''[[triphala]]'' fruits and the likes as an [[herbal]] [[rasayana]].&lt;ref&gt;{{cite book|title=Diagnosis and treatment of diseases in Ayurveda|author=Vaidya Bhagwan Dash|publisher=Concept Publishing|page=xLi|url= https://books.google.com/books?id=qhEJwG2mqsgC&amp;pg=PR41&amp;dq=pratibandhaka&amp;hl=en&amp;sa=X&amp;ei=nkCmVO35KMSUuATsxoGACg&amp;redir_esc=y#v=onepage&amp;q=pratibandhaka&amp;f=false }}&lt;/ref&gt;
==References==
{{Reflist}}
{{Indian Philosophy|state=collapsed}}

[[Category:Hindu philosophical concepts]]
[[Category:History of logic]]
[[Category:Nyaya|!]]
[[Category:Vedas]]
[[Category:Vedanta]]
[[Category:Jainism]]</text>
      <sha1>2pp2bwv0lrh6e90buzira7nz6s7t79z</sha1>
    </revision>
  </page>
  <page>
    <title>Principle of explosion</title>
    <ns>0</ns>
    <id>591394</id>
    <revision>
      <id>868860748</id>
      <parentid>849272979</parentid>
      <timestamp>2018-11-14T22:37:39Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8143">{{redirect|EFQ|the literary baseball journal|Elysian Fields Quarterly}}
{{redirect|Ex falso quodlibet|the audio player|Quod Libet|the related tag editor and library organizer|Ex Falso}}

{{One source|date= December 2011}}

The '''principle of explosion''' (Latin: ''ex falso (sequitur) quodlibet'' (EFQ), "from falsehood, anything (follows)", or ''ex contradictione (sequitur) quodlibet'' (ECQ), "from contradiction, anything (follows)"), or the '''principle of [[Pseudo-Scotus]]''', is the law of [[classical logic]], [[intuitionistic logic]] and similar logical systems, according to which any statement can be proven from a contradiction.&lt;ref&gt;Carnielli, W. and Marcos, J. (2001) [http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.107.70 "Ex contradictione non sequitur quodlibet"] ''Proc. 2nd Conf. on Reasoning and Logic'' (Bucharest, July 2000)&lt;/ref&gt; That is, once a contradiction has been asserted, any proposition (including their negations) can be inferred from it. This is known as '''deductive explosion'''.&lt;ref&gt;{{cite journal
|journal=[[Synthese]]
|title=Some topological properties of paraconsistent models
|last1=Başkent
|first1=Can
|date=2013-01-31
|doi=10.1007/s11229-013-0246-8
|volume=190
|issue=18
|page=4023}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
|series=Logic, Epistemology, and the Unity of Science
|publisher=[[Springer International Publishing]]
|title=Paraconsistent Logic: Consistency, Contradiction and Negation
|last1=Carnielli
|first1=Walter
|last2=Coniglio
|first2=Marcelo Esteban
|year=2016
|doi=10.1007/978-3-319-33205-5
|at=ix}}&lt;/ref&gt;   The proof of this principle was first given by 12th century French philosopher [[William of Soissons]].&lt;ref&gt; Graham Priest, 'What's so bad about contradictions?' in Priest, Beal and Armour-Garb, ''The law of non-contradicton'', p. 25, Clarendon Press, Oxford, 2011. &lt;/ref&gt;

As a demonstration of the principle, consider two contradictory statements – "All lemons are yellow" and "Not all lemons are yellow", and suppose (for the sake of argument) that both are simultaneously true.  If that is the case, anything can be proven, e.g. "unicorns exist", by using the following argument:
# We know that "All lemons are yellow" as it is defined to be true.
# Therefore, the statement that ("All lemons are yellow" OR "unicorns exist”) must also be true, since the first part is true.
# However, if "Not all lemons are yellow" (and this is also defined to be true), unicorns must exist – otherwise statement 2 would be false (in rigor, given that at least one lemon exists).  It has thus been "proven" that unicorns exist. The same could be applied to any assertion, including the statement "unicorns do not exist".

Due to the principle of explosion, the existence of a contradiction ([[inconsistency]]) in a [[formal system|formal axiomatic system]] is disastrous; since any statement can be proved true it trivializes the concepts of truth and falsity.&lt;ref name="McKubre-Jordens"&gt;{{cite web
  | last = McKubre-Jordens
  | first = Maarten  
  | title = This is not a carrot: Paraconsistent mathematics
  | work = Plus Magazine
  | publisher = Millennium Mathematics Project
  | date = August 2011
  | url = https://plus.maths.org/content/not-carrot
  | format = 
  | doi = 
  | accessdate = January 14, 2017}}&lt;/ref&gt;  Around the turn of the 20th century, the discovery of contradictions such as [[Russell's paradox]] at the foundations of mathematics thus threatened the entire structure of mathematics.  Mathematicians such as [[Gottlob Frege]], [[Ernst Zermelo]], [[Abraham Fraenkel]], and [[Thoralf Skolem]] put much effort into revising [[set theory]] to eliminate these contradictions, resulting in the modern [[Zermelo–Fraenkel set theory]].    

In a different solution to these problems, a few mathematicians have devised alternate theories of [[logic (mathematics)|logic]] called [[paraconsistent logic]]s, which eliminate the principle of explosion.&lt;ref name="McKubre-Jordens" /&gt;  These allow some contradictory statements to be proved without affecting other proofs.

==Symbolic representation==
In [[symbolic logic]], the principle of explosion can be expressed in the following way
:&lt;math&gt;\forall P \forall Q: (P \land \lnot P) \vdash Q&lt;/math&gt;
(For any statements ''P'' and ''Q'', if ''P'' and not-''P'' are both true, then ''Q'' is true)

==Proof==
Below is a formal proof of the principle using [[symbolic logic]]
#&lt;math&gt;P \wedge \neg P&lt;/math&gt;
#:assumption
#&lt;math&gt;P&lt;/math&gt;
#:from (1) by [[conjunction elimination]]
#&lt;math&gt;\neg P&lt;/math&gt;
#:from (1) by conjunction elimination
#&lt;math&gt;P \vee Q&lt;/math&gt;
#:from (2) by [[disjunction introduction]]
#&lt;math&gt;Q&lt;/math&gt;
#:from (3) and (4) by [[disjunctive syllogism]]
#&lt;math&gt;(P \wedge \neg P) \to Q&lt;/math&gt;
#:from (5) by [[conditional proof]] (discharging assumption 1)

This is just the symbolic version of the informal argument given in the introduction, with &lt;math&gt;P&lt;/math&gt; standing for "all lemons are yellow" and &lt;math&gt;Q&lt;/math&gt; standing for "Unicorns exist". From "all lemons are yellow and not all lemons are yellow" (1), we infer "all lemons are yellow" (2) and "not all lemons are yellow" (3); from "all lemons are yellow" (2), we infer "all lemons are yellow or unicorns exist" (4); and from "not all lemons are yellow" (3) and "all lemons are yellow or unicorns exist" (4), we infer "unicorns exist" (5). Hence, if all lemons are yellow and not all lemons are yellow, then unicorns exist.

===Semantic argument===
An alternate argument for the principle stems from [[model theory]].  A sentence &lt;math&gt;P&lt;/math&gt; is a ''[[semantic consequence]]'' of a set of sentences &lt;math&gt;\Gamma&lt;/math&gt; only if every model of &lt;math&gt;\Gamma&lt;/math&gt; is a model of &lt;math&gt;P&lt;/math&gt;.  But there is no model of the contradictory set &lt;math&gt;(P \wedge \lnot P)&lt;/math&gt;.  [[A fortiori]], there is no model of &lt;math&gt;(P \wedge \lnot P)&lt;/math&gt; that is not a model of &lt;math&gt;Q&lt;/math&gt;.  Thus, vacuously, every model of &lt;math&gt;(P \wedge \lnot P)&lt;/math&gt; is a model of &lt;math&gt;Q&lt;/math&gt;.   Thus &lt;math&gt;Q&lt;/math&gt; is a semantic consequence of &lt;math&gt;(P \wedge \lnot P)&lt;/math&gt;.

==Paraconsistent logic==

[[Paraconsistent logic]]s have been developed that allow for sub-contrary forming operators.   [[Formal semantics (logic)|Model-theoretic]] paraconsistent logicians often deny the assumption that there can be no model of &lt;math&gt;\{\phi , \lnot \phi \}&lt;/math&gt; and devise semantical systems in which there are such models. Alternatively, they reject the idea that propositions can be classified as true or false.  [[Proof-theoretic semantics|Proof-theoretic]] paraconsistent logics usually deny the validity of one of the steps necessary for deriving an explosion, typically including disjunctive syllogism, disjunction introduction, and [[reductio ad absurdum]].

==Use==
The [[metamathematics|metamathematical]] value of the principle of explosion is that for any logical system where this principle holds, any derived [[mathematical theory|theory]] which proves [[false (logic)|⊥]] (or an equivalent form, &lt;math&gt;\phi \land \lnot \phi&lt;/math&gt;) is worthless because ''all'' its [[statement (logic)|statements]] would become [[theorem]]s, making it impossible to distinguish [[truth]] from falsehood. That is to say, the principle of explosion is an argument for the [[law of non-contradiction]] in classical logic, because without it all truth statements become meaningless.

==See also==
* [[Consequentia mirabilis]] – Clavius's Law
* [[Dialetheism]] – belief in the existence of true contradictions
* [[Law of excluded middle]] – every proposition is true or false
* [[Law of noncontradiction]] – no proposition can be both true and not true
* [[Paraconsistent logic]] – a family of logics used to address contradictions
* [[Paradox of entailment]] – a seeming paradox derived from the principle of explosion
* [[Reductio ad absurdum]] – concluding that a proposition is false because it produces a contradiction
* [[Trivialism]] – the belief that all statements of the form "P and not-P" are true

==References==
{{reflist}}

{{Classical logic}}

[[Category:Theorems in propositional logic]]
[[Category:Classical logic]]
[[Category:Principles]]</text>
      <sha1>jo5v7ha57un7x6md7yc7abscsgny8oq</sha1>
    </revision>
  </page>
  <page>
    <title>Resolution (logic)</title>
    <ns>0</ns>
    <id>2724082</id>
    <revision>
      <id>867368690</id>
      <parentid>857235467</parentid>
      <timestamp>2018-11-05T07:44:38Z</timestamp>
      <contributor>
        <ip>89.16.150.10</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16704">In [[mathematical logic]] and [[automated theorem proving]], '''resolution''' is a [[rule of inference]] leading to a [[Reductio ad absurdum|refutation]] [[theorem-proving]] technique for sentences in [[propositional logic]] and [[first-order logic]]. In other words, iteratively applying the resolution rule in a suitable way allows for telling whether a [[propositional formula]] is satisfiable and for proving that a first-order formula is unsatisfiable.&lt;!---redundant:---; this method may prove the satisfiability of a first-order satisfiable formula,---&gt;&lt;!---wrong (resolution is refutation-complete for 1st order logic; Gödel's incompleteness theorems are about 2nd (or higher) order logic):--- but not always, as it is the case for all methods for first-order logic (see [[Gödel's incompleteness theorems]] and [[Halting problem]])---&gt; Attempting to prove a satisfiable first-order formula as unsatisfiable may result in a nonterminating computation; this problem doesn't occur in propositional logic.

The resolution rule can be traced back to Davis and Putnam (1960);&lt;ref&gt;{{cite journal| author=Martin Davis, Hilary Putnam| title=A Computing Procedure for Quantification Theory| journal=J. ACM| year=1960| volume=7| number=3| pages=201–215| doi=10.1145/321033.321034}} Here: p.210, "III. Rule for Eliminating Atomic Formulas".&lt;/ref&gt; however, their [[Davis-Putnam algorithm|algorithm]] required trying all [[ground instance]]s of the given formula. This source of combinatorial explosion was eliminated in 1965 by [[John Alan Robinson]]'s syntactical [[Unification (computer science)|unification algorithm]], which allowed one to instantiate the formula during the proof "on demand" just as far as needed to keep [[refutation completeness]].&lt;ref&gt;{{cite journal| author=J.A. Robinson| title=A Machine-Oriented Logic Based on the Resolution Principle| journal=Journal of the ACM|date=Jan 1965| volume=12| number=1| pages=23–41| doi=10.1145/321250.321253}}&lt;/ref&gt;

The clause produced by a resolution rule is sometimes called a '''resolvent'''.

== Resolution in propositional logic ==

=== Resolution rule ===
The '''resolution rule''' in propositional logic is a single valid inference rule that produces a new clause implied by two [[Clause (logic)|clauses]] containing complementary literals. A [[literal (mathematical logic)|literal]] is a propositional variable or the negation of a propositional variable. Two literals are said to be complements if one is the negation of the other (in the following,
&lt;math&gt;\lnot c&lt;/math&gt; is taken to be the complement to &lt;math&gt;c&lt;/math&gt;). The resulting clause contains all the literals that do not have complements.
Formally:
:&lt;math&gt;\frac{
a_1 \lor \ldots \vee a_{i-1} \lor c \lor a_{i+1} \vee \ldots \lor a_n,
\quad b_1 \lor \ldots \vee b_{j-1} \lor \lnot c \lor b_{j+1} \vee \ldots \lor b_m}
{a_1 \lor \ldots \lor a_{i-1} \lor a_{i+1} \lor \ldots \lor a_n  \lor  b_1 \lor \ldots \lor b_{j-1} \lor b_{j+1} \lor \ldots \lor b_m}&lt;/math&gt;
where
: all &lt;math&gt;a&lt;/math&gt;s, &lt;math&gt;b&lt;/math&gt;s and &lt;math&gt;c&lt;/math&gt; are literals,
: the dividing line stands for [[logical consequence|entails]]

The clause produced by the resolution rule is called the ''resolvent'' of the two input clauses. It is the principle of ''[[consensus theorem|consensus]]'' applied to clauses rather than terms.&lt;ref&gt;D.E. Knuth, ''[[The Art of Computer Programming]]'' '''4A''': ''Combinatorial Algorithms'', part 1, p. 539&lt;/ref&gt;

When the two clauses contain more than one pair of complementary literals, the resolution rule can be applied (independently) for each such pair; however, the result is always a [[tautology (logic)|tautology]].

[[Modus ponens]] can be seen as a special case of resolution (of a one-literal clause and a two-literal clause).
:&lt;math&gt;\frac{
p \rightarrow q, p}
{
q
}&lt;/math&gt;
is equivalent to
:&lt;math&gt;\frac{
\lnot p \lor q, p}
{
q
}&lt;/math&gt;

=== A resolution technique ===
When coupled with a complete [[search algorithm]], the resolution rule yields a sound and complete algorithm for deciding the ''satisfiability'' of a propositional formula, and, by extension, the [[Validity (logic)|validity]] of a sentence under a set of axioms.

This resolution technique uses [[proof by contradiction]] and is based on the fact that any sentence in propositional logic can be transformed into an equivalent sentence in [[conjunctive normal form]].&lt;ref name="leitsch"&gt;{{citation|title=The resolution calculus|series=EATCS Monographs in Theoretical Computer Science|first=Alexander|last=Leitsch|publisher=Springer|year=1997|page=11|quote=Before applying the inference method itself, we transform the formulas to quantifier-free conjunctive normal form.}}&lt;/ref&gt; The steps are as follows.

* All sentences in the knowledge base and the ''negation'' of the sentence to be proved (the ''conjecture'') are conjunctively connected.
* The resulting sentence is transformed into a conjunctive normal form with the conjuncts viewed as elements in a set, ''S'', of clauses.&lt;ref name="leitsch"/&gt;
**For example   &lt;math&gt; (A_1 \lor A_2) \land (B_1 \lor B_2 \lor B_3) \land (C_1)&lt;/math&gt; gives rise to the set &lt;math&gt;S=\{A_1 \lor A_2, B_1 \lor B_2 \lor B_3, C_1\}&lt;/math&gt;.
* The resolution rule is applied to all possible pairs of clauses that contain complementary literals. After each application of the resolution rule, the resulting sentence is simplified by removing repeated literals. If the sentence contains complementary literals, it is discarded (as a tautology). If not, and if it is not yet present in the clause set ''S'', it is added to ''S'', and is considered for further resolution inferences.
* If after applying a resolution rule the ''empty clause'' is derived, the original formula is unsatisfiable (or ''contradictory''), and hence it can be concluded that the initial conjecture [[Logical consequence|follows from]] the axioms.
* If, on the other hand, the empty clause cannot be derived, and the resolution rule cannot be applied to derive any more new clauses, the conjecture is not a theorem of the original knowledge base.

One instance of this algorithm is the original [[Davis–Putnam algorithm]] that was later refined into the [[DPLL algorithm]] that removed the need for explicit representation of the resolvents.

This description of the resolution technique uses a set ''S'' as the underlying data-structure to represent resolution derivations. Lists, Trees and Directed Acyclic Graphs are other possible and common alternatives. Tree representations are more faithful to the fact that the resolution rule is binary. Together with a sequent notation for clauses, a tree representation also makes it clear to see how the resolution rule is related to a special case of the cut-rule, restricted to atomic cut-formulas. However, tree representations are not as compact as set or list representations, because they explicitly show redundant subderivations of clauses that are used more than once in the derivation of the empty clause. Graph representations can be as compact in the number of clauses as list representations and they also store structural information regarding which clauses were resolved to derive each resolvent.

== A simple example ==

&lt;math&gt;
\frac{a \vee b, \quad \neg a \vee c}
{b \vee c}
&lt;/math&gt;

In plain language: Suppose &lt;math&gt;a&lt;/math&gt; is false. In order for the premise &lt;math&gt;a \vee b&lt;/math&gt; to be true, &lt;math&gt;b&lt;/math&gt; must be true.
Alternatively, suppose &lt;math&gt;a&lt;/math&gt; is true. In order for the premise &lt;math&gt;\neg a \vee c&lt;/math&gt; to be true, &lt;math&gt;c&lt;/math&gt; must be true. Therefore regardless of falsehood or veracity of &lt;math&gt;a&lt;/math&gt;, if both premises hold, then the conclusion &lt;math&gt;b \vee c&lt;/math&gt; is true.

== Resolution in first order logic ==

Resolution rule can be generalized to [[first-order logic]] to:&lt;ref&gt;Enrique P. Arís, Juan L. González y Fernando M. Rubio, Lógica Computacional, Thomson, (2005).&lt;/ref&gt;

:&lt;math&gt;
\frac{\Gamma_1 \cup\left\{ L_1\right\} \,\,\,\, \Gamma_2 \cup\left\{ L_2\right\} }{ (\Gamma_1 \cup \Gamma_2)\phi } \phi
&lt;/math&gt;

where &lt;math&gt;\phi&lt;/math&gt; is a [[most general unifier]] of &lt;math&gt;L_1&lt;/math&gt; and &lt;math&gt;\overline{L_2}&lt;/math&gt; and &lt;math&gt;\Gamma_1&lt;/math&gt; and &lt;math&gt;\Gamma_2&lt;/math&gt; have no common variables.

=== Example ===
The clauses &lt;math&gt;P(x),Q(x)&lt;/math&gt; and &lt;math&gt;\neg P(b)&lt;/math&gt; can apply this rule with &lt;math&gt;[b/x]&lt;/math&gt; as unifier.

Here x is a variable and b is a constant.

:&lt;math&gt;
\frac{P(x),Q(x) \,\,\,\, \neg P(b)}
{Q(b)}[b/x]
&lt;/math&gt;

Here we see that

* The clauses &lt;math&gt;P(x),Q(x)&lt;/math&gt;  and &lt;math&gt; \neg P(b) &lt;/math&gt; are the inference’s premises
* &lt;math&gt; Q(b) &lt;/math&gt; (the resolvent of the premises) is its conclusion.
* The literal &lt;math&gt;P(x)&lt;/math&gt; is the left resolved literal,
* The literal &lt;math&gt;\neg P(b)&lt;/math&gt; is the right resolved literal,
* &lt;math&gt;P&lt;/math&gt; is the resolved atom or pivot.
* &lt;math&gt;[b/x]&lt;/math&gt; is the most general unifier of the resolved literals.

=== Informal explanation ===
In first order logic, resolution condenses the traditional [[syllogism]]s of [[rule of inference|logical inference]] down to a single rule.

To understand how resolution works, consider the following example syllogism of [[term logic]]:

: All Greeks are Europeans.
: Homer is a Greek.
: Therefore, Homer is a European.

Or, more generally:

: &lt;math&gt;\forall x. P(x) \Rightarrow Q(x)&lt;/math&gt;
: &lt;math&gt;P(a)&lt;/math&gt;
: Therefore, &lt;math&gt;Q(a)&lt;/math&gt;

To recast the reasoning using the resolution technique, first the clauses must be converted to [[conjunctive normal form]] (CNF). In this form, all [[Quantification (logic)|quantification]] becomes implicit: [[Universal quantification|universal quantifiers]] on variables (''X'', ''Y'', ...) are simply omitted as understood, while [[Existential quantification|existentially-quantified]] variables are replaced by [[Skolem function]]s.

: &lt;math&gt;\neg P(x) \vee Q(x)&lt;/math&gt;
: &lt;math&gt;P(a)&lt;/math&gt;
: Therefore, &lt;math&gt;Q(a)&lt;/math&gt;

So the question is, how does the resolution technique derive the last clause from the first two? The rule is simple:

* Find two clauses containing the same predicate, where it is negated in one clause but not in the other.
* Perform a [[Unification (computing)|unification]] on the two predicates. (If the unification fails, you made a bad choice of predicates. Go back to the previous step and try again.)
* If any unbound variables which were bound in the unified predicates also occur in other predicates in the two clauses, replace them with their bound values (terms) there as well.
* Discard the unified predicates, and combine the remaining ones from the two clauses into a new clause, also joined by the "∨" operator.

To apply this rule to the above example, we find the predicate ''P'' occurs in negated form

: ¬''P''(''X'')

in the first clause, and in non-negated form

: ''P''(''a'')

in the second clause. ''X'' is an unbound variable, while ''a'' is a bound value (term). Unifying the two produces the substitution

: ''X'' {{mapsto}} ''a''

Discarding the unified predicates, and applying this substitution to the remaining predicates (just ''Q''(''X''), in this case), produces the conclusion:

: ''Q''(''a'')

For another example, consider the syllogistic form

: All Cretans are islanders.
: All islanders are liars.
: Therefore all Cretans are liars.

Or more generally,

: ∀''X'' ''P''(''X'') → ''Q''(''X'')
: ∀''X'' ''Q''(''X'') → ''R''(''X'')
: Therefore, ∀''X'' ''P''(''X'') → ''R''(''X'')

In CNF, the antecedents become:

: ¬''P''(''X'') ∨ ''Q''(''X'')
: ¬''Q''(''Y'') ∨ ''R''(''Y'')

(Note that the variable in the second clause was renamed to make it clear that variables in different clauses are distinct.)

Now, unifying ''Q''(''X'') in the first clause with ¬''Q''(''Y'') in the second clause means that ''X'' and ''Y'' become the same variable anyway. Substituting this into the remaining clauses and combining them gives the conclusion:

: ¬''P''(''X'') ∨ ''R''(''X'')

The resolution rule, as defined by Robinson, also incorporated factoring, which unifies two literals in the same clause, before or during the application of resolution as defined above. The resulting inference rule is refutation-complete,&lt;ref&gt;{{cite book| author1=Stuart J. Russell| author2=Peter Norvig| title=Artificial Intelligence: A Modern Approach| year=2009| publisher=Prentice Hall|edition=3rd}} p. 350 (=p.286 in the 1st edition of 1995)&lt;/ref&gt; in that a set of clauses is unsatisfiable if and only if there exists a derivation of the empty clause using resolution alone.

== Paramodulation ==

Paramodulation is a related technique for reasoning on sets of clauses where the predicate symbol is equality. It generates all "equal" versions of clauses, except reflexive identities. The paramodulation operation takes a positive ''from'' clause, which must contain an equality literal. It then searches an ''into'' clause with a subterm that unifies with one side of the equality. The subterm is then replaced by the other side of the equality. The general aim of paramodulation is to reduce the system to atoms, reducing the size of the terms when substituting.&lt;ref name="Rubio"&gt;{{cite book|chapter=Paramodulation-Based Theorem Proving|title=Handbook of Automated Reasoning|first1=Robert|last1=Nieuwenhuis|first2=Alberto|last2=Rubio|url=http://www.cmi.ac.in/~madhavan/courses/theorem-proving-2014/reading/Nieuwenhuis-Rubio.pdf}}&lt;/ref&gt;

== Implementations ==

* [[CARINE]]
* [[Gandalf (theorem prover)|Gandalf]]
* [[Otter (theorem prover)|Otter]]
* [[Prover9]]
* [[SNARK (theorem prover)|SNARK]]
* [[SPASS]]
* [[Vampire (theorem prover)|Vampire]]

== See also ==
* [[Condensed detachment]]&amp;nbsp;— an earlier version of resolution
* [[Inductive logic programming]]
* [[Inverse resolution]]
* [[Logic programming]]
* [[Method of analytic tableaux]]
* [[SLD resolution]]
* [[Resolution inference]]

== Notes ==
{{Reflist}}

== References ==

* {{cite journal
 |last=[[John Alan Robinson|Robinson]]
 |first=J. Alan
 |title=A Machine-Oriented Logic Based on the Resolution Principle
 |journal=[[Journal of the ACM]]
 |year=1965|volume=12|issue=1|pages=23–41
 |doi=10.1145/321250.321253
}}
* {{cite book
 | last = Leitsch
 | first = Alexander
 | title = The Resolution Calculus
 | publisher = [[Springer Science+Business Media|Springer]]
 | year = 1997
}}
* {{cite book
 | last = Gallier
 | first = Jean H. | authorlink = Jean Gallier
 | title = Logic for Computer Science: Foundations of Automatic Theorem Proving
 | publisher = [[Harper &amp; Row]] Publishers
 | year = 1986
 | url = http://www.cis.upenn.edu/~jean/gbooks/logic.html
}}
* {{cite book
 |last=Lee
 |first=Chin-Liang Chang, Richard Char-Tung
 |title=Symbolic logic and mechanical theorem proving
 |year=1987|publisher=Academic Press
 |location=San Diego
 |isbn=0-12-170350-9
 |edition=[reprint]
}}
Approaches to '''non-clausal resolution''', i.e. resolution of first-order formulas that need not be in [[clausal normal form]], are presented in:
* {{cite thesis| type=Master's Thesis| author=D. Wilkins| title=QUEST — A Non-Clausal Theorem Proving System| year=1973| publisher=Univ. of Essex, England}}
* {{cite techreport| author=Neil V. Murray| title=A Proof Procedure for Quantifier-Free Non-Clausal First Order Logic|date=Feb 1979| number=2-79| institution=Syracuse Univ.| url=http://surface.syr.edu/cgi/viewcontent.cgi?article=1005&amp;context=eecs_techreports}} (Cited from Manna, Waldinger, 1980 as: "A Proof Procedure for Non-Clausal First-Order Logic", 1978)
* {{cite journal| author=[[Zohar Manna]], [[Richard Waldinger]]| title=A Deductive Approach to Program Synthesis| journal=[[ACM Transactions on Programming Languages and Systems]]|date=Jan 1980| volume=2| pages=90–121| doi=10.1145/357084.357090| url=http://www.dtic.mil/get-tr-doc/pdf?AD=ADA065558}} A preprint appearead in Dec 1978 as [http://www.sri.com/sites/default/files/uploads/publications/pdf/725.pdf SRI Technical Note 177]
* {{cite journal| author=N. V. Murray| title=Completely Non-Clausal Theorem Proving| journal=[[Artificial Intelligence (journal)|Artificial Intelligence]]| year=1982| volume=18| pages=67–85| doi=10.1016/0004-3702(82)90011-x}}
* {{cite journal| author=Schmerl, U.R.| title=Resolution on Formula-Trees| journal=[[Acta Informatica]]| year=1988| volume=25| pages=425–438| doi=10.1007/bf02737109}} [http://www.zentralblatt-math.org/ioport/en/?id=2297405&amp;type=pdf Summary]

== External links ==
* {{MathWorld | urlname=ResolutionPrinciple | title=Resolution Principle | author=Alex Sakharov}}
* {{MathWorld | urlname=Resolution | title=Resolution | author=Alex Sakharov}}

[[Category:1965 introductions]]
[[Category:Rules of inference]]
[[Category:Automated theorem proving]]
[[Category:Theorems in propositional logic]]</text>
      <sha1>4ququx5f6q4we0z69rhza3wyctjhfyb</sha1>
    </revision>
  </page>
  <page>
    <title>Ruth Moufang</title>
    <ns>0</ns>
    <id>2003831</id>
    <revision>
      <id>806647778</id>
      <parentid>720092561</parentid>
      <timestamp>2017-10-23T09:45:43Z</timestamp>
      <contributor>
        <username>Melcous</username>
        <id>20472590</id>
      </contributor>
      <comment>per [[Template:Infobox academic]] , only for those notable enough for their own wiki article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2897">{{Infobox scientist
| name              = Ruth Moufang
| image             = Ruth Moufang.jpg
| image_size        = 
| caption           = 
| birth_date        = {{Birth date|1905|01|10}}
| birth_place       = [[Darmstadt]], [[German Empire|Germany]] 
| death_date        = {{Death date and age|1977|11|26|1905|01|10}}
| death_place       = [[Frankfurt am Main]], [[West Germany|Germany]]
| nationality       = {{flag|GER|name=German}}
| fields            = [[Mathematics]]
| workplaces        = [[Goethe University Frankfurt]]
| alma_mater        = Goethe University Frankfurt
| doctoral_advisor  = [[Max Dehn]]
| doctoral_students = 
| known_for         = [[Moufang plane]]&lt;br&gt;[[Moufang polygon]]&lt;br&gt;[[Moufang–Lie algebra]]&lt;br&gt;[[Moufang loop]]
| awards            = 
}}
'''Ruth Moufang''' (January 10, 1905 &amp;ndash; November 26, 1977) was a [[German people|German]] [[mathematician]].  

Born to a German chemist Dr. Eduard Moufang and Else Fecht Moufang, she studied mathematics at the [[Goethe University Frankfurt|University of Frankfurt]]. In 1931 she received her Ph.D. on [[projective geometry]] under the direction of [[Max Dehn]], and in 1932 spent a fellowship year in Rome. After her year in [[Rome]], she returned to Germany to lecture at the [[University of Königsberg]] and the University of Frankfurt. Her research in projective geometry built upon the work of [[David Hilbert]]. She was responsible for ground-breaking work on [[non-associative algebra|non-associative]] [[algebraic structure]]s, including the [[Moufang loop]]s named after her.

In 1933 Moufang  showed [[Desargues's theorem]] does not hold in the  [[Cayley plane]]. The Cayley plane uses [[octonion]] coordinates which do not satisfy the [[associative law]]. Such connections between geometry and algebra had been previously noted by  [[Karl von Staudt]] and [[David Hilbert]]. Ruth Moufang thus initiated a new branch of geometry called [[Moufang plane]]s.

Denied permission to teach by the minister of education of [[Nazi Germany]], she worked in private industry until 1946, when she became the first woman professor at the University of Frankfurt.

==References==
*{{MacTutor|id=Moufang}}
*{{MathGenealogy |id=34257}}
*[http://www.agnesscott.edu/lriddle/women/moufang.htm "Ruth Moufang", Biographies of Women Mathematicians], [[Agnes Scott College]]
* Bhama Srinivasan (1984) "Ruth Moufang, 1905—1977" [[Mathematical Intelligencer]] 6(2):51&amp;ndash;5.

{{Authority control}}
{{DEFAULTSORT:Moufang, Ruth}}
[[Category:1905 births]]
[[Category:1977 deaths]]
[[Category:20th-century mathematicians]]
[[Category:German mathematicians]]
[[Category:Women mathematicians]]
[[Category:Algebraists]]
[[Category:Goethe University Frankfurt alumni]]
[[Category:University of Königsberg faculty]]
[[Category:Goethe University Frankfurt faculty]]
[[Category:People from Darmstadt]]
[[Category:German women academics]]</text>
      <sha1>eaouewezbsjyrvn5qafvp2m4isz1t7t</sha1>
    </revision>
  </page>
  <page>
    <title>Semigroup action</title>
    <ns>0</ns>
    <id>1058218</id>
    <revision>
      <id>868493933</id>
      <parentid>868493029</parentid>
      <timestamp>2018-11-12T15:23:05Z</timestamp>
      <contributor>
        <ip>134.59.11.233</ip>
      </contributor>
      <comment>/* Semiautomata */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12129">{{Redirect|S-set|the suburban train fleet|Sydney Trains S set}}

In [[algebra]] and [[theoretical computer science]], an '''action''' or '''act''' of a '''[[semigroup]]''' on a [[Set (mathematics)|set]] is a rule which associates to each element of the semigroup a [[transformation (geometry)|transformation]] of the set in such a way that the product of two elements of the semigroup (using the semigroup [[binary operation|operation]]) is associated with the [[function composition|composite]] of the two corresponding transformations. The terminology conveys the idea that the elements of the semigroup are ''acting'' as transformations of the set. From an [[algebraic structure|algebraic]] perspective, a semigroup action is a generalization of the notion of a [[group action]] in [[group (mathematics)|group theory]]. From the computer science point of view, semigroup actions are closely related to [[finite state machine|automata]]: the set models the state of the automaton and the action models transformations of that state in response to inputs.

An important special case is a '''monoid action''' or '''act''', in which the semigroup is a [[monoid]] and the [[identity element]] of the monoid acts as the [[identity transformation]] of a set. From a [[category theoretic]] point of view, a monoid is a [[category (mathematics)|category]] with one object, and an act is a functor from that category to the [[category of sets]]. This immediately provides a generalization to monoid acts on objects in categories other than the category of sets.

Another important special case is a '''[[transformation semigroup]]'''. This is a semigroup of transformations of a set, and hence it has a tautological action on that set. This concept is linked to the more general notion of a semigroup by an analogue of [[Cayley's theorem]].

''(A note on terminology: the terminology used in this area varies, sometimes significantly, from one author to another. See the article for details.)''

==Formal definitions==

Let ''S'' be a semigroup. Then a (left) '''semigroup action''' (or '''act''') of ''S'' is a set ''X'' together with an operation {{nowrap|• : ''S'' × ''X'' → ''X''}} which is compatible with the semigroup [[binary operation|operation]] * as follows:
* for all ''s'', ''t'' in ''S'' and ''x'' in ''X'', {{nowrap|1=''s'' • (''t'' • ''x'') = (''s'' * ''t'') • ''x''}}.
This is the analogue in semigroup theory of a (left) [[group action]], and is equivalent to a [[semigroup#Semigroup homomorphisms|semigroup homomorphism]] into the set of functions on ''X''. Right semigroup actions are defined in a similar way using an operation {{nowrap|• : ''X'' × ''S'' → ''X''}} satisfying {{nowrap|1=(''x'' • ''a'') • ''b'' = ''x'' • (''a'' * ''b'')}}.

If ''M'' is a monoid, then a (left) '''monoid action''' (or '''act''') of ''M'' is a (left) semigroup action of ''M'' with the additional property that
* for all ''x'' in ''X'': ''e'' • ''x'' = ''x''
where ''e'' is the identity element of ''M''. This correspondingly gives a monoid homomorphism. Right monoid actions are defined in a similar way. A monoid ''M'' with an action on a set is also called an '''operator monoid'''.

A semigroup action of ''S'' on ''X'' can be made into monoid act by adjoining an identity to the semigroup and requiring that it acts as the identity transformation on ''X''. 

===Terminology and notation===

If ''S'' is a semigroup or monoid, then a set ''X'' on which ''S'' acts as above (on the left, say) is also known as a (left) '''''S''-act''', '''''S''-set''', '''''S''-action''', '''''S''-operand''', or '''left act over ''S'''''. Some authors do not distinguish between semigroup and monoid actions, by regarding the identity axiom ({{nowrap|1=''e'' • ''x'' = ''x''}}) as empty when there is no identity element, or by using the term '''unitary ''S''-act''' for an ''S''-act with an identity.&lt;ref&gt;Kilp, Knauer and Mikhalev, 2000, pages 43–44.&lt;/ref&gt; Furthermore, since a monoid is a semigroup, one can consider semigroup actions of monoids.

The defining property of an act is analogous to the [[associativity]] of the semigroup operation, and means that all parentheses can be omitted. It is common practice, especially in computer science, to omit the operations as well so that both the semigroup operation and the action are indicated by juxtaposition. In this way  [[string (computer science)|strings]] of letters from ''S'' act on ''X'', as in the expression ''stx'' for ''s'', ''t'' in ''S'' and ''x'' in ''X''.

It is also quite common to work with right acts rather than left acts.&lt;ref&gt;Kilp, Knauer and Mikhalev, 2000.&lt;/ref&gt; However, every right S-act can be interpreted as a left act over the '''opposite semigroup''', which has the same elements as S, but where multiplication is defined by reversing the factors, {{nowrap|1=''s'' • ''t'' = ''t'' • ''s''}}, so the two notions are essentially equivalent. Here we primarily adopt the point of view of left acts.

===Acts and transformations===

It is often convenient (for instance if there is more than one act under consideration) to use a letter, such as &lt;math&gt;T&lt;/math&gt;, to denote the function
:&lt;math&gt; T\colon S\times X \to X&lt;/math&gt;
defining the &lt;math&gt;S&lt;/math&gt;-action and hence write &lt;math&gt;T(s, x)&lt;/math&gt; in place of &lt;math&gt;s\cdot x&lt;/math&gt;. Then for any &lt;math&gt;s&lt;/math&gt; in &lt;math&gt;S&lt;/math&gt;, we denote by
:&lt;math&gt; T_s\colon X \to X&lt;/math&gt;
the transformation of &lt;math&gt;X&lt;/math&gt; defined by
:&lt;math&gt; T_s(x) = T(s,x).&lt;/math&gt;
By the defining property of an &lt;math&gt;S&lt;/math&gt;-act, &lt;math&gt;T&lt;/math&gt; satisfies
:&lt;math&gt; T_{s*t} = T_s\circ T_t.&lt;/math&gt;
Further, consider a function &lt;math&gt;s\mapsto T_s&lt;/math&gt;. It is the same as &lt;math&gt;curry(T):S\to(X\to X)&lt;/math&gt; (see [[currying]]). Because &lt;math&gt;curry&lt;/math&gt; is a bijection, semigroup actions can be defined as functions &lt;math&gt;S\to(X\to X)&lt;/math&gt; which satisfies
:&lt;math&gt; curry(T)(s*t) = curry(T)(s)\circ curry(T)(t).&lt;/math&gt;
I.e. &lt;math&gt;T&lt;/math&gt; is a semigroup action of &lt;math&gt;S&lt;/math&gt; on &lt;math&gt;X&lt;/math&gt; iff &lt;math&gt;curry(T)&lt;/math&gt; is a [[semigroup homomorphism]] from &lt;math&gt;S&lt;/math&gt; to the full transformation monoid of &lt;math&gt;X&lt;/math&gt;.

===''S''-homomorphisms===

Let ''X'' and ''X''′ be ''S''-acts. Then an ''S''-homomorphism from ''X'' to ''X''′ is a map
:&lt;math&gt;F\colon X\to X'&lt;/math&gt;
such that 
:&lt;math&gt;F(sx) =s F(x)&lt;/math&gt; for all &lt;math&gt;s\in S&lt;/math&gt; and &lt;math&gt;x\in X&lt;/math&gt;.
The set of all such ''S''-homomorphisms is commonly written as &lt;math&gt;\mathrm{Hom}_S(X,X')&lt;/math&gt;.

''M''-homomorphisms of ''M''-acts, for ''M'' a monoid, are defined in exactly the same way.

===''S''-Act and ''M''-Act===

For a fixed semigroup ''S'', the left ''S''-acts are the objects of a category, denoted ''S''-Act, whose morphisms are the ''S''-homomorphisms. The corresponding category of right ''S''-acts is sometimes denoted by Act-''S''. (This is analogous to the categories ''R''-Mod and Mod-''R'' of left and right [[module (mathematics)|modules]] over a [[ring (mathematics)|ring]].)

For a monoid ''M'', the categories ''M''-Act and Act-''M'' are defined in the same way.

==Examples==
* Any semigroup &lt;math&gt;(S, *)&lt;/math&gt; has an action on &lt;math&gt;S&lt;/math&gt;, where &lt;math&gt;\cdot = *&lt;/math&gt;. The action property holds due to the associativity of &lt;math&gt;*&lt;/math&gt;.
* More generally, for any semigroup homomorphism &lt;math&gt;F\colon (S, *) \rightarrow (T, \oplus)&lt;/math&gt;, the semigroup &lt;math&gt;(S, *)&lt;/math&gt; has an action on &lt;math&gt;T&lt;/math&gt; given by &lt;math&gt;s \cdot t = F(s) \oplus t&lt;/math&gt;.
* For any set &lt;math&gt;X&lt;/math&gt;, let &lt;math&gt;X^*&lt;/math&gt; be the set of sequences of elements of &lt;math&gt;X&lt;/math&gt;. The semigroup &lt;math&gt;(\mathbb{N}, \times)&lt;/math&gt; has an action on &lt;math&gt;X^*&lt;/math&gt; given by &lt;math&gt;n \cdot s = s^n&lt;/math&gt; (where &lt;math&gt;s^n&lt;/math&gt; denotes &lt;math&gt;s&lt;/math&gt; repeated &lt;math&gt;n&lt;/math&gt; times).

==Transformation semigroups==

{{main|Transformation semigroup}}

A correspondence between transformation semigroups and semigroup actions is described below. If we restrict it to [[Faithful action|faithful]] semigroup actions, it has nice properties.

Any transformation semigroup can be turned into a semigroup action by the following construction. For any transformation semigroup &lt;math&gt;S&lt;/math&gt; of &lt;math&gt;X&lt;/math&gt;, define a semigroup action &lt;math&gt;T&lt;/math&gt; of &lt;math&gt;S&lt;/math&gt; on &lt;math&gt;X&lt;/math&gt; as &lt;math&gt;T(s, x) = s(x)&lt;/math&gt; for &lt;math&gt; s\in S, x\in X&lt;/math&gt;. This action is faithful, which is equivalent to &lt;math&gt;curry(T)&lt;/math&gt; being [[injective]].

Conversely, for any semigroup action &lt;math&gt;T&lt;/math&gt; of &lt;math&gt;S&lt;/math&gt; on &lt;math&gt;X&lt;/math&gt;, define a transformation semigroup &lt;math&gt;S' = \{T_s | s\in S\}&lt;/math&gt;. In this construction we "forget" the set &lt;math&gt;S&lt;/math&gt;. &lt;math&gt;S'&lt;/math&gt; is equal to the [[Image (mathematics)|image]] of &lt;math&gt;curry(T)&lt;/math&gt;. Lets denote &lt;math&gt;curry(T)&lt;/math&gt; as &lt;math&gt;f&lt;/math&gt; for brevity. If &lt;math&gt;curry(T)&lt;/math&gt; is [[injective]], then &lt;math&gt;f&lt;/math&gt; is a semigroup [[isomorphism]] from &lt;math&gt;S&lt;/math&gt; to &lt;math&gt;S'&lt;/math&gt;. In other words, if &lt;math&gt;T&lt;/math&gt; is faithful, then we forget nothing important. This claim is made precise by the following observation: if we turn &lt;math&gt;S'&lt;/math&gt; back into a semigroup action &lt;math&gt;T'&lt;/math&gt; of &lt;math&gt;S'&lt;/math&gt; on &lt;math&gt;X&lt;/math&gt;, then &lt;math&gt;T'(f(s), x)=T(s, x)&lt;/math&gt; for all &lt;math&gt; s\in S, x\in X&lt;/math&gt;. &lt;math&gt;T&lt;/math&gt; and &lt;math&gt;T'&lt;/math&gt; are "isomorphic" via &lt;math&gt;f&lt;/math&gt;, i.e., we essentially recovered &lt;math&gt;T&lt;/math&gt;. Thus some authors&lt;ref&gt;{{cite book
| editor1-first = Michael A.
| editor1-last = Arbib
| year = 1968
| title = Algebraic Theory of Machines, Languages, and Semigroups
| publisher = Academic Press
| location = New York and London
| page = 83
}}&lt;/ref&gt; see no distinction between faithful semigroup actions and transformation semigroups.

==Applications to computer science==
===Semiautomata===

{{main|semiautomaton}}

Transformation semigroups are of essential importance for the structure theory of [[finite state machine]]s in [[automata theory]]. In particular, a ''semiautomaton'' is a triple (''Σ'',''X'',''T''), where ''Σ'' is a non-empty set called the ''input alphabet'', ''X'' is a non-empty set called the ''set of states'' and ''T'' is a function
:&lt;math&gt;T\colon \Sigma\times X \to X&lt;/math&gt;
called the ''transition function''. Semiautomata arise from [[deterministic finite automaton|deterministic automata]] by ignoring the initial state and the set of accept states.

Given a semiautomaton, let ''T''&lt;sub&gt;''a''&lt;/sub&gt;: ''X'' → ''X'', for ''a'' ∈ ''Σ'', denote the transformation of ''X'' defined by ''T''&lt;sub&gt;''a''&lt;/sub&gt;(''x'') = ''T''(''a'',''x''). Then the semigroup of transformations of ''X'' generated by {''T''&lt;sub&gt;''a''&lt;/sub&gt; : ''a'' ∈ ''Σ''} is called the ''[[characteristic semigroup]]'' or ''transition system'' of (''Σ'',''X'',''T''). This semigroup is a monoid, so this monoid is called the ''characteristic'' or ''[[transition monoid]]''. It is also sometimes viewed as an ''Σ''&lt;sup&gt;∗&lt;/sup&gt;-act on ''X'', where ''Σ''&lt;sup&gt;∗&lt;/sup&gt; is the [[free monoid]] of strings generated by the alphabet ''Σ'' and the action of strings extends the action of ''Σ'' via the property
:&lt;math&gt;T_{vw} = T_w \circ T_v.&lt;/math&gt;

===Krohn–Rhodes theory===

{{main|Krohn–Rhodes theory}}

Krohn–Rhodes theory, sometimes also called ''algebraic automata theory'', gives powerful decomposition results for finite transformation semigroups by cascading simpler components.

==Notes==
{{reflist|2}}

==References==
* A. H. Clifford and G. B. Preston (1961), ''The Algebraic Theory of Semigroups'', volume 1. American Mathematical Society, {{isbn|978-0-8218-0272-4}}.
* A. H. Clifford and G. B. Preston (1967), ''The Algebraic Theory of Semigroups'', volume 2. American Mathematical Society, {{isbn|978-0-8218-0272-4}}.
* Mati Kilp, Ulrich Knauer, Alexander V. Mikhalev (2000), ''Monoids, Acts and Categories: with Applications to Wreath Products and Graphs'', Expositions in Mathematics '''29''', Walter de Gruyter, Berlin, {{isbn|978-3-11-015248-7}}.
* Rudolf Lidl and Günter Pilz, ''Applied Abstract Algebra'' (1998), Springer, {{isbn|978-0-387-98290-8}}

[[Category:Semigroup theory]]
[[Category:Theoretical computer science]]</text>
      <sha1>5g2sznkyshtn3a21ougjxjoibh9ssk8</sha1>
    </revision>
  </page>
  <page>
    <title>Set packing</title>
    <ns>0</ns>
    <id>2017636</id>
    <revision>
      <id>863538603</id>
      <parentid>840799833</parentid>
      <timestamp>2018-10-11T12:28:36Z</timestamp>
      <contributor>
        <ip>195.206.105.37</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11639">'''Set packing''' is a classical [[NP-complete]] problem in [[computational complexity theory]] and [[combinatorics]], and was one of [[Karp's 21 NP-complete problems]].

Suppose one has a [[finite set]] ''S'' and a list of [[subset]]s of ''S''. Then, the set packing problem asks if some ''k'' subsets in the list are pairwise [[disjoint sets|disjoint]] (in other words, no two of them share an element).

More formally, given a universe &lt;math&gt;\mathcal{U}&lt;/math&gt; and a family &lt;math&gt;\mathcal{S}&lt;/math&gt; of subsets of &lt;math&gt;\mathcal{U}&lt;/math&gt;,
a ''packing'' is a subfamily &lt;math&gt;\mathcal{C}\subseteq\mathcal{S}&lt;/math&gt; of sets such that all sets in &lt;math&gt;\mathcal{C}&lt;/math&gt; are pairwise disjoint. The size of the packing is &lt;math&gt;|\mathcal{C}|&lt;/math&gt;. In the set packing [[decision problem]], the input is a pair &lt;math&gt;(\mathcal{U},\mathcal{S})&lt;/math&gt; and an integer &lt;math&gt;k&lt;/math&gt;; the question is whether
there is a set packing of size &lt;math&gt;k&lt;/math&gt; or more. In the set packing [[optimization problem]], the input is a pair &lt;math&gt;(\mathcal{U},\mathcal{S})&lt;/math&gt;, and the task is to find a set packing that uses the most sets. 

The problem is clearly in [[NP (complexity)|NP]] since, given ''k'' subsets, we can easily verify that they are pairwise disjoint in [[P (complexity)|polynomial time]].

The [[optimization problem|optimization version]] of the problem, '''maximum set packing''', asks for the maximum number of pairwise disjoint sets in the list. It is a maximization problem that can be formulated naturally as an [[integer linear program]], belonging to the class of [[packing problems]].

{{Covering-Packing Problem Pairs}}

==Integer linear program formulation==
The maximum set packing problem can be formulated as the following [[integer linear program]].
{|
| maximize
| &lt;math&gt;\sum_{S \in \mathcal S}  x_S&lt;/math&gt;
|
| (maximize the total number of subsets)
|-
| subject to
| &lt;math&gt;\sum_{S\colon e \in S} x_S \leqslant 1 &lt;/math&gt;
| for all &lt;math&gt;e\in \mathcal U&lt;/math&gt;
| (selected sets have to be pairwise disjoint)
|-
|
| &lt;math&gt;x_S \in \{0,1\}&lt;/math&gt;
| for all &lt;math&gt;S\in \mathcal S&lt;/math&gt;.
| (every set is either in the set packing or not)
|}

== Examples ==
As a simple example, suppose your kitchen contains a collection of different food ingredients (&lt;math&gt;\mathcal{U}&lt;/math&gt;), and you have a cook-book with a collection of recipes ( &lt;math&gt;\mathcal{S}&lt;/math&gt;). Each recipe requires a subset of the food ingredients. You want to prepare the largest possible collection of recipes from the cook-book. You are actually looking for a set-packing (&lt;math&gt;\mathcal{C}&lt;/math&gt;) on (&lt;math&gt;\mathcal{U},\mathcal{S}&lt;/math&gt;) - a collection of recipes whose sets of ingredients are pairwise disjoint.

As another example, suppose you're at a convention of foreign ambassadors, each of which speaks English and also various other languages. You want to make an announcement to a group of them, but because you don't trust them, you don't want them to be able to speak among themselves without you being able to understand them. To ensure this, you will choose a group such that no two ambassadors speak the same language, other than English. On the other hand you also want to give your announcement to as many ambassadors as possible.  In this case, the elements of the set are languages other than English, and the subsets are the sets of languages spoken by a particular ambassador. If two sets are disjoint, those two ambassadors share no languages other than English. A maximum set packing will choose the largest possible number of ambassadors under the desired constraint. Although this problem is hard to solve in general, in this example a good heuristic is to choose ambassadors who only speak unusual languages first, so that not too many others are disqualified.

== Weighted version  ==

There is a weighted version of the set packing problem in which each subset is assigned a real weight and it is this weight we wish to maximize: &lt;math&gt;\sum_{S \in \mathcal S} w(S) \cdot x_S&lt;/math&gt;

In our simple example above, we might weight the recipes according to the number of friends that love the resulting dishes, so that our dinner will please the largest number of friends. 

This seems to make the problem harder, but most known results for the unweighted problem apply to the weighted problem as well.{{Citation needed|date=September 2017}}

== Heuristics ==

The set packing problem may be hard for some ''k'', but it's not hard to find a ''k'' for which it is easy on a particular input. For example, we can use a [[greedy algorithm]] where we look for the set which intersects the smallest number of other sets, add it to our solution, and remove the sets it intersects. We continually do this until no sets are left, and we have a set packing of some size, although it may not be the maximum set packing. Although no algorithm{{Citation needed|date=February 2017}} can always produce results close to the maximum (see next section), on many practical inputs these heuristics do so.

== Complexity ==

The set packing problem is not only NP-complete, but its optimization version (general maximum set packing problem) has been proven as difficult to approximate as the [[maximum clique problem]]; in particular, it cannot be approximated within any constant factor.&lt;ref&gt;{{citation
 | last1 = Hazan | first1 = Elad
 | last2 = Safra | first2 = Shmuel
 | last3 = Schwartz | first3 = Oded
 | doi = 10.1007/s00037-006-0205-6
 | issue = 1
 | journal = [[Computational Complexity (journal)|Computational Complexity]]
 | mr = 2226068
 | pages = 20–39
 | title = On the complexity of approximating ''k''-set packing
 | volume = 15
 | year = 2006}}. See in particular p.&amp;nbsp;21: "Maximum clique (and therefore also maximum independent set and maximum set packing) cannot be approximated to within &lt;math&gt;O(n^{1-\epsilon})&lt;/math&gt; unless NP &amp;sub; ZPP."&lt;/ref&gt; The best known algorithm approximates it within a factor of &lt;math&gt;O(\sqrt{|U|})&lt;/math&gt;.&lt;ref&gt;{{cite conference
| last1 = Halldórsson | first1 = Magnus M.
| last2 = Kratochvíl | first2 = Jan
| last3 = Telle | first3 = Jan Arne
| title = Independent sets with domination constraints
| conference = 25th International Colloquium on Automata, Languages and Programming
| series = Lecture Notes in Computer Science
| volume = 1443
| publisher = Springer-Verlag
| pages = 176–185
| year = 1998
}}&lt;/ref&gt;
The weighted variant can also be approximated as well.&lt;ref&gt;{{cite conference
| last = Halldórsson | first = Magnus M.
| year = 1999
| title = Approximations of weighted independent set and hereditary subset problems
| conference = 5th Annual International Conference on Computing and Combinatorics
| series = Lecture Notes in Computer Science
| volume = 1627
| publisher = Springer-Verlag
| pages = 261–270
}}&lt;/ref&gt;

However, the problem does have a variant which is more tractable: if we assume no subset exceeds ''k''≥3 elements, the answer can be approximated within a factor of ''k''/2 + ε for any ε &gt; 0; in particular, the problem with 3-element sets can be approximated within about 50%. In another more tractable variant, if no element occurs in more than ''k'' of the subsets, the answer can be approximated within a factor of ''k''. This is also true for the weighted version.

== Equivalent problems ==

There is a one-to-one polynomial-time reduction between the [[Independent set (graph theory)|independent set]] problem and the set packing problem:
* Given a set packing problem on a collection &lt;math&gt;\mathcal{S}&lt;/math&gt;, create a graph where for each set &lt;math&gt;S \in \mathcal{S}&lt;/math&gt; there is a vertex &lt;math&gt;v_S&lt;/math&gt;, and there is an edge between &lt;math&gt;v_S&lt;/math&gt; and &lt;math&gt;v_T&lt;/math&gt; if &lt;math&gt;S \cap T \neq \varnothing&lt;/math&gt;. Now every independent set of vertices in the generated graph corresponds to a set packing in &lt;math&gt;\mathcal{S}&lt;/math&gt;.
* Given an independent vertex set problem on a graph &lt;math&gt;G(V,E)&lt;/math&gt;, create a collection of sets where for each vertex &lt;math&gt;v&lt;/math&gt; there is a set &lt;math&gt;S_v&lt;/math&gt; containing all edges adjacent to &lt;math&gt;v&lt;/math&gt;. Now every set packing in the generated collection corresponds to an independent vertex set in &lt;math&gt;G(V,E)&lt;/math&gt;.

This is also a bidirectional [[PTAS reduction]], and it shows that the two problems are equally difficult to approximate.

== Special cases ==

[[Matching (graph theory)|Matching]] and [[3-dimensional matching]] are special cases of set packing. A maximum-size matching can be found in polynomial time, but finding a largest 3-dimensional matching or a largest independent set is NP-hard.

== Other related problems ==

Set packing is one among a family of problems related to covering or partitioning the elements of a set. One closely related problem is the [[set cover problem]]. Here, we are also given a set ''S'' and a list of sets, but the goal is to determine whether we can choose ''k'' sets that together contain every element of ''S''. These sets may overlap. The optimization version finds the minimum number of such sets. The maximum set packing need not cover every possible element.

The NP-complete [[exact cover]] problem, on the other hand, requires every element to be contained in exactly one of the subsets. Finding such an exact cover at all, regardless of size, is an [[NP-complete]] problem. However, if we create a [[singleton set]] for each element of ''S'' and add these to the list, the resulting problem is about as easy as set packing.

Karp originally showed set packing NP-complete via a reduction from the [[clique problem]].

See also: [[Packing in a hypergraph]].

== Notes ==
{{reflist}}

== References ==
* [http://www.nada.kth.se/~viggo/wwwcompendium/node144.html Maximum Set Packing], Viggo Kann.
* "[https://xlinux.nist.gov/dads/HTML/setpacking.html set packing]". ''Dictionary of Algorithms and Data Structures'', editor Paul E. Black, ''National Institute of Standards and Technology.'' Note that the definition here is somewhat different.
* Steven S. Skiena. "[http://www3.cs.stonybrook.edu/~algorith/files/set-packing.shtml Set Packing]". ''The Algorithm Design Manual''.
* Pierluigi Crescenzi, Viggo Kann, Magnús Halldórsson, [[Marek Karpinski]] and [[Gerhard J. Woeginger|Gerhard Woeginger]]. "[http://www.nada.kth.se/~viggo/wwwcompendium/node144.html Maximum Set Packing]". [http://www.nada.kth.se/%7Eviggo/wwwcompendium/ ''A compendium of NP optimization problems'']. Last modified March 20, 2000.
* {{cite book|author = [[Michael R. Garey]] and [[David S. Johnson]] | year = 1979 | title = [[Computers and Intractability: A Guide to the Theory of NP-Completeness]] | publisher = W.H. Freeman | isbn = 0-7167-1045-5}} A3.1: SP3, pg.221.
* {{Cite book | last=Vazirani | first=Vijay V. | authorlink=Vijay Vazirani | title=Approximation Algorithms | year=2001 | publisher=Springer-Verlag | isbn=3-540-65367-8 | pages=}}

== External links ==
* [http://www.cs.sunysb.edu/~algorith/implement/syslo/implement.shtml]: A Pascal program for solving the problem. From ''Discrete Optimization Algorithms with Pascal Programs'' by MacIej M. Syslo, {{isbn|0-13-215509-5}}.
* [http://www.nlsde.buaa.edu.cn/~kexu/benchmarks/set-benchmarks.htm Benchmarks with Hidden Optimum Solutions for Set Covering, Set Packing and Winner Determination]
*[https://web.archive.org/web/20101226041147/http://www.phpqa.in/2010/10/solving-packaging-problem-in-php.html Solving packaging problem in PHP]
*[https://pdfs.semanticscholar.org/bb99/86af2f26f7726fcef1bc684eac8239c9b853.pdf?_ga=1.50320358.1394974689.1485463187 Optimizing Three-Dimensional Bin Packing]

{{Packing problem}}

[[Category:Combinatorics]]
[[Category:NP-complete problems]]</text>
      <sha1>7c9zriwcl50pllvako4pfsn6m3vlt6a</sha1>
    </revision>
  </page>
  <page>
    <title>Shephard's problem</title>
    <ns>0</ns>
    <id>10614436</id>
    <revision>
      <id>834507015</id>
      <parentid>799018583</parentid>
      <timestamp>2018-04-06T02:17:24Z</timestamp>
      <contributor>
        <username>Vycl1994</username>
        <id>19014806</id>
      </contributor>
      <comment>/* References */ wl</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3082">In [[mathematics]], '''Shephard's problem''', is the following geometrical question asked by {{harvs|txt|first=Geoffrey Colin |last=Shephard|authorlink=Geoffrey Colin Shephard|year=1964}}: if ''K'' and ''L'' are centrally symmetric [[convex body|convex bodies]] in ''n''-[[dimension]]al [[Euclidean space]] such that whenever ''K'' and ''L'' are [[projection (mathematics)|projected]] onto a [[hyperplane]], the [[volume]] of the projection of ''K'' is smaller than the volume of the projection of ''L'', then does it follow that the volume of ''K'' is smaller than that of ''L''?

In this case, "centrally symmetric" means that the [[Reflection symmetry|reflection]] of ''K'' in the origin, ''&amp;minus;K'', is a translate of ''K'', and similarly for ''L''. If ''π''&lt;sub&gt;''k''&lt;/sub&gt;&amp;nbsp;:&amp;nbsp;'''R'''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;Π&lt;sub&gt;''k''&lt;/sub&gt; is a [[projection (mathematics)|projection]] of '''R'''&lt;sup&gt;''n''&lt;/sup&gt; onto some ''k''-dimensional [[hyperplane]] Π&lt;sub&gt;''k''&lt;/sub&gt; (not necessarily a coordinate hyperplane) and ''V''&lt;sub&gt;''k''&lt;/sub&gt; denotes ''k''-dimensional volume, Shephard's problem is to determine the truth or falsity of the implication

:&lt;math&gt;V_{k} (\pi_{k} (K)) \leq V_{k} (\pi_{k} (L)) \mbox{ for all } 1 \leq k &lt; n \implies V_{n} (K) \leq V_{n} (L).&lt;/math&gt;

''V''&lt;sub&gt;''k''&lt;/sub&gt;(''π''&lt;sub&gt;''k''&lt;/sub&gt;(''K'')) is sometimes known as the '''brightness''' of ''K'' and the function ''V''&lt;sub&gt;''k''&lt;/sub&gt;&amp;nbsp;&lt;small&gt;o&lt;/small&gt;&amp;nbsp;''π''&lt;sub&gt;''k''&lt;/sub&gt; as a (''k''-dimensional) '''brightness function'''.

In dimensions ''n''&amp;nbsp;=&amp;nbsp;1 and 2, the answer to Shephard's problem is "yes". In 1967, however, Petty and Schneider showed that the answer is "no" for every ''n''&amp;nbsp;≥&amp;nbsp;3. The solution of Shephard's problem requires [[Minkowski's first inequality for convex bodies]] and the notion of [[projection body| projection bodies]] of convex bodies.

==See also==

*[[Busemann–Petty problem]]

==References==

* {{cite journal
| last=Gardner 
| first=Richard J. 
| title=The Brunn-Minkowski inequality 
| journal=[[Bulletin of the American Mathematical Society|Bull. Amer. Math. Soc.]] (N.S.) 
| volume=39 
| issue=3 
| year=2002 
| pages=355&amp;ndash;405 (electronic) 
| doi=10.1090/S0273-0979-02-00941-2 
}}
* {{cite journal
|     last = Petty
|    first = C.M.
|    title = Projection bodies
|  journal = Proc. Colloquium on Convexity (Copenhagen, 1965)
|    pages = 234&amp;ndash;241
|publisher = Kobenhavns Univ. Mat. Inst., Copenhagen
|     year = 1967
}}
* {{cite journal
|     last = Schneider
|    first = Rolf
| authorlink = Rolf Schneider
|    title = Zur einem Problem von Shephard über die Projektionen konvexer Körper
|  journal = Math. Z.
|   volume = 101
|     year = 1967
|    pages = 71&amp;ndash;82
| language = German
|    doi = 10.1007/BF01135693
}}
*{{Citation | last1=Shephard | first1=G. C. | title=Shadow systems of convex sets | doi=10.1007/BF02759738 |mr=0179686 | year=1964 | journal=Israel Journal of Mathematics | issn=0021-2172 | volume=2 | pages=229–236}}

[[Category:Convex geometry]]
[[Category:Convex analysis]]</text>
      <sha1>m3ip44m4dxmt11ezl5rhtmy0p0zbtvt</sha1>
    </revision>
  </page>
  <page>
    <title>Størmer's theorem</title>
    <ns>0</ns>
    <id>3445204</id>
    <revision>
      <id>842878146</id>
      <parentid>793455740</parentid>
      <timestamp>2018-05-25T08:38:22Z</timestamp>
      <contributor>
        <ip>82.132.223.72</ip>
      </contributor>
      <comment>Corrected typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13665">In [[number theory]], '''Størmer's theorem''', named after [[Carl Størmer]], gives a finite bound on the number of consecutive pairs of [[smooth numbers]] that exist, for a given degree of smoothness, and provides a method for finding all such pairs using [[Pell equation]]s. It follows from the [[Thue–Siegel–Roth theorem]] that there are only a finite number of pairs of this type, but Størmer gave a procedure for finding them all.{{sfnp|Størmer|1897}}

==Statement==
If one chooses a [[finite set]] &lt;math&gt;P=\{p_1,p_2,\dots p_k\}&lt;/math&gt; of [[prime number]]s then the {{mvar|P}}-smooth numbers are defined as the set of integers

:&lt;math&gt;\left\{p_1^{e_1}p_2^{e_2}\cdots p_k^{e_k}\mid e_i\in\{0,1,2,\ldots\}\right\}&lt;/math&gt;

that can be generated by products of numbers in {{mvar|P}}. Then Størmer's theorem states that, for every choice of {{mvar|P}}, there are only finitely many pairs of consecutive {{mvar|P}}-smooth numbers. Further, it gives a method of finding them all using Pell equations.

== The procedure ==
Størmer's original procedure involves solving a set of roughly 3&lt;sup&gt;''k''&lt;/sup&gt; [[Pell's equation|Pell equations]], in each one finding only the smallest solution. A simplified version of the procedure, due to [[D. H. Lehmer]],&lt;ref name="lehmer"&gt;{{harvtxt|Lehmer|1964}}.&lt;/ref&gt; is described below; it solves fewer equations but finds more solutions in each equation.

Let ''P'' be the given set of primes, and define a number to be ''P''-[[smooth number|smooth]] if all its prime factors belong to ''P''. Assume ''p''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;2; otherwise there could be no consecutive ''P''-smooth numbers, because all ''P''-smooth numbers would be odd. Lehmer's method involves solving the Pell equation
:&lt;math&gt;x^2-2qy^2 = 1&lt;/math&gt;
for each ''P''-smooth [[square-free number]] ''q'' other than 2. Each such number ''q'' is generated as a product of a subset of ''P'', so there are 2&lt;sup&gt;''k''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;1 Pell equations to solve. For each such equation, let ''x&lt;sub&gt;i&lt;/sub&gt;,&amp;nbsp;y&lt;sub&gt;i&lt;/sub&gt;'' be the generated solutions, for ''i'' in the range from 1 to max(3,&amp;nbsp;(''p&lt;sub&gt;k&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;1)/2) (inclusive), where ''p&lt;sub&gt;k&lt;/sub&gt;'' is the largest of the primes in ''P''.

Then, as Lehmer shows, all consecutive pairs of ''P''-smooth numbers are of the form (''x&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;&amp;minus;&amp;nbsp;1)/2, (''x&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;1)/2. Thus one can find all such pairs by testing the numbers of this form for ''P''-smoothness.

== Example ==
To find the ten consecutive pairs of [[regular number|{2,3,5}-smooth numbers]] (in [[music theory]], giving the [[superparticular ratio]]s for [[just tuning]]) let ''P'' = {2,3,5}. There are seven ''P''-smooth squarefree numbers ''q'' (omitting the eighth ''P''-smooth squarefree number, 2): 1, 3, 5, 6, 10, 15, and 30, each of which leads to a Pell equation. The number of solutions per Pell equation required by Lehmer's method is max(3,&amp;nbsp;(5&amp;nbsp;+&amp;nbsp;1)/2) = 3, so this method generates three solutions to each Pell equation, as follows.

* For ''q'' = 1, the first three solutions to the Pell equation ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 2''y''&lt;sup&gt;2&lt;/sup&gt; = 1 are (3,2), (17,12), and (99,70). Thus, for each of the three values ''x&lt;sub&gt;i&lt;/sub&gt;'' = 3, 17, and 99, Lehmer's method tests the pair (''x&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;&amp;minus;&amp;nbsp;1)/2, (''x&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;1)/2 for smoothness; the three pairs to be tested are (1,2), (8,9), and (49,50).  Both (1,2) and (8,9) are pairs of  consecutive ''P''-smooth numbers, but (49,50) is not, as 49 has 7 as a prime factor.
* For ''q'' = 3, the first three solutions to the Pell equation ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 6''y''&lt;sup&gt;2&lt;/sup&gt; = 1 are (5,2), (49,20), and (485,198). From the three values ''x&lt;sub&gt;i&lt;/sub&gt;'' = 5, 49, and 485 Lehmer's method forms the three candidate pairs of consecutive numbers (''x&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;&amp;minus;&amp;nbsp;1)/2, (''x&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;1)/2: (2,3), (24,25), and (242,243). Of these, (2,3) and (24,25) are pairs of consecutive ''P''-smooth numbers but (242,243) is not.
* For ''q'' = 5, the first three solutions to the Pell equation ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 10''y''&lt;sup&gt;2&lt;/sup&gt; = 1 are (19,6), (721,228), and (27379,8658). The Pell solution (19,6) leads to the pair of consecutive ''P''-smooth numbers (9,10); the other two solutions to the Pell equation do not lead to ''P''-smooth pairs.
* For ''q'' = 6, the first three solutions to the Pell equation ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 12''y''&lt;sup&gt;2&lt;/sup&gt; = 1 are (7,2), (97,28), and (1351,390). The Pell solution (7,2) leads to the pair of consecutive ''P''-smooth numbers (3,4).
* For ''q'' = 10, the first three solutions to the Pell equation ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 20''y''&lt;sup&gt;2&lt;/sup&gt; = 1 are (9,2), (161,36), and (2889,646). The Pell solution (9,2) leads to the pair of consecutive ''P''-smooth numbers (4,5) and the Pell solution (161,36) leads to the pair of consecutive ''P''-smooth numbers (80,81).
* For ''q'' = 15, the first three solutions to the Pell equation ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 30''y''&lt;sup&gt;2&lt;/sup&gt; = 1 are (11,2), (241,44), and (5291,966). The Pell solution (11,2) leads to the pair of consecutive ''P''-smooth numbers (5,6).
* For ''q'' = 30, the first three solutions to the Pell equation ''x''&lt;sup&gt;2&lt;/sup&gt; &amp;minus; 60''y''&lt;sup&gt;2&lt;/sup&gt; = 1 are (31,4), (1921,248), and (119071,15372). The Pell solution (31,4) leads to the pair of consecutive ''P''-smooth numbers (15,16).

== Counting solutions ==
Størmer's original result can be used to show that the number of consecutive pairs of integers that are smooth with respect to a set of ''k'' primes is at most 3&lt;sup&gt;''k''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;2&lt;sup&gt;''k''&lt;/sup&gt;. Lehmer's result produces a tighter bound for sets of small primes: (2&lt;sup&gt;''k''&lt;/sup&gt;&amp;nbsp;&amp;minus;&amp;nbsp;1)&amp;nbsp;&amp;times;&amp;nbsp;max(3,(''p&lt;sub&gt;k&lt;/sub&gt;''+1)/2).&lt;ref name="lehmer"/&gt;

The number of consecutive pairs of integers that are smooth with respect to the first ''k'' primes are
:1, 4, 10, 23, 40, 68, 108, 167, 241, 345, ... {{OEIS|id = A002071}}.
The largest integer from all these pairs, for each ''k'', is
:2, 9, 81, 4375, 9801, 123201, 336141, 11859211, ... {{OEIS | id = A117581}}.
OEIS also lists the number of pairs of this type where the larger of the two integers in the pair is square {{OEIS|id = A117582}} or [[triangular number|triangular]] {{OEIS|id = A117583}}, as both types of pair arise frequently.

== Generalizations and applications ==
[[Louis Mordell]] wrote about this result, saying that it "is very pretty, and there are many applications of it."&lt;ref&gt;As quoted by {{harvtxt|Chapman|1958}}.&lt;/ref&gt;

===In mathematics===
{{harvtxt|Chein|1976}} used Størmer's method to prove [[Catalan's conjecture]] on the nonexistence of consecutive [[perfect power]]s (other than 8,9) in the case where one of the two powers is a [[square number|square]].

{{harvtxt|Mabkhout|1993}} proved that every number ''x''&lt;sup&gt;4&lt;/sup&gt; + 1, for ''x'' &gt; 3, has a prime factor greater than or equal to 137. Størmer's theorem is an important part of his proof, in which he reduces the problem to the solution of 128 Pell equations.

Several authors have extended Størmer's work by providing methods for listing the solutions to more general [[diophantine equation]]s, or by providing more general [[divisibility]] criteria for the solutions to Pell equations.&lt;ref&gt;In particular see {{harvtxt|Cao|1991}}, {{harvtxt|Luo|1991}}, {{harvtxt|Mei|Sun|1997}}, {{harvtxt|Sun|Yuan|1989}}, and {{harvtxt|Walker|1967}}.&lt;/ref&gt;

{{harvtxt|Conrey|Holmstrom|McLaughlin|2013}} describe a computational procedure that, empirically, finds many but not all of the consecutive pairs of smooth numbers described by Størmer's theorem, and is much faster
than using Pell's equation to find all solutions.

===In music theory===
In the musical practice of [[just intonation]], musical intervals can be described as ratios between positive integers. More specifically, they can be described as ratios between members of the [[Harmonic series (music)|harmonic series]]. Any musical tone can be broken into its fundamental frequency and harmonic frequencies, which are integer multiples of the fundamental. This series is conjectured to be the basis of natural harmony and melody. The tonal complexity of ratios between these harmonics is said to get more complex with higher prime factors. To limit this tonal complexity, an interval is said to be [[prime limit|''n''-limit]] when both its numerator and denominator are [[Smooth number|''n''-smooth]].&lt;ref&gt;Harry Partch, Genesis of a Music: An Account of a Creative Work, Its Roots, and Its Fulfillments, second edition, enlarged (New York: Da Capo Press, 1974), p. 73. {{ISBN|0-306-71597-X}}; {{ISBN|0-306-80106-X}} (pbk reprint, 1979).&lt;/ref&gt; Furthermore, [[superparticular ratio]]s are very important in just tuning theory as they represent ratios between adjacent members of the harmonic series.&lt;ref&gt;Halsey, G. D.; Hewitt, Edwin (1972). "More on the superparticular ratios in music". American Mathematical Monthly (Mathematical Association of America) 79 (10): 1096–1100. {{doi|10.2307/2317424}}. {{JSTOR|2317424}}. {{MR|0313189}}.&lt;/ref&gt;

Størmer's theorem allows all possible superparticular ratios in a given limit to be found. For example, in the 3-limit ([[Pythagorean tuning]]), the only possible superparticular ratios are 2/1 (the [[octave]]), 3/2 (the [[perfect fifth]]), 4/3 (the [[perfect fourth]]), and 9/8 (the [[whole step]]). That is, the only pairs of consecutive integers that have only powers of two and three in their prime factorizations are (1,2), (2,3), (3,4), and (8,9). If this is extended to the 5-limit, six additional superparticular ratios are available: 5/4 (the [[major third]]), 6/5 (the [[minor third]]), 10/9 (the [[Major second#Major and minor tones|minor tone]]), 16/15 (the [[minor second]]), 25/24 (the [[Semitone#Just intonation|minor semitone]]), and 81/80 (the [[syntonic comma]]). All are musically meaningful.

==Notes==
{{Reflist|30em}}

== References ==
{{Refbegin|colwidth=30em}}
*{{cite journal
 | last = Cao | first = Zhen Fu
 | title = On the Diophantine equation (''ax&lt;sup&gt;m&lt;/sup&gt;'' - 1)/(''abx''-1) = ''by''&lt;sup&gt;2&lt;/sup&gt;
 | journal = Chinese Sci. Bull.
 | volume = 36
 | year = 1991
 | issue = 4
 | pages = 275–278
 | mr = 1138803 |ref=harv}}
*{{Cite journal|first=Sydney|last=Chapman|authorlink=Sydney Chapman (astronomer)|title=Fredrik Carl Mulertz Stormer, 1874-1957|journal=Biographical Memoirs of Fellows of the Royal Society|volume=4|year=1958|pages=257–279|jstor=769515|doi=10.1098/rsbm.1958.0021|ref=harv}}
*{{cite journal
 | last = Chein | first = E. Z.
 | title = A note on the equation ''x''&lt;sup&gt;2&lt;/sup&gt; = ''y&lt;sup&gt;q&lt;/sup&gt;'' + 1
 | jstor = 2041579
 | journal = [[Proceedings of the American Mathematical Society]]
 | volume = 56
 | issue = 1
 | year = 1976
 | pages = 83–84
 | doi = 10.2307/2041579
 | mr = 0404133 |ref=harv}}
*{{cite journal
 | last1 = Conrey | first1 = J. B.
 | last2 = Holmstrom | first2 = M. A.
 | last3 = McLaughlin | first3 = T. L.
 | arxiv = 1212.5161
 | doi = 10.1080/10586458.2013.768483
 | issue = 2
 | journal = Experimental Mathematics
 | mr = 3047912
 | pages = 195–202
 | title = Smooth neighbors
 | volume = 22
 | year = 2013
 | ref=harv}}
*{{cite journal
 | last1 = Halsey | first1 = G. D. | last2 = Hewitt | first2 = Edwin
 | title = More on the superparticular ratios in music
 | jstor = 2317424
 | journal = [[American Mathematical Monthly]]
 | volume = 79
 | issue = 10
 | year = 1972
 | pages = 1096–1100
 | mr = 0313189 
 | doi = 10.2307/2317424|ref=harv}}
*{{cite journal
 | last = Lehmer | first = D. H.
 | authorlink = D. H. Lehmer
 | year = 1964
 | title = On a Problem of Størmer
 | journal = Illinois Journal of Mathematics
 | volume = 8
 | pages = 57–79
 | mr = 0158849|ref=harv }}
*{{cite journal
 | last = Luo | first = Jia Gui
 | title = A generalization of the Störmer theorem and some applications
 | journal = Sichuan Daxue Xuebao
 | volume = 28
 | year = 1991
 | issue = 4
 | pages = 469–474
 | mr = 1148835|ref=harv }}
*{{cite journal
 | last = Mabkhout | first = M.
 | title = Minoration de ''P''(''x''&lt;sup&gt;4&lt;/sup&gt;+1)
 | journal = Rend. Sem. Fac. Sci. Univ. Cagliari
 | volume = 63
 | year = 1993
 | issue = 2
 | pages = 135–148
 | mr = 1319302|ref=harv }}
*{{cite journal
 | last1 = Mei | first1 = Han Fei | last2 = Sun | first2 = Sheng Fang
 | title = A further extension of Störmer's theorem | language =Chinese
 | journal = Journal of Jishou University (Natural Science Edition)
 | volume = 18
 | year = 1997
 | issue = 3
 | pages = 42–44
 | mr = 1490505|ref=harv }}
*{{cite journal
 | last = Størmer | first = Carl
 | authorlink = Carl Størmer
 | title = Quelques théorèmes sur l'équation de Pell &lt;math&gt;x^2 - Dy^2 = \pm1&lt;/math&gt; et leurs applications
 | journal = Skrifter Videnskabs-selskabet (Christiania), Mat.-Naturv. Kl.
 | volume = I
 | issue = 2
 | year = 1897|ref=harv}}
*{{cite journal
 | last1 = Sun | first1 = Qi | last2 = Yuan | first2 = Ping Zhi
 | title = On the Diophantine equations &lt;math&gt;(ax^n - 1)/(ax - 1) = y^2&lt;/math&gt; and &lt;math&gt;(ax^n + 1)/(ax + 1) = y^2&lt;/math&gt;
 | journal = Sichuan Daxue Xuebao
 | volume = 26
 | year = 1989
 | pages = 20–24
 | mr = 1059671 |ref=harv}}
*{{cite journal
 | last = Walker | first = D. T.
 | title = On the diophantine equation ''mX''&lt;sup&gt;2&lt;/sup&gt; - ''nY''&lt;sup&gt;2&lt;/sup&gt; = ±1
 | jstor = 2314877
 | journal = [[American Mathematical Monthly]]
 | volume = 74
 | issue = 5
 | year = 1967
 | pages = 504–513
 | doi = 10.2307/2314877
 | mr = 0211954|ref=harv }}
{{Refend}}

{{DEFAULTSORT:Stormers theorem}}
[[Category:Mathematics of music]]
[[Category:Theorems in number theory]]</text>
      <sha1>szpvpdkj83s7ux22ft0r6jtb9ltc4ma</sha1>
    </revision>
  </page>
  <page>
    <title>Truncated mean</title>
    <ns>0</ns>
    <id>430588</id>
    <revision>
      <id>853238416</id>
      <parentid>852365659</parentid>
      <timestamp>2018-08-03T10:12:02Z</timestamp>
      <contributor>
        <ip>92.3.55.160</ip>
      </contributor>
      <comment>/* See also */ The "AVT Statistical filtering algorithm" article is original research and ought to be deleted.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8860">{{Refimprove|date=July 2010}}
A '''truncated mean''' or '''trimmed mean''' is a [[Statistics|statistical]] [[Average|measure of central tendency]], much like the [[mean]] and [[median]]. It involves the calculation of the mean after discarding given parts of a [[probability distribution]] or [[Sampling (statistics)|sample]] at the high and low end, and typically discarding an equal amount of both. This number of points to be discarded is usually given as a percentage of the total number of points, but may also be given as a fixed number of points.

For most statistical applications, 5 to 25 percent of the ends are discarded; the 25% trimmed mean (when the lowest 25% and the highest 25% are discarded) is known as the [[interquartile mean]]. For example, given a set of 8 points, trimming by 12.5% would discard the minimum and maximum value in the sample: the smallest and largest values, and would compute the mean of the remaining 6 points. 

The median can be regarded as a fully truncated mean and is most robust.  As with other [[trimmed estimator]]s, the main advantage of the trimmed mean is robustness and higher [[Efficiency (statistics)|efficiency]] for mixed distributions and heavy-tailed distribution (like the Cauchy distribution), at the cost of lower efficiency for some other less heavily-tailed distributions (such as the normal distribution). For intermediate distributions the differences between the efficiency of the mean and the median are not very big, e.g. for the student-t distribution with 2 degrees of freedom the variances for mean and median are nearly equal.

==Terminology==
In some regions of [[Central Europe]] it is also known as a '''Windsor mean''',{{fact|date=October 2016}} but this name should not be confused with the [[Winsorized mean]]: in the latter, the observations that the trimmed mean would discard are instead replaced by the largest/smallest of the remaining values.

Discarding only the maximum and minimum is known as the '''{{visible anchor|modified mean}}''', particularly in management statistics.&lt;ref&gt;Arulmozhi, G.; Statistics For Management, 2nd Edition, Tata McGraw-Hill Education, 2009, p. [https://books.google.com/books?id=2qcyNld-bHwC&amp;pg=PA458&amp;lpg=PA458&amp;dq=Modified+mean 458]&lt;/ref&gt; This is also known as the '''{{visible anchor|Olympic average}}''' (for example in US agriculture, like the [[Average Crop Revenue Election]]), due to its use in Olympic events, such as the [[ISU Judging System]] in [[figure skating]], to make the score robust to a single outlier judge.&lt;ref&gt;{{cite web |url=http://farmdocdaily.illinois.edu/2012/08/lessons_from_libor.html |title=Lessons from LIBOR |author=Paul E. Peterson |date=August 3, 2012 |quote=Once the quotes are compiled, LIBOR uses a trimmed mean process, in which the highest and lowest values are thrown out and the remaining values are averaged. This is sometimes called an "Olympic average" from its use in the Olympics to eliminate the impact of a biased judge on an athlete's final score.}}&lt;/ref&gt;

==Interpolation==
When the percentage of points to discard does not yield a whole number, the trimmed mean may be defined by interpolation, generally linear interpolation, between the nearest whole numbers. For example, if you need to calculate the 15% trimmed mean of a sample containing 10 entries, strictly this would mean discarding 1 point from each end (equivalent to the 10% trimmed mean). If interpolating, one would instead compute the 10% trimmed mean (discarding 1 point from each end) and the 20% trimmed mean (discarding 2 points from each end), and then interpolating, in this case averaging these two values. Similarly, if interpolating the 12% trimmed mean, one would take the [[weighted average]]: weight the 10% trimmed mean by 0.8 and the 20% trimmed mean by 0.2.

==Advantages==
The truncated mean is a useful estimator because it is less sensitive to [[outlier]]s than the mean but will still give a reasonable estimate of central tendency or mean for many statistical models. In this regard it is referred to as a [[Robust statistics|robust estimator]]. For example, in its use in Olympic judging, truncating the maximum and minimum prevents a single judge from increasing or lowering the overall score by giving an exceptionally high or low score.

One situation in which it can be advantageous to use a truncated mean is when estimating the [[location parameter]] of a [[Cauchy distribution]], a bell shaped probability distribution with (much) fatter tails than a [[normal distribution]].  It can be shown that the truncated mean of the middle 24% sample [[order statistics]] (i.e., truncate the sample by 38%) produces an estimate for the population location parameter that is more efficient than using either the sample median or the full sample mean.&lt;ref name=rothenberg&gt;{{cite journal|last1=Rothenberg|first1=Thomas J.|last2=Fisher|first2=Franklin, M.|last3=Tilanus|first3=C.B.|year=1964|volume=59|issue=306|journal=Journal of the American Statistical Association|title=A note on estimation from a cauchy sample|pages=460–463|doi=10.1080/01621459.1964.10482170}}&lt;/ref&gt;&lt;ref name=bloch&gt;{{cite journal|last1=Bloch|first1=Daniel|year=1966|volume=61|issue=316|journal=Journal of the American Statistical Association|title=A note on the estimation of the location parameters of the Cauchy distribution|pages=852–855|jstor=2282794|doi=10.1080/01621459.1966.10480912}}&lt;/ref&gt; However, due to the fat tails of the Cauchy distribution, the efficiency of the estimator decreases as more of the sample gets used in the estimate.&lt;ref name=rothenberg/&gt;&lt;ref name=bloch/&gt;  Note that for the Cauchy distribution, neither the truncated mean, full sample mean or sample median represents a [[maximum likelihood]] estimator, nor are any as asymptotically efficient as the maximum likelihood estimator; however, the maximum likelihood estimate is more difficult to compute, leaving the truncated mean as a useful alternative.&lt;ref name=bloch/&gt;&lt;ref name=ferguson&gt;{{cite journal|last1=Ferguson|first1=Thomas S.|year=1978|journal=Journal of the American Statistical Association |volume=73|issue=361|title=Maximum Likelihood Estimates of the Parameters of the Cauchy Distribution for Samples of Size 3 and 4|page=211|jstor=2286549|doi=10.1080/01621459.1978.10480031}}&lt;/ref&gt;

==Drawbacks==
The truncated mean uses more information from the distribution or [[Sample (statistics)|sample]] than the [[median]], but unless the underlying distribution is [[Symmetry|symmetric]], the truncated mean of a sample is unlikely to produce an [[Bias of an estimator|unbiased estimator]] for either the mean or the median.

==Statistical tests==

It is possible to perform a [[Student's t-test]] based on the truncated mean, this is called Yuen's t-test &lt;ref&gt;Yuen, K.K. (1974) The two-sample trimmed t for unequal population variances. Biometrika, 61, 165-170.&lt;/ref&gt;&lt;ref&gt;Wilcox, R.R. (2005). Introduction to robust estimation and hypothesis testing. Academic Press.&lt;/ref&gt;, which also has several implementations in [[R (programming language)|R]] &lt;ref&gt;https://cran.r-project.org/web/packages/WRS2/&lt;/ref&gt;&lt;ref&gt;https://cran.r-project.org/web/packages/DescTools/&lt;/ref&gt;

==Examples==
The scoring method used in many [[sport]]s that are evaluated by a panel of judges is a truncated mean: ''discard the lowest and the highest scores; calculate the mean value of the remaining scores''.&lt;ref name="wsj-sport"&gt;{{cite web |url=https://online.wsj.com/news/articles/SB10000872396390443477104577551253521597214 |title=Removing Judges' Bias Is Olympic-Size Challenge |last1=Bialik |first1=Carl|date=27 July 2012 |website=The Wall Street Journal | accessdate=7 September 2014}}&lt;/ref&gt;

The [[Libor]] benchmark interest rate is [[Libor#Calculation|calculated]] as a trimmed mean: given 18 response, the top 4 and bottom 4 are discarded, and the remaining 10 are averaged (yielding trim factor of 4/18 ≈ 22%).&lt;ref&gt;{{Cite web|url=http://www.bbalibor.com/explained/the-basics|title=bbalibor: The Basics|publisher=The British Bankers' Association}}&lt;/ref&gt;

Consider the data set consisting of:

:{92, 19, '''101''', 58, '''1053''', 91, 26, 78, 10, 13, '''−40''', '''101''', 86, 85, 15, 89, 89, 28, '''−5''', 41} {{nb5}} (N = 20, mean = 101.5)
The 5th percentile (−6.75) lies between −40 and −5, while the 95th percentile (148.6) lies between 101 and 1053 (values shown in bold). Then, a 5% trimmed mean would result in the following:

:{92, 19, 101, 58, 91, 26, 78, 10, 13, 101, 86, 85, 15, 89, 89, 28, −5, 41} {{nb5}} (N = 18, mean = 56.5)
This example can be compared with the one using the [[Winsorising#Example|Winsorising]] procedure.

==See also==
*[[Trimean]]
*[[Interquartile mean]]

==References==
{{Reflist}}

{{DEFAULTSORT:Truncated Mean}}
[[Category:Means]]
[[Category:Robust statistics]]

[[de:Mittelwert#Winsorisiertes oder gestutztes Mittel]]</text>
      <sha1>gyg3gtp4bo9o4pr6qmtruo0mqj1kdft</sha1>
    </revision>
  </page>
  <page>
    <title>Truth-table reduction</title>
    <ns>0</ns>
    <id>2695407</id>
    <revision>
      <id>870307467</id>
      <parentid>786594501</parentid>
      <timestamp>2018-11-23T22:25:46Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Category:Reduction (complexity)]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2979">In [[computability theory]], a '''truth-table reduction''' is a [[reduction (complexity)|reduction]] from one set of [[natural number]]s to another. 
As a "tool", it is weaker than [[Turing reduction]], since not every Turing reduction between sets can be performed by a truth-table reduction, but every truth-table reduction can be performed by a Turing reduction. For the same reason it is said to be a stronger reducibility than Turing reducibility, because it implies Turing reducibility. A '''weak truth-table reduction''' is a related type of reduction which is so named because it weakens the constraints placed on a truth-table reduction, and provides a weaker equivalence classification; as such, a "weak truth-table reduction" can actually be more powerful than a truth-table reduction as a "tool", and perform a reduction which is not performable by truth table.

A Turing reduction from a set ''B'' to a set ''A'' computes the membership of a single element in ''B'' by asking questions about the membership of various elements in ''A'' during the computation; it may adaptively determine which questions it asks based upon answers to previous questions. In contrast, a truth-table reduction or a weak truth-table reduction must present all of its (finitely many) [[oracle (computer science)|oracle]] queries at the same time. In a truth-table reduction, the reduction also gives a [[boolean function]] (a truth table) which, when given the answers to the queries, will produce the final answer of the reduction. In a weak truth-table reduction, the reduction uses the oracle answers as a basis for further computation which may depend on the given answers but may not ask further questions of the oracle.

Equivalently, a weak truth-table reduction is a Turing reduction for which the [[Turing reduction#The use of a reduction|use]] of the reduction is bounded by a [[computable function]]. For this reason, they are sometimes referred to as '''bounded Turing''' (bT) reductions rather than as weak truth-table (wtt) reductions.

== Properties ==

As every truth-table reduction is a Turing reduction, if ''A'' is truth-table reducible to ''B'' (''A'' &amp;le;&lt;sub&gt;tt&lt;/sub&gt; ''B''), then ''A'' is also Turing reducible to ''B'' (''A'' &amp;le;&lt;sub&gt;T&lt;/sub&gt; ''B''). Considering also one-one reducibility, many-one reducibility and weak truth-table reducibility,
: &lt;math&gt;A \leq_1 B \Rightarrow A \leq_m B \Rightarrow A \leq_{tt} B \Rightarrow A \leq_{wtt} B \Rightarrow A \leq_T B&lt;/math&gt;,
or in other words, one-one reducibility implies many-one reducibility, which implies truth-table reducibility, which in turn implies weak truth-table reducibility, which in turn implies Turing reducibility.

== References ==

* [[Hartley Rogers, Jr.|H. Rogers, Jr.]], 1967. ''The Theory of Recursive Functions and Effective Computability'', second edition 1987, MIT Press. {{isbn|0-262-68052-1}} (paperback), {{isbn|0-07-053522-1}}

[[Category:Reduction (complexity)]]


{{mathlogic-stub}}</text>
      <sha1>ihdgn0uhvc7pak2kok5fn55pjzye3ta</sha1>
    </revision>
  </page>
  <page>
    <title>Verification condition generator</title>
    <ns>0</ns>
    <id>39811070</id>
    <revision>
      <id>798357988</id>
      <parentid>639857870</parentid>
      <timestamp>2017-09-01T12:42:15Z</timestamp>
      <contributor>
        <username>Cic</username>
        <id>1968383</id>
      </contributor>
      <comment>References header</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1456">{{Orphan|date=June 2013}}

A '''verification condition generator''' is a common sub-component of an automated [[program verifier]] that synthesizes formal verification conditions by analyzing a program's source code using a method based upon [[Hoare logic]]. VC generators may require that the source code contains logical annotations provided by the programmer or the compiler such as pre/post-conditions and loop invariants (a form of [[proof-carrying code]]). VC generators are often coupled with [[SMT solver]]s in the backend of a program verifier. After a verification condition generator has created the verification conditions they are passed to an [[automated theorem prover]], which can then formally prove the correctness of the code.

Methods have been proposed to use the [[operational semantics]] of machine languages to automatically generate verification condition generators.&lt;ref&gt;{{cite book | author1=John Matthews |author2= [[J. Strother Moore]]  |author3= Sandip Ray |author4= Daron Vroon | contribution=Verification Condition Generation Via Theorem Proving | editor1=Miki Hermann |editor2= [[Andrei Voronkov]] | title=Proc. Int. Conf. [[Logic for Programming, Artificial Intelligence, and Reasoning]] | publisher=Springer | series=LNCS | volume=4246 | pages=362-376 | year=2005 |contribution-url=http://www.cs.utexas.edu/~sandip/publications/symbolic-lpar/symbolic.pdf}}&lt;/ref&gt;

== References ==
{{reflist}}

[[Category:Formal methods]]</text>
      <sha1>nsqsaut7dfylishsfy7k6k7o7s116df</sha1>
    </revision>
  </page>
  <page>
    <title>Vincenty's formulae</title>
    <ns>0</ns>
    <id>18863206</id>
    <revision>
      <id>871338354</id>
      <parentid>871334416</parentid>
      <timestamp>2018-11-30T11:39:16Z</timestamp>
      <contributor>
        <username>Cffk</username>
        <id>4328267</id>
      </contributor>
      <comment>/* References */ Use en-dash where appropriate</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16783">{{for|the mathematical background to this problem|Geodesics on an ellipsoid}}
'''Vincenty's formulae''' are two related [[iterative method]]s used in [[geodesy]] to calculate the distance between two points on the surface of a spheroid, developed by [[Thaddeus Vincenty]] (1975a). They are based on the assumption that the [[figure of the Earth]] is an [[oblate spheroid]], and hence are more accurate than methods that assume a [[spherical]] Earth, such as [[great-circle distance]].

The first (direct) method computes the location of a point that is a given distance and [[azimuth]] (direction) from another point. The second (inverse) method computes the [[geographical distance]] and [[azimuth]] between two given points. They have been widely used in geodesy because they are accurate to within 0.5&amp;nbsp;mm (0.020″) on the [[Earth ellipsoid]].

== Background ==

[[Thaddeus Vincenty|Vincenty]]'s goal was to express existing algorithms for [[geodesics on an ellipsoid]] in a form that minimized the program length (see the first sentence of his paper). His unpublished report (1975b) mentions the use of a [[Wang Laboratories#Calculators|Wang]] 720 desk calculator, which had only a few kilobytes of memory. To obtain good accuracy for long lines, the solution uses the classical solution of Legendre (1806), Bessel (1825), and Helmert (1880) based on the auxiliary sphere. (Vincenty relied on formulation of this method given by Rainsford, 1955.) Legendre showed that an ellipsoidal geodesic can be exactly mapped to a great circle on the auxiliary sphere by mapping the geographic latitude to reduced latitude and setting the azimuth of the great circle equal to that of the geodesic. The longitude on the ellipsoid and the distance along the geodesic are then given in terms of the longitude on the sphere and the arc length along the great circle by simple integrals. Bessel and Helmert gave rapidly converging series for these integrals, which allow the geodesic to be computed with arbitrary accuracy.

In order to minimize the program size, Vincenty took these series, re-expanded them using the first term of each series as the small parameter, and truncated them to &lt;math&gt;O(f^3) &lt;/math&gt;. This resulted in compact expressions for the longitude and distance integrals. The expressions were put in [[Horner scheme|Horner]] (or ''nested'') form, since this allows polynomials to be evaluated using only a single temporary register. Finally, simple iterative techniques were used to solve the implicit equations in the direct and inverse methods; even though these are slow (and in the case of the inverse method it sometimes does
not converge), they result in the least increase in code size.

== Notation ==
Define the following notation:
{|
|-
| ''a'' || length of semi-[[major axis]] of the ellipsoid (radius at equator); || (6378137.0 metres in [[WGS-84]])
|-
| ''&amp;fnof;'' || [[flattening]] of the ellipsoid; || (1/298.257223563 in [[WGS-84]])
|-
| ''b'' = (1&amp;nbsp;−&amp;nbsp;''&amp;fnof;'')&amp;nbsp;''a''|| length of semi-[[minor axis]] of the ellipsoid (radius at the poles); || (6356752.314245 meters in [[WGS-84]])
|-
| ''Φ''&lt;sub&gt;1&lt;/sub&gt;, ''Φ''&lt;sub&gt;2&lt;/sub&gt; || [[latitude]] of the points;
|-
| ''U''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;arctan( (1&amp;nbsp;−&amp;nbsp;''ƒ'')&amp;nbsp;tan&amp;nbsp;''Φ''&lt;sub&gt;1&lt;/sub&gt; ), &lt;br/&gt; ''U''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;arctan( (1&amp;nbsp;−&amp;nbsp;''ƒ'') tan ''Φ''&lt;sub&gt;2&lt;/sub&gt; ) || [[Latitude#Reduced (or parametric) latitude|reduced latitude]] (latitude on the auxiliary sphere)
|-
| ''L'' = ''L''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;−&amp;nbsp;''L''&lt;sub&gt;1&lt;/sub&gt; || difference in [[longitude]] of two points;
|-
| ''λ''&lt;sub&gt;1&lt;/sub&gt;, ''λ''&lt;sub&gt;2&lt;/sub&gt; || longitude of the points on the auxiliary sphere;
|-
| ''α''&lt;sub&gt;1&lt;/sub&gt;, ''α''&lt;sub&gt;2&lt;/sub&gt; || forward [[azimuth]]s at the points;
|-
| ''α'' || [[azimuth]] at the equator;
|-
| ''s'' || ellipsoidal distance between the two points;
|-
| ''σ'' || arc length between points on the auxiliary sphere
|}

== Inverse problem==
Given the coordinates of the two points (''&amp;#934;''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''L''&lt;sub&gt;1&lt;/sub&gt;) and (''&amp;#934;''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;''L''&lt;sub&gt;2&lt;/sub&gt;), the inverse problem finds the azimuths ''α''&lt;sub&gt;1&lt;/sub&gt;, ''α''&lt;sub&gt;2&lt;/sub&gt; and the ellipsoidal distance ''s''.

Calculate ''U''&lt;sub&gt;1&lt;/sub&gt;, ''U''&lt;sub&gt;2&lt;/sub&gt; and ''L'', and set initial value of ''λ'' = ''L''. Then iteratively evaluate the following equations until ''λ'' converges:

::&lt;math&gt;\sin \sigma = \sqrt{ (\cos U_2 \sin \lambda)^2 + (\cos U_1 \sin U_2 - \sin U_1 \cos U_2 \cos \lambda)^2}&lt;/math&gt;

::&lt;math&gt;\cos \sigma = \sin U_1 \sin U_2 + \cos U_1 \cos U_2 \cos \lambda \,&lt;/math&gt;

::&lt;math&gt;\sigma = \arctan\frac{\sin\sigma}{\cos\sigma}\,&lt;/math&gt;&lt;ref&gt;''σ'' isn't evaluated directly from sin&amp;nbsp;''σ'' or cos&amp;nbsp;''σ'' to preserve numerical accuracy near the poles and equator&lt;/ref&gt;&lt;ref name="atan"&gt;The arctan quantity should be evaluated using a two argument [[atan2]] type function.&lt;/ref&gt;

::&lt;math&gt;\sin \alpha = \frac{\cos U_1 \cos U_2 \sin \lambda}{\sin \sigma} \,&lt;/math&gt;&lt;ref name="opposite"&gt;If sin ''&amp;sigma; = 0'' the value of sin ''α'' is indeterminate. It represents an end point equal to, or diametrically opposite the start point.&lt;/ref&gt;

::&lt;math&gt;\cos^2 \alpha = 1 - \sin^2 \alpha \,&lt;/math&gt;

::&lt;math&gt;\cos (2 \sigma_m) = \cos \sigma - \frac{2 \sin U_1\sin U_2}{\cos^2 \alpha} \,&lt;/math&gt;&lt;ref name="equator"&gt;The start and end point are on the equator. In this case, ''C = 0'' so the value of &lt;math&gt;\cos (2 \sigma_m) &lt;/math&gt; is not used. The limiting value is &lt;math&gt;\cos (2 \sigma_m) = -1&lt;/math&gt;.&lt;/ref&gt;

::&lt;math&gt;C = \frac{f}{16} \cos^2 \alpha \big[4 + f(4-3 \cos^2 \alpha) \big] \,&lt;/math&gt;

::&lt;math&gt;\lambda = L + (1-C) f \sin \alpha \left\{ \sigma + C \sin \sigma \left[\cos (2 \sigma_m) + C \cos \sigma (-1 + 2 \cos^2 (2 \sigma_m)) \right]\right\} \, &lt;/math&gt;

When ''λ'' has converged to the desired degree of accuracy (10&lt;sup&gt;−12&lt;/sup&gt; corresponds to approximately 0.06mm), evaluate the following:

:&lt;math&gt;u^2 = \cos^2 \alpha \left(\frac{a^2 - b^2}{b^2} \right)&lt;/math&gt;

:&lt;math&gt;A = 1 + \frac{u^2}{16384} \left\{ 4096 + u^2 \left[ -768 +u^2 (320 - 175u^2) \right] \right\}&lt;/math&gt;
 
:&lt;math&gt;B = \frac{u^2}{1024} \left\{ 256 + u^2 \left[ -128 + u^2 (74-47 u^2) \right] \right\} &lt;/math&gt;

:&lt;math&gt; \Delta \sigma = B \sin \sigma \Big\{ \cos(2 \sigma_m) + \tfrac{1}{4} B \big[ \cos \sigma \big(-1+2 \cos^2(2 \sigma_m) \big) - \tfrac{B}{6}  \cos(2 \sigma_m) (-3+4 \sin^2 \sigma) \big(-3+4 \cos^2 (2 \sigma_m)\big) \big] \Big\} &lt;/math&gt;

:&lt;math&gt; s = b A(\sigma - \Delta \sigma) \,&lt;/math&gt;

:&lt;math&gt; \alpha_1 = \arctan \left( \frac{\cos U_2 \sin \lambda}{\cos U_1 \sin U_2 - \sin U_1 \cos U_2 \cos \lambda} \right) &lt;/math&gt;&lt;ref name="atan"/&gt;

:&lt;math&gt; \alpha_2 = \arctan \left( \frac{\cos U_1 \sin \lambda}{-\sin U_1 \cos U_2 + \cos U_1 \sin U_2 \cos \lambda} \right) &lt;/math&gt;&lt;ref name="atan"/&gt;

Between two nearly antipodal points, the iterative formula may fail to converge; this will occur when the first guess at ''λ'' as computed by the equation above is greater than ''π'' in absolute value.

==Direct Problem==
Given an initial point (''&amp;#934;''&lt;sub&gt;1&lt;/sub&gt;, ''L''&lt;sub&gt;1&lt;/sub&gt;) and initial azimuth, ''α''&lt;sub&gt;1&lt;/sub&gt;, and a distance, ''s'', along the geodesic the problem is to find the end point (''&amp;#934;''&lt;sub&gt;2&lt;/sub&gt;, ''L''&lt;sub&gt;2&lt;/sub&gt;) and azimuth, ''α''&lt;sub&gt;2&lt;/sub&gt;.

Start by calculating the following:

:&lt;math&gt; U_1 = \arctan \left ((1 - f)\tan \phi_1 \right )\, &lt;/math&gt;

:&lt;math&gt; \sigma_1 = \arctan \left ( \frac{ \tan U_1}{ \cos \alpha_1} \right ) \, &lt;/math&gt;&lt;ref name="atan"/&gt;

:&lt;math&gt; \sin \alpha = \cos U_1 \sin \alpha_1 \, &lt;/math&gt;

:&lt;math&gt; \cos^2 \alpha = 1 - \sin^2 \alpha \, &lt;/math&gt;

:&lt;math&gt; u^2 = \cos^2 \alpha \left(\frac{a^2 - b^2}{b^2}\right) \, &lt;/math&gt;

:&lt;math&gt; A = 1 + \frac{u^2}{16384} \left\{ 4096 + u^2 \left[ -768 +u^2 (320 - 175u^2) \right] \right\} &lt;/math&gt;

:&lt;math&gt; B = \frac{u^2}{1024} \left\{ 256 + u^2 \left[ -128 + u^2 (74-47 u^2) \right] \right\} &lt;/math&gt;

Then, using an initial value &lt;math&gt; \sigma = \tfrac{s}{bA} &lt;/math&gt;, iterate the following equations until there is no significant change in ''σ'':

::&lt;math&gt; 2 \sigma_m = 2 \sigma_1 + \sigma \, &lt;/math&gt;

::&lt;math&gt; \Delta \sigma = B \sin \sigma \Big\{ \cos(2 \sigma_m) + \tfrac{1}{4} B \big[ \cos \sigma \big(-1+2 \cos^2(2 \sigma_m) \big) - \tfrac{B}{6} \cos(2 \sigma_m) (-3+4 \sin^2 \sigma) \big(-3+4 \cos^2 (2 \sigma_m)\big) \big] \Big\} &lt;/math&gt;

::&lt;math&gt; \sigma = \frac{s}{bA} + \Delta \sigma \, &lt;/math&gt;

Once ''σ'' is obtained to sufficient accuracy evaluate:

:&lt;math&gt; \phi_2 = \arctan \left( \frac{\sin U_1 \cos \sigma + \cos U_1 \sin \sigma \cos \alpha_1}{(1 - f) \sqrt{\sin^2 \alpha + (\sin U_1 \sin \sigma - \cos U_1 \cos \sigma \cos \alpha_1 )^2 } } \right) \, &lt;/math&gt;&lt;ref name="atan"/&gt;

:&lt;math&gt; \lambda = \arctan \left( \frac{\sin \sigma \sin \alpha_1}{\cos U_1 \cos \sigma - \sin U_1 \sin \sigma \cos \alpha_1} \right) \, &lt;/math&gt;&lt;ref name="atan"/&gt;

:&lt;math&gt; C = \frac{f}{16} \cos^2 \alpha \big[4 + f(4-3 \cos^2 \alpha) \big] \, &lt;/math&gt;

:&lt;math&gt; L = \lambda - (1-C) f \sin \alpha \left\{ \sigma + C \sin \sigma \left[\cos (2 \sigma_m) + C \cos \sigma (-1 + 2 \cos^2 (2 \sigma_m)) \right]\right\} \, &lt;/math&gt;

:&lt;math&gt; L_2 = L + L_1 \, &lt;/math&gt;

:&lt;math&gt; \alpha_2 = \arctan \left( \frac{\sin \alpha}{-\sin U_1 \sin \sigma + \cos U_1 \cos \sigma \cos \alpha_1} \right) \, &lt;/math&gt;&lt;ref name="atan"/&gt;

If the initial point is at the North or South pole, then the first equation is indeterminate.
If the initial azimuth is due East or West, then the second equation is indeterminate. 
If a double valued ''atan2'' type function is used, then these values are usually handled correctly.

==Vincenty's modification==

In his letter to Survey Review in 1976, Vincenty suggested replacing his series expressions for ''A'' and ''B'' with simpler formulas using Helmert's expansion parameter ''k''&lt;sub&gt;1&lt;/sub&gt;:

&lt;math&gt;A = \frac {1 + \frac {1}{4} (k_1)^2}{1 - k_1}&lt;/math&gt;

&lt;math&gt;B = k_1(1 - \tfrac {3}{8}(k_1)^2)&lt;/math&gt;

where{{pad|4em}}&lt;math&gt; k_1 = \frac { \sqrt {1 + u^2} - 1}{ \sqrt {1 + u^2} + 1}&lt;/math&gt;

==Nearly antipodal points==

As noted above, the iterative solution to the inverse problem fails to converge or converges slowly for nearly antipodal points. An example of slow convergence is (''&amp;#934;''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''L''&lt;sub&gt;1&lt;/sub&gt;) = (0°,&amp;nbsp;0°) and (''&amp;#934;''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;''L''&lt;sub&gt;2&lt;/sub&gt;) = (0.5°,&amp;nbsp;179.5°) for the WGS84 ellipsoid. This requires about 130 iterations to give a result accurate to 1&amp;nbsp;mm. Depending on how the inverse method is implemented, the algorithm might return the correct result (19936288.579&amp;nbsp;m), an incorrect result, or an error indicator. An example of an incorrect result is provided by the [http://www.ngs.noaa.gov/TOOLS/Inv_Fwd/Inv_Fwd.html NGS online utility], which returns a distance that is about 5&amp;nbsp;km too long. Vincenty suggested a method of accelerating the convergence in such cases (Rapp, 1973).

An example of a failure of the inverse method to converge is (''&amp;#934;''&lt;sub&gt;1&lt;/sub&gt;,&amp;nbsp;''L''&lt;sub&gt;1&lt;/sub&gt;) = (0°,&amp;nbsp;0°) and (''&amp;#934;''&lt;sub&gt;2&lt;/sub&gt;,&amp;nbsp;''L''&lt;sub&gt;2&lt;/sub&gt;) = (0.5°,&amp;nbsp;179.7°) for the WGS84 ellipsoid. In an unpublished report, Vincenty (1975b) gave an alternative iterative scheme to handle such cases. This converges to the correct result 19944127.421&amp;nbsp;m after about 60 iterations; however, in other cases many thousands of iterations are required.

[[Newton's method]] has been successfully used to give rapid convergence for all pairs of input points (Karney, 2013).

==See also==
*[[Geographical distance]]
*[[Great-circle distance]]
*[[Meridian arc]]
*[[Geodesics on an ellipsoid]]
*[[Thaddeus Vincenty]]
*[[Geodesy]]

==Notes==
{{reflist}}

==References==
* {{cite journal
 |first=Friedrich W. |last=Bessel |authorlink=Friedrich Bessel
 |title=The calculation of longitude and latitude from geodesic measurements (1825)
 |journal=Astron. Nachr.
 |year=2010
 |volume=331 |issue=8 |pages=852–861
 |doi=10.1002/asna.201011352
 |arxiv=0908.1824 |postscript=. English translation of Astron. Nachr. '''4''', 241&amp;ndash;254 (1825). 
|bibcode=2010AN....331..852K}}
* {{cite book
 |first=Friedrich R. |last=Helmert |authorlink=Friedrich Robert Helmert
 |title=Mathematical and Physical Theories of Higher Geodesy, Part 1 (1880)
 |publisher=Aeronautical Chart and Information Center
 |year=1964
 |location=St. Louis
 |url=https://geographiclib.sourceforge.io/geodesic-papers/helmert80-en.html
 |accessdate=2011-07-30
}}  English translation of ''Die Mathematischen und Physikalischen Theorieen der Höheren Geodäsie'', Vol. 1 (Teubner, Leipzig, 1880).
* {{Cite journal | ref = harv
 |last1=Karney |first1=Charles F. F.
 |doi=10.1007/s00190-012-0578-z
 |doi-access=free
 |title=Algorithms for geodesics
 |url=https://geographiclib.sourceforge.io/geod.html
 |journal=Journal of Geodesy
 |volume=87 |issue=1 |pages=43–55|date=January 2013
 |arxiv=1109.4448
 |bibcode=2013JGeod..87...43K
}} [https://geographiclib.sourceforge.io/geod-addenda.html Addenda].
* {{cite journal
 |first=Adrien-Marie |last=Legendre |authorlink=Adrien-Marie Legendre
 |title=Analyse des triangles tracės sur la surface d'un sphėroïde
 |journal=Mém. de l'Inst. Nat. de France
 |year=1806
 |issue=1st sem. |pages=130–161
 |url=https://books.google.com/books?id=-d0EAAAAQAAJ&amp;pg=PA130-IA4
 |accessdate=2011-07-30
}}
* {{Cite journal | ref = harv
 |last=Rainsford |first1=H. F.
 |doi=10.1007/BF02527187
 |title=Long geodesics on the ellipsoid
 |journal=Bulletin géodésique
 |volume=37 |pages=12–22 |year=1955
 |bibcode=1955BGeod..29...12R
}}
* {{cite techreport
 |first=Ricahrd H. |last=Rapp
 |title=Geometric Geodesy, Part II
 |institution=Ohio State University
 |date=March 1993
 |url=http://hdl.handle.net/1811/24409
 |accessdate=2011-08-01
}}
* {{cite journal
 |first=Thaddeus |last=Vincenty |authorlink=Thaddeus Vincenty
 |title=Direct and Inverse Solutions of Geodesics on the Ellipsoid with application of nested equations
 |journal=Survey Review
 |volume=XXIII &lt;!--Volume 23 was issues 175–182 (1975–1976), inclusive--&gt;
 |issue=176 |date=April 1975a |pages=88–93
 |doi=10.1179/sre.1975.23.176.88
 |url=http://www.ngs.noaa.gov/PUBS_LIB/inverse.pdf |accessdate=2009-07-11
 |quote=In selecting a formula for the solution of geodesics it is of primary importance to consider the length of the program, that is the amount of core which it will occupy in the computer along with trigonometric and other required functions.
}}
* {{cite techreport
 |first=Thaddeus |last=Vincenty |authorlink=Thaddeus Vincenty
 |title=Geodetic inverse solution between antipodal points
 |institution=DMAAC Geodetic Survey Squadron
 |date=August 1975b
 |url = https://geographiclib.sourceforge.io/geodesic-papers/vincenty75b.pdf
 |doi = 10.5281/zenodo.32999
}}
* {{cite journal
 |first=Thaddeus |last=Vincenty |authorlink=Thaddeus Vincenty
 |title=Correspondence
 |journal=Survey Review
 |volume=XXIII |issue=180 |date=April 1976 |pages=294
}}
* {{cite book
 |publisher=Intergovernmental committee on survey and mapping (ICSM) 
 |date=February 2006
 |isbn=0-9579951-0-5
 |title=Geocentric Datum of Australia (GDA) Reference Manual
 |url=http://www.icsm.gov.au/gda/gdatm/index.html
 |format=PDF
 |accessdate=2009-07-11
}}

==External links==
* Online calculators from [[Geoscience Australia]]:
** [http://www.ga.gov.au/geodesy/datums/vincenty_direct.jsp Vincenty Direct] (destination point)
** [http://www.ga.gov.au/geodesy/datums/vincenty_inverse.jsp Vincenty Inverse] (distance between points)
* Calculators from the [[U.S. National Geodetic Survey]]:
** [http://www.ngs.noaa.gov/TOOLS/Inv_Fwd/Inv_Fwd.html Online and downloadable PC-executable calculation utilities], including forward (direct) and inverse problems, in both two and three dimensions (accessed 2011-08-01).
* Online calculators with JavaScript source code by Chris Veness (Creative Commons Attribution license):
** [http://www.movable-type.co.uk/scripts/latlong-vincenty-direct.html Vincenty Direct] (destination point)
** [http://www.movable-type.co.uk/scripts/latlong-vincenty.html Vincenty Inverse] (distance between points)
* [https://geographiclib.sourceforge.io GeographicLib] provides a utility GeodSolve (with MIT/X11 licensed source code) for solving direct and inverse geodesic problems. Compared to Vincenty, this is about 1000 times more accurate (error = 15&amp;nbsp;nm) and the inverse solution is complete. Here is an [https://geographiclib.sourceforge.io/cgi-bin/GeodSolve online version of GeodSolve].
* [https://github.com/tdjastrzebski/VincentyExcel Excel Add-in] by Tomasz Jastrzębski - provides complete Vincenty's direct and inverse formulae implementation with source code.

{{DEFAULTSORT:Vincenty's Formulae}}
[[Category:Geodesy]]
[[Category:Articles with example pseudocode]]
[[Category:Distance]]</text>
      <sha1>254xaet4y0uolud5hjxbp9lu6vgvufh</sha1>
    </revision>
  </page>
  <page>
    <title>Weak inverse</title>
    <ns>0</ns>
    <id>22797782</id>
    <revision>
      <id>787027059</id>
      <parentid>784990951</parentid>
      <timestamp>2017-06-23T00:21:11Z</timestamp>
      <contributor>
        <username>Quondum</username>
        <id>12331483</id>
      </contributor>
      <comment>spelling</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2362">{{refimprove|date=September 2014}}
In [[mathematics]], the term '''weak inverse''' is used with several meanings.

== Theory of semigroups ==
In the theory of [[semigroup]]s, a weak inverse of an element ''x'' in a semigroup {{nowrap|(''S'', •)}} is an element ''y'' such that {{nowrap|1=''y'' • ''x'' • ''y'' = ''y''}}. If every element has a weak inverse, the semigroup is called an [[E-dense semigroup|''E''-inversive or ''E''-dense semigroup]]. An ''E''-inversive semigroup may equivalently be defined by requiring that for every element {{nowrap|''x'' ∈ ''S''}}, there exists {{nowrap|''y'' ∈ ''S''}} such that {{nowrap|''x'' • ''y''}} and {{nowrap|''y'' • ''x''}} are [[idempotent]]s.&lt;ref name="Gomes2002"&gt;{{cite book|editor=Gracinda M. S. Gomes|title=Semigroups, Algorithms, Automata and Languages|url=https://books.google.com/books?id=IL58mAsfXOgC&amp;pg=PA167|year=2002|publisher=World Scientific|isbn=978-981-277-688-4|pages=167–168|author=John Fountain|chapter=An introduction to covers for semigroups}} [http://www-users.york.ac.uk/~jbf1/coimbra2.pdf preprint]&lt;/ref&gt;

An element ''x'' of ''S'' for which there is an element ''y'' of ''S'' such that {{nowrap|1=''x'' • ''y'' • ''x'' = ''x''}} is called regular. A [[regular semigroup]] is a semigroup in which every element is regular. This is a stronger notion than weak inverse. Every ''E''-inversive semigroup is regular, but not vice versa.&lt;ref name="Gomes2002"/&gt;

If every element ''x'' in ''S'' has a unique inverse ''y'' in ''S'' in the sense that {{nowrap|1=''x'' • ''y'' • ''x'' = ''x''}} and {{nowrap|1=''y'' • ''x'' • ''y'' = ''y''}} then ''S'' is called an [[inverse semigroup]].

== Category theory ==
In [[category theory]], a weak inverse of an [[object (category theory)|object]] ''A'' in a [[monoidal category]] ''C'' with monoidal product ⊗ and unit object ''I'' is an object ''B'' such that both {{nowrap|''A'' ⊗ ''B''}} and {{nowrap|''B'' ⊗ ''A''}} are [[isomorphism|isomorphic]] to the unit object ''I'' of ''C''. A monoidal category in which every [[morphism]] is invertible and every object has a weak inverse is called a [[2-group]].

== See also ==
* [[Generalized inverse]]
* [[Von Neumann regular ring]]

== References ==
{{reflist}}

[[Category:Monoidal categories]]
[[Category:Semigroup theory]]


{{cattheory-stub}}
{{Abstract-algebra-stub}}</text>
      <sha1>l6midey75clb7hup5b8p66rx9767k6m</sha1>
    </revision>
  </page>
</mediawiki>
