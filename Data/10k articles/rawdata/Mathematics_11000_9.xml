<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>130 (number)</title>
    <ns>0</ns>
    <id>421596</id>
    <revision>
      <id>776381149</id>
      <parentid>776380899</parentid>
      <timestamp>2017-04-20T17:24:57Z</timestamp>
      <contributor>
        <ip>130.180.201.101</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1461">{{Infobox number
| number = 130
| divisor = 1, 2, 5, 10, 13, 26, 65, 130
}}

'''130''' ('''one hundred [and] thirty''') is the [[natural number]] following [[129 (number)|129]] and preceding [[131 (number)|131]].

==In mathematics==
130 is a [[sphenic number]]. It is a [[noncototient]] since there is no answer to the equation ''x'' - [[Euler's totient function|φ]](''x'') = 130.

130 is the only integer that is the sum of the squares of its first four divisors, including 1: 1&lt;sup&gt;2&lt;/sup&gt; + 2&lt;sup&gt;2&lt;/sup&gt; + 5&lt;sup&gt;2&lt;/sup&gt; + 10&lt;sup&gt;2&lt;/sup&gt; = 130.

130 is the largest number that cannot be written as the sum of four [[hexagonal number]]s.&lt;ref&gt;[http://mathworld.wolfram.com/HexagonalNumber.html MathWorld - Hexagonal Number]&lt;/ref&gt;

==In religion==
The [[Books of Chronicles|Second Book of Chronicles]] says that [[Jehoiada]] died at the age of 130.&lt;ref&gt;{{bibleverse|2|Chronicles|24:15|NIV}}&lt;/ref&gt;

==In other fields==
'''One hundred [and] thirty''' is also:
* The year [[130|AD130]] or [[130 BC]]
* The [[130 nanometer]] process is a semiconductor process technology by [[semiconductor]] companies
* A [[130-30 fund]] or a ratio up to 150/50 is a type of collective investment vehicle
* The [[C130 Hercules]] aircraft

==References==
&lt;references/&gt;

== See also ==
* [[List of highways numbered 130]]
* [[United Nations Security Council Resolution 130]]
* [[130 Liberty Street]], New York City

{{Integers|1}}

{{DEFAULTSORT:130 (Number)}}
[[Category:Integers]]</text>
      <sha1>sh5rxve4q2de32ac02bkgcf16kkkbzp</sha1>
    </revision>
  </page>
  <page>
    <title>207 (number)</title>
    <ns>0</ns>
    <id>6317347</id>
    <revision>
      <id>846457047</id>
      <parentid>846457019</parentid>
      <timestamp>2018-06-18T22:06:21Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: class, eprint. Removed parameters. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="825">{{Infobox number
| number = 207
| divisor = 1, 3, 9, 23, 69, 207
}}
'''207''' ('''two hundred [and] seven''') is the [[natural number]] following [[206 (number)|206]] and preceding [[208 (number)|208]].

It is a [[Wedderburn-Etherington number]].&lt;ref&gt;{{Cite OEIS|A001190|name=Wedderburn-Etherington numbers}}&lt;/ref&gt; There are exactly 207 different [[matchstick graph]]s with eight edges.&lt;ref&gt;{{Cite OEIS|A066951|name=Number of nonisomorphic connected graphs that can be drawn in the plane using n unit-length edges}}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv
 | last = Salvia | first = Raffaele
 | year = 2013
 | title = A catalog for matchstick graphs
 | eprint = 1303.5965| class = math.CO
 }}&lt;/ref&gt;

==See also==
*[[Peugeot 207]]

==References==
{{reflist}}
{{Integers|2}}

{{DEFAULTSORT:207 (Number)}}
[[Category:Integers]]


{{Number-stub}}</text>
      <sha1>paquf3cmqu76krp9czg1psopuhfkpd4</sha1>
    </revision>
  </page>
  <page>
    <title>Actor (UML)</title>
    <ns>0</ns>
    <id>426769</id>
    <revision>
      <id>862056470</id>
      <parentid>743623216</parentid>
      <timestamp>2018-10-01T21:47:48Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2482">[[Image:Use Case diagram V1.JPG|thumb|240px|UML [[use case diagram]] with two actors and several [[use case]]s.]]
An '''actor''' in the [[Unified Modeling Language]] (UML) "specifies a role played by a user or any other system that interacts with the subject."&lt;ref name="OMG UML V2.1.2"&gt;{{cite web| url= http://www.omg.org/spec/UML/2.1.2/Superstructure/PDF| title= OMG Unified Modeling Language (OMG UML), Superstructure, V2.1.2, pp. 586–588| accessdate= November 7, 2010| archiveurl= https://web.archive.org/web/20100923033721/http://www.omg.org/spec/UML/2.1.2/Superstructure/PDF| archivedate= 2010-09-23| deadurl= yes| df= }}&lt;/ref&gt;

"An Actor models a type of role played by an entity that interacts with the subject (e.g., by exchanging signals and data),
but which is external to the subject."&lt;ref name= "OMG UML V2.1.2"/&gt;

"Actors may represent roles played by human users, external hardware, or other subjects. Actors do not necessarily represent specific physical entities but merely particular facets (i.e., “roles”) of some entities that are relevant to the specification of its associated use cases. A single physical instance may play the role of several different actors and a given actor may be played by multiple different instances."&lt;ref name= "OMG UML V2.1.2"/&gt;

UML 2 does not permit associations between Actors.&lt;ref name= "OMG UML V2.1.2"/&gt;&lt;ref&gt;{{cite web |url=http://www.ifi.uzh.ch/rerg/fileadmin/downloads/publications/papers/IWSSD-10.pdf |title=Problems and Deficiencies of UML as a Requirements Specification, s.3.2. |accessdate=November 7, 2010| archiveurl= https://web.archive.org/web/20101017015344/http://www.ifi.uzh.ch/rerg/fileadmin/downloads/publications/papers/IWSSD-10.pdf| archivedate= 17 October 2010 &lt;!--DASHBot--&gt;| deadurl= no}}&lt;/ref&gt; The use of generalization/specialization relationship between actors is useful in modeling overlapping behaviours between actors and does not violate this constraint since a generalization relation is not a type of association.&lt;ref name="UML Specification"&gt;{{cite web |url=http://www.omg.org/spec/|title=UML 2 Specification |accessdate=July 4, 2012}}&lt;/ref&gt;

Actors interact with [[use case]]s.

==References== 
{{Reflist}}

==External links==
* [http://advanceduml.wordpress.com/2008/09/22/release-management Illustration of actors in UML]
* [http://www.uml-diagrams.org/use-case-diagrams.html#actor Actor in UML 2]

{{UML}}

{{DEFAULTSORT:Actor (Uml)}}
[[Category:Unified Modeling Language]]

{{uml-stub}}</text>
      <sha1>abcfapnq7uiw50bc6zh1mwgjnbtsdmv</sha1>
    </revision>
  </page>
  <page>
    <title>All-serial CORDIC</title>
    <ns>0</ns>
    <id>49022824</id>
    <redirect title="CORDIC" />
    <revision>
      <id>699006755</id>
      <parentid>698520913</parentid>
      <timestamp>2016-01-09T17:35:11Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="197">#redirect [[CORDIC#All-serial CORDIC]] {{R to related topic}}

[[Category:Numerical analysis]]
[[Category:Trigonometry]]
[[Category:Digit-by-digit algorithms]]
[[Category:Shift-and-add algorithms]]</text>
      <sha1>l3rlv48mvgcm9kbkxc01uv60qef7vh2</sha1>
    </revision>
  </page>
  <page>
    <title>Arithmetica Universalis</title>
    <ns>0</ns>
    <id>4806014</id>
    <revision>
      <id>781380650</id>
      <parentid>744862947</parentid>
      <timestamp>2017-05-20T21:59:23Z</timestamp>
      <contributor>
        <username>Bellerophon5685</username>
        <id>1258165</id>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2596">{{Use dmy dates|date=May 2012}}
{{Italic title}}
[[File:arithmetica.jpg|100px|thumb|&lt;center&gt;''Arithmetica'' Title page (1707)&lt;/center&gt;]]
[[File:UniversalArithmetick.gif|100px|thumb|&lt;center&gt;Raphson 's Eng. Tr. (1720)&lt;/center&gt;]]

'''''Arithmetica Universalis''''' ("Universal Arithmetic") is a [[mathematics]] text by [[Isaac Newton]]. Written in [[Latin language|Latin]], it was edited and published by [[William Whiston]], Newton's successor as [[Lucasian Professor of Mathematics]] at the University of Cambridge. The ''Arithmetica'' was based on Newton's lecture notes.

Whiston's original edition was published in 1707. It was translated into English by [[Joseph Raphson]], who published it in 1720 as the ''Universal Arithmetick''. [[John Machin]] published a second Latin edition in 1722.

None of these editions credits Newton as author; Newton was unhappy with the publication of the ''Arithmetica'', and so refused to have his name appear. In fact, when Whiston's edition was published, Newton was so upset he considered purchasing all of the copies so he could destroy them.

The ''Arithmetica'' touches on algebraic notation, arithmetic, the relationship between [[geometry]] and [[algebra]], and the solution of equations. Newton also applied [[René Descartes|Descartes]]' [[Descartes' rule of signs|rule of signs]] to [[imaginary numbers|imaginary]] roots. He also offered, without proof, a rule to determine the number of imaginary roots of polynomial equations. Not for another 150 years would a rigorous proof to Newton's counting formula be found (by [[James Joseph Sylvester]], published in 1865). &lt;!-- I think this is referring Sylvester's "On the real and imaginary roots of algebraical equations" trilogy- can anyone with access to it confirm that it's there, and cite it?--&gt;

==References==
*[http://www.babson.edu/about-babson/at-a-glance/babsons-history/archives-and-collections/Pages/grace-k--babson-collection.aspx The ''Arithmetica Universalis'' from the Grace K. Babson Collection, including links to PDFs of English and Latin versions of the ''Arithmetica'']
* [https://books.google.com/books?id=3_s2AAAAMAAJ ''Arithmetica Universalis''] (1720) Raphson Tr. @GoogleBooks
*[https://web.archive.org/web/20070927004805/http://www.centre.edu/web/library/Newton_two.pdf Centre College Library information on Newton's works]

{{wikiquote|Isaac Newton#Arithmetica Universalis (1707)}}
{{Isaac Newton}}

{{authoritycontrol}}
[[Category:1707 books]]
[[Category:1720 books]]
[[Category:Mathematics books]]
[[Category:Books by Isaac Newton]]
[[Category:18th-century Latin books]]</text>
      <sha1>7vmpx8k28h798djbq66c10maz5kdjc5</sha1>
    </revision>
  </page>
  <page>
    <title>Audrey Terras</title>
    <ns>0</ns>
    <id>23003425</id>
    <revision>
      <id>866071484</id>
      <parentid>863182830</parentid>
      <timestamp>2018-10-28T02:11:08Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 2 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8570">{{Infobox scientist
|name              = Audrey Terras
|image             =
|birth_date        = {{birth date and age|1942|9|10|mf=y}}
|birth_place       = [[Washington, D.C.]]
|death_date        =
|death_place       =
|residence         = [[San Diego, California]]
|citizenship       =
|nationality       =
|ethnicity         =
|fields            = [[Mathematics]]
|workplaces        = [[University of California San Diego]]
|alma_mater        = [[Yale University]]
|doctoral_advisor  = [[Tsuneo Tamagawa]]
|academic_advisors =
|doctoral_students =
|notable_students  =
|known_for         =
|influences        =
|influenced        =
|awards            = [[Fellow of the AAAS]]&lt;br&gt;[[Noether Lecturer]]&lt;br&gt;[[AWM/MAA Falconer Lecturer]]
|religion          =
}}
'''Audrey Anne Terras''' (born September 10, 1942) is an [[United States|American]] [[mathematician]] who works primarily in [[number theory]]. Her research has focused on [[quantum chaos]] and on various types of [[Riemann zeta function|zeta functions]].

==Life and education==
Audrey Terras was born September 10, 1942 in [[Washington, D.C.]]&lt;ref name=Bio2000&gt;
{{cite journal |date=September 2000 |title=Biographies of Candidates 2000 |journal=Notices of the American Mathematical Society |volume=47 |issue=8 |pages=922–934 |url=http://www.ams.org/notices/200008/bios00.pdf |accessdate=2009-05-24 }}&lt;/ref&gt;
She received a [[Bachelor of Science|BS]] degree in mathematics from the [[University of Maryland, College Park]] in 1964, and [[Master of Arts|MA]] and [[PhD]] degrees from [[Yale University]] in 1966 and 1970 respectively.&lt;ref name=AWM2000&gt;
{{cite web | title=2000 AWM-MAA Invited Address: Audrey Terras | url=http://www.awm-math.org/maalectures/terras2000.html | publisher=Association for Women in Mathematics | accessdate=2009-05-25}}&lt;/ref&gt;
She stated in a 2008 interview that she chose to study mathematics because "The U.S. government paid me! And not much! It was the time of Sputnik, so we needed to produce more mathematicians, and when I was deciding between Math and History, they weren’t paying me to do history, they were paying me to do math."&lt;ref name=MathClub&gt;{{cite web |title=Interview with Audrey Terras |url=http://math.ucsd.edu/programs/undergraduate/Math_Club_Newsletter.pdf |work=UCSD Math Club Newsletter |publisher=University of California, San Diego |pages=1, 3 |format=PDF |date=Fall 2008 |accessdate=2009-05-26 |archive-url=https://web.archive.org/web/20100621160402/http://www.math.ucsd.edu/programs/undergraduate/Math_Club_Newsletter.pdf |archive-date=2010-06-21 |dead-url=yes |df= }}&lt;/ref&gt;

==Career==
Terras joined the [[University of California San Diego]] as an assistant professor in 1972, and is now a full professor there.&lt;ref name=AWM2000 /&gt;

As an undergraduate Terras was inspired by her teacher [[Sigekatu Kuroda]] to become a [[number theorist]]; she was especially interested in the use of [[analytic number theory|analytic techniques]] to get algebraic results. Today her research interests are in [[number theory]], [[harmonic analysis]] on [[symmetric space]]s and [[finite group]]s, [[special function]]s, [[algebraic graph theory]], [[Riemann zeta function|zeta functions]] of [[Graph (discrete mathematics)|graphs]], arithmetical [[quantum chaos]], and the [[Selberg trace formula]].&lt;ref&gt;
{{cite web | title=Audrey Terras's Home Page | url=http://math.ucsd.edu/~aterras/ | publisher=University of California, San Diego | date=2009-03-29 | accessdate=2009-05-27}}
&lt;/ref&gt;

==Recognition==
Terras was elected a [[Fellow of the AAAS|Fellow of the American Association for the Advancement of Science]] in 1982.&lt;ref name=Bio2000 /&gt; She was the [[Association for Women in Mathematics]]-
[[Mathematical Association of America]] [[AWM/MAA Falconer Lecturer]] in 2000, speaking on "Finite Quantum Chaos,"&lt;ref name=FalconerTOC&gt;
{{cite web | title=AWM Falconer Lectures  | url=http://www.awm-math.org/falconerlectures.html | publisher=Association for Women in Mathematics | accessdate=2009-05-26| archiveurl= https://web.archive.org/web/20090617203332/http://www.awm-math.org/falconerlectures.html| archivedate= 17 June 2009 &lt;!--DASHBot--&gt;| deadurl= no}}
&lt;/ref&gt;
and the [[Association for Women in Mathematics|AWM]]'s [[Noether Lecturer]] in 2008, speaking on "Fun with Zeta Functions of Graphs".&lt;ref name=NoetherTOC&gt;
{{cite web | title=Emmy Noether Lectures  | url=http://www.awm-math.org/noetherbrochure/TOC.html | publisher=Association for Women in Mathematics | accessdate=2009-05-25| archiveurl= https://web.archive.org/web/20090426055805/http://www.awm-math.org/noetherbrochure/TOC.html| archivedate= 26 April 2009 &lt;!--DASHBot--&gt;| deadurl= no}}
&lt;/ref&gt; In 2012 she became a fellow of the [[American Mathematical Society]].&lt;ref&gt;[http://www.ams.org/profession/fellows-list List of Fellows of the American Mathematical Society], retrieved 2013-08-25.&lt;/ref&gt;
She is part of the 2019 class of fellows of the [[Association for Women in Mathematics]].&lt;ref&gt;{{citation|url=https://sites.google.com/site/awmmath/awm-fellows|title=2019 Class of AWM Fellows|publisher=[[Association for Women in Mathematics]]|accessdate=2018-10-07}}&lt;/ref&gt;

==Selected publications==
* {{cite book | last = Terras | first = Audrey | title = Harmonic Analysis on Symmetric Spaces and Applications |volume = 1| publisher = Springer-Verlag | location = Berlin | year = 1985 | isbn = 978-0-387-96159-0 }}&lt;ref name="HASSAreview"&gt;{{cite journal|author=Garrett, Paul B.|title=Review: ''Harmonic analysis on symmetric spaces and applications'', by Audrey Terras|journal=Bull. Amer. Math. Soc. (N.S.)|year=1990|volume=22|issue=1|pages=219–230|url=http://www.ams.org/journals/bull/1990-22-01/S0273-0979-1990-15884-7/S0273-0979-1990-15884-7.pdf|doi=10.1090/s0273-0979-1990-15884-7}}&lt;/ref&gt;
* {{cite book | last = Terras | first = Audrey | title = Harmonic Analysis on Symmetric Spaces and Applications |volume = 2 | publisher = Springer-Verlag | location = Berlin | year = 1988 | isbn = 978-0-387-96663-2 }}&lt;ref name=HASSAreview/&gt;
* {{cite book | last = Terras | first = Audrey | title = Fourier Analysis on Finite Groups and Applications | publisher = Cambridge University Press | location = Cambridge | year = 1999 | isbn = 978-0-521-45718-7 }}
* {{cite journal |last=Terras |first=Audrey|date=February 2002 |title=Finite Quantum Chaos |journal=American Mathematical Monthly |volume=109 |issue=2 |pages=121–139 |publisher=Mathematical Association of America |location=Washington, DC |issn=0002-9890 |doi= 10.2307/2695325 |jstor=2695325 }} Article based on her 2000 Falconer lecture.
* {{cite web |first=Audrey |last=Terras|title=A Stroll Through the Garden of Graph Zeta Functions |url=http://math.ucsd.edu/%7Eaterras/newbook.pdf |publisher=University of California, San Diego |format=PDF|date= 2007-03-20 |accessdate=2009-05-26 }} Draft of a book on zeta functions of graphs.

==Notes==
{{reflist}}

==Further reading==
* {{cite web |title=Interview with Audrey Terras |url=http://math.ucsd.edu/programs/undergraduate/Math_Club_Newsletter.pdf |work=UCSD Math Club Newsletter |publisher=University of California, San Diego |pages=1, 3 |format=PDF |date=Fall 2008 |accessdate=2009-05-26 |archive-url=https://web.archive.org/web/20100621160402/http://www.math.ucsd.edu/programs/undergraduate/Math_Club_Newsletter.pdf |archive-date=2010-06-21 |dead-url=yes |df= }} Interview conducted October 30, 2008.
* {{cite book |last1=Terras |first1=Audrey |editor1-first=Bettye Anne |editor1-last=Case |editor1-link=Bettye Anne Case |editor2-first=Anne M. |editor2-last=Leggett |editor2-link=Anne M. Leggett  |title=Complexities: Women in Mathematics |year=2005 |publisher=Princeton University Press |isbn=978-0-691-11462-0 |pages=218–220 |chapter=Rules for Academic Success }} Terras's "Five Simple Rules for (Academic) Success (or at Least Survival)."

==External links==
* {{MathGenealogy|id=14755}}
* [http://math.ucsd.edu/~aterras/ Terras's home page at UCSD]

{{Chaos theory}}
{{Authority control}}

{{DEFAULTSORT:Terras, Audrey}}
[[Category:20th-century American mathematicians]]
[[Category:21st-century American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Number theorists]]
[[Category:Fellows of the American Association for the Advancement of Science]]
[[Category:Fellows of the American Mathematical Society]]
[[Category:Fellows of the Association for Women in Mathematics]]
[[Category:University of Maryland, College Park alumni]]
[[Category:Yale University alumni]]
[[Category:University of California, San Diego faculty]]
[[Category:1942 births]]
[[Category:Living people]]</text>
      <sha1>f9tjpjed609ux63lsxi2tjkjb3rc5pr</sha1>
    </revision>
  </page>
  <page>
    <title>Average path length</title>
    <ns>0</ns>
    <id>8337647</id>
    <revision>
      <id>839919005</id>
      <parentid>812383336</parentid>
      <timestamp>2018-05-06T15:39:09Z</timestamp>
      <contributor>
        <username>Stef-the</username>
        <id>14397089</id>
      </contributor>
      <minor/>
      <comment>/* Applications */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3445">'''Average path length''' is a concept in [[network topology]] that is defined as the average number of steps along the shortest paths for all possible pairs of network [[Node (networking)|nodes]]. It is a measure of the efficiency of information or mass transport on a network.

__TOC__

==Concept==
Average path length is one of the three most robust measures of network topology, along with its [[clustering coefficient]] and its [[degree distribution]]. Some examples are: the average number of clicks which will lead you from one website to another, or the number of people you will have to communicate through, on an average, to contact a complete stranger. It should not be confused with the [[diameter]] of the network, which is defined as the longest [[geodesic]], i.e., the longest [[shortest path]] between any two nodes in the network (see [[Distance (graph theory)]]).

The average path length distinguishes an easily negotiable network from one, which is complicated and inefficient, with a shorter average path length being more desirable. However, the average path length is simply what the path length will most likely be. The network itself might have some very remotely connected nodes and many nodes, which are neighbors of each other.

==Definition==
Consider an unweighted directed [[Graph (discrete mathematics)|graph]] &lt;math&gt;G&lt;/math&gt; with the set of vertices &lt;math&gt;V&lt;/math&gt;. Let &lt;math&gt;d(v_1, v_2)&lt;/math&gt;, where &lt;math&gt;v_1, v_2 \in V&lt;/math&gt; denote the shortest distance between &lt;math&gt;v_1&lt;/math&gt; and &lt;math&gt;v_2&lt;/math&gt;.
Assume that &lt;math&gt;d(v_1, v_2) = 0&lt;/math&gt; if &lt;math&gt;v_2&lt;/math&gt; cannot be reached from &lt;math&gt;v_1&lt;/math&gt;. Then, the average path length &lt;math&gt;l_G&lt;/math&gt; is:

&lt;math&gt;l_G = \frac{1}{n \cdot (n - 1)} \cdot \sum_{i \ne j} d(v_i, v_j),&lt;/math&gt;

where &lt;math&gt;n&lt;/math&gt; is the number of vertices in &lt;math&gt;G&lt;/math&gt;.

==Applications==
In a real network like the [[Internet]], a short average path length facilitates the quick transfer of information and reduces costs. The efficiency of mass transfer in a [[Metabolic network modelling|metabolic network]] can be judged by studying its average path length. A [[power grid]] network will have fewer losses if its average path length is minimized.  

Most real networks have a very short average path length leading to the concept of a [[Watts and Strogatz model|small world]] where everyone is connected to everyone else through a very short path.

As a result, most models of real networks are created with this condition in mind. One of the first models which tried to explain real networks was the [[Erdős–Rényi model|random network model]]. It was later followed by the [[Watts and Strogatz model]], and even later there were the [[scale-free networks]] starting with the [[BA model]]. All these models had one thing in common: they all predicted very short average path length. The average path lengths of some networks are listed in Table.[1].&lt;ref name=bara&gt;Barabási, A.-L., and R. Albert, 2002, Rev. Mod. Phys. 74, 47.&lt;/ref&gt; &lt;br/&gt;
&lt;!-- Deleted image removed: [[Image:Comb0000.jpg|center|frame|]] --&gt;

The average path length depends on the system size but does not change drastically with it. Small world network theory predicts that the average path length changes proportionally to log n, where n is the number of nodes in the network.

==References==
&lt;references/&gt;

{{DEFAULTSORT:Average Path Length}}
[[Category:Network theory]]
[[Category:Graph invariants]]</text>
      <sha1>j06qpy1uocjvcpqn7jky3t9mcms59fy</sha1>
    </revision>
  </page>
  <page>
    <title>Berger's inequality for Einstein manifolds</title>
    <ns>0</ns>
    <id>13229336</id>
    <revision>
      <id>657307888</id>
      <parentid>607155540</parentid>
      <timestamp>2015-04-20T10:05:56Z</timestamp>
      <contributor>
        <username>K9re11</username>
        <id>19647483</id>
      </contributor>
      <comment>/* References */ stub template</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="833">In [[mathematics]] &amp;mdash; specifically, in [[differential topology]] &amp;mdash; '''Berger's inequality for Einstein manifolds''' is the statement that any 4-dimensional [[Einstein manifold]] (''M'',&amp;nbsp;''g'') has non-negative [[Euler characteristic]] ''&amp;chi;''(''M'')&amp;nbsp;≥&amp;nbsp;0. The inequality is named after the [[France|French]] [[mathematician]] [[Marcel Berger]].

==See also==
*[[Hitchin–Thorpe inequality]]

== References ==
*{{cite book | first = Arthur L. | last = Besse | title = Einstein Manifolds | series = Classics in Mathematics | publisher = Springer | location = Berlin | year = 1987 | isbn = 3-540-74120-8}}

[[Category:Riemannian manifolds|Einstein manifolds]]
[[Category:4-manifolds|Einstein manifolds]]
[[Category:Geometric inequalities]]
[[Category:Differential topology]]

{{differential-geometry-stub}}</text>
      <sha1>10n0f0ig6ffjmtviqdxrtmcb2aexdyy</sha1>
    </revision>
  </page>
  <page>
    <title>Binomial transform</title>
    <ns>0</ns>
    <id>3877474</id>
    <revision>
      <id>854793653</id>
      <parentid>844070874</parentid>
      <timestamp>2018-08-13T20:28:59Z</timestamp>
      <contributor>
        <ip>68.193.124.165</ip>
      </contributor>
      <comment>/* Ordinary generating function */ Fixed sign error in the definition of the generating function for the binomial transform: f \left(\frac{x}{1-x} ... |----&gt; f \left(\frac{-x}{1-x}.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8299">In [[combinatorics]], the '''binomial transform''' is a [[sequence transformation]] (i.e., a transform of a [[sequence]]) that computes its [[forward difference]]s. It is closely related to the '''Euler transform''', which is the result of applying the binomial transform to the sequence associated with its [[ordinary generating function]].

==Definition==
The '''binomial transform''', ''T'', of a sequence, {''a''&lt;sub&gt;''n''&lt;/sub&gt;}, is the sequence {''s''&lt;sub&gt;''n''&lt;/sub&gt;} defined by

:&lt;math&gt;s_n = \sum_{k=0}^n (-1)^k {n\choose k} a_k.&lt;/math&gt;

Formally, one may write 

:&lt;math&gt;s_n = (Ta)_n = \sum_{k=0}^\infty T_{nk} a_k&lt;/math&gt;

for the transformation, where ''T'' is an infinite-dimensional [[operator (mathematics)|operator]] with matrix elements ''T''&lt;sub&gt;''nk''&lt;/sub&gt;.
The transform is an [[involution (mathematics)|involution]], that is,

:&lt;math&gt;TT = 1 \,&lt;/math&gt;

or, using index notation,

:&lt;math&gt;\sum_{k=0}^\infty T_{nk}T_{km} = \delta_{nm}&lt;/math&gt;

where &lt;math&gt;\delta_{nm}&lt;/math&gt; is the [[Kronecker delta]]. The original series can be regained by

:&lt;math&gt;a_n=\sum_{k=0}^n (-1)^k {n\choose k} s_k.&lt;/math&gt;

The binomial transform of a sequence is just the ''n''th [[forward difference#n-th difference | forward differences]] of the sequence, with odd differences carrying a negative sign, namely:

:&lt;math&gt;s_0 = a_0&lt;/math&gt;
:&lt;math&gt;s_1 = - (\Delta a)_0 = -a_1+a_0&lt;/math&gt;
:&lt;math&gt;s_2 = (\Delta^2 a)_0 = -(-a_2+a_1)+(-a_1+a_0) = a_2-2a_1+a_0&lt;/math&gt;
:&lt;math&gt;\vdots\,&lt;/math&gt;
:&lt;math&gt;s_n = (-1)^n (\Delta^n a)_0&lt;/math&gt;

where Δ is the [[forward difference operator]].

Some authors define the binomial transform with an extra sign, so that it is not self-inverse:

:&lt;math&gt;t_n=\sum_{k=0}^n (-1)^{n-k} {n\choose k} a_k&lt;/math&gt;

whose inverse is

:&lt;math&gt;a_n=\sum_{k=0}^n {n\choose k} t_k.&lt;/math&gt;

In this case the former transform is called the ''inverse binomial transform'', and the latter is just ''binomial transform''. This is standard usage for example in [[On-Line Encyclopedia of Integer Sequences]].

==Example==

Binomial transforms can be seen in difference tables. Consider the following:

{| style=text-align:center
|-
| style="width:9%;"| 0 || style="width:9%;"| &amp;nbsp; || style="width:9%;"| 1 || style="width:9%;"| &amp;nbsp; || style="width:9%;"| 10 || style="width:9%;"| &amp;nbsp; || style="width:9%;"| 63 || style="width:9%;"| &amp;nbsp; || style="width:9%;"| 324 || style="width:9%;"| &amp;nbsp; || style="width:9%;"| 1485
|-
| &amp;nbsp; || 1 || &amp;nbsp; || 9 || &amp;nbsp; || 53 || &amp;nbsp; || 261 || &amp;nbsp; || 1161
|-
| &amp;nbsp; || &amp;nbsp; || 8 || &amp;nbsp; || 44 || &amp;nbsp; || 208 || &amp;nbsp; || 900
|-
| &amp;nbsp; || &amp;nbsp; || &amp;nbsp; || 36 || &amp;nbsp; || 164 || &amp;nbsp; || 692
|-
| &amp;nbsp; || &amp;nbsp; || &amp;nbsp; || &amp;nbsp; || 128 || &amp;nbsp; || 528
|-
| &amp;nbsp; || &amp;nbsp; || &amp;nbsp; || &amp;nbsp; || &amp;nbsp; || 400
|}

The top line 0, 1, 10, 63, 324, 1485,... (a sequence defined by (2''n''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''n'')3&lt;sup&gt;''n''&amp;nbsp;−&amp;nbsp;2&lt;/sup&gt;) is the (noninvolutive version of the) binomial transform of the diagonal 0, 1, 8, 36, 128, 400,... (a sequence defined by ''n''&lt;sup&gt;2&lt;/sup&gt;2&lt;sup&gt;''n''&amp;nbsp;−&amp;nbsp;1&lt;/sup&gt;).

==Ordinary generating function==
The transform connects the [[generating function]]s associated with the series.  For the [[ordinary generating function]], let

:&lt;math&gt;f(x)=\sum_{n=0}^\infty a_n x^n&lt;/math&gt;

and

:&lt;math&gt;g(x)=\sum_{n=0}^\infty s_n x^n &lt;/math&gt;

then

:&lt;math&gt;g(x) = (Tf)(x) = \frac{1}{1-x} f\left(\frac{-x}{1-x}\right).&lt;/math&gt;

==Euler transform==
The relationship between the ordinary generating functions is sometimes called the '''Euler transform'''. It commonly makes its appearance in one of two different ways. In one form, it is used to [[series acceleration|accelerate the convergence]] of an [[alternating series]].  That is, one has the identity

:&lt;math&gt;\sum_{n=0}^\infty (-1)^n a_n = \sum_{n=0}^\infty (-1)^n
\frac {\Delta^n a_0} {2^{n+1}}&lt;/math&gt;

which is obtained by substituting ''x''=1/2 into the last formula above. The terms on the right hand side typically become much smaller, much more rapidly, thus allowing rapid numerical summation.

The Euler transform can be generalized (Borisov B. and Shkodrov V., 2007):

:&lt;math&gt;\sum_{n=0}^\infty (-1)^n {n+p\choose n} a_n = \sum_{n=0}^\infty (-1)^n
{n+p\choose n}\frac {\Delta^n a_0} {2^{n+p+1}}&lt;/math&gt;,

where ''p'' = 0, 1, 2,...

The Euler transform is also frequently applied to the [[Euler hypergeometric integral]] &lt;math&gt;\,_2F_1&lt;/math&gt;.  Here, the Euler transform takes the form:

:&lt;math&gt;\,_2F_1 (a,b;c;z) = (1-z)^{-b} \,_2F_1 \left(c-a, b; c;\frac{z}{z-1}\right).&lt;/math&gt;

The binomial transform, and its variation as the Euler transform, is notable for its connection to the [[continued fraction]] representation of a number. Let &lt;math&gt;0 &lt; x &lt; 1&lt;/math&gt; have the continued fraction representation

:&lt;math&gt;x=[0;a_1, a_2, a_3,\cdots]&lt;/math&gt;

then

:&lt;math&gt;\frac{x}{1-x}=[0;a_1-1, a_2, a_3,\cdots]&lt;/math&gt;

and

:&lt;math&gt;\frac{x}{1+x}=[0;a_1+1, a_2, a_3,\cdots].&lt;/math&gt;

==Exponential generating function==
For the [[exponential generating function]], let

:&lt;math&gt;\overline{f}(x)= \sum_{n=0}^\infty a_n \frac{x^n}{n!}&lt;/math&gt;

and

:&lt;math&gt;\overline{g}(x)= \sum_{n=0}^\infty s_n \frac{x^n}{n!}&lt;/math&gt;

then

:&lt;math&gt;\overline{g}(x) = (T\overline{f})(x) = e^x \overline{f}(-x).&lt;/math&gt;

The [[Borel summation|Borel transform]] will convert the ordinary generating function to the exponential generating function.

==Integral representation==
When the sequence can be interpolated by a [[complex analytic]] function, then the binomial transform of the sequence can be represented by means of a [[Nörlund–Rice integral]] on the interpolating function.

==Generalizations==
Prodinger gives a related, [[modular form|modular-like]] transformation: letting

:&lt;math&gt;u_n = \sum_{k=0}^n {n\choose k} a^k (-c)^{n-k} b_k&lt;/math&gt;

gives

:&lt;math&gt;U(x) = \frac{1}{cx+1} B\left(\frac{ax}{cx+1}\right)&lt;/math&gt;

where ''U'' and ''B'' are the ordinary generating functions associated with the series &lt;math&gt;\{u_n\}&lt;/math&gt; and &lt;math&gt;\{b_n\}&lt;/math&gt;, respectively.

The rising ''k''-binomial transform is sometimes defined as

:&lt;math&gt;\sum_{j=0}^n {n\choose j} j^k a_j.&lt;/math&gt;

The falling ''k''-binomial transform is

:&lt;math&gt;\sum_{j=0}^n {n\choose j} j^{n-k} a_j&lt;/math&gt;.

Both are homomorphisms of the [[kernel (algebra)|kernel]] of the [[Hankel transform of a series]].

In the case where the binomial transform is defined as

:&lt;math&gt;\sum_{i=0}^n(-1)^{n-i}\binom{n}{i}a_i=b_n.&lt;/math&gt;

Let this be equal to the function &lt;math&gt;\mathfrak J(a)_n=b_n.&lt;/math&gt;

If a new [[forward difference]] table is made and the first elements from each row of this table are taken to form a new sequence &lt;math&gt;\{b_n\}&lt;/math&gt;, then the second binomial transform of the original sequence is,

:&lt;math&gt;\mathfrak J^2(a)_n=\sum_{i=0}^n(-2)^{n-i}\binom{n}{i}a_i.&lt;/math&gt;

If the same process is repeated ''k'' times, then it follows that,

:&lt;math&gt;\mathfrak J^k(a)_n=b_n=\sum_{i=0}^n(-k)^{n-i}\binom{n}{i}a_i.&lt;/math&gt;

Its inverse is,

:&lt;math&gt;\mathfrak J^{-k}(b)_n=a_n=\sum_{i=0}^nk^{n-i}\binom{n}{i}b_i.&lt;/math&gt;

This can be generalized as,

:&lt;math&gt;\mathfrak J^k(a)_n=b_n=(\mathbf E-k)^na_0&lt;/math&gt;

where &lt;math&gt;\mathbf E&lt;/math&gt; is the [[shift operator]].

Its inverse is

:&lt;math&gt;\mathfrak J^{-k}(b)_n=a_n=(\mathbf E+k)^nb_0.&lt;/math&gt;

==See also==
* [[Newton series]]
* [[Hankel matrix]]
* [[Möbius transform]]
* [[Stirling transform]]
* [[Euler summation]]
* [[List of factorial and binomial topics]]

==References==
* John H. Conway and Richard K. Guy, 1996, ''The Book of Numbers''
* Donald E. Knuth, ''[[The Art of Computer Programming]] Vol. 3'', (1973) Addison-Wesley, Reading, MA.
* Helmut Prodinger, 1992, ''[http://math.sun.ac.za/~prodinger/abstract/abs_87.htm Some information about the Binomial transform]''
* Michael Z. Spivey and Laura L. Steil, 2006, ''[http://www.cs.uwaterloo.ca/journals/JIS/VOL9/Spivey/spivey7.pdf The k-Binomial Transforms and the Hankel Transform]''
* Borisov B. and Shkodrov V., 2007, Divergent Series in the Generalized Binomial Transform, Adv. Stud. Cont. Math., 14 (1): 77-82
==External links==
*[http://mathworld.wolfram.com/BinomialTransform.html Binomial Transform]
*[https://oeis.org/transforms.html Transformations of Integer Sequences]

[[Category:Transforms]]
[[Category:Factorial and binomial topics]]
[[Category:Hypergeometric functions]]</text>
      <sha1>9boo1vrxen9j28196kpfv0iulq6m51e</sha1>
    </revision>
  </page>
  <page>
    <title>Björling problem</title>
    <ns>0</ns>
    <id>37039361</id>
    <revision>
      <id>641215876</id>
      <parentid>634999375</parentid>
      <timestamp>2015-01-06T09:33:51Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>Removed invisible unicode characters + other fixes, removed: ­ (2) using [[Project:AWB|AWB]] (10691)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2920">[[File:Catalan's Minimal Surface.png|thumb|Catalan's minimal surface. It can be defined as the minimal surface symmetrically passing through a cycloid.]]

In [[differential geometry]], the '''Björling problem''' is the problem of finding a [[minimal surface]] passing through a given curve with prescribed normal (or tangent planes). The problem was posed and solved by Swedish mathematician [[Emanuel Björling|Emanuel Gabriel Björling]],&lt;ref&gt;E.G. Björling, Arch. Grunert , IV (1844) pp. 290&lt;/ref&gt; with further refinement by [[Hermann Schwarz]].&lt;ref&gt;H.A. Schwarz, J. reine angew. Math. 80 280-300 1875&lt;/ref&gt;

The problem can be solved by extending the surface from the curve using complex [[analytic continuation]]. If &lt;math&gt;c(s)&lt;/math&gt; is a real analytic curve in ℝ&lt;sup&gt;3&lt;/sup&gt; defined over an interval ''I'', with &lt;math&gt;c'(s)\neq 0&lt;/math&gt; and a vector field &lt;math&gt;n(s)&lt;/math&gt; along ''c'' such that &lt;math&gt;||n(t)||=1&lt;/math&gt; and &lt;math&gt;c'(t)\cdot n(t)=0&lt;/math&gt;, then the following surface is minimal:

:&lt;math&gt;X(u,v) = \Re \left ( c(w) - i \int_{w_0}^w n(w) \wedge c'(w) \, dw \right)&lt;/math&gt;

where &lt;math&gt;w = u+iv \in \Omega&lt;/math&gt;, &lt;math&gt;u_0\in I&lt;/math&gt;, and &lt;math&gt;I \subset \Omega&lt;/math&gt; is a simply connected domain where the interval is included and the power series expansions of &lt;math&gt;c(s)&lt;/math&gt; and &lt;math&gt;n(s)&lt;/math&gt; are convergent.&lt;ref&gt;Kai-Wing Fung, Minimal Surfaces as Isotropic Curves in '''C'''&lt;sup&gt;3&lt;/sup&gt;: Associated minimal surfaces and the Björling's problem. MIT BA Thesis. 2004 http://ocw.mit.edu/courses/mathematics/18-994-seminar-in-geometry-fall-2004/projects/main1.pdf&lt;/ref&gt;

A classic example is [[Catalan's minimal surface]], which passes through a [[cycloid]] curve. Applying the method to a [[semicubical parabola]] produces the [[Henneberg surface]], and to a circle (with a suitably twisted normal field) a minimal [[Möbius strip]].&lt;ref&gt;{{cite journal |author=W.H. Meeks III |title=The classification of complete minimal surfaces in '''R'''&lt;sup&gt;3&lt;/sup&gt; with total curvature greater than &lt;math&gt;-8\pi&lt;/math&gt; |journal=Duke Math. J. |volume=48 |year=1981 |pages=523–535 |issue=3 |doi=10.1215/S0012-7094-81-04829-8 |mr=630583 |zbl=0472.53010}}&lt;/ref&gt;

A unique solution always exists. It can be viewed as a [[Cauchy problem]] for minimal surfaces, allowing one to find a surface if a geodesic, asymptote or lines of curvature is known. In particular, if the curve is planar and geodesic, then the plane of the curve will be a symmetry plane of the surface.&lt;ref&gt;Björling problem. Encyclopedia of Mathematics. URL: http://www.encyclopediaofmath.org/index.php?title=Bj%C3%B6rling_problem&amp;oldid=23196&lt;/ref&gt;

==References==

{{reflist|30em}}

==External image galleries==

* Björling Surfaces, at the Indiana Minimal Surface Archive: http://www.indiana.edu/~minimal/archive/Bjoerling/index.html

{{DEFAULTSORT:Bjorling problem}}
[[Category:Minimal surfaces]]
[[Category:Differential geometry]]</text>
      <sha1>59n49sogiffb1dn8vi98efalcwujow8</sha1>
    </revision>
  </page>
  <page>
    <title>Boolean ring</title>
    <ns>0</ns>
    <id>54356</id>
    <revision>
      <id>855978650</id>
      <parentid>828553804</parentid>
      <timestamp>2018-08-22T03:32:19Z</timestamp>
      <contributor>
        <username>A loose noose</username>
        <id>33384696</id>
      </contributor>
      <minor/>
      <comment>link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10735">In [[mathematics]], a '''Boolean ring''' ''R'' is a [[ring (mathematics)|ring]] for which ''x''&lt;sup&gt;2&lt;/sup&gt; = ''x'' for all ''x'' in ''R'',&lt;ref&gt;{{harvtxt|Fraleigh|1976|p=200}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Herstein|1975|p=130}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|McCoy|1968|p=46}}&lt;/ref&gt; such as the ring of [[modular arithmetic#Integers modulo n|integers modulo 2]].  That is, ''R'' consists only of [[idempotent element (ring theory)|idempotent element]]s.&lt;ref&gt;{{harvtxt|Fraleigh|1976|p=25}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Herstein|1975|p=268}}&lt;/ref&gt;

Every Boolean ring gives rise to a [[Boolean algebra (structure)|Boolean algebra]], with ring multiplication corresponding to [[logical conjunction|conjunction]] or [[meet (mathematics)|meet]] ∧, and ring addition to [[exclusive or|exclusive disjunction]] or [[symmetric difference]] ([http://math.stackexchange.com/questions/1621618/disjunction-as-sum-operation-in-boolean-ring ''not''] [[logical disjunction|disjunction]] ∨, which would constitute a [[semiring]]).  Boolean rings are named after the founder of Boolean algebra, [[George Boole]].

==Notations==
There are at least four different and incompatible systems of notation for Boolean rings and algebras. 
*In commutative algebra the standard notation is to use ''x''&amp;nbsp;+&amp;nbsp;''y'' = (''x''&amp;nbsp;∧&amp;nbsp;¬&amp;nbsp;''y'')&amp;nbsp;∨&amp;nbsp;(¬&amp;nbsp;''x''&amp;nbsp;∧&amp;nbsp;''y'') for the ring sum of ''x'' and ''y'', and use ''xy'' = ''x''&amp;nbsp;∧&amp;nbsp;''y'' for their product.
*In logic, a common notation is to use ''x''&amp;nbsp;∧&amp;nbsp;''y'' for the meet (same as the ring product) and use ''x''&amp;nbsp;∨&amp;nbsp;''y'' for the join, given in terms of ring notation (given just above) by ''x''&amp;nbsp;+&amp;nbsp;''y''&amp;nbsp;+&amp;nbsp;''xy''.
*In set theory and logic it is also common to use ''x''&amp;nbsp;·&amp;nbsp;''y'' for the meet, and ''x''&amp;nbsp;+&amp;nbsp;''y'' for the join ''x''&amp;nbsp;∨&amp;nbsp;''y''. This use of + is different from the use in ring theory.
*A rare convention is to use ''xy'' for the product and ''x''&amp;nbsp;⊕&amp;nbsp;''y'' for the ring sum, in an effort to avoid the ambiguity of +.

Historically, the term "Boolean ring" has been used to mean a "Boolean ring possibly without an identity", and "Boolean algebra" has been used to mean a Boolean ring with an identity.  The existence of the identity is necessary to consider the ring as an algebra over the [[GF(2)|field of two elements]]: otherwise there cannot be a (unital) ring homomorphism of the field of two elements into the Boolean ring. (This is the same as the old use of the terms "ring" and "algebra" in [[measure theory]].{{efn|When a Boolean ring has an identity, then a complement operation becomes definable on it, and a key characteristic of the modern definitions of both Boolean algebra and [[sigma-algebra]] is that they have complement operations.}})

==Examples==
One example of a Boolean ring is the [[power set]] of any set ''X'', where the addition in the ring is [[symmetric difference]], and the multiplication is [[intersection (set theory)|intersection]]. As another example, we can also consider the set of all [[finite set|finite]] or cofinite subsets of ''X'', again with symmetric difference and intersection as operations. More generally with these operations any [[field of sets]] is a Boolean ring. By [[Stone's representation theorem for Boolean algebras|Stone's representation theorem]] every Boolean ring is isomorphic to a field of sets (treated as a ring with these operations).

== Relation to Boolean algebras ==

[[File:Vennandornot.svg|center|500px|thumb|[[Venn diagram]]s for the Boolean operations of conjunction, disjunction, and complement]]
Since the join operation ∨ in a Boolean algebra is often written additively, it makes sense in this context to denote ring addition by ⊕, a symbol that is often used to denote [[exclusive or]].

Given a Boolean ring ''R'', for ''x'' and ''y'' in ''R'' we can define

:''x'' ∧ ''y'' = ''xy'',

:''x'' ∨ ''y'' = ''x'' ⊕ ''y'' ⊕ ''xy'',

:¬''x'' = 1 ⊕ ''x''.

These operations then satisfy all of the axioms for meets, joins, and complements in a [[Boolean algebra (structure)|Boolean algebra]]. Thus every Boolean ring becomes a Boolean algebra.  Similarly, every Boolean algebra becomes a Boolean ring thus:

:''xy'' = ''x'' ∧ ''y'',

:''x'' ⊕ ''y'' = (''x'' ∨ ''y'') ∧ ¬(''x'' ∧ ''y'').

If a Boolean ring is translated into a Boolean algebra in this way, and then the Boolean algebra is translated into a ring, the result is the original ring. The analogous result holds beginning with a Boolean algebra.

A map between two Boolean rings is a [[ring homomorphism]] [[if and only if]] it is a homomorphism of the corresponding Boolean algebras. Furthermore, a subset of a Boolean ring is a [[ring ideal]] (prime ring ideal, maximal ring ideal) if and only if it is an [[order ideal]] (prime order ideal, maximal order ideal) of the Boolean algebra. The [[quotient ring]] of a Boolean ring modulo a ring ideal corresponds to the factor algebra of the corresponding Boolean algebra modulo the corresponding order ideal.

== Properties of Boolean rings==

Every Boolean ring ''R'' satisfies ''x'' ⊕ ''x'' = 0 for all ''x'' in ''R'', because we know

:''x'' ⊕ ''x'' = (''x'' ⊕ ''x'')&lt;sup&gt;2&lt;/sup&gt; = ''x''&lt;sup&gt;2&lt;/sup&gt; ⊕ ''x''&lt;sup&gt;2&lt;/sup&gt; ⊕ ''x''&lt;sup&gt;2&lt;/sup&gt; ⊕ ''x''&lt;sup&gt;2&lt;/sup&gt; = ''x'' ⊕ ''x'' ⊕ ''x'' ⊕ ''x''

and since (''R'',⊕) is an abelian group, we can subtract ''x'' ⊕ ''x'' from both sides of this equation, which gives ''x'' ⊕ ''x'' = 0. A similar proof shows that every Boolean ring is [[commutative]]:

:''x'' ⊕ ''y'' = (''x'' ⊕ ''y'')&lt;sup&gt;2&lt;/sup&gt; = ''x''&lt;sup&gt;2&lt;/sup&gt; ⊕ ''xy'' ⊕ ''yx'' ⊕ ''y''&lt;sup&gt;2&lt;/sup&gt; = ''x'' ⊕ ''xy'' ⊕ ''yx'' ⊕ ''y''

and this yields ''xy'' ⊕ ''yx'' = 0, which means ''xy''  = ''yx'' (using the first property above).

The property ''x'' ⊕ ''x'' = 0 shows that any Boolean ring is an [[associative algebra]] over the [[field (mathematics)|field]] '''F'''&lt;sub&gt;2&lt;/sub&gt; with two elements, in just one way. In particular, any finite Boolean ring has as [[cardinality]] a [[power of two]]. Not every associative algebra with one over '''F'''&lt;sub&gt;2&lt;/sub&gt; is a Boolean ring: consider for instance the [[polynomial ring]] '''F'''&lt;sub&gt;2&lt;/sub&gt;[''X''].

The quotient ring ''R''/''I'' of any Boolean ring ''R'' modulo any ideal ''I'' is again a Boolean ring. Likewise, any [[subring]] of a Boolean ring is a Boolean ring.

Any [[localization_of_a_ring|localization]] &lt;math&gt;RS^{-1}&lt;/math&gt; of a Boolean ring ''R'' by a set &lt;math&gt;S\subseteq R&lt;/math&gt; is a Boolean ring, since every element in the localization is idempotent.

The maximal ring of quotients &lt;math&gt;Q(R)&lt;/math&gt; (in the sense of Utumi and Lambek) of a Boolean ring ''R'' is a Boolean ring, since every partial endomorphism is idempotent&lt;ref&gt;{{cite journal|last1=B. Brainerd, J. Lambek|title=On the ring of quotients of a Boolean ring|journal=[[Canadian Mathematical Bulletin]] |date=1959|volume=2|page=25-29}} Corollary 2.&lt;/ref&gt;.

Every [[prime ideal]] ''P'' in a Boolean ring ''R'' is [[maximal ideal|maximal]]: the [[quotient ring]] ''R''/''P'' is an [[integral domain]] and also a Boolean ring, so it is isomorphic to the [[field (mathematics)|field]] '''F'''&lt;sub&gt;2&lt;/sub&gt;, which shows the maximality of ''P''. Since maximal ideals are always prime,  prime ideals and maximal ideals coincide in Boolean rings.

Boolean rings are [[von Neumann regular ring]]s.

Boolean rings are absolutely flat: this means that every module over them is [[flat module|flat]].

Every finitely generated ideal of a Boolean ring is [[principal ideal|principal]] (indeed, ''(x,y)=(x+y+xy)'').

== Unification ==
[[Unification (logic)|Unification]] in Boolean rings is [[Decidability (logic)|decidable]],&lt;ref&gt;{{cite book|author1=Martin, U. |author2=Nipkow, T. | chapter=Unification in Boolean Rings| title=Proc. 8th CADE| year=1986| volume=230| pages=506–513| publisher=Springer| editor=Jörg H. Siekmann| series=LNCS}}&lt;/ref&gt; that is, algorithms exist to solve arbitrary equations over Boolean rings. Both unification and matching in [[finitely generated algebra|finitely generated]] free Boolean rings are [[NP-complete]], and [[NP-hard]] in [[finitely presented algebra|finitely presented]] Boolean rings.&lt;ref&gt;Kandri-Rody, A., Kapur, D., and Narendran, P., "An ideal-theoretic approach to word problems and unification problems over finitely presented commutative algebras", ''Proc. of the first Conference on Rewriting Techniques and Applications, Dijon, France, May 1985'', LNCS 202, Springer Verlag, 345-364.&lt;/ref&gt; (In fact, as any unification problem ''f''(''X'') = ''g''(''X'') in a Boolean ring can be rewritten as the matching problem ''f''(''X'') + ''g''(''X'') = 0, the problems are equivalent.)

Unification in Boolean rings is unitary if all the uninterpreted function symbols are nullary and finitary otherwise (i.e. if the function symbols not occurring in the signature of Boolean rings are all constants then there exists a [[most general unifier]], and otherwise the [[Unification (computer science)#Unification problem, solution set|minimal complete set of unifiers]] is finite).&lt;ref&gt;{{cite journal| author=A. Boudet| author2=J.-P. Jouannaud| author2-link=J.-P. Jouannaud| author3=M. Schmidt-Schauß| title=Unification of Boolean Rings and Abelian Groups| journal=[[Journal of Symbolic Computation]] | year=1989| volume=8| pages=449–477 |url=http://www.sciencedirect.com/science/article/pii/S0747717189800549/pdf?md5=713ed362e4b6f2db53923cc5ed47c818&amp;pid=1-s2.0-S0747717189800549-main.pdf| doi=10.1016/s0747-7171(89)80054-9}}&lt;/ref&gt;

== See also ==
* [[Ring-sum normal form]]

== Notes ==
{{notelist}}

==References==
{{Reflist}}

==Further reading==
*{{Citation | last1=Atiyah | first1=Michael Francis | authorlink1=Michael Atiyah | last2=Macdonald | first2=I. G. | authorlink2=Ian G. Macdonald | title=Introduction to Commutative Algebra | publisher=Westview Press | isbn=978-0-201-40751-8 | year=1969}}
*{{citation | first = John B. | last = Fraleigh | year = 1976 | isbn = 0-201-01984-1 | title = A First Course In Abstract Algebra | edition = 2nd | publisher = [[Addison-Wesley]]  }}
*{{citation | first = I. N. | last = Herstein | authorlink= Israel Nathan Herstein | year = 1975 | title = Topics In Algebra | edition= 2nd | publisher = [[John Wiley &amp; Sons]] }}
*{{citation | first=Neal H. |last=McCoy |year=1968 |title=Introduction To Modern Algebra | edition = Revised |publisher=[[Allyn and Bacon]] |lccn=68015225}}
*{{springerEOM |id=Boolean_ring |oldid=18972 |first=Yu. M. |last=Ryabukhin}}

== External links ==
*John Armstrong, [http://unapologetic.wordpress.com/2010/08/04/boolean-rings Boolean Rings]

[[Category:Ring theory]]
[[Category:Boolean algebra]]</text>
      <sha1>movnts1l2ml1603xmf7lxku58re0ynf</sha1>
    </revision>
  </page>
  <page>
    <title>Breath gas analysis</title>
    <ns>0</ns>
    <id>31211209</id>
    <revision>
      <id>822450798</id>
      <parentid>811546710</parentid>
      <timestamp>2018-01-26T13:00:14Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8579">'''Breath gas analysis''' is a method for gaining non-invasive information on the clinical state of an individual by monitoring [[volatile organic compound]]s present in the exhaled [[breath]]. Breath gas concentration can then be related to [[blood]] concentrations via [[mathematical modeling]] as for example in [[blood alcohol]] testing.

==History==

The area of modern breath testing commenced in 1971, when [[Nobel Prize]] winner [[Linus Pauling]] demonstrated that human breath is a complex gas, containing more than 200 different volatile organic compounds. However, physicians have used breath analysis since the days of [[Hippocrates]].&lt;ref&gt;Anil S. Modak:  ''Single time point diagnostic breath tests: a review'', J. Breath Res. 4 (2010), 017002 [https://dx.doi.org/10.1088/1752-7155/4/1/017002]&lt;/ref&gt;

==Overview==

[[Endogenous]] volatile organic compounds (VOCs) are released within the human organism as a result of normal [[metabolism|metabolic]] activity or due to pathological disorders. They enter the blood stream and are eventually metabolized or excreted via [[exhalation]], [[skin]] emission, [[urine]], etc.

Breath sampling is non-invasive and breath samples can be extracted as often as desired.&lt;ref&gt;H. Koc, K. Unterkofler, S. Teschl, and J. King: "Mathematical modeling for breath gas analysis," 3. Forschungsforum der Österreichischen Fachhochschulen, Wien 2011. [http://www.esi.ac.at/~susanne/FFOeFH2011_KUTK.pdf]{{dead link|date=November 2016 |bot=InternetArchiveBot |fix-attempted=yes }}&lt;/ref&gt;

Identification and quantification of potential disease [[biomarker]]s can be seen as the driving force for the analysis of exhaled breath. Moreover, future applications for medical diagnosis and therapy control with dynamic assessments of normal physiological function or pharmacodynamics  are intended.

[[Exogenous]] VOCs penetrating the body as a result of  environmental exposure can be used to quantify body burden. Also breath tests are often based on the ingestion of  isotopically labeled precursors, producing isotopically labeled [[carbon dioxide]] and potentially many other metabolites.

However, breath sampling is far from being a standardized procedure due to the numerous confounding factors biasing the concentrations of volatiles in breath. These factors are related to both the breath sampling protocols as well as the complex physiological mechanisms underlying [[pulmonary gas exchange]]. Even under resting conditions exhaled breath concentrations of VOCs can strongly be influenced by specific physiological parameters such as cardiac output and breathing patterns, depending on the physico-chemical properties of the compound under study.

Understanding the influence of all this factors and their control is necessary for achieving an accurate standardization of breath sample collection and for the correct deduction of the corresponding blood concentration levels.

The simplest model relating breath gas concentration to blood concentrations was developed by Farhi&lt;ref&gt;Leon E. Farhi: ''Elimination of inert gas by the lung,'' Respiration Physiology 3 (1967) 1–11 [https://dx.doi.org/10.1016/0034-5687(67)90018-7]&lt;/ref&gt;
: &lt;math&gt;
C_A = \frac{C_{\bar v}}{\lambda_\text{b:air} + \dot V_A/\dot Q_c},
 &lt;/math&gt;
where &lt;math&gt; C_A &lt;/math&gt; denotes the alveolar concentration which is assumed to be equal to the measured concentration.
It expresses the fact that the concentration of an inert gas in the alveolar air depends on the mixed venous concentration  &lt;math&gt;C_{\bar v} &lt;/math&gt;, the substance-specific blood:air [[partition coefficient]] &lt;math&gt;\lambda_\text{b:air} &lt;/math&gt;, and the [[ventilation-perfusion ratio]]  &lt;math&gt;\dot V_A/\dot Q_c &lt;/math&gt;.
But this model fails when two prototypical substances like [[acetone]] (partition coefficient  &lt;math&gt;\lambda_\text{b:air} = 340 &lt;/math&gt;) or [[isoprene]] (partition coefficient  &lt;math&gt;\lambda_\text{b:air} = 0.75  &lt;/math&gt; ) are measured.&lt;ref&gt;Julian King, Alexander Kupferthaler, [[Karl Unterkofler]], Helin Koc, Susanne Teschl, [[Gerald Teschl]], Wolfram Miekisch, Jochen Schubert, Hartmann Hinterhuber, and [[Anton Amann]]: ''Isoprene and acetone concentration profiles during exercise at an ergometer'', J. Breath Research 3, (2009) 027006 (16 pp) [http://iopscience.iop.org/1752-7163/3/2/027006]&lt;/ref&gt;

E.g., multiplying the proposed population mean of approximately &lt;math&gt; 1 \mu g/l &lt;/math&gt; acetone  in end-tidal breath by the partition coefficient &lt;math&gt;\lambda_\text{b:air} = 340 &lt;/math&gt; at body temperature  grossly underestimates observed (arterial) blood levels spreading around  &lt;math&gt; 1 mg/l &lt;/math&gt;. Furthermore, breath profiles of acetone (and other highly soluble volatile compounds such as 2-pentanone or methyl acetate) associated with moderate workload ergometer challenges of normal healthy volunteers drastically depart from the trend suggested by the equation above.

Hence some more refined models are necessary. Such models have been developed recently.&lt;ref&gt;Julian King, Helin Koc,  Karl Unterkofler, Pawel Mochalski, Alexander Kupferthaler, Gerald Teschl, Susanne Teschl, Hartmann Hinterhuber, and Anton Amann: ''Physiological modeling of isoprene dynamics in exhaled breath,''  J. Theoret. Biol.  267  (2010), 626–637, [https://arxiv.org/abs/1010.2145]&lt;/ref&gt;&lt;ref&gt;Julian King, Karl Unterkofler, Gerald Teschl, Susanne Teschl, Helin Koc, Hartmann Hinterhuber, and Anton Amann: ''A mathematical model for breath gas analysis of volatile organic compounds with special emphasis on acetone,'' J. Math. Biol. 63 (2011),  959-999, [https://dx.doi.org/10.1007/s00285-010-0398-9]&lt;/ref&gt;

==Applications==

Breath gas analysis is used in a number of [[breath test]]s.

* [[Asthma]] detection by [[exhaled nitric oxide]]
* [[Blood alcohol]] testing&lt;ref&gt;Michael P. Hlastala: [http://www.mphlastala.com/abtreview.pdf ''The alcohol breath test—a review''], Journal of Applied Physiology (1998) vol. 84 no. 2, 401–408.&lt;/ref&gt;
* [[Lung cancer]] detection&lt;ref&gt;"[https://www.newscientist.com/channel/tech/mg19926715.200-nasas-electronic-nose-could-sniff-out-cancer.html NASA's electronic nose could sniff out cancer]", [[New Scientist]], 27 Aug. 2008.&lt;/ref&gt;
* [[Diabetes]] detection
* Fructose malabsorption with [[hydrogen breath test]]
* [[Helicobacter pylori]] with [[urea breath test]]
* [[Halitosis#Diagnosis|Diagnosis of bad breath]]
* Organ rejection
* Carbon Monoxide poisoning 
* Smoking cessation
* Measurement of endogenous metabolic processes&lt;ref&gt;Heaney LM et al. [https://doi.org/10.4155/bio-2016-0045 Real-time monitoring of exhaled volatiles using atmospheric pressure chemical ionization on a compact mass spectrometer]. Bioanalysis 2016;8(13):1325-1336.&lt;/ref&gt;
* Monitoring uptake of disinfection by-products following swimming&lt;ref&gt;Heaney LM &amp; Lindley MR. [https://doi.org/10.1007/s11306-017-1266-z Translation of exhaled breath volatile analyses to sport and exercise applications]. Metabolomics 2017;13(11):139.&lt;/ref&gt;

==Breath collectors==

Breath can be collected using a variety of home-made and commercially available devices.  The three basic types of breath collector for VOC analysis are:

* Coated stainless steel canister
* End tidal air collector
* Tedlar bag

Each of these can be used as a vehicle for direct introduction of a gas sample into an appropriate analytical instrument, or serve as a reservoir of breath gas into which an absorption device such as an SPME fiber is placed to collect specific compounds.

==Analytical instruments==

Breath analysis can be done with various forms of mass spectrometry, but there are also simpler methods for specific purposes, such as the [[Halimeter]] and the [[breathalyzer]].

* Gas chromatography-mass spectrometry [[GC-MS]]
* Gas chromatography-UV spectrometry [[GC-UV]]
* Proton transfer reaction mass spectrometry [[PTR-MS]] and [[Time-of-flight mass spectrometry|PTR-TOF]]
* Selected ion flow tube mass spectrometry [[SIFT-MS]]
* Ion mobility spectrometry [[Ion mobility spectrometry|IMS]]
* Fourier transform infrared spectroscopy [[FTIR]]
* Laser spectrometry [[Spectroscopy]]
* [[Chemical sensors]] resp. [[Electronic nose]]

==References==
{{reflist}}

==External links==
*[https://web.archive.org/web/20110818055652/http://iabr.voc-research.at/ International Association for Breath Research (IABR)]
*[http://iopscience.iop.org/1752-7163/ Journal of Breath Research]
*[http://www.breath-analysis.net Computational Breath Analysis project]

{{DEFAULTSORT:Breath Gas Analysis}}
[[Category:Breath tests]]
[[Category:Mathematical and theoretical biology]]
[[Category:Mathematical modeling]]</text>
      <sha1>gc5bx5v6e76ft82zprlk3uq5zrhwmjt</sha1>
    </revision>
  </page>
  <page>
    <title>Butcher group</title>
    <ns>0</ns>
    <id>23338010</id>
    <revision>
      <id>869207060</id>
      <parentid>859282064</parentid>
      <timestamp>2018-11-17T02:39:01Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: isbn. Add: url, doi, pages, volume, issue, citeseerx. Removed parameters. Formatted [[WP:ENDASH|dashes]]. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24942">In [[mathematics]],  the '''Butcher group''', named after the New Zealand mathematician [[John C. Butcher]] by {{harvtxt|Hairer|Wanner|1974}}, is an infinite-dimensional  [[Lie group]]&lt;ref name=":0"&gt;{{harvnb|Bogfjellmo|Schmeding|2015}}&lt;/ref&gt; first introduced in [[numerical analysis]] to study solutions of non-linear [[ordinary differential equation]]s by the [[Runge&amp;ndash;Kutta method]]. It arose from an algebraic formalism involving [[rooted tree]]s that provides [[formal power series]] solutions of the differential equation modeling the flow of a [[vector field]]. It was {{harvtxt|Cayley|1857}}, prompted by the work of [[James Joseph Sylvester|Sylvester]] on change of variables in [[differential calculus]], who first noted that the [[Faà di Bruno's formula|derivatives of a composition of functions]] can be conveniently expressed in terms of rooted trees and their combinatorics.

{{harvtxt|Connes|Kreimer|1999}} pointed out that the Butcher group is the group of characters of the [[Hopf algebra]] of rooted trees that had arisen independently in their own work on [[renormalization]] in [[quantum field theory]] and [[Alain Connes|Connes]]' work with [[Henri Moscovici|Moscovici]] on local [[index theorem]]s. This Hopf algebra, often called the ''Connes-Kreimer algebra'', is essentially equivalent to the Butcher group, since its dual can be identified with the [[universal enveloping algebra]] of the [[Lie algebra]] of the Butcher group.&lt;ref&gt;{{harvnb|Brouder|2004}}&lt;/ref&gt; As they commented:
{{cquote|We regard Butcher’s work on the classification of numerical integration methods as an impressive example that concrete problem-oriented work can lead to far-reaching conceptual results.}}

==Differentials and rooted trees==
[[File:Caylrich-first-trees.png|thumb|250px|right|Rooted trees with two, three and four nodes, from Cayley's original article]]
A rooted tree is a [[graph theory|graph]] with a distinguished node, called the ''root'', in which every other node is connected to the root by a unique path.  If the root of a tree '''t''' is removed and the nodes connected to the original node by a single bond are taken as new roots, the tree '''t''' breaks up into rooted trees '''t'''&lt;sub&gt;1&lt;/sub&gt;, '''t'''&lt;sub&gt;2&lt;/sub&gt;, ... Reversing this process a new tree '''t''' = ['''t'''&lt;sub&gt;1&lt;/sub&gt;, '''t'''&lt;sub&gt;2&lt;/sub&gt;, ...] can be constructed by joining the roots of the trees to a new common root. The number of nodes in a tree is denoted by |'''t'''|. A ''heap-ordering'' of a rooted tree '''t''' is an allocation of the numbers 1 through |'''t'''| to the nodes so that the numbers increase on any path going away from the root. Two heap orderings are ''equivalent'', if there is an [[automorphism]] of rooted trees mapping one of them on the other. The number of [[equivalence class]]es of heap-orderings on a particular tree is denoted by α('''t''') and can be computed using the Butcher's formula:&lt;ref name="Butcher2008"&gt;{{harvnb|Butcher|2008}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Brouder|2000}}&lt;/ref&gt;

:&lt;math&gt;\displaystyle \alpha(t)= {|t|!\over t! |S_t|},&lt;/math&gt;

where ''S''&lt;sub&gt;'''t'''&lt;/sub&gt; denotes the [[symmetry group]] of '''t''' and the tree factorial is defined recursively by
 
:&lt;math&gt;[t_1,\dots,t_n]! = |[t_1,\dots,t_n]| \cdot t_1! \cdots t_n!&lt;/math&gt;

with the tree factorial of an isolated root defined to be 1

:&lt;math&gt;\bullet ! =1.&lt;/math&gt;

The ordinary differential equation for the flow of a [[vector field]] on an open subset ''U'' of '''R'''&lt;sup&gt;N&lt;/sup&gt; can be written

:&lt;math&gt;\displaystyle {dx(s)\over ds} = f(x(s)),\,\, x(0)=x_0, &lt;/math&gt;

where ''x''(''s'') takes values in ''U'', ''f'' is a smooth function from ''U'' to  '''R'''&lt;sup&gt;N&lt;/sup&gt; and ''x''&lt;sub&gt;0&lt;/sub&gt; is the starting point of the flow at time ''s'' = 0.

{{harvtxt|Cayley|1857}} gave a method to compute the higher order derivatives ''x''&lt;sup&gt;(''m'')&lt;/sup&gt;(''s'') in terms of rooted trees. His formula can be conveniently expressed using the ''elementary differentials'' introduced by Butcher. These are defined inductively by

:&lt;math&gt; \delta_\bullet^i= f^i, \,\,\, \delta^i_{[t_1,\dots,t_n]} = \sum_{j_1,\dots,j_n=1}^N (\delta^{j_1}_{t_1} \cdots \delta^{j_n}_{t_n})\partial_{j_1} \cdots \partial_{j_n} f^i.&lt;/math&gt;

With this notation

:&lt;math&gt; {d^m x\over ds^m} = \sum_{|t|=m} \alpha(t) \delta_t,&lt;/math&gt;

giving the power series expansion

:&lt;math&gt;\displaystyle x(s) = x_0 + \sum_{t}  {s^{|t|}\over |t|!} \alpha(t) \delta_t(0).&lt;/math&gt;

As an example when ''N'' = 1, so that ''x'' and ''f'' are real-valued functions of a single real variable, the formula yields

:&lt;math&gt; x^{(4)} = f^{\prime\prime\prime}f^3  + 3 f^{\prime\prime}f^{\prime} f^2 + f^{\prime}f^{\prime\prime} f^2 +(f^\prime)^3 f,&lt;/math&gt;

where the four terms correspond to the four rooted trees from left to right in Figure 3 above.

In a single variable this formula is the same as [[Faà di Bruno's formula]] of 1855; however in several variables it has to be written more carefully in the form

:&lt;math&gt; x^{(4)} = f^{\prime\prime\prime}(f,f,f)  + 3f^{\prime\prime}(f,f^\prime(f))   +   f^\prime(f^{\prime\prime}(f,f))            +f^\prime(f^\prime(f^\prime(f))),&lt;/math&gt;

where the tree structure is crucial.

==Definition using Hopf algebra of rooted trees==
The [[Hopf algebra]] '''H''' of rooted trees was defined by {{harvtxt|Connes|Kreimer|1998}} in connection with [[Dirk Kreimer|Kreimer]]'s previous work on [[renormalization]] in [[quantum field theory]]. It was later discovered that the Hopf algebra was the dual of a Hopf algebra defined earlier by {{harvtxt|Grossman|Larsen|1989}} in a different context. The characters of '''H''', i.e. the homomorphisms of the underlying commutative algebra into '''R''', form a group, called the '''Butcher group'''. It corresponds to the [[formal group]] structure discovered in [[numerical analysis]] by {{harvtxt|Butcher|1972}}.

The '''Hopf algebra of rooted trees''' '''H''' is defined to be the [[polynomial ring]] in the variables '''t''', where '''t''' runs through rooted trees.

*Its [[comultiplication]] &lt;math&gt; \Delta:H\rightarrow H \otimes H&lt;/math&gt; is defined by

:&lt;math&gt;\Delta(t) = t\otimes I + I \otimes t +\sum_{s\subset t} s\otimes [t\backslash s],&lt;/math&gt;

where the sum is over all proper rooted subtrees '''s''' of '''t'''; &lt;math&gt;[t\backslash s]&lt;/math&gt; is the monomial given by the product the variables '''t'''&lt;sub&gt;i&lt;/sub&gt; formed by the rooted trees that arise on erasing all the nodes of '''s''' and connected links from '''t'''. The number of such trees is denoted by ''n''('''t'''\'''s''').

*Its [[counit]] is the homomorphism ε of '''H''' into '''R''' sending each variable '''t''' to zero.
*Its [[antipode (algebra)|antipode]] ''S'' can be defined recursively by the formula

:&lt;math&gt; S(t) = -t - \sum_{s \subset t}(-1)^{n(t\backslash s)}S([t\backslash s])s, \,\,\, S(\bullet)= -\bullet.&lt;/math&gt;

The '''Butcher group''' is defined to be the set of algebra homomorphisms φ of '''H''' into '''R''' with group structure

:&lt;math&gt;\varphi_1 \star \varphi_2 (t)= (\varphi_1\otimes \varphi_2)\Delta(t).&lt;/math&gt;

The inverse in the Butcher group is given by

:&lt;math&gt;\varphi^{-1}(t)=\varphi(St)&lt;/math&gt;

and the identity by the counit ε.

Using complex coefficients in the construction of the Hopf algebra of rooted trees one obtains the complex Hopf algebra of rooted trees.
Its '''C'''-valued characters form a group, called the '''complex Butcher group G&lt;sub&gt;C&lt;/sub&gt;'''. The complex Butcher group '''G'''&lt;sub&gt;'''C'''&lt;/sub&gt; is an infinite-dimensional complex Lie group&lt;ref name=":0" /&gt; which appears as a toy model in the {{section link||Renormalization}} of quantum field theories.

==Butcher series and Runge&amp;ndash;Kutta method==
The non-linear ordinary differential equation

:&lt;math&gt; {dx(s)\over ds} = f(x(s)),\,\,\, x(0)=x_0,&lt;/math&gt;

can be solved approximately by the [[Runge-Kutta method]]. This iterative scheme requires an ''m'' x ''m'' matrix

:&lt;math&gt;A=(a_{ij})&lt;/math&gt;

and a vector

:&lt;math&gt;b=(b_i)&lt;/math&gt;

with ''m'' components.

The scheme defines vectors ''x''&lt;sub&gt;''n''&lt;/sub&gt; by first finding a solution ''X''&lt;sub&gt;1&lt;/sub&gt;, ... , ''X''&lt;sub&gt;''m''&lt;/sub&gt; of

:&lt;math&gt; X_i= x_{n-1} + h \sum_{j=1}^m a_{ij} f(X_j)&lt;/math&gt;

and then setting

:&lt;math&gt;x_n=x_{n-1} +h \sum_{j=1}^m b_j f(x_j).&lt;/math&gt;

{{harvtxt|Butcher|1963}} showed that the solution of the corresponding ordinary differential equations

:&lt;math&gt; X_i(s)=x_0 + s\sum_{j=1}^m a_{ij} f(X_j(s)),\,\,\, x(s)=x_0 + s \sum_{j=1}^m b_jf(X_j(s))&lt;/math&gt;

has the power series expansion

:&lt;math&gt; X_i(s) = x_0 +\sum_t {s^{|t|}\over |t|!} \alpha(t) t! \sum_{j=1}^m a_{ij} \varphi_j(t)\delta_t(0),\,\,\,\,x(s) = x_0 +
\sum_t {s^{|t|}\over |t|!} \alpha(t) t! \varphi(t)\delta_t(0), &lt;/math&gt;

where φ&lt;sub&gt;''j''&lt;/sub&gt; and φ are determined recursively by

:&lt;math&gt;\varphi_j(\bullet)=1.\,\,\, \varphi_i([t_1,\cdots,t_k])=\sum_{j_1,\dots,j_k} a_{ij_1}\dots a_{ij_k} \varphi_{j_1}(t_1)\dots \varphi_{j_k}(t_k)&lt;/math&gt;

and

:&lt;math&gt;\varphi(t) = \sum_{j=1}^m b_j \varphi_j(t).&lt;/math&gt;

The power series above are called '''B-series''' or '''Butcher series'''.&lt;ref name="Butcher2008" /&gt;&lt;ref&gt;{{citation|title=The use of Butcher series in the analysis of Newton-like iterations in Runge-Kutta formulas|journal=Applied Numerical Mathematics|volume=15 |year=1994|pages=341–356| first=K. R.|last= Jackson|first2=A. |last2=Kværnø|first3=S.P.|last3=Nørsett|doi=10.1016/0168-9274(94)00031-X|issue=3|citeseerx=10.1.1.42.8612}} (Special issue to honor professor J. C. Butcher on his sixtieth birthday)&lt;/ref&gt; The corresponding assignment φ is an element of the Butcher group. The homomorphism corresponding to the actual flow has

:&lt;math&gt; \Phi(t)={1\over t!}.&lt;/math&gt;

Butcher showed that the Runge-Kutta method gives an ''n''th order approximation of the actual flow provided that φ and Φ agree on all trees with ''n'' nodes or less. Moreover, {{harvtxt|Butcher|1972}} showed that the homomorphisms defined by the Runge-Kutta method form a dense subgroup of the Butcher group: in fact he showed that, given a homomorphism  φ', there is a Runge-Kutta homomorphism φ agreeing with φ' to order ''n''; and that if given homomorphims φ and φ' corresponding to Runge-Kutta data (''A'', ''b'') and (''A' '', ''b' ''), the product homomorphism &lt;math&gt;\varphi\star \varphi^\prime&lt;/math&gt; corresponds to the data

:&lt;math&gt; \begin{pmatrix} A &amp; 0\\ 0 &amp; A^\prime\\ \end{pmatrix},\,\, (b,b^\prime).&lt;/math&gt;

{{harvtxt|Hairer|Wanner|1974}} proved that the Butcher group acts naturally on the functions ''f''. Indeed, setting

:&lt;math&gt;\varphi\circ f= 1 +\sum_t {s^{|t|}\over |t|!} \alpha(t) t! \varphi(t)\delta_t(0),&lt;/math&gt;

they proved that

:&lt;math&gt; \varphi_1\circ (\varphi_2\circ f) = (\varphi_1\star \varphi_2)\circ f.&lt;/math&gt;

==Lie algebra==
{{harvtxt|Connes|Kreimer|1998}} showed that associated with the Butcher group '''G''' is an infinite-dimensional Lie algebra. The existence of this Lie algebra is predicted by a [[Milnor–Moore theorem|theorem]] of {{harvtxt|Milnor|Moore|1965}}: the commutativity and natural grading on '''H''' implies that the graded dual '''H'''* can be identified with the [[universal enveloping algebra]] of a Lie algebra &lt;math&gt;\mathfrak{g}&lt;/math&gt;. Connes and Kreimer explicitly identify &lt;math&gt;\mathfrak{g}&lt;/math&gt; with a space of [[derivation (abstract algebra)|derivation]]s  θ of '''H''' into '''R''', i.e. linear maps such that

:&lt;math&gt;\theta(ab)=\varepsilon(a)\theta(b) + \theta(a)\varepsilon(b),&lt;/math&gt;

the formal tangent space of '''G''' at the identity ε. This forms a Lie algebra with Lie bracket

:&lt;math&gt;[\theta_1,\theta_2](t)=(\theta_1 \otimes \theta_2 -\theta_2\otimes\theta_1)\Delta(t).&lt;/math&gt;

&lt;math&gt;\mathfrak{g}&lt;/math&gt; is generated by the derivations θ&lt;sub&gt;'''t'''&lt;/sub&gt; defined by

:&lt;math&gt;\theta_t(t^\prime)=\delta_{tt^\prime}, &lt;/math&gt;

for each rooted tree '''t'''.

The infinite-dimensional Lie algebra &lt;math&gt;\mathfrak{g}&lt;/math&gt; from {{harvtxt|Connes|Kreimer|1998}} and the Lie algebra '''L(G)''' of the Butcher group as an infinite-dimensional Lie group are not the same. The Lie algebra '''L(G)''' can be identified with the Lie algebra of all derivations in the dual of '''H''' (i.e. the space of all linear maps from  '''H''' to '''R'''), whereas &lt;math&gt;\mathfrak{g}&lt;/math&gt; is obtained from the graded dual. Hence &lt;math&gt;\mathfrak{g}&lt;/math&gt; turns out to be a (strictly smaller) Lie subalgebra of '''L(G)'''.&lt;ref name=":0" /&gt;

==Renormalization==
{{harvtxt|Connes|Kreimer|1998}} provided a general context for using [[Hopf algebra]]ic methods to give a simple mathematical formulation of [[renormalization]] in [[quantum field theory]]. Renormalization was interpreted as [[Riemann–Hilbert problem|Birkhoff factorization]] of loops in the character group of the associated Hopf algebra.  The models considered by {{harvtxt|Kreimer|1999}} had Hopf algebra '''H''' and character group '''G''', the Butcher group. {{harvtxt|Brouder|2000}} has given an account of this renormalization process in terms of Runge-Kutta data.

In this simplified setting, a ''renormalizable model'' has two pieces of input data:&lt;ref&gt;{{harvnb|Kreimer|2007}}&lt;/ref&gt;
 
* a set of ''Feynman rules'' given by an algebra homomorphism Φ of '''H''' into the algebra ''V'' of [[Laurent series]] in ''z'' with poles of finite order;
* a ''renormalization scheme'' given by a linear operator ''R''  on ''V'' such that ''R'' satisfies the [[Rota-Baxter algebra|Rota-Baxter identity]]
::&lt;math&gt;R(fg) + R(f)R(g) = R(fR(g)) + R(R(f)g)&lt;/math&gt;
:and the image of ''R'' – ''id'' lies in the algebra ''V''&lt;sub&gt;+&lt;/sub&gt; of [[power series]] in ''z''.

Note that ''R'' satisfies the Rota-Baxter identity if and only if ''id'' –  ''R'' does. An important example is the ''[[minimal subtraction scheme]]''

:&lt;math&gt;\displaystyle R(\sum_{n} a_n z^n )= \sum_{n&lt; 0} a_n z^n.&lt;/math&gt;

In addition there is a projection ''P'' of '''H''' onto the [[augmentation ideal]] ker ε given by

:&lt;math&gt;\displaystyle P(x) = x -\varepsilon(x)1.&lt;/math&gt;

To define the renormalized Feynman rules, note that the antipode ''S'' satisfies

:&lt;math&gt; m\circ (S\otimes {\rm id}) \Delta (x) =\varepsilon(x)1&lt;/math&gt;

so that

:&lt;math&gt;S = - m\circ (S\otimes P)\Delta,&lt;/math&gt;

The ''renormalized Feynman rules'' are given by a homomorphism &lt;math&gt;\Phi_S^R&lt;/math&gt; of '''H''' into ''V'' obtained by twisting the homomorphism Φ • S. The homomorphism &lt;math&gt;\Phi_S^R&lt;/math&gt; is uniquely specified by

:&lt;math&gt;\Phi_S^R = -m(S\otimes \Phi_S^R\circ P)\Delta.&lt;/math&gt;

Because of the precise form of Δ, this gives a recursive formula for &lt;math&gt;\Phi_S^R&lt;/math&gt;.

For the minimal subtraction scheme, this process can be interpreted in terms of Birkhoff factorization in the complex Butcher group. Φ can be regarded as a map γ of the unit circle into the complexification '''G'''&lt;sub&gt;'''C'''&lt;/sub&gt; of '''G''' (maps into '''C''' instead of '''R'''). As such it has a Birkhoff factorization

:&lt;math&gt; \displaystyle \gamma(z)=\gamma_-(z)^{-1} \gamma_+(z),&lt;/math&gt;

where  γ&lt;sub&gt;+&lt;/sub&gt; is [[Holomorphic function|holomorphic]] on the interior of the closed unit disk and γ&lt;sub&gt;–&lt;/sub&gt; is holomorphic on its complement in the [[Riemann sphere]] '''C''' &lt;math&gt;\cup\{\infty\}&lt;/math&gt; with γ&lt;sub&gt;–&lt;/sub&gt;(∞) = 1. The loop γ&lt;sub&gt;+&lt;/sub&gt; corresponds to the renormalized homomorphism. The evaluation at ''z'' =  0 of γ&lt;sub&gt;+&lt;/sub&gt; or the renormalized homomorphism gives the ''dimensionally regularized'' values for each rooted tree.

In example, the Feynman rules depend on additional parameter μ, a "unit of mass". {{harvtxt|Connes|Kreimer|2001}} showed that

:&lt;math&gt;\partial_\mu \gamma_{\mu-} =0,&lt;/math&gt;

so that γ&lt;sub&gt;μ–&lt;/sub&gt; is independent of μ.

The complex Butcher group comes with a natural one-parameter group λ&lt;sub&gt;''w''&lt;/sub&gt; of automorphisms, dual to that on '''H'''

:&lt;math&gt;\lambda_{w}(t)= w^{|t|}t&lt;/math&gt;

for ''w'' ≠ 0 in '''C'''.

The loops γ&lt;sub&gt;μ&lt;/sub&gt; and λ&lt;sub&gt;''w''&lt;/sub&gt; · γ&lt;sub&gt;μ&lt;/sub&gt; have the same negative part and, for ''t'' real,

:&lt;math&gt;\displaystyle F_t=\lim_{z=0} \gamma_-(z) \lambda_{tz}(\gamma_-(z)^{-1})&lt;/math&gt;

defines a one-parameter subgroup of the complex Butcher group '''G'''&lt;sub&gt;'''C'''&lt;/sub&gt; called the [[renormalization group| renormalization group flow]] (RG).

Its infinitesimal generator β is an element of the Lie algebra of '''G'''&lt;sub&gt;'''C'''&lt;/sub&gt; and is defined by

:&lt;math&gt;\beta=\partial_t F_t|_{t=0}.&lt;/math&gt;

It is called the [[beta-function]] of the model.

In any given model, there is usually a finite-dimensional space of complex coupling constants. The complex Butcher group acts by diffeomorphims on this space. In particular the renormalization group defines a flow on the space of coupling constants, with the beta function giving the corresponding vector field.

More general models in quantum field theory require rooted trees to be replaced by [[Feynman diagram]]s with vertices decorated by symbols from a finite index set. Connes and Kreimer have also defined Hopf algebras in this setting and have shown how they can be used to systematize standard computations in renormalization theory.

==Example==
{{harvtxt|Kreimer|2007}} has given a "toy model" involving [[dimensional regularization]] for '''H''' and the algebra ''V''. If ''c'' is a positive integer and ''q''&lt;sub&gt;μ&lt;/sub&gt; = ''q'' / μ is a dimensionless constant, Feynman rules can be defined recursively by

:&lt;math&gt;\displaystyle \Phi([t_1,\dots, t_n])=\int {\Phi(t_1)\cdots \Phi(t_n) \over |y|^2 + q_\mu^2} (|y|^2)^{-z({c\over 2} -1)} \, d^D y,&lt;/math&gt;

where ''z'' = 1 – ''D''/2 is the regularization parameter. These integrals can be computed explicitly in terms of the [[Gamma function]] using the formula

:&lt;math&gt;\displaystyle \int  {(|y|^2)^{-u}\over |y|^2 +q_\mu^2} \, d^Dy =  \pi^{D/2} (q_\mu^2)^{-z-u} {\Gamma(-u +D/2)\Gamma(1+u-D/2)\over \Gamma(D/2)}.&lt;/math&gt;

In particular

:&lt;math&gt;\displaystyle \Phi(\bullet)=\pi^{D/2}(q_\mu^2)^{-zc/2}{\Gamma(1+cz)\over cz}.&lt;/math&gt;

Taking the renormalization scheme ''R'' of minimal subtraction, the renormalized quantities &lt;math&gt;\Phi_S^R(t)&lt;/math&gt; are [[polynomial]]s in &lt;math&gt;\log q_\mu^2&lt;/math&gt; when evaluated at ''z'' = 0.

==Notes==
{{reflist|2}}

==References==
*{{citation|journal=Annales Henri Poincaré|volume= 6 |year=2005|pages=343–367|title=The Hopf Algebra of Rooted Trees in Epstein-Glaser Renormalization|first=Christoph|last= Bergbauer|first2=Dirk|last2= Kreimer|authorlink2=Dirk Kreimer|arxiv=hep-th/0403207|doi=10.1007/s00023-005-0210-3|issue=2|bibcode = 2005AnHP....6..343B }}
*{{citation|last=Boutet de Monvel|first= Louis|title=Algèbre de Hopf des diagrammes de Feynman, renormalisation et factorisation de Wiener-Hopf (d'après A. Connes et D. Kreimer). [Hopf algebra of Feynman diagrams, renormalization and Wiener-Hopf factorization (following A. Connes and D. Kreimer)]|series=[[Séminaire Bourbaki]]|journal= Astérisque|volume= 290|year=2003|pages= 149–165|url=http://people.math.jussieu.fr/~boutet/renormalisation.pdf}}
*{{citation|title=Runge&amp;ndash;Kutta methods and renormalization|first=Christian |last=Brouder|journal=Eur.Phys.J.|volume= C12 |issue=3 |year=2000|pages= 521&amp;ndash;534|arxiv=hep-th/9904014|bibcode = 2000EPJC...12..521B |doi = 10.1007/s100529900235 }}
*{{citation|first=G. |last=Bogfjellmo|first2=A. |last2=Schmeding|title= The Lie group structure of the Butcher group|journal= Foundations of Computational Mathematics|volume=17|issue=1|pages=127–159|year= 2015|url=https://link.springer.com/article/10.1007%2Fs10208-015-9285-5#page-1|doi=10.1007/s10208-015-9285-5|arxiv=1410.4761}}
*{{citation|first=Christian |last=Brouder|title= Trees, Renormalization and Differential Equations|journal=BIT Numerical Mathematics|volume= 44|year= 2004|pages=425–438|url=http://www.springerlink.com/content/m334351x243t2412/|doi=10.1023/B:BITN.0000046809.66837.cc|issue=3|citeseerx=10.1.1.180.7535}}
*{{citation|first=J.C|last=Butcher|authorlink=John C. Butcher|title=Coefficients for the study of Runge-Kutta integration processes|journal=J. Austral. Math. Soc. |volume=3 |year=1963 |pages=185–201|doi=10.1017/S1446788700027932|issue=2}}
*{{citation|first=J.C|last=Butcher|authorlink=John C. Butcher|title=An algebraic theory of integration methods|journal=Math. Comput.|volume=26|issue=117|year=1972|pages=79&amp;ndash;106|jstor=2004720|doi=10.2307/2004720}}
*{{Citation | last1=Butcher | first1=John C. | author1-link=John C. Butcher | title=Numerical methods for ordinary differential equations | publisher=John Wiley &amp; Sons Ltd. | edition=2nd | isbn=978-0-470-72335-7 | mr=2401398 | year=2008}}
*{{citation|first=J.C|last=Butcher|authorlink=John C. Butcher|title=Trees and numerical methods for ordinary differential equations|url=http://www.springerlink.com/content/un0168l544n80250/|journal=Numerical Algorithms|volume=53|issue=2–3|pages=153–170|year=2009|doi=10.1007/s11075-009-9285-0}}
*{{citation|first=Arthur|last=Cayley|authorlink=Arthur Cayley|title=On the theory of analytic forms called trees|url= https://archive.org/stream/collectedmathema03cayluoft#page/242/mode/1up|journal=[[Philosophical Magazine]]|volume=XIII|year=1857|pages=172&amp;ndash;176}} (also in Volume 3 of the Collected Works of Cayley, pages 242&amp;ndash;246)
*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title=Hopf Algebras, Renormalization and Noncommutative Geometry|journal=Communications in Mathematical Physics|volume= 199|issue=1|year= 1998|pages=203&amp;ndash;242|url=http://www.alainconnes.org/docs/ncgk.pdf|doi=10.1007/s002200050499|arxiv = hep-th/9808042 |bibcode = 1998CMaPh.199..203C }}
*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title=Lessons from quantum field theory: Hopf algebras and spacetime geometries|journal=[[Letters in Mathematical Physics]]|volume= 48 |year=1999|pages= 85–96|doi=10.1023/A:1007523409317}}
*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title=Renormalization in quantum field theory and the Riemann-Hilbert problem. I. The Hopf algebra structure of graphs and the main theorem|journal=Commun. Math. Phys.|volume= 210|issue=1|year=2000|pages=249–273
|url=http://www.alainconnes.org/docs/RH1.pdf|doi=10.1007/s002200050779|arxiv = hep-th/9912092 |bibcode = 2000CMaPh.210..249C }}
*{{citation|first=Alain|last=Connes|authorlink=Alain Connes|first2=Dirk|last2=Kreimer|authorlink2=Dirk Kreimer|title= Renormalization in quantum field theory and the Riemann-Hilbert problem. II. The β-function, diffeomorphisms and the renormalization group|journal= Commun. Math. Phys.|volume= 216|issue=1|pages= 215–241|year=2001|
url=http://www.alainconnes.org/docs/RH2.pdf|doi=10.1007/PL00005547|arxiv = hep-th/0003188 |bibcode = 2001CMaPh.216..215C }}
*{{citation|title=Elements of noncommutative geometry|first=José |last=Gracia-Bondía|first2= Joseph C.|last2= Várilly|first3= Héctor|last3= Figueroa|publisher=Birkhäuser|year=2000|isbn=978-0-8176-4124-5}}, Chapter 14.
*{{citation|first=R. |last=Grossman |first2=R. |last2=Larson |title=Hopf algebraic structures of families of trees |journal=Journal of Algebra |volume=26 |year=1989 |pages=184&amp;ndash;210 |url=http://users.lac.uic.edu/~grossman/papers/journal-03.pdf |deadurl=yes |archiveurl=https://web.archive.org/web/20080820054732/http://users.lac.uic.edu/~grossman/papers/journal-03.pdf |archivedate=2008-08-20 |df= }}
*{{citation|title=On the Butcher group and general multi-value methods|journal=Computing|volume= 13|year= 1974|pages=1&amp;ndash;15|first=E. |last=Hairer|first2=G.|last2= Wanner|url=http://www.springerlink.com/content/e6r7327737lq3516/|doi=10.1007/BF02268387}}
*{{citation|last=Kreimer|first= Dirk|authorlink=Dirk Kreimer|title=On the Hopf algebra structure of perturbative quantum field theories|journal=Adv. Theor. Math. Phys.|volume=2|year=1998|pages= 303–334|arxiv=q-alg/9707029|bibcode = 1997q.alg.....7029K }}
*{{citation|arxiv=hep-th/9901099|last=Kreimer|first= Dirk|authorlink=Dirk Kreimer|title=Chen's iterated integral represents the operator product expansion|journal=Adv. Theor. Math. Phys.|volume= 3 |year=1999|pages=627–670|bibcode = 1999hep.th....1099K }}
*{{citation|last=Kreimer|first= Dirk|authorlink=Dirk Kreimer|title= Factorization in Quantum Field Theory: An Exercise in Hopf Algebras and Local Singularities|
series=Frontiers in Number Theory, Physics, and Geometry II|publisher=Springer|year=2007|pages=715–736|arxiv=hep-th/0306020|bibcode = 2003hep.th....6020K }}
*{{Citation | last1=Milnor | first1=John Willard | author1-link=John Milnor | last2=Moore | first2=John C. | title=On the structure of Hopf algebras | jstor=1970615 | mr=0174052 | year=1965 | journal=[[Annals of Mathematics]] | series = Second Series | volume=81 | issue=2 | pages=211–264 | doi=10.2307/1970615| url=https://polipapers.upv.es/index.php/AGT/article/view/2250 }}

[[Category:Combinatorics]]
[[Category:Numerical analysis]]
[[Category:Quantum field theory]]
[[Category:Renormalization group]]
[[Category:Hopf algebras]]</text>
      <sha1>8w9jxww3egb3qj4u9wjcrvpnrlnwdvs</sha1>
    </revision>
  </page>
  <page>
    <title>Close-packing of equal spheres</title>
    <ns>0</ns>
    <id>901260</id>
    <revision>
      <id>868889610</id>
      <parentid>868077896</parentid>
      <timestamp>2018-11-15T02:57:30Z</timestamp>
      <contributor>
        <ip>67.251.209.163</ip>
      </contributor>
      <comment>/* Cannonball problem */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17612">[[File:Close packing box.svg|thumb|Illustration of the close-packing of equal spheres in both hcp (left) and fcc (right) lattices]]
In [[geometry]], '''close-packing of equal [[sphere]]s''' is a dense arrangement of congruent spheres in an infinite, regular arrangement (or [[Lattice (group)|lattice]]). [[Carl Friedrich Gauss]] proved that the highest average density – that is, the greatest fraction of space occupied by spheres – that can be achieved by a [[Lattice (group)|lattice]] packing is
: &lt;math&gt;\frac{\pi}{3\sqrt 2} \simeq 0.74048.&lt;/math&gt;
The same [[packing density]] can also be achieved by alternate stackings of the same close-packed planes of spheres, including structures that are aperiodic in the stacking direction.  The [[Kepler conjecture]] states that this is the highest density that can be achieved by any arrangement of spheres, either regular or irregular. This conjecture was proven by [[Thomas Callister Hales|T. C. Hales]].&lt;ref&gt;{{cite arXiv |last=Hales |first=T. C. |authorlink=Thomas Callister Hales |eprint=math/9811071v2 |title=An overview of the Kepler conjecture |year=1998}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |url=http://www.nature.com/nature/journal/v424/n6944/full/424012a.html |title=Mathematics: Does the proof stack up? | volume=424|doi=10.1038/424012a |journal=Nature |pages=12–13|bibcode=2003Natur.424...12S}}&lt;/ref&gt; Highest density is known only in case of 1, 2, 3, 8 and 24 dimensions.&lt;ref&gt;{{cite journal |first1=H. |last1=Cohn |first2=A. |last2=Kumar |first3=S. D. |last3=Miller |first4=D. |last4=Radchenko |first5=M. |last5=Viazovska |title=The sphere packing problem in dimension 24 |journal=Annals of Mathematics |volume=185 |issue=3 |year=2017 |pages=1017–1033 |doi=10.4007/annals.2017.185.3.8 |arxiv=1603.06518}}&lt;/ref&gt;

Many [[crystal]] structures are based on a close-packing of a single kind of atom, or a close-packing of large ions with smaller ions filling the spaces between them. The cubic and hexagonal arrangements are very close to one another in energy, and it may be difficult to predict which form will be preferred from first principles.

==FCC and HCP Lattices==
[[File:Square circle grid spheres.png|120px|thumb|left|fcc arrangement seen on 4-fold axis direction]]
{| class=wikitable align=right width=360
!colspan=2|fcc
!hcp
|-
|[[File:Cuboctahedron B2 planes.png|120px]]||[[File:Cuboctahedron 3 planes.png|120px]]
|[[File:Triangular orthobicupola wireframe.png|120px]]
|-
|colspan=3|The ''fcc'' arrangement can be oriented in two different planes, square or triangular. These can be seen in the [[cuboctahedron]] with 12 vertices representing the positions of 12 neighboring spheres around one central sphere. The ''hcp'' arrangement can be seen in the triangular orientation, but alternates two positions of spheres, in a [[triangular orthobicupola]] arrangement.
|}
There are two simple regular lattices that achieve this highest average density. They are called '''face-centered cubic''' ('''fcc''') (also called '''[[cubic crystal system|cubic]] close packed''') and '''[[Hexagonal crystal system|hexagonal]] close-packed''' ('''hcp'''), based on their [[symmetry]]. Both are based upon sheets of spheres arranged at the vertices of a triangular tiling; they differ in how the sheets are stacked upon one another.  The fcc lattice is also known to mathematicians as that generated by the A&lt;sub&gt;3&lt;/sub&gt; [[root system]].&lt;ref&gt;{{cite book |authorlink1=John Horton Conway |last1=Conway |first1=John Horton |authorlink2=Neil Sloane |last2=Sloane |first2=Neil James Alexander |last3=Bannai |first3=Eiichi |title=Sphere packings, lattices, and groups |publisher=Springer |year=1999 |at=Section 6.3}}&lt;/ref&gt;

=== Cannonball problem ===
{{main|Cannonball problem}}
[[Image:Fortres Monroe 1861 - Cannon-balls.jpg|thumb|Cannonballs piled on a triangular ''(front)'' and rectangular ''(back)'' base, both [[Face-centered cubic|fcc]] lattices.]]
The problem of close-packing of spheres was first mathematically analyzed by [[Thomas Harriot]] around 1587, after a question on piling cannonballs on ships was posed to him by Sir [[Walter Raleigh]] on their expedition to America.&lt;ref&gt;{{cite web |title=Cannonball Problem |work=The Internet Encyclopedia of Science |first=David |last=Darling |url=http://www.daviddarling.info/encyclopedia/C/Cannonball_Problem.html }}&lt;/ref&gt; 
Cannonballs were usually piled in a rectangular or triangular wooden frame, forming a three-sided or four-sided pyramid. Both arrangements produce a face-centered cubic lattice – with different orientation to the ground.  Hexagonal close-packing would result in a six-sided pyramid with a hexagonal base. 
[[File:Snowpyramids.jpg|thumb| Snowballs stacked in preparation for a [[snowball fight]]. The front pyramid is hexagonal close-packed and rear is face-centered cubic. ]]

The [[cannonball problem]] asks which flat square arrangements of cannonballs can be stacked into a square pyramid. [[Édouard Lucas]] formulated the problem as the [[Diophantine equation]] &lt;math&gt;\sum_{n=1}^{N} n^2 = M^2&lt;/math&gt; or &lt;math&gt;\frac{1}{6} N(N+1)(2N+1) = M^2&lt;/math&gt; and conjectured that the only solutions are &lt;math&gt;N = 1, M = 1,&lt;/math&gt; and &lt;math&gt;N = 24, M = 70&lt;/math&gt;. Here &lt;math&gt;N&lt;/math&gt; is the number of layers in the pyramidal stacking arrangement and &lt;math&gt;M&lt;/math&gt; is the number of cannonballs along an edge in the flat square arrangement.
&lt;!-- TO DO: Who first proposed the hcp arrangement? --&gt;

=== Positioning and spacing ===
In both the fcc and hcp arrangements each sphere has twelve neighbors. For every sphere there is one gap surrounded by six spheres (octahedral) and two smaller gaps surrounded by four spheres (tetrahedral). The distances to the centers of these gaps from the centers of the surrounding spheres is {{sqrt|{{frac|3|2}}}} for the tetrahedral, and {{sqrt|2}} for the octahedral, when the sphere radius is 1.

Relative to a reference layer with positioning A, two more positionings B and C are possible. Every sequence of A, B, and C without immediate repetition of the same one is possible and gives an equally dense packing for spheres of a given radius.

The most regular ones are
*fcc = ABC ABC ABC... (every third layer is the same)
*hcp = AB AB AB AB... (every other layer is the same).

There is an uncountably infinite number of disordered arrangements of planes (e.g. ABCACBABABAC...) that are sometimes collectively referred to as "Barlow packings", after crystallographer [[William Barlow (geologist)|William Barlow]]&lt;ref&gt;{{cite journal|author=Barlow, William|title=Probable Nature of the Internal Symmetry of Crystals|journal=Nature|year=1883|volume=29|pages=186–188|doi=10.1038/029186a0|bibcode=1883Natur..29..186B}}&lt;/ref&gt;

In close-packing, the center-to-center spacing of spheres in the ''xy'' plane is a simple honeycomb-like tessellation with a pitch (distance between sphere centers) of one sphere diameter. The distance between sphere centers, projected on the ''z'' (vertical) axis, is:

:&lt;math&gt;\text{pitch}_Z = \sqrt{6} \cdot {d\over 3}\approx0.816\,496\,58 d,&lt;/math&gt;

where ''d'' is the diameter of a sphere; this follows from the tetrahedral arrangement of close-packed spheres.

The [[coordination number]] of hcp and fcc is 12 and their [[atomic packing factor]]s (APFs) are equal to the number mentioned above, 0.74.

{| border="0" cellpadding="10px" style="border:1px solid gray;"
|-
!Comparison between hcp and fcc
|- style="text-align:center;"
| [[Image:close packing.svg|100000x250px]]
|-
| '''Figure 1''' – The hcp lattice (left) and the fcc lattice (right). The outline of each respective [[Bravais lattice]] is shown in red. The letters indicate which layers are the same. There are two "A" layers in the hcp matrix, where all the spheres are in the same position. All three layers in the fcc stack are different. Note the fcc stacking may be converted to the hcp stacking by translation of the upper-most sphere, as shown by the dashed outline.
|}
{| border=0 cellspacing=2em
|- style="text-align:center;"
| [[Image:Hexagonal close-packed unit cell.jpg|x250px]]
| [[Image:Close-packed spheres, with umbrella light &amp; camerea.jpg|x250px]]
|-
| '''Figure 2''' – Shown here is a stack of eleven spheres of the '''hcp''' lattice illustrated in ''Figure&amp;nbsp;1''. The hcp stack differs from the top 3 tiers of the fcc stack shown in ''Figure&amp;nbsp;3'' only in the lowest tier; it can be modified to fcc by an appropriate rotation or translation.
| '''Figure 3''' – [[Thomas Harriot]], circa 1585, first pondered the mathematics of the ''cannonball arrangement'' or ''cannonball stack,'' which has an '''fcc''' lattice. Note how adjacent balls along each edge of the regular [[tetrahedron]] enclosing the stack are all in direct contact with one another. This does not occur in an hcp lattice, as shown in ''Figure&amp;nbsp;2''.
|}

==Lattice generation==
When forming any sphere-packing lattice, the first fact to notice is that whenever two spheres touch a straight line may be drawn from the center of one sphere to the center of the other intersecting the point of contact. The distance between the centers along the shortest path namely that straight line will therefore be ''r''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;+&amp;nbsp;''r''&lt;sub&gt;2&lt;/sub&gt; where ''r''&lt;sub&gt;1&lt;/sub&gt; is the radius of the first sphere and ''r''&lt;sub&gt;2&lt;/sub&gt; is the radius of the second. In close packing all of the spheres share a common radius, ''r''. Therefore two centers would simply have a distance 2''r''.

===Simple hcp lattice===
[[Image:Animated-HCP-Lattice.gif|thumbnail=Animated-HCP-Lattice-Thumbnail.gif|An animation of close-packing lattice generation. Note: If a third layer (not shown) is directly over the first layer, then the HCP lattice is built. If the third layer is placed over holes in the first layer, then the FCC lattice is created.]]

To form an A-B-A-B-... hexagonal close packing of spheres, the coordinate points of the lattice will be the spheres' centers. Suppose, the goal is to fill a box with spheres according to hcp. The box would be placed on the [[Cartesian coordinate system|''x''-''y''-''z'' coordinate space]].

First form a row of spheres. The centers will all lie on a straight line. Their ''x''-coordinate will vary by 2''r'' since the distance between each center of the spheres are touching is 2''r''. The ''y''-coordinate and z-coordinate will be the same. For simplicity, say that the balls are the first row and that their ''y''- and ''z''-coordinates are simply ''r'', so that their surfaces rest on the zero-planes. Coordinates of the centers of the first row will look like (2''r'',&amp;nbsp;''r'',&amp;nbsp;''r''), (4''r'',&amp;nbsp;''r'',&amp;nbsp;''r''), (6''r''&amp;nbsp;,''r'',&amp;nbsp;''r''), (8''r''&amp;nbsp;,''r'',&amp;nbsp;''r''),&amp;nbsp;...&amp;nbsp;.

Now, form the next row of spheres. Again, the centers will all lie on a straight line with ''x''-coordinate differences of 2''r'', but there will be a shift of distance ''r'' in the ''x''-direction so that the center of every sphere in this row aligns with the ''x''-coordinate of where two spheres touch in the first row. This allows the spheres of the new row to slide in closer to the first row until all spheres in the new row are touching two spheres of the first row. Since the new spheres ''touch'' two spheres, their centers form an equilateral triangle with those two neighbors' centers. The side lengths are all 2''r'', so the height or ''y''-coordinate difference between the rows is {{sqrt|3}}''r''. Thus, this row will have coordinates like this:

: &lt;math&gt;\left(r, r + \sqrt{3}r, r\right),\ \left(3r, r + \sqrt{3}r, r\right),\ \left(5r, r + \sqrt{3}r, r\right),\ \left(7r, r + \sqrt{3}r, r\right), \dots.&lt;/math&gt;

The first sphere of this row only touches one sphere in the original row, but its location follows suit with the rest of the row.

The next row follows this pattern of shifting the ''x''-coordinate by ''r'' and the ''y''-coordinate by {{sqrt|3}}. Add rows until reaching the ''x'' and ''y'' maximum borders of the box.

In an A-B-A-B-... stacking pattern, the odd numbered ''planes'' of spheres will have exactly the same coordinates save for a pitch difference in the ''z''-coordinates and the even numbered ''planes'' of spheres will share the same ''x''- and ''y''-coordinates. Both types of planes are formed using the pattern mentioned above, but the starting place for the ''first'' row's first sphere will be different.

Using the plane described precisely above as plane #1, the A plane, place a sphere on top of this plane so that it lies touching three spheres in the A-plane. The three spheres are all already touching each other, forming an equilateral triangle, and since they all touch the new sphere, the four centers form a [[tetrahedron|regular tetrahedron]].&lt;ref&gt;{{cite web|url=http://www.grunch.net/synergetics/sphpack.html |title=on Sphere Packing |publisher=Grunch.net |date= |accessdate=2014-06-12}}&lt;/ref&gt; All of the sides are equal to 2''r'' because all of the sides are formed by two spheres touching. The height of which or the ''z''-coordinate difference between the two "planes" is {{sfrac|{{sqrt|6}}''r''2|3}}. This, combined with the offsets in the ''x'' and ''y''-coordinates gives the centers of the first row in the B plane:

: &lt;math&gt;\left(r, r + \frac{\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right),\ \left(3r, r + \frac{\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right),\ \left(5r, r + \frac{\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right),\ \left(7r, r + \frac{\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right), \dots. &lt;/math&gt;

The second row's coordinates follow the pattern first described above and are:

: &lt;math&gt;\left(2r, r + \frac{4\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right),\ \left(4r, r + \frac{4\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right),\ \left(6r, r + \frac{4\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right),\ \left(8r,r + \frac{4\sqrt{3}r}{3}, r + \frac{\sqrt{6}r2}{3}\right),\dots. &lt;/math&gt;

The difference to the next plane, the A plane, is again {{sfrac|{{sqrt|6}}''r''2|3}} in the ''z''-direction and a shift in the ''x'' and ''y'' to match those ''x''- and ''y''-coordinates of the first A plane.&lt;ref&gt;{{MathWorld|urlname = HexagonalClosePacking|title = Hexagonal Close Packing}}&lt;/ref&gt;

In general, the coordinates of sphere centers can be written as:

: &lt;math&gt;\begin{bmatrix}
  2i + ((j\ +\ k) \bmod 2)\\
  \sqrt{3}\left[j + \frac{1}{3}(k \bmod 2)\right]\\
  \frac{2\sqrt{6}}{3}k
\end{bmatrix}r&lt;/math&gt;

where ''i'', ''j'' and ''k'' are indices starting at 0 for the ''x''-, ''y''- and ''z''-coordinates.

==Miller indices==
{{main|Miller index}}
[[Image:Indices miller bravais.png|thumb|Miller–Bravais index for hcp lattice]]
Crystallographic features of hcp systems, such as vectors and atomic plane families, can be described using a four-value [[Miller index]] notation ( ''hkil'' ) in which the third index ''i'' denotes a convenient but degenerate component which is equal to −''h''&amp;nbsp;−&amp;nbsp;''k''. The ''h'', ''i'' and ''k'' index directions are separated by 120°, and are thus not orthogonal; the ''l'' component is mutually perpendicular to the ''h'', ''i'' and ''k'' index directions.

== Filling the remaining space ==
The fcc and hcp packings are the densest known packings of equal spheres with the highest symmetry (smallest repeat units).
Denser [[sphere packing]]s are known, but they involve [[sphere packing#Unequal sphere packing|unequal sphere packing]].
A packing density of 1, filling space completely, requires non-spherical shapes, such as [[honeycomb (geometry)|honeycombs]].

Replacing each contact point between two spheres with an edge connecting the centers of the touching spheres produces tetrahedrons and octahedrons of equal edge lengths.
The fcc arrangement produces the [[tetrahedral-octahedral honeycomb]].
The hcp arrangement produces the [[gyrated tetrahedral-octahedral honeycomb]].
If, instead, every sphere is augmented with the points in space that are closer to it than to any other sphere, the duals of these honeycombs are produced: the [[rhombic dodecahedral honeycomb]] for fcc, and the [[trapezo-rhombic dodecahedral honeycomb]] for hcp.

Spherical bubbles in soapy water in a fcc or hcp arrangement, when the water in the gaps between the bubbles drains out, also approach the [[rhombic dodecahedral honeycomb]] or [[trapezo-rhombic dodecahedral honeycomb]]. However, such fcc or hcp foams of very small liquid content are unstable, as they do not satisfy [[Plateau's laws]]. The [[Kelvin foam]] and the [[Weaire–Phelan structure|Weaire–Phelan foam]] are more stable, having smaller interfacial energy in the limit of a very small liquid content.&lt;ref&gt;{{cite book|title=Foams, Structure and Dynamics|first1=Isabelle|last1=Cantat|first2=Sylvie|last2=Cohen-Addad|first3=Florence|last3=Elias|first4=François|last4=Graner|first5=Reinhard|last5=Höhler|first6=Ruth|last6=Flatman|first7=Olivier|last7=Pitois|publisher=Oxford University Press|location=Oxford|date=2013|isbn=9780199662890}}&lt;/ref&gt;

==See also==
*[[Cubic crystal system]]
*[[Hermite constant]]
*[[Random close pack]]
*[[Sphere packing]]

==Notes==
{{reflist}}

==External links==
{{commonscat|Highest density sphere packing}}
*[http://www.iucr.org/__data/assets/pdf_file/0015/13254/5.pdf P. Krishna &amp; D. Pandey, "Close-Packed Structures" International Union of Crystallography by University College Cardiff Press. Cardiff, Wales. PDF]
*[http://alecjacobson.com/graphics/hw10b/ "3D Sphere Packing Applet"] Close-Packing of Spheres java applet

{{Packing problem}}

{{DEFAULTSORT:Close-Packing Of Spheres}}
[[Category:Discrete geometry]]
[[Category:Crystallography]]
[[Category:Packing problems]]
[[Category:Spheres]]</text>
      <sha1>hvpg19avnqennsxfe05k2125cgqobyu</sha1>
    </revision>
  </page>
  <page>
    <title>Countable chain condition</title>
    <ns>0</ns>
    <id>1550771</id>
    <revision>
      <id>793562526</id>
      <parentid>786498494</parentid>
      <timestamp>2017-08-02T14:50:25Z</timestamp>
      <contributor>
        <username>Mac Moneysac</username>
        <id>17971344</id>
      </contributor>
      <minor/>
      <comment>I added another property, unfortunately I do not have a proper reference yet.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3169">In [[order theory]], a [[partially ordered set]] ''X'' is said to satisfy the '''countable chain condition''', or to be '''ccc''', if every [[strong antichain]] in ''X'' is [[countable]]. 

==Overview==
There are really two conditions: the ''upwards'' and ''downwards'' countable chain conditions. These are not equivalent. The countable chain condition means the downwards countable chain condition, in other words no two elements have a common lower bound.

This is called the "countable chain condition" rather than the more logical term "countable antichain condition" for historical reasons related to certain chains of open sets in topological spaces and chains in complete Boolean algebras, where chain conditions sometimes happen to be equivalent to antichain conditions. For example, if &amp;kappa; is a cardinal, then in a complete Boolean algebra every antichain has size less than &amp;kappa; if and only if there is no descending &amp;kappa;-sequence of elements, so chain conditions are equivalent to antichain conditions.

Partial orders and spaces satisfying the ccc are used in the statement of [[Martin's axiom]].

In the theory of [[forcing (set theory)|forcing]], ccc partial orders are used because forcing with any generic set over such an order preserves cardinals and cofinalities.  Furthermore, the ccc property is preserved by finite support iterations (see [[iterated forcing]]). For more information on ccc in the context of forcing, see {{format link|Forcing (set theory)#The countable chain condition}}.

More generally, if &amp;kappa; is a cardinal then a poset is said to satisfy the '''&amp;kappa;-chain condition''' if every antichain has size less than &amp;kappa;. The countable chain condition is the &amp;alefsym;&lt;sub&gt;1&lt;/sub&gt;-chain condition.

==Examples and properties in topology==
A [[topological space]] is said to satisfy the countable chain condition, or '''Suslin's Condition''', if the partially ordered set of non-empty [[open subset]]s of ''X'' satisfies the countable chain condition, ''i.e.'' every [[pairwise disjoint]] collection of non-empty open subsets of ''X'' is countable. The name originates from  [[Suslin's problem|Suslin's Problem]].

* Every [[separable topological space]] is ccc. Furthermore, the [[Product topology|product space]] of at most [[Cardinality of the continuum|&lt;math&gt;\mathfrak{c}=2^{\aleph_{0}}&lt;/math&gt;]] separable spaces is a separable space and, thus, ccc.
* Every [[metric space]] is ccc if and only if it's separable, but in general a ccc topological space need not be separable.
* Paracompact ccc spaces are [[Lindelöf space|Lindelöf]].

For example, &lt;math&gt;\{ 0, 1 \}^{2^{2^{\aleph_{0}}}}&lt;/math&gt; with the [[product topology]] is ccc, though ''not'' separable.

==References==
*{{Citation | last1=Jech | first1=Thomas | author1-link=Thomas Jech | title=Set Theory: Millennium Edition | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Springer Monographs in Mathematics | isbn=978-3-540-44085-7 | year=2003}}
*Products of Separable Spaces, K. A. Ross, and A. H. Stone. The American Mathematical Monthly 71(4):pp.&amp;nbsp;398–403 (1964)

[[Category:Order theory]]
[[Category:Forcing (mathematics)]]</text>
      <sha1>er27sk0yh8hk0sx6ywh43mptfbnddpv</sha1>
    </revision>
  </page>
  <page>
    <title>De Bruijn torus</title>
    <ns>0</ns>
    <id>5980981</id>
    <revision>
      <id>868398602</id>
      <parentid>838810391</parentid>
      <timestamp>2018-11-11T23:21:21Z</timestamp>
      <contributor>
        <username>Jack Dobson</username>
        <id>24507807</id>
      </contributor>
      <minor/>
      <comment>Rewritten for better comprehension</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4752">[[image:2-2-4-4-de-Bruijn-torus.svg|right|thumb|A De Bruijn torus. Each 2-by-2 binary matrix can be found within it exactly once.]]
In [[combinatorics|combinatorial]] mathematics, a '''De Bruijn torus''', named after [[Nicolaas Govert de Bruijn]], is an [[matrix (mathematics)|array]] of symbols from an alphabet (often just 0 and 1) that contains every ''m''-by-''n'' [[matrix (mathematics)|matrix]] exactly once.  It is a [[torus]] because the edges are considered wraparound for the purpose of finding matrices. Its name comes from the [[De Bruijn sequence]], which can be considered a special case where ''n'' is&amp;nbsp;1 (one dimension).

One of the main open questions regarding De Bruijn tori is whether a De Bruijn torus for a particular alphabet size can be constructed for a given ''m'' and&amp;nbsp;''n''.  It is known that these always exist when ''n''&amp;nbsp;=&amp;nbsp;1, since then we simply get the De Bruijn sequences, which always exist. It is also known that "square" tori exist whenever&amp;nbsp;''m''&amp;nbsp;=&amp;nbsp;''n'' and even (for the odd case the resulting tori cannot be square).
&lt;ref&gt;
{{cite journal|
title=On de Bruijn arrays.|
author1=Fan|first1=C. T.|
author2=Fan|first2=S. M.|
author3=Ma|first3=S. L.|
author4=Siu|first4=M. K.|
journal=Ars Combinatoria A|
volume=19|
year=1985|
pages=205–213}}
&lt;/ref&gt;
&lt;ref&gt;
{{cite journal|
title=Universal cycles for combinatorial structures.|
author1=Chung|first1=F.|
author2=Diaconis|first2=P.|
author3=Graham|first3=R.|
journal=Discrete Mathematics|
volume=110|
issue=1|
year=1992|
pages=43–59|doi=10.1016/0012-365x(92)90699-g}}
&lt;/ref&gt;
&lt;ref&gt;{{cite journal|title=Research problems on Gray codes and universal cycles|author1=Jackson|first1=Brad|last2=Stevens|first2=Brett|last3=Hurlbert|first3=Glenn|journal=Discrete Mathematics|volume=309|issue=17|date=Sep 2009|pages=5341–5348|doi=10.1016/j.disc.2009.04.002}}&lt;/ref&gt;

The smallest possible binary "square" de Bruijn torus, depicted above right, denoted as ''(4,4;2,2)&lt;sub&gt;2&lt;/sub&gt;'' de Bruijn torus (or simply as ''B&lt;sub&gt;2&lt;/sub&gt;''), contains all ''2×2'' binary matrices.

==''B&lt;sub&gt;2&lt;/sub&gt;''==

Apart from "translation", "inversion" (exchanging ''0''s and ''1''s) and "rotation" (by 90 degrees), no other ''(4,4;2,2)&lt;sub&gt;2&lt;/sub&gt;'' de Bruijn tori are possible - this can be shown by complete inspection of all ''2&lt;sup&gt;16&lt;/sup&gt;'' binary matrices (or subset fulfilling constrains such as equal numbers of ''0''s and ''1''s) .
&lt;ref&gt;
{{cite journal|title=The Binatorix B2.|author1=Eggen|first1=Bernd R.|journal=Private communication|year=1990}}
&lt;/ref&gt;

==Larger example: ''B&lt;sub&gt;4&lt;/sub&gt;''==
An example of the next possible binary "square" de Bruijn torus, ''(256,256;4,4)&lt;sub&gt;2&lt;/sub&gt;'' (abbreviated as ''B&lt;sub&gt;4&lt;/sub&gt;''), has been explicitly constructed.&lt;ref&gt;
{{cite journal|title=Decoding de Bruijn arrays constructed by the FFMS method.|author1=Shiu|first1=Wai-Chee|journal=Ars Combinatoria|volume=47|issue=17|year=1997|pages=33–48}}
&lt;/ref&gt;

The image below shows an example of a ''(256,256;4,4)&lt;sub&gt;2&lt;/sub&gt;'' de Bruijn torus / array, where the ''zeroes'' have been encoded as black and the ''ones'' as white pixels respectively.

[[image:Visualisation of a (256,256;4,4) 2 de Bruijn torus.png|centre|Image of a De Bruijn torus. Each 4-by-4 binary matrix can be found within it exactly once.]]

==Binary de Bruijn tori of greater size==
The paper in which an example of the ''(256,256;4,4)&lt;sub&gt;2&lt;/sub&gt;'' de Bruijn torus was constructed contained over 10 pages of binary, despite its reduced font size, requiring three lines per row of array.

The subsequent possible binary de Bruijn torus, containing all binary ''6×6'' matrices, would have ''2&lt;sup&gt;36&lt;/sup&gt; = 68,719,476,736'' entries, yielding a square array of dimension ''262,144x262,144'', denoted a ''(262144,262144;6,6)&lt;sub&gt;2&lt;/sub&gt;'' de Bruijn torus or simply ''B&lt;sub&gt;6&lt;/sub&gt;''. This could easily be stored on a computer &amp;em; if printed with pixels of side 0.1&amp;nbsp;mm, such a matrix would require an area of approximately 26×26 [[square metres|square metre]].

The object ''B&lt;sub&gt;8&lt;/sub&gt;'', containing all binary ''8×8'' matrices and denoted ''(4294967296,4294967296;8,8)&lt;sub&gt;2&lt;/sub&gt;'', has a total of ''2&lt;sup&gt;64&lt;/sup&gt; ≈ 18.447×10&lt;sup&gt;18&lt;/sup&gt;'' entries: storing such a matrix would require 18.5 exabits, or 2.3 [[exabytes|Exabyte]] of storage, an order of magnitude above even modern data centres.

==See also==
* [[De Bruijn sequence]]
* [[De Bruijn graph]]

==References==
{{reflist}}

==External links==
* [https://web.archive.org/web/20140527202958/http://lcni.uoregon.edu/~dow/Geek_art/Minimal_combinatorics/Minimal_arrays_containing_all_combinations.html Minimal arrays containing all sub-array combinations of symbols: De Bruijn sequences and tori]

[[Category:Combinatorics]]</text>
      <sha1>nhwqmc34a7iz8sp74ot26ugzamwyaen</sha1>
    </revision>
  </page>
  <page>
    <title>Dependent type</title>
    <ns>0</ns>
    <id>1949487</id>
    <revision>
      <id>870081106</id>
      <parentid>869529580</parentid>
      <timestamp>2018-11-22T07:03:46Z</timestamp>
      <contributor>
        <username>Cedar101</username>
        <id>374440</id>
      </contributor>
      <minor/>
      <comment>/* Comparison of languages with dependent types */ {{Any}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="20706">{{Type systems}}
In [[computer science]] and [[logic]], a '''dependent type''' is a type whose definition depends on a value. A "pair of integers" is a type. A "pair of integers where the second is greater than the first" is a dependent type because of the dependence on the value. It is an overlapping feature of [[type theory]] and [[type system]]s.  In [[intuitionistic type theory]], dependent types are used to encode logic's [[Generalized quantifier|quantifiers]] like "for all" and "there exists". In [[functional programming languages]] like [[Agda (theorem prover)|Agda]], [[ATS (programming language)|ATS]], [[Coq]], [[F*_(programming_language) | F*]] , [[Epigram (programming language)|Epigram]], [[Idris (programming language)|Idris]], and [[Shen (programming language)|Shen]], dependent types prevent bugs by allowing extremely expressive types.

Two common examples of dependent types are dependent functions and dependent pairs.  A dependent function's return type may depend on the ''value'' (not just type) of an argument.  A function that takes a positive integer "n" may return an array of length "n".  (Note that this is different from [[Polymorphism (computer science)|polymorphism]] and [[generic programming]], both of which include the type as an argument.)  A dependent pair may have a second value that depends on the first.  It can be used to encode a pair of integers where the second one is greater than the first.

Dependent types add complexity to a type system.  Deciding the equality of dependent types in a program may require computations. If arbitrary values are allowed in dependent types, then deciding type equality may involve deciding whether two arbitrary programs produce the same result; hence [[type checking]] may become [[Undecidable problem|undecidable]].

==History==

Dependent types were created to deepen the connection between programming and logic.{{clarify|date=June 2017}}

In 1934, [[Haskell Curry]] noticed that the types used in [[typed lambda calculus]], and in its [[combinatory logic]] counterpart, followed the same pattern as axioms in [[Propositional calculus|propositional logic]].  Going further, for every proof in the logic, there was a matching function (term) in the programming language.  One of Curry's examples was the correspondence between [[simply typed lambda calculus]] and [[intuitionistic logic]].&lt;ref name=curry_howard&gt;{{cite journal|last=Sørensen|first=Morten Heine B.|author2=Pawel Urzyczyn|title=Lectures on the Curry-Howard Isomorphism|year=1998|url=http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.17.7385}}&lt;/ref&gt;

[[Predicate logic]] is an extension of propositional logic, adding quantifiers. [[William Alvin Howard|Howard]] and [[Nicolaas Govert de Bruijn|de Bruijn]] extended lambda calculus to match this more powerful logic by creating types for dependent functions, which correspond to "for all", and dependent pairs, which correspond to "there exists".&lt;ref name=dep_types_at_work&gt;{{cite journal|last=Bove|first=Ana|author2=Peter Dybjer|title=Dependent Types at Work|year=2008|url=http://www.cse.chalmers.se/~peterd/papers/DependentTypesAtWork.pdf}}&lt;/ref&gt;

(Because of this and other work by Howard, propositions-as-types is known as the [[Curry–Howard correspondence]].)

==Formal definition==
===&lt;math&gt;\Pi&lt;/math&gt; type===
Loosely speaking, dependent types are similar to the type of an indexed family of sets. More formally, given a type &lt;math&gt;A:\mathcal{U}&lt;/math&gt; in a universe of types &lt;math&gt;\mathcal{U}&lt;/math&gt;, one may have a '''family of types''' &lt;math&gt;B:A\to\mathcal{U}&lt;/math&gt;, which assigns to each term &lt;math&gt;a:A&lt;/math&gt; a type &lt;math&gt;B(a):\mathcal{U}&lt;/math&gt;. We say that the type ''B(a)'' varies with ''a''.

A function whose type of return value varies with its argument (i.e. there is no fixed [[codomain]]) is a '''dependent function''' and the type of this function is called '''dependent product type''', '''pi-type''' or '''dependent function type'''&lt;ref name='without-sugar'/&gt;.  For this example, the dependent function type is typically written as &lt;math display="block"&gt;\prod_{x:A} B(x)&lt;/math&gt; or &lt;math display="block"&gt;\prod\nolimits_{x:A} B(x).&lt;/math&gt;

If &lt;math&gt;B:A\to\mathcal{U}&lt;/math&gt; is a constant function, the corresponding dependent product type is equivalent to an ordinary [[function type]]. That is, &lt;math display="inline"&gt;\prod_{x:A}B&lt;/math&gt; is judgmentally equal to &lt;math&gt;A\to B&lt;/math&gt; when ''B'' does not depend on ''x''.

The name 'pi-type' comes from the idea that these may be viewed as a [[Cartesian product]] of types. Pi-types can also be understood as [[model theory|models]] of [[Universal quantification#As adjoint|universal quantifiers]].

For example, if we write &lt;math&gt;\operatorname{Vec}(\mathbb{R},n)&lt;/math&gt; for ''n''-tuples of [[real numbers]], then &lt;math display="inline"&gt;\prod_{n:\mathbb{N}} \operatorname{Vec}(\mathbb{R},n)&lt;/math&gt; would be the type of a function which, given a [[natural number]] ''n'', returns a tuple of real numbers of size ''n''. The usual function space arises as a special case when the range type does not actually depend on the input. E.g. &lt;math display="inline"&gt;\prod_{n:\mathbb{N}} {\mathbb{R}}&lt;/math&gt; is the type of functions from natural numbers to the real numbers, which is written as &lt;math&gt;\mathbb{N}\to\mathbb{R}&lt;/math&gt; in typed lambda calculus.

===&lt;math&gt;\Sigma&lt;/math&gt; type===
The [[dual (category theory)|dual]] of the dependent product type is the '''dependent pair type''', '''dependent sum type''', '''sigma-type''', or (confusingly) '''dependent product type'''&lt;ref name='without-sugar'/&gt;. Sigma-types can also be understood as [[Universal quantification#As adjoint|existential quantifiers]]. Continuing the above example, if, in the universe of types &lt;math&gt;\mathcal{U}&lt;/math&gt;, there is a type &lt;math&gt;A:\mathcal{U}&lt;/math&gt; and a family of types &lt;math&gt;B:A\to\mathcal{U}&lt;/math&gt;, then there is a dependent pair type &lt;math display="block"&gt;\sum_{x:A} B(x).&lt;/math&gt;

The dependent pair type captures the idea of an ordered pair where the type of the second term is dependent on the value of the first. If &lt;math display="block"&gt;(a,b):\sum_{x:A} B(x),&lt;/math&gt; then &lt;math&gt;a:A&lt;/math&gt; and &lt;math&gt;b:B(a)&lt;/math&gt;. If ''B'' is a constant function, then the dependent pair type becomes (is judgementally equal to) the [[product type]], that is, an ordinary Cartesian product &lt;math&gt;A\times B&lt;/math&gt;.&lt;ref follow='without-sugar'&gt;{{Cite web|url=http://www.cs.nott.ac.uk/~psztxa/publ/pisigma-new.pdf| title=ΠΣ: Dependent Types without the Sugar}}&lt;/ref&gt;

====Example as existential quantification====
Let &lt;math&gt;A:\mathcal{U}&lt;/math&gt; be some type, and let &lt;math&gt;B:A\to\mathcal{U}&lt;/math&gt;. By the [[Curry–Howard correspondence]], ''B'' can be interpreted as a logical [[predicate (mathematical logic)|predicate]] on terms of ''A''. For a given &lt;math&gt;a:A&lt;/math&gt;, whether the type ''B(a)'' is inhabited indicates whether ''a'' satisfies this predicate. The correspondence can be extended to existential quantification and dependent pairs: the proposition &lt;math&gt;\exists{a}{\in}A\,B(a)&lt;/math&gt; is true [[if and only if]] the type &lt;math display="inline"&gt;\sum_{a:A}B(a)&lt;/math&gt; is inhabited.

For example, &lt;math&gt;m:\mathbb{N}&lt;/math&gt; is less than or equal to &lt;math&gt;n:\mathbb{N}&lt;/math&gt; if and only if there exists another natural number &lt;math&gt;k:\mathbb{N}&lt;/math&gt; such that ''m'' + ''k'' = ''n''. In logic, this statement is codified by existential quantification: &lt;math display="block"&gt;m\le n \iff \exists{k}{\in}\mathbb{N}\,m+k=n.&lt;/math&gt; This proposition corresponds to the dependent pair type: &lt;math display="block"&gt;\sum_{k:\mathbb{N}} m+k=n.&lt;/math&gt; That is, a proof of the statement that ''m'' is less than ''n'' is a pair that contains both a number ''k'', which is the difference between ''m'' and ''n'', and a proof of the equality ''m'' + ''k'' = ''n''.

==Systems of the lambda cube==
[[Henk Barendregt]] developed the [[lambda cube]] as a means of classifying type systems along three axes.  The eight corners of the resulting cube-shaped diagram each correspond to a type system, with [[simply typed lambda calculus]] in the least expressive corner, and [[calculus of constructions]] in the most expressive.  The three axes of the cube correspond to three different augmentations of the simply typed lambda calculus: the addition of dependent types, the addition of polymorphism, and the addition of higher [[kind (type theory)|kinded]] type constructors (functions from types to types, for example).  The lambda cube is generalized further by [[pure type system]]s.

===First order dependent type theory===
The system &lt;math&gt;\lambda \Pi&lt;/math&gt; of pure first order dependent types, corresponding to the logical framework [[LF (logical framework)|LF]], is obtained by generalising the function space type of the [[simply typed lambda calculus]] to the dependent product type.

===Second order dependent type theory===
The system &lt;math&gt;\lambda \Pi 2&lt;/math&gt; of second order dependent types is obtained from &lt;math&gt;\lambda \Pi&lt;/math&gt; by allowing quantification over type constructors. In this theory the dependent product operator subsumes both the &lt;math&gt;\to&lt;/math&gt; operator of simply typed lambda calculus and the &lt;math&gt;\forall&lt;/math&gt; binder of [[System F]].

===Higher order dependently typed polymorphic lambda calculus===
The higher order system &lt;math&gt;\lambda \Pi \omega&lt;/math&gt; extends &lt;math&gt;\lambda \Pi 2&lt;/math&gt; to all four forms of abstraction from the [[lambda cube]]: functions from terms to terms, types to types, terms to types and types to terms. The system corresponds to the [[calculus of constructions]] whose derivative, the [[calculus of inductive constructions]] is the underlying system of [[Coq|the Coq proof assistant]].

== Simultaneous programming language and logic ==

The [[Curry–Howard correspondence]] implies that types can be constructed that express arbitrarily complex mathematical properties.  If the user can supply a [[constructive proof]] that a type is ''inhabited'' (i.e., that a value of that type exists) then a compiler can check the proof and convert it into executable computer code that computes the value by carrying out the construction.  The proof checking feature makes dependently typed languages closely related to [[proof assistant]]s.  The code-generation aspect provides a powerful approach to formal [[program verification]] and [[proof-carrying code]], since the code is derived directly from a mechanically verified mathematical proof.

== Comparison of languages with dependent types ==
{{anchor|Comparison}}
{{see also|Proof assistant#Comparison}}
{| class="wikitable sortable"
|-
! Language !! Actively developed !! Paradigm{{refn|This refers to the ''core'' language, not to any tactic or code generation sublanguage.|group=fn}} !! [[Tactic (proof assistant)|Tactics]] !! [[Proof term]]s !! [[Termination checking]] !! Types can depend on{{refn|Subject to semantic constraints, such as universe constraints|group=fn}} !! [[Universe (mathematics)|Universes]] !! [[Proof irrelevance]] !! [[Program extraction]] !! Extraction erases irrelevant terms
|-
| [[Ada (programming language)|Ada 202x]] || {{yes}}&lt;ref&gt;{{cite web|url=https://www.adacore.com/download/|title=GNAT Community download page}}&lt;/ref&gt; || Imperative || {{yes}}&lt;ref&gt;{{cite web|url=http://www.ada-auth.org/standards/2xrm/html/RM-3-2-4.html|title=RM3.2.4 Subtype Predicates}}&lt;/ref&gt; || {{yes|Yes (optional)}}&lt;ref&gt;[[SPARK_(programming_language)|SPARK]] is a provable subset of [[Ada (programming language)|Ada]]&lt;/ref&gt; || {{dunno}} || {{Any}} term{{refn|Static_Predicate for restricted terms, Dynamic_Predicate for Assert-like checking of any term in type cast|group=fn}} || {{dunno}} || {{dunno}} || {{yes|[[Ada (programming language)|Ada]]}} || {{dunno}}
|-
| [[Agda (theorem prover)|Agda]] || {{yes}}&lt;ref&gt;{{cite web|url=http://wiki.portal.chalmers.se/agda/pmwiki.php?n=Main.Download|title=Agda download page}}&lt;/ref&gt; || [[Purely functional programming|Purely functional]] || Few/limited{{refn|Ring solver&lt;ref&gt;{{cite web|url=http://www.cs.nott.ac.uk/~nad/listings/lib/Algebra.RingSolver.html|title=Agda Ring Solver}}&lt;/ref&gt;|group=fn}} || {{yes}} || {{yes|Yes (optional)}} || {{Any}} term || {{yes|Yes (optional){{refn|Optional universes, optional universe polymorphism, and optional explicitly specified universes|group=fn}}}} || Proof-irrelevant arguments (experimental)&lt;ref name='agda-2.2.8'&gt;{{cite web|url=http://permalink.gmane.org/gmane.comp.lang.agda/2051|title=Announce: Agda 2.2.8}}&lt;/ref&gt; || {{yes|[[Haskell (programming language)|Haskell]], Javascript}} || {{yes}}&lt;ref name='agda-2.2.8'/&gt;
|-
| [[ATS (programming language)|ATS]] || {{yes}}&lt;ref&gt;{{cite web|url=http://sourceforge.net/projects/ats2-lang/files/|title=ATS2 downloads}}&lt;/ref&gt; || Functional / imperative || {{no}}&lt;ref&gt;{{cite web|url=http://sourceforge.net/mailarchive/message.php?msg_id=27050673|title=email from ATS inventor Hongwei Xi}}&lt;/ref&gt; || {{yes}} || {{yes}}  || {{Some|Static terms}}&lt;ref&gt;{{cite web|url=http://www.ats-lang.org/MYDATA/ATSfoundation.pdf}}&lt;/ref&gt; || {{dunno}} || {{yes}} || {{yes}} || {{yes}}
|-
| [[Cayenne (programming language)|Cayenne]] || {{no}} || Purely functional || {{no}} || {{yes}} || {{no}} || {{Any}} term || {{no}} || {{no}} || {{dunno}} || {{dunno}}
|-
| Gallina&lt;br /&gt;([[Coq]]) || {{yes}}&lt;ref&gt;{{cite web|url=https://gforge.inria.fr/scm/viewvc.php/trunk/CHANGES?root=coq&amp;view=log|title=Coq CHANGES in Subversion repository}}&lt;/ref&gt; || Purely functional || {{yes}} || {{yes}} || {{yes}} || {{Any}} term || {{yes|Yes{{refn|Universes, automatically inferred universe constraints (not the same as Agda's universe polymorphism) and optional explicit printing of universe constraints|group=fn}}}} || {{no}} || {{yes|[[Haskell (programming language)|Haskell]], [[Scheme (programming language)|Scheme]] and [[OCaml]]}} || {{yes}}
|-
| [[Dependent ML]] || {{no|No{{refn|Has been superseded by ATS|group=fn}}}} || {{dunno}} || {{dunno}} || {{yes}} || {{dunno}} || Natural numbers || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}}
|-
| [[F* (programming language)|F*]] || {{yes}}&lt;ref&gt;{{cite web|url=https://github.com/FStarLang/FStar/commits/master|title=F* changes on GitHub}}&lt;/ref&gt; || Functional and imperative || {{yes}}&lt;ref&gt;{{cite web|url=https://github.com/FStarLang/FStar/releases/tag/v0.9.5.0|title=F* v0.9.5.0 release notes on GitHub}}&lt;/ref&gt; || {{yes}} || {{yes|Yes (optional)}} || {{Any}} pure term || {{yes}} || {{yes}} || {{yes|[[OCaml]], [[F Sharp (programming language)|F#]], and [[C (programming language)|C]]}} || {{yes}}
|-
| [http://code.google.com/p/guru-lang/ Guru] || {{no}}&lt;ref&gt;{{cite web|url=https://code.google.com/p/guru-lang/source/list|title=Guru SVN}}&lt;/ref&gt; || Purely functional&lt;ref name='guru-book'&gt;{{cite web|url=http://guru-lang.googlecode.com/svn/branches/1.0/doc/book.pdf|title=Verified Programming in Guru|author=Aaron Stump|date=6 April 2009|accessdate=28 September 2010|deadurl=yes|archiveurl=https://web.archive.org/web/20091229234011/http://guru-lang.googlecode.com/svn/branches/1.0/doc/book.pdf|archivedate=29 December 2009|df=}}&lt;/ref&gt; || {{yes|hypjoin}}&lt;ref name='hypjoin-paper'&gt;{{cite web|url=http://www.cs.uiowa.edu/~astump/papers/petcher-thesis.pdf|title=Deciding Joinability Modulo Ground Equations in Operational Type Theory|author=Adam Petcher|date=1 April 2008|accessdate=14 October 2010}}&lt;/ref&gt; || {{yes}}&lt;ref name='guru-book'/&gt; || {{yes}} || {{Any}} term || {{no}} || {{yes}} || {{yes|Carraway}} || {{yes}}
|-
| [[Idris (programming language)|Idris]] || {{yes}}&lt;ref&gt;{{cite web|url=https://github.com/idris-lang/Idris-dev/|title=Idris git repository}}&lt;/ref&gt; || Purely functional&lt;ref&gt;{{cite web|url=http://www.cs.st-andrews.ac.uk/~eb/drafts/ifl08.pdf|title=Idris, a language with dependent types - extended abstract|deadurl=yes|archiveurl=https://web.archive.org/web/20110716082621/http://www.cs.st-andrews.ac.uk/~eb/drafts/ifl08.pdf|archivedate=2011-07-16|df=}}&lt;/ref&gt; || {{yes}}&lt;ref name='idris-compare'&gt;{{cite web|url=http://www.quora.com/How-does-Idris-compare-to-other-dependently-typed-programming-languages|title=How does Idris compare to other dependently-typed programming languages?|author=Edwin Brady}}&lt;/ref&gt; || {{yes}} || {{yes|Yes (optional)}} || {{Any}} term || {{yes}} || {{no}} || {{yes}} || {{yes|Yes, aggressively}}&lt;ref name='idris-compare'/&gt;
|-
| [https://leanprover.github.io/ Lean] || {{yes}} || Purely functional || {{yes}} || {{yes}} || {{yes}} || {{Any}} term || {{yes}} || {{yes}} || {{yes}} || {{yes}}
|-
| [[Matita]] || {{yes}}&lt;ref&gt;{{cite web|url=http://helm.cs.unibo.it/websvn/listing.php?repname=helm&amp;path=%2F&amp;sc=0|title=Matita SVN}}&lt;/ref&gt; || Purely functional || {{yes}} || {{yes}} || {{yes}} || {{Any}} term || {{yes}} || {{yes}} || {{yes|[[OCaml]]}} || {{yes}}
|-
| [[NuPRL]] || {{yes}} || Purely functional || {{yes}} || {{yes}} || {{yes}} || {{Any}} term || {{yes}} || {{dunno}} || {{yes}} || {{dunno}}
|-
| [[Prototype Verification System|PVS]] || {{yes}} || {{dunno}} || {{yes}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}}
|-
| [http://sage.soe.ucsc.edu/ Sage] || {{no|No{{refn|Last Sage paper and last code snapshot are both dated 2006|group=fn}}}} || Purely functional || {{no}} || {{no}} || {{no}} || {{dunno}} || {{no}} || {{dunno}} || {{dunno}} || {{dunno}}
|-
| [[Twelf]] || {{yes}} || [[Logic programming]] || {{dunno}} || {{yes}} || {{yes|Yes (optional)}} || {{Any}} (LF) term || {{no}} || {{no}} || {{dunno}} || {{dunno}}
|-
| [http://www.cs.bu.edu/~hwxi/Xanadu/Xanadu.html Xanadu] || {{no}}&lt;ref&gt;{{cite web|url=http://www.cs.bu.edu/~hwxi/Xanadu/Xanadu.html|title=Xanadu home page}}&lt;/ref&gt; || Imperative || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}} || {{dunno}}
|}

==See also==
*[[Typed lambda calculus]]
*[[Intuitionistic type theory]]

== Footnotes ==
&lt;references group="fn"/&gt;

==References==
{{reflist|2}}

==Further reading==
* {{cite book|first=Per|last=Martin-Löf|authorlink=Per Martin-Löf|year=1984|title=Intuitionistic Type Theory|publisher=Bibliopolis|url=http://www.cs.cmu.edu/afs/cs/Web/People/crary/819-f09/Martin-Lof80.pdf}}
* {{cite book|title=Programming in Martin-Löf's Type Theory: An Introduction|first1=Bengt|last1=Nordström|authorlink1=Bengt Nordström|first2=Kent|last2=Petersson|first3=Jan M.|last3=Smith|year=1990|publisher=Oxford University Press|url=http://www.cse.chalmers.se/research/group/logic/book/}}
* {{cite book|editor=S. Abramsky, D. Gabbay and T. Maibaum|first=Henk|last=Barendregt|authorlink=Henk Barendregt|chapter=Lambda calculi with types|chapterurl=ftp://ftp.cs.ru.nl/pub/CompMath.Found/HBK.ps|title=Handbook of Logic in Computer Science|publisher=[[Oxford University Press|Oxford Science Publications]]|year=1992}}
* {{cite journal|first1=Conor|last1=McBride|authorlink1=Conor McBride|first2=James|last2=McKinna|authorlink2=James McKinna|date=January 2004|title=The view from the left|url=http://strictlypositive.org/view.ps.gz|journal=[[Journal of Functional Programming]]|volume=14|issue=1|pages=69&amp;ndash;111|doi=10.1017/s0956796803004829}}
* {{cite journal|first1=Thorsten|last1=Altenkirch|authorlink1=Thorsten Altenkirch|first2=Conor|last2=McBride|authorlink2=Conor McBride|first3=James|last3=McKinna|authorlink3=James McKinna|date=April 2005|title=Why dependent types matter|url=http://www.cs.nott.ac.uk/~txa/publ/ydtm.pdf}}
* Norell, Ulf. ''[http://www.cse.chalmers.se/~ulfn/papers/thesis.pdf Towards a practical programming language based on dependent type theory]''. PhD thesis, Department of Computer Science and Engineering, Chalmers University of Technology, SE-412 96 Göteborg, Sweden, September 2007.
* Oury, Nicolas and Swierstra, Wouter (2008). [http://www.cs.ru.nl/~wouters/Publications/ThePowerOfPi.pdf "The Power of Pi"]. Accepted for presentation at ICFP, 2008.
* Norell, Ulf (2008). [http://www.cse.chalmers.se/~ulfn/papers/afp08/tutorial.pdf Dependently Typed Programming in Agda].

== External links ==
* [http://sneezy.cs.nott.ac.uk/darcs/DTP08/ Dependently Typed Programming 2008]
* [http://sneezy.cs.nott.ac.uk/darcs/dtp10/ Dependently Typed Programming 2010]
* [http://www.cs.ru.nl/dtp11/ Dependently Typed Programming 2011]
* [http://www.haskell.org/haskellwiki/Dependent_type "Dependent type"] at the Haskell Wiki
* {{nlab|id=dependent+type+theory|title=dependent type theory}}
* {{nlab|id=dependent+type|title=dependent type}}
* {{nlab|id=dependent+product+type|title=dependent product type}}
* {{nlab|id=dependent+sum+type|title=dependent sum type}}
* {{nlab|id=dependent+product|title=dependent product}}
* {{nlab|id=dependent+sum|title=dependent sum}}

{{DEFAULTSORT:Dependent Type}}
[[Category:Dependently typed programming| ]]
[[Category:Type theory]]
[[Category:Type systems]]</text>
      <sha1>mne82j7ovtv537zic7geylxjlrasyuf</sha1>
    </revision>
  </page>
  <page>
    <title>Dyadic rational</title>
    <ns>0</ns>
    <id>56263</id>
    <revision>
      <id>859193333</id>
      <parentid>859119288</parentid>
      <timestamp>2018-09-12T10:58:03Z</timestamp>
      <contributor>
        <ip>2601:42:0:4C76:240D:6E88:9F72:8140</ip>
      </contributor>
      <comment>/* Additional properties */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7320">[[Image:Dyadic rational.svg|thumb|300px|Dyadic rationals in the interval from 0 to 1.]]
In [[mathematics]], a '''dyadic fraction''' or '''dyadic rational''' is a [[rational number]] whose [[denominator]], when the ratio is in minimal (coprime) terms, is a [[power of two]], i.e., a number of the form &lt;math&gt;\frac{a}{2^b}&lt;/math&gt; where ''a'' is an [[integer]] and ''b'' is a [[natural number]]; for example, 1/2 or 3/8, but not 1/3. These are precisely the numbers possessing a finite [[binary numeral system|binary]] expansion.  

==Use in measurement==
The [[inch]] is customarily subdivided in dyadic rather than decimal fractions; similarly, the customary divisions of the [[gallon]] into half-gallons, [[quart]]s, and [[pint]]s are dyadic. The ancient Egyptians also used dyadic fractions in measurement, with denominators up to 64.&lt;ref&gt;{{citation
  | title = Concept of the exponential law prior to 1900
  | last = Curtis | first = Lorenzo J.
  | journal = [[American Journal of Physics]]
  | year = 1978
  | volume = 46
  | issue = 9
  | pages = 896–906
  | doi = 10.1119/1.11512}}.&lt;/ref&gt;

==Arithmetic==
The [[Addition|sum]], [[Multiplication|product]], or [[Subtraction|difference]] of any two dyadic fractions is itself another dyadic fraction:
:&lt;math&gt;\frac{a}{2^b}+\frac{c}{2^d}=\frac{2^{d-b}a+c}{2^d} \quad (d\ge b)&lt;/math&gt;

:&lt;math&gt;\frac{a}{2^b}-\frac{c}{2^d}=\frac{2^{d-b}a-c}{2^d} \quad (d\ge b)&lt;/math&gt;

:&lt;math&gt;\frac{a}{2^b}-\frac{c}{2^d}=\frac{a-2^{b-d}c}{2^b} \quad (d&lt; b)&lt;/math&gt;

:&lt;math&gt;\frac{a}{2^b}\times \frac{c}{2^d} = \frac{ a \times c}{2^{b+d}}.&lt;/math&gt;
However, the result of [[Division (mathematics)|dividing]] one dyadic fraction by another is not necessarily a dyadic fraction.

Addition modulo 1 forms a group; this is the [[Prüfer group|Prüfer 2-group]].

==Additional properties==
Because they are closed under addition, subtraction, and multiplication, but not division, the dyadic fractions form a [[subring]] of the rational numbers '''[[rational number|Q]]''' and an [[overring]] of the integers '''Z'''. Algebraically, this subring is the [[localization of a ring|localization]] of the integers '''Z''' with respect to the set of powers of two.

The set of all dyadic fractions is [[dense set|dense]] in the [[real line]]: any real number ''x'' can be arbitrarily closely approximated by dyadic rationals of the form &lt;math&gt;\lfloor 2^i x \rfloor / 2^i&lt;/math&gt;.
Compared to other dense subsets of the real line, such as the rational numbers, the dyadic rationals are in some sense a relatively "small" dense set, which is why they sometimes occur in proofs. (See for instance [[Urysohn's lemma]].)

While it is true that dyadic fractions are precisely those numbers possessing finite binary expansions, their binary expansions are not unique; there is both a finite and an infinite representation of each, with exactly two infinite binary representations for each one other than 0. For example,  0.1000…&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;= 0.0111…&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;= {{nowrap|[[Infinite series|1/4 + 1/8 + 1/16 + …]] {{=}}}} 1/2. Also,  0.11000…&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;= 0.10111…&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;= 3/4.  It would be more precise to say these numbers have binary representations which are eventually constant.

==Dual group==
Considering only the addition and subtraction operations of the dyadic rationals gives them the structure of an additive [[abelian group]]. The [[Pontryagin duality|dual group]] of a [[Group (mathematics)|group]] consists of its  [[Character (mathematics)|characters]], [[group homomorphism]]s to the multiplicative group of the [[complex number]]s, and in the spirit of [[Pontryagin duality]] the dual group of the additive dyadic rationals can also be viewed as a [[topological group]]. It is called the '''dyadic solenoid''' and is an example of a [[solenoid group]] and of a [[protorus]].

The dyadic rationals are the [[direct limit]] of [[infinite cyclic]] [[subgroup]]s of the rational numbers,
:&lt;math&gt;\varinjlim \left\{2^{-i}\mathbb{Z}\mid i = 0, 1, 2, \dots \right\}&lt;/math&gt;
and their dual group can be constructed as the [[inverse limit]] of the [[unit circle]] group under the repeated squaring map
:&lt;math&gt;\zeta\mapsto\zeta^2.&lt;/math&gt;

An element of the dyadic solenoid can be represented as an infinite sequence of complex numbers ''q''&lt;sub&gt;0&lt;/sub&gt;, ''q''&lt;sub&gt;1&lt;/sub&gt;, ''q''&lt;sub&gt;2&lt;/sub&gt;, ..., with the properties that each ''q''&lt;sub&gt;i&lt;/sub&gt; lies on the unit circle and that, for all ''i''&amp;nbsp;&gt;&amp;nbsp;0, ''q''&lt;sub&gt;i&lt;/sub&gt;&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''q''&lt;sub&gt;i&amp;nbsp;&amp;minus;&amp;nbsp;1&lt;/sub&gt;.  The group operation on these elements multiplies any two sequences componentwise. Each element of the dyadic solenoid corresponds to a character of the dyadic rationals that maps ''a''/2&lt;sup&gt;''b''&lt;/sup&gt; to the complex number ''q''&lt;sub&gt;''b''&lt;/sub&gt;&lt;sup&gt;''a''&lt;/sup&gt;. Conversely, every character ''&amp;chi;'' of the dyadic rationals corresponds to the  element of the dyadic solenoid given by ''q''&lt;sub&gt;''i''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''&amp;chi;''(1/2&lt;sup&gt;''i''&lt;/sup&gt;).

As a topological space the dyadic solenoid is a [[Solenoid (mathematics)|solenoid]], and an [[indecomposable continuum]].&lt;ref&gt;{{citation
  | title = The indecomposability of the dyadic solenoid
  | jstor = 2319174
  | last = Nadler | first = S. B., Jr.
  | journal = [[American Mathematical Monthly]]
  | year = 1973
  | volume = 80
  | issue = 6
  | pages = 677–679
  | doi = 10.2307/2319174}}.&lt;/ref&gt;

==Related constructions==
The [[surreal number]]s are generated by an iterated construction principle which starts by generating all finite dyadic fractions, and then goes on to create new and strange kinds of infinite, infinitesimal and other numbers.

The binary [[van der Corput sequence]] is an [[equidistributed]] [[permutation]] of the positive dyadic rational numbers.

==In music==
[[Time signature]]s in Western [[musical notation]] traditionally consist of dyadic fractions (for example: 2/2, 4/4, 6/8...), although [[Time signature#Irrational meters|non-dyadic time signatures]] have been introduced by composers in the twentieth century (for example: 2/{{music|dotted quarter}}, which would literally mean 2/{{frac|3|8}}). Non-dyadic time signatures are called ''irrational'' in musical terminology, but this usage does not correspond to the [[irrational number|irrational numbers]] of mathematics, because they still consist of ratios of integers. Irrational time signatures in the mathematical sense are very rare, but one example ({{sqrt|42}}/1) appears in [[Conlon Nancarrow]]'s ''Studies for Player Piano''.

== In computing ==
As a data type used by computers, [[floating point|floating-point numbers]] are often defined as integers multiplied by positive or negative powers of two, and thus all numbers that can be represented for instance by binary [[IEEE floating point|IEEE floating-point datatypes]] are dyadic rationals.  The same is true for the majority of [[fixed-point arithmetic|fixed-point datatypes]], which also uses powers of two implicitly in the majority of cases.

==See also==
* [[Half-integer]], a dyadic rational formed by dividing an odd number by two
* [[p-adic number|2-adic number]], a number system that extends the dyadic rationals

== References ==
{{reflist}}

{{Fractions and ratios}}
{{Rational numbers}}

[[Category:Fractions (mathematics)]]
[[Category:Rational numbers]]</text>
      <sha1>qighj1o4866x3ky2rm6nqp4225hdghw</sha1>
    </revision>
  </page>
  <page>
    <title>Ehrenpreis's fundamental principle</title>
    <ns>0</ns>
    <id>39993538</id>
    <revision>
      <id>816387608</id>
      <parentid>816387573</parentid>
      <timestamp>2017-12-21T00:48:04Z</timestamp>
      <contributor>
        <username>Cherkash</username>
        <id>10363</id>
      </contributor>
      <minor/>
      <comment>Cherkash moved page [[Ehrenpreis' fundamental principle]] to [[Ehrenpreis's fundamental principle]]: singular possessive</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1040">In mathematical analysis, '''Ehrenpreis's fundamental principle''', introduced by [[Leon Ehrenpreis]], states:&lt;ref&gt;{{cite journal | url = https://link.springer.com/content/pdf/10.1007/978-1-4614-4075-8_24.pdf|doi=10.1007/978-1-4614-4075-8_24 | title=Ehrenpreis and the Fundamental Principle |volume=28 | pages=491–507|series=Developments in Mathematics |year=2013 |last1=Treves |first1=François |isbn=978-1-4614-4074-1 }}&lt;/ref&gt;
:Every solution of a system (in general, overdetermined) of homogeneous [[partial differential equation]]s with constant [[coefficient]]s can be represented as the integral with respect to an appropriate Radon measure over the complex “[[characteristic variety]]” of the system.&lt;ref&gt;{{cite web|last=Oshima|first=Toshio|title=A Proof of Ehrenpreis' Fundamental Principle in Hyperfunctions|url=http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.pja/1195519103|accessdate=25 July 2013}}&lt;/ref&gt;

== References ==
{{reflist}}

[[Category:Mathematical analysis]]


{{analysis-stub}}</text>
      <sha1>j0mkf6g8mf0iw7mxz8vrgtzcw1rf2d2</sha1>
    </revision>
  </page>
  <page>
    <title>Empirical modelling</title>
    <ns>0</ns>
    <id>3003070</id>
    <revision>
      <id>857837178</id>
      <parentid>857250555</parentid>
      <timestamp>2018-09-03T10:14:56Z</timestamp>
      <contributor>
        <username>Steveruss</username>
        <id>30169461</id>
      </contributor>
      <minor/>
      <comment>/* Empirical Modelling */small changes to tense of last sentence.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14294">:''This article deals with the use of the term in computer science. For the use in economics, see [[Econometric model]].   For uses in other contexts, see  [[Scientific modelling#Other types|Types of scientific modeling]].''

'''Empirical modelling''' refers to any kind of ([[computer]]) [[Computer model|modelling]] based on [[empirical]] observations rather than on mathematically describable relationships of the system modelled.

==Empirical Modelling==
'''Empirical Modelling as a variety of empirical modelling'''

Empirical modelling is a generic term for activities that create models by observation and experiment. Empirical Modelling (with the initial letters capitalised, and often abbreviated to EM) refers to a specific variety of empirical modelling in which models are constructed following particular principles. Though the extent to which these principles can be applied to model-building without computers is an interesting issue (to be revisited below), there are at least two good reasons to consider Empirical Modelling in the first instance as computer-based. Without doubt, new technologies that are based on computers have had a transformative impact where the full exploitation of Empirical Modelling principles is concerned. What is more, the conception of Empirical Modelling has been closely associated with thinking about the role of the computer in model-building.

An empirical model operates on a simple semantic principle: the maker observes a close correspondence between the behaviour of the model and that of its referent. The crafting of this correspondence can be 'empirical' in a wide variety of senses: it may entail a trial-and-error process, may be based on computational approximation to analytic formulae, it may be derived as a black-box relation that affords no insight into 'why it works'.

Empirical Modelling is rooted on the key principle of William James's 'radical empiricism', which postulates that all knowing is rooted in connections that are given-in-experience. Empirical Modelling aspires to craft the correspondence between the model and its referent in such a way that its derivation can be traced to connections given-in-experience. Making connections in experience is an essentially individual human activity that requires skill and is highly context-dependent. Examples of such connections include: identifying familiar objects in the stream of thought, associating natural languages words with objects to which they refer, and subliminally interpreting the rows and columns of a spreadsheet as exam results of particular students in particular subjects.

'''Empirical Modelling principles'''

In Empirical Modelling, the process of construction is an incremental one in which the intermediate products are artefacts that evoke aspects of the intended (and sometimes emerging) referent through live interaction and observation. The connections evoked in this way have distinctive qualities: they are of their essence personal and experiential in character and are provisional in so far as they may be undermined, refined and reinforced as the model builder's experience and understanding of the referent develops. Following a precedent established by David Gooding in his account of the role that artefacts played in Michael Faraday's experimental investigation of electromagnetism, the intermediate products of the Empirical Modelling process are described as 'construals'. Gooding's account is a powerful illustration of how ''making construals'' can support the sense-making activities that lead to conceptual insights (cf. the contribution that Faraday's work made to electromagnetic theory) and to practical products (cf. Faraday's invention of the electric motor).

[[File:Making a Construal fundamentaldiagram.png|thumb|Figure 1 Making a construal]]

The activities associated with making a construal in the Empirical Modelling framework are depicted in Figure 1.

The eye icon at the centre the figure represents the maker's observation of the current state of development of the construal and its referent. The two arrows emanating from the eye represent the connection given-in-experience between the construal and its referent that is established in the mind of the maker. This connection is crafted through experimental interaction with the construal under construction and its emerging referent. As in genuine experiment, the scope of the interactions that can be entertained by the maker is inconceivably broad. At the maker's discretion, the interactions that characterise the construal are those that respect the connection given in the maker's experience. As the Empirical Modelling process unfolds, the construal, the referent, the maker's understanding and the context for the maker's engagement co-evolve in such a way that:
* the interactive experience that the construal affords is enhanced;
* the interactive experience that characterises the referent is refined;
* the repertoire of characteristic interactions with the construal and its referent is enlarged;
* the contextual constraints on characteristic interactions with the construal and its referent are identified.
'''Empirical Modelling concepts'''

In Empirical Modelling. making and maintaining the connection given-in-experience between the construal and referent is based on three primary concepts: ''observables'', ''dependencies'' and ''agency''. Within both the construal and its referent, the maker identifies '''observables''' as entities that can take on a range of different values, and whose current values determine its current state. All state-changing interactions with the construal and referent are conceived as changes to the values of observables. A change to the value of one observable may be directly attributable to a change in the value of another observable, in which case these values are linked by a '''dependency'''. Changes to observable values are attributed to '''agents''', amongst which the most important is the maker of the construal. When changes to observable values are observed to occur simultaneously, this can be construed as concurrent action on the part of different agents, or as concomitant changes to observables derived from a single agent action via dependencies. To craft the connection given-in-experience between the construal and referent, the maker constructs the construal in such a way that its observables, dependencies and agency correspond closely to those that are observed in the referent. To this end, the maker must conceive appropriate ways in which observables and agent actions in the referent can be given suitable experiential counterparts in the construal.

The semantic framework shown in Figure 1 resembles that adopted in working with spreadsheets, where the state that is currently displayed in the grid is meaningful only when experienced in conjunction with an external referent. In this setting, the cells serve as observables, their definitions specify the dependencies, and agency is enacted by changing the values or the definitions of cells. In making a construal, the maker explores the roles of each relevant agent by projecting agency upon it as if it were a human agent and identifying observables and dependencies from that perspective. By automating agency, construals can then be used to specify behaviours in much the same way that behaviours can be expressed using macros in conjunction with spreadsheets. In this way, animated construals can emulate program-like behaviours in which the intermediate states are meaningful and live to auditing by the maker.

'''Environments to support Empirical Modelling'''

The development of computer environments for making construals has been an ongoing subject of research over the last thirty years. The many variants of such environments that have been implemented are based on common principles. The network of dependencies that currently connect observables is recorded as a family of definitions. Semantically such definitions resemble the definitions of spreadsheet cells, whereby changes to the values of observables on the right hand side propagate so as to change the value of the observable on the LHS in a conceptually indivisble manner. The dependencies in these networks are acyclic but are also reconfigurable: redefining an observable may introduce a new definition that alters the dependency structure. Observables built into the environment include scalars, geometric and screen display elements: these can be elaborated using multi-level list structures. A dependency is typically represented by a definition which uses a relatively simple functional expression to relate the value of an observable to the values of other observables. Such functions have typically been expressed in fragments of simple procedural code, but the most recent variants of environments of making construals also enable dependency relations to be expressed by suitably contextualised families of definitions. The maker can interact with a construal through redefining existing observables or introducing new observables in an open-ended unconstrained manner. Such interaction has a crucial role in the experimental activity that informs the incremental development of the construal. Triggered actions can be introduced to automate state-change: these perform redefinitions in response to specified changes in the values of observables.

'''Empirical Modelling as a broader view of computing'''

In Figure 1, identifying 'the computer' as the medium in which the construal is created is potentially misleading. The term COMPUTER is not merely a reference to a powerful computational device. In making construals, the primary emphasis is on the rich potential scope for interaction and perceptualisation that the computer enables when used in conjunction with other technologies and devices. The primary motivation for developing Empirical Modelling is to give a satisfactory account of computing that integrates these two complementary roles of the computer. The principles by which James and Dewey sought to reconcile perspectives on agency informed by logic and experience play a crucial role in achieving this integration.

The dual role for the computer implicit in Figure 1 is widely relevant to contemporary computing applications. On this basis, Empirical Modelling can be viewed as providing a foundation for a broader view of computing. This perspective is reflected in numerous Empirical Modelling publications on topics such as educational technology, computer-aided design and software development. Making construals has also been proposed as a suitable technique to support constructionism, as conceived by Seymour Papert, and to meet the guarantees for 'construction' as identified by Bruno Latour.

'''Empirical Modelling as generic sense-making?'''

The Turing machine provides the theoretical foundation for the role of the computer as a computational device: it can be regarded as modelling 'a mind following rules'. The practical applications of Empirical Modelling to date suggest that making construals is well-suited to supporting the supplementary role the computer can play in orchestrating rich experience. In particular, in keeping with the pragmatic philosophical stance of James and Dewey, making construals can fulfill an explanatory role by offering contingent explanations for human experience in contexts where computational rules cannot be invoked. In this respect, making construals may be regarded as modelling 'a mind making sense of a situation'.

In the same way that the Turing machine is a conceptual tool for understanding the nature of algorithms whose value is independent of the existence of the computer, Empirical Modelling principles and concepts may have generic relevance as a framework for thinking about sense-making without specific reference to the use of a computer. The contribution that William James's analysis of human experience makes to the concept of Empirical Modelling may be seen as evidence for this. By this token, Empirical Modelling principles may be an appropriate way to analyse varieties of empirical modelling that are not computer-based. For instance, it is plausible that the analysis in terms of observables, dependencies and agency that applies to interaction with electronic spreadsheets would also be appropriate for the manual spreadsheets that predated them.

'''Background'''

Empirical Modelling has been pioneered since the early 1980s by Meurig Beynon and the Empirical Modelling Research Group in Computer Science at the University of Warwick.

The term 'Empirical Modelling' (EM) has been adopted for this work since about 1995 to reflect the experiential basis of the modelling process in observation and experiment. Special purpose software supporting the central concepts of observable, dependency and agency has been under continuous development (mainly led by research students) since the late 1980s.

The principles and tools of EM have been used and developed by many hundreds of students within coursework, project work, and research theses. The undergraduate and MSc module 'Introduction to Empirical Modelling' was taught for many years up to 2013-14 until the retirement of Meurig Beynon and Steve Russ (authors of this article). There is a large website [1] containing research and teaching material with an extensive collection of refereed publications and conference proceedings.

The term 'construal' has been used since the early 2000s for the artefacts, or models, made with EM tools. The term has been adapted from its use by David Gooding in the book 'Experiment and the Making of Meaning' (1990) to describe the emerging, provisional ideas that formed in Faraday's mind, and were recorded in his notebooks, as he investigated electromagnetism, and made the first electric motors, in the 1800s.

The main practical activity associated with EM - that of 'making construals' - was the subject of an Erasmus+ Project CONSTRUIT! (2014-2017)[2].

== External links, Notes, References to be added soon ==
* 
[1] http://www.dcs.warwick.ac.uk/modelling/ Empirical Modelling Research Group

[2] https://warwick.ac.uk/fac/sci/dcs/research/em/welcome/   CONSTRUIT! Project web pages

{{Reflist}}

[[Category:Mathematical modeling]]</text>
      <sha1>svo9fx1r95vpaktw5fdzahhmxifhyrp</sha1>
    </revision>
  </page>
  <page>
    <title>Extended side</title>
    <ns>0</ns>
    <id>43958459</id>
    <revision>
      <id>796539927</id>
      <parentid>717627488</parentid>
      <timestamp>2017-08-21T14:53:49Z</timestamp>
      <contributor>
        <username>WOSlinker</username>
        <id>3138265</id>
      </contributor>
      <minor/>
      <comment>fix image options</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2987">[[Image:Incircle and Excircles.svg|thumb|300px|Each of a triangle's excircles (orange) is tangent to one of the triangle's sides and to the other two extended sides. ]]

In [[plane geometry]], an '''extended side''' or '''sideline''' of a [[polygon]] is the [[line (geometry)|line]] that contains one [[Edge (geometry)|side]] of the polygon. The extension of a side arises in various contexts.

==Triangle==

In an [[obtuse triangle]], the [[altitude (triangle)|altitudes]] from the [[acute angle]]d [[vertex (geometry)|vertices]] intersect the corresponding extended base sides but not the base sides themselves.  

The [[excircle]]s of a triangle, as well as the triangle's [[inconic]]s that are not [[inellipse]]s, are externally [[tangent]] to one side and to the other two extended sides.

[[Trilinear coordinates]] locate a point in the plane by its relative distances from the extended sides of a reference triangle. If the point is outside the triangle, the perpendicular from the point to the sideline may meet the sideline outside the triangle&amp;mdash;that is, not on the actual side of the triangle.

In a triangle, three intersection points, each of an [[external angle]] [[bisection|bisector]] with the opposite extended side, are [[collinearity|collinear]].&lt;ref name=Johnson&gt;Johnson, Roger A., ''Advanced Euclidean Geometry'', Dover Publ., 2007 (orig. 1929).&lt;/ref&gt;{{rp|p. 149}}

In a triangle, three intersection points, two of them between an [[interior angle]] bisector and the opposite side, and the third between the other exterior angle bisector and the opposite side extended, are collinear.&lt;ref name=Johnson/&gt;{{rp|p. 149}}

==Ex-tangential quadrilateral==

[[File:Ex-tangential quadrilateral.png|400px|thumb|An ex-tangential quadrilateral ''ABCD'' and its excircle]]

An [[ex-tangential quadrilateral]] is a [[quadrilateral]] for which there exists a circle that is tangent to all four extended sides. The excenter (center of the tangent circle) lies at the intersection of six [[angle bisector]]s. These are the [[internal angle]] bisectors at two opposite vertex angles, the [[external angle]] bisectors ([[supplementary angle]] bisectors) at the other two vertex angles, and the external angle bisectors at the angles formed where the extensions of opposite sides intersect.

==Hexagon==
[[File:THPascal.svg|thumb|350px|right|The intersections of the extended opposite sides of inscribed hexagon ABCDEF lie on the blue '''Pascal line''' MNP. The hexagon's extended sides are in gray and red.]]

[[Pascal's theorem]] states that if six arbitrary points are chosen on a [[conic section]] (i.e., [[ellipse]], [[parabola ]] or [[hyperbola]]) and joined by line segments in any order to form a [[hexagon]], then the three pairs of opposite sides of the hexagon (extended if necessary) meet in three points which lie on a straight line, called the Pascal line of the hexagon.

==References==

{{reflist}}



[[Category:Elementary geometry]]
[[Category:Triangle geometry]]</text>
      <sha1>c4ywt6n8wt67t0yog8cbmjv75bfvexr</sha1>
    </revision>
  </page>
  <page>
    <title>Fractal art</title>
    <ns>0</ns>
    <id>48253</id>
    <revision>
      <id>842671971</id>
      <parentid>842671898</parentid>
      <timestamp>2018-05-23T22:38:14Z</timestamp>
      <contributor>
        <username>Pepperwatts</username>
        <id>32660048</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16412">[[File:Hindu Temple Design.jpg|thumb|[[Hindu_temple_architecture|Hindu temples]] feature self-similar, fractal-like structures, where parts resemble the whole.&lt;ref&gt;{{cite journal|last1=Trivedi|first1=K.|title=Hindu Temples: Models of a Fractal Universe|journal=The Visual Computer|date=1989|volume=5|issue=4|page=243-258}}&lt;/ref&gt;]]

[[File:Selimiye Mosque, Dome.jpg|thumb|[[Islamic geometric patterns]] are reminiscent of fractal art, as on the main dome of [[Selimiye Mosque (Edirne)|Selimiye Mosque]] in [[Edirne]], Turkey, with [[self-similar]] patterns.]]
[[Image:Julian fractal.jpg|thumb|upright|A piece generated in [[Apophysis (software)|Apophysis]]]]
[[File:NonIntegerMultibrot - Breaking of Space.jpg|thumb|right|A detail from a non-integer [[Multibrot set]]]]

'''Fractal art''' is a form of [[algorithmic art]] created by calculating [[fractal]] objects and representing the calculation results as still images, animations, and [[Algorithmic composition|media]]. Fractal art developed from the mid-1980s onwards.&lt;ref name="fgad"&gt;{{cite book |title=Fractal geometry in architecture and design |last=Bovill |first=Carl |year=1996 |publisher=Birkhauser |location=Boston |isbn=0-8176-3795-8 |page=153 |url=https://books.google.com/books?id=w5ptaiGsac4C |accessdate=28 October 2011}}&lt;/ref&gt; It is a genre of [[computer art]] and [[digital art]] which are part of [[new media art]]. The [[mathematical beauty]] of fractals lies at the intersection of [[generative art]] and [[computer art]].  They combine to produce a type of [[abstract art]].

Fractal art (especially in the western world) is rarely drawn or painted by hand. It is usually created indirectly with the assistance of [[fractal-generating software]], iterating through three phases: setting parameters of appropriate fractal software; executing the possibly lengthy calculation; and evaluating the product. In some cases, other [[graphics software|graphics programs]] are used to further modify the images produced. This is called post-processing. Non-fractal imagery may also be integrated into the artwork.&lt;ref name="mra"&gt;{{cite web |url=http://www.casperjournal.com/article_bbe58a64-0b86-5e64-8fc5-459eafbe67fb.html |title=Meet Reginald Atkins, mathematical artist |author=Elysia Conner |date=February 25, 2009 |publisher=CasperJournal.com |accessdate=October 28, 2011 }}&lt;/ref&gt; The [[Julia set]] and [[Mandelbrot set]]s can be considered as [[icon]]s of fractal art.&lt;ref name="hema"&gt;{{cite book |title=The heart of mathematics: an invitation to effective thinking |last=Burger |first=Edward B. |author2=Michael P. Starbird |year=2005 |publisher=Springer |isbn=1-931914-41-9 |page=475 |url=https://books.google.com/books?id=M-qK8anbZmwC |accessdate=30 October 2011}}&lt;/ref&gt;

It was assumed that fractal art could not have developed without computers because of the [[calculation|calculative]] capabilities they provide.&lt;ref name="dima"&gt;{{cite book |title=Digital Mantras: The languages of abstract and virtual worlds |last=Steven R. |first=Holtzman |year=1995 |publisher=MIT Press |isbn=0-262-58143-4 |page=241 |url=https://books.google.com/books?id=gc5hnRuABy0C |accessdate=28 October 2011}}&lt;/ref&gt;  Fractals are generated by applying [[Iteration|iterative]] methods to solving non-linear equations or [[polynomial equation]]s. Fractals are any of various extremely irregular curves or shapes for which any suitably chosen part is similar in shape to a given larger or smaller part when magnified or reduced to the same size.&lt;ref&gt;[http://www.merriam-webster.com/dictionary/fractal Fractal - Definition]. Free Merriam-Webster Dictionary.&lt;/ref&gt;
[[File:AmidstFractalArt.png|thumb|A piece generated by Mandelbulb3D.]] 
==Types==
[[File:FWF Samuel Monnier détail.jpg|thumb|left|upright|A [[Fibonacci word]] fractal]]
[[File:Mandelbulb072a.JPG|thumb|upright|A 3D [[Mandelbulb]] fractal generated using Visions of Chaos]]
[[File:Lai4d fractal tetrahedron fantasy.jpg|thumb|left|upright|3D fractal fantasy generated using LAI4D]]
There are many different kinds of fractal images and can be subdivided into several groups. 
* Fractals derived from standard geometry by using iterative transformations on an initial common figure like a straight line (the Cantor dust or the [[Koch snowflake|von Koch curve]]), a triangle (the [[Sierpinski triangle]]), or a cube (the [[Menger sponge]]). The first fractal figures invented near the end of the 19th and early 20th centuries belong to this group.
* IFS ([[iterated function systems]])
* [[Strange attractors]]
* [[Flame fractals|Fractal flame]]
* [[L-system]] fractals
* Fractals created by the iteration of complex [[polynomial]]s:  perhaps the most famous fractals.
* [[Newton fractal]]s, including [[Nova fractal]]s
* [[Quaternionic]] and (recently) hypernionic{{clarify||date=January 2014}} fractals&lt;ref&gt;[http://paulbourke.net/fractals/quatjulia/ Quaternion Julia Fractals]&lt;/ref&gt;
* [[Fractal terrain]]s generated by random fractal processes&lt;ref&gt;[https://www.fractalus.com/fractal-art-faq/faq03.html#3a Fractal Art FAQ]&lt;/ref&gt;
* [[Mandelbulb]]s are a kind of three dimensional fractal.

[[Fractal Expressionism]] is a term used to differentiate traditional visual art that incorporates fractal elements such as [[self-similarity]] for example.  Perhaps the best example of fractal expressionism is found in [[Jackson Pollock]]'s dripped patterns.  They have been analysed and found to contain a [[fractal dimension]] which has been attributed to his technique.&lt;ref name="coex"&gt;{{cite book |title=Complexity explained |last=Érdi |first=Péter |authorlink=Péter Érdi|year=2008 |publisher=Springer |isbn=3-540-35777-7 |page=214 |url=https://books.google.com/books?id=JwgpLvknc8wC |accessdate=29 October 2011}}&lt;/ref&gt;

==Techniques==
[[File:Electricsheep-14525.jpg|thumb|Fractal image generated by [[Electric Sheep]]]]
{{main|Fractal-generating software}}
Fractals of all kinds have been used as the basis for digital art and animation. High resolution color graphics became increasingly available at scientific research labs in the mid-1980s.  Scientific forms of art, including fractal art, have developed separately from [[mainstream]] culture.&lt;ref name="ciem"&gt;{{cite book |title=Critical issues in electronic media |last=Penny |first=Simon |year=1995 |publisher=State University of New York Press |isbn=0-7914-2317-4 |pages=81–82 |url=https://books.google.com/books?id=vzFJnyBjaLMC |accessdate=29 October 2011}}&lt;/ref&gt; Starting with 2-dimensional details of fractals, such as the Mandelbrot Set, fractals have found artistic application in fields as varied as texture generation, plant growth simulation and landscape generation.

Fractals are sometimes combined with [[evolutionary algorithms]], either by iteratively choosing good-looking specimens in a set of random variations of a fractal artwork and producing new variations, to avoid dealing with cumbersome or unpredictable parameters, or collectively, as in the [[Electric Sheep]] project, where people use [[fractal flame]]s rendered with [[distributed computing]] as their [[screensaver]] and "rate" the flame they are viewing, influencing the server, which reduces the traits of the undesirables, and increases those of the desirables to produce a computer-generated, community-created piece of art.

Many fractal images are admired because of their perceived [[Principles of art#Harmony|harmony]]. This is typically achieved by the [[pattern]]s which emerge from the [[Principles of art#Balance|balance]] of order and [[Chaos theory|chaos]]. Similar qualities have been described in [[Chinese painting]] and [[Penjing|miniature trees and rockeries]].&lt;ref name="caftc"&gt;{{cite book |title=Chaos, complexity, curriculum and culture |editor1-first=William E. |editor1-last=Doll, Jr |editor2-first=Jayne |editor2-last=Fleener |editor3-first=Donna |editor3-last=Trueit |editor4-first=John |display-editors = 3 |editor4-last=St. Julien |last=Wang |first=Hongyu |chapter=Chinese aesthetics, Fractals and the Tao of Curriculum |year=2005 |publisher=Peter Lang Publishing |location=New York |isbn=978-0-8204-6780-1 |page=301 |url=https://books.google.com/books?id=fROt7Yjz3xgC |accessdate=28 October 2011}}&lt;/ref&gt;

==Landscapes==
&lt;gallery&gt;
Image:Mandelbrot island.jpg|A 3D landscape generated with [[Terragen]], using the Mandelbrot set
File:Sark-aerial.jpg|The real island of [[Sark]]
&lt;/gallery&gt;
{{main|Fractal landscape}}
The first fractal image that was intended to be a work of art was probably the famous one on the cover of ''[[Scientific American]]'', August 1985. This image showed a [[landscape]] formed from the potential function on the domain outside the (usual) [[Mandelbrot set]]. However, as the potential function grows fast near the boundary of the Mandelbrot set, it was necessary for the creator to let the landscape grow downwards, so that it looked as if the Mandelbrot set was a [[plateau]] atop a mountain with steep sides. The same technique was used a year after in some images in ''[[The Beauty of Fractals]]'' by [[Heinz-Otto Peitgen]] and [[Michael M. Richter]]. They provide a formula to estimate the distance from a point outside the Mandelbrot set to the boundary of the Mandelbrot set (and a similar formula for the Julia sets). Landscapes can, for example, be formed from the distance function for a family of iterations of the form &lt;math&gt;z^{2} + az^{4} + c&lt;/math&gt;.

==Artists==
Notable fractal artists include [[Desmond Paul Henry]], [[Hamid Naderi Yeganeh]] and musician [[Bruno Degazio]].  The British artist [[William Latham (computer scientist)|William Latham]], has used fractal geometry and other computer graphics techniques in his works.&lt;ref name="fpc"&gt;{{cite book |title=Fractals: The Patterns of Chaos |last=Briggs |first=John |authorlink=John Briggs (author) |year=1992 |publisher=Thames and Hudson |location=London |isbn=0-500-27693-5 |page=169 }}&lt;/ref&gt; [[Greg Sams]] has used fractal designs in postcards, T-shirts and textiles. American [[Vicky Brago-Mitchell]] has created fractal art which has appeared in exhibitions and on magazine covers. [[Scott Draves]] is credited with inventing flame fractals. [[Carlos Ginzburg]] has explored fractal art and developed a concept called "homo fractalus" which is based around the idea that the human is the ultimate fractal.&lt;ref name="cagi"&gt;{{cite web |url=http://muse.jhu.edu/journals/leonardo/v034/34.1ginzburg.html |title=Carlos Ginzburg |year=2001 |work=[[Leonardo (journal)|Leonardo]] |publisher=[[Leonardo,_The_International_Society_of_the_Arts,_Sciences_and_Technology|Leonardo/ISAST]], the International Society for the Arts, Sciences and Technology |accessdate=29 October 2011 }}&lt;/ref&gt; Merrin Parkers from New Zealand specialises in fractal art.&lt;ref name="hfn"&gt;{{cite book |title=Heaven's fractal net: retrieving lost visions in the humanities, Volume 1 |last=Jackson |first=William Joseph |year=2004 |publisher=Indiana University Press |isbn=0-253-21620-6 |page=116 |url=https://books.google.com/books?id=U0rJz7FC2z8C |accessdate=30 October 2011}}&lt;/ref&gt; 
[[Kerry Mitchell]] wrote a "Fractal Art Manifesto", claiming that&lt;ref name=manifesto&gt;{{cite web |url=https://www.fractalus.com/info/manifesto.htm |title=The Fractal Art Manifesto |author=Mitchell, Kerry |authorlink=Kerry Mitchell |date= |accessdate=28 December 2015}}&lt;/ref&gt;

{{quote|Fractal Art is a subclass of two-dimensional visual art, and is in many respects similar to photography—another art form that was greeted by skepticism upon its arrival. Fractal images typically are manifested as [[Printmaking|prints]], bringing fractal artists into the company of painters, photographers, and printmakers. Fractals exist natively as electronic images. This is a format that traditional visual artists are quickly embracing, bringing them into Fractal Art's digital realm. Generating fractals can be an artistic endeavor, a mathematical pursuit, or just a soothing diversion. However, Fractal Art is clearly distinguished from other digital activities by what it is, and by what it is not.&lt;ref name=manifesto/&gt;}}

According to Mitchell, fractal art is not computerized art, lacking in rules, unpredictable, nor something that any person with access to a computer can do well. Instead, fractal art is expressive, creative, and requires input, effort, and intelligence. Most importantly, "fractal art is simply that which is created by Fractal Artists: ART."&lt;ref name=manifesto/&gt;

More recently, American artist Hal Tenny was hired to design environment in [[Guardians of the Galaxy Vol. 2]].

==Exhibits==
[[File:Burst Fractal Art Show.jpg|thumb|left|upright|Fractal art exhibition, 2013]]
Fractal art has been exhibited at major international art galleries.&lt;ref name="aue"&gt;{{cite book |title=The artful universe expanded |last=Barrow |first=John D. |authorlink=John D. Barrow |year=1995 |publisher=Oxford University Press |isbn=0-19-280569-X |page=69 |url=https://books.google.com/books?id=sXQJbl5mamcC |accessdate=28 October 2011}}&lt;/ref&gt; One of the first exhibitions of fractal art was "Map Art", a travelling exhibition of works from researchers at the [[University of Bremen]].&lt;ref name="funa"&gt;{{cite book |title=FutureNatural |last=Robertson |first=George |year=1996 |publisher=Routledge |location=London |isbn=0-415-07013-9 |pages=220–221 |url=https://books.google.com/books?id=zby751yKI_kC |accessdate=28 October 2011}}&lt;/ref&gt; Mathematicians [[Heinz-Otto Peitgen]] and [[Michael M. Richter]] discovered that the public not only found the images aesthetically pleasing but that they also wanted to understand the scientific background to the images.&lt;ref name="asc"&gt;{{cite web |url=http://www.uiowa.edu/~commstud/resources/digitalmedia/wright.html |title=Art and Science in Chaos: Contesting Readings of Scientific Visualisation |author=Richard Wright |work=ISEA'94 Proceedings - The Next Generation |publisher=University of Iowa |accessdate=28 October 2011 |deadurl=yes |archiveurl=https://web.archive.org/web/20111001183453/http://www.uiowa.edu/~commstud/resources/digitalmedia/wright.html |archivedate=1 October 2011 |df= }}&lt;/ref&gt;

In 1989, fractals were part of the subject matter for an art show called ''Strange Attractors: Signs of Chaos'' at the [[New Museum of Contemporary Art]].&lt;ref name="ciem"/&gt; The show consisted of photographs, installations and sculptures designed to provide greater scientific [[discourse]] to the field which had already captured the public's attention through colourful and intricate computer imagery.

==See also==
{{Portal|Visual arts|Computer graphics|Computer Science|Mathematics}}
* [[Batik]]
* [[Mathematics and architecture]]
* [[Persian carpet]]
* [[Psychedelic art]]
* [[Systems art]]
* [[Infinite compositions of analytic functions]]
{{-}}

==References==
{{Reflist|30em}}

==Further reading==
* {{cite book |last=Duarte |first=German A.| title=Fractal Narrative. About the Relationship Between Geometries and Technology and Its Impact on Narrative Spaces|date=2014 |publisher=Transcript-Verlag |isbn=9783837628296}}
* {{cite book |last=Pickover |first=Clifford | authorlink=Clifford A. Pickover |title=Computers, Pattern, Chaos and Beauty |date=1990 |publisher=St. Martin's Press |isbn=0-486-41709-3}}
* {{cite book |last=Schroeder |first=Manfred| title=Fractals, Chaos, Power Laws |date=1991 |publisher=Freeman |isbn=0-7167-2357-3}}

==External links==
{{Prone to spam|date=September 2012}}
{{Z148}}&lt;!--     {{No more links}}

       Please be cautious adding more external links.

Wikipedia is not a collection of links and should not be used for advertising.

     Excessive or inappropriate links will be removed.

 See [[Wikipedia:External links]] and [[Wikipedia:Spam]] for details.

If there are already suitable links, propose additions or replacements on
the article's talk page, or submit your link to the relevant category at 
the Open Directory Project (dmoz.org) and link there  using {{Dmoz}}.

--&gt;
{{Commons category|Fractal art}}
* {{dmoz|Science/Math/Chaos_and_Fractals/Fractal_art/|Fractal Art}}
* [[commons:Mandelbrot set#Some details of the Mandelbrot set|Art and the Mandelbrot set (in commons.Wikimedia)]]
* [[commons:Fractal|Fractals in Wikimedia]]

{{Fractal software}}
{{Mathematical art}}
{{Abstract art}}

[[Category:Fractals]]
[[Category:Abstract art]]
[[Category:Abstract animation]]
[[Category:Computer graphic techniques]]
[[Category:Algorithmic art]]
[[Category:Psychedelic art]]
[[Category:Digital art]]</text>
      <sha1>feryfzti0gbrv97ula6yhfdgz377es3</sha1>
    </revision>
  </page>
  <page>
    <title>Golden angle</title>
    <ns>0</ns>
    <id>315659</id>
    <revision>
      <id>833446148</id>
      <parentid>750210434</parentid>
      <timestamp>2018-03-31T16:10:57Z</timestamp>
      <contributor>
        <username>Wbm1058</username>
        <id>14383484</id>
      </contributor>
      <minor/>
      <comment>spelling correction</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3904">{{for|the butterfly|Caprona ransonnetii}}

[[File:Golden Angle.svg|right|thumb|The golden angle is the angle subtended by the smaller (red) arc when two arcs that make up a circle are in the [[golden ratio]]]]

In [[geometry]], the '''golden angle''' is the smaller of the two [[angle]]s created by sectioning the circumference of a circle according to the [[golden ratio]]; that is, into two [[Arc (geometry)|arc]]s such that the ratio of the length of the larger arc to the length of the smaller arc is the same as the ratio of the full circumference to the length of the larger arc.

Algebraically, let ''a+b'' be the circumference of a [[circle]], divided into a longer arc of length ''a'' and a smaller arc of length ''b'' such that

:&lt;math&gt; \frac{a + b}{a} = \frac{a}{b} &lt;/math&gt;

The golden angle is then the angle [[subtend]]ed by the smaller arc of length ''b''. It measures approximately 137.5077640500378546463487 ...°  {{OEIS2C|id=A096627}} or in [[radian]]s 2.39996322972865332 ...  {{OEIS2C|id=A131988}}.

The name comes from the golden angle's connection to the [[golden ratio]] ''&amp;phi;''; the exact value of the golden angle is

: &lt;math&gt;360\left(1 - \frac{1}{\varphi}\right) = 360(2 - \varphi) = \frac{360}{\varphi^2} = 180(3 - \sqrt{5})\text{ degrees}&lt;/math&gt;

or

: &lt;math&gt; 2\pi \left( 1 - \frac{1}{\varphi}\right) = 2\pi(2 - \varphi) = \frac{2\pi}{\varphi^2} = \pi(3 - \sqrt{5})\text{ radians},&lt;/math&gt;

where the equivalences follow from well-known algebraic properties of the golden ratio.

== Derivation ==
The golden ratio is equal to ''&amp;phi;''&amp;nbsp;=&amp;nbsp;''a''/''b'' given the conditions above.

Let ''&amp;fnof;'' be the fraction of the circumference subtended by the golden angle, or equivalently, the golden angle divided by the angular measurement of the circle.

:&lt;math&gt; f = \frac{b}{a+b} = \frac{1}{1+\varphi}.&lt;/math&gt;

But since

: &lt;math&gt;{1+\varphi} = \varphi^2,&lt;/math&gt;

it follows that

:&lt;math&gt; f = \frac{1}{\varphi^2} &lt;/math&gt;

This is equivalent to saying that ''&amp;phi;''&lt;sup&gt;&amp;nbsp;2&lt;/sup&gt; golden angles can fit in a circle.

The fraction of a circle occupied by the golden angle is therefore

:&lt;math&gt;f \approx 0.381966. \,&lt;/math&gt;

The golden angle ''g'' can therefore be numerically approximated in [[Degree (angle)|degrees]] as:

:&lt;math&gt;g \approx 360 \times 0.381966 \approx 137.508^\circ,\,&lt;/math&gt;

or in radians as :

:&lt;math&gt; g \approx 2\pi \times 0.381966 \approx 2.39996. \,&lt;/math&gt;

== Golden angle in nature ==
[[File:Goldener Schnitt Blattstand.png|thumb|right|300px|The angle between successive florets in some flowers is the golden angle.]]

The golden angle plays a significant role in the theory of [[phyllotaxis]]; for example, the golden angle is the angle separating the [[floret]]s on a [[sunflower]].&lt;ref&gt;{{cite web
| url        = http://news.mit.edu/2012/sunflower-concentrated-solar-0111
| title      = Here comes the sun
| author     = Jennifer Chu
| work       = MIT News
| date       = 2011-01-12
| accessdate = 2016-04-22
}}&lt;/ref&gt;

== References ==
{{Reflist}}
{{refbegin}}
*{{Cite journal
  | last =Vogel
  | first =H
  | title =A better way to construct the sunflower head
  | journal =Mathematical Biosciences
  | issue =44
  | pages =179–189
  | year =1979
  | doi =10.1016/0025-5564(79)90080-4
  | volume =44
}}
*{{cite book
  | last =Prusinkiewicz
  | first =Przemysław
  | authorlink =Przemysław Prusinkiewicz
  |author2=Lindenmayer, Aristid |authorlink2=Aristid Lindenmayer 
  | title =The Algorithmic Beauty of Plants
  | publisher =Springer-Verlag
  | date =1990
  | location =
  | pages =101&amp;ndash;107
  | url =http://algorithmicbotany.org/papers/#abop
  | doi =
  | isbn = 978-0-387-97297-8 }}
{{refend}}

== External links ==
{{commons category|Golden angle}}
* [http://mathworld.wolfram.com/GoldenAngle.html Golden Angle] at [[MathWorld]]

{{Metallic ratios}}

[[Category:Elementary geometry]]
[[Category:Golden ratio]]
[[Category:Angle]]</text>
      <sha1>789zgeq96s1k7fvj2tjhv8cvu3jhw6x</sha1>
    </revision>
  </page>
  <page>
    <title>Gorenstein scheme</title>
    <ns>0</ns>
    <id>48497362</id>
    <revision>
      <id>721307259</id>
      <parentid>705529280</parentid>
      <timestamp>2016-05-20T23:34:41Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>Remove blank line(s) between list items per [[WP:LISTGAP]] to fix an accessibility issue for users of [[screen reader]]s. Do [[WP:GENFIXES]] and cleanup if needed. Discuss this at [[Wikipedia talk:WikiProject Accessibility#LISTGAP]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5839">In algebraic geometry, a '''Gorenstein scheme''' is a [[glossary of algebraic geometry#local|locally Noetherian]] [[scheme (mathematics)|scheme]] whose local rings are all [[Gorenstein ring|Gorenstein]].&lt;ref&gt;Kollár (2013), section 2.5; {{Citation | title=Stacks Project, Tag 0AWV | url=http://stacks.math.columbia.edu/tag/0AWV}}.&lt;/ref&gt; The [[canonical line bundle]] is defined for any Gorenstein scheme over a [[field (mathematics)|field]], and its properties are much the same as in the special case of [[smooth scheme]]s.

==Related properties==

For a Gorenstein scheme ''X'' of [[Glossary of algebraic geometry#finite type (locally)|finite type]] over a field, ''f'': ''X'' → Spec(''k''), the [[dualizing complex]] ''f''&lt;sup&gt;!&lt;/sup&gt;(''k'') on ''X'' is a [[invertible sheaf|line bundle]] (called the '''canonical bundle''' ''K''&lt;sub&gt;''X''&lt;/sub&gt;), viewed as a complex in degree −dim(''X'').&lt;ref&gt;Hartshorne (1966), Proposition V.9.3.&lt;/ref&gt; If ''X'' is smooth of dimension ''n'' over ''k'', the canonical bundle ''K''&lt;sub&gt;''X''&lt;/sub&gt; can be identified with the line bundle Ω&lt;sup&gt;''n''&lt;/sup&gt; of top-degree [[Kahler differentials#Use in algebraic geometry|differential forms]].&lt;ref&gt;Hartshorne (1966), section III.1.&lt;/ref&gt;

Using the canonical bundle, [[Serre duality]] takes the same form for Gorenstein schemes as it does for smooth schemes.

Let ''X'' be a [[normal scheme]] of finite type over a field ''k''. Then ''X'' is [[regular scheme|regular]] outside a closed subset of [[codimension]] at least 2. Let ''U'' be the open subset where ''X'' is regular; then the canonical bundle ''K''&lt;sub&gt;''U''&lt;/sub&gt; is a line bundle. The restriction from the [[divisor class group]] Cl(''X'') to Cl(''U'') is an isomorphism, and (since ''U'' is smooth) Cl(''U'') can be identified with the [[Picard group]] Pic(''U''). As a result, ''K''&lt;sub&gt;''U''&lt;/sub&gt; defines a [[divisor class group|linear equivalence]] class of [[Weil divisor]]s on ''X''. Any such divisor is called the '''canonical divisor''' ''K''&lt;sub&gt;''X''&lt;/sub&gt;. For a normal scheme ''X'', the canonical divisor ''K''&lt;sub&gt;''X''&lt;/sub&gt; is said to be '''Q-Cartier''' if some positive multiple of the Weil divisor ''K''&lt;sub&gt;''X''&lt;/sub&gt; is [[Cartier divisor|Cartier]]. (This property does not depend on the choice of Weil divisor in its linear equivalence class.) Alternatively, normal schemes ''X'' with ''K''&lt;sub&gt;''X''&lt;/sub&gt; '''Q'''-Cartier are sometimes said to be '''Q-Gorenstein'''.

It is also useful to consider the normal schemes ''X'' for which the canonical divisor ''K''&lt;sub&gt;''X''&lt;/sub&gt; is '''Cartier'''. Such a scheme is sometimes said to be '''Q-Gorenstein of index 1'''. (Some authors use "Gorenstein" for this property, but that can lead to confusion.) A normal scheme ''X'' is Gorenstein (as defined above) if and only if ''K''&lt;sub&gt;''X''&lt;/sub&gt; is Cartier and ''X'' is [[Cohen–Macaulay ring|Cohen–Macaulay]].&lt;ref&gt;Kollár &amp; Mori (1998), Corollary 5.69.&lt;/ref&gt;

==Examples==

*An [[algebraic variety]] with [[complete intersection ring|local complete intersection]] singularities, for example any [[hypersurface]] in a smooth variety, is Gorenstein.&lt;ref&gt;Eisenbud (1995), Corollary 21.19.&lt;/ref&gt;
*A variety ''X'' with quotient singularities over a field of [[characteristic of a field|characteristic]] zero is Cohen–Macaulay, and ''K''&lt;sub&gt;''X''&lt;/sub&gt; is '''Q'''-Cartier. The quotient variety of a vector space ''V'' by a linear action of a finite group ''G'' is Gorenstein if ''G'' maps into the subgroup SL(''V'') of linear transformations of [[determinant]] 1. By contrast, if ''X'' is the quotient of '''C'''&lt;sup&gt;2&lt;/sup&gt; by the [[cyclic group]] of order ''n'' acting by scalars, then ''K''&lt;sub&gt;''X''&lt;/sub&gt; is not Cartier (and so ''X'' is not Gorenstein) for ''n'' ≥ 3.
*Generalizing the previous example, every variety ''X'' with [[canonical singularity#Pairs|klt]] (Kawamata log terminal) singularities over a field of characteristic zero is Cohen–Macaulay, and ''K''&lt;sub&gt;''X''&lt;/sub&gt; is '''Q'''-Cartier.&lt;ref&gt;Kollár &amp; Mori (1998), Theorems 5.20 and 5.22.&lt;/ref&gt;
*If a variety ''X'' has [[canonical singularity#Pairs|log canonical]] singularities, then ''K''&lt;sub&gt;''X''&lt;/sub&gt; is '''Q'''-Cartier, but ''X'' need not be Cohen–Macaulay. For example, any [[affine cone]] ''X'' over an [[abelian variety]] ''Y'' is log canonical, and ''K''&lt;sub&gt;''X''&lt;/sub&gt; is Cartier, but ''X'' is not Cohen–Macaulay when ''Y'' has dimension at least 2.&lt;ref&gt;Kollár (2013), Example 3.6.&lt;/ref&gt;

== Notes ==
{{reflist|2}}

==References==
*{{Citation | last1=Eisenbud | first1=David | author1-link=David Eisenbud | title=Commutative Algebra with a View toward Algebraic Geometry | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=[[Graduate Texts in Mathematics]] | isbn=978-0-387-94268-1 | mr=1322960 | year=1995 | volume=150}}
* {{Citation | last1=Hartshorne | first1=Robin | author1-link=Robin Hartshorne | title=Residues and Duality | publisher=[[Springer-Verlag]] | location=Berlin, New York | series=Lecture Notes in Mathematics | volume=20 | year=1966 | isbn=978-3-540-03603-6 | mr=0222093}}
*{{Citation | author1-first=János | author1-last=Kollár | author1-link=János Kollár | title=Singularities of the Minimal Model Program | publisher=[[Cambridge University Press]] | year=2013 | isbn=978-1-107-03534-8 | mr=3057950 }}
*{{Citation | author1-first=János | author1-last=Kollár | author1-link=János Kollár | author2-first=Shigefumi | author2-last=Mori | author2-link=Shigefumi Mori| title=Birational Geometry of Algebraic Varieties | publisher=[[Cambridge University Press]] | year=1998 | isbn=0-521-63277-3 | mr=1658959}}

==External links==
*{{Citation | author1=The Stacks Project Authors | title=The Stacks Project  | url=http://stacks.math.columbia.edu/}}

[[Category:Algebraic geometry]]
[[Category:Algebraic varieties]]
[[Category:Scheme theory]]</text>
      <sha1>t0smgv9xbma9zovr280dk3dux4slw08</sha1>
    </revision>
  </page>
  <page>
    <title>Graded poset</title>
    <ns>0</ns>
    <id>2514970</id>
    <revision>
      <id>808718852</id>
      <parentid>744905630</parentid>
      <timestamp>2017-11-04T18:19:26Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>[[Catherine Yan]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13166">[[Image:Hasse diagram of powerset of 3.svg|thumb|right|300px|A [[power set]], [[Partial order|partially ordered]] by [[Inclusion (set theory)|inclusion]], with rank defined as number of elements, forms a graded poset.]]

In [[mathematics]], in the branch of [[combinatorics]], a '''graded poset''' is a [[partially ordered set]] (poset) ''P'' equipped with a '''rank function''' ρ from ''P'' to '''N''' satisfying the following two properties:
* The rank function is compatible with the ordering, meaning that for every ''x'' and ''y'' in the order with ''x''&amp;nbsp;&amp;lt;&amp;nbsp;''y'', it must be the case that ρ(''x'')&amp;nbsp;&amp;lt;&amp;nbsp;ρ(''y''), and
* The rank is consistent with the [[covering relation]] of the ordering, meaning that for every ''x'' and ''y'' for which ''y'' covers ''x'', it must be the case that ρ(''y'')&amp;nbsp;=&amp;nbsp;ρ(''x'')&amp;nbsp;+&amp;nbsp;1.
The value of the rank function for an element of the poset is called its '''rank'''. Sometimes a graded poset is called a '''ranked poset''' but that phrase has other meanings; see [[ranked poset]]. A '''rank''' or  '''rank level''' of a graded poset is the subset of all the elements of the poset that have a given rank value.&lt;ref name=stanley&gt;{{citation
 | last = Stanley | first = Richard
 |authorlink=Richard P. Stanley
 | doi = 10.1007/BF00396271
 | mr = 0745587
 | issue = 1
 | journal = [[Order (journal)|Order]]
 | pages = 29–34
 | title = Quotients of Peck posets
 | volume = 1
 | year = 1984}}.&lt;/ref&gt;&lt;ref&gt;{{citation|title=Subgroup Lattices and Symmetric Functions|volume=539|series=Memoirs of the American Mathematical Society|first=Lynne M.|last=Butler|publisher=American Mathematical Society|year=1994|isbn=9780821826003|page=151|url=https://books.google.com/books?id=IrK3c3ypPFgC&amp;pg=PA151}}.&lt;/ref&gt;

Graded posets play an important role in  [[combinatorics]] and can be visualized by means of a [[Hasse diagram]].

== Examples ==

Some examples of graded posets (with the rank function in parentheses) are:
* the natural numbers '''N''', with their usual order (rank: the number itself), or some interval [0,''N''] of this poset,
* '''N'''&lt;sup&gt;''n''&lt;/sup&gt;, with the [[product order]] (sum of the coefficients), or a subposet of it that is a product of intervals,
* the positive integers, ordered by divisibility (number of prime factors, counted with multiplicity), or a subposet of it formed by the divisors of a fixed ''N'',
* the [[Boolean lattice]] of finite subsets of a set (number of elements of the subset),
* the lattice of [[set partition|partitions]] of a set into finitely many parts, ordered by reverse refinement (number of parts),
* the lattice of [[set partition|partitions]] of a finite set ''X'', ordered by refinement (number of elements of ''X'' minus number of parts),
* a group and a generating set, or equivalently its [[Cayley graph]], ordered by the weak or strong [[Bruhat order]], and ranked by [[word metric|word length]] (length of shortest reduced word).
** In particular for [[Coxeter group]]s, for example [[permutation]]s of a totally ordered ''n''-element set, with either the weak or strong [[Bruhat order]] (number of adjacent inversions),
* [[geometric lattice]]s, such as the lattice of subspaces of a [[vector space]] (dimension of the subspace),
* the [[distributive lattice]] of finite [[lower set]]s of another poset (number of elements),
* [[Young's lattice]], a particular instance of the previous example (number of boxes in the Young diagram),
* [[face lattice]]s of [[convex polytope]]s (dimension of the face, plus one),
* [[abstract polytope]]s ("distance" from the least face, minus one ),
* [[abstract simplicial complex]]es (number of elements of the simplex).

== Alternative characterizations ==
[[File:Smallest nonmodular lattice 1.svg|thumb|100px|The lattice [[modular lattice|''N''&lt;sub&gt;5&lt;/sub&gt;]] can't be graded.]]
A [[bounded poset]]&lt;ref&gt;Meaning it has a [[least element]] and [[greatest element]].&lt;/ref&gt; admits a grading if and only if all [[maximal chain]]s in ''P'' have the same length:&lt;ref&gt;I.e., one does not have a situation like &lt;math&gt;x &lt; z_1 &lt; y&lt;/math&gt; and &lt;math&gt;x &lt; w_1 &lt; w_2 &lt; y&lt;/math&gt; both being maximal chains.&lt;/ref&gt; setting the rank of the least element to 0 then determines the rank function completely. This covers many finite cases of interest; see picture for a negative example. However, unbounded posets can be more complicated.

A candidate rank function, compatible with the ordering, makes a poset into graded poset if and only if, whenever one has ''x''&amp;nbsp;&amp;lt;&amp;nbsp;''z'' with ''z'' of rank ''n''+1, an element ''y'' of rank ''n'' can be found with ''x''&amp;nbsp;≤&amp;nbsp;''y''&amp;nbsp;&amp;lt;&amp;nbsp;''z''. This condition is sufficient because if ''z'' is taken to be a cover of ''x'', the only possible choice is ''y''&amp;nbsp;=&amp;nbsp;''x'' showing that the ranks of ''x'' and ''z'' differ by 1, and it is necessary because in a graded poset one can take for ''y'' any element of maximal rank with ''x''&amp;nbsp;≤&amp;nbsp;''y''&amp;nbsp;&amp;lt;&amp;nbsp;''z'', which always exists and is covered by ''z''.

Often a poset comes with a natural candidate for a rank function; for instance if its elements are finite subsets of some base set ''B'', one can take the number of elements of those subsets. Then the criterion just given can be more practical than the definition because it avoids mention of covers. For instance if ''B'' is itself a poset, and ''P'' consists of its finite [[lower set]]s (subsets for which with every one of its elements, all smaller elements are also in the subset), then the criterion is automatically satisfied, since for lower sets ''x''&amp;nbsp;⊂&amp;nbsp;''z'' there is always a [[maximal element]] of ''z'' that is absent from ''x'', and it can be removed from ''z'' to form ''y''.

:In some common posets such as the [[face lattice]] of a [[convex polytope]] there is a natural grading by [[dimension]], which if used as rank function would give the minimal element, the empty face, rank –1. In such cases it might be convenient to bend the definition stated above by adjoining the value –1 to the set of values allowed for the rank function. Allowing arbitrary integers as rank would however give a fundamentally different notion; for instance the existence of a minimal element would no longer be assured.

A graded poset (with positive integer ranks) cannot have any elements ''x'' for which arbitrarily long [[Glossary of order theory#C|chains]] with greatest element ''x'' exist, as otherwise it would have to have elements of arbitrarily small (and eventually negative) rank. For instance, the [[integer]]s (with the usual order) cannot be a graded poset, nor can any interval (with more than one element) of rational or [[real number]]s. (In particular, graded posets are [[well-founded]], meaning that they satisfy the [[descending chain condition]] (DCC): they do not contain any [[infinite descending chain]]s.&lt;ref&gt;Not containing arbitrarily long descending chains starting at a fixed element of course excludes any infinite descending chains. The former condition is strictly stronger though; the set &lt;math&gt;\N\cup\{\infty\}&lt;/math&gt; has arbitrarily long chains descending from&amp;nbsp;&lt;math&gt;\infty&lt;/math&gt;, but has no infinite descending chains.&lt;/ref&gt;) Henceforth we shall therefore only consider posets in which this does not happen. This implies that whenever ''x''&amp;nbsp;&amp;lt;&amp;nbsp;''y'' we can get from ''x'' to ''y'' by repeatedly choosing a cover, finitely many times. It also means that (for positive integer rank functions) compatibility of ρ with the ordering follows from the requirement about covers. As a variant of the definition of a graded poset, Birkhoff&lt;ref&gt;'Lattice Theory', Am. Math. Soc., Colloquium Publications, Vol.25, 1967, p.5&lt;/ref&gt; allows rank functions to have arbitrary (rather than only nonnegative) integer values. In this variant, the integers can be graded (by the identity function) in his setting, and the compatibility of ranks with the ordering is not redundant. As a third variant, Brightwell and West&lt;ref&gt;See reference [2], p.722.&lt;/ref&gt; define a rank function to be integer-valued, but don't require its compatibility with the ordering; hence this variant can grade even e.g. the real numbers by any function, as the requirement about covers is [[vacuous truth|vacuous]] for this example.

Note that graded posets need not satisfy the [[ascending chain condition]] (ACC): for instance, the natural numbers contain the infinite ascending chain &lt;math&gt;0 &lt; 1 &lt; 2 &lt; \cdots&lt;/math&gt;.

A poset is graded if and only if every connected component of its [[comparability graph]] is graded, so further characterizations will suppose this comparability graph to be connected. On each connected component the rank function is only unique up to a uniform shift (so the rank function can always be chosen so that the elements of minimal rank in their connected component have rank 0).

If ''P'' has a [[least element]] Ô then being graded is equivalent to the condition that for any element ''x'' all [[Glossary of order theory#M|maximal chains]] in the [[Glossary of order theory#I|interval]] [Ô,''x''] have the same length. This condition is necessary since every step in a maximal chain is a covering relation, which should change the rank by&amp;nbsp;1. The condition is also sufficient, since when it holds, one can use the mentioned length to define the rank of ''x'' (the length of a finite chain is its number of "steps", so one less than its number of elements), and whenever ''x'' covers ''y'', adjoining ''x'' to a maximal chain in [Ô,''y''] gives a maximal chain in [Ô,''x''].

If ''P'' also has a [[greatest element]] Î (so that it is a [[bounded poset]]), then the previous condition can be simplified to the requirement that all maximal chains in ''P'' have the same (finite) length. This suffices, since any pair of maximal chains in [Ô,''x''] can be extended by a maximal chain in [''x'',Î] to give a pair of maximal chains in ''P''.

:''Note'' [[Richard P. Stanley|Stanley]] defines a poset to be '''graded of length''' ''n'' if all its maximal chains have length ''n'' (Stanley 1997, p.99). This definition is given in a context where interest is mostly in finite posets, and although the book subsequently often drops the part "of length ''n''", it does not seem appropriate to use this as definition of "graded" for general posets, because (1) it says nothing about posets whose maximal chains are infinite, in particular (2) it excludes important posets like [[Young's lattice]]. Also it is not clear why in a graded poset all minimal elements, as well as all maximal elements, should be required to have the same length, even if Stanley gives examples making clear that he does mean to require that  (ibid, pp.216 and 219).

== The usual case ==
Many authors in [[combinatorics]] define graded posets in such a way that all [[minimal element]]s of ''P'' must have rank 0, and moreover that there is a maximal rank ''r'' which is the rank of any maximal element. Then being graded means that all maximal chains have length ''r'', as is indicated above. In this case one says that ''P'' has rank ''r''.

Furthermore, in this case with the '''rank levels''' are associated  the '''rank numbers''' or '''Whitney numbers''' '''&lt;math&gt;W_0,W_1,W_2,... &lt;/math&gt;'''. These [[number]]s are defined by '''&lt;math&gt;W_i&lt;/math&gt;  = number of elements of ''P'' having rank ''i'' '''.

The '''Whitney numbers''' are connected with a lot of important combinatorial [[theorem]]s. The classic example is [[Sperner's theorem]] which can be formulated as follows:

:''For the [[powerset]] &lt;math&gt; \mathcal P(S) &lt;/math&gt; of every [[finite set]]  '''&lt;math&gt;S&lt;/math&gt;''' the maximum [[cardinality]] of a [[Sperner family]] equals the [[maximum]] '''Whitney number'''.''

This means: 
:''Every finite [[powerset]] has the [[Sperner property of a partially ordered set|Sperner property]]''

== See also ==
* [[Graded (mathematics)]]
* [[Prewellordering]] – a prewellordering with a norm is analogous to a graded poset, replacing a map to the integers with a map to the ordinals
* [[Star product]], a method for combining two graded posets

== Notes ==
&lt;references/&gt;

== References ==

*{{cite book | last = Stanley| first = Richard | authorlink=Richard P. Stanley |  title=Enumerative Combinatorics (vol.1, Cambridge Studies in Advanced Mathematics 49)  | publisher= [[Cambridge University Press]]| year=1997 | isbn = 0-521-66351-2}}
*{{cite book | last = Anderson | first = Ian | authorlink=|  title=Combinatorics of Finite Sets | publisher= [[Clarendon Press]]|location = Oxford, UK| year=1987 | isbn = 0-19-853367-5}}
* {{cite book |last =Engel| first = Konrad |title=Sperner Theory |publisher=Cambridge University Press |location =Cambridge, UK (et al.) |year=1997 |isbn =0-521-45206-6}}
* {{cite book |last1 =Kung| first1 = Joseph P. S.| authorlink1=|last2 =Rota| first2 = Gian-Carlo| authorlink2=Gian-Carlo Rota|last3 =Yan| authorlink3=Catherine Yan| first3 = Catherine H.|title=Combinatorics: The Rota Way|publisher=Cambridge University Press |location =Cambridge, UK (et al.) |year=2009|isbn =978-0-521-73794-4}}

[[Category:Algebraic combinatorics]]
[[Category:Order theory]]</text>
      <sha1>6fa4hlayso76eaimseiz154wfuudwrk</sha1>
    </revision>
  </page>
  <page>
    <title>Hamiltonian fluid mechanics</title>
    <ns>0</ns>
    <id>3038013</id>
    <revision>
      <id>809971394</id>
      <parentid>800306401</parentid>
      <timestamp>2017-11-12T17:29:38Z</timestamp>
      <contributor>
        <username>Felida97</username>
        <id>25112844</id>
      </contributor>
      <minor/>
      <comment>/* References */ fixed CS1 error (redundant parameters)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4499">'''Hamiltonian fluid mechanics''' is the application of [[Hamiltonian mechanics|Hamiltonian]] methods to [[fluid mechanics]]. Note that this formalism only applies to non[[dissipative]] fluids.

==Irrotational barotropic flow==
Take the simple example of a [[barotropic]], [[inviscid]] [[vorticity-free]] fluid.

Then, the [[Conjugate variables|conjugate fields]] are the [[mass density]] field ''&amp;rho;'' and the [[velocity potential]] ''&amp;phi;''. The [[Poisson bracket]] is given by

:&lt;math&gt;\{\varphi(\vec{x}),\rho(\vec{y})\}=\delta^d(\vec{x}-\vec{y})&lt;/math&gt;

and the Hamiltonian by:

:&lt;math&gt;H=\int \mathrm{d}^d x \mathcal{H}=\int \mathrm{d}^d x \left( \frac{1}{2}\rho(\nabla \varphi)^2 +e(\rho) \right),&lt;/math&gt;

where ''e'' is the [[internal energy]] density, as a function of ''&amp;rho;''. 
For this barotropic flow, the internal energy is related to the pressure ''p'' by:

:&lt;math&gt;e'' = \frac{1}{\rho}p',&lt;/math&gt;

where an apostrophe ('), denotes differentiation with respect to ''&amp;rho;''.

This Hamiltonian structure gives rise to the following two [[equations of motion]]:

:&lt;math&gt;
\begin{align}
  \frac{\partial \rho}{\partial t}&amp;=+\frac{\partial \mathcal{H}}{\partial \varphi}= -\nabla \cdot(\rho\vec{u}),
  \\
  \frac{\partial \varphi}{\partial t}&amp;=-\frac{\partial \mathcal{H}}{\partial \rho}=-\frac{1}{2}\vec{u}\cdot\vec{u}-e',
\end{align}
&lt;/math&gt;

where &lt;math&gt;\vec{u}\ \stackrel{\mathrm{def}}{=}\  \nabla \varphi&lt;/math&gt; is the velocity and is [[vorticity-free]]. The second equation leads to the [[Euler equations]]:

:&lt;math&gt;\frac{\partial \vec{u}}{\partial t} + (\vec{u}\cdot\nabla) \vec{u} = -e''\nabla\rho = -\frac{1}{\rho}\nabla{p}&lt;/math&gt;

after exploiting the fact that the [[vorticity]] is zero:

:&lt;math&gt;\nabla \times\vec{u}=\vec{0}.&lt;/math&gt;

As fluid dynamics is described by non-canonical dynamics, which possess an infinite amount of Casimir invariants, an alternative formulation of Hamiltonian formulation of fluid dynamics can be introduced through the use of [[Nambu mechanics]]&lt;ref&gt;{{harvnb|Nevir|Blender|1993}}&lt;/ref&gt;&lt;ref&gt;{{harvnb|Blender|Badin|2015}}&lt;/ref&gt;

==See also==
*[[Luke's variational principle]]
*[[Hamiltonian field theory]]

== Notes ==
{{reflist|2}}

==References==
*{{cite book| ISBN=978-3-319-59694-5 |last1=Badin|first1=Gualtiero|last2=Crisciani|first2=Fulvio| title=Variational Formulation of Fluid and Geophysical Fluid Dynamics - Mechanics, Symmetries and Conservation Laws - | publisher=Springer| year=2018 | pages=218 | doi= 10.1007/978-3-319-59695-2}}
*{{cite article|encyclopedia=Encyclopedia of Mathematical Physics| volume=2 | pages=593-600| year=2006| title=Hamiltonian Fluid Mechanics | first=P.J. |last=Morrison|url=http://web2.ph.utexas.edu/~morrison/06EMP_morrison.pdf|editor=Elsevier|location=Amsterdam}}
*{{cite article|last=Morrison|first=P. J.| title=Hamiltonian Description of the Ideal Fluid |journal=Reviews of Modern Physics|volume=70|number=2| date=April 1998 |pages=467-521|location=Austin, Texas|url=http://web2.ph.utexas.edu/~morrison/98RMP_morrison.pdf|bibcode=1998RvMP...70..467M|doi=10.1103/RevModPhys.70.467}}
*{{cite journal | journal=Annual Review of Fluid Mechanics | volume=20 | pages=225–256 | year=1988 | doi=10.1146/annurev.fl.20.010188.001301 | title=Hamiltonian Fluid Mechanics | author=R. Salmon|bibcode = 1988AnRFM..20..225S }}
*{{cite journal|last1=Shepherd|first1=Theodore G|authorlink=Ted Shepherd|title=Symmetries, Conservation Laws, and Hamiltonian Structure in Geophysical Fluid Dynamics|volume=32|year=1990|pages=287–338|doi=10.1016/S0065-2687(08)60429-X|bibcode=1990AdGeo..32..287S}}
*{{cite book| ISBN=1-58488-023-6 |last=Swaters|first=Gordon E.| title=Introduction to Hamiltonian Fluid Dynamics and Stability Theory | publisher=Chapman &amp; Hall/CRC| year=2000 | pages=274|location=Boca Raton, Florida}}
*{{cite journal |ref = harv |first=P. |last=Nevir |first2=R. |last2=Blender |title=A Nambu representation of incompressible hydrodynamics using helicity and enstrophy |journal=[[J. Phys. A]] |volume=26 |issue= 22 |year=1993 |pages=1189–1193 |doi=10.1088/0305-4470/26/22/010 |bibcode = 1993JPhA...26L1189N }}
*{{cite journal |ref = harv |first=R. |last=Blender |first2=G. |last2=Badin |title=Hydrodynamic Nambu mechanics derived by geometric constraints |journal=[[J. Phys. A]] |volume=48 |issue= 10 |year=2015 |pages=105501 |doi=10.1088/1751-8113/48/10/105501|arxiv = 1510.04832 |bibcode = 2015JPhA...48j5501B }}
[[Category:Fluid dynamics]]
[[Category:Hamiltonian mechanics]]
[[Category:Dynamical systems]]</text>
      <sha1>7mlmhi3s8yvyi8kq5lx5x0h0h1lvyq0</sha1>
    </revision>
  </page>
  <page>
    <title>Hamiltonian path problem</title>
    <ns>0</ns>
    <id>149646</id>
    <revision>
      <id>861403185</id>
      <parentid>860689686</parentid>
      <timestamp>2018-09-27T04:40:21Z</timestamp>
      <contributor>
        <username>Bubba73</username>
        <id>218586</id>
      </contributor>
      <minor/>
      <comment>/* Algorithms */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13290">{{about|the specific problem of determining whether a Hamiltonian path or cycle exists in a given graph|the general graph theory concepts|Hamiltonian path}}

In the [[mathematics|mathematical]] field of [[graph theory]] the '''Hamiltonian path problem''' and the '''Hamiltonian cycle problem''' are problems of determining whether a [[Hamiltonian path]] (a path in an undirected or directed graph that visits each vertex exactly once) or a Hamiltonian cycle exists in a given [[Graph (discrete mathematics)|graph]] (whether [[directed graph|directed]] or [[undirected graph|undirected]]). Both problems are [[NP-complete]].&lt;ref&gt;{{Citation|author = [[Michael R. Garey]] and [[David S. Johnson]] | year = 1979 | title = [[Computers and Intractability: A Guide to the Theory of NP-Completeness]] | publisher = W.H. Freeman | isbn = 0-7167-1045-5}} A1.3: GT37&amp;ndash;39, pp.&amp;nbsp;199&amp;ndash;200.&lt;/ref&gt;

There is a simple relation between the problems of finding a Hamiltonian path and a Hamiltonian cycle. In one direction, the Hamiltonian path problem for graph G is equivalent to the Hamiltonian cycle problem in a graph H obtained from G by adding a new vertex and connecting it to all vertices of G. Thus, finding a Hamiltonian path cannot be significantly slower (in the worst case, as a function of the number of vertices) than finding a Hamiltonian cycle.
In the other direction, the Hamiltonian cycle problem for a graph G is equivalent to the Hamiltonian path problem in the graph H obtained by copying one vertex v of G, v', that is, letting v' have the same neighbourhood as v, and by adding two dummy vertices of degree one, and connecting them with v and v', respectively.&lt;ref&gt;http://math.stackexchange.com/questions/7130/reduction-from-hamiltonian-cycle-to-hamiltonian-path/1290804#1290804&lt;/ref&gt;
The Hamiltonian cycle problem is also a special case of the [[travelling salesman problem]], obtained by setting the distance between two cities to one if they are adjacent and two otherwise, and verifying that the total distance travelled is equal to n (if so, the route is a Hamiltonian circuit; if there is no Hamiltonian circuit then the shortest route will be longer).

==Algorithms==
There are ''n''! different sequences of vertices that ''might'' be Hamiltonian paths in a given ''n''-vertex graph (and are, in a [[complete graph]]), so a [[brute force search]] algorithm that tests all possible sequences would be very slow. An early exact algorithm for finding an Hamiltonian cycle on a directed graph was the enumerative algorithm of Martello&lt;ref&gt;{{citation
 | last = Martello | first = Silvano
 | journal = [[ACM Transactions on Mathematical Software]]
 | pages = 131–138
 | title = An Enumerative Algorithm for Finding Hamiltonian Circuits in a Directed Graph
 | volume = 9
 | year = 1983
 | doi = 10.1145/356022.356030
 | issue = 1}}&lt;/ref&gt;. A search procedure by Frank Rubin&lt;ref&gt;{{citation
 | last = Rubin | first = Frank
 | journal = [[Journal of the ACM]]
 | pages = 576–80
 | title = A Search Procedure for Hamilton Paths and Circuits                         
 | volume = 21
 | year = 1974
 | doi = 10.1145/321850.321854
 | issue = 4}}.&lt;/ref&gt; divides the edges of the graph into three classes: those that must be in the path, those that cannot be in the path, and undecided.  As the search proceeds, a set of decision rules classifies the undecided edges, and determines whether to halt or continue the search.  The algorithm divides the graph into components that can be solved separately.  Also, a [[dynamic programming]] algorithm of Bellman, Held, and Karp can be used to solve the problem in time O(''n''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;2&lt;sup&gt;''n''&lt;/sup&gt;). In this method, one determines, for each set ''S'' of vertices and each vertex ''v'' in ''S'', whether there is a path that covers exactly the vertices in ''S'' and ends at ''v''. For each choice of ''S'' and ''v'', a path exists for (''S'',''v'') if and only if ''v'' has a neighbor ''w'' such that a path exists for (''S''&amp;nbsp;&amp;minus;&amp;nbsp;''v'',''w''), which can be looked up from already-computed information in the dynamic program.&lt;ref&gt;{{citation
 | last = Bellman | first = R. | authorlink = Richard Bellman
 | doi = 10.1145/321105.321111
 | journal = [[Journal of the ACM]]
 | pages = 61–63
 | title = Dynamic programming treatment of the travelling salesman problem
 | volume = 9
 | year = 1962}}.&lt;/ref&gt;&lt;ref&gt;{{citation
 | last1 = Held | first1 = M.
 | last2 = Karp | first2 = R. M. | author2-link = Richard Karp
 | doi = 10.1137/0110015
 | issue = 1
 | journal = J. SIAM
 | pages = 196–210
 | title = A dynamic programming approach to sequencing problems
 | volume = 10
 | year = 1962}}.&lt;/ref&gt;

Andreas Björklund provided an alternative approach using the [[inclusion–exclusion principle]] to reduce the problem of counting the number of Hamiltonian cycles to a simpler counting problem, of counting cycle covers, which can be solved by computing certain matrix determinants. Using this method, he showed how to solve the Hamiltonian cycle problem in arbitrary ''n''-vertex graphs by a [[Monte Carlo algorithm]] in time O(1.657&lt;sup&gt;''n''&lt;/sup&gt;); for [[bipartite graph]]s this algorithm can be further improved to time [[Big O notation#Little-o notation|o]](1.415&lt;sup&gt;''n''&lt;/sup&gt;).&lt;ref&gt;{{citation
 | last = Björklund | first = Andreas
 | arxiv = 1008.0541
 | contribution = Determinant sums for undirected Hamiltonicity
 | doi = 10.1109/FOCS.2010.24
 | pages = 173–182
 | title = Proc. 51st IEEE Symposium on Foundations of Computer Science (FOCS '10)
 | year = 2010
 | isbn = 978-1-4244-8525-3}}.&lt;/ref&gt;

For graphs of maximum degree three, a careful backtracking search can find a Hamiltonian cycle (if one exists) in time O(1.251&lt;sup&gt;''n''&lt;/sup&gt;).&lt;ref&gt;{{citation
 | last1 = Iwama | first1 = Kazuo
 | last2 = Nakashima | first2 = Takuya
 | contribution = An improved exact algorithm for cubic graph TSP
 | doi = 10.1007/978-3-540-73545-8_13
 | pages = 108–117
 | series = Lecture Notes in Computer Science
 | title = Proc. 13th Annual International Conference on Computing and Combinatorics (COCOON 2007)
 | volume = 4598
 | year = 2007
 | isbn = 978-3-540-73544-1}}.&lt;/ref&gt;

Hamiltonian paths and cycles can be found using a [[SAT solver]].

Because of the difficulty of solving the Hamiltonian path and cycle problems on conventional computers, they have also been studied in unconventional models of computing. For instance, [[Leonard Adleman]] showed that the Hamiltonian path problem may be solved using a [[DNA computing|DNA computer]]. Exploiting the parallelism inherent in chemical reactions, the problem may be solved using a number of chemical reaction steps linear in the number of vertices of the graph; however, it requires a factorial number of DNA molecules to participate in the reaction.&lt;ref&gt;{{citation
 | last = Adleman | first = Leonard | author-link = Leonard Adleman
 | doi = 10.1126/science.7973651
 | issue = 5187
 | journal = [[Science (journal)|Science]]
 | jstor = 2885489
 | pages = 1021–1024
 | pmid = 7973651
 | title = Molecular computation of solutions to combinatorial problems
 | volume = 266
 | date = November 1994| bibcode = 1994Sci...266.1021A
 }}.&lt;/ref&gt; 

An optical solution to the Hamiltonian problem has been proposed in &lt;ref name= "oltean_hamiltonian"&gt;{{cite conference|author=Mihai Oltean|title= A light-based device for solving the Hamiltonian path problem |conference=Unconventional Computing| pages= 217-227| publisher= Springer LNCS 4135|doi=10.1007/11839132_18|date=2006|arxiv=0708.1496}}&lt;/ref&gt;. The idea is to create a graph-like structure made from optical cables and beam splitters which are traversed by light in order to construct a solution for the problem. The weak point of this approach is the required amount of energy which is exponential in the number of nodes.

==Complexity==
The problem of finding a Hamiltonian cycle or path is in [[FNP (complexity)|FNP]]; the analogous [[decision problem]] is to test whether a Hamiltonian cycle or path exists. The directed and undirected Hamiltonian cycle problems were two of [[Karp's 21 NP-complete problems]]. They remain NP-complete even for undirected [[planar graph]]s of maximum degree three,&lt;ref&gt;{{citation
 | last1 = Garey | first1 = M. R. | author1-link = Michael Garey
 | last2 = Johnson | first2 = D. S. | author2-link = David S. Johnson
 | last3 = Stockmeyer | first3 = L. | author3-link = Larry Stockmeyer
 | contribution = Some simplified NP-complete problems
 | doi = 10.1145/800119.803884
 | pages = 47–63
 | title = Proc. 6th ACM Symposium on Theory of Computing (STOC '74)
 | year = 1974}}.&lt;/ref&gt; for directed planar graphs with indegree and outdegree at most two,&lt;ref&gt;{{citation
 | last = Plesńik | first = J.
 | issue = 4
 | journal = [[Information Processing Letters]]
 | pages = 199–201
 | title = The NP-completeness of the Hamiltonian cycle problem in planar digraphs with degree bound two
 | url = http://www.aya.or.jp/~babalabo/DownLoad/Plesnik%208.4.192-196.pdf
 | volume = 8
 | year = 1979
 | doi = 10.1016/0020-0190(79)90023-1}}.&lt;/ref&gt; for bridgeless undirected planar 3-[[regular graph|regular]] [[bipartite graph]]s, for 3-connected 3-regular bipartite graphs,&lt;ref&gt;{{citation
 | last1 = Akiyama | first1 = Takanori
 | last2 = Nishizeki | first2 = Takao | author2-link = Takao Nishizeki
 | last3 = Saito | first3 = Nobuji
 | issue = 2
 | journal = Journal of Information Processing
 | mr = 596313
 | pages = 73–76
 | title = NP-completeness of the Hamiltonian cycle problem for bipartite graphs
 | url = 
 | volume = 3
 | year = 1980–1981}}.&lt;/ref&gt; subgraphs of the [[Lattice graph#Square grid graph|square grid graph]],&lt;ref&gt;{{citation
 | last1 = Itai | first1 = Alon
 | last2 = Papadimitriou | first2 = Christos
 | last3 = Szwarcfiter | first3 = Jayme
 | issue = 11
 | journal = [[SIAM Journal on Computing]]
 | pages = 676–686
 | title = Hamilton Paths in Grid Graphs
 | doi = 10.1137/0211056
 | url = http://epubs.siam.org/doi/abs/10.1137/0211056
 | volume = 4
 | year = 1982| citeseerx = 10.1.1.383.1078}}.&lt;/ref&gt; and cubic subgraphs of the square grid graph.&lt;ref&gt;{{citation
 | last = Buro | first = Michael
 | contribution = Simple Amazons endgames and their connection to Hamilton circuits in cubic subgrid graphs
 | contribution-url = http://skatgame.net/mburo/ps/amaend.pdf
 | title = Conference on Computers and Games
 | year = 2000
 | doi = 10.1007/3-540-45579-5_17}}.&lt;/ref&gt;

However, 4-connected planar graphs are always Hamiltonian by a result due to Tutte, and the computational task of finding a Hamiltonian cycle in these graphs can be carried out in linear time&lt;ref&gt;{{citation
 | last1 = Chiba| first1 = Norishige
 | last2 = Nishizeki| first2 = Takao
 | title = The Hamiltonian cycle problem is linear-time solvable for 4-connected planar graphs
 | doi = 10.1016/0196-6774(89)90012-6
 | pages = 187-211
 | journal = Journal of Algorithms
 | volume = 10
 | issue = 2
 | year = 1989}}&lt;/ref&gt;
by computing a so-called [[Tutte path]]. Tutte proved this result by showing that every 2-connected planar graph contains a [[Tutte path]]. Tutte paths in turn can be computed in quadratic time even for 2-connected planar graphs&lt;ref&gt;{{citation
 | last1 = Schmid| first1 = Andreas
 | last2 = Schmidt| first2 = Jens M.
 | contribution = Computing Tutte Paths
 | title = Proceedings of the 45th International Colloquium on Automata, Languages and Programming (ICALP'18), to appear.
 | year = 2018
}}&lt;/ref&gt;, which may be used to find Hamiltonian cycles and long cycles in generalizations of planar graphs.

Putting all of these conditions together, it remains open whether 3-connected 3-regular bipartite planar graphs must always contain a Hamiltonian cycle, in which case the problem restricted to those graphs could not be NP-complete; see [[Barnette's conjecture]].

In graphs in which all vertices have odd degree, an argument related to the [[handshaking lemma]] shows that the number of Hamiltonian cycles through any fixed edge is always even, so if one Hamiltonian cycle is given, then a second one must also exist.&lt;ref&gt;{{citation
 | last = Thomason | first = A. G.
 | contribution = Hamiltonian cycles and uniquely edge colourable graphs
 | doi = 10.1016/S0167-5060(08)70511-9
 | mr = 499124
 | pages = 259–268
 | series = Annals of Discrete Mathematics
 | title = Advances in Graph Theory (Cambridge Combinatorial Conf., Trinity College, Cambridge, 1977)
 | volume = 3
 | year = 1978
 | isbn = 9780720408430}}.&lt;/ref&gt; However, finding this second cycle does not seem to be an easy computational task. [[Christos Papadimitriou|Papadimitriou]] defined the [[complexity class]] [[PPA (complexity)|PPA]] to encapsulate problems such as this one.&lt;ref&gt;{{citation | last = Papadimitriou| first = Christos H.| author-link = Christos Papadimitriou | doi = 10.1016/S0022-0000(05)80063-7
| issue = 3
| journal = [[Journal of Computer and System Sciences]]
| pages = 498–532
| title = On the complexity of the parity argument and other inefficient proofs of existence
| volume = 48
| year = 1994 | mr = 1279412}}.&lt;/ref&gt;

== References ==
{{commons category inline}}
{{Reflist|30em}}

{{DEFAULTSORT:Hamiltonian Path Problem}}
[[Category:NP-complete problems]]
[[Category:Computational problems in graph theory]]
[[Category:Hamiltonian paths and cycles]]</text>
      <sha1>s46qusvy97bik4j8gbbqak9qt6vw4v5</sha1>
    </revision>
  </page>
  <page>
    <title>Higher Topos Theory</title>
    <ns>0</ns>
    <id>44533369</id>
    <revision>
      <id>822488945</id>
      <parentid>643551287</parentid>
      <timestamp>2018-01-26T17:34:41Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="686">{{DISPLAYTITLE:''Higher Topos Theory''}}
'''''Higher Topos Theory''''' is a mathematical book by American mathematician [[Jacob Lurie]]. The main subject of the book is an [[∞-topos]]. But it also develops the theory of [[∞-category]] as a particular kind of a [[simplicial set]]. All together the book provides a categorical foundation for [[derived algebraic geometry]].

The book is available at https://arxiv.org/abs/math/0608040.

== External links ==
*http://ncatlab.org/nlab/show/Higher+Topos+Theory
*http://mathoverflow.net/questions/74642/if-i-want-to-study-jacob-luries-books-higher-topoi-theory-derived-ag-what


{{mathematics-lit-stub}}



[[Category:Mathematics books]]</text>
      <sha1>paobjrvyvtdy6rrpze0nlrtgwzmr6iw</sha1>
    </revision>
  </page>
  <page>
    <title>John Lane Bell</title>
    <ns>0</ns>
    <id>25759134</id>
    <revision>
      <id>835448548</id>
      <parentid>818915676</parentid>
      <timestamp>2018-04-08T19:39:40Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Journal articles */[[User:JCW-CleanerBot#Logic|task]], replaced: Brit. J. → Br. J. using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11684">'''John Lane Bell''' (born March 25, 1945) is Professor of Philosophy at the [[University of Western Ontario]] in Canada. He has made contributions to mathematical logic and philosophy, and is the author of a number of books. His research includes such topics as set theory, model theory, lattice theory, modal logic, quantum logic, constructive mathematics, type theory, topos theory, infinitesimal analysis, spacetime theory, and the philosophy of mathematics. He is the author of more than 70 articles and of 11 books. In 2009, he was elected a Fellow of the [[Royal Society of Canada]].

==Biography==
John Bell was awarded a scholarship to [[Oxford University]] at the age of 15, and graduated with a D.Phil. in Mathematics: his dissertation supervisor was [[John Crossley (mathematician)|John Crossley]]. During 1968-89 he was lecturer in Mathematics and Reader in Mathematical Logic at the [[London School of Economics]].&lt;ref name="bellbio1"&gt;{{cite web|url=http://publish.uwo.ca/~jbell/|title=Professor John L. Bell|publisher=University of Western Ontario|accessdate=25 March 2010}}&lt;/ref&gt;

John Bell's students include [[Graham Priest]] (Ph.D. Mathematics LSE, 1972), Michael Hallett (Ph.D. Philosophy LSE, 1979), David DeVidi (Ph.D. Philosophy UWO, 1994), Elaine Landry (Ph.D. Philosophy UWO, 1997) and Richard Feist (Ph.D. Philosophy UWO, 1999).

==Bibliography==

===Books===
*''Intuitionistic Set Theory''. College Publications, 2013.
*''Set Theory: Boolean-Valued Models and Independence Proofs''. Oxford University Press 2011.
*''The Axiom of Choice''. College Publications, 2009.
*''The Continuous and the Infinitesimal in Mathematics and Philosophy''. Polimetrica, 2005.
*(With D. DeVidi and G. Solomon) ''Logical Options: An Introduction to Classical and Alternative Logics''. Broadview Press, 2001.
*''The Art of the Intelligible: An Elementary Survey of Mathematics in its Conceptual Development''. Kluwer, 1999.
*''A Primer of Infinitesimal Analysis''. Cambridge University Press, 1998. Second Edition, 2008.
*''Toposes &amp; Local Set Theories: An Introduction''. Clarendon Press,  Oxford, 1988. Reprinted by Dover, 2008. 
*''Boolean-Valued Models and Independence Proofs in Set Theory''. Clarendon Press, Oxford, 1977. 2nd edition, 1985. 3rd edition, 2005.
*(With [[Moshé Machover|M. Machover]]). ''A Course in Mathematical Logic''. North-Holland, Amsterdam, 1977. 4th printing, 2003.
*(With A. B. Slomson). ''Models and Ultraproducts: An Introduction''. North-Holland, Amsterdam, 1969. Reprinted by Dover, 2006.

===Journal articles===
*The Axiom of Choice in the Foundations of Mathematics, forthcoming in volume on ''Foundations of Mathematics'', Giovanni Sommaruga, ed., University of Western Ontario Series, Springer
*Cohesiveness, ''[[Intellectica]]'', 41, 2009.
*Types, Sets and Categories, ''Handbook of the History of Logic'' (Elsevier), forthcoming.
*Hermann Weyl, ''[[Stanford Encyclopedia of Philosophy]]'', 2009
*"The Axiom of Choice and the Law of Excluded Middle in Weak Set Theories", ''Mathematical Logic Quarterly'', 54, no. 2, 2008.
*"The Axiom of Choice", ''Stanford Encyclopedia of Philosophy'', 2008.
*Contribution to "Philosophy of Mathematics: 5 Questions", V. Hendricks and H. Leitgeb, eds., Automatic Press, 2007.
*"Incompleteness in a General Setting". ''Bulletin of Symbolic Logic'' 13, 2007.
*"Cover Schemes, Frame-Valued Sets and Their Potential Uses in Spacetime Physics". ''Spacetime Physics Research Trends, Horizons in World Physics'', Volume 248, Nova Science Publishers, New York, 2007.
*"Cosmological Theories and the Question of the Existence of a Creator". ''Religion and the Challenges of Science'', Ashgate Publishers, 2007.
*"Abstract and Variable Sets in Category Theory". ''In What is Category Theory?'', {{ill|Polimetrica|it}}, 2006.
*"Divergent Concepts of the Continuum in 19th and Early 20th Century Mathematics and Philosophy". ''Axiomathes'' 15, 2005.
*"The Development of Categorical Logic", ''Handbook of Philosophical Logic'', Volume 12. Springer, 2005.
*"Continuity and Infinitesimals". ''Stanford Encyclopedia of Philosophy'', 2005.
*"Choice Principles in Intuitionistic Set Theory.", ''A Logical Approach to Philosophy, Essays in Honour of Graham Solomon, D. DeVidi and T. Kenyon'', eds., Springer, 2006.
*"Oppositions and Paradoxes in Mathematics and Philosophy." ''Axiomathes'' 15, 2005.
*"Observations on Mathematics", ''Mathematics as Story'', Proceedings of 2003 [[Fields Institute]] Conference, UWO, 2004.
*Whole and Part in Mathematics. ''Axiomathes'' 14, 2004.
*(With [[Geoffrey Hellman]]) "Pluralism and the Foundations of Mathematics". ''Proceedings of Workshop on Scientific Pluralism'', University of Minnesota,  2002. Minnesota University Press, 2006.
*"Some New Intuitionistic Equivalents of Zorn's Lemma", ''Archive for Mathematical Logic'', 42, Number 8, 2003.
*"Russell's Paradox and Diagonalization in a Constructive Context", ''100 Years of Russell's Paradox'', Munich 2001, Walter de Gruyter, 2004.
*"Hermann Weyl's Later Philosophical Views: His Divergence from Husserl", ''Husserl and the Sciences'', R. Feist, ed.  U. of Ottawa Press, 2003.
*"The Development of Categorical Logic", ''Handbook of Philosophical Logic'', Volume 12. Springer, 2005.
*"Time and Causation in Gödel's Universe", ''Transcendent Philosophy'' 3, 2002.
*"Observations on Category Theory", ''Axiomathes'' 12, 2001
*"The Continuum in Smooth Infinitesimal Analysis". In ''Reuniting the Antipodes-Constructive and Nonstandard Views of the Continuum''. Symposion Proceedings, San Servolo/Venice, Italy, 1999. U. Berger, H. Osswald and P. Schuster, eds. Kluwer, 2001.
*"Continuity and the Logic of Perception", ''Transcendent Philosophy'' 1, no. 2, 2000.
*"Hermann Weyl on Intuition and the Continuum", ''Philosophia Mathematica'' (3), 8, 2000.
*"Sets and Classes as Many", ''Journal of Philosophical Logic'', 29, 2000.
*"Infinitary Logic", ''Stanford Encyclopedia of Philosophy'', 2000
*"Finite Sets and Frege Structures", ''Journal of Symbolic Logic'', 64, no. 4,1999.
*"Frege's Theorem in a Constructive Setting", ''Journal of Symbolic Logic'', 64, no. 2, 1999.
*"Boolean Algebras and Distributive Lattices Treated Constructively", ''Math. Logic Quarterly'' 45, 1999.
*"Boolean Algebras", ''Routledge Encyclopedia of Philosophy'', 1998.
*"Zorn's Lemma and Complete Boolean Algebras in Intuitionistic Type Theories", ''Journal of Symbolic Logic'' 62, no. 4, 1997.
*(With S. Gebellato) "Precovers, Modalities, and Universal Closure Operators in a Topos", ''Math. Logic Quarterly'' 42, 1996.
*"Polymodal Lattices and Polymodal Logic", ''Math. Logic Quarterly'' 42, 1996.
*(With W. Demopoulos) "Elementary Propositions and Independence", ''Notre Dame Journal of Formal Logic'', 37, no. 1, 1996.
*"Logical Reflections on the Kochen-Specker Theorem", in ''Perspectives on Quantum Reality'', R. Clifton, ed., Kluwer, 1996.
*(With R.Clifton†) "Quasi Boolean Algebras and Simultaneously Definite Properties in Quantum Mechanics", ''[[Int. Journal of Theoretical Physics]]'', 34, 12, 1995.
*"Infinitesimals and the Continuum", ''Mathematical Intelligencer'', 17, no. 2, 1995.
*"Type-Reducing Correspondences and Well-Orderings: Frege's and Zermelo's Constructions Re-examined", ''Journal of Symbolic Logic'', 60, no. 1, 1995.
*"Frege's Theorem and the Zermelo-Bourbaki Lemma". Appendix to ''Frege's Philosophy of Mathematics'', W. Demopoulos, ed. Harvard U.P., 1995
*"Fregean Extensions of First-Order Theories", ''Math. Logic Quarterly'', 40, 1994. (Also reprinted in W. Demopoulos, ed. Frege's Philosophy of Mathematics, Harvard U.P. 1995)
*"Hilbert's Epsilon Operator in Intuitionistic Type Theories", ''Math. Logic Quarterly'', 39, 1993.
*(with W. Demopoulos) "Frege's Theory of Concepts and Objects and the Interpretation of Second-Order Logic", ''Philosophia Mathematica'', (3), 1, 1993.
*"Hilbert's Epsilon-Operator and Classical Logic", ''Journal of Philosophical Logic'', 22, 1993.
*"Some Propositions Equivalent to the Sikorski Extension Theorem for Boolean Algebras", ''[[Fundamenta Mathematicae]]'' 130 (1988).
*"Infinitesimals", ''Synthese'', 75, 1988.
*"Logic, the Paradoxes, and the Foundations of Mathematics", ''LSE Quarterly'' Vol.I, No.3, 1987.
*"From Absolute to Local Mathematics", ''Synthese'' 69, 1986.
*"A New Approach to Quantum Logic", ''Br. J. Philos. Sci.'', 37, 1986.
*"Orthospaces and Quantum Logic", ''Foundations of Physics'' 15, 1985.
*"Orthologic, Forcing and the Manifestation of Attributes", ''Proceedings of 1981 S.E. Asian Conference in Mathematical Logic''. North Holland, Amsterdam, 1983.
*"The Strength of the Sikorski Extension Theorem for Boolean Algebras", ''Journal of Symbolic Logic'' 48, 1983.
*(With M.F. Hallett), "Logic, Quantum Logic, and Empiricism", ''[[Philosophy of Science]]'' 49, 1982.
*"Categories, Toposes and Sets", ''Synthese'', 51, No.3, 1982.
*"Some Aspects of the Category of Subobjects of Constant Objects in a Topos", ''[[Journal of Pure and Applied Algebra]]'' 24, 1982.
*"Category Theory and the Foundations of Mathematics", ''[[Brit.J.Phil.Sci.]]'' 32, 1981.
*"Isomorphism of Structures in S-Toposes", ''Journal of Symbolic Logic'', 46, 1981.
*"The Infinite Past Regained: A Reply to Whitrow", ''Brit.J.Phil.Sci. Sci'', 1979
*"Boolean Extensions as Toposes", ''Bull. de la Soc. Francaise de Logique'', Methodologie et Phil.des Sci. 6, 1979.
*"Uncountable Standard Models of ZFC + V = L", in ''Set Theory and Hierarchy Theory, a Memorial Tribute to Andrzej Mostowski'', Springer Lecture Notes in Math. 537,1976.
*"A Note on Generic Ultrafilters", ''Zeitschr. f. Math.Logik und Grund.der Math.'' 22, 1976.
*"Universal Complete Boolean Algebras and Cardinal Collapsing", ''Zeitsch. f. Math.Logik und Grund. der Math.'' 22, 1976.
*"A Characterization of Universal Complete Boolean Algebras", ''[[J. London Math.Soc.]]'' (2), 12, 1975.
*"On Compact Cardinals", ''Zeitschr.f. Math.Logik und Grund.der Math.'' 20.1974.
*(With D.H. Fremlin), "A Geometric Form of the Axiom of Choice", ''Fund. Math.'' LXXVII, 1972.
*(With D.H. Fremlin), "The Maximal Ideal Theorem for Lattices of Sets", ''Bull. London Math. Soc.'', 4, 1972.
*"On the Relationship between Weak Compactness and Restricted Second- Order Languages", ''Arch. Math. Logik'' 15, 1972.
*"Some Remarks on Current Mathematical Practice", in ''Proceedings of the Bertrand Russell Memorial Logic Conference'', Denmark, 1971.
*(With F. Jellett). "On the Relationship between the Boolean Prime Ideal Theorem and Two Principles of Functional Analysis", ''Bull. de l'Acad. Pol. des Sci.'', XIX, No.3, 1971.
*"Weak Compactness in Restricted Second-Order Languages", ''Bull. de l'Acad. Pol. des Sci.'', No.3, 1970.

==References==
&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

==External links==
*[http://publish.uwo.ca/~jbell/ John Bell's webpage]
*[http://genealogy.math.ndsu.nodak.edu/id.php?id=15663 John Bell at the Mathematics Genealogy Project]

{{Authority control}}

{{DEFAULTSORT:Bell, John Lane}}
[[Category:1945 births]]
[[Category:20th-century Canadian mathematicians]]
[[Category:20th-century philosophers]]
[[Category:21st-century Canadian mathematicians]]
[[Category:21st-century philosophers]]
[[Category:Academics of the London School of Economics]]
[[Category:Alumni of the University of Oxford]]
[[Category:Canadian mathematicians]]
[[Category:Canadian philosophers]]
[[Category:Living people]]
[[Category:National University of Singapore faculty]]
[[Category:Model theorists]]
[[Category:Philosophers of mathematics]]
[[Category:Set theorists]]
[[Category:University of Western Ontario faculty]]</text>
      <sha1>bsq1j3f72utf1n6jytrfdxqobtzpsib</sha1>
    </revision>
  </page>
  <page>
    <title>List of things named after John von Neumann</title>
    <ns>0</ns>
    <id>38050430</id>
    <revision>
      <id>869991363</id>
      <parentid>857889056</parentid>
      <timestamp>2018-11-21T18:12:58Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Add: date, issue, author pars. 1-3. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2614">This is a '''list of things named after John von Neumann'''. [[John von Neumann]] (1903–1957), a mathematician, is the eponym of all of the things (and topics) listed below.

*[[22824 von Neumann]]
*[[Abelian von Neumann algebra]]
*[[Enveloping von Neumann algebra]]
*[[Finite-dimensional von Neumann algebra]]
*[[IEEE John von Neumann Medal]]
*[[John von Neumann Award]]
*[[John von Neumann Lecture]]
*[[John von Neumann Computer Society]]
*[[John von Neumann Center]] (JVNC) at [[Princeton University]] (1985-1990), part of the [[Consortium for Scientific Computing]]
*[[John von Neumann Theory Prize]]
*[[Stone–von Neumann theorem]]
*[[von Neumann algebra]]
*[[von Neumann architecture]]
*[[von Neumann bicommutant theorem]]
*[[Birkoff-von Neumann theorem]]
*[[Von Neumann architecture#Von Neumann bottleneck|Von Neumann bottleneck]]
*[[von Neumann cardinal assignment]]
*[[von Neumann cellular automaton]]
*[[von Neumann conjecture]]
*[[von Neumann constant]]
**[[Coupling constant|Murray-von Neumann coupling constant]]
**Jordan-von Neumann constant&lt;ref&gt;{{cite journal | url = http://www.sciencedirect.com/science/article/pii/S0022247X00967271 | doi=10.1006/jmaa.2000.6727 | volume=244 | issue=2 | title=Von Neumann–Jordan Constant of Absolute Normalized Norms on C2 | journal=Journal of Mathematical Analysis and Applications | pages=515–532| date=2000-04-15 | last1=Saito | first1=Kichi-Suke | last2=Kato | first2=Mikio | last3=Takahashi | first3=Yasuji }}&lt;/ref&gt;
*[[von Neumann entropy]]
*[[von Neumann equation]]
*[[von Neumann ergodic theorem]]
*[[von Neumann extractor]]
*[[von Neumann-Wigner interpretation]]
*[[von Neumann measurement scheme]]
*[[Self-replicating machine|von Neumann machines]]
*[[von Neumann neighborhood]]
*[[von Neumann ordinal]]
*[[von Neumann paradox]]
*[[von Neumann probe]]
*[[von Neumann programming languages]]
*[[von Neumann regular ring]]
*[[Spectral theorem#von Neumann spectral theorem| von Neumann spectral theorem]]
*[[von Neumann stability analysis]]
*[[von Neumann universal constructor]]
*[[von Neumann universe]]
*[[von Neumann–Bernays–Gödel set theory]]
*[[von Neumann–Morgenstern utility theorem]]
*[[von Neumann's inequality]]
*[[von Neumann's theorem]]
*[[von Neumann's trace inequality]]
*[[von Neumann (crater)]]
*[[Weyl–von Neumann theorem]]
*[[Wold–von Neumann decomposition]]

==References==
{{reflist}}

{{DEFAULTSORT:List of things named after John von Neumann}}
[[Category:Lists of things named after scientists|Neumann, John von]]
[[Category:Lists of things named after mathematicians|Neumann, John von]]
[[Category:John von Neumann]]</text>
      <sha1>swt13n5czl3askudjn4qf69sldhrpey</sha1>
    </revision>
  </page>
  <page>
    <title>Medial triangle</title>
    <ns>0</ns>
    <id>3339743</id>
    <revision>
      <id>818288744</id>
      <parentid>818254101</parentid>
      <timestamp>2018-01-02T18:37:03Z</timestamp>
      <contributor>
        <username>Wcherowi</username>
        <id>13428914</id>
      </contributor>
      <comment>/* top */ more grammatical</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5262">[[File:Medial Triangle.svg|thumb|right|The red triangle is the medial triangle of the black. The endpoints of the red triangle coincide with the midpoints of the black triangle.]] The '''medial triangle''' or '''midpoint triangle''' of a [[triangle]] ''ABC'' is the triangle with [[vertex (geometry)|vertices]] at the [[midpoint]]s of the triangle's sides AB, AC and BC. It is the ''n''=3 case of the [[midpoint polygon]] of a [[polygon]] with ''n'' sides.  The medial triangle is not the same thing as the [[median triangle]], which is the triangle whose sides have the same lengths as the [[Median (geometry)|medians]] of ''ABC''.

Each side of the medial triangle is called a ''midsegment'' (or ''midline''). In general, a midsegment of a triangle is a line segment which joins the midpoints of two sides of the triangle. It is parallel to the third side and has a length  equal to half the length of the third side.

==Properties==
The medial triangle can also be viewed as the image of triangle ''ABC'' transformed by a [[Homothetic transformation|homothety]] centered at the [[centroid]] with ratio -1/2. Thus, the sides of the medial triangle are half and parallel to the corresponding sides of triangle ABC. Hence, the medial triangle is inversely [[Similarity (geometry)|similar]] and shares the same centroid and [[median (geometry)|medians]] with triangle ''ABC''. It also follows from this that the [[perimeter]] of the medial triangle equals the [[semiperimeter]] of triangle ''ABC'', and that the [[area]] is one quarter of the area of triangle ''ABC''. Furthermore, the four triangles that the original triangle is subdivided into by the medial triangle are all mutually [[congruence (geometry)|congruent]] by [[Triangle#Similarity and congruence|SSS]], so their areas are equal and thus the area of each is 1/4 the area of the original triangle.&lt;ref name=PL&gt;Posamentier, Alfred S., and Lehmann, Ingmar. ''The Secrets of Triangles'', Prometheus Books, 2012.&lt;/ref&gt;{{rp|p.177}}

The [[orthocenter]] of the medial triangle coincides with the [[circumcenter]] of triangle ''ABC''. This fact provides a tool for proving [[Line (geometry)|collinearity]] of the circumcenter, centroid and orthocenter. The medial triangle is the [[pedal triangle]] of the circumcenter. The [[nine-point circle]] circumscribes the medial triangle, and so the nine-point center is the circumcenter of the medial triangle.

The [[Nagel point]] of the medial triangle is the [[incenter]] of its reference triangle.&lt;ref name=ac&gt;Altshiller-Court, Nathan. ''College Geometry''. Dover Publications, 2007.&lt;/ref&gt;{{rp|p.161,Thm.337}}

A reference triangle's medial triangle is [[congruence (geometry)|congruent]] to the triangle whose vertices are the midpoints between the reference triangle's [[orthocenter]] and its vertices.&lt;ref name=ac/&gt;{{rp|p.103,#206;p.108,#1}}

The [[incenter]] of a triangle lies in its medial triangle.&lt;ref name=Franzsen&gt;[http://forumgeom.fau.edu/FG2011volume11/FG201126.pdf Franzsen, William N.. "The distance from the incenter to the Euler line", ''Forum Geometricorum'' 11 (2011): 231–236.]&lt;/ref&gt;{{rp|p.233,Lemma 1}}

A point in the interior of a triangle is the center of an [[Circumconic and inconic|inellipse]] of the triangle if and only if the point lies in the interior of the medial triangle.&lt;ref name=Chakerian&gt;Chakerian, G. D. "A Distorted View of Geometry." Ch. 7 in ''Mathematical Plums'' (R. Honsberger, editor). Washington, DC: Mathematical Association of America, 1979.&lt;/ref&gt;{{rp|p.139}}

The medial triangle is the only [[inscribed figure|inscribed triangle]] for which none of the other three interior triangles has smaller area.&lt;ref name=Torrejon&gt; Torrejon, Ricardo M. "On an Erdos inscribed triangle inequality", ''Forum Geometricorum'' 5, 2005, 137–141. http://forumgeom.fau.edu/FG2005volume5/FG200519index.html&lt;/ref&gt;{{rp|p. 137}}

==Coordinates==
Let a = |BC|, b = |CA|, c = |AB| be the sidelengths of triangle ABC.  [[Trilinear coordinates]] for the vertices of the medial triangle are given by
* X = 0 : 1/b : 1/c
* Y = 1/a : 0 : 1/c
* Z = 1/a : 1/b : 0

==Anticomplementary triangle==
If ''XYZ'' is the medial triangle of ''ABC'', then ''ABC'' is the '''anticomplementary triangle''' or '''antimedial triangle''' of ''XYZ''. The anticomplementary triangle of ''ABC'' is formed by three lines parallel to the sides of ''ABC'': the parallel to ''AB'' through ''C'', the parallel to ''AC'' through ''B'', and the parallel to ''BC'' through ''A''.

[[Trilinear coordinates]] for the vertices of the anticomplementary triangle, X'Y'Z', are given by
* X' = &amp;minus;1/a : 1/b : 1/c
* Y' = 1/a : &amp;minus;1/b : 1/c
* Z' = 1/a : 1/b : &amp;minus;1/c

The name "anticomplementary triangle" corresponds to the fact that its vertices are the anticomplements of the vertices A, B, C of the reference triangle.  The vertices of the medial triangle are the complements of A, B, C.  

==References==

{{reflist}}

== External links ==

* {{mathworld | urlname = MedialTriangle | title = Medial triangle}}
* {{mathworld | urlname = AnticomplementaryTriangle | title = Anticomplementary Triangle}}

{{DEFAULTSORT:Medial Triangle}}
[[Category:Elementary geometry]]
[[Category:Triangle geometry]]

[[de:Mittelparallele#Mittelparallelen eines Dreiecks]]</text>
      <sha1>bu0uuntlab6ko3loqtky84jpnvwfubg</sha1>
    </revision>
  </page>
  <page>
    <title>Metrization theorem</title>
    <ns>0</ns>
    <id>19738</id>
    <revision>
      <id>852554406</id>
      <parentid>851106305</parentid>
      <timestamp>2018-07-29T20:04:18Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta5)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5723">In [[topology]] and related areas of [[mathematics]], a '''metrizable space''' is a [[topological space]] that is [[homeomorphism|homeomorphic]] to a [[metric space]]. That is, a topological space &lt;math&gt;(X, \mathcal{T})&lt;/math&gt; is said to be metrizable if there is a [[metric (mathematics)|metric]] 
:&lt;math&gt;d\colon X \times X \to [0,\infty)&lt;/math&gt;

such that the topology induced by ''d'' is &lt;math&gt;\mathcal{T}&lt;/math&gt;.&lt;ref&gt;{{cite web|last=Simon|first=Jonathan|title=Metrization Theorems|url=http://homepage.math.uiowa.edu/~jsimon/COURSES/M132Fall07/MetrizationTheorem_v5.pdf|access-date=16 June 2016}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Munkres|first=James|authorlink=James Munkres|title=Topology (second edition)|year=1999|publisher=[[Pearson PLC|Pearson]]|page=119}}&lt;/ref&gt; '''Metrization theorems''' are [[theorem]]s that give [[sufficient condition]]s for a topological space to be metrizable.

==Properties==
Metrizable spaces inherit all topological properties from metric spaces. For example, they are [[Hausdorff space|Hausdorff]] [[paracompact]] spaces (and hence [[normal space|normal]] and [[Tychonoff space|Tychonoff]]) and [[first-countable space|first-countable]].  However, some properties of the metric, such as completeness, cannot be said to be inherited. This is also true of other structures linked to the metric. A metrizable [[uniform space]], for example, may have a different set of [[Contraction mapping|contraction maps]] than a metric space to which it is homeomorphic.

==Metrization theorems==
One of the first widely recognized metrization theorems was '''Urysohn's metrization theorem'''. This states that every Hausdorff [[second-countable]] [[regular space]] is metrizable. So, for example, every second-countable [[manifold]] is metrizable. (Historical note: The form of the theorem shown here was in fact proved by [[Andrey Nikolayevich Tychonoff|Tychonoff]] in 1926. What [[Pavel Samuilovich Urysohn|Urysohn]] had shown, in a paper published posthumously in 1925, was that every second-countable ''[[normal space|normal]]'' Hausdorff space is metrizable). The converse does not hold: there exist metric spaces that are not second countable, for example, an uncountable set endowed with the discrete metric.&lt;ref&gt;{{Cite web |url=http://www.math.lsa.umich.edu/~mityab/teaching/m395f10/10_counterexamples.pdf |title=Archived copy |access-date=2012-08-08 |archive-url=https://web.archive.org/web/20110925003841/http://www.math.lsa.umich.edu/~mityab/teaching/m395f10/10_counterexamples.pdf |archive-date=2011-09-25 |dead-url=yes |df= }}&lt;/ref&gt; The [[Nagata–Smirnov metrization theorem]], described below, provides a more specific theorem where the converse does hold.

Several other metrization theorems follow as simple corollaries to Urysohn's Theorem. For example, a [[Compact space|compact]] Hausdorff space is metrizable if and only if it is second-countable.

Urysohn's Theorem can be restated as: A topological space is [[separable space|separable]] and metrizable if and only if it is regular, Hausdorff and second-countable. The [[Nagata–Smirnov metrization theorem]] extends this to the non-separable case. It states that a topological space is metrizable if and only if it is regular, Hausdorff and has a σ-locally finite base. A σ-locally finite base is a base which is a union of countably many [[locally finite collection]]s of open sets. For a closely related theorem see the [[Bing metrization theorem]].

Separable metrizable spaces can also be characterized as those spaces which are [[homeomorphic]] to a subspace of the [[Hilbert cube]] &lt;math&gt;\lbrack 0,1\rbrack ^\mathbb{N}&lt;/math&gt;, i.e. the countably infinite product of the unit interval (with its natural subspace topology from the reals) with itself, endowed with the [[product topology]].

A space is said to be '''locally metrizable''' if every point has a metrizable [[neighbourhood (mathematics)|neighbourhood]]. Smirnov proved that a locally metrizable space is metrizable if and only if it is Hausdorff and [[paracompact]]. In particular, a manifold is metrizable if and only if it is paracompact.

==Examples==
The group of unitary operators &lt;math&gt; \mathbb{U}(\mathcal{H})&lt;/math&gt; on a separable Hilbert space &lt;math&gt; \mathcal{H}&lt;/math&gt; endowed
with the strong operator topology is metrizable (see Proposition II.1 in  &lt;ref&gt;Neeb, Karl-Hermann,
On a theorem of S. Banach. 
J. Lie Theory 7 (1997), no. 2, 293–300.&lt;/ref&gt;).

== Examples of non-metrizable spaces==
Non-normal spaces cannot be metrizable; important examples include
* the [[Zariski topology]] on an [[algebraic variety]] or on the [[spectrum of a ring]], used in [[algebraic geometry]],
* the [[topological vector space]] of all [[function (mathematics)|function]]s from the [[real line]] '''R''' to itself, with the [[topology of pointwise convergence]].

The real line with the [[lower limit topology]] is not metrizable.  The usual distance function is not a metric on this space because the topology it determines is the usual topology, not the lower limit topology. This space is Hausdorff, paracompact and first countable.

The [[long line (topology)|long line]] is locally metrizable but not metrizable; in a sense it is "too long".

== See also ==
* [[Uniformizability]], the property of a topological space of being homeomorphic to a [[uniform space]], or equivalently the topology being defined by a family of [[pseudometric space|pseudometrics]]
* [[Moore space (topology)]]
* [[Ion Barbu#Apollonian metric|Apollonian metric]]
*  [[Nagata–Smirnov metrization theorem]]
* [[Bing metrization theorem]]

==References==
{{reflist}}

{{PlanetMath attribution|id=1538|title=Metrizable}}

[[Category:General topology]]
[[Category:Theorems in topology]]</text>
      <sha1>rdfm05w2jh3qntofid8ndxp5aslb56o</sha1>
    </revision>
  </page>
  <page>
    <title>Mikhail Kadets</title>
    <ns>0</ns>
    <id>34061412</id>
    <revision>
      <id>845007080</id>
      <parentid>842799986</parentid>
      <timestamp>2018-06-08T17:46:24Z</timestamp>
      <contributor>
        <ip>209.93.28.137</ip>
      </contributor>
      <comment>same date format throughout</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7982">{{Infobox scientist
|name              = Mikhail Kadets
|image             = 
|image_size        =
|caption           =
|birth_date        = {{birth date|1923|11|30|df=y}}
|birth_place       = [[Kiev]]
|death_date        = {{Death date and age|2011|3|7|1923|11|30|df=y}}
|death_place       = [[Kharkov]]
|residence         = 
|citizenship       = [[Ukraine]]
|nationality       =
|ethnicity         =
|fields            = [[Banach space]]s &lt;br&gt; [[harmonic analysis]]
|workplaces        = 
|alma_mater        = [[Kharkov University]]
|doctoral_advisor  = [[Boris Levin]]
|academic_advisors =
|doctoral_students = 
|notable_students  =
|known_for         = Banach–Fréchet problem&lt;br&gt;Kadets&amp;nbsp;{{frac|1|4}}-theorem&lt;br&gt;Kadets–Snobar estimate
|influences        = 
|influenced        =
|awards            = 
|religion          =
|signature         =  &lt;!--(filename only)--&gt;
|footnotes         =
}}

'''Mikhail&amp;nbsp;Iosiphovich Kadets''' ({{lang-ru|Михаил Иосифович Кадец}}, {{lang-uk|Михайло Йосипович Кадець }},  sometimes transliterated as '''Kadec''', 30 November 1923 – 7 March 2011) was a Soviet-born Jewish mathematician working in [[mathematical analysis|analysis]] and the theory of [[Banach space]]s.&lt;ref&gt;{{cite journal|mr=2829617|title=In memory of Mikhail Iosifovich Kadets (1923–2011)|journal=Zh. Mat. Fiz. Anal. Geom.|volume= 7 |year=2011|issue=2|pages=194–195|language=Russian}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|journal=Russ. Math. Surv. |volume=66|issue=4|pages=809|year=2011|doi=10.1070/RM2011v066n04ABEH004756|title=Mikhail Iosifovich Kadets (obituary)|first1=Yurii&amp;nbsp;I. |last1=Lyubich|authorlink1=Yurii Lyubich|first2=Vladimir&amp;nbsp;A.|last2= Marchenko|first3=Sergei&amp;nbsp;P.|last3= Novikov|first4=M.&amp;nbsp;I.|last4=Ostrovskii|first5=Leonid&amp;nbsp;A.|last5= Pastur|first6=Anatolii&amp;nbsp;N.|last6= Plichko|first7=M.&amp;nbsp;M.|last7=Popov|first8=Evgenii&amp;nbsp;M.|last8= Semenov|first9=S.&amp;nbsp;L.|last9=Troyanskii|first10=Vladimir&amp;nbsp;P.|last10= Fonf|first11=Evgenii&amp;nbsp;Ya.|last11= Khruslov}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|mr=0771114|last1=Gelʹfand|first1=I.&amp;nbsp;M.|last2=Levin|first2=B.&amp;nbsp;Ya.|last3=Marchenko|first3=V.&amp;nbsp;A.|last4=Pogorelov|first4=A.&amp;nbsp;V.|last5=Sobolev|first5=S.&amp;nbsp;L.|title=
Mikhail&amp;nbsp;Iosifovich Kadets (on the occasion of his sixtieth birthday)|journal=Russian Math. Surveys|volume=39 |year=1984|issue=6|pages=231–232|doi=10.1070/rm1984v039n06abeh003197}}&lt;/ref&gt;

==Life and work==
Kadets was born in Kiev. In 1943, he was drafted into the army. After demobilisation in 1946, he studied at [[Kharkov University]], graduating in 1950. After several years in [[Makeevka]] he returned to Kharkov in 1957, where he spent the remainder of his life working at various institutes. He defended his PhD in 1955 (under the supervision of [[Boris Levin]]), and his doctoral dissertation in 1963.  He was awarded the State Prize of Ukraine in 2005.

After reading the Ukrainian translation of [[Stefan Banach|Banach]]'s monograph ''Théorie des opérations linéaires'',&lt;ref&gt;The French original {{cite book|jfm=58.0420.01|last=
Banach|first=S.|authorlink=Stefan Banach|title=Theory of Linear Operations|location=Warszawa|publisher=Mathematisches Seminar der Univ. Warschau|series= Monografje Matematyczne I|year=1932}} was translated as {{cite book|last=Banach|first=S.|location=Kiev|year=1948|language=Ukrainian|title=Course in functional analysis|publisher=Radians'ka shkola}}&lt;/ref&gt; he became interested in the theory of Banach spaces.&lt;ref&gt;{{harvtxt|Ostrovskii|Plichko|2009|loc=First page of preprint}}: {{cite journal|mr=2597043|last=Ostrovskii|first=M. I.|last2=Plichko|first2=A. M.|title=On the Ukrainian translation of ''Théorie des opérations linéaires'' and Mazur's updates of the "remarks" section|journal=
Mat. Stud.|volume= 32|year=2009|issue=1|pages=96–111|ref=harv|url=http://facpub.stjohns.edu/ostrovsm/OstrovskiiPlichko.pdf|format=pdf}}&lt;/ref&gt; In 1966, Kadets solved in the affirmative the [[Stefan Banach|Banach]]–[[Maurice René Fréchet|Fréchet]] problem, asking whether every two [[separable space|separable]] infinite-dimensional  Banach spaces are [[homeomorphism|homeomorphic]]. He developed the method of equivalent norms, which has found numerous applications. For example, he showed that every separable Banach space admits an equivalent [[Fréchet derivative|Fréchet differentiable]] norm if and only if the [[dual space]] is separable.&lt;ref name=pietsch&gt;{{cite book|mr=2300779|last=Pietsch|first=Albrecht|title=History of Banach spaces and linear operators|publisher=Birkhäuser Boston, Inc.|location=Boston, MA|year=2007|isbn=978-0-8176-4367-6|page=609}}&lt;/ref&gt;

Together with [[Aleksander Pełczyński]], he obtained important results on the topological structure of [[Lp space]]s.&lt;ref&gt;{{cite book|mr=0889253|last=Beauzamy|first=Bernard|title=Introduction to Banach spaces and their geometry|edition=2nd|series=North-Holland Mathematics Studies|volume=68|publisher=North-Holland Publishing Co.|location=Amsterdam|year=1985|isbn=0-444-87878-5 |chapter=Chapter VI}}&lt;/ref&gt;

Kadets also made several contributions to the theory of finite-dimensional normed spaces. Together with M.&amp;nbsp;G.&amp;nbsp;Snobar (1971), he showed that every ''n''-dimensional subspace of a Banach space is the image of a projection of norm at most {{sqrt|''n''}}.&lt;ref&gt;{{cite book|mr=2766381|last=Fabian|first=Marián|last2=Habala|first2=Petr|last3=Hájek|first3=Petr|last4=Montesinos|first4=Vicente|last5=Zizler|first5=Václav|title=Banach&amp;nbsp;space theory. The basis for linear and nonlinear analysis|series=CMS Books in Mathematics/Ouvrages de Mathématiques de la SMC|publisher=Springer|location=New York|year=2011|isbn=978-1-4419-7514-0|pages=320–323}}&lt;/ref&gt; Together with [[Vladimir Gurariy|V.&amp;nbsp;I.&amp;nbsp;Gurarii]] and V.&amp;nbsp;I.&amp;nbsp;Matsaev, he found the exact order of magnitude of the [[Banach–Mazur distance]] between the ''n''-dimensional spaces {{nowrap|''ℓ''{{su|p=''n''|b=''p''}}}} and {{nowrap|''ℓ''{{su|p=''n''|b=''q''}}}}.&lt;ref&gt;{{cite book|mr=0993774|last=Tomczak-Jaegermann|first=Nicole|title=Banach-Mazur distances and finite-dimensional operator ideals|series= 
Pitman Monographs and Surveys in Pure and Applied Mathematics|volume=38|publisher=Longman Scientific &amp; Technical|location=Harlow|year=1989|isbn=0-582-01374-7|page=138}}&lt;/ref&gt;

In [[harmonic analysis]], Kadets proved (1964) what is now called the Kadets&amp;nbsp;{{frac|1|4}} theorem, which states that, if |''&amp;lambda;''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;&amp;minus;&amp;nbsp;''n''|&amp;nbsp;≤&amp;nbsp;''C''&amp;nbsp;&lt;&amp;nbsp;{{frac|1|4}} for all integer ''n'', then the sequence (exp(''i&amp;lambda;''&lt;sub&gt;''n''&lt;/sub&gt;x))&lt;sub&gt;''n''&amp;nbsp;∈&amp;nbsp;'''Z'''&lt;/sub&gt; is a [[Riesz sequence|Riesz basis]] in ''L''&lt;sub&gt;2&lt;/sub&gt;[-{{pi}},&amp;nbsp;{{pi}}].&lt;ref&gt;{{cite book|mr=0499341|last=Higgins|first=John Rowland|title=Completeness and basis&amp;nbsp;properties of sets of special functions|series=Cambridge Tracts in Mathematics|volume=72|publisher=Cambridge University Press|location=Cambridge-New York-Melbourne|year=1977|isbn=0-521-21376-2}}&lt;/ref&gt;

Kadets was the founder of the Kharkov school of Banach spaces.&lt;ref name=pietsch/&gt;
Together with his son Vladimir Kadets, he authored two books about series in Banach spaces.&lt;ref&gt;
{{cite book|last1=Kadets|first1=Mikhail I.|last2=Kadets|first2=Vladimir M.|chapter=|title=Series in Banach spaces: Conditional and unconditional convergence| edition=Translated by Andrei Iacob from the Russian-language|series=Operator Theory: Advances and Applications|volume=94|publisher=Birkhäuser Verlag|location=Basel|year=1997|pages=viii+156|isbn=3-7643-5401-1|mr=1442255}}
&lt;/ref&gt;

==Notes==
{{Reflist}}

==External links==
* [http://testuvannya.com.ua/M.I.Kadets/ Kadets memorial website]
* {{MathGenealogy|id=75247}}

{{Authority control}}

{{DEFAULTSORT:Kadets, Mikhail}}
[[Category:Functional analysts]]
[[Category:Mathematical analysts]]
[[Category:University of Kharkiv alumni]]
[[Category:1923 births]]
[[Category:2011 deaths]]</text>
      <sha1>ji5x734k8jrxvzs54onrfwck2syx7cw</sha1>
    </revision>
  </page>
  <page>
    <title>Modulus of continuity</title>
    <ns>0</ns>
    <id>964161</id>
    <revision>
      <id>857235079</id>
      <parentid>837720964</parentid>
      <timestamp>2018-08-30T12:19:58Z</timestamp>
      <contributor>
        <ip>83.29.36.111</ip>
      </contributor>
      <comment>I changed "diagonal of X" into "diagonal of X x X"</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19209">In [[mathematical analysis]], a '''modulus of continuity''' is a function ω : [0, ∞] → [0, ∞] used to measure quantitatively the [[uniform continuity]] of functions. So, a function ''f'' : ''I'' → '''R''' admits ω as a modulus of continuity if and only if
:&lt;math&gt;|f(x)-f(y)|\leq\omega(|x-y|),&lt;/math&gt;
for all ''x'' and ''y'' in the domain of ''f''. Since moduli of continuity are required to be infinitesimal at 0, a function turns out to be uniformly continuous if and only if it admits a modulus of continuity. Moreover, relevance to the notion is given by the fact that sets of functions sharing the same modulus of continuity are exactly [[equicontinuity|equicontinuous families]]. For instance, the modulus ω(''t'') := ''kt'' describes the k-[[Lipschitz functions]], the moduli ω(''t'') := ''kt''&lt;sup&gt;α&lt;/sup&gt; describe the [[Hölder continuity]], the modulus ω(''t'') := ''kt''(|log(''t'')|+1) describes the '''almost Lipschitz''' class, and so on. In general, the role of ω is to fix some explicit functional dependence of ε on δ in the [[(ε, δ)-definition of limit#Uniform continuity|(ε, δ) definition of uniform continuity]]. The same notions generalize naturally to functions between [[metric space]]s. Moreover, a suitable local version of these notions allows to describe quantitatively the continuity at a point in terms of moduli of continuity.

A special role is played by concave moduli of continuity, especially in connection with extension properties, and with approximation of uniformly continuous functions. For a function between metric spaces, it is equivalent to admit a modulus of continuity that is either concave, or subadditive, or uniformly continuous, or sublinear (in the sense of [[linear growth|growth]]). Actually, the existence of such special moduli of continuity for a uniformly continuous function is always ensured whenever the domain is either a compact, or a convex subset of a normed space. However, a uniformly continuous function on a general metric space admits a concave modulus of continuity if and only if the ratios

:&lt;math&gt;\frac{d_Y(f(x),f(x'))}{d_X(x,x')}&lt;/math&gt;

are uniformly bounded for all pairs (''x'', ''x''′) bounded away from the diagonal of ''X x X''. The functions with the latter property constitute a special subclass of the uniformly continuous functions, that in the following we refer to as the ''special uniformly continuous'' functions. Real-valued special uniformly continuous functions on the metric space ''X'' can also be characterized as the set of all functions that are restrictions to ''X'' of uniformly continuous functions over any normed space isometrically containing ''X''. Also, it can be characterized as the uniform closure of the Lipschitz functions on ''X''.

==Formal definition==
Formally, a modulus of continuity is any real-extended valued function ω : [0, ∞] → [0, ∞], vanishing at 0 and continuous at 0, that is
:&lt;math&gt;\lim_{t\to0}\omega(t)=\omega(0)=0.&lt;/math&gt;

Moduli of continuity are mainly used to give a quantitative account both of the continuity at a point, and of the uniform continuity, for functions between metric spaces, according to the following definitions.

A function ''f'' : (''X'', ''d&lt;sub&gt;X&lt;/sub&gt;'') → (''Y'', ''d&lt;sub&gt;Y&lt;/sub&gt;'') admits ω as (local) modulus of continuity at the point ''x'' in ''X'' if and only if,
:&lt;math&gt;\forall x'\in X: d_Y(f(x),f(x'))\leq\omega(d_X(x,x')).&lt;/math&gt;
Also, ''f'' admits ω as (global) modulus of continuity if and only if,
:&lt;math&gt;\forall x,x'\in X: d_Y(f(x),f(x'))\leq\omega(d_X(x,x')).&lt;/math&gt;
One equivalently says that ω is a modulus of continuity (resp., at ''x'') for ''f'', or shortly, ''f'' is ω-continuous (resp., at ''x''). Here, we mainly treat the global notion.

===Elementary facts===
*If ''f'' has ω as modulus of continuity and ω&lt;sub&gt;1&lt;/sub&gt; ≥ ω, then, obviously, ''f'' admits ω&lt;sub&gt;1&lt;/sub&gt; too as modulus of continuity.
*If ''f'' : ''X'' → ''Y'' and ''g'' : ''Y'' → ''Z'' are functions between metric spaces with moduli respectively ω&lt;sub&gt;1&lt;/sub&gt; and ω&lt;sub&gt;2&lt;/sub&gt;, then the composition map &lt;math&gt;g\circ f:X\to Z&lt;/math&gt; has modulus of continuity &lt;math&gt;\omega_2\circ\omega_1&lt;/math&gt;.
*If ''f'' and ''g'' are functions from the metric space X to the Banach space ''Y'', with moduli respectively ω&lt;sub&gt;1&lt;/sub&gt; and ω&lt;sub&gt;2&lt;/sub&gt;, then any linear combination ''af''+''bg'' has modulus of continuity |''a''|ω&lt;sub&gt;1&lt;/sub&gt;+|''b''|ω&lt;sub&gt;2&lt;/sub&gt;. In particular, the set of all functions from ''X'' to ''Y'' that have ω as a modulus of continuity is a convex subset of the vector space ''C''(''X'', ''Y''), closed under [[pointwise convergence]].
*If ''f'' and ''g'' are bounded real-valued functions on the metric space ''X'', with moduli respectively ω&lt;sub&gt;1&lt;/sub&gt; and ω&lt;sub&gt;2&lt;/sub&gt;, then the pointwise product ''fg'' has modulus of continuity &lt;math&gt;\|g\|_\infty\omega_1+\|f\|_\infty \omega_2&lt;/math&gt;.
*If &lt;math&gt;\{f_\lambda\}_{\lambda\in\Lambda}&lt;/math&gt; is a family of real-valued functions on the metric space ''X'' with common modulus of continuity ω, then the inferior envelope &lt;math&gt;\inf_{\lambda\in\Lambda}f_\lambda&lt;/math&gt;, respectively, the superior envelope &lt;math&gt;\sup_{\lambda\in\Lambda}f_\lambda&lt;/math&gt;, is a real-valued function with modulus of continuity ω, provided it is finite valued at every point. If ω is real-valued, it is sufficient that the envelope be finite at one point of ''X'' at least.

===Remarks===
*Some authors require additional properties such as ω being increasing, or continuous. However, if f admits a modulus of continuity in the weaker definition above, it also admits a modulus of continuity which is increasing and infinitely differentiable in [0, ∞]. For instance,
::&lt;math&gt;\omega_1(t):=\sup_{s\leq t}\omega(s)&lt;/math&gt; is increasing, and ω&lt;sub&gt;1&lt;/sub&gt; ≥ ω;
::&lt;math&gt;\omega_2(t):=\frac{1}{t}\int_t^{2t}\omega_1(s)ds&lt;/math&gt; is also continuous, and ω&lt;sub&gt;2&lt;/sub&gt; ≥ ω&lt;sub&gt;1&lt;/sub&gt;,
:and a suitable variant of the preceding definition also makes ω&lt;sub&gt;2&lt;/sub&gt; infinitely differentiable in [0, ∞].
*Any uniformly continuous function admits a minimal modulus of continuity ω&lt;sub&gt;''f''&lt;/sub&gt;, that is sometimes referred to as ''the'' (optimal) modulus of continuity of ''f'':
::&lt;math&gt;\omega_f(t):=\sup\{ d_Y(f(x),f(x')):x\in X,x'\in X,d_X(x,x')=t \} ,\quad\forall t\geq0.&lt;/math&gt;
:Similarly, any function continuous at the point ''x'' admits a minimal modulus of continuity at ''x'', ω&lt;sub&gt;''f''&lt;/sub&gt;(''t''; ''x'') (''the'' (optimal) modulus of continuity of ''f'' at ''x'') :
::&lt;math&gt;\omega_f(t;x):=\sup\{ d_Y(f(x),f(x')): x'\in X,d_X(x,x')= t \},\quad\forall t\geq0.&lt;/math&gt;
:However, these restricted notions are not as relevant, for in most cases the optimal modulus of ''f'' could not be computed explicitly, but only bounded from above (by ''any'' modulus of continuity of f). Moreover, the main properties of moduli of continuity concern directly the unrestricted definition.
*In general, the modulus of continuity of a uniformly continuous function on a metric space needs to take the value +∞. For instance, the function ''f'' : '''N''' → '''N''' such that ''f''(''n'') := ''n''&lt;sup&gt;2&lt;/sup&gt; is uniformly continuous with respect to the [[discrete metric]] on '''N''', and its minimal modulus of continuity is ω&lt;sub&gt;''f''&lt;/sub&gt;(''t'') = +∞ for any positive integer ''t'', and ω&lt;sub&gt;''f''&lt;/sub&gt;(''t'') = 0 otherwise. However, the situation is different for uniformly continuous functions defined on compact or convex subsets of normed spaces.

==Special moduli of continuity==
Special moduli of continuity also reflect certain global properties of functions such as extendibility and uniform approximation. In this section we mainly deal with moduli of continuity that are [[concave function|concave]], or [[subadditive]], or uniformly continuous, or sublinear. These properties are essentially equivalent in that, for a modulus ω (more precisely, its restriction on [0, ∞]) each of the following implies the next:
*ω is concave;
*ω is subadditive;
*ω is uniformly continuous;
*ω is sublinear, that is, there are constants ''a'' and ''b'' such that ω(''t'') ≤ ''at''+''b'' for all ''t'';
*ω is dominated by a concave modulus, that is, there exists a concave modulus of continuity &lt;math&gt;\tilde\omega&lt;/math&gt; such that &lt;math&gt;\omega(t)\leq \tilde\omega(t)&lt;/math&gt; for all ''t''.

Thus, for a function ''f'' between metric spaces it is equivalent to admit a modulus of continuity which is either concave, or subadditive, or uniformly continuous, or sublinear. In this case, the function ''f'' is sometimes called a ''special uniformly continuous'' map. This is always true in case of either compact or convex domains. Indeed, a uniformly continuous map ''f'' : ''C'' → ''Y'' defined on a [[convex set]] ''C'' of a normed space ''E'' always admits a [[subadditive]] modulus of continuity; in particular, real-valued as a function ω : [0, ∞] → [0, ∞]. Indeed, it is immediate to check that the optimal modulus of continuity ω&lt;sub&gt;''f''&lt;/sub&gt; defined above is subadditive if the domain of ''f'' is convex: we have, for all ''s'' and ''t'':

:&lt;math&gt;\begin{align}
\omega_f(s+t) &amp;=\sup_{|x-x'|=t+s} d_Y(f(x),f(x')) \\
&amp;\leq \sup_{|x-x'|=t+s}\left\{d_Y\left( f(x), f\left(x +t\frac{x-x'}{|x-x'|}\right)\right) + d_Y\left( f\left(x +t\frac{x-x'}{|x-x'|}\right), f(x')\right )\right\} \\
&amp;\leq \omega_f(t)+\omega_f(s).
\end{align}&lt;/math&gt;

However, a uniformly continuous function on a general metric space admits a concave modulus of continuity if and only if the ratios &lt;math&gt;d_Y(f(x),f(x'))/d_X(x,x')&lt;/math&gt; are uniformly bounded for all pairs (''x'', ''x''′) bounded away from the diagonal of ''X''; this condition is certainly satisfied by any bounded uniformly continuous function; hence in particular, by any continuous function on a compact metric space.

===Sublinear moduli, and bounded perturbations from Lipschitz===
A sublinear modulus of continuity can easily found for any uniformly function which is a bounded perturbation of a Lipschitz function: if ''f'' is a uniformly continuous function with modulus of continuity ω, and ''g'' is a ''k'' Lipschitz function with uniform distance ''r'' from ''f'', then ''f'' admits the sublinear module of continuity min{ω(''t''), 2''r''+''kt''}. Conversely, at least for real-valued functions, any bounded, uniformly continuous perturbation of a Lipschitz function is a special uniformly continuous function; indeed more is true as shown below. Note that as an immediate consequence, any uniformly continuous function on a convex subset of a normed space has a sublinear growth: there are constants ''a'' and ''b'' such that |''f''(''x'')| ≤ ''a''|''x''|+''b'' for all ''x''.

===Subadditive moduli, and extendibility===
The above property for uniformly continuous function on convex domains admits a sort of converse at least in the case of real-valued functions: that is, every special uniformly continuous real-valued function ''f'' : ''X'' → '''R''' defined on a subset ''X'' of a normed space ''E'' admits extensions over ''E'' that preserves any subadditive modulus ω of ''f''. The least and the greatest of such extensions are respectively:

:&lt;math&gt;\begin{align}
f_*(x) &amp;:=\sup_{y\in X}\left\{f(y)-\omega(|x-y|)\right\}, \\
f^*(x) &amp;:=\inf_{y\in X}\left\{f(y)+\omega(|x-y|)\right\}.
\end{align}&lt;/math&gt;

As remarked, any subadditive modulus of continuity is uniformly continuous: in fact, it admits itself as a modulus of continuity. Therefore, ''f''&lt;sub&gt;∗&lt;/sub&gt; and ''f*'' are respectively inferior and superior envelopes of ω-continuous families; hence still ω-continuous. Incidentally, by the [[Kuratowski embedding]] any metric space is isometric to a subset of a normed space. Hence, special uniformly continuous real-valued functions are essentially the restrictions of uniformly continuous functions on normed spaces. In particular, this construction provides a quick proof of the [[Tietze extension theorem]] on compact metric spaces. However, for mappings with values in more general Banach spaces than '''R''', the situation is quite more complicated; the first non-trivial result in this direction is the [[Kirszbraun theorem]].

===Concave moduli, and Lipschitz approximation===
Every special uniformly continuous real-valued function ''f'' : ''X'' → '''R''' defined on the metric space ''X'' is [[uniform convergence|uniformly]] approximable by means of Lipschitz functions. Moreover, the speed of convergence in terms of the Lipschitz constants of the approximations is strictly related to the modulus of continuity of ''f''. Precisely, let ω be the minimal concave modulus of continuity of ''f'', which is
:&lt;math&gt;\omega(t)=\inf\big\{at+b\, :\, a&gt;0,\, b&gt;0,\, \forall x\in X,\, \forall x'\in X\,\,  |f(x)-f(x')|\leq a|x-x'|+b\big\}.&lt;/math&gt;
Let δ(''s'') be the uniform [[metric spaces#Distance between points and sets; Hausdorff distance and Gromov metric|distance]] between the function ''f'' and the set Lip&lt;sub&gt;''s''&lt;/sub&gt; of all Lipschitz real-valued functions on ''C'' having Lipschitz constant ''s'' :
:&lt;math&gt;\delta(s):=\inf\big\{\|f-u\|_{\infty,X}\,:\, u\in \mathrm{Lip}_s\big\}\leq+\infty.&lt;/math&gt;
Then the functions ω(''t'') and δ(''s'') can be related with each other via a [[Legendre transformation]]: more precisely, the functions 2δ(''s'') and −ω(−''t'') (suitably extended to +∞ outside their domains of finiteness) are a pair of conjugated convex functions&lt;sup&gt;[http://mathoverflow.net/questions/194863/legendre-transform-and-lipschitz-approximation/194890#194890]&lt;/sup&gt;, for

:&lt;math&gt;2\delta(s)=\sup_{t\geq0}\left\{\omega(t)-st\right\},&lt;/math&gt;
:&lt;math&gt;\omega(t)=\inf_{s\geq0}\left\{2\delta(s)+st\right\}.&lt;/math&gt;

Since ω(''t'') = o(1) for ''t'' → 0&lt;sup&gt;+&lt;/sup&gt;, it follows that δ(''s'') = o(1) for ''s'' → +∞, that exactly means that ''f'' is uniformly approximable by Lipschitz functions. Correspondingly, an optimal approximation is given by the functions
:&lt;math&gt;f_s:=\delta(s)+\inf_{y\in X}\{f(y)+sd(x,y)\}, \quad  \mathrm{for} \ s\in\mathrm{dom}(\delta):&lt;/math&gt;
each function ''f&lt;sub&gt;s&lt;/sub&gt;'' has Lipschitz constant ''s'' and
:&lt;math&gt;\|f-f_s\|_{\infty,X}=\delta(s);&lt;/math&gt;
in fact, it is the greatest ''s''-Lipschitz function that realize the distance δ(''s''). For example, the α-Hölder real-valued functions on a metric space are characterized as those functions that can be uniformly approximated by ''s''-Lipschitz functions with speed of convergence &lt;math&gt;O(s^{-\frac{\alpha}{1-\alpha}}),&lt;/math&gt; while the almost Lipschitz functions are characterized by an exponential speed of convergence &lt;math&gt;O(e^{-as}).&lt;/math&gt;

==Examples of use==
*Let ''f'' : [''a'', ''b''] → '''R''' a continuous function. In the proof that ''f'' is [[Riemann integrable]], one usually  bounds the distance between the upper and lower [[Riemann sums]] with respect to the Riemann partition ''P'' := {''t''&lt;sub&gt;0&lt;/sub&gt;, ..., ''t&lt;sub&gt;n&lt;/sub&gt;''} in terms of the modulus of continuity of ''f'' and the [[Riemann_integrable#Definition|mesh]] of the partition ''P'' (which  is the number &lt;math&gt; \scriptstyle |P|:=\max_{0\le i&lt;n} (t_{i+1}-t_i)\quad &lt;/math&gt;)
::&lt;math&gt;S^*(f;P)-S_*(f;P)\leq(b-a)\omega(|P|).&lt;/math&gt;

*For an example of use in the Fourier series, see [[Dini test]].

==History==
Steffens (2006, p.&amp;nbsp;160) attributes the first usage of omega for the modulus of continuity to [[Lebesgue]] (1909, p.&amp;nbsp;309/p.&amp;nbsp;75) where omega refers to the oscillation of a Fourier transform. [[De la Vallée Poussin]] (1919, pp.&amp;nbsp;7-8) mentions both names (1) "modulus of continuity" and (2) "modulus of oscillation" and then concludes "but we choose (1) to draw attention to the usage we will make of it".

==The translation group of ''L&lt;sup&gt;p&lt;/sup&gt;'' functions, and moduli of continuity ''L&lt;sup&gt;p&lt;/sup&gt;''.==
Let 1 ≤ ''p''; let ''f'' : '''R'''&lt;sup&gt;''n''&lt;/sup&gt; → '''R''' a function of class ''L&lt;sup&gt;p&lt;/sup&gt;'', and let ''h'' ∈ '''R'''&lt;sup&gt;''n''&lt;/sup&gt;. The ''h''-[[Translation (geometry)|translation]] of ''f'', the function defined by (τ&lt;sub&gt;''h''&lt;/sub&gt;''f'')(''x'') := ''f''(''x''−''h''), belongs to the ''L&lt;sup&gt;p&lt;/sup&gt;'' class; moreover, if 1 ≤ ''p'' &lt; ∞, then as ǁ''h''ǁ → 0 we have:

:&lt;math&gt;\|\tau_h f - f\|_p=o(1).&lt;/math&gt;

Therefore, since translations are in fact  linear isometries, also

:&lt;math&gt;\|\tau_{v+h} f - \tau_v f\|_p=o(1),&lt;/math&gt;

as ǁ''h''ǁ → 0, uniformly on ''v'' ∈ '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.

In other words, the map ''h'' → τ&lt;sub&gt;''h''&lt;/sub&gt; defines a strongly continuous group of linear isometries of ''L&lt;sup&gt;p&lt;/sup&gt;''. In the case ''p'' = ∞ the above property does not hold in general: actually, it exactly reduces to the uniform continuity, and defines the uniform continuous functions. This leads to the following definition, that generalizes the notion of a modulus of continuity of the uniformly continuous functions: a modulus of continuity ''L&lt;sup&gt;p&lt;/sup&gt;'' for a measurable function ''f'' : ''X'' → '''R''' is a modulus of continuity ω : [0, ∞] → [0, ∞] such that

:&lt;math&gt;\|\tau_h f - f\|_p\leq \omega(h).&lt;/math&gt;

This way, moduli of continuity also give a quantitative account of the continuity property shared by all ''L&lt;sup&gt;p&lt;/sup&gt;'' functions.

==Modulus of continuity of higher orders==
It can be seen that formal definition of the modulus uses notion of [[finite difference]] of first order:

:&lt;math&gt;\omega_f(\delta)=\omega(f, \delta)=\sup\limits_{x; |h|&lt;\delta;}\left|\Delta_h(f,x)\right|.&lt;/math&gt;

If we replace that difference with a [[finite difference#Higher-order differences|difference of order ''n'']], we get a modulus of continuity of order ''n'':

:&lt;math&gt;\omega_n(f, \delta)=\sup\limits_{x; |h|&lt;\delta;}\left|\Delta^n_h(f,x)\right|.&lt;/math&gt;

==See also==
* [[Constructive analysis]]
* [[Modulus of convergence]]

==References==
*{{cite book |first=G. |last=Choquet |title=Cours D'Analyse. Tome II, Topologie |publisher=Masson et C&lt;sup&gt;ie&lt;/sup&gt; |location=Paris |year=1964 |language=fr}}
*{{cite book |first=A. V. |last=Efimov |chapterurl=http://eom.springer.de/c/c025580.htm |chapter=Modulus of continuity |title=Encyclopaedia of Mathematics |publisher=Springer |year=2001 |isbn=1-4020-0609-8 }}
*{{cite book |first=H. |last=Lebesgue |chapter=Sur les intégrales singulières |series=Ann. Fac. Sci. Univ. Toulouse |volume=3 |issue=1 |year=1909 |pages=25–117 }} Reproduced in: {{cite book |first=Henri |last=Lebesgue |title=Œuvres scientifiques |volume=3 |pages=259–351 |language=fr}}
*{{cite book |first=Ch. de la Vallée |last=Poussin |title=L'approximation des fonctions d'une variable réelle |publisher=Gauthier-Villars |location=Paris |year=1952 |edition=Reprint of 1919 |isbn= |language=fr}}
*{{cite book |first1=Y| last1=Benyamini|first2=J| last2= Lindenstrauss |title=Geometric Nonlinear Functional Analysis: Volume 1 |publisher=American Mathematical Soc. |location=Providence, RI  |year=1998 |edition=Colloquium Publications, Vol. 48 |isbn= |language=en}}
*{{cite book |first=K.-G. |last=Steffens |title=The History of Approximation Theory |publisher=Birkhäuser |location=Boston |year=2006 |isbn=0-8176-4353-2 }}

[[Category:Lipschitz maps]]
[[Category:Approximation theory]]
[[Category:Constructivism (mathematics)]]
[[Category:Fourier analysis]]</text>
      <sha1>ojgywne5jbpr9ews3loj3d606hspedz</sha1>
    </revision>
  </page>
  <page>
    <title>Multi-compartment model</title>
    <ns>0</ns>
    <id>9050760</id>
    <revision>
      <id>841936012</id>
      <parentid>787349982</parentid>
      <timestamp>2018-05-19T02:21:23Z</timestamp>
      <contributor>
        <username>Rdsteed</username>
        <id>33796660</id>
      </contributor>
      <minor/>
      <comment>Added heading for multi-compartment model.  Removed caption for previously deleted three compartment model and dead link to removed image.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8127">A '''multi-compartment model''' is a type of [[mathematical model]] used for describing the way materials or energies are transmitted among the ''compartments'' of a system. Each compartment is assumed to be a homogeneous entity within which the entities being modelled are equivalent. For instance, in a pharmacokinetic model, the compartments may represent different sections of a body within which the concentration of a drug is assumed to be uniformly equal.

Hence a multi-compartment model is a [[lumped parameters]] model.

Multi-compartment models are used in many fields including [[pharmacokinetics]], [[compartmental models in epidemiology|epidemiology]], [[biomedicine]], [[systems theory]], [[Complex systems|complexity theory]], engineering, physics, information science and social science. The circuits systems can be viewed as a multi-compartment model as well.

In systems theory, it involves the description of a network whose components are compartments that represent a population of elements that are equivalent with respect to the manner in which they process input signals to the compartment.

:
*Instant homogeneous distribution of materials or energies within a "compartment."
*The exchange rate of materials or energies among the compartments is related to the densities of these compartments.
*Usually, it is desirable that the materials do not undergo chemical reactions while transmitting among the compartments.
*When concentration of the cell is of interest, typically the volume is assumed to be constant over time, though this may not be totally true in reality. 
     
Most commonly, the mathematics of multi-compartment models is simplified to provide only a single parameter—such as concentration—within a compartment.

== Single-compartment model ==
[[Image:Singlecell.PNG]]

Possibly the simplest application of multi-compartment model is in the single-cell concentration monitoring (see the figure above). If the volume of a cell is ''V'', the [[mass]] of [[solution|solute]] is ''q'', the input is ''u''(''t'') and the secretion of the solution is proportional to the density of it within the cell, then the concentration of the solution ''C'' within the cell over time is given by

:&lt;math&gt;\frac{\mathrm{d}q}{\mathrm{d}t}=u(t)-kq&lt;/math&gt;

:&lt;math&gt;C=\frac{q}{V}&lt;/math&gt;

where ''k'' is the proportionality.

==Multi-Compartment Model==
As the number of compartments increases, the model can be very complex and the solutions usually beyond ordinary calculation.

The formulae for '''n-cell''' multi-compartment models become:
: &lt;math&gt;
\begin{align}
\dot{q}_1=q_1 k_{11}+q_2 k_{12}+\cdots+q_n k_{1n}+u_1(t) \\
\dot{q}_2=q_1 k_{21}+q_2 k_{22}+\cdots+q_n k_{2n}+u_2(t) \\
\vdots\\
\dot{q}_n=q_1 k_{n1}+q_2 k_{n2}+\cdots+q_n k_{nn}+u_n(t)
\end{align}
&lt;/math&gt;

Where 
:&lt;math&gt;0=\sum^n_{i=1}{k_{ij}}&lt;/math&gt; for &lt;math&gt;j=1,2,\dots,n&lt;/math&gt; (as the total 'contents' of all compartments is constant in a closed system)

Or in matrix forms:
: &lt;math&gt;
\mathbf{\dot{q}}=\mathbf{Kq}+\mathbf{u}&lt;/math&gt;

Where
:&lt;math&gt;\mathbf{K}=\begin{bmatrix}
k_{11}&amp; k_{12} &amp;\cdots &amp;k_{1n}\\
k_{21}&amp; k_{22} &amp; \cdots&amp;k_{2n}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots \\
k_{n1}&amp; k_{n2} &amp;\cdots &amp;k_{nn}\\
\end{bmatrix} 
\mathbf{q}=\begin{bmatrix}
q_1 \\
q_2 \\
\vdots \\
q_n
\end{bmatrix}
\mathbf{u}=\begin{bmatrix}
u_1(t) \\
u_2(t) \\
\vdots \\
u_n(t)
\end{bmatrix}
&lt;/math&gt; and &lt;math&gt;
\begin{bmatrix}
1 &amp; 1 &amp;\cdots &amp; 1\\
\end{bmatrix}\mathbf{K}=\begin{bmatrix}
0 &amp; 0 &amp;\cdots &amp; 0\\
\end{bmatrix} &lt;/math&gt; (as the total 'contents' of all compartments is constant in a closed system)

In the special case of a closed system (see below) i.e. where &lt;math&gt;\mathbf{u}=0&lt;/math&gt; then there is a general solution.

: &lt;math&gt;\mathbf{q} = c_1 e^{\lambda_1 t} \mathbf{v_1} + c_2 e^{\lambda_2 t} \mathbf{v_2} + \cdots + c_n e^{\lambda_n t} \mathbf{v_n}&lt;/math&gt;

Where &lt;math&gt;\lambda_1&lt;/math&gt;, &lt;math&gt;\lambda_2&lt;/math&gt;, ... and &lt;math&gt;\lambda_n&lt;/math&gt; are the [[Eigenvalues and eigenvectors|eigenvalues]] of &lt;math&gt;\mathbf{K}&lt;/math&gt;; &lt;math&gt;\mathbf{v_1}&lt;/math&gt;, &lt;math&gt;\mathbf{v_2}&lt;/math&gt;, ... and &lt;math&gt;\mathbf{v_n}&lt;/math&gt; are the respective [[Eigenvalues and eigenvectors|eigenvectors]] of &lt;math&gt;\mathbf{K}&lt;/math&gt;; and &lt;math&gt;c_1&lt;/math&gt;, &lt;math&gt;c_2&lt;/math&gt;, .... and &lt;math&gt;c_n&lt;/math&gt; are constants.

However it can be shown that given the above requirement to ensure the 'contents' of a closed system are constant, then for every pair of [[Eigenvalues and eigenvectors|eigenvalue]] and [[Eigenvalues and eigenvectors|eigenvector]] then either &lt;math&gt;\lambda=0&lt;/math&gt; or &lt;math&gt;
\begin{bmatrix}
1 &amp; 1 &amp;\cdots &amp; 1\\
\end{bmatrix}\mathbf{v}=0&lt;/math&gt; and also that one [[Eigenvalues and eigenvectors|eigenvalue]] is 0, say &lt;math&gt;\lambda_1&lt;/math&gt;

So
: &lt;math&gt;\mathbf{q} = c_1  \mathbf{v_1} + c_2 e^{\lambda_2 t} \mathbf{v_2} + \cdots + c_n e^{\lambda_n t} \mathbf{v_n}&lt;/math&gt;

Where
: &lt;math&gt;
\begin{bmatrix}
1 &amp; 1 &amp;\cdots &amp; 1\\
\end{bmatrix}\mathbf{v_i}=0&lt;/math&gt; for &lt;math&gt;\mathbf{i}=2, 3, \dots n&lt;/math&gt;

This solution can be rearranged:

: &lt;math&gt;
\mathbf{q} = 
\Bigg[ \mathbf{v_1}\begin{bmatrix}
 c_1 &amp; 0 &amp; \cdots &amp; 0 \\
 \end{bmatrix}
+ \mathbf{v_2}\begin{bmatrix}
 0 &amp; c_2 &amp; \cdots &amp; 0 \\
 \end{bmatrix}
+ \dots + \mathbf{v_n}\begin{bmatrix}
 0 &amp; 0 &amp; \cdots &amp; c_n \\
 \end{bmatrix} \Bigg]
\begin{bmatrix}
1 \\
e^{\lambda_2t} \\
 \vdots \\
e^{\lambda_nt} \\
\end{bmatrix}
&lt;/math&gt;

This somewhat inelegant equation demonstrates that all solutions of an ''n-cell'' multi-compartment model with constant or no inputs are of the form:

: &lt;math&gt; \mathbf{q} = \mathbf{A}
\begin{bmatrix}
1 \\
e^{\lambda_2t} \\
 \vdots \\
e^{\lambda_nt} \\
\end{bmatrix}
&lt;/math&gt;

Where &lt;math&gt;\mathbf{A}&lt;/math&gt; is a ''nxn'' matrix and &lt;math&gt;\lambda_2&lt;/math&gt;, &lt;math&gt;\lambda_3&lt;/math&gt;, ... and &lt;math&gt;\lambda_n&lt;/math&gt; are constants.
Where &lt;math&gt;\begin{bmatrix}
1 &amp; 1 &amp;\cdots &amp; 1\\
\end{bmatrix}\mathbf{A}=\begin{bmatrix}
 a &amp; 0 &amp; \cdots &amp; 0 \\
 \end{bmatrix}&lt;/math&gt;

==Model topologies==
Generally speaking, as the number of compartments increase, it is challenging both to find the algebraic and numerical solutions of the model. However, there are special cases of models, which rarely exist in nature, when the topologies exhibit certain regularities that the solutions become easier to find. The model can be classified according to the interconnection of cells and input/output characteristics:

#'''Closed model''': No sinks or source, lit. all ''k''&lt;sub&gt;oi&lt;/sub&gt; = 0 and ''u''&lt;sub&gt;''i''&lt;/sub&gt; = 0;
#'''Open model''': There are sinks or/and sources among cells.
#'''Catenary model''': All compartments are arranged in a chain, with each pool connecting only to its neighbors. This model has two or more cells.
#'''Cyclic model''': It's a special case of the catenary model, with three or more cells, in which the first and last cell are connected, i.e. ''k''&lt;sub&gt;1''n''&lt;/sub&gt; &amp;ne; 0 or/and ''k''&lt;sub&gt;''n''1&lt;/sub&gt; &amp;ne; 0.
#'''Mammillary model''': Consists of a central compartment with peripheral compartments connecting to it. There are no interconnections among other compartments. 
#'''Reducible model''': It's a set of unconnected models. It bears great resemblance to the computer concept of '''forest''' as against '''trees'''.

== See also ==
* [[Mathematical model]] 
* [[Biomedical engineering]]
* [[Biological neuron models#Compartmental models|Biological neuron models]]
* [[Compartmental models in epidemiology]]
* [[Physiologically-based pharmacokinetic modelling]]

==References==
*Godfrey, K., ''Compartmental Models and Their Application'', Academic Press, 1983 ({{ISBN|0-12-286970-2}}).
*Anderson, D. H., ''Compartmental Modeling and Tracer Kinetics'', Springer-Verlag Lecture Notes in Biomathematics #50, 1983 ({{ISBN|0-387-12303-2}}).
*Jacquez, J. A, ''Compartmental Analysis in Biology and Medicine'', 2nd ed., The University of Michigan Press, 1985.
*Evans, W. C., Linear Systems, Compartmental Modeling, and Estimability Issues in IAQ Studies, in Tichenor, B., ''Characterizing Sources of Indoor Air Pollution and Related Sink Effects'', ASTM STP 1287, pp.&amp;nbsp;239–262, 1996 ({{ISBN|0-8031-2030-3}}).

[[Category:Mathematical modeling]]
[[Category:Systems theory]]</text>
      <sha1>227fjr4dqmbmncb3k4xf2581umbwmh3</sha1>
    </revision>
  </page>
  <page>
    <title>Multivector</title>
    <ns>0</ns>
    <id>2727288</id>
    <revision>
      <id>860533840</id>
      <parentid>860531381</parentid>
      <timestamp>2018-09-21T09:29:07Z</timestamp>
      <contributor>
        <username>AnomieBOT</username>
        <id>7611264</id>
      </contributor>
      <comment>Rescuing orphaned refs ("Flanders" from rev 847946531)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27943">{{Redirect|p-vector||K-vector (disambiguation)}}
In [[multilinear algebra]], a '''multivector''', sometimes called '''Clifford number''',&lt;ref&gt;John Snygg (2012), ''A New Approach to Differential Geometry Using Clifford’s Geometric Algebra'', Birkhäuser, p.5 §2.12&lt;/ref&gt; is an element of the [[exterior algebra]] {{math|Λ(''V'')}} of a [[vector space]] {{mvar|V}}. This algebra is [[graded algebra|graded]], [[associative algebra|associative]] and [[alternating algebra|alternating]], and consists of [[linear combination]]s of '''simple''' {{math|''k''}}-vectors (also known as '''decomposable''' {{math|''k''}}-vectors or [[Blade (geometry)|{{math|''k''}}-blades]]) of the form
:&lt;math&gt; v_1\wedge\cdots\wedge v_k,&lt;/math&gt;
where &lt;math&gt;v_1, \ldots, v_k&lt;/math&gt; are in {{mvar|V}}.

"Multivector" may mean either ''homogeneous'' elements (all terms of the linear combination have the same grade or degree {{math|''k''}}, that is are the product of the same number {{math|''k''}} of vectors), which are referred to as '''{{math|''k''}}-vectors''' or '''{{math|''p''}}-vectors''',&lt;ref&gt;Élie Cartan, ''The theory of spinors'', [https://books.google.com/books?id=AEZ1h7Cg3cwC&amp;pg=PA16&amp;dq=p-vector+multivectors p. 16], considers only homogeneous vectors, particularly simple ones, referring to them as "multivectors" (collectively) or ''p''-vectors (specifically).&lt;/ref&gt; or may allow sums of terms in different degrees.

In [[differential geometry]], a '''{{math|''p''}}-vector''' is the antisymmetric [[tensor]] obtained by taking [[linear combination]]s of the [[wedge product]] of {{math|''p''}} [[tangent vector]]s, for some integer {{math|''p'' ≥ 0}}. It is the [[Dual space|dual]] concept to a [[p-form|{{math|''p''}}-form]].

For {{math|1=''p'' = 0, 1, 2}} and {{math|3}}, these are often called respectively ''[[Scalar (mathematics)|scalar]]s'', ''vectors'', ''[[bivector]]s'' and ''trivectors''; they are respectively dual to [[0-form]]s, [[1-form]]s, [[2-form]]s and 3-forms.&lt;ref name="Ławrynowicz"&gt;

{{cite book |title=Deformations of mathematical structures II  |url=https://books.google.com/books?id=KfNgBHNUW_cC&amp;pg=PA131 |page=131 ''ff'' |isbn=0-7923-2576-1 |author=William M Pezzaglia Jr.|editor=Julian Ławrynowicz |year=1992 |publisher =Springer |chapter=Clifford algebra derivation of the characteristic hypersurfaces of Maxwell's equations |quote=Hence in 3D we associate the alternate terms of ''pseudovector'' for [[bivector]], and ''pseudoscalar'' for the [[p-vector|trivector]]}}
&lt;/ref&gt;&lt;ref name=Baylis&gt;
{{cite book |author=Baylis |title=Theoretical methods in the physical sciences: an introduction to problem solving using Maple V |url=https://books.google.com/books?id=pEfMq1sxWVEC&amp;pg=PA234 |page=234, see footnote |isbn=0-8176-3715-X |year=1994 |publisher=Birkhäuser}}
&lt;/ref&gt;

==Wedge product==
{{Main|Exterior algebra}}

The wedge product operation used to construct multivectors is linear, associative and alternating, which reflect the properties of the determinant. This means for vectors '''u''', '''v''' and '''w''' in a vector space ''V'' and for scalars ''α'', ''β'', the wedge product has the properties,

* Linear:  &lt;math&gt; \mathbf{u}\wedge(\alpha\mathbf{v}+\beta\mathbf{w})=\alpha\mathbf{u}\wedge\mathbf{v}+\beta\mathbf{u}\wedge\mathbf{w};&lt;/math&gt;
* Associative:  &lt;math&gt; (\mathbf{u}\wedge\mathbf{v})\wedge\mathbf{w}=\mathbf{u}\wedge(\mathbf{v}\wedge\mathbf{w})=\mathbf{u}\wedge\mathbf{v}\wedge\mathbf{w};&lt;/math&gt;
* Alternating:  &lt;math&gt; \mathbf{u}\wedge\mathbf{v}=-\mathbf{v}\wedge\mathbf{u}, \quad\mathbf{u}\wedge\mathbf{u}=0.&lt;/math&gt;

The product of ''p'' vectors is called a grade ''p'' multivector, or a ''p''-vector.  The maximum grade of a multivector is the dimension of the vector space ''V''.

The linearity of the wedge product allows a multivector to be defined as the linear combination of basis multivectors.  There are &lt;big&gt;(&lt;/big&gt;{{su|p=''n''|b=''p''}}&lt;big&gt;)&lt;/big&gt; basis ''p''-vectors in an ''n''-dimensional vector space.&lt;ref name="Flanders"&gt;H. Flanders, ''Differential Forms with Applications to the Physical Sciences, Academic Press, New York, NY, 1963&lt;/ref&gt;

==Area and volume==
The ''p''-vector obtained from the wedge product of ''p'' separate vectors in an ''n''-dimensional space has components that define the projected {{nowrap|(''p'' − 1)}}-volumes of the ''p''-[[Parallelepiped#Parallelotope|parallelotope]] spanned by the vectors.  The square root of the sum of the squares of these components defines the volume of the ''p''-parallelotope.&lt;ref name="Flanders"/&gt;&lt;ref&gt;G. E. Shilov, ''Linear Algebra'', (trans. R. A. Silverman), Dover Publications, 1977.&lt;/ref&gt;

The following examples show that a bivector in two dimensions measures the area of a parallelogram, and the magnitude of a bivector in three dimensions also measures the area of a parallelogram.  Similarly, a three-vector in three dimensions measures the volume of a parallelepiped.

It is easy to check that the magnitude of a three-vector in four dimensions measures the volume of the parallelepiped spanned by these vectors.

===Multivectors in R&lt;sup&gt;2&lt;/sup&gt;===
Properties of multivectors can be seen by considering the two dimensional vector space {{nowrap|1=''V'' = '''R'''&lt;sup&gt;2&lt;/sup&gt;}}.  Let the basis vectors be '''e'''&lt;sub&gt;1&lt;/sub&gt; and '''e'''&lt;sub&gt;2&lt;/sub&gt;, so '''u''' and '''v''' are given by

:&lt;math&gt; \mathbf{u}=u_1\mathbf{e}_1+u_2\mathbf{e}_2,\quad \mathbf{v}=v_1\mathbf{e}_1+v_2\mathbf{e}_2,&lt;/math&gt;

and the multivector {{nowrap|'''u''' ∧ '''v'''}}, also called a bivector, is computed to be

:&lt;math&gt; \mathbf{u} \wedge \mathbf{v} =\begin{vmatrix} u_1 &amp; v_1 \\ u_2 &amp; v_2\end{vmatrix} \mathbf{e}_1\wedge\mathbf{e}_2.&lt;/math&gt;

The vertical bars denote the determinant of the matrix, which is the area of the parallelogram spanned by the vectors '''u''' and '''v'''.  The magnitude of {{nowrap|'''u''' ∧ '''v'''}} is the area of this parallelogram.  Notice that because ''V'' has dimension two the basis bivector {{nowrap|'''e'''&lt;sub&gt;1&lt;/sub&gt; ∧ '''e'''&lt;sub&gt;2&lt;/sub&gt;}} is the only multivector in Λ''V''.

The relationship between the magnitude of a multivector and the area or volume spanned by the vectors is an important feature in all dimensions.  Furthermore, the linear functional version of a multivector that computes this volume is known as a differential form.

===Multivectors in R&lt;sup&gt;3&lt;/sup&gt;===
More features of multivectors can be seen by considering the three dimensional vector space {{nowrap|1=''V'' = '''R'''&lt;sup&gt;3&lt;/sup&gt;}}.  In this case, let the basis vectors be '''e'''&lt;sub&gt;1&lt;/sub&gt;, '''e'''&lt;sub&gt;2&lt;/sub&gt;, and '''e'''&lt;sub&gt;3&lt;/sub&gt;, so '''u''', '''v''' and '''w''' are given by

:&lt;math&gt; \mathbf{u}=u_1\mathbf{e}_1+u_2\mathbf{e}_2 +u_3\mathbf{e}_3 ,\quad \mathbf{v}=v_1\mathbf{e}_1+v_2\mathbf{e}_2+v_3\mathbf{e}_3, \quad \mathbf{w}=w_1\mathbf{e}_1+w_2\mathbf{e}_2+w_3\mathbf{e}_3,&lt;/math&gt;

and the bivector {{nowrap|'''u''' ∧ '''v'''}} is computed to be

:&lt;math&gt; \mathbf{u} \wedge \mathbf{v} =\begin{vmatrix} u_2 &amp; v_2 \\ u_3 &amp; v_3\end{vmatrix} \mathbf{e}_2\wedge\mathbf{e}_3 + \begin{vmatrix} u_1 &amp; v_1 \\ u_3 &amp; v_3\end{vmatrix} \mathbf{e}_1\wedge\mathbf{e}_3 +\begin{vmatrix} u_1 &amp; v_1 \\ u_2 &amp; v_2\end{vmatrix} \mathbf{e}_1\wedge\mathbf{e}_2.&lt;/math&gt;

The components of this bivector are the same as the components of the cross product.  The magnitude of this bivector is the square root of the sum of the squares of its components.

This shows that the magnitude of the bivector {{nowrap|'''u''' ∧ '''v'''}} is the area of the parallelogram spanned by the vectors '''u''' and '''v''' as it lies in the three-dimensional space ''V''.  The components of the bivector are the projected areas of the parallelogram on each of the three coordinate planes.

Notice that because ''V'' has dimension three, there is one basis three-vector in Λ''V''.  Compute the three-vector
:&lt;math&gt;\mathbf{u}\wedge\mathbf{v}\wedge\mathbf{w}=\begin{vmatrix} u_1 &amp; v_1 &amp;w_1\\ u_2 &amp; v_2&amp; w_2\\u_3&amp;v_3&amp;w_3\end{vmatrix} \mathbf{e}_1\wedge\mathbf{e}_2\wedge\mathbf{e}_3. &lt;/math&gt;
This shows that the magnitude of the three-vector {{nowrap|'''u''' ∧ '''v''' ∧ '''w'''}} is the volume of the parallelepiped spanned by the three vectors '''u''', '''v''' and '''w'''.

In higher-dimensional spaces, the component three-vectors are projections of the volume of a parallelepiped onto the coordinate three-spaces, and the magnitude of the three-vector is the volume of the parallelepiped as it sits in the higher-dimensional space.

==Grassmann coordinates==
In this section, we consider multivectors on a [[projective space]] ''P''&lt;sup&gt;''n''&lt;/sup&gt;, which provide a convenient set of coordinates for lines, planes and hyperplanes that have properties similar to the homogeneous coordinates of points, called [[Grassmann coordinates]].&lt;ref&gt;W. V. D. Hodge and D. Pedoe, Methods of Algebraic Geometry, Vol. 1, Cambridge Univ. Press, 1947&lt;/ref&gt;

Points in a real projective space ''P''&lt;sup&gt;''n''&lt;/sup&gt; are defined to be lines through the origin of the vector space '''R'''&lt;sup&gt;''n''+1&lt;/sup&gt;.  For example, the projective plane ''P''&lt;sup&gt;2&lt;/sup&gt; is the set of lines through the origin of '''R'''&lt;sup&gt;3&lt;/sup&gt;.  Thus, multivectors defined on '''R'''&lt;sup&gt;''n''+1&lt;/sup&gt; can be viewed as multivectors on ''P''&lt;sup&gt;''n''&lt;/sup&gt;.

A convenient way to view a multivector on ''P''&lt;sup&gt;''n''&lt;/sup&gt; is to examine it in an [[affine space|affine component]] of ''P''&lt;sup&gt;''n''&lt;/sup&gt;, which is the intersection of the lines through the origin of '''R'''&lt;sup&gt;''n''+1&lt;/sup&gt; with a selected hyperplane, such as {{nowrap|1=H: ''x''&lt;sub&gt;''n''+1&lt;/sub&gt; = 1}}.  Lines through the origin of '''R'''&lt;sup&gt;3&lt;/sup&gt; intersect the plane {{nowrap|1=E: ''z'' = 1}} to define an affine version of the projective plane that only lacks the points {{nowrap|1=''z'' = 0}}, called the points at infinity.

===Multivectors on ''P''&lt;sup&gt;2&lt;/sup&gt;===
Points in the affine component {{nowrap|1=E: ''z'' = 1}} of the projective plane have coordinates {{nowrap|1='''x''' = (''x'', ''y'', 1)}}.  A linear combination of two points {{nowrap|1='''p''' = (''p''&lt;sub&gt;1&lt;/sub&gt;, ''p''&lt;sub&gt;2&lt;/sub&gt;, 1)}} and {{nowrap|1='''q''' = (''q''&lt;sub&gt;1&lt;/sub&gt;, ''q''&lt;sub&gt;2&lt;/sub&gt;, 1)}} defines a plane in '''R'''&lt;sup&gt;3&lt;/sup&gt; that intersects E in the line joining '''p''' and '''q'''.  The multivector {{nowrap|'''p''' ∧ '''q'''}} defines a parallelogram in '''R'''&lt;sup&gt;3&lt;/sup&gt; given by
:&lt;math&gt; \mathbf{p} \wedge \mathbf{q} =(p_2 - q_2)\mathbf{e}_2\wedge\mathbf{e}_3 + (p_1- q_1) \mathbf{e}_1\wedge\mathbf{e}_3 +(p_1 q_2-  q_1 p_2)\mathbf{e}_1\wedge\mathbf{e}_2.&lt;/math&gt;
Notice that substitution of {{nowrap|''α'''''p''' + ''β'''''q'''}} for '''p''' multiplies this multivector by a constant.  Therefore, the components of {{nowrap|'''p''' ∧ '''q'''}} are homogeneous coordinates for the plane through the origin of '''R'''&lt;sup&gt;3&lt;/sup&gt;.

The set of points {{nowrap|1='''x''' = (''x'', ''y'', 1)}} on the line through '''p''' and '''q''' is the intersection of the plane defined by {{nowrap|'''p''' ∧ '''q'''}}  with the plane {{nowrap|1=E: ''z'' = 1}}.  These points satisfy {{nowrap|1='''x''' ∧ '''p''' ∧ '''q''' = 0}}, that is,

:&lt;math&gt; \mathbf{x}\wedge\mathbf{p} \wedge \mathbf{q} = (x\mathbf{e}_1+y\mathbf{e}_2+\mathbf{e}_3)\wedge \big( (p_2 - q_2)\mathbf{e}_2\wedge\mathbf{e}_3 + (p_1- q_1) \mathbf{e}_1\wedge\mathbf{e}_3 +(p_1 q_2-  q_1 p_2)\mathbf{e}_1\wedge\mathbf{e}_2\big)=0,&lt;/math&gt;

which simplifies to the equation of a line

:&lt;math&gt;  \lambda:  x(p_2 - q_2) + y(p_1- q_1)+ (p_1 q_2- q_1 p_2)=0.&lt;/math&gt;

This equation is satisfied by points {{nowrap|1='''x''' = ''α'''''p''' + ''β'''''q'''}} for real values of α and β.

The three components of {{nowrap|'''p''' ∧ '''q'''}} that define the line ''λ'' are called the [[Grassmann coordinates]] of the line.  Because three homogeneous coordinates define both a point and a line, the geometry of points is said to be dual to the geometry of lines in the projective plane.  This is called the [[duality (projective geometry)|principle of duality]].

===Multivectors on ''P''&lt;sup&gt;3&lt;/sup&gt;===
Three dimensional projective space, ''P''&lt;sup&gt;3&lt;/sup&gt; consists of all lines through the origin of '''R'''&lt;sup&gt;4&lt;/sup&gt;.  Let the three dimensional hyperplane, {{nowrap|1=H: ''w'' = 1}}, be the affine component of projective space defined by the points {{nowrap|1='''x''' = (''x'', ''y'', ''z'', 1)}}.  The multivector {{nowrap|'''p''' ∧ '''q''' ∧ '''r'''}} defines a parallelepiped in '''R'''&lt;sup&gt;4&lt;/sup&gt; given by

:&lt;math&gt;\mathbf{p}\wedge\mathbf{q}\wedge\mathbf{r}=\begin{vmatrix} p_2 &amp; q_2 &amp;r_2\\ p_3 &amp; q_3&amp; r_3\\1&amp;1&amp;1\end{vmatrix}\mathbf{e}_2\wedge\mathbf{e}_3\wedge\mathbf{e}_4 + \begin{vmatrix} p_1 &amp; q_1 &amp;r_1\\ p_3 &amp; q_3&amp; r_3\\1&amp;1&amp;1\end{vmatrix}\mathbf{e}_1\wedge\mathbf{e}_3\wedge\mathbf{e}_4 + \begin{vmatrix} p_1 &amp; q_1 &amp;r_1\\ p_2 &amp; q_2&amp; r_2\\1&amp;1&amp;1\end{vmatrix}\mathbf{e}_1\wedge\mathbf{e}_2\wedge\mathbf{e}_4 + \begin{vmatrix} p_1 &amp; q_1 &amp;r_1\\ p_2 &amp; q_2&amp; r_2\\ p_3 &amp; q_3&amp; r_3\end{vmatrix} \mathbf{e}_1\wedge\mathbf{e}_2\wedge\mathbf{e}_3. &lt;/math&gt;

Notice that substitution of {{nowrap|α'''p''' + β'''q''' + γ'''r'''}} for '''p''' multiplies this multivector by a constant.  Therefore, the components of {{nowrap|'''p''' ∧ '''q''' ∧ '''r'''}}  are homogeneous coordinates for the 3-space through the origin of '''R'''&lt;sup&gt;4&lt;/sup&gt;.

A plane in the affine component {{nowrap|1=H: ''w'' = 1}} is the set of points {{nowrap|1='''x''' = (''x'', ''y'', ''z'', 1)}} in the intersection of H with the 3-space defined by {{nowrap|'''p''' ∧ '''q''' ∧ '''r'''}}.  These points satisfy {{nowrap|1='''x''' ∧ '''p''' ∧ '''q''' ∧ '''r''' = 0}}, that is,

:&lt;math&gt; \mathbf{x}\wedge\mathbf{p} \wedge \mathbf{q}\wedge\mathbf{r} = (x\mathbf{e}_1+y\mathbf{e}_2+z\mathbf{e}_3 +\mathbf{e}_4)\wedge \mathbf{p}\wedge\mathbf{q}\wedge\mathbf{r} = 0 ,&lt;/math&gt;

which simplifies to the equation of a plane

:&lt;math&gt;  \lambda:  x\begin{vmatrix} p_2 &amp; q_2 &amp;r_2\\ p_3 &amp; q_3&amp; r_3\\1&amp;1&amp;1\end{vmatrix} + y \begin{vmatrix} p_1 &amp; q_1 &amp;r_1\\ p_3 &amp; q_3&amp; r_3\\1&amp;1&amp;1\end{vmatrix}+ z\begin{vmatrix} p_1 &amp; q_1 &amp;r_1\\ p_2 &amp; q_2&amp; r_2\\1&amp;1&amp;1\end{vmatrix}+  \begin{vmatrix} p_1 &amp; q_1 &amp;r_1\\ p_2 &amp; q_2&amp; r_2\\ p_3 &amp; q_3&amp; r_3\end{vmatrix} =0.&lt;/math&gt;

This equation is satisfied by points {{nowrap|1='''x''' = ''α'''''p''' + ''β'''''q''' + ''γ'''''r'''}} for real values of ''α'', ''β'' and ''γ''.

The four components of {{nowrap|'''p''' ∧ '''q''' ∧ '''r'''}} that define the plane ''λ'' are called the [[Grassmann coordinates]] of the plane.  Because four homogeneous coordinates define both a point and a plane in projective space, the geometry of points is dual to the geometry of planes.

'''A line as the join of two points:''' In projective space the line ''λ'' through two points '''p''' and '''q''' can be viewed as the intersection of the affine space {{nowrap|1=H: ''w'' = 1}} with the plane {{nowrap|1='''x''' = ''α'''''p''' + ''β'''''q'''}}  in '''R'''&lt;sup&gt;4&lt;/sup&gt;.  The multivector {{nowrap|'''p''' ∧ '''q'''}} provides homogeneous coordinates for the line

:&lt;math&gt; \lambda:  \mathbf{p} \wedge \mathbf{q} = (p_1\mathbf{e}_1+p_2\mathbf{e}_2+p_3\mathbf{e}_3 +\mathbf{e}_4)\wedge  (q_1\mathbf{e}_1+q_2\mathbf{e}_2+q_3\mathbf{e}_3 +\mathbf{e}_4),&lt;/math&gt;
:&lt;math&gt;\qquad =\begin{vmatrix} p_1 &amp; q_1\\ 1 &amp; 1 \end{vmatrix}\mathbf{e}_1\wedge\mathbf{e}_4 + \begin{vmatrix} p_2 &amp; q_2\\ 1 &amp; 1 \end{vmatrix}\mathbf{e}_2\wedge\mathbf{e}_4 + \begin{vmatrix} p_3 &amp; q_3\\ 1 &amp; 1 \end{vmatrix}\mathbf{e}_3\wedge\mathbf{e}_4+ \begin{vmatrix} p_2 &amp; q_2\\ p_3 &amp; q_3 \end{vmatrix}\mathbf{e}_2\wedge\mathbf{e}_3+\begin{vmatrix} p_3 &amp; q_3\\ p_1 &amp; q_1 \end{vmatrix}\mathbf{e}_3\wedge\mathbf{e}_1+\begin{vmatrix} p_1 &amp; q_1\\ p_2 &amp; q_2\end{vmatrix}\mathbf{e}_1\wedge\mathbf{e}_2.&lt;/math&gt;
These are known as the [[Plücker coordinates]] of the line, though they are also an example of Grassmann coordinates.

'''A line as the intersection of two planes:'''  A line ''μ'' in projective space can also be defined as the set of points '''x''' that form the intersection of two planes ''π'' and ''ρ'' defined by grade three multivectors, so the points '''x''' are the solutions to the linear equations

:&lt;math&gt;  \mu: \mathbf{x}\wedge \pi = 0, \mathbf{x}\wedge \rho = 0.&lt;/math&gt;

In order to obtain the Plucker coordinates of the line ''μ'', map the multivectors ''π'' and ''ρ'' to their dual point coordinates using the [[Hodge star operator]],&lt;ref name="Flanders"/&gt;

:&lt;math&gt; \mathbf{e}_1 = {\star}(\mathbf{e}_2\wedge\mathbf{e}_3 \wedge\mathbf{e}_4), -\mathbf{e}_2 = {\star}(\mathbf{e}_1\wedge\mathbf{e}_3 \wedge\mathbf{e}_4), \mathbf{e}_3 = {\star}(\mathbf{e}_1\wedge\mathbf{e}_2 \wedge\mathbf{e}_4), -\mathbf{e}_4 = {\star}(\mathbf{e}_1\wedge\mathbf{e}_2 \wedge\mathbf{e}_3),&lt;/math&gt;

then

:&lt;math&gt; {\star}\pi = \pi_1\mathbf{e}_1 + \pi_2\mathbf{e}_2 + \pi_3\mathbf{e}_3 + \pi_4\mathbf{e}_4, \quad {\star}\rho = \rho_1\mathbf{e}_1 + \rho_2\mathbf{e}_2 + \rho_3\mathbf{e}_3 + \rho_4\mathbf{e}_4 .&lt;/math&gt;

So, the Plücker coordinates of the line ''μ'' are given by

:&lt;math&gt; \mu: ({\star}\pi)\wedge({\star}\rho) =\begin{vmatrix} \pi_1 &amp; \rho_1\\ \pi_4 &amp; \rho_4 \end{vmatrix}\mathbf{e}_1\wedge\mathbf{e}_4 + \begin{vmatrix} \pi_2 &amp; \rho_2\\ \pi_4 &amp; \rho_4 \end{vmatrix}\mathbf{e}_2\wedge\mathbf{e}_4 + \begin{vmatrix} \pi_3 &amp; \rho_3\\ \pi_4 &amp; \rho_4\end{vmatrix}\mathbf{e}_3\wedge\mathbf{e}_4+ \begin{vmatrix}  \pi_2 &amp; \rho_2\\ \pi_3 &amp; \rho_3\end{vmatrix}\mathbf{e}_2\wedge\mathbf{e}_3+\begin{vmatrix}  \pi_3 &amp; \rho_3\\ \pi_1 &amp; \rho_1\end{vmatrix}\mathbf{e}_3\wedge\mathbf{e}_1+\begin{vmatrix}  \pi_1 &amp; \rho_1\\ \pi_2 &amp; \rho_2\end{vmatrix}\mathbf{e}_1\wedge\mathbf{e}_2.&lt;/math&gt;

Because the six homogeneous coordinates of a line can be obtained from the join of two points or the intersection of two planes, the line is said to be self dual in projective space.

==Clifford product==
[[William Kingdon Clifford|W. K. Clifford]] combined multivectors with the [[inner product]] defined on the vector space, in order to obtain a general construction for hypercomplex numbers that includes the usual complex numbers and Hamilton's [[quaternion]]s.&lt;ref&gt;W. K. Clifford, "Preliminary sketch of bi-quaternions," Proc. London Math. Soc. Vol. 4 (1873) pp. 381-395&lt;/ref&gt;&lt;ref&gt;W. K. Clifford, ''Mathematical Papers'', (ed. R. Tucker), London: Macmillan, 1882.&lt;/ref&gt;

The Clifford product between two vectors '''u''' and '''v''' is linear and associative like the wedge product, and has the additional property that the multivector '''uv''' is coupled to the inner product {{nowrap|'''u''' · '''v'''}} by Clifford's relation,
:&lt;math&gt; \mathbf{u}\mathbf{v} + \mathbf{v}\mathbf{u} = 2\mathbf{u}\cdot\mathbf{v}.&lt;/math&gt;

Clifford's relation preserves the alternating property for the product of vectors that are perpendicular.  This can be seen for the orthogonal unit vectors {{nowrap|1='''e'''&lt;sub&gt;''i''&lt;/sub&gt;, ''i'' = 1, ..., ''n''}} in '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.  Clifford's relation yields

:&lt;math&gt; \mathbf{e}_i\mathbf{e}_j + \mathbf{e}_j\mathbf{e}_i = 2\mathbf{e}_i\cdot\mathbf{e}_j = 0, &lt;/math&gt;

therefore the basis vectors are alternating,

:&lt;math&gt; \mathbf{e}_i\mathbf{e}_j = -  \mathbf{e}_j\mathbf{e}_i, \quad i\neq j = 1, \ldots, n.&lt;/math&gt;

In contrast to the wedge product, the Clifford product of a vector with itself is no longer zero.  To see this compute the product,

:&lt;math&gt; \mathbf{e}_i\mathbf{e}_i +  \mathbf{e}_i\mathbf{e}_i = 2 \mathbf{e}_i\cdot\mathbf{e}_i = 2,&lt;/math&gt;

which yields

:&lt;math&gt; \mathbf{e}_i\mathbf{e}_i = 1,\quad i=1,\ldots, n.&lt;/math&gt;

The set of multivectors constructed using Clifford's product yields an associative algebra known as a [[Clifford algebra]].  Inner products with different properties can be used to construct different Clifford algebras.&lt;ref&gt;[https://books.google.com/books?id=glOqQgAACAAJ&amp;dq=inauthor:%22J.+M.+McCarthy%22&amp;hl=en&amp;ei=_QoMToDvMcfd0QGFh-mvDg&amp;sa=X&amp;oi=book_result&amp;ct=book-thumbnail&amp;resnum=3&amp;ved=0CDsQ6wEwAg J. M. McCarthy, ''An Introduction to Theoretical Kinematics'', pp.&amp;nbsp;62–5, MIT Press 1990.]&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=f8I4yGVi9ocC&amp;printsec=frontcover&amp;source=gbs_ge_summary_r&amp;cad=0#v=onepage&amp;q&amp;f=false O. Bottema and B. Roth, ''Theoretical Kinematics'', North Holland Publ. Co., 1979]&lt;/ref&gt;

==Geometric algebra==
{{See also|Blade (geometry)}}

Multivectors play a central role in the mathematical formulation of physics known as geometric algebra.  The term ''geometric algebra'' was used by E. Artin for matrix methods in projective geometry.&lt;ref&gt;[https://www.amazon.com/dp/B009Z61B58/ref=rdr_ext_tmb  E. Artin, ''Geometric algebra, Interscience Publ., 1957]&lt;/ref&gt; It was D. Hestenes who used ''[[geometric algebra]]'' to describe the application of Clifford algebras to classical mechanics,&lt;ref&gt;D. Hestenes, New Foundations for Classical Mechanics, Kluwer Academic Publishers, 1986.&lt;/ref&gt;  This formulation was expanded to ''geometric calculus'' by D. Hestenes and G. Sobczyk,&lt;ref&gt;[https://www.amazon.com/Clifford-Algebra-Geometric-Calculus-Mathematics/dp/9027725616/ref=sr_1_10?s=books&amp;ie=UTF8&amp;qid=1396272483&amp;sr=1-10&amp;keywords=geometric+algebra D. Hestenes and G. Sobczyk, Clifford Algebra to Geometric Calculus: A Unified Language for Mathematics and Physics, Springer Verlag, 1987]&lt;/ref&gt; who provided new terminology for a variety of features in this application of Clifford algebra to physics. C. Doran and A. Lasenby show that Hestene's geometric algebra provides a convenient formulation for modern physics.&lt;ref&gt;[https://www.amazon.com/Geometric-Algebra-Physicists-Chris-Doran/dp/0521715954/ref=pd_bxgy_b_img_z C. Doran and A. Lasenby, Geometric Algebra for Physicists, Cambridge Univ. Press, 2007.]&lt;/ref&gt;

In [[geometric algebra]], a multivector is defined to be the sum of different-grade [[blade (geometry)|''k''-blades]], such as the summation of a [[scalar (mathematics)|scalar]], a [[Vector (geometric)|vector]], and a ''2''-vector.&lt;ref name= Rodrigues&gt;{{cite book |title=Invariants for pattern recognition and classification |author=Marcos A. Rodrigues |chapter=§1.2 Geometric algebra: an outline |url=https://books.google.com/books?id=QbFSt0SlDjIC&amp;pg=PA3 |page=3 ''ff'' |isbn=981-02-4278-6 |year=2000 |publisher=World Scientific}}
&lt;/ref&gt; A sum of only ''k''-grade components is called a ''k''-vector,&lt;ref name=Sommer&gt;{{cite book |title=Computer algebra and geometric algebra with applications |editor1=Hongbo Li |editor2=Peter J. Olver |editor2-link=Peter J. Olver |editor3=Gerald Sommer |url=https://books.google.com/books?id=uxofVAQE3LoC&amp;pg=PA330 |chapter=Applications of conformal geometric algebra in computer vision and graphics |page=330 |author=R Wareham, J Cameron &amp; J Lasenby |isbn=3-540-26296-2 |year=2005 |publisher=Springer}}
&lt;/ref&gt; or a ''homogeneous'' multivector.&lt;ref name=Sanfeliu&gt;{{cite book |title=Progress in pattern recognition, image analysis and applications |url=https://books.google.com/books?id=gsnXS1xdeekC&amp;pg=PA25 |page=25 |editor1=Alberto Sanfeliu |editor2=José Francisco Martínez Trinidad |editor3=Jesús Ariel Carrasco Ochoa |author=Eduardo Bayro-Corrochano |chapter = Clifford geometric algebra: A promising framework for computer vision, robotics and learning |isbn=3-540-23527-2 |publisher=Springer |year=2004}}
&lt;/ref&gt;

The highest grade element in a space is called a ''[[pseudoscalar]]''.

If a given element is homogeneous of a grade ''k'', then it is a ''k''-vector, but not necessarily a ''k''-blade.  Such an element is a ''k''-blade when it can be expressed as the wedge product of ''k'' vectors.  A geometric algebra generated by a 4-dimensional Euclidean vector space illustrates the point with an example: The sum of any two blades with one taken from the XY-plane and the other taken from the ZW-plane will form a 2-vector that is not a 2-blade.  In a geometric algebra generated by a Euclidean vector space of dimension 2 or 3, all sums of 2-blades may be written as a single 2-blade.

===Examples===
  {{multiple image
   | left
   | footer    = Geometric interpretation of grade ''n'' elements in a real exterior algebra for {{nowrap|1=''n'' = 0}} (signed point), 1 (directed line segment, or vector), 2 (oriented plane element), 3 (oriented volume). The exterior product of ''n'' vectors can be visualized as any ''n''-dimensional shape (e.g. ''n''-[[Parallelepiped#Parallelotope|parallelotope]], ''n''-[[ellipsoid]]); with magnitude ([[hypervolume]]), and [[Orientation (vector space)|orientation]] defined by that on its {{nowrap|(''n'' − 1)}}-dimensional boundary and on which side the interior is.&lt;ref&gt;{{cite book |author=R. Penrose| title=[[The Road to Reality]]| publisher= Vintage books| year=2007 | isbn=0-679-77631-1}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Gravitation|author1=J.A. Wheeler |author2=C. Misner |author3=K.S. Thorne |publisher=W.H. Freeman &amp; Co|year=1973|page=83|isbn=0-7167-0344-0}}&lt;/ref&gt;
   | width1    = 220
   | image1    = N vector positive.svg
   | caption1  = Orientation defined by an ordered set of vectors.
   | width2    = 220
   | image2    = N vector negative.svg
   | caption2  = Reversed orientation corresponds to negating the exterior product.
  }}

* 0-vectors are scalars;
* 1-vectors are vectors;
* 2-vectors are [[bivector]]s;
* (''n'' − 1)-vectors are [[pseudovector]]s;
* ''n''-vectors are [[pseudoscalar]]s.

In the presence of a [[volume form]] (such as given an [[inner product]] and an orientation), pseudovectors and pseudoscalars can be identified with vectors and scalars, which is routine in [[vector calculus]], but without a volume form this cannot be done without a choice.

In the [[algebra of physical space]] (the geometric algebra of Euclidean 3-space, used as a model of (3+1)-spacetime), a sum of a scalar and a vector is called a [[paravector]], and represents a point in spacetime (the vector the space, the scalar the time).

===Bivectors===
{{main|Bivector}}

A '''bivector''' is therefore an element of the [[antisymmetric tensor|antisymmetric]] [[tensor product]] of a [[tangent space]] with itself.

In [[geometric algebra]], also, a '''bivector''' is a grade 2 element (a 2-vector) resulting from the [[wedge product]] of two vectors, and so it is geometrically an ''oriented area'', in the same way a ''vector'' is an oriented line segment. If '''a''' and '''b''' are two vectors, the bivector {{nowrap|'''a''' ∧ '''b'''}} has

* a [[norm (mathematics)|norm]] which is its area, given by
*:&lt;math&gt;\left\| \mathbf a \wedge \mathbf b \right\| = \left\| \mathbf{a} \right\| \, \left\| \mathbf{b} \right\| \, \sin(\phi_{a,b})&lt;/math&gt;
* a direction: the plane where that area lies on, i.e., the plane determined by '''a''' and '''b''', as long as they are linearly independent;
* an orientation (out of two), determined by the order in which the originating vectors are multiplied. 
Bivectors are connected to [[pseudovector]]s, and are used to represent rotations in geometric algebra.

As bivectors are elements of a vector space Λ&lt;sup&gt;2&lt;/sup&gt;''V'' (where ''V'' is a finite-dimensional vector space with {{nowrap|1=dim ''V'' = ''n''}}), it makes sense to define an [[inner product]] on this vector space as follows. First, write any element {{nowrap|''F'' ∈ Λ&lt;sup&gt;2&lt;/sup&gt;''V''}} in terms of a basis {{nowrap|1=('''e'''&lt;sub&gt;''i''&lt;/sub&gt; ∧ '''e'''&lt;sub&gt;''j''&lt;/sub&gt;)&lt;sub&gt;1 ≤ ''i'' &lt; ''j'' ≤ ''n''&lt;/sub&gt; of Λ&lt;sup&gt;2&lt;/sup&gt;''V''}} as

: &lt;math&gt;F = F^{ab} \mathbf{e}_a \wedge \mathbf{e}_b \quad (1 \le a &lt; b  \le n) ,&lt;/math&gt;

where the [[Einstein summation convention]] is being used.

Now define a map {{nowrap|G : Λ&lt;sup&gt;2&lt;/sup&gt;''V'' × Λ&lt;sup&gt;2&lt;/sup&gt;''V'' → '''R'''}} by insisting that

: &lt;math&gt;G(F, H) := G_{abcd}F^{ab}H^{cd} ,&lt;/math&gt;

where &lt;math&gt;G_{abcd}&lt;/math&gt; are a set of numbers.

==Applications==
Bivectors play many important roles in physics, for example, in the [[classification of electromagnetic fields]].

==See also==
* [[Blade (geometry)]]
* [[Paravector]]

==References==
{{reflist}}

{{Linear algebra}}
{{tensors}}

[[Category:Multilinear algebra]]
[[Category:Tensors]]
[[Category:Differential geometry]]
[[Category:Geometric algebra]]</text>
      <sha1>6az8uiv9rfis37u2icgfcpevxxfix2o</sha1>
    </revision>
  </page>
  <page>
    <title>Octahedral cupola</title>
    <ns>0</ns>
    <id>40384850</id>
    <revision>
      <id>639806433</id>
      <parentid>622699792</parentid>
      <timestamp>2014-12-27T13:11:13Z</timestamp>
      <contributor>
        <username>Tomruen</username>
        <id>63601</id>
      </contributor>
      <comment>4-polytope</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2498">{| class="wikitable" align="right" style="margin-left:10px" width="280"
|-
!bgcolor=#e7dcc3 colspan=3|Octahedral cupola
|-
|align=center colspan=3|[[File:4D_octahedral_cupola-perspective-octahedron-first.png|280px]]&lt;BR&gt;[[Schlegel diagram]]
|-
|bgcolor=#e7dcc3|Type
|colspan=2|[[Polyhedral cupola]]
|-
|bgcolor=#e7dcc3|[[Schläfli symbol]]
|colspan=2|{3,4} v rr{3,4}
|-
|bgcolor=#e7dcc3|Cells
|28
|1 [[octahedron|{3,4}]] [[File:Uniform polyhedron-43-t2.png|30px]]&lt;BR&gt; 1 [[rhombicuboctahedron|rr{4,3}]] [[File:Uniform polyhedron-43-t02.png|30px]]&lt;BR&gt;8+12 [[triangular prism|{}×{3}]] [[File:triangular prism.png|30px]]&lt;BR&gt;6 [[square pyramid|{}v{4}]] [[File:square pyramid.png|30px]]
|-
|bgcolor=#e7dcc3|Faces
|82
|40 triangles&lt;BR&gt;42 squares
|-
|bgcolor=#e7dcc3|Edges
|colspan=2|84
|-
|bgcolor=#e7dcc3|Vertices
|colspan=2|30
|-
|bgcolor=#e7dcc3|Dual
|colspan=2|
|-
|bgcolor=#e7dcc3|[[Coxeter group|Symmetry group]]
|colspan=2|[4,3,1], order 48
|-
|bgcolor=#e7dcc3|Properties
|colspan=2|[[Convex polytope|convex]], regular-faced
|}
In 4-dimensional [[geometry]], the '''octahedral cupola''' is a [[4-polytope]] bounded by one [[octahedron]] and a parallel [[rhombicuboctahedron]], connected by 20 [[triangular prism]]s, and 6 [[square pyramid]]s.&lt;ref&gt;[http://www.bendwavy.org/klitzing/pdf/artConvSeg_8.pdf Convex Segmentochora] Dr. Richard Klitzing, Symmetry: Culture and Science, Vol. 11, Nos. 1-4, 139-181, 2000 (4.107 octahedron || rhombicuboctahedron)&lt;/ref&gt;

== Related polytopes==
The ''octahedral cupola'' can be sliced off from a [[runcinated 24-cell]], on a hyperplane parallel to an octahedral cell. The cupola can be seen in a B&lt;sub&gt;2&lt;/sub&gt; and B&lt;sub&gt;3&lt;/sub&gt; Coxeter plane orthogonal projection of the runcinated 24-cell:
{| class=wikitable
|- align=center
!Runcinated 24-cell
![[Octahedron]]&lt;BR&gt;(cupola top)
![[Rhombicuboctahedron]]&lt;BR&gt;(cupola base)
|-
!colspan=3|B&lt;sub&gt;3&lt;/sub&gt; Coxeter plane
|- align=center
|[[File:24-cell_t03_B3.svg|160px]]
|[[File:3-cube_t2.svg|60px]]
|[[File:3-cube t02.svg|120px]]
|-
!colspan=3|B&lt;sub&gt;2&lt;/sub&gt; Coxeter plane
|- align=center
|[[File:24-cell_t03_B2.svg|160px]]
|[[File:3-cube_t2 B2.svg|60px]]
|[[File:3-cube t02 B2.svg|120px]]
|}

== See also ==
* [[Octahedral pyramid]]
* [[Cubic cupola]]
* [[Runcinated 24-cell]]

== References==
{{reflist}}

==External links==
* [http://bendwavy.org/klitzing/explain/segmentochora.htm Segmentochora:] [http://bendwavy.org/klitzing/incmats/oct=sirco.htm oct || sirco, K-4.107] 

[[Category:Polychora]]

{{geometry-stub}}</text>
      <sha1>mdbqxp9f8jem47boeoemxw2xwlscax4</sha1>
    </revision>
  </page>
  <page>
    <title>Psychological statistics</title>
    <ns>0</ns>
    <id>23545</id>
    <revision>
      <id>869901202</id>
      <parentid>869901176</parentid>
      <timestamp>2018-11-21T03:16:11Z</timestamp>
      <contributor>
        <ip>206.123.177.161</ip>
      </contributor>
      <comment>/* References */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13747">{{Underlinked|date=December 2017}}
{{Psychology sidebar}}

'''Psychological statistics''' is application of formulas, theorems, numbers and laws to [[psychology]]. 
Statistical Methods for psychology include development and application statistical theory and methods for modeling psychological data. 
These methods include psychometrics, Factor analysis, Experimental Designs, Multivariate Behavioral Research. The article also discusses journals in the same field Wilcox, R. (2012).&lt;ref&gt;Wilcox, R. (2012). Modern Statistics for the Social and Behavioral Sciences: A Practical Introduction. FL: CRC Press. {{isbn|9781439834565}}&lt;/ref&gt;

==Psychometrics==
{{Main article|Psychometrics}}
Psychometrics deals with measurement of psychological attributes. It involved developing and applying statistical models for mental measurements (Lord and Novik, ; etc.) The measurement theories are divided into two major areas: (1) Classical test theory; (2) Item Response Theory  (Nunnally, J. &amp; Bernstein, I. (1994)&lt;ref name=":1"&gt;Nunnally, J. &amp; Bernstein, I. (1994). Psychometric Theory.  McGraw-Hill.&lt;/ref&gt;).

===Classical Test Theory===
{{Main article|Classical test theory}}
The classical test theory or true score theory or reliability theory in statistics is a set of statistical procedures useful for development of psychological tests and scales. It is based on fundamental equation 
X = T + E
where, X is total score, T is a true score and E is error of measurement. For each participant, it assumes that there exist a true score and it need to be obtained score (X) has to be as close to it as possible (Lord, F. M. , and Novick, M. R. ( 1 968),&lt;ref&gt;Lord, F. M. , and Novick, M. R. ( 1 968). Statistical theories of mental test scores. Reading, Mass. : Addison-Wesley, 1968.&lt;/ref&gt; Raykov, T.  &amp; Marcoulides, G.A. (2010) &lt;ref&gt;Raykov, T.  &amp; Marcoulides, G.A. (2010) Introduction to Psychometric Theory. New York: Routledge.&lt;/ref&gt; ). The closeness of X has with T is expressed in terms of ratability of the obtained score. The reliability in terms of classical test procedure is correlation between true score and obtained score. The typical test construction procedures has following steps:

(1)	Determine the construct 
(2)	Outline the behavioral domain of the construct
(3)	Write 3 to 5 times more items than desired test length
(4)	Get item content analyzed by experts and cull items
(5)	Obtain data on initial version of the test 
(6)	Item analysis (Statistical Procedure)
(7)	Factor analysis (Statistical Procedure)
(8)	After the second cull, make final version
(9)	Use it for research

====Reliability ====
{{Main article|Reliability (research methods)}}

The reliability is computed in specific ways.  
(A)	Inter-Rater reliability: Inter-Rater reliability is estimate of agreement between independent raters. This is most useful for subjective responses. Cohen’s Kappa, Krippendorff’s Alpha, Intra-Class correlation coefficients, Correlation coefficients, Kendal’s concordance coefficient, etc. are useful statistical tools. 
(B)	Test-Retest Reliability: Test-Retest Procedure is estimation of temporal consistency of the test. A test is administered twice to the same sample with a time interval. Correlation between two sets of scores is used as an estimate of reliability. Testing conditions are assumed to be identical. 
(C)	 Internal Consistency Reliability: Internal consistency reliability estimates consistency of items with each other. Split-half reliability (Spearman- Brown Prophecy) and Cronbach Alpha are popular estimates of this reliability . (Cronbach LJ (1951)&lt;ref&gt;Cronbach LJ (1951). Coefficient alpha and the internal structure of tests. Psychometrika 16, 297–334. doi:10.1007/bf02310555&lt;/ref&gt;). 
(D)	Parallel Form Reliability: It is an estimate of consistency between two different instruments of measurement. The inter-correlation between two parallel forms of a test or scale is used as an estimate of parallel form reliability.

====Validity====
{{Main article|Test validity}}

Validity of a scale or test is ability of the instrument to measure what it purports to measure (Nunnally, J. &amp; Bernstein, I. (1994)&lt;ref name=":1" /&gt;). Construct validity, Content Validity, Criterion Validity are types of validity. 
Construct validity is estimated by convergent and discriminant validity and factor analysis. Convergent and discriminant validity are ascertained by correlation between similar of different constructs. 
Content Validity: Subject matter experts evaluate content validity. 
Criterion Validity is correlation between the test and a criterion variable (or variables) of the construct. Regression analysis, Multiple regression analysis, Logistic regression is used as an estimate of criterion validity. 
Software applications: The R software has ‘psych’ package that is useful for classical test theory analysis.&lt;ref&gt;Kline, T. J. B. (2005)Psychological Testing: A Practical Approach to Design and Evaluation. Sage Publications: Thousand Oaks.&lt;/ref&gt;

===Modern test Theory ===
{{Main article|Item Response Theory}}

The modern test theory is based on latent trait model. Every item estimates the ability of the test taker. The ability parameter is called as theta (θ). The difficulty parameter is called b. the two important assumptions are local independence and unidimensionality.   
The Item Response Theory has three models. They are one parameter logistic model, two parameter logistic model and three parameter logistic model. In addition, Polychromous IRT Model are also useful (Hambleton &amp; Swaminathan, 1985).&lt;ref&gt;Hambleton, R. K., &amp; Swaminathan H. (1985). Item Response theory: Principles and Applications. Boston: Kluwer.&lt;/ref&gt;

The R Software has ‘ltm’, packages useful for IRT analysis.

==Factor Analysis ==
{{Main article|Factor Analysis}}

Factor analysis is at the core of psychological statistics. It has two schools: (1) Exploratory Factor analysis (2) Confirmatory Factor analysis

===Exploratory Factor Analysis (EFA)===
{{Main article|Exploratory Factor Analysis}}
The exploratory factor analysis begins without a theory or with a very tentative theory. It is a dimension reduction technique. It is useful in psychometrics, multivariate analysis of data and data analytics. 
Typically a k-dimensional correlation matrix or covariance matrix of variables is reduced to k X r factor pattern matrix where r &lt; k. Principal Component analysis and common factor analysis are two ways of extracting data. Principal axis factoring, ML factor analysis, alpha factor analysis and image factor analysis is most useful ways of EFA. 
It employees various factor rotation methods which can be classified into orthogonal (resulting in uncorrelated factors) and oblique (resulting correlated factors).

The ‘psych’ package in R is useful for EFA.

===Confirmatory Factor Analysis (CFA)===
{{Main article|Confirmatory Factor Analysis}}

Confirmatory Factor Analysis (CFA) is factor analytic technique that begins with theory and test the theory by carrying out factor analysis. 
The CFA is also called as latent structure analysis, which considers factor as latent variables causing actual observable variables. The basic equation of the CFA is

X = Λξ + δ

where, X is observed variables, Λ are structural coefficients, ξ are latent variables (factors) and δ are errors. 
The parameters are estimated using ML methods however; other methods of estimation are also available. The chi-square test is very sensitive and hence various fit measures are used (Bollen,1989,&lt;ref&gt;Bollen, KA. (1989). Structural Equations with Latent Variables. New York: John Wiley &amp; Sons.&lt;/ref&gt; Loehlin, 1992&lt;ref name=":2"&gt;Loehlin, J. E. (1992). Latent Variable Models: An Introduction to Factor, Path, and Structural Analysis (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.&lt;/ref&gt;).
R package ‘sem’, ‘lavaan’ are useful for the same.

==Experimental Design==
{{Main article|Experimental Psychology}}

Experimental Methods are very popular in psychology. It has more than 100 years tradition. Experimental psychology has a status of sub-discipline in psychology .
The statistical methods are applied for designing and analyzing experimental data. They involve, t-test, ANOVA, ANCOVA,  MANOVA, MANCOVA, binomial test, chi-square etc. are used for the analysis of the experimental data.

==Multivariate Behavioral Research==
Multivariate behavioral research is becoming very popular in psychology. These methods include Multiple Regression and Prediction; Moderated and Mediated Regression Analysis; Logistics Regression; Canonical Correlations; Cluster analysis; Multi-level modeling; Survival-Failure analysis; Structural Equations Modeling; hierarchical linear modelling etc. are very useful for psychological statistics (Hayes, 2013;&lt;ref&gt;Hayes, A. F. (2013). Introduction to mediation, moderation, and conditional process analysis. The Guilford Press: NY.&lt;/ref&gt; Agresti, 1990;&lt;ref&gt;Agresti, A. (1990). Categorical data analysis. Wiley: NJ.&lt;/ref&gt; Loehlin, 1992;&lt;ref name=":2" /&gt; Menard, 2001;&lt;ref&gt;Menard, S. (2001). Applied logistic regression analysis. (2nd ed.). Thousand Oaks. CA: Sage Publications.&lt;/ref&gt;  Tabachnick, &amp; Fidell, 2007&lt;ref&gt;Tabachnick, B. G., &amp; Fidell, L. S. (2007). Using Multivariate Statistics, 5th ed. Boston: Allyn and Bacon.&lt;/ref&gt;).

==Journals for statistical application for psychology==
There are many specialized journals that publish advances in statistical analysis for psychology. Psychometrika is at the forefront. Educational and Psychological Measurement, Assessment, American Journal of Evaluation, Applied Psychological Measurement, Behavior Research Methods, British Journal of Mathematical and Statistical Psychology, Journal of Educational and Behavioral Statistics, Journal of Mathematical Psychology, Multivariate Behavioral Research, Psychological Assessment, Structural Equation Modeling are other useful journals.

==Software Packages for Psychological Research==

Various software packages are available for statistical methods for psychological research. They can be classified as commercial software (e.g., [[JMP (statistical software)|JMP]] and SPSS) and Open-Source (e.g., R). Among the free-wares, the R software is most popular one. There are many online references for R and specialised books on R for Psychologist are also being written (e.g., Belhekar, 2016 &lt;ref&gt;Belhekar, V. M. (2016). Statistics for Psychology Using R, New Delhi: SAGE. {{ISBN|9789385985003}}&lt;/ref&gt;). The "psych" package of R is very useful for psychologists. Among others, "lavaan", "sem", "ltm", "ggplot2" are some of the popular packages. PSPP and KNIME are other free packages. Among the commercial packages include JMP, SPSS and SAS. JMP and SPSS are commonly reported in books.

== See also ==
*[[Quantitative psychology]]

==References==
* Agresti, A. (1990). Categorical data analysis. Wiley: NJ.
* Bollen, KA. (1989). Structural Equations with Latent Variables. New York: John Wiley &amp; Sons.
* Belhekar, V. M. (2016). Statistics for Psychology Using R, New Delhi: SAGE. {{isbn|9789385985003}}
* {{cite book|author1=Christine P. Dancey|author2=John Reidy|title=Statistics Without Maths for Psychology|url=https://books.google.com/books?id=dTKdcQAACAAJ|year=2011|publisher=Prentice Hall|isbn=978-0-273-72602-9}}
* Cohen, B.H. (2007) ''Explaining Psychological Statistics, 3rd Edition'', Wiley. {{isbn|978-0-470-00718-1}}
* Cronbach LJ (1951). Coefficient alpha and the internal structure of tests. Psychometrika 16, 297–334. doi:10.1007/bf02310555
* Hambleton, R. K., &amp; Swaminathan H. (1985). Item Response theory: Principles and Applications. Boston: Kluwer. 
* Harman, H. H. (1976). Modern Factor Analysis(3rd ed.). Chicago: University of Chicago Press. 
* Hayes, A. F. (2013). Introduction to mediation, moderation, and conditional process analysis. The Guilford Press: NY. 
* Howell, D. (2009) ''Statistical Methods for Psychology, International Edition'', Wadsworth. {{isbn|0-495-59785-6}}
* Kline, T. J. B. (2005)Psychological Testing: A Practical Approach to Design and Evaluation. Sage Publications: Thousand Oaks. 
* Loehlin, J. E. (1992). Latent Variable Models: An Introduction to Factor, Path, and Structural Analysis (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum.
* Lord, F. M. , and Novick, M. R. ( 1 968). Statistical theories of mental test scores. Reading, Mass. : Addison-Wesley, 1968.
* Menard, S. (2001). Applied logistic regression analysis. (2nd ed.). Thousand Oaks. CA: Sage Publications.
* Nunnally, J. &amp; Bernstein, I. (1994). Psychometric Theory.  McGraw-Hill. 
* Raykov, T.  &amp; Marcoulides, G.A. (2010) Introduction to Psychometric Theory. New York: Routledge. 
* Tabachnick, B. G., &amp; Fidell, L. S. (2007). Using Multivariate Statistics, 6th ed. Boston: Pearson. {{isbn|9780205849574}}
* Wilcox, R. (2012). Modern Statistics for the Social and Behavioral Sciences: A Practical Introduction. FL: CRC Press. {{isbn|9781439834565}}


;Specific
&lt;references /&gt;

==External links==
* [https://cran.r-project.org  CRAN Webpage for R]
*[http://personality-project.org/r/   Page for R functions for psychological statistics]
* [http://www.celiagreen.com/charlesmccreery.html Charles McCreery's tutorials on chi-square, probability and Bayes’ theorem for Oxford University psychology students]
* [http://psychologyaustralia.homestead.com/index.htm Matthew Rockloff's tutorials on t-tests, correlation and ANOVA]
*[https://www.youtube.com/user/vivekbelhekar/featured YouTube videos on statistics for psychology by Vivek Belhekar]

{{Library resources box 
|by=no 
|onlinebooks=no 
|others=no 
|about=yes 
|label=Psychological statistics}}

[[Category:Psychometrics]]
[[Category:Psychology experiments]]
[[Category:Psychology lists]]
[[Category:Applied statistics]]</text>
      <sha1>3fnflu7cume2rdbkh9ejg4x4a4labd0</sha1>
    </revision>
  </page>
  <page>
    <title>Robinson's joint consistency theorem</title>
    <ns>0</ns>
    <id>12761741</id>
    <revision>
      <id>746717790</id>
      <parentid>710181181</parentid>
      <timestamp>2016-10-29T03:07:27Z</timestamp>
      <contributor>
        <username>Bender the Bot</username>
        <id>28903366</id>
      </contributor>
      <minor/>
      <comment>/* References */http&amp;rarr;https for [[Google Books]] and [[Google News]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1653">'''Robinson's joint consistency theorem''' is an important theorem of [[mathematical logic]]. It is related to [[Craig interpolation]] and [[Beth definability]].

The classical formulation of Robinson's joint [[consistency]] theorem is as follows:

Let &lt;math&gt;T_1&lt;/math&gt; and  &lt;math&gt;T_2&lt;/math&gt; be [[first-order logic|first-order]] theories. If &lt;math&gt;T_1&lt;/math&gt; and  &lt;math&gt;T_2&lt;/math&gt; are [[consistent]] and the intersection &lt;math&gt;T_1\cap T_2&lt;/math&gt; is [[complete theory | complete]] (in the common language of &lt;math&gt;T_1&lt;/math&gt; and  &lt;math&gt;T_2&lt;/math&gt;), then the union &lt;math&gt;T_1\cup T_2&lt;/math&gt; is consistent. Note that a theory is complete if it decides every formula, i.e. either  &lt;math&gt;T \vdash \varphi&lt;/math&gt; or  &lt;math&gt;T \vdash \neg\varphi&lt;/math&gt;.

Since the completeness assumption is quite hard to fulfill, there is a variant of the theorem:

Let &lt;math&gt;T_1&lt;/math&gt; and  &lt;math&gt;T_2&lt;/math&gt; be [[first-order logic|first-order]] theories. If &lt;math&gt;T_1&lt;/math&gt; and  &lt;math&gt;T_2&lt;/math&gt; are consistent and if there is no formula  &lt;math&gt;\varphi&lt;/math&gt; in the common language of &lt;math&gt;T_1&lt;/math&gt; and  &lt;math&gt;T_2&lt;/math&gt;  such that &lt;math&gt;T_1 \vdash \varphi&lt;/math&gt; and  &lt;math&gt;T_2 \vdash \neg\varphi&lt;/math&gt;, then the union &lt;math&gt;T_1\cup T_2&lt;/math&gt; is consistent.

==References==
*{{cite book|last = Boolos|first = George S. |author2=Burgess, John P. |author3=Jeffrey, Richard C.|title = Computability and Logic|publisher = Cambridge University Press|date = 2002|pages = 264|isbn = 0-521-00758-5|url = https://books.google.com/books?id=Yy14JSjPyY8C}}

[[Category:Mathematical logic]]
[[Category:Theorems in the foundations of mathematics]]

{{logic-stub}}
{{mathlogic-stub}}</text>
      <sha1>tfw352pa0s6hqdljggufo4lnuwlgxlk</sha1>
    </revision>
  </page>
  <page>
    <title>S-plane</title>
    <ns>0</ns>
    <id>2614482</id>
    <revision>
      <id>851459649</id>
      <parentid>851459616</parentid>
      <timestamp>2018-07-22T12:45:19Z</timestamp>
      <contributor>
        <username>Orphan Wiki</username>
        <id>11316070</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2409:4064:31B:8DF2:8C35:558D:272:5BD0|2409:4064:31B:8DF2:8C35:558D:272:5BD0]] ([[User talk:2409:4064:31B:8DF2:8C35:558D:272:5BD0|talk]]) ([[WP:HG|HG]]) (3.1.22)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2898">{{unreferenced|date=February 2016}}
{{DISPLAYTITLE:''s''-plane}}
In [[mathematics]] and [[engineering]], the '''''s''-plane''' is the [[complex plane]] on which [[Laplace transform]]s are graphed.  It is a mathematical domain where, instead of viewing processes in the [[time domain]] modeled with time-based functions, they are viewed as equations in the [[frequency domain]].  It is used as a graphical analysis tool in engineering and physics. 

A real function &lt;math&gt;f&lt;/math&gt; in time &lt;math&gt;t&lt;/math&gt; is translated into the ''s''-plane by taking the [[integral]] of the function multiplied by &lt;math&gt;e^{-st}&lt;/math&gt; from &lt;math&gt;0&lt;/math&gt; to &lt;math&gt;\infty&lt;/math&gt; where ''s'' is a [[complex number]] with the form &lt;math&gt;s = \sigma+j\omega&lt;/math&gt;.

:&lt;math&gt;F(s) = \int_{0}^\infty f(t) e^{-st}\,dt \; | \; s \; \in \mathbb{C}&lt;/math&gt;

This transformation from the ''t''-domain into the ''s''-domain is known as a [[Laplace transform]] and the function &lt;math&gt;F(s)&lt;/math&gt; is called the Laplace transform of  &lt;math&gt;f&lt;/math&gt;.  
One way to understand what this equation is doing is to remember how [[Fourier analysis]] works. In [[Fourier analysis]], harmonic sine and cosine waves are multiplied into the signal, and the resultant integration provides indication of a signal present at that frequency (i.e. the signal's energy at a point in the frequency domain). The Laplace transform does the same thing, but more generally. The &lt;math&gt;e^{-st}&lt;/math&gt; not only catches frequencies, but also the real &lt;math&gt;e^{-t}&lt;/math&gt; effects as well. Laplace transforms therefore cater not only for frequency response, but decay effects as well. For instance, a [[damped sine wave]] can be modeled correctly using Laplace transforms. 

A function in the s-plane can be translated back into a function of time using the [[inverse Laplace transform]]
:&lt;math&gt;f(t) = {1 \over 2\pi i}\lim_{T \to \infty}\int_{\gamma-iT}^{\gamma+iT} F(s) e^{st}\,ds&lt;/math&gt; 
where the real number &lt;math&gt;\gamma&lt;/math&gt; is chosen so the integration path is within the [[region of convergence]] of &lt;math&gt;F(s)&lt;/math&gt;.  However rather than use this complicated integral, most functions of interest are translated using tables of Laplace transform pairs, and the [[Cauchy residue theorem]].
 
Analysing the [[complex number|complex]] roots of an ''s''-plane equation and plotting them on an [[Argand diagram]] can reveal information about the [[frequency]] response and stability of a real time system. This process is called [[Root locus|root locus analysis]].

==See also==
*[[Root locus]]  
*[[State space (controls)]]
*[[z-transform|''z''-transform]]

==External links==
* [http://dspcan.homestead.com/files/Ztran/zlap.htm Illustration of a mapping from the ''s''-plane to the ''z''-plane]
* Kevin Brown (2015) [http://www.mathpages.com/home/kmath508/kmath508.htm Laplace Transforms] at Math Pages.

[[Category:Fourier analysis]]

{{Mathanalysis-stub}}</text>
      <sha1>4ydjg5fs8v4ixkponiz0v1nw428pliy</sha1>
    </revision>
  </page>
  <page>
    <title>Secondary vector bundle structure</title>
    <ns>0</ns>
    <id>26221731</id>
    <revision>
      <id>871684090</id>
      <parentid>829958811</parentid>
      <timestamp>2018-12-02T19:54:11Z</timestamp>
      <contributor>
        <username>Michael Lee Baker</username>
        <id>19769560</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5795">In [[mathematics]], particularly [[differential topology]], the '''secondary vector bundle structure'''
refers to the natural [[vector bundle]] structure {{math|(''TE'', ''p''&lt;sub&gt;∗&lt;/sub&gt;, ''TM'')}} on the total space ''TE'' of the [[tangent bundle]] of a smooth vector bundle {{math|(''E'', ''p'', ''M'')}}, induced by the [[Pushforward (differential)|push-forward]] {{math|''p''&lt;sub&gt;∗&lt;/sub&gt; : ''TE'' → ''TM''}} of the original projection map {{math|''p'' : ''E'' → ''M''}}.
This gives rise to a [[double vector bundle]] structure {{math|(''TE'',''E'',''TM'',''M'')}}.

In the special case {{math|(''E'', ''p'', ''M'') {{=}} (''TM'', ''π&lt;sub&gt;TM&lt;/sub&gt;'', ''M'')}}, where {{math|''TE'' {{=}} ''TTM''}} is the [[double tangent bundle]], the secondary vector bundle {{math|(''TTM'', (''π&lt;sub&gt;TM&lt;/sub&gt;'')&lt;sub&gt;∗&lt;/sub&gt;, ''TM'')}} is isomorphic to the [[tangent bundle]]
{{math|(''TTM'', ''π&lt;sub&gt;TTM&lt;/sub&gt;'', ''TM'')}} of {{math|''TM''}} through the [[double tangent bundle|canonical flip]].

== Construction of the secondary vector bundle structure ==
Let {{math|(''E'', ''p'', ''M'')}} be a smooth vector bundle of rank {{mvar|N}}. Then the preimage {{math|(''p''&lt;sub&gt;∗&lt;/sub&gt;)&lt;sup&gt;−1&lt;/sup&gt;(''X'') ⊂ ''TE''}} of any tangent vector {{mvar|X}} in {{math|''TM''}} in the push-forward {{math|''p''&lt;sub&gt;∗&lt;/sub&gt; : ''TE'' → ''TM''}} of the canonical projection {{math|''p'' : ''E'' → ''M''}} is a smooth submanifold of dimension {{math|2''N''}}, and it becomes a vector space with the push-forwards

:&lt;math&gt; +_*:T(E\times E)\to TE, \qquad \lambda_*:TE\to TE &lt;/math&gt;

of the original addition and scalar multiplication

:&lt;math&gt;+:E\times E\to E, \qquad \lambda:E\to E&lt;/math&gt;

as its vector space operations. The triple {{math|(''TE'', ''p''&lt;sub&gt;∗&lt;/sub&gt;, ''TM'')}} becomes a smooth vector bundle with these vector space operations on its fibres.

=== Proof ===
Let {{math|(''U'', ''φ'')}} be a local coordinate system on the base manifold {{mvar|M}} with {{math|''φ''(''x'') {{=}} (''x''&lt;sup&gt;1&lt;/sup&gt;, ..., ''x&lt;sup&gt;n&lt;/sup&gt;'')}} and let

:&lt;math&gt;\begin{cases}\psi:W \to \varphi(U)\times \mathbf{R}^N \\ \psi \left (v^k e_k|_x \right ) := \left (x^1,\ldots,x^n,v^1,\ldots,v^N \right )\end{cases}&lt;/math&gt;

be a coordinate system on &lt;math&gt;W:=p^{-1}(U)\subset E&lt;/math&gt; adapted to it. Then

:&lt;math&gt; p_*\left (X^k\frac{\partial}{\partial x^k}\Bigg|_v + Y^\ell\frac{\partial}{\partial v^\ell}\Bigg|_v \right) = X^k\frac{\partial}{\partial x^k}\Bigg|_{p(v)},&lt;/math&gt;

so the fiber of the secondary vector bundle structure at {{mvar|X}} in {{math|''T&lt;sub&gt;x&lt;/sub&gt;M''}} is of the form

:&lt;math&gt;p^{-1}_*(X) = \left \{ X^k\frac{\partial}{\partial x^k}\Bigg|_v + Y^\ell\frac{\partial}{\partial v^\ell}\Bigg|_v \ : \ v\in E_x;  Y^1,\ldots,Y^N\in\mathbf{R} \right \}.&lt;/math&gt;

Now it turns out that

:&lt;math&gt; \chi\left(X^k\frac{\partial}{\partial x^k}\Bigg|_v + Y^\ell\frac{\partial}{\partial v^\ell}\Bigg|_v\right ) = \left (X^k\frac{\partial}{\partial x^k}\Bigg|_{p(v)}, \left (v^1,\ldots,v^N,Y^1,\ldots,Y^N \right) \right )&lt;/math&gt;

gives a local trivialization {{math|''χ'' : ''TW'' → ''TU'' × '''R'''&lt;sup&gt;2''N''&lt;/sup&gt;}} for {{math|(''TE'', ''p''&lt;sub&gt;∗&lt;/sub&gt;, ''TM'')}}, and the push-forwards of the original vector space operations read in the adapted coordinates as

:&lt;math&gt;\left (X^k\frac{\partial}{\partial x^k}\Bigg|_v + Y^\ell\frac{\partial}{\partial v^\ell}\Bigg|_v\right) +_* \left (X^k\frac{\partial}{\partial x^k}\Bigg|_w + Z^\ell\frac{\partial}{\partial v^\ell}\Bigg|_w\right) = X^k\frac{\partial}{\partial x^k}\Bigg|_{v+w} + (Y^\ell+Z^\ell)\frac{\partial}{\partial v^\ell}\Bigg|_{v+w} &lt;/math&gt;

and

:&lt;math&gt; \lambda_*\left (X^k\frac{\partial}{\partial x^k}\Bigg|_v + Y^\ell\frac{\partial}{\partial v^\ell}\Bigg|_v\right) = X^k\frac{\partial}{\partial x^k}\Bigg|_{\lambda v} + \lambda Y^\ell\frac{\partial}{\partial v^\ell}\Bigg|_{\lambda v}, &lt;/math&gt;

so each fibre {{math|(''p''&lt;sub&gt;∗&lt;/sub&gt;)&lt;sup&gt;−1&lt;/sup&gt;(''X'') ⊂ ''TE''}} is a vector space and the triple {{math|(''TE'', ''p''&lt;sub&gt;∗&lt;/sub&gt;, ''TM'')}} is a smooth vector bundle.

== Linearity of connections on vector bundles ==
The general [[Ehresmann connection]] {{math|''TE'' {{=}} ''HE'' ⊕ ''VE''}} on a vector bundle {{math|(''E'', ''p'', ''M'')}} can be characterized in terms of the '''connector map'''

:&lt;math&gt;\begin{cases}\kappa:T_vE\to E_{p(v)} \\ \kappa(X):=\operatorname{vl}_v^{-1}(\operatorname{vpr}X) \end{cases}&lt;/math&gt;

where {{math|vl&lt;sub&gt;''v''&lt;/sub&gt; : ''E''  → ''V&lt;sub&gt;v&lt;/sub&gt;E''}} is the [[vector bundle|vertical lift]], and {{math|vpr&lt;sub&gt;''v''&lt;/sub&gt; : ''T&lt;sub&gt;v&lt;/sub&gt;E'' → ''V&lt;sub&gt;v&lt;/sub&gt;E''}} is the [[Ehresmann connection|vertical projection]]. The mapping

:&lt;math&gt;\begin{cases}\nabla:\Gamma(TM)\times\Gamma(E)\to\Gamma(E) \\ \nabla_Xv := \kappa(v_*X) \end{cases}&lt;/math&gt;

induced by an Ehresmann connection is a [[covariant derivative]] on {{math|Γ(''E'')}} in the sense that

:&lt;math&gt;\begin{align}
\nabla_{X+Y}v &amp;= \nabla_X v + \nabla_Y v \\
\nabla_{\lambda X}v &amp;=\lambda \nabla_Xv \\
\nabla_X(v+w) &amp;= \nabla_X v + \nabla_X w \\
\nabla_X(\lambda v) &amp;=\lambda \nabla_Xv \\
\nabla_X(fv) &amp;= X[f]v + f\nabla_Xv
\end{align}&lt;/math&gt;

if and only if the connector map is linear with respect to the secondary vector bundle structure {{math|(''TE'', ''p''&lt;sub&gt;∗&lt;/sub&gt;, ''TM'')}} on {{math|''TE''}}. Then the connection is called ''linear''. Note that the connector map is automatically linear with respect to the tangent bundle structure {{math|(''TE'', ''π&lt;sub&gt;TE&lt;/sub&gt;'', ''E'')}}.

== See also ==
* [[Connection (vector bundle)]]
* [[Double tangent bundle]]
* [[Ehresmann connection]]
* [[Vector bundle]]

== References ==

* P.Michor. ''Topics in Differential Geometry,'' American Mathematical Society (2008).

[[Category:Differential geometry]]
[[Category:Topology]]
[[Category:Differential topology]]</text>
      <sha1>5p23ht79om3daz7iglephs3z90zs9se</sha1>
    </revision>
  </page>
  <page>
    <title>Submodular set function</title>
    <ns>0</ns>
    <id>33273315</id>
    <revision>
      <id>871414365</id>
      <parentid>868863075</parentid>
      <timestamp>2018-11-30T22:11:19Z</timestamp>
      <contributor>
        <username>KilgoresPen</username>
        <id>35273898</id>
      </contributor>
      <comment>Deleted a property which was incorrect. The page used to state that the composition of a concave and submodular function was submodular - this is not true in general. Also minor reformatting.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17928">In mathematics, a '''submodular set function''' (also known as a '''submodular function''') is a [[set function]] whose value, informally, has the property that the difference in the incremental value of the function that a single element makes when added to an input set decreases as the size of the input set increases. Submodular functions have a natural [[diminishing returns]] property which makes them suitable for many applications, including [[approximation algorithms]], [[game theory]] (as functions modeling user preferences) and [[electrical network]]s. Recently, submodular functions have also found immense utility in several real world problems in [[machine learning]] and [[artificial intelligence]], including [[automatic summarization]], [[multi-document summarization]], [[feature selection]], [[Active learning (machine learning)|active learning]], sensor placement, image collection summarization and many other domains.&lt;ref name="LB" /&gt;&lt;ref name="TIWB" /&gt;&lt;ref name="KG1" /&gt;&lt;ref name="KG" /&gt;

== Definition ==
If &lt;math&gt;\Omega&lt;/math&gt; is a finite [[set (mathematics)|set]], a submodular function is a set function &lt;math&gt;f:2^{\Omega}\rightarrow \mathbb{R}&lt;/math&gt;, where &lt;math&gt;2^\Omega&lt;/math&gt; denotes the [[Power set#Representing subsets as functions|power set]] of &lt;math&gt;\Omega&lt;/math&gt;, which satisfies one of the following equivalent conditions.&lt;ref&gt;{{Harvard citations|last = Schrijver|year = 2003|loc = §44, p. 766|nb = }}&lt;/ref&gt;
# For every &lt;math&gt;X, Y \subseteq \Omega&lt;/math&gt; with &lt;math&gt; X \subseteq Y&lt;/math&gt; and every &lt;math&gt;x \in \Omega \setminus Y&lt;/math&gt; we have that &lt;math&gt;f(X\cup \{x\})-f(X)\geq f(Y\cup \{x\})-f(Y)&lt;/math&gt;.
# For every &lt;math&gt;S, T \subseteq \Omega&lt;/math&gt; we have that &lt;math&gt;f(S)+f(T)\geq f(S\cup T)+f(S\cap T)&lt;/math&gt;.
# For every &lt;math&gt;X\subseteq \Omega&lt;/math&gt; and &lt;math&gt;x_1,x_2\in \Omega\backslash X&lt;/math&gt; we have that &lt;math&gt;f(X\cup \{x_1\})+f(X\cup \{x_2\})\geq f(X\cup \{x_1,x_2\})+f(X)&lt;/math&gt;.

A nonnegative submodular function is also a [[Subadditive set function|subadditive]] function, but a subadditive function need not be submodular.
If &lt;math&gt;\Omega&lt;/math&gt; is not assumed finite, then the above conditions are not equivalent.  In particular a function 
&lt;math&gt;f&lt;/math&gt; defined by &lt;math&gt;f(S) = 1&lt;/math&gt; if &lt;math&gt;S&lt;/math&gt; is finite and &lt;math&gt;f(S) = 0&lt;/math&gt; if &lt;math&gt;S&lt;/math&gt; is infinite 
satisfies the first condition above, but the second condition fails when &lt;math&gt;S&lt;/math&gt; and &lt;math&gt;T&lt;/math&gt; are infinite sets with finite intersection.

== Types of submodular functions ==

=== Monotone ===
A submodular function &lt;math&gt;f&lt;/math&gt; is ''monotone'' if for every &lt;math&gt;T\subseteq S&lt;/math&gt; we have that &lt;math&gt;f(T)\leq f(S)&lt;/math&gt;. Examples of monotone submodular functions include:
; Linear (Modular) functions : Any function of the form &lt;math&gt;f(S)=\sum_{i\in S}w_i&lt;/math&gt; is called a linear function. Additionally if &lt;math&gt;\forall i,w_i\geq 0&lt;/math&gt; then f is monotone.
; Budget-additive functions : Any function of the form &lt;math&gt;f(S)=\min\left\{B,~\sum_{i\in S}w_i\right\}&lt;/math&gt; for each &lt;math&gt;w_i\geq 0&lt;/math&gt; and &lt;math&gt;B\geq 0&lt;/math&gt; is called budget additive.{{citation needed|date=August 2014}}
; Coverage functions : Let &lt;math&gt;\Omega=\{E_1,E_2,\ldots,E_n\}&lt;/math&gt; be a collection of subsets of some [[matroid|ground set]] &lt;math&gt;\Omega'&lt;/math&gt;. The function &lt;math&gt;f(S)=\left|\bigcup_{E_i\in S}E_i\right|&lt;/math&gt; for &lt;math&gt;S\subseteq \Omega&lt;/math&gt; is called a coverage function. This can be generalized by adding non-negative weights to the elements.
; [[Entropy (information theory)|Entropy]] : Let &lt;math&gt;\Omega=\{X_1,X_2,\ldots,X_n\}&lt;/math&gt; be a set of [[random variables]]. Then for any &lt;math&gt;S\subseteq \Omega&lt;/math&gt; we have that &lt;math&gt;H(S)&lt;/math&gt; is a submodular function, where &lt;math&gt;H(S)&lt;/math&gt; is the entropy of the set of random variables &lt;math&gt;S&lt;/math&gt;.&lt;ref&gt;{{Cite web|url = http://www.cs.cmu.edu/~aarti/Class/10704_Spring15/lecs/lec3.pdf|title = Information Processing and Learning|date = |access-date = |website = |publisher = cmu|last = |first = }}&lt;/ref&gt;
; [[Matroid]] [[matroid rank|rank functions]] : Let &lt;math&gt;\Omega=\{e_1,e_2,\dots,e_n\}&lt;/math&gt; be the ground set on which a matroid is defined. Then the rank function of the matroid is a submodular function.&lt;ref name=F22&gt;Fujishige (2005) p.22&lt;/ref&gt;

=== Non-monotone ===
A submodular function which is not monotone is called ''non-monotone''.

==== Symmetric ====
A non-monotone submodular function &lt;math&gt;f&lt;/math&gt; is called ''symmetric'' if for every &lt;math&gt;S\subseteq \Omega&lt;/math&gt; we have that &lt;math&gt;f(S)=f(\Omega-S)&lt;/math&gt;.
Examples of symmetric non-monotone submodular functions include:
; Graph cuts : Let &lt;math&gt;\Omega=\{v_1,v_2,\dots,v_n\}&lt;/math&gt; be the vertices of a [[Graph (discrete mathematics)|graph]]. For any set of vertices &lt;math&gt;S\subseteq \Omega&lt;/math&gt; let &lt;math&gt;f(S)&lt;/math&gt; denote the number of edges &lt;math&gt;e=(u,v)&lt;/math&gt; such that &lt;math&gt;u\in S&lt;/math&gt; and &lt;math&gt;v\in \Omega-S&lt;/math&gt;. This can be generalized by adding non-negative weights to the edges.
; [[Mutual information]] : Let &lt;math&gt;\Omega=\{X_1,X_2,\ldots,X_n\}&lt;/math&gt; be a set of [[random variable]]s. Then for any &lt;math&gt;S\subseteq \Omega&lt;/math&gt; we have that &lt;math&gt;f(S)=I(S;\Omega-S)&lt;/math&gt; is a submodular function, where &lt;math&gt;I(S;\Omega-S)&lt;/math&gt; is the mutual information.

==== Asymmetric ====
A non-monotone submodular function which is not symmetric is called asymmetric.
; Directed cuts : Let &lt;math&gt;\Omega=\{v_1,v_2,\dots,v_n\}&lt;/math&gt; be the vertices of a [[directed graph]]. For any set of vertices &lt;math&gt;S\subseteq \Omega&lt;/math&gt; let &lt;math&gt;f(S)&lt;/math&gt; denote the number of edges &lt;math&gt;e=(u,v)&lt;/math&gt; such that &lt;math&gt;u\in S&lt;/math&gt; and &lt;math&gt;v\in \Omega-S&lt;/math&gt;. This can be generalized by adding non-negative weights to the directed edges.

== Continuous extensions ==

=== Lovász extension ===
This extension is named after mathematician [[László Lovász]]. Consider any vector &lt;math&gt;\mathbf{x}=\{x_1,x_2,\dots,x_n\}&lt;/math&gt; such that each &lt;math&gt;0\leq x_i\leq 1&lt;/math&gt;. Then the Lovász extension is defined as &lt;math&gt;f^L(\mathbf{x})=\mathbb{E}(f(\{i|x_i\geq \lambda\}))&lt;/math&gt; where the expectation is over &lt;math&gt;\lambda&lt;/math&gt; chosen from the [[uniform distribution (continuous)|uniform distribution]] on the interval &lt;math&gt;[0,1]&lt;/math&gt;. The Lovász extension is a convex function.

=== Multilinear extension ===
Consider any vector &lt;math&gt;\mathbf{x}=\{x_1,x_2,\ldots,x_n\}&lt;/math&gt; such that each &lt;math&gt;0\leq x_i\leq 1&lt;/math&gt;. Then the multilinear extension is defined as &lt;math&gt;F(\mathbf{x})=\sum_{S\subseteq \Omega} f(S) \prod_{i\in S} x_i \prod_{i\notin S} (1-x_i)&lt;/math&gt;.

=== Convex closure ===
Consider any vector &lt;math&gt;\mathbf{x}=\{x_1,x_2,\dots,x_n\}&lt;/math&gt; such that each &lt;math&gt;0\leq x_i\leq 1&lt;/math&gt;. Then the convex closure is defined as &lt;math&gt;f^-(\mathbf{x})=\min\left(\sum_S \alpha_S f(S):\sum_S \alpha_S 1_S=\mathbf{x},\sum_S \alpha_S=1,\alpha_S\geq 0\right)&lt;/math&gt;. It can be shown that &lt;math&gt;f^L(\mathbf{x})=f^-(\mathbf{x})&lt;/math&gt;.

=== Concave closure ===
Consider any vector &lt;math&gt;\mathbf{x}=\{x_1,x_2,\dots,x_n\}&lt;/math&gt; such that each &lt;math&gt;0\leq x_i\leq 1&lt;/math&gt;. Then the concave closure is defined as &lt;math&gt;f^+(\mathbf{x})=\max\left(\sum_S \alpha_S f(S):\sum_S \alpha_S 1_S=\mathbf{x},\sum_S \alpha_S=1,\alpha_S\geq 0\right)&lt;/math&gt;.

== Properties ==
# The class of submodular functions is [[closure (mathematics)|closed]] under non-negative [[linear combination]]s. Consider any submodular function &lt;math&gt;f_1,f_2,\ldots,f_k&lt;/math&gt; and non-negative numbers &lt;math&gt;\alpha_1,\alpha_2,\ldots,\alpha_k&lt;/math&gt;. Then the function &lt;math&gt;g&lt;/math&gt; defined by &lt;math&gt;g(S)=\sum_{i=1}^k \alpha_i f_i(S)&lt;/math&gt; is submodular. 
#For any submodular function &lt;math&gt;f&lt;/math&gt;, the function defined by &lt;math&gt;g(S)=f(\Omega \setminus S)&lt;/math&gt; is submodular. 
#The function &lt;math&gt;g(S)=\min(f(S),c)&lt;/math&gt;, where &lt;math&gt;c&lt;/math&gt; is a real number, is submodular whenever &lt;math&gt;f&lt;/math&gt; is monotone submodular.
# Consider a random process where a set &lt;math&gt;T&lt;/math&gt; is chosen with each element in &lt;math&gt;\Omega&lt;/math&gt; being included in &lt;math&gt;T&lt;/math&gt; independently with probability &lt;math&gt;p&lt;/math&gt;. Then the following inequality is true &lt;math&gt;\mathbb{E}[f(T)]\geq p f(\Omega)+(1-p) f(\varnothing)&lt;/math&gt; where &lt;math&gt;\varnothing&lt;/math&gt; is the empty set. More generally consider the following random process where a set &lt;math&gt;S&lt;/math&gt; is constructed as follows. For each of &lt;math&gt;1\leq i\leq l, A_i\subseteq \Omega&lt;/math&gt; construct &lt;math&gt;S_i&lt;/math&gt; by including each element in &lt;math&gt;A_i&lt;/math&gt; independently into &lt;math&gt;S_i&lt;/math&gt; with probability &lt;math&gt;p_i&lt;/math&gt;. Furthermore let &lt;math&gt;S=\cup_{i=1}^l S_i&lt;/math&gt;. Then the following inequality is true &lt;math&gt;\mathbb{E}[f(S)]\geq \sum_{R\subseteq [l]} \Pi_{i\in R}p_i \Pi_{i\notin R}(1-p_i)f(\cup_{i\in R}A_i)&lt;/math&gt;.{{Citation needed|date=November 2013}}

== Optimization problems ==
Submodular functions have properties which are very similar to [[convex function|convex]] and [[concave function]]s. For this reason, an [[optimization problem]] which concerns optimizing a convex or concave function can also be described as the problem of maximizing or minimizing a submodular function subject to some constraints.

=== Submodular minimization===
The simplest minimization problem is to find a set &lt;math&gt;S\subseteq \Omega&lt;/math&gt; which minimizes a submodular function subject to no constraints. This problem is computable in (strongly)&lt;ref name="IFF" /&gt;&lt;ref name="Schrijver" /&gt; [[polynomial time]].&lt;ref name="GLS" /&gt;&lt;ref name="Cunningham" /&gt; Computing the [[minimum cut]] in a graph is a special case of this general minimization problem. However, even simple constraints like cardinality lower bound constraints make this problem [[NP hard]], with polynomial lower bound approximation factors.&lt;ref name="SF" /&gt;&lt;ref name="IJB" /&gt;

=== Submodular maximization===
Unlike minimization, maximization of submodular functions is usually [[NP-hard]]. Many problems, such as [[max cut]] and the [[maximum coverage problem]], can be cast as special cases of this general maximization problem under suitable constraints. Typically, the approximation algorithms for these problems are based on either [[greedy algorithm]]s or [[local search (optimization)|local search algorithm]]s. The problem of maximizing a symmetric non-monotone submodular function subject to no constraints admits a 1/2 approximation algorithm.&lt;ref name="FMV" /&gt; Computing the [[maximum cut]] of a graph is a special case of this problem. The more general problem of maximizing an arbitrary non-monotone submodular function subject to no constraints also admits a 1/2 approximation algorithm.&lt;ref name="BFNS" /&gt; The problem of maximizing a monotone submodular function subject to a cardinality constraint admits a &lt;math&gt;1 - 1/e&lt;/math&gt; approximation algorithm.&lt;ref name="NVF" /&gt; The [[maximum coverage problem]] is a special case of this problem. The more general problem of maximizing a monotone submodular function subject to a [[matroid]] constraint also admits a &lt;math&gt;1 - 1/e&lt;/math&gt; approximation algorithm.&lt;ref name="CCPV" /&gt;&lt;ref name="FNS" /&gt;&lt;ref name="FW" /&gt; Many of these algorithms can be unified within a semi-differential based framework of algorithms.&lt;ref name="IJB" /&gt;

===Related optimization problems===
Apart from submodular minimization and maximization, another natural problem is Difference of Submodular Optimization.&lt;ref name="NB" /&gt;&lt;ref name="IBUAI" /&gt; Unfortunately, this problem is not only NP hard, but also inapproximable.&lt;ref name="IBUAI" /&gt; A related optimization problem is minimize or maximize a submodular function, subject to a submodular level set constraint (also called submodular optimization subject to submodular cover or submodular knapsack constraint). This problem admits bounded approximation guarantees.&lt;ref name="IB" /&gt; Another optimization problem involves partitioning data based on a submodular function, so as to maximize the average welfare. This problem is called the submodular welfare problem.&lt;ref name="JV" /&gt;

== Applications ==
Submodular functions naturally occur in several real world applications, in [[economics]], [[game theory]], [[machine learning]] and [[computer vision]]. Owing the diminishing returns property, submodular functions naturally model costs of items, since there is often a larger discount, with an increase in the items one buys. Submodular functions model notions of complexity, similarity and cooperation when they appear in minimization problems. In maximization problems, on the other hand, they model notions of diversity, information and coverage. For more information on applications of submodularity, particularly in machine learning, see &lt;ref name="KG" /&gt;&lt;ref name="ST" /&gt;&lt;ref name="JB" /&gt;

== See also ==
* [[Supermodular function]]
* [[Matroid]], [[Polymatroid]]
* [[Utility functions on indivisible goods]]

== Citations ==
{{reflist|30em|
refs=
&lt;ref name="GLS"&gt;{{cite journal |authorlink=Martin Grötschel |first=M. |last=Gr&amp;ouml;tschel |authorlink2=László Lovász |first2=L. |last2=Lovasz |authorlink3=Alexander Schrijver |first3=A. |last3=Schrijver |title=The ellipsoid method and its consequences in combinatorial optimization |journal=Combinatorica |volume=1 |issue=2 |year=1981 |pages=169–197 |doi=10.1007/BF02579273 }}&lt;/ref&gt;
&lt;ref name="Cunningham"&gt;{{cite journal |first=W. H. |last=Cunningham |title=On submodular function minimization |journal=Combinatorica |volume=5 |issue=3 |year=1985 |pages=185–192 |doi=10.1007/BF02579361 }}&lt;/ref&gt;
&lt;ref name="IFF"&gt;{{cite journal |first=S. |last=Iwata |first2=L. |last2=Fleischer |first3=S. |last3=Fujishige |title=A combinatorial strongly polynomial algorithm for minimizing submodular functions |journal=J. ACM |volume=48 |year=2001 |issue=4 |pages=761–777 |doi=10.1145/502090.502096 }}&lt;/ref&gt;
&lt;ref name="Schrijver"&gt;{{cite journal |authorlink=Alexander Schrijver |first=A. |last=Schrijver |title=A combinatorial algorithm minimizing submodular functions in strongly polynomial time |journal=J. Combin. Theory Ser. B |volume=80 |year=2000 |issue=2 |pages=346–355 |doi=10.1006/jctb.2000.1989 }}&lt;/ref&gt;
&lt;ref name="IJB"&gt;R. Iyer, S. Jegelka and J. Bilmes, Fast Semidifferential based submodular function optimization, Proc. ICML (2013).&lt;/ref&gt;
&lt;ref name="IB"&gt;R. Iyer and J. Bilmes, Submodular Optimization Subject to Submodular Cover and Submodular Knapsack Constraints, In Advances of NIPS (2013).&lt;/ref&gt;
&lt;ref name="IBUAI"&gt;R. Iyer and J. Bilmes, Algorithms for Approximate Minimization of the Difference between Submodular Functions, In Proc. UAI (2012).&lt;/ref&gt;
&lt;ref name="NB"&gt;M. Narasimhan and J. Bilmes, A submodular-supermodular procedure with applications to discriminative structure learning, In Proc. UAI (2005).&lt;/ref&gt;
&lt;ref name="FMV"&gt;[[Uriel Feige|U. Feige]], V. Mirrokni and J. Vondr&amp;aacute;k, Maximizing non-monotone submodular functions, Proc. of 48th FOCS (2007), pp. 461–471.&lt;/ref&gt;
&lt;ref name="NVF"&gt;[[George Nemhauser|G. L. Nemhauser]], L. A. Wolsey and M. L. Fisher, An analysis of approximations for maximizing submodular set functions I, Mathematical Programming 14 (1978), 265–294.&lt;/ref&gt;
&lt;ref name="CCPV"&gt;G. Calinescu, C. Chekuri, M. P&amp;aacute;l and J. Vondr&amp;aacute;k, Maximizing a submodular set function subject to a matroid constraint, SIAM J. Comp. 40:6 (2011), 1740-1766.&lt;/ref&gt;
&lt;ref name="BFNS"&gt;N. Buchbinder, M. Feldman, J. Naor and R. Schwartz, A tight linear time (1/2)-approximation for unconstrained submodular maximization, Proc. of 53rd FOCS (2012), pp. 649-658.&lt;/ref&gt;
&lt;ref name="FW"&gt;Y. Filmus, J. Ward, A tight combinatorial algorithm for submodular maximization subject to a matroid constraint, Proc. of 53rd FOCS (2012), pp. 659-668.&lt;/ref&gt;
&lt;ref name="SF"&gt;Z. Svitkina and L. Fleischer, Submodular approximation: Sampling-based algorithms and lower bounds, SIAM Journal on Computing (2011).&lt;/ref&gt;
&lt;ref name="JV"&gt;J. Vondr&amp;aacute;k, Optimal approximation for the submodular welfare problem in the value oracle model, Proc. of STOC (2008), pp. 461–471.&lt;/ref&gt;
&lt;ref name="ST"&gt;http://submodularity.org/.&lt;/ref&gt;
&lt;ref name="KG"&gt;A. Krause and C. Guestrin, Beyond Convexity: Submodularity in Machine Learning, Tutorial at ICML-2008&lt;/ref&gt;
&lt;ref name="JB"&gt;J. Bilmes, Submodularity in Machine Learning Applications, Tutorial at AAAI-2015.&lt;/ref&gt;
&lt;ref name="LB"&gt;H. Lin and J. Bilmes, A Class of Submodular Functions for Document Summarization, ACL-2011.&lt;/ref&gt;
&lt;ref name="TIWB"&gt;S. Tschiatschek, R. Iyer, H. Wei and J. Bilmes, Learning Mixtures of Submodular Functions for Image Collection Summarization, NIPS-2014.&lt;/ref&gt;
&lt;ref name="KG1"&gt;A. Krause and C. Guestrin, Near-optimal nonmyopic value of information in graphical models, UAI-2005.&lt;/ref&gt;
&lt;ref name="FNS"&gt;M. Feldman, J. Naor and R. Schwartz, A unified continuous greedy algorithm for submodular maximization, Proc. of 52nd FOCS (2011).&lt;/ref&gt;
}}

== References ==

*{{Citation|last=Schrijver|first=Alexander|authorlink=Alexander Schrijver|year=2003|title=Combinatorial Optimization|location=|publisher=[[Springer Publishing|Springer]]|isbn=3-540-44389-4}}
*{{Citation|last=Lee|first=Jon|authorlink=Jon Lee (mathematician)|year= 2004 |title=A First Course in Combinatorial Optimization |location=|publisher=[[Cambridge University Press]]|isbn= 0-521-01012-8}}
*{{Citation|last=Fujishige|first=Satoru|year=2005|title=Submodular Functions and Optimization|location=|publisher=[[Elsevier]]|isbn=0-444-52086-4}}
*{{Citation|last=Narayanan|first=H.|year= 1997 |title=Submodular Functions and Electrical Networks|location=|publisher=|isbn= 0-444-82523-1}}
*{{citation | last=Oxley | first=James G. | title=Matroid theory | series=Oxford Science Publications | location=Oxford | publisher=[[Oxford University Press]] | year=1992 | isbn=0-19-853563-5 | zbl=0784.05002 }}

==External links==
* http://www.cs.berkeley.edu/~stefje/references.html has a longer bibliography

&lt;!--- Categories ---&gt;
[[Category:Combinatorial optimization| ]]
[[Category:Approximation algorithms| ]]
[[Category:Matroid theory|Matroid theory]]</text>
      <sha1>jsfup7nhr3qh6a2wzwwsqeaw7crm6nc</sha1>
    </revision>
  </page>
  <page>
    <title>Sulston score</title>
    <ns>0</ns>
    <id>17218394</id>
    <revision>
      <id>815588005</id>
      <parentid>807271136</parentid>
      <timestamp>2017-12-15T19:32:49Z</timestamp>
      <contributor>
        <username>Sbmehta</username>
        <id>765172</id>
      </contributor>
      <minor/>
      <comment>capitalization</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8932">The '''Sulston score''' is an equation used in [[Gene mapping#Physical Mapping|DNA mapping]] to numerically assess the likelihood that a given "fingerprint" similarity between two DNA clones is merely a result of chance. Used as such, it is a [[Statistical significance|test of statistical significance]]. That is, low values imply that similarity is ''significant'', suggesting that two DNA clones overlap one another and that the given similarity is not just a chance event. The name is an [[eponym]] that refers to [[John Sulston]] by virtue of his being the lead author of the paper that first proposed the equation's use.&lt;ref name=sulston1988&gt;{{cite journal |vauthors=Sulston J, Mallett F, Staden R, Durbin R, Horsnell T, Coulson A |title=Software for genome mapping by fingerprinting techniques |journal=Comput Appl Biosci |volume=4 |issue=1 |pages=125–32 |date=Mar 1988 |pmid=2838135 |doi=10.1093/bioinformatics/4.1.125}}&lt;/ref&gt;

== The overlap problem in mapping ==

Each clone in a [[Gene mapping#Physical Mapping|DNA mapping]] project has a "fingerprint", ''i.e.'' a set of DNA fragment lengths inferred from (1) enzymatically digesting the clone, (2) separating these fragments on a gel, and (3) estimating their lengths based on gel location. For each pairwise clone comparison, one can establish how many lengths from each set match-up. Cases having at least 1 match indicate that the clones ''might'' overlap because matches ''may'' represent the same DNA. However, the underlying sequences for each match are not known. Consequently, two fragments whose lengths match may still represent different sequences. In other words, matches do not conclusively indicate overlaps. The problem is instead one of using matches to [[Probability|probabilistically]] classify overlap status.

=== Mathematical scores in overlap assessment ===

Biologists have used a variety of means (often in combination) to discern clone overlaps in [[Gene mapping#Physical Mapping|DNA mapping]] projects. While many are biological, ''i.e.'' looking for shared markers, others are basically mathematical, usually adopting probabilistic and/or statistical approaches.

== Sulston score exposition ==

The Sulston score is rooted in the concepts of [[Bernoulli process|Bernoulli]] and [[Binomial Distribution|binomial processes]], as follows. Consider two clones, &lt;math&gt;\alpha&lt;/math&gt; and &lt;math&gt;\beta&lt;/math&gt;, having &lt;math&gt;m&lt;/math&gt; and &lt;math&gt;n&lt;/math&gt; measured fragment lengths, respectively, where &lt;math&gt;m \ge n&lt;/math&gt;. That is, clone &lt;math&gt;\alpha&lt;/math&gt; has at least as many fragments as clone &lt;math&gt;\beta&lt;/math&gt;, but usually more. The Sulston score is the probability that at least &lt;math&gt;h&lt;/math&gt; fragment lengths on clone &lt;math&gt;\beta&lt;/math&gt; will be matched by any combination of lengths on &lt;math&gt;\alpha&lt;/math&gt;. Intuitively, we see that, at most, there can be &lt;math&gt;n&lt;/math&gt; matches. Thus, for a given comparison between two clones, one can measure the statistical significance of a match of &lt;math&gt;h&lt;/math&gt; fragments, ''i.e.'' how likely it is that this match occurred simply as a result of random chance. Very low values would indicate a significant match that is highly unlikely to have arisen by pure chance, while higher values would suggest that the given match could be just a coincidence.

:{| class="toccolours collapsible collapsed" width="60%" style="text-align:left"
!Derivation of the Sulston Score
|-
|One of the basic assumptions is that fragments are uniformly distributed on a gel, ''i.e.'' a fragment has an equal likelihood of appearing anywhere on the gel. Since gel position is an indicator of fragment length, this assumption is equivalent to presuming that the fragment lengths are uniformly distributed. The measured location of any fragment &lt;math&gt;x&lt;/math&gt;, has an associated error tolerance of &lt;math&gt;\pm t&lt;/math&gt;, so that its true location is only known to lie within the segment &lt;math&gt;x \pm t&lt;/math&gt;.

In what follows, let us refer to individual fragment lengths simply as ''lengths''. Consider a specific length &lt;math&gt;j&lt;/math&gt; on clone &lt;math&gt;\beta&lt;/math&gt; and a specific length &lt;math&gt;i&lt;/math&gt; on clone &lt;math&gt;\alpha&lt;/math&gt;. These two lengths are arbitrarily selected from their respective sets &lt;math&gt;i \in \{1, 2, \dots, m\}&lt;/math&gt; and &lt;math&gt;j \in \{1, 2, \dots, n\}&lt;/math&gt;. We assume that the gel location of fragment &lt;math&gt;j&lt;/math&gt; has been determined and we want
the probability of the event &lt;math&gt;E_{ij}&lt;/math&gt; that the location of fragment &lt;math&gt;i&lt;/math&gt; will match that of &lt;math&gt;j&lt;/math&gt;. Geometrically, &lt;math&gt;i&lt;/math&gt; will be declared to match &lt;math&gt;j&lt;/math&gt; if it falls inside the window of size &lt;math&gt;2 t&lt;/math&gt; around &lt;math&gt;j&lt;/math&gt;. Since fragment &lt;math&gt;i&lt;/math&gt; could occur anywhere in the gel of length &lt;math&gt;G&lt;/math&gt;, we have &lt;math&gt;P \langle E_{ij} \rangle = 2 t / G&lt;/math&gt;. The probability that &lt;math&gt;i&lt;/math&gt; ''does not'' match &lt;math&gt;j&lt;/math&gt; is simply the complement, i.e. &lt;math&gt;P \langle E_{i,j}^C \rangle = 1 - 2 t / G&lt;/math&gt;, since it must either match or not match.

Now, let us expand this to compute the probability that no length on clone &lt;math&gt;\alpha&lt;/math&gt; matches the single particular length &lt;math&gt;j&lt;/math&gt; on clone &lt;math&gt;\beta&lt;/math&gt;. This is simply the intersection of all individual trials &lt;math&gt;i \in \{1, 2, \dots, m\}&lt;/math&gt; where the event &lt;math&gt;E_{i,j}^C&lt;/math&gt; occurs, ''i.e.'' &lt;math&gt;P \langle E_{1,j}^C \cap E_{2,j}^C \cap \cdots \cap E_{m,j}^C \rangle&lt;/math&gt;. This can be restated verbally as: length 1 on clone &lt;math&gt;\alpha&lt;/math&gt; does not match length &lt;math&gt;j&lt;/math&gt; on clone &lt;math&gt;\beta&lt;/math&gt; ''and'' length 2 does not match length &lt;math&gt;j&lt;/math&gt; ''and'' length 3 does not match, etc. Since each of these trials is assumed to be independent, the probability is simply

:&lt;math&gt;P \langle E_{1,j}^C \rangle \times P \langle E_{2,j}^C \rangle \times \cdots \times P \langle E_{m,j}^C \rangle = \left(1 - 2 t / G\right)^m.&lt;/math&gt;

Of course, the actual event of interest is the complement: ''i.e.'' there is ''not'' "no matches". In other words, the probability of one or more matches is &lt;math&gt;p = 1 - \left(1 - 2 t / G\right)^m&lt;/math&gt;. Formally, &lt;math&gt;p&lt;/math&gt; is the probability that at least one band on clone &lt;math&gt;\alpha&lt;/math&gt; matches band &lt;math&gt;j&lt;/math&gt; on clone &lt;math&gt;\beta&lt;/math&gt;.

This event is taken as a [[Bernoulli trial]] having a "success" (matching) probability of &lt;math&gt;p&lt;/math&gt; for band &lt;math&gt;j&lt;/math&gt;. However, we want to describe the process over ''all'' the bands on clone &lt;math&gt;\beta&lt;/math&gt;. Since &lt;math&gt;p&lt;/math&gt; is constant, the number of matches is distributed [[Binomial distribution|binomially]]. Given &lt;math&gt;h&lt;/math&gt; observed matches, the Sulston score &lt;math&gt;S&lt;/math&gt;is simply the probability of obtaining ''at least'' &lt;math&gt;h&lt;/math&gt; matches by chance according to

:&lt;math&gt;S = \sum_{j=h}^n C_{n,j} p^j (1-p)^{n-j},&lt;/math&gt;

where &lt;math&gt;C_{n,j}&lt;/math&gt; are [[binomial coefficient]]s.
|}

==Mathematical refinement==

In a 2005 paper,&lt;ref name=wendl2005&gt;{{cite journal |author=Wendl MC |title=Probabilistic assessment of clone overlaps in DNA fingerprint mapping via a priori models |journal=J Comput Biol. |volume=12 |issue=3 |pages=283–97 |date=Apr 2005 |pmid=15857243 |doi=10.1089/cmb.2005.12.283 }}&lt;/ref&gt; [[Michael Christopher Wendl|Michael Wendl]] gave an example showing that the assumption of independent trials is not valid. So, although the traditional Sulston score does indeed represent a [[probability distribution]], it is not actually the distribution characteristic of the fingerprint problem. Wendl went on to give the general solution for this problem in terms of the [[Bell polynomials]], showing the traditional score overpredicts P-values by orders of magnitude. (P-values are very small in this problem, so we are talking, for example, about probabilities on the order of 10&amp;times;10&lt;sup&gt;&amp;minus;14&lt;/sup&gt; versus 10&amp;times;10&lt;sup&gt;&amp;minus;12&lt;/sup&gt;, the latter Sulston value being 2 orders of magnitude too high.) This solution provides a basis for determining when a problem has sufficient information content to be treated by the probabilistic approach and is also a general solution to the [[Birthday paradox#Generalization to multiple types|birthday problem of 2 types]].

A disadvantage of the exact solution is that its evaluation is computationally intensive and, in fact, is not feasible for comparing large clones.&lt;ref name=wendl2005/&gt; Some fast approximations for this problem have been proposed.&lt;ref name="wendl-2007"&gt;{{cite journal |author=Wendl MC |title=Algebraic correction methods for computational assessment of clone overlaps in DNA fingerprint mapping |journal=BMC Bioinformatics |volume=8 |pages=127 |year=2007 |pmid=17442113 |pmc=1868038 |doi=10.1186/1471-2105-8-127 }}&lt;/ref&gt;

== References ==
{{reflist}}

==See also==
*[http://www.agcol.arizona.edu/software/fpc/ FPC]: a widely used fingerprint mapping program that utilizes the Sulston Score

[[Category:Bioinformatics]]
[[Category:Mathematical and theoretical biology]]</text>
      <sha1>2j72qrhrnhs9kv2oc39af1qgpln2jge</sha1>
    </revision>
  </page>
  <page>
    <title>The Human Use of Human Beings</title>
    <ns>0</ns>
    <id>25309878</id>
    <revision>
      <id>850358349</id>
      <parentid>849845158</parentid>
      <timestamp>2018-07-15T11:29:19Z</timestamp>
      <contributor>
        <username>Gagarine</username>
        <id>11797131</id>
      </contributor>
      <comment>/* What is cybernetics? */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10951">{{no footnotes|date=March 2016}}
{{Infobox book
| name             = The Human Use of Human Beings
| title_orig       = 
| translator       = 
| image            = File:humanusecover.jpg
| caption          = First UK edition
| author           = Norbert Wiener
| country          = 
| language         = English
| series           = 
| subject          = 
| genre            = 
| publisher        = [[Houghton Mifflin]] (US)&lt;br&gt;[[Eyre &amp; Spottiswoode]] (UK)
| pub_date         = 1950
| english_pub_date = 
| media_type       = Book
| pages            = 
| isbn             = 
| oclc             = 
| dewey            = 
}}

'''''The Human Use of Human Beings''''' is a book by [[Norbert Wiener]], the founding thinker of [[cybernetics]] theory and an influential advocate of [[automation]]; it was first published in 1950 and revised in 1954. The text argues for the benefits of automation to society; it analyzes the meaning of productive communication and discusses ways for humans and machines to cooperate, with the potential to amplify human power and release people from the repetitive drudgery of manual labor, in favor of more creative pursuits in [[knowledge worker|knowledge work]] and the arts. The risk that such changes might harm society (through dehumanization or subordination of our species) is explored, and suggestions are offered on how to avoid such risk.

==What is cybernetics?==

The word ''cybernetics'' refers to the theory of message transmission among people and machines. The thesis of the book is that: 

&lt;blockquote&gt;society can only be understood through a study of the messages and the communication facilities which belong to it; and that in the future development of these messages and communication facilities, messages between man and machines, between machines and man, and between machine and machine, are destined to play an ever-increasing part. (p.&amp;nbsp;16)&lt;/blockquote&gt;

[[Communication]] methods have entered a new realm, involving new technologies. Whether a transmission is between people, or between people and machines, the process is similar in that information is sent by one party and received by another, which can send a response. This is a type of [[feedback]]. People, animals, and plants all have the ability to take certain actions in response to their environments; in the same way, machines have feedback systems in order for their performances to be altered or evaluated in accordance with results. In the context of human/machine society, Wiener offers a definition of the [[message]] as: 

&lt;blockquote&gt;"a sequence of events in time which, though in itself has a certain contingency, strives to hold back nature's tendency toward disorder by adjusting its parts to various purposive ends" (p.&amp;nbsp;27).&lt;/blockquote&gt;

==Entropy and negentropy==

The physical world has a "tendency toward disorder." [[Entropy]] (although a broad concept used in somewhat different ways across disciplines) roughly describes the way that isolated systems naturally become less and less organized with the passage of time; popularly understood as meaning a gradual decline into a state of chaos, the concept more accurately refers to the diffusion of energy toward a state of equilibrium, following the [[second law of thermodynamics]].

Wiener believed that communication of information is essentially [[negentropic]] – it resists entropy –, because it relies on organizational structures. There are two kinds of possible disorganizational forces, passive and active:&lt;blockquote&gt;"Nature offers resistance to decoding, but it does not show ingenuity in finding new and undecipherable methods for jamming our communication with the outer world" (pp.&amp;nbsp;35–36).&lt;/blockquote&gt;Nature's passive resistance is in contrast to active resistance, like that of a chess opponent. This is similar to [[Einstein]]'s view, expressed in his famous comment: &lt;blockquote&gt;"The Lord is subtle but he is not vicious".&lt;/blockquote&gt;

==Potential for learning==

An increase of information, whether communicated by a living being or a machine, will increase organization. The feedback systems of an organism and those of a machine (informational organization in machines does not necessarily constitute "vitality" or a "soul") function in a similar way, allowing either to make assessments and act on the actual effectiveness of previous actions; when such feedback modifies not just a discrete action but an entire set of behaviors, Wiener calls this [[learning]].

==Forms and patterns==

The individuality of a being is a certain intricate form, not an enduring substance. In order to understand an organism, it must be thought of as a pattern which maintains itself through [[homeostasis]] – life continues by maintaining an internal balance of various factors such as temperature and molecular structure. While the material substances that compose a living being may be constantly replaced by nearly identical ones, an organism continues functioning with the same identity as long as the pattern is kept sufficiently intact. Since patterns can be transmitted, modified, or duplicated, they are therefore a kind of information. Based on this, Wiener suggests it should be theoretically possible to transmit the entirety of a living person as a message (which is practically indistinguishable from the concept of physical [[teleportation]]) – although he admits that the obstacles to such a process would be great, because of the enormous amount of information embodied in a person, and the difficulty of reading or writing it.

==Science, law, and industry==

According to Wiener, the "progress" of human society as we conceive it today did not exist until four hundred years ago, but now we have entered "a special period in the history of the world" (p.&amp;nbsp;46). The progress of recent centuries has changed our world so dramatically that humans are being forced to adapt to the new environmental order or disorder that we are still creating. Wiener believes the quickness and range of our adaptability has always been the strong point of the human species, which distinguishes us from even the most intelligent of other living creatures. Our advancements in technology have created new opportunities along with new restrictions.

Increasingly better sensory mechanics will allow machines to react to changes in stimuli, and adapt more efficiently to their surroundings. This type of machine will be most useful in factory assembly lines, giving humans the freedom to supervise and use their creative abilities constructively. 

Medicine can benefit from robotic advances in the design of prostheses for the handicapped. Wiener mentions the [[Vocorder]], a device from [[Bell Telephone Company]] that creates visual speech. He discusses the possibility of creating an automated prosthesis that inputs speech directly into the brain for processing, effectively giving deaf individuals the ability to "hear" speech again. Progress in these areas is ongoing and rapid, exemplified by such devices as the [http://www.popsci.com/technology/article/2009-12/new-artificial-larynx-does-away-dreaded-robot-voice palatometer], a new device created to replace a damaged larynx; it uses a speech synthesizer to recreate words based on its ability to monitor tongue movements.  This device effectively rids people with damaged larynxes of the robotic tones associated with artificial speech synthesizers (like the one famously used by disabled physicist [[Stephen Hawking]]), enabling people to have more natural social interactions.

Machines, in Wiener's opinion, are meant to interact harmoniously with humanity and provide respite from the industrial trap we have made for ourselves. Wiener describes the automaton as inherently necessary to humanity's societal evolution. People could be free to expand their minds, pursue artistic careers, while automatons take over assembly line production to create necessary commodities. These machines must be "used for the benefit of man, for increasing his leisure and enriching his spiritual life, rather than merely for profits and the worship of the machine as a new brazen calf" (p.&amp;nbsp;162).

==How can automata harm human society?==

Though hopeful that humanity will ultimately prosper by the use of automatons, he mentions a few ways this relationship with technology could be detrimental. Automatons must not be taken for granted, because with advances in technology that allow them to learn, the machines may be able to escape human control if humans do not continue proper supervision of them. We might become entirely dependent on them, or even controlled by them. There is danger in trusting decisions to something which cannot think abstractly, and may therefore be unlikely to identify with intellectual human values which are not purely utilitarian.

==Importance and influence of the book==

Norbert Wiener's book was the forerunner of studies in cybernetics, and has influenced many theorists. It has impacted the fields of computers and technology, engineering, biology, sociology, and a broad range of other sciences. Numerous books have been published in relation to cybernetics theory which explore alternative concepts and models of feedback, human/machine relationships, systems science, and industrial advancement. [[William Ross Ashby]], another founder of cybernetics, wrote the book ''Introduction to Cybernetics'', which presents many new interpretations and definitions. Other theorists have produced writings on systems, communication, and the human experience in cybernetics. [[N. Katherine Hayles]], author of ''How We Became Posthuman: Virtual Bodies in Cybernetics, Literature, and Informatics'', describes the effects of technology in the age of virtual information and what it means for humans to live in an ever-advancing society. The [[American Society for Cybernetics]] (ASC) is a research association founded in 1964, the same year Wiener died, and is dedicated to the cooperative understanding and further improvement of cybernetics theory.

The Human Use of Human Beings has been translated to French in 1950 as ''Cybernétique et société'' (Paris : 10/18).

== References ==
* [http://www.english.ucla.edu/faculty/hayles/ N. Katherine Hayles]
* [http://www.gwu.edu/~asc/origin.html The Origins of Cybernetics]
* [https://web.archive.org/web/20171004033417/http://english.ucla.edu/faculty/hayles/Flick.html Virtual Bodies and Flickering Signifiers]
* Wiener, Norbert. ''The Human Use of Human Beings: Cybernetics and Society.'' Da Capo Press, 1988. Print.

&lt;!--- See [[Wikipedia:Footnotes]] on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

== External links ==
* [http://www.asc-cybernetics.org/ American Society for Cybernetics] (Official Web Site)

{{DEFAULTSORT:Human Use Of Human Beings}}
[[Category:Cybernetics]]
[[Category:1950 books]]
[[Category:Works about automation]]</text>
      <sha1>t0zd2ucfzhgl18dppxpj37ah32jbov9</sha1>
    </revision>
  </page>
  <page>
    <title>The Lady Tasting Tea</title>
    <ns>0</ns>
    <id>2922561</id>
    <revision>
      <id>858957079</id>
      <parentid>856309136</parentid>
      <timestamp>2018-09-10T19:23:33Z</timestamp>
      <contributor>
        <username>Swpb</username>
        <id>1921264</id>
      </contributor>
      <comment>removed [[Category:History of Statistics]]; added [[Category:History of probability and statistics]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3873">{{Infobox book
| name          = The Lady Tasting Tea
| title_orig    = 
| translator    = 
| image         = The Lady Tasting Tea - David Salsburg.jpg
| caption = 2001 paperback edition
| author        = [[David Salsburg]]
| illustrator   = 
| cover_artist  = 
| country       = USA
| language      = English
| series        = 
| subject       = [[Statistics]]
| genre         = [[History of science and technology]]
| publisher     = [[Henry Holt and Company]]
| pub_date      = 2001
| english_pub_date = 
| media_type    = Print ([[paperback]])
| pages         = 352 pages
| isbn          = 0-8050-7134-2
| oclc          = 
| preceded_by   = [[The Use Of Restricted Significance Tests In Clinical Trials]]
| followed_by   = Love Poems to Fran
}}
'''''The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century''''' ({{ISBN|0-8050-7134-2}}) is a book by [[David Salsburg]] about the history of modern [[statistics]] and the role it played in the development of science and industry.&lt;ref&gt;{{cite web|last=Mehlman|first=Marc H.|title=The Lady Tasting Tea by David Salsburg |work=The MAA Online book review column|publisher=[[The Mathematical Association of America]]|date=2003-03-22|url=http://mathdl.maa.org/mathDL/19/?pa=reviews&amp;sa=viewBook&amp;bookId=68520|accessdate=2013-03-20}}&lt;/ref&gt;&lt;!--&lt;ref&gt;{{cite web|last=Matthews|first=Robert|title=Don't Buy a Lottery Ticket|work=New Scientist|date=2001-05-05|url=http://www.newscientist.com/article/mg17022895.100-dont-buy-a-lottery-ticket.html|accessdate=2009-12-04}}&lt;/ref&gt;--&gt;&lt;ref&gt;{{cite web|last=Morgan|first=Peter|title=The Left Atrium|work=Canadian Medical Association Journal|date=2002-09-17|url=http://www.cmaj.ca/cgi/content/full/167/6/674|accessdate=2009-12-04}}&lt;/ref&gt;&lt;!--&lt;ref&gt;{{cite web|last=Olsen|first=Chris|title=The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century. (Book Reviews)|work=Journal of the American Statistical Association|date=2002-06-01|url=http://www.accessmylibrary.com/coms2/summary_0286-25570221_ITM|accessdate=2009-12-04}}&lt;/ref&gt;&lt;ref&gt;{{cite web|last=Porter|first=Theodore|title=Statistical Tales.(Review)|work=American Scientist|date=2001-09-01|url=http://www.accessmylibrary.com/coms2/summary_0286-27122857_ITM|accessdate=2009-12-04}}&lt;/ref&gt;&lt;ref&gt;{{cite web|title=THE LADY TASTING TEA: How Statistics Revolutionized Science in the Twentieth Century.(Review)(Brief Article)|work=Publishers Weekly|date=2001-04-02|url=http://www.accessmylibrary.com/coms2/summary_0286-10841330_ITM|accessdate=2009-12-04}}&lt;/ref&gt;&lt;ref name="Nature"&gt;{{cite journal|last=Colquhoun|first=David|authorlink=David Colquhoun|date=31 May 2001|title=Still waiting for the revolution (Book Review)|journal=[[Nature (journal)|Nature]]|volume=411|issue=411|pages=524–525|doi=10.1038/35079167|url=http://www.nature.com/nature/journal/v411/n6837/full/411524a0.html|accessdate=2010-07-27}}&lt;/ref&gt;--&gt;

The title comes from the "[[lady tasting tea]]", an example from the famous book, ''[[The Design of Experiments]]'', by [[Ronald A. Fisher]]. Regarding Fisher's example, the statistician [[Debabrata Basu]] wrote that "the famous case of the '[[lady tasting tea]]'" was "one of the two supporting pillars [...] of the randomization analysis of experimental data".&lt;ref&gt;Page 575 in:
* {{cite journal
|doi=10.2307/2287648
|title=Randomization Analysis of Experimental Data: The Fisher Randomization Test
|first=D. 
|last=Basu
|authorlink=Debabrata Basu
|journal=Journal of the American Statistical Association
|volume=75
|issue=371
|date=Sep 1980
|pages=575–582
|jstor = 2287648
}}
&lt;/ref&gt;

==References==
{{reflist}}

==External links==
*[http://us.macmillan.com/theladytastingtea Publisher's web page]

{{DEFAULTSORT:Lady Tasting Tea}}
[[Category:2002 books]]
[[Category:Statistics books]]
[[Category:History of probability and statistics]]
[[Category:Henry Holt and Company books]]</text>
      <sha1>57cbgxf0xtxn3iwf3r9ooo5qsiz4qai</sha1>
    </revision>
  </page>
  <page>
    <title>UML Partners</title>
    <ns>0</ns>
    <id>4510295</id>
    <revision>
      <id>851987993</id>
      <parentid>850119342</parentid>
      <timestamp>2018-07-25T21:31:31Z</timestamp>
      <contributor>
        <username>GreenC bot</username>
        <id>27823944</id>
      </contributor>
      <comment>Rescued 1 archive link; reformat 1 link. [[User:GreenC/WaybackMedic_2.1|Wayback Medic 2.1]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2055">'''UML Partners''' was a consortium of system integrators and vendors convened in 1996 to specify the [[Unified Modeling Language]] (UML).&lt;ref name="uml paper"&gt;
{{cite journal | author=G. Booch | title=UML in Action | journal=Communications of the ACM | year=1999 | volume=42 | issue=10 | pages= 26–28 | doi=10.1145/317665.317672}}&lt;/ref&gt; Initially the consortium was led by [[Grady Booch]], [[Ivar Jacobson]], and [[James Rumbaugh]] of Rational Software. The UML Partners' UML 1.0 specification draft was proposed to the [[Object Management Group]] (OMG) in January 1997. 
During the same month the UML Partners formed a Semantics Task Force, chaired by [[Cris Kobryn]], to finalize the semantics of the specification and integrate it with other standardization efforts. The result of this work, UML 1.1, was submitted to the OMG in August 1997 and adopted by the OMG in November 1997.&lt;ref&gt;[http://www.omg.org/docs/ad/97-08-11.pdf UML Specification v. 1.1 (OMG document ad/97-08-11)]&lt;/ref&gt;

==Member list==
Members of the consortium include:

*[[Digital Equipment Corporation]]
*[[Hewlett-Packard]]
*[[i-Logix]]
*[[IBM]]
*[[ICON Computing]]
*[[IntelliCorp (Software)|IntelliCorp]]
*[[MCI Systemhouse]]
*[[Microsoft]]
*[[ObjecTime]]
*[[Oracle Corporation]]
*[[Platinum Technology]]
*[[Ptech]]
*[[Rational Software]]
*[[Reich Technologies]]
*[[Softeam]]
*[[Taskon]]
*[[Texas Instruments]]
*[[Unisys]]

==See also==
*[[Unified Modeling Language]]
*[[object-oriented language]]

== References ==
&lt;!-- See http://en.wikipedia.org/wiki/Wikpedia:Footnotes for information on how to add references using &lt;ref&gt; tags --&gt;
{{reflist}}

== External links==
*[https://web.archive.org/web/20060221045543/http://www.omg.org/news/pr99/UML_2001_CACM_Oct99_p29-Kobryn.pdf 2001: A Standardization Odyssey] PDF document
*[https://web.archive.org/web/20030430143625/http://etna.int-evry.fr/COURS/UML/summary/summary5.html#5.2 UML 1.0 - 1.1 and the UML partners]

{{UML}}

[[Category:Unified Modeling Language]]
[[Category:Information technology organizations]]


{{uml-stub}}</text>
      <sha1>1u4ojr6sswcw8tbn343mgq315ayokpv</sha1>
    </revision>
  </page>
  <page>
    <title>Unitary perfect number</title>
    <ns>0</ns>
    <id>553027</id>
    <revision>
      <id>787484034</id>
      <parentid>787016875</parentid>
      <timestamp>2017-06-25T17:38:03Z</timestamp>
      <contributor>
        <username>Red Director</username>
        <id>1261736</id>
      </contributor>
      <minor/>
      <comment>/* Examples */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3483">A '''unitary perfect number''' is an [[integer]] which is the sum of its positive proper [[unitary divisor]]s, not including the number itself. (A [[divisor]] ''d'' of a number ''n'' is a unitary divisor if ''d'' and ''n''/''d'' share no common factors.) Some [[perfect number]]s are not unitary perfect numbers, and some unitary perfect numbers are not regular perfect numbers.

==Examples==
[[60 (number)|60]] is a unitary perfect number, because 1, 3, 4, 5, 12, 15, and 20 are its proper unitary divisors, and 1 + 3 + 4 + 5 + 12 + 15 + 20 = 60. The first five, and only known, unitary perfect numbers are:

[[6 (number)|6]], 60, [[90 (number)|90]], 87360, 146361946186458562560000 {{OEIS|id=A002827}}

The respective sums of proper unitary divisors:
* 6 = 1 + 2 + 3
* 60 = 1 + 3 + 4 + 5 + 12 + 15 + 20
* 90 = 1 + 2 + 5 + 9 + 10 + 18 + 45
* 87360 = 1 + 3 + 5 + 7 + 13 + 15 + 21 + 35 + 39 + 64 + 65 + 91 + 105 + 192 + 195 + 273 + 320 + 448 + 455 + 832 + 960 + 1344 + 1365 + 2240 + 2496 + 4160 + 5824 + 6720 + 12480 + 17472 + 29120
* 146361946186458562560000 = 1 + 3 + 7 + 11 + ... 13305631471496232960000 + 20908849455208366080000 + 48787315395486187520000 (4095 divisors in the sum)

==Properties==
There are no odd unitary perfect numbers. This follows since one has 2&lt;sup&gt;''d''*(''n'')&lt;/sup&gt; dividing the sum of the unitary divisors of an odd number (where ''d''*(''n'') is the number of distinct prime divisors of n). One gets this because the sum of all the unitary divisors is a [[multiplicative function]] and one has the sum of the unitary divisors of a power of a [[prime number|prime]] ''p''&lt;sup&gt;''a''&lt;/sup&gt; is ''p''&lt;sup&gt;''a''&lt;/sup&gt; + 1 which is even for all odd primes ''p''. Therefore, an odd unitary perfect number must have only one distinct prime factor, and it is not hard to show that a power of prime cannot be a unitary perfect number, since there are not enough divisors. 

{{unsolved|mathematics|Are there infinitely many unitary perfect numbers?}}
It is not known whether or not there are infinitely many unitary perfect numbers, or indeed whether there are any further examples beyond the five already known.  A sixth such number would have at least nine odd prime factors.&lt;ref name=Wall1988&gt;{{cite journal | last=Wall | first=Charles R. | title=New unitary perfect numbers have at least nine odd components | journal=[[Fibonacci Quarterly]] | volume=26 | number=4 | pages=312–317 | year=1988 | issn=0015-0517 | mr=967649 | zbl=0657.10003 }}&lt;/ref&gt;

== References ==
{{reflist}}
* {{cite book|author=Richard K. Guy|authorlink=Richard K. Guy|title=Unsolved Problems in Number Theory|publisher=[[Springer-Verlag]]|year=2004|isbn=0-387-20860-7 | pages=84–86}}  Section B3.
* {{cite book | title=My Numbers, My Friends: Popular Lectures on Number Theory | authorlink=Paulo Ribenboim | author=Paulo Ribenboim | publisher=Springer-Verlag | year=2000 | isbn=0-387-98911-0 | page=352 }}
* {{cite book | editor1-last=Sándor | editor1-first=József | editor2-last=Mitrinović | editor2-first=Dragoslav S. | editor3-last=Crstici |editor3-first=Borislav | title=Handbook of number theory I | location=Dordrecht | publisher=[[Springer-Verlag]] | year=2006 | isbn=1-4020-4215-9 | zbl=1151.11300 }}
* {{cite book | last1=Sándor | first1=Jozsef | last2=Crstici | first2=Borislav | title=Handbook of number theory II | location=Dordrecht | publisher=Kluwer Academic | year=2004 | isbn=1-4020-2546-7 | zbl=1079.11001 }}

{{Divisor classes}}

[[Category:Integer sequences]]</text>
      <sha1>bwyh0srxu1c37wk7cbwl5fv3iudabsb</sha1>
    </revision>
  </page>
  <page>
    <title>Vizing's theorem</title>
    <ns>0</ns>
    <id>5449464</id>
    <revision>
      <id>840544020</id>
      <parentid>840543234</parentid>
      <timestamp>2018-05-10T15:47:41Z</timestamp>
      <contributor>
        <username>Jonathan Hall</username>
        <id>2284432</id>
      </contributor>
      <comment>Statement - edge colouring. I think this is less likely to be misread (like I did before my previous edit), but I'm happy to be rv'd</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="19062">In [[graph theory]], '''Vizing's theorem''' (named for [[Vadim G. Vizing]] who published it in 1964) states that every simple [[undirected graph]] may be [[edge coloring|edge colored]] using a number of colors that is at most one larger than the maximum [[degree (graph theory)|degree]] {{math|Δ}} of the graph.

At least {{math|Δ}} colors are always necessary, so the undirected graphs may be partitioned into two classes: "class one" graphs for which {{math|Δ}} colors suffice, and "class two" graphs for which {{math|Δ + 1}} colors are necessary.

==Examples==
When {{math|1=Δ = 1}}, the graph {{mvar|G}} must itself be a matching, with no two edges adjacent, and its edge chromatic number is one. That is, all graphs with {{math|1=Δ(''G'') = 1}} are of class one.

When {{math|1=Δ = 2}}, the graph {{mvar|G}} must be a [[disjoint union]] of [[path (graph theory)|paths]] and [[cycle (graph theory)|cycles]]. If all cycles are even, they can be 2-edge-colored by alternating the two colors around each cycle. However, if there exists at least one odd cycle, then no 2-edge-coloring is possible. That is, a graph with {{math|1=Δ = 2}} is of class one if and only if it is [[bipartite graph|bipartite]].

[[Multigraph]]s do not in general obey Vizing's theorem. For instance, the multigraph formed by doubling each edge of a triangle has maximum degree four but cannot be edge-colored with fewer than six colors.

==Proof==
This proof is inspired by {{harvtxt|Diestel|2000}}.

Let {{math|1=''G''&amp;nbsp;=&amp;nbsp;(''V'',&amp;nbsp;''E'')}} be a simple undirected graph. We proceed by induction on {{math|''m''}}, the number of edges. If the graph is empty, the theorem trivially holds. Let {{math|''m''&amp;nbsp;&gt;&amp;nbsp;0}} and suppose a proper {{math|(Δ+1)}}-edge-coloring exists for all {{math|''G''&amp;nbsp;&amp;minus;&amp;nbsp;''xy''}} where {{math|''xy''&amp;nbsp;&amp;isin;&amp;nbsp;''E''}}.

We say that color {{math|&amp;alpha;&amp;nbsp;&amp;isin;&amp;nbsp;{1,...,Δ+1}}} is missing in {{math|''x''&amp;nbsp;&amp;isin;&amp;nbsp;''V''}} with respect to proper {{math|(Δ+1)}}-edge-coloring {{math|''c''}} if {{math|''c''(''xy'')&amp;nbsp;&amp;ne;&amp;nbsp;&amp;alpha;}} for all {{math|''y''&amp;nbsp;&amp;isin;&amp;nbsp;N(''x'')}}. Also, let {{math|&amp;alpha;/&amp;beta;}}-path from {{math|''x''}} denote the unique maximal path starting in {{math|''x''}} with {{math|&amp;alpha;}}-colored edge and alternating the colors of edges (the second edge has color {{math|&amp;beta;}}, the third edge has color {{math|&amp;alpha;}} and so on), its length can be {{math|0}}. Note that if {{math|''c''}} is a proper {{math|(Δ+1)}}-edge-coloring of {{math|''G''}} then every vertex has a missing color with respect to {{math|''c''}}.

Suppose that no proper {{math|(Δ+1)}}-edge-coloring of {{math|''G''}} exists. This is equivalent to this statement:
:(1) Let {{math|''xy''&amp;nbsp;&amp;isin;&amp;nbsp;''E''}} and {{math|''c''}} be arbitrary proper {{math|(Δ+1)}}-edge-coloring of {{math|''G''&amp;nbsp;&amp;minus;&amp;nbsp;''xy''}} and {{math|&amp;alpha;}} be missing from {{math|''x''}} and {{math|&amp;beta;}} be missing from {{math|''y''}} with respect to {{math|''c''}}. Then the {{math|&amp;alpha;/&amp;beta;}}-path from {{math|''y''}} ends in {{math|''x''}}.

This is equivalent, because if (1) doesn't hold, then we can interchange the colors {{math|&amp;alpha;}} and {{math|&amp;beta;}} on the {{math|&amp;alpha;/&amp;beta;}}-path and set the color of {{math|''xy''}} to be {{math|&amp;alpha;}}, thus creating a proper {{math|(Δ+1)}}-edge-coloring of {{math|''G''}} from {{math|''c''}}. The other way around, if a proper {{math|(Δ+1)}}-edge-coloring exists, then we can delete an edge, restrict the coloring and (1) won't hold either.

Now, let {{math|''xy''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;&amp;isin;&amp;nbsp;''E''}} and {{math|''c''&lt;sub&gt;0&lt;/sub&gt;}} be a proper {{math|(Δ+1)}}-edge-coloring of {{math|''G''&amp;nbsp;&amp;minus;&amp;nbsp;''xy''&lt;sub&gt;0&lt;/sub&gt;}} and {{math|&amp;alpha;}} be missing in {{math|''x''}} with respect to {{math|''c''&lt;sub&gt;0&lt;/sub&gt;}}. We define {{math|''y''&lt;sub&gt;0&lt;/sub&gt;,...,''y''&lt;sub&gt;''k''&lt;/sub&gt;}} to be a maximal sequence of neighbours of {{math|''x''}} such that {{math|''c''&lt;sub&gt;0&lt;/sub&gt;(''xy''&lt;sub&gt;''i''&lt;/sub&gt;)}} is missing in {{math|''y''&lt;sub&gt;''i''&amp;minus;1&lt;/sub&gt;}} with respect to {{math|''c''&lt;sub&gt;0&lt;/sub&gt;}} for all {{math|0&amp;nbsp;&lt;&amp;nbsp;''i''&amp;nbsp;&amp;le;&amp;nbsp;''k''}}.

We define coloring {{math|''c''&lt;sub&gt;1&lt;/sub&gt;,...,''c''&lt;sub&gt;''k''&lt;/sub&gt;}} as
:{{math|''c''&lt;sub&gt;''i''&lt;/sub&gt;(''xy''&lt;sub&gt;''j''&lt;/sub&gt;){{=}}''c''&lt;sub&gt;0&lt;/sub&gt;(''xy''&lt;sub&gt;''j''+1&lt;/sub&gt;)}} for all {{math|0&amp;nbsp;&amp;le;&amp;nbsp;''j''&amp;nbsp;&lt;&amp;nbsp;''i''}},
:{{math|''c''&lt;sub&gt;''i''&lt;/sub&gt;(''xy''&lt;sub&gt;''i''&lt;/sub&gt;)}} not defined,
:{{math|''c''&lt;sub&gt;''i''&lt;/sub&gt;(''e''){{=}}''c''&lt;sub&gt;0&lt;/sub&gt;(''e'')}} otherwise.

Then {{math|''c''&lt;sub&gt;''i''&lt;/sub&gt;}} is a proper {{math|(Δ+1)}}-edge-coloring of {{math|''G''&amp;nbsp;&amp;minus;&amp;nbsp;''xy''&lt;sub&gt;''i''&lt;/sub&gt;}} due to definition of {{math|''y''&lt;sub&gt;0&lt;/sub&gt;,...,''y''&lt;sub&gt;''k''&lt;/sub&gt;}}. Also, note that the missing colors in {{math|''x''}} are the same with respect to {{math|''c''&lt;sub&gt;''i''&lt;/sub&gt;}} for all {{math|0&amp;nbsp;&amp;le;&amp;nbsp;''i''&amp;nbsp;&amp;le;&amp;nbsp;''k''}}.

Let {{math|&amp;beta;}} be the color missing in {{math|''y''&lt;sub&gt;''k''&lt;/sub&gt;}} with respect to {{math|''c''&lt;sub&gt;0&lt;/sub&gt;}}, then {{math|&amp;beta;}} is also missing in {{math|''y''&lt;sub&gt;''k''&lt;/sub&gt;}} with respect to {{math|''c''&lt;sub&gt;''i''&lt;/sub&gt;}} for all {{math|0&amp;nbsp;&amp;le;&amp;nbsp;''i''&amp;nbsp;&amp;le;&amp;nbsp;''k''}}. Note that {{math|&amp;beta;}} cannot be missing in {{math|''x''}}, otherwise we could easily extend {{math|''c''&lt;sub&gt;''k''&lt;/sub&gt;}}, therefore an edge with color {{math|&amp;beta;}} is incident to {{math|''x''}} for all {{math|''c''&lt;sub&gt;''j''&lt;/sub&gt;}}. From the maximality of {{math|''k''}}, there exists {{math|1&amp;nbsp;&amp;le;&amp;nbsp;''i''&amp;nbsp;&lt;&amp;nbsp;''k''}} such that {{math|''c''&lt;sub&gt;0&lt;/sub&gt;(''xy''&lt;sub&gt;''i''&lt;/sub&gt;)&amp;nbsp;{{=}}&amp;nbsp;&amp;beta;}}. From the definition of {{math|''c''&lt;sub&gt;1&lt;/sub&gt;,...,''c''&lt;sub&gt;''k''&lt;/sub&gt;}} this holds: 
:{{math|''c''&lt;sub&gt;0&lt;/sub&gt;(''xy''&lt;sub&gt;''i''&lt;/sub&gt;)&amp;nbsp;{{=}}&amp;nbsp;''c''&lt;sub&gt;''i''&amp;minus;1&lt;/sub&gt;(''xy''&lt;sub&gt;''i''&lt;/sub&gt;)&amp;nbsp;{{=}}&amp;nbsp;''c''&lt;sub&gt;''k''&lt;/sub&gt;(''xy''&lt;sub&gt;''i''&amp;minus;1&lt;/sub&gt;)&amp;nbsp;{{=}}&amp;nbsp;&amp;beta;}}

Let {{math|''P''}} be the {{math|&amp;alpha;/&amp;beta;}}-path from {{math|''y''&lt;sub&gt;''k''&lt;/sub&gt;}} with respect to {{math|''c''&lt;sub&gt;''k''&lt;/sub&gt;}}. From (1), {{math|''P''}} has to end in {{math|''x''}}. But {{math|&amp;alpha;}} is missing in {{math|''x''}}, so it has to end with an edge of color {{math|&amp;beta;}}. Therefore, the last edge of {{math|''P''}} is {{math|''y''&lt;sub&gt;''i''&amp;minus;1&lt;/sub&gt;''x''}}. Now, let {{math|''P' ''}} be the {{math|&amp;alpha;/&amp;beta;}}-path from {{math|''y''&lt;sub&gt;''i''&amp;minus;1&lt;/sub&gt;}} with respect to {{math|''c''&lt;sub&gt;''i''&amp;minus;1&lt;/sub&gt;}}. Since {{math|''P' ''}} is uniquely determined and the inner edges of {{math|''P''}} are not changed in {{math|''c''&lt;sub&gt;0&lt;/sub&gt;,...,''c''&lt;sub&gt;''k''&lt;/sub&gt;}}, the path {{math|''P' ''}} uses the same edges as {{math|''P''}} in reverse order and visits {{math|''y''&lt;sub&gt;''k''&lt;/sub&gt;}}. The edge leading to {{math|''y''&lt;sub&gt;''k''&lt;/sub&gt;}} clearly has color {{math|&amp;alpha;}}. But {{math|&amp;beta;}} is missing in {{math|''y''&lt;sub&gt;''k''&lt;/sub&gt;}}, so {{math|''P' ''}} ends in {{math|''y''&lt;sub&gt;''k''&lt;/sub&gt;}}. Which is a contradiction with (1) above.

==Classification of graphs==
Several authors have provided additional conditions that classify some graphs as being of class one or class two, but do not provide a complete classification. For instance, if the vertices of the maximum degree {{math|Δ}} in a graph {{mvar|G}} form an [[Independent set (graph theory)|independent set]], or more generally if the [[induced subgraph]] for this set of vertices is a forest, then {{mvar|G}} must be of class one.&lt;ref&gt;{{harvtxt|Fournier|1973}}.&lt;/ref&gt;

{{harvtxt|Erdős|Wilson|1977}} showed that [[almost all]] graphs are of class one. That is, in the [[Erdős–Rényi model]] of random graphs, in which all {{mvar|n}}-vertex graphs are equally likely, let {{math|''p''(''n'')}} be the probability that an {{mvar|n}}-vertex graph drawn from this distribution is of class one; then {{math|''p''(''n'')}} approaches one in the limit as {{mvar|n}} goes to infinity. For more precise bounds on the rate at which {{math|''p''(''n'')}} converges to one, see {{harvtxt|Frieze|Jackson|McDiarmid|Reed|1988}}.

==Planar graphs==
{{harvtxt|Vizing|1965}} showed that a [[planar graph]] is of class one if its maximum degree is at least eight.
In contrast, he observed that for any maximum degree in the range from two to five, there exist
planar graphs of class two.  For degree two, any odd cycle is such a graph, and for degree three, four, and five, these graphs can be constructed from [[platonic solid]]s by replacing a single edge by a path of two adjacent edges.

In '''Vizing's planar graph conjecture''', {{harvtxt|Vizing|1965}} states that all simple, planar graphs with maximum degree six or seven are of class one, closing the remaining possible cases.
{{harvtxt|Sanders|Zhao|2001}} partially proved Vizing's planar graph conjecture by showing that all planar graphs with maximum degree seven are of class one.
Thus, the only case of the conjecture that remains unsolved is that of maximum degree six. This conjecture has implications for the [[Total coloring|total coloring conjecture]].

The planar graphs of class two constructed by subdivision of the platonic solids are not regular: they have vertices of degree two as well as vertices of higher degree.
The [[four color theorem]] (proved by {{harvtxt|Appel|Haken|1976}}) on vertex coloring of planar graphs, is equivalent to the statement that every bridgeless 3-regular planar graph is of class one {{harv|Tait|1880}}.

==Graphs on nonplanar surfaces==
In 1969, [[Branko Grünbaum]] conjectured that every 3-regular graph with a polyhedral embedding on any two-dimensional [[oriented manifold]] such as a [[torus]] must be of class one. In this context, a polyhedral embedding is a [[graph embedding]] such that every face of the embedding is topologically a disk and such that the [[dual graph]] of the embedding is simple, with no self-loops or multiple adjacencies. If true, this would be a generalization of the four color theorem, which was shown by Tait to be equivalent to the statement that  3-regular graphs with a polyhedral embedding on a [[sphere]] are of class one. However, {{harvtxt|Kochol|2009}} showed the conjecture to be false by finding [[Snark (graph theory)|snarks]] that have polyhedral embeddings on high-genus orientable surfaces. Based on this construction, he also showed that it is NP-complete to tell whether a polyhedrally embedded graph is of class one.&lt;ref&gt;{{harvtxt|Kochol|2010}}.&lt;/ref&gt;

==Algorithms==
{{harvtxt|Misra|Gries|1992}} describe a polynomial time algorithm for coloring the edges of any graph with {{math|Δ + 1}} colors, where {{math|Δ}} is the maximum degree of the graph. That is, the algorithm uses the optimal number of colors for graphs of class two, and uses at most one more color than necessary for all graphs. Their algorithm follows the same strategy as Vizing's original proof of his theorem: it starts with an uncolored graph, and then repeatedly finds a way of recoloring the graph in order to increase the number of colored edges by one.

More specifically, suppose that {{math|''uv''}} is an uncolored edge in a partially colored graph. The algorithm of Misra and Gries may be interpreted as constructing a directed [[pseudoforest]] {{mvar|P}} (a graph in which each vertex has at most one outgoing edge) on the neighbors of {{mvar|u}}: for each neighbor {{mvar|p}} of {{mvar|u}}, the algorithm finds a color {{mvar|c}} that is not used by any of the edges incident to {{mvar|p}}, finds the vertex {{mvar|q}} (if it exists) for which edge {{mvar|uq}} has color {{mvar|c}}, and adds {{mvar|pq}} as an edge to {{mvar|P}}. There are two cases:
*If the pseudoforest {{mvar|P}} constructed in this way contains a path from {{mvar|v}} to a vertex {{mvar|w}} that has no outgoing edges in {{mvar|P}}, then there is a color {{mvar|c}} that is available both at {{mvar|u}} and {{mvar|w}}. Recoloring edge {{mvar|uw}} with color {{mvar|c}} allows the remaining edge colors to be shifted one step along this path: for each vertex {{mvar|p}} in the path, edge {{mvar|up}} takes the color that was previously used by the successor of {{mvar|p}} in the path. This leads to a new coloring that includes edge {{mvar|uv}}.
*If, on the other hand, the path starting from {{mvar|v}} in the pseudoforest {{mvar|P}} leads to a cycle, let {{mvar|w}} be the neighbor of {{mvar|u}} at which the path joins the cycle, let {{mvar|c}} be the color of edge {{mvar|uw}}, and let {{mvar|d}} be a color that is not used by any of the edges at vertex {{mvar|u}}. Then swapping colors {{mvar|c}} and {{mvar|d}} on a [[Kempe chain]] either breaks the cycle or the edge on which the path joins the cycle, leading to the previous case.
With some simple data structures to keep track of the colors that are used and available at each vertex, the construction of {{mvar|P}} and the recoloring steps of the algorithm can all be implemented in time {{math|O(''n'')}}, where {{mvar|n}} is the number of vertices in the input graph. Since these steps need to be repeated {{mvar|m}} times, with each repetition increasing the number of colored edges by one, the total time is {{math|O(''mn'')}}.

In an unpublished technical report, {{harvtxt|Gabow|Nishizeki|Kariv|Leven|1985}} claimed a faster &lt;math&gt;O(m\sqrt n\log n)&lt;/math&gt; time bound for the same problem of coloring with  {{math|Δ + 1}} colors.

==History==
In both {{harvtxt|Gutin|Toft|2000}} and {{harvtxt|Soifer|2008}}, Vizing mentions that his work was motivated by a theorem of {{harvtxt|Shannon|1949}} showing that multigraphs could be colored with at most {{math|(3/2)Δ}} colors. Although Vizing's theorem is now standard material in many graph theory textbooks, Vizing had trouble publishing the result initially, and his paper on it appears in an obscure journal, ''Diskret. Analiz''.&lt;ref&gt;The full name of this journal was ''Akademiya Nauk SSSR. Sibirskoe Otdelenie. Institut Matematiki. Diskretny˘ı Analiz. Sbornik Trudov''. It was renamed ''Metody Diskretnogo Analiza'' in 1980 (the name given for it in {{harvtxt|Gutin|Toft|2000}}) and discontinued in 1991 [http://www.ams.org/mathscinet/search/journaldoc.html?jc=DISKA].&lt;/ref&gt;

==See also==
*[[Brooks' theorem]] relating vertex colorings to maximum degree

==Notes==
{{reflist}}

==References==
*{{citation
 | last1 = Appel | first1 = K. | author1-link = Kenneth Appel
 | last2 = Haken | first2 = W. | author2-link = Wolfgang Haken
 | doi = 10.1090/S0002-9904-1976-14122-5
 | issue = 5
 | journal = Bulletin of the American Mathematical Society
 | mr = 0424602
 | pages = 711–712
 | title = Every planar map is four colorable
 | volume = 82
 | year = 1976}}.
*{{Citation | last1=Diestel | first1=Reinhard | title=Graph Theory | pages=103–104| url=http://www.esi2.us.es/~mbilbao/pdffiles/DiestelGT.pdf | publisher=Springer-Verlag | location=Berlin, New York | year=2000 }}.
*{{citation
 | last1 = Erdős | first1 = Paul | authorlink1 = Paul Erdős
 | last2 = Wilson | first2 = Robin J.
 | year = 1977
 | title = Note on the chromatic index of almost all graphs
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | volume = 23
 | pages = 255–257
 | url = http://www.renyi.hu/~p_erdos/1977-20.pdf
 | doi = 10.1016/0095-8956(77)90039-9
 | issue = 2–3}}.
*{{citation
 | last = Fournier | first = Jean-Claude
 | journal = Cahiers du Centre d'Études de Recherche Opérationnelle
 | mr = 0349458
 | pages = 311–314
 | title = Colorations des arêtes d'un graphe
 | volume = 15
 | year = 1973}}.
*{{citation
 | last1 = Frieze | first1 = Alan M. | author1-link = Alan M. Frieze
 | last2 = Jackson | first2 = B.
 | last3 = McDiarmid | first3 = C. J. H.
 | last4 = Reed | first4 = B. | author4-link = Bruce Reed (mathematician)
 | doi = 10.1016/0095-8956(88)90065-2
 | issue = 2
 | journal = [[Journal of Combinatorial Theory]] | series = Series B
 | mr = 961145
 | pages = 135–149
 | title = Edge-colouring random graphs
 | volume = 45
 | year = 1988}}.
*{{citation
 | last1 = Gabow | first1 = Harold N.
 | last2 = Nishizeki | first2 = Takao | author2-link = Takao Nishizeki
 | last3 = Kariv | first3 = Oded
 | last4 = Leven | first4 = Daniel
 | last5 = Terada | first5 = Osamu
 | publisher = Tohoku University
 | series = Tech. Report TRECIS-8501
 | title = Algorithms for edge-coloring graphs
 | year = 1985}}.
*{{citation|first1=Gregory|last1=Gutin|first2=Bjarne|last2=Toft|title=Interview with Vadim G. Vizing|journal=European Mathematical Society Newsletter|volume=38|date=December 2000|pages=22–23|url=http://www.emis.de/newsletter/newsletter38.pdf}}.
*{{citation
 | last = Kochol | first = Martin
 | contribution = Polyhedral embeddings of snarks in orientable surfaces
 | pages = 1613–1619
 | volume = 137 
 | title = Proceedings of the American Mathematical Society 
 | year = 2009}}.
*{{citation
 | last = Kochol | first = Martin
 | doi = 10.1016/j.dam.2010.06.019
 | issue = 16
 | journal = Discrete Applied Mathematics
 | mr = 2679785
 | pages = 1856–1860
 | title = Complexity of 3-edge-coloring in the class of cubic graphs with a polyhedral embedding in an orientable surface
 | volume = 158
 | year = 2010}}.
*{{citation
 | last1 = Misra | first1 = J.
 | last2 = Gries | first2 = David | author2-link = David Gries
 | doi = 10.1016/0020-0190(92)90041-S
 | issue = 3
 | journal = [[Information Processing Letters]]
 | pages = 131–133
 | title = A constructive proof of Vizing's Theorem
 | volume = 41
 | year = 1992}}.
*{{citation
 | authorlink = Daniel P. Sanders | last1 = Sanders | first1 = Daniel P. | last2 = Zhao | first2 = Yue | year = 2001
 | title = Planar graphs of maximum degree seven are class I
 | journal = [[Journal of Combinatorial Theory]] | series = Series B | volume = 83 | issue = 2 | pages = 201–212
 | doi = 10.1006/jctb.2001.2047}}.
*{{citation
 | last = Shannon | first = Claude E. | authorlink = Claude Shannon
 | title = A theorem on coloring the lines of a network | mr = 0030203
 | journal = J. Math. Physics | volume = 28 | year = 1949 | pages = 148–151}}.
*{{citation|first=Alexander|last=Soifer|year=2008|title=The Mathematical Coloring Book|publisher=Springer-Verlag|isbn=978-0-387-74640-1|pages=136–137}}.
*{{Citation | authorlink=Peter Guthrie Tait|first=P. G.|last= Tait| title=Remarks on the colourings of maps| journal=Proc. R. Soc. Edinburgh| volume=10| year=1880| pages=729}}.
*{{citation
 | last = Vizing | first = V. G. | year = 1964 | authorlink = Vadim G. Vizing
 | title = On an estimate of the chromatic class of a ''p''-graph | mr = 0180505
 | journal = Diskret. Analiz. | volume = 3 | pages = 25–30}}.
*{{citation
 | last = Vizing | first = V. G. | year = 1965 | authorlink = Vadim G. Vizing
 | title = Critical graphs with given chromatic class
 | journal = Metody Diskret. Analiz. | volume = 5 | pages = 9–17}}. (In Russian.)

==External links==
* [http://planetmath.org/?op=getobj&amp;from=objects&amp;id=6932 Proof of Vizing's theorem] at [[PlanetMath]].

[[Category:Graph coloring]]
[[Category:Theorems in graph theory]]</text>
      <sha1>pk3x16n9xudgr5mk8n791zgybjjsypa</sha1>
    </revision>
  </page>
  <page>
    <title>Wedge (symbol)</title>
    <ns>0</ns>
    <id>37702563</id>
    <revision>
      <id>850336445</id>
      <parentid>831907541</parentid>
      <timestamp>2018-07-15T06:50:26Z</timestamp>
      <contributor>
        <username>Beland</username>
        <id>57939</id>
      </contributor>
      <comment>italics</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1149">'''Wedge''' ('''∧''') is a [[symbol]] that looks similar to an in-line [[caret]] (^). It is used to represent various [[ operation (mathematics)|operations]]. In [[Unicode]], the symbol is encoded {{unichar|2227|Logical and|html=}} and by &lt;code&gt;\wedge&lt;/code&gt; and &lt;code&gt;\land&lt;/code&gt; in [[TeX]]. The opposite symbol (∨) is called a [[Vel (symbol)|vel]], or sometimes a (descending) wedge. Some authors who call the descending wedge ''vel'' often call the ascending wedge ''ac'' (the corresponding Latin word for "and", also spelled "atque"), keeping their usage parallel.

== Use ==
Wedge is used to represent various [[ operation (mathematics)|operations]]:
* [[Logical conjunction]] in [[propositional calculus|propositional logic]]
* [[Join and meet|Meet]] in [[lattice (order)|lattice theory]]
* [[Exterior algebra|Exterior product]] or wedge product in [[differential geometry]]

==See also==
{{wiktionary|Wedge|wedge|∧}}
*[[Turned v]]
*[[Vel (symbol)]]
*[[List of mathematical symbols]]
*[[List of logic symbols]]
* [[Wedge (disambiguation)]]
* [[/\ (disambiguation)]]

{{Common logical symbols}}

{{math-stub}}

[[Category:Logic symbols]]</text>
      <sha1>t2zyz0zo525xgi8qr8yuvww25ppto8m</sha1>
    </revision>
  </page>
  <page>
    <title>Wolfram Mathematica</title>
    <ns>0</ns>
    <id>49024</id>
    <revision>
      <id>869222140</id>
      <parentid>862833291</parentid>
      <timestamp>2018-11-17T05:28:27Z</timestamp>
      <contributor>
        <ip>70.51.45.46</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36401">{{For|the programming language used in this program|Wolfram Language|Mathematica (disambiguation)}}
{{Infobox software
| name                   = Wolfram Mathematica
| logo                   = Mathematica Logo.svg
| screenshot             = Mathematica logistic bifurcation.png
| screenshot alt         = A computer display showing in the upper half programming source code, and in the lower half a graph of four branching bifurcating chaotic functions&lt;!-- This description is for sightless laypersons. Please do not turn it into incomprehensible jargon. --&gt;
| caption                = Mathematica 8.0.0 [[Linux]] frontend
| author                 = 
| developer              = [[Wolfram Research]]
| released               = {{Start date and age|1988|06|23}}&lt;ref&gt;{{citation|title=Mathematica Turns 20 Today|first=Stephen|last=Wolfram|url=http://blog.wolfram.com/2008/06/23/mathematica-turns-20-today/|date=23 Jun 2008|publisher=Wolfram|access-date=16 May 2012}}&lt;/ref&gt;
| latest release version = {{Latest stable software release/Mathematica}}
| latest release date    = {{Start date and age|2018|03|08}}
| latest preview version = 
| latest preview date    = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| status                 = 
| programming language   = [[Wolfram Language]],&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2013/06/23/celebrating-mathematicas-first-quarter-century/|title=Celebrating Mathematica’s First Quarter Century|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [[C (programming language)|C]]/[[C++]], [[Java (programming language)|Java]]&lt;ref&gt;[http://reference.wolfram.com/legacy/v9/tutorial/TheSoftwareEngineeringOfMathematica.html The Software Engineering of Mathematica—Wolfram Mathematica 9 Documentation]. Reference.wolfram.com. Retrieved on 2015-03-23.&lt;/ref&gt;
| operating system       = 
| platform               = [[Microsoft Windows|Windows]] (7, 8, 10), [[macOS]], [[Linux]], [[Raspberry Pi|Raspbian]], online service.&lt;ref&gt;[https://www.theverge.com/2013/11/21/5130394/raspberry-pi-includes-mathematica-wolfram-language-free Raspberry Pi Includes Mathematica for Free] The Verge&lt;/ref&gt; All platforms support 64-bit implementations.&lt;ref&gt;{{cite web|url=http://www.wolfram.com/products/mathematica/platforms/|title=Wolfram Mathematica|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [http://www.wolfram.com/mathematica/system-requirements.html (list)]
| size                   = 
| language               = English, Chinese, Japanese
| language count         = &lt;!-- DO NOT include this parameter unless you know what it does --&gt;
| language footnote      = 
| genre                  = [[Computer algebra system|Computer algebra]], [[List of numerical analysis software|numerical computations]], [[information visualization]], [[List of statistical packages|statistics]], [[Graphical user interface|user interface creation]]
| license                = [[Proprietary software|Proprietary]]
| alexa                  = 
| website                = {{URL|www.wolfram.com/mathematica}}
| standard               = 
| AsOf                   = 
}}
'''Wolfram Mathematica''' (usually termed '''Mathematica''') is a modern technical computing system spanning most areas of technical computing — including [[Artificial neural network|neural networks]], [[machine learning]], [[Digital image processing|image processing]], [[geometry]], [[data science]], [[Visualization (graphics)|visualizations]], and others. The system is used in many technical, scientific, engineering, mathematical, and computing fields. It was conceived by [[Stephen Wolfram]] and is developed by [[Wolfram Research]] of [[Champaign, Illinois]].&lt;ref&gt;[http://www.businessweek.com/magazine/content/05_40/b3953024.htm Stephen Wolfram: Simple Solutions; The iconoclastic physicist's Mathematica software nails complex puzzles], BusinessWeek, October 3, 2005.&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.wolfram.com/company/contact.cgi|title=Contact Wolfram Research|publisher=|access-date=11 August 2015}}&lt;/ref&gt; The [[Wolfram Language]] is the programming language used in Mathematica.&lt;ref&gt;{{cite web|url=http://www.slate.com/articles/technology/bitwise/2014/03/stephen_wolfram_s_new_programming_language_can_he_make_the_world_computable.html|title=Stephen Wolfram’s new programming language: Can he make the world computable?|work=Slate Magazine|access-date=11 August 2015}}&lt;/ref&gt;

__TOC__

== Features ==
[[Image:Mathematica dinis surface.png|thumb|325px|[[Dini's surface]] plotted with adjustable parameters]]
Features of Wolfram Mathematica include:&lt;ref&gt;{{cite web|url=http://reference.wolfram.com|title=Wolfram Language &amp; System Documentation Center|publisher=|access-date=11 August 2015}}&lt;/ref&gt;
*Libraries of mathematical [[elementary function]]s and [[special functions]] 
*Support for [[complex number]], [[arbitrary precision arithmetic]], interval arithmetic, and symbolic computation
*Matrix and data manipulation tools including support for [[sparse array]]s
*2D and 3D data, function and geo [[Visualization (graphic)|visualization]] and animation tools
*Solvers for systems of equations, [[diophantine equation]]s, [[ordinary differential equation]]s (ODEs), [[partial differential equation]]s (PDEs), [[differential algebraic equation]]s (DAEs), [[delay differential equation]]s (DDEs), [[stochastic differential equation]]s (SDEs), and [[recurrence relation]]s
*Finite element analysis including 2D and 3D adaptive mesh generation
*Numeric and symbolic tools for discrete and continuous calculus including continuous and discrete [[integral transform]]s
*Constrained and unconstrained local and global [[Optimization (mathematics)|optimization]]
*Multivariate [[statistics]] libraries including fitting, hypothesis testing, and probability and expectation calculations on over 160 distributions.
*Support for [[Censoring (statistics)|censored]] data, temporal data, [[time series]], and unit based data
*Calculations and simulations on random processes and queues
*[[Supervised learning|Supervised]] and [[Unsupervised learning|unsupervised]] [[machine learning]] tools for data, images and sounds including [[artificial neural network]]s
*Tools for [[text mining]] including regular expressions and semantic analysis
*[[Data mining]] tools such as [[cluster analysis]], [[sequence alignment]] and [[pattern matching]]
*Computational geometry in 2D, 3D and higher dimensions
*Libraries for signal processing including [[wavelet]] analysis on sounds, images and data
*Linear and non-linear [[control system]] libraries
*Tools for 2D and 3D [[image processing]]&lt;ref&gt;[http://www.macworld.com/article/138219/mathematica_7.html Review: Mathematica 7. Technical computing powerhouse gets more oomph] Macworld, Jan 2009&lt;/ref&gt; and [[morphological image processing]] including [[image recognition]]
*Presenter tools for generating professional presentations that allow for code to be executed directly within the notebook environment.
*Tools for visualizing and analysing directed and undirected [[Graph (discrete mathematics)|graphs]]
*Tools for combinatoric problems
*[[Number theory]] function library
*Tools for financial calculations including bonds, annuities, derivatives, options etc.
*[[Group theory]] and symbolic [[tensor]] functions
* Tools for [[Automated theorem proving]]
* Tools for [[Systems modeling]] including generation and execution of [[Modelica]] models.
*Import and export filters for data, images, video, sound, [[computer-aided design]] (CAD), [[geographic information system]]s (GIS),&lt;ref&gt;[http://www.cadalyst.com/general-software/mathematica-6-cadalyst-labs-review-6299 Mathematica 6 Labs Review] Cadalyst Feb 1, 2008&lt;/ref&gt; document and biomedical formats
*Database collection for mathematical, scientific, and socio-economic information and access to [[Wolfram Alpha]] data and computations
*Technical word processing including [[formula editor]] and automated report generator
*Programming language supporting [[Procedural programming|procedural]], [[Functional programming|functional]], [[Object-oriented programming|object-oriented]] constructs and parallel programming
*Toolkit for adding [[user interface]]s to calculations and applications
*Tools for creating and deploying cloud based computational applications and services
*Tools to connect to [[dynamic-link library]] (DLL), Structured Query Language ([[SQL]]), [[Java (software platform)|Java]], [[.NET Framework|.NET]], [[C++]], [[Fortran]], [[CUDA]], [[OpenCL]], and [[Hypertext Transfer Protocol]] (HTTP) based systems
*Using both "''free-form linguistic input''" (a [[natural language user interface]])&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2010/11/15/the-free-form-linguistics-revolution-in-mathematica/|title=The Free-Form Linguistics Revolution in Mathematica|publisher=|access-date=11 August 2015}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.wolfram.com/mathematica/new-in-8/free-form-linguistic-input/|title=Free-Form Linguistic Input|publisher=|access-date=11 August 2015}}&lt;/ref&gt; and Wolfram Language in notebook when connected to the Internet

== The Notebook interface ==
Wolfram Mathematica is split into two parts, the kernel and the [[Front and back ends|front end]]. The kernel interprets expressions (Wolfram Language code) and returns result expressions.

The front end, designed by [[Theodore Gray]]&lt;ref&gt;[https://www.google.com/patents/US8407580 Patent US8407580] Google Patent Search&lt;/ref&gt; in 1988, provides a [[GUI]], which allows the creation and editing of [[Notebook interface|Notebook documents]]&lt;ref&gt;{{Cite news|url=http://bit-player.org/wp-content/extras/bph-publications/Pixel-1990-01-Hayes-Mathematica.pdf|title=Thoughts on Mathematica|last=Hayes|first=Brian|date=1990-01-01|work=Pixel|access-date=|via=}}&lt;/ref&gt; containing program code with [[prettyprint]]ing, formatted text together with results including [[Formula editor|typeset mathematics]], graphics, GUI components, tables, and sounds. All content and formatting can be generated algorithmically or edited interactively. Standard word processing capabilities are supported, including real-time multi-lingual spell-checking.

Documents can be structured using a hierarchy of cells, which allow for outlining and sectioning of a document and support automatic numbering index creation. Documents can be presented in a slideshow environment for presentations. Notebooks and their contents are represented as Mathematica expressions that can be created, modified or analyzed by Mathematica programs or converted to other formats.

The front end includes development tools such as a debugger, input completion, and automatic [[syntax highlighting]].

Among the alternative front ends is the Wolfram Workbench, an [[Eclipse (software)|Eclipse]] based [[integrated development environment]] (IDE), introduced in 2006. It provides project-based code development tools for Mathematica, including revision management, debugging, profiling, and testing.&lt;ref&gt;{{cite web|url=http://www.macworld.com/news/2006/06/21/workbench/index.php|title=Wolfram intros Workbench IDE for Mathematica|date=21 June 2006|work=Macworld|access-date=11 August 2015}}&lt;/ref&gt;
There is a plugin for [[IntelliJ IDEA]] based IDEs to work with Wolfram Language code which in addition to [[syntax highlighting]] can analyse and auto-complete local variables and defined functions.&lt;ref&gt;[http://mathematicaplugin.halirutan.de/ Mathematica plugin for IntelliJ IDEA]&lt;/ref&gt;
The Mathematica Kernel also includes a command line front end.&lt;ref&gt;[http://reference.wolfram.com/mathematica/tutorial/UsingATextBasedInterface.html Using a Text-Based Interface] documentation at wolfram.com&lt;/ref&gt; Other interfaces include JMath,&lt;ref&gt;{{cite web|url=http://robotics.caltech.edu/~radford/jmath/|title=JMath: A GNU Readline based frontend for Mathematica|publisher=|access-date=11 August 2015}}&lt;/ref&gt; based on [[GNU readline]] and MASH&lt;ref&gt;{{cite web|url=http://ai.eecs.umich.edu/people/dreeves/mash/|title=Directory listing:|publisher=|access-date=11 August 2015}}&lt;/ref&gt; which runs self-contained Mathematica programs (with arguments) from the UNIX command line.

== High-performance computing ==
In recent years, the capabilities for [[high-performance computing]] have been extended with the introduction of [[packed array]]s (version 4, 1999)&lt;ref&gt;[http://goliath.ecnext.com/premium/0199/0199-1526706.html Math software packs new power; new programs automate such tedious processes as solving nonlinear differential equations and converting units] by Agnes Shanley, ''Chemical Engineering'', March 1, 2002.&lt;/ref&gt; and [[sparse matrix|sparse matrices]] (version 5, 2003),&lt;ref&gt;[http://www.accessmylibrary.com/coms2/summary_0286-9587712_ITM Mathematica 5.1: additional features make software well-suited for operations research professionals] by ManMohan S. Sodhi, ''OR/MS Today'', December 1, 2004.&lt;/ref&gt; and by adopting the [[GNU Multi-Precision Library]] to evaluate high-precision arithmetic.

Version 5.2 (2005) added automatic [[Thread (computer science)|multi-threading]] when computations are performed on [[multi-core]] computers.&lt;ref&gt;[http://www.accessmylibrary.com/coms2/summary_0286-12336000_ITM The 21st annual Editors' Choice Awards], Macworld, February 1, 2006.&lt;/ref&gt; This release included CPU specific optimized libraries. In addition Mathematica is supported by third party specialist acceleration hardware such as [[ClearSpeed]].&lt;ref&gt;{{cite web|url=http://www.thefreelibrary.com/ClearSpeed+Advance(TM)+Accelerator+Boards+Certified+by+Wolfram...-a0147498410|title=ClearSpeed Advance Accelerator Boards Certified by Wolfram Research; Math Coprocessors Enable Mathematica Users to Quadruple Performance.|publisher=|access-date=11 August 2015}}&lt;/ref&gt;

In 2002, [[gridMathematica]] was introduced to allow user level [[Parallel computing|parallel programming]] on heterogeneous clusters and multiprocessor systems&lt;ref&gt;[http://www.macworld.com/news/2002/11/20/mathematica/index.php gridMathematica offers parallel computing solution] by Dennis Sellers, MacWorld, November 20, 2002.&lt;/ref&gt; and in 2008 parallel computing technology was included in all Mathematica licenses including support for grid technology such as [[Windows HPC Server 2008]], [[Windows Server 2003|Microsoft Compute Cluster Server]] and [[Sun Grid]].

Support for [[CUDA]] and [[OpenCL]] [[GPU]] hardware was added in 2010. Also, since version 8 it can generate [[C (programming language)|C]] code, which is automatically compiled by a system C compiler, such as [[GNU Compiler Collection|GCC]] or [[Microsoft Visual Studio]].

== Deployment ==
There are several ways to deploy applications written in Wolfram Mathematica:
*Mathematica Player Pro is a runtime version of Mathematica that will run any Mathematica application but does not allow editing or creation of the code.&lt;ref&gt;[http://www.gizmag.com/mathematica-player-pro-new-application-delivery-system-for-mathematica/9096/ Mathematica Player Pro - new Application Delivery System for Mathematica] www.gizmag.com&lt;/ref&gt; 
*A [[gratis versus libre|free-of-charge]] version, Wolfram [[CDF Player]], is provided for running Mathematica programs that have been saved in the [[Computable Document Format]] (CDF).&lt;ref&gt;{{cite web|url=http://wolfram.com/cdf|title=Computable Document Format (CDF) for Interactive Content|publisher=|access-date=11 August 2015}}&lt;/ref&gt; It can also view standard Mathematica files, but not run them. It includes plugins for common web browsers on Windows and Macintosh.
*webMathematica allows a web browser to act as a front end to a remote Mathematica server. It is designed to allow a user-written application to be remotely accessed via a browser on any platform. It may not be used to give full access to Mathematica. Due to bandwidth limitations interactive 3D graphics is not fully supported within a web browser.
*Wolfram Language code can be converted to C code or to an automatically generated DLL.
*Wolfram Language code can be run on a Wolfram cloud service as a web-app or as an API either on Wolfram-hosted servers or in a private installation of the Wolfram Enterprise Private Cloud.

== Connections with other applications ==
Communication with other applications occurs through a protocol called Wolfram Symbolic Transfer Protocol (WSTP). It allows communication between the Wolfram Mathematica kernel and front-end, and also provides a general interface between the kernel and other applications.&lt;ref&gt;[https://www.wolfram.com/wstp/ Wolfram Symbolic Transfer Protocol (WSTP)]&lt;/ref&gt; Wolfram Research freely distributes a developer kit for linking applications written in the programming language [[C (programming language)|C]] to the Mathematica kernel through ''WSTP''. Using ''J/Link''.,&lt;ref name="macworld.com"&gt;[http://www.macworld.com/2002/11/reviews/mathematica/ Mathematica 4.2] {{webarchive|url=https://web.archive.org/web/20071121151440/http://www.macworld.com/2002/11/reviews/mathematica/ |date=2007-11-21 }} by Charles Seiter, ''Macworld'', November 1, 2002.&lt;/ref&gt; a [[Java (programming language)|Java]] program can ask Mathematica to perform computations; likewise, a Mathematica program can load Java [[class (computer science)|classes]], manipulate Java objects and perform method calls. Similar functionality is achieved with ''.NET /Link'',&lt;ref&gt;[http://www.wolfram.com/solutions/mathlink/netlink/ .NET/Link]: .NET/Link is a toolkit that integrates Mathematica and the Microsoft .NET Framework.&lt;/ref&gt; but with [[.NET Framework|.NET]] programs instead of Java programs. Other languages that connect to Mathematica include [[Haskell (programming language)|Haskell]],&lt;ref&gt;{{cite web|url=http://hackage.haskell.org/package/mathlink|title=mathlink: Write Mathematica packages in Haskell - Hackage|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [[AppleScript]],&lt;ref&gt;{{cite web|url=http://www.unisoftwareplus.com/products/mathlinkosax/|title=MathLink for AppleScript|author=S.Kratky|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [[Racket (programming language)|Racket]],&lt;ref&gt;{{cite web|url=http://www.cs.utah.edu/~czhu/SchemeLink/mrmma.html|title=MrMathematica: Calling Mathematica from Scheme|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [[Visual Basic]],&lt;ref&gt;{{cite web|url=http://library.wolfram.com/infocenter/TechNotes/4710/|title=Mathematica for ActiveX – from Wolfram Library Archive|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [[Python (programming language)|Python]]&lt;ref&gt;{{cite web|url=https://code.google.com/p/pythonika/|title=erocarrera/pythonika|work=GitHub|access-date=11 August 2015}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://library.wolfram.com/infocenter/MathSource/585/|title=PYML (Python Mathematica interface) – from Wolfram Library Archive|publisher=|access-date=11 August 2015}}&lt;/ref&gt; and [[Clojure]].&lt;ref&gt;{{cite web|url=http://clojuratica.weebly.com/ |title=Clojuratica - Home |publisher=Clojuratica.weebly.com |date= |access-date=2013-08-16}}&lt;/ref&gt;

Links are available to many mathematical software packages including [[OpenOffice.org Calc]],&lt;ref&gt;[http://www.lauschkeconsulting.net/calclink.html CalcLink] Lauschke Consulting&lt;/ref&gt; [[Microsoft Excel]],&lt;ref&gt;{{cite web|url=http://www.wolfram.com/products/applications/excel_link/|title=Mathematica Link for Excel: Bringing the Power of Mathematica to Excel|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [[MATLAB]],&lt;ref&gt;{{cite web|url=http://matlink.org|title=MATLink|author=R. Menon, Sz. Horvát|publisher=|access-date=11 August 2015}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.mathworks.com/matlabcentral/fileexchange/6044-mathematica-symbolic-toolbox-for-matlab-version-2-0|title=Mathematica Symbolic Toolbox for MATLAB–Version 2.0|author=Ben Barrowes|date=10 June 2010|publisher=|access-date=11 August 2015}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://library.wolfram.com/infocenter/MathSource/618/|title=MaMa: Calling MATLAB from Mathematica with MathLink – from Wolfram Library Archive|publisher=|access-date=11 August 2015}}&lt;/ref&gt; [[R Statistics|R]],&lt;ref&gt;[http://reference.wolfram.com/mathematica/RLink/guide/RLink.html RLink] Mathematica Documentation&lt;/ref&gt; [[SageMath]] (which can also pull up Mathematica),&lt;ref&gt;{{Cite journal|title=Tensor calculus with open-source software: the SageManifolds project|journal=Journal of Physics: Conference Series|volume=600|pages=012002|last=Gourgoulhon|first=Eric|last2=Bejger|first2=Michal|date=21 Dec 2014|arxiv=1412.4765|last3=Mancini|first3=Marco|bibcode=2015JPhCS.600a2002G|doi=10.1088/1742-6596/600/1/012002}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://doc.sagemath.org/html/en/reference/interfaces/sage/interfaces/mathematica.html|title=Interface to Mathematica — Sage Reference Manual v7.4: Interpreter Interfaces|website=doc.sagemath.org|access-date=2017-01-08}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.math.lsu.edu/comp/resources/sagewithmathematica|title=Using Mathematica within Sagemath {{!}} LSUMath|website=www.math.lsu.edu|access-date=2017-01-08}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=http://www.calvin.edu/~rpruim/talks/Sage/2010-05-08-MAA/sagetalk.pdf|title=Can Sage replace Maple and Mathematica?|last=Pruim|first=Randall|date=5 May 2010|website=Calvin College|publisher=|access-date=8 Jan 2016}}&lt;/ref&gt; [[Singular (software)|Singular]],&lt;ref&gt;[http://www.risc.uni-linz.ac.at/people/mkauers/publications/kauers06m.pdf Manuel Kauers and Viktor Levandovskyy] of the [[Johannes Kepler University Linz]], in Austria&lt;/ref&gt; [[Wolfram SystemModeler]], and [[Origin (data analysis software)|Origin]].&lt;ref&gt;[http://electronicdesign.com/Articles/ArticleID/1323/1323.html * Interface Links Origin And Mathematica Software] {{webarchive|url=https://web.archive.org/web/20070320113853/http://www.electronicdesign.com/Articles/ArticleID/1323/1323.html |date=2007-03-20 }} Electronic Design&lt;/ref&gt; Mathematical equations can be exchanged with other computational or typesetting software via [[MathML]].

Mathematica includes interfaces to [[SQL]] databases (via [[Java Database Connectivity]] JDBC).,&lt;ref&gt;[http://www.databasejournal.com/news/article.php/3453911 Mathematica 5.1 Available], Database Journal, Jan 3, 2005.&lt;/ref&gt; [[MongoDB]] and can read and write to Multichain and [[Bitcoin]] [[Blockchain]]s. Mathematica can also install [[web service]]s from a [[Web Services Description Language]] (WSDL) description.&lt;ref&gt;[http://www.w3.org/Math/Documents/Notes/services.xml Mathematical Web Services: W3C Note 1 August 2003]&lt;/ref&gt;&lt;ref&gt;[http://reference.wolfram.com/mathematica/WebServices/tutorial/Introduction.html Introduction to Web Services], Mathematica Web Services Tutorial&lt;/ref&gt; It can access HDFS data via [[Apache Hadoop|Hadoop]].&lt;ref&gt;{{cite web|url=https://github.com/shadanan/HadoopLink|title=shadanan/HadoopLink|work=GitHub|access-date=11 August 2015}}&lt;/ref&gt;

Mathematica can call a variety of cloud services to retrieve or send data including [[ArXiv]], [[Bing (search engine)|Bing]], [[ChemSpider]], [[CrossRef]], [[Dropbox (service)|Dropbox]], [[Facebook]], [[Factual]], [[Federal Reserve]], [[Fitbit]], [[Flickr]], [[Google]] (Analytics, Calendar, Contacts, Custom search, Plus, search, translate), [[Instagram]], [[LinkedIn]], [[MailChimp]], [[Microsoft Translator]], [[Mixpanel]], [[OpenLibrary]], [[OpenPHACTS]], [[PubChem]], [[PubMed]], [[Pushbullet]], [[Reddit]], [[RunKeeper]], [[SeatGeek]], [[SurveyMonkey]], [[TextTranslation]], [[Twilio]], [[Twitter]], [[WebImageSearch]], [[WebSearch]], [[Wikipedia]] and [[Yelp]].

Mathematica can capture real-time data via a link to [[LabVIEW]],&lt;ref&gt;[http://www.bettervi.com/mlink/index.html Mathematica Link to Labview] BetterView Consulting&lt;/ref&gt; from financial data feeds&lt;ref&gt;[http://www.lauschkeconsulting.net/ddfplus.html DDFLink] Lauschke Consulting&lt;/ref&gt; and directly from hardware devices via GPIB (IEEE 488),&lt;ref&gt;[http://sourceforge.net/projects/gitm/ GITM] SourceForge. Note that the GITM project currently (as of 2014-08-03) has no downloadable artefacts and appears to be inactive so GPIB support for Mathematica may not actually exist.&lt;/ref&gt; [[USB]]&lt;ref&gt;[http://www.wolfram.com/news/btoptools.html BTopTools] A commercial interface to USB devices&lt;/ref&gt; and serial interfaces.&lt;ref&gt;{{cite web|url=http://library.wolfram.com/infocenter/MathSource/6380/|title=Interfacing Hardware with Mathematica – from Wolfram Library Archive|publisher=|access-date=11 August 2015}}&lt;/ref&gt; It automatically detects and reads from [[Human interface device|HID]] devices. It can read directly from a range of Vernier sensors.&lt;ref&gt;[https://www.vernier.com/news/2017/08/25/vernier-and-mathematica/ Vernier and Mathematica]&lt;/ref&gt;

== Computable data ==
[[Image:MathematicaWind.png|thumb|325px|A stream plot of live weather data]]
Wolfram Mathematica includes collections of curated data provided for use in computations. Mathematica is also integrated with [[Wolfram Alpha]], an online computational knowledge [[answer engine]] which provides additional data, some of which is kept updated in real time. Some of the data sets include astronomical, chemical, geopolitical, language, biomedical and weather data, in addition to mathematical data (such as knots and polyhedra).&lt;ref&gt;{{citation|chapter=Scientific and Technical Data|title=Mathematic Guide|url=http://reference.wolfram.com/mathematica/guide/ScientificAndTechnicalData.html|publisher=Wolfram Research|access-date=16 May 2012|deadurl=yes|archiveurl=https://web.archive.org/web/20120510202912/http://reference.wolfram.com/mathematica/guide/ScientificAndTechnicalData.html|archivedate=10 May 2012|df=}}&lt;/ref&gt;

==Reception==
''[[BYTE]]'' in 1989 listed Mathematica as among the "Distinction" winners of the BYTE Awards, stating that it "is another breakthrough Macintosh application ... it could enable you to absorb the algebra and calculus that seemed impossible to comprehend from a textbook".&lt;ref name="byte198901"&gt;{{Cite magazine |date=January 1989 |title=The BYTE Awards |url=https://archive.org/stream/byte-magazine-1989-01/1989_01_BYTE_14-01_PC_Communications_and_Annual_Awards_and_Digitizing_Tablets#page/n371/mode/2up |magazine=BYTE |page=327}}&lt;/ref&gt;

== Version history ==
[[File:Mathematica-version-history.png|thumb|325px|Mathematica version history]]
Wolfram Mathematica built on the ideas in Cole and Wolfram's earlier [[Symbolic Manipulation Program]] (SMP).&lt;ref&gt;[http://www.accessmylibrary.com/coms2/summary_0286-11287695_ITM Math, the universe, and Stephen: the author of Mathematica created a whirlwind of scientific controversy this year when, after more than 10 years of research, he published his treatise on the ability of simple structures to create unpredictable complex patterns. (2002 Scientist Of The Year).(Stephen Wolfram)] by Tim Studt, R&amp;D, November 1, 2002.&lt;/ref&gt;&lt;ref&gt;[https://query.nytimes.com/gst/fullpage.html?res=940DE5DA173AF937A15755C0A96E948260 A Top Scientist's Latest: Math Software] by Andrew Pollack, ''The New York Times'', June 24, 1988.&lt;/ref&gt; The name of the program "Mathematica" was suggested to Stephen Wolfram by Apple cofounder [[Steve Jobs]] although Wolfram had thought about it earlier and rejected it.&lt;ref&gt;{{citation|first=Stephen|last=Wolfram|title=Steve Jobs: A Few Memories|url=http://blog.wolframalpha.com/2011/10/06/steve-jobs-a-few-memories/#more-15338|publisher=Wolfram Alpha|date=6 Oct 2011|access-date=16 May 2012}}&lt;/ref&gt;

[[Wolfram Research]] has released the following versions of Mathematica:&lt;ref name="revhistory"&gt;{{cite web|url=http://www.wolfram.com/products/mathematica/quickrevisionhistory.html|title=Mathematica Latest Version and Quick Revision History|publisher=|access-date=11 August 2015}}&lt;/ref&gt;
{{Div col|colwidth=23em}}
* 1.0 – June 23, 1988&lt;ref&gt;{{citation|title=Mathematica: The Scrapbook|url=http://www.wolfram.com/company/scrapbook/page03.html|publisher=Wolfram|access-date=16 May 2012|deadurl=yes|archiveurl=https://web.archive.org/web/20120518031023/http://www.wolfram.com/company/scrapbook/page03.html|archivedate=18 May 2012|df=}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.mathematica-journal.com/issue/v9i1/news.html|title=The Mathematica Journal: Volume 9, Issue 1: News Bulletins|publisher=|access-date=11 August 2015}}&lt;/ref&gt;&lt;ref&gt;[https://query.nytimes.com/gst/fullpage.html?res=940DE6DB133EF933A05753C1A96E948260 Supercomputer Pictures Solve the Once Insoluble], John Markoff, October 30, 1988.&lt;/ref&gt;&lt;ref name="12000.org"&gt;{{cite web |url=http://12000.org/my_notes/compare_mathematica/index.htm |author= Nasser M. Abbasi |title=A little bit of Mathematica history}}&lt;/ref&gt;
* 1.1 – October 31, 1988
* 1.2 – August 1, 1989&lt;ref name="12000.org" /&gt;&lt;ref&gt;[http://www.accessmylibrary.com/coms2/summary_0286-9205258_ITM Mathematica 1.2 adds new graphics options: upgrade also promises concurrent operations] by Elinor Craig, ''MacWeek'', July 25, 1989.&lt;/ref&gt;
* 2.0 – January 15, 1991&lt;ref name="12000.org" /&gt;&lt;ref&gt;[http://www.accessmylibrary.com/coms2/summary_0286-9227849_ITM Mathematica + 283 functions = Mathematica 2.0] by Raines Cohen, ''MacWeek'', January 15, 1991.&lt;/ref&gt;
* 2.1 – June 15, 1992&lt;ref name="12000.org" /&gt;
* 2.2 – June 1, 1993&lt;ref name="12000.org" /&gt;&lt;ref&gt;[http://www.highbeam.com/doc/1G1-13185601.html New version of Mathematica], ''Mechanical Engineering'', June 1, 1993.&lt;/ref&gt;
* 3.0 – September 3, 1996&lt;ref&gt;{{cite web|url=http://www.wolfram.com/news/archive/#1996 |title=Wolfram News Archive |publisher=Wolfram.com |date= |access-date=2013-08-16}}&lt;/ref&gt;
* 4.0 – May 19, 1999&lt;ref name="12000.org" /&gt;&lt;ref&gt;[http://www.highbeam.com/doc/1G1-61370961.html Mathematica 4.0] by Charles Seiters, ''Macworld'', October 1, 1999.&lt;/ref&gt;
* 4.1 – November 2, 2000&lt;ref name="12000.org" /&gt;
* 4.2 – November 1, 2002&lt;ref name="12000.org" /&gt;
* 5.0 – June 12, 2003&lt;ref name="12000.org" /&gt;&lt;ref&gt;[http://www.mywire.com/pubs/PCMagazine/2003/09/02/420220?extID=10051 Mathematica 5.0 Adds Up: Exactly 15 years after Mathematica's initial release, Wolfram Research has released Mathematica], ''PC Magazine'', September 3, 2003.&lt;/ref&gt;
* 5.1 – October 25, 2004&lt;ref name="12000.org" /&gt;&lt;ref&gt;[http://moreresults.factiva.com/results/index/index.aspx?ref=PCW0000020050115e0c60001i Mathematica 5.1's Web Services Add Up; Mathematica 5.1 delivers improvements over Version 5.0 that are vastly out of proportion for a .1 upgrade.] by Peter Coffee, ''eWeek'', December 6, 2004.&lt;/ref&gt;
* 5.2 – June 20, 2005&lt;ref name="12000.org" /&gt;&lt;ref&gt;[http://www.macworld.co.uk/news/index.cfm?NewsID=12069&amp;Page=1&amp;pagePos=6 Mathematica hits 64-bit], ''MacWorld'' UK, July 13, 2005.&lt;/ref&gt;
* 6.0 – May 1, 2007&lt;ref&gt;[http://blog.wolfram.com/2007/05/ Today, Mathematica is reinvented] – Blog by Stephen Wolfram&lt;/ref&gt;&lt;ref&gt;[http://www.scientific-computing.com/products/review_details.php?review_id=17 Mathematica 6: Felix Grant finds that version 6 of Wolfram Research's symbolic mathematical software really does live up to its expectations.] Scientific Computing, 2007.&lt;/ref&gt;
* 7.0 – November 18, 2008&lt;ref&gt;[http://blog.wolfram.com/2008/11/ Mathematica 7.0 Released Today!] – Blog by Stephen Wolfram&lt;/ref&gt;
* 8.0 – November 15, 2010&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2010/11/15/mathematica-8/|title=Stephen Wolfram blog: Mathematica 8!|access-date=18 November 2010}}&lt;/ref&gt;
* 9.0 – November 28, 2012&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2012/11/28/mathematica-9-is-released-today/|title=Stephen Wolfram blog: Mathematica 9 Is Released Today!|access-date=28 November 2012}}&lt;/ref&gt;
* 10.0 – July 9, 2014&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2014/07/09/launching-mathematica-10-with-700-new-functions-and-a-crazy-amount-of-rd/|title=Stephen Wolfram blog: Launching Mathematica 10—with 700+ New Functions and a Crazy Amount of R&amp;D|access-date=9 July 2014}}&lt;/ref&gt;
* 10.1 – March 30, 2015&lt;ref&gt;{{cite web|url=http://company.wolfram.com/news/2015/mathematica-10-1-is-now-available/|title=Wolfram Research News » Mathematica 10.1 is Now Available!|publisher=|access-date=11 August 2015}}&lt;/ref&gt;
* 10.2 – July 14, 2015&lt;ref&gt;{{cite web|url=http://www.wolfram.com/mathematica/quick-revision-history.html|title=Mathematica Latest Version and Quick Revision History|publisher=|access-date=11 August 2015}}&lt;/ref&gt;
* 10.3 – October 15, 2015
* 10.4 – March 2, 2016
* 10.4.1 – April 18, 2016
* 11.0.0 – August 8, 2016&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2016/08/08/today-we-launch-version-11/|title=Stephen Wolfram blog: Today We Launch Version 11!|access-date=8 August 2016}}&lt;/ref&gt;
* 11.0.1 – September 28, 2016
* 11.1 – March 16, 2017&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2017/03/16/the-rd-pipeline-continues-launching-version-11-1/|title=Stephen Wolfram blog: The R&amp;D Pipeline Continues: Launching Version 11.1|access-date=16 March 2017}}&lt;/ref&gt;
* 11.1.1 – April 25, 2017
* 11.2 – September 14, 2017&lt;ref&gt;{{cite web|url=http://blog.wolfram.com/2017/09/14/its-another-impressive-release-launching-version-11-2-today/|title=Stephen Wolfram blog: It’s Another Impressive Release! Launching Version 11.2 Today|access-date=14 September 2017}}&lt;/ref&gt;
* 11.3 – March 8, 2018&lt;ref&gt;{{cite web|url=http://blog.stephenwolfram.com/2018/03/roaring-into-2018-with-another-big-release-launching-version-11-3-of-the-wolfram-language-mathematica/|title=Stephen Wolfram blog: Roaring into 2018 with Another Big Release: Launching Version 11.3 of the Wolfram Language &amp; Mathematica|access-date=8 March 2018}}&lt;/ref&gt;
{{div col end}}

== See also ==
{{div col|colwidth=22em}}
*[[List of computer algebra systems]]
*[[Comparison of multi-paradigm programming languages]]
*[[Comparison of numerical analysis software]]
*[[Comparison of programming languages]]
*[[Comparison of regular expression engines]]
*[[Computational X]]
*[[Dynamic programming language]]
*[[Fourth-generation programming language]]
*[[Functional programming]]
*[[List of computer algebra systems]]
*[[List of computer simulation software]]
*[[List of graphing software]]
*[[Literate programming]]
*[[Mathematical markup language]]
*[[Mathematical software]]
*[[Wolfram Alpha]], a web answer engine
*[[Wolfram Language]]
*[[Wolfram SystemModeler]], a physical modeling and simulation tool which integrates with Mathematica
{{div col end}}

== References ==
{{Reflist}}

== External links ==
{{sisterlinks|d=Q81294|n=no|s=no|commons=Category:Mathematica|voy=no|m=no|mw=no|species=no|q=no|wikt=no|v=no}}
*{{Official website|www.wolfram.com/mathematica}}
*[http://reference.wolfram.com/ Mathematica Documentation Center]
*[https://www.open.wolframcloud.com/ Wolfram Open Cloud] limited free access to Mathematica via a browser
*[http://www.imageidentify.com/ Image identification] website powered by Mathematica
*[http://demonstrations.wolfram.com Wolfram Demonstrations Project] Mathematica based demonstrations
*[http://12000.org/my_notes/compare_mathematica/index.htm A little bit of Mathematica history] documenting the growth of code base and number of functions over time
*[http://www.wolfram.com/broadcast/c?c=141&amp;&amp;disp=list#chan Wolfram Screencast &amp; Video Gallery: Hands-on Start to Mathematica]

{{Computer algebra systems}}
{{Numerical analysis software}}
{{Statistical software}}
{{Fractal software}}
{{Image Processing Software}}
{{Graph Analysis Software}}
{{Deep_Learning_Software}}
{{Wolfram Research}}

[[Category:1988 software]]
[[Category:Astronomical databases]]
[[Category:Computational notebook]]
[[Category:Computer algebra system software for Linux]]
[[Category:Computer algebra system software for MacOS]]
[[Category:Computer algebra system software for Windows]]
[[Category:Computer algebra systems]]
[[Category:Cross-platform software]]
[[Category:Data mining and machine learning software]]
[[Category:Earth sciences graphics software]]
[[Category:Econometrics software]]
[[Category:Formula editors]]
[[Category:Interactive geometry software]]
[[Category:Mathematical optimization software]]
[[Category:Mathematical software]]
[[Category:Numerical analysis software for Linux]]
[[Category:Numerical analysis software for MacOS]]
[[Category:Numerical analysis software for Windows]]
[[Category:Numerical programming languages]]
[[Category:Numerical software]]
[[Category:Physics software]]
[[Category:Pi-related software]]
[[Category:Plotting software]]
[[Category:Proprietary commercial software for Linux]]
[[Category:Proprietary cross-platform software]]
[[Category:Regression and curve fitting software]]
[[Category:Simulation programming languages]]
[[Category:Software that uses Qt]]
[[Category:Statistical programming languages]]
[[Category:Theorem proving software systems]]
[[Category:Time series software]]
[[Category:Wolfram Research]]</text>
      <sha1>2kmw48mr41ceths1v0j8limfyi64u02</sha1>
    </revision>
  </page>
</mediawiki>
