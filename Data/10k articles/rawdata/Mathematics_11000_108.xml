<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>Adaptive resonance theory</title>
    <ns>0</ns>
    <id>3056879</id>
    <revision>
      <id>862126373</id>
      <parentid>857075668</parentid>
      <timestamp>2018-10-02T10:20:40Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 9 sources and tagging 0 as dead. #IABot (v2.0beta9)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="14149">'''Adaptive resonance theory''' ('''ART''') is a theory developed by [[Stephen Grossberg]] and [[Gail Carpenter]] on aspects of how the brain processes information. It describes a number of [[neural network models]] which use supervised and unsupervised learning methods, and address problems such as [[pattern recognition]] and prediction.

The primary intuition behind the ART model is that object identification and recognition generally occur as a result of the interaction of 'top-down' observer expectations with 'bottom-up' sensory information. The model postulates that 'top-down' expectations take the form of a memory template or [[prototype]] that is then compared with the actual features of an object as detected by the senses. This comparison gives rise to a measure of category belongingness. As long as this difference between sensation and expectation does not exceed a set threshold called the 'vigilance parameter', the sensed object will be considered a member of the expected class. The system thus offers a solution to the 'plasticity/stability' problem, i.e. the problem of acquiring new knowledge without disrupting existing knowledge that is also called [[incremental learning]].

==Learning model==
[[Image:ART.png|thumb|Basic ART structure]]
The basic ART system is an [[unsupervised learning]] model. It typically consists of a comparison field and a recognition field composed of neurons, a vigilance parameter (threshold of recognition), and a reset module. The comparison field takes an input vector (a one-dimensional array of values) and transfers it to its best match in the recognition field. Its best match is the single neuron whose set of weights (weight vector) most closely matches the input vector. Each recognition field neuron outputs a negative signal (proportional to that neuron’s quality of match to the input vector) to each of the other recognition field neurons and thus inhibits their output. In this way the recognition field exhibits [[lateral inhibition]], allowing each neuron in it to represent a category to which input vectors are classified.

After the input vector is classified, the reset module compares the strength of the recognition match to the vigilance parameter. If the vigilance parameter is overcome (i.e. the input vector is within the normal range seen on previous input vectors), training commences: the weights of the winning recognition neuron are adjusted towards the features of the input vector. Otherwise, if the match level is below the vigilance parameter (i.e. the input vector's match is outside the normal expected range for that neuron) the winning recognition neuron is inhibited and a search procedure is carried out. In this search procedure, recognition neurons are disabled one by one by the reset function until the vigilance parameter is overcome by a recognition match. In particular, at each cycle of the search procedure the most active recognition neuron is selected and then switched off if its activation is below the vigilance parameter (note that it thus releases the remaining recognition neurons from its inhibition). If no committed recognition neuron’s match overcomes the vigilance parameter, then an uncommitted neuron is committed and its weights are adjusted towards matching the input vector. The vigilance parameter has considerable influence on the system: higher vigilance produces highly detailed memories (many, fine-grained categories), while lower vigilance results in more general memories (fewer, more-general categories).

==Training==
There are two basic methods of training ART-based neural networks: slow and fast. In the slow learning method, the degree of training of the recognition neuron’s weights towards the input vector is calculated to continuous values with [[differential equation]]s and is thus dependent on the length of time the input vector is presented. With fast learning, [[algebraic equation]]s are used to calculate degree of weight adjustments to be made, and binary values are used. While fast learning is effective and efficient for a variety of tasks, the slow learning method is more biologically plausible and can be used with continuous-time networks (i.e. when the input vector can vary continuously).

==Types==

'''ART 1'''&lt;ref name="ART 1"&gt;Carpenter, G.A. &amp; Grossberg, S. (2003), [http://cns.bu.edu/Profiles/Grossberg/CarGro2003HBTNN2.pdf Adaptive Resonance Theory] {{Webarchive|url=https://web.archive.org/web/20060519091948/http://cns.bu.edu/Profiles/Grossberg/CarGro2003HBTNN2.pdf |date=2006-05-19 }}, In [[Michael A. Arbib]] (Ed.), The Handbook of Brain Theory and Neural Networks, Second Edition (pp. 87-90). Cambridge, MA: MIT Press&lt;/ref&gt;&lt;ref name="AR"&gt;Grossberg, S. (1987), [http://www.cns.bu.edu/Profiles/Grossberg/Gro1987CogSci.pdf Competitive learning: From interactive activation to adaptive resonance] {{Webarchive|url=https://web.archive.org/web/20060907041202/http://www.cns.bu.edu/Profiles/Grossberg/Gro1987CogSci.pdf |date=2006-09-07 }}, [[Cognitive Science (journal)]], 11, 23-63&lt;/ref&gt; is the simplest variety of ART networks, accepting only binary inputs.
'''ART 2'''&lt;ref name="ART 2"&gt;Carpenter, G.A. &amp; Grossberg, S. (1987), [http://cns-web.bu.edu/Profiles/Grossberg/CarGro1987AppliedOptics.pdf ART 2: Self-organization of stable category recognition codes for analog input patterns] {{Webarchive|url=https://web.archive.org/web/20060904212143/http://cns-web.bu.edu/Profiles/Grossberg/CarGro1987AppliedOptics.pdf |date=2006-09-04 }}, [[Applied Optics]], 26(23), 4919-4930&lt;/ref&gt; extends network capabilities to support continuous inputs.
'''ART 2-A'''&lt;ref name="ART 2-A"&gt;Carpenter, G.A., Grossberg, S., &amp; Rosen, D.B. (1991a), [http://cns.bu.edu/Profiles/Grossberg/CarGroRos1991NNART2A.pdf ART 2-A: An adaptive resonance algorithm for rapid category learning and recognition] {{Webarchive|url=https://web.archive.org/web/20060519092850/http://cns.bu.edu/Profiles/Grossberg/CarGroRos1991NNART2A.pdf |date=2006-05-19 }}, [[Neural Networks (Publication)]], 4, 493-504&lt;/ref&gt; is a streamlined form of ART-2 with a drastically accelerated runtime, and with qualitative results being only rarely inferior to the full ART-2 implementation.
'''ART 3'''&lt;ref name="ART 3"&gt;Carpenter, G.A. &amp; Grossberg, S. (1990), [http://cns.bu.edu/Profiles/Grossberg/CarGro1990NN.pdf ART 3: Hierarchical search using chemical transmitters in self-organizing pattern recognition architectures] {{Webarchive|url=https://web.archive.org/web/20060906014656/http://cns.bu.edu/Profiles/Grossberg/CarGro1990NN.pdf |date=2006-09-06 }}, [[Neural Networks (Publication)]], 3, 129-152&lt;/ref&gt; builds on ART-2 by simulating rudimentary [[neurotransmitter]] regulation of [[synapse|synaptic activity]] by incorporating simulated sodium (Na+) and calcium (Ca2+) ion concentrations into the system's equations, which results in a more physiologically realistic means of partially inhibiting categories that trigger mismatch resets.

[[Image:ARTMAP.png|thumb|ARTMAP overview]]
'''ARTMAP'''&lt;ref name="ARTMAP"&gt;Carpenter, G.A., Grossberg, S., &amp; Reynolds, J.H. (1991), [http://cns.bu.edu/Profiles/Grossberg/CarGroRey1991NN.pdf ARTMAP: Supervised real-time learning and classification of nonstationary data by a self-organizing neural network] {{Webarchive|url=https://web.archive.org/web/20060519091848/http://cns.bu.edu/Profiles/Grossberg/CarGroRey1991NN.pdf |date=2006-05-19 }}, [[Neural Networks (Publication)]], 4, 565-588&lt;/ref&gt; also known as '''Predictive ART''', combines two slightly modified ART-1 or ART-2 units into a supervised learning structure where the first unit takes the input data and the second unit takes the correct output data, then used to make the minimum possible adjustment of the vigilance parameter in the first unit in order to make the correct classification.

'''Fuzzy ART'''&lt;ref name="Fuzzy ART"&gt;Carpenter, G.A., Grossberg, S., &amp; Rosen, D.B. (1991b), [http://cns.bu.edu/Profiles/Grossberg/CarGroRos1991NNFuzzyART.pdf Fuzzy ART: Fast stable learning and categorization of analog patterns by an adaptive resonance system] {{Webarchive|url=https://web.archive.org/web/20060519091505/http://cns.bu.edu/Profiles/Grossberg/CarGroRos1991NNFuzzyART.pdf |date=2006-05-19 }}, [[Neural Networks (Publication)]], 4, 759-771&lt;/ref&gt; implements fuzzy logic into ART’s pattern recognition, thus enhancing generalizability. An optional (and very useful) feature of fuzzy ART is complement coding, a means of incorporating the absence of features into pattern classifications, which goes a long way towards preventing inefficient and unnecessary category proliferation. The applied similarity measures are based on the [[L1 norm]]. Fuzzy ART is known to be very sensitive to noise.

'''Fuzzy ARTMAP'''&lt;ref name="Fuzzy ARTMAP"&gt;Carpenter, G.A., Grossberg, S., Markuzon, N., Reynolds, J.H., &amp; Rosen, D.B. (1992), [http://cns.bu.edu/Profiles/Grossberg/CarGroMarRey1992IEEETransNN.pdf Fuzzy ARTMAP: A neural network architecture for incremental supervised learning of analog multidimensional maps] {{Webarchive|url=https://web.archive.org/web/20060519094345/http://cns.bu.edu/Profiles/Grossberg/CarGroMarRey1992IEEETransNN.pdf |date=2006-05-19 }}, [[IEEE Transactions on Neural Networks]], 3, 698-713&lt;/ref&gt; is merely ARTMAP using fuzzy ART units, resulting in a corresponding increase in efficacy.

'''Simplified Fuzzy ARTMAP (SFAM)'''&lt;ref&gt;Mohammad-Taghi Vakil-Baghmisheh and Nikola Pavešić. (2003) A Fast Simplified Fuzzy ARTMAP Network, Neural Processing Letters, 17(3):273–316&lt;/ref&gt; constitutes a strongly simplified variant of fuzzy ARTMAP dedicated to [[statistical classification|classification]] tasks.

'''Gaussian ART'''&lt;ref name="GaussianART"&gt;James R. Williamson. (1996), [http://dcommon.bu.edu/bitstream/handle/2144/2180/95.003.pdf?sequence=1&amp;isAllowed=y Gaussian ARTMAP: A Neural Network for Fast Incremental Learning of Noisy Multidimensional Maps], Neural Networks, 9(5):881-897&lt;/ref&gt; and '''Gaussian ARTMAP'''&lt;ref name="GaussianART" /&gt; use Gaussian activation functions and computations based on probability theory. Therefore, they have some similarity with Gaussian [[mixture models]]. In comparison to fuzzy ART and fuzzy ARTMAP, they are less sensitive to noise. But the stability of learnt representations is reduced which may lead to category proliferation in open-ended learning tasks.

'''[[Fusion adaptive resonance theory|Fusion ART and related networks]]'''&lt;ref&gt;Y.R. Asfour, G.A. Carpenter, S. Grossberg, and G.W. Lesher. (1993) [http://open.bu.edu/xmlui/bitstream/handle/2144/2029/93.052.pdf?...1&amp;sa=U&amp;ei=ZpBPU5iSAZCWyAToioHIDg&amp;ved=0CC4QFjAE&amp;usg=AFQjCNGbPmXW27YRaMlcQyD9FQLDNXB7lg Fusion ARTMAP: an adaptive fuzzy network for multi-channel classification]. In: Proceedings of the Third International Conference on Industrial Fuzzy Control and Intelligent Systems (IFIS).&lt;/ref&gt; extend ART and ARTMAP to multiple pattern channels. They support several learning paradigms.

'''TopoART'''&lt;ref&gt;Marko Tscherepanow. (2010) [https://pub.uni-bielefeld.de/download/1925596/2499061 TopoART: A Topology Learning Hierarchical ART Network], In: Proceedings of the International Conference on Artificial Neural Networks (ICANN), Part III, LNCS 6354, 157-167&lt;/ref&gt; combines fuzzy ART with topology learning networks such as the [[neural gas#Variants|growing neural gas]]. Furthermore, it adds a noise reduction mechanism. There are several derived neural networks which extend TopoART to further learning paradigms.

'''Hypersphere ART'''&lt;ref name="HypersphereART"&gt;Georgios C. Anagnostopoulos and Michael Georgiopoulos. (2000), [http://techlab.bu.edu/files/resources/articles_tt/Anagnostopoulos_Georgiopoulos_2000.pdf Hypersphere ART and ARTMAP for Unsupervised and Supervised Incremental Learning], In: Proceedings of the International Joint Conference on Neural Networks (IJCNN), vol. 6, 59-64&lt;/ref&gt; and '''Hypersphere ARTMAP'''&lt;ref name="HypersphereART" /&gt; are closely related to fuzzy ART and fuzzy ARTMAP, respectively. But as they use a different type of category representation (namely hyperspheres), they do not require their input to be normalised to the interval [0, 1]. They apply similarity measures based on the [[L2 norm]].

'''LAPART'''&lt;ref&gt;Sandia National Laboratories (2017) [https://lapart-python.readthedocs.io/en/latest/index.html#lapart-python-documentation Lapart-python documentation]&lt;/ref&gt;The Laterally Primed Adaptive Resonance Theory (LAPART) neural networks couple two Fuzzy ART algorithms to create a mechanism for making predictions based on learned associations. The coupling of the two Fuzzy ARTs has a unique stability that allows the system to converge rapidly towards a clear solution. Additionally, it can perform logical inference and supervised learning similar to fuzzy ARTMAP.

==Criticism==
{{expand section|date=September 2015}}
It has been noted that results of Fuzzy ART and ART 1 depend critically upon the order in which the training data are processed. The effect can be reduced to some extent by using a slower learning rate, but is present regardless of the size of the input data set. Hence Fuzzy ART and ART 1 estimates do not possess the statistical property of [[Consistent estimator|consistency]].&lt;ref name="Sarle"&gt;Sarle, Warren S. (1995), [http://medusa.sdsu.edu/Robotics/Neuromuscular/Articles/ATM_articles/fart.txt Why Statisticians Should Not FART] {{webarchive |url=https://web.archive.org/web/20110720042616/http://medusa.sdsu.edu/Robotics/Neuromuscular/Articles/ATM_articles/fart.txt |date=July 20, 2011 }}&lt;/ref&gt;

==References==
{{Reflist|30em}}

Wasserman, Philip D. (1989), Neural computing: theory and practice, New York: Van Nostrand Reinhold, {{ISBN|0-442-20743-3}}

==External links==
* [[Stephen Grossberg]]'s [https://web.archive.org/web/20060616203130/http://cns-web.bu.edu/Profiles/Grossberg/ website]
* [https://web.archive.org/web/20120109162743/http://users.visualserver.org/xhudik/art ART's implementation for unsupervised learning (ART 1, ART 2A, ART 2A-C and ART distance)]
* [http://cns.bu.edu/Profiles/Grossberg/ART.pdf Summary of the ART algorithm]]

[[Category:Neuropsychology]]
[[Category:Artificial neural networks]]</text>
      <sha1>66w5pblyxmf6kg3tvdp3ilcx2iwb608</sha1>
    </revision>
  </page>
  <page>
    <title>Approximation</title>
    <ns>0</ns>
    <id>336271</id>
    <revision>
      <id>868840951</id>
      <parentid>863553705</parentid>
      <timestamp>2018-11-14T20:01:49Z</timestamp>
      <contributor>
        <username>Peter M. Brown</username>
        <id>12680084</id>
      </contributor>
      <minor/>
      <comment>/* Unicode */ Enlarged symbols to aid recognition</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11101">{{for|the sound change|Lenition}}
{{Refimprove|date=April 2013}}
{{Certainty}}

An '''approximation''' is anything that is similar but not exactly equal to something else.

==Etymology and usage==
The word ''approximation'' is derived from [[Latin]] ''approximatus'', from ''proximus'' meaning ''very near'' and the prefix ''ap-'' (''ad-'' before ''p'') meaning ''to''.&lt;ref&gt;The Concise Oxford Dictionary, ''Eighth edition 1990, {{ISBN|0-19-861243-5}}''&lt;/ref&gt; Words like ''approximate'', ''approximately'' and ''approximation'' are used especially in technical or scientific contexts. In everyday English, words such as ''roughly'' or ''around'' are used with a similar meaning.&lt;ref&gt;Longman Dictionary of Contemporary English, ''Pearson Education Ltd 2009, {{ISBN|978 1 4082 1532 6}}''&lt;/ref&gt; It is often found abbreviated as ''approx.''

The term can be applied to various properties (e.g., value, quantity, image, description) that are nearly, but not exactly correct; similar, but not exactly the same (e.g., the approximate time was 10 o'clock).
 
Although approximation is most often applied to [[number]]s, it is also frequently applied to such things as [[Function (mathematics)|mathematical functions]], [[shape]]s, and [[physical law]]s.

In science, approximation can refer to using a simpler process or model when the correct model is difficult to use. An approximate model is used to make calculations easier. Approximations might also be used if incomplete [[information]] prevents use of exact representations.

The type of approximation used depends on the available [[information]], [[Order of approximation|the degree of accuracy required]], the sensitivity of the problem to this data, and the savings (usually in time and effort) that can be achieved by approximation.

== Mathematics ==
[[Approximation theory]] is a branch of mathematics, a quantitative part of [[functional analysis]]. [[Diophantine approximation]] deals with approximations of [[real number]]s by [[rational number]]s. Approximation usually occurs when an exact form  or an exact numerical number is unknown or difficult to obtain. However some known form may exist and may be able to represent the real form so that no significant deviation can be found. It also is used when a number is [[Irrational number|not rational]], such as the number [[Pi|π]], which often is shortened to 3.14159, or {{radic|2}} to 1.414.

Numerical approximations sometimes result from using a small number of [[Significant figures|significant digits]]. Calculations are likely to involve [[Round-off error|rounding errors]] leading to approximation. [[Logarithm|Log tables]], slide rules and calculators produce approximate answers to all but the simplest calculations. The results of computer calculations are normally an approximation expressed in a limited number of significant digits, although they can be programmed to produce more precise results.&lt;ref&gt;[http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html Numerical Computation Guide]&lt;/ref&gt; Approximation can occur when a decimal number cannot be expressed in a finite number of binary digits.

Related to approximation of functions is the [[Asymptotic analysis|asymptotic]] value of a function, i.e. the value as one or more of a function's parameters becomes arbitrarily large. For example, the sum  (''k''/2)+(''k''/4)+(''k''/8)+...(''k''/2^''n'') is asymptotically equal to ''k''. Unfortunately no consistent notation is used throughout mathematics and some texts will use ≈ to mean approximately equal and ~ to mean asymptotically equal whereas other texts use the symbols the other way around.

As another example, in order to accelerate the convergence rate of evolutionary algorithms, [[fitness approximation]]—that leads to build model of the fitness function to choose smart search steps—is a good solution. 

== Science ==
Approximation arises naturally in [[scientific experiment]]s. The predictions of a scientific theory can differ from actual measurements. This can be because there are factors in the real situation that are not included in the theory. For example, simple calculations may not include the effect of air resistance. Under these circumstances, the theory is an approximation to reality. Differences may also arise because of limitations in the measuring technique. In this case, the measurement is an approximation to the actual value.

The [[history of science]] shows that earlier theories and laws can be ''approximations'' to some deeper set of laws. Under the [[correspondence principle]], a new scientific theory should reproduce the results of older, well-established, theories in those domains where the old theories work.&lt;ref&gt;[http://www.britannica.com/EBchecked/topic/138678/correspondence-principle Encyclopædia Britannica]&lt;/ref&gt; The old theory becomes an approximation to the new theory.

Some problems in physics are too complex to solve by direct analysis, or progress could be limited by available analytical tools. Thus, even when the exact representation is known, an approximation may yield a sufficiently accurate solution while reducing the complexity of the problem significantly. [[Physicists]] often approximate the [[shape of the Earth]] as a [[sphere]] even though more accurate representations are possible, because many physical characteristics (e.g., [[gravity]]) are much easier to calculate for a sphere than for other shapes.

Approximation is also used to analyze the motion of several planets orbiting a star. This is extremely difficult due to the complex interactions of the planets' gravitational effects on each other.&lt;ref&gt;[http://plus.maths.org/content/mathematical-mysteries-three-body-problem The three body problem]&lt;/ref&gt; An approximate solution is effected by performing [[iteration]]s. In the first iteration, the planets' gravitational interactions are ignored, and the star is assumed to be fixed. If a more precise solution is desired, another iteration is then performed, using the positions and motions of the planets as identified in the first iteration, but adding a first-order gravity interaction from each planet on the others. This process may be repeated until a satisfactorily precise solution is obtained.

The use of [[Perturbation theory|perturbations]] to correct for the errors can yield more accurate solutions. Simulations of the motions of the planets and the star also yields more accurate solutions.

The most common versions of [[philosophy of science]] accept that empirical [[measurement]]s are always ''approximations''—they do not perfectly represent what is being measured.

The error-tolerance property of several applications (e.g., graphics applications) allows use of approximation (e.g., lowering the precision of numerical computations) to improve performance and energy efficiency.&lt;ref name="surveyACT"&gt;{{cite journal|last1=Mittal|first1=Sparsh|title=A Survey of Techniques for Approximate Computing|journal=ACM Comput. Surv.|date=May 2016|volume=48|issue=4|pages=62:1–62:33|doi=10.1145/2893356|publisher=ACM|language=en}}&lt;/ref&gt; This approach of using deliberate, controlled approximation for achieving various optimizations is referred to as [[approximate computing]].

==Unicode==
{{See also|Unicode mathematical operators}}

Symbols used to denote items that are approximately equal are wavy or dotted equals signs.&lt;ref&gt;{{cite web| title =Mathematical Operators – Unicode| url =https://www.unicode.org/charts/PDF/U2200.pdf| accessdate =2013-04-20}}&lt;/ref&gt;
* &lt;span style="font-size: 150%;line-height:50%;"&gt;≈&lt;/span&gt; ([[Unicode|U]]+2248, ''almost equal to'')
* &lt;span style="font-size: 150%;line-height:50%;"&gt;≉&lt;/span&gt; ([[Unicode|U]]+2249, ''not almost equal to'')
* &lt;span style="font-size: 150%;line-height:50%"&gt;[[≃]]&lt;/span&gt; (U+2243), a combination of "≈" and "=", also used to indicate [[≃|asymptotically equal to]]{{clarify|Target article mentions nothing of this symbol|date=January 2016}}
** &lt;span style="font-size: 150%;line-height:50%"&gt;≒&lt;/span&gt; (U+2252), which is used like "&lt;big&gt;≃&lt;/big&gt;" in [[Japanese language|Japan]], [[Taiwanese Mandarin|Taiwan]], and [[Korean language|Korea]]
** &lt;span style="font-size: 150%;line-height:50%"&gt;≓&lt;/span&gt; (U+2253), a reversed variation of "&lt;big&gt;≒&lt;/big&gt;"
* &lt;span style="font-size: 150%;line-height:50%"&gt;[[≅ (disambiguation)|≅]]&lt;/span&gt; (U+2245), another combination of "≈" and "=", which is used to indicate [[isomorphism]] or [[congruence relation|congruence]]
* &lt;span style="font-size: 150%;line-height:50%"&gt;≊&lt;/span&gt; (U+224A), yet another combination of "≈" and "=", used to indicate equivalence or approximate equivalence
* &lt;span style="font-size: 150%;line-height:50%"&gt;∼&lt;/span&gt; (U+223C), which is also sometimes used to indicate [[proportionality (mathematics)|proportionality]]
* &lt;span style="font-size: 150%;line-height:50%"&gt;∽&lt;/span&gt; (U+223D), which is also sometimes used to indicate [[proportionality (mathematics)|proportionality]]
* &lt;span style="font-size: 150%;line-height:50%"&gt;≐&lt;/span&gt; (U+2250, ''approaches the limit''), which can be used to represent the approach of a variable, {{math|y}}, to a [[limit (mathematics)|limit]]; like the common syntax, &lt;math&gt;\scriptstyle \lim_{x \to \inf} y(x)&lt;/math&gt; &lt;small&gt;≐ 0&lt;/small&gt;{{citation needed|reason=This is what the unicode spec. implies, but I have no direct confirmation|date=January 2016}}

==[[LaTeX]] Symbols==
: &lt;math&gt; \approx &lt;/math&gt; (&lt;code&gt;\approx&lt;/code&gt;), usually to indicate approximation between numbers, like &lt;math&gt; \pi \approx 3.14&lt;/math&gt;.
: &lt;math&gt; \not\approx &lt;/math&gt; (&lt;code&gt;\not\approx&lt;/code&gt;), usually to indicate that numbers are not approximately equal (1 &lt;math&gt; \not\approx &lt;/math&gt; 2).
: &lt;math&gt; \simeq &lt;/math&gt; (&lt;code&gt;\simeq&lt;/code&gt;), usually to indicate asymptotic equivalence between functions, like &lt;math&gt; f(n) \simeq 3n^2 &lt;/math&gt;. So writing &lt;math&gt; \pi \simeq 3.14 &lt;/math&gt; would be wrong, despite wide use.
: &lt;math&gt; \sim &lt;/math&gt; (&lt;code&gt;\sim&lt;/code&gt;), usually to indicate proportionality between functions, the same  &lt;math&gt; f(n)  &lt;/math&gt; of the line above will be &lt;math&gt; f(n) \sim n^2 &lt;/math&gt;.
: &lt;math&gt; \cong &lt;/math&gt; (&lt;code&gt;\cong&lt;/code&gt;), usually to indicate congruence between figures, like &lt;math&gt; \Delta ABC \cong \Delta A'B'C' &lt;/math&gt;.

== See also ==
{{columns-list|colwidth=22em|
* [[Approximately equals sign]]
* [[Approximation error]]
* [[Congruence relation]]
* [[Estimation]]
* [[Fermi estimate]]
* [[Fitness approximation]]
* [[Least squares]]
* [[Linear approximation]]
* [[Binomial approximation]]
* [[Newton's method]]
* [[Numerical analysis]]
* [[Orders of approximation]]
* [[Runge–Kutta methods]]
* [[Successive approximation ADC]]
* [[Taylor series]]
* [[Small-angle approximation]]
* [[Approximate computing]]
* [[Tolerance relation]]
* [[Rough set]]
}}

== References ==
{{Reflist}}

==External links==
{{Wiktionary|approximation}}
*{{Commonscatinline}}

{{Authority control}}

[[Category:Approximations| ]]
[[Category:Numerical analysis]]
[[Category:Equivalence (mathematics)]]
[[Category:Comparison (mathematical)]]
&lt;!-- this category expressly includes similarities--&gt;</text>
      <sha1>h0flt0oycvfyw7tek6xl904kj37evbo</sha1>
    </revision>
  </page>
  <page>
    <title>Arity</title>
    <ns>0</ns>
    <id>42301</id>
    <revision>
      <id>870619016</id>
      <parentid>862423347</parentid>
      <timestamp>2018-11-26T00:15:18Z</timestamp>
      <contributor>
        <username>Cydebot</username>
        <id>1215485</id>
      </contributor>
      <minor/>
      <comment>Robot - Removing category Equivalence classes per [[WP:CFD|CFD]] at [[Wikipedia:Categories for discussion/Log/2018 November 13]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="12571">In [[logic]], [[mathematics]], and [[computer science]], the '''arity''' {{IPAc-en|audio=en-us-arity.ogg|ˈ|æ|r|ᵻ|t|i}} of a [[function (mathematics)|function]] or [[operation (mathematics)|operation]] is the number of [[argument of a function|arguments]] or [[operand]]s that the function takes. The arity of a [[relation (mathematics)|relation]] (or [[predicate (mathematical logic)|predicate]]) is the dimension of the [[domain of a function|domain]] in the corresponding [[Cartesian product]]. (A function of arity ''n'' thus has arity ''n''+1 considered as a relation.) The term springs from words like unary, binary, ternary, etc. Unary functions or predicates may be also called "monadic"; similarly, binary functions may be called "dyadic".

In mathematics, arity may also be named ''rank'',&lt;ref name="Hazewinkel2001"&gt;{{cite book|authorlink=Michiel Hazewinkel|first=Michiel|last=Hazewinkel|title=Encyclopaedia of Mathematics, Supplement III|url=https://books.google.com/books?id=47YC2h295JUC&amp;pg=PA3|year=2001|publisher=Springer|isbn=978-1-4020-0198-7|page=3}}&lt;/ref&gt;&lt;ref name="Schechter1997"&gt;{{cite book|first=Eric|last=Schechter|title=Handbook of Analysis and Its Foundations|url=https://books.google.com/books?id=eqUv3Bcd56EC&amp;pg=PA356|year=1997|publisher=Academic Press|isbn=978-0-12-622760-4|page=356}}&lt;/ref&gt; but this word can have many other meanings in mathematics. In logic and philosophy, arity is also called '''adicity''' and '''degree'''.&lt;ref name="DetlefsenBacon1999"&gt;{{cite book|first1=Michael |last1=Detlefsen|first2=David Charles|last2=McCarty|first3=John B.|last3=Bacon|title=Logic from A to Z|url=https://books.google.com/books?id=pc3E4Xdf2GgC&amp;pg=PP17|year=1999|publisher=Routeledge|isbn=978-0-415-21375-2|page=7}}&lt;/ref&gt;&lt;ref name="CocchiarellaFreund2008"&gt;{{cite book|first1=Nino B.|last1=Cocchiarella|first2=Max A.|last2=Freund|title=Modal Logic: An Introduction to its Syntax and Semantics|url=https://books.google.com/books?id=zLmxqytfLhgC&amp;pg=PA121|year=2008|publisher=Oxford University Press|isbn=978-0-19-536658-7|page=121}}&lt;/ref&gt; In [[linguistics]], arity is usually named '''[[valency (linguistics)|valency]]'''.&lt;ref name="Crystal2008"&gt;{{cite book|first=David|last=Crystal|title=Dictionary of Linguistics and Phonetics|year=2008|publisher=John Wiley &amp; Sons|isbn=978-1-405-15296-9|page=507|edition=6th}}&lt;/ref&gt;

In [[computer programming]], there is often a [[Syntax (programming languages)|syntactical]] distinction between [[Operator (programming)|operators]] and [[Function (computer science)|functions]]; syntactical operators usually have arity 0, 1, or 2 (the [[Ternary operation|ternary operator]] [[?:]] is also common).  Functions vary widely in the number of arguments, though large numbers can become unwieldy. Some programming languages also offer support for [[variadic functions]], i.e., functions syntactically accepting a variable number of arguments.

==Examples==
{{Expand section|more math and logic examples|date=March 2012}}
The term "arity" is rarely employed in everyday usage. For example, rather than saying "the arity of the [[addition]] operation is 2" or "addition is an operation of arity 2" one usually says "addition is a binary operation".
In general, the naming of functions or operators with a given arity follows a convention similar to the one used for ''n''-based [[numeral system]]s such as [[Binary numeral system|binary]] and [[hexadecimal]]. One combines a [[Latin]] prefix with the -ary ending; for example:

* A nullary function takes no arguments.
** Example: &lt;math&gt;f()=2&lt;/math&gt;
* A [[unary operation|unary function]] takes one argument.
** Example: &lt;math&gt;f(x)=2x&lt;/math&gt;
* A [[binary operation|binary function]] takes two arguments.
** Example: &lt;math&gt;f(x,y)=2xy&lt;/math&gt;
* A [[ternary operation|ternary function]] takes three arguments.
** Example: &lt;math&gt;f(x,y,z)=2xyz&lt;/math&gt;
* An ''n''-ary function takes ''n'' arguments.
** Example: &lt;math&gt;f(x_1, x_2, \ldots, x_n)=2\prod_{i=1}^n \displaystyle x_i&lt;/math&gt;

===Nullary===
Sometimes it is useful to consider a [[constant (mathematics)|constant]] to be an operation of arity 0, and hence call it ''nullary''.

Also, in non-[[functional programming]], a function without arguments can be meaningful and not necessarily constant (due to [[side effect (computer science)|side effect]]s). Often, such functions have in fact some ''hidden input'' which might be [[global variable]]s, including the whole state of the system (time, free memory, ...). The latter are important examples which usually also exist in "purely" functional programming languages.

===Unary===
Examples of [[unary operator]]s in mathematics and in programming include the unary minus and plus, the increment and decrement operators in [[C (programming language)|C]]-style languages (not in logical languages), and the [[Successor function|successor]], [[factorial]], [[Multiplicative inverse|reciprocal]], [[floor function|floor]], [[ceiling function|ceiling]], [[fractional part]], [[sign (mathematics)|sign]], [[absolute value]], [[square root]] (the principal square root), [[complex conjugate]] (unary of "one" complex number, that however has two parts at a lower level of abstraction), and [[Norm (mathematics)|norm]] functions in mathematics. The [[two's complement]], [[Reference (computer science)|address reference]] and the [[logical NOT]] operators are examples of unary operators in math and programming.

All functions in [[lambda calculus]] and in some [[functional programming language]]s (especially those descended from [[ML (programming language)|ML]]) are technically unary, but see [[#n-ary|n-ary]] below.

According to [[Willard Van Orman Quine|Quine]], the Latin distributives being ''singuli, bini, terni,'' and so forth, the term "singulary" is the correct adjective, rather than "unary."&lt;ref&gt;{{Citation
  | last = Quine
  | first = W. V. O.
  | title = Mathematical logic
  | year = 1940
  | place = Cambridge, Massachusetts
  | publisher = Harvard University Press
  | page=13
 }}&lt;/ref&gt;
[[Abraham Robinson]] follows Quine's usage.&lt;ref&gt;{{Citation
  | last = Robinson
  | first = Abraham
  | title = "Non-standard Analysis"
  | year = 1966
  | place = Amsterdam
  | publisher = North-Holland
  | page=19
}}&lt;/ref&gt;

===Binary===
Most operators encountered in programming and mathematics are of the [[binary operation|binary]] form. For both programming and mathematics these can be the [[multiplication operator]], the radix operator, the often omitted [[exponentiation]] operator, the [[logarithm]] operator, the addition operator, the division operator. Logical predicates such as ''OR'', ''[[exclusive or|XOR]]'', ''AND'', ''IMP'' are typically used as binary operators with two distinct operands. In [[Complex instruction set computing|CISC]] architectures, it's common to have two source operands (and store result in one of them).

===Ternary===
Common ternary operations besides generic function in mathemathics are the [[summatory]] and the [[productory]] though some other n-ary operation may be implied.

The computer programming language  [[C (programming language)|C]] and its various descendants (including [[C++]], [[C Sharp (programming language)|C#]], [[Java (programming language)|Java]], [[Julia (programming language)|Julia]], [[Perl]], and others) provides the [[ternary operator]] &lt;code&gt;[[?:]]&lt;/code&gt;, also known as the [[conditional operator]], taking three operands. The first operand (the condition) is evaluated, and if it is true, the result of the entire expression is the value of the second operand, otherwise it is the value of the third operand. The [[Forth (programming language)|Forth]] language also contains a ternary operator, &lt;code&gt;*/&lt;/code&gt;, which multiplies the first two (one-cell) numbers, dividing by the third, with the intermediate result being a double cell number. This is used when the intermediate result would overflow a single cell. The [[Python (programming language)|Python]] language has a ternary conditional expression, &lt;code&gt;x if C else y&lt;/code&gt;. The Unix [[dc (computer program)|dc calculator]] has several ternary operators, such as &lt;code&gt;|&lt;/code&gt;, which will pop three values from the stack and efficiently compute &lt;math display="inline"&gt;x^y \bmod z&lt;/math&gt; with [[arbitrary-precision arithmetic|arbitrary precision]]. Additionally, many ([[Reduced instruction set computing|RISC]]) [[assembly language]] instructions are ternary (as opposed to only two operands specified in CISC); or higher, such as &lt;source lang="asm" inline&gt;MOV %AX, (%BX, %CX)&lt;/source&gt;, which will load (MOV) into register {{mono|AX}} the contents of a calculated memory location that is the sum (parenthesis) of the registers {{mono|BX}} and {{mono|CX}}.
&lt;!-- examples section needs complete rewrite, with links and subsection on math, logic and programming --&gt;

===''n''-ary===
From a mathematical point of view, a function of ''n'' arguments can always be considered as a function of one single argument which is an element of some [[product space]]. However, it may be convenient for notation to consider ''n''-ary functions, as for example [[multilinear map]]s (which are not linear maps on the product space, if ''n''≠1).

The same is true for programming languages, where functions taking several arguments could always be defined as functions taking a single argument of some [[object composition|composite type]] such as a [[tuple]], or in languages with [[higher-order function]]s, by [[currying]].

===Variable arity===
In computer science, a function accepting a variable number of arguments is called ''[[variadic function|variadic]]''. In logic and philosophy, predicates or relations accepting a variable number of arguments are called ''[[multigrade predicate|multigrade]]'', anadic, or variably polyadic.&lt;ref&gt;{{Cite journal | doi = 10.1093/mind/113.452.609 | last1 = Oliver | first1 = Alex | year = 2004 | title = Multigrade Predicates | url = | journal = Mind | volume = 113 | issue = | pages = 609–681 }}&lt;/ref&gt;

==Other names==
There are Latinate names for specific arities, primarily based on Latin [[distributive number]]s meaning "in group of ''n''", though some are based on [[cardinal number]]s or [[ordinal number]]s. Only ''binary'' and ''ternary'' are both commonly used and derived from distributive numbers.

* ''Nullary'' means 0-ary (from ''nūllus'').
* ''[[Unary operation|Unary]]'' means 1-ary (from cardinal ''unus'', rather than ''singulary'' from distributive ''singulī'').
* ''[[Binary operation|Binary]]'' means 2-ary.
* ''[[Ternary operation|Ternary]]'' means 3-ary.
* ''Quaternary'' means 4-ary.
* ''Quinary'' means 5-ary.
* ''Senary'' means  6-ary.
* ''Septenary'' means 7-ary.
* ''Octonary'' means 8-ary (alternatively ''octary'').
* ''Novenary'' means 9-ary (alternatively ''nonary'', from ordinal).
* ''Denary'' means 10-ary (alternatively ''decenary'')
* ''Polyadic'', ''multary'' and ''multiary'' mean 2 or more operands (or parameters).
* ''n''-''ary'' means ''n'' operands (or parameters), but is often used as a synonym of "polyadic".

So we can use any [[decimal prefix|decimal]] [[unit prefix]] to expand the concept to [[Yotta-|yotta]]&lt;nowiki/&gt;nary (10&lt;sup&gt;24&lt;/sup&gt;-ary) or [[googolplex]]&lt;nowiki/&gt;anary (10{{sup|10{{sup|100}}}}-ary), but no usage has been found for this yet.

An alternative nomenclature is derived in a similar fashion from the corresponding [[Greek language|Greek]] roots; for example, ''niladic'' (or ''medadic''), ''monadic'', ''dyadic'', ''triadic'', ''polyadic'', and so on.  Thence derive the alternative terms ''adicity'' and ''adinity'' for the Latin-derived ''arity''.

These words are often used to describe anything related to that number (e.g., [[undenary chess]] is a [[chess variant]] with an 11×11 board, or the [[Millenary Petition]] of 1603).

==See also==
{{Portal|Mathematics|Logic}}
{{Div col|colwidth=30em}}
* [[Logic of relatives]]
* [[Binary relation]]
* [[Triadic relation]]
* [[Theory of relations]]
* [[Signature (logic)]]
* [[Parameter]]
* [[Cardinality]]
* [[Valency (linguistics)|Valency]]
* [[n-ary code|''n''-ary code]]
* [[n-ary group|''n''-ary group]]
{{colend}}

==References==
{{Reflist}}

==External links==
{{wiktionary|Appendix:English arities and adicities}}
A monograph available free online:

* Burris, Stanley N., and H.P. Sankappanavar, H. P., 1981. ''[http://www.thoralf.uwaterloo.ca/htdocs/ualg.html A Course in Universal Algebra.]''  Springer-Verlag. {{ISBN|3-540-90578-2}}. Especially pp.&amp;nbsp;22–24.

[[Category:Abstract algebra]]
[[Category:Universal algebra]]

[[cs:Operace (matematika)#Arita operace]]</text>
      <sha1>74geg2ihyfoih7xwcoekasx84t8c2sh</sha1>
    </revision>
  </page>
  <page>
    <title>Binary clock</title>
    <ns>0</ns>
    <id>650189</id>
    <revision>
      <id>869827541</id>
      <parentid>869826159</parentid>
      <timestamp>2018-11-20T16:58:02Z</timestamp>
      <contributor>
        <username>BBCLCD</username>
        <id>14810604</id>
      </contributor>
      <comment>rearranged images</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4226">{{inline citations|date=February 2015}}
A '''binary clock''' is a [[clock]] that displays the time of day in a [[binary numeral system|binary]] format.  Originally, such clocks showed ''each decimal digit'' of sexagesimal time as a binary value, but presently binary clocks also exist which display hours, minutes, and seconds as binary numbers. Most binary clocks are [[Digital data|digital]], although [[analog signal|analog]] varieties exist. True binary clocks also exist, which indicate the time by successively halving the day, instead of using hours, minutes, or seconds. Similar clocks, based on [[Gray code]]d binary, also exist. 

== Binary-coded decimal clocks ==
[[File:Binary clock.svg|thumbnail|right|Reading a [[binary-coded decimal|BCD]] [[clock]]: Add the values of each column of [[Light-emitting diode|LEDs]] to get six decimal digits. There are two columns each for [[hour]]s, [[minute]]s and [[second]]s.]]
[[File:Digital-BCD-clock.jpg|thumbnail|right|Both clocks read 12:15:45.]]

Most common binary clocks  use six columns of [[LED]]s to represent [[0 (number)|zeros]] and [[1 (number)|ones]]. Each column represents a single decimal digit, a format known as [[binary-coded decimal]] (BCD). The bottom row in each column represents 1 (or 2&lt;sup&gt;0&lt;/sup&gt;), with each row above representing higher powers of two, up to 2&lt;sup&gt;3&lt;/sup&gt; (or 8). 

To read each individual digit in the time, the user adds the values that each illuminated [[light-emitting diode|LED]] represents, then reads these from left to right. The first two columns represent the [[hour]], the next two represent the [[minute]] and the last two represent the [[second]]. Since zero digits are not illuminated, the positions of each digit must be memorized if the clock is to be usable in the dark.

== Binary-coded sexagesimal clocks ==

[[File:Binary clock samui moon.jpg|thumbnail|right|Time Technology's Samui Moon binary-coded sexagesimal wristwatch. This clock reads 3:25.]]

Binary clocks that display time in binary-coded [[sexagesimal]] also exist. Instead of representing each digit of traditional sexagesimal time with one binary number, each component of traditional sexagesimal time is represented with one binary number, that is, using up to 6 bits instead of only 4.

For 24-hour binary-coded sexagesimal clocks, there are 11 or 17 LED lights to show us the time.  There are 5 LEDs to show the hours, there are 6 LEDs to show the minutes, and there are 6 LEDs to show the seconds. 6 LEDs to show the seconds are not needed in 24-hour binary-coded sexagesimal clocks with 11 LED lights.

{| class="wikitable" style="text-align: center;"
|-
| 
! Hours
! Minutes
! Seconds
|-
! 32
|  
| 1
| 1
|-
! 16
| 0
| 0
| 1
|-
! 8
| 1
| 0
| 0
|-
! 4
| 0
| 1
| 0
|-
! 2
| 1
| 0
| 0
|-
! 1
| 0
| 1
| 1
|-
| 
! 10
! 37
! 49
|}

[[File:Binary clock Swiss railway station.jpg|thumbnail|right|Binary large-scale electronic clock to indicate the time of day on 3 lines in hours, minutes, seconds on the face of the main railway station in St. Gallen, Switzerland. Time indicated is 9 o'clock 25 minutes 46 seconds.]]
A format exists also where hours, minutes and seconds are shown on three lines instead of columns as binary numbers.&lt;ref&gt;[https://www.tagblatt.ch/ostschweiz/stgallen-gossau-rorschach/stgallen-verpassen-sie-den-zug-oder-koennen-sie-eine-binaer-uhr-lesen-ld.1013362 ''Verpassen Sie den Zug oder koennen Sie eine Binaer-Uhr lesen?''] (in German), St. Galler Tagblatt, 4 April 2018. Retrieved 20 November 2018.&lt;/ref&gt;

== See also ==
* [[Hexadecimal time]]

==References==
{{Reflist}}

== External links ==
* [http://www.glassgiant.com/geek/binaryclock/binary_clock_flash.swf Binary clock made in Flash]
* [http://public.tembolab.pl/?dir=applications/binary-clocks Binary clocks as applications] (for Windows)
* [http://www.abulsme.com/binarytime/ "True" binary clock] — portrays time of day as a sequence of 16 bits
* [http://scratch.mit.edu/projects/23808257/ Colorful binary clock] - A colorful binary clock on Scratch
* [https://flyinghyrax.deviantart.com/art/Binary-Clock-266686125] - Binary Clock for Rainmeter by FlyingHyrax
[[Category:Clock designs]]
[[Category:Time measurement systems]]
[[Category:Binary arithmetic|Clock]]</text>
      <sha1>s2t9kk5pud3ott9o0tdvh4n7um1qa3f</sha1>
    </revision>
  </page>
  <page>
    <title>Carl Friedrich Gauss</title>
    <ns>0</ns>
    <id>6125</id>
    <revision>
      <id>870482247</id>
      <parentid>870482205</parentid>
      <timestamp>2018-11-25T03:12:18Z</timestamp>
      <contributor>
        <ip>2600:1700:6550:2160:4D1B:66FB:C149:2989</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="66758">{{Short description|German mathematician and physicist}}
{{redirect|Gauss|other persons or things named Gauss|Gauss (disambiguation)}}
{{pp-pc1}}
{{Use dmy dates|date=July 2017}}
{{Infobox scientist
| image = Carl Friedrich Gauss 1840 by Jensen.jpg
| caption = Carl Friedrich Gauß (1777–1855), painted by [[Christian Albrecht Jensen]]
| birth_name = Johann Carl Friedrich Gauss
| birth_date = {{birth date|df=yes|1777|4|30}}
| birth_place = [[Braunschweig|Brunswick]], [[Principality of Brunswick-Wolfenbüttel]]
| death_date = {{death date and age|df=yes|1855|2|23|1777|4|30}}
| death_place = [[Göttingen]], [[Kingdom of Hanover]], [[German Confederation]]
| residence = [[Kingdom of Hanover]]
| citizenship =
| nationality = German
| fields = [[Mathematics]] and [[physics]]
| workplaces = [[University of Göttingen]]
| alma_mater = [[Braunschweig University of Technology|Collegium Carolinum]], [[University of Göttingen]], [[University of Helmstedt]]
| thesis_title = Demonstratio nova...
| thesis_url = http://www.e-rara.ch/zut/content/titleinfo/1336299
| thesis_year = 1799
| doctoral_advisor = [[Johann Friedrich Pfaff]]
| academic_advisors = [[Johann Christian Martin Bartels]]
| doctoral_students = [[Johann Benedict Listing|Johann Listing]]&lt;br /&gt;[[Christian Ludwig Gerling]]&lt;br /&gt;[[Richard Dedekind]]&lt;br /&gt;[[Bernhard Riemann]]&lt;br /&gt;[[Christian Heinrich Friedrich Peters|Christian Peters]]&lt;br /&gt;[[Moritz Cantor]]
| notable_students = [[Johann Franz Encke|Johann Encke]]&lt;br /&gt;[[Christoph Gudermann]]&lt;br /&gt;[[Peter Gustav Lejeune Dirichlet]]&lt;br /&gt;[[Gotthold Eisenstein]]&lt;br /&gt;[[Carl Wolfgang Benjamin Goldschmidt]]&lt;br /&gt;[[Gustav Kirchhoff]]&lt;br /&gt;[[Ernst Kummer]]&lt;br /&gt;[[August Ferdinand Möbius]]&lt;br /&gt;[[L. C. Schnürlein]]&lt;br /&gt;[[Julius Weisbach]]&lt;br /&gt;[[Sophie Germain]] (epistolary correspondent)
| known_for = [[List of topics named after Carl Friedrich Gauss|See full list]]
| influences =
| influenced = [[Ferdinand Minding]]
| awards = [[Lalande Prize]] (1809)&lt;br /&gt;[[Copley Medal]] (1838)
| signature = Carl Friedrich Gauß signature.svg
| footnotes =
}}
'''Johann Carl Friedrich Gauss''' ({{IPAc-en|ɡ|aʊ|s}}; {{lang-de|Gauß}} {{IPA-de|ˈkaɐ̯l ˈfʁiːdʁɪç ˈɡaʊs||De-carlfriedrichgauss.ogg}};&lt;ref&gt;{{cite book|author1=Dudenredaktion|last2=Kleiner|first2=Stefan|last3=Knöbl|first3=Ralf|year=2015|orig-year=First published 1962|title=Das Aussprachewörterbuch|trans-title=The Pronunciation Dictionary|url=https://books.google.com/books?id=T6vWCgAAQBAJ|language=German|edition=7th|location=Berlin|publisher=Dudenverlag|isbn=978-3-411-04067-4|pp=246, 381, 391}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last1=Krech|first1=Eva-Maria|last2=Stock|first2=Eberhard|last3=Hirschfeld|first3=Ursula|last4=Anders|first4=Lutz Christian|title=Deutsches Aussprachewörterbuch|trans-title=German Pronunciation Dictionary|url=https://books.google.com/books?id=E-1tr_oVkW4C&amp;dq=deutsches+ausspracheworterbuch&amp;source=gbs_navlinks_s|language=German|year=2009|publisher=Walter de Gruyter|location=Berlin|isbn=978-3-11-018202-6|pp=402, 520, 529}}&lt;/ref&gt; {{lang-la|Carolus Fridericus Gauss}}; (30 April 1777{{spaced ndash}}23 February 1855) was a [[German mathematician]] and physicist who made significant contributions to many fields in mathematics and sciences.&lt;ref&gt;{{cite web |title=Gauss, Carl Friedrich |url=https://www.encyclopedia.com/people/science-and-technology/mathematics-biographies/carl-friedrich-gauss#2830901590 |website=Encyclopedia.com |accessdate=17 September 2018}}&lt;/ref&gt; Sometimes referred to as the ''Princeps mathematicorum''&lt;ref&gt;{{cite book
 |last=Zeidler
 |first=Eberhard
 |title=[[Oxford Users' Guide to Mathematics]]
 |location=Oxford, UK
 |publisher=[[Oxford University Press]]
 |year=2004
 |isbn=0-19-850763-1
 |page=1188
 }}&lt;/ref&gt; ({{Language with name/for|2=Latin|3="the foremost of mathematicians"}}) and "the greatest mathematician since antiquity", Gauss had an exceptional influence in many fields of mathematics and science, and is ranked among history's most influential mathematicians.&lt;ref name="scientificmonthly"&gt;Dunnington, G. Waldo. (May 1927).{{cite journal |url=http://www.mathsong.com/cfgauss/Dunnington/1927/  |title=The Sesquicentennial of the Birth of Gauss | journal=Scientific Monthly | volume=24 |pages=402–414| jstor=7912 |deadurl=bot: unknown |archiveurl=https://web.archive.org/web/20080226020629/http://www.mathsong.com/cfgauss/Dunnington/1927/ |archivedate=26 February 2008 |df= }}  Also available at {{cite web|url=http://gausschildren.org/genwiki/index.php?title=The_Sesquicentennial_of_the_Birth_of_Gauss |title=The Sesquicentennial of the Birth of Gauss }} Retrieved 23 February 2014. Comprehensive biographical article.&lt;/ref&gt;

==Personal life==
=== Early years ===
[[File:Statue-of-Gauss-in-Braunschweig.jpg|left|thumb|Statue of Gauss at his birthplace, [[Braunschweig|Brunswick]]]]
Johann Carl Friedrich Gauss was born on 30 April 1777 in [[Braunschweig|Brunswick (Braunschweig)]], in the [[Duchy of Brunswick-Wolfenbüttel]] (now part of [[Lower Saxony]], Germany), to poor, working-class parents.&lt;ref name="wichita state"&gt;{{cite web |url=http://www.math.wichita.edu/history/men/gauss.html|title=Carl Friedrich Gauss|publisher=Wichita State University }}&lt;/ref&gt; His mother was illiterate and never recorded the date of his birth, remembering only that he had been born on a Wednesday, eight days before the [[Ascension of Jesus|Feast of the Ascension]] (which occurs 39 days after Easter). Gauss later solved this puzzle about his birthdate in the context of [[Computus|finding the date of Easter]], deriving methods to compute the date in both past and future years.&lt;ref&gt;{{cite web|url=http://american_almanac.tripod.com/gauss.htm|title=Gauss Birthday Problem}}&lt;/ref&gt; He was christened and [[Confirmation|confirmed]] in a church near the school he attended as a child.&lt;ref&gt;{{cite web|author=Susan Chamberless |url=http://www.gausschildren.org/genwiki/index.php?title=Letter:WORTHINGTON,_Helen_to_Carl_F._Gauss_-_1911-07-26 |title=Letter:WORTHINGTON, Helen to Carl F. Gauss – 26 July 1911 |publisher=Susan D. Chambless |date=11 March 2000 |accessdate=14 September 2011}}&lt;/ref&gt;

Gauss was a [[child prodigy]]. In his memorial on Gauss, [[Wolfgang Sartorius von Waltershausen]] says that when Gauss was barely three years old he corrected a math error his father made; and that when he was seven, he confidently solved an [[Arithmetic progression|arithmetic series]] problem faster than anyone else in his class of 100 students.&lt;ref&gt;Waltershausen, Wolfgang Sartorius von (1856). Gauss zum Gedächtniss. p. 12 https://archive.org/details/bub_gb_h_Q5AAAAcAAJ.&lt;/ref&gt; Many versions of this story have been retold since that time with various details regarding what the series was - the most frequent being the classical problem of adding all the integers from 1 to 100.&lt;ref name=":0"&gt;{{Cite book|url=https://www.worldcat.org/oclc/41497065|title=Math and mathematicians : the history of math discoveries around the world|last=Bruno|first=Leonard C.|date=2003|origyear=1999|publisher=U X L|others=Baker, Lawrence W.|year=|isbn=0787638137|location=Detroit, Mich.|pages=178|oclc=41497065}}&lt;/ref&gt;&lt;ref&gt;"Gauss, Carl Friedrich (1777–1855)." (2014). In The Hutchinson Dictionary of scientific biography. Abington, United Kingdom: Helicon.&lt;/ref&gt;&lt;ref name="hayesreckoning"&gt;{{cite web|author=Brian Hayes |url=http://www.americanscientist.org/issues/pub/gausss-day-of-reckoning/ |title=Gauss's Day of Reckoning|doi=10.1511/2006.3.200 |publisher=American Scientist |date=14 November 2009 |accessdate=30 October 2012}}&lt;/ref&gt; There are many other anecdotes about his precocity while a toddler, and he made his first groundbreaking mathematical discoveries while still a teenager. He completed his [[masterpiece|magnum opus]], ''[[Disquisitiones Arithmeticae]]'', in 1798, at the age of 21—though it was not published until 1801.&lt;ref name=":1" /&gt; This work was fundamental in consolidating number theory as a discipline and has shaped the field to the present day.

Gauss's intellectual abilities attracted the attention of the [[Charles William Ferdinand, Duke of Brunswick|Duke of Brunswick]],&lt;ref name=":0" /&gt;&lt;ref name="scientificmonthly"/&gt; who sent him to the Collegium Carolinum (now [[Braunschweig University of Technology]]),&lt;ref name=":0" /&gt; which he attended from 1792 to 1795,&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/41497065|title=Math and mathematicians : the history of math discoveries around the world|last=Bruno|first=Leonard C.|date=2003|origyear=1999|publisher=U X L|others=Baker, Lawrence W.|year=|isbn=0787638137|location=Detroit, Mich.|pages=178–9|oclc=41497065}}&lt;/ref&gt; and to the [[Georg-August University of Göttingen|University of Göttingen]] from 1795 to 1798.&lt;ref name=":1"&gt;{{Cite book|url=https://www.worldcat.org/oclc/41497065|title=Math and mathematicians : the history of math discoveries around the world|last=Bruno|first=Leonard C.|date=2003|origyear=1999|publisher=U X L|others=Baker, Lawrence W.|year=|isbn=0787638137|location=Detroit, Mich.|pages=179|oclc=41497065}}&lt;/ref&gt;
While at university, Gauss independently rediscovered several important theorems.&lt;ref&gt;{{MacTutor Biography|id=Gauss}}&lt;/ref&gt; His breakthrough occurred in 1796 when he showed that a regular [[polygon]] can be constructed by [[Compass and straightedge constructions|compass and straightedge]] if the number of its sides is the product of distinct [[Fermat number|Fermat primes]] and a [[exponentiation|power]] of 2.&lt;ref&gt;Gauss stated without proof that this condition was also necessary, but never published his proof. A full proof of necessity was given by [[Pierre Wantzel]]. See the [[Constructible polygon]] article for further discussion.&lt;/ref&gt; This was a major discovery in an important field of mathematics; construction problems had occupied mathematicians since the days of the [[Ancient Greece|Ancient Greeks]], and the discovery ultimately led Gauss to choose mathematics instead of [[philology]] as a career.
Gauss was so pleased with this result that he requested that a regular [[heptadecagon]] be inscribed on his tombstone. The [[stone masonry|stonemason]] declined, stating that the difficult construction would essentially look like a circle.&lt;ref&gt;Pappas, Theoni, ''Mathematical Snippets'', 2008, p. 42.&lt;/ref&gt;

The year 1796 was more productive for both Gauss and number theory. He discovered a construction of the heptadecagon on 30 March.&lt;ref name=":1" /&gt;&lt;ref&gt;Carl Friedrich Gauss §§365–366 in ''[[Disquisitiones Arithmeticae]]''. Leipzig, Germany, 1801. New Haven, CT: [[Yale University Press]], 1965.&lt;/ref&gt; He further advanced [[modular arithmetic]], greatly simplifying manipulations in number theory. On 8 April he became the first to prove the [[quadratic reciprocity]] law. This remarkably general law allows mathematicians to determine the solvability of any quadratic equation in modular arithmetic. The [[prime number theorem]], conjectured on 31 May, gives a good understanding of how the [[prime number]]s are distributed among the integers.

Gauss also discovered that every positive integer is representable as a sum of at most three [[triangular number]]s on 10 July and then jotted down in [[Gauss's diary|his diary]] the note: "[[Eureka (word)|ΕΥΡΗΚΑ]]! {{nowrap|num {{=}} Δ + Δ' + Δ"}}. On 1 October he published a result on the number of solutions of polynomials with coefficients in [[finite field]]s, which 150 years later led to the [[Weil conjectures]].

=== Later years and death ===
[[File:Carl Friedrich Gauss on his Deathbed, 1855.jpg|thumb|Gauss on his deathbed (1855)]]
[[File:Grave of Carl Friedrich Gauß at Albani-Friedhof Göttingen 2017 02.jpg|thumb|Gauss's gravesite at [[Albanifriedhof|Albani Cemetery]] in [[Göttingen]], Germany]]
Gauss remained mentally active into his old age, even while suffering from [[gout]] and general unhappiness.&lt;ref name=":4" /&gt; For example, at the age of 62, he taught himself Russian.&lt;ref name=":4" /&gt;

In 1840, Gauss published his influential ''Dioptrische Untersuchungen'',&lt;ref name="Bühler1"&gt;{{Cite book|title=Gauss: a biographical study|first=Walter Kaufmann|last=Bühler|publisher=Springer-Verlag|year=1987|isbn=0-387-10662-6|ref=harv|pages=144–145}}&lt;/ref&gt; in which he gave the first systematic analysis on the formation of images under a [[paraxial approximation]] ([[Gaussian optics]]).&lt;ref name=Hecht&gt;{{Cite book|title=Optics|first=Eugene|last=Hecht|publisher=Addison Wesley|year=1987|isbn=0-201-11609-X|ref=harv|page=134}}&lt;/ref&gt; Among his results, Gauss showed that under a paraxial approximation an optical system can be characterized by its [[Cardinal point (optics)|cardinal points]]&lt;ref name=Bass&gt;{{Cite book|title=Handbook of Optics| first1=Michael|last1=Bass|first2=Casimer|last2=DeCusatis| first3=Jay|last3=Enoch|first4=Vasudevan|last4=Lakshminarayanan|publisher=McGraw Hill Professional|year=2009|isbn=0-07-149889-3|ref=harv|page=17.7}}&lt;/ref&gt; and he derived the Gaussian lens formula.&lt;ref name=Ostdiek&gt;{{Cite book|title=Inquiry into Physics |first1=Vern J. |last1=Ostdiek|first2=Donald J.|last2=Bord|publisher=Cengage Learning|year=2007|isbn=0-495-11943-1|ref=harv|page=381}}&lt;/ref&gt;

In 1845, he became an associated member of the Royal Institute of the Netherlands; when that became the [[Royal Netherlands Academy of Arts and Sciences]] in 1851, he joined as a foreign member.&lt;ref&gt;{{cite web|url=http://www.dwc.knaw.nl/biografie/pmknaw/?pagetype=authorDetail&amp;aId=PE00000342 |title=C.F. Gauss (1797–1855) |publisher=Royal Netherlands Academy of Arts and Sciences |accessdate=19 July 2015}}&lt;/ref&gt;

In 1854, Gauss selected the topic for [[Bernhard Riemann]]'s inaugural lecture "Über die Hypothesen, welche der Geometrie zu Grunde liegen" (''About the hypotheses that underlie Geometry'').&lt;ref name=Monastyrsky&gt;{{Cite book|title=Riemann, Topology, and Physics|first=Michael|last=Monastyrsky|publisher=Birkhäuser|year=1987|isbn=0-8176-3262-X|ref=harv|pages=21–22}}&lt;/ref&gt; On the way home from Riemann's lecture, Weber reported that Gauss was full of praise and excitement.&lt;ref name="Bühler2"&gt;{{Cite book|title=Gauss: a biographical study|first=Walter Kaufmann|last=Bühler|publisher=Springer-Verlag|year=1987|isbn=0-387-10662-6|ref=harv|page=154}}&lt;/ref&gt;

On 23 February 1855, Gauss died of a heart attack in Göttingen (then [[Kingdom of Hanover]] and now [[Lower Saxony]]);&lt;ref name="wichita state" /&gt;&lt;ref name=":4" /&gt; he is interred in the [[Albanifriedhof|Albani Cemetery]] there. Two people gave eulogies at his funeral: Gauss's son-in-law [[Heinrich Ewald]], and [[Wolfgang Sartorius von Waltershausen]], who was Gauss's close friend and biographer. Gauss's brain was preserved and was studied by [[Rudolf Wagner]], who found its mass to be slightly above average, at 1,492&amp;nbsp;grams, and the cerebral area equal to 219,588 square millimeters&lt;ref&gt;This reference from 1891 ({{cite journal
|last=Donaldson
|first=Henry H.
|title=Anatomical Observations on the Brain and Several Sense-Organs of the Blind Deaf-Mute, Laura Dewey Bridgman
|journal=The American Journal of Psychology
|volume=4
|issue=2
|pages=248–294
|publisher=E. C. Sanford
|year=1891
|doi=10.2307/1411270
|jstor=1411270}}) says: "Gauss, 1492 grm. 957 grm. 219588. sq. mm."; i.e. the unit is ''square mm''. In the later reference: Dunnington (1927), the unit is erroneously reported as square cm, which gives an unreasonably large area; the 1891 reference is more reliable.&lt;/ref&gt; (340.362 square inches). Highly developed convolutions were also found, which in the early 20th century were suggested as the explanation of his genius.&lt;ref name=bardi&gt;{{Cite book| last = Bardi | first = Jason | title = The Fifth Postulate: How Unraveling A Two Thousand Year Old Mystery Unraveled the Universe | publisher = John Wiley &amp; Sons, Inc. | year = 2008 | page = 189 | isbn = 978-0-470-46736-7}}&lt;/ref&gt;

=== Religious views ===
Gauss was a [[Lutheran]] [[Protestant]], a member of the St. Albans Evangelical Lutheran church in Göttingen.&lt;ref&gt;Guy Waldo Dunnington (1955). ''Carl Friedrich Gauss, Titan of Science: A Study of His Life and Work''. Exposition Press, pp. 300&lt;/ref&gt; Potential evidence that Gauss believed in God comes from his response after solving a problem that had previously defeated him: "Finally, two days ago, I succeeded—not on account of my hard efforts, but by the grace of the Lord."&lt;ref&gt;{{cite web|title=WikiQuotes|url=https://en.wikiquote.org/wiki/Carl_Friedrich_Gauss|website=WikiQuotes}}&lt;/ref&gt; One of his biographers, [[G. Waldo Dunnington]], described Gauss's religious views as follows:
&lt;blockquote&gt;For him science was the means of exposing the immortal nucleus of the human soul. In the days of his full strength, it furnished him recreation and, by the prospects which it opened up to him, gave consolation. Toward the end of his life, it brought him confidence. Gauss's God was not a cold and distant figment of metaphysics, nor a distorted caricature of embittered theology. To man is not vouchsafed that fullness of knowledge which would warrant his arrogantly holding that his blurred vision is the full light and that there can be none other which might report the truth as does his. For Gauss, not he who mumbles his creed, but he who lives it, is accepted. He believed that a life worthily spent here on earth is the best, the only, preparation for heaven. Religion is not a question of literature, but of life. God's revelation is continuous, not contained in tablets of stone or sacred parchment. A book is inspired when it inspires. The unshakeable idea of personal continuance after death, the firm belief in a last regulator of things, in an eternal, just, omniscient, omnipotent God, formed the basis of his religious life, which harmonized completely with his scientific research.&lt;ref&gt;Guy Waldo Dunnington (1955). ''Carl Friedrich Gauss, Titan of Science: A Study of His Life and Work''. Exposition Press, pp. 298–301&lt;/ref&gt;&lt;/blockquote&gt;

Apart from his correspondence, there are not many known details about Gauss's personal creed. Many biographers of Gauss disagree about his religious stance, with Bühler and others considering him a [[deism|deist]] with very unorthodox views,&lt;ref name=Buhler3/&gt;&lt;ref name="Gerhard Falk 1995 121"&gt;{{cite book|title=American Judaism in Transition: The Secularization of a Religious Community|year=1995|publisher=University Press of America|isbn=978-0-7618-0016-3|author=Gerhard Falk|page=121|quote=Gauss told his friend Rudolf Wagner, a professor of biology at Gottingen University, that he did not fully believe in the Bible but that he had meditated a great deal on the future of the human soul and speculated on the possibility of the soul being reincarnated on another planet. Evidently, Gauss was a Deist with a good deal of skepticism concerning religion but incorporating a great deal of philosophical interest in the Big Questions, that is. the immortality of the soul, the afterlife and the meaning of man's existence.}}&lt;/ref&gt;&lt;ref name="Bühler4"&gt;{{Cite book|title=Gauss: a biographical study|first=Walter Kaufmann|last=Bühler|publisher=Springer-Verlag|year=1987|isbn=0-387-10662-6|ref=harv|page=152|quote=Closely related to Gauss's political and social views were his religious beliefs. Despite his religious beliefs. Despite his strong roots in the Enlightenment, Gauss was not an atheist, rather a [[deism|deist]] with very unorthodox convictions, unorthodox even if measured against the very liberal persuasions of the contemporary Protestant church.}}&lt;/ref&gt; while Dunnington (though admitting that Gauss did not believe literally in all Christian dogmas and that it is unknown what he believed on most doctrinal and confessional questions) points out that he was, at least, a nominal [[Lutheran]].&lt;ref&gt;{{cite book|title=Carl Friedrich Gauss: Titan of Science|year=2004|publisher=MAA|isbn=9780883855478|page=305|author=Guy Waldo Dunnington|quote="It is not known just what Gauss believed on most doctrinal and confessional questions. He did not believe literally in all Christian dogmas. Officially he was a member of St. Albans Church (Evangelical Lutheran) in Gottingen. All baptisms, burials, and weddings in his family occurred there. It is also not known whether he attended church regularly or contributed financially. A faculty colleague called Gauss a deist, but there is good reason to believe that this label did not fit well. Gauss possessed strong religious tolerance which he carried over to every belief originating in the depths of the human heart. This tolerance is not to be confused with religious indifference. He took a special interest in the religious development of the human race, especially in his own century. With reference to the manifold denominations, which frequently did not agree with his views, he always emphasized that one is not justified in disturbing the faith of others in which they find consolation for earthly sufferings and a safe refuge in days of misfortune"}}&lt;/ref&gt;

In connection to this, there is a record of a conversation between [[Rudolf Wagner]] and Gauss, in which they discussed [[William Whewell]]'s book ''Of the Plurality of Worlds''. In this work, Whewell had discarded the possibility of existing life in other planets, on the basis of theological arguments, but this was a position with which both Wagner and Gauss disagreed. Later Wagner explained that he did not fully believe in the Bible, though he confessed that he "envied" those who were able to easily believe.&lt;ref name=Buhler3&gt;{{Cite book|title=Gauss: a biographical study|first=Walter Kaufmann|last=Bühler|publisher=Springer-Verlag|year=1987|isbn=0-387-10662-6|ref=harv|page=153}}&lt;/ref&gt;&lt;ref&gt;{{cite book|title=Carl Friedrich Gauss: Titan of Science|year=2004|publisher=MAA|isbn=9780883855478|page=305|author=Guy Waldo Dunnington|quote="league, I believe you are more believing in the Bible than I. I am not, and, he added, with the expression of great inner emotion, you are much happier than I. I must say that so often in earlier times when I saw people of the lower classes, simple manual laborers who could believe so rightly with their hearts, I always envied them, and now, he continued, with soft voice and that naive childlike manner peculiar to him, while a tear came to his eye, tell me how does one begin this?..."}}&lt;/ref&gt; This later led them to discuss the topic of [[faith]], and in some other religious remarks, Gauss said that he had been more influenced by theologians like Lutheran minister [[Paul Gerhardt]] than by [[Moses]].&lt;ref&gt;{{cite book|title=Carl Friedrich Gauss: Titan of Science|year=2004|publisher=MAA|isbn=9780883855478|page=356|author=Guy Waldo Dunnington|quote="I must confess that such old theologians and song writers as Paul Gerhard have always made a great impression on me; a song by Paul Gerhard always exerted a wonderful power on me, much more than, for example, Moses, against whom as a man of God I have all sorts of qualms."}}&lt;/ref&gt; Other religious influences included Wilhelm Braubach, [[Johann Peter Süssmilch]], and the [[New Testament]].&lt;ref&gt;{{cite book|title=Carl Friedrich Gauss: Titan of Science|year=2004|publisher=MAA|isbn=9780883855478|page=305|author=Guy Waldo Dunnington|quote=" Two religious works which Gauss read frequently were Braubach's ''Seelenlehre'' (Giessen, 1843) and Siissmilch's ''Gottliche'' (Ordnung gerettet A756); he also devoted considerable time to the New Testament in the original Greek.}}&lt;/ref&gt;

Dunnington further elaborates on Gauss's religious views by writing: &lt;blockquote&gt;Gauss's religious consciousness was based on an insatiable thirst for truth and a deep feeling of justice extending to intellectual as well as material goods. He conceived spiritual life in the whole universe as a great system of law penetrated by eternal truth, and from this source he gained the firm confidence that death does not end all.&lt;ref&gt;{{cite book|title=Carl Friedrich Gauss: Titan of Science|year=2004|publisher=MAA|isbn=978-0-88385-547-8|author1=Guy Waldo Dunnington|author2=Jeremy Gray|author3=Fritz-Egbert Dohse|page=300|quote=Gauss's religious consciousness was based on an insatiable thirst for truth and a deep feeling of justice extending to intellectual as well as material goods. He conceived spiritual life in the whole universe as a great system of law penetrated by eternal truth, and from this source, he gained the firm confidence that death does not end all.}}&lt;/ref&gt;&lt;/blockquote&gt;

Gauss declared he firmly believed in the [[afterlife]], and saw spirituality as something essentially important for human beings.&lt;ref&gt;{{cite book|title=Mathematics: The Loss of Certainty|year=1982|publisher=Oxford University Press|isbn=978-0-19-503085-3|author=Morris Kline|page=73}}&lt;/ref&gt; He was quoted stating: ''"The world would be nonsense, the whole creation an absurdity without immortality,"''&lt;ref&gt;Dunnington. 2004:357&lt;/ref&gt; and for this statement he was severely criticized by the atheist [[Karl Eugen Dühring|Eugen Dühring]] who judged him as a narrow superstitious man.&lt;ref&gt;Dunnington. 2004:359&lt;/ref&gt;

Though he was not a church-goer,&lt;ref&gt;{{cite web|title=Gauss, Carl Friedrich|url=http://www.encyclopedia.com/topic/Carl_Friedrich_Gauss.aspx|publisher=Complete Dictionary of Scientific Biography|accessdate=29 July 2012|year=2008|quote=In seeming contradiction, his religious and philosophical views leaned toward those of his political opponents. He was an uncompromising believer in the priority of empiricism in science. He did not adhere to the views of Kant, Hegel and other idealist philosophers of the day. He was not a churchman and kept his religious views to himself. Moral rectitude and the advancement of scientific knowledge were his avowed principles.}}&lt;/ref&gt; Gauss strongly upheld [[religious tolerance]], believing "that one is not justified in disturbing another's religious belief, in which they find consolation for earthly sorrows in time of trouble."&lt;ref name="scientificmonthly"/&gt; When his son Eugene announced that he wanted to become a Christian missionary, Gauss approved of this, saying that regardless of the problems within religious organizations, missionary work was "a highly honorable" task.&lt;ref&gt;Guy Waldo Dunnington (1955). ''Carl Friedrich Gauss, Titan of Science: A Study of His Life and Work''. Exposition Press, pp. 311&lt;/ref&gt;

=== Family ===
[[File:Therese Gauss.jpg|thumb|Gauss's daughter Therese (1816–1864)]]
On 9 October 1805,&lt;ref name=":2"&gt;{{Cite web|url=http://gausschildren.org/genwiki/index.php?title=GAUSS,_Carl_Friedrich_(1777-1855)|title=Person:GAUSS, Carl Friedrich (1777–1855) – Gauss's Children|website=gausschildren.org|language=en|access-date=2017-12-10}}&lt;/ref&gt; Gauss married Johanna Osthoff (1780–1809), and had a son and a daughter with her.&lt;ref name=":2" /&gt;&lt;ref name=":3"&gt;{{Cite book|url=https://www.worldcat.org/oclc/41497065|title=Math and mathematicians : the history of math discoveries around the world|last=Bruno|first=Leonard C.|date=2003|origyear=1999|publisher=U X L|others=Baker, Lawrence W.|year=|isbn=0787638137|location=Detroit, Mich.|pages=180|oclc=41497065}}&lt;/ref&gt; Johanna died on 11 October 1809,&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt;&lt;ref&gt;{{Cite web|url=https://www.ancestry.com/genealogy/records/johanna-elizabeth-osthoff_14646886|title=Johanna Elizabeth Osthoff 1780–1809 – Ancestry|website=www.ancestry.com|language=en-us|access-date=2017-12-10}}&lt;/ref&gt; and her most recent child, Louis, died the following year.&lt;ref name=":2" /&gt; Gauss plunged into a depression from which he never fully recovered. He then married Minna Waldeck (1788–1831)&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt; on 4 August 1810,&lt;ref name=":2" /&gt; and had three more children.&lt;ref name=":3" /&gt; Gauss was never quite the same without his first wife, so he, just like his father, grew to dominate his children.&lt;ref name=":3" /&gt; Minna Waldeck died on 12 September 1831.&lt;ref name=":2" /&gt;&lt;ref name=":3" /&gt;

Gauss had six children. With Johanna (1780–1809), his children were Joseph (1806–1873), Wilhelmina (1808–1846) and Louis (1809–1810). With Minna Waldeck he also had three children: Eugene (1811–1896), Wilhelm (1813–1879) and Therese (1816–1864). Eugene shared a good measure of Gauss's talent in languages and computation.&lt;ref name="gausschildren"&gt;{{cite web|url=http://www.gausschildren.org/genwiki/index.php?title=Letter:GAUSS,_Charles_Henry_to_Florian_Cajori_-_1898-12-21 |title=Letter: Charles Henry Gauss to Florian Cajori – 21 December 1898 |publisher=Susan D. Chambless |accessdate=14 September 2011 |date=11 March 2000}}&lt;/ref&gt; After his second wife's death in 1831 Therese took over the household and cared for Gauss for the rest of his life. His mother lived in his house from 1817 until her death in 1839.&lt;ref name="scientificmonthly"/&gt;

Gauss eventually had conflicts with his sons. He did not want any of his sons to enter mathematics or science for "fear of lowering the family name", as he believed none of them would surpass his own achievements.&lt;ref name="gausschildren" /&gt; Gauss wanted Eugene to become a lawyer, but Eugene wanted to study languages. They had an argument over a party Eugene held, which Gauss refused to pay for. The son left in anger and, in about 1832, emigrated to the United States, where he was quite successful. While working for the American Fur Company in the Midwest, he learned the Sioux language. Later, he moved to [[Missouri]] and became a successful businessman. Wilhelm also moved to America in 1837 and settled in Missouri, starting as a farmer and later becoming wealthy in the shoe business in [[St. Louis, Missouri|St. Louis]]. It took many years for Eugene's success to counteract his reputation among Gauss's friends and colleagues. See also [[s:Robert Gauss to Felix Klein - September 3, 1912|the letter from Robert Gauss to Felix Klein]] on 3 September 1912.

=== Personality ===
Carl Gauss was an ardent [[perfectionism (psychology)|perfectionist]] and a hard worker. He was never a prolific writer, refusing to publish work which he did not consider complete and above criticism. This was in keeping with his personal motto ''pauca sed matura'' ("few, but ripe"). His personal diaries indicate that he had made several important mathematical discoveries years or decades before his contemporaries published them. Scottish-American mathematician and writer [[Eric Temple Bell]] said that if Gauss had published all of his discoveries in a timely manner, he would have advanced mathematics by fifty years.&lt;ref&gt;{{cite book
 |last=Bell |first=E. T.
 |chapter=Ch. 14: The Prince of Mathematicians: Gauss
 |title=Men of Mathematics: The Lives and Achievements of the Great Mathematicians from Zeno to Poincaré
 |location=New York
 |publisher=Simon and Schuster
 |pages=218–269
 |year=2009
 |isbn=0-671-46400-0
 }}&lt;/ref&gt;

Though he did take in a few students, Gauss was known to dislike teaching. It is said that he attended only a single scientific conference, which was in [[Berlin]] in 1828. However, several of his students became influential mathematicians, among them [[Richard Dedekind]] and [[Bernhard Riemann]].

On Gauss's recommendation, [[Friedrich Bessel]] was awarded an honorary doctor degree from Göttingen in March 1811.&lt;ref&gt;Bessel never had a university education.&lt;/ref&gt; Around that time, the two men engaged in an epistolary correspondence.&lt;ref&gt;Helmut Koch, ''Introduction to Classical Mathematics I: From the Quadratic Reciprocity Law to the Uniformization Theorem'', Springer, p. 90.&lt;/ref&gt; However, when they met in person in 1825, they quarrelled; the details are unknown.&lt;ref&gt;Oscar Sheynin, [http://sheynin.de/download/hist_stat.pdf ''History of Statistics''], Berlin: NG Verlag Berlin, 2012, p. 88.&lt;/ref&gt;

Before she died, [[Sophie Germain]] was recommended by Gauss to receive her honorary degree; she never received it.&lt;ref&gt;Mackinnon, Nick (1990). "Sophie Germain, or, Was Gauss a feminist?". ''The Mathematical Gazette'' '''74''' (470): 346–351, esp. p. 347.&lt;/ref&gt;

Gauss usually declined to present the intuition behind his often very elegant proofs—he preferred them to appear "out of thin air" and erased all traces of how he discovered them.{{Citation needed|date=July 2007}} This is justified, if unsatisfactorily, by Gauss in his ''[[Disquisitiones Arithmeticae]]'', where he states that all analysis (i.e., the paths one traveled to reach the solution of a problem) must be suppressed for sake of brevity.

Gauss supported the monarchy and opposed [[Napoleon I of France|Napoleon]], whom he saw as an outgrowth of revolution.

Gauss summarized his views on the pursuit of knowledge in a letter to [[Farkas Bolyai]] dated 2 September 1808 as follows:&lt;blockquote&gt;It is not knowledge, but the act of learning, not possession but the act of getting there, which grants the greatest enjoyment. When I have clarified and exhausted a subject, then I turn away from it, in order to go into darkness again. The never-satisfied man is so strange; if he has completed a structure, then it is not in order to dwell in it peacefully, but in order to begin another. I imagine the world conqueror must feel thus, who, after one kingdom is scarcely conquered, stretches out his arms for others.&lt;ref&gt;{{Cite book|title=Carl Friedrich Gauss: Titan of Science|last=Dunnington|first=G. Waldo|publisher=|year=2004|isbn=|location=|pages=416}}&lt;/ref&gt;&lt;/blockquote&gt;

== Career and achievements ==
{{refimprove section|date=July 2012}}

===Algebra===
[[File:Disqvisitiones-800.jpg|thumb|Title page of Gauss's magnum opus, ''[[Disquisitiones Arithmeticae]]'']]
In his 1799 doctorate in absentia, ''A new proof of the theorem that every integral rational algebraic function of one variable can be resolved into real factors of the first or second degree'', Gauss proved the [[fundamental theorem of algebra]] which states that every non-constant single-variable [[polynomial]] with complex coefficients has at least one complex [[root of a function|root]]. Mathematicians including [[Jean le Rond d'Alembert]] had produced false proofs before him, and Gauss's dissertation contains a critique of d'Alembert's work. Ironically, by today's standard, Gauss's own attempt is not acceptable, owing to the implicit use of the [[Jordan curve theorem]]. However, he subsequently produced three other proofs, the last one in 1849 being generally rigorous. His attempts clarified the concept of complex numbers considerably along the way.

Gauss also made important contributions to [[number theory]] with his 1801 book ''[[Disquisitiones Arithmeticae]]'' ([[Latin]], Arithmetical Investigations), which, among other things, introduced the symbol {{math|≡}} for [[Congruence relation|congruence]] and used it in a clean presentation of [[modular arithmetic]], contained the first two proofs of the law of [[quadratic reciprocity]], developed the theories of binary and ternary [[quadratic form]]s, stated the [[class number problem]] for them, and showed that a regular [[heptadecagon]] (17-sided polygon) can be [[Compass and straightedge constructions|constructed with straightedge and compass]]. It appears that Gauss already knew the [[class number formula]] in 1801.&lt;ref&gt;http://mathoverflow.net/questions/109330/did-gauss-know-dirichlets-class-number-formula-in-1801&lt;/ref&gt;

In addition, he proved the following conjectured theorems:
* [[Fermat polygonal number theorem]] for ''n'' = 3
* [[Fermat's last theorem]] for ''n'' = 5
* [[Descartes's rule of signs]]
* [[Kepler conjecture]] for regular arrangements

He also
* explained the pentagramma mirificum (see [https://www.math.uni-bielefeld.de/~sek/cluster/pentagramma/ University of Bielefeld website])
* developed an algorithm for determining the [[Computus#Gauss algorithm|date of Easter]]
* invented the [[Cooley–Tukey FFT algorithm]] for calculating the [[discrete Fourier transform]]s 160 years before Cooley and Tukey

===Astronomy===
[[File:Bendixen - Carl Friedrich Gauß, 1828.jpg|thumb|Portrait of Gauss published in ''[[Astronomische Nachrichten]]'' (1828)]]
In the same year, Italian astronomer [[Giuseppe Piazzi]] discovered the [[dwarf planet]] [[Ceres (dwarf planet)|Ceres]]. Piazzi could only track Ceres for somewhat more than a month, following it for three degrees across the night sky. Then it disappeared temporarily behind the glare of the Sun. Several months later, when Ceres should have reappeared, Piazzi could not locate it: the mathematical tools of the time were not able to extrapolate a position from such a scant amount of data—three degrees represent less than 1% of the total orbit. Gauss heard about the problem and tackled it. After three months of intense work, he predicted a position for Ceres in December 1801—just about a year after its first sighting—and this turned out to be accurate within a half-degree when it was rediscovered by [[Franz Xaver von Zach]] on 31 December at [[Gotha Observatory|Gotha]], and one day later by [[Heinrich Wilhelm Matthäus Olbers|Heinrich Olbers]] in [[Bremen]].&lt;ref name=":1" /&gt;

[[Gauss's method]] involved determining a [[conic section]] in space, given one focus (the Sun) and the conic's intersection with three given lines (lines of sight from the Earth, which is itself moving on an ellipse, to the planet) and given the time it takes the planet to traverse the arcs determined by these lines (from which the lengths of the arcs can be calculated by [[Kepler's laws of planetary motion|Kepler's Second Law]]). This problem leads to an equation of the eighth degree, of which one solution, the Earth's orbit, is known. The solution sought is then separated from the remaining six based on physical conditions. In this work, Gauss used comprehensive approximation methods which he created for that purpose.&lt;ref&gt;{{cite book|title=Development of mathematics in the 19th century|last1=Klein|first1=Felix|last2=Hermann|first2=Robert |isbn=978-0-915692-28-6|year=1979|publisher=Math Sci Press}}&lt;/ref&gt;

One such method was the [[fast Fourier transform]]. While this method is traditionally attributed to a 1965 paper by [[J. W. Cooley]] and [[J. W. Tukey]],&lt;ref&gt;{{cite journal |last=Cooley |first=James W. |first2=John W. |last2=Tukey |title=An algorithm for the machine calculation of complex Fourier series |journal=[[Mathematics of Computation|Math. Comput.]] |volume=19 |issue= |pages=297–301 |year=1965 |doi=10.2307/2003354 }}&lt;/ref&gt; Gauss developed it as a trigonometric interpolation method. His paper, ''Theoria Interpolationis Methodo Nova Tractata'',&lt;ref&gt;{{cite book |last1=Gauss |first1=C.F. |date=1876| orig-year=n.d. | title= Theoria Interpolationis Methodo Nova Tractata | work=Carl Friedrich Gauss Werke| location=Göttingen |language=la|pages=265-327 |url=https://archive.org/stream/werkecarlf03gausrich#page/n277/mode/2up}}&lt;/ref&gt; was only published posthumously in Volume 3 of his collected works. This paper predates the first presentation by [[Joseph Fourier]] on the subject in 1807.&lt;ref&gt;{{cite journal|last=Heideman|first=M.|author2=Johnson, D.|author3=Burrus, C.|title=Gauss and the history of the fast fourier transform|journal=IEEE ASSP Magazine|year=1984|volume=1|issue=4|pages=14–21|doi=10.1109/MASSP.1984.1162257|url=http://www.cis.rit.edu/class/simg716/Gauss_History_FFT.pdf}}&lt;/ref&gt;

Zach noted that "without the intelligent work and calculations of Doctor Gauss we might not have found Ceres again". Though Gauss had up to that point been financially supported by his stipend from the Duke, he doubted the security of this arrangement, and also did not believe pure mathematics to be important enough to deserve support. Thus he sought a position in astronomy, and in 1807 was appointed Professor of Astronomy and Director of the astronomical [[Göttingen Observatory|observatory in Göttingen]], a post he held for the remainder of his life.

[[File:Normal Distribution PDF.svg|thumb|Four [[Gaussian distributions]]]]
The discovery of Ceres led Gauss to his work on a theory of the motion of planetoids disturbed by large planets, eventually published in 1809 as ''Theoria motus corporum coelestium in sectionibus conicis solem ambientum'' (Theory of motion of the celestial bodies moving in conic sections around the Sun). In the process, he so streamlined the cumbersome mathematics of 18th-century orbital prediction that his work remains a cornerstone of astronomical computation.&lt;ref&gt;Felix Klein, Vorlesungen über die Entwicklung der Mathematik im 19. Jahrhundert. Berlin: Julius Springer Verlag, 1926. &lt;/ref&gt; It introduced the [[Gaussian gravitational constant]], and contained an influential treatment of the [[Least squares|method of least squares]], a procedure used in all sciences to this day to minimize the impact of [[Observational error|measurement error]].

Gauss proved the method under the assumption of [[normal distribution|normally distributed]] errors (see [[Gauss–Markov theorem]]; see also [[List of topics named after Carl Friedrich Gauss|Gaussian]]). The method had been described earlier by [[Adrien-Marie Legendre]] in 1805, but Gauss claimed that he had been using it since 1794 or 1795.&lt;ref&gt;Oscar Sheynin, [http://sheynin.de/download/hist_stat.pdf ''History of Statistics''], Berlin: NG Verlag Berlin, 2012, p. 81.&lt;/ref&gt; In the history of statistics, this disagreement is called the "priority dispute over the discovery of the method of least squares."&lt;ref&gt;Stephen M. Stigler, "Gauss and the Invention of Least Squares," ''Ann. Statist.'', '''9'''(3), 1981, pp. 465–474.&lt;/ref&gt;

=== Geodetic survey ===
[[File:Gauß-Stein Garlste.jpg|thumb|[[Surveying|Geodetic survey]] stone in Garlste (now [[Garstedt|Garlstedt]])]]
In 1818 Gauss, putting his calculation skills to practical use, carried out a [[surveying|geodetic survey]] of the [[Kingdom of Hanover]], linking up with previous Danish surveys. To aid the survey, Gauss invented the [[heliotrope (instrument)|heliotrope]], an instrument that uses a mirror to reflect sunlight over great distances, to measure positions.

===Non-Euclidean geometries===
Gauss also claimed to have discovered the possibility of [[non-Euclidean geometry|non-Euclidean geometries]] but never published it. This discovery was a major paradigm shift in mathematics, as it freed mathematicians from the mistaken belief that Euclid's axioms were the only way to make geometry consistent and non-contradictory.

Research on these geometries led to, among other things, [[Albert Einstein|Einstein]]'s theory of general relativity, which describes the universe as non-Euclidean. His friend [[Farkas Bolyai|Farkas Wolfgang Bolyai]] with whom Gauss had sworn "brotherhood and the banner of truth" as a student, had tried in vain for many years to prove the parallel postulate from Euclid's other axioms of geometry.

Bolyai's son, [[János Bolyai]], discovered non-Euclidean geometry in 1829; his work was published in 1832. After seeing it, Gauss wrote to Farkas Bolyai: "To praise it would amount to praising myself. For the entire content of the work&amp;nbsp;... coincides almost exactly with my own meditations which have occupied my mind for the past thirty or thirty-five years."

This unproved statement put a strain on his relationship with Bolyai who thought that Gauss was "stealing" his idea.&lt;ref name="Krantz2010"&gt;{{cite book|author=Steven G. Krantz|title=An Episodic History of Mathematics: Mathematical Culture through Problem Solving|url=https://books.google.com/books?id=ulmAH-6IzNoC&amp;pg=PA171|accessdate=9 February 2013|date=1 April 2010|publisher=MAA|isbn=978-0-88385-766-3|pages=171–}}&lt;/ref&gt;

Letters from Gauss years before 1829 reveal him obscurely discussing the problem of parallel lines. [[G. Waldo Dunnington|Waldo Dunnington]], a biographer of Gauss, argues in ''Gauss, Titan of Science'' that Gauss was in fact in full possession of non-Euclidean geometry long before it was published by Bolyai, but that he refused to publish any of it because of his fear of controversy.&lt;ref&gt;{{cite journal|last1=Halsted|first1=G. B.|title=Duncan M. Y. Sommerville|journal=American Mathematical Monthly|year=1912|volume=19|pages=1–4|doi=10.2307/2973871|jstor=2973871}}&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Sondow|first1=J.|title=From the ''Monthly'' Over 100 Years Ago…|journal=American Mathematical Monthly|year=2014|volume=121|issue=10|pages=963|doi=10.4169/amer.math.monthly.121.10.963|url=https://arxiv.org/pdf/1405.4198|arxiv=1405.4198}}[https://www.jstor.org/stable/10.4169/amer.math.monthly.121.10.963 jstor.org] [https://arxiv.org/abs/1405.4198 arXiv] "Gauss and the eccentric Halsted".&lt;/ref&gt;

===Theorema Egregium===
The geodetic survey of Hanover, which required Gauss to spend summers traveling on horseback for a decade,&lt;ref&gt;[http://www.keplersdiscovery.com/Gauss.html The Prince of Mathematics]. The Door to Science by keplersdiscovery.com.&lt;/ref&gt; fueled Gauss's interest in [[differential geometry]] and [[topology]], fields of mathematics dealing with [[curve]]s and [[Surface (topology)|surfaces]]. Among other things, he came up with the notion of [[Gaussian curvature]].
This led in 1828 to an important theorem, the [[Theorema Egregium]] (''remarkable theorem''), establishing an important property of the notion of [[curvature]]. Informally, the theorem says that the curvature of a surface can be determined entirely by measuring [[angle]]s and [[distance]]s on the surface.

That is, curvature does not depend on how the surface might be [[embedding|embedded]] in 3-dimensional space or 2-dimensional space.

In 1821, he was made a foreign member of the [[Royal Swedish Academy of Sciences]]. Gauss was elected a Foreign Honorary Member of the [[American Academy of Arts and Sciences]] in 1822.&lt;ref name=AAAS&gt;{{cite web|title=Book of Members, 1780–2010: Chapter G|url=http://www.amacad.org/publications/BookofMembers/ChapterG.pdf|publisher=American Academy of Arts and Sciences|accessdate=8 September 2016}}&lt;/ref&gt;

===Magnetism===
In 1831, Gauss developed a fruitful collaboration with the physics professor [[Wilhelm Eduard Weber|Wilhelm Weber]], leading to new knowledge in [[magnetism]] (including finding a representation for the unit of magnetism in terms of mass, charge, and time) and the discovery of [[Kirchhoff's circuit laws]] in electricity.&lt;ref name=":4"&gt;{{Cite book|url=https://www.worldcat.org/oclc/41497065|title=Math and mathematicians : the history of math discoveries around the world|last=Bruno|first=Leonard C.|date=2003|origyear=1999|publisher=U X L|others=Baker, Lawrence W.|year=|isbn=0787638137|location=Detroit, Mich.|pages=181|oclc=41497065}}&lt;/ref&gt; It was during this time that he formulated his namesake [[Gauss's law|law]]. They constructed the first [[Electrical telegraph|electromechanical telegraph]] in 1833,&lt;ref name=":4" /&gt; which connected the observatory with the institute for physics in Göttingen. Gauss ordered a magnetic [[observatory]] to be built in the garden of the observatory, and with Weber founded the "Magnetischer Verein" (''magnetic association''), which supported measurements of Earth's magnetic field in many regions of the world. He developed a method of measuring the horizontal intensity of the magnetic field which was in use well into the second half of the 20th century, and worked out the mathematical theory for separating the inner and outer ([[magnetosphere|magnetospheric]]) sources of Earth's magnetic field.

==Appraisal==
The British mathematician [[Henry John Stephen Smith]] (1826–1883) gave the following appraisal of Gauss:
{{block quote|If we except the great name of [[Isaac Newton|Newton]] it is probable that no mathematicians of any age or country have ever surpassed Gauss in the combination of an abundant fertility of invention with an absolute rigorousness in demonstration, which the ancient Greeks themselves might have envied. It may seem paradoxical, but it is probably nevertheless true that it is precisely the efforts after logical perfection of form which has rendered the writings of Gauss open to the charge of obscurity and unnecessary difficulty. Gauss says more than once that, for brevity, he gives only the synthesis, and suppresses the analysis of his propositions. If, on the other hand, we turn to a memoir of [[Leonhard Euler|Euler]]'s, there is a sort of free and luxuriant gracefulness about the whole performance, which tells of the quiet pleasure which Euler must have taken in each step of his work. It is not the least of Gauss's claims to the admiration of mathematicians, that, while fully penetrated with a sense of the vastness of the science, he exacted the utmost rigorousness in every part of it, never passed over a difficulty, as if it did not exist, and never accepted a theorem as true beyond the limits within which it could actually be demonstrated.&lt;ref&gt;H.J.S Smith,''Presidential Address'', Proceedings of the London Math. Soc. VIII, 18.&lt;/ref&gt;}}

== Anecdotes ==
There are several stories of his early genius. According to one, his gifts became very apparent at the age of three when he corrected, mentally and without fault in his calculations, an error his father had made on paper while calculating finances.

Another story has it that in primary school after the young Gauss misbehaved, his teacher, J.G. Büttner, gave him a task: add a list of [[integer]]s in [[arithmetic progression]]; as the story is most often told, these were the numbers from 1 to 100. The young Gauss reputedly produced the correct answer within seconds, to the astonishment of his teacher and his assistant [[Johann Christian Martin Bartels|Martin Bartels]].

Gauss's presumed method was to realize that pairwise addition of terms from opposite ends of the list yielded identical intermediate sums: 1&amp;nbsp;+&amp;nbsp;100&amp;nbsp;=&amp;nbsp;101, 2&amp;nbsp;+&amp;nbsp;99&amp;nbsp;=&amp;nbsp;101, 3&amp;nbsp;+&amp;nbsp;98&amp;nbsp;=&amp;nbsp;101, and so on, for a [[Triangular number|total sum]] of 50&amp;nbsp;×&amp;nbsp;101&amp;nbsp;=&amp;nbsp;5050.
However, the details of the story are at best uncertain (see&lt;ref name="hayesreckoning" /&gt; for discussion of the original [[Wolfgang Sartorius von Waltershausen]] source and the changes in other versions); some authors, such as Joseph Rotman in his book ''A first course in Abstract Algebra'', question whether it ever happened.

According to [[Isaac Asimov]], Gauss was once interrupted in the middle of a problem and told that his wife was dying. He is purported to have said, "Tell her to wait a moment till I'm done."&lt;ref&gt;{{cite book
 |last=Asimov |first=I.
 |title=Biographical Encyclopedia of Science and Technology; the Lives and Achievements of 1195 Great Scientists from Ancient Times to the Present, Chronologically Arranged.
 |location=New York
 |publisher=Doubleday
 |year=1972
 |isbn=978-0385177719}}&lt;/ref&gt; This anecdote is briefly discussed in [[G. Waldo Dunnington]]'s ''Gauss, Titan of Science'' where it is suggested that it is an [[apocryphal]] story.

He referred to mathematics as "the queen of sciences"&lt;ref&gt;Quoted in Waltershausen, Wolfgang Sartorius von (1856, repr. 1965). Gauss zum Gedächtniss. Sändig Reprint Verlag H. R. Wohlwend. {{ISBN|3-253-01702-8}}&lt;/ref&gt; and supposedly once espoused a belief in the necessity of immediately understanding [[Euler's identity]] as a benchmark pursuant to becoming a first-class mathematician.&lt;ref name=First-Class&gt;{{cite book|last=Derbyshire|first=John|title=Prime Obsession: Bernhard Riemann and the Greatest Unsolved Problem in Mathematics|year=2003|publisher=Joseph Henry Press|location= Washington, DC|isbn=0-309-08549-7|page=202|url=https://books.google.com/books?id=qsoqLNQUIJMC&amp;q=first-class+mathematician#v=snippet&amp;q=first-class%20mathematician&amp;f=false}}&lt;/ref&gt;

== Commemorations ==
{{Main|List of things named after Carl Friedrich Gauss}}
[[File:10 DM Serie4 Vorderseite.jpg|thumb|German 10-[[Deutsche Mark]] [[Banknote]] (1993; discontinued) featuring Gauss]]
From 1989 through 2001, Gauss's portrait, a [[normal distribution curve]] and some prominent [[Göttingen]] buildings were featured on the German ten-mark banknote. The reverse featured the approach for [[Kingdom of Hanover|Hanover]]. Germany has also issued three postage stamps honoring Gauss. One (no. 725) appeared in 1955 on the hundredth anniversary of his death; two others, nos. 1246 and 1811, in 1977, the 200th anniversary of his birth.

[[Daniel Kehlmann]]'s 2005 novel ''Die Vermessung der Welt'', translated into English as ''[[Measuring the World]]'' (2006), explores Gauss's life and work through a lens of historical fiction, contrasting them with those of the German explorer [[Alexander von Humboldt]]. A film version directed by [[Detlev Buck]] was released in 2012.&lt;ref&gt;{{cite web|url=https://www.imdb.com/title/tt1571401/|title=Die Vermessung der Welt (2012) – Internet Movie Database|author=baharuka|date=25 October 2012|publisher=Internet Movie Database}}&lt;/ref&gt;

In 2007 a [[Bust (sculpture)|bust]] of Gauss was placed in the [[Walhalla temple]].&lt;ref&gt;{{cite web |url=http://www.stmwfk.bayern.de/downloads/aviso/2004_1_aviso_48-49.pdf |title=Bayerisches Staatsministerium für Wissenschaft, Forschung und Kunst: Startseite |publisher=Stmwfk.bayern.de |accessdate=19 July 2009 |archive-url=https://web.archive.org/web/20090325153748/http://www.stmwfk.bayern.de/downloads/aviso/2004_1_aviso_48-49.pdf |archive-date=25 March 2009 |dead-url=yes |df=dmy-all }}&lt;/ref&gt;

The [[List of things named after Carl Friedrich Gauss|numerous things named in honor of Gauss]] include:
* The [[Normal Distribution]], also known at the Gaussian distribution, the most common bell curve in statistics.
* The [[Gauss Prize]], one of the highest honors in mathematics
* [[Gauss (unit)|gauss]], the [[Centimetre gram second system of units|CGS unit]] for [[magnetic field]]

In 1929 the Polish mathematician [[Marian Rejewski]], who helped to solve the German [[Enigma machine|Enigma cipher machine]] in December 1932, began studying [[actuarial statistics]] at [[Göttingen]]. At the request of his [[Poznań University]] professor, [[Zdzisław Krygowski]], on arriving at Göttingen Rejewski laid flowers on Gauss's grave.&lt;ref&gt;[[Władysław Kozaczuk]], ''Enigma:  How the German Machine Cipher Was Broken, and How It Was Read by the Allies in World War Two'', Frederick, Maryland, University Publications of America, 1984, p. 7, note 6.&lt;/ref&gt;

On 30 April 2018, [[Google]] honoured Gauss in his would-be 241st birthday with a [[Google Doodle]] showcased in Europe, Russia, Israel, Japan, Taiwan, parts of Southern and Central America and the United States.&lt;ref&gt;{{Cite web|url=https://www.google.com/doodles/johann-carl-friedrich-gaus-241st-birthday|title=Johann Carl Friedrich Gauß’s 241st Birthday|website=www.google.com|language=en|access-date=2018-04-30}}&lt;/ref&gt;

Carl Friedrich Gauss, who also introduced the so called [[Gaussian logarithm]]s, sometimes gets confused with {{ill|Friedrich Gustav Gauss|de|Friedrich Gustav Gauß}} (1829–1915), a German geologist, who also published some well-known [[logarithm table]]s used up into the early 1980s.&lt;ref name="Kühn_2008"&gt;{{cite web |title=C. F. Gauß und die Logarithmen |language=German |author-first=Klaus |author-last=Kühn |location=Alling-Biburg, Germany |date=2008 |url=http://www.rechenschieber.org/Gauss.pdf |access-date=2018-07-14 |dead-url=no |archive-url=https://web.archive.org/web/20180714030921/http://www.rechenschieber.org/Gauss.pdf |archive-date=2018-07-14}}&lt;/ref&gt;

== Writings ==
* 1799: [[Doctoral dissertation]] on the [[fundamental theorem of algebra]], with the title: ''Demonstratio nova theorematis omnem functionem algebraicam rationalem integram unius variabilis in factores reales primi vel secundi gradus resolvi posse'' ("New proof of the theorem that every integral algebraic function of one variable can be resolved into real factors (i.e., polynomials) of the first or second degree")
* 1801: ''[[Disquisitiones Arithmeticae]]'' (Latin). A German translation by H. Maser {{Cite journal
  | title = Untersuchungen über höhere Arithmetik (Disquisitiones Arithmeticae &amp; other papers on number theory) (Second edition)
  | publisher = Chelsea
  | location = New York
  | year = 1965
  | isbn = 0-8284-0191-8
  | postscript = &lt;!--None--&gt;}}, pp.&amp;nbsp;1–453. English translation by Arthur A. Clarke {{Cite journal
  | title = Disquisitiones Arithmeticae (Second, corrected edition)
  | publisher = [[Springer Science+Business Media|Springer]]
  | location = New York
  | year = 1986
  | isbn = 0-387-96254-9
  | postscript = &lt;!--None--&gt;}}.
* 1808: {{Cite journal
    | title = Theorematis arithmetici demonstratio nova
  | publisher = Commentationes Societatis Regiae Scientiarum Gottingensis. 16
  | location = Göttingen
    | postscript = &lt;!--None--&gt; }}. German translation by H. Maser {{Cite journal
  | title = Untersuchungen über höhere Arithmetik (Disquisitiones Arithmeticae &amp; other papers on number theory) (Second edition)
  | publisher = Chelsea
  | location = New York
  | year = 1965
  | isbn = 0-8284-0191-8
  | postscript = &lt;!--None--&gt;}}, pp.&amp;nbsp;457–462 [Introduces [[Gauss's lemma (number theory)|Gauss's lemma]], uses it in the third proof of quadratic reciprocity]
* 1809: ''Theoria Motus Corporum Coelestium in sectionibus conicis solem ambientium'' (Theorie der Bewegung der Himmelskörper, die die Sonne in Kegelschnitten umkreisen), ''Theory of the Motion of Heavenly Bodies Moving about the Sun in Conic Sections'' (English translation by C. H. Davis), reprinted 1963, Dover, New York.
* 1811: {{Cite journal
    | title = Summatio serierun quarundam singularium
  | publisher = Commentationes Societatis Regiae Scientiarum Gottingensis
  | location = Göttingen
    | postscript = &lt;!--None--&gt; }}. German translation by H. Maser {{Cite journal
  | title = Untersuchungen über höhere Arithmetik (Disquisitiones Arithmeticae &amp; other papers on number theory) (Second edition)
  | publisher = Chelsea
  | location = New York
  | year = 1965
  | isbn = 0-8284-0191-8
  | postscript = &lt;!--None--&gt;}}, pp.&amp;nbsp;463–495 [Determination of the sign of the [[quadratic Gauss sum]], uses this to give the fourth proof of quadratic reciprocity]
* 1812: ''Disquisitiones Generales Circa Seriem Infinitam'' &lt;math&gt;1+\frac{\alpha\beta}{\gamma.1}+\mbox{etc.}&lt;/math&gt;
* 1818: {{Cite journal
    | title = Theorematis fundamentallis in doctrina de residuis quadraticis demonstrationes et amplicationes novae
  | publisher = Commentationes Societatis Regiae Scientiarum Gottingensis
  | location = Göttingen
    | postscript = &lt;!--None--&gt; }}. German translation by H. Maser {{Cite journal
  | title = Untersuchungen über höhere Arithmetik (Disquisitiones Arithmeticae &amp; other papers on number theory) (Second edition)
  | publisher = Chelsea
  | location = New York
  | year = 1965
  | isbn = 0-8284-0191-8
  | postscript = &lt;!--None--&gt;}}, pp.&amp;nbsp;496–510 [Fifth and sixth proofs of quadratic reciprocity]
* 1821, 1823 and 1826: ''Theoria combinationis observationum erroribus minimis obnoxiae''. Drei Abhandlungen betreffend die Wahrscheinlichkeitsrechnung als Grundlage des Gauß'schen Fehlerfortpflanzungsgesetzes. (Three essays concerning the calculation of probabilities as the basis of the Gaussian law of error propagation) English translation by G. W. Stewart, 1987, Society for Industrial Mathematics.
* 1827: ''Disquisitiones generales circa superficies curvas'', Commentationes Societatis Regiae Scientiarum Gottingesis Recentiores. Volume '''VI''', pp.&amp;nbsp;99–146. [http://www.gutenberg.org/ebooks/36856 "General Investigations of Curved Surfaces"] (published 1965) Raven Press, New York, translated by  J.C.Morehead and A.M.Hiltebeitel
* 1828: {{Cite journal
    | title = Theoria residuorum biquadraticorum, Commentatio prima
  | publisher = Commentationes Societatis Regiae Scientiarum Gottingensis. 6
  | location = Göttingen
    | postscript = &lt;!--None--&gt;}}. German translation by H. Maser
* 1828: {{Cite journal
  | title = Untersuchungen über höhere Arithmetik (Disquisitiones Arithmeticae &amp; other papers on number theory) (Second edition)
  | publisher = Chelsea
  | location = New York
  | year = 1965
  | isbn = 0-8284-0191-8
  | pages=511–533}} [Elementary facts about biquadratic residues, proves one of the supplements of the law of [[biquadratic reciprocity]] (the biquadratic character of 2)]
* 1832: {{Cite journal
  | title = Theoria residuorum biquadraticorum, Commentatio secunda
  | publisher = Commentationes Societatis Regiae Scientiarum Gottingensis. 7
  | location = Göttingen
  | postscript = &lt;!--None--&gt;}}. German translation by H. Maser {{Cite journal
  | title = Untersuchungen über höhere Arithmetik (Disquisitiones Arithmeticae &amp; other papers on number theory) (Second edition)
  | publisher = Chelsea
  | location = New York
  | year = 1965
  | isbn = 0-8284-0191-8
  | postscript = &lt;!--None--&gt;}}, pp.&amp;nbsp;534–586 [Introduces the [[Gaussian integers]], states (without proof) the law of [[biquadratic reciprocity]], proves the supplementary law for 1 + ''i'']
* {{cite journal | title = Intensitas vis magneticae terrestris ad mensuram absolutam revocata | journal = Commentationes Societatis Regiae Scientiarum Gottingensis Recentiores | volume = 8 | year = 1832 | pages = 3–44}} [http://www.21stcenturysciencetech.com/translations/gaussMagnetic.pdf English translation]
* 1843/44: ''Untersuchungen über Gegenstände der Höheren Geodäsie. Erste Abhandlung'', Abhandlungen der Königlichen Gesellschaft der Wissenschaften in Göttingen. Zweiter Band, pp.&amp;nbsp;3–46
* 1846/47: ''Untersuchungen über Gegenstände der Höheren Geodäsie. Zweite Abhandlung'', Abhandlungen der Königlichen Gesellschaft der Wissenschaften in Göttingen. Dritter Band, pp.&amp;nbsp;3–44
* ''Mathematisches Tagebuch 1796–1814'', Ostwaldts Klassiker, [[Verlag Harri Deutsch]] 2005, mit Anmerkungen von Neumamn, {{isbn|978-3-8171-3402-1}} (English translation with annotations by Jeremy Gray: Expositiones Math. 1984)

== See also ==
* [[Gaussian elimination]]
* [[German inventors and discoverers]]
* [[List of things named after Carl Friedrich Gauss]]
* [[Romanticism in science]]
*[[Seconds pendulum]]

== Notes ==
{{Reflist}}

== Further reading ==
* {{Cite book|title=Gauss: A Biographical Study|first=Walter Kaufmann|last=Bühler|publisher=Springer-Verlag|year=1987|isbn=0-387-10662-6|ref=harv}}
* {{cite book |last=Dunnington|first=G. Waldo.|title=Carl Friedrich Gauss: Titan of Science
 |publisher=The Mathematical Association of America|year=2003|isbn=0-88385-547-X |oclc=53933110}}
* {{cite book |last=Gauss|first=Carl Friedrich|others=tr. Arthur A. Clarke|title=[[Disquisitiones Arithmeticae]]|publisher=Yale University Press|year=1965|isbn=0-300-09473-6}}
* {{cite book
 |last=Hall
 |first=Tord
 |title=Carl Friedrich Gauss: A Biography
 |location=Cambridge, MA
 |publisher=[[MIT Press]]
 |year=1970
 |isbn=0-262-08040-0
 |oclc=185662235}}
* {{cite book
 |last=Kehlmann
 |first=Daniel
 |title=[[Measuring the World|Die Vermessung der Welt]]
 |publisher=Rowohlt
 |year=2005
 |isbn=3-498-03528-2
 |oclc=144590801}}
* {{cite book
 |last= Sartorius von Waltershausen
 |first=Wolfgang
 |authorlink=Wolfgang Sartorius von Waltershausen
 |title= Gauss: A Memorial
 |url=https://archive.org/details/gauss00waltgoog
 |publisher= S. Hirzel
 |year=1856
 }}
* {{cite book
 |last=Simmons
 |first=J.
 |title=The Giant Book of Scientists: The 100 Greatest Minds of All Time
 |publisher=The Book Company
 |location=Sydney
 |year=1996
 }}
* {{cite book
 |last=Tent
 |first=Margaret
 |title=The Prince of Mathematics: Carl Friedrich Gauss
 |publisher=A K Peters
 |isbn= 1-56881-455-0
 |year=2006
 }}

== External links ==
{{commons|Johann Carl Friedrich Gauß}}
{{wikisource|Author:Carl Friedrich Gauss|Carl Friedrich Gauss}}
{{wikiquote}}
{{EB1911 poster|Gauss, Karl Friedrich}}
* {{Gutenberg author | id=Gauss,+Karl+Friedrich | name=Karl Friedrich Gauss}}
* {{Internet Archive author |sname=Carl Friedrich Gauss}}
* {{planetmath reference |id=5594 |title=Carl Friedrich Gauss}}
* [https://gdz.sub.uni-goettingen.de/volumes/id/PPN235957348 Carl Friedrich Gauss Werke] – 12 vols., published from 1863-1933
* [http://www.gausschildren.org Gauss and his children]
* [http://www.corrosion-doctors.org/Biographies/GaussBio.htm Gauss biography]
* {{MathGenealogy|id=18231}}
* [http://fermatslasttheorem.blogspot.com/2005/06/carl-friedrich-gauss.html Carl Friedrich Gauss] – Biography at Fermat's Last Theorem Blog
* [http://www.idsia.ch/~juergen/gauss.html Gauss: mathematician of the millennium], by [[Jürgen Schmidhuber]]
* [https://archive.org/details/gauss00waltgoog English translation of Waltershausen's 1862 biography]
* [https://web.archive.org/web/20040728015519/http://gauss.info/ Gauss] general website on Gauss
* [http://adsabs.harvard.edu//full/seri/MNRAS/0016//0000080.000.html MNRAS '''16''' (1856) 80] Obituary
* [http://www-personal.umich.edu/~jbourj/money1.htm Carl Friedrich Gauss on the 10 Deutsche Mark banknote]
* {{MacTutor Biography|id=Gauss}}
* [http://www.bbc.co.uk/programmes/b00ss0lf "Carl Friedrich Gauss"] in the series ''A Brief History of Mathematics'' on BBC 4
* {{cite web|last=Grimes|first=James|title=5050 And a Gauss Trick|url=http://www.numberphile.com/videos/one_to_million.html|work=Numberphile|publisher=[[Brady Haran]]}}
* [https://www.uni-goettingen.de/en/62596.html Carl Friedrich Gauß] at the Göttingen University

{{Copley Medallists 1801–1850}}
{{Age of Enlightenment}}
{{Scientists whose names are used as non SI units}}
{{Authority control}}

{{DEFAULTSORT:Gauss, Carl Friedrich}}
[[Category:Carl Friedrich Gauss| ]]
[[Category:1777 births]]
[[Category:1855 deaths]]
[[Category:18th-century German mathematicians]]
[[Category:19th-century German mathematicians]]
[[Category:Braunschweig University of Technology alumni]]
[[Category:Corresponding Members of the St Petersburg Academy of Sciences]]
[[Category:German deists]]
[[Category:Differential geometers]]
[[Category:Fellows of the American Academy of Arts and Sciences]]
[[Category:Fellows of the Royal Society]]
[[Category:German astronomers]]
[[Category:German Lutherans]]
[[Category:German physicists]]
[[Category:German scientists]]
[[Category:Honorary Members of the St Petersburg Academy of Sciences]]
[[Category:Members of the Bavarian Maximilian Order for Science and Art]]
[[Category:Members of the Royal Netherlands Academy of Arts and Sciences]]
[[Category:Members of the Royal Swedish Academy of Sciences]]
[[Category:Mental calculators]]
[[Category:Number theorists]]
[[Category:Optical physicists]]
[[Category:People from Braunschweig]]
[[Category:People from the Duchy of Brunswick]]
[[Category:Recipients of the Copley Medal]]
[[Category:Recipients of the Pour le Mérite (civil class)]]
[[Category:University of Göttingen alumni]]
[[Category:University of Göttingen faculty]]
[[Category:University of Helmstedt alumni]]
[[Category:Ceres (dwarf planet)]]</text>
      <sha1>snc4xe1cc5fwoessd6dl8mq2mja2hgt</sha1>
    </revision>
  </page>
  <page>
    <title>Change of variables</title>
    <ns>0</ns>
    <id>2146848</id>
    <revision>
      <id>856457088</id>
      <parentid>856455586</parentid>
      <timestamp>2018-08-25T10:21:32Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Undid revision 856455586 by [[Special:Contributions/UlyssesZhan|UlyssesZhan]] ([[User talk:UlyssesZhan|talk]]) "and" was correct, but the surrounding sentences were too sketchy</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11200">{{Unreferenced|date=December 2009}}
{{Calculus |Differential}}

In mathematics, a '''change of variables''' is a basic technique used to simplify problems in which the original [[variable (mathematics)|variable]]s are replaced with [[function (mathematics)|functions]] of other variables. The intent is that when expressed in new variables, the problem  may become simpler, or equivalent to a better understood problem.

Change of variables is an operation that is related to [[substitution (algebra)|substitution]]. However these are different operations, as can be seen when considering [[derivative|differentiation]] ([[chain rule]]) or [[integral|integration]] ([[integration by substitution]]).

A very simple example of a useful variable change can be seen in the problem of finding the roots of the sixth degree polynomial:

:&lt;math&gt;x^6 - 9 x^3 + 8 = 0. \,&lt;/math&gt;

Sixth degree polynomial equations are generally impossible to solve in terms of radicals (see [[Abel–Ruffini theorem]]). This particular equation, however, may be written 
:&lt;math&gt;(x^3)^2-9(x^3)+8=0&lt;/math&gt;
(this is a simple case of a [[polynomial decomposition]]). Thus the equation may be
simplified by defining a new variable ''u'' =''x''&lt;sup&gt;3&lt;/sup&gt;. Substituting ''x'' by &lt;math&gt;\sqrt[3]{u}&lt;/math&gt; into the polynomial gives

:&lt;math&gt;u^2 - 9 u + 8 = 0 ,&lt;/math&gt;

which is just a [[quadratic equation]] with the two solutions:

:&lt;math&gt;u = 1 \quad \text{and} \quad u = 8.&lt;/math&gt;

The solutions in terms of the original variable are obtained by substituting ''x''&lt;sup&gt;3&lt;/sup&gt; back in for ''u'', which gives
:&lt;math&gt;x^3 = 1 \quad \text{and} \quad x^3 = 8.&lt;/math&gt;

Then, assuming that one is interested only in [[Real number|real]] solutions, the solutions of the original equation are
:&lt;math&gt;x =  (1)^{1/3} = 1 \quad \text{and} \quad x =  (8)^{1/3} = 2.&lt;/math&gt;

==Simple example==

Consider the system of equations
:&lt;math&gt;xy+x+y=71&lt;/math&gt;

:&lt;math&gt;x^2y+xy^2=880&lt;/math&gt;

where &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;y&lt;/math&gt; are positive integers with &lt;math&gt;x&gt;y&lt;/math&gt;. (Source: 1991 [[American Invitational Mathematics Examination|AIME]])

Solving this normally is not very difficult, but it may get a little tedious.  However, we can rewrite the second equation as &lt;math&gt;xy(x+y)=880&lt;/math&gt;.  Making the substitution &lt;math&gt;s=x+y, t=xy&lt;/math&gt; reduces the system to &lt;math&gt;s+t=71, st=880.&lt;/math&gt; Solving this gives &lt;math&gt;(s,t)=(16,55)&lt;/math&gt; or &lt;math&gt;(s,t)=(55,16).&lt;/math&gt;  Back-substituting the first ordered pair gives us &lt;math&gt;x+y=16, xy=55&lt;/math&gt;, which easily gives the solution &lt;math&gt;(x,y)=(11,5).&lt;/math&gt;  Back-substituting the second ordered pair gives us &lt;math&gt;x+y=55, xy=16&lt;/math&gt;, which gives no solutions.  Hence the solution that solves the system is &lt;math&gt;(x,y)=(11,5)&lt;/math&gt;.

==Formal introduction==
Let &lt;math&gt;A&lt;/math&gt;, &lt;math&gt;B&lt;/math&gt; be [[smooth manifold]]s and let &lt;math&gt;\Phi: A \rightarrow B&lt;/math&gt; be a &lt;math&gt;C^r&lt;/math&gt;-[[diffeomorphism]] between them, that is: &lt;math&gt;\Phi&lt;/math&gt; is a &lt;math&gt;r&lt;/math&gt; times continuously differentiable, [[bijective]] map from &lt;math&gt;A&lt;/math&gt; to &lt;math&gt;B&lt;/math&gt; with &lt;math&gt;r&lt;/math&gt; times continuously differentiable inverse from &lt;math&gt;B&lt;/math&gt; to &lt;math&gt;A&lt;/math&gt;. Here &lt;math&gt;r&lt;/math&gt; may be any natural number (or zero), &lt;math&gt;\infty&lt;/math&gt; ([[smooth function|smooth]]) or &lt;math&gt;\omega&lt;/math&gt; ([[analytic function|analytic]]).

The map &lt;math&gt;\Phi&lt;/math&gt; is called a ''regular coordinate transformation'' or ''regular variable substitution'', where ''regular'' refers to the &lt;math&gt;C^r&lt;/math&gt;-ness of &lt;math&gt;\Phi&lt;/math&gt;. Usually one will write &lt;math&gt;x = \Phi(y)&lt;/math&gt; to indicate the replacement of the variable &lt;math&gt;x&lt;/math&gt; by the variable &lt;math&gt;y&lt;/math&gt; by substituting the value of &lt;math&gt;\Phi&lt;/math&gt; in &lt;math&gt;y&lt;/math&gt; for every occurrence of &lt;math&gt;x&lt;/math&gt;.

==Other examples==

===Coordinate transformation===
Some systems can be more easily solved when switching to [[polar coordinates]]. Consider for example the equation

:&lt;math&gt;U(x, y) := (x^2 + y^2) \sqrt{ 1 - \frac{x^2}{x^2 + y^2} } = 0.&lt;/math&gt;

This may be a potential energy function for some physical problem. If one does not immediately see a solution, one might try the substitution

:&lt;math&gt;\displaystyle (x, y) = \Phi(r, \theta)&lt;/math&gt; given by &lt;math&gt;\displaystyle \Phi(r,\theta) = (r \cos(\theta), r \sin(\theta)).&lt;/math&gt;

Note that if &lt;math&gt;\theta&lt;/math&gt; runs outside a &lt;math&gt;2\pi&lt;/math&gt;-length interval, for example, &lt;math&gt;[0, 2\pi]&lt;/math&gt;, the map &lt;math&gt;\Phi&lt;/math&gt; is no longer bijective. Therefore &lt;math&gt;\Phi&lt;/math&gt; should be limited to, for example &lt;math&gt;(0, \infty] \times [0, 2\pi)&lt;/math&gt;. Notice how &lt;math&gt;r = 0&lt;/math&gt; is excluded, for &lt;math&gt;\Phi&lt;/math&gt; is not bijective in the origin (&lt;math&gt;\theta&lt;/math&gt; can take any value, the point will be mapped to (0, 0)). Then, replacing all occurrences of the original variables by the new [[expression (mathematics)|expression]]s prescribed by &lt;math&gt;\Phi&lt;/math&gt; and using the identity &lt;math&gt;\sin^2 x + \cos^2 x = 1&lt;/math&gt;, we get

: &lt;math&gt;V(r, \theta) = r^2 \sqrt{ 1 - \frac{r^2 \cos^2 \theta}{r^2} } = r^2 \sqrt{1 - \cos^2 \theta} = r^2\left|\sin\theta\right|. &lt;/math&gt;

Now the solutions can be readily found: &lt;math&gt;\sin(\theta) = 0&lt;/math&gt;, so &lt;math&gt;\theta = 0&lt;/math&gt; or &lt;math&gt;\theta = \pi&lt;/math&gt;. Applying the inverse of &lt;math&gt;\Phi&lt;/math&gt; shows that this is equivalent to &lt;math&gt;y = 0&lt;/math&gt; while &lt;math&gt;x \not= 0&lt;/math&gt;. Indeed we see that for &lt;math&gt;y = 0&lt;/math&gt; the function vanishes, except for the origin.

Note that, had we allowed &lt;math&gt;r = 0&lt;/math&gt;, the origin would also have been a solution, though it is not a solution to the original problem. Here the bijectivity of &lt;math&gt;\Phi&lt;/math&gt; is crucial. Note also that the function is always positive (for &lt;math&gt;x,y\in\reals&lt;/math&gt;), hence the absolute values.

===Differentiation===
{{Main|Chain rule}}
The [[chain rule]] is used to simplify complicated differentiation. For example, consider the problem of calculating the derivative

: &lt;math&gt;\frac d {d x}\sin(x^2).&lt;/math&gt;

Writing

: &lt;math&gt; y = \sin u \quad \text{and} \quad u = x^2 &lt;/math&gt;

we get

: &lt;math&gt;
\begin{align}
&amp; \frac d {dx} \sin(x^2) = \overbrace{ \frac {dy}{dx} = \frac{dy}{du}\, \frac{du}{dx} }^{\text{This part is the chain rule.}}  = \left( \frac d {du} \sin u \right) \left( \frac d {dx} x^2 \right) \\[8pt]
= {} &amp; \big( \cos u \big) (2x) = \cos(x^2) \cdot 2x.
\end{align}
&lt;/math&gt;

===Integration===
{{Main|Integration by substitution}}
Difficult integrals may often be evaluated by changing variables; this is enabled by the [[substitution rule]] and is analogous to the use of the chain rule above. Difficult integrals may also be solved by simplifying the integral using a change of variables given by the corresponding [[Jacobian matrix and determinant]]. Using the Jacobian determinant and the corresponding change of variable that it gives is the basis of coordinate systems such as polar, cylindrical, and spherical coordinate systems.

===Differential equations===
Variable changes for differentiation and integration are taught in elementary [[calculus]] and the steps are rarely carried out in full.

The very broad use of variable changes is apparent when considering differential equations, where the independent variables may be changed using the [[chain rule]] or the dependent variables are changed resulting in some differentiation to be carried out. Exotic changes, such as the mingling of dependent and independent variables in [[point transformation|point]] and [[contact transformation]]s, can be very complicated but allow much freedom.

Very often, a general form for a change is substituted into a problem and parameters picked along the way to best simplify the problem.

===Scaling and shifting===
Probably the simplest change is the scaling and shifting of variables, that is replacing them with new variables that are "stretched" and "moved" by constant amounts. This is very common in practical applications to get physical parameters out of problems. For an ''n''&lt;sup&gt;th&lt;/sup&gt; order derivative, the change simply results in

:&lt;math&gt;\frac{d^n y}{d x^n} = \frac{y_\text{scale}}{x_\text{scale}^n} \frac{d^n \hat y}{d \hat x^n}&lt;/math&gt;

where

:&lt;math&gt;x = \hat x x_\text{scale} + x_\text{shift}&lt;/math&gt;

:&lt;math&gt;y = \hat y y_\text{scale} + y_\text{shift}.&lt;/math&gt;

This may be shown readily through the [[chain rule]] and linearity of differentiation. This change is very common in practical applications to get physical parameters out of problems, for example, the [[boundary value problem]]

:&lt;math&gt;\mu \frac{d^2 u}{d y^2} = \frac{d p}{d x} \quad ; \quad u(0) = u(L) = 0&lt;/math&gt;

describes parallel fluid flow between flat solid walls separated by a distance δ; µ is the [[viscosity]] and &lt;math&gt;d p/d x&lt;/math&gt; the [[pressure gradient]], both constants. By scaling the variables the problem becomes

:&lt;math&gt;\frac{d^2 \hat u}{d \hat y^2} = 1 \quad ; \quad \hat u(0) = \hat u(1) = 0&lt;/math&gt;

where

:&lt;math&gt;y = \hat y L \qquad \text{and} \qquad u = \hat u \frac{L^2}{\mu} \frac{d p}{d x}.&lt;/math&gt;

Scaling is useful for many reasons. It simplifies analysis both by reducing the number of parameters and by simply making the problem neater. Proper scaling may ''normalize'' variables, that is make them have a sensible unitless range such as 0 to 1. Finally, if a problem mandates numeric solution, the fewer the parameters the fewer the number of computations.

===Momentum vs. velocity===
Consider a system of equations
: &lt;math&gt;
\begin{align}
m \dot v &amp; = - \frac{ \partial H }{ \partial x } \\[5pt]
m \dot x &amp; = \frac{ \partial H }{ \partial v }
\end{align}
&lt;/math&gt;

for a given function &lt;math&gt;H(x, v)&lt;/math&gt;.
The mass can be eliminated by the (trivial) substitution &lt;math&gt;\Phi(p) = 1/m \cdot p&lt;/math&gt;.
Clearly this is a bijective map from &lt;math&gt;\mathbb{R}&lt;/math&gt; to &lt;math&gt;\mathbb{R}&lt;/math&gt;. Under the substitution &lt;math&gt;v = \Phi(p)&lt;/math&gt; the system becomes

: &lt;math&gt;
\begin{align}
\dot p &amp; = - \frac{ \partial H }{ \partial x } \\[5pt]
\dot x &amp; = \frac{ \partial H }{ \partial p }
\end{align}
&lt;/math&gt;

===Lagrangian mechanics===
{{Main|Lagrangian mechanics}}
Given a force field &lt;math&gt;\varphi(t, x, v)&lt;/math&gt;, [[Isaac Newton|Newton]]'s [[equations of motion]] are
:&lt;math&gt;m \ddot x = \varphi(t, x, v).&lt;/math&gt;
Lagrange examined how these equations of motion change under an arbitrary substitution of variables &lt;math&gt;x = \Psi(t, y)&lt;/math&gt;, &lt;math&gt;v = \frac{\partial \Psi(t, y)}{\partial t} + \frac{\partial\Psi(t, y)}{\partial y} \cdot w.&lt;/math&gt;

He found that the equations
:&lt;math&gt; \frac{ \partial{L} }{ \partial y} = \frac{\mathrm{d}}{\mathrm{d}t} \frac{\partial{L}}{\partial{w}} &lt;/math&gt;
are equivalent to Newton's equations for the function &lt;math&gt;L = T - V&lt;/math&gt;,
where ''T'' is the kinetic, and ''V'' the potential energy.

In fact, when the substitution is chosen well (exploiting for example symmetries and constraints of the system) these equations are much easier to solve than Newton's equations in Cartesian coordinates.

==See also==
*[[Change of variables (PDE)]]
*[[Substitution property of equality]]
*[[Instantiation of universals]]
*[[Probability density function#Dependent variables and change of variables|Change of variables for probability densities]]

[[Category:Elementary algebra]]
[[Category:Mathematical physics]]</text>
      <sha1>r8llwe3pcmbopw09fj7j38m6frw5573</sha1>
    </revision>
  </page>
  <page>
    <title>Ciphertext expansion</title>
    <ns>0</ns>
    <id>2467473</id>
    <revision>
      <id>825270345</id>
      <parentid>354967329</parentid>
      <timestamp>2018-02-12T12:51:52Z</timestamp>
      <contributor>
        <username>Usernamekiran (AWB)</username>
        <id>31804499</id>
      </contributor>
      <minor/>
      <comment>/* top */general fixes using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="942">{{unreferenced|date=April 2010}}
In [[cryptography]], the term '''ciphertext expansion''' refers to the length increase of a message when it is [[encryption|encrypted]]. Many modern cryptosystems cause some degree of expansion during the encryption process, for instance when the resulting [[ciphertext]] must include a message-unique [[Initialization Vector]] (IV).  [[Probabilistic encryption]] schemes cause ciphertext expansion, as the set of possible ciphertexts is necessarily greater than the set of input plaintexts.  Certain schemes, such as [[Cocks Identity Based Encryption]], or the [[Goldwasser-Micali cryptosystem]] result in ciphertexts hundreds or thousands of times longer than the plaintext.

Ciphertext expansion may be offset or increased by other processes which compress or expand the message, e.g., [[data compression]] or [[error correction codes|error correction coding]].

[[Category:Cryptography]]


{{crypto-stub}}</text>
      <sha1>43gjdg3u0rupja9gl8625f8sjn1uh2h</sha1>
    </revision>
  </page>
  <page>
    <title>Comparability graph</title>
    <ns>0</ns>
    <id>6978672</id>
    <revision>
      <id>803020977</id>
      <parentid>706053077</parentid>
      <timestamp>2017-09-29T23:35:29Z</timestamp>
      <contributor>
        <ip>23.91.152.122</ip>
      </contributor>
      <comment>/* Relation to other graph families */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11566">In [[graph theory]], a '''comparability graph''' is an [[undirected graph]] that connects pairs of elements that are [[comparability|comparable]] to each other in a [[partial order]]. Comparability graphs have also been called '''transitively orientable graphs''', '''partially orderable graphs''', and '''containment graphs'''.&lt;ref&gt;{{harvtxt|Golumbic|1980}}, p. 105; {{harvtxt|Brandstädt|Le|Spinrad|1999}}, p. 94.&lt;/ref&gt;
An '''incomparability graph''' is an [[undirected graph]] that connects pairs of elements that are not [[comparability|comparable]] to each other in a [[partial order]].

==Definitions and characterization==
[[File:Poset et graphe de comparabilité.svg|thumb|300px|Hasse diagram of a poset (left) and its comparability graph (right)]]
[[Image:Forbidden interval subgraph.svg|thumb|One of the forbidden induced subgraphs of a comparability graph. The generalized cycle 
''a''–''b''–''d''–''f''–''d''–''c''–''e''–''c''–''b''–''a'' in this graph has odd length (nine) but has no triangular chords.]]
For any [[strict partial order|strict partially ordered set]] (''S'',&amp;lt;), the '''comparability graph''' of (''S'', &amp;lt;) is the graph (''S'', ⊥) of which the vertices are the elements of ''S'' and the edges are those pairs {''u'', ''v''} of elements such that ''u'' &amp;lt; ''v''.  That is, for a partially ordered set, take the [[directed acyclic graph]], apply [[transitive closure]], and remove orientation. 

Equivalently, a comparability graph is a graph that has a '''transitive orientation''',&lt;ref&gt;{{harvtxt|Ghouila-Houri|1962}}; see {{harvtxt|Brandstädt|Le|Spinrad|1999}}, theorem 1.4.1, p. 12. Although the orientations coming from partial orders are [[directed acyclic graph|acyclic]], it is not necessary to include acyclicity as a condition of this characterization.&lt;/ref&gt; an assignment of directions to the edges of the graph (i.e. an [[Orientation (graph theory)|orientation]] of the graph) such that the [[adjacency relation]] of the resulting [[directed graph]] is [[transitive relation|transitive]]: whenever there exist directed edges (''x'',''y'') and (''y'',''z''), there must exist an edge (''x'',''z'').

One can represent any partial order as a family of sets, such that ''x'' &amp;lt; ''y'' in the partial order whenever the set corresponding to ''x'' is a subset of the set corresponding to ''y''. In this way, comparability graphs can be shown to be equivalent to containment graphs of set families; that is, a graph with a vertex for each set in the family and an edge between two sets whenever one is a subset of the other.&lt;ref&gt;{{harvtxt|Urrutia|1989}}; {{harvtxt|Trotter|1992}}; {{harvtxt|Brandstädt|Le|Spinrad|1999}}, section 6.3, pp. 94–96.&lt;/ref&gt;

Alternatively,&lt;ref&gt;{{harvtxt|Ghouila-Houri|1962}} and {{harvtxt|Gilmore|Hoffman|1964}}. See also {{harvtxt|Brandstädt|Le|Spinrad|1999}}, theorem 6.1.1, p. 91.&lt;/ref&gt; a comparability graph is a graph such that, for every ''generalized cycle'' of odd length, one can find an edge (''x'',''y'') connecting two vertices that are at distance two in the cycle. Such an edge is called a ''triangular chord''. In this context, a generalized cycle is defined to be a [[Glossary of graph theory#Walks|closed walk]] that uses each edge of the graph at most once in each direction.

Comparability graphs can also be characterized by a list of [[forbidden induced subgraph]]s.&lt;ref&gt;{{harvtxt|Gallai|1967}}; {{harvtxt|Trotter|1992}}; {{harvtxt|Brandstädt|Le|Spinrad|1999}}, p. 91 and p. 112.&lt;/ref&gt;

==Relation to other graph families==
Every [[complete graph]] is a comparability graph, the comparability graph of a [[total order]]. All acyclic orientations of a complete graph are transitive. Every [[bipartite graph]] is also a comparability graph. Orienting the edges of a bipartite graph from one side of the bipartition to the other results in a transitive orientation, corresponding to a partial order of height two. As {{harvtxt|Seymour|2006}} observes, every comparability graph that is neither complete nor bipartite has a [[skew partition]].

The [[complement (graph theory)|complement]] of any [[interval graph]] is a comparability graph. The comparability relation is called an [[interval order]]. Interval graphs are exactly the graphs that are chordal and that have comparability graph complements.&lt;ref&gt;Transitive orientability of interval graph complements was proven by {{harvtxt|Ghouila-Houri|1962}}; the characterization of interval graphs is due to {{harvtxt|Gilmore|Hoffman|1964}}. See also {{harvtxt|Golumbic|1980}}, prop. 1.3, pp. 15–16.&lt;/ref&gt;

A [[permutation graph]] is a containment graph on a set of intervals.&lt;ref&gt;{{harvtxt|Dushnik|Miller|1941}}. {{harvtxt|Brandstädt|Le|Spinrad|1999}}, theorem 6.3.1, p. 95.&lt;/ref&gt; Therefore, permutation graphs are another subclass of comparability graphs.

The [[trivially perfect graph]]s are the comparability graphs of [[rooted tree]]s.&lt;ref&gt;{{harvtxt|Brandstädt|Le|Spinrad|1999}}, theorem 6.6.1, p. 99.&lt;/ref&gt;
[[Cograph]]s can be characterized as the comparability graphs of [[series-parallel partial order]]s; thus, cographs are also comparability graphs.&lt;ref&gt;{{harvtxt|Brandstädt|Le|Spinrad|1999}}, corollary 6.4.1, p. 96; {{harvtxt|Jung|1978}}.&lt;/ref&gt;

[[Threshold graph]]s are another special kind of comparability graph.

Every comparability graph is [[perfect graph|perfect]]. The perfection of comparability graphs is [[Mirsky's theorem]], and the perfection of their complements is [[Dilworth's theorem]]; these facts, together with the [[perfect graph theorem]] can be used to prove Dilworth's theorem from Mirsky's theorem or vice versa.&lt;ref&gt;{{harvtxt|Golumbic|1980}}, theorems 5.34 and 5.35, p. 133.&lt;/ref&gt; More specifically, comparability graphs are [[perfectly orderable graph]]s, a subclass of perfect graphs: a [[greedy coloring]] algorithm for a [[topological ordering]] of a transitive orientation of the graph will optimally color them.&lt;ref&gt;{{harvtxt|Maffray|2003}}.&lt;/ref&gt;

The [[complement graph|complement]] of every comparability graph is a [[string graph]].&lt;ref&gt;{{harvtxt|Golumbic|Rotem|Urrutia|1983}} and {{harvtxt|Lovász|1983}}. See also {{harvtxt|Fox|Pach|2012}}.&lt;/ref&gt;

==Algorithms==
A transitive orientation of a graph, if it exists, can be found in linear time.&lt;ref&gt;{{harvtxt|McConnell|Spinrad|1997}}; see {{harvtxt|Brandstädt|Le|Spinrad|1999}}, p. 91.&lt;/ref&gt; However, the algorithm for doing so will assign orientations to the edges of any graph, so to complete the task of testing whether a graph is a comparability graph, one must test whether the resulting orientation is transitive, a problem provably equivalent in complexity to [[matrix multiplication]].

Because comparability graphs are perfect, many problems that are hard on more general classes of graphs, including [[graph coloring]] and the [[independent set problem]], can be computed in polynomial time for comparability graphs.

==Notes==
{{reflist|2}}

== References ==
{{refbegin|2}}
*{{citation
 | last1 = Brandstädt | first1 = Andreas | author1-link = Andreas Brandstädt
 | last2 = Le | first2 = Van Bang | last3 = Spinrad | first3 = Jeremy
 | title = Graph Classes: A Survey
 | publisher = SIAM Monographs on Discrete Mathematics and Applications
 | year = 1999
 | isbn = 0-89871-432-X}}.
*{{citation
 | last1 = Dushnik | first1 = Ben | last2 = Miller | first2 = E. W.
 | title = Partially ordered sets
 | journal = American Journal of Mathematics
 | volume = 63
 | year = 1941
 | pages = 600–610
 | mr = 0004862
 | doi = 10.2307/2371374
 | issue = 3
 | publisher = The Johns Hopkins University Press
 | jstor = 2371374}}.
*{{citation
 | first1 = J. | last1 = Fox | first2 = J. | last2 = Pach | author2-link = János Pach
 | title = String graphs and incomparability graphs
 | journal = Advances in Mathematics
 | volume = 230
 | issue = 3
 | year = 2012
 | doi = 10.1016/j.aim.2012.03.011
 | url = http://www.renyi.hu/~pach/publications/stringpartial071709.pdf
 | pages = 1381–1401
 }}.
*{{citation
 | last = Gallai | first = Tibor
 | authorlink=Tibor Gallai
 | title = Transitiv orientierbare Graphen
 | journal = Acta Math. Acad. Sci. Hung.
 | volume = 18
 | year = 1967
 | pages = 25–66
 | mr = 0221974
 | doi = 10.1007/BF02020961}}.
*{{citation
 | last = Ghouila-Houri | first = Alain
 | title = Caractérisation des graphes non orientés dont on peut orienter les arrêtes de manière à obtenir le graphe d'une relation d'ordre
 | journal = [[Les Comptes rendus de l'Académie des sciences]]
 | volume = 254
 | year = 1962
 | pages = 1370–1371
 | mr =0172275}}.
*{{citation
 | last1 = Gilmore | first1 = P. C. | last2 = Hoffman | first2 = A. J.
 | title = A characterization of comparability graphs and of interval graphs
 | journal = Canadian Journal of Mathematics
 | volume = 16
 | year = 1964
 | pages = 539–548
 | mr = 0175811
 | doi = 10.4153/CJM-1964-055-5}}.
*{{citation
 | last = Golumbic | first = Martin Charles | authorlink = Martin Charles Golumbic
 | title = Algorithmic Graph Theory and Perfect Graphs
 | publisher = Academic Press
 | year = 1980
 | isbn = 0-12-289260-7}}.
*{{citation
 | first1 = M. | last1 = Golumbic | first2 = D. | last2 = Rotem | first3 = J. | last3 = Urrutia | author3-link = Jorge Urrutia Galicia
 | title = Comparability graphs and intersection graphs
 | journal = Discrete Mathematics
 | volume = 43
 | year = 1983
 | pages = 37–46
 | issue = 1
 | doi = 10.1016/0012-365X(83)90019-5}}.
*{{citation
 | last = Jung | first = H. A.
 | title = On a class of posets and the corresponding comparability graphs
 | journal = Journal of Combinatorial Theory, Series B
 | volume = 24
 | year = 1978
 | issue = 2
 | pages = 125–133
 | mr = 0491356
 | doi = 10.1016/0095-8956(78)90013-8}}.
*{{citation
 | first = L. | last = Lovász | authorlink = László Lovász
 | contribution = Perfect graphs
 | title = Selected Topics in Graph Theory
 | volume = 2
 | publisher = Academic Press
 | location = London
 | year = 1983
 | pages = 55–87}}.
*{{citation
 | last = Maffray | first = Frédéric
 | contribution = On the coloration of perfect graphs
 | doi = 10.1007/0-387-22444-0_3
 | editor1-last = Reed | editor1-first = Bruce A. | editor1-link = Bruce Reed (mathematician)
 | editor2-last = Sales | editor2-first = Cláudia L.
 | pages = 65–84
 | publisher = Springer-Verlag
 | series = CMS Books in Mathematics
 | title = Recent Advances in Algorithms and Combinatorics
 | volume = 11
 | year = 2003}}.
*{{citation
 | last1 = McConnell | first1 = R. M. | last2 = Spinrad | first2 = J.
 | contribution = Linear-time transitive orientation
 | title = 8th ACM-SIAM Symposium on Discrete Algorithms
 | year = 1997
 | pages = 19–25}}.
*{{citation
 | last = Seymour | first = Paul | author-link = Paul Seymour (mathematician)
 | issue = 109
 | journal = Gazette des Mathématiciens
 | mr = 2245898
 | pages = 69–83
 | title = How the proof of the strong perfect graph conjecture was found
 | url = http://users.encs.concordia.ca/~chvatal/perfect/pds.pdf
 | year = 2006}}.
*{{citation
 | last = Trotter | first = William T.
 | title = Combinatorics and Partially Ordered Sets — Dimension Theory
 | publisher = Johns Hopkins University Press
 | year = 1992}}.
*{{citation
 | last = Urrutia | first = Jorge | authorlink = Jorge Urrutia Galicia
 | title = Partial orders and Euclidean geometry
 | booktitle = Algorithms and Order
 | editor = [[Ivan Rival|Rival, I.]]
 | year = 1989
 | publisher = Kluwer Academic Publishers
 | pages = 327–436}}.
{{refend}}

[[Category:Order theory]]
[[Category:Graph families]]
[[Category:Perfect graphs]]</text>
      <sha1>iquzisiw0k6gmbtcmwryasjua81p8si</sha1>
    </revision>
  </page>
  <page>
    <title>Contractible space</title>
    <ns>0</ns>
    <id>1752414</id>
    <revision>
      <id>853872799</id>
      <parentid>853856612</parentid>
      <timestamp>2018-08-07T14:03:08Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <comment>/* Properties */ fair point about clarifying the quantifier here though</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4185">[[File:Contractibility figure.png|right|thumb|Illustration of some contractible and non-contractible spaces. Spaces A, B, and C are contractible; spaces D, E, and F are not.]]

In [[mathematics]], a [[topological space]] ''X'' is '''contractible''' if the [[identity function|identity map]] on ''X'' is null-homotopic, i.e. if it is [[homotopic]] to some constant map.&lt;ref&gt;{{cite book | last=Munkres | first=James R. | authorlink=James Munkres | title=Topology | edition=2nd | publisher=[[Prentice Hall]] | year=2000 | isbn=0-13-181629-2}}&lt;/ref&gt;&lt;ref&gt;{{cite book | last=Hatcher | first=Allen | authorlink=Allen Hatcher | title=Algebraic Topology | publisher=[[Cambridge University Press]] | year=2002 | isbn=0-521-79540-0 | url=http://www.math.cornell.edu/~hatcher/AT/ATpage.html}}&lt;/ref&gt; Intuitively, a contractible space is one that can be continuously shrunk to a point within that space.

==Properties==
A contractible space is precisely one with the [[homotopy type]] of a point. It follows that all the [[homotopy group]]s of a contractible space are [[trivial group|trivial]]. Therefore any space with a nontrivial homotopy group cannot be contractible.  Similarly, since [[singular homology]] is a homotopy invariant, the [[Reduced homology|reduced homology groups]] of a contractible space are all trivial.

For a topological space ''X'' the following are all equivalent:
*''X'' is contractible (i.e. the identity map is null-homotopic).
*''X'' is homotopy equivalent to a one-point space.
*''X'' [[deformation retract]]s onto a point. (However, there exist contractible spaces which do not ''strongly'' deformation retract to a point.)
*For any space ''Y'', any two maps ''f'',''g'': ''Y'' → ''X'' are homotopic.
*For any space ''Y'', any map ''f'': ''Y'' → ''X'' is null-homotopic.

The [[cone (topology)|cone]] on a space ''X'' is always contractible. Therefore any space can be embedded in a contractible one (which also illustrates that subspaces of contractible spaces need not be contractible).

Furthermore, ''X'' is contractible [[if and only if]] there exists a [[Deformation retract|retraction]] from the cone of ''X'' to ''X''.

Every contractible space is [[path connected]] and [[simply connected]]. Moreover, since all the higher homotopy groups vanish, every contractible space is [[n-connected|''n''-connected]] for all ''n'' ≥ 0.

==Locally contractible spaces==
A topological space is '''locally contractible''' if every point has a [[local base]] of contractible [[neighborhood (topology)|neighborhood]]s. Contractible spaces are not necessarily locally contractible nor vice versa. For example, the [[comb space]] is contractible but not locally contractible (if it were, it would be locally connected which it is not). Locally contractible spaces are locally ''n''-connected for all ''n'' ≥ 0. In particular, they are [[locally simply connected]], [[Locally connected space|locally path connected]], and [[locally connected]].

==Examples and counterexamples==
*Any [[Euclidean space]] is contractible, as is any [[star domain]] on a Euclidean space.
*The [[Whitehead manifold]] is contractible.
*[[n-sphere|Spheres]] of any finite dimension are not contractible.
*The [[unit sphere]] in an infinite-dimensional [[Hilbert space]] [[Contractibility of unit sphere in Hilbert space|is contractible]].
*The [[house with two rooms]] is standard example of a space which is contractible, but not intuitively so.
*The [[Dunce hat (topology)|Dunce hat]] is contractible, but not [[Collapse (topology)|collapsible]].
*The cone on a [[Hawaiian earring]] is contractible (since it is a cone), but not locally contractible or even locally simply connected.
*All [[manifold]]s and [[CW complex]]es are ''locally'' contractible, but in general not contractible.
* The [[Warsaw circle]] is obtained by "closing up" the [[topologist's sine curve]] by an arc connecting (0,&amp;minus;1) and (1,sin(1)). It is a one-dimensional continuum whose [[homotopy group]]s are all trivial, but it is not contractible.

==References==
{{reflist}}

{{DEFAULTSORT:Contractible Space}}
[[Category:Topology]]
[[Category:Homotopy theory]]
[[Category:Properties of topological spaces]]</text>
      <sha1>mx8d26n83e8psfoedwn2ow5m6lzxd7n</sha1>
    </revision>
  </page>
  <page>
    <title>Cooling and heating (combinatorial game theory)</title>
    <ns>0</ns>
    <id>58629308</id>
    <revision>
      <id>863462272</id>
      <parentid>862979550</parentid>
      <timestamp>2018-10-10T22:38:49Z</timestamp>
      <contributor>
        <username>PJTraill</username>
        <id>522601</id>
      </contributor>
      <comment>Add a {{ short description }}.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6587">{{ Short description | Operations adjusting incentives of combinatorial games }}

In [[combinatorial game theory]], '''cooling''', '''heating''', and '''overheating''' are operations on [[hot game]]s to make them more amenable to the traditional methods of the theory,
which was originally devised for [[cold game]]s in which the winner is the last player to have a legal move.&lt;ref&gt;{{cite book
 | first=Elwyn R.   | last=Berlekamp | authorlink=Elwyn Berlekamp
 | first2=John H.    | last2=Conway   | author2-link=John Horton Conway
 | first3=Richard K. | last3=Guy      | author3-link=Richard K. Guy
 | title=[[Winning Ways for Your Mathematical Plays]] 
 | publisher=Academic Press | year=1982 | isbn=0-12-091101-9 
 | pages=147, 163, 170
 }}&lt;/ref&gt;
'''Overheating''' was generalised by Berlekamp for the analysis of [[Blockbusting (game)|Blockbusting]].&lt;ref&gt;{{cite journal
|last= Berlekamp|first= Elwyn|author-link=Elwyn Berlekamp &lt;!-- Department of Mathematics, University of California, Berkeley, California 94720 --&gt;
|date= January 13, 1987
|publication-date= September 1988
|title= Blockbusting and Domineering
|url= https://ac.els-cdn.com/0097316588900283/1-s2.0-0097316588900283-main.pdf?_tid=d0939db9-46c7-4e58-ad05-8a659ea988e2&amp;acdnat=1538430082_200c08afb1fa31f85820ba8725daec82
|journal= Journal of Combinatorial Theory |volume= 49|issue= 1|pages= 67–116|doi= |access-date= October 1, 2018
}}&lt;/ref&gt;
'''Chilling''' (or '''unheating''') and '''warming''' are variants used in the analysis of the endgame of [[Go (game)|Go]].&lt;ref&gt;{{cite book
 | last1 = Berlekamp | first1 = Elwyn | author1-link = Elwyn Berlekamp
 | last2 = Wolfe | first2 = David | author2-link = David Wolfe (mathematician)
 | isbn = 1-56881-032-6
 | publisher = A K Peters Ltd
 | title = Mathematical Go: Chilling Gets the Last Point
 | year = 1997}}&lt;/ref&gt;&lt;ref&gt;
{{cite book
 | last1= Berlekamp|first1= Elwyn |author1-link= Elwyn Berlekamp
 | last2= Wolfe    |first2= David |author2-link= David Wolfe (mathematician)
 | date= 1994
 | title= Mathematical Go Endgames
 | pages = 50–55
 | publisher= Ishi Press |isbn= 0-923891-36-6}} (paperback version of ''Mathematical Go: Chilling Gets the Last Point'')
&lt;/ref&gt;

Cooling and chilling may be thought of as a tax on the player who moves, who has to pay for the privilege of doing so,
while heating, warming and overheating are operations that more or less reverse cooling and chilling.

== Basic operations: cooling, heating ==
The '''cooled''' game &lt;math&gt; G_t &lt;/math&gt; ("&lt;math&gt; G &lt;/math&gt; cooled by &lt;math&gt; t &lt;/math&gt;") for a game  &lt;math&gt; G &lt;/math&gt; and a [[surreal number|(surreal) number]] &lt;math&gt; t &lt;/math&gt; is defined by&lt;ref&gt;Berlekamp, Conway &amp; Guy (1982), p. 147&lt;/ref&gt;
:: &lt;math&gt;
G_t  = \begin{cases} \{ G^L_t - t \mid G^R_t + t \} &amp; \text { for all numbers } t \leq \text{ any number } \tau \text{ for which }  G_\tau \text{ is infinitesimally close to some number } m \text{ , }\\
G_t  = m &amp; \text{ for } t &gt; \tau
\end{cases}
&lt;/math&gt;.
The amount &lt;math&gt; t &lt;/math&gt; by which &lt;math&gt; G &lt;/math&gt; is cooled is known as the ''temperature''; the minimum &lt;math&gt; \tau &lt;/math&gt; for which &lt;math&gt; G_\tau &lt;/math&gt; is infinitesimally close to &lt;math&gt; m &lt;/math&gt; is known as the ''temperature'' &lt;math&gt; t(G) &lt;/math&gt; ''of'' &lt;math&gt; G &lt;/math&gt;; &lt;math&gt; G &lt;/math&gt; is said to ''freeze'' to &lt;math&gt; G_\tau &lt;/math&gt;; &lt;math&gt; m &lt;/math&gt; is the ''mean value'' (or simply ''mean'') of &lt;math&gt; G &lt;/math&gt;.

'''Heating''' is the inverse of cooling and is defined as the "''[[integral]]''"&lt;ref&gt;Berlekamp, Conway &amp; Guy (1982), p. 163&lt;/ref&gt;
:: &lt;math&gt;
\int^t G = \begin{cases} G &amp; \text{ if } G \text{ is a number, } \\
\{ \int^t (G^L) + t \mid \int^t (G^R) - t \} &amp; \text{ otherwise. }
\end{cases}
&lt;/math&gt;


== Multiplication and overheating ==
'''Norton multiplication''' is an extension of [[multiplication]] to a game &lt;math&gt; G &lt;/math&gt; and a positive game &lt;math&gt; U &lt;/math&gt; (the "unit")
defined by&lt;ref&gt;Berlekamp, Conway &amp; Guy (1982), p. 246&lt;/ref&gt;
:: &lt;math&gt;
G.U = \begin{cases} G \times s &amp; \text{ (i.e. the sum of } G \text{ copies of } s \text{) if } G \text{ is a non-negative integer, } \\
-G \times -s &amp; \text{ if } G \text{ is a negative integer, } \\
\{ G^L.U + (U + I) \mid G^R.U - (U + I) \} \text { where } I \text { ranges over } \Delta (U) &amp; \text{ otherwise. }
\end{cases}
&lt;/math&gt;
The incentives &lt;math&gt; \Delta (U) &lt;/math&gt; of a game &lt;math&gt; U &lt;/math&gt; are defined as &lt;math&gt; \{ u - U : u \in U^L \} \cup \{ U - u : u \in U^R \} &lt;/math&gt;.

'''Overheating''' is an extension of heating used in Berlekamp's [[solved game|solution]] of [[Blockbusting (game)|Blockbusting]],
where &lt;math&gt; G &lt;/math&gt; ''overheated from'' &lt;math&gt; s &lt;/math&gt; ''to'' &lt;math&gt; t &lt;/math&gt; is defined for arbitrary games &lt;math&gt; G, s, t &lt;/math&gt; with &lt;math&gt; s &gt; 0 &lt;/math&gt; as&lt;ref&gt; Berlekamp (1987), p. 77&lt;/ref&gt;
:: &lt;math&gt;
\int_s^t G = \begin{cases} G . s &amp; \text{ if } G \text{ is an integer, } \\
\{ \int_s^t (G^L) + t \mid \int_s^t (G^R) - t \} &amp; \text{ otherwise. }
\end{cases}
&lt;/math&gt;

''[[Winning Ways]]'' also defines overheating of a game &lt;math&gt; G &lt;/math&gt; by a positive game &lt;math&gt; X &lt;/math&gt;, as&lt;ref&gt;Berlekamp, Conway &amp; Guy (1982), p. 170&lt;/ref&gt;
:: &lt;math&gt;
\int_0^t G = \{ \int_0^t (G^L) + X \mid \int_0^t (G^R) - X \}
&lt;/math&gt;
: Note that in this definition numbers are not treated differently from arbitrary games.
: Note that the "lower bound" 0 distinguishes this from the previous definition by Berlekamp


== Operations for Go: chilling and warming {{anchor|Chilling}} {{anchor|Warming}} ==
'''Chilling''' is a variant of cooling by &lt;math&gt; 1 &lt;/math&gt; used for Go endgames and is defined by&lt;ref&gt;Berlekamp &amp; Wolfe (1994), p. 53&lt;/ref&gt;
:: &lt;math&gt;
f(G) = \begin{cases} m &amp; \text{ if } G \text{ is of the form } m \text{ or } m * \text{ , } \\
\{ f(G^L) - 1 \mid F(G^R) + 1 \} &amp; \text{ otherwise }.
\end{cases}
&lt;/math&gt;
This is equivalent to cooling by &lt;math&gt;1&lt;/math&gt; when &lt;math&gt; G &lt;/math&gt; is an "even elementary Go position in canonical form".&lt;ref&gt;Berlekamp &amp; Wolfe (1994), pp. 53–55&lt;/ref&gt;

'''Warming''' is a special case of overheating, namely &lt;math&gt; \int_{1*}^1 &lt;/math&gt;, normally written simply as &lt;math&gt; \int &lt;/math&gt;  which inverts chilling when &lt;math&gt; G &lt;/math&gt; is an "even elementary Go position in canonical form".
In this case the previous definition simplifies to the form&lt;ref&gt;Berlekamp &amp; Wolfe (1994), pp. 52–55&lt;/ref&gt;
:: &lt;math&gt;
\int G = \begin{cases} G &amp; \text{ if } G \text{ is an even integer, } \\
G * &amp; \text{ if } G \text{ is an odd integer, } \\
\{ \int (G^L) + 1 \mid \int (G^R) - 1 \} &amp; \text{ otherwise. }
\end{cases}
&lt;/math&gt;

== References ==
{{Reflist}}


[[Category:Combinatorial game theory]]


{{combin-stub}}</text>
      <sha1>emfvyx82r1ckivrrgyfepims7xkphfz</sha1>
    </revision>
  </page>
  <page>
    <title>Digital probabilistic physics</title>
    <ns>0</ns>
    <id>8678944</id>
    <revision>
      <id>840329699</id>
      <parentid>822416905</parentid>
      <timestamp>2018-05-09T05:27:54Z</timestamp>
      <contributor>
        <username>Chronocam</username>
        <id>33484094</id>
      </contributor>
      <minor/>
      <comment>wikilink [[state machine]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4018">'''Digital probabilistic physics''' is a branch of [[digital philosophy]] which holds that the universe exists as a [[Nondeterministic finite automaton|nondeterministic]] [[State Machine|state machine]].  The notion of the universe existing as a state machine was first postulated by [[Konrad Zuse]]'s book ''[[Rechnender Raum]]''.  Adherents hold that the universe state machine can move between more and less probable states, with the less probable states containing more [[information]].  This theory is in contrast to [[digital physics]], which holds that the history of the universe is [[computable]] and is deterministically unfolding from initial conditions.

The fundamental tenets of digital probabilistic physics were first explored at great length by Tom Stonier in a series of books which explore the notion of information as existing as a physical phenomenon of the universe.  According to Stonier, the arrangement of atoms and molecules which make up physical objects contains information, and high-information objects such as DNA are low-probability physical structures.  Within this framework, [[civilization]] itself is a low-probability construct maintaining its existence by propagating through communication.  Stonier's work has been unique in considering information as existing as a physical phenomenon, being broader than as an application to the domain of telecommunications. 

To distinguish the [[probability]] of the physical state of the molecules from the probability of the energy distribution of thermodynamics, the term [[Negentropy|extropy]] was appropriated to define the probability of the atomic configuration, as opposed to the [[entropy]]. Thus, in thermodynamics, a 'coarse-grain' set of partitions is defined which groups together similar microscopically different states and in ''digital probabilistic physics'' the specific microscopic state probability is considered alone.  The extropy is defined to be the [[self-information]] of the [[Markov chain]] describing the physical system.

The extropy of a system &lt;math&gt;X(A_n)&lt;/math&gt; in bits associated with the Markov chain configuration &lt;math&gt;A_n&lt;/math&gt; whose outcome has probability &lt;math&gt;p&lt;/math&gt; is{{Citation needed|reason=a literature search does not show 'extropy' being used in this way|date=February 2014}}:

:&lt;math&gt;X(A_n) = \log_2 \left(\frac{1}{p(A_n)} \right) = - \log_2(p(A_n)) &lt;/math&gt; 

Within this philosophy, the probability of the physical system does not necessarily change with the deterministic flow of energy through the atomic framework, but rather moves into a lesser probability state when the system goes through a bifurcating transition. Examples of this include Bernoulli cell formation, quantum fluctuations in a gravitational field causing gravitational precipitation points, and other systems moving through unstable self-amplifying state transitions.

==Criticism==

* The existence of discrete digital states is incompatible with the continuous symmetries such as [[rotational symmetry]], [[Lorentz symmetry]], [[electroweak symmetry]] and others.  Proponents of digital physics hold that the continuous models are approximations to the underlying discrete nature of the universe.

==See also==

* [[Digital physics]]
* [[Cellular automata]]
* [[Extropy]]
* [[Digital philosophy]]


==References==

# {{note|tom}} Stonier, Tom, "Information and Meaning: An Evolutionary Perspective" (1990)
# {{note|tom2}} Stonier, Tom, "Information and the internal structure of the universe" (1990)
# {{note|tom3}} Stonier, Tom, "Beyond Information" (1992)
#{{note|lloyd}}S. Lloyd, ''The Computational Universe: Quantum gravity from quantum computation'', [https://arxiv.org/abs/quant-ph/0501135 preprint].
#{{note|smol}}L. Smolin, ''Matrix models as non-local hidden variables theories'', [https://arxiv.org/abs/hep-th/0201031 preprint].

==External links==
* [ftp://ftp.idsia.ch/pub/juergen/zuse67scan.pdf Scan of Zuse's paper in PDF]

[[Category:Theoretical physics]]
[[Category:Theoretical computer science]]</text>
      <sha1>p9hz22w33o5e8n1mgosswatiffvh7ns</sha1>
    </revision>
  </page>
  <page>
    <title>Direct Anonymous Attestation</title>
    <ns>0</ns>
    <id>18347128</id>
    <revision>
      <id>831106495</id>
      <parentid>829488456</parentid>
      <timestamp>2018-03-18T20:00:14Z</timestamp>
      <contributor>
        <username>Intgr</username>
        <id>246230</id>
      </contributor>
      <minor/>
      <comment>Bold per [[MOS:BOLD]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9608">'''Direct Anonymous Attestation''' ('''DAA''') is a [[cryptographic primitive]] which enables remote authentication of a [[trusted computing|trusted computer]] whilst preserving privacy of the platform's user. The protocol has been adopted by the [[Trusted Computing Group]] (TCG) in the latest version of its [[Trusted Platform Module]] (TPM) specification&lt;ref&gt;[https://www.trustedcomputinggroup.org/tpm-library-specification/ TPM Specification]&lt;/ref&gt; to address privacy concerns (see also [[Trusted computing#Loss of anonymity|Loss of Internet anonymity]]). ISO/IEC 20008 specifies DAA, as well, and Intel's [[Enhanced_privacy_ID | Enhanced Privacy ID (EPID)]] 2.0 implementation for [[microprocessor]]s is available for licensing [[RAND-Z]] along with an open source SDK.

== Historical perspective ==

In principle the privacy issue could be resolved using any standard signature scheme (or [[Public-key cryptography|public key encryption]]) and a single key pair. Manufacturers would embed the private key into every TPM produced and the public key would be published as a certificate. Signatures produced by the TPM must have originated from the private key, by the nature of the technology, and since all TPMs use the same private key they are indistinguishable ensuring the user's privacy. This rather naive solution relies upon the assumption that there exists a ''global secret''. One only needs to look at the precedent of [[Content Scramble System]] (CSS), an encryption system for [[DVD]]s, to see that this assumption is fundamentally flawed. Furthermore, this approach fails to realize a secondary goal: the ability to detect rogue TPMs. A rogue TPM is a TPM that has been compromised and had its secrets extracted.

The solution first adopted by the TCG (TPM specification v1.1) required a trusted third-party, namely a ''privacy certificate authority'' (privacy CA). Each TPM has an embedded [[RSA (algorithm)|RSA]] key pair called an Endorsement Key (EK) which the privacy CA is assumed to know. In order to attest the TPM generates a second RSA key pair called an Attestation Identity Key (AIK). It sends the public AIK, signed by EK, to the privacy CA who checks its validity and issues a certificate for the AIK. (For this to work, either a) the privacy CA must know the TPM's public EK ''a priori'', or b) the TPM's manufacturer must have provided an ''endorsement certificate''.) The host/TPM is now able to authenticate itself with respect to the certificate. This approach permits two possibilities to detecting rogue TPMs: firstly the privacy CA should maintain a list of TPMs identified by their EK known to be rogue and reject requests from them, secondly if a privacy CA receives too many requests from a particular TPM it may reject them and blacklist the TPMs EK. The number of permitted requests should be subject to a risk management exercise. This solution is problematic since the privacy CA must take part in every transaction and thus must provide high availability whilst remaining secure. Furthermore, privacy requirements may be violated if the privacy CA and verifier collude. Although the latter issue can probably be resolved using blind signatures, the first remains.

The EPID 2.0 solution embeds the private key in the microprocessor when it is manufactured, inherently distributes the key with the physical device shipment, and has the key provision and ready for use with 1st power-on.

== Overview ==
The DAA protocol is based on three entities and two different steps. The entities are the DAA Member (TPM platform or EPID-enabled microprocessor), the DAA Issuer and the DAA Verifier. The issuer is charged to verify the TPM platform during the Join step and to issue DAA credential to the platform.  The platform (Member) uses the DAA credential with the Verifier during the Sign step. Through a [[zero-knowledge proof]] the Verifier can verify the credential without attempting to violate the platform's privacy. The protocol also supports a blacklisting capability so that Verifiers can identify attestations from TPMs that have been compromised.

== Privacy properties ==
The protocol allows differing degrees of privacy. Interactions are always anonymous, but the Member/Verifier may negotiate as to whether the Verifier is able to link transactions. This would allow user profiling and/or the rejection of requests originating from a host which has made too many requests. The Member and Verifier can also elect to reveal additional information to accomplish non-anonymous interactions (just as you can choose to tell a stranger your full name, or not). Thus, known identity can be built on top of an anonymous start. (Contrast this with: if you start with known identity, you can never prove you un-know that identity to regress to anonymity.)

== Implementations ==
The first Direct Anonymous Attestation scheme is due to Brickell, Camenisch, and Chen;&lt;ref&gt;
{{cite journal|
  last1=Brickell|
  last2=Camenisch|
  last3=Chen|
  title=Direct Anonymous Attestation|journal=ACM Conference on Computer and Communications Security|
  date=2004|
  pages=132–145|
  url=https://eprint.iacr.org/2004/205.pdf}}
&lt;/ref&gt; that scheme is insecure and requires a fix.&lt;ref&gt;
{{cite journal|
  last1=Smyth|
  last2=Ryan|
  last3=Chen|
  title=Formal analysis of privacy in Direct Anonymous Attestation schemes|
  journal=Science of Computer Programming|
  date=2015|
  volume=111|
  issue=2|
  url=https://eprint.iacr.org/2012/650.pdf}}&lt;/ref&gt;
Brickell, Chen, and Li improve efficiency of that first scheme using symmetric pairings, rather than RSA.&lt;ref&gt;
{{cite journal|
  last1=Brickell|
  last2=Chen|
  last3=Li|
  title=Simplified security notions of Direct Anonymous Attestation and a concrete scheme from pairings|
  journal=International Journal of Information Security|
  date=2009|
  volume=8|
  issue=5|
  pages=315–330|
  url=https://eprint.iacr.org/2008/104.pdf
|doi=10.1007/s10207-009-0076-3}}&lt;/ref&gt; 
And Chen, Morrissey, and Smart attempt to further improve efficiency by switching from a symmetric to an asymmetric setting;&lt;ref&gt;
{{cite journal|
  last1=Chen|
  last2=Morrissey|
  last3=Smart|
  title=On Proofs of Security for DAA Schemes|
  journal=3rd International Conference on Trust and Trustworthy Computing|
  date=2008|
  volume=5324|
  pages=156–175|
  url=}}&lt;/ref&gt;&lt;ref&gt;
{{cite journal|
  last1=Chen|
  last2=Morrissey|
  last3=Smart|
  title=Pairings in Trusted Computing|
  journal=2nd International Conference on Pairing-Based Cryptography|
  date=2008|
  volume=5209|
  pages=1–17|
  url=}}&lt;/ref&gt; 
unfortunately, the asymmetric scheme is insecure.&lt;ref&gt;
{{cite journal|
  last1=Chen|
  last2=Li|
  title=A note on the Chen-Morrissey-Smart DAA scheme|
  journal=Information Processing Letters|
  date=2010|
  volume=110|
  issue=12-13|
  pages=485–488|
  url=
|doi=10.1016/j.ipl.2010.04.017}}&lt;/ref&gt; 
Chen, Page, and Smart proposed a new [[elliptic curve cryptography]] scheme using Barreto-Naehrig curves.&lt;ref&gt;
{{cite journal|
  last1=Chen|
  last2=Page|
  last3=Smart|
  title=On the Design and Implementation of an Efficient DAA Scheme|
  journal=8th International Conference on Smart Card Research and Advanced Applications|
  date=2010|
  volume=6035|
  pages=223–237|
  url=https://eprint.iacr.org/2009/598.pdf}}&lt;/ref&gt; This scheme is implemented by both EPID 2.0 and the TPM 2.0 standard, and the TPM 2.0 standard recommends that this scheme is implemented by TPMs in general&lt;ref&gt;https://www.trustedcomputinggroup.org/wp-content/uploads/TPM-Rev-2.0-Part-1-Architecture-01.16.pdf&lt;/ref&gt; and is required for TPMs that conform to the PC client profile.&lt;ref&gt;https://www.trustedcomputinggroup.org/wp-content/uploads/PC-Client-Specific-Platform-TPM-Profile-for-TPM-2-0-v43-150126.pdf&lt;/ref&gt;
In addition, the Intel EPID 2.0 implementation of ISO/IEC 20008 DAA and the available open source SDK &lt;ref&gt;EPID SDK [https://github.com/Intel-EPID-SDK/epid-sdk]&lt;/ref&gt; can be used for members and verifiers to do attestation. Since one of the DAA attestation methods in TPM 2.0 is identical to EPID 2.0, work is underway to make ISO/IEC 20008 DAA and TPM 2.0 DAA attestation read consistently with each other at the spec level.

==See also==
* [[Cryptographic protocol]]
* [[Digital credential]]
* [[Trusted platform module]]
* [[Enhanced_privacy_ID|Enhanced Privacy ID]]
* [[Privacy enhancing technologies]]

==References==
&lt;references/&gt;

==External links==
* E. Brickell, J. Camenisch, and L. Chen: ''Direct anonymous attestation''. In Proceedings of 11th ACM Conference on Computer and Communications Security, ACM Press, 2004. ([http://www.zurich.ibm.com/~jca/papers/brcach04.pdf PDF])
* E. Brickell, J. Camenisch, and L. Chen: ''Direct anonymous attestation'' . ([http://eprint.iacr.org/2004/205.pdf])
* [https://www.ma.rhul.ac.uk/static/techrep/2005/RHUL-MA-2005-13.pdf ''Interdomain User Authentication and Privacy''] by Andreas Pashalidis - section 6 provides a useful introduction to DAA
* [http://www.zurich.ibm.com/security/idemix/ ''IBM idemix (identity mixer)''] an 'anonymous credential system' under development by IBM
* Heiko Stamer - [https://gist.github.com/HeikoStamer/713d7bcdf936e6e46a75cacd1f5bee74/raw/32960ddc98b85e46d69801f084c8bbd63ea1ea1b/KryptoTag_Bochum.pdf Implementing Direct Anonymous Attestation for the TPM Emulator Project ]
* Open source [https://github.com/xaptum/ecdaa C library implementation] by [https://www.xaptum.com Xaptum]
* Open source [https://github.com/Intel-EPID-SDK/epid-sdk  Intel(R) Enhanced Privacy ID Software Development Kit]

[[Category:Cryptography]]
[[Category:Internet privacy software]]</text>
      <sha1>fwnh4e10977tke97l5ss5wx66o0vktb</sha1>
    </revision>
  </page>
  <page>
    <title>Edward Waring</title>
    <ns>0</ns>
    <id>9723</id>
    <revision>
      <id>825480680</id>
      <parentid>776183526</parentid>
      <timestamp>2018-02-13T17:08:32Z</timestamp>
      <contributor>
        <ip>192.173.128.38</ip>
      </contributor>
      <comment>unnecessary infobox rows</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9974">{{EngvarB|date=July 2014}}
{{Use dmy dates|date=July 2014}}
{{other people}}
{{Refimprove|date=February 2009}}
{{Infobox scientist
|name              = Edward Waring
|image             = edwardwaring.jpg  
|image_size        = 200px
|caption           = Edward Waring (ca. 1736–1798). Portrait by [[Thomas Kerrich]], 1794.
|birth_date        = ca. 1736
|birth_place       = [[Shrewsbury|Old Heath]], Shropshire, England, UK
|death_date        = {{death date and age|df=yes|1798|08|15|1736|01|01}}
|death_place       = {{nowrap|[[Plealey]], [[Pontesbury]], Shropshire, England}}
|residence         = England
|citizenship       = 
|nationality       = British
|ethnicity         = 
|fields            = Mathematics
|workplaces        = [[University of Cambridge]]
|alma_mater        = [[Magdalene College, Cambridge]] 
|notable_students  = [[John Wilson (mathematician)|John Wilson]]&lt;br&gt;[[John Dawson (surgeon)|John Dawson]]
|known_for         = [[Waring's problem]]&lt;br&gt;[[Waring's prime number conjecture]] 
|influences        = 
|influenced        = 
|awards            = [[Copley Medal]] (1784)
|signature         =  &lt;!--(filename only)--&gt;
|footnotes         = 
}}
'''Edward Waring''' {{post-nominals|country=GBR|FRS}} ({{circa|1736}}{{spaced ndash}}15 August 1798) was a British mathematician. He entered [[Magdalene College, Cambridge]] as a [[sizar]] and became [[Senior wrangler]] in 1757. He was elected a Fellow of Magdalene and in 1760 [[Lucasian Professor of Mathematics]], holding the chair until his death. He made the assertion known as [[Waring's problem]] without proof in his writings ''Meditationes Algebraicae''. Waring was elected a [[Fellow of the Royal Society]] in 1763 and awarded the [[Copley Medal]] in 1784.

==Early years==
Waring was the eldest son of John and Elizabeth Waring, a prosperous farming couple. He received his early education in [[Shrewsbury School]] under a Mr Hotchkin and was admitted as a [[sizar]] at [[Magdalene College, Cambridge]], on 24 March 1753, being also Millington exhibitioner.&lt;ref&gt;{{acad|id=WRN753E|name=Waring, Edward}}&lt;/ref&gt; His extraordinary talent for mathematics was recognised from his early years in Cambridge. In 1757 he graduated BA as [[senior wrangler]] and on 24 April 1758 was elected to a fellowship at Magdalene. He belonged to the [[Hyson Club]], whose members included [[William Paley]].

==Career==
At the end of 1759 Waring published the first chapter of ''Miscellanea Analytica''. On 28 January the next year he was appointed [[Lucasian professor]] of mathematics, one of the highest positions in Cambridge. [[William Samuel Powell]], then tutor in [[St John's College, Cambridge]] opposed Waring's election and instead supported the candidacy of [[William Ludlam]]. In the polemic with Powell, Waring was backed by [[John Wilson (mathematician)|John Wilson]]. In fact Waring was very young and did not hold the MA, necessary for qualifying for the Lucasian chair, but this was granted him in 1760 by royal mandate. In 1762 he published the full ''Miscellanea Analytica'', mainly devoted to the theory of numbers and algebraic equations. In 1763 he was elected to the [[Royal Society]]. He was awarded its [[Copley Medal]] in 1784 but withdrew from the society in 1795, after he had reached sixty, 'on account of [his] age'. Waring was also a member of the academies of sciences of [[Göttingen]] and [[Institute of Bologna Academy of Sciences|Bologna]]. In 1767 he took an MD degree, but his activity in medicine was quite limited. He carried out dissections with [[Richard Watson (bishop)|Richard Watson]], professor of chemistry and later bishop of [[Llandaff]]. From about 1770 he was physician at [[Addenbrooke's Hospital]] at Cambridge, and he also practised at [[St Ives, Huntingdonshire]], where he lived for some years after 1767. His career as a physician was not very successful since he was seriously short-sighted and a very shy man.

==Personal life==
Waring had a younger brother, Humphrey, who obtained a fellowship at Magdalene in 1775. In 1776 Waring married Mary Oswell, sister of a draper in Shrewsbury; they moved to Shrewsbury and then retired to [[Plealey]], 8 miles out of the town, where Waring owned an estate of 215 acres in 1797&lt;ref&gt;{{cite book|last=Gaydon &amp; Lawson|first=A.T. &amp; J.B.|title=A History of Pontesbury|year=1982|publisher=Shropshire Libraries|page=275|isbn=0-903802-23-6}}&lt;/ref&gt;

==Work==
[[File:Waring - Miscellanea analytica, de aequationibus algebraicis et curvarum proprietatibus, 1762 - 717386.tif|thumb|''Miscellanea analytica'', 1762]]
Waring wrote a number of papers in the ''Philosophical Transactions of the Royal Society'', dealing with the resolution of algebraic equations, number theory, series, approximation of roots, interpolation, the geometry of conic sections, and dynamics. The ''Meditationes Algebraicae'' (1770), where many of the results published in ''Miscellanea Analytica'' were reworked and expanded, was described by [[Joseph-Louis Lagrange]] as 'a work full of excellent researches'. In this work Waring published many theorems concerning the solution of algebraic equations which attracted the attention of continental mathematicians, but his best results are in number theory. Included in this work was the so-called [[Goldbach conjecture]] (every even integer is the sum of two primes), and also the following conjecture: every odd integer is a prime or the sum of three primes. Lagrange had proved that every positive integer is the [[Lagrange's four-square theorem|sum of not more than four squares]]; Waring suggested that every positive integer is either a cube or the sum of not more than nine cubes. He also advanced the hypothesis that every positive integer is either a biquadrate (fourth power) or the sum of not more than nineteen biquadrates. These hypotheses form what is known as [[Waring's problem]]. He also published a theorem, due to his friend John Wilson, concerning prime numbers; it was later proven rigorously by Lagrange.

In ''Proprietates Algebraicarum Curvarum'' (1772) Waring reissued in a much revised form the first four chapters of the second part of ''Miscellanea Analytica''. He devoted himself to the classification of higher plane curves, improving results obtained by [[Isaac Newton]], [[James Stirling (mathematician)|James Stirling]], [[Leonhard Euler]], and [[Gabriel Cramer]]. In 1794 he published a few copies of a philosophical work entitled ''An Essay on the Principles of Human Knowledge'', which were circulated among his friends.

Waring's mathematical style is highly analytical. In fact he criticised those British mathematicians who adhered too strictly to geometry. It is indicative that he was one of the subscribers of [[John Landen]]'s ''Residual Analysis'' (1764), one of the works in which the tradition of the Newtonian fluxional calculus was more severely criticised. In the preface of ''Meditationes Analyticae'' Waring showed a good knowledge of continental mathematicians such as [[Alexis Clairaut]], [[Jean le Rond d'Alembert]], and Euler. He lamented the fact that in Great Britain mathematics was cultivated with less interest than on the continent, and clearly desired to be considered as highly as the great names in continental mathematics—there is no doubt that he was reading their work at a level never reached by any other eighteenth-century British mathematician. Most notably, at the end of chapter three of ''Meditationes Analyticae'' Waring presents some partial fluxional equations (partial differential equations in Leibnizian terminology); such equations are a mathematical instrument of great importance in the study of continuous bodies which was almost completely neglected in Britain before Waring's researches. One of the most interesting results in ''Meditationes Analyticae'' is a test for the convergence of series generally attributed to d'Alembert (the 'ratio test'). The theory of convergence of series (the object of which is to establish when the summation of an infinite number of terms can be said to have a finite 'sum') was not much advanced in the eighteenth century.

Waring's work was known both in Britain and on the continent, but it is difficult to evaluate his impact on the development of mathematics. His work on algebraic equations contained in ''Miscellanea Analytica'' was translated into Italian by [[Vincenzo Riccati]] in 1770. Waring's style is not systematic and his exposition is often obscure. It seems that he never lectured and did not habitually correspond with other mathematicians. After [[Jérôme Lalande]] in 1796 observed, in ''Notice sur la vie de Condorcet'', that in 1764 there was not a single first-rate analyst in England, Waring's reply, published after his death as 'Original letter of Dr Waring' in the ''Monthly Magazine'', stated that he had given 'somewhere between three and four hundred new propositions of one kind or another'.

==Death==
During his last years he sank into a deep religious melancholy, and a violent cold caused his death, in [[Plealey]], on 15 August 1798. He was buried in the churchyard at [[Fitz, Shropshire]].

==See also==
*[[Lagrange polynomial]]
*[[Waring's prime number conjecture]]

==References==
&lt;references/&gt;

==External links==
*{{MacTutor Biography|id=Waring}}

{{Lucasian Professors of Mathematics}}
{{Copley Medallists 1751–1800}}

{{Authority control}}

{{DEFAULTSORT:Waring, Edward}}
[[Category:1736 births]]
[[Category:1798 deaths]]
[[Category:18th-century English people]]
[[Category:18th-century English mathematicians]]
[[Category:Academics of the University of Cambridge]]
[[Category:Alumni of Magdalene College, Cambridge]]
[[Category:Fellows of Magdalene College, Cambridge]]
[[Category:Fellows of the Royal Society]]
[[Category:Lucasian Professors of Mathematics]]
[[Category:Number theorists]]
[[Category:People from Shrewsbury]]
[[Category:Recipients of the Copley Medal]]
[[Category:Senior Wranglers]]
[[Category:Date of birth unknown]]</text>
      <sha1>drzgwpxqetynm1svixhggj680g65uzq</sha1>
    </revision>
  </page>
  <page>
    <title>Finite model property</title>
    <ns>0</ns>
    <id>14842181</id>
    <revision>
      <id>852637456</id>
      <parentid>816113490</parentid>
      <timestamp>2018-07-30T10:38:41Z</timestamp>
      <contributor>
        <ip>213.10.47.45</ip>
      </contributor>
      <comment>missing word</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1603">In [[logic]], a logic '''L''' has the '''finite model property''' (fmp for short) if any non-theorem of '''L''' is falsified by some ''finite'' model of '''L'''. Another way of putting this is to say that '''L''' has the fmp if for every formula A of '''L''', A is an L-theorem [[iff]] A is a theorem of the theory of finite models of '''L'''.

If '''L''' is finitely axiomatizable (and has a recursive set of recursive rules) and has the fmp, then it is decidable. However, the result does not hold if '''L''' is merely recursively axiomatizable. Even if there are only finitely many finite models to choose from (up to isomorphism) there is still the problem of checking whether the underlying frames of such models validate the logic, and this may not be decidable when the logic is not finitely axiomatizable, even when it is recursively axiomatizable. (Note that a logic is recursively enumerable if and only if it is recursively axiomatizable, a result known as [[Craig's theorem]].)

== Example ==
A first-order formula with one universal quantification has the fmp. A first-order formula without functional symbols, where all existential quantifications appear first in the formula, also has the fmp.&lt;ref&gt;[[Leonid Libkin]], ''Elements of finite model theory'', chapter 14&lt;/ref&gt;

== See also ==
* [[Kripke semantics]]

== References ==
* Blackburn P., de Rijke M., Venema Y. ''Modal Logic''. Cambridge University Press, 2001.
* A Urquhart. Decidability and the Finite Model Property. ''Journal of Philosophical Logic'', 10 (1981), 367-370.
{{Reflist}}

[[Category:Logic]]
[[Category:Modal logic]]</text>
      <sha1>0oeuac8ude217vtlonrno4udosme0b2</sha1>
    </revision>
  </page>
  <page>
    <title>First-order predicate</title>
    <ns>0</ns>
    <id>11344</id>
    <revision>
      <id>772185084</id>
      <parentid>745601821</parentid>
      <timestamp>2017-03-25T20:32:10Z</timestamp>
      <contributor>
        <username>Jabowery</username>
        <id>50861</id>
      </contributor>
      <comment>Correct serious error (confusing "monad" with "first order predicate").</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="934">In [[mathematical logic]], a '''first-order predicate''' is a [[predicate (logic)|predicate]] that takes only individual(s) constants or variables as argument(s).&lt;ref&gt;{{citation|title=A Dictionary of Philosophy: Revised Second Edition|first=Antony|last=Flew|publisher=Macmillan|year=1984|isbn=9780312209230|page=147|url=https://books.google.com/books?id=MmJHVU9Rv3YC&amp;pg=PA147}}.&lt;/ref&gt; Compare [[second-order predicate]] and [[higher-order predicate]].

This is not to be confused with a '''one-place predicate''' or monad, which is a predicate that takes only one argument. For example the expression "is a planet" is a one-place predicate, while the expression "is father of" is a '''two-place predicate'''.

==See also==
*[[First-order predicate calculus]]
*[[Monadic predicate calculus]]

==References==
{{reflist}}

{{DEFAULTSORT:First-Order Predicate}}
[[Category:Predicate logic]]
[[Category:Concepts in logic]]


{{Logic-stub}}</text>
      <sha1>iuin3q9kmo3y9r6mdhtehln6fck7s2j</sha1>
    </revision>
  </page>
  <page>
    <title>Formulas for generating Pythagorean triples</title>
    <ns>0</ns>
    <id>21138193</id>
    <revision>
      <id>864470879</id>
      <parentid>862928529</parentid>
      <timestamp>2018-10-17T12:37:55Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <minor/>
      <comment>clean up spacing around commas, replaced: ,k → , k, ,q → , q, ,y → , y,  ,  → ,</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="23964">Besides Euclid's formula, many other '''formulas for generating [[Pythagorean triple]]s''' have been developed.

==Euclid's, Pythagoras', and Plato's formulas==

Euclid's, Pythagoras' and Plato's formulas for calculating triples have been described here: {{main article|Pythagorean triple}}

The methods below appear in various sources, often without attribution as to their origin.

==Fibonacci's method==
[[Leonardo of Pisa]] ({{circa|1170|1250}}) described this method&lt;ref&gt;Fibonacci, Leonardo Pisano, (1225), [[The Book of Squares|Liber Quadratorum]].&lt;/ref&gt;&lt;ref&gt;Fibonacci, Leonardo Pisano .  ''[http://www.elsevierdirect.com/ISBN/9780126431308/Leonardo-Pisano-Fibonacc The Book of Squares (Liber Quadratorum).  An annotated translation into modern English''] by L. E. Sigler.  (1987) Orlando, FL: Academic Press. {{ISBN|978-0-12-643130-8}}&lt;/ref&gt; for generating primitive triples using the sequence of consecutive odd integers &lt;math&gt;1,3,5,7,9,11,\ldots&lt;/math&gt; and the fact that the sum of the first &lt;math&gt;n&lt;/math&gt; terms of this sequence is &lt;math&gt;n^2&lt;/math&gt;. If &lt;math&gt;k&lt;/math&gt; is the &lt;math&gt;n&lt;/math&gt;-th member of this sequence then &lt;math&gt;n=(k+1)/2&lt;/math&gt;.

Choose any odd square number &lt;math&gt;k&lt;/math&gt; from this sequence (&lt;math&gt;k=a^2&lt;/math&gt;) and let this square be the &lt;math&gt;n&lt;/math&gt;-th term of the sequence. Also, let &lt;math&gt;b^2&lt;/math&gt; be the sum of the previous &lt;math&gt;n-1&lt;/math&gt; terms,  and let &lt;math&gt;c^2&lt;/math&gt;   be the sum of all &lt;math&gt;n&lt;/math&gt; terms. Then we have established that &lt;math&gt;a^2+b^2=c^2&lt;/math&gt; and we have generated the primitive triple [''a, b, c'']. This method produces an infinite number of primitive triples, but not all of them.

EXAMPLE:
Choose &lt;math&gt;k=9=3^2=a^2&lt;/math&gt;. This odd square number is the fifth term of the sequence, because &lt;math&gt;5=n=(a^2+1)/2&lt;/math&gt;. The sum of the previous 4 terms is &lt;math&gt;b^2 = 4^2&lt;/math&gt; and the sum of all &lt;math&gt;n=5&lt;/math&gt; terms is &lt;math&gt;c^2 = 5^2&lt;/math&gt; giving us &lt;math&gt;a^2+b^2=c^2&lt;/math&gt; and the primitive triple [''a, b, c''] = [3, 4, 5].

==Progressions of whole and fractional numbers==

The German monk and mathematician [[Michael Stifel]] published the following method in 1544.&lt;ref&gt;Stifel, Michael, (1544),
  [http://mathdl.maa.org/mathDL/46/?pa=content&amp;sa=viewDocument&amp;nodeId=2591&amp;bodyId=3752 Arithmetica Integra].&lt;/ref&gt;&lt;ref&gt;{{Cite journal |author=Ozanam, Jacques | url=https://books.google.com/?id=s_IJAAAAMAAJ&amp;pg=RA3-PA49&amp;lpg=RA3-PA49&amp;dq=%22progression+of+whole+and+fractional+numbers%22&amp;q=%22progression%20of%20whole%20and%20fractional%20numbers%22 |title=Recreations in Mathematics and Natural Philosophy |publisher=G. Kearsley|volume=1|page=49 |year=1814|accessdate=2009-11-19 |postscript=. }}&lt;/ref&gt;

Consider the progression of whole and fractional numbers:
&lt;math&gt;1\tfrac{1}{3},\text{ }2\tfrac{2}{5},\text{ }3\tfrac{3}{7},\text{ }4\tfrac{4}{9},\ldots &lt;/math&gt;

The properties of this progression are:
(a) the whole numbers are those of the common series and have unity as their common difference; (b) the numerators of the fractions, annexed to the whole numbers, are also the natural numbers; (c) the denominators of the fractions are the odd numbers, &lt;math&gt;3,\text{ }5,\text{ }7,\text{ }9,&lt;/math&gt; etc.

To calculate a Pythagorean triple select any term of this progression and reduce it to an improper fraction.  For example, take the term &lt;math&gt;3\tfrac{3}{7}&lt;/math&gt;.  The improper fraction is &lt;math&gt;\tfrac{24}{7}&lt;/math&gt;.  The numbers 7 and 24 are the sides, ''a'' and ''b'', of a right triangle, and the hypotenuse is one greater than the largest side.  For example:

: &lt;math&gt;1\tfrac{1}{3}\text{ }\xrightarrow{\text{yields}}\text{ }[3,4,5],\text{    2}\tfrac{2}{5}\text{ }\xrightarrow{\text{yields}}\text{ }[5,12,13],\text{    3}\tfrac{3}{7}\text{ }\xrightarrow{\text{yields}}\text{ }[7,24,25],\text{    4}\tfrac{4}{9}\text{ }\xrightarrow{\text{yields}}\text{ }[9,40,41],\text{ }\ldots&lt;/math&gt;

[[Jacques Ozanam]]&lt;ref&gt;Ozanam, Jacques, (1844). Science and Natural Philosophy: Dr. Hutton's Translation of Montucla's edition of Ozanam, revised by Edward Riddle, Thomas Tegg, London. [http://ebooks.library.cornell.edu/cgi/t/text/pageviewer-idx?c=math;cc=math;q1=ozanam;rgn=full%20text;idno=07160001;didno=07160001;view=image;seq=7;page=root;size=50  Read online- Cornell University]&lt;/ref&gt; republished Stifel's sequence in 1694 and added the similar sequence &lt;math&gt;1\tfrac{7}{8},\text{ }2\tfrac{11}{12},\text{ }3 \tfrac{15}{16},\text{ }4\tfrac{19}{20},\ldots&lt;/math&gt;  with terms derived from &lt;math&gt;n+\tfrac{4n+3}{4n+4}&lt;/math&gt;.  As before, to produce a triple from this sequence, select any term and reduce it to an improper fraction.  The numerator and denominator are the sides, ''a'' and ''b'', of a right triangle. In this case, the hypotenuse of the triple(s) produced is 2 greater than the larger side.  For example:

: &lt;math&gt;1\tfrac{7}{8}\xrightarrow{\text{yields}}[15,8,17],2\tfrac{11}{12}\xrightarrow{\text{yields}}[35,12,37],3\tfrac{15}{16}\xrightarrow{\text{yields}}[63,16,65],4\tfrac{19}{20}\xrightarrow{\text{yields}}[99,20,101],\ldots &lt;/math&gt;

Together, the Stifel and Ozanam sequences produce all primitive triples of the '''''Plato''''' and '''''Pythagoras''''' families respectively.  The '''''Fermat''''' family must be found by other means.

:&lt;math&gt;\text{Plato: }c-b=1,\quad \quad \text{Pythagoras: }c-a=2,\quad \quad \text{Fermat: }\left| a-b \right|=1&lt;/math&gt;

==Dickson's method==

[[L. E. Dickson|Leonard Eugene Dickson]] (1920)&lt;ref&gt;Dickson, L. E. (1920), ''[[History of the Theory of Numbers]], Vol.II. Diophantine Analysis'', Carnegie Institution of Washington, Publication No. 256, 12+803pp [https://archive.org/stream/historyoftheoryo02dickuoft#page/168/mode/2up Read online - University of Toronto]&lt;/ref&gt; attributes to himself the following method for generating Pythagorean triples. To find integer solutions to &lt;math&gt;x^2+y^2=z^2&lt;/math&gt;, find positive integers ''r'', ''s'', and ''t'' such that &lt;math&gt;r^2=2st&lt;/math&gt; is a perfect square.

Then:

: &lt;math&gt; x = r + s \,,\,y = r + t \,,\, z = r + s + t. &lt;/math&gt;

From this we see that &lt;math&gt;r&lt;/math&gt; is any even integer and that ''s'' and ''t'' are factors of &lt;math&gt;\tfrac{r^2}{2}&lt;/math&gt;.&amp;nbsp; All Pythagorean triples may be found by this method. &amp;nbsp;When ''s'' and ''t'' are coprime, the triple will be primitive. A simple proof of Dickson's method has been presented by Josef Rukavicka  (2013).&lt;ref&gt;Rukavicka, J. (2013), ''Dickson's Method for Generating Pythagorean Triples Revisited'', European Journal of Pure and Applied Mathematics ISSN 1307-5543, Vol. 6, No. 3 (2013) p.363-364, [https://www.researchgate.net/publication/314088315_Dickson%27s_Method_for_Generating_Pythagorean_Triples_Revisited online1] [http://ejpam.com/index.php/ejpam/article/view/1844/309 online2]&lt;/ref&gt;

Example: Choose ''r'' = 6.  Then &lt;math&gt;\tfrac{r^2}{2} = 18&lt;/math&gt;.
The three factor-pairs of 18 are: (1, 18), (2, 9), and (3, 6). All three factor pairs will produce triples using the above equations.

:''s'' = 1, ''t'' = 18 produces the triple [7, 24, 25] because ''x'' = 6 + 1 = 7,&amp;nbsp; ''y'' = 6 + 18 = 24, &amp;nbsp;''z'' = 6 + 1 + 18 = 25.

:''s'' = 2, ''t'' = &amp;nbsp; 9 produces the triple [8, 15, 17] because ''x'' = 6 + 2 = 8,&amp;nbsp; ''y'' = 6 + &amp;nbsp;9 = 15,&amp;nbsp; ''z'' = 6 + 2 + 9 = 17.

:''s'' = 3, ''t'' = &amp;nbsp; 6 produces the triple [9, 12, 15] because ''x'' = 6 + 3 = 9,&amp;nbsp; ''y'' = 6 + &amp;nbsp;6 = 12, &amp;nbsp;''z'' = 6 + 3 + 6 = 15. (Since ''s'' and ''t'' are not coprime, this triple is not primitive.)

==Generalized Fibonacci sequence==

===Method I===

For Fibonacci numbers starting with {{nowrap|1=''F''&lt;sub&gt;1&lt;/sub&gt; = 0}} and {{nowrap|1=''F''&lt;sub&gt;2&lt;/sub&gt; = 1}} and with each succeeding Fibonacci number being the sum of the preceding two, one can generate a sequence of Pythagorean triples starting from (''a''&lt;sub&gt;3&lt;/sub&gt;, ''b''&lt;sub&gt;3&lt;/sub&gt;, ''c''&lt;sub&gt;3&lt;/sub&gt;) = (4, 3, 5) via

:&lt;math&gt;(a_n, b_n, c_n) = (a_{n-1}+b_{n-1}+c_{n-1}, \, F_{2n-1}-b_{n-1}, \, F_{2n})&lt;/math&gt;

for ''n'' ≥ 4.

===Method II===

A Pythagorean triple can be generated using any two positive integers by the following procedures using generalized [[Fibonacci sequence]]s.

For initial positive integers ''h''&lt;sub&gt;''n''&lt;/sub&gt; and ''h''&lt;sub&gt;''n''+1&lt;/sub&gt;, if {{nowrap|1=''h''&lt;sub&gt;''n''&lt;/sub&gt; + ''h''&lt;sub&gt;''n''+1&lt;/sub&gt; = ''h''&lt;sub&gt;''n''+2&lt;/sub&gt;}} and {{nowrap|1=''h''&lt;sub&gt;''n''+1&lt;/sub&gt; + ''h''&lt;sub&gt;''n''+2&lt;/sub&gt; = ''h''&lt;sub&gt;''n''+3&lt;/sub&gt;}}, then

:&lt;math&gt;(2h_{n+1} h_{n+2}, h_nh_{n+3}, 2h_{n+1}h_{n+2}+h_n ^2)&lt;/math&gt;

is a Pythagorean triple.&lt;ref&gt;Horadam, A. F., "Fibonacci number triples", ''[[American Mathematical Monthly]]'' 68, 1961, 751-753.&lt;/ref&gt;

===Method III===

The following is a [[Matrix (mathematics)|matrix]]-based approach to generating primitive triples with generalized Fibonacci sequences.&lt;ref name=Bernhart&gt;{{cite arXiv|author1=Bernhart, Frank R.  |author2=Price, H. Lee |title=Heron's formula, Descartes circles, and Pythagorean triangles |year=2005 |eprint=math/0701624v1 }}&lt;/ref&gt;  Start with a 2 × 2 array and insert two coprime positive integers '''''( q,q' )''''' in the top row. Place the even integer (if any) in the {{nowrap|left-hand}}  column.

: &lt;math&gt;
\left[ {\begin{array}{*{20}c}
   q &amp; {q'}  \\
    \bullet  &amp;  \bullet
\end{array}} \right]
&lt;/math&gt;

Now apply the following "Fibonacci rule" to get the entries in the bottom 
row:

: &lt;math&gt;
\begin{array}{*{20}c}
   q' + q = p  \\
   q + p = p'
\end{array} \to \left[ {\begin{array}{*{20}c}
   q &amp; q'  \\
   p &amp; p'
\end{array}} \right]
&lt;/math&gt;

Such an array may be called a "Fibonacci Box".  Note that  ''''' q', q, p, p' '''''  is a generalized Fibonacci sequence. Taking column, row, and diagonal products we obtain the sides of triangle '''[a, b, c],''' its area '''''A''''', and its perimeter '''''P''''', as well as the radii '''''r'''''&lt;sub&gt;'''''i'''''&lt;/sub&gt; of its [[incircle]] and three [[excircles]] as follows:

: &lt;math&gt;
\begin{array}{l}
 a = 2qp \\ 
 b = q'p' \\ 
 c = pp' - qq' = qp' + q'p \\ 
  \\ 
 \text{radii} \to (r_1 = qq', r_2 = qp', r_3 = q'p, r_4 = pp') \\ 
 A = qq'pp' \\ 
 P = r_1 + r_2 + r_3 + r_4
 \end{array}
&lt;/math&gt;

The half-angle tangents at the acute angles are '''''q/p''''' and '''''q'/p''''''.

EXAMPLE:

Using [[coprime]] integers 9 and 2.

: &lt;math&gt;
\left[ {\begin{array}{*{20}c}
   2 &amp; 9  \\
    \bullet  &amp;  \bullet
\end{array}} \right] \to \left[ {\begin{array}{*{20}c}
   2 &amp; 9  \\
   11 &amp; 13
\end{array}} \right]
&lt;/math&gt;

The column, row, and diagonal products are: (columns: 22 and 117), (rows: 18 and 143), (diagonals: 26 and 99), so

: &lt;math&gt;
\begin{array}{l}
 a = 2(22) = 44  \\ 
 b = 117 \\ 
 c = (143 - 18) = (26 + 99) = 125 \\ 
  \\ 
 \text{radii} \to (r_1 = 18,\quad r_2 = 26,\quad r_3 = 99,\quad r_4 = 143) \\ 
 A = 18(143) = 2574 \\ 
 P = (18 + 26 + 99 + 143) = 286
 \end{array}
&lt;/math&gt;

The half-angle tangents at the acute angles are 2/11 and 9/13.  Note that if the chosen integers '''''q''''', '''''q'''''' are not [[coprime]], the same procedure leads to a non-primitive triple.

====Pythagorean triples and Descartes' circle equation====

This method of generating ''primitive Pythagorean triples'' also provides integer solutions to [[Descartes' theorem|Descartes' Circle Equation]],&lt;ref name=Bernhart /&gt;

: &lt;math&gt;\left( k_1 + k_2 + k_3 + k_4 \right)^2 = 2\left( k_1^2 + k_2^2 + k_3^2 + k_4^2 \right),&lt;/math&gt;

where integer [[curvature]]s  ''k&lt;sub&gt;i&lt;/sub&gt;'' are obtained by multiplying the reciprocal of each radius by the area '''''A'''''. The result is ''k''&lt;sub&gt;1&lt;/sub&gt; = pp',  ''k''&lt;sub&gt;2&lt;/sub&gt; = qp', ''k''&lt;sub&gt;3&lt;/sub&gt; = q'p,  ''k''&lt;sub&gt;4&lt;/sub&gt; = qq'.  Here, the largest circle is taken as having negative curvature with respect to the other three. The largest circle (curvature ''k''&lt;sub&gt;4&lt;/sub&gt;) may also be replaced by a smaller circle with positive curvature ( ''k''&lt;sub&gt;0&lt;/sub&gt; = 4''pp' − qq' ''). 

EXAMPLE: 

Using the area and four radii obtained above for primitive triple [44, 117, 125] we obtain the following integer solutions to Descartes' Equation:  ''k''&lt;sub&gt;1&lt;/sub&gt; = 143, ''k''&lt;sub&gt;2&lt;/sub&gt; = 99, ''k''&lt;sub&gt;3&lt;/sub&gt; = 26, ''k''&lt;sub&gt;4&lt;/sub&gt; = (−18), and ''k''&lt;sub&gt;0&lt;/sub&gt; = 554.

====A Ternary Tree:  Generating All Primitive Pythagorean Triples====

Each primitive Pythagorean triple corresponds uniquely to a Fibonacci Box.  Conversely, each Fibonacci Box corresponds to a unique and primitive Pythagorean triple. In this section we shall use the Fibonacci Box in place of the primitive triple it represents.  An infinite [[ternary tree]] containing all primitive Pythagorean triples/Fibonacci Boxes can be constructed by the following procedure.&lt;ref name=Price&gt;{{cite arXiv|first=H. Lee|last=Price|title=The Pythagorean Tree: A New Species |year=2008|eprint=0809.4324}}&lt;/ref&gt;

Consider a Fibonacci Box containing two, odd, coprime integers ''x'' and ''y'' in the right-hand column.

: &lt;math&gt;
\left[ {\begin{array}{*{20}{c}}
    \bullet  &amp; x  \\
    \bullet  &amp; y
\end{array}} \right]
&lt;/math&gt;

It may be seen that these integers can also be placed as follows:
 
: &lt;math&gt;
\left[ {\begin{array}{*{20}{c}}
    \bullet  &amp; x  \\
   y &amp;  \bullet
\end{array}} \right],\left[ {\begin{array}{*{20}{c}}
   x &amp; y  \\
    \bullet  &amp;  \bullet
\end{array}} \right],\left[ {\begin{array}{*{20}{c}}
   y &amp; x  \\
    \bullet  &amp;  \bullet
\end{array}} \right]
&lt;/math&gt;

resulting in three more valid Fibonacci boxes containing ''x'' and ''y''. We may think of the first Box as the "parent" of the next three.  For example, if ''x'' = 1 and ''y'' = 3 we have:

: &lt;math&gt;
\left[ {\begin{array}{*{20}{c}}
   1 &amp; 1  \\
   2 &amp; 3
\end{array}} \right] \leftarrow \text{parent}
&lt;/math&gt;

: &lt;math&gt;
\left[ {\begin{array}{*{20}{c}}
   2 &amp; 1  \\
   3 &amp; 5
\end{array}} \right],\left[ {\begin{array}{*{20}{c}}
   1 &amp; 3  \\
   4 &amp; 5
\end{array}} \right],\left[ {\begin{array}{*{20}{c}}
   3 &amp; 1  \\
   4 &amp; 7
\end{array}} \right] \leftarrow \text{children}
&lt;/math&gt;

Moreover, each "child" is itself the parent of three more children which can be obtained by the same procedure.   Continuing this process at each node leads to an infinite ternary tree containing all possible Fibonacci Boxes, or equivalently, to a ternary tree containing all possible primitive triples.  (The tree shown here is distinct from the classic tree described by Berggren in 1934, and has many different number-theoretic properties.)  Compare: "Classic Tree".&lt;ref name=Berggren&gt;{{Cite journal|last=Berggren|first=B.|title=Pytagoreiska trianglar| journal=Tidskrift för elementär matematik, fysik och kemi|volume=17|year=1934|pages=129–139|language=Swedish|postscript=.}}&lt;/ref&gt;  See also [[Tree of primitive Pythagorean triples]].&lt;ref&gt;{{cite book |last=Carvalho |first1=Alda |last2=Pereira dos Santos |first2=Carlos |title=Proceedings of the recreational mathematics colloquium II, University of Évora, Portugal, April 27–30, 2011 |chapter=A very useful Pythagorean tree |editor-last=Silva |editor-first=Jorge Nuno |publisher=Lisboa: Associação Ludus |date=2012 |pages=3–15 |isbn=9789899734623 }}&lt;/ref&gt;

==Generating triples using quadratic equations==

There are several methods for defining [[quadratic equations]] for calculating each leg of a Pythagorean triple.&lt;ref&gt;J. L. Poet and D. L. Vestal, Jr. (2005). "Curious Consequences of a Miscopied Quadratic, " ''College Mathematics Journal'' 36, 273–277.&lt;/ref&gt;   A simple method is to modify the standard Euclid equation by adding a variable ''x'' to each ''m'' and ''n'' pair.    The ''m, n'' pair is treated as a constant while the value of ''x'' is varied to produce a "family" of triples based on the selected triple.  An arbitrary coefficient can be placed in front of the "''x''" value on either ''m'' or ''n'', which causes the resulting equation to systematically "skip" through the triples.   For example, consider the  triple  [20, 21, 29] which can be calculated from the Euclid equations with a value of ''m'' = 5 and ''n'' = 2.   Also, arbitrarily put the coefficient of 4 in front of the "''x''" in the "''m''" term.

Let &lt;math&gt;m_1=(4x+m)&lt;/math&gt; and let &lt;math&gt;n_1=(x+n)&lt;/math&gt;

Hence, substituting the values of ''m'' and ''n'':

: &lt;math&gt;\begin{align}
   \text{Side }A &amp; =2m_1 n_1 &amp; &amp; = 2(4x+5)\text{ }(x+2) &amp; &amp; = 8x^2+26x+20  \\
   \text{Side }B &amp; =m_1^2-n_1^2 &amp; &amp; = (4x+5)^2-(x+2)^2 &amp; &amp; = 15x^2+36x+21  \\
   \text{Side }C &amp; =m_1^2+n_1^2 &amp; &amp; = (4x+5)^2+(x+2)^2 &amp; &amp; = 17x^2+44x+29
\end{align}&lt;/math&gt;

Note that the original triple comprises the constant term in each of the respective quadratic equations.  Below is a sample output from these equations.  Note that the effect of these equations is to cause the "''m''" value in the Euclid equations to increment in steps of 4, while the "''n''" value increments by 1.

{| class="wikitable" style="margin-left:1.5em; text-align:right;"
! ''x'' || side ''a'' || side ''b'' || side ''c'' || ''m'' ||  ''n'' 
|-
| 0 || 20 || 21 || 29 || 5 ||  2 
|-
| 1 || 54 || 72 || 90 || 9 ||  3
|-
| 2 || 104 || 153 || 185 || 13 ||  4
|-
| 3 || 170 || 264 || 314 || 17 ||  5
|-
| 4 || 252 || 405 || 477 || 21 || 6
|}

==Pythagorean triples by use of matrices and linear transformations==

{{main article|Tree of primitive Pythagorean triples}}

Let {{math|[''a'', ''b'', ''c'']}} be a primitive triple with {{math|''a''}} odd.  Then 3 new triples {{math|[''a''&lt;sub&gt;1&lt;/sub&gt;, ''b''&lt;sub&gt;1&lt;/sub&gt;, ''c''&lt;sub&gt;1&lt;/sub&gt;]}},  {{math|[''a''&lt;sub&gt;2&lt;/sub&gt;, ''b''&lt;sub&gt;2&lt;/sub&gt;, ''c''&lt;sub&gt;2&lt;/sub&gt;]}}, {{math|[''a''&lt;sub&gt;3&lt;/sub&gt;, ''b''&lt;sub&gt;3&lt;/sub&gt;, ''c''&lt;sub&gt;3&lt;/sub&gt;]}}  may be produced from {{math|[''a'', ''b'', ''c'']}} using [[matrix multiplication]] and  Berggren's&lt;ref name="Berggren"/&gt;  three matrices ''A'', ''B'', ''C''. Triple {{math|[''a'', ''b'', ''c'']}} is termed the ''parent'' of the three new triples (the ''children'').  Each child is itself the parent of 3 more children, and so on.  If one begins with primitive triple [3, 4, 5], all primitive triples will eventually be produced by application of these matrices.  The result can be graphically represented as an infinite [[ternary tree]] with {{math|[''a'', ''b'', ''c'']}} at the root node. An equivalent result may be obtained using Berggrens's three [[linear transformations]] shown below.

: &lt;math&gt;\overset{A}{\mathop{\left[ \begin{matrix}
   -1 &amp; 2 &amp; 2  \\
   -2 &amp; 1 &amp; 2  \\
   -2 &amp; 2 &amp; 3  \\
\end{matrix} \right]}} \left[ \begin{matrix}
   a  \\
   b  \\
   c  \\
\end{matrix} \right]=\left[ \begin{matrix}
   a_1  \\
   b_1  \\
   c_1  \\
\end{matrix} \right],\quad \text{     }\overset{B}{\mathop{\left[ \begin{matrix}
   1 &amp; 2 &amp; 2  \\
   2 &amp; 1 &amp; 2  \\
   2 &amp; 2 &amp; 3  \\
\end{matrix} \right]}} \left[ \begin{matrix}
   a  \\
   b  \\
   c  \\
\end{matrix} \right]=\left[ \begin{matrix}
   a_2 \\
   b_2  \\
   c_2
\end{matrix} \right],\quad \text{     }\overset{C}{\mathop{\left[ \begin{matrix}
   1 &amp; -2 &amp; 2  \\
   2 &amp; -1 &amp; 2  \\
   2 &amp; -2 &amp; 3
\end{matrix} \right]}} \left[ \begin{matrix}
   a  \\
   b  \\
   c
\end{matrix} \right]=\left[ \begin{matrix}
   a_3  \\
   b_3  \\
   c_3
\end{matrix} \right]&lt;/math&gt;

Berggren's three linear transformations are:

: &lt;math&gt;\begin{align}
  &amp; \begin{matrix}
   -a+2b+2c=a_1 \quad &amp; -2a+b+2c=b_1 \quad &amp; -2a+2b+3c=c_1 &amp; \quad\to \left[ \text{ }a_1,\text{ }b_1,\text{ }c_1 \right]  \\
\end{matrix} \\ 
 &amp; \begin{matrix}
   +a+2b+2c={{a}_{2}} \quad &amp; +2a+b+2c={{b}_{2}} \quad &amp; +2a+2b+3c={{c}_{2}} &amp; \quad\to \left[ \text{ }{{a}_{2}},\text{ }{{b}_{2}},\text{ }{{c}_{2}} \right]  \\
\end{matrix} \\ 
 &amp; \begin{matrix}
   +a-2b+2c={{a}_{3}} \quad &amp; +2a-b+2c={{b}_{3}} \quad &amp; +2a-2b+3c={{c}_{3}} &amp; \quad\to \left[ \text{ }{{a}_{3}},\text{ }{{b}_{3}},\text{ }{{c}_{3}}\right]  \\
\end{matrix} \\
 &amp;
\end{align}&lt;/math&gt;

Alternatively, one may also use 3 different matrices found by Price.&lt;ref name="Price"/&gt; These matrices ''A', B', C''' and their corresponding linear transformations are shown below.

: &lt;math&gt;\overset{{{A}'}}{\mathop{\left[ \begin{matrix}
   2 &amp; 1 &amp; -1  \\
   -2 &amp; 2 &amp; 2  \\
   -2 &amp; 1 &amp; 3
\end{matrix} \right]}} \left[ \begin{matrix}
   a  \\
   b  \\
   c
\end{matrix} \right]=\left[ \begin{matrix}
   a_1  \\
   b_1  \\
   c_1
\end{matrix} \right],\quad \text{     }\overset{{{B}'}}{\mathop{\left[ \begin{matrix}
   2 &amp; 1 &amp; 1  \\
   2 &amp; -2 &amp; 2  \\
   2 &amp; -1 &amp; 3
\end{matrix} \right]}} \left[ \begin{matrix}
   a  \\
   b  \\
   c  \\
\end{matrix} \right]=\left[ \begin{matrix}
   a_2 \\
   b_2 \\
   c_2
\end{matrix} \right],\quad \text{     }\overset{{{C}'}}{\mathop{\left[ \begin{matrix}
   2 &amp; -1 &amp; 1  \\
   2 &amp; 2 &amp; 2  \\
   2 &amp; 1 &amp; 3  \\
\end{matrix} \right]}} \left[ \begin{matrix}
   a  \\
   b  \\
   c  \\
\end{matrix} \right]=\left[ \begin{matrix}
   a_3 \\
   b_3 \\
   c_3
\end{matrix} \right]&lt;/math&gt;

Price's three linear transformations are

: &lt;math&gt;\begin{align}
  &amp; \begin{matrix}
   +2a+b-c=a_1 \quad &amp; -2a+2b+2c=b_1 \quad &amp; -2a+b+3c=c_1 &amp; \quad \to \left[ \text{ }a_1,\text{ }b_1,\text{ }c_1 \right]
\end{matrix} \\ 
 &amp; \begin{matrix}
   +2a+b+c=a_2 \quad &amp; +2a-2b+2c=b_2 \quad  &amp; +2a-b+3c=c_2 &amp; \quad \to \left[ \text{ }a_2,\text{ }b_2,\text{ }c_2  \right]
\end{matrix} \\ 
 &amp; \begin{matrix}
   +2a-b+c=a_3 \quad &amp; +2a+2b+2c=b_3 \quad  &amp; +2a+b+3c=c_3 &amp; \quad \to \left[ \text{ }a_3,\text{ }b_3,\text{ }c_3 \right]
\end{matrix} \\ 
 &amp;
\end{align}&lt;/math&gt;

The 3 children produced by each of the two sets of matrices are not the same, but each set separately produces all primitive triples. 
 
For example, using [5, 12, 13] as the parent, we get two sets of three children:

: &lt;math&gt;\begin{array}{ccc}
     &amp; \left[ 5,12,13 \right] &amp;   \\
   A &amp;      B      &amp; C \\
   \left[ 45,28,53 \right] &amp; \left[ 55,48,73 \right] &amp; \left[ 7,24,25 \right]
\end{array}
\quad \quad \quad \quad \quad \quad 
\begin{array}{ccc}
   {} &amp; \left[ 5,12,13 \right] &amp; {}  \\
   A' &amp; B' &amp; C'  \\
   \left[ 9,40,41 \right] &amp; \left[ 35,12,37\right] &amp; \left[ 11,60,61 \right]
\end{array}
&lt;/math&gt;

==Area proportional to sums of squares==

All primitive triples with &lt;math&gt;b+1=c&lt;/math&gt; and with ''a'' odd can be generated as follows:&lt;ref&gt;Barbeau, Edward, ''Power Play'', Mathematical Association of America,1997, p. 51, item 3.&lt;/ref&gt;

{| class="wikitable"
|-
! Pythagorean triple !! Semi-perimeter !! Area !! Incircle radius !! Circumcircle radius
|-
| &lt;math&gt;\left( 3,4,5 \right)&lt;/math&gt; || 1 + 2 + 3 || &lt;math&gt;6\times (1^2)&lt;/math&gt; || 1 || &lt;math&gt;\tfrac{5}{2}&lt;/math&gt;
|-
| &lt;math&gt;\left( 5,12,13 \right)&lt;/math&gt; || 1 + 2 + 3 + 4 + 5 || &lt;math&gt;6\times (1^2+2^2)&lt;/math&gt; || 2 || &lt;math&gt;\tfrac{13}{2}&lt;/math&gt;
|-
| &lt;math&gt;\left( 7,24,25 \right)&lt;/math&gt; || 1 + 2 + 3 + 4 + 5 + 6 + 7  || &lt;math&gt;6\times (1^2+2^2+3^2)&lt;/math&gt; || 3 || &lt;math&gt;\tfrac{25}{2}&lt;/math&gt;
|-
| ....... || ....... || ....... || ....... || .......
|-
| &lt;math&gt;\left( a,\tfrac{a^2-1}{2},\tfrac{a^2+1}{2} \right)&lt;/math&gt; || 1 + 2 + ... + ''a'' || &lt;math&gt;6\times \left[ 1^2+2^2+\cdots+\left( \tfrac{a-1}{2} \right)^2 \right]&lt;/math&gt; || &lt;math&gt;\left( \tfrac{a-1}{2} \right)&lt;/math&gt; || &lt;math&gt;\tfrac{c}{2}&lt;/math&gt;
|}

==Height-excess enumeration theorem==

Wade and Wade&lt;ref&gt;Wade, Peter, and Wade, William, "Recursions that produce Pythoagorean triples", ''[[College Mathematics Journal]]'' 31, March 2000, 98-101.&lt;/ref&gt; first introduced the categorization of Pythagorean triples by their height, defined as c - b, linking 3,4,5 to 5,12,13 and 7,24,25 and so on.

McCullough and Wade&lt;ref&gt;McCullough, Darryl, and Wade, Elizabeth, "Recursive enumeration of Pythagorean triples", ''[[College Mathematics Journal]]'' 34, March 2003, 107-111.&lt;/ref&gt; extended this approach, which produces all Pythagorean triples when &lt;math&gt;k&gt; \frac{h \sqrt{2}}{d}:&lt;/math&gt; Write a positive integer ''h'' as pq&lt;sup&gt;2&lt;/sup&gt; with ''p'' square-free and ''q'' positive. Set ''d'' = 2''pq'' if ''p'' is odd, or ''d''= ''pq'' if ''p'' is even. For all pairs (''h,k'') of positive integers, the triples are given by

:&lt;math&gt;(h+dk, dk+\frac{(dk)^2}{2h}, h+dk+\frac{(dk)^2}{2h}).&lt;/math&gt;

The primitive triples occur when gcd(''k, h'') = 1 and either ''h=q''&lt;sup&gt;2&lt;/sup&gt; with ''q'' odd or ''h''=2''q''&lt;sup&gt;2&lt;/sup&gt;.

==References==

{{reflist}}

{{DEFAULTSORT:Formulas For Generating Pythagorean Triples}}
[[Category:Number theory]]</text>
      <sha1>fdukktquo018rchxh2hnyd384mfbbqo</sha1>
    </revision>
  </page>
  <page>
    <title>Forney algorithm</title>
    <ns>0</ns>
    <id>32969421</id>
    <revision>
      <id>803724987</id>
      <parentid>668913433</parentid>
      <timestamp>2017-10-04T06:38:44Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v1.5.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4887">In [[coding theory]], the '''Forney algorithm''' (or '''Forney's algorithm''') calculates the error values at known error locations.  It is used as one of the steps in decoding [[BCH code]]s and [[Reed&amp;ndash;Solomon error correction|Reed&amp;ndash;Solomon codes]] (a subclass of BCH codes).  [[Dave Forney|George David Forney, Jr.]] developed the algorithm.&lt;ref&gt;{{Harvnb|Forney|1965}}&lt;/ref&gt;

==Procedure==
:''Need to introduce terminology and the setup...''

Code words look like polynomials. By design, the generator polynomial has consecutive roots &amp;alpha;&lt;sup&gt;c&lt;/sup&gt;, &amp;alpha;&lt;sup&gt;''c''+1&lt;/sup&gt;, ..., &amp;alpha;&lt;sup&gt;''c''+''d''&amp;minus;2&lt;/sup&gt;.&lt;!-- for RS, c = 1 --&gt;

Syndromes

Error location polynomial&lt;ref&gt;{{Harvnb|Gill|n.d.|p=24}}&lt;/ref&gt;

:&lt;math&gt;\Lambda(x) = \prod_{i=1}^\nu (1- x \, X_i) = 1 + \sum_{i=1}^\nu \lambda_i \, x^i&lt;/math&gt;

The zeros of &amp;Lambda;(''x'') are ''X''&lt;sub&gt;1&lt;/sub&gt;&lt;sup&gt;&amp;minus;1&lt;/sup&gt;, ..., ''X''&lt;sub&gt;''&amp;nu;''&lt;/sub&gt;&lt;sup&gt;&amp;minus;1&lt;/sup&gt;. The zeros are the reciprocals of the error locations &lt;math&gt;X_j = \alpha^{i_j}&lt;/math&gt;.

Once the error locations are known, the next step is to determine the error values at those locations. The error values are then used to correct the received values at those locations to recover the original codeword.

In the more general case, the error weights {{mvar|e&lt;sub&gt;j&lt;/sub&gt;}} can be determined by solving the linear system

:&lt;math&gt;s_0 = e_1 \alpha^{(c + 0)\,i_1} + e_2 \alpha^{(c + 0)\,i_2} + \cdots \, &lt;/math&gt;
:&lt;math&gt;s_1 = e_1 \alpha^{(c + 1)\,i_1} + e_2 \alpha^{(c + 1)\,i_2} + \cdots \, &lt;/math&gt;
:&lt;math&gt; \cdots \, &lt;/math&gt;

However, there is a more efficient method known as the Forney algorithm, which is based on [[Lagrange polynomial|Lagrange interpolation]]. First calculate the error evaluator polynomial&lt;ref name="Gill-Forney"&gt;{{Harvnb|Gill|n.d.|p=47}}&lt;/ref&gt;

:&lt;math&gt;\Omega(x) = S(x)\,\Lambda(x) \pmod{x^{2t}} \, &lt;/math&gt;
&lt;!-- previous used small omega; mod was x^(d-1); Gill uses 2t. --&gt;

Where {{math|''S''(''x'')}} is the partial syndrome polynomial:&lt;ref&gt;{{Harvtxt|Gill|n.d.|p=48}}&lt;/ref&gt;
:&lt;math&gt;S(x) = s_0 x^0 + s_1 x^1 + s_2 x^2 + \cdots + s_{2t-1} x^{2t-1}.&lt;/math&gt;

Then evaluate the error values:&lt;ref name="Gill-Forney"/&gt;
&lt;!-- Gill uses b where c is used above --&gt;

:&lt;math&gt;e_j = - \frac{X_j^{1-c} \, \Omega(X_j^{-1})}{\Lambda'(X_j^{-1})} \, &lt;/math&gt;
&lt;!-- minus often left out because no effect in common fields. Formal derivative in some fields has drastic simplification. --&gt;

The value {{mvar|c}} is often called the "first consecutive root" or "fcr". Some codes select {{math|''c'' {{=}} 1}}, so the expression simplifies to:
:&lt;math&gt;e_j = - \frac{\Omega(X_j^{-1})}{\Lambda'(X_j^{-1})}&lt;/math&gt;

==Formal derivative==
{{Main|Formal derivative}}

&amp;Lambda;'(''x'') is the [[formal derivative]] of the error locator polynomial &amp;Lambda;(''x''):&lt;ref name="Gill-Forney"/&gt;
:&lt;math&gt;\Lambda'(x) = \sum_{i=1}^{\nu} i \, \cdot \, \lambda_i \, x^{i-1}&lt;/math&gt;
&lt;!-- nu is number of errors / order of Lambda(x). Better exposition needed. --&gt;

In the above expression, note that ''i'' is an integer, and &amp;lambda;&lt;sub&gt;''i''&lt;/sub&gt; would be an element of the finite field. The operator &amp;middot; represents ordinary multiplication (repeated addition in the finite field) and not the finite field's multiplication operator.

&lt;!-- discuss simplification. When addition is exclusive or (common case), only odd ''i'' are relevant. --&gt;

==Derivation==
[[Lagrange interpolation]]

{{Harvtxt|Gill|n.d.|pp=52&amp;ndash;54}} gives a derivation of the Forney algorithm.

==Erasures==
Define the erasure locator polynomial
:&lt;math&gt;\Gamma(x) = \prod (1- x \, \alpha^{j_i})&lt;/math&gt;
Where the erasure locations are given by ''j&lt;sub&gt;i&lt;/sub&gt;''. Apply the procedure described above, substituting &amp;Gamma; for &amp;Lambda;.

If both errors and erasures are present, use the error-and-erasure locator polynomial
:&lt;math&gt;\Psi(x) = \Lambda(x) \, \Gamma(x)&lt;/math&gt;

==See also==
*[[BCH code]]
*[[Reed&amp;ndash;Solomon error correction]]

==References==
{{reflist|30em}}
*{{Citation
 |first= G., Jr.
 |last= Forney
 |authorlink=Dave Forney
 |title= On Decoding BCH Codes
 |journal= [[IEEE Transactions on Information Theory]]
 |volume= 11
 |issue= 4
 |date= October 1965
 |pages= 549–557
 |issn= 0018-9448
 |doi= 10.1109/TIT.1965.1053825}}
*{{Citation
 |last        = Gill
 |first       = John
 |title       = EE387 Notes #7, Handout #28
 |date        = n.d.
 |accessdate  = April 21, 2010
 |pages       = 42&amp;ndash;45
 |publisher   = Stanford University
 |url         = http://www.stanford.edu/class/ee387/handouts/notes7.pdf
 |doi         = 
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20140630172526/http://web.stanford.edu/class/ee387/handouts/notes7.pdf
 |archivedate = June 30, 2014
 |df          = 
}}
* [[W. Wesley Peterson]]'s book

==External links==

{{DEFAULTSORT:Forney algorithm}}
[[Category:Error detection and correction]]
[[Category:Coding theory]]</text>
      <sha1>n8niuy1dckigpfc8tn67cb82ufj0gn6</sha1>
    </revision>
  </page>
  <page>
    <title>Fourier transform on finite groups</title>
    <ns>0</ns>
    <id>18536812</id>
    <revision>
      <id>867857024</id>
      <parentid>867838464</parentid>
      <timestamp>2018-11-08T12:35:06Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/Affinesoldier|Affinesoldier]] ([[User talk:Affinesoldier|talk]]): Vague and does not improve the article. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7880">{{see also|Discrete Fourier transform (general)}}
In [[mathematics]], the '''Fourier transform on finite groups''' is a generalization of the [[discrete Fourier transform]] from [[cyclic group|cyclic]] to arbitrary [[finite group]]s.

==Definitions==
The '''Fourier transform''' of a function &lt;math&gt;f : G \rightarrow \mathbb{C}\,&lt;/math&gt;
at a [[representation of a finite group|representation]] &lt;math&gt;\varrho : G \rightarrow GL(d_\varrho, \mathbb{C})\,&lt;/math&gt; of &lt;math&gt;G\,&lt;/math&gt; is

:&lt;math&gt;
\widehat{f}(\varrho) = \sum_{a \in G} f(a) \varrho(a).
&lt;/math&gt;

For each representation &lt;math&gt;\varrho\,&lt;/math&gt; of &lt;math&gt;G\,&lt;/math&gt;, &lt;math&gt;\widehat{f}(\varrho)\,&lt;/math&gt; is a &lt;math&gt;d_\varrho \times d_\varrho\,&lt;/math&gt; matrix, where &lt;math&gt;d_\varrho\,&lt;/math&gt; is the degree of &lt;math&gt;\varrho\,&lt;/math&gt;.

The '''inverse Fourier transform''' at an element &lt;math&gt;a\,&lt;/math&gt; of &lt;math&gt;G\,&lt;/math&gt; is given by

:&lt;math&gt;
f(a) = \frac{1}{|G|} \sum_i d_{\varrho_i} \text{Tr}\left(\varrho_i(a^{-1})\widehat{f}(\varrho_i)\right).
&lt;/math&gt;

==Properties==

===Transform of a convolution===
The '''convolution''' of two functions &lt;math&gt;f, g : G \rightarrow \mathbb{C}\,&lt;/math&gt; is defined as

:&lt;math&gt;
(f \ast g)(a) = \sum_{b \in G} f(ab^{-1}) g(b).
&lt;/math&gt;

The Fourier transform of a convolution at any representation &lt;math&gt;\varrho\,&lt;/math&gt; of &lt;math&gt;G\,&lt;/math&gt; is given by

:&lt;math&gt;
\widehat{f \ast g}(\varrho) = \widehat{f}(\varrho)\widehat{g}(\varrho).
&lt;/math&gt;

===Plancherel formula===
For functions &lt;math&gt;f, g : G \rightarrow \mathbb{C}\,&lt;/math&gt;, the Plancherel formula states

:&lt;math&gt;
\sum_{a \in G} f(a^{-1}) g(a) = \frac{1}{|G|} \sum_i d_{\varrho_i} \text{Tr}\left(\widehat{f}(\varrho_i)\widehat{g}(\varrho_i)\right),
&lt;/math&gt;

where &lt;math&gt;\varrho_i\,&lt;/math&gt; are the irreducible representations of &lt;math&gt;G.\,&lt;/math&gt;

==Fourier transform for finite abelian groups==
If the group ''G'' is a finite [[abelian group]], the situation simplifies considerably:

* all irreducible representations &lt;math&gt;\varrho_i&lt;/math&gt; are of degree 1 and hence equal to the irreducible characters of the group. Thus the matrix-valued Fourier transform becomes scalar-valued in this case.

* The set of irreducible ''G''-representations has a natural group structure in its own right, which can be identified with the group &lt;math&gt;\widehat G := \mathrm{Hom}(G, S^1)&lt;/math&gt; of [[group homomorphisms]] from ''G'' to &lt;math&gt;S^1 = \{z \in \mathbb C, |z|=1\}&lt;/math&gt;. This group is known as the [[Pontryagin dual]] of ''G''.

The Fourier transform of an element &lt;math&gt;f\in G &lt;/math&gt; is the function &lt;math&gt;\widehat{f}: \widehat{G}\to \mathbb{C}&lt;/math&gt; given by

:&lt;math&gt;
\widehat{f}(\chi) = \sum_{a \in G} f(a) \bar{\chi}(a).
&lt;/math&gt;

The inverse Fourier transform is then given by

:&lt;math&gt;
f(a) = \frac{1}{|G|} \sum_{\chi \in \widehat{G}} \widehat{f}(\chi) \chi(a).
&lt;/math&gt;
For &lt;math&gt;G = \mathbb Z/n&lt;/math&gt;, a choice of a primitive ''n''-th [[root of unity]] &lt;math&gt;\zeta&lt;/math&gt; yields an isomorphism

:&lt;math&gt;G \to \widehat G,&lt;/math&gt;

given by &lt;math&gt;m \mapsto (r \mapsto \zeta^{mr})&lt;/math&gt;. In the literature, the common choice is &lt;math&gt;\zeta = e^{2 \pi i /n}&lt;/math&gt;, which explains the formula given in the article about the [[discrete Fourier transform]]. However, such an isomorphism is not canonical, similarly to the situation that a finite-dimensional vector space is isomorphic to its [[dual vector space|dual]], but giving an isomorphism requires choosing a basis.

A property that is often useful in probability is that the Fourier transform of the uniform distribution is simply &lt;math&gt;\delta_{a,0},\,&lt;/math&gt; where 0 is the group identity and &lt;math&gt;\delta_{i,j}\,&lt;/math&gt; is the [[Kronecker delta]].

Fourier Transform can also be done on cosets of a group.

==Relationship with representation theory==
There is a direct relationship between the Fourier transform on finite groups and the [[representation theory of finite groups]]. The set of complex-valued functions on a finite group, &lt;math&gt;G&lt;/math&gt;, together with the operations of pointwise addition and convolution, form a ring that is naturally identified with the [[group ring]] of &lt;math&gt;G&lt;/math&gt; over the complex numbers, &lt;math&gt;\mathbb{C}[G]&lt;/math&gt;. [[Module_(mathematics)|Modules]] of this ring are the same thing as representations. [[Maschke's theorem]] implies that &lt;math&gt;\mathbb{C}[G]&lt;/math&gt; is a [[semisimple ring]], so by the [[Artin–Wedderburn theorem]] it decomposes as a [[product of rings|direct product]] of [[matrix ring]]s. The Fourier transform on finite groups explicitly exhibits this decomposition, with a matrix ring of dimension &lt;math&gt;d_\varrho&lt;/math&gt; for each irreducible representation.
More specifically, the [[Peter-Weyl theorem]] (for finite groups) states that there is an isomorphism

:&lt;math&gt;\mathbb C[G] \cong \bigoplus_{i} \mathrm{GL}(V_i)&lt;/math&gt;
given by

:&lt;math&gt;\sum_{g \in G} a_g g \mapsto (\sum a_g \rho_i(g): V_i \to V_i)&lt;/math&gt;
The left hand side is the [[group algebra]] of ''G''. The direct sum is over a complete set of inequivalent irreducible ''G''-representations &lt;math&gt;\varrho_i : G \to \mathrm{GL}(V_i)&lt;/math&gt;.

The Fourier transform for a finite group is just this isomorphism. The product formula mentioned above is equivalent to saying that this map is a [[ring isomorphism]].
==Applications==

This generalization of the discrete Fourier transform is used in [[numerical analysis]]. A [[circulant matrix]] is a matrix where every column is a [[cyclic shift]] of the previous one. Circulant matrices can be [[Matrix diagonalization|diagonalized]] quickly using the [[fast Fourier transform]], and this  yields a fast method for solving [[system of linear equations|systems of linear equations]] with circulant matrices. Similarly, the Fourier transform on arbitrary groups can be used to give fast algorithms for matrices with other symmetries {{harv|Åhlander|Munthe-Kaas|2005}}. These algorithms can be used for the construction of [[numerical partial differential equations|numerical methods for solving partial differential equations]] that preserve the symmetries of the equations {{harv|Munthe-Kaas|2006}}.

==See also==
*[[Fourier transform]]
*[[Representation theory of finite groups]]
*[[Character theory]]

==References==
{{Reflist}}
{{refbegin}}
* {{Citation | last1=Åhlander | first1=Krister | last2=Munthe-Kaas | first2=Hans Z. | title=Applications of the generalized Fourier transform in numerical linear algebra | doi=10.1007/s10543-005-0030-3 | mr=2191479  | year=2005 | journal=BIT | volume=45 | issue=4 | pages=819–850}}.
*{{citation |first=Persi |last=Diaconis |title=Group representations in probability and statistics |publisher=Institute of Mathematical Statistics |volume=11 |series=Lecture Notes—Monograph Series |year=1988 |url=http://projecteuclid.org/euclid.lnms/1215467407 |zbl=0695.60012}}.
*{{citation |first=Persi |last=Diaconis |chapter=Finite Fourier Methods: Access to Tools |editor-first=Béla |editor-last=Bollobás |editor2-first=Fan R. K. |editor2-last=Chung |title=Probabilistic combinatorics and its applications |chapterurl=https://books.google.com/books?id=SHe1bNqIt38C&amp;pg=PA171 |publisher=American Mathematical Society |isbn=978-0-8218-6749-5 |pages=171–194 |series=Proceedings of Symposia in Applied Mathematics |volume=44}}.
* {{Citation | last1=Munthe-Kaas | first1=Hans Z. | title=On group Fourier analysis and symmetry preserving discretizations of PDEs | doi=10.1088/0305-4470/39/19/S14 | mr=2220776  | year=2006 | journal=[[Journal of Physics A]] | volume=39 | issue=19 | pages=5563–84}}.
*{{citation |first=Audrey |last=Terras |title=Fourier Analysis on Finite Groups and Applications |url=https://books.google.com/books?id=-B2TA669dJMC&amp;pg=PA251 |year=1999 |publisher=Cambridge University Press |isbn=978-0-521-45718-7 |page=251 |zbl=0928.43001}}.
{{refend}}

{{DEFAULTSORT:Fourier Transform On Finite Groups}}
[[Category:Fourier analysis]]
[[Category:Finite groups]]</text>
      <sha1>pm5321y0hpx3l8om4h2w8p4wdrd08xr</sha1>
    </revision>
  </page>
  <page>
    <title>Fourth power</title>
    <ns>0</ns>
    <id>665027</id>
    <revision>
      <id>856104981</id>
      <parentid>827431528</parentid>
      <timestamp>2018-08-22T22:16:31Z</timestamp>
      <contributor>
        <ip>184.23.210.148</ip>
      </contributor>
      <comment>/* Properties */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4279">{{About|mathematics|other uses|Fourth branch of government|and|Fourth Estate}}
In [[arithmetic]] and [[algebra]], the '''fourth [[exponentiation|power]]''' of a number ''n'' is the result of multiplying four instances of ''n'' together. So:

:''n''&lt;sup&gt;4&lt;/sup&gt; = ''n'' &amp;times; ''n'' &amp;times; ''n'' &amp;times; ''n''

Fourth powers are also formed by multiplying a number by its [[cube (arithmetic)|cube]]. Furthermore, they are [[square number|squares]] of squares.

The sequence of fourth powers of [[integer]]s (also known as '''biquadratic numbers''' or '''[[tesseract]]ic numbers''') is:
 
:0, 1, 16, 81, 256, 625, 1296, 2401, 4096, 6561, 10000, 14641, 20736, 28561, 38416, 50625, 65536, 83521, 104976, 130321, 160000, 194481, 234256, 279841, 331776, 390625, 456976, 531441, 614656, 707281, 810000, ... {{OEIS|id=A000583}}

==Properties==

The last two digits of a fourth power of an integer in base 10 can be easily shown (for instance, by computing the squares of possible last two digits of square numbers) to be restricted to only ''twelve'' possibilities:

* if a number ends in 0, its fourth power ends in &lt;math&gt;00&lt;/math&gt; (in fact in &lt;math&gt;0000&lt;/math&gt;)
* if a number ends in 1, 3, 7 or 9 its fourth power ends in &lt;math&gt;01&lt;/math&gt;, &lt;math&gt;21&lt;/math&gt;, &lt;math&gt;41&lt;/math&gt;, &lt;math&gt;61&lt;/math&gt; or &lt;math&gt;81&lt;/math&gt;
* if a number ends in 2, 4, 6, or 8 its fourth power ends in &lt;math&gt;16&lt;/math&gt;, &lt;math&gt;36&lt;/math&gt;, &lt;math&gt;56&lt;/math&gt;, &lt;math&gt;76&lt;/math&gt; or &lt;math&gt;96&lt;/math&gt;
* if a number ends in 5 its fourth power ends in &lt;math&gt;25&lt;/math&gt; (in fact in &lt;math&gt;0625&lt;/math&gt;)

These twelve possibilities can be conveniently expressed as 00, ''e''1, ''o''6 or 25 where ''o'' is an [[odd number|odd]] digit and ''e'' an [[even number|even]] digit.

Every positive integer can be expressed as the sum of at most 19 fourth powers; every sufficiently large integer can be expressed as the sum of at most 16 fourth powers (see [[Waring's problem]]).

[[Fermat]] knew that a fourth power cannot be the sum of two other fourth powers (the ''n''=4 case of [[Fermat's Last Theorem]]; see [[Fermat's right triangle theorem]]). [[Euler]] [[Euler's sum of powers conjecture|conjectured]] that a fourth power cannot be written as the sum of three fourth powers, but 200 years later, in 1986,  this was disproven by [[Noam Elkies|Elkies]] with:

: &lt;math&gt;20615673^4 =  18796760^4 + 15365639^4 + 2682440^4 .&lt;/math&gt;

Elkies showed that there are infinitely many other counterexamples for exponent four, some of which are:&lt;ref name=meyrignac&gt;Quoted in {{cite web
| last = Meyrignac
| first = Jean-Charles
| url = http://euler.free.fr/records.htm
| title = Computing Minimal Equal Sums Of Like Powers: Best Known Solutions
| date = 14 February 2001
| accessdate = 17 July 2017
}}&lt;/ref&gt;

:&lt;math&gt;2813001^4=2767624^4+1390400^4+673865^4&lt;/math&gt; (Allan MacLeod)
:&lt;math&gt; 8707481^4=8332208^4+5507880^4+1705575^4&lt;/math&gt; (D.J. Bernstein)
:&lt;math&gt;12197457^4=11289040^4+8282543^4+5870000^4&lt;/math&gt; (D.J. Bernstein)
:&lt;math&gt;16003017^4=14173720^4+12552200^4+4479031^4&lt;/math&gt; (D.J. Bernstein)
:&lt;math&gt;16430513^4=16281009^4+7028600^4+3642840^4&lt;/math&gt; (D.J. Bernstein)
:&lt;math&gt; 422481^4=414560^4+217519^4+95800^4&lt;/math&gt; (Roger Frye, 1988)
:&lt;math&gt; 638523249^4=630662624^4+275156240^4+219076465^4&lt;/math&gt; (Allan MacLeod,1998)

That the equation ''x''&lt;sup&gt;4&lt;/sup&gt; + ''y''&lt;sup&gt;4&lt;/sup&gt; = ''z''&lt;sup&gt;4&lt;/sup&gt; has no solutions in nonzero integers ([[Proof_of_Fermat's_Last_Theorem_for_specific_exponents#n.C2.A0.3D.C2.A04|a special case]] of [[Fermat's Last Theorem]]), was known by [[Pierre de Fermat|Fermat]]; see [[Fermat's right triangle theorem]].

==Equations containing a fourth power==
[[Fourth-degree equation]]s, which contain a fourth degree (but no higher) [[polynomial]] are, by the [[Abel–Ruffini theorem]], the highest degree equations having a general solution using [[Nth root|radicals]].

== See also ==
*[[Square (algebra)]]
*[[Cube (algebra)]]
*[[Exponentiation]]
*[[Fifth power (algebra)]]
*[[Sixth power]]
*[[Seventh power]]
*[[Perfect power]]

==References==
&lt;references /&gt;
*{{MathWorld|title=Biquadratic Number|urlname=BiquadraticNumber}}

{{Classes of natural numbers}}

[[Category:Integers]]
[[Category:Number theory]]
[[Category:Elementary arithmetic]]
[[Category:Integer sequences]]
[[Category:Unary operations]]

{{algebra-stub}}</text>
      <sha1>9868lghylc0i2xq8lat6pljovmgsrwq</sha1>
    </revision>
  </page>
  <page>
    <title>Fraňková–Helly selection theorem</title>
    <ns>0</ns>
    <id>9775880</id>
    <revision>
      <id>866121522</id>
      <parentid>671954085</parentid>
      <timestamp>2018-10-28T11:31:50Z</timestamp>
      <contributor>
        <username>Sullivan.t.j</username>
        <id>2036293</id>
      </contributor>
      <minor/>
      <comment>/* References */ Added MR number</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3778">In [[mathematics]], the '''Fraňková&amp;ndash;Helly selection theorem''' is a generalisation of [[Helly's selection theorem]] for functions of [[bounded variation]] to the case of [[regulated function]]s. It was proved in 1991 by the [[Czech Republic|Czech]] [[mathematician]] [[Dana Fraňková]].

==Background==

Let ''X'' be a [[separable space|separable]] [[Hilbert space]], and let BV([0, ''T'']; ''X'') denote the [[normed vector space]] of all functions ''f'' : [0, ''T''] &amp;rarr; ''X'' with finite total variation over the [[interval (mathematics)|interval]] [0, ''T''], equipped with the total variation norm. It is well known that BV([0, ''T'']; ''X'') satisfies the [[compact space|compactness theorem]] known as '''Helly's selection theorem''': given any sequence of functions (''f''&lt;sub&gt;''n''&lt;/sub&gt;)&lt;sub&gt;''n''&amp;isin;'''N'''&lt;/sub&gt; in BV([0, ''T'']; ''X'') that is uniformly bounded in the total variation norm, there exists a subsequence

:&lt;math&gt;\left( f_{n(k)} \right) \subseteq (f_{n}) \subset \mathrm{BV}([0, T]; X)&lt;/math&gt;

and a limit function ''f'' &amp;isin; BV([0, ''T'']; ''X'') such that ''f''&lt;sub&gt;''n''(''k'')&lt;/sub&gt;(''t'') [[Weak convergence (Hilbert space)|converges weakly]] in ''X'' to ''f''(''t'') for every ''t'' &amp;isin; [0, ''T'']. That is, for every [[continuous linear functional]] ''&amp;lambda;'' &amp;isin; ''X''*,

:&lt;math&gt;\lambda \left( f_{n(k)}(t) \right) \to \lambda(f(t)) \mbox{ in } \mathbb{R} \mbox{ as } k \to \infty.&lt;/math&gt;

Consider now the [[Banach space]] Reg([0, ''T'']; ''X'') of all regulated functions ''f'' : [0, ''T''] &amp;rarr; ''X'', equipped with the [[supremum norm]]. Helly's theorem does not hold for the space Reg([0, ''T'']; ''X''): a [[counterexample]] is given by the sequence

:&lt;math&gt;f_{n} (t) = \sin (n t).&lt;/math&gt;

One may ask, however, if a weaker selection theorem is true, and the '''Fraňková&amp;ndash;Helly selection theorem''' is such a result.

==Statement of the Fraňková&amp;ndash;Helly selection theorem==

As before, let ''X'' be a separable Hilbert space and let Reg([0, ''T'']; ''X'') denote the space of regulated functions ''f'' : [0, ''T''] &amp;rarr; ''X'', equipped with the supremum norm. Let (''f''&lt;sub&gt;''n''&lt;/sub&gt;)&lt;sub&gt;''n''&amp;isin;'''N'''&lt;/sub&gt; be a sequence in Reg([0, ''T'']; ''X'') satisfying the following condition: for every ''ε'' &amp;gt; 0, there exists some ''L''&lt;sub&gt;ε&lt;/sub&gt; &amp;gt; 0 so that each ''f''&lt;sub&gt;''n''&lt;/sub&gt; may be approximated by a ''u''&lt;sub&gt;''n''&lt;/sub&gt; &amp;isin; BV([0, ''T'']; ''X'') satisfying

:&lt;math&gt;\| f_{n} - u_{n} \|_{\infty} &lt; \varepsilon&lt;/math&gt;

and

:&lt;math&gt;| u_{n}(0) | + \mathrm{Var}(u_{n}) \leq L_{\varepsilon},&lt;/math&gt;

where |-| denotes the [[norm (mathematics)|norm]] in ''X'' and Var(''u'') denotes the variation of ''u'', which is defined to be the [[supremum]]

:&lt;math&gt;\sup_{\Pi} \sum_{j=1}^{m} | u(t_{j}) - u(t_{j-1}) |&lt;/math&gt;

over all [[partition of an interval|partitions]]

:&lt;math&gt;\Pi = \{ 0 = t_{0} &lt; t_{1} &lt; \dots &lt; t_{m} = T , m \in \mathbf{N} \}&lt;/math&gt;

of [0, ''T'']. Then there exists a subsequence

:&lt;math&gt;\left( f_{n(k)} \right) \subseteq (f_{n}) \subset \mathrm{Reg}([0, T]; X)&lt;/math&gt;

and a limit function ''f'' &amp;isin; Reg([0, ''T'']; ''X'') such that ''f''&lt;sub&gt;''n''(''k'')&lt;/sub&gt;(''t'') converges weakly in ''X'' to ''f''(''t'') for every ''t'' &amp;isin; [0, ''T'']. That is, for every continuous linear functional ''&amp;lambda;'' &amp;isin; ''X''*,

:&lt;math&gt;\lambda \left( f_{n(k)}(t) \right) \to \lambda(f(t)) \mbox{ in } \mathbb{R} \mbox{ as } k \to \infty.&lt;/math&gt;

==References==

* {{cite journal | last=Fraňková | first=Dana | title=Regulated functions | journal=Math. Bohem. | volume=116 | year=1991 | issue=1 | pages=20–59  | issn=0862-7959 | mr=1100424 }}

{{DEFAULTSORT:Frankova-Helly selection theorem}}
[[Category:Theorems in analysis]]
[[Category:Compactness theorems]]</text>
      <sha1>austkjhqbqeei0mw4kptv3fvvqmdinn</sha1>
    </revision>
  </page>
  <page>
    <title>Fröhlich Prize</title>
    <ns>0</ns>
    <id>1359153</id>
    <revision>
      <id>858496345</id>
      <parentid>731290486</parentid>
      <timestamp>2018-09-07T16:04:44Z</timestamp>
      <contributor>
        <username>Plucas58</username>
        <id>9766640</id>
      </contributor>
      <comment>Update to 2018</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1455">The '''Fröhlich Prize''' of the [[London Mathematical Society]] is awarded in even numbered years in memory of  [[Albrecht Fröhlich]]. The prize is awarded for original and extremely innovative work in any branch of mathematics. According to the regulations the prize is awarded "to a mathematician who has fewer than 25 years (full time equivalent) of involvement in mathematics at post-doctoral level, allowing for breaks in continuity, or who in the opinion of the Prizes Committee is at an equivalent stage in their career."

==Prize winners==
Source: [http://www.lms.ac.uk/content/list-lms-prize-winners LMS website] 
*2004 [[Ian Grojnowski]]
*2006 [[Michael Weiss (mathematician)|Michael Weiss]]
*2008 [[Nicholas Higham]]
*2010 [[Jonathan Keating]]
*2012 [[Trevor Wooley]]
*2014 [[Martin Hairer]]
*2016 [[Dominic Joyce]]
*2018 [[Francesco Mezzadri]]

==See also==
* [[Whitehead Prize]]
* [[Senior Whitehead Prize]]
* [[Berwick Prize]]
* [[Naylor Prize and Lectureship]]
* [[Pólya Prize (LMS)]]
* [[De Morgan Medal]]

==References==
{{Reflist}}

==External links==
* [http://www.lms.ac.uk/content/list-lms-prize-winners#FR%C3%96HLICH_prize LMS prizes]

{{Awards of the London Mathematical Society}}

{{DEFAULTSORT:Frohlich Prize}}
[[Category:Mathematics awards]]
[[Category:British science and technology awards]]
[[Category:Awards of the London Mathematical Society]]
[[Category:Early career awards]]
[[Category:Biennial events]]


{{award-stub}}</text>
      <sha1>nboeft1zczzpg5pdspbpcnu840xpc3w</sha1>
    </revision>
  </page>
  <page>
    <title>Generalized eigenvector</title>
    <ns>0</ns>
    <id>1137612</id>
    <revision>
      <id>868856580</id>
      <parentid>857799690</parentid>
      <timestamp>2018-11-14T22:03:40Z</timestamp>
      <contributor>
        <username>Texvc2LaTeXBot</username>
        <id>33995001</id>
      </contributor>
      <minor/>
      <comment>Replacing deprecated latex syntax [[mw:Extension:Math/Roadmap]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="36590">{{Distinguish|Generalized eigenvalue problem}}

In [[linear algebra]], a '''generalized eigenvector''' of an ''n'' × ''n'' [[matrix (mathematics)|matrix]] &lt;math&gt;A&lt;/math&gt; is a [[vector (mathematics and physics)|vector]] which satisfies certain criteria which are more relaxed than those for an (ordinary) [[eigenvector]].&lt;ref&gt;{{harvtxt|Bronson|1970|p=189}}&lt;/ref&gt;

Let &lt;math&gt;V&lt;/math&gt; be an ''n''-dimensional [[vector space]]; let &lt;math&gt;\phi&lt;/math&gt; be a [[linear map]] in {{math|''L''(''V'')}}, the set of all linear maps from &lt;math&gt;V&lt;/math&gt; into itself; and let &lt;math&gt;A&lt;/math&gt; be the [[Linear map#Examples|matrix representation]] of &lt;math&gt;\phi&lt;/math&gt; with respect to some ordered [[basis (linear algebra)|basis]].

There may not always exist a full set of ''n'' [[linear independence|linearly independent]] eigenvectors of &lt;math&gt;A&lt;/math&gt; that form a complete basis for &lt;math&gt;V&lt;/math&gt;.  That is, the matrix &lt;math&gt;A&lt;/math&gt; may not be [[diagonalizable matrix|diagonalizable]].&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|p=310}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Nering|1970|p=118}}&lt;/ref&gt;  This happens when the [[algebraic multiplicity]] of at least one [[eigenvalue]] &lt;math&gt;\lambda_i&lt;/math&gt; is greater than its [[geometric multiplicity]] (the [[kernel (linear algebra)#Representation as matrix multiplication|nullity]] of the matrix &lt;math&gt;(A-\lambda_i I)&lt;/math&gt;, or the [[dimension (vector space)|dimension]] of its [[kernel (linear algebra)|nullspace]]).  In this case, &lt;math&gt;\lambda_i&lt;/math&gt; is called a [[defective eigenvalue]] and &lt;math&gt;A&lt;/math&gt; is called a [[defective matrix]].&lt;ref&gt;{{harvtxt|Golub|Van Loan|1996|p=316}}&lt;/ref&gt;

A generalized eigenvector &lt;math&gt;x_i&lt;/math&gt; corresponding to &lt;math&gt;\lambda_i&lt;/math&gt;, together with the matrix &lt;math&gt;(A-\lambda_i I)&lt;/math&gt; generate a Jordan chain of linearly independent generalized eigenvectors which form a basis for an [[invariant subspace]] of &lt;math&gt;V&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|p=319}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Bronson|1970|pp=194–195}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Golub|Van Loan|1996|p=311}}&lt;/ref&gt;

Using generalized eigenvectors, a set of linearly independent eigenvectors of &lt;math&gt;A&lt;/math&gt; can be extended, if necessary, to a complete basis for &lt;math&gt;V&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=196}}&lt;/ref&gt;  This basis can be used to determine an "almost diagonal matrix" &lt;math&gt;J&lt;/math&gt; in [[Jordan normal form]], [[matrix similarity|similar]] to &lt;math&gt;A&lt;/math&gt;, which is useful in computing certain [[matrix function]]s of &lt;math&gt;A&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=189}}&lt;/ref&gt;  The matrix &lt;math&gt;J&lt;/math&gt; is also useful in solving the [[Ordinary differential equation#System of ODEs|system of linear differential equations]] &lt;math&gt;\mathbf x' = A \mathbf x,&lt;/math&gt; where &lt;math&gt;A&lt;/math&gt; need not be diagonalizable.&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|pp=316–318}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Nering|1970|p=118}}&lt;/ref&gt;

== Overview and definition ==
There are several equivalent ways to define an '''ordinary eigenvector'''.&lt;ref&gt;{{harvtxt|Anton|1987|pp=301–302}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|p=266}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Burden|Faires|1993|p=401}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Golub|Van Loan|1996|pp=310–311}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Harper|1976|p=58}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Herstein|1964|p=225}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Kreyszig|1972|pp=273,684}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Nering|1970|p=104}}&lt;/ref&gt;  For our purposes, an eigenvector &lt;math&gt;\mathbf u&lt;/math&gt; associated with an eigenvalue &lt;math&gt;\lambda&lt;/math&gt; of an &lt;math&gt;n&lt;/math&gt; × &lt;math&gt;n&lt;/math&gt; matrix &lt;math&gt;A&lt;/math&gt; is a nonzero vector for which &lt;math&gt;(A - \lambda I) \mathbf u = \mathbf 0&lt;/math&gt;, where &lt;math&gt;I&lt;/math&gt; is the &lt;math&gt;n&lt;/math&gt; × &lt;math&gt;n&lt;/math&gt; [[identity matrix]] and &lt;math&gt;\mathbf 0&lt;/math&gt; is the [[zero vector]] of length &lt;math&gt;n&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Burden|Faires|1993|p=401}}&lt;/ref&gt;  That is, &lt;math&gt;\mathbf u&lt;/math&gt; is in the [[kernel (linear algebra)|kernel]] of the [[linear transformation|transformation]] &lt;math&gt;(A - \lambda I)&lt;/math&gt;.  If &lt;math&gt;A&lt;/math&gt; has &lt;math&gt;n&lt;/math&gt; linearly independent eigenvectors, then &lt;math&gt;A&lt;/math&gt; is similar to a diagonal matrix &lt;math&gt;D&lt;/math&gt;.  That is, there exists an [[invertible matrix]] &lt;math&gt;M&lt;/math&gt; such that &lt;math&gt;A&lt;/math&gt; is diagonalizable through the similarity transformation &lt;math&gt;D = M^{-1}AM&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|pp=270–274}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Bronson|1970|pp=179–183}}&lt;/ref&gt;  The matrix &lt;math&gt;D&lt;/math&gt; is called a [[spectral matrix]] for &lt;math&gt;A&lt;/math&gt;.  The matrix &lt;math&gt;M&lt;/math&gt; is called a [[modal matrix]] for &lt;math&gt;A&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=181}}&lt;/ref&gt;  Diagonalizable matrices are of particular interest since matrix functions of them can be computed easily.&lt;ref&gt;{{harvtxt|Bronson|1970|p=179}}&lt;/ref&gt;

On the other hand, if &lt;math&gt;A&lt;/math&gt; does not have &lt;math&gt;n&lt;/math&gt; linearly independent eigenvectors associated with it, then &lt;math&gt;A&lt;/math&gt; is not diagonalizable.&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|pp=270–274}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Bronson|1970|pp=179–183}}&lt;/ref&gt;

'''Definition:'''  A vector &lt;math&gt;\mathbf x_m&lt;/math&gt; is a '''generalized eigenvector of rank ''m''''' of the matrix &lt;math&gt;A&lt;/math&gt; and corresponding to the eigenvalue &lt;math&gt;\lambda&lt;/math&gt; if

:&lt;math&gt;(A - \lambda I)^m \mathbf x_m = \mathbf 0&lt;/math&gt;

but

:&lt;math&gt;(A - \lambda I)^{m-1} \mathbf x_m \ne \mathbf 0.&lt;/math&gt; &lt;ref&gt;{{harvtxt|Bronson|1970|p=189}}&lt;/ref&gt;

Clearly, a generalized eigenvector of rank 1 is an ordinary eigenvector.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=190,202}}&lt;/ref&gt;  Every &lt;math&gt;n&lt;/math&gt; × &lt;math&gt;n&lt;/math&gt; matrix &lt;math&gt;A&lt;/math&gt; has &lt;math&gt;n&lt;/math&gt; linearly independent generalized eigenvectors associated with it and can be shown to be similar to an "almost diagonal" matrix &lt;math&gt;J&lt;/math&gt; in Jordan normal form.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=189,203}}&lt;/ref&gt;  That is, there exists an invertible matrix &lt;math&gt;M&lt;/math&gt; such that &lt;math&gt;J = M^{-1}AM&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=206–207}}&lt;/ref&gt;  The matrix &lt;math&gt;M&lt;/math&gt; in this case is called a [[generalized modal matrix]] for &lt;math&gt;A&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=205}}&lt;/ref&gt;  If &lt;math&gt;\lambda&lt;/math&gt; is an eigenvalue of algebraic multiplicity &lt;math&gt;\mu&lt;/math&gt;, then &lt;math&gt;A&lt;/math&gt; will have &lt;math&gt;\mu&lt;/math&gt; linearly independent generalized eigenvectors corresponding to &lt;math&gt;\lambda&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=196}}&lt;/ref&gt;  These results, in turn, provide a straightforward method for computing certain matrix functions of &lt;math&gt;A&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=189,209–215}}&lt;/ref&gt;

{{anchor|Note}}Note:  For an &lt;math&gt;n \times n&lt;/math&gt; matrix &lt;math&gt;A&lt;/math&gt; over a [[Field (mathematics)|field]] &lt;math&gt;F&lt;/math&gt; to be expressed in Jordan normal form, all eigenvalues of &lt;math&gt;A&lt;/math&gt; must be in &lt;math&gt;F&lt;/math&gt;.  That is, the [[characteristic polynomial]] &lt;math&gt;f(x)&lt;/math&gt; must factor completely into linear factors.  For example, if &lt;math&gt;A&lt;/math&gt; has [[Real number|real-valued]] elements, then it may be necessary for the eigenvalues and the components of the eigenvectors to have [[Complex number|complex values]].&lt;ref&gt;{{harvtxt|Golub|Van Loan|1996|p=316}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Herstein|1964|p=259}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Nering|1970|p=118}}&lt;/ref&gt;

The set [[Linear span#Definition|spanned]] by all generalized eigenvectors for a given &lt;math&gt; \lambda &lt;/math&gt;, forms the '''generalized eigenspace''' for &lt;math&gt; \lambda &lt;/math&gt;.&lt;ref&gt;{{harvtxt|Nering|1970|p=118}}&lt;/ref&gt;

==Examples==
Here are some examples to illustrate the concept of generalized eigenvectors.  Some of the details will be described later.

===Example 1===
This example is simple but clearly illustrates the point.  This type of matrix is used frequently in textbooks.&lt;ref&gt;{{harvtxt|Nering|1970|p=118}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Herstein|1964|p=261}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|p=310}}&lt;/ref&gt;
Suppose
:&lt;math&gt; A = \begin{pmatrix} 1 &amp; 1\\ 0 &amp; 1 \end{pmatrix}. &lt;/math&gt;
Then there is only one eigenvalue, &lt;math&gt; \lambda = 1&lt;/math&gt;, and its algebraic multiplicity is ''m'' = 2.

Notice that this matrix is in Jordan normal form but is not [[diagonal matrix|diagonal]]. Hence, this matrix is not diagonalizable.  Since there is one [[superdiagonal]] entry, there will be one generalized eigenvector of rank greater than 1 (or one could note that the vector space &lt;math&gt; V &lt;/math&gt; is of dimension 2, so there can be at most one generalized eigenvector of rank greater than 1).  Alternatively, one could compute the dimension of the [[nullspace]] of  &lt;math&gt; A - \lambda I &lt;/math&gt; to be ''p'' = 1, and thus there are ''m'' – ''p'' = 1 generalized eigenvectors of rank greater than 1.

The ordinary eigenvector &lt;math&gt; \mathbf v_1=\begin{pmatrix}1 \\0 \end{pmatrix}&lt;/math&gt; is computed as usual (see the [[Eigenvalues and eigenvectors#Calculation|eigenvector]] page for examples).  Using this eigenvector, we compute the generalized eigenvector  &lt;math&gt; \mathbf v_2 &lt;/math&gt; by solving

:&lt;math&gt; (A-\lambda I) \mathbf v_2 = \mathbf v_1. &lt;/math&gt;
Writing out the values:
:&lt;math&gt; \left(\begin{pmatrix} 1 &amp; 1\\ 0 &amp; 1 \end{pmatrix} - 1 \begin{pmatrix} 1 &amp; 0\\ 0 &amp; 1 \end{pmatrix}\right)\begin{pmatrix}v_{21} \\v_{22} \end{pmatrix} = \begin{pmatrix} 0 &amp; 1\\ 0 &amp; 0 \end{pmatrix} \begin{pmatrix}v_{21} \\v_{22} \end{pmatrix} =
\begin{pmatrix}1 \\0 \end{pmatrix}.&lt;/math&gt;
This simplifies to

:&lt;math&gt; v_{22}= 1. &lt;/math&gt;

The element &lt;math&gt;v_{21}&lt;/math&gt; has no restrictions. The generalized eigenvector of rank 2 is then &lt;math&gt; \mathbf v_2=\begin{pmatrix}a \\1 \end{pmatrix}&lt;/math&gt;, where ''a'' can have any scalar value.  The choice of ''a'' = 0 is usually the simplest.

Note that

:&lt;math&gt; (A-\lambda I) \mathbf v_2 =  \begin{pmatrix} 0 &amp; 1\\ 0 &amp; 0 \end{pmatrix} \begin{pmatrix}a \\1 \end{pmatrix} =
\begin{pmatrix}1 \\0 \end{pmatrix} = \mathbf v_1,&lt;/math&gt;

so that &lt;math&gt; \mathbf v_2 &lt;/math&gt; is a generalized eigenvector,

:&lt;math&gt; (A-\lambda I) \mathbf v_1 =  \begin{pmatrix} 0 &amp; 1\\ 0 &amp; 0 \end{pmatrix} \begin{pmatrix}1 \\0 \end{pmatrix} =
\begin{pmatrix}0 \\0 \end{pmatrix} = \mathbf 0,&lt;/math&gt;

so that &lt;math&gt; \mathbf v_1 &lt;/math&gt; is an ordinary eigenvector, and that &lt;math&gt; \mathbf v_1&lt;/math&gt; and &lt;math&gt; \mathbf v_2&lt;/math&gt; are linearly independent and hence constitute a basis for the vector space &lt;math&gt; V &lt;/math&gt;.

===Example 2===
This example is more complex than [[Generalized eigenvector#Example 1|Example 1]].  Unfortunately, it is a little difficult to construct an interesting example of low order.&lt;ref&gt;{{harvtxt|Nering|1970|pp=122,123}}&lt;/ref&gt;
The matrix

:&lt;math&gt;A = \begin{pmatrix} 
1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
6 &amp; 3 &amp; 2 &amp; 0 &amp; 0 \\
10 &amp; 6 &amp; 3 &amp; 2 &amp; 0 \\
15 &amp; 10 &amp; 6 &amp; 3 &amp; 2
\end{pmatrix}&lt;/math&gt;

has ''eigenvalues'' &lt;math&gt; \lambda_1 = 1 &lt;/math&gt; and &lt;math&gt; \lambda_2 = 2 &lt;/math&gt; with ''algebraic multiplicities'' &lt;math&gt; \mu_1 = 2 &lt;/math&gt; and &lt;math&gt; \mu_2 = 3 &lt;/math&gt;, but ''geometric multiplicities'' &lt;math&gt; \gamma_1 = 1 &lt;/math&gt; and &lt;math&gt; \gamma_2 = 1&lt;/math&gt;.

The ''generalized eigenspaces'' of &lt;math&gt;A&lt;/math&gt; are calculated below.
&lt;math&gt; \mathbf x_1 &lt;/math&gt; is the ordinary eigenvector associated with &lt;math&gt; \lambda_1 &lt;/math&gt;.
&lt;math&gt; \mathbf x_2 &lt;/math&gt; is a generalized eigenvector associated with &lt;math&gt; \lambda_1 &lt;/math&gt;.
&lt;math&gt; \mathbf y_1 &lt;/math&gt; is the ordinary eigenvector associated with &lt;math&gt; \lambda_2 &lt;/math&gt;.
&lt;math&gt; \mathbf y_2 &lt;/math&gt; and &lt;math&gt; \mathbf y_3 &lt;/math&gt; are generalized eigenvectors associated with &lt;math&gt; \lambda_2 &lt;/math&gt;.

:&lt;math&gt;(A-1 I) \mathbf x_1
 = \begin{pmatrix} 
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
6 &amp; 3 &amp; 1 &amp; 0 &amp; 0 \\
10 &amp; 6 &amp; 3 &amp; 1 &amp; 0 \\
15 &amp; 10 &amp; 6 &amp; 3 &amp; 1
\end{pmatrix}\begin{pmatrix}
0 \\ 3 \\ -9 \\ 9 \\ -3
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ 0 \\ 0 \\ 0
\end{pmatrix} = \mathbf 0 ,&lt;/math&gt;

:&lt;math&gt;(A - 1 I) \mathbf x_2
 = \begin{pmatrix} 
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
6 &amp; 3 &amp; 1 &amp; 0 &amp; 0 \\
10 &amp; 6 &amp; 3 &amp; 1 &amp; 0 \\
15 &amp; 10 &amp; 6 &amp; 3 &amp; 1
\end{pmatrix} \begin{pmatrix}
1 \\ -15 \\ 30 \\ -1 \\ -45
\end{pmatrix} = \begin{pmatrix}
0 \\ 3 \\ -9 \\ 9 \\ -3
\end{pmatrix} = \mathbf x_1 ,&lt;/math&gt;

:&lt;math&gt;(A - 2 I) \mathbf y_1
 = \begin{pmatrix} 
-1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\
6 &amp; 3 &amp; 0 &amp; 0 &amp; 0 \\
10 &amp; 6 &amp; 3 &amp; 0 &amp; 0 \\
15 &amp; 10 &amp; 6 &amp; 3 &amp; 0
\end{pmatrix} \begin{pmatrix}
0 \\ 0 \\ 0 \\ 0 \\ 9
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ 0 \\ 0 \\ 0
\end{pmatrix} = \mathbf 0 ,&lt;/math&gt;

:&lt;math&gt;(A - 2 I) \mathbf y_2 = \begin{pmatrix} 
-1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\
6 &amp; 3 &amp; 0 &amp; 0 &amp; 0 \\
10 &amp; 6 &amp; 3 &amp; 0 &amp; 0 \\
15 &amp; 10 &amp; 6 &amp; 3 &amp; 0
\end{pmatrix} \begin{pmatrix}
0 \\ 0 \\ 0 \\ 3 \\ 0
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ 0 \\ 0 \\ 9
\end{pmatrix} = \mathbf y_1 ,&lt;/math&gt;

:&lt;math&gt;(A - 2 I) \mathbf y_3 = \begin{pmatrix} 
-1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
3 &amp; -1 &amp; 0 &amp; 0 &amp; 0 \\
6 &amp; 3 &amp; 0 &amp; 0 &amp; 0 \\
10 &amp; 6 &amp; 3 &amp; 0 &amp; 0 \\
15 &amp; 10 &amp; 6 &amp; 3 &amp; 0
\end{pmatrix} \begin{pmatrix}
0 \\ 0 \\ 1 \\ -2 \\ 0
\end{pmatrix} = \begin{pmatrix}
0 \\ 0 \\ 0 \\ 3 \\ 0
\end{pmatrix} = \mathbf y_2 .&lt;/math&gt;

This results in a basis for each of the ''generalized eigenspaces'' of &lt;math&gt;A&lt;/math&gt;.
Together the two ''chains'' of generalized eigenvectors span the space of all 5-dimensional column vectors.

:&lt;math&gt;
\left\{ \mathbf x_1, \mathbf x_2 \right\} =
\left\{
\begin{pmatrix} 0 \\ 3 \\ -9 \\ 9 \\ -3 \end{pmatrix}
\begin{pmatrix} 1 \\ -15 \\ 30 \\ -1 \\ -45 \end{pmatrix} 
\right\},
\left\{ \mathbf y_1, \mathbf y_2, \mathbf y_3 \right\} =
\left\{ 
\begin{pmatrix} 0 \\ 0 \\ 0 \\ 0 \\ 9 \end{pmatrix}
\begin{pmatrix} 0 \\ 0 \\ 0 \\ 3 \\ 0 \end{pmatrix}
\begin{pmatrix} 0 \\ 0 \\ 1 \\ -2 \\ 0 \end{pmatrix}
\right\}.
&lt;/math&gt;

An "almost diagonal" matrix &lt;math&gt;J&lt;/math&gt; in ''Jordan normal form'', similar to &lt;math&gt;A&lt;/math&gt; is obtained as follows:

:&lt;math&gt;
M =
\begin{pmatrix} \mathbf x_1 &amp; \mathbf x_2 &amp; \mathbf y_1 &amp; \mathbf y_2 &amp; \mathbf y_3 \end{pmatrix} =
\begin{pmatrix}
0 &amp;  1 &amp; 0 &amp;0&amp; 0 \\
3 &amp;  -15 &amp; 0 &amp;0&amp; 0 \\
-9 &amp;  30 &amp; 0 &amp;0&amp; 1 \\
9 &amp;  -1 &amp; 0 &amp;3&amp; -2 \\
-3 &amp;  -45 &amp; 9 &amp;0&amp; 0
\end{pmatrix},&lt;/math&gt;
:&lt;math&gt;J = \begin{pmatrix}
1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 2 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 2 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 2
\end{pmatrix},
&lt;/math&gt;

where &lt;math&gt;M&lt;/math&gt; is a [[generalized modal matrix]] for &lt;math&gt;A&lt;/math&gt;, the columns of &lt;math&gt;M&lt;/math&gt; are a [[Canonical basis#Linear algebra|canonical basis]] for &lt;math&gt;A&lt;/math&gt;, and &lt;math&gt;AM = MJ&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=189–209}}&lt;/ref&gt;

== Jordan chains ==
'''Definition:'''  Let &lt;math&gt;\mathbf x_m&lt;/math&gt; be a generalized eigenvector of rank ''m'' corresponding to the matrix &lt;math&gt;A&lt;/math&gt; and the eigenvalue &lt;math&gt;\lambda&lt;/math&gt;.  The '''chain generated by''' &lt;math&gt;\mathbf x_m&lt;/math&gt; is a set of vectors &lt;math&gt;\left\{ \mathbf x_m, \mathbf x_{m-1}, \dots , \mathbf x_1 \right\}&lt;/math&gt; given by

:{{NumBlk|:|
&lt;math&gt; \mathbf x_{m-1} = (A - \lambda I) \mathbf x_m, &lt;/math&gt;&lt;br&gt;
&lt;math&gt; \mathbf x_{m-2} = (A - \lambda I)^2 \mathbf x_m = (A - \lambda I) \mathbf x_{m-1}, &lt;/math&gt;&lt;br&gt;
&lt;math&gt; \mathbf x_{m-3} = (A - \lambda I)^3 \mathbf x_m = (A - \lambda I) \mathbf x_{m-2}, &lt;/math&gt;&lt;br&gt;
::&lt;math&gt; \vdots &lt;/math&gt;
&lt;math&gt; \mathbf x_1 = (A - \lambda I)^{m-1} \mathbf x_m = (A - \lambda I) \mathbf x_2. &lt;/math&gt;
|{{EquationRef|1}}}}

Thus, in general,

:{{NumBlk|:|&lt;math&gt; \mathbf x_j = (A - \lambda I)^{m-j} \mathbf x_m = (A - \lambda I) \mathbf x_{j+1} \qquad (j = 1, 2, \dots , m - 1). &lt;/math&gt;|{{EquationRef|2}}}}

The vector &lt;math&gt;\mathbf x_j &lt;/math&gt;, given by ({{EquationNote|2}}), is a generalized eigenvector of rank ''j'' corresponding to the eigenvalue &lt;math&gt;\lambda&lt;/math&gt;.  A chain is a linearly independent set of vectors.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=194–195}}&lt;/ref&gt;

== Canonical basis ==
{{Main|Canonical basis#Linear algebra}}
'''Definition:'''  A set of ''n'' linearly independent generalized eigenvectors is a '''canonical basis''' if it is composed entirely of Jordan chains.

Thus, once we have determined that a generalized eigenvector of rank ''m'' is in a canonical basis, it follows that the ''m'' − 1 vectors &lt;math&gt; \mathbf x_{m-1}, \mathbf x_{m-2}, \ldots , \mathbf x_1 &lt;/math&gt; that are in the Jordan chain generated by &lt;math&gt; \mathbf x_m &lt;/math&gt; are also in the canonical basis.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=196,197}}&lt;/ref&gt;

Let &lt;math&gt; \lambda_i &lt;/math&gt; be an eigenvalue of &lt;math&gt;A&lt;/math&gt; of algebraic multiplicity &lt;math&gt; \mu_i &lt;/math&gt;.  First, find the [[rank (linear algebra)|ranks]] (matrix ranks) of the matrices &lt;math&gt; (A - \lambda_i I), (A - \lambda_i I)^2, \ldots , (A - \lambda_i I)^{m_i} &lt;/math&gt;.  The integer &lt;math&gt;m_i&lt;/math&gt; is determined to be the ''first integer'' for which &lt;math&gt; (A - \lambda_i I)^{m_i} &lt;/math&gt; has rank &lt;math&gt;n - \mu_i &lt;/math&gt; (''n'' being the number of rows or columns of &lt;math&gt;A&lt;/math&gt;, that is, &lt;math&gt;A&lt;/math&gt; is ''n'' × ''n'').

Now define

:&lt;math&gt; \rho_k = rank(A - \lambda_i I)^{k-1} - rank(A - \lambda_i I)^k \qquad (k = 1, 2, \ldots , m_i).&lt;/math&gt;

The variable &lt;math&gt; \rho_k &lt;/math&gt; designates the number of linearly independent generalized eigenvectors of rank ''k'' corresponding to the eigenvalue &lt;math&gt; \lambda_i &lt;/math&gt; that will appear in a canonical basis for &lt;math&gt;A&lt;/math&gt;.  Note that

:&lt;math&gt; rank(A - \lambda_i I)^0 = rank(I) = n &lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=197,198}}&lt;/ref&gt;

== Computation of generalized eigenvectors ==
In the preceding sections we have seen techniques for obtaining the ''n'' linearly independent generalized eigenvectors of a canonical basis for the vector space &lt;math&gt;V&lt;/math&gt; associated with an ''n'' × ''n'' matrix &lt;math&gt;A&lt;/math&gt;.  These techniques can be combined into a procedure:

:Solve the [[characteristic polynomial|characteristic equation]] of &lt;math&gt;A&lt;/math&gt; for eigenvalues &lt;math&gt; \lambda_i &lt;/math&gt; and their algebraic multiplicities &lt;math&gt; \mu_i &lt;/math&gt;;
:For each &lt;math&gt; \lambda_i :&lt;/math&gt;
::Determine &lt;math&gt;n - \mu_i&lt;/math&gt;;
::Determine &lt;math&gt;m_i&lt;/math&gt;;
::Determine &lt;math&gt;\rho_k&lt;/math&gt; for &lt;math&gt;(k = 1, \ldots , m_i)&lt;/math&gt;;
::Determine each Jordan chain for &lt;math&gt;\lambda_i&lt;/math&gt;;

=== Example 3 ===
The matrix

:&lt;math&gt;
A = 
\begin{pmatrix}
 5 &amp;  1 &amp; -2 &amp;  4 \\
 0 &amp;  5 &amp;  2 &amp;  2 \\
 0 &amp;  0 &amp;  5 &amp;  3 \\
 0 &amp;  0 &amp;  0 &amp;  4
\end{pmatrix}
&lt;/math&gt;

has an eigenvalue &lt;math&gt;\lambda_1 = 5&lt;/math&gt; of algebraic multiplicity &lt;math&gt;\mu_1 = 3&lt;/math&gt; and an eigenvalue &lt;math&gt;\lambda_2 = 4&lt;/math&gt; of algebraic multiplicity &lt;math&gt;\mu_2 = 1&lt;/math&gt;.  We also have ''n'' = 4.  For &lt;math&gt;\lambda_1&lt;/math&gt; we have &lt;math&gt;n - \mu_1 = 4 - 3 = 1&lt;/math&gt;.

:&lt;math&gt;
(A - 5I) =
\begin{pmatrix}
 0 &amp;  1 &amp; -2 &amp;  4 \\
 0 &amp;  0 &amp;  2 &amp;  2 \\
 0 &amp;  0 &amp;  0 &amp;  3 \\
 0 &amp;  0 &amp;  0 &amp; -1
\end{pmatrix},
\qquad rank(A - 5I) = 3.
&lt;/math&gt;
:&lt;math&gt;
(A - 5I)^2 =
\begin{pmatrix}
 0 &amp;  0 &amp;  2 &amp; -8 \\
 0 &amp;  0 &amp;  0 &amp;  4 \\
 0 &amp;  0 &amp;  0 &amp; -3 \\
 0 &amp;  0 &amp;  0 &amp;  1
\end{pmatrix},
\qquad rank(A - 5I)^2 = 2.
&lt;/math&gt;
:&lt;math&gt;
(A - 5I)^3 =
\begin{pmatrix}
0 &amp;  0 &amp;  0 &amp; 14 \\
 0 &amp;  0 &amp;  0 &amp; -4 \\
 0 &amp;  0 &amp;  0 &amp;  3 \\
 0 &amp;  0 &amp;  0 &amp; -1
\end{pmatrix},
\qquad rank(A - 5I)^3 = 1.
&lt;/math&gt;

The first integer &lt;math&gt;m_1&lt;/math&gt; for which &lt;math&gt;(A - 5I)^{m_1}&lt;/math&gt; has rank &lt;math&gt;n - \mu_1 = 1&lt;/math&gt; is &lt;math&gt;m_1 = 3&lt;/math&gt;.

We now define

:&lt;math&gt; \rho_3 = rank(A - 5I)^2 - rank(A - 5I)^3 = 2 - 1 = 1 ,&lt;/math&gt;
:&lt;math&gt; \rho_2 = rank(A - 5I)^1 - rank(A - 5I)^2 = 3 - 2 = 1 ,&lt;/math&gt;
:&lt;math&gt; \rho_1 = rank(A - 5I)^0 - rank(A - 5I)^1 = 4 - 3 = 1 .&lt;/math&gt;

Consequently, there will be three linearly independent generalized eigenvectors; one each of ranks 3, 2 and 1.  Since &lt;math&gt;\lambda_1&lt;/math&gt; corresponds to a single chain of three linearly independent generalized eigenvectors, we know that there is a generalized eigenvector &lt;math&gt; \mathbf x_3 &lt;/math&gt; of rank 3 corresponding to &lt;math&gt;\lambda_1&lt;/math&gt; such that

::{{NumBlk|:|&lt;math&gt;(A - 5I)^3 \mathbf x_3 = \mathbf 0&lt;/math&gt;|{{EquationRef|3}}}}

but

::{{NumBlk|:|&lt;math&gt;(A - 5I)^2 \mathbf x_3\neq \mathbf 0 .&lt;/math&gt;|{{EquationRef|4}}}}

Equations ({{EquationNote|3}}) and ({{EquationNote|4}}) represent [[system of linear equations|linear systems]] that can be solved for &lt;math&gt; \mathbf x_3 &lt;/math&gt;.  Let

:&lt;math&gt;
\mathbf x_3 = 
\begin{pmatrix}
x_{31} \\
x_{32} \\
x_{33} \\
x_{34}
\end{pmatrix}.
&lt;/math&gt;

Then

:&lt;math&gt;
(A - 5I)^3 \mathbf x_3 = 
\begin{pmatrix}
 0 &amp;  0 &amp;  0 &amp; 14 \\
 0 &amp;  0 &amp;  0 &amp; -4 \\
 0 &amp;  0 &amp;  0 &amp;  3 \\
 0 &amp;  0 &amp;  0 &amp; -1
\end{pmatrix}
\begin{pmatrix}
x_{31} \\
x_{32} \\
x_{33} \\
x_{34}
\end{pmatrix} = 
\begin{pmatrix}
14 x_{34} \\
-4 x_{34} \\
 3 x_{34} \\
-  x_{34}
\end{pmatrix} = 
\begin{pmatrix}
 0 \\
 0 \\
 0 \\
 0
\end{pmatrix}
&lt;/math&gt;

and

:&lt;math&gt;
(A - 5I)^2 \mathbf x_3 = 
\begin{pmatrix}
 0 &amp;  0 &amp;  2 &amp; -8 \\
 0 &amp;  0 &amp;  0 &amp;  4 \\
 0 &amp;  0 &amp;  0 &amp; -3 \\
 0 &amp;  0 &amp;  0 &amp;  1
\end{pmatrix}
\begin{pmatrix}
x_{31} \\
x_{32} \\
x_{33} \\
x_{34}
\end{pmatrix} = 
\begin{pmatrix}
 2 x_{33} - 8 x_{34} \\
 4 x_{34} \\
-3 x_{34} \\
    x_{34}
\end{pmatrix} \ne 
\begin{pmatrix}
 0 \\
 0 \\
 0 \\
 0
\end{pmatrix}.
&lt;/math&gt;

Thus, in order to satisfy the conditions ({{EquationNote|3}}) and ({{EquationNote|4}}), we must have &lt;math&gt;x_{34} = 0&lt;/math&gt; and &lt;math&gt;x_{33} \ne 0&lt;/math&gt;.  No restrictions are placed on &lt;math&gt;x_{31}&lt;/math&gt; and &lt;math&gt;x_{32}&lt;/math&gt;.  By choosing &lt;math&gt;x_{31} = x_{32} = x_{34} = 0, x_{33} = 1&lt;/math&gt;, we obtain

:&lt;math&gt;
\mathbf x_3 = 
\begin{pmatrix}
0 \\
 0 \\
 1 \\
 0
\end{pmatrix}
&lt;/math&gt;

as a generalized eigenvector of rank 3 corresponding to &lt;math&gt; \lambda_1 = 5 &lt;/math&gt;.  Note that it is possible to obtain infinitely many other generalized eigenvectors of rank 3 by choosing different values of  &lt;math&gt;x_{31}&lt;/math&gt;, &lt;math&gt;x_{32}&lt;/math&gt; and &lt;math&gt;x_{33}&lt;/math&gt;, with &lt;math&gt;x_{33} \ne 0&lt;/math&gt;.  Our first choice, however, is the simplest.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=190–191}}&lt;/ref&gt;

Now using equations ({{EquationNote|1}}), we obtain &lt;math&gt; \mathbf x_2 &lt;/math&gt; and &lt;math&gt; \mathbf x_1 &lt;/math&gt; as generalized eigenvectors of rank 2 and 1 respectively, where

:&lt;math&gt;
\mathbf x_2 = (A - 5I) \mathbf x_3 = 
\begin{pmatrix}
-2 \\
 2 \\
 0 \\
 0
\end{pmatrix},
&lt;/math&gt;

and

:&lt;math&gt;
\mathbf x_1 = (A - 5I) \mathbf x_2 = 
\begin{pmatrix}
 2 \\
 0 \\
 0 \\
 0
\end{pmatrix}.
&lt;/math&gt;

The [[simple eigenvalue]] &lt;math&gt;\lambda_2 = 4&lt;/math&gt; can be dealt with using [[Eigenvalues and eigenvectors#Calculation|standard techniques]] and has an ordinary eigenvector

:&lt;math&gt;
\mathbf y_1 = 
\begin{pmatrix}
-14 \\
  4 \\
 -3 \\
  1
\end{pmatrix}.
&lt;/math&gt;

A canonical basis for &lt;math&gt;A&lt;/math&gt; is

:&lt;math&gt;
\left\{ \mathbf x_3, \mathbf x_2, \mathbf x_1, \mathbf y_1 \right\} =
\left\{
\begin{pmatrix} 0 \\ 0 \\ 1 \\ 0 \end{pmatrix}
\begin{pmatrix} -2 \\ 2 \\ 0 \\ 0 \end{pmatrix}
\begin{pmatrix} 2 \\ 0 \\ 0 \\ 0 \end{pmatrix}
\begin{pmatrix} -14 \\ 4 \\ -3 \\ 1 \end{pmatrix}
\right\}.
&lt;/math&gt;

&lt;math&gt; \mathbf x_1, \mathbf x_2 &lt;/math&gt; and &lt;math&gt; \mathbf x_3 &lt;/math&gt; are generalized eigenvectors associated with &lt;math&gt; \lambda_1 &lt;/math&gt;.  
&lt;math&gt; \mathbf y_1 &lt;/math&gt; is the ordinary eigenvector associated with &lt;math&gt; \lambda_2 &lt;/math&gt;.

It should be noted that this is a fairly simple example.  In general, the numbers &lt;math&gt;\rho_k&lt;/math&gt; of linearly independent generalized eigenvectors of rank ''k'' will not always be equal.  That is, there may be several chains of different lengths corresponding to a particular eigenvalue.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=197–198}}&lt;/ref&gt;

== Generalized modal matrix ==
{{Main|Generalized modal matrix}}
Let &lt;math&gt;A&lt;/math&gt; be an ''n'' × ''n'' matrix.  A '''generalized modal matrix''' &lt;math&gt;M&lt;/math&gt; for &lt;math&gt;A&lt;/math&gt; is an ''n'' × ''n'' matrix whose columns, considered as vectors, form a canonical basis for &lt;math&gt;A&lt;/math&gt; and appear in &lt;math&gt;M&lt;/math&gt; according to the following rules:

* All Jordan chains consisting of one vector (that is, one vector in length) appear in the first columns of &lt;math&gt;M&lt;/math&gt;.
* All vectors of one chain appear together in adjacent columns of &lt;math&gt;M&lt;/math&gt;.
* Each chain appears in &lt;math&gt;M&lt;/math&gt; in order of increasing rank (that is, the generalized eigenvector of rank 1 appears before the generalized eigenvector of rank 2 of the same chain, which appears before the generalized eigenvector of rank 3 of the same chain, etc.).&lt;ref&gt;{{harvtxt|Bronson|1970|p=205}}&lt;/ref&gt;

== Jordan normal form ==
[[File:Jordan blocks.svg|right|thumb|250px|An example of a matrix in Jordan normal form. The grey blocks are called Jordan blocks.]]
{{Main|Jordan normal form}}
Let &lt;math&gt;V&lt;/math&gt; be an ''n''-dimensional vector space; let &lt;math&gt;\phi&lt;/math&gt; be a linear map in {{math|''L''(''V'')}}, the set of all linear maps from &lt;math&gt;V&lt;/math&gt; into itself; and let &lt;math&gt;A&lt;/math&gt; be the matrix representation of &lt;math&gt;\phi&lt;/math&gt; with respect to some ordered basis.  It can be shown that if the [[characteristic polynomial]] &lt;math&gt;f(\lambda)&lt;/math&gt; of &lt;math&gt;A&lt;/math&gt; factors into linear factors, so that &lt;math&gt;f(\lambda)&lt;/math&gt; has the form

:&lt;math&gt; f(\lambda) = \pm (\lambda - \lambda_1)^{\mu_1}(\lambda - \lambda_2)^{\mu_2} \cdots (\lambda - \lambda_r)^{\mu_r} ,&lt;/math&gt;

where &lt;math&gt; \lambda_1, \lambda_2, \ldots , \lambda_r &lt;/math&gt; are the distinct eigenvalues of &lt;math&gt;A&lt;/math&gt;, then each &lt;math&gt;\mu_i&lt;/math&gt; is the algebraic multiplicity of its corresponding eigenvalue &lt;math&gt;\lambda_i&lt;/math&gt; and &lt;math&gt;A&lt;/math&gt; is similar to a matrix &lt;math&gt;J&lt;/math&gt; in '''Jordan normal form''', where each &lt;math&gt;\lambda_i&lt;/math&gt; appears &lt;math&gt;\mu_i&lt;/math&gt; consecutive times on the diagonal, and the entry directly above each &lt;math&gt;\lambda_i&lt;/math&gt; (that is, on the [[superdiagonal]]) is either 0 or 1: the entry above the first occurrence of each &lt;math&gt;\lambda_i&lt;/math&gt; is always 0; all other entries on the superdiagonal are 1.  All other entries (that is, off the diagonal and superdiagonal) are 0.  The matrix &lt;math&gt;J&lt;/math&gt; is as close as one can come to a diagonalization of &lt;math&gt;A&lt;/math&gt;.  If &lt;math&gt;A&lt;/math&gt; is diagonalizable, then all entries above the diagonal are zero.&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|p=311}}&lt;/ref&gt;  Note that some textbooks have the ones on the [[subdiagonal]], that is, immediately below the main diagonal instead of on the superdiagonal.  The eigenvalues are still on the main diagonal.&lt;ref&gt;{{harvtxt|Cullen|1966|p=114}}&lt;/ref&gt;&lt;ref&gt;{{harvtxt|Franklin|1968|p=122}}&lt;/ref&gt;

Every ''n'' × ''n'' matrix &lt;math&gt;A&lt;/math&gt; is similar to a matrix &lt;math&gt;J&lt;/math&gt; in Jordan normal form, obtained through the similarity transformation &lt;math&gt; J = M^{-1}AM &lt;/math&gt;, where &lt;math&gt;M&lt;/math&gt; is a generalized modal matrix for &lt;math&gt;A&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=207}}&lt;/ref&gt; (See [[#Note|Note]] above.)

=== Example 4 ===
Find a matrix in Jordan normal form that is similar to

:&lt;math&gt;
A = 
\begin{pmatrix}
 0 &amp;  4 &amp;  2 \\
-3 &amp;  8 &amp;  3 \\
 4 &amp; -8 &amp; -2
\end{pmatrix}.
&lt;/math&gt;

'''Solution:'''  The characteristic equation of &lt;math&gt;A&lt;/math&gt; is &lt;math&gt;(\lambda - 2)^3 = 0&lt;/math&gt;, hence, &lt;math&gt;\lambda = 2&lt;/math&gt; is an eigenvalue of algebraic multiplicity three.  Following the procedures of the previous sections, we find that

:&lt;math&gt; rank(A - 2I) = 1&lt;/math&gt;

and

:&lt;math&gt;rank(A - 2I)^2 = 0 = n - \mu .&lt;/math&gt;

Thus, &lt;math&gt;\rho_2 = 1&lt;/math&gt; and &lt;math&gt;\rho_1 = 2&lt;/math&gt;, which implies that a canonical basis for &lt;math&gt;A&lt;/math&gt; will contain one linearly independent generalized eigenvector of rank 2 and two linearly independent generalized eigenvectors of rank 1, or equivalently, one chain of two vectors &lt;math&gt; \left\{ \mathbf x_2, \mathbf x_1 \right\} &lt;/math&gt; and one chain of one vector &lt;math&gt; \left\{ \mathbf y_1 \right\} &lt;/math&gt;.  Designating &lt;math&gt; M = \begin{pmatrix} \mathbf y_1 &amp; \mathbf x_1 &amp; \mathbf x_2 \end{pmatrix} &lt;/math&gt;, we find that

:&lt;math&gt;
M = 
\begin{pmatrix}
 2 &amp;  2 &amp;  0 \\
 1 &amp;  3 &amp;  0 \\
 0 &amp; -4 &amp;  1
\end{pmatrix},
&lt;/math&gt;

and

:&lt;math&gt;
J = 
\begin{pmatrix}
 2 &amp;  0 &amp;  0 \\
 0 &amp;  2 &amp;  1 \\
 0 &amp;  0 &amp;  2
\end{pmatrix},
&lt;/math&gt;

where &lt;math&gt;M&lt;/math&gt; is a generalized modal matrix for &lt;math&gt;A&lt;/math&gt;, the columns of &lt;math&gt;M&lt;/math&gt; are a canonical basis for &lt;math&gt;A&lt;/math&gt;, and &lt;math&gt;AM = MJ&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=208}}&lt;/ref&gt;  Note that since generalized eigenvectors themselves are not unique, and since some of the columns of both &lt;math&gt;M&lt;/math&gt; and &lt;math&gt;J&lt;/math&gt; may be interchanged, it follows that both &lt;math&gt;M&lt;/math&gt; and &lt;math&gt;J&lt;/math&gt; are not unique.&lt;ref&gt;{{harvtxt|Bronson|1970|p=206}}&lt;/ref&gt;

=== Example 5 ===
In [[Generalized eigenvector#Example 3|Example 3]], we found a canonical basis of linearly independent generalized eigenvectors for a matrix &lt;math&gt;A&lt;/math&gt;.  A generalized modal matrix for &lt;math&gt;A&lt;/math&gt; is

:&lt;math&gt;
M =
\begin{pmatrix} \mathbf y_1 &amp; \mathbf x_1 &amp; \mathbf x_2 &amp; \mathbf x_3 \end{pmatrix} =
\begin{pmatrix}
-14 &amp;   2 &amp;  -2 &amp;   0 \\
   4 &amp;   0 &amp;   2 &amp;   0 \\
  -3 &amp;   0 &amp;   0 &amp;   1 \\
   1 &amp;   0 &amp;   0 &amp;   0
\end{pmatrix}.&lt;/math&gt;

A matrix in Jordan normal form, similar to &lt;math&gt;A&lt;/math&gt; is

:&lt;math&gt;J = \begin{pmatrix}
 4 &amp;  0 &amp;  0 &amp;  0 \\
 0 &amp;  5 &amp;  1 &amp;  0 \\
 0 &amp;  0 &amp;  5 &amp;  1 \\
 0 &amp;  0 &amp;  0 &amp;  5
\end{pmatrix},
&lt;/math&gt;

so that &lt;math&gt;AM = MJ&lt;/math&gt;.

== Applications ==

=== Matrix functions ===
{{Main|Matrix function}}
Three of the most fundamental operations which can be performed on [[square matrix|square matrices]] are matrix addition, multiplication by a scalar, and matrix multiplication.&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|pp=57–61}}&lt;/ref&gt;  These are exactly those operations necessary for defining a [[polynomial]] function of an ''n'' × ''n'' matrix &lt;math&gt;A&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=104}}&lt;/ref&gt;  If we recall from basic [[calculus]] that many functions can be written as a [[Maclaurin series]], then we can define more general functions of matrices quite easily.&lt;ref&gt;{{harvtxt|Bronson|1970|p=105}}&lt;/ref&gt;  If &lt;math&gt;A&lt;/math&gt; is diagonalizable, that is

:&lt;math&gt; D = M^{-1}AM ,&lt;/math&gt;

with

:&lt;math&gt;
D = 
\begin{pmatrix}
 \lambda_1 &amp; 0 &amp; \cdots &amp; 0 \\
     0 &amp;  \lambda_2 &amp; \cdots &amp; 0 \\
\vdots &amp;     \vdots &amp; \ddots &amp; \vdots \\
     0 &amp;          0 &amp; \cdots &amp; \lambda_n
\end{pmatrix},
&lt;/math&gt;

then

:&lt;math&gt;
D^k = 
\begin{pmatrix}
 \lambda_1^k &amp;           0 &amp; \cdots &amp; 0 \\
           0 &amp; \lambda_2^k &amp; \cdots &amp; 0 \\
      \vdots &amp;      \vdots &amp; \ddots &amp; \vdots \\
           0 &amp;           0 &amp; \cdots &amp; \lambda_n^k
\end{pmatrix}
&lt;/math&gt;

and the evaluation of the Maclaurin series for functions of &lt;math&gt;A&lt;/math&gt; is greatly simplified.&lt;ref&gt;{{harvtxt|Bronson|1970|p=184}}&lt;/ref&gt;  For example, to obtain any power ''k'' of &lt;math&gt;A&lt;/math&gt;, we need only compute &lt;math&gt;D^k&lt;/math&gt;, premultiply &lt;math&gt;D^k&lt;/math&gt; by &lt;math&gt;M&lt;/math&gt;, and postmultiply the result by &lt;math&gt;M^{-1}&lt;/math&gt;.&lt;ref&gt;{{harvtxt|Bronson|1970|p=185}}&lt;/ref&gt;

Using generalized eigenvectors, we can obtain the Jordan normal form for &lt;math&gt;A&lt;/math&gt; and these results can be generalized to a straightforward method for computing functions of nondiagonalizable matrices.&lt;ref&gt;{{harvtxt|Bronson|1970|pp=209–218}}&lt;/ref&gt;  (See [[Matrix function#Jordan decomposition]].)

=== Differential equations ===
{{Main|Ordinary differential equation}}
Consider the problem of solving the system of linear ordinary differential equations

:{{NumBlk|:|&lt;math&gt; \mathbf x' = A \mathbf x ,&lt;/math&gt;|{{EquationRef|5}}}}

where

:&lt;math&gt;
\mathbf x = 
\begin{pmatrix}
x_1(t) \\
x_2(t) \\
\vdots \\
x_n(t)
\end{pmatrix}, \quad
\mathbf x' = 
\begin{pmatrix}
x_1'(t) \\
x_2'(t) \\
\vdots \\
x_n'(t)
\end{pmatrix},
&lt;/math&gt; {{spaces|4}} and {{spaces|4}} &lt;math&gt; A = (a_{ij}) .&lt;/math&gt;

If the matrix &lt;math&gt;A&lt;/math&gt; is a diagonal matrix so that &lt;math&gt; a_{ij} = 0 &lt;/math&gt; for &lt;math&gt;i \ne j&lt;/math&gt;, then the system ({{EquationNote|5}}) reduces to a system of ''n'' equations which take the form

:{{NumBlk|:|
&lt;math&gt; x_1' = a_{11} x_1 &lt;/math&gt;&lt;br&gt;
&lt;math&gt; x_2' = a_{22} x_2 &lt;/math&gt;&lt;br&gt;
:&lt;math&gt; \vdots &lt;/math&gt;
&lt;math&gt; x_n' = a_{nn} x_n .&lt;/math&gt;
|{{EquationRef|6}}}}

In this case, the general solution is given by

:&lt;math&gt; x_1 = k_1 e^{a_{11}t} &lt;/math&gt;
:&lt;math&gt; x_2 = k_2 e^{a_{22}t} &lt;/math&gt;
::&lt;math&gt; \vdots &lt;/math&gt;
:&lt;math&gt; x_n = k_n e^{a_{nn}t} .&lt;/math&gt;

In the general case, we try to diagonalize &lt;math&gt;A&lt;/math&gt; and reduce the system ({{EquationNote|5}}) to a system like ({{EquationNote|6}}) as follows.  If &lt;math&gt;A&lt;/math&gt; is diagonalizable, we have &lt;math&gt; D = M^{-1}AM &lt;/math&gt;, where &lt;math&gt;M&lt;/math&gt; is a modal matrix for &lt;math&gt;A&lt;/math&gt;.  Substituting &lt;math&gt; A = MDM^{-1} &lt;/math&gt;, equation ({{EquationNote|5}}) takes the form &lt;math&gt; M^{-1} \mathbf x' = D(M^{-1} \mathbf x) &lt;/math&gt;, or

:{{NumBlk|:|&lt;math&gt; \mathbf y' = D \mathbf y ,&lt;/math&gt;|{{EquationRef|7}}}}

where

:{{NumBlk|:|&lt;math&gt; \mathbf x = M \mathbf y .&lt;/math&gt;|{{EquationRef|8}}}}

The solution of ({{EquationNote|7}}) is

:&lt;math&gt; y_1 = k_1 e^{\lambda_1 t} &lt;/math&gt;
:&lt;math&gt; y_2 = k_2 e^{\lambda_2 t} &lt;/math&gt;
::&lt;math&gt; \vdots &lt;/math&gt;
:&lt;math&gt; y_n = k_n e^{\lambda_n t} .&lt;/math&gt;

The solution &lt;math&gt; \mathbf x &lt;/math&gt; of ({{EquationNote|5}}) is then obtained using the relation ({{EquationNote|8}}).&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|pp=274–275}}&lt;/ref&gt;

On the other hand, if &lt;math&gt;A&lt;/math&gt; is not diagonalizable, we choose &lt;math&gt;M&lt;/math&gt; to be a generalized modal matrix for &lt;math&gt;A&lt;/math&gt;, such that &lt;math&gt; J = M^{-1}AM &lt;/math&gt; is the Jordan normal form of &lt;math&gt;A&lt;/math&gt;.  The system &lt;math&gt; \mathbf y' = J \mathbf y &lt;/math&gt; has the form

:{{NumBlk|:|
&lt;math&gt;
\begin{align}
y_1' &amp; = \lambda_1 y_1 + \epsilon_1 y_2 \\
&amp; \vdots \\
y_{n-1}' &amp; = \lambda_{n-1} y_{n-1} + \epsilon_{n-1} y_n \\
y_n' &amp; = \lambda_n y_n ,
\end{align}
&lt;/math&gt;
|{{EquationRef|9}}}}

where the &lt;math&gt; \lambda_i &lt;/math&gt; are the eigenvalues from the main diagonal of &lt;math&gt;J&lt;/math&gt; and the &lt;math&gt; \epsilon_i &lt;/math&gt; are the ones and zeros from the superdiagonal of &lt;math&gt;J&lt;/math&gt;.  The system ({{EquationNote|9}}) is often more easily solved than ({{EquationNote|5}}).  We may solve the last equation in ({{EquationNote|9}}) for &lt;math&gt;y_n&lt;/math&gt;, obtaining &lt;math&gt;y_n = k_n e^{\lambda_n t} &lt;/math&gt;.  We then substitute this solution for &lt;math&gt;y_n&lt;/math&gt; into the next to last equation in ({{EquationNote|9}}) and solve for &lt;math&gt;y_{n-1}&lt;/math&gt;.  Continuing this procedure, we work through ({{EquationNote|9}}) from the last equation to the first, solving the entire system for &lt;math&gt; \mathbf y &lt;/math&gt;.  The solution &lt;math&gt; \mathbf x &lt;/math&gt; is then obtained using the relation ({{EquationNote|8}}).&lt;ref&gt;{{harvtxt|Beauregard|Fraleigh|1973|p=317}}&lt;/ref&gt;

==Notes==
{{reflist|30em}}

== References ==
* {{ citation | first1 = Howard | last1 = Anton | year = 1987 | isbn = 0-471-84819-0 | title = Elementary Linear Algebra | edition = 5th | publisher = [[John Wiley &amp; Sons|Wiley]] | location = New York }}
*{{Cite book
  | last = Axler
  | first = Sheldon
  | title = Linear Algebra Done Right
  | publisher = Springer
  | year = 1997
  | edition = 2nd
  | isbn = 978-0-387-98258-8}}
* {{ citation | first1 = Raymond A. | last1 = Beauregard | first2 = John B. | last2 = Fraleigh | year = 1973 | isbn = 0-395-14017-X | title = A First Course In Linear Algebra: with Optional Introduction to Groups, Rings, and Fields | publisher = [[Houghton Mifflin Co.]] | location = Boston }}
* {{ citation | first1 = Richard | last1 = Bronson | year = 1970 | lccn = 70097490 | title = Matrix Methods:  An Introduction | publisher = [[Academic Press]] | location = New York }}
* {{ citation | first1 = Richard L. | last1 = Burden | first2 = J. Douglas | last2 = Faires | year = 1993 | isbn = 0-534-93219-3 | title = Numerical Analysis | edition = 5th | publisher = [[Prindle, Weber and Schmidt]] | location = Boston }}
* {{ citation | first1 = Charles G. | last1 = Cullen | title = Matrices and Linear Transformations | location = Reading | publisher = [[Addison-Wesley]] | year = 1966 | lccn = 66021267 }}
* {{ citation | first1 = Joel N. | last1 = Franklin | title = Matrix Theory | location = Englewood Cliffs | publisher = [[Prentice-Hall]] | year = 1968 | lccn = 68016345 }}
* {{ citation | first1 = Gene H. | last1 = Golub | first2 = Charles F. | last2 = Van Loan | year = 1996 | isbn = 0-8018-5414-8 | title = Matrix Computations | edition = 3rd | publisher = [[Johns Hopkins University Press]] | location = Baltimore }}
* {{ citation | first1 = Charlie | last1 = Harper | year = 1976 | isbn = 0-13-487538-9 | title = Introduction to Mathematical Physics | publisher = [[Prentice-Hall]] | location = New Jersey }}
* {{ citation | first1 = I. N. | last1 = Herstein | year = 1964 | isbn = 978-1114541016 | title = Topics In Algebra | publisher = [[Blaisdell Publishing Company]] | location = Waltham }}
* {{ citation | first1 = Erwin | last1 = Kreyszig | year = 1972 | isbn = 0-471-50728-8 | title = Advanced Engineering Mathematics | edition = 3rd | publisher = [[John Wiley &amp; Sons|Wiley]] | location = New York }}
* {{ citation | first1 = Evar D. | last1 = Nering | year = 1970 | title = Linear Algebra and Matrix Theory | edition = 2nd | publisher = [[John Wiley &amp; Sons|Wiley]] | location = New York | lccn = 76091646 }}

{{Linear algebra|collapsed}}
{{Areas of mathematics|collapsed}}

[[Category:Linear algebra]]
[[Category:Matrix theory]]</text>
      <sha1>1n5nwb176nvr0f2kzh1yrx255ffnvjr</sha1>
    </revision>
  </page>
  <page>
    <title>Ida Barney</title>
    <ns>0</ns>
    <id>37673979</id>
    <revision>
      <id>867542809</id>
      <parentid>864587125</parentid>
      <timestamp>2018-11-06T11:37:53Z</timestamp>
      <contributor>
        <username>Victuallers</username>
        <id>2592184</id>
      </contributor>
      <comment>pic added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11920">{{Infobox scientist
| name              = Ida Barney
| image = Ida_Barney_died_1982.jpg
| birth_date        = {{Birth date|1886|11|06}}
| birth_place       = [[New Haven]], Connecticut
| death_date        = {{Death date and age|1982|03|07|1886|11|06}}
| death_place       = New Haven, Connecticut
| citizenship       = United States
| fields            = Astronomy
| workplaces        = {{plainlist |
* [[Rollins College]]
* [[Smith College]]
* [[Lake Erie College]]
* [[Yale University Observatory]]
}}
| alma_mater        = {{plainlist |
* Smith College (B.A.)
* Yale University (Ph.D.)
}}
| thesis_year       = 1911
| known_for         = [[Astrometry|Astrometric]] measurements of 150,000 stars
| awards            = [[Annie J. Cannon Award in Astronomy]] (1952)
}}

'''Ida Barney''' (November 6, 1886 – March 7, 1982) was an American [[astronomer]], best known for her 22 volumes of [[astrometry|astrometric measurements]] on 150,000 stars. She was educated at [[Smith College]] and [[Yale University]] and spent most of her career at the [[Yale University Observatory]]. She was the 1952 recipient of the [[Annie J. Cannon Award in Astronomy]].

==Early life==
Barney was born on 6 November 1886 in [[New Haven, Connecticut]]. Her mother was Ida Bushnell Barney and her father was Samuel Eben Barney.{{sfn|Slight-Gibney|1997|p=1}}
She was an avid [[birder]] and the New Haven Bird Club President.{{sfn|Hoffleit|1990}} After her retirement from Yale, she continued to live in New Haven,{{sfn|Milite|1999|p=27}} where she died on 7 March 1982,{{sfn|Slight-Gibney|1997|p=1}} 95 years old.{{sfn|Slight-Gibney|1997|p=3}}

==Education==
In 1908, Barney graduated from [[Smith College]] with a [[Bachelor of Arts]] degree. There, she was a member of [[Phi Beta Kappa]] and [[Sigma Xi]], national honor societies for students. Three years later, she received her [[Ph.D.]] in [[mathematics]] from [[Yale University]].{{sfn|Slight-Gibney|1997|p=1}}

==Scientific career==
[[File:Old Knowles Hall, Rollins College, Winter Park, FL.jpg|thumb|Rollins College, ca.1909]]
From 1911–1912, just after receiving her Ph.D., Barney was a mathematics professor at [[Rollins College]]. At the conclusion of that year, she moved to her [[alma mater]] to [[Smith College]], where she was an instructor of mathematics. In 1917, she was hired as a professor at [[Lake Erie College]], where she stayed until 1919. In 1920, she returned to Smith College as an assistant professor. In 1922, the [[Yale University Observatory]] appointed Barney a Research Assistant, a title she held until 1949, when she was promoted to Research Associate.{{sfn|Slight-Gibney|1997|p=1}} The Observatory, like many other university observatories, was allocating significant resources to astrometry, thanks to the development of telescope-mounted cameras. At the beginning of her career in astronomy, Barney worked under [[Frank Schlesinger]]; she plotted the position of stars from photographic plates and worked on the calculations of their celestial coordinates from their positions on the plates.{{sfn|Slight-Gibney|1997|p=2}} The work was tedious, which Schlesinger thought to be suitable for women incapable of theoretical research.{{sfn|Ogilvie|Harvey|2000|p=82}} Despite this, she developed several methods that increased both the accuracy and speed of her measurements, including the use of a machine that automatically centered the photographic plates.{{sfn|Milite|1999|p=27}} Her life's work, completed over 23 years, contributed to the [[Yale Observatory Zone Catalog]], a series of star catalogs published by the Yale Observatory for 1939 to 1983, containing around 400,000 stars, and influenced the [[Bright Star Catalogue]].{{sfn|Hoffleit|1990}} In 1941, when Schlesinger retired, Barney took over full supervision of the cataloguing. Under her direction, the measurements of the photographic plates were completed at the IBM Watson Scientific Laboratory using a new electronic device that further reduced eye strain and increased accuracy.{{sfn|Slight-Gibney|1997|p=3}} Her individual contribution to these [[star catalogue]]s recorded the position, [[apparent magnitude|magnitude]], and [[proper motion]] of approximately 150,000 stars. Due to its high accuracy, the catalogue is still used today in proper motion studies.{{sfn|Slight-Gibney|1997|p=1}}{{sfn|Hoffleit|1990}} She retired from academic life in 1955.{{sfn|Slight-Gibney|1997|p=3}}  She was succeeded by [[Ellen Dorrit Hoffleit]].{{sfn|Hoffleit|1990}}

===Honors===
While a Research Associate at the Yale University Observatory, in 1952, Barney was awarded the triennial [[Annie J. Cannon Award in Astronomy]], a prestigious award for women astronomers given by the [[American Astronomical Society]].{{sfn|Slight-Gibney|1997|p=1}}{{sfn|Hoffleit|1990}}{{sfn|Slight-Gibney|1997|p=3}}{{sfn|ASP 65|1953}}{{sfn|AAS|2012}}

Her remains are interred at [[Grove Street Cemetery]] in New Haven, Connecticut.{{sfn|Find A Grave}}

Asteroid [[5655 Barney]], discovered by [[Ingrid van Houten-Groeneveld]], [[Cornelis Johannes van Houten]] and [[Tom Gehrels]] at [[Palomar Observatory]] in 1973, was named it in her memory.{{sfn|Hockey|2009}}

==Published works==
*{{cite journal |first1=Ida |last1=Barney |first2=Jan |last2=Schilt |authorlink2=Jan Schilt |title=Discussion of the proper motions in the equatorial Zone|journal=[[Astronomical Journal]] |volume=37 |date=1927|doi=10.1086/104785 |bibcode = 1927AJ.....37..181B |pages=181}}
*{{cite journal |first1=Ida |last1=Barney |first2=Jan |last2=Schilt |authorlink2=Jan Schilt|title=Analysis of the Yale proper motions in the zones between +50 degrees and +55 degrees and between +55 degrees and +60 |journal=Astronomical Journal |volume=40 |date=1930 | doi=10.1086/105000 |bibcode = 1930AJ.....40..168B |pages=168}}
*{{cite journal |first1=Ida |last1=Barney |first2=Frank |last2=Schlesinger |authorlink2=Frank Schlesinger |title=An effect of a star's color upon its apparent photographic position|journal=Astronomical Journal|volume=47|page=86|date=1938|bibcode=1938AJ.....47...86B|doi=10.1086/105478}}
*{{cite journal |first1=Ida |last1=Barney |first2=Frank |last2=Schlesinger |authorlink2=Frank Schlesinger |title=
On the accuracy of the proper motions in the General Catalogue Albany |journal=Astronomical Journal |volume=48 |date=1939|doi=10.1086/105546|bibcode = 1939AJ.....48...51B |pages=51}}
* {{cite journal |first1=Ida |last1=Barney |first2=Frank |last2=Schlesinger |authorlink2=Frank Schlesinger |title=New reductions of astrographic plates with the help of the Yale photographic Catalogues |journal=Astronomical Journal |volume=49 |date=1940|doi=10.1086/105625|bibcode = 1940AJ.....49...39B |pages=39}}&lt;ref group=upper-alpha&gt;[http://bibpurl.oclc.org/web/8910 Scanned issues (1849–1997) from ADS]&lt;/ref&gt;

==See also==
*[[List of minor planets: 5001–6000|List of Minor Planets 5001{{ndash}}6000, #5655]]
*[[List of minor planets named after people]]
*[[Meanings of minor planet names: 5501–6000]]

==References==

===Notes===
{{Reflist|group=upper-alpha}}

===Footnotes===
;Citations
{{Reflist|30em}}
;References
*{{citation
  | title = Annie J. Cannon Award in Astronomy
  | year = 2012
  | publisher = American Astronomical Society
  | url = http://aas.org/prizes/annie_j_cannon_award_in_astronomy
  | accessdate = 20 November 2012
  | ref = {{sfnRef|AAS|2012}}
  }}
*{{citation
  | ref = {{sfnRef|ASP 65|1953}}
  | title = General Notes
  | journal = [[Publications of the Astronomical Society of the Pacific]]
  | date = April 1953
  | pages = 98–100
  | volume = 65
  | bibcode=1953PASP...65...98.
  | doi=10.1086/126550
  }}
*{{citation
  | work = [[The Biographical Encyclopedia of Astronomers]]
  | last1 = Hockey | first1 = Thomas
  | year = 2009
  | publisher = [[Springer Publishing]]
  | subscription = yes
  | isbn = 978-0-387-31022-0
  | url = http://www.springerreference.com/docs/html/chapterdbid/130278.html
  | title = (5655) Barney1159 T-2
  | accessdate = November 19, 2012
  | ref = harv
  }}
*{{citation
  | url = http://www.aas.org/cswa/status/status_june1990.pdf
  | format = [[PDF]]
  | work = STATUS: The Committee on the Status of Women in Astronomy
  | publisher = [[American Astronomical Society]]
  | date = June 1990
  | title = Ida M. Barney, Ace Astrometrist
  | first = E. Dorrit
  | last1 = Hoffleit
  | authorlink=Ellen Dorrit Hoffleit
  | accessdate = 17 November 2012
  }}
*{{citation
  | url = http://www.findagrave.com/cgi-bin/fg.cgi?page=gr&amp;GSln=barney&amp;GSfn=Ida&amp;GSby=1886&amp;GSbyrel=in&amp;GSdy=1982&amp;GSdyrel=in&amp;GScntry=4&amp;GSob=n&amp;GRid=16794228&amp;df=all&amp;
  | title = Ida Barney
  | publisher = [[Find A Grave]]
  | accessdate = 19 November 2012
  | ref = {{sfnRef|Find A Grave}}
  }}
*{{citation
  | title = Ida Barney
  | work = Notable Women Scientists
  | editor = Pamela Proffitt
  | year = 1999
  | page = 27
  | last = Milite
  | first = George A.
  | publisher = [[Gale Group|Gale Group, Inc.]]
  | location = Farmington Hills, Michigan
  | isbn = 0-7876-3900-1
  | ref = harv
  }}
*{{citation
  | title = Biographical Dictionary of Women in Science
  | last1 = Ogilvie
  | last2 = Harvey
  | first1 = Marilyn
  | first2 = Joy
  | publisher = [[Routledge]]
  | location = New York
  | year = 2000
  | isbn = 0-415-92038-8
  | ref = harv
  }}
*{{citation
  | title = Ida Barney
  | work = Notable Women in the Physical Sciences: A Biographical Dictionary
  | editors = Barbara S. and Benjamin F. Shearer
  | last = Slight-Gibney
  | first = Nancy
  | pages = 1–4
  | publisher = [[Greenwood Press]]
  | location = Westport, Connecticut
  | year = 1997
  | isbn = 0-313-29303-1
  | ref = harv
  }}

==Further reading==
*{{cite web |url=https://www.loc.gov/rr/scitech/womenastro/womenastro-all.html |title=Bibliography: Ida Smith Barney |work=Women in Astronomy|publisher=[[Library of Congress]]|accessdate=18 November 2012}}
*{{cite journal |work=The Biographical Encyclopedia of Astronomers |last=Hockey |first=Thomas |date=2009 |publisher=[[Springer Publishing]] |isbn=978-0-387-31022-0 |title=Doritt E. Hoffleit |accessdate=August 22, 2012 |url=http://www.springerreference.com/docs/html/chapterdbid/58639.html}} {{subscription}}
*{{cite journal |work=The Biographical Encyclopedia of Astronomers |last=Hockey |first=Thomas |date=2009 |publisher=[[Springer Publishing]] |isbn=978-0-387-31022-0 |accessdate=August 22, 2012 |url=http://www.springerreference.com/docs/html/chapterdbid/59236.html |title=Frank Schleisinger}} {{subscription}}
*{{cite book | url=https://books.google.de/books?id=IRbOAwAAQBAJ | isbn=978-0-8218-4376-5 | first1 = Judy | last1 = Green | author1-link = Judy Green (mathematician) | first2 = Jeanne | last2 = LaDuke | author2-link = Jeanne LaDuke| title=Pioneering Women in American Mathematics &amp;mdash; The Pre-1940 PhD's | location= | publisher=[[American Mathematical Society]],  The [[London Mathematical Society]] | series=History of Mathematics | volume=34 | edition=1st | date=2008 }} Biography on p.54-57 of the [https://www.ams.org/bookpages/hmath-34-PioneeringWomen.pdf Supplementary Material] at [https://www.ams.org/publications/authors/books/postpub/hmath-34 AMS]

{{Authority control}}

{{DEFAULTSORT:Barney, Ida}}
[[Category:Astronomical catalogues]]
[[Category:Astronomical catalogues of stars]]
[[Category:American astronomers]]
[[Category:American mathematicians]]
[[Category:Women mathematicians]]
[[Category:Lake Erie College faculty]]
[[Category:Scientists from New Haven, Connecticut]]
[[Category:Smith College alumni]]
[[Category:Rollins College faculty]]
[[Category:Smith College faculty]]
[[Category:Women astronomers]]
[[Category:American women scientists]]
[[Category:Yale University alumni]]
[[Category:Yale University faculty]]
[[Category:1886 births]]
[[Category:1982 deaths]]
[[Category:Recipients of the Annie J. Cannon Award in Astronomy]]
[[Category:20th-century women scientists]]
[[Category:20th-century American scientists]]</text>
      <sha1>m7br3ntn8kzlelmvvi0hb81m4ft1sal</sha1>
    </revision>
  </page>
  <page>
    <title>Inclusion (logic)</title>
    <ns>0</ns>
    <id>26280279</id>
    <revision>
      <id>845297615</id>
      <parentid>609028697</parentid>
      <timestamp>2018-06-10T21:05:18Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <comment>eg Logical matrix</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1273">In [[logic]] and [[mathematics]], '''inclusion''' is the concept that all the contents of one object are also contained within a second object.&lt;ref&gt;{{cite article| doi=10.2307/2268279 | journal=[[The Journal of Symbolic Logic]] | volume=2 | number=4 | date=December 1937 | pages=145–152 | title=Logic based on inclusion and abstraction | first=W. V. | last=Quine }}&lt;/ref&gt;

For example, if ''m'' and ''n'' are two [[logical matrix|logical matrices]], then
:&lt;math&gt;m \subset n \quad \text{when} \quad \forall i,j \quad m_{ij} = 1 \implies n_{ij} = 1 .&lt;/math&gt;

The modern symbol for inclusion first appears in [[Joseph Diaz Gergonne|Gergonne]] (1816), who defines it as one idea 'containing' or being 'contained' by another, using the backward letter 'C' to express this. [[Charles Sanders Peirce|Peirce]] articulated this clearly in 1870, arguing also that inclusion was a wider concept than equality, and hence a logically simpler one.&lt;ref&gt;"Descr. of a notation", CP III 28.&lt;/ref&gt;  [[Ernst Schröder|Schröder]] (also [[Gottlob Frege|Frege]]) calls the same concept 'subordination'.&lt;ref&gt;Vorlesungen I., 127.&lt;/ref&gt;

==References==
{{reflist}}

{{DEFAULTSORT:Inclusion (Logic)}}
[[Category:1816 introductions]]
[[Category:History of logic]]
[[Category:Logic]]

{{logic-stub}}</text>
      <sha1>q3e14gsspj5fs83cwvjp9oio7od16rz</sha1>
    </revision>
  </page>
  <page>
    <title>James Gow (scholar)</title>
    <ns>0</ns>
    <id>52183761</id>
    <revision>
      <id>857178104</id>
      <parentid>794032535</parentid>
      <timestamp>2018-08-30T01:57:11Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* External links */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3056">'''James Gow''' (1854–1923) was an English scholar, educator, historian, and author, widely recognized for ''A Short History of Greek Mathematics''. The history drew highly upon the work of [[Moritz Cantor]],&lt;ref&gt;Joseph W. Dauben, Christoph J. Scriba, ''Writing the History of Mathematics: Its Historical Development'' (2002) p. 171.&lt;/ref&gt; as well as upon pioneering works of [[Carl Anton Bretschneider]], [[Hermann Hankel]], and [[George Johnston Allman]],&lt;ref&gt;[[Thomas Little Heath]], ''A History of Greek Mathematics'' (1921) [https://books.google.com/books?id=h4JsAAAAMAAJ Vol. 1]. ''From Thales to Euclid'' Preface, p. vi.&lt;/ref&gt; but included material, e.g., [[gematria]], not discussed by contemporary historians of mathematics.

==Life==
James was the son of the artist James Gow (Sr.), who was a member of the Royal Society of British Artists. He married Gertrude Sydenham (the daughter of G. P. and M. A. Everett Green) with whom he had three sons. Following an education at King's College School, he received his Master of Arts a Trinity College, Cambridge. Gow was a third Classic and Chancellor's Classical medalist in 1875 at Cambridge, and became a Fellow of Trinity College and of King's College, London and in 1876. At Cambridge he earned Doctor of Letters in 1885 and served as University Extension Lecturer from 1876 to 1878. He was Barrister at Lincoln's Inn in 1875, President of the Headmaster's Association from 1900 to 1902, and Chairman of the Headmaster's Conference in 1906. Gow was also Master of the Nottingham High School from 1885 to 1901, following which, he became Headmaster of Westminster school.&lt;ref&gt;''Who's who: An Annual Biographical Dictionary'' (1907) A. &amp; C. Black, [https://books.google.com/books?id=yEcuAAAAYAAJ Part 2]. p. 710.&lt;/ref&gt; He also contributed articles to the 1911 ''Encyclopædia Britannica''.

==Works==
* (1884) ''[https://archive.org/details/ashorthistorygr00gowgoog A Short History of Greek Mathematics]''
* (1888) ''[https://archive.org/details/acompaniontosch01gowgoog A Companion to School Classics]''&lt;ref&gt;{{cite journal|title=Review of ''A Companion to School Classics'' by James Gow|journal=Science|date=8 June 1888|volume=XI|issue=279|page=275|url=https://babel.hathitrust.org/cgi/pt?id=uc1.31822020652350;view=1up;seq=299}}&lt;/ref&gt;
* (1895) ''Horace's Odes and Satires'' edited, with introduction and notes by James Gow
* (1907) ''A Method of English for Secondary Schools'', [https://archive.org/details/amethodenglishf00gowgoog Part 1]
*{{cite EB1911|wstitle=Horace|volume=13 |pages=687–691 |short=x}}

==References==
{{Reflist|30em}}

==External links==
{{wikiquote}}
{{wikisource|Author:James Gow}}
* ''[https://books.google.com/books?id=9d8DAAAAMAAJ A Short History of Greek Mathematics]'' (1884) (public domain) @GoogleBooks

{{authority control}}

{{DEFAULTSORT:Gow, James}}
[[Category:1854 births]]
[[Category:1923 deaths]]
[[Category:19th-century English writers]]
[[Category:Classical scholars]]
[[Category:Fellows of King's College London]]
[[Category:Historians of mathematics]]</text>
      <sha1>36m3o8xvsw7fkgk78behvj1f96w8itj</sha1>
    </revision>
  </page>
  <page>
    <title>John Riordan (mathematician)</title>
    <ns>0</ns>
    <id>11751393</id>
    <revision>
      <id>866718181</id>
      <parentid>866009763</parentid>
      <timestamp>2018-11-01T02:48:26Z</timestamp>
      <contributor>
        <username>Alaney2k</username>
        <id>209266</id>
      </contributor>
      <minor/>
      <comment>/* top */US =&gt; Americans; reduce overlinking</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7304">{{Infobox person
| name = John Riordan
| birth_name = 
| image =
| imagesize = 
| caption = 
| birth_date = {{birth date|mf=yes|1903|4|22}} 
| birth_place = [[Derby, Connecticut]], United States
| death_date = {{death date and age|mf=yes|1988|8|27|1903|4|22}}
| death_place = [[Scituate, Massachusetts]], United States
| occupation  = Mathematician
| nationality = [[Americans|American]]
| alma mater  = [[Yale University]]
| spouse = Mavis McIntosh
| yearsactive = 1926&amp;ndash;1968

}}
'''John Francis Riordan''' (April 22, 1903 &amp;ndash; August 27, 1988)&lt;ref&gt;[https://www.nytimes.com/1988/08/31/obituaries/john-f-riordan-85-ex-bell-labs-engineer.html John F. Riordan, 85, Ex-Bell Labs Engineer], ''[[The New York Times]]'' obituary, August 31, 1988&lt;/ref&gt; was an American [[mathematician]] and the author of major early works in [[combinatorics]], particularly ''Introduction to Combinatorial Analysis'' and ''Combinatorial Identities''.

==Biography==

Riordan was a graduate of [[Yale University]]. In his early life he wrote a number of poems and essays and a book of short-stories, ''On the Make'', published in 1929, and was Editor-in-Chief of ''Salient'' and ''The Figure in the Carpet'', literary magazines published by [[The New School|The New School for Social Research]] in New York. He married Mavis McIntosh, the well-known poet and literary agent and founder of [[McIntosh &amp; Otis]].  The couple had two daughters: Sheila Riordan and Kathleen Riordan Speeth, and were long time residents of [[Hastings-on-Hudson, New York]].&lt;ref&gt;[https://www.nytimes.com/1986/08/06/obituaries/mavis-mcintosh-riordan-83-represented-noted-writers.html Mavis McIntosh Riordan, 83; Represented Noted Writers], ''The New York Times'' obituary, August 6, 1986.&lt;/ref&gt;

Riordan's long professional career was at [[Bell labs|Bell Labs]], which he joined in 1926 (a year after its foundation) and where he remained, publishing over a hundred scholarly papers on combinatorial analysis, until he retired in 1968. He then joined the faculty at [[Rockefeller University]] as professor emeritus. A [[Festschrift]] was published in his honor in 1978.&lt;ref&gt;{{cite journal |last1=Kac |first1=M. |year=1978 |volume=24 |number=3 |journal=Journal of Combinatorial Theory, Series A |title=Special Issue in Honor of Riordan, John - Introduction |pages=ii,255 |doi=10.1016/0097-3165(78)90055-9}}&lt;/ref&gt;

Throughout his life Riordan led an active literary life, with many distinguished friends such as [[Kenneth Burke]], [[William Carlos Williams]], and [[A. R. Orage]].

== Tribute ==

From the ''Introduction'' by [[Marc Kac]] to the Special Issue of the ''[[Journal of Combinatorial Theory|JCTA]]'' in honor of John Riordan:

: ''Foremost among the keepers of the barely flickering combinatorial flame was John Riordan.  John’s work in Combinatorial Theory (or Combinatorial Analysis as he prefers to call it) is uncompromisingly classical in spirit and appearance. Though largely tolerant of modernity he does not let anyone forget that Combinatorial Analysis is the art and science of counting (enumerating is the word he prefers) and that a [[generating function]] by any other name or definition is still a generating function.''

From [http://www.research.att.com/~njas/doc/interview.html an interview] with [[Neil Sloane]] published by Bell Labs:

: ''Even at the end of my first year as a graduate student at Cornell, in 1962, I managed to arrange a summer job at Bell Labs in Holmdel. This was still on minimal cost networks. During that summer I met another of my heroes, John Riordan, one of the great early workers in combinatorics. His book'' An Introduction to Combinatorial Analysis ''is a classic. He was working at Bell Labs in West Street in Manhattan at that time. One of my earliest papers, on a problem that came up in my thesis work, was a joint paper with him.&lt;ref&gt;{{cite journal |author=J. Riordan, N. J. A. Sloane |title=The enumeration of rooted trees by total height |journal=J. Austral. Math. Soc. |volume=10 |year=1969 |pages=278–282 |doi=10.1017/S1446788700007527 |url=http://www.research.att.com/~njas/doc/rooted.html}}&lt;/ref&gt;

==Selected publications==

* {{cite book |last=Riordan |first=John |title=On the Make |publisher=[[Farrar &amp; Rinehart]] |year=1929 |oclc=7532863}} (book of 14 short-stories)
* {{cite journal |last1=Carlitz |first1=Leonard |authorlink1=Leonard Carlitz |last2=Riordan |first2=John |title=The number of labeled two-terminal series-parallel networks |journal=[[Duke Mathematical Journal]] |publisher=[[Duke University Press]] |url=http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;handle=euclid.dmj/1077466956 |year=1956}}
* {{cite book |last=Riordan |first=John |url=https://books.google.com/books?id=zWgIPlds29UC |title=Introduction to Combinatorial Analysis |publisher=Princeton University Press |year=1958 |isbn=978-0-691-02365-6}}&lt;ref&gt;{{cite journal|author=Harary, Frank|authorlink=Frank Harary|title=Review: ''Introduction to combinatorial analysis'', by John Riordan|journal=Bull. Amer. Math. Soc.|year=1959|volume=65|issue=3|pages=166–169|url=http://www.ams.org/journals/bull/1959-65-03/S0002-9904-1959-10314-1/S0002-9904-1959-10314-1.pdf|doi=10.1090/s0002-9904-1959-10314-1}}&lt;/ref&gt; (reissued in 1980; reprinted again in 2002 by Courier Dover Publications) translated into Russian in 1962.
* {{cite book |last=Riordan |first=John |title=Stochastic Service Systems |publisher=[[John Wiley &amp; Sons]] |year=1962 |lccn=62008785 |url=https://books.google.com/books?id=VElVAAAAMAAJ}}
* {{cite book |last=Riordan |first=John |title=Combinatorial Identities |publisher=[[John Wiley &amp; Sons]] |year=1968 |oclc=681863847 |lccn=67031375 |url=https://books.google.com/books?id=X6ccBWwECP8C}}&lt;ref&gt;{{cite journal|author=Stein, Paul R.|title=Review: ''Combinatorial identities'', by John Riordan|journal=Bull. Amer. Math. Soc.|year=1972|volume=78|issue=4|pages=490–496|url=http://www.ams.org/journals/bull/1972-78-04/S0002-9904-1972-12968-9/S0002-9904-1972-12968-9.pdf|doi=10.1090/s0002-9904-1972-12968-9}}&lt;/ref&gt; (reprinted with corrections: {{cite book  |last=Riordan |first=John |title=Combinatorial Identities |publisher=R.E. Krieger Pub. Co. |year=1979 |isbn=978-0-88275-829-9}})

== Notes ==
{{Reflist}}

==External links==
* [http://cm.bell-labs.com/cm/ms/center/frmdir.html Former Members of the Technical Staff]{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }} in the mathematics group at Bell Laboratories.
* [http://cm.bell-labs.com/cm/ms/departments/fm/history.html A history of mathematics at Bell Labs]{{dead link|date=November 2017 |bot=InternetArchiveBot |fix-attempted=yes }}
* [http://dimes.rockarch.org/xtf/view?docId=ead/FA191/FA191.xml;chunk.id=ref6;brand=default&amp;doc.view=contents A Guide to John F. Riordan Papers' Rockefeller University Faculty FA 191]
* [http://dimes.rockarch.org/FA191/biohist John F. Riordan, 1903-1988. Mathematician and engineer]
* [https://oeis.org/wiki/RiordanPrize The John Riordan Prize]

{{Authority control}}

{{DEFAULTSORT:Riordan, John}}
[[Category:20th-century mathematicians]]
[[Category:Combinatorialists]]
[[Category:Scientists at Bell Labs]]
[[Category:Yale University alumni]]
[[Category:People from Hastings-on-Hudson, New York]]
[[Category:1902 births]]
[[Category:1988 deaths]]</text>
      <sha1>850f8seurm0bjxn0p1y7s6m2ijck7za</sha1>
    </revision>
  </page>
  <page>
    <title>Karl-Heinz Boseck</title>
    <ns>0</ns>
    <id>46187197</id>
    <revision>
      <id>861379757</id>
      <parentid>797034428</parentid>
      <timestamp>2018-09-27T00:36:38Z</timestamp>
      <contributor>
        <username>Ser Amantio di Nicolao</username>
        <id>753665</id>
      </contributor>
      <minor/>
      <comment>/* References */add authority control, test</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3934">{{POV|date=March 2015}}

'''Karl-Heinz Boseck''' (born 11 December 1915)&lt;ref name="Simon.2010"&gt;{{cite report | author=Gerd Simon&lt;sup&gt;([[:de:Gerd Simon|de]])&lt;/sup&gt; | title=Chronologie Häftlingsforschung | institution=Univ. Tübingen | date=May 2010 |url=http://homepages.uni-tuebingen.de/gerd.simon/ChrHaeftlingsfo.pdf }}&lt;/ref&gt;{{rp|39}} was a German mathematician.

According to Segal (2003), Boseck was a fanatical [[National Socialist]] and a student leader.&lt;ref name="Segal.2003"&gt;{{cite book | author=Sanford Segal | title=Mathematicians under the Nazis | location=Princeton/NJ | publisher=Princeton University Press | isbn=0-691-00451-X | year=2003 }}&lt;/ref&gt;{{rp|323}}
He was an informer of the [[Gestapo]]&lt;ref name="Mehrtens.1996"&gt;{{cite book | author=H. Mehrtens | contribution=Mathematics and War: Germany, 1900–1945 | pages=87–134 | editor=Paul Forman and José M. Sánchez-Ron | title=National Military Establishments and  the Advancement of Science and Technology | location=Dordrecht | publisher=Kluwer Academic Publishers | isbn=0-7923-3541-4 | year=1996}}&lt;/ref&gt;{{rp|119}}&lt;ref name="Luig.2008"&gt;{{cite news | last =Luig | first =Judith | title =Die Mathe-Nazis | newspaper =taz | location =Berlin | pages = | language =German | publisher = | date =2008-08-30 | url =http://www.taz.de/1/archiv/print-archiv/printressorts/digi-artikel/?ressort=do&amp;dig=2008%2F08%2F30%2Fa0010&amp;cHash=bba66f8109 }}&lt;/ref&gt; since 1939.&lt;ref name="Simon.2010"/&gt;{{rp|39}}
In 1944, shortly after his diploma graduation he was made an [[Untersturmführer]] of the [[Nazi SS]] and established a department for numerical computation in the [[Sachsenhausen concentration camp]]&lt;ref name="Mehrtens.1996"/&gt;{{rp|118–120}}&lt;ref name="Luig.2008"/&gt;
He was exempted from war service due to a disease.
He was an assistant of the German mathematician [[Alfred Klose]]&lt;sup&gt;([[:de:Alfred Klose (Mathematiker)|de]])&lt;/sup&gt; at [[Berlin University]], and had great influence in the faculty during World War II.&lt;ref name="Segal.2003"/&gt;{{rp|323}}
At the first mathematicians camp 1–3 July 1938 in the youth hostel of Ützdorf&lt;sup&gt;([[:de:Ützdorf (Wandlitz)#Bebauung, Sport und weitere Besonderheiten|de]])&lt;/sup&gt; near [[Bernau bei Berlin|Bernau]], he lectured "On the development of student science work".&lt;ref&gt;{{cite journal | author=[[Johannes Juilfs]] | title=Das erste deutsche Mathematikerlager | journal=[[Deutsche Mathematik]] | volume=3 | number=1 | pages=109–140 | date=Mar 1939 }}&lt;/ref&gt;{{rp|123&amp;mdash;124}}
&lt;!---
commented out for now, to avoid undue weight in short article:---According to the mathematician [[Alexander Dinghas]], Boseck was "a small version of Robespierre", and had "narrow views, lust for power, desire to dominate other human beings and the blind belief in ideas".---&gt;He was department chairman for natural science at Berlin University, and had great influence on [[Ludwig Bieberbach]] who was leader of the "seminar" (may be institute); with course of time even more power shifted from Bieberbach to Boseck.&lt;ref&gt;{{cite book | author=Alexander Dinghas | contribution=Erinnerungen aus den letzten Jahren  des Mathematischen Instituts der Universität Berlin | editor=Heinrich Begehr | title=Mathematik in Berlin &amp;mdash; Geschichte und Dokumentation (2.Halbband)| location=Aachen | publisher=Shaker Verlag | year=1998}}&lt;/ref&gt;&lt;ref&gt;{{cite book | author=Eckart Menzler-Trott | title=Logic's Lost Genius: The Life of Gerhard Gentzen | location=Providence/RI | publisher=American Mathematical Society | series=History of Mathematics | volume=33 | isbn=978-0-8218-3550-0 | year=2007 }}&lt;/ref&gt;{{rp|153}}

==References==
{{reflist}}


{{authority control}}

{{DEFAULTSORT:Boseck, Karl-Heinz}}
[[Category:German mathematicians]]
[[Category:SS personnel]]
[[Category:Sachsenhausen concentration camp]]
[[Category:Humboldt University of Berlin alumni]]
[[Category:1915 births]]
[[Category:Year of death missing]]


{{nazi-stub}}
{{mathematician-stub}}</text>
      <sha1>qk53vle2jqnvw8pnz3db5j2644ez00g</sha1>
    </revision>
  </page>
  <page>
    <title>Krylov–Bogolyubov theorem</title>
    <ns>0</ns>
    <id>7635266</id>
    <revision>
      <id>834499575</id>
      <parentid>790712337</parentid>
      <timestamp>2018-04-06T01:37:39Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* top */[[User:JCW-CleanerBot#Logic|task]], replaced: Ann. Math. II → Annals of Mathematics |series=Second Series using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3364">In [[mathematics]], the '''Krylov–Bogolyubov theorem''' (also known as the '''existence of invariant measures theorem''') may refer to either of the two related fundamental [[theorem]]s within the theory of [[dynamical systems]]. The theorems guarantee the existence of [[invariant measure]]s for certain "nice" maps defined on "nice" spaces and were named after [[Russia]]n-[[Ukraine|Ukrainian]] [[mathematician]]s and [[theoretical physics|theoretical physicists]] [[Nikolay Mitrofanovich Krylov|Nikolay Krylov]] and [[Nikolay Bogolyubov]] who proved the theorems.&lt;ref name="Bogoliubov1937"&gt;{{cite journal|author=N. N. Bogoliubov and N. M. Krylov|journal=Annals of Mathematics |series=Second Series|volume=38|pages=65–113|year=1937|jstor=1968511|title=La theorie generalie de la mesure dans son application a l'etude de systemes dynamiques de la mecanique non-lineaire|language=French|doi=10.2307/1968511|issue=1|publisher=Annals of Mathematics}} Zbl. 16.86.&lt;/ref&gt;

==Formulation of the theorems==

===Invariant measures for a single map===
'''Theorem (Krylov–Bogolyubov)'''. Let (''X'',&amp;nbsp;''T'') be a [[compact space|compact]], [[metrization theorem|metrizable]] [[topological space]] and ''F''&amp;nbsp;:&amp;nbsp;''X''&amp;nbsp;→&amp;nbsp;''X'' a [[continuous map]]. Then ''F'' admits an invariant [[Borel measure|Borel]] [[probability measure]].

That is, if Borel(''X'') denotes the [[Borel sigma algebra|Borel]] [[sigma algebra|&amp;sigma;-algebra]] generated by the collection ''T'' of [[open set|open subsets]] of ''X'', then there exists a probability measure ''μ'' : Borel(''X'') → [0, 1] such that for any subset ''A'' ∈ Borel(''X''),
:&lt;math&gt;\mu \left( F^{-1} (A) \right) = \mu (A).&lt;/math&gt;

In terms of the [[pushforward measure|push forward]], this states that
:&lt;math&gt;F_{*} (\mu) = \mu.&lt;/math&gt;

===Invariant measures for a Markov process===
Let ''X'' be a [[Polish space]] and let &lt;math&gt;P_t, t\ge 0,&lt;/math&gt; be the transition probabilities for a time-homogeneous [[Markov process|Markov]] [[semigroup]] on ''X'', i.e.
:&lt;math&gt;\Pr [ X_{t} \in A | X_{0} = x ] = P_{t} (x, A).&lt;/math&gt;

'''Theorem (Krylov–Bogolyubov)'''. If there exists a point &lt;math&gt;x\in X&lt;/math&gt; for which the family of probability measures {&amp;nbsp;''P''&lt;sub&gt;''t''&lt;/sub&gt;(''x'',&amp;nbsp;·)&amp;nbsp;|&amp;nbsp;''t''&amp;nbsp;&amp;gt;&amp;nbsp;0&amp;nbsp;} is [[tightness of measures|uniformly tight]] and the semigroup (''P''&lt;sub&gt;''t''&lt;/sub&gt;) satisfies the [[Feller-continuous process|Feller property]], then there exists at least one invariant measure for (''P''&lt;sub&gt;''t''&lt;/sub&gt;), i.e. a probability measure ''μ'' on ''X'' such that
:&lt;math&gt;(P_{t})_{\ast} (\mu) = \mu \mbox{ for all } t &gt; 0.&lt;/math&gt;

==See also==
* For the 1st theorem: [[Ya. G. Sinai]] (Ed.) (1997): ''Dynamical Systems II. Ergodic Theory with Applications to Dynamical Systems and Statistical Mechanics''. Berlin, New York: Springer-Verlag. {{isbn|3-540-17001-4}}. (Section 1).
* For the 2nd theorem: G. Da Prato and J. Zabczyk (1996): ''Ergodicity for Infinite Dimensional Systems''. Cambridge Univ. Press. {{isbn|0-521-57900-7}}. (Section 3).

==Notes==
{{reflist}}

{{PlanetMath attribution|id=5525|title=Krylov-Bogolubov theorem}}

{{DEFAULTSORT:Krylov-Bogolyubov theorem}}
[[Category:Ergodic theory]]
[[Category:Theorems in dynamical systems]]
[[Category:Probability theorems]]
[[Category:Random dynamical systems]]
[[Category:Measure theory]]</text>
      <sha1>71ym7sic06ad0pgdqiy6lhpl3bqzsnp</sha1>
    </revision>
  </page>
  <page>
    <title>List of Slovenian mathematicians</title>
    <ns>0</ns>
    <id>249844</id>
    <revision>
      <id>863333633</id>
      <parentid>797753315</parentid>
      <timestamp>2018-10-10T03:53:57Z</timestamp>
      <contributor>
        <username>Doremo</username>
        <id>9337959</id>
      </contributor>
      <comment>link</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4343">{{Cleanup list|date=November 2016}}
{{Lists of Slovenians}}
This is a list of '''[[Slovenia]]n [[mathematician]]s'''.

{{compact ToC|side=yes|top=yes|num=yes}}

== A ==

* [[Anton Ambschel]] (1749–1821)

== B ==

* [[Iztok Banič]]
* [[Vladimir Batagelj]] (1948–)
* [[Andrej Blejec]] (1953–)
* [[Marijan Blejec]] (1919–1992)
* [[Marko Boben]] (1973–)
* [[Ludvik Bogataj]] (1949–2009)
* [[Zvonimir Bohte]] (1935–)
* [[Janko Bračič]]
* [[Franc Breckerfeld]] (1681–1744)
* [[Matevž Bren]] (1954–)
* [[Boštjan Brešar]]
* [[Matej Brešar]] (1963–)
* [[Silvo Breskvar]] (1902–1969)
* [[Andrej Brodnik]] (1961–)

== C ==

* [[Anton Cedilnik]]
* [[Matija Cencelj]]
* [[Andrej Cergol]] (1595–1645)
* [[Miran Černe]]
* [[Jaka Cimprič]]

== D ==
* [[France Dacar]]
* [[Mirko Dobovišek]]
* [[Roman Drnovšek]]

== F ==
* [[Joannes Disma Floriantschitsch de Grienfeld]] (1691–1757)
* [[Franc Forstnerič]]

== G ==

* [[Franc Galič]] (1929–1982)
* [[Josip Globevnik]] (1945–)
* [[Darja Govekar]]
* [[Josip Grasselli]] (1924–)
* [[Janko Gravner]]

== H ==

* [[Izidor Hafner]]
* [[Ferdinand Augustin Hallerstein]] (1703–1774)
* [[Herman of Carinthia]] (circa 1100–circa 1160) 
* [[Milan Hladnik]]
* [[Franc Hočevar]] (1853–1919)
* [[Bojan Hvala]]
* [[Dušan Hvalica]]

== I ==

* [[Stane Indihar]]

== J ==

* [[Rajko Jamnik]] (1924–1983)
* [[Fran Jeran]] (1881–1954)
* [[Aleksandar Jurišič]]
* [[Martin Juvan]]

==K ==

* [[Milan Kac]] (1924–)
* [[Sandi Klavžar]] (1962–)
* [[Igor Klep]]
* [[Andrej Kobav]] (1593–1654)
* [[Tomaž Košir]]
* [[Joahim Košutnik]] (1714–1789)
* [[Jernej Kozak]] (1946–)
* [[Edvard Kramar]]
* [[Josip Križan]] (1841–1921)
* [[France Križanič]] (1928–2002)
* [[Bogdan Krušič]]
* [[Igor Kukavica]]
* [[Klemen Kukec]] (?–1541)
* [[Karel Kunc]] (1879–1950)
* [[Ivan Kuščer]] (1918–2000)

== L ==

* [[Ivo Lah]] (1896–1979)
* [[Vito Lampret]]
* [[Boris Lavrič]]
* [[Franc Lebedinec]]
* [[Peter Legiša]] (1950–)
* [[Gorazd Lešnjak]]

==M ==

* [[Bojan Magajna]]
* [[Joze Malešič]]
* [[Aleksander Malnič]] (1954–)
* [[Dragan Marušič]] (1953–)
* [[Miklavž Mastinšek]]
* [[Blaž Matek]] (1855–1910)
* [[Josip Mazi]]
* [[Uroš Milutinović]]
* [[Pavlina Mizori–Oblak]]
* [[Štefan Močilnik]] (1928–)
* [[Franc Močnik]] (1814–1892)
* [[Bojan Mohar]]
* [[Ivan Molinaro]] (1903–1988)
* [[Nežka Mramor–Kosta]]
* [[Janez Mrčun]]

== O ==

* [[Matjaz Omladič]] (1950–)
* [[Bojan Orel]]

== P ==

* [[Dušan Pagon]] (1955–)
* [[Bernard Pergerl]] (1440–1501)
* [[Andrej Perlah]] (1490–1551)
* [[Peter Petek]] (1944–)
* [[Iztok Peterin]] (1974–)
* [[Marko Petkovšek]](1955–)
* [[Tomaž Pisanski]] (1949–)
* [[Josip Plemelj]] (1873–1967)
* [[Bor Plestenjak]]
* [[Primož Potočnik]] (1971–)
* [[Jože Povšič]] (1907–1985)
* [[Andreja Prijatelj]] (1953–2002)
* [[Niko Prijatelj]] (1922–2003)
* [[Ivan Pucelj (mathematician)|Ivan Pucelj]]

== R ==

* [[Janez Rakovec]]
* [[Marko Razpet]]
* [[Dušan Repovš]] (1954–)
* [[Viljem Rupnik]]

==S ==

* [[Oton Sajovic]] (1907–1996)
* [[Pavle Saksida]] (1960–)
* [[Janez Krstnik Schoettl]] (1724–1777)
* [[Peter Šemrl]]
* [[Marjeta Škapin-Rugelj]]
* [[Tomislav Skubic]] (1930–1996)
* [[Marko Sodnig]] (1729–1800)
* [[Ivan Štalec]] (1910–1994)
* [[Joseph Stefan|Jožef Stefan]] (1835–1893)
* [[Boštjan Steiner]] (1680–1748)
* [[Rok Strašek]] (1972–)
* [[Anton Suhadolc]]

== T ==

* [[Karl Tirnberger]] (1731–1780)
* [[Gabrijel Tomšič]]
* [[Zvonko Trontelj]]
* [[Aleksej Turnšek]]

== V ==

* [[Alojzij Vadnal]] (1910–1987)
* [[Anton Vakselj]] (1899–1987)
* [[Aleš Vavpetič]]
* [[Jurij Vega]] (1754–1802)
* [[Aleksander Vesel]]
* [[Ivan Vidav]] (1918–2015)
* [[Jože Vrabec]] (1940–)
* [[Joso Vukman]]

== Z ==

* [[Emil Žagar]]
* [[Egon Zakrajšek]] (1941–2002)
* [[Borut Zalar]]
* [[Aleš Založnik]]
* [[Matjaz Željko]]
* [[Janez Žerovnik]]
* [[Boris Zgrablič]]
* [[Milan Ziegler]]
* [[Petra Žigert]]
* [[Arjana Žitnik]]
* [[Rihard Zupančič]] (1878–1949)

==See also==
[[Mathematician]], [[Geometer]], [[List of Slovenians]].

[[Category:Lists of Slovenian people by occupation|Mathematicians]]
[[Category:Lists of mathematicians|Slovenian mathematicians]]
[[Category:Slovenian mathematicians|*List]]</text>
      <sha1>t07p1v69ukafr75vav5hn87060tfby7</sha1>
    </revision>
  </page>
  <page>
    <title>List of integrals of rational functions</title>
    <ns>0</ns>
    <id>234854</id>
    <revision>
      <id>866464427</id>
      <parentid>796455107</parentid>
      <timestamp>2018-10-30T14:08:53Z</timestamp>
      <contributor>
        <username>Skysmurf</username>
        <id>11331109</id>
      </contributor>
      <comment>/* Miscellaneous integrands */ Integration constant was omitted in one of two equivalent primitives.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="26286">The following is a list of [[integral]]s ([[antiderivative]] functions) of [[rational function]]s. 
Any rational function can be integrated by [[partial fraction decomposition]] of the function into a sum of functions of the form:
: &lt;math&gt;\frac{a}{(x-b)^n}&lt;/math&gt;, and &lt;math&gt;\frac{ax + b}{\left((x-c)^2+d^2\right)^n}.&lt;/math&gt;
which can then be integrated term by term.

For other types of functions, see [[lists of integrals]].
&lt;!--CAUTION: before 'correcting' one of these integrals, please check that the amended integral doesn't simply differ from the existing version by a constant term. NOTE: a constant *factor* in the argument of ln() may amount to a constant term in the integral. --&gt;

== Miscellaneous integrands ==

:&lt;math&gt;\int\frac{f'(x)}{f(x)} \, dx= \ln\left|f(x)\right| + C&lt;/math&gt;

:&lt;math&gt;\int\frac{1}{x^2+a^2} \, dx = \frac{1}{a}\arctan\frac{x}{a}\,\! + C&lt;/math&gt;
:&lt;math&gt;\int\frac{1}{x^2-a^2} \, dx = \begin{cases} \displaystyle -\frac{1}{a}\,\operatorname{arctanh}\frac{x}{a} + C = \frac{1}{2a}\ln\frac{a-x}{a+x} + C  &amp; \text{(for }|x| &lt; |a|\mbox{)} \\[12pt] \displaystyle -\frac{1}{a}\,\operatorname{arccoth}\frac{x}{a} + C = \frac{1}{2a}\ln\frac{x-a}{x+a} + C &amp; \text{(for }|x| &gt; |a| \mbox{)} \end{cases}&lt;/math&gt;
:&lt;math&gt;\begin{align}
\int \frac{dx}{x^{2^n} + 1} &amp;= \sum_{k=1}^{2^{n-1}} \left\{ \frac{1}{2^{n-1}} \left [ \sin \left(\frac{(2k -1) \pi}{2^n}\right) \arctan\left[\left(x - \cos \left(\frac{(2k -1) \pi}{2^n} \right) \right ) \csc \left(\frac{(2k -1) \pi}{2^n} \right) \right] \right] \right. \\
&amp;\qquad\qquad \left. - \frac{1}{2^n} \left [ \cos \left(\frac{(2k -1) \pi}{2^n} \right) \ln \left | x^2 - 2 x \cos \left(\frac{(2k -1) \pi}{2^n} \right) + 1 \right |  \right ] \right \} + C
\end{align}&lt;/math&gt;

== Integrands of the form ''x''&lt;sup&gt;''m''&lt;/sup&gt;(''a x'' + ''b'')&lt;sup&gt;''n''&lt;/sup&gt; ==

Many of the following antiderivatives have a term of the form ln |''ax'' + ''b''|.  Because this is undefined when ''x'' = −''b'' / ''a'', the most general form of the antiderivative replaces the [[constant of integration]] with a [[locally constant function]].&lt;ref&gt;"[http://golem.ph.utexas.edu/category/2012/03/reader_survey_logx_c.html Reader Survey: log|''x''| + ''C'']", Tom Leinster, ''The ''n''-category Café'', March 19, 2012&lt;/ref&gt;  However, it is conventional to omit this from the notation.  For example,
:&lt;math&gt;\int\frac{1}{ax + b} \, dx= \begin{cases}
\dfrac{1}{a}\ln(-(ax + b)) + C^- &amp; ax+b&lt;0 \\
\dfrac{1}{a}\ln(ax + b) + C^+ &amp; ax+b&gt;0
\end{cases}&lt;/math&gt;
is usually abbreviated as
:&lt;math&gt;\int\frac{1}{ax + b} \, dx= \frac{1}{a}\ln\left|ax + b\right| + C,&lt;/math&gt;
where ''C'' is to be understood as notation for a locally constant function of ''x''.  This convention will be adhered to in the following.

:&lt;math&gt;\int (ax + b)^n \, dx= \frac{(ax + b)^{n+1}}{a(n + 1)} + C \qquad\text{(for } n\neq -1\mbox{)}&lt;/math&gt; ([[Cavalieri's quadrature formula]])
:&lt;math&gt;\int\frac{x}{ax + b} \, dx= \frac{x}{a} - \frac{b}{a^2}\ln\left|ax + b\right| + C&lt;/math&gt;
:&lt;math&gt;\int\frac{x}{(ax + b)^2} \, dx= \frac{b}{a^2(ax + b)} + \frac{1}{a^2}\ln\left|ax + b\right| + C&lt;/math&gt;
:&lt;math&gt;\int\frac{x}{(ax + b)^n} \, dx= \frac{a(1 - n)x - b}{a^2(n - 1)(n - 2)(ax + b)^{n-1}} + C \qquad\text{(for } n\not\in \{1, 2\}\mbox{)}&lt;/math&gt;
:&lt;math&gt;\int x(ax + b)^n \, dx= \frac{a(n + 1)x - b}{a^2(n + 1)(n + 2)} (ax + b)^{n+1} + C \qquad\text{(for }n \not\in \{-1, -2\}\mbox{)}&lt;/math&gt;
:&lt;math&gt;\int\frac{x^2}{ax + b} \, dx= \frac{b^2\ln(\left|ax + b\right|)}{a^3}+\frac{ax^2 - 2bx}{2a^2} + C&lt;/math&gt;
:&lt;math&gt;\int\frac{x^2}{(ax + b)^2} \, dx= \frac{1}{a^3}\left(ax - 2b\ln\left|ax + b\right| - \frac{b^2}{ax + b}\right) + C&lt;/math&gt;
:&lt;math&gt;\int\frac{x^2}{(ax + b)^3} \, dx= \frac{1}{a^3}\left(\ln\left|ax + b\right| + \frac{2b}{ax + b} - \frac{b^2}{2(ax + b)^2}\right) + C&lt;/math&gt;
:&lt;math&gt;\int\frac{x^2}{(ax + b)^n} \, dx= \frac{1}{a^3}\left(-\frac{(ax + b)^{3-n}}{(n-3)} + \frac{2b (ax + b)^{2-n}}{(n-2)} - \frac{b^2 (ax + b)^{1-n}}{(n - 1)}\right) + C \qquad\text{(for } n\not\in \{1, 2, 3\}\mbox{)}&lt;/math&gt;
:&lt;math&gt;\int\frac{1}{x(ax + b)} \, dx = -\frac{1}{b}\ln\left|\frac{ax+b}{x}\right| + C&lt;/math&gt;
:&lt;math&gt;\int\frac{1}{x^2(ax+b)} \, dx = -\frac{1}{bx} + \frac{a}{b^2}\ln\left|\frac{ax+b}{x}\right| + C&lt;/math&gt;
:&lt;math&gt;\int\frac{1}{x^2(ax+b)^2} \, dx = -a\left(\frac{1}{b^2(ax+b)} + \frac{1}{ab^2x} - \frac{2}{b^3}\ln\left|\frac{ax+b}{x}\right|\right) + C&lt;/math&gt;

== Integrands of the form ''x''&lt;sup&gt;''m''&lt;/sup&gt; / (''a x''&lt;sup&gt;2&lt;/sup&gt; + ''b x'' + ''c'')&lt;sup&gt;''n''&lt;/sup&gt; ==

For &lt;math&gt;a\neq 0:&lt;/math&gt;
&lt;br&gt;
:&lt;math&gt;\int\frac{1}{ax^2+bx+c} dx =
\begin{cases}
 \displaystyle \frac{2}{\sqrt{4ac-b^2}}\arctan\frac{2ax+b}{\sqrt{4ac-b^2}} + C &amp; \text{(for }4ac-b^2&gt;0\mbox{)} \\[12pt]
\displaystyle \frac{1}{\sqrt{b^2-4ac}}\ln\left|\frac{2ax+b-\sqrt{b^2-4ac}}{2ax+b+\sqrt{b^2-4ac}}\right| + C =
\begin{cases}
\displaystyle -\frac{2}{\sqrt{b^2-4ac}}\,\operatorname{arctanh}\frac{2ax+b}{\sqrt{b^2-4ac}} + C &amp;\text{(for }|2ax+b|&lt;\sqrt{b^2-4ac}\mbox{)} \\[6pt]
\displaystyle -\frac{2}{\sqrt{b^2-4ac}}\,\operatorname{arccoth}\frac{2ax+b}{\sqrt{b^2-4ac}} + C &amp;\text{(else)}
\end{cases}
 &amp; \text{(for }4ac-b^2&lt;0\mbox{)} \\[12pt]
\displaystyle -\frac{2}{2ax+b} + C &amp; \text{(for }4ac-b^2=0\mbox{)}
\end{cases}&lt;/math&gt;
:&lt;math&gt;\int\frac{x}{ax^2+bx+c} \, dx = \frac{1}{2a}\ln\left|ax^2+bx+c\right|-\frac{b}{2a}\int\frac{dx}{ax^2+bx+c} + C&lt;/math&gt;
&lt;br&gt;
:&lt;math&gt;\int\frac{mx+n}{ax^2+bx+c} \, dx = \begin{cases}
\displaystyle \frac{m}{2a}\ln\left|ax^2+bx+c\right|+\frac{2an-bm}{a\sqrt{4ac-b^2}}\arctan\frac{2ax+b}{\sqrt{4ac-b^2}} + C &amp;\text{(for }4ac-b^2&gt;0\mbox{)} \\[12pt] \displaystyle \frac{m}{2a}\ln\left|ax^2+bx+c\right|-\frac{2an-bm}{a\sqrt{b^2-4ac}}\,\operatorname{arctanh}\frac{2ax+b}{\sqrt{b^2-4ac}} + C &amp;\text{(for }4ac-b^2&lt;0\mbox{)} \\[12pt] \displaystyle \frac{m}{2a}\ln\left|ax^2+bx+c\right|-\frac{2an-bm}{a(2ax+b)} + C &amp;\text{(for }4ac-b^2=0\mbox{)}\end{cases}&lt;/math&gt;
: &lt;math&gt;\int\frac{1}{(ax^2+bx+c)^n} \, dx= \frac{2ax+b}{(n-1)(4ac-b^2)(ax^2+bx+c)^{n-1}}+\frac{(2n-3)2a}{(n-1)(4ac-b^2)}\int\frac{1}{(ax^2+bx+c)^{n-1}} \, dx + C&lt;/math&gt;
&lt;br&gt;
: &lt;math&gt;\int\frac{x}{(ax^2+bx+c)^n} \, dx= -\frac{bx+2c}{(n-1)(4ac-b^2)(ax^2+bx+c)^{n-1}}-\frac{b(2n-3)}{(n-1)(4ac-b^2)}\int\frac{1}{(ax^2+bx+c)^{n-1}} \, dx + C&lt;/math&gt;
: &lt;math&gt;\int\frac{1}{x(ax^2+bx+c)} \, dx= \frac{1}{2c}\ln\left|\frac{x^2}{ax^2+bx+c}\right|-\frac{b}{2c}\int\frac{1}{ax^2+bx+c} \, dx + C&lt;/math&gt;

== Integrands of the form ''x''&lt;sup&gt;''m''&lt;/sup&gt; (''a'' + ''b x''&lt;sup&gt;''n''&lt;/sup&gt;)&lt;sup&gt;''p''&lt;/sup&gt; ==
* The resulting integrands are of the same form as the original integrand, so these reduction formulas can be repeatedly applied to drive the exponents ''m'' and ''p'' toward 0.
* These reduction formulas can be used for integrands having integer and/or fractional exponents.

:&lt;math&gt;
\int x^m \left(a+b\,x^n\right)^p dx = 
  \frac{x^{m+1} \left(a+b\,x^n\right)^p}{m+n\,p+1}\,+\,
  \frac{a\,n\,p}{m+n\,p+1}\int x^m \left(a+b\,x^n\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n\right)^p dx = 
  -\frac{x^{m+1} \left(a+b\,x^n\right)^{p+1}}{a\,n (p+1)}\,+\,
  \frac{m+n (p+1)+1}{a\,n (p+1)}\int x^m \left(a+b\,x^n\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n\right)^p dx =
  \frac{x^{m+1} \left(a+b\,x^n\right)^p}{m+1}\,-\,
  \frac{b\,n\,p}{m+1}\int x^{m+n} \left(a+b\,x^n\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n\right)^p dx = 
  \frac{x^{m-n+1} \left(a+b\,x^n\right)^{p+1}}{b\,n (p+1)}\,-\,
  \frac{m-n+1}{b\,n (p+1)}\int x^{m-n} \left(a+b\,x^n\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n\right)^p dx = 
  \frac{x^{m-n+1} \left(a+b\,x^n\right)^{p+1}}{b (m+n\,p+1)}\,-\,
  \frac{a (m-n+1)}{b (m+n\,p+1)}\int x^{m-n}\left(a+b\,x^n\right)^pdx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n\right)^p dx = 
  \frac{x^{m+1} \left(a+b\,x^n\right)^{p+1}}{a (m+1)}\,-\,
  \frac{b (m+n (p+1)+1)}{a (m+1)}\int x^{m+n}\left(a+b\,x^n\right)^pdx
&lt;/math&gt;

== Integrands of the form (''A'' + ''B x'') (''a'' + ''b x'')&lt;sup&gt;''m''&lt;/sup&gt; (''c'' + ''d x'')&lt;sup&gt;''n''&lt;/sup&gt; (''e'' + ''f x'')&lt;sup&gt;''p''&lt;/sup&gt; ==
* The resulting integrands are of the same form as the original integrand, so these reduction formulas can be repeatedly applied to drive the exponents ''m'', ''n'' and ''p'' toward 0.
* These reduction formulas can be used for integrands having integer and/or fractional exponents.
* Special cases of these reductions formulas can be used for integrands of the form &lt;math&gt;(a+b\,x)^m (c+d\,x)^n (e+f\,x)^p&lt;/math&gt; by setting ''B'' to 0.

:&lt;math&gt;
\int (A+B\,x) (a+b\,x)^m (c+d\,x)^n (e+f\,x)^p dx=
  -\frac{(A\,b-a\,B)(a+b\,x)^{m+1} (c+d\,x)^n(e+f\,x)^{p+1}}{b (m+1) (a\,f-b\,e)}\,+\,
  \frac{1}{b (m+1) (a\,f-b\,e)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int (b\,c(m+1) (A\,f-B\,e)+(A\,b-a\,B) (n\,d\,e+c\,f(p+1))+d(b(m+1) (A\,f-B\,e)+f(n+p+1) (A\,b-a\,B))x)(a+b\,x)^{m+1} (c+d\,x)^{n-1}(e+f\,x)^p dx
&lt;/math&gt;

:&lt;math&gt;
\int (A+B\,x) (a+b\,x)^m (c+d\,x)^n (e+f\,x)^p dx=
  \frac{B(a+b\,x)^m (c+d\,x)^{n+1}(e+f\,x)^{p+1}}{d\,f(m+n+p+2)}\,+\,
  \frac{1}{d\,f(m+n+p+2)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int (A\,a\,d\,f(m+n+p+2)-B (b\,c\,e\,m+a(d\,e(n+1)+c\,f(p+1)))+(A\,b\,d\,f(m+n+p+2)+B (a\,d\,f\,m-b(d\,e(m+n+1)+c\,f(m+p+1)))) x)(a+b\,x)^{m-1} (c+d\,x)^n(e+f\,x)^p dx
&lt;/math&gt;

:&lt;math&gt;
\int (A+B\,x) (a+b\,x)^m (c+d\,x)^n (e+f\,x)^p dx=
  \frac{(A\,b-a\,B)(a+b\,x)^{m+1} (c+d\,x)^{n+1}(e+f\,x)^{p+1}}{(m+1)(a\,d-b\,c)(a\,f-b\,e)}\,+\,
  \frac{1}{(m+1)(a\,d-b\,c)(a\,f-b\,e)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int ((m+1) (A (a\,d\,f-b(c\,f+d\,e))+B\,b\,c\,e)-(A\,b-a\,B) (d\,e(n+1)+c\,f(p+1))-d\,f(m+n+p+3) (A\,b-a\,B)x)(a+b\,x)^{m+1} (c+d\,x)^n(e+f\,x)^p dx
&lt;/math&gt;

== Integrands of the form ''x''&lt;sup&gt;''m''&lt;/sup&gt; (''A'' + ''B x''&lt;sup&gt;''n''&lt;/sup&gt;) (''a'' + ''b x''&lt;sup&gt;''n''&lt;/sup&gt;)&lt;sup&gt;''p''&lt;/sup&gt; (''c'' + ''d x''&lt;sup&gt;''n''&lt;/sup&gt;)&lt;sup&gt;''q''&lt;/sup&gt; ==
* The resulting integrands are of the same form as the original integrand, so these reduction formulas can be repeatedly applied to drive the exponents ''m'', ''p'' and ''q'' toward 0.
* These reduction formulas can be used for integrands having integer and/or fractional exponents.
* Special cases of these reductions formulas can be used for integrands of the form &lt;math&gt;\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^q&lt;/math&gt; and &lt;math&gt;x^m\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^q&lt;/math&gt; by setting ''m'' and/or ''B'' to 0.

:&lt;math&gt;
\int x^m\left(A+B\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx=
  -\frac{(A\,b-a\,B) x^{m+1} \left(a+b\,x^n\right)^{p+1} \left(c+d\,x^n\right)^q}{a\,b\,n (p+1)}\,+\,
  \frac{1}{a\,b\,n (p+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^m\left(c (A\,b\,n (p+1)+(A\,b-a\,B) (m+1))+d (A\,b\,n (p+1)+(A\,b-a\,B) (m+n\,q+1)) x^n\right)\left(a+b\,x^n\right)^{p+1}\left(c+d\,x^n\right)^{q-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(A+B\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx=
  \frac{B\,x^{m+1} \left(a+b\,x^n\right)^{p+1} \left(c+d\,x^n\right)^q}{b (m+n (p+q+1)+1)}\,+\,
  \frac{1}{b (m+n (p+q+1)+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^m\left(c ((A\,b-a\,B) (1+m)+A\,b\,n (1+p+q))+(d(A\,b-a\,B) (1+m)+B\,n\,q(b\,c-a\,d)+A\,b\,d\,n (1+p+q))\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^{q-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(A+B\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx=
  -\frac{(A\,b-a\,B) x^{m+1} \left(a+b\,x^n\right)^{p+1} \left(c+d\,x^n\right)^{q+1}}{a\,n (b\,c-a\,d) (p+1)}\,+\,
  \frac{1}{a\,n(b\,c-a\,d)(p+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^m\left(c(A\,b-a\,B)(m+1)+A\,n (b\,c-a\,d)(p+1)+d(A\,b-a\,B) (m+n (p+q+2)+1) x^n\right)\left(a+b\,x^n\right)^{p+1}\left(c+d\,x^n\right)^qdx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(A+B\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx=
  \frac{B\,x^{m-n+1} \left(a+b\,x^n\right)^{p+1} \left(c+d\,x^n\right)^{q+1}}{b\,d (m+n (p+q+1)+1)}\,-\,
  \frac{1}{b\,d (m+n (p+q+1)+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m-n}\left(a\,B\,c (m-n+1)+(a\,B\,d (m+n\,q+1)-b (-B\,c (m+n\,p+1)+A\,d (m+n (p+q+1)+1))) x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(A+B\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx=
  \frac{A\,x^{m+1} \left(a+b\,x^n\right)^{p+1} \left(c+d\,x^n\right)^{q+1}}{a\,c (m+1)}\,+\,
  \frac{1}{a\,c (m+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m+n}\left(a\,B\,c (m+1)-A (b\,c+a\,d) (m+n+1)-A\,n (b\,c\,p+a\,d\,q)-A\,b\,d (m+n (p+q+2)+1) x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(A+B\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx=
  \frac{A\,x^{m+1} \left(a+b\,x^n\right)^{p+1} \left(c+d\,x^n\right)^q}{a (m+1)}\,-\,
  \frac{1}{a (m+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m+n}\left(c(A\,b-a\,B)(m+1)+A\,n (b\,c (p+1)+a\,d\,q)+d ((A\,b-a\,B) (m+1)+A\,b\,n (p+q+1)) x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^{q-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(A+B\,x^n\right)\left(a+b\,x^n\right)^p\left(c+d\,x^n\right)^qdx=
  \frac{(A\,b-a\,B) x^{m-n+1} \left(a+b\,x^n\right)^{p+1} \left(c+d\,x^n\right)^{q+1}}{b\,n (b\,c-a\,d) (p+1)}\,-\,
  \frac{1}{b\,n(b\,c-a\,d)(p+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m-n}\left(c(A\,b-a\,B)(m-n+1)+(d(A\,b-a\,B)(m+n\,q+1)-b\,n(B\,c-A\,d)(p+1)) x^n\right)\left(a+b\,x^n\right)^{p+1}\left(c+d\,x^n\right)^qdx
&lt;/math&gt;

== Integrands of the form (''d'' + ''e x'')&lt;sup&gt;''m''&lt;/sup&gt; (''a'' + ''b x'' + ''c x''&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;''p''&lt;/sup&gt; when ''b''&lt;sup&gt;2&lt;/sup&gt; − 4 ''a c'' = 0 ==
* The resulting integrands are of the same form as the original integrand, so these reduction formulas can be repeatedly applied to drive the exponents ''m'' and ''p'' toward 0.
* These reduction formulas can be used for integrands having integer and/or fractional exponents.
* Special cases of these reductions formulas can be used for integrands of the form &lt;math&gt;\left(a+b\,x+c\,x^2\right)^p&lt;/math&gt; when &lt;math&gt;b^2-4\,a\,c=0&lt;/math&gt; by setting ''m'' to 0.

:&lt;math&gt;
\int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^{m+1} \left(a+b\,x+c\,x^2\right)^p}{e(m+1)}\,-\,
  \frac{p (d+e\,x)^{m+2}(b+2 c\,x) \left(a+b\,x+c\,x^2\right)^{p-1}}{e^2(m+1)(m+2 p+1)}\,+\,
  \frac{p(2 p-1)(2 c\,d-b\,e)}{e^2(m+1)(m+2 p+1)} \int (d+e\,x)^{m+1}\left(a+b\,x+c\,x^2\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^{m+1} \left(a+b\,x+c\,x^2\right)^p}{e(m+1)}\,-\,
  \frac{p (d+e\,x)^{m+2}(b+2\,c\,x)\left(a+b\,x+c\,x^2\right)^{p-1}}{e^2(m+1)(m+2)}\,+\,
  \frac{2\,c\,p\,(2\,p-1)}{e^2(m+1)(m+2)} \int (d+e\,x)^{m+2} \left(a+b\,x+c\,x^2\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m\left(a+b\,x+c\,x^2\right)^pdx=
  -\frac{e(m+2 p+2)(d+e\,x)^m \left(a+b\,x+c\,x^2\right)^{p+1}}{(p+1)(2p+1)(2 c\,d-b\,e)}\,+\,
  \frac{(d+e\,x)^{m+1}(b+2 c\,x) \left(a+b\,x+c\,x^2\right)^p}{(2p+1)(2 c\,d-b\,e)}\,+\,
  \frac{e^2m(m+2 p+2)}{(p+1)(2p+1)(2 c\,d-b\,e)} \int (d+e\,x)^{m-1} \left(a+b\,x+c\,x^2\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^pdx=
  -\frac{e\,m(d+e\,x)^{m-1} \left(a+b\,x+c\,x^2\right)^{p+1}}{2c (p+1) (2p+1)}\,+\,
  \frac{(d+e\,x)^m(b+2 c\,x)\left(a+b\,x+c\,x^2\right)^p}{2c (2p+1)}\,+\,
  \frac{e^2m(m-1)}{2c (p+1) (2p+1)} \int (d+e\,x)^{m-2} \left(a+b\,x+c\,x^2\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^{m+1} \left(a+b\,x+c\,x^2\right)^p}{e(m+2p+1)}\,-\,
  \frac{p(2 c\,d-b\,e)(d+e\,x)^{m+1}(b+2 c\,x)\left(a+b\,x+c\,x^2\right)^{p-1}}{2c\,e^2(m+2 p)(m+2p+1)}\,+\,
  \frac{p (2 p-1)(2 c\,d-b\,e)^2}{2c\,e^2(m+2 p)(m+2p+1)} \int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^pdx=
  -\frac{2c\,e(m+2p+2)(d+e\,x)^{m+1} \left(a+b\,x+c\,x^2\right)^{p+1}}{(p+1) (2 p+1)(2 c\,d-b\,e)^2}\,+\,
  \frac{(d+e\,x)^{m+1}(b+2 c\,x)\left(a+b\,x+c\,x^2\right)^p}{(2 p+1)(2 c\,d-b\,e)}\,+\,
  \frac{2c\,e^2(m+2p+2)(m+2 p+3)}{(p+1) (2 p+1)(2 c\,d-b\,e)^2} \int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^m (b+2 c\,x)\left(a+b\,x+c\,x^2\right)^p}{2c (m+2p+1)}\,+\,
  \frac{m(2 c\,d-b\,e)}{2c (m+2p+1)} \int (d+e\,x)^{m-1}\left(a+b\,x+c\,x^2\right)^pdx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m\left(a+b\,x+c\,x^2\right)^pdx=
  -\frac{(d+e\,x)^{m+1} (b+2 c\,x)\left(a+b\,x+c\,x^2\right)^p}{(m+1)(2 c\,d-b\,e)}\,+\,
  \frac{2c (m+2p+2)}{(m+1)(2 c\,d-b\,e)} \int (d+e\,x)^{m+1} \left(a+b\,x+c\,x^2\right)^pdx
&lt;/math&gt;

== Integrands of the form (''d'' + ''e x'')&lt;sup&gt;''m''&lt;/sup&gt; (''A'' + ''B x'') (''a'' + ''b x'' + ''c x''&lt;sup&gt;2&lt;/sup&gt;)&lt;sup&gt;''p''&lt;/sup&gt; ==
* The resulting integrands are of the same form as the original integrand, so these reduction formulas can be repeatedly applied to drive the exponents ''m'' and ''p'' toward 0.
* These reduction formulas can be used for integrands having integer and/or fractional exponents.
* Special cases of these reductions formulas can be used for integrands of the form &lt;math&gt;\left(a+b\,x+c\,x^2\right)^p&lt;/math&gt; and &lt;math&gt;(d+e\,x)^m \left(a+b\,x+c\,x^2\right)^p&lt;/math&gt; by setting ''m'' and/or ''B'' to 0.

:&lt;math&gt;
\int (d+e\,x)^m (A+B\,x) \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^{m+1} (A\,e (m+2 p+2)-B\,d (2 p+1)+e\,B (m+1) x) \left(a+b\,x+c\,x^2\right)^p}{e^2(m+1) (m+2 p+2)}\,+\,
  \frac{1}{e^2(m+1) (m+2 p+2)}p\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int (d+e\,x)^{m+1} (B (b\,d+2 a\,e+2 a\,e\,m+2 b\,d\,p)-A\,b\,e (m+2 p+2)+(B (2 c\,d+b\,e+b\,e m+4 c\,d\,p)-2 A\,c\,e (m+2 p+2))x)\left(a+b\,x+c\,x^2\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m (A+B\,x) \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^m (A\,b-2 a\,B-(b\,B-2 A\,c) x)\left(a+b\,x+c\,x^2\right)^{p+1}}{(p+1)\left(b^2-4 a\,c\right) }\,+\,
  \frac{1}{(p+1)\left(b^2-4 a\,c\right) }\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int (d+e\,x)^{m-1}(B (2 a\,e\,m+b\,d (2 p+3))-A (b\,e\,m+2 c\,d (2 p+3))+e(b\,B-2 A\,c) (m+2 p+3) x)\left(a+b\,x+c\,x^2\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m (A+B\,x) \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^{m+1} (A\,c\,e (m+2 p+2)-B (c\,d+2 c\,d\,p-b\,e\,p)+B\,c\,e(m+2 p+1) x)\left(a+b\,x+c\,x^2\right)^p}{c\,e^2(m+2 p+1) (m+2 p+2)}\,-\,
  \frac{p}{c\,e^2(m+2 p+1) (m+2 p+2)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int (d+e\,x)^m (A\,c\,e (b\,d-2 a\,e) (m+2 p+2)+B (a\,e (b\,e-2 c\,d\,m+b\,e\,m)+b\,d (b\,e\,p-c\,d-2 c\,d\,p))+
&lt;/math&gt;

:::&lt;math&gt;
  \left(A\,c\,e (2 c\,d-b\,e) (m+2 p+2)-B \left(-b^2 e^2 (m+p+1)+2 c^2 d^2 (1+2 p)+c\,e (b\,d (m-2 p)+2 a\,e (m+2 p+1))\right)\right) x)\left(a+b\,x+c\,x^2\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m (A+B\,x) \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{(d+e\,x)^{m+1} \left(A \left(b\,c\,d-b^2 e+2 a\,c\,e\right)-a\,B (2 c\,d-b\,e)+c (A (2 c\,d-b\,e)-B (b\,d-2 a\,e)) x\right)\left(a+b\,x+c\,x^2\right)^{p+1}}{(p+1)\left(b^2-4 a\,c\right) \left(c\,d^2-b\,d\,e+a\,e^2\right)}\,+
&lt;/math&gt;

::&lt;math&gt;
  \frac{1}{(p+1)\left(b^2-4 a\,c\right) \left(c\,d^2-b\,d\,e+a\,e^2\right)}\,\cdot
&lt;/math&gt;

:::&lt;math&gt;
  \int (d+e\,x)^m (A \left(b\,c\,d\,e (2 p-m+2)+b^2 e^2 (m+p+2)-2 c^2 d^2 (3+2 p)-2 a\,c\,e^2 (m+2 p+3)\right)-
&lt;/math&gt;

::::&lt;math&gt;
  B (a\,e (b\,e-2 c\,d m+b\,e\,m)+b\,d (-3 c\,d+b\,e-2 c\,d\,p+b\,e\,p))+c\,e(B (b\,d-2 a\,e)-A (2 c\,d-b\,e)) (m+2 p+4) x)\left(a+b\,x+c\,x^2\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m (A+B\,x) \left(a+b\,x+c\,x^2\right)^pdx=
  \frac{B(d+e\,x)^m\left(a+b\,x+c\,x^2\right)^{p+1}}{c(m+2 p+2)}\,+\,
  \frac{1}{c(m+2 p+2)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int (d+e\,x)^{m-1} (m(A\,c\,d-a\,B\,e)-d(b\,B-2 A\,c)(p+1) +((B\,c\,d-b\,B\,e+A\,c\,e) m-e(b\,B-2 A\,c)(p+1))x) \left(a+b\,x+c\,x^2\right)^pdx
&lt;/math&gt;

:&lt;math&gt;
\int (d+e\,x)^m (A+B\,x) \left(a+b\,x+c\,x^2\right)^pdx=
  -\frac{(B\,d-A\,e) (d+e\,x)^{m+1} \left(a+b\,x+c\,x^2\right)^{p+1}}{(m+1)\left(c\,d^2-b\,d\,e+a\,e^2\right)}\,+\,
  \frac{1}{(m+1)\left(c\,d^2-b\,d\,e+a\,e^2\right)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int (d+e\,x)^{m+1} ((A\,c\,d-A\,b\,e+a\,B\,e) (m+1)+b (B\,d-A\,e) (p+1)+c (B\,d-A\,e) (m+2 p+3) x)\left(a+b\,x+c\,x^2\right)^pdx
&lt;/math&gt;

== Integrands of the form ''x''&lt;sup&gt;''m''&lt;/sup&gt; (''a'' + ''b x''&lt;sup&gt;''n''&lt;/sup&gt; + ''c x''&lt;sup&gt;2''n''&lt;/sup&gt;)&lt;sup&gt;''p''&lt;/sup&gt; when ''b''&lt;sup&gt;2&lt;/sup&gt; − 4 ''a c'' = 0 ==
* The resulting integrands are of the same form as the original integrand, so these reduction formulas can be repeatedly applied to drive the exponents ''m'' and ''p'' toward 0.
* These reduction formulas can be used for integrands having integer and/or fractional exponents.
* Special cases of these reductions formulas can be used for integrands of the form &lt;math&gt;\left(a+b\,x^n+c\,x^{2 n}\right)^p&lt;/math&gt; when &lt;math&gt;b^2-4\,a\,c=0&lt;/math&gt; by setting ''m'' to 0.

:&lt;math&gt;
\int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  \frac{ x^{m+1}\left(a+b\,x^n+c\,x^{2 n}\right)^p}{m+2 n\,p+1}\,+\,
  \frac{n\,p\,x^{m+1} \left(2 a+b\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}}{(m+1)(m+2 n\,p+1)}\,-\,
  \frac{b\,n^2 p (2 p-1)}{(m+1)(m+2 n\,p+1)} \int x^{m+n} \left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  \frac{(m+n(2 p-1)+1) x^{m+1}\left(a+b\,x^n+c\,x^{2 n}\right)^p}{(m+1)(m+n+1)}\,+\,
  \frac{n\,p\,x^{m+1} \left(2 a+b\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}}{(m+1)(m+n+1)}\,+\,
  \frac{2 c\,p\,n^2(2 p-1)}{(m+1)(m+n+1)} \int x^{m+2n} \left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  \frac{(m+n(2 p+1)+1) x^{m-n+1}\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}}{b\,n^2 (p+1) (2p+1)}\,-\,
  \frac{x^{m+1} \left(b+2 c\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^p}{b\,n (2p+1)}\,-\,
  \frac{(m-n+1)(m+n(2 p+1)+1)}{b\,n^2 (p+1) (2p+1)} \int x^{m-n} \left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  -\frac{(m-3 n-2 n\,p+1) x^{m-2n+1}\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}}{2 c\,n^2(p+1)(2p+1)}\,-\,
  \frac{ x^{m-2n+1} \left(2 a+b\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^p}{2 c\,n(2p+1)}\,+\,
  \frac{(m-n+1)(m-2n+1)}{2 c\,n^2(p+1)(2p+1)} \int x^{m-2n} \left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  \frac{x^{m+1}\left(a+b\,x^n+c\,x^{2 n}\right)^p}{m+2 n\,p+1}\,+\,
  \frac{n\,p\,x^{m+1} \left(2 a+b\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}}{(m+2 n\,p+1) (m+n(2 p-1)+1)}\,+\,
  \frac{2 a\,n^2 p (2 p-1)}{(m+2 n\,p+1) (m+n(2 p-1)+1)} \int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  -\frac{(m+n+2 n\,p+1) x^{m+1}\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}}{2 a\,n^2 (p+1) (2p+1)}\,-\,
  \frac{x^{m+1} \left(2 a+b\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^p}{2 a\,n(2p+1)}\,+\,
  \frac{(m+n(2 p+1)+1)(m+2 n (p+1)+1)}{2 a\,n^2 (p+1) (2p+1)} \int x^m \left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  \frac{x^{m-n+1} \left(b+2c\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^p}{2c (m+2n\,p+1)}\,-\,
  \frac{b (m-n+1)}{2c (m+2n\,p+1)} \int x^{m-n} \left(a+b\,x^n+c\,x^{2 n}\right)^p dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m\left(a+b\,x^n+c\,x^{2 n}\right)^p dx=
  \frac{x^{m+1} \left(b+2c\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^p}{b (m+1)}\,-\,
  \frac{2c (m+n(2 p+1)+1)}{b (m+1)} \int x^{m+n} \left(a+b\,x^n+c\,x^{2 n}\right)^p dx
&lt;/math&gt;

== Integrands of the form ''x''&lt;sup&gt;''m''&lt;/sup&gt; (''A'' + ''B x''&lt;sup&gt;''n''&lt;/sup&gt;) (''a'' + ''b x''&lt;sup&gt;''n''&lt;/sup&gt; + ''c x''&lt;sup&gt;2''n''&lt;/sup&gt;)&lt;sup&gt;''p''&lt;/sup&gt; ==
* The resulting integrands are of the same form as the original integrand, so these reduction formulas can be repeatedly applied to drive the exponents ''m'' and ''p'' toward 0.
* These reduction formulas can be used for integrands having integer and/or fractional exponents.
* Special cases of these reductions formulas can be used for integrands of the form &lt;math&gt;\left(a+b\,x^n+c\,x^{2 n}\right)^p&lt;/math&gt; and &lt;math&gt;x^m \left(a+b\,x^n+c\,x^{2 n}\right)^p&lt;/math&gt; by setting ''m'' and/or ''B'' to 0.

:&lt;math&gt;
\int x^m \left(A+B\,x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^pdx=
  \frac{x^{m+1} \left(A (m+n (2 p+1)+1)+B (m+1) x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^p}{(m+1) (m+n (2 p+1)+1)}\,+\,
  \frac{n\,p}{(m+1) (m+n (2 p+1)+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m+n} \left(2 a\,B (m+1)-A\,b (m+n (2 p+1)+1)+(b\,B (m+1)-2\,A\,c (m+n (2 p+1)+1)) x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
 \int x^m \left(A+B\,x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^pdx=
  \frac{x^{m-n+1} \left(A\,b-2 a\,B-(b\,B-2 A\,c) x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}}{n(p+1) \left(b^2-4 a\,c\right)}\,+\,
  \frac{1}{n(p+1) \left(b^2-4 a\,c\right)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m-n}\left((m-n+1)(2 a\,B-A\,b)+(m+2n (p+1)+1) (b\,B-2 A\,c) x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(A+B\,x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^pdx=
  \frac{x^{m+1} \left(b\,B\,n\,p+A\,c (m+n (2 p+1)+1)+B\,c (m+2 n\,p+1) x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^p}{c (m+2 n\,p+1) (m+n (2 p+1)+1)}\,+\,
  \frac{n\,p}{c (m+2 n\,p+1) (m+n (2 p+1)+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^m \left(2 a\,A\,c (m+n (2 p+1)+1)-a\,b\,B (m+1)+\left(2 a\,B\,c (m+2 n\,p+1)+A\,b\,c (m+n (2 p+1)+1)-b^2 B (m+n\,p+1)\right) x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p-1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(A+B\,x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^pdx=
  -\frac{x^{m+1} \left(A\,b^2-a\,b\,B-2 a\,A\,c+(A\,b-2 a\,B) c\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}}{a\,n(p+1) \left(b^2-4 a\,c\right)}\,+\,
  \frac{1}{a\,n(p+1) \left(b^2-4 a\,c\right)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^m \left((m+n (p+1)+1) A\,b^2-a\,b\,B(m+1)-2(m+2n (p+1)+1)a\,A\,c+(m+n (2p+3)+1)(A\,b-2 a\,B) c\,x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}dx
&lt;/math&gt;

:&lt;math&gt;
\int x^m \left(A+B\,x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^pdx=
  \frac{B\,x^{m-n+1}\left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}}{c (m+n (2 p+1)+1)}\,-\,
  \frac{1}{c (m+n (2 p+1)+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m-n} \left(a\,B (m-n+1)+(b\,B (m+n\,p+1)-A\,c (m+n (2 p+1)+1)) x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^pdx
&lt;/math&gt;&lt;/ul&gt;&lt;/ul&gt;

:&lt;math&gt;
\int x^m \left(A+B\,x^n\right) \left(a+b\,x^n+c\,x^{2 n}\right)^pdx=
  \frac{A\,x^{m+1} \left(a+b\,x^n+c\,x^{2 n}\right)^{p+1}}{a(m+1)}\,+\,
  \frac{1}{a(m+1)}\,\cdot
&lt;/math&gt;

::&lt;math&gt;
  \int x^{m+n} \left(a\,B (m+1)-A\,b (m+n (p+1)+1)-A\,c (m+2 n(p+1)+1) x^n\right)\left(a+b\,x^n+c\,x^{2 n}\right)^pdx
&lt;/math&gt;

== References ==
{{reflist}}

{{Lists of integrals}}

[[Category:Integrals|Rational functions]]
[[Category:Mathematics-related lists|Integrals of rational functions]]</text>
      <sha1>7bf970fhwvs44kq4btth2r7wm43uc6n</sha1>
    </revision>
  </page>
  <page>
    <title>Ludwig Schlesinger</title>
    <ns>0</ns>
    <id>26826869</id>
    <revision>
      <id>842800473</id>
      <parentid>842751161</parentid>
      <timestamp>2018-05-24T18:58:43Z</timestamp>
      <contributor>
        <username>BrownHairedGirl</username>
        <id>754619</id>
      </contributor>
      <minor/>
      <comment>remove [[:Category:Jewish mathematicians]]. [[WP:G4]] per [[:WP:Categories for discussion/Log/2007 May 14#Category:Jewish_mathematicians]] using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5510">{{Infobox scholar
| image            = Ludwig Schlesinger.jpg
| image_size       = 
| alt              = 
| caption          = 
| name             = Ludwig Schlesinger
| fullname         = 
| other_names      = Lajos Schlesinger
| birth_date       = {{Birth date|1864|11|01}}
| birth_place      = [[Trnava]]
| death_date       =  {{Death date and age|1933|12|15|1864|11|01}}
| death_place      = [[Giessen]]
| era              = 
| region           = 
| school_tradition = 
| main_interests   = 
| notable_ideas    = 
| major_works      = 
| influences       = 
| influenced       = 
}}
'''Ludwig Schlesinger''' (Hungarian: Lajos Schlesinger, Slovak Ľudovít Schlesinger), (1 November 1864 &amp;ndash; 15 December 1933) was a [[Germans|German]] [[mathematician]] known for the research in the field of [[linear differential equation]]s.&lt;ref&gt;Gottwald, Ilgauds, Schlote ''Lexikon bedeutender Mathematiker'', Bibliographisches Institut, Leipzig 1990&lt;/ref&gt;

==Biography==
Schlesinger attended the high school in [[Bratislava]] and later studied physics and mathematics in [[Heidelberg]] and [[Berlin]]. In 1887 he received his PhD (Über lineare homogene Differentialgleichungen vierter Ordnung, zwischen deren Integralen homogene Relationen höheren als ersten Grades bestehen.) His thesis advisors were [[Lazarus Immanuel Fuchs]] and [[Leopold Kronecker]]. In 1889 he became an associate professor at Berlin; in 1897 an invited professor in [[Bonn]] and in the same year, a full professor at the [[University of Kolozsvár]], [[Hungary]] (now Cluj, Romania). From 1911 he was professor at the [[University of Giessen]], where he taught until 1930. In 1933 he was forced to retire by the [[Nazis]]. He died shortly afterwards.

Schlesinger was a [[historian of science]]. He wrote an article on the [[Complex analysis|function theory]] of [[Carl Friedrich Gauss]] and translated [[René Descartes]]' ''[[La Géométrie]]'' into German (1894). He was one of the organizers of the celebrations for the hundredth anniversary of [[János Bolyai]] and from 1904 to 1909 with R. Fuchs he collected the works of his teacher Lazarus Fuchs, who was also his father-in-law. In 1902 he became a corresponding member of the [[Hungarian Academy of Sciences]]. In 1909 he received the [[Lobachevsky Prize]].&lt;ref&gt;http://www.math.wsu.edu/faculty/slapin/research/presentations/Lobachevsky.pdf&lt;/ref&gt;

From 1929 until his death he was co-editor of ''[[Crelle's Journal]]''.

Like his teacher Fuchs, he worked primarily on linear [[ordinary differential equations]]. His two-volume ''Handbuch der Theorie der Linearen Differentialgleichungen'' was published from 1895 to 1898 in Teubner in Leipzig (Vol.2 in two parts).&lt;ref&gt;{{cite journal|author=Bôcher, Maxime|authorlink=Maxime Bôcher|title=Review: ''Handbuch der Theorie der Linearen Differentialgleichungen'', by Ludwig Schlesinger|journal=Bull. Amer. Math. Soc.|year=1897|volume=3|issue=4|pages=146–153|url=http://www.ams.org/journals/bull/1897-03-04/S0002-9904-1897-00387-1/|doi=10.1090/s0002-9904-1897-00387-1}}&lt;/ref&gt; He also published ''Einführung in die Theorie der gewöhnlichen Differentialgleichungen auf funktionentheoretischer Grundlage'' (Auflage, 1922), ''Vorlesungen über lineare Differentialgleichungen'' (1908)&lt;ref&gt;{{cite journal|author=Wilczynski, E. J.|authorlink=Ernest Julius Wilczynski|title=Review: ''Vorlesungen über lineare Differentialgleichungen'', by Ludwig Schlesinger|journal=Bull. Amer. Math. Soc.|year=1910|volume=16|issue=9|pages=483–489|url=http://www.ams.org/journals/bull/1910-16-09/S0002-9904-1910-01948-0/|doi=10.1090/s0002-9904-1910-01948-0}}&lt;/ref&gt; and ''Automorphe Funktionen'' (Gruyter, 1924). In 1909 he wrote a long report for the annual report of the German Mathematical Society on the history of linear differential equations since 1865. He also studied differential geometry, and wrote a book of lectures on [[Einstein]]'s [[general relativity theory]].

Today, his best known work is ''Über eine Klasse von Differentialsystemen beliebiger Ordnung mit festen kritischen Punkten'' (Crelle's Journal, 1912). There he considered the problem of [[isomonodromy deformation]]s for a certain matrix [[Regular singular point|Fuchsian equation]]; this is a special case of [[Hilbert's 21st Problem]] (existence of differential equations with prescribed monodromy). The paper introduced what are today called Schlesinger transformations and [[Schlesinger equations]].

==References ==
{{reflist}}

==External links ==
The article was created as a translation (by Google) of the corresponding article in [[German Wikipedia]].
* [https://web.archive.org/web/20160303215839/https://portal.d-nb.de/opac.htm?query=Woe%3D117326259&amp;method=simpleSearch Literatur von und über Ludwig Schlesinger] in [[German National Library]].
* {{MacTutor Biography|id=Schlesinger}}
* {{MathGenealogy|id=47610}}

{{authority control}}

{{DEFAULTSORT:Schlesinger, Ludwig}}
[[Category:1864 births]]
[[Category:1933 deaths]]
[[Category:18th-century Hungarian people]]
[[Category:19th-century Hungarian people]]
[[Category:19th-century German people]]
[[Category:German mathematicians]]
[[Category:Hungarian mathematicians]]
[[Category:Historians of mathematics]]
[[Category:German people of Hungarian-Jewish descent]]
[[Category:People from Trnava]]
[[Category:Franz Joseph University faculty]]
[[Category:Heidelberg University alumni]]
[[Category:University of Bonn faculty]]
[[Category:University of Giessen faculty]]
[[Category:Austro-Hungarian mathematicians]]</text>
      <sha1>7gg2rxhxcpimlbmyxejt0qyeo62za66</sha1>
    </revision>
  </page>
  <page>
    <title>Naimark's dilation theorem</title>
    <ns>0</ns>
    <id>5173642</id>
    <revision>
      <id>861926596</id>
      <parentid>785961423</parentid>
      <timestamp>2018-10-01T01:05:53Z</timestamp>
      <contributor>
        <username>Mcoupal</username>
        <id>8519392</id>
      </contributor>
      <comment>/* Some preliminary notions */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7484">In [[operator theory]], '''[[Mark Naimark|Naimark]]'s dilation theorem''' is a result that characterizes [[POVM|positive operator valued measures]]. It can be viewed as a consequence of [[Stinespring factorization theorem|Stinespring's dilation theorem]].

== Note ==

In the mathematical literature, one may also find other results that bear Naimark's name.

==Spelling==
In the physics literature, it is common to see the spelling “Neumark” instead of “Naimark.” The latter variant is according to the [[romanization of Russian]] used in translation of Soviet journals, with diacritics omitted (originally Naĭmark). The former is according to the etymology of the surname.

== Some preliminary notions ==

Let ''X'' be a [[Compact space|compact]] [[Hausdorff space]], ''H'' be a [[Hilbert space]], and ''L(H)'' the [[Banach space]] of [[bounded operator]]s on ''H''. A mapping ''E'' from the [[Borel σ-algebra]] on ''X'' to &lt;math&gt;L(H)&lt;/math&gt; is called an '''operator-valued measure''' if it is weakly countably additive, that is, for any disjoint sequence of Borel sets &lt;math&gt;\{ B_i \}&lt;/math&gt;, we have

:&lt;math&gt;
\langle E (\cup _i B_i) x, y \rangle = \sum_i \langle E (B_i) x, y \rangle 
&lt;/math&gt;

for all ''x'' and ''y''. Some terminology for describing such measures are:

* ''E'' is called ''regular'' if the scalar valued measure

:&lt;math&gt;
B \rightarrow \langle E (B) x, y \rangle 
&lt;/math&gt;

is a regular Borel measure, meaning all compact sets have finite total variation and the measure of a set can be approximated by those of open sets.

* ''E'' is called ''bounded'' if &lt;math&gt;|E| = \sup_B \|E(B) \| &lt; \infty&lt;/math&gt;.
* ''E'' is called ''positive'' if ''E(B)'' is a positive operator for all ''B''.
* ''E'' is called ''self-adjoint '' if ''E(B)'' is self-adjoint for all ''B''.
* ''E'' is called ''spectral'' if it is self-adjoint and &lt;math&gt;E (B_1 \cap B_2) = E(B_1) E(B_2)&lt;/math&gt; for all &lt;math&gt; B_1, B_2 &lt;/math&gt;.

We will assume throughout that ''E'' is regular.

Let ''C(X)'' denote the abelian C*-algebra of continuous functions on ''X''. If ''E'' is regular and bounded, it induces a map &lt;math&gt;\Phi _E : C(X) \rightarrow L(H)&lt;/math&gt; in the obvious way:

:&lt;math&gt;\langle \Phi _E (f) h_1 , h_2 \rangle = \int _X f(x) \langle E(dx) h_1, h_2 \rangle&lt;/math&gt;

The boundedness of ''E'' implies, for all ''h'' of unit norm

:&lt;math&gt;
\langle \Phi _E (f) h , h \rangle = \int _X f(x)  \langle E(dx) h, h \rangle \leq \| f \|_\infty \cdot |E| .
&lt;/math&gt;

This shows &lt;math&gt;\; \Phi _E (f)&lt;/math&gt; is a bounded operator for all ''f'', and &lt;math&gt;\Phi _E&lt;/math&gt; itself is a bounded linear map as well.

The properties of &lt;math&gt;\Phi_E&lt;/math&gt; are directly related to those of ''E'':

* If ''E'' is positive, then &lt;math&gt;\Phi_E&lt;/math&gt;, viewed as a map between C*-algebras, is also positive.
* &lt;math&gt;\Phi_E&lt;/math&gt; is a homomorphism if, by definition, for all continuous ''f'' on ''X'' and &lt;math&gt;h_1, h_2 \in H&lt;/math&gt;,

:&lt;math&gt;
\langle \Phi_E (fg) h_1, h_2 \rangle = \int _X f(x) \cdot g(x) \; \langle E(dx) h_1, h_2 \rangle 
= \langle \Phi_E (f) \Phi_E (g) h_1 , h_2 \rangle.
&lt;/math&gt;

Take ''f'' and ''g'' to be indicator functions of Borel sets and we see that &lt;math&gt;\Phi _E&lt;/math&gt; is a homomorphism if and only if ''E'' is spectral.

* Similarly, to say &lt;math&gt;\Phi_E&lt;/math&gt; respects the * operation means

:&lt;math&gt;
\langle \Phi_E ( {\bar f} ) h_1, h_2 \rangle = \langle \Phi_E (f) ^* h_1 , h_2 \rangle.
&lt;/math&gt;

The LHS is

:&lt;math&gt; 
\int _X {\bar f} \; \langle E(dx) h_1, h_2 \rangle,
&lt;/math&gt;

and the RHS is

:&lt;math&gt; 
\langle h_1, \Phi_E (f) h_2 \rangle = \overline{\langle \Phi_E(f) h_2, h_1 \rangle} = \int _X {\bar f}(x) \; \overline{\langle E(dx) h_2, h_1 \rangle} =  \int _X {\bar f}(x) \; \langle h_1, E(dx) h_2 \rangle
&lt;/math&gt;

So, taking f a sequence of continuous functions increasing to the indicator function of ''B'', we get &lt;math&gt;\langle E(B) h_1, h_2 \rangle = \langle h_1, E(B) h_2 \rangle&lt;/math&gt;, i.e. ''E(B)'' is self adjoint.

* Combining the previous two facts gives the conclusion that &lt;math&gt;\Phi _E&lt;/math&gt; is a *-homomorphism if and only if ''E'' is spectral and self adjoint. (When ''E'' is spectral and self adjoint, ''E'' is said to be a [[projection-valued measure]] or PVM.)

== Naimark's theorem ==

The theorem reads as follows: Let ''E'' be a positive ''L(H)''-valued measure on ''X''. There exists a Hilbert space ''K'', a bounded operator &lt;math&gt;V: K \rightarrow H&lt;/math&gt;, and a self-adjoint, spectral ''L(K)''-valued measure on ''X'', ''F'', such that

:&lt;math&gt;\; E(B) = V F(B) V^*.&lt;/math&gt;

=== Proof ===

We now sketch the proof. The argument passes ''E'' to the induced map &lt;math&gt;\Phi_E&lt;/math&gt; and uses [[Stinespring factorization theorem|Stinespring's dilation theorem]]. Since ''E'' is positive, so is &lt;math&gt;\Phi_E&lt;/math&gt; as a map between C*-algebras, as explained above. Furthermore, because the domain of &lt;math&gt;\Phi _E&lt;/math&gt;, ''C(X)'', is an abelian C*-algebra, we have that &lt;math&gt;\Phi_E&lt;/math&gt; is [[Choi's theorem on completely positive maps|completely positive]]. By Stinespring's result, there exists a Hilbert space ''K'', a *-homomorphism &lt;math&gt;\pi : C(X) \rightarrow L(K)&lt;/math&gt;, and operator &lt;math&gt;V: K \rightarrow H&lt;/math&gt; such that

:&lt;math&gt;\; \Phi_E(f) = V \pi (f) V^*.&lt;/math&gt;

Since π is a *-homomorphism, its corresponding operator-valued measure ''F'' is spectral and self adjoint. It is easily seen that ''F'' has the desired properties.

== Finite-dimensional case ==

In the finite-dimensional case, there is a somewhat more explicit formulation.

Suppose now &lt;math&gt;X = \{1, \dotsc, n \}&lt;/math&gt;, therefore ''C''(''X'') is the finite-dimensional algebra &lt;math&gt;\mathbb{C}^n&lt;/math&gt;, and ''H'' has finite dimension ''m''. A positive operator-valued measure ''E'' then assigns each ''i'' a positive semidefinite ''m'' &amp;times; ''m'' matrix &lt;math&gt;E_i&lt;/math&gt;. Naimark's theorem now states that there is a projection-valued measure on ''X'' whose restriction is ''E''.

Of particular interest is the special case when &lt;math&gt;\sum_i E_i = I&lt;/math&gt; where ''I'' is the identity operator. (See the article on [[POVM]] for relevant applications.) In this case, the induced map &lt;math&gt;\Phi_E&lt;/math&gt; is unital. It can be assumed with no loss of generality that each &lt;math&gt;E_i&lt;/math&gt; is a rank-one projection onto some &lt;math&gt;x_i \in \mathbb{C}^m&lt;/math&gt;. Under such assumptions, the case &lt;math&gt;n &lt; m&lt;/math&gt; is excluded and we must have either
# &lt;math&gt;n = m&lt;/math&gt; and ''E'' is already a projection-valued measure (because &lt;math&gt;\sum_{i=1}^n x_i x_i^* = I&lt;/math&gt; if and only if &lt;math&gt;\{x_i\}&lt;/math&gt; is an orthonormal basis),
# &lt;math&gt;n &gt; m&lt;/math&gt; and &lt;math&gt;\{ E_i \}&lt;/math&gt; does not consist of mutually orthogonal projections.
For the second possibility, the problem of finding a suitable projection-valued measure now becomes the following problem. By assumption, the non-square matrix
:&lt;math&gt; M = \begin{bmatrix} x_1 \cdots x_n \end{bmatrix}&lt;/math&gt;
is an isometry, that is &lt;math&gt;M M^* = I&lt;/math&gt;. If we can find a &lt;math&gt;(n-m) \times n&lt;/math&gt; matrix ''N'' where
:&lt;math&gt;U = \begin{bmatrix} M \\ N \end{bmatrix}&lt;/math&gt;
is a ''n'' &amp;times; ''n'' unitary matrix, the projection-valued measure whose elements are projections onto the column vectors of ''U'' will then have the desired properties. In principle, such a ''N'' can always be found.

==References==

*V. Paulsen, ''Completely Bounded Maps and Operator Algebras'', Cambridge University Press, 2003.

[[Category:Operator theory]]
[[Category:Measure theory]]
[[Category:Theorems in functional analysis]]</text>
      <sha1>r8labr34d8tpwhd9qklcc06ahe6cu49</sha1>
    </revision>
  </page>
  <page>
    <title>Negative-dimensional space</title>
    <ns>0</ns>
    <id>47077309</id>
    <revision>
      <id>852398528</id>
      <parentid>809747562</parentid>
      <timestamp>2018-07-28T18:29:41Z</timestamp>
      <contributor>
        <username>Lamro</username>
        <id>3636441</id>
      </contributor>
      <comment>,</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3890">In [[topology]], a discipline within mathematics, a '''negative-dimensional space''' is an extension of the usual notion of space, allowing for negative [[dimension]]s.&lt;ref&gt;{{cite conference|
first1=Luke|last1=Wolcott|first2=Elizabeth|last2=McTernan|
title=Imagining Negative-Dimensional Space|
pages=637–642|
book-title=Proceedings of Bridges 2012: Mathematics, Music, Art, Architecture, Culture|
year=2012|
editor-first1=Robert|editor-last1=Bosch|editor-first2=Douglas|editor-last2=McKenna|editor-first3=Reza|editor-last3=Sarhangi|
isbn=978-1-938664-00-7|
issn=1099-6702|
publisher=Tessellations Publishing|
location=Phoenix, Arizona, USA|
url=http://bridgesmathart.org/2012/cdrom/proceedings/65/paper_65.pdf|accessdate=25 June 2015
}}&lt;/ref&gt;

==Definition==
Suppose that {{math|''M''&lt;sub&gt;''t''&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;}} is a [[compact space]] of [[Hausdorff dimension]] {{math|''t''&lt;sub&gt;0&lt;/sub&gt;}}, which is an element of a scale of compact spaces embedded in each other and parametrized by {{math|''t''}} ({{math|0 &lt; ''t'' &lt; ∞}}). Such scales are considered ''equivalent'' with respect to {{math|''M''&lt;sub&gt;''t''&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;}} if the compact spaces constituting them coincide for {{math|''t'' ≥ ''t''&lt;sub&gt;0&lt;/sub&gt;}}. It is said that the compact space {{math|''M''&lt;sub&gt;''t''&lt;sub&gt;0&lt;/sub&gt;&lt;/sub&gt;}} is the ''hole'' in this equivalent set of scales, and {{math|−''t''&lt;sub&gt;0&lt;/sub&gt;}} is the negative dimension of the corresponding equivalence class.&lt;ref&gt;{{cite journal|url=https://static-content.springer.com/lookinside/art%3A10.1134%2FS0001434607010166/000.png|doi=10.1134/S0001434607010166|title=General notion of a topological space of negative dimension and quantization of its density|journal=Mathematical Notes|volume=81|pages=140|year=2007|last1=Maslov|first1=V. P.}}&lt;/ref&gt;

==History==
By the 1940s, the science of topology had developed and studied a thorough basic theory of topological spaces of positive dimension. Motivated by computations, and to some extent aesthetics, topologists searched
for mathematical frameworks that extended our notion of space to allow for negative dimensions. Such dimensions, as well as the [[Four-dimensional space|fourth]] and higher dimensions, are hard to imagine since we are not able to directly observe them. It wasn’t until the 1960s that a special topological framework was constructed—the category of [[Spectrum (topology)|spectra]]. A spectrum is a generalization of space that allows for negative dimensions. The concept of negative-dimensional spaces is applied, for example, to analyze [[Outline of linguistics|linguistic statistics]].&lt;ref&gt;{{cite arxiv|eprint=math/0612543 |last1= Maslov |first1= V. P. |title= Negative dimension in general and asymptotic topology |year= 2006 }}&lt;/ref&gt;

==See also==
*[[Cone (topology)]]
*[[Equidimensionality]]
*[[Join (topology)]]
*[[Suspension (topology)|Suspension]]/[[desuspension]]
*[[Spectrum (topology)]]

==References==
{{Reflist}}

==External links==
*[http://www.mathnet.ru/php/archive.phtml?wshow=paper&amp;jrnid=mzm&amp;paperid=3362&amp;option_lang=rus Отрицательная асимптотическая топологическая размерность, новый конденсат и их связь с квантованным законом Ципфа]. For a translation into English, see {{cite journal|first=V.P.|last=Maslov|title=Negative asymptotic topological dimension, a new condensate, and their relation to the quantized Zipf law |journal=Mathematical Notes|date=November 2006|volume=80|issue=5–6|pages=806–813|url=http://www.mathnet.ru/php/archive.phtml?wshow=paper&amp;jrnid=mzm&amp;paperid=3362&amp;option_lang=eng|accessdate=11 November 2017|doi=10.4213/mzm3362}}

{{Dimension topics}}

[[Category:Dimension]]
[[Category:Dimension theory]]
[[Category:Descriptive set theory]]
[[Category:Properties of topological spaces]]
[[Category:Topology]]
[[Category:Negative concepts]]</text>
      <sha1>1dhasjdyc0erk7socp7zx8dmvwlvdx8</sha1>
    </revision>
  </page>
  <page>
    <title>Nondeterministic algorithm</title>
    <ns>0</ns>
    <id>665957</id>
    <revision>
      <id>850864247</id>
      <parentid>826425632</parentid>
      <timestamp>2018-07-18T13:16:23Z</timestamp>
      <contributor>
        <username>Cheater no1</username>
        <id>13807923</id>
      </contributor>
      <minor/>
      <comment>/* top */ year of introduction added</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6009">[[Image:Difference_between_deterministic_and_Nondeterministic.png|thumb|475px|right| A deterministic algorithm that performs ''f''(''n'') steps always finishes in ''f''(''n'') steps and always returns the same result. A non deterministic algorithm that has ''f''(''n'') levels might not return the same result on different runs.  A non deterministic algorithm may never finish due to the potentially infinite size of the fixed height tree.]]

In [[computer science]], a '''nondeterministic algorithm''' is an [[algorithm]] that, even for the same input, can exhibit different behaviors on different runs, as opposed to a [[deterministic algorithm]]. There are several ways an algorithm may behave differently from run to run. A [[concurrent algorithm]] can perform differently on different runs due to a [[race condition]]. A [[probabilistic algorithm]]'s behaviors depends on a [[random number generator]]. An algorithm that solves a problem in [[nondeterministic polynomial time]] can run in polynomial time or exponential time depending on the choices it makes during execution. The nondeterministic algorithms are often used to find an approximation to a solution, when the exact solution would be too costly to obtain using a deterministic one.

The notion was introduced by [[Robert W. Floyd]] in 1967.&lt;ref&gt;
{{cite web
| url = http://dl.acm.org/citation.cfm?id=321422
| title = Nondeterministic Algorithms
| author = Robert W.Floyd
| journal = [[Journal of the ACM]]
| volume = 14
| number = 4
|date=October 1967
| pages = 636–644
}}&lt;/ref&gt;

==Use==
Often in [[computational theory]], the term "algorithm" refers to a [[deterministic algorithm]]. A nondeterministic algorithm is different from its more familiar deterministic counterpart in its ability to arrive at outcomes using various routes. If a deterministic algorithm represents a single path from an input to an outcome, a nondeterministic algorithm represents a single path stemming into many paths, some of which may arrive at the same output and some of which may arrive at unique outputs. This property is captured mathematically in "nondeterministic" [[models of computation]] such as the [[nondeterministic finite automaton]]. In some scenarios, all possible paths are allowed to run simultaneously.

In algorithm design, nondeterministic algorithms are often used when the problem solved by the algorithm inherently allows multiple outcomes (or when there is a single outcome with multiple paths by which the outcome may be discovered, each equally preferable). Crucially, every outcome the nondeterministic algorithm produces is valid, regardless of which choices the algorithm makes while running.

In [[computational complexity theory]], nondeterministic algorithms are ones that, at every possible step, can allow for multiple continuations (imagine a person walking down a path in a forest and, every time they step further, they must pick which fork in the road they wish to take). These algorithms do not arrive at a solution for every possible computational path; however, they are guaranteed to arrive at a correct solution for some path (i.e., the person walking through the forest may only find their cabin if they pick some combination of "correct" paths). The choices can be interpreted as guesses in a [[search algorithm|search]] process.

A large number of problems can be conceptualized through nondeterministic algorithms, including the most famous unresolved question in computing theory, [[P&amp;nbsp;vs&amp;nbsp;NP]].

==Implementing nondeterministic algorithms with deterministic ones==
One way to simulate a nondeterministic algorithm ''N'' using a deterministic algorithm ''D'' is to treat sets of states of ''N'' as states of ''D''.  This means that ''D'' simultaneously traces all the possible execution paths of ''N'' (see [[powerset construction]] for this technique in use for [[finite automata]]).

Another is [[Randomized algorithm|randomization]], which consists of letting all choices be determined by a [[random number generator]]. The result is called a [[probabilistic]] deterministic algorithm.

==Examples==

===Primality testing===
The problem: given a [[natural number]] ''n'' larger than two, determine whether it is [[prime number|prime]].

A nondeterministic algorithm for this problem is the following based on [[Fermat's little theorem]]:
# Repeat thirty times:
## Pick a random integer ''a'' such that 2 ≤ ''a'' ≤ ''n''-1.
## If &lt;math&gt;a^{n-1}\neq 1 \pmod n&lt;/math&gt;, return answer '''composite'''
# Return answer '''probably prime'''.

If this algorithm returns the answer '''composite''' then the number is certainly not prime. If the algorithm returns the answer '''probably prime''' then there is a high probability that the number is prime, but a slight chance that it is composite. This is an example of a probabilistic nondeterministic algorithm, because it will not always return the same result given a particular input.&lt;ref&gt;{{cite web | url = http://community.topcoder.com/tc?module=Static&amp;d1=tutorials&amp;d2=primalityTesting | title = Primality Testing : Non-deterministic Algorithms | publisher = TopCoder | accessdate = August 21, 2011}}&lt;/ref&gt;

==See also==
* [[Non-deterministic Turing machine]]
* [[Nondeterministic finite automaton]]
* [[Nondeterministic programming]]

==References==
{{reflist}}

==Further reading==
*{{cite book | title = Introduction to Algorithms |edition=3rd | author = Cormen, Thomas H. |year=2009 |publisher=MIT Press | isbn = 978-0-262-03384-8}}
*{{cite web | url = http://xlinux.nist.gov/dads/HTML/nondetermAlgo.html | title = Nondeterministic algorithm | publisher = National Institute of Standards and Technology |accessdate=July 7, 2013}}
*{{cite web | url = http://cs.nyu.edu/courses/spring03/G22.2560-001/nondet.html | title = Non-deterministic Algorithms |publisher=New York University Computer Science |accessdate=July 7, 2013}}

{{DEFAULTSORT:Nondeterministic Algorithm}}
[[Category:Computational complexity theory]]
[[Category:Theory of computation]]</text>
      <sha1>miidljn23kmypj6dxrixca1cg0hgg38</sha1>
    </revision>
  </page>
  <page>
    <title>North</title>
    <ns>0</ns>
    <id>56478</id>
    <revision>
      <id>856971327</id>
      <parentid>856857622</parentid>
      <timestamp>2018-08-28T18:22:31Z</timestamp>
      <contributor>
        <username>GünniX</username>
        <id>237572</id>
      </contributor>
      <comment>Undid revision 856857622 by [[Special:Contributions/108.41.236.184|108.41.236.184]] ([[User talk:108.41.236.184|talk]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9156">{{Other uses}} 
{{Refimprove|date=December 2011}}
[[File:Compass Rose English North.svg|thumb|250px|right|A 16-point [[compass rose]] with north highlighted and at the top]]

'''North''' is one of the four [[compass points]] or [[cardinal directions]]. It is the opposite of [[south]] and is [[perpendicular]] to [[east]] and [[west]]. ''North'' is a [[noun]], [[adjective]], or [[adverb]] indicating [[Direction (geometry)|direction]] or [[geography]].

==Etymology==
{{Unreferenced section|date=April 2017}}The word ''north'' is [[etymology|related]] to the [[Old High German]] ''nord'',&lt;ref&gt;{{cite web|url=http://www.dictionary.com/browse/north|title=the definition of north|website=Dictionary.com|accessdate=10 November 2017}}&lt;/ref&gt; both descending from the [[Proto-Indo-European language|Proto-Indo-European]] unit *''ner-'', meaning "left; below" as north is to left when facing the rising sun.&lt;ref&gt;{{Cite web|url=https://www.etymonline.com/word/north|title=north {{!}} Origin and meaning of north by Online Etymology Dictionary|website=www.etymonline.com|language=en|access-date=2018-03-03}}&lt;/ref&gt; Similarly, the other cardinal directions are also related to the sun's position.&lt;ref&gt;{{Cite web|url=https://www.etymonline.com/word/south|title=south {{!}} Origin and meaning of south by Online Etymology Dictionary|website=www.etymonline.com|language=en|access-date=2018-03-03}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.etymonline.com/word/west|title=west {{!}} Origin and meaning of west by Online Etymology Dictionary|website=www.etymonline.com|language=en|access-date=2018-03-03}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://www.etymonline.com/word/east|title=east {{!}} Origin and meaning of east by Online Etymology Dictionary|website=www.etymonline.com|language=en|access-date=2018-03-03}}&lt;/ref&gt;

The Latin word ''borealis'' comes from the [[Ancient Greek|Greek]] ''[[Anemoi#Boreas|boreas]]'' "north wind, north", which, according to [[Ovid]], was personified as the son of the river-god [[Strymon (mythology)|Strymon]], the father of [[Calais and Zetes]]. ''Septentrionalis'' is from ''septentriones'', "the seven plow oxen", a name of ''[[Ursa Maior]]''. The Greek ἀρκτικός (''arktikós'') is named for the same constellation, and is the source of the English word ''[[Arctic]]''.

Other languages have other derivations. For example, in [[Lezgian language|Lezgian]], ''kefer'' can mean both "disbelief" and "north", since to the north of the Muslim [[Lezgian people|Lezgian]] homeland there are areas formerly inhabited by non-Muslim Caucasian and Turkic peoples. In many languages of [[Mesoamerica]], ''north'' also means "up". In [[Hungarian language|Hungarian]], the word for north is ''észak'', which is derived from ''éjszaka'' ("night"), since above the [[Tropic of Cancer]], the [[Sun]] never shines from the north, except inside the [[Arctic Circle]] during the summer [[midnight sun]].

The direction north is often associated with colder climates because most of the world's land at high latitudes is located in the [[Northern Hemisphere]]. The Arctic Circle passes through the [[Arctic Ocean]], [[Norway]], [[Sweden]], [[Finland]], [[Russia]], the [[United States]] ([[Alaska]]), [[Canada]] ([[Yukon]], [[Northwest Territories]] and [[Nunavut]]), [[Denmark]] ([[Greenland]]) and [[Iceland]] (where it passes through the small offshore island of [[Grímsey]]).

==Mapping==
By [[Norm (sociology)|convention]], the top side of a [[map]] is often north.

To go north using a compass for [[navigation]], set a [[Bearing (navigation)|bearing]] or [[azimuth]] of 0° or 360°.

North is specifically the direction that, in [[Western culture]], is treated as ''the'' fundamental direction:
* North is used (explicitly or implicitly) to define all other directions.
* The (visual) top edges of [[map]]s usually correspond to the northern edge of the area represented, unless explicitly stated otherwise or [[landmarks]] are considered more useful for that territory than specific directions.
* On any rotating astronomical object, ''north'' denotes the side appearing to rotate &lt;big&gt;counter-clockwise&lt;/big&gt; when viewed from afar along the axis of rotation.

==Magnetic north and declination==
[[magnetic north pole|Magnetic north]] is of interest because it is the direction indicated as north on a properly functioning (but uncorrected) magnetic [[compass]].  The difference between it and [[true north]] is called the [[magnetic declination]] (or simply the declination where the context is clear).  For many purposes and physical circumstances, the error in direction that results from ignoring the distinction is tolerable; in others a mental or instrument compensation, based on assumed knowledge of the applicable declination, can solve all the problems. But simple generalizations on the subject should be treated as unsound, and as likely to reflect popular misconceptions about [[terrestrial magnetism]].

Maps intended for usage in orienteering by compass will clearly indicate the local declination for easy correction to true north. Maps may also indicate [[grid north]], which is a navigational term referring to the direction northwards along the grid lines of a [[map projection]].

==Roles of north as prime direction==
The visible rotation of the night sky around the visible [[celestial pole]] provides a vivid metaphor of that direction corresponding to up.  Thus the choice of the north as corresponding to up in the northern hemisphere, or of south in that role in the southern, is, prior to worldwide communication, anything but an arbitrary one.  On the contrary, it is of interest that Chinese and Islamic culture even considered south as the proper top end for maps.&lt;ref&gt;{{cite web|url=http://www.bbc.com/future/story/20160614-maps-have-north-at-the-top-but-it-couldve-been-different|title=Maps have ‘north’ at the top, but it could’ve been different|first=Caroline|last=Williams|website=Bbc.com|accessdate=10 November 2017}}&lt;/ref&gt;

In Western culture:
* Maps tend to be drawn for viewing with either true north or magnetic north at the top
* [[Globe]]s of the earth have the [[North Pole]] at the top, or if the Earth's axis is represented as inclined from vertical (normally by the angle it has relative to the axis of the Earth's orbit), in the top half.
* Maps are usually labelled to indicate which direction on the map corresponds to a direction on the earth,
** usually with a single arrow oriented to the map's representation of true north,
** occasionally with a single arrow oriented to the map's representation of magnetic north, or two arrows oriented to true and magnetic north respectively,
** occasionally with a [[compass rose]], but if so, usually on a map with north at the top and usually with north decorated more prominently than any other compass point.
* Up is a metaphor for north. The notion that north should always be up and east at the right was established by the Greek astronomer [[Ptolemy]]. The historian [[Daniel Boorstin]] suggests that perhaps this was because the better-known places in his world were in the northern hemisphere, and on a flat map these were most convenient for study if they were in the upper right-hand corner.&lt;ref&gt;
{{Cite book|title=The Discoverers|author=Daniel Boorstin|year=1983|page=98|publisher=Random House/J.M.Dent &amp; Sons}}&lt;/ref&gt;

==Roles of east and west as inherently subsidiary directions==
While the choice of north over south as prime direction reflects quite arbitrary historical factors,{{which|date=January 2016}} east and west are not nearly as natural alternatives as first glance might suggest.  Their folk definitions are, respectively, "where the sun rises" and "where it sets".  Except on the Equator, however, these definitions, taken together, would imply that
* east and west would not be 180 degrees apart, but instead would differ from that by up to twice the degrees of latitude of the location in question, and
* they would each move slightly from day to day and, in the [[temperate zone]]s, markedly over the course of the year.

Reasonably accurate folk astronomy, such as is usually attributed to [[Stone Age]] peoples or later [[Celts]], would arrive at east and west by noting the directions of rising and setting (preferably more than once each) and choosing as prime direction one of the two mutually opposite directions that lie halfway between those two.  The true folk-astronomical definitions of east and west are "the directions, a right angle from the prime direction, that are closest to the rising and setting, respectively, of the sun (or moon).

==Cultural references==
Being the "default" direction on the compass, north is referred to frequently in Western popular culture.  Some examples include:

* The phrase "north of X" is often used by Americans to mean "more than X" or "greater than X", i.e. "The world population is north of 7 billion people" or "north of 40 [years old]".

==See also==
* [[Nordicity]]
* [[List of northernmost items]]
* [[Northing]]
* [[Septentrional]]

==References==
{{Reflist}}

==External links==
* {{Wiktionary-inline}}

{{CandODirections}}

[[Category:Orientation (geometry)]]</text>
      <sha1>5prqhiwnhgwip0hbl4rq48pfw21tjb6</sha1>
    </revision>
  </page>
  <page>
    <title>Partially ordered group</title>
    <ns>0</ns>
    <id>172048</id>
    <revision>
      <id>837359193</id>
      <parentid>787463437</parentid>
      <timestamp>2018-04-20T10:04:56Z</timestamp>
      <contributor>
        <ip>128.240.225.114</ip>
      </contributor>
      <comment>/* See also */ Articles on other orderings on groups</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5431">In [[abstract algebra]], a '''partially ordered group''' is a [[group (mathematics)|group]] ''(G,+)'' equipped with a [[partial order]] "≤" that is ''translation-invariant''; in other words, "≤" has the property that, for all ''a'', ''b'', and ''g'' in ''G'', if ''a'' ≤ ''b'' then ''a+g'' ≤ ''b+g'' and ''g+a'' ≤ ''g+b''.

An element ''x'' of ''G'' is called '''positive element''' if 0 ≤ ''x''. The set of elements 0 ≤ ''x'' is often denoted with ''G''&lt;sup&gt;+&lt;/sup&gt;, and it is called the '''positive cone of G'''. So we have ''a'' ≤ ''b'' [[if and only if]] ''-a''+''b'' ∈ ''G''&lt;sup&gt;+&lt;/sup&gt;.

By the definition, we can reduce the partial order to a monadic property: ''a'' ≤ ''b'' if and only if ''0'' ≤ ''-a''+''b''.

For the general group ''G'', the existence of a positive cone specifies an order on ''G''. A group ''G'' is a partially ordered group if and only if there exists a subset ''H'' (which is ''G''&lt;sup&gt;+&lt;/sup&gt;) of ''G'' such that:
* ''0'' ∈ ''H''
* if ''a'' ∈ ''H'' and ''b'' ∈ ''H'' then ''a+b'' ∈ ''H''
* if ''a'' ∈ ''H'' then ''-x''+''a''+''x'' ∈ ''H'' for each ''x'' of ''G''
* if ''a'' ∈ ''H'' and ''-a'' ∈ ''H'' then ''a=0''

A partially ordered group ''G'' with positive cone ''G''&lt;sup&gt;+&lt;/sup&gt; is said to be '''unperforated''' if ''n'' · ''g'' ∈ ''G''&lt;sup&gt;+&lt;/sup&gt; for some positive integer ''n'' implies ''g'' ∈ ''G''&lt;sup&gt;+&lt;/sup&gt;. Being unperforated means there is no "gap" in the positive cone ''G''&lt;sup&gt;+&lt;/sup&gt;.

If the order on the group is a [[linear order]], then it is said to be a [[linearly ordered group]].
If the order on the group is a [[lattice order]], i.e. any two elements have a least upper bound, then it is a '''lattice-ordered group''' (shortly '''l-group''', though usually typeset with a [[Script typeface|script]] ell: &amp;#8467;-group).

A '''Riesz group''' is an unperforated partially ordered group with a property slightly weaker than being a lattice ordered group. Namely, a Riesz group satisfies the '''Riesz interpolation property''': if ''x''&lt;sub&gt;1&lt;/sub&gt;, ''x''&lt;sub&gt;2&lt;/sub&gt;, ''y''&lt;sub&gt;1&lt;/sub&gt;, ''y''&lt;sub&gt;2&lt;/sub&gt; are elements of ''G'' and ''x&lt;sub&gt;i&lt;/sub&gt;'' ≤ ''y&lt;sub&gt;j&lt;/sub&gt;'', then there exists ''z'' ∈ ''G'' such that ''x&lt;sub&gt;i&lt;/sub&gt;'' ≤ ''z'' ≤ ''y&lt;sub&gt;j&lt;/sub&gt;''.

If ''G'' and ''H'' are two partially ordered groups, a map from ''G'' to ''H'' is a ''morphism of partially ordered groups'' if it is both a [[group homomorphism]] and a [[monotonic function]]. The partially ordered groups, together with this notion of morphism, form a [[category theory|category]].

Partially ordered groups are used in the definition of [[Valuation (algebra)|valuation]]s of [[field (mathematics)|field]]s.

== Examples ==

* An [[ordered vector space]] is a partially ordered group
* A [[Riesz space]] is a lattice-ordered group
* A typical example of a partially ordered group is '''[[integer|Z]]'''&lt;sup&gt;''n''&lt;/sup&gt;, where the group operation is componentwise addition, and we write (''a''&lt;sub&gt;1&lt;/sub&gt;,...,''a''&lt;sub&gt;''n''&lt;/sub&gt;) ≤ (''b''&lt;sub&gt;1&lt;/sub&gt;,...,''b''&lt;sub&gt;''n''&lt;/sub&gt;) [[if and only if]] ''a''&lt;sub&gt;''i''&lt;/sub&gt; ≤ ''b''&lt;sub&gt;''i''&lt;/sub&gt; (in the usual order of integers) for all ''i''=1,...,''n''.
* More generally, if ''G'' is a partially ordered group and ''X'' is some set, then the set of all functions from ''X'' to ''G'' is again a partially ordered group: all operations are performed componentwise. Furthermore, every [[subgroup]] of ''G'' is a partially ordered group: it inherits the order from ''G''.
* If ''A'' is an [[approximately finite-dimensional C*-algebra]], or more generally, if ''A'' is a stably finite unital C*-algebra, then [[Approximately finite-dimensional C*-algebra#K0|K&lt;sub&gt;0&lt;/sub&gt;]](''A'') is a partially ordered [[abelian group]]. (Elliott, 1976)

== See also ==
* [[Partially ordered ring]]
* [[Linearly ordered group]]
* [[Cyclically ordered group]]

==References==

*M. Anderson and T. Feil, ''Lattice Ordered Groups: an Introduction'', D. Reidel, 1988.
*M. R. Darnel, ''The Theory of Lattice-Ordered Groups'', Lecture Notes in Pure and Applied Mathematics 187, Marcel Dekker, 1995.
*L. Fuchs, ''Partially Ordered Algebraic Systems'', Pergamon Press, 1963.
*A. M. W. Glass, ''Ordered Permutation Groups'', London Math. Soc. Lecture Notes Series 55, Cambridge U. Press, 1981.
*V. M. Kopytov and A. I. Kokorin (trans. by D. Louvish), ''Fully Ordered Groups'', Halsted Press (John Wiley &amp; Sons), 1974.
*V. M. Kopytov and N. Ya. Medvedev, ''Right-ordered groups'', Siberian School of Algebra and Logic, Consultants Bureau, 1996.
*V. M. Kopytov and N. Ya. Medvedev, ''The Theory of Lattice-Ordered Groups'', Mathematics and its Applications 307, Kluwer Academic Publishers, 1994.
*R. B. Mura and A. Rhemtulla, ''Orderable groups'', Lecture Notes in Pure and Applied Mathematics 27, Marcel Dekker, 1977.
*T.S. Blyth, ''Lattices and Ordered Algebraic Structures'', Springer, 2005, {{ISBN|1-85233-905-5}}, chap. 9.
* G.A. Elliott, On the classification of inductive limits of sequences of semisimple finite-dimensional algebras, J. Algebra, 38 (1976)29-44.

== External links ==
* {{cite web| title = Partially Ordered Group | publisher = [[Encyclopedia of Mathematics]] | url = http://eom.springer.de/p/p071710.htm | accessdate = 2009-04-03}}
* http://www.encyclopediaofmath.org/index.php/Lattice-ordered_group

[[Category:Ordered algebraic structures]]
[[Category:Ordered groups]]
[[Category:Order theory]]</text>
      <sha1>6ji10muw1hlu8bghhg0ex0nnxo10pca</sha1>
    </revision>
  </page>
  <page>
    <title>Pentagonal bipyramidal molecular geometry</title>
    <ns>0</ns>
    <id>13309700</id>
    <revision>
      <id>869503414</id>
      <parentid>860714044</parentid>
      <timestamp>2018-11-19T01:12:29Z</timestamp>
      <contributor>
        <username>Officer781</username>
        <id>5336741</id>
      </contributor>
      <comment>add another reference for the common geometries</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3153">{{expert needed|1=Chemistry|date=April 2017}}
{{one source|date=April 2017}}
{{Infobox molecular geometry
| Examples= [[Iodine heptafluoride|IF&lt;sub&gt;7&lt;/sub&gt;]], ZrF&lt;sub&gt;7&lt;/sub&gt;&lt;sup&gt;3−&lt;/sup&gt;
| Image_File=Pentagonal-bipyramidal-3D-balls.png
| Symmetry_group= ''D&lt;sub&gt;5h&lt;/sub&gt;''
| Atom_direction= 7
| Bond_angle= 90°, 72°
| mu= 0
}}
[[Image:Iodine-heptafluoride-3D-vdW.png|thumb|left|200px|Structure of [[iodine heptafluoride]], an example of a molecule with the pentagonal-bipyramidal coordination geometry.]]
In [[chemistry]], a '''pentagonal bipyramid''' is a [[molecular geometry]] with one atom at the centre with seven [[ligand]]s at the corners of a [[pentagonal bipyramid]]. A perfect pentagonal bipyramid belongs to the [[molecular point group]] ''D&lt;sub&gt;5h&lt;/sub&gt;''.

The pentagonal bipyramid is a case where bond angles surrounding an atom are not identical (see also [[trigonal bipyramidal molecular geometry]]).&lt;ref&gt;{{Cotton&amp;Wilkinson6th}}&lt;/ref&gt;  This is one of the three common shapes for heptacoordinate transition metal complexes, along with the [[capped octahedral molecular geometry|capped octahedron]] and the [[capped trigonal prismatic molecular geometry|capped trigonal prism]].&lt;ref&gt;{{cite journal
| title   = Seven-coordination. A molecular orbital exploration of structure, stereochemistry, and reaction dynamics
| author1 = Roald. Hoffmann
| author2 = Barbara F. Beier
| author3 = Earl L. Muetterties
| author4 = Angelo R. Rossi
| journal = [[Inorganic Chemistry (journal)|Inorganic Chemistry]]
| year    = 1977
| volume  = 16
| issue   = 3
| pages   = 511–522
| doi     = 10.1021/ic50169a002
}}&lt;/ref&gt;&lt;ref&gt;Wells A.F. (1984) ''Structural Inorganic Chemistry'' 5th edition Oxford Science Publications {{ISBN|0-19-855370-6}}&lt;/ref&gt;

{{clear}}
==Examples==
* [[Iodine heptafluoride]] (IF&lt;sub&gt;7&lt;/sub&gt;) with 7 bonding groups
* [[Peroxide|Peroxo]] [[chromium]](IV) complexes, e.g. [Cr(O&lt;sub&gt;2&lt;/sub&gt;)&lt;sub&gt;2&lt;/sub&gt;(NH&lt;sub&gt;3&lt;/sub&gt;)&lt;sub&gt;3&lt;/sub&gt;] where the peroxo groups occupy four of the planar positions.
* ZrF&lt;sub&gt;7&lt;/sub&gt;&lt;sup&gt;3−&lt;/sup&gt; and HfF&lt;sub&gt;7&lt;/sub&gt;&lt;sup&gt;3−&lt;/sup&gt;&lt;ref&gt;{{cite journal
| title   = "Non-VSEPR" Structures and Bonding in d(0) Systems
| first   = Martin
| last    = Kaupp
| journal = Angew Chem Int Ed Engl
| year    = 2001
| volume  = 40
| issue   = 1
| pages   = 3534–3565
| doi     = 10.1002/1521-3773(20011001)40:19&lt;3534::AID-ANIE3534&gt;3.0.CO;2-#
}}&lt;/ref&gt;&lt;ref&gt;{{cite journal
| title   = Stereochemistry of Seven-Coordinate Main Group and d0 Transition Metal Molecules
| author1 = Zhenyang Lin
| author2 =  Ian Bytheway
| journal = [[Inorganic Chemistry (journal)|Inorganic Chemistry]]
| year    = 1996
| volume  = 35
| issue   = 3
| pages   = 594–603
| doi     = 10.1021/ic950271o
}}&lt;/ref&gt;

==References==
{{Reflist}}

==External links==
* [http://www.ch.ic.ac.uk/rzepa/bpr/Figure-5.html] – Images of IF&lt;sub&gt;7&lt;/sub&gt;
* [http://www.3dchem.com/ 3D Chem] – Chemistry, Structures, and 3D Molecules 
* [http://arquivo.pt/wayback/20160523113736/http://www.iumsc.indiana.edu/ IUMSC] – Indiana University Molecular Structure Center

{{MolecularGeometry}}

[[Category:Stereochemistry]]
[[Category:Molecular geometry]]</text>
      <sha1>2sd6iwyu356o0jgs7v5s25jfhxy1y4h</sha1>
    </revision>
  </page>
  <page>
    <title>Permanent (mathematics)</title>
    <ns>0</ns>
    <id>215889</id>
    <revision>
      <id>858843672</id>
      <parentid>848966595</parentid>
      <timestamp>2018-09-10T00:24:53Z</timestamp>
      <contributor>
        <username>Görre Mörre</username>
        <id>34146978</id>
      </contributor>
      <minor/>
      <comment>/* Computation */ Added a ref to the wiki article of the algorithm</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="25440">{{hatlink|For other uses, see [[wikt:permanent]] and [[wikt:permanence]] ''(for ordinary dictionary meaning)'' and [[Permanent (disambiguation)]].}}
In [[linear algebra]], the '''permanent''' of a [[square matrix]] is a function of the matrix similar to the [[determinant]]. The permanent, as well as the determinant, is a polynomial in the entries of the matrix.&lt;ref&gt;{{cite journal|author=Marcus, Marvin|author2=Minc, Henryk|title=Permanents|journal=Amer. Math. Monthly|volume=72|year=1965|pages=577–591|url=http://www.maa.org/programs/maa-awards/writing-awards/permanents|doi=10.2307/2313846}}&lt;/ref&gt; Both are special cases of a more general function of a matrix called the [[immanant]].

== Definition ==
The permanent of an ''n''-by-''n'' matrix ''A'' = (''a''&lt;sub&gt;''i,j''&lt;/sub&gt;) is defined as

: &lt;math&gt; \operatorname{perm}(A)=\sum_{\sigma\in S_n}\prod_{i=1}^n a_{i,\sigma(i)}.&lt;/math&gt;

The sum here extends over all elements σ of the [[symmetric group]] ''S''&lt;sub&gt;''n''&lt;/sub&gt;; i.e. over all [[permutation]]s of the numbers 1, 2, ..., ''n''.

For example,

:&lt;math&gt;\operatorname{perm}\begin{pmatrix}a&amp;b \\ c&amp;d\end{pmatrix}=ad+bc,&lt;/math&gt;

and

:&lt;math&gt;\operatorname{perm}\begin{pmatrix}a&amp;b&amp;c \\ d&amp;e&amp;f \\ g&amp;h&amp;i \end{pmatrix}=aei + bfg + cdh + ceg + bdi + afh.&lt;/math&gt;

The definition of the permanent of ''A'' differs from that of the [[determinant]] of ''A'' in that the [[signature (permutation)|signatures]] of the permutations are not taken into account.

The permanent of a matrix A is denoted per ''A'', perm ''A'', or Per ''A'', sometimes with parentheses around the argument. In his monograph, {{harvtxt|Minc|1984}} uses Per(''A'') for the permanent of rectangular matrices, and uses per(''A'') when ''A'' is a square matrix. {{harvtxt|Muir|1882}} uses the notation &lt;math&gt;\overset{+}{|}\quad \overset{+}{|}&lt;/math&gt;.

The word, ''permanent'', originated with Cauchy in 1812 as “fonctions symétriques permanentes” for a related type of function,&lt;ref&gt;{{Citation| last=Cauchy | first=A. L.| title=Mémoire sur les fonctions qui ne peuvent obtenir que deux valeurs égales et de signes contraires par suite des transpositions opérées entre les variables qu’elles renferment. |url=http://gallica.bnf.fr/ark:/12148/bpt6k90193x/f97 |journal=Journal de l'École Polytechnique |volume=10 |pages=91–169 |year=1815}}&lt;/ref&gt; and was used by {{harvtxt|Muir|1882}} in the modern, more specific, sense.&lt;ref&gt;{{harvnb|van Lint|Wilson|2001|loc=p. 108}}&lt;/ref&gt;

== Properties and applications ==
If one views the permanent as a map that takes ''n'' vectors as arguments, then it is a [[multilinear map]] and it is symmetric (meaning that any order of the vectors results in the same permanent). Furthermore, given a square matrix &lt;math&gt;A = (a_{ij})&lt;/math&gt; of order ''n'', we have:&lt;ref&gt;{{harvnb|Ryser|1963|loc=pp. 25 &amp;ndash; 26}}&lt;/ref&gt;
* perm(''A'') is invariant under arbitrary permutations of the rows and/or columns of ''A''. This property may be written symbolically as perm(''A'') = perm(''PAQ'') for any appropriately sized [[permutation matrix|permutation matrices]] ''P'' and ''Q'',
* multiplying any single row or column of ''A'' by a [[Scalar (mathematics)|scalar]] ''s'' changes perm(''A'') to ''s''⋅perm(''A''),
* perm(''A'') is invariant under [[Transposition (mathematics)|transposition]], that is, perm(''A'') = perm(''A''&lt;sup&gt;T&lt;/sup&gt;).

If &lt;math&gt;A = (a_{ij})&lt;/math&gt; and &lt;math&gt;B=(b_{ij})&lt;/math&gt; are square matrices of order ''n'' then,&lt;ref&gt;{{harvnb|Percus|1971|loc=p. 2}}&lt;/ref&gt;

:&lt;math&gt;\operatorname{perm}(A + B) = \sum_{s,t} \operatorname{perm} (a_{ij})_{i \in s, j \in t} \operatorname{perm} (b_{ij})_{i \in \bar{s}, j \in \bar{t}},&lt;/math&gt;

where ''s'' and ''t'' are subsets of the same size of {1,2,...,''n''} and &lt;math&gt;\bar{s}, \bar{t}&lt;/math&gt; are their respective complements in that set.

On the other hand, the basic multiplicative property of determinants is not valid for permanents.&lt;ref name="Ryser 1963 loc=p. 26"&gt;{{harvnb|Ryser|1963|loc=p. 26}}&lt;/ref&gt; A simple example shows that this is so.

: &lt;math&gt;\begin{align} 4 &amp;= \operatorname{perm} \left ( \begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \right )\operatorname{perm} \left ( \begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \right ) \\ 
&amp;\neq \operatorname{perm}\left ( \left ( \begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \right ) \left ( \begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \right ) \right ) = \operatorname{perm} \left ( \begin{matrix} 2 &amp; 2 \\ 2 &amp; 2 \end{matrix} \right )= 8.\end{align} &lt;/math&gt;

A formula similar to [[Expansion by minors|Laplace's]] for the development of a determinant along a row, column or diagonal is also valid for the permanent;&lt;ref name="Percus 1971 loc=p. 12"&gt;{{harvnb|Percus|1971|loc=p. 12}}&lt;/ref&gt; all signs have to be ignored for the permanent. For example, expanding along the first column,

: &lt;math&gt;\begin{align} \operatorname{perm} \left ( \begin{matrix} 1 &amp; 1 &amp; 1 &amp; 1\\2 &amp; 1 &amp; 0 &amp; 0\\3 &amp; 0 &amp; 1 &amp; 0\\4 &amp; 0 &amp; 0 &amp; 1 \end{matrix} \right )         
= {} &amp; 1 \cdot \operatorname{perm} \left( \begin{matrix} 1&amp;0&amp;0\\ 0&amp;1&amp;0\\ 0&amp;0&amp;1 \end{matrix}\right) + 2\cdot \operatorname{perm} \left(\begin{matrix}1&amp;1&amp;1\\0&amp;1&amp;0\\0&amp;0&amp;1\end{matrix}\right) \\
&amp; {} + \ 3\cdot \operatorname{perm} \left(\begin{matrix}1&amp;1&amp;1\\1&amp;0&amp;0\\0&amp;0&amp;1\end{matrix}\right) + 4 \cdot \operatorname{perm} \left(\begin{matrix}1&amp;1&amp;1\\1&amp;0&amp;0\\0&amp;1&amp;0\end{matrix}\right) \\
= {} &amp; 1(1) + 2(1) + 3(1) + 4(1) = 10, \end{align}  &lt;/math&gt; 

while expanding along the last row gives,

: &lt;math&gt;\begin{align}\operatorname{perm} \left ( \begin{matrix} 1 &amp; 1 &amp; 1 &amp; 1\\2 &amp; 1 &amp; 0 &amp; 0\\3 &amp; 0 &amp; 1 &amp; 0\\4 &amp; 0 &amp; 0 &amp; 1 \end{matrix} \right )  
= {} &amp; 4 \cdot \operatorname{perm} \left(\begin{matrix}1&amp;1&amp;1\\1&amp;0&amp;0\\0&amp;1&amp;0\end{matrix}\right) + 0\cdot \operatorname{perm} \left(\begin{matrix}1&amp;1&amp;1\\2&amp;0&amp;0\\3&amp;1&amp;0\end{matrix}\right) \\
&amp; {} + \ 0\cdot \operatorname{perm} \left(\begin{matrix}1&amp;1&amp;1\\2&amp;1&amp;0\\3&amp;0&amp;0\end{matrix}\right) + 
1 \cdot \operatorname{perm} \left( \begin{matrix} 1&amp;1&amp;1\\ 2&amp;1&amp;0\\ 3&amp;0&amp;1\end{matrix}\right)  \\
= {} &amp; 4(1) + 0 + 0 + 1(6) = 10.\end{align}  &lt;/math&gt;

Unlike the determinant, the permanent has no easy geometrical interpretation; it is mainly used in [[combinatorics]], in treating boson [[Green's function (many-body theory)|Green's functions]] in [[quantum field theory]], and in determining state probabilities of [[boson sampling]] systems&lt;ref&gt;{{cite arXiv |last=Aaronson |first=Scott |date=14 Nov 2010 |title=The Computational Complexity of Linear Optics |eprint=1011.3245}}&lt;/ref&gt;. However, it has two [[graph-theoretic]] interpretations: as the sum of weights of [[Vertex cycle cover|cycle cover]]s of a [[directed graph]], and as the sum of weights of perfect matchings in a [[bipartite graph]].

===Symmetric tensors===

The permanent arises naturally in the study of the symmetric tensor power of [[Hilbert spaces]].&lt;ref&gt;{{cite book|last1=Bhatia|first1=Rajendra|title=Matrix Analysis|date=1997|publisher=Springer-Verlag|location=New York|isbn=0-387-94846-5|pages=16–19}}&lt;/ref&gt;  In particular, for a Hilbert space &lt;math&gt;H&lt;/math&gt;, let &lt;math&gt;\vee^k H&lt;/math&gt; denote the &lt;math&gt;k&lt;/math&gt;th symmetric tensor power of &lt;math&gt;H&lt;/math&gt;, which is the space of [[Tensor product#Exterior and symmetric algebra|symmetric tensors]].  Note in particular that &lt;math&gt;\vee^k H&lt;/math&gt; is spanned by the [[Symmetric tensor#Symmetric product|Symmetric products]] of elements in &lt;math&gt;H&lt;/math&gt;.  For &lt;math&gt;x_1,x_2,\dots,x_k \in H&lt;/math&gt;, we define the symmetric product of these elements by
:&lt;math&gt;
x_1 \vee x_2 \vee \cdots \vee x_k = 
(k!)^{-1/2} \sum_{\sigma \in S_k} 
x_{\sigma(1)} \otimes x_{\sigma(2)} \otimes \cdots \otimes x_{\sigma(k)}
&lt;/math&gt;
If we consider &lt;math&gt;\vee^k H&lt;/math&gt; (as a subspace of &lt;math&gt;\otimes^kH&lt;/math&gt;, the ''k''th [[Tensor product of Hilbert spaces|tensor power]] of &lt;math&gt;H&lt;/math&gt;) and define the inner product on &lt;math&gt;\vee^kH&lt;/math&gt; accordingly, we find that for &lt;math&gt;x_j,y_j \in H&lt;/math&gt;
:&lt;math&gt;\langle
x_1 \vee x_2 \vee \cdots \vee x_k,
y_1 \vee y_2 \vee \cdots \vee y_k
\rangle = 
\operatorname{perm}\left[\langle x_i,y_j \rangle\right]_{i,j = 1}^k&lt;/math&gt;
Applying the [[Cauchy–Schwarz inequality]], we find that &lt;math&gt;\operatorname{perm} \left[\langle x_i,x_j \rangle\right]_{i,j = 1}^k \geq 0&lt;/math&gt;, and that
:&lt;math&gt;\left|\operatorname{perm} \left[\langle x_i,y_j \rangle\right]_{i,j = 1}^k \right|^2 \leq
\operatorname{perm} \left[\langle x_i,x_j \rangle\right]_{i,j = 1}^k \cdot 
\operatorname{perm} \left[\langle y_i,y_j \rangle\right]_{i,j = 1}^k
&lt;/math&gt;

===Cycle covers===
Any square matrix &lt;math&gt;A = (a_{ij})&lt;/math&gt; can be viewed as the [[adjacency matrix]] of a weighted directed graph, with &lt;math&gt;a_{ij}&lt;/math&gt; representing the weight of the arc from vertex ''i'' to vertex ''j''. 
A [[Vertex cycle cover|cycle cover]] of a weighted directed graph is a collection of vertex-disjoint [[directed cycle]]s in the digraph that covers all vertices in the graph. Thus, each vertex ''i'' in the digraph has a unique "successor" &lt;math&gt;\sigma(i)&lt;/math&gt; in the cycle cover, and &lt;math&gt;\sigma&lt;/math&gt; is a [[permutation]] on &lt;math&gt;\{1,2,\dots,n\}&lt;/math&gt; where ''n'' is the number of vertices in the digraph. Conversely, any permutation &lt;math&gt;\sigma&lt;/math&gt; on &lt;math&gt;\{1,2,\dots,n\}&lt;/math&gt; corresponds to a cycle cover in which there is an arc from vertex ''i'' to vertex &lt;math&gt;\sigma(i)&lt;/math&gt; for each ''i''.
 
If the weight of a cycle-cover is defined to be the product of the weights of the arcs in each cycle, then

: &lt;math&gt; \operatorname{weight}(\sigma) = \prod_{i=1}^n a_{i,\sigma(i)}.&lt;/math&gt;

The permanent of an &lt;math&gt;n \times n&lt;/math&gt; matrix ''A'' is defined as

:&lt;math&gt; \operatorname{perm}(A)=\sum_\sigma \prod_{i=1}^n a_{i,\sigma(i)}&lt;/math&gt;

where &lt;math&gt;\sigma&lt;/math&gt; is a permutation over &lt;math&gt;\{1,2,\ldots,n\}&lt;/math&gt;. Thus the permanent of ''A'' is equal to the sum of the weights of all cycle-covers of the digraph.

===Perfect matchings===
A square matrix &lt;math&gt;A = (a_{ij})&lt;/math&gt; can also be viewed as the [[adjacency matrix]] of a [[bipartite graph]] which has [[vertex (graph theory)|vertices]] &lt;math&gt;x_1, x_2, \dots, x_n&lt;/math&gt; on one side and &lt;math&gt;y_1, y_2, \dots, y_n&lt;/math&gt; on the other side, with &lt;math&gt;a_{ij}&lt;/math&gt; representing the weight of the edge from vertex &lt;math&gt;x_i&lt;/math&gt; to vertex &lt;math&gt;y_j&lt;/math&gt;. If the weight of a [[perfect matching]] &lt;math&gt;\sigma&lt;/math&gt; that matches &lt;math&gt;x_i&lt;/math&gt; to &lt;math&gt;y_{\sigma(i)}&lt;/math&gt; is defined to be the product of the weights of the edges in the matching, then
:&lt;math&gt; \operatorname{weight}(\sigma) = \prod_{i=1}^n a_{i,\sigma(i)}.&lt;/math&gt;
Thus the permanent of ''A'' is equal to the sum of the weights of all perfect matchings of the graph.

== Permanents of (0, 1) matrices ==
=== Enumeration ===
The answers to many counting questions can be computed as permanents of matrices that only have 0 and 1 as entries. 

Let Ω(''n'',''k'') be the class of all (0, 1)-matrices of order ''n'' with each row and column sum equal to ''k''. Every matrix ''A'' in this class has perm(''A'') &gt; 0.&lt;ref name="Ryser 1963 loc=p. 124"&gt;{{harvnb|Ryser|1963|loc=p. 124}}&lt;/ref&gt; The incidence matrices of [[projective plane]]s are in the class Ω(''n''&lt;sup&gt;2&lt;/sup&gt; + ''n'' + 1, ''n'' + 1) for ''n'' an integer &gt; 1. The permanents corresponding to the smallest projective planes have been calculated. For ''n'' = 2, 3, and 4 the values are 24, 3852 and 18,534,400 respectively.&lt;ref name="Ryser 1963 loc=p. 124"/&gt; Let ''Z'' be the incidence matrix of the projective plane with ''n'' = 2, the [[Fano plane]]. Remarkably, perm(''Z'') = 24 = |det (''Z'')|, the absolute value of the determinant of ''Z''. This is a consequence of ''Z'' being a [[circulant matrix]] and the theorem:&lt;ref&gt;{{harvnb|Ryser|1963|loc=p. 125}}&lt;/ref&gt;

:If ''A'' is a circulant matrix in the class Ω(''n'',''k'') then if ''k''&amp;nbsp;&gt;&amp;nbsp;3, perm(''A'')&amp;nbsp;&gt;&amp;nbsp;|det (''A'')| and if ''k''&amp;nbsp;=&amp;nbsp;3, perm(''A'')&amp;nbsp;=&amp;nbsp;|det (''A'')|. Furthermore, when ''k''&amp;nbsp;=&amp;nbsp;3, by permuting rows and columns, ''A'' can be put into the form of a direct sum of ''e'' copies of the matrix ''Z'' and consequently, ''n''&amp;nbsp;=&amp;nbsp;7''e'' and perm(''A'')&amp;nbsp;=&amp;nbsp;24&lt;sup&gt;e&lt;/sup&gt;.

Permanents can also be used to calculate the number of [[permutation]]s with restricted (prohibited) positions. For the standard ''n''-set {1, 2, ..., ''n''}, let &lt;math&gt;A = (a_{ij})&lt;/math&gt; be the (0, 1)-matrix where ''a''&lt;sub&gt;''ij''&lt;/sub&gt; = 1 if ''i''&amp;nbsp;→&amp;nbsp;''j'' is allowed in a permutation and ''a''&lt;sub&gt;''ij''&lt;/sub&gt; = 0 otherwise. Then perm(''A'') is equal to the number of permutations of the ''n''-set that satisfy all the restrictions.&lt;ref name="Percus 1971 loc=p. 12"/&gt; Two well known special cases of this are the solution of the [[derangement]] problem and the [[ménage problem]]: the number of permutations of an ''n''-set with no fixed points (derangements) is given by

:&lt;math&gt;\operatorname{perm}(J - I) = \operatorname{perm}\left (\begin{matrix} 0 &amp; 1 &amp; 1 &amp; \dots &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; \dots &amp; 1 \\ 1 &amp; 1 &amp; 0 &amp; \dots &amp; 1 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; 1 &amp; 1 &amp; \dots &amp; 0 \end{matrix} \right) = n! \sum_{i=0}^n \frac{(-1)^i}{i!},&lt;/math&gt;
where ''J'' is the ''n''×''n'' all 1's matrix and ''I'' is the identity matrix, and the [[ménage number]]s are given by

: &lt;math&gt;
\begin{align}
\operatorname{perm}(J - I - I') &amp; = \operatorname{perm}\left (\begin{matrix} 0 &amp; 0 &amp; 1 &amp; \dots &amp; 1 \\ 1 &amp; 0 &amp; 0 &amp; \dots &amp; 1 \\ 1 &amp; 1 &amp; 0 &amp; \dots &amp; 1 \\ \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; 1 &amp; 1 &amp; \dots &amp; 0 \end{matrix} \right) \\
&amp; =  \sum_{k=0}^n (-1)^k \frac{2n}{2n-k} {2n-k\choose k} (n-k)!,
\end{align}
&lt;/math&gt;

where ''I''' is the (0, 1)-matrix with nonzero entries in positions (''i'', ''i'' + 1) and (''n'', 1).

=== Bounds ===
The [[Bregman–Minc inequality]], conjectured by H. Minc in 1963&lt;ref&gt;{{citation|first=Henryk|last=Minc|title=Upper bounds for permanents of (0,1)-matrices|journal=Bulletin of the American Mathematical Society|volume=69|year=1963|pages=789–791|doi=10.1090/s0002-9904-1963-11031-9}}&lt;/ref&gt; and proved by [[Lev M Bregman|L. M. Brégman]] in 1973,&lt;ref&gt;{{harvnb|van Lint|Wilson|2001|loc=p. 101}}&lt;/ref&gt; gives an upper bound for the permanent of an ''n'' × ''n'' (0, 1)-matrix.  If ''A'' has ''r''&lt;sub&gt;''i''&lt;/sub&gt; ones in row ''i'' for each 1 ≤ ''i'' ≤ ''n'', the inequality states that

::&lt;math&gt;\operatorname{perm} A \leq \prod_{i=1}^n (r_i)!^{1/r_i}.&lt;/math&gt;

== Van der Waerden's conjecture ==
In 1926 [[Bartel Leendert van der Waerden|Van der Waerden]] conjectured that the minimum permanent among all {{nowrap|''n'' &amp;times; ''n''}} [[doubly stochastic matrix|doubly stochastic matrices]] is ''n''&lt;nowiki&gt;!&lt;/nowiki&gt;/''n''&lt;sup&gt;''n''&lt;/sup&gt;, achieved by the matrix for which all entries are equal to&amp;nbsp;1/''n''.&lt;ref&gt;{{citation
 | last = van der Waerden | first = B. L. | author-link = Bartel Leendert van der Waerden
 | journal = Jber. Deutsch. Math.-Verein.
 | page = 117
 | title = Aufgabe 45
 | volume = 35
 | year = 1926}}.&lt;/ref&gt; Proofs of this conjecture were published in 1980 by B. Gyires&lt;ref&gt;{{citation
 | last = Gyires | first = B.
 | issue = 3-4
 | journal = Publicationes Mathematicae Institutum Mathematicum Universitatis Debreceniensis
 | mr = 604006
 | pages = 291–304
 | title = The common source of several inequalities concerning doubly stochastic matrices
 | volume = 27
 | year = 1980}}.&lt;/ref&gt; and in 1981 by G. P. Egorychev&lt;ref&gt;{{citation
 | last = Egoryčev | first = G. P.
 | language = Russian
 | location = Krasnoyarsk
 | mr = 602332
 | page = 12
 | publisher = Akad. Nauk SSSR Sibirsk. Otdel. Inst. Fiz.
 | title = Reshenie problemy van-der-Vardena dlya permanentov
 | year = 1980}}. {{citation
 | last = Egorychev | first = G. P.
 | issue = 6
 | journal = Akademiya Nauk SSSR
 | language = Russian
 | mr = 638007
 | pages = 65–71, 225
 | title = Proof of the van der Waerden conjecture for permanents
 | volume = 22
 | year = 1981}}. {{citation
 | last = Egorychev | first = G. P.
 | doi = 10.1016/0001-8708(81)90044-X
 | issue = 3
 | journal = Advances in Mathematics
 | mr = 642395
 | pages = 299–305
 | title = The solution of van der Waerden's problem for permanents
 | volume = 42
 | year = 1981}}.&lt;/ref&gt; and D. I. Falikman;&lt;ref&gt;{{citation
 | last = Falikman | first = D. I.
 | issue = 6
 | journal = Akademiya Nauk Soyuza SSR
 | language = Russian
 | mr = 625097
 | pages = 931–938, 957
 | title = Proof of the van der Waerden conjecture on the permanent of a doubly stochastic matrix
 | volume = 29
 | year = 1981}}.&lt;/ref&gt; Egorychev's proof is an application of the [[Alexandrov&amp;ndash;Fenchel inequality]].&lt;ref name=CMC487&gt;Brualdi (2006) p.487&lt;/ref&gt; For this work, Egorychev and Falikman won the [[Fulkerson Prize]] in 1982.&lt;ref&gt;[http://www.mathopt.org/?nav=fulkerson Fulkerson Prize], Mathematical Optimization Society, retrieved 2012-08-19.&lt;/ref&gt;

== Computation ==
{{main|Computing the permanent|Sharp-P-completeness of 01-permanent}}
The naïve approach, using the definition, of computing permanents is computationally infeasible even for relatively small matrices. One of the fastest known algorithms is due to [[H. J. Ryser]] ({{harvtxt|Ryser|1963|loc=p. 27}}). [[Ryser's formula|Ryser’s method]] is based on an [[inclusion–exclusion principle|inclusion–exclusion]] formula that can be given&lt;ref&gt;{{harvtxt|van Lint|Wilson|2001}} [https://books.google.com/books?id=5l5ps2JkyT0C&amp;pg=PA108&amp;dq=permanent+ryser&amp;lr=#PPA99,M1 p. 99]&lt;/ref&gt; as follows: Let &lt;math&gt;A_k&lt;/math&gt; be obtained from ''A'' by deleting ''k'' columns, let &lt;math&gt;P(A_k)&lt;/math&gt; be the product of the row-sums of &lt;math&gt;A_k&lt;/math&gt;, and  let &lt;math&gt;\Sigma_k&lt;/math&gt; be the sum of the values of &lt;math&gt;P(A_k)&lt;/math&gt; over all possible &lt;math&gt;A_k&lt;/math&gt;. Then  
:&lt;math&gt; \operatorname{perm}(A)=\sum_{k=0}^{n-1} (-1)^{k}\Sigma_k.&lt;/math&gt;

It may be rewritten in terms of the matrix entries as follows:
: &lt;math&gt;\operatorname{perm} (A) = (-1)^n \sum_{S\subseteq\{1,\dots,n\}} (-1)^{|S|} \prod_{i=1}^n \sum_{j\in S} a_{ij}.&lt;/math&gt;

The permanent is believed to be more difficult to compute than the determinant. While the determinant can be computed in [[polynomial time]] by [[Gaussian elimination]], Gaussian elimination cannot be used to compute the permanent. Moreover, computing the permanent of a (0,1)-matrix is [[sharp-P-complete|#P-complete]]. Thus, if the permanent can be computed in polynomial time by any method, then '''[[FP (complexity)|FP]]&amp;nbsp;=&amp;nbsp;[[sharp-P|#P]]''', which is an even stronger statement than [[P = NP problem|P&amp;nbsp;=&amp;nbsp;NP]]. When the entries of ''A'' are nonnegative, however, the permanent can be computed [[approximation algorithm|approximately]] in [[randomized algorithm|probabilistic]] polynomial time, up to an error of &lt;math&gt;\varepsilon M&lt;/math&gt;, where &lt;math&gt;M&lt;/math&gt; is the value of the permanent and &lt;math&gt;\varepsilon &gt; 0 &lt;/math&gt; is arbitrary.&lt;ref&gt;{{Citation|last1= Jerrum | first1= M.|author1-link= Mark Jerrum |last2=Sinclair | first2= A.|author2-link=  Alistair Sinclair|last3=Vigoda | first3= E.|title=A polynomial-time approximation algorithm for the permanent of a matrix with nonnegative entries |journal=[[Journal of the ACM]] |year=2004 |volume= 51 |pages= 671–697 | doi=10.1145/1008731.1008738}}&lt;/ref&gt; The permanent of a certain set of [[positive definite matrix|positive semidefinite matrices]] can also be approximated in probabilistic polynomial time: the best achievable error of this approximation is &lt;math&gt;\varepsilon\sqrt{M}&lt;/math&gt; (&lt;math&gt;M&lt;/math&gt; is again the value of the permanent).&lt;ref&gt;{{cite journal|last1=Chakhmakhchyan|first1=Levon|last2=Cerf|first2=Nicolas|last3=Garcia-Patron|first3=Raul|title=A quantum-inspired algorithm for estimating the permanent of positive semidefinite matrices| journal = Phys. Rev. A|volume=96 |issue=2|pages=022329 |doi=10.1103/PhysRevA.96.022329|year=2017|bibcode=2017PhRvA..96b2329C|arxiv=1609.02416}}&lt;/ref&gt;

==MacMahon's Master Theorem==
{{main|MacMahon Master theorem}}
Another way to view permanents is via multivariate [[generating function]]s. Let &lt;math&gt;A = (a_{ij})&lt;/math&gt; be a square matrix of order ''n''. Consider the multivariate generating function:
:&lt;math&gt;F(x_1,x_2,\dots,x_n) = \prod_{i=1}^n \left ( \sum_{j=1}^n a_{ij} x_j \right ) &lt;/math&gt;
:&lt;math&gt;= \left ( \sum_{j=1}^n a_{1j} x_j \right ) \left ( \sum_{j=1}^n a_{2j} x_j \right ) \cdots \left ( \sum_{j=1}^n a_{nj} x_j \right ).&lt;/math&gt;
The coefficient of  &lt;math&gt;x_1 x_2 \dots x_n&lt;/math&gt; in &lt;math&gt;F(x_1,x_2,\dots,x_n)&lt;/math&gt; is perm(''A'').&lt;ref&gt;{{harvnb|Percus|1971|loc=p. 14}}&lt;/ref&gt;

As a generalization, for any sequence of ''n'' non-negative integers, &lt;math&gt;s_1,s_2,\dots,s_n&lt;/math&gt; define:
:&lt;math&gt;\operatorname{perm}^{(s_1,s_2,\dots,s_n)}(A)&lt;/math&gt;  as the coefficient of &lt;math&gt;x_1^{s_1} x_2^{s_2} \cdots x_n^{s_n} &lt;/math&gt; in&lt;math&gt;\left ( \sum_{j=1}^n a_{1j} x_j \right )^{s_1} \left ( \sum_{j=1}^n a_{2j} x_j \right )^{s_2} \cdots \left ( \sum_{j=1}^n a_{nj} x_j \right )^{s_n}.&lt;/math&gt; 
: 
'''MacMahon's Master Theorem''' relating permanents and determinants is:&lt;ref&gt;{{harvnb|Percus|1971|loc=p. 17}}&lt;/ref&gt;
:&lt;math&gt;\operatorname{perm}^{(s_1,s_2,\dots,s_n)}(A) = \text{ coefficient of }x_1^{s_1} x_2^{s_2} \cdots x_n^{s_n} \text{ in } \frac{1}{\det(I - XA)},&lt;/math&gt;
where ''I'' is the order ''n'' identity matrix and ''X'' is the diagonal matrix with diagonal &lt;math&gt;[x_1,x_2,\dots,x_n].&lt;/math&gt;

==Permanents of rectangular matrices==
The permanent function can be generalized to apply to non-square matrices. Indeed, several authors make this the definition of a permanent and consider the restriction to square matrices a special case.&lt;ref&gt;In particular, {{harvtxt|Minc|1984}} and {{harvtxt|Ryser|1963}} do this.&lt;/ref&gt; Specifically, for an ''m''&amp;nbsp;×&amp;nbsp;''n'' matrix &lt;math&gt;A = (a_{ij})&lt;/math&gt; with ''m''&amp;nbsp;≤&amp;nbsp;''n'', define
:&lt;math&gt;\operatorname{perm} (A) = \sum_{\sigma \in \operatorname{P}(n,m)} a_{1 \sigma(1)} a_{2 \sigma(2)} \ldots a_{m \sigma(m)}&lt;/math&gt;
where P(''n'',''m'') is the set of all ''m''-permutations of the ''n''-set {1,2,...,n}.&lt;ref&gt;{{harvnb|Ryser|1963|loc=p. 25}}&lt;/ref&gt;

Ryser's computational result for permanents also generalizes. If ''A'' is an ''m''&amp;nbsp;×&amp;nbsp;''n'' matrix with ''m''&amp;nbsp;≤&amp;nbsp;''n'', let &lt;math&gt;A_k&lt;/math&gt; be obtained from ''A'' by deleting ''k'' columns, let &lt;math&gt;P(A_k)&lt;/math&gt; be the product of the row-sums of &lt;math&gt;A_k&lt;/math&gt;, and  let &lt;math&gt;\sigma_k&lt;/math&gt; be the sum of the values of &lt;math&gt;P(A_k)&lt;/math&gt; over all possible &lt;math&gt;A_k&lt;/math&gt;. Then  
:&lt;math&gt; \operatorname{perm}(A)=\sum_{k=0}^{m-1} (-1)^{k}\binom{n-m+k}{k}\sigma_{n-m+k}.&lt;/math&gt;&lt;ref name="Ryser 1963 loc=p. 26"/&gt;

===Systems of distinct representatives===
The generalization of the definition of a permanent to non-square matrices allows the concept to be used in a more natural way in some applications. For instance:

Let ''S''&lt;sub&gt;1&lt;/sub&gt;, ''S''&lt;sub&gt;2&lt;/sub&gt;, ..., ''S''&lt;sub&gt;''m''&lt;/sub&gt; be subsets (not necessarily distinct) of an ''n''-set with ''m''&amp;nbsp;≤&amp;nbsp;''n''. The [[incidence matrix]] of this collection of subsets is an ''m''&amp;nbsp;×&amp;nbsp;''n'' (0,1)-matrix ''A''. The number of [[transversal (combinatorics)|systems of distinct representatives]] (SDR's) of this collection is perm(''A'').&lt;ref&gt;{{harvnb|Ryser|1963|loc=p. 54}}&lt;/ref&gt;

==See also==
*[[Computing the permanent]]
*[[Bapat–Beg theorem]], an application of permanents in [[order statistics]]
*[[Slater determinant]], an application of permanents in [[quantum mechanics]]

==Notes==
{{reflist|30em}}

==References==

*{{cite book | zbl=1106.05001 | last=Brualdi | first=Richard A. | authorlink=Richard A. Brualdi | title=Combinatorial matrix classes | series=Encyclopedia of Mathematics and Its Applications | volume=108 | location=Cambridge | publisher=[[Cambridge University Press]] | year=2006 | isbn=0-521-86565-4 }}
*{{cite book | last=Minc | first=Henryk | title= Permanents | others=With a foreword by Marvin Marcus | series=Encyclopedia of Mathematics and its Applications | volume=6| publisher=Addison–Wesley | year= 1978 | issn=0953-4806 | oclc=3980645 | zbl=0401.15005 | location=Reading, MA }}
*{{Cite book| last=Muir | first=Thomas |author2=William H. Metzler.| year=1960 | origyear=1882| title = A Treatise on the Theory of Determinants |location=New York| publisher=Dover | oclc=535903}}
*{{citation|first=J.K.|last=Percus|title=Combinatorial Methods|series=Applied Mathematical Sciences #4|publisher=Springer-Verlag|place=New York|year=1971|isbn=0-387-90027-6}}
*{{citation|first=Herbert John|last=Ryser|authorlink=H. J. Ryser|title=Combinatorial Mathematics|series=The Carus Mathematical Monographs #14|year=1963|publisher=The Mathematical Association of America}}
*{{citation|last1=van Lint|first1=J.H. |last2=Wilson|first2=R.M. |title=A Course in Combinatorics|publisher=Cambridge University Press|year= 2001|isbn=0521422604}}

==Further reading==
* {{citation|first=Marshall|last=Hall, Jr.| authorlink=Marshall Hall (mathematician)|title=Combinatorial Theory|edition=2nd|year=1986|publisher=John Wiley &amp; Sons|place=New York|isbn=0-471-09138-3|pages=56&amp;ndash;72}} Contains a proof of the Van der Waerden conjecture.
* {{citation|first1=M.|last1=Marcus|first2=H.|last2=Minc|title=Permanents|journal=The American Mathematical Monthly|volume=72|year=1965|pages=577&amp;ndash;591|doi=10.2307/2313846}}

==External links==
*[http://planetmath.org/encyclopedia/Permanent.html Permanent at PlanetMath]
*{{planetmath reference|id= 6935|title=Van der Waerden's permanent conjecture}}

[[Category:Algebra]]
[[Category:Linear algebra]]
[[Category:Matrix theory]]
[[Category:Permutations]]</text>
      <sha1>fhvyuwtai9z7i1mx5nr0qryc6tiu0tn</sha1>
    </revision>
  </page>
  <page>
    <title>Primefree sequence</title>
    <ns>0</ns>
    <id>2716293</id>
    <revision>
      <id>855350937</id>
      <parentid>833442656</parentid>
      <timestamp>2018-08-17T17:24:46Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted the phrase "it is obvious that"  - see [[Wikipedia:Manual_of_Style/Words_to_watch#Editorializing]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5309">In [[mathematics]], a '''primefree sequence''' is a [[sequence]] of [[integer]]s that does not contain any [[prime number]]s. More specifically, it usually means a sequence defined by the same [[recurrence relation]] as the [[Fibonacci number]]s, but with different [[initial conditions]] causing all members of the sequence to be [[composite number]]s that do not all have a common [[divisor]]. To put it algebraically, a sequence of this type is defined by an appropriate choice of two composite numbers ''a''&lt;sub&gt;1&lt;/sub&gt; and ''a''&lt;sub&gt;2&lt;/sub&gt;, such that the [[greatest common divisor]] GCD(''a''&lt;sub&gt;1&lt;/sub&gt;,''a''&lt;sub&gt;2&lt;/sub&gt;) is equal to 1, and such that for ''n''&amp;nbsp;&amp;gt;&amp;nbsp;2 there are no primes in the sequence of numbers calculated from the formula
:''a''&lt;sub&gt;''n''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''a''&lt;sub&gt;''n''&amp;nbsp;&amp;minus;&amp;nbsp;1&lt;/sub&gt;&amp;nbsp;+&amp;nbsp;''a''&lt;sub&gt;''n''&amp;nbsp;&amp;minus;&amp;nbsp;2&lt;/sub&gt;.

==Wilf's sequence==
Perhaps the best known primefree sequence is the one found by [[Herbert Wilf]], with initial terms 

:''a''&lt;sub&gt;1&lt;/sub&gt; = 20615674205555510, ''a''&lt;sub&gt;2&lt;/sub&gt; = 3794765361567513 {{OEIS|id=A083216}}.

The proof that every term of this sequence is composite relies on the periodicity of Fibonacci-like number sequences modulo the members of a finite set of primes. For each prime ''p'', the positions in the sequence where the numbers are divisible by ''p'' repeat in a periodic pattern, and different primes in the set have overlapping patterns that result in a [[covering set]] for the whole sequence.

==Nontriviality==
The requirement that the initial terms of a primefree sequence be coprime is necessary for the question to be non-trivial. If we allow the initial terms to share a prime factor ''p'' (e.g., set ''a''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''xp'' and ''a''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;''yp'' for some ''x'' and ''y'' both greater than 1), due to the [[distributivity|distributive property]] of [[multiplication]] ''a''&lt;sub&gt;3&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;(''x''&amp;nbsp;+&amp;nbsp;''y'')''p'' and more generally all subsequent value in the sequence will be multiples of ''p''. In this case, all the numbers in the sequence will be composite, but for a trivial reason.

The order of the initial terms is also important. In [[Paul Hoffman (science writer)|Paul Hoffman]]'s biography of [[Paul Erdős]], ''[[The man who loved only numbers]]'', the Wilf sequence is cited but with the initial terms switched. The resulting sequence appears primefree for the first hundred terms or so, but term 138 is the 45-digit prime 439351292910452432574786963588089477522344721.&lt;ref&gt;{{Cite OEIS|sequencenumber=A108156}}&lt;/ref&gt;

==Other sequences==
Several other primefree sequences are known:
:''a''&lt;sub&gt;1&lt;/sub&gt; = 331635635998274737472200656430763, ''a''&lt;sub&gt;2&lt;/sub&gt; = 1510028911088401971189590305498785 (sequence [[OEIS:A083104|A083104]] in the [[On-Line Encyclopedia of Integer Sequences|OEIS]]; Graham 1964),
:''a''&lt;sub&gt;1&lt;/sub&gt; = 62638280004239857, ''a''&lt;sub&gt;2&lt;/sub&gt; = 49463435743205655 (sequence [[OEIS:A083105|A083105]] in the OEIS; Knuth 1990), and
:''a''&lt;sub&gt;1&lt;/sub&gt; = 407389224418, ''a''&lt;sub&gt;2&lt;/sub&gt; = 76343678551 (sequence [[OEIS:A082411|A082411]] in  the OEIS; Nicol 1999).
The sequence of this type with the smallest known initial terms has
:''a''&lt;sub&gt;1&lt;/sub&gt; = 106276436867, ''a''&lt;sub&gt;2&lt;/sub&gt; = 35256392432 (sequence [[OEIS:A221286|A221286]] in the OEIS; Vsemirnov 2004).

==Notes==
{{reflist}}

== References ==
*{{cite journal
 |doi        = 10.2307/2689243
 |author     = Graham, Ronald L.
 |authorlink = Ronald L. Graham
 |title      = A Fibonacci-like sequence of composite numbers
 |journal    = Mathematics Magazine
 |volume     = 37
 |year       = 1964
 |issue      = 5
 |url        = http://www.math.ucsd.edu/~sbutler/ron/64_06_fibonacci.pdf
 |pages      = 322–324
 |jstor      = 2689243
}}{{dead link|date=March 2018 |bot=InternetArchiveBot |fix-attempted=yes }}
*{{cite journal
 | doi = 10.2307/2691504
 | author = Knuth, Donald E.
 | authorlink = Donald Knuth
 | title = A Fibonacci-like sequence of composite numbers
 | journal = Mathematics Magazine
 | volume = 63
 | issue = 1
 | pages = 21–25
 | year = 1990
 |mr=1042933
 | jstor = 2691504}}
*{{cite journal
 | author = Wilf, Herbert S.
 | authorlink = Herbert Wilf
 | title = Letters to the Editor
 | journal = Mathematics Magazine
 | volume = 63
 | pages = 284
 | year = 1990}}
*{{cite journal
 | author = Nicol, John W.
 | title = A Fibonacci-like sequence of composite numbers
 | journal = Electronic Journal of Combinatorics
 | volume = 6
 | issue = 1
 | year = 1999
 | pages = 44
 | url = http://www.combinatorics.org/Volume_6/PDF/v6i1r44.pdf
 |mr=1728014}}
*{{cite journal
 | author = Vsemirnov, M.
 | title = A new Fibonacci-like sequence of composite numbers
 | journal = Journal of Integer Sequences
 | volume = 7
 | year = 2004
 | issue = 3
 | pages = 04.3.7
 |mr=2110778
 | url = http://www.emis.ams.org/journals/JIS/VOL7/Vsemirnov/vsem5.pdf}}

== External links ==
*[http://www.primepuzzles.net/problems/prob_031.htm Problem 31.  Fibonacci- all composites sequence]. The prime puzzles and problems connection.
*{{planetmath reference|id=7917|title=Primefree sequence}}
*{{mathworld | title = Primefree Sequence | urlname = PrimefreeSequence}}

[[Category:Integer sequences]]
[[Category:Number theory]]
[[Category:Recurrence relations]]</text>
      <sha1>mf819ny9816jl39b8kgxo4ke3llz52b</sha1>
    </revision>
  </page>
  <page>
    <title>Ramified theory of types</title>
    <ns>0</ns>
    <id>7218685</id>
    <redirect title="Principia Mathematica" />
    <revision>
      <id>764256313</id>
      <parentid>334929294</parentid>
      <timestamp>2017-02-07T22:31:06Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>[[WP:AES|←]]Redirected page to [[Principia Mathematica#Ramified types and the axiom of reducibility]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="130">#REDIRECT[[Principia Mathematica#Ramified types and the axiom of reducibility]]
{{R with possibilities}}

[[Category:Type theory]]</text>
      <sha1>46ibmd4san8u99oj9phy1mc0fmjz8be</sha1>
    </revision>
  </page>
  <page>
    <title>Range criterion</title>
    <ns>0</ns>
    <id>5442412</id>
    <revision>
      <id>855357080</id>
      <parentid>686324896</parentid>
      <timestamp>2018-08-17T18:16:19Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted the phrase "it is obvious that"  - see [[Wikipedia:Manual_of_Style/Words_to_watch#Editorializing]].  It is not obvious to over 99% of Wikipedia readers, who belong to a general audience and are not mathematicians.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2984">In [[quantum mechanics]], in particular [[quantum information]], the '''Range criterion''' is a necessary condition that a state must satisfy in order to be [[separable states|separable]]. In other words, it is a ''separability criterion''.

== The result ==

Consider a quantum mechanical system composed of ''n'' subsystems. The state space ''H'' of such a system is the tensor product of those of the subsystems, i.e. &lt;math&gt;H = H_1 \otimes \cdots \otimes H_n&lt;/math&gt;.

For simplicity we will assume throughout that all relevant state spaces are finite-dimensional.

The criterion reads as follows: If ρ is a separable mixed state acting on ''H'', then the range of ρ is spanned by a set of product vectors.

=== Proof ===

In general, if a matrix ''M'' is of the form &lt;math&gt;M = \sum_i v_i v_i^*&lt;/math&gt;, the range of ''M'', ''Ran(M)'', is contained in the linear span of &lt;math&gt;\; \{ v_i \}&lt;/math&gt;. On the other hand, we can also show &lt;math&gt;v_i&lt;/math&gt; lies in ''Ran(M)'', for all ''i''. Assume without loss of generality ''i = 1''. We can write
&lt;math&gt;M = v_1 v_1 ^* + T&lt;/math&gt;, where ''T'' is Hermitian and positive semidefinite. There are two possibilities:

1) ''span''&lt;math&gt;\{ v_1 \} \subset&lt;/math&gt;''Ker(T)''. Clearly, in this case, &lt;math&gt;v_1 \in&lt;/math&gt; ''Ran(M)''.

2) Notice 1) is true if and only if ''Ker(T)''&lt;math&gt;\;^{\perp} \subset&lt;/math&gt; ''span''&lt;math&gt;\{ v_1 \}^{\perp}&lt;/math&gt;, where &lt;math&gt;\perp&lt;/math&gt; denotes orthogonal complement. By Hermiticity of ''T'', this is the same as ''Ran(T)''&lt;math&gt;\subset&lt;/math&gt; ''span''&lt;math&gt;\{ v_1 \}^{\perp}&lt;/math&gt;. So if 1) does not hold, the intersection ''Ran(T)'' &lt;math&gt;\cap&lt;/math&gt; ''span''&lt;math&gt;\{ v_1 \}&lt;/math&gt; is nonempty, i.e. there exists some complex number α such that &lt;math&gt;\; T w = \alpha v_1&lt;/math&gt;. So 

:&lt;math&gt;M w = \langle w, v_1 \rangle v_1 + T w = ( \langle w, v_1 \rangle + \alpha ) v_1.&lt;/math&gt;

Therefore &lt;math&gt;v_1&lt;/math&gt; lies in ''Ran(M)''.

Thus ''Ran(M)'' coincides with the linear span of &lt;math&gt;\; \{ v_i \}&lt;/math&gt;. The range criterion is a special case of this fact.

A density matrix ρ acting on ''H'' is separable if and only if it can be written as 

:&lt;math&gt;\rho = \sum_i \psi_{1,i} \psi_{1,i}^* \otimes \cdots \otimes \psi_{n,i} \psi_{n,i}^*&lt;/math&gt; 

where &lt;math&gt;\psi_{j,i} \psi_{j,i}^*&lt;/math&gt; is a (un-normalized) pure state on the ''j''-th subsystem. This is also

:&lt;math&gt;
\rho = \sum_i ( \psi_{1,i} \otimes \cdots \otimes \psi_{n,i} ) ( \psi_{1,i} ^* \otimes \cdots \otimes \psi_{n,i} ^* ).
&lt;/math&gt; 

But this is exactly the same form as ''M'' from above, with the vectorial product state &lt;math&gt;\psi_{1,i} \otimes \cdots \otimes \psi_{n,i}&lt;/math&gt; replacing &lt;math&gt;v_i&lt;/math&gt;. It then immediately follows that the range of ρ is the linear span of these product states. This proves the criterion.

== References ==

* P. Horodecki, "Separability Criterion and Inseparable Mixed States with Positive Partial Transposition", ''Physics Letters'' '''A 232''', (1997).

[[Category:Quantum information science]]</text>
      <sha1>esl1kc4j0lci0kqq3mnv1yv5c5ixrqb</sha1>
    </revision>
  </page>
  <page>
    <title>Star product</title>
    <ns>0</ns>
    <id>2518933</id>
    <revision>
      <id>763697860</id>
      <parentid>763676612</parentid>
      <timestamp>2017-02-04T19:02:01Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>undid test edits</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1726">:''The term "Star product" may also refer to the [[Moyal product]]''.
In [[mathematics]], the '''star product''' is a method of combining [[graded poset]]s with unique minimal and maximal elements, preserving the property that the posets are [[Eulerian poset|Eulerian]].

==Definition==
The star product of two [[graded poset]]s &lt;math&gt;(P,\le_P)&lt;/math&gt; and &lt;math&gt;(Q,\le_Q)&lt;/math&gt;, where &lt;math&gt;P&lt;/math&gt; has a unique [[maximal element]] &lt;math&gt;\widehat{1}&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; has a unique minimal element &lt;math&gt;\widehat{0}&lt;/math&gt;, is a [[poset]] &lt;math&gt;P*Q&lt;/math&gt; on the set &lt;math&gt;(P\setminus\{\widehat{1}\})\cup(Q\setminus\{\widehat{0}\})&lt;/math&gt;. We define the [[partial order]] &lt;math&gt;\le_{P*Q}&lt;/math&gt; by &lt;math&gt;x\le y&lt;/math&gt; if and only if:

:1. &lt;math&gt;\{x,y\}\subset P&lt;/math&gt;, and &lt;math&gt;x\le_P y&lt;/math&gt;;
:2. &lt;math&gt;\{x,y\}\subset Q&lt;/math&gt;, and &lt;math&gt;x\le_Q y&lt;/math&gt;; or
:3. &lt;math&gt;x\in P&lt;/math&gt; and &lt;math&gt;y\in Q&lt;/math&gt;.

In other words, we pluck out the top of &lt;math&gt;P&lt;/math&gt; and the bottom of &lt;math&gt;Q&lt;/math&gt;, and require that everything in &lt;math&gt;P&lt;/math&gt; be smaller than everything in &lt;math&gt;Q&lt;/math&gt;.

==Example==
For example, suppose &lt;math&gt;P&lt;/math&gt; and &lt;math&gt;Q&lt;/math&gt; are the [[Two-element Boolean algebra|Boolean algebra]] on two elements.

[[Image:star product 1.png]] 

Then &lt;math&gt;P*Q&lt;/math&gt; is the poset with the [[Hasse diagram]] below.

[[Image:star product 3.png]]

==Properties==
The star product of [[Eulerian poset]]s is Eulerian.

==See also==
*[[Product order]], a different way of combining posets

==References==
* Stanley, R., Flag &lt;math&gt;f&lt;/math&gt;-vectors and the &lt;math&gt;\mathbf{cd}&lt;/math&gt;-index, Math. Z. 216 (1994), 483-499. 


{{PlanetMath attribution|id=5574|title=star product}}

[[Category:Combinatorics]]</text>
      <sha1>6era9fgjbvfhtwm500gl1ygwgs281bu</sha1>
    </revision>
  </page>
  <page>
    <title>Strength (mathematical logic)</title>
    <ns>0</ns>
    <id>28870339</id>
    <revision>
      <id>799570786</id>
      <parentid>786595876</parentid>
      <timestamp>2017-09-08T14:41:48Z</timestamp>
      <contributor>
        <username>RJGray</username>
        <id>8268674</id>
      </contributor>
      <comment>/* top */ links</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="721">The relative '''strength''' of two systems of [[formal logic]] can be defined via [[model theory]]. Specifically, a logic &lt;math&gt;\alpha&lt;/math&gt; is said to be as strong as a logic &lt;math&gt;\beta&lt;/math&gt; if every [[elementary class]] in &lt;math&gt;\beta&lt;/math&gt; is an elementary class in  &lt;math&gt;\alpha&lt;/math&gt;.&lt;ref&gt;[[Heinz-Dieter Ebbinghaus]] ''Extended logics: the general framework'' in [[Jon Barwise|K. J. Barwise]] and [[Solomon Feferman|S. Feferman]], editors, ''Model-theoretic logics'', 1985 {{isbn|0-387-90936-2}} page 43&lt;/ref&gt;

==See also==
* [[Abstract logic]]
* [[Lindström's theorem]]

==References==
{{Reflist}}

[[Category:Model theory]] 
[[Category:Mathematical logic]]
[[Category:Concepts in logic]]

{{mathlogic-stub}}</text>
      <sha1>5tvu9r4khj3gyrzt9m8ptvgx3sdga57</sha1>
    </revision>
  </page>
  <page>
    <title>Strongly connected component</title>
    <ns>0</ns>
    <id>684680</id>
    <revision>
      <id>863307635</id>
      <parentid>848558902</parentid>
      <timestamp>2018-10-09T23:39:25Z</timestamp>
      <contributor>
        <ip>27.242.36.208</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10773">[[Image:Scc.png|thumb|Graph with strongly connected components marked]]
In the mathematical theory of [[directed graph]]s, a graph is said to be '''strongly connected''' or '''diconnected'''&lt;!-- THIS IS NOT A TYPO FOR DISCONNECTED --&gt; if every vertex is [[reachability|reachable]] from every other vertex. The '''strongly connected components''' or '''diconnected components''' of an arbitrary directed graph form a [[Partition of a set|partition]] into subgraphs that are themselves strongly connected. It is possible to test the strong connectivity of a graph, or to find its strongly connected components, in [[linear time]] (that is, Θ(V+E)).

==Definitions==
A [[directed graph]] is called '''strongly connected''' if there is a [[path (graph theory)|path]] in each direction between each pair of vertices of the graph. That is, a path exists from the first vertex in the pair to the second, and another path exists from the second vertex to the first.
In a directed graph ''G'' that may not itself be strongly connected, a pair of vertices ''u'' and ''v'' are said to be strongly connected to each other if there is a path in each direction between them.

The [[binary relation]] of being strongly connected is an [[equivalence relation]], and the [[induced subgraph]]s of its [[equivalence class]]es are called '''strongly connected components'''.
Equivalently, a '''strongly connected component''' of a directed graph ''G'' is a subgraph that is strongly connected, and is [[maximal element|maximal]] with this property: no additional edges or vertices from ''G'' can be included in the subgraph without breaking its property of being strongly connected. The collection of strongly connected components forms a [[partition of a set|partition]] of the set of vertices of ''G''.

[[File:Graph Condensation.svg|thumb|upright=1.5|The yellow [[directed acyclic graph]] is the condensation of the blue directed graph. It is formed by contracting each strongly connected component of the blue graph into a single yellow vertex.]]
If each strongly connected component is [[vertex contraction|contracted]] to a single vertex, the resulting graph is a [[directed acyclic graph]], the '''condensation''' of ''G''. A directed graph is acyclic if and only if it has no strongly connected subgraphs with more than one vertex, because a directed cycle is strongly connected and every nontrivial strongly connected component contains at least one directed cycle.

==Algorithms==
===DFS-based linear-time algorithms===
Several algorithms based on [[depth first search]] compute strongly connected components in [[linear time]].
*[[Kosaraju's algorithm]] uses two passes of [[depth first search]]. The first, in the original graph, is used to choose the order in which the outer loop of the second depth first search tests vertices for having been visited already and recursively explores them if not. The second depth first search is on the [[transpose graph]] of the original graph, and each recursive exploration finds a single new strongly connected component.&lt;ref&gt;[[Thomas H. Cormen]], [[Charles E. Leiserson]], [[Ronald L. Rivest]], and [[Clifford Stein]]. ''[[Introduction to Algorithms]]'', Second Edition. MIT Press and McGraw-Hill, 2001. {{isbn|0-262-03293-7}}. Section 22.5, pp.&amp;nbsp;552&amp;ndash;557.&lt;/ref&gt;&lt;ref name="hong2013fast" /&gt; It is named after [[S. Rao Kosaraju]], who described it (but did not publish his results) in 1978; [[Micha Sharir]] later published it in 1981.&lt;ref&gt;[[Micha Sharir]]. A strong connectivity algorithm and its applications to data flow analysis.  ''Computers and Mathematics with Applications'' 7(1):67–72, 1981.&lt;/ref&gt;
*[[Tarjan's strongly connected components algorithm]], published by [[Robert Tarjan]] in 1972,&lt;ref&gt;{{citation|first=R. E.|last=Tarjan|authorlink=Robert Tarjan|title=Depth-first search and linear graph algorithms|journal=[[SIAM Journal on Computing]]|volume=1|year=1972|issue=2|pages=146–160|doi=10.1137/0201010}}&lt;/ref&gt; performs a single pass of depth first search. It maintains a [[Stack (abstract data type)|stack]] of vertices that have been explored by the search but not yet assigned to a component, and calculates "low numbers" of each vertex (an index number of the highest ancestor reachable in one step from a descendant of the vertex) which it uses to determine when a set of vertices should be popped off the stack into a new component.
*The [[path-based strong component algorithm]] uses a depth first search, like Tarjan's algorithm, but with two stacks. One of the stacks is used to keep track of the vertices not yet assigned to components, while the other keeps track of the current path in the depth first search tree. The first linear time version of this algorithm was published by [[Edsger W. Dijkstra]] in 1976.&lt;ref&gt;{{citation
 | last = Dijkstra | first = Edsger | author-link = Edsger Dijkstra
 | location = NJ
 | at = Ch.&amp;nbsp;25
 | publisher = Prentice Hall
 | title = A Discipline of Programming
 | year = 1976}}.&lt;/ref&gt;
Although Kosaraju's algorithm is conceptually simple, Tarjan's and the path-based algorithm require only one [[depth-first search]] rather than two.

===Reachability-based Algorithms===

Previous linear-time algorithms are based on [[depth-first search]] which is generally considered hard to parallelize.  Fleischer et al.&lt;ref name="Fleischer"&gt;Fleischer, Lisa K; Hendrickson, Bruce; and Pinar, Ali. [http://www.sandia.gov/~apinar/papers/irreg00.pdf On identifying strongly connected components in parallel]. IPDPS 2000.&lt;/ref&gt; in 2000 proposed a [[Divide and conquer algorithm|divide-and-conquer]] approach based on [[reachability]] queries, and such algorithms are usually called reachability-based SCC algorithms.  The idea of this approach is to pick a random pivot vertex and apply forward and backward reachability queries from this vertex.  The two queries partition the vertex set into 4 subsets: vertices reached by both, either one, or none of the searches.  One can show that a strongly connected component has to be contained in one of the subsets.  The vertex subset reached by both searches forms a strongly connected components, and the algorithm then recurses on the other 3 subsets.

The expected sequential running time of this algorithm is shown to be O(''n'' log ''n''), a factor of O(log ''n'') more than the classic algorithms.  The parallelism comes from: (1) the reachability queries can be parallelized more easily (e.g. by a [[Breadth-first search|BFS]], and it can be fast if the diameter of the graph is small); and (2) the independence between the subtasks in the divide-and-conquer process.
This algorithm performs well on real-world graphs,&lt;ref name="hong2013fast"&gt;Hong, Sungpack; Rodia, Nicole C; and Olukotun, Kunle. [https://ppl.stanford.edu/papers/sc13-hong.pdf On fast parallel detection of strongly connected components (SCC) in small-world graphs]. SC 2013.&lt;/ref&gt; but does not have theoretical guarantee on the parallelism (consider if a graph has no edges, the algorithm requires O(''n'') levels of recursions).

Blelloch et al.&lt;ref name="Parallel"&gt;Blelloch, Guy; Gu, Yan; Shun, Julian; and Sun, Yihan. [http://www.cs.cmu.edu/~ygu1/paper/SPAA16/Incremental.pdf Parallelism in Randomized Incremental Algorithms]. SPAA 2016. doi:10.1145/2935764.2935766.&lt;/ref&gt; in 2016 shows that if the reachability queries are applied in a random order, the cost bound of O(''n'' log ''n'') still holds.  Furthermore, the queries then can be batched in a prefix-doubling manner (i.e. 1, 2, 4, 8 queries) and run simultaneously in one round.  The overall [[Analysis of parallel algorithms|span]] of this algorithm is log&lt;sub&gt;2&lt;/sub&gt; ''n'' reachability queries, which is probably the optimal parallelism that can be achieved using the reachability-based approach.

==Applications==
Algorithms for finding strongly connected components may be used to solve [[2-satisfiability]] problems (systems of Boolean variables with constraints on the values of pairs of variables): as {{harvtxt|Aspvall|Plass|Tarjan|1979}} showed, a [[2-satisfiability]] instance is unsatisfiable if and only if there is a variable ''v'' such that ''v'' and its complement are both contained in the same strongly connected component of the [[implication graph]] of the instance.&lt;ref&gt;{{citation
 | last1 = Aspvall | first1 = Bengt
 | last2 = Plass | first2 = Michael F.
 | authorlink3 = Robert Tarjan | last3 = Tarjan | first3 = Robert E.
 | title = A linear-time algorithm for testing the truth of certain quantified boolean formulas
 | journal = Information Processing Letters
 | volume = 8 | issue = 3 | pages = 121–123 | year = 1979
 | doi = 10.1016/0020-0190(79)90002-4}}.&lt;/ref&gt;

Strongly connected components are also used to compute the [[Dulmage–Mendelsohn decomposition]], a classification of the edges of a [[bipartite graph]], according to whether or not they can be part of a [[perfect matching]] in the graph.&lt;ref&gt;{{citation |title=Coverings of bipartite graphs |first=A. L. |last=Dulmage |authorlink2=Nathan Mendelsohn |first2=N. S. |last2=Mendelsohn |lastauthoramp=yes |journal=Can. J. Math. |year=1958 |volume=10 |pages=517–534 |doi=10.4153/cjm-1958-052-0}}.&lt;/ref&gt;

==Related results==
A directed graph is strongly connected if and only if it has an [[ear decomposition]], a partition of the edges into a sequence of directed paths and cycles such that the first subgraph in the sequence is a cycle, and each subsequent subgraph is either a cycle sharing one vertex with previous subgraphs, or a path sharing its two endpoints with previous subgraphs.

According to [[Robbins' theorem]], an undirected graph may be [[graph orientation|oriented]] in such a way that it becomes strongly connected, if and only if it is [[k-edge-connected graph|2-edge-connected]]. One way to prove this result is to find an ear decomposition of the underlying undirected graph and then orient each ear consistently.&lt;ref&gt;{{citation
 | last = Robbins | first = H. E. | author-link = Herbert Robbins
 | journal = [[American Mathematical Monthly]]
 | jstor = 2303897
 | pages = 281–283
 | title = A theorem on graphs, with an application to a problem on traffic control
 | volume = 46
 | year = 1939
 | doi=10.2307/2303897}}.&lt;/ref&gt;

==See also==
* [[Clique (graph theory)|Clique]]
* [[Connected component (graph theory)|Connected component]]
* [[Modular decomposition]]

== References ==
{{reflist}}

== External links ==
* [http://code.google.com/p/jbpt/ Java implementation for computation of strongly connected components] in the jBPT library (see StronglyConnectedComponents class).
* [http://www.geeksforgeeks.org/tarjan-algorithm-find-strongly-connected-components/ C++ implementation of Strongly Connected Components]

[[Category:Graph connectivity]]
[[Category:Directed graphs]]</text>
      <sha1>t6w4zy9hujnerue5e76ofxntr1oq8qz</sha1>
    </revision>
  </page>
  <page>
    <title>Structured program theorem</title>
    <ns>0</ns>
    <id>1482138</id>
    <revision>
      <id>860865508</id>
      <parentid>860864372</parentid>
      <timestamp>2018-09-23T16:02:31Z</timestamp>
      <contributor>
        <ip>86.168.70.186</ip>
      </contributor>
      <comment>/* Origin and variants */ Corrected "the contents of the Böhm–Jacopini proof was..." to "the contents of the Böhm–Jacopini proof were..."</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="18906">The '''structured program theorem''', also called '''Böhm-Jacopini theorem''',&lt;ref name="kozen"&gt;{{cite journal|url= http://www.cs.cornell.edu/~kozen/papers/bohmjacopini.pdf |title=The Böhm–Jacopini Theorem Is False, Propositionally|author=[[Dexter Kozen]] and Wei-Lung Dustin Tseng|doi=10.1007/978-3-540-70594-9_11|journal=Mpc 2008|volume=5133|pages=177–192|series=Lecture Notes in Computer Science|year=2008|isbn=978-3-540-70593-2}}&lt;/ref&gt;&lt;ref&gt;{{cite web|url=http://www.cse.buffalo.edu/~rapaport/111F04/greatidea3.html |title=CSE 111, Fall 2004, BOEHM-JACOPINI THEOREM |publisher=Cse.buffalo.edu |date=2004-11-22 |accessdate=2013-08-24}}&lt;/ref&gt; is a result in [[programming language theory]]. It states that a class of [[control flow graph]]s (historically called [[Flowchart|charts]] in this context) can compute any [[computable function]] if it combines subprograms in only three specific ways ([[control structure]]s). These are
#Executing one subprogram, and then another subprogram (sequence)
#Executing one of two subprograms according to the value of a [[Boolean data type|boolean]] expression (selection)
#Repeatedly executing a subprogram as long as a boolean expression is true (iteration)

The structured chart subject to these constraints may however use additional variables in the form of [[bit]]s (stored in an extra integer variable in the original proof) in order to keep track of information that the original program represents by the program location. The construction was based on Böhm's programming language [[P′′]].

== Origin and variants ==
The theorem is typically credited&lt;ref name="Harel"/&gt;{{rp|381}} to a 1966 paper by [[Corrado Böhm]] and [[Giuseppe Jacopini]].&lt;ref&gt;{{cite journal|last=Bohm|first=Corrado|author2=Giuseppe Jacopini |date=May 1966|title=Flow Diagrams, Turing Machines and Languages with Only Two Formation Rules|journal=[[Communications of the ACM]]|volume=9|issue=5|pages=366–371|doi=10.1145/355592.365646}}&lt;/ref&gt; [[David Harel]] wrote in 1980 that the Böhm–Jacopini paper enjoyed "universal popularity",&lt;ref name="Harel"/&gt;{{rp|381}} particularly with proponents of structured programming. Harel also noted that "due to its rather technical style [the 1966 Böhm–Jacopini paper] is apparently more often cited than read in detail"&lt;ref name="Harel"/&gt;{{rp|381}} and, after reviewing a large number of papers published up to 1980, Harel argued that the contents of the Böhm–Jacopini proof were usually misrepresented as a [[Mathematical folklore|folk theorem]] that essentially contains a simpler result, a result which itself can be traced to the inception of modern computing theory in the papers of von Neumann and Kleene.&lt;ref name="Harel"/&gt;{{rp|383}}

Harel also writes that the more generic name was proposed by [[Harlan Mills|H.D. Mills]] as "The Structure Theorem" in the early 1970s.&lt;ref name="Harel"&gt;{{cite journal|last=Harel|first=David|authorlink=David Harel|year=1980|title=On Folk Theorems|journal=Communications of the ACM|volume=23|issue=7|pages=379–389|doi=10.1145/358886.358892|url=http://www.wisdom.weizmann.ac.il/~dharel/SCANNED.PAPERS/OnFolkTheorems.pdf}}&lt;/ref&gt;{{rp|381}}

=== Single-while-loop, folk version of the theorem ===
This version of the theorem replaces all the original program's control flow with a single global &lt;code&gt;while&lt;/code&gt; loop that simulates a [[program counter]] going over all possible labels (flowchart boxes) in the original non-structured program. Harel traced the origin of this folk theorem to two papers marking the beginning of computing. One is the 1946 description of the [[von Neumann architecture]], which explains how a [[program counter]] operates in terms of a while loop. Harel notes that the single loop used by the folk version of the structured programming theorem basically just provides [[operational semantics]] for the execution of a flowchart on a von Neumann computer.&lt;ref name="Harel"/&gt;{{rp|383}} Another, even older source that Harel traced the folk version of the theorem is [[Stephen Kleene]]'s [[Kleene's T predicate|normal form theorem]] from 1936.&lt;ref name="Harel"/&gt;{{rp|383}}

[[Donald Knuth]] criticized this form of the proof, which results in [[pseudocode]] like the one below, by pointing out that the structure of the original program is completely lost in this transformation.&lt;ref&gt;{{cite journal
 |  author = Donald Knuth
 |   title = Structured Programming with go to Statements
 | journal = Computing Surveys
 |  volume = 6
 |   issue = 4
 |    year = 1974
 |     url =
 |   pages = 261–301
 |   doi = 10.1145/356635.356640
}}&lt;/ref&gt;{{rp|274}} Similarly, Bruce Ian Mills wrote about this approach that "The spirit of block structure is a style, not a language. By simulating a Von Neumann machine, we can produce the behavior of any spaghetti code within the confines of a block-structured language. This does not prevent it from being spaghetti."&lt;ref name="Mills2005"&gt;{{cite book|author=Bruce Ian Mills|title=Theoretical Introduction to Programming|year=2005|publisher=Springer|isbn=978-1-84628-263-8|page=279}}&lt;/ref&gt;

&lt;source lang="Pascal"&gt;
p := 1;
while p &gt; 0 do begin
  if p = 1 then begin
    perform step 1 from the flowchart;
    p := resulting successor step number of step 1 from the flowchart (0 if no successor);
  end;
  if p = 2 then begin
    perform step 2 from the flowchart;
    p := resulting successor step of step 2 from the flowchart (0 if no successor);
  end;
  ...
  if p = n then begin
    perform step n from the flowchart;
    p := resulting successor step of step n from the flowchart (0 if no successor);
  end;
end.
&lt;/source&gt;

=== Böhm and Jacopini's proof ===
{{expand section|date=July 2014}}
The proof in Böhm and Jacopini's paper proceeds by [[structural induction|induction on the structure]] of the flow chart.&lt;ref name="Harel"/&gt;{{rp|381}} Because it employed [[Subgraph isomorphism problem|pattern matching in graphs]], the proof of Böhm and Jacopini's was not really practical as a [[program transformation]] algorithm, and thus opened the door for additional research in this direction.&lt;ref name="amma92"/&gt;

== Implications and refinements ==
The Böhm-Jacopini proof did not settle the question of whether to adopt [[structured programming]] for software development, partly because the construction was more likely to obscure a program than to improve it. On the contrary, it signalled the beginning of the debate. [[Edsger Dijkstra]]'s famous letter, "[[Go To Statement Considered Harmful]]," followed in 1968.&lt;ref&gt;{{cite journal|last=Dijkstra|first=Edsger|authorlink=Edsger W. Dijkstra|year=1968|title=Go To Statement Considered Harmful|journal=Communications of the ACM|volume=11|issue=3|pages=147–148|doi=10.1145/362929.362947|url=http://www.acm.org/classics/oct95/|deadurl=yes|archiveurl=https://web.archive.org/web/20070703050443/http://www.acm.org/classics/oct95/|archivedate=2007-07-03|df=}}&lt;/ref&gt;

Some academics took a purist approach to the Böhm-Jacopini result and argued that even instructions like &lt;code&gt;break&lt;/code&gt; and &lt;code&gt;return&lt;/code&gt; from the middle of loops are bad practice as they are not needed in the Böhm-Jacopini proof, and thus they advocated that all loops should have a single exit point. This purist approach is embodied in the [[Pascal (programming language)|Pascal programming language]] (designed in 1968–1969), which up to the mid-1990s was the preferred tool for teaching introductory programming classes in academia.&lt;ref name="roberts"&gt;Roberts, E. [1995] "[http://cs.stanford.edu/people/eroberts/papers/SIGCSE-1995/LoopExits.pdf Loop Exits and Structured Programming: Reopening the Debate]," ACM SIGCSE Bulletin, (27)1: 268–272.&lt;/ref&gt;

[[Edward Yourdon]] notes that in the 1970s there was even philosophical opposition to transforming unstructured programs into structured ones by automated means, based on the argument that one needed to think in structured programming fashion from the get go. The pragmatic counterpoint was that such transformations benefited a large body of existing programs.&lt;ref name="Yourdon1979"&gt;{{cite book|author=E. N. Yourdon|title=Classics in Software Engineering|year=1979|publisher=Yourdon Press|isbn=978-0-917072-14-7|pages=49–50}}&lt;/ref&gt; Among the first proposals for an automated transformation was a 1971 paper by Edward Ashcroft and [[Zohar Manna]].&lt;ref&gt;{{cite journal|last=Ashcroft|first=Edward|author2=Zohar Manna |year=1971|title=The translation of go to programs to 'while' programs|journal=[[Proceedings of IFIP Congress]]}} The paper, which is difficult to obtain in the original conference proceedings due to their limited distribution, was republished in Yourdon's 1979 book pp. 51-65&lt;/ref&gt;

The direct application of the Böhm-Jacopini theorem may result in additional local variables being introduced in the structured chart, and may also result in some [[code duplication]].&lt;ref name="WattFindlay2004"&gt;{{cite book|author1=David Anthony Watt|author2=William Findlay|title=Programming language design concepts|year=2004|publisher=John Wiley &amp; Sons|isbn=978-0-470-85320-7|page=228}}&lt;/ref&gt; The latter issue is called the [[loop and a half problem]] in this context.&lt;ref name="LoudenLambert2011"&gt;{{cite book|author1=Kenneth C. Louden|author2=Kenneth A. Lambert|title=Programming Languages: Principles and Practices|year=2011|publisher=Cengage Learning|isbn=1-111-52941-8|pages=422–423|edition=3}}&lt;/ref&gt; Pascal is affected by both of these problems and according to empirical studies cited by [[Eric S. Roberts]], student programmers had difficulty formulating correct solutions in Pascal for several simple problems, including writing a function for searching an element in an array. A 1980 study by Henry Shapiro cited by Roberts found that using only the Pascal-provided control structures, the correct solution was given by only 20% of the subjects, while no subject wrote incorrect code for this problem if allowed to write a return from the middle of a loop.&lt;ref name="roberts"/&gt;

In 1973, [[S. Rao Kosaraju]] proved that it's possible to avoid adding additional variables in structured programming, as long as arbitrary-depth, multi-level breaks from loops are allowed.&lt;ref name="kozen"/&gt;&lt;ref&gt;KOSARAJU, S. RAO. "Analysis of structured programs," Proc. Fifth Annual ACM Syrup.
Theory of Computing, (May 1973), 240-252; also in J. Computer and System Sciences, 9,
3 (December 1974), {{doi| 10.1016/S0022-0000(74)80043-7}} cited by {{cite journal
 |  author = [[Donald Knuth]]
 |   title = Structured Programming with go to Statements
 | journal = Computing Surveys
 |  volume = 6
 |   issue = 4
 |    year = 1974
 |     url =
 |   pages = 261–301
 |   doi = 10.1145/356635.356640
}}&lt;/ref&gt; Furthermore, Kosaraju proved that a strict hierarchy of programs exists, nowadays called the ''Kosaraju hierarchy'', in that for every integer ''n'', there exists a program containing a multi-level break of depth ''n'' that cannot be rewritten as program with multi-level breaks of depth less than ''n'' (without introducing additional variables).&lt;ref name="kozen"/&gt; Kosaraju cites the multi-level break construct to the [[BLISS]] programming language. The multi-level breaks, in the form a &lt;code&gt;leave ''label''&lt;/code&gt; keyword were actually introduced in the BLISS-11 version of that language; the original BLISS only had single-level breaks. The BLISS family of languages didn't provide an unrestricted goto. The [[Java (programming language)|Java programming language]] would later follow this approach as well.&lt;ref&gt;{{cite journal | doi = 10.1002/spe.470 | title=The BLISS programming language: a history | journal=Software: Practice and Experience | date=2002 | volume=32 | issue=10 | pages=955–981 | first=Ronald F. | last=Brender | url = http://www.cs.tufts.edu/~nr/cs257/archive/ronald-brender/bliss.pdf}}&lt;/ref&gt;{{rp|960–965}}

A simpler result from Kosaraju's paper is that a program is reducible to a structured program (without adding variables) if and only if it does not contain a loop with two distinct exits. Reducibility was defined by Kosaraju, loosely speaking, as computing the same function and using the same "primitive actions" and predicates as the original program, but possibly using different control flow structures. (This is a narrower notion of reducibility than what Böhm-Jacopini used.) Inspired by this result, in section VI of his highly-cited paper that introduced the notion of [[cyclomatic complexity]], Thomas J. McCabe described an analogue of [[Kuratowski's theorem]] for the [[control flow graph]]s (CFG) of non-structured programs, which is to say, the minimal [[Induced subgraph|subgraphs]] that make the CFG of a program non-structured. These subgraphs have a very good description in natural language. They are:
# branching out of a loop (other than from the loop cycle test)
# branching into a loop
# branching into a decision (i.e. into an if "branch")
# branching out of a decision
McCabe actually found that these four graphs are not independent when appearing as subgraphs, meaning that a necessary and sufficient condition for a program to be non-structured is for its CFG to have as subgraph one of any subset of three of these four graphs. He also found that if a non-structured program contains one of these four sub-graphs, it must contain another distinct one from the set of four. This latter result helps explain how the control flow of non-structured program becomes entangled in what is popularly called "[[spaghetti code]]". McCabe also devised a numerical measure that, given an arbitrary program, quantifies how far off it is from the ideal of being a structured program; McCabe called his measure [[essential complexity (numerical measure of "structuredness")|essential complexity]].&lt;ref name="McCabe"&gt;The original paper is {{cite journal |author=Thomas J. McCabe |date=December 1976 |journal=IEEE Transactions on Software Engineering |issue=4 |pages=315–318 |title=A Complexity Measure|url=https://books.google.com/books?id=vtNWAAAAMAAJ&amp;pg=PA3 |doi=10.1109/tse.1976.233837}} For a secondary exposition see {{cite book|author=Paul C. Jorgensen|title=Software Testing: A Craftsman's Approach, Second Edition|url=https://books.google.com/books?id=Yph_AwAAQBAJ&amp;pg=PA150|year=2002|publisher=CRC Press|isbn=978-0-8493-0809-3|pages=150–153|edition=2nd}}&lt;/ref&gt;

McCabe's characterization of the [[forbidden graph]]s for structured programming can be considered incomplete, at least if the Dijkstra's D structures are considered the building blocks.&lt;ref&gt;{{cite journal | doi = 10.1093/comjnl/26.3.270 | title=Flowchart Schemata and the Problem of Nomenclature | journal=The Computer Journal | date=1983 | volume=26 | issue=3 | pages=270–276 | first=M. H. | last=Williams}}&lt;/ref&gt;{{rp|274–275}}{{clarify|date=July 2014}}

Up to 1990 there were quite a few proposed methods for eliminating gotos from existing program, while preserving most of their structure. The various approaches to this problem also proposed several notions of equivalence, which are stricter than simply Turing equivalence, in order to avoid output like the folk theorem discussed above. The strictness of the chosen notion of equivalence dictates the minimal set of control flow structures needed. The 1988 [[JACM]] paper by Lyle Ramshaw surveys the field up to that point, as well proposing its own method.&lt;ref&gt;{{Cite journal | doi = 10.1145/48014.48021| title = Eliminating go to's while preserving program structure| journal = Journal of the ACM| volume = 35| issue = 4| pages = 893–920| year = 1988| last1 = Ramshaw | first1 = L. }}&lt;/ref&gt; Ramshaw's algorithm was used for example in some Java [[decompiler]]s because the [[Java virtual machine]] code has branch instructions with targets expressed as offsets, but the high-level Java language only has multi-level &lt;code&gt;break&lt;/code&gt; and &lt;code&gt;continue&lt;/code&gt; statements.&lt;ref name="Nolan2004"&gt;{{cite book|author=Godfrey Nolan|title=Decompiling Java|year=2004|publisher=Apress|isbn=978-1-4302-0739-9|page=142}}&lt;/ref&gt;&lt;ref&gt;https://www.usenix.org/legacy/publications/library/proceedings/coots97/full_papers/proebsting2/proebsting2.pdf&lt;/ref&gt;&lt;ref&gt;http://www.openjit.org/publications/pro1999-06/decompiler-pro-199906.pdf&lt;/ref&gt; Ammarguellat (1992) proposed a transformation method that goes back to enforcing single-exit.&lt;ref name="amma92"&gt;{{cite journal | doi = 10.1109/32.126773 | title=A control-flow normalization algorithm and its complexity | journal=IEEE Transactions on Software Engineering | date=1992 | volume=18 | issue=3 | pages=237–251 | first=Z. | last=Ammarguellat}}&lt;/ref&gt;

==Application to Cobol==
{{Refimprove section|date=August 2013}}
In the 1980s [[IBM]] researcher [[Harlan Mills]] oversaw the development of the [[COBOL Structuring Facility]], which applied a structuring algorithm to [[COBOL]] code. Mills's transformation involved the following steps for each procedure.

#Identify the [[basic block]]s in the procedure.
#Assign a unique [[Label (programming language)|label]] to each block's entry path, and label each block's exit paths with the labels of the entry paths they connect to. Use 0 for return from the procedure and 1 for the procedure's entry path.
#Break the procedure into its basic blocks.
#For each block that is the destination of only one exit path, reconnect that block to that exit path.
#Declare a new variable in the procedure (called L for reference).
#On each remaining unconnected exit path, add a statement that sets L to the label value on that path.
#Combine the resulting programs into a selection statement that executes the program with the entry path label indicated by L
#Construct a loop that executes this selection statement as long as L is not 0.
#Construct a sequence that initializes L to 1 and executes the loop.

Note that this construction can be improved by converting some cases of the selection statement into subprocedures.

==See also==
*[[Structured programming]]
*[[Turing completeness]]

==References==
{{reflist}}

==Further reading==
Material not yet covered above:
* {{cite journal | doi = 10.1145/322169.322180 | title=Space-Time Trade-Offs in Structured Programming: An Improved Combinatorial Embedding Theorem | journal=Journal of the ACM | date=1980 | volume=27 | issue=1 | pages=123–127 | first=Richard A. | last=DeMillo}}
* {{cite journal | doi = 10.1007/3-540-57785-8_128 | title=One binary horn clause is enough | journal=Lecture Notes in Computer Science | volume=775 | date=1994 | pages=19–32 | first=Philippe | last=Devienne| series=Lecture Notes in Computer Science | isbn=978-3-540-57785-0 }}

==External links==
* http://www.cs.uwlax.edu/~riley/CS421/lect8_boehm.ppt a slightly more detailed explanation of the construction used in the folk theorem's proof, with a concrete example of transformed program

[[Category:Programming language theory]]
[[Category:Models of computation]]
[[Category:Theorems in computational complexity theory]]</text>
      <sha1>ffiybm4yleeo6ho89xxi0yz4a9kul0b</sha1>
    </revision>
  </page>
  <page>
    <title>Surface integral</title>
    <ns>0</ns>
    <id>528867</id>
    <revision>
      <id>866352466</id>
      <parentid>866326853</parentid>
      <timestamp>2018-10-29T20:43:26Z</timestamp>
      <contributor>
        <username>LynxTufts</username>
        <id>29502899</id>
      </contributor>
      <comment>Reverted 1 edit by [[Special:Contributions/Pals4773|Pals4773]] ([[User talk:Pals4773|talk]]). ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13131">{{Calculus |Multivariable}}
{{Refimprove|date=January 2017}}

In [[mathematics]], a '''surface integral'''  is a generalization of [[multiple integral]]s to integration over [[surface (differential geometry)|surface]]s. It can be thought of as the [[double integral]] analog of the [[line integral]].  Given a surface, one may integrate over its [[scalar field]]s (that is, [[function (mathematics)|functions]] which return [[Scalar (mathematics)|scalars]] as values), and [[vector field]]s (that is, functions which return [[Vector (geometric)|vectors]] as values).

Surface integrals have applications in [[physics]], particularly with the theories of [[classical electromagnetism]].
[[Image:Surface integral illustration.svg|right|thumb|The definition of surface integral relies on splitting the surface into small surface elements.]]
[[Image:Surface integral1.svg|right|thumb|An illustration of a single surface element. These elements are made infinitesimally small, by the limiting process, so as to approximate the surface.]]

== Surface integrals of scalar fields ==
To find an explicit formula for the surface integral, we need to [[Coordinate system|parameterize]] the surface of interest, ''S'', by considering a system of [[curvilinear coordinates]] on ''S'', like the [[Geographic coordinate system|latitude and longitude]] on a [[sphere]]. Let such a parameterization be '''x'''(''s'', ''t''), where (''s'', ''t'') varies in some region ''T'' in the [[Cartesian coordinate system#Cartesian coordinates in two dimensions|plane]]. Then, the surface integral is given by

:&lt;math&gt;
\iint\limits_{S} f \,\mathrm dS
= \iint\limits_{T} f(\mathbf{x}(s, t)) \left\|{\partial \mathbf{x} \over \partial s}\times {\partial \mathbf{x} \over \partial t}\right\| \mathrm ds\, \mathrm dt
&lt;/math&gt;
where the expression between bars on the right-hand side is the [[Magnitude (mathematics)|magnitude]] of the [[cross product]] of the [[partial derivative]]s of '''x'''(''s'', ''t''), and is known as the surface [[volume element#Area_element_of_a_surface|element]].  The surface integral can also be expressed in the equivalent form

:&lt;math&gt;
\iint\limits_{S} f \,\mathrm d\Sigma
= \iint\limits_{T} f(\mathbf{x}(s, t)) \sqrt{g} \, \mathrm ds\, \mathrm dt
&lt;/math&gt;
where ''g'' is the determinant of the [[first fundamental form]] of the surface mapping '''x'''(''s'', ''t'').&lt;ref&gt;{{Cite book|title = Advanced Calculus of Several Variables|last = Edwards|first = C. H.|publisher = Dover|year = 1994|isbn = 0-486-68336-2|location = Mineola, NY|pages = 335}}&lt;/ref&gt;&lt;ref&gt;{{Cite book|title = Encyclopedia of Mathematics|last = Hazewinkel|first = Michiel|publisher = Springer|year = 2001|isbn = 978-1-55608-010-4|location = |pages = Surface Integral|url = https://www.encyclopediaofmath.org/index.php/Surface_integral}}&lt;/ref&gt;

For example, if we want to find the [[surface area]] of the graph of some scalar function, say &lt;math&gt;z=f\,(x,y)&lt;/math&gt;, we have
:&lt;math&gt;
A = \iint\limits_S \,\mathrm d\Sigma
= \iint\limits_T \left\|{\partial \mathbf{r} \over \partial x}\times {\partial \mathbf{r} \over \partial y}\right\| \mathrm dx\, \mathrm dy
&lt;/math&gt;
where &lt;math&gt;\mathbf{r}=(x, y, z)=(x, y, f(x,y))&lt;/math&gt;.  So that &lt;math&gt;{\partial \mathbf{r} \over \partial x}=(1, 0, f_x(x,y))&lt;/math&gt;, and &lt;math&gt;{\partial \mathbf{r} \over \partial y}=(0, 1, f_y(x,y))&lt;/math&gt;.  So,
:&lt;math&gt;\begin{align}
A
&amp;{} = \iint\limits_T \left\|\left(1, 0, {\partial f \over \partial x}\right)\times \left(0, 1, {\partial f \over \partial y}\right)\right\| \mathrm dx\, \mathrm dy \\
&amp;{} = \iint\limits_T \left\|\left(-{\partial f \over \partial x}, -{\partial f \over \partial y}, 1\right)\right\| \mathrm dx\, \mathrm dy \\
&amp;{} = \iint\limits_T \sqrt{\left({\partial f \over \partial x}\right)^2+\left({\partial f \over \partial y}\right)^2+1}\, \,  \mathrm dx\, \mathrm dy
\end{align}&lt;/math&gt;
which is the standard formula for the area of a surface described this way.  One can recognize the vector in the second line above as the [[surface normal|normal vector]] to the surface.

Note that because of the presence of the cross product, the above formulas only work for surfaces embedded in three-dimensional space.

This can be seen as integrating a [[Riemannian volume form]] on the parameterized surface, where the [[metric tensor]] is given by the [[first fundamental form]] of the surface.

== Surface integrals of vector fields ==&lt;!-- This section is linked from [[Flux]] --&gt;
[[Image:Surface vectors.png|right|thumb|300px|A vector field on a surface]]
Consider a vector field '''v''' on ''S'', that is, for each '''x''' in ''S'', '''v'''('''x''') is a vector.

The surface integral can be defined component-wise according to the definition of the surface integral of a scalar field; the result is a vector. This applies for example in the expression of the electric field at some fixed point due to an electrically charged surface, or the gravity at some fixed point due to a sheet of material.

Alternatively, if we integrate the [[normal component]] of the vector field, the result is a scalar. Imagine that we have a fluid flowing through ''S'', such that '''v'''('''x''') determines the velocity of the fluid at '''x'''. The [[flux]] is defined as the quantity of fluid flowing through ''S'' per unit time.

This illustration implies that if the vector field is [[tangent]] to ''S'' at each point, then the flux is zero because the fluid just flows in [[Parallel (geometry)|parallel]] to ''S'', and neither in nor out. This also implies that if '''v''' does not just flow along ''S'', that is, if '''v''' has both a tangential and a normal component, then only the normal component contributes to the flux. Based on this reasoning, to find the flux, we need to take the [[dot product]] of  '''v''' with the unit [[surface normal]] '''n''' to ''S'' at each point, which will give us a scalar field, and integrate the obtained field as above. We find the formula

:&lt;math&gt;\begin{align}
\iint\limits_S {\mathbf v}\cdot\mathrm d{\mathbf {\Sigma}} &amp;= \iint\limits_S \left({\mathbf v}\cdot {\mathbf n}\right)\,\mathrm d\Sigma\\
&amp;{}= \iint\limits_T \left({\mathbf v}(\mathbf{x}(s, t)) \cdot {\left({\partial \mathbf{x} \over \partial s}\times {\partial \mathbf{x} \over \partial t}\right) \over \left\|\left({\partial \mathbf{x} \over \partial s}\times {\partial \mathbf{x} \over \partial t}\right)\right\|}\right) \left\|\left({\partial \mathbf{x} \over \partial s}\times {\partial \mathbf{x} \over \partial t}\right)\right\| \mathrm ds\, \mathrm dt\\
&amp;{}=\iint\limits_T {\mathbf v}(\mathbf{x}(s, t))\cdot \left({\partial \mathbf{x} \over \partial s}\times {\partial \mathbf{x} \over \partial t}\right) \mathrm ds\, \mathrm dt.
\end{align}&lt;/math&gt;

The cross product on the right-hand side of this expression is a (not necessarily unital) surface normal determined by the parametrization.

This formula ''defines'' the integral on the left (note the dot and the vector notation for the surface element).

We may also interpret this as a special case of integrating 2-forms, where we identify the vector field with a 1-form, and then integrate its [[Hodge dual]] over the surface.
This is equivalent to integrating &lt;math&gt;\langle \mathbf{v}, \mathbf{n} \rangle \;\mathrm d\Sigma &lt;/math&gt; over the immersed surface, where &lt;math&gt;\mathrm d\Sigma&lt;/math&gt; is the induced volume form on the surface, obtained
by [[interior multiplication]] of the Riemannian metric of the ambient space with the outward normal of the surface.

== Surface integrals of differential 2-forms ==
Let
:&lt;math&gt; f=f_{z}\, \mathrm dx \wedge \mathrm dy + f_{x}\, \mathrm dy \wedge \mathrm dz + f_{y}\, \mathrm dz  \wedge \mathrm dx &lt;/math&gt;
be a [[differential form|differential 2-form]] defined on the surface ''S'', and let

:&lt;math&gt;\mathbf{x} (s,t)=( x(s,t), y(s,t), z(s,t))\!&lt;/math&gt;

be an [[orientability|orientation preserving]] parametrization of ''S'' with &lt;math&gt;(s,t)&lt;/math&gt; in ''D''. Changing coordinates from &lt;math&gt;(x, y)&lt;/math&gt;
to &lt;math&gt;(s, t)&lt;/math&gt;, the differential forms transform as

:&lt;math&gt;\mathrm dx=\frac{\mathrm dx}{\mathrm ds}\mathrm ds+\frac{\mathrm dx}{\mathrm dt}\mathrm dt&lt;/math&gt;

:&lt;math&gt;\mathrm dy=\frac{\mathrm dy}{\mathrm ds}\mathrm ds+\frac{\mathrm dy}{\mathrm dt}\mathrm dt&lt;/math&gt;

So &lt;math&gt; \mathrm dx \wedge \mathrm dy &lt;/math&gt; transforms to &lt;math&gt; \frac{\partial(x,y)}{\partial(s,t)}  \mathrm ds \wedge \mathrm dt &lt;/math&gt;, where &lt;math&gt; \frac{\partial(x,y)}{\partial(s,t)} &lt;/math&gt; denotes the determinant of the Jacobian of the transition function from &lt;math&gt;(s, t)&lt;/math&gt; to &lt;math&gt;(x,y)&lt;/math&gt;. The transformation of the other forms are similar.

Then, the surface integral of ''f'' on ''S'' is given by

:&lt;math&gt;\iint\limits_D \left[ f_{z} ( \mathbf{x} (s,t)) \frac{\partial(x,y)}{\partial(s,t)} + f_{x} ( \mathbf{x} (s,t))\frac{\partial(y,z)}{\partial(s,t)} + f_{y} ( \mathbf{x} (s,t))\frac{\partial(z,x)}{\partial(s,t)} \right]\, \mathrm ds\, \mathrm dt&lt;/math&gt;

where
:&lt;math&gt;{\partial \mathbf{x} \over \partial s}\times {\partial \mathbf{x} \over \partial t}=\left(\frac{\partial(y,z)}{\partial(s,t)}, \frac{\partial(z,x)}{\partial(s,t)}, \frac{\partial(x,y)}{\partial(s,t)}\right)&lt;/math&gt;
is the surface element normal to ''S''.

Let us note that the surface integral of this 2-form is the same as the surface integral of the vector field which has as components &lt;math&gt;f_x&lt;/math&gt;, &lt;math&gt;f_y&lt;/math&gt; and &lt;math&gt;f_z&lt;/math&gt;.

== Theorems involving surface integrals ==
Various useful results for surface integrals can be derived using [[differential geometry]] and [[vector calculus]], such as the [[divergence theorem]], and its generalization, [[Stokes' theorem]].

== Advanced issues ==
Let us notice that we defined the surface integral by using a parametrization of the surface ''S''. We know that a given surface might have several parametrizations. For example, if we move the locations of the North Pole and the South Pole on a sphere, the latitude and longitude change for all the points on the sphere. A natural question is then whether the definition of the surface integral depends on the chosen parametrization. For integrals of scalar fields, the answer to this question is simple, the value of the surface integral will be the same no matter what parametrization one uses.

For integrals of vector fields, things are more complicated, because the surface normal is involved. It can be proven that given two parametrizations of the same surface, whose surface normals point in the same direction, one obtains the same value for the surface integral with both parametrizations. If, however, the normals for these parametrizations point in opposite directions, the value of the surface integral obtained using one parametrization is the negative of the one obtained via the other parametrization. It follows that given a surface, we do not need to stick to any unique parametrization; but, when integrating vector fields, we do need to decide in advance which direction the normal will point to and then choose any parametrization consistent with that direction.

Another issue is that sometimes surfaces do not have parametrizations which cover the whole surface. The obvious solution is then to split that surface into several pieces, calculate the surface integral on each piece, and then add them all up. This is indeed how things work, but when integrating vector fields, one needs to again be careful how to choose the normal-pointing vector for each piece of the surface, so that when the pieces are put back together, the results are consistent. For the cylinder, this means that if we decide that for the side region the normal will point out of the body, then for the top and bottom circular parts the normal must point out of the body too.

Lastly, there are surfaces which do not admit a surface normal at each point with consistent results (for example, the [[Möbius strip]]).  If such a surface is split into pieces, on each piece a parametrization and corresponding surface normal is chosen, and the pieces are put back together, we will find that the normal vectors coming from different pieces cannot be reconciled. This means that at some junction between two pieces we will have normal vectors pointing in opposite directions. Such a surface is called [[Orientability|non-orientable]], and on this kind of surface, one cannot talk about integrating vector fields.

== See also ==
* [[Divergence theorem]]
* [[Stokes' theorem]]
* [[Line integral]]
* [[Volume element]]
* [[Volume integral]]
* [[Cartesian coordinate system]]
* [[Spherical coordinate system#Integration and differentiation in spherical coordinates|Volume and surface area elements in spherical coordinate systems]]
* [[Cylindrical coordinate system#Line and volume elements|Volume and surface area elements in cylindrical coordinate systems]]
* [[Holstein–Herring method]]

==References==
{{Reflist}}

== External links ==
* [http://mathworld.wolfram.com/SurfaceIntegral.html Surface Integral — from MathWorld]
* [http://www.math.gatech.edu/%7Ecain/notes/cal15.pdf Surface Integral — Theory and exercises]

[[Category:Multivariable calculus]]
[[Category:Area]]
[[Category:Surfaces]]</text>
      <sha1>1u3oy2tqlpvjquqh368eg22c67ij7dp</sha1>
    </revision>
  </page>
  <page>
    <title>Trillian (character)</title>
    <ns>0</ns>
    <id>168977</id>
    <revision>
      <id>865822140</id>
      <parentid>865819592</parentid>
      <timestamp>2018-10-26T11:43:31Z</timestamp>
      <contributor>
        <username>Chaheel Riens</username>
        <id>8839503</id>
      </contributor>
      <comment>/* Relationships */ Surely it cannot be necessary to clarify why two different species cannot conceive offspring together?  [[Mule]] notwithstanding.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11440">{{Refimprove |date=January 2014}}
{{Infobox character
| colour     = #FFFFFF
| name       = Trillian (Tricia McMillan)
| image      = [[Image:Sandra Dickinson as Trillian.jpg|250px|[[Sandra Dickinson]] as Trillian from the [[The Hitchhiker's Guide to the Galaxy (TV series)|TV adaptation]].]]
| caption    = [[Sandra Dickinson]] as Trillian from the [[The Hitchhiker's Guide to the Galaxy (TV series)|TV adaptation]].
| first      = [[The Hitchhiker's Guide to the Galaxy Primary and Secondary Phases#Fit the Second|Fit the Second (radio)]]
| last       = 
| cause      = 
| nickname   = 
| alias      = 
| species    = Human
| gender     = Female
| age        = 
| born       = 
| death      = 
| occupation = 
| title      = 
| family     = 
| spouse     = 
| children   = [[Minor characters from The Hitchhiker's Guide to the Galaxy#Random Dent|Random Dent]]
| relatives  = 
| episode    = 
| portrayer  = [[Sandra Dickinson]] (TV)&lt;br /&gt;[[Zooey Deschanel]] (film)&lt;br /&gt;[[Susan Sheridan]] (radio)&lt;br /&gt;[[Cindy Oswin]] (LP)
| creator    = [[Douglas Adams]]
}}
'''Tricia Marie McMillan''', also known as '''Trillian Astra''', is a [[fictional character]] from [[Douglas Adams]]' series ''[[The Hitchhiker's Guide to the Galaxy]]''.  She is most commonly referred to simply as "Trillian", a modification of her birth name, which she adopted because it sounded more "space-like". According to the [[The Hitchhiker's Guide to the Galaxy (film)|movie version]], her middle name is Marie.  Physically, she is described as "a slim, darkish humanoid, with long waves of black hair, a full mouth, an odd little knob of a nose and ridiculously brown eyes," looking "vaguely Arabic."&lt;ref&gt;{{Citation|last=Adams|first=Douglas|title=The Hitchhiker's Guide to the Galaxy|chapter=4|author-link=Douglas Adams}}. p. 31.&lt;/ref&gt;

==Biography==
Tricia McMillan is a [[mathematician]] and [[astrophysics|astrophysicist]] whom [[Arthur Dent]] attempted to talk to at a party in [[Islington]]. She and Arthur next meet six months later on the spaceship [[Technology in The Hitchhiker's Guide to the Galaxy#Heart of Gold|Heart of Gold]], shortly after the Earth has been destroyed to make way for a hyperspace bypass. The trilogy later reveals that Trillian eventually left the party with [[Zaphod Beeblebrox]], who, according to [[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#The Quintessential Phase|the Quintessential Phase]], is directly responsible for her nickname.

In the radio series, she is carried off and forcibly married to the President of the Algolian Chapter of the Galactic Rotary Club, and consequently does not appear in the second radio series at all.  The later radio series (the Tertiary Phase and beyond) reveal this (probably) occurred only in the artificial universe within the Guide offices.  In the books, which the third, fourth and fifth series follow, she saves the universe from the Krikketers, and later becomes a [[Technology in The Hitchhiker's Guide to the Galaxy#Sub-Etha|Sub-Etha]] Radio reporter under the name Trillian Astra.

Some drafts of the movie's screenplay, and Robbie Stamp's "making of" book covering the movie, state that Trillian was to be revealed as half-human, an acknowledged divergence from Douglas Adams' original storyline. This would have been done in order to underline the loneliness of Arthur Dent, the only 100% [[Human|Homo sapiens]] remaining in the universe, after Earth's demolition. This idea was scrapped after the "making of" book was written, and the scene revealing Trillian's heritage (by the mice, to Arthur, on the Earth Mark II) was re-written. An interview with actress [[Zooey Deschanel]], included on the DVD version, has her mention that Trillian is half-human, suggesting the interview was recorded prior to the change of plan.

==Relationships==
The movie puts a different spin on the character. The main emotional arc of the movie is a love triangle between Trillian, Zaphod, and Arthur. Trillian is initially attracted to Arthur when she meets him on Earth, but she's disappointed by his apparent lack of spontaneity. During their travels, Trillian discovers that Zaphod may be the more superficially exciting choice, but Arthur is the man who truly cares about her, Arthur commenting when he is about to have his head cut open by the mice that his feelings for Trillian are the only thing that he ever had questions about where the answer made him happy.

In the novels and radio series, Trillian does not have a romantic relationship with Arthur (although when Arthur starts seeing Fenchurch, Ford asks him what happened to Trillian). In the fifth book, Trillian is revealed as the mother of [[List of minor The Hitchhiker's Guide to the Galaxy characters#Random Dent|Random Dent]]. It is unclear for how long (if ever) Trillian had a relationship with Zaphod. They seem to travel away from each other after the third book, although in the fourth one Arthur states Trillian is with Zaphod, and in the fifth Trillian implies that she hadn't had a child with Zaphod simply because they're different species.  In the sixth novel, ''[[And Another Thing... (novel)|And Another Thing...]]'', she pursues a relationship with [[List of minor The Hitchhiker's Guide to the Galaxy characters#Wowbagger, the Infinitely Prolonged|Wowbagger, the Infinitely Prolonged]]; she accuses Arthur of carrying a torch for her as well.

==Portrayals==
Trillian was played on radio by [[Susan Sheridan]], on television by [[Sandra Dickinson]] (who also reprised an alternate-universe version of the role in the fifth and sixth radio series, playing both original and alternate-universe versions in the latter)), on the Original Records LP version by [[Cindy Oswin]], and in the 2005 film by [[Zooey Deschanel]]. In ''The Illustrated Hitchhiker's Guide to the Galaxy'', she is portrayed by Tali, a model.&lt;ref&gt;{{cite book | last = Adams | first = Douglas | authorlink = Douglas Adams | title = The Illustrated Hitchhiker's Guide to the Galaxy | publisher = Harmony/Crown | date = 1994 | location = New York, NY | pages = 4 | isbn = 0-517-59924-4}}&lt;/ref&gt;

In the original radio series, she is portrayed with an English accent&amp;nbsp;&amp;ndash; in both the TV series and movie she is played as an American. The [[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#The Quintessential Phase|"Quintessential Phase"]] of the radio series features Sandra Dickinson in the role of the alternate version of Tricia McMillan as a "blonder and more American" Trillian&amp;nbsp;&amp;ndash; the radio series indicates that the character is otherwise identical to the first Trillian and was born in the United Kingdom. In the book ''[[Mostly Harmless]]'', it is said that both the alternate Tricia McMillan and Trillian have an English accent. In ''The Hitchhiker's Guide to the Galaxy'' novel, she is described as follows: "She was slim, darkish, humanoid, with long waves of black hair, a full mouth, an odd little knob of a nose and ridiculously brown eyes. With her red head scarf knotted in that particular way and her long flowing silky brown dress, she looked vaguely Arabic." She has consistently not been portrayed as such in the television and film adaptions, although the film adaptation Trillian is closer to her appearance in the books than it was in the television series.

==Appearances==
Trillian comes closest of all female characters to appearing in the entire "Hitchhiker's" saga.

===Novels===
*[[The Hitchhiker's Guide to the Galaxy (novel)|The Hitchhiker's Guide to the Galaxy]]
*[[The Restaurant at the End of the Universe]]
*[[Life, the Universe and Everything]]
*[[So Long, and Thanks for All the Fish]] (mentioned only)
*[[Mostly Harmless]] (also alternate Tricia McMillan)
*[[And Another Thing... (novel)|And Another Thing...]] (also Alternate Tricia McMillan)

===Radio===
[[The Hitchhiker's Guide to the Galaxy (radio series)|The Hitchhiker's Guide to the Galaxy'' radio series]]

Featuring [[Susan Sheridan]] as Trillian:
* Primary Phase: "[[The Hitchhiker's Guide to the Galaxy Primary and Secondary Phases#Fit the Second|Fit the Second]]", "[[The Hitchhiker's Guide to the Galaxy Primary and Secondary Phases#Fit the Third|Fit the Third]]", "[[The Hitchhiker's Guide to the Galaxy Primary and Secondary Phases#Fit the Fourth|Fit the Fourth]]", "[[The Hitchhiker's Guide to the Galaxy Primary and Secondary Phases#Fit the Fifth|Fit the Fifth]]", "[[The Hitchhiker's Guide to the Galaxy Primary and Secondary Phases#Fit the Sixth|Fit the Sixth]]"
* Tertiary Phase: "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Thirteenth|Fit the Thirteenth]]", "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Sixteenth|Fit the Sixteenth]]", "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Seventeenth|Fit the Seventeenth]]", "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Eighteenth|Fit the Eighteenth]]"
* Quintessential Phase: "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Twenty-Third|Fit the Twenty-Third]]", "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Twenty-Fifth|Fit the Twenty-Fifth]]", "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Twenty-Sixth|Fit the Twenty-Sixth]]"

Featuring [[Sandra Dickinson]] as the alternate character Tricia McMillan:
* Quintessential Phase: "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Twenty-Fourth|Fit the Twenty-Fourth]]", "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Twenty-Fifth|Fit the Twenty-Fifth]]", "[[The Hitchhiker's Guide to the Galaxy Tertiary to Quintessential Phases#Fit the Twenty-Sixth|Fit the Twenty-Sixth]]"

Featuring Sandra Dickinson as Trillian and Tricia McMillan:
* "[[The Hitchhiker's Guide to the Galaxy Tertiary to Hexagonal Phases#The Hexagonal Phase|The Hexagonal Phase]]"

===LP===
Featuring Cindy Oswin as Trillian
*[[The Hitchhiker's Guide to the Galaxy#LP album adaptations|The Hitchhiker's Guide to the Galaxy]]
*[[The Hitchhiker's Guide to the Galaxy#LP album adaptations|The Restaurant at the End of the Universe]]

===Television===
Featuring Sandra Dickinson as Trillian
*[[The Hitchhiker's Guide to the Galaxy (TV series)#Episode 2|Episode 2]]
*[[The Hitchhiker's Guide to the Galaxy (TV series)#Episode 3|Episode 3]]
*[[The Hitchhiker's Guide to the Galaxy (TV series)#Episode 4|Episode 4]]
*[[The Hitchhiker's Guide to the Galaxy (TV series)#Episode 5|Episode 5]]
*[[The Hitchhiker's Guide to the Galaxy (TV series)#Episode 6|Episode 6]]

===Computer game===
*[[The Hitchhiker's Guide to the Galaxy (video game)|The Hitchhiker's Guide to the Galaxy]]

===Film===
Featuring [[Zooey Deschanel]] as Trillian
*[[The Hitchhiker's Guide to the Galaxy (film)|The Hitchhiker's Guide to the Galaxy]]

==References==
{{reflist}}

{{HitchhikerCharacters}}

[[Category:The Hitchhiker's Guide to the Galaxy characters]]
[[Category:Female characters in film]]
[[Category:Female characters in literature]]
[[Category:Female characters in television]]
[[Category:Fictional mathematicians]]
[[Category:Fictional astronomers]]
[[Category:Fictional reporters]]
[[Category:Fictional characters introduced in 1978]]
[[Category:Fictional sole survivors]]
[[Category:Fictional women scientists]]</text>
      <sha1>2k3uccppf8it6cuqfnkqi8iwgqlpbea</sha1>
    </revision>
  </page>
  <page>
    <title>Two-element Boolean algebra</title>
    <ns>0</ns>
    <id>2584449</id>
    <revision>
      <id>870508604</id>
      <parentid>870508573</parentid>
      <timestamp>2018-11-25T08:02:31Z</timestamp>
      <contributor>
        <username>Nbarth</username>
        <id>570614</id>
      </contributor>
      <comment>/* See also */ [[Boolean semiring]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8068">In [[mathematics]] and [[abstract algebra]], the '''two-element Boolean algebra''' is the [[Boolean algebra (structure)| Boolean algebra]] whose ''underlying set'' (or [[Universe_(mathematics)|universe]] or ''carrier'') ''B'' is the [[Boolean domain]]. The elements of the Boolean domain are 1 and 0 by convention, so that ''B''&amp;nbsp;=&amp;nbsp;{0,&amp;nbsp;1}. [[Paul Halmos]]'s name for this algebra "'''2'''" has some following in the literature, and will be employed here.

==Definition==
''B'' is a [[partial order|partially ordered set]] and the elements of ''B'' are also its [[bounded set|bounds]].

An [[operation (mathematics)|operation]] of [[arity]] ''n'' is a [[map (mathematics)|mapping]] from ''B''&lt;sup&gt;n&lt;/sup&gt; to ''B''. Boolean algebra consists of two [[binary operation]]s and [[unary operation|unary]] [[Complement (order theory)|complementation]]. The binary operations have been named and notated in various ways. Here they are called  'sum' and 'product', and notated by infix '+' and '∙', respectively. Sum and product [[commutativity|commute]] and [[associativity|associate]], as in the usual [[elementary algebra|algebra of real numbers]]. As for the [[order of operations]], brackets are decisive if present. Otherwise '∙' precedes '+'. Hence ''A∙B&amp;nbsp;+&amp;nbsp;C'' is parsed as ''(A∙B)&amp;nbsp;+&amp;nbsp;C'' and not as ''A∙(B&amp;nbsp;+&amp;nbsp;C)''. [[Boolean algebra (logic)|Complementation]] is denoted by writing an overbar over its argument. The numerical analog of the complement of ''X'' is 1&amp;nbsp;&amp;minus;&amp;nbsp;''X''. In the language of [[universal algebra]], a Boolean algebra is a &lt;math&gt;\langle B,+,.,\overline{..},1,0\rangle&lt;/math&gt; [[algebraic structure|algebra]] of [[arity|type]] &lt;math&gt;\langle 2,2,1,0,0\rangle&lt;/math&gt;.

Either [[one-to-one correspondence]] between {0,1} and {''True'',''False''} yields classical [[bivalent logic]] in equational form, with complementation read as [[logical NOT|NOT]]. If 1 is read as ''True'', '+' is read as [[logical OR|OR]], and '∙' as [[logical AND|AND]], and vice versa if 1 is read as ''False''. These two operations define a commutative [[semiring]], known as the [[Boolean semiring]].

==Some basic identities==
'''2''' can be seen as grounded in the following trivial "Boolean" arithmetic:

:&lt;math&gt;
\begin{align}
&amp;1 + 1 = 1 + 0 = 0 + 1 = 1 \\
&amp;0 + 0 = 0 \\
&amp;0\cdot0 = 0\cdot1 = 1\cdot0 = 0 \\
&amp;1\cdot1 = 1 \\
&amp;\overline{1} = 0 \\
&amp;\overline{0} = 1
\end{align}
&lt;/math&gt;

Note that:
* '+' and '∙' work exactly as in numerical arithmetic, except that 1+1=1. '+' and '∙' are derived by analogy from numerical arithmetic; simply set any nonzero number to 1.
* Swapping 0 and 1, and '+' and '∙' preserves truth; this is the essence of the [[Duality (order theory)|duality]] pervading all Boolean algebras.
This Boolean arithmetic suffices to verify any equation of '''2''', including the axioms, by examining every possible assignment of 0s and 1s to each variable (see [[decision procedure]]).

The following equations may now be verified:

:&lt;math&gt;
\begin{align}
&amp;A + A = A \\
&amp;A \cdot A = A \\
&amp;A + 0 = A \\
&amp;A + 1 = 1 \\
&amp;A \cdot 0 = 0 \\
&amp;\overline{\overline{A}} = A
\end{align}
&lt;/math&gt;

Each of '+' and '∙' [[distributivity|distributes]] over the other:
*&lt;math&gt;\ A \cdot (B+C) = A \cdot B + A \cdot C;&lt;/math&gt;
*&lt;math&gt;\ A+(B \cdot C) = (A+B) \cdot (A+C).&lt;/math&gt;
That '∙' distributes over '+' agrees with [[elementary algebra]], but not '+' over '∙'. For this and other reasons, a sum of products (leading to a [[Sheffer stroke|NAND]] synthesis) is more commonly employed than a product of sums (leading to a [[Logical NOR|NOR]] synthesis).

Each of '+' and '∙' can be defined in terms of the other and complementation:
* &lt;math&gt;A \cdot B=\overline{\overline{A}+\overline{B}}&lt;/math&gt;
* &lt;math&gt;A+B=\overline{\overline{A} \cdot \overline{B}}.&lt;/math&gt;
We only need one binary operation, and [[concatenation]] suffices to denote it. Hence concatenation and overbar suffice to notate '''2'''. This notation is also that of [[Willard Van Orman Quine|Quine]]'s [[Boolean term schemata]]. Letting (''X'') denote the complement of ''X'' and "()" denote either 0 or 1 yields the [[syntax]] of the [[laws of form|primary algebra]].

A ''basis'' for '''2''' is a set of equations, called [[axiom]]s, from which all of the above equations (and more) can be derived. There are many known bases for all Boolean algebras and hence for '''2'''. An elegant basis notated using only concatenation and overbar is:
# &lt;math&gt;\ ABC = BCA&lt;/math&gt; (Concatenation commutes, associates)
# &lt;math&gt;\overline{A}A = 1&lt;/math&gt; ('''2''' is a [[Complement (order theory)|complemented]] lattice, with an [[bounded set|upper bound]] of 1)
#&lt;math&gt;\ A0 = A&lt;/math&gt; (0 is the [[bounded set|lower bound]]).
# &lt;math&gt;A\overline{AB} = A\overline{B}&lt;/math&gt; ('''2''' is a [[distributive lattice]])

Where concatenation = OR, 1 = true, and 0 = false, or concatenation = AND, 1 = false, and 0 = true. (overbar is negation in both cases.)

If 0=1, (1)-(3) are the axioms for an [[abelian group]].

(1) only serves to prove that concatenation commutes and associates. First assume that (1) associates from either the left or the right, then prove commutativity. Then prove association from the other direction. Associativity is simply association from the left and right combined.

This basis makes for an easy approach to proof, called [[Laws of Form|calculation]], that proceeds by simplifying expressions to 0 or 1, by invoking axioms (2)&amp;ndash;(4), and the elementary identities &lt;math&gt;AA=A, \overline{\overline{A}}=A, 1+A = 1&lt;/math&gt;, and the distributive law.

==Metatheory==
[[De Morgan's theorem]] states that if one does the following, in the given order, to any [[Boolean function]]:
* Complement every variable;
* Swap '+' and '∙' operators (taking care to add brackets to ensure the order of operations remains the same);
* Complement the result,
the result is [[Logical equivalence|logically equivalent]] to what you started with. Repeated application of De Morgan's theorem to parts of a function can be used to drive all complements down to the individual variables.

A powerful and nontrivial [[metatheorem]] states that any theorem of '''2''' holds for all Boolean algebras.&lt;ref&gt;Givant, S., and Halmos, P. (2009) [https://dx.doi.org/10.1007/978-0-387-68436-9 ''Introduction to Boolean Algebras''], Springer Verlag. Theorem 9.&lt;/ref&gt; Conversely, an identity that holds for an arbitrary nontrivial Boolean algebra also holds in '''2'''. Hence all the mathematical content of Boolean algebra is captured by '''2'''. This theorem is useful because any equation in '''2''' can be verified by a [[decision procedure]]. Logicians refer to this fact as "'''2''' is [[decidability (logic)|decidable]]". All known [[decision procedure]]s require a number of steps that is an [[exponential function]] of the number of variables ''N'' appearing in the equation to be verified. Whether there exists a decision procedure whose steps are a [[polynomial function]] of ''N'' falls under the [[P&amp;nbsp;=&amp;nbsp;NP]] conjecture.
&lt;!--==Minterms and minimum two level forms==
Any Boolean expression can be written as a series of [[minterm]]s added together--&gt;

==See also==
*[[Boolean algebra]]
*[[Boolean semiring]]
*[[Bounded set]]
*[[Lattice (order)]]
*[[Order theory]]

==References==
{{Reflist}}

==Further reading==
Many elementary texts on Boolean algebra were published in the early years of the computer era. Perhaps the best of the lot, and one still in print, is:
* Mendelson, Elliot, 1970. ''Schaum's Outline of Boolean Algebra''. McGraw&amp;ndash;Hill.

The following items reveal how the two-element Boolean algebra is mathematically nontrivial.
* [[Stanford Encyclopedia of Philosophy]]: "[http://plato.stanford.edu/entries/boolalg-math/ The Mathematics of Boolean Algebra,]" by J. Donald Monk.
* Burris, Stanley N., and H.P. Sankappanavar, H. P., 1981. ''[http://www.thoralf.uwaterloo.ca/htdocs/ualg.html A Course in Universal Algebra.]''  Springer-Verlag. {{isbn|3-540-90578-2}}.

[[Category:Elementary algebra]]
[[Category:Boolean algebra]]</text>
      <sha1>b3x0yq07jvpsp3r8n26sdwin1z3h102</sha1>
    </revision>
  </page>
  <page>
    <title>UK National Quantum Technologies Programme</title>
    <ns>0</ns>
    <id>48710592</id>
    <revision>
      <id>850103027</id>
      <parentid>846800094</parentid>
      <timestamp>2018-07-13T16:32:59Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 1 sources and tagging 0 as dead. #IABot (v2.0beta)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10469">{{Use dmy dates|date=April 2018}}
{{Use British English|date=April 2018}}
{{Primary sources|date=August 2015}}

{{Infobox university
|name              = UK National Quantum Technologies Programme (UKNQTP)
|image_name = UKNQTP.png
|established       = 2013
|country           = UK
|website           = [http://uknqt.epsrc.ac.uk Uknqt.epsrc.ac.uk]
}}
The '''UK National Quantum Technologies Programme''' ('''UKNQTP''') is a programme set up by the UK government &lt;ref name="physicsworld"&gt;{{cite web|url=http://physicsworld.com/cws/article/news/2014/jan/30/uk-splashes-out-GBP-270m-on-quantum-technology|title=UK splashes out £270m on quantum technology |website=Physicsworld.com|accessdate=2015-12-02}}&lt;/ref&gt; to translate academic work on [[quantum mechanics]], and the effects of [[quantum superposition]] and [[quantum entanglement]] into new products and services. It brings UK physicists and engineers together with companies and entrepreneurs who have an interest in commercialising the technology.

==The "second quantum revolution"==
The "second quantum revolution", or "quantum 2.0" is a term that is often used to describe [[quantum technology|quantum technologies]] based on superposition and entanglement. Originally described in a 1997 book by [[Gerard J. Milburn]],&lt;ref&gt;{{cite web|url=http://www.physics.uq.edu.au/people/milburn/books/Schr_Mach.html|archiveurl=https://web.archive.org/web/20091004212857/http://www.physics.uq.edu.au/people/milburn/books/Schr_Mach.html|title=Schrodinger's Machines|author=|date=|archivedate=4 October 2009|work=uq.edu.au}}&lt;/ref&gt; which was then followed by a 2003 article by [[Jonathan P. Dowling]] and [[Gerard J. Milburn]],&lt;ref&gt;{{cite web|url=http://journals.royalsociety.org/content/bdm1frlb9tfmr3ar/ |archive-url=https://archive.is/20120714114853/http://journals.royalsociety.org/content/bdm1frlb9tfmr3ar/ |dead-url=yes |archive-date=14 July 2012 |accessdate=2 December 2015 }}&lt;/ref&gt;&lt;ref&gt;{{cite arxiv|eprint=quant-ph/0206091 |title=Quantum Technology: The Second Quantum Revolution |date=2002-06-13 |last1=Dowling |first1=Jonathan P |last2=Milburn |first2=Gerard J }}&lt;/ref&gt; as well as a 2003 article by [[David Deutsch]].&lt;ref&gt;{{cite web|url=http://www.qubit.org/people/david/structure/Documents/Research%20Papers/PPQT.pdf |title=David Deutsch |website=Qubit.org |date= |accessdate=2015-12-03}}&lt;/ref&gt; These technologies use equipment such as highly stabilised [[laser]] systems, [[magneto-optical trap]]s, [[cryogenic]] cooled [[solid state (electronics)|solid state]] devices, [[ion traps]] and vacuum systems to create, manipulate and then use quantum effects for a number of different purposes. These include: [[quantum information]] processing, such as [[quantum computing]], [[quantum simulator|quantum simulation]], [[quantum cryptography|quantum secure communications]], [[quantum sensing]] and [[quantum metrology|metrology]] and [[quantum imaging]], and are widely believed to offer capabilities that will out-perform existing and future [[classical physics|classical]] technologies.

==Vision== 
The vision of the UK National Quantum Technologies programme is to "create a coherent government, industry and academic quantum technology community that gives the UK a world-leading position in the emerging multi-billion-pound new quantum technology markets, and to substantially enhance the value of some of the biggest UK-based industries."&lt;ref name="epsrc"&gt;{{cite web|url=https://www.epsrc.ac.uk/newsevents/pubs/quantumtechstrategy/ |title=National strategy for quantum technologies |website=Epsrc.ac.uk |accessdate=2015-12-03}}&lt;/ref&gt;

==History==
The UKNQTP was initiated by a £270&amp;nbsp;million investment by the UK Chancellor of the exchequer, [[George Osborne]] in the Autumn Statement 2013.&lt;ref name="ft"&gt;{{cite web|url=http://www.ft.com/cms/s/0/2532c07a-5cfe-11e3-a558-00144feabdc0.html#axzz3tBeUQXQX|archive-url=https://web.archive.org/web/20131207055831/http://www.ft.com/cms/s/0/2532c07a-5cfe-11e3-a558-00144feabdc0.html#axzz3tBeUQXQX|archive-date=7 December 2013|dead-url=yes|title=Autumn Statement 2013: Quantum technology to get &amp;pound;270m boost - FT.com|website=Web.archive.org|accessdate=2015-12-02|df=dmy-all}}&lt;/ref&gt; In addition to this, the UK [[Defence Science and Technology Laboratory]] (Dstl) separately announced a £30&amp;nbsp;million investment into a programme to produce demonstrator devices.

==Organisation and governance==
The primary focus of the UKNQTP are four 'hubs' for quantum technologies:
*Quantum Hub for sensors and metrology,&lt;ref&gt;{{cite web|url=http://www.birmingham.ac.uk/generic/quantum/index.aspx |title=UK Quantum Technology Hub for Sensors and Metrology |website=Birmingham.ac.uk |date= |accessdate=2015-12-03}}&lt;/ref&gt; led by the [[University of Birmingham]]&lt;ref&gt;{{cite web|title=UK National Quantum Hub in Sensors and Metrology|url=http://uknqt.epsrc.ac.uk/files/flyer-sensors-and-meteorology-hub/|website=uknqt.epsrc.ac.uk|publisher=[[University of Birmingham]]|accessdate=5 January 2016}}&lt;/ref&gt;
*[[Quantum Communications Hub]],&lt;ref&gt;{{cite web|url=http://quantumcommshub.net |title=Home - Quantum Communications |website=Quantumcommshub.net |date=2015-11-19 |accessdate=2015-12-03}}&lt;/ref&gt; led by the [[University of York]]&lt;ref&gt;{{cite web|title=UK Quantum Technology Hub for Quantum Communications Technologies|url=http://quantumcommshub.net/|website=quantumcommshub.net|publisher=Quantum Communications Hub|accessdate=5 January 2016}}&lt;/ref&gt;
*NQIT: Quantum hub for [[NQIT|Networked Quantum Information Technologies]],&lt;ref&gt;{{cite web|url=http://nqit.ox.ac.uk |title=Networked Quantum Information Technologies &amp;#124; Networked Quantum Information Technologies |website=Nqit.ox.ac.uk |date= |accessdate=2015-12-03}}&lt;/ref&gt; led by the [[University of Oxford]]&lt;ref&gt;{{cite web|last1=Walmsley|first1=Prof. Ian|authorlink1=Ian Walmsley|title=A message from the Networked Quantum Information Technologies (NQIT) Hub Director|url=http://uknqt.epsrc.ac.uk/files/nqit-flyer/|website=uknqt.epsrc.ac.uk|accessdate=5 January 2016}}&lt;/ref&gt;
*QuantIC: Quantum hub for quantum enhanced imaging,&lt;ref&gt;{{cite web|url=https://quantic.ac.uk |title=Homepage |website=QuantIC.ac.uk |date= |accessdate=2015-12-03}}&lt;/ref&gt; with a central team at the [[University of Glasgow]]&lt;ref&gt;{{cite web|title=About us|url=https://quantic.ac.uk/about-us/|website=quantic.ac.uk|accessdate=5 January 2016}}&lt;/ref&gt;

The UKQTP is advised by the Quantum Technologies Strategic Advisory Board, which is chaired by [[David Delpy|Professor David Delpy]], it also consists of [[Peter Knight (scientist)|Professor Sir Peter Knight]], [[Baroness Neville-Jones]], [[Gerard J. Milburn|Professor Gerald Milburn]],  [[Ian Walmsley|Professor Ian Walmsley]] and other leading individuals from industry, academia and public sector.

The programme is delivered by several UK public bodies: UK government [[Department for Business, Innovation and Skills]] (BIS), [[EPSRC]], [[Innovate UK]], [[Dstl]], [[National Physical Laboratory (United Kingdom)|NPL]], [[Communications-Electronics Security Group|CESG]] and the Knowledge Transfer Network.

==Press coverage==
The UKQTP has received some attention from the UK media, with an interview with Professor [[Miles J. Padgett|Miles Padgett]]  on the [[BBC Radio 4]] [[Today (BBC Radio 4)|Today programme]] on 11 November 2015 and articles in the ''[[Daily Mail]]'',&lt;ref name="dailymail"&gt;{{cite web|url=http://www.dailymail.co.uk/sciencetech/article-2629088/MoD-quantum-compass-GPS-without-satellites.html|title=Could a quantum compass replace GPS? MoD system lets you navigate WITHOUT using space satellites|website=Dailymail.co.uk|accessdate=2015-12-02}}&lt;/ref&gt; ''[[New Scientist]]'',&lt;ref name="newscientist"&gt;{{cite web|url=https://www.newscientist.com/article/mg22830434-100-quantum-technology-set-to-hit-the-streets-within-two-years/|archive-url=https://web.archive.org/web/20151016132204/https://www.newscientist.com/article/mg22830434-100-quantum-technology-set-to-hit-the-streets-within-two-years/ |archive-date=2015-10-16 |dead-url=yes|title=Quantum technology set to hit the streets within two years &amp;#124; New Scientist|website=Web.archive.org|accessdate=2015-12-02}}&lt;/ref&gt; and Nature materials&lt;ref name="nature"&gt;{{cite journal|url=http://www.nature.com/nmat/journal/v14/n9/full/nmat4404.html|title=The British route to innovation |accessdate=2015-12-02|volume=14|issue=9 |doi=10.1038/nmat4404|pages=851–852|journal=Nature Materials|year=2015 |last1=Maragkou |first1=Maria |last2=Murray |first2=Richard |bibcode=2015NatMa..14..851M}}&lt;/ref&gt;

==Key milestones and achievements==
{{Prose|section|date=December 2015}}
* '''Summer 2013''' - [[Dstl]], after consultation with the academic community publish a UK Quantum Technologies Landscape document, which outlines a number of areas of research that are ready to become devices for defence and commercial use.
* '''Autumn 2013''' - The UK Chancellor [[George Osborne]] announces a £270 million investment into quantum technologies
* '''November 2014''' - The Science Minister at the time, [[Greg Clark]] announces a "national network of quantum technology hubs" &lt;ref&gt;{{cite web|url=http://www.nature.com/news/four-uk-hubs-to-make-spooky-quantum-physics-useful-1.16426|title=Four UK hubs to make 'spooky' quantum physics useful|author=|date=|work=Nature News &amp; Comment|accessdate=3 December 2015}}&lt;/ref&gt;
* '''March 2015''' - The Quantum Technologies Strategic Advisory Board release their strategy for the UKNQTP&lt;ref&gt;{{cite web|url=https://www.gov.uk/government/news/quantum-technologies-a-new-era-for-the-uk|title=Quantum technologies: a new era for the UK|author=|date=|website=Gov.uk|accessdate=3 December 2015}}&lt;/ref&gt;
* '''April 2015''' - [[Innovate UK]] announces the results the competition 'exploring the commercial applications of quantum technologies',&lt;ref&gt;{{cite web|url=https://interact.innovateuk.org/-/exploring-the-commercial-applications-of-quantum-technologies-feasibility-study|title=Exploring the commercial applications of quantum technologies - Feasibility study|author=|date=|website=Innovateuk.org|accessdate=3 December 2015}}&lt;/ref&gt; a £5 million funding round for companies working to develop quantum technologies.

==References==
{{Reflist}}

[[Category:Programmes of the Government of the United Kingdom]]
[[Category:Quantum mechanics]]
[[Category:Emerging technologies]]
[[Category:Engineering and Physical Sciences Research Council]]
[[Category:Quantum information science]]
[[Category:Quantum computing]]</text>
      <sha1>jbn43xp58o6vga74ujw48795ii7dhja</sha1>
    </revision>
  </page>
  <page>
    <title>Woodall number</title>
    <ns>0</ns>
    <id>321962</id>
    <revision>
      <id>869844577</id>
      <parentid>869842341</parentid>
      <timestamp>2018-11-20T19:10:11Z</timestamp>
      <contributor>
        <ip>2600:387:5:803:0:0:0:A3</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9307">In [[number theory]], a '''Woodall number''' (W&lt;sub&gt;n&lt;/sub&gt;) is any [[natural number]] of the form

:&lt;math&gt;W_n = n \cdot 2^n - 1&lt;/math&gt;

for some natural number ''n''. The first few Woodall numbers are:

:1, 7, 23, 63, 159, 383, 895, … {{OEIS|id=A003261}}.

==History==
Woodall numbers were first studied by [[Allan J. C. Cunningham]] and [[H. J. Woodall]] in 1917,&lt;ref&gt;{{citation
 | last1 = Cunningham | first1 = A. J. C | author1-link = Allan Joseph Champneys Cunningham
 | last2 = Woodall | first2 = H. J. | author2-link = H. J. Woodall
 | journal = [[Messenger of Mathematics]]
 | pages = 1–38
 | title = Factorisation of &lt;math&gt;Q = (2^q \mp q)&lt;/math&gt; and &lt;math&gt;(q \cdot {2^q} \mp 1)&lt;/math&gt;
 | volume = 47
 | year = 1917}}.&lt;/ref&gt; inspired by [[James Cullen (mathematician)|James Cullen]]'s earlier study of the similarly-defined [[Cullen number]]s.

==Woodall primes==
Woodall numbers that are also [[prime number]]s are called '''Woodall primes'''; the first few exponents ''n'' for which the corresponding Woodall numbers ''W''&lt;sub&gt;''n''&lt;/sub&gt; are prime are 2, 3, 6, 30, 75, 81, 115, 123, 249, 362, 384, … {{OEIS|id=A002234}}; the Woodall primes themselves begin with 7, 23, 383, 32212254719, … {{OEIS|id=A050918}}.

In 1976 [[Christopher Hooley]] showed that [[almost all]] [[Cullen number]]s are [[composite number|composite]].&lt;ref name=EPSW94&gt;{{cite book | last1=Everest | first1=Graham | last2=van der Poorten | first2=Alf | author2-link=Alfred van der Poorten | last3=Shparlinski | first3=Igor | last4=Ward | first4=Thomas | title=Recurrence sequences | series=Mathematical Surveys and Monographs | volume=104 | location=[[Providence, RI]] | publisher=[[American Mathematical Society]] | year=2003 | isbn=0-8218-3387-1 | zbl=1033.11006 | page=94 }}&lt;/ref&gt; Hooley's proof was reworked by [[Hiromi Suyama]] to show that it works for any sequence of numbers ''n'' · 2&lt;sup&gt;''n''+''a''&lt;/sup&gt; + ''b'' where ''a'' and ''b'' are integers, and in particular also for Woodall numbers. Nonetheless, it is conjectured that there are infinitely many Woodall primes.{{Citation needed|date=December 2011}} {{As of|2018|10}}, the largest known Woodall prime is 17016602&amp;nbsp;×&amp;nbsp;2&lt;sup&gt;17016602&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1.&lt;ref&gt;{{Citation |url=http://primes.utm.edu/primes/page.php?id=124539 |title=The Prime Database: 8508301*2^17016603-1 |work=Chris Caldwell's The Largest Known Primes Database |accessdate=March 24, 2018 }}&lt;/ref&gt; It has 5,122,515 digits and was found by Diego Bertolotti in March 2018 in the [[distributed computing]] project [[PrimeGrid]].&lt;ref&gt;{{Citation |url=http://www.primegrid.com/download/WOO-17016602.pdf |title= Announcement of 17016602*2^17016602&amp;nbsp;-&amp;nbsp;1 |author=[[PrimeGrid]] |accessdate=April 1, 2018 }}&lt;/ref&gt;

==Restrictions==
Starting with W&lt;sub&gt;4&lt;/sub&gt; = 63 and W&lt;sub&gt;5&lt;/sub&gt; = 159, every sixth Woodall number is divisible by 3; thus, in order for W&lt;sub&gt;n&lt;/sub&gt; to be prime, the index n cannot be congruent to 4 or 5 (modulo 6). Also, for a positive integer m, the Woodall number W&lt;sub&gt;2&lt;sup&gt;m&lt;/sup&gt;&lt;/sub&gt; may be prime only if 2&lt;sup&gt;m&lt;/sup&gt; + m is prime. 

==Divisibility properties==
Like Cullen numbers, Woodall numbers have many divisibility properties. For example, if ''p'' is a prime number, then ''p'' divides

:''W''&lt;sub&gt;(''p'' + 1) / 2&lt;/sub&gt;  if the [[Jacobi symbol]] &lt;math&gt;\left(\frac{2}{p}\right)&lt;/math&gt; is +1 and

:''W''&lt;sub&gt;(3''p''&amp;nbsp;−&amp;nbsp;1)&amp;nbsp;/&amp;nbsp;2&lt;/sub&gt;  if the Jacobi symbol &lt;math&gt;\left(\frac{2}{p}\right)&lt;/math&gt;  is −1.{{Citation needed|date=December 2011}}

==Generalization==
A '''generalized Woodall number base ''b''''' is defined to be a number of the form ''n'' × ''b''&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1, where ''n''&amp;nbsp;+&amp;nbsp;2&amp;nbsp;&gt;&amp;nbsp;''b''; if a prime can be written in this form, it is then called a '''generalized Woodall prime'''.

Least ''n'' such that ''n'' × ''b''&lt;sup&gt;''n''&lt;/sup&gt; - 1 is prime are&lt;ref&gt;[http://harvey563.tripod.com/GWlist.txt List of generalized Woodall primes base 3 to 10000]&lt;/ref&gt;
:3, 2, 1, 1, 8, 1, 2, 1, 10, 2, 2, 1, 2, 1, 2, 167, 2, 1, 12, 1, 2, 2, 29028, 1, 2, 3, 10, 2, 26850, 1, 8, 1, 42, 2, 6, 2, 24, 1, 2, 3, 2, 1, 2, 1, 2, 2, 140, 1, 2, 2, 22, 2, 8, 1, 2064, 2, 468, 6, 2, 1, 362, 1, 2, 2, 6, 3, 26, 1, 2, 3, 20, 1, 2, 1, 28, 2, 38, 5, 3024, 1, 2, 81, 858, 1, 2, 3, 2, 8, 60, 1, 2, 2, 10, 5, 2, 7, 182, 1, 17782, 3, ... {{OEIS|id=A240235}}

{|class="wikitable"
|''b''
|numbers ''n'' such that ''n'' × ''b''&lt;sup&gt;''n''&lt;/sup&gt; - 1 is prime (these ''n'' are checked up to 350000)
|[[OEIS]] sequence
|-
|1
|3, 4, 6, 8, 12, 14, 18, 20, 24, 30, 32, 38, 42, 44, 48, 54, 60, 62, 68, 72, 74, 80, 84, 90, 98, 102, 104, 108, 110, 114, 128, 132, 138, 140, 150, 152, 158, 164, 168, 174, 180, 182, 192, 194, 198, 200, 212, 224, 228, 230, 234, 240, 242, 252, 258, 264, 270, 272, 278, 282, 284, 294, ... (all primes plus 1)
|{{OEIS link|id=A008864}}
|-
|2
|2, 3, 6, 30, 75, 81, 115, 123, 249, 362, 384, 462, 512, 751, 822, 5312, 7755, 9531, 12379, 15822, 18885, 22971, 23005, 98726, 143018, 151023, 667071, 1195203, 1268979, 1467763, 2013992, 2367906, 3752948, ...
|{{OEIS link|id=A002234}}
|-
|3
|1, 2, 6, 10, 18, 40, 46, 86, 118, 170, 1172, 1698, 1810, 2268, 4338, 18362, 72662, 88392, 94110, 161538, 168660, 292340, 401208, 560750, 1035092, ...
|{{OEIS link|id=A006553}}
|-
|4
|1, 2, 3, 5, 8, 14, 23, 63, 107, 132, 428, 530, 1137, 1973, 2000, 7064, 20747, 79574, 113570, 293912, ..., 1993191, ...
|{{OEIS link|id=A086661}}
|-
|5
|8, 14, 42, 384, 564, 4256, 6368, 21132, 27180, 96584, 349656, 545082, ...
|{{OEIS link|id=A059676}}
|-
|6
|1, 2, 3, 19, 20, 24, 34, 77, 107, 114, 122, 165, 530, 1999, 4359, 11842, 12059, 13802, 22855, 41679, 58185, 145359, 249987, ...
|{{OEIS link|id=A059675}}
|-
|7
|2, 18, 68, 84, 3812, 14838, 51582, ...
|{{OEIS link|id=A242200}}
|-
|8
|1, 2, 7, 12, 25, 44, 219, 252, 507, 1155, 2259, 2972, 4584, 12422, 13905, 75606, ...
|{{OEIS link|id=A242201}}
|-
|9
|10, 58, 264, 1568, 4198, 24500, ...
|{{OEIS link|id=A242202}}
|-
|10
|2, 3, 8, 11, 15, 39, 60, 72, 77, 117, 183, 252, 396, 1745, 2843, 4665, 5364, ...
|{{OEIS link|id=A059671}}
|-
|11
|2, 8, 252, 1184, 1308, ...
|{{OEIS link|id=A299374}}
|-
|12
|1, 6, 43, 175, 821, 910, 1157, 13748, 27032, 71761, 229918, ...
|{{OEIS link|id=A299375}}
|-
|13
|2, 6, 563528, ...
|{{OEIS link|id=A299376}}
|-
|14
|1, 3, 7, 98, 104, 128, 180, 834, 1633, 8000, 28538, 46605, 131941, 147684, 433734, ...
|{{OEIS link|id=A299377}}
|-
|15
|2, 10, 14, 2312, 16718, 26906, 27512, 41260, 45432, 162454, 217606, ...
|{{OEIS link|id=A299378}}
|-
|16
|167, 189, 639, ...
|{{OEIS link|id=A299379}}
|-
|17
|2, 18, 20, 38, 68, 3122, 3488, 39500, ...
|{{OEIS link|id=A299380}}
|-
|18
|1, 2, 6, 8, 10, 28, 30, 39, 45, 112, 348, 380, 458, 585, 17559, 38751, 43346, 46984, 92711, ...
|{{OEIS link|id=A299381}}
|-
|19
|12, 410, 33890, 91850, 146478, 189620, 280524, ...
|{{OEIS link|id=A299382}}
|-
|20
|1, 18, 44, 60, 80, 123, 429, 1166, 2065, 8774, 35340, 42968, 50312, 210129, ...
|{{OEIS link|id=A299383}}
|-
|21
|2, 18, 200, 282, 294, 1174, 2492, 4348, ...
|
|-
|22
|2, 5, 140, 158, 263, 795, 992, 341351, ...
|
|-
|23
|29028, ...
|
|-
|24
|1, 2, 5, 12, 124, 1483, 22075, 29673, 64593, ...
|
|-
|25
|2, 68, 104, 450, ...
|
|-
|26
|3, 8, 79, 132, 243, 373, 720, 1818, 11904, 134778, ...
|
|-
|27
|10, 18, 20, 2420, 6638, 11368, 14040, 103444, ...
|
|-
|28
|2, 5, 6, 12, 20, 47, 71, 624, 1149, 2399, 8048, 30650, 39161, ...
|
|-
|29
|26850, 237438, 272970, ...
|
|-
|30
|1, 63, 331, 366, 1461, 3493, 4002, 5940, 13572, 34992, 182461, 201038, ...
|
|}

{{As of|2018|10}}, the largest known generalized Woodall prime is 17016602×2&lt;sup&gt;17016602&lt;/sup&gt; − 1.

==See also==
* [[Mersenne prime]] - Prime numbers of the form 2&lt;sup&gt;''n''&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;1.

==References==
{{Reflist}}

==Further reading==
* {{Citation |first=Richard K. |last=Guy |authorlink=Richard K. Guy |title=Unsolved Problems in Number Theory |edition=3rd |publisher=[[Springer Verlag]] |location=New York |year=2004 |isbn=0-387-20860-7 |pages=section B20 }}.
* {{Citation |first=Wilfrid |last=Keller |title=New Cullen Primes |journal=[[Mathematics of Computation]] |volume=64 |issue=212 |year=1995 |pages=1733–1741 |url=http://www.ams.org/mcom/1995-64-212/S0025-5718-1995-1308456-3/S0025-5718-1995-1308456-3.pdf |doi=10.2307/2153382}}.
* {{Citation |first=Chris |last=Caldwell |url=http://primes.utm.edu/top20/page.php?id=7 |title=The Top Twenty: Woodall Primes |work=The [[Prime Pages]] |accessdate=December 29, 2007 }}.

==External links==
* Chris Caldwell, [http://primes.utm.edu/glossary/page.php?sort=WoodallNumber The Prime Glossary: Woodall number], and [http://primes.utm.edu/top20/page.php?id=7 The Top Twenty: Woodall], and [http://primes.utm.edu/top20/page.php?id=45 The Top Twenty: Generalized Woodall], at The [[Prime Pages]].
* {{MathWorld|urlname=WoodallNumber|title=Woodall number}}
* Steven Harvey, [http://harvey563.tripod.com/GeneralizedWoodallPrimes.txt List of Generalized Woodall primes].
* Paul Leyland, [https://web.archive.org/web/20120204131629/http://www.leyland.vispa.com/numth/factorization/cullen_woodall/gcw.htm Generalized Cullen and Woodall Numbers]

{{Prime number classes|state=collapsed}}
{{Classes of natural numbers}}
__NOTOC__

{{DEFAULTSORT:Woodall Number}}
[[Category:Integer sequences]]
[[Category:Unsolved problems in mathematics]]</text>
      <sha1>1iagdbdtxhkj1m4u9ga6flrszohmwqh</sha1>
    </revision>
  </page>
</mediawiki>
