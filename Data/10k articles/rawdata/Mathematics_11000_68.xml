<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>208 (number)</title>
    <ns>0</ns>
    <id>6317356</id>
    <revision>
      <id>835807467</id>
      <parentid>835800597</parentid>
      <timestamp>2018-04-10T21:57:06Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>Undid revision 835800597 by [[Special:Contributions/86.169.201.181|86.169.201.181]] ([[User talk:86.169.201.181|talk]]) that's not the name of that OEIS entry</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1623">{{Infobox number
| number = 208
}}
'''208''' ('''two hundred [and] eight''') is the [[natural number]] following [[207 (number)|207]] and preceding [[209 (number)|209]]. 

208 is a [[practical number]],&lt;ref&gt;{{Cite OEIS|A005153|name=Practical numbers}}&lt;/ref&gt;
a [[tetranacci number]],&lt;ref&gt;{{Cite OEIS|A000078|name=Tetranacci numbers}}&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Waddill | first = Marcellus E.
 | issue = 1
 | journal = The Fibonacci Quarterly
 | mr = 1146535
 | pages = 9–20
 | title = The Tetranacci sequence and generalizations
 | url = http://www.fq.math.ca/Scanned/30-1/waddill.pdf
 | volume = 30
 | year = 1992}}.&lt;/ref&gt; a rhombic matchstick number,&lt;ref&gt;{{Cite OEIS|A045944|name=Rhombic matchstick numbers}}&lt;/ref&gt; a [[happy number]], and a member of [[Aronson's sequence]].&lt;ref&gt;{{Cite OEIS|A005224|name=T is the first, fourth, eleventh, ... letter in this sentence, not counting spaces or commas (Aronson's sequence)}}&lt;/ref&gt;
There are exactly 208 five-bead [[necklace (combinatorics)|necklaces]] drawn from a set of beads with four colors,&lt;ref&gt;{{Cite OEIS|A001868|name=Number of n-bead necklaces with 4 colors}}&lt;/ref&gt;
and 208 generalized weak orders on three labeled points.&lt;ref&gt;{{Cite OEIS|A004121|name=Generalized weak orders on n points}}&lt;/ref&gt;&lt;ref&gt;{{citation
 | last = Wagner | first = Carl G.
 | doi = 10.1007/BF01899195
 | issue = 2
 | journal = Archiv der Mathematik
 | mr = 675654
 | pages = 147–152
 | title = Enumeration of generalized weak orders
 | volume = 39
 | year = 1982}}.&lt;/ref&gt;

==References==
{{reflist|30em}}
{{Integers|2}}

{{DEFAULTSORT:208 (Number)}}
[[Category:Integers]]

{{Number-stub}}</text>
      <sha1>3nqrdgk3yjs7uf4n0u0iyy4tdbrzuf3</sha1>
    </revision>
  </page>
  <page>
    <title>AMS Distinguished Public Service Award</title>
    <ns>0</ns>
    <id>57181697</id>
    <revision>
      <id>852139906</id>
      <parentid>848073214</parentid>
      <timestamp>2018-07-26T22:21:32Z</timestamp>
      <contributor>
        <username>Josvebot</username>
        <id>14967932</id>
      </contributor>
      <minor/>
      <comment>Fixing [[WP:CHECKWIKI]] #16: unicode contol charater (and other minor genral edits caused by AWB), replaced: →</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1597">{{more citations needed|date=June 2018}}

The '''AMS Distinguished Public Service Award''', awarded every 2 years by the [[American Mathematical Society]], recognizes a research mathematician who has made a distinguished contribution to the mathematics profession during the preceding five years. It was first awarded in 1990.&lt;ref&gt;{{Cite book|url=https://www.worldcat.org/oclc/37513025|title=Recognizing excellence in the mathematical sciences : an international compilation of awards, prizes, and recipients|date=1997|publisher=JAI Press|others=Jaguszewski, Janice M.|isbn=0762302356|location=Greenwich, Conn.|oclc=37513025}}&lt;/ref&gt;

== Recipients ==
The recipients of the AMS Distinguished Public Service Award are:&lt;ref&gt;{{Cite web|url=http://www.ams.org/profession/prizes-awards/ams-awards/public-service-award|title=American Mathematical Society|website=www.ams.org|language=en-US|access-date=2018-04-20}}&lt;/ref&gt;

* 1990: Kenneth M. Hoffman
* 1991: No award
* 1992: Harvey B. Keynes
* 1993: [[Isadore Singer|I. M. Singer]]  
* 1995: [[Donald John Lewis|Donald J. Lewis]]
* 1997: No award made
* 1998: [[Kenneth Millett|Kenneth C. Millett]]
* 2000: [[Paul Sally|Paul J. Sally, Jr.]]
* 2002: [[Margaret H. Wright]]
* 2004: [[Richard A. Tapia]]
* 2006: [[Roger Evans Howe|Roger Howe]]
* 2008: [[Herbert Clemens]]
* 2010: [[Carlos Castillo-Chavez]]
* 2012: [[William G. McCallum|William McCallum]]
* 2014: [[Philip Kutzko]]
* 2016: Aloysius Helminck
* 2018: [[Sylvain Cappell]]

== References ==
&lt;references /&gt;

[[Category:Mathematics awards]]
[[Category:Awards of the American Mathematical Society]]</text>
      <sha1>9ad9bb9reomxp6ugp9tj87mmt85dlz7</sha1>
    </revision>
  </page>
  <page>
    <title>Abstract additive Schwarz method</title>
    <ns>0</ns>
    <id>16269602</id>
    <revision>
      <id>724235653</id>
      <parentid>649474318</parentid>
      <timestamp>2016-06-07T23:59:01Z</timestamp>
      <contributor>
        <username>Trappist the monk</username>
        <id>10289486</id>
      </contributor>
      <minor/>
      <comment>/* top */Remove unnecessary |display-authors= / |display-editors= parameters from CS1 templates; using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1353">In [[mathematics]], the '''abstract additive Schwarz method''', named after [[Hermann Schwarz]], is an abstract version of the [[additive Schwarz method]] for [[boundary value problem]]s on [[partial differential equation]]s, formulated only in terms of [[linear algebra]] without reference to domains, subdomains, etc. Many if not all [[domain decomposition methods]] can be cast as abstract additive Schwarz method, which is often the first and most convenient approach to their analysis.&lt;ref&gt;{{citation|first1=Maksymilian|last1=Dryja|first2=Olof B.|last2=Widlund|author2-link=Olof B. Widlund|contribution=Towards a unified theory of domain decomposition algorithms for elliptic problems|editor1-first=Tony|editor1-last=Chan|editor2-first=Roland|editor2-last=Glowinski|editor3-first=Jacques|editor3-last=Périaux|editor4-first=Olof B.|editor4-last=Widlund|title=Third International Symposium on Domain Decomposition Methods for Partial Differential Equations (Houston, Texas, March 20–22, 1989)|pages=3–21|publisher=SIAM|location=Philadelphia, PA|year=1990|url=http://www.ddm.org/DD03/Towards_a_Unified_Theory_of_Domain_Decomposition_Algorithms_for_Elliptic_Problems_(Dryj.pdf}}.&lt;/ref&gt;

==References==
{{reflist}}

{{Numerical PDE}}

{{DEFAULTSORT:Abstract Additive Schwarz Method}}
[[Category:Domain decomposition methods]]


{{mathapplied-stub}}</text>
      <sha1>qlgi1l9tmuaschy5zvypk173x6ysvv0</sha1>
    </revision>
  </page>
  <page>
    <title>Annals of Applied Probability</title>
    <ns>0</ns>
    <id>31018340</id>
    <revision>
      <id>849061984</id>
      <parentid>801487799</parentid>
      <timestamp>2018-07-06T07:29:04Z</timestamp>
      <contributor>
        <ip>2001:638:501:526C:F4D5:F9E8:9FCC:BE2B</ip>
      </contributor>
      <comment>/* External links */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1532">{{Infobox journal
 | title        = The Annals of Applied Probability
 | cover        = 
 | abbreviation = Ann. Appl. Probab.
 | discipline   = [[Probability]]
 | editor       = {{nowrap|1=[[Andrew Barbour]]}}
 | publisher    = [[Institute of Mathematical Statistics]]
 | frequency    = Bimonthly
 | history      = 1991–present
 | impact       = 1.755
 | impact-year  = 2015
 | ISSN         = 1050-5164
 | eISSN        = 
 | CODEN        = 
 | LCCN         = 91650942
 | OCLC         = 
 | link1        = http://projecteuclid.org/DPubS?service=UI&amp;version=1.0&amp;verb=Display&amp;page=current&amp;handle=euclid.aoap 
 | link1-name   = Online access
 | url = http://imstat.org/aap/
}}

''''' The Annals of Applied Probability''''' is a [[peer review|peer-reviewed]] [[mathematics journal]] published by the [[Institute of Mathematical Statistics]]. The journal was established in 1991 by founding editor [[J. Michael Steele]] and is indexed by ''[[Mathematical Reviews]]'' and [[Zentralblatt MATH]].
Its 2009 [[Mathematical Citation Quotient|MCQ]] was 1.02. Its 2015 [[impact factor]] was 1.755, and it was 1.454 in 2014.

==External links==
*{{Official website|1=https://www.imstat.org/journals-and-publications/annals-of-applied-probability/}}

[[Category:Probability journals]]
[[Category:Publications established in 1991]]
[[Category:English-language journals]]
[[Category:Bimonthly journals]]
[[Category:Institute of Mathematical Statistics academic journals]]
[[Category:1991 establishments in the United States]]


{{math-journal-stub}}</text>
      <sha1>13unfg7c277r0odoihk308qqirwm3iv</sha1>
    </revision>
  </page>
  <page>
    <title>Antifragile</title>
    <ns>0</ns>
    <id>37758875</id>
    <revision>
      <id>869473543</id>
      <parentid>860851074</parentid>
      <timestamp>2018-11-18T21:07:29Z</timestamp>
      <contributor>
        <username>InternetArchiveBot</username>
        <id>27015025</id>
      </contributor>
      <comment>Rescuing 3 sources and tagging 0 as dead. #IABot (v2.0beta10)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="27426">{{about|the book|the concept|Antifragility}}
{{Infobox book
&lt;!-- |italic title = (see above) --&gt;
| name             = Antifragile: Things That Gain from Disorder
| image            = Antifragile.png
| size             = 
| border           = yes
| caption          = Hardcover, 1st edition 
| author           = [[Nassim Nicholas Taleb]]
| title_orig       = 
| translator       = 
| illustrator      = 
| cover_artist     = 
| country          = United States
| language         = English
| series           = ''[[Incerto]]''
| subject          = Philosophy, mathematics, business, economics
| genre            = Non-fiction 
| publisher        = [[Random House]] ''(US)''&lt;br&gt;[[Penguin Books]] ''(UK)''
| publisher2       = 
| pub_date         = November 27, 2012
| english_pub_date = 
| media_type       = Print, E-book
| pages            = 519 pp
| awards           = 
| isbn             = 1-400-06782-0
| oclc             = 
| dewey            = 155.24 TA
| congress         = 
| preceded_by      = [[The Bed of Procrustes: Philosophical and Practical Aphorisms|The Bed of Procrustes]]
| followed_by      = [[Skin in the Game (book)|Skin in the Game]]
| wikisource       =
}}

'''''Antifragile: Things That Gain From Disorder''''' is a book by [[Nassim Nicholas Taleb]] published on November 27, 2012, by [[Random House]] in the United States and [[Penguin Books|Penguin]] in the United Kingdom. This book builds upon ideas from his previous works including ''[[Fooled by Randomness]]'' (2001), [[The Black Swan: The Impact of the Highly Improbable|''The Black Swan'']] (2007–2010), and ''[[The Bed of Procrustes]]'' (2010–2016) and is the fourth book in the five-volume philosophical treatise on uncertainty titled ''[[Incerto]]''. Some of the ideas are expanded in Taleb’s fifth book [[Skin in the Game (book)|''Skin in the Game: Hidden Asymmetries in Daily Life'']] (2018).

==Introduction==
Taleb introduces the book as follows: "Some things benefit from shocks; they thrive and grow when exposed to volatility, ''[[randomness]]'', disorder, and stressors and love adventure, [[risk]], and [[uncertainty]]. Yet, in spite of the ubiquity of the phenomenon, there is no word for the exact opposite of fragile. Let us call it antifragile. Antifragility is beyond resilience or robustness. The resilient resists shocks and stays the same; the antifragile gets better".&lt;ref&gt;{{cite web|url=http://www.fooledbyrandomness.com/prologue.pdf|format=PDF|title=Prologue|website=Fooledbyrandomness.com|accessdate=3 November 2017}}&lt;/ref&gt; 
The phenomenon is well studied in medicine, where for example [[Wolff's law]] describes how bones grow stronger due to external load.
[[Hormesis]] is an example of mild antifragility, where the stressor is a poisonous substance and the antifragile becomes better overall from a small dose of the stressor. This is different from robustness or resilience in that the antifragile system improves with, not withstands, stressors, where the stressors are neither too large or small. The larger point, according to Taleb, is that depriving systems of vital stressors is not necessarily a good thing and can be downright harmful.

More technically, Taleb defines antifragility as a nonlinear response: "Simply, antifragility is defined as a convex response to a stressor or source of harm (for some range of variation), leading to a positive sensitivity to increase in volatility (or variability, stress, dispersion of outcomes, or uncertainty, what is grouped under the designation "disorder cluster"). Likewise fragility is defined as a concave sensitivity to stressors, leading a negative sensitivity to increase in volatility. The relation between fragility, convexity and sensitivity to disorder is mathematical, obtained by theorem, not derived from [[empirical research|empirical]] [[data mining]] or some historical narrative. It is [[a priori and a posteriori|a priori]]".&lt;ref&gt;{{cite arxiv |eprint=1208.1189|title=Mathematical Definition, Mapping, and Detection of (Anti)Fragility|author1=N. N. Taleb|author2=R Douady|authorlink=Nassim Nicholas Taleb|class=q-fin.RM|year=2012}}&lt;/ref&gt;

As the book progresses, Taleb covers in great depth the domain of the fragile and the opposing domain of the antifragile showing how fragility can be detected, measured, and transformed. Recurring themes throughout the book include [[Skin in the game (phrase)|Skin in the Game]], [[Via Negativa]], [[Lindy effect|Lindy Effect]], [[Barbell strategy|Barbell Strategy]] and the [[Antifragile#Green Lumber Fallacy|Green Lumber Fallacy]].

==Impact ==
The concept of antifragility has been applied in [[physics]],&lt;ref name="Naji, A. 2014"&gt;Naji, A., Ghodrat, M., Komaie-Moghaddam, H., &amp; Podgornik, R. (2014). Asymmetric Coulomb fluids at randomly charged dielectric interfaces: Anti-fragility, overcharging and charge inversion. J. Chem. Phys. 141 174704.&lt;/ref&gt; [[risk analysis]],&lt;ref name="Derbyshire, J. 2014"&gt;Derbyshire, J., &amp; Wright, G. (2014). Preparing for the future: Development of an ‘antifragile’ methodology that complements scenario planning by omitting causation. Technological Forecasting and Social Change, 82, 215–225.&lt;/ref&gt;&lt;ref&gt;Aven, T. (2014). The Concept of Antifragility and its Implications for the Practice of Risk Analysis. Risk Analysis.&lt;/ref&gt; [[molecular biology]],&lt;ref name="Grube, M. 2013 pp. 551-566"&gt;Grube, M., Muggia, L., &amp; Gostinčar, C. (2013). Niches and Adaptations of Polyextremotolerant Black Fungi. In Polyextremophiles (pp. 551–566). Springer Netherlands.&lt;/ref&gt;&lt;ref&gt;{{cite journal|author1=Antoine Danchin|author2=Philippe M. Binder|author3=Stanislas Noria|title=Antifragility and Tinkering in Biology (and in Business) Flexibility Provides an Efficient Epigenetic Way to Manage Risk|journal=Genes|date=2011|volume=2|issue=4|pages=998–1016|doi=10.3390/genes2040998|pmid=24710302}}&lt;/ref&gt; [[transportation planning]],&lt;ref name="Levin, J. S. 2014, pp. 285-292"&gt;Levin, J. S., Brodfuehrer, S. P., &amp; Kroshl, W. M. (2014, March). Detecting antifragile decisions and models lessons from a conceptual analysis model of Service Life Extension of aging vehicles. In Systems Conference (SysCon), 2014 8th Annual IEEE (pp. 285–292). IEEE.&lt;/ref&gt;&lt;ref&gt;{{cite journal|last1=Isted|first1=Richard|title=The Use of Anti-Fragility Heuristics in Transport Planning|date=August 2014|issue=3|url=http://www.aitpm.com.au/ArticleDocuments/249/Transport_and_Land_Use_Session_3-Richard_Isted_The_use_of_anti_fragility_heuristics_in_transport_planning.pdf.aspx?Embed=Y|publisher=Australian Institute of Traffic Planning and Management National Conference|location=Adelaide, South Australia|journal=|access-date=2015-01-16|archive-url=https://web.archive.org/web/20160303214045/http://www.aitpm.com.au/ArticleDocuments/249/Transport_and_Land_Use_Session_3-Richard_Isted_The_use_of_anti_fragility_heuristics_in_transport_planning.pdf.aspx?Embed=Y#|archive-date=2016-03-03|dead-url=yes|df=}}&lt;/ref&gt; [[engineering]],&lt;ref name="Jones, K. H. 2014"&gt;{{cite journal | last1 = Jones | first1 = K. H. | year = 2014 | title = Engineering Antifragile Systems: A Change In Design Philosophy | url = | journal = Procedia Computer Science | volume = 32 | issue = | pages = 870–875 | doi=10.1016/j.procs.2014.05.504}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Verhulsta | first1 = E | year = 2014 | title = Applying Systems and Safety Engineering Principles for Antifragility | url = | journal = Procedia Computer Science | volume = 32 | issue = | pages = 842–849 | doi=10.1016/j.procs.2014.05.500}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Lichtman|first=M.|last2=Vondal|first2=M. T.|last3=Clancy|first3=T. C.|last4=Reed|first4=J. H.|date=2016-01-01|title=Antifragile Communications|url=http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7409948|journal=IEEE Systems Journal|volume=PP|issue=99|pages=1–12|doi=10.1109/JSYST.2016.2517164|issn=1932-8184|bibcode=2018ISysJ..12..659L}}&lt;/ref&gt; Aerospace (NASA),&lt;ref&gt;{{Cite web |url=https://ntrs.nasa.gov/search.jsp?R=20160007433# |title=Archived copy |access-date=2016-11-16 |archive-url=https://web.archive.org/web/20161117064741/https://ntrs.nasa.gov/search.jsp?R=20160007433# |archive-date=2016-11-17 |dead-url=yes |df= }}&lt;/ref&gt; megaproject management,&lt;ref&gt;{{Cite journal|author1=Atif Ansar |author2=Bent Flyvbjerg |author3=Alexander Budzier |author4=Daniel Lunn |date=2016|title=Big is Fragile: An Attempt at Theorizing Scale|ssrn=2741198|journal=The Oxford Handbook of Megaproject Management, Oxford University Press|doi=|pmid=|access-date=}}&lt;/ref&gt; and [[computer science]].&lt;ref name="Jones, K. H. 2014"/&gt;&lt;ref name="Ramirez, C. A. 2014"&gt;Ramirez, C. A., &amp; Itoh, M. (2014, September). An initial approach towards the implementation of human error identification services for antifragile systems. In SICE Annual Conference (SICE), 2014 Proceedings of the (pp. 2031–2036). IEEE.&lt;/ref&gt;&lt;ref name="Abid, A. 2014"&gt;{{cite journal | last1 = Abid | first1 = A. | last2 = Khemakhem | first2 = M. T. | last3 = Marzouk | first3 = S. | last4 = Jemaa | first4 = M. B. | last5 = Monteil | first5 = T. | last6 = Drira | first6 = K. | year = 2014 | title = Toward Antifragile Cloud Computing Infrastructures | url = | journal = Procedia Computer Science | volume = 32 | issue = | pages = 850–855 | doi=10.1016/j.procs.2014.05.501}}&lt;/ref&gt;&lt;ref name="Monperrus, M. 2014"&gt;{{cite journal|last1=Monperrus|first1=Martin|title=Principles of Antifragile Software|year=2017|doi=10.1145/3079368.3079412|arxiv=1404.3056|url=http://arxiv.org/pdf/1404.3056}}&lt;/ref&gt;&lt;ref&gt;{{cite journal | last1 = Guang | first1 = L. | last2 = Nigussie | first2 = E. | last3 = Plosila | first3 = J. | last4 = Tenhunen | first4 = H. | year = 2014 | title = Positioning Antifragility for Clouds on Public Infrastructures | url = | journal = Procedia Computer Science | volume = 32 | issue = | pages = 856–861 | doi=10.1016/j.procs.2014.05.502}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Lichtman|first=Marc|date=2016-08-16|title=Antifragile Communications|url=http://vtechworks.lib.vt.edu/handle/10919/72267|journal=Virginia Tech|volume=|issue=|doi=|pmid=|access-date=|via=}}&lt;/ref&gt;

In computer science, there is a structured proposal for an "Antifragile Software Manifesto", to react to traditional system designs.&lt;ref&gt;{{Cite journal|last=Russo|first=Daniel|last2=Ciancarini|first2=Paolo|date=2016-01-01|title=A Proposal for an Antifragile Software Manifesto|url=http://www.sciencedirect.com/science/article/pii/S1877050916302290|journal=Procedia Computer Science|series=The 7th International Conference on Ambient Systems, Networks and Technologies (ANT 2016) / The 6th International Conference on Sustainable Energy Information Technology (SEIT-2016) / Affiliated Workshops|volume=83|pages=982–987|doi=10.1016/j.procs.2016.04.196}}&lt;/ref&gt; The major idea is to develop antifragility by design, building a system which improves from environment's input.

== Skin in the game ==
{{Main|Skin in the game (phrase)}}
To have "skin in the game" is to have incurred risk by being involved in achieving a goal. Taleb extends the definition to include any risk so that “Every captain goes down with every ship”. This removes the [[principal–agent problem|agency problem]] or in other words “Situation in which the manager of a business is not the true owner, so he follows a strategy that cosmetically seems to be sound, but in a hidden way benefits him and makes him antifragile at the expense (fragility) of the true owners or society. When he is right, he collects large benefits; when he is wrong, others pay the price. Typically this problem leads to fragility, as it is easy to hide risks. It also affects politicians and academics. A major source of fragility.”&lt;ref name="antifragile book p430"/&gt;{{rp|430}}

{{quotation|To me, every opinion maker needs to have “skin in the game” in the event of harm caused by reliance on his information or opinion (not having such persons as, say, the people who helped cause the criminal Iraq invasion come out of it completely unscathed). Further, anyone producing a forecast or making an economic analysis needs to have something to lose from it, given that others rely on those forecasts (to repeat, forecasts induce risk taking; they are more toxic to us than any other form of human pollution).&lt;ref name="antifragile book np"/&gt;{{rp|382}}}}

Taleb’s next book ''[[Skin in the Game (book)|Skin in the Game: Hidden Asymmetries in Daily Life]]'' furthers the idea, asserting it is necessary for fairness, commercial efficiency, and risk management, as well as being necessary to understand the world.

== Via negativa ==
{{Main|Via negativa}}
Via negativa is a type of theological thinking that attempts to describe God by negation or in other words, by what God is not. Taleb expanded this definition to include more generally the focus on what something is not, in action, what to avoid or what not to do. Avoiding the doctor for minor illnesses or removing certain food from one’s diet to improve health are examples.

{{quotation|I would add that, in my own experience, a considerable jump in my personal health has been achieved by removing offensive irritants: the morning newspapers (the mere mention of the names of the fragilista journalists [[Thomas Friedman]] or [[Paul Krugman]] can lead to explosive bouts of unrequited anger on my part), the boss, the daily commute, air-conditioning (though not heating), television, emails from documentary filmmakers, economic forecasts, news about the stock market, gym “strength training” machines, and many more.&lt;ref name="antifragile book np"/&gt;{{rp|363}}}}

== Lindy effect ==
{{Main|Lindy effect}}
A technology, or anything nonperishable, increases in life expectancy with every day of its life—unlike perishable items (such as humans, cats, dogs, and tomatoes). So a book that has been a hundred years in print is likely to stay in print another hundred years. The opposite is Neomania, a love of change for its own sake, a form of philistinism that does not comply with the Lindy effect and that understands fragility. Forecasts the future by adding, not subtracting.&lt;ref name="antifragile book p430"/&gt;{{rp|430}}

== Barbell strategy ==
{{Main|Barbell strategy}}
In finance, a Barbell strategy is formed when a Trader invests in Long and Short duration bonds, but does not invest in Intermediate duration bonds. This strategy is useful when interest rates are rising; as the short term maturities are rolled over they receive a higher interest rate, raising the value. Taleb generalizes the phenomenon and applies it to other domains. Essentially it is the transformation of anything from fragile to antifragile.

{{quotation | A dual strategy, a combination of two extremes, one safe and one speculative, deemed more robust than a “monomodal” strategy; often a necessary condition for antifragility. For instance, in biological systems, the equivalent of marrying an accountant and having an occasional fling with a rock star; for a writer, getting a stable sinecure and writing without the pressures of the market during spare time. Even trial and error are a form of barbell.&lt;ref name="antifragile book np"/&gt;{{rp|428}}}}

== Green Lumber Fallacy ==
The Green Lumber Fallacy refers to a kind of [[fallacy]] where one mistakes one important kind of knowledge for another; in other words, "mistaking the source of important or even necessary knowledge, for another less visible from the outside, less tractable one... how many things we call 'relevant knowledge' aren’t so much so".&lt;ref name="antifragile book p430"&gt;{{cite book |author=Nassim Nicholas Taleb |authorlink=Nassim Nicholas Taleb |year=2012 |title=Antifragile: Things That Gain from Disorder |publisher=[[Random House]] |page=430 |url=https://books.google.com/?id=5E5o3_y5TpAC&amp;pg=PA430&amp;lpg=PA430&amp;dq=antifragile+Mistaking+the+source+of+important+or+even+necessary#v=onepage&amp;q=antifragile%20Mistaking%20the%20source%20of%20important%20or%20even%20necessary&amp;f=false |isbn=9781400067824}}&lt;/ref&gt;{{rp|430}} Mathematically, it is the use of an incorrect function that, by chance, returns the correct output, such that one conflates ''g''&amp;nbsp;(x) with ''f''&amp;nbsp;(x). The root of the fallacy is that although people may be focusing on the right things, due to complexity of the thing, they are not good enough to figure it out intellectually.

The term ''green lumber'' refers to a story by authors Jim Paul and Brendan Moynihan in their book ''What I Learned Losing A Million Dollars'', where a trader made a fortune trading lumber he thought was literally "green" rather than fresh cut.&lt;ref&gt;{{cite book |author1=Jim Paul |author2=Brendan Moynihan |year=2013 |title=What I Learned Losing a Million Dollars |publisher=[[Columbia University Press]] |url=https://books.google.com/books?id=ZGowrCKiX24C&amp;q=one+morning+joe#v=snippet&amp;q=one%20morning%20joe&amp;f=false |isbn=9780231535236}}&lt;/ref&gt; "This gets at the idea that a supposed understanding of an investment rationale, a narrative or a theoretical model is unhelpful in practical trading."&lt;ref&gt;{{cite web|url=https://finance.yahoo.com/blogs/michael-santoli/gold-not-antifragile-enough-black-swan-author-141516155.html|title=Gold Not ‘Antifragile’ Enough for ‘Black Swan’ Author|website=Finance.yahoo.com|accessdate=3 November 2017}}&lt;/ref&gt;

{{quotation|The protagonist makes a big discovery. He remarks that a fellow named Joe Siegel, one of the most successful traders in a commodity called "green lumber," actually thought that it was lumber painted green (rather than freshly cut lumber, called green because it had not been dried). And he made it his profession to trade the stuff! Meanwhile the narrator was into grand intellectual theories and narratives of what caused the price of commodities to move, and went bust. It is not just that the successful expert on lumber was ignorant of central matters like the designation "green." He also knew things about lumber that nonexperts think are unimportant. People we call ignorant might not be ignorant. The fact is that predicting the order flow in lumber and the usual narrative had little to do with the details one would assume from the outside are important. People who do things in the field are not subjected to a set exam; they are selected in the most nonnarrative manner—nice arguments don’t make much difference.&lt;ref name="antifragile book np"&gt;{{cite book |author=Nassim Nicholas Taleb |authorlink=Nassim Nicholas Taleb |year=2012 |title=Antifragile: Things That Gain from Disorder |publisher=[[Random House]]}}&lt;/ref&gt;{{rp|needed=y|date=March 2018}}}}

=== Early occurrences ===
An early occurrence of this fallacy is found in the ancient story of [[Thales]]. [[Aristotle]] explains that Thales reserved presses ahead of the olive harvest at a discount only to rent them out at a high price when demand peaked, following his predictions of a particularly good harvest. Aristotle attributes Thales’ success to his ability to correctly forecast the weather. However, it was not his ability to forecast that made Thales successful but that "Thales put himself in a position to take advantage of his lack of knowledge… that he did not need to understand too much the messages from the stars… that was the very first [[option (finance)|option]] on record".&lt;ref name="antifragile book np"/&gt;{{rp|needed=y|date=March 2018}}

=== Green Lumber Problem ===
The Green Lumber Fallacy only becomes a problem (namely, the Green Lumber Problem) when the perpetuation of the fallacy has a high, and opaque, negative impact. For example:
* Green Lumber Fallacy and a Green Lumber Problem: "[[James Le Fanu]] showed how our understanding of the biological processes was coupled with a decline of pharmaceutical discoveries, as if rationalistic theories were blinding and somehow a handicap".&lt;ref name="antifragile book np"/&gt;{{rp|needed=y|date=March 2018}}
* Green Lumber Fallacy Only: "The same holds for the statement {{'}}''[[weight training|lifting weights]] increases your [[muscle mass]]''{{'}}. In the past they used to say that weight lifting caused the 'micro-tearing of muscles', with subsequent healing and increase in size. Today some people discuss [[hormonal]] [[endocrine system|signaling]] or genetic mechanisms, tomorrow they will discuss something else. But the effect has held forever and will continue to do so."&lt;ref name="antifragile book np"/&gt;{{rp|needed=y|date=March 2018}}

== The Alan Blinder problem ==
Toward the end of the book Taleb provides examples of the problems of agency and cherry-picking, calling them the [[Robert Rubin]] problem, the [[Joseph Stiglitz]] problem, and the Alan Blinder problem. In the last chapter (p.&amp;nbsp;412), for example, Taleb criticizes [[Alan Blinder]], the former vice chairman of the board of governors of the [[Federal Reserve System]] for trying to sell him an investment product at [[World Economic Forum|Davos]] in 2008 which would allow an investor to circumvent the regulations limiting [[deposit insurance]] and to benefit from coverage for near unlimited amounts. Taleb commented that the scheme "would allow the super-rich to scam taxpayers by getting free government-sponsored insurance". He also criticized Blinder for using ex-regulators to game the system which they built in the first place and for voicing his opposition to policies of bank insurance that would hurt his business, i.e., claiming that what is good for his business is "for the public good". The event has been discussed in the media, but not denied by Blinder.&lt;ref&gt;{{cite web|url=https://www.huffingtonpost.com/nassim-nicholas-taleb/the-regulator-franchise-o_b_667967.html|title=The Regulator Franchise, or the Alan Blinder Problem|first=Nassim Nicholas|last=Taleb|authorlink=Nassim Nicholas Taleb |date=2 August 2010|website=Huffingtonpost.com|accessdate=3 November 2017}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://regator.com/p/244047854/taleb_calls_out_alan_blinder_for_questionable_ethics/# |title=Archived copy |access-date=2015-06-01 |archive-url=https://web.archive.org/web/20150507103914/http://regator.com/p/244047854/taleb_calls_out_alan_blinder_for_questionable_ethics/# |archive-date=2015-05-07 |dead-url=yes |df= }}&lt;/ref&gt;

== Critical reception ==
''Antifragile'' was a [[New York Times Bestseller|''New York Times'' Bestseller]] and praised by critics in a litany of notable periodicals including the ''[[Harvard Business Review]]'',&lt;ref&gt;{{cite web|url=https://hbr.org/2012/11/nassim-talebs-cure-for-fragili|title=Nassim Taleb’s Cure for Fragility|website=Hbr.org|accessdate=3 November 2017}}&lt;/ref&gt; ''[[Fortune (magazine)|Fortune]]'' magazine,&lt;ref&gt;{{cite news|url=http://fortune.com/2012/12/14/antifragility-how-disorder-makes-us-stronger/?iid=sr-link1|title=Antifragility: How disorder makes us stronger|work=[[Fortune (magazine)|Fortune]]|accessdate=3 November 2017}}&lt;/ref&gt; the ''[[New Statesman]]'',&lt;ref&gt;{{cite web|url=http://fooledbyrandomness.com/clergyman.pdf|format=PDF|author=Ed Smith |title=Left Field From Michael Lewis to Montaigne, the best writers first live an interesting life| website=Fooledbyrandomness.com|accessdate=3 November 2017}}&lt;/ref&gt; and ''[[The Economist]]'',&lt;ref&gt;{{cite news| url=https://www.economist.com/news/books-and-arts/21566619-how-surprises-make-you-stronger-stress-best| title=Stress best| work=[[The Economist]]| accessdate=3 November 2017}}&lt;/ref&gt; and Forbes.&lt;ref&gt;{{cite news| url=https://www.forbes.com/sites/moneybuilder/2013/01/23/nassim-talebs-antifragile-celebrates-randomness-in-people-markets/ |title=Nassim Taleb's 'Antifragile' Celebrates Randomness In People, Markets| first=Charles |last=Sizemore |work=[[Forbes]] |accessdate=3 November 2017}}&lt;/ref&gt; Although Boyd Tonkin of ''[[The Independent]]'' criticized Taleb’s style as "vulgar, silly, slapdash and infuriating", of the ideas in the book he remarked "time and again I returned to two questions about his core ideas: Is he right, and does it matter? My verdict? Yes, and yes."&lt;ref&gt;{{cite news|url=https://www.independent.co.uk/arts-entertainment/books/reviews/antifragile-by-nassim-nicholas-taleb-8343870.html|title=Antifragile, By Nassim Nicholas Taleb|date=24 November 2012|work=[[The Independent]]|accessdate=3 November 2017}}&lt;/ref&gt; [[Michael Shermer]] gave the book a generally favorable review&lt;ref&gt;{{cite web|url=http://www.skeptic.com/eskeptic/13-01-09/#feature|title=13-01-09|date=9 January 2013|website=Skeptic.com|accessdate=3 November 2017}}&lt;/ref&gt; but Taleb responded in ''[[Nature (magazine)|Nature]]'' magazine that "Michael Shermer mischaracterizes the concept of ‘antifragility’... The relation of fragility, convexity and sensitivity to disorder is thus mathematical and not derived from empirical data."&lt;ref&gt;{{cite journal | url = http://www.nature.com/nature/journal/v494/n7438/full/494430e.html | title = Antifragility as a mathematical idea | volume=494 | issue = 7438 | doi=10.1038/494430e | journal=[[Nature (magazine)|Nature]] | page=430| year = 2013 | last1 = Taleb | first1 = Nassim N | bibcode=2013Natur.494..430T }}&lt;/ref&gt;

Less favorable reviews include [[Michiko Kakutani]] of ''[[The New York Times]]'', who described the book as being "maddening, bold, repetitious, judgmental, intemperate, erudite, reductive, shrewd, self-indulgent, self-congratulatory, provocative, pompous, penetrating, perspicacious and pretentious."&lt;ref&gt;{{cite news|url=https://www.nytimes.com/2012/12/17/books/antifragile-by-nassim-nicholas-taleb.html|title=‘Antifragile,’ by Nassim Nicholas Taleb|first=Michiko|last=Kakutani|date=16 December 2012|accessdate=3 November 2017|work=[[New York Times]]}}&lt;/ref&gt; Taleb responded in turn by noting one of five errors from her review and questioning "Is she crazy enough to engage a technical subject without asking for specialist advice, or even engaging in something as basic as Google search?"&lt;ref&gt;{{cite web| url=http://www.fooledbyrandomness.com/mishiko.htm| title=Mathematics of Black Swans| website=Fooledbyrandomness.com| accessdate=3 November 2017}}&lt;/ref&gt;

Some of the negative reviews focus on Taleb's style and the overall structure of the book, particularly the difficulty to easily summarize on a cursory review. So although the book has a table of contents, chapter summaries and map, a summary of the book is difficult to discern as the content headers and summaries have no noticeable pattern and many of the titles are abstruse (e.g., Hungry Donkeys) which according to the author is by design intended to handicap book reviewers, forcing them to read the book in its entirety.&lt;ref&gt;{{cite news |url= http://articles.economictimes.indiatimes.com/2015-01-18/news/58200731_1_black-swan-volatility-nassim-nicholas-taleb |title= ET Global Business Summit: Nassim Nicholas Taleb on why he agrees with PM Modi's 'small is beautiful' thesis|quote=”I tried to avoid the US book reviewers by writing something that cannot possibly be reviewed by skimming through. Intentionally, I made no direct connection between the titles of the chapters and the content and you get the metaphor after reading the full chapter“| work=[[India Times]]|accessdate=3 November 2017}}&lt;/ref&gt;

==See also==
* [[Eustress]]
* [[Mathematical fallacy#Howlers|Howlers]]
* [[Lindy effect]]
* [[Moral hazard]]

==References==
{{Reflist}}

{{Nassim Nicholas Taleb}}

[[Category:2012 non-fiction books]]
[[Category:Economics books]]
[[Category:Philosophy books]]
[[Category:Mathematics books]]
[[Category:Books by Nassim Nicholas Taleb]]</text>
      <sha1>i6pydxmnctwanucifv4bf2r2d2xe6pf</sha1>
    </revision>
  </page>
  <page>
    <title>Attractiveness principle</title>
    <ns>0</ns>
    <id>30577937</id>
    <revision>
      <id>836307330</id>
      <parentid>790093106</parentid>
      <timestamp>2018-04-13T23:00:36Z</timestamp>
      <contributor>
        <username>Rich Farmbrough</username>
        <id>82835</id>
      </contributor>
      <minor/>
      <comment>/* History */clean up, replaced: Cambridge, MA → Cambridge, Massachusetts using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13970">'''Attractiveness Principle''' is one of [[System Dynamics]] archetypes. [[System archetype]]s describe common patterns of behavior in dynamic [[complex systems]]. Attractiveness principle is a variation of [[Limits to Growth]] archetype, with restrictions caused by multiple limits. The limiting factors here are each of different character and usually cannot be dealt with the same way and/or (and very likely) they cannot be all addressed.

== Introduction to the problem ==
Attractiveness principle is a concept that incorporates the fact that any product or kind of business cannot ever be ''“all things to all people”'' &lt;ref name="systemsthinking"&gt;Attractiveness Principle at Systems-thinking.org. http://www.systems-thinking.org/theWay/sap/ap.htm&lt;/ref&gt; though companies very often strive to follow this way.&lt;ref name="Powell"&gt;Powell, Bob (2001). The Attractiveness Principle. Continuous Improvement Associates. 1–2. http://www.exponentialimprovement.com/cms/uploads/flyer_attractiveness_principle2p.pdf&lt;/ref&gt; One needs to make necessary decisions on the characteristics of the product as it cannot be perfect in all dimensions. If she doesn’t, the product is not going to be successful as of the natural constraints (limited resources) it will have to face – sooner or later. It is a fact of life that (assuming we know the relationships among the system’s elements) we can influence, inhibit or remove some of these limits through making expert changes in the system. The archetype can help us to get the insight into the system behavior so we could identify and decide which limiting factors to inhibit before they inhibit the results we want to achieve. But there will always be some limits we are not able to reduce and simply “we have to learn to live with them” and make compromises between our goals.

=== Application field ===
Knowledge of the attractiveness principle system archetype is essential in management of various projects and businesses. Managers decide which problem is more attractive in terms of possible future improvement of the company &lt;ref name="Braun"/&gt; – the origin of the archetype’s name actually came from this point. Manager as a decision-maker needs efficient support in solving such complex problems, and system dynamics can play this role. Its main advantage is the ability to reach higher complexity and to provide simultaneous calculations. These can be used to determine the future possible behavior of the [[system]].&lt;ref&gt;Mildeová, Stanislava and Vojtko, Viktor (2006). Selected Chapters of System Dynamics. KARTPRINT. 86–87. {{ISBN|80-88870-60-7}}.&lt;/ref&gt; If managers are able to recognize the archetype in a problem it often helps them to solve it with less cost and they are also often able to change its [[structure]].&lt;ref&gt;Mildeová, Stanislava and Vojtko, Viktor (2003). Systémová dynamika. Oeconomica. 39. {{ISBN|80-245-0626-2}}.&lt;/ref&gt;

=== History ===
The term attractiveness principle was first used by inventor of system dynamics [[Jay W. Forrester]].&lt;ref name="forrester"&gt;Forrester, J. W. (1975). Collected Papers of Jay W. Forrester. Cambridge, Massachusetts: Wright-Allen Press. http://dieoff.org/page23.htm&lt;/ref&gt; According to Forrester, the only way to control growth is to control attractiveness.&lt;ref name="forrester" /&gt; Other references on this topic can be found in The Systems Thinker &lt;ref&gt;The Systems Thinker. Pegasus Communications, Inc. Waltham, MA.&lt;/ref&gt; and in The Fifth Discipline Fieldbook &lt;ref&gt;Senge, P. et al. (1994). The Fifth Discipline Fieldbook. New York: Doubleday Currency.&lt;/ref&gt; in articles and parts by Michael Goodman and Art Kleiner.

== Model ==

=== Structure ===
The system is made up of a [[reinforcing loop]] and at least two [[balancing loop]]s. See [[causal loop diagram]] and [[stock and flow diagram]] for the insight into model fundamentals.&lt;br /&gt;
 [[File:Attractiveness Principle-Causal Loop.svg|thumb|400px|left|Figure 1. Causal loop diagram]] &lt;br /&gt; [[File:Attractiveness principle-stock and flow.svg|thumb|400px|left|Figure 2. Stock and flow diagram]]

The Reinforcing Loop (R1 in Figure 1 and 2) represents accelerating growth – a growing action is producing results. This is a positive feedback loop – the more the growing action taken, the higher the results level, and yet the result itself produces even more of growing action.
Balancing loops (B2 and B3 in Figure 1 and 2) represent the way the system turns back to its original state. Result produced in the reinforcing loop is influenced within the balancing loop. There are (at least) two limits causing the slowing actions in the system and adding to them. Limiting actions start to influence the system at various levels of results, generally. Since that moment slowing actions act in the system simultaneously. Both the slowing actions contribute to the total slowing action. Total slowing action then inhibits the results (this process is delayed in time).
If we get back to the reinforcing loop then we can see the inhibited results are reducing growing action which is leading to the reduced results again.

=== Trade-offs ===
[[Trade-off]]s must be calculated to decide which ones of limits to focus on and address first.&lt;ref name="sherrer"&gt;Sherrer, J. Alex (2010). Fix It With Systems Thinking: Part 4. Project Management Road Trip. http://www.pmroadtrip.com/art09004c.html#ATTRACTIVENESS&lt;/ref&gt; The one that is more attractive in terms of future benefit to the results should be chosen to be dealt with. It is necessary to compare the future situations after removing each of the slowing actions and their values in terms of reaching the desired result. But not only the one that will have a greater impact should be chosen but a possible [[Synergy|synergetic effect]] when removing interdependent limits should be considered when making a decision.&lt;ref name="Braun"/&gt;

== System behavior ==
Graphs in Figure 3 and 4 show the results of simulation in [http://simgua.com/ Simgua] simulation tool.
 [[File:Atractiveness Principle-graph no limits.png|thumb|400px|left|Figure 3. Situation with no limiting factor.]] &lt;br /&gt; [[File:Atractiveness Principle-graph limits.png|thumb|400px|left|Figure 4. Situation with one limiting factor set at 3 and another one set at 5.]]

You can also run the [https://web.archive.org/web/20110716071950/http://live.simgua.com/6D2BC1 Simgua Attractiveness principle model].

==Examples==

=== Project management example &lt;ref name="sherrer"/&gt; ===

There is a project with a negative impact of a risk. Some people were taken off the team, there are unexpected changes in the project content and the economic circumstances have changed, too. The indicators of its quality, schedule and costs need to be kept up. Management’s task is to allocate the resources as well as possible in terms of the project’s indicators. Due to the fact the resources are limited it is necessary to make tradeoffs among opportunities.

=== Attractiveness of geographical areas ===
[[Jay W. Forrester]] studied the attractiveness principle of geographical areas.&lt;ref name="forrester"/&gt;&lt;ref&gt;Forrester, Jay (1971). Counterintuitive behavior of social systems. Technology Review. {{cite web|url=http://sysdyn.clexchange.org/sdep/Roadmaps/RM1/D-4468-2.pdf |title=Archived copy |accessdate=2009-09-03 |deadurl=yes |archiveurl=https://web.archive.org/web/20090823210010/http://sysdyn.clexchange.org/sdep/Roadmaps/RM1/D-4468-2.pdf |archivedate=2009-08-23 }}&lt;/ref&gt; He states that all the places in the world tend to the equilibrium where they are all equally attractive, no matter the population class. Let attractivity be the overall rating of a city in terms of its desirability for potential inhabitants. If a city has high attractivity people move to this city, which increases the prices of housing which is getting scarce, cause overloading of job opportunities (leading to unemployment), the environmental stress is rising, city getting overcrowded etc. These changes demonstrate the impact of the movement as of an equalizing process which makes the mentioned city less and less attractive – to the (idealized) point when no one wants to move to it anymore.
We can illustrate this situation by Forester’s words:
:''To illustrate the attractiveness principle, imagine for a moment the ideal city. Perhaps the ideal city would be one with readily available housing at low cost, a surplus of jobs at high wages, excellent schools, no smoke or pollution, housing located near one's place of work, no crime, beautiful parks, cultural opportunities, and to this list the reader can add his own preferences. Suppose such a city existed. What would happen? It would be perceived as the ideal place to live. People from everywhere would move into the ideal city until the advantages had been so swamped by rising population that the city would offer no net attractiveness compared with other locations.'' (,&lt;ref name="forrester"/&gt; pg. 275-276)
As stated by [[Richard C. Duncan]], using Forrester’s Word dynamics model to predict the behavior of [[Third World]] countries shows that it is not possible to stop the immigration from these countries to USA as these countries can never reach the USA’s level of geographical attractiveness (and so there always will be a tendency to immigrate).&lt;ref&gt;Duncan, Richard C. (2007). The olduvai theory: terminal decline imminent. http://www.oilcrash.com/articles/olduv_7.htm&lt;/ref&gt;

== Effective strategies ==
Here is a list of possible effective strategies to deal with Attractiveness principle in praxis based on.&lt;ref name="systemsthinking"/&gt;&lt;ref name="Powell"/&gt;&lt;ref name="Braun"&gt;Braun, William (2002). The System Archetypes: 21–23. {{cite web|url=http://wwwu.uni-klu.ac.at/gossimit/pap/sd/wb_sysarch.pdf |title=Archived copy |accessdate=2011-01-22 |deadurl=yes |archiveurl=https://web.archive.org/web/20110706090016/http://wwwu.uni-klu.ac.at/gossimit/pap/sd/wb_sysarch.pdf |archivedate=2011-07-06 |df= }}&lt;/ref&gt;&lt;ref name="systemswiki"&gt;Attractiveness Principle Systems Archetype. SystemsWiki. {{cite web|url=http://www.systemswiki.org/index.php?title%3DAttractiveness_Principle_Systems_Archetype |title=Archived copy |accessdate=2011-01-22 |deadurl=yes |archiveurl=https://web.archive.org/web/20110728080935/http://www.systemswiki.org/index.php?title=Attractiveness_Principle_Systems_Archetype |archivedate=2011-07-28 |df= }}&lt;/ref&gt;
# Knowing the growth is limited is the first step.
# The insight is complicated by mutual interaction of limits, so analysis of their relation should be a priority. Such an analysis can also reveal possible synergies that can be achieved by allocating resources to carefully chosen limits.
# Consider replacing limited resources by another ones.
# Dominant strategy is to monitor the limits and using tradeoff analysis for deciding which of them it is convenient to reduce or remove to obtain desired results.
# Define the acceptable level of (un)attraction.
# Slowing actions are not usually appearing at the same time so it is important to manage them through the time.
# Try to inhibit the limits before they even start to act like limits.
# As limits start to have impact on various levels of results it is important to keep the right timing – intercept the moment when the limit starts playing its role but not waste the resources to avoid its impact unless it is necessary.

It is important to have in mind that dynamic complexity is very often counterintuitive – cause and effect are distant in time and space, but decision-makers rather tend to look for causes “near” their effects. The solution is not to concentrate on the symptoms of the problem, but on its causes.&lt;ref&gt;Sterman, John D. (2000). Business Dynamics: Systems thinking and modeling for a complex world. McGraw Hill. 22. {{ISBN|0-07-231135-5}}.&lt;/ref&gt;

== References ==
&lt;!--- See http://en.wikipedia.org/wiki/Wikipedia:Footnotes on how to create references using &lt;ref&gt;&lt;/ref&gt; tags which will then appear here automatically --&gt;
{{Reflist}}

== Further reading ==
* {{Cite book|title = The Fifth Discipline: The Art &amp; Practice of The Learning Organization|last = Senge|first = Peter M.|publisher = Doubleday/Currency|year = 2006|isbn = 978-0385517829|location = |pages = |edition = |author-link = Peter Senge}}
* {{Cite book|title = The Fifth Discipline Fieldbook|last = Senge|first = Peter M.|publisher = Crown Business|year = 1994|isbn = 978-0385472562|location = |pages = |author-link = Peter Senge}}
* {{Cite book|title = World Dynamics|last = Forrester|first = Jay W.|publisher = Wright-Allen Press|year = 1973|isbn = 978-0262560184|location = |pages = |author-link = Jay Forrester}}
* {{Cite book|title = Urban Dynamics|last = Forrester|first = Jay W.|publisher = MIT Press|year = 1969|isbn = 978-0262060264|location = |pages = |author-link = Jay W. Forrester}}
* {{Cite book|title = Collected Papers of Jay W. Forrester|last = Forrester|first = Jay W.|publisher = Pegasus Communications|year = 1975|isbn = 978-1883823375|location = |pages = |author-link = Jay W. Forrester}}
* {{Cite book|title = Business Dynamics: Systems thinking and modeling for a complex world|last = Sterman|first = John D.|publisher = Irwin/McGraw-Hill|year = 2000|isbn = 9780072311358|location = |pages = |author-link = John Sterman}}
* {{Cite book|title = Systémová dynamika.|last = Mildeová|first = Stanislava|publisher = Oeconomica|year = 2003|isbn = 9788024506265|location = |pages = |last2 = Vojtko|editor-last = |first2 = Viktor}}
* The Systems Thinker. Pegasus Communications, Inc. Waltham, MA.

== External links ==
* [http://simgua.com/ Simgua simulation tool]
* [https://web.archive.org/web/20110716071950/http://live.simgua.com/6D2BC1 Simgua Attractiveness principle model]
* [http://www.systems-thinking.org/ Systems Thinking.org]
* [http://www.systemdynamics.org/ System Dynamics Society]

{{DEFAULTSORT:Attractiveness Principle}}
[[Category:Systems theory]]
[[Category:Scientific modeling]]
[[Category:Complex systems theory]]</text>
      <sha1>pstazy03vtvryvw15qfg0o2556347di</sha1>
    </revision>
  </page>
  <page>
    <title>Bareiss algorithm</title>
    <ns>0</ns>
    <id>17919686</id>
    <revision>
      <id>860784631</id>
      <parentid>839498963</parentid>
      <timestamp>2018-09-23T01:40:51Z</timestamp>
      <contributor>
        <ip>207.38.238.155</ip>
      </contributor>
      <comment>Note that this method is commonly known as Bareiss-Montante in Spanish-speaking countries</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2801">In mathematics, the '''Bareiss algorithm''', named after [[Erwin Bareiss]], is an [[algorithm]] to calculate the [[determinant]] or the [[echelon form]] of a [[Matrix (mathematics)|matrix]] with [[integer]] entries using only integer arithmetic; any [[division (mathematics)|division]]s that are performed are guaranteed to be exact (there is no [[remainder]]). The method can also be used to compute the determinant of matrices with (approximated) [[real number|real]] entries, avoiding the introduction any round-off errors beyond those already present in the input.

During the execution of Bareiss algorithm, every integer that is computed is the determinant of a submatrix of the input matrix. This allows, using the [[Hadamard inequality]], to bound the size of these integers. Otherwise, the Bareiss algorithm may be viewed as a variant of [[Gaussian elimination]] and needs roughly the same number of arithmetic operations.

It follows that, for an ''n'' × ''n'' matrix of maximum (absolute) value 2&lt;sup&gt;''L''&lt;/sup&gt; for each entry, the Bareiss algorithm runs in [[Big O notation|O(''n''&lt;sup&gt;3&lt;/sup&gt;)]] elementary operations with an O(''n''&lt;sup&gt;&amp;nbsp;''n''/2&lt;/sup&gt;&amp;nbsp;2&lt;sup&gt;''nL''&lt;/sup&gt;) bound on the absolute value of intermediate values needed. Its [[Analysis of algorithms|computational complexity]] is thus O(''n''&lt;sup&gt;5&lt;/sup&gt;''L''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;(log(''n'')&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''L''&lt;sup&gt;2&lt;/sup&gt;)) when using elementary arithmetic or O(''n''&lt;sup&gt;4&lt;/sup&gt;''L''&amp;nbsp;(log(''n'')&amp;nbsp;+&amp;nbsp;''L'')&amp;nbsp;log(log(''n'')&amp;nbsp;+&amp;nbsp;''L''))) by using [[fast multiplication]].

The general Bareiss algorithm is distinct from the Bareiss algorithm for [[Toeplitz matrix|Toeplitz matrices]].

In some Spanish-speaking countries, this algorithm is also known as '''Bareiss-Montante''', because of [[René Mario Montante Pardo]], a professor of the [[Universidad Autónoma de Nuevo León]], [[Mexico]], that popularized the method among his students.  

==References==
*{{citation|first=Erwin H.|last=Bareiss|title= Sylvester's Identity and multistep integer-preserving Gaussian elimination|pages=565&amp;ndash;578|url=http://www.ams.org/journals/mcom/1968-22-103/S0025-5718-1968-0226829-0/S0025-5718-1968-0226829-0.pdf|journal=[[Mathematics of Computation]]|year=1968|volume=22|issue=102|doi=10.2307/2004533|jstor=2004533}}.
*{{citation|first=Erwin H.|last=Bareiss|title=MULTISTEP INTEGER-PRESERVING GAUSSIAN ELIMINATION|url=https://digital.library.unt.edu/ark:/67531/metadc1035277/m2/1/high_res_d/4474185.pdf|year=1966}}. ''(Contains a clearer picture of the operations sequence)''

{{Numerical linear algebra}}

{{DEFAULTSORT:Bareiss Algorithm}}
[[Category:Determinants]]
[[Category:Numerical linear algebra]]
[[Category:Exchange algorithms]]
[[Category:Computer algebra]]

{{algorithm-stub}}</text>
      <sha1>ffjyks4kvwfsrfu3btyflb3d1azsukt</sha1>
    </revision>
  </page>
  <page>
    <title>Bernstein–Kushnirenko theorem</title>
    <ns>0</ns>
    <id>45428442</id>
    <revision>
      <id>841020679</id>
      <parentid>841020239</parentid>
      <timestamp>2018-05-13T15:39:10Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>wikify</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4032">'''Bernstein–Kushnirenko theorem''' (also known as '''BKK theorem''' or '''Bernstein–Khovanskii–Kushnirenko theorem''' &lt;ref&gt;*{{citation|first1=David A.|last1=Cox|authorlink1=David A. Cox|first2= John|last2= Little|first3=Donal|last3= O'Shea|authorlink3=Donal O'Shea| title=Using algebraic geometry|edition=Second |series=Graduate Texts in Mathematics|volume= 185|publisher= Springer|year= 2005|isbn=0-387-20706-6}}&lt;/ref&gt;), proven by [[David Bernstein (mathematician)|David Bernstein]]&lt;ref&gt;{{citation|first=David N. |last=Bernstein|title=The number of roots of a system of equations|journal=Funct. Anal. Appl.|volume= 9 |year=1975|pages= 183–185}}&lt;/ref&gt; and {{Interlanguage link multi|Anatoli Kushnirenko|ru|3=Кушниренко, Анатолий Георгиевич}}&lt;ref&gt;{{citation|first=Anatoli G.|last=Kouchnirenko|title=Polyèdres de Newton et nombres de Milnor|journal=[[Inventiones Mathematicae]]|volume=32 |issue=1| |year=1976|pages=1–31|mr=0419433|doi=10.1007/BF01389769}}&lt;/ref&gt; in 1975, is a theorem in [[algebra]]. It states that the number of non-zero complex solutions of a system of Laurent [[polynomial equation]]s &lt;math&gt;f_1=0, \ldots, f_n=0&lt;/math&gt; is equal to the [[mixed volume]] of the [[Newton polytope]]s of the polynomials &lt;math&gt;f_1, \ldots, f_n&lt;/math&gt;, assuming that all non-zero coefficients of &lt;math&gt;f_n&lt;/math&gt; are generic.
A more precise statement is as follows:

==Theorem statement==

Let &lt;math&gt;A&lt;/math&gt; be a finite subset of &lt;math&gt;\mathbb{Z}^n &lt;/math&gt;. Consider the subspace &lt;math&gt;L_A&lt;/math&gt; of the Laurent polynomial algebra &lt;math&gt;\mathbb{C}[x_1^{\pm 1}, \ldots, x_n^{\pm 1}]&lt;/math&gt; consisting of [[Laurent polynomial]]s whose exponents are in &lt;math&gt;A&lt;/math&gt;. That is:

:&lt;math&gt;L_A = \{ f \mid f(x) = \sum_{\alpha \in A} c_\alpha x^\alpha \},&lt;/math&gt;

where &lt;math&gt;c_\alpha \in \mathbb{C}&lt;/math&gt; and for each &lt;math&gt;\alpha = (a_1, \ldots, a_n) \in \mathbb{Z}^n &lt;/math&gt; we have used the shorthand notation &lt;math&gt; x^\alpha&lt;/math&gt; to write the monomial &lt;math&gt; x_1^{a_1} \cdots x_n^{a_n} &lt;/math&gt;.

Now take &lt;math&gt;n&lt;/math&gt; finite subsets &lt;math&gt; A_1, \ldots, A_n &lt;/math&gt; with the corresponding subspaces of Laurent polynomials &lt;math&gt;L_{A_1}, \ldots, L_{A_n}&lt;/math&gt;.
Consider a generic system of equations from these subspaces, that is:

: &lt;math&gt;f_1(x) = \ldots = f_n(x) = 0, &lt;/math&gt;

where each &lt;math&gt;f_i&lt;/math&gt; is a generic element in the (finite dimensional vector space) &lt;math&gt;L_{A_i}&lt;/math&gt;.

The Bernstein–Kushnirenko theorem states that the number of solutions &lt;math&gt;x \in (\mathbb{C} \setminus 0)^n &lt;/math&gt; of such a system 
is equal to 

:&lt;math&gt; n!\, V(\Delta_1, \ldots, \Delta_n)&lt;/math&gt;, 

where &lt;math&gt;V&lt;/math&gt; denotes the Minkowski [[mixed volume]] and for each &lt;math&gt;i&lt;/math&gt;, &lt;math&gt;\Delta_i&lt;/math&gt; is the [[convex hull]] of the finite set of points &lt;math&gt;A_i&lt;/math&gt;. Clearly &lt;math&gt;\Delta_i&lt;/math&gt; is a 
[[convex lattice polytope]]. It can be interpreted as the [[Newton polytope]] of a generic element of the subspace &lt;math&gt;L_{A_i}&lt;/math&gt;.

In particular, if all the sets &lt;math&gt;A_i&lt;/math&gt; are the same &lt;math&gt;A = A_1 = \cdots = A_n&lt;/math&gt;, then the number of solutions of a generic system of Laurent polynomials from &lt;math&gt;L_A&lt;/math&gt; is equal to 

:&lt;math&gt;n! \,{\rm vol} (\Delta),&lt;/math&gt; 

where &lt;math&gt;\Delta&lt;/math&gt; is the convex hull of &lt;math&gt;A&lt;/math&gt; and vol is the usual &lt;math&gt;n&lt;/math&gt;-dimensional Euclidean volume. Note that even though the volume of a lattice polytope is not necessarily an integer, it becomes an integer after multiplying by &lt;math&gt;n!&lt;/math&gt;.

== Trivia ==
Kushnirenko's name is also spelt Kouchnirenko. David Bernstein is a brother of [[Joseph Bernstein]]. [[Askold Khovanskii]] has found about 15 different proofs of this theorem.
&lt;ref&gt;[http://www.ams.org/distribution/mmj/vol7-2-2007/khovanskii-birthday.html Moscow Mathematical Journal volume in honor of Askold Khovanskii (Mosc. Math. J., 7:2 (2007), 169–171)]&lt;/ref&gt;

== References ==
{{reflist}}

{{DEFAULTSORT:Bernstein-Kushnirenko theorem}}
[[Category:Theorems in algebra]]
[[Category:Theorems in geometry]]</text>
      <sha1>djczua29q49u6g7o7jmqc10o5q46lg7</sha1>
    </revision>
  </page>
  <page>
    <title>Bessel–Maitland function</title>
    <ns>0</ns>
    <id>32768148</id>
    <revision>
      <id>858971546</id>
      <parentid>622319232</parentid>
      <timestamp>2018-09-10T21:12:20Z</timestamp>
      <contributor>
        <username>Veryproicelandic</username>
        <id>23790359</id>
      </contributor>
      <comment>added a couple of links, removed that flag... added technical and context flags, stubbed it...</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="895">{{Multiple issues|
{{technical|date=September 2018}}
{{context|date=September 2018}}
}}

In [[mathematics]], the '''Bessel–Maitland function''', or '''Wright generalized Bessel function''', is a generalization of the [[Bessel function]], introduced by {{harvs|txt|authorlink=Edward Maitland Wright |first=Edward Maitland |last=Wright|year =1934}}. The word "Maitland" in the name of the [[Function (mathematics)|function]] seems to be the result of confusing Edward Maitland Wright's middle and last names. It is given by

: &lt;math&gt; J^{\mu,\nu}(z) = \sum_{k\ge 0} \frac{(-z)^k}{\Gamma(k\mu+\nu+1)k!}.&lt;/math&gt;

==References==

*{{Citation | last1=Wright | first1=E. M. | title=The asymptotic expansion of the generalized Bessel function. | doi=10.1112/plms/s2-38.1.257 | jfm=60.0306.02 | year=1934}}

{{DEFAULTSORT:Bessel-Maitland function}}
[[Category:Special functions]]


{{applied-math-stub}}</text>
      <sha1>97u7y8ltugfutgmbhnt7yh7uu8u2uep</sha1>
    </revision>
  </page>
  <page>
    <title>Bit-length</title>
    <ns>0</ns>
    <id>31837848</id>
    <revision>
      <id>722651975</id>
      <parentid>692301661</parentid>
      <timestamp>2016-05-29T11:29:00Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+See also</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1537">{{Refimprove|date=May 2011}}

'''Bit-length''' is the number of binary digits, called [[bit]]s, necessary to represent an [[integer]]&lt;ref&gt;{{cite web |url=http://reference.wolfram.com/mathematica/ref/BitLength.html |title=Wolfram Mathematica 8 Documentation |accessdate=10 Jan 2012 }}&lt;/ref&gt; in the [[binary numeral system|binary number system]].

At their most fundamental level, digital computers and telecommunications devices (as opposed to [[analog signal|analog]] devices) can process only data that has been expressed in [[binary code|binary]] format.  The binary format expresses data as an arbitrary length series of values with one of two choices:  Yes/No, 1/0, True/False, etc., all of which can be expressed electronically as On/Off.  For information technology applications, the amount of information being processed is an important design consideration.  The term bit-length is technical shorthand for this measure.

For example, computer [[processors]] are often designed to process data group into [[data type|word]]s of a given length of bits (8 bit, 16 bit, 32 bit, 64 bit, etc.). The bit-length of each [[word (data type)|word]] defines, for one thing, how many memory locations can be independently addressed by the processor. In [[public-key cryptography]], [[key (cryptography)|key]]s are defined by their length expressed in binary digits - their bit length.

==See also==
*[[Bit width]]&lt;!-- red link with possibilities --&gt;

==References==
{{Reflist}}

[[Category:Binary arithmetic]]
[[Category:Computer arithmetic]]</text>
      <sha1>pdm3t1nstji7gl8eyrvkf9rxhrywx93</sha1>
    </revision>
  </page>
  <page>
    <title>Cave5D</title>
    <ns>0</ns>
    <id>27566216</id>
    <revision>
      <id>805366384</id>
      <parentid>793382940</parentid>
      <timestamp>2017-10-14T22:11:30Z</timestamp>
      <contributor>
        <username>JCW-CleanerBot</username>
        <id>31737083</id>
      </contributor>
      <minor/>
      <comment>/* Bibliography */clean up |journal= parameter per [[User:JCW-CleanerBot#Logic|task]], replaced: Int. J. of → International Journal of using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1245">{{Portal|Free software}}
'''Cave5D''' is an adaptation of [[Vis5D]] to the [[Cave Automatic Virtual Environment|CAVE]] for [[Immersion (virtual reality)|immersive]] [[virtual reality]]. It is released under the [[GNU GPL]].&lt;ref&gt;See files in src/c5dSupport/ of the [ftp://ftp.mcs.anl.gov/pub/People/mickelso/CAVE5D/CAVE5Dsrc.tar.gz tarball].&lt;/ref&gt;

==Bibliography==
* W. Hibbard, J. Anderson, I. Foster, B. Paul, R. Jacob, C. Schafer, and M. Tyree, Exploring Coupled Atmosphere-Ocean Models Using Vis5D, ''International Journal of Supercomputer Applications'' 10, no. 2, 1996, pp.&amp;nbsp;211–222.
* B. Hibbard, Vis5D, Cave5D, and VisAD, in ''The Visualization Handbook'' ed. C. D. Hansen, C. R. Johnson. Elsevier, New York. 2005, pp.&amp;nbsp;673–688.

==References==
{{reflist}}

==External links==
* [https://web.archive.org/web/20100528015800/http://www.mcs.anl.gov/~mickelso/CAVE2.0.html Cave5D Home Page]
* [http://sites.google.com/site/whibbard/history History of Vis5D and VisAD]

[[Category:Meteorological data and networks]]
[[Category:Computational science]]
[[Category:Infographics]]
[[Category:Free data visualization software]]
[[Category:Virtual reality]]
[[Category:Scientific modeling]]
[[Category:Earth sciences graphics software]]</text>
      <sha1>crwmsaxvzfplb51cp769pyfq7lyrkx8</sha1>
    </revision>
  </page>
  <page>
    <title>Dana Angluin</title>
    <ns>0</ns>
    <id>28382324</id>
    <revision>
      <id>870462783</id>
      <parentid>863182775</parentid>
      <timestamp>2018-11-25T00:10:39Z</timestamp>
      <contributor>
        <username>Citation bot</username>
        <id>7903804</id>
      </contributor>
      <minor/>
      <comment>Alter: url. Add: issue. You can [[WP:UCB|use this bot]] yourself. [[WP:DBUG|Report bugs here]]. | [[WP:UCB|User-activated]].</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="9006">{{BLP sources|date=August 2010}}
{{Infobox scientist
| name              = Dana Angluin
| image             =
| death_date        =
| death_place       =
| citizenship       =
| nationality       =
| ethnicity         =
| field             = [[Computer Science]] [[Machine Learning]]
| work_institution  = [[Yale University]]
| alma_mater        = [[University of California, Berkeley]]
| doctoral_advisor  = [[Manuel Blum]]&lt;ref&gt;{{MathGenealogy|61380}}&lt;/ref&gt;
| known_for         = L* Algorithm &lt;br&gt; Query learning &lt;br&gt; Exact learning
| religion          =
| footnotes         =
| thesis_title = An Application of the Theory of Computational Complexity to the Study of Inductive Inference
| thesis_year = 1976
| doctoral_students = [[Ehud Shapiro]]
}}
'''Dana Angluin''' is a professor of [[computer science]] at [[Yale University]].  She contributed to the foundations of [[computational learning theory]].

==Education==
Angluin received her B.S. and Ph.D. at [[University of California, Berkeley]]. Her thesis, entitled "An application of the theory of computational complexity to the study of inductive inference" was one of the first works to apply [[Computational complexity theory|complexity theory]] to the field of inductive inference.

==Career==
Angluin joined the faculty at [[Yale University|Yale]] in 1979.&lt;ref&gt;{{cite web|title=Dana Angluin, B.A., Ph.D. University of California at Berkeley, 1969, 1976. Joined Yale Faculty 1979.|url=http://cpsc.yale.edu/people/dana-angluin|website=Yale University Computer Science|accessdate=12 April 2017}}&lt;/ref&gt;

Dana Angluin has authored many papers and been a pioneer in many fields specifically learning regular sets from queries and counterexamples, robot navigation with distance queries, self-stabilizing universal algorithms and query learning of regular tree languages.&lt;ref name=":1"&gt;{{Cite web|url=http://cpsc.yale.edu/people/dana-angluin|title=Dana Angluin, B.A., Ph.D. University of California at Berkeley, 1969, 1976. Joined Yale Faculty 1979.  &amp;#124; Computer Science|website=cpsc.yale.edu|access-date=2016-12-11}}&lt;/ref&gt;&lt;ref name=":0" /&gt; A lot of Angluin's work involves queries, a field in which she has made many great contributions. Angluin also has worked in the field of robotics as well dealing with navigation with distance queries.&lt;ref name=":1" /&gt;

Professor Angluin is interested in machine learning and computational learning theory. Algorithmic modeling and analysis of learning tasks gives insight into the phenomena of learning, and suggests avenues for the creation of tools to help people learn, and for the design of "smarter" software and artificial agents that flexibly adapt their behavior. Professor Angluin's thesis&lt;ref name=":0"&gt;D Angluin (1976). "An Application of the Theory of Computational Complexity to the Study of Inductive Inference." Available from ProQuest Dissertations &amp; Theses Global. (302813707)&lt;/ref&gt; was among the first work to apply [[computational complexity theory]] to the field of [[inductive inference]]. Her work on learning from positive data reversed a previous dismissal of that topic, and established a flourishing line of research. Her work on learning with queries established the models and the foundational results for learning with membership queries. Recently, her work has focused on the areas of coping with errors in the answers to queries, map-learning by mobile robots, and fundamental questions in modeling the interaction of a teacher and a learner.

Professor Angluin helped found the Computational Learning Theory (COLT) conference, and has served on program committees for COLT&lt;ref&gt;[https://books.google.com/books?id=CX6jBQAAQBAJ&amp;lpg=PA301&amp;ots=7WiD-jsLl-&amp;dq=COLT%20'88&amp;pg=PP7#v=onepage&amp;q=Angluin&amp;f=false], COLT '89 Proceedings&lt;/ref&gt;&lt;ref&gt;[https://books.google.com/books?id=A1dqomCv1-4C&amp;lpg=PP7&amp;ots=Dodw3QGsu7&amp;dq=%22COLT%20steering%20committee%22%20angluin&amp;pg=PP1#v=onepage&amp;q=%22COLT%20steering%20committee%22%20angluin&amp;f=false], COLT '02 Proceedings&lt;/ref&gt;&lt;ref&gt;[http://colt2008.cs.helsinki.fi/papers/COLT2008.pdf], COLT '08 Proceedings&lt;/ref&gt; and on the COLT Steering committee. She served as an area editor for [[Information and Computation]] from 1989–1992.&lt;ref&gt;{{cite journal |journal=Information and Computation |volume=82 |issue=1 |year=1989 |page=i |title=Editorial Board |doi=10.1016/0890-5401(89)90061-8}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |journal=Information and Computation |volume=99 |issue=1 |year=1992 |page=i |title=Editorial Board |doi=10.1016/0890-5401(92)90023-9}}&lt;/ref&gt; She organized Yale's Computer Science Department's Perlis Symposium in April 2001: "From Statistics to Chat: Trends in Machine Learning".&lt;ref&gt;{{cite web |url=http://www.yale.edu/opa/arc-ybc/v29.n27/story11.html |archive-url=https://web.archive.org/web/20090418113435/http://www.yale.edu/opa/arc-ybc/v29.n27/story11.html |archive-date=April 18, 2009 |deadurl=yes |title=Symposium will explore 'trends in machine learning' |work=Yale Bulletin and Calendar |date=April 20, 2001 |volume=29 |issue=27 }}&lt;/ref&gt; She is a member of the [[Association for Computing Machinery]] and the [[Association for Women in Mathematics]].

Angluin has also published works on [[Ada Lovelace]] and her involvement with the [[Analytical Engine]].&lt;ref&gt;{{Cite book|url=https://books.google.com/?id=PNIJDAAAQBAJ&amp;pg=PA60&amp;lpg=PA60&amp;dq=dana+angluin+ada+lovelace#v=onepage&amp;q=dana%20angluin%20ada%20lovelace&amp;f=false|title=Complexities: Women in Mathematics|last=Case|first=Bettye Anne|author1-link=Bettye Anne Case|last2=Leggett|first2=Anne M.|author2-link=Anne M. Leggett|date=2016-05-31|publisher=Princeton University Press|isbn=9781400880164|language=en}}&lt;/ref&gt; Angluin is highly regarded as one of the best researchers in her field of Computer Science. Angluin continues to make more progress in her chosen field of queries at Yale.&lt;ref name=":1" /&gt;

==Work==

Representative Publications:
* {{cite book| author=Dana Angluin| chapter=Queries revisited (Invited paper)| title=Algorithmic Learning Theory – 12th International Conference|date=Nov 2001| volume=2225| pages=12–31| publisher=Springer|editor1=Naoki Abe |editor2=Roni Khardon |editor3=Thomas Zeugmann | series=LNCS}}
* {{cite journal |author=Dana Angluin |title=Robot navigation with distance queries |author2=Jeffery Westbrook |author3=Wenhong Zhu |journal=[[SIAM Journal on Computing]] |volume=30 |issue=1 |pages=110–144 |year=2000 |doi=10.1137/S0097539797330057|citeseerx=10.1.1.44.9279 }}
* {{cite journal|author=Dana Angluin |title=Learning Regular Sets from Queries and Counter-Examples |journal=[[Information and Control]] |year=1987 |volume=75 |issue=2 |pages=87–106 |url=http://www.cse.iitk.ac.in/users/chitti/thesis/references/learningRegSetsFromQueriesAndCounterExamples.pdf |doi=10.1016/0890-5401(87)90052-6 |deadurl=yes |archiveurl=https://web.archive.org/web/20131202232143/http://www.cse.iitk.ac.in/users/chitti/thesis/references/learningRegSetsFromQueriesAndCounterExamples.pdf |archivedate=2013-12-02 |df= }}
* {{cite techreport| author=Dana Angluin| title=Learning k-Bounded Context-Free Grammars|date=Aug 1987| number=557| pages=13| institution=Yale University| url=http://www.cvc.yale.edu/publications/techreports/tr557.pdf}}
* {{cite journal| author=Dana Angluin| title=Finding Patterns Common to a Set of Strings| journal=[[Journal of Computer and System Sciences]]| year=1980| volume=21| pages=46–62| url=http://www.sciencedirect.com/science/article/pii/0022000080900410/pdf?md5=c3534f6c086df22fbf814b12984fab5e&amp;pid=1-s2.0-0022000080900410-main.pdf| doi=10.1016/0022-0000(80)90041-0}}
* {{cite journal| author=Dana Angluin| title=Inductive Inference of Formal Languages from Positive Data| journal=[[Information and Control]]| year=1980| volume=45| issue=2| pages=117–135|url=http://www-personal.umich.edu/~yinw/papers/Angluin80.pdf| doi=10.1016/s0019-9958(80)90285-5}} [http://citeseer.ist.psu.edu/context/14508/0]
* {{cite thesis| type=Ph.D.| author=Dana Angluin| title=An Application of the Theory of Computational Complexity to the Study of Inductive Inference| year=1976| publisher=University of California at Berkeley}}

==See also==

* [[Automata Theory]]

== References ==
{{Reflist}}

==External links==
&lt;!---outdated 4.Apr.2014---* [http://www.cs.yale.edu/people/angluin.html Angluin's home page at Yale University]---&gt;
* [http://cpsc.yale.edu/people/dana-angluin Angluin's home page at Yale University]
* [https://scholar.google.com/citations?user=bxi6JXYAAAAJ Angluin's Google Scholar listing]

{{Authority control}}

{{DEFAULTSORT:Angluin, Dana}}
[[Category:American computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Living people]]
[[Category:Women computer scientists]]
[[Category:Yale University faculty]]
[[Category:University of California, Berkeley alumni]]
[[Category:Place of birth missing (living people)]]
[[Category:Year of birth missing (living people)]]
[[Category:American women scientists]]
[[Category:20th-century women scientists]]
[[Category:21st-century women scientists]]</text>
      <sha1>ksex374mqsxydi2iyxmd5smcmvirh9v</sha1>
    </revision>
  </page>
  <page>
    <title>Divergence of the sum of the reciprocals of the primes</title>
    <ns>0</ns>
    <id>249208</id>
    <revision>
      <id>862605815</id>
      <parentid>850410007</parentid>
      <timestamp>2018-10-05T13:31:25Z</timestamp>
      <contributor>
        <username>Tony1</username>
        <id>332841</id>
      </contributor>
      <comment>[[User:Ohconfucius/script|Script]]-assisted fixes: per [[MOS:NUM]], [[MOS:CAPS]], [[MOS:LINK]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13047">{{Use dmy dates|date=October 2018}}
[[File:Sum of reciprocals of primes.svg|thumb|300px|The sum of the reciprocal of the primes increasing without bound. The x axis is in log scale, showing that the divergence is very slow. The red function is a lower bound that also diverges.]]
The '''sum of the [[multiplicative inverse|reciprocal]]s of all [[prime number]]s [[Divergent series|diverges]]'''; that is:

:&lt;math&gt;\sum_{p\text{ prime}}\frac1p = \frac12 + \frac13 + \frac15 + \frac17 + \frac1{11} + \frac1{13} + \frac1{17} + \cdots = \infty&lt;/math&gt;

This was proved by [[Leonhard Euler]] in 1737,&lt;ref&gt;{{cite journal|first=Leonhard|last=Euler|authorlink=Leonhard Euler|title=Variae observationes circa series infinitas|trans-title=Various observations concerning infinite series|journal=Commentarii Academiae Scientiarum Petropolitanae|volume=9|year=1737|pages=160–188}}&lt;/ref&gt; and strengthens [[Euclid]]'s 3rd-century-BC result that [[Euclid's theorem|there are infinitely many prime number]]s.

There are a variety of proofs of Euler's result, including a [[lower bound]] for the partial sums stating that

:&lt;math&gt;\sum_{\scriptstyle p\text{ prime}\atop \scriptstyle p\le n}\frac1p \ge \ln \ln (n+1) - \ln\frac{\pi^2}6&lt;/math&gt;

for all natural numbers {{mvar|n}}. The double [[natural logarithm]] (ln&amp;nbsp;ln) indicates that the divergence might be very slow, which is indeed the case. See [[Meissel–Mertens constant]].

==The harmonic series==
First, we describe how Euler originally discovered the result. He was considering the [[harmonic series (mathematics)|harmonic series]]

: &lt;math&gt; \sum_{n=1}^\infty \frac{1}{n} = 1 + \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \cdots = \infty &lt;/math&gt;

He had already used the following "[[Riemann zeta function#Euler product formula|product formula]]" to show the existence of infinitely many primes.

: &lt;math&gt; \sum_{n=1}^\infty \frac{1}{n} = \prod_{p} \left( 1+\frac{1}{p}+\frac{1}{p^2}+\cdots \right) = \prod_{p} \frac{1}{1-p^{-1}} &lt;/math&gt;

Here the product is taken over the set of all primes.

Such infinite products are today called [[Euler product]]s. The product above is a reflection of the [[fundamental theorem of arithmetic]]. Euler noted that if there were only a finite number of primes, then the product on the right would clearly converge, contradicting the divergence of the harmonic series.

==Proofs==

===Euler's proof===

Euler considered the above product formula and proceeded to make a sequence of audacious leaps of logic. First, he took the natural logarithm of each side, then he used the Taylor series expansion for {{math|ln ''x''}} as well as the sum of a converging series:

: &lt;math&gt;\begin{align}
 \ln \left( \sum_{n=1}^\infty \frac{1}{n}\right) &amp; {} = \ln\left( \prod_p \frac{1}{1-p^{-1}}\right)
  = -\sum_p \ln \left( 1-\frac{1}{p}\right) \\
 &amp; {} = \sum_p \left( \frac{1}{p} + \frac{1}{2p^2} + \frac{1}{3p^3} + \cdots \right) \\
 &amp; {} =  \sum_{p}\frac{1}{p}   + \frac{1}{2}\sum_p \frac{1}{p^2} + \frac{1}{3}\sum_p \frac{1}{p^3}  + \frac{1}{4}\sum_p \frac{1}{p^4}+ \cdots  \\
 &amp; {} =   A  + \frac{1}{2} B+ \frac{1}{3} C+ \frac{1}{4} D  + \cdots  \\
 &amp; {} = A  + K
\end{align}&lt;/math&gt;

for a fixed constant {{math|''K'' &lt; 1}}. Then he invoked the relation

:&lt;math&gt;\sum_{n=1}^\infty\frac1n=\ln\infty,&lt;/math&gt;

which he explained, for instance in a later 1748 work,&lt;ref&gt;{{cite book|authorlink=Leonhard Euler|first=Leonhard|last=Euler|title=[[Introductio in analysin infinitorum]]. Tomus Primus|trans-title=Introduction to Infinite Analysis. Volume I|publisher=Bousquet|location=Lausanne|date=1748|at=p. 228, ex. 1}}&lt;/ref&gt; by setting {{math|''x'' {{=}} 1}} in the Taylor series expansion

:&lt;math&gt;\ln\left(\frac1{1-x}\right)=\sum_{n=1}^\infty\frac{x^{n}}n.&lt;/math&gt;

This allowed him to conclude that

:&lt;math&gt;A=\frac{1}{2} + \frac{1}{3} + \frac{1}{5} + \frac{1}{7} + \frac{1}{11} + \cdots = \ln \ln \infty.&lt;/math&gt;

It is almost certain that Euler meant that the sum of the reciprocals of the primes less than {{mvar|n}} is asymptotic to {{math|ln ln ''n''}} as {{mvar|n}} approaches infinity. It turns out this is indeed the case, and a more precise version of this fact was rigorously proved by [[Franz Mertens]] in 1874.&lt;ref&gt;{{cite journal |authorlink = Franz Mertens | last1 = Mertens | first1 = F. | year = 1874 | title = Ein Beitrag zur analytischer Zahlentheorie | journal = J. Reine Angew. Math. | volume = 78 | pages = 46–62 }}&lt;/ref&gt; Thus Euler obtained a correct result by questionable means.

===Erdős's proof by upper and lower estimates===

The following [[proof by contradiction]] is due to [[Paul Erdős]].

Let {{mvar|p&lt;sub&gt;i&lt;/sub&gt;}} denote the {{mvar|i}}th prime number.  Assume that the [[series (mathematics)|sum]] of the reciprocals of the primes [[convergent series|converges]]; i.e.,

:&lt;math&gt;\sum_{i=1}^\infty \frac 1 {p_i} &lt; \infty&lt;/math&gt;

Then there exists a smallest [[Positive number|positive]] [[integer]] {{mvar|k}} such that

:&lt;math&gt;\sum_{i=k+1}^\infty \frac 1 {p_i} &lt; \frac12 \qquad(1)&lt;/math&gt;

For a positive integer {{mvar|x}}, let {{mvar|M&lt;sub&gt;x&lt;/sub&gt;}} denote the set of those {{mvar|n}} in {{math|{1, 2, …, ''x''}|}} which are not [[divisible]] by any prime greater than {{mvar|p&lt;sub&gt;k&lt;/sub&gt;}} (or equivalently all {{math|''n'' ≤ ''x''}} which are a product of powers of primes {{math|''p&lt;sub&gt;i&lt;/sub&gt;'' ≤ ''p''&lt;sub&gt;''k''&lt;/sub&gt;}}). We will now derive an upper and a lower estimate for {{math|{{abs|''M&lt;sub&gt;x&lt;/sub&gt;''}}}}, the [[cardinality|number of elements]] in {{math|M&lt;sub&gt;x&lt;/sub&gt;}}. For large&amp;nbsp;{{mvar|x}}, these bounds will turn out to be contradictory.

'''Upper estimate:'''
:Every {{mvar|n}} in {{mvar|M&lt;sub&gt;x&lt;/sub&gt;}} can be written as {{math|''n'' {{=}} ''m''&lt;sup&gt;2&lt;/sup&gt;''r''}} with positive integers {{mvar|m}} and {{mvar|r}}, where {{mvar|r}} is [[square-free integer|square-free]]. Since only the {{mvar|k}} primes {{math|''p''&lt;sub&gt;1&lt;/sub&gt;, …, ''p&lt;sub&gt;k&lt;/sub&gt;''}} can show up (with exponent&amp;nbsp;1) in the [[Fundamental theorem of arithmetic|prime factorization]] of&amp;nbsp;{{mvar|r}}, there are at most {{math|2&lt;sup&gt;''k''&lt;/sup&gt;}} different possibilities for&amp;nbsp;{{mvar|r}}. Furthermore, there are at most {{math|{{sqrt|''x''}}}} possible values for&amp;nbsp;{{mvar|m}}. This gives us the upper estimate

::&lt;math&gt;|M_x| \le 2^k\sqrt{x} \qquad(2)&lt;/math&gt;

'''Lower estimate:'''
:The remaining {{math|''x''&amp;nbsp;−&amp;nbsp;{{abs|''M&lt;sub&gt;x&lt;/sub&gt;''}}}} numbers in the [[set difference]] {{math|{1, 2, …, ''x''} \ ''M&lt;sub&gt;x&lt;/sub&gt;''}} are all divisible by a prime greater than {{mvar|p&lt;sub&gt;k&lt;/sub&gt;}}. Let {{math|''N''&lt;sub&gt;''i'',''x''&lt;/sub&gt;}} denote the set of those {{mvar|n}} in {{math|{1, 2, …, ''x''}|}} which are divisible by the {{mvar|i}}th prime {{mvar|p&lt;sub&gt;i&lt;/sub&gt;}}. Then

::&lt;math&gt;\{1,2,\ldots,x\}\smallsetminus M_x = \bigcup_{i=k+1}^\infty N_{i,x}&lt;/math&gt;

:Since the number of integers in {{math|''N''&lt;sub&gt;''i'',''x''&lt;/sub&gt;}} is at most {{math|{{sfrac|''x''|''p&lt;sub&gt;i&lt;/sub&gt;''}}}} (actually zero for {{math|''p&lt;sub&gt;i&lt;/sub&gt;'' &gt; ''x''}}), we get

::&lt;math&gt;x-|M_x| \le \sum_{i=k+1}^\infty |N_{i,x}|&lt; \sum_{i=k+1}^\infty \frac x {p_i}&lt;/math&gt;

:Using (1), this implies

::&lt;math&gt;\frac x 2 &lt; |M_x| \qquad(3)&lt;/math&gt;

This produces a contradiction: when {{math|''x'' ≥ 2&lt;sup&gt;2''k'' + 2&lt;/sup&gt;}}, the estimates (2) and (3) cannot both hold, because {{math|{{sfrac|''x''|2}} ≥ 2&lt;sup&gt;''k''&lt;/sup&gt;{{sqrt|''x''}}}}.

===Proof that the series exhibits log-log growth===

Here is another proof that actually gives a lower estimate for the partial sums; in particular, it shows that these sums grow at least as fast as {{math|ln ln ''n''}}. The proof is an adaptation of the product expansion idea of [[Euler]].  In the following, a sum or product taken over {{mvar|p}} always represents a sum or product taken over a specified set of primes.

The proof rests upon the following four inequalities:

* Every positive integer {{mvar|i}} can be uniquely expressed as the product of a square-free integer and a square.  This gives the inequality
::&lt;math&gt; \sum_{i=1}^n{\frac{1}{i}} \le \prod_{p \le n}{\left(1 + \frac{1}{p}\right)}\sum_{k=1}^n{\frac{1}{k^2}}&lt;/math&gt;
:where for every {{mvar|i}} between 1 and {{mvar|n}} the (expanded) product corresponds to the [[Radical of an integer|square-free part]] of {{mvar|i}} and the sum corresponds to the square part of {{mvar|i}} (see [[fundamental theorem of arithmetic]]).

* The upper estimate for the [[natural logarithm]]
::&lt;math&gt;\begin{align}
 \ln(n+1) &amp;= \int_1^{n+1}\frac{dx}x \\
 &amp;= \sum_{i=1}^n\underbrace{\int_i^{i+1}\frac{dx}x}_{{} \,&lt;\, \frac1i} \\
 &amp;&lt; \sum_{i=1}^n{\frac{1}{i}}
\end{align}&lt;/math&gt;

* The lower estimate {{math|1 + ''x'' &lt; exp(''x'')}} for the [[exponential function]], which holds for all {{math|''x'' &gt; 0}}.
* Let  {{math|''n'' ≥ 2}}.  The upper bound (using a [[telescoping sum]]) for the partial sums (convergence is all we really need)
::&lt;math&gt;\begin{align}
 \sum_{k=1}^n{\frac{1}{k^2}} 
 &amp;&lt; 1 + \sum_{k=2}^n\underbrace{\left(\frac1{k - \frac{1}{2}} - \frac1{k + \frac{1}{2}}\right)}_{=\, \frac{1}{k^2 - \frac14} \,&gt;\, \frac{1}{k^2}} \\
 &amp;= 1 + \frac23 - \frac1{n + \frac{1}{2}} &lt; \frac53
\end{align}&lt;/math&gt;

Combining all these inequalities, we see that
:&lt;math&gt;\begin{align}
    \ln(n+1) &amp; &lt; \sum_{i=1}^n\frac{1}{i} \\
     &amp; \le \prod_{p \le n}{\left(1 + \frac{1}{p}\right)}\sum_{k=1}^n{\frac{1}{k^2}} \\
     &amp; &lt; \frac53\prod_{p \le n}{\exp\left(\frac{1}{p}\right)} \\
     &amp; = \frac53\exp\left(\sum_{p \le n}{\frac{1}{p}}\right)
\end{align}&lt;/math&gt;

Dividing through by {{sfrac|5|3}} and taking the natural logarithm of both sides gives
:&lt;math&gt;\ln\ln(n + 1) - \ln\frac53 &lt; \sum_{p \le n}{\frac{1}{p}}&lt;/math&gt;

as desired.&amp;nbsp;[[Q.E.D.|∎]]

Using

:&lt;math&gt;\sum_{k=1}^\infty{\frac{1}{k^2}} = \frac{\pi^2}6&lt;/math&gt;

(see the [[Basel problem]]), the above constant {{math|ln {{sfrac|5|3}} {{=}} 0.51082…}} can be improved to {{math|ln {{sfrac|π&lt;sup&gt;2&lt;/sup&gt;|6}} {{=}} 0.4977…}}; in fact it turns out that
:&lt;math&gt; \lim_{n \to \infty } \left( \sum_{p \leq n} \frac{1}{p} - \ln \ln n \right) = M&lt;/math&gt;

where {{math|''M'' {{=}} 0.261497…}} is the [[Meissel–Mertens constant]] (somewhat analogous to the much more famous [[Euler–Mascheroni constant]]).

===Proof from Dusart's inequality===

From [[Dusart's inequality]], we get

:&lt;math&gt; p_n &lt;  n \ln n + n \ln \ln n \quad\mbox{for } n \ge 6&lt;/math&gt;

Then
:&lt;math&gt;\begin{align}
 \sum_{n=1}^\infty \frac1{ p_n}
  &amp;\ge \sum_{n=6}^\infty \frac1{ p_n} \\
  &amp;\ge \sum_{n=6}^\infty \frac1{ n \ln n + n \ln \ln n} \\
  &amp;\ge \sum_{n=6}^\infty \frac1{2n \ln n} = \infty
\end{align}&lt;/math&gt;

by the [[integral test for convergence]]. This shows that the series on the left diverges.

==Partial sums==

While the [[partial sum]]s of the reciprocals of the primes eventually exceed any integer value, they never equal an integer.

One proof&lt;ref&gt;{{cite journal | last1 = Lord | first1 = Nick | year = 2015 | title = Quick proofs that certain sums of fractions are not integers | journal = The Mathematical Gazette | volume = 99 | pages = 128–130 | doi = 10.1017/mag.2014.16 }}&lt;/ref&gt; is by induction: The first partial sum is {{sfrac|1|2}}, which has the form {{sfrac|odd|even}}. If the {{mvar|n}}th partial sum (for {{math|''n'' ≥ 1}}) has the form {{sfrac|odd|even}}, then the {{math|(''n'' + 1)}}st sum is

:&lt;math&gt;\frac\text{odd}\text{even} + \frac{1}{p_{n+1}} = \frac{\text{odd} \cdot p_{n+1} + \text{even}}{\text{even} \cdot p_{n+1}} = \frac{\text{odd} + \text{even}}\text{even} = \frac\text{odd}\text{even}&lt;/math&gt;

as the {{math|(''n'' + 1)}}st prime {{math|''p''&lt;sub&gt;''n'' + 1&lt;/sub&gt;}} is odd; since this sum also has an {{sfrac|odd|even}} form, this partial sum cannot be an integer (because 2 divides the denominator but not the numerator), and the induction continues.

Another proof rewrites the expression for the sum of the first {{mvar|n}} reciprocals of primes (or indeed the sum of the reciprocals of ''any'' set of primes) in terms of the [[least common denominator]], which is the product of all these primes. Then each of these primes divides all but one of the numerator terms and hence does not divide the numerator itself; but each prime ''does'' divide the denominator. Thus the expression is irreducible and is non-integer.

==See also==
*[[Euclid's theorem]] that there are infinitely many primes
*[[Small set (combinatorics)]]
*[[Brun's theorem]], on the convergent sum of reciprocals of the twin primes
*[[List of sums of reciprocals]]

==References==
{{reflist}}

;Sources
* {{cite book | first=William | last=Dunham | authorlink=William Dunham (mathematician) | title=Euler The Master of Us All | publisher=[[Mathematical Association of America|MAA]] | year=1999 | isbn=0-88385-328-0 | pages=61–79 }}

==External links==
* {{cite web|url=http://www.utm.edu/research/primes/infinity.shtml|first=Chris K. |last=Caldwell |title=There are infinitely many primes, but, how big of an infinity?}}

{{Series and sequence}}

{{DEFAULTSORT:Sum Of The Reciprocals Of The Primes Diverges}}
[[Category:Mathematical series]]
[[Category:Articles containing proofs]]
[[Category:Theorems about prime numbers]]</text>
      <sha1>2thpzq5villme1ptzpkrrzyhzvzrfdj</sha1>
    </revision>
  </page>
  <page>
    <title>Enumerated type</title>
    <ns>0</ns>
    <id>4723370</id>
    <revision>
      <id>870007823</id>
      <parentid>868940679</parentid>
      <timestamp>2018-11-21T20:24:37Z</timestamp>
      <contributor>
        <username>Lucicat</username>
        <id>35197454</id>
      </contributor>
      <comment>/* C and syntactically similar languages */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30182">In [[computer programming]], an '''enumerated type''' (also called '''enumeration''', '''enum''', or '''factor''' in the [[R (programming language)|R programming language]], and a [[categorical variable]] in statistics) is a [[data type]] consisting of a set of named [[value (computer science)|values]] called ''elements'', ''members'', ''enumeral'',  or ''enumerators'' of the type. The enumerator names are usually [[identifier]]s that behave as [[constant (programming)|constants]] in the language. An enumerated type can be seen as a degenerate [[tagged union]] of [[unit type]]. A [[variable (computer science)|variable]] that has been [[declaration (computer science)|declared]] as having an enumerated type can be assigned any of the enumerators as a value. In other words, an enumerated type has values that are different from each other, and that can be compared and assigned, but are not specified by the programmer  as having any particular concrete representation in the computer's memory; compilers and interpreters can represent them arbitrarily.

For example, the four [[Suit (cards)|suits]] in a deck of playing cards may be four enumerators named ''Club'', ''Diamond'', ''Heart'', and ''Spade'', belonging to an enumerated type named ''suit''. If a variable ''V'' is declared having ''suit'' as its data type, one can assign any of those four values to it.

Although the enumerators are usually distinct, some languages may allow the same enumerator to be listed twice in the type's declaration. The names of enumerators need not be semantically complete or compatible in any sense. For example, an enumerated type called ''color'' may be defined to consist of the enumerators ''Red'', ''Green'', ''Zebra'', ''Missing'', and ''Bacon''. In some languages, the declaration of an enumerated type also intentionally defines an [[total order|ordering]] of its members; in others, the enumerators are unordered; in others still, an implicit ordering arises from the compiler concretely representing enumerators as integers.

Some enumerator types may be [[built-in type|built into]] the language. The [[Boolean type]], for example is often a pre-defined enumeration of the values ''False'' and ''True''. Many languages allow users to define new enumerated types.

Values and variables of an enumerated type are usually implemented as fixed-length [[bit string]]s, often in a format and size compatible with some [[integer (computer science)|integer]] type. Some languages, especially [[system programming language]]s, allow the user to specify the bit combination to be used for each enumerator. In [[type theory]], enumerated types are often regarded as [[tagged union]]s of [[unit type]]s. Since such types are of the form &lt;math&gt;1 + 1 + \cdots + 1&lt;/math&gt;, they may also be written as natural numbers.

==Rationale==
Some early programming languages did not originally have enumerated types. If a programmer wanted a variable, for example ''myColor'', to have a value of red, the variable red would be declared and assigned some arbitrary value, usually an integer constant. The variable red would then be assigned to ''myColor''. Other techniques assigned arbitrary values to strings containing the names of the enumerators.

These arbitrary values were sometimes referred to as [[magic number (programming)|magic numbers]] since there often was no explanation as to how the numbers were obtained or whether their actual values were significant. These magic numbers could make the source code harder for others to understand and maintain.

Enumerated types, on the other hand, make the code more self-documenting. Depending on the language, the compiler could automatically assign default values to the enumerators thereby hiding unnecessary detail from the programmer. These values may not even be visible to the programmer (see [[information hiding]]). Enumerated types can also prevent a programmer from writing illogical code such as performing mathematical operations on the values of the enumerators. If the value of a variable that was assigned an enumerator were to be printed, some programming languages could also print the name of the enumerator rather than its underlying numerical value. A further advantage is that enumerated types can allow compilers to enforce semantic correctness. For instance:&lt;br&gt;
&lt;code&gt;
myColor = TRIANGLE
&lt;/code&gt;&lt;br&gt;
can be forbidden, whilst &lt;br&gt;
&lt;code&gt;
myColor = RED
&lt;/code&gt;&lt;br&gt;
is accepted, even if ''TRIANGLE'' and ''RED'' are both internally represented as ''1''.

Conceptually, an enumerated type is similar to a list of [[nominal number|nominals]] (numeric codes), since each possible value of the type is assigned a distinctive natural number. A given enumerated type is thus a concrete implementation of this notion. When order is meaningful and/or used for comparison, then an enumerated type becomes an [[ordinal number|ordinal]] type.

== Conventions ==

[[Programming languages]] tend to have their own, oftentimes multiple, [[programming styles]] and [[Naming_convention_(programming)|naming conventions]]. Enumerations frequently follow either a [[PascalCase]] or [[uppercase]] convention, while [[lowercase]] and others are seen less frequently.

== Pascal and syntactically similar languages ==

=== Pascal ===
In [[Pascal (programming language)|Pascal]], an enumerated type can be implicitly declared by listing the values in a parenthesised list:
  &lt;source lang=Pascal&gt;
  var
    suit: (clubs, diamonds, hearts, spades);
  &lt;/source&gt;
The declaration will often appear in a type synonym declaration, such that it can be used for multiple variables:

&lt;source lang=Pascal&gt;
  type
    cardsuit = (clubs, diamonds, hearts, spades);
    card = record
             suit: cardsuit;
             value: 1 .. 13;
           end;
  var
    hand: array [ 1 .. 13 ] of card;
    trump: cardsuit;
&lt;/source&gt;
  
The order in which the enumeration values are given matters. An enumerated type is an ordinal type, and the &lt;code&gt;pred&lt;/code&gt; and &lt;code&gt;succ&lt;/code&gt; functions will give the prior or next value of the enumeration, and &lt;code&gt;ord&lt;/code&gt; can convert enumeration values to their integer representation. Standard Pascal does not offer a conversion from arithmetic types to enumerations, however. Extended Pascal offers this functionality via an extended &lt;code&gt;succ&lt;/code&gt; function. Some other Pascal dialects allow it via type-casts. Some modern descendants of Pascal, such as [[Modula-3]], provide a special conversion syntax using a method called &lt;code&gt;VAL&lt;/code&gt;; Modula-3 also treats &lt;code&gt;BOOLEAN&lt;/code&gt; and &lt;code&gt;CHAR&lt;/code&gt; as special pre-defined enumerated types and uses &lt;code&gt;ORD&lt;/code&gt; and &lt;code&gt;VAL&lt;/code&gt; for standard [[ASCII]] decoding and encoding.

Pascal style languages also allow enumeration to be used as array index:

  &lt;source lang=Pascal&gt;
  var
    suitcount: array [cardsuit] of integer;
  &lt;/source&gt;

=== Ada ===

In [[Ada (programming language)|Ada]], the use of "=" was replaced with "is" leaving the definition quite similar:

 &lt;source lang=Ada&gt;type Cardsuit is (clubs, diamonds, hearts, spades);&lt;/source&gt;

In addition to &lt;code&gt;Pred&lt;/code&gt;, &lt;code&gt;Succ&lt;/code&gt;, &lt;code&gt;Val&lt;/code&gt; and &lt;code&gt;Pos&lt;/code&gt; Ada also supports simple string conversions via &lt;code&gt;Image&lt;/code&gt; and &lt;code&gt;Value&lt;/code&gt;.

Similar to C-style languages Ada allows the internal representation of the enumeration to be specified:

 &lt;source lang=Ada&gt;
 for Cardsuit use
   (clubs =&gt; 1, diamonds =&gt; 2, hearts =&gt; 4, spades =&gt; 8);
 &lt;/source&gt;

Unlike C-style languages Ada also allows the number of bits of the enumeration to be specified:

  &lt;source lang=Ada&gt;for Cardsuit'Size use 4;  -- 4 bits&lt;/source&gt;

Additionally, one can use enumerations as indexes for arrays, like in Pascal, but there are attributes defined for enumerations
&lt;source lang=Ada&gt;
   Shuffle : constant array(Cardsuit) of Cardsuit :=
     (Clubs =&gt; Cardsuit'Succ(Clubs), -- see attributes of enumerations 'First, 'Last, 'Succ, 'Pred
      Diamonds =&gt; Hearts, --an explicit value
      Hearts =&gt; Cardsuit'Last, --first enumeration value of type Cardsuit e.g., clubs
      Spades =&gt; Cardsuit'First --last enumeration value of type Cardsuit e.g., spades
      );
&lt;/source&gt;

Like [[Modula-3]] Ada treats &lt;code&gt;Boolean&lt;/code&gt; and &lt;code&gt;Character&lt;/code&gt; as special pre-defined (in package "&lt;code&gt;Standard&lt;/code&gt;") enumerated types. Unlike Modula-3 one can also define own character types:

 &lt;source lang=Ada&gt;type Cards is ('7', '8', '9', 'J', 'Q', 'K', 'A');&lt;/source&gt;

== C and syntactically similar languages ==

=== C ===
The original [[K&amp;R C|K&amp;R]] dialect of the programming language [[C (programming language)|C]] had no enumerated types. They were added in the [[ANSI]] standard for C, which became [[ANSI C]] (sometimes termed C89). In C, enumerations are created by explicit definitions (the &lt;code&gt;enum&lt;/code&gt; keyword by itself does not cause allocation of storage) which use the &lt;code&gt;enum&lt;/code&gt; keyword and are reminiscent of [[struct (C programming language)|struct]] and [[Union type|union]] definitions:

&lt;source lang=C&gt;
enum cardsuit {
   Clubs,
   Diamonds,
   Hearts,
   Spades
};

struct card {
   enum cardsuit suit;
   short int value;
} hand[13];

enum cardsuit trump;
&lt;/source&gt;

C exposes the integer representation of enumeration values directly to the programmer. Integers and enum values can be mixed freely, and all arithmetic operations on enum values are permitted. It is even possible for an enum variable to hold an integer that does not represent any of the enumeration values. In fact, according to the language definition, the above code will define &lt;code&gt;Clubs&lt;/code&gt;, &lt;code&gt;Diamonds&lt;/code&gt;, &lt;code&gt;Hearts&lt;/code&gt;, and &lt;code&gt;Spades&lt;/code&gt; as constants of type &lt;code&gt;int&lt;/code&gt;, which will only be converted (silently) to &lt;code&gt;enum cardsuit&lt;/code&gt; if they are stored in a variable of that type.

C also allows the programmer to choose the values of the enumeration constants explicitly, even without type. For example,

&lt;source lang=C&gt;
enum cardsuit {
    Clubs    = 1,
    Diamonds = 2,
    Hearts   = 4,
    Spades   = 8
};
&lt;/source&gt;

could be used to define a type that allows mathematical sets of suits to be represented as an &lt;code&gt;enum cardsuit&lt;/code&gt; by bitwise logic operations.

=== Swift ===

In C, enumerations assign related names to a set of integer values. In [[Swift (programming language)|Swift]], enumerations are much more flexible and need not provide a value for each case of the enumeration. If a value (termed a ''raw'' value) is provided for each enumeration case, the value can be a string, a character, or a value of any integer or floating-point type.

Alternatively, enumeration cases can specify associated values of any type to be stored along with each different case value, much as unions or variants do in other languages. One can define a common set of related cases as part of one enumeration, each of which has a different set of values of appropriate types associated with it.

In Swift, enumerations are a first-class type. They adopt many features traditionally supported only by classes, such as computed properties to provide additional information about the enumeration’s current value, and instance methods to provide functionality related to the values the enumeration represents. Enumerations can also define initializers to provide an initial case value and can be extended to expand their functionality beyond their original implementation; and can conform to protocols to provide standard functionality.

&lt;source lang="Swift"&gt;
enum CardSuit {
     case clubs
     case diamonds
     case hearts
     case spades
}
&lt;/source&gt;

Unlike C and [[Objective-C]], Swift enumeration cases are not assigned a default integer value when they are created. In the CardSuit example above, clubs, diamonds, hearts, and spades do not implicitly equal 0, 1, 2 and 3. Instead, the different enumeration cases are fully-fledged values in their own right, with an explicitly-defined type of CardSuit.

Multiple cases can appear on a single line, separated by commas:
&lt;source lang="Swift"&gt;
enum CardSuit {
     case clubs, diamonds, hearts, spades
}
&lt;/source&gt;

When working with enumerations that store integer or string raw values, one doesn’t need to explicitly assign a raw value for each case because Swift will automatically assign the values.

For instance, when integers are used for raw values, the implicit value for each case is one more than the previous case. If the first case doesn’t have a value set, its value is 0.

The enumeration below is a refinement of the earlier Planet enumeration, with integer raw values to represent each planet’s order from the sun:

&lt;source lang="Swift"&gt;
enum Planet: Int {
     case mercury = 1, venus, earth, mars, jupiter, saturn, uranus, neptune
}
&lt;/source&gt;
In the example above, Planet.mercury has an explicit raw value of 1, Planet.venus has an implicit raw value of 2, and so on.

[https://developer.apple.com/library/ios/documentation/Swift/Conceptual/Swift_Programming_Language/Enumerations.html "Details are found in Swift documentation online here."]

=== Perl ===
Dynamically typed languages in the syntactic tradition of C (e.g., [[Perl]] or [[JavaScript]]) do not, in general, provide enumerations.  But in Perl programming the same result can be obtained with the shorthand [[String literal|strings]] [[List (abstract data type)|list]] and [[Hash table|hashes]] (possibly [[Array slicing|slices]]):

&lt;source lang=C&gt;
my @enum = qw(Clubs Diamonds Hearts Spades);
my( %set1, %set2 );
@set1{@enum} = ();          # all cleared
@set2{@enum} = (1) x @enum; # all set to 1
$set1{Clubs} ...            # false
$set2{Diamonds} ...         # true
&lt;/source&gt;

=== Perl 6 ===
[[Perl 6]] does provide enumerations. There are multiple ways to declare enumerations in [[Perl 6]], all creating a back-end Map.

&lt;source lang=Perl&gt;enum Cat &lt;sphynx siamese bengal shorthair other&gt;; # Using "quote-words"&lt;/source&gt;
&lt;source lang=Perl&gt;enum Cat ('sphynx', 'siamese', 'bengal', 'shorthair', 'other'); # Using a list&lt;/source&gt;
&lt;source lang=Perl&gt;enum Cat (sphynx =&gt; 0, siamese =&gt; 1, bengal =&gt; 2, shorthair =&gt; 3, other =&gt; 4); # Using Pair constructors&lt;/source&gt;
&lt;source lang=Perl&gt;enum Cat (:sphynx(0), :siamese(1), :bengal(2), shorthair(3), :other(4)); # Another way of using Pairs, you can also use `:0sphynx`&lt;/source&gt;

===C#===

Enumerated types in the [[C Sharp (programming language)|C#]] programming language preserve most of the "small integer" semantics of C's enums. Some arithmetic operations are not defined for enums, but an enum value can be explicitly converted to an integer and back again, and an enum variable can have values that were not declared by the enum definition. For example, given

 &lt;source lang=CSharp&gt;enum Cardsuit { Clubs, Diamonds, Spades, Hearts };&lt;/source&gt;

the expressions &lt;code lang=CSharp&gt;CardSuit.Diamonds + 1&lt;/code&gt; and &lt;code lang=CSharp&gt;CardSuit.Hearts - CardSuit.Clubs&lt;/code&gt; are allowed directly (because it may make sense to step through the sequence of values or ask how many steps there are between two values), but &lt;code lang=CSharp&gt;CardSuit.Hearts*CardSuit.Spades&lt;/code&gt; is deemed to make less sense and is only allowed if the values are first converted to integers.

C# also provides the C-like feature of being able to define specific integer values for enumerations. By doing this it is possible to perform binary operations on enumerations, thus treating enumeration values as sets of flags. These flags can be tested using binary operations or with the Enum type's builtin 'HasFlag' method.

The enumeration definition defines names for the selected integer values and is [[syntactic sugar]], as it is possible to assign to an enum variable other integer values that are not in the scope of the enum definition.&lt;ref name="enum"&gt;{{cite web
 | url         = http://www.25hoursaday.com/
 | title       = A Comparison of Microsoft's C# Programming Language to Sun Microsystems' Java Programming Language
 | first      = Dare
 | last = Obasanjo
 | year        = 2007
 | work        = 
 | archiveurl  = http://www.25hoursaday.com/CsharpVsJava.html
 | archivedate = 2007
 | quote       = In Java, enumerated types are a full fledged class which means they are typesafe and can be extended by adding methods, fields or even implementing interfaces. Whereas in C#, an enumerated type is simply syntactic sugar around an integral type (typically an int) meaning they cannot be extended and are not typesafe.
 | accessdate  = 2012-09-06
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
 | url         = http://www.cstruter.com/
 | title       = Java 5: Taming the Tiger: Syntactic Sugar
 | last1       = Gruntz
 | first1      = Dominik, Prof. Dr.
 | date        = 2005-04-08
 | language    = German
 | publisher   = Fachhochschule Aargau, Nordwestschweiz
 | archiveurl  = http://www.gruntz.ch/courses/sem/ss05/Java5_SyntacticSugar.pdf
 | archivedate = 2005-04-08
 | quote       = Enumerationen sind die heimlichen Sieger von Java 1.5. Nach vielen Beteuerungen durch Sun, Enums seien in Java überflüssig und können einfach nachgebildet werden, wurden sie nun doch eingeführt. Die einfachste Möglichkeit einer Enumeration der Jahreszeiten  sieht wie folgt aus … Das Schlüsselwort  enum steht für eine spezielle Art von Klasse, die eine Enumeration  definiert. … ''Im Gegensatz zu anderen Programmiersprachen wie C/C++ und C# kann man ihnen per Gleichheitszeichen keine ganzen Zahlen zuordnen.''
 | accessdate  = 2012-09-10
}}&lt;/ref&gt;&lt;ref&gt;{{cite web
 | url         = http://www.cstruter.com/
 | title       = Syntactic sugar (C#): Enum
 | last1       = Truter
 | first1      = Christoff
 | date        = 2011-08-04
 | publisher   = CSTrüter
 | archiveurl  = http://www.cstruter.com/blog/325
 | archivedate = 2011-08-04
 | quote       = // Poorly designed enum don't do this … Obviously (like with everything else), we can misuse this piece of sugar ending up with a system suffering from hyperglycemia. … Seeing as the underlying type of our enum is an int (can also use other integral types) it can lead to some interesting issues when using an enum as bit flags via bitwise operators. 
 | accessdate  = 2012-09-10
}}&lt;/ref&gt;

=== C++ ===

[[C++]] has enumeration types that are directly inherited from C's and work mostly like these, except that an enumeration is a real type in C++, giving added compile-time checking. Also (as with structs), the C++ &lt;code&gt;enum&lt;/code&gt; keyword is automatically combined with a ''typedef'', so that instead of naming the type &lt;code&gt;enum name&lt;/code&gt;, simply name it &lt;code&gt;name&lt;/code&gt;. This can be simulated in C using a typedef: &lt;code&gt;typedef enum {Value1, Value2} name;&lt;/code&gt;

[[C++11]] provides a second, type-safe enumeration type that is not implicitly converted to an integer type. It allows io streaming to be defined for that type. Additionally the enumerations do not leak, so they have to be used with Enumeration &lt;code&gt;Type::enumeration&lt;/code&gt;. This is specified by the phrase "enum class". For example:

&lt;source lang="cpp"&gt;
enum class Color {Red, Green, Blue};
&lt;/source&gt;

The ''underlying type'' is an implementation-defined integral type that is large enough to hold all enumerated values (it doesn't have to be the smallest possible type!). In C++ you can specify the underlying type directly. That allows "forward declarations" of enumerations:

&lt;source lang="cpp"&gt;
enum class Color : long {Red, Green, Blue};  // must fit in size and memory layout the type 'long'
enum class Shapes : char;  // forward declaration. If later there are values defined that don't fit in 'char' it is an error.
&lt;/source&gt;

=== Rust ===

&lt;source lang=Rust&gt;
enum Message {
    Quit,
    Move { x: i32, y: i32 }, // anonymous struct
    Write(String),
    ChangeColor(i32, i32, i32),
}
&lt;/source&gt;

===Go===

[[Go (programming language)|Go]] uses the &lt;code&gt;iota&lt;/code&gt; keyword to create enumerated constants.&lt;ref&gt;{{cite web
 | url         = http://golang.org/doc/effective_go.html#constants
 | title       = Effective Go
 | work=golang.org
 | publisher=The Go Authors
 | accessdate  = 2014-05-13
}}&lt;/ref&gt;

&lt;source lang=Go&gt;
type ByteSize float64

const (
    _           = iota // ignore first value by assigning to blank identifier
    KB ByteSize = 1 &lt;&lt; (10 * iota)
    MB
    GB
)
&lt;/source&gt;

===Java===

The J2SE version 5.0 of the [[Java (programming language)|Java programming language]] added enumerated types whose declaration syntax is
similar to that of [[C (programming language)|C]]:

&lt;source lang=Java5&gt;
  enum Cardsuit { CLUBS, DIAMONDS, SPADES, HEARTS };
  ...
  Cardsuit trump;
&lt;/source&gt;

The Java type system, however, treats enumerations as a type separate from integers, and intermixing of enum and integer values is not allowed. In fact, an enum type in Java is actually a special compiler-generated [[class (computer science)|class]] rather than an arithmetic type, and enum values behave as global pre-generated instances of that class. Enum types can have instance methods and a constructor (the arguments of which can be specified separately for each enum value). All enum types implicitly extend the {{Javadoc:SE|java/lang|Enum}} abstract class. An enum type cannot be instantiated directly.&lt;ref&gt;{{cite web
 | url         = http://docs.oracle.com/javase/tutorial/java/javaOO/enum.html
 | title       = Enum Types
 | publisher   = Oracle
 | accessdate  = 2013-12-05
}}&lt;/ref&gt;

Internally, each enum value contains an integer, corresponding to the order in which they are declared in the source code, starting from 0. The programmer cannot set a custom integer for an enum value directly, but one can define overloaded constructors that can then assign arbitrary values to self-defined members of the enum class. Defining getters allows then access to those self-defined members. The internal integer can be obtained from an enum value using the {{Javadoc:SE|name=ordinal()|java/lang|Enum|ordinal()}} method, and the list of enum values of an enumeration type can be obtained in order using the &lt;code&gt;values()&lt;/code&gt; method. It is generally discouraged for programmers to convert enums to integers and vice versa.&lt;ref&gt;{{Cite book |last=Bloch |first=Joshua |authorlink=Joshua Bloch |title=Effective Java |edition=Second |year=2008 |publisher=Addison-Wesley |location=Upper Saddle River, N.J. |isbn=978-0-321-35668-0 |page=158}}&lt;/ref&gt; Enumerated types are &lt;code&gt;Comparable&lt;/code&gt;, using the internal integer; as a result, they can be sorted.

The Java standard library provides utility classes to use with enumerations. The {{Javadoc:SE|java/util|EnumSet}} class implements a &lt;code&gt;Set&lt;/code&gt; of enum values; it is implemented as a [[bit array]], which makes it very compact and as efficient as explicit bit manipulation, but safer. The {{Javadoc:SE|java/util|EnumMap}} class implements a &lt;code&gt;Map&lt;/code&gt; of enum values to object. It is implemented as an array, with the integer value of the enum value serving as the index.

===TypeScript===

A helpful addition to the standard set of datatypes from JavaScript is the 'enum'. Like languages like C#, an enum is a way of giving more friendly names to sets of numeric values.

&lt;source lang=JavaScript&gt;
enum Cardsuit {Clubs, Diamonds, Hearts, Spades};
var c: Cardsuit = Cardsuit.Diamonds;
&lt;/source&gt;

By default, enums begin numbering their members starting at 0. This can be changed by manually setting the value of one its members. For example, the prior example can start at 1 instead of 0:

&lt;source lang=JavaScript&gt;
enum Cardsuit {Clubs = 1, Diamonds, Hearts, Spades};
var c: Cardsuit = Cardsuit.Diamonds;
&lt;/source&gt;

Or, even manually set all the values in the enum:

&lt;source lang=JavaScript&gt;
enum Cardsuit {Clubs = 1, Diamonds = 2, Hearts = 4, Spades = 8};
var c: Cardsuit = Cardsuit.Diamonds;
&lt;/source&gt;

A handy feature of enums in TypeScript is that you can also go from a numeric value to the name of that value in the enum. For example, if presented with the value 2 but unsure which that mapped to in the enum, one could look up the corresponding name:

&lt;source lang=JavaScript&gt;
enum Cardsuit {Clubs = 1, Diamonds, Hearts, Spades};
var suitName: string = Cardsuit[2];

alert(suitName);
&lt;/source&gt;

==Python==
An [https://docs.python.org/3.4/library/enum.html &lt;code&gt;enum&lt;/code&gt;] module was added to the Python standard library in version 3.4.&lt;source lang=Python&gt;
from enum import Enum
class Cards(Enum):
    clubs = 1
    diamonds = 2
    hearts = 3
    spades = 4
&lt;/source&gt;

There is also a [https://docs.python.org/3.4/library/enum.html#functional-api functional API] for creating enumerations with automatically generated indices (starting with one):

&lt;source lang=Python&gt;
Cards = Enum('Cards', ['clubs', 'diamonds', 'hearts', 'spades'])
&lt;/source&gt;

Python enumerations do not enforce semantic correctness (a meaningless comparison to an incompatible enumeration always returns ''False'' rather than raising a ''TypeError''):

&lt;source lang=Python&gt;
&gt;&gt;&gt; Color = Enum('Color', ['red', 'green', 'blue'])
&gt;&gt;&gt; Shape = Enum('Shape', ['circle', 'triangle', 'square', 'hexagon'])
&gt;&gt;&gt; def has_vertices(shape):
... 	return shape != Shape.circle
...
&gt;&gt;&gt; has_vertices(Color.green)
True
&lt;/source&gt;

==Fortran==

[[Fortran]] only has enumerated types for interoperability with C; hence, the semantics is similar to C and, as in C, the enum values are just integers and no further type check is done. The C example from above can be written in Fortran as

&lt;source lang=Fortran&gt;
  enum, bind( C )
    enumerator :: CLUBS = 1, DIAMONDS = 2, HEARTS = 4, SPADES = 8
  end enum
&lt;/source&gt;

==Visual Basic/VBA==

Enumerated datatypes in [[Visual Basic]] (up to version 6) and [[Visual Basic for Applications|VBA]] are automatically assigned the "&lt;code&gt;Long&lt;/code&gt;" datatype and also become a datatype themselves:

&lt;source lang=VB&gt;
'Zero-based
Enum CardSuit
   Clubs
   Diamonds
   Hearts
   Spades
End Enum

Sub EnumExample()
    Dim suit As CardSuit
    suit = Diamonds
    MsgBox suit
End Sub
&lt;/source&gt;

Example Code in vb.Net

&lt;source lang=vbNet&gt;
Enum CardSuit
        Clubs
        Diamonds
        Hearts
        Spades
End Enum

Sub EnumExample()
        Dim suit As CardSuit
        suit = CardSuit.Diamonds
        MessageBox.show(suit)
End Sub
&lt;/source&gt;

== Algebraic data type in functional programming ==

In [[functional programming]] languages in the [[ML (programming language)|ML]] lineage (e.g., [[Standard ML]] (SML), [[OCaml]], and [[Haskell (programming language)|Haskell]]), an [[algebraic data type]] with only [[nullary constructor]]s can be used to implement an enumerated type. For example (in the syntax of SML signatures):
&lt;source lang="sml"&gt;
 datatype cardsuit = Clubs | Diamonds | Hearts | Spades
 type card = { suit: cardsuit; value: int }
 val hand : card list
 val trump : cardsuit
&lt;/source&gt;
In these languages the small-integer representation is completely hidden from the programmer, if indeed such a representation is employed by the implementation. However, Haskell has the &lt;code&gt;Enum&lt;/code&gt; [[type class]] which a type can derive or implement to get a mapping between the type and &lt;code&gt;Int&lt;/code&gt;.

== Lisp ==

[[Common Lisp]] uses the member type specifier, e.g.,

&lt;source lang=Lisp&gt;
(deftype cardsuit ()
  '(member club diamond heart spade))
&lt;/source&gt;

that states that object is of type cardsuit if it is &lt;code&gt;#'eql&lt;/code&gt; to club, diamond, heart or spade. The member type specifier is not valid as a [[Common Lisp Object System]] (CLOS) parameter specializer, however. Instead, &lt;code&gt;(eql atom)&lt;/code&gt;, which is the equivalent to &lt;code&gt;(member atom)&lt;/code&gt; may be used (that is, only one member of the set may be specified with an eql type specifier, however, it may be used as a CLOS parameter specializer.) In other words, to define methods to cover an enumerated type, a method must be defined for each specific element of that type.

Additionally,

&lt;source lang=Lisp&gt;
(deftype finite-element-set-type (&amp;rest elements)
   `(member ,@elements))
&lt;/source&gt;

may be used to define arbitrary enumerated types at runtime. For instance

&lt;source lang=Lisp&gt;
(finite-element-set-type club diamond heart spade)
&lt;/source&gt;

would refer to a type equivalent to the prior definition of cardsuit, as of course would simply have been using

&lt;source lang=Lisp&gt;
(member club diamond heart spade)
&lt;/source&gt;

but may be less confusing with the function &lt;code&gt;#'member&lt;/code&gt; for stylistic reasons.

== Databases ==

Some [[database]]s support enumerated types directly. [[MySQL]] provides an enumerated type &lt;code&gt;ENUM&lt;/code&gt; with allowable values specified as strings when a table is created. The values are stored as numeric indices with the empty string stored as 0, the first string value stored as 1, the second string value stored as 2, etc. Values can be stored and retrieved as numeric indexes or string values.

== XML Schema ==

[[XML Schema]] supports enumerated types through the enumeration facet used for constraining most primitive datatypes such as strings.

&lt;source lang=XML&gt;
&lt;xs:element name="cardsuit"&gt;
  &lt;xs:simpleType&gt;
    &lt;xs:restriction base="xs:string"&gt;
      &lt;xs:enumeration value="Clubs"/&gt;
      &lt;xs:enumeration value="Diamonds"/&gt;
      &lt;xs:enumeration value="Hearts"/&gt;
      &lt;xs:enumeration value="Spades"/&gt;
    &lt;/xs:restriction&gt;
  &lt;/xs:simpleType&gt;
&lt;/xs:element&gt;
&lt;/source&gt;

== See also ==
* [[contrast set]]
* [[tagged union|sum type]]

== References ==
{{Reflist|2}}

== External links ==
{{Wikibooks|Ada Programming|Types/Enumeration|Enumeration}}
* [http://www.cppreference.com/keywords/enum.html Enumerated types in C/C++]
* [http://msdn.microsoft.com/en-us/library/cc138362.aspx Enumerated types in C#]
* [http://java.sun.com/j2se/1.5.0/docs/guide/language/enums.html Enumerated types in Java]
* [http://dev.mysql.com/doc/refman/5.1/en/enum.html Enumerated types in MySQL]
* [https://archive.is/20130201203915/http://www.rps-obix.com/docs/manuals/enumerated_data_type.html Enumerated types in Obix]
* [http://www.w3.org/TR/xmlschema-2/ Enumerated types in XML]
* [http://msdn.microsoft.com/en-us/library/93khb7k9.aspx Enumerated types in Visual Basic]

{{Data types}}

&lt;!--Categories--&gt;
[[Category:Data types]]
[[Category:Type theory]]
[[Category:Articles with example Ada code]]
[[Category:Articles with example Python code]]</text>
      <sha1>bwgjshr1kn8lq5jy2i51tfb5kgb5sit</sha1>
    </revision>
  </page>
  <page>
    <title>Extravagant number</title>
    <ns>0</ns>
    <id>10396781</id>
    <revision>
      <id>822417433</id>
      <parentid>774611687</parentid>
      <timestamp>2018-01-26T07:18:09Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1316">An '''extravagant number''' (also known as a ''wasteful'' number) is a [[natural number]] that has fewer digits than the number of digits in its [[Integer factorization|prime factorization]] (including [[Exponentiation|exponents]]).&lt;ref name="Darling102"&gt;{{cite book |title=The universal book of mathematics: from Abracadabra to Zeno's paradoxes |last=Darling |first=David J. |year=2004 |publisher=[[John Wiley &amp; Sons]] |isbn=978-0-471-27047-8 |page=102 |url=https://books.google.com/books?id=nnpChqstvg0C&amp;pg=PA102 }}&lt;/ref&gt; For example, in [[Numeral system|base]]-10 arithmetic 4&amp;nbsp;=&amp;nbsp;2², 6&amp;nbsp;=&amp;nbsp;2&amp;times;3, 8&amp;nbsp;=&amp;nbsp;2³, and 9&amp;nbsp;=&amp;nbsp;3² are extravagant numbers {{OEIS|id=A046760}}.

Extravagant numbers can be defined in any base. There are infinitely many extravagant numbers, no matter what base is used.&lt;ref name="Darling102" /&gt;

== See also ==
*[[Equidigital number]]
*[[Frugal number]]

== Notes ==
{{reflist}}

== References ==
* R.G.E. Pinch (1998), [https://arxiv.org/pdf/math/9802046 Economical Numbers].
* Chris Caldwell, [http://primes.utm.edu/glossary/page.php?sort=ExtravagantNumber The Prime Glossary: extravagant number] at The [[Prime Pages]].


{{Divisor classes}}
{{Classes of natural numbers}}

[[Category:Integer sequences]]
[[Category:Base-dependent integer sequences]]</text>
      <sha1>kpr8a6g7qkubody8cnofacswj6j8zu9</sha1>
    </revision>
  </page>
  <page>
    <title>Feldman–Hájek theorem</title>
    <ns>0</ns>
    <id>58507539</id>
    <revision>
      <id>859958647</id>
      <timestamp>2018-09-17T12:21:59Z</timestamp>
      <contributor>
        <username>Sullivan.t.j</username>
        <id>2036293</id>
      </contributor>
      <comment>[[WP:AES|←]]Created page with 'In [[probability theory]], the '''Feldman–Hájek theorem''' or '''Feldman–Hájek dichotomy''' is a fundamental result in the theory of [[Gaussian measure]]s....'</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2744">In [[probability theory]], the '''Feldman–Hájek theorem''' or '''Feldman–Hájek dichotomy''' is a fundamental result in the theory of [[Gaussian measure]]s.  It states that two Gaussian measures &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\nu&lt;/math&gt; on a [[locally convex space]] &lt;math&gt;X&lt;/math&gt; are either [[equivalent measures]] or else [[singular measure|mutually singular]]:&lt;ref name="Bogachev"&gt;{{cite book
| last = Bogachev
| first = Vladimir I.
| title = Gaussian Measures
| series = Mathematical Surveys and Monographs
| volume = 62
| publisher = American Mathematical Society
| location = Providence, RI
| year = 1998
| isbn = 0-8218-1054-5
| doi = 10.1090/surv/062}} (See Theorem 2.7.2)&lt;/ref&gt;  there is no possibility of an intermediate situation in which, for example, &lt;math&gt;\mu&lt;/math&gt; has a [[probability density function|density]] with respect to &lt;math&gt;\nu&lt;/math&gt; but not vice versa.  In the special case that &lt;math&gt;X&lt;/math&gt; is a [[Hilbert space]], it is possible to give a explicit description of the circumstances under which &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\nu&lt;/math&gt; are equivalent:  writing &lt;math&gt;m_{\mu}&lt;/math&gt; and &lt;math&gt;m_{\nu}&lt;/math&gt; for the means of &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\nu&lt;/math&gt;, and &lt;math&gt;C_\mu&lt;/math&gt; and &lt;math&gt;C_\nu&lt;/math&gt; for their [[covariance operator]]s, equivalence of &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\nu&lt;/math&gt; holds if and only if&lt;ref name="DaPratoZabczyk"&gt;{{cite book
| last1 = Da Prato
| first1 = Giuseppe
| last2 = Zabczyk
| first2 = Jerzy
| title = Stochastic Equations in Infinite Dimensions
| series = Encyclopedia of Mathematics and its Applications
| volume = 152
| edition = Second
| publisher = Cambridge University Press
| location = Cambridge
| year = 2014
| isbn = 978-1-107-05584-1
| doi = 10.1017/CBO9781107295513}} (See Theorem 2.25)&lt;/ref&gt;
* &lt;math&gt;\mu&lt;/math&gt; and &lt;math&gt;\nu&lt;/math&gt; have the same [[Cameron–Martin theorem|Cameron–Martin space]] &lt;math&gt;H = C_{\mu}^{1/2}(X) = C_{\nu}^{1/2}(X)&lt;/math&gt;;
* the difference in their means lies in this common Cameron–Martin space, i.e. &lt;math&gt;m_{\mu} - m_{\nu} \in H&lt;/math&gt;;  and
* the operator &lt;math&gt;(C_{\mu}^{-1/2} C_{\nu}^{1/2}) (C_{\mu}^{-1/2} C_{\nu}^{1/2})^{\ast} - I&lt;/math&gt; is a [[Hilbert–Schmidt operator]] on &lt;math&gt;\bar{H}&lt;/math&gt;.

A simple consequence of the Feldman–Hájek theorem is that dilating a Gaussian measure on an infinite-dimensional Hilbert space &lt;math&gt;X&lt;/math&gt; (i.e. taking &lt;math&gt;C_{\nu} = s C_{\mu}&lt;/math&gt; for some scale factor &lt;math&gt;s \geq 0&lt;/math&gt;) always yields two mutually singular Gaussian measures, except for the trivial dilation with &lt;math&gt;s = 1&lt;/math&gt;, since &lt;math&gt;(s^{2} - 1) I&lt;/math&gt; is Hilbert–Schmidt only when &lt;math&gt;s = 1&lt;/math&gt;.

==References==
&lt;references/&gt;

[[Category:Measure theory]]
[[Category:Probability theorems]]</text>
      <sha1>iqqj68uxszcvznd2h7pe97fu9g0zovd</sha1>
    </revision>
  </page>
  <page>
    <title>Ferran Sunyer i Balaguer Prize</title>
    <ns>0</ns>
    <id>57181134</id>
    <revision>
      <id>841726448</id>
      <parentid>840401361</parentid>
      <timestamp>2018-05-17T17:14:25Z</timestamp>
      <contributor>
        <username>Cnwilliams</username>
        <id>10190671</id>
      </contributor>
      <minor/>
      <comment>Disambiguated: [[Catalan]] → [[Catalonia]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3298">{{onesource|date=April 2018}}
&lt;!-- info to use in infobox:
Sponsor:  Ferran Sunyer i Balaguer Foundation
Description: Honors the memory of Ferran Sunyer i Balaguer (1912–1967), a self-taught Catalan mathematician who, despite a serious physical disability, was very active in research in classical analysis.  This award acknowledges an outstanding mathematical monograph of an expository nature, presenting the latest developments in an active area of mathematics research.
Type of award: 15.000 euros as of 2017. The winning monograph will be published in Birkhauser-Verlag's series ''Progress in Mathematics''.  Frequency: Annual.
Update schedule:  April
Website:  &lt;nowiki&gt;http://ffsb.espais.iec.cat/en/the-ferran-sunyer-i-balaguer-prize/&lt;/nowiki&gt;
--&gt;

The '''Ferran Sunyer i Balaguer Prize''' is a prize in [[mathematics]], first awarded in 1993. It honors the memory of [[Ferran Sunyer i Balaguer]] (1912–1967), a self-taught [[Catalonia|Catalan]] mathematician who, despite a serious physical disability, was very active in research in classical analysis. This award acknowledges an outstanding mathematical [[monograph]] of an expository nature, presenting the latest developments in an active area of mathematics research. The annually awarded prize consists of {{€|15,000}} as of 2017. The winning monograph is also published in Birkhauser-Verlag's series ''Progress in Mathematics''. It is awarded by the Ferran Sunyer i Balaguer Foundation.&lt;ref name="prizebook"&gt;{{Cite book|url=https://www.worldcat.org/oclc/37513025|title=Recognizing excellence in the mathematical sciences : an international compilation of awards, prizes, and recipients|date=1997|publisher=JAI Press|others=Jaguszewski, Janice M.|isbn=0762302356|location=Greenwich, Conn.|oclc=37513025}}&lt;/ref&gt;

== Recipients ==
The recipients of the Ferran Sunyer i Balaguer Prize are:&lt;ref name="prizebook" /&gt;&lt;ref&gt;{{Cite web|url=http://ffsb.espais.iec.cat/en/the-ferran-sunyer-i-balaguer-prize/|title=The Ferran Sunyer i Balaguer Prize {{!}} Fundació Ferran Sunyer i Balaguer|website=ffsb.espais.iec.cat|language=en-US|access-date=2018-05-09}}&lt;/ref&gt;

* 1993: Alexander Lubotzky
* 1994: [[Klaus Schmidt (mathematician)|Klaus Schmidt]]
* 1995: Not awarded
* 1996: [[V. Kumar Murty]], [[M. Ram Murty]]
* 1997: A. Böttcher, Y. I. Karlovich
* 1998: Juan J. Morales-Ruiz
* 1999: [[Patrick Dehornoy]]
* 2000: Juan-Pablo Ortega, [[Tudor Ratiu]]
* 2001: [[Marty Golubitsky|Martin Golubitsky]], [[Ian Stewart (mathematician)|Ian Stewart]]
* 2002: Alexander Lubotzky, [[Dan Segal]]
* 2002: André Unterberger
* 2003: Fuensanta Andreu-Vaillo, José M. Mazón
* 2004: Guy David
* 2005: [[Antonio Ambrosetti]], [[Andrea Malchiodi]]
* 2005: José Seade
* 2006: [[Xiaonan Ma]], George Marinescu
* 2007: Rosa M. Miró-Roig
* 2008: Luis Barreira
* 2009: Tim Browning
* 2010: Carlo Mantegazza
* 2011: Jayce Getz and [[Mark Goresky]]
* 2012: Angel Cano, Juan Pablo Navarrete, Jose Seade.
* 2013: Xavier Tolsa
* 2014: Veronique Fischer, Michael Ruzhansky
* 2015: Not awarded
* 2016: [[Vladimir Turaev]], Alexis Virelizier
* 2017: Antoine Chambert-Loir, Johannes Nicaise, Julien Sebag

== References ==
&lt;references /&gt;

== External links ==
[http://ffsb.espais.iec.cat/en/the-ferran-sunyer-i-balaguer-prize/ Website]

[[Category:Mathematics awards]]</text>
      <sha1>ng0vwf4uddm2x1w9dvk9a2042z141fb</sha1>
    </revision>
  </page>
  <page>
    <title>Francis Wollaston (philosopher)</title>
    <ns>0</ns>
    <id>14417429</id>
    <revision>
      <id>827608214</id>
      <parentid>713094761</parentid>
      <timestamp>2018-02-25T18:39:37Z</timestamp>
      <contributor>
        <username>Tassedethe</username>
        <id>7098284</id>
      </contributor>
      <minor/>
      <comment>v1.43 - Repaired 1 link to disambiguation page - [[WP:DPL|(You can help)]] - [[Edward Pearson]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2761">'''Francis John Hyde Wollaston'''  [[Fellow of the Royal Society|FRS]] (13 April 1762, [[London]] – 12 October 1823) was an [[England|English]] [[natural philosopher]] and [[Jacksonian Professor of Natural Philosophy|Jacksonian Professor]] at the [[University of Cambridge]].

==Life==
Francis John Hyde Wollaston was the son of [[Francis Wollaston (astronomer)|Francis Wollaston]] (1731–1815) and Althea Hyde, and brother to [[William Hyde Wollaston]] (1766-1828). He was educated in Scarning, [[Norfolk]] and at [[Charterhouse School|Charterhouse]] before entering [[Sidney Sussex College, Cambridge]] in 1779. He graduated as [[senior wrangler]] in 1783, became a fellow of [[Trinity Hall, Cambridge|Trinity Hall]] in 1785, and was ordained a priest in 1787.&lt;ref name=Venn&gt;{{acad|id=WLSN779FJ|name=Wollaston, Francis John Hyde}}&lt;/ref&gt;

Wollaston was elected a [[Fellow of the Royal Society]] in 1786.&lt;ref&gt;{{cite encyclopedia
 | last = Clark
 | first = J. W.
 |author2=Anita McConnell
 | encyclopedia =Oxford Dictionary of National Biography
 | title = Wollaston, Francis John Hyde (1762–1823)
 | url = http://www.oxforddnb.com/view/article/29838
 | year =2004 
 | publisher = Oxford University Press
}}&lt;/ref&gt; From 1792 to 1813 he was Jacksonian Professor at Cambridge. Resigning his Trinity Hall fellowship to marry Frances Hayles in 1793, he became Rector of [[South Weald]] the following year. In 1807 he was elected Master of Sidney Sussex College, but the election was declared invalid on the grounds that he had never been a fellow of Sidney Sussex. On resigning his professorship in 1813, he assumed additional clerical duties: from 1813 to 1823 he was rector of [[Cold Norton]] and [[Archdeacon of Essex]].&lt;ref name=Venn/&gt;

==Works==
*''A Plan of a Course of Chemical Lectures'', 1794
*''Charge, delivered to the Clergy of the Archdeaconry of Essex'', 1815

==References==
{{Reflist}}

==External links==
*{{worldcat id|lccn-nr93-43145}}

{{s-start}}
{{s-aca}}
{{succession box 
  | title = [[Sidney Sussex College, Cambridge|Master of Sidney Sussex College, Cambridge]]
  | years = 1807-1808
  | before = [[William Elliston]]
  | after = [[Edward Pearson (theologian)|Edward Pearson]]
}}
{{end}}
{{Archdeacons of Essex}}
{{Wollaston family tree}}
{{Authority control}}

{{DEFAULTSORT:Wollaston, Francis John Hyde}}
[[Category:Archdeacons of Essex]]
[[Category:Academics of the University of Cambridge]]
[[Category:Fellows of the Royal Society]]
[[Category:1762 births]]
[[Category:1823 deaths]]
[[Category:Senior Wranglers]]
[[Category:People educated at Charterhouse School]]
[[Category:Fellows of Trinity Hall, Cambridge]]
[[Category:Masters of Sidney Sussex College, Cambridge]]
[[Category:Natural philosophers]]


{{England-scientist-stub}}</text>
      <sha1>8hghg0zlaah3ne51g1to5hiquzgjrib</sha1>
    </revision>
  </page>
  <page>
    <title>Gordon–Luecke theorem</title>
    <ns>0</ns>
    <id>10208241</id>
    <revision>
      <id>797014858</id>
      <parentid>761898029</parentid>
      <timestamp>2017-08-24T12:32:47Z</timestamp>
      <contributor>
        <username>Ventricule</username>
        <id>1639963</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2400">In [[mathematics]], the '''Gordon–Luecke theorem''' on [[knot complement]]s states that if the complements of two [[tame knot]]s are homeomorphic, then the knots are equivalent. In particular, any homeomorphism between knot complements must take a meridian to a meridian.  

The theorem is usually stated as "knots are determined by their complements"; however this is  slightly ambiguous as it considers two knots to be equivalent if there is a self-homeomorphism taking one knot to the other.  Thus mirror images are neglected.  Often two knots are considered equivalent if they are ''[[Regular isotopy|isotopic]]''.  The correct version in this case is that if two knots have complements which are orientation-preserving homeomorphic, then they are isotopic.  

These results follow from the following (also called the Gordon–Luecke theorem): no nontrivial [[Dehn surgery]] on a nontrivial knot in the [[3-sphere]] can yield the [[3-sphere]].  

The theorem was proved by [[Cameron Gordon (mathematician)|Cameron Gordon]] and [[John Luecke (mathematician)|John Luecke]].  Essential ingredients of the proof are their joint work with [[Marc Culler]] and [[Peter Shalen]] on the [[cyclic surgery theorem]], combinatorial techniques in the style of Litherland, [[thin position]], and [[Scharlemann cycle]]s.

For link complements, it is not in fact true that links are determined by their complements.  For example, [[JHC Whitehead]] proved that there are infinitely many links whose complements are all homeomorphic to the [[Whitehead link]].  His construction is to twist along a disc spanning an unknotted component (as is the case for either component of the Whitehead link).  Another method is to twist along an annulus spanning two components.  Gordon proved that for the class of links where these two constructions are not possible there are finitely many links ''in this class'' with a given complement.

==References==
*Cameron Gordon and John Luecke, ''Knots are determined by their complements''.  [[Journal of the American Mathematical Society|J. Amer. Math. Soc.]] 2 (1989), no. 2, 371–415. 
*Cameron Gordon, ''Links and their complements.''  Topology and geometry: commemorating SISTAG, 71–82, Contemp. Math., 314, Amer. Math. Soc., Providence, RI, 2002.

{{DEFAULTSORT:Gordon-Luecke theorem}}
[[Category:Knot theory]]
[[Category:3-manifolds]]
[[Category:Theorems in topology]]</text>
      <sha1>9fxyor5e4ny52zj74fkmpywge3spm2f</sha1>
    </revision>
  </page>
  <page>
    <title>Hecke algebra acting on modular forms</title>
    <ns>0</ns>
    <id>55907189</id>
    <revision>
      <id>853209111</id>
      <parentid>832735629</parentid>
      <timestamp>2018-08-03T04:36:56Z</timestamp>
      <contributor>
        <username>David Schwein</username>
        <id>10360153</id>
      </contributor>
      <comment>Fixed typoe</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="344">In [[number theory]] in mathematics, the '''Hecke algebra''' is the algebra generated by [[Hecke operator]]s. The algebra is commutative.&lt;ref&gt;{{harvnb|Serre|1973|loc=Ch. VII, § 5. Corollary 2.}}&lt;/ref&gt;

== References ==
{{reflist}}
*[[Jean-Pierre Serre]], ''A course in arithmetic''.

{{algebra-stub}}

{{improve categories|date=December 2017}}</text>
      <sha1>g2kqsqkv7dv50czva234hz6qlse07go</sha1>
    </revision>
  </page>
  <page>
    <title>Hermes8</title>
    <ns>0</ns>
    <id>6338664</id>
    <revision>
      <id>482743461</id>
      <parentid>290650026</parentid>
      <timestamp>2012-03-19T16:18:12Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>[[WP:CHECKWIKI]] error  fixes + [[WP:GENFIXES|general fixes]] using [[Project:AWB|AWB]] (8024)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="767">In [[cryptography]], '''Hermes8''' is the name of a [[stream cipher|stream cypher]] [[algorithm]] designed by Ulrich Kaiser. It has been submitted to the [[eSTREAM]] Project of the [[eCRYPT]] network. It has been classified as an 'archive' algorithm and will not be further considered.

==Security==
In the paper "An Analysis of the Hermes8 Stream Ciphers" the authors claim, 'an attack on the latest version of the cipher (Hermes8F), which requires very few known [[keystream]] bytes and recovers the cipher's secret key in less than a second on a normal PC'.

==References==
* [http://eprint.iacr.org/2006/269 "An Analysis of the Hermes8 Stream Ciphers" paper by Steve Babbage et al.]

{{Cryptography navbox | stream}}

[[Category:Stream ciphers]]


{{crypto-stub}}</text>
      <sha1>hg9z4qxhbr2c16zpdyt5z34p52fk8hh</sha1>
    </revision>
  </page>
  <page>
    <title>In-place matrix transposition</title>
    <ns>0</ns>
    <id>11174336</id>
    <revision>
      <id>834013831</id>
      <parentid>832584988</parentid>
      <timestamp>2018-04-03T13:48:25Z</timestamp>
      <contributor>
        <username>K7miller</username>
        <id>33447714</id>
      </contributor>
      <comment>/* Square matrices */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21955">'''In-place matrix transposition''', also called '''in-situ matrix transposition''', is the problem of [[transpose|transposing]] an ''N''×''M'' [[matrix (mathematics)|matrix]] [[in-place]] in [[computer memory]], ideally with [[Big O notation|''O''(1)]] (bounded) additional storage, or at most with additional storage much less than ''NM''.  Typically, the matrix is assumed to be stored in [[row-major order]] or [[column-major order]] (i.e., contiguous rows or columns, respectively, arranged consecutively).

Performing an in-place transpose (in-situ transpose) is most difficult when ''N'' ≠ ''M'', i.e. for a non-square (rectangular) matrix, where it involves a complicated [[permutation]] of the data elements, with many [[cyclic permutation|cycle]]s of length greater than 2.  In contrast, for a square matrix (''N'' = ''M''), all of the cycles are of length 1 or 2, and the transpose can be achieved by a simple loop to swap the upper triangle of the matrix with the lower triangle.  Further complications arise if one wishes to maximize [[memory locality]] in order to improve [[cache line]] utilization or to operate [[out-of-core]] (where the matrix does not fit into main memory), since transposes inherently involve non-consecutive memory accesses.

The problem of non-square in-place transposition has been studied since at least the late 1950s, and several algorithms are known, including several which attempt to optimize locality for cache, out-of-core, or similar memory-related contexts.

==Background==

On a [[computer]], one can often avoid explicitly transposing a matrix in [[Random access memory|memory]] by simply accessing the same data in a different order.  For example, [[software libraries]] for [[linear algebra]], such as [[BLAS]], typically provide options to specify that certain matrices are to be interpreted in transposed order to avoid data movement.

However, there remain a number of circumstances in which it is necessary or desirable to physically reorder a matrix in memory to its transposed ordering.  For example, with a matrix stored in [[row-major order]], the rows of the matrix are contiguous in memory and the columns are discontiguous.  If repeated operations need to be performed on the columns, for example in a [[fast Fourier transform]] algorithm (e.g. Frigo &amp; Johnson, 2005), transposing the matrix in memory (to make the columns contiguous) may improve performance by increasing [[memory locality]].  Since these situations normally coincide with the case of very large matrices (which exceed the cache size), performing the transposition in-place with minimal additional storage becomes desirable.

Also, as a purely mathematical problem, in-place transposition involves a number of interesting [[number theory]] puzzles that have been worked out over the course of several decades.

==Example==

For example, consider the 2×4 matrix:

:&lt;math&gt;\begin{bmatrix} 11 &amp; 12 &amp; 13 &amp; 14 \\ 21 &amp; 22 &amp; 23 &amp; 24\end{bmatrix}.&lt;/math&gt;

In row-major format, this would be stored in computer memory as the sequence (11, 12, 13, 14, 21, 22, 23, 24), i.e. the two rows stored consecutively. If we transpose this, we obtain the 4×2 matrix:

:&lt;math&gt;\begin{bmatrix} 11 &amp; 21 \\ 12 &amp; 22 \\ 13 &amp; 23 \\ 14 &amp; 24\end{bmatrix}&lt;/math&gt;

which is stored in computer memory as the sequence (11, 21, 12, 22, 13, 23, 14, 24).

{| class="wikitable infobox" style="color:black"
! style="text-align:right;" |Position
! style="background:#ccffff"|0
! style="background:#ffcccc"|1
! style="background:#ffcccc"|2
! style="background:#ffffcc"|3
! style="background:#ffcccc"|4
! style="background:#ffffcc"|5
! style="background:#ffffcc"|6
! style="background:#ccffcc"|7
|-
| Original storage
! style="background:#ccffff"|11
! style="background:#ffcccc"|12
! style="background:#ffcccc"|13
! style="background:#ffffcc"|14
! style="background:#ffcccc"|21
! style="background:#ffffcc"|22
! style="background:#ffffcc"|23
! style="background:#ccffcc"|24
|-
| Transposed storage
! style="background:#ccffff"|11
! style="background:#ffcccc"|21
! style="background:#ffcccc"|12
! style="background:#ffffcc"|22
! style="background:#ffcccc"|13
! style="background:#ffffcc"|23
! style="background:#ffffcc"|14
! style="background:#ccffcc"|24
|}
If we number the storage locations 0 to 7, from left to right, then this permutation consists of four cycles:

:(0), (1 2 4), (3 6 5), (7)

That is, the value in position 0 goes to position 0 (a cycle of length 1, no data motion). Next, the value in position 1 (in the original storage: 11, '''12''', 13, 14, 21, 22, 23, 24) goes to position 2 (in the transposed storage 11, 21, '''12''', 22, 13, 23, 14, 24), while the value in position 2 (11, 12, '''13''', 14, 21, 22, 23, 24) goes to position 4 (11, 21, 12, 22, '''13''', 23, 14, 24), and position 4 (11, 12, 13, 14, '''21''', 22, 23, 24) goes back to position 1 (11, '''21''', 12, 22, 13, 23, 14, 24). Similarly for the values in position 7 and positions (3 6 5).

==Properties of the permutation==

In the following, we assume that the ''N''×''M'' matrix is stored in row-major order with zero-based indices.  This means that the (''n'',''m'') element, for ''n'' = 0,&amp;#8230;,''N''&amp;minus;1 and ''m'' = 0,&amp;#8230;,''M''&amp;minus;1, is stored at an address ''a'' = ''Mn'' + ''m'' (plus some offset in memory, which we ignore).  In the transposed ''M''×''N'' matrix, the corresponding (''m'',''n'') element is stored at the address ''a' '' = ''Nm'' + ''n'', again in row-major order.  We define the ''transposition permutation'' to be the function ''a' '' = ''P''(''a'') such that:
:&lt;math&gt;Nm + n = P(Mn + m) \,&lt;/math&gt; for all &lt;math&gt;(n,m) \in [0,N-1]\times[0,M-1] \,.&lt;/math&gt;
This defines a permutation on the numbers &lt;math&gt;a = 0,\ldots,MN-1&lt;/math&gt;.

It turns out that one can define simple formulas for ''P'' and its inverse (Cate &amp; Twigg, 1977).  First:

:&lt;math&gt;P(a) = \begin{cases}
MN - 1 &amp; \text{if } a = MN - 1, \\
Na \bmod MN - 1 &amp; \text{otherwise},
\end{cases}
&lt;/math&gt;

where "mod" is the [[modulo operation]]. 
{{cot|Proof}} 
If 0 ≤ ''a'' = ''Mn'' + ''m'' &lt; ''MN'' &amp;minus; 1, then ''Na'' mod (''MN''&amp;minus;1) = ''MN'' ''n'' + ''Nm'' mod (''MN'' &amp;minus; 1) = ''n'' + ''Nm''.  &lt;ref group="ProofNote"&gt; ''MN'' ''x'' mod (''MN''&amp;minus;1) = (''MN'' &amp;minus; 1) ''x''  + ''x'' mod (''MN''&amp;minus;1) = ''x'' for 0 ≤ ''x'' &lt; ''MN'' &amp;minus; 1.&lt;/ref&gt;&lt;ref group="ProofNote"&gt;The first (''a'' = 0) and last (''a'' = ''MN''&amp;minus;1) elements are always left invariant under transposition. &lt;/ref&gt;
{{cob}}  
Second, the inverse permutation is given by:

:&lt;math&gt;P^{-1}(a') = \begin{cases}
MN - 1 &amp; \text{if } a' = MN - 1, \\
Ma' \bmod MN - 1 &amp; \text{otherwise}.
\end{cases}
&lt;/math&gt;

(This is just a consequence of the fact that the inverse of an ''N''×''M'' transpose is an ''M''×''N'' transpose, although it is also easy to show explicitly that ''P''&lt;sup&gt;&amp;minus;1&lt;/sup&gt; composed with ''P'' gives the identity.)

As proved by Cate &amp; Twigg (1977), the number of [[fixed point (mathematics)|fixed points]] (cycles of length 1) of the permutation is precisely {{math|1&amp;nbsp;+&amp;nbsp;gcd(''N''&amp;minus;1,''M''&amp;minus;1)}}, where gcd is the [[greatest common divisor]].  For example, with ''N'' = ''M'' the number of fixed points is simply ''N'' (the diagonal of the matrix).  If {{math|''N''&amp;nbsp;&amp;minus;&amp;nbsp;1}} and {{math|''M''&amp;nbsp;&amp;minus;&amp;nbsp;1}} are [[coprime]], on the other hand, the only two fixed points are the upper-left and lower-right corners of the matrix.

The number of cycles of any length ''k''&amp;gt;1 is given by (Cate &amp; Twigg, 1977):

:&lt;math&gt;\frac{1}{k} \sum_{d | k} \mu(k/d) \gcd(N^d - 1, MN - 1) ,&lt;/math&gt;

where μ is the [[Möbius function]] and the sum is over the [[divisor]]s ''d'' of ''k''.

Furthermore, the cycle containing ''a''=1 (i.e. the second element of the first row of the matrix) is always a cycle of maximum length ''L'', and the lengths ''k'' of all other cycles must be divisors of ''L''  (Cate &amp; Twigg, 1977).

For a given cycle ''C'', every element &lt;math&gt;x \in C&lt;/math&gt; has the same greatest common divisor &lt;math&gt;d = \gcd(x, MN - 1)&lt;/math&gt;.  
{{cot|Proof (Brenner, 1973)}}  
Let ''s'' be the smallest element of the cycle, and &lt;math&gt;d = \gcd(s, MN - 1)&lt;/math&gt;.  From the definition of the permutation ''P'' above, every other element ''x'' of the cycle is obtained by repeatedly multiplying ''s'' by ''N'' modulo ''MN''&amp;minus;1, and therefore every other element is divisible by ''d''.  But, since ''N'' and {{math|''MN''&amp;nbsp;&amp;minus;&amp;nbsp;1}} are coprime, ''x'' cannot be divisible by any factor of {{math|''MN''&amp;nbsp;&amp;minus;&amp;nbsp;1}} larger than ''d'', and hence &lt;math&gt;d = \gcd(x, MN - 1)&lt;/math&gt;.
{{cob}}  
This theorem is useful in searching for cycles of the permutation, since an efficient search can look only at multiples of divisors of ''MN''&amp;minus;1 (Brenner, 1973).

Laflin &amp; Brebner (1970) pointed out that the cycles often come in pairs, which is exploited by several algorithms that permute pairs of cycles at a time.  In particular, let ''s'' be the smallest element of some cycle ''C'' of length ''k''.  It follows that ''MN''&amp;minus;1&amp;minus;''s'' is also an element of a cycle of length ''k'' (possibly the same cycle).  
{{cot|Proof by the definition of ''P'' above}} 
The length ''k'' of the cycle containing ''s'' is the smallest ''k'' &amp;gt; 0 such that &lt;math&gt;s N^k = s \bmod (MN - 1)&lt;/math&gt;.  Clearly, this is the same as the smallest ''k''&amp;gt;0 such that &lt;math&gt;(-s) N^k = -s \bmod (MN - 1)&lt;/math&gt;, since we are just multiplying both sides by &amp;minus;1, and &lt;math&gt;MN-1-s = -s \bmod (MN - 1)&lt;/math&gt;. 
{{cob}}

{{cot|Note of proofs}}
&lt;references group="ProofNote"/&gt;
{{cob}}

==Algorithms==

The following briefly summarizes the published algorithms to perform in-place matrix transposition.  [[Source code]] implementing some of these algorithms can be found in the references, below.

===Square matrices===

For a square ''N''×''N'' matrix ''A''&lt;sub&gt;''n'',''m''&lt;/sub&gt; = ''A''(''n'',''m''), in-place transposition is easy because all of the cycles have length 1 (the diagonals ''A''&lt;sub&gt;''n'',''n''&lt;/sub&gt;) or length 2 (the upper triangle is swapped with the lower triangle).  [[Pseudocode]] to accomplish this (assuming zero-based [[array data structure|array]] indices) is:

 '''for''' n = 0 to N - 2
     '''for''' m = n + 1 to N - 1
         swap A(n,m) with A(m,n)

This type of implementation, while simple, can exhibit poor performance due to poor cache-line utilization, especially when ''N'' is a [[power of two]] (due to cache-line conflicts in a [[CPU cache]] with limited associativity).  The reason for this is that, as ''m'' is incremented in the inner loop, the memory address corresponding to ''A''(''n'',''m'') or ''A''(''m'',''n'') jumps discontiguously by ''N'' in memory (depending on whether the array is in column-major or row-major format, respectively).  That is, the algorithm does not exploit [[locality of reference]].

One solution to improve the cache utilization is to "block" the algorithm to operate on several numbers at once, in blocks given by the cache-line size; unfortunately, this means that the algorithm depends on the size of the cache line (it is "cache-aware"), and on a modern computer with multiple levels of cache it requires multiple levels of machine-dependent blocking. Instead, it has been suggested (Frigo ''et al.'', 1999) that better performance can be obtained by a [[recursion|recursive]] algorithm: divide the matrix into four submatrices of roughly equal size, transposing the two submatrices along the diagonal recursively and transposing and swapping the two submatrices above and below the diagonal.  (When ''N'' is sufficiently small, the simple algorithm above is used as a base case, as naively recurring all the way down to ''N''=1 would have excessive function-call overhead.)  This is a [[cache-oblivious]] algorithm, in the sense that it can exploit the cache line without the cache-line size being an explicit parameter.

===Non-square matrices: Following the cycles===

For non-square matrices, the algorithms are more complicated.  Many of the algorithms prior to 1980 could be described as "follow-the-cycles" algorithms.  That is, they loop over the cycles, moving the data from one location to the next in the cycle.  In pseudocode form:

 '''for each''' length&amp;gt;1 cycle ''C'' of the permutation
     pick a starting address ''s'' in ''C''
     let ''D'' = data at ''s''
     let ''x'' = predecessor of ''s'' in the cycle
     '''while''' ''x'' ≠ ''s''
         move data from ''x'' to successor of ''x''
         let ''x'' = predecessor of ''x''
     move data from ''D'' to successor of ''s''

The differences between the algorithms lie mainly in how they locate the cycles, how they find the starting addresses in each cycle, and how they ensure that each cycle is moved exactly once.  Typically, as discussed above, the cycles are moved in pairs, since ''s'' and ''MN''&amp;minus;1&amp;minus;''s'' are in cycles of the same length (possibly the same cycle).  Sometimes, a small scratch array, typically of length ''M''+''N'' (e.g. Brenner, 1973; Cate &amp; Twigg, 1977) is used to keep track of a subset of locations in the array that have been visited, to accelerate the algorithm.

In order to determine whether a given cycle has been moved already, the simplest scheme would be to use ''O''(''MN'') auxiliary storage, one [[bit]] per element, to indicate whether a given element has been moved.  To use only ''O''(''M''+''N'') or even {{math|''O''(log&amp;nbsp;''MN'')}} auxiliary storage, more complicated algorithms are required, and the known algorithms have a worst-case [[linearithmic]] computational cost of {{math|''O''(''MN''&amp;nbsp;log&amp;nbsp;''MN'')}} at best, as first proved by [[Donald Knuth|Knuth]] (Fich ''et al.'', 1995; Gustavson &amp; Swirszcz, 2007).

Such algorithms are designed to move each data element exactly once.  However, they also involve a considerable amount of arithmetic to compute the cycles, and require heavily non-consecutive memory accesses since the adjacent elements of the cycles differ by multiplicative factors of ''N'', as discussed above.

===Improving memory locality at the cost of greater total data movement===

Several algorithms have been designed to achieve greater memory locality at the cost of greater data movement, as well as slightly greater storage requirements.  That is, they may move each data element more than once, but they involve more consecutive memory access (greater spatial locality), which can improve performance on modern CPUs that rely on caches, as well as on [[SIMD]] architectures optimized for processing consecutive data blocks.  The oldest context in which the spatial locality of transposition seems to have been studied is for out-of-core operation (by Alltop, 1975), where the matrix is too large to fit into main memory ("[[Magnetic-core memory|core]]").

For example, if ''d'' = [[greatest common divisor|gcd]](''N'',''M'') is not small, one can perform the transposition using a small amount (''NM''/''d'') of additional storage, with at most three passes over the array (Alltop, 1975; Dow, 1995).  Two of the passes involve a sequence of separate, small transpositions (which can be performed efficiently out of place using a small buffer) and one involves an in-place ''d''&amp;times;''d'' square transposition of &lt;math&gt;NM/d^2&lt;/math&gt; blocks (which is efficient since the blocks being moved are large and consecutive, and the cycles are of length at most 2). This is further simplified if N is a multiple of M (or vice versa), since only one of the two out-of-place passes is required.

Another algorithm for non-[[coprime]] dimensions, involving multiple subsidiary transpositions, was described by Catanzaro et al. (2014).  For the case where {{math|{{abs|''N''&amp;nbsp;&amp;minus;&amp;nbsp;''M''}}}} is small, Dow (1995) describes another algorithm requiring {{math|{{abs|''N''&amp;nbsp;&amp;minus;&amp;nbsp;''M''}} ⋅ min(''N'',''M'')}} additional storage, involving a {{math|min(''N'',&amp;nbsp;''M'') ⋅ min(''N'',&amp;nbsp;''M'')}} square transpose preceded or followed by a small out-of-place transpose.  Frigo &amp; Johnson (2005) describe the adaptation of these algorithms to use cache-oblivious techniques for general-purpose CPUs relying on cache lines to exploit spatial locality.

Work on out-of-core matrix transposition, where the matrix does not fit in main memory and must be stored largely on a [[hard disk]], has focused largely on the ''N'' = ''M'' square-matrix case, with some exceptions (e.g. Alltop, 1975).  Recent reviews of out-of-core algorithms, especially as applied to [[parallel computing]], can be found in e.g. Suh &amp; Prasanna (2002) and Krishnamoorth et al. (2004).

==References==
{{refbegin}}
* P. F. Windley, "Transposing matrices in a digital computer," ''Computer Journal'' '''2''', p.&amp;nbsp;47-48 (1959).
* G. Pall, and E. Seiden, "A problem in Abelian Groups, with application to the transposition of a matrix on an electronic computer," ''Math. Comp.'' '''14''', p.&amp;nbsp;189-192 (1960).
* J. Boothroyd, "[http://portal.acm.org/citation.cfm?id=363304&amp;dl=GUIDE&amp;coll=GUIDE&amp;CFID=436989&amp;CFTOKEN=18491885 Algorithm 302: Transpose vector stored array]," ''ACM Transactions on Mathematical Software'' '''10''' (5), p.&amp;nbsp;292-293 (1967). 
* Susan Laflin and M. A. Brebner, "[http://portal.acm.org/citation.cfm?id=362368&amp;dl=GUIDE&amp;coll=GUIDE&amp;CFID=436989&amp;CFTOKEN=18491885 Algorithm 380: in-situ transposition of a rectangular matrix]," ''ACM Transactions on Mathematical Software'' '''13''' (5), p.&amp;nbsp;324-326 (1970).  [http://www.netlib.org/toms/380 Source code].
* Norman Brenner, "[http://portal.acm.org/citation.cfm?id=362542&amp;dl=GUIDE&amp;coll=GUIDE&amp;CFID=436989&amp;CFTOKEN=18491885 Algorithm 467: matrix transposition in place]," ''ACM Transactions on Mathematical Software'' '''16''' (11), p.&amp;nbsp;692-694 (1973). [http://www.netlib.org/toms/467 Source code].
* W. O. Alltop, "A computer algorithm for transposing nonsquare matrices," ''IEEE Trans. Comput.'' '''24''' (10), p.&amp;nbsp;1038-1040 (1975).
* Esko G. Cate and David W. Twigg, "[http://portal.acm.org/citation.cfm?id=355719.355729&amp;coll=GUIDE&amp;dl=GUIDE&amp;CFID=436989&amp;CFTOKEN=18491885 Algorithm 513: Analysis of In-Situ Transposition]," ''ACM Transactions on Mathematical Software'' '''3''' (1), p.&amp;nbsp;104-110 (1977). [http://www.netlib.org/toms/513 Source code].
* Bryan Catanzaro, Alexander Keller, and Michael Garland, [A decomposition for in-place matrix transposition http://dl.acm.org/citation.cfm?id=2555253],  Proceedings of the 19th ACM SIGPLAN symposium on Principles and practice of parallel programming (PPoPP '14), pp.&amp;nbsp;193–206 (2014).
* Murray Dow, "Transposing a matrix on a vector computer," ''Parallel Computing'' '''21''' (12), p.&amp;nbsp;1997-2005 (1995).
* Donald E. Knuth, ''[[The Art of Computer Programming]] Volume 1: Fundamental Algorithms'', third edition, section 1.3.3 exercise 12 (Addison-Wesley: New York, 1997).
* M. Frigo, C. E. Leiserson, H. Prokop, and S. Ramachandran, "[http://supertech.lcs.mit.edu/cilk/papers/abstracts/abstract4.html Cache-oblivious algorithms]," in ''Proceedings of the 40th IEEE Symposium on Foundations of Computer Science'' (FOCS 99), p.&amp;nbsp;285-297 (1999). [http://ieeexplore.ieee.org/iel5/6604/17631/00814600.pdf?arnumber=814600 Extended abstract at IEEE], [http://citeseer.ist.psu.edu/307799.html at Citeseer].
* J. Suh and V. K. Prasanna, "[https://dx.doi.org/10.1109/12.995452 An efficient algorithm for out-of-core matrix transposition]," ''IEEE Trans. Computers'' '''51''' (4), p.&amp;nbsp;420-438 (2002).
* S. Krishnamoorthy, G. Baumgartner, D. Cociorva, C.-C. Lam, and P. Sadayappan, "[http://csc.lsu.edu/~gb/TCE//Publications/ParTranspose2.pdf Efficient parallel out-of-core matrix transposition]," ''International Journal of High Performance Computing and Networking'' '''2''' (2-4), p.&amp;nbsp;110-119 (2004).
* M. Frigo and S. G. Johnson, "[http://fftw.org/fftw-paper-ieee.pdf The Design and Implementation of FFTW3]," ''Proceedings of the IEEE'' '''93''' (2), 216–231 (2005). [http://www.fftw.org Source code] of the [[FFTW]] library, which includes optimized serial and [[parallel computing|parallel]] square and non-square transposes, in addition to [[Fast Fourier transform|FFT]]s.
* [[Faith Ellen|Faith E. Fich]], J. Ian Munro, and Patricio V. Poblete, "Permuting in place," ''SIAM Journal on Computing'' '''24''' (2), p.&amp;nbsp;266-278 (1995).
* Fred G. Gustavson and Tadeusz Swirszcz, "In-place transposition of rectangular matrices," ''Lecture Notes in Computer Science'' '''4699''', p.&amp;nbsp;560-569 (2007), from the Proceedings of the 2006 Workshop on State-of-the-Art &lt;nowiki&gt;[&lt;/nowiki&gt;''sic''&lt;nowiki&gt;]&lt;/nowiki&gt; in Scientific and Parallel Computing (PARA 2006) (Umeå, Sweden, June 2006).
*{{Cite OEIS|sequencenumber=A093055|name=Number of non-singleton cycles in the in-situ transposition of a rectangular j X k matrix}}
*{{Cite OEIS|sequencenumber=A093056|name=Length of the longest cycle in the in-situ transposition of a rectangular j X k matrix}}
*{{Cite OEIS|sequencenumber=A093057|name=Number of matrix elements remaining at fixed position in the in-situ transposition of a rectangular j X k matrix}}
{{refend}}

==External links==

===Source code===
* [http://romo661.free.fr/offt.html OFFT] - recursive block in-place transpose of square matrices, in Fortran
* [https://groups.google.com/group/sci.math.num-analysis/msg/680211b3fbac30c4?hl=en Jason Stratos Papadopoulos], blocked in-place transpose of square matrices, in [[C (programming language)|C]], ''sci.math.num-analysis'' newsgroup (April 7, 1998).
* See "Source code" links in the references section above, for additional code to perform in-place transposes of both square and non-square matrices.
* [https://bitbucket.org/ijsung/libmarshal/wiki/Home libmarshal] Blocked in-place transpose of rectangular matrices for the GPUs.
{{Numerical linear algebra}}

[[Category:Numerical linear algebra]]
[[Category:Permutations]]
[[Category:Articles with example pseudocode]]</text>
      <sha1>htujhh2xhublgpizwcai0bb2vkamalb</sha1>
    </revision>
  </page>
  <page>
    <title>Independence number</title>
    <ns>0</ns>
    <id>5526051</id>
    <redirect title="Independent set (graph theory)" />
    <revision>
      <id>704472799</id>
      <parentid>313414960</parentid>
      <timestamp>2016-02-11T20:25:04Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>change redirect target</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="74">#redirect [[Independent set (graph theory)]]
[[Category:Graph invariants]]</text>
      <sha1>i3lfg7wcjrr88vmiq38s9g0yc2hu6bs</sha1>
    </revision>
  </page>
  <page>
    <title>Injective metric space</title>
    <ns>0</ns>
    <id>7840768</id>
    <revision>
      <id>740362817</id>
      <parentid>725762496</parentid>
      <timestamp>2016-09-20T15:58:31Z</timestamp>
      <contributor>
        <username>Zeiimer</username>
        <id>21416735</id>
      </contributor>
      <comment>/* Injectivity */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6306">In [[metric geometry]], an '''injective metric space''', or equivalently a '''hyperconvex metric space''', is a [[metric space]] with certain properties generalizing those of the real line and of [[Chebyshev distance|L&lt;sub&gt;∞&lt;/sub&gt; distances]] in higher-dimensional [[vector space]]s. These properties can be defined in two seemingly different ways: hyperconvexity involves the intersection properties of closed balls in the space, while injectivity involves the [[isometry|isometric embeddings]] of the space into larger spaces. However it is a theorem of Aronszajn and Panitchpakdi ([[#{{harvid|Aronszajn|Panitchpakdi|1956}}|1956]]; see e.g. {{harvnb|Chepoi|1997}}) that these two different types of definitions are equivalent.

== Hyperconvexity ==

A metric space ''X'' is said to be '''hyperconvex''' if it is [[convex metric|convex]] and its closed [[Ball (mathematics)|balls]] have the binary [[Helly family|Helly property]]. That is,
#any two points ''x'' and ''y'' can be connected by the [[isometry|isometric image]] of a line segment of length equal to the distance between the points (i.e. ''X'' is a path space), and
#if ''F'' is any family of closed balls
::&lt;math&gt;{\bar B}_r(p) = \{q \mid d(p,q) \le r\}&lt;/math&gt;
:such that each pair of balls in ''F'' meet, then there exists a point ''x'' common to all the balls in ''F''.

Equivalently, if a set of points ''p&lt;sub&gt;i&lt;/sub&gt;'' and radii ''r&lt;sub&gt;i&lt;/sub&gt; &gt; 0'' satisfies ''r&lt;sub&gt;i&lt;/sub&gt;''&amp;nbsp;+&amp;nbsp;''r&lt;sub&gt;j&lt;/sub&gt;'' ≥ ''d''(''p&lt;sub&gt;i&lt;/sub&gt;'',''p&lt;sub&gt;j&lt;/sub&gt;'') for each ''i'' and ''j'', then there is a point ''q'' of the metric space that is within distance ''r&lt;sub&gt;i&lt;/sub&gt;'' of each ''p&lt;sub&gt;i&lt;/sub&gt;''.

== Injectivity ==

A [[retract (metric geometry)|retraction]] of a metric space ''X'' is a function ''&amp;fnof;'' mapping ''X'' to a subspace of itself, such that
# for all ''x'', ''&amp;fnof;''(''&amp;fnof;''(''x''))&amp;nbsp;=&amp;nbsp;''&amp;fnof;''(''x''); that is, ''&amp;fnof;'' is the [[identity function]] on its image (i. e. it is [[idempotent]]), and
# for all ''x'' and ''y'', ''d''(''&amp;fnof;''(''x''),&amp;nbsp;''&amp;fnof;''(''y''))&amp;nbsp;≤&amp;nbsp;''d''(''x'',&amp;nbsp;''y''); that is, ''&amp;fnof;'' is [[nonexpansive mapping|nonexpansive]].
A ''retract'' of a space ''X'' is a subspace of ''X'' that is an image of a retraction.
A metric space &amp;nbsp;''X'' is said to be '''injective''' if, whenever ''X'' is [[isometry|isometric]] to a subspace&amp;nbsp;''Z'' of a space&amp;nbsp;''Y'', that subspace ''Z'' is a retract of&amp;nbsp;''Y''.

== Examples ==

Examples of hyperconvex metric spaces include
* The real line
* Any vector space '''R'''&lt;sup&gt;''d''&lt;/sup&gt; with the [[Lp space|L&lt;sub&gt;∞&lt;/sub&gt; distance]]
* [[taxicab geometry|Manhattan distance]] (''L''&lt;sub&gt;1&lt;/sub&gt;) in the plane (which is equivalent up to rotation and scaling to the ''L''&lt;sub&gt;∞&lt;/sub&gt;), but not in higher dimensions
* The [[tight span]] of a metric space
* Any [[real tree]]
* Aim(''X'') &amp;ndash; see [[Metric space aimed at its subspace]]
Due to the equivalence between hyperconvexity and injectivity, these spaces are all also injective.

== Properties ==

In an injective space, the radius of the [[circumradius|minimum ball]] that contains any set ''S'' is equal to half the [[diameter]] of ''S''. This follows since the balls of radius half the diameter, centered at the points of ''S'', intersect pairwise and therefore by hyperconvexity have a common intersection; a ball of radius half the diameter centered at a point of this common intersection contains all of ''S''. Thus, injective spaces satisfy a particularly strong form of [[Jung's theorem]].

Every injective space is a [[complete space]] {{harv|Aronszajn|Panitchpakdi|1956}}, and every [[metric map]] (or, equivalently, [[short map|nonexpansive mapping, or short map]]) on a bounded injective space has a [[Fixed-point theorem|fixed point]] ({{harvnb|Sine|1979}}; {{harv|Soardi|1979}}). A metric space is injective if and only if it is an [[injective object]] in the [[category (mathematics)|category]] of [[category of metric spaces|metric spaces and metric maps]].  For additional properties of injective spaces see {{harvtxt|Espínola|Khamsi|2001}}.

== References ==
*{{cite journal
 | author1-link = Nachman Aronszajn | last1 = Aronszajn | first1 = N. | last2 = Panitchpakdi | first2 = P.
 | title = Extensions of uniformly continuous transformations and hyperconvex metric spaces
 | mr = 0084762
 | journal = [[Pacific Journal of Mathematics]]
 | volume = 6
 | year = 1956
 | pages = 405–439
 | url = http://projecteuclid.org/Dienst/UI/1.0/Summarize/euclid.pjm/1103043960 | doi=10.2140/pjm.1956.6.405
 | ref = harv}} Correction (1957), ''Pacific J. Math.'' '''7''': 1729, {{MR|0092146}}.
*{{cite journal
 | last = Chepoi | first = Victor
 | title = A ''T&lt;sub&gt;X&lt;/sub&gt;'' approach to some results on cuts and metrics
 | mr = 1479014
 | journal = [[Advances in Applied Mathematics]]
 | volume = 19
 | issue = 4
 | year = 1997
 | pages = 453–470
 | doi = 10.1006/aama.1997.0549
 | ref = harv}}
*{{cite conference
 | last1 = Espínola | first1 = R. | last2 = Khamsi | first2 = M. A.
 | title = Introduction to hyperconvex spaces
 | mr = 1904284
 | booktitle = Handbook of Metric Fixed Point Theory
 | editor = Kirk, W. A. |editor2=Sims B. (Eds.)
 | publisher = Kluwer Academic Publishers
 | location = Dordrecht
 | year = 2001
 | url = http://drkhamsi.com/publication/Es-Kh.pdf
 | ref = harv}}
*{{cite journal
 | last = Isbell | first = J. R. | authorlink = John R. Isbell
 | title = Six theorems about injective metric spaces
 | journal = [[Commentarii Mathematici Helvetici]]
 | mr = 0182949
 | volume = 39
 | year = 1964
 | pages = 65–76
 | doi = 10.1007/BF02566944
 | ref = harv}}
*{{cite journal
 | last = Sine | first = R. C.
 | title = On nonlinear contraction semigroups in sup norm spaces
 | mr = 0548959
 | journal = Nonlinear Analysis
 | volume = 3
 | year = 1979
 | pages = 885–890
 | doi = 10.1016/0362-546X(79)90055-5
 | issue = 6
 | ref = harv}}
*{{cite journal
 | last = Soardi | first = P.
 | title = Existence of fixed points of nonexpansive mappings in certain Banach lattices
 | mr = 0512051
 | journal = [[Proceedings of the American Mathematical Society]]
 | volume = 73
 | year = 1979
 | pages = 25–29
 | doi = 10.2307/2042874
 | issue = 1
 | jstor = 2042874
 | ref = harv}}

[[Category:Metric geometry]]</text>
      <sha1>pkn3alz98ex75m35oxmqxb1fci0t4p6</sha1>
    </revision>
  </page>
  <page>
    <title>Integrability conditions for differential systems</title>
    <ns>0</ns>
    <id>968734</id>
    <revision>
      <id>854178588</id>
      <parentid>846305031</parentid>
      <timestamp>2018-08-09T13:52:25Z</timestamp>
      <contributor>
        <ip>132.72.23.23</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6252">In [[mathematics]], certain systems of [[partial differential equation]]s are usefully formulated, from the point of view of their underlying geometric and algebraic structure, in terms of a system of [[differential form]]s. The idea is to take advantage of the way a differential form ''restricts'' to a [[submanifold]], and the fact that this restriction is compatible with the [[exterior derivative]]. This is one possible approach to certain [[over-determined system]]s, for example, including [[Lax pair|Lax pairs]] of [[Integrable system|integrable systems]]. A '''Pfaffian system''' is specified by [[1-form]]s alone, but the theory includes other types of example of '''differential system'''.

Given a collection of differential 1-forms &lt;math&gt;\textstyle\alpha_i, i=1,2,\dots, k&lt;/math&gt; on an &lt;math&gt;\textstyle n&lt;/math&gt;-dimensional manifold &lt;math&gt;M&lt;/math&gt;,  an '''integral manifold''' is a submanifold whose tangent space at every point &lt;math&gt;\textstyle p\in M&lt;/math&gt; is annihilated by each &lt;math&gt;\textstyle \alpha_i&lt;/math&gt;.

A '''maximal integral manifold''' is a submanifold

:&lt;math&gt;i:N\subset M&lt;/math&gt;

such that the kernel of the restriction map on forms

:&lt;math&gt;i^*:\Omega_p^1(M)\rightarrow \Omega_p^1(N)&lt;/math&gt;

is spanned by the &lt;math&gt;\textstyle \alpha_i&lt;/math&gt; at every point &lt;math&gt;p&lt;/math&gt; of &lt;math&gt;N&lt;/math&gt;.  If in addition the &lt;math&gt;\textstyle \alpha_i&lt;/math&gt; are linearly independent, then &lt;math&gt;N&lt;/math&gt; is (&lt;math&gt;n-k&lt;/math&gt;)-dimensional. Note that &lt;math&gt;\textstyle i:N\subset M&lt;/math&gt; need not be an embedded submanifold.

A Pfaffian system is said to be '''completely integrable''' if &lt;math&gt;M&lt;/math&gt; admits a [[foliation]] by maximal integral manifolds. (Note that the foliation need not be '''regular'''; i.e. the leaves of the foliation might not be embedded submanifolds.)

An '''integrability condition''' is a condition on the &lt;math&gt;\alpha_i&lt;/math&gt; to guarantee that there will be integral submanifolds of sufficiently high dimension.

==Necessary and sufficient conditions==
The necessary and sufficient conditions for '''complete integrability''' of a Pfaffian system are given by the [[Frobenius theorem (differential topology)|Frobenius theorem]].  One version states that if the ideal &lt;math&gt;\mathcal I&lt;/math&gt; algebraically generated by the collection of α&lt;sub&gt;''i''&lt;/sub&gt; inside the ring Ω(''M'') is differentially closed, in other words

:&lt;math&gt;d{\mathcal I}\subset {\mathcal I},&lt;/math&gt;

then the system admits a [[foliation]] by maximal integral manifolds. (The converse is obvious from the definitions.)

==Example of a non-integrable system==
Not every Pfaffian system  is completely integrable in the Frobenius sense. For example, consider the following one-form {{nowrap|on '''R'''&lt;sup&gt;3&lt;/sup&gt; − (0,0,0)}}:

:&lt;math&gt;\theta=x\,dy+y\,dz+z\,dx.&lt;/math&gt;

If ''d''θ were in the ideal generated by θ we would have, by the skewness of the wedge product

:&lt;math&gt;\theta\wedge d\theta=0.&lt;/math&gt;

But a direct calculation gives

:&lt;math&gt;\theta\wedge d\theta=(x+y+z)\,dx\wedge dy\wedge dz&lt;/math&gt;

which is a nonzero multiple of the standard volume form on '''R'''&lt;sup&gt;3&lt;/sup&gt;.  Therefore, there are no two-dimensional leaves, and the system is not completely integrable.

On the other hand, for the curve defined by

:&lt;math&gt; x =t, \quad y= c,  \qquad z = e^{-t/c},  \quad t &gt; 0 &lt;/math&gt;

then θ defined as above is 0, and hence the curve is easily verified to be a solution (i.e. an [[integral curve]]) for the above Pfaffian system for any nonzero constant ''c''.

==Examples of applications==
In [[Riemannian geometry]], we may consider the problem of finding an orthogonal [[coframe]] ''θ''&lt;sup&gt;''i''&lt;/sup&gt;,  i.e., a collection of 1-forms forming a basis of the cotangent space at every point with &lt;math&gt;\langle\theta^i,\theta^j\rangle=\delta^{ij}&lt;/math&gt; which are closed (dθ&lt;sup&gt;''i''&lt;/sup&gt; = 0, ''i''&amp;nbsp;=&amp;nbsp;1,&amp;nbsp;2,&amp;nbsp;...,&amp;nbsp;''n'').  By the [[Poincaré lemma]], the θ&lt;sup&gt;''i''&lt;/sup&gt; locally will have the form d''x&lt;sup&gt;i&lt;/sup&gt;'' for some functions ''x&lt;sup&gt;i&lt;/sup&gt;'' on the manifold, and thus provide an isometry of an open subset of ''M'' with an open subset of '''R'''&lt;sup&gt;''n''&lt;/sup&gt;.  Such a manifold is called '''locally flat.'''

This problem reduces to a question on the [[frame bundle|coframe bundle]] of ''M''.  Suppose we had such a closed coframe

:&lt;math&gt;\Theta=(\theta^1,\dots,\theta^n).&lt;/math&gt;

If we had another coframe &lt;math&gt;\Phi=(\phi^1,\dots,\phi^n)&lt;/math&gt;, then the two coframes would be related by an orthogonal transformation

:&lt;math&gt;\Phi=M\Theta&lt;/math&gt;

If the connection 1-form is ''ω'', then we have

:&lt;math&gt;d\Phi=\omega\wedge\Phi&lt;/math&gt;

On the other hand,
: &lt;math&gt;
\begin{align}
d\Phi &amp; = (dM)\wedge\Theta+M\wedge d\Theta \\
&amp; =(dM)\wedge\Theta \\
&amp; =(dM)M^{-1}\wedge\Phi.
\end{align}
&lt;/math&gt;

But &lt;math&gt;\omega=(dM)M^{-1}&lt;/math&gt; is the [[Maurer–Cartan form]] for the [[orthogonal group]].  Therefore, it obeys the structural equation
&lt;math&gt;d\omega+\omega\wedge\omega=0,&lt;/math&gt; and this is just the [[curvature]] of M: &lt;math&gt;\Omega=d\omega+\omega\wedge\omega=0.&lt;/math&gt;
After an application of the Frobenius theorem, one concludes that a manifold M is locally flat if and only if its curvature vanishes.

==Generalizations==
Many generalizations exist to integrability conditions on differential systems which are not necessarily generated by one-forms.  The most famous of these are the [[Cartan–Kähler theorem]], which only works for [[Real analysis|real analytic]] differential systems, and the [[Cartan–Kuranishi prolongation theorem]].  See ''Further reading'' for details.

==Further reading==
*Bryant, Chern, Gardner, Goldschmidt, Griffiths, ''Exterior Differential Systems'',  Mathematical Sciences Research Institute Publications, Springer-Verlag, {{ISBN|0-387-97411-3}}
*Olver, P., ''Equivalence, Invariants, and Symmetry'', Cambridge, {{ISBN|0-521-47811-1}}
*Ivey, T., Landsberg, J.M., ''Cartan for Beginners: Differential Geometry via Moving Frames and Exterior Differential Systems'', American Mathematical Society, {{ISBN|0-8218-3375-8}}
*Dunajski, M., ''Solitons, Instantons and Twistors'', Oxford University Press, {{ISBN|978-0-19-857063-9}}

[[Category:Partial differential equations]]
[[Category:Differential topology]]
[[Category:Differential systems]]</text>
      <sha1>ovlscciwvzx51gck53tiqg8xsin23xp</sha1>
    </revision>
  </page>
  <page>
    <title>Integrodifference equation</title>
    <ns>0</ns>
    <id>7992036</id>
    <revision>
      <id>762339444</id>
      <parentid>758256931</parentid>
      <timestamp>2017-01-28T04:40:59Z</timestamp>
      <contributor>
        <username>MATThematical</username>
        <id>5146654</id>
      </contributor>
      <minor/>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3593">In [[mathematics]], an '''integrodifference equation''' is a [[recurrence relation]] on a [[function space]], of the following form:

:&lt;math&gt; n_{t+1}(x) = \int_{\Omega} k(x, y)\, f(n_t(y))\, dy,&lt;/math&gt;

where &lt;math&gt;\{n_t\}\,&lt;/math&gt; is a sequence in the function space and &lt;math&gt;\Omega\,&lt;/math&gt; is the domain of those functions. In most applications, for any &lt;math&gt;y\in\Omega\,&lt;/math&gt;,  &lt;math&gt;k(x,y)\,&lt;/math&gt; is a [[probability density function]] on &lt;math&gt;\Omega\,&lt;/math&gt;. Note that in the definition above, &lt;math&gt;n_t&lt;/math&gt; can be vector valued, in which case each element of &lt;math&gt;\{n_t\}&lt;/math&gt; has a scalar valued integrodifference equation associated with it. Integrodifference equations are widely used in [[mathematical biology]], especially [[theoretical ecology]], to model the [[biological dispersal|dispersal]] and growth of populations. In this case, &lt;math&gt;n_t(x)&lt;/math&gt; is the population size or density at location &lt;math&gt;x&lt;/math&gt; at time &lt;math&gt;t&lt;/math&gt;, &lt;math&gt;f(n_t(x))&lt;/math&gt; describes the local population growth at location &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;k(x,y)&lt;/math&gt;, is the probability of moving from point &lt;math&gt;y&lt;/math&gt; to point &lt;math&gt;x&lt;/math&gt;, often referred to as the dispersal kernel. Integrodifference equations are most commonly used to describe [[voltinism|univoltine]] populations, including, but not limited to, many arthropod, and annual plant species. However, multivoltine populations can also be modeled with integrodifference equations,&lt;ref&gt;Kean, John M., and Nigel D. Barlow. 2001. A Spatial Model for the Successful Biological Control of Sitona discoideus by Microctonus aethiopoides. The Journal of Applied Ecology. 38:1:162-169.&lt;/ref&gt; as long as the organism has non-overlapping generations.  In this case, &lt;math&gt;t&lt;/math&gt; is not measured in years, but rather the time increment between broods.

==Convolution kernels and invasion speeds==
In one spatial dimension, the dispersal kernel often depends only on the distance between the source and the destination, and can be 
written as &lt;math&gt;k(x-y)&lt;/math&gt;.  In this case, some natural conditions on f and k imply that there is a well-defined
spreading speed for waves of invasion generated from compact initial conditions.  The wave speed is often calculated
by studying the linearized equation
:&lt;math&gt; n_{t+1} = \int_{-\infty}^{\infty} k(x-y) R n_t(y) dy &lt;/math&gt;
where &lt;math&gt; R = df/dn(n=0)&lt;/math&gt;.
This can be written as the convolution
:&lt;math&gt; n_{t+1} = f'(0) k * n_t &lt;/math&gt;
Using a moment-generating-function transformation
:&lt;math&gt; M(s) = \int_{-\infty}^{\infty} e^{sx} n(x) dx &lt;/math&gt;
it has been shown that the critical wave speed
:&lt;math&gt; c^* = \min_{ w &gt; 0 } \left[\frac{1}{w} \ln \left( R \int_{-\infty}^{\infty} k(s) e^{w s} ds \right) \right] &lt;/math&gt;

Other types of equations used to model [[population dynamics]] through space include [[reaction-diffusion equation|reaction-diffusion]] equations and [[metapopulation]] equations. However, diffusion equations do not as easily allow for the inclusion of explicit dispersal patterns and are only biologically accurate for populations with overlapping generations.&lt;ref&gt;Kot, Mark and William M Schaffer. 1986. Discrete-Time Growth Dispersal Models. ''Mathematical Biosciences''. 80:109-136&lt;/ref&gt; Metapopulation equations are different from integrodifference equations in the fact that they break the population down into discrete patches rather than a continuous landscape.

==References==
{{reflist}}
{{refbegin}} 
{{refend}}

{{DEFAULTSORT:Integrodifference Equation}}
[[Category:Mathematical and theoretical biology]]
[[Category:Recurrence relations]]</text>
      <sha1>2lxh6m69p02otoankmsqn3vg5hjel48</sha1>
    </revision>
  </page>
  <page>
    <title>Ivor Grattan-Guinness</title>
    <ns>0</ns>
    <id>2010784</id>
    <revision>
      <id>830861401</id>
      <parentid>830861192</parentid>
      <timestamp>2018-03-17T09:23:35Z</timestamp>
      <contributor>
        <username>Ontoraul</username>
        <id>3366403</id>
      </contributor>
      <minor/>
      <comment>/* Editions */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15108">{{Use British English|date=May 2012}}
{{Infobox scientist
|name              = Ivor Grattan-Guinness
|image             = Grattan-Guinness 1.jpg
|image_size        = 200px
|caption           = Ivor Grattan-Guinness in 2003.
|birth_date        = {{Birth date|1941|06|23|df=y}}
|birth_place       = [[Bakewell]], England
|death_date        = {{Death date and age|2014|12|12|1941|06|23|df=y}}
|death_place       = England
|residence         = England
|citizenship       = 
|nationality       = British
|ethnicity         = 
|fields            = Mathematician, historian, [[logician]]
|workplaces        = [[Middlesex University]]&lt;br/&gt;[[London School of Economics]]
|alma_mater        = [[Wadham College, Oxford]]&lt;br/&gt;[[London School of Economics]]&lt;br/&gt;[[University of London]]
|doctoral_advisor  =
|academic_advisors =
|doctoral_students = [[Niccolò Guicciardini]]
|notable_students  =
|known_for         = [[History of mathematics]], [[history of logic]]
|influences        =
|influenced        =
|awards            = [[Kenneth O. May Prize|Kenneth O. May Medal]]
|religion          =
|signature         = &lt;!--(filename only)--&gt;
|footnotes         = He shared a birthday with the mathematician [[Alan Turing]], born 29 years earlier.
}}

'''Ivor Owen Grattan-Guinness''' (23 June 1941 – 12 December 2014) was a [[History of mathematics|historian of mathematics]] and [[History of logic|logic]].&lt;ref name="guardian"&gt;{{cite news|title=Ivor Grattan-Guinness obituary: Energetic historian of mathematics and logic|newspaper=[[The Guardian]]|date=31 December 2014|url=https://www.theguardian.com/education/2014/dec/31/ivor-grattan-guinness|first=Tony|last=Grilly}}&lt;/ref&gt;&lt;ref name="the"&gt;{{cite news| title=Obituaries: Ivor Grattan-Guinness, 1941–2014 | newspaper=[[Times Higher Education]] | date=8 January 2015 |  url=http://www.timeshighereducation.co.uk/news/people/obituaries/ivor-grattan-guinness-1941-2014/2017747.article | first=Matthew | last=Reisz }}&lt;/ref&gt;

==Life==
Grattan-Guinness was born in [[Bakewell]], England; his father was a mathematics teacher and educational administrator.&lt;ref name="guardian"/&gt; He gained his [[bachelor degree]] as a Mathematics Scholar at [[Wadham College, Oxford]], and an MSc (Econ) in Mathematical Logic and the Philosophy of Science at the [[London School of Economics]] in 1966.&lt;ref name="guardian"/&gt;&lt;ref name="profile"&gt;{{cite web | url=http://www.tandf.co.uk/journals/pdf/mathematics/Grattan-Guiness.pdf | title=Editor Profile: Professor Ivor Grattan-Guinness | publisher=[[Taylor &amp; Francis]] | date=March 2005 | accessdate=11 January 2012}}&lt;/ref&gt; He gained both the doctorate (PhD) in 1969, and higher doctorate ([[D.Sc.]]) in 1978, in the History of Science at the [[University of London]].  He was [[Emeritus Professor]] of the History of Mathematics and Logic at [[Middlesex University]], and a Visiting Research Associate at the London School of Economics.

He was awarded the [[Kenneth O. May Prize|Kenneth O. May Medal]] for services to the History of Mathematics by the [[International Commission on the History of Mathematics]] (ICHM) on 31 July 2009, at [[Budapest]], on the occasion of the 23rd International Congress for the History of Science.&lt;ref&gt;[http://www.unizar.es/ichm/reports/budapest09.html Report on the Awarding of the Kenneth O. May Prize to Ivor Grattan-Guinness and Rhada Charan Gupta on the Occasion of the 23rd International Congress of History of Science and Technology], Craig Fraser, ICHM, retrieved 2015-02-04.&lt;/ref&gt; In 2010, he was elected an Honorary Member of the [[Bertrand Russell Society]].

Grattan-Guinness spent much of his career at Middlesex University.&lt;ref&gt;{{cite web|url=http://mubs.mdx.ac.uk/Staff/Standard_pages/Ivor2.htm |title=Academic Staff Profile: Prof Ivor Grattan-Guinness |publisher=[[Archive.org]] |work=[[Middlesex University]] |date=1999–2004 |accessdate=11 January 2012 |deadurl=yes |archiveurl=https://web.archive.org/web/20070929090103/http://mubs.mdx.ac.uk/Staff/Standard_pages/Ivor2.htm |archivedate=29 September 2007 }}&lt;/ref&gt; He was a fellow at the [[Institute for Advanced Study]] in [[Princeton, New Jersey]], United States, and a member of the [[International Academy of the History of Science]].&lt;ref&gt;[http://www.aihs-iahs.org/en/node/523 Member profile], IAHS, retrieved 2015-02-04.&lt;/ref&gt;

From 1974 to 1981, Grattan-Guinness was editor of the [[history of science]] journal ''[[Annals of Science]]''.&lt;ref name="profile" /&gt; In 1979 he founded the journal ''[[History and Philosophy of Logic]]'',&lt;ref name="guardian"/&gt; and edited it until 1992. He was an associate editor of ''[[Historia Mathematica]]'' for twenty years from its inception in 1974, and again from 1996.

He also acted as advisory editor to the editions of the writings of [[C.S. Peirce]] and [[Bertrand Russell]], and to several other journals and book series. He was a member of the Executive Committee of the International Commission on the History of Mathematics from 1977 to 1993.

Grattan-Guinness gave over 570 invited lectures to organisations and societies, or to conferences and congresses, in over 20 countries around the world. These lectures include tours undertaken in Australia, New Zealand, Italy, South Africa and Portugal.

From 1986 to 1988, Grattan-Guinness was the President of the [[British Society for the History of Mathematics]], and for 1992 the Vice-President. In 1991, he was elected an effective member of the [[Académie Internationale d'Histoire des Sciences]]. He was the Associate Editor for mathematicians and statisticians for the [[Oxford Dictionary of National Biography]] (2004).

Grattan-Guinness took an interest in the phenomenon of [[coincidence]] and has written on it for the [[Society for Psychical Research]]. He claimed to have a recurrent affinity with one particular number, namely the square of 15 (225), even recounting one occasion when a car was in front of him with the number plate IGG225, i.e. his very initials and that number. He died of [[heart failure]] on 12 December 2014, aged 73, survived by his wife Enid Grattan-Guinness.&lt;ref name="the"/&gt;

==Work==
The work of Grattan-Guinness touched on all historical periods, but he specialised in the development of the calculus and mathematical analysis, and their applications to mechanics and mathematical physics, and in the rise of [[set theory]] and [[mathematical logic]].&lt;ref name="guardian" /&gt; He was especially interested in characterising how past thinkers, far removed from us in time, view their findings differently from the way we see them now (for example, [[Euclid]]). He has emphasised the importance of ignorance as an epistemological notion in this task. He did extensive research with original sources both published and unpublished, thanks to his reading and spoken knowledge of the main European languages.

==Selected publications==

===Books written===
* 1970. ''The Development of the Foundations of Mathematical Analysis from Euler to Riemann''.  [[MIT Press]].&lt;ref&gt;{{cite journal|author=Waterhouse, William C.|authorlink=William C. Waterhouse|title=Review: ''Lebesgue's Theory of Integration'', by Thomas Hawkins; ''A History of Vector Analysis'', by Michael J. Crowe; ''The Development of the Foundations of Mathematical Analysis from Euler to Riemann'', by I. Grattan-Guinness; and ''Die Genesis des abstrakten Gruppenbegriffes'', by Hans Wussing|journal=Bull. Amer. Math. Soc.|year=1972|volume=78|issue=3|pages=385–391|url=http://www.ams.org/journals/bull/1972-78-03/S0002-9904-1972-12909-4/S0002-9904-1972-12909-4.pdf|doi=10.1090/S0002-9904-1972-12909-4}}&lt;/ref&gt;
* 1972. ''Joseph Fourier, 1768–1830'' (In collaboration with J.R. Ravetz). MIT Press.&lt;ref&gt;{{cite journal|author=Gillmor, G. Stewart|title=Review: ''Joseph Fourier, 1768–1830'', by I. Grattan-Guinness|journal=Technology and Culture|date=July 1973|volume=14|issue=3|pages=501–503|doi=10.2307/3102345|jstor=3102345}}&lt;/ref&gt;
* 1977. ''Dear Russell—Dear Jourdain: a Commentary on Russell's Logic, Based on His Correspondence with Philip Jourdain''. [[Gerald Duckworth and Company|Duckworth]].&lt;ref&gt;{{cite journal|author=Sainsbury, R. M.|authorlink=R. M. Sainsbury|title=Review: ''Dear Russell—Dear Jourdain'', by I. Grattan-Guinness|journal=Mind|series=New Series|date=Oct 1979|volume=88|issue=352|pages=604–607|jstor=2253463}}&lt;/ref&gt;
* 1980. ''From the Calculus to Set Theory, 1630–1910: An Introductory History'' (with chapters written by [[Henk J. M. Bos|H. J. M. Bos]]). Duckworth.
* 1982. ''Psychical Research: A Guide to Its History, Principles &amp; Practices - in celebration of 100 years of the Society for Psychical Research'', Aquarian Press, {{ISBN|0-85030-316-8}} .
* 1990. ''Convolutions in French Mathematics, 1800–1840'' in 3 Vols. Birkhauser.
* 1997. ''The Rainbow of Mathematics: A History of the Mathematical Sciences''. [[Fontana Press|Fontana]]. {{ISBN|978-0-00-686179-9}} (pbk). W. W. Norton and Company (1999). {{ISBN|978-0-393-04650-2}} (hbk), {{ISBN|0-393-32030-8}} (pbk).
* 2000. (Reprint) [https://books.google.com/books/about/From_the_Calculus_to_Set_Theory_1630_191.html?id=OLNeNIbD3jUC ''From the Calculus to Set Theory 1630–1910: An Introductory History''] (with chapters written by H. J. M. Bos). [[Princeton University Press]]. {{ISBN|0-691-07082-2}}.
* 2000. ''The Search for Mathematical Roots, 1870–1940: Logics, Set Theories, and the Foundations of Mathematics from Cantor through Russell to Gödel''.  Princeton University Press. {{ISBN|0-691-05858-X}}. Bibliography.&lt;ref&gt;{{cite journal|author=Ewald, William|title=Review: ''The search for mathematical roots, 1870–1940: Logics, set theories, and the foundations of mathematics from Cantor through Russell to Gödel'', by I. Grattan-Guinness|journal=Bull. Amer. Math. Soc. (N.S.)|year=2003|volume=40|issue=1|pages=125–129|url=http://www.ams.org/journals/bull/2003-40-01/S0273-0979-02-00959-X/S0273-0979-02-00959-X.pdf|doi=10.1090/s0273-0979-02-00959-x}}&lt;/ref&gt; (For research on this book he held a [[Leverhulme Fellowship]] from 1995 to 1997.)
* 2009 ''Routes of Learning: Highways, Pathways, and Byways in the History of Mathematics''. [[Johns Hopkins University Press]]. {{ISBN|0-8018-9248-1}}.

===Editions===
* W.H. and G.C. Young, ''The theory of sets of points'', 2nd edition (ed. with R.C.H. Tanner; 1972, New York: Chelsea). [Introduction and appendix.]
* [[E.L. Post]], "The modern paradoxes", ''History and philosophy of logic'', 11 (1990), 85–91.
* Philip E. B. Jourdain, ''Selected essays on the history of set theory and logics (1906–1918)'', (1991, Bologna: CLUEB), xlii + 352 pages. [Introduction and indexes.]
* [[George Boole]], ''Selected manuscripts on logic and its philosophy'' (ed. with G. Bornet, 1997, Basel: Birkhäuser), lxvi + 236 pages.[Part Introduction and editorial material.]
* Grattan-Guinness' ''The Search for Mathematical Roots 1870–1940'' is a sweeping study of the rise of [[mathematical logic]] during that critical period. The central theme of the book is the rise of [[logicism]], thanks to the efforts of [[Frege]], [[Bertrand Russell]], and [[Alfred North Whitehead|Alfred Whitehead]], and its demise due to [[Gödel]] and indifference. Whole chapters are devoted to the emergence of [[algebraic logic]] in the 19th century UK, [[Georg Cantor|Cantor]] and the emergence of [[set theory]], the emergence of mathematical logic in Germany told in a way that downplays Frege's importance, and to [[Peano]] and his followers. There follow four chapters devoted to the ideas of the young Bertrand Russell, the writing of both ''[[The Principles of Mathematics]]''  and ''[[Principia Mathematica]]'', and to the mixed reception the ideas and methods encountered over the period 1910–40. The book touches on the rise of [[model theory]] as well as [[proof theory]], and on the emergence of American research on the [[foundation of mathematics]], especially in the hands of [[E. H. Moore]] and his students, of the postulate theorists, and of [[Willard Van Orman Quine|Quine]]. While Polish logic is often mentioned, it is not covered systematically. Finally, the book is a contribution to the [[history of philosophy]] as well as of mathematics.

===Books edited===
* 2003. ''Companion Encyclopedia of the History and Philosophy of the Mathematical Sciences'', 2 vols.  Johns Hopkins University Press. {{ISBN|0-8018-7396-7}}
* 2005. [https://books.google.com/books/about/Landmark_Writings_in_Western_Mathematics.html?id=UdGBy8iLpocC ''Landmark Writings in Western Mathematics'']. [[Elsevier]].

===Articles===
* 2000. "Christianity and Mathematics:  Kinds of Link and the Rare Occurrences after 1750." ''Physis: Rivista Internazionale di Storia della Scienza XXXVII.'' Nuova Serie. Fasc. 2. 2000: 467-500.
* 2001. "Manifestations of Mathematics in and around the Christianities:  Some Examples and Issues." ''Historia Scientiarum 11-1.'' July 2001: 48-84.
* 2002. [http://www.ams.org/notices/200007/fea-grattan.pdf A Sideways Look at Hilbert's Twenty-Three Problems of 1900], [[Notices of the American Mathematical Society]] 47: 752–57.
* 2008. "Foundations of Mathematics and Logicism," in [[Michel Weber]] and Will Desmond (eds.), [https://www.academia.edu/6359521/Michel_Weber_and_Will_Desmond_eds._Handbook_of_Whiteheadian_Process_Thought_2008 Handbook of Whiteheadian Process Thought], Frankfurt / Lancaster, Ontos Verlag: 97-104. Cf. [[Michel Weber]], « [https://www.academia.edu/2636680/_Ivor_Grattan-Guinness_Algebras_Projective_Geometry_Mathematical_Logic_and_Constructing_the_World._Intersections_in_the_Philosophy_of_Mathematics_of_A.N._Whitehead_2003_ Ivor Grattan-Guinness, "Algebras, Projective Geometry, Mathematical Logic, and Constructing the World. Intersections in the Philosophy of Mathematics of A.N. Whitehead", Historia Mathematica 29, N° 4, 2002, pp. 427-462] », ''Zentralblatt MATH'', European Mathematical Society, Fachinformationszentrum Karlsruhe &amp; Springer-Verlag, 1046.00003.

==References==
{{reflist|colwidth=30em}}

==External links==
{{wikiquote}}
* [http://www.mathscifound.org/activities/professor_ivor_grattan_gunness.asp Encomium] at [[Mathematical Sciences Foundation]]
* {{AcademicSearch|18676398}}
* {{fr}} [http://bibnum.hypotheses.org/671 Hommage à I. Grattan-Guinness], December 2014.
* {{MathGenealogy|id=28330|name=Ivor Grattan-Guinness}}

{{Use dmy dates|date=May 2012}}
{{Kenneth O. May Prize laureates}}
{{Authority control}}

{{DEFAULTSORT:Grattan-Guinness, Ivor}}
[[Category:1941 births]]
[[Category:2014 deaths]]
[[Category:People from Bakewell]]
[[Category:Alumni of Wadham College, Oxford]]
[[Category:Alumni of the London School of Economics]]
[[Category:Alumni of the University of London]]
[[Category:Academics of Middlesex University]]
[[Category:Academics of the London School of Economics]]
[[Category:Institute for Advanced Study visiting scholars]]
[[Category:Parapsychologists]]
[[Category:English mathematicians]]
[[Category:English logicians]]
[[Category:English historians]]
[[Category:English philosophers]]
[[Category:Historians of mathematics]]
[[Category:History of logic]]
[[Category:Academic journal editors]]</text>
      <sha1>3iqsnwtxtt72wgxxwvpl7axdip47kxf</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Algebra</title>
    <ns>0</ns>
    <id>14838867</id>
    <revision>
      <id>790527738</id>
      <parentid>692721503</parentid>
      <timestamp>2017-07-14T09:30:25Z</timestamp>
      <contributor>
        <username>Randy Kryn</username>
        <id>4796325</id>
      </contributor>
      <comment>italicize title</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1219">{{italic title}}
{{redirect|J Algebra|the mathematical concept|j-algebra}}

'''''Journal of Algebra''''' (ISSN 0021-8693) is an international mathematical research journal in [[abstract algebra|algebra]]. An imprint of [[Academic Press]], it is published by [[Elsevier]]. ''Journal of Algebra'' was founded by [[Graham Higman]], who was its editor from 1964 to 1984. From 1985 until 2000, [[Walter Feit]] served as its editor-in-chief.

In 2004, ''Journal of Algebra'' announced (vol. 276, no. 1 and 2) the creation of a new section on computational algebra, with a separate editorial board. The first issue completely devoted to computational algebra was vol. 292, no. 1 (October 2005).

The Editor-in-Chief of the ''Journal of Algebra'' is [[Michel Broué]], [[Université Paris Diderot]], and Gerhard Hiß, Rheinisch-Westfälische Technische Hochschule Aachen ([[RWTH]]) is Editor of the computational algebra section. 

==See also==

*[[Susan Montgomery]], an editor of the journal

== External links ==

* [http://www.sciencedirect.com/science/journal/00218693 ''Journal of Algebra'' at ScienceDirect] 

[[Category:Mathematics journals]]
[[Category:Publications established in 1964]]


{{mathematics-journal-stub}}</text>
      <sha1>mglisddxg8l1gza6gd1cabk8jgudrr0</sha1>
    </revision>
  </page>
  <page>
    <title>Lexis diagram</title>
    <ns>0</ns>
    <id>23067360</id>
    <revision>
      <id>728404395</id>
      <parentid>727556461</parentid>
      <timestamp>2016-07-05T06:19:46Z</timestamp>
      <contributor>
        <username>Jochen Burghardt</username>
        <id>17350134</id>
      </contributor>
      <comment>/* top */ suggest image (French axes captions)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2434">[[File:DL CVds 11 V02.png|thumb|Lexis diagram showing the cohort of 2003-born persons in green, and the year 2005 in red]]
In [[demography]] (the branch of [[statistics]] that deals with the study of populations) a '''Lexis diagram''' (named after economist and social scientist [[Wilhelm Lexis]]) is a two dimensional diagram that is used to represent events (such as births or deaths) that occur to individuals belonging to different [[cohort (statistics)|cohort]]s.  Calendar time is usually represented on the horizontal axis, while age is represented on the vertical axis. In some textbooks the y-axis is plotted backwards, with age 0 at the top of the page and increasing downwards. However, other arrangements of the axes are also seen. As an example the death of an individual in 2009 at age 80 is represented by the point (2009,80); the cohort of all persons born in 1929 is represented by a diagonal line starting at (1929,0) and continuing through (1930,1) and so on.

==References==
* Feeney, Griffith. ''Lexis Diagram''. In: Paul Demeny and Geoffrey McNicoll (eds.) ''Encyclopedia of Population, Volume 2'', Macmillan Reference USA, 2003, 586-588.
* N. Keyfitz: ''Introduction to the mathematics of population'', Addison-Wesley, 1968, page 10
* [[United Nations Statistics Division]] 2004 Lexis Diagrams. Annex to [http://unstats.un.org/unsd/pubs/gesgrid.asp?id=325 Handbook on the Collection of Fertility and Mortality Data], 90-101. Statistics and Statistical Methods Publications, Series F, No. 92. Available in [[Arabic]], [[Chinese language|Chinese]], English, [[French language|French]], [[Russian language|Russian]] and [[Spanish language|Spanish]]. New York: United Nations, 2004.

== External links ==
{{commons category|Lexis diagrams}}
*{{Cite web
   | url         = http://icampus.uclouvain.be/courses/LEXIS/document/index.htm
   | title       = Introduction to Lexis diagram (in French).
   | année       = 
   | editor      =  Démographie sur le web
   | work        = 
   | access-date = 
}}
*{{Cite journal
   | url         = http://www.demographic-research.org/Volumes/Vol4/3/4-3.pdf
   | title       = The Lexis diagram, a misnomer 
   | author      = Vandeschrick, Christophe
   | year        = 2001
   |journal=Demographic Research |volume=4 |pp=97-124
   | access-date = 
}}


[[Category:Actuarial science]]
[[Category:Demography]]
[[Category:Statistical charts and diagrams]]


{{statistics-stub}}</text>
      <sha1>hpvfabq8orihsvj0yuttx92a2mcu5b2</sha1>
    </revision>
  </page>
  <page>
    <title>Line-intercept sampling</title>
    <ns>0</ns>
    <id>17076220</id>
    <revision>
      <id>799965461</id>
      <parentid>577578792</parentid>
      <timestamp>2017-09-10T21:45:26Z</timestamp>
      <contributor>
        <username>ImportanceDirection</username>
        <id>31559391</id>
      </contributor>
      <comment>Add disambiguation</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1217">{{About|the sampling technique used in biological studies|the structural reliability analysis method|Line Sampling}}

[[Image:LiTrSa42008Geelhoed.svg|thumb|right|Click to see animation of line-intercept sampling.]]
In [[statistics]], '''line-intercept sampling (LIS)''' is a method of sampling elements in a region whereby an element is sampled if a chosen line segment, called a “[[transect]]”, intersects the element.&lt;ref name="Sarndal"&gt;Kaiser, L, 1983. Unbiased Estimation in Line-Intercept Sampling, Biometrics 39. pp 965&amp;ndash;976.&lt;/ref&gt; 

Line intercept sampling has proven to be a reliable, versatile, and easy to implement method to analyze an area containing various objects of interest.&lt;ref name="Buckland"&gt;Buckland, S.T. Introduction to distance sampling: estimating abundance of biological populations, New York, Oxford University Press; 2001.&lt;/ref&gt; It has recently also been applied to estimating variances during particulate material sampling.&lt;ref&gt;http://www.saimm.co.za/Journal/v110n06p323.pdf&lt;/ref&gt;

== References ==
{{Reflist}}

== See also ==

* [[Sampling (statistics)]]

[[Category:Sampling techniques]]
[[Category:Environmental statistics]]


{{stat-stub}}

[[sl:Metoda linijskega transekta]]</text>
      <sha1>dwkpg695r17j3f8quge51mzvevxcq3z</sha1>
    </revision>
  </page>
  <page>
    <title>List of inequalities</title>
    <ns>0</ns>
    <id>601070</id>
    <revision>
      <id>864181973</id>
      <parentid>860940293</parentid>
      <timestamp>2018-10-15T16:45:10Z</timestamp>
      <contributor>
        <username>Michael Hardy</username>
        <id>4626</id>
      </contributor>
      <comment>[[Bendixson's inequality]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8547">This page lists Wikipedia articles about named mathematical [[inequality (mathematics)|inequalities]].

== Inequalities in pure mathematics ==

===[[Mathematical analysis|Analysis]]===
* [[Agmon's inequality]]
* [[Askey–Gasper inequality]]
* [[Babenko–Beckner inequality]]
* [[Bernoulli's inequality]]
* [[Bernstein's inequality (mathematical analysis)]]
* [[Bessel's inequality]]
* [[Bihari–LaSalle inequality]]
* [[Littlewood's inequality#Bohnenblust–Hille_inequality|Bohnenblust–Hille inequality]]
* [[Borell–Brascamp–Lieb inequality]]
* [[Brezis–Gallouet inequality]]
* [[Carleman's inequality]]
* [[Chebyshev–Markov–Stieltjes inequalities]]
* [[Chebyshev's sum inequality]]
* [[Clarkson's inequalities]]
* [[Eilenberg's inequality]]
* [[Fekete–Szegő inequality]]
* [[Fenchel's inequality]]
* [[Friedrichs's inequality]]
* [[Gagliardo–Nirenberg interpolation inequality]]
* [[Gårding's inequality]]
* [[Grothendieck inequality]]
* [[Grunsky's theorem|Grunsky's inequalities]]
* [[Hanner's inequalities]]
* [[Hardy's inequality]]
* [[Hardy–Littlewood inequality]]
* [[Hardy–Littlewood–Sobolev inequality]]
* [[Harnack's inequality]]
* [[Hausdorff–Young inequality]]
* [[Hermite–Hadamard inequality]]
* [[Hilbert's inequality]]
* [[Hölder's inequality]]
* [[Jackson's inequality]]
* [[Jensen's inequality]]
* [[Khabibullin’s conjecture on integral inequalities]]
* [[Kantorovich inequality]]
* [[Karamata's inequality]]
* [[Korn's inequality]]
* [[Ladyzhenskaya's inequality]]
* [[Landau–Kolmogorov inequality]]
* [[Lebedev–Milin inequality]]
* [[Lieb–Thirring inequality]]
* [[Littlewood's 4/3 inequality]]
* [[Markov brothers' inequality]]
* [[Mashreghi–Ransford inequality]]
* [[Max–min inequality]]
* [[Minkowski's inequality]]
* [[Poincaré inequality]]
* [[Popoviciu's inequality]]
* [[Prékopa–Leindler inequality]]
* [[Rayleigh–Faber–Krahn inequality]]
* [[Remez inequality]]
* [[Riesz rearrangement inequality]]
* [[Schur test]]
* [[Shapiro inequality]]
* [[Sobolev inequality]]
* [[Steffensen's inequality]]
* [[Szegő inequality]]
* [[Three spheres inequality]]
* [[Trace inequalities]]
* [[Trudinger's theorem]]
* [[Turán's inequalities]]
* [[Von Neumann's inequality]]
* [[Wirtinger's inequality for functions]]
* [[Young's convolution inequality]]
* [[Young's inequality for products]]

====Inequalities relating to [[mean]]s====
* [[Hardy–Littlewood maximal inequality]]
* [[Inequality of arithmetic and geometric means]]
* [[Ky Fan inequality]]
* [[Levinson's inequality]]
* [[Maclaurin's inequality]]
* [[Mahler's inequality]]
* [[Muirhead's inequality]]
* [[Newton's inequalities]]
* [[Stein–Strömberg theorem]]

===[[Combinatorics]]===
* [[Binomial coefficient#Bounds and asymptotic formulas|Binomial coefficient bounds]]
* [[Factorial#Rate of growth and approximations for large n|Factorial bounds]]
* [[Fishburn–Shepp inequality]]
* [[Fisher's inequality]]
* [[Ingleton's inequality]]
* [[Lubell–Yamamoto–Meshalkin inequality]]
* [[Nesbitt's inequality]]
* [[Rearrangement inequality]]
* [[Schur's inequality]]
* [[Shapiro inequality]]
* [[Stirling's approximation#Speed of convergence and error estimates|Stirling's formula (bounds)]]

===[[Differential equation]]s===
* [[Grönwall's inequality]]

===[[Geometry]]===
{{See also|List of triangle inequalities}}

* [[Alexandrov–Fenchel inequality]]
* [[Aristarchus's inequality]]
* [[Barrow's inequality]]
* [[Berger–Kazdan comparison theorem]]
* [[Blaschke–Santaló inequality]]
* [[Bishop–Gromov inequality]]
* [[Bogomolov–Miyaoka–Yau inequality]]
* [[Bonnesen's inequality]]
* [[Brascamp–Lieb inequality]]
* [[Brunn–Minkowski inequality]]
* [[Castelnuovo–Severi inequality]]
* [[Cheng's eigenvalue comparison theorem]]
* [[Clifford's theorem on special divisors]]
* [[Cohn-Vossen's inequality]]
* [[Erdős–Mordell inequality]]
* [[Euler's theorem in geometry]]
* [[Gromov's inequality for complex projective space]]
* [[Gromov's systolic inequality for essential manifolds]]
* [[Hadamard's inequality]]
* [[Hadwiger–Finsler inequality]]
* [[Hinge theorem]]
* [[Hitchin–Thorpe inequality]]
* [[Isoperimetry|Isoperimetric inequality]]
* [[Jordan's inequality]]
* [[Jung's theorem]]
* [[Loewner's torus inequality]]
* [[Łojasiewicz inequality]]
* [[Loomis–Whitney inequality]]
* [[Sylvester–Gallai theorem#Melchior's inequality|Melchior's inequality]]
* [[Milman's reverse Brunn–Minkowski inequality]]
* [[Minkowski's first inequality for convex bodies]]
* [[Myers's theorem]]
* [[Noether inequality]]
* [[Ono's inequality]]
* [[Pedoe's inequality]]
* [[Ptolemy's inequality]]
* [[Pu's inequality]]
* [[Riemannian Penrose inequality]]
* [[Toponogov's theorem]]
* [[Triangle inequality]]
* [[Weitzenböck's inequality]]
* [[Wirtinger inequality (2-forms)]]

===[[Information theory]]===
* [[Inequalities in information theory]]
* [[Kraft's inequality]]
* [[Log sum inequality]]
* [[Welch bounds]]

===[[Algebra]]===

* [[Abhyankar's inequality]]
* [[Pisier–Ringrose inequality]]

==== [[Linear algebra]] ====

* [[Abel's inequality]]
* [[Bendixson's inequality]]
* [[Bregman–Minc inequality]]
* [[Cauchy–Schwarz inequality]]
* [[Golden–Thompson inequality]]
* [[Hadamard's inequality]]
* [[Linear matrix inequality]]
* [[Peetre's inequality]]
* [[Sylvester's rank inequality]]
* [[Triangle inequality]]
* [[von Neumann's trace inequality]]
* [[Weyl's inequality]]

===[[Number theory]]===
* [[Bonse's inequality]]
* [[Large sieve inequality]]
* [[Pólya–Vinogradov inequality]]
* [[Turán–Kubilius inequality]]
* [[Weyl's inequality]]

===[[Probability theory]] and [[statistics]] ===
* [[Azuma's inequality]]
* [[Bennett's inequality]], an upper bound on the probability that the sum of independent random variables deviates from its expected value by more than any specified amount
* [[Bhatia–Davis inequality]], an upper bound on the variance of any bounded probability distribution
* [[Bernstein inequalities (probability theory)]]
* [[Boole's inequality]]
* [[Borell–TIS inequality]]
* [[Burkholder's inequality]]
* [[Burkholder–Davis–Gundy inequalities]]
* [[Cantelli's inequality]]
* [[Chebyshev's inequality]]
* [[Chernoff's inequality]]
* [[Chung–Erdős inequality]]
* [[Concentration inequality]]
* [[Cramér–Rao inequality]]
* [[Doob's martingale inequality]]
* [[Dvoretzky–Kiefer–Wolfowitz inequality]]
* [[Eaton's inequality]], a bound on the largest absolute value of a linear combination of bounded random variables
* [[Emery's inequality]]
* [[Entropy power inequality]]
* [[Etemadi's inequality]]
* [[Fannes–Audenaert inequality]]
* [[Fano's inequality]]
* [[Fefferman's inequality]]
* [[Fréchet inequalities]]
* [[Gauss's inequality]]
* [[Gauss–Markov theorem]], the statement that the least-squares estimators in certain linear models are the best linear unbiased estimators
* [[Gaussian correlation inequality]]
* [[Gaussian isoperimetric inequality]]
* [[Gibbs's inequality]]
* [[Hoeffding's inequality]]
* [[Hoeffding's lemma]]
* [[Jensen's inequality]]
* [[Khintchine inequality]]
* [[Kolmogorov's inequality]]
* [[Kunita–Watanabe inequality]]
* [[Le Cam's theorem]]
* [[Marcinkiewicz–Zygmund inequality]]
* [[Markov's inequality]]
* [[McDiarmid's inequality]]
* [[Paley–Zygmund inequality]]
* [[Pinsker's inequality]]
* [[Popoviciu's inequality on variances]]
* [[Rao–Blackwell theorem]]
* [[Ross's conjecture]], a lower bound on the average waiting time in certain queues
* [[Samuelson's inequality]]
* [[Shearer's inequality]]
* [[Talagrand's concentration inequality]]
* [[Vitale's random Brunn–Minkowski inequality]]
* [[Vysochanskiï–Petunin inequality]]

===[[Topology]]===
* [[Berger's inequality for Einstein manifolds]]

== Inequalities particular to physics ==
* [[Ahlswede–Daykin inequality]]
* Bell's inequality &amp;ndash; see [[Bell's theorem]]
** [[Bell's original inequality]]
* [[CHSH inequality]]
* [[Clausius–Duhem inequality]]
* [[Correlation inequality]] – any of several inequalities
* [[FKG inequality]]
* [[Ginibre inequality]]
* [[Griffiths inequality]]
* [[Heisenberg's inequality]]
* [[Holley inequality]]
* [[Leggett–Garg inequality]]
* [[Riemannian Penrose inequality]]
* [[Rushbrooke inequality]]
* [[Sakurai's Bell inequality]]
* [[Tsirelson's inequality]]
* [[Wigner–d'Espagnat inequality]]

== See also ==

* [[Comparison theorem]]
* [[List of mathematical identities|List of identities]]

[[Category:Inequalities| ]]
[[Category:Mathematics-related lists|Inequalities]]</text>
      <sha1>a7ubm7v4yyk91crcd1sh4jn723do1e9</sha1>
    </revision>
  </page>
  <page>
    <title>List of topology topics</title>
    <ns>0</ns>
    <id>3039388</id>
    <revision>
      <id>632601962</id>
      <parentid>611270160</parentid>
      <timestamp>2014-11-05T20:36:23Z</timestamp>
      <contributor>
        <username>John of Reading</username>
        <id>11308236</id>
      </contributor>
      <minor/>
      <comment>/* Miscellaneous */Typo/[[WP:AWB/GF|general]] fixing, replaced: Catergory → Category using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1753">This is a list of [[topology]] topics, by Wikipedia page. See also:

*[[topology glossary]]
*[[List of general topology topics]]
*[[List of geometric topology topics]]
*[[List of algebraic topology topics]]
*[[Topological property|List of topological invariants (topological properties)]]
*[[List of publications in mathematics#Topology|Publications in topology]]

==Topology and physics==

*[[Quantum topology]]
*[[Topological defect]]
*[[Topological entropy in physics]]
*[[Topological order]]
*[[Topological quantum field theory]]
*[[Topological quantum number]]
*[[Topological string theory]]
*[[Topology of the universe]]

==Topology and dynamical systems==

*[[Milnor–Thurston kneading theory]]
*[[Topological conjugacy]]
*[[Topological dynamics]]
*[[Topological entropy]]
*[[Topological mixing]]

==Topology and computing==

* [[Computational topology]]
* [[Digital topology]]
* [[Network topology]]
* [[Topological computing]]
* [[Topological Quantum Computing]]
* [[Topological quantum computer]]

== Miscellaneous ==

*[[Combinatorial topology]]
*[[Counterexamples in Topology]]
*[[Differential topology]]
*[[Geometric topology]]
*[[Geospatial topology]]
*[[Grothendieck topology]]
*[[Link (knot theory)]]
*[[Listing number]]
*[[Mereotopology]]
*[[Noncommutative topology]]
*[[Pointless topology]]
*[[Set-theoretic topology]] [[Talk:Set-theoretic topology| ]]
*[[Topological combinatorics]]
*[[Topological data analysis]]
*[[Topological degree theory]]
*[[Topological game]]
*[[Topological graph theory]]
*[[Topological K-theory]]
*[[Topological modular forms]]
*[[Topological skeleton]]
*[[Topology optimization]]
*[[Water, gas, and electricity]]

{{Topology}}

[[Category:Topology| ]]
[[Category:Mathematics-related lists|Topology topics]]</text>
      <sha1>0ay82mh1o6ot3tsdwgd59x53mceumb4</sha1>
    </revision>
  </page>
  <page>
    <title>Math Curse</title>
    <ns>0</ns>
    <id>9514440</id>
    <revision>
      <id>856276428</id>
      <parentid>856276029</parentid>
      <timestamp>2018-08-24T02:44:22Z</timestamp>
      <contributor>
        <username>Donner60</username>
        <id>12744454</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/2600:100E:B147:A179:463:3107:8943:3F1C|2600:100E:B147:A179:463:3107:8943:3F1C]] ([[User talk:2600:100E:B147:A179:463:3107:8943:3F1C|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3981">{{Infobox book
  | name           = Math Curse
  | title_orig     =
  | translator     =Jake Scott
  | image          = mathcurse.jpg
  | author         = [[Jon Scieszka]]&lt;br&gt;[[Lane Smith (illustrator)|Lane Smith]]
  | cover_artist   = Lane Smith
  | country        = United States
  | language       = English
  | series         =
  | subject        = [[Mathematics]]
  | genre          = [[Children's book]]s&lt;br&gt;[[Picture book]]s
  | publisher      = [[Viking Press]]
  | release_date   = 1995
  | media_type     =
  | pages          = 32
  | size_weight    =
  | isbn           = 978-0-670-86194-1
  | dewey          = [E] 20
  | congress       = PZ7.S41267 Mat 1995
  | oclc           = 32589625
  | preceded_by    =
  | followed_by    = [[Science Verse]]
}}
'''''Math Curse''''' is a children's [[picture book]] written by [[Jon Scieszka]] and [[illustrator|illustrated]] by [[Lane Smith (illustrator)|Lane Smith]], suitable for ages six through ninety-nine years.  Published in 1995 through [[Viking Press]], the book tells the story of a student who is cursed by the way [[mathematics]] works in everyday life.

==Plot summary==

The nameless student, begins with a seemingly innocent statement by her math teacher- "you know, almost everything in life can be considered a math problem." The next morning, the hero finds herself thinking of the time she needs to get up along the lines of [[algebra]]. Next comes the mathematical school of [[probability]], followed by [[charts]] and [[statistics]]. As the narrator slowly turns into a "math zombie", everything in her life is transformed into a problem. A class treat of cupcakes becomes a study in [[fractions]], while a trip to the store turns into a problem of [[money]]. Finally, she is left painstakingly calculating how many minutes of "math madness" will be in her life now that she is a "mathematical lunatic." Her sister asks her what her problem is, and she responds, "365 days x 24 hours x 60 minutes." Finally, she collapses on her bed, and dreams that she is trapped in a [[blackboard]]-room covered in math problems. Armed with only a piece of chalk, she must escape and she manages to do just that by breaking the chalk in half, because "two halves make a whole." She escapes through this "whole", and awakens the next morning with the ability to solve any problem. Her curse is broken...until the next day, when her science teacher mentions that in life, everything can be viewed as a science experiment.

==Math Problems==

The book is full of actual math problems (and some rather unrelated questions, such as "[[Rorschach inkblot test|What does this inkblot look like]]?"). Readers can try to solve the problems and check their answers, which are located on the back cover of the book.

==Adapted for the stage==

The book was also adapted for the stage by Heath Corson and Kathleen Collins in 1997.  It was first performed at the A Red Orchid Theatre in Chicago, Illinois, in 1997, with subsequent productions at other locations. Its West Coast premiere was in 2003 at the Powerhouse Theatre of [[Santa Monica, California]].  Directed by Collins, the cast included Kerry Lacy, Thomas Colby, Will Moran, Andrew David James, and Emily Marver.  The play met with warm reviews and succeeded with its audiences as well as local school children.

==Awards==

The book was critically acclaimed, winning a number of awards and accolades, including [[Maine]]'s Student Favorite Book Award, the [[Texas]] Bluebonnet Award, and [[New Hampshire]]'s The Great Stone Face Book Award.[https://archive.is/20000818235058/http://www.txla.org/pubs/tlacast/tlac0297.html][https://web.archive.org/web/20070101003655/http://www-personal.ksu.edu/~aec8484/biography.html]

[[Category:American picture books]]
[[Category:1995 children's books]]
[[Category:Mathematics books]]
[[Category:Children's fiction books]]
[[Category:Mathematics fiction books]]
[[Category:Books featured on Reading Rainbow]]

{{child-picture-book-stub}}</text>
      <sha1>p01m6lad48u5kbx482jbctdnkmvfm5u</sha1>
    </revision>
  </page>
  <page>
    <title>Mathematics, Form and Function</title>
    <ns>0</ns>
    <id>13558237</id>
    <revision>
      <id>865822157</id>
      <parentid>860317862</parentid>
      <timestamp>2018-10-26T11:43:40Z</timestamp>
      <contributor>
        <username>Pirhayati</username>
        <id>16750284</id>
      </contributor>
      <comment>removed [[Category:Philosophy of mathematics]]; added [[Category:Philosophy of mathematics literature]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5774">{{italic title}}
'''''Mathematics, Form and Function''''' is a survey of the whole of [[mathematics]], including its origins and deep structure, by the American mathematician [[Saunders Mac Lane]].

== Mathematics and human activities==
Throughout his book, and especially in chapter I.11, Mac Lane informally discusses how mathematics is grounded in more ordinary concrete and abstract human activities. The following table is adapted from one given on p.&amp;nbsp;35 of Mac Lane (1986). The rows are very roughly ordered from most to least fundamental. For a bullet list that can be compared and contrasted with this table, see section 3 of ''[[Where Mathematics Comes From]]''.

{| class="wikitable" style="text-align: center;"
|-
|'''Human Activity'''
|'''Related Mathematical Idea'''
|'''Mathematical Technique'''
|-
|Collecting
|Object Collection
|[[Set (mathematics)|Set]]; [[class (set theory)|class]]; [[multiset]]; [[list (computing)|list]]; [[indexed family|family]]
|-
|Connecting
|[[causality|Cause and effect]]
|[[ordered pair]]; [[relation (mathematics)|relation]]; [[function (set theory)|function]]; [[operation (mathematics)|operation]] 
|-
| "
|[[Proximity space|Proximity]]; [[connectedness|connection]]
|[[Topological space]]; [[mereotopology]]
|-
|Following
|Successive actions
|[[Function composition]]; [[transformation group]]
|-
|Comparing
|Enumeration
|[[Bijection]]; [[cardinal number]]; [[order theory|order]]
|-
|Timing
|Before &amp; After
|[[Linear order]]
|-
|[[Counting]]
|[[Successor ordinal|Successor]]
|[[Successor function]]; [[ordinal number]]
|-
|Computing
|[[operation (mathematics)|Operations]] on [[number]]s
|[[Peano axioms|Addition, multiplication recursively defined]]; [[abelian group]]; [[ring (mathematics)|rings]]
|-
|Looking at objects
|[[Symmetry]]
|[[Symmetry group]]; [[invariant (mathematics)|invariance]]; [[isometries]]
|-
|Building; shaping
|[[Shape]]; [[point (geometry)|point]]
|[[Set (mathematics)|Sets]] of [[point (geometry)|points]]; [[geometry]]; [[pi]]
|-
|Rearranging
|[[Permutation]]
|[[Bijection]]; [[permutation group]]
|-
|Selecting; distinguishing
|[[mereology|Parthood]]
|[[Subset]]; [[order theory|order]]; [[lattice (order)|lattice theory]]; [[mereology]]
|-
|[[argumentation|Arguing]]
|[[Mathematical proof|Proof]]
|[[First-order logic]]
|-
|[[measurement|Measuring]]
|[[Distance]]; extent
|[[Rational number]]; [[metric space]]
|-
|Endless repetition
|[[Infinity]];&lt;ref&gt;Also see the "Basic [[Metaphor]] of [[Infinity]]" in Lakoff and Núñez (2000), chpt. 8.&lt;/ref&gt; [[Recursion]]
|[[Recursive set]]; [[Infinite set]]
|-
|Estimating
|[[Approximation]]
|[[Real number]]; [[real closed field|real field]]
|-
|Moving through [[space]] &amp; [[time]]:
|[[curvature]]
|[[calculus]]; [[differential geometry]]
|-
| --Without cycling
|Change
|[[Real analysis]]; [[transformation group]] 
|-
| --With cycling
|Repetition
||[[pi]]; [[trigonometry]]; [[complex number]]; [[complex analysis]]
|-
| --Both
| 
|[[Differential equations]]; [[mathematical physics]]
|-
|Motion through time alone
|Growth &amp; decay 
|[[e (mathematical constant)|e]]; [[exponential function]]; [[natural logarithms]]; 
|-
|Altering shapes
|[[deformation (engineering)|Deformation]]
|[[Differential geometry]]; [[topology]]
|-
|Observing patterns
|[[Abstraction]]
|[[Axiomatic set theory]]; [[universal algebra]]; [[category theory]]; [[morphism]]
|-
|Seeking to do better
|[[Optimization (mathematics)|Optimization]]
|[[Operations research]]; [[optimal control theory]]; [[dynamic programming]]
|-
|Choosing; [[gambling]]
|[[Probability|Chance]]
|[[Probability theory]]; [[mathematical statistics]]; [[Measure (mathematics)|measure]]
|}

Also see the related diagrams appearing on the following pages of Mac Lane (1986): 149, 184, 306, 408, 416, 422-28.

Mac Lane (1986) cites a related monograph by [[Lars Gårding]] (1977).

== Mac Lane's relevance to the philosophy of mathematics ==
Mac Lane cofounded [[category theory]] with [[Samuel Eilenberg]], which enables a [[unifying theories in mathematics|unified treatment]] of mathematical structures and of the relations among them, at the cost of [[abstract nonsense|breaking away from their cognitive grounding]].  Nevertheless, his views&amp;mdash;however informal&amp;mdash;are a valuable contribution to the [[philosophy of mathematics|philosophy]] and [[anthropology]] of mathematics.&lt;ref&gt;On the anthropological grounding of mathematics, see White (1947) and Hersh (1997).&lt;/ref&gt; His views anticipate, in some respects, the more detailed account of the [[cognitive science of mathematics|cognitive basis of mathematics]] given by [[George Lakoff]] and [[Rafael E. Núñez]] in their ''[[Where Mathematics Comes From]]''. Lakoff and Núñez argue that mathematics emerges via [[conceptual metaphor]]s grounded in the [[embodied philosophy|human body]], its motion through [[space]] and [[time]], and in human sense perceptions.

== See also ==
* [[1986 in philosophy]]

==Notes==
&lt;references /&gt;


==References==
*Gårding, Lars, 1977. ''Encounter with Mathematics''. Springer-Verlag.
* [[Reuben Hersh]], 1997. ''What Is Mathematics, Really?'' Oxford Univ. Press.
*[[George Lakoff]] and [[Rafael E. Núñez]], 2000. ''[[Where Mathematics Comes From]]''. Basic Books.
* {{cite book |first=Saunders |last=Mac Lane |title=Mathematics, Form and Function |year=1986 |publisher=Springer-Verlag |isbn=0-387-96217-4}}
* [[Leslie White]], 1947, "The Locus of Mathematical Reality: An Anthropological Footnote," ''Philosophy of Science 14'': 289-303. Reprinted in Hersh, R., ed., 2006. ''18 Unconventional Essays on the Nature of Mathematics''. Springer: 304–19.

[[Category:1986 books]]
[[Category:Mathematics books]]
[[Category:Philosophy of mathematics literature]]
[[Category:Cognitive science literature]]</text>
      <sha1>ce9p83uutdcz55p097djsheay1i1r0q</sha1>
    </revision>
  </page>
  <page>
    <title>N-group (category theory)</title>
    <ns>0</ns>
    <id>21368075</id>
    <revision>
      <id>822423734</id>
      <parentid>672485219</parentid>
      <timestamp>2018-01-26T08:39:34Z</timestamp>
      <contributor>
        <username>KolbertBot</username>
        <id>31691822</id>
      </contributor>
      <minor/>
      <comment>Bot: [[User:KolbertBot|HTTP→HTTPS]] (v481)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1668">{{DISPLAYTITLE:''n''-group (category theory)}}
{{distinguish|p-group}}
In [[mathematics]], an '''''n''-group''', or '''''n''-dimensional higher group''', is a special kind of [[n-category|''n''-category]] that generalises the concept of [[group (math)|group]] to [[higher-dimensional algebra]].  Here, ''n'' may be any [[natural number]] or [[infinity]]. The thesis of [[Alexander Grothendieck]]'s student [[Hoàng Xuân Sính]] was an in-depth study of [[2-group]]s under the monniker 'gr-category'.

The general definition of ''n''-group is a matter of ongoing research.  However, it is expected that every [[topological space]] will have a ''homotopy ''n''-group'' at every point, which will encapsulate the [[Postnikov tower]] of the space up to the [[homotopy group]] π&lt;sub&gt;n&lt;/sub&gt;, or the entire Postnikov tower for ''n''&amp;nbsp;= ∞.

The definition and many properties of 2-groups are already known.  A 1-group is simply a [[group (math)|group]], and the only 0-group is trivial. 2-groups can be described using [[crossed modules]].

== References ==
* [[Hoàng Xuân Sính]], [http://www.math.rwth-aachen.de/~kuenzer/sinh.html Gr-catégories], PhD thesis, (1973)
* [[John C. Baez]] and Aaron D. Lauda, [https://arxiv.org/abs/math.QA/0307200 Higher-Dimensional Algebra V: 2-Groups], Theory and Applications of Categories 12 (2004), 423–491.
* David Michael Roberts and Urs Schreiber, [https://arxiv.org/abs/0708.1741 The inner automorphism 3-group of a strict 2-group], Journal of Homotopy and Related Structures, vol. 3(1) (2008), pp.193–245.

[[Category:Group theory]]
[[Category:Higher category theory]]
[[Category:Homotopy theory]]


{{cattheory-stub}}</text>
      <sha1>7i1kjukrkegpnhe0yjcupnxjbjxhvnh</sha1>
    </revision>
  </page>
  <page>
    <title>Observational equivalence</title>
    <ns>0</ns>
    <id>1064136</id>
    <revision>
      <id>836513614</id>
      <parentid>827119734</parentid>
      <timestamp>2018-04-15T07:14:32Z</timestamp>
      <contributor>
        <username>Fayenatic london</username>
        <id>1639942</id>
      </contributor>
      <minor/>
      <comment>Removing from [[Category:Equivalence]] using [[c:Help:Cat-a-lot|Cat-a-lot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2490">'''Observational equivalence''' is the property of two or more underlying entities being indistinguishable on the basis of their observable implications. Thus, for example, two [[scientific theory|scientific theories]] are observationally equivalent if all of their empirically testable predictions are identical, in which case empirical evidence cannot be used to distinguish which is closer to being correct; indeed, it may be that they are actually two different perspectives on one underlying theory.

In [[econometrics]], two parameter values (or two ''structures,'' from among a class of statistical models) are considered observationally equivalent if they both result in the same probability distribution of observable data.&lt;ref name="palgrave"&gt;{{cite encyclopedia |last1=Dufour |first1=Jean-Marie |last2=Hsiao |first2=Cheng |editor1-last=Durlauf |editor1-first=Steven N. |editor2-last=Blume |editor2-first=Lawrence E. |title=Identification |encyclopedia=The New Palgrave Dictionary of Economics |edition=Second |year=2008 |url=http://www.dictionaryofeconomics.com/article?id=pde2008_I000004}}&lt;/ref&gt;&lt;ref name="nber"&gt;{{cite web |last=Stock |first=James H. |publisher=National Bureau of Economic Research  |date=July 14, 2008 |title=Weak Instruments, Weak Identification, and Many Instruments, Part I |url=http://www.nber.org/WNE/slides7-14-08/Lecture3.pdf}}&lt;/ref&gt;&lt;ref name="koopmans"&gt;{{cite journal |last=Koopmans |first=Tjalling C. |title=Identification problems in economic model construction |journal=Econometrica |volume=17 |issue=2 |year=1949 |pages=125–144 | doi=10.2307/1905689 }}&lt;/ref&gt;  This term often arises in relation to the [[Parameter identification problem|identification problem]].

In the [[formal semantics of programming languages]], two [[term (mathematics)|term]]s ''M'' and ''N'' are observationally equivalent if and only if, in all contexts ''C''[...] where ''C''[''M''] is a valid term, it is the case that ''C''[''N''] is also a valid term with the same value. Thus it is not possible, within the system, to distinguish between the two terms. This definition can be made precise only with respect to a particular calculus, one that comes with its own specific definitions of ''term'', ''context'', and the ''value of a term''.

==See also==
*[[Underdetermination]]

==References==
{{reflist}}

{{FOLDOC}}

[[Category:Statistical theory]]
[[Category:Econometric modeling]]
[[Category:Programming language semantics]]
{{econometrics-stub}}
{{comp-sci-stub}}</text>
      <sha1>91i3d45o2qbowibwo0s1mkxf1xupho1</sha1>
    </revision>
  </page>
  <page>
    <title>Partial cube</title>
    <ns>0</ns>
    <id>30697444</id>
    <revision>
      <id>846710315</id>
      <parentid>745995637</parentid>
      <timestamp>2018-06-20T12:35:09Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 0 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="13647">{{distinguish|cubic graph}}
In [[graph theory]], a '''partial cube''' is a [[Graph (discrete mathematics)|graph]] that is an [[isometry|isometric]] [[Glossary of graph theory#Subgraphs|subgraph]] of a [[hypercube graph|hypercube]].&lt;ref&gt;{{harvtxt|Ovchinnikov|2011}}, Definition 5.1, p. 127.&lt;/ref&gt; In other words, a partial cube is a subgraph of a hypercube that preserves [[distance (graph theory)|distance]]s—the distance between any two vertices in the subgraph is the same as the distance between those vertices in the hypercube. Equivalently, a partial cube is a graph whose vertices can be labeled with [[bit string]]s of equal length in such a way that the distance between two vertices in the graph is equal to the [[Hamming distance]] between their labels. Such a labeling is called a ''Hamming labeling''; it represents an isometric [[embedding]] of the partial cube into a hypercube.

==History==
{{harvtxt|Firsov|1965}} was the first to study isometric embeddings of graphs into hypercubes. The graphs that admit such embeddings were characterized by {{harvtxt|Djoković|1973}} and {{harvtxt|Winkler|1984}}, and were later named partial cubes. A separate line of research on the same structures, in the terminology of [[Family of sets|families of sets]] rather than of hypercube labelings of graphs, was followed by {{harvtxt|Kuzmin|Ovchinnikov|1975}} and {{harvtxt|Falmagne|Doignon|1997}}, among others.&lt;ref&gt;{{harvtxt|Ovchinnikov|2011}}, p. 174.&lt;/ref&gt;

==Examples==
[[File:2SAT median graph.svg|thumb|upright=1.35|An example of a partial cube with a Hamming labeling on its vertices. This graph is also a [[median graph]].]]
Every [[tree (graph theory)|tree]] is a partial cube. For, suppose that a tree ''T'' has ''m'' edges, and number these edges (arbitrarily) from 0 to ''m''&amp;nbsp;&amp;minus;&amp;nbsp;1. Choose a root vertex ''r'' for the tree, arbitrarily, and label each vertex ''v'' with a string of ''m'' bits that has a 1 in position ''i'' whenever edge ''i'' lies on the path from ''r'' to ''v'' in ''T''. For instance, ''r'' itself will have a label that is all zero bits, its neighbors will have labels with a single 1-bit, etc. Then the Hamming distance between any two labels is the distance between the two vertices in the tree, so this labeling shows that ''T'' is a partial cube.

Every [[hypercube graph]] is itself a partial cube, which can be labeled with all the different bitstrings of length equal to the dimension of the hypercube.

More complex examples include the following:
*Consider the graph whose vertex labels consist of all possible {{nowrap|(2''n'' + 1)}}-digit bitstrings that have either ''n'' or {{nowrap|''n'' + 1}} nonzero bits, where two vertices are adjacent whenever their labels differ by a single bit. This labeling defines an embedding of these graphs into a hypercube (the graph of all bitstrings of a given length, with the same adjacency-condition) that turns out to be distance-preserving. The resulting graph is a [[Kneser graph|bipartite Kneser graph]]; the graph formed in this way with {{nowrap|1=''n'' = 2}} has 20 vertices and 30 edges, and is called the [[Desargues graph]].
*All [[median graph]]s are partial cubes.&lt;ref&gt;{{harvtxt|Ovchinnikov|2011}}, Section 5.11, "Median Graphs", pp. 163–165.&lt;/ref&gt; The trees and hypercube graphs are examples of median graphs. Since the median graphs include the [[squaregraph]]s, [[simplex graph]]s, and [[Fibonacci cube]]s, as well as the covering graphs of finite [[distributive lattice]]s, these are all partial cubes.
*The [[planar dual]] graph of an [[arrangement of lines]] in the [[Euclidean plane]] is a partial cube. More generally, for any [[hyperplane arrangement]] in [[Euclidean space]] of any number of dimensions, the graph that has a vertex for each cell of the arrangement and an edge for each two adjacent cells is a partial cube.&lt;ref&gt;{{harvtxt|Ovchinnikov|2011}}, Chapter 7, "Hyperplane Arrangements", pp. 207–235.&lt;/ref&gt;
*A partial cube in which every vertex has exactly three neighbors is known as a [[cubic graph|cubic]] partial cube. Although several infinite families of cubic partial cubes are known, together with many other sporadic examples, the only known cubic partial cube that is not a [[planar graph]] is the Desargues graph.&lt;ref&gt;{{harvtxt|Eppstein|2006}}.&lt;/ref&gt;
*The underlying graph of any [[antimatroid]], having a vertex for each set in the antimatroid and an edge for every two sets that differ by a single element, is always a partial cube.
*The [[Cartesian product of graphs|Cartesian product]] of any finite set of partial cubes is another partial cube.&lt;ref&gt;{{harvtxt|Ovchinnikov|2011}}, Section 5.7, "Cartesian Products of Partial Cubes", pp. 144–145.&lt;/ref&gt;

==The Djoković–Winkler relation==
Many of the theorems about partial cubes are based directly or indirectly upon a certain [[binary relation]] defined on the edges of the graph. This relation, first described by {{harvtxt|Djoković|1973}} and given an equivalent definition in terms of distances by {{harvtxt|Winkler|1984}}, is denoted by&amp;nbsp;&lt;math&gt;\Theta&lt;/math&gt;. Two edges &lt;math&gt;e=\{x,y\}&lt;/math&gt; and &lt;math&gt;f=\{u,v\}&lt;/math&gt; are defined to be in the relation&amp;nbsp;&lt;math&gt;\Theta&lt;/math&gt;, written &lt;math&gt;e\mathrel{\Theta}f&lt;/math&gt;, if
&lt;math&gt;d(x,u)+d(y,v)\not=d(x,v)+d(y,u)&lt;/math&gt;. This relation is [[reflexive relation|reflexive]] and [[symmetric relation|symmetric]], but in general it is not [[transitive relation|transitive]].

Winkler showed that a [[connectivity (graph theory)|connected]] graph is a partial cube if and only&amp;nbsp;if it is [[bipartite graph|bipartite]] and the relation&amp;nbsp;&lt;math&gt;\Theta&lt;/math&gt; is transitive.&lt;ref&gt;{{harvtxt|Winkler|1984}}, Theorem&amp;nbsp;4. See also {{harvtxt|Ovchinnikov|2011}}, Definition 2.13, p.29, and Theorem 5.19, p. 136.&lt;/ref&gt; In this case, it forms an [[equivalence relation]] and each equivalence class separates two connected subgraphs of the graph from each other. A Hamming labeling may be obtained by assigning one bit of each label to each of the equivalence classes of the Djoković–Winkler relation; in one of the two connected subgraphs separated by an equivalence class of edges, all of the vertices have a 0 in that position of their labels, and in the other connected subgraph all of the vertices have a 1 in the same position.

==Recognition==
Partial cubes can be recognized, and a Hamming labeling constructed, in &lt;math&gt;O(n^2)&lt;/math&gt;&amp;nbsp;time, where &lt;math&gt;n&lt;/math&gt;&amp;nbsp;is the number of vertices in the graph.&lt;ref&gt;{{harvtxt|Eppstein|2008}}.&lt;/ref&gt; Given a partial cube, it is straightforward to construct the equivalence classes of the Djoković–Winkler relation by doing a [[breadth first search]] from each vertex, in total time &lt;math&gt;O(nm)&lt;/math&gt;; the &lt;math&gt;O(n^2)&lt;/math&gt;-time recognition algorithm speeds this up by using [[bit-level parallelism]] to perform multiple breadth first searches in a single pass through the graph, and then applies a separate algorithm to verify that the result of this computation is a valid partial cube labeling.

==Dimension==
The '''isometric dimension''' of a partial cube is the minimum dimension of a hypercube onto which it may be isometrically embedded, and is equal to the number of equivalence classes of the Djoković–Winkler relation. For instance, the isometric dimension of an &lt;math&gt;n&lt;/math&gt;-vertex tree is its number of edges, &lt;math&gt;n-1&lt;/math&gt;. An embedding of a partial cube onto a hypercube of this dimension is unique, up to symmetries of the hypercube.&lt;ref&gt;{{harvtxt|Ovchinnikov|2011}}, Section 5.6, "Isometric Dimension", pp. 142–144, and Section 5.10, "Uniqueness of Isometric Embeddings", pp. 157–162.&lt;/ref&gt;

Every hypercube and therefore every partial cube may be embedded isometrically into an [[integer lattice]], and the '''lattice dimension''' of the partial cube is the minimum dimension of an integer lattice for which this is possible. The lattice dimension may be significantly smaller than the isometric dimension; for instance, for a tree it is half the number of leaves in the tree (rounded up to the nearest integer). The lattice dimension of any graph, and a lattice embedding of minimum dimension, may be found in [[polynomial time]] by an algorithm based on [[maximum matching]] in an auxiliary graph.&lt;ref&gt;{{harvtxt|Hadlock|Hoffman|1978}}; {{harvtxt|Eppstein|2005}}; {{harvtxt|Ovchinnikov|2011}}, Chapter 6, "Lattice Embeddings", pp. 183–205.&lt;/ref&gt;

Other types of dimension of partial cubes have also been defined, based on embeddings into more specialized structures.&lt;ref&gt;{{harvtxt|Eppstein|2009}}; {{harvtxt|Cabello|Eppstein|Klavžar|2011}}.&lt;/ref&gt;

==Application to chemical graph theory==
Isometric embeddings of graphs into hypercubes have an important application in [[chemical graph theory]]. A ''benzenoid graph'' is a graph consisting of all vertices and edges lying on and in the interior of a cycle in a [[hexagonal lattice]]. Such graphs are the [[molecular graph]]s of the [[benzenoid hydrocarbon]]s, a large class of organic molecules. Every such graph is a partial cube. A Hamming labeling of such a graph can be used to compute the [[Wiener index]] of the corresponding molecule, which can then be used to predict certain of its chemical properties.&lt;ref&gt;{{harvtxt|Klavžar|Gutman|Mohar|1995}}, Propositions 2.1 and 3.1; {{harvtxt|Imrich|Klavžar|2000}}, p.&amp;nbsp;60; {{harvtxt|Ovchinnikov|2011}}, Section 5.12, "Average Length and the Wiener Index", pp. 165–168.&lt;/ref&gt;

A different molecular structure formed from carbon, the [[diamond cubic]], also forms partial cube graphs.&lt;ref&gt;{{harvtxt|Eppstein|2009}}.&lt;/ref&gt;

==Notes==
{{reflist|colwidth=30em}}

==References==
*{{citation|title=The Fibonacci dimension of a graph|first1=S.|last1=Cabello|first2=D.|last2=Eppstein|author2-link=David Eppstein|first3=S.|last3=Klavžar|arxiv=0903.2507|journal=Electronic Journal of Combinatorics|volume=18|issue=1|at=P55|year=2011|bibcode=2009arXiv0903.2507C}}.
*{{citation
 | last1 = Djoković | first1 = D.&amp;nbsp;Ž.
 | title = Distance-preserving subgraphs of hypercubes
 | journal = [[Journal of Combinatorial Theory]] | series = Series&amp;nbsp;B
 | volume = 14 | issue = 3 | year = 1973 | pages = 263–267
 | mr = 0314669 
 | doi = 10.1016/0095-8956(73)90010-5
 }}.
*{{citation|first=David|last=Eppstein|authorlink=David Eppstein|arxiv=cs.DS/0402028|title=The lattice dimension of a graph|journal=European Journal of Combinatorics|volume=26|issue=6|pages=585–592|year=2005|doi=10.1016/j.ejc.2004.05.001}}.
*{{citation|title=Cubic partial cubes from simplicial arrangements|first=David|last=Eppstein|authorlink=David Eppstein|arxiv=math.CO/0510263 |journal=Electronic Journal of Combinatorics|volume=13|issue=1|at=R79|year=2006|url=http://www.combinatorics.org/Volume_13/Abstracts/v13i1r79.html}}.
*{{citation|contribution=Recognizing partial cubes in quadratic time|first=David|last=Eppstein|authorlink=David Eppstein|arxiv=0705.1025 |title=Proc. 19th ACM-SIAM Symposium on Discrete Algorithms|year=2008|pages=1258–1266|bibcode=2007arXiv0705.1025E}}.
*{{citation|contribution=Isometric diamond subgraphs|first=David|last=Eppstein|authorlink=David Eppstein|arxiv=0807.2218 |title=[[International Symposium on Graph Drawing|Proc. 16th International Symposium on Graph Drawing, Heraklion, Crete, 2008]]|series=Lecture Notes in Computer Science|volume=5417|year=2009|pages=384–389|publisher=Springer-Verlag|doi=10.1007/978-3-642-00219-9_37}}.
*{{citation|last1=Falmagne|first1=J.-C.|author1-link=Jean-Claude Falmagne|last2=Doignon|first2=J.-P.|title=Stochastic evolution of rationality|journal=Theory and Decision|volume=43|pages=107–138|year=1997|doi=10.1023/A:1004981430688}}.
*{{citation|first=V.V.|last=Firsov|year=1965|title=On isometric embedding of a graph into a Boolean cube|journal=Cybernetics|volume=1|pages=112–113|doi=10.1007/bf01074705}}. As cited by {{harvtxt|Ovchinnikov|2011}}.
*{{citation|first1=F.|last1=Hadlock|first2=F.|last2=Hoffman|title=Manhattan trees|journal=Utilitas Mathematica|year=1978|volume=13|pages=55–67}}. As cited by {{harvtxt|Ovchinnikov|2011}}.
*{{citation
 | last1 = Imrich | first1 = Wilfried
 | last2 = Klavžar | first2 = Sandi
 | title = Product Graphs: Structure and Recognition
 | series = Wiley-Interscience Series in Discrete Mathematics and Optimization
 | publisher = John Wiley &amp; Sons
 | year = 2000 | location = New York
 | isbn = 978-0-471-37039-0
 | mr = 1788124 
 }}.
*{{citation
 | last1 = Klavžar | first1 = Sandi
 | last2 = Gutman | first2 = Ivan
 | last3 = Mohar | first3 = Bojan | author3-link = Bojan Mohar
 | title = Labeling of benzenoid systems which reflects the vertex-distance relations
 | url = http://www.fmf.uni-lj.si/~klavzar/preprints/labeling-benzi.pdf
 | journal = Journal of Chemical Information and Computer Sciences
 | volume = 35 | issue = 3 | year = 1995 | pages = 590–593 | doi=10.1021/ci00025a030
 }}.
*{{citation|first1=V.|last1=Kuzmin|first2=S.|last2=Ovchinnikov|title=Geometry of preferences spaces I|journal=Automation and Remote Control|volume=36|year=1975|pages=2059–2063}}. As cited by {{harvtxt|Ovchinnikov|2011}}.
*{{citation|first=Sergei|last=Ovchinnikov|title=Graphs and Cubes|series=Universitext|publisher=Springer|year=2011}}. See especially Chapter 5, "Partial Cubes", pp. 127–181.
*{{citation
 | last1 = Winkler | first1 = Peter&amp;nbsp;M. | authorlink = Peter Winkler
 | title = Isometric embedding in products of complete graphs
 | journal = Discrete Applied Mathematics
 | volume = 7 | issue = 2 | year = 1984 | pages = 221–225
 | mr = 0727925 
 | doi = 10.1016/0166-218X(84)90069-6
 }}.

[[Category:Graph families]]
[[Category:Mathematical chemistry]]
[[Category:Bipartite graphs]]</text>
      <sha1>1ml3bg2u0gs28t9eltt9vm01gz9ykyp</sha1>
    </revision>
  </page>
  <page>
    <title>Paul Kelly (mathematician)</title>
    <ns>0</ns>
    <id>45092620</id>
    <revision>
      <id>831153383</id>
      <parentid>725186287</parentid>
      <timestamp>2018-03-19T01:28:32Z</timestamp>
      <contributor>
        <username>Turgidson</username>
        <id>1747755</id>
      </contributor>
      <comment>added [[Category:Mathematicians from California]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4315">'''Paul Joseph Kelly''' (June 26, 1915 – July 15, 1995) was an American mathematician who worked in [[geometry]] and [[graph theory]].&lt;ref name="mactutor"&gt;{{MacTutor|id=Kelly|title=Paul Joseph Kelly}}&lt;/ref&gt;&lt;ref name="uc"&gt;{{citation|url=http://texts.cdlib.org/view?docId=hb238nb0fs&amp;chunk.id=div00046&amp;brand=calisphere&amp;doc.view=entire_text|title=Paul J. Kelly, Mathematics: Santa Barbara|website=University of California: In Memoriam|year=1995|first1=Gordon|last1=Baker|first2=Andrew|last2=Bruckner|first3=Ernest|last3=Michael|first4=Adil|last4=Yaqub|publisher=California Digital Library}}&lt;/ref&gt;

==Education and career==
Kelly was born in [[Riverside, California]]. He earned bachelor's and master's degrees from the [[University of California, Los Angeles]] before moving to the [[University of Wisconsin–Madison]] for doctoral studies; he earned his Ph.D. in 1942 with a dissertation concerning [[geometric transformation]]s under the supervision of [[Stanislaw Ulam]].&lt;ref name="mactutor"/&gt;&lt;ref name="uc"/&gt;&lt;ref name="mg"&gt;{{mathgenealogy|id=8083}}&lt;/ref&gt;

He spent the rest of the war years serving in the [[United States Air Force]] as a First Lieutenant, before returning to academia with a teaching appointment at the [[University of Southern California]] in 1946. He moved to the [[University of California, Santa Barbara]] in 1949, and was chair there from 1957 to 1962.&lt;ref name="mactutor"/&gt;&lt;ref name="uc"/&gt; At UCSB, his students included [[Brian Alspach]] (through whom he has nearly 30 [[academic genealogy|academic descendants]]) and [[Phyllis Chinn]].&lt;ref name="mg"/&gt; He retired in 1982.&lt;ref name="mactutor"/&gt;&lt;ref name="uc"/&gt;

==Contributions==
Kelly is known for posing the [[reconstruction conjecture]] with his advisor Ulam, which states that every graph is uniquely determined by the ensemble of subgraphs formed by deleting one vertex in each possible way.&lt;ref&gt;{{citation
 | last = Harary | first = F. | authorlink = Frank Harary
 | contribution = On the reconstruction of a graph from a collection of subgraphs
 | mr = 0175111
 | pages = 47–52
 | publisher = Publ. House Czechoslovak Acad. Sci., Prague
 | title = Theory of Graphs and its Applications (Proc. Sympos. Smolenice, 1963)
 | year = 1964}}.&lt;/ref&gt; He also proved a special case of this conjecture, for [[Tree (graph theory)|trees]].&lt;ref&gt;{{citation
 | last = Kelly | first = Paul J.
 | journal = Pacific Journal of Mathematics
 | mr = 0087949
 | pages = 961–968
 | title = A congruence theorem for trees
 | url = http://msp.org/pjm/1957/7-1/pjm-v7-n1-p.pdf#page=167
 | volume = 7
 | year = 1957
 | doi=10.2140/pjm.1957.7.961}}.&lt;/ref&gt;

He is the coauthor of three textbooks: ''Projective geometry and projective metrics'' (1953, with [[Herbert Busemann]]), ''Geometry and convexity'' (1979, with Max L. Weiss), and ''The non-Euclidean, hyperbolic plane : Its structure and consistency'' (1981, with Gordon Matthews).

==Selected articles==
*with David Merriell: {{cite journal|title=A class of graphs |journal=Trans. Amer. Math. Soc.|volume=96|year=1960|pages=488–492|mr=0115932|doi=10.1090/s0002-9947-1960-0115932-0}} 
*with [[Ernst G. Straus|E. G. Straus]]: {{cite journal|title=Inversive and conformal convexity|journal=Proc. Amer. Math. Soc.|volume=8|year=1957|pages=572–577|mr=0087973|doi=10.1090/s0002-9939-1957-0087973-9}}
*{{cite journal|title=On Minkowski bodies of constant width|journal=Bull. Amer. Math. Soc.|volume=55|year=1949|pages=1147–1150|mr=0033079|doi=10.1090/s0002-9904-1949-09345-x}} 
*{{cite journal|title=On isometries of product sets|journal=Bull. Amer. Math. Soc.|volume=54|year=1948|pages=723–727|mr=0026320|doi=10.1090/s0002-9904-1948-09063-2}}
*{{cite journal|title=On isometries of square sets|journal=Bull. Amer. Math. Soc.|volume=51|year=1945|pages=960–963|mr=0013898|doi=10.1090/s0002-9904-1945-08482-1}}

==References==
{{reflist}}

{{Authority control}}
{{DEFAULTSORT:Kelly, Paul Joseph}}
[[Category:1915 births]]
[[Category:1995 deaths]]
[[Category:20th-century American mathematicians]]
[[Category:Graph theorists]]
[[Category:University of California, Los Angeles alumni]]
[[Category:University of Wisconsin–Madison alumni]]
[[Category:University of Southern California faculty]]
[[Category:University of California, Santa Barbara faculty]]
[[Category:Mathematicians from California]]</text>
      <sha1>jdgs23lzn1pz413416dvhbb5l2zu8zf</sha1>
    </revision>
  </page>
  <page>
    <title>Polynomial greatest common divisor</title>
    <ns>0</ns>
    <id>9927028</id>
    <revision>
      <id>867719106</id>
      <parentid>857866312</parentid>
      <timestamp>2018-11-07T15:33:19Z</timestamp>
      <contributor>
        <username>D.Lazard</username>
        <id>12336988</id>
      </contributor>
      <comment>/* Pseudo-remainder sequences */ {{anchor|pseudo-remainder|pseudo-division}}</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="48712">{{refimprove|date=September 2012}}
In algebra, the '''greatest common divisor''' (frequently abbreviated as GCD) of two [[polynomial]]s is a polynomial, of the highest possible degree, that is a [[factorization|factor]] of both the two original polynomials. This concept is analogous to the [[greatest common divisor]] of two integers.

In the important case of [[univariate]] polynomials over a [[field (mathematics)|field]] the polynomial GCD may be computed, like for the integer GCD, by [[Euclid's algorithm]] using [[polynomial long division|long division]]. The polynomial GCD is defined only [[up to]] the multiplication by an invertible constant.

The similarity between the integer GCD and the polynomial GCD allows us to extend to univariate polynomials all the properties that may be deduced from Euclid's algorithm and [[Euclidean division]]. Moreover, the polynomial GCD has specific properties that make it a fundamental notion in various areas of algebra. Typically, the [[root of a function|root]]s of the GCD of two polynomials are the common roots of the two polynomials, and this allows us to get information on the roots without computing them. For example, the [[multiple root]]s of a polynomial are the roots of the GCD of the polynomial and its derivative, and further GCD computations allow us to compute the [[square-free factorization]] of the polynomial, which provides polynomials whose roots are the roots of a given [[multiplicity (mathematics)|multiplicity]].

The greatest common divisor may be defined and exists, more generally, for [[multivariate polynomial]]s over a field or the ring of integers, and also over a [[unique factorization domain]]. There exist algorithms to compute them as soon as one has a GCD algorithm in the ring of coefficients. These algorithms proceed by a [[recursion]] on the number of variables to reduce the problem to a variant of Euclid's algorithm. They are a fundamental tool in [[computer algebra]], because [[computer algebra system]]s use them systematically to simplify fractions. Conversely, most of the modern theory of polynomial GCD has been developed to satisfy the need of efficiency of computer algebra systems.

==General definition==
Let ''p'' and ''q'' be polynomials with [[coefficients]] in an [[integral domain]] ''F'', typically a [[field (mathematics)|field]] or the integers.  
A '''greatest common divisor''' of ''p'' and ''q'' is a polynomial ''d'' that divides ''p'' and ''q'' and such that every common divisor of ''p'' and ''q'' also divides ''d''. Every pair of polynomials (not both zero) has a GCD if and only  if ''F'' is a [[unique factorization domain]].

If ''F'' is a field and ''p'' and ''q'' are not both zero, for ''d'' to be a greatest common divisor it is sufficient that it divides both ''p'' and ''q'' and it has the greatest degree among the polynomials having this property. If ''p'' = ''q'' = 0, the GCD is 0. However, some authors consider that it is not defined in this case.

The greatest common divisor of ''p'' and ''q'' is usually denoted "gcd(''p'', ''q'')".

The greatest common divisor is not unique: if ''d'' is a GCD of ''p'' and ''q'', then the polynomial ''f'' is another GCD if and only if there is an invertible element ''u'' of ''F'' such that 
:&lt;math&gt;f=u d&lt;/math&gt;
and 
:&lt;math&gt;d=u^{-1} f&lt;/math&gt;.
In other words, the GCD is unique up to the multiplication by an invertible constant.

In the case of the integers, this indetermination has been settled by choosing, as the GCD, the unique one which is positive (there is another one, which is its opposite). With this convention, the GCD of two integers is also the greatest (for the usual ordering) common divisor. However, since there is no natural [[total order]] for polynomials over an integral domain, one cannot proceed in the same way here. For [[univariate]] polynomials over a field, one can additionally require the GCD to be [[monic polynomial|monic]] (i.e. it has 1 as coefficient of the highest degree), but in more general cases there is no general convention. Therefore, equalities like ''d'' = gcd(''p'', ''q'') or gcd(''p'', ''q'') = gcd(''r'', ''s'') are usual abuses of notation which should be read "''d'' is a GCD of ''p'' and ''q''" and "''p'', ''q'' has the same set of GCD as ''r'', ''s''". In particular, gcd(''p'', ''q'') = 1 means that the invertible constants are the only common divisors, and thus that ''p'' and ''q'' are [[coprime]].
&lt;!-- This example seems not really useful. In any case, it should be placed in another section

These hypotheses for the ring of the coefficients are necessary.  For example, suppose we allow ''F''&amp;nbsp;=&amp;nbsp;'''Z'''/6'''Z''', which is not a field. Then we have

: &lt;math&gt;x(x + 3) = x^2 + 3x,\ &lt;/math&gt;

: &lt;math&gt;x(x + 1) = x^2 + x,\ &lt;/math&gt;

and

: &lt;math&gt;(x + 3)(x + 4) = x^2 + 7x + 12 = x^2 + x,\ &lt;/math&gt;

after reduction modulo six (see [[modular arithmetic]]). This shows that ''x'' and &lt;math&gt;x+3&lt;/math&gt; would both satisfy the definition of

: &lt;math&gt;\gcd(x^2 + x, x^2 + 3x).\ &lt;/math&gt;
--&gt;

==Properties==

*As stated above, the GCD of two polynomials exists if the coefficients belong either to a field, the ring of the integers or more generally to a [[unique factorization domain]].
*If ''c'' is any common divisor of ''p'' and ''q'', then ''c'' divides their GCD.
*&lt;math&gt;\gcd(p,q)= \gcd(q,p).&lt;/math&gt;
*&lt;math&gt;\gcd(p, q)= \gcd(q,p+rq)&lt;/math&gt; for any polynomial ''r''. This property is at the basis of the proof of Euclid's algorithm.
*For any invertible element ''k'' of the ring of the coefficients, &lt;math&gt;\gcd(p,q)=\gcd(p,kq)&lt;/math&gt;.
*Hence &lt;math&gt;\gcd(p,q)=\gcd(a_1p+b_1q,a_2p+b_2q)&lt;/math&gt; for any scalars &lt;math&gt;a_1, b_1, a_2, b_2&lt;/math&gt; such that &lt;math&gt;a_1 b_2 - a_2 b_1&lt;/math&gt; is invertible.
*If &lt;math&gt;\gcd(p, r)=1&lt;/math&gt;, then &lt;math&gt;\gcd(p, q)=\gcd(p, qr)&lt;/math&gt;.
*If &lt;math&gt;\gcd(q, r)=1&lt;/math&gt;, then &lt;math&gt;\gcd(p, qr)=\gcd(p, q)\,\gcd(p, r)&lt;/math&gt;.
*For two univariate polynomials ''p'' and ''q'' over a field, there exist polynomials ''a'' and ''b'', such that &lt;math&gt;\gcd(p,q)=ap+bq&lt;/math&gt; and &lt;math&gt;\gcd(p,q)&lt;/math&gt; divides every such linear combination of ''p'' and ''q'' ([[Bézout's identity]]).
*The greatest common divisor of three or more polynomials may be defined similarly as for two polynomials. It may be computed recursively from GCD's of two polynomials by the identities:
::&lt;math&gt;\gcd(p, q, r) = \gcd(p, \gcd(q, r)),&lt;/math&gt;
: and
::&lt;math&gt;\gcd(p_1, p_2, \dots , p_n) = \gcd( p_1, \gcd(p_2, \dots , p_n)).&lt;/math&gt;

==GCD by hand computation==
There are several ways to find the greatest common divisor of two polynomials. Two of them are:

#''[[Factorization of polynomials]]'', in which one finds the factors of each expression, then selects the set of common factors held by all from within each set of factors. This method may be useful only in simple cases, as factoring is usually more difficult than computing the greatest common divisor.
#The ''[[Euclidean algorithm]]'', which can be used to find the GCD of two polynomials in the same manner as for two numbers.

===Factoring===
To find the GCD of two polynomials using factoring, simply factor the two polynomials completely.  Then, take the product of all common factors.  At this stage, we do not necessarily have a monic polynomial, so finally multiply this by a constant to make it a monic polynomial.  This will be the GCD of the two polynomials as it includes all common divisors and is monic.

Example one: Find the GCD of {{math|''x''&lt;sup&gt;2&lt;/sup&gt; + 7''x'' + 6}} and {{math|''x''&lt;sup&gt;2&lt;/sup&gt; − 5''x'' − 6}}.

:{{math|1=''x''&lt;sup&gt;2&lt;/sup&gt; + 7''x'' + 6 = (''x'' + 1)(''x'' + 6)}}
:{{math|1=''x''&lt;sup&gt;2&lt;/sup&gt; − 5''x'' − 6 = (''x'' + 1)(''x'' − 6)}}

Thus, their GCD is {{math|''x'' + 1}}.

===Euclidean algorithm===
Factoring polynomials can be difficult, especially if the polynomials have large degree. The [[Euclidean algorithm]] is a method which works for any pair of polynomials. It makes repeated use of [[Euclidean division]]. When using this algorithm on two numbers, the size of the numbers decreases at each stage. With polynomials, the degree of the polynomials decreases at each stage. The last nonzero remainder, made monic if necessary, is the GCD of the two polynomials.

More specifically, assume we wish to find the gcd of two polynomials {{math|''a''(''x'')}} and {{math|''b''(''x'')}}, where we can suppose 
:&lt;math&gt;\deg(b(x)) \le \deg(a(x)) \,.&lt;/math&gt;

We can find two polynomials {{math|''q''(''x'')}} and {{math|''r''(''x'')}} which satisfy (see [[Polynomial long division]])

* &lt;math&gt;a(x) = q_0(x)b(x) + r_0(x)&lt;/math&gt;
* &lt;math&gt;\deg(r_0(x)) &lt; \deg(b(x))&lt;/math&gt;

The polynomial {{math|''q''&lt;sub&gt;0&lt;/sub&gt;(''x'')}} is called the quotient and {{math|''r''&lt;sub&gt;0&lt;/sub&gt;(''x'')}} is the remainder. Notice that a polynomial {{math|''g''(''x'')}} divides {{math|''a''(''x'')}} and {{math|''b''(''x'')}} if and only if it divides {{math|''b''(''x'')}} and {{math|''r''&lt;sub&gt;0&lt;/sub&gt;(''x'')}}. We deduce 
:&lt;math&gt;\gcd(a(x), b(x)) = \gcd(b(x), r_0(x)) \,.&lt;/math&gt;
Then set 
:&lt;math&gt;a_1(x) = b(x), b_1(x) = r_0(x)\,.&lt;/math&gt;
Repeat the [[polynomial long division]] to get new polynomials {{math|''q''&lt;sub&gt;1&lt;/sub&gt;(''x''), ''r''&lt;sub&gt;1&lt;/sub&gt;(''x''), ''a''&lt;sub&gt;2&lt;/sub&gt;(''x''), ''b''&lt;sub&gt;2&lt;/sub&gt;(''x'')}} and so on. At each stage we have 
:&lt;math&gt;\deg(a_{k+1})+\deg(b_{k+1}) &lt; \deg(a_{k})+\deg(b_{k})\ ,&lt;/math&gt;
so the sequence will eventually reach a point at which 
:&lt;math&gt;b_N(x) = 0&lt;/math&gt;
and we will have found our GCD: 
:&lt;math&gt;\gcd(a,b)=\gcd(a_1,b_1)=\cdots=\gcd(a_N, 0)=a_N \,.&lt;/math&gt;

Example: Find the GCD of {{math|1=&lt;span style="color:#0000ff"&gt;''x''&lt;sup&gt;2&lt;/sup&gt; + 7''x'' + 6&lt;/span&gt;}} and {{math|1=&lt;span style="color:#990000"&gt;''x''&lt;sup&gt;2&lt;/sup&gt; − 5''x'' − 6&lt;/span&gt;}}.

: {{math|1=&lt;span style="color:#0000ff"&gt;''x''&lt;sup&gt;2&lt;/sup&gt; + 7''x'' + 6&lt;/span&gt; = &lt;span style="color:#990000"&gt;(''x''&lt;sup&gt;2&lt;/sup&gt; − 5''x'' − 6)&lt;/span&gt;(1) + &lt;span style="color:#009900"&gt;(''x'' + 1)&lt;/span&gt;(12)}}

: {{math|1=&lt;span style="color:#990000"&gt;''x''&lt;sup&gt;2&lt;/sup&gt; − 5''x'' − 6&lt;/span&gt; = &lt;span style="color:#009900"&gt;(''x'' + 1)&lt;/span&gt;(''x'' − 6) + 0}}

Since {{math|1=&lt;span style="color:#009900"&gt;''x'' + 1&lt;/span&gt;}} is the last nonzero remainder, the GCD of these polynomials is {{math|1=''x''&amp;nbsp;+&amp;nbsp;1}}.

This method works only if one may test the equality to zero of the elements of the field of the coefficients, so one needs a description of the coefficients as elements of some finitely generated field, for which the generators and relations are known exactly. If the coefficients are floating point numbers, known only approximately, then one uses completely different techniques, usually based on [[singular value decomposition|SVD]].

This induces a new difficulty: For all these fields except the finite ones, the coefficients are fractions. If the fractions are not simplified during the computation, the size of the coefficients grows exponentially during the computation, which makes it impossible except for very small degrees. On the other hand, it is highly time consuming to simplify the fractions immediately. Therefore, two different alternative methods have been introduced (see below):
* Pseudo-remainder sequences, especially subresultant sequences
* Modular GCD algorithm using [[modular arithmetic]]

==Univariate polynomials with coefficients in a field==

The case of univariate polynomials over a field is specially important for several reasons. Firstly, it is the most elementary case and therefore appear in most first courses in algebra. Secondly, it is very similar to the case of the integers, and this analogy is the source of the notion of [[Euclidean domain]]. A third reason is that the theory and the algorithms for the [[multivariate polynomial|multivariate]] case and for coefficients in a [[unique factorization domain]] are strongly based on this particular case. Last but not least, polynomial GCD algorithms and derived algorithms allow one to get useful information on the roots of a polynomial, without computing them.

===Euclidean division===
Euclidean division of polynomials, which is used in [[#Euclid's algorithm|Euclid's algorithm]] for computing  GCDs, is very similar to [[Euclidean division]] of integers. Its existence is based on the following theorem: Given two univariate polynomials ''a'' and ''b'' ≠ 0 defined over a field, there exist two polynomials ''q'' (the ''quotient'') and ''r'' (the ''remainder'')  which satisfy
:&lt;math&gt;a=bq+r&lt;/math&gt;
and
:&lt;math&gt;\deg(r)&lt;\deg(b),&lt;/math&gt;
where "deg(...)" denotes the degree and the degree of the zero polynomial is defined as being negative. Moreover, ''q'' and ''r'' are uniquely defined by these relations.

The difference from Euclidean division of the integers is that, for the integers, the degree is replaced by the absolute value, and that to have uniqueness one has to suppose that ''r'' is non-negative. The rings for which such a theorem exists are called [[Euclidean domain]]s.

Like for the integers, the Euclidean division of the polynomials may be computed by the [[polynomial long division|long division]] algorithm. This algorithm is usually presented for paper-and-pencil computation, but it works well on computers, when formalized as follows (note that the names of the variables correspond exactly to the regions of the paper sheet in a pencil-and-paper computation of long division). In the following computation "deg" stands for the degree of its argument (with the convention {{nowrap|deg(0) &amp;lt; 0}}), and "lc" stands for the leading coefficient, the coefficient of the highest degree of the variable.

{{pre2|1=
'''Euclidean division'''

'''''Input:''''' ''a'' and ''b'' ≠ 0 two polynomials in the variable ''x'';
'''''Output:''''' ''q'', the quotient, and ''r'', the remainder;

'''''Begin'''''
    ''q'' := 0
    ''r'' := ''a''
    ''d'' := deg(''b'')
    ''c'' := lc(''b'')
    '''''while''''' deg(''r'') ≥ ''d'' '''''do'''''
        ''s'' := {{sfrac|lc(''r'')|''c''}} ''x''{{sup|deg(''r'')−''d''}}
        ''q'' := ''q'' + ''s''
        ''r'' := ''r'' − ''sb''
    '''''end do'''''
    '''''return''''' (''q'', ''r'')
'''''end.'''''
}}

The proof of the validity of this algorithm relies on the fact that during the whole "while" loop, we have {{math|1=''a'' = ''bq'' + ''r''}} and {{math|deg(''r'')}} is a non-negative integer that decreases at each iteration. Thus the proof of the validity of this algorithm also proves the validity of Euclidean division.

===Euclid's algorithm===
As for the integers, Euclidean division allows us to define [[Euclid's algorithm]] for computing  GCDs.

Starting from two polynomials ''a'' and ''b'', Euclid's algorithm consists of recursively replacing the pair {{math|(''a'', ''b'')}} by {{math|(''b'', rem(''a'', ''b''))}} (where "{{math|rem(''a'', ''b'')}}" denotes the remainder of the Euclidean division, computed by the algorithm of the preceding section), until ''b'' = 0. The GCD is the last non zero remainder.

Euclid's algorithm may be formalized in the recursive programming style as:
{{quotation|
&lt;math&gt;\gcd(a,b):= \text{if } b=0 \text{ then } a \text{ else } \gcd(b, \operatorname{rem}(a,b)).&lt;/math&gt;
}}
In the imperative programming style, the same algorithm becomes, giving a name to each intermediate remainder:
{{pre2|
{{nowrap|&lt;math&gt;\begin{align} r_0:=a\\ r_1:=b \end{align}&lt;/math&gt;}}

{{nowrap|'''''for''''' (&lt;math&gt;i:=1&lt;/math&gt;; &lt;math&gt;r_i \neq 0&lt;/math&gt;; &lt;math&gt;i:=i+1&lt;/math&gt;) '''''do'''''}}
  {{nowrap|&lt;math&gt;\begin{align} r_{i+1}&amp;:=\operatorname{rem}(r_{i-1},r_i) \end{align}&lt;/math&gt;}}
'''''end do'''''

{{nowrap|'''''return''''' &lt;math&gt;(r_{i-1}).&lt;/math&gt;}}
}}

The sequence of the degrees of the {{math|''r&lt;sub&gt;i&lt;/sub&gt;''}} is strictly decreasing. Thus after, at most, {{math|deg(''b'')}} steps, one get a null remainder, say {{math|''r&lt;sub&gt;k&lt;/sub&gt;''}}. As {{math|(''a'', ''b'')}} and {{math|(''b'', rem(''a'',''b''))}} have the same divisors, the set of the common divisors is not changed by Euclid's algorithm and thus all pairs {{math|(''r&lt;sub&gt;i&lt;/sub&gt;'', ''r''&lt;sub&gt;''i''+1&lt;/sub&gt;)}} have the same set of common divisors. The common divisors of {{mvar|a}} and {{mvar|b}} are thus the common divisors of {{math|''r''&lt;sub&gt;''k''−1&lt;/sub&gt;}} and 0. Thus {{math|''r''&lt;sub&gt;''k''−1&lt;/sub&gt;}} is a GCD of {{mvar|a}} and {{mvar|b}}.
This not only proves that Euclid's algorithm computes GCDs, but also proves that GCDs exist.

===Bézout's identity and extended GCD algorithm===

[[Bézout's identity]] is a GCD related theorem, initially proved for the integers, which is valid for every [[principal ideal domain]]. In the case of the univariate polynomials over a field, it may be stated as follows.

{{quotation|
If {{mvar|g}} is the greatest common divisor of  two polynomials {{mvar|a}} and {{mvar|b}}, then there are two polynomials {{mvar|u}} and {{mvar|v}} such that
:&lt;math&gt;au+bv=g\quad\mathrm{(B}\mathrm{\acute{e}}\text{zout's identity)}&lt;/math&gt;
and
:&lt;math&gt;\deg(u)&lt;\deg(b)-\deg(g), \quad \deg(v)&lt;\deg(a)-\deg(g).&lt;/math&gt;
}}

The interest of this result in the case of the polynomials is that there is an efficient algorithm to compute the polynomials {{mvar|u}} and {{mvar|v}}, This algorithm differs from Euclid's algorithm by a few more computations done at each iteration of the loop. It is therefore called '''extended GCD algorithm'''. Another difference with Euclid's algorithm is that it also uses the quotient, denoted "quo", of the Euclidean division instead of only the remainder. This algorithm works as follows.

{{pre2|1=
'''Extended GCD''' algorithm

'''''Input:''''' {{mvar|a}}, {{mvar|b}}, univariate polynomials

'''''Output:'''''
  {{mvar|g}},the GCD of {{mvar|a}} and {{mvar|b}}
  {{mvar|u}}, {{mvar|v}}, such that
    {{nowrap|&lt;math&gt;au+bv=g&lt;/math&gt;}}
    {{nowrap|&lt;math&gt;\begin{align}
    \deg(u)&lt;\deg(b)-\deg(g)\\
    \deg(v)&lt;\deg(a)-\deg(g)
    \end{align}&lt;/math&gt;}}
  {{math|''a''&lt;sub&gt;1&lt;/sub&gt;}}, {{math|''b''&lt;sub&gt;1&lt;/sub&gt;}}, such that
    {{nowrap|&lt;math&gt;\begin{align}
    a=ga_1\\
    b=gb_1
    \end{align}&lt;/math&gt;}}
'''''Begin'''''
  {{nowrap|&lt;math&gt;\begin{array}{ll}
  r_0  =a &amp; r_1  =b\\
  s_0  =1 &amp; s_1  =0\\
  t_0  =0 &amp; t_1  =1
  \end{array}&lt;/math&gt;}}
  
  '''''for''''' ({{math|1=''i''=1}}; {{math|''r&lt;sub&gt;i&lt;/sub&gt;'' ≠ 0}}; {{math|1=''i''=''i''+1}}) '''''do'''''
    {{nowrap|&lt;math&gt;q  =\operatorname{quo}(r_{i-1},r_{i})&lt;/math&gt;}}
    {{nowrap|&lt;math&gt;\begin{align}
    r_{i+1} &amp; =r_{i-1}-qr_{i}\\
    s_{i+1} &amp; =s_{i-1}-qs_{i}\\
    t_{i+1} &amp; =t_{i-1}-qt_{i}
    \end{align}&lt;/math&gt;}}
  '''''end do'''''
  {{nowrap|&lt;math&gt;\begin{align}
  g &amp; =r_{i-1}\\
  u &amp; =s_{i-1}\\
  v &amp; =t_{i-1}
  \end{align}&lt;/math&gt;}}
  {{nowrap|&lt;math&gt;\begin{align}
  a_1 &amp; =(-1)^{i-1}t_i\\
  b_1 &amp; =(-1)^i s_i
  \end{align}&lt;/math&gt;}}
'''''end.'''''
}}

The proof that the algorithm satisfies its output specification relies on the fact that, for every {{mvar|i}} we have 
:&lt;math&gt;r_i=as_i+bt_i&lt;/math&gt;
:&lt;math&gt;s_it_{i+1}-t_is_{i+1}=s_it_{i-1}-t_is_{i-1},&lt;/math&gt;
the latter equality implying 
:&lt;math&gt;s_it_{i+1}-t_is_{i+1}=(-1)^i.&lt;/math&gt;
The assertion on the degrees follows from the fact that, at every iteration, the degrees of {{math|''s&lt;sub&gt;i&lt;/sub&gt;''}} and {{math|''t&lt;sub&gt;i&lt;/sub&gt;''}} increase at most as the degree of {{math|''r&lt;sub&gt;i&lt;/sub&gt;''}} decreases.

An interesting feature of this algorithm is that, when the coefficients of Bezout's identity are needed, one gets for free the quotient of the input polynomials by their GCD.

====Arithmetic of algebraic extensions====

An important application of extended GCD algorithm is that it allows one to compute division in [[algebraic extension|algebraic field extension]]s.

Let {{mvar|L}} an algebraic extension of a field {{mvar|K}}, generated by an element whose minimal polynomial {{mvar|f}} has degree {{mvar|n}}. The elements of {{mvar|L}} are usually represented by univariate polynomials over {{mvar|K}} of degree less than {{mvar|n}}.

The addition in {{mvar|L}} is simply the addition of polynomials:
:&lt;math&gt;a+_Lb=a+_{K[X]}b.&lt;/math&gt;

The multiplication in {{mvar|L}} is the multiplication of polynomials followed by the division by {{mvar|f}}:
:&lt;math&gt;a\cdot_Lb=\operatorname{rem}(a._{K[X]}b,f).&lt;/math&gt;

The inverse of a non zero element {{mvar|a}} of {{mvar|L}} is the coefficient {{mvar|u}} in Bézout's identity {{math|1=''au'' + ''fv'' = 1}}, which may be computed by extended GCD algorithm. (the GCD is 1 because the minimal polynomial {{mvar|f}} is irreducible). The degrees inequality in the specification of extended GCD algorithm shows that a further division by {{mvar|f}} is not needed to get deg({{mvar|u}}) &lt; deg({{mvar|f}}).

===Subresultants===&lt;!-- [[subresultant]] links here --&gt;

In the case of univariate polynomials, there is a strong relationship between greatest common divisors and [[resultant]]s. In fact the resultant of two polynomials ''P'', ''Q'' is a polynomial function of the coefficients of ''P'' and ''Q'' which has the value zero if and only if the GCD of ''P'' and ''Q'' is not constant.

The subresultants theory is a generalization of this property that allows characterizing generically the GCD of two polynomials, and the resultant is the 0-th subresultant polynomial.&lt;ref&gt;
{{cite book
 | author = Saugata Basu |author2=Richard Pollack |author3=Marie-Françoise Roy
 | year = 2006
 | title = Algorithms in real algebraic geometry, chapter 4.2
 | publisher = [[Springer Science+Business Media|Springer-Verlag]]
 | url = http://perso.univ-rennes1.fr/marie-francoise.roy/bpr-ed2-posted1.html
}}&lt;/ref&gt;

The ''i''-th ''subresultant polynomial'' ''S&lt;sub&gt;i&lt;/sub&gt;''(''P'' ,''Q'') of two polynomials ''P'' and ''Q'' is a polynomial of degree at most ''i'' whose coefficients are polynomial functions of the coefficients of ''P'' and ''Q'', and the ''i''-th ''principal subresultant coefficient'' ''s&lt;sub&gt;i&lt;/sub&gt;''(''P'' ,''Q'') is the coefficient of degree ''i'' of ''S&lt;sub&gt;i&lt;/sub&gt;''(''P'', ''Q''). They have the property that the GCD of ''P'' and ''Q'' has a degree ''d'' if and only if 
:&lt;math&gt;s_0(P,Q)=\cdots=s_{d-1}(P,Q) =0 \ , s_d(P,Q)\neq 0&lt;/math&gt;.

In this case, ''S&lt;sub&gt;d&lt;/sub&gt;''(''P'' ,''Q'') is a GCD of ''P'' and ''Q'' and

:&lt;math&gt;S_0(P,Q)=\cdots=S_{d-1}(P,Q) =0.&lt;/math&gt;

Every coefficient of the subresultant polynomials is defined as the determinant of a submatrix of the [[Sylvester matrix]] of ''P'' and ''Q''. This implies that subresultants "specialize" well. More precisely, subresultants are defined for polynomials over any commutative ring ''R'', and have the following property.

Let ''φ'' be a ring homomorphism of ''R'' into another commutative ring ''S''. It extends to another homomorphism, denoted also ''φ'' between the polynomials rings over ''R'' and ''S''. Then, if ''P'' and ''Q'' are univariate polynomials with coefficients in ''R'' such that 
:&lt;math&gt;\deg(P)=\deg(\varphi(P))&lt;/math&gt;
and 
:&lt;math&gt;\deg(Q)=\deg(\varphi(Q)),&lt;/math&gt;
then the subresultant polynomials and the principal subresultant coefficients of ''φ''(''P'') and ''φ''(''Q'') are the image by ''φ'' of those of ''P'' and ''Q''.

The subresultants have two important properties which make them fundamental for the computation on computers of the GCD of two polynomials with integer coefficients.
Firstly, their definition through determinants allows bounding, through [[Hadamard inequality]], the size of the coefficients of the GCD.
Secondly, this bound and the property of good specialization allow to compute the GCD of two polynomials with integer coefficients through [[modular arithmetic|modular computation]] and [[Chinese remainder theorem]] (see [[#Modular GCD algorithm|below]]).

====Technical definition====
Let 
:&lt;math&gt;P=p_0+p_1 X+\cdots +p_m X^m,\quad Q=q_0+q_1 X+\cdots +q_n X^n.&lt;/math&gt;
be two univariate polynomials with coefficients in a field ''K''. Let us denote by &lt;math&gt;\mathcal{P}_i&lt;/math&gt; the ''K'' vector space of dimension ''i'' the polynomials of degree less than ''i''. For non-negative integer ''i'' such that ''i'' ≤ ''m'' and ''i'' ≤ ''n'', let 
:&lt;math&gt;\varphi_i:\mathcal{P}_{n-i} \times \mathcal{P}_{m-i} \rightarrow \mathcal{P}_{m+n-i}&lt;/math&gt;
be the linear map such that
:&lt;math&gt;\varphi_i(A,B)=AP+BQ.&lt;/math&gt;

The [[resultant]] of ''P'' and ''Q'' is the determinant of the [[Sylvester matrix]], which is the (square) matrix of &lt;math&gt;\varphi_0&lt;/math&gt; on the bases of the powers of ''X''. Similarly, the ''i''-subresultant polynomial is defined in term of determinants of submatrices of the matrix of &lt;math&gt;\varphi_i.&lt;/math&gt;

Let us describe these matrices more precisely;

Let ''p''&lt;sub&gt;''i''&lt;/sub&gt; = 0 for ''i'' &lt; 0 or ''i'' &gt; ''m'', and ''q''&lt;sub&gt;''i''&lt;/sub&gt; = 0 for ''i'' &lt; 0 or ''i'' &gt; ''n''. The [[Sylvester matrix]] is the (''m'' + ''n'') × (''m'' + ''n'')-matrix such that the coefficient of the ''i''-th row and the ''j''-th column is ''p''&lt;sub&gt;''m''+''j''−''i''&lt;/sub&gt; for ''j'' ≤ ''n'' and ''q''&lt;sub&gt;''j''−''i''&lt;/sub&gt; for ''j'' &gt; ''n'':&lt;ref&gt;Many author define the Sylvester matrix as the transpose of ''S''. This breaks the usual convention for writing the matrix of a linear map.&lt;/ref&gt;

:&lt;math&gt;S=\begin{pmatrix} 
p_m     &amp; 0       &amp; \cdots &amp; 0       &amp; q_n     &amp; 0       &amp; \cdots &amp; 0       \\
p_{m-1} &amp; p_m     &amp; \cdots &amp; 0       &amp; q_{n-1} &amp; q_n     &amp; \cdots &amp; 0  \\
p_{m-2} &amp; p_{m-1} &amp; \ddots &amp; 0       &amp; q_{n-2} &amp; q_{n-1} &amp; \ddots &amp; 0 \\
\vdots  &amp;\vdots   &amp; \ddots &amp; p_m     &amp; \vdots  &amp;\vdots   &amp; \ddots &amp; q_n  \\
\vdots  &amp;\vdots   &amp; \cdots &amp; p_{m-1} &amp; \vdots  &amp;\vdots   &amp; \cdots &amp; q_{n-1}\\
p_0     &amp; p_1     &amp; \cdots &amp; \vdots  &amp; q_0     &amp; q_1     &amp; \cdots &amp; \vdots\\
0       &amp; p_0     &amp; \ddots &amp;  \vdots &amp; 0       &amp; q_0     &amp; \ddots &amp;  \vdots &amp; \\
\vdots  &amp; \vdots  &amp; \ddots &amp; p_1     &amp; \vdots  &amp; \vdots  &amp; \ddots &amp; q_1   \\
0       &amp; 0       &amp; \cdots &amp; p_0     &amp; 0       &amp; 0       &amp; \cdots &amp; q_0   
\end{pmatrix}.&lt;/math&gt;

The matrix ''T&lt;sub&gt;i&lt;/sub&gt;'' of &lt;math&gt;\varphi_i&lt;/math&gt; is the (''m'' + ''n'' − ''i'') × (''m'' + ''n'' − 2''i'')-submatrix of ''S'' which is obtained by removing the last ''i'' rows of zeros in the submatrix of the columns 1 to ''n'' − ''i'' and ''n'' + 1 to ''m'' + ''n'' − ''i'' of ''S'' (that is removing ''i'' columns in each block and the ''i'' last rows of zeros). The ''principal subresultant coefficient'' ''s&lt;sub&gt;i&lt;/sub&gt;'' is the determinant of the ''m'' + ''n'' − 2''i'' first rows of ''T&lt;sub&gt;i&lt;/sub&gt;''.

Let ''V&lt;sub&gt;i&lt;/sub&gt;'' be the (''m'' + ''n'' − 2''i'') × (''m'' + ''n'' − ''i'') matrix defined as follows. First we add (''i'' + 1) columns of zeros to the right of the (''m'' + ''n'' − 2''i'' − 1) × (''m'' + ''n'' − 2''i'' − 1) [[identity matrix]]. Then we border the bottom of the resulting matrix by a row consisting in (''m'' + ''n'' − ''i'' − 1) zeros followed by ''X&lt;sup&gt;i&lt;/sup&gt;'', ''X''&lt;sup&gt;''i''−1&lt;/sup&gt;, ..., ''X'', 1:
:&lt;math&gt;V_i=\begin{pmatrix} 
1       &amp; 0       &amp; \cdots &amp; 0       &amp; 0       &amp; 0      &amp; \cdots &amp; 0 \\
0       &amp; 1       &amp; \cdots &amp; 0       &amp; 0       &amp; 0      &amp; \cdots &amp; 0 \\
\vdots  &amp;\vdots   &amp; \ddots &amp; \vdots  &amp; \vdots  &amp;\ddots  &amp; \vdots &amp; 0 \\
0       &amp; 0       &amp; \cdots &amp; 1       &amp; 0       &amp; 0      &amp; \cdots &amp; 0 \\
0       &amp; 0       &amp; \cdots &amp; 0       &amp; X^i     &amp; X^{i-1}&amp; \cdots &amp; 1 
\end{pmatrix}.&lt;/math&gt;

With this notation, the ''i''-th ''subresultant polynomial'' is the determinant of the matrix product ''V&lt;sub&gt;i&lt;/sub&gt;T&lt;sub&gt;i&lt;/sub&gt;''. Its coefficient of degree ''j'' is the determinant of the square submatrix of ''T&lt;sub&gt;i&lt;/sub&gt;'' consisting in its ''m'' + ''n'' − 2''i'' − 1 first rows and the  (''m'' + ''n'' − ''i'' − ''j'')-th row.

====Sketch of the proof====
It is not obvious that, as defined, the subresultants have the desired properties. In fact the proof is rather simple if the properties of linear algebra and those of polynomials are put together.

As defined, the columns of the matrix ''T&lt;sub&gt;i&lt;/sub&gt;'' are the vectors of the coefficients of some polynomials belonging to the image of &lt;math&gt;\varphi_i&lt;/math&gt;. The definition of the ''i''-th subresultant polynomial ''S&lt;sub&gt;i&lt;/sub&gt;'' shows that the vector of its coefficients is a linear combination of these column vectors, and thus that ''S&lt;sub&gt;i&lt;/sub&gt;'' belongs to the image of &lt;math&gt;\varphi_i.&lt;/math&gt;

If the degree of the GCD is greater than ''i'', then [[Bézout's identity]] shows that every non zero polynomial in the image of &lt;math&gt;\varphi_i&lt;/math&gt; has a degree larger than ''i''. This implies that ''S&lt;sub&gt;i&lt;/sub&gt;''=0.

If, on the other hand, the degree of the GCD is ''i'', then Bézout's identity again allows proving that the multiples of the GCD that have a degree lower than ''m'' + ''n'' − ''i'' are in the image of &lt;math&gt;\varphi_i&lt;/math&gt;. The vector space of these multiples has the dimension ''m'' + ''n'' − 2''i'' and has a base of polynomials of pairwise different degrees, not smaller than ''i''. This implies that the submatrix of the ''m'' + ''n'' − 2''i'' first rows of the column echelon form of ''T&lt;sub&gt;i&lt;/sub&gt;'' is the identity matrix and thus that ''s&lt;sub&gt;i&lt;/sub&gt;'' is not 0. Thus ''S&lt;sub&gt;i&lt;/sub&gt;'' is a polynomial in the image of &lt;math&gt;\varphi_i&lt;/math&gt;, which is a multiple of the GCD and has the same degree. It is thus a greatest common divisor.

===GCD and root finding===

====Square-free factorization====
{{main|Square-free factorization}}

Most [[root-finding algorithm]]s behave badly with polynomials that have [[multiple root]]s. It is therefore useful to detect and remove them before calling a root-finding algorithm. A GCD computation allows detection of the existence of multiple roots, because the multiple roots of a polynomial are the roots of the GCD of the polynomial and its [[formal derivative|derivative]].

After computing the GCD of the polynomial and its derivative, further GCD computations provide the complete ''square-free factorization'' of the polynomial, which is a factorization 
:&lt;math&gt;f=\prod_{i=1}^{\deg(f)} f_i^i&lt;/math&gt;
where, for each ''i'', the polynomial ''f''&lt;sub&gt;''i''&lt;/sub&gt; either is 1 if ''f'' does not have any root of multiplicity ''i'' or is a square-free polynomial (that is a polynomial without multiple root) whose roots are exactly the roots of multiplicity ''i'' of ''f'' (see [[Square-free polynomial#Yun's algorithm|Yun's algorithm]]).

Thus the square-free factorization reduces root finding of a polynomial with multiple roots to root finding of several square-free polynomials of lower degree. The square-free factorization is also the first step in most [[polynomial factorization]] algorithms.

====Sturm sequence====
{{main|Sturm sequence}}
The ''Sturm sequence'' of a polynomial with real coefficients is the sequence of the remainders provided by a variant of Euclid's algorithm applied to the polynomial and its derivative. For getting the Sturm sequence, one simply replaces the instruction 
:&lt;math&gt;r_{i+1}:=\operatorname{rem}(r_{i-1},r_{i})&lt;/math&gt;
of Euclid's algorithm by 
:&lt;math&gt;r_{i+1}:=-\operatorname{rem}(r_{i-1},r_{i}).&lt;/math&gt;

Let ''V''(''a'') be the number of changes of signs in the sequence, when evaluated at a point ''a''. Sturm's theorem asserts that ''V''(''a'') − ''V''(''b'') is the number of real roots of the polynomial in the interval [''a'', ''b'']. Thus the Sturm sequence allows computing the number of real roots in a given interval. By subdividing the interval until every subinterval contains at most one root, this provides an algorithm that  locates the real roots in intervals of arbitrary small length.

==GCD over a ring and over its field of fractions==

In this section, we consider polynomials over a [[unique factorization domain]] ''R'', typically the ring of the integers, and over its [[field of fractions]] ''F'', typically the field of the rational numbers, and we denote ''R''[''X''] and ''F''[''X''] the rings of polynomials in a set of variables over these rings.

===Primitive part–content factorization===
{{see also|Content (algebra)|Gauss's lemma (polynomial)}}

The ''content'' of a polynomial ''p'' ∈ ''R''[''X''], denoted "cont(''p'')",  is the GCD of its coefficients. A polynomial ''q'' ∈ ''F''[''X''] may be written

:&lt;math&gt;q = \frac{p}{c}&lt;/math&gt;
where ''p'' ∈ ''R''[''X''] and ''c'' ∈ ''R'': it suffices to take for ''c'' a multiple of all denominators of the coefficients of ''q'' (for example their product) and ''p'' = ''cq''. The ''content'' of ''q'' is defined as:
:&lt;math&gt;\operatorname{cont} (q) =\frac{\operatorname{cont} (p)}{c}.&lt;/math&gt;
In both cases, the content is defined up to the multiplication by a [[unit (ring theory)|unit]] of ''R''.

The ''primitive part'' of a polynomial in ''R''[''X''] or ''F''[''X''] is defined by 
:&lt;math&gt;\operatorname{primpart} (p) =\frac{p}{\operatorname{cont} (p)}.&lt;/math&gt;

In both cases, it is a polynomial in ''R''[''X''] that is ''primitive'', which means that 1 is a GCD of its coefficients.

Thus every polynomial in ''R''[''X''] or ''F''[''X''] may be factorized as 
:&lt;math&gt;p =\operatorname{cont} (p)\,\operatorname{primpart} (p),&lt;/math&gt;
and this factorization is unique up to the multiplication of the content by a unit of ''R'' and of the primitive part by the inverse of this unit.

Gauss's lemma implies that the product of two primitive polynomials is primitive. It follows that 
:&lt;math&gt;\operatorname{primpart} (pq)=\operatorname{primpart} (p) \operatorname{primpart}(q)&lt;/math&gt;
and
:&lt;math&gt;\operatorname{cont} (pq)=\operatorname{cont} (p) \operatorname{cont}(q).&lt;/math&gt;

===Relation between the GCD over ''R'' and over ''F''===

The relations of the preceding section imply a strong relation between the GCD's in ''R''[''X''] and in ''F''[''X'']. In order to avoid ambiguities, the notation "''gcd''" will be indexed, in the following, by the ring in which the GCD is computed.

If ''q''&lt;sub&gt;1&lt;/sub&gt; and ''q''&lt;sub&gt;2&lt;/sub&gt; belong to ''F''[''X''], then
:&lt;math&gt;\operatorname{primpart}(\gcd_{F[X]}(q_1,q_2))=\gcd_{R[X]}(\operatorname{primpart}(q_1),\operatorname{primpart}(q_2)).&lt;/math&gt;

If ''p''&lt;sub&gt;1&lt;/sub&gt; and ''p''&lt;sub&gt;2&lt;/sub&gt; belong to ''R''[''X''], then
:&lt;math&gt;\gcd_{R[X]}(p_1,p_2)=\gcd_R(\operatorname{cont}(p_1),\operatorname{cont}(p_2)) \gcd_{R[X]}(\operatorname{primpart}(p_1),\operatorname{primpart}(p_2)),&lt;/math&gt;
and
:&lt;math&gt;\gcd_{R[X]}(\operatorname{primpart}(p_1),\operatorname{primpart}(p_2))=\operatorname{primpart}(\gcd_{F[X]}(p_1,p_2)).&lt;/math&gt;

Thus the computation of polynomial GCD's is essentially the same problem over ''F''[''X''] and over ''R''[''X''].

For univariate polynomials over the rational numbers one may think that Euclid's algorithm is a convenient method for computing the GCD. However, it involves to simplify a large number of fractions of integers, and the resulting algorithm is not efficient. For this reason, methods have been designed to modify Euclid's algorithm for working only with polynomials over the integers. They consist in replacing Euclidean division, which introduces fractions, by a so-called ''pseudo-division'', and replacing the remainder sequence of Euclid's algorithm by so-called ''pseudo-remainder sequences'' (see [[#Pseudo-remainder sequences|below]]).

===Proof that GCD exists for multivariate polynomials===

In the previous section we have seen that the GCD of polynomials in ''R''[''X''] may be deduced from GCDs in ''R'' and in ''F''[''X'']. A closer look on the proof shows that this allows us to prove the existence of GCDs in ''R''[''X''], if they exist in ''R'' and in ''F''[''X'']. In particular, if GCDs exist in ''R'', and if ''X'' is reduced to one variable, this proves that GCDs exist in ''R''[''X''] (Euclid's algorithm proves the existence of GCDs in ''F''[''X'']).

A polynomial in ''n'' variables may be considered as a univariate polynomial over the ring of polynomials in (''n'' − 1) variables. Thus a recursion on the number of variables shows that if GCDs exists and may be computed in ''R'', then they exist and may be computed in every multivariate polynomial ring over ''R''. In particular, if ''R'' is either the ring of the integers or a field, then GCDs exist in ''R''[''x''&lt;sub&gt;1&lt;/sub&gt;,..., ''x&lt;sub&gt;n&lt;/sub&gt;''], and what precedes provides an algorithm to compute them.

The proof that a polynomial ring over a unique factorization domain is also a unique factorization domain is similar, but it does not provide an algorithm, because there is no general algorithm to factor univariate polynomials over a field (there are examples of fields for which there does not exist any factorization algorithm for the univariate polynomials).

==Pseudo-remainder sequences==

In this section, we consider an [[integral domain]] ''Z'' (typically the ring '''Z''' of the integers) and its field of fractions ''Q'' (typically the field '''Q''' of the rational numbers). Given two polynomials ''A'' and ''B'' in the univariate polynomial ring ''Z''[''X''], the Euclidean division (over ''Q'') of ''A'' by ''B'' provides a quotient and a remainder which may not belong to ''Z''[''X''].

For, if one applies Euclid's algorithm to the following polynomials &lt;ref&gt;D.E. Knuth, the Art of Computer Programming II, Addison-Wesley, 1969, pp. 370-371&lt;/ref&gt;
:&lt;math&gt;X^8+X^6-3 X^4-3 X^3+8 X^2+2 X-5&lt;/math&gt;
and
:&lt;math&gt;3 X^6+5 X^4-4 X^2-9 X+21,&lt;/math&gt;
the successive remainders of Euclid's algorithm are
:&lt;math&gt;-\frac{5}{9}X^4+\frac{1}{9}X^2-\frac{1}{3},&lt;/math&gt;
:&lt;math&gt;-\frac{117}{25}X^2-9X+\frac{441}{25},&lt;/math&gt;
:&lt;math&gt;\frac{233150}{19773}X-\frac{102500}{6591},&lt;/math&gt;
:&lt;math&gt;-\frac{1288744821}{543589225}.&lt;/math&gt;
One sees that, despite the small degree and the small size of the coefficients of the input polynomials, one has to manipulate and simplify integer fractions of rather large size.

{{anchor|pseudo-remainder|pseudo-division}}
The ''pseudo-division'' has been introduced to allow a variant of Euclid's algorithm for which all remainders belong to ''Z''[''X''].

If &lt;math&gt;\deg(A)=a&lt;/math&gt; and &lt;math&gt;\deg(B)=b&lt;/math&gt; and ''a'' ≥ ''b'', the '''pseudo-remainder''' of the pseudo-division of ''A'' by ''B'', denoted by prem(''A'',''B'') is 
:&lt;math&gt;\operatorname{prem}(A,B)=\operatorname{rem}(\operatorname{lc}(B)^{a-b+1}A,B),&lt;/math&gt;
where lc(''B'') is the leading coefficient of ''B'' (the coefficient of ''X''&lt;sup&gt;''b''&lt;/sup&gt;).

The pseudo-remainder of the pseudo-division of two polynomials in ''Z''[''X''] belongs always to ''Z''[''X''].

A '''pseudo-remainder sequence''' is the sequence of the (pseudo) remainders ''r''&lt;sub&gt;''i''&lt;/sub&gt; obtained by replacing the instruction 
:&lt;math&gt;r_{i+1}:=\operatorname{rem}(r_{i-1},r_{i})&lt;/math&gt;
of Euclid's algorithm by 
:&lt;math&gt;r_{i+1}:=\frac{\operatorname{prem}(r_{i-1},r_{i})}{\alpha},&lt;/math&gt;
where ''α'' is an element of ''Z'' that divides exactly every coefficient of the numerator. Different choices of ''α'' give different pseudo-remainder sequences, which are described in the next subsections.

As the common divisors of two polynomials are not changed if the polynomials are multiplied by invertible constants (in ''Q''), the last non zero term in a pseudo-remainder sequence is a GCD (in ''Q''[''X'']) of the input polynomials. Therefore, pseudo-remainder sequences allows computing GCD's in ''Q''[''X''] without introducing fractions in ''Q''.

===Trivial pseudo-remainder sequence===

The simplest (to define) remainder sequence consists in taking always ''α''=1. In practice, it is not interesting, as the size of the coefficients grow exponentially with the degree of the input polynomials. This appears clearly on the example of the preceding section, for which the successive pseudo-remainders are 
:&lt;math&gt;-15\, X^4+3\, X^2-9,&lt;/math&gt;
:&lt;math&gt;15795\, X^2+30375\, X-59535,&lt;/math&gt;
:&lt;math&gt;1254542875143750\, X-1654608338437500,&lt;/math&gt;
:&lt;math&gt;12593338795500743100931141992187500.&lt;/math&gt;
The number of digits of the coefficients of the successive remainders is more than doubled at each iteration of the algorithm. This is a typical behavior of the trivial pseudo-remainder sequences.

=== Primitive pseudo-remainder sequence===

The ''primitive pseudo-remainder sequence'' consists in taking for ''α'' the content of the numerator. Thus all the ''r''&lt;sub&gt;''i''&lt;/sub&gt; are primitive polynomials.

The primitive pseudo-remainder sequence is the pseudo-remainder sequence, which generates the smallest coefficients. However it requires to compute a number of GCD's in ''Z'', and therefore is not sufficiently efficient to be used in practice, especially when ''Z'' is itself a polynomial ring.

With the same input as in the preceding sections, the successive remainders, after division by their content are 
:&lt;math&gt;-5\,X^4+X^2-3,&lt;/math&gt;
:&lt;math&gt;13\,X^2+25\,X-49,&lt;/math&gt;
:&lt;math&gt;4663\,X-6150,&lt;/math&gt;
:&lt;math&gt;1.&lt;/math&gt;
The small size of the coefficients hides the fact that a number of integers GCD and divisions by the GCD have been computed.

=== Subresultant pseudo-remainder sequence===

A subresultant sequence can be also computed with pseudo-remainders. The process consists in choosing ''α'' is such a way that every ''r''&lt;sub&gt;''i''&lt;/sub&gt; is a subresultant polynomial. Surprisingly, the computation of ''α'' is very easy (see below). On the other hand, the proof of correctness of the algorithm is difficult, because it should take into account all the possibilities for the difference of degrees of two consecutive remainders.

The coefficients in the subresultant sequence are rarely much larger than those of the primitive pseudo-remainder sequence. As GCD computations in ''Z'' are not needed, the subresultant sequence with pseudo-remainders gives the most efficient computation.

With the same input as in the preceding sections, the successive remainders are
:&lt;math&gt;15\,X^4-3\,X^2+9,&lt;/math&gt;
:&lt;math&gt;65\,X^2+125\,X-245,&lt;/math&gt;
:&lt;math&gt;9326\,X-12300,&lt;/math&gt;
:&lt;math&gt;260708.&lt;/math&gt;
The coefficients have a reasonable size. They are obtained without any GCD computation, only exact divisions. This makes this algorithm more efficient than that of primitive pseudo-remainder sequences.

The algorithm computing the subresultant  sequence with pseudo-remainders is given below. In this algorithm, the input {{math|(''a'', ''b'')}} is a pair of polynomials in ''Z''[X]. The {{math|''r''&lt;sub&gt;''i''&lt;/sub&gt;}} are the successive pseudo remainders in ''Z''[X], the variables ''i'' and {{math|''d''&lt;sub&gt;''i''&lt;/sub&gt;}} are non negative integers, and the Greek letters denote elements in ''Z''. The functions deg() and rem() denote the degree of a polynomial and the remainder of the Euclidean division. In the algorithm, this remainder is always in ''Z''[X]. Finally the divisions denoted / are always exact and have their result either in ''Z''[X] or in ''Z''.

{{pre2|
{{nowrap|&lt;math&gt;\begin{align}r_0:=a\\ r_1:=b \end{align}&lt;/math&gt;}}
{{nowrap|'''''for''''' (&lt;math&gt;i:=1&lt;/math&gt;; &lt;math&gt;r_i \neq 0&lt;/math&gt;; &lt;math&gt;i:=i+1;&lt;/math&gt;) '''''do'''''}}
  {{nowrap|&lt;math&gt;\begin{align} d_{i}&amp;:=\deg(r_{i-1})-\deg(r_{i})\\ \gamma_{i}&amp;:=\operatorname{lc}(r_{i})
  \end{align}&lt;/math&gt;}}
  {{nowrap|'''if''' &lt;math&gt;i:=1&lt;/math&gt; '''then'''}}
    {{nowrap|&lt;math&gt;\begin{align} \beta_1&amp;:=(-1)^{d_1+1}\\ \psi_1&amp;:=-1 \end{align}&lt;/math&gt;}}
  '''else'''
    {{nowrap|&lt;math&gt;\begin{align} \beta_i&amp;:=-\gamma_{i-1}\psi_i^{d_i}\\ \psi_{i}&amp;:=\frac{(-\gamma_i)^{d_{i-1}}}{\psi_{i-1}^{d_{i-1}-1}} \end{align}&lt;/math&gt;}}
  '''end if'''
  {{nowrap|&lt;math&gt;r_{i+1}:=\frac{\operatorname{rem}(\gamma_i^{d_i +1}r_{i-1},r_{i})}{\beta_i}&lt;/math&gt;}}
'''''end do.'''''
}}
Note: "lc" stands for the leading coefficient, the coefficient of the highest degree of the variable.

This algorithm computes not only the greatest common divisor (the last non zero {{math|''r''&lt;sub&gt;''i''&lt;/sub&gt;}}), but also all the subresultant polynomials: The remainder {{math|''r''&lt;sub&gt;''i''&lt;/sub&gt;}} is the {{math|(deg(''r''&lt;sub&gt;''i''−1&lt;/sub&gt;) − 1)}}-th subresultant polynomial. If {{math|deg(''r''&lt;sub&gt;''i''&lt;/sub&gt;) &lt; deg(''r''&lt;sub&gt;''i''−1&lt;/sub&gt;) − 1}}, the {{math|deg(''r''&lt;sub&gt;''i''&lt;/sub&gt;)}}-th subresultant polynomial is {{math|lc(''r''&lt;sub&gt;''i''&lt;/sub&gt;)&lt;sup&gt;deg(''r''&lt;sub&gt;''i''−1&lt;/sub&gt;)−deg(''r''&lt;sub&gt;''i''&lt;/sub&gt;)−1&lt;/sup&gt;''r''&lt;sub&gt;''i''&lt;/sub&gt;}}. All the other subresultant polynomials are zero.

===Sturm sequence with pseudo-remainders===

One may use pseudo-remainders for constructing sequences having the same properties as [[Sturm sequence]]s. This requires to control the signs of the successive pseudo-remainders, in order to have the same signs as in the Sturm sequence. This may be done by defining a modified pseudo-remainder as follows.

If &lt;math&gt;\deg(A)=a&lt;/math&gt; and &lt;math&gt;\deg(B)=b&lt;/math&gt; and ''a'' ≥ ''b'', the modified pseudo-remainder prem2(''A'', ''B'') of the pseudo-division of ''A'' by ''B'' is 
:&lt;math&gt;\operatorname{prem2}(A,B)=-\operatorname{rem}(|\operatorname{lc}(B)|^{a-b+1}A,B),&lt;/math&gt;
where |lc(''B'')| is the absolute value of the leading coefficient of ''B'' (the coefficient of ''X''&lt;sup&gt;''b''&lt;/sup&gt;).

For input polynomials with integers coefficients, this allows retrieval of Sturm sequences consisting of polynomials with integer coefficients. The subresultant pseudo-remainder sequence may be modified similarly, in which case the signs of the remainders '''coincide''' with those computed over the rationals.

Note that the algorithm for computing the subresultant pseudo-remainder sequence given above  will compute wrong subresultant polynomials if one uses &lt;math&gt;-\mathrm{prem2}(A,B)&lt;/math&gt; instead of &lt;math&gt;\operatorname{prem}(A,B)&lt;/math&gt;.

==Modular GCD algorithm==
If ''f'' and ''g'' are polynomials in ''F''[''x''] for some finitely generated field ''F'', the Euclidean Algorithm is the most natural way to compute their GCD. However, modern [[computer algebra]] systems only use it if ''F'' is finite because of a phenomenon called [[symbolic computation|intermediate expression swell]]. Although degrees keep decreasing during the Euclidean algorithm, if ''F'' is not [[finite field|finite]] then the bitsize of the polynomials can increase (sometimes dramatically) during the computations because repeated arithmetic operations in ''F'' tends to lead to larger expressions. For example, the addition of two rational numbers whose denominators are bounded by ''b'' leads to a rational number whose denominator is bounded by ''b''&lt;sup&gt;2&lt;/sup&gt;, so in the worst case, the bitsize could nearly double with just one operation.

To expedite the computation, take a ring ''D'' for which ''f'' and ''g'' are in ''D''[''x''], and take an ideal ''I'' such that ''D''/''I'' is a finite ring. Then compute the GCD over this finite ring with the Euclidean Algorithm. Using reconstruction techniques ([[Chinese remainder theorem]], [[Rational reconstruction (mathematics)|rational reconstruction]], etc.) one can recover the GCD of ''f'' and ''g'' from its image modulo a number of ideals ''I''. One can prove&lt;ref&gt;{{citation|title=M. van Hoeij, M.B. Monagan: Algorithms for polynomial GCD computation over algebraic function fields. ISSAC 2004: 297–304}}&lt;/ref&gt; that this works provided that one discards modular images with non-minimal degree, and avoids ideals ''I'' modulo which a leading coefficient vanishes.

Suppose &lt;math&gt;F = \mathbb{Q}(\sqrt{3})&lt;/math&gt;, &lt;math&gt;D = \mathbb{Z}[\sqrt{3}]&lt;/math&gt;, &lt;math&gt;f = \sqrt{3}x^3 - 5 x^2 + 4x + 9&lt;/math&gt; and &lt;math&gt;g = x^4 + 4 x^2 + 3\sqrt{3}x - 6&lt;/math&gt;. If we take &lt;math&gt;I=(2)&lt;/math&gt; then &lt;math&gt;D/I&lt;/math&gt; is a [[finite ring]] (not a field since &lt;math&gt;I&lt;/math&gt; is not maximal in &lt;math&gt;D&lt;/math&gt;). The Euclidean algorithm applied to the images of &lt;math&gt;f,g&lt;/math&gt; in &lt;math&gt;(D/I)[x]&lt;/math&gt; succeeds and returns 1. This implies that the GCD of &lt;math&gt;f,g&lt;/math&gt; in &lt;math&gt;F[x]&lt;/math&gt; must be 1 as well. Note that this example could easily be handled by any method because the degrees were too small for expression swell to occur, but it illustrates that if two polynomials have GCD 1, then the modular algorithm is likely to terminate after a single ideal &lt;math&gt;I&lt;/math&gt;.

==See also==
* [[List of polynomial topics]]
* [[Multivariate division algorithm]]

==References==
{{reflist|1}}
*{{cite book|first1=James H.|last1=Davenport|author1-link=James H. Davenport|first2=Yvon|last2=Siret|first3= Évelyne|last3=Tournier|title=Computer algebra: systems and algorithms for algebraic computation|others=Translated from the French by A. Davenport and J.H. Davenport|year=1988|publisher=Academic Press|isbn=978-0-12-204230-0}}
*{{cite book
|author=[[Donald E. Knuth|Knuth, Donald E]]
|title=Seminumerical Algorithms
|series=The Art of Computer Programming
|volume=2
|edition=Third
|location=Reading, Massachusetts
|publisher=Addison-Wesley
|year=1997
|pages=439–461, 678–691&lt;!--   xiv+762 --&gt;
|isbn=0-201-89684-2}}
* {{citation|first1=Rudiger|last1=Loos|chapter=Generalized polynomial remainder sequences|title=Computer Algebra|publisher=Springer Verlag|year=1982|editor1 =B. Buchberger|editor2=R. Loos|editor3=G. Collins}}
* {{citation|title=S.M.M. Javadi, M.B. Monagan: A sparse modular GCD algorithm for polynomials over algebraic function fields. ISSAC 2007: 187–194}}

{{Polynomials}}

[[Category:Polynomials]]
[[Category:Computer algebra]]</text>
      <sha1>lowwc1ugioklj6sgasafef2dcb61ixg</sha1>
    </revision>
  </page>
  <page>
    <title>Quadratic residue code</title>
    <ns>0</ns>
    <id>14433598</id>
    <revision>
      <id>860954436</id>
      <parentid>860954400</parentid>
      <timestamp>2018-09-24T05:24:36Z</timestamp>
      <contributor>
        <ip>117.211.78.47</ip>
      </contributor>
      <comment>/* Weight */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3247">{{distinguish|QR Code}}
A '''quadratic residue code''' is a type of [[cyclic code]].

==Examples==
Examples of quadratic
residue codes include the &lt;math&gt;(7,4)&lt;/math&gt; [[Hamming code]]
over &lt;math&gt;GF(2)&lt;/math&gt;, the &lt;math&gt;(23,12)&lt;/math&gt; [[binary Golay code]]
over &lt;math&gt;GF(2)&lt;/math&gt; and the &lt;math&gt;(11,6)&lt;/math&gt; [[ternary Golay code]]
over &lt;math&gt;GF(3)&lt;/math&gt;.

==Constructions==
There is a quadratic residue code of length &lt;math&gt;p&lt;/math&gt;
over the finite field &lt;math&gt;GF(l)&lt;/math&gt; whenever &lt;math&gt;p&lt;/math&gt;
and &lt;math&gt;l&lt;/math&gt; are primes, &lt;math&gt;p&lt;/math&gt; is odd, and 
&lt;math&gt;l&lt;/math&gt; is a [[quadratic residue]] modulo &lt;math&gt;p&lt;/math&gt;.
Its generator polynomial as a cyclic code is given by
:&lt;math&gt;f(x)=\prod_{j\in Q}(x-\zeta^j)&lt;/math&gt;
where &lt;math&gt;Q&lt;/math&gt; is the set of quadratic residues of
&lt;math&gt;p&lt;/math&gt; in the set &lt;math&gt;\{1,2,\ldots,p-1\}&lt;/math&gt; and
&lt;math&gt; \zeta&lt;/math&gt; is a primitive &lt;math&gt;p&lt;/math&gt;th root of
unity in some finite extension field of &lt;math&gt;GF(l)&lt;/math&gt;.
The condition that &lt;math&gt;l&lt;/math&gt; is a quadratic residue
of &lt;math&gt;p&lt;/math&gt; ensures that the coefficients of &lt;math&gt;f&lt;/math&gt;
lie in &lt;math&gt;GF(l)&lt;/math&gt;. The dimension of the code is
&lt;math&gt;(p+1)/2&lt;/math&gt;.
Replacing &lt;math&gt;\zeta&lt;/math&gt; by another primitive &lt;math&gt;p&lt;/math&gt;-th
root of unity &lt;math&gt;\zeta^r&lt;/math&gt; either results in the same code
or an equivalent code, according to whether or not &lt;math&gt;r&lt;/math&gt;
is a quadratic residue of &lt;math&gt;p&lt;/math&gt;.

An alternative construction avoids roots of unity. Define
:&lt;math&gt;g(x)=c+\sum_{j\in Q}x^j&lt;/math&gt;
for a suitable &lt;math&gt;c\in GF(l)&lt;/math&gt;. When &lt;math&gt;l=2&lt;/math&gt;
choose &lt;math&gt;c&lt;/math&gt; to ensure that &lt;math&gt;g(1)=1&lt;/math&gt;.
If &lt;math&gt;l&lt;/math&gt; is odd, choose  &lt;math&gt;c=(1+\sqrt{p^*})/2&lt;/math&gt;,
where &lt;math&gt;p^*=p&lt;/math&gt; or &lt;math&gt;-p&lt;/math&gt; according to whether
&lt;math&gt;p&lt;/math&gt; is congruent to &lt;math&gt;1&lt;/math&gt; or &lt;math&gt;3&lt;/math&gt;
modulo &lt;math&gt;4&lt;/math&gt;. Then &lt;math&gt;g(x)&lt;/math&gt; also generates
a quadratic residue code; more precisely the ideal of
&lt;math&gt;F_l[X]/\langle X^p-1\rangle&lt;/math&gt; generated by &lt;math&gt;g(x)&lt;/math&gt;
corresponds to the quadratic residue code.

==Weight==
The [[minimum weight]] of a quadratic residue code of length &lt;math&gt;p&lt;/math&gt;
is greater than &lt;math&gt;\sqrt{p}&lt;/math&gt;; this is the '''square root bound'''.

==Extended code==
Adding an overall parity-check digit to a quadratic residue code
gives an '''extended quadratic residue code'''. When
&lt;math&gt;p\equiv 3&lt;/math&gt; (mod &lt;math&gt;4&lt;/math&gt;) an extended quadratic
residue code is self-dual; otherwise it is equivalent but not
equal to its dual. By the '''Gleason–Prange theorem''' (named for [[Andrew Gleason]] and [[Eugene Prange]]), the automorphism group of an extended quadratic residue
code has a subgroup which is isomorphic to
either &lt;math&gt;PSL_2(p)&lt;/math&gt; or &lt;math&gt;SL_2(p)&lt;/math&gt;.

== References ==
*F. J. MacWilliams and N. J. A. Sloane, ''The Theory of Error-Correcting Codes'', North-Holland Publishing Co., Amsterdam-New York-Oxford, 1977.
*{{citation
 | last = Blahut | first = R. E.
 | date = September 2006
 | doi = 10.1109/18.133245
 | issue = 5
 | journal = IEEE Trans. Inf. Theory
 | location = Piscataway, NJ, USA
 | pages = 1269–1273
 | publisher = IEEE Press
 | title = The Gleason-Prange theorem
 | volume = 37}}.

[[Category:Quadratic residue]]
[[Category:Coding theory]]</text>
      <sha1>1b970v0e6rheed5tlayfz2ythxkay58</sha1>
    </revision>
  </page>
  <page>
    <title>Ray–Dutt twist</title>
    <ns>0</ns>
    <id>12518595</id>
    <revision>
      <id>811269258</id>
      <parentid>796679616</parentid>
      <timestamp>2017-11-20T15:33:39Z</timestamp>
      <contributor>
        <username>Project Osprey</username>
        <id>17599853</id>
      </contributor>
      <comment>link to [[helical chirality]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1655">The '''Ray–Dutt twist''' is a mechanism proposed for the [[racemization]] of octahedral complexes containing three bidentate chelate rings.  Such complexes typically adopt an [[octahedral molecular geometry]] in their [[ground state]]s, in which case they possess [[helical chirality]].  The pathway entails formation of an intermediate of C&lt;sub&gt;2v&lt;/sub&gt; [[symmetry group|point group symmetry]].&lt;ref&gt;{{Cite journal |last=Ray |first=P. |last2=Dutt |first2=N. K. |year=1943 |title=Kinetics and Mechanism of Racemization of Optically Active Cobaltic Trisbiguanide Complex |journal=J. Indian Chem. Soc. |volume=20 |pages=81-92}}&lt;/ref&gt;  An alternative pathway that also does not break any metal-ligand bonds is called the [[Bailar twist]].  Both of these mechanism product complexes wherein the ligating atoms (X in the scheme) are arranged in an approximate trigonal prism.

This pathway is called the Ray–Dutt twist in honor of [[Prafulla Chandra Ray]] and N. K. Dutt, the [[inorganic chemistry|inorganic chemist]]s who proposed this process.&lt;ref&gt;{{cite journal
| author = A. Rodger, B. F. G. Johnson
| title = Which is more likely: the Ray–Dutt twist or the Bailar twist?
| journal = Inorganic Chemistry
| year = 1988 
| volume = 27 
| issue = 18
| pages = 3061–3062
| doi = 10.1021/ic00291a001 }}&lt;/ref&gt;

[[File:Ray-Dutt.png|thumb|center|400px|Ray-Dutt mechanism.]]

==See also==
* [[Pseudorotation]]
* [[Bailar twist]]
* [[Bartell mechanism]]
* [[Berry mechanism]]
* [[Fluxional molecule]]

==References==
&lt;references/&gt;

{{DEFAULTSORT:Ray-Dutt twist}}
[[Category:Molecular geometry]]
[[Category:Stereochemistry]]
[[Category:Coordination chemistry]]</text>
      <sha1>ikbhzzqcg8rtkn2ocss6j789bac7r2v</sha1>
    </revision>
  </page>
  <page>
    <title>Rhombitetrapentagonal tiling</title>
    <ns>0</ns>
    <id>38266327</id>
    <revision>
      <id>786601646</id>
      <parentid>631122480</parentid>
      <timestamp>2017-06-20T12:58:50Z</timestamp>
      <contributor>
        <username>CBM</username>
        <id>1108292</id>
      </contributor>
      <minor/>
      <comment>Manually reviewed edit to replace magic words per [[Special:PermanentLink/772743896#Future_of_magic_links|local rfc]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1663">{{Uniform hyperbolic tiles db|Uniform hyperbolic tiling stat table|U54_02}}
In [[geometry]], the '''rhombitetrapentagonal tiling''' is a uniform tiling of the [[Hyperbolic geometry|hyperbolic plane]]. It has [[Schläfli symbol]] of t&lt;sub&gt;0,2&lt;/sub&gt;{4,5}.

== Dual tiling ==
The dual is called the ''deltoidal tetrapentagonal tiling'' with [[face configuration]] V.4.4.4.5.
:[[File:Deltoidal_tetrapentagonal_tiling.png|240px]]

== Related polyhedra and tiling ==
{{Order 5-4 tiling table}}

{{Expanded4 table}}

==References==
* [[John Horton Conway|John H. Conway]], Heidi Burgiel, Chaim Goodman-Strass, ''The Symmetries of Things'' 2008, {{isbn|978-1-56881-220-5}} (Chapter 19, The Hyperbolic Archimedean Tessellations)
* {{Cite book|title=The Beauty of Geometry: Twelve Essays|year=1999|publisher=Dover Publications|lccn=99035678|isbn=0-486-40919-8|chapter=Chapter 10: Regular honeycombs in hyperbolic space}}

==See also==
{{Commonscat|Uniform tiling 4-4-4-5}}
*[[Uniform tilings in hyperbolic plane]]
*[[List of regular polytopes]]

== External links ==
*{{MathWorld | urlname= HyperbolicTiling | title = Hyperbolic tiling}}
*{{MathWorld | urlname=PoincareHyperbolicDisk | title = Poincaré hyperbolic disk }}
* [http://bork.hampshire.edu/~bernie/hyper/ Hyperbolic and Spherical Tiling Gallery]
* [http://geometrygames.org/KaleidoTile/index.html KaleidoTile 3: Educational software to create spherical, planar and hyperbolic tilings]
* [http://www.plunk.org/~hatch/HyperbolicTesselations Hyperbolic Planar Tessellations, Don Hatch]

{{Tessellation}}

[[Category:Hyperbolic tilings]]
[[Category:Isogonal tilings]]
[[Category:Uniform tilings]]

{{geometry-stub}}</text>
      <sha1>15hlv185ur7k5tc8uxmp764x6fksisi</sha1>
    </revision>
  </page>
  <page>
    <title>Rüdiger Gamm</title>
    <ns>0</ns>
    <id>14098497</id>
    <revision>
      <id>865020594</id>
      <parentid>865020576</parentid>
      <timestamp>2018-10-21T04:59:58Z</timestamp>
      <contributor>
        <username>Batchketch</username>
        <id>34897096</id>
      </contributor>
      <comment>/* Early life */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3259">{{Expand German|Rüdiger Gamm|date=May 2015}}
'''Rüdiger Gamm''' (born July 10, 1971) is a [[Germany|German]] "[[mental calculator]]". He attained the ability to mentally evaluate large arithmetic expressions at the age of 21.{{Citation needed|date=September 2017}} He can also speak backwards, and calculate [[calendar]]s.{{Citation needed|date=September 2017}} Featured on the [[Discovery Channel]] program ''[[The Real Superhumans]]'',&lt;ref name=imdb&gt;{{cite web|url=https://www.imdb.com/name/nm2586540/|title=Rüdiger Gamm|website=imdb.com|access-date=7 April 2018}}&lt;/ref&gt; he was examined by [[Allan Snyder]], an expert on [[autistic savant|savant]]s, who concluded that Gamm's ability was not a result of [[savant syndrome]] but connected to [[genetics]].

In terms of mental calculations, Rüdiger's most notable talent is the ability to memorize large powers. In the 2008 [[Mental Calculation World Cup]] in Leipzig, he recited 81&lt;sup&gt;100&lt;/sup&gt;, which took approximately 2 minutes and 30 seconds. In the tournament itself, he performed strongly, finishing in 5th position overall. He also held a seminar in 2012 at the BOLDTalks event at [[DUCTAC]] (Dubai).&lt;ref name=Dubai/&gt;

==Early life==
Rüdiger Gamm was born on July 10, 1971, in [[Welzheim, Germany]]. Gamm stated that he learnt how to speak backwards before learning how to speak forwards which prompted classmates to tease him or avoid him. Gamm was a self-proclaimed underachiever at school and stated "I was the worst in my class at maths. I failed my exam six times and hated school a lot. The only thing I was interested in was [[bodybuilding]]. I wanted to be like [[Arnold Schwarzenegger]], rather than a mathematician."&lt;ref name=Dubai&gt;{{cite web|url=https://www.thenational.ae/arts-culture/maths-genius-to-hold-dubai-seminar-for-would-be-savants-1.353852|title=Maths genius to hold Dubai seminar for would-be savants|last=Berger|first=Hugo|date=|website=|access-date=22 March 2017}}&lt;/ref&gt; Gamm recalls, shortly after leaving college, listening to the radio and calculating alongside a champion mathematician. After Gamm answered the calculations faster than the champion, he started training his brain into the field of mental math and, a year later, appeared on the German TV game show [[Wetten, dass..?]] (in the [[United States]] it is known as [[Wanna Bet?]] and in the [[United Kingdom]] known as [[You Bet!]].) Gamm won the show with the highest score achieved and received a prize of 8,400 [[Deutsche Marks]].&lt;ref name=Dubai/&gt;

==See also==

== References ==
{{Reflist}}

== External links ==

* [https://www.youtube.com/watch?v=zcFHzhoV3As The Real Superhumans], [[Discovery Channel]], 2007
* [https://www.youtube.com/watch?v=8b2jOcKI798 Deutschlands Superhirn 2013]
* [https://www.youtube.com/watch?v=0WAEiPkr8eo Web Interview 2016]
* [https://www.youtube.com/watch?v=FW0c4UcM7kk Japanese television appearance (2007) - Part 1]
* [https://www.youtube.com/watch?v=68yGYvMxQKI Japanese television appearance (2007) - Part 2]
* [https://www.youtube.com/watch?v=tpkZrUFiaLE Japanese television appearance (2007) - Part 3]


{{Authority control}}

{{DEFAULTSORT:Gamm, Rudiger}}
[[Category:Mental calculators]]
[[Category:1971 births]]
[[Category:Living people]]


{{germany-bio-stub}}</text>
      <sha1>ddgjptessofnag6qwo59sv3plk8jsdy</sha1>
    </revision>
  </page>
  <page>
    <title>Set intersection oracle</title>
    <ns>0</ns>
    <id>45378348</id>
    <revision>
      <id>788929196</id>
      <parentid>679470672</parentid>
      <timestamp>2017-07-04T09:51:06Z</timestamp>
      <contributor>
        <ip>132.65.248.117</ip>
      </contributor>
      <comment>/* Minimum memory, maximum query time */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3841">{{technical|date=February 2015}}

A '''set intersection oracle (SIO)''' is a [[data structure]] which represents a collection of sets and can quickly answer queries about whether the [[set intersection]] of two given sets is non-empty.

The input to the problem is ''n'' finite sets. The sum of the sizes of all sets is ''N'' (which also means that there are at most ''N'' distinct elements). The SIO should quickly answer any query of the form:
: "Does the set ''S''&lt;sub&gt;''i''&lt;/sub&gt; intersect the set ''S''&lt;sub&gt;''k''&lt;/sub&gt;"?

== Minimum memory, maximum query time ==

Without any pre-processing, a query can be answered by inserting the elements of ''S''&lt;sub&gt;''i''&lt;/sub&gt; into a temporary [[hash table]] and then checking for each element of ''S''&lt;sub&gt;''k''&lt;/sub&gt; whether it is in the hash table. The query time is &lt;math&gt;O(|S_i|+|S_j|)=O(N)&lt;/math&gt;.

== Maximum memory, minimum query time ==

Alternatively, we can pre-process the sets and create an ''n''-by-''n'' table where the intersection information is already entered. Then the query time is &lt;math&gt;O(1)&lt;/math&gt;, but the memory required is &lt;math&gt;O(n^2)&lt;/math&gt;.

== A compromise ==

Define a "large set" as a set with at least &lt;math&gt;\sqrt{N}&lt;/math&gt; elements. Obviously there are at most &lt;math&gt;\sqrt{N}&lt;/math&gt; such sets. Create a table of intersection data between every large set to every other large set. This requires &lt;math&gt;O(N)&lt;/math&gt; memory. Additionally, for each large set, keep a hash table of all its elements. This requires additional &lt;math&gt;O(N^{3/2})&lt;/math&gt; memory.

Given two sets, there are three possible cases:
# Both sets are large. Then just read the answer to the intersection query from the table, in time &lt;math&gt;O(1)&lt;/math&gt;.
# Both sets are small. Then insert the elements of one of them into a hash table and check the elements of the other one; because the sets are small, the required time is &lt;math&gt;O(\sqrt{N})&lt;/math&gt;.
# One set is large and one set is small. Loop over all elements in the small set and check them against the hash table of the large set. The required time is again &lt;math&gt;O(\sqrt{N})&lt;/math&gt;.

In general, if we define a "large set" as a set with at least &lt;math&gt;N^c&lt;/math&gt; elements, then the number of large set is at most &lt;math&gt;N^{1-c}&lt;/math&gt; so the memory required is &lt;math&gt;O(N^{2-c})&lt;/math&gt;, and the query time is &lt;math&gt;O(N^c)&lt;/math&gt;.

== Reduction to approximate distance oracle ==

The SIO problem can be reduced to the approximate [[distance oracle]] (DO) problem, in the following way.&lt;ref name=pr10&gt;{{Cite conference| doi = 10.1109/FOCS.2010.83| title = Distance Oracles beyond the Thorup–Zwick Bound| conference = 2010 IEEE 51st Annual Symposium on Foundations of Computer Science (FOCS)| pages = 815| year = 2010| last1 = [[Mihai Patrascu|Patrascu]] | first1 = M. | last2 = Roditty | first2 = L. | isbn = 978-1-4244-8525-3}}&lt;/ref&gt;
* Build an undirected bipartite graph where one part contains a node for each of the ''n'' sets, and the other part contains a node for each of the (at most) ''N'' elements contained in the sets.
* There is an edge between a set and an element, iff the set contains the element.

This graph has the following properties:
* If two sets intersect, the distance between them is 2 (from one set, to an element in the intersection, to the other set).
* If two sets do not intersect, the distance between them is at least 4.

So, with a DO whose approximation factor of less than 2, we can solve the SIO problem.

It is believed that the SIO problem does not have a non-trivial solution. I.e., it requires &lt;math&gt;\Omega(n^2)&lt;/math&gt; space to answer queries in time &lt;math&gt;O(1)&lt;/math&gt;. If this conjecture is true, this implies that there is no DO with an approximation factor of less than 2 and a constant query time.&lt;ref name=pr10/&gt;

== References ==
{{reflist}}


[[Category:Data structures]]
[[Category:Set theory]]</text>
      <sha1>nvubx7gcx46ib61vlzavgrzb8byt8jm</sha1>
    </revision>
  </page>
  <page>
    <title>Silver ratio</title>
    <ns>0</ns>
    <id>920526</id>
    <revision>
      <id>864788066</id>
      <parentid>864787967</parentid>
      <timestamp>2018-10-19T13:21:20Z</timestamp>
      <contributor>
        <ip>116.15.69.115</ip>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="10175">{{Refimprove|date=April 2016}}
{{For|a ratio also known as the silver ratio&lt;ref&gt;Weisstein, Eric W. (2002). ''CRC Concise Encyclopedia of Mathematics, Second Edition'', p.1207-8. CRC Press. {{isbn|9781420035223}}.&lt;/ref&gt;|Golden ratio conjugate}}
{{Redirects|Silver triangle||Kepler triangle}}
[[File:Silver rectangle.svg|thumb|Silver rectangle]]
{| class="infobox bordered" cellpadding=5
| colspan="2" align="center" | {{Irrational numbers}}
|-
|[[Binary numeral system|Binary]]
| {{gaps|10.0110|1010|0000|1001|1110|…}}
|-
| [[Decimal]]
| {{gaps|2.41421|35623|73095|0488…}}
|-
| [[Hexadecimal]]
| {{gaps|2.6A09|E667|F3BC|C908|B2F…}}
|-
| [[Continued fraction]]
| &lt;math&gt;\textstyle 2 + \cfrac{1}{2 + \cfrac{1}{2 + \cfrac{1}{2 + \cfrac{1}{\ddots}}}}&lt;/math&gt;
|-
| [[Algebraic number|Algebraic form]]
| 1 + {{sqrt|2}}
|}
[[File:Silver ratio octagon.png|thumb|120px|Silver ratio within the octagon]]

In [[mathematics]], two quantities are in the '''silver ratio''' (also '''silver mean''' or '''silver constant''') if the [[ratio]] of the sum of the smaller and twice the larger of those quantities, to the larger quantity, is the same as the ratio of the larger one to the smaller one (see below). This defines the silver ratio as an [[irrational number|irrational]] [[mathematical constant]], whose value of one plus the [[square root of 2]] is approximately 2.4142135623. Its name is an allusion to the [[golden ratio]]; analogously to the way the golden ratio is the limiting ratio of consecutive [[Fibonacci number]]s, the silver ratio is the limiting ratio of consecutive [[Pell number]]s. The silver ratio is denoted by {{math|''δ&lt;sub&gt;S&lt;/sub&gt;''}}.

[[Mathematician]]s have studied the silver ratio since the time of the Greeks (although perhaps without giving a special name until recently) because of its connections to the square root of 2, its convergents, [[square triangular number]]s, [[Pell numbers]], [[octagon]]s and the like.

The relation described above can be expressed algebraically:

:&lt;math&gt; \frac{2a + b}{a} = \frac{a}{b} \equiv \delta_S&lt;/math&gt;

or equivalently,

:&lt;math&gt; 2 + \frac{b}{a} = \frac{a}{b} \equiv \delta_S&lt;/math&gt;

The silver ratio can also be defined by the simple [[continued fraction]] [2; 2, 2, 2, ...]:

:&lt;math&gt; 2 + \cfrac{1}{2 + \cfrac{1}{2 + \cfrac{1}{2 + \ddots}}} =\delta_S &lt;/math&gt;

The [[Convergent (continued fraction)|convergents]] of this continued fraction ({{sfrac|2|1}}, {{sfrac|5|2}}, {{sfrac|12|5}}, {{sfrac|29|12}}, {{sfrac|70|29}}, ...) are ratios of consecutive Pell numbers. These fractions provide accurate [[Diophantine approximation|rational approximations]] of the silver ratio, analogous to the approximation of the golden ratio by ratios of consecutive Fibonacci numbers.

== Calculation ==

For comparison, two quantities ''a'', ''b'' with ''a''&amp;nbsp;&gt;&amp;nbsp;''b''&amp;nbsp;&gt;&amp;nbsp;0 are said to be in the ''[[golden ratio]]'' {{math|''φ''}} if,

:&lt;math&gt; \frac{a+b}{a} = \frac{a}{b} = \varphi&lt;/math&gt;

However, they are in the ''silver ratio'' {{math|''δ&lt;sub&gt;S&lt;/sub&gt;''}} if,

:&lt;math&gt; \frac{2a+b}{a} = \frac{a}{b} = \delta_S.&lt;/math&gt;

Equivalently,

:&lt;math&gt; 2+\frac{b}{a} = \frac{a}{b} = \delta_S&lt;/math&gt;

Therefore,

:&lt;math&gt; 2 + \frac{1}{\delta_S} = \delta_S. &lt;/math&gt;

Multiplying by {{math|''δ&lt;sub&gt;S&lt;/sub&gt;''}} and rearranging gives

:&lt;math&gt;{\delta_S}^2 - 2\delta_S - 1 = 0.&lt;/math&gt;

Using the [[quadratic formula]], two solutions can be obtained. Because {{math|''δ&lt;sub&gt;S&lt;/sub&gt;''}} is the ratio of positive quantities, it is necessarily positive, so,

:&lt;math&gt;\delta_S = 1 + \sqrt{2} = 2.41421356237\dots&lt;/math&gt;

== Properties ==
[[File:Silver rectangle repeats.svg|thumb|If one cuts two of the largest squares possible off of a silver rectangle one is left with a silver rectangle, to which the process may be repeated...]]
[[File:Silver spiral approximation.png|150px|thumb|Silver spirals within the silver rectangle]]

=== Number-theoretic properties ===
The silver ratio is a [[Pisot–Vijayaraghavan number]] (PV number), as its conjugate {{math|1 − {{sqrt|2}} {{=}} {{sfrac|−1|''δ&lt;sub&gt;S&lt;/sub&gt;''}} ≈ −0.41}} has absolute value less than 1. In fact it is the second smallest quadratic PV number after the golden ratio. This means the distance from {{math|''δ{{su|p=&amp;nbsp;n|b=S}}''}} to the nearest integer is {{math|{{sfrac|1|''δ{{su|p=&amp;nbsp;n|b=S}}''}} ≈ 0.41&lt;sup&gt;''n''&lt;/sup&gt;}}. Thus, the sequence of [[fractional part]]s of {{math|''δ{{su|p=&amp;nbsp;n|b=S}}''}}, {{math|''n'' {{=}} 1, 2, 3, ...}} (taken as elements of the torus) converges. In particular, this sequence is not [[equidistributed sequence|equidistributed mod 1]].

=== Powers ===
The lower powers of the silver ratio are
:&lt;math&gt; \delta_S^{-1} = 1 \delta_S - 2 = [0;2,2,2,2,2,\dots] \approx 0.41421&lt;/math&gt;
:&lt;math&gt; \delta_S^0\!\ \!\ = 0 \delta_S + 1 = [1] = 1&lt;/math&gt;
:&lt;math&gt; \delta_S^1\!\ \!\ = 1 \delta_S + 0 = [2;2,2,2,2,2,\dots] \approx 2.41421&lt;/math&gt;
:&lt;math&gt; \delta_S^2\!\ \!\ = 2 \delta_S + 1 = [5;1,4,1,4,1,\dots] \approx 5.82842&lt;/math&gt;
:&lt;math&gt; \delta_S^3\!\ \!\ = 5 \delta_S + 2 = [14;14,14,14,\dots] \approx 14.07107&lt;/math&gt;
:&lt;math&gt; \delta_S^4\!\ \!\ = 12\delta_S + 5 = [33;1,32,1,32,\dots] \approx 33.97056 &lt;/math&gt;

The powers continue in the pattern
:&lt;math&gt; \delta_S^n = K_n\delta_S + K_{n-1} &lt;/math&gt;
where
:&lt;math&gt; K_n = 2 K_{n-1} + K_{n-2} &lt;/math&gt;
For example, using this property:
:&lt;math&gt; \!\ \delta_S^5 = 29\delta_S + 12 = [82;82,82,82,\dots] \approx 82.01219 &lt;/math&gt;

Using {{math|''K''&lt;sub&gt;0&lt;/sub&gt; {{=}} 1}} and {{math|''K''&lt;sub&gt;1&lt;/sub&gt; {{=}} 2}} as initial conditions, a [[Binet's formula|Binet]]-like formula results from solving the recurrence relation
:&lt;math&gt; \!\ K_n = 2 K_{n-1} + K_{n-2} &lt;/math&gt;
which becomes
:&lt;math&gt; \!\ K_n = \tfrac{1}{2\sqrt{2}} \left(\delta_S^{n+1} - {(2-\delta_S)}^{n+1}\right) &lt;/math&gt;

=== Trigonometric properties ===
{{see also|Trigonometric constants expressed in real radicals #22.5°: regular octagon}}
The silver ratio is intimately connected to trigonometric ratios for {{math|{{sfrac|π|8}} {{=}} 22.5°}}.
:&lt;math&gt;\sin \tfrac{\pi}{8} = \frac{\sqrt{2 - \sqrt 2}}{2}=\frac{\sqrt{1-1/ \delta_s}}{2} &lt;/math&gt;
:&lt;math&gt;\cos \tfrac{\pi}{8} = \frac{\sqrt{2 + \sqrt 2}}{2}=\frac{\sqrt{1+\delta_s}}{2} &lt;/math&gt;
:&lt;math&gt;\tan \tfrac{\pi}{8} = \sqrt{2}-1= \frac{1}{\delta_s} &lt;/math&gt;
:&lt;math&gt;\cot \tfrac{\pi}{8} = \tan \tfrac{3\pi}{8} = \sqrt{2}+1=\delta_s &lt;/math&gt;

So the area of a regular octagon with side length {{math|''a''}} is given by
:&lt;math&gt;A = \textstyle 2a^2 \cot \tfrac{\pi}{8} = 2(1+\sqrt{2})a^2 \simeq 4.828427 a^2.&lt;/math&gt;

== Paper sizes and silver rectangles ==
&lt;!-- linked from redirect [[Silver rectangles]] --&gt;
{{For|the square root of {{sqrt|2}} rectangle, as in origami|ISO 216#Application}}

[[File:A size illustration2.svg|150px|right]]
The [[paper size]]s under [[ISO 216]] are [[rectangle]]s in the proportion 1:{{sqrt|2}} (approximately 1:1.4142135 decimal), sometimes called "A4 rectangles". Removing a largest possible square from a sheet of such paper leaves a rectangle with proportions {{nowrap|1 : ({{sqrt|2}} − 1)}} which is the same as {{nowrap|(1 + {{sqrt|2}}) : 1}}, the silver ratio. Removing a largest square from one of ''these'' sheets leaves one again with aspect ratio 1:{{sqrt|2}}. A rectangle whose aspect ratio is the silver ratio is sometimes called a '''silver rectangle''' by analogy with [[golden rectangle]]s. Confusingly, "silver rectangle" can also refer to the paper sizes specified by ISO 216.&lt;ref&gt;{{cite web|url=http://www.britishorigami.info/academic/lister/a4.php|title=The A4 rectangle|last=Lister|first=David|work=The Lister List|publisher=British Origami Society|location=England|accessdate=2009-05-06}}&lt;/ref&gt;

[[File:Octagon1.png|150px|right]]
Removing the largest possible square from either kind yields a silver rectangle of the other kind, and then repeating the process once more gives a rectangle of the original shape but smaller by a linear factor of {{nowrap|1 + {{sqrt|2}}}}.&lt;ref name="kapusta"&gt;{{citation|last=Kapusta|first=Janos|title=The square, the circle, and the golden proportion: a new class of geometrical constructions|journal=Forma|volume=19|year=2004|pages=293–313|url=http://www.scipress.org/journals/forma/pdf/1904/19040293.pdf}}.&lt;/ref&gt;

However, only the 1:{{sqrt|2}} rectangles (rectangles with the shape of ISO 216 paper) have the property that by cutting the rectangle in half across its long side produces two smaller rectangles of the same aspect ratio.

The silver rectangle is connected to the regular octagon. If a regular octagon is partitioned into two isosceles trapezoids and a rectangle, then the rectangle is a silver rectangle with an aspect ratio of 1:{{math|''δ''&lt;sub&gt;''S''&lt;/sub&gt;}}, and the 4 sides of the trapezoids are in a ratio of 1:1:1:{{math|''δ''&lt;sub&gt;''S''&lt;/sub&gt;}}. If the edge length of a regular octagon is {{math|''t''}}, then the [[inscribed figure|inradius]] of the octagon (the distance between opposite sides) is {{math|''δ''&lt;sub&gt;''S''&lt;/sub&gt;''t''}}, and the area of the octagon is {{math|2''δ''&lt;sub&gt;''S''&lt;/sub&gt;''t''&lt;sup&gt;2&lt;/sup&gt;}}.&lt;ref name="kapusta"/&gt;

==See also==
*[[Metallic mean]]s
*[[Ammann–Beenker tiling]]

== References ==
{{Reflist}}

== Further reading ==
*Buitrago, Antonia Redondo (2008). "Polygons, Diagonals, and the Bronze Mean", ''Nexus Network Journal 9,2: Architecture and Mathematics'', p.321-2. Springer Science &amp; Business Media. {{isbn|9783764386993}}.

== External links ==
*{{mathworld|urlname=SilverRatio|title=Silver Ratio}}
*"[http://personal.maths.surrey.ac.uk/ext/R.Knott/Fibonacci/cfINTRO.html#silver  An Introduction to Continued Fractions: The Silver Means]", '' Fibonacci Numbers and the Golden Section''.
*"[http://www.maecla.it/tartapelago/museo/oro/rettangoli/en%20silverrectangle.htm Silver rectangle and its sequence]" at Tartapelago by Giorgio Pietrocola
{{Algebraic numbers}}
{{Fractions and ratios}}
{{Irrational number}}
{{Metallic ratios}}

{{DEFAULTSORT:Silver Ratio}}
[[Category:Algebraic numbers]]
&lt;!--[[Category:Continued fractions]]--&gt;[[Category:Periodic continued fractions]]
[[Category:Irrational numbers]]
[[Category:Quadratic irrational numbers]]
[[Category:Mathematical constants]]
[[Category:Metallic means]]
[[Category:Ratios]]</text>
      <sha1>kauvxgsg3q2ssumhz352ozsfv951zjn</sha1>
    </revision>
  </page>
  <page>
    <title>Superperfect number</title>
    <ns>0</ns>
    <id>16911683</id>
    <revision>
      <id>865633992</id>
      <parentid>854296852</parentid>
      <timestamp>2018-10-25T05:17:47Z</timestamp>
      <contributor>
        <username>Ciphers</username>
        <id>7643502</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4570">In mathematics, a '''superperfect number''' is a positive [[integer]] ''n'' that satisfies

:&lt;math&gt;\sigma^2(n)=\sigma(\sigma(n))=2n\, ,&lt;/math&gt;

where σ is the [[divisor summatory function]]. Superperfect numbers are a generalization of [[perfect number]]s.  The term was coined by [[Suryanarayana]] (1969).&lt;ref name=Guy99/&gt;

The first few superperfect numbers are :

:[[2 (number)|2]], [[4 (number)|4]], [[16 (number)|16]], [[64 (number)|64]], [[4096 (number)|4096]], [[65536 (number)|65536]], 262144, 1073741824, ... {{OEIS|id=A019279}}.

To illustrate: it can be seen that 16 is a superperfect number as σ(16) = 1 + 2 + 4 + 8 + 16 = 31, and σ(31) = 1 + 31 = 32, thus σ(σ(16)) = 32 = 2 × 16.

If ''n'' is an ''even'' superperfect number, then ''n'' must be a power of 2, 2&lt;sup&gt;''k''&lt;/sup&gt;, such that 2&lt;sup&gt;''k''+1&lt;/sup&gt; − 1 is a [[Mersenne prime]].&lt;ref name="Guy99" /&gt;&lt;ref name="mathworld"&gt;{{MathWorld|urlname=SuperperfectNumber |title=Superperfect Number }}&lt;/ref&gt;

It is not known whether there are any [[Odd number|odd]] superperfect numbers. An odd superperfect number ''n'' would have to be a square number such that either ''n'' or σ(''n'') is divisible by at least three distinct primes. &lt;ref name=mathworld/&gt; There are no odd superperfect numbers below 7{{e|24}}.&lt;ref name=Guy99&gt;Guy (2004) p. 99.&lt;/ref&gt;

==Generalizations==
Perfect and superperfect numbers are examples of the wider class of ''m''-superperfect numbers, which satisfy

:&lt;math&gt; \sigma^m(n) = 2n , &lt;/math&gt;

corresponding to ''m''=1 and 2 respectively.  For ''m'' ≥ 3 there are no even ''m''-superperfect numbers.&lt;ref name=Guy99/&gt;

The ''m''-superperfect numbers are in turn examples of (''m'',''k'')-perfect numbers which satisfy&lt;ref&gt;Cohen &amp; te Riele (1996)&lt;/ref&gt;

:&lt;math&gt;\sigma^m(n)=kn\, .&lt;/math&gt;

With this notation, perfect numbers are (1,2)-perfect, [[multiperfect number]]s are (1,''k'')-perfect,  superperfect numbers are (2,2)-perfect and ''m''-superperfect numbers are (''m'',2)-perfect.&lt;ref&gt;Guy (2007) p.79&lt;/ref&gt;  Examples of classes of (''m'',''k'')-perfect numbers are:

:{| class="wikitable"
|-
! ''m''
! ''k''
! (''m'',''k'')-perfect numbers
! [[OEIS]] sequence
|-
| 2
| 2
| 2, 4, 16, 64, 4096, 65536, 262144
| {{OEIS link|A019279}}
|-
| 2
| 3
| 8, 21, 512
| {{OEIS link|A019281}}
|-
| 2
| 4
| 15, 1023, 29127
| {{OEIS link|A019282}}
|-
| 2
| 6
| 42, 84, 160, 336, 1344, 86016, 550095, 1376256, 5505024 
| {{OEIS link|A019283}}
|-
| 2
| 7
| 24, 1536, 47360, 343976
| {{OEIS link|A019284}}
|-
| 2
| 8
| 60, 240, 960, 4092, 16368, 58254, 61440, 65472, 116508, 466032, 710400, 983040, 1864128, 3932160, 4190208, 67043328, 119304192, 268173312, 1908867072 
| {{OEIS link|A019285}}
|-
| 2
| 9
| 168, 10752, 331520, 691200, 1556480, 1612800, 106151936 
| {{OEIS link|A019286}}
|-
| 2
| 10
| 480, 504, 13824, 32256, 32736, 1980342, 1396617984, 3258775296
| {{OEIS link|A019287}}
|-
| 2
| 11
| 4404480, 57669920, 238608384 
| {{OEIS link|A019288}}
|-
| 2
| 12
| 2200380, 8801520, 14913024, 35206080, 140896000, 459818240, 775898880, 2253189120  
| {{OEIS link|A019289}}
|-
| 3
| any
| 12, 14, 24, 52, 98, 156, 294, 684, 910, 1368, 1440, 4480, 4788, 5460, 5840, ...  
| {{OEIS link|A019292}}
|-
| 4
| any
| 2, 3, 4, 6, 8, 10, 12, 15, 18, 21, 24, 26, 32, 39, 42, 60, 65, 72, 84, 96, 160, 182, ...  
| {{OEIS link|A019293}}
|}

== Notes ==
{{reflist}}

== References ==
{{refbegin}}
*{{PlanetMath |urlname=SuperperfectNumber |title=Superperfect Number}}
*{{cite journal |first1=G. L. |last1=Cohen |first2=H. J. J. |last2=te Riele |title=Iterating the sum-of-divisors function |journal=[[Experimental Mathematics (journal)|Experimental Mathematics]] |volume=5 |year=1996 |pages=93–100 |zbl=0866.11003 |doi=10.1080/10586458.1996.10504580}}
* {{cite book |last=Guy |first=Richard K. |authorlink=Richard K. Guy |title=Unsolved problems in number theory |publisher=[[Springer-Verlag]] |edition=3rd | year=2004 |isbn=978-0-387-20860-2 |zbl=1058.11001 |at=B9}}
* {{cite book | editor1-last=Sándor | editor1-first=József | editor2-last=Mitrinović | editor2-first=Dragoslav S. | editor3-last=Crstici |editor3-first=Borislav | title=Handbook of number theory I | location=Dordrecht | publisher=[[Springer-Verlag]] | year=2006 | isbn=1-4020-4215-9 | zbl=1151.11300 }}
* {{cite journal |zbl=0165.36001 |last=Suryanarayana |first=D. |title=Super perfect numbers |journal=Elem. Math. |volume=24 |pages=16–17 |year=1969}}
{{refend}}


{{Divisor classes}}
{{Classes of natural numbers}}

[[Category:Divisor function]]
[[Category:Integer sequences]]
[[Category:Unsolved problems in mathematics]]</text>
      <sha1>80y0y4lv6qhtyerectc2s55luzs4z1a</sha1>
    </revision>
  </page>
  <page>
    <title>Symbolic-numeric computation</title>
    <ns>0</ns>
    <id>22288224</id>
    <revision>
      <id>862653909</id>
      <parentid>800737288</parentid>
      <timestamp>2018-10-05T19:56:36Z</timestamp>
      <contributor>
        <username>Liberio</username>
        <id>1955461</id>
      </contributor>
      <comment>professional organization as a start for improving this stub</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2610">In [[mathematics]] and [[computer science]], '''symbolic-numeric computation''' is the use of [[software]] that combines [[Symbolic computation|symbolic]] and [[numerical analysis|numeric]] methods to solve problems.

== Background ==



== Computational Algebraic Geometry ==


==References==
* {{cite book | url = https://books.google.com/books?id=BlRlhmwSPwMC | title = Symbolic-numeric Computation | first1 = Dongming | last1 = Wang | first2 = Lihong | last2 = Zhi | publisher = Springer | year = 2007 | isbn = 3-7643-7983-9 }}
* {{cite book | citeseerx = 10.1.1.135.1680 | chapter = SYNAPS: A Library for Dedicated Applications in Symbolic Numeric Computing | first1 = Bernard | last1 = Mourrain | first2 = Jean-Pascal | last2 = Pavone | first3 = Philippe | last3 = Trebuchet | first4 = Elias P. | last4 = Tsigaridas | first5 = Julien | last5 = Wintz | title = Software for Algebraic Geometry | series = The IMA Volumes in Mathematics and its Applications | year = 2008 | volume = 148 | pages = 81–109 | doi = 10.1007/978-0-387-78133-4_6 }}
* {{cite book | chapterurl = http://www4.ncsu.edu/~kaltofen/bibliography/01/symnum.pdf | chapter = Hybrid methods | url = https://books.google.com/books?id=-U_j6VoUvPAC | title = Computer algebra handbook: foundations, applications, systems, Volume 1 | editor1-first = Johannes | editor1-last = Grabmeier | editor2-first = Erich | editor2-last = Kaltofen | editor3-first = Volker | editor3-last = Weispfenning | publisher = Springer | year = 2003 | isbn = 978-3-540-65466-7 }}
* {{cite book | url = https://books.google.com/books?id=dWhYcTGakBcC | title = Approximate Commutative Algebra | first1 = Lorenzo | last1 = Robbiano | first2 = John | last2 = Abbott | publisher = Springer | year = 2009 | isbn = 978-3-211-99313-2 }}
* {{cite book | url = https://www.springer.com/mathematics/computational+science+%26+engineering/book/978-3-7091-0793-5 | title = Numerical and Symbolic Scientific Computing | editor1-last = Langer | editor1-first = Ulrich | editor2-last = Paule | editor2-first = Peter|editor2-link=Peter Paule | publisher = Springer | year = 2011 | isbn = 978-3-7091-0793-5 }}

==External links==
* {{cite web | url = http://www.cargo.wlu.ca/SNC2011/ | title = The Fourth International Workshop on Symbolic-Numeric Computation (SNC2011) | date = June 7–9, 2011 | location = San Jose, California }}
'''Professional organizations'''
* [http://www.sigsam.org ACM SIGSAM: Special Interest Group in Symbolic and Algebraic Manipulation]

[[Category:Computer algebra]]
[[Category:Numerical analysis]]
[[Category:Computational science]]


{{algorithm-stub}}</text>
      <sha1>7rh0oxepxrq4ltj8mp8gf5w7bo3f9i2</sha1>
    </revision>
  </page>
  <page>
    <title>Type-2 fuzzy sets and systems</title>
    <ns>0</ns>
    <id>21171254</id>
    <revision>
      <id>862620814</id>
      <parentid>845871407</parentid>
      <timestamp>2018-10-05T15:34:26Z</timestamp>
      <contributor>
        <username>Gelbukh</username>
        <id>7545862</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="30723">{{technical|date=July 2013}}
'''Type-2 fuzzy sets and systems''' generalize standard '''[[fuzzy sets|Type-1 fuzzy sets]] and [[fuzzy sets and systems|systems]]''' so that more uncertainty can be handled. From the very beginning of fuzzy sets, criticism was made about the fact that the membership function of a type-1 fuzzy set has no uncertainty associated with it, something that seems to contradict the word ''fuzzy'', since that word has the connotation of lots of uncertainty. So, what does one do when there is uncertainty about the value of the membership function? The answer to this question was provided in 1975 by the inventor of fuzzy sets, Prof. [[Lotfi A. Zadeh]]&lt;ref name="[27]"&gt;L. A. Zadeh, "The Concept of a Linguistic Variable and Its Application to Approximate Reasoning–1," ''Information Sciences'', vol. 8, pp.&amp;nbsp;199–249, 1975.&lt;/ref&gt;, when he proposed more sophisticated kinds of fuzzy sets, the first of which he called a '''''type-2 fuzzy set'''''. A type-2 fuzzy set lets us incorporate uncertainty about the membership function into fuzzy set theory, and is a way to address the above criticism of type-1 fuzzy sets head-on. And, if there is no uncertainty, then a type-2 fuzzy set reduces to a type-1 fuzzy set, which is analogous to probability reducing to determinism when unpredictability vanishes.

In order to symbolically distinguish between a type-1 fuzzy set and a type-2 fuzzy set, a tilde symbol is put over the symbol for the fuzzy set; so, A denotes a type-1 fuzzy set, whereas Ã denotes the comparable type-2 fuzzy set. When the latter is done, the resulting type-2 fuzzy set is called a '''''general type-2 fuzzy set''''' (to distinguish it from the special interval type-2 fuzzy set).

Prof. Zadeh didn't stop with type-2 fuzzy sets, because in that 1976 paper&lt;ref name="[27]" /&gt; he also generalized all of this to type-''n'' fuzzy sets. The present article focuses only on type-2 fuzzy sets because they are the ''next step'' in the logical progression from type-1 to type-''n'' fuzzy sets, where ''n'' = 1, 2, … . Although some researchers are beginning to explore higher than type-2 fuzzy sets, as of early 2009, this work is in its infancy.

[[Image:MF of general T2 FS.jpg|right|thumb|Figure 1. The membership function of a general type-2 fuzzy set is three-dimensional. A cross-section of one slice of the third dimension is shown. This cross-section, as well as all others, sits on the FOU. Only the boundary of the cross-section is used to describe the membership function of a general type-2 fuzzy set. It is shown filled-in for artistic purposes.]]
The membership function of a general type-2 fuzzy set, Ã, is three-dimensional (Fig. 1), where the third dimension is the value of the membership function at each point on its two-dimensional domain that is called its '''''footprint of uncertainty''''' (FOU).

For an interval type-2 fuzzy set that third-dimension value is the same (e.g., 1) everywhere, which means that no new information is contained in the third dimension of an interval type-2 fuzzy set. So, for such a set, the third dimension is ignored, and only the FOU is used to describe it. It is for this reason that an interval type-2 fuzzy set is sometimes called a ''first-order uncertainty'' fuzzy set model, whereas a general type-2 fuzzy set (with its useful third-dimension) is sometimes referred to as a ''second-order uncertainty'' fuzzy set model.

[[Image:FOU for IT2 FS.jpg|thumb|left|Figure 2. FOU for an interval type-2 fuzzy set. Many other shapes are possible for the FOU.]]
The FOU represents the blurring of a type-1 membership function, and is completely described by its two bounding functions (Fig. 2), a lower membership function (LMF) and an upper membership function (UMF), both of which are type-1 fuzzy sets! Consequently, it is possible to use type-1 fuzzy set mathematics to characterize and work with interval type-2 fuzzy sets. This means that engineers and scientists who already know type-1 fuzzy sets will not have to invest a lot of time learning about general type-2 fuzzy set mathematics in order to understand and use interval type-2 fuzzy sets.

Work on type-2 fuzzy sets languished during the 1980s and early-to-mid 1990's, although a small number of articles were published about them. People were still trying to figure out what to do with type-1 fuzzy sets, so even though Zadeh proposed type-2 fuzzy sets in 1976, the time was not right for researchers to drop what they were doing with type-1 fuzzy sets to focus on type-2 fuzzy sets. This changed in the latter part of the 1990s as a result of Prof. Jerry Mendel and his student's works on type-2 fuzzy sets and systems.&lt;ref name="[12]"&gt;J. M. Mendel, ''Uncertain Rule-Based Fuzzy Logic Systems: Introduction and New Directions'', Prentice-Hall, Upper-Saddle River, NJ, 2001.&lt;/ref&gt; Since then, more and more researchers around the world are writing articles about type-2 fuzzy sets and systems.

==Interval Type-2 Fuzzy Sets==
Interval type-2 fuzzy sets have received the most attention because the mathematics that is needed for such sets—primarily [[Interval arithmetic]]—is much simpler than the mathematics that is needed for general type-2 fuzzy sets. So, the literature about interval type-2 fuzzy sets is large, whereas the literature about general type-2 fuzzy sets is much smaller. Both kinds of fuzzy sets are being actively researched by an ever-growing number of researchers around the world and have resulted in successful employment in variety of domains such as robot control.&lt;ref name=hassanzadeh&gt;Hassanzadeh, Hamid Reza, et al. "An interval-valued fuzzy controller for complex dynamical systems with application to a 3-PSP parallel robot." Fuzzy sets and systems 235 (2014): 83-100.&lt;/ref&gt;

Formilleri for the following have already been worked out for interval type-2 fuzzy sets:

* [[Fuzzy set operations]]: union, intersection and complement&lt;ref name="[6]"&gt;N. N. Karnik and J. M. Mendel, "Operations on Type-2 Fuzzy Sets," ''Fuzzy Sets and Systems'', vol. 122, pp.&amp;nbsp;327–348, 2001.&lt;/ref&gt;&lt;ref name="[12]" /&gt;
* [[Centroid]] (a very widely used operation by practitioners of such sets, and also an important uncertainty measure for them)&lt;ref name="[7]"&gt;N. N. Karnik and J. M. Mendel, "Centroid of a type-2 fuzzy set," ''Information Sciences'', vol. 132, pp.&amp;nbsp;195–220, 2001.&lt;/ref&gt;&lt;ref name="[12]" /&gt;&lt;ref name="[33]"&gt;O. Salazar, J. Soriano, and H. Serrano, "A short note on the centroid of an interval type-2 fuzzy set," in Proceedings of IEEE 2012 Workshop on Engineering Applications (WEA), Bogota, Colombia, May 2012, pp.&amp;nbsp;1–4&lt;/ref&gt;
* Other uncertainty measures [fuzziness, [[cardinality]], [[variance]] and [[skewness]]&lt;ref name="[22]"&gt;D. Wu and J. M. Mendel, "Uncertainty measures for interval type-2 fuzzy sets," ''Information Sciences'', vol. 177, pp.&amp;nbsp;5378–5393, 2007.&lt;/ref&gt; and uncertainty bounds&lt;ref name="[26]"&gt;H. Wu and J. M. Mendel, "Uncertainty Bounds and Their Use in the Design of Interval Type-2 Fuzzy Logic Systems," ''IEEE Trans. on Fuzzy Systems'', vol. 10, pp.&amp;nbsp;622–639, Oct. 2002.&lt;/ref&gt;
* Similarity&lt;ref name="[1]"&gt;H. Bustince, "Indicator of inclusion grade for interval-valued fuzzy sets: Application to approximate reasoning based on interval-valued fuzzy sets," ''International Journal of Approximate Reasoning'', vol. 23, pp.&amp;nbsp;137–209, 2000.&lt;/ref&gt;&lt;ref name="{24]"&gt;D. Wu and J. M. Mendel, "A Vector Similarity Measure for Interval Type-2 Fuzzy Sets and Type-1 Fuzzy Sets," ''Information Sciences'', vol. 178, pp.&amp;nbsp;381–402, 2008.&lt;/ref&gt;&lt;ref name="[25]"&gt;D. Wu and J. M. Mendel, "A comparative study of ranking methods, similarity measures and uncertainty measures for interval type-2 fuzzy sets," ''Information Sciences'', to appear in 2009.&lt;/ref&gt;
* Subsethood&lt;ref name="[21]"&gt;J. T. Rickard, J. Aisbett, G. Gibbon and D. Morgenthaler, "Fuzzy subsethood for type-n fuzzy sets," ''NAFIPS 2008'', Paper # 60101, New York City, May 2008.&lt;/ref&gt;
* Embedded fuzzy sets&lt;ref name="[32]"&gt;O. Salazar and J. Soriano, "Generating embedded type-1 fuzzy sets by means of convex combination," in Proceedings of the 2013 IFSA World Congress NAFIPS Annual Meeting, Edmonton, Canada, Jun. 2013, pp.&amp;nbsp;51–56.&lt;/ref&gt;&lt;ref name="[34]"&gt;O. Salazar, and J. Soriano, "Convex combination and its application to fuzzy sets and interval-valued fuzzy sets I," Applied Mathematical Sciences, vol. 9, no. 22, pp.&amp;nbsp;1061–1068, 2015&lt;/ref&gt;&lt;ref name="[35]"&gt;O. Salazar, and J. Soriano, "Convex combination and its application to fuzzy sets and interval-valued fuzzy sets II," Applied Mathematical Sciences, vol. 9, no. 22, pp. 1069–1076, 2015&lt;/ref&gt;
* Fuzzy set ranking&lt;ref name="[25]" /&gt;
* Fuzzy rule ranking and selection&lt;ref name="[31]"&gt;S. -M. Zhou, J. M. Garibaldi, R. I. John and F. Chiclana, "On constructing parsimonious type-2 fuzzy logic systems via influential rule selection," ''IEEE Trans. on Fuzzy Systems'', vol.17, no.3, pp.&amp;nbsp;654–667, 2009.&lt;/ref&gt;
* Type-reduction methods&lt;ref name="[7]" /&gt;&lt;ref name="[12]" /&gt;
* Firing intervals for an interval type-2 fuzzy logic system&lt;ref name="[3]"&gt;M. B. Gorzalczany, "A Method of Inference in Approximate Reasoning Based on Interval-Valued Fuzzy Sets," ''Fuzzy Sets and Systems'', vol. 21, pp.&amp;nbsp;1–17, 1987&lt;/ref&gt;&lt;ref name="[8]"&gt;Q. Liang and J. M. Mendel, "Interval Type-2 Fuzzy Logic Systems: Theory and Design," ''IEEE Trans. on Fuzzy Systems'', vol. 8, pp.&amp;nbsp;535–550, 2000.&lt;/ref&gt;&lt;ref name="[12]" /&gt; 
* Fuzzy weighted average&lt;ref name="[9]"&gt;F. Liu and J. M. Mendel, "Aggregation Using the Fuzzy Weighted Average, as Computed by the KM Algorithms," ''IEEE Trans. on Fuzzy Systems'', vol. 16, pp.&amp;nbsp;1–12, February 2008.&lt;/ref&gt;
* Linguistic weighted average&lt;ref name="[23]"&gt;D. Wu and J. M. Mendel, "Aggregation Using the Linguistic Weighted Average and Interval Type-2 Fuzzy Sets," ''IEEE Trans. on Fuzzy Systems'', vol. 15, pp.&amp;nbsp;1145–1161, December 2007.&lt;/ref&gt;
* Synthesizing an FOU from data that are collected from a group of subject&lt;ref name="[10]"&gt;F. Liu and J. M. Mendel, "Encoding words into interval type-2 fuzzy sets using an interval approach," ''IEEE Trans. on Fuzzy Systems'', vol. 16, pp.&amp;nbsp;1503–1521, December 2008.&lt;/ref&gt;

==Interval Type-2 Fuzzy Logic Systems==
Type-2 fuzzy sets are finding very wide applicability in '''''rule-based fuzzy logic systems''''' (FLSs) because they let uncertainties be modeled by them whereas such uncertainties cannot be modeled by type-1 fuzzy sets. A block diagram of a type-2 FLS is depicted in Fig. 3. This kind of FLS is used in fuzzy logic control, fuzzy logic signal processing, rule-based classification, etc., and is sometimes referred to as a ''function approximation'' application of fuzzy sets, because the FLS is designed to minimize an error function.

[[Image:T2 FLS.jpg|thumb|left|Figure 3. Type-2 FLS]]

The following discussions, about the four components in the Fig. 3 rule-based FLS, are given for an interval type-2 FLS, because to-date they are the most popular kind of type-2 FLS; however, most of the discussions are also applicable for a general type-2 FLS.

'''''Rules''''', that are either provided by subject experts or are extracted from numerical data, are expressed as a collection of IF-THEN statements, e.g.,

:IF temperature is ''moderate'' and pressure is ''high'', then rotate the valve ''a bit to the right''.

Fuzzy sets are associated with the terms that appear in the antecedents (IF-part) or consequents (THEN-part) of rules, and with the inputs to and the outputs of the FLS. Membership functions are used to describe these fuzzy sets, and in a type-1 FLS they are all type-1 fuzzy sets, whereas in an interval type-2 FLS at least one membership function is an interval type-2 fuzzy set.

An interval type-2 FLS lets any one or all of the following kinds of uncertainties be quantified:

# Words that are used in antecedents and consequents of rules—because words can mean different things to different people.
# Uncertain consequents—because when rules are obtained from a group of experts, consequents will often be different for the same rule, i.e. the experts will not necessarily be in agreement.
# Membership function parameters—because when those parameters are optimized using uncertain (noisy) training data, the parameters become uncertain.
# Noisy measurements—because very often it is such measurements that activate the FLS.

In Fig. 3, measured (crisp) inputs are first transformed into fuzzy sets in the '''''Fuzzifier''''' block because it is fuzzy sets and not numbers that activate the rules which are described in terms of fuzzy sets and not numbers. Three kinds of fuzzifiers are possible in an interval type-2 FLS. When measurements are:
* Perfect, they are modeled as a crisp set;  
* Noisy, but the noise is stationary, they are modeled as a type-1 fuzzy set; and,
* Noisy, but the noise is non-stationary, they are modeled as an interval type-2 fuzzy set (this latter kind of fuzzification cannot be done in a type-1 FLS).

In Fig. 3, after measurements are fuzzified, the resulting input fuzzy sets are mapped into fuzzy output sets by the '''''Inference''''' block. This is accomplished by first quantifying each rule using fuzzy set theory, and by then using the mathematics of fuzzy sets to establish the output of each rule, with the help of an inference mechanism. If there are ''M'' rules then the fuzzy input sets to the Inference block will activate only a subset of those rules, where the subset contains at least one rule and usually way fewer than ''M'' rules. Inference is done one rule at a time. So, at the output of the Inference block, there will be one or more ''fired-rule fuzzy output sets''.

In most engineering applications of a FLS, a number (and not a fuzzy set) is needed as its final output, e.g., the consequent of the rule given above is "Rotate the valve a bit to the right." No automatic valve will know what this means because "a bit to the right" is a linguistic expression, and a valve must be turned by numerical values, i.e. by a certain number of degrees. Consequently, the fired-rule output fuzzy sets have to be converted into a number, and this is done in the Fig. 3 '''''Output Processing''''' block.

In a type-1 FLS, output processing, called '''''[[Defuzzification]]''''', maps a type-1 fuzzy set into a number. There are many ways for doing this, e.g., compute the union of the fired-rule output fuzzy sets (the result is another type-1 fuzzy set) and then compute the center of gravity of the membership function for that set; compute a weighted average of the center of gravities of each of the fired rule consequent membership functions; etc.

Things are somewhat more complicated for an interval type-2 FLS, because to go from an interval type-2 fuzzy set to a number (usually) requires two steps (Fig. 3). The first step, called '''''type-reduction''''', is where an interval type-2 fuzzy set is reduced to an interval-valued type-1 fuzzy set. There are as many type-reduction methods as there are type-1 defuzzification methods. An algorithm developed by Karnik and Mendel&lt;ref name="[7]" /&gt;&lt;ref name="[12]" /&gt; now known as the '''''KM Algorithm''''' is used for type-reduction. Although this algorithm is iterative, it is very fast.

The second step of Output Processing, which occurs after type-reduction, is still called '''''defuzzification'''''. Because a type-reduced set of an interval type-2 fuzzy set is always a finite interval of numbers, the defuzzified value is just the average of the two end-points of this interval.

It is clear from Fig. 3 that there can be two outputs to an interval type-2 FLS—crisp numerical values and the type-reduced set. The latter provides a measure of the uncertainties that have flowed through the interval type-2 FLS, due to the (possibly) uncertain input measurements that have activated rules whose antecedents or consequents or both are uncertain. Just as standard deviation is widely used in probability and statistics to provide a measure of unpredictable uncertainty about a mean value, the type-reduced set can provided a measure of uncertainty about the crisp output of an interval type-2 FLS.

==Computing with words==
Another application for fuzzy sets has also been inspired by Prof. Zadeh&lt;ref name="[28]"&gt;L. A. Zadeh, "Fuzzy logic = computing with words," ''IEEE Trans. on Fuzzy Systems'', vol. 4, pp.&amp;nbsp;103–111, 1996.&lt;/ref&gt;&lt;ref name="[29]"&gt;L. A. Zadeh, "From computing with numbers to computing with words—from manipulation of measurements to manipulation of perceptions," ''IEEE Trans. on Circuits and Systems–1, Fundamental Theory and Applications'', vol. 4, pp.&amp;nbsp;105–119, 1999.&lt;/ref&gt;&lt;ref name="[30]"&gt;L. A. Zadeh, "Toward human level machine intelligence—is it achievable? The need for a new paradigm shift," ''IEEE Computational Intelligence Magazine'', vol. 3, pp.&amp;nbsp;11–22, August 2008.&lt;/ref&gt; — '''''Computing With Words'''''. Different acronyms have been used for "computing with words," e.g., CW and CWW. According to Zadeh:
:CWW is a methodology in which the objects of computation are words and propositions drawn from a natural language. [It is] inspired by the remarkable human capability to perform a wide variety of physical and mental tasks without any measurements and any computations. 
Of course, he did not mean that computers would actually compute using words—single words or phrases—rather than numbers. He meant that computers would be activated by words, which would be converted into a mathematical representation using fuzzy sets and that these fuzzy sets would be mapped by a CWW engine into some other fuzzy set after which the latter would be converted back into a word. A natural question to ask is: Which kind of fuzzy set—type-1 or type-2—should be used as a model for a word? Mendel&lt;ref name="[13]"&gt;J. M. Mendel, "Fuzzy Sets for Words: a New Beginning," ''Proc. IEEE FUZZ Conference'', St. Louis, MO, May 26–28, 2003, pp.&amp;nbsp;37–42.&lt;/ref&gt;&lt;ref name="[16]"&gt;J. M. Mendel, "Computing with words: Zadeh, Turing, Popper and Occam," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;10–17, November 2007.&lt;/ref&gt; has argued, on the basis of [[Karl Popper]]'s concept of '''''[[Falsificationism]]''''',&lt;ref name="[19]"&gt;K. Popper, ''The Logic of Scientific Discovery'' (translation of Logik der Forschung), Hutchinson, London, 1959.&lt;/ref&gt;&lt;ref name="[30]" /&gt; that using a type-1 fuzzy set as a model for a word is scientifically incorrect. An interval type-2 fuzzy set should be used as a (first-order uncertainty) model for a word. Much research is under way about CWW.

== Applications ==
Type-2 fuzzy sets were applied in image processing, video processing and computer vision, as well as [[Failure mode and effects analysis|Failure Mode And Effect Analysis.]]&lt;ref&gt;{{cite journal |author1=Chai K.C.|author2=Tay K. M.|author3=Lim C.P. | title=A perceptual computing-based method to prioritize failure modes in failure mode and effect analysis and its application to edible bird nest farming |journal=Applied Soft Computing |volume=49|year=2016|url=http://www.sciencedirect.com/science/article/pii/S1568494616304379 |doi=10.1016/j.asoc.2016.08.043 |pages= 734–747}}&lt;/ref&gt;

==Further reading==
* For the reader who is new to interval type-2 fuzzy sets and systems and wants to learn more about them, without getting into lots of details, the easiest way to do this is to read Mendel's 2007 magazine article,&lt;ref name="[14]"&gt;J. M. Mendel, "Type-2 fuzzy sets and systems: an overview," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;20–29, February 2007.&lt;/ref&gt; or Wu's [https://sites.google.com/site/drwu09/publications/A_Brief_Tutorial_on_Interval_Type-2_Fuzzy_Sets_and_Systems.pdf?attredirects=0 brief tutorial on interval type-2 fuzzy sets and systems]. The latter also contains a Matlab implementation of interval type-2 fuzzy logic systems.
* For the reader who is new to interval type-2 fuzzy sets and systems and wants to learn more about them, with lots of details, but does not want to first learn about general type-2 fuzzy sets and systems, the easiest way to do this is to read the journal article by Mendel, John and Liu.J. M. Mendel, R. I. John and F. Liu, "Interval type-2 fuzzy logic systems made simple," ''IEEE Trans. on Fuzzy Systems'', vol. 14, pp.&amp;nbsp;808–821, December 2006.J. M. Mendel, R. I. John and F. Liu, "Interval type-2 fuzzy logic systems made simple," ''IEEE Trans. on Fuzzy Systems'', vol. 14, pp.&amp;nbsp;808–821, December 2006.&lt;/ref&gt;
* For the reader who is new to type-2 fuzzy sets and systems and wants to learn more about them, wants all of the details, wants a top-down presentation—from general type-2 to interval type-2—, and wants to see how they compare with type-1 fuzzy sets and systems, the easiest way to do this is to read Mendel's 2001 textbook.&lt;ref name="[12]" /&gt;
* For the reader who wants to learn about a very powerful and useful representation for general type-2 fuzzy sets, in terms of simpler type-2 fuzzy sets that are called embedded type-2 fuzzy sets, read the paper by Mendel and John.&lt;ref name="[17]"&gt;J. M. Mendel and R. I. John, ""Type-2 Fuzzy Sets Made Simple," ''IEEE Trans. on Fuzzy Systems'', vol. 10, pp.&amp;nbsp;117–127, April 2002.&lt;/ref&gt;
* For the reader who may already be familiar with type-2 fuzzy sets and systems and who wants to know what has happened since the 2001 publication of Mendel's book, see Mendel's 2007 journal article&lt;ref name="[15]"&gt;J. M. Mendel, "Type-2 fuzzy sets and systems: an overview," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;20–29, February 2007.&lt;/ref&gt; and also the 2008 book by Castillo and Melin.&lt;ref name="[2]"&gt;O. Castillo and P. Melin, ''Type-2 Fuzzy Logic Theory and Applications'', Springer-Verlag, Berlin, 2008.&lt;/ref&gt;
* The February 2007 issue of the ''IEEE Computational Intelligence Magazine'' is a special issue that is about type-2 fuzzy sets and systems. This issue contains articles (see the reference list below) about:
*# The history of type-2 fuzzy logic, by Bob John and Simon Coupland&lt;ref name="[5]"&gt;R. John and S. Coupland, "Type-2 fuzzy logic: a historical view," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;57–62, February 2007.&lt;/ref&gt;
*# Type-2 fuzzy logic controllers, by Hani Hagras&lt;ref name="[4]"&gt;H. Hagras, "Type-2 FLCs: A new generation of fuzzy controllers," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;30–43, February 2007.&lt;/ref&gt;
*# Fuzzy clustering using type-2 fuzzy sets, by Frank Rhee&lt;ref name="[20]"&gt;F. Rhee, "Uncertain fuzzy clustering: Insights and recommendations," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;44–56, February 2007.&lt;/ref&gt;
*# Hardware implementation for a type-2 fuzzy system, by Miguel Melgarejo&lt;ref name="[11]"&gt;M. Melgarejo, "Implementing interval type-2 fuzzy processors," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;63–71, February 2007.&lt;/ref&gt;

==See also==

* [[Computational intelligence]]
* [[Expert system]]
* [[Fuzzy control system]]
* [[Fuzzy logic]]
* [[Fuzzy set]]
* [[Granular computing]]
* [[Perceptual Computing]]
* [[Rough set]]
* [[Soft set]]
* [[Vagueness]]

==References==
{{Reflist}}
&lt;!-- old reference list as backup...
[1]* H. Bustince, "Indicator of inclusion grade for interval-valued fuzzy sets: Application to approximate reasoning based on interval-valued fuzzy sets," ''International Journal of Approximate Reasoning'', vol. 23, pp.&amp;nbsp;137–209, 2000.

[2]* O. Castillo and P. Melin, ''Type-2 Fuzzy Logic Theory and Applications'', Springer-Verlag, Berlin, 2008.

[3]* M. B. Gorzalczany, "A Method of Inference in Approximate Reasoning Based on Interval-Valued Fuzzy Sets," ''Fuzzy Sets and Systems'', vol. 21, pp.&amp;nbsp;1–17, 1987.

[4]* H. Hagras, "Type-2 FLCs: A new generation of fuzzy controllers," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;30–43, February 2007.

[5]* R. John and S. Coupland, "Type-2 fuzzy logic: a historical view," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;57–62, February 2007.

[6]* N. N. Karnik and J. M. Mendel, "Operations on Type-2 Fuzzy Sets," ''Fuzzy Sets and Systems'', vol. 122, pp.&amp;nbsp;327–348, 2001.

[7]* N. N. Karnik and J. M. Mendel, "Centroid of a type-2 fuzzy set," ''Information Sciences'', vol. 132, pp.&amp;nbsp;195–220, 2001.

[8]* Q. Liang and J. M. Mendel, "Interval Type-2 Fuzzy Logic Systems: Theory and Design," ''IEEE Trans. on Fuzzy Systems'', vol. 8, pp.&amp;nbsp;535–550, 2000.

[9]* F. Liu and J. M. Mendel, "Aggregation Using the Fuzzy Weighted Average, as Computed by the KM Algorithms," ''IEEE Trans. on Fuzzy Systems'', vol. 16, pp.&amp;nbsp;1–12, February 2008.

[10]* F. Liu and J. M. Mendel, "Encoding words into interval type-2 fuzzy sets using an interval approach," ''IEEE Trans. on Fuzzy Systems'', vol. 16, pp.&amp;nbsp;1503–1521, December 2008.

[11]* M. Melgarejo, "Implementing interval type-2 fuzzy processors," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;63–71, February 2007.

[12]* J. M. Mendel, ''Uncertain Rule-Based Fuzzy Logic Systems: Introduction and New Directions'', Prentice-Hall, Upper-Saddle River, NJ, 2001.

[13]* J. M. Mendel, "Fuzzy Sets for Words: a New Beginning," ''Proc. IEEE FUZZ Conference'', St. Louis, MO, May 26–28, 2003, pp.&amp;nbsp;37–42.

[14]* J. M. Mendel, "Type-2 fuzzy sets and systems: an overview," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;20–29, February 2007.

[15]* J. M. Mendel, "Advances in type-2 fuzzy sets and systems," ''Information Sciences'', Vol. 177, pp.&amp;nbsp;84–110, 2007.

[16]* J. M. Mendel, "Computing with words: Zadeh, Turing, Popper and Occam," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;10–17, November 2007.

[17]* J. M. Mendel and R. I. John, ""Type-2 Fuzzy Sets Made Simple," ''IEEE Trans. on Fuzzy Systems'', vol. 10, pp.&amp;nbsp;117–127, April 2002.

[18]* J. M. Mendel, R. I. John and F. Liu, "Interval type-2 fuzzy logic systems made simple," ''IEEE Trans. on Fuzzy Systems'', vol. 14, pp.&amp;nbsp;808–821, December 2006.

[19]* K. Popper, ''The Logic of Scientific Discovery'' (translation of Logik der Forschung), Hutchinson, London, 1959.

[20]* F. Rhee, "Uncertain fuzzy clustering: Insights and recommendations," ''IEEE Computational Intelligence Magazine'', vol. 2, pp.&amp;nbsp;44–56, February 2007.

[21]* J. T. Rickard, J. Aisbett, G. Gibbon and D. Morgenthaler, "Fuzzy subsethood for type-n fuzzy sets," ''NAFIPS 2008'', Paper # 60101, New York City, May 2008.

[22]* D. Wu and J. M. Mendel, "Uncertainty measures for interval type-2 fuzzy sets," ''Information Sciences'', vol. 177, pp.&amp;nbsp;5378–5393, 2007.

[23]* D. Wu and J. M. Mendel, "Aggregation Using the Linguistic Weighted Average and Interval Type-2 Fuzzy Sets," ''IEEE Trans. on Fuzzy Systems'', vol. 15, pp.&amp;nbsp;1145–1161, December 2007.

[24]* D. Wu and J. M. Mendel, "A Vector Similarity Measure for Interval Type-2 Fuzzy Sets and Type-1 Fuzzy Sets," ''Information Sciences'', vol. 178, pp.&amp;nbsp;381–402, 2008.

[25]* D. Wu and J. M. Mendel, "A comparative study of ranking methods, similarity measures and uncertainty measures for interval type-2 fuzzy sets," ''Information Sciences'', to appear in 2009.

[26]* H. Wu and J. M. Mendel, "Uncertainty Bounds and Their Use in the Design of Interval Type-2 Fuzzy Logic Systems," ''IEEE Trans. on Fuzzy Systems'', vol. 10, pp.&amp;nbsp;622–639, Oct. 2002.

[27]* L. A. Zadeh, "The Concept of a Linguistic Variable and Its Application to Approximate Reasoning–1," ''Information Sciences'', vol. 8, pp.&amp;nbsp;199–249, 1975.

[28]* L. A. Zadeh, "Fuzzy logic = computing with words," ''IEEE Trans. on Fuzzy Systems'', vol. 4, pp.&amp;nbsp;103–111, 1996.

[29]* L. A. Zadeh, "From computing with numbers to computing with words—from manipulation of measurements to manipulation of perceptions," ''IEEE Trans. on Circuits and Systems–1, Fundamental Theory and Applications'', vol. 4, pp.&amp;nbsp;105–119, 1999.

[30]* L. A. Zadeh, "Toward human level machine intelligence—is it achievable? The need for a new paradigm shift," ''IEEE Computational Intelligence Magazine'', vol. 3, pp.&amp;nbsp;11–22, August 2008.

[31]* S. -M. Zhou, J. M. Garibaldi, R. I. John and F. Chiclana, "On constructing parsimonious type-2 fuzzy logic systems via influential rule selection," ''IEEE Trans. on Fuzzy Systems'', vol.17, no.3, pp.&amp;nbsp;654–667, 2009.

[32]* O. Salazar and J. Soriano, "Generating embedded type-1 fuzzy sets by means of convex combination," in Proceedings of the 2013 IFSA World Congress NAFIPS Annual Meeting, Edmonton, Canada, Jun. 2013, pp.&amp;nbsp;51–56.

[33]* O. Salazar, J. Soriano, and H. Serrano, "A short note on the centroid of an interval type-2 fuzzy set," in Proceedings of IEEE 2012 Workshop on Engineering Applications (WEA), Bogota, Colombia, May 2012, pp.&amp;nbsp;1–4

[34]* O. Salazar, and J. Soriano, "Convex combination and its application to fuzzy sets and interval-valued fuzzy sets I," Applied Mathematical Sciences, vol. 9, no. 22, pp.&amp;nbsp;1061–1068, 2015

[35]* O. Salazar, and J. Soriano, "Convex combination and its application to fuzzy sets and interval-valued fuzzy sets II," Applied Mathematical Sciences, vol. 9, no. 22, pp.&amp;nbsp;1069–1076, 2015

;Notes
&lt;references /&gt;
--&gt;

==External links==
There are two I''EEE Expert Now'' multi-media modules that can be accessed from the IEEE at: http://www.ieee.org/web/education/Expert_Now_IEEE/Catalog/AI.html
* "Introduction to Type-2 Fuzzy Sets and Systems" by Jerry Mendel, sponsored by the IEEE Computational Intelligence Society
* "Type-2 Fuzzy Logic Controllers: Towards a New Approach for Handling Uncertainties in Real World Environments" by Hani Hagras, sponsored by the IEEE Computational Intelligence Society

===Software===
Freeware MATLAB implementations, which cover general and interval type-2 fuzzy sets and systems, as well as type-1 fuzzy systems, are available at: http://sipi.usc.edu/~mendel/software.&lt;br /&gt;
Software supporting discrete interval type-2 fuzzy logic systems is available at:&lt;br /&gt;
DIT2FLS Toolbox - http://dit2fls.com/projects/dit2fls-toolbox/&lt;br /&gt;
DIT2FLS Library Package - http://dit2fls.com/projects/dit2fls-library-package/

Java libraries including source code for type-1, interval- and general type-2 fuzzy systems are available at: http://juzzy.wagnerweb.net/.

An open source Matlab/Simulink Toolbox for Interval Type-2 Fuzzy Logic Systems is available at: http://web.itu.edu.tr/kumbasart/type2fuzzy.htm&lt;br /&gt;

[[Category:Artificial intelligence]]
[[Category:Fuzzy logic]]
[[Category:Logic in computer science]]</text>
      <sha1>7pf4ehd8zm0bln81e6zpu9pv4tz4z2h</sha1>
    </revision>
  </page>
  <page>
    <title>Whitney's planarity criterion</title>
    <ns>0</ns>
    <id>3126156</id>
    <revision>
      <id>841430968</id>
      <parentid>810821447</parentid>
      <timestamp>2018-05-15T20:11:43Z</timestamp>
      <contributor>
        <username>OAbot</username>
        <id>28481209</id>
      </contributor>
      <minor/>
      <comment>[[Wikipedia:OABOT|Open access bot]]: add pmc identifier to citation with #oabot.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3512">[[File:Duals graphs.svg|thumb|300px|A planar graph and its dual. Every cycle in the blue graph is a minimal cut in the red graph, and vice versa, so the two graphs are algebraic duals and have dual graphic matroids.]]
In mathematics, '''Whitney's planarity criterion''' is a [[matroid]]-theoretic characterization of [[planar graph]]s, named after [[Hassler Whitney]].&lt;ref&gt;{{citation
 | last = Whitney | first = Hassler | author-link = Hassler Whitney
 | journal = Transactions of the American Mathematical Society
 | pages = 339–362
 | title = Non-separable and planar graphs
 | volume = 34
 | issue = 2
 |doi=10.1090/S0002-9947-1932-1501641-2 
 | year = 1932| pmc = 1076008}}.&lt;/ref&gt; It states that a graph ''G'' is planar if and only if its [[graphic matroid]] is also cographic (that is, it is the [[dual matroid]] of another graphic matroid).

In purely graph-theoretic terms, this criterion can be stated as follows: There must be another (dual) graph ''G''&lt;nowiki/&gt;'=(''V''&lt;nowiki/&gt;',''E''&lt;nowiki/&gt;') and a bijective correspondence between the edges ''E''&lt;nowiki/&gt;' and the edges ''E'' of the original graph ''G'', such that a subset ''T'' of ''E'' forms a spanning tree of ''G'' if and only if the edges corresponding to the complementary subset ''E''-''T'' form a spanning tree of ''G''&lt;nowiki/&gt;'.

==Algebraic duals==
An equivalent form of Whitney's criterion is that a graph ''G'' is planar if and only if it has a [[dual graph]] whose graphic matroid is dual to the graphic matroid of ''G''. 
A graph whose graphic matroid is dual to the graphic matroid of ''G'' is known as an algebraic dual of ''G''. This, Whitney's planarity criterion can be expressed succinctly as: a graph is planar if and only if it has an algebraic dual.

==Topological duals==
If a graph is [[graph embedding|embedded]] into a topological surface such as the plane, in such a way that every face of the embedding is a topological disk, then the dual graph of the embedding is defined as the graph (or in some cases [[multigraph]]) ''H'' that has a vertex for every face of the embedding, and an edge for every adjacency between a pair of faces.
According to Whitney's criterion, the following conditions are equivalent:
*The surface on which the embedding exists is topologically equivalent to the plane, sphere, or punctured plane
*''H'' is an algebraic dual of ''G''
*Every simple cycle in ''G'' corresponds to a minimal cut in ''H'', and vice versa
*Every simple cycle in ''H'' corresponds to a minimal cut in ''G'', and vice versa
*Every [[spanning tree]] in ''G'' corresponds to the [[complement (set theory)|complement]] of a spanning tree in ''H'', and vice versa.&lt;ref&gt;{{citation
 | last = Tutte | first = W. T. | authorlink = W. T. Tutte
 | journal = Journal of Research of the National Bureau of Standards
 | mr = 0179781
 | pages = 1–47
 | title = Lectures on matroids
 | url = http://cdm16009.contentdm.oclc.org/cdm/ref/collection/p13011coll6/id/66650
 | volume = 69B
 | year = 1965
 | doi=10.6028/jres.069b.001}}. See in particular section 2.5, "Bon-matroid of a graph", pp. 5–6, section 5.6, "Graphic and co-graphic matroids", pp. 19–20, and section 9, "Graphic matroids", pp. 38–47.&lt;/ref&gt;

It is possible to define dual graphs of graphs embedded on nonplanar surfaces such as the torus, but these duals do not generally have the correspondence between cuts, cycles, and spanning trees required by Whitney's criterion.

==References==
{{reflist}}

[[Category:Matroid theory]]
[[Category:Planar graphs]]</text>
      <sha1>3wgldm62otgeq0pq7mijnqivgmgyzyk</sha1>
    </revision>
  </page>
  <page>
    <title>Wildfire modeling</title>
    <ns>0</ns>
    <id>20115268</id>
    <revision>
      <id>869415127</id>
      <parentid>868164346</parentid>
      <timestamp>2018-11-18T13:18:43Z</timestamp>
      <contributor>
        <username>Colonies Chris</username>
        <id>577301</id>
      </contributor>
      <comment>/* Physically based models and coupling with the atmosphere */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="21571">[[File:Propagation model wildfire (English).svg|thumb|250px|right|A simple wildfire propagation model.]]

In [[computational science]], '''wildfire modeling''' is concerned with [[numerical weather prediction|numerical simulation]] of [[wildland fire]]s in order to understand and predict fire behavior. Wildfire modeling can ultimately aid [[wildland fire suppression]], namely increase safety of [[firefighter]]s and the public, reduce risk, and minimize damage. Wildfire modeling can also aid in protecting [[ecosystem]]s, [[Drainage basin|watershed]]s, and [[air quality]].

==Objectives of wildfire modeling==

Wildfire modeling attempts to reproduce fire behavior, such as how quickly the fire spreads, in which direction, how much heat it generates. A key input to behavior modeling is the [[Fuel model|Fuel Model]], or type of fuel, through which the fire is burning.  Behavior modeling can also include whether the fire transitions from the surface (a "surface fire") to the tree crowns (a "crown fire"), as well as extreme fire behavior including rapid rates of spread, [[fire whirl]]s, and tall well-developed convection columns. Fire modeling also attempts to estimate fire effects, such as the [[ecology|ecological]] and [[hydrology|hydrological]] effects of the fire, fuel consumption, tree mortality, and amount and rate of smoke produced.

==Environmental factors==

Wildland fire behavior is affected by [[weather]], [[fuel]] characteristics, and [[topography]].

Weather influences fire through [[wind]] and [[moisture]].  [[Wind]] increases the fire spread in the wind direction, higher [[temperature]] makes the fire burn faster, while higher [[relative humidity]], and [[precipitation (meteorology)|precipitation]] (rain or snow) may slow it down or extinguish it altogether. Weather involving fast wind changes can be particularly dangerous, since they can suddenly change the fire direction and behavior. Such weather includes [[cold front]]s, [[foehn wind]]s, [[thunderstorm]] [[downdrafts]], [[sea breeze|sea and land breeze]], and [[Daytime (astronomy)|diurnal]] [[slope wind]]s.

Wildfire fuel includes grass, wood, and anything else that can burn. Small dry twigs burn faster while large logs burn slower; dry fuel ignites more easily and burns faster than wet fuel.

Topography factors that influence wildfires include the orientation toward the sun, which influences the amount of energy received from the sun, and the slope (fire spreads faster uphill). Fire can accelerate in narrow canyons and it can be slowed down or stopped by barriers such as creeks and roads.

These factors act in combination. Rain or snow increases the fuel moisture, high [[relative humidity]] slows the drying of the fuel, while winds can make fuel dry faster. Wind can change the fire-accelerating effect of slopes to effects such as downslope windstorms (called [[Santa Ana winds|Santa Ana]]s, foehn winds, East winds, depending on the geographic location). Fuel properties may vary with topography as plant density varies with elevation or aspect with respect to the sun.

It has long been recognized that "fires create their own weather." That is, the heat and moisture created by the fire feed back into the atmosphere, creating intense winds that drive the fire behavior. The heat produced by the wildfire changes the temperature of the atmosphere and creates strong updrafts, which can change the direction of surface winds. The water vapor released by the fire changes the moisture balance of the atmosphere. The water vapor can be carried away, where the [[latent heat]] stored in the vapor is released through [[condensation]].

==Approaches to fire modeling==

Like all models in computational science, fire models need to strike a balance between fidelity, availability of data, and fast execution. Wildland fire models span a vast range of complexity, from simple cause and effect principles to the most physically complex presenting a difficult supercomputing challenge that cannot hope to be solved faster than real time.

[[Forest-fire model]]s have been developed since 1940 to the present, but a lot of chemical and thermodynamic questions related to fire behaviour are still to be resolved. Scientists and their forest fire models from 1940 till 2003 are listed in article.&lt;ref&gt;E. Pastor, L. Zarate, E. Planas and J. Arnaldos. Mathematical models and calculation systems for the study of wildland fire behaviour. Progress in Energy and Combustion Science, 29:139–153, 2003.  Doi:10.1016/S0360-1285(03)00017-0)&lt;/ref&gt; Models can be divided into three groups: Empirical, Semi-empirical, and Physically based.

===Empirical models===

Conceptual models from experience and intuition from past fires can be used to anticipate the future. Many semi-empirical fire spread equations, as in those published by the USDA Forest Service,&lt;ref name="Rothermel-1972-MMP"&gt;Richard C. Rothermel. A mathematical model for predicting fire spread in wildland fires. USDA Forest Service Research Paper INT-115, 1972.&lt;/ref&gt; Forestry Canada,&lt;ref name="Forestry-1992-DSC"&gt;Forestry Canada Fire Danger Group. Development and structure of the Canadian forest fire behavior prediction system. Forestry Canada, Science and Sustainable Development Directorate, Ottawa, ON, Information Report ST-X-3, 1992.&lt;/ref&gt; Nobel, Bary, and Gill,&lt;ref name="Noble-1980-FMD"&gt;I. R. Noble, G. A. V. Bary, and A. M. Gill. McArthur's fire danger meters expressed as equations. ''Australian Journal of Ecology'', 5:201--203, 1980.&lt;/ref&gt; and Cheney, Gould, and Catchpole&lt;ref name="Cheney-1993-IFW"&gt;N. P. Cheney, J. S. Gould, and W. R. Catchpole. The influence of fuel, weather, and fire shape variables on fire-spread in grasslands. ''International Journal of Wildland Fire'', 3:31--44, 1993.&lt;/ref&gt; for Australasian fuel complexes have been developed for quick estimation of fundamental parameters of interest such as fire spread rate, flame length, and fireline intensity of surface fires at a point for specific fuel complexes, assuming a representative point-location wind and terrain slope. Based on the work by Fons's in 1946,&lt;ref name="Fons-1946-AFS"&gt;W. L. Fons. Analysis of fire spread in light fuels. ''Journal of Agricultural Research'', 72:93--121, 1946.&lt;/ref&gt; and Emmons in 1963,&lt;ref name="Emmons-1963-FF"&gt;H. W. Emmons. Fire in the forest. ''Fire Research Abstracts and Reviews'', 5:163, 1963.&lt;/ref&gt; the quasi-steady equilibrium spread rate calculated for a surface fire on flat ground in no-wind conditions was calibrated using data of piles of sticks burned in a flame chamber/wind tunnel to represent other wind and slope conditions for the fuel complexes tested.

Two-dimensional fire growth models such as [[FARSITE]]&lt;ref name="Finney-1998-FFA"&gt;Mark A. Finney. FARSITE: Fire area simulator-model development and evaluation. Res. Pap. RMRS-RP-4, Ogden, UT: U.S. Department of Agriculture, Forest Service, Rocky Mountain Research Station. 47 p., http://www.farsite.org, 1998.&lt;/ref&gt; and Prometheus,&lt;ref&gt;{{vcite web | url = http://firegrowthmodel.ca/  | title = PROMETHEUS | publisher =  Tymstra, C.; Bryce, R.W.; Wotton, B.M.; Armitage, O.B. 2009. Development and structure of Prometheus: the Canadian wildland fire growth simulation Model.  Inf. Rep. NOR-X-417. Nat. Resour. Can., Can. For. Serv., North. For. Cent., Edmonton, AB. | accessdate = 2009-01-01}}&lt;/ref&gt; the Canadian wildland fire growth model designed to work in Canadian fuel complexes, have been developed that apply such semi-empirical relationships and others regarding ground-to-crown transitions to calculate fire spread and other parameters along the surface. Certain assumptions must be made in models such as FARSITE and Prometheus to shape the fire growth. For example, Prometheus and FARSITE use the Huygens principle of wave propagation. A set of equations that can be used to propagate (shape and direction) a fire front using an elliptical shape was developed by Richards in 1990.&lt;ref name="Richards-1990-EGM"&gt;G.D. Richards, “An Elliptical Growth Model of Forest Fire Fronts and Its Numerical Solution”, Int. J. Numer. Meth. Eng.,. 30:1163-1179, 1990.&lt;/ref&gt; Although more sophisticated applications use a three-dimensional numerical weather prediction system to provide inputs such as wind velocity to one of the fire growth models listed above, the input was passive and the feedback of the fire upon the atmospheric wind and humidity are not accounted for.

===Physically based models and coupling with the atmosphere===

A simplified physically based two-dimensional fire spread models based upon conservation laws that use radiation as the dominant heat transfer mechanism and convection, which represents the effect of wind and slope, lead to [[reaction–diffusion system]]s of [[partial differential equation]]s.&lt;ref name="Asensio-2002-WFM"&gt;M. I. Asensio and L. Ferragut. On a wildland fire model with radiation. ''Int. J. Numer. Meth. Engrg.'', 54:137--157, 2002 [https://dx.doi.org/10.1002/nme.420 fultext]&lt;/ref&gt;&lt;ref name="Mandel-2008-WMD"&gt;Jan Mandel, Lynn S. Bennethum, Jonathan D. Beezley, Janice L. Coen, Craig C. Douglas, Minjeong Kim, and Anthony Vodacek. "A wildfire model with data assimilation". ''Mathematics and Computers in Simulation'' 79:584-606, 2008. [https://dx.doi.org/10.1016/j.matcom.2008.03.015 fulltext] [https://arxiv.org/abs/0709.0086 arXiv]&lt;/ref&gt;

More complex physical models join [[computational fluid dynamics]] models with a wildland fire component and allow the fire to feed back upon the atmosphere. These models include [[NCAR]]'s Coupled Atmosphere-Wildland Fire-Environment (CAWFE) model developed in 2005,&lt;ref name="Coen-2005-SBE"&gt;J. L. Coen. "Simulation of the Big Elk Fire using coupled atmosphere-fire modeling". ''International Journal of Wildland Fire'', 14(1):49--59, 2005. [https://dx.doi.org/10.1071/WF04047 fulltext]&lt;/ref&gt; [[WRF-Fire]] at NCAR and [[University of Colorado Denver]]&lt;ref name="Mandel-2007-DAW"&gt;Jan Mandel, Jonathan D. Beezley, Janice L. Coen, Minjeong Kim, "Data Assimilation for Wildland Fires: Ensemble Kalman filters in coupled atmosphere-surface models", ''IEEE Control Systems Magazine'' 29, Issue 3, June 2009, 47-65. [https://dx.doi.org/10.1109/MCS.2009.932224 article] [https://arxiv.org/abs/0712.3965 arXiv]&lt;/ref&gt; which combines the [[Weather Research and Forecasting Model]] with a spread model by the [[level-set method]], [[University of Utah]]'s Coupled Atmosphere-Wildland Fire Large Eddy Simulation developed in 2009,&lt;ref name="Sun-2009-ICB"&gt;R. Sun, S. K Krueger, M. A. Jenkins, M. A. Zulauf, and J. J. Charney. "The importance of fire-atmosphere coupling and boundary-layer turbulence to wildfire spread". ''International Journal of Wildland Fire'',18(1) 50–60, 2009.[https://dx.doi.org/10.1071/WF07072 fulltext]&lt;/ref&gt; Los Alamos National Laboratory's [[FIRETEC]] developed in,&lt;ref name="Linn-2002-SWB"&gt;R. Linn, J. Reisner, J. J. Colman, and J. Winterkamp. Studying wildfire behavior using FIRETEC. ''International Journal of Wildland Fire'', 11:233--246, 2002. [https://dx.doi.org/10.1071/WF02007 fulltext]&lt;/ref&gt; the WUI (Wildland Urban Interface) [[Fire Dynamics Simulator]] (WFDS) developed in 2007,&lt;ref name="Mell-2007-PAM"&gt;W. Mell, M. A. Jenkins, J. Gould, and P. Cheney. A physics-based approach to modelling grassland fires. ''Intl. J. Wildland Fire'', 16:1--22, 2007. [https://dx.doi.org/10.1071/WF06002 fulltext]&lt;/ref&gt; and, to some degree, the two-dimensional model FIRESTAR.&lt;ref name="Dupuy-1999-FSP"&gt;Jean-Luc Dupuy and Michel Larini. Fire spread through a porous forest fuel bed: A radiative and convective model including fire-induced flow effects. ''International Journal of Wildland Fire'', 9(3):155--172, 1999.&lt;/ref&gt;&lt;ref name="Porterie-1998-MMP"&gt;B. Porterie, D. Morvan, J.C. Loraud, and M. Larini. A multiphase model for predicting line fire propagation. In Domingos Xavier Viegas, editor, ''Forest Fire Research: Proceedings 3rd International Conference on Forest Fire Research and 14th Conference on Fire and Forest Meteorology, Louso, Coimbra, Portugal, 16--18 November 1998'', volume 1, pages 343--360. Associa\cc\ ao para o Desenvolvimento da Aerodinamica Industrial, 1998.&lt;/ref&gt;&lt;ref&gt;D. Morvan and J.L. Dupuy Modelling the propagation of a wildfire through a Mediterranean shrub using a multiphase formulation” Combustion &amp; Flame, Vol.138, pp.199-200, 2004.&lt;/ref&gt; These tools have different emphases and have been applied to better understand the fundamental aspects of fire behavior, such as fuel inhomogeneities on fire behavior,&lt;ref name="Linn-2002-SWB"/&gt; feedbacks between the fire and the atmospheric environment as the basis for the universal fire shape,&lt;ref name="Coen-2001-CAF"&gt;J. L. Coen, T. L. Clark, and D. Latham. Coupled atmosphere-fire model simulations in various fuel types in complex terrain. In ''4th. Symp. Fire and Forest Meteor. Amer. Meteor. Soc., Reno, Nov. 13-15'', pages 39--42, 2001.&lt;/ref&gt;&lt;ref name="Clark-2004-DCA"&gt;Terry L. Clark, Janice Coen, and Don Latham. Description of a coupled atmosphere-fire model. ''International Journal of Wildland Fire'', 13:49--64, 2004. [https://dx.doi.org/10.1071/WF03043 fulltext]&lt;/ref&gt; and are beginning to be applied to wildland urban interface house-to-house fire spread at the community-scale.

The cost of added physical complexity is a corresponding increase in computational cost, so much so that a full three-dimensional explicit treatment of [[combustion]] in wildland fuels by [[direct numerical simulation]] (DNS) at scales relevant for atmospheric modeling does not exist, is beyond current supercomputers, and does not currently make sense to do because of the limited skill of weather models at spatial resolution under 1&amp;nbsp;km. Consequently, even these more complex models parameterize the fire in some way, for example, papers by Clark&lt;ref name="Clark-1996-CAFb"&gt;T. L. Clark, M. A. Jenkins, J. Coen, and David Packham. A coupled atmospheric-fire model: Convective Froude number and dynamic fingering. ''International Journal of Wildland Fire'', 6:177--190, 1996.&lt;/ref&gt;&lt;ref name="Clark-1996-CAF"&gt;Terry L. Clark, Marry Ann Jenkins, Janice Coen, and David Packham. A coupled atmospheric-fire model: Convective feedback on fire line dynamics. ''J. Appl. Meteor'', 35:875--901, 1996.&lt;/ref&gt; use equations developed by Rothermel for the USDA forest service&lt;ref name="Rothermel-1972-MMP"/&gt; to calculate local fire spread rates using fire-modified local winds. And, although FIRETEC and WFDS carry prognostic conservation equations for the reacting fuel and oxygen concentrations, the computational grid cannot be fine enough to resolve the reaction rate-limiting mixing of fuel and oxygen, so approximations must be made concerning the subgrid-scale temperature distribution or the combustion reaction rates themselves. These models also are too small-scale to interact with a weather model, so the fluid motions use a computational fluid dynamics model confined in a box much smaller than the typical wildfire.

Attempts to create the most complete theoretical model were made by Albini F.A. in USA and Grishin A.M.&lt;ref&gt;A.M. Grishin. Mathematical models of forest fires and New Methods of Fighting Them. Publishing House of the Tomsk University, Tomsk, Russia, 1997. (edited by F.A. Albini)&lt;/ref&gt; in Russia. Grishin's work is based on the fundamental laws of physics, conservation and theoretical justifications are provided. The simplified two-dimensional model of running crown forest fire was developed in [[Belarusian State University]] by Barovik D.V.&lt;ref&gt;Barovik, D.; Taranchuk, V. 2010. Mathematical modelling of running crown forest fires. Mathematical Modelling and Analysis 15(2):161-174 [http://elib.bsu.by/bitstream/123456789/10110/1/TVB_2010.pdf fulltext]&lt;/ref&gt; and Taranchuk V.B..

==Data assimilation==

[[Data assimilation]] periodically adjusts the model state to incorporate new data using statistical methods. Because fire is highly nonlinear and irreversible, data assimilation for fire models poses special challenges, and standard methods, such as the [[ensemble Kalman filter]] (EnKF) do not work well. Statistical variability of corrections and especially large corrections may result in nonphysical states, which tend to be preceded or accompanied by large spatial [[gradient]]s. In order to ease this problem, the [[Regularization (mathematics)|regularized]] EnKF&lt;ref name="Johns-2008-TEK"&gt;Craig J. Johns and Jan Mandel. A two-stage ensemble Kalman filter for smooth data assimilation. ''Environmental and Ecological Statistics'', 15:101--110, 2008. Proceedings of Conference on New Developments of Statistical Analysis in Wildlife, Fisheries, and Ecological Research, Oct 13-16, 2004, Columbia, MI. [https://dx.doi.org/10.1007/s10651-007-0033-0 fulltext] [http://math.ucdenver.edu/~jmandel/papers/cjjm-fires-revised.pdf preprint]&lt;/ref&gt; penalizes large changes of spatial gradients in the Bayesian update in EnKF. The regularization technique has a stabilizing effect on the simulations in the ensemble but it does not improve much the ability of the EnKF to track the data: The posterior ensemble is made out of [[linear combination]]s of the prior ensemble, and if a reasonably close location and shape of the fire cannot be found between the linear combinations, the data assimilation is simply out of luck, and the ensemble cannot approach the data. From that point on, the ensemble evolves essentially without regard to the data. This is called filter divergence. So, there is clearly a need to adjust the simulation state by a position change rather than an additive correction only. The ''morphing EnKF''&lt;ref name="Beezley-2008-MEK"&gt;Jonathan D. Beezley and Jan Mandel. Morphing ensemble Kalman filters. ''Tellus'', 60A:131--140, 2008 [https://dx.doi.org/10.1111/j.1600-0870.2007.00275.x fulltext] [https://arxiv.org/abs/0705.3693 preprint]&lt;/ref&gt; combines the ideas of data assimilation with [[image registration]] and [[morphing]] to provide both additive and position correction in a natural manner, and can be used to change a model state reliably in response to data.&lt;ref name="Mandel-2007-DAW"/&gt;

==Limitations and practical use==

The limitations on fire modeling are not entirely computational. At this level, the models encounter limits in knowledge about the composition of [[pyrolysis]] products and [[reaction pathway]]s, in addition to gaps in basic understanding about some aspects of fire behavior such as fire spread in live fuels and surface-to-crown fire transition.

Thus, while more complex models have value in studying fire behavior and testing fire spread in a range of scenarios, from the application point of view, FARSITE and [[Palm (PDA)|Palm]]-based applications of BEHAVE have shown great utility as practical in-the-field tools because of their ability to provide estimates of fire behavior in real time. While the coupled fire-atmosphere models have the ability to incorporate the ability of the fire to affect its own local weather, and model many aspects of the explosive, unsteady nature of fires that cannot be incorporated in current tools, it remains a challenge to apply these more complex models in a faster-than-real-time operational environment. Also, although they have reached a certain degree of realism when simulating specific natural fires, they must yet address issues such as identifying what specific, relevant operational information they could provide beyond current tools, how the simulation time could fit the operational time frame for decisions (therefore, the simulation must run substantially faster than real time), what temporal and spatial resolution must be used by the model, and how they estimate the inherent uncertainty in numerical weather prediction in their forecast. These operational constraints must be used to steer model development.

==See also==
* [[Catastrophe modeling]]
* [[Extreme value theory]]
* [[Fuel model]]

==References==
{{reflist|2}}

==External links==
* [http://www.firemodels.org/ FARSITE fire simulator]
* [http://www.firegrowthmodel.com PROMETHEUS fire growth simulator]
* [http://www.openwfm.org/ WRF-Fire]
* [http://serc.carleton.edu/NAGTWorkshops/health/visualizations/wildfire.html Wildfire Visualizations collected links]
* [https://www.youtube.com/profile?user=Wildfireproject Wildfire simulations on Youtube]
* [http://www.vets.ucar.edu/vg/categories/wildfires.shtml Wildfire visualizations at NCAR]
* [http://www.mmm.ucar.edu/people/coen/files/newpage_f.html Coupled Weather-Wildfire Modeling - Basic aspects of wildfire behavior]
* [http://www.mmm.ucar.edu/people/coen/files/newpage_m.html Coupled Weather-Wildfire Modeling - Wildfire Case Studies]
* [http://www.cifor.cgiar.org/fire/Link.htm Fire research links]
*{{vcite journal |author=McKenzie D, Gedalof Z, Peterson DL, Mote P |title=Climatic change, wildfire, and conservation |journal=Conservation Biology |volume=18 |issue=4 |date=2004 |pages=890–902 |doi=10.1111/j.1523-1739.2004.00492.x |url=http://www2.for.nau.edu/courses/pzf/FireEcolMgt/McKenzie_ConBio2004.pdf |format=PDF }}
*[https://www.theatlantic.com/magazine/archive/2012/09/burning-question/309057/ ''Why are wildfires defying long-standing computer models?''] September 2012

{{Computer modeling}}
{{Atmospheric, Oceanographic and Climate Models}}

[[Category:Wildfires]]
[[Category:Wildfire prevention]]
[[Category:Wildland fire suppression]]
[[Category:Computational physics]]
[[Category:Firefighting]]
[[Category:Sustainable forest management]]
[[Category:Mathematical modeling]]
[[Category:Numerical climate and weather models]]
[[Category:Wildfire ecology]]</text>
      <sha1>fl4og8uq0994mqkwroceek0ptmouklb</sha1>
    </revision>
  </page>
</mediawiki>
