<mediawiki xmlns="http://www.mediawiki.org/xml/export-0.10/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.mediawiki.org/xml/export-0.10/ http://www.mediawiki.org/xml/export-0.10.xsd" version="0.10" xml:lang="en">
  <siteinfo>
    <sitename>Wikipedia</sitename>
    <dbname>enwiki</dbname>
    <base>https://en.wikipedia.org/wiki/Main_Page</base>
    <generator>MediaWiki 1.33.0-wmf.6</generator>
    <case>first-letter</case>
    <namespaces>
      <namespace key="-2" case="first-letter">Media</namespace>
      <namespace key="-1" case="first-letter">Special</namespace>
      <namespace key="0" case="first-letter" />
      <namespace key="1" case="first-letter">Talk</namespace>
      <namespace key="2" case="first-letter">User</namespace>
      <namespace key="3" case="first-letter">User talk</namespace>
      <namespace key="4" case="first-letter">Wikipedia</namespace>
      <namespace key="5" case="first-letter">Wikipedia talk</namespace>
      <namespace key="6" case="first-letter">File</namespace>
      <namespace key="7" case="first-letter">File talk</namespace>
      <namespace key="8" case="first-letter">MediaWiki</namespace>
      <namespace key="9" case="first-letter">MediaWiki talk</namespace>
      <namespace key="10" case="first-letter">Template</namespace>
      <namespace key="11" case="first-letter">Template talk</namespace>
      <namespace key="12" case="first-letter">Help</namespace>
      <namespace key="13" case="first-letter">Help talk</namespace>
      <namespace key="14" case="first-letter">Category</namespace>
      <namespace key="15" case="first-letter">Category talk</namespace>
      <namespace key="100" case="first-letter">Portal</namespace>
      <namespace key="101" case="first-letter">Portal talk</namespace>
      <namespace key="108" case="first-letter">Book</namespace>
      <namespace key="109" case="first-letter">Book talk</namespace>
      <namespace key="118" case="first-letter">Draft</namespace>
      <namespace key="119" case="first-letter">Draft talk</namespace>
      <namespace key="710" case="first-letter">TimedText</namespace>
      <namespace key="711" case="first-letter">TimedText talk</namespace>
      <namespace key="828" case="first-letter">Module</namespace>
      <namespace key="829" case="first-letter">Module talk</namespace>
      <namespace key="2300" case="first-letter">Gadget</namespace>
      <namespace key="2301" case="first-letter">Gadget talk</namespace>
      <namespace key="2302" case="case-sensitive">Gadget definition</namespace>
      <namespace key="2303" case="case-sensitive">Gadget definition talk</namespace>
    </namespaces>
  </siteinfo>
  <page>
    <title>143 (number)</title>
    <ns>0</ns>
    <id>1752068</id>
    <revision>
      <id>864902634</id>
      <parentid>864893496</parentid>
      <timestamp>2018-10-20T08:32:47Z</timestamp>
      <contributor>
        <username>Gap9551</username>
        <id>8367391</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/106.193.66.211|106.193.66.211]] ([[User talk:106.193.66.211|talk]]) to last version by AnomieBOT</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5637">{{Example farm|date=September 2015}}
{{Infobox number
| number = 143
| divisor = 1, 11, 13, 143
}}
'''143''' ('''one hundred [and] forty-three''') is the natural number following [[142 (number)|142]] and preceding [[144 (number)|144]].

==In mathematics==
'''143''' is the sum of seven consecutive primes (11 + 13 + 17 + 19 + 23 + 29 + 31). But this number is never the sum of an integer and its base 10 digits, making it a [[self number]].

Every positive integer is the sum of at most 143 seventh powers (see [[Waring's problem]]).

143 is the difference in the first exception to the pattern shown below:
:&lt;math&gt;3^2+4^2=5^2&lt;/math&gt;
:&lt;math&gt;3^3+4^3+5^3=6^3&lt;/math&gt;
:&lt;math&gt;3^4+4^4+5^4+6^4=7^4-143&lt;/math&gt;.

==In the military==
* [[Vickers Type 143]] was a [[United Kingdom|British]] single-seat fighter [[biplane]] in 1929
* [[United States Air Force]] [[143d Airlift Wing]] airlift unit at [[Quonset Point]], [[Rhode Island]]
* {{USS|Arcade|AM-143}} was a [[United States Navy]] minesweeper ship during [[World War II]]
* {{USS|Clermont|APA-143}} was a United States Navy {{sclass-|Haskell|attack transport}} during World War II
* {{USS|Fiske|DE-143}} was a United States Navy {{sclass-|Edsall|destroyer escort}} during World War II
* {{USS|General H. B. Freeman|AP-143}} was a United States Navy ''General G. O. Squier''-class [[transport ship]] in World War II
* {{USS|Magistrate|SP-143}} was a United States Navy ''Magistrate''-class patrol boat
* {{USS|Neosho|AO-143}} was a United States Navy ''Neosho''-class fleet oiler during the [[Cuban Missile Crisis]]
* {{USS|Yarnall|DD-143}} was a United States Navy {{sclass-|Wickes|destroyer}} during [[World War I]]

==In transportation==
* [[London Buses route 143]] is a [[Transport for London]] contracted bus route in [[London]]
* [[Gimli Glider|Air Canada Flight 143]], landed at [[Gimli, Manitoba]] Air Force Base after gliding {{convert|80|mi|km}} after running out of fuel on July 22, 1983
* [[Philippine Airlines Flight 143]] exploded prior to takeoff on May 11, 1990, at [[Ninoy Aquino International Airport|Manila Airport]]
* [[Bristol Type 143]] was a [[United Kingdom|British]] twin-engined [[monoplane]] aircraft of the [[Bristol Aeroplane Company]]
* [[British Rail Class 143]] [[diesel multiple unit]], part of the [[Pacer (train)|Pacer]] family of [[train]]s introduced in 1985
* [[East 143rd Street–St. Mary's Street (IRT Pelham Line)|East 143rd Street–St. Mary's Street]] [[metro station|station]] on the [[IRT Pelham Line]] of the [[New York City Subway]]
* [[Orland Park 143rd Street (Metra)|143rd Street]] station on [[Metra]]'s [[SouthWest Service]] in [[Orland Park, Illinois|Orland Park]], [[Illinois]]

==In media==
* [[143 (film)|''143'' (film)]], a 2004 Indian film
* Musicians [[Ray J]] and Bobby Brackins wrote the song "143"
* On [[Mister Rogers' Neighborhood]]: "Transformations", 143 is used to mean "I love you". 1 meaning I for 1 letter, 4 meaning Love for the 4 letters, and 3 meaning You for the 3 letters. Reportedly, [[Fred Rogers]] maintained his weight at exactly 143&amp;nbsp;pounds for the last thirty years of his life, and associated the number with the phrase "I love you"&lt;ref&gt;Hattikutur, Mangkesh. "15 reasons Mr. Rogers was best neighbor ever." http://www.cnn.com/2008/LIVING/wayoflife/07/28/mf.mrrogers.neighbor/  Mental Floss/CNN. 28 Jul 2008.&lt;/ref&gt;
* [[Jake Shimabukuro]] released the song "143" based on his experience in high school when 143 was sent on a pager to indicate "I Love You" &lt;ref&gt;{{cite web|url=https://www.jakeshimabukuro.com/home/release/peace-love-ukelele/|title=Peace Love Ukelele|author=|date=19 May 2015|website=jakeshimabukuro.com|accessdate=8 April 2018}}&lt;/ref&gt;

==In popular culture==
* A popular [[pager]] number to communicate "I love you" (based on the number of letters in each of the three words){{cn|date=September 2018}}

==In other fields==
143 is also:
* The year [[143|AD 143]] or [[143 BC]]
* 143 AH is a year in the [[Islamic calendar]] that corresponds to [[760]] – [[761]] [[Common Era|CE]]
* [[143 Adria]] is a large [[main belt]] [[asteroid]]
* [[143 Records]] [[record label|label]] of producer [[David Foster]], a sub-label of [[Atlantic Records]]
* [http://www.biblegateway.com/passage/?search=Psalm+143;&amp;version=31; Psalm 143]
* [[Sonnet 143]] by [[William Shakespeare]]
* [[Slovenia]] ranks #143 in world [[List of countries by population|population]]
* ''The 143'', in [[South Africa]], refers to the 143 [[conscientious objector]]s who publicly refused to do military service in the [[Apartheid]] army in 1988.&lt;ref&gt;Nan Cross: Supported men resisting apartheid conscription [http://www.thetimes.co.za/Columnists/Article.aspx?id=521101|The Sunday Times (South Africa), 2007-07-22, accessed 2009-01-05].&lt;/ref&gt;
* The song “143” by [[Musiq Soulchild|Musiq]]
* The song “Flying Dream 143” by [[Elbow (band)|Elbow]]
* The [[atomic number]] of [http://www.flw.com/datatools/periodic/001.php?id=143 Unquadtrium], a temporary [[chemical element]]
* Cycle 143 is the name of an album by digital artist j03l [https://play.spotify.com/album/2KhnYoJqagNeUaI8y3snPd]

==See also==
* [[List of highways numbered 143]]
* [[United Nations Security Council Resolution 143]]
* [[List of United States Supreme Court cases, volume 143|United States Supreme Court cases, S3XiFi3D 143]]

==References==
&lt;references/&gt;

==External links==
{{Commons category|143 (number)}}
* [http://numbers.daresler.net/143/ The Natural Number 143]
* [[Urbandict:143|143 at Urban Dictionary]]
* [http://www.virtuescience.com/143.html 143 at Virtual Science]

{{Integers|1}}

{{DEFAULTSORT:143 (Number)}}
[[Category:Integers]]</text>
      <sha1>oabeqxe6alvu55f0l76dpag3u7ybaen</sha1>
    </revision>
  </page>
  <page>
    <title>242 (number)</title>
    <ns>0</ns>
    <id>5113977</id>
    <revision>
      <id>832157947</id>
      <parentid>832148362</parentid>
      <timestamp>2018-03-24T05:00:49Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>Reverted [[WP:AGF|good faith]] edits by [[Special:Contributions/74.214.48.190|74.214.48.190]] ([[User talk:74.214.48.190|talk]]): Trivia. ([[WP:TW|TW]])</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1836">{{refimprove|date=August 2012}}
{{Infobox number
| number = 242
}}
'''242''' ('''two hundred [and] forty-two''') is the [[natural number]] following [[241 (number)|241]] and preceding [[243 (number)|243]].

==In mathematics==

242 is the smallest integer to start a run of four consecutive integers with the same number of divisors.&lt;ref&gt;R. K. Guy ''Unsolved Problems in Number Theory'', section B18.&lt;/ref&gt;&lt;ref&gt;D. Wells, ''[[The Penguin Dictionary of Curious and Interesting Numbers]],'' Penguin Books, NY, 1986: 147, 176.&lt;/ref&gt;

242 is a [[nontotient]] since there is no integer with 242 [[coprime]]s below it.

242 is a [[palindrome]].

==In other fields==
242 is also:
*part of the name of a Belgian [[electronic body music]] group called [[Front 242]]
*the number of a notable UN Security Council resolution pertaining to the Arab/Israeli conflict, [[United Nations Security Council Resolution 242]]
*the [[telephone numbering plan|area code]] of [[The Bahamas]] located in the North West Atlantic Ocean.
*[[Volvo 242]] (2xx-series, 4-cylinder, 2-door) Produced from 1974-1984.
*[[Fiat 242]], a van produced by Fiat
*A rumoured time for the release of Radiohead's pre-sale for their 2012 tour.
*the total number of [http://www.mariowiki.com/Power_Star Power Stars] a player can collect in ''[[Super Mario Galaxy]]'' and ''[[Super Mario Galaxy 2]]'' for the [[Wii]].
*the orbit, in days, of [[Kepler-69c]], a planet 70 percent larger than the size of Earth, orbiting in the habitable zone of a star similar to our sun. Astronomers are uncertain about the composition of Kepler-69c, but its orbit of 242 days around a sun-like star resembles that of our neighboring planet Venus.
*[[2-4-2]], a [[Whyte notation]] classification of [[steam locomotive]].

==References==
&lt;references/&gt;

{{Integers|2}}

[[Category:Integers]]

{{num-stub}}</text>
      <sha1>0vbwpm7qjob4d5n0vb07fhh19gyja9v</sha1>
    </revision>
  </page>
  <page>
    <title>78 (number)</title>
    <ns>0</ns>
    <id>305608</id>
    <revision>
      <id>869420392</id>
      <parentid>868714518</parentid>
      <timestamp>2018-11-18T14:13:17Z</timestamp>
      <contributor>
        <username>Arthur Rubin</username>
        <id>374195</id>
      </contributor>
      <comment>remove as ephemeral number in a local racing circuit</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2555">{{refimprove|date=December 2010}}
{{Infobox number
| number = 78
| divisor = 1, 2, 3, 6, 13, 26, 39, 78
}}
'''78''' ('''seventy-eight''') is the [[natural number]] following [[77 (number)|77]] and followed by [[79 (number)|79]].

==In mathematics==
'''78''' is:

*the dimension of the [[Simple Lie group#Exceptional cases|exceptional]] Lie group [[E6 (mathematics)|E&lt;sub&gt;6&lt;/sub&gt;]] and several related objects.
*a [[sphenic number]], having 3 distinct prime [[factorization|factors]].&lt;ref&gt;{{Cite web|url=https://oeis.org/A007304|title=Sloane's A007304 : Sphenic numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;
*an [[abundant number]] with an aliquot sum of 90.
*a [[semiperfect number]], as a multiple of a perfect number.
*the 12th [[triangular number]].
*a [[palindromic number]] in bases 5 (303&lt;sub&gt;5&lt;/sub&gt;), 7 (141&lt;sub&gt;7&lt;/sub&gt;), 12 (66&lt;sub&gt;12&lt;/sub&gt;), 25 (33&lt;sub&gt;25&lt;/sub&gt;), 38 (22&lt;sub&gt;38&lt;/sub&gt;), 77 (11&lt;sub&gt;77&lt;/sub&gt;) and all bases greater 78.
*a [[Harshad number]] in bases 3, 4, 5, 6, 7, 13 and 14.
*an [[Erdős–Woods number]], since it is possible to find sequences of 78 consecutive integers such that each inner member shares a factor with either the first or the last member.&lt;ref&gt;{{Cite web|url=https://oeis.org/A059756|title=Sloane's A059756 : Erdős-Woods numbers|last=|first=|date=|website=The On-Line Encyclopedia of Integer Sequences|publisher=OEIS Foundation|access-date=2016-05-29}}&lt;/ref&gt;

77 and 78 form a [[Ruth-Aaron pair]].

==In science==
*The [[atomic number]] of [[platinum]].

==In other fields==
{{Seealso|List of highways numbered 78}}
78 is also:
*In reference to [[gramophone record]]s, '''78''' refers those meant to be spun at 78 [[revolutions per minute]]. Compare: [[gramophone record|LP]], {{frac|[[Thirty three|33]]|1|3}} and [[Forty five|45]] rpm. 33 + 45 = 78
*A typical [[tarot]] deck containing the 21 [[trump cards]],  the [[The Fool (Tarot card)|Fool]] and the 56 suit cards make up 78 cards
*The total number of gifts in the song ''The Twelve Days of Christmas'' (since 78 is the 12th triangular number)
*The [[Rule of 78s]] is a method of yearly interest calculation
*The number of the laps of the [[Monaco Grand Prix]] since [[1985 Monaco Grand Prix|1985]] (with the exception of [[1989 Monaco Grand Prix|1989]] by just 77 laps).
*The only non-conforming sequenced episode of the [[Hello Internet]] podcast written using the Roman numerals LXXVIII.

== References ==
&lt;references/&gt;

{{Integers|zero}}

[[Category:Integers]]</text>
      <sha1>8za8b8rwsko7hwig9xg2cg2h2wt3vid</sha1>
    </revision>
  </page>
  <page>
    <title>Alfred Cardew Dixon</title>
    <ns>0</ns>
    <id>16688292</id>
    <revision>
      <id>832666507</id>
      <parentid>832460996</parentid>
      <timestamp>2018-03-27T09:38:48Z</timestamp>
      <contributor>
        <username>Yobot</username>
        <id>7328338</id>
      </contributor>
      <minor/>
      <comment>/* top */Removed invisible unicode characters + other fixes ([[User:Yobot/55|Task 55]]), replaced: → using [[Project:AWB|AWB]] (12151)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3122">{{Use dmy dates|date=June 2016}}
'''Sir Alfred Cardew Dixon, 1st Baronet Warford''' [[Fellow of the Royal Society|FRS]]&lt;ref name="frs"&gt;{{Cite journal | last1 = Whittaker | first1 = E. T.| authorlink = E. T. Whittaker | title = Alfred Cardew Dixon. 1865–1936 | doi = 10.1098/rsbm.1936.0014 | journal = [[Obituary Notices of Fellows of the Royal Society]] | volume = 2 | issue = 5 | pages = 165 | year = 1936 | jstor = 769137| pmid =  | pmc = }}&lt;/ref&gt; (22 May 1865 – 4 May 1936) was an [[England|English]] [[mathematician]].&lt;ref&gt;{{MacTutor Biography|id=Dixon}}&lt;/ref&gt;

Dixon was born on 22 May 1865 in [[Northallerton]], Yorkshire, England. He studied at the [[University of London]] and graduated with an [[Master of Arts|MA]]. He entered [[Trinity College, Cambridge]], in 1883 and graduated as [[Senior Wrangler]] in the Mathematical Tripos in 1886.&lt;ref&gt;{{acad|id=DKSN883AC|name=Dixon, Alfred Cardew}}&lt;/ref&gt; In 1888, Dixon was awarded the second [[Smith's Prize]], and also appointed a Fellow of Trinity College, Cambridge. He took the degree of Sc.D. at [[University of Cambridge|Cambridge University]] in 1897. He was Professor of Mathematics at [[Queen's College, Galway]], from 1893 to 1901. In 1901 he was appointed to the chair at Queen's University Belfast, which he held till 1930, receiving the title of Emeritus Professor on retirement.

Dixon was elected to the Royal Society in 1904 and after he retired from [[Queen's University Belfast]], he served as president of the [[London Mathematical Society]] from 1931 until 1933. Queen's University Belfast conferred on him the honorary degree of D.Sc. in 1932.

Dixon was well known for his work in [[differential equation]]s. He did early work on [[Fredholm integral equation|Fredholm integral]]s independently of [[Erik Ivar Fredholm|Fredholm]]. He worked both on [[ordinary differential equation]]s and on [[partial differential equation]]s studying [[Abelian integral]]s, [[automorphic function]]s, and [[functional equation]]s.

In 1894 Dixon wrote ''The Elementary Properties of the Elliptic Functions''.&lt;ref&gt;''The Elementary Properties of the Elliptic Functions, with Examples'' by Alfred Cardew Dixon, Palala Press 2016,  {{ISBN|1355940508}}&lt;/ref&gt;   Certain elliptic functions ([[meromorphic function|meromorphic]] [[doubly periodic function|doubly periodic]] functions) denoted cm and sm satisfying the identity cm(''z'')&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;sm(''z'')&lt;sup&gt;3&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;1 are known as [[Dixon's elliptic functions]].

[[Dixon's identity]] is any of several closely related identities involving [[binomial coefficient]]s and [[hypergeometric function]]s.

== References ==
{{Reflist}}

{{Authority control}}

{{DEFAULTSORT:Dixon, Alfred Cardew}}
[[Category:1865 births]]
[[Category:1936 deaths]]
[[Category:20th-century mathematicians]]
[[Category:Academics of Queen's University Belfast]]
[[Category:Alumni of Trinity College, Cambridge]]
[[Category:Fellows of Trinity College, Cambridge]]
[[Category:Fellows of the Royal Society]]
[[Category:Senior Wranglers]]
[[Category:People from Northallerton]]
[[Category:People from North Yorkshire]]</text>
      <sha1>kdby81yfcy1tfi6pn9zkjnrulbngm8b</sha1>
    </revision>
  </page>
  <page>
    <title>Attack tolerance</title>
    <ns>0</ns>
    <id>44453564</id>
    <revision>
      <id>863639363</id>
      <parentid>862519353</parentid>
      <timestamp>2018-10-12T01:45:38Z</timestamp>
      <contributor>
        <username>Ira Leviton</username>
        <id>25046916</id>
      </contributor>
      <minor/>
      <comment>Deleted a duplicate 'the'.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7368">{{Multiple issues|{{more footnotes|date=February 2015}}{{technical|date=February 2015}}}}

In the context of [[complex networks]], '''attack tolerance''' is the network’s robustness meaning the ability to maintain the overall connectivity and diameter of the network as [[Node deletion|nodes are removed]].

==Attack types==
If an attack was to be mounted on a network, it would not be through random nodes but ones that were the most significant to the network. Different methods of ranking are utilized to determine the nodes priority in the network.

===Average node degree===
This form of attack prioritizes the most connected nodes as the most important ones. This takes into account the network (represented by graph &lt;math&gt;G&lt;/math&gt;) changing over time, by analyzing the network as a series of snapshots (indexed by &lt;math&gt;j&lt;/math&gt;); we denote the snapshot at time &lt;math&gt;t_j&lt;/math&gt; by &lt;math&gt;G(t_j)&lt;/math&gt;.  The average of the degree of a node, labeled &lt;math&gt;i&lt;/math&gt;, within a given snapshot &lt;math&gt;deg_{G(t_j)}&lt;/math&gt;, throughout a time interval (a sequence of &lt;math&gt; T&lt;/math&gt; snapshots) &lt;math&gt;\{t_1,...,t_T\}&lt;/math&gt;, is given by:

&lt;math&gt;deg_{G}(i;t_{1},t_{n})=\textstyle\frac{1}{T}\sum_{j=1}^T{deg_{G(t_{j})}(i)}&lt;/math&gt;

===Node persistence===
This form of attack prioritizes nodes that occur most frequently over a period of time. The equation below calculates the frequency that a node (i) occurs in a time interval &lt;math&gt;\{t_1,...,t_T\}&lt;/math&gt;. When the node is present during the snapshot then equation is equal to 1, but if the node is not present then it is equal to 0.

&lt;math&gt;Np_{G}(i;t_{1},t_{n})=\textstyle\frac{1}{T}\sum_{j=1}^T{\delta_{t_{j}}(i)}&lt;/math&gt;

Where

&lt;math&gt;\delta_{t_{j}}(i)=\begin{cases}
1,&amp;\text{if }i\in V_{t_{j}}\text{at }t_{j}^{th}\text{ time step.}\\
0,&amp;\text{otherwise.}
\end{cases}
&lt;/math&gt;

===Temporal closeness===
This form of attack prioritizes nodes by the summation of temporal distances from one node to all other nodes over a period of time. The equation below calculates the temporal distance of a node (i) by averaging the sum of all the temporal distances for the interval  [t&lt;sub&gt;1&lt;/sub&gt;,t&lt;sub&gt;n&lt;/sub&gt;].&lt;ref name= Time-varying /&gt;

&lt;math&gt;C_{G}(i;t_{1},t_{n})=\frac{1}{(N-1)}\sum_{j;j\ne i}{d_{ji}(t_{1},t_{n})}&lt;/math&gt;

==Network model tolerances==
Not all networks are the same, so it is no surprise that an attack on different networks would have different results. The common method for measuring change in the network is through the average of the size of all the isolated clusters, &lt;nowiki&gt;&lt;s&gt;&lt;/nowiki&gt;, and the fraction of the nodes contained in the largest cluster, S.&lt;ref name= Achilles /&gt; When no nodes have been attacked, both S and &lt;nowiki&gt;&lt;s&gt;&lt;/nowiki&gt; equal 1.

===Erdős–Rényi model===
{{main|Erdős–Rényi model}}
&lt;!-- Commented out because image was deleted: [[File:AttackFailureGraph.png|framed|right|Size of Largest cluster S, and size of average cluster &lt;nowiki&gt;&lt;s&gt;&lt;/nowiki&gt; in exponential and scale-free models after attack and random failure &lt;ref name=Achilles /&gt;]] --&gt;
In the ER model, the network generated is homogeneous, meaning each node has the same number of links. This is considered to be an exponential network. When comparing the connectivity of the ER model when it undergoes random failures vs directed attacks, we are shown that the exponential network reacts the same way to a random failure as it does to a directed attack. This is due to the homogeneity of the network, making it so that it does not matter whether a random node is selected or one is specifically targeted. All the nodes on average are the same in degree therefore attacking one shouldn't cause anymore damage than attacking another. As the number of attacks go up and more nodes are removed, we observe that S decreases non-linearly and acts as if a threshold exists when a fraction of the nodes (f) has been removed, (f≈.28). At this point, S goes to zero. The average size of the isolated clusters behaves opposite, increasing exponentially to &lt;nowiki&gt;&lt;s&gt;&lt;/nowiki&gt;= 2, also approaching the threshold line f≈.28, except decreases back to 1 after. 
This model was tested for a large range of nodes and proven to maintain the same pattern.&lt;ref name= Achilles /&gt;

===Scale-free model===
{{main|Scale-free network}}
&lt;!-- Commented out because image was deleted: [[File:PatternAttackFailure.png|framed|right|Progression of exponential and scale-free network undergoing random failure and attack &lt;ref name=Barabasi /&gt;]] --&gt;
In the scale-free model, the network is defined by its degree distribution following the [[power law]],&lt;ref name= Barabasi /&gt; which means that each node has no set number of links, unlike the exponential network. This makes the scale-free model more vulnerable because there are nodes that are more important than others, and if these nodes were to be deliberately attacked the network would break down. However this inhomogeneous network has its strengths when it comes to random failures. Due to the power law there are many more nodes in the system that have very few links, and probability estimates that these are the nodes that will be targeted (because there are more of them). Severing these smaller nodes will not affect the network as a whole and therefore allows the structure of the network to stay approximately the same.
When the scale-free model undergoes random failures, ''S'' slowly decreases with no threshold-like behavior and &lt;nowiki&gt;&lt;s&gt;&lt;/nowiki&gt; remains approximately 1. This indicates that the network is being broken apart one by one and not by large clusters. However, when the scale-free model undergoes deliberate attack the system behaves similarly to an exponential system, except it breaks down much quicker. As the number of attacks increases, ''S'' decreases with a threshold close to f=0.05, and &lt;nowiki&gt;&lt;s&gt;&lt;/nowiki&gt; increases to the same threshold and then decreases back to one. The speed at which this type of network  breaks down shows the vulnerability of common networks that are used everyday, such as the Internet.&lt;ref name= Murphey /&gt;

==See also==
*[[Complex network]]
*[[Scale-free network]]
*[[Degree distribution]]

==References==
{{reflist|refs=
&lt;ref name= Murphey&gt;{{cite book|last1=Sorokin|first1=Alexey|last2=Murphey|first2=Robert|last3=Thai|first3=My|last4=Pardalos|first4=Panos|title=Dynamics of Information Systems: Mathematical Foundations|date=2012|publisher=Springer New York|isbn=978-1-4614-3905-9}}&lt;/ref&gt;
&lt;ref name=Barabasi&gt;{{cite book|last1=BARABÁSI|first1=ALBERT-LÁSZLÓ|title=NETWORK SCIENCE|date=2014}}&lt;/ref&gt;
&lt;ref name=Time-varying&gt;{{cite journal|last1=Sur|first1=Souvik|last2=Ganguly|first2=Niloy|last3=Mukherjee|first3=Animesh|title=Attack tolerance of correlated time-varying social networks with well-defined communities|url=http://www.sciencedirect.com/science/article/pii/S0378437114009455|accessdate=16 November 2014|doi=10.1016/j.physa.2014.08.074|volume=420|journal=Physica A: Statistical Mechanics and its Applications|pages=98–107|bibcode=2015PhyA..420...98S}}&lt;/ref&gt;
&lt;ref name=Achilles&gt;{{cite journal|last1=Albert|first1=Réka|last2=Jeong|first2=Hawoong|last3=Barabási|first3=Albert-László|title=The Internet's Achilles' Heel: Error and attack tolerance of complex networks|journal=Nature|date=2000|volume=406|doi= 10.1038/35019019|pages=378–382|arxiv=cond-mat/0008064}}&lt;/ref&gt;
}}

[[Category:Network theory]]</text>
      <sha1>4z1k78t2f2xji2ikjwb5osu50obcplz</sha1>
    </revision>
  </page>
  <page>
    <title>Bashar ibn Shu'aib</title>
    <ns>0</ns>
    <id>57917884</id>
    <revision>
      <id>866436284</id>
      <parentid>860188296</parentid>
      <timestamp>2018-10-30T09:38:20Z</timestamp>
      <contributor>
        <username>Veryproicelandic</username>
        <id>23790359</id>
      </contributor>
      <comment>added some links, removed that flag...</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="974">'''Bashar''' (or '''Bishr''') '''ben Phinehas ibn Shu'aib''' was a tenth century [[Jew]]ish [[mathematician]].&lt;ref name=jencmath&gt;{{Cite Jewish Encyclopedia|url=http://www.jewishencyclopedia.com/articles/10478-mathematics|title=Mathematics}}&lt;/ref&gt;

According to Hottinger (''Promptuarium'', p.&amp;nbsp;96), the [[Arabic language|Arabic]] works of Ibn Shu'aib are often quoted by [[Arabic literature|Arabic writer]]s. In 997, Abu 'Ali 'Isa ibn Zara'ah addressed to Ibn Shu'aib a [[pamphlet]] against [[Judaism]] which seemed to be an answer to a pro-Jewish work by Ibn Shu'aib (see Ibn Abi Uṣaibi'a, ''Uyun al-Anba'', ii. 236).

==References==
{{Jewish Encyclopedia |title=Ibn Shu'aib, Bishr (Bashar) ben Phinehas}}

* Steinschneider, ''Polemische Literatur'', p.&amp;nbsp;145.
* Steinschneider, ''Die Arabische Litteratur der Juden'', § 61b.

{{reflist}}

[[Category:10th-century Jews]]
[[Category:Medieval mathematicians]]
[[Category:Jewish scientists]]


{{mathematician-stub}}</text>
      <sha1>sm3gioonuhz1xdi470vuspqhtm7k3k5</sha1>
    </revision>
  </page>
  <page>
    <title>Basic skills</title>
    <ns>0</ns>
    <id>6980594</id>
    <revision>
      <id>859117216</id>
      <parentid>859117206</parentid>
      <timestamp>2018-09-11T20:41:56Z</timestamp>
      <contributor>
        <username>ClueBot NG</username>
        <id>13286072</id>
      </contributor>
      <minor/>
      <comment>Reverting possible vandalism by [[Special:Contribs/2001:A61:4CA:B00:3D53:7ED8:A93A:5902|2001:A61:4CA:B00:3D53:7ED8:A93A:5902]] to version by Oshwah. [[WP:CBFP|Report False Positive?]] Thanks, [[WP:CBNG|ClueBot NG]]. (3470494) (Bot)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4491">'''Basic skills''' can be compared to [[higher order thinking skills]]. Facts and methods are highly valued under the [[back to basics (education)|back-to-basics]] approach to education.

* Facts are learned one at a time, in isolation, as compared to an [[integrated curriculum]] which combines fields of learning.
* They are learned from a book or teacher as compared to [[Constructivism (learning theory)|constructivism]] or [[student-centered learning]] where the learner constructs his or her own knowledge.
* [[Direct Instruction]] is based on teaching basic skills.
* They are learned for academics sake rather than in context or "real life" as compared to [[project-based learning]]. Critics who dismissed some mathematics as "Rainforest algebra" find pages filled with information about rainforests, the environment, or even shoe companies like Nike &lt;ref&gt;Core-Plus Mathematics Project Matrix unit 1&lt;/ref&gt; but very little information on how to actually solve the mathematics exercises.
* A basic skills test is generally a [[multiple choice]] which tests for one area of knowledge, as compared to a [[standards based assessment]] which requires an open response that requires integrating many different areas of knowledge such as communication, [[problem solving]], mathematics and science on a science item.
* Mathematical skills such as borrowing or long division are learned without adding cultural context such as multiculturalism or ethnic heritage or issues of social justice.
* Facts are learned in sequence, rather than spiraling. Some curriculum frameworks specify that students in all grade levels as early as Kindergarten will learn elements of number sense, algebra, geometry, statistics, mathematical communication, problem solving in nearly identical wording between grade levels.

Teaching methods that emphasize ''basic skills'' tend to be compatible with [[traditional education]] rather than student-centered [[standards based education reform]]. Materials that are primarily marketed to [[homeschool]]ers such as [[Saxon math]] and [[Modern Curriculum Press]] are based on emphasis on basic skills. Such curricula typically require much less teacher training, less expensive and smaller books, and do not require purchasing expensive expendable materials such as scissors, paste, paint, beads as is required by [[reform mathematics]] curricula such as [[Investigations in Number, Data, and Space]].

Most local, state and federal education agencies are committed to [[standards based education reform]], which is based on beliefs which conflict with the outcomes of traditional education. The goal is that all students will succeed at one high world-class level of what students know and are able to do, rather than different students learning different amounts on different tracks, producing some failures and some successes. [[Higher order thinking skills]] are emphasized by the new standards. A widely cited paper by [[Constance Kamii]] even suggests that teaching of basic arithmetic methods is harmful to learning, and guided the thinking behind many of today's commonly used mathematics teaching curricula.

==United Kingdom usage==
In the [[United Kingdom]], basic skills education is [[literacy]] and [[numeracy]] education for adults who for some reason did not acquire these skills or a level sufficient for everyday adult life when they were at school. It is therefore often referred to as "adult basic skills". [[Skills for life]] is a basic skills programme running in [[further education]] colleges, taken by young people over 16 and by older adults. Students on [[vocational education|vocational]] courses and [[apprentices]] are often required to take "key skills" units in communication, application of number and information and communication technology (ICT)....

==Australia usage==
Common name for the previous standard [[literacy]] and [[numeracy]] testing, undertaken in [[Year Three|Years 3]], [[Year Five|5]], [[Year Seven|7]] &amp; [[Year Nine|9]]. The Literacy and Numeracy test has been replaced by a standard Australia wide test called the [[NAPLAN test]].

== See also ==

* [[List of abandoned education methods]]
* [[Mathematically Correct]] Advocates for teaching basic skills
* [[NCTM]] Math standards organization which recently switched back to emphasis on basic skills.
* [[Standards based education reform]]
* [[Traditional education]]

==References==
{{reflist}}

[[Category:Mathematics education]]
[[Category:Education reform]]</text>
      <sha1>0ftga2iuix71hy859goj22f8xbvhiod</sha1>
    </revision>
  </page>
  <page>
    <title>Berger code</title>
    <ns>0</ns>
    <id>9898864</id>
    <revision>
      <id>855511230</id>
      <parentid>854785618</parentid>
      <timestamp>2018-08-18T21:04:16Z</timestamp>
      <contributor>
        <ip>95.40.235.140</ip>
      </contributor>
      <comment>removed bashing against the keyboard</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4439">In [[telecommunication]], a '''Berger code''' is a unidirectional [[error detection and correction|error detecting code]], named after its inventor, J. M. Berger. Berger codes can detect all unidirectional errors. Unidirectional errors are errors that only flip ones into zeroes or only zeroes into ones, such as in asymmetric channels. The [[check bits]] of Berger codes are computed by summing all the zeroes in the information word, and expressing that sum in natural binary. If the information word consists of &lt;math&gt;n&lt;/math&gt; bits, then the Berger code needs &lt;math&gt;k = \lceil \log_2 (n+1)\rceil &lt;/math&gt; "check bits", giving a Berger code of length k+n. (In other words, the &lt;math&gt;k&lt;/math&gt; check bits are enough to check up to &lt;math&gt;n = 2^k - 1&lt;/math&gt; information bits).
Berger codes can detect any number of one-to-zero bit-flip errors, as long as no zero-to-one errors occurred in the same code word.
Similarly, Berger codes can detect any number of zero-to-one bit-flip errors, as long as no one-to-zero bit-flip errors occur in the same code word.
Berger codes cannot correct any error.

Like all unidirectional error detecting codes,
Berger codes can also be used in [[delay-insensitive]] circuits.

==Unidirectional error detection==
As stated above, Berger codes detect ''any'' number of unidirectional errors. For a ''given code word'', if the only errors that have occurred are that some (or all) bits with value 1 have changed to value 0, then this transformation will be detected by the Berger code implementation. To understand why, consider that there are three such cases:
# Some 1s bit in the information part of the code word have changed to 0s.
# Some 1s bits in the check (or ''redundant'') portion of the code word have changed to 0s.
# Some 1s bits in both the information and check portions have changed to 0s.

For case 1, the number of 0-valued bits in the information section will, by definition of the error, increase. Therefore, our Berger check code will be lower than the actual 0-bit-count for the data, and so the check will fail.

For case 2, the number of 0-valued bits in the information section have stayed the same, but the value of the check data has changed. Since we know some 1s turned into 0s, but no 0s have turned into 1s (that's how we defined the error model in this case), the encoded binary value of the check data will go down (e.g., from binary 1011 to 1010, or to 1001, or 0011). Since the information data has stayed the same, it has the same number of zeros it did before, and that will no longer match the mutated check value.

For case 3, where bits have changed in both the information and the check sections, notice that the number of zeros in the information section has ''gone up'', as described for case 1, and the binary value stored in the check portion has ''gone down'', as described for case 2. Therefore, there is no chance that the two will end up mutating in such a way as to become a different valid code word.

A similar analysis can be performed, and is perfectly valid, in the case where the only errors that occur are that some 0-valued bits change to 1. Therefore, if all the errors that occur on a specific codeword all occur in the same direction, these errors will be detected. For the next code word being transmitted (for instance), the errors can go in the opposite direction, and they will still be detected, as long as they all go in the same direction as each other.

Unidirectional errors are common in certain situations. For instance, in [[flash memory]], bits can more easily be programmed to a 0 than can be reset to a 1.

==References==
* {{cite journal |author=J. M. Berger |title=A note on an error detection code for asymmetric channels |journal=Information and Control |volume=4 |issue=1 |pages=68–73 |date=March 1961 |doi=10.1016/S0019-9958(61)80037-5 |doi-access=free}}
* Subhasish Mitra and Edward J. McCluskey, "[http://crc.stanford.edu/crc_papers/mitraitc002.pdf Which concurrent error detection scheme to choose?]", Center for Reliable Computing, Stanford University, 2000.  {{CiteSeerX|10.1.1.9.2021}} 
* {{cite journal |url=http://alexandria.tue.nl/extra1/wskrap/publichtml/8837761.pdf |title=Delay-insensitive codes — an overview] by |author=Tom Verhoeff |journal=Dostributed Computing |date=March 1988 |volume=3 |issue=1 |pages=1–8 |doi=10.1007/BF01788562}}

[[Category:Coding theory]]
[[Category:Error detection and correction]]</text>
      <sha1>lhrsz4h1qgww6d9ti9u3yw708bq7ew7</sha1>
    </revision>
  </page>
  <page>
    <title>Bid–ask matrix</title>
    <ns>0</ns>
    <id>28293188</id>
    <revision>
      <id>725220526</id>
      <parentid>707596125</parentid>
      <timestamp>2016-06-14T09:06:15Z</timestamp>
      <contributor>
        <username>Nyq</username>
        <id>1893804</id>
      </contributor>
      <minor/>
      <comment>/* Mathematical Definition */ decapitalized common noun</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2420">The '''bid–ask matrix''' is a [[matrix (mathematics)|matrix]] with elements corresponding with exchange rates between the [[assets]].  These rates are in ''physical units'' (e.g. number of stocks) and not with respect to any ''[[numeraire]]''.  The &lt;math&gt;(i,j)&lt;/math&gt; element of the matrix is the number of units of asset &lt;math&gt;i&lt;/math&gt; which can be exchanged for 1 unit of asset &lt;math&gt;j&lt;/math&gt;.

==Mathematical definition==
A &lt;math&gt;d \times d&lt;/math&gt; matrix &lt;math&gt;\Pi = \left[\pi_{ij}\right]_{1 \leq i,j \leq d}&lt;/math&gt; is a ''bid-ask matrix'', if
# &lt;math&gt;\pi_{ij} &gt; 0&lt;/math&gt; for &lt;math&gt;1 \leq i,j \leq d&lt;/math&gt;.  Any trade has a positive exchange rate.
# &lt;math&gt;\pi_{ii} = 1&lt;/math&gt; for &lt;math&gt;1 \leq i \leq d&lt;/math&gt;.  Can always trade 1 unit with itself.
# &lt;math&gt;\pi_{ij} \leq \pi_{ik}\pi_{kj}&lt;/math&gt; for &lt;math&gt;1 \leq i,j,k \leq d&lt;/math&gt;.  A direct exchange is always at most as expensive as a chain of exchanges.&lt;ref name="WS02"&gt;{{cite journal|last=Schachermayer|first=Walter|date=November 15, 2002|title=The Fundamental Theorem of Asset Pricing under Proportional Transaction Costs in Finite Discrete Time}}&lt;/ref&gt;

==Example==
Assume a market with 2 assets (A and B), such that &lt;math&gt;x&lt;/math&gt; units of A can be exchanged for 1 unit of B, and &lt;math&gt;y&lt;/math&gt; units of B can be exchanged for 1 unit of A.  Then the ''bid–ask matrix'' &lt;math&gt;\Pi&lt;/math&gt; is:

: &lt;math&gt;\Pi = \begin{bmatrix}
1 &amp; x \\
y &amp; 1
\end{bmatrix}&lt;/math&gt;

==Relation to solvency cone==
If given a bid–ask matrix &lt;math&gt;\Pi&lt;/math&gt; for &lt;math&gt;d&lt;/math&gt; assets such that &lt;math&gt;\Pi = \left(\pi^{ij}\right)_{1 \leq i,j \leq d}&lt;/math&gt; and &lt;math&gt;m \leq d&lt;/math&gt; is the number of assets which with any non-negative quantity of them can be "discarded" (traditionally &lt;math&gt;m = d&lt;/math&gt;).  Then the [[solvency cone]] &lt;math&gt;K(\Pi) \subset \mathbb{R}^d&lt;/math&gt; is the convex cone spanned by the unit vectors &lt;math&gt;e^i, 1 \leq i \leq m&lt;/math&gt; and the vectors &lt;math&gt;\pi^{ij}e^i-e^j, 1 \leq i,j \leq d&lt;/math&gt;.&lt;ref name="WS02" /&gt;

Similarly given a (constant) solvency cone it is possible to extract the bid–ask matrix from the bounding vectors.

==Notes==
* The [[bid–ask spread]] for pair &lt;math&gt;(i,j)&lt;/math&gt; is &lt;math&gt;\left\{\frac{1}{\pi_{ji}},\pi_{ij}\right\}&lt;/math&gt;.
* If &lt;math&gt;\pi_{ij} = \frac{1}{\pi_{ji}}&lt;/math&gt; then that pair is [[frictionless market|frictionless]].

==References==
{{Reflist}}

{{DEFAULTSORT:Bid-ask matrix}}
[[Category:Mathematical finance]]</text>
      <sha1>f4h9lnt0llfch3ga9rlfwuim95p6da1</sha1>
    </revision>
  </page>
  <page>
    <title>Blum–Shub–Smale machine</title>
    <ns>0</ns>
    <id>14988352</id>
    <revision>
      <id>763882614</id>
      <parentid>734567455</parentid>
      <timestamp>2017-02-05T19:51:32Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>rewrite of [[real RAM]] makes merge less appropriate — remove stale merge tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2811">In [[computation theory]], the '''Blum–Shub–Smale machine''', or '''BSS machine''', is a model of computation introduced by [[Lenore Blum]], [[Michael Shub]] and [[Stephen Smale]], intended to describe computations over the real numbers. Essentially, a BSS machine is a [[Random Access Machine]] with registers that can store arbitrary real numbers and that can compute rational functions over reals at unit cost. It is often referred to as [[Real RAM]] model.

==Definition==
A BSS machine M is given by the set &lt;math&gt;I&lt;/math&gt; of &lt;math&gt;N+1&lt;/math&gt; instructions, indexed &lt;math&gt;0, 1, \dots, N&lt;/math&gt;. A configuration of M is a tuple &lt;math&gt;(k,r,w,x)&lt;/math&gt;, where k is the number of the instruction currently executed, r and w are copy registers and x stores the content of all registers of M. The computation begins with configuration &lt;math&gt;(0,0,0,x)&lt;/math&gt; and ends whenever &lt;math&gt;k=N&lt;/math&gt;, the final content of x is said to be the output of the machine.

The instructions of M can be of the following types:
*Computation&lt;math&gt;(x_{0})&lt;/math&gt;: a substitution &lt;math&gt;x_{0} := g_{k}(x)&lt;/math&gt; is performed, where &lt;math&gt;g_{k}&lt;/math&gt; is an arbitrary rational function; copy registers r and w may be changed, either by &lt;math&gt;r := 0&lt;/math&gt; or &lt;math&gt;r := r + 1&lt;/math&gt; and similarly for w. 
*Branch&lt;math&gt;(x_{0}, l)&lt;/math&gt;: if &lt;math&gt;x_{0} \geq 0&lt;/math&gt; then goto l else goto k+1.
*Copy(&lt;math&gt;x_{r}, x_{w}&lt;/math&gt;): the content of the "read" register &lt;math&gt;x_{r}&lt;/math&gt; is copied into the "write" register &lt;math&gt;x_{w}&lt;/math&gt;; the next instruction is k+1

==See also==
*[[Hypercomputation]]
*[[Real computer]]

==Further reading==
* {{cite book | last=Bürgisser | first=Peter | title=Completeness and reduction in algebraic complexity theory | zbl=0948.68082 | series=Algorithms and Computation in Mathematics | volume=7 | location=Berlin | publisher=[[Springer-Verlag]] | year=2000 | isbn=3-540-66752-0 }}
*{{cite book|last=Grädel|first=E.|title=Finite Model Theory and Its Applications|publisher=Springer-Verlag|year=2007|zbl=1133.03001|pages=125–230|chapter=Finite Model Theory and Descriptive Complexity|url=http://www.logic.rwth-aachen.de/pub/graedel/FMTbook-Chapter3.pdf}}
*{{cite journal| last1=Blum | first1=Lenore | author1-link=Lenore Blum | last2=Shub | first2=Mike | author2-link=Michael Shub | last3=Smale | first3=Steve | author3-link=Stephen Smale | zbl=0681.03020 | pages=1–46 | doi=10.1090/S0273-0979-1989-15750-9 | year=1989|title=On a Theory of Computation and Complexity over the Real Numbers: NP-completeness, Recursive Functions and Universal Machines|journal=Bulletin of the American Mathematical Society|volume=21|issue=1|url=http://www.ams.org/bull/1989-21-01/S0273-0979-1989-15750-9/S0273-0979-1989-15750-9.pdf}}

{{DEFAULTSORT:Blum-Shub-Smale machine}}
[[Category:Models of computation]]</text>
      <sha1>1wgu8nj1f1v3139j3kr03t4doboaglz</sha1>
    </revision>
  </page>
  <page>
    <title>Contour line</title>
    <ns>0</ns>
    <id>650086</id>
    <revision>
      <id>870727641</id>
      <parentid>870727598</parentid>
      <timestamp>2018-11-26T17:43:12Z</timestamp>
      <contributor>
        <username>Alex Cohn</username>
        <id>60778</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contributions/92.238.95.204|92.238.95.204]] ([[User talk:92.238.95.204|talk]]) ([[WP:HG|HG]]) (3.4.4)</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="34885">{{About|lines of equal value in maps and diagrams|more meanings of the word "contour"|Contour (disambiguation)}}

[[File:Courbe niveau.svg|thumb|right|The bottom part of the diagram shows some contour lines with a straight line running through the location of the maximum value. The curve at the top represents the values along that straight line.]]	
[[Image:Contour3D.jpg|right|thumb|300px|A three-dimensional surface, whose contour graph is below.]]
[[Image:Contour2D.svg|right|thumb|300px|A two-dimensional contour graph of the three-dimensional surface in the above picture.]]

A '''contour line''' (also '''isoline''', '''isopleth''', or '''isarithm''') of a [[Function (mathematics)|function]] of two variables is a  [[curve]] along which the function has a constant value, so that the curve joins points of equal value.&lt;ref&gt;Courant, Richard, Herbert Robbins, and Ian Stewart. ''What Is Mathematics?: An Elementary Approach to Ideas and Methods''. New York: Oxford University Press, 1996. [https://books.google.com/books?id=_kYBqLc5QoQC&amp;pg=PA344 p. 344.]&lt;/ref&gt;&lt;ref name="Hughes"&gt;{{cite book|last1=Hughes-Hallett|first1=Deborah|last2=McCallum|first2=William G.|last3=Gleason|first3=Andrew M.|title=Calculus : Single and Multivariable|date=2013|publisher=John wiley|isbn=978-0470-88861-2|edition=6|accessdate=}}&lt;/ref&gt; It is a [[cross-section (geometry)#Definition|plane section]] of the [[graph of a function of two variables|three-dimensional graph]] of the function ''f''(''x'', ''y'') parallel to the ''x'', ''y'' plane. In [[cartography]], a contour line (often just called a "contour") joins points of equal [[elevation]] (height) above a given level, such as [[mean sea level]].&lt;ref&gt;[http://dictionary.reference.com/browse/contour%20line Merriam Webster - ''contour line'']&lt;/ref&gt; A '''contour map''' is a [[map]] illustrated with contour lines, for example a [[topographic map]], which thus shows valleys and hills, and the steepness or gentleness of slopes.&lt;ref&gt;[http://www.merriam-webster.com/dictionary/contour%20map ''contour map'' Merriam Webster]&lt;/ref&gt;  The '''contour interval''' of a contour map is the difference in elevation between successive contour lines.&lt;ref&gt;Tracy, John C. ''Plane Surveying; A Text-Book and Pocket Manual''. New York: J. Wiley &amp; Sons, 1907. [https://books.google.com/books?id=lp0NAAAAYAAJ&amp;pg=PA337 p. 337.]&lt;/ref&gt;

More generally, a contour line for a function of two variables is a curve connecting points where the function has the same particular value.&lt;ref name="Hughes"/&gt;

The [[gradient]] of the function is always perpendicular to the contour lines. When the lines are close together the magnitude of the gradient is large: the variation is steep. A [[level set]] is a generalization of a contour line for functions of any number of variables.

Contour lines are curved, straight or a mixture of both lines on a [[map]] describing the intersection of a real or hypothetical surface with one or more horizontal planes. The configuration of these contours allows map readers to infer relative gradient of a parameter and estimate that parameter at specific places. Contour lines may be either traced on a visible three-dimensional model of the [[surface (mathematics)|surface]], as when a photogrammetrist viewing a stereo-model plots elevation contours, or interpolated from estimated surface [[elevations]], as when a computer program threads contours through a network of observation points of area centroids. In the latter case, the method of [[interpolation]] affects the reliability of individual isolines and their portrayal of [[slope]], pits and peaks.&lt;ref&gt;Davis, John C., 1986, ''Statistics and data analysis in geology'', Wiley {{ISBN|0-471-08079-9}}&lt;/ref&gt;

== Types ==&lt;!-- [[Isogon]] and internal links redirect here --&gt;
Contour lines are often given specific names beginning "iso-" ({{lang-grc|ἴσος|isos|equal}}) according to the nature of the variable being mapped, although in many usages the phrase "contour line" is most commonly used. Specific names are most common in meteorology, where multiple maps with different variables may be viewed simultaneously. The prefix "iso-" can be replaced with "isallo-" to specify a contour line connecting points where a variable changes at the same ''rate'' during a given time period.

The words ''isoline'' and ''isarithm'' ({{lang|grc|ἀριθμός}} ''{{lang|grc-Latn|arithmos}}'' "number") are general terms covering all types of contour line.  The word ''isogram'' ({{lang|grc|γράμμα}} ''{{lang|grc-Latn|gramma}}'' "writing or drawing") was proposed by [[Francis Galton]] in 1889 as a convenient generic designation for lines indicating equality of some physical condition or quantity;&lt;ref&gt;Oxford English Dictionary; see also: Nature, 40, 1889, p.651.&lt;/ref&gt; but it commonly refers to a [[isogram|word without a repeated letter]].

An '''isogon''' (from {{lang|grc|γωνία}} or ''gonia'', meaning 'angle') is a contour line for a variable which measures direction.  In meteorology and in geomagnetics, the term ''isogon'' has specific meanings which are described below.  An '''[[isocline]]''' (from {{lang|grc|κλίνειν}} or ''klinein'', meaning 'to lean or slope') is a line joining points with equal slope.  In population dynamics and in geomagnetics, the terms ''isocline'' and ''isoclinic line'' have specific meanings which are described below.

=== Equidistant points ===
A curve of equidistant points is a set of points all at the same distance from a given [[point (geometry)|point]], [[line (geometry)|line]], or [[polyline]]. In this case the function whose value is being held constant along a contour line is a [[distance function]].

=== Isopleths ===&lt;!-- [[Isopleth]] and [[Isopleths]] redirect here --&gt;
In geography, the word ''isopleth'' (from {{lang|grc|πλῆθος}} or ''plethos'', meaning 'quantity') is used for contour lines that depict a variable which cannot be measured at a point, but which instead must be calculated from data collected over an area. An example is [[population density]], which can be calculated by dividing the population of a [[census tract|census district]] by the surface area of that district. Each calculated value is presumed to be the value of the variable at the centre of the area, and isopleths can then be drawn by a process of [[interpolation]]. The idea of an isopleth map can be compared with that of a [[choropleth map]].&lt;ref&gt;{{cite journal | vauthors = Robinson AH | authorlink = Arthur H. Robinson | year = 1971 | title = The genealogy of the isopleth | url = | journal = Cartographic Journal | volume = 8 | issue = | pages = 49–53 }}&lt;/ref&gt;&lt;ref&gt;T. Slocum, R. McMaster, F. Kessler, and H. Howard, ''Thematic Cartography and Geographic Visualization'', 2nd edition, Pearson, 2005, {{ISBN|0-13-035123-7}}, p. 272.&lt;/ref&gt;&lt;ref&gt;ArcGIS, [http://www.arcgis.com/home/item.html?id=830338fc8ca947c38b8d97f51724f5c9 Isopleth: Contours], 2013.&lt;/ref&gt;

In meteorology, the word ''isopleth'' is used for any type of contour line.&lt;ref&gt;NOAA's National Weather Service, [http://w1.weather.gov/glossary/index.php?letter=i Glossary].&lt;/ref&gt;

=== Meteorology ===
[[File:Isohyet.png|thumb|Isohyetal map of precipitation]]

Meteorological contour lines are based on [[interpolation]] of the point data received from [[weather station]]s and [[weather satellite]]s. Weather stations are seldom exactly positioned at a contour line (when they are, this indicates a measurement precisely equal to the value of the contour). Instead, lines are drawn to best approximate the locations of exact values, based on the scattered information points available.

[[Weather maps|Meteorological contour maps]] may present collected data such as actual air pressure at a given time, or generalized data such as average pressure over a period of time, or forecast data such as predicted air pressure at some point in the future

[[Thermodynamic diagrams]] use multiple overlapping contour sets (including isobars and isotherms) to present a picture of the major thermodynamic factors in a weather system.

==== Barometric pressure ====&lt;!-- [[Isobar (meteorology)]] redirects here --&gt;
[[File:Loop isallobaric tendencies.gif|thumb|Loop showing the motion of a cold front by the movement of isallobars]]
An '''isobar''' (from {{linktext|lang=grc|βάρος}} or ''baros'', meaning 'weight') is a line of equal or constant [[pressure]] on a graph, plot, or map; an isopleth or contour line of pressure.
More accurately, isobars are lines drawn on a map joining places of equal average atmospheric pressure reduced to sea level for a specified period of time. In [[meteorology]], the [[barometric pressure]]s shown are reduced to [[sea level]], not the surface pressures at the map locations.&lt;ref&gt;{{cite web|publisher=University of Wisconsin|author=Edward J. Hopkins, Ph.D.|date=1996-06-10|url=http://www.meteor.wisc.edu/~hopkins/aos100/sfc-anl.htm|title=Surface Weather Analysis Chart|accessdate=2007-05-10}}&lt;/ref&gt;  The distribution of isobars is closely related to the magnitude and direction of the [[wind]] field, and can be used to predict future weather patterns. Isobars are commonly used in television weather reporting.

'''Isallobars''' are lines joining points of equal pressure change during a specific time interval.&lt;ref name="OMM"&gt;{{cite web | url= http://www.eumetcal.org/resources/ukmeteocal/rapid_cyclo/www/english/glossary/isalloba.htm | title= Isallobar | author= [[World Meteorological Organisation]] | work= Eumetcal | accessdate= 12 April 2014 | deadurl= yes | archiveurl= https://web.archive.org/web/20140416031654/http://www.eumetcal.org/resources/ukmeteocal/rapid_cyclo/www/english/glossary/isalloba.htm | archivedate= 16 April 2014 | df=  }}&lt;/ref&gt; These can be divided into ''anallobars'', lines joining points of equal pressure increase during a specific time interval,&lt;ref name="OMM-1"&gt;{{cite web | url= http://www.eumetcal.org/euromet/glossary/analloba.htm | archive-url= https://web.archive.org/web/20150924003018/http://www.eumetcal.org/euromet/glossary/analloba.htm | dead-url= yes | archive-date= 24 September 2015 | title= Anallobar | author= [[World Meteorological Organisation]] | work= Eumetcal | accessdate= 12 April 2014 }}&lt;/ref&gt; and ''katallobars'', lines joining points of equal pressure decrease.&lt;ref name="OMM-2"&gt;{{cite web | url= http://www.eumetcal.org/euromet/glossary/katallob.htm | archive-url= https://web.archive.org/web/20080205124154/http://www.eumetcal.org/euromet/glossary/katallob.htm | dead-url= yes | archive-date= 5 February 2008 | title= Katallobar | author= [[World Meteorological Organisation]] | work= Eumetcal | accessdate= 12 April 2014 }}&lt;/ref&gt; In general, weather systems move along an axis joining high and low isallobaric centers.&lt;ref&gt;{{ cite web | url= http://apollo.lsc.vsc.edu/classes/met130/notes/chapter13/isallobars.html | title= Forecasting weather system movement with pressure tendency | work= Chapter 13 - Weather Forecasting | publisher = Lyndon State College Atmospheric Sciences | accessdate = 12 April 2014}}&lt;/ref&gt; Isallobaric gradients are important components of the wind as they increase or decrease the [[geostrophic wind]].

An [[isopycnal]] is a line of constant density. An ''isoheight'' or ''isohypse'' is a line of constant [[geopotential]] height on a constant pressure surface chart. Isohypse and isoheight are simply known as lines showing equal pressure on a map.

==== Temperature and related subjects ====
[[Image:arctic.svg|thumb|The {{convert|10|C}} mean isotherm in July, marked by the red line, is commonly used to define the border of the [[Arctic region]]]]

An '''isotherm''' (from {{linktext|lang=grc|θέρμη}} or ''thermē'', meaning 'heat') is a line that connects points on a map that have the same [[temperature]]. Therefore, all points through which an isotherm passes have the same or equal temperatures at the time indicated.&lt;ref name="DataAir"&gt;{{cite web|author=DataStreme Atmosphere|publisher=American Meteorological Society|url=http://www.ametsoc.org/amsedu/dstreme/learn/sample.act.html |title=Air Temperature Patterns|date=2008-04-28|accessdate=2010-02-07 |archiveurl = https://web.archive.org/web/20080511124504/http://www.ametsoc.org/amsedu/dstreme/learn/sample.act.html |archivedate = 2008-05-11}}&lt;/ref&gt;&lt;ref name="Hughes"/&gt;  An isotherm at 0&amp;nbsp;°C is called the [[freezing level]]. The term was coined by the Prussian geographer and naturalist Alexander von Humboldt, who as part of his research into the geographical distribution of plants published the first map of isotherms in Paris, in 1817.&lt;ref&gt;{{Cite journal|last=Munzar|first=Jan|date=1967-09-01|title=Alexander Von Humboldt and His Isotherms|url=http://onlinelibrary.wiley.com/doi/10.1002/j.1477-8696.1967.tb02989.x/abstract|journal=Weather|language=en|volume=22|issue=9|pages=360–363|doi=10.1002/j.1477-8696.1967.tb02989.x|issn=1477-8696|bibcode=1967Wthr...22..360M}}&lt;/ref&gt;

An '''isogeotherm''' is a line of equal mean annual temperature. An '''isocheim''' is a line of equal mean winter temperature, and an '''isothere''' is a line of equal mean summer temperature.

An '''isohel''' (from {{linktext|lang=grc|ἥλιος}} or ''helios'', meaning 'Sun') is a line of equal or constant [[solar radiation]].

==== Rainfall and air moisture ====
An '''isohyet''' or '''isohyetal line''' (from {{linktext|lang=grc|ὕετος}} or ''huetos'', meaning 'rain') is a line joining points of equal rainfall on a [[map]] in a given period . A map with isohyets is called an '''isohyetal map'''.

An '''isohume''' is a line of constant relative [[humidity]], while a '''isodrosotherm''' (from {{linktext|lang=grc|δρόσος}} or ''drosos'', meaning 'dew', and {{lang|grc|θέρμη}} or ''therme'', meaning 'heat') is a line of equal or constant [[dew point]].

An '''isoneph''' is a line indicating equal [[cloud]] cover.

An '''isochalaz''' is a line of constant frequency of [[hail]] storms, and an '''isobront''' is a line drawn through geographical points at which a given phase of thunderstorm activity occurred simultaneously.

[[Snow]] cover is frequently shown as a contour-line map.

==== Wind ====&lt;!-- [[Isogon (meteorology)]] redirects here --&gt;
An '''isotach''' (from {{linktext|lang=grc|ταχύς}} or ''tachus'', meaning 'fast') is a line joining points with constant [[wind]] speed.
In meteorology, the term '''isogon''' refers to a line of constant wind direction.

==== Freeze and thaw ====
An '''isopectic''' line denotes equal dates of [[ice]] formation each winter, and an '''isotac''' denotes equal dates of thawing.

=== Physical geography and oceanography ===

==== Elevation and depth ====
[[File:Topographic map example.png|thumb|right|[[Topographic map]] of [[Stowe, Vermont|Stowe]], [[Vermont]]. The brown contour lines represent the [[elevation]]. The contour interval is 20 [[foot (length)|feet]].]]

Contours are one of several [[Cartographic relief depiction|common methods]] used to denote [[elevation]] or [[altitude]] and depth on [[map]]s. From these contours, a sense of the general [[terrain]] can be determined. They are used at a variety of scales, from large-scale engineering drawings and architectural plans, through [[topographic maps]] and [[bathymetric charts]], up to continental-scale maps.

"Contour line" is the most common usage in [[cartography]], but [[isobath]] for underwater depths on [[bathymetric]] maps and '''isohypse''' for elevations are also used.

In cartography, the '''contour interval''' is the elevation difference between adjacent contour lines. The contour interval should be the same over a single map. When calculated as a ratio against the map scale, a sense of the hilliness of the terrain can be derived.

===== Interpretation =====

There are several rules to note when interpreting terrain contour lines:
* '''The rule of Vs''': sharp-pointed vees usually are in stream valleys, with the drainage channel passing through the point of the vee, with the vee pointing upstream. This is a consequence of [[erosion]].
* '''The rule of Os''': closed loops are normally uphill on the inside and downhill on the outside, and the innermost loop is the highest area. If a loop instead represents a depression, some maps note this by short lines radiating from the inside of the loop, called "hachures".
* '''Spacing of contours''': close contours indicate a steep slope; distant contours a shallow slope. Two or more contour lines merging indicates a cliff. By counting the number of contours that cross a segment of a [[stream]], the [[stream gradient]] can be approximated.

Of course, to determine differences in elevation between two points, the contour interval, or distance in altitude between two adjacent contour lines, must be known, and this is normally stated in the map key. Usually contour intervals are consistent throughout a map, but there are exceptions. Sometimes intermediate contours are present in flatter areas; these can be dashed or dotted lines at half the noted contour interval. When contours are used with hypsometric tints on a small-scale map that includes mountains and flatter low-lying areas, it is common to have smaller intervals at lower elevations so that detail is shown in all areas. Conversely, for an island which consists of a plateau surrounded by steep cliffs, it is possible to use smaller intervals as the height increases.&lt;ref&gt;''[[Sark]] (Sercq)'', D Survey, Ministry of Defence, Series M 824, Sheet Sark, Edition 4 GSGS, 1965, [[Online Computer Library Center|OCLC]] {{OCLC|27636277}}. Scale 1:10,560. Contour intervals: 50&amp;nbsp;feet up to 200, 20&amp;nbsp;feet from 200 to 300, and 10&amp;nbsp;feet above 300.&lt;/ref&gt;

==== Electrostatics ====
An '''[[isopotential map]]''' is a measure of electrostatic potential in space, often depicted in two dimensions with the electostatic charges inducing that [[electric potential]]. The term '''[[equipotential]] line''' or '''isopotential line'''  refers to a curve of constant [[electric potential]]. Whether crossing an equipotential line represents ascending or descending the potential is inferred from the labels on the charges. In three dimensions, '''[[equipotential]] surfaces''' may be depicted with a two dimensional cross-section, showing [[equipotential]] lines at the intersection of the surfaces and the cross-section.

The general mathematical term [[level set]] is often used to describe the full collection of points having a particular potential, especially in higher dimensional space.

==== Magnetism ====&lt;!-- [[Isogon (geomagnetism)]], [[Isogonic line]], [[Isogonic lines]], [[Agonic line]], [[Agonic lines]], [[Isoclinic line]], [[Aclinic line]] and [[Isodynamic line]] redirect here --&gt;
[[Image:IGRF 2000 magnetic declination.gif|thumb|left|Isogonic lines for the year 2000. The agonic lines are thicker and labeled with "0".]]
In the study of the [[Earth's magnetic field]], the term '''isogon''' or '''isogonic line''' refers to a line of constant [[magnetic declination]], the variation of magnetic north from geographic north. An '''agonic line''' is drawn through points of zero magnetic declination. An '''isoporic line''' refers to a line of constant annual variation of magnetic declination
.&lt;ref&gt;{{cite web|url=http://historicalcharts.noaa.gov/historicals/preview/image/3077-00-1946
|accessdate=2015-07-20
|title=isoporic line
|date=1946
}}&lt;/ref&gt;

An '''isoclinic line''' connects points of equal [[magnetic dip]], and an '''aclinic line''' is the isoclinic line of magnetic dip zero.

An '''isodynamic line''' (from {{lang|grc|δύναμις}} or ''dynamis'' meaning 'power') connects points with the same intensity of magnetic force.

==== Oceanography ====
Besides ocean depth, [[oceanography|oceanographers]] use contour to describe diffuse variable phenomena much as meteorologists do with atmospheric phenomena. In particular, '''isobathytherms''' are lines showing depths of water with equal temperature, '''isohalines''' show lines of equal ocean salinity, and '''[[Isopycnal]]s''' are surfaces of equal water density.

=== Geology ===
Various [[Geology|geological]] data are rendered as contour maps in [[structural geology]], [[sedimentology]], [[stratigraphy]] and [[economic geology]]. Contour maps are used to show the below ground surface of geologic [[stratum|strata]], [[Fault (geology)|fault]] surfaces (especially low angle [[thrust fault]]s) and [[unconformity|unconformities]]. [[Isopach map]]s use '''isopachs''' (lines of equal thickness) to illustrate variations in thickness of geologic units.

=== Environmental science ===
In discussing pollution, density maps can be very useful in indicating sources and areas of greatest contamination. Contour maps are especially useful for diffuse forms or scales of pollution. Acid precipitation is indicated on maps with '''isoplats'''.  Some of the most widespread applications of environmental science contour maps involve mapping of [[environmental noise]] (where lines of equal sound pressure level are denoted '''isobels'''&lt;ref&gt;{{cite web|url=https://www.sfu.ca/sonic-studio/handbook/Isobel.html
|accessdate=2010-04-25
|title=Isobel
|date=2005-01-05
}}&lt;/ref&gt;), [[air pollution]], [[soil contamination]], [[thermal pollution]] and [[groundwater]] contamination.  By [[contour planting]] and [[contour ploughing]], the rate of [[water runoff]] and thus [[soil erosion]] can be substantially reduced; this is especially important in [[riparian]] zones.

=== Ecology ===
An '''isoflor''' is an isopleth contour connecting areas of comparable biological diversity. Usually, the variable is the number of species of a given genus or family that occurs in a region. Isoflor maps are thus used to show distribution patterns and trends such as centres of diversity.&lt;ref name="Specht 1981"&gt;{{cite book | author = Specht, Raymond | title = Heathlands and related shrublands: Analytical studies | publisher = Elsevier | pages = 219–220}}&lt;/ref&gt;

=== Social sciences ===
[[File:Simple-indifference-curves.svg|thumb|240px|left|From [[economics]], an indifference map with three indifference curves shown. All points on a particular indifference curve have the same value of the [[utility function]], whose values implicitly come out of the page in the unshown third dimension.]]

In [[economics]], contour lines can be used to describe features which vary quantitatively over space. An '''[[wikt:isochrone|isochrone]]''' shows lines of equivalent drive time or travel time to a given location and is used in the generation of [[isochrone map]]s. An '''isotim''' shows equivalent transport costs from the source of a raw material, and an '''[[isodapane]]''' shows equivalent cost of travel time.

[[File:TE-Production-Isoquant.png|thumb|250px|right|A single production isoquant (convex) and a single isocost curve (linear). [[labor demand|Labor]] usage is plotted horizontally and [[physical capital]] usage is plotted vertically.]]

Contour lines are also used to display non-geographic information in economics. '''[[Indifference curves]]''' (as shown at left) are used to show bundles of goods to which a person would assign equal utility. An '''[[isoquant]]''' (in the image at right) is a curve of equal production quantity for alternative combinations of [[factors of production|input usages]], and an '''[[isocost|isocost curve]]''' (also in the image at right) shows alternative usages having equal production costs.

In [[political science]] an analogous method is used in understanding coalitions (for example the diagram in Laver and Shepsle's work&lt;ref&gt;Laver, Michael and Kenneth A. Shepsle (1996) Making and breaking governments [https://books.google.com/books?id=nFeKE07AUMsC&amp;pg=PA132&amp;lpg=PA132 pictures].&lt;/ref&gt;).

In [[population dynamics]], an '''[[isocline]]''' shows the set of population sizes at which the rate of change, or partial derivative, for one population in a pair of interacting populations is zero.

=== Statistics ===
In statistics, isodensity lines &lt;ref name="Fernandez 2011"&gt;{{cite journal |vauthors= Fernández, Antonio|date=2011 |title= A Generalized Regression Methodology for Bivariate Heteroscedastic Data|url= http://www.tandfonline.com/doi/abs/10.1080/03610920903444011|journal= Communications in Statistics - Theory and Methods|publisher= Taylor and Francis |volume= 40|issue=4 |pages= 601 |doi=10.1080/03610920903444011}}&lt;/ref&gt; or isodensanes are lines that join points with the same value of a [[probability density]]. Isodensanes are used to display [[bivariate distribution]]s. For example, for a bivariate [[elliptical distribution]] the isodensity lines are [[ellipse]]s.

=== Thermodynamics, engineering, and other sciences ===
Various types of graphs in [[thermodynamics]], engineering, and other sciences use isobars (constant pressure), isotherms (constant temperature), isochors (constant specific volume), or other types of isolines, even though these graphs are usually not related to maps.  Such isolines are useful for representing more than two dimensions (or quantities) on two-dimensional graphs.  Common examples in thermodynamics are some types of [[phase diagram]]s.

'''[[Isocline]]s''' are used to solve [[ordinary differential equations]].

In interpreting [[radar]] images, an '''isodop''' is a line of equal [[Doppler effect|Doppler]] velocity, and an '''isoecho''' is a line of equal radar reflectivity.

=== Other phenomena ===
* isochasm: [[aurora (astronomy)|aurora]] equal occurrence
* isochor: [[volume]]
* isodose: [[Absorbed dose]] of radiation
* isophene: biological events occurring with [[coincidence]] such as plants [[flowering]]
* isophote: [[illuminance]]
* mobile telephony: [[Received signal strength indication|mobile received power]] and [[Coverage (telecommunication)|cell coverage area]]

==Algorithms==
* finding boundaries of level sets after [[image segmentation]]
** [[Edge detection]]
** [[Level-set method]]
** [[Boundary tracing]]
* [[Active contour model]]

== History ==
The idea of lines that join points of equal value was rediscovered several times. The oldest known [[isobath]] (contour line of constant depth) is found on a map dated 1584 of the river [[Spaarne]], near [[Haarlem]], by [[Dutch (ethnic group)|Dutchman]] Pieter Bruinsz.&lt;ref name=":0"&gt;{{Cite journal|url=http://www.age-geografia.es/ojs/index.php/bage/article/viewFile/2414/2262|title=Orígenes de la representación topográfica del terreno en algunos mapas hispanoamericanos del s. XVI|last=Morato-Moreno|first=Manuel|date=2017|journal=Boletín de la Asociación de Geógrafos Españoles|doi=|pmid=}}&lt;/ref&gt; In 1701, [[Edmond Halley]] used such lines (isogons) on a chart of magnetic variation.&lt;ref&gt;Thrower, N. J. W. ''Maps and Civilization: Cartography in Culture and Society'', University of Chicago Press, 1972, revised 1996, page 97; and Jardine, Lisa ''Ingenious Pursuits: Building the Scientific Revolution'', Little, Brown, and Company, 1999, page 31.&lt;/ref&gt;  The Dutch engineer [[Nicolaas Kruik|Nicholas Cruquius]] drew the bed of the river [[Merwede]] with lines of equal depth (isobaths) at intervals of 1 [[fathom]] in 1727, and [[Philippe Buache]] used them at 10-fathom intervals on a chart of the [[English Channel]] that was prepared in 1737 and published in 1752.  Such lines were used to describe a land surface (contour lines) in a map of the Duchy of Modena and Reggio by Domenico Vandelli in 1746, and they were studied theoretically by Ducarla in 1771, and [[Charles Hutton]] used them in the [[Schiehallion experiment]].  In 1791, a map of [[France]] by J. L. Dupain-Triel used contour lines at 20-metre intervals, hachures, spot-heights and a vertical section.  In 1801, the chief of the Corps of Engineers, [[François Nicolas Benoît, Baron Haxo|Haxo]], used contour lines at the larger scale of 1:500 on a plan of his projects for Rocca d'Aufo.&lt;ref name="Skel58"&gt;R. A. Skelton, "Cartography", ''History of Technology'', Oxford, vol. 6, pp. 612-614, 1958.&lt;/ref&gt;&lt;ref&gt;Colonel Berthaut, ''La Carte de France'', vol. 1, p. 139, quoted by Close.&lt;/ref&gt;&lt;ref&gt;C. Hutton, "An account of the calculations made from the survey and measures taken at Schehallien, in order to ascertain the mean density of the Earth", ''Philosophical Transactions of the Royal Society of London'', vol. 68, pp. [http://gallica.bnf.fr/ark:/12148/bpt6k55873m/f808.item 756]-[http://gallica.bnf.fr/ark:/12148/bpt6k55873m/f809.item 757]&lt;/ref&gt;

By around 1843, when the [[Ordnance Survey]] started to regularly record contour lines in [[Great Britain]] and [[Ireland]], they were already in general use in European countries.  Isobaths were not routinely used on [[nautical chart]]s until those of [[Russia]] from 1834, and those of Britain from 1838.&lt;ref name="Skel58"/&gt;&lt;ref&gt;C. Close, ''The Early Years of the Ordnance Survey'', 1926, republished by David and Charles, 1969, {{ISBN|0-7153-4477-3}}, pp. 141-144.&lt;/ref&gt;&lt;ref&gt;T. Owen and E. Pilbeam, ''Ordnance Survey: Map Makers to Britain since 1791'', HMSO, 1992, {{ISBN|0-11-701507-5}}.&lt;/ref&gt;

When maps with contour lines became common, the idea spread to other applications. Perhaps the latest to develop are [[air quality]] and [[noise pollution]] contour maps, which first appeared in the United States in approximately 1970, largely as a result of national legislation requiring spatial delineation of these parameters. In 2007, [[Pictometry International]] was the first to allow users to dynamically generate elevation contour lines to be laid over oblique images.

== Graphical design ==
{{For|features specific to [[topography]]|Terrain cartography#Contour lines|Topographic map#Conventions}}

To maximize readability of contour maps, there are several design choices available to the map creator, principally line weight, line [[color]], line type and method of numerical marking.

'''Line weight''' is simply the darkness or thickness of the line used.  This choice is made based upon the least intrusive form of contours that enable the reader to decipher the background information in the map itself.  If there is little or no content on the base map, the contour lines may be drawn with relatively heavy thickness.  Also, for many forms of contours such as topographic maps, it is common to vary the line weight and/or color, so that a different line characteristic occurs for certain numerical values. For example, in the [[topographic]] map above, the even hundred foot elevations are shown in a different weight from the twenty foot intervals.

'''Line color''' is the choice of any number of [[pigment]]s that suit the display.  Sometimes a [[Gloss (paint)|sheen or gloss]] is used as well as color to set the contour lines apart from the [[base map]].  Line colour can be varied to show other information.

'''Line type''' refers to whether the basic contour line is solid, dashed, dotted or broken in some other pattern to create the desired effect.  Dotted or dashed lines are often used when the underlying base map conveys very important (or difficult to read) information.  Broken line types are used when the location of the contour line is inferred.

'''Numerical marking''' is the manner of denoting the [[arithmetic]]al values of contour lines.  This can be done by placing numbers along some of the contour lines, typically using [[interpolation]] for intervening lines. Alternatively a map key can be produced associating the contours with their values.

If the contour lines are not numerically labeled and adjacent lines have the same style (with the same weight, color and type), then the direction of the gradient cannot be determined from the contour lines alone.  However, if the contour lines cycle through three or more styles, then the direction of the gradient can be determined from the lines.  The orientation of the numerical text labels is often used to indicate the direction of the slope.

== Plan view versus profile view ==
{{see also|Topographic profile}}
Most commonly contour lines are drawn in plan view, or as an observer in space would view the Earth's surface: ordinary map form. However, some parameters can often be displayed in profile view showing a vertical profile of the parameter mapped. Some of the most common parameters mapped in profile are [[air pollutant concentrations]] and [[Sound exposure level|sound level]]s.  In each of those cases it may be important to analyze (air pollutant concentrations or sound levels) at varying heights so as to determine the air quality or [[noise health effects]] on people at different elevations, for example, living on different floor levels of an urban apartment. &lt;!-- One can see an example of vertical contours in the article on [[noise barrier]]s. (Article does not have such an example.) --&gt; In actuality, both plan and profile view contour maps are used in [[air pollution]] and [[noise pollution]] studies.

== Labeling contour maps ==
[[Image:Cntr-map-1.jpg|right|thumb|300px|Contour map labeled aesthetically in an "elevation up" manner.]]

[[Labeling (map design)|Labels]] are a critical component of elevation maps. A properly labeled contour map helps the reader to quickly interpret the shape of the terrain. If numbers are placed close to each other, it means that the terrain is steep. Labels should be placed along a slightly curved line "pointing" to the summit or nadir, from several directions if possible, making the visual identification of the summit or nadir easy.&lt;ref&gt;Imhof, E., "Die Anordnung der Namen in der Karte," Annuaire International de Cartographie II, Orell-Füssli Verlag, Zürich, 93-129, 1962.&lt;/ref&gt;&lt;ref&gt;Freeman, H., "Computer Name Placement," ch. 29, in Geographical Information Systems, 1, D.J. Maguire, M.F. Goodchild, and D.W. Rhind, John Wiley, New York, 1991, 449-460.&lt;/ref&gt; Contour labels can be oriented so a reader is facing uphill when reading the label.

Manual labeling of contour maps is a time-consuming process, however, there are a few software systems that can do the job automatically and in accordance with cartographic conventions, called [[automatic label placement]].

== See also ==
{{Portal|Atlas}}
{{colbegin}}
* [[Active contour model]]
* [[Aeronautical chart]]
* [[Boundary tracing]]
* [[Cartogram]]
* [[Compass rose]]
* [[Curve tracing]]
* [[Dymaxion map]]
* [[Estate map]]
* [[Fall line (topography)]]
* [[Fantasy map]]
* [[Floor plan]]
* [[Geologic map]]
* [[Cartography|Map design]]
* [[Marching squares]]
* [[Nautical chart]]
* [[Pictorial maps]]
* [[Planform]]
* [[Plat]]
* [[Reversed map]]
* [[Road atlas]]
* [[Street map]]
* [[TERCOM]]
* [[Thematic map]]
* [[Topographic map]]
* [[World map]]
{{colend}}

== References ==
{{reflist|colwidth=35em}}

== External links ==
{{Commons category|Contour lines}}
* [http://phrontistery.info/contour.html ''Forthright's Phrontistery'']

{{Authority control}}

{{DEFAULTSORT:Contour Line}}
[[Category:Cartography]]
[[Category:Curves]]
[[Category:Multivariable calculus]]
[[Category:Topography]]</text>
      <sha1>50af2h22qr6hp3683kcy3x2emf8nvqh</sha1>
    </revision>
  </page>
  <page>
    <title>DNSS point</title>
    <ns>0</ns>
    <id>22079394</id>
    <revision>
      <id>788970703</id>
      <parentid>740693130</parentid>
      <timestamp>2017-07-04T15:16:27Z</timestamp>
      <contributor>
        <username>PrimeBOT</username>
        <id>29463730</id>
      </contributor>
      <minor/>
      <comment>Replace [[Help:Magic_links|magic links]] with templates per [[Special:PermaLink/772743896#Future_of_magic_links|local RfC]] - [[User:PrimeBOT/13|BRFA]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6311">'''DNSS points''', also known as Skiba points, arise in [[optimal control]] problems that exhibit multiple optimal solutions. A DNSS point&lt;math&gt;-&lt;/math&gt;named alphabetically after Deckert and Nishimura,&lt;ref name = "DN83"&gt;{{Cite journal | doi = 10.1016/0022-0531(83)90081-9 | last1 = Deckert | first1 = D.W. | last2 = Nishimura | first2 = K. | year = 1983 | title = A Complete Characterization of Optimal Growth Paths in an Aggregated Model with Nonconcave Production Function | url = | journal = Journal of Economic Theory | volume = 31 | issue = 2| pages = 332–354 }}&lt;/ref&gt; Sethi,&lt;ref name = "sethi77"&gt;{{Cite journal | doi = 10.1007/BF00933297 | last1 = [[Suresh P.Sethi|Sethi]]  | first1 = S.P. | year = 1977 | title = Nearest Feasible Paths in Optimal Control Problems: Theory, Examples, and Counterexamples | url = | journal = Journal of Optimization Theory and Applications | volume = 23 | issue = 4| pages = 563–579 }}&lt;/ref&gt;&lt;ref name = "sethi79"&gt;{{Cite journal | doi = 10.1007/BF00934454 | last1 = [[Suresh P.Sethi|Sethi]] | first1 = S.P. | year = 1979 | title = Optimal Advertising Policy with the Contagion Model | url = | journal = Journal of Optimization Theory and Applications | volume = 29 | issue = 4| pages = 615–627 }}&lt;/ref&gt; and Skiba&lt;ref name = "skiba78"&gt;{{Cite journal | doi = 10.2307/1914229 | last1 = Skiba | first1 = A.K. | year = 1978 | title = Optimal Growth with a Convex-Concave Production Function | jstor = 1914229| journal = Econometrica | volume = 46 | issue = 3| pages = 527–539 }}&lt;/ref&gt;&lt;math&gt;-&lt;/math&gt;is an indifference point in an optimal control problem such that starting from such a point, the problem has more than one different optimal solutions. A good discussion of such points can be found in Grass et al.&lt;ref name="grass"&gt;Grass, D., Caulkins, J.P., Feichtinger, G., Tragler, G., Behrens, D.A. (2008). ''Optimal Control of Nonlinear Processes: With Applications in Drugs, Corruption, and Terror''. Springer. {{ISBN|978-3-540-77646-8}}.&lt;/ref&gt;

== Definition ==
Of particular interest here are discounted infinite horizon [[optimal control]] problems that are autonomous.&lt;ref&gt;[[Suresh P.Sethi|Sethi, S.P.]] and Thompson, G.L. (2000). ''Optimal Control Theory: Applications to Management Science and Economics''. Second Edition. Springer. {{ISBN|0-387-28092-8}} and {{ISBN|0-7923-8608-6}}. Slides are available at http://www.utdallas.edu/~sethi/OPRE7320presentation.html&lt;/ref&gt; These problems can be formulated as

: &lt;math&gt;
\max_{u(t)\in \Omega}\int_0^{\infty} e^{-\rho t} \varphi\left(x(t), u(t)\right)dt&lt;/math&gt;

s.t.

: &lt;math&gt;
\dot{x}(t) = f\left(x(t), u(t)\right), x(0) = x_{0},
&lt;/math&gt;

where &lt;math&gt;\rho &gt; 0&lt;/math&gt; is the discount rate, &lt;math&gt;x(t)&lt;/math&gt; and &lt;math&gt;u(t)&lt;/math&gt; are the state and control variables, respectively, at time &lt;math&gt;t&lt;/math&gt;, functions &lt;math&gt;\varphi&lt;/math&gt; and &lt;math&gt;f&lt;/math&gt; are assumed to be continuously differentiable with respect to their arguments and they do not depend explicitly on time &lt;math&gt;t&lt;/math&gt;, and &lt;math&gt;\Omega&lt;/math&gt; is the set of feasible controls and it also is explicitly independent of time &lt;math&gt;t&lt;/math&gt;. Furthermore, it is assumed that the integral converges for any admissible solution &lt;math&gt;\left(x(.), u(.)\right)&lt;/math&gt;. In such a problem with one-dimensional state variable &lt;math&gt;x&lt;/math&gt;, the initial state &lt;math&gt;x_{0}&lt;/math&gt; is called a ''DNSS point'' if the system starting from it exhibits multiple optimal solutions or equilibria. Thus, at least in the neighborhood of &lt;math&gt;x_0&lt;/math&gt;, the system moves to one equilibrium for &lt;math&gt;x &gt; x_0&lt;/math&gt; and to another for &lt;math&gt;x &lt; x_0&lt;/math&gt;. In this sense, &lt;math&gt;x_0&lt;/math&gt; is an indifference point from which the system could move to either of the two equilibria.

For two-dimensional [[optimal control]] problems, Grass et al.&lt;ref name="grass" /&gt; and Zeiler et al.&lt;ref&gt;Zeiler, I., Caulkins, J., Grass, D., Tragler, G. (2009). Keeping Options Open: An Optimal Control Model with Trajectories that Reach a DNSS Point in Positive Time. ''SIAM Journal on Control and Optimization'', Vol. 48, No. 6, pp. 3698-3707.| doi =10.1137/080719741 |&lt;/ref&gt; present examples that exhibit DNSS curves. 

Some references on the application of DNSS points are Caulkins et al.&lt;ref name = "caulkins09"&gt;{{Cite journal | doi = 10.1016/j.orl.2009.07.003 | last1 = Caulkins | first1 = J. P. | last2 = Feichtinger | first2 = G. | last3 = Grass | first3 = D. | last4 = Tragler | first4 = G. | year = 2009| title = Optimal control of terrorism and global reputation: A case study with novel threshold behavior | url = | journal = Operations Research Letters | volume = 37 | issue = 6| pages = 387–391 }}&lt;/ref&gt; and Zeiler et al.&lt;ref name = "zeiler10"&gt;I. Zeiler, J. P. Caulkins, and G. Tragler. When Two Become One: Optimal Control of Interacting Drug. ''Working paper, ''Vienna University of Technology, Vienna, Austria&lt;/ref&gt;

== History ==
[[Suresh P. Sethi]] identified such indifference points for the first time in 1977.&lt;ref name="sethi77" /&gt; Further, Skiba,&lt;ref name="skiba78" /&gt; Sethi,&lt;ref name="sethi79" /&gt; and Deckert and Nishimura&lt;ref name="DN83" /&gt; explored these indifference points in economic models. The term DNSS (Deckert, Nishimura, Sethi, Skiba) points, introduced by Grass et al.,&lt;ref name="grass" /&gt; recognizes (alphabetically) the contributions of these authors.

These indifference points have been referred to earlier as ''Skiba points'' or ''DNS points'' in the literature.&lt;ref name="grass" /&gt;

== Example ==
A simple problem exhibiting this behavior is given by &lt;math&gt;\varphi\left(x,u\right) =xu,&lt;/math&gt; &lt;math&gt;f\left(x,u\right) = -x + u,&lt;/math&gt; and &lt;math&gt;\Omega = \left[-1, 1\right]&lt;/math&gt;. It is shown in Grass et al.&lt;ref name="grass" /&gt; that &lt;math&gt;x_{0} = 0&lt;/math&gt; is a DNSS point for this problem because the optimal path &lt;math&gt;x(t)&lt;/math&gt; can be either &lt;math&gt;\left(1-e^{-t}\right)&lt;/math&gt; or &lt;math&gt;\left(-1+e^{-t}\right)&lt;/math&gt;. Note that for &lt;math&gt;x_{0} &lt; 0&lt;/math&gt;, the optimal path is &lt;math&gt;x(t) = -1 + e^{-t\left(x_{0}+1 \right)}&lt;/math&gt; and for &lt;math&gt;x_{0} &gt; 0&lt;/math&gt;, the optimal path is &lt;math&gt;x(t) = 1 + e^{-t\left(x_{0}-1 \right)}&lt;/math&gt;.

== Extensions ==
For further details and extensions, the reader is referred to Grass et al.&lt;ref name="grass" /&gt;

==References==
&lt;references /&gt;

[[Category:Optimal control]]
[[Category:Mathematical economics]]</text>
      <sha1>3yah9liawr8mcnloen5osq1v2lppok2</sha1>
    </revision>
  </page>
  <page>
    <title>DeepArt</title>
    <ns>0</ns>
    <id>50551441</id>
    <revision>
      <id>827353889</id>
      <parentid>798624739</parentid>
      <timestamp>2018-02-24T06:25:50Z</timestamp>
      <contributor>
        <username>Störm</username>
        <id>25154634</id>
      </contributor>
      <comment>-[[Category:Websites]]; -[[Category:Web applications]] using [[WP:HC|HotCat]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="7072">{{Infobox software
| name                   = DeepArt
| logo                   = 
| logo alt               = 
| screenshot             = 
| caption                = An image rendered by DeepArt
| screenshot alt         = 
| collapsible            = 
| author                 = Matthias Bethge, Alex Ecker, Leon Gatys, Łukasz Kidziński, Michał Warchoł
| developer              = DeepArt UG (haftungsbeschränkt)
| released               =  {{Start date and age|2015|10|01|df=yes}}
| discontinued           = 
| latest release version = 
| latest release date    = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| latest preview version = 
| latest preview date    = &lt;!-- {{Start date and age|YYYY|MM|DD|df=yes/no}} --&gt;
| status                 = Active
| programming language   = 
| operating system       = Web application
| platform               = 
| size                   = 
| language               = 
| language count         = &lt;!-- Number only --&gt;
| language footnote      = 
| genre                  = [[Photography|Photo]] and [[video]]
| license                = [[Freeware]]
| alexa                  = 
| website                = {{URL|http://deepart.io/}}
| standard               = 
| AsOf                   = 
}}
'''DeepArt''' or '''DeepArt.io''' is a website that allows users to create unique artistic images by using an [[algorithm]] to redraw one image using the stylistic elements of another image.&lt;ref name="wired"&gt;{{Cite web |url=https://www.wired.co.uk/news/archive/2015-09/01/art-algorithm-recreates-paintings |title=This algorithm can create an imitation Van Gogh in 60 minutes |last=Culpan |first=Daniel |publisher=Wired |publication-place=Wired.co.uk |publication-date=1 September 2016 |access-date=28 November 2016}}&lt;/ref&gt;&lt;ref name="Washington Post"&gt;{{Cite web |url=https://www.washingtonpost.com/news/innovations/wp/2015/08/31/this-algorithm-can-create-a-new-van-gogh-or-picasso-in-just-an-hour/ |title=This algorithm can create a new Van Gogh or Picasso in just an hour |last=McFarland |first=Matt |website=WashingtonPost.com |publisher=Washington Post |publication-date=31 August 2015 |access-date=28 November 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://www.theguardian.com/technology/2015/sep/02/computer-algorithm-recreates-van-gogh-painting-picasso |title=Computer algorithm recreates Van Gogh painting in one hour |last=Parkinson |first=Hannah Jane |date=2 September 2015 |website=theguardian.com |publisher=The Guardian |access-date=28 November 2016 |via=The Guardian}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.spiegel.de/netzwelt/gadgets/algorithmus-forscher-lassen-fotos-wie-gemaelde-aussehen-a-1051084.html |title=Neuronale Netzwerke: Computer malen wie van Gogh |last=Meusers |first=Richard |date=3 September 2015 |website=spiegel.de |publisher=spiegel |access-date=28 November 2016}}&lt;/ref&gt; This uses "A Neural Algorithm of Artistic Style" that was developed by several of its creators to separate style elements from a piece of art.&lt;ref name="A Neural Algorithm of Artistic Style"&gt;{{Cite arxiv |last=Gatys |first=Leon|last2=Ecker |first2=Alexander |last3=Bethge |first3=Matthias |date=26 August 2015 |title=A Neural Algorithm of Artistic Style |eprint=1508.06576 |class=cs.CV}}&lt;/ref&gt;&lt;ref name="About"&gt;{{Cite web |url=https://deepart.io/page/about/ |title=Depart.io - About |access-date=28 November 2016}}&lt;/ref&gt; The tool allows users to create imitation works of art using the style of famous artists.&lt;ref&gt;{{Cite web |url=http://uk.businessinsider.com/ai-makes-photos-look-like-famous-paintings-2015-9?r=US&amp;IR=T |title=This artificially intelligent program can transform photos to make them look like famous paintings |last=Del Prado |first=Guia Marie |date=2 September 2015 |website=uk.businessinsider.com |publisher=businessinsider |access-date=28 November 2015}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.huffingtonpost.com/entry/could-an-instagram-filter-turn-your-photos-into-masterful-paintings_us_55e854c6e4b0c818f61ad0ca |title=Could An Instagram Filter Turn Your Photos Into Masterful Paintings? |last=Fallon |first=Claire |date=4 September 2015 |website=TheHuffingtonPost.com |publisher=The Huffington Post |access-date=28 November 2016}}&lt;/ref&gt; The neural algorithm is used by the Deep Art website to create a representation of an image provided by the user by using the 'style' of another image provided by the user.&lt;ref&gt;{{Cite web |url=http://www.livescience.com/54415-computer-turns-photos-into-fine-art.html |title=Turn Your Photos Into Fine-Art 'Paintings' on Free Website |last=Weisberger |first=Mindy |date=14 April 2016 |website=livescience.com |publisher=livescience |access-date=28 November 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://mic.com/articles/141508/deep-art-turns-your-selfies-into-works-of-art-worthy-of-a-museum#.KdSwZKNTq |title=This Website Turns Your Selfies Into Works of Art Worthy of a Museum |last=Leung |first=Andrew |date=21 April 2016 |website=Mic.com |publisher=Mic |access-date=28 November 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.heraldnet.com/article/20160417/LIVING/160419347 |title=With new computer technology, data imitates art - HeraldNet.com - Everett and Snohomish County news |last=McFarland |first=Matt |date=15 April 2016 |website=heraldnet.com |publisher=heraldnet |access-date=28 November 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://www.geekwire.com/2015/a-computer-algorithm-can-now-create-a-picasso-like-painting-in-an-hour/ |title=A computer algorithm can now create a Picasso-like painting in an hour |last=Brown |first=Molly |date=2 September 2015 |website=geekwire.com |publisher=geekwire |access-date=28 November 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=http://news.discovery.com/tech/robotics/a-i-painter-emulates-great-artists-160411.htm |title=A.I. Painter Emulates Great Artists |last=McDonald |first=Glenn |date=11 April 2016 |website=news.discovery.com |publisher=Discovery News |access-date=28 November 2016}}&lt;/ref&gt; A similar program, [[Prisma (app)|Prisma]], is an [[iOS]] and [[Android (operating system)|Android]] [[Mobile app|app]] that was based on the open source programming that underlies DeepArt.&lt;ref&gt;{{Cite web |url=https://venturebeat.com/2016/07/25/with-10-million-downloads-on-ios-prisma-now-lets-android-users-turn-their-photos-into-works-of-art/ |title=With 10M downloads on iOS, Prisma now lets Android users turn their photos into works of art |last=Sawers |first=Paul |date=25 July 2016 |website=venturebeat.com |publisher=venturebeat |access-date=28 November 2016}}&lt;/ref&gt;&lt;ref&gt;{{Cite web |url=https://www.theverge.com/2016/11/8/13548798/facebook-live-art-filters-prisma |title=Now you can Facebook Live with Prisma's art filters 4 |last=Vincent |first=James |date=8 November 2016 |website=Theverge.com |publisher=The Verge |access-date=28 November 2016}}&lt;/ref&gt;

==See also==
* [[Computational creativity]]

==References==
{{reflist}}

== External links ==
*[http://www.Deepart.io/ Website]

[[Category:Algorithmic art]]
[[Category:Neural network software]]
[[Category:Android (operating system) software]]
[[Category:IOS software]]
[[Category:2015 software]]</text>
      <sha1>75y0z3v927q0yc3royl17cgny0olrhk</sha1>
    </revision>
  </page>
  <page>
    <title>Discrete space</title>
    <ns>0</ns>
    <id>56061</id>
    <revision>
      <id>857764815</id>
      <parentid>857762815</parentid>
      <timestamp>2018-09-02T21:38:36Z</timestamp>
      <contributor>
        <username>Paul August</username>
        <id>87355</id>
      </contributor>
      <minor/>
      <comment>Reverted edits by [[Special:Contribs/43.240.4.88|43.240.4.88]] ([[User talk:43.240.4.88|talk]]) to last version by Simplexity22</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11838">{{Refimprove|date=March 2011}}
In [[topology]], a '''discrete space''' is a particularly simple example of a [[topological space]] or similar structure, one in which the points form a ''discontinuous sequence'', meaning they are ''[[Isolated point|isolated]]'' from each other in a certain sense. The discrete topology is the [[Comparison of topologies|finest]] topology that can be given on a set, i.e., it defines all subsets as open sets. In particular, each [[Singleton (mathematics)|singleton]] is an open set in the discrete topology.

== Definitions ==
Given a set ''X'':
* the '''discrete topology''' on ''X'' is defined by letting every [[subset]] of ''X'' be [[open set|open]] (and hence also [[closed set|closed]]), and ''X'' is a '''discrete topological space''' if it is equipped with its discrete topology;
* the '''discrete [[uniform space|uniformity]]''' on ''X'' is defined by letting every [[superset]] of the diagonal {(''x'',''x'')&amp;nbsp;: ''x'' is in ''X''} in ''X''&amp;nbsp;× ''X'' be an [[Entourage (topology)#Entourage definition|entourage]], and ''X'' is a '''discrete uniform space''' if it is equipped with its discrete uniformity.
* the '''discrete [[metric space|metric]]''' &lt;math&gt;\rho&lt;/math&gt; on ''X'' is defined by
:&lt;math&gt;\rho(x,y) = 
\left\{\begin{matrix} 
1 &amp;\mbox{if}\ x\neq y , \\
0 &amp;\mbox{if}\ x = y
\end{matrix}\right.
&lt;/math&gt;
for any &lt;math&gt;x,y \in X&lt;/math&gt;. In this case &lt;math&gt;(X,\rho)&lt;/math&gt; is called a '''discrete metric space''' or a '''space of [[isolated point]]s'''.
* a [[set (mathematics)|set]] ''S'' is '''discrete''' in a [[metric space]] &lt;math&gt;(X,d)&lt;/math&gt;, for &lt;math&gt;S \subseteq X&lt;/math&gt;, if for every &lt;math&gt;x \in S&lt;/math&gt;, there exists some &lt;math&gt;\delta &gt;0&lt;/math&gt; (depending on &lt;math&gt;x&lt;/math&gt;) such that &lt;math&gt;d(x,y) &gt;\delta&lt;/math&gt; for all &lt;math&gt;y \in S\setminus\{x\}&lt;/math&gt;; such a set consists of [[isolated point]]s.  A set ''S'' is '''uniformly discrete''' in the [[metric space]] &lt;math&gt;(X,d)&lt;/math&gt;, for &lt;math&gt;S \subseteq X&lt;/math&gt;, if there exists ''ε'' &gt; 0 such that for any two distinct &lt;math&gt;x, y \in S&lt;/math&gt;, &lt;math&gt;d(x, y)&lt;/math&gt; &gt;  ''ε''.

A metric space &lt;math&gt;(E,d)&lt;/math&gt; is said to be ''[[uniformly discrete set|uniformly discrete]]'' if there exists a "packing radius" &lt;math&gt;r&gt;0&lt;/math&gt; such that, for any &lt;math&gt;x,y \in E&lt;/math&gt;, one has either &lt;math&gt;x=y&lt;/math&gt; or &lt;math&gt;d(x,y)&gt;r&lt;/math&gt;.&lt;ref&gt;{{cite book | zbl=0982.52018 | last=Pleasants | first=Peter A.B. | chapter=Designer quasicrystals: Cut-and-project sets with pre-assigned properties | editor1-last=Baake | editor1-first=Michael | title=Directions in mathematical quasicrystals | location=Providence, RI | publisher=[[American Mathematical Society]] | series=CRM Monograph Series | volume=13 | pages=95–141 | year=2000 | isbn=0-8218-2629-8 }}&lt;/ref&gt;  The topology underlying a metric space can be discrete, without the metric being uniformly discrete: for example the usual metric on the set {1, 1/2, 1/4, 1/8, ...} of real numbers.

{{Collapse top|title=Proof that a discrete space is not necessarily uniformly discrete }}
Let X = {1, 1/2, 1/4, 1/8, ...}, consider this set using the usual metric on the real numbers. Then, X is a discrete space, since for each point 1/2&lt;sup&gt;n&lt;/sup&gt;, we can surround it with the interval (1/2&lt;sup&gt;n&lt;/sup&gt; - ɛ, 1/2&lt;sup&gt;n&lt;/sup&gt; + ɛ), where ɛ = 1/2(1/2&lt;sup&gt;n&lt;/sup&gt; - 1/2&lt;sup&gt;n+1&lt;/sup&gt;) = 1/2&lt;sup&gt;n+2&lt;/sup&gt;. The intersection (1/2&lt;sup&gt;n&lt;/sup&gt; - ɛ, 1/2&lt;sup&gt;n&lt;/sup&gt; + ɛ) &amp;cap; {1/2&lt;sup&gt;n&lt;/sup&gt;} is just the singleton {1/2&lt;sup&gt;n&lt;/sup&gt;}. Since the intersection of two open sets is open, and singletons are open, it follows that X is a discrete space.

However, X cannot be uniformly discrete. To see why, suppose there exists an r&gt;0 such that d(x,y)&gt;r whenever x≠y. It suffices to show that there are at least two points x and y in X that are closer to each other than r. Since the distance between adjacent points 1/2&lt;sup&gt;n&lt;/sup&gt; and 1/2&lt;sup&gt;n+1&lt;/sup&gt; is 1/2&lt;sup&gt;n+1&lt;/sup&gt;, we need to find an n that satisfies this inequality:

&lt;math&gt;
1/2^{n+1} &lt; r
&lt;/math&gt;

&lt;math&gt;
1 &lt; r2^{n+1}
&lt;/math&gt;

&lt;math&gt;
1/r &lt; 2^{n+1}
&lt;/math&gt;

&lt;math&gt;
\log_2(1/r) &lt; n+1
&lt;/math&gt;

&lt;math&gt;
-\log_2(r) &lt; n+1
&lt;/math&gt;

&lt;math&gt;
-1 - \log_2(r) &lt; n
&lt;/math&gt;

Since there is always an n bigger than any given real number, it follows that there will always be at least two points in X that are closer to each other than any positive r, therefore X is not uniformly discrete.
...
{{Collapse bottom}}

== Properties ==
The underlying uniformity on a discrete metric space is the discrete uniformity, and the underlying topology on a discrete uniform space is the discrete topology.
Thus, the different notions of discrete space are compatible with one another.
On the other hand, the underlying topology of a non-discrete uniform or metric space can be discrete; an example is the metric space ''X''&amp;nbsp;:= {1/''n''&amp;nbsp;: ''n''&amp;nbsp;= 1,2,3,...} (with metric inherited from the [[real line]] and given by d(''x'',''y'')&amp;nbsp;= |''x''&amp;nbsp;&amp;minus; ''y''|).
Obviously, this is not the discrete metric; also, this space is not [[complete (topology)|complete]] and hence not discrete as a uniform space.
Nevertheless, it is discrete as a topological space.
We say that ''X'' is ''topologically discrete'' but not ''uniformly discrete'' or ''metrically discrete''.

Additionally:
* The [[topological dimension]] of a discrete space is equal to 0.
* A topological space is discrete if and only if its [[singleton (mathematics)|singleton]]s are open, which is the case if and only if it doesn't contain any [[accumulation point]]s.
* The singletons form a [[basis (topology)|basis]] for the discrete topology.
* A uniform space ''X'' is discrete if and only if the diagonal {(''x'',''x'')&amp;nbsp;: ''x'' is in ''X''} is an [[entourage (topology)|entourage]].
* Every discrete topological space satisfies each of the [[separation axioms]]; in particular, every discrete space is [[Hausdorff space|Hausdorff]], that is, separated.
* A discrete space is [[compact space|compact]] [[if and only if]] it is [[finite set|finite]].
* Every discrete uniform or metric space is [[complete space|complete]].
* Combining the above two facts, every discrete uniform or metric space is [[totally bounded space|totally bounded]] if and only if it is finite.
* Every discrete metric space is [[bounded space|bounded]].
* Every discrete space is [[first-countable space|first-countable]]; it is moreover [[second-countable space|second-countable]] if and only if it is [[countable]].
* Every discrete space is [[totally disconnected]].
* Every non-empty discrete space is [[second category]].
* Any two discrete spaces with the same [[cardinality]] are [[homeomorphic]].
* Every discrete space is metrizable (by the discrete metric).
* A finite space is metrizable only if it is discrete.
* If ''X'' is a topological space and ''Y'' is a set carrying the discrete topology, then ''X'' is evenly covered by {{nowrap|''X'' × ''Y''}} (the projection map is the desired covering)
* The [[subspace topology]] on the [[integers]] as a subspace of the [[real line]] is the discrete topology.
*A discrete space is separable if and only if it is countable.

Any function from a discrete topological space to another topological space is [[continuous function (topology)|continuous]], and any function from a discrete uniform space to another uniform space is [[uniformly continuous]]. That is, the discrete space ''X'' is [[free object|free]] on the set ''X'' in the [[category theory|category]] of topological spaces and continuous maps or in the category of uniform spaces and uniformly continuous maps. These facts are examples of a much broader phenomenon, in which discrete structures are usually free on sets.

With metric spaces, things are more complicated, because there are several categories of metric spaces, depending on what is chosen for the [[morphism]]s. Certainly the discrete metric space is free when the morphisms are all uniformly continuous maps or all continuous maps, but this says nothing interesting about the metric [[Mathematical structure|structure]], only the uniform or topological structure. Categories more relevant to the metric structure can be found by limiting the morphisms to [[Lipschitz continuous]] maps or to [[short map]]s; however, these categories don't have free objects (on more than one element). However, the discrete metric space is free in the category of [[bounded metric space]]s and Lipschitz continuous maps, and it is free in the category of metric spaces bounded by 1 and short maps. That is, any function from a discrete metric space to another bounded metric space is Lipschitz continuous, and any function from a discrete metric space to another metric space bounded by 1 is short.

Going the other direction, a function ''f'' from a topological space ''Y'' to a discrete space ''X'' is continuous if and only if it is ''[[locally constant function|locally constant]]'' in the sense that every point in ''Y'' has a [[topological neighborhood|neighborhood]] on which ''f'' is constant.

== Uses ==

A discrete structure is often used as the "default structure" on a set that doesn't carry any other natural topology, uniformity, or metric; discrete structures can often be used as "extreme" examples to test particular suppositions. For example, any [[group (mathematics)|group]] can be considered as a [[topological group]] by giving it the discrete topology, implying that theorems about topological groups apply to all groups. Indeed, analysts may refer to the ordinary, non-topological groups studied by algebraists as "[[discrete group]]s" . In some cases, this can be usefully applied, for example in combination with [[Pontryagin duality]]. A 0-dimensional [[manifold]] (or differentiable or analytical manifold) is nothing but a discrete topological space. We can therefore view any discrete group as a 0-dimensional [[Lie group]].

A [[product topology|product]] of [[countably infinite]] copies of the discrete space of [[natural number]]s is [[homeomorphic]] to the space of [[irrational number]]s, with the homeomorphism given by the [[continued fraction]] expansion. A product of countably infinite copies of the discrete space [[2 (number)|{0,1}]] is homeomorphic to the [[Cantor set]]; and in fact [[uniformly homeomorphic]] to the Cantor set if we use the [[product uniformity]] on the product. Such a homeomorphism is given by using [[Ternary numeral system|ternary notation]] of numbers. (See [[Cantor space]].)

In the [[foundations of mathematics]], the study of [[compact space|compactness]] properties of products of {0,1} is central to the topological approach to the [[Boolean prime ideal theorem|ultrafilter principle]], which is a weak form of [[axiom of choice|choice]].

== Indiscrete spaces ==
{{main|Trivial topology}}

In some ways, the opposite of the discrete topology is the [[trivial topology]] (also called the ''indiscrete topology''), which has the fewest possible open sets (just the [[empty set]] and the space itself). Where the discrete topology is initial or free, the indiscrete topology is final or [[cofree]]: every function ''from'' a topological space ''to'' an indiscrete space is continuous, etc.

==See also==
* [[Cylinder set]]
* [[Taxicab geometry]]

== References ==
&lt;!--See http://en.wikipedia.org/wiki/Wikipedia:Footnotes for an explanation of how to generate footnotes using the &lt;ref(erences/)&gt; tags--&gt;
&lt;references /&gt;
* {{cite book | last1=Steen | first1=Lynn Arthur | author1-link=Lynn Arthur Steen | last2=Seebach | first2=J. Arthur Jr. | author2-link=J. Arthur Seebach, Jr. | title=[[Counterexamples in Topology]] | edition=2nd | year=1978 | publisher=[[Springer-Verlag]] | location=Berlin, New York | isbn=3-540-90312-7 | mr=507446 | zbl=0386.54001 }}

[[Category:Topology]]
[[Category:General topology]]
[[Category:Topological spaces]]</text>
      <sha1>1dyfd3v6qslcm2rhnnlc1gkorhc0qf9</sha1>
    </revision>
  </page>
  <page>
    <title>Double Diamond (design process model)</title>
    <ns>0</ns>
    <id>52235725</id>
    <revision>
      <id>764152921</id>
      <parentid>749141120</parentid>
      <timestamp>2017-02-07T10:50:06Z</timestamp>
      <contributor>
        <username>Boomer Vial</username>
        <id>27200870</id>
      </contributor>
      <comment>rmv dead end tag</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="545">'''Double Diamond''' is the name of a design process model developed by the British Design Council in 2005.&lt;ref&gt;{{cite web|last1=British Design Council|url=http://www.designcouncil.org.uk/sites/default/files/asset/document/ElevenLessons_Design_Council%20(2).pdf|title=Eleven lessons. A study of the design process|website=www.designcouncil.org.uk|accessdate=9 November 2016}}&lt;/ref&gt; It suggests that the [[design process]] should have four phases:

* Discover
* Define
* Develop
* Deliver

==References==
{{Reflist}}



[[Category:Design theory]]</text>
      <sha1>bzhqouwsjhexbkshxstjvz8aeqr9m0m</sha1>
    </revision>
  </page>
  <page>
    <title>Enterprise risk management</title>
    <ns>0</ns>
    <id>2360715</id>
    <revision>
      <id>869145007</id>
      <parentid>862005795</parentid>
      <timestamp>2018-11-16T18:13:21Z</timestamp>
      <contributor>
        <username>GünniX</username>
        <id>237572</id>
      </contributor>
      <minor/>
      <comment>Heading with bold</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="32595">'''Enterprise risk management''' ('''ERM''') in [[business]] includes the methods and processes used by organizations to manage risks and seize opportunities related to the achievement of their objectives.  ERM provides a framework for [[risk management]], which typically involves identifying particular events or circumstances relevant to the organization's objectives (risks and opportunities), assessing them in terms of likelihood and magnitude of impact, determining a response strategy, and monitoring process.  By identifying and proactively addressing risks and opportunities, business enterprises protect and create value for their stakeholders, including owners, employees, customers, regulators, and society overall.

ERM can also be described as a risk-based approach to managing an enterprise, integrating concepts of [[internal control]], the [[Sarbanes–Oxley Act]], [[General Data Protection Regulation|data protection]] and [[strategic planning]].  ERM is evolving to address the needs of various stakeholders, who want to understand the broad spectrum of risks facing complex organizations to ensure they are appropriately managed.  Regulators and debt rating agencies have increased their scrutiny on the risk management processes of companies.

According to Thomas Stanton of Johns Hopkins University, the point of enterprise risk management is not to create more bureaucracy, but to facilitate discussion on what the really big risks are.&lt;ref&gt;{{cite web|last1=Thomas Stanton|title=Enterprise Risk Management|url=https://www.youtube.com/watch?v=voGyHN-tWMg|website=YouTube|publisher=TEDxJHUDC|date=Feb 18, 2017|quote=The whole point of enterprise risk management is not to create another layer of bureaucracy, but rather to have your chief risk officer facilitate the conversations and then the discussions about priorities – what are the really big risks we’ve got to grapple with.}}&lt;/ref&gt;

==ERM frameworks defined==

There are various important ERM frameworks, each of which describes an approach for identifying, analyzing, responding to, and monitoring risks and opportunities, within the internal and external environment facing the enterprise.  Management selects a ''risk response strategy'' for specific risks identified and analyzed, which may include:

#Avoidance: exiting the activities giving rise to risk
#Reduction: taking action to reduce the likelihood or impact related to the risk
#Alternative Actions: deciding and considering other feasible steps to minimize risks 
#Share or Insure: transferring or sharing a portion of the risk, to finance it
#Accept: no action is taken, due to a cost/benefit decision

Monitoring is typically performed by management as part of its internal control activities, such as review of analytical reports or management committee meetings with relevant experts, to understand how the risk response strategy is working and whether the objectives are being achieved.

===Casualty Actuarial Society framework===
In 2003, the [[Casualty Actuarial Society]] (CAS) defined ERM as the discipline by which an organization in any industry assesses, controls, exploits, finances, and monitors risks from all sources for the purpose of increasing the organization's short- and long-term value to its stakeholders."&lt;ref name = "CASOverview2003-8"&gt;{{cite journal
| author         = Enterprise Risk Management Committee
| title          = Overview of Enterprise Risk Management
| publisher      = [[Casualty Actuarial Society]]
| date           = May 2003
| url            = http://www.casact.org/research/erm/overview.pdf
| pages          = 8
| format         = PDF
| accessdate     = 2008-09-15
}}
&lt;/ref&gt; The CAS conceptualized ERM as proceeding across the two dimensions of ''risk type'' and ''risk management processes.''&lt;ref name = "CASOverview2003-8" /&gt; The risk types and examples include:&lt;ref name = "CASOverview2003-9-10"&gt;{{cite journal
| author         = Enterprise Risk Management Committee
| title          = Overview of Enterprise Risk Management
| publisher      = [[Casualty Actuarial Society]]
| date           = May 2003
| url            = http://www.casact.org/research/erm/overview.pdf
| pages          = 9–10
| format         = PDF
| accessdate     = 2008-09-15
}}
&lt;/ref&gt;
;Hazard risk: Liability torts, Property damage, Natural catastrophe
;Financial risk: Pricing risk, Asset risk, Currency risk, Liquidity risk
;Operational risk: Customer satisfaction, Product failure, Integrity, Reputational risk; Internal Poaching; Knowledge drain
;Strategic risks: Competition, Social trend, Capital availability

The risk management process involves:&lt;ref name = "CASOverview2003-911-13"&gt;{{cite journal
| author         = Enterprise Risk Management Committee
| title          = Overview of Enterprise Risk Management
| publisher      = [[Casualty Actuarial Society]]
| date           = May 2003
| url            = http://www.casact.org/research/erm/overview.pdf
| pages          = 11–13
| format         = PDF
| accessdate     = 2008-09-15
}}
&lt;/ref&gt;
#'''Establishing Context:''' This includes an understanding of the current conditions in which the organization operates on an internal, external and risk management context.
#'''Identifying Risks:''' This includes the documentation of the material threats to the organization’s achievement of its objectives and the representation of areas that the organization may exploit for competitive advantage.
#'''Analyzing/Quantifying Risks:''' This includes the calibration and, if possible, creation of probability distributions of outcomes for each material risk.
#'''Integrating Risks:''' This includes the aggregation of all risk distributions, reflecting correlations and portfolio effects, and the formulation of the results in terms of impact on the organization’s key performance metrics.
#'''Assessing/Prioritizing Risks:''' This includes the determination of the contribution of each risk to the aggregate risk profile, and appropriate prioritization.
#'''Treating/Exploiting Risks:''' This includes the development of strategies for controlling and exploiting the various risks.
#'''Monitoring and Reviewing:''' This includes the continual measurement and monitoring of the risk environment and the performance of the risk management strategies.

=== COSO ERM framework ===

The [[Committee of Sponsoring Organizations of the Treadway Commission|COSO]] "Enterprise Risk Management-Integrated Framework" published in 2004 (New edition COSO ERM 2017 is not Mentioned and the 2004 version is outdated) defines ERM as a "…process, effected by an entity's board of directors, management, and other personnel, applied in strategy setting and across the enterprise, designed to identify potential events that may affect the entity, and manage risk to be within its [[risk appetite]], to provide reasonable assurance regarding the achievement of entity objectives."&lt;ref name = "COSO Summary"&gt;{{cite journal
| title          = Enterprise Risk Management — Integrated Framework: Executive Summary
| publisher      = [[Committee of Sponsoring Organizations of the Treadway Commission]]
| date           = September 2004
| url            = http://www.coso.org/Publications/ERM/COSO_ERM_ExecutiveSummary.pdf
| format         = PDF
| accessdate     = 2008-09-16
}}
&lt;/ref&gt;

The COSO ERM Framework has eight Components and four objectives categories.  It is an expansion of the COSO [[Internal Control]]-Integrated Framework published in 1992 and amended in 1994. The eight components - additional components highlighted - are:

* Authority and pledge to the ERM
* RISK Management policy
* Mixer of ERM in the institution
* Risk Assessment
* Risk Response
* communication and reporting
* Information and Communication
* Monitoring

The four objectives categories - additional components highlighted - are:
* '''Strategy''' - high-level goals, aligned with and supporting the organization's mission
* Operations - effective and efficient use of resources
* Financial Reporting - reliability of operational and financial reporting
* Compliance - compliance with applicable laws and regulations

=== RIMS Risk Maturity Model ===

The RIMS Risk Maturity Model (RMM) for Enterprise Risk Management, published in 2006, is an umbrella framework of content and methodology that detail the requirements for sustainable and effective enterprise risk management.&lt;ref name="RMM"&gt;[http://www.rims.org/resources/erm/pages/RiskMaturityModel.aspx]&lt;/ref&gt; The RMM model consists of twenty-five competency drivers for seven attributes that create ERM’s value and utility in an organization. The 7 attributes are:
* ERM-based approach
* ERM process management
* Risk appetite management
* Root cause discipline
* Uncovering risks
* Performance management
* Business resiliency and sustainability

The model was developed by Steven Minsky, CEO of LogicManager, and published by the [[Risk and Insurance Management Society]] in collaboration with the RIMS ERM Committee. The Risk Maturity Model is based on the Capability Maturity Model, a methodology founded by the Carnegie Mellon University Software Engineering Institute (SEI) in the 1980s.&lt;ref name="RIMS"&gt;[http://www.rims.org/resources/ERM/Pages/RiskMaturityModelFAQ.aspx]&lt;/ref&gt;

==Implementing an ERM program==

===Goals of an ERM program===
Organizations by nature manage risks and have a variety of existing departments or functions ("risk functions") that identify and manage particular risks.  However, each risk function varies in capability and how it coordinates with other risk functions.  A central goal and challenge of ERM is improving this capability and coordination, while integrating the output to provide a unified picture of risk for stakeholders and improving the organization's ability to manage the risks effectively.

===Typical risk functions===

The primary risk functions in large corporations that may participate in an ERM program typically include:

* Strategic planning - identifies external threats and competitive opportunities, along with strategic initiatives to address them 
* Marketing - understands the target customer to ensure product/service alignment with customer requirements
* Compliance &amp; Ethics - monitors compliance with code of conduct and directs fraud investigations
* Accounting / Financial compliance - directs the Sarbanes-Oxley Section 302 and 404 assessment, which identifies financial reporting risks
* Law Department - manages litigation and analyzes emerging legal trends that may impact the organization
* Insurance - ensures the proper insurance coverage for the organization
* Treasury - ensures cash is sufficient to meet business needs, while managing risk related to commodity pricing or foreign exchange
* Operational Quality Assurance - verifies operational output is within tolerances
* Operations management - ensures the business runs day-to-day and that related barriers are surfaced for resolution
* Credit - ensures any credit provided to customers is appropriate to their ability to pay
* Customer service - ensures customer complaints are handled promptly and root causes are reported to operations for resolution
* Internal audit - evaluates the effectiveness of each of the above risk functions and recommends improvements

===Common challenges in ERM implementation===

Various consulting firms offer suggestions for how to implement an ERM program.&lt;ref&gt;[http://www.protiviti.it/downloads/PRO/pro-gb/ProtivitiBulletin6.pdf ERM Implementation Advice]&lt;/ref&gt;  Common topics and challenges include:&lt;ref&gt;[http://www.knowledgeleader.com/KnowledgeLeader/Content.nsf/Web+Content/WhitePapersArticlesGuidetoEnterpriseRiskManagementFrequentlyAskedQuestions!OpenDocument ERM Frequently Asked Questions]&lt;/ref&gt;

* Identifying executive sponsors for ERM.
* Establishing a common risk language or glossary.
* Describing the entity's [[risk appetite]] (i.e., risks it will and will not take)
* Identifying and describing the risks in a "risk inventory".
* Implementing a risk-ranking methodology to prioritize risks within and across functions.
* Establishing a risk committee and or [[Chief Risk Officer]] (CRO) to coordinate certain activities of the risk functions.
* Establishing ownership for particular risks and responses.
* Demonstrating the cost-benefit of the risk management effort.
* Developing action plans to ensure the risks are appropriately managed.
* Developing consolidated reporting for various stakeholders.
* Monitoring the results of actions taken to mitigate risk.
* Ensuring efficient risk coverage by internal auditors, consulting teams, and other evaluating entities.
* Developing a technical ERM framework that enables secure participation by 3rd parties and remote employees.

===Internal audit role===
{{Accounting}}
In addition to information technology audit, [[internal audit]]ors play an important role in evaluating the risk-management processes of an organization and advocating their continued improvement.  However, to preserve its organizational independence and objective judgment, Internal Audit professional standards indicate the function should not take any direct responsibility for making risk management decisions for the enterprise or managing the risk-management function.&lt;ref&gt;[http://www.theiia.org/download.cfm?file=283 Role of Internal Auditing in ERM] {{webarchive|url=https://web.archive.org/web/20130905225145/http://www.theiia.org/download.cfm?file=283 |date=2013-09-05 }}&lt;/ref&gt;

Internal auditors typically perform an annual risk assessment of the enterprise, to develop a plan of audit engagements for the upcoming year.  This plan is updated at various frequencies in practice.  This typically involves review of the various risk assessments performed by the enterprise (e.g., strategic plans, competitive benchmarking, and [[SOX 404 top-down risk assessment]]), consideration of prior audits, and interviews with a variety of senior management.  It is designed for identifying audit projects, not to identify, prioritize, and manage risks directly for the enterprise.

==Current issues in ERM==

The risk management processes of corporations worldwide are under increasing regulatory and private scrutiny. Risk is an essential part of any business. Properly managed, it drives growth and opportunity. Executives struggle with business pressures that may be partly or completely beyond their immediate control, such as distressed financial markets; mergers, acquisitions and restructurings; [[disruptive technology]] change; geopolitical instabilities; and the rising price of energy.

===Sarbanes-Oxley Act requirements===

[[SOX 404 top-down risk assessment|Section 404]] of the [[Sarbanes-Oxley Act]] of 2002 required U.S. publicly traded corporations to utilize a control framework in their internal control assessments. Many opted for the [[Committee of Sponsoring Organizations of the Treadway Commission|COSO]] [[Internal Control]] Framework, which includes a risk assessment element.    In addition, new guidance issued by the [[Securities and Exchange Commission]] (SEC) and [[PCAOB]] in 2007 placed increasing scrutiny on [[top-down risk assessment]] and included a specific requirement to perform a [[fraud]] risk assessment.&lt;ref&gt;[http://www.pcaob.org/Rules/Docket_021/2007-05-24_Release_No_2007-005.pdf PCAOB Auditing Standard No 5] {{webarchive|url=https://web.archive.org/web/20070627001642/http://www.pcaob.org/Rules/Docket_021/2007-05-24_Release_No_2007-005.pdf |date=2007-06-27 }}&lt;/ref&gt;  Fraud risk assessments typically involve identifying scenarios of potential (or experienced) fraud, related exposure to the organization, related controls, and any action taken as a result.

===NYSE corporate governance rules===

The [[New York Stock Exchange]] requires the Audit Committees of its listed companies to "discuss policies with respect to [[risk assessment]] and [[risk management]]."  The related commentary continues: "While it is the job of the CEO and senior management to assess and manage the company’s exposure to risk, the audit committee must discuss guidelines and policies to govern the process by which this is handled. The audit committee should discuss the company’s major financial risk exposures and the steps management has taken to monitor and control such exposures. The audit committee is not required to be the sole body responsible for risk assessment and management, but, as stated above, the committee must discuss guidelines and policies to govern the process by which risk assessment and management is undertaken. Many companies, particularly financial companies, manage and assess their risk through mechanisms other than the audit committee. The processes these companies have in place should be reviewed in a general manner by the audit committee, but they need not be replaced by the audit committee."&lt;ref&gt;[https://www.nyse.com/pdfs/finalcorpgovrules.pdf NYSE Listing Standards Part 7d]&lt;/ref&gt;

===ERM and corporate debt ratings===

Standard &amp; Poor's (S&amp;P), the debt rating agency, plans to include a series of questions about risk management in its company evaluation process.  This will rollout to financial companies in 2007.&lt;ref&gt;[http://www.treasuryandrisk.com/article-print.php?article=714 S&amp;P Ratings - Treasury &amp; Risk Article] {{webarchive|url=https://web.archive.org/web/20070928191041/http://www.treasuryandrisk.com/article-print.php?article=714 |date=2007-09-28 }}&lt;/ref&gt;  The results of this inquiry is one of the many factors considered in debt rating, which has a corresponding impact on the interest rates lenders charge companies for loans or bonds.&lt;ref&gt;[http://www.mgt.ncsu.edu/pdfs/erm/sp_erm_busdevbk.pdf S&amp;P ERM for Financial Institutions]&lt;/ref&gt; On May 7, 2008, S&amp;P also announced that it would begin including an ERM assessment in its ratings for non-financial companies starting in 2009,&lt;ref&gt;[http://www.towersperrin.com/tp/getwebcachedoc?webc=HRS/USA/2008/200806/ERM_NonFinanFAQ.pdf S&amp;P ERM FAQs]&lt;/ref&gt; with initial comments in its reports during Q4 2008.&lt;ref&gt;[http://www.towersperrin.com/tp/getwebcachedoc?webc=HRS/USA/2008/200805/ERM4Corp.pdf S&amp;P ERM Announcement]&lt;/ref&gt;

===ISO 31000 : the new International Risk Management Standard===

[[ISO 31000]] is an International Standard for Risk Management which was published on 13 November 2009. An accompanying standard, ISO 31010 - Risk Assessment Techniques, soon followed publication (December 1, 2009) together with the updated Risk Management vocabulary ISO Guide 73.

===IFC Performance Standards===

IFC Performance Standard&lt;ref&gt;http://www.ifc.org/wps/wcm/connect/topics_ext_content/ifc_external_corporate_site/sustainability-at-ifc/policies-standards/performance-standards/ps1&lt;/ref&gt; focuses on the management of Health, Safety, Environmental and Social risks. The third edition was published on January 1, 2012 after a two-year negotiation process with the private sector, governments and civil society organisations. It has been adopted by the [http://www.equator-principles.com/ Equator] Banks, a consortium of over 90 commercial banks in 37 countries.

=== Data Privacy ===
Data privacy rules, such as the [[European Union]]'s [[General Data Protection Regulation]], increasingly foresee significant penalties for failure to maintain adequate protection of individuals' personal data such as names, e-mail addresses and personal financial information, or alert affected individuals when data privacy is breached. The EU regulation requires any organization--including organizations located outside the EU--to appoint a Data Protection Officer reporting to the highest management level&lt;ref&gt;{{Cite web|url=https://www.ferma.eu/ferma-eciia-cyber-risk-governance-report-0|title=FERMA ECIIA Cyber Risk Governance Report {{!}} Ferma|website=www.ferma.eu|language=en|access-date=2018-10-01}}&lt;/ref&gt; if they handle the personal data of anyone living in the EU.

==Actuarial response==

===Casualty Actuarial Society===
In 2003, the Enterprise Risk Management Committee of the [[Casualty Actuarial Society]] (CAS) issued its overview of ERM.&lt;ref name = "CASOverview2003"&gt;{{cite journal
| author         = Enterprise Risk Management Committee
| title          = Overview of Enterprise Risk Management
| publisher      = [[Casualty Actuarial Society]]
| date           = May 2003
| url            = http://www.casact.org/area/erm/overview.pdf
| format         = PDF
| accessdate     = 2008-09-15
}}
&lt;/ref&gt; This paper laid out the evolution, rationale, definitions, and frameworks for ERM from the casualty actuarial perspective, and also included a vocabulary, conceptual and technical foundations, actual practice and applications, and case studies.&lt;ref name = "CASOverview2003" /&gt;

The CAS has specific stated ERM goals, including being "a leading supplier internationally of educational materials relating to Enterprise Risk Management (ERM) in the property casualty insurance arena,"&lt;ref name = "CASgoal"&gt;{{cite web
 | url = http://www.casact.org/about/ERM_SAMs.pdf
 | title = ERM SAM Goals
 | accessdate = 2008-09-15
 |date=March 2008 
 | format = PDF
 | work = CAS Centennial Goal and SAM Goals
 | publisher = [[Casualty Actuarial Society]]
}}
&lt;/ref&gt; and has sponsored research, development, and training of casualty actuaries in that regard.&lt;ref name = "CASERMPage"&gt;{{cite web
 | url = http://www.casact.org/research/erm/
 | title = Enterprise Risk Management Web Site
 | accessdate = 2008-09-15
 | year = 2008
 | publisher = [[Casualty Actuarial Society]]
}}
&lt;/ref&gt; The CAS has refrained from issuing its own credential; instead, in 2007, the CAS Board decided that the CAS should participate in the initiative to develop a global ERM designation, and make a final decision at some later date.&lt;ref name="CASCred"&gt;{{cite web
 |url         = http://www.casact.org/about/governance/bod/061707ES.pdf
 |format      = PDF
 |title       = Executive Summary: CAS Board of Directors Meeting
 |accessdate  = 2008-09-15
 |date        = June 17, 2007
 |publisher   = [[Casualty Actuarial Society]]
 |deadurl     = yes
 |archiveurl  = https://web.archive.org/web/20100627193942/http://www.casact.org/about/governance/bod/061707ES.pdf
 |archivedate = June 27, 2010
 |df          = 
}}
&lt;/ref&gt;

===Society of Actuaries===
In 2007, the [[Society of Actuaries]] developed the Chartered Enterprise Risk Analyst (CERA) credential in response to the growing field of enterprise risk management.&lt;ref name = "CERA1"&gt;{{cite web
 | url = http://www.ceranalyst.org/overview.asp
 | title = Credential Overview
 | accessdate = 2008-09-15
 | year = 2008
 | publisher = [[Society of Actuaries]]
}}
&lt;/ref&gt; This is the first new professional credential to be introduced by the SOA since 1949.&lt;ref name = "CERA2"&gt;{{cite web
 | url = http://www.ceranalyst.org/cera-facts-overview.asp
 | title = CERA Fast Facts
 | accessdate = 2008-09-15
 | year = 2008
 | publisher = [[Society of Actuaries]]
}}
&lt;/ref&gt; A CERA studies to focus on how various risks, including operational, investment, strategic, and reputational combine to affect organizations. CERAs work in environments beyond insurance, reinsurance and the consulting markets, including  broader financial services, energy, transportation, media, technology, manufacturing and healthcare.&lt;ref name = "CERA2" /&gt;

It takes approximately three to four years to complete the CERA curriculum which combines basic actuarial science, ERM principles and a course on professionalism. To earn the CERA credential, candidates must take five exams, fulfill an educational experience requirement, complete one online course, and attend one in-person course on professionalism.&lt;ref name = "CERA2" /&gt;

===CERA Global===

Initially all CERAs were members of the [[Society of Actuaries]]&lt;ref name = "CERA3"&gt;{{cite web
 | url = http://www.ceranalyst.org/benefits.asp
 | title = Benefits
 | accessdate = 2008-09-15
 | year = 2008
 | publisher = [[Society of Actuaries]]
}}
&lt;/ref&gt; but in 2009 the CERA designation became a global specialized professional credential, awarded and regulated by multiple actuarial bodies.&lt;ref name = "CERA4"&gt;{{cite web
 | url = http://www.ceraglobal.org/about/treaty
 | title = The CERA Treaty
 | accessdate = 2015-01-12
 | year = 2009
 | publisher = CERA Global
}}
&lt;/ref&gt;

===Institute and Faculty of Actuaries===

The [[Institute and Faculty of Actuaries]] (the merged body formed in 2010 from the [[Institute of Actuaries]] and the [[Faculty of Actuaries]]) is the professional body representing actuaries in the United Kingdom. In March 2008, Enterprise Risk Management was adopted as one of the six actuarial practice areas, reflecting the increased involvement of actuaries in the ERM field.

A regular [https://www.actuaries.org.uk/news-and-insights/newsletters newsletter] communicates the ongoing work that the profession performs in respect of ERM.

Some of the key areas that the profession works on are summarised below (together with some of the recent outcomes in each area):

* Education, CPD, Career Support and Development

From April 2010 actuaries were able to study ERM as one of the [[Institute and Faculty of Actuaries#Specialist Technical Stage|Specialist Technical Stage]] exams ([http://www.actuaries.org.uk/students/pages/st9-enterprise-risk-management-specialist-technical ST9 course information]), which (with other exam passes) gives candidates the Chartered Enterprise Risk Actuary (CERA) qualification.  In July 2010 the first nine actuaries to obtain the CERA qualification were announced. The CERA qualification is offered by 13&lt;ref&gt;{{cite web |url=http://www.ceraglobal.org/about/participating |title=Archived copy |accessdate=2011-06-23 |deadurl=yes |archiveurl=https://web.archive.org/web/20110605204026/http://www.ceraglobal.org/about/participating |archivedate=2011-06-05 |df= }}&lt;/ref&gt; participating actuarial associations, with further information available at a [http://www.ceraglobal.org global] or [https://www.actuaries.org.uk/practice-areas/risk-management/chartered-enterprise-risk-actuary-cera UK] level.

Various [https://www.actuaries.org.uk/learn-develop/attend-event events] (e.g. networking evenings and webinars) are available to actuaries and other interested parties.
The main event is the Risk and Investment Conference, which is often held during the summer months. There is also some regularly reviewed [https://www.actuaries.org.uk/studying/plan-my-study-route/fellowshipassociateship/specialist-technical-subjects/st9-enterprise-risk-management material] available from the profession which may be of use in developing knowledge of ERM.

* Research &amp; Thought Leadership

A committee has been established to consider research and thought leadership in the ERM field (including what the “[[elevator speech]]” on ERM issues might be, definition of the scope of ERM and demonstration of the value of ERM).

Some areas in which work has been completed include:

- [https://www.actuaries.org.uk/documents/erm-guide-implementation-draft ERM - A guide to Implementation] &lt;br /&gt;
- A [https://www.actuaries.org.uk/documents/actuaries-risk-management-actuarial-profession-survey-20102011 survey] on actuaries in risk management &lt;br /&gt;
- A suggested common [https://www.actuaries.org.uk/documents/common-risk-classification-system-actuarial-profession risk classification] system for the actuarial profession

Research topics will be categorised and subject to a number of tests before proceeding with the research.

- enterprise-wide test (not just topic-specific / silo-based)&lt;br /&gt;
- risk management test (management = taking actions, not just modelling)&lt;br /&gt;
- director test (important enough for the Board, not just line managers)

* Communications &amp; Marketing

Actuaries continue to look to demonstrate and promote the value of actuaries and the CERA qualification in the field of ERM - including through publication of articles in [http://www.theactuary.com/ the Actuary]

The Actuarial Profession also liaises with other professions where appropriate- e.g. the [[Institution of Civil Engineers]] on considering ERM in the context of [http://www.icevirtuallibrary.com/content/book/100868 Risk Analysis and Management for Projects (RAMP)].

==Companies increasingly focusing on ERM==

It is clear that companies recognize ERM as a critical management issue. This is demonstrated through the prominence assigned to ERM within organizations and the resources devoted to building ERM capabilities. In a 2008 survey by Towers Perrin,&lt;ref&gt;[http://www.towersperrin.com/tp/getwebcachedoc?webc=TILL/USA/2008/200805/CFO_Survey19.pdf Embedding Enterprise Risk Management [[Towers Perrin]]]&lt;/ref&gt; at most life insurance companies, responsibility for ERM resides within the [[C-suite]]. Most often, the chief risk officer (CRO) or the chief financial officer (CFO) is in charge of ERM, and these individuals typically report directly to the chief executive officer. From their vantage point, the CRO and CFO are able to look across the organization and develop a perspective on the risk profile of the firm and how that profile matches its [[risk appetite]]. They act as drivers to improve skills, tools and processes for evaluating risks and to weigh various actions to manage those exposures. Companies are also actively enhancing their ERM tools and capabilities. Three quarters of responding companies said they have tools for specifically monitoring and managing enterprise-wide risk. These tools are used primarily for identifying and measuring risk and for management decision making. Respondents also reported that they have made good progress in building their ERM capabilities in certain areas.

In this study, more than 80% of respondents reported that they currently have adequate or better controls in place for most major risks. In addition, about 60% currently have a coordinated process for risk governance and include risk management
in decision making to optimize risk adjusted returns.

In another survey conducted in May and June 2008, against the backdrop of the developing financial crisis, six major findings came to light regarding risk and capital management among insurers worldwide:&lt;ref&gt;[http://www.towersperrin.com/tp/getwebcachedoc?webc=GBR/2009/200901/2008_Global_ERM_Survey_12809.pdf 2008 Global Insurance Industry ERM Survey Report [[Towers Perrin]]]&lt;/ref&gt;
* Embedding ERM is proving to be a significant challenge
* Company size matters
* European insurers are better positioned
* ERM is influencing important strategic decisions
* Economic capital standards are gaining ground
* [[Operational risk]] remains a weak spot

=== ERM Examples ===

==== Nedbank Group ====
[http://www.nedbankgroup.co.za/financial/Nedbank_ar2014/downloads/Integrated_Report_2014/HTML/#132/z Nedbank in South Africa] approaches ERM as a strategy to help them "optimise risk versus return on a sustainable basis, and risk management is therefore approached across three integrated core dimensions:  Managing risk as a THREAT...as an UNCERTAINTY  and as an OPPORTUNITY".

==== The Reserve Bank of Australia ====
[http://www.rba.gov.au/about-rba/risk-appetite-statement.html The Reserve Bank of Australia] - The Bank has established a risk appetite statement regarding its key risks, including risk appetite statements, a supporting risk management framework, and implementation guidelines.

==See also==
{{Div col|colwidth=22em}}
*[[Actuarial science]]
* [[Airmic]]
* [[Basel III]]
* [[Benefit risk]]
* [[Committee of Sponsoring Organizations of the Treadway Commission]]
* [[Cost risk]]
* [[Credit risk]]
* [[Information Quality Management]]
* [[ISO 31000]]
* [[Market risk]]
* [[Operational risk management]]
* [[Optimism bias]]
* [[Risk adjusted return on capital]]
* [[Risk appetite]]
* [[Risk management tools]]
* [[RiskLab]]
* [[ISA 400 Risk Assessments and Internal Control]]
* [[SOX 404 top-down risk assessment]]
* [[Total Security Management]]
* [[Web Presence Management]]
{{div col end}}

==References==
{{Reflist|2}}

==External links==
*{{cite web|last1=Thomas Stanton|title=Enterprise Risk Management|url=https://www.youtube.com/watch?v=voGyHN-tWMg|website=YouTube|publisher=TEDxJHUDC|date=Feb 18, 2017}}
*[https://web.archive.org/web/20100705072108/http://www.theirm.org/documents/SARM_FINAL.pdf Airmic / Alarm / IRM (2010) "A structured approach to Enterprise Risk Management (ERM) and the requirements of ISO 31000"]
*Hopkin, Paul "Fundamentals of Risk Management 2nd Edition" Kogan-Page (2012) {{ISBN|978-0-7494-6539-1}}

{{DEFAULTSORT:Enterprise Risk Management}}
[[Category:Actuarial science]]
[[Category:Auditing]]
[[Category:Information technology audit]]
[[Category:Internal audit]]</text>
      <sha1>kvdqdnjvfuutg7humicpvetvuse8qrb</sha1>
    </revision>
  </page>
  <page>
    <title>Ergodic sequence</title>
    <ns>0</ns>
    <id>2912899</id>
    <revision>
      <id>514265717</id>
      <parentid>399639882</parentid>
      <timestamp>2012-09-24T04:39:13Z</timestamp>
      <contributor>
        <username>Hyacinth</username>
        <id>17171</id>
      </contributor>
      <comment>--&gt;[[Category:Integer sequences]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2386">{{Unreferenced|date=December 2009}}

In [[mathematics]], an '''ergodic sequence''' is a certain type of [[integer sequence]], having certain equidistribution properties.

==Definition==
Let &lt;math&gt;A = \{a_j\}&lt;/math&gt; be an infinite, strictly increasing [[sequence]] of positive integers. Then, given an integer ''q'', this sequence is said to be '''ergodic mod ''q'' ''' if, for all integers &lt;math&gt;1\leq k \leq q&lt;/math&gt;, one has

:&lt;math&gt;\lim_{t\to\infty} \frac{N(A,t,k,q)}{N(A,t)} = \frac {1}{q}&lt;/math&gt;

where

:&lt;math&gt;N(A,t) = \mbox{card} \{a_j \in A : a_j \leq t \}&lt;/math&gt;

and [[cardinality|card]] is the count (the number of elements) of a set, so that &lt;math&gt;N(A,t)&lt;/math&gt; is the number of elements in the sequence ''A'' that are less than or equal to ''t'', and

:&lt;math&gt;N(A,t,k,q) = \mbox{card} \{a_j \in A : a_j\leq t,\, a_j \mod q = k \}&lt;/math&gt;

so &lt;math&gt;N(A,t,k,q)&lt;/math&gt; is the number of elements in the sequence ''A'', less than ''t'', that are equivalent to ''k'' modulo ''q''. That is, a sequence is an ergodic sequence if it becomes uniformly distributed mod ''q'' as the sequence is taken to infinity.

An equivalent definition is that the sum

:&lt;math&gt;\lim_{t\to\infty} \frac{1}{N(A,t)} \sum_{j; a_j\leq t} 
\exp \frac{2\pi ika_j}{q} = 0&lt;/math&gt;

vanish for every integer ''k'' with &lt;math&gt;k \mod q \ne 0&lt;/math&gt;. 

If a sequence is ergodic for all ''q'', then it is sometimes said to be '''ergodic for periodic systems'''.

==Examples==
The sequence of positive integers is ergodic for all ''q''.

[[Almost all]] [[Bernoulli sequence]]s, that is, sequences associated with a [[Bernoulli process]], are ergodic for all ''q''. That is, let &lt;math&gt;(\Omega,Pr)&lt;/math&gt; be a [[probability space]] of [[random variable]]s over two letters &lt;math&gt;\{0,1\}&lt;/math&gt;.  Then, given &lt;math&gt;\omega \in \Omega&lt;/math&gt;, the random variable &lt;math&gt;X_j(\omega)&lt;/math&gt; is 1 with some probability ''p'' and is zero with some probability 1-''p''; this is the definition of a Bernoulli process. Associated with each &lt;math&gt;\omega&lt;/math&gt; is the sequence of integers

:&lt;math&gt;\mathbb{Z}^\omega = \{n\in \mathbb{Z} : X_n(\omega) = 1 \}&lt;/math&gt;

Then almost every sequence &lt;math&gt;\mathbb{Z}^\omega&lt;/math&gt; is ergodic.

==See also==
*[[Ergodic theory]]
*[[Ergodic process]], for the use of the term in [[signal processing]]

{{DEFAULTSORT:Ergodic Sequence}}
[[Category:Ergodic theory]]
[[Category:Integer sequences]]</text>
      <sha1>6lxpj8v1sjyrkj8bm1p6kr5bw7ce3x4</sha1>
    </revision>
  </page>
  <page>
    <title>Forbidden graph characterization</title>
    <ns>0</ns>
    <id>13547826</id>
    <revision>
      <id>843435198</id>
      <parentid>829473652</parentid>
      <timestamp>2018-05-29T04:13:34Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <minor/>
      <comment>/* List of forbidden characterizations for graphs and hypergraphs */ [[Regina Tyshkevich]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15409">{{Redirect-synonym|Forbidden minors|[[age restrictions]]}}
In [[graph theory]], a branch of mathematics, many important families of graphs can be described by a finite set of individual graphs
that do not belong to the family and further exclude all graphs from the family which contain any of these forbidden graphs as (induced) subgraph or minor.
A prototypical example of this phenomenon is [[Kuratowski's theorem]], which states that a graph is [[planar graph|planar]] (can be drawn without crossings in the plane) if and only if it does not contain either of two forbidden graphs, the [[complete graph]] ''K''&lt;sub&gt;5&lt;/sub&gt; and the [[complete bipartite graph]] ''K''&lt;sub&gt;3,3&lt;/sub&gt;. For Kuratowski's theorem, the notion of containment is that of [[graph homeomorphism]], in which a subdivision of one graph appears as a subgraph of the other. Thus, every graph either has a planar drawing (in which case it belongs to the family of planar graphs) or it has a subdivision of one of these two graphs as a subgraph (in which case it does not belong to the planar graphs).

More generally, a '''forbidden graph characterization''' is a method of [[characterization (mathematics)|specifying]] a family of [[graph (discrete mathematics)|graph]], or [[hypergraph]], structures, by specifying substructures that are forbidden from existing within any graph in the family. Different families vary in the nature of what is ''forbidden''.  In general, a structure ''G'' is a member of a family &lt;math&gt;\mathcal{F}&lt;/math&gt; [[if and only if]] a forbidden substructure is '''not''' contained in ''G''.  The '''forbidden substructure''' might be one of:
* [[Glossary of graph theory#Subgraphs|subgraph]]s, smaller graphs obtained from subsets of the vertices and edges of a larger graph,
* [[induced subgraph]]s, smaller graphs obtained by selecting a subset of the vertices and using all edges with both endpoints in that subset,
* [[Homeomorphism (graph theory)|homeomorphic]] subgraphs (also called [[topological minor]]s), smaller graphs obtained from subgraphs by collapsing paths of degree-two vertices to single edges, or
* [[graph minor]]s, smaller graphs obtained from subgraphs by arbitrary [[edge contraction]]s.
The set of structures that are forbidden from belonging to a given graph family can also be called an '''obstruction set''' for that family.

Forbidden graph characterizations may be used in [[algorithm]]s for testing whether a graph belongs to a given family. In many cases, it is possible to test in [[polynomial time]] whether a given graph contains any of the members of the obstruction set, and therefore whether it belongs to the family defined by that obstruction set.

In order for a family to have a forbidden graph characterization, with a particular type of substructure, the family must be closed under substructures.
That is, every substructure (of a given type) of a graph in the family must be another graph in the family. Equivalently, if a graph is not part of the family, all larger graphs containing it as a substructure must also be excluded from the family. When this is true, there always exists an obstruction set (the set of graphs that are not in the family but whose smaller substructures all belong to the family). However, for some notions of what a substructure is, this obstruction set could be infinite. The [[Robertson–Seymour theorem]] proves that, for the particular case of [[graph minor]]s, a family that is closed under minors always has a finite obstruction set.

==List of forbidden characterizations for graphs and hypergraphs==
{{Expand list|date=August 2008}}
{| class="wikitable"
|-

! Family

! Forbidden graphs

! Relation

! Reference
|-
| rowspan=2|[[Forest (graph theory)|Forest]]s
| loops, pairs of parallel edges, and [[Cycle (graph theory)|cycles]] of all lengths
| subgraph
| Definition
|-
| a loop (for multigraphs) or a triangle ''K''&lt;sub&gt;3&lt;/sub&gt; (for simple graphs)
| graph minor
| Definition
|-
| [[Claw-free graph]]s
| [[Star (graph theory)|star]] ''K''&lt;sub&gt;1,3&lt;/sub&gt;
| induced subgraph
| Definition
|-
| [[Comparability graph]]s
| 
| induced subgraph
| 
|-
| [[Triangle-free graph]]s
| triangle ''K''&lt;sub&gt;3&lt;/sub&gt;
| induced subgraph
| Definition
|-
| rowspan=2|[[Planar graph]]s
|''K''&lt;sub&gt;5&lt;/sub&gt; and ''K''&lt;sub&gt;3,3&lt;/sub&gt;
| homeomorphic subgraph
| [[Kuratowski's theorem]]
|-
|''K''&lt;sub&gt;5&lt;/sub&gt; and ''K''&lt;sub&gt;3,3&lt;/sub&gt;
| graph minor
| [[Wagner's theorem]]
|-
| [[Outerplanar graph]]s
|''K''&lt;sub&gt;4&lt;/sub&gt; and ''K''&lt;sub&gt;2,3&lt;/sub&gt;
| graph minor
|{{harvtxt|Diestel|2000}},&lt;ref name="diestel"&gt;{{citation|first=Reinhard|last=Diestel|year=2000|title=Graph Theory|publisher= Springer-Verlag|isbn=0-387-98976-5|series=Graduate Texts in Mathematics|volume=173}}.&lt;/ref&gt; [https://books.google.com/books?id=04YbQF8oscQC&amp;lpg=PA327&amp;pg=PA107 p. 107]

|-
| [[1-planar graph|Outer 1-planar graphs]]
| five forbidden minors
| graph minor
| {{harvtxt|Auer|Bachmaier|Brandenburg|Gleißner|2013}}&lt;ref&gt;{{citation
 | last1 = Auer | first1 = Christopher
 | last2 = Bachmaier | first2 = Christian
 | last3 = Brandenburg | first3 = Franz J.
 | last4 = Gleißner | first4 = Andreas
 | last5 = Hanauer | first5 = Kathrin
 | last6 = Neuwirth | first6 = Daniel
 | last7 = Reislhuber | first7 = Josef
 | editor1-last = Wismath | editor1-first = Stephen
 | editor2-last = Wolff | editor2-first = Alexander
 | contribution = Recognizing outer 1-planar graphs in linear time
 | doi = 10.1007/978-3-319-03841-4_10
 | pages = 107–118
 | series = Lecture Notes in Computer Science
 | title = 21st International Symposium, GD 2013, Bordeaux, France, September 23-25, 2013, Revised Selected Papers
 | volume = 8242
 | year = 2013}}.&lt;/ref&gt;

|-
| Graphs of fixed [[graph genus|genus]]
| a finite obstruction set
| graph minor
|{{harvtxt|Diestel|2000}},&lt;ref name="diestel"/&gt; [https://books.google.com/books?id=NvRXJSl9hUUC&amp;pg=RA1-PA275&amp;vq=forbidden&amp;dq=%22hereditary+property%22+forbidden p. 275]
|-
| [[Apex graph]]s
| a finite obstruction set
| graph minor
|&lt;ref&gt;{{citation | last1 = Gupta | first1 = A. | last2 = Impagliazzo | first2 = R. | author2-link = Russell Impagliazzo | contribution = Computing planar intertwines | doi = 10.1109/SFCS.1991.185452 | pages = 802–811 | publisher = IEEE Computer Society | title = [[Symposium on Foundations of Computer Science|Proc. 32nd IEEE Symposium on Foundations of Computer Science (FOCS '91)]] | contribution-url = http://www.cse.ucsd.edu/users/russell/arvind.ps | year = 1991}}.&lt;/ref&gt;
|-
| [[linkless embedding|Linklessly embeddable graphs]]
| The [[Petersen family]]
| graph minor
| &lt;ref&gt;{{citation | last1 = Robertson | first1 = Neil | author1-link = Neil Robertson (mathematician) | last2 = Seymour | first2 = P. D. | author2-link = Paul Seymour (mathematician) | last3 = Thomas | first3 = Robin | author3-link = Robin Thomas (mathematician) | doi = 10.1090/S0273-0979-1993-00335-5 | issue = 1 | journal = Bulletin of the American Mathematical Society | pages = 84–89 | title = Linkless embeddings of graphs in 3-space | volume = 28 | year = 1993 | arxiv = math/9301216 | mr = 1164063}}.&lt;/ref&gt;
|-
| [[Bipartite graph]]s
| odd cycles
| subgraph
| &lt;ref&gt;[[Béla Bollobás]] (1998) "Modern Graph Theory", Springer, {{ISBN|0-387-98488-7}} [https://books.google.com/books?id=SbZKSZ-1qrwC&amp;pg=PA9&amp;dq=bipartite+odd+cycle p. 9]&lt;/ref&gt;
|-
|[[Chordal graph]]s
| cycles of length 4 or more
| induced subgraph
| &lt;ref&gt;{{citation | last = Kashiwabara | first = Toshinobu | contribution = Algorithms for some intersection graphs | doi = 10.1007/3-540-10704-5\_15 | editor1-last = Saito | editor1-first = Nobuji | editor2-last = Nishizeki | editor2-link = Takao Nishizeki | editor2-first = Takao | pages = 171–181 | publisher = Springer-Verlag | series = Lecture Notes in Computer Science | title = Graph Theory and Algorithms, 17th Symposium of Research Institute of Electric Communication, Tohoku University, Sendai, Japan, October 24-25, 1980, Proceedings | volume = 108 | year = 1981}}.&lt;/ref&gt;
|-
|[[Perfect graph]]s
| cycles of odd length 5 or more or their [[complement graph|complements]]
| induced subgraph
| &lt;ref&gt;{{citation
 | doi = 10.4007/annals.2006.164.51
 | last1 = Chudnovsky | first1 = Maria | author1-link = Maria Chudnovsky
 | last2 = Robertson | first2 = Neil | author2-link = Neil Robertson (mathematician)
 | last3 = Seymour | first3 = Paul | author3-link = Paul Seymour (mathematician)
 | last4 = Thomas | first4 = Robin | author4-link = Robin Thomas (mathematician)
 | journal = [[Annals of Mathematics]]
 | pages = 51–229
 | url = http://people.math.gatech.edu/~thomas/PAP/spgc.pdf
 | issue = 1
 | title = The strong perfect graph theorem
 | volume = 164
 | year = 2006
 | arxiv = math/0212070v1
}}.&lt;/ref&gt;
|-
| [[Line graph| Line graph of graph]]s
| nine forbidden subgraphs (listed [[Line graph#Characterization and recognition|here]])
| induced subgraph
| &lt;ref&gt;{{citation
 | last = Beineke | first = L. W.
 | contribution = Derived graphs of digraphs
 | editor1-last = Sachs | editor1-first = H.
 | editor2-last = Voss | editor2-first = H.-J.
 | editor3-last = Walter | editor3-first = H.-J.
 | location = Leipzig
 | pages = 17–33
 | publisher = Teubner
 | title = Beiträge zur Graphentheorie
 | year = 1968}}.&lt;/ref&gt;
|-
|[[Graph union]]s of [[cactus graph]]s
|the four-vertex ''[[diamond graph]]'' formed by removing an edge from the [[complete graph]] ''K''&lt;sub&gt;4&lt;/sub&gt;
| graph minor
|&lt;ref&gt;{{citation|last1=El-Mallah|first1=Ehab|last2=Colbourn|first2=Charles J.|author2-link=Charles Colbourn|title=The complexity of some edge deletion problems|journal=IEEE Transactions on Circuits and Systems|volume=35|issue=3|year=1988|pages=354–362|doi=10.1109/31.1748}}.&lt;/ref&gt;
|-
| [[Ladder graph]]s
|  ''K''&lt;sub&gt;2,3&lt;/sub&gt; and its [[dual graph]]
| homeomorphic subgraph
| &lt;ref&gt;{{citation | last1 = Takamizawa | first1 = K. | last2 = Nishizeki | author2-link = Takao Nishizeki | first2 = Takao | last3 = Saito | first3 = Nobuji | doi = 10.1016/0166-218X(81)90031-7 | issue = 1 | journal = Discrete Applied Mathematics | pages = 75–76 | title = Combinatorial problems on series-parallel graphs | volume = 3 | year = 1981}}.&lt;/ref&gt;
|-
| [[split graph]]s
| &lt;math&gt;C_4, C_5, \bar{C_4} (=K_2+K_2)&lt;/math&gt;
| induced subgraph
| &lt;ref&gt;{{citation
 | last1 = Földes | first1 = Stéphane
 | last2 = Hammer | first2 = Peter Ladislaw | author2-link =Peter Ladislaw Hammer
 | contribution = Split graphs
 | title = Proceedings of the Eighth Southeastern Conference on Combinatorics, Graph Theory and Computing (Louisiana State Univ., Baton Rouge, La., 1977)
 | pages = 311–315
 | series = Congressus Numerantium
 | volume = XIX
 | publisher = Utilitas Math.
 | location = Winnipeg
 | year = 1977a
 | mr = 0505860 }}&lt;/ref&gt;
|-
| 2-connected [[Series-parallel graph| series-parallel]] ([[treewidth]] ≤&amp;nbsp;2 [[branchwidth]] ≤&amp;nbsp;2)
| ''K''&lt;sub&gt;4&lt;/sub&gt;
| graph minor
|{{harvtxt|Diestel|2000}},&lt;ref name="diestel"/&gt; [https://books.google.com/books?id=04YbQF8oscQC&amp;lpg=PA327&amp;pg=PA327 p. 327]
|-
| [[treewidth]] ≤&amp;nbsp;3
| ''K''&lt;sub&gt;5&lt;/sub&gt;, [[octahedron]], [[pentagonal prism]], [[Wagner graph]]
| graph minor
| &lt;ref&gt;{{citation | last = Bodlaender | first = Hans L. | authorlink = Hans L. Bodlaender | title = A partial ''k''-arboretum of graphs with bounded treewidth | journal = Theoretical Computer Science | volume = 209 | issue = 1–2 | pages = 1–45 | year = 1998 | doi = 10.1016/S0304-3975(97)00228-4}}.&lt;/ref&gt;
|-
| [[branchwidth]] ≤&amp;nbsp;3
| ''K''&lt;sub&gt;5&lt;/sub&gt;, [[octahedron]], [[cube]], [[Wagner graph]]
| graph minor
| &lt;ref&gt;{{citation | last1 = Bodlaender | first1 = Hans L. | author1-link = Hans L. Bodlaender | last2 = Thilikos | first2 = Dimitrios M. | doi = 10.1006/jagm.1999.1011 | issue = 2 | journal = Journal of Algorithms | pages = 167–194 | title = Graphs with branchwidth at most three | volume = 32 | year = 1999}}.&lt;/ref&gt;
|-
| [[Cograph|Complement-reducible graphs (cographs)]]
| 4-vertex path ''P''&lt;sub&gt;4&lt;/sub&gt;
| induced subgraph
| &lt;ref&gt;{{Citation
 | last1=Seinsche | first1=D.
 | title=On a property of the class of ''n''-colorable graphs
 | mr=0337679
 | year=1974
 | journal=Journal of Combinatorial Theory, Series B
 | pages=191–193
 | issue=2
 | doi=10.1016/0095-8956(74)90063-X
 | volume=16}}&lt;/ref&gt;
|-
| [[Trivially perfect graph]]s
| 4-vertex path ''P''&lt;sub&gt;4&lt;/sub&gt; and 4-vertex cycle ''C''&lt;sub&gt;4&lt;/sub&gt;
| induced subgraph
| &lt;ref name="g78"&gt;{{citation
 | last = Golumbic | first = Martin Charles | authorlink = Martin Charles Golumbic
 | doi = 10.1016/0012-365X(78)90178-4
 | issue = 1
 | journal = Discrete Mathematics
 | pages = 105–107
 | title = Trivially perfect graphs
 | volume = 24
 | year = 1978}}..&lt;/ref&gt;
|-
| [[Threshold graph]]s
| 4-vertex path ''P''&lt;sub&gt;4&lt;/sub&gt;, 4-vertex cycle ''C''&lt;sub&gt;4&lt;/sub&gt;, and complement of ''C''&lt;sub&gt;4&lt;/sub&gt;
| induced subgraph
| &lt;ref name="g78"/&gt;
|-
| [[Line graph of a hypergraph|Line graph of 3-uniform linear hypergraph]]s
| a finite list of forbidden induced subgraphs with minimum degree at least 19
| induced subgraph
| &lt;ref&gt;{{Citation
 | first1 = Yury | last1 = Metelsky
 | first2 = Regina | last2 = Tyshkevich | author2-link = Regina Tyshkevich
 | year = 1997 | title = On line graphs of linear 3-uniform hypergraphs
 | journal = Journal of Graph Theory | volume = 25
 | issue = 4 | pages = 243–251
 | mr = 1459889  | doi = 10.1002/(SICI)1097-0118(199708)25:4&lt;243::AID-JGT1&gt;3.0.CO;2-K}}&lt;/ref&gt;
|-
| [[Line graph of a hypergraph|Line graph of ''k''-uniform linear hypergraphs, ''k''&amp;nbsp;&gt;&amp;nbsp;3]]
| a finite list of forbidden induced subgraphs with minimum edge degree at least 2''k''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;−&amp;nbsp;3''k''&amp;nbsp;+&amp;nbsp;1
| induced subgraph
| &lt;ref&gt;{{citation
 | first1 = M. S. | last1 = Jacobson
 | first2 = Andre E. | last2 = Kézdy
 | first3 = Jeno | last3 = Lehel
 | title = Recognizing intersection graphs of linear uniform hypergraphs
 | journal = [[Graphs and Combinatorics]] | volume = 13 | pages = 359–367 | year = 1997
 | mr = 1485929
 | doi = 10.1007/BF03353014 }}&lt;/ref&gt;&lt;ref&gt;{{citation
 | first1 = Ranjan N. | last1 = Naik
 | first2 = S. B. | last2 = Rao
 | first3 = S. S. | last3 = Shrikhande | authorlink3 = S. S. Shrikhande
 | first4 = N. M. | last4 = Singhi
 | title = Intersection graphs of ''k''-uniform hypergraphs
 | journal = European J. Combinatorics | volume = 3 | pages = 159–172 | year = 1982
 | mr = 0670849 | doi=10.1016/s0195-6698(82)80029-2}}&lt;/ref&gt;
|-
| Graphs [[Apex graph#YΔY-reducibility|ΔY-reducible]] to a single vertex
| a finite list of at least 68 billion distinct (1,2,3)-clique sums
| graph minor
| &lt;ref&gt;{{citation
 | first1 = Yanming | last1 = Yu
 | title = More Forbidden Minors for Wye-Delta-Wye Reducibility
 | journal = The Electronic Journal of Combinatorics | volume = 13 | year = 2006}} [http://www.combinatorics.org/ojs/index.php/eljc/article/view/v13i1r7 Website]&lt;/ref&gt;
| colspan=4 | 
|-
| colspan=4 | '''General theorems'''
|-
| colspan=4 | 
|-
|a family defined by an [[induced-hereditary property]]
| a (not necessarily finite) obstruction set
| induced subgraph
|
|-
|a family defined by a [[minor-hereditary property]]
| a finite obstruction set
| graph minor
| [[Robertson–Seymour theorem]]
&lt;!--
|-

|
|
|
|
--&gt;
|}

==See also==
*[[Erdős–Hajnal conjecture]]
*[[Forbidden subgraph problem]]
*[[Matroid minor]]
*[[Zarankiewicz problem]]

==References==
{{reflist|2}}

[[Category:Graph theory]]
[[Category:Graph minor theory]]
[[Category:Graph families]]
[[Category:Hypergraphs]]</text>
      <sha1>2wyrzvvfj7tykm0bafqzdtcht18by2w</sha1>
    </revision>
  </page>
  <page>
    <title>Geometrically regular ring</title>
    <ns>0</ns>
    <id>40023277</id>
    <revision>
      <id>810551925</id>
      <parentid>810551675</parentid>
      <timestamp>2017-11-15T23:38:26Z</timestamp>
      <contributor>
        <username>TakuyaMurata</username>
        <id>6707</id>
      </contributor>
      <comment>/* top */ lk</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2410">In [[algebraic geometry]], a '''geometrically regular ring''' is a [[Noetherian ring]] over a [[field (algebra)|field]] that remains a [[regular ring]] after any finite extension of the base field. Geometrically regular schemes are defined in a similar way. In older terminology, points with regular [[local ring]]s were called '''simple points''', and points with geometrically regular local rings were called '''absolutely simple points'''. Over fields that are of characteristic 0, or algebraically closed, or more generally [[perfect field|perfect]], geometrically regular rings are the same as regular rings. Geometric regularity originated when Chevalley and Weil pointed out to  {{harvs|txt|last=Zariski||authorlink=Oscar Zariski|year=1947}} that, over non-perfect fields, the [[Jacobian criterion]] for a simple point of an algebraic variety is not equivalent to the condition that the local ring is regular.

A Noetherian local ring containing a field ''k'' is geometrically regular over ''k'' if and only if it is [[formally smooth]] over&amp;nbsp;''k''.

==Examples==

{{harvtxt|Zariski|1947}} gave the following two examples of local rings that are regular but not geometrically regular. 

#Suppose that ''k'' is a field of characteristic ''p''&amp;nbsp;&gt;&amp;nbsp;0 and ''a'' is an element of ''k'' that is not a ''p''th power. Then every point of the curve ''x''&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''y''&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''a'' is regular. However over the field ''k''[''a''&lt;sup&gt;1/''p''&lt;/sup&gt;], every point of the curve is singular. So the points of this curve are regular but not geometrically regular.
#In the previous example, the equation defining the curve becomes reducible over a finite extension of the base field. This is not the real cause of the phenomenon: Chevalley pointed out to Zariski that the curve ''x''&lt;sup&gt;''p''&lt;/sup&gt;&amp;nbsp;+&amp;nbsp;''y''&lt;sup&gt;2&lt;/sup&gt;&amp;nbsp;=&amp;nbsp;''a'' (with the notation of the previous example) is absolutely irreducible but still has a point that is regular but not geometrically regular.

== See also ==
*[[regular scheme]]

==References==

*{{EGA|book=IV-2}}
*{{citation|mr=0021694|last=Zariski|first= Oscar|title=The concept of a simple point of an abstract algebraic variety. 
|journal=Trans. Amer. Math. Soc. |volume=62|year=1947|pages= 1–52|jstor=1990628|doi=10.1090/s0002-9947-1947-0021694-1}}

[[Category:Commutative algebra]]
[[Category:Algebraic geometry]]</text>
      <sha1>g2qebksh9ky65e3zbb0qgbcvc7tku1q</sha1>
    </revision>
  </page>
  <page>
    <title>Hanoi graph</title>
    <ns>0</ns>
    <id>58619302</id>
    <revision>
      <id>861914753</id>
      <timestamp>2018-09-30T23:18:58Z</timestamp>
      <contributor>
        <username>David Eppstein</username>
        <id>2051880</id>
      </contributor>
      <comment>New article</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6024">[[File:Hanoi-Graph-7.svg|thumb|The Hanoi graph &lt;math&gt;H^7_3&lt;/math&gt;]]
In [[graph theory]] and [[recreational mathematics]], the '''Hanoi graphs''' are [[undirected graph]]s whose vertices represent the possible states of the [[Tower of Hanoi]] puzzle, and whose edges represent allowable moves between pairs of states.

==Construction==
The puzzle consists of a set of disks of different sizes, placed in increasing order of size on a fixed set of towers.
The Hanoi graph for a puzzle with &lt;math&gt;n&lt;/math&gt; disks on &lt;math&gt;k&lt;/math&gt; towers is denoted &lt;math&gt;H^n_k&lt;/math&gt;.{{r|hkp|ikr}} Each state of the puzzle is determined by the choice of one tower for each disk, so the graph has &lt;math&gt;k^n&lt;/math&gt; vertices.{{r|ikr}}

In the moves of the puzzle, the smallest disk on one tower is moved either to an unoccupied tower or to a tower whose smallest disk is larger. If there are &lt;math&gt;u&lt;/math&gt; unoccupied towers, the number of allowable moves is
:&lt;math&gt;\binom{k}{2}-\binom{u}{2},&lt;/math&gt;
which ranges from a maximum of &lt;math&gt;\tbinom{k}{2}&lt;/math&gt;
(when &lt;math&gt;u&lt;/math&gt; is zero or one and &lt;math&gt;\tbinom{u}{2}&lt;/math&gt; is zero)
to &lt;math&gt;k-1&lt;/math&gt; (when all disks are on one tower and &lt;math&gt;u&lt;/math&gt; is &lt;math&gt;k-1&lt;/math&gt;). Therefore, the [[degree (graph theory)|degrees]] of the vertices in the Hanoi graph range from a maximum of &lt;math&gt;\tbinom{k}{2}&lt;/math&gt; to a minimum of &lt;math&gt;k-1&lt;/math&gt;.
The total number of edges is{{r|ad}}
:&lt;math&gt;\frac{1}{2}\binom{k}{2}\bigl(k^n-(k-2)^n\bigr).&lt;/math&gt;

For &lt;math&gt;k=0&lt;/math&gt; (no disks) there is only one state of the puzzle and one vertex of the graph.
For &lt;math&gt;k &gt; 0&lt;/math&gt;, the Hanoi graph &lt;math&gt;H^n_k&lt;/math&gt; can be decomposed into &lt;math&gt;k&lt;/math&gt; copies of the smaller Hanoi graph &lt;math&gt;H^{n-1}_k&lt;/math&gt;, one for each placement of the largest disk. These copies are connected to each other only at states where the largest disk is free to move: it is the only disk in its tower, and some other tower is unoccupied.{{r|afm}}

==General properties==
Every Hanoi graph contains a [[Hamiltonian cycle]].{{r|hp}}

The Hanoi graph &lt;math&gt;H^1_k&lt;/math&gt; is a [[complete graph]] on &lt;math&gt;k&lt;/math&gt; vertices. Because they contain complete graphs, all larger Hanoi graphs &lt;math&gt;H^n_k&lt;/math&gt; require at least &lt;math&gt;k&lt;/math&gt; colors in any [[graph coloring]]. They may be colored with exactly &lt;math&gt;k&lt;/math&gt; colors by summing the indexes of the towers containing each disk, and using the sum modulo &lt;math&gt;k&lt;/math&gt; as the color.{{r|ad}}

==Three towers==
A particular case of the Hanoi graphs that has been well studied since the work of {{harvtxt|Scorer|Grundy|Smith|1944}}{{r|hkp|sgs}} is the case of the three-tower Hanoi graphs, &lt;math&gt;H^n_3&lt;/math&gt;. These graphs are [[penny graph]]s (the [[contact graph]]s of non-overlapping unit disks in the plane), with an arrangement of disks that resembles the [[Sierpinski triangle]]. One way of constructing this arrangement is to arrange the numbers of [[Pascal's triangle]] on the points of a [[hexagonal lattice]], with unit spacing, and place a unit disk on each point whose number is odd.
The [[Distance (graph theory)|diameter]] of these graphs, and the length of the solution to the standard form of the Tower of Hanoi puzzle (in which the disks all start on one tower and must all move to one other tower) is &lt;math&gt;2^{n}-1&lt;/math&gt;.{{r|ikr}}

==More than three towers==
{{unsolved|mathematics|What is the diameter of the graphs &lt;math&gt;H^n_k&lt;/math&gt; for &lt;math&gt;k &gt; 3&lt;/math&gt;?}}
For &lt;math&gt;k &gt; 3&lt;/math&gt;, the structure of the Hanoi graphs is not as well understood, and the diameter of these graphs is unknown.{{r|ikr}}
When &lt;math&gt;k &gt; 1&lt;/math&gt; or when &lt;math&gt;k = 1&lt;/math&gt; and &lt;math&gt;n &gt; 3&lt;/math&gt;, these graphs are nonplanar.{{r|hp}}

==References==
{{reflist|refs=

&lt;ref name=ad&gt;{{citation
 | last1 = Arett | first1 = Danielle
 | last2 = Dorée | first2 = Suzanne | author2-link = Suzanne Dorée
 | doi = 10.4169/002557010X494841
 | issue = 3
 | journal = Mathematics Magazine
 | mr = 2668333
 | pages = 200–209
 | title = Coloring and counting on the Tower of Hanoi graphs
 | volume = 83
 | year = 2010}}&lt;/ref&gt;

&lt;ref name=afm&gt;{{citation
 | last = Stewart | first = Ian | authorlink = Ian Stewart (mathematician)
 | isbn = 0-486-43181-9
 | mr = 2046372
 | contribution = Chapter 1: The Lion, the Llama, and the Lettuce
 | publisher = Dover Publications | location = Mineola, NY
 | title = Another Fine Math You've Got Me Into
 | year = 2003}}&lt;/ref&gt;
 
&lt;ref name=hkp&gt;{{citation
 | last1 = Hinz | first1 = Andreas M.
 | last2 = Klavžar | first2 = Sandi | author2-link = Sandi Klavžar
 | last3 = Petr | first3 = Ciril
 | contribution = 2.3 Hanoi Graphs
 | doi = 10.1007/978-3-319-73779-9
 | isbn = 978-3-319-73778-2
 | location = Cham
 | mr = 3791459
 | page = 120
 | publisher = Birkhäuser
 | title = The tower of Hanoi—myths and maths
 | year = 2018}}&lt;/ref&gt;

&lt;ref name=hp&gt;{{citation
 | last1 = Hinz | first1 = Andreas M.
 | last2 = Parisse | first2 = Daniele
 | doi = 10.1016/S0723-0869(02)80023-8
 | issue = 3
 | journal = Expositiones Mathematicae
 | mr = 1924112
 | pages = 263–268
 | title = On the planarity of Hanoi graphs
 | volume = 20
 | year = 2002}}&lt;/ref&gt;

&lt;ref name=ikr&gt;{{citation
 | last1 = Imrich | first1 = Wilfried | author1-link = Wilfried Imrich
 | last2 = Klavžar | first2 = Sandi | author2-link = Sandi Klavžar
 | last3 = Rall | first3 = Douglas F.
 | contribution = 2.2 Hanoi Graphs
 | isbn = 978-1-56881-429-2
 | location = Wellesley, MA
 | mr = 2468851
 | pages = 13–15
 | publisher = A K Peters
 | title = Topics in Graph Theory: Graphs and their Cartesian Product
 | year = 2008}}&lt;/ref&gt;

&lt;ref name=sgs&gt;{{citation
 | last1 = Scorer | first1 = R. S.
 | last2 = Grundy | first2 = P. M. | author2-link = Patrick Michael Grundy
 | last3 = Smith | first3 = C. A. B. | author3-link = Cedric Smith (statistician)
 | date = July 1944
 | doi = 10.2307/3606393
 | issue = 280
 | journal = The Mathematical Gazette
 | page = 96
 | title = Some binary games
 | volume = 28}}&lt;/ref&gt;

}}

[[Category:Parametric families of graphs]]
[[Category:Planar graphs]]</text>
      <sha1>i302j7k06z49cp7l3fckja2exjabnq6</sha1>
    </revision>
  </page>
  <page>
    <title>Horn function</title>
    <ns>0</ns>
    <id>2522311</id>
    <revision>
      <id>677436295</id>
      <parentid>626902004</parentid>
      <timestamp>2015-08-23T07:35:33Z</timestamp>
      <contributor>
        <username>TomyDuby</username>
        <id>2575906</id>
      </contributor>
      <comment>Corrected the link / reference to Erdelyi: section 5.7.1 is in volume 1.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2162">In the theory of [[special function]]s in [[mathematics]], the '''Horn functions''' (named for [[Jakob Horn]]) are the 34 distinct convergent [[hypergeometric series]] of order two (i.e. having two independent variables), enumerated by {{harvtxt|Horn|1931}} (corrected by {{harvtxt|Borngässer|1933}}). They are listed in {{harv|Erdélyi|1953|loc=section 5.7.1}}. B. C. Carlson&lt;ref&gt;[http://dlmf.nist.gov/about/bio/BCCarlson 'Profile: Bille C. Carlson' in ''Digital Library of Mathematical Functions''. National Institute of Standards and Technology.]&lt;/ref&gt; revealed a problem with the Horn function classification scheme.&lt;ref&gt;{{cite journal|author=Carlson, B. C.|title=The need for a new classification of double hypergeometric series|journal=Proc. Amer. Math. Soc.|year=1976|volume=56|pages=221–224|mr=0402138|doi=10.1090/s0002-9939-1976-0402138-8}}&lt;/ref&gt;

==References==
{{reflist}}
*{{Citation | last1=Borngässer | first1=Ludwig | title=Über hypergeometrische funkionen zweier Veränderlichen | publisher=Darmstadt | series=Dissertation | year=1933}}
*{{Citation | last1=Erdélyi | first1=Arthur | last2=Magnus | first2=Wilhelm | author2-link=Wilhelm Magnus | last3=Oberhettinger | first3=Fritz | last4=Tricomi | first4=Francesco G. | title=Higher transcendental functions. Vol I | publisher=McGraw-Hill Book Company, Inc., New York-Toronto-London |mr=0058756 | year=1953 | url=http://apps.nrbook.com/bateman/Vol1.pdf}}
*{{Citation | last1=Horn | first1=J. | title=Hypergeometrische Funktionen zweier Veränderlichen | url=http://www.digizeitschriften.de/main/dms/img/?IDDOC=364781 | doi=10.1007/BF01455825 | year=1935 | journal=	Mathematische Annalen | volume=105 | issue=1 | pages=381–407}}
* J. Horn [http://www.digizeitschriften.de/resolveppn/GDZPPN002278006 Math. Ann.] '''111''', 637 (1933)
*{{Citation | last1=Srivastava | first1=H. M. | last2=Karlsson | first2=Per W. | title=Multiple Gaussian hypergeometric series | publisher=Ellis Horwood Ltd. | location=Chichester | series=Ellis Horwood Series: Mathematics and its Applications | isbn=978-0-85312-602-7 |mr=834385 | year=1985}}

[[Category:Hypergeometric functions]]


{{mathanalysis-stub}}</text>
      <sha1>16vmsvpl65fc1sltgg3wuaxe26znhog</sha1>
    </revision>
  </page>
  <page>
    <title>Integration by substitution</title>
    <ns>0</ns>
    <id>193748</id>
    <revision>
      <id>867301395</id>
      <parentid>866514385</parentid>
      <timestamp>2018-11-04T22:26:45Z</timestamp>
      <contributor>
        <username>Christopher.Gordon3</username>
        <id>7849188</id>
      </contributor>
      <minor/>
      <comment>Typo correction: changed \varphi to \phi.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="15538">{{Calculus|Integral}}
{{no footnotes|date=September 2017}}
In [[calculus]], '''integration by substitution''', also known as '''''u''-substitution''', is a method for finding [[integral]]s. Using the [[fundamental theorem of calculus]] often requires finding an [[antiderivative]]. For this and other reasons, integration by substitution is an important tool in mathematics. It is the counterpart to the [[chain rule]] for [[derivative|differentiation]].

== Substitution for a single variable ==

=== Proposition ===
Let {{math|''I'' ⊆ '''R'''}} be an interval and {{math|''φ'' : [''a'',''b''] → ''I''}} be a differentiable function with integrable derivative. Suppose that {{math|''f'' : ''I'' → '''R'''}} is a [[continuous function]]. Then
:&lt;math&gt;
\int_{\varphi(a)}^{\varphi(b)} f(u)\,du = \int_a^b f(\varphi(x))\varphi'(x)\, dx.
&lt;/math&gt;

In Leibniz notation, the substitution {{math|''u'' {{=}} ''φ''(''x'')}} yields 
:&lt;math&gt;\frac{du}{dx} = \varphi'(x).&lt;/math&gt;
Working heuristically with infinitesimals yields the equation
:&lt;math&gt;du = \varphi'(x)\,dx,&lt;/math&gt;
which suggests the substitution formula above.  (This equation may be put on a rigorous foundation by interpreting it as a statement about [[differential form]]s.)  One may view the method of integration by substitution as a partial justification of [[Leibniz's notation]] for integrals and derivatives.

The formula is used to transform one integral into another integral that is easier to compute. Thus, the formula can be used from left to right or from right to left in order to simplify a given integral. When used in the latter manner, it is sometimes known as '''''u''-substitution''' or '''''w''-substitution'''.

=== Proof ===

Integration by substitution can be derived from the [[fundamental theorem of calculus]] as follows.  Let {{math|''f''}} and {{math|''φ''}} be two functions satisfying the above hypothesis that {{math|''f''}} is continuous on {{math|''I''}} and {{math|''φ''′}} is integrable on the closed interval {{math|[''a'',''b'']}}.  Then the function {{math|''f''(''φ''(''x''))''φ''′(''x'')}} is also integrable on {{math|[''a'',''b'']}}.  Hence the integrals

:&lt;math&gt;
\int_{\varphi(a)}^{\varphi(b)} f(u)\,du
&lt;/math&gt;

and

:&lt;math&gt;
\int_a^b f(\varphi(x))\varphi'(x)\,dx
&lt;/math&gt;

in fact exist, and it remains to show that they are equal.

Since {{math|''f''}} is continuous, it has an [[antiderivative]] {{math|''F''}}. The [[function composition|composite function]] {{math|''F'' ∘ ''φ''}} is then defined. Since {{math|''φ''}} is differentiable, combining the [[chain rule]] and the definition of an antiderivative gives

:&lt;math&gt;(F \circ \varphi)'(x) = F'(\varphi(x))\varphi'(x) = f(\varphi(x))\varphi'(x).&lt;/math&gt;

Applying the [[fundamental theorem of calculus]] twice gives

:&lt;math&gt;
\begin{align}
\int_a^b f(\varphi(x))\varphi'(x)\,dx
&amp;= \int_a^b (F \circ \varphi)'(x)\,dx \\
&amp;= (F \circ \varphi)(b) - (F \circ \varphi)(a) \\
&amp;= F(\varphi(b)) - F(\varphi(a)) \\
&amp;= \int_{\varphi(a)}^{\varphi(b)} f(u)\,du,
\end{align}
&lt;/math&gt;

which is the substitution rule.

=== Examples ===

==== Example 1: from right to left ====
Consider the integral
:&lt;math&gt;\int_0^2 x \cos(x^2+1) \,dx.&lt;/math&gt;

If we apply the formula from right to left and make the substitution {{math|1=''u'' =  ''φ''(''x'') =  ''x''&lt;sup&gt;2&lt;/sup&gt; + 1}}, we obtain {{math|1=''du'' = 2''x'' ''dx''}} and hence {{math|1=''x'' ''dx'' = ½''du''}}.  Therefore

:&lt;math&gt;\begin{align}
\int_{x=0}^{x=2} x \cos(x^2+1) \,dx
&amp;= \frac{1}{2} \int_{u=1}^{u=5}\cos(u)\,du \\
&amp;= \frac{1}{2}(\sin(5)-\sin(1)).
\end{align}&lt;/math&gt;

Since the lower limit {{math|1=''x'' = 0}} was replaced with {{math|1=''u'' = 0&lt;sup&gt;2&lt;/sup&gt; + 1 = 1}}, and the upper limit {{math|1=''x'' = 2}} replaced with {{math|1=''u'' = 2&lt;sup&gt;2&lt;/sup&gt; + 1 = 5}}, a transformation back into terms of {{math|''x''}} was unnecessary.

==== Example 2: from left to right ====

For the integral
:&lt;math&gt;\int_0^1 \sqrt{1-x^2}\,dx,&lt;/math&gt;
the formula needs to be used from left to right.  The substitution {{math|1=''x'' = sin(''u'')}}, {{math|1=''dx'' = cos(''u'')&amp;thinsp;''du''}} is useful because &lt;math&gt;\sqrt{1-\sin^2u} = \cos(u)&lt;/math&gt;:

:&lt;math&gt;\begin{align}
\int_0^1 \sqrt{1-x^2}\,dx
&amp;= \int_0^{\pi/2} \sqrt{1-\sin^2u} \cos(u)\,du \\
&amp;= \int_0^{\pi/2} \cos^2u\,du \\
&amp;= \left(\frac{u}{2} + \frac{\sin(2u)}{4}\right)\Bigg\vert_0^{\pi/2} \\
&amp;= \frac{\pi}{4} + 0 = \frac{\pi}{4}.
\end{align}&lt;/math&gt;

The resulting integral can be computed using [[integration by parts]] or a [[List of trigonometric identities#Double-.2C triple-.2C and half-angle formulae|double angle formula]] followed by one more substitution. One can also note that the function being integrated is the upper right quarter of a circle with a radius of one, and hence integrating the upper right quarter from zero to one is the geometric equivalent to the area of one quarter of the unit circle, or {{math|π / 4}}.

==== Example 3: antiderivatives ====

Substitution can be used to determine [[antiderivative]]s. One chooses a relation between {{math|''x''}} and {{math|''u''}}, determines the corresponding relation between {{math|''dx''}} and {{math|''du''}} by differentiating, and performs the substitutions. An antiderivative for the substituted function can hopefully be determined; the original substitution between {{math|''u''}} and {{math|''x''}} is then undone.

Similar to our first example above, we can determine the following antiderivative with this method:

:&lt;math&gt;\begin{align}
\int x \cos(x^2+1) \,dx
&amp;= \frac{1}{2} \int 2x \cos(x^2+1) \,dx \\
&amp;= \frac{1}{2} \int\cos u\,du \\
&amp;= \frac{1}{2}\sin u + C = \frac{1}{2}\sin(x^2+1) + C,
\end{align}&lt;/math&gt;

where ''C'' is an arbitrary [[constant of integration]].

Note that there were no integral boundaries to transform, but in the last step we had to revert the original substitution {{math|1=''u'' = ''x''&lt;sup&gt;2&lt;/sup&gt; + 1}}.

== Substitution for multiple variables ==

One may also use substitution when integrating functions of several variables. 
Here the substitution function {{math|1=(''v''&lt;sub&gt;1&lt;/sub&gt;,...,''v''&lt;sub&gt;''n''&lt;/sub&gt;) = ''φ''(''u''&lt;sub&gt;1&lt;/sub&gt;, ..., ''u''&lt;sub&gt;''n''&lt;/sub&gt;)}} needs to be [[injective]] and continuously differentiable, and the differentials transform as

:&lt;math&gt;dv_1 \cdots dv_n = |\det(D\phi)(u_1, \ldots, u_n)| \, du_1 \cdots du_n,&lt;/math&gt;

where {{math|det(''Dφ'')(''u''&lt;sub&gt;1&lt;/sub&gt;, ..., ''u''&lt;sub&gt;''n''&lt;/sub&gt;)}} denotes the [[determinant]] of the [[Jacobian matrix]] of [[partial derivative]]s of ''φ'' at the point {{math|(''u''&lt;sub&gt;1&lt;/sub&gt;, ..., ''u''&lt;sub&gt;''n''&lt;/sub&gt;)}}. This formula expresses the fact that the [[absolute value]] of the determinant of a matrix equals the volume of the [[Parallelepiped#Parallelotope|parallelotope]] spanned by its columns or rows.

More precisely, the ''[[change of variables]]'' formula is stated in the next theorem:

'''Theorem'''. Let {{math|''U''}} be an open set in {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}} and {{math|''φ'' : ''U'' → '''R'''&lt;sup&gt;''n''&lt;/sup&gt;}} an [[Injective function|injective]] differentiable function with continuous partial derivatives, the Jacobian of which is nonzero for every {{math|''x''}} in {{math|''U''}}.  Then for any real-valued, compactly supported, continuous function {{math|''f''}}, with support contained in {{math|''φ''(''U'')}},

:&lt;math&gt;\int_{\varphi(U)} f(\mathbf{v})\, d\mathbf{v}
= \int_U f(\varphi(\mathbf{u})) \left|\det(D\varphi)(\mathbf{u})\right| \,d\mathbf{u}.&lt;/math&gt;

The conditions on the theorem can be weakened in various ways.  First, the requirement that {{math|''φ''}} be continuously differentiable can be replaced by the weaker assumption that {{math|''φ''}} be merely differentiable and have a continuous inverse {{harv|Rudin|1987|loc=Theorem 7.26}}.  This is guaranteed to hold if {{math|''φ''}} is continuously differentiable by the [[inverse function theorem]].  Alternatively, the requirement that {{math|det(''Dφ'') ≠ 0}} can be eliminated by applying [[Sard's theorem]] {{harv|Spivak|1965}}.

For Lebesgue measurable functions, the theorem can be stated in the following form {{harv|Fremlin|2010|loc=Theorem 263D}}:

'''Theorem'''. Let {{math|''U''}} be a measurable subset of {{math|'''R'''&lt;sup&gt;''n''&lt;/sup&gt;}} and {{math|''φ'' : ''U'' → '''R'''&lt;sup&gt;''n''&lt;/sup&gt;}} an [[Injective function|injective]] function, and suppose for every {{math|''x''}} in {{math|''U''}} there exists {{math|''φ''&amp;prime;(''x'')}} in {{math|'''R'''&lt;sup&gt;''n'',''n''&lt;/sup&gt;}} such that {{math|1=''φ''(''y'') = ''φ''(''x'') + ''φ&amp;prime;''(''x'')(''y'' − ''x'') + ''o''(&lt;nowiki&gt;||&lt;/nowiki&gt;''y'' − ''x''&lt;nowiki&gt;||&lt;/nowiki&gt;)}} as {{math|''y'' → ''x''}} (here {{math|''o''}} is [[Landau symbol#Related asymptotic notations|little-''o'' notation]]). Then {{math|''φ''(''U'')}} is measurable, and for any real-valued function {{math|''f''}} defined on {{math|''φ''(''U'')}},
:&lt;math&gt;\int_{\varphi(U)} f(v)\, dv = \int_U f(\varphi(u)) \left|\det \varphi'(u)\right| \,du&lt;/math&gt;
in the sense that if either integral exists (including the possibility of being properly infinite), then so does the other one, and they have the same value.

Another very general version in [[measure theory]] is the following {{harv|Hewitt|Stromberg|1965|loc=Theorem 20.3}}:

'''Theorem'''.  Let {{math|''X''}} be a [[locally compact]] [[Hausdorff space]] equipped with a finite [[Radon measure]] {{math|μ}}, and let {{math|''Y''}} be a [[Σ-compact space|&amp;sigma;-compact]] Hausdorff space with a [[sigma finite measure|&amp;sigma;-finite]] Radon measure {{math|ρ}}.  Let {{math|''φ'' : ''X'' → ''Y''}} be a [[continuous function|continuous]] and [[absolutely continuous]] function (where the latter means that {{math|1=''ρ''(''φ''(''E'')) = 0}} whenever {{math|1=''μ''(''E'') = 0}}).  Then there exists a real-valued [[Borel algebra|Borel measurable function]] {{math|''w''}} on {{math|''X''}} such that for every [[Lebesgue integral|Lebesgue integrable]] function {{math|''f'' : ''Y'' → '''R'''}}, the function {{math|(''f'' ∘ ''φ'') ⋅ ''w''}} is Lebesgue integrable on {{math|''X''}}, and
:&lt;math&gt;\int_Y f(y)\,d\rho(y) = \int_X (f\circ \varphi)(x)\,w(x)\,d\mu(x).&lt;/math&gt;
Furthermore, it is possible to write
:&lt;math&gt;w(x) = (g\circ \varphi)(x)&lt;/math&gt;
for some Borel measurable function {{math|''g''}} on {{math|''Y''}}.

In [[geometric measure theory]], integration by substitution is used with [[Lipschitz function]]s.  A bi-Lipschitz function is a Lipschitz function {{math|''φ'' : ''U'' → '''R'''&lt;sup&gt;n&lt;/sup&gt;}} which is injective and whose inverse function {{math|''φ''&lt;sup&gt;&amp;minus;1&lt;/sup&gt; : ''φ''(''U'') → ''U''}} is also Lipschitz.  By [[Rademacher's theorem]] a bi-Lipschitz mapping is differentiable [[almost everywhere]].  In particular, the Jacobian determinant of a bi-Lipschitz mapping {{math|det ''Dφ''}} is well-defined almost everywhere.  The following result then holds:

'''Theorem.''' Let {{math|''U''}} be an open subset of {{math|'''R'''&lt;sup&gt;n&lt;/sup&gt;}} and {{math|''φ'' : ''U'' → '''R'''&lt;sup&gt;n&lt;/sup&gt;}} be a bi-Lipschitz mapping.  Let {{math|''f'' : ''φ''(''U'') → '''R'''}} be measurable.  Then
:&lt;math&gt;\int_U (f\circ \varphi)(x) |\det D\varphi(x)|\,dx = \int_{\varphi(U)} f(x)\,dx&lt;/math&gt;
in the sense that if either integral exists (or is properly infinite), then so does the other one, and they have the same value.

The above theorem was first proposed by [[Euler]] when he developed the notion of [[double integrals]] in 1769. Although generalized to triple integrals by [[Lagrange]] in 1773, and used by [[Adrien-Marie Legendre|Legendre]], [[Laplace]], [[Gauss]], and first generalized to {{math|''n''}} variables by [[Mikhail Ostrogradski]] in 1836, it resisted a fully rigorous formal proof for a surprisingly long time, and was first satisfactorily resolved 125 years later, by [[Élie Cartan]] in a series of papers beginning in the mid-1890s ({{harnvb|Katz|1982}}; {{harvnb|Ferzola|1994}}).

==Application in probability==

Substitution can be used to answer the following important question in probability: given a random variable &lt;math&gt;X&lt;/math&gt; with probability density &lt;math&gt;p_X&lt;/math&gt; and another random variable &lt;math&gt;Y&lt;/math&gt; related to &lt;math&gt;X&lt;/math&gt; by the equation &lt;math&gt;y=\phi(x)&lt;/math&gt;, what is the probability density for &lt;math&gt;Y&lt;/math&gt;?

It is easiest to answer this question by first answering a slightly different question: what is the probability that &lt;math&gt;Y&lt;/math&gt; takes a value in some particular subset &lt;math&gt;S&lt;/math&gt;?  Denote this probability &lt;math&gt;P(Y \in S)&lt;/math&gt;.  Of course, if &lt;math&gt;Y&lt;/math&gt; has probability density &lt;math&gt;p_Y&lt;/math&gt; then the answer is

:&lt;math&gt;P(Y \in S) = \int_S p_Y(y)\,dy, &lt;/math&gt;

but this isn't really useful because we don't know &lt;math&gt;p_Y&lt;/math&gt;; it's what we're trying to find.  We can make progress by considering the problem in the variable &lt;math&gt;X&lt;/math&gt;.  &lt;math&gt;Y&lt;/math&gt; takes a value in &lt;math&gt;S&lt;/math&gt; whenever &lt;math&gt;X&lt;/math&gt; takes a value in &lt;math&gt;\phi^{-1}(S)&lt;/math&gt;, so

:&lt;math&gt;P(Y \in S) = \int_{\phi^{-1}(S)} p_X(x)\,dx.&lt;/math&gt;

Changing from variable &lt;math&gt;x&lt;/math&gt; to &lt;math&gt;y&lt;/math&gt; gives

:&lt;math&gt;P(Y \in S) = \int_{\phi^{-1}(S)} p_X(x)\,dx = \int_S p_X(\phi^{-1}(y)) \left|\frac{d\phi^{-1}}{dy}\right|\,dy.&lt;/math&gt;

Combining this with our first equation gives

:&lt;math&gt;\int_S p_Y(y)\,dy = \int_S p_X(\phi^{-1}(y)) \left|\frac{d\phi^{-1}}{dy}\right|\,dy,&lt;/math&gt;

so

:&lt;math&gt;p_Y(y) = p_X(\phi^{-1}(y)) \left|\frac{d\phi^{-1}}{dy}\right|.&lt;/math&gt;

In the case where &lt;math&gt;X&lt;/math&gt; and &lt;math&gt;Y&lt;/math&gt; depend on several uncorrelated variables, i.e. &lt;math&gt;p_X=p_X(x_1, \ldots, x_n)&lt;/math&gt; and &lt;math&gt;y=\phi(x)&lt;/math&gt;, &lt;math&gt;p_Y&lt;/math&gt; can be found by substitution in several variables discussed above. The result is

:&lt;math&gt;p_Y(y) = p_X(\phi^{-1}(y)) \left|\det D\phi ^{-1}(y) \right|.&lt;/math&gt;

==See also==
*[[Probability density function]]
*[[Substitution of variables]]
*[[Tangent half-angle substitution]]
*[[Trigonometric substitution]]

==References==
*{{citation|first=Anthony P.|last=Ferzola|url=http://mathdl.maa.org/mathDL/22/?pa=content&amp;sa=viewDocument&amp;nodeId=2688|title=Euler and differentials|journal=[[The College Mathematics Journal]]|volume=25|issue=2|year=1994|pages=102&amp;ndash;111|doi=10.2307/2687130}}
* {{citation|first=D.H.|last=Fremlin|title=Measure Theory, Volume 2|publisher=Torres Fremlin|year=2010|isbn=978-0-9538129-7-4}}.
* {{citation|first1=Edwin|last1=Hewitt|first2=Karl|last2=Stromberg|authorlink1=Edwin Hewitt|title=Real and Abstract Analysis|publisher=Springer-Verlag|year=1965|isbn=978-0-387-04559-7}}.
* {{citation|first=V.|last=Katz|title=Change of variables in multiple integrals: Euler to Cartan|journal=[[Mathematics Magazine]]|volume=55|year=1982|pages=3&amp;ndash;11|doi=10.2307/2689856|issue=1}}
* {{citation|first=Walter|last=Rudin|authorlink=Walter Rudin|title=Real and Complex Analysis|publisher=McGraw-Hill|year=1987|isbn=978-0-07-054234-1}}.
* {{citation|first=Michael|last=Spivak|authorlink=Michael Spivak|title=Calculus on Manifolds|publisher=Westview Press|year=1965|isbn=978-0-8053-9021-6}}.

==External links==
{{Wikibooks|Calculus|Integration#The_Substitution_Rule|The Substitution Rule}}
{{Wikiversity|Integration by Substitution}}
* [https://www.encyclopediaofmath.org/index.php/Integration_by_substitution Integration by substitution] at [[Encyclopedia of Mathematics]]
* [https://www.encyclopediaofmath.org/index.php/Area_formula Area formula] at [[Encyclopedia of Mathematics]]

[[Category:Articles containing proofs]]
[[Category:Integral calculus]]

[[es:Métodos de integración#Método de integración por sustitución]]</text>
      <sha1>33gvlckxr9xcjd1lp53x0l118hfszsf</sha1>
    </revision>
  </page>
  <page>
    <title>Journal of Pure and Applied Algebra</title>
    <ns>0</ns>
    <id>42530503</id>
    <revision>
      <id>824112811</id>
      <parentid>814491066</parentid>
      <timestamp>2018-02-05T11:40:56Z</timestamp>
      <contributor>
        <username>Julia W</username>
        <id>7377492</id>
      </contributor>
      <comment>fix IF</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2283">{{Infobox journal
| title = Journal of Pure and Applied Algebra
| cover = 
| editor = Eric Friedlander, Chuck Weibel, Srikanth Iyengar
| discipline = [[Algebra]]
| former_names = 
| abbreviation = J. Pure Appl. Algebra
| publisher = [[Elsevier#Imprints|North-Holland]]
| country = 
| frequency = Monthly
| history = 1971-present
| openaccess = 
| license = 
| impact = 0.652
| impact-year = 2016
| website = http://www.journals.elsevier.com/journal-of-pure-and-applied-algebra/
| link1 = http://www.sciencedirect.com/science/journal/00224049
| link1-name = Online access
| link2 = 
| link2-name = 
| JSTOR = 
| OCLC = 1800179
| LCCN = 79612749
| CODEN = JPAAA2
| ISSN = 0022-4049
| eISSN = 
}}
The '''''Journal of Pure and Applied Algebra''''' is a monthly [[peer-reviewed]] [[scientific journal]] covering that part of [[algebra]] likely to be of general mathematical interest: algebraic results with immediate applications, and the development of algebraic theories of sufficiently general relevance to allow for future applications. Its founding [[editors-in-chief]] were P. Freyd ([[University of Pennsylvania]]) and A. Heller ([[City University of New York]]). The current managing editors are Eric Friedlander ([[University of Southern California]]), Chuck Weibel ([[Rutgers University]]), and Srikanth Iyengar ([[University of Utah]]).

== Abstracting and indexing ==
The journal is abstracted and indexed in [[Current Contents]]/Physics, Chemical, &amp; Earth Sciences, [[Mathematical Reviews]], [[PASCAL (database)|PASCAL]], [[Science Citation Index]], [[Zentralblatt MATH]], and [[Scopus]]. According to the ''[[Journal Citation Reports]]'', the journal has a 2016 [[impact factor]] of 0.652.&lt;ref name=WoS&gt;{{cite book |year=2017 |chapter=Journal of Pure and Applied Algebra |title=2016 [[Journal Citation Reports]] |publisher=[[Thomson Reuters]] |edition=Science |series=[[Web of Science]] |postscript=.}}&lt;/ref&gt;

== References ==
{{Reflist}}

== External links ==
* {{Official website|http://www.journals.elsevier.com/journal-of-pure-and-applied-algebra/}}

[[Category:Mathematics journals]]
[[Category:Monthly journals]]
[[Category:English-language journals]]
[[Category:Elsevier academic journals]]
[[Category:Publications established in 1971]]


{{mathematics-journal-stub}}</text>
      <sha1>435897iltqqfxfbhrloygxeoqd4suco</sha1>
    </revision>
  </page>
  <page>
    <title>L-moment</title>
    <ns>0</ns>
    <id>24350828</id>
    <revision>
      <id>823716098</id>
      <parentid>787006865</parentid>
      <timestamp>2018-02-02T23:28:57Z</timestamp>
      <contributor>
        <username>Bender235</username>
        <id>88026</id>
      </contributor>
      <minor/>
      <comment>[[WP:AWB/T|Typo fixing]], [[WP:AWB/T|typo(s) fixed]]: Consequently → Consequently, using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17027">In [[statistics]], '''L-moments''' are a sequence of statistics used to summarize the shape of a [[probability distribution]].&lt;ref name=hos:90&gt;{{cite journal | last=Hosking | first=J.R.M. | year=1990 | title=L-moments: analysis and estimation of distributions using linear combinations of order statistics | journal=Journal of the Royal Statistical Society, Series B | volume=52 | pages=105&amp;ndash;124 | jstor=2345653}}&lt;/ref&gt;&lt;ref name=hos:92&gt;{{cite journal | last=Hosking | first= J.R.M. | year=1992 | title=Moments or L moments? An example comparing two measures of distributional shape | journal=The American Statistician | volume=46 | number=3 | pages=186&amp;ndash;189 | jstor=2685210 | doi=10.2307/2685210}}&lt;/ref&gt;&lt;ref name=hos:96&gt;{{cite journal | last=Hosking | first=J.R.M. | year=2006 | title=On the characterization of distributions by their L-moments | journal=Journal of Statistical Planning and Inference | volume=136 | pages=193&amp;ndash;198 | doi=10.1016/j.jspi.2004.06.004}}&lt;/ref&gt;&lt;ref&gt;Asquith, W.H. (2011) ''Distributional analysis with L-moment statistics using the R environment for statistical computing'', Create Space Independent Publishing Platform, [print-on-demand], {{ISBN|1-463-50841-7}}&lt;/ref&gt; They are [[linear combination]]s of [[order statistic]]s ([[L-statistic]]s) analogous to conventional [[Moment (mathematics)|moments]], and can be used to calculate quantities analogous to [[standard deviation]], [[skewness]] and [[kurtosis]], termed the L-scale, L-skewness and L-kurtosis respectively (the L-mean is identical to the conventional [[mean]]). Standardised L-moments are called '''L-moment ratios''' and are
analogous to [[standardized moment]]s. Just as for conventional moments, a theoretical distribution has a set of population L-moments. Sample L-moments can be defined for a sample from the population, and can be used as estimators of the population L-moments.

==Population L-moments==
For a random variable ''X'', the ''r''th population L-moment is&lt;ref name=hos:90/&gt;

:&lt;math&gt;
\lambda_r = r^{-1} \sum_{k=0}^{r-1} {(-1)^k \binom{r-1}{k} \mathrm{E}X_{r-k:r}},
&lt;/math&gt;

where ''X''&lt;sub&gt;''k:n''&lt;/sub&gt; denotes the ''k''&lt;sup&gt;th&lt;/sup&gt; [[order statistic]] (''k''&lt;sup&gt;th&lt;/sup&gt; smallest value) in an [[statistical independence|independent]] [[statistical sample|sample]] of size ''n'' from the distribution of ''X'' and &lt;math&gt;\mathrm{E}&lt;/math&gt; denotes [[expected value]]. In particular, the first four population L-moments are

:&lt;math&gt;
\lambda_1 = \mathrm{E}X
&lt;/math&gt;

:&lt;math&gt;
\lambda_2 = (\mathrm{E}X_{2:2} - \mathrm{E}X_{1:2})/2
&lt;/math&gt;

:&lt;math&gt;
\lambda_3 = (\mathrm{E}X_{3:3} - 2\mathrm{E}X_{2:3} + \mathrm{E}X_{1:3})/3
&lt;/math&gt;

:&lt;math&gt;
\lambda_4 = (\mathrm{E}X_{4:4} - 3\mathrm{E}X_{3:4}  + 3\mathrm{E}X_{2:4} - \mathrm{E}X_{1:4})/4.
&lt;/math&gt;

Note that the coefficients of the ''k''-th L-moment are the same as in the ''k''-th term of the [[binomial transform]], as used in the ''k''-order [[finite difference]] (finite analog to the derivative).

The first two of these L-moments have conventional names:
:&lt;math&gt;\lambda_1 = \text{mean, L-mean or L-location},&lt;/math&gt;
:&lt;math&gt;\lambda_2 = \text{L-scale}.&lt;/math&gt;
The L-scale is equal to half the [[Mean absolute difference|mean difference]].&lt;ref name=jones:02/&gt;

==Sample L-moments==
The sample L-moments can be computed as the population L-moments of the sample, summing over ''r''-element subsets of the sample &lt;math&gt;\left\{ x_1 &lt; \cdots &lt; x_j &lt; \cdots &lt; x_r \right\},&lt;/math&gt; hence averaging by dividing by the [[binomial coefficient]]:
:&lt;math&gt;
\lambda_r = r^{-1}{\tbinom{n}{r}}^{-1} \sum_{x_1 &lt; \cdots &lt; x_j &lt; \cdots &lt; x_r} {(-1)^{r-j} \binom{r-1}{j} x_j}.
&lt;/math&gt;

Grouping these by order statistic counts the number of ways an element of an ''n''-element sample can be the ''j''th element of an ''r''-element subset, and yields formulas of the form below. Direct estimators for the first four L-moments in a finite sample of ''n'' observations are:&lt;ref name=wang:96&gt;{{cite journal|last=Wang|first=Q. J.|title=Direct Sample Estimators of ''L'' Moments|journal=Water Resources Research|year=1996|volume=32|issue=12|pages=3617–3619|doi=10.1029/96WR02675}}&lt;/ref&gt;
:&lt;math&gt;\ell_1 = {\tbinom{n}{1}}^{-1} \sum_{i=1}^n x_{(i)}&lt;/math&gt;
:&lt;math&gt;\ell_2 = \tfrac{1}{2} {\tbinom{n}{2}}^{-1} \sum_{i=1}^n \left\{ \tbinom{i-1}{1} - \tbinom{n-i}{1} \right\} x_{(i)}&lt;/math&gt;
:&lt;math&gt;\ell_3 = \tfrac{1}{3} {\tbinom{n}{3}}^{-1} \sum_{i=1}^n \left\{ \tbinom{i-1}{2} - 2\tbinom{i-1}{1}\tbinom{n-i}{1} + \tbinom{n-i}{2} \right\} x_{(i)}&lt;/math&gt;
:&lt;math&gt;\ell_4 = \tfrac{1}{4} {\tbinom{n}{4}}^{-1} \sum_{i=1}^n \left\{ \tbinom{i-1}{3} - 3\tbinom{i-1}{2}\tbinom{n-i}{1} + 3\tbinom{i-1}{1}\tbinom{n-i}{2} - \tbinom{n-i}{3} \right\} x_{(i)}&lt;/math&gt;
where {{math|''x''&lt;sub&gt;(''i'')&lt;/sub&gt;}} is the {{math|''i''}}th [[order statistic]] and &lt;math&gt;\tbinom{\cdot}{\cdot}&lt;/math&gt; is a [[binomial coefficient]]. Sample L-moments can also be defined indirectly in terms of [[probability weighted moment]]s,&lt;ref name=hos:90/&gt;&lt;ref name=green:79&gt;{{cite journal|url=http://onlinelibrary.wiley.com/doi/10.1029/WR015i005p01049/abstract|title=Probability Weighted Moments: Definition and relation to parameters of several distributions expressed in inverse form|first1= JA |last1=Greenwood|first2= JM |last2=Landwehr| first3=NC |last3= Matalas |first4=JR |last4=Wallis |year= 1979|journal= Water Resources Research |volume=15 |pages=1049–1054|accessdate =17 January 2013|doi= 10.1029/WR015i005p01049}}&lt;/ref&gt;&lt;ref name=land:79&gt;{{cite journal|url=http://onlinelibrary.wiley.com/doi/10.1029/WR015i005p01055/abstract|title=Probability weighted moments compared with some traditional techniques in estimating Gumbel parameters and quantiles|first1= JM |last1=Landwehr|first2= NC |last2=Matalas| first3=JR |last3= Wallis |year= 1979|journal= Water Resources Research |volume=15 |pages=1055–1064|accessdate =4 February 2013|doi= 10.1029/WR015i005p01055}}&lt;/ref&gt; which leads to a more efficient [[algorithm]] for their computation.&lt;ref name=wang:96/&gt;&lt;ref&gt;{{citation |url=http://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/lmoment.htm|title=L Moments|date=6 January 2006|accessdate =19 January 2013}} NIST Dataplot documentation&lt;/ref&gt;

==L-moment ratios==
A set of ''L-moment ratios'', or scaled L-moments, is defined by
:&lt;math&gt;\tau_r = \lambda_r / \lambda_2, \qquad r=3,4, \dots. &lt;/math&gt;
The most useful of these are &lt;math&gt;\tau_3&lt;/math&gt;, called the ''L-skewness'', and &lt;math&gt;\tau_4&lt;/math&gt;, the ''L-kurtosis''.

L-moment ratios lie within the interval (–1, 1). Tighter bounds can be found for some specific L-moment ratios; in particular, the L-kurtosis &lt;math&gt;\tau_4&lt;/math&gt; lies in [-¼,1), and
:&lt;math&gt;\tfrac{1}{4}(5\tau_3^2-1) \leq \tau_4 &lt; 1.&lt;/math&gt;&lt;ref name=hos:90/&gt;

A quantity analogous to the [[coefficient of variation]], but based on L-moments, can also be defined:
&lt;math&gt;\tau = \lambda_2 / \lambda_1, &lt;/math&gt;
which is called the "coefficient of L-variation", or "L-CV". For a non-negative random variable, this lies in the interval (0,1)&lt;ref name=hos:90/&gt; and is identical to the [[Gini coefficient]].&lt;ref name=rvp:01&gt;{{cite journal | last1=Valbuena| first1=R. | last2=Maltamo | first2=M. | last3=Mehtätalo | first3=L. | last4=Packalen| first4=P. | year=2017 | title=Key structural features of Boreal forests may be detected directly using L-moments from airborne lidar data | journal=Remote Sensing of Environment | volume=194 | pages=437&amp;ndash;446 | doi=10.1016/j.rse.2016.10.024}}&lt;/ref&gt;

==Related quantities==

L-moments  are statistical quantities that are derived from probability weighted moments&lt;ref&gt;{{cite book|url=https://books.google.com/books/about/Regional_Frequency_Analysis.html?id=gurAnfB4nvUC|pages=3|first1=JRM |last1=Hosking|first2= JR|last2= Wallis|title= Regional Frequency Analysis: An Approach Based on L-moments|year=2005|isbn=0521019400|accessdate = 22 January 2013|publisher=Cambridge University Press}}&lt;/ref&gt;  (PWM) which were defined earlier (1979).&lt;ref name=green:79/&gt; PWM are used to efficiently estimate the parameters of distributions expressable in inverse form such as the [[Gumbel distribution|Gumbel]],&lt;ref name=land:79/&gt; the Tukey, and the Wakeby distributions.

==Usage==
There are two common ways that L-moments are used, in both cases analogously to the conventional moments:
# As [[summary statistics]] for data.
# To derive estimators for the parameters of [[probability distributions]], applying the [[method of moments (statistics)|method of moments]] to the L-moments rather than conventional moments.

In addition to doing these with standard moments, the latter (estimation) is more commonly done using [[maximum likelihood]] methods; however using L-moments provides a number of advantages. Specifically, L-moments are more [[robust statistics|robust]] than conventional moments, and existence of higher L-moments only requires that the random variable have finite mean. One disadvantage of L-moment ratios for estimation is their typically smaller sensitivity. For instance, the Laplace distribution has a kurtosis of 6 and weak exponential tails, but a larger 4th L-moment ratio than e.g. the student-t distribution with d.f.=3, which has an infinite kurtosis and much heavier tails.

As an example consider a dataset with a few data points and one outlying data value. If the ordinary [[standard deviation]] of this data set is taken it will be highly influenced by this one point: however, if the L-scale is taken it will be far less sensitive to this data value. Consequently, L-moments are far more meaningful when dealing with outliers in data than conventional moments. However, there are also other better suited methods to achieve an even higher robustness than just replacing moments by L-moments. One example of this is using L-moments as summary statistics in [[extreme value theory]]&amp;nbsp;(EVT). This application shows the limited robustness of L-moments, i.e. L-statistics are not [[resistant statistic]]s, as a single extreme value can throw them off, but because they are only linear (not [[higher-order statistics]]), they are less affected by extreme values than conventional moments.

Another advantage L-moments have over conventional moments is that their existence only requires the random variable to have finite mean, so the L-moments exist even if the higher conventional moments do not exist (for example, for [[Student's t distribution]] with low [[degrees of freedom (statistics)|degrees of freedom]]). A finite variance is required in addition in order for the standard errors of estimates of the L-moments to be finite.&lt;ref name=hos:90/&gt;

Some appearances of L-moments in the statistical literature include the book by David &amp; Nagaraja (2003, Section 9.9)&lt;ref&gt;{{cite book |last=David |first=H. A. |last2=Nagaraja |first2=H. N. |year=2003 |title=Order Statistics |edition=3rd |publisher=Wiley |isbn=0-471-38926-9 }}&lt;/ref&gt; and a number of papers.&lt;ref name=rvp:01/&gt;&lt;ref&gt;{{cite journal |last=Serfling |first=R. |last2=Xiao |first2=P. |year=2007 |title=A contribution to multivariate L-moments: L-comoment matrices |journal=Journal of Multivariate Analysis |volume=98 |issue=9 |pages=1765–1781 |doi=10.1016/j.jmva.2007.01.008 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Delicado |first=P. |last2=Goria |first2=M. N. |year=2008 |title=A small sample comparison of maximum likelihood, moments and L-moments methods for the asymmetric exponential power distribution |journal=Computational Statistics &amp; Data Analysis |volume=52 |issue=3 |pages=1661–1673 |doi=10.1016/j.csda.2007.05.021 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Alkasasbeh |first=M. R. |last2=Raqab |first2=M. Z. |year=2009 |title=Estimation of the generalized logistic distribution parameters: comparative study |journal=Statistical Methodology |volume=6 |issue=3 |pages=262–279 |doi=10.1016/j.stamet.2008.10.001 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Jones |first=M. C. |year=2004 |title=On some expressions for variance, covariance, skewness and L-moments |journal=Journal of Statistical Planning and Inference |volume=126 |issue=1 |pages=97–106 |doi=10.1016/j.jspi.2003.09.001 }}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Jones |first=M. C. |year=2009 |title=Kumaraswamy's distribution: A beta-type distribution with some tractability advantages |journal=Statistical Methodology |volume=6 |issue=1 |pages=70–81 |doi=10.1016/j.stamet.2008.04.001 }}&lt;/ref&gt; A number of favourable comparisons of L-moments with ordinary moments have been reported.&lt;ref&gt;{{cite journal |last=Royston |first=P. |year=1992 |title=Which measures of skewness and kurtosis are best? |journal=[[Statistics in Medicine (journal)|Statistics in Medicine]] |volume=11 |issue=3 |pages=333–343 |doi=10.1002/sim.4780110306}}&lt;/ref&gt;&lt;ref&gt;{{cite journal |last=Ulrych |first=T. J. |last2=Velis |first2=D. R. |last3=Woodbury |first3=A. D. |last4=Sacchi |first4=M. D. |year=2000 |title=L-moments and C-moments |journal=Stochastic Environmental Research and Risk Assessment |volume=14 |issue=1 |pages=50–68 |doi=10.1007/s004770050004 }}&lt;/ref&gt;

==Values for some common distributions==
The table below gives expressions for the first two L-moments and numerical values of the first two L-moment ratios of some common [[continuous probability distribution]]s with constant L-moment ratios.&lt;ref name=hos:90/&gt;&lt;ref name=jones:02&gt;{{cite journal|last=Jones|first=M.C.|title=Student's Simplest Distribution|journal=[[Journal of the Royal Statistical Society, Series D]]|year=2002|volume=51|issue=1|pages=41–49|jstor=3650389|doi=10.1111/1467-9884.00297}}&lt;/ref&gt;
More complex expressions have been derived for some further distributions for which the L-moment ratios vary with one or more of the distributional parameters, including the [[log-normal distribution|log-normal]], [[Gamma distribution|Gamma]], [[generalized Pareto distribution|generalized Pareto]], [[generalized extreme value distribution|generalized extreme value]], and [[generalized logistic distribution|generalized logistic]] distributions.&lt;ref name=hos:90/&gt;

{| class="wikitable sortable" style="text-align:center;"
|-
! Distribution 
! class="unsortable" | Parameters
! class="unsortable" | mean, {{math|''λ''&lt;sub&gt;1&lt;/sub&gt;}}
! class="unsortable" | L-scale, {{math|''λ''&lt;sub&gt;2&lt;/sub&gt;}}
! L-skewness, {{math|''τ''&lt;sub&gt;3&lt;/sub&gt;}} 
! L-kurtosis, {{math|''τ''&lt;sub&gt;4&lt;/sub&gt;}}
|-
! [[Continuous uniform distribution|Uniform]] 
| ''a'', ''b'' ||(''a''+''b'') / 2  || (''b''–''a'') / 6 
|align="right"| 0 
|align="right"| 0 
|-
! [[Logistic distribution|Logistic]] 
| ''μ'', ''s'' || ''μ'' || ''s'' 
|align="right"| 0 
|align="right"| {{sort|0.1667|{{Fraction|1|6}} {{=}} 0.1667}}
|-
! [[Normal distribution|Normal]] 
| ''μ'', ''σ''&lt;sup&gt;2&lt;/sup&gt; || ''μ'' || ''σ'' / {{sqrt|π}} 
|align="right"| 0 
|align="right"| 0.1226 
|-
! [[Laplace distribution|Laplace]] 
| ''μ'', ''b'' || ''μ'' || 3''b'' / 4 
|align="right"| 0 
|align="right"| {{sort|0.2357|1 / (3{{sqrt|2}}) {{=}} 0.2357}}
|-
! [[Student's t-distribution|Student's ''t'']], 2 [[degrees of freedom (statistics)|d.f.]]
| ''ν'' = 2 || 0 || ''π''/2&lt;sup&gt;3/2&lt;/sup&gt; = 1.111 
|align="right"| 0 
|align="right"| {{sort|0.375|{{Fraction|3|8}} {{=}} 0.375}}
|-
! [[Student's t-distribution|Student's ''t'']], 4 [[degrees of freedom (statistics)|d.f.]]
| ''ν'' = 4 || 0 || 15''π''/64 = 0.7363
|align="right"| 0 
|align="right"| {{sort|0.2168|111/512 {{=}} 0.2168}}
|-
! [[Exponential distribution|Exponential]] 
| ''λ'' || 1 / ''λ'' || 1 / (2''λ'')
|align="right"| {{sort|0.3333|{{1/3}} {{=}} 0.3333}} 
|align="right"| {{sort|0.1667|{{Fraction|1|6}} {{=}} 0.1667}}
|-
! [[Gumbel distribution|Gumbel]] 
| ''μ'', ''β'' || ''μ'' + ''[[Euler–Mascheroni constant|γ]]β'' || ''β'' log 2
|align="right"| 0.1699 
|align="right"| 0.1504
|}
The notation for the parameters of each distribution is the same as that used in the linked article. In the expression for the mean of the Gumbel distribution, ''γ'' is the [[Euler–Mascheroni constant]] 0.57721… .

==Extensions==
''Trimmed L-moments'' are generalizations of L-moments that give zero weight to extreme observations. They are therefore more robust to the presence of outliers, and unlike L-moments they may be well-defined for distributions for which the mean does not exist, such as the [[Cauchy distribution]].&lt;ref&gt;{{cite journal|last=Elamir|first=Elsayed A. H.|author2=Seheult, Allan H. |title=Trimmed L-moments|journal=Computational Statistics &amp; Data Analysis|year=2003|volume=43|issue=3|pages=299–314|doi=10.1016/S0167-9473(02)00250-5}}&lt;/ref&gt;

==See also==
*[[L-estimator]]

==References==
{{reflist}}

==External links==
* [http://www.research.ibm.com/people/h/hosking/lmoments.html The L-moments page] Jonathan R.M. Hosking, [[IBM Research]]
* [http://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/lmoment.htm L Moments.] [[Dataplot]] reference manual, vol. 1, auxiliary chapter. [[National Institute of Standards and Technology]], 2006. Accessed 2010-05-25.

{{theory of probability distributions|state=expanded}}
{{Statistics|descriptive}}

[[Category:Moment (mathematics)]]
[[Category:Summary statistics]]</text>
      <sha1>4dnzn7tsjr9prahbgo1siw7vespjwo9</sha1>
    </revision>
  </page>
  <page>
    <title>Laplace principle (large deviations theory)</title>
    <ns>0</ns>
    <id>12795419</id>
    <revision>
      <id>852895855</id>
      <parentid>832725955</parentid>
      <timestamp>2018-08-01T02:44:55Z</timestamp>
      <contributor>
        <username>Ozob</username>
        <id>7029908</id>
      </contributor>
      <minor/>
      <comment>Formatting, copyedits</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2582">In [[mathematics]], '''Laplace's principle''' is a basic [[theorem]] in [[large deviations theory]] which is similar to [[Varadhan's lemma]]. It gives an [[Asymptotic analysis|asymptotic expression]] for the [[Lebesgue integration|Lebesgue integral]] of exp(&amp;minus;''&amp;theta;&amp;phi;''(''x'')) over a fixed set ''A'' as ''&amp;theta;'' becomes large. Such expressions can be used, for example, in [[statistical mechanics]] to determining the limiting behaviour of a system as the temperature tends to [[absolute zero]].

==Statement of the result==

Let ''A'' be a [[Lebesgue measure|Lebesgue-measurable]] [[subset]] of ''d''-[[dimension]]al [[Euclidean space]] '''R'''&lt;sup&gt;''d''&lt;/sup&gt; and let ''&amp;phi;''&amp;nbsp;:&amp;nbsp;'''R'''&lt;sup&gt;''d''&lt;/sup&gt;&amp;nbsp;→&amp;nbsp;'''R''' be a [[measurable function]] with

:&lt;math&gt;\int_A e^{-\varphi(x)} \,dx &lt; \infty.&lt;/math&gt;

Then

:&lt;math&gt;\lim_{\theta \to \infty} \frac1{\theta} \log \int_A e^{-\theta \varphi(x)} \, dx = - \mathop{\mathrm{ess \, inf}}_{x \in A} \varphi(x),&lt;/math&gt;

where ess&amp;nbsp;inf denotes the [[essential infimum]]. Heuristically, this may be read as saying that for large ''&amp;theta;'',

:&lt;math&gt;\int_A e^{-\theta \varphi(x)} \, dx \approx \exp \left(-\theta \mathop{\mathrm{ess \, inf}}_{x \in A} \varphi(x) \right).&lt;/math&gt;

==Application==

The Laplace principle can be applied to the family of [[probability measure]]s '''P'''&lt;sub&gt;''&amp;theta;''&lt;/sub&gt; given by

:&lt;math&gt;\mathbf{P}_\theta (A) = \left( \int_A e^{-\theta \varphi(x)} \, dx \right) \bigg/ \left( \int_{\mathbf{R}^{d}} e^{-\theta \varphi(y)} \, dy \right)&lt;/math&gt;

to give an asymptotic expression for the probability of some event ''A'' as ''&amp;theta;'' becomes large. For example, if ''X'' is a standard [[normal distribution|normally distributed]] [[random variable]] on '''R''', then

:&lt;math&gt;\lim_{\varepsilon \downarrow 0} \varepsilon \log \mathbf{P} \big[ \sqrt{\varepsilon} X \in A \big] = - \mathop{\mathrm{ess \, inf}}_{x \in A} \frac{x^2}{2}&lt;/math&gt;

for every measurable set ''A''.

== See also ==
* [[Laplace's method]]

==References==

* {{cite book
| last= Dembo
| first = Amir
|author2=Zeitouni, Ofer
 | title = Large deviations techniques and applications
| series = Applications of Mathematics (New York) 38
| edition = Second
| publisher = Springer-Verlag
| location = New York
| year = 1998
| pages = xvi+396
| isbn = 0-387-98406-2
}} {{MathSciNet|id=1619036}}

[[Category:Asymptotic analysis]]
[[Category:Large deviations theory]]
[[Category:Probability theorems]]
[[Category:Statistical mechanics]]
[[Category:Mathematical principles]]
[[Category:Theorems in analysis]]</text>
      <sha1>iwojfv64qfob1tw3inybtr4ojut0ttf</sha1>
    </revision>
  </page>
  <page>
    <title>Louvain Modularity</title>
    <ns>0</ns>
    <id>44454257</id>
    <revision>
      <id>866629355</id>
      <parentid>848515111</parentid>
      <timestamp>2018-10-31T14:41:46Z</timestamp>
      <contributor>
        <username>Prubbens</username>
        <id>19103445</id>
      </contributor>
      <minor/>
      <comment>Reference 1 and 3 were the same. Merged to one</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="8707">{{Network Science}}

The '''Louvain Method for community detection''' is a method to extract communities from large networks created by Blondel ''et al''.&lt;ref name = "Louvain"&gt;{{cite journal|last1=Blondel|first1=Vincent D|last2=Guillaume|first2=Jean-Loup|last3=Lambiotte|first3=Renaud|last4=Lefebvre|first4=Etienne|title=Fast unfolding of communities in large networks|journal=Journal of Statistical Mechanics: Theory and Experiment|date=9 October 2008|volume=2008|issue=10|pages=P10008|doi=10.1088/1742-5468/2008/10/P10008|arxiv=0803.0476|bibcode=2008JSMTE..10..008B}}&lt;/ref&gt; from the University of Louvain (affiliation of authors has given the method its name).  The method is a greedy optimization method that appears to run in time &lt;math&gt;O(n \log n)&lt;/math&gt;.

==Modularity Optimization==
The inspiration for this method of [[Community structure|community detection]] is the optimization of [[Modularity (networks)|Modularity]] as the algorithm progresses. Modularity is a scale value between -1 and 1 that measures the density of edges inside communities to edges outside communities. Optimizing this value theoretically results in the best possible grouping of the nodes of a given network, however going through all possible iterations of the nodes into groups is impractical so heuristic algorithms are used.
In the Louvain Method of community detection, first small communities are found by optimizing modularity locally on all nodes, then each small community is grouped into one node and the first step is repeated. The method is similar to the earlier method by Clauset, Newman and Moore&lt;ref&gt;{{Cite journal|last=Clauset|first=Aaron|last2=Newman|first2=M. E. J.|last3=Moore|first3=Cristopher|date=2004-12-06|title=Finding community structure in very large networks|arxiv=cond-mat/0408187|journal=Physical Review E|volume=70|issue=6|doi=10.1103/PhysRevE.70.066111|issn=1539-3755|bibcode=2004PhRvE..70f6111C}}&lt;/ref&gt; that connects communities whose amalgamation produces the largest increase in modularity.

==Algorithm==
The value to be optimized is [[Modularity (networks)|modularity]], defined as a value between -1 and 1 that measures the density of links inside communities compared to links between communities.&lt;ref name = "Louvain"&gt;&lt;/ref&gt; For a weighted graph, modularity is defined as:

&lt;math&gt;Q = \frac{1}{2m}\sum\limits_{ij}\bigg[A_{ij} - \frac{k_i k_j}{2m}\bigg]\delta (c_i,c_j), &lt;/math&gt;

where
* &lt;math&gt;A_{ij}&lt;/math&gt; represents the edge weight between nodes &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt;;
* &lt;math&gt;k_i&lt;/math&gt; and &lt;math&gt;k_j&lt;/math&gt; are the sum of the weights of the edges attached to nodes &lt;math&gt;i&lt;/math&gt; and &lt;math&gt;j&lt;/math&gt;, respectively;
* &lt;math&gt;2m&lt;/math&gt; is the sum of all of the edge weights in the graph;
* &lt;math&gt;c_i&lt;/math&gt; and &lt;math&gt;c_j&lt;/math&gt; are the communities of the nodes; and 
* &lt;math&gt;\delta&lt;/math&gt; is a simple [[Kronecker delta|delta function]].

In order to maximize this value efficiently, the Louvain Method has two phases that are repeated iteratively.

First, each node in the network is assigned to its own community. Then for each node &lt;math&gt;i&lt;/math&gt;, the change in modularity is calculated for removing &lt;math&gt;i&lt;/math&gt; from its own community and moving it into the community of each neighbor &lt;math&gt;j&lt;/math&gt; of &lt;math&gt;i&lt;/math&gt;. This value is easily calculated by two steps: (1) removing &lt;math&gt;i&lt;/math&gt; from its original community, and (2) inserting &lt;math&gt;i&lt;/math&gt; to the community of &lt;math&gt;j&lt;/math&gt;. The two equations are quite similar, and the equation for step (2) is: &lt;ref name="Louvain" /&gt;

&lt;math&gt; \Delta Q = \bigg[ \frac{\Sigma_{in} + 2k_{i,in}}{2m} - \bigg(\frac{\Sigma_{tot} + k_i}{2m}\bigg)^2 \bigg]-\bigg[\frac{\Sigma_{in}}{2m} - \bigg(\frac{\Sigma_{tot}}{2m}\bigg)^2-\bigg(\frac{k_i}{2m}\bigg)^2\bigg] &lt;/math&gt;

Where &lt;math&gt;\Sigma_{in}&lt;/math&gt; is sum of all the weights of the links inside the community &lt;math&gt;i&lt;/math&gt; is moving into, &lt;math&gt;\Sigma_{tot}&lt;/math&gt; is the sum of all the weights of the links to nodes in the community &lt;math&gt;i&lt;/math&gt; is moving into, &lt;math&gt;k_i&lt;/math&gt; is the weighted degree of &lt;math&gt;i&lt;/math&gt;, &lt;math&gt;k_{i,in}&lt;/math&gt; is the sum of the weights of the links between &lt;math&gt;i&lt;/math&gt; and other nodes in the community that &lt;math&gt;i&lt;/math&gt; is moving into, and &lt;math&gt;m&lt;/math&gt; is the sum of the weights of all links in the network. Then, once this value is calculated for all communities &lt;math&gt;i&lt;/math&gt; is connected to, &lt;math&gt;i&lt;/math&gt; is placed into the community that resulted in the greatest modularity increase. If no increase is possible, &lt;math&gt;i&lt;/math&gt; remains in its original community. This process is applied repeatedly and sequentially to all nodes until no modularity increase can occur. Once this local maximum of modularity is hit, the first phase has ended.

In the second phase of the algorithm, it groups all of the nodes in the same community and builds a new network where nodes are the communities from the previous phase. Any links between nodes of the same community are now represented by self loops on the new community node and links from multiple nodes in the same community to a node in a different community are represented by weighted edges between communities. Once the new network is created, the second phase has ended and the first phase can be re-applied to the new network.

==Previous Uses==
*Twitter social Network (2.4 Million nodes, 38 million links) by Josep Pujol, Vijay Erramilli, and Pablo Rodriguez:&lt;ref&gt;https://arxiv.org/pdf/0905.4918v1.pdf&lt;/ref&gt; The authors explore the problem of partitioning Online Social Networks onto different machines.
*Mobile phone Network (4 Million nodes, 100 Million links) by Derek Greene, Donal Doyle, and Padraig Cunningham:&lt;ref&gt;{{cite web |url=https://www.csi.ucd.ie/files/ucd-csi-2011-06.pdf |title=Archived copy |accessdate=2014-11-20 |deadurl=yes |archiveurl=https://web.archive.org/web/20130512153616/http://www.csi.ucd.ie/files/ucd-csi-2011-06.pdf |archivedate=2013-05-12 |df= }}&lt;/ref&gt; Community-tracking strategies for identifying dynamic communities of different dynamic social networks.
*Detecting species in network-based dynamical model.&lt;ref&gt;{{Cite journal|last=Markovitch|first=Omer | last2=Krasnogor|first2=Natalio | title=Predicting species emergence in simulated complex pre-biotic networks |url=http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0192871 | journal=PLoS ONE|volume=13|issue=2|doi=10.1371/journal.pone.0192871|pages=e0192871}}&lt;/ref&gt;

==Comparison to Other Methods==
When comparing modularity optimization methods, the two measures of importance are the speed and the resulting modularity value. A higher speed is better as it shows a method is more efficient than others and a higher modularity value is desirable as it points to having better defined communities.
The compared methods are, the algorithm of Clauset, Newman, and Moore,&lt;ref&gt;http://journals.aps.org/pre/abstract/10.1103/PhysRevE.70.066111&lt;/ref&gt; Pons and Latapy,&lt;ref&gt;http://jgaa.info/accepted/2006/PonsLatapy2006.10.2.pdf&lt;/ref&gt; and Watika and Tsurumi.&lt;ref&gt;https://arxiv.org/abs/cs/0702048&lt;/ref&gt;

{| border="1" class="wikitable"
|+ Modularity Optimization Comparison&lt;ref&gt;https://arxiv.org/pdf/0803.0476v2.pdf&lt;/ref&gt;
!
! Karate
! Arxiv
! Internet
! Web nd.edu
! Phone
! Web uk-2005
! Web WebBase 2001
|-
! Nodes/links
| 34/77 || 9k/24k || 70k/351k || 325k/1M || 2.6M/6.3M || 39M/783M || 118M/1B
|-
! Clauset, Newman, and Moore
|  .38/0s || .772/3.6s || .692/799s || .927/5034s || -/- || -/- || -/-
|-
!Pons and Latapy 
|.42/0s || .757/3.3s || .729/575s || .895/6666s || -/- || -/- || -/-
|-
! Watike and Tsurmi
|.42/0s || .761/0.7s || .667/62s || .898/248s || .56/464s || -/- || -/-
|-
! Louvain Method
|.42/0s || .813/0s || .781/1s || .935/3s || .769/134s || .979/738s || .984/152mn
|}
-/- in the table refers to a method that took over 24hrs to run. This table (from &lt;ref name="Louvain" /&gt;&lt;ref&gt;Multilevel local optimization of modularity, T. Aynaud, V.D. Blondel, J.-L. Guillaume, R. Lambiotte - in Graph Partitioning, 315-345, Publisher John Wiley &amp; Sons, 2011.&lt;/ref&gt;) shows that the Louvain method outperforms many similar modularity optimization methods in both the modularity and the time categories.

==See also==
* [[Modularity (networks)|Modularity]]
* [[Community structure]]
* [[Network science|Network Science]]
* [[K-means clustering]]

==References==
{{reflist}}
&lt;!--- After listing your sources please cite them using inline citations and place them after the information they cite. Please see http://en.wikipedia.org/wiki/Wikipedia:REFB for instructions on how to add citations. ---&gt;
*"The Louvain method for community detection in large networks" Vincent Blondel http://perso.uclouvain.be/vincent.blondel/research/louvain.html

[[Category:Network theory]]</text>
      <sha1>8022g93096bq7v2jqjcouk30ubt8cpx</sha1>
    </revision>
  </page>
  <page>
    <title>Miklós Ajtai</title>
    <ns>0</ns>
    <id>6935703</id>
    <revision>
      <id>735644092</id>
      <parentid>725647820</parentid>
      <timestamp>2016-08-22T03:52:47Z</timestamp>
      <contributor>
        <username>TAnthony</username>
        <id>1808194</id>
      </contributor>
      <comment>USA is deprecated, per [[MOS:NOTUSA]], and correct [[MOS:OVERLINK|overlinking]] of common places and languages using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4802">{{One source|date=December 2009}}
{{eastern name order|Ajtai Miklós}}
{{Infobox scientist
| name              = Miklos Ajtai
| image             = &lt;!--(filename only)--&gt;
| image_size        = 
| alt               = 
| caption           = 
| birth_date        = {{birth date and age|1946|7|2|df=yes}}
| birth_place       = [[Budapest]], [[Second Republic of Hungary]]
| death_date        = 
| death_place       = 
| residence         = [[San Jose, California|San Jose]], [[California]], United States
| citizenship       = 
| nationality       = Hungarian-American
| ethnicity         = 
| fields            = [[Computational complexity theory]]
| workplaces        = [[IBM]] [[Almaden Research Center]]
| alma_mater        = [[Hungarian Academy of Sciences]]
| doctoral_advisor  = 
| academic_advisors = 
| doctoral_students = 
| notable_students  = 
| known_for         = 
| author_abbrev_bot = 
| author_abbrev_zoo = 
| influences        = 
| influenced        = 
| awards            = [[Knuth Prize]] (2003)&lt;ref name=knuth&gt;http://www.sigact.org/Prizes/Knuth/2003.html&lt;/ref&gt;
| signature         = &lt;!--(filename only)--&gt;
| signature_alt     = 
| footnotes         = 
}}

'''Miklós Ajtai''' (born 2 July 1946) is a [[computer scientist]] at the [[IBM]] [[Almaden Research Center]], United States. In 2003, he received the [[Knuth Prize]] for his numerous contributions to the field, including a classic [[sorting network]] algorithm (developed jointly with [[János Komlós (mathematician)|J. Komlós]] and [[Endre Szemerédi]]), exponential lower bounds, superlinear time-space tradeoffs for branching programs, and other "unique and spectacular" results.

==Selected results==
One of Ajtai's results states that the length of proofs in [[propositional logic]] of the [[pigeonhole principle]] for ''n'' items grows faster than any [[polynomial]] in ''n''. He also proved that the statement "any two [[countable]] [[structure (mathematical logic)|structure]]s that are second-order equivalent are also [[isomorphic]]" is both [[consistent]] with and [[Independence (mathematical logic)|independent]] of [[ZFC]]. Ajtai and [[Endre Szemerédi|Szemerédi]] proved the [[corners theorem]], an important step toward higher-dimensional generalizations of the [[Szemerédi's theorem|Szemerédi theorem]]. With [[János Komlós (mathematician)|Komlós]] and [[Endre Szemerédi|Szemerédi]] he proved the ''ct''&lt;sup&gt;2&lt;/sup&gt;/log ''t'' upper bound for the [[Ramsey's theorem#Ramsey numbers|Ramsey number]] ''R''(3,''t''). The corresponding lower bound was proved by [[Jeong Han Kim|Kim]] only in 1995, a result that earned him a [[Fulkerson Prize]].  With [[Václav Chvátal|Chvátal]], [[Monty Newborn|Newborn]], and [[Endre Szemerédi|Szemerédi]], Ajtai proved the [[crossing number inequality]], that any drawing of a graph with ''n'' vertices and ''m'' edges, where {{nowrap|''m'' &gt; 4''n''}}, has at least {{nowrap|''m''&lt;sup&gt;3&lt;/sup&gt; / 100''n''&lt;sup&gt;2&lt;/sup&gt;}} [[Crossing number (graph theory)|crossings]]. Ajtai and [[Cynthia Dwork|Dwork]] devised in 1997 a lattice-based [[public-key cryptosystem]]; Ajtai has done extensive work on [[lattice problem]]s. For his numerous contributions in Theoretical Computer Science he received the Knuth Prize.&lt;ref name=knuth /&gt;

==Biodata==
Ajtai received his [[Candidate of Sciences]] degree in 1976 from the [[Hungarian Academy of Sciences]].&lt;ref&gt;Magyar Tudományos Akadémia, Almanach, 1986, Budapest.&lt;/ref&gt; Since 1995 he has been an external member of the [[Hungarian Academy of Sciences]].

==Selected papers==
#{{citation|first=M.|last=Ajtai|title=Isomorphism and higher order equivalence|journal=Annals of Mathematical Logic|volume=16|issue=3|year=1979|pages=181–203|doi=10.1016/0003-4843(79)90001-9}}.
#{{citation|first1=M.|last1=Ajtai|author2-link=János Komlós (mathematician)|first2=J.|last2=Komlós|author3-link=Endre Szemerédi|first3=E.|last3=Szemerédi|title=Largest random component of a ''k''-cube|journal=[[Combinatorica]]|volume=2|issue=1|year=1982|pages=1–7|doi=10.1007/BF02579276}}.
&lt;!--
==See also==
*[[Ajtai–Dwork cryptosystem]]--&gt;

==References==
{{reflist}}

==External links==
* [http://www.almaden.ibm.com/cs/people/ajtai/  Miklós Ajtai home page]
* {{AcademicSearch|787016}}
* {{MathGenealogy|id=95775}}

{{Knuth Prize laureates}}

{{Authority control}}

{{DEFAULTSORT:Ajtai, Miklos}}
[[Category:1946 births]]
[[Category:Living people]]
[[Category:Knuth Prize laureates]]
[[Category:Hungarian mathematicians]]
[[Category:Hungarian computer scientists]]
[[Category:Members of the Hungarian Academy of Sciences]]
[[Category:Theoretical computer scientists]]
[[Category:Hungarian expatriates in the United States]]
[[Category:American computer scientists]]
[[Category:IBM employees]]


{{Hungary-scientist-stub}}
{{compu-scientist-stub}}</text>
      <sha1>lydjwj9g8bul5zzsluq3dadxuhdih3o</sha1>
    </revision>
  </page>
  <page>
    <title>Minimum rank of a graph</title>
    <ns>0</ns>
    <id>39378034</id>
    <revision>
      <id>702639230</id>
      <parentid>702590981</parentid>
      <timestamp>2016-01-31T20:33:41Z</timestamp>
      <contributor>
        <username>BD2412</username>
        <id>196446</id>
      </contributor>
      <minor/>
      <comment>Fixing [[Wikipedia:Disambiguation pages with links|links to disambiguation pages]], replaced: [[Graph (mathematics)|graph]]{{dn|date=January 2016}} → [[Graph (discrete mathematics)|graph]] (2) using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3495">In mathematics, the '''minimum rank''' is a [[Graph (discrete mathematics)|graph]] parameter &lt;math&gt;\operatorname{mr}(G)&lt;/math&gt; for any [[Graph (discrete mathematics)|graph]] ''G''. It was motivated by the [[Colin de Verdière's invariant]].

==Definition==
The [[adjacency matrix]] of a given [[undirected graph]] is a [[symmetric matrix]] whose rows and columns both correspond to the vertices of the graph. Its coefficients are all 0 or 1, and the coefficient in row ''i'' and column ''j'' is nonzero whenever vertex ''i'' is adjacent to vertex ''j'' in the graph. More generally, one can define a ''generalized adjacency matrix'' to be any matrix of real numbers with the same pattern of nonzeros. The minimum rank of the graph &lt;math&gt; G&lt;/math&gt; is denoted by &lt;math&gt;\operatorname{mr} (G)&lt;/math&gt; and is defined as the smallest [[Rank (linear algebra)|rank]] of any generalized adjacency matrix of the graph.

==Properties==
*The minimum rank of a graph is always at most equal to ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1, where ''n'' is the number of vertices in the graph.&lt;ref&gt;Fallat-Hogben, Observation 1.2.&lt;/ref&gt;
*For every [[induced subgraph]] ''H'' of a given graph ''G'', the minimum rank of ''H'' is at most equal to the minimum rank of ''G''.&lt;ref&gt;Fallat-Hogben, Observation 1.6.&lt;/ref&gt;
*If a given graph is not [[connected graph|connected]], then its minimum rank is the sum of the minimum ranks of its [[Connected component (graph theory)|connected components]].&lt;ref&gt;Fallat-Hogben, Observation 1.6.&lt;/ref&gt;
*The minimum rank is a [[graph invariant]]: any two [[Graph isomorphism|isomorphic]] graphs necessarily have the same minimum rank.

==Characterization of known graph families==
Several families of graphs may be characterized in terms of their minimum ranks.
* For &lt;math&gt;n\geq 2&lt;/math&gt;, the [[complete graph]] ''K''&lt;sub&gt;''n''&lt;/sub&gt; on ''n'' vertices has minimum rank one. The only graphs that are connected and have minimum rank one are the complete graphs.&lt;ref&gt;Fallat-Hogben, Observation 1.2.&lt;/ref&gt;
*A [[path graph]] ''P''&lt;sub&gt;''n''&lt;/sub&gt; on ''n'' vertices has minimum rank ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1. The only ''n''-vertex graphs with minimum rank  ''n''&amp;nbsp;&amp;minus;&amp;nbsp;1 are the path graphs.&lt;ref&gt;Fallat-Hogben, Corollary 1.5.&lt;/ref&gt;
*A [[cycle graph]] ''C''&lt;sub&gt;''n''&lt;/sub&gt; on ''n'' vertices has minimum rank ''n''&amp;nbsp;&amp;minus;&amp;nbsp;2.&lt;ref&gt;Fallat-Hogben, Observation 1.6.&lt;/ref&gt;
* Let &lt;math&gt;G&lt;/math&gt; be a [[K-vertex-connected graph|2-connected]] graph. Then &lt;math&gt;\operatorname{mr}(G)=|G|-2&lt;/math&gt; if and only if &lt;math&gt;G&lt;/math&gt; is a linear 2-tree.&lt;ref&gt;Fallat-Hogben, Theorem 2.10.&lt;/ref&gt;
* A graph &lt;math&gt;G&lt;/math&gt; has &lt;math&gt;\operatorname{mr}(G)\leq 2&lt;/math&gt; if and only if the complement of &lt;math&gt;G&lt;/math&gt; is of the form &lt;math&gt;(K_{s_1}\cup K_{s_2}\cup K_{p_1,q_1}\cup \cdots \cup K_{p_k,q_k} ) \vee K_r&lt;/math&gt; for appropriate nonnegative integers &lt;math&gt;k, s_1, s_2, p_1, q_1,\ldots , p_k, q_k, r&lt;/math&gt; with &lt;math&gt;p_i+q_i&gt;0&lt;/math&gt; for all &lt;math&gt;i=1,\ldots, k&lt;/math&gt;.&lt;ref&gt;Fallat-Hogben, Theorem 2.9.&lt;/ref&gt;

== Notes ==
{{Reflist|30em}}

== References ==
*{{citation
 | last1 = Fallat | first1 = Shaun
 | last2 = Hogben | first2 = Leslie
 | contribution = The minimum rank of symmetric matrices described by a graph: A survey
 | pages = 558–582
 | title = Linear Algebra and its Applications 426 (2007)  
 | url = http://orion.math.iastate.edu/lhogben/research/FallatHogbenMinRank07.pdf}}.

{{DEFAULTSORT:Minimum rank of a graph}}
[[Category:Algebraic graph theory]]
[[Category:Graph invariants]]</text>
      <sha1>dybl8kwcwsml1s78rp48fi0m22mz1iq</sha1>
    </revision>
  </page>
  <page>
    <title>Multipartite entanglement</title>
    <ns>0</ns>
    <id>16293393</id>
    <revision>
      <id>863082728</id>
      <parentid>800385936</parentid>
      <timestamp>2018-10-08T16:17:17Z</timestamp>
      <contributor>
        <username>Qcomp</username>
        <id>138574</id>
      </contributor>
      <minor/>
      <comment>/* Further reading */ -obsolete "class", -arxiv= where no preprint exists</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="17729">In the case of systems composed of &lt;math&gt;m &gt; 2&lt;/math&gt; subsystems the classification of entangled states is richer than in the bipartite case. Indeed, in '''multipartite entanglement''' apart from fully [[separable state]]s and fully [[entangled state]]s, there also exists the notion of partially separable states.&lt;ref name=quantiki&gt;
{{cite web
 |date=4 January 2008
 |title=Multipartite entanglement
 |url=https://www.quantiki.org/wiki/multipartite-entanglement
 |work=Quantiki.org
}}&lt;/ref&gt;

== Full and partial separability ==
The definitions of fully separable and fully entangled multipartite states naturally generalizes that of separable and entangled states in the bipartite case, as follows.&lt;ref name=quantiki/&gt;

'''Definition [Full &lt;math&gt;\; m&lt;/math&gt;-partite separability (&lt;math&gt;\; m&lt;/math&gt;-separability) of &lt;math&gt;\; m&lt;/math&gt; systems]:''' The state &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; of &lt;math&gt;\; m&lt;/math&gt; subsystems &lt;math&gt;\; A_1, \ldots, A_m&lt;/math&gt; with Hilbert space &lt;math&gt;\; \mathcal{H}_{A_1 \ldots A_m}=\mathcal{H}_{A_1}\otimes\ldots\otimes \mathcal{H}_{A_m}&lt;/math&gt; is '''fully separable''' if and only if it can be written in the form
:&lt;math&gt;\; \varrho_{A_1\ldots A_m} = \sum_{i=1}^k p_i \varrho_{A_1}^i \otimes \ldots \otimes \varrho_{A_m}^i.&lt;/math&gt;
Correspondingly, the state &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; is '''fully entangled''' if it cannot be written in the above form.

As in the bipartite case, the set of &lt;math&gt;\; m&lt;/math&gt;-separable states is ''convex'' and ''closed'' with respect to trace norm, and separability is preserved under  &lt;math&gt;\; m&lt;/math&gt;-separable operations &lt;math&gt;\; \sum_i\Omega_i^1\otimes\ldots\otimes\Omega_i^n&lt;/math&gt; which are a straightforward generalization of the bipartite ones:
:&lt;math&gt;\; \varrho_{A_1\ldots A_m}\to 
\frac{\sum_i\Omega_i^1\otimes\ldots\otimes\Omega_i^n\varrho_{A_1\ldots A_m}
(\Omega_i^1\otimes\ldots\otimes\Omega_i^n)^\dagger}{Tr[\sum_i
\Omega_i^1\otimes\ldots\otimes\Omega_i^n\varrho_{A_1\ldots A_m}
(\Omega_i^1\otimes\ldots\otimes\Omega_i^n)^\dagger]} . &lt;/math&gt;&lt;ref name=quantiki/&gt;

As mentioned above, though, in the multipartite setting we also have different notions of '''partial separability'''.&lt;ref name=quantiki/&gt;

'''Definition [separability with respect to partitions]:''' The state &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; of &lt;math&gt;\; m&lt;/math&gt; subsystems &lt;math&gt;\; A_1, \ldots, A_m&lt;/math&gt; is '''separable with respect to a given partition''' &lt;math&gt;\; \{I_1, \ldots, I_k\}&lt;/math&gt;, where &lt;math&gt;\; I_i&lt;/math&gt; are disjoint subsets of the indices &lt;math&gt;\; I=\{1, \ldots, m\}, \cup_{j=1}^k I_j = I&lt;/math&gt;, if and only if it can be written
:&lt;math&gt;\; \varrho_{A_1\ldots A_m} = \sum_{i=1}^N p_i \varrho_1^i \otimes \ldots \otimes \varrho_k^i.&lt;/math&gt;&lt;ref name=quantiki/&gt;

'''Definition [semiseparability]:''' The state &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; is '''semiseparable''' if and only if it is '''separable under all &lt;math&gt;\; 1&lt;/math&gt;-&lt;math&gt;\; (m-1)&lt;/math&gt; partitions''', &lt;math&gt;\; \big\{I_1=\{k\}, I_2=\{1,\ldots,k-1,k+1,\ldots,m\}\big\}, 1\leq k \leq m&lt;/math&gt;.&lt;ref name=quantiki/&gt;

'''Definition [s-particle entanglement]:''' An &lt;math&gt;\; m&lt;/math&gt;-particle system can have at most '''&lt;math&gt;\; s&lt;/math&gt;-particle entanglement''' if it is a mixture of all states such that each of them is separable with respect to some partition &lt;math&gt;\; \{I_1,\ldots,I_k\}&lt;/math&gt;, where all sets of indices &lt;math&gt;\; I_k&lt;/math&gt; have cardinality &lt;math&gt;\; N\leq s&lt;/math&gt;.&lt;ref name=quantiki/&gt;

== Separability characterization and criteria==
=== Pure states ===
An equivalent definition to Full m-partite separability is given as follows: The pure state &lt;math&gt;|\Psi_{A_1\ldots A_m}\rangle&lt;/math&gt; of &lt;math&gt;\; m&lt;/math&gt; subsystems &lt;math&gt;\; A_1, \ldots, A_m&lt;/math&gt; is '''fully &lt;math&gt;\; m&lt;/math&gt;-partite separable''' if and only if it can be written
:&lt;math&gt;\; |\Psi_{A_1\ldots A_m}\rangle =  |\psi_{A_1}\rangle \otimes \ldots \otimes |\psi_{A_m}\rangle.&lt;/math&gt;&lt;ref name=quantiki/&gt;

In order to check this, it is enough to compute reduced density matrices of elementary subsystems and see whether they are pure. However, this cannot be done so easily in the multipartite case, as only rarely multipartite pure states admit the ''[[Bipartite states and Schmidt Decomposition|generalized Schmidt Decomposition]]'' &lt;math&gt;\; |\Psi_{A_1\ldots A_m}\rangle = \sum_{i=1}^{min\{d_{A_1},\ldots,d_{A_m}\}}a_i |e_{A_1}^i\rangle \otimes \ldots \otimes |e_{A_m}^i\rangle&lt;/math&gt;. A multipartite state admits generalized Schmidt decomposition if, tracing out any subsystem, the rest is in a fully separable state. 
Thus, in general the entanglement of a pure state is described by the spectra of the reduced density matrices of all bipartite partitions: the state is '''genuinely &lt;math&gt;\; m&lt;/math&gt;-partite entangled''' if and only if all bipartite partitions produce mixed reduced density matrices.&lt;ref name=quantiki/&gt;

=== Mixed states ===
In the multipartite case there is no simple necessary and sufficient condition for separability like the one given by the [[PPT criterion]] for the &lt;math&gt;2\otimes2&lt;/math&gt; and &lt;math&gt;2\otimes3&lt;/math&gt; cases. However, many [[separability criteria]] used in the bipartite setting can be generalized to the multipartite case.&lt;ref name=quantiki/&gt;

====Positive but not completely positive (PnCP) maps and entanglement witnesses====

The characterization of separability in terms of [[Separability criteria|positive but not completely positive maps]] can be naturally generalized from the bipartite case, as follows.&lt;ref name=quantiki/&gt;

Any positive but not completely positive (PnCP) map &lt;math&gt;\; \Lambda_{A_2\ldots A_m}:\mathcal{B}(\mathcal{H}_{A_2\ldots A_m}) \to \mathcal{B}(\mathcal{H}_{A_1})&lt;/math&gt; provides a nontrivial necessary separability criterion in the form:
:&lt;math&gt;\; (I_{A_1}\otimes \Lambda_{A_2\ldots A_m})[\varrho_{A_1\ldots A_m}] \geq 0 ,&lt;/math&gt;
where &lt;math&gt;\; I_{A_1}&lt;/math&gt; is the identity acting on the first subsystem &lt;math&gt;\; \mathcal{H}_{A_1}&lt;/math&gt;.
The state &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; is ''separable'' if and only if the above condition is satisfied for all PnCP maps &lt;math&gt;\; \Lambda_{A_2\ldots A_m}:\mathcal{B}(\mathcal{H}_{A_2\ldots A_m}) \to \mathcal{B}(\mathcal{H}_{A_1})&lt;/math&gt;.&lt;ref name=quantiki/&gt;

The definition of [[entanglement witness]]es and the Choi-Jamiolkowski isomorphism that links PnCP maps to entanglement witnesses in the bipartite case can also be generalized to the multipartite setting.
We therefore get a separability condition from entanglement witnesses for multipartite states: the state &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; is separable if it has non-negative mean value &lt;math&gt;\; Tr(W\varrho_{A_1\ldots A_m}) \geq 0&lt;/math&gt; for all entanglement witnesses &lt;math&gt;W&lt;/math&gt;. Correspondingly, the entanglement of &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; is detected by the witness &lt;math&gt;\; W&lt;/math&gt; if and only if &lt;math&gt;\; Tr(W\varrho_{A_1\ldots A_m}) &lt; 0 &lt;/math&gt;.&lt;ref name=quantiki/&gt;

The above description provides a full characterization of &lt;math&gt;\; m&lt;/math&gt;-separability of  &lt;math&gt;\; m&lt;/math&gt;-partite systems.&lt;ref name=quantiki/&gt;

====Range criterion====
The "range criterion" can also be immediately generalized from the bipartite to the multipartite case.  In the latter case the range of &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; must be spanned by the vectors &lt;math&gt;\; \{|\phi_{A_1}\rangle, \ldots, |\phi_{ A_m}\rangle\}&lt;/math&gt;, while the range of &lt;math&gt;\; \varrho_{A_1\ldots A_m}^{T_{A_{k_1}\ldots A_{k_l}}}&lt;/math&gt; partially transposed with respect to the subset &lt;math&gt;\; \{A_{k_1}\ldots A_{k_l}\} \subset  \{A_1\ldots A_m\}&lt;/math&gt; must be spanned by the products of these vectors where those with indices &lt;math&gt;\; k_1, \ldots, k_l&lt;/math&gt; are complex conjugated. If the state &lt;math&gt;\; \varrho_{A_1\ldots A_m}&lt;/math&gt; is ''separable'', then all such partial transposes must lead to matrices with non-negative spectrum, i.e. all the matrices &lt;math&gt;\; \varrho_{A_1\ldots A_m}^{T_{A_{k_1}\ldots A_{k_l}}}&lt;/math&gt; should be states themselves.&lt;ref name=quantiki/&gt;

====Realignment criteria====
The "realignment criteria" from the bipartite case are generalized to permutational criteria in the multipartite setting: if the state &lt;math&gt;\varrho_{A_1\ldots A_m}&lt;/math&gt; is separable, then the matrix &lt;math&gt;\; [R_\pi(\varrho_{A_1\ldots A_m})]_{i_1j_1,i_2j_2,\ldots,i_nj_n}\equiv\varrho_{\pi(i_1j_1,i_2j_2,\ldots,i_nj_n)}
&lt;/math&gt;, obtained from the original state via permutation &lt;math&gt;\; \pi&lt;/math&gt; of matrix indices in product basis, satisfies &lt;math&gt;\; ||R_\pi(\varrho_{A_1\ldots A_m})]||_{Tr}\leq1&lt;/math&gt;.&lt;ref name=quantiki/&gt;

====Contraction criterion====
Finally, the contraction criterion generalizes immediately from the bipartite to the multipartite case.&lt;ref name=quantiki/&gt;

== Multipartite entanglement measures ==
Many of the axiomatic entanglement measures for bipartite states, such as [[Quantum relative entropy|relative entropy of entanglement]], [[robustness of entanglement]] and [[squashed entanglement]] can be generalized to the multipartite setting.&lt;ref name=quantiki/&gt;
 
The relative entropy of entanglement, for example, can be generalized to the multipartite case by taking a suitable set in place of the set of bipartite separable states. One can take the set of fully separable states, even though with this choice the measure will not distinguish between truly multipartite entanglement and several instances of bipartite entanglement, such as &lt;math&gt;EPR_{AB}\otimes EPR_{CD}&lt;/math&gt;. In order to analyze truly multipartite entanglement one has to consider the set of states containing no more than &lt;math&gt;k&lt;/math&gt;-particle entanglement.&lt;ref name=quantiki/&gt;

In the case of squashed entanglement, its multipartite version can be obtained by simply replacing the [[mutual information]] of the bipartite system with its generalization for multipartite systems, i.e. 
&lt;math&gt;I(A_1 : \ldots : A_N) = S(A_1) + \ldots + S(A_N) - S(A_1 \ldots A_N)&lt;/math&gt;.&lt;ref name=quantiki/&gt;

However, in the multipartite setting many more parameters are needed to describe the entanglement of the states, and therefore many new entanglement measures have been constructed, especially for pure multipartite states.

=== Multipartite entanglement measures for pure states ===
In the multipartite setting there are entanglement measures that simply are functions of sums of bipartite entanglement measures, as, for instance, the '''global entanglement''', which is given by the sum of [[Concurrence (quantum computing)|concurrences]] between one [[qubit]] and all others. For these multipartite entanglement measures the 'monotonicity under [[LOCC]] is simply inherited from the bipartite measures. But there are also entanglement measures that were constructed specifically for multipartite states, as the following:&lt;ref name=quantiki/&gt;

====Tangle====
The first multipartite entanglement measure that is neither a direct generalization nor an easy combination of bipartite measures was introduced by Coffman ''et al.'' and called '''tangle'''.&lt;ref name=quantiki/&gt;

'''Definition [tangle]:'''
:&lt;math&gt;\; \tau(A : B : C) = \tau(A : BC) - \tau(AB) - \tau(AC) ,&lt;/math&gt;
where the &lt;math&gt;\; 2&lt;/math&gt;-tangles on the right-hand-side are the squares of ''[[Concurrence (quantum computing)|concurrence]]''.&lt;ref name=quantiki/&gt;

The tangle measure is permutationally invariant; it vanishes on all states that are separable under any cut; it is nonzero, for example, on the GHZ-state; it can be thought to be zero for states that are  3-entangled (i.e. that are not product with respect to any cut) as, for instance, the [[W-state]]. Moreover, there might be the possibility to obtain a good generalization of the ''tangle'' for multiqubit systems by means of [[hyperdeterminant]].&lt;ref name=quantiki/&gt;

====Schmidt measure====
This was one of the first entanglement measures constructed specifically for multipartite states.&lt;ref name=quantiki/&gt;

'''Definition [Schmidt measure]:''' The minimum of &lt;math&gt;\; \log r&lt;/math&gt;, where &lt;math&gt;\; r&lt;/math&gt; is the number of terms in an expansion of the state in product basis.&lt;ref name=quantiki/&gt;

This measure is zero if and only if the state is fully product; therefore, it cannot distinguish between truly multipartite entanglement and bipartite entanglement, but it may nevertheless be useful in many contexts.&lt;ref name=quantiki/&gt;

====Measures based on normal forms====
This is an interesting class of multipartite entanglement measures obtained in the context of classification of states. Namely, one considers any homogeneous function of the state: if it is invariant under SLOCC (stochastic LOCC) operations with determinant equal to 1, then it is an ''entanglement monotone in the strong sense'', i.e. it satisfies the condition of strong monotonicity.&lt;ref name=quantiki/&gt;

====Measures based on hyperdeterminant====
It was proved by Miyake that [[hyperdeterminant]]s are entanglement monotones and they describe truly multipartite entanglement in the sense that states such as products of &lt;math&gt;EPR&lt;/math&gt;'s have zero entanglement. In particular concurrence and tangle are special cases of hyperdeterminant. Indeed for two qubits concurrence is simply the modulus of the determinant, which is the hyperdeterminant of first order; whereas the tangle is the hyperdeterminant of second order, i.e. a function of tensors with three indices.&lt;ref name=quantiki/&gt;

====Geometric entanglement====
'''Definition [geometric entanglement]:''' 
:&lt;math&gt;\; E_g = 1 - \Lambda^k[\psi] ,&lt;/math&gt;
where &lt;math&gt;\; \Lambda^k[\psi] = sup_{\phi \in S_k}|\langle \psi|\phi\rangle|^2&lt;/math&gt;, with &lt;math&gt;\; S_k&lt;/math&gt; the set of &lt;math&gt;\; k&lt;/math&gt;-separable states. This measure belongs to a family of entanglement measures defined by Barnum and Linden, and it is the multipartite generalization of the [[Shimony measure]].&lt;ref name=quantiki/&gt;

The entanglement can be quantified using a [[geometric measure of entanglement]].

====Localisable entanglement====
This entanglement measure is a generalization of the [[entanglement of assistance]] and was constructed in the context of spin chains. Namely, one chooses two spins and performs LOCC operations that aim at obtaining the largest possible bipartite entanglement between them (measured according to a chosen entanglement measure for two bipartite states).&lt;ref name=quantiki/&gt;

==Sources and notes==
{{Reflist}}

== Further reading ==
*{{cite journal |last1=Horodecki |first1=R. |year=1994 |title=Informationally coherent quantum systems |journal=[[Physics Letters A]] |volume=187 |issue=2 |page=145 |bibcode=1994PhLA..187..145H |doi=10.1016/0375-9601(94)90052-3}}
*{{cite journal |last1=Coffman |first1=V. |last2= Kundu|first2= Joydip|last3= Wootters|first3= William K.|year=2000 |title= Distributed entanglement |journal=[[Physical Review A]] |volume=61 |issue=5 |page=052306 |arxiv=quant-ph/9907047 |bibcode=2000PhRvA..61e2306C |doi=10.1103/PhysRevA.61.052306}}
*{{cite journal |last1=Barnum |first1=H. |last2=Linden |first2=N. |year=2001  |title=Monotones and invariants for multi-particle quantum states |journal=[[Journal of Physics A]] |volume=34 |issue=35 |page=6787 |arxiv=quant-ph/0103155 |bibcode=2001JPhA...34.6787B |doi=10.1088/0305-4470/34/35/305}}
*{{cite journal |last1=Bourennane |first1=M. |last2=Karlsson |first2=A. |last3=Björk |first3=G. |year=2001 |journal=[[Physical Review A]] |volume=64 |issue=2 |page=022306 |bibcode=2001PhRvA..64a2306B |doi=10.1103/PhysRevA.64.012306 |title=Quantum key distribution using multilevel encoding}}
*{{cite journal |last1=Meyer |first1=D. A. |last2=Wallach |first2=N. R. |year=2001 |title=Global entanglement in multiparticle systems |arxiv=quant-ph/0108104 |doi=10.1063/1.1497700 |volume=43 |journal=Journal of Mathematical Physics |pages=4273–4278|bibcode=2002JMP....43.4273M }}
*{{cite journal |last1=Miyake |first1=A. |year=2003 |title=Classification of multipartite entangled states by multidimensional determinants |journal=[[Physical Review A]] |volume=67 |issue=1 |page=012108 |arxiv=quant-ph/0206111 |bibcode=2003PhRvA..67a2108M |doi=10.1103/PhysRevA.67.012108}}
*{{cite journal |last1=Verstraete |first1=F.  |last2=Dehaene |first2=J. |last3=De Moor |first3=B. |year=2003 |title=Normal forms and entanglement measures for multipartite quantum states |journal=[[Physical Review A]] |volume=68 |issue=1 |page=012103 |arxiv=quant-ph/0105090 |bibcode=2003PhRvA..68a2103V |doi=10.1103/PhysRevA.68.012103}}
*{{cite journal |last1=Boileau |first1=J.-C. |last2=Gottesman |first2=D. |last3=Laflamme |first3=R. |last4=Poulin |first4=D. |last5=Spekkens |first5=R. |year=2004 |title=Robust Polarization-Based Quantum Key Distribution over a Collective-Noise Channel |journal=[[Physical Review Letters]] |volume=92 |issue=2 |page=027901 |arxiv=quant-ph/0306199 |bibcode=2004PhRvL..92a7901B |doi=10.1103/PhysRevLett.92.017901 |pmid=14754020}}
*{{cite journal |last1=Miyake |first1=A. |year=2004 |title=Multipartite Entanglement under Stochastic Local Operations and Classical Communication |journal=[[International Journal of Quantum Information]] |volume=2 |issue= |page=65 |arxiv=quant-ph/0401023 |bibcode= 2004quant.ph..1023M |doi=10.1142/s0219749904000080}}
*{{cite journal |last1=Horodecki |first1=R. |last2=Horodecki |first2=P. |last3=Horodecki |first3=M. |last4=Horodecki |first4=K. |year=2009 |title=Quantum entanglement |journal=[[Reviews of Modern Physics]] |volume=81 |issue=2 |pages=865–942 |arxiv=quant-ph/0702225 |bibcode=2009RvMP...81..865H |doi=10.1103/RevModPhys.81.865}}
* {{cite journal |first1=O. |last1=Gühne|first2=G. |last2=Tóth |title=Entanglement detection |journal=[[Physics Reports]] |volume=474 |year=2009 |pages=1–75 |arxiv=0811.2803 |bibcode=2009PhR...474....1G |doi=10.1016/j.physrep.2009.02.004}}

[[Category:Quantum information science]]</text>
      <sha1>ouhi86sac6yveo2thjrp81ob1jjbsft</sha1>
    </revision>
  </page>
  <page>
    <title>NTRUSign</title>
    <ns>0</ns>
    <id>3513327</id>
    <revision>
      <id>858133391</id>
      <parentid>858130951</parentid>
      <timestamp>2018-09-05T08:35:40Z</timestamp>
      <contributor>
        <username>Crypto1451</username>
        <id>34577692</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="5751">'''NTRUSign''', also known as the '''NTRU Signature Algorithm''', is a [[public-key cryptography]] [[digital signature]] algorithm based on the [[GGH signature scheme]]. The original version of NTRUSign was '''Polynomial Authentication and Signature Scheme''' ('''PASS'''), and was published at CrypTEC'99 &lt;ref&gt;{{cite conference | first1 =Jeffrey | last1 = Hoffstein | first2 = Daniel | last2 = Lieman | first3 = Joseph H. | last3 = Silverman | title = Polynomial Rings and Efficient Public Key Authentication | year =1999 | booktitle = International Workshop on Cryptographic Techniques and E-Commerce (CrypTEC'99) | publisher = City University of Hong Kong Press | url =http://www3.ntu.edu.sg/home/wuhj/research/publications/2000_ACISP_PASS.pdf |  }}&lt;/ref&gt;. The improved version of PASS was named as NTRUSign, and was presented at the rump session of [[Asiacrypt]] 2001 and published in peer-reviewed form at the [[RSA Conference]] 2003 &lt;ref&gt;{{cite conference | first1 =Jeffrey | last1 = Hoffstein | first2 = Nick | last2 = Howgrave-Graham | first3 = Jill | last3 = Pipher | first4 = Joseph H. | last4 = Silverman | first5 = William| last5 = Whyte | title = NTRUSign: Digital Signatures Using the NTRU Lattice | year =2003 | series = LNCS | volume = 2612 | booktitle = Topics in Cryptology — CT-RSA 2003 | publisher = Springer | url =http://www.math.brown.edu/~jpipher/NTRUSign_RSA.pdf | pages = 122-140| }}&lt;/ref&gt;. The 2003 publication included parameter recommendations for 80-bit security. A subsequent 2005 publication revised the parameter recommendations for 80-bit security, presented parameters that gave claimed [[Security level|security levels]] of 112, 128, 160, 192 and 256 bits, and described an algorithm to derive parameter sets at any desired security level. NTRU Cryptosystems, Inc. have applied for a patent on the algorithm.

NTRUSign involves mapping a message to a random point in 2''N''-dimensional space, where ''N'' is one of the NTRUSign parameters, and solving the [[closest vector problem]] in a [[Lattice (group)|lattice]] closely related to the [[NTRUEncrypt]] lattice. NTRUSign is claimed to be faster than those algorithms at low security levels, and considerably faster at high security levels. However, analysis had shown that original scheme is insecure and would leak knowledge of private key.&lt;ref name=":0" /&gt;&lt;ref name=":1" /&gt;

A redesigned '''pqNTRUSign''' had been submitted to NIST's [[Post-Quantum Cryptography Standardization]] competition.&lt;ref&gt;{{Cite news|url=https://www.onboardsecurity.com/nist-post-quantum-crypto-submission|title=NIST Post Quantum Crypto Submission|last=|first=|date=|work=OnBoard Security|access-date=2018-03-20|archive-url=|archive-date=|dead-url=|language=en}}&lt;/ref&gt; It is based on "hash-and-sign" (contrasting [[Fiat–Shamir_heuristic|Fiat–Shamir transformation]]) methodology, and claims to achieve smaller signature size. 

NTRUSign is under consideration for standardization by the [[IEEE]] [[IEEE P1363|P1363]] working group.

==Security==
It was demonstrated in 2000 by Wu, Bao, Ye and Deng that the signature of PASS, the original version of NTURSign, can be forged easily without knowing the private key &lt;ref&gt;{{cite conference | first1 =Hongjun | last1 =Wu | first2 =Feng | last2 = Bao | first3 =Dingfeng | last3 = Ye | first4 = Robert H. | last4 = Deng | title = Cryptanalysis of Polynomial Authentication and Signature Scheme | year =2000 | series =LNCS | volume =1841 | booktitle =ACISP 2000 | publisher =Springer | url =http://www3.ntu.edu.sg/home/wuhj/research/publications/2000_ACISP_PASS.pdf | pages =278-288 | }}&lt;/ref&gt;. NTRUSign is not a [[zero-knowledge proof|zero-knowledge]] signature scheme and a transcript of signatures leaks information about the private key, as first observed by Gentry and Szydlo.&lt;ref name=":0"&gt;http://www.szydlo.com/ntru-revised-full02.pdf&lt;/ref&gt; Nguyen and Regev demonstrated in 2006 that for the original unperturbed NTRUSign parameter sets an attacker can recover the private key with as few as 400 signatures.&lt;ref name=":1"&gt;P. Nguyen and O. Regev, "Learning a Parallelepiped: Cryptanalysis of GGH and NTRU Signatures", available from http://www.cims.nyu.edu/~regev/papers/gghattack.pdf&lt;/ref&gt;

The current proposals use ''perturbations'' to increase the transcript length required to recover the private key: the signer displaces the point representing the message by a small secret amount before the signature itself is calculated. NTRU claimed that at least 2&lt;sup&gt;30&lt;/sup&gt; signatures are needed, and probably considerably more, before a transcript of perturbed signatures enabled any useful attack. In 2012 an attack on the scheme with perturbations was presented that required a few thousand signatures for standard security parameters.&lt;ref&gt;{{cite conference | first1 =Léo | last1 =Ducas | first2 =Phong | last2 =Nguyen | title =Learning a Zonotope and More: Cryptanalysis of NTRUSign Countermeasures | year =2012 | series =LNCS | volume =7658 | booktitle =ASIACRYPT 2012 | publisher =Springer | url =https://homepages.cwi.nl/~ducas/NTRUSign_Cryptanalysis/DucasNguyen_Learning.pdf | pages =433-450 | doi =10.1007/978-3-642-34961-4_27 | accessdate =2013-03-07}}&lt;/ref&gt;

The pqNTRUSign claims a 128-bit classical and quantum security for their given parameter set. 

== External links ==
* [http://grouper.ieee.org/groups/1363/lattPK/submissions.html#2005-08 Most recent NTRUSign paper, including parameter sets for multiple security levels]
* [http://sourceforge.net/projects/ntru/ A Java implementation of NTRUSign]

== References ==

&lt;references/&gt;

{{Cryptography navbox | public-key}}

[[Category:Digital signature schemes]]
[[Category:Cryptography]]
[[Category:Post-quantum cryptography]]
[[Category:Lattice-based cryptography]]</text>
      <sha1>bxxz5ra5i77g4zfzqeogurg0ykhjp3u</sha1>
    </revision>
  </page>
  <page>
    <title>Newton–Krylov method</title>
    <ns>0</ns>
    <id>48753670</id>
    <revision>
      <id>840900355</id>
      <parentid>701565024</parentid>
      <timestamp>2018-05-12T21:07:04Z</timestamp>
      <contributor>
        <ip>92.237.93.249</ip>
      </contributor>
      <comment>Setting this article as a stub, as it has no real information about the method, and does not even link to a page about newton's methods or krylov methods.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="719">
{{orphan|date=December 2015}}
'''Newton–Krylov methods''' are [[numerical method]]s for solving non-linear problems using Krylov subspace linear solvers.&lt;ref&gt;{{cite journal|doi=10.1016/j.jcp.2003.08.010|title=Jacobian-free Newton–Krylov methods: a survey of approaches and applications|year=2004|last1=Knoll|first1=D.A.|last2=Keyes|first2=D.E.|journal=Journal of Computational Physics|volume=193|page=357}}&lt;/ref&gt;&lt;ref&gt;{{cite book|last=Kelley|first=C.T.|title=Solving nonlinear equations with Newton's method|edition=1|year=2003|publisher=[[Society for Industrial and Applied Mathematics|SIAM]]}}&lt;/ref&gt;

== References ==
{{reflist}}

{{DEFAULTSORT:Newton-Krylov method}}
[[Category:Numerical analysis]]
{{math-stub}}</text>
      <sha1>6joyh64dyajhbn6z17z3vrjpmdaw39r</sha1>
    </revision>
  </page>
  <page>
    <title>Pocketbook of Mathematical Functions</title>
    <ns>0</ns>
    <id>49766574</id>
    <redirect title="Abramowitz and Stegun" />
    <revision>
      <id>785729791</id>
      <parentid>709896379</parentid>
      <timestamp>2017-06-15T03:16:15Z</timestamp>
      <contributor>
        <username>Tom.Reding</username>
        <id>9784415</id>
      </contributor>
      <minor/>
      <comment>+{{[[Template:Redirect category shell|Redirect category shell]]}} for multiple-{{R}} #Rs using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="356">#REDIRECT [[Abramowitz and Stegun#Pocketbook]]

{{Redirect category shell|1=
{{R to related topic}}
{{R to section}}
}}

[[Category:1984 books]]
[[Category:Handbooks and manuals]]
[[Category:Mathematics books]]
[[Category:Mathematical tables]]
[[Category:Numerical analysis]]
[[Category:Reference works in the public domain]]
[[Category:Special functions]]</text>
      <sha1>ovxw8qcas7m2fw4s83py66e41opmcx3</sha1>
    </revision>
  </page>
  <page>
    <title>Polygon covering</title>
    <ns>0</ns>
    <id>43043289</id>
    <revision>
      <id>829515031</id>
      <parentid>801193794</parentid>
      <timestamp>2018-03-09T02:49:33Z</timestamp>
      <contributor>
        <username>Deacon Vorbis</username>
        <id>29330520</id>
      </contributor>
      <minor/>
      <comment>/* Covering a rectilinear polygon with rectangles */√ glyph -&gt; {{radic}} using [[Project:AWB|AWB]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="16054">A '''covering''' of a [[polygon]] is a set of primitive units (e.g. squares) whose union equals the polygon. A '''polygon covering problem''' is a problem of finding a covering with a smallest number of units for a given polygon. This is an important class of problems in [[computational geometry]]. There are many different polygon covering problems, depending on the type of polygon being covered and on the types of units allowed in the covering. An example polygon covering problem is: given a [[rectilinear polygon]], find a smallest set of squares whose union equals the polygon.

In some scenarios, it is not required to cover the entire polygon but only its edges (this is called ''polygon edge covering'') or its vertices (this is called ''polygon vertex covering'').

In a [[covering problems|covering problem]], the units in the covering are allowed to overlap, as long as their union is exactly equal to the target polygon. This is in contrast to a [[packing problems|packing problem]], in which the units must be disjoint and their union may be smaller than the target polygon, and to a [[polygon partition]] problem, in which the units must be disjoint ''and'' their union must be equal to the target polygon.

A polygon covering problem is a special case of the [[set cover problem]]. In general, the problem of finding a smallest set covering is NP-complete, but for special classes of polygons, a smallest polygon covering can be found in polynomial time.

== Basic concepts ==
A unit ''u'' contained in a polygon ''P'' is called ''maximal'' if it is not contained in any other unit in ''P''. When looking for a polygon covering, it is sufficient to consider maximal units, since every unit which is not maximal can be replaced with a maximal unit containing it without affecting the size of the covering.

A ''covering'' of a polygon ''P'' is a collection of maximal units, possibly overlapping, whose union equals ''P''.

A ''minimal covering'' is a covering that does not contain any other covering (i.e. it is a local minimum).

A ''minimum covering'' is a covering with a smallest number of units (i.e. a global minimum). Every minimum covering is minimal, but not vice versa.

== Covering a rectilinear polygon with squares ==
A [[rectilinear polygon]] can always be covered with a finite number of squares.

For hole-free polygons, a minimum covering by squares can be found in time O(''n''), where ''n'' is the number of vertices of the polygon.&lt;ref name=bybc96&gt;{{Cite journal | doi = 10.1142/S021819599600006X| title = A Linear-Time Algorithm for Covering Simple Polygons with Similar Rectangles| journal = International Journal of Computational Geometry &amp; Applications| volume = 06| pages = 79| year = 1996| last1 = Bar-Yehuda | first1 = R. | last2 = Ben-Hanoch | first2 = E. }}&lt;/ref&gt; The algorithm uses a local optimization approach: it builds the covering by iteratively selecting maximal squares that are essential to the cover (- contain uncovered points not covered by other maximal squares) and then deleting from the polygon the points that become unnecessary (- unneeded to support future squares). Here is a simplified pseudo-code of the algorithm:

*While the polygon ''P'' is not empty:
**Select a [[Rectilinear polygon#Squares in a rectilinear polygon|continuator square]] ''s'' in ''P''.
**If the [[Rectilinear polygon#Squares in a rectilinear polygon|balcony]] of ''s'' is not yet covered, then add ''s'' to the covering.
**Remove the balcony of ''s'' from ''P''.
**If what remains of ''s'' is a one-knob continuator, then remove from ''P'' a certain rectangle adjacent to the knob, taking care to leave a sufficient security distance for future squares.

[[File:Removing holes from a rectilinear polygon.png|thumb]]
For polygons which may contain holes, finding a minimum such covering is [[NP-hard]].&lt;ref name=acko88&gt;{{cite journal|last1=Aupperle|first1=L.J.|last2=Conn|first2=H.E.|last3=Keil|first3=J.M.|last4=O'Rourke|first4=Joseph|title=Covering orthogonal polygons with squares|journal=Proc. 26th Allerton Conf. Commun. Control Comput.|date=1988|pages=97–106}}&lt;/ref&gt; This sharp difference between hole-free and general polygons can be intuitively explained based on the following analogy between maximal squares in a rectilinear polygon and nodes in an undirected graph:&lt;ref name=bybc96/&gt;

* Some maximal squares have a continuous intersection with the boundary of the polygon; when they are removed, the remaining polygon remains connected. Such squares are called "continuators" and are analogous to leaf nodes – nodes with a single edge – that can be removed without disconnecting the graph.
* Other maximal squares are "separators": when they are removed, the polygon splits into two disconnected polygons. They are analogous to nodes with two or more edges that, when removed, leave a disconnected remainder.

In a hole-free rectilinear polygon, all maximal squares are either continuators or separators; thus, such a polygon is analogous to a [[tree graph]]. A general polygon is analogous to a general graph. Just like the [[Vertex cover]] problem is polynomial for tree graphs but NP-hard for general graphs, the square covering problem is linear for hole-free polygons but NP-hard for general polygons.

It is possible to use the linear algorithm to get a 2-approximation – i.e., a covering with at most 2⋅OPT squares, where OPT is the number of squares in a minimum covering:&lt;ref&gt;Prof. Reuven Bar-Yehuda in personal communication&lt;/ref&gt;
* For each hole, find a square ''s'' connecting the hole to the external boundary.
* Cut ''s'' from the polygon, then glue back two overlapping copies of ''s'' (see figure). The resulting polygon is not planar, but it still 2-dimensional, and now it has no holes.
* Now use the original algorithm to find a minimum covering.
The number of squares in the resulting covering is at most OPT+HOLES, where HOLES is the number of holes. It is possible to prove that OPT≥HOLES. Hence the number of squares in the covering is at most 2⋅OPT.

== Covering a rectilinear polygon with rectangles ==
For general rectilinear polygons, the problem of finding a minimum rectangle covering is NP-hard, even when the target polygon is hole-free.&lt;ref name=cr88/&gt; Several partial solutions have been suggested to this problem:

1. In [[orthogonally convex]] polygons, the number of rectangles in a minimum covering is equal to the number of blocks in an [[anti rectangle]], and this fact can be used to build a polynomial time algorithm for finding a minimum covering by rectangles.&lt;ref&gt;{{Cite journal | doi = 10.1137/0602042| title = Covering Regions by Rectangles| journal = SIAM Journal on Algebraic Discrete Methods| volume = 2| issue = 4| pages = 394| year = 1981| last1 = Chaiken | first1 = S. | last2 = Kleitman | first2 = D. J. | last3 = Saks | first3 = M. | last4 = Shearer | first4 = J. }}&lt;/ref&gt;

2. Even when the target polygon is only half-orthogonally convex (i.e. only in the ''y'' direction), a minimum covering by rectangles can be found in time O(''n''&lt;sup&gt;2&lt;/sup&gt;), where ''n'' is the number of vertices of the polygon.&lt;ref&gt;{{Cite book | doi = 10.1145/800057.808678| chapter = An algorithm for constructing regions with rectangles| title = Proceedings of the sixteenth annual ACM symposium on Theory of computing  - STOC '84| pages = 167| year = 1984| last1 = Franzblau | first1 = D. S. | last2 = Kleitman | first2 = D. J. | isbn = 0897911334}}&lt;/ref&gt;

3. An approximation algorithm which gives good empirical results on real-life data is presented by.&lt;ref&gt;{{Cite journal | doi = 10.1145/1187436.1216583| title = Rectangle covers revisited computationally| journal = Journal of Experimental Algorithmics| volume = 11| pages = 2.6| year = 2007| last1 = Heinrich-Litan | first1 = L. | last2 = Lübbecke | first2 = M. E. }}&lt;/ref&gt;

4. For rectilinear polygons which may contain holes, there is an O({{radic|log ''n''}}) factor approximation algorithm.&lt;ref&gt;{{Cite journal | doi = 10.1137/s0097539799358835| title = Covering Rectilinear Polygons with Axis-Parallel Rectangles| journal = SIAM Journal on Computing| volume = 32| issue = 6| pages = 1509| year = 2003| last1 = Kumar | first1 = V. S. A. | last2 = Ramesh | first2 = H.}}&lt;/ref&gt;

== Covering a rectilinear polygon with orthogonally convex polygons ==
For a [[rectilinear polygon]] which is half-orthogonally convex (i.e. only in the ''x'' direction), a minimum covering by [[orthogonally convex]] polygons can be found in time O(''n''^2), where ''n'' is the number of vertices of the polygon. The same is true for a covering by rectilinear [[star polygon]]s.&lt;ref&gt;{{Cite book | doi = 10.1145/10515.10520| chapter = Minimally covering a horizontally convex orthogonal polygon| title = Proceedings of the second annual symposium on Computational geometry  - SCG '86| pages = 43| year = 1986| last1 = Keil | first1 = J. M. | isbn = 0897911946}}&lt;/ref&gt;

The number of orthogonally-convex components in a minimum covering can, in some cases, be found without finding the covering itself, in time O(''n'').&lt;ref&gt;{{Cite journal | doi = 10.1016/0022-0000(89)90043-3| title = Orthogonally convex coverings of orthogonal polygons without holes| journal = Journal of Computer and System Sciences| volume = 39| issue = 2| pages = 166| year = 1989| last1 = Culberson | first1 = J. | last2 = Reckhow | first2 = R. A. }}&lt;/ref&gt;

== Covering a rectilinear polygon with star polygons ==
A rectilinear [[star polygon]] is a polygon ''P'' containing a point ''p'', such that for every point ''q'' in ''P'', there is an [[orthogonally convex]] polygon containing ''p'' and ''q''.

The problem of covering a polygon with star polygons is a variant of the [[art gallery problem]].

The visibility graph for the problem of minimally covering hole-free [[rectilinear polygon]]s with star polygons is a [[perfect graph]]. This perfectness property implies a polynomial algorithm for finding a minimum covering of any rectilinear polygon with rectilinear star polygons.&lt;ref&gt;{{Cite journal | doi = 10.1016/0022-0000(90)90017-f| title = Covering orthogonal polygons with star polygons: The perfect graph approach| journal = Journal of Computer and System Sciences| volume = 40| pages = 19| year = 1990| last1 = Motwani | first1 = R. | last2 = Raghunathan | first2 = A. | last3 = Saran | first3 = H. }}&lt;/ref&gt;

== Covering a polygon without acute angles with squares or rectangles ==
The most general class of polygons for which coverings by squares or rectangles can be found is the class of polygons without acute interior angles. This is because an acute angle cannot be covered by a finite number of rectangles. This problem is NP-hard, but several approximation algorithms exist.&lt;ref&gt;{{Cite book | doi = 10.1007/3-540-63248-4_3| chapter = Approximation algorithms for covering polygons with squares and similar problems| title = Randomization and Approximation Techniques in Computer Science| volume = 1269| pages = 27| series = Lecture Notes in Computer Science| year = 1997| last1 = Levcopoulos | first1 = C. | last2 = Gudmundsson | first2 = J. | isbn = 978-3-540-63248-1}}, Grazyna Zwozniak, 1998&lt;/ref&gt;

== Covering a polygon with rectangles of a finite family ==
In some cases, a polygon has to be covered not with arbitrary rectangles but with rectangles from a finite family.&lt;ref&gt;{{Cite journal | doi = 10.1007/s10589-009-9258-1| title = Covering a polygonal region by rectangles| journal = Computational Optimization and Applications| volume = 48| issue = 3| pages = 675| year = 2009| last1 = Stoyan | first1 = Y. G.| last2 = Romanova | first2 = T.| last3 = Scheithauer | first3 = G.| last4 = Krivulya | first4 = A.}}&lt;/ref&gt;

== Covering a polygon with triangles ==
Finding the smallest set of triangles covering a given polygon is NP-hard. It is also hard to approximate - every polynomial-time algorithm might find a covering with size (1+1/19151) times the minimal covering.&lt;ref name=c11&gt;{{Cite book | doi = 10.1007/978-3-642-22300-6_20| chapter = Beyond Triangulation: Covering Polygons with Triangles| title = Algorithms and Data Structures| volume = 6844| pages = 231| series = Lecture Notes in Computer Science| year = 2011| last1 = Christ | first1 = T. | isbn = 978-3-642-22299-3}}&lt;/ref&gt;

If the polygon is in [[general position]] (i.e. no two edges are collinear), then every triangle can cover at most 3 polygon edges. Hence every [[Polygon triangulation]] is a 3-approximation.

If the covering is restricted to triangles whose vertices are vertices of the polygon (i.e. [[Steiner point (computational geometry)|Steiner points]] are not allowed), then the problem is NP-complete.

If Steiner points are not allowed ''and'' the polygon is in [[general position]] (i.e. no two edges are collinear), then every minimal covering without Steiner points is also a minimal partitioning of the polygon to triangles (i.e., the triangles in the minimal covering to not overlap).&lt;ref name=c11/&gt; Hence, the minimum covering problem is identical to the [[Polygon triangulation]] problem, which can be solved in time O(''n''log''n'').   Note that if we drop the general position assumption, there are polygons in which the triangles in the optimal covering overlap. Think of the [[Star of David]] for example.

The problem of covering only the boundary of a polygon with triangles is NP-complete, but there is an efficient 2-approximation.&lt;ref name=c11/&gt;

== Covering a polygon with convex polygons ==

Covering a polygon (which may contain holes) with convex polygons is NP-hard.&lt;ref name=os83/&gt; There is an O(log''n'') approximation algorithm.&lt;ref name=ew01&gt;{{Cite book | doi = 10.1007/3-540-44676-1_28| chapter = An Approximation Algorithm for Minimum Convex Cover with Logarithmic Performance Guarantee| title = Algorithms — ESA 2001| volume = 2161| pages = 333| series = Lecture Notes in Computer Science| year = 2001| last1 = Eidenbenz | first1 = S. | last2 = Widmayer | first2 = P. | isbn = 978-3-540-42493-2}}&lt;/ref&gt;

Covering a polygon with convex polygons is NP-hard even when the target polygon is [[simple polygon|hole-free]].&lt;ref name=cr88&gt;{{Cite book | doi = 10.1109/sfcs.1988.21976| chapter = Covering polygons is hard| title = [Proceedings 1988] 29th Annual Symposium on Foundations of Computer Science| pages = 601| year = 1988| last1 = Culberson | first1 = J. C. | last2 = Reckhow | first2 = R. A. | isbn = 0-8186-0877-3}}.&lt;/ref&gt; It is also [[APX-hard]].&lt;ref name=ew01/&gt; The problem is NP-complete when the covering must not introduce new vertices (i.e. [[Steiner tree problem|Steiner point]]s are not allowed).&lt;ref name=c11/&gt;

== Covering a polygon with star polygons ==
{{Main|Art gallery problem}}

Covering a polygon (which may contain holes) with [[star polygon]]s is NP-hard.&lt;ref name=os83/&gt;

Covering a general (non-rectilinear) polygon with star polygons is NP-hard even when the target polygon is hole-free.&lt;ref&gt;{{cite book|last1=Aggarwal|first1=Alok|title=The art gallery theorem: its variations, applications and algorithmic aspects|date=1984|publisher=Department of Electrical Engineering and Computer Science|location=The Johns Hopkins University|url=http://dl.acm.org/citation.cfm?id=911725}}&lt;/ref&gt;

== Other combinations ==

Covering a polygon (which may contain holes) with  [[spiral]]s is NP-hard.&lt;ref name=os83&gt;{{Cite journal | doi = 10.1109/tit.1983.1056648| title = Some NP-hard polygon decomposition problems| journal = IEEE Transactions on Information Theory| volume = 29| issue = 2| pages = 181| year = 1983| last1 = O'Rourke | first1 = J.| last2 = Supowit | first2 = K.}}&lt;/ref&gt;

Covering a polygon with [[Pseudotriangle]]s has also been studied.

Additional information can be found in.&lt;ref&gt;{{Cite book | doi = 10.1016/B978-044482537-7/50012-7| chapter = Polygon Decomposition| title = Handbook of Computational Geometry| pages = 491| year = 2000| last1 = Keil | first1 = J. M. | isbn = 9780444825377}}&lt;/ref&gt;

== See also ==
* [[Covering problems]]
* [[Art gallery problem]]
* [[Tessellation]]

==References==
{{reflist}}

[[Category:Computational geometry]]
[[Category:Polygons]]</text>
      <sha1>iq67ue3l554orzfy57vex9hlowvbfyb</sha1>
    </revision>
  </page>
  <page>
    <title>Principles of Mathematical Logic</title>
    <ns>0</ns>
    <id>2134047</id>
    <revision>
      <id>857481085</id>
      <parentid>787541322</parentid>
      <timestamp>2018-08-31T23:23:34Z</timestamp>
      <contributor>
        <username>Rgdboer</username>
        <id>92899</id>
      </contributor>
      <minor/>
      <comment>/* References */ ch cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3333">{{Italic title}}
'''''Principles of Mathematical Logic''''' is the 1950&lt;ref&gt;{{cite journal|author=Curry, Haskell B.|authorlink=Haskell Curry|title=Review: ''Grundzüge der theoretischen Logik'' (3rd edition)|journal=Bull. Amer. Math. Soc.|year=1953|volume=59|issue=3|pages=263–267|url=http://www.ams.org/journals/bull/1953-59-03/S0002-9904-1953-09701-4/S0002-9904-1953-09701-4.pdf|doi=10.1090/s0002-9904-1953-09701-4}} The translation of the 1938 2nd German edition into English was published in 1950, while the 3rd German edition was published in 1949.&lt;/ref&gt; American translation of the 1938 second edition&lt;ref&gt;{{cite journal|author=Rosser, Barkley|authorlink=J. Barkley Rosser|title=Review: ''Grundzüge der theoretischen Logik'' (2nd edition)|journal=Bull. Amer. Math. Soc.|year=1938|volume=44|issue=7|pages=474–475|url=http://www.ams.org/journals/bull/1938-44-07/S0002-9904-1938-06760-2/S0002-9904-1938-06760-2.pdf|doi=10.1090/s0002-9904-1938-06760-2}}&lt;/ref&gt; of [[David Hilbert]]'s and [[Wilhelm Ackermann]]'s classic text ''Grundzüge der theoretischen Logik'',&lt;ref&gt;{{cite journal|author=Langford, C. H|authorlink=Cooper Harold Langford|title=Review of ''Grundzüge der theoretischen Logik'' by D. Hilbert and W. Ackermann|journal=Bull. Amer. Math. Soc.|year=1930|volume=36|issue=1|pages=22–25|url=http://www.ams.org/bull/1930-36-01/S0002-9904-1930-04859-4/S0002-9904-1930-04859-4.pdf|doi=10.1090/s0002-9904-1930-04859-4}}&lt;/ref&gt;  on elementary mathematical logic. The 1928 first edition thereof is considered the first elementary text clearly grounded in the formalism now known as [[first-order logic]] (FOL). Hilbert and Ackermann also formalized FOL in a way that subsequently achieved canonical status. FOL is now a core formalism of mathematical logic, and is presupposed by contemporary treatments of [[Peano arithmetic]] and nearly all treatments of [[axiomatic set theory]].

The 1928 edition included a clear statement of the [[Entscheidungsproblem]] ([[decision problem]]) for FOL, and also asked whether that logic was [[Gödel's completeness theorem|complete]] (i.e., whether all semantic truths of FOL were theorems derivable from the FOL axioms and rules). The former problem was answered in the negative first by [[Alonzo Church]] and independently by [[Alan Turing]] in 1936.  The latter was answered affirmatively by [[Kurt Gödel]] in 1929.

The text also touched on [[set theory]] and [[relational algebra]] as ways of going beyond FOL. Contemporary notation for logic owes more to this text than it does to the notation of ''[[Principia Mathematica]]'', long popular in the English speaking world.

==Notes==
{{reflist}}

==References==
* [[David Hilbert]] and [[Wilhelm Ackermann]] (1928). ''Grundzüge der theoretischen Logik'' (''Principles of Mathematical Logic''). Springer-Verlag, {{ISBN|0-8218-2024-9}}. This text went into four subsequent German editions, the last in 1972.
* Hendricks, Neuhaus, Petersen, Scheffler and Wansing (eds.) (2004).  ''First-order logic revisited''.  Logos Verlag, {{ISBN|3-8325-0475-3}}.  Proceedings of a workshop, FOL-75, commemorating the 75th anniversary of the publication of Hilbert and Ackermann (1928).


{{logic-stub}}

[[Category:1928 books]]
[[Category:1938 books]]
[[Category:Logic books]]
[[Category:Mathematics textbooks]]
[[Category:History of logic]]</text>
      <sha1>3p5lcghrrrvdm9dbkyhp74q4oquqaem</sha1>
    </revision>
  </page>
  <page>
    <title>Privilege Management Infrastructure</title>
    <ns>0</ns>
    <id>16089583</id>
    <revision>
      <id>854423058</id>
      <parentid>776499901</parentid>
      <timestamp>2018-08-11T07:10:52Z</timestamp>
      <contributor>
        <ip>140.168.79.1</ip>
      </contributor>
      <comment>refine statement, X.509 as a general set of standards was implemented prior to the PERMIS project, however, PERMIS was the first implementation of an X.509-compliant PMI</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4224">'''Privilege Management''' is the process of managing user authorisations based on the ITU-T Recommendation [[X.509]]. The 2001 edition of X.509 &lt;ref&gt;ISO 9594-8/ITU-T Rec. X.509 (2001) The  Directory:  Public-key and attribute certificate frameworks&lt;/ref&gt; specifies most (but not all) of the components of a '''''Privilege Management Infrastructure''''' (PMI), based on X.509 [[attribute certificate]]s (ACs). Later editions of X.509 (2005 and 2009) have added further components to the PMI, including a delegation service (in 2005 &lt;ref&gt;ISO 9594-8/ITU-T Rec. X.509 (2005) The  Directory:  Public-key and attribute certificate frameworks&lt;/ref&gt;) and interdomain authorisation (in the 2009 edition &lt;ref&gt;ISO 9594-8/ITU-T Rec. X.509 (2009)&lt;/ref&gt;).

Privilege management infrastructures (PMIs) are to authorisation what [[public key infrastructure]]s (PKIs) are to authentication. PMIs use attribute certificates (ACs) to hold user privileges, in the form of attributes, instead of [[public key certificate]]s (PKCs) to hold public keys. PMIs have Sources of Authority (SoAs) and Attribute Authorities (AAs) that issue ACs to users, instead of [[certification authorities]] (CAs) that issue PKCs to users. Usually PMIs rely on an underlying PKI, since ACs have to be digitally signed by the issuing AA, and the PKI is used to validate the AA's signature.

An X.509 AC is a generalisation of the well known X.509 public key certificate (PKC), in which the public key of the PKC has been replaced by any set of attributes of the certificate holder (or subject). Therefore, one could in theory use X.509 ACs to hold a user's public key as well as any other attribute of the user. (In a similar vein, X.509 PKCs can also be used to hold privilege attributes of the subject, by adding them to the subject directory attributes extension of an X.509 PKC). However, the life cycle of public keys and user privileges are usually very different, and therefore it isn't usually a good idea to combine both of them in the same certificate. Similarly, the  authority that assigns a privilege to someone is usually different from the authority that certifies someone's public key. Therefore, it isn't usually a good idea to combine the functions of the SoA/AA and the CA in the same trusted authority. PMIs allow privileges and authorisations to be managed separately from keys and authentication.

The first open source implementation of an X.509 PMI was built with funding under the EC [[PERMIS]] project, and the software is available from [http://sec.cs.kent.ac.uk/permis/ here]. A description of the implementation can be found in.&lt;ref&gt;D.W.Chadwick, A. Otenko “The PERMIS X.509 Role Based Privilege Management Infrastructure”. Future Generation Computer Systems, 936 (2002) 1–13, December 2002. Elsevier Science BV.&lt;/ref&gt;&lt;ref&gt;David W. Chadwick, GansenZhao, Sassa Otenko, Romain Laborde, Linying Su and Tuan Anh Nguyen. “PERMIS: a modular authorization infrastructure”. Concurrency And Computation: Practice And Experience. Volume 20, Issue 11, Pages 1341-1357, 10&lt;/ref&gt;

X.509 ACs and PMIs are used today in Grids (see [[Grid computing]]), to assign privileges to users, and to carry the privileges around the Grid. In the most popular Grid privilege management system today, called [[VOMS]],&lt;ref&gt;Alfieri, R., Cecchini, R., Ciaschini, V., Dell'Agnello, L., Frohner, A., Lorentey, K., Spataro, F., “From gridmap-file to VOMS: managing authorization in a Grid environment”. Future Generation Computer Systems. Vol. 21, no. 4, pp. 549-558. Apr. 2005&lt;/ref&gt; user privileges, in the shape of VO memberships and roles, are placed inside an X.509 AC by the VOMS server, signed by the VOMS server, and then embedded in the user's X.509 proxy certificate for carrying around the Grid.

Because of the rise in popularity of [[XML]] [[SOAP]] based services, [[Security Assertion Markup Language|SAML]] attribute assertions are now more popular than X.509 ACs for transporting user attributes. However, they both have similar functionality, which is to strongly bind a set of privilege attributes to a user.

== References ==
{{reflist|30em}}

[[Category:Computer security]]
[[Category:Cryptography]]
[[Category:Communications protocols]]</text>
      <sha1>iiia7e3mw74arrydcal40dpnig1flyo</sha1>
    </revision>
  </page>
  <page>
    <title>Pyrrho's lemma</title>
    <ns>0</ns>
    <id>32538447</id>
    <revision>
      <id>750250700</id>
      <parentid>648183062</parentid>
      <timestamp>2016-11-18T16:46:52Z</timestamp>
      <contributor>
        <username>Marcocapelle</username>
        <id>14965160</id>
      </contributor>
      <comment>removed parent category of [[Category:Regression analysis]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="1485">In statistics, '''Pyrrho's lemma''' is the result that if one adds just one extra variable as a regressor from a suitable set to a linear regression model, one can get any desired outcome in terms of the coefficients (signs and sizes), as well as predictions, the R-squared, the t-statistics, prediction- and confidence-intervals. The argument for the coefficients was advanced by Herman Wold and Lars Juréen&lt;ref&gt;Wold, Herman and L. Juréen (1953) ''Demand Analysis: A Study in Econometrics'', John Wiley &amp; Sons (2nd Ed)&lt;/ref&gt; but named, extended to include the other statistics and explained more fully by Theo Dijkstra.&lt;ref&gt;{{cite journal | last1 = Dijkstra | first1 = Theo K | year = 1995 | title = Pyrrho's lemma, or have it your way | url = | journal = Metrika | volume = 42 | issue = 1| pages = 119–125 | doi = 10.1007/BF01894292 }}&lt;/ref&gt; Dijkstra named it after the sceptic philosopher Pyrrho and concludes his article by noting that this lemma provides "some ground for a wide-spread scepticism concerning products of extensive datamining". One can only prove that a model 'works' by testing it on data different from the data that gave it birth. &lt;ref&gt;(Dijkstra, p. 122)&lt;/ref&gt;

The result has been discussed in the context of [[econometrics]].&lt;ref&gt;[[David Forbes Hendry|Hendry, David F.]] (1995) ''Dynamic Econometrics'', [[Oxford University Press]]&lt;/ref&gt;

== References ==

{{Reflist}}

[[Category:Statistical theorems]]
[[Category:Regression analysis]]
[[Category:Lemmas]]</text>
      <sha1>1zyo5yjuhn6v32xhps5vp5e06918c11</sha1>
    </revision>
  </page>
  <page>
    <title>Radon–Riesz property</title>
    <ns>0</ns>
    <id>20894986</id>
    <revision>
      <id>847551879</id>
      <parentid>842301444</parentid>
      <timestamp>2018-06-26T04:49:40Z</timestamp>
      <contributor>
        <username>Kontribuanto</username>
        <id>33515312</id>
      </contributor>
      <minor/>
      <comment>fixed an obvious typo</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="3254">The '''Radon–Riesz property''' is a mathematical property for [[normed space]]s that helps ensure [[limit of a sequence|convergence]] in norm. Given two assumptions (essentially weak convergence and continuity of norm), we would like to ensure convergence in the [[norm topology]].

==Definition==
Suppose that (''X'', ||·||) is a normed space. We say that ''X'' has the ''Radon–Riesz property'' (or that ''X'' is a ''Radon–Riesz space'') if whenever &lt;math&gt;(x_{n})&lt;/math&gt; is a sequence in the space and &lt;math&gt;x&lt;/math&gt; is a member of ''X'' such that &lt;math&gt;(x_{n})&lt;/math&gt; [[weak topology|converges weakly]] to &lt;math&gt;x&lt;/math&gt; and &lt;math&gt;\lim_{n\to\infty} \Vert x_n \Vert = \Vert x\Vert &lt;/math&gt;, then &lt;math&gt;(x_{n})&lt;/math&gt; converges to &lt;math&gt;x&lt;/math&gt; in norm; that is, &lt;math&gt;\lim_{n\to\infty} \Vert x_n - x\Vert = 0 &lt;/math&gt;.

==Other names==

Although it would appear that [[Johann Radon]] was one of the first to make significant use of this property in 1913, [[Mikhail Kadets|M. I. Kadets]] and V. L. Klee also used versions of the Radon–Riesz property to make advancements in [[Banach space]] theory in the late 1920s. It is common for the Radon–Riesz property to also be referred to as the '''Kadets–Klee property''' or '''property (H)'''. According to [[Robert Megginson]], the letter H does not stand for anything. It was simply referred to as property (H) in a list of properties for normed spaces that starts with (A) and ends with (H). This list was given by K. Fan and I. Glicksberg (Observe that the definition of (H) given by Fan and Glicksberg includes additionally the rotundity of the norm, so it does not coincide with the Radon-Riesz property itself). The "Riesz" part of the name refers to [[Frigyes Riesz]]. He also made some use of this property in the 1920s.

It is important to know that the name "Kadets-Klee property" is used sometimes to speak about the coincidence of the weak topologies and norm topologies in the unit sphere of the normed space.

==Examples==
1. Every real Hilbert space is a Radon–Riesz space. Indeed, suppose that ''H'' is a real [[Hilbert space]] and that &lt;math&gt; (x_{n}) &lt;/math&gt; is a sequence in ''H'' converging weakly to a member &lt;math&gt; x &lt;/math&gt; of ''H''. Using the two assumptions on the sequence and the fact that
:&lt;math&gt;\langle x_{n} - x, x_{n} - x\rangle = \langle x_{n} , x_{n} \rangle - \langle x_{n} ,  x\rangle  - \langle  x, x_{n} \rangle + \langle  x,  x\rangle, &lt;/math&gt;
and letting ''n'' tend to infinity, we see that 
:&lt;math&gt;\lim_{n\to\infty}{\langle x_{n} - x, x_{n} - x\rangle} = 0. &lt;/math&gt;
Thus ''H'' is a Radon–Riesz space.

2. Every [[uniformly convex Banach space]] is a Radon-Riesz space. See Section 3.7 of [[Haim Brezis]]' Functional analysis.

==See also==
* [[Johann Radon]]
* [[Frigyes Riesz]]
* [[Hilbert space]] or [[Banach space]] theory
* [[Weak topology]]
* [[Normed space]]
* [[Functional analysis]]
* [[Schur's property]]

==References==
* {{Citation
  | first = Robert E. | last = Megginson  | authorlink = Robert Megginson
  | title = An Introduction to Banach Space Theory
  | place = New York Berlin Heidelberg
  | publisher = Springer-Verlag
  | year = 1998
  | isbn = 0-387-98431-3 }}

{{DEFAULTSORT:Radon-Riesz property}}
[[Category:Functional analysis]]</text>
      <sha1>s337gu94n72buj5cysiscizietyuetx</sha1>
    </revision>
  </page>
  <page>
    <title>Scale-free ideal gas</title>
    <ns>0</ns>
    <id>24474524</id>
    <revision>
      <id>617278642</id>
      <parentid>569085620</parentid>
      <timestamp>2014-07-17T06:36:47Z</timestamp>
      <contributor>
        <username>Bibcode Bot</username>
        <id>14394459</id>
      </contributor>
      <minor/>
      <comment>Adding 2 [[arXiv|arxiv eprint(s)]], 2 [[bibcode|bibcode(s)]] and 0 [[digital object identifier|doi(s)]]. Did it miss something? Report bugs, errors, and suggestions at [[User talk:Bibcode Bot]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2761">{{category unsourced|Information theory|date=July 2012}}

The '''scale-free ideal gas (SFIG)''' is a physical model assuming a collection of non-interacting elements with an [[stochastic]] proportional growth. It is the  [[Scale invariance|scale-invariant]] version of an [[ideal gas]]. Some cases of city-population, electoral results and cites to scientific journals can be approximately considered scale-free ideal gases.&lt;ref&gt;{{cite journal |first=A. |last=Hernando |first2=C. |last2=Vesperinas |first3=A. |last3=Plastino |title=Fisher information and the thermodynamics of scale-invariant systems |journal=Physica A: Statistical Mechanics and its Applications |volume=389 |issue=3 |year=2010 |pages=490–498 |doi=10.1016/j.physa.2009.09.054 |arxiv = 0908.0504 |bibcode = 2010PhyA..389..490H }}&lt;/ref&gt;

In a one-dimensional discrete model with size-parameter ''k'', where ''k''&lt;sub&gt;1&lt;/sub&gt; and ''k''&lt;sub&gt;''M''&lt;/sub&gt; are the minimum and maximum allowed sizes respectively, and ''v''&amp;nbsp;=&amp;nbsp;''dk''/''dt'' is the growth, the bulk [[probability density function]] ''F''(''k'',&amp;nbsp;''v'') of a scale-free ideal gas follows

: &lt;math&gt;
F(k,v)=\frac{N}{\Omega k^2}\frac{\exp\left[-(v/k-\overline{w})^2/2\sigma_w^2\right]}{\sqrt{2\pi}\sigma_w},
&lt;/math&gt;

where ''N'' is the total number of elements, Ω&amp;nbsp;=&amp;nbsp;ln&amp;nbsp;''k''&lt;sub&gt;1&lt;/sub&gt;/''k''&lt;sub&gt;''M''&lt;/sub&gt; is the logaritmic "volume" of the system, &lt;math&gt;\overline{w}=\langle v/k \rangle&lt;/math&gt; is the mean relative growth and &lt;math&gt;\sigma_w&lt;/math&gt; is the standard deviation of the relative growth. The [[entropy]] equation of state is

: &lt;math&gt;S=N\kappa\left\{\ln\frac{\Omega}{N}\frac{\sqrt{2\pi}\sigma_w}{H'}+\frac{3}{2}\right\},
&lt;/math&gt;

where &lt;math&gt;\kappa&lt;/math&gt; is a constant that accounts for dimensionality and &lt;math&gt;H'=1/M\Delta\tau&lt;/math&gt; is the elementary volume in phase space, with &lt;math&gt;\Delta\tau&lt;/math&gt; the elementary time and ''M'' the total number of allowed discrete sizes. This expression has the same form as the one-dimensional ideal gas, changing the thermodynamical variables (''N'',&amp;nbsp;''V'',&amp;nbsp;''T'') by (''N'',&amp;nbsp;Ω,''σ''&lt;sub&gt;''w''&lt;/sub&gt;).

[[Zipf's law]] may emerge in the external limits of the density since it is a special regime of scale-free ideal gases.&lt;ref&gt;{{cite journal |first=A. |last=Hernando |first2=D. |last2=Puigdomènech |first3=D. |last3=Villuendas |first4=C. |last4=Vesperinas |first5=A. |last5=Plastino |title=Zipf's law from a Fisher variational-principle |journal=Physics Letters A |volume=374 |issue=1 |year=2009 |pages=18–21 |doi=10.1016/j.physleta.2009.10.027 |arxiv = 0908.0501 |bibcode = 2009PhLA..374...18H }}&lt;/ref&gt;

== References ==
{{Reflist}}

[[Category:Information theory]]
[[Category:Thermodynamics]]
[[Category:Scale-invariant systems]]</text>
      <sha1>pntgewdja0ent0gr9h046x9jvxc57hl</sha1>
    </revision>
  </page>
  <page>
    <title>Second-order arithmetic</title>
    <ns>0</ns>
    <id>3542454</id>
    <revision>
      <id>869632176</id>
      <parentid>867686254</parentid>
      <timestamp>2018-11-19T20:34:27Z</timestamp>
      <contributor>
        <ip>76.127.225.26</ip>
      </contributor>
      <comment>/* Induction and comprehension schema */  Was missing a close parenthesis on the induction axiom</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="24061">In [[mathematical logic]], '''second-order arithmetic''' is a collection of [[axiom]]atic systems that formalize the [[natural number]]s and their subsets. It is an alternative to [[axiomatic set theory]] as a [[foundation of mathematics|foundation]] for much, but not all, of mathematics. A precursor to second-order arithmetic, involving third-order parameters, was introduced by [[David Hilbert]] and [[Paul Bernays]] in their book [[Grundlagen der Mathematik]]. The standard axiomatization of second-order arithmetic is denoted Z&lt;sub&gt;2&lt;/sub&gt;.

Second-order arithmetic includes, but is significantly stronger than, its [[first order logic|first-order]] counterpart [[Peano arithmetic]]. Unlike Peano arithmetic, second-order arithmetic allows [[Quantification (logic)|quantification]] over sets of natural numbers as well as numbers themselves. Because [[real number]]s can be represented as ([[infinite set|infinite]]) sets of natural numbers in well-known ways, and because second order arithmetic allows quantification over such sets, it is possible to formalize the [[real number]]s in second-order arithmetic. For this reason, second-order arithmetic is sometimes called “[[mathematical analysis|analysis]]” (Sieg 2013, p.&amp;nbsp;291).

Second-order arithmetic can also be seen as a weak version of [[set theory]] in which every element is either a natural number or a set of natural numbers. Although it is much weaker than [[Zermelo–Fraenkel set theory]], second-order arithmetic can prove essentially all of the results of [[classical mathematics]] expressible in its language.

A '''subsystem of second-order arithmetic''' is a theory in the language of second-order arithmetic each axiom of which is a theorem of full second-order arithmetic (Z&lt;sub&gt;2&lt;/sub&gt;). Such subsystems are essential to [[reverse mathematics]], a research program investigating how much of classical mathematics can be derived in certain weak subsystems of varying strength. Much of core mathematics can be formalized in these weak subsystems, some of which are defined below. Reverse mathematics also clarifies the extent and manner in which classical mathematics is [[nonconstructive]].

==Definition==

===Syntax===
The language of second-order arithmetic is [[Many-sorted logic|two-sorted]]. The first sort of [[Term (mathematics)|terms]] and in particular [[Variable (mathematics)|variables]], usually denoted by lower case letters, consists of [[individual]]s, whose intended interpretation is as natural numbers. The other sort of variables, variously called “set variables,” “class variables,” or even “predicates” are usually denoted by upper-case letters. They refer to classes/predicates/properties of individuals, and so can be thought of as sets of natural numbers. Both individuals and set variables can be quantified universally or existentially. A formula with no [[bound variable|bound]] set variables (that is, no quantifiers over set variables) is called '''arithmetical'''. An arithmetical formula may have free set variables and bound individual variables.

Individual terms are formed from the constant 0, the unary function ''S'' (the ''[[successor function]]''), and the binary operations + and &lt;math&gt; \cdot &lt;/math&gt; (addition and multiplication). The successor function adds 1 to its input. The relations = (equality) and &lt; (comparison of natural numbers) relate two individuals, whereas the relation ∈ (membership) relates an individual and a set (or class). Thus in notation the language of second-order arithmetic is given by the signature &lt;math&gt;\mathcal{L}=\{0,S,+,\cdot,=,&lt;,\in\}&lt;/math&gt;.

For example, &lt;math&gt;\forall n (n\in X \rightarrow Sn \in X)&lt;/math&gt;, is a [[well-formed formula]] of second-order arithmetic that is arithmetical, has one free set variable ''X'' and one bound individual variable ''n'' (but no bound set variables, as is required of an arithmetical formula)&amp;mdash;whereas &lt;math&gt;\exists X \forall n(n\in X \leftrightarrow n &lt; SSSSSS0\cdot SSSSSSS0)&lt;/math&gt; is a well-formed formula that is not arithmetical, having one bound set variable ''X'' and one bound individual variable ''n''.

===Semantics===
Several different interpretations of the quantifiers are possible.    If second-order arithmetic is studied using the full semantics of [[second-order logic]] then the set quantifiers range over all subsets of the range of the number variables.  If second-order arithmetic is formalized using the semantics of [[first-order logic]] (Henkin semantics) then any model includes a domain for the set variables to range over, and this domain may be a proper subset of the full powerset of the domain of number variables (Shapiro 1991, pp.&amp;nbsp;74&amp;ndash;75).

===Axioms===

====Basic====
The following axioms are known as the ''basic axioms'', or sometimes the ''Robinson axioms.'' The resulting [[first-order theory]], known as [[Robinson arithmetic]], is essentially [[Peano arithmetic]] without induction. The [[domain of discourse]] for the  [[Quantification (logic)|quantified variable]]s is the [[natural number]]s, collectively denoted by '''N''', and including the distinguished member &lt;math&gt;\ 0&lt;/math&gt;, called "[[zero]]."

The primitive functions are the unary [[successor function]], denoted by [[prefix]] &lt;math&gt;\ S,&lt;/math&gt;, and two [[binary operation]]s, [[addition]] and [[multiplication]], denoted by [[infix]] "+" and "&lt;math&gt; \cdot&lt;/math&gt;", respectively. There is also a primitive [[binary relation]] called [[order relation|order]], denoted by infix "&lt;".

Axioms governing the [[successor function]] and [[zero]]:
:1. &lt;math&gt;\forall m [Sm=0 \rightarrow \bot].&lt;/math&gt; (“the successor of a natural number is never zero”)
:2. &lt;math&gt;\forall m \forall n [Sm=Sn \rightarrow m=n].&lt;/math&gt; (“the successor function is [[Injective function|injective]]”)
:3. &lt;math&gt;\forall n [0=n \lor \exists m [Sm=n] ].&lt;/math&gt; (“every natural number is zero or a successor”)

[[Addition]] defined [[recursion|recursively]]:
:4. &lt;math&gt;\forall m [m+0=m].&lt;/math&gt;
:5. &lt;math&gt;\forall m \forall n [m+Sn = S(m+n)].&lt;/math&gt;

[[Multiplication]] defined recursively:
:6. &lt;math&gt;\forall m [m\cdot 0 = 0].&lt;/math&gt;
:7. &lt;math&gt;\forall m \forall n [m \cdot Sn = (m\cdot n)+m].&lt;/math&gt;

Axioms governing the [[order relation]] "&lt;":
:8. &lt;math&gt;\forall m [m&lt;0 \rightarrow \bot].&lt;/math&gt; (“no natural number is smaller than zero”)
:9. &lt;math&gt;\forall n \forall m [m&lt;Sn \leftrightarrow (m&lt;n \lor m=n)].&lt;/math&gt;
:10. &lt;math&gt;\forall n [0=n \lor 0&lt;n].&lt;/math&gt; (“every natural number is zero or bigger than zero”)
:11. &lt;math&gt;\forall m \forall n [(Sm&lt;n \lor Sm=n) \leftrightarrow m&lt;n].&lt;/math&gt;

These axioms are all [[first order logic|first order statements]]. That is, all variables range over the [[natural number]]s and not [[set theory|sets]] thereof, a fact even stronger than their being arithmetical. Moreover, there is but one [[existential quantifier]], in axiom 3. Axioms 1 and 2, together with an [[Peano axioms|axiom schema of induction]] make up the usual [[Peano axioms|Peano-Dedekind]] definition of '''N'''. Adding to these axioms any sort of [[Peano axioms|axiom schema of induction]] makes redundant the axioms 3, 10, and 11.

====Induction and comprehension schema====
If φ(''n'') is a formula of second-order arithmetic with a free number variable ''n'' and possible other free number or set variables (written ''m''&lt;sub&gt;•&lt;/sub&gt; and ''X''&lt;sub&gt;•&lt;/sub&gt;), the '''induction axiom''' for φ is the axiom:
:&lt;math&gt;\forall m \forall X ((\varphi(0) \land \forall n (\varphi(n) \rightarrow \varphi(Sn))) \rightarrow \forall n \varphi(n))&lt;/math&gt;
The ('''full''') '''second-order induction scheme''' consists of all instances of this axiom, over all second-order formulas.

One particularly important instance of the induction scheme is when φ is the formula “&lt;math&gt;n \in X&lt;/math&gt;” expressing the fact that ''n'' is a member of ''X'' (''X'' being a free set variable): in this case, the induction axiom for φ is
:&lt;math&gt;\forall X ((0\in X \land \forall n (n\in X \rightarrow Sn\in X)) \rightarrow \forall n (n\in X))&lt;/math&gt;
This sentence is called the '''second-order induction axiom'''.

If φ(''n'') is a formula with a free variable ''n'' and possibly other free variables, but not the variable ''Z'', the '''comprehension axiom''' for φ is the formula
:&lt;math&gt;\exists Z \forall n (n\in Z \leftrightarrow \varphi(n))&lt;/math&gt;

This axiom makes it possible to form the set &lt;math&gt;Z = \{ n | \varphi(n) \}&lt;/math&gt; of natural numbers satisfying φ(''n'').  There is a technical restriction that the formula φ may not contain the variable ''Z'', for otherwise the formula &lt;math&gt;n \not \in Z&lt;/math&gt; would lead to the comprehension axiom
:&lt;math&gt;\exists Z \forall n ( n \in Z \leftrightarrow n \not \in Z)&lt;/math&gt;,
which is inconsistent.  This convention is assumed in the remainder of this article.

===The full system===
The formal theory of '''second-order arithmetic''' (in the language of second-order arithmetic) consists of the basic axioms, the comprehension axiom for every formula φ (arithmetic or otherwise), and the second-order induction axiom. This theory is sometimes called ''full second-order arithmetic'' to distinguish it from its subsystems, defined below. Because full second-order semantics imply that every possible set exists, the comprehension axioms may be taken to be part of the deductive system when these semantics are employed (Shapiro 1991, p.&amp;nbsp;66).

==Models==
This section describes second-order arithmetic with first-order semantics. Thus a '''model''' &lt;math&gt;\mathcal{M}&lt;/math&gt; of the language of second-order arithmetic consists of a set ''M'' (which forms the range of individual variables) together with a constant 0 (an element of ''M''), a function ''S'' from ''M'' to ''M'', two binary operations + and · on ''M'', a binary relation &lt; on ''M'', and a collection ''D'' of subsets of ''M'', which is the range of the set variables.  Omitting ''D'' produces a model of the language of first order arithmetic.

When ''D'' is the full powerset of ''M'', the model &lt;math&gt;\mathcal{M}&lt;/math&gt; is called a '''full model'''.  The use of full second-order semantics is equivalent to limiting the models of second-order arithmetic to the full models.  In fact, the axioms of second-order arithmetic have only one full model. This follows from the fact that the axioms of [[Peano arithmetic]] with the second-order induction axiom have only one model under second-order semantics.

When ''M'' is the usual set of natural numbers with its usual operations, &lt;math&gt;\mathcal{M}&lt;/math&gt; is called an '''ω-model'''.  In this case, the model may be identified with ''D'', its collection of sets of naturals, because this set is enough to completely determine an ω-model.

The unique full &lt;math&gt;\omega&lt;/math&gt;-model, which is the usual set of natural numbers with its usual structure and all its subsets, is called the '''intended''' or '''standard''' model of second-order arithmetic.

===Definable functions===
The first-order functions that are provably total in second-order arithmetic are precisely the same as those representable in [[system F]] (Girard and Taylor 1987, pp.&amp;nbsp;122&amp;ndash;123).  Almost equivalently, system F is the theory of functionals corresponding to second-order arithmetic in a manner parallel to how Gödel's [[Dialectica interpretation|system T]] corresponds to first-order arithmetic in the [[Dialectica interpretation]].

==Subsystems==
{{main|Reverse mathematics}}

There are many named subsystems of second-order arithmetic.

A subscript 0 in the name of a subsystem indicates that it includes only
a restricted portion of the full second-order induction scheme (Friedman 1976). Such a restriction lowers the [[proof-theoretic strength]] of the system significantly. For example, the system ACA&lt;sub&gt;0&lt;/sub&gt; described below is [[equiconsistency|equiconsistent]] with [[Peano arithmetic]]. The corresponding theory ACA, consisting of ACA&lt;sub&gt;0&lt;/sub&gt; plus the full second-order induction scheme, is stronger than Peano arithmetic.

===Arithmetical comprehension===
Many of the well-studied subsystems are related to closure properties of models.  For example, it can be shown that every ω-model of full second-order arithmetic is closed under [[Turing jump]], but not every ω-model closed under Turing jump is a model of full second-order arithmetic.  The subsystem ACA&lt;sub&gt;0&lt;/sub&gt; includes just enough axioms to capture the notion of closure under Turing jump.

ACA&lt;sub&gt;0&lt;/sub&gt; is defined as the theory consisting of the basic axioms, the '''arithmetical comprehension axiom''' scheme (in other words the comprehension axiom for every ''arithmetical'' formula φ) and the ordinary second-order induction axiom. It would be equivalent to include the entire arithmetical induction axiom scheme, in other words to include the induction axiom for every arithmetical formula φ.

It can be shown that a collection ''S'' of subsets of ω determines an ω-model of ACA&lt;sub&gt;0&lt;/sub&gt; if and only if ''S'' is closed under Turing jump, Turing reducibility, and Turing join (Simpson 2009, pp.&amp;nbsp;311&amp;ndash;313).

The subscript 0 in ACA&lt;sub&gt;0&lt;/sub&gt; indicates that not every instance of the induction axiom scheme is included this subsystem.  This makes no difference for ω-models, which automatically satisfy every instance of the induction axiom.  It is of importance, however, in the study of non-ω-models.  The system consisting of ACA&lt;sub&gt;0&lt;/sub&gt; plus induction for all formulas is sometimes called ACA with no subscript.

The system ACA&lt;sub&gt;0&lt;/sub&gt; is a conservative extension of '''first-order arithmetic''' (or first-order Peano axioms), defined as the basic axioms, plus the first order induction axiom scheme (for all formulas φ involving no class variables at all, bound or otherwise), in the language of first order arithmetic (which does not permit class variables at all). In particular it has the same [[Ordinal analysis|proof-theoretic ordinal]] ε&lt;sub&gt;0&lt;/sub&gt; as first-order arithmetic, owing to the limited induction schema.

===The arithmetical hierarchy for formulas===
{{main|Arithmetical hierarchy}}

A formula is called ''bounded arithmetical'', or Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;0&lt;/sub&gt;, when all its quantifiers are of the form ∀''n''&lt;''t'' or ∃''n''&lt;''t'' (where ''n'' is the individual variable being quantified and ''t'' is an individual term), where
:&lt;math&gt;\forall n&lt;t(\cdots)&lt;/math&gt;
stands for
:&lt;math&gt;\forall n(n&lt;t \rightarrow \cdots)&lt;/math&gt;
and
:&lt;math&gt;\exists n&lt;t(\cdots)&lt;/math&gt;
stands for
:&lt;math&gt;\exists n(n&lt;t \land \cdots)&lt;/math&gt;.

A formula is called Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; (or sometimes Σ&lt;sub&gt;1&lt;/sub&gt;), respectively Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; (or sometimes Π&lt;sub&gt;1&lt;/sub&gt;) when it of the form ∃''m''&lt;sub&gt;•&lt;/sub&gt;(φ), respectively ∀''m''&lt;sub&gt;•&lt;/sub&gt;(φ) where φ is a bounded arithmetical formula and ''m'' is an individual variable (that is free in φ).  More generally, a formula is called Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;''n''&lt;/sub&gt;, respectively Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;''n''&lt;/sub&gt; when it is obtained by adding existential, respectively universal, individual quantifiers to a Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;''n''&amp;minus;1&lt;/sub&gt;, respectively Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;''n''&amp;minus;1&lt;/sub&gt; formula (and Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;0&lt;/sub&gt; and Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;0&lt;/sub&gt; are all equivalent to Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;0&lt;/sub&gt;).  By construction, all these formulas are arithmetical (no class variables are ever bound) and, in fact, by putting the formula in [[Skolem prenex form]] one can see that every arithmetical formula is equivalent to a Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;''n''&lt;/sub&gt; or Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;''n''&lt;/sub&gt; formula for all large enough ''n''.

===Recursive comprehension===
The subsystem  RCA&lt;sub&gt;0&lt;/sub&gt;  is a weaker system than ACA&lt;sub&gt;0&lt;/sub&gt; and is often used as the base system in [[reverse mathematics]].  It consists of: the basic axioms, the Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; induction scheme, and the Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; comprehension scheme.  The former term is clear: the Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; induction scheme is the induction axiom for every Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; formula φ.  The term “Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; comprehension” is more complex, because there is no such thing as a Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; formula. The  Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; comprehension scheme instead asserts the comprehension axiom for every Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; formula which is equivalent to a Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; formula. This scheme includes,  for every Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; formula φ and every Π&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; formula ψ, the axiom:

:&lt;math&gt;\forall m \forall X ((\forall n (\varphi(n) \leftrightarrow \psi(n))) \rightarrow \exists Z \forall n (n\in Z \leftrightarrow \varphi(n)))&lt;/math&gt;

The set of first-order consequences of  RCA&lt;sub&gt;0&lt;/sub&gt;  is the same as those of the subsystem I&amp;Sigma;&lt;sub&gt;1&lt;/sub&gt; of Peano arithmetic in which induction is restricted to Σ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; formulas. In turn, I&amp;Sigma;&lt;sub&gt;1&lt;/sub&gt; is conservative over [[primitive recursive arithmetic]] (PRA) for &lt;math&gt;\Pi^0_2&lt;/math&gt; sentences. Moreover, the proof-theoretic ordinal of &lt;math&gt;\mathrm{RCA}_0&lt;/math&gt; is ω&lt;sup&gt;ω&lt;/sup&gt;, the same as that of PRA.

It can be seen that a collection ''S'' of subsets of ω determines an ω-model of RCA&lt;sub&gt;0&lt;/sub&gt; if and only if ''S ''is closed under Turing reducibility and Turing join.   In particular, the collection of all computable subsets of ω gives an ω-model of RCA&lt;sub&gt;0&lt;/sub&gt;.  This is the motivation behind the name of this system—if a set can be proved to exist using RCA&lt;sub&gt;0&lt;/sub&gt;, then the set is recursive (i.e. computable).

=== Weaker systems ===
Sometimes an even weaker system than RCA&lt;sub&gt;0&lt;/sub&gt; is desired.  One such system is defined as follows: one must first augment the language of arithmetic with an exponential function (in stronger systems the exponential can be defined in terms of addition and multiplication by the usual trick, but when the system becomes too weak this is no longer possible) and the basic axioms by the obvious axioms defining exponentiation inductively from multiplication; then the system consists of the (enriched) basic axioms, plus Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt; comprehension, plus Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;0&lt;/sub&gt; induction.

===Stronger systems===

Over ACA&lt;sub&gt;0&lt;/sub&gt;, each formula of second-order arithmetic is equivalent to a Σ&lt;sup&gt;1&lt;/sup&gt;&lt;sub style="margin-left:-0.6em"&gt;''n''&lt;/sub&gt; or Π&lt;sup&gt;1&lt;/sup&gt;&lt;sub style="margin-left:-0.6em"&gt;''n''&lt;/sub&gt; formula for all large enough ''n''.  The system '''Π&lt;sup&gt;1&lt;/sup&gt;&lt;sub style="margin-left:-0.6em"&gt;1&lt;/sub&gt;-comprehension''' is the system consisting of the basic axioms, plus the ordinary second-order induction axiom and the comprehension axiom for every Π&lt;sup&gt;1&lt;/sup&gt;&lt;sub style="margin-left:-0.6em"&gt;1&lt;/sub&gt; formula φ.  This is equivalent to Σ&lt;sup&gt;1&lt;/sup&gt;&lt;sub style="margin-left:-0.6em"&gt;1&lt;/sub&gt;-comprehension (on the other hand, Δ&lt;sup&gt;1&lt;/sup&gt;&lt;sub style="margin-left:-0.6em"&gt;1&lt;/sub&gt;-comprehension, defined analogously to Δ&lt;sup&gt;0&lt;/sup&gt;&lt;sub style="margin-left:-0.65em"&gt;1&lt;/sub&gt;-comprehension, is weaker).

== Projective determinacy ==
[[Projective determinacy]] is the assertion that every two-player perfect information game with moves being integers, game length ω and projective payoff set is determined, that is one of the players has a winning strategy.  (The first player wins the game if the play belongs to the payoff set; otherwise, the second player wins.)  A set is projective iff (as a predicate) it is expressible by a formula in the language of second order arithmetic, allowing real numbers as parameters, so projective determinacy is expressible as a schema in the language of Z&lt;sub&gt;2&lt;/sub&gt;.

Many natural propositions expressible in the language of second order arithmetic are independent of Z&lt;sub&gt;2&lt;/sub&gt; and even [[ZFC]] but are provable from projective determinacy.  Examples include coanalytic [[Perfect set property|perfect subset property]], measurability and the [[property of Baire]] for &lt;math&gt;\Sigma^1_2&lt;/math&gt; sets, &lt;math&gt;\Pi^1_3&lt;/math&gt; [[Uniformization (set theory)|uniformization]], etc.  Over a weak base theory (such as RCA&lt;sub&gt;0&lt;/sub&gt;), projective determinacy implies comprehension and provides an essentially complete theory of second order arithmetic &amp;mdash; natural statements in the language of Z&lt;sub&gt;2&lt;/sub&gt; that are independent of Z&lt;sub&gt;2&lt;/sub&gt; with projective determinacy are hard to find (Woodin 2001).

ZFC + {there are ''n'' [[Woodin cardinal]]s: ''n'' is a natural number} is conservative over Z&lt;sub&gt;2&lt;/sub&gt; with projective determinacy, that is a statement in the language of second order arithmetic is provable in Z&lt;sub&gt;2&lt;/sub&gt; with projective determinacy iff its translation into the language of set theory is provable in ZFC + {there are ''n'' Woodin cardinals: ''n''∈N}.

==Coding mathematics==

Second-order arithmetic directly formalizes natural numbers and sets of natural numbers.  However, it is able to formalize other mathematical objects indirectly via coding techniques, a fact which was first noticed by Weyl (Simpson 2009, p.&amp;nbsp;16). The integers, rational numbers, and real numbers can all be formalized in the subsystem RCA&lt;sub&gt;0&lt;/sub&gt;, along with complete separable metric spaces and continuous functions between them (Simpson 2009, Chapter&amp;nbsp;II).

The research program of [[Reverse Mathematics]] uses these formalizations of mathematics in second-order arithmetic to study the set-existence axioms required to prove mathematical theorems (Simpson 2009, p.&amp;nbsp;32). For example, the intermediate value theorem for functions from the reals to the reals is provable in RCA&lt;sub&gt;0&lt;/sub&gt; (Simpson 2009, p.&amp;nbsp;87), while the Bolzano/Weierstrass theorem is equivalent to ACA&lt;sub&gt;0&lt;/sub&gt; over RCA&lt;sub&gt;0&lt;/sub&gt; (Simpson 2009, p.&amp;nbsp;34).

==References==
*Burgess, J. P. (2005), ''Fixing Frege'',  Princeton University Press.
*Buss, S. R. (1998), ''Handbook of proof theory'', Elsevier. {{isbn|0-444-89840-9}}
*[[Harvey Friedman|Friedman, H.]] (1976), "Systems of second order arithmetic with restricted induction," I, II (Abstracts). ''Journal of Symbolic Logic'', v.&amp;nbsp;41, pp.&amp;nbsp;557– 559. [https://www.jstor.org/stable/2272259 JStor]
* Girard, L. and Taylor (1987), ''[http://www.paultaylor.eu/stable/Proofs+Types.html Proofs and Types]'', Cambridge University Press.
* [[David Hilbert|Hilbert, D.]] and [[Paul Bernays|Bernays, P.]] (1934), ''Grundlagen der Mathematik'', Springer-Verlag. {{mr|0237246}}
* [[Wilfried Sieg|Sieg, W.]] (2013), ''Hilbert's Programs and Beyond'', Oxford University Press.
* [[Stewart Shapiro|Shapiro, S.]] (1991), ''Foundations without foundationalism'', Oxford University Press.  {{isbn|0-19-825029-0}}
* [[Steve Simpson (mathematician)|Simpson, S. G.]] (2009), ''[http://www.math.psu.edu/simpson/sosoa/ Subsystems of second order arithmetic]'',  2nd edition, Perspectives in Logic, Cambridge University Press. {{isbn|978-0-521-88439-6}} {{mr|2517689}}
* [[Gaisi Takeuti|Takeuti, G.]] (1975) ''Proof theory'' {{isbn|0-444-10492-5}}
* [[W. Hugh Woodin|Woodin, W. H.]] (2001), "The Continuum Hypothesis, Part I", ''Notices of the American Mathematical Society'', v.&amp;nbsp;48 n.&amp;nbsp;6.

==See also==
*[[Paris–Harrington theorem]]
*[[Reverse mathematics]]
*[[Presburger arithmetic]]
*[[Peano arithmetic]]
*[[Robinson arithmetic]]
*[[Second-order logic]]

[[Category:Formal theories of arithmetic]]</text>
      <sha1>sjeo2cfksyerjge524211w1k312cyj2</sha1>
    </revision>
  </page>
  <page>
    <title>Selberg's zeta function conjecture</title>
    <ns>0</ns>
    <id>31306009</id>
    <revision>
      <id>860247094</id>
      <parentid>763484244</parentid>
      <timestamp>2018-09-19T10:41:06Z</timestamp>
      <contributor>
        <ip>95.166.232.165</ip>
      </contributor>
      <comment>mention early that it is now a theorem</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4114">In mathematics, the '''Selberg conjecture''', named after [[Atle Selberg]], is a [[theorem]] about the density of zeros of the [[Riemann zeta function]] &amp;zeta;(1/2&amp;nbsp;+&amp;nbsp;''it''). It is known that the function has infinitely many zeroes on this line in the complex plane: the point at issue is how densely they are clustered. Results on this can be formulated in terms of ''N''(''T''), the function counting zeroes on the line for which the value of ''t'' satisfies 0 &amp;le; ''t'' &amp;le; ''T''.

==Background==
In 1942 Atle Selberg investigated the problem of the [[Hardy–Littlewood zeta-function conjectures|Hardy–Littlewood conjecture '''2''']]; and he proved that for any

:&lt;math&gt;\varepsilon &gt; 0&lt;/math&gt;

there exist

:&lt;math&gt;T_0 = T_0(\varepsilon) &gt; 0&lt;/math&gt;

and

:&lt;math&gt;c = c(\varepsilon) &gt; 0,&lt;/math&gt;

such that for

:&lt;math&gt;T \geq T_0&lt;/math&gt;

and

:&lt;math&gt;H=T^{0.5+\varepsilon}&lt;/math&gt;

the inequality

:&lt;math&gt;N(T+H)-N(T) \geq cH\log T&lt;/math&gt;

holds true.

In his turn, Selberg stated a conjecture relating to shorter intervals,&lt;ref&gt;{{cite journal| last=Selberg| first=A.| title= On the zeros of Riemann's zeta-function| pages=1–59| journal= Shr. Norske Vid. Akad. Oslo| issue=10| year=1942}}&lt;/ref&gt; namely that it is possible to decrease the value of the exponent ''a'' = 0.5 in

:&lt;math&gt;H=T^{0.5+\varepsilon}.&lt;/math&gt;

==Proof of the conjecture==
In 1984 [[Anatolii Karatsuba]] proved&lt;ref&gt;{{cite journal| first=A. A.| last=Karatsuba| title= On the zeros of the function ζ(s) on short intervals of the critical line| pages=569–584| journal= Izv. Akad. Nauk SSSR, Ser. Mat.| issue=48:3| year=1984}}&lt;/ref&gt;&lt;ref&gt;{{cite journal| first=A. A.| last=Karatsuba|title= The distribution of zeros of the function ζ(1/2&amp;nbsp;+&amp;nbsp;''it'')| pages=1214–1224 | journal= Izv. Akad. Nauk SSSR, Ser. Mat.| issue=48:6|year=1984}}&lt;/ref&gt;&lt;ref&gt;{{cite journal| first=A. A.| last=Karatsuba| title= On the zeros of the Riemann zeta-function on the critical line| pages=167–178| journal= Proc. Steklov Inst. Math.| issue=167| year=1985}}&lt;/ref&gt; that for a fixed &lt;math&gt;\varepsilon&lt;/math&gt; satisfying the condition

:&lt;math&gt;0&lt;\varepsilon &lt; 0.001,&lt;/math&gt;

a sufficiently large ''T'' and

:&lt;math&gt;H = T^{a+\varepsilon},&lt;/math&gt; &lt;math&gt;a = \tfrac{27}{82} = \tfrac{1}{3} -\tfrac{1}{246},&lt;/math&gt;

the interval in the ordinate ''t'' (''T'',&amp;nbsp;''T''&amp;nbsp;+&amp;nbsp;''H'') contains at least ''cH''&amp;nbsp;ln&amp;nbsp;''T'' real zeros of the Riemann zeta function

:&lt;math&gt;\zeta\Bigl(\tfrac{1}{2}+it\Bigr);&lt;/math&gt;

and thereby confirmed the Selberg conjecture. The estimates of Selberg and Karatsuba cannot be improved in respect of the order of growth as ''T''&amp;nbsp;&amp;rarr;&amp;nbsp;+&amp;infin;.

==Further work==
In 1992 Karatsuba proved&lt;ref&gt;{{cite journal| first=A. A.| last=Karatsuba| title= On the number of zeros of the Riemann zeta-function lying in almost all short intervals of the critical line | pages=372–397| journal= Izv. Ross. Akad. Nauk, Ser. Mat.| issue=56:2| year=1992}}&lt;/ref&gt; that an analog of the Selberg conjecture holds for "almost all" intervals (''T'',&amp;nbsp;''T''&amp;nbsp;+&amp;nbsp;''H''], ''H''&amp;nbsp;=&amp;nbsp;''T''&lt;sup&gt;&amp;epsilon;&lt;/sup&gt;, where &amp;epsilon; is an arbitrarily small fixed positive number. The Karatsuba method permits one to investigate zeroes of the Riemann zeta-function on "supershort" intervals of the critical line, that is, on the intervals (''T'',&amp;nbsp;''T''&amp;nbsp;+&amp;nbsp;''H''], the length ''H'' of which grows slower than any, even arbitrarily small degree ''T''.

In particular, he proved that for any given numbers &amp;epsilon;, &amp;epsilon;&lt;sub&gt;1&lt;/sub&gt; satisfying the conditions 0&amp;nbsp;&amp;lt;&amp;nbsp;&amp;epsilon;,&amp;nbsp;&amp;epsilon;&lt;sub&gt;1&lt;/sub&gt;&amp;lt;&amp;nbsp;1 almost all intervals (''T'',&amp;nbsp;''T''&amp;nbsp;+&amp;nbsp;''H''] for ''H''&amp;nbsp;&amp;ge;&amp;nbsp;exp[(ln&amp;nbsp;''T'')&lt;sup&gt;&amp;epsilon;&lt;/sup&gt;] contain at least ''H''&amp;nbsp;(ln&amp;nbsp;''T'')&lt;sup&gt;1&amp;nbsp;&amp;minus;&amp;epsilon;&lt;sub&gt;1&lt;/sub&gt;&lt;/sup&gt; zeros of the function &amp;zeta;(1/2&amp;nbsp;+&amp;nbsp;''it''). This estimate is quite close to the conditional result that follows from the [[Riemann hypothesis]].

==References==
{{Reflist}}

[[Category:Zeta and L-functions]]
[[Category:Conjectures that have been proved]]</text>
      <sha1>fhbudwmfhyrk6bfix5bj5fnr8pg1y15</sha1>
    </revision>
  </page>
  <page>
    <title>Serial binary adder</title>
    <ns>0</ns>
    <id>9436252</id>
    <revision>
      <id>837526237</id>
      <parentid>633439922</parentid>
      <timestamp>2018-04-21T11:35:13Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+See also</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2127">The '''serial binary adder''' or '''bit-serial adder''' is a [[digital circuit]] that performs [[binary numeral system|binary]] [[binary adder|addition]] bit by bit.  The serial [[full adder]] has three single-bit inputs for the numbers to be added and the carry in.  There are two single-bit outputs for the sum and carry out.  The carry-in signal is the previously calculated carry-out signal.  The addition is performed by adding each bit, lowest to highest, one per clock cycle.

==Serial binary addition==

Serial binary addition is done by a [[Flip-flop (electronics)|flip-flop]] and a [[full adder]].  The flip-flop takes the carry-out signal on each clock cycle and provides its value as the carry-in signal on the next clock cycle.  After all of the bits of the input operands have arrived, all of the bits of the sum have come out of the sum output.

==Serial binary subtracter==

The serial binary [[subtracter (electronics)|subtracter]] operates the same as the serial binary adder, except the subtracted number is converted to its [[two's complement]] before being added.  Alternatively, the number to be subtracted is converted to its [[ones' complement]], by inverting its bits, and the carry flip-flop is initialized to a 1 instead of to 0 as in addition.  The ones' complement plus the 1 is the two's complement.

==Example of operation==

;Decimal: 5+9=14
:*X=5, Y=9, Sum=14
;Binary: 0101+1001=1110

;Addition of each step
{|border=1
!colspan=3 |Inputs
!colspan=2 |Outputs
|-
!width=30|Cin
!width=30|X
!width=30|Y
!width=30|Sum
!width=30|Cout
|-
|0
|1
|1
|0
|1
|-
|1
|0
|0
|1
|0
|-
|0
|1
|0
|1
|0
|-
|0
|0
|1
|1
|0
|}
''*addition starts from lowest''
;Result=1110 or 14

==See also==
* [[Parallel binary adder]]

==References==
{{reflist}}

==Further reading==
* http://www.quinapalus.com/wires8.html
* http://www.asic-world.com/digital/arithmetic3.html

==External links==
* [http://teahlab.com/finite_state_machine_Serial_Adder/ Interactive Serial Adder], Provides the visual logic of the Serial Adder circuit built with Teahlab's Simulator.

[[Category:Binary arithmetic]]
[[Category:Adders (electronics)]]</text>
      <sha1>a3gza0s9137ag1f53dn4tafu0l648y5</sha1>
    </revision>
  </page>
  <page>
    <title>Spectral leakage</title>
    <ns>0</ns>
    <id>545288</id>
    <revision>
      <id>868552008</id>
      <parentid>868359239</parentid>
      <timestamp>2018-11-12T22:44:06Z</timestamp>
      <contributor>
        <username>Bob K</username>
        <id>586364</id>
      </contributor>
      <comment>Update the first figure.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="6703">{{refimprove|date=July 2018}}
[[File:Spectral_leakage_caused_by_%22windowing%22.svg|thumb|350px|Windowing a sinusoid causes spectral leakage, even if the sinusoid has an integer number of cycles within a rectangular window. The leakage is evident in the 2nd row, blue trace. It is the same amount as the red trace, which represents a slightly higher frequency that does not have an integer number of cycles. When the sinusoid is sampled and windowed, its discrete-time Fourier transform also suffers from the same leakage pattern. But when the DTFT is only sampled, at a certain interval, it is possible (depending on your point of view) to: (1) avoid the leakage, or (2) create the illusion of no leakage. For the case of the blue sinusoid (3rd row of plots, right-hand side), those samples are the outputs of the discrete Fourier transform (DFT). The red sinusoid DTFT (4th row) has the same interval of zero-crossings, but the DFT samples fall in-between them, and the leakage is revealed.]]
The [[Fourier transform]] of a function of time, s(t), is a complex-valued function of frequency, S(f), often referred to as a [[frequency spectrum]].  Any [[LTI_system_theory|linear time-invariant]] operation on s(t) produces a new spectrum of the form H(f)•S(f), which changes the relative magnitudes and/or angles (phase) of the non-zero values of S(f).  Any other type of operation creates new frequency components that may be referred to as '''spectral leakage''' in the broadest sense.  [[Sampling_(signal_processing)|Sampling]], for instance, produces leakage, which we call [[aliasing|aliases]] of the original spectral component.  For [[Fourier transform]] purposes, [[Sampling_(signal_processing)|sampling]] is modeled as a product between s(t) and a [[Dirac comb]] function.  The spectrum of a product is the [[convolution]] between S(f) and another function, which inevitably creates the new frequency components.  But the term 'leakage' usually refers to the effect of ''windowing'', which is the product of s(t) with a different kind of function, the [[window function]].  Window functions happen to have finite duration, but that is not necessary to create leakage.  Multiplication by a time-variant function is sufficient.

Leakage caused by a window function is most easily characterized by its effect on a sinusoidal s(t) function, whose unwindowed Fourier transform is zero for all but one frequency.  The customary frequency of choice is 0 Hz, because the windowed Fourier transform is simply the Fourier transform of the window function itself''':'''

:&lt;math&gt;\mathcal{F}\{ w(t)\cdot \underbrace{\cos(2\pi 0 t)}_{1}\} = \mathcal{F}\{ w(t)\}.&lt;/math&gt;

== Discrete-time functions ==

When both sampling and windowing are applied to s(t), in either order, the leakage caused by windowing is a relatively localized spreading of frequency components, with often a blurring effect, whereas the aliasing caused by sampling is a periodic repetition of the entire blurred spectrum.

==Window tradeoffs==

[[Image:Scalloping and noise floor comparisons (2 window functions).png|thumb|350px|Comparison of two window functions in terms of their effects on equal-strength sinusoids with additive noise.  The sinusoid at bin −20 suffers no scalloping and the one at bin +20.5 exhibits worst-case scalloping.  The rectangular window produces the most scalloping but also narrower peaks and lower noise-floor.  A third sinusoid with amplitude −16 dB would be noticeable in the upper spectrum, but not in the lower spectrum.]]

{{main|Window function}}
The total leakage of a window function is measured by a metric called ''equivalent noise bandwidth'' (ENBW)&lt;ref&gt;
{{cite journal
  | doi = 10.1109/PROC.1978.10837
  | last = Harris
  | first = Fredric j.
  | coauthors = 
  | title = On the use of Windows for Harmonic Analysis with the Discrete Fourier Transform
  | journal = Proceedings of the IEEE
  | volume = 66
  | issue = 1
  | pages = 51–83
  |date=Jan 1978
  | url=http://web.mit.edu/xiphmont/Public/windows.pdf}} Article on FFT windows which introduced many of the key metrics used to compare windows.&lt;/ref&gt; or ''noise equivalent bandwidth'' (NEB).  The best window in that regard is the simplest, called ''rectangular'' because of its flat top and vertical sides.  Its spreading effect occurs mostly a factor of 10 to 100 below the amplitude of the original component.  Unfortunately the spreading is very wide, which may mask important spectrum details at even lower levels.  That prevents the rectangular window from being a popular choice.  Non-rectangular window functions actually increase the total leakage, but they can also redistribute it to places where it does the least harm, depending on the application.  Specifically, to different degrees they reduce the level of the spreading by increasing the high-level leakage in the near vicinity of the original component.  In general, they control the trade-off between resolving comparable strength signals with similar frequencies or resolving disparate strength signals with dissimilar frequencies: one speaks of "high resolution" versus "high dynamic range" windows.  And leakage near the original component is actually beneficial for a metric known as ''scalloping loss''.

We customarily think of leakage as a spreading out of (say) a sinusoid in one "bin" of a [[discrete Fourier transform|DFT]] into the other bins at levels that generally decrease with distance.  What that actually means is that when the actual sinusoid frequency lies in bin "k", its presence is sensed/recorded at different levels in the other bins; i.e. the correlations they measure are non-zero.  The value measured in bin k+10 and plotted on the spectrum graph is the response of that measurement to the imperfect (i.e. windowed) sinusoid 10 bins away.  And when the input is just [[white noise]] (energy at all frequencies), the value measured in bin k is the sum of its responses to a continuum of frequencies.  One could say that leakage is actually a ''leaking in'' process, rather than leaking out.  That perspective might help to interpret the different noise-floor levels between the two graphs in the figure on the right.  Both spectra were made from the same data set with the same noise power.  But the bins in the bottom graph each responded more strongly than the bins in the top graph.  The exact amount of the difference is given by the ENBW difference of the two window functions.

== See also ==
* [[Window_function#Windowing]]
* [[DTFT#Sampling_the_DTFT]]
* [[Knife-edge effect]], spatial analog of truncation
* [[Gibbs phenomenon]]

==Citations==
{{reflist}}

[[Category:Fourier analysis]]
[[Category:Digital signal processing]]</text>
      <sha1>0nrlsh2p2fyjvw5me9jg785tgxbrnxk</sha1>
    </revision>
  </page>
  <page>
    <title>Two Generals' Problem</title>
    <ns>0</ns>
    <id>4058119</id>
    <revision>
      <id>861584205</id>
      <parentid>861584151</parentid>
      <timestamp>2018-09-28T14:20:26Z</timestamp>
      <contributor>
        <ip>24.227.165.242</ip>
      </contributor>
      <comment>/* Illustrating the problem */</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="11959">In computing, the '''Two Generals Problem''' is a [[thought experiment]] meant to illustrate the pitfalls and design challenges of attempting to coordinate an action by communicating over an unreliable link. It is related to the more general [[Byzantine Generals]] Problem and appears often in introductory classes about [[computer networking]] (particularly with regard to the [[Transmission Control Protocol]], where it shows that TCP can't guarantee state consistency between endpoints and why), though it applies to any type of two-party communication where failures of communication are possible. A key concept in [[epistemic logic]], this problem highlights the importance of [[common knowledge (logic)|common knowledge]]. Some authors also refer to this as the '''Two Generals Paradox''', the '''Two Armies Problem''', or the '''Coordinated Attack Problem'''.&lt;ref&gt;{{cite journal|last=Gmytrasiewicz|first=Piotr J.|author2=Edmund H. Durfee |title=Decision-theoretic recursive modeling and the coordinated attack problem|journal=Proceedings of the first international conference on Artificial intelligence planning systems|year=1992|pages=88–95|url=http://dl.acm.org/citation.cfm?id=139492.139503|accessdate=27 December 2013|publisher=Morgan Kaufmann Publishers|location=San Francisco}}&lt;/ref&gt;&lt;ref&gt;[http://www.dsi.uniroma1.it/~asd3/dispense/attack+amazons.pdf The coordinated attack and the jealous amazons] Alessandro Panconesi. Retrieved 2011-05-17.&lt;/ref&gt;  The Two Generals Problem was the first computer communication problem to be proved to be unsolvable.  An important consequence of this proof is that generalizations like the Byzantine Generals problem are also unsolvable in the face of arbitrary communication failures, thus providing a base of realistic expectations for any distributed consistency protocols.

==Definition==
Two [[army|armies]], each led by a different [[general]], are preparing to attack a fortified city. The armies are encamped near the city, each in its own valley. A third valley separates the two hills, and the only way for the two generals to communicate is by sending [[Runner (war)|messenger]]s through the valley. Unfortunately, the valley is occupied by the city's defenders and there's a chance that any given messenger sent through the valley will be captured.

[[File:2-generals.svg|right|thumb|Positions of the armies. Armies A1 and A2 need to communicate but their messengers may be captured by army B.]]

While the two generals have agreed that they will attack, they haven't agreed upon a time for attack. It is required that the two generals have their armies attack the city at the same time in order to succeed, else the lone attacker army will die trying. They must thus communicate with each other to decide on a time to attack and to agree to attack at that time, and each general must know that the other general knows that they have agreed to the attack plan. Because [[Acknowledgement (data networks)|acknowledgement of message receipt]] can be lost as easily as the original message, a potentially infinite series of messages is required to come to [[Consensus (computer science)|consensus]].

The thought experiment involves considering how they might go about coming to consensus. In its simplest form one general is known to be the leader, decides on the time of attack, and must communicate this time to the other general. The problem is to come up with algorithms that the generals can use, including sending messages and processing received messages, that can allow them to correctly conclude:

:Yes, we will both attack at the agreed-upon time.

Allowing that it is quite simple for the generals to come to an agreement on the time to attack (i.e. one successful message with a successful acknowledgement), the subtlety of the Two Generals' Problem is in the impossibility of designing algorithms for the generals to use to safely agree to the above statement.

==Illustrating the problem==
The first general may start by sending a message "Attack at 0900 on August 4." However, once dispatched, the first general has no idea whether or not the messenger got through. This uncertainty may lead the first general to hesitate to attack due to the risk of being the sole attacker.

To be sure, the second general may send a confirmation back to the first: "I received your message and will attack at 0900 on August 4." However, the messenger carrying the confirmation could face capture and the second general may hesitate, knowing that the first might hold back without the confirmation.

Further confirmations may seem like a solution—let the second general send a second confirmation: "I received your confirmation of the planned attack at 0900 on August 4." However, this new messenger from the second general is liable to be captured, too. Thus it quickly becomes evident that no matter how many rounds of confirmation are made, there is no way to guarantee the second requirement that each general be sure the other has agreed to the attack plan. Both generals will always be left wondering whether their last messenger got through.

==Proof==

===For deterministic protocols with a fixed number of messages===
Because this protocol is '''[[Deterministic_system|deterministic]]''', suppose there is a '''sequence''' of a fixed number of messages, one or more successfully delivered and one or more not. The assumption is that there should be a ''shared certainty for both generals to attack''.

Consider the last such message that was successfully delivered. If that last message had not been successfully delivered, then one general at least (presumably the receiver) would decide not to attack. {{Citation needed|reason=There is probably an error in the proof. In original reference or only here? See Talk page for details.|date=May 2017}} From the viewpoint of the sender of that last message, however, the '''sequence''' of messages sent and delivered is exactly the same as it would have been, had that message been delivered.

Since the protocol is '''deterministic''', the general sending that last message will still decide to attack. 
We've now created a situation where the suggested protocol leads one general to attack and the other not to attack—contradicting the assumption that the protocol was a solution to the problem.

===For nondeterministic and variable-length protocols===
A '''nondeterministic''' protocol with a variable message count can be compared to a '''finite''' [[tree (graph theory)|tree]], where each leaf or branch (node) in the tree represents an explored example up to a specified point.

The roots of this tree are labeled with the possible starting messages, and the branch nodes stemming from these roots are labeled with the possible next messages. Leaf nodes represent examples which end after sending the last message. A protocol that terminates before sending any messages is represented by a null tree.

Suppose there exists a '''nondeterministic''' protocol which solves the problem. Then, by a similar argument to the '''deterministic''' example in the previous section, where a deterministic protocol can be obtained from the non-deterministic one by removing all leaf nodes, the '''deterministic''' protocol must then also solve the problem.

Since the '''nondeterministic''' protocol is '''finite''', it then follows that the protocol represented by the empty tree would solve the problem. Clearly this is not possible. Therefore a '''nondeterministic''' protocol which solves the problem cannot exist.&lt;ref&gt;{{cite book|last1=Kennard|first1=Fredrick|title=Thought Experiments: Popular Thought Experiments in Philosophy, Physics, Ethics, Computer Science &amp; Mathematics|publisher=Lulu.com|isbn=9781329003422|page=346|url=https://books.google.nl/books?id=sX-pCQAAQBAJ|accessdate=15 September 2015}}&lt;/ref&gt;

==Engineering approaches==
A pragmatic approach to dealing with the Two Generals' Problem is to use schemes that accept the [[uncertainty]] of the [[communication]]s channel and not attempt to eliminate it, but rather mitigate it to an acceptable degree. For example, the first general could send 100 messengers, anticipating that the probability of all being captured is low. With this approach the first general will attack no matter what, and the second general will attack if any message is received. Alternatively the first general could send a stream of messages and the second general could send acknowledgments to each, with each general feeling more comfortable with every message received. As seen in the proof, however, neither can be certain that the attack will be coordinated. There's no algorithm that they can use (e.g. attack if more than four messages are received) which will be certain to prevent one from attacking without the other. Also, the first general can send a marking on each message saying it is message 1, 2, 3 ... of n. This method will allow the second general to know how reliable the channel is and send an appropriate number of messages back to ensure a high probability of at least one message being received. If the channel can be made to be reliable, then one message will suffice and additional messages do not help. The last is as likely to get lost as the first.

Assuming that the generals must sacrifice lives every time a messenger is sent and intercepted, an algorithm can be designed to minimize the number of messengers required to achieve the maximum amount of confidence the attack is coordinated.  To save them from sacrificing hundreds of lives to achieve a very high confidence in coordination, the generals could agree to use the absence of messengers as an indication that the general who began the transaction has received at least one confirmation, and has promised to attack. Suppose it takes a messenger 1 minute to cross the danger zone, allowing 200 minutes of silence to occur after confirmations have been received will allow us to achieve extremely high confidence while not sacrificing messenger lives.  In this case messengers are used only in the case where a party has not received the attack time.  At the end of 200 minutes, each general can reason: "I have not received an additional message for 200 minutes; either 200 messengers failed to cross the danger zone, or it means the other general has confirmed and committed to the attack and has confidence I will too".

==History==
The Two Generals Problem and its impossibility proof was first published by E. A. Akkoyunlu, K. Ekanadham, and R. V. Huber in 1975 in "Some Constraints and Trade-offs in the Design of Network Communications",&lt;ref&gt;{{cite web|url=http://hydra.infosys.tuwien.ac.at/teaching/courses/AdvancedDistributedSystems/download/1975_Akkoyunlu,%20Ekanadham,%20Huber_Some%20constraints%20and%20tradeoffs%20in%20the%20design%20of%20network%20communications.pdf |doi=10.1145/800213.806523 
|title=Some constraints and trade-offs in the design of network communications |publisher=Portal.acm.org |accessdate=2010-03-19}}&lt;/ref&gt; where it is described starting on page 73 in the context of communication between two groups of gangsters.

This problem was given the name the ''Two Generals Paradox'' by [[Jim Gray (computer scientist)|Jim Gray]]&lt;ref&gt;{{cite web|url=http://research.microsoft.com/~Gray/JimGrayHomePageSummary.htm |title=Jim Gray Summary Home Page |publisher=Research.microsoft.com |date=2004-05-03 |accessdate=2010-03-19}}&lt;/ref&gt; in 1978 in "Notes on Data Base Operating Systems"&lt;ref&gt;{{cite web|url=http://portal.acm.org/citation.cfm?coll=GUIDE&amp;dl=GUIDE&amp;id=723863 |title=Notes on Data Base Operating Systems |publisher=Portal.acm.org |accessdate=2010-03-19}}&lt;/ref&gt; starting on page 465. This reference is widely given as a source for the definition of the problem and the impossibility proof, though both were published previously as above.

==References==
{{reflist|30em}}

[[Category:Distributed computing problems]]
[[Category:Theory of computation]]
[[Category:Thought experiments]]</text>
      <sha1>tfora6op1sbue8ajq4lbe22uyyk1cxk</sha1>
    </revision>
  </page>
  <page>
    <title>Uniqueness theorem</title>
    <ns>0</ns>
    <id>29759120</id>
    <revision>
      <id>825105422</id>
      <parentid>825100370</parentid>
      <timestamp>2018-02-11T14:42:37Z</timestamp>
      <contributor>
        <username>Frode54</username>
        <id>28691415</id>
      </contributor>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2218">In mathematics, a '''uniqueness theorem''' is a [[theorem]] proving that certain conditions determine a unique solution. Examples of uniqueness theorems include:

* [[Alexandrov's uniqueness theorem]] of three-dimensional polyhedra
* [[Black hole uniqueness theorem]]
* [[Cauchy–Kowalevski theorem]] is the main local [[existence theorem|existence]] and uniqueness theorem for [[analytic function|analytic]] [[partial differential equation]]s associated with [[Cauchy problem|Cauchy initial value problem]]s.
* [[Cauchy–Kowalevski theorem#Cauchy–Kowalevski–Kashiwara theorem|Cauchy–Kowalevski–Kashiwara theorem]] is a wide generalization of the Cauchy–Kowalevski theorem for systems of linear partial differential equations with analytic coefficients.
* [[Fundamental theorem of arithmetic]], the uniqueness of prime factorization.
* [[Holmgren's uniqueness theorem]] for linear partial differential equations with real analytic coefficients.
* [[Picard–Lindelöf theorem]], the uniqueness of solutions to first-order differential equations.
* [[Thompson uniqueness theorem]] in finite group theory
* [[Uniqueness theorem for Poisson's equation]]
* [[Electromagnetism uniqueness theorem]] for the solution of Maxwell's equation
* [[Uniqueness case]] in finite group theory
A theorem, also called a unicity theorem, stating the uniqueness of a mathematical object, which usually means that there is only one object fulfilling given properties, or that all objects of a given class are equivalent (i.e., they can be represented by the same model). This is often expressed by saying that the object is uniquely determined by a certain set of data. The word unique is sometimes replaced by essentially unique, whenever one wants to stress that the uniqueness is only referred to the underlying structure, whereas the form may vary in all ways that do not affect the mathematical content.

A uniqueness theorem / proof is, at least within mathematics of differential equations, often combined with an existence theorem / proof to a combined existence and uniqueness theorem.

==See also==
* [[Rigidity (mathematics)]]
* [[Uniqueness quantification]]

{{set index article|mathematics}}

[[Category:Theorems]]</text>
      <sha1>r1d305qw95l3nkny62b447zxht5ta0l</sha1>
    </revision>
  </page>
  <page>
    <title>Victor Shoup</title>
    <ns>0</ns>
    <id>3978418</id>
    <revision>
      <id>864119760</id>
      <parentid>864119254</parentid>
      <timestamp>2018-10-15T06:34:19Z</timestamp>
      <contributor>
        <username>BenKuykendall</username>
        <id>12604315</id>
      </contributor>
      <comment>update and reference for ISO standard</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4111">{{Infobox scientist
| name              = Victor Shoup
| image             = &lt;!--(filename only, i.e. without "File:" prefix)--&gt;
| birth_date        = &lt;!--{{birth date |YYYY|MM|DD}}--&gt;
| death_date        = &lt;!--{{death date and age |YYYY|MM|DD |YYYY|MM|DD}} (death date then birth date)--&gt;
| nationality       =
| fields            = {{Plainlist|
*[[Computer science]]
*[[Mathematics]]
}}
| workplaces        = {{Plainlist|
*[[New York University|NYU]] [[Courant Institute of Mathematical Sciences|Courant Institute]]
*[[AT&amp;T Bell Labs]]
*[[University of Toronto]]
*[[Saarland University]]
*[[IBM]] [[IBM Zurich Research Laboratory|Zurich Research Lab]]
}}
| alma_mater        = {{Plainlist|
*[[University of Wisconsin-Eau Claire|UW-Eau Claire]]
*[[University of Wisconsin-Madison|UW-Madison]]
}}
| thesis_title      = "Removing Randomness from Computational Number Theory"
| thesis_year       = 1989
| doctoral_advisor  = [[Eric Bach]]
| doctoral_students =
| known_for         = [[Cramer–Shoup cryptosystem]]
| awards            =
| website           = {{URL|http://www.shoup.net/}}
}}

'''Victor Shoup''' is a [[computer scientist]] and [[mathematician]].  He obtained a PhD in computer science from the [[University of Wisconsin–Madison]] in 1989 &lt;ref&gt;{{MathGenealogy|id=75326}}&lt;/ref&gt;, and he did his undergraduate work at the [[University of Wisconsin-Eau Claire]].&lt;ref&gt;[https://web.archive.org/web/20110720020632/http://as.nyu.edu/object/victorshoup.html Victor Shoup] at NYU Arts and Sciences&lt;/ref&gt; He is a professor at the [[Courant Institute of Mathematical Sciences]] at [[New York University]], focusing on algorithm and cryptography courses. He has held positions at [[AT&amp;T Bell Labs]], the [[University of Toronto]], [[Saarland University]], and the [[IBM Zurich Research Laboratory]].&lt;ref&gt;[https://web.archive.org/web/20120716205532/http://www.win.tue.nl/wsk/eidma/courses/minicourses/shoup/shoup.html 5-day minicourse on Public Key Cryptography] at NYU Courant Institute&lt;/ref&gt;

Shoup's main research interests and contributions are computer [[algorithms]] relating to [[number theory]], [[algebra]], and [[cryptography]].  His contributions to these fields include:

* The [[Cramer–Shoup cryptosystem]] asymmetric encryption algorithm bears his name.
* His freely available (under the terms of the [[GNU]] [[GNU General Public License|GPL]]) [[C++]] library of number theory algorithms, NTL, is widely used and well regarded for its high performance.
* He is the author of a widely used{{Citation needed|date=October 2018}} textbook, ''A Computational Introduction to Number Theory and Algebra'', which is freely available online.
* He has proved (while at IBM Zurich) a lower bound to the [[Analysis of algorithms|computational complexity]] for solving the [[discrete logarithm problem]] in the [[generic group model]]. This is a problem in computational [[group theory]] which is of considerable importance to public-key cryptography.
* He acted as editor for the [[International Organization for Standardization|ISO]] 18033-2 standard for public-key cryptography.&lt;ref&gt;{{cite web |url=http://www.shoup.net/iso/std6.pdf |title= FCD 18033-2 Encryption algorithms — Part 2: Asymmetric ciphers |last=Victor |first=Shoup |date=December 6, 2004 |access-date=October 15, 2018}}&lt;/ref&gt;

==Bibliography==
*''A Computational Introduction to Number Theory and Algebra'', 2nd Edition, 2009, Cambridge University Press, {{ISBN|978-0521516440}}, {{ISBN|0521516447}}

==References==

{{Reflist}}

{{authority control}}

{{DEFAULTSORT:Shoup, Victor}}
[[Category:Courant Institute of Mathematical Sciences faculty]]
[[Category:Year of birth missing (living people)]]
[[Category:University of Wisconsin–Madison alumni]]
[[Category:American computer scientists]]
[[Category:Theoretical computer scientists]]
[[Category:Modern cryptographers]]
[[Category:Public-key cryptographers]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:Number theorists]]
[[Category:IBM employees]]
[[Category:Living people]]
[[Category:University of Wisconsin–Eau Claire alumni]]</text>
      <sha1>daimyab85jsmvot43m3zyz9ps3lso0u</sha1>
    </revision>
  </page>
  <page>
    <title>Vienna Series in Theoretical Biology</title>
    <ns>0</ns>
    <id>21796270</id>
    <revision>
      <id>712926876</id>
      <parentid>532119293</parentid>
      <timestamp>2016-03-31T21:55:36Z</timestamp>
      <contributor>
        <username>BG19bot</username>
        <id>14508071</id>
      </contributor>
      <minor/>
      <comment>/* Volumes */Remove blank line(s) between list items per [[WP:LISTGAP]] to fix an accessibility issue for users of [[screen reader]]s. Do [[WP:GENFIXES]] and cleanup if needed. Discuss this at [[Wikipedia talk:WikiProject Accessibility#LISTGAP]]</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2848">The '''''Vienna Series in Theoretical Biology''''' is a book series published by [[MIT Press]] and devoted to advances in [[theoretical biology]] at large. By promoting the formulation and discussion of new theoretical [[concept]]s, the series intends to help fill the gaps in our understanding of some of the major open questions of [[biology]], such as the origin and organization of organismal form, the relationship between [[Evolutionary developmental biology|development and evolution]], and the biological bases of [[cognition]] and [[mind]].

The Vienna Series grew out of the [[Altenberg Workshops in Theoretical Biology]] organized by the [[Konrad Lorenz Institute for Evolution and Cognition Research]] (KLI), an international center for advanced study in Altenberg, near [[Vienna]], [[Austria]]. The KLI fosters research projects, workshops, archives, book projects, and the journal [[Biological Theory]], all devoted to aspects of theoretical biology, with an emphasis on integrating the developmental, evolutionary, and cognitive sciences.

==Series Editors==

[[Gerd Müller (theoretical biologist)|Gerd B. Müller]], [[Günter Wagner]], [[Werner Callebaut]]

==Volumes==
*''Cognitive Biology. Evolutionary and Developmental Perspectives on Mind, Brain, and Behavior.'' Luca Tommasi, Mary A. Peterson and Lynn Nadel (Eds.), July 2009.
*''Functions in Biological and Artificial Worlds. Comparative Philosophical Perspectives.'' Ulrich Krohs and Peter Kroes (Eds.), 2009.
*''Evolution of Communicative Flexibility. Complexity, Creativity, and Adaptability in Human and Animal Communication.'' D. Kimbrough Oller and Ulrike Griebel (Eds.), 2008.
*''Modeling Biology. Structures, Behaviors, Evolution.'' Manfred D. Laubichler and Gerd B. Müller (Eds.), 2007.
*''Biological Emergences. Evolution by Natural Experiment.'' Robert G. B. Reid, 2007.
*''Compositional Evolution. The Impact of Sex, Symbiosis, and Modularity on the Gradualist Framework of Evolution.'' Richard A. Watson, 2006.
*''Modularity. Understanding the Development and Evolution of Natural Complex Systems.'' Werner Callebaut and Diego Rasskin-Gutman (Eds.), 2005.
*''Evolution of Communication Systems. A Comparative Approach.'' D. Kimbrough Oller and Ulrike Griebel (Eds.), 2004.
*''Environment, Development, and Evolution. Toward a Synthesis.'' Brian K. Hall, Roy D. Pearson and Gerd B. Müller (Eds.), 2004.
*''Origination of Organismal Form. Beyond the Gene in Developmental and Evolutionary Biology.'' Gerd B. Müller and Stuart A. Newman (Eds.), 2003.
*''The Evolution of Cognition''. Cecilia Heyes and Ludwig Huber (Eds.), 2000.

==External links==
*[http://mitpress.mit.edu/catalog/browse/browse.asp?serid=102&amp;sid=B5C39998-812F-4084-8F62-E95ECF623F17&amp;btype=6&amp;order=d9 The Vienna Series in Theoretical Biology]

[[Category:Mathematical and theoretical biology]]</text>
      <sha1>9h69re01p030f40n8tavrmam79wtc6u</sha1>
    </revision>
  </page>
  <page>
    <title>Volder's algorithm</title>
    <ns>0</ns>
    <id>8727323</id>
    <redirect title="CORDIC" />
    <revision>
      <id>699005939</id>
      <parentid>693285673</parentid>
      <timestamp>2016-01-09T17:28:53Z</timestamp>
      <contributor>
        <username>Matthiaspaul</username>
        <id>13467261</id>
      </contributor>
      <comment>+cat</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="185">#REDIRECT [[CORDIC]] {{R from alternative title}}

[[Category:Numerical analysis]]
[[Category:Trigonometry]]
[[Category:Digit-by-digit algorithms]]
[[Category:Shift-and-add algorithms]]</text>
      <sha1>p7qae73ixdxpktod7i4qzzchikco0s2</sha1>
    </revision>
  </page>
  <page>
    <title>Window function</title>
    <ns>0</ns>
    <id>244097</id>
    <revision>
      <id>868636257</id>
      <parentid>868635931</parentid>
      <timestamp>2018-11-13T14:09:29Z</timestamp>
      <contributor>
        <username>Bob K</username>
        <id>586364</id>
      </contributor>
      <minor/>
      <comment>update figure numbers</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="70686">{{For|the term used in SQL statements|Window function (SQL)}}
[[File:Hanning.png|thumb|A popular window function, the [[#Hann and Hamming windows|Hann window]].  Most popular window functions are similar bell-shaped curves.]]

In [[signal processing]] and [[statistics]], a '''window function''' (also known as an '''apodization function''' or '''tapering function'''&lt;ref&gt;{{cite book | title = CRC Concise Encyclopedia of Mathematics |first= Eric W. |last=Weisstein | publisher = CRC Press | year = 2003 | isbn = 1-58488-347-2 | url = https://books.google.com/?id=aFDWuZZslUUC&amp;pg=PA97&amp;dq=apodization+function }}&lt;/ref&gt;) is a [[function (mathematics)|mathematical function]] that is zero-valued outside of some chosen [[interval (mathematics)|interval]], normally symmetric around the middle of the interval, usually near a maximum in the middle, and usually tapering away from the middle. Mathematically, when another function or waveform/data-sequence is "multiplied" by a window function, the product is also zero-valued outside the interval: all that is left is the part where they overlap, the "view through the window".  Equivalently, and in actual practice, the segment of data within the window is first isolated, and then only that data is multiplied by the window function values.  Thus, tapering, not segmentation, is the main purpose of window functions.

The reasons for examining segments of a longer function include detection of transient events and time-averaging of frequency spectra.  The duration of the segments is determined in each application by requirements like time and frequency resolution.  But that method also changes the frequency content of the signal by an effect called [[spectral leakage]].  Window functions allow us to distribute the leakage spectrally in different ways, according to the needs of the particular application.  There are many choices detailed in this article, but many of the differences are so subtle as to be insignificant in practice.

In typical applications, the window functions used are non-negative, smooth, "bell-shaped" curves.&lt;ref&gt;{{cite book | title = Microsound |first=Curtis |last=Roads | publisher = MIT Press | year = 2002 | isbn = 0-262-18215-7 | url =  }}&lt;/ref&gt; Rectangle, triangle, and other functions can also be used.  A rectangular window does not modify the data segment at all.  It's only for modelling purposes that we say it multiplies by 1 inside the window and by 0 outside.  A more general definition of window functions does not require them to be identically zero outside an interval, as long as the product of the window multiplied by its argument is [[square integrable]], and, more specifically, that the function goes sufficiently rapidly toward zero.&lt;ref&gt;{{cite book | title = Wavelet and Wave Analysis As Applied to Materials With Micro Or Nanostructure |first=Carlo |last=Cattani |first2=Jeremiah |last2=Rushchitsky |publisher=World Scientific |year=2007 |isbn=981-270-784-0 |url=https://books.google.com/?id=JuJKu_0KDycC&amp;pg=PA53&amp;dq=define+%22window+function%22+nonzero+interval }}&lt;/ref&gt;

== Applications ==

Window functions are used in [[frequency spectrum#Spectrum analysis|spectral analysis]]/modification/[[Overlap–add method|resynthesis]],&lt;ref&gt;{{Cite web|url=https://www.dsprelated.com/freebooks/sasp/Overlap_Add_OLA_STFT_Processing.html|title=Overlap-Add (OLA) STFT Processing {{!}} Spectral Audio Signal Processing|last=|first=|date=|website=www.dsprelated.com|publisher=|access-date=2016-08-07|quote=The window is applied twice: once before the FFT (the "analysis window") and secondly after the inverse FFT prior to reconstruction by overlap-add (the so-called "synthesis window"). ... More generally, any positive COLA window can be split into an analysis and synthesis window pair by taking its square root.}}&lt;/ref&gt; the design of [[finite impulse response]] filters, as well as [[beamforming]] and [[Antenna (radio)|antenna]] design.

=== Spectral analysis ===&lt;!-- This section is linked from [[Discrete Fourier transform]] --&gt;

The [[Fourier transform]] of the function cos&amp;nbsp;ω''t'' is zero, except at frequency ±ω.  However, many other functions and waveforms do not have convenient closed-form transforms. Alternatively, one might be interested in their spectral content only during a certain time period.

In either case, the Fourier transform (or a similar transform) can be applied on one or more finite intervals of the waveform.  In general, the transform is applied to the product of the waveform and a window function.  Any window (including rectangular) affects the spectral estimate computed by this method.

[[File:Spectral_leakage_caused_by_%22windowing%22.svg|thumb|350px|Figure 2:  Windowing a sinusoid causes spectral leakage, even if the sinusoid has an integer number of cycles within a rectangular window. The leakage is evident in the 2nd row, blue trace. It is the same amount as the red trace, which represents a slightly higher frequency that does not have an integer number of cycles. When the sinusoid is sampled and windowed, its discrete-time Fourier transform also suffers from the same leakage pattern. But when the DTFT is only sampled, at a certain interval, it is possible (depending on your point of view) to: (1) avoid the leakage, or (2) create the illusion of no leakage. For the case of the blue sinusoid (3rd row of plots, right-hand side), those samples are the outputs of the discrete Fourier transform (DFT). The red sinusoid DTFT (4th row) has the same interval of zero-crossings, but the DFT samples fall in-between them, and the leakage is revealed.]]

==== Windowing ====

Windowing of a simple waveform like cos&amp;nbsp;ω''t'' causes its Fourier transform to develop non-zero values (commonly called [[spectral leakage]]) at frequencies other than ω. The leakage tends to be worst (highest) near ω and least at frequencies farthest from ω.

If the waveform under analysis comprises two sinusoids of different frequencies, leakage can interfere with the ability to distinguish them spectrally. If their frequencies are dissimilar and one component is weaker, then leakage from the stronger component can obscure the weaker one's presence. But if the frequencies are similar, leakage can render them ''unresolvable'' even when the sinusoids are of equal strength.  The rectangular window has excellent resolution characteristics for sinusoids of comparable strength, but it is a poor choice for sinusoids of disparate amplitudes. This characteristic is sometimes described as ''low [[dynamic range]]''.

At the other extreme of dynamic range are the windows with the poorest resolution and '''''sensitivity''''', which is the ability to reveal relatively weak sinusoids in the presence of additive random noise.  That is because the noise produces a stronger response with high-dynamic-range windows than with high-resolution windows.  Therefore, high-dynamic-range windows are most often justified in ''wideband applications'', where the spectrum being analyzed is expected to contain many different components of various amplitudes.

In between the extremes are moderate windows, such as [[Window function#Hamming window|Hamming]] and [[Window function#Hann (Hanning) window|Hann]]. They are commonly used in ''narrowband applications'', such as the spectrum of a telephone channel. In summary, spectral analysis involves a trade-off between resolving comparable strength components with similar frequencies and resolving disparate strength components with dissimilar frequencies. That trade-off occurs when the window function is chosen.

==== Discrete-time signals ====

When the input waveform is time-sampled, instead of continuous, the analysis is usually done by applying a window function and then a [[discrete Fourier transform]] (DFT). But the DFT provides only a sparse sampling of the actual [[discrete-time Fourier transform]] (DTFT) spectrum. Figure 2, row 3 shows a DTFT for a rectangularly-windowed sinusoid. The actual frequency of the sinusoid is indicated as "13" on the horizontal axis. Everything else is leakage, exaggerated by the use of a logarithmic presentation. The unit of frequency is "DFT bins"; that is, the integer values on the frequency axis correspond to the frequencies sampled by the DFT.  So the figure depicts a case where the actual frequency of the sinusoid coincides with a DFT sample, and the maximum value of the spectrum is accurately measured by that sample.  In row 4, it misses the maximum value by ½ bin, and the resultant measurement error is referred to as '''''scalloping loss''''' (inspired by the shape of the peak).  For a known frequency, such as a musical note or a sinusoidal test signal, matching the frequency to a DFT bin can be prearranged by choices of a sampling rate and a window length that results in an integer number of cycles within the window.

[[File:Processing losses for 3 window functions.gif|thumb|480px|Figure 3: This figure compares the processing losses of three window functions for sinusoidal inputs, with both minimum and maximum scalloping loss.]]

==== Noise bandwidth ====

The concepts of resolution and dynamic range tend to be somewhat subjective, depending on what the user is actually trying to do.  But they also tend to be highly correlated with the total leakage, which is quantifiable.  It is usually expressed as an equivalent bandwidth, B.  It can be thought of as redistributing the DTFT into a rectangular shape with height equal to the spectral maximum and width B.&lt;ref name="noise bandwidth" group="note"&gt;Mathematically, the noise equivalent bandwidth of transfer function ''H'' is the bandwidth of an ideal rectangular filter with the same peak gain as ''H'' that would pass the same power with [[white noise]] input.  In the units of frequency ''f'' (e.g. [[hertz]]), it is given by''':'''

:&lt;math&gt; B_{\text{noise}} = \frac{1}{|H(f)|^2_{\max}} \int_0^{\infty} |H(f)|^2 df.&lt;/math&gt;
&lt;/ref&gt;&lt;ref&gt;{{cite book |url=https://books.google.com/?id=V_JSAAAAMAAJ |title=Communication Systems: An Introduction to Signals and Noise in Electrical Communication |first=A. Bruce |last=Carlson |publisher=McGraw-Hill |year=1986 |isbn=0-07-009960-X}}&lt;/ref&gt;  The more the leakage, the greater the bandwidth.  It is sometimes called ''noise equivalent bandwidth'' or ''equivalent noise bandwidth'', because it is proportional to the average power that will be registered by each DFT bin when the input signal contains a random noise component (or '''is''' just random noise).  A graph of the [[power spectrum]], averaged over time, typically reveals a flat ''[[noise floor]]'', caused by this effect.  The height of the noise floor is proportional to B.  So two different window functions can produce different noise floors.

==== Processing gain and losses ====
In [[signal processing]], operations are chosen to improve some aspect of quality of a signal by exploiting the differences between the signal and the corrupting influences.  When the signal is a sinusoid corrupted by additive random noise, spectral analysis distributes the signal and noise components differently, often making it easier to detect the signal's presence or measure certain characteristics, such as amplitude and frequency.  Effectively, the [[signal to noise ratio]] (SNR) is improved by distributing the noise uniformly, while concentrating most of the sinusoid's energy around one frequency.  ''Processing gain'' is a term often used to describe an SNR improvement.  The processing gain of spectral analysis depends on the window function, both its noise bandwidth (B) and its potential scalloping loss.  These effects partially offset, because windows with the least scalloping naturally have the most leakage.

The figure at right depicts the effects of three different window functions on the same data set, comprising two equal strength sinusoids in additive noise.  The frequencies of the sinusoids are chosen such that one encounters no scalloping and the other encounters maximum scalloping.  Both sinusoids suffer less SNR loss under the Hann window than under the [[Ralph Beebe Blackman|Blackman]]–[[Fredric J. Harris|Harris]] window.  In general (as mentioned earlier), this is a deterrent to using high-dynamic-range windows in low-dynamic-range applications.

=== Filter design ===

{{Main|Filter design}}

Windows are sometimes used in the design of [[digital filters]], in particular to convert an "ideal" impulse response of infinite duration, such as a [[sinc function]], to a [[finite impulse response]] (FIR) filter design.  That is called the [[Finite impulse response#Window design method|''window method'']].&lt;ref&gt;{{Cite web|url=http://www.labbookpages.co.uk/audio/firWindowing.html|title=FIR Filters by Windowing - The Lab Book Pages|website=www.labbookpages.co.uk|access-date=2016-04-13}}&lt;/ref&gt;&lt;ref&gt;[http://www.cg.tuwien.ac.at/research/vis/vismed/Windows/MasteringWindows.pdf Mastering Windows: Improving Reconstruction]&lt;/ref&gt;

=== Statistics and curve fitting ===

{{Main|kernel (statistics)}}

Window functions are sometimes used in the field of [[statistics|statistical analysis]] to restrict the set of data being analyzed to a range near a given point, with a [[Weighting | weighting factor]] that diminishes the effect of points farther away from the portion of the curve being fit. In the field of  Bayesian analysis and [[curve fitting]] , this is often referred to as the [[kernel (statistics)|kernel]].

=== Rectangular window applications ===

==== Analysis of transients ====

When analyzing a transient signal in [[modal analysis]], such as an impulse, a shock response, a sine burst, a chirp burst, or noise burst, where the energy vs time distribution is extremely uneven, the rectangular window may be most appropriate.  For instance, when most of the energy is located at the beginning of the recording, a non-rectangular window attenuates most of the energy, degrading the signal-to-noise ratio.&lt;ref name="hpmemoryproject.org"&gt;{{cite web|url=http://www.hpmemoryproject.org/an/pdf/an_243.pdf|title=The Fundamentals of Signal Analysis Application Note 243|author=|date=|website=hpmemoryproject.org|accessdate=10 April 2018}}&lt;/ref&gt;

==== Harmonic analysis ====

One might wish to measure the harmonic content of a musical note from a particular instrument or the harmonic distortion of an amplifier at a given frequency.  Referring again to '''Figure 2''', we can observe that there is no leakage at a discrete set of harmonically-related frequencies sampled by the DFT.  (The spectral nulls are actually zero-crossings, which cannot be shown on a logarithmic scale such as this.)  This property is unique to the rectangular window, and it must be appropriately configured for the signal frequency, as described above.

[[File:8-point Hann windows.png|thumb|300px|Figure 4: Two different ways to generate an 8-point Hann window sequence for spectral analysis applications. MATLAB calls them "symmetric" and "periodic". The latter is also historically called "DFT Even".]]

[[File:Comparison of symmetric and periodic triangular windows.png|thumb|300px|Figures 5a and 5b: Comparison of symmetric and periodic triangular windows]]

===Symmetry===

Window functions generated for digital filter design are symmetrical sequences, usually an odd length with a single maximum at the center.  Windows for DFT/FFT usage, as in spectral analysis or [[Time–frequency analysis#TF filtering and signal decomposition|time-frequency filtering]], are even-length sequences, usually created by deleting the right-most coefficient of an odd-length, symmetrical window.  These are known as '''periodic''',&lt;ref&gt;{{Cite web|url=http://www.mathworks.com/help/signal/ref/hann.html|title=Hann (Hanning) window - MATLAB hann|website=www.mathworks.com|access-date=2016-04-13}}&lt;/ref&gt;&lt;ref group="note"&gt;''Periodic'' is an oblique reference to the fact that symmetry is restored when the sequence is viewed as one cycle of a periodic sequence.&lt;/ref&gt; or '''DFT-even'''.&lt;ref name="f.harris"/&gt;  Such a window is generated by the [[MATLAB]] function hann(512,'periodic') for instance.  To generate it with the formula in section [[#Hann window|Hann window]], the window length (N) is 513, and the 513th coefficient of the generated sequence is discarded.  With N=512, the same formula is equivalent to hann(512,'symmetric').

The DFT of an N-length ''DFT-even'' window has zero-valued imaginary components, because the n=0 and n=N/2 samples do not contribute to them, and the other samples are all symmetric about N/2, causing their contributions to cancel each other; i.e. &amp;nbsp;&lt;math&gt;e^{-i2\pi kn/N} + e^{-i2\pi k(N-n)/N} = 2 \cos(2\pi kn/N)&lt;/math&gt;&amp;nbsp; is real-valued.  The inverse DFT is always N-periodic, but when the input is a ''DFT-even'' window, the inverse is symmetrical around the origin, which is the classic indicator of a real-valued frequency-domain representation.  See section [[#Cosine-sum windows|Cosine-sum windows]] for an example of how this characteristic can be beneficial.

For a window function with zero-valued end-points, deleting one or both end-points has no effect on its DTFT (spectral leakage).  But the function designed for N+1 samples, in anticipation of deleting an end point, typically has a slightly narrower main lobe, slightly higher sidelobes, and a slightly lower noise bandwidth.  Similarly, deleting both zeros from a function designed for N+2 samples further amplifies those effects.

There is also a cosmetic result of truncating an N+1 sample symmetric window.  It happens when we sample the DTFT only at intervals of &lt;math&gt;\tfrac{1}{N}&lt;/math&gt; cycles/sample, which is the effect of an N-point DFT.  For example, the N-point DFT of the sequence generated by hann(N,'periodic') has only 3 non-zero values.  (see [https://commons.wikimedia.org/wiki/File:DFT-even_Hann_window_&amp;_spectral_leakage.png '''DFT-even Hann window'''])  All the other samples coincide with zero-crossings of the DTFT, which creates an illusion of little or no spectral leakage.  Such a sparse sampling only reveals the leakage into the DFT bins from a sinusoid whose frequency is also an integer DFT bin. The unseen sidelobes reveal the leakage to expect from sinusoids at other frequencies.&lt;ref&gt;Harris, Fredric J. (Jan 1978), fig 10, p 178.&lt;/ref&gt; That is why it's important to sample the DTFT more densely (as we do in the subsequent sections) and choose a window that suppresses the sidelobes to an acceptable level.

== A list of window functions ==

Terminology''':'''

*'''N''' represents the width, in samples, of a discrete-time, symmetrical window function &amp;nbsp;&lt;math&gt;w[n],\ 0\le n \le N-1.&lt;/math&gt;&amp;nbsp;  When N is an odd number, the non-flat windows have a singular maximum point.  When N is even, they have a double maximum.
*It is sometimes useful to express &amp;nbsp;&lt;math&gt;w[n]&lt;/math&gt;&amp;nbsp; as a sequence of samples of the ''lagged'' version of a  [https://ccrma.stanford.edu/~jos/filters/Zero_Phase_Filters_Even_Impulse.html zero-phase] function''':'''
:&lt;math&gt;w[n] = \ w_0\left(n-\tfrac{N-1}{2}\right),\ 0\le n \le N-1.&lt;/math&gt; &amp;nbsp;&lt;ref&gt;{{cite book
|first=C. Britton |last=Rorabaugh
|title=DSP Primer
|series=Primer series
|date=October 1998
|publisher=McGraw-Hill Professional
|isbn=0070540047
|page=196
}}&lt;/ref&gt;&lt;ref group="note"&gt;Conversely:
:&lt;math&gt;w_0(n)\ = w\left( n+\tfrac{N-1}{2}\right ),\quad -\tfrac{N+1}{2} &lt; n &lt; \tfrac{N+1}{2},&lt;/math&gt;
where the limits of integer n ensure an odd number of coefficients and symmetry about n=0, whether N is even or odd valued.
&lt;/ref&gt;
:*Function &lt;math&gt;w_0&lt;/math&gt; is also known as the ''finite Fourier transform'' data window.&lt;ref&gt;Harris, Fredric J. (Jan 1978), sect V.E., p 63.&lt;/ref&gt;

*Each figure label includes the corresponding noise equivalent bandwidth metric ('''B'''),&lt;ref name="noise bandwidth" group="note" /&gt; in units of ''DFT bins''.

=== Rectangular window ===
&lt;!-- [[Boxcar window]] redirects here --&gt;
[[File:Window function and frequency response - Rectangular.svg|thumb|480px|right|Rectangular window; ''B''&amp;nbsp;=&amp;nbsp;1.0000.&lt;ref name=Heinzel2002/&gt;]]

The rectangular window (sometimes known as the '''[[Boxcar function|boxcar]]''' or '''[[Dirichlet kernel|Dirichlet]] window''') is the simplest window, equivalent to replacing all but ''N'' values of a data sequence by zeros, making it appear as though the waveform suddenly turns on and off:

:&lt;math&gt;w(n) = 1.&lt;/math&gt;

Other windows are designed to moderate these sudden changes, which reduces scalloping loss and improves dynamic range, as described above ([[Window function#Spectral analysis]]).

The rectangular window is the 1st order ''B''-spline window as well as the 0th power [[#Power-of-sine/cosine_windows|Power-of-sine window]].
{{clear}}

=== ''B''-spline windows ===

''B''-spline windows can be obtained as ''k''-fold convolutions of the rectangular window. They include the rectangular window itself (''k''&amp;nbsp;=&amp;nbsp;1), the [[#Triangular_window|triangular window]] (''k''&amp;nbsp;=&amp;nbsp;2) and the Parzen window (''k''&amp;nbsp;=&amp;nbsp;4).&lt;ref name="toraichi89"&gt;{{Cite journal | last1 = Toraichi | first1 = K. | last2 = Kamada | first2 = M. | last3 = Itahashi | first3 = S. | last4 = Mori | first4 = R. | title = Window functions represented by B-spline functions | doi = 10.1109/29.17517 | journal = IEEE Transactions on Acoustics, Speech, and Signal Processing | volume = 37 | pages = 145 | year = 1989 | pmid =  | pmc = }}&lt;/ref&gt; Alternative definitions sample the appropriate normalized [[B-spline|''B''-spline]] [[basis function]]s instead of convolving discrete-time windows. A ''k''th order ''B''-spline basis function is a piece-wise polynomial function of degree ''k''−1 that is obtained by ''k''-fold self-convolution of the [[rectangular function]].
{{clear}}

==== Triangular window ====
[[File:Window function and frequency response - Triangular.svg|thumb|480px|right|Triangular window (with ''L''=''N''-1) or equivalently the Bartlett window; ''B''&amp;nbsp;=&amp;nbsp;1.3333.&lt;ref name=Heinzel2002/&gt;]]

Triangular windows are given by:

:&lt;math&gt;w(n)=1 - \left|\frac{n-\frac{N-1}{2}}{\frac{L}{2}}\right|,&lt;/math&gt;

where ''L'' can be ''N'',&lt;ref name="f.harris"/&gt;&lt;ref&gt;{{Cite web|url=http://www.mathworks.com/help/signal/ref/triang.html|title=Triangular window - MATLAB triang|website=www.mathworks.com|access-date=2016-04-13}}&lt;/ref&gt; ''N''+1,&lt;ref name="Welch1967"&gt;{{Cite journal | last1 = Welch | first1 = P. | title = The use of fast Fourier transform for the estimation of power spectra: A method based on time averaging over short, modified periodograms | doi = 10.1109/TAU.1967.1161901 | journal = IEEE Transactions on Audio and Electroacoustics | volume = 15 | issue = 2 | pages = 70 | year = 1967 | pmid =  | pmc = }}&lt;/ref&gt; or ''N''-1.&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Bartlett_Triangular_Window.html|title=Bartlett Window|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;  The last one is also known as '''[[M. S. Bartlett|Bartlett]] window''' or '''[[Lipót Fejér|Fejér]] window'''.  All three definitions converge at large ''N''.

The triangular window is the 2nd order ''B''-spline window and can be seen as the convolution of two N/2 width rectangular windows.  The Fourier transform of the result is the squared values of the transform of the half-width rectangular window.
{{clear}}

==== Parzen window ====
[[File:Window function and frequency response - Parzen.svg|thumb|480px|right|Parzen window; ''B''&amp;nbsp;=&amp;nbsp;1.92.&lt;ref name="f.harris"/&gt;]]

{{Distinguish|Kernel density estimation}}
The Parzen window, also known as the '''de la Vallée Poussin window''',&lt;ref name="f.harris"/&gt; is the 4th order ''B''-spline window given by:

:&lt;math&gt;
w_0(n) = \left\{ \begin{array}{ll}
 1 - 6 \left(\frac{n}{N/2}\right)^2 \left(1 - \frac{|n|}{N/2}\right),
 &amp; 0 \le |n| \le \frac{N}{4} \\ 
 2 \left(1 - \frac{|n|}{N/2}\right)^3,
 &amp; \frac{N}{4} &lt; |n| \le \frac{N}{2} \\ 
\end{array} \right.
&lt;/math&gt;
:&lt;math&gt;w[n] = \ w_0\left(n-\tfrac{N-1}{2}\right),\ 0\le n \le N-1.&lt;/math&gt;
{{clear}}

[[File:Window function and frequency response - Welch.svg|thumb|480px|right|Welch window; ''B''&amp;nbsp;=&amp;nbsp;1.20.&lt;ref name="f.harris"/&gt;]]

=== Other polynomial windows ===
==== Welch window ====

The Welch window consists of a single [[parabola|parabolic]] section:

:&lt;math&gt;w(n)=1 - \left(\frac{n-\frac{N-1}{2}}{\frac{N-1}{2}}\right)^2&lt;/math&gt;.&lt;ref name="Welch1967"/&gt;

The defining [[quadratic polynomial]] reaches a value of zero at the samples just outside the span of the window.

{{clear}}

=== Sine window ===
[[File:Window function and frequency response - Cosine.svg|thumb|480px|right|Sine window; ''B''&amp;nbsp;=&amp;nbsp;1.23]]

:&lt;math&gt;w(n) = \sin\left(\frac{\pi n}{N-1}\right) = \cos\left(\frac{\pi n}{N-1} - \frac{\pi}{2}\right)&lt;/math&gt;

The corresponding &lt;math&gt;w_0(n)\,&lt;/math&gt; function is a cosine without the π/2 phase offset.  So the ''sine window''&lt;ref&gt;{{cite book|last1=Bosi |first1=Marina |last2=Goldberg |first2=Richard E. |title=Introduction to Digital Audio Coding and Standards |chapter=Time to Frequency Mapping Part II: The MDCT |publisher=Springer US |series=The Springer International Series in Engineering and Computer Science |volume=721 |date=2003 |location=Boston, MA |page=106 |isbn=978-1-4615-0327-9 |doi=10.1007/978-1-4615-0327-9}}&lt;/ref&gt; is sometimes also called ''cosine window''.&lt;ref name="f.harris"/&gt;

The [[autocorrelation]] of a sine window produces a function known as the [https://www.mathworks.com/help/signal/ref/bohmanwin.html?s_tid=gn_loc_drop Bohman window].

==== Power-of-sine/cosine windows ====

These window functions have the form:&lt;ref&gt;{{cite web|url=https://ccrma.stanford.edu/~jos/sasp/Power_of_Cosine_Window_Family.html|title=Power-of-Cosine Window Family|author=|date=|website=ccrma.stanford.edu|accessdate=10 April 2018}}&lt;/ref&gt;

:&lt;math&gt;w(n) = \sin^\alpha\left(\frac{\pi n}{N-1}\right) = \cos^\alpha\left(\frac{\pi n}{N-1} - \frac{\pi}{2}\right).&lt;/math&gt;

The [[#Rectangular_window|rectangular window]] (''α''&amp;nbsp;=&amp;nbsp;0), the [[#sine window|sine window]] (''α''&amp;nbsp;=&amp;nbsp;1), and the [[#Hann window|Hann window]] (''α''&amp;nbsp;=&amp;nbsp;2) are members of this family.

{{clear}}

=== Cosine-sum windows ===
This family is also known as ''[https://www.mathworks.com/help/signal/ug/generalized-cosine-windows.html generalized cosine windows]''.  The symmetric and DFT-even (''periodic'') versions have the following forms, respectively''':'''

{{NumBlk|:|&lt;math&gt;w(n) = \sum_{k = 0}^{K} (-1)^k a_k\; \cos\left( \frac{2 \pi k n}{N-1} \right),\quad 0\le n \le N-1&lt;/math&gt;|{{EquationRef|Eq.1}}}}

:&lt;math&gt;w(n) = \sum_{k = 0}^{K} (-1)^k a_k\; \cos\left( \frac{2 \pi k n}{N} \right),\quad 0\le n \le N-1.&lt;/math&gt;&amp;nbsp; &amp;nbsp; &amp;nbsp; ('''N''' even-valued)&lt;ref&gt;Harris, Fredric J. (Jan 1978), sect V.E., eq 31b, p 63.&lt;/ref&gt;

In most cases, including the examples below, all coefficients a&lt;sub&gt;k&lt;/sub&gt; ≥ 0.&amp;nbsp; The popular ''periodic'' form has only 2''K''&amp;nbsp;+&amp;nbsp;1 non-zero N-point DFT coefficients, and they are all real-valued (see [[#Symmetry|Symmetry]]).&lt;ref name="DFT-even" group="note"&gt;The N-point DFT of an N-sample DFT-even Hann or Hamming window, for example, has only 3 DTFT samples that do not coincide with zero-crossings.  An illustration, for N=16,  can be viewed at [https://commons.wikimedia.org/wiki/File:DFT-even_Hann_window_&amp;_spectral_leakage.png '''DFT-even Hann window'''].&lt;/ref&gt;&amp;nbsp;  These properties make periodic cosine-sum windows a natural choice for real-time applications that require both windowed and non-windowed (rectangularly windowed) transforms, because the windowed transforms can be  efficiently derived from the non-windowed transforms by [[Discrete Fourier transform#Convolution theorem duality|convolution]].&lt;ref&gt;{{Citation |ref=refCarlin |inventor-last =Carlin |inventor-first=Joe |inventor2-last=Collins |inventor2-first=Terry |inventor3-last=Hays |inventor3-first=Peter |inventor4-last=Hemmerdinger |inventor4-first=Barry |inventor5-last=Kellogg |inventor5-first=Robert |inventor6-last=Kettig |inventor6-first=Robert |inventor7-last=Lemmon |inventor7-first=Bradley |inventor8-last=Murdock |inventor8-first=Thomas |inventor9-last=Tamaru |inventor9-first=Robert |inventor10-last=Ware |inventor10-first=Stuart |publication-date=1999 |issue-date=2005 |title=Wideband communication intercept and direction finding device using hyperchannelization |country-code=US |description=patent |patent-number=6898235}}&lt;/ref&gt;  The formulas below are symmetric.  As discussed earlier, choosing an odd value of N and dropping the last coefficient also produces a ''periodic'' ('''DFT-even''') window.

==== Hann and Hamming windows{{anchor|Hamming window}} ====
{{Main|Hann function}}
[[File:Window function and frequency response - Hann.svg|thumb|480px|right|Hann window; ''B''&amp;nbsp;=&amp;nbsp;1.5000.&lt;ref name=Heinzel2002/&gt;]]
[[File:Window function and frequency response - Hamming (alpha = 0.53836).svg|thumb|480px|right|Hamming window, a&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.53836 and a&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.46164; ''B''&amp;nbsp;=&amp;nbsp;1.37. The original Hamming window would have a&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.54 and a&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.46; ''B''&amp;nbsp;=&amp;nbsp;1.3628.&lt;ref name=Heinzel2002/&gt;]]

The customary cosine-sum windows for case K=1 have the form:

:&lt;math&gt;w(n) = a_0 - \underbrace{(1-a_0)}_{a_1}\cdot \cos\left( \tfrac{2 \pi n}{N - 1} \right),\quad 0\le n \le N-1,&lt;/math&gt;

which is easily (and often) confused with its zero-phase version:

:&lt;math&gt;
\begin{align}
w_0(n)\ &amp;\stackrel{\mathrm{def}}{=}\ w\left( n+\tfrac{N-1}{2}\right )\\
&amp;= a_0 + a_1\cdot \cos \left ( \tfrac{2\pi n}{N-1} \right),\quad -\tfrac{N+1}{2} &lt; n &lt; \tfrac{N+1}{2}.
\end{align}
&lt;/math&gt;

Setting &amp;nbsp;&lt;math&gt;a_0 = 0.5&lt;/math&gt;&amp;nbsp; produces a '''Hann window:'''

:&lt;math&gt;w(n) = 0.5\; \left[1 - \cos \left ( \frac{2 \pi n}{N-1} \right) \right] = \sin^2 \left ( \frac{\pi n}{N-1} \right),&lt;/math&gt;&lt;ref&gt;{{Cite web|url=http://www.mathworks.com/help/toolbox/signal/ref/hann.html|title=Hann (Hanning) window - MATLAB hann|website=www.mathworks.com|access-date=2016-04-13}}&lt;/ref&gt;

named after [[Julius von Hann]], and sometimes referred to as ''Hanning'', presumably due to its linguistic and formulaic similarities to the Hamming window.  It is also known as '''raised cosine''', because the zero-phase version, &lt;math&gt;w_0(n),&lt;/math&gt; is one lobe of an elevated cosine function.

This function is a member of both the [[#Cosine-sum windows|cosine-sum]] and [[#Power-of-sine/cosine_windows|power-of-sine]] families.  Unlike the [[#Hamming window|Hamming window]], the end points of the Hann window just touch zero.  The resulting [[Spectral leakage|side-lobes]] roll off at about 18&amp;nbsp;dB per octave.&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Hann_Hanning_Raised_Cosine.html|title=Hann or Hanning or Raised Cosine|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

Setting &amp;nbsp;&lt;math&gt;a_0&lt;/math&gt;&amp;nbsp; to approximately 0.54, or more precisely 25/46, produces the '''Hamming window,''' proposed by [[Richard W. Hamming]].  That choice places a zero-crossing at frequency 5π/(''N''&amp;nbsp;−&amp;nbsp;1), which cancels the first sidelobe of the Hann window, giving it a height of about one-fifth that of the Hann window.&lt;ref name="f.harris"/&gt;&lt;ref&gt;{{cite book | title = Programming and Analysis for Digital Time Series Data |first=Loren D. |last=Enochson |first2=Robert K. |last2=Otnes |publisher=U.S. Dept. of Defense, Shock and Vibration Info. Center |year=1968 |pages=142 |url=https://books.google.com/?id=duBQAAAAMAAJ&amp;q=%22hamming+window%22+date:0-1970&amp;dq=%22hamming+window%22+date:0-1970 }}&lt;/ref&gt;&lt;ref name="JOSHamming"&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Hamming_Window.html|title=Hamming Window|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

Approximation of the coefficients to two decimal places substantially lowers the level of sidelobes,&lt;ref name="f.harris"/&gt; to a nearly equiripple condition.&lt;ref name="JOSHamming"/&gt; In the equiripple sense, the optimal values for the coefficients are a&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.53836 and a&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.46164.&lt;ref name="JOSHamming"/&gt;&lt;ref&gt;{{cite journal |first=A. H. |last=Nuttall |title=Some windows with very good sidelobe behavior |journal=IEEE Transactions on Acoustics, Speech, and Signal Processing |volume=ASSP-29 |pages=84–91 |date=February 1981}}&lt;/ref&gt;
{{clear}}

==== Blackman window ====
[[File:Window function and frequency response - Blackman.svg|thumb|480px|right|Blackman window; ''α''&amp;nbsp;=&amp;nbsp;0.16; ''B''&amp;nbsp;=&amp;nbsp;1.73.&lt;ref name="f.harris"/&gt;]]

Blackman windows are defined as:
:&lt;math&gt;w(n)=a_0 -  a_1 \cos \left ( \frac{2 \pi n}{N-1} \right) + a_2 \cos \left ( \frac{4 \pi n}{N-1} \right)&lt;/math&gt;

:&lt;math&gt;a_0=\frac{1-\alpha}{2};\quad a_1=\frac{1}{2};\quad a_2=\frac{\alpha}{2}\,&lt;/math&gt;

By common convention, the unqualified term ''Blackman window'' refers to Blackman's "not very serious proposal" of ''α''&amp;nbsp;=&amp;nbsp;0.16 (''a''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.42, ''a''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.5, ''a''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.08), which closely approximates the "exact Blackman",&lt;ref&gt;{{Cite web|url=http://mathworld.wolfram.com/BlackmanFunction.html|title=Blackman Function|last=W.|first=Weisstein, Eric|website=mathworld.wolfram.com|language=en|access-date=2016-04-13}}&lt;/ref&gt; with ''a''&lt;sub&gt;0&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;7938/18608&amp;nbsp;≈&amp;nbsp;0.42659, ''a''&lt;sub&gt;1&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;9240/18608&amp;nbsp;≈&amp;nbsp;0.49656, and ''a''&lt;sub&gt;2&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;1430/18608&amp;nbsp;≈&amp;nbsp;0.076849.&lt;ref&gt;{{Cite web|url=http://zone.ni.com/reference/en-XX/help/371361E-01/lvanlsconcepts/char_smoothing_windows/#Exact_Blackman|title=Characteristics of Different Smoothing Windows - NI LabVIEW 8.6 Help|website=zone.ni.com|access-date=2016-04-13}}&lt;/ref&gt; These exact values place zeros at the third and fourth sidelobes,&lt;ref name="f.harris"/&gt; but result in a discontinuity at the edges and a 6&amp;nbsp;dB/oct fall-off.  The truncated coefficients do not null the sidelobes as well, but have an improved 18&amp;nbsp;dB/oct fall-off.&lt;ref name="f.harris" /&gt;&lt;ref&gt;{{Cite book|url=https://smile.amazon.com/Measurement-Power-Spectra-Communications-Engineering/dp/B0006AW1C4|title=The Measurement of Power Spectra from the Point of View of Communications Engineering|last=Blackman|first=R. B.|last2=Tukey|first2=J. W.|date=1959-01-01|publisher=Dover Publications|year=|isbn=9780486605074|location=|page=99|pages=|language=English|via=}}&lt;/ref&gt;

{{clear}}

==== Nuttall window, continuous first derivative ====
[[File:Window function and frequency response - Nuttall (continuous first derivative).svg|thumb|480px|right|Nuttall window, continuous first derivative; ''B''&amp;nbsp;=&amp;nbsp;2.0212.&lt;ref name=Heinzel2002/&gt;]]

Considering ''n'' as a real number, the Nuttall window function and its first [[derivative]] are continuous everywhere, like in Hann. That is, the function goes to 0 at ''n'' = 0, unlike the Blackman–Nuttall and Blackman–Harris windows, which have a small positive value at zero (a "step" from the zero outside the window), like the Hamming window.  The Blackman window defined via ''&amp;alpha;'' is also continuous with continuous derivative at the edge, but the described "exact Blackman window" is not.

:&lt;math&gt;w(n)=a_0 - a_1 \cos \left ( \frac{2 \pi n}{N-1} \right)+ a_2 \cos \left ( \frac{4 \pi n}{N-1} \right)- a_3 \cos \left ( \frac{6 \pi n}{N-1} \right)&lt;/math&gt;

:&lt;math&gt;a_0=0.355768;\quad a_1=0.487396;\quad a_2=0.144232;\quad a_3=0.012604\,&lt;/math&gt;
{{clear}}

==== Blackman–Nuttall window ====
[[File:Window function and frequency response - Blackman-Nuttall.svg|thumb|480px|right|Blackman–Nuttall window; ''B''&amp;nbsp;=&amp;nbsp;1.9761.&lt;ref name=Heinzel2002/&gt;]]

:&lt;math&gt;w(n)=a_0 - a_1 \cos \left ( \frac{2 \pi n}{N-1} \right)+ a_2 \cos \left ( \frac{4 \pi n}{N-1} \right)- a_3 \cos \left ( \frac{6 \pi n}{N-1} \right)&lt;/math&gt;

:&lt;math&gt;a_0=0.3635819; \quad a_1=0.4891775; \quad a_2=0.1365995; \quad a_3=0.0106411\,&lt;/math&gt;
{{clear}}

==== Blackman–Harris window ====
[[File:Window function and frequency response - Blackman-Harris.svg|thumb|480px|right|Blackman–Harris window; ''B''&amp;nbsp;=&amp;nbsp;2.0044.&lt;ref name=Heinzel2002/&gt;]]

A generalization of the Hamming family, produced by adding more shifted sinc functions, meant to minimize side-lobe levels&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Blackman_Harris_Window_Family.html|title=Blackman-Harris Window Family|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Three_Term_Blackman_Harris_Window.html|title=Three-Term Blackman-Harris Window|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

:&lt;math&gt;w(n)=a_0 - a_1 \cos \left ( \frac{2 \pi n}{N-1} \right)+ a_2 \cos \left ( \frac{4 \pi n}{N-1} \right)- a_3 \cos \left ( \frac{6 \pi n}{N-1} \right)&lt;/math&gt;

:&lt;math&gt;a_0=0.35875;\quad a_1=0.48829;\quad a_2=0.14128;\quad a_3=0.01168\,&lt;/math&gt;
{{clear}}

==== Flat top window ====
[[File:Window function and frequency response - flat top.svg|thumb|480px|right|flat top window; ''B''&amp;nbsp;=&amp;nbsp;3.7703.]]

A flat top window is a partially negative-valued window that has minimal [[#Discrete-time_signals|scalloping loss]] in the frequency domain. That property is desirable for the measurement of amplitudes of sinusoidal frequency components.&lt;ref name=Heinzel2002&gt;{{cite techreport |first=G. |last=Heinzel |last2=Rüdiger |first2=A. |last3=Schilling |first3=R. |title=Spectrum and spectral density estimation by the Discrete Fourier transform (DFT), including a comprehensive list of window functions and some new flat-top windows |id=395068.0 |institution=Max Planck Institute (MPI) für Gravitationsphysik / Laser Interferometry &amp; Gravitational Wave Astronomy |year=2002 |url=http://edoc.mpg.de/395068 |accessdate=2013-02-10}}&lt;/ref&gt;&lt;ref name="dspguide"&gt;{{cite book |last=Smith |first=Steven W. |title=The Scientist and Engineer's Guide to Digital Signal Processing |url=http://www.dspguide.com/ch9/1.htm |accessdate=2013-02-14 |year=2011 |publisher=California Technical Publishing |location=San Diego, California, USA}}&lt;/ref&gt; Drawbacks of the broad bandwidth are poor frequency resolution and high [[#Noise_bandwidth|noise bandwidth]].

Flat top windows can be designed using low-pass filter design methods,&lt;ref name="dspguide"/&gt; or they may be of the usual [[#Cosine-sum windows|cosine-sum]] variety:

:&lt;math&gt;
\begin{align}
w(n) = a_0 &amp;- a_1 \cos \left ( \frac{2 \pi n}{N-1} \right)+ a_2 \cos \left ( \frac{4 \pi n}{N-1} \right)\\
           &amp;- a_3 \cos \left ( \frac{6 \pi n}{N-1} \right)+a_4 \cos \left ( \frac{8 \pi n}{N-1} \right)
\end{align}
&lt;/math&gt;


The [https://www.mathworks.com/help/signal/ref/flattopwin.html Matlab variant] has these coefficients:
:&lt;math&gt;a_0=0.21557895;\quad a_1=0.41663158;\quad a_2=0.277263158;\quad a_3=0.083578947;\quad a_4=0.006947368&lt;/math&gt;

Other variations are available, such as sidelobes that roll off at the cost of higher values near the main lobe.&lt;ref name="Heinzel2002"/&gt;
{{clear}}


==== Rife–Vincent windows ====

Rife-Vincent windows&lt;ref&gt;{{Citation |last=Rife |first=David C. |first2=G. A. |last2=Vincent |title=Use of the discrete Fourier transform in the measurement of frequencies and levels of tones |journal=Bell Syst. Tech. J. |volume=49 |issue=2 |year=1970 |pages=197–228 |doi=10.1002/j.1538-7305.1970.tb01766.x}}&lt;/ref&gt; are customarily scaled for unity average value, instead of unity peak value.  The coefficient values below, applied to {{EquationNote|Eq.1}}, reflect that custom.

Class I, Order 1 (K=1):&amp;nbsp; &lt;math&gt;a_0=1;\quad a_1=1&lt;/math&gt; &amp;nbsp; &amp;nbsp;  &amp;nbsp; Functionally equivalent to the [[#Hann window|Hann window]].

Class I, Order 2 (K=2):&amp;nbsp; &lt;math&gt;a_0=1;\quad a_1=\tfrac{4}{3};\quad a_2=\tfrac{1}{3}&lt;/math&gt;

Class I is defined by minimizing the high-order sidelobe amplitude.  Coefficients for orders up to K=4 are tabulated.&lt;ref name=andria&gt;{{Citation |last1=Andria |first1=Gregorio |first2=Mario |last2=Savino |first3=Amerigo |last3=Trotta |title=Windows and interpolation algorithms to improve electrical measurement accuracy |journal=Instrumentation and Measurement, IEEE Transactions on |volume=38 |issue=4 |year=1989 |pages=856–863 |doi=10.1109/19.31004}}&lt;/ref&gt;

Class II minimizes the main-lobe width for a given maximum side-lobe.

Class III is a compromise for which order K=2 resembles the [[#Blackman window|Blackman window]].&lt;ref name=andria/&gt;&lt;ref&gt;{{Citation |last1=Schoukens |first1=Joannes |first2=Rik |last2=Pintelon |first3=Hugo |last3=Van Hamme |title=The interpolated fast Fourier transform: a comparative study |journal=Instrumentation and Measurement, IEEE Transactions on |volume=41 |issue=2 |year=1992 |pages=226–232 |doi=10.1109/19.137352}}&lt;/ref&gt;

{{clear}}

=== Adjustable windows ===

==== Gaussian window ====
[[File:Window function and frequency response - Gaussian (sigma = 0.4).svg|thumb|480px|right|Gaussian window, ''σ''&amp;nbsp;=&amp;nbsp;0.4; ''B''&amp;nbsp;=&amp;nbsp;1.45.]]
The Fourier transform of a [[Gaussian function|Gaussian]] is also a Gaussian (it is an [[eigenfunction]] of the Fourier Transform).  Since the Gaussian function extends to infinity, it must either be truncated at the ends of the window, or itself windowed with another zero-ended window.&lt;ref name="JOSGaussian"&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Gaussian_Window_Transform.html|title=Gaussian Window and Transform|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

Since the log of a Gaussian produces a [[parabola]], this can be used for nearly exact quadratic interpolation in [[frequency estimation]].&lt;ref name="JOSGaussian"/&gt;&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Matlab_Gaussian_Window.html|title=Matlab for the Gaussian Window|website=ccrma.stanford.edu|access-date=2016-04-13|quote=Note that, on a dB scale, Gaussians are quadratic. This means that parabolic interpolation of a sampled Gaussian transform is exact. ... quadratic interpolation of spectral peaks may be more accurate on a log-magnitude scale (e.g., dB) than on a linear magnitude scale}}&lt;/ref&gt;&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Quadratic_Interpolation_Spectral_Peaks.html|title=Quadratic Interpolation of Spectral Peaks|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

:&lt;math&gt;w(n)=e^{-\frac{1}{2} \left ( \frac{n-(N-1)/2}{\sigma (N-1)/2} \right)^{2}}&lt;/math&gt;
:&lt;math&gt;\sigma \le \;0.5\,&lt;/math&gt;

The standard deviation of the Gaussian function is ''σ''(''N''−1)/2 sampling periods.
{{clear}}

[[File:Window function and frequency response - Confined Gaussian (sigma t = 0.1).svg|thumb|480px|right|Confined Gaussian window, ''σ''&lt;sub&gt;''t''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.1; ''B''&amp;nbsp;=&amp;nbsp;1.9982.]]

==== Confined Gaussian window ====
The confined Gaussian window yields the smallest possible root mean square frequency width ''σ''&lt;sub&gt;''ω''&lt;/sub&gt; for a given temporal width N''σ''&lt;sub&gt;''t''&lt;/sub&gt;.&lt;ref name="Starosielec2014"&gt;{{cite journal |last=Starosielec |first=S. |last2=Hägele |first2=D. |title=Discrete-time windows with minimal RMS bandwidth for given RMS temporal width |journal=Signal Processing |publisher=Elsevier |date=2014|doi=10.1016/j.sigpro.2014.03.033}}&lt;/ref&gt; These windows optimize the RMS time-frequency bandwidth products. They are computed as the minimum eigenvectors of a parameter-dependent matrix. The confined Gaussian window family contains the [[#Cosine window|cosine window]] and the [[#Gaussian window|Gaussian window]] in the limiting cases of large and small ''σ''&lt;sub&gt;''t''&lt;/sub&gt;, respectively.
{{clear}}

[[File:Window function and frequency response - Approximate confined Gaussian (sigma t = 0.1).svg|thumb|480px|right|Approximate confined Gaussian window, ''σ''&lt;sub&gt;''t''&lt;/sub&gt;&amp;nbsp;=&amp;nbsp;0.1; ''B''&amp;nbsp;=&amp;nbsp;1.9979.]]

==== Approximate confined Gaussian window ====

A [[#Confined Gaussian window|confined Gaussian window]] of temporal width N''σ''&lt;sub&gt;''t''&lt;/sub&gt; is well approximated by:&lt;ref name="Starosielec2014"/&gt;

:&lt;math&gt;w(n) = G(n) - \frac{G(-\tfrac{1}{2})[G(n + N) + G(n - N)]}{G(-\tfrac{1}{2} + N) + G(-\tfrac{1}{2} - N)}&lt;/math&gt;

with the Gaussian:

::&lt;math&gt;G(x) = e^{- \left(\cfrac{x - \frac{N-1}{2}}{2 N \sigma_t}\right)^2}&lt;/math&gt;

The standard deviation of the approximate window is [[asymptotically equal]] (i.e. large values of N) to &amp;nbsp;N''σ''&lt;sub&gt;''t''&lt;/sub&gt;&amp;nbsp; for &amp;nbsp;''σ''&lt;sub&gt;''t''&lt;/sub&gt;&amp;nbsp;&lt;&amp;nbsp;0.14.&lt;ref name="Starosielec2014"/&gt;
{{clear}}

==== Generalized normal window ====
A more generalized version of the Gaussian window is the generalized normal window.&lt;ref&gt;Debejyo Chakraborty and Narayan Kovvali Generalized Normal Window for Digital Signal Processing in IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2013 6083 -- 6087 {{DOI|10.1109/ICASSP.2013.6638833}}&lt;/ref&gt; Retaining the notation from the [[Gaussian window]] above, we can represent this window as
:&lt;math&gt;w(n,p)=e^{-\left ( \frac{n-(N-1)/2}{\sigma (N-1)/2} \right)^{p}}&lt;/math&gt;
for any even &lt;math&gt;p&lt;/math&gt;. At &lt;math&gt;p=2&lt;/math&gt;, this is a Gaussian window and as &lt;math&gt;p&lt;/math&gt; approaches &lt;math&gt;\infty&lt;/math&gt;, this approximates to a rectangular window. The [[Fourier transform]] of this window does not exist in a closed form for a general &lt;math&gt;p&lt;/math&gt;. However, it demonstrates the other benefits of being smooth, adjustable bandwidth. Like the [[Tukey window]] discussed later, this window naturally offers a "flat top" to control the amplitude attenuation of a time-series (on which we don't have a control with Gaussian window). In essence, it offers a good (controllable) compromise, in terms of spectral leakage, frequency resolution and amplitude attenuation, between the Gaussian window and the rectangular window.
See also &lt;ref&gt;Diethorn, E.J., "The generalized exponential time-frequency distribution," Signal Processing, IEEE Transactions on , vol.42, no.5, pp.1028,1037, May 1994
doi: 10.1109/78.295214&lt;/ref&gt; for a study on [[time-frequency representation]] of this window (or function).

{{clear}}

==== Tukey window ====
[[File:Window function and frequency response - Tukey (alpha = 0.5).svg|thumb|480px|right|Tukey window, ''α''&amp;nbsp;=&amp;nbsp;0.5; ''B''&amp;nbsp;=&amp;nbsp;1.22.&lt;ref name="f.harris"/&gt;]]

The Tukey window,&lt;ref name="f.harris"&gt;
{{cite journal
  |doi=10.1109/PROC.1978.10837
  |last=Harris
  |first=Fredric J.
  |title=On the use of Windows for Harmonic Analysis with the Discrete Fourier Transform
  |journal=Proceedings of the IEEE
  |volume=66
  |issue=1
  |pages=51–83
  |date=Jan 1978
  |url=http://web.mit.edu/xiphmont/Public/windows.pdf}} '''The fundamental 1978 paper on FFT windows by Harris, which specified many windows and introduced key metrics used to compare them.'''&lt;/ref&gt;&lt;ref&gt;{{Cite journal  | last=Tukey | first=J.W. |  title = An introduction to the calculations of numerical spectrum analysis |  journal=Spectral Analysis of Time Series | year=1967  | pages=25–46  | postscript=&lt;!--None--&gt;  }}&lt;/ref&gt; also known as the ''tapered cosine window'', can be regarded as a cosine lobe of width ''αN''/2 that is convolved with a rectangular window of width (1&amp;nbsp;−&amp;nbsp;''α''/2)N.
:&lt;math&gt;
w(n) = \left\{ \begin{matrix}
\frac{1}{2} \left[1+\cos \left(\pi \left( \frac{2 n}{\alpha (N-1)}-1 \right) \right) \right]
&amp; 0 \leqslant n &lt; \frac{\alpha (N-1)}{2} \\ 
1 &amp; \frac{\alpha (N-1)}{2}\leqslant n \leqslant (N-1) (1 - \frac{\alpha}{2}) \\ 
\frac{1}{2} \left[1+\cos \left(\pi \left( \frac{2 n}{\alpha (N-1)}- \frac{2}{\alpha} + 1 \right) \right) \right]
&amp; (N-1) (1 - \frac{\alpha}{2}) &lt; n \leqslant  (N-1) \\
\end{matrix} \right.
&lt;/math&gt;&lt;ref group="note"&gt;Also see  [[havercosine]] ({{math|hvc}}) function.&lt;/ref&gt;

At ''α''&amp;nbsp;=&amp;nbsp;0 it becomes rectangular, and at ''α''&amp;nbsp;=&amp;nbsp;1 it becomes a Hann window.
{{clear}}

==== Planck-taper window ====
[[File:Window function and frequency response - Planck-taper (epsilon = 0.1).svg|thumb|480px|Planck-taper window, ''ε''&amp;nbsp;=&amp;nbsp;0.1; ''B''&amp;nbsp;=&amp;nbsp;1.10.]]

The so-called "Planck-taper" window is a [[bump function]] that has been widely used&lt;ref&gt;{{cite book |last=Tu |first=Loring W. |title=An Introduction to Manifolds |chapter=Bump Functions and Partitions of Unity |url=https://link.springer.com/chapter/10.1007%2F978-0-387-48101-2_13#page-1 |accessdate=2013-10-04 |year=2008 |publisher=Springer |location=New York |isbn=978-0-387-48098-5 |pages=127–134 }}&lt;/ref&gt; in the theory of [[partitions of unity]] in [[manifolds]].  It is [[Smooth function|smooth]] (a &lt;math&gt;C^\infty&lt;/math&gt; function) everywhere, but is exactly zero outside of a compact region, exactly one over an interval within that region, and varies smoothly and monotonically between those limits.  Its use as a window function in signal processing was first suggested in the context of [[gravitational-wave astronomy]], inspired by the [[Planck's law|Planck distribution]].&lt;ref&gt;{{cite journal |last=McKechan |first=D. J. A. |last2=Robinson |first2=C. |last3=Sathyaprakash |first3=B. S. |title=A tapering window for time-domain templates and simulated signals in the detection of gravitational waves from coalescing compact binaries|journal=Classical and Quantum Gravity|date=21 April 2010|volume=27|issue=8|pages=084020|doi=10.1088/0264-9381/27/8/084020|arxiv=1003.2939|bibcode = 2010CQGra..27h4020M }}&lt;/ref&gt; It is defined as a [[piecewise]] function''':'''
:&lt;math&gt;
w(n) = \left\{ \begin{matrix}
 \frac{1}{\exp(Z_+)+1} &amp; 0 \leqslant n &lt; \epsilon(N - 1) \\
 1 &amp; \epsilon(N - 1) &lt; n &lt; (1 - \epsilon)(N - 1) \\
 \frac{1}{\exp(Z_-)+1} &amp; (1 - \epsilon)(N - 1) &lt; n \leqslant (N - 1) \\
 0 &amp; \mbox{otherwise} \\
\end{matrix} \right.
&lt;/math&gt;
where
:&lt;math&gt;
Z_\pm(n; \epsilon) = 2\epsilon\left[\frac{1}{1 \pm (2 n /(N - 1) - 1)} + \frac{1}{1 - 2\epsilon \pm (2 n / (N - 1) - 1)}\right].
&lt;/math&gt;
The amount of tapering (the region over which the function is exactly 1) is controlled by the parameter ''ε'', with smaller values giving sharper transitions.

{{clear}}

==== DPSS or Slepian window ====
[[File:Window function and frequency response - DPSS (alpha = 2).svg|thumb|480px|right|DPSS window, ''α''&amp;nbsp;=&amp;nbsp;2; ''B''&amp;nbsp;=&amp;nbsp;1.47.]]
[[File:Window function and frequency response - DPSS (alpha = 3).svg|thumb|480px|right|DPSS window, ''α''&amp;nbsp;=&amp;nbsp;3; ''B''&amp;nbsp;=&amp;nbsp;1.77.]]

The DPSS (discrete prolate spheroidal sequence) or Slepian window [[Spectral concentration problem|maximizes the energy concentration in the main lobe]],&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Slepian_DPSS_Window.html|title=Slepian or DPSS Window|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt; and is used in [[multitaper]] spectral analysis, which averages out noise in the spectrum and reduces information loss at the edges of the window.

The main lobe ends at a frequency bin given by the parameter ''α''.&lt;ref name="JOSKaiserDPSS"&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Kaiser_DPSS_Windows_Compared.html|title=Kaiser and DPSS Windows Compared|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

{{clear}}

==== Kaiser window ====
[[File:Window function and frequency response - Kaiser (alpha = 2).svg|thumb|480px|right|Kaiser window, ''α''&amp;nbsp;=&amp;nbsp;2; ''B''&amp;nbsp;=&amp;nbsp;1.4963.]]
[[File:Window function and frequency response - Kaiser (alpha = 3).svg|thumb|480px|right|Kaiser window, ''α''&amp;nbsp;=&amp;nbsp;3; ''B''&amp;nbsp;=&amp;nbsp;1.7952.&lt;ref name=Heinzel2002/&gt;]]

{{Main|Kaiser window}}
The Kaiser, or Kaiser-Bessel, window is a simple approximation of the [[#DPSS or Slepian window|DPSS window]] using [[Bessel function]]s, discovered by [[James Kaiser]].&lt;ref name="JOSKaiserDPSS"/&gt;&lt;ref&gt;{{Cite book|title=System Analysis by Digital Computer|last=Kaiser|first=James F.|last2=Kuo|first2=Franklin F.|publisher=John Wiley and Sons|year=1966|isbn=|location=|pages=232–235|quote=This family of window functions was "discovered" by Kaiser in 1962 following a discussion with B. F. Logan of the Bell Telephone Laboratories. ... Another valuable property of this family ... is that they also approximate closely the prolate spheroidal wave functions of order zero|via=}}&lt;/ref&gt;&lt;ref&gt;{{Cite journal|last=Kaiser|first=James F.|date=November 1964|title=A family of window functions having nearly ideal properties|url=|journal=unpublished memorandum|location=Murray Hill, NJ|publisher=[[Bell Telephone Laboratories]]|volume=|issue=|doi=|pmid=|access-date=|via=}}&lt;/ref&gt;&lt;ref name="Kaiser"&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Kaiser_Window.html|title=Kaiser Window|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

:&lt;math&gt;w(n)=\frac{I_0\left(\pi\alpha \sqrt{1-(\frac{2 n}{N-1}-1)^2}\right)}{I_0(\pi\alpha)}&lt;/math&gt;

where ''I''&lt;sub&gt;0&lt;/sub&gt; is the zero-th order modified Bessel function of the first kind.  Variable parameter ''α'' determines the tradeoff between main lobe width and side lobe levels of the spectral leakage pattern.  The main lobe width, in between the nulls, is given by &amp;nbsp;&lt;math&gt;2\sqrt{1 + \alpha^2},&lt;/math&gt;&amp;nbsp; in units of DFT bins,&lt;ref name="Kaiser1980"&gt;{{Cite journal | last1 = Kaiser | first1 = James F. | last2 = Schafer | first2 = Ronald W. | doi = 10.1109/TASSP.1980.1163349 | title = On the use of the I&lt;sub&gt;0&lt;/sub&gt;-sinh window for spectrum analysis | journal = IEEE Transactions on Acoustics, Speech, and Signal Processing | volume = 28 | pages = 105–107| year = 1980 | pmid =  | pmc = }}&lt;/ref&gt;&amp;nbsp; and a typical value of ''α'' is 3.

* Sometimes the formula for w(n) is written in terms of a parameter &lt;math&gt;\beta  \ \stackrel{\text{def}}{=}\ \pi\alpha.&lt;/math&gt;&lt;ref name="Kaiser"/&gt;
* zero-phase version:
:&lt;math&gt;
w_0(n) = \frac{I_0\left(\pi\alpha \sqrt{1-(\frac{2 n}{N-1})^2}\right)}{I_0(\pi\alpha)}&lt;/math&gt;
{{clear}}

==== Dolph–Chebyshev window ====
[[File:Window function and frequency response - Dolph-Chebyshev (alpha = 5).svg|thumb|480px|right|Dolph–Chebyshev window, ''α''&amp;nbsp;=&amp;nbsp;5; ''B''&amp;nbsp;=&amp;nbsp;1.94.]]

Minimizes the [[Uniform norm|Chebyshev norm]] of the side-lobes for a given main lobe width.&lt;ref name="JOSDolphChebyshev"&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Dolph_Chebyshev_Window.html|title=Dolph-Chebyshev Window|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt;

The zero-phase Dolph–Chebyshev window function ''w&lt;sub&gt;0&lt;/sub&gt;''(''n'') is usually defined in terms of its real-valued discrete Fourier transform, ''W&lt;sub&gt;0&lt;/sub&gt;''(''k''):&lt;ref name="DolphChebyshevDefinition"&gt;{{Cite web|url=https://www.mathworks.com/help/signal/ref/sigwin.chebwin-class.html|title=sigwin.chebwin-class|website=mathworks.com|access-date=2016-12-09}}&lt;/ref&gt;

:&lt;math&gt;\begin{align}
 W_0(k) &amp;= \frac{\cos\{N \cos^{-1}[\beta \cos(\frac{\pi k}{N})]\}}{\cosh[N \cosh^{-1}(\beta)]}\\
 \beta &amp;= \cosh[\frac{1}{N} \cosh^{-1}(10^\alpha)],
\end{align}&lt;/math&gt;

where the parameter ''α'' sets the Chebyshev norm of the sidelobes to −20''α''&amp;nbsp;decibels.&lt;ref name="JOSDolphChebyshev"/&gt;

The window function can be calculated from ''W''&lt;sub&gt;0&lt;/sub&gt;(''k'') by an inverse [[discrete Fourier transform]] (DFT):&lt;ref name="JOSDolphChebyshev"/&gt;

:&lt;math&gt;w_0(n) = \frac{1}{N} \sum_{k=0}^{N-1} W_0(k) \cdot e^{i 2 \pi k n / N},\ -N/2 \le n \le N/2.&lt;/math&gt;

The ''lagged'' version of the window, with 0&amp;nbsp;≤&amp;nbsp;''n''&amp;nbsp;≤&amp;nbsp;''N''−1, can be obtained by:

:&lt;math&gt;w(n) = w_0\left(n-\frac{N-1}{2}\right),&lt;/math&gt;

which for even values of N must be computed as follows:

:&lt;math&gt;\begin{align}
w_0\left(n-\frac{N-1}{2}\right) 
= \frac{1}{N} \sum_{k=0}^{N-1} W_0(k) \cdot e^{i 2 \pi k (n-\frac{N-1}{2}) / N}
=\frac{1}{N} \sum_{k=0}^{N-1} \left[(-e^{\frac{i\pi}{N}})^k\cdot W_0(k)\right] e^{i 2 \pi k n / N},
\end{align}&lt;/math&gt;

which is an inverse DFT of &amp;nbsp;&lt;math&gt;(-e^{\frac{i\pi}{N}})^k\cdot W_0(k).&lt;/math&gt;

Variations:
*Due to the equiripple condition, the time-domain window has discontinuities at the edges.  An approximation that avoids them, by allowing the equiripples to drop off at the edges, is a [http://www.mathworks.com/help/signal/ref/taylorwin.html Taylor window].
*An alternative to the inverse DFT definition is also available.[http://practicalcryptography.com/miscellaneous/machine-learning/implementing-dolph-chebyshev-window/].
{{clear}}

==== Ultraspherical window ====
[[File:Window function and frequency response - Ultraspherical (mu = -0.5).svg|thumb|481px|right|The Ultraspherical window's ''µ'' parameter determines whether its Fourier transform's side-lobe amplitudes decrease, are level, or (shown here) increase with frequency.]]
The Ultraspherical window was introduced in 1984 by Roy Streit&lt;ref name=kabal&gt;{{cite journal|last=Kabal|first=Peter|title=Time Windows for Linear Prediction of Speech|journal=Technical Report, Dept. Elec. &amp; Comp. Eng., McGill University|year=2009|issue=2a|page=31|url=http://www-mmsp.ece.mcgill.ca/Documents/Reports/2009/KabalR2009b.pdf|accessdate=2 February 2014}}&lt;/ref&gt; and has application in  antenna array design,&lt;ref name=streit&gt;{{cite journal|last=Streit|first=Roy|title=A two-parameter family of weights for nonrecursive digital filters and antennas|journal=Transactions of ASSP|year=1984|volume=32|pages=108–118|doi=10.1109/tassp.1984.1164275}}&lt;/ref&gt; non-recursive filter design,&lt;ref name=kabal /&gt; and spectrum analysis.&lt;ref name=deczky /&gt;

Like other adjustable windows, the Ultraspherical window has parameters that can be used to control its Fourier transform main-lobe width and relative side-lobe amplitude. Uncommon to other windows, it has an additional parameter which can be used to set the rate at which side-lobes decrease (or increase) in amplitude.&lt;ref name=deczky /&gt;&lt;ref name=bergen&gt;{{cite journal
  |last=Bergen
  |first=S. W. A.
  |first2=A. |last2=Antoniou
  |title=Design of Ultraspherical Window Functions with Prescribed Spectral Characteristics
  |journal=EURASIP Journal on Applied Signal Processing
  |volume=2004
  |issue=13
  |pages=2053–2065
  |year=2004
  |doi=10.1155/S1110865704403114 |bibcode=2004EJASP2004...63B
  }}&lt;/ref&gt;

The window can be expressed in the time-domain as follows:&lt;ref name=deczky /&gt;

:&lt;math&gt;\begin{align}
w\left(n\right) 
= \frac{1}{N} \left[ C^{\mu}_{N-1}(x_0)+\sum_{k=1}^{\frac{N-1}{2}}  C^{\mu}_{N-1}\left(x_{0}\cos\frac{k\pi}{N}\right)\cos\frac{2n\pi k}{N} \right]
\end{align}&lt;/math&gt;

where &lt;math&gt;C^{\mu}_{N}&lt;/math&gt; is the [[Ultraspherical polynomial]] of degree N, and &lt;math&gt;x_0&lt;/math&gt; and &lt;math&gt;\mu&lt;/math&gt; control the side-lobe patterns.&lt;ref name=deczky&gt;{{cite journal |last=Deczky |first=Andrew |title=Unispherical Windows |journal=IEEE Int. Symp. on Circuits and Systems |year=2001 |volume=II |pages=85–88 |doi=10.1109/iscas.2001.921012}}&lt;/ref&gt;

Certain specific values of &lt;math&gt;\mu&lt;/math&gt; yield other well-known windows: &lt;math&gt;\mu=0&lt;/math&gt; and &lt;math&gt;\mu=1&lt;/math&gt; give the Dolph–Chebyshev and Saramäki windows respectively.&lt;ref name=kabal /&gt; See [http://octave.sourceforge.net/signal/function/ultrwin.html here] for illustration of Ultraspherical windows with varied parametrization.
{{clear}}

==== Exponential or Poisson window ====
[[File:Window function and frequency response - Exponential (half window decay).svg|thumb|480px|Exponential window, ''τ''&amp;nbsp;=&amp;nbsp;''N''/2, ''B''&amp;nbsp;=&amp;nbsp;1.08.]]
[[File:Window function and frequency response - Exponential (60dB decay).svg|thumb|480px|Exponential window, ''τ''&amp;nbsp;=&amp;nbsp;(''N''/2)/(60/8.69), ''B''&amp;nbsp;=&amp;nbsp;3.46.]]

The Poisson window, or more generically the exponential window increases exponentially towards the center of the window and decreases exponentially in the second half. Since the [[exponential function]] never reaches zero, the values of the window at its limits are non-zero (it can be seen as the multiplication of an exponential function by a rectangular window &lt;ref&gt;{{Citation
  | last = Smith
  | first = Julius O. III
  | author-link = 
  | title = Spectral Audio Signal Processing
  | date = April 23, 2011
  | url = https://ccrma.stanford.edu/~jos/sasp/Poisson_Window.html
  | accessdate = November 22, 2011}}&lt;/ref&gt;). It is defined by

:&lt;math&gt;w(n)=e^{-\left|n-\frac{N-1}{2}\right|\frac{1}{\tau}},&lt;/math&gt;

where ''τ'' is the time constant of the function. The exponential function decays as ''e''&amp;nbsp;≃&amp;nbsp;2.71828 or approximately 8.69&amp;nbsp;dB per time constant.&lt;ref&gt;{{cite web
  | last = Gade
  | first = Svend
  | last2 = Herlufsen
  | first2 = Henrik
  | title = Technical Review No 3-1987: Windows to FFT analysis (Part I)
  | publisher = Brüel &amp; Kjær
  | year = 1987
  | url = http://www.bksv.com/doc/Bv0031.pdf
  | accessdate = November 22, 2011}}&lt;/ref&gt;
This means that for a targeted decay of ''D''&amp;nbsp;dB over half of the window length, the time constant ''τ'' is given by

:&lt;math&gt;\tau = \frac{N}{2}\frac{8.69}{D}.&lt;/math&gt;
{{clear}}

=== Hybrid windows ===

Window functions have also been constructed as multiplicative or additive combinations of other windows.

==== Bartlett–Hann window ====
[[File:Window function and frequency response - Bartlett-Hann.svg|thumb|480px|right|Bartlett–Hann window; ''B''&amp;nbsp;=&amp;nbsp;1.46.]]

:&lt;math&gt;w(n)=a_0 - a_1 \left |\frac{n}{N-1}-\frac{1}{2} \right| - a_2 \cos \left (\frac{2 \pi n}{N-1}\right )&lt;/math&gt;

:&lt;math&gt;a_0=0.62;\quad a_1=0.48;\quad a_2=0.38\,&lt;/math&gt;
{{clear}}

==== Planck–Bessel window ====

[[File:Window function and frequency response - Planck-Bessel (epsilon = 0.1, alpha = 4.45).svg|thumb|480px|right|Planck–Bessel window, ''ε''&amp;nbsp;=&amp;nbsp;0.1, ''α''&amp;nbsp;=&amp;nbsp;4.45; ''B''&amp;nbsp;=&amp;nbsp;2.16.]]

A [[#Planck-taper window|Planck-taper window]] multiplied by a [[Kaiser window]] which is defined in terms of a [[Modified Bessel function#Modified Bessel functions : I.CE.B1.2C K.CE.B1|modified Bessel function]]. This hybrid window function was introduced to decrease the peak side-lobe level of the Planck-taper window while still exploiting its good asymptotic decay.&lt;ref&gt;{{cite journal |last=Berry |first=C. P. L. |last2=Gair |first2=J. R. |title=Observing the Galaxy's massive black hole with gravitational wave bursts |journal=[[Monthly Notices of the Royal Astronomical Society]] |date=12 December 2012 |volume=429 |issue=1 |arxiv=1210.2778 |pages=589–612 |doi=10.1093/mnras/sts360|bibcode=2013MNRAS.429..589B }}&lt;/ref&gt; It has two tunable parameters, ''ε'' from the Planck-taper and ''α'' from the Kaiser window, so it can be adjusted to fit the requirements of a given signal.

{{clear}}

==== Hann–Poisson window ====
[[File:Window function and frequency response - Hann-Poisson (alpha = 2).svg|thumb|480px|Hann–Poisson window, ''α''&amp;nbsp;=&amp;nbsp;2; ''B''&amp;nbsp;=&amp;nbsp;2.02&lt;ref name="f.harris"/&gt;]]
A [[#Hann_.28Hanning.29_window|Hann window]] multiplied by a [[#Exponential_or_Poisson_window|Poisson window]], which has no side-lobes, in the sense that its Fourier transform drops off forever away from the main lobe.  It can thus be used in [[hill climbing]] algorithms like [[Newton's method]].&lt;ref&gt;{{Cite web|url=https://ccrma.stanford.edu/~jos/sasp/Hann_Poisson_Window.html|title=Hann-Poisson Window|website=ccrma.stanford.edu|access-date=2016-04-13}}&lt;/ref&gt; The Hann–Poisson window is defined by:

:&lt;math&gt;w(n)=\frac{1}{2}\left(1-\cos\left(\frac{2 \pi n}{N - 1}\right)\right)e^\frac{-\alpha\left|N - 1 - 2n\right|}{N - 1}\,=\operatorname{hav}\left(\frac{2 \pi n}{N - 1}\right)e^\frac{-\alpha\left|N - 1 - 2n\right|}{N - 1}\,&lt;/math&gt;

where ''α'' is a parameter that controls the slope of the exponential.
{{Clear}}

=== Other windows ===

==== Lanczos window ====
[[File:Window function and frequency response - Lanczos.svg|thumb|480px|right|Sinc or Lanczos window; ''B''&amp;nbsp;=&amp;nbsp;1.30.&lt;ref name="f.harris"/&gt;]]
:&lt;math&gt;w(n) = \mathrm{sinc}\left(\frac{2n}{N-1}-1\right)&lt;/math&gt;

* used in [[Lanczos resampling]]
* for the Lanczos window, &lt;math&gt;\mathrm{sinc}(x)&lt;/math&gt; is defined as &lt;math&gt;{\sin(\pi x)}/{\pi x}&lt;/math&gt;
* also known as a ''sinc window'', because''':'''
::&lt;math&gt;w_0(n) = \mathrm{sinc}\left(\frac{2n}{N-1}\right)\,&lt;/math&gt; is the main lobe of a normalized [[sinc function]]
{{clear}}

== Comparison of windows ==

[[File:Window functions in the frequency domain.png|thumb|500px|right|Window functions in the frequency domain ("spectral leakage")]]

When selecting an appropriate window function for an application, this comparison graph may be useful. The frequency axis has units of FFT "bins" when the window of length N is applied to data and a transform of length N is computed.  For instance, the value at frequency ½ "bin" (third tick mark) is the response that would be measured in bins k and k+1 to a sinusoidal signal at frequency k+½.  It is relative to the maximum possible response, which occurs when the signal frequency is an integer number of bins.  The value at frequency ½ is referred to as the maximum ''scalloping loss'' of the window, which is one metric used to compare windows.  The rectangular window is noticeably worse than the others in terms of that metric.

Other metrics that can be seen are the width of the main lobe and the peak level of the sidelobes, which respectively determine the ability to resolve comparable strength signals and disparate strength signals.  The rectangular window (for instance) is the best choice for the former and the worst choice for the latter.  What cannot be seen from the graphs is that the rectangular window has the best noise bandwidth, which makes it a good candidate for detecting low-level sinusoids in an otherwise [[white noise]] environment.  Interpolation techniques, such as [[Discrete-time Fourier transform#Sampling the DTFT|zero-padding]] and frequency-shifting, are available to mitigate its potential scalloping loss. {{clear}}

== Overlapping windows ==

When the length of a data set to be transformed is larger than necessary to provide the desired frequency resolution, a common practice is to subdivide it into smaller sets and window them individually.  To mitigate the "loss" at the edges of the window, the individual sets may overlap in time.  See [[Welch method]] of power spectral analysis and the [[modified discrete cosine transform]].

== Two-dimensional windows ==
Two-dimensional windows are used in, e.g., image processing. They can be constructed from one-dimensional windows in either of two forms.&lt;ref&gt;Matt A. Bernstein, Kevin Franklin King, Xiaohong Joe Zhou (2007), Handbook of MRI Pulse Sequences, Elsevier; p.495-499. [https://books.google.com/books?id=d6PLHcyejEIC&amp;lpg=PA495&amp;ots=tcBHi9Obfy&amp;dq=image%20tapering%20tukey&amp;pg=PA496#v=onepage&amp;q&amp;f=false]&lt;/ref&gt;

The separable form, &lt;math&gt;W(m,n)=w(m)w(n)&lt;/math&gt; is trivial to compute. The [[Radial function|radial]] form, &lt;math&gt;W(m,n)=w(r)&lt;/math&gt;, which involves the radius &lt;math&gt;r=\sqrt{(m-M/2)^2+(n-N/2)^2}&lt;/math&gt;, is [[Isotropy|isotropic]], independent on the orientation of the coordinate axes. Only the [[#Gaussian_window|Gaussian]] function is both separable and isotropic.&lt;ref&gt;{{Cite book | last1 = Awad | first1 = A. I. | last2 = Baba | first2 = K. | chapter = An Application for Singular Point Location in Fingerprint Classification | doi = 10.1007/978-3-642-22389-1_24 | title = Digital Information Processing and Communications | series = Communications in Computer and Information Science | volume = 188 | pages = 262 | year = 2011 | isbn = 978-3-642-22388-4 | pmid =  | pmc = }}&lt;/ref&gt; The separable forms of all other window functions have corners that depend on the choice of the coordinate axes. The isotropy/[[anisotropy]] of a two-dimensional window function is shared by its two-dimensional Fourier transform. The difference between the separable and radial forms is akin to the result of [[diffraction]] from rectangular vs. circular appertures, which can be visualized in terms of the product of two [[sinc function]]s vs. an [[Airy function]], respectively.

== See also ==
{{Commons category|Window function}}
* [[Spectral leakage]]
* [[Multitaper]]
* [[Apodization]]
* [[Welch method]]
* [[Short-time Fourier transform]]
* [[Window design method]]
* [[Kolmogorov–Zurbenko filter]]

== Notes ==

{{reflist|group=note}}

==References==

{{reflist}}

== Further reading ==
{{refbegin}}
* {{Cite book
 |last=Albrecht |first=Hans-Helge
 |authorlink= 
 |title=Tailored minimum sidelobe and minimum sidelobe cosine-sum windows. A catalog.
 |year=2012
 |publisher=
 |location=  
 |isbn=
 |pages=
 |doi=10.7795/110.20121022aa
}}
* {{cite journal
  |last=Bergen
  |first=S. W. A.
  |first2=A. |last2=Antoniou
  |title=Design of Ultraspherical Window Functions with Prescribed Spectral Characteristics
  |journal=EURASIP Journal on Applied Signal Processing
  |volume=2004
  |issue=13
  |pages=2053–2065
  |year=2004
  |doi=10.1155/S1110865704403114 |bibcode=2004EJASP2004...63B
  }}
* {{cite journal
  |last = Bergen
  |first = S. W. A.
  |first2=A. |last2=Antoniou
  |title=Design of Nonrecursive Digital Filters Using the Ultraspherical Window Function
  |journal=EURASIP Journal on Applied Signal Processing
  |volume=2005
  |issue=12
  |pages=1910–1922
  |year=2005
  |doi=10.1155/ASP.2005.1910 |bibcode=2005EJASP2005...44B
  }}
* {{cite journal
  | doi = 10.1109/TASSP.1981.1163506
  | last = Nuttall
  | first = Albert H.
  | title = Some Windows with Very Good Sidelobe Behavior
  | journal = IEEE Transactions on Acoustics, Speech, and Signal Processing
  | volume = 29
  | issue = 1
  | pages = 84–91
  |date=February 1981}} Extends Harris' paper, covering all the window functions known at the time, along with key metric comparisons.
* {{Cite book
 |last=Oppenheim |first=Alan V. |authorlink=Alan V. Oppenheim
 |last2=Schafer |first2=Ronald W. |author2-link=Ronald W. Schafer
 |last3=Buck |first3=John A. 
 |title=Discrete-time signal processing
 |year=1999
 |publisher=Prentice Hall
 |location=Upper Saddle River, N.J.
 |isbn=0-13-754920-2
 |pages=468–471
}}
* {{Cite book
 |last=Prabhu |first=K. M. M.
 |title=Window Functions and Their Applications in Signal Processing
 |year=2014
 |publisher=CRC Press
 |location=Boca Raton, FL
 |isbn=978-1-4665-1583-3
}}
* {{Cite patent
 | title = System and method for generating a root raised cosine orthogonal frequency division multiplexing (RRC OFDM) modulation
 | country-code = US
 | description = patent
 | patent-number = 7065150
 | postscript = &lt;!--None--&gt;
 | inventor-last =Park
 | inventor-first =Young-Seo
 | publication-date = 2003
 | issue-date = 2006
 |ref=none
}}

==External links==
* LabView Help, Characteristics of Smoothing Filters, http://zone.ni.com/reference/en-XX/help/371361B-01/lvanlsconcepts/char_smoothing_windows/
* Evaluation of Various Window Function using Multi-Instrument, http://www.multi-instrument.com/doc/D1003/Evaluation_of_Various_Window_Functions_using_Multi-Instrument_D1003.pdf
* Creation and properties of Cosine-sum Window functions, http://electronicsart.weebly.com/fftwindows.html
{{refend}}

[[Category:Fourier analysis]]
[[Category:Signal estimation]]
[[Category:Digital signal processing]]
[[Category:Types of functions]]</text>
      <sha1>q8ivg3013a7xphj4slzxjor0okuovht</sha1>
    </revision>
  </page>
  <page>
    <title>Yiannis N. Moschovakis</title>
    <ns>0</ns>
    <id>2291002</id>
    <revision>
      <id>813391521</id>
      <parentid>813391464</parentid>
      <timestamp>2017-12-03T12:46:09Z</timestamp>
      <contributor>
        <username>Omnipaedista</username>
        <id>8524693</id>
      </contributor>
      <comment>resectioning per WP:LEAD</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="4291">{{Infobox scientist
|image = Yiannis Moschovakis.jpg
|image_size = 150px
|name              = Yiannis N. Moschovakis
|birth_name=Yiannis Nicholas Moschovakis
|birth_date        = {{birth date and age|1938|1|18}}
|birth_place       = [[Athens]], [[Greece]]
|death_date        = 
|death_place       = 
|residence         = 
|citizenship       = 
|nationality       = 
|ethnicity         = 
|field             = [[Mathematics]]
|work_institutions = [[University of California, Los Angeles|UCLA]]
|alma_mater        = [[University of Wisconsin–Madison]]
|doctoral_advisor  = [[Stephen Kleene]]
|doctoral_students = [[Alexander S. Kechris]]
|known_for         = [[Effective descriptive set theory]]
|author_abbrev_bot = 
|author_abbrev_zoo = 
|prizes            = 
|religion          = 
|signature         =
|footnotes         = 
}}
'''Yiannis Nicholas Moschovakis''' ({{lang-el|Γιάννης Μοσχοβάκης}}; born January 18, 1938) is a [[Set theory|set theorist]], [[Descriptive set theory|descriptive set theorist]], and [[recursion theory|recursion (computability) theorist]], at [[UCLA]].

His book ''Descriptive Set Theory'' (North-Holland) is the primary reference for the subject. He is especially associated with the development of the [[Effective descriptive set theory|effective]], or [[lightface pointclass|lightface]], version of descriptive set theory, and he is known for the [[Moschovakis coding lemma]] that is named after him.

==Biography==
Moschovakis earned his [[Ph.D.]] from [[University of Wisconsin–Madison]] in 1963 under the direction of [[Stephen Kleene]], with a dissertation entitled ''Recursive Analysis''. In 2015 he was elected as a [[fellow]] of the [[American Mathematical Society]] "for contributions to mathematical logic, especially set theory and computability theory, and for exposition".&lt;ref&gt;{{citation|url=http://www.ams.org/profession/ams-fellows/new-fellows|title=2016 Class of the Fellows of the AMS|publisher=[[American Mathematical Society]]|accessdate=2015-11-16}}.&lt;/ref&gt;

For many years he has split his time between UCLA and [[University of Athens]] (he retired from the latter in July 2005).

Moschovakis is married to [[Joan Moschovakis]], with whom he gave the 2014 Lindström Lectures at the [[University of Gothenburg]].&lt;ref&gt;http://flov.gu.se/english/research/logic/lindstrom-lectures&lt;/ref&gt;

==Publications==
* {{cite book|title=Elementary induction on abstract structures|year=1974|publisher=North-Holland}}&lt;ref&gt;{{cite journal|author=Barwise, K. Jon|authorlink=Jon Barwise|title=Review: ''Elementary induction on abstract structures'', by Y. Moschovakis|journal=Bull. Amer. Math. Soc.|year=1975|volume=81|issue=6|pages=1031–1035|url=http://www.ams.org/journals/bull/1975-81-06/S0002-9904-1975-13893-6/|doi=10.1090/s0002-9904-1975-13893-6}}&lt;/ref&gt; {{cite book|title=2nd edn|publisher=Dover|year=2008|url=https://books.google.com/books/about/Elementary_Induction_on_Abstract_Structu.html?id=WOBHLPItEasC}}
* {{cite book|title=Descriptive set theory|year=1980|publisher=North-Holland}}&lt;ref&gt;{{cite journal|author=Jech, Thomas|authorlink=Thomas Jech|title=Review: ''Descriptive set theory'', by Y. Moschovakis|journal=Bull. Amer. Math. Soc. (N.S.)|year=1981|volume=5|issue=3|pages=339–349|url=http://www.ams.org/journals/bull/1981-05-03/S0273-0979-1981-14952-1/|doi=10.1090/s0273-0979-1981-14952-1}}&lt;/ref&gt; {{cite book|title=2nd edn|year=2005}} [http://www.math.ucla.edu/~ynm/books.htm Second edition available online]
* {{cite book|title=Notes on set theory|year=1994|publisher=North-Holland|url=https://books.google.com/books/about/Notes_on_Set_Theory.html?id=ndx0_6VCypcC}} {{cite book|title=2nd edn|year=2005}}

==References==
{{reflist}}

==External links==
* [http://www.math.ucla.edu/~ynm/ Home page]
* {{MathGenealogy|id=8414}}

{{Authority control}}

{{DEFAULTSORT:Moschovakis, Yiannis N.}}
[[Category:Living people]]
[[Category:20th-century mathematicians]]
[[Category:21st-century mathematicians]]
[[Category:American logicians]]
[[Category:Greek logicians]]
[[Category:Greek mathematicians]]
[[Category:Greek academics]]
[[Category:Set theorists]]
[[Category:University of California, Los Angeles faculty]]
[[Category:1938 births]]
[[Category:Tarski lecturers]]
[[Category:Fellows of the American Mathematical Society]]</text>
      <sha1>9v6u3ybc752pmev63rd9asjuy9y0jpv</sha1>
    </revision>
  </page>
  <page>
    <title>Zeno machine</title>
    <ns>0</ns>
    <id>1256751</id>
    <revision>
      <id>769240480</id>
      <parentid>647268557</parentid>
      <timestamp>2017-03-08T10:19:32Z</timestamp>
      <contributor>
        <username>Antepali</username>
        <id>27424999</id>
      </contributor>
      <comment>/* Zeno machines and computability */ cleanup. References under 'hypercomputation' now.</comment>
      <model>wikitext</model>
      <format>text/x-wiki</format>
      <text xml:space="preserve" bytes="2257">{{Nofootnotes|date=November 2009}}
In [[mathematics]] and [[computer science]], '''Zeno machines''' (abbreviated '''ZM''', and also called '''accelerated Turing machine''', '''ATM''') are a hypothetical computational model related to [[Turing machines]] that allows a [[countably infinite]] number of algorithmic steps to be performed in finite time.  These machines are ruled out in most models of computation.

More formally, a Zeno machine is a Turing machine that takes 2&lt;sup&gt;−''n''&lt;/sup&gt; units of time to perform its ''n''-th step; thus, the first step takes 0.5 units of time, the second takes 0.25, the third 0.125 and so on, so that after one unit of time, a [[countably infinite]] (i.e. [[aleph_0#Aleph-null|&amp;alefsym;&lt;sub&gt;0&lt;/sub&gt;]]&lt;!-- &lt;math&gt;\aleph_0&lt;/math&gt; --&gt;) number of steps will have been performed.

The idea of Zeno machines was first discussed by [[Hermann Weyl]] in 1927; the name refers to [[Zeno's paradoxes]], attributed to the ancient Greek philosopher [[Zeno of Elea]]. Zeno machines play a crucial role in some theories. The theory of the [[Omega Point]] devised by physicist [[Frank J. Tipler]], for instance, can only be valid if Zeno machines are possible.

== Zeno machines and computability ==

Zeno machines would allow some functions to be computed that are not Turing-computable. For example, the [[halting problem]] for Turing machines can be solved by a Zeno machine (using the following [[pseudocode]] algorithm):

 begin program
   write 0 on the first position of the output tape;
   begin loop
     simulate 1 successive step of the given Turing machine on the given input;
     if the Turing machine has halted, then write 1 on the first position of the output tape and break out of loop;
   end loop
 end program

Computing of this kind that goes beyond the Turing Limit is called [[hypercomputation]], in this case hypercomputation through a [[supertask]] - see there for further discussion and literature.

== See also ==
* [[Hypercomputation]]
* [[Ross–Littlewood paradox]]
* [[Supertask]]
* [[Thomson's lamp]]
* [[Frank J. Tipler#The Omega Point|Tipler's Omega Point]]
* [[Zeno's paradoxes]]

[[Category:Models of computation]]
[[Category:Turing machine]]
[[Category:Hypercomputation]]
[[Category:Supertasks]]</text>
      <sha1>hyhgwppge9vywsi9vyvh9zr1ytvmgyr</sha1>
    </revision>
  </page>
</mediawiki>
